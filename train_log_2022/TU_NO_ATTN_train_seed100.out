2022-01-21 20:45:10,073 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-21 20:45:10,073 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-21 20:45:10,073 ============================================================
2022-01-21 20:45:10,073 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-21 20:45:10,073 ============================================================
2022-01-21 20:45:10,074 Loading data...
2022-01-21 20:45:10,074 Reading NCI - RUNMC images...
2022-01-21 20:45:10,074 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-21 20:45:10,075 Already preprocessed this configuration. Loading now!
2022-01-21 20:45:10,090 Training Images: (256, 256, 286)
2022-01-21 20:45:10,090 Training Labels: (256, 256, 286)
2022-01-21 20:45:10,090 Validation Images: (256, 256, 98)
2022-01-21 20:45:10,090 Validation Labels: (256, 256, 98)
2022-01-21 20:45:10,090 ============================================================
2022-01-21 20:45:10,117 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-21 20:45:13,022 iteration 1 : loss : 0.926133, loss_ce: 1.128748
2022-01-21 20:45:14,155 iteration 2 : loss : 0.885034, loss_ce: 1.039615
2022-01-21 20:45:15,268 iteration 3 : loss : 0.831636, loss_ce: 0.935393
2022-01-21 20:45:16,439 iteration 4 : loss : 0.760659, loss_ce: 0.850705
2022-01-21 20:45:17,532 iteration 5 : loss : 0.720961, loss_ce: 0.760554
2022-01-21 20:45:18,742 iteration 6 : loss : 0.673715, loss_ce: 0.695171
2022-01-21 20:45:19,921 iteration 7 : loss : 0.655818, loss_ce: 0.653985
2022-01-21 20:45:21,102 iteration 8 : loss : 0.616614, loss_ce: 0.595394
2022-01-21 20:45:22,171 iteration 9 : loss : 0.570165, loss_ce: 0.554960
2022-01-21 20:45:23,358 iteration 10 : loss : 0.551496, loss_ce: 0.510736
2022-01-21 20:45:24,551 iteration 11 : loss : 0.524628, loss_ce: 0.463128
2022-01-21 20:45:25,780 iteration 12 : loss : 0.491786, loss_ce: 0.428838
2022-01-21 20:45:26,916 iteration 13 : loss : 0.470028, loss_ce: 0.385418
2022-01-21 20:45:28,139 iteration 14 : loss : 0.450224, loss_ce: 0.360926
2022-01-21 20:45:29,298 iteration 15 : loss : 0.430683, loss_ce: 0.327031
2022-01-21 20:45:30,439 iteration 16 : loss : 0.426389, loss_ce: 0.314656
2022-01-21 20:45:31,556 iteration 17 : loss : 0.419781, loss_ce: 0.277466
  0%|                               | 1/400 [00:21<2:23:02, 21.51s/it]2022-01-21 20:45:32,822 iteration 18 : loss : 0.371668, loss_ce: 0.262385
2022-01-21 20:45:34,007 iteration 19 : loss : 0.377442, loss_ce: 0.228472
2022-01-21 20:45:35,281 iteration 20 : loss : 0.339750, loss_ce: 0.226817
2022-01-21 20:45:36,425 iteration 21 : loss : 0.387842, loss_ce: 0.230528
2022-01-21 20:45:37,522 iteration 22 : loss : 0.337793, loss_ce: 0.192549
2022-01-21 20:45:38,729 iteration 23 : loss : 0.327333, loss_ce: 0.182786
2022-01-21 20:45:39,939 iteration 24 : loss : 0.289764, loss_ce: 0.169414
2022-01-21 20:45:41,175 iteration 25 : loss : 0.337934, loss_ce: 0.221414
2022-01-21 20:45:42,334 iteration 26 : loss : 0.297345, loss_ce: 0.184375
2022-01-21 20:45:43,445 iteration 27 : loss : 0.318680, loss_ce: 0.185498
2022-01-21 20:45:44,550 iteration 28 : loss : 0.251440, loss_ce: 0.135563
2022-01-21 20:45:45,734 iteration 29 : loss : 0.380428, loss_ce: 0.203755
2022-01-21 20:45:46,864 iteration 30 : loss : 0.286540, loss_ce: 0.147419
2022-01-21 20:45:47,973 iteration 31 : loss : 0.266776, loss_ce: 0.123747
2022-01-21 20:45:49,120 iteration 32 : loss : 0.300216, loss_ce: 0.167797
2022-01-21 20:45:50,319 iteration 33 : loss : 0.302421, loss_ce: 0.159097
2022-01-21 20:45:51,571 iteration 34 : loss : 0.252217, loss_ce: 0.123179
  0%|▏                              | 2/400 [00:41<2:16:46, 20.62s/it]2022-01-21 20:45:52,820 iteration 35 : loss : 0.267913, loss_ce: 0.140035
2022-01-21 20:45:54,000 iteration 36 : loss : 0.296047, loss_ce: 0.116289
2022-01-21 20:45:55,198 iteration 37 : loss : 0.253521, loss_ce: 0.104180
2022-01-21 20:45:56,369 iteration 38 : loss : 0.274026, loss_ce: 0.115436
2022-01-21 20:45:57,455 iteration 39 : loss : 0.303860, loss_ce: 0.137388
2022-01-21 20:45:58,599 iteration 40 : loss : 0.312123, loss_ce: 0.152697
2022-01-21 20:45:59,672 iteration 41 : loss : 0.215911, loss_ce: 0.102174
2022-01-21 20:46:00,856 iteration 42 : loss : 0.291901, loss_ce: 0.151592
2022-01-21 20:46:02,026 iteration 43 : loss : 0.225723, loss_ce: 0.105542
2022-01-21 20:46:03,109 iteration 44 : loss : 0.259944, loss_ce: 0.138596
2022-01-21 20:46:04,334 iteration 45 : loss : 0.275817, loss_ce: 0.119136
2022-01-21 20:46:05,504 iteration 46 : loss : 0.242403, loss_ce: 0.112378
2022-01-21 20:46:06,673 iteration 47 : loss : 0.272866, loss_ce: 0.127402
2022-01-21 20:46:07,842 iteration 48 : loss : 0.266830, loss_ce: 0.137997
2022-01-21 20:46:09,064 iteration 49 : loss : 0.276016, loss_ce: 0.129326
2022-01-21 20:46:10,277 iteration 50 : loss : 0.426146, loss_ce: 0.197800
2022-01-21 20:46:11,509 iteration 51 : loss : 0.404796, loss_ce: 0.187876
  1%|▏                              | 3/400 [01:01<2:14:22, 20.31s/it]2022-01-21 20:46:12,677 iteration 52 : loss : 0.389397, loss_ce: 0.155443
2022-01-21 20:46:13,775 iteration 53 : loss : 0.356874, loss_ce: 0.152787
2022-01-21 20:46:14,994 iteration 54 : loss : 0.337644, loss_ce: 0.130130
2022-01-21 20:46:16,187 iteration 55 : loss : 0.348190, loss_ce: 0.131048
2022-01-21 20:46:17,393 iteration 56 : loss : 0.344955, loss_ce: 0.174297
2022-01-21 20:46:18,530 iteration 57 : loss : 0.342121, loss_ce: 0.168090
2022-01-21 20:46:19,642 iteration 58 : loss : 0.349288, loss_ce: 0.180580
2022-01-21 20:46:20,763 iteration 59 : loss : 0.317964, loss_ce: 0.147648
2022-01-21 20:46:21,904 iteration 60 : loss : 0.299735, loss_ce: 0.144356
2022-01-21 20:46:23,049 iteration 61 : loss : 0.307656, loss_ce: 0.145438
2022-01-21 20:46:24,278 iteration 62 : loss : 0.304893, loss_ce: 0.113937
2022-01-21 20:46:25,415 iteration 63 : loss : 0.312923, loss_ce: 0.140165
2022-01-21 20:46:26,595 iteration 64 : loss : 0.319680, loss_ce: 0.124517
2022-01-21 20:46:27,768 iteration 65 : loss : 0.286784, loss_ce: 0.105986
2022-01-21 20:46:28,991 iteration 66 : loss : 0.314599, loss_ce: 0.123293
2022-01-21 20:46:30,143 iteration 67 : loss : 0.304944, loss_ce: 0.136024
2022-01-21 20:46:31,242 iteration 68 : loss : 0.290902, loss_ce: 0.121026
  1%|▎                              | 4/400 [01:21<2:12:31, 20.08s/it]2022-01-21 20:46:32,496 iteration 69 : loss : 0.297796, loss_ce: 0.123325
2022-01-21 20:46:33,641 iteration 70 : loss : 0.323951, loss_ce: 0.125994
2022-01-21 20:46:34,797 iteration 71 : loss : 0.315642, loss_ce: 0.158776
2022-01-21 20:46:35,979 iteration 72 : loss : 0.298223, loss_ce: 0.123666
2022-01-21 20:46:37,178 iteration 73 : loss : 0.300721, loss_ce: 0.108518
2022-01-21 20:46:38,364 iteration 74 : loss : 0.273218, loss_ce: 0.106589
2022-01-21 20:46:39,511 iteration 75 : loss : 0.289509, loss_ce: 0.137193
2022-01-21 20:46:40,606 iteration 76 : loss : 0.304588, loss_ce: 0.134053
2022-01-21 20:46:41,785 iteration 77 : loss : 0.308440, loss_ce: 0.140091
2022-01-21 20:46:42,958 iteration 78 : loss : 0.285125, loss_ce: 0.120327
2022-01-21 20:46:44,143 iteration 79 : loss : 0.293074, loss_ce: 0.115864
2022-01-21 20:46:45,224 iteration 80 : loss : 0.275691, loss_ce: 0.103649
2022-01-21 20:46:46,456 iteration 81 : loss : 0.298820, loss_ce: 0.131463
2022-01-21 20:46:47,605 iteration 82 : loss : 0.308318, loss_ce: 0.112994
2022-01-21 20:46:48,721 iteration 83 : loss : 0.296019, loss_ce: 0.091699
2022-01-21 20:46:49,973 iteration 84 : loss : 0.330649, loss_ce: 0.147351
2022-01-21 20:46:49,973 Training Data Eval:
2022-01-21 20:46:55,644   Average segmentation loss on training set: 0.3273
2022-01-21 20:46:55,645 Validation Data Eval:
2022-01-21 20:46:57,605   Average segmentation loss on validation set: 0.3441
2022-01-21 20:47:01,688 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 20:47:02,855 iteration 85 : loss : 0.331105, loss_ce: 0.150550
  1%|▍                              | 5/400 [01:52<2:39:35, 24.24s/it]2022-01-21 20:47:04,112 iteration 86 : loss : 0.269044, loss_ce: 0.115505
2022-01-21 20:47:05,259 iteration 87 : loss : 0.270789, loss_ce: 0.098593
2022-01-21 20:47:06,377 iteration 88 : loss : 0.277415, loss_ce: 0.126232
2022-01-21 20:47:07,555 iteration 89 : loss : 0.305127, loss_ce: 0.113100
2022-01-21 20:47:08,711 iteration 90 : loss : 0.265492, loss_ce: 0.106848
2022-01-21 20:47:09,922 iteration 91 : loss : 0.278827, loss_ce: 0.120060
2022-01-21 20:47:11,145 iteration 92 : loss : 0.266960, loss_ce: 0.088408
2022-01-21 20:47:12,259 iteration 93 : loss : 0.250938, loss_ce: 0.081781
2022-01-21 20:47:13,458 iteration 94 : loss : 0.253431, loss_ce: 0.094164
2022-01-21 20:47:14,618 iteration 95 : loss : 0.307461, loss_ce: 0.136296
2022-01-21 20:47:15,855 iteration 96 : loss : 0.277175, loss_ce: 0.102563
2022-01-21 20:47:17,030 iteration 97 : loss : 0.266666, loss_ce: 0.090371
2022-01-21 20:47:18,231 iteration 98 : loss : 0.321315, loss_ce: 0.110222
2022-01-21 20:47:19,391 iteration 99 : loss : 0.285452, loss_ce: 0.103150
2022-01-21 20:47:20,593 iteration 100 : loss : 0.294369, loss_ce: 0.119778
2022-01-21 20:47:21,746 iteration 101 : loss : 0.306112, loss_ce: 0.127319
2022-01-21 20:47:22,887 iteration 102 : loss : 0.297672, loss_ce: 0.137262
  2%|▍                              | 6/400 [02:12<2:29:46, 22.81s/it]2022-01-21 20:47:24,138 iteration 103 : loss : 0.310724, loss_ce: 0.117121
2022-01-21 20:47:25,366 iteration 104 : loss : 0.290211, loss_ce: 0.112157
2022-01-21 20:47:26,585 iteration 105 : loss : 0.269401, loss_ce: 0.100951
2022-01-21 20:47:27,877 iteration 106 : loss : 0.288846, loss_ce: 0.102047
2022-01-21 20:47:29,093 iteration 107 : loss : 0.288329, loss_ce: 0.092323
2022-01-21 20:47:30,263 iteration 108 : loss : 0.303258, loss_ce: 0.098815
2022-01-21 20:47:31,371 iteration 109 : loss : 0.331972, loss_ce: 0.139456
2022-01-21 20:47:32,510 iteration 110 : loss : 0.274083, loss_ce: 0.107852
2022-01-21 20:47:33,746 iteration 111 : loss : 0.272472, loss_ce: 0.110870
2022-01-21 20:47:34,910 iteration 112 : loss : 0.253388, loss_ce: 0.092376
2022-01-21 20:47:36,019 iteration 113 : loss : 0.269861, loss_ce: 0.095137
2022-01-21 20:47:37,232 iteration 114 : loss : 0.263202, loss_ce: 0.086501
2022-01-21 20:47:38,385 iteration 115 : loss : 0.259109, loss_ce: 0.111050
2022-01-21 20:47:39,582 iteration 116 : loss : 0.294035, loss_ce: 0.132236
2022-01-21 20:47:40,724 iteration 117 : loss : 0.256531, loss_ce: 0.097977
2022-01-21 20:47:41,873 iteration 118 : loss : 0.277090, loss_ce: 0.124973
2022-01-21 20:47:43,049 iteration 119 : loss : 0.233659, loss_ce: 0.079684
  2%|▌                              | 7/400 [02:32<2:23:43, 21.94s/it]2022-01-21 20:47:44,336 iteration 120 : loss : 0.247141, loss_ce: 0.094607
2022-01-21 20:47:45,596 iteration 121 : loss : 0.272147, loss_ce: 0.097155
2022-01-21 20:47:46,699 iteration 122 : loss : 0.249085, loss_ce: 0.099885
2022-01-21 20:47:47,915 iteration 123 : loss : 0.254727, loss_ce: 0.099060
2022-01-21 20:47:49,124 iteration 124 : loss : 0.257077, loss_ce: 0.085074
2022-01-21 20:47:50,292 iteration 125 : loss : 0.276165, loss_ce: 0.127526
2022-01-21 20:47:51,500 iteration 126 : loss : 0.293127, loss_ce: 0.096025
2022-01-21 20:47:52,720 iteration 127 : loss : 0.255117, loss_ce: 0.085685
2022-01-21 20:47:53,958 iteration 128 : loss : 0.236385, loss_ce: 0.082826
2022-01-21 20:47:55,104 iteration 129 : loss : 0.248317, loss_ce: 0.075853
2022-01-21 20:47:56,336 iteration 130 : loss : 0.249419, loss_ce: 0.094466
2022-01-21 20:47:57,511 iteration 131 : loss : 0.275123, loss_ce: 0.108874
2022-01-21 20:47:58,642 iteration 132 : loss : 0.253511, loss_ce: 0.079594
2022-01-21 20:47:59,866 iteration 133 : loss : 0.251313, loss_ce: 0.081935
2022-01-21 20:48:01,051 iteration 134 : loss : 0.257669, loss_ce: 0.091808
2022-01-21 20:48:02,247 iteration 135 : loss : 0.259097, loss_ce: 0.098290
2022-01-21 20:48:03,409 iteration 136 : loss : 0.267048, loss_ce: 0.109321
  2%|▌                              | 8/400 [02:53<2:20:03, 21.44s/it]2022-01-21 20:48:04,577 iteration 137 : loss : 0.226380, loss_ce: 0.074494
2022-01-21 20:48:05,707 iteration 138 : loss : 0.239756, loss_ce: 0.101112
2022-01-21 20:48:06,945 iteration 139 : loss : 0.244701, loss_ce: 0.075632
2022-01-21 20:48:08,211 iteration 140 : loss : 0.258360, loss_ce: 0.083817
2022-01-21 20:48:09,400 iteration 141 : loss : 0.245561, loss_ce: 0.078193
2022-01-21 20:48:10,532 iteration 142 : loss : 0.230839, loss_ce: 0.072791
2022-01-21 20:48:11,660 iteration 143 : loss : 0.260487, loss_ce: 0.087175
2022-01-21 20:48:12,876 iteration 144 : loss : 0.259925, loss_ce: 0.084479
2022-01-21 20:48:14,217 iteration 145 : loss : 0.234994, loss_ce: 0.085367
2022-01-21 20:48:15,371 iteration 146 : loss : 0.238643, loss_ce: 0.073555
2022-01-21 20:48:16,536 iteration 147 : loss : 0.250764, loss_ce: 0.084173
2022-01-21 20:48:17,717 iteration 148 : loss : 0.238200, loss_ce: 0.084659
2022-01-21 20:48:18,912 iteration 149 : loss : 0.241372, loss_ce: 0.079658
2022-01-21 20:48:20,084 iteration 150 : loss : 0.270920, loss_ce: 0.107155
2022-01-21 20:48:21,261 iteration 151 : loss : 0.248756, loss_ce: 0.090858
2022-01-21 20:48:22,504 iteration 152 : loss : 0.240851, loss_ce: 0.085235
2022-01-21 20:48:23,742 iteration 153 : loss : 0.238174, loss_ce: 0.093474
  2%|▋                              | 9/400 [03:13<2:17:25, 21.09s/it]2022-01-21 20:48:24,955 iteration 154 : loss : 0.233796, loss_ce: 0.077611
2022-01-21 20:48:26,163 iteration 155 : loss : 0.254559, loss_ce: 0.092360
2022-01-21 20:48:27,357 iteration 156 : loss : 0.231249, loss_ce: 0.082813
2022-01-21 20:48:28,555 iteration 157 : loss : 0.263228, loss_ce: 0.094500
2022-01-21 20:48:29,748 iteration 158 : loss : 0.245809, loss_ce: 0.087164
2022-01-21 20:48:30,933 iteration 159 : loss : 0.254928, loss_ce: 0.085624
2022-01-21 20:48:32,101 iteration 160 : loss : 0.274269, loss_ce: 0.083840
2022-01-21 20:48:33,309 iteration 161 : loss : 0.219889, loss_ce: 0.074158
2022-01-21 20:48:34,572 iteration 162 : loss : 0.238132, loss_ce: 0.085449
2022-01-21 20:48:35,668 iteration 163 : loss : 0.216875, loss_ce: 0.072020
2022-01-21 20:48:36,896 iteration 164 : loss : 0.229107, loss_ce: 0.071343
2022-01-21 20:48:38,060 iteration 165 : loss : 0.204527, loss_ce: 0.067764
2022-01-21 20:48:39,295 iteration 166 : loss : 0.221541, loss_ce: 0.072163
2022-01-21 20:48:40,535 iteration 167 : loss : 0.222607, loss_ce: 0.078129
2022-01-21 20:48:41,750 iteration 168 : loss : 0.216387, loss_ce: 0.077655
2022-01-21 20:48:42,925 iteration 169 : loss : 0.224299, loss_ce: 0.081573
2022-01-21 20:48:42,925 Training Data Eval:
2022-01-21 20:48:48,612   Average segmentation loss on training set: 0.2288
2022-01-21 20:48:48,613 Validation Data Eval:
2022-01-21 20:48:50,571   Average segmentation loss on validation set: 0.2328
2022-01-21 20:48:54,693 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 20:48:55,874 iteration 170 : loss : 0.220243, loss_ce: 0.077743
  2%|▊                             | 10/400 [03:45<2:39:14, 24.50s/it]2022-01-21 20:48:57,102 iteration 171 : loss : 0.242968, loss_ce: 0.095278
2022-01-21 20:48:58,176 iteration 172 : loss : 0.247516, loss_ce: 0.071533
2022-01-21 20:48:59,286 iteration 173 : loss : 0.203394, loss_ce: 0.072089
2022-01-21 20:49:00,522 iteration 174 : loss : 0.251934, loss_ce: 0.079292
2022-01-21 20:49:01,677 iteration 175 : loss : 0.223209, loss_ce: 0.082589
2022-01-21 20:49:02,945 iteration 176 : loss : 0.218199, loss_ce: 0.071090
2022-01-21 20:49:04,110 iteration 177 : loss : 0.251963, loss_ce: 0.081116
2022-01-21 20:49:05,334 iteration 178 : loss : 0.218411, loss_ce: 0.061476
2022-01-21 20:49:06,540 iteration 179 : loss : 0.220146, loss_ce: 0.074748
2022-01-21 20:49:07,755 iteration 180 : loss : 0.209365, loss_ce: 0.061412
2022-01-21 20:49:08,970 iteration 181 : loss : 0.188509, loss_ce: 0.058412
2022-01-21 20:49:10,177 iteration 182 : loss : 0.183625, loss_ce: 0.059958
2022-01-21 20:49:11,401 iteration 183 : loss : 0.176777, loss_ce: 0.053372
2022-01-21 20:49:12,584 iteration 184 : loss : 0.202850, loss_ce: 0.079376
2022-01-21 20:49:13,728 iteration 185 : loss : 0.204794, loss_ce: 0.087910
2022-01-21 20:49:14,866 iteration 186 : loss : 0.187096, loss_ce: 0.077009
2022-01-21 20:49:15,989 iteration 187 : loss : 0.250282, loss_ce: 0.110946
  3%|▊                             | 11/400 [04:05<2:30:07, 23.16s/it]2022-01-21 20:49:17,219 iteration 188 : loss : 0.253049, loss_ce: 0.096119
2022-01-21 20:49:18,444 iteration 189 : loss : 0.217664, loss_ce: 0.081268
2022-01-21 20:49:19,680 iteration 190 : loss : 0.194085, loss_ce: 0.062546
2022-01-21 20:49:20,868 iteration 191 : loss : 0.207263, loss_ce: 0.080391
2022-01-21 20:49:21,972 iteration 192 : loss : 0.181266, loss_ce: 0.068516
2022-01-21 20:49:23,102 iteration 193 : loss : 0.254368, loss_ce: 0.087250
2022-01-21 20:49:24,217 iteration 194 : loss : 0.227139, loss_ce: 0.077316
2022-01-21 20:49:25,471 iteration 195 : loss : 0.198644, loss_ce: 0.068611
2022-01-21 20:49:26,678 iteration 196 : loss : 0.191847, loss_ce: 0.058526
2022-01-21 20:49:27,868 iteration 197 : loss : 0.195063, loss_ce: 0.069021
2022-01-21 20:49:29,085 iteration 198 : loss : 0.249905, loss_ce: 0.098003
2022-01-21 20:49:30,302 iteration 199 : loss : 0.186356, loss_ce: 0.075930
2022-01-21 20:49:31,466 iteration 200 : loss : 0.209097, loss_ce: 0.072642
2022-01-21 20:49:32,636 iteration 201 : loss : 0.209301, loss_ce: 0.081759
2022-01-21 20:49:33,706 iteration 202 : loss : 0.226918, loss_ce: 0.083833
2022-01-21 20:49:34,936 iteration 203 : loss : 0.188864, loss_ce: 0.073660
2022-01-21 20:49:36,100 iteration 204 : loss : 0.176748, loss_ce: 0.081990
  3%|▉                             | 12/400 [04:26<2:23:46, 22.23s/it]2022-01-21 20:49:37,397 iteration 205 : loss : 0.211629, loss_ce: 0.078121
2022-01-21 20:49:38,593 iteration 206 : loss : 0.302020, loss_ce: 0.129268
2022-01-21 20:49:39,853 iteration 207 : loss : 0.223914, loss_ce: 0.083441
2022-01-21 20:49:41,080 iteration 208 : loss : 0.182346, loss_ce: 0.079972
2022-01-21 20:49:42,286 iteration 209 : loss : 0.231805, loss_ce: 0.094479
2022-01-21 20:49:43,457 iteration 210 : loss : 0.197380, loss_ce: 0.084210
2022-01-21 20:49:44,652 iteration 211 : loss : 0.176174, loss_ce: 0.068285
2022-01-21 20:49:45,886 iteration 212 : loss : 0.207922, loss_ce: 0.087481
2022-01-21 20:49:47,116 iteration 213 : loss : 0.200499, loss_ce: 0.080945
2022-01-21 20:49:48,285 iteration 214 : loss : 0.208538, loss_ce: 0.074708
2022-01-21 20:49:49,432 iteration 215 : loss : 0.165759, loss_ce: 0.057265
2022-01-21 20:49:50,663 iteration 216 : loss : 0.183140, loss_ce: 0.065464
2022-01-21 20:49:51,903 iteration 217 : loss : 0.184533, loss_ce: 0.068517
2022-01-21 20:49:53,073 iteration 218 : loss : 0.190809, loss_ce: 0.074696
2022-01-21 20:49:54,230 iteration 219 : loss : 0.178696, loss_ce: 0.074530
2022-01-21 20:49:55,427 iteration 220 : loss : 0.154172, loss_ce: 0.053042
2022-01-21 20:49:56,649 iteration 221 : loss : 0.204989, loss_ce: 0.075188
  3%|▉                             | 13/400 [04:46<2:20:05, 21.72s/it]2022-01-21 20:49:57,886 iteration 222 : loss : 0.149868, loss_ce: 0.056064
2022-01-21 20:49:59,049 iteration 223 : loss : 0.264605, loss_ce: 0.120027
2022-01-21 20:50:00,210 iteration 224 : loss : 0.178113, loss_ce: 0.053493
2022-01-21 20:50:01,503 iteration 225 : loss : 0.156223, loss_ce: 0.067723
2022-01-21 20:50:02,716 iteration 226 : loss : 0.182302, loss_ce: 0.066561
2022-01-21 20:50:03,894 iteration 227 : loss : 0.183721, loss_ce: 0.065510
2022-01-21 20:50:05,066 iteration 228 : loss : 0.142397, loss_ce: 0.048514
2022-01-21 20:50:06,272 iteration 229 : loss : 0.188991, loss_ce: 0.067792
2022-01-21 20:50:07,406 iteration 230 : loss : 0.138446, loss_ce: 0.057804
2022-01-21 20:50:08,591 iteration 231 : loss : 0.162348, loss_ce: 0.061436
2022-01-21 20:50:09,759 iteration 232 : loss : 0.176965, loss_ce: 0.073786
2022-01-21 20:50:10,867 iteration 233 : loss : 0.171099, loss_ce: 0.075789
2022-01-21 20:50:12,030 iteration 234 : loss : 0.173190, loss_ce: 0.066885
2022-01-21 20:50:13,166 iteration 235 : loss : 0.170317, loss_ce: 0.065796
2022-01-21 20:50:14,341 iteration 236 : loss : 0.278012, loss_ce: 0.111974
2022-01-21 20:50:15,468 iteration 237 : loss : 0.243549, loss_ce: 0.124325
2022-01-21 20:50:16,681 iteration 238 : loss : 0.181714, loss_ce: 0.060785
  4%|█                             | 14/400 [05:06<2:16:28, 21.21s/it]2022-01-21 20:50:17,902 iteration 239 : loss : 0.182329, loss_ce: 0.065503
2022-01-21 20:50:19,166 iteration 240 : loss : 0.166902, loss_ce: 0.052185
2022-01-21 20:50:20,392 iteration 241 : loss : 0.215493, loss_ce: 0.078990
2022-01-21 20:50:21,564 iteration 242 : loss : 0.148811, loss_ce: 0.050216
2022-01-21 20:50:22,723 iteration 243 : loss : 0.165976, loss_ce: 0.057475
2022-01-21 20:50:23,890 iteration 244 : loss : 0.203068, loss_ce: 0.081965
2022-01-21 20:50:25,018 iteration 245 : loss : 0.165988, loss_ce: 0.047945
2022-01-21 20:50:26,173 iteration 246 : loss : 0.200772, loss_ce: 0.061769
2022-01-21 20:50:27,374 iteration 247 : loss : 0.229749, loss_ce: 0.086247
2022-01-21 20:50:28,590 iteration 248 : loss : 0.156459, loss_ce: 0.066597
2022-01-21 20:50:29,759 iteration 249 : loss : 0.185746, loss_ce: 0.067101
2022-01-21 20:50:30,925 iteration 250 : loss : 0.211894, loss_ce: 0.071280
2022-01-21 20:50:32,048 iteration 251 : loss : 0.169507, loss_ce: 0.072421
2022-01-21 20:50:33,300 iteration 252 : loss : 0.151762, loss_ce: 0.067278
2022-01-21 20:50:34,484 iteration 253 : loss : 0.154930, loss_ce: 0.054093
2022-01-21 20:50:35,644 iteration 254 : loss : 0.150558, loss_ce: 0.062822
2022-01-21 20:50:35,644 Training Data Eval:
2022-01-21 20:50:41,355   Average segmentation loss on training set: 0.1440
2022-01-21 20:50:41,356 Validation Data Eval:
2022-01-21 20:50:43,326   Average segmentation loss on validation set: 0.1838
2022-01-21 20:50:46,816 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 20:50:47,996 iteration 255 : loss : 0.216566, loss_ce: 0.097258
  4%|█▏                            | 15/400 [05:37<2:35:38, 24.26s/it]2022-01-21 20:50:49,155 iteration 256 : loss : 0.172710, loss_ce: 0.063818
2022-01-21 20:50:50,282 iteration 257 : loss : 0.172304, loss_ce: 0.066813
2022-01-21 20:50:51,502 iteration 258 : loss : 0.169583, loss_ce: 0.073281
2022-01-21 20:50:52,684 iteration 259 : loss : 0.181908, loss_ce: 0.077513
2022-01-21 20:50:53,816 iteration 260 : loss : 0.131735, loss_ce: 0.069695
2022-01-21 20:50:55,019 iteration 261 : loss : 0.186751, loss_ce: 0.076120
2022-01-21 20:50:56,246 iteration 262 : loss : 0.227284, loss_ce: 0.103306
2022-01-21 20:50:57,382 iteration 263 : loss : 0.180224, loss_ce: 0.074227
2022-01-21 20:50:58,603 iteration 264 : loss : 0.260516, loss_ce: 0.096066
2022-01-21 20:50:59,883 iteration 265 : loss : 0.189740, loss_ce: 0.092250
2022-01-21 20:51:01,088 iteration 266 : loss : 0.193000, loss_ce: 0.068861
2022-01-21 20:51:02,365 iteration 267 : loss : 0.153313, loss_ce: 0.049635
2022-01-21 20:51:03,567 iteration 268 : loss : 0.183846, loss_ce: 0.069666
2022-01-21 20:51:04,762 iteration 269 : loss : 0.239574, loss_ce: 0.105193
2022-01-21 20:51:05,932 iteration 270 : loss : 0.217500, loss_ce: 0.077943
2022-01-21 20:51:07,088 iteration 271 : loss : 0.184014, loss_ce: 0.075264
2022-01-21 20:51:08,224 iteration 272 : loss : 0.146638, loss_ce: 0.056948
  4%|█▏                            | 16/400 [05:58<2:27:29, 23.05s/it]2022-01-21 20:51:09,503 iteration 273 : loss : 0.195551, loss_ce: 0.072721
2022-01-21 20:51:10,688 iteration 274 : loss : 0.252666, loss_ce: 0.119535
2022-01-21 20:51:11,857 iteration 275 : loss : 0.215641, loss_ce: 0.056857
2022-01-21 20:51:13,011 iteration 276 : loss : 0.170884, loss_ce: 0.062591
2022-01-21 20:51:14,162 iteration 277 : loss : 0.142720, loss_ce: 0.056154
2022-01-21 20:51:15,341 iteration 278 : loss : 0.234884, loss_ce: 0.097531
2022-01-21 20:51:16,508 iteration 279 : loss : 0.193115, loss_ce: 0.074050
2022-01-21 20:51:17,680 iteration 280 : loss : 0.178044, loss_ce: 0.072662
2022-01-21 20:51:18,904 iteration 281 : loss : 0.160813, loss_ce: 0.078299
2022-01-21 20:51:20,104 iteration 282 : loss : 0.144185, loss_ce: 0.052974
2022-01-21 20:51:21,260 iteration 283 : loss : 0.189069, loss_ce: 0.073421
2022-01-21 20:51:22,459 iteration 284 : loss : 0.139630, loss_ce: 0.072728
2022-01-21 20:51:23,683 iteration 285 : loss : 0.179859, loss_ce: 0.062083
2022-01-21 20:51:24,778 iteration 286 : loss : 0.158059, loss_ce: 0.063983
2022-01-21 20:51:25,957 iteration 287 : loss : 0.168685, loss_ce: 0.069902
2022-01-21 20:51:27,151 iteration 288 : loss : 0.148317, loss_ce: 0.056733
2022-01-21 20:51:28,311 iteration 289 : loss : 0.194495, loss_ce: 0.065940
  4%|█▎                            | 17/400 [06:18<2:21:25, 22.15s/it]2022-01-21 20:51:29,569 iteration 290 : loss : 0.194491, loss_ce: 0.080550
2022-01-21 20:51:30,710 iteration 291 : loss : 0.186930, loss_ce: 0.069224
2022-01-21 20:51:31,841 iteration 292 : loss : 0.171669, loss_ce: 0.071416
2022-01-21 20:51:33,070 iteration 293 : loss : 0.161194, loss_ce: 0.056434
2022-01-21 20:51:34,233 iteration 294 : loss : 0.148326, loss_ce: 0.062227
2022-01-21 20:51:35,460 iteration 295 : loss : 0.153304, loss_ce: 0.069636
2022-01-21 20:51:36,696 iteration 296 : loss : 0.186613, loss_ce: 0.081493
2022-01-21 20:51:37,901 iteration 297 : loss : 0.139752, loss_ce: 0.063966
2022-01-21 20:51:39,072 iteration 298 : loss : 0.175853, loss_ce: 0.081957
2022-01-21 20:51:40,188 iteration 299 : loss : 0.188826, loss_ce: 0.064314
2022-01-21 20:51:41,340 iteration 300 : loss : 0.164280, loss_ce: 0.068016
2022-01-21 20:51:42,437 iteration 301 : loss : 0.192620, loss_ce: 0.061549
2022-01-21 20:51:43,672 iteration 302 : loss : 0.178489, loss_ce: 0.055524
2022-01-21 20:51:44,896 iteration 303 : loss : 0.128269, loss_ce: 0.041739
2022-01-21 20:51:46,119 iteration 304 : loss : 0.213523, loss_ce: 0.093480
2022-01-21 20:51:47,275 iteration 305 : loss : 0.155602, loss_ce: 0.061971
2022-01-21 20:51:48,444 iteration 306 : loss : 0.187088, loss_ce: 0.071994
  4%|█▎                            | 18/400 [06:38<2:17:11, 21.55s/it]2022-01-21 20:51:49,598 iteration 307 : loss : 0.222512, loss_ce: 0.085754
2022-01-21 20:51:50,704 iteration 308 : loss : 0.159231, loss_ce: 0.059264
2022-01-21 20:51:51,830 iteration 309 : loss : 0.177763, loss_ce: 0.084767
2022-01-21 20:51:53,013 iteration 310 : loss : 0.182119, loss_ce: 0.077317
2022-01-21 20:51:54,222 iteration 311 : loss : 0.153923, loss_ce: 0.058515
2022-01-21 20:51:55,449 iteration 312 : loss : 0.140390, loss_ce: 0.053877
2022-01-21 20:51:56,597 iteration 313 : loss : 0.175905, loss_ce: 0.066917
2022-01-21 20:51:57,789 iteration 314 : loss : 0.155014, loss_ce: 0.070000
2022-01-21 20:51:59,021 iteration 315 : loss : 0.162890, loss_ce: 0.064871
2022-01-21 20:52:00,209 iteration 316 : loss : 0.219078, loss_ce: 0.088005
2022-01-21 20:52:01,342 iteration 317 : loss : 0.185932, loss_ce: 0.064091
2022-01-21 20:52:02,497 iteration 318 : loss : 0.179876, loss_ce: 0.072634
2022-01-21 20:52:03,728 iteration 319 : loss : 0.144319, loss_ce: 0.057000
2022-01-21 20:52:04,878 iteration 320 : loss : 0.195037, loss_ce: 0.067596
2022-01-21 20:52:06,006 iteration 321 : loss : 0.156772, loss_ce: 0.069462
2022-01-21 20:52:07,188 iteration 322 : loss : 0.150989, loss_ce: 0.053702
2022-01-21 20:52:08,414 iteration 323 : loss : 0.163538, loss_ce: 0.063371
  5%|█▍                            | 19/400 [06:58<2:13:49, 21.08s/it]2022-01-21 20:52:09,567 iteration 324 : loss : 0.176913, loss_ce: 0.061300
2022-01-21 20:52:10,737 iteration 325 : loss : 0.164060, loss_ce: 0.058391
2022-01-21 20:52:11,899 iteration 326 : loss : 0.163072, loss_ce: 0.060576
2022-01-21 20:52:13,158 iteration 327 : loss : 0.176435, loss_ce: 0.063300
2022-01-21 20:52:14,378 iteration 328 : loss : 0.168367, loss_ce: 0.065113
2022-01-21 20:52:15,566 iteration 329 : loss : 0.160268, loss_ce: 0.061169
2022-01-21 20:52:16,663 iteration 330 : loss : 0.142852, loss_ce: 0.060571
2022-01-21 20:52:17,887 iteration 331 : loss : 0.116927, loss_ce: 0.043101
2022-01-21 20:52:19,116 iteration 332 : loss : 0.155381, loss_ce: 0.067325
2022-01-21 20:52:20,247 iteration 333 : loss : 0.147814, loss_ce: 0.059081
2022-01-21 20:52:21,470 iteration 334 : loss : 0.168494, loss_ce: 0.081785
2022-01-21 20:52:22,620 iteration 335 : loss : 0.146550, loss_ce: 0.048604
2022-01-21 20:52:23,840 iteration 336 : loss : 0.131241, loss_ce: 0.048601
2022-01-21 20:52:24,986 iteration 337 : loss : 0.154900, loss_ce: 0.056038
2022-01-21 20:52:26,096 iteration 338 : loss : 0.161653, loss_ce: 0.069386
2022-01-21 20:52:27,273 iteration 339 : loss : 0.148712, loss_ce: 0.051833
2022-01-21 20:52:27,273 Training Data Eval:
2022-01-21 20:52:32,933   Average segmentation loss on training set: 0.2039
2022-01-21 20:52:32,934 Validation Data Eval:
2022-01-21 20:52:34,901   Average segmentation loss on validation set: 0.2659
2022-01-21 20:52:36,055 iteration 340 : loss : 0.180014, loss_ce: 0.070762
  5%|█▌                            | 20/400 [07:25<2:25:56, 23.04s/it]2022-01-21 20:52:37,320 iteration 341 : loss : 0.174883, loss_ce: 0.073737
2022-01-21 20:52:38,564 iteration 342 : loss : 0.151945, loss_ce: 0.061831
2022-01-21 20:52:39,859 iteration 343 : loss : 0.177867, loss_ce: 0.088296
2022-01-21 20:52:41,033 iteration 344 : loss : 0.191345, loss_ce: 0.063861
2022-01-21 20:52:42,229 iteration 345 : loss : 0.180073, loss_ce: 0.071782
2022-01-21 20:52:43,487 iteration 346 : loss : 0.183128, loss_ce: 0.073234
2022-01-21 20:52:44,641 iteration 347 : loss : 0.167352, loss_ce: 0.070385
2022-01-21 20:52:45,922 iteration 348 : loss : 0.159019, loss_ce: 0.065246
2022-01-21 20:52:47,103 iteration 349 : loss : 0.165651, loss_ce: 0.075676
2022-01-21 20:52:48,205 iteration 350 : loss : 0.152266, loss_ce: 0.061226
2022-01-21 20:52:49,452 iteration 351 : loss : 0.173525, loss_ce: 0.054670
2022-01-21 20:52:50,634 iteration 352 : loss : 0.165867, loss_ce: 0.059470
2022-01-21 20:52:51,911 iteration 353 : loss : 0.168515, loss_ce: 0.044337
2022-01-21 20:52:53,123 iteration 354 : loss : 0.156947, loss_ce: 0.065254
2022-01-21 20:52:54,379 iteration 355 : loss : 0.158244, loss_ce: 0.062508
2022-01-21 20:52:55,523 iteration 356 : loss : 0.179706, loss_ce: 0.072453
2022-01-21 20:52:56,685 iteration 357 : loss : 0.175334, loss_ce: 0.073477
  5%|█▌                            | 21/400 [07:46<2:20:59, 22.32s/it]2022-01-21 20:52:57,980 iteration 358 : loss : 0.186367, loss_ce: 0.068089
2022-01-21 20:52:59,229 iteration 359 : loss : 0.135856, loss_ce: 0.060554
2022-01-21 20:53:00,418 iteration 360 : loss : 0.187225, loss_ce: 0.048745
2022-01-21 20:53:01,641 iteration 361 : loss : 0.191922, loss_ce: 0.063997
2022-01-21 20:53:02,749 iteration 362 : loss : 0.147127, loss_ce: 0.053310
2022-01-21 20:53:04,001 iteration 363 : loss : 0.184720, loss_ce: 0.090156
2022-01-21 20:53:05,201 iteration 364 : loss : 0.193270, loss_ce: 0.090937
2022-01-21 20:53:06,374 iteration 365 : loss : 0.163996, loss_ce: 0.055992
2022-01-21 20:53:07,554 iteration 366 : loss : 0.145655, loss_ce: 0.051316
2022-01-21 20:53:08,776 iteration 367 : loss : 0.171978, loss_ce: 0.072536
2022-01-21 20:53:09,910 iteration 368 : loss : 0.206495, loss_ce: 0.067675
2022-01-21 20:53:11,127 iteration 369 : loss : 0.169229, loss_ce: 0.073036
2022-01-21 20:53:12,242 iteration 370 : loss : 0.181687, loss_ce: 0.052182
2022-01-21 20:53:13,480 iteration 371 : loss : 0.155244, loss_ce: 0.067653
2022-01-21 20:53:14,721 iteration 372 : loss : 0.149685, loss_ce: 0.049655
2022-01-21 20:53:15,931 iteration 373 : loss : 0.131888, loss_ce: 0.047302
2022-01-21 20:53:17,089 iteration 374 : loss : 0.127134, loss_ce: 0.052626
  6%|█▋                            | 22/400 [08:07<2:16:59, 21.74s/it]2022-01-21 20:53:18,388 iteration 375 : loss : 0.158780, loss_ce: 0.062312
2022-01-21 20:53:19,611 iteration 376 : loss : 0.150877, loss_ce: 0.057951
2022-01-21 20:53:20,830 iteration 377 : loss : 0.177313, loss_ce: 0.058477
2022-01-21 20:53:22,039 iteration 378 : loss : 0.187066, loss_ce: 0.079769
2022-01-21 20:53:23,173 iteration 379 : loss : 0.180169, loss_ce: 0.064179
2022-01-21 20:53:24,391 iteration 380 : loss : 0.152071, loss_ce: 0.069770
2022-01-21 20:53:25,489 iteration 381 : loss : 0.122245, loss_ce: 0.047016
2022-01-21 20:53:26,773 iteration 382 : loss : 0.152090, loss_ce: 0.071564
2022-01-21 20:53:27,998 iteration 383 : loss : 0.156455, loss_ce: 0.059810
2022-01-21 20:53:29,183 iteration 384 : loss : 0.130089, loss_ce: 0.058832
2022-01-21 20:53:30,330 iteration 385 : loss : 0.141698, loss_ce: 0.055427
2022-01-21 20:53:31,550 iteration 386 : loss : 0.176260, loss_ce: 0.066848
2022-01-21 20:53:32,763 iteration 387 : loss : 0.163898, loss_ce: 0.065756
2022-01-21 20:53:34,009 iteration 388 : loss : 0.156693, loss_ce: 0.064851
2022-01-21 20:53:35,171 iteration 389 : loss : 0.177859, loss_ce: 0.058033
2022-01-21 20:53:36,388 iteration 390 : loss : 0.146632, loss_ce: 0.074227
2022-01-21 20:53:37,552 iteration 391 : loss : 0.140325, loss_ce: 0.049924
  6%|█▋                            | 23/400 [08:27<2:14:12, 21.36s/it]2022-01-21 20:53:38,895 iteration 392 : loss : 0.138770, loss_ce: 0.061356
2022-01-21 20:53:40,053 iteration 393 : loss : 0.166906, loss_ce: 0.070818
2022-01-21 20:53:41,260 iteration 394 : loss : 0.192070, loss_ce: 0.071906
2022-01-21 20:53:42,428 iteration 395 : loss : 0.159909, loss_ce: 0.075434
2022-01-21 20:53:43,666 iteration 396 : loss : 0.124857, loss_ce: 0.051776
2022-01-21 20:53:44,891 iteration 397 : loss : 0.130161, loss_ce: 0.055829
2022-01-21 20:53:46,102 iteration 398 : loss : 0.163302, loss_ce: 0.077422
2022-01-21 20:53:47,283 iteration 399 : loss : 0.119817, loss_ce: 0.046884
2022-01-21 20:53:48,530 iteration 400 : loss : 0.124566, loss_ce: 0.051741
2022-01-21 20:53:49,653 iteration 401 : loss : 0.154557, loss_ce: 0.046469
2022-01-21 20:53:50,892 iteration 402 : loss : 0.183491, loss_ce: 0.068868
2022-01-21 20:53:52,164 iteration 403 : loss : 0.145106, loss_ce: 0.053813
2022-01-21 20:53:53,356 iteration 404 : loss : 0.172243, loss_ce: 0.053008
2022-01-21 20:53:54,589 iteration 405 : loss : 0.138743, loss_ce: 0.044198
2022-01-21 20:53:55,753 iteration 406 : loss : 0.141179, loss_ce: 0.061655
2022-01-21 20:53:56,908 iteration 407 : loss : 0.137963, loss_ce: 0.052074
2022-01-21 20:53:58,059 iteration 408 : loss : 0.137887, loss_ce: 0.046556
  6%|█▊                            | 24/400 [08:47<2:12:14, 21.10s/it]2022-01-21 20:53:59,408 iteration 409 : loss : 0.125749, loss_ce: 0.047930
2022-01-21 20:54:00,590 iteration 410 : loss : 0.158896, loss_ce: 0.057246
2022-01-21 20:54:01,806 iteration 411 : loss : 0.126634, loss_ce: 0.046128
2022-01-21 20:54:02,984 iteration 412 : loss : 0.144020, loss_ce: 0.054027
2022-01-21 20:54:04,157 iteration 413 : loss : 0.115012, loss_ce: 0.044731
2022-01-21 20:54:05,365 iteration 414 : loss : 0.131837, loss_ce: 0.062773
2022-01-21 20:54:06,599 iteration 415 : loss : 0.184169, loss_ce: 0.100123
2022-01-21 20:54:07,676 iteration 416 : loss : 0.165835, loss_ce: 0.056790
2022-01-21 20:54:08,851 iteration 417 : loss : 0.157280, loss_ce: 0.056620
2022-01-21 20:54:10,043 iteration 418 : loss : 0.150007, loss_ce: 0.049282
2022-01-21 20:54:11,205 iteration 419 : loss : 0.209063, loss_ce: 0.084113
2022-01-21 20:54:12,399 iteration 420 : loss : 0.132567, loss_ce: 0.054809
2022-01-21 20:54:13,497 iteration 421 : loss : 0.146175, loss_ce: 0.037610
2022-01-21 20:54:14,720 iteration 422 : loss : 0.142787, loss_ce: 0.049962
2022-01-21 20:54:15,885 iteration 423 : loss : 0.116251, loss_ce: 0.043926
2022-01-21 20:54:17,039 iteration 424 : loss : 0.150133, loss_ce: 0.066465
2022-01-21 20:54:17,039 Training Data Eval:
2022-01-21 20:54:22,716   Average segmentation loss on training set: 0.2386
2022-01-21 20:54:22,716 Validation Data Eval:
2022-01-21 20:54:24,669   Average segmentation loss on validation set: 0.3436
2022-01-21 20:54:25,900 iteration 425 : loss : 0.186055, loss_ce: 0.082876
  6%|█▉                            | 25/400 [09:15<2:24:31, 23.13s/it]2022-01-21 20:54:27,168 iteration 426 : loss : 0.128515, loss_ce: 0.056986
2022-01-21 20:54:28,316 iteration 427 : loss : 0.123392, loss_ce: 0.054295
2022-01-21 20:54:29,599 iteration 428 : loss : 0.148631, loss_ce: 0.062119
2022-01-21 20:54:30,765 iteration 429 : loss : 0.115229, loss_ce: 0.041609
2022-01-21 20:54:31,873 iteration 430 : loss : 0.162862, loss_ce: 0.071816
2022-01-21 20:54:33,093 iteration 431 : loss : 0.125341, loss_ce: 0.057632
2022-01-21 20:54:34,296 iteration 432 : loss : 0.121059, loss_ce: 0.040669
2022-01-21 20:54:35,414 iteration 433 : loss : 0.149159, loss_ce: 0.058636
2022-01-21 20:54:36,544 iteration 434 : loss : 0.131249, loss_ce: 0.043844
2022-01-21 20:54:37,736 iteration 435 : loss : 0.116465, loss_ce: 0.045429
2022-01-21 20:54:38,946 iteration 436 : loss : 0.167658, loss_ce: 0.045415
2022-01-21 20:54:40,093 iteration 437 : loss : 0.145469, loss_ce: 0.055263
2022-01-21 20:54:41,235 iteration 438 : loss : 0.142841, loss_ce: 0.055458
2022-01-21 20:54:42,395 iteration 439 : loss : 0.125020, loss_ce: 0.047222
2022-01-21 20:54:43,702 iteration 440 : loss : 0.145650, loss_ce: 0.063169
2022-01-21 20:54:44,878 iteration 441 : loss : 0.151916, loss_ce: 0.071203
2022-01-21 20:54:46,031 iteration 442 : loss : 0.096391, loss_ce: 0.035758
  6%|█▉                            | 26/400 [09:35<2:18:33, 22.23s/it]2022-01-21 20:54:47,291 iteration 443 : loss : 0.121190, loss_ce: 0.048229
2022-01-21 20:54:48,434 iteration 444 : loss : 0.139305, loss_ce: 0.048805
2022-01-21 20:54:49,560 iteration 445 : loss : 0.146546, loss_ce: 0.055190
2022-01-21 20:54:50,722 iteration 446 : loss : 0.125431, loss_ce: 0.041847
2022-01-21 20:54:51,954 iteration 447 : loss : 0.105657, loss_ce: 0.039859
2022-01-21 20:54:53,055 iteration 448 : loss : 0.174753, loss_ce: 0.058339
2022-01-21 20:54:54,203 iteration 449 : loss : 0.124679, loss_ce: 0.036754
2022-01-21 20:54:55,305 iteration 450 : loss : 0.161046, loss_ce: 0.078023
2022-01-21 20:54:56,475 iteration 451 : loss : 0.183460, loss_ce: 0.083983
2022-01-21 20:54:57,656 iteration 452 : loss : 0.131335, loss_ce: 0.045817
2022-01-21 20:54:58,805 iteration 453 : loss : 0.092959, loss_ce: 0.037985
2022-01-21 20:55:00,073 iteration 454 : loss : 0.155815, loss_ce: 0.070458
2022-01-21 20:55:01,296 iteration 455 : loss : 0.142759, loss_ce: 0.064867
2022-01-21 20:55:02,472 iteration 456 : loss : 0.104331, loss_ce: 0.036912
2022-01-21 20:55:03,632 iteration 457 : loss : 0.112988, loss_ce: 0.055062
2022-01-21 20:55:04,789 iteration 458 : loss : 0.117808, loss_ce: 0.058416
2022-01-21 20:55:05,983 iteration 459 : loss : 0.138425, loss_ce: 0.062254
  7%|██                            | 27/400 [09:55<2:13:55, 21.54s/it]2022-01-21 20:55:07,143 iteration 460 : loss : 0.133047, loss_ce: 0.062448
2022-01-21 20:55:08,293 iteration 461 : loss : 0.101788, loss_ce: 0.046909
2022-01-21 20:55:09,541 iteration 462 : loss : 0.179994, loss_ce: 0.075093
2022-01-21 20:55:10,729 iteration 463 : loss : 0.164660, loss_ce: 0.056956
2022-01-21 20:55:12,042 iteration 464 : loss : 0.200930, loss_ce: 0.066516
2022-01-21 20:55:13,270 iteration 465 : loss : 0.122675, loss_ce: 0.047156
2022-01-21 20:55:14,430 iteration 466 : loss : 0.108372, loss_ce: 0.046453
2022-01-21 20:55:15,602 iteration 467 : loss : 0.152190, loss_ce: 0.074628
2022-01-21 20:55:16,762 iteration 468 : loss : 0.105679, loss_ce: 0.044904
2022-01-21 20:55:17,981 iteration 469 : loss : 0.116687, loss_ce: 0.050550
2022-01-21 20:55:19,171 iteration 470 : loss : 0.104456, loss_ce: 0.043607
2022-01-21 20:55:20,352 iteration 471 : loss : 0.218240, loss_ce: 0.115719
2022-01-21 20:55:21,565 iteration 472 : loss : 0.110743, loss_ce: 0.051377
2022-01-21 20:55:22,759 iteration 473 : loss : 0.135807, loss_ce: 0.056847
2022-01-21 20:55:23,908 iteration 474 : loss : 0.190188, loss_ce: 0.063637
2022-01-21 20:55:25,084 iteration 475 : loss : 0.173623, loss_ce: 0.057923
2022-01-21 20:55:26,332 iteration 476 : loss : 0.118075, loss_ce: 0.040151
  7%|██                            | 28/400 [10:16<2:11:20, 21.19s/it]2022-01-21 20:55:27,562 iteration 477 : loss : 0.095197, loss_ce: 0.039674
2022-01-21 20:55:28,683 iteration 478 : loss : 0.122895, loss_ce: 0.054111
2022-01-21 20:55:29,897 iteration 479 : loss : 0.147182, loss_ce: 0.047931
2022-01-21 20:55:31,077 iteration 480 : loss : 0.135949, loss_ce: 0.044622
2022-01-21 20:55:32,213 iteration 481 : loss : 0.133793, loss_ce: 0.038637
2022-01-21 20:55:33,467 iteration 482 : loss : 0.142551, loss_ce: 0.055778
2022-01-21 20:55:34,593 iteration 483 : loss : 0.171204, loss_ce: 0.082138
2022-01-21 20:55:35,785 iteration 484 : loss : 0.148277, loss_ce: 0.054856
2022-01-21 20:55:36,980 iteration 485 : loss : 0.147168, loss_ce: 0.075472
2022-01-21 20:55:38,262 iteration 486 : loss : 0.134152, loss_ce: 0.048968
2022-01-21 20:55:39,445 iteration 487 : loss : 0.191867, loss_ce: 0.062941
2022-01-21 20:55:40,556 iteration 488 : loss : 0.137720, loss_ce: 0.062227
2022-01-21 20:55:41,760 iteration 489 : loss : 0.150492, loss_ce: 0.073094
2022-01-21 20:55:42,933 iteration 490 : loss : 0.126072, loss_ce: 0.055371
2022-01-21 20:55:44,170 iteration 491 : loss : 0.199617, loss_ce: 0.075494
2022-01-21 20:55:45,322 iteration 492 : loss : 0.145449, loss_ce: 0.081850
2022-01-21 20:55:46,466 iteration 493 : loss : 0.123862, loss_ce: 0.060985
  7%|██▏                           | 29/400 [10:36<2:09:03, 20.87s/it]2022-01-21 20:55:47,685 iteration 494 : loss : 0.166196, loss_ce: 0.063296
2022-01-21 20:55:48,808 iteration 495 : loss : 0.143300, loss_ce: 0.054116
2022-01-21 20:55:49,996 iteration 496 : loss : 0.148697, loss_ce: 0.052348
2022-01-21 20:55:51,259 iteration 497 : loss : 0.158048, loss_ce: 0.064149
2022-01-21 20:55:52,539 iteration 498 : loss : 0.110561, loss_ce: 0.049686
2022-01-21 20:55:53,760 iteration 499 : loss : 0.109474, loss_ce: 0.038424
2022-01-21 20:55:55,063 iteration 500 : loss : 0.159246, loss_ce: 0.060661
2022-01-21 20:55:56,252 iteration 501 : loss : 0.146182, loss_ce: 0.048321
2022-01-21 20:55:57,384 iteration 502 : loss : 0.126796, loss_ce: 0.052591
2022-01-21 20:55:58,668 iteration 503 : loss : 0.129251, loss_ce: 0.035642
2022-01-21 20:55:59,968 iteration 504 : loss : 0.122724, loss_ce: 0.046519
2022-01-21 20:56:01,130 iteration 505 : loss : 0.129416, loss_ce: 0.051592
2022-01-21 20:56:02,351 iteration 506 : loss : 0.147583, loss_ce: 0.052735
2022-01-21 20:56:03,595 iteration 507 : loss : 0.125381, loss_ce: 0.048630
2022-01-21 20:56:04,779 iteration 508 : loss : 0.136112, loss_ce: 0.056158
2022-01-21 20:56:05,985 iteration 509 : loss : 0.133536, loss_ce: 0.060759
2022-01-21 20:56:05,986 Training Data Eval:
2022-01-21 20:56:11,684   Average segmentation loss on training set: 0.2677
2022-01-21 20:56:11,684 Validation Data Eval:
2022-01-21 20:56:13,654   Average segmentation loss on validation set: 0.2314
2022-01-21 20:56:14,738 iteration 510 : loss : 0.125785, loss_ce: 0.046550
  8%|██▎                           | 30/400 [11:04<2:22:22, 23.09s/it]2022-01-21 20:56:15,837 iteration 511 : loss : 0.107112, loss_ce: 0.041535
2022-01-21 20:56:17,159 iteration 512 : loss : 0.151629, loss_ce: 0.060652
2022-01-21 20:56:18,287 iteration 513 : loss : 0.139758, loss_ce: 0.064244
2022-01-21 20:56:19,495 iteration 514 : loss : 0.140837, loss_ce: 0.054318
2022-01-21 20:56:20,646 iteration 515 : loss : 0.123851, loss_ce: 0.050843
2022-01-21 20:56:21,742 iteration 516 : loss : 0.086556, loss_ce: 0.042757
2022-01-21 20:56:23,061 iteration 517 : loss : 0.126248, loss_ce: 0.047915
2022-01-21 20:56:24,272 iteration 518 : loss : 0.151502, loss_ce: 0.076433
2022-01-21 20:56:25,421 iteration 519 : loss : 0.106398, loss_ce: 0.045358
2022-01-21 20:56:26,566 iteration 520 : loss : 0.124967, loss_ce: 0.057853
2022-01-21 20:56:27,838 iteration 521 : loss : 0.223486, loss_ce: 0.062331
2022-01-21 20:56:28,989 iteration 522 : loss : 0.102052, loss_ce: 0.039398
2022-01-21 20:56:30,199 iteration 523 : loss : 0.097788, loss_ce: 0.043249
2022-01-21 20:56:31,269 iteration 524 : loss : 0.131887, loss_ce: 0.061948
2022-01-21 20:56:32,432 iteration 525 : loss : 0.096750, loss_ce: 0.040219
2022-01-21 20:56:33,635 iteration 526 : loss : 0.119734, loss_ce: 0.048224
2022-01-21 20:56:34,808 iteration 527 : loss : 0.162278, loss_ce: 0.071929
  8%|██▎                           | 31/400 [11:24<2:16:26, 22.19s/it]2022-01-21 20:56:36,071 iteration 528 : loss : 0.074495, loss_ce: 0.028979
2022-01-21 20:56:37,252 iteration 529 : loss : 0.106275, loss_ce: 0.053344
2022-01-21 20:56:38,408 iteration 530 : loss : 0.109246, loss_ce: 0.044622
2022-01-21 20:56:39,636 iteration 531 : loss : 0.196661, loss_ce: 0.075319
2022-01-21 20:56:40,753 iteration 532 : loss : 0.181081, loss_ce: 0.049403
2022-01-21 20:56:41,952 iteration 533 : loss : 0.128522, loss_ce: 0.058724
2022-01-21 20:56:43,140 iteration 534 : loss : 0.143667, loss_ce: 0.076164
2022-01-21 20:56:44,330 iteration 535 : loss : 0.122906, loss_ce: 0.052247
2022-01-21 20:56:45,439 iteration 536 : loss : 0.138562, loss_ce: 0.065201
2022-01-21 20:56:46,613 iteration 537 : loss : 0.169261, loss_ce: 0.066959
2022-01-21 20:56:47,781 iteration 538 : loss : 0.098866, loss_ce: 0.037933
2022-01-21 20:56:48,926 iteration 539 : loss : 0.131503, loss_ce: 0.051597
2022-01-21 20:56:50,053 iteration 540 : loss : 0.111652, loss_ce: 0.052077
2022-01-21 20:56:51,223 iteration 541 : loss : 0.148009, loss_ce: 0.067958
2022-01-21 20:56:52,337 iteration 542 : loss : 0.142043, loss_ce: 0.049333
2022-01-21 20:56:53,472 iteration 543 : loss : 0.150068, loss_ce: 0.042701
2022-01-21 20:56:54,636 iteration 544 : loss : 0.117009, loss_ce: 0.041377
  8%|██▍                           | 32/400 [11:44<2:11:44, 21.48s/it]2022-01-21 20:56:55,836 iteration 545 : loss : 0.147351, loss_ce: 0.059157
2022-01-21 20:56:57,022 iteration 546 : loss : 0.116038, loss_ce: 0.044379
2022-01-21 20:56:58,195 iteration 547 : loss : 0.137010, loss_ce: 0.060751
2022-01-21 20:56:59,305 iteration 548 : loss : 0.137595, loss_ce: 0.049086
2022-01-21 20:57:00,493 iteration 549 : loss : 0.102184, loss_ce: 0.046279
2022-01-21 20:57:01,770 iteration 550 : loss : 0.131056, loss_ce: 0.065114
2022-01-21 20:57:02,982 iteration 551 : loss : 0.121478, loss_ce: 0.042661
2022-01-21 20:57:04,214 iteration 552 : loss : 0.136830, loss_ce: 0.071822
2022-01-21 20:57:05,453 iteration 553 : loss : 0.132152, loss_ce: 0.060982
2022-01-21 20:57:06,584 iteration 554 : loss : 0.093197, loss_ce: 0.038814
2022-01-21 20:57:07,788 iteration 555 : loss : 0.099781, loss_ce: 0.049849
2022-01-21 20:57:09,047 iteration 556 : loss : 0.119628, loss_ce: 0.048957
2022-01-21 20:57:10,217 iteration 557 : loss : 0.141308, loss_ce: 0.070662
2022-01-21 20:57:11,357 iteration 558 : loss : 0.148644, loss_ce: 0.051332
2022-01-21 20:57:12,567 iteration 559 : loss : 0.122947, loss_ce: 0.054306
2022-01-21 20:57:13,780 iteration 560 : loss : 0.129473, loss_ce: 0.048436
2022-01-21 20:57:14,915 iteration 561 : loss : 0.143277, loss_ce: 0.042895
  8%|██▍                           | 33/400 [12:04<2:09:10, 21.12s/it]2022-01-21 20:57:16,120 iteration 562 : loss : 0.109833, loss_ce: 0.039850
2022-01-21 20:57:17,321 iteration 563 : loss : 0.130387, loss_ce: 0.058246
2022-01-21 20:57:18,556 iteration 564 : loss : 0.096241, loss_ce: 0.043411
2022-01-21 20:57:19,764 iteration 565 : loss : 0.184271, loss_ce: 0.106856
2022-01-21 20:57:20,867 iteration 566 : loss : 0.098789, loss_ce: 0.036491
2022-01-21 20:57:22,096 iteration 567 : loss : 0.133728, loss_ce: 0.038962
2022-01-21 20:57:23,246 iteration 568 : loss : 0.108046, loss_ce: 0.042177
2022-01-21 20:57:24,420 iteration 569 : loss : 0.086629, loss_ce: 0.028439
2022-01-21 20:57:25,676 iteration 570 : loss : 0.115124, loss_ce: 0.051119
2022-01-21 20:57:26,906 iteration 571 : loss : 0.125782, loss_ce: 0.045574
2022-01-21 20:57:28,125 iteration 572 : loss : 0.120141, loss_ce: 0.043483
2022-01-21 20:57:29,290 iteration 573 : loss : 0.123193, loss_ce: 0.043394
2022-01-21 20:57:30,453 iteration 574 : loss : 0.112797, loss_ce: 0.050667
2022-01-21 20:57:31,675 iteration 575 : loss : 0.115201, loss_ce: 0.047383
2022-01-21 20:57:32,861 iteration 576 : loss : 0.131783, loss_ce: 0.065410
2022-01-21 20:57:34,064 iteration 577 : loss : 0.205756, loss_ce: 0.065002
2022-01-21 20:57:35,266 iteration 578 : loss : 0.126969, loss_ce: 0.043627
  8%|██▌                           | 34/400 [12:25<2:07:24, 20.89s/it]2022-01-21 20:57:36,480 iteration 579 : loss : 0.098828, loss_ce: 0.032122
2022-01-21 20:57:37,649 iteration 580 : loss : 0.082250, loss_ce: 0.035961
2022-01-21 20:57:38,841 iteration 581 : loss : 0.097285, loss_ce: 0.042733
2022-01-21 20:57:40,046 iteration 582 : loss : 0.093582, loss_ce: 0.035644
2022-01-21 20:57:41,205 iteration 583 : loss : 0.163995, loss_ce: 0.086158
2022-01-21 20:57:42,287 iteration 584 : loss : 0.093416, loss_ce: 0.037193
2022-01-21 20:57:43,418 iteration 585 : loss : 0.091533, loss_ce: 0.035709
2022-01-21 20:57:44,635 iteration 586 : loss : 0.100758, loss_ce: 0.045676
2022-01-21 20:57:45,800 iteration 587 : loss : 0.101286, loss_ce: 0.038891
2022-01-21 20:57:47,012 iteration 588 : loss : 0.093101, loss_ce: 0.036550
2022-01-21 20:57:48,197 iteration 589 : loss : 0.081051, loss_ce: 0.035606
2022-01-21 20:57:49,339 iteration 590 : loss : 0.125686, loss_ce: 0.065768
2022-01-21 20:57:50,509 iteration 591 : loss : 0.081047, loss_ce: 0.032584
2022-01-21 20:57:51,669 iteration 592 : loss : 0.125243, loss_ce: 0.048238
2022-01-21 20:57:52,887 iteration 593 : loss : 0.127448, loss_ce: 0.045244
2022-01-21 20:57:54,124 iteration 594 : loss : 0.099935, loss_ce: 0.050390
2022-01-21 20:57:54,124 Training Data Eval:
2022-01-21 20:57:59,792   Average segmentation loss on training set: 0.0902
2022-01-21 20:57:59,792 Validation Data Eval:
2022-01-21 20:58:01,759   Average segmentation loss on validation set: 0.1428
2022-01-21 20:58:05,913 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 20:58:07,163 iteration 595 : loss : 0.103176, loss_ce: 0.033180
  9%|██▋                           | 35/400 [12:57<2:27:10, 24.19s/it]2022-01-21 20:58:08,333 iteration 596 : loss : 0.070846, loss_ce: 0.028956
2022-01-21 20:58:09,511 iteration 597 : loss : 0.107353, loss_ce: 0.048534
2022-01-21 20:58:10,710 iteration 598 : loss : 0.100666, loss_ce: 0.041133
2022-01-21 20:58:11,937 iteration 599 : loss : 0.081884, loss_ce: 0.031229
2022-01-21 20:58:13,038 iteration 600 : loss : 0.083422, loss_ce: 0.041350
2022-01-21 20:58:14,214 iteration 601 : loss : 0.097523, loss_ce: 0.034181
2022-01-21 20:58:15,435 iteration 602 : loss : 0.096473, loss_ce: 0.043021
2022-01-21 20:58:16,528 iteration 603 : loss : 0.114202, loss_ce: 0.049113
2022-01-21 20:58:17,688 iteration 604 : loss : 0.182459, loss_ce: 0.081279
2022-01-21 20:58:18,856 iteration 605 : loss : 0.114226, loss_ce: 0.046542
2022-01-21 20:58:19,997 iteration 606 : loss : 0.165959, loss_ce: 0.077210
2022-01-21 20:58:21,162 iteration 607 : loss : 0.109712, loss_ce: 0.043971
2022-01-21 20:58:22,441 iteration 608 : loss : 0.092177, loss_ce: 0.031483
2022-01-21 20:58:23,600 iteration 609 : loss : 0.112866, loss_ce: 0.042702
2022-01-21 20:58:24,828 iteration 610 : loss : 0.123761, loss_ce: 0.041078
2022-01-21 20:58:26,000 iteration 611 : loss : 0.134312, loss_ce: 0.046361
2022-01-21 20:58:27,179 iteration 612 : loss : 0.123971, loss_ce: 0.051599
  9%|██▋                           | 36/400 [13:17<2:19:08, 22.94s/it]2022-01-21 20:58:28,419 iteration 613 : loss : 0.124042, loss_ce: 0.056681
2022-01-21 20:58:29,700 iteration 614 : loss : 0.113647, loss_ce: 0.046859
2022-01-21 20:58:30,879 iteration 615 : loss : 0.106399, loss_ce: 0.039012
2022-01-21 20:58:32,007 iteration 616 : loss : 0.121522, loss_ce: 0.068106
2022-01-21 20:58:33,186 iteration 617 : loss : 0.112428, loss_ce: 0.050805
2022-01-21 20:58:34,319 iteration 618 : loss : 0.141954, loss_ce: 0.056462
2022-01-21 20:58:35,479 iteration 619 : loss : 0.127403, loss_ce: 0.046829
2022-01-21 20:58:36,741 iteration 620 : loss : 0.135508, loss_ce: 0.054945
2022-01-21 20:58:37,884 iteration 621 : loss : 0.092316, loss_ce: 0.036373
2022-01-21 20:58:39,086 iteration 622 : loss : 0.098877, loss_ce: 0.040402
2022-01-21 20:58:40,324 iteration 623 : loss : 0.105671, loss_ce: 0.031286
2022-01-21 20:58:41,488 iteration 624 : loss : 0.139131, loss_ce: 0.044412
2022-01-21 20:58:42,612 iteration 625 : loss : 0.181620, loss_ce: 0.071142
2022-01-21 20:58:43,731 iteration 626 : loss : 0.102285, loss_ce: 0.037073
2022-01-21 20:58:44,881 iteration 627 : loss : 0.093844, loss_ce: 0.027968
2022-01-21 20:58:46,037 iteration 628 : loss : 0.124730, loss_ce: 0.068324
2022-01-21 20:58:47,241 iteration 629 : loss : 0.092307, loss_ce: 0.032217
  9%|██▊                           | 37/400 [13:37<2:13:33, 22.08s/it]2022-01-21 20:58:48,441 iteration 630 : loss : 0.084214, loss_ce: 0.034545
2022-01-21 20:58:49,652 iteration 631 : loss : 0.135430, loss_ce: 0.064300
2022-01-21 20:58:50,843 iteration 632 : loss : 0.144316, loss_ce: 0.058519
2022-01-21 20:58:52,056 iteration 633 : loss : 0.092560, loss_ce: 0.035920
2022-01-21 20:58:53,293 iteration 634 : loss : 0.082539, loss_ce: 0.040237
2022-01-21 20:58:54,461 iteration 635 : loss : 0.169445, loss_ce: 0.057516
2022-01-21 20:58:55,712 iteration 636 : loss : 0.105387, loss_ce: 0.046530
2022-01-21 20:58:56,860 iteration 637 : loss : 0.108958, loss_ce: 0.043059
2022-01-21 20:58:58,010 iteration 638 : loss : 0.152664, loss_ce: 0.067802
2022-01-21 20:58:59,229 iteration 639 : loss : 0.112991, loss_ce: 0.042150
2022-01-21 20:59:00,393 iteration 640 : loss : 0.129539, loss_ce: 0.048377
2022-01-21 20:59:01,594 iteration 641 : loss : 0.097486, loss_ce: 0.040162
2022-01-21 20:59:02,803 iteration 642 : loss : 0.097200, loss_ce: 0.035414
2022-01-21 20:59:03,983 iteration 643 : loss : 0.118395, loss_ce: 0.048749
2022-01-21 20:59:05,157 iteration 644 : loss : 0.073471, loss_ce: 0.029894
2022-01-21 20:59:06,348 iteration 645 : loss : 0.158975, loss_ce: 0.065488
2022-01-21 20:59:07,523 iteration 646 : loss : 0.108832, loss_ce: 0.055157
 10%|██▊                           | 38/400 [13:57<2:09:56, 21.54s/it]2022-01-21 20:59:08,732 iteration 647 : loss : 0.129725, loss_ce: 0.038912
2022-01-21 20:59:09,878 iteration 648 : loss : 0.100271, loss_ce: 0.048015
2022-01-21 20:59:11,022 iteration 649 : loss : 0.100418, loss_ce: 0.047976
2022-01-21 20:59:12,240 iteration 650 : loss : 0.163038, loss_ce: 0.051180
2022-01-21 20:59:13,451 iteration 651 : loss : 0.099351, loss_ce: 0.034751
2022-01-21 20:59:14,585 iteration 652 : loss : 0.083359, loss_ce: 0.037366
2022-01-21 20:59:15,738 iteration 653 : loss : 0.095626, loss_ce: 0.049086
2022-01-21 20:59:16,925 iteration 654 : loss : 0.131712, loss_ce: 0.052794
2022-01-21 20:59:18,044 iteration 655 : loss : 0.121216, loss_ce: 0.044117
2022-01-21 20:59:19,266 iteration 656 : loss : 0.119353, loss_ce: 0.045790
2022-01-21 20:59:20,440 iteration 657 : loss : 0.115174, loss_ce: 0.039931
2022-01-21 20:59:21,618 iteration 658 : loss : 0.109996, loss_ce: 0.040525
2022-01-21 20:59:22,847 iteration 659 : loss : 0.111501, loss_ce: 0.036082
2022-01-21 20:59:24,044 iteration 660 : loss : 0.099384, loss_ce: 0.039983
2022-01-21 20:59:25,240 iteration 661 : loss : 0.091718, loss_ce: 0.039634
2022-01-21 20:59:26,447 iteration 662 : loss : 0.092658, loss_ce: 0.040080
2022-01-21 20:59:27,626 iteration 663 : loss : 0.164917, loss_ce: 0.078414
 10%|██▉                           | 39/400 [14:17<2:06:59, 21.11s/it]2022-01-21 20:59:28,810 iteration 664 : loss : 0.152288, loss_ce: 0.079153
2022-01-21 20:59:30,031 iteration 665 : loss : 0.085150, loss_ce: 0.028809
2022-01-21 20:59:31,228 iteration 666 : loss : 0.125526, loss_ce: 0.044866
2022-01-21 20:59:32,467 iteration 667 : loss : 0.114419, loss_ce: 0.045511
2022-01-21 20:59:33,642 iteration 668 : loss : 0.072091, loss_ce: 0.026325
2022-01-21 20:59:34,884 iteration 669 : loss : 0.117784, loss_ce: 0.052040
2022-01-21 20:59:36,112 iteration 670 : loss : 0.146789, loss_ce: 0.060473
2022-01-21 20:59:37,317 iteration 671 : loss : 0.097124, loss_ce: 0.038565
2022-01-21 20:59:38,434 iteration 672 : loss : 0.114232, loss_ce: 0.048289
2022-01-21 20:59:39,601 iteration 673 : loss : 0.094064, loss_ce: 0.039048
2022-01-21 20:59:40,915 iteration 674 : loss : 0.102546, loss_ce: 0.049226
2022-01-21 20:59:42,111 iteration 675 : loss : 0.096793, loss_ce: 0.034700
2022-01-21 20:59:43,284 iteration 676 : loss : 0.124110, loss_ce: 0.054014
2022-01-21 20:59:44,581 iteration 677 : loss : 0.077478, loss_ce: 0.033428
2022-01-21 20:59:45,793 iteration 678 : loss : 0.106557, loss_ce: 0.030019
2022-01-21 20:59:46,939 iteration 679 : loss : 0.088063, loss_ce: 0.040352
2022-01-21 20:59:46,939 Training Data Eval:
2022-01-21 20:59:52,633   Average segmentation loss on training set: 0.0862
2022-01-21 20:59:52,634 Validation Data Eval:
2022-01-21 20:59:54,609   Average segmentation loss on validation set: 0.1285
2022-01-21 20:59:58,721 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 20:59:59,906 iteration 680 : loss : 0.100127, loss_ce: 0.040005
 10%|███                           | 40/400 [14:49<2:26:45, 24.46s/it]2022-01-21 21:00:01,237 iteration 681 : loss : 0.101963, loss_ce: 0.041785
2022-01-21 21:00:02,420 iteration 682 : loss : 0.108089, loss_ce: 0.042025
2022-01-21 21:00:03,563 iteration 683 : loss : 0.115323, loss_ce: 0.030831
2022-01-21 21:00:04,804 iteration 684 : loss : 0.088939, loss_ce: 0.035932
2022-01-21 21:00:06,054 iteration 685 : loss : 0.115682, loss_ce: 0.042415
2022-01-21 21:00:07,280 iteration 686 : loss : 0.088184, loss_ce: 0.039179
2022-01-21 21:00:08,499 iteration 687 : loss : 0.086574, loss_ce: 0.037097
2022-01-21 21:00:09,755 iteration 688 : loss : 0.087823, loss_ce: 0.033817
2022-01-21 21:00:10,976 iteration 689 : loss : 0.098629, loss_ce: 0.046118
2022-01-21 21:00:12,162 iteration 690 : loss : 0.098369, loss_ce: 0.043414
2022-01-21 21:00:13,394 iteration 691 : loss : 0.109748, loss_ce: 0.040615
2022-01-21 21:00:14,523 iteration 692 : loss : 0.084289, loss_ce: 0.036486
2022-01-21 21:00:15,687 iteration 693 : loss : 0.073136, loss_ce: 0.030393
2022-01-21 21:00:16,874 iteration 694 : loss : 0.171167, loss_ce: 0.062796
2022-01-21 21:00:18,055 iteration 695 : loss : 0.128187, loss_ce: 0.049169
2022-01-21 21:00:19,205 iteration 696 : loss : 0.168342, loss_ce: 0.044563
2022-01-21 21:00:20,308 iteration 697 : loss : 0.078024, loss_ce: 0.035729
 10%|███                           | 41/400 [15:10<2:19:04, 23.24s/it]2022-01-21 21:00:21,544 iteration 698 : loss : 0.100240, loss_ce: 0.043647
2022-01-21 21:00:22,750 iteration 699 : loss : 0.071275, loss_ce: 0.027224
2022-01-21 21:00:23,899 iteration 700 : loss : 0.097402, loss_ce: 0.037316
2022-01-21 21:00:25,055 iteration 701 : loss : 0.104999, loss_ce: 0.036802
2022-01-21 21:00:26,277 iteration 702 : loss : 0.078382, loss_ce: 0.031586
2022-01-21 21:00:27,475 iteration 703 : loss : 0.134760, loss_ce: 0.046087
2022-01-21 21:00:28,736 iteration 704 : loss : 0.115564, loss_ce: 0.046858
2022-01-21 21:00:29,975 iteration 705 : loss : 0.086050, loss_ce: 0.043182
2022-01-21 21:00:31,215 iteration 706 : loss : 0.112829, loss_ce: 0.034357
2022-01-21 21:00:32,385 iteration 707 : loss : 0.099687, loss_ce: 0.045119
2022-01-21 21:00:33,588 iteration 708 : loss : 0.089058, loss_ce: 0.028928
2022-01-21 21:00:34,796 iteration 709 : loss : 0.096888, loss_ce: 0.036434
2022-01-21 21:00:35,931 iteration 710 : loss : 0.083417, loss_ce: 0.039953
2022-01-21 21:00:37,165 iteration 711 : loss : 0.091442, loss_ce: 0.036524
2022-01-21 21:00:38,336 iteration 712 : loss : 0.120626, loss_ce: 0.048285
2022-01-21 21:00:39,452 iteration 713 : loss : 0.077957, loss_ce: 0.032684
2022-01-21 21:00:40,588 iteration 714 : loss : 0.082724, loss_ce: 0.030793
 10%|███▏                          | 42/400 [15:30<2:13:22, 22.35s/it]2022-01-21 21:00:41,873 iteration 715 : loss : 0.088825, loss_ce: 0.044067
2022-01-21 21:00:43,042 iteration 716 : loss : 0.078141, loss_ce: 0.032275
2022-01-21 21:00:44,206 iteration 717 : loss : 0.110148, loss_ce: 0.039832
2022-01-21 21:00:45,381 iteration 718 : loss : 0.098323, loss_ce: 0.041256
2022-01-21 21:00:46,636 iteration 719 : loss : 0.083157, loss_ce: 0.034288
2022-01-21 21:00:47,790 iteration 720 : loss : 0.136084, loss_ce: 0.045927
2022-01-21 21:00:49,016 iteration 721 : loss : 0.083265, loss_ce: 0.031122
2022-01-21 21:00:50,214 iteration 722 : loss : 0.109089, loss_ce: 0.045933
2022-01-21 21:00:51,358 iteration 723 : loss : 0.071765, loss_ce: 0.026076
2022-01-21 21:00:52,641 iteration 724 : loss : 0.086127, loss_ce: 0.036213
2022-01-21 21:00:53,777 iteration 725 : loss : 0.068485, loss_ce: 0.024941
2022-01-21 21:00:54,973 iteration 726 : loss : 0.107601, loss_ce: 0.028238
2022-01-21 21:00:56,208 iteration 727 : loss : 0.107596, loss_ce: 0.032342
2022-01-21 21:00:57,546 iteration 728 : loss : 0.100918, loss_ce: 0.048389
2022-01-21 21:00:58,633 iteration 729 : loss : 0.070959, loss_ce: 0.027686
2022-01-21 21:00:59,827 iteration 730 : loss : 0.085274, loss_ce: 0.039037
2022-01-21 21:01:01,020 iteration 731 : loss : 0.106483, loss_ce: 0.039842
 11%|███▏                          | 43/400 [15:50<2:09:33, 21.77s/it]2022-01-21 21:01:02,350 iteration 732 : loss : 0.078056, loss_ce: 0.035254
2022-01-21 21:01:03,555 iteration 733 : loss : 0.143959, loss_ce: 0.063652
2022-01-21 21:01:04,685 iteration 734 : loss : 0.100736, loss_ce: 0.034348
2022-01-21 21:01:05,865 iteration 735 : loss : 0.072797, loss_ce: 0.027151
2022-01-21 21:01:07,054 iteration 736 : loss : 0.111993, loss_ce: 0.037964
2022-01-21 21:01:08,287 iteration 737 : loss : 0.085380, loss_ce: 0.027514
2022-01-21 21:01:09,482 iteration 738 : loss : 0.065841, loss_ce: 0.029218
2022-01-21 21:01:10,651 iteration 739 : loss : 0.106711, loss_ce: 0.042016
2022-01-21 21:01:11,818 iteration 740 : loss : 0.096429, loss_ce: 0.047034
2022-01-21 21:01:13,011 iteration 741 : loss : 0.083837, loss_ce: 0.032191
2022-01-21 21:01:14,269 iteration 742 : loss : 0.110271, loss_ce: 0.040545
2022-01-21 21:01:15,431 iteration 743 : loss : 0.097330, loss_ce: 0.042352
2022-01-21 21:01:16,594 iteration 744 : loss : 0.088767, loss_ce: 0.036077
2022-01-21 21:01:17,738 iteration 745 : loss : 0.073337, loss_ce: 0.032059
2022-01-21 21:01:18,913 iteration 746 : loss : 0.155043, loss_ce: 0.082271
2022-01-21 21:01:20,117 iteration 747 : loss : 0.116379, loss_ce: 0.033666
2022-01-21 21:01:21,210 iteration 748 : loss : 0.076186, loss_ce: 0.032842
 11%|███▎                          | 44/400 [16:11<2:06:23, 21.30s/it]2022-01-21 21:01:22,440 iteration 749 : loss : 0.093072, loss_ce: 0.046907
2022-01-21 21:01:23,660 iteration 750 : loss : 0.074068, loss_ce: 0.031518
2022-01-21 21:01:24,782 iteration 751 : loss : 0.070929, loss_ce: 0.030484
2022-01-21 21:01:25,961 iteration 752 : loss : 0.082018, loss_ce: 0.030984
2022-01-21 21:01:27,225 iteration 753 : loss : 0.086849, loss_ce: 0.032198
2022-01-21 21:01:28,393 iteration 754 : loss : 0.131249, loss_ce: 0.065311
2022-01-21 21:01:29,586 iteration 755 : loss : 0.061098, loss_ce: 0.024460
2022-01-21 21:01:30,717 iteration 756 : loss : 0.089158, loss_ce: 0.036059
2022-01-21 21:01:31,866 iteration 757 : loss : 0.080679, loss_ce: 0.030569
2022-01-21 21:01:33,052 iteration 758 : loss : 0.071510, loss_ce: 0.028332
2022-01-21 21:01:34,163 iteration 759 : loss : 0.071307, loss_ce: 0.028992
2022-01-21 21:01:35,367 iteration 760 : loss : 0.145724, loss_ce: 0.054079
2022-01-21 21:01:36,590 iteration 761 : loss : 0.076605, loss_ce: 0.024908
2022-01-21 21:01:37,801 iteration 762 : loss : 0.110684, loss_ce: 0.048777
2022-01-21 21:01:38,966 iteration 763 : loss : 0.080202, loss_ce: 0.035342
2022-01-21 21:01:40,100 iteration 764 : loss : 0.085994, loss_ce: 0.039598
2022-01-21 21:01:40,100 Training Data Eval:
2022-01-21 21:01:45,774   Average segmentation loss on training set: 0.2928
2022-01-21 21:01:45,774 Validation Data Eval:
2022-01-21 21:01:47,727   Average segmentation loss on validation set: 0.3909
2022-01-21 21:01:48,921 iteration 765 : loss : 0.066970, loss_ce: 0.028901
 11%|███▍                          | 45/400 [16:38<2:17:24, 23.22s/it]2022-01-21 21:01:50,115 iteration 766 : loss : 0.097344, loss_ce: 0.038053
2022-01-21 21:01:51,338 iteration 767 : loss : 0.130545, loss_ce: 0.055149
2022-01-21 21:01:52,430 iteration 768 : loss : 0.103499, loss_ce: 0.032501
2022-01-21 21:01:53,609 iteration 769 : loss : 0.190275, loss_ce: 0.040088
2022-01-21 21:01:54,740 iteration 770 : loss : 0.069049, loss_ce: 0.026801
2022-01-21 21:01:55,985 iteration 771 : loss : 0.079003, loss_ce: 0.025251
2022-01-21 21:01:57,218 iteration 772 : loss : 0.069759, loss_ce: 0.032283
2022-01-21 21:01:58,409 iteration 773 : loss : 0.077978, loss_ce: 0.028916
2022-01-21 21:01:59,592 iteration 774 : loss : 0.090809, loss_ce: 0.039370
2022-01-21 21:02:00,757 iteration 775 : loss : 0.078933, loss_ce: 0.031962
2022-01-21 21:02:01,853 iteration 776 : loss : 0.083771, loss_ce: 0.038934
2022-01-21 21:02:03,082 iteration 777 : loss : 0.074609, loss_ce: 0.032812
2022-01-21 21:02:04,272 iteration 778 : loss : 0.060552, loss_ce: 0.025422
2022-01-21 21:02:05,456 iteration 779 : loss : 0.072972, loss_ce: 0.039077
2022-01-21 21:02:06,585 iteration 780 : loss : 0.099889, loss_ce: 0.038922
2022-01-21 21:02:07,806 iteration 781 : loss : 0.092903, loss_ce: 0.042792
2022-01-21 21:02:09,025 iteration 782 : loss : 0.082134, loss_ce: 0.033182
 12%|███▍                          | 46/400 [16:58<2:11:28, 22.28s/it]2022-01-21 21:02:10,285 iteration 783 : loss : 0.072441, loss_ce: 0.035390
2022-01-21 21:02:11,471 iteration 784 : loss : 0.108532, loss_ce: 0.037733
2022-01-21 21:02:12,692 iteration 785 : loss : 0.069877, loss_ce: 0.032460
2022-01-21 21:02:13,861 iteration 786 : loss : 0.074314, loss_ce: 0.024586
2022-01-21 21:02:15,045 iteration 787 : loss : 0.080564, loss_ce: 0.033919
2022-01-21 21:02:16,253 iteration 788 : loss : 0.064705, loss_ce: 0.019809
2022-01-21 21:02:17,557 iteration 789 : loss : 0.120605, loss_ce: 0.071620
2022-01-21 21:02:18,798 iteration 790 : loss : 0.068393, loss_ce: 0.023121
2022-01-21 21:02:19,962 iteration 791 : loss : 0.079355, loss_ce: 0.030434
2022-01-21 21:02:21,172 iteration 792 : loss : 0.084213, loss_ce: 0.036053
2022-01-21 21:02:22,276 iteration 793 : loss : 0.110041, loss_ce: 0.049660
2022-01-21 21:02:23,444 iteration 794 : loss : 0.078272, loss_ce: 0.030934
2022-01-21 21:02:24,623 iteration 795 : loss : 0.072080, loss_ce: 0.030542
2022-01-21 21:02:25,807 iteration 796 : loss : 0.109734, loss_ce: 0.043271
2022-01-21 21:02:26,953 iteration 797 : loss : 0.089486, loss_ce: 0.042141
2022-01-21 21:02:28,102 iteration 798 : loss : 0.183415, loss_ce: 0.049134
2022-01-21 21:02:29,310 iteration 799 : loss : 0.079763, loss_ce: 0.029872
 12%|███▌                          | 47/400 [17:19<2:07:35, 21.69s/it]2022-01-21 21:02:30,585 iteration 800 : loss : 0.093860, loss_ce: 0.027128
2022-01-21 21:02:31,729 iteration 801 : loss : 0.099289, loss_ce: 0.032442
2022-01-21 21:02:32,904 iteration 802 : loss : 0.118010, loss_ce: 0.066532
2022-01-21 21:02:34,150 iteration 803 : loss : 0.114014, loss_ce: 0.063591
2022-01-21 21:02:35,276 iteration 804 : loss : 0.074293, loss_ce: 0.034582
2022-01-21 21:02:36,402 iteration 805 : loss : 0.181655, loss_ce: 0.042318
2022-01-21 21:02:37,580 iteration 806 : loss : 0.117740, loss_ce: 0.039475
2022-01-21 21:02:38,839 iteration 807 : loss : 0.096314, loss_ce: 0.038330
2022-01-21 21:02:40,068 iteration 808 : loss : 0.097797, loss_ce: 0.034617
2022-01-21 21:02:41,237 iteration 809 : loss : 0.148200, loss_ce: 0.040019
2022-01-21 21:02:42,466 iteration 810 : loss : 0.112936, loss_ce: 0.037643
2022-01-21 21:02:43,620 iteration 811 : loss : 0.047983, loss_ce: 0.019580
2022-01-21 21:02:44,862 iteration 812 : loss : 0.124500, loss_ce: 0.044872
2022-01-21 21:02:46,035 iteration 813 : loss : 0.071457, loss_ce: 0.029361
2022-01-21 21:02:47,230 iteration 814 : loss : 0.082772, loss_ce: 0.035797
2022-01-21 21:02:48,461 iteration 815 : loss : 0.070469, loss_ce: 0.025258
2022-01-21 21:02:49,532 iteration 816 : loss : 0.063565, loss_ce: 0.023644
 12%|███▌                          | 48/400 [17:39<2:04:39, 21.25s/it]2022-01-21 21:02:50,717 iteration 817 : loss : 0.063546, loss_ce: 0.024719
2022-01-21 21:02:51,934 iteration 818 : loss : 0.093799, loss_ce: 0.038354
2022-01-21 21:02:53,110 iteration 819 : loss : 0.078917, loss_ce: 0.028650
2022-01-21 21:02:54,384 iteration 820 : loss : 0.086394, loss_ce: 0.035799
2022-01-21 21:02:55,487 iteration 821 : loss : 0.126283, loss_ce: 0.047661
2022-01-21 21:02:56,697 iteration 822 : loss : 0.070057, loss_ce: 0.028391
2022-01-21 21:02:57,872 iteration 823 : loss : 0.089463, loss_ce: 0.034433
2022-01-21 21:02:59,026 iteration 824 : loss : 0.071442, loss_ce: 0.032830
2022-01-21 21:03:00,206 iteration 825 : loss : 0.084988, loss_ce: 0.026195
2022-01-21 21:03:01,415 iteration 826 : loss : 0.071821, loss_ce: 0.029696
2022-01-21 21:03:02,582 iteration 827 : loss : 0.119227, loss_ce: 0.036788
2022-01-21 21:03:03,813 iteration 828 : loss : 0.091042, loss_ce: 0.039580
2022-01-21 21:03:04,987 iteration 829 : loss : 0.111243, loss_ce: 0.032735
2022-01-21 21:03:06,254 iteration 830 : loss : 0.088047, loss_ce: 0.031416
2022-01-21 21:03:07,458 iteration 831 : loss : 0.089385, loss_ce: 0.036185
2022-01-21 21:03:08,619 iteration 832 : loss : 0.069983, loss_ce: 0.025187
2022-01-21 21:03:09,755 iteration 833 : loss : 0.072130, loss_ce: 0.034738
 12%|███▋                          | 49/400 [17:59<2:02:29, 20.94s/it]2022-01-21 21:03:10,935 iteration 834 : loss : 0.125179, loss_ce: 0.047223
2022-01-21 21:03:12,147 iteration 835 : loss : 0.105323, loss_ce: 0.043458
2022-01-21 21:03:13,350 iteration 836 : loss : 0.096512, loss_ce: 0.041819
2022-01-21 21:03:14,512 iteration 837 : loss : 0.076946, loss_ce: 0.031519
2022-01-21 21:03:15,664 iteration 838 : loss : 0.125737, loss_ce: 0.058923
2022-01-21 21:03:16,911 iteration 839 : loss : 0.072261, loss_ce: 0.024924
2022-01-21 21:03:18,114 iteration 840 : loss : 0.138408, loss_ce: 0.056372
2022-01-21 21:03:19,311 iteration 841 : loss : 0.110554, loss_ce: 0.065970
2022-01-21 21:03:20,610 iteration 842 : loss : 0.109164, loss_ce: 0.045828
2022-01-21 21:03:21,775 iteration 843 : loss : 0.056748, loss_ce: 0.020681
2022-01-21 21:03:22,997 iteration 844 : loss : 0.094696, loss_ce: 0.035434
2022-01-21 21:03:24,144 iteration 845 : loss : 0.071251, loss_ce: 0.029158
2022-01-21 21:03:25,324 iteration 846 : loss : 0.098725, loss_ce: 0.035154
2022-01-21 21:03:26,548 iteration 847 : loss : 0.087596, loss_ce: 0.037902
2022-01-21 21:03:27,650 iteration 848 : loss : 0.084389, loss_ce: 0.031978
2022-01-21 21:03:28,851 iteration 849 : loss : 0.077131, loss_ce: 0.034963
2022-01-21 21:03:28,851 Training Data Eval:
2022-01-21 21:03:34,583   Average segmentation loss on training set: 0.0905
2022-01-21 21:03:34,584 Validation Data Eval:
2022-01-21 21:03:36,554   Average segmentation loss on validation set: 0.1091
2022-01-21 21:03:40,700 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 21:03:41,994 iteration 850 : loss : 0.094030, loss_ce: 0.033021
 12%|███▊                          | 50/400 [18:31<2:21:55, 24.33s/it]2022-01-21 21:03:43,243 iteration 851 : loss : 0.082458, loss_ce: 0.039060
2022-01-21 21:03:44,462 iteration 852 : loss : 0.077578, loss_ce: 0.026512
2022-01-21 21:03:45,682 iteration 853 : loss : 0.102429, loss_ce: 0.040245
2022-01-21 21:03:46,816 iteration 854 : loss : 0.069976, loss_ce: 0.026133
2022-01-21 21:03:47,913 iteration 855 : loss : 0.059750, loss_ce: 0.023573
2022-01-21 21:03:49,048 iteration 856 : loss : 0.083910, loss_ce: 0.030601
2022-01-21 21:03:50,305 iteration 857 : loss : 0.062864, loss_ce: 0.026368
2022-01-21 21:03:51,483 iteration 858 : loss : 0.079404, loss_ce: 0.028550
2022-01-21 21:03:52,746 iteration 859 : loss : 0.070987, loss_ce: 0.026968
2022-01-21 21:03:53,965 iteration 860 : loss : 0.086927, loss_ce: 0.033602
2022-01-21 21:03:55,147 iteration 861 : loss : 0.068908, loss_ce: 0.024593
2022-01-21 21:03:56,326 iteration 862 : loss : 0.069637, loss_ce: 0.018009
2022-01-21 21:03:57,442 iteration 863 : loss : 0.119305, loss_ce: 0.057206
2022-01-21 21:03:58,611 iteration 864 : loss : 0.077773, loss_ce: 0.031642
2022-01-21 21:03:59,726 iteration 865 : loss : 0.077657, loss_ce: 0.037646
2022-01-21 21:04:00,853 iteration 866 : loss : 0.053706, loss_ce: 0.022162
2022-01-21 21:04:01,996 iteration 867 : loss : 0.089263, loss_ce: 0.037409
 13%|███▊                          | 51/400 [18:51<2:13:58, 23.03s/it]2022-01-21 21:04:03,243 iteration 868 : loss : 0.065370, loss_ce: 0.022711
2022-01-21 21:04:04,391 iteration 869 : loss : 0.083609, loss_ce: 0.035994
2022-01-21 21:04:05,587 iteration 870 : loss : 0.157601, loss_ce: 0.042628
2022-01-21 21:04:06,783 iteration 871 : loss : 0.095828, loss_ce: 0.037680
2022-01-21 21:04:07,901 iteration 872 : loss : 0.058633, loss_ce: 0.027325
2022-01-21 21:04:09,028 iteration 873 : loss : 0.053498, loss_ce: 0.021130
2022-01-21 21:04:10,227 iteration 874 : loss : 0.078160, loss_ce: 0.037675
2022-01-21 21:04:11,428 iteration 875 : loss : 0.081903, loss_ce: 0.041760
2022-01-21 21:04:12,602 iteration 876 : loss : 0.076012, loss_ce: 0.032310
2022-01-21 21:04:13,719 iteration 877 : loss : 0.056149, loss_ce: 0.018397
2022-01-21 21:04:14,854 iteration 878 : loss : 0.065240, loss_ce: 0.020921
2022-01-21 21:04:16,035 iteration 879 : loss : 0.084326, loss_ce: 0.030131
2022-01-21 21:04:17,180 iteration 880 : loss : 0.061990, loss_ce: 0.027536
2022-01-21 21:04:18,397 iteration 881 : loss : 0.080571, loss_ce: 0.033128
2022-01-21 21:04:19,552 iteration 882 : loss : 0.069679, loss_ce: 0.030640
2022-01-21 21:04:20,709 iteration 883 : loss : 0.089001, loss_ce: 0.026974
2022-01-21 21:04:22,000 iteration 884 : loss : 0.077728, loss_ce: 0.030177
 13%|███▉                          | 52/400 [19:11<2:08:18, 22.12s/it]2022-01-21 21:04:23,291 iteration 885 : loss : 0.115431, loss_ce: 0.050142
2022-01-21 21:04:24,453 iteration 886 : loss : 0.090189, loss_ce: 0.031622
2022-01-21 21:04:25,619 iteration 887 : loss : 0.097683, loss_ce: 0.044127
2022-01-21 21:04:26,804 iteration 888 : loss : 0.080515, loss_ce: 0.030241
2022-01-21 21:04:27,948 iteration 889 : loss : 0.070060, loss_ce: 0.022145
2022-01-21 21:04:29,170 iteration 890 : loss : 0.069265, loss_ce: 0.032748
2022-01-21 21:04:30,374 iteration 891 : loss : 0.093658, loss_ce: 0.048824
2022-01-21 21:04:31,559 iteration 892 : loss : 0.124371, loss_ce: 0.038239
2022-01-21 21:04:32,817 iteration 893 : loss : 0.075982, loss_ce: 0.032332
2022-01-21 21:04:34,003 iteration 894 : loss : 0.065390, loss_ce: 0.026075
2022-01-21 21:04:35,202 iteration 895 : loss : 0.107542, loss_ce: 0.036084
2022-01-21 21:04:36,438 iteration 896 : loss : 0.144848, loss_ce: 0.048386
2022-01-21 21:04:37,559 iteration 897 : loss : 0.048729, loss_ce: 0.018947
2022-01-21 21:04:38,844 iteration 898 : loss : 0.100708, loss_ce: 0.038214
2022-01-21 21:04:40,024 iteration 899 : loss : 0.082148, loss_ce: 0.029823
2022-01-21 21:04:41,230 iteration 900 : loss : 0.109765, loss_ce: 0.039630
2022-01-21 21:04:42,404 iteration 901 : loss : 0.080084, loss_ce: 0.040738
 13%|███▉                          | 53/400 [19:32<2:04:58, 21.61s/it]2022-01-21 21:04:43,629 iteration 902 : loss : 0.056214, loss_ce: 0.023385
2022-01-21 21:04:44,846 iteration 903 : loss : 0.066420, loss_ce: 0.021071
2022-01-21 21:04:46,011 iteration 904 : loss : 0.069396, loss_ce: 0.029367
2022-01-21 21:04:47,141 iteration 905 : loss : 0.133157, loss_ce: 0.041354
2022-01-21 21:04:48,276 iteration 906 : loss : 0.076774, loss_ce: 0.026748
2022-01-21 21:04:49,503 iteration 907 : loss : 0.050970, loss_ce: 0.024556
2022-01-21 21:04:50,627 iteration 908 : loss : 0.068701, loss_ce: 0.035809
2022-01-21 21:04:51,839 iteration 909 : loss : 0.097115, loss_ce: 0.052055
2022-01-21 21:04:53,026 iteration 910 : loss : 0.121459, loss_ce: 0.055499
2022-01-21 21:04:54,224 iteration 911 : loss : 0.092465, loss_ce: 0.033538
2022-01-21 21:04:55,323 iteration 912 : loss : 0.078403, loss_ce: 0.028541
2022-01-21 21:04:56,546 iteration 913 : loss : 0.072446, loss_ce: 0.028545
2022-01-21 21:04:57,699 iteration 914 : loss : 0.061648, loss_ce: 0.029016
2022-01-21 21:04:58,902 iteration 915 : loss : 0.086826, loss_ce: 0.037881
2022-01-21 21:05:00,061 iteration 916 : loss : 0.076167, loss_ce: 0.029147
2022-01-21 21:05:01,240 iteration 917 : loss : 0.071489, loss_ce: 0.026681
2022-01-21 21:05:02,420 iteration 918 : loss : 0.069554, loss_ce: 0.023903
 14%|████                          | 54/400 [19:52<2:01:50, 21.13s/it]2022-01-21 21:05:03,701 iteration 919 : loss : 0.052657, loss_ce: 0.021146
2022-01-21 21:05:04,843 iteration 920 : loss : 0.110502, loss_ce: 0.058948
2022-01-21 21:05:06,109 iteration 921 : loss : 0.062907, loss_ce: 0.025758
2022-01-21 21:05:07,206 iteration 922 : loss : 0.060876, loss_ce: 0.028599
2022-01-21 21:05:08,331 iteration 923 : loss : 0.077073, loss_ce: 0.029154
2022-01-21 21:05:09,501 iteration 924 : loss : 0.064789, loss_ce: 0.021333
2022-01-21 21:05:10,626 iteration 925 : loss : 0.048328, loss_ce: 0.017153
2022-01-21 21:05:11,755 iteration 926 : loss : 0.072925, loss_ce: 0.026460
2022-01-21 21:05:12,942 iteration 927 : loss : 0.071748, loss_ce: 0.031313
2022-01-21 21:05:14,070 iteration 928 : loss : 0.063197, loss_ce: 0.025286
2022-01-21 21:05:15,387 iteration 929 : loss : 0.076274, loss_ce: 0.034771
2022-01-21 21:05:16,573 iteration 930 : loss : 0.087984, loss_ce: 0.051771
2022-01-21 21:05:17,767 iteration 931 : loss : 0.065527, loss_ce: 0.022906
2022-01-21 21:05:18,962 iteration 932 : loss : 0.082400, loss_ce: 0.023865
2022-01-21 21:05:20,284 iteration 933 : loss : 0.106143, loss_ce: 0.035859
2022-01-21 21:05:21,461 iteration 934 : loss : 0.064205, loss_ce: 0.024452
2022-01-21 21:05:21,461 Training Data Eval:
2022-01-21 21:05:27,170   Average segmentation loss on training set: 0.0684
2022-01-21 21:05:27,170 Validation Data Eval:
2022-01-21 21:05:29,138   Average segmentation loss on validation set: 0.1341
2022-01-21 21:05:30,285 iteration 935 : loss : 0.061468, loss_ce: 0.023740
 14%|████▏                         | 55/400 [20:20<2:13:06, 23.15s/it]2022-01-21 21:05:31,487 iteration 936 : loss : 0.066725, loss_ce: 0.016896
2022-01-21 21:05:32,646 iteration 937 : loss : 0.065873, loss_ce: 0.027031
2022-01-21 21:05:33,847 iteration 938 : loss : 0.083470, loss_ce: 0.041696
2022-01-21 21:05:35,021 iteration 939 : loss : 0.113947, loss_ce: 0.047098
2022-01-21 21:05:36,174 iteration 940 : loss : 0.088371, loss_ce: 0.040382
2022-01-21 21:05:37,370 iteration 941 : loss : 0.121541, loss_ce: 0.043649
2022-01-21 21:05:38,533 iteration 942 : loss : 0.082799, loss_ce: 0.028504
2022-01-21 21:05:39,646 iteration 943 : loss : 0.112701, loss_ce: 0.042782
2022-01-21 21:05:40,788 iteration 944 : loss : 0.057386, loss_ce: 0.023806
2022-01-21 21:05:41,934 iteration 945 : loss : 0.092522, loss_ce: 0.050816
2022-01-21 21:05:43,117 iteration 946 : loss : 0.052017, loss_ce: 0.019829
2022-01-21 21:05:44,393 iteration 947 : loss : 0.082666, loss_ce: 0.034867
2022-01-21 21:05:45,542 iteration 948 : loss : 0.093171, loss_ce: 0.038704
2022-01-21 21:05:46,746 iteration 949 : loss : 0.082132, loss_ce: 0.033088
2022-01-21 21:05:47,968 iteration 950 : loss : 0.109051, loss_ce: 0.032549
2022-01-21 21:05:49,220 iteration 951 : loss : 0.084840, loss_ce: 0.041071
2022-01-21 21:05:50,358 iteration 952 : loss : 0.105557, loss_ce: 0.032403
 14%|████▏                         | 56/400 [20:40<2:07:26, 22.23s/it]2022-01-21 21:05:51,581 iteration 953 : loss : 0.096227, loss_ce: 0.037924
2022-01-21 21:05:52,858 iteration 954 : loss : 0.055434, loss_ce: 0.020546
2022-01-21 21:05:54,025 iteration 955 : loss : 0.049786, loss_ce: 0.020577
2022-01-21 21:05:55,195 iteration 956 : loss : 0.074735, loss_ce: 0.030574
2022-01-21 21:05:56,261 iteration 957 : loss : 0.069488, loss_ce: 0.025803
2022-01-21 21:05:57,416 iteration 958 : loss : 0.089673, loss_ce: 0.032162
2022-01-21 21:05:58,540 iteration 959 : loss : 0.065590, loss_ce: 0.029611
2022-01-21 21:05:59,665 iteration 960 : loss : 0.059568, loss_ce: 0.024158
2022-01-21 21:06:00,849 iteration 961 : loss : 0.082392, loss_ce: 0.028108
2022-01-21 21:06:02,002 iteration 962 : loss : 0.062466, loss_ce: 0.022303
2022-01-21 21:06:03,215 iteration 963 : loss : 0.073904, loss_ce: 0.028249
2022-01-21 21:06:04,415 iteration 964 : loss : 0.074287, loss_ce: 0.029224
2022-01-21 21:06:05,585 iteration 965 : loss : 0.064726, loss_ce: 0.025823
2022-01-21 21:06:06,848 iteration 966 : loss : 0.121696, loss_ce: 0.061527
2022-01-21 21:06:08,029 iteration 967 : loss : 0.128117, loss_ce: 0.058464
2022-01-21 21:06:09,226 iteration 968 : loss : 0.087386, loss_ce: 0.035455
2022-01-21 21:06:10,450 iteration 969 : loss : 0.070468, loss_ce: 0.027001
 14%|████▎                         | 57/400 [21:00<2:03:25, 21.59s/it]2022-01-21 21:06:11,684 iteration 970 : loss : 0.095644, loss_ce: 0.051376
2022-01-21 21:06:12,939 iteration 971 : loss : 0.102425, loss_ce: 0.037598
2022-01-21 21:06:14,072 iteration 972 : loss : 0.057291, loss_ce: 0.020690
2022-01-21 21:06:15,202 iteration 973 : loss : 0.057467, loss_ce: 0.022895
2022-01-21 21:06:16,368 iteration 974 : loss : 0.069819, loss_ce: 0.026811
2022-01-21 21:06:17,500 iteration 975 : loss : 0.075183, loss_ce: 0.029524
2022-01-21 21:06:18,642 iteration 976 : loss : 0.089182, loss_ce: 0.032554
2022-01-21 21:06:19,880 iteration 977 : loss : 0.071931, loss_ce: 0.025997
2022-01-21 21:06:21,102 iteration 978 : loss : 0.069563, loss_ce: 0.032019
2022-01-21 21:06:22,321 iteration 979 : loss : 0.051019, loss_ce: 0.024032
2022-01-21 21:06:23,442 iteration 980 : loss : 0.068350, loss_ce: 0.024587
2022-01-21 21:06:24,672 iteration 981 : loss : 0.080008, loss_ce: 0.030686
2022-01-21 21:06:25,791 iteration 982 : loss : 0.075212, loss_ce: 0.037219
2022-01-21 21:06:26,993 iteration 983 : loss : 0.090920, loss_ce: 0.037837
2022-01-21 21:06:28,172 iteration 984 : loss : 0.085519, loss_ce: 0.041624
2022-01-21 21:06:29,346 iteration 985 : loss : 0.096881, loss_ce: 0.034075
2022-01-21 21:06:30,518 iteration 986 : loss : 0.094746, loss_ce: 0.035670
 14%|████▎                         | 58/400 [21:20<2:00:27, 21.13s/it]2022-01-21 21:06:31,755 iteration 987 : loss : 0.058865, loss_ce: 0.024648
2022-01-21 21:06:33,005 iteration 988 : loss : 0.081169, loss_ce: 0.032927
2022-01-21 21:06:34,151 iteration 989 : loss : 0.099220, loss_ce: 0.034615
2022-01-21 21:06:35,398 iteration 990 : loss : 0.055240, loss_ce: 0.028543
2022-01-21 21:06:36,623 iteration 991 : loss : 0.084171, loss_ce: 0.042531
2022-01-21 21:06:37,760 iteration 992 : loss : 0.092988, loss_ce: 0.038065
2022-01-21 21:06:39,058 iteration 993 : loss : 0.068183, loss_ce: 0.029767
2022-01-21 21:06:40,287 iteration 994 : loss : 0.085320, loss_ce: 0.026289
2022-01-21 21:06:41,489 iteration 995 : loss : 0.070741, loss_ce: 0.025136
2022-01-21 21:06:42,644 iteration 996 : loss : 0.046177, loss_ce: 0.017630
2022-01-21 21:06:43,855 iteration 997 : loss : 0.098047, loss_ce: 0.044944
2022-01-21 21:06:45,043 iteration 998 : loss : 0.090505, loss_ce: 0.034909
2022-01-21 21:06:46,312 iteration 999 : loss : 0.055407, loss_ce: 0.023538
2022-01-21 21:06:47,521 iteration 1000 : loss : 0.065603, loss_ce: 0.031727
2022-01-21 21:06:48,728 iteration 1001 : loss : 0.078467, loss_ce: 0.029507
2022-01-21 21:06:49,854 iteration 1002 : loss : 0.058012, loss_ce: 0.017157
2022-01-21 21:06:51,010 iteration 1003 : loss : 0.095327, loss_ce: 0.039830
 15%|████▍                         | 59/400 [21:40<1:59:01, 20.94s/it]2022-01-21 21:06:52,228 iteration 1004 : loss : 0.060663, loss_ce: 0.024031
2022-01-21 21:06:53,495 iteration 1005 : loss : 0.108009, loss_ce: 0.039236
2022-01-21 21:06:54,687 iteration 1006 : loss : 0.088930, loss_ce: 0.040904
2022-01-21 21:06:55,896 iteration 1007 : loss : 0.076144, loss_ce: 0.032824
2022-01-21 21:06:57,105 iteration 1008 : loss : 0.095915, loss_ce: 0.026590
2022-01-21 21:06:58,306 iteration 1009 : loss : 0.077308, loss_ce: 0.028970
2022-01-21 21:06:59,457 iteration 1010 : loss : 0.059057, loss_ce: 0.023010
2022-01-21 21:07:00,628 iteration 1011 : loss : 0.044161, loss_ce: 0.019269
2022-01-21 21:07:01,878 iteration 1012 : loss : 0.097235, loss_ce: 0.029220
2022-01-21 21:07:03,035 iteration 1013 : loss : 0.078135, loss_ce: 0.026039
2022-01-21 21:07:04,251 iteration 1014 : loss : 0.060910, loss_ce: 0.022577
2022-01-21 21:07:05,423 iteration 1015 : loss : 0.090269, loss_ce: 0.038733
2022-01-21 21:07:06,527 iteration 1016 : loss : 0.090068, loss_ce: 0.042509
2022-01-21 21:07:07,805 iteration 1017 : loss : 0.067244, loss_ce: 0.021352
2022-01-21 21:07:09,041 iteration 1018 : loss : 0.059101, loss_ce: 0.023686
2022-01-21 21:07:10,298 iteration 1019 : loss : 0.105439, loss_ce: 0.050611
2022-01-21 21:07:10,299 Training Data Eval:
2022-01-21 21:07:16,014   Average segmentation loss on training set: 0.0551
2022-01-21 21:07:16,014 Validation Data Eval:
2022-01-21 21:07:17,989   Average segmentation loss on validation set: 0.0861
2022-01-21 21:07:22,126 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 21:07:23,409 iteration 1020 : loss : 0.073790, loss_ce: 0.027157
 15%|████▌                         | 60/400 [22:13<2:18:08, 24.38s/it]2022-01-21 21:07:24,724 iteration 1021 : loss : 0.086170, loss_ce: 0.036617
2022-01-21 21:07:25,907 iteration 1022 : loss : 0.066056, loss_ce: 0.021414
2022-01-21 21:07:27,060 iteration 1023 : loss : 0.098574, loss_ce: 0.032193
2022-01-21 21:07:28,272 iteration 1024 : loss : 0.052587, loss_ce: 0.024234
2022-01-21 21:07:29,428 iteration 1025 : loss : 0.101609, loss_ce: 0.043897
2022-01-21 21:07:30,632 iteration 1026 : loss : 0.097252, loss_ce: 0.036007
2022-01-21 21:07:31,804 iteration 1027 : loss : 0.062347, loss_ce: 0.033325
2022-01-21 21:07:32,945 iteration 1028 : loss : 0.088732, loss_ce: 0.025670
2022-01-21 21:07:34,146 iteration 1029 : loss : 0.097848, loss_ce: 0.029867
2022-01-21 21:07:35,354 iteration 1030 : loss : 0.062745, loss_ce: 0.024780
2022-01-21 21:07:36,604 iteration 1031 : loss : 0.080762, loss_ce: 0.036484
2022-01-21 21:07:37,737 iteration 1032 : loss : 0.055211, loss_ce: 0.021294
2022-01-21 21:07:38,971 iteration 1033 : loss : 0.072121, loss_ce: 0.026715
2022-01-21 21:07:40,225 iteration 1034 : loss : 0.051874, loss_ce: 0.026422
2022-01-21 21:07:41,442 iteration 1035 : loss : 0.112550, loss_ce: 0.040320
2022-01-21 21:07:42,719 iteration 1036 : loss : 0.084308, loss_ce: 0.031593
2022-01-21 21:07:43,795 iteration 1037 : loss : 0.067735, loss_ce: 0.029140
 15%|████▌                         | 61/400 [22:33<2:10:58, 23.18s/it]2022-01-21 21:07:44,978 iteration 1038 : loss : 0.065933, loss_ce: 0.028459
2022-01-21 21:07:46,163 iteration 1039 : loss : 0.073574, loss_ce: 0.032445
2022-01-21 21:07:47,284 iteration 1040 : loss : 0.089636, loss_ce: 0.034079
2022-01-21 21:07:48,539 iteration 1041 : loss : 0.079340, loss_ce: 0.028885
2022-01-21 21:07:49,784 iteration 1042 : loss : 0.077535, loss_ce: 0.027442
2022-01-21 21:07:50,930 iteration 1043 : loss : 0.057886, loss_ce: 0.021514
2022-01-21 21:07:52,102 iteration 1044 : loss : 0.067351, loss_ce: 0.026229
2022-01-21 21:07:53,265 iteration 1045 : loss : 0.063484, loss_ce: 0.034293
2022-01-21 21:07:54,451 iteration 1046 : loss : 0.063389, loss_ce: 0.025895
2022-01-21 21:07:55,715 iteration 1047 : loss : 0.081809, loss_ce: 0.036532
2022-01-21 21:07:56,903 iteration 1048 : loss : 0.077572, loss_ce: 0.034253
2022-01-21 21:07:58,022 iteration 1049 : loss : 0.079704, loss_ce: 0.031800
2022-01-21 21:07:59,165 iteration 1050 : loss : 0.062482, loss_ce: 0.024145
2022-01-21 21:08:00,354 iteration 1051 : loss : 0.074251, loss_ce: 0.027463
2022-01-21 21:08:01,537 iteration 1052 : loss : 0.078332, loss_ce: 0.034508
2022-01-21 21:08:02,825 iteration 1053 : loss : 0.068983, loss_ce: 0.026726
2022-01-21 21:08:03,987 iteration 1054 : loss : 0.065545, loss_ce: 0.023261
 16%|████▋                         | 62/400 [22:53<2:05:30, 22.28s/it]2022-01-21 21:08:05,208 iteration 1055 : loss : 0.049958, loss_ce: 0.018633
2022-01-21 21:08:06,388 iteration 1056 : loss : 0.086320, loss_ce: 0.039289
2022-01-21 21:08:07,599 iteration 1057 : loss : 0.085264, loss_ce: 0.022865
2022-01-21 21:08:08,720 iteration 1058 : loss : 0.064296, loss_ce: 0.026421
2022-01-21 21:08:09,974 iteration 1059 : loss : 0.096084, loss_ce: 0.045263
2022-01-21 21:08:11,139 iteration 1060 : loss : 0.064690, loss_ce: 0.029247
2022-01-21 21:08:12,358 iteration 1061 : loss : 0.059148, loss_ce: 0.023009
2022-01-21 21:08:13,542 iteration 1062 : loss : 0.063047, loss_ce: 0.021487
2022-01-21 21:08:14,806 iteration 1063 : loss : 0.061350, loss_ce: 0.020555
2022-01-21 21:08:15,965 iteration 1064 : loss : 0.060937, loss_ce: 0.027662
2022-01-21 21:08:17,073 iteration 1065 : loss : 0.068591, loss_ce: 0.027718
2022-01-21 21:08:18,270 iteration 1066 : loss : 0.059543, loss_ce: 0.029954
2022-01-21 21:08:19,576 iteration 1067 : loss : 0.087369, loss_ce: 0.041349
2022-01-21 21:08:20,814 iteration 1068 : loss : 0.110632, loss_ce: 0.042549
2022-01-21 21:08:21,951 iteration 1069 : loss : 0.103993, loss_ce: 0.046708
2022-01-21 21:08:23,223 iteration 1070 : loss : 0.074682, loss_ce: 0.027527
2022-01-21 21:08:24,403 iteration 1071 : loss : 0.060447, loss_ce: 0.023183
 16%|████▋                         | 63/400 [23:14<2:02:00, 21.72s/it]2022-01-21 21:08:25,620 iteration 1072 : loss : 0.055433, loss_ce: 0.022871
2022-01-21 21:08:26,890 iteration 1073 : loss : 0.066180, loss_ce: 0.026054
2022-01-21 21:08:28,050 iteration 1074 : loss : 0.044822, loss_ce: 0.021048
2022-01-21 21:08:29,244 iteration 1075 : loss : 0.055428, loss_ce: 0.021628
2022-01-21 21:08:30,396 iteration 1076 : loss : 0.072637, loss_ce: 0.030408
2022-01-21 21:08:31,623 iteration 1077 : loss : 0.172020, loss_ce: 0.068722
2022-01-21 21:08:32,743 iteration 1078 : loss : 0.067250, loss_ce: 0.028113
2022-01-21 21:08:33,927 iteration 1079 : loss : 0.062527, loss_ce: 0.026190
2022-01-21 21:08:35,142 iteration 1080 : loss : 0.062750, loss_ce: 0.024286
2022-01-21 21:08:36,353 iteration 1081 : loss : 0.084585, loss_ce: 0.038670
2022-01-21 21:08:37,544 iteration 1082 : loss : 0.099017, loss_ce: 0.046428
2022-01-21 21:08:38,737 iteration 1083 : loss : 0.092602, loss_ce: 0.031218
2022-01-21 21:08:40,008 iteration 1084 : loss : 0.120766, loss_ce: 0.029575
2022-01-21 21:08:41,178 iteration 1085 : loss : 0.068649, loss_ce: 0.026080
2022-01-21 21:08:42,397 iteration 1086 : loss : 0.063557, loss_ce: 0.023303
2022-01-21 21:08:43,523 iteration 1087 : loss : 0.057734, loss_ce: 0.023819
2022-01-21 21:08:44,679 iteration 1088 : loss : 0.079190, loss_ce: 0.038548
 16%|████▊                         | 64/400 [23:34<1:59:13, 21.29s/it]2022-01-21 21:08:45,828 iteration 1089 : loss : 0.071892, loss_ce: 0.032082
2022-01-21 21:08:47,004 iteration 1090 : loss : 0.065524, loss_ce: 0.020028
2022-01-21 21:08:48,221 iteration 1091 : loss : 0.077131, loss_ce: 0.037673
2022-01-21 21:08:49,417 iteration 1092 : loss : 0.073345, loss_ce: 0.021749
2022-01-21 21:08:50,621 iteration 1093 : loss : 0.070300, loss_ce: 0.020923
2022-01-21 21:08:51,919 iteration 1094 : loss : 0.190885, loss_ce: 0.058931
2022-01-21 21:08:53,045 iteration 1095 : loss : 0.066715, loss_ce: 0.022878
2022-01-21 21:08:54,184 iteration 1096 : loss : 0.058662, loss_ce: 0.026552
2022-01-21 21:08:55,304 iteration 1097 : loss : 0.061248, loss_ce: 0.024175
2022-01-21 21:08:56,549 iteration 1098 : loss : 0.067236, loss_ce: 0.029761
2022-01-21 21:08:57,729 iteration 1099 : loss : 0.062985, loss_ce: 0.021191
2022-01-21 21:08:58,966 iteration 1100 : loss : 0.073176, loss_ce: 0.035016
2022-01-21 21:09:00,217 iteration 1101 : loss : 0.077995, loss_ce: 0.030338
2022-01-21 21:09:01,396 iteration 1102 : loss : 0.081088, loss_ce: 0.030035
2022-01-21 21:09:02,606 iteration 1103 : loss : 0.066480, loss_ce: 0.032491
2022-01-21 21:09:03,775 iteration 1104 : loss : 0.055785, loss_ce: 0.023045
2022-01-21 21:09:03,775 Training Data Eval:
2022-01-21 21:09:09,456   Average segmentation loss on training set: 0.0769
2022-01-21 21:09:09,478 Validation Data Eval:
2022-01-21 21:09:11,445   Average segmentation loss on validation set: 0.1068
2022-01-21 21:09:12,621 iteration 1105 : loss : 0.063616, loss_ce: 0.027253
 16%|████▉                         | 65/400 [24:02<2:10:01, 23.29s/it]2022-01-21 21:09:13,899 iteration 1106 : loss : 0.063980, loss_ce: 0.025109
2022-01-21 21:09:15,078 iteration 1107 : loss : 0.063552, loss_ce: 0.025279
2022-01-21 21:09:16,241 iteration 1108 : loss : 0.074416, loss_ce: 0.023143
2022-01-21 21:09:17,487 iteration 1109 : loss : 0.058323, loss_ce: 0.021882
2022-01-21 21:09:18,666 iteration 1110 : loss : 0.067908, loss_ce: 0.029496
2022-01-21 21:09:19,939 iteration 1111 : loss : 0.107344, loss_ce: 0.031638
2022-01-21 21:09:21,077 iteration 1112 : loss : 0.066718, loss_ce: 0.029032
2022-01-21 21:09:22,265 iteration 1113 : loss : 0.052473, loss_ce: 0.019980
2022-01-21 21:09:23,461 iteration 1114 : loss : 0.097507, loss_ce: 0.035823
2022-01-21 21:09:24,666 iteration 1115 : loss : 0.056494, loss_ce: 0.017902
2022-01-21 21:09:25,782 iteration 1116 : loss : 0.088648, loss_ce: 0.041997
2022-01-21 21:09:26,918 iteration 1117 : loss : 0.066009, loss_ce: 0.027366
2022-01-21 21:09:28,124 iteration 1118 : loss : 0.067319, loss_ce: 0.031686
2022-01-21 21:09:29,343 iteration 1119 : loss : 0.057069, loss_ce: 0.023582
2022-01-21 21:09:30,537 iteration 1120 : loss : 0.081685, loss_ce: 0.027754
2022-01-21 21:09:31,698 iteration 1121 : loss : 0.059788, loss_ce: 0.027005
2022-01-21 21:09:32,817 iteration 1122 : loss : 0.063284, loss_ce: 0.021869
 16%|████▉                         | 66/400 [24:22<2:04:27, 22.36s/it]2022-01-21 21:09:34,139 iteration 1123 : loss : 0.042790, loss_ce: 0.016348
2022-01-21 21:09:35,321 iteration 1124 : loss : 0.044026, loss_ce: 0.021326
2022-01-21 21:09:36,471 iteration 1125 : loss : 0.090245, loss_ce: 0.030112
2022-01-21 21:09:37,632 iteration 1126 : loss : 0.070783, loss_ce: 0.022353
2022-01-21 21:09:38,783 iteration 1127 : loss : 0.061754, loss_ce: 0.023557
2022-01-21 21:09:40,034 iteration 1128 : loss : 0.072985, loss_ce: 0.030650
2022-01-21 21:09:41,308 iteration 1129 : loss : 0.087067, loss_ce: 0.034316
2022-01-21 21:09:42,444 iteration 1130 : loss : 0.057499, loss_ce: 0.022617
2022-01-21 21:09:43,670 iteration 1131 : loss : 0.081945, loss_ce: 0.038054
2022-01-21 21:09:44,936 iteration 1132 : loss : 0.058125, loss_ce: 0.023806
2022-01-21 21:09:46,184 iteration 1133 : loss : 0.077088, loss_ce: 0.032272
2022-01-21 21:09:47,431 iteration 1134 : loss : 0.087882, loss_ce: 0.027925
2022-01-21 21:09:48,576 iteration 1135 : loss : 0.076920, loss_ce: 0.027561
2022-01-21 21:09:49,741 iteration 1136 : loss : 0.050482, loss_ce: 0.022879
2022-01-21 21:09:50,904 iteration 1137 : loss : 0.084815, loss_ce: 0.038960
2022-01-21 21:09:52,121 iteration 1138 : loss : 0.089511, loss_ce: 0.034555
2022-01-21 21:09:53,251 iteration 1139 : loss : 0.067553, loss_ce: 0.026747
 17%|█████                         | 67/400 [24:43<2:00:53, 21.78s/it]2022-01-21 21:09:54,494 iteration 1140 : loss : 0.066200, loss_ce: 0.025246
2022-01-21 21:09:55,703 iteration 1141 : loss : 0.098026, loss_ce: 0.048041
2022-01-21 21:09:57,006 iteration 1142 : loss : 0.067560, loss_ce: 0.030227
2022-01-21 21:09:58,217 iteration 1143 : loss : 0.062305, loss_ce: 0.026318
2022-01-21 21:09:59,432 iteration 1144 : loss : 0.073464, loss_ce: 0.024660
2022-01-21 21:10:00,629 iteration 1145 : loss : 0.073372, loss_ce: 0.027752
2022-01-21 21:10:01,791 iteration 1146 : loss : 0.050881, loss_ce: 0.020943
2022-01-21 21:10:02,955 iteration 1147 : loss : 0.051993, loss_ce: 0.021094
2022-01-21 21:10:04,109 iteration 1148 : loss : 0.056893, loss_ce: 0.022348
2022-01-21 21:10:05,287 iteration 1149 : loss : 0.048357, loss_ce: 0.021862
2022-01-21 21:10:06,441 iteration 1150 : loss : 0.053631, loss_ce: 0.020218
2022-01-21 21:10:07,606 iteration 1151 : loss : 0.044020, loss_ce: 0.019284
2022-01-21 21:10:08,745 iteration 1152 : loss : 0.073478, loss_ce: 0.028989
2022-01-21 21:10:10,015 iteration 1153 : loss : 0.074392, loss_ce: 0.024315
2022-01-21 21:10:11,232 iteration 1154 : loss : 0.069485, loss_ce: 0.025605
2022-01-21 21:10:12,464 iteration 1155 : loss : 0.102996, loss_ce: 0.031858
2022-01-21 21:10:13,759 iteration 1156 : loss : 0.087535, loss_ce: 0.029978
 17%|█████                         | 68/400 [25:03<1:58:23, 21.40s/it]2022-01-21 21:10:15,023 iteration 1157 : loss : 0.076771, loss_ce: 0.031098
2022-01-21 21:10:16,197 iteration 1158 : loss : 0.053413, loss_ce: 0.020184
2022-01-21 21:10:17,292 iteration 1159 : loss : 0.074735, loss_ce: 0.029716
2022-01-21 21:10:18,445 iteration 1160 : loss : 0.073511, loss_ce: 0.035583
2022-01-21 21:10:19,647 iteration 1161 : loss : 0.066026, loss_ce: 0.024087
2022-01-21 21:10:20,859 iteration 1162 : loss : 0.066059, loss_ce: 0.027806
2022-01-21 21:10:22,047 iteration 1163 : loss : 0.052574, loss_ce: 0.026442
2022-01-21 21:10:23,285 iteration 1164 : loss : 0.080510, loss_ce: 0.035571
2022-01-21 21:10:24,402 iteration 1165 : loss : 0.067690, loss_ce: 0.029263
2022-01-21 21:10:25,544 iteration 1166 : loss : 0.079448, loss_ce: 0.027753
2022-01-21 21:10:26,736 iteration 1167 : loss : 0.093251, loss_ce: 0.046129
2022-01-21 21:10:27,978 iteration 1168 : loss : 0.115729, loss_ce: 0.039600
2022-01-21 21:10:29,109 iteration 1169 : loss : 0.095042, loss_ce: 0.028002
2022-01-21 21:10:30,313 iteration 1170 : loss : 0.082110, loss_ce: 0.027287
2022-01-21 21:10:31,615 iteration 1171 : loss : 0.128228, loss_ce: 0.040069
2022-01-21 21:10:32,739 iteration 1172 : loss : 0.061194, loss_ce: 0.022955
2022-01-21 21:10:33,856 iteration 1173 : loss : 0.050281, loss_ce: 0.016241
 17%|█████▏                        | 69/400 [25:23<1:55:54, 21.01s/it]2022-01-21 21:10:35,119 iteration 1174 : loss : 0.054265, loss_ce: 0.019429
2022-01-21 21:10:36,381 iteration 1175 : loss : 0.081959, loss_ce: 0.031591
2022-01-21 21:10:37,544 iteration 1176 : loss : 0.089952, loss_ce: 0.032136
2022-01-21 21:10:38,697 iteration 1177 : loss : 0.072176, loss_ce: 0.031708
2022-01-21 21:10:39,819 iteration 1178 : loss : 0.081932, loss_ce: 0.027985
2022-01-21 21:10:41,052 iteration 1179 : loss : 0.067919, loss_ce: 0.028067
2022-01-21 21:10:42,259 iteration 1180 : loss : 0.063759, loss_ce: 0.026079
2022-01-21 21:10:43,386 iteration 1181 : loss : 0.065641, loss_ce: 0.021584
2022-01-21 21:10:44,545 iteration 1182 : loss : 0.079412, loss_ce: 0.036644
2022-01-21 21:10:45,719 iteration 1183 : loss : 0.065808, loss_ce: 0.030070
2022-01-21 21:10:46,910 iteration 1184 : loss : 0.109530, loss_ce: 0.056075
2022-01-21 21:10:48,077 iteration 1185 : loss : 0.055989, loss_ce: 0.029542
2022-01-21 21:10:49,274 iteration 1186 : loss : 0.076780, loss_ce: 0.026561
2022-01-21 21:10:50,406 iteration 1187 : loss : 0.054995, loss_ce: 0.023073
2022-01-21 21:10:51,622 iteration 1188 : loss : 0.085081, loss_ce: 0.031033
2022-01-21 21:10:52,850 iteration 1189 : loss : 0.119648, loss_ce: 0.035393
2022-01-21 21:10:52,850 Training Data Eval:
2022-01-21 21:10:58,534   Average segmentation loss on training set: 0.0508
2022-01-21 21:10:58,534 Validation Data Eval:
2022-01-21 21:11:00,499   Average segmentation loss on validation set: 0.0960
2022-01-21 21:11:01,642 iteration 1190 : loss : 0.067459, loss_ce: 0.024335
 18%|█████▎                        | 70/400 [25:51<2:06:43, 23.04s/it]2022-01-21 21:11:02,876 iteration 1191 : loss : 0.051313, loss_ce: 0.018431
2022-01-21 21:11:04,037 iteration 1192 : loss : 0.083470, loss_ce: 0.046844
2022-01-21 21:11:05,140 iteration 1193 : loss : 0.052656, loss_ce: 0.020003
2022-01-21 21:11:06,323 iteration 1194 : loss : 0.088320, loss_ce: 0.032576
2022-01-21 21:11:07,503 iteration 1195 : loss : 0.074051, loss_ce: 0.030845
2022-01-21 21:11:08,698 iteration 1196 : loss : 0.053868, loss_ce: 0.020578
2022-01-21 21:11:09,918 iteration 1197 : loss : 0.067443, loss_ce: 0.023080
2022-01-21 21:11:11,037 iteration 1198 : loss : 0.044307, loss_ce: 0.015273
2022-01-21 21:11:12,204 iteration 1199 : loss : 0.069112, loss_ce: 0.033088
2022-01-21 21:11:13,314 iteration 1200 : loss : 0.048742, loss_ce: 0.020394
2022-01-21 21:11:14,457 iteration 1201 : loss : 0.093528, loss_ce: 0.033009
2022-01-21 21:11:15,687 iteration 1202 : loss : 0.057130, loss_ce: 0.024102
2022-01-21 21:11:16,919 iteration 1203 : loss : 0.101016, loss_ce: 0.046573
2022-01-21 21:11:18,037 iteration 1204 : loss : 0.071578, loss_ce: 0.021210
2022-01-21 21:11:19,248 iteration 1205 : loss : 0.064018, loss_ce: 0.026360
2022-01-21 21:11:20,395 iteration 1206 : loss : 0.061583, loss_ce: 0.024288
2022-01-21 21:11:21,636 iteration 1207 : loss : 0.057519, loss_ce: 0.025527
 18%|█████▎                        | 71/400 [26:11<2:01:19, 22.13s/it]2022-01-21 21:11:22,849 iteration 1208 : loss : 0.069281, loss_ce: 0.029594
2022-01-21 21:11:24,040 iteration 1209 : loss : 0.065756, loss_ce: 0.021271
2022-01-21 21:11:25,161 iteration 1210 : loss : 0.062757, loss_ce: 0.030433
2022-01-21 21:11:26,394 iteration 1211 : loss : 0.058783, loss_ce: 0.027279
2022-01-21 21:11:27,559 iteration 1212 : loss : 0.057995, loss_ce: 0.021110
2022-01-21 21:11:28,650 iteration 1213 : loss : 0.055862, loss_ce: 0.019341
2022-01-21 21:11:29,900 iteration 1214 : loss : 0.095942, loss_ce: 0.046720
2022-01-21 21:11:31,066 iteration 1215 : loss : 0.051941, loss_ce: 0.020622
2022-01-21 21:11:32,237 iteration 1216 : loss : 0.046622, loss_ce: 0.016533
2022-01-21 21:11:33,529 iteration 1217 : loss : 0.083830, loss_ce: 0.033143
2022-01-21 21:11:34,648 iteration 1218 : loss : 0.078445, loss_ce: 0.036962
2022-01-21 21:11:35,964 iteration 1219 : loss : 0.075756, loss_ce: 0.036455
2022-01-21 21:11:37,144 iteration 1220 : loss : 0.064086, loss_ce: 0.026915
2022-01-21 21:11:38,397 iteration 1221 : loss : 0.111963, loss_ce: 0.050341
2022-01-21 21:11:39,552 iteration 1222 : loss : 0.082485, loss_ce: 0.029744
2022-01-21 21:11:40,704 iteration 1223 : loss : 0.066616, loss_ce: 0.024057
2022-01-21 21:11:41,871 iteration 1224 : loss : 0.119941, loss_ce: 0.053279
 18%|█████▍                        | 72/400 [26:31<1:57:51, 21.56s/it]2022-01-21 21:11:43,097 iteration 1225 : loss : 0.063747, loss_ce: 0.021789
2022-01-21 21:11:44,308 iteration 1226 : loss : 0.053965, loss_ce: 0.019510
2022-01-21 21:11:45,444 iteration 1227 : loss : 0.084166, loss_ce: 0.033276
2022-01-21 21:11:46,587 iteration 1228 : loss : 0.145975, loss_ce: 0.058456
2022-01-21 21:11:47,878 iteration 1229 : loss : 0.083769, loss_ce: 0.044677
2022-01-21 21:11:49,099 iteration 1230 : loss : 0.071511, loss_ce: 0.028235
2022-01-21 21:11:50,296 iteration 1231 : loss : 0.056650, loss_ce: 0.022247
2022-01-21 21:11:51,443 iteration 1232 : loss : 0.109402, loss_ce: 0.053934
2022-01-21 21:11:52,678 iteration 1233 : loss : 0.061762, loss_ce: 0.022131
2022-01-21 21:11:53,965 iteration 1234 : loss : 0.076011, loss_ce: 0.029539
2022-01-21 21:11:55,082 iteration 1235 : loss : 0.087280, loss_ce: 0.032539
2022-01-21 21:11:56,302 iteration 1236 : loss : 0.076246, loss_ce: 0.038739
2022-01-21 21:11:57,485 iteration 1237 : loss : 0.070813, loss_ce: 0.024577
2022-01-21 21:11:58,617 iteration 1238 : loss : 0.070172, loss_ce: 0.028566
2022-01-21 21:11:59,788 iteration 1239 : loss : 0.052251, loss_ce: 0.022163
2022-01-21 21:12:01,049 iteration 1240 : loss : 0.080712, loss_ce: 0.026289
2022-01-21 21:12:02,236 iteration 1241 : loss : 0.055571, loss_ce: 0.021672
 18%|█████▍                        | 73/400 [26:52<1:55:33, 21.20s/it]2022-01-21 21:12:03,520 iteration 1242 : loss : 0.062167, loss_ce: 0.032165
2022-01-21 21:12:04,712 iteration 1243 : loss : 0.089134, loss_ce: 0.027123
2022-01-21 21:12:05,987 iteration 1244 : loss : 0.079867, loss_ce: 0.029063
2022-01-21 21:12:07,247 iteration 1245 : loss : 0.065613, loss_ce: 0.025154
2022-01-21 21:12:08,422 iteration 1246 : loss : 0.055966, loss_ce: 0.025705
2022-01-21 21:12:09,766 iteration 1247 : loss : 0.092593, loss_ce: 0.033452
2022-01-21 21:12:10,919 iteration 1248 : loss : 0.088521, loss_ce: 0.033174
2022-01-21 21:12:12,093 iteration 1249 : loss : 0.065766, loss_ce: 0.027802
2022-01-21 21:12:13,286 iteration 1250 : loss : 0.087415, loss_ce: 0.025008
2022-01-21 21:12:14,534 iteration 1251 : loss : 0.051634, loss_ce: 0.022623
2022-01-21 21:12:15,665 iteration 1252 : loss : 0.100951, loss_ce: 0.031380
2022-01-21 21:12:16,840 iteration 1253 : loss : 0.065666, loss_ce: 0.028759
2022-01-21 21:12:18,025 iteration 1254 : loss : 0.044186, loss_ce: 0.015734
2022-01-21 21:12:19,317 iteration 1255 : loss : 0.074471, loss_ce: 0.032439
2022-01-21 21:12:20,496 iteration 1256 : loss : 0.048292, loss_ce: 0.016489
2022-01-21 21:12:21,592 iteration 1257 : loss : 0.047100, loss_ce: 0.016679
2022-01-21 21:12:22,687 iteration 1258 : loss : 0.051294, loss_ce: 0.024634
 18%|█████▌                        | 74/400 [27:12<1:53:58, 20.98s/it]2022-01-21 21:12:23,882 iteration 1259 : loss : 0.059662, loss_ce: 0.022879
2022-01-21 21:12:25,163 iteration 1260 : loss : 0.045502, loss_ce: 0.018523
2022-01-21 21:12:26,328 iteration 1261 : loss : 0.057048, loss_ce: 0.019200
2022-01-21 21:12:27,455 iteration 1262 : loss : 0.044502, loss_ce: 0.016081
2022-01-21 21:12:28,624 iteration 1263 : loss : 0.068782, loss_ce: 0.023456
2022-01-21 21:12:29,815 iteration 1264 : loss : 0.083228, loss_ce: 0.041961
2022-01-21 21:12:31,001 iteration 1265 : loss : 0.048906, loss_ce: 0.017474
2022-01-21 21:12:32,144 iteration 1266 : loss : 0.037837, loss_ce: 0.016814
2022-01-21 21:12:33,274 iteration 1267 : loss : 0.069362, loss_ce: 0.029875
2022-01-21 21:12:34,414 iteration 1268 : loss : 0.055297, loss_ce: 0.020204
2022-01-21 21:12:35,573 iteration 1269 : loss : 0.073250, loss_ce: 0.036497
2022-01-21 21:12:36,752 iteration 1270 : loss : 0.043008, loss_ce: 0.019340
2022-01-21 21:12:38,000 iteration 1271 : loss : 0.079946, loss_ce: 0.032983
2022-01-21 21:12:39,083 iteration 1272 : loss : 0.050570, loss_ce: 0.018694
2022-01-21 21:12:40,224 iteration 1273 : loss : 0.075989, loss_ce: 0.022927
2022-01-21 21:12:41,429 iteration 1274 : loss : 0.071402, loss_ce: 0.029821
2022-01-21 21:12:41,429 Training Data Eval:
2022-01-21 21:12:47,106   Average segmentation loss on training set: 0.0451
2022-01-21 21:12:47,107 Validation Data Eval:
2022-01-21 21:12:49,065   Average segmentation loss on validation set: 0.0810
2022-01-21 21:12:53,094 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 21:12:54,277 iteration 1275 : loss : 0.060278, loss_ce: 0.023990
 19%|█████▋                        | 75/400 [27:44<2:10:51, 24.16s/it]2022-01-21 21:12:55,466 iteration 1276 : loss : 0.050924, loss_ce: 0.022216
2022-01-21 21:12:56,749 iteration 1277 : loss : 0.091873, loss_ce: 0.033080
2022-01-21 21:12:57,931 iteration 1278 : loss : 0.078386, loss_ce: 0.038039
2022-01-21 21:12:59,097 iteration 1279 : loss : 0.054431, loss_ce: 0.017951
2022-01-21 21:13:00,296 iteration 1280 : loss : 0.044763, loss_ce: 0.019866
2022-01-21 21:13:01,436 iteration 1281 : loss : 0.058098, loss_ce: 0.023997
2022-01-21 21:13:02,611 iteration 1282 : loss : 0.042337, loss_ce: 0.018669
2022-01-21 21:13:03,713 iteration 1283 : loss : 0.084641, loss_ce: 0.025600
2022-01-21 21:13:04,873 iteration 1284 : loss : 0.054072, loss_ce: 0.020463
2022-01-21 21:13:05,987 iteration 1285 : loss : 0.055490, loss_ce: 0.018685
2022-01-21 21:13:07,215 iteration 1286 : loss : 0.063093, loss_ce: 0.021442
2022-01-21 21:13:08,435 iteration 1287 : loss : 0.047210, loss_ce: 0.019541
2022-01-21 21:13:09,571 iteration 1288 : loss : 0.059858, loss_ce: 0.023757
2022-01-21 21:13:10,745 iteration 1289 : loss : 0.087733, loss_ce: 0.029425
2022-01-21 21:13:11,878 iteration 1290 : loss : 0.077111, loss_ce: 0.026181
2022-01-21 21:13:13,009 iteration 1291 : loss : 0.057538, loss_ce: 0.021555
2022-01-21 21:13:14,138 iteration 1292 : loss : 0.065770, loss_ce: 0.037065
 19%|█████▋                        | 76/400 [28:04<2:03:29, 22.87s/it]2022-01-21 21:13:15,442 iteration 1293 : loss : 0.061356, loss_ce: 0.029446
2022-01-21 21:13:16,554 iteration 1294 : loss : 0.042008, loss_ce: 0.018140
2022-01-21 21:13:17,773 iteration 1295 : loss : 0.067874, loss_ce: 0.023167
2022-01-21 21:13:18,965 iteration 1296 : loss : 0.086153, loss_ce: 0.023878
2022-01-21 21:13:20,037 iteration 1297 : loss : 0.042441, loss_ce: 0.015647
2022-01-21 21:13:21,272 iteration 1298 : loss : 0.061185, loss_ce: 0.022761
2022-01-21 21:13:22,421 iteration 1299 : loss : 0.050158, loss_ce: 0.021038
2022-01-21 21:13:23,669 iteration 1300 : loss : 0.097639, loss_ce: 0.040445
2022-01-21 21:13:24,931 iteration 1301 : loss : 0.092026, loss_ce: 0.030902
2022-01-21 21:13:26,054 iteration 1302 : loss : 0.067467, loss_ce: 0.022854
2022-01-21 21:13:27,264 iteration 1303 : loss : 0.085700, loss_ce: 0.028418
2022-01-21 21:13:28,447 iteration 1304 : loss : 0.065512, loss_ce: 0.026202
2022-01-21 21:13:29,704 iteration 1305 : loss : 0.067139, loss_ce: 0.027049
2022-01-21 21:13:30,905 iteration 1306 : loss : 0.065142, loss_ce: 0.026512
2022-01-21 21:13:32,052 iteration 1307 : loss : 0.057511, loss_ce: 0.019828
2022-01-21 21:13:33,228 iteration 1308 : loss : 0.082998, loss_ce: 0.036995
2022-01-21 21:13:34,369 iteration 1309 : loss : 0.066192, loss_ce: 0.024691
 19%|█████▊                        | 77/400 [28:24<1:58:50, 22.08s/it]2022-01-21 21:13:35,572 iteration 1310 : loss : 0.063615, loss_ce: 0.023521
2022-01-21 21:13:36,847 iteration 1311 : loss : 0.083025, loss_ce: 0.031486
2022-01-21 21:13:38,034 iteration 1312 : loss : 0.069215, loss_ce: 0.023586
2022-01-21 21:13:39,204 iteration 1313 : loss : 0.053236, loss_ce: 0.021691
2022-01-21 21:13:40,444 iteration 1314 : loss : 0.069989, loss_ce: 0.032557
2022-01-21 21:13:41,692 iteration 1315 : loss : 0.052606, loss_ce: 0.027499
2022-01-21 21:13:42,848 iteration 1316 : loss : 0.066150, loss_ce: 0.027234
2022-01-21 21:13:43,975 iteration 1317 : loss : 0.052366, loss_ce: 0.021179
2022-01-21 21:13:45,098 iteration 1318 : loss : 0.056577, loss_ce: 0.021851
2022-01-21 21:13:46,294 iteration 1319 : loss : 0.077553, loss_ce: 0.025331
2022-01-21 21:13:47,407 iteration 1320 : loss : 0.056222, loss_ce: 0.019603
2022-01-21 21:13:48,584 iteration 1321 : loss : 0.066871, loss_ce: 0.031776
2022-01-21 21:13:49,735 iteration 1322 : loss : 0.056864, loss_ce: 0.019742
2022-01-21 21:13:50,968 iteration 1323 : loss : 0.060416, loss_ce: 0.019964
2022-01-21 21:13:52,225 iteration 1324 : loss : 0.051713, loss_ce: 0.022146
2022-01-21 21:13:53,399 iteration 1325 : loss : 0.057613, loss_ce: 0.026181
2022-01-21 21:13:54,582 iteration 1326 : loss : 0.066099, loss_ce: 0.023846
 20%|█████▊                        | 78/400 [28:44<1:55:28, 21.52s/it]2022-01-21 21:13:55,790 iteration 1327 : loss : 0.046851, loss_ce: 0.015832
2022-01-21 21:13:56,981 iteration 1328 : loss : 0.047738, loss_ce: 0.018150
2022-01-21 21:13:58,166 iteration 1329 : loss : 0.092508, loss_ce: 0.035141
2022-01-21 21:13:59,418 iteration 1330 : loss : 0.042808, loss_ce: 0.015630
2022-01-21 21:14:00,601 iteration 1331 : loss : 0.052706, loss_ce: 0.020428
2022-01-21 21:14:01,757 iteration 1332 : loss : 0.082006, loss_ce: 0.031538
2022-01-21 21:14:02,915 iteration 1333 : loss : 0.072360, loss_ce: 0.032412
2022-01-21 21:14:04,139 iteration 1334 : loss : 0.042203, loss_ce: 0.017276
2022-01-21 21:14:05,343 iteration 1335 : loss : 0.065325, loss_ce: 0.029146
2022-01-21 21:14:06,479 iteration 1336 : loss : 0.048048, loss_ce: 0.021711
2022-01-21 21:14:07,710 iteration 1337 : loss : 0.072174, loss_ce: 0.030933
2022-01-21 21:14:08,865 iteration 1338 : loss : 0.043566, loss_ce: 0.019302
2022-01-21 21:14:10,005 iteration 1339 : loss : 0.085592, loss_ce: 0.037246
2022-01-21 21:14:11,143 iteration 1340 : loss : 0.047064, loss_ce: 0.020076
2022-01-21 21:14:12,341 iteration 1341 : loss : 0.064529, loss_ce: 0.025486
2022-01-21 21:14:13,592 iteration 1342 : loss : 0.059659, loss_ce: 0.018836
2022-01-21 21:14:14,699 iteration 1343 : loss : 0.053985, loss_ce: 0.020196
 20%|█████▉                        | 79/400 [29:04<1:52:52, 21.10s/it]2022-01-21 21:14:15,953 iteration 1344 : loss : 0.042012, loss_ce: 0.014864
2022-01-21 21:14:17,099 iteration 1345 : loss : 0.045611, loss_ce: 0.011716
2022-01-21 21:14:18,321 iteration 1346 : loss : 0.056858, loss_ce: 0.020123
2022-01-21 21:14:19,501 iteration 1347 : loss : 0.050457, loss_ce: 0.022808
2022-01-21 21:14:20,646 iteration 1348 : loss : 0.072074, loss_ce: 0.030948
2022-01-21 21:14:21,828 iteration 1349 : loss : 0.077027, loss_ce: 0.028917
2022-01-21 21:14:22,992 iteration 1350 : loss : 0.077310, loss_ce: 0.026476
2022-01-21 21:14:24,252 iteration 1351 : loss : 0.095482, loss_ce: 0.045265
2022-01-21 21:14:25,386 iteration 1352 : loss : 0.054119, loss_ce: 0.023395
2022-01-21 21:14:26,568 iteration 1353 : loss : 0.061865, loss_ce: 0.024525
2022-01-21 21:14:27,750 iteration 1354 : loss : 0.063028, loss_ce: 0.024224
2022-01-21 21:14:28,867 iteration 1355 : loss : 0.055457, loss_ce: 0.019406
2022-01-21 21:14:30,110 iteration 1356 : loss : 0.074519, loss_ce: 0.027775
2022-01-21 21:14:31,233 iteration 1357 : loss : 0.047066, loss_ce: 0.023518
2022-01-21 21:14:32,386 iteration 1358 : loss : 0.061660, loss_ce: 0.026491
2022-01-21 21:14:33,642 iteration 1359 : loss : 0.059849, loss_ce: 0.030896
2022-01-21 21:14:33,643 Training Data Eval:
2022-01-21 21:14:39,316   Average segmentation loss on training set: 0.0778
2022-01-21 21:14:39,316 Validation Data Eval:
2022-01-21 21:14:41,284   Average segmentation loss on validation set: 0.1171
2022-01-21 21:14:42,471 iteration 1360 : loss : 0.058885, loss_ce: 0.023230
 20%|██████                        | 80/400 [29:32<2:03:11, 23.10s/it]2022-01-21 21:14:43,757 iteration 1361 : loss : 0.091673, loss_ce: 0.030943
2022-01-21 21:14:44,917 iteration 1362 : loss : 0.075712, loss_ce: 0.025012
2022-01-21 21:14:46,109 iteration 1363 : loss : 0.044779, loss_ce: 0.018398
2022-01-21 21:14:47,219 iteration 1364 : loss : 0.066581, loss_ce: 0.033552
2022-01-21 21:14:48,355 iteration 1365 : loss : 0.060850, loss_ce: 0.019641
2022-01-21 21:14:49,610 iteration 1366 : loss : 0.095380, loss_ce: 0.033137
2022-01-21 21:14:50,807 iteration 1367 : loss : 0.061880, loss_ce: 0.037236
2022-01-21 21:14:52,155 iteration 1368 : loss : 0.060973, loss_ce: 0.025211
2022-01-21 21:14:53,330 iteration 1369 : loss : 0.049586, loss_ce: 0.017224
2022-01-21 21:14:54,474 iteration 1370 : loss : 0.053848, loss_ce: 0.021824
2022-01-21 21:14:55,647 iteration 1371 : loss : 0.057089, loss_ce: 0.021893
2022-01-21 21:14:56,963 iteration 1372 : loss : 0.071741, loss_ce: 0.028735
2022-01-21 21:14:58,131 iteration 1373 : loss : 0.056294, loss_ce: 0.025608
2022-01-21 21:14:59,279 iteration 1374 : loss : 0.059087, loss_ce: 0.021619
2022-01-21 21:15:00,437 iteration 1375 : loss : 0.049780, loss_ce: 0.020594
2022-01-21 21:15:01,609 iteration 1376 : loss : 0.043778, loss_ce: 0.014150
2022-01-21 21:15:02,854 iteration 1377 : loss : 0.050069, loss_ce: 0.027355
 20%|██████                        | 81/400 [29:52<1:58:29, 22.29s/it]2022-01-21 21:15:04,170 iteration 1378 : loss : 0.071942, loss_ce: 0.039103
2022-01-21 21:15:05,405 iteration 1379 : loss : 0.065274, loss_ce: 0.028979
2022-01-21 21:15:06,594 iteration 1380 : loss : 0.093199, loss_ce: 0.032205
2022-01-21 21:15:07,824 iteration 1381 : loss : 0.071926, loss_ce: 0.028229
2022-01-21 21:15:09,033 iteration 1382 : loss : 0.068664, loss_ce: 0.026907
2022-01-21 21:15:10,165 iteration 1383 : loss : 0.088661, loss_ce: 0.025996
2022-01-21 21:15:11,381 iteration 1384 : loss : 0.061480, loss_ce: 0.026432
2022-01-21 21:15:12,585 iteration 1385 : loss : 0.049659, loss_ce: 0.019621
2022-01-21 21:15:13,759 iteration 1386 : loss : 0.068379, loss_ce: 0.027354
2022-01-21 21:15:15,048 iteration 1387 : loss : 0.066733, loss_ce: 0.024789
2022-01-21 21:15:16,225 iteration 1388 : loss : 0.052613, loss_ce: 0.019899
2022-01-21 21:15:17,397 iteration 1389 : loss : 0.046243, loss_ce: 0.018336
2022-01-21 21:15:18,615 iteration 1390 : loss : 0.053342, loss_ce: 0.019846
2022-01-21 21:15:19,808 iteration 1391 : loss : 0.063042, loss_ce: 0.017674
2022-01-21 21:15:21,007 iteration 1392 : loss : 0.071858, loss_ce: 0.021038
2022-01-21 21:15:22,176 iteration 1393 : loss : 0.046951, loss_ce: 0.016119
2022-01-21 21:15:23,348 iteration 1394 : loss : 0.043575, loss_ce: 0.021256
 20%|██████▏                       | 82/400 [30:13<1:55:16, 21.75s/it]2022-01-21 21:15:24,573 iteration 1395 : loss : 0.050832, loss_ce: 0.019909
2022-01-21 21:15:25,729 iteration 1396 : loss : 0.052522, loss_ce: 0.021519
2022-01-21 21:15:26,925 iteration 1397 : loss : 0.078347, loss_ce: 0.024619
2022-01-21 21:15:28,196 iteration 1398 : loss : 0.042181, loss_ce: 0.018633
2022-01-21 21:15:29,410 iteration 1399 : loss : 0.071271, loss_ce: 0.031789
2022-01-21 21:15:30,573 iteration 1400 : loss : 0.076722, loss_ce: 0.040747
2022-01-21 21:15:31,735 iteration 1401 : loss : 0.060476, loss_ce: 0.020747
2022-01-21 21:15:32,849 iteration 1402 : loss : 0.042472, loss_ce: 0.016403
2022-01-21 21:15:34,123 iteration 1403 : loss : 0.060623, loss_ce: 0.022735
2022-01-21 21:15:35,358 iteration 1404 : loss : 0.054087, loss_ce: 0.018897
2022-01-21 21:15:36,576 iteration 1405 : loss : 0.056956, loss_ce: 0.028207
2022-01-21 21:15:37,774 iteration 1406 : loss : 0.054218, loss_ce: 0.018121
2022-01-21 21:15:38,912 iteration 1407 : loss : 0.054364, loss_ce: 0.030710
2022-01-21 21:15:40,068 iteration 1408 : loss : 0.081142, loss_ce: 0.027554
2022-01-21 21:15:41,335 iteration 1409 : loss : 0.065245, loss_ce: 0.022540
2022-01-21 21:15:42,548 iteration 1410 : loss : 0.079014, loss_ce: 0.028872
2022-01-21 21:15:43,711 iteration 1411 : loss : 0.052179, loss_ce: 0.020492
 21%|██████▏                       | 83/400 [30:33<1:52:41, 21.33s/it]2022-01-21 21:15:44,854 iteration 1412 : loss : 0.078310, loss_ce: 0.028776
2022-01-21 21:15:46,077 iteration 1413 : loss : 0.048332, loss_ce: 0.018611
2022-01-21 21:15:47,260 iteration 1414 : loss : 0.046620, loss_ce: 0.021273
2022-01-21 21:15:48,383 iteration 1415 : loss : 0.056845, loss_ce: 0.018924
2022-01-21 21:15:49,570 iteration 1416 : loss : 0.044646, loss_ce: 0.013674
2022-01-21 21:15:50,792 iteration 1417 : loss : 0.053227, loss_ce: 0.019611
2022-01-21 21:15:51,912 iteration 1418 : loss : 0.043837, loss_ce: 0.011916
2022-01-21 21:15:53,209 iteration 1419 : loss : 0.053285, loss_ce: 0.018119
2022-01-21 21:15:54,447 iteration 1420 : loss : 0.066399, loss_ce: 0.019581
2022-01-21 21:15:55,599 iteration 1421 : loss : 0.055887, loss_ce: 0.027806
2022-01-21 21:15:56,778 iteration 1422 : loss : 0.105516, loss_ce: 0.047907
2022-01-21 21:15:57,927 iteration 1423 : loss : 0.071983, loss_ce: 0.030508
2022-01-21 21:15:59,146 iteration 1424 : loss : 0.055470, loss_ce: 0.019317
2022-01-21 21:16:00,405 iteration 1425 : loss : 0.076651, loss_ce: 0.029435
2022-01-21 21:16:01,473 iteration 1426 : loss : 0.049971, loss_ce: 0.020207
2022-01-21 21:16:02,633 iteration 1427 : loss : 0.051635, loss_ce: 0.021345
2022-01-21 21:16:03,816 iteration 1428 : loss : 0.066903, loss_ce: 0.027892
 21%|██████▎                       | 84/400 [30:53<1:50:24, 20.96s/it]2022-01-21 21:16:05,135 iteration 1429 : loss : 0.068975, loss_ce: 0.028310
2022-01-21 21:16:06,276 iteration 1430 : loss : 0.081885, loss_ce: 0.030234
2022-01-21 21:16:07,450 iteration 1431 : loss : 0.064728, loss_ce: 0.029811
2022-01-21 21:16:08,644 iteration 1432 : loss : 0.056400, loss_ce: 0.024384
2022-01-21 21:16:09,915 iteration 1433 : loss : 0.088747, loss_ce: 0.042246
2022-01-21 21:16:11,153 iteration 1434 : loss : 0.066145, loss_ce: 0.027787
2022-01-21 21:16:12,250 iteration 1435 : loss : 0.060464, loss_ce: 0.017646
2022-01-21 21:16:13,493 iteration 1436 : loss : 0.051688, loss_ce: 0.021558
2022-01-21 21:16:14,615 iteration 1437 : loss : 0.090877, loss_ce: 0.021497
2022-01-21 21:16:15,708 iteration 1438 : loss : 0.050241, loss_ce: 0.022415
2022-01-21 21:16:16,884 iteration 1439 : loss : 0.047152, loss_ce: 0.013950
2022-01-21 21:16:18,131 iteration 1440 : loss : 0.069942, loss_ce: 0.032962
2022-01-21 21:16:19,287 iteration 1441 : loss : 0.046594, loss_ce: 0.019944
2022-01-21 21:16:20,420 iteration 1442 : loss : 0.050651, loss_ce: 0.021674
2022-01-21 21:16:21,621 iteration 1443 : loss : 0.092413, loss_ce: 0.037663
2022-01-21 21:16:22,862 iteration 1444 : loss : 0.057670, loss_ce: 0.021674
2022-01-21 21:16:22,862 Training Data Eval:
2022-01-21 21:16:28,534   Average segmentation loss on training set: 0.0730
2022-01-21 21:16:28,534 Validation Data Eval:
2022-01-21 21:16:30,504   Average segmentation loss on validation set: 0.0881
2022-01-21 21:16:31,713 iteration 1445 : loss : 0.054111, loss_ce: 0.016680
 21%|██████▍                       | 85/400 [31:21<2:00:58, 23.04s/it]2022-01-21 21:16:32,989 iteration 1446 : loss : 0.067297, loss_ce: 0.024625
2022-01-21 21:16:34,214 iteration 1447 : loss : 0.083041, loss_ce: 0.034259
2022-01-21 21:16:35,381 iteration 1448 : loss : 0.045845, loss_ce: 0.023688
2022-01-21 21:16:36,570 iteration 1449 : loss : 0.086535, loss_ce: 0.032000
2022-01-21 21:16:37,671 iteration 1450 : loss : 0.079238, loss_ce: 0.032888
2022-01-21 21:16:38,799 iteration 1451 : loss : 0.051515, loss_ce: 0.019760
2022-01-21 21:16:39,985 iteration 1452 : loss : 0.093263, loss_ce: 0.020939
2022-01-21 21:16:41,222 iteration 1453 : loss : 0.051757, loss_ce: 0.015805
2022-01-21 21:16:42,368 iteration 1454 : loss : 0.049730, loss_ce: 0.020831
2022-01-21 21:16:43,524 iteration 1455 : loss : 0.052469, loss_ce: 0.020845
2022-01-21 21:16:44,711 iteration 1456 : loss : 0.063124, loss_ce: 0.021569
2022-01-21 21:16:45,903 iteration 1457 : loss : 0.047020, loss_ce: 0.020592
2022-01-21 21:16:47,076 iteration 1458 : loss : 0.055244, loss_ce: 0.020449
2022-01-21 21:16:48,172 iteration 1459 : loss : 0.046706, loss_ce: 0.019578
2022-01-21 21:16:49,397 iteration 1460 : loss : 0.111916, loss_ce: 0.053385
2022-01-21 21:16:50,567 iteration 1461 : loss : 0.069075, loss_ce: 0.021300
2022-01-21 21:16:51,746 iteration 1462 : loss : 0.045465, loss_ce: 0.018511
 22%|██████▍                       | 86/400 [31:41<1:55:52, 22.14s/it]2022-01-21 21:16:52,951 iteration 1463 : loss : 0.047959, loss_ce: 0.020092
2022-01-21 21:16:54,174 iteration 1464 : loss : 0.072967, loss_ce: 0.022771
2022-01-21 21:16:55,414 iteration 1465 : loss : 0.058736, loss_ce: 0.026921
2022-01-21 21:16:56,600 iteration 1466 : loss : 0.060659, loss_ce: 0.017187
2022-01-21 21:16:57,769 iteration 1467 : loss : 0.061585, loss_ce: 0.024258
2022-01-21 21:16:58,971 iteration 1468 : loss : 0.073876, loss_ce: 0.025248
2022-01-21 21:17:00,181 iteration 1469 : loss : 0.052583, loss_ce: 0.029207
2022-01-21 21:17:01,368 iteration 1470 : loss : 0.044541, loss_ce: 0.016938
2022-01-21 21:17:02,485 iteration 1471 : loss : 0.057007, loss_ce: 0.018836
2022-01-21 21:17:03,654 iteration 1472 : loss : 0.053531, loss_ce: 0.019505
2022-01-21 21:17:04,893 iteration 1473 : loss : 0.045364, loss_ce: 0.021791
2022-01-21 21:17:06,023 iteration 1474 : loss : 0.053910, loss_ce: 0.022859
2022-01-21 21:17:07,192 iteration 1475 : loss : 0.068710, loss_ce: 0.024594
2022-01-21 21:17:08,419 iteration 1476 : loss : 0.071814, loss_ce: 0.035771
2022-01-21 21:17:09,598 iteration 1477 : loss : 0.052935, loss_ce: 0.017958
2022-01-21 21:17:10,833 iteration 1478 : loss : 0.050856, loss_ce: 0.018893
2022-01-21 21:17:12,035 iteration 1479 : loss : 0.069529, loss_ce: 0.024745
 22%|██████▌                       | 87/400 [32:01<1:52:36, 21.58s/it]2022-01-21 21:17:13,255 iteration 1480 : loss : 0.057371, loss_ce: 0.029430
2022-01-21 21:17:14,504 iteration 1481 : loss : 0.037358, loss_ce: 0.017051
2022-01-21 21:17:15,665 iteration 1482 : loss : 0.057664, loss_ce: 0.023031
2022-01-21 21:17:16,784 iteration 1483 : loss : 0.053976, loss_ce: 0.024701
2022-01-21 21:17:17,914 iteration 1484 : loss : 0.054484, loss_ce: 0.023626
2022-01-21 21:17:19,057 iteration 1485 : loss : 0.061972, loss_ce: 0.025543
2022-01-21 21:17:20,210 iteration 1486 : loss : 0.068169, loss_ce: 0.022334
2022-01-21 21:17:21,454 iteration 1487 : loss : 0.079606, loss_ce: 0.041630
2022-01-21 21:17:22,617 iteration 1488 : loss : 0.046124, loss_ce: 0.018577
2022-01-21 21:17:23,816 iteration 1489 : loss : 0.045272, loss_ce: 0.016765
2022-01-21 21:17:24,992 iteration 1490 : loss : 0.037507, loss_ce: 0.016902
2022-01-21 21:17:26,120 iteration 1491 : loss : 0.049323, loss_ce: 0.017566
2022-01-21 21:17:27,324 iteration 1492 : loss : 0.077579, loss_ce: 0.030816
2022-01-21 21:17:28,609 iteration 1493 : loss : 0.067410, loss_ce: 0.031780
2022-01-21 21:17:29,826 iteration 1494 : loss : 0.062596, loss_ce: 0.021718
2022-01-21 21:17:31,009 iteration 1495 : loss : 0.073823, loss_ce: 0.024991
2022-01-21 21:17:32,191 iteration 1496 : loss : 0.060725, loss_ce: 0.026402
 22%|██████▌                       | 88/400 [32:22<1:50:01, 21.16s/it]2022-01-21 21:17:33,387 iteration 1497 : loss : 0.044065, loss_ce: 0.017215
2022-01-21 21:17:34,468 iteration 1498 : loss : 0.041998, loss_ce: 0.016910
2022-01-21 21:17:35,589 iteration 1499 : loss : 0.051244, loss_ce: 0.022043
2022-01-21 21:17:36,891 iteration 1500 : loss : 0.092914, loss_ce: 0.033524
2022-01-21 21:17:38,001 iteration 1501 : loss : 0.046587, loss_ce: 0.015345
2022-01-21 21:17:39,188 iteration 1502 : loss : 0.070293, loss_ce: 0.027819
2022-01-21 21:17:40,439 iteration 1503 : loss : 0.063198, loss_ce: 0.019540
2022-01-21 21:17:41,590 iteration 1504 : loss : 0.072299, loss_ce: 0.027477
2022-01-21 21:17:42,720 iteration 1505 : loss : 0.053154, loss_ce: 0.018900
2022-01-21 21:17:43,949 iteration 1506 : loss : 0.070001, loss_ce: 0.021270
2022-01-21 21:17:45,100 iteration 1507 : loss : 0.043437, loss_ce: 0.019526
2022-01-21 21:17:46,290 iteration 1508 : loss : 0.126884, loss_ce: 0.026028
2022-01-21 21:17:47,456 iteration 1509 : loss : 0.061744, loss_ce: 0.027237
2022-01-21 21:17:48,605 iteration 1510 : loss : 0.068870, loss_ce: 0.021893
2022-01-21 21:17:49,875 iteration 1511 : loss : 0.072228, loss_ce: 0.038198
2022-01-21 21:17:51,059 iteration 1512 : loss : 0.051309, loss_ce: 0.018755
2022-01-21 21:17:52,249 iteration 1513 : loss : 0.081253, loss_ce: 0.033513
 22%|██████▋                       | 89/400 [32:42<1:47:56, 20.83s/it]2022-01-21 21:17:53,489 iteration 1514 : loss : 0.055903, loss_ce: 0.020692
2022-01-21 21:17:54,674 iteration 1515 : loss : 0.038848, loss_ce: 0.017298
2022-01-21 21:17:55,888 iteration 1516 : loss : 0.053126, loss_ce: 0.029253
2022-01-21 21:17:57,044 iteration 1517 : loss : 0.079954, loss_ce: 0.040789
2022-01-21 21:17:58,163 iteration 1518 : loss : 0.050006, loss_ce: 0.023019
2022-01-21 21:17:59,321 iteration 1519 : loss : 0.044006, loss_ce: 0.017257
2022-01-21 21:18:00,640 iteration 1520 : loss : 0.057535, loss_ce: 0.024292
2022-01-21 21:18:01,779 iteration 1521 : loss : 0.048144, loss_ce: 0.016890
2022-01-21 21:18:03,012 iteration 1522 : loss : 0.038954, loss_ce: 0.013180
2022-01-21 21:18:04,200 iteration 1523 : loss : 0.062153, loss_ce: 0.023814
2022-01-21 21:18:05,328 iteration 1524 : loss : 0.042541, loss_ce: 0.014675
2022-01-21 21:18:06,494 iteration 1525 : loss : 0.050651, loss_ce: 0.022638
2022-01-21 21:18:07,653 iteration 1526 : loss : 0.084302, loss_ce: 0.031103
2022-01-21 21:18:08,901 iteration 1527 : loss : 0.046422, loss_ce: 0.018713
2022-01-21 21:18:10,116 iteration 1528 : loss : 0.055628, loss_ce: 0.019996
2022-01-21 21:18:11,285 iteration 1529 : loss : 0.060594, loss_ce: 0.019942
2022-01-21 21:18:11,285 Training Data Eval:
2022-01-21 21:18:16,963   Average segmentation loss on training set: 0.0461
2022-01-21 21:18:16,964 Validation Data Eval:
2022-01-21 21:18:18,927   Average segmentation loss on validation set: 0.0898
2022-01-21 21:18:20,071 iteration 1530 : loss : 0.047012, loss_ce: 0.020127
 22%|██████▊                       | 90/400 [33:09<1:58:27, 22.93s/it]2022-01-21 21:18:21,324 iteration 1531 : loss : 0.054898, loss_ce: 0.023214
2022-01-21 21:18:22,538 iteration 1532 : loss : 0.079607, loss_ce: 0.030410
2022-01-21 21:18:23,684 iteration 1533 : loss : 0.053051, loss_ce: 0.019629
2022-01-21 21:18:24,845 iteration 1534 : loss : 0.042362, loss_ce: 0.026173
2022-01-21 21:18:25,979 iteration 1535 : loss : 0.069181, loss_ce: 0.029711
2022-01-21 21:18:27,182 iteration 1536 : loss : 0.045316, loss_ce: 0.014523
2022-01-21 21:18:28,330 iteration 1537 : loss : 0.053510, loss_ce: 0.024420
2022-01-21 21:18:29,402 iteration 1538 : loss : 0.071024, loss_ce: 0.018472
2022-01-21 21:18:30,526 iteration 1539 : loss : 0.057532, loss_ce: 0.024758
2022-01-21 21:18:31,709 iteration 1540 : loss : 0.076773, loss_ce: 0.036674
2022-01-21 21:18:32,934 iteration 1541 : loss : 0.051288, loss_ce: 0.020492
2022-01-21 21:18:34,212 iteration 1542 : loss : 0.055701, loss_ce: 0.022016
2022-01-21 21:18:35,403 iteration 1543 : loss : 0.074972, loss_ce: 0.017647
2022-01-21 21:18:36,596 iteration 1544 : loss : 0.041359, loss_ce: 0.017001
2022-01-21 21:18:37,713 iteration 1545 : loss : 0.046985, loss_ce: 0.018738
2022-01-21 21:18:38,873 iteration 1546 : loss : 0.064646, loss_ce: 0.020617
2022-01-21 21:18:40,070 iteration 1547 : loss : 0.046421, loss_ce: 0.019741
 23%|██████▊                       | 91/400 [33:29<1:53:32, 22.05s/it]2022-01-21 21:18:41,270 iteration 1548 : loss : 0.060114, loss_ce: 0.021511
2022-01-21 21:18:42,392 iteration 1549 : loss : 0.102009, loss_ce: 0.031328
2022-01-21 21:18:43,603 iteration 1550 : loss : 0.064398, loss_ce: 0.022712
2022-01-21 21:18:44,798 iteration 1551 : loss : 0.083017, loss_ce: 0.027532
2022-01-21 21:18:45,961 iteration 1552 : loss : 0.045796, loss_ce: 0.014860
2022-01-21 21:18:47,176 iteration 1553 : loss : 0.071640, loss_ce: 0.031230
2022-01-21 21:18:48,272 iteration 1554 : loss : 0.065446, loss_ce: 0.029963
2022-01-21 21:18:49,411 iteration 1555 : loss : 0.050965, loss_ce: 0.016194
2022-01-21 21:18:50,678 iteration 1556 : loss : 0.089508, loss_ce: 0.033676
2022-01-21 21:18:51,846 iteration 1557 : loss : 0.056444, loss_ce: 0.017468
2022-01-21 21:18:52,994 iteration 1558 : loss : 0.065967, loss_ce: 0.021476
2022-01-21 21:18:54,250 iteration 1559 : loss : 0.079660, loss_ce: 0.029331
2022-01-21 21:18:55,396 iteration 1560 : loss : 0.049924, loss_ce: 0.026114
2022-01-21 21:18:56,576 iteration 1561 : loss : 0.061083, loss_ce: 0.026884
2022-01-21 21:18:57,749 iteration 1562 : loss : 0.061986, loss_ce: 0.032785
2022-01-21 21:18:58,948 iteration 1563 : loss : 0.065506, loss_ce: 0.023900
2022-01-21 21:19:00,105 iteration 1564 : loss : 0.064306, loss_ce: 0.021583
 23%|██████▉                       | 92/400 [33:50<1:50:06, 21.45s/it]2022-01-21 21:19:01,301 iteration 1565 : loss : 0.047444, loss_ce: 0.025598
2022-01-21 21:19:02,513 iteration 1566 : loss : 0.085886, loss_ce: 0.026437
2022-01-21 21:19:03,699 iteration 1567 : loss : 0.067232, loss_ce: 0.029365
2022-01-21 21:19:04,979 iteration 1568 : loss : 0.061193, loss_ce: 0.020931
2022-01-21 21:19:06,157 iteration 1569 : loss : 0.062788, loss_ce: 0.029721
2022-01-21 21:19:07,351 iteration 1570 : loss : 0.046600, loss_ce: 0.016840
2022-01-21 21:19:08,536 iteration 1571 : loss : 0.064115, loss_ce: 0.019086
2022-01-21 21:19:09,804 iteration 1572 : loss : 0.091058, loss_ce: 0.035210
2022-01-21 21:19:10,905 iteration 1573 : loss : 0.048596, loss_ce: 0.024633
2022-01-21 21:19:12,112 iteration 1574 : loss : 0.077878, loss_ce: 0.030950
2022-01-21 21:19:13,364 iteration 1575 : loss : 0.066696, loss_ce: 0.027534
2022-01-21 21:19:14,611 iteration 1576 : loss : 0.039799, loss_ce: 0.016626
2022-01-21 21:19:15,719 iteration 1577 : loss : 0.042101, loss_ce: 0.015155
2022-01-21 21:19:16,876 iteration 1578 : loss : 0.038765, loss_ce: 0.013572
2022-01-21 21:19:18,114 iteration 1579 : loss : 0.073727, loss_ce: 0.024989
2022-01-21 21:19:19,327 iteration 1580 : loss : 0.075970, loss_ce: 0.025393
2022-01-21 21:19:20,631 iteration 1581 : loss : 0.044420, loss_ce: 0.019431
 23%|██████▉                       | 93/400 [34:10<1:48:20, 21.17s/it]2022-01-21 21:19:21,896 iteration 1582 : loss : 0.035978, loss_ce: 0.013600
2022-01-21 21:19:23,099 iteration 1583 : loss : 0.052513, loss_ce: 0.020755
2022-01-21 21:19:24,207 iteration 1584 : loss : 0.063143, loss_ce: 0.020555
2022-01-21 21:19:25,391 iteration 1585 : loss : 0.139394, loss_ce: 0.037390
2022-01-21 21:19:26,639 iteration 1586 : loss : 0.062737, loss_ce: 0.018922
2022-01-21 21:19:27,822 iteration 1587 : loss : 0.057757, loss_ce: 0.017047
2022-01-21 21:19:29,062 iteration 1588 : loss : 0.055914, loss_ce: 0.026497
2022-01-21 21:19:30,241 iteration 1589 : loss : 0.064826, loss_ce: 0.018565
2022-01-21 21:19:31,442 iteration 1590 : loss : 0.057185, loss_ce: 0.027381
2022-01-21 21:19:32,584 iteration 1591 : loss : 0.087214, loss_ce: 0.045964
2022-01-21 21:19:33,730 iteration 1592 : loss : 0.074950, loss_ce: 0.033901
2022-01-21 21:19:34,977 iteration 1593 : loss : 0.053345, loss_ce: 0.014012
2022-01-21 21:19:36,178 iteration 1594 : loss : 0.051297, loss_ce: 0.027358
2022-01-21 21:19:37,376 iteration 1595 : loss : 0.073132, loss_ce: 0.033113
2022-01-21 21:19:38,556 iteration 1596 : loss : 0.047711, loss_ce: 0.020176
2022-01-21 21:19:39,705 iteration 1597 : loss : 0.065685, loss_ce: 0.019788
2022-01-21 21:19:40,921 iteration 1598 : loss : 0.054771, loss_ce: 0.024202
 24%|███████                       | 94/400 [34:30<1:46:37, 20.91s/it]2022-01-21 21:19:42,190 iteration 1599 : loss : 0.049193, loss_ce: 0.023308
2022-01-21 21:19:43,342 iteration 1600 : loss : 0.054035, loss_ce: 0.022701
2022-01-21 21:19:44,516 iteration 1601 : loss : 0.084836, loss_ce: 0.032793
2022-01-21 21:19:45,674 iteration 1602 : loss : 0.069651, loss_ce: 0.038153
2022-01-21 21:19:46,922 iteration 1603 : loss : 0.069543, loss_ce: 0.030028
2022-01-21 21:19:48,083 iteration 1604 : loss : 0.090078, loss_ce: 0.042248
2022-01-21 21:19:49,340 iteration 1605 : loss : 0.051522, loss_ce: 0.018711
2022-01-21 21:19:50,565 iteration 1606 : loss : 0.052763, loss_ce: 0.014360
2022-01-21 21:19:51,748 iteration 1607 : loss : 0.061857, loss_ce: 0.024132
2022-01-21 21:19:52,952 iteration 1608 : loss : 0.045350, loss_ce: 0.016208
2022-01-21 21:19:54,160 iteration 1609 : loss : 0.051956, loss_ce: 0.019102
2022-01-21 21:19:55,333 iteration 1610 : loss : 0.067359, loss_ce: 0.028802
2022-01-21 21:19:56,532 iteration 1611 : loss : 0.067908, loss_ce: 0.023645
2022-01-21 21:19:57,717 iteration 1612 : loss : 0.063111, loss_ce: 0.028939
2022-01-21 21:19:58,914 iteration 1613 : loss : 0.068610, loss_ce: 0.025514
2022-01-21 21:20:00,116 iteration 1614 : loss : 0.054784, loss_ce: 0.017698
2022-01-21 21:20:00,116 Training Data Eval:
2022-01-21 21:20:05,800   Average segmentation loss on training set: 0.0490
2022-01-21 21:20:05,800 Validation Data Eval:
2022-01-21 21:20:07,768   Average segmentation loss on validation set: 0.0938
2022-01-21 21:20:08,981 iteration 1615 : loss : 0.074496, loss_ce: 0.033879
 24%|███████▏                      | 95/400 [34:58<1:57:11, 23.05s/it]2022-01-21 21:20:10,194 iteration 1616 : loss : 0.055776, loss_ce: 0.017257
2022-01-21 21:20:11,318 iteration 1617 : loss : 0.034706, loss_ce: 0.015093
2022-01-21 21:20:12,495 iteration 1618 : loss : 0.029069, loss_ce: 0.011650
2022-01-21 21:20:13,727 iteration 1619 : loss : 0.037698, loss_ce: 0.018554
2022-01-21 21:20:14,844 iteration 1620 : loss : 0.045492, loss_ce: 0.017404
2022-01-21 21:20:16,060 iteration 1621 : loss : 0.051531, loss_ce: 0.020589
2022-01-21 21:20:17,214 iteration 1622 : loss : 0.059844, loss_ce: 0.020229
2022-01-21 21:20:18,325 iteration 1623 : loss : 0.049778, loss_ce: 0.024657
2022-01-21 21:20:19,513 iteration 1624 : loss : 0.069671, loss_ce: 0.027211
2022-01-21 21:20:20,616 iteration 1625 : loss : 0.039019, loss_ce: 0.020170
2022-01-21 21:20:21,759 iteration 1626 : loss : 0.050050, loss_ce: 0.020607
2022-01-21 21:20:22,885 iteration 1627 : loss : 0.061121, loss_ce: 0.019863
2022-01-21 21:20:24,089 iteration 1628 : loss : 0.062757, loss_ce: 0.018605
2022-01-21 21:20:25,285 iteration 1629 : loss : 0.063751, loss_ce: 0.030749
2022-01-21 21:20:26,425 iteration 1630 : loss : 0.038902, loss_ce: 0.015018
2022-01-21 21:20:27,601 iteration 1631 : loss : 0.044065, loss_ce: 0.019319
2022-01-21 21:20:28,679 iteration 1632 : loss : 0.041887, loss_ce: 0.017952
 24%|███████▏                      | 96/400 [35:18<1:51:42, 22.05s/it]2022-01-21 21:20:29,970 iteration 1633 : loss : 0.066991, loss_ce: 0.026258
2022-01-21 21:20:31,174 iteration 1634 : loss : 0.045321, loss_ce: 0.020346
2022-01-21 21:20:32,335 iteration 1635 : loss : 0.051046, loss_ce: 0.022268
2022-01-21 21:20:33,415 iteration 1636 : loss : 0.044871, loss_ce: 0.015686
2022-01-21 21:20:34,634 iteration 1637 : loss : 0.041874, loss_ce: 0.015080
2022-01-21 21:20:35,827 iteration 1638 : loss : 0.045538, loss_ce: 0.017520
2022-01-21 21:20:37,069 iteration 1639 : loss : 0.058262, loss_ce: 0.021539
2022-01-21 21:20:38,243 iteration 1640 : loss : 0.063790, loss_ce: 0.025757
2022-01-21 21:20:39,454 iteration 1641 : loss : 0.051708, loss_ce: 0.021210
2022-01-21 21:20:40,730 iteration 1642 : loss : 0.083860, loss_ce: 0.028773
2022-01-21 21:20:41,941 iteration 1643 : loss : 0.032559, loss_ce: 0.013238
2022-01-21 21:20:43,133 iteration 1644 : loss : 0.092648, loss_ce: 0.041520
2022-01-21 21:20:44,225 iteration 1645 : loss : 0.048038, loss_ce: 0.016509
2022-01-21 21:20:45,388 iteration 1646 : loss : 0.045975, loss_ce: 0.018629
2022-01-21 21:20:46,642 iteration 1647 : loss : 0.053571, loss_ce: 0.026903
2022-01-21 21:20:47,808 iteration 1648 : loss : 0.055903, loss_ce: 0.026518
2022-01-21 21:20:49,075 iteration 1649 : loss : 0.078099, loss_ce: 0.022076
 24%|███████▎                      | 97/400 [35:39<1:48:49, 21.55s/it]2022-01-21 21:20:50,323 iteration 1650 : loss : 0.046414, loss_ce: 0.013377
2022-01-21 21:20:51,571 iteration 1651 : loss : 0.064396, loss_ce: 0.027334
2022-01-21 21:20:52,817 iteration 1652 : loss : 0.091118, loss_ce: 0.027263
2022-01-21 21:20:54,041 iteration 1653 : loss : 0.050667, loss_ce: 0.023763
2022-01-21 21:20:55,218 iteration 1654 : loss : 0.048502, loss_ce: 0.016029
2022-01-21 21:20:56,380 iteration 1655 : loss : 0.072868, loss_ce: 0.021145
2022-01-21 21:20:57,539 iteration 1656 : loss : 0.041312, loss_ce: 0.018397
2022-01-21 21:20:58,787 iteration 1657 : loss : 0.059460, loss_ce: 0.023959
2022-01-21 21:20:59,923 iteration 1658 : loss : 0.045448, loss_ce: 0.019494
2022-01-21 21:21:01,107 iteration 1659 : loss : 0.058128, loss_ce: 0.024328
2022-01-21 21:21:02,405 iteration 1660 : loss : 0.082063, loss_ce: 0.038339
2022-01-21 21:21:03,593 iteration 1661 : loss : 0.064334, loss_ce: 0.023674
2022-01-21 21:21:04,761 iteration 1662 : loss : 0.053738, loss_ce: 0.020653
2022-01-21 21:21:06,004 iteration 1663 : loss : 0.064690, loss_ce: 0.027939
2022-01-21 21:21:07,241 iteration 1664 : loss : 0.078022, loss_ce: 0.033397
2022-01-21 21:21:08,388 iteration 1665 : loss : 0.032382, loss_ce: 0.012735
2022-01-21 21:21:09,531 iteration 1666 : loss : 0.037159, loss_ce: 0.015088
 24%|███████▎                      | 98/400 [35:59<1:46:49, 21.22s/it]2022-01-21 21:21:10,769 iteration 1667 : loss : 0.061521, loss_ce: 0.035569
2022-01-21 21:21:12,013 iteration 1668 : loss : 0.064925, loss_ce: 0.026649
2022-01-21 21:21:13,186 iteration 1669 : loss : 0.040057, loss_ce: 0.016361
2022-01-21 21:21:14,360 iteration 1670 : loss : 0.051310, loss_ce: 0.017655
2022-01-21 21:21:15,569 iteration 1671 : loss : 0.047728, loss_ce: 0.019965
2022-01-21 21:21:16,729 iteration 1672 : loss : 0.059512, loss_ce: 0.022030
2022-01-21 21:21:17,874 iteration 1673 : loss : 0.033759, loss_ce: 0.013769
2022-01-21 21:21:19,107 iteration 1674 : loss : 0.049489, loss_ce: 0.020584
2022-01-21 21:21:20,266 iteration 1675 : loss : 0.045971, loss_ce: 0.016585
2022-01-21 21:21:21,493 iteration 1676 : loss : 0.046856, loss_ce: 0.020652
2022-01-21 21:21:22,739 iteration 1677 : loss : 0.051057, loss_ce: 0.021820
2022-01-21 21:21:23,955 iteration 1678 : loss : 0.088376, loss_ce: 0.024198
2022-01-21 21:21:25,183 iteration 1679 : loss : 0.041365, loss_ce: 0.011152
2022-01-21 21:21:26,388 iteration 1680 : loss : 0.048869, loss_ce: 0.022537
2022-01-21 21:21:27,565 iteration 1681 : loss : 0.069570, loss_ce: 0.017065
2022-01-21 21:21:28,707 iteration 1682 : loss : 0.062413, loss_ce: 0.031012
2022-01-21 21:21:29,919 iteration 1683 : loss : 0.056419, loss_ce: 0.025037
 25%|███████▍                      | 99/400 [36:19<1:45:12, 20.97s/it]2022-01-21 21:21:31,171 iteration 1684 : loss : 0.043678, loss_ce: 0.015033
2022-01-21 21:21:32,315 iteration 1685 : loss : 0.050814, loss_ce: 0.019373
2022-01-21 21:21:33,558 iteration 1686 : loss : 0.059025, loss_ce: 0.024233
2022-01-21 21:21:34,692 iteration 1687 : loss : 0.041000, loss_ce: 0.012212
2022-01-21 21:21:35,900 iteration 1688 : loss : 0.053560, loss_ce: 0.020749
2022-01-21 21:21:37,106 iteration 1689 : loss : 0.054278, loss_ce: 0.023389
2022-01-21 21:21:38,227 iteration 1690 : loss : 0.044187, loss_ce: 0.017120
2022-01-21 21:21:39,343 iteration 1691 : loss : 0.067216, loss_ce: 0.022604
2022-01-21 21:21:40,533 iteration 1692 : loss : 0.034989, loss_ce: 0.014841
2022-01-21 21:21:41,774 iteration 1693 : loss : 0.049725, loss_ce: 0.019103
2022-01-21 21:21:42,997 iteration 1694 : loss : 0.051330, loss_ce: 0.014805
2022-01-21 21:21:44,161 iteration 1695 : loss : 0.055099, loss_ce: 0.014310
2022-01-21 21:21:45,348 iteration 1696 : loss : 0.062265, loss_ce: 0.030890
2022-01-21 21:21:46,552 iteration 1697 : loss : 0.039999, loss_ce: 0.017317
2022-01-21 21:21:47,761 iteration 1698 : loss : 0.031340, loss_ce: 0.011668
2022-01-21 21:21:48,920 iteration 1699 : loss : 0.051040, loss_ce: 0.022534
2022-01-21 21:21:48,920 Training Data Eval:
2022-01-21 21:21:54,633   Average segmentation loss on training set: 0.0374
2022-01-21 21:21:54,634 Validation Data Eval:
2022-01-21 21:21:56,592   Average segmentation loss on validation set: 0.1022
2022-01-21 21:21:57,789 iteration 1700 : loss : 0.038751, loss_ce: 0.014535
 25%|███████▎                     | 100/400 [36:47<1:55:12, 23.04s/it]2022-01-21 21:21:59,024 iteration 1701 : loss : 0.042784, loss_ce: 0.018551
2022-01-21 21:22:00,206 iteration 1702 : loss : 0.042678, loss_ce: 0.016275
2022-01-21 21:22:01,455 iteration 1703 : loss : 0.072835, loss_ce: 0.026283
2022-01-21 21:22:02,627 iteration 1704 : loss : 0.046435, loss_ce: 0.022242
2022-01-21 21:22:03,840 iteration 1705 : loss : 0.054377, loss_ce: 0.020394
2022-01-21 21:22:05,087 iteration 1706 : loss : 0.065767, loss_ce: 0.024766
2022-01-21 21:22:06,248 iteration 1707 : loss : 0.043371, loss_ce: 0.019952
2022-01-21 21:22:07,431 iteration 1708 : loss : 0.131127, loss_ce: 0.037110
2022-01-21 21:22:08,604 iteration 1709 : loss : 0.062764, loss_ce: 0.025424
2022-01-21 21:22:09,825 iteration 1710 : loss : 0.060164, loss_ce: 0.021042
2022-01-21 21:22:11,006 iteration 1711 : loss : 0.045995, loss_ce: 0.016941
2022-01-21 21:22:12,123 iteration 1712 : loss : 0.038880, loss_ce: 0.019242
2022-01-21 21:22:13,323 iteration 1713 : loss : 0.058310, loss_ce: 0.018767
2022-01-21 21:22:14,581 iteration 1714 : loss : 0.068907, loss_ce: 0.020401
2022-01-21 21:22:15,818 iteration 1715 : loss : 0.062946, loss_ce: 0.025951
2022-01-21 21:22:16,934 iteration 1716 : loss : 0.039324, loss_ce: 0.010752
2022-01-21 21:22:18,168 iteration 1717 : loss : 0.059353, loss_ce: 0.022578
 25%|███████▎                     | 101/400 [37:08<1:50:49, 22.24s/it]2022-01-21 21:22:19,415 iteration 1718 : loss : 0.074002, loss_ce: 0.032638
2022-01-21 21:22:20,591 iteration 1719 : loss : 0.073799, loss_ce: 0.015059
2022-01-21 21:22:21,817 iteration 1720 : loss : 0.050155, loss_ce: 0.020022
2022-01-21 21:22:22,968 iteration 1721 : loss : 0.039929, loss_ce: 0.012878
2022-01-21 21:22:24,180 iteration 1722 : loss : 0.052019, loss_ce: 0.017659
2022-01-21 21:22:25,316 iteration 1723 : loss : 0.064722, loss_ce: 0.020726
2022-01-21 21:22:26,516 iteration 1724 : loss : 0.041083, loss_ce: 0.015533
2022-01-21 21:22:27,706 iteration 1725 : loss : 0.059892, loss_ce: 0.019244
2022-01-21 21:22:28,895 iteration 1726 : loss : 0.048234, loss_ce: 0.018498
2022-01-21 21:22:30,149 iteration 1727 : loss : 0.086665, loss_ce: 0.041679
2022-01-21 21:22:31,252 iteration 1728 : loss : 0.042500, loss_ce: 0.013995
2022-01-21 21:22:32,454 iteration 1729 : loss : 0.053049, loss_ce: 0.017755
2022-01-21 21:22:33,697 iteration 1730 : loss : 0.038032, loss_ce: 0.016185
2022-01-21 21:22:34,868 iteration 1731 : loss : 0.061672, loss_ce: 0.031642
2022-01-21 21:22:36,024 iteration 1732 : loss : 0.047292, loss_ce: 0.020133
2022-01-21 21:22:37,159 iteration 1733 : loss : 0.040522, loss_ce: 0.017057
2022-01-21 21:22:38,319 iteration 1734 : loss : 0.055330, loss_ce: 0.022531
 26%|███████▍                     | 102/400 [37:28<1:47:20, 21.61s/it]2022-01-21 21:22:39,674 iteration 1735 : loss : 0.044454, loss_ce: 0.017913
2022-01-21 21:22:40,829 iteration 1736 : loss : 0.058111, loss_ce: 0.022607
2022-01-21 21:22:42,128 iteration 1737 : loss : 0.050812, loss_ce: 0.021772
2022-01-21 21:22:43,311 iteration 1738 : loss : 0.037896, loss_ce: 0.019596
2022-01-21 21:22:44,442 iteration 1739 : loss : 0.037688, loss_ce: 0.013130
2022-01-21 21:22:45,669 iteration 1740 : loss : 0.037516, loss_ce: 0.015285
2022-01-21 21:22:46,890 iteration 1741 : loss : 0.051487, loss_ce: 0.018104
2022-01-21 21:22:48,108 iteration 1742 : loss : 0.054562, loss_ce: 0.018994
2022-01-21 21:22:49,225 iteration 1743 : loss : 0.048924, loss_ce: 0.014931
2022-01-21 21:22:50,475 iteration 1744 : loss : 0.062734, loss_ce: 0.025953
2022-01-21 21:22:51,717 iteration 1745 : loss : 0.047015, loss_ce: 0.018075
2022-01-21 21:22:52,912 iteration 1746 : loss : 0.056109, loss_ce: 0.026103
2022-01-21 21:22:54,067 iteration 1747 : loss : 0.045729, loss_ce: 0.019518
2022-01-21 21:22:55,267 iteration 1748 : loss : 0.037114, loss_ce: 0.012848
2022-01-21 21:22:56,358 iteration 1749 : loss : 0.037421, loss_ce: 0.011243
2022-01-21 21:22:57,560 iteration 1750 : loss : 0.098801, loss_ce: 0.022027
2022-01-21 21:22:58,828 iteration 1751 : loss : 0.048010, loss_ce: 0.017005
 26%|███████▍                     | 103/400 [37:48<1:45:21, 21.28s/it]2022-01-21 21:23:00,202 iteration 1752 : loss : 0.092420, loss_ce: 0.021401
2022-01-21 21:23:01,301 iteration 1753 : loss : 0.047239, loss_ce: 0.014139
2022-01-21 21:23:02,536 iteration 1754 : loss : 0.045018, loss_ce: 0.016468
2022-01-21 21:23:03,685 iteration 1755 : loss : 0.042167, loss_ce: 0.017391
2022-01-21 21:23:04,879 iteration 1756 : loss : 0.050570, loss_ce: 0.018327
2022-01-21 21:23:06,012 iteration 1757 : loss : 0.034002, loss_ce: 0.014196
2022-01-21 21:23:07,180 iteration 1758 : loss : 0.044472, loss_ce: 0.023503
2022-01-21 21:23:08,321 iteration 1759 : loss : 0.055169, loss_ce: 0.017936
2022-01-21 21:23:09,464 iteration 1760 : loss : 0.069890, loss_ce: 0.022335
2022-01-21 21:23:10,690 iteration 1761 : loss : 0.060861, loss_ce: 0.021865
2022-01-21 21:23:11,794 iteration 1762 : loss : 0.038601, loss_ce: 0.015195
2022-01-21 21:23:12,918 iteration 1763 : loss : 0.051420, loss_ce: 0.018844
2022-01-21 21:23:14,002 iteration 1764 : loss : 0.051017, loss_ce: 0.014965
2022-01-21 21:23:15,196 iteration 1765 : loss : 0.044596, loss_ce: 0.023283
2022-01-21 21:23:16,438 iteration 1766 : loss : 0.064746, loss_ce: 0.037986
2022-01-21 21:23:17,596 iteration 1767 : loss : 0.042742, loss_ce: 0.019213
2022-01-21 21:23:18,790 iteration 1768 : loss : 0.054323, loss_ce: 0.020158
 26%|███████▌                     | 104/400 [38:08<1:43:02, 20.89s/it]2022-01-21 21:23:20,031 iteration 1769 : loss : 0.052131, loss_ce: 0.020356
2022-01-21 21:23:21,183 iteration 1770 : loss : 0.046203, loss_ce: 0.017609
2022-01-21 21:23:22,291 iteration 1771 : loss : 0.048869, loss_ce: 0.020158
2022-01-21 21:23:23,416 iteration 1772 : loss : 0.044229, loss_ce: 0.022405
2022-01-21 21:23:24,639 iteration 1773 : loss : 0.091021, loss_ce: 0.029501
2022-01-21 21:23:25,837 iteration 1774 : loss : 0.031818, loss_ce: 0.010479
2022-01-21 21:23:27,052 iteration 1775 : loss : 0.062805, loss_ce: 0.026864
2022-01-21 21:23:28,199 iteration 1776 : loss : 0.035659, loss_ce: 0.017437
2022-01-21 21:23:29,336 iteration 1777 : loss : 0.039184, loss_ce: 0.014631
2022-01-21 21:23:30,451 iteration 1778 : loss : 0.043667, loss_ce: 0.014246
2022-01-21 21:23:31,664 iteration 1779 : loss : 0.057593, loss_ce: 0.021062
2022-01-21 21:23:32,850 iteration 1780 : loss : 0.058158, loss_ce: 0.026861
2022-01-21 21:23:33,979 iteration 1781 : loss : 0.039682, loss_ce: 0.015744
2022-01-21 21:23:35,184 iteration 1782 : loss : 0.049786, loss_ce: 0.021723
2022-01-21 21:23:36,382 iteration 1783 : loss : 0.040157, loss_ce: 0.015958
2022-01-21 21:23:37,533 iteration 1784 : loss : 0.042325, loss_ce: 0.016389
2022-01-21 21:23:37,533 Training Data Eval:
2022-01-21 21:23:43,240   Average segmentation loss on training set: 0.0329
2022-01-21 21:23:43,240 Validation Data Eval:
2022-01-21 21:23:45,212   Average segmentation loss on validation set: 0.0687
2022-01-21 21:23:49,320 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 21:23:50,599 iteration 1785 : loss : 0.049765, loss_ce: 0.018541
 26%|███████▌                     | 105/400 [38:40<1:58:47, 24.16s/it]2022-01-21 21:23:51,850 iteration 1786 : loss : 0.044246, loss_ce: 0.022169
2022-01-21 21:23:52,948 iteration 1787 : loss : 0.046294, loss_ce: 0.017382
2022-01-21 21:23:54,174 iteration 1788 : loss : 0.076861, loss_ce: 0.058201
2022-01-21 21:23:55,375 iteration 1789 : loss : 0.048575, loss_ce: 0.017109
2022-01-21 21:23:56,560 iteration 1790 : loss : 0.040037, loss_ce: 0.017641
2022-01-21 21:23:57,798 iteration 1791 : loss : 0.055833, loss_ce: 0.020800
2022-01-21 21:23:58,934 iteration 1792 : loss : 0.053619, loss_ce: 0.025714
2022-01-21 21:24:00,083 iteration 1793 : loss : 0.092248, loss_ce: 0.032315
2022-01-21 21:24:01,251 iteration 1794 : loss : 0.037462, loss_ce: 0.014144
2022-01-21 21:24:02,464 iteration 1795 : loss : 0.047602, loss_ce: 0.017889
2022-01-21 21:24:03,634 iteration 1796 : loss : 0.049573, loss_ce: 0.024991
2022-01-21 21:24:04,894 iteration 1797 : loss : 0.074782, loss_ce: 0.024527
2022-01-21 21:24:06,136 iteration 1798 : loss : 0.040167, loss_ce: 0.015408
2022-01-21 21:24:07,293 iteration 1799 : loss : 0.055200, loss_ce: 0.021316
2022-01-21 21:24:08,491 iteration 1800 : loss : 0.078956, loss_ce: 0.038610
2022-01-21 21:24:09,627 iteration 1801 : loss : 0.113530, loss_ce: 0.054519
2022-01-21 21:24:10,784 iteration 1802 : loss : 0.083280, loss_ce: 0.028899
 26%|███████▋                     | 106/400 [39:00<1:52:32, 22.97s/it]2022-01-21 21:24:12,089 iteration 1803 : loss : 0.073198, loss_ce: 0.027964
2022-01-21 21:24:13,329 iteration 1804 : loss : 0.045398, loss_ce: 0.013292
2022-01-21 21:24:14,490 iteration 1805 : loss : 0.059430, loss_ce: 0.015760
2022-01-21 21:24:15,640 iteration 1806 : loss : 0.070209, loss_ce: 0.030080
2022-01-21 21:24:16,787 iteration 1807 : loss : 0.085579, loss_ce: 0.029122
2022-01-21 21:24:17,954 iteration 1808 : loss : 0.039637, loss_ce: 0.016029
2022-01-21 21:24:19,097 iteration 1809 : loss : 0.043397, loss_ce: 0.018135
2022-01-21 21:24:20,177 iteration 1810 : loss : 0.038028, loss_ce: 0.014952
2022-01-21 21:24:21,400 iteration 1811 : loss : 0.077814, loss_ce: 0.041041
2022-01-21 21:24:22,637 iteration 1812 : loss : 0.056699, loss_ce: 0.020078
2022-01-21 21:24:23,934 iteration 1813 : loss : 0.067658, loss_ce: 0.027361
2022-01-21 21:24:25,147 iteration 1814 : loss : 0.049835, loss_ce: 0.023877
2022-01-21 21:24:26,283 iteration 1815 : loss : 0.049866, loss_ce: 0.015850
2022-01-21 21:24:27,377 iteration 1816 : loss : 0.042388, loss_ce: 0.016949
2022-01-21 21:24:28,615 iteration 1817 : loss : 0.055424, loss_ce: 0.020074
2022-01-21 21:24:29,790 iteration 1818 : loss : 0.068424, loss_ce: 0.028280
2022-01-21 21:24:31,010 iteration 1819 : loss : 0.087982, loss_ce: 0.037453
 27%|███████▊                     | 107/400 [39:20<1:48:08, 22.15s/it]2022-01-21 21:24:32,348 iteration 1820 : loss : 0.049487, loss_ce: 0.022491
2022-01-21 21:24:33,502 iteration 1821 : loss : 0.050403, loss_ce: 0.019646
2022-01-21 21:24:34,692 iteration 1822 : loss : 0.057800, loss_ce: 0.021382
2022-01-21 21:24:35,798 iteration 1823 : loss : 0.045974, loss_ce: 0.016673
2022-01-21 21:24:36,864 iteration 1824 : loss : 0.040386, loss_ce: 0.015569
2022-01-21 21:24:38,073 iteration 1825 : loss : 0.054387, loss_ce: 0.022557
2022-01-21 21:24:39,170 iteration 1826 : loss : 0.046315, loss_ce: 0.024912
2022-01-21 21:24:40,441 iteration 1827 : loss : 0.170258, loss_ce: 0.059123
2022-01-21 21:24:41,604 iteration 1828 : loss : 0.049999, loss_ce: 0.023175
2022-01-21 21:24:42,761 iteration 1829 : loss : 0.090770, loss_ce: 0.034916
2022-01-21 21:24:43,916 iteration 1830 : loss : 0.048441, loss_ce: 0.022287
2022-01-21 21:24:45,165 iteration 1831 : loss : 0.045329, loss_ce: 0.022451
2022-01-21 21:24:46,330 iteration 1832 : loss : 0.039180, loss_ce: 0.012380
2022-01-21 21:24:47,500 iteration 1833 : loss : 0.048889, loss_ce: 0.024474
2022-01-21 21:24:48,762 iteration 1834 : loss : 0.052101, loss_ce: 0.018185
2022-01-21 21:24:49,920 iteration 1835 : loss : 0.043689, loss_ce: 0.021182
2022-01-21 21:24:51,097 iteration 1836 : loss : 0.068885, loss_ce: 0.024006
 27%|███████▊                     | 108/400 [39:41<1:44:46, 21.53s/it]2022-01-21 21:24:52,383 iteration 1837 : loss : 0.046621, loss_ce: 0.019293
2022-01-21 21:24:53,619 iteration 1838 : loss : 0.042057, loss_ce: 0.018803
2022-01-21 21:24:54,779 iteration 1839 : loss : 0.056422, loss_ce: 0.020260
2022-01-21 21:24:55,885 iteration 1840 : loss : 0.047292, loss_ce: 0.022255
2022-01-21 21:24:57,093 iteration 1841 : loss : 0.054399, loss_ce: 0.023853
2022-01-21 21:24:58,330 iteration 1842 : loss : 0.043864, loss_ce: 0.017331
2022-01-21 21:24:59,446 iteration 1843 : loss : 0.035154, loss_ce: 0.015567
2022-01-21 21:25:00,625 iteration 1844 : loss : 0.043554, loss_ce: 0.017101
2022-01-21 21:25:01,739 iteration 1845 : loss : 0.041064, loss_ce: 0.015692
2022-01-21 21:25:03,015 iteration 1846 : loss : 0.045710, loss_ce: 0.021218
2022-01-21 21:25:04,236 iteration 1847 : loss : 0.056238, loss_ce: 0.021414
2022-01-21 21:25:05,418 iteration 1848 : loss : 0.039673, loss_ce: 0.015251
2022-01-21 21:25:06,521 iteration 1849 : loss : 0.033001, loss_ce: 0.015185
2022-01-21 21:25:07,706 iteration 1850 : loss : 0.059413, loss_ce: 0.016110
2022-01-21 21:25:08,914 iteration 1851 : loss : 0.061245, loss_ce: 0.030126
2022-01-21 21:25:10,103 iteration 1852 : loss : 0.039577, loss_ce: 0.017031
2022-01-21 21:25:11,294 iteration 1853 : loss : 0.043711, loss_ce: 0.010731
 27%|███████▉                     | 109/400 [40:01<1:42:28, 21.13s/it]2022-01-21 21:25:12,518 iteration 1854 : loss : 0.052087, loss_ce: 0.017790
2022-01-21 21:25:13,689 iteration 1855 : loss : 0.053257, loss_ce: 0.017957
2022-01-21 21:25:14,868 iteration 1856 : loss : 0.041675, loss_ce: 0.013051
2022-01-21 21:25:16,045 iteration 1857 : loss : 0.069689, loss_ce: 0.024125
2022-01-21 21:25:17,212 iteration 1858 : loss : 0.066472, loss_ce: 0.035445
2022-01-21 21:25:18,336 iteration 1859 : loss : 0.058654, loss_ce: 0.035562
2022-01-21 21:25:19,612 iteration 1860 : loss : 0.065873, loss_ce: 0.026983
2022-01-21 21:25:20,817 iteration 1861 : loss : 0.053452, loss_ce: 0.018857
2022-01-21 21:25:21,991 iteration 1862 : loss : 0.041376, loss_ce: 0.017841
2022-01-21 21:25:23,215 iteration 1863 : loss : 0.049432, loss_ce: 0.019958
2022-01-21 21:25:24,407 iteration 1864 : loss : 0.048890, loss_ce: 0.021652
2022-01-21 21:25:25,668 iteration 1865 : loss : 0.044126, loss_ce: 0.021409
2022-01-21 21:25:26,905 iteration 1866 : loss : 0.045697, loss_ce: 0.023133
2022-01-21 21:25:28,104 iteration 1867 : loss : 0.127893, loss_ce: 0.048471
2022-01-21 21:25:29,260 iteration 1868 : loss : 0.046841, loss_ce: 0.022455
2022-01-21 21:25:30,440 iteration 1869 : loss : 0.060483, loss_ce: 0.022601
2022-01-21 21:25:30,440 Training Data Eval:
2022-01-21 21:25:36,141   Average segmentation loss on training set: 0.0358
2022-01-21 21:25:36,141 Validation Data Eval:
2022-01-21 21:25:38,109   Average segmentation loss on validation set: 0.0828
2022-01-21 21:25:39,226 iteration 1870 : loss : 0.052467, loss_ce: 0.017649
 28%|███████▉                     | 110/400 [40:29<1:51:58, 23.17s/it]2022-01-21 21:25:40,445 iteration 1871 : loss : 0.052074, loss_ce: 0.023799
2022-01-21 21:25:41,579 iteration 1872 : loss : 0.040138, loss_ce: 0.013605
2022-01-21 21:25:42,756 iteration 1873 : loss : 0.048502, loss_ce: 0.019363
2022-01-21 21:25:43,986 iteration 1874 : loss : 0.047839, loss_ce: 0.019596
2022-01-21 21:25:45,241 iteration 1875 : loss : 0.053570, loss_ce: 0.028132
2022-01-21 21:25:46,497 iteration 1876 : loss : 0.049384, loss_ce: 0.014350
2022-01-21 21:25:47,730 iteration 1877 : loss : 0.072345, loss_ce: 0.019363
2022-01-21 21:25:48,860 iteration 1878 : loss : 0.037848, loss_ce: 0.013947
2022-01-21 21:25:50,006 iteration 1879 : loss : 0.045503, loss_ce: 0.019794
2022-01-21 21:25:51,143 iteration 1880 : loss : 0.041103, loss_ce: 0.012837
2022-01-21 21:25:52,278 iteration 1881 : loss : 0.037077, loss_ce: 0.012603
2022-01-21 21:25:53,452 iteration 1882 : loss : 0.099253, loss_ce: 0.025872
2022-01-21 21:25:54,567 iteration 1883 : loss : 0.048338, loss_ce: 0.019324
2022-01-21 21:25:55,805 iteration 1884 : loss : 0.045873, loss_ce: 0.020658
2022-01-21 21:25:56,936 iteration 1885 : loss : 0.037221, loss_ce: 0.013433
2022-01-21 21:25:58,136 iteration 1886 : loss : 0.049391, loss_ce: 0.024933
2022-01-21 21:25:59,277 iteration 1887 : loss : 0.057762, loss_ce: 0.023959
 28%|████████                     | 111/400 [40:49<1:47:05, 22.23s/it]2022-01-21 21:26:00,540 iteration 1888 : loss : 0.041420, loss_ce: 0.012580
2022-01-21 21:26:01,795 iteration 1889 : loss : 0.052865, loss_ce: 0.024712
2022-01-21 21:26:02,911 iteration 1890 : loss : 0.032984, loss_ce: 0.011750
2022-01-21 21:26:04,106 iteration 1891 : loss : 0.059610, loss_ce: 0.031980
2022-01-21 21:26:05,278 iteration 1892 : loss : 0.045186, loss_ce: 0.013452
2022-01-21 21:26:06,493 iteration 1893 : loss : 0.083864, loss_ce: 0.026893
2022-01-21 21:26:07,664 iteration 1894 : loss : 0.057335, loss_ce: 0.024684
2022-01-21 21:26:08,865 iteration 1895 : loss : 0.047026, loss_ce: 0.014585
2022-01-21 21:26:10,050 iteration 1896 : loss : 0.043832, loss_ce: 0.021510
2022-01-21 21:26:11,228 iteration 1897 : loss : 0.054807, loss_ce: 0.019369
2022-01-21 21:26:12,489 iteration 1898 : loss : 0.043352, loss_ce: 0.018375
2022-01-21 21:26:13,602 iteration 1899 : loss : 0.036517, loss_ce: 0.014599
2022-01-21 21:26:14,848 iteration 1900 : loss : 0.045209, loss_ce: 0.020952
2022-01-21 21:26:16,121 iteration 1901 : loss : 0.056980, loss_ce: 0.019863
2022-01-21 21:26:17,296 iteration 1902 : loss : 0.069804, loss_ce: 0.023313
2022-01-21 21:26:18,515 iteration 1903 : loss : 0.043524, loss_ce: 0.019786
2022-01-21 21:26:19,744 iteration 1904 : loss : 0.056169, loss_ce: 0.016733
 28%|████████                     | 112/400 [41:09<1:44:11, 21.71s/it]2022-01-21 21:26:21,032 iteration 1905 : loss : 0.048921, loss_ce: 0.019615
2022-01-21 21:26:22,224 iteration 1906 : loss : 0.054011, loss_ce: 0.017348
2022-01-21 21:26:23,398 iteration 1907 : loss : 0.035032, loss_ce: 0.014864
2022-01-21 21:26:24,699 iteration 1908 : loss : 0.047261, loss_ce: 0.017864
2022-01-21 21:26:25,906 iteration 1909 : loss : 0.082153, loss_ce: 0.040985
2022-01-21 21:26:27,123 iteration 1910 : loss : 0.083006, loss_ce: 0.018372
2022-01-21 21:26:28,356 iteration 1911 : loss : 0.030424, loss_ce: 0.010796
2022-01-21 21:26:29,463 iteration 1912 : loss : 0.046726, loss_ce: 0.015386
2022-01-21 21:26:30,648 iteration 1913 : loss : 0.057297, loss_ce: 0.025262
2022-01-21 21:26:31,839 iteration 1914 : loss : 0.037234, loss_ce: 0.017069
2022-01-21 21:26:33,043 iteration 1915 : loss : 0.064287, loss_ce: 0.027501
2022-01-21 21:26:34,223 iteration 1916 : loss : 0.052701, loss_ce: 0.020408
2022-01-21 21:26:35,403 iteration 1917 : loss : 0.050574, loss_ce: 0.022863
2022-01-21 21:26:36,614 iteration 1918 : loss : 0.052452, loss_ce: 0.018873
2022-01-21 21:26:37,771 iteration 1919 : loss : 0.052213, loss_ce: 0.020834
2022-01-21 21:26:38,928 iteration 1920 : loss : 0.067888, loss_ce: 0.027089
2022-01-21 21:26:40,177 iteration 1921 : loss : 0.072273, loss_ce: 0.033405
 28%|████████▏                    | 113/400 [41:30<1:41:59, 21.32s/it]2022-01-21 21:26:41,385 iteration 1922 : loss : 0.054939, loss_ce: 0.029239
2022-01-21 21:26:42,561 iteration 1923 : loss : 0.044619, loss_ce: 0.020098
2022-01-21 21:26:43,795 iteration 1924 : loss : 0.034446, loss_ce: 0.015828
2022-01-21 21:26:44,990 iteration 1925 : loss : 0.072262, loss_ce: 0.031210
2022-01-21 21:26:46,148 iteration 1926 : loss : 0.036904, loss_ce: 0.015546
2022-01-21 21:26:47,300 iteration 1927 : loss : 0.054579, loss_ce: 0.023281
2022-01-21 21:26:48,566 iteration 1928 : loss : 0.060238, loss_ce: 0.028083
2022-01-21 21:26:49,714 iteration 1929 : loss : 0.047796, loss_ce: 0.016403
2022-01-21 21:26:50,849 iteration 1930 : loss : 0.038797, loss_ce: 0.017583
2022-01-21 21:26:52,049 iteration 1931 : loss : 0.081249, loss_ce: 0.020928
2022-01-21 21:26:53,288 iteration 1932 : loss : 0.077509, loss_ce: 0.027134
2022-01-21 21:26:54,532 iteration 1933 : loss : 0.067520, loss_ce: 0.042407
2022-01-21 21:26:55,626 iteration 1934 : loss : 0.036063, loss_ce: 0.015220
2022-01-21 21:26:56,817 iteration 1935 : loss : 0.060077, loss_ce: 0.019910
2022-01-21 21:26:58,075 iteration 1936 : loss : 0.052486, loss_ce: 0.025622
2022-01-21 21:26:59,198 iteration 1937 : loss : 0.051547, loss_ce: 0.014178
2022-01-21 21:27:00,306 iteration 1938 : loss : 0.048113, loss_ce: 0.016360
 28%|████████▎                    | 114/400 [41:50<1:39:55, 20.96s/it]2022-01-21 21:27:01,509 iteration 1939 : loss : 0.038391, loss_ce: 0.012411
2022-01-21 21:27:02,793 iteration 1940 : loss : 0.041802, loss_ce: 0.019022
2022-01-21 21:27:04,071 iteration 1941 : loss : 0.041639, loss_ce: 0.016912
2022-01-21 21:27:05,283 iteration 1942 : loss : 0.047102, loss_ce: 0.016915
2022-01-21 21:27:06,451 iteration 1943 : loss : 0.044022, loss_ce: 0.018664
2022-01-21 21:27:07,642 iteration 1944 : loss : 0.039556, loss_ce: 0.015530
2022-01-21 21:27:08,787 iteration 1945 : loss : 0.051470, loss_ce: 0.017375
2022-01-21 21:27:09,975 iteration 1946 : loss : 0.041308, loss_ce: 0.015639
2022-01-21 21:27:11,192 iteration 1947 : loss : 0.054468, loss_ce: 0.027154
2022-01-21 21:27:12,379 iteration 1948 : loss : 0.063897, loss_ce: 0.018078
2022-01-21 21:27:13,536 iteration 1949 : loss : 0.036519, loss_ce: 0.016703
2022-01-21 21:27:14,667 iteration 1950 : loss : 0.031491, loss_ce: 0.013421
2022-01-21 21:27:15,903 iteration 1951 : loss : 0.063147, loss_ce: 0.021295
2022-01-21 21:27:17,117 iteration 1952 : loss : 0.046590, loss_ce: 0.013712
2022-01-21 21:27:18,369 iteration 1953 : loss : 0.061271, loss_ce: 0.029451
2022-01-21 21:27:19,569 iteration 1954 : loss : 0.031575, loss_ce: 0.014543
2022-01-21 21:27:19,569 Training Data Eval:
2022-01-21 21:27:25,249   Average segmentation loss on training set: 0.0306
2022-01-21 21:27:25,250 Validation Data Eval:
2022-01-21 21:27:27,210   Average segmentation loss on validation set: 0.0952
2022-01-21 21:27:28,410 iteration 1955 : loss : 0.043714, loss_ce: 0.013946
 29%|████████▎                    | 115/400 [42:18<1:49:45, 23.11s/it]2022-01-21 21:27:29,625 iteration 1956 : loss : 0.061873, loss_ce: 0.015812
2022-01-21 21:27:30,894 iteration 1957 : loss : 0.046874, loss_ce: 0.018901
2022-01-21 21:27:32,164 iteration 1958 : loss : 0.042306, loss_ce: 0.015337
2022-01-21 21:27:33,366 iteration 1959 : loss : 0.056479, loss_ce: 0.022726
2022-01-21 21:27:34,491 iteration 1960 : loss : 0.046881, loss_ce: 0.019352
2022-01-21 21:27:35,698 iteration 1961 : loss : 0.080193, loss_ce: 0.043712
2022-01-21 21:27:36,916 iteration 1962 : loss : 0.042041, loss_ce: 0.018711
2022-01-21 21:27:38,048 iteration 1963 : loss : 0.040885, loss_ce: 0.014756
2022-01-21 21:27:39,189 iteration 1964 : loss : 0.034654, loss_ce: 0.013649
2022-01-21 21:27:40,331 iteration 1965 : loss : 0.039295, loss_ce: 0.015250
2022-01-21 21:27:41,580 iteration 1966 : loss : 0.056555, loss_ce: 0.025071
2022-01-21 21:27:42,836 iteration 1967 : loss : 0.047590, loss_ce: 0.016971
2022-01-21 21:27:44,068 iteration 1968 : loss : 0.040727, loss_ce: 0.019778
2022-01-21 21:27:45,284 iteration 1969 : loss : 0.046543, loss_ce: 0.017166
2022-01-21 21:27:46,458 iteration 1970 : loss : 0.060806, loss_ce: 0.020699
2022-01-21 21:27:47,691 iteration 1971 : loss : 0.054953, loss_ce: 0.024398
2022-01-21 21:27:48,846 iteration 1972 : loss : 0.059020, loss_ce: 0.020991
 29%|████████▍                    | 116/400 [42:38<1:45:33, 22.30s/it]2022-01-21 21:27:49,962 iteration 1973 : loss : 0.036970, loss_ce: 0.014170
2022-01-21 21:27:51,166 iteration 1974 : loss : 0.047024, loss_ce: 0.018631
2022-01-21 21:27:52,338 iteration 1975 : loss : 0.046275, loss_ce: 0.014565
2022-01-21 21:27:53,587 iteration 1976 : loss : 0.034676, loss_ce: 0.014671
2022-01-21 21:27:54,778 iteration 1977 : loss : 0.043423, loss_ce: 0.012681
2022-01-21 21:27:55,893 iteration 1978 : loss : 0.027680, loss_ce: 0.012799
2022-01-21 21:27:57,007 iteration 1979 : loss : 0.037721, loss_ce: 0.014520
2022-01-21 21:27:58,201 iteration 1980 : loss : 0.043635, loss_ce: 0.018852
2022-01-21 21:27:59,339 iteration 1981 : loss : 0.048097, loss_ce: 0.014759
2022-01-21 21:28:00,433 iteration 1982 : loss : 0.056138, loss_ce: 0.021693
2022-01-21 21:28:01,683 iteration 1983 : loss : 0.047457, loss_ce: 0.023912
2022-01-21 21:28:02,799 iteration 1984 : loss : 0.038581, loss_ce: 0.010335
2022-01-21 21:28:03,985 iteration 1985 : loss : 0.028271, loss_ce: 0.010908
2022-01-21 21:28:05,185 iteration 1986 : loss : 0.049625, loss_ce: 0.023381
2022-01-21 21:28:06,418 iteration 1987 : loss : 0.041379, loss_ce: 0.016457
2022-01-21 21:28:07,543 iteration 1988 : loss : 0.057397, loss_ce: 0.017012
2022-01-21 21:28:08,712 iteration 1989 : loss : 0.041680, loss_ce: 0.020791
 29%|████████▍                    | 117/400 [42:58<1:41:45, 21.58s/it]2022-01-21 21:28:09,860 iteration 1990 : loss : 0.027895, loss_ce: 0.012226
2022-01-21 21:28:10,991 iteration 1991 : loss : 0.028934, loss_ce: 0.010609
2022-01-21 21:28:12,201 iteration 1992 : loss : 0.043797, loss_ce: 0.015089
2022-01-21 21:28:13,503 iteration 1993 : loss : 0.043536, loss_ce: 0.022802
2022-01-21 21:28:14,643 iteration 1994 : loss : 0.030801, loss_ce: 0.012814
2022-01-21 21:28:15,823 iteration 1995 : loss : 0.066803, loss_ce: 0.020366
2022-01-21 21:28:17,014 iteration 1996 : loss : 0.074523, loss_ce: 0.024752
2022-01-21 21:28:18,194 iteration 1997 : loss : 0.036438, loss_ce: 0.013008
2022-01-21 21:28:19,376 iteration 1998 : loss : 0.050786, loss_ce: 0.019187
2022-01-21 21:28:20,536 iteration 1999 : loss : 0.042063, loss_ce: 0.017643
2022-01-21 21:28:21,785 iteration 2000 : loss : 0.054407, loss_ce: 0.013716
2022-01-21 21:28:22,953 iteration 2001 : loss : 0.038702, loss_ce: 0.017264
2022-01-21 21:28:24,201 iteration 2002 : loss : 0.050452, loss_ce: 0.025950
2022-01-21 21:28:25,339 iteration 2003 : loss : 0.048294, loss_ce: 0.021915
2022-01-21 21:28:26,540 iteration 2004 : loss : 0.058980, loss_ce: 0.015784
2022-01-21 21:28:27,762 iteration 2005 : loss : 0.065586, loss_ce: 0.020958
2022-01-21 21:28:28,978 iteration 2006 : loss : 0.060269, loss_ce: 0.022581
 30%|████████▌                    | 118/400 [43:18<1:39:33, 21.18s/it]2022-01-21 21:28:30,250 iteration 2007 : loss : 0.043920, loss_ce: 0.019319
2022-01-21 21:28:31,392 iteration 2008 : loss : 0.056784, loss_ce: 0.031073
2022-01-21 21:28:32,554 iteration 2009 : loss : 0.076365, loss_ce: 0.024160
2022-01-21 21:28:33,671 iteration 2010 : loss : 0.062719, loss_ce: 0.025328
2022-01-21 21:28:34,836 iteration 2011 : loss : 0.046427, loss_ce: 0.021825
2022-01-21 21:28:36,030 iteration 2012 : loss : 0.054744, loss_ce: 0.019408
2022-01-21 21:28:37,264 iteration 2013 : loss : 0.038648, loss_ce: 0.015519
2022-01-21 21:28:38,477 iteration 2014 : loss : 0.040218, loss_ce: 0.013761
2022-01-21 21:28:39,603 iteration 2015 : loss : 0.037657, loss_ce: 0.013544
2022-01-21 21:28:40,769 iteration 2016 : loss : 0.044144, loss_ce: 0.013487
2022-01-21 21:28:41,857 iteration 2017 : loss : 0.032349, loss_ce: 0.012659
2022-01-21 21:28:43,036 iteration 2018 : loss : 0.063129, loss_ce: 0.026678
2022-01-21 21:28:44,166 iteration 2019 : loss : 0.048220, loss_ce: 0.021437
2022-01-21 21:28:45,352 iteration 2020 : loss : 0.092188, loss_ce: 0.044815
2022-01-21 21:28:46,559 iteration 2021 : loss : 0.055463, loss_ce: 0.020815
2022-01-21 21:28:47,803 iteration 2022 : loss : 0.043687, loss_ce: 0.019607
2022-01-21 21:28:48,975 iteration 2023 : loss : 0.070636, loss_ce: 0.019225
 30%|████████▋                    | 119/400 [43:38<1:37:31, 20.82s/it]2022-01-21 21:28:50,245 iteration 2024 : loss : 0.045671, loss_ce: 0.021399
2022-01-21 21:28:51,376 iteration 2025 : loss : 0.042280, loss_ce: 0.015202
2022-01-21 21:28:52,519 iteration 2026 : loss : 0.050206, loss_ce: 0.020211
2022-01-21 21:28:53,730 iteration 2027 : loss : 0.043926, loss_ce: 0.014319
2022-01-21 21:28:54,929 iteration 2028 : loss : 0.041532, loss_ce: 0.017599
2022-01-21 21:28:56,044 iteration 2029 : loss : 0.037794, loss_ce: 0.018968
2022-01-21 21:28:57,234 iteration 2030 : loss : 0.037708, loss_ce: 0.013867
2022-01-21 21:28:58,437 iteration 2031 : loss : 0.038247, loss_ce: 0.013543
2022-01-21 21:28:59,650 iteration 2032 : loss : 0.050362, loss_ce: 0.016029
2022-01-21 21:29:00,823 iteration 2033 : loss : 0.069672, loss_ce: 0.022074
2022-01-21 21:29:01,933 iteration 2034 : loss : 0.033253, loss_ce: 0.011737
2022-01-21 21:29:03,052 iteration 2035 : loss : 0.032784, loss_ce: 0.014589
2022-01-21 21:29:04,262 iteration 2036 : loss : 0.036867, loss_ce: 0.013643
2022-01-21 21:29:05,442 iteration 2037 : loss : 0.048959, loss_ce: 0.016002
2022-01-21 21:29:06,584 iteration 2038 : loss : 0.037704, loss_ce: 0.013786
2022-01-21 21:29:07,779 iteration 2039 : loss : 0.041916, loss_ce: 0.017117
2022-01-21 21:29:07,779 Training Data Eval:
2022-01-21 21:29:13,443   Average segmentation loss on training set: 0.0358
2022-01-21 21:29:13,444 Validation Data Eval:
2022-01-21 21:29:15,415   Average segmentation loss on validation set: 0.1184
2022-01-21 21:29:16,564 iteration 2040 : loss : 0.037512, loss_ce: 0.011397
 30%|████████▋                    | 120/400 [44:06<1:46:38, 22.85s/it]2022-01-21 21:29:17,790 iteration 2041 : loss : 0.043658, loss_ce: 0.017096
2022-01-21 21:29:18,954 iteration 2042 : loss : 0.032359, loss_ce: 0.013304
2022-01-21 21:29:20,135 iteration 2043 : loss : 0.032952, loss_ce: 0.014543
2022-01-21 21:29:21,370 iteration 2044 : loss : 0.040552, loss_ce: 0.015730
2022-01-21 21:29:22,625 iteration 2045 : loss : 0.054049, loss_ce: 0.018798
2022-01-21 21:29:23,844 iteration 2046 : loss : 0.056614, loss_ce: 0.025270
2022-01-21 21:29:25,041 iteration 2047 : loss : 0.041013, loss_ce: 0.014594
2022-01-21 21:29:26,151 iteration 2048 : loss : 0.038748, loss_ce: 0.012521
2022-01-21 21:29:27,312 iteration 2049 : loss : 0.045119, loss_ce: 0.017965
2022-01-21 21:29:28,524 iteration 2050 : loss : 0.044969, loss_ce: 0.012983
2022-01-21 21:29:29,741 iteration 2051 : loss : 0.048284, loss_ce: 0.016812
2022-01-21 21:29:30,887 iteration 2052 : loss : 0.031531, loss_ce: 0.015252
2022-01-21 21:29:32,023 iteration 2053 : loss : 0.037955, loss_ce: 0.012936
2022-01-21 21:29:33,211 iteration 2054 : loss : 0.055846, loss_ce: 0.020720
2022-01-21 21:29:34,410 iteration 2055 : loss : 0.059418, loss_ce: 0.030261
2022-01-21 21:29:35,604 iteration 2056 : loss : 0.042225, loss_ce: 0.017188
2022-01-21 21:29:36,819 iteration 2057 : loss : 0.035563, loss_ce: 0.014554
 30%|████████▊                    | 121/400 [44:26<1:42:39, 22.08s/it]2022-01-21 21:29:38,142 iteration 2058 : loss : 0.041423, loss_ce: 0.018730
2022-01-21 21:29:39,357 iteration 2059 : loss : 0.039582, loss_ce: 0.012698
2022-01-21 21:29:40,590 iteration 2060 : loss : 0.046946, loss_ce: 0.015350
2022-01-21 21:29:41,746 iteration 2061 : loss : 0.034077, loss_ce: 0.016134
2022-01-21 21:29:42,867 iteration 2062 : loss : 0.033269, loss_ce: 0.011261
2022-01-21 21:29:43,999 iteration 2063 : loss : 0.028180, loss_ce: 0.011667
2022-01-21 21:29:45,189 iteration 2064 : loss : 0.032704, loss_ce: 0.015308
2022-01-21 21:29:46,391 iteration 2065 : loss : 0.038620, loss_ce: 0.012970
2022-01-21 21:29:47,621 iteration 2066 : loss : 0.051090, loss_ce: 0.020903
2022-01-21 21:29:48,779 iteration 2067 : loss : 0.044691, loss_ce: 0.017157
2022-01-21 21:29:50,018 iteration 2068 : loss : 0.046277, loss_ce: 0.025649
2022-01-21 21:29:51,266 iteration 2069 : loss : 0.054166, loss_ce: 0.016587
2022-01-21 21:29:52,432 iteration 2070 : loss : 0.033280, loss_ce: 0.011266
2022-01-21 21:29:53,601 iteration 2071 : loss : 0.036605, loss_ce: 0.014229
2022-01-21 21:29:54,724 iteration 2072 : loss : 0.037536, loss_ce: 0.016895
2022-01-21 21:29:55,840 iteration 2073 : loss : 0.036770, loss_ce: 0.012353
2022-01-21 21:29:57,023 iteration 2074 : loss : 0.059520, loss_ce: 0.017123
 30%|████████▊                    | 122/400 [44:46<1:39:40, 21.51s/it]2022-01-21 21:29:58,276 iteration 2075 : loss : 0.042423, loss_ce: 0.014557
2022-01-21 21:29:59,519 iteration 2076 : loss : 0.048290, loss_ce: 0.015661
2022-01-21 21:30:00,718 iteration 2077 : loss : 0.037063, loss_ce: 0.013795
2022-01-21 21:30:01,857 iteration 2078 : loss : 0.040594, loss_ce: 0.016222
2022-01-21 21:30:03,022 iteration 2079 : loss : 0.037336, loss_ce: 0.012622
2022-01-21 21:30:04,264 iteration 2080 : loss : 0.049677, loss_ce: 0.014778
2022-01-21 21:30:05,465 iteration 2081 : loss : 0.049270, loss_ce: 0.020144
2022-01-21 21:30:06,650 iteration 2082 : loss : 0.048642, loss_ce: 0.017627
2022-01-21 21:30:07,819 iteration 2083 : loss : 0.026929, loss_ce: 0.009250
2022-01-21 21:30:08,994 iteration 2084 : loss : 0.046438, loss_ce: 0.017035
2022-01-21 21:30:10,158 iteration 2085 : loss : 0.039168, loss_ce: 0.017857
2022-01-21 21:30:11,326 iteration 2086 : loss : 0.046411, loss_ce: 0.020515
2022-01-21 21:30:12,455 iteration 2087 : loss : 0.058278, loss_ce: 0.015755
2022-01-21 21:30:13,742 iteration 2088 : loss : 0.050087, loss_ce: 0.026746
2022-01-21 21:30:14,908 iteration 2089 : loss : 0.040689, loss_ce: 0.014682
2022-01-21 21:30:16,137 iteration 2090 : loss : 0.046259, loss_ce: 0.019054
2022-01-21 21:30:17,318 iteration 2091 : loss : 0.032308, loss_ce: 0.012957
 31%|████████▉                    | 123/400 [45:07<1:37:37, 21.15s/it]2022-01-21 21:30:18,538 iteration 2092 : loss : 0.040769, loss_ce: 0.014711
2022-01-21 21:30:19,809 iteration 2093 : loss : 0.040108, loss_ce: 0.018159
2022-01-21 21:30:21,024 iteration 2094 : loss : 0.031898, loss_ce: 0.013898
2022-01-21 21:30:22,237 iteration 2095 : loss : 0.038801, loss_ce: 0.016308
2022-01-21 21:30:23,482 iteration 2096 : loss : 0.055382, loss_ce: 0.019517
2022-01-21 21:30:24,624 iteration 2097 : loss : 0.036916, loss_ce: 0.017792
2022-01-21 21:30:25,860 iteration 2098 : loss : 0.049214, loss_ce: 0.018690
2022-01-21 21:30:27,094 iteration 2099 : loss : 0.058672, loss_ce: 0.021850
2022-01-21 21:30:28,377 iteration 2100 : loss : 0.064277, loss_ce: 0.028747
2022-01-21 21:30:29,581 iteration 2101 : loss : 0.058520, loss_ce: 0.018927
2022-01-21 21:30:30,740 iteration 2102 : loss : 0.037504, loss_ce: 0.014544
2022-01-21 21:30:32,034 iteration 2103 : loss : 0.043898, loss_ce: 0.017959
2022-01-21 21:30:33,264 iteration 2104 : loss : 0.027691, loss_ce: 0.010539
2022-01-21 21:30:34,428 iteration 2105 : loss : 0.047425, loss_ce: 0.014303
2022-01-21 21:30:35,701 iteration 2106 : loss : 0.080008, loss_ce: 0.024345
2022-01-21 21:30:36,898 iteration 2107 : loss : 0.046586, loss_ce: 0.019508
2022-01-21 21:30:38,110 iteration 2108 : loss : 0.036320, loss_ce: 0.012962
 31%|████████▉                    | 124/400 [45:28<1:36:46, 21.04s/it]2022-01-21 21:30:39,359 iteration 2109 : loss : 0.046601, loss_ce: 0.018271
2022-01-21 21:30:40,537 iteration 2110 : loss : 0.044874, loss_ce: 0.014368
2022-01-21 21:30:41,845 iteration 2111 : loss : 0.045730, loss_ce: 0.015160
2022-01-21 21:30:43,166 iteration 2112 : loss : 0.035482, loss_ce: 0.015597
2022-01-21 21:30:44,329 iteration 2113 : loss : 0.040616, loss_ce: 0.014121
2022-01-21 21:30:45,495 iteration 2114 : loss : 0.044414, loss_ce: 0.015885
2022-01-21 21:30:46,566 iteration 2115 : loss : 0.053925, loss_ce: 0.014970
2022-01-21 21:30:47,769 iteration 2116 : loss : 0.036915, loss_ce: 0.014784
2022-01-21 21:30:49,021 iteration 2117 : loss : 0.054672, loss_ce: 0.017956
2022-01-21 21:30:50,203 iteration 2118 : loss : 0.054310, loss_ce: 0.024859
2022-01-21 21:30:51,414 iteration 2119 : loss : 0.048266, loss_ce: 0.018103
2022-01-21 21:30:52,602 iteration 2120 : loss : 0.051676, loss_ce: 0.017898
2022-01-21 21:30:53,883 iteration 2121 : loss : 0.059597, loss_ce: 0.021651
2022-01-21 21:30:55,020 iteration 2122 : loss : 0.036359, loss_ce: 0.014235
2022-01-21 21:30:56,168 iteration 2123 : loss : 0.041637, loss_ce: 0.021354
2022-01-21 21:30:57,391 iteration 2124 : loss : 0.047539, loss_ce: 0.016833
2022-01-21 21:30:57,391 Training Data Eval:
2022-01-21 21:31:03,096   Average segmentation loss on training set: 0.0265
2022-01-21 21:31:03,097 Validation Data Eval:
2022-01-21 21:31:05,072   Average segmentation loss on validation set: 0.0696
2022-01-21 21:31:06,262 iteration 2125 : loss : 0.025818, loss_ce: 0.008815
 31%|█████████                    | 125/400 [45:56<1:46:13, 23.17s/it]2022-01-21 21:31:07,494 iteration 2126 : loss : 0.028099, loss_ce: 0.009541
2022-01-21 21:31:08,746 iteration 2127 : loss : 0.036308, loss_ce: 0.014020
2022-01-21 21:31:09,884 iteration 2128 : loss : 0.037198, loss_ce: 0.016314
2022-01-21 21:31:11,073 iteration 2129 : loss : 0.033044, loss_ce: 0.011739
2022-01-21 21:31:12,199 iteration 2130 : loss : 0.035166, loss_ce: 0.011431
2022-01-21 21:31:13,460 iteration 2131 : loss : 0.062684, loss_ce: 0.027629
2022-01-21 21:31:14,719 iteration 2132 : loss : 0.052354, loss_ce: 0.018570
2022-01-21 21:31:15,947 iteration 2133 : loss : 0.053893, loss_ce: 0.020222
2022-01-21 21:31:17,180 iteration 2134 : loss : 0.066608, loss_ce: 0.022977
2022-01-21 21:31:18,384 iteration 2135 : loss : 0.038954, loss_ce: 0.013140
2022-01-21 21:31:19,590 iteration 2136 : loss : 0.037378, loss_ce: 0.014676
2022-01-21 21:31:20,778 iteration 2137 : loss : 0.068885, loss_ce: 0.020198
2022-01-21 21:31:21,933 iteration 2138 : loss : 0.040511, loss_ce: 0.013124
2022-01-21 21:31:23,042 iteration 2139 : loss : 0.033041, loss_ce: 0.014100
2022-01-21 21:31:24,198 iteration 2140 : loss : 0.036589, loss_ce: 0.012835
2022-01-21 21:31:25,388 iteration 2141 : loss : 0.044481, loss_ce: 0.017529
2022-01-21 21:31:26,571 iteration 2142 : loss : 0.056861, loss_ce: 0.025460
 32%|█████████▏                   | 126/400 [46:16<1:41:54, 22.32s/it]2022-01-21 21:31:27,840 iteration 2143 : loss : 0.041433, loss_ce: 0.012770
2022-01-21 21:31:29,019 iteration 2144 : loss : 0.073145, loss_ce: 0.022550
2022-01-21 21:31:30,124 iteration 2145 : loss : 0.031274, loss_ce: 0.016035
2022-01-21 21:31:31,447 iteration 2146 : loss : 0.062039, loss_ce: 0.024999
2022-01-21 21:31:32,655 iteration 2147 : loss : 0.037779, loss_ce: 0.016470
2022-01-21 21:31:33,848 iteration 2148 : loss : 0.047801, loss_ce: 0.021148
2022-01-21 21:31:35,056 iteration 2149 : loss : 0.048978, loss_ce: 0.018927
2022-01-21 21:31:36,305 iteration 2150 : loss : 0.058108, loss_ce: 0.022286
2022-01-21 21:31:37,546 iteration 2151 : loss : 0.050064, loss_ce: 0.018929
2022-01-21 21:31:38,684 iteration 2152 : loss : 0.033594, loss_ce: 0.013494
2022-01-21 21:31:39,843 iteration 2153 : loss : 0.046440, loss_ce: 0.012933
2022-01-21 21:31:40,956 iteration 2154 : loss : 0.029804, loss_ce: 0.014222
2022-01-21 21:31:42,101 iteration 2155 : loss : 0.051429, loss_ce: 0.026052
2022-01-21 21:31:43,327 iteration 2156 : loss : 0.051027, loss_ce: 0.019268
2022-01-21 21:31:44,527 iteration 2157 : loss : 0.052663, loss_ce: 0.026913
2022-01-21 21:31:45,685 iteration 2158 : loss : 0.040197, loss_ce: 0.017147
2022-01-21 21:31:46,920 iteration 2159 : loss : 0.054695, loss_ce: 0.018706
 32%|█████████▏                   | 127/400 [46:36<1:38:51, 21.73s/it]2022-01-21 21:31:48,095 iteration 2160 : loss : 0.031016, loss_ce: 0.010903
2022-01-21 21:31:49,304 iteration 2161 : loss : 0.038175, loss_ce: 0.015752
2022-01-21 21:31:50,487 iteration 2162 : loss : 0.039272, loss_ce: 0.016127
2022-01-21 21:31:51,576 iteration 2163 : loss : 0.041457, loss_ce: 0.012473
2022-01-21 21:31:52,768 iteration 2164 : loss : 0.041226, loss_ce: 0.017416
2022-01-21 21:31:53,953 iteration 2165 : loss : 0.027503, loss_ce: 0.008969
2022-01-21 21:31:55,199 iteration 2166 : loss : 0.052115, loss_ce: 0.027807
2022-01-21 21:31:56,389 iteration 2167 : loss : 0.041089, loss_ce: 0.018158
2022-01-21 21:31:57,570 iteration 2168 : loss : 0.037346, loss_ce: 0.014516
2022-01-21 21:31:58,775 iteration 2169 : loss : 0.033698, loss_ce: 0.013937
2022-01-21 21:31:59,934 iteration 2170 : loss : 0.038721, loss_ce: 0.011690
2022-01-21 21:32:01,111 iteration 2171 : loss : 0.023490, loss_ce: 0.008274
2022-01-21 21:32:02,200 iteration 2172 : loss : 0.041700, loss_ce: 0.019267
2022-01-21 21:32:03,374 iteration 2173 : loss : 0.041052, loss_ce: 0.013152
2022-01-21 21:32:04,596 iteration 2174 : loss : 0.039609, loss_ce: 0.015127
2022-01-21 21:32:05,732 iteration 2175 : loss : 0.051527, loss_ce: 0.017693
2022-01-21 21:32:06,883 iteration 2176 : loss : 0.032050, loss_ce: 0.014245
 32%|█████████▎                   | 128/400 [46:56<1:36:04, 21.19s/it]2022-01-21 21:32:08,180 iteration 2177 : loss : 0.048884, loss_ce: 0.017157
2022-01-21 21:32:09,312 iteration 2178 : loss : 0.029286, loss_ce: 0.012911
2022-01-21 21:32:10,483 iteration 2179 : loss : 0.037183, loss_ce: 0.014929
2022-01-21 21:32:11,700 iteration 2180 : loss : 0.031360, loss_ce: 0.009596
2022-01-21 21:32:12,859 iteration 2181 : loss : 0.037469, loss_ce: 0.011970
2022-01-21 21:32:14,027 iteration 2182 : loss : 0.036664, loss_ce: 0.012128
2022-01-21 21:32:15,166 iteration 2183 : loss : 0.037074, loss_ce: 0.011941
2022-01-21 21:32:16,287 iteration 2184 : loss : 0.048216, loss_ce: 0.022168
2022-01-21 21:32:17,382 iteration 2185 : loss : 0.036121, loss_ce: 0.014190
2022-01-21 21:32:18,661 iteration 2186 : loss : 0.088934, loss_ce: 0.033096
2022-01-21 21:32:19,782 iteration 2187 : loss : 0.035395, loss_ce: 0.017685
2022-01-21 21:32:20,998 iteration 2188 : loss : 0.041188, loss_ce: 0.015823
2022-01-21 21:32:22,136 iteration 2189 : loss : 0.040163, loss_ce: 0.017771
2022-01-21 21:32:23,369 iteration 2190 : loss : 0.042466, loss_ce: 0.015807
2022-01-21 21:32:24,475 iteration 2191 : loss : 0.030760, loss_ce: 0.012738
2022-01-21 21:32:25,647 iteration 2192 : loss : 0.037805, loss_ce: 0.013037
2022-01-21 21:32:26,899 iteration 2193 : loss : 0.042762, loss_ce: 0.019001
 32%|█████████▎                   | 129/400 [47:16<1:34:08, 20.84s/it]2022-01-21 21:32:28,102 iteration 2194 : loss : 0.040679, loss_ce: 0.015546
2022-01-21 21:32:29,249 iteration 2195 : loss : 0.039466, loss_ce: 0.014426
2022-01-21 21:32:30,440 iteration 2196 : loss : 0.039683, loss_ce: 0.020218
2022-01-21 21:32:31,652 iteration 2197 : loss : 0.061907, loss_ce: 0.026002
2022-01-21 21:32:32,810 iteration 2198 : loss : 0.028227, loss_ce: 0.013778
2022-01-21 21:32:34,138 iteration 2199 : loss : 0.035675, loss_ce: 0.015989
2022-01-21 21:32:35,316 iteration 2200 : loss : 0.045420, loss_ce: 0.016172
2022-01-21 21:32:36,505 iteration 2201 : loss : 0.058125, loss_ce: 0.017027
2022-01-21 21:32:37,678 iteration 2202 : loss : 0.099718, loss_ce: 0.032416
2022-01-21 21:32:38,899 iteration 2203 : loss : 0.033560, loss_ce: 0.011962
2022-01-21 21:32:40,126 iteration 2204 : loss : 0.045872, loss_ce: 0.016373
2022-01-21 21:32:41,209 iteration 2205 : loss : 0.040655, loss_ce: 0.016546
2022-01-21 21:32:42,318 iteration 2206 : loss : 0.030936, loss_ce: 0.014378
2022-01-21 21:32:43,497 iteration 2207 : loss : 0.064851, loss_ce: 0.028363
2022-01-21 21:32:44,661 iteration 2208 : loss : 0.044148, loss_ce: 0.018508
2022-01-21 21:32:45,900 iteration 2209 : loss : 0.052990, loss_ce: 0.016581
2022-01-21 21:32:45,900 Training Data Eval:
2022-01-21 21:32:51,564   Average segmentation loss on training set: 0.0324
2022-01-21 21:32:51,564 Validation Data Eval:
2022-01-21 21:32:53,522   Average segmentation loss on validation set: 0.0843
2022-01-21 21:32:54,714 iteration 2210 : loss : 0.054815, loss_ce: 0.020434
 32%|█████████▍                   | 130/400 [47:44<1:43:12, 22.93s/it]2022-01-21 21:32:55,959 iteration 2211 : loss : 0.038669, loss_ce: 0.019169
2022-01-21 21:32:57,062 iteration 2212 : loss : 0.032588, loss_ce: 0.011675
2022-01-21 21:32:58,188 iteration 2213 : loss : 0.031752, loss_ce: 0.012147
2022-01-21 21:32:59,378 iteration 2214 : loss : 0.040043, loss_ce: 0.018190
2022-01-21 21:33:00,538 iteration 2215 : loss : 0.034083, loss_ce: 0.013473
2022-01-21 21:33:01,680 iteration 2216 : loss : 0.038081, loss_ce: 0.015802
2022-01-21 21:33:02,785 iteration 2217 : loss : 0.050624, loss_ce: 0.022194
2022-01-21 21:33:03,969 iteration 2218 : loss : 0.052817, loss_ce: 0.021922
2022-01-21 21:33:05,135 iteration 2219 : loss : 0.039250, loss_ce: 0.016243
2022-01-21 21:33:06,323 iteration 2220 : loss : 0.027769, loss_ce: 0.013776
2022-01-21 21:33:07,561 iteration 2221 : loss : 0.046605, loss_ce: 0.020304
2022-01-21 21:33:08,704 iteration 2222 : loss : 0.054266, loss_ce: 0.017263
2022-01-21 21:33:09,999 iteration 2223 : loss : 0.091147, loss_ce: 0.032944
2022-01-21 21:33:11,148 iteration 2224 : loss : 0.082422, loss_ce: 0.021135
2022-01-21 21:33:12,315 iteration 2225 : loss : 0.046765, loss_ce: 0.019451
2022-01-21 21:33:13,617 iteration 2226 : loss : 0.044900, loss_ce: 0.016374
2022-01-21 21:33:14,850 iteration 2227 : loss : 0.047326, loss_ce: 0.012546
 33%|█████████▍                   | 131/400 [48:04<1:39:03, 22.10s/it]2022-01-21 21:33:16,131 iteration 2228 : loss : 0.058590, loss_ce: 0.022932
2022-01-21 21:33:17,334 iteration 2229 : loss : 0.048707, loss_ce: 0.020886
2022-01-21 21:33:18,487 iteration 2230 : loss : 0.046627, loss_ce: 0.018273
2022-01-21 21:33:19,613 iteration 2231 : loss : 0.031807, loss_ce: 0.016306
2022-01-21 21:33:20,743 iteration 2232 : loss : 0.033310, loss_ce: 0.010920
2022-01-21 21:33:21,883 iteration 2233 : loss : 0.032715, loss_ce: 0.010042
2022-01-21 21:33:23,081 iteration 2234 : loss : 0.058503, loss_ce: 0.018935
2022-01-21 21:33:24,200 iteration 2235 : loss : 0.049721, loss_ce: 0.026022
2022-01-21 21:33:25,333 iteration 2236 : loss : 0.035579, loss_ce: 0.015641
2022-01-21 21:33:26,503 iteration 2237 : loss : 0.039918, loss_ce: 0.016514
2022-01-21 21:33:27,646 iteration 2238 : loss : 0.051854, loss_ce: 0.017108
2022-01-21 21:33:28,848 iteration 2239 : loss : 0.040815, loss_ce: 0.013859
2022-01-21 21:33:29,957 iteration 2240 : loss : 0.047184, loss_ce: 0.017917
2022-01-21 21:33:31,164 iteration 2241 : loss : 0.041144, loss_ce: 0.014551
2022-01-21 21:33:32,281 iteration 2242 : loss : 0.046358, loss_ce: 0.021813
2022-01-21 21:33:33,408 iteration 2243 : loss : 0.037141, loss_ce: 0.010783
2022-01-21 21:33:34,566 iteration 2244 : loss : 0.026061, loss_ce: 0.009927
 33%|█████████▌                   | 132/400 [48:24<1:35:29, 21.38s/it]2022-01-21 21:33:35,766 iteration 2245 : loss : 0.030131, loss_ce: 0.011820
2022-01-21 21:33:36,962 iteration 2246 : loss : 0.040713, loss_ce: 0.013996
2022-01-21 21:33:38,142 iteration 2247 : loss : 0.050028, loss_ce: 0.020143
2022-01-21 21:33:39,231 iteration 2248 : loss : 0.026809, loss_ce: 0.011442
2022-01-21 21:33:40,459 iteration 2249 : loss : 0.045016, loss_ce: 0.017401
2022-01-21 21:33:41,754 iteration 2250 : loss : 0.045075, loss_ce: 0.019118
2022-01-21 21:33:42,864 iteration 2251 : loss : 0.030436, loss_ce: 0.013253
2022-01-21 21:33:44,061 iteration 2252 : loss : 0.034588, loss_ce: 0.013295
2022-01-21 21:33:45,215 iteration 2253 : loss : 0.050766, loss_ce: 0.015224
2022-01-21 21:33:46,440 iteration 2254 : loss : 0.037503, loss_ce: 0.016151
2022-01-21 21:33:47,660 iteration 2255 : loss : 0.040244, loss_ce: 0.019641
2022-01-21 21:33:48,926 iteration 2256 : loss : 0.054578, loss_ce: 0.019644
2022-01-21 21:33:50,083 iteration 2257 : loss : 0.031002, loss_ce: 0.010856
2022-01-21 21:33:51,257 iteration 2258 : loss : 0.040698, loss_ce: 0.015264
2022-01-21 21:33:52,474 iteration 2259 : loss : 0.051478, loss_ce: 0.017990
2022-01-21 21:33:53,664 iteration 2260 : loss : 0.048442, loss_ce: 0.017107
2022-01-21 21:33:54,803 iteration 2261 : loss : 0.058652, loss_ce: 0.013156
 33%|█████████▋                   | 133/400 [48:44<1:33:37, 21.04s/it]2022-01-21 21:33:56,160 iteration 2262 : loss : 0.042972, loss_ce: 0.017108
2022-01-21 21:33:57,361 iteration 2263 : loss : 0.036677, loss_ce: 0.016001
2022-01-21 21:33:58,576 iteration 2264 : loss : 0.038386, loss_ce: 0.012108
2022-01-21 21:33:59,779 iteration 2265 : loss : 0.037141, loss_ce: 0.014884
2022-01-21 21:34:00,958 iteration 2266 : loss : 0.041710, loss_ce: 0.014413
2022-01-21 21:34:02,145 iteration 2267 : loss : 0.041740, loss_ce: 0.013587
2022-01-21 21:34:03,248 iteration 2268 : loss : 0.054943, loss_ce: 0.020361
2022-01-21 21:34:04,441 iteration 2269 : loss : 0.047632, loss_ce: 0.018182
2022-01-21 21:34:05,572 iteration 2270 : loss : 0.041081, loss_ce: 0.016885
2022-01-21 21:34:06,714 iteration 2271 : loss : 0.062871, loss_ce: 0.037060
2022-01-21 21:34:07,841 iteration 2272 : loss : 0.046266, loss_ce: 0.012423
2022-01-21 21:34:09,059 iteration 2273 : loss : 0.055531, loss_ce: 0.020328
2022-01-21 21:34:10,177 iteration 2274 : loss : 0.037385, loss_ce: 0.011218
2022-01-21 21:34:11,332 iteration 2275 : loss : 0.044254, loss_ce: 0.019641
2022-01-21 21:34:12,518 iteration 2276 : loss : 0.052111, loss_ce: 0.015781
2022-01-21 21:34:13,671 iteration 2277 : loss : 0.042192, loss_ce: 0.017900
2022-01-21 21:34:14,843 iteration 2278 : loss : 0.039942, loss_ce: 0.016301
 34%|█████████▋                   | 134/400 [49:04<1:31:56, 20.74s/it]2022-01-21 21:34:16,165 iteration 2279 : loss : 0.060841, loss_ce: 0.027087
2022-01-21 21:34:17,372 iteration 2280 : loss : 0.038033, loss_ce: 0.016976
2022-01-21 21:34:18,481 iteration 2281 : loss : 0.031714, loss_ce: 0.011061
2022-01-21 21:34:19,760 iteration 2282 : loss : 0.047290, loss_ce: 0.017473
2022-01-21 21:34:20,897 iteration 2283 : loss : 0.045239, loss_ce: 0.019699
2022-01-21 21:34:22,172 iteration 2284 : loss : 0.078354, loss_ce: 0.027519
2022-01-21 21:34:23,314 iteration 2285 : loss : 0.041591, loss_ce: 0.016904
2022-01-21 21:34:24,470 iteration 2286 : loss : 0.035573, loss_ce: 0.011852
2022-01-21 21:34:25,684 iteration 2287 : loss : 0.039295, loss_ce: 0.011481
2022-01-21 21:34:26,789 iteration 2288 : loss : 0.035273, loss_ce: 0.013835
2022-01-21 21:34:27,978 iteration 2289 : loss : 0.045246, loss_ce: 0.015262
2022-01-21 21:34:29,161 iteration 2290 : loss : 0.037796, loss_ce: 0.012957
2022-01-21 21:34:30,327 iteration 2291 : loss : 0.038272, loss_ce: 0.012758
2022-01-21 21:34:31,558 iteration 2292 : loss : 0.045379, loss_ce: 0.015785
2022-01-21 21:34:32,670 iteration 2293 : loss : 0.057999, loss_ce: 0.023201
2022-01-21 21:34:33,832 iteration 2294 : loss : 0.035402, loss_ce: 0.015381
2022-01-21 21:34:33,832 Training Data Eval:
2022-01-21 21:34:39,546   Average segmentation loss on training set: 0.0269
2022-01-21 21:34:39,546 Validation Data Eval:
2022-01-21 21:34:41,520   Average segmentation loss on validation set: 0.0846
2022-01-21 21:34:42,686 iteration 2295 : loss : 0.039285, loss_ce: 0.013984
 34%|█████████▊                   | 135/400 [49:32<1:41:00, 22.87s/it]2022-01-21 21:34:43,915 iteration 2296 : loss : 0.036237, loss_ce: 0.012472
2022-01-21 21:34:45,092 iteration 2297 : loss : 0.035926, loss_ce: 0.009935
2022-01-21 21:34:46,378 iteration 2298 : loss : 0.050765, loss_ce: 0.017684
2022-01-21 21:34:47,547 iteration 2299 : loss : 0.066878, loss_ce: 0.017151
2022-01-21 21:34:48,801 iteration 2300 : loss : 0.052272, loss_ce: 0.018533
2022-01-21 21:34:49,965 iteration 2301 : loss : 0.056557, loss_ce: 0.026489
2022-01-21 21:34:51,127 iteration 2302 : loss : 0.037214, loss_ce: 0.017981
2022-01-21 21:34:52,263 iteration 2303 : loss : 0.045835, loss_ce: 0.013511
2022-01-21 21:34:53,356 iteration 2304 : loss : 0.055827, loss_ce: 0.021872
2022-01-21 21:34:54,560 iteration 2305 : loss : 0.041395, loss_ce: 0.014651
2022-01-21 21:34:55,689 iteration 2306 : loss : 0.041497, loss_ce: 0.013349
2022-01-21 21:34:56,798 iteration 2307 : loss : 0.030588, loss_ce: 0.010656
2022-01-21 21:34:57,946 iteration 2308 : loss : 0.033159, loss_ce: 0.015351
2022-01-21 21:34:59,143 iteration 2309 : loss : 0.041652, loss_ce: 0.015102
2022-01-21 21:35:00,343 iteration 2310 : loss : 0.046599, loss_ce: 0.019201
2022-01-21 21:35:01,604 iteration 2311 : loss : 0.034300, loss_ce: 0.012616
2022-01-21 21:35:02,795 iteration 2312 : loss : 0.033981, loss_ce: 0.013284
 34%|█████████▊                   | 136/400 [49:52<1:36:59, 22.04s/it]2022-01-21 21:35:04,027 iteration 2313 : loss : 0.033662, loss_ce: 0.015519
2022-01-21 21:35:05,154 iteration 2314 : loss : 0.038493, loss_ce: 0.016342
2022-01-21 21:35:06,336 iteration 2315 : loss : 0.036389, loss_ce: 0.013210
2022-01-21 21:35:07,549 iteration 2316 : loss : 0.044737, loss_ce: 0.019965
2022-01-21 21:35:08,649 iteration 2317 : loss : 0.040224, loss_ce: 0.016132
2022-01-21 21:35:09,889 iteration 2318 : loss : 0.032456, loss_ce: 0.015656
2022-01-21 21:35:11,142 iteration 2319 : loss : 0.057473, loss_ce: 0.017830
2022-01-21 21:35:12,279 iteration 2320 : loss : 0.039656, loss_ce: 0.019085
2022-01-21 21:35:13,449 iteration 2321 : loss : 0.039862, loss_ce: 0.012395
2022-01-21 21:35:14,633 iteration 2322 : loss : 0.033286, loss_ce: 0.013827
2022-01-21 21:35:15,881 iteration 2323 : loss : 0.077809, loss_ce: 0.026468
2022-01-21 21:35:17,075 iteration 2324 : loss : 0.033780, loss_ce: 0.010998
2022-01-21 21:35:18,253 iteration 2325 : loss : 0.042687, loss_ce: 0.021314
2022-01-21 21:35:19,468 iteration 2326 : loss : 0.046745, loss_ce: 0.025303
2022-01-21 21:35:20,626 iteration 2327 : loss : 0.033068, loss_ce: 0.012552
2022-01-21 21:35:21,890 iteration 2328 : loss : 0.039039, loss_ce: 0.014559
2022-01-21 21:35:23,059 iteration 2329 : loss : 0.041877, loss_ce: 0.015510
 34%|█████████▉                   | 137/400 [50:12<1:34:16, 21.51s/it]2022-01-21 21:35:24,272 iteration 2330 : loss : 0.034832, loss_ce: 0.013929
2022-01-21 21:35:25,403 iteration 2331 : loss : 0.037990, loss_ce: 0.010763
2022-01-21 21:35:26,655 iteration 2332 : loss : 0.045748, loss_ce: 0.021573
2022-01-21 21:35:27,771 iteration 2333 : loss : 0.033126, loss_ce: 0.017352
2022-01-21 21:35:28,939 iteration 2334 : loss : 0.055333, loss_ce: 0.016484
2022-01-21 21:35:30,219 iteration 2335 : loss : 0.059665, loss_ce: 0.022307
2022-01-21 21:35:31,365 iteration 2336 : loss : 0.044734, loss_ce: 0.020885
2022-01-21 21:35:32,543 iteration 2337 : loss : 0.038400, loss_ce: 0.012589
2022-01-21 21:35:33,760 iteration 2338 : loss : 0.038072, loss_ce: 0.015541
2022-01-21 21:35:34,938 iteration 2339 : loss : 0.068491, loss_ce: 0.025078
2022-01-21 21:35:36,150 iteration 2340 : loss : 0.041019, loss_ce: 0.016379
2022-01-21 21:35:37,333 iteration 2341 : loss : 0.052494, loss_ce: 0.018298
2022-01-21 21:35:38,541 iteration 2342 : loss : 0.023461, loss_ce: 0.008262
2022-01-21 21:35:39,730 iteration 2343 : loss : 0.029884, loss_ce: 0.011650
2022-01-21 21:35:40,830 iteration 2344 : loss : 0.031451, loss_ce: 0.011291
2022-01-21 21:35:41,963 iteration 2345 : loss : 0.040966, loss_ce: 0.015664
2022-01-21 21:35:43,067 iteration 2346 : loss : 0.041189, loss_ce: 0.013915
 34%|██████████                   | 138/400 [50:33<1:31:56, 21.06s/it]2022-01-21 21:35:44,343 iteration 2347 : loss : 0.043712, loss_ce: 0.014613
2022-01-21 21:35:45,492 iteration 2348 : loss : 0.033295, loss_ce: 0.010977
2022-01-21 21:35:46,686 iteration 2349 : loss : 0.042270, loss_ce: 0.021334
2022-01-21 21:35:47,791 iteration 2350 : loss : 0.032286, loss_ce: 0.014582
2022-01-21 21:35:48,979 iteration 2351 : loss : 0.055379, loss_ce: 0.015030
2022-01-21 21:35:50,239 iteration 2352 : loss : 0.045887, loss_ce: 0.019457
2022-01-21 21:35:51,345 iteration 2353 : loss : 0.032608, loss_ce: 0.014067
2022-01-21 21:35:52,529 iteration 2354 : loss : 0.040089, loss_ce: 0.011571
2022-01-21 21:35:53,654 iteration 2355 : loss : 0.038450, loss_ce: 0.020049
2022-01-21 21:35:54,920 iteration 2356 : loss : 0.055081, loss_ce: 0.018756
2022-01-21 21:35:56,162 iteration 2357 : loss : 0.038179, loss_ce: 0.014859
2022-01-21 21:35:57,424 iteration 2358 : loss : 0.060991, loss_ce: 0.023310
2022-01-21 21:35:58,659 iteration 2359 : loss : 0.054148, loss_ce: 0.013484
2022-01-21 21:35:59,746 iteration 2360 : loss : 0.069475, loss_ce: 0.015710
2022-01-21 21:36:00,867 iteration 2361 : loss : 0.029301, loss_ce: 0.010793
2022-01-21 21:36:02,041 iteration 2362 : loss : 0.051241, loss_ce: 0.021341
2022-01-21 21:36:03,213 iteration 2363 : loss : 0.036242, loss_ce: 0.012163
 35%|██████████                   | 139/400 [50:53<1:30:25, 20.79s/it]2022-01-21 21:36:04,447 iteration 2364 : loss : 0.059252, loss_ce: 0.025863
2022-01-21 21:36:05,569 iteration 2365 : loss : 0.040402, loss_ce: 0.015221
2022-01-21 21:36:06,758 iteration 2366 : loss : 0.032044, loss_ce: 0.012916
2022-01-21 21:36:07,910 iteration 2367 : loss : 0.044173, loss_ce: 0.012911
2022-01-21 21:36:09,175 iteration 2368 : loss : 0.050717, loss_ce: 0.013557
2022-01-21 21:36:10,343 iteration 2369 : loss : 0.047129, loss_ce: 0.015315
2022-01-21 21:36:11,474 iteration 2370 : loss : 0.028183, loss_ce: 0.009782
2022-01-21 21:36:12,659 iteration 2371 : loss : 0.048033, loss_ce: 0.019498
2022-01-21 21:36:13,767 iteration 2372 : loss : 0.027761, loss_ce: 0.013317
2022-01-21 21:36:14,944 iteration 2373 : loss : 0.029859, loss_ce: 0.011856
2022-01-21 21:36:16,173 iteration 2374 : loss : 0.033264, loss_ce: 0.012798
2022-01-21 21:36:17,291 iteration 2375 : loss : 0.039052, loss_ce: 0.012781
2022-01-21 21:36:18,516 iteration 2376 : loss : 0.039701, loss_ce: 0.015397
2022-01-21 21:36:19,681 iteration 2377 : loss : 0.029969, loss_ce: 0.008302
2022-01-21 21:36:20,952 iteration 2378 : loss : 0.048622, loss_ce: 0.025834
2022-01-21 21:36:22,160 iteration 2379 : loss : 0.049058, loss_ce: 0.016749
2022-01-21 21:36:22,161 Training Data Eval:
2022-01-21 21:36:27,828   Average segmentation loss on training set: 0.0283
2022-01-21 21:36:27,829 Validation Data Eval:
2022-01-21 21:36:29,796   Average segmentation loss on validation set: 0.0632
2022-01-21 21:36:34,047 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 21:36:35,406 iteration 2380 : loss : 0.032788, loss_ce: 0.013104
 35%|██████████▏                  | 140/400 [51:25<1:44:52, 24.20s/it]2022-01-21 21:36:36,591 iteration 2381 : loss : 0.038679, loss_ce: 0.012961
2022-01-21 21:36:37,821 iteration 2382 : loss : 0.039010, loss_ce: 0.018094
2022-01-21 21:36:39,052 iteration 2383 : loss : 0.052809, loss_ce: 0.024074
2022-01-21 21:36:40,235 iteration 2384 : loss : 0.042221, loss_ce: 0.014616
2022-01-21 21:36:41,425 iteration 2385 : loss : 0.045985, loss_ce: 0.021646
2022-01-21 21:36:42,678 iteration 2386 : loss : 0.046121, loss_ce: 0.015525
2022-01-21 21:36:43,827 iteration 2387 : loss : 0.057052, loss_ce: 0.018983
2022-01-21 21:36:45,025 iteration 2388 : loss : 0.027607, loss_ce: 0.011298
2022-01-21 21:36:46,160 iteration 2389 : loss : 0.038611, loss_ce: 0.017202
2022-01-21 21:36:47,343 iteration 2390 : loss : 0.027675, loss_ce: 0.011818
2022-01-21 21:36:48,481 iteration 2391 : loss : 0.039638, loss_ce: 0.013367
2022-01-21 21:36:49,599 iteration 2392 : loss : 0.037142, loss_ce: 0.014985
2022-01-21 21:36:50,717 iteration 2393 : loss : 0.040485, loss_ce: 0.019219
2022-01-21 21:36:51,898 iteration 2394 : loss : 0.050892, loss_ce: 0.010574
2022-01-21 21:36:53,201 iteration 2395 : loss : 0.047941, loss_ce: 0.015722
2022-01-21 21:36:54,459 iteration 2396 : loss : 0.027046, loss_ce: 0.010620
2022-01-21 21:36:55,644 iteration 2397 : loss : 0.056891, loss_ce: 0.017797
 35%|██████████▏                  | 141/400 [51:45<1:39:21, 23.02s/it]2022-01-21 21:36:56,989 iteration 2398 : loss : 0.047408, loss_ce: 0.025221
2022-01-21 21:36:58,109 iteration 2399 : loss : 0.030933, loss_ce: 0.011179
2022-01-21 21:36:59,263 iteration 2400 : loss : 0.041601, loss_ce: 0.012192
2022-01-21 21:37:00,446 iteration 2401 : loss : 0.041700, loss_ce: 0.016354
2022-01-21 21:37:01,596 iteration 2402 : loss : 0.046489, loss_ce: 0.018669
2022-01-21 21:37:02,765 iteration 2403 : loss : 0.029723, loss_ce: 0.011011
2022-01-21 21:37:03,907 iteration 2404 : loss : 0.035778, loss_ce: 0.017126
2022-01-21 21:37:05,078 iteration 2405 : loss : 0.038034, loss_ce: 0.014003
2022-01-21 21:37:06,320 iteration 2406 : loss : 0.041922, loss_ce: 0.018236
2022-01-21 21:37:07,446 iteration 2407 : loss : 0.031635, loss_ce: 0.011086
2022-01-21 21:37:08,618 iteration 2408 : loss : 0.035875, loss_ce: 0.014136
2022-01-21 21:37:09,794 iteration 2409 : loss : 0.039816, loss_ce: 0.014029
2022-01-21 21:37:11,002 iteration 2410 : loss : 0.052399, loss_ce: 0.014557
2022-01-21 21:37:12,131 iteration 2411 : loss : 0.027447, loss_ce: 0.008464
2022-01-21 21:37:13,359 iteration 2412 : loss : 0.047170, loss_ce: 0.018045
2022-01-21 21:37:14,623 iteration 2413 : loss : 0.046262, loss_ce: 0.022873
2022-01-21 21:37:15,852 iteration 2414 : loss : 0.041910, loss_ce: 0.017168
 36%|██████████▎                  | 142/400 [52:05<1:35:20, 22.17s/it]2022-01-21 21:37:17,101 iteration 2415 : loss : 0.031021, loss_ce: 0.009144
2022-01-21 21:37:18,277 iteration 2416 : loss : 0.036900, loss_ce: 0.017009
2022-01-21 21:37:19,479 iteration 2417 : loss : 0.033537, loss_ce: 0.010839
2022-01-21 21:37:20,686 iteration 2418 : loss : 0.039829, loss_ce: 0.012197
2022-01-21 21:37:21,870 iteration 2419 : loss : 0.038216, loss_ce: 0.020009
2022-01-21 21:37:22,998 iteration 2420 : loss : 0.030576, loss_ce: 0.011044
2022-01-21 21:37:24,281 iteration 2421 : loss : 0.064498, loss_ce: 0.018183
2022-01-21 21:37:25,505 iteration 2422 : loss : 0.038275, loss_ce: 0.012525
2022-01-21 21:37:26,700 iteration 2423 : loss : 0.038391, loss_ce: 0.016750
2022-01-21 21:37:27,832 iteration 2424 : loss : 0.034930, loss_ce: 0.011803
2022-01-21 21:37:29,083 iteration 2425 : loss : 0.040304, loss_ce: 0.018233
2022-01-21 21:37:30,260 iteration 2426 : loss : 0.032053, loss_ce: 0.012081
2022-01-21 21:37:31,545 iteration 2427 : loss : 0.063340, loss_ce: 0.018874
2022-01-21 21:37:32,804 iteration 2428 : loss : 0.041435, loss_ce: 0.016183
2022-01-21 21:37:34,081 iteration 2429 : loss : 0.049482, loss_ce: 0.021677
2022-01-21 21:37:35,284 iteration 2430 : loss : 0.035218, loss_ce: 0.014806
2022-01-21 21:37:36,431 iteration 2431 : loss : 0.024008, loss_ce: 0.010909
 36%|██████████▎                  | 143/400 [52:26<1:32:56, 21.70s/it]2022-01-21 21:37:37,717 iteration 2432 : loss : 0.040564, loss_ce: 0.017305
2022-01-21 21:37:38,913 iteration 2433 : loss : 0.053298, loss_ce: 0.016991
2022-01-21 21:37:40,103 iteration 2434 : loss : 0.021819, loss_ce: 0.005915
2022-01-21 21:37:41,408 iteration 2435 : loss : 0.040962, loss_ce: 0.023513
2022-01-21 21:37:42,512 iteration 2436 : loss : 0.032571, loss_ce: 0.013636
2022-01-21 21:37:43,630 iteration 2437 : loss : 0.027906, loss_ce: 0.010551
2022-01-21 21:37:44,941 iteration 2438 : loss : 0.033794, loss_ce: 0.013287
2022-01-21 21:37:46,149 iteration 2439 : loss : 0.038469, loss_ce: 0.015315
2022-01-21 21:37:47,320 iteration 2440 : loss : 0.026064, loss_ce: 0.008373
2022-01-21 21:37:48,477 iteration 2441 : loss : 0.033411, loss_ce: 0.009336
2022-01-21 21:37:49,621 iteration 2442 : loss : 0.033711, loss_ce: 0.010922
2022-01-21 21:37:50,739 iteration 2443 : loss : 0.029489, loss_ce: 0.012616
2022-01-21 21:37:51,949 iteration 2444 : loss : 0.027990, loss_ce: 0.009945
2022-01-21 21:37:53,049 iteration 2445 : loss : 0.080901, loss_ce: 0.014250
2022-01-21 21:37:54,317 iteration 2446 : loss : 0.032069, loss_ce: 0.011196
2022-01-21 21:37:55,574 iteration 2447 : loss : 0.042176, loss_ce: 0.018654
2022-01-21 21:37:56,769 iteration 2448 : loss : 0.033528, loss_ce: 0.009944
 36%|██████████▍                  | 144/400 [52:46<1:30:49, 21.29s/it]2022-01-21 21:37:57,984 iteration 2449 : loss : 0.047849, loss_ce: 0.018356
2022-01-21 21:37:59,240 iteration 2450 : loss : 0.050469, loss_ce: 0.017300
2022-01-21 21:38:00,481 iteration 2451 : loss : 0.048299, loss_ce: 0.018241
2022-01-21 21:38:01,598 iteration 2452 : loss : 0.023647, loss_ce: 0.010442
2022-01-21 21:38:02,765 iteration 2453 : loss : 0.053085, loss_ce: 0.015734
2022-01-21 21:38:03,977 iteration 2454 : loss : 0.040915, loss_ce: 0.020043
2022-01-21 21:38:05,187 iteration 2455 : loss : 0.054174, loss_ce: 0.025340
2022-01-21 21:38:06,505 iteration 2456 : loss : 0.089976, loss_ce: 0.036901
2022-01-21 21:38:07,692 iteration 2457 : loss : 0.045979, loss_ce: 0.014416
2022-01-21 21:38:08,960 iteration 2458 : loss : 0.033326, loss_ce: 0.011857
2022-01-21 21:38:10,101 iteration 2459 : loss : 0.051677, loss_ce: 0.014571
2022-01-21 21:38:11,275 iteration 2460 : loss : 0.034712, loss_ce: 0.011622
2022-01-21 21:38:12,477 iteration 2461 : loss : 0.042315, loss_ce: 0.013265
2022-01-21 21:38:13,639 iteration 2462 : loss : 0.033408, loss_ce: 0.013749
2022-01-21 21:38:14,842 iteration 2463 : loss : 0.046988, loss_ce: 0.015427
2022-01-21 21:38:16,107 iteration 2464 : loss : 0.065819, loss_ce: 0.026808
2022-01-21 21:38:16,107 Training Data Eval:
2022-01-21 21:38:21,799   Average segmentation loss on training set: 0.0275
2022-01-21 21:38:21,799 Validation Data Eval:
2022-01-21 21:38:23,766   Average segmentation loss on validation set: 0.0681
2022-01-21 21:38:24,913 iteration 2465 : loss : 0.034755, loss_ce: 0.011713
 36%|██████████▌                  | 145/400 [53:14<1:39:12, 23.34s/it]2022-01-21 21:38:26,132 iteration 2466 : loss : 0.028656, loss_ce: 0.010528
2022-01-21 21:38:27,353 iteration 2467 : loss : 0.036052, loss_ce: 0.020345
2022-01-21 21:38:28,492 iteration 2468 : loss : 0.033327, loss_ce: 0.014820
2022-01-21 21:38:29,599 iteration 2469 : loss : 0.022163, loss_ce: 0.010522
2022-01-21 21:38:30,818 iteration 2470 : loss : 0.047873, loss_ce: 0.018387
2022-01-21 21:38:32,046 iteration 2471 : loss : 0.042972, loss_ce: 0.018558
2022-01-21 21:38:33,328 iteration 2472 : loss : 0.042269, loss_ce: 0.015919
2022-01-21 21:38:34,443 iteration 2473 : loss : 0.035292, loss_ce: 0.013999
2022-01-21 21:38:35,655 iteration 2474 : loss : 0.039839, loss_ce: 0.014511
2022-01-21 21:38:36,773 iteration 2475 : loss : 0.026335, loss_ce: 0.011048
2022-01-21 21:38:38,030 iteration 2476 : loss : 0.048806, loss_ce: 0.013207
2022-01-21 21:38:39,206 iteration 2477 : loss : 0.039511, loss_ce: 0.015830
2022-01-21 21:38:40,377 iteration 2478 : loss : 0.033061, loss_ce: 0.009811
2022-01-21 21:38:41,671 iteration 2479 : loss : 0.033491, loss_ce: 0.010339
2022-01-21 21:38:42,925 iteration 2480 : loss : 0.051429, loss_ce: 0.020781
2022-01-21 21:38:44,085 iteration 2481 : loss : 0.040180, loss_ce: 0.016153
2022-01-21 21:38:45,272 iteration 2482 : loss : 0.057015, loss_ce: 0.022007
 36%|██████████▌                  | 146/400 [53:35<1:35:02, 22.45s/it]2022-01-21 21:38:46,532 iteration 2483 : loss : 0.030823, loss_ce: 0.012664
2022-01-21 21:38:47,770 iteration 2484 : loss : 0.034620, loss_ce: 0.012446
2022-01-21 21:38:49,047 iteration 2485 : loss : 0.040626, loss_ce: 0.016388
2022-01-21 21:38:50,187 iteration 2486 : loss : 0.036975, loss_ce: 0.015074
2022-01-21 21:38:51,353 iteration 2487 : loss : 0.046364, loss_ce: 0.016168
2022-01-21 21:38:52,585 iteration 2488 : loss : 0.043130, loss_ce: 0.013487
2022-01-21 21:38:53,834 iteration 2489 : loss : 0.043468, loss_ce: 0.017257
2022-01-21 21:38:54,989 iteration 2490 : loss : 0.032272, loss_ce: 0.013378
2022-01-21 21:38:56,183 iteration 2491 : loss : 0.035841, loss_ce: 0.015038
2022-01-21 21:38:57,337 iteration 2492 : loss : 0.049571, loss_ce: 0.021344
2022-01-21 21:38:58,492 iteration 2493 : loss : 0.036660, loss_ce: 0.012318
2022-01-21 21:38:59,624 iteration 2494 : loss : 0.037189, loss_ce: 0.014341
2022-01-21 21:39:00,789 iteration 2495 : loss : 0.044532, loss_ce: 0.013561
2022-01-21 21:39:02,021 iteration 2496 : loss : 0.061732, loss_ce: 0.020947
2022-01-21 21:39:03,190 iteration 2497 : loss : 0.040279, loss_ce: 0.016445
2022-01-21 21:39:04,288 iteration 2498 : loss : 0.044899, loss_ce: 0.020265
2022-01-21 21:39:05,533 iteration 2499 : loss : 0.036187, loss_ce: 0.017483
 37%|██████████▋                  | 147/400 [53:55<1:31:52, 21.79s/it]2022-01-21 21:39:06,796 iteration 2500 : loss : 0.051011, loss_ce: 0.020704
2022-01-21 21:39:07,932 iteration 2501 : loss : 0.028895, loss_ce: 0.009810
2022-01-21 21:39:09,099 iteration 2502 : loss : 0.050105, loss_ce: 0.016972
2022-01-21 21:39:10,287 iteration 2503 : loss : 0.033981, loss_ce: 0.014892
2022-01-21 21:39:11,497 iteration 2504 : loss : 0.041733, loss_ce: 0.014336
2022-01-21 21:39:12,624 iteration 2505 : loss : 0.035431, loss_ce: 0.015339
2022-01-21 21:39:13,767 iteration 2506 : loss : 0.049707, loss_ce: 0.012062
2022-01-21 21:39:14,980 iteration 2507 : loss : 0.030780, loss_ce: 0.010142
2022-01-21 21:39:16,143 iteration 2508 : loss : 0.035224, loss_ce: 0.017218
2022-01-21 21:39:17,380 iteration 2509 : loss : 0.042291, loss_ce: 0.018051
2022-01-21 21:39:18,539 iteration 2510 : loss : 0.038416, loss_ce: 0.013475
2022-01-21 21:39:19,663 iteration 2511 : loss : 0.042442, loss_ce: 0.020401
2022-01-21 21:39:20,897 iteration 2512 : loss : 0.044392, loss_ce: 0.016269
2022-01-21 21:39:22,044 iteration 2513 : loss : 0.031684, loss_ce: 0.012662
2022-01-21 21:39:23,258 iteration 2514 : loss : 0.043532, loss_ce: 0.013326
2022-01-21 21:39:24,415 iteration 2515 : loss : 0.030819, loss_ce: 0.015360
2022-01-21 21:39:25,749 iteration 2516 : loss : 0.045783, loss_ce: 0.015874
 37%|██████████▋                  | 148/400 [54:15<1:29:33, 21.32s/it]2022-01-21 21:39:27,015 iteration 2517 : loss : 0.029322, loss_ce: 0.010021
2022-01-21 21:39:28,240 iteration 2518 : loss : 0.047469, loss_ce: 0.013124
2022-01-21 21:39:29,358 iteration 2519 : loss : 0.025290, loss_ce: 0.008144
2022-01-21 21:39:30,581 iteration 2520 : loss : 0.037841, loss_ce: 0.016624
2022-01-21 21:39:31,779 iteration 2521 : loss : 0.031146, loss_ce: 0.012830
2022-01-21 21:39:32,987 iteration 2522 : loss : 0.052585, loss_ce: 0.019941
2022-01-21 21:39:34,177 iteration 2523 : loss : 0.041633, loss_ce: 0.012374
2022-01-21 21:39:35,417 iteration 2524 : loss : 0.035608, loss_ce: 0.015266
2022-01-21 21:39:36,570 iteration 2525 : loss : 0.049839, loss_ce: 0.014557
2022-01-21 21:39:37,692 iteration 2526 : loss : 0.033918, loss_ce: 0.012504
2022-01-21 21:39:38,892 iteration 2527 : loss : 0.037462, loss_ce: 0.017736
2022-01-21 21:39:40,069 iteration 2528 : loss : 0.038752, loss_ce: 0.017700
2022-01-21 21:39:41,286 iteration 2529 : loss : 0.044531, loss_ce: 0.016877
2022-01-21 21:39:42,401 iteration 2530 : loss : 0.036825, loss_ce: 0.015204
2022-01-21 21:39:43,661 iteration 2531 : loss : 0.033241, loss_ce: 0.010805
2022-01-21 21:39:44,927 iteration 2532 : loss : 0.037322, loss_ce: 0.018316
2022-01-21 21:39:46,053 iteration 2533 : loss : 0.036214, loss_ce: 0.009591
 37%|██████████▊                  | 149/400 [54:35<1:27:54, 21.01s/it]2022-01-21 21:39:47,308 iteration 2534 : loss : 0.036023, loss_ce: 0.013238
2022-01-21 21:39:48,397 iteration 2535 : loss : 0.037633, loss_ce: 0.015117
2022-01-21 21:39:49,535 iteration 2536 : loss : 0.029100, loss_ce: 0.013958
2022-01-21 21:39:50,806 iteration 2537 : loss : 0.047579, loss_ce: 0.022034
2022-01-21 21:39:51,871 iteration 2538 : loss : 0.029896, loss_ce: 0.010316
2022-01-21 21:39:52,979 iteration 2539 : loss : 0.026981, loss_ce: 0.010638
2022-01-21 21:39:54,151 iteration 2540 : loss : 0.041203, loss_ce: 0.019103
2022-01-21 21:39:55,392 iteration 2541 : loss : 0.050293, loss_ce: 0.019074
2022-01-21 21:39:56,570 iteration 2542 : loss : 0.047957, loss_ce: 0.015755
2022-01-21 21:39:57,839 iteration 2543 : loss : 0.042161, loss_ce: 0.012075
2022-01-21 21:39:59,099 iteration 2544 : loss : 0.045407, loss_ce: 0.019573
2022-01-21 21:40:00,243 iteration 2545 : loss : 0.033081, loss_ce: 0.016079
2022-01-21 21:40:01,606 iteration 2546 : loss : 0.052224, loss_ce: 0.018923
2022-01-21 21:40:02,848 iteration 2547 : loss : 0.060457, loss_ce: 0.018939
2022-01-21 21:40:04,108 iteration 2548 : loss : 0.043429, loss_ce: 0.018113
2022-01-21 21:40:05,284 iteration 2549 : loss : 0.035059, loss_ce: 0.011564
2022-01-21 21:40:05,284 Training Data Eval:
2022-01-21 21:40:10,946   Average segmentation loss on training set: 0.0245
2022-01-21 21:40:10,947 Validation Data Eval:
2022-01-21 21:40:12,910   Average segmentation loss on validation set: 0.0775
2022-01-21 21:40:14,085 iteration 2550 : loss : 0.048927, loss_ce: 0.012160
 38%|██████████▉                  | 150/400 [55:04<1:36:19, 23.12s/it]2022-01-21 21:40:15,336 iteration 2551 : loss : 0.035547, loss_ce: 0.012942
2022-01-21 21:40:16,529 iteration 2552 : loss : 0.023549, loss_ce: 0.009585
2022-01-21 21:40:17,725 iteration 2553 : loss : 0.033269, loss_ce: 0.011890
2022-01-21 21:40:18,895 iteration 2554 : loss : 0.028475, loss_ce: 0.011641
2022-01-21 21:40:20,052 iteration 2555 : loss : 0.029959, loss_ce: 0.012217
2022-01-21 21:40:21,234 iteration 2556 : loss : 0.061476, loss_ce: 0.030720
2022-01-21 21:40:22,407 iteration 2557 : loss : 0.031308, loss_ce: 0.012822
2022-01-21 21:40:23,568 iteration 2558 : loss : 0.032091, loss_ce: 0.010200
2022-01-21 21:40:24,686 iteration 2559 : loss : 0.047271, loss_ce: 0.022274
2022-01-21 21:40:25,951 iteration 2560 : loss : 0.034020, loss_ce: 0.011098
2022-01-21 21:40:27,131 iteration 2561 : loss : 0.051360, loss_ce: 0.019229
2022-01-21 21:40:28,333 iteration 2562 : loss : 0.027026, loss_ce: 0.010392
2022-01-21 21:40:29,449 iteration 2563 : loss : 0.033698, loss_ce: 0.014819
2022-01-21 21:40:30,584 iteration 2564 : loss : 0.037128, loss_ce: 0.018567
2022-01-21 21:40:31,715 iteration 2565 : loss : 0.023307, loss_ce: 0.009450
2022-01-21 21:40:32,811 iteration 2566 : loss : 0.026245, loss_ce: 0.009758
2022-01-21 21:40:33,968 iteration 2567 : loss : 0.071947, loss_ce: 0.022329
 38%|██████████▉                  | 151/400 [55:23<1:31:55, 22.15s/it]2022-01-21 21:40:35,183 iteration 2568 : loss : 0.032762, loss_ce: 0.014527
2022-01-21 21:40:36,347 iteration 2569 : loss : 0.021917, loss_ce: 0.008667
2022-01-21 21:40:37,607 iteration 2570 : loss : 0.044908, loss_ce: 0.012803
2022-01-21 21:40:38,779 iteration 2571 : loss : 0.037283, loss_ce: 0.011469
2022-01-21 21:40:39,887 iteration 2572 : loss : 0.042722, loss_ce: 0.013312
2022-01-21 21:40:41,040 iteration 2573 : loss : 0.028936, loss_ce: 0.011152
2022-01-21 21:40:42,168 iteration 2574 : loss : 0.032975, loss_ce: 0.013509
2022-01-21 21:40:43,277 iteration 2575 : loss : 0.027586, loss_ce: 0.009912
2022-01-21 21:40:44,387 iteration 2576 : loss : 0.028128, loss_ce: 0.008071
2022-01-21 21:40:45,585 iteration 2577 : loss : 0.048785, loss_ce: 0.027963
2022-01-21 21:40:46,739 iteration 2578 : loss : 0.026331, loss_ce: 0.008655
2022-01-21 21:40:47,921 iteration 2579 : loss : 0.029852, loss_ce: 0.010548
2022-01-21 21:40:49,043 iteration 2580 : loss : 0.034143, loss_ce: 0.009643
2022-01-21 21:40:50,243 iteration 2581 : loss : 0.041835, loss_ce: 0.018655
2022-01-21 21:40:51,476 iteration 2582 : loss : 0.026719, loss_ce: 0.012194
2022-01-21 21:40:52,623 iteration 2583 : loss : 0.031861, loss_ce: 0.014677
2022-01-21 21:40:53,778 iteration 2584 : loss : 0.035100, loss_ce: 0.010526
 38%|███████████                  | 152/400 [55:43<1:28:39, 21.45s/it]2022-01-21 21:40:55,014 iteration 2585 : loss : 0.037481, loss_ce: 0.012204
2022-01-21 21:40:56,361 iteration 2586 : loss : 0.048657, loss_ce: 0.016572
2022-01-21 21:40:57,625 iteration 2587 : loss : 0.044566, loss_ce: 0.015009
2022-01-21 21:40:58,812 iteration 2588 : loss : 0.049062, loss_ce: 0.018549
2022-01-21 21:40:59,931 iteration 2589 : loss : 0.055440, loss_ce: 0.014989
2022-01-21 21:41:01,152 iteration 2590 : loss : 0.039132, loss_ce: 0.012811
2022-01-21 21:41:02,332 iteration 2591 : loss : 0.026744, loss_ce: 0.011782
2022-01-21 21:41:03,471 iteration 2592 : loss : 0.029720, loss_ce: 0.014354
2022-01-21 21:41:04,555 iteration 2593 : loss : 0.043084, loss_ce: 0.017758
2022-01-21 21:41:05,731 iteration 2594 : loss : 0.056804, loss_ce: 0.024094
2022-01-21 21:41:06,850 iteration 2595 : loss : 0.046262, loss_ce: 0.013176
2022-01-21 21:41:07,994 iteration 2596 : loss : 0.041497, loss_ce: 0.012385
2022-01-21 21:41:09,155 iteration 2597 : loss : 0.036016, loss_ce: 0.011573
2022-01-21 21:41:10,332 iteration 2598 : loss : 0.030690, loss_ce: 0.012869
2022-01-21 21:41:11,520 iteration 2599 : loss : 0.029348, loss_ce: 0.011086
2022-01-21 21:41:12,662 iteration 2600 : loss : 0.032665, loss_ce: 0.012185
2022-01-21 21:41:13,780 iteration 2601 : loss : 0.039105, loss_ce: 0.013229
 38%|███████████                  | 153/400 [56:03<1:26:30, 21.02s/it]2022-01-21 21:41:14,991 iteration 2602 : loss : 0.042400, loss_ce: 0.013268
2022-01-21 21:41:16,185 iteration 2603 : loss : 0.056841, loss_ce: 0.012881
2022-01-21 21:41:17,359 iteration 2604 : loss : 0.028270, loss_ce: 0.009655
2022-01-21 21:41:18,530 iteration 2605 : loss : 0.044400, loss_ce: 0.014902
2022-01-21 21:41:19,713 iteration 2606 : loss : 0.038941, loss_ce: 0.014327
2022-01-21 21:41:20,907 iteration 2607 : loss : 0.037629, loss_ce: 0.015897
2022-01-21 21:41:22,039 iteration 2608 : loss : 0.042690, loss_ce: 0.015087
2022-01-21 21:41:23,254 iteration 2609 : loss : 0.037290, loss_ce: 0.018480
2022-01-21 21:41:24,454 iteration 2610 : loss : 0.038186, loss_ce: 0.012363
2022-01-21 21:41:25,686 iteration 2611 : loss : 0.045216, loss_ce: 0.017546
2022-01-21 21:41:26,898 iteration 2612 : loss : 0.053824, loss_ce: 0.018707
2022-01-21 21:41:28,151 iteration 2613 : loss : 0.037894, loss_ce: 0.014589
2022-01-21 21:41:29,375 iteration 2614 : loss : 0.030039, loss_ce: 0.011460
2022-01-21 21:41:30,572 iteration 2615 : loss : 0.034258, loss_ce: 0.015505
2022-01-21 21:41:31,820 iteration 2616 : loss : 0.037220, loss_ce: 0.015983
2022-01-21 21:41:33,015 iteration 2617 : loss : 0.038764, loss_ce: 0.016183
2022-01-21 21:41:34,241 iteration 2618 : loss : 0.039434, loss_ce: 0.011714
 38%|███████████▏                 | 154/400 [56:24<1:25:27, 20.84s/it]2022-01-21 21:41:35,589 iteration 2619 : loss : 0.038647, loss_ce: 0.014886
2022-01-21 21:41:36,800 iteration 2620 : loss : 0.053660, loss_ce: 0.020703
2022-01-21 21:41:37,890 iteration 2621 : loss : 0.031609, loss_ce: 0.013057
2022-01-21 21:41:39,089 iteration 2622 : loss : 0.049196, loss_ce: 0.017791
2022-01-21 21:41:40,232 iteration 2623 : loss : 0.028487, loss_ce: 0.011195
2022-01-21 21:41:41,456 iteration 2624 : loss : 0.047273, loss_ce: 0.018390
2022-01-21 21:41:42,693 iteration 2625 : loss : 0.031706, loss_ce: 0.012604
2022-01-21 21:41:43,901 iteration 2626 : loss : 0.034892, loss_ce: 0.014663
2022-01-21 21:41:45,014 iteration 2627 : loss : 0.033234, loss_ce: 0.016967
2022-01-21 21:41:46,140 iteration 2628 : loss : 0.034745, loss_ce: 0.012551
2022-01-21 21:41:47,236 iteration 2629 : loss : 0.030323, loss_ce: 0.007443
2022-01-21 21:41:48,444 iteration 2630 : loss : 0.072192, loss_ce: 0.013170
2022-01-21 21:41:49,561 iteration 2631 : loss : 0.048375, loss_ce: 0.023223
2022-01-21 21:41:50,685 iteration 2632 : loss : 0.033032, loss_ce: 0.010826
2022-01-21 21:41:51,867 iteration 2633 : loss : 0.021648, loss_ce: 0.007458
2022-01-21 21:41:53,024 iteration 2634 : loss : 0.028421, loss_ce: 0.009153
2022-01-21 21:41:53,024 Training Data Eval:
2022-01-21 21:41:58,687   Average segmentation loss on training set: 0.0231
2022-01-21 21:41:58,687 Validation Data Eval:
2022-01-21 21:42:00,639   Average segmentation loss on validation set: 0.0580
2022-01-21 21:42:04,789 Found new lowest validation loss at iteration 2634! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 21:42:05,983 iteration 2635 : loss : 0.035634, loss_ce: 0.014437
 39%|███████████▏                 | 155/400 [56:55<1:38:27, 24.11s/it]2022-01-21 21:42:07,145 iteration 2636 : loss : 0.023363, loss_ce: 0.007868
2022-01-21 21:42:08,297 iteration 2637 : loss : 0.037531, loss_ce: 0.015709
2022-01-21 21:42:09,545 iteration 2638 : loss : 0.044213, loss_ce: 0.017109
2022-01-21 21:42:10,702 iteration 2639 : loss : 0.032245, loss_ce: 0.011705
2022-01-21 21:42:11,894 iteration 2640 : loss : 0.041489, loss_ce: 0.016024
2022-01-21 21:42:13,055 iteration 2641 : loss : 0.032556, loss_ce: 0.011814
2022-01-21 21:42:14,249 iteration 2642 : loss : 0.026648, loss_ce: 0.009194
2022-01-21 21:42:15,401 iteration 2643 : loss : 0.036672, loss_ce: 0.014894
2022-01-21 21:42:16,593 iteration 2644 : loss : 0.047836, loss_ce: 0.029684
2022-01-21 21:42:17,712 iteration 2645 : loss : 0.028454, loss_ce: 0.012310
2022-01-21 21:42:18,846 iteration 2646 : loss : 0.031445, loss_ce: 0.009212
2022-01-21 21:42:20,087 iteration 2647 : loss : 0.048162, loss_ce: 0.021472
2022-01-21 21:42:21,230 iteration 2648 : loss : 0.040748, loss_ce: 0.013815
2022-01-21 21:42:22,410 iteration 2649 : loss : 0.035088, loss_ce: 0.011367
2022-01-21 21:42:23,693 iteration 2650 : loss : 0.042284, loss_ce: 0.016911
2022-01-21 21:42:24,851 iteration 2651 : loss : 0.036493, loss_ce: 0.013933
2022-01-21 21:42:26,099 iteration 2652 : loss : 0.029846, loss_ce: 0.011737
 39%|███████████▎                 | 156/400 [57:16<1:33:10, 22.91s/it]2022-01-21 21:42:27,368 iteration 2653 : loss : 0.051211, loss_ce: 0.017789
2022-01-21 21:42:28,492 iteration 2654 : loss : 0.024877, loss_ce: 0.010546
2022-01-21 21:42:29,648 iteration 2655 : loss : 0.028943, loss_ce: 0.012337
2022-01-21 21:42:30,795 iteration 2656 : loss : 0.026839, loss_ce: 0.013583
2022-01-21 21:42:31,993 iteration 2657 : loss : 0.029976, loss_ce: 0.012543
2022-01-21 21:42:33,226 iteration 2658 : loss : 0.060679, loss_ce: 0.021185
2022-01-21 21:42:34,426 iteration 2659 : loss : 0.034424, loss_ce: 0.012414
2022-01-21 21:42:35,687 iteration 2660 : loss : 0.051340, loss_ce: 0.022396
2022-01-21 21:42:36,781 iteration 2661 : loss : 0.031178, loss_ce: 0.009973
2022-01-21 21:42:38,016 iteration 2662 : loss : 0.036799, loss_ce: 0.012691
2022-01-21 21:42:39,238 iteration 2663 : loss : 0.057213, loss_ce: 0.019775
2022-01-21 21:42:40,354 iteration 2664 : loss : 0.040698, loss_ce: 0.013973
2022-01-21 21:42:41,491 iteration 2665 : loss : 0.022612, loss_ce: 0.008615
2022-01-21 21:42:42,738 iteration 2666 : loss : 0.043127, loss_ce: 0.014623
2022-01-21 21:42:43,874 iteration 2667 : loss : 0.031776, loss_ce: 0.012906
2022-01-21 21:42:45,115 iteration 2668 : loss : 0.031320, loss_ce: 0.013827
2022-01-21 21:42:46,273 iteration 2669 : loss : 0.034020, loss_ce: 0.009504
 39%|███████████▍                 | 157/400 [57:36<1:29:28, 22.09s/it]2022-01-21 21:42:47,420 iteration 2670 : loss : 0.027922, loss_ce: 0.011564
2022-01-21 21:42:48,524 iteration 2671 : loss : 0.029692, loss_ce: 0.011119
2022-01-21 21:42:49,667 iteration 2672 : loss : 0.033034, loss_ce: 0.011238
2022-01-21 21:42:50,801 iteration 2673 : loss : 0.030842, loss_ce: 0.009293
2022-01-21 21:42:51,989 iteration 2674 : loss : 0.036217, loss_ce: 0.011502
2022-01-21 21:42:53,207 iteration 2675 : loss : 0.024564, loss_ce: 0.008615
2022-01-21 21:42:54,365 iteration 2676 : loss : 0.032480, loss_ce: 0.010981
2022-01-21 21:42:55,532 iteration 2677 : loss : 0.026503, loss_ce: 0.009820
2022-01-21 21:42:56,645 iteration 2678 : loss : 0.031438, loss_ce: 0.014669
2022-01-21 21:42:57,818 iteration 2679 : loss : 0.033346, loss_ce: 0.013281
2022-01-21 21:42:59,053 iteration 2680 : loss : 0.034235, loss_ce: 0.015767
2022-01-21 21:43:00,228 iteration 2681 : loss : 0.044376, loss_ce: 0.014888
2022-01-21 21:43:01,442 iteration 2682 : loss : 0.033841, loss_ce: 0.012620
2022-01-21 21:43:02,588 iteration 2683 : loss : 0.034822, loss_ce: 0.015026
2022-01-21 21:43:03,775 iteration 2684 : loss : 0.029132, loss_ce: 0.012983
2022-01-21 21:43:04,992 iteration 2685 : loss : 0.031722, loss_ce: 0.013630
2022-01-21 21:43:06,202 iteration 2686 : loss : 0.075637, loss_ce: 0.024229
 40%|███████████▍                 | 158/400 [57:56<1:26:29, 21.44s/it]2022-01-21 21:43:07,388 iteration 2687 : loss : 0.040638, loss_ce: 0.017092
2022-01-21 21:43:08,545 iteration 2688 : loss : 0.026506, loss_ce: 0.009906
2022-01-21 21:43:09,675 iteration 2689 : loss : 0.035160, loss_ce: 0.013108
2022-01-21 21:43:10,893 iteration 2690 : loss : 0.053301, loss_ce: 0.014593
2022-01-21 21:43:12,023 iteration 2691 : loss : 0.027727, loss_ce: 0.012855
2022-01-21 21:43:13,153 iteration 2692 : loss : 0.039667, loss_ce: 0.014344
2022-01-21 21:43:14,278 iteration 2693 : loss : 0.029017, loss_ce: 0.011968
2022-01-21 21:43:15,465 iteration 2694 : loss : 0.045471, loss_ce: 0.022067
2022-01-21 21:43:16,634 iteration 2695 : loss : 0.039855, loss_ce: 0.021241
2022-01-21 21:43:17,799 iteration 2696 : loss : 0.031817, loss_ce: 0.014430
2022-01-21 21:43:18,936 iteration 2697 : loss : 0.040515, loss_ce: 0.018037
2022-01-21 21:43:20,071 iteration 2698 : loss : 0.034086, loss_ce: 0.009783
2022-01-21 21:43:21,223 iteration 2699 : loss : 0.047152, loss_ce: 0.020624
2022-01-21 21:43:22,352 iteration 2700 : loss : 0.037252, loss_ce: 0.012737
2022-01-21 21:43:23,634 iteration 2701 : loss : 0.052867, loss_ce: 0.015036
2022-01-21 21:43:24,849 iteration 2702 : loss : 0.029627, loss_ce: 0.014382
2022-01-21 21:43:26,093 iteration 2703 : loss : 0.037849, loss_ce: 0.013190
 40%|███████████▌                 | 159/400 [58:16<1:24:15, 20.98s/it]2022-01-21 21:43:27,377 iteration 2704 : loss : 0.056176, loss_ce: 0.018588
2022-01-21 21:43:28,511 iteration 2705 : loss : 0.030552, loss_ce: 0.013822
2022-01-21 21:43:29,741 iteration 2706 : loss : 0.071220, loss_ce: 0.033536
2022-01-21 21:43:30,898 iteration 2707 : loss : 0.031641, loss_ce: 0.015975
2022-01-21 21:43:32,105 iteration 2708 : loss : 0.025034, loss_ce: 0.010527
2022-01-21 21:43:33,277 iteration 2709 : loss : 0.029096, loss_ce: 0.012865
2022-01-21 21:43:34,389 iteration 2710 : loss : 0.033084, loss_ce: 0.015018
2022-01-21 21:43:35,580 iteration 2711 : loss : 0.026990, loss_ce: 0.009045
2022-01-21 21:43:36,791 iteration 2712 : loss : 0.031934, loss_ce: 0.009973
2022-01-21 21:43:37,924 iteration 2713 : loss : 0.028509, loss_ce: 0.012699
2022-01-21 21:43:39,162 iteration 2714 : loss : 0.030033, loss_ce: 0.011362
2022-01-21 21:43:40,379 iteration 2715 : loss : 0.034028, loss_ce: 0.009965
2022-01-21 21:43:41,603 iteration 2716 : loss : 0.036558, loss_ce: 0.011628
2022-01-21 21:43:42,776 iteration 2717 : loss : 0.041110, loss_ce: 0.016964
2022-01-21 21:43:43,998 iteration 2718 : loss : 0.056138, loss_ce: 0.015272
2022-01-21 21:43:45,155 iteration 2719 : loss : 0.032454, loss_ce: 0.011147
2022-01-21 21:43:45,155 Training Data Eval:
2022-01-21 21:43:50,867   Average segmentation loss on training set: 0.0228
2022-01-21 21:43:50,867 Validation Data Eval:
2022-01-21 21:43:52,832   Average segmentation loss on validation set: 0.0730
2022-01-21 21:43:53,963 iteration 2720 : loss : 0.028586, loss_ce: 0.009208
 40%|███████████▌                 | 160/400 [58:43<1:32:10, 23.04s/it]2022-01-21 21:43:55,198 iteration 2721 : loss : 0.031905, loss_ce: 0.013750
2022-01-21 21:43:56,382 iteration 2722 : loss : 0.079635, loss_ce: 0.038828
2022-01-21 21:43:57,593 iteration 2723 : loss : 0.025159, loss_ce: 0.009646
2022-01-21 21:43:58,788 iteration 2724 : loss : 0.045084, loss_ce: 0.018808
2022-01-21 21:43:59,949 iteration 2725 : loss : 0.037525, loss_ce: 0.011567
2022-01-21 21:44:01,258 iteration 2726 : loss : 0.070180, loss_ce: 0.026412
2022-01-21 21:44:02,497 iteration 2727 : loss : 0.044116, loss_ce: 0.017998
2022-01-21 21:44:03,682 iteration 2728 : loss : 0.030106, loss_ce: 0.011262
2022-01-21 21:44:04,855 iteration 2729 : loss : 0.051967, loss_ce: 0.021772
2022-01-21 21:44:05,969 iteration 2730 : loss : 0.029088, loss_ce: 0.011320
2022-01-21 21:44:07,157 iteration 2731 : loss : 0.033789, loss_ce: 0.013262
2022-01-21 21:44:08,400 iteration 2732 : loss : 0.039112, loss_ce: 0.016618
2022-01-21 21:44:09,602 iteration 2733 : loss : 0.030849, loss_ce: 0.011630
2022-01-21 21:44:10,782 iteration 2734 : loss : 0.036040, loss_ce: 0.012173
2022-01-21 21:44:12,057 iteration 2735 : loss : 0.037359, loss_ce: 0.011791
2022-01-21 21:44:13,232 iteration 2736 : loss : 0.024964, loss_ce: 0.011301
2022-01-21 21:44:14,449 iteration 2737 : loss : 0.038255, loss_ce: 0.013084
 40%|███████████▋                 | 161/400 [59:04<1:28:44, 22.28s/it]2022-01-21 21:44:15,614 iteration 2738 : loss : 0.022035, loss_ce: 0.008452
2022-01-21 21:44:16,865 iteration 2739 : loss : 0.029440, loss_ce: 0.012747
2022-01-21 21:44:18,125 iteration 2740 : loss : 0.035070, loss_ce: 0.016092
2022-01-21 21:44:19,281 iteration 2741 : loss : 0.027292, loss_ce: 0.008929
2022-01-21 21:44:20,400 iteration 2742 : loss : 0.035039, loss_ce: 0.011441
2022-01-21 21:44:21,598 iteration 2743 : loss : 0.028224, loss_ce: 0.008858
2022-01-21 21:44:22,910 iteration 2744 : loss : 0.047261, loss_ce: 0.016911
2022-01-21 21:44:24,086 iteration 2745 : loss : 0.044346, loss_ce: 0.015273
2022-01-21 21:44:25,249 iteration 2746 : loss : 0.030407, loss_ce: 0.010207
2022-01-21 21:44:26,538 iteration 2747 : loss : 0.045869, loss_ce: 0.019977
2022-01-21 21:44:27,689 iteration 2748 : loss : 0.023890, loss_ce: 0.009363
2022-01-21 21:44:28,883 iteration 2749 : loss : 0.028783, loss_ce: 0.012510
2022-01-21 21:44:30,049 iteration 2750 : loss : 0.034072, loss_ce: 0.009918
2022-01-21 21:44:31,207 iteration 2751 : loss : 0.035875, loss_ce: 0.010834
2022-01-21 21:44:32,353 iteration 2752 : loss : 0.030930, loss_ce: 0.012586
2022-01-21 21:44:33,510 iteration 2753 : loss : 0.026444, loss_ce: 0.010852
2022-01-21 21:44:34,697 iteration 2754 : loss : 0.042019, loss_ce: 0.013685
 40%|███████████▋                 | 162/400 [59:24<1:25:57, 21.67s/it]2022-01-21 21:44:35,917 iteration 2755 : loss : 0.031427, loss_ce: 0.011346
2022-01-21 21:44:37,115 iteration 2756 : loss : 0.042958, loss_ce: 0.019948
2022-01-21 21:44:38,257 iteration 2757 : loss : 0.024368, loss_ce: 0.010159
2022-01-21 21:44:39,419 iteration 2758 : loss : 0.030443, loss_ce: 0.011314
2022-01-21 21:44:40,586 iteration 2759 : loss : 0.024876, loss_ce: 0.009151
2022-01-21 21:44:41,804 iteration 2760 : loss : 0.045966, loss_ce: 0.011558
2022-01-21 21:44:42,982 iteration 2761 : loss : 0.023670, loss_ce: 0.008105
2022-01-21 21:44:44,152 iteration 2762 : loss : 0.036270, loss_ce: 0.014649
2022-01-21 21:44:45,316 iteration 2763 : loss : 0.038132, loss_ce: 0.014497
2022-01-21 21:44:46,431 iteration 2764 : loss : 0.028126, loss_ce: 0.012427
2022-01-21 21:44:47,604 iteration 2765 : loss : 0.041167, loss_ce: 0.019268
2022-01-21 21:44:48,830 iteration 2766 : loss : 0.035770, loss_ce: 0.011931
2022-01-21 21:44:49,946 iteration 2767 : loss : 0.027909, loss_ce: 0.006756
2022-01-21 21:44:51,239 iteration 2768 : loss : 0.028041, loss_ce: 0.010758
2022-01-21 21:44:52,399 iteration 2769 : loss : 0.028927, loss_ce: 0.009799
2022-01-21 21:44:53,521 iteration 2770 : loss : 0.029158, loss_ce: 0.013476
2022-01-21 21:44:54,683 iteration 2771 : loss : 0.032265, loss_ce: 0.014179
 41%|███████████▊                 | 163/400 [59:44<1:23:36, 21.17s/it]2022-01-21 21:44:55,974 iteration 2772 : loss : 0.040432, loss_ce: 0.012693
2022-01-21 21:44:57,087 iteration 2773 : loss : 0.040877, loss_ce: 0.013378
2022-01-21 21:44:58,242 iteration 2774 : loss : 0.029453, loss_ce: 0.011867
2022-01-21 21:44:59,415 iteration 2775 : loss : 0.028688, loss_ce: 0.011380
2022-01-21 21:45:00,594 iteration 2776 : loss : 0.029960, loss_ce: 0.012762
2022-01-21 21:45:01,809 iteration 2777 : loss : 0.032644, loss_ce: 0.012941
2022-01-21 21:45:02,923 iteration 2778 : loss : 0.027015, loss_ce: 0.011687
2022-01-21 21:45:04,130 iteration 2779 : loss : 0.042743, loss_ce: 0.017648
2022-01-21 21:45:05,383 iteration 2780 : loss : 0.035855, loss_ce: 0.013764
2022-01-21 21:45:06,485 iteration 2781 : loss : 0.029583, loss_ce: 0.011608
2022-01-21 21:45:07,689 iteration 2782 : loss : 0.034926, loss_ce: 0.012807
2022-01-21 21:45:08,941 iteration 2783 : loss : 0.050778, loss_ce: 0.018671
2022-01-21 21:45:10,216 iteration 2784 : loss : 0.030336, loss_ce: 0.015282
2022-01-21 21:45:11,337 iteration 2785 : loss : 0.030046, loss_ce: 0.010190
2022-01-21 21:45:12,533 iteration 2786 : loss : 0.031484, loss_ce: 0.010397
2022-01-21 21:45:13,792 iteration 2787 : loss : 0.049606, loss_ce: 0.014209
2022-01-21 21:45:14,988 iteration 2788 : loss : 0.030106, loss_ce: 0.008346
 41%|███████████                | 164/400 [1:00:04<1:22:13, 20.91s/it]2022-01-21 21:45:16,215 iteration 2789 : loss : 0.025395, loss_ce: 0.012264
2022-01-21 21:45:17,367 iteration 2790 : loss : 0.036846, loss_ce: 0.009577
2022-01-21 21:45:18,567 iteration 2791 : loss : 0.028546, loss_ce: 0.009248
2022-01-21 21:45:19,804 iteration 2792 : loss : 0.050216, loss_ce: 0.011601
2022-01-21 21:45:20,995 iteration 2793 : loss : 0.041592, loss_ce: 0.018894
2022-01-21 21:45:22,196 iteration 2794 : loss : 0.030745, loss_ce: 0.013562
2022-01-21 21:45:23,440 iteration 2795 : loss : 0.029278, loss_ce: 0.011117
2022-01-21 21:45:24,715 iteration 2796 : loss : 0.041285, loss_ce: 0.014019
2022-01-21 21:45:25,940 iteration 2797 : loss : 0.029639, loss_ce: 0.012456
2022-01-21 21:45:27,212 iteration 2798 : loss : 0.039357, loss_ce: 0.013014
2022-01-21 21:45:28,448 iteration 2799 : loss : 0.033339, loss_ce: 0.013187
2022-01-21 21:45:29,668 iteration 2800 : loss : 0.025918, loss_ce: 0.012579
2022-01-21 21:45:30,834 iteration 2801 : loss : 0.029635, loss_ce: 0.013292
2022-01-21 21:45:31,952 iteration 2802 : loss : 0.023512, loss_ce: 0.009625
2022-01-21 21:45:33,228 iteration 2803 : loss : 0.042256, loss_ce: 0.015707
2022-01-21 21:45:34,415 iteration 2804 : loss : 0.033530, loss_ce: 0.013426
2022-01-21 21:45:34,415 Training Data Eval:
2022-01-21 21:45:40,088   Average segmentation loss on training set: 0.0238
2022-01-21 21:45:40,088 Validation Data Eval:
2022-01-21 21:45:42,054   Average segmentation loss on validation set: 0.0587
2022-01-21 21:45:43,209 iteration 2805 : loss : 0.040942, loss_ce: 0.014155
 41%|███████████▏               | 165/400 [1:00:33<1:30:28, 23.10s/it]2022-01-21 21:45:44,462 iteration 2806 : loss : 0.037136, loss_ce: 0.011978
2022-01-21 21:45:45,782 iteration 2807 : loss : 0.042664, loss_ce: 0.019609
2022-01-21 21:45:46,884 iteration 2808 : loss : 0.027585, loss_ce: 0.012681
2022-01-21 21:45:48,060 iteration 2809 : loss : 0.034708, loss_ce: 0.013570
2022-01-21 21:45:49,276 iteration 2810 : loss : 0.035782, loss_ce: 0.013522
2022-01-21 21:45:50,432 iteration 2811 : loss : 0.031987, loss_ce: 0.011374
2022-01-21 21:45:51,611 iteration 2812 : loss : 0.029804, loss_ce: 0.011457
2022-01-21 21:45:52,823 iteration 2813 : loss : 0.028413, loss_ce: 0.009115
2022-01-21 21:45:54,011 iteration 2814 : loss : 0.044322, loss_ce: 0.017561
2022-01-21 21:45:55,149 iteration 2815 : loss : 0.022013, loss_ce: 0.009122
2022-01-21 21:45:56,287 iteration 2816 : loss : 0.029962, loss_ce: 0.012833
2022-01-21 21:45:57,437 iteration 2817 : loss : 0.026027, loss_ce: 0.008886
2022-01-21 21:45:58,686 iteration 2818 : loss : 0.034486, loss_ce: 0.010812
2022-01-21 21:45:59,909 iteration 2819 : loss : 0.039915, loss_ce: 0.019077
2022-01-21 21:46:01,200 iteration 2820 : loss : 0.038905, loss_ce: 0.017073
2022-01-21 21:46:02,388 iteration 2821 : loss : 0.030685, loss_ce: 0.013198
2022-01-21 21:46:03,537 iteration 2822 : loss : 0.030587, loss_ce: 0.010587
 42%|███████████▏               | 166/400 [1:00:53<1:26:50, 22.27s/it]2022-01-21 21:46:04,829 iteration 2823 : loss : 0.056804, loss_ce: 0.023156
2022-01-21 21:46:05,966 iteration 2824 : loss : 0.027014, loss_ce: 0.010109
2022-01-21 21:46:07,171 iteration 2825 : loss : 0.045953, loss_ce: 0.024916
2022-01-21 21:46:08,310 iteration 2826 : loss : 0.029898, loss_ce: 0.012936
2022-01-21 21:46:09,515 iteration 2827 : loss : 0.031605, loss_ce: 0.015349
2022-01-21 21:46:10,715 iteration 2828 : loss : 0.029886, loss_ce: 0.013239
2022-01-21 21:46:12,005 iteration 2829 : loss : 0.032959, loss_ce: 0.012888
2022-01-21 21:46:13,130 iteration 2830 : loss : 0.027847, loss_ce: 0.011974
2022-01-21 21:46:14,311 iteration 2831 : loss : 0.029302, loss_ce: 0.012490
2022-01-21 21:46:15,530 iteration 2832 : loss : 0.037903, loss_ce: 0.010557
2022-01-21 21:46:16,769 iteration 2833 : loss : 0.037868, loss_ce: 0.014685
2022-01-21 21:46:17,937 iteration 2834 : loss : 0.047128, loss_ce: 0.014213
2022-01-21 21:46:19,157 iteration 2835 : loss : 0.041929, loss_ce: 0.010190
2022-01-21 21:46:20,398 iteration 2836 : loss : 0.036423, loss_ce: 0.018225
2022-01-21 21:46:21,580 iteration 2837 : loss : 0.041040, loss_ce: 0.012488
2022-01-21 21:46:22,703 iteration 2838 : loss : 0.025805, loss_ce: 0.008730
2022-01-21 21:46:23,926 iteration 2839 : loss : 0.036034, loss_ce: 0.014649
 42%|███████████▎               | 167/400 [1:01:13<1:24:17, 21.70s/it]2022-01-21 21:46:25,128 iteration 2840 : loss : 0.045361, loss_ce: 0.023182
2022-01-21 21:46:26,326 iteration 2841 : loss : 0.036353, loss_ce: 0.013889
2022-01-21 21:46:27,514 iteration 2842 : loss : 0.059447, loss_ce: 0.019805
2022-01-21 21:46:28,623 iteration 2843 : loss : 0.028091, loss_ce: 0.010414
2022-01-21 21:46:29,714 iteration 2844 : loss : 0.023023, loss_ce: 0.008063
2022-01-21 21:46:30,868 iteration 2845 : loss : 0.037644, loss_ce: 0.013829
2022-01-21 21:46:32,148 iteration 2846 : loss : 0.040431, loss_ce: 0.013153
2022-01-21 21:46:33,376 iteration 2847 : loss : 0.041784, loss_ce: 0.014277
2022-01-21 21:46:34,565 iteration 2848 : loss : 0.067348, loss_ce: 0.021184
2022-01-21 21:46:35,780 iteration 2849 : loss : 0.033634, loss_ce: 0.013312
2022-01-21 21:46:36,962 iteration 2850 : loss : 0.032224, loss_ce: 0.015825
2022-01-21 21:46:38,221 iteration 2851 : loss : 0.027832, loss_ce: 0.011485
2022-01-21 21:46:39,371 iteration 2852 : loss : 0.032163, loss_ce: 0.009730
2022-01-21 21:46:40,573 iteration 2853 : loss : 0.046764, loss_ce: 0.013160
2022-01-21 21:46:41,701 iteration 2854 : loss : 0.036685, loss_ce: 0.010210
2022-01-21 21:46:42,845 iteration 2855 : loss : 0.046680, loss_ce: 0.024927
2022-01-21 21:46:43,941 iteration 2856 : loss : 0.026902, loss_ce: 0.012784
 42%|███████████▎               | 168/400 [1:01:33<1:21:58, 21.20s/it]2022-01-21 21:46:45,164 iteration 2857 : loss : 0.042781, loss_ce: 0.017691
2022-01-21 21:46:46,454 iteration 2858 : loss : 0.036446, loss_ce: 0.011493
2022-01-21 21:46:47,674 iteration 2859 : loss : 0.032435, loss_ce: 0.012445
2022-01-21 21:46:48,889 iteration 2860 : loss : 0.033137, loss_ce: 0.012682
2022-01-21 21:46:50,084 iteration 2861 : loss : 0.031681, loss_ce: 0.010317
2022-01-21 21:46:51,311 iteration 2862 : loss : 0.050299, loss_ce: 0.012481
2022-01-21 21:46:52,451 iteration 2863 : loss : 0.024605, loss_ce: 0.009682
2022-01-21 21:46:53,621 iteration 2864 : loss : 0.034331, loss_ce: 0.012923
2022-01-21 21:46:54,789 iteration 2865 : loss : 0.029480, loss_ce: 0.012310
2022-01-21 21:46:55,956 iteration 2866 : loss : 0.027524, loss_ce: 0.008645
2022-01-21 21:46:57,221 iteration 2867 : loss : 0.037922, loss_ce: 0.011279
2022-01-21 21:46:58,441 iteration 2868 : loss : 0.034574, loss_ce: 0.015496
2022-01-21 21:46:59,676 iteration 2869 : loss : 0.048063, loss_ce: 0.017305
2022-01-21 21:47:00,948 iteration 2870 : loss : 0.037111, loss_ce: 0.012357
2022-01-21 21:47:02,075 iteration 2871 : loss : 0.039861, loss_ce: 0.024269
2022-01-21 21:47:03,226 iteration 2872 : loss : 0.027322, loss_ce: 0.012569
2022-01-21 21:47:04,395 iteration 2873 : loss : 0.028667, loss_ce: 0.012003
 42%|███████████▍               | 169/400 [1:01:54<1:20:45, 20.98s/it]2022-01-21 21:47:05,607 iteration 2874 : loss : 0.029719, loss_ce: 0.010201
2022-01-21 21:47:06,861 iteration 2875 : loss : 0.032392, loss_ce: 0.012997
2022-01-21 21:47:08,009 iteration 2876 : loss : 0.037614, loss_ce: 0.014033
2022-01-21 21:47:09,119 iteration 2877 : loss : 0.034615, loss_ce: 0.010728
2022-01-21 21:47:10,287 iteration 2878 : loss : 0.030989, loss_ce: 0.009448
2022-01-21 21:47:11,397 iteration 2879 : loss : 0.026383, loss_ce: 0.011447
2022-01-21 21:47:12,597 iteration 2880 : loss : 0.048905, loss_ce: 0.024315
2022-01-21 21:47:13,705 iteration 2881 : loss : 0.025532, loss_ce: 0.011169
2022-01-21 21:47:14,849 iteration 2882 : loss : 0.036168, loss_ce: 0.010665
2022-01-21 21:47:16,054 iteration 2883 : loss : 0.054125, loss_ce: 0.017724
2022-01-21 21:47:17,273 iteration 2884 : loss : 0.040504, loss_ce: 0.015180
2022-01-21 21:47:18,462 iteration 2885 : loss : 0.028493, loss_ce: 0.010527
2022-01-21 21:47:19,605 iteration 2886 : loss : 0.028485, loss_ce: 0.009173
2022-01-21 21:47:20,740 iteration 2887 : loss : 0.025466, loss_ce: 0.008330
2022-01-21 21:47:21,953 iteration 2888 : loss : 0.032645, loss_ce: 0.014612
2022-01-21 21:47:23,131 iteration 2889 : loss : 0.039379, loss_ce: 0.014004
2022-01-21 21:47:23,131 Training Data Eval:
2022-01-21 21:47:28,831   Average segmentation loss on training set: 0.0205
2022-01-21 21:47:28,832 Validation Data Eval:
2022-01-21 21:47:30,801   Average segmentation loss on validation set: 0.0628
2022-01-21 21:47:31,954 iteration 2890 : loss : 0.039769, loss_ce: 0.018829
 42%|███████████▍               | 170/400 [1:02:21<1:27:58, 22.95s/it]2022-01-21 21:47:33,161 iteration 2891 : loss : 0.026715, loss_ce: 0.012084
2022-01-21 21:47:34,358 iteration 2892 : loss : 0.031343, loss_ce: 0.011697
2022-01-21 21:47:35,464 iteration 2893 : loss : 0.029136, loss_ce: 0.010968
2022-01-21 21:47:36,600 iteration 2894 : loss : 0.025058, loss_ce: 0.008839
2022-01-21 21:47:37,737 iteration 2895 : loss : 0.033886, loss_ce: 0.010567
2022-01-21 21:47:38,896 iteration 2896 : loss : 0.043623, loss_ce: 0.017643
2022-01-21 21:47:40,178 iteration 2897 : loss : 0.056520, loss_ce: 0.014561
2022-01-21 21:47:41,381 iteration 2898 : loss : 0.037418, loss_ce: 0.012627
2022-01-21 21:47:42,566 iteration 2899 : loss : 0.038498, loss_ce: 0.016637
2022-01-21 21:47:43,865 iteration 2900 : loss : 0.041183, loss_ce: 0.017279
2022-01-21 21:47:45,084 iteration 2901 : loss : 0.042652, loss_ce: 0.017063
2022-01-21 21:47:46,241 iteration 2902 : loss : 0.030925, loss_ce: 0.012419
2022-01-21 21:47:47,424 iteration 2903 : loss : 0.054500, loss_ce: 0.014144
2022-01-21 21:47:48,588 iteration 2904 : loss : 0.034361, loss_ce: 0.016258
2022-01-21 21:47:49,803 iteration 2905 : loss : 0.026394, loss_ce: 0.010873
2022-01-21 21:47:50,940 iteration 2906 : loss : 0.031147, loss_ce: 0.013383
2022-01-21 21:47:52,116 iteration 2907 : loss : 0.025092, loss_ce: 0.010394
 43%|███████████▌               | 171/400 [1:02:42<1:24:23, 22.11s/it]2022-01-21 21:47:53,359 iteration 2908 : loss : 0.040401, loss_ce: 0.017553
2022-01-21 21:47:54,589 iteration 2909 : loss : 0.033401, loss_ce: 0.011938
2022-01-21 21:47:55,810 iteration 2910 : loss : 0.026652, loss_ce: 0.009799
2022-01-21 21:47:57,046 iteration 2911 : loss : 0.038198, loss_ce: 0.015986
2022-01-21 21:47:58,193 iteration 2912 : loss : 0.022101, loss_ce: 0.008570
2022-01-21 21:47:59,385 iteration 2913 : loss : 0.036391, loss_ce: 0.012284
2022-01-21 21:48:00,604 iteration 2914 : loss : 0.050118, loss_ce: 0.018472
2022-01-21 21:48:01,791 iteration 2915 : loss : 0.041035, loss_ce: 0.022070
2022-01-21 21:48:02,973 iteration 2916 : loss : 0.042512, loss_ce: 0.015649
2022-01-21 21:48:04,156 iteration 2917 : loss : 0.034324, loss_ce: 0.014117
2022-01-21 21:48:05,263 iteration 2918 : loss : 0.026603, loss_ce: 0.011923
2022-01-21 21:48:06,451 iteration 2919 : loss : 0.042210, loss_ce: 0.013698
2022-01-21 21:48:07,607 iteration 2920 : loss : 0.031645, loss_ce: 0.012866
2022-01-21 21:48:08,778 iteration 2921 : loss : 0.028224, loss_ce: 0.012606
2022-01-21 21:48:09,934 iteration 2922 : loss : 0.049957, loss_ce: 0.017992
2022-01-21 21:48:11,187 iteration 2923 : loss : 0.046384, loss_ce: 0.013488
2022-01-21 21:48:12,406 iteration 2924 : loss : 0.025861, loss_ce: 0.010317
 43%|███████████▌               | 172/400 [1:03:02<1:21:57, 21.57s/it]2022-01-21 21:48:13,649 iteration 2925 : loss : 0.037488, loss_ce: 0.017525
2022-01-21 21:48:14,768 iteration 2926 : loss : 0.025844, loss_ce: 0.008998
2022-01-21 21:48:15,955 iteration 2927 : loss : 0.028291, loss_ce: 0.009416
2022-01-21 21:48:17,177 iteration 2928 : loss : 0.028277, loss_ce: 0.010118
2022-01-21 21:48:18,311 iteration 2929 : loss : 0.037003, loss_ce: 0.010515
2022-01-21 21:48:19,436 iteration 2930 : loss : 0.023977, loss_ce: 0.010054
2022-01-21 21:48:20,605 iteration 2931 : loss : 0.090533, loss_ce: 0.019487
2022-01-21 21:48:21,863 iteration 2932 : loss : 0.037996, loss_ce: 0.013963
2022-01-21 21:48:23,077 iteration 2933 : loss : 0.041149, loss_ce: 0.018156
2022-01-21 21:48:24,327 iteration 2934 : loss : 0.033800, loss_ce: 0.015733
2022-01-21 21:48:25,484 iteration 2935 : loss : 0.039716, loss_ce: 0.012438
2022-01-21 21:48:26,657 iteration 2936 : loss : 0.043959, loss_ce: 0.021862
2022-01-21 21:48:27,854 iteration 2937 : loss : 0.034152, loss_ce: 0.015916
2022-01-21 21:48:29,064 iteration 2938 : loss : 0.063352, loss_ce: 0.021765
2022-01-21 21:48:30,159 iteration 2939 : loss : 0.056805, loss_ce: 0.013887
2022-01-21 21:48:31,314 iteration 2940 : loss : 0.041894, loss_ce: 0.016802
2022-01-21 21:48:32,474 iteration 2941 : loss : 0.044378, loss_ce: 0.018305
 43%|███████████▋               | 173/400 [1:03:22<1:19:53, 21.12s/it]2022-01-21 21:48:33,776 iteration 2942 : loss : 0.045844, loss_ce: 0.019035
2022-01-21 21:48:34,997 iteration 2943 : loss : 0.032969, loss_ce: 0.012845
2022-01-21 21:48:36,199 iteration 2944 : loss : 0.090695, loss_ce: 0.023922
2022-01-21 21:48:37,384 iteration 2945 : loss : 0.050640, loss_ce: 0.023450
2022-01-21 21:48:38,624 iteration 2946 : loss : 0.034234, loss_ce: 0.013969
2022-01-21 21:48:39,776 iteration 2947 : loss : 0.031774, loss_ce: 0.011215
2022-01-21 21:48:40,980 iteration 2948 : loss : 0.031393, loss_ce: 0.011911
2022-01-21 21:48:42,131 iteration 2949 : loss : 0.034215, loss_ce: 0.013095
2022-01-21 21:48:43,235 iteration 2950 : loss : 0.028187, loss_ce: 0.010280
2022-01-21 21:48:44,405 iteration 2951 : loss : 0.038319, loss_ce: 0.012836
2022-01-21 21:48:45,498 iteration 2952 : loss : 0.099180, loss_ce: 0.017269
2022-01-21 21:48:46,738 iteration 2953 : loss : 0.036442, loss_ce: 0.013384
2022-01-21 21:48:47,921 iteration 2954 : loss : 0.034922, loss_ce: 0.016713
2022-01-21 21:48:49,111 iteration 2955 : loss : 0.052113, loss_ce: 0.012952
2022-01-21 21:48:50,231 iteration 2956 : loss : 0.047805, loss_ce: 0.024532
2022-01-21 21:48:51,349 iteration 2957 : loss : 0.033362, loss_ce: 0.011116
2022-01-21 21:48:52,527 iteration 2958 : loss : 0.057742, loss_ce: 0.023396
 44%|███████████▋               | 174/400 [1:03:42<1:18:20, 20.80s/it]2022-01-21 21:48:53,779 iteration 2959 : loss : 0.043569, loss_ce: 0.023082
2022-01-21 21:48:54,952 iteration 2960 : loss : 0.063252, loss_ce: 0.027750
2022-01-21 21:48:56,171 iteration 2961 : loss : 0.031912, loss_ce: 0.015677
2022-01-21 21:48:57,385 iteration 2962 : loss : 0.042492, loss_ce: 0.016136
2022-01-21 21:48:58,530 iteration 2963 : loss : 0.037444, loss_ce: 0.015860
2022-01-21 21:48:59,672 iteration 2964 : loss : 0.055647, loss_ce: 0.021482
2022-01-21 21:49:00,776 iteration 2965 : loss : 0.066633, loss_ce: 0.024196
2022-01-21 21:49:01,865 iteration 2966 : loss : 0.037104, loss_ce: 0.015139
2022-01-21 21:49:03,057 iteration 2967 : loss : 0.040379, loss_ce: 0.019359
2022-01-21 21:49:04,324 iteration 2968 : loss : 0.076115, loss_ce: 0.022201
2022-01-21 21:49:05,544 iteration 2969 : loss : 0.027661, loss_ce: 0.011602
2022-01-21 21:49:06,703 iteration 2970 : loss : 0.033146, loss_ce: 0.011271
2022-01-21 21:49:07,823 iteration 2971 : loss : 0.036940, loss_ce: 0.015517
2022-01-21 21:49:09,032 iteration 2972 : loss : 0.037896, loss_ce: 0.013471
2022-01-21 21:49:10,174 iteration 2973 : loss : 0.045752, loss_ce: 0.021346
2022-01-21 21:49:11,407 iteration 2974 : loss : 0.029807, loss_ce: 0.010019
2022-01-21 21:49:11,407 Training Data Eval:
2022-01-21 21:49:17,081   Average segmentation loss on training set: 0.0282
2022-01-21 21:49:17,082 Validation Data Eval:
2022-01-21 21:49:19,048   Average segmentation loss on validation set: 0.0943
2022-01-21 21:49:20,249 iteration 2975 : loss : 0.042086, loss_ce: 0.009644
 44%|███████████▊               | 175/400 [1:04:10<1:25:47, 22.88s/it]2022-01-21 21:49:21,547 iteration 2976 : loss : 0.056423, loss_ce: 0.031036
2022-01-21 21:49:22,661 iteration 2977 : loss : 0.039376, loss_ce: 0.015751
2022-01-21 21:49:23,754 iteration 2978 : loss : 0.031146, loss_ce: 0.011002
2022-01-21 21:49:24,967 iteration 2979 : loss : 0.029418, loss_ce: 0.009721
2022-01-21 21:49:26,267 iteration 2980 : loss : 0.036782, loss_ce: 0.015445
2022-01-21 21:49:27,474 iteration 2981 : loss : 0.037094, loss_ce: 0.013204
2022-01-21 21:49:28,730 iteration 2982 : loss : 0.033274, loss_ce: 0.015623
2022-01-21 21:49:29,902 iteration 2983 : loss : 0.032801, loss_ce: 0.014722
2022-01-21 21:49:31,146 iteration 2984 : loss : 0.040422, loss_ce: 0.017497
2022-01-21 21:49:32,342 iteration 2985 : loss : 0.055085, loss_ce: 0.019117
2022-01-21 21:49:33,575 iteration 2986 : loss : 0.044647, loss_ce: 0.019166
2022-01-21 21:49:34,706 iteration 2987 : loss : 0.034024, loss_ce: 0.015898
2022-01-21 21:49:35,861 iteration 2988 : loss : 0.027368, loss_ce: 0.009142
2022-01-21 21:49:37,060 iteration 2989 : loss : 0.027902, loss_ce: 0.008219
2022-01-21 21:49:38,266 iteration 2990 : loss : 0.047557, loss_ce: 0.017966
2022-01-21 21:49:39,531 iteration 2991 : loss : 0.025547, loss_ce: 0.008801
2022-01-21 21:49:40,850 iteration 2992 : loss : 0.040114, loss_ce: 0.015373
 44%|███████████▉               | 176/400 [1:04:30<1:22:50, 22.19s/it]2022-01-21 21:49:42,012 iteration 2993 : loss : 0.035490, loss_ce: 0.010636
2022-01-21 21:49:43,185 iteration 2994 : loss : 0.032660, loss_ce: 0.012632
2022-01-21 21:49:44,451 iteration 2995 : loss : 0.038077, loss_ce: 0.017292
2022-01-21 21:49:45,633 iteration 2996 : loss : 0.026353, loss_ce: 0.009566
2022-01-21 21:49:46,806 iteration 2997 : loss : 0.028444, loss_ce: 0.009821
2022-01-21 21:49:47,972 iteration 2998 : loss : 0.033015, loss_ce: 0.009134
2022-01-21 21:49:49,196 iteration 2999 : loss : 0.043915, loss_ce: 0.016466
2022-01-21 21:49:50,368 iteration 3000 : loss : 0.052666, loss_ce: 0.015470
2022-01-21 21:49:51,586 iteration 3001 : loss : 0.034518, loss_ce: 0.016429
2022-01-21 21:49:52,696 iteration 3002 : loss : 0.043552, loss_ce: 0.019428
2022-01-21 21:49:53,926 iteration 3003 : loss : 0.036439, loss_ce: 0.013616
2022-01-21 21:49:55,031 iteration 3004 : loss : 0.026817, loss_ce: 0.010174
2022-01-21 21:49:56,232 iteration 3005 : loss : 0.051155, loss_ce: 0.019367
2022-01-21 21:49:57,444 iteration 3006 : loss : 0.028297, loss_ce: 0.010450
2022-01-21 21:49:58,598 iteration 3007 : loss : 0.026291, loss_ce: 0.009264
2022-01-21 21:49:59,893 iteration 3008 : loss : 0.035849, loss_ce: 0.014925
2022-01-21 21:50:01,064 iteration 3009 : loss : 0.032406, loss_ce: 0.017510
 44%|███████████▉               | 177/400 [1:04:50<1:20:16, 21.60s/it]2022-01-21 21:50:02,274 iteration 3010 : loss : 0.028298, loss_ce: 0.010920
2022-01-21 21:50:03,446 iteration 3011 : loss : 0.044954, loss_ce: 0.015704
2022-01-21 21:50:04,589 iteration 3012 : loss : 0.035235, loss_ce: 0.012212
2022-01-21 21:50:05,724 iteration 3013 : loss : 0.027427, loss_ce: 0.011771
2022-01-21 21:50:06,967 iteration 3014 : loss : 0.032870, loss_ce: 0.011822
2022-01-21 21:50:08,164 iteration 3015 : loss : 0.028407, loss_ce: 0.009084
2022-01-21 21:50:09,331 iteration 3016 : loss : 0.034086, loss_ce: 0.013314
2022-01-21 21:50:10,497 iteration 3017 : loss : 0.045073, loss_ce: 0.012374
2022-01-21 21:50:11,628 iteration 3018 : loss : 0.018721, loss_ce: 0.004908
2022-01-21 21:50:12,783 iteration 3019 : loss : 0.039417, loss_ce: 0.014382
2022-01-21 21:50:13,843 iteration 3020 : loss : 0.034265, loss_ce: 0.017548
2022-01-21 21:50:14,932 iteration 3021 : loss : 0.023579, loss_ce: 0.007833
2022-01-21 21:50:16,085 iteration 3022 : loss : 0.031725, loss_ce: 0.008748
2022-01-21 21:50:17,238 iteration 3023 : loss : 0.032113, loss_ce: 0.015662
2022-01-21 21:50:18,408 iteration 3024 : loss : 0.026925, loss_ce: 0.009728
2022-01-21 21:50:19,489 iteration 3025 : loss : 0.030380, loss_ce: 0.013151
2022-01-21 21:50:20,690 iteration 3026 : loss : 0.029053, loss_ce: 0.013694
 44%|████████████               | 178/400 [1:05:10<1:17:43, 21.01s/it]2022-01-21 21:50:21,914 iteration 3027 : loss : 0.031894, loss_ce: 0.014806
2022-01-21 21:50:23,080 iteration 3028 : loss : 0.046919, loss_ce: 0.020047
2022-01-21 21:50:24,258 iteration 3029 : loss : 0.033947, loss_ce: 0.014152
2022-01-21 21:50:25,521 iteration 3030 : loss : 0.031354, loss_ce: 0.011478
2022-01-21 21:50:26,616 iteration 3031 : loss : 0.024896, loss_ce: 0.009477
2022-01-21 21:50:27,778 iteration 3032 : loss : 0.036183, loss_ce: 0.013885
2022-01-21 21:50:28,972 iteration 3033 : loss : 0.033086, loss_ce: 0.017225
2022-01-21 21:50:30,129 iteration 3034 : loss : 0.028931, loss_ce: 0.010000
2022-01-21 21:50:31,380 iteration 3035 : loss : 0.034763, loss_ce: 0.010950
2022-01-21 21:50:32,573 iteration 3036 : loss : 0.030171, loss_ce: 0.013379
2022-01-21 21:50:33,800 iteration 3037 : loss : 0.024649, loss_ce: 0.009146
2022-01-21 21:50:34,905 iteration 3038 : loss : 0.030535, loss_ce: 0.007171
2022-01-21 21:50:36,230 iteration 3039 : loss : 0.037454, loss_ce: 0.013558
2022-01-21 21:50:37,359 iteration 3040 : loss : 0.026224, loss_ce: 0.011835
2022-01-21 21:50:38,499 iteration 3041 : loss : 0.033558, loss_ce: 0.013258
2022-01-21 21:50:39,631 iteration 3042 : loss : 0.026051, loss_ce: 0.011275
2022-01-21 21:50:40,908 iteration 3043 : loss : 0.026800, loss_ce: 0.010114
 45%|████████████               | 179/400 [1:05:30<1:16:30, 20.77s/it]2022-01-21 21:50:42,165 iteration 3044 : loss : 0.037798, loss_ce: 0.013775
2022-01-21 21:50:43,327 iteration 3045 : loss : 0.027708, loss_ce: 0.011074
2022-01-21 21:50:44,474 iteration 3046 : loss : 0.038706, loss_ce: 0.013261
2022-01-21 21:50:45,760 iteration 3047 : loss : 0.031150, loss_ce: 0.012320
2022-01-21 21:50:47,007 iteration 3048 : loss : 0.039623, loss_ce: 0.021119
2022-01-21 21:50:48,156 iteration 3049 : loss : 0.037153, loss_ce: 0.014646
2022-01-21 21:50:49,429 iteration 3050 : loss : 0.030321, loss_ce: 0.014908
2022-01-21 21:50:50,655 iteration 3051 : loss : 0.052512, loss_ce: 0.013136
2022-01-21 21:50:51,915 iteration 3052 : loss : 0.043320, loss_ce: 0.017273
2022-01-21 21:50:53,132 iteration 3053 : loss : 0.030565, loss_ce: 0.013403
2022-01-21 21:50:54,331 iteration 3054 : loss : 0.052075, loss_ce: 0.017311
2022-01-21 21:50:55,542 iteration 3055 : loss : 0.031393, loss_ce: 0.012157
2022-01-21 21:50:56,724 iteration 3056 : loss : 0.029060, loss_ce: 0.009651
2022-01-21 21:50:57,862 iteration 3057 : loss : 0.023342, loss_ce: 0.007809
2022-01-21 21:50:59,111 iteration 3058 : loss : 0.064877, loss_ce: 0.021290
2022-01-21 21:51:00,373 iteration 3059 : loss : 0.060079, loss_ce: 0.024456
2022-01-21 21:51:00,373 Training Data Eval:
2022-01-21 21:51:06,089   Average segmentation loss on training set: 0.0307
2022-01-21 21:51:06,089 Validation Data Eval:
2022-01-21 21:51:08,068   Average segmentation loss on validation set: 0.1274
2022-01-21 21:51:09,242 iteration 3060 : loss : 0.045732, loss_ce: 0.020468
 45%|████████████▏              | 180/400 [1:05:59<1:24:28, 23.04s/it]2022-01-21 21:51:10,433 iteration 3061 : loss : 0.028774, loss_ce: 0.010053
2022-01-21 21:51:11,642 iteration 3062 : loss : 0.029377, loss_ce: 0.009833
2022-01-21 21:51:12,799 iteration 3063 : loss : 0.040576, loss_ce: 0.013300
2022-01-21 21:51:14,036 iteration 3064 : loss : 0.038656, loss_ce: 0.020460
2022-01-21 21:51:15,213 iteration 3065 : loss : 0.031856, loss_ce: 0.009309
2022-01-21 21:51:16,379 iteration 3066 : loss : 0.032050, loss_ce: 0.008110
2022-01-21 21:51:17,570 iteration 3067 : loss : 0.035698, loss_ce: 0.016506
2022-01-21 21:51:18,810 iteration 3068 : loss : 0.021494, loss_ce: 0.006894
2022-01-21 21:51:20,054 iteration 3069 : loss : 0.053358, loss_ce: 0.011802
2022-01-21 21:51:21,177 iteration 3070 : loss : 0.032463, loss_ce: 0.012687
2022-01-21 21:51:22,427 iteration 3071 : loss : 0.038996, loss_ce: 0.018079
2022-01-21 21:51:23,629 iteration 3072 : loss : 0.019018, loss_ce: 0.007156
2022-01-21 21:51:24,774 iteration 3073 : loss : 0.056099, loss_ce: 0.027996
2022-01-21 21:51:26,058 iteration 3074 : loss : 0.036449, loss_ce: 0.017598
2022-01-21 21:51:27,287 iteration 3075 : loss : 0.033840, loss_ce: 0.012638
2022-01-21 21:51:28,455 iteration 3076 : loss : 0.034001, loss_ce: 0.015895
2022-01-21 21:51:29,718 iteration 3077 : loss : 0.043750, loss_ce: 0.021798
 45%|████████████▏              | 181/400 [1:06:19<1:21:17, 22.27s/it]2022-01-21 21:51:30,836 iteration 3078 : loss : 0.020965, loss_ce: 0.008405
2022-01-21 21:51:32,074 iteration 3079 : loss : 0.048970, loss_ce: 0.018837
2022-01-21 21:51:33,252 iteration 3080 : loss : 0.035120, loss_ce: 0.015698
2022-01-21 21:51:34,414 iteration 3081 : loss : 0.035544, loss_ce: 0.009754
2022-01-21 21:51:35,602 iteration 3082 : loss : 0.032089, loss_ce: 0.012772
2022-01-21 21:51:36,790 iteration 3083 : loss : 0.036411, loss_ce: 0.015785
2022-01-21 21:51:37,962 iteration 3084 : loss : 0.028049, loss_ce: 0.012132
2022-01-21 21:51:39,148 iteration 3085 : loss : 0.044914, loss_ce: 0.009936
2022-01-21 21:51:40,290 iteration 3086 : loss : 0.023743, loss_ce: 0.009613
2022-01-21 21:51:41,419 iteration 3087 : loss : 0.029932, loss_ce: 0.009396
2022-01-21 21:51:42,543 iteration 3088 : loss : 0.028456, loss_ce: 0.010392
2022-01-21 21:51:43,672 iteration 3089 : loss : 0.031997, loss_ce: 0.012984
2022-01-21 21:51:44,868 iteration 3090 : loss : 0.048427, loss_ce: 0.018486
2022-01-21 21:51:46,007 iteration 3091 : loss : 0.037735, loss_ce: 0.014241
2022-01-21 21:51:47,115 iteration 3092 : loss : 0.031975, loss_ce: 0.015807
2022-01-21 21:51:48,281 iteration 3093 : loss : 0.025265, loss_ce: 0.008074
2022-01-21 21:51:49,416 iteration 3094 : loss : 0.043835, loss_ce: 0.022348
 46%|████████████▎              | 182/400 [1:06:39<1:18:06, 21.50s/it]2022-01-21 21:51:50,686 iteration 3095 : loss : 0.026901, loss_ce: 0.009058
2022-01-21 21:51:51,843 iteration 3096 : loss : 0.024191, loss_ce: 0.009945
2022-01-21 21:51:53,000 iteration 3097 : loss : 0.026314, loss_ce: 0.010199
2022-01-21 21:51:54,132 iteration 3098 : loss : 0.027495, loss_ce: 0.009612
2022-01-21 21:51:55,367 iteration 3099 : loss : 0.050928, loss_ce: 0.016264
2022-01-21 21:51:56,498 iteration 3100 : loss : 0.027573, loss_ce: 0.010161
2022-01-21 21:51:57,675 iteration 3101 : loss : 0.027432, loss_ce: 0.012445
2022-01-21 21:51:58,895 iteration 3102 : loss : 0.025212, loss_ce: 0.010163
2022-01-21 21:52:00,051 iteration 3103 : loss : 0.028438, loss_ce: 0.009379
2022-01-21 21:52:01,228 iteration 3104 : loss : 0.029492, loss_ce: 0.009831
2022-01-21 21:52:02,380 iteration 3105 : loss : 0.028695, loss_ce: 0.009993
2022-01-21 21:52:03,697 iteration 3106 : loss : 0.040549, loss_ce: 0.016257
2022-01-21 21:52:04,873 iteration 3107 : loss : 0.036140, loss_ce: 0.014450
2022-01-21 21:52:05,985 iteration 3108 : loss : 0.027673, loss_ce: 0.010311
2022-01-21 21:52:07,212 iteration 3109 : loss : 0.041126, loss_ce: 0.022638
2022-01-21 21:52:08,452 iteration 3110 : loss : 0.048697, loss_ce: 0.021709
2022-01-21 21:52:09,593 iteration 3111 : loss : 0.034118, loss_ce: 0.010288
 46%|████████████▎              | 183/400 [1:06:59<1:16:18, 21.10s/it]2022-01-21 21:52:10,775 iteration 3112 : loss : 0.024485, loss_ce: 0.009610
2022-01-21 21:52:11,943 iteration 3113 : loss : 0.025357, loss_ce: 0.010791
2022-01-21 21:52:13,230 iteration 3114 : loss : 0.051236, loss_ce: 0.013281
2022-01-21 21:52:14,474 iteration 3115 : loss : 0.035785, loss_ce: 0.018723
2022-01-21 21:52:15,667 iteration 3116 : loss : 0.027831, loss_ce: 0.010937
2022-01-21 21:52:16,832 iteration 3117 : loss : 0.027075, loss_ce: 0.012601
2022-01-21 21:52:18,067 iteration 3118 : loss : 0.042049, loss_ce: 0.016976
2022-01-21 21:52:19,283 iteration 3119 : loss : 0.041206, loss_ce: 0.013940
2022-01-21 21:52:20,481 iteration 3120 : loss : 0.028756, loss_ce: 0.009077
2022-01-21 21:52:21,684 iteration 3121 : loss : 0.033477, loss_ce: 0.010484
2022-01-21 21:52:22,931 iteration 3122 : loss : 0.031122, loss_ce: 0.007939
2022-01-21 21:52:24,125 iteration 3123 : loss : 0.026299, loss_ce: 0.011461
2022-01-21 21:52:25,338 iteration 3124 : loss : 0.032142, loss_ce: 0.012926
2022-01-21 21:52:26,541 iteration 3125 : loss : 0.028656, loss_ce: 0.013095
2022-01-21 21:52:27,670 iteration 3126 : loss : 0.030691, loss_ce: 0.011730
2022-01-21 21:52:28,861 iteration 3127 : loss : 0.031632, loss_ce: 0.011003
2022-01-21 21:52:29,970 iteration 3128 : loss : 0.022554, loss_ce: 0.007754
 46%|████████████▍              | 184/400 [1:07:19<1:15:10, 20.88s/it]2022-01-21 21:52:31,228 iteration 3129 : loss : 0.042824, loss_ce: 0.014131
2022-01-21 21:52:32,434 iteration 3130 : loss : 0.042083, loss_ce: 0.014358
2022-01-21 21:52:33,686 iteration 3131 : loss : 0.033694, loss_ce: 0.012618
2022-01-21 21:52:34,846 iteration 3132 : loss : 0.026348, loss_ce: 0.009663
2022-01-21 21:52:35,961 iteration 3133 : loss : 0.035192, loss_ce: 0.014515
2022-01-21 21:52:37,139 iteration 3134 : loss : 0.022642, loss_ce: 0.007197
2022-01-21 21:52:38,316 iteration 3135 : loss : 0.031112, loss_ce: 0.010357
2022-01-21 21:52:39,558 iteration 3136 : loss : 0.059056, loss_ce: 0.022369
2022-01-21 21:52:40,759 iteration 3137 : loss : 0.031730, loss_ce: 0.014128
2022-01-21 21:52:41,979 iteration 3138 : loss : 0.032219, loss_ce: 0.014345
2022-01-21 21:52:43,233 iteration 3139 : loss : 0.064257, loss_ce: 0.019894
2022-01-21 21:52:44,457 iteration 3140 : loss : 0.040202, loss_ce: 0.014109
2022-01-21 21:52:45,691 iteration 3141 : loss : 0.039207, loss_ce: 0.015104
2022-01-21 21:52:46,874 iteration 3142 : loss : 0.033513, loss_ce: 0.011321
2022-01-21 21:52:48,112 iteration 3143 : loss : 0.031761, loss_ce: 0.015123
2022-01-21 21:52:49,369 iteration 3144 : loss : 0.043373, loss_ce: 0.015051
2022-01-21 21:52:49,369 Training Data Eval:
2022-01-21 21:52:55,032   Average segmentation loss on training set: 0.0226
2022-01-21 21:52:55,032 Validation Data Eval:
2022-01-21 21:52:56,989   Average segmentation loss on validation set: 0.0683
2022-01-21 21:52:58,064 iteration 3145 : loss : 0.027895, loss_ce: 0.010109
 46%|████████████▍              | 185/400 [1:07:47<1:22:35, 23.05s/it]2022-01-21 21:52:59,193 iteration 3146 : loss : 0.030589, loss_ce: 0.010831
2022-01-21 21:53:00,346 iteration 3147 : loss : 0.034617, loss_ce: 0.014774
2022-01-21 21:53:01,514 iteration 3148 : loss : 0.024681, loss_ce: 0.008592
2022-01-21 21:53:02,663 iteration 3149 : loss : 0.031341, loss_ce: 0.011976
2022-01-21 21:53:03,823 iteration 3150 : loss : 0.028458, loss_ce: 0.014023
2022-01-21 21:53:04,965 iteration 3151 : loss : 0.034723, loss_ce: 0.008803
2022-01-21 21:53:06,121 iteration 3152 : loss : 0.026102, loss_ce: 0.009409
2022-01-21 21:53:07,305 iteration 3153 : loss : 0.063616, loss_ce: 0.020136
2022-01-21 21:53:08,446 iteration 3154 : loss : 0.026962, loss_ce: 0.012922
2022-01-21 21:53:09,603 iteration 3155 : loss : 0.026548, loss_ce: 0.009406
2022-01-21 21:53:10,833 iteration 3156 : loss : 0.037625, loss_ce: 0.014501
2022-01-21 21:53:12,039 iteration 3157 : loss : 0.031024, loss_ce: 0.012121
2022-01-21 21:53:13,202 iteration 3158 : loss : 0.050856, loss_ce: 0.025618
2022-01-21 21:53:14,375 iteration 3159 : loss : 0.024597, loss_ce: 0.009354
2022-01-21 21:53:15,544 iteration 3160 : loss : 0.029906, loss_ce: 0.011663
2022-01-21 21:53:16,676 iteration 3161 : loss : 0.029366, loss_ce: 0.011122
2022-01-21 21:53:17,924 iteration 3162 : loss : 0.043041, loss_ce: 0.018366
 46%|████████████▌              | 186/400 [1:08:07<1:18:47, 22.09s/it]2022-01-21 21:53:19,206 iteration 3163 : loss : 0.029921, loss_ce: 0.013422
2022-01-21 21:53:20,420 iteration 3164 : loss : 0.028035, loss_ce: 0.010002
2022-01-21 21:53:21,582 iteration 3165 : loss : 0.025251, loss_ce: 0.009126
2022-01-21 21:53:22,824 iteration 3166 : loss : 0.028325, loss_ce: 0.010324
2022-01-21 21:53:24,003 iteration 3167 : loss : 0.023250, loss_ce: 0.008872
2022-01-21 21:53:25,304 iteration 3168 : loss : 0.033843, loss_ce: 0.014085
2022-01-21 21:53:26,575 iteration 3169 : loss : 0.035451, loss_ce: 0.015333
2022-01-21 21:53:27,737 iteration 3170 : loss : 0.026000, loss_ce: 0.012358
2022-01-21 21:53:28,857 iteration 3171 : loss : 0.024502, loss_ce: 0.012063
2022-01-21 21:53:30,059 iteration 3172 : loss : 0.028994, loss_ce: 0.010330
2022-01-21 21:53:31,295 iteration 3173 : loss : 0.022572, loss_ce: 0.008344
2022-01-21 21:53:32,472 iteration 3174 : loss : 0.034444, loss_ce: 0.013999
2022-01-21 21:53:33,743 iteration 3175 : loss : 0.046258, loss_ce: 0.014451
2022-01-21 21:53:34,920 iteration 3176 : loss : 0.033908, loss_ce: 0.011492
2022-01-21 21:53:36,156 iteration 3177 : loss : 0.050900, loss_ce: 0.018839
2022-01-21 21:53:37,282 iteration 3178 : loss : 0.032249, loss_ce: 0.010883
2022-01-21 21:53:38,436 iteration 3179 : loss : 0.027207, loss_ce: 0.008218
 47%|████████████▌              | 187/400 [1:08:28<1:16:44, 21.62s/it]2022-01-21 21:53:39,711 iteration 3180 : loss : 0.041576, loss_ce: 0.019865
2022-01-21 21:53:40,855 iteration 3181 : loss : 0.026557, loss_ce: 0.009063
2022-01-21 21:53:42,049 iteration 3182 : loss : 0.022627, loss_ce: 0.008413
2022-01-21 21:53:43,208 iteration 3183 : loss : 0.019692, loss_ce: 0.004919
2022-01-21 21:53:44,394 iteration 3184 : loss : 0.033343, loss_ce: 0.011160
2022-01-21 21:53:45,615 iteration 3185 : loss : 0.037337, loss_ce: 0.015913
2022-01-21 21:53:46,726 iteration 3186 : loss : 0.034624, loss_ce: 0.017446
2022-01-21 21:53:47,914 iteration 3187 : loss : 0.026464, loss_ce: 0.012593
2022-01-21 21:53:49,081 iteration 3188 : loss : 0.021863, loss_ce: 0.009394
2022-01-21 21:53:50,283 iteration 3189 : loss : 0.031940, loss_ce: 0.013966
2022-01-21 21:53:51,457 iteration 3190 : loss : 0.036195, loss_ce: 0.015925
2022-01-21 21:53:52,751 iteration 3191 : loss : 0.051222, loss_ce: 0.017592
2022-01-21 21:53:53,898 iteration 3192 : loss : 0.042043, loss_ce: 0.015363
2022-01-21 21:53:55,125 iteration 3193 : loss : 0.031738, loss_ce: 0.014842
2022-01-21 21:53:56,355 iteration 3194 : loss : 0.043846, loss_ce: 0.011667
2022-01-21 21:53:57,545 iteration 3195 : loss : 0.026986, loss_ce: 0.012901
2022-01-21 21:53:58,729 iteration 3196 : loss : 0.030455, loss_ce: 0.011982
 47%|████████████▋              | 188/400 [1:08:48<1:14:58, 21.22s/it]2022-01-21 21:53:59,888 iteration 3197 : loss : 0.026175, loss_ce: 0.010476
2022-01-21 21:54:01,048 iteration 3198 : loss : 0.033580, loss_ce: 0.014331
2022-01-21 21:54:02,233 iteration 3199 : loss : 0.033888, loss_ce: 0.015746
2022-01-21 21:54:03,505 iteration 3200 : loss : 0.033887, loss_ce: 0.016081
2022-01-21 21:54:04,711 iteration 3201 : loss : 0.049092, loss_ce: 0.015017
2022-01-21 21:54:05,897 iteration 3202 : loss : 0.034311, loss_ce: 0.011365
2022-01-21 21:54:07,178 iteration 3203 : loss : 0.031004, loss_ce: 0.012668
2022-01-21 21:54:08,354 iteration 3204 : loss : 0.025194, loss_ce: 0.007380
2022-01-21 21:54:09,593 iteration 3205 : loss : 0.032898, loss_ce: 0.009241
2022-01-21 21:54:10,795 iteration 3206 : loss : 0.021718, loss_ce: 0.008384
2022-01-21 21:54:12,072 iteration 3207 : loss : 0.055320, loss_ce: 0.026403
2022-01-21 21:54:13,205 iteration 3208 : loss : 0.026374, loss_ce: 0.008359
2022-01-21 21:54:14,342 iteration 3209 : loss : 0.037980, loss_ce: 0.019742
2022-01-21 21:54:15,436 iteration 3210 : loss : 0.021988, loss_ce: 0.010217
2022-01-21 21:54:16,601 iteration 3211 : loss : 0.029832, loss_ce: 0.008659
2022-01-21 21:54:17,752 iteration 3212 : loss : 0.035552, loss_ce: 0.014593
2022-01-21 21:54:18,934 iteration 3213 : loss : 0.031593, loss_ce: 0.009319
 47%|████████████▊              | 189/400 [1:09:08<1:13:33, 20.92s/it]2022-01-21 21:54:20,160 iteration 3214 : loss : 0.033533, loss_ce: 0.016892
2022-01-21 21:54:21,433 iteration 3215 : loss : 0.031301, loss_ce: 0.012004
2022-01-21 21:54:22,669 iteration 3216 : loss : 0.030260, loss_ce: 0.009814
2022-01-21 21:54:23,915 iteration 3217 : loss : 0.055205, loss_ce: 0.011948
2022-01-21 21:54:25,118 iteration 3218 : loss : 0.038992, loss_ce: 0.013650
2022-01-21 21:54:26,280 iteration 3219 : loss : 0.024695, loss_ce: 0.010337
2022-01-21 21:54:27,502 iteration 3220 : loss : 0.032739, loss_ce: 0.011376
2022-01-21 21:54:28,655 iteration 3221 : loss : 0.030894, loss_ce: 0.012342
2022-01-21 21:54:29,846 iteration 3222 : loss : 0.036053, loss_ce: 0.023011
2022-01-21 21:54:31,057 iteration 3223 : loss : 0.031018, loss_ce: 0.008004
2022-01-21 21:54:32,295 iteration 3224 : loss : 0.028632, loss_ce: 0.009769
2022-01-21 21:54:33,458 iteration 3225 : loss : 0.044767, loss_ce: 0.017412
2022-01-21 21:54:34,727 iteration 3226 : loss : 0.031194, loss_ce: 0.009430
2022-01-21 21:54:35,937 iteration 3227 : loss : 0.029747, loss_ce: 0.011318
2022-01-21 21:54:37,050 iteration 3228 : loss : 0.021753, loss_ce: 0.009862
2022-01-21 21:54:38,307 iteration 3229 : loss : 0.035532, loss_ce: 0.014687
2022-01-21 21:54:38,307 Training Data Eval:
2022-01-21 21:54:44,016   Average segmentation loss on training set: 0.0218
2022-01-21 21:54:44,016 Validation Data Eval:
2022-01-21 21:54:45,990   Average segmentation loss on validation set: 0.0748
2022-01-21 21:54:47,253 iteration 3230 : loss : 0.037693, loss_ce: 0.013492
 48%|████████████▊              | 190/400 [1:09:37<1:20:58, 23.14s/it]2022-01-21 21:54:48,457 iteration 3231 : loss : 0.029248, loss_ce: 0.010403
2022-01-21 21:54:49,636 iteration 3232 : loss : 0.035696, loss_ce: 0.014445
2022-01-21 21:54:50,805 iteration 3233 : loss : 0.024928, loss_ce: 0.009438
2022-01-21 21:54:51,933 iteration 3234 : loss : 0.032586, loss_ce: 0.011648
2022-01-21 21:54:53,078 iteration 3235 : loss : 0.021373, loss_ce: 0.005947
2022-01-21 21:54:54,281 iteration 3236 : loss : 0.034146, loss_ce: 0.013869
2022-01-21 21:54:55,497 iteration 3237 : loss : 0.022364, loss_ce: 0.009853
2022-01-21 21:54:56,692 iteration 3238 : loss : 0.038104, loss_ce: 0.009140
2022-01-21 21:54:57,868 iteration 3239 : loss : 0.024638, loss_ce: 0.009776
2022-01-21 21:54:59,066 iteration 3240 : loss : 0.028710, loss_ce: 0.010035
2022-01-21 21:55:00,294 iteration 3241 : loss : 0.026618, loss_ce: 0.009909
2022-01-21 21:55:01,565 iteration 3242 : loss : 0.035156, loss_ce: 0.015570
2022-01-21 21:55:02,714 iteration 3243 : loss : 0.028474, loss_ce: 0.014481
2022-01-21 21:55:03,892 iteration 3244 : loss : 0.051605, loss_ce: 0.014561
2022-01-21 21:55:05,051 iteration 3245 : loss : 0.028748, loss_ce: 0.012606
2022-01-21 21:55:06,294 iteration 3246 : loss : 0.036023, loss_ce: 0.015988
2022-01-21 21:55:07,505 iteration 3247 : loss : 0.028846, loss_ce: 0.011377
 48%|████████████▉              | 191/400 [1:09:57<1:17:35, 22.27s/it]2022-01-21 21:55:08,885 iteration 3248 : loss : 0.036515, loss_ce: 0.017060
2022-01-21 21:55:10,007 iteration 3249 : loss : 0.023508, loss_ce: 0.006762
2022-01-21 21:55:11,215 iteration 3250 : loss : 0.031012, loss_ce: 0.012083
2022-01-21 21:55:12,404 iteration 3251 : loss : 0.037577, loss_ce: 0.009550
2022-01-21 21:55:13,543 iteration 3252 : loss : 0.025320, loss_ce: 0.010159
2022-01-21 21:55:14,751 iteration 3253 : loss : 0.030526, loss_ce: 0.012909
2022-01-21 21:55:15,942 iteration 3254 : loss : 0.030824, loss_ce: 0.009695
2022-01-21 21:55:17,181 iteration 3255 : loss : 0.035979, loss_ce: 0.016274
2022-01-21 21:55:18,311 iteration 3256 : loss : 0.025717, loss_ce: 0.014978
2022-01-21 21:55:19,483 iteration 3257 : loss : 0.036861, loss_ce: 0.013084
2022-01-21 21:55:20,738 iteration 3258 : loss : 0.030169, loss_ce: 0.012361
2022-01-21 21:55:21,916 iteration 3259 : loss : 0.032988, loss_ce: 0.013669
2022-01-21 21:55:23,066 iteration 3260 : loss : 0.027400, loss_ce: 0.011225
2022-01-21 21:55:24,303 iteration 3261 : loss : 0.047873, loss_ce: 0.020366
2022-01-21 21:55:25,476 iteration 3262 : loss : 0.046798, loss_ce: 0.022094
2022-01-21 21:55:26,646 iteration 3263 : loss : 0.035740, loss_ce: 0.013177
2022-01-21 21:55:27,811 iteration 3264 : loss : 0.042477, loss_ce: 0.018332
 48%|████████████▉              | 192/400 [1:10:17<1:15:09, 21.68s/it]2022-01-21 21:55:28,926 iteration 3265 : loss : 0.022142, loss_ce: 0.008254
2022-01-21 21:55:30,130 iteration 3266 : loss : 0.022859, loss_ce: 0.009980
2022-01-21 21:55:31,274 iteration 3267 : loss : 0.022755, loss_ce: 0.009552
2022-01-21 21:55:32,562 iteration 3268 : loss : 0.028766, loss_ce: 0.011346
2022-01-21 21:55:33,690 iteration 3269 : loss : 0.030408, loss_ce: 0.013315
2022-01-21 21:55:34,819 iteration 3270 : loss : 0.023294, loss_ce: 0.009445
2022-01-21 21:55:36,067 iteration 3271 : loss : 0.034929, loss_ce: 0.013262
2022-01-21 21:55:37,220 iteration 3272 : loss : 0.023263, loss_ce: 0.008860
2022-01-21 21:55:38,362 iteration 3273 : loss : 0.037785, loss_ce: 0.013765
2022-01-21 21:55:39,579 iteration 3274 : loss : 0.031786, loss_ce: 0.012585
2022-01-21 21:55:40,711 iteration 3275 : loss : 0.022916, loss_ce: 0.009969
2022-01-21 21:55:41,886 iteration 3276 : loss : 0.025314, loss_ce: 0.008860
2022-01-21 21:55:43,123 iteration 3277 : loss : 0.025711, loss_ce: 0.009999
2022-01-21 21:55:44,297 iteration 3278 : loss : 0.031359, loss_ce: 0.012622
2022-01-21 21:55:45,525 iteration 3279 : loss : 0.041956, loss_ce: 0.018479
2022-01-21 21:55:46,733 iteration 3280 : loss : 0.029751, loss_ce: 0.013891
2022-01-21 21:55:47,921 iteration 3281 : loss : 0.023606, loss_ce: 0.007613
 48%|█████████████              | 193/400 [1:10:37<1:13:10, 21.21s/it]2022-01-21 21:55:49,111 iteration 3282 : loss : 0.024274, loss_ce: 0.010131
2022-01-21 21:55:50,386 iteration 3283 : loss : 0.033839, loss_ce: 0.011980
2022-01-21 21:55:51,540 iteration 3284 : loss : 0.024317, loss_ce: 0.010844
2022-01-21 21:55:52,643 iteration 3285 : loss : 0.021919, loss_ce: 0.008195
2022-01-21 21:55:53,874 iteration 3286 : loss : 0.090323, loss_ce: 0.025313
2022-01-21 21:55:55,095 iteration 3287 : loss : 0.035399, loss_ce: 0.015086
2022-01-21 21:55:56,274 iteration 3288 : loss : 0.029811, loss_ce: 0.009403
2022-01-21 21:55:57,462 iteration 3289 : loss : 0.043948, loss_ce: 0.013873
2022-01-21 21:55:58,598 iteration 3290 : loss : 0.027551, loss_ce: 0.007283
2022-01-21 21:55:59,823 iteration 3291 : loss : 0.036547, loss_ce: 0.011156
2022-01-21 21:56:00,980 iteration 3292 : loss : 0.032655, loss_ce: 0.015553
2022-01-21 21:56:02,105 iteration 3293 : loss : 0.024299, loss_ce: 0.009223
2022-01-21 21:56:03,234 iteration 3294 : loss : 0.024623, loss_ce: 0.009427
2022-01-21 21:56:04,407 iteration 3295 : loss : 0.037592, loss_ce: 0.016366
2022-01-21 21:56:05,606 iteration 3296 : loss : 0.037754, loss_ce: 0.012971
2022-01-21 21:56:06,756 iteration 3297 : loss : 0.044349, loss_ce: 0.017347
2022-01-21 21:56:07,866 iteration 3298 : loss : 0.033381, loss_ce: 0.013258
 48%|█████████████              | 194/400 [1:10:57<1:11:31, 20.83s/it]2022-01-21 21:56:09,041 iteration 3299 : loss : 0.023719, loss_ce: 0.009902
2022-01-21 21:56:10,198 iteration 3300 : loss : 0.036200, loss_ce: 0.017108
2022-01-21 21:56:11,412 iteration 3301 : loss : 0.040024, loss_ce: 0.012173
2022-01-21 21:56:12,530 iteration 3302 : loss : 0.027446, loss_ce: 0.008899
2022-01-21 21:56:13,750 iteration 3303 : loss : 0.036160, loss_ce: 0.012491
2022-01-21 21:56:14,961 iteration 3304 : loss : 0.055656, loss_ce: 0.029541
2022-01-21 21:56:16,174 iteration 3305 : loss : 0.033535, loss_ce: 0.012223
2022-01-21 21:56:17,322 iteration 3306 : loss : 0.027640, loss_ce: 0.010055
2022-01-21 21:56:18,578 iteration 3307 : loss : 0.033950, loss_ce: 0.014726
2022-01-21 21:56:19,837 iteration 3308 : loss : 0.031851, loss_ce: 0.012202
2022-01-21 21:56:21,036 iteration 3309 : loss : 0.023200, loss_ce: 0.010025
2022-01-21 21:56:22,284 iteration 3310 : loss : 0.040617, loss_ce: 0.014608
2022-01-21 21:56:23,453 iteration 3311 : loss : 0.033195, loss_ce: 0.011248
2022-01-21 21:56:24,588 iteration 3312 : loss : 0.022033, loss_ce: 0.010223
2022-01-21 21:56:25,817 iteration 3313 : loss : 0.041025, loss_ce: 0.016143
2022-01-21 21:56:26,890 iteration 3314 : loss : 0.027422, loss_ce: 0.012356
2022-01-21 21:56:26,890 Training Data Eval:
2022-01-21 21:56:32,592   Average segmentation loss on training set: 0.0259
2022-01-21 21:56:32,592 Validation Data Eval:
2022-01-21 21:56:34,556   Average segmentation loss on validation set: 0.1478
2022-01-21 21:56:35,689 iteration 3315 : loss : 0.032847, loss_ce: 0.012976
 49%|█████████████▏             | 195/400 [1:11:25<1:18:20, 22.93s/it]2022-01-21 21:56:36,888 iteration 3316 : loss : 0.028163, loss_ce: 0.006852
2022-01-21 21:56:38,082 iteration 3317 : loss : 0.049868, loss_ce: 0.019610
2022-01-21 21:56:39,272 iteration 3318 : loss : 0.030432, loss_ce: 0.012583
2022-01-21 21:56:40,402 iteration 3319 : loss : 0.021233, loss_ce: 0.008305
2022-01-21 21:56:41,685 iteration 3320 : loss : 0.036542, loss_ce: 0.011808
2022-01-21 21:56:42,801 iteration 3321 : loss : 0.020460, loss_ce: 0.010074
2022-01-21 21:56:43,894 iteration 3322 : loss : 0.026504, loss_ce: 0.009161
2022-01-21 21:56:45,078 iteration 3323 : loss : 0.031401, loss_ce: 0.013817
2022-01-21 21:56:46,265 iteration 3324 : loss : 0.028321, loss_ce: 0.008735
2022-01-21 21:56:47,504 iteration 3325 : loss : 0.029571, loss_ce: 0.010855
2022-01-21 21:56:48,698 iteration 3326 : loss : 0.024351, loss_ce: 0.009001
2022-01-21 21:56:50,019 iteration 3327 : loss : 0.037864, loss_ce: 0.011683
2022-01-21 21:56:51,167 iteration 3328 : loss : 0.030295, loss_ce: 0.017116
2022-01-21 21:56:52,320 iteration 3329 : loss : 0.025982, loss_ce: 0.009762
2022-01-21 21:56:53,516 iteration 3330 : loss : 0.031289, loss_ce: 0.014304
2022-01-21 21:56:54,617 iteration 3331 : loss : 0.021176, loss_ce: 0.007750
2022-01-21 21:56:55,704 iteration 3332 : loss : 0.022629, loss_ce: 0.007137
 49%|█████████████▏             | 196/400 [1:11:45<1:14:59, 22.06s/it]2022-01-21 21:56:56,913 iteration 3333 : loss : 0.035491, loss_ce: 0.016980
2022-01-21 21:56:58,099 iteration 3334 : loss : 0.031135, loss_ce: 0.016139
2022-01-21 21:56:59,334 iteration 3335 : loss : 0.029409, loss_ce: 0.011922
2022-01-21 21:57:00,472 iteration 3336 : loss : 0.025453, loss_ce: 0.008871
2022-01-21 21:57:01,601 iteration 3337 : loss : 0.026251, loss_ce: 0.010067
2022-01-21 21:57:02,809 iteration 3338 : loss : 0.024493, loss_ce: 0.009024
2022-01-21 21:57:04,032 iteration 3339 : loss : 0.044460, loss_ce: 0.014334
2022-01-21 21:57:05,230 iteration 3340 : loss : 0.029407, loss_ce: 0.012275
2022-01-21 21:57:06,373 iteration 3341 : loss : 0.024674, loss_ce: 0.010113
2022-01-21 21:57:07,519 iteration 3342 : loss : 0.027044, loss_ce: 0.014354
2022-01-21 21:57:08,680 iteration 3343 : loss : 0.028029, loss_ce: 0.011214
2022-01-21 21:57:09,916 iteration 3344 : loss : 0.028705, loss_ce: 0.008097
2022-01-21 21:57:11,150 iteration 3345 : loss : 0.022945, loss_ce: 0.010941
2022-01-21 21:57:12,336 iteration 3346 : loss : 0.039879, loss_ce: 0.012367
2022-01-21 21:57:13,501 iteration 3347 : loss : 0.023537, loss_ce: 0.008273
2022-01-21 21:57:14,753 iteration 3348 : loss : 0.027191, loss_ce: 0.010970
2022-01-21 21:57:15,887 iteration 3349 : loss : 0.039658, loss_ce: 0.009859
 49%|█████████████▎             | 197/400 [1:12:05<1:12:43, 21.49s/it]2022-01-21 21:57:17,061 iteration 3350 : loss : 0.021310, loss_ce: 0.010078
2022-01-21 21:57:18,275 iteration 3351 : loss : 0.022485, loss_ce: 0.008071
2022-01-21 21:57:19,415 iteration 3352 : loss : 0.026859, loss_ce: 0.008646
2022-01-21 21:57:20,592 iteration 3353 : loss : 0.025314, loss_ce: 0.007758
2022-01-21 21:57:21,731 iteration 3354 : loss : 0.023328, loss_ce: 0.006257
2022-01-21 21:57:22,920 iteration 3355 : loss : 0.023545, loss_ce: 0.009110
2022-01-21 21:57:24,053 iteration 3356 : loss : 0.039966, loss_ce: 0.020471
2022-01-21 21:57:25,187 iteration 3357 : loss : 0.022331, loss_ce: 0.008862
2022-01-21 21:57:26,356 iteration 3358 : loss : 0.023938, loss_ce: 0.007711
2022-01-21 21:57:27,512 iteration 3359 : loss : 0.026014, loss_ce: 0.012177
2022-01-21 21:57:28,730 iteration 3360 : loss : 0.025779, loss_ce: 0.009689
2022-01-21 21:57:29,918 iteration 3361 : loss : 0.027706, loss_ce: 0.010685
2022-01-21 21:57:31,061 iteration 3362 : loss : 0.036024, loss_ce: 0.012943
2022-01-21 21:57:32,153 iteration 3363 : loss : 0.028649, loss_ce: 0.009587
2022-01-21 21:57:33,375 iteration 3364 : loss : 0.029451, loss_ce: 0.011538
2022-01-21 21:57:34,539 iteration 3365 : loss : 0.024680, loss_ce: 0.010556
2022-01-21 21:57:35,700 iteration 3366 : loss : 0.022742, loss_ce: 0.008980
 50%|█████████████▎             | 198/400 [1:12:25<1:10:39, 20.99s/it]2022-01-21 21:57:37,021 iteration 3367 : loss : 0.031209, loss_ce: 0.013559
2022-01-21 21:57:38,196 iteration 3368 : loss : 0.029627, loss_ce: 0.014294
2022-01-21 21:57:39,388 iteration 3369 : loss : 0.030850, loss_ce: 0.012855
2022-01-21 21:57:40,517 iteration 3370 : loss : 0.022141, loss_ce: 0.006540
2022-01-21 21:57:41,676 iteration 3371 : loss : 0.025291, loss_ce: 0.009165
2022-01-21 21:57:42,906 iteration 3372 : loss : 0.034735, loss_ce: 0.010011
2022-01-21 21:57:44,098 iteration 3373 : loss : 0.022146, loss_ce: 0.008249
2022-01-21 21:57:45,354 iteration 3374 : loss : 0.025288, loss_ce: 0.010496
2022-01-21 21:57:46,631 iteration 3375 : loss : 0.033846, loss_ce: 0.011745
2022-01-21 21:57:47,736 iteration 3376 : loss : 0.019520, loss_ce: 0.006345
2022-01-21 21:57:48,959 iteration 3377 : loss : 0.023982, loss_ce: 0.009987
2022-01-21 21:57:50,105 iteration 3378 : loss : 0.034184, loss_ce: 0.013157
2022-01-21 21:57:51,319 iteration 3379 : loss : 0.024514, loss_ce: 0.009537
2022-01-21 21:57:52,446 iteration 3380 : loss : 0.022367, loss_ce: 0.006813
2022-01-21 21:57:53,636 iteration 3381 : loss : 0.027302, loss_ce: 0.013532
2022-01-21 21:57:54,852 iteration 3382 : loss : 0.033198, loss_ce: 0.012532
2022-01-21 21:57:56,026 iteration 3383 : loss : 0.027182, loss_ce: 0.011607
 50%|█████████████▍             | 199/400 [1:12:45<1:09:38, 20.79s/it]2022-01-21 21:57:57,246 iteration 3384 : loss : 0.025499, loss_ce: 0.010097
2022-01-21 21:57:58,398 iteration 3385 : loss : 0.028945, loss_ce: 0.012258
2022-01-21 21:57:59,539 iteration 3386 : loss : 0.022104, loss_ce: 0.007475
2022-01-21 21:58:00,666 iteration 3387 : loss : 0.034841, loss_ce: 0.011531
2022-01-21 21:58:01,887 iteration 3388 : loss : 0.030596, loss_ce: 0.012385
2022-01-21 21:58:03,018 iteration 3389 : loss : 0.025183, loss_ce: 0.008430
2022-01-21 21:58:04,199 iteration 3390 : loss : 0.046169, loss_ce: 0.020807
2022-01-21 21:58:05,463 iteration 3391 : loss : 0.037542, loss_ce: 0.019918
2022-01-21 21:58:06,694 iteration 3392 : loss : 0.027319, loss_ce: 0.011031
2022-01-21 21:58:07,813 iteration 3393 : loss : 0.030190, loss_ce: 0.012116
2022-01-21 21:58:08,974 iteration 3394 : loss : 0.030013, loss_ce: 0.010073
2022-01-21 21:58:10,158 iteration 3395 : loss : 0.031132, loss_ce: 0.014734
2022-01-21 21:58:11,338 iteration 3396 : loss : 0.024007, loss_ce: 0.009337
2022-01-21 21:58:12,457 iteration 3397 : loss : 0.025102, loss_ce: 0.009771
2022-01-21 21:58:13,765 iteration 3398 : loss : 0.031355, loss_ce: 0.010271
2022-01-21 21:58:14,959 iteration 3399 : loss : 0.030773, loss_ce: 0.013943
2022-01-21 21:58:14,959 Training Data Eval:
2022-01-21 21:58:20,640   Average segmentation loss on training set: 0.0190
2022-01-21 21:58:20,640 Validation Data Eval:
2022-01-21 21:58:22,611   Average segmentation loss on validation set: 0.0620
2022-01-21 21:58:23,792 iteration 3400 : loss : 0.028145, loss_ce: 0.008600
 50%|█████████████▌             | 200/400 [1:13:13<1:16:15, 22.88s/it]2022-01-21 21:58:25,051 iteration 3401 : loss : 0.033966, loss_ce: 0.012620
2022-01-21 21:58:26,250 iteration 3402 : loss : 0.029324, loss_ce: 0.010488
2022-01-21 21:58:27,516 iteration 3403 : loss : 0.030005, loss_ce: 0.011425
2022-01-21 21:58:28,656 iteration 3404 : loss : 0.021031, loss_ce: 0.007304
2022-01-21 21:58:29,821 iteration 3405 : loss : 0.020994, loss_ce: 0.005664
2022-01-21 21:58:30,937 iteration 3406 : loss : 0.030225, loss_ce: 0.013617
2022-01-21 21:58:32,074 iteration 3407 : loss : 0.044898, loss_ce: 0.025824
2022-01-21 21:58:33,248 iteration 3408 : loss : 0.022537, loss_ce: 0.007579
2022-01-21 21:58:34,419 iteration 3409 : loss : 0.024061, loss_ce: 0.004843
2022-01-21 21:58:35,583 iteration 3410 : loss : 0.028840, loss_ce: 0.010647
2022-01-21 21:58:36,794 iteration 3411 : loss : 0.031312, loss_ce: 0.010469
2022-01-21 21:58:38,033 iteration 3412 : loss : 0.028601, loss_ce: 0.013177
2022-01-21 21:58:39,305 iteration 3413 : loss : 0.027526, loss_ce: 0.012880
2022-01-21 21:58:40,542 iteration 3414 : loss : 0.046621, loss_ce: 0.013371
2022-01-21 21:58:41,639 iteration 3415 : loss : 0.021433, loss_ce: 0.008804
2022-01-21 21:58:42,837 iteration 3416 : loss : 0.026833, loss_ce: 0.011674
2022-01-21 21:58:43,998 iteration 3417 : loss : 0.021928, loss_ce: 0.009104
 50%|█████████████▌             | 201/400 [1:13:33<1:13:14, 22.08s/it]2022-01-21 21:58:45,310 iteration 3418 : loss : 0.054965, loss_ce: 0.017798
2022-01-21 21:58:46,508 iteration 3419 : loss : 0.031183, loss_ce: 0.015793
2022-01-21 21:58:47,640 iteration 3420 : loss : 0.027383, loss_ce: 0.013797
2022-01-21 21:58:48,823 iteration 3421 : loss : 0.041386, loss_ce: 0.011952
2022-01-21 21:58:49,995 iteration 3422 : loss : 0.052373, loss_ce: 0.021647
2022-01-21 21:58:51,227 iteration 3423 : loss : 0.038999, loss_ce: 0.016720
2022-01-21 21:58:52,354 iteration 3424 : loss : 0.023200, loss_ce: 0.007796
2022-01-21 21:58:53,544 iteration 3425 : loss : 0.031037, loss_ce: 0.015894
2022-01-21 21:58:54,705 iteration 3426 : loss : 0.025645, loss_ce: 0.007306
2022-01-21 21:58:55,993 iteration 3427 : loss : 0.040265, loss_ce: 0.013998
2022-01-21 21:58:57,189 iteration 3428 : loss : 0.023676, loss_ce: 0.008392
2022-01-21 21:58:58,392 iteration 3429 : loss : 0.032057, loss_ce: 0.015695
2022-01-21 21:58:59,595 iteration 3430 : loss : 0.028754, loss_ce: 0.009194
2022-01-21 21:59:00,836 iteration 3431 : loss : 0.050349, loss_ce: 0.016857
2022-01-21 21:59:01,979 iteration 3432 : loss : 0.029628, loss_ce: 0.010068
2022-01-21 21:59:03,161 iteration 3433 : loss : 0.026797, loss_ce: 0.008029
2022-01-21 21:59:04,320 iteration 3434 : loss : 0.024308, loss_ce: 0.008033
 50%|█████████████▋             | 202/400 [1:13:54<1:11:07, 21.55s/it]2022-01-21 21:59:05,477 iteration 3435 : loss : 0.023122, loss_ce: 0.010930
2022-01-21 21:59:06,633 iteration 3436 : loss : 0.036893, loss_ce: 0.012307
2022-01-21 21:59:07,763 iteration 3437 : loss : 0.024084, loss_ce: 0.007926
2022-01-21 21:59:08,930 iteration 3438 : loss : 0.032075, loss_ce: 0.015544
2022-01-21 21:59:10,181 iteration 3439 : loss : 0.029401, loss_ce: 0.011803
2022-01-21 21:59:11,429 iteration 3440 : loss : 0.045949, loss_ce: 0.014470
2022-01-21 21:59:12,514 iteration 3441 : loss : 0.027922, loss_ce: 0.014272
2022-01-21 21:59:13,651 iteration 3442 : loss : 0.022228, loss_ce: 0.007336
2022-01-21 21:59:14,861 iteration 3443 : loss : 0.021406, loss_ce: 0.007530
2022-01-21 21:59:16,018 iteration 3444 : loss : 0.029541, loss_ce: 0.008916
2022-01-21 21:59:17,226 iteration 3445 : loss : 0.021177, loss_ce: 0.006749
2022-01-21 21:59:18,399 iteration 3446 : loss : 0.038866, loss_ce: 0.011911
2022-01-21 21:59:19,578 iteration 3447 : loss : 0.039380, loss_ce: 0.017818
2022-01-21 21:59:20,680 iteration 3448 : loss : 0.026083, loss_ce: 0.009164
2022-01-21 21:59:21,863 iteration 3449 : loss : 0.041285, loss_ce: 0.011844
2022-01-21 21:59:23,089 iteration 3450 : loss : 0.030968, loss_ce: 0.010362
2022-01-21 21:59:24,220 iteration 3451 : loss : 0.022843, loss_ce: 0.009913
 51%|█████████████▋             | 203/400 [1:14:14<1:09:08, 21.06s/it]2022-01-21 21:59:25,427 iteration 3452 : loss : 0.021548, loss_ce: 0.007806
2022-01-21 21:59:26,650 iteration 3453 : loss : 0.042970, loss_ce: 0.018397
2022-01-21 21:59:27,896 iteration 3454 : loss : 0.025229, loss_ce: 0.009437
2022-01-21 21:59:29,104 iteration 3455 : loss : 0.036935, loss_ce: 0.016740
2022-01-21 21:59:30,308 iteration 3456 : loss : 0.031938, loss_ce: 0.011340
2022-01-21 21:59:31,525 iteration 3457 : loss : 0.032203, loss_ce: 0.013139
2022-01-21 21:59:32,741 iteration 3458 : loss : 0.023922, loss_ce: 0.012213
2022-01-21 21:59:34,006 iteration 3459 : loss : 0.038651, loss_ce: 0.017475
2022-01-21 21:59:35,231 iteration 3460 : loss : 0.037317, loss_ce: 0.012717
2022-01-21 21:59:36,416 iteration 3461 : loss : 0.033548, loss_ce: 0.013400
2022-01-21 21:59:37,549 iteration 3462 : loss : 0.025221, loss_ce: 0.009503
2022-01-21 21:59:38,652 iteration 3463 : loss : 0.022331, loss_ce: 0.007578
2022-01-21 21:59:39,819 iteration 3464 : loss : 0.027235, loss_ce: 0.011277
2022-01-21 21:59:40,948 iteration 3465 : loss : 0.034201, loss_ce: 0.012571
2022-01-21 21:59:42,145 iteration 3466 : loss : 0.020265, loss_ce: 0.008406
2022-01-21 21:59:43,416 iteration 3467 : loss : 0.034199, loss_ce: 0.013802
2022-01-21 21:59:44,717 iteration 3468 : loss : 0.032329, loss_ce: 0.010710
 51%|█████████████▊             | 204/400 [1:14:34<1:08:14, 20.89s/it]2022-01-21 21:59:45,869 iteration 3469 : loss : 0.030204, loss_ce: 0.013305
2022-01-21 21:59:47,185 iteration 3470 : loss : 0.027213, loss_ce: 0.009280
2022-01-21 21:59:48,422 iteration 3471 : loss : 0.029400, loss_ce: 0.010343
2022-01-21 21:59:49,658 iteration 3472 : loss : 0.030226, loss_ce: 0.012550
2022-01-21 21:59:50,903 iteration 3473 : loss : 0.025592, loss_ce: 0.011408
2022-01-21 21:59:52,054 iteration 3474 : loss : 0.029614, loss_ce: 0.013347
2022-01-21 21:59:53,316 iteration 3475 : loss : 0.051725, loss_ce: 0.023620
2022-01-21 21:59:54,494 iteration 3476 : loss : 0.032372, loss_ce: 0.012220
2022-01-21 21:59:55,724 iteration 3477 : loss : 0.036362, loss_ce: 0.010663
2022-01-21 21:59:56,925 iteration 3478 : loss : 0.041592, loss_ce: 0.016285
2022-01-21 21:59:58,089 iteration 3479 : loss : 0.065218, loss_ce: 0.029701
2022-01-21 21:59:59,230 iteration 3480 : loss : 0.025525, loss_ce: 0.010413
2022-01-21 22:00:00,418 iteration 3481 : loss : 0.035260, loss_ce: 0.019398
2022-01-21 22:00:01,530 iteration 3482 : loss : 0.033563, loss_ce: 0.012999
2022-01-21 22:00:02,777 iteration 3483 : loss : 0.025578, loss_ce: 0.009566
2022-01-21 22:00:03,958 iteration 3484 : loss : 0.028040, loss_ce: 0.008875
2022-01-21 22:00:03,958 Training Data Eval:
2022-01-21 22:00:09,666   Average segmentation loss on training set: 0.0202
2022-01-21 22:00:09,666 Validation Data Eval:
2022-01-21 22:00:11,633   Average segmentation loss on validation set: 0.0666
2022-01-21 22:00:12,810 iteration 3485 : loss : 0.023806, loss_ce: 0.009081
 51%|█████████████▊             | 205/400 [1:15:02<1:14:54, 23.05s/it]2022-01-21 22:00:13,991 iteration 3486 : loss : 0.024897, loss_ce: 0.008521
2022-01-21 22:00:15,171 iteration 3487 : loss : 0.027163, loss_ce: 0.010799
2022-01-21 22:00:16,399 iteration 3488 : loss : 0.033418, loss_ce: 0.020121
2022-01-21 22:00:17,542 iteration 3489 : loss : 0.047958, loss_ce: 0.013701
2022-01-21 22:00:18,795 iteration 3490 : loss : 0.026732, loss_ce: 0.010170
2022-01-21 22:00:20,012 iteration 3491 : loss : 0.027271, loss_ce: 0.011892
2022-01-21 22:00:21,114 iteration 3492 : loss : 0.025563, loss_ce: 0.007996
2022-01-21 22:00:22,370 iteration 3493 : loss : 0.042497, loss_ce: 0.010842
2022-01-21 22:00:23,573 iteration 3494 : loss : 0.025461, loss_ce: 0.013195
2022-01-21 22:00:24,670 iteration 3495 : loss : 0.018489, loss_ce: 0.007902
2022-01-21 22:00:25,869 iteration 3496 : loss : 0.042066, loss_ce: 0.011916
2022-01-21 22:00:27,112 iteration 3497 : loss : 0.031878, loss_ce: 0.014645
2022-01-21 22:00:28,307 iteration 3498 : loss : 0.026614, loss_ce: 0.010783
2022-01-21 22:00:29,542 iteration 3499 : loss : 0.031956, loss_ce: 0.007769
2022-01-21 22:00:30,706 iteration 3500 : loss : 0.031534, loss_ce: 0.009789
2022-01-21 22:00:31,908 iteration 3501 : loss : 0.026888, loss_ce: 0.010476
2022-01-21 22:00:33,095 iteration 3502 : loss : 0.027904, loss_ce: 0.009921
 52%|█████████████▉             | 206/400 [1:15:23<1:11:50, 22.22s/it]2022-01-21 22:00:34,251 iteration 3503 : loss : 0.022074, loss_ce: 0.010732
2022-01-21 22:00:35,442 iteration 3504 : loss : 0.025011, loss_ce: 0.008867
2022-01-21 22:00:36,621 iteration 3505 : loss : 0.034234, loss_ce: 0.018875
2022-01-21 22:00:37,889 iteration 3506 : loss : 0.034214, loss_ce: 0.010838
2022-01-21 22:00:39,049 iteration 3507 : loss : 0.035182, loss_ce: 0.014559
2022-01-21 22:00:40,157 iteration 3508 : loss : 0.023059, loss_ce: 0.007105
2022-01-21 22:00:41,316 iteration 3509 : loss : 0.027521, loss_ce: 0.012222
2022-01-21 22:00:42,589 iteration 3510 : loss : 0.024283, loss_ce: 0.009305
2022-01-21 22:00:43,749 iteration 3511 : loss : 0.024174, loss_ce: 0.009984
2022-01-21 22:00:44,941 iteration 3512 : loss : 0.031404, loss_ce: 0.012777
2022-01-21 22:00:46,068 iteration 3513 : loss : 0.033791, loss_ce: 0.010720
2022-01-21 22:00:47,172 iteration 3514 : loss : 0.018450, loss_ce: 0.008058
2022-01-21 22:00:48,322 iteration 3515 : loss : 0.024892, loss_ce: 0.009891
2022-01-21 22:00:49,539 iteration 3516 : loss : 0.025966, loss_ce: 0.009732
2022-01-21 22:00:50,722 iteration 3517 : loss : 0.020858, loss_ce: 0.008031
2022-01-21 22:00:51,843 iteration 3518 : loss : 0.018992, loss_ce: 0.008385
2022-01-21 22:00:52,979 iteration 3519 : loss : 0.028636, loss_ce: 0.009477
 52%|█████████████▉             | 207/400 [1:15:42<1:09:13, 21.52s/it]2022-01-21 22:00:54,182 iteration 3520 : loss : 0.023042, loss_ce: 0.007728
2022-01-21 22:00:55,386 iteration 3521 : loss : 0.026805, loss_ce: 0.010057
2022-01-21 22:00:56,595 iteration 3522 : loss : 0.031132, loss_ce: 0.015767
2022-01-21 22:00:57,881 iteration 3523 : loss : 0.045546, loss_ce: 0.020468
2022-01-21 22:00:59,042 iteration 3524 : loss : 0.031557, loss_ce: 0.008197
2022-01-21 22:01:00,247 iteration 3525 : loss : 0.029499, loss_ce: 0.012889
2022-01-21 22:01:01,447 iteration 3526 : loss : 0.026653, loss_ce: 0.012918
2022-01-21 22:01:02,658 iteration 3527 : loss : 0.020764, loss_ce: 0.006178
2022-01-21 22:01:03,794 iteration 3528 : loss : 0.022700, loss_ce: 0.011687
2022-01-21 22:01:04,980 iteration 3529 : loss : 0.039790, loss_ce: 0.012333
2022-01-21 22:01:06,150 iteration 3530 : loss : 0.033813, loss_ce: 0.010893
2022-01-21 22:01:07,353 iteration 3531 : loss : 0.029465, loss_ce: 0.011490
2022-01-21 22:01:08,504 iteration 3532 : loss : 0.021667, loss_ce: 0.007456
2022-01-21 22:01:09,637 iteration 3533 : loss : 0.027143, loss_ce: 0.011319
2022-01-21 22:01:10,784 iteration 3534 : loss : 0.023774, loss_ce: 0.011719
2022-01-21 22:01:11,905 iteration 3535 : loss : 0.019215, loss_ce: 0.006969
2022-01-21 22:01:13,022 iteration 3536 : loss : 0.022733, loss_ce: 0.006739
 52%|██████████████             | 208/400 [1:16:02<1:07:26, 21.08s/it]2022-01-21 22:01:14,213 iteration 3537 : loss : 0.022749, loss_ce: 0.008024
2022-01-21 22:01:15,386 iteration 3538 : loss : 0.028157, loss_ce: 0.008101
2022-01-21 22:01:16,596 iteration 3539 : loss : 0.028230, loss_ce: 0.013201
2022-01-21 22:01:17,724 iteration 3540 : loss : 0.025293, loss_ce: 0.005456
2022-01-21 22:01:18,960 iteration 3541 : loss : 0.066068, loss_ce: 0.035572
2022-01-21 22:01:20,118 iteration 3542 : loss : 0.023292, loss_ce: 0.006757
2022-01-21 22:01:21,318 iteration 3543 : loss : 0.023407, loss_ce: 0.011396
2022-01-21 22:01:22,537 iteration 3544 : loss : 0.029825, loss_ce: 0.010817
2022-01-21 22:01:23,686 iteration 3545 : loss : 0.026678, loss_ce: 0.009427
2022-01-21 22:01:24,788 iteration 3546 : loss : 0.022514, loss_ce: 0.010212
2022-01-21 22:01:26,004 iteration 3547 : loss : 0.035063, loss_ce: 0.012408
2022-01-21 22:01:27,223 iteration 3548 : loss : 0.024986, loss_ce: 0.008131
2022-01-21 22:01:28,408 iteration 3549 : loss : 0.031704, loss_ce: 0.017811
2022-01-21 22:01:29,544 iteration 3550 : loss : 0.024275, loss_ce: 0.008099
2022-01-21 22:01:30,788 iteration 3551 : loss : 0.031903, loss_ce: 0.008945
2022-01-21 22:01:32,027 iteration 3552 : loss : 0.046850, loss_ce: 0.019274
2022-01-21 22:01:33,271 iteration 3553 : loss : 0.031712, loss_ce: 0.011615
 52%|██████████████             | 209/400 [1:16:23<1:06:17, 20.83s/it]2022-01-21 22:01:34,476 iteration 3554 : loss : 0.021872, loss_ce: 0.008287
2022-01-21 22:01:35,700 iteration 3555 : loss : 0.027438, loss_ce: 0.012602
2022-01-21 22:01:36,872 iteration 3556 : loss : 0.036087, loss_ce: 0.014088
2022-01-21 22:01:38,028 iteration 3557 : loss : 0.021692, loss_ce: 0.009648
2022-01-21 22:01:39,147 iteration 3558 : loss : 0.020265, loss_ce: 0.006865
2022-01-21 22:01:40,378 iteration 3559 : loss : 0.027912, loss_ce: 0.010199
2022-01-21 22:01:41,541 iteration 3560 : loss : 0.029326, loss_ce: 0.008495
2022-01-21 22:01:42,748 iteration 3561 : loss : 0.024496, loss_ce: 0.010330
2022-01-21 22:01:43,927 iteration 3562 : loss : 0.032373, loss_ce: 0.012087
2022-01-21 22:01:45,105 iteration 3563 : loss : 0.022250, loss_ce: 0.008257
2022-01-21 22:01:46,317 iteration 3564 : loss : 0.033878, loss_ce: 0.011494
2022-01-21 22:01:47,440 iteration 3565 : loss : 0.033853, loss_ce: 0.014073
2022-01-21 22:01:48,511 iteration 3566 : loss : 0.018220, loss_ce: 0.007004
2022-01-21 22:01:49,615 iteration 3567 : loss : 0.025824, loss_ce: 0.007889
2022-01-21 22:01:50,825 iteration 3568 : loss : 0.026252, loss_ce: 0.009585
2022-01-21 22:01:51,957 iteration 3569 : loss : 0.024858, loss_ce: 0.010293
2022-01-21 22:01:51,957 Training Data Eval:
2022-01-21 22:01:57,630   Average segmentation loss on training set: 0.0171
2022-01-21 22:01:57,630 Validation Data Eval:
2022-01-21 22:01:59,595   Average segmentation loss on validation set: 0.0647
2022-01-21 22:02:00,738 iteration 3570 : loss : 0.022577, loss_ce: 0.007036
 52%|██████████████▏            | 210/400 [1:16:50<1:12:15, 22.82s/it]2022-01-21 22:02:01,980 iteration 3571 : loss : 0.028683, loss_ce: 0.012033
2022-01-21 22:02:03,228 iteration 3572 : loss : 0.022860, loss_ce: 0.008710
2022-01-21 22:02:04,433 iteration 3573 : loss : 0.027077, loss_ce: 0.009480
2022-01-21 22:02:05,582 iteration 3574 : loss : 0.022911, loss_ce: 0.009649
2022-01-21 22:02:06,719 iteration 3575 : loss : 0.023567, loss_ce: 0.008657
2022-01-21 22:02:07,863 iteration 3576 : loss : 0.030392, loss_ce: 0.010813
2022-01-21 22:02:09,071 iteration 3577 : loss : 0.025171, loss_ce: 0.010071
2022-01-21 22:02:10,229 iteration 3578 : loss : 0.020763, loss_ce: 0.009016
2022-01-21 22:02:11,413 iteration 3579 : loss : 0.024650, loss_ce: 0.008878
2022-01-21 22:02:12,632 iteration 3580 : loss : 0.025243, loss_ce: 0.010905
2022-01-21 22:02:13,853 iteration 3581 : loss : 0.029194, loss_ce: 0.010003
2022-01-21 22:02:15,051 iteration 3582 : loss : 0.030904, loss_ce: 0.011973
2022-01-21 22:02:16,219 iteration 3583 : loss : 0.026218, loss_ce: 0.007255
2022-01-21 22:02:17,321 iteration 3584 : loss : 0.022939, loss_ce: 0.008193
2022-01-21 22:02:18,467 iteration 3585 : loss : 0.018550, loss_ce: 0.007185
2022-01-21 22:02:19,587 iteration 3586 : loss : 0.017104, loss_ce: 0.004993
2022-01-21 22:02:20,765 iteration 3587 : loss : 0.029339, loss_ce: 0.014558
 53%|██████████████▏            | 211/400 [1:17:10<1:09:14, 21.98s/it]2022-01-21 22:02:22,033 iteration 3588 : loss : 0.021802, loss_ce: 0.008300
2022-01-21 22:02:23,276 iteration 3589 : loss : 0.027381, loss_ce: 0.007069
2022-01-21 22:02:24,463 iteration 3590 : loss : 0.039152, loss_ce: 0.011656
2022-01-21 22:02:25,596 iteration 3591 : loss : 0.022443, loss_ce: 0.007254
2022-01-21 22:02:26,768 iteration 3592 : loss : 0.018723, loss_ce: 0.007180
2022-01-21 22:02:27,974 iteration 3593 : loss : 0.026845, loss_ce: 0.013539
2022-01-21 22:02:29,150 iteration 3594 : loss : 0.024284, loss_ce: 0.007571
2022-01-21 22:02:30,319 iteration 3595 : loss : 0.041073, loss_ce: 0.013471
2022-01-21 22:02:31,461 iteration 3596 : loss : 0.021464, loss_ce: 0.008836
2022-01-21 22:02:32,644 iteration 3597 : loss : 0.024688, loss_ce: 0.009759
2022-01-21 22:02:33,854 iteration 3598 : loss : 0.026462, loss_ce: 0.011315
2022-01-21 22:02:35,069 iteration 3599 : loss : 0.031894, loss_ce: 0.012388
2022-01-21 22:02:36,196 iteration 3600 : loss : 0.021725, loss_ce: 0.011742
2022-01-21 22:02:37,401 iteration 3601 : loss : 0.022367, loss_ce: 0.008860
2022-01-21 22:02:38,615 iteration 3602 : loss : 0.030907, loss_ce: 0.011653
2022-01-21 22:02:39,766 iteration 3603 : loss : 0.028827, loss_ce: 0.013850
2022-01-21 22:02:40,939 iteration 3604 : loss : 0.037555, loss_ce: 0.009720
 53%|██████████████▎            | 212/400 [1:17:30<1:07:11, 21.44s/it]2022-01-21 22:02:42,279 iteration 3605 : loss : 0.036224, loss_ce: 0.015228
2022-01-21 22:02:43,399 iteration 3606 : loss : 0.030388, loss_ce: 0.007477
2022-01-21 22:02:44,484 iteration 3607 : loss : 0.020147, loss_ce: 0.009013
2022-01-21 22:02:45,711 iteration 3608 : loss : 0.025920, loss_ce: 0.008825
2022-01-21 22:02:46,939 iteration 3609 : loss : 0.060692, loss_ce: 0.024047
2022-01-21 22:02:48,058 iteration 3610 : loss : 0.014808, loss_ce: 0.005746
2022-01-21 22:02:49,229 iteration 3611 : loss : 0.028097, loss_ce: 0.011695
2022-01-21 22:02:50,357 iteration 3612 : loss : 0.020975, loss_ce: 0.008538
2022-01-21 22:02:51,540 iteration 3613 : loss : 0.019511, loss_ce: 0.006937
2022-01-21 22:02:52,682 iteration 3614 : loss : 0.021168, loss_ce: 0.008488
2022-01-21 22:02:53,842 iteration 3615 : loss : 0.027685, loss_ce: 0.009471
2022-01-21 22:02:55,002 iteration 3616 : loss : 0.023231, loss_ce: 0.011996
2022-01-21 22:02:56,200 iteration 3617 : loss : 0.027213, loss_ce: 0.013519
2022-01-21 22:02:57,403 iteration 3618 : loss : 0.033151, loss_ce: 0.012716
2022-01-21 22:02:58,560 iteration 3619 : loss : 0.020556, loss_ce: 0.006919
2022-01-21 22:02:59,745 iteration 3620 : loss : 0.032834, loss_ce: 0.010728
2022-01-21 22:03:00,911 iteration 3621 : loss : 0.020337, loss_ce: 0.009415
 53%|██████████████▍            | 213/400 [1:17:50<1:05:27, 21.00s/it]2022-01-21 22:03:02,167 iteration 3622 : loss : 0.024420, loss_ce: 0.007532
2022-01-21 22:03:03,357 iteration 3623 : loss : 0.024704, loss_ce: 0.009203
2022-01-21 22:03:04,551 iteration 3624 : loss : 0.039429, loss_ce: 0.017260
2022-01-21 22:03:05,661 iteration 3625 : loss : 0.021417, loss_ce: 0.008389
2022-01-21 22:03:06,847 iteration 3626 : loss : 0.034871, loss_ce: 0.012403
2022-01-21 22:03:08,056 iteration 3627 : loss : 0.031881, loss_ce: 0.013465
2022-01-21 22:03:09,271 iteration 3628 : loss : 0.039553, loss_ce: 0.012063
2022-01-21 22:03:10,525 iteration 3629 : loss : 0.042737, loss_ce: 0.019497
2022-01-21 22:03:11,726 iteration 3630 : loss : 0.022406, loss_ce: 0.009599
2022-01-21 22:03:12,911 iteration 3631 : loss : 0.028671, loss_ce: 0.010859
2022-01-21 22:03:14,128 iteration 3632 : loss : 0.028444, loss_ce: 0.014781
2022-01-21 22:03:15,350 iteration 3633 : loss : 0.049975, loss_ce: 0.021296
2022-01-21 22:03:16,491 iteration 3634 : loss : 0.024792, loss_ce: 0.008574
2022-01-21 22:03:17,779 iteration 3635 : loss : 0.024177, loss_ce: 0.011437
2022-01-21 22:03:18,890 iteration 3636 : loss : 0.023514, loss_ce: 0.011451
2022-01-21 22:03:20,068 iteration 3637 : loss : 0.028641, loss_ce: 0.013188
2022-01-21 22:03:21,267 iteration 3638 : loss : 0.032218, loss_ce: 0.011563
 54%|██████████████▍            | 214/400 [1:18:11<1:04:30, 20.81s/it]2022-01-21 22:03:22,527 iteration 3639 : loss : 0.028176, loss_ce: 0.009437
2022-01-21 22:03:23,744 iteration 3640 : loss : 0.033764, loss_ce: 0.011667
2022-01-21 22:03:24,963 iteration 3641 : loss : 0.028143, loss_ce: 0.012359
2022-01-21 22:03:26,122 iteration 3642 : loss : 0.035732, loss_ce: 0.017530
2022-01-21 22:03:27,329 iteration 3643 : loss : 0.025891, loss_ce: 0.008080
2022-01-21 22:03:28,534 iteration 3644 : loss : 0.027079, loss_ce: 0.010006
2022-01-21 22:03:29,789 iteration 3645 : loss : 0.054834, loss_ce: 0.020509
2022-01-21 22:03:30,991 iteration 3646 : loss : 0.035332, loss_ce: 0.017951
2022-01-21 22:03:32,153 iteration 3647 : loss : 0.022342, loss_ce: 0.008747
2022-01-21 22:03:33,365 iteration 3648 : loss : 0.029787, loss_ce: 0.009885
2022-01-21 22:03:34,448 iteration 3649 : loss : 0.024119, loss_ce: 0.009671
2022-01-21 22:03:35,639 iteration 3650 : loss : 0.025024, loss_ce: 0.011473
2022-01-21 22:03:36,780 iteration 3651 : loss : 0.021524, loss_ce: 0.008184
2022-01-21 22:03:37,900 iteration 3652 : loss : 0.027733, loss_ce: 0.010858
2022-01-21 22:03:39,127 iteration 3653 : loss : 0.035531, loss_ce: 0.015822
2022-01-21 22:03:40,284 iteration 3654 : loss : 0.022592, loss_ce: 0.008608
2022-01-21 22:03:40,284 Training Data Eval:
2022-01-21 22:03:45,975   Average segmentation loss on training set: 0.0188
2022-01-21 22:03:45,976 Validation Data Eval:
2022-01-21 22:03:47,945   Average segmentation loss on validation set: 0.0892
2022-01-21 22:03:49,254 iteration 3655 : loss : 0.040763, loss_ce: 0.014978
 54%|██████████████▌            | 215/400 [1:18:39<1:10:47, 22.96s/it]2022-01-21 22:03:50,478 iteration 3656 : loss : 0.030861, loss_ce: 0.009757
2022-01-21 22:03:51,696 iteration 3657 : loss : 0.030502, loss_ce: 0.013114
2022-01-21 22:03:52,876 iteration 3658 : loss : 0.025778, loss_ce: 0.010548
2022-01-21 22:03:53,989 iteration 3659 : loss : 0.034730, loss_ce: 0.011653
2022-01-21 22:03:55,244 iteration 3660 : loss : 0.026388, loss_ce: 0.009619
2022-01-21 22:03:56,407 iteration 3661 : loss : 0.038478, loss_ce: 0.016054
2022-01-21 22:03:57,526 iteration 3662 : loss : 0.029476, loss_ce: 0.012818
2022-01-21 22:03:58,691 iteration 3663 : loss : 0.032474, loss_ce: 0.011944
2022-01-21 22:03:59,890 iteration 3664 : loss : 0.023595, loss_ce: 0.007401
2022-01-21 22:04:01,172 iteration 3665 : loss : 0.024761, loss_ce: 0.006771
2022-01-21 22:04:02,405 iteration 3666 : loss : 0.038002, loss_ce: 0.015436
2022-01-21 22:04:03,563 iteration 3667 : loss : 0.030565, loss_ce: 0.012432
2022-01-21 22:04:04,725 iteration 3668 : loss : 0.036376, loss_ce: 0.013373
2022-01-21 22:04:05,930 iteration 3669 : loss : 0.049859, loss_ce: 0.014216
2022-01-21 22:04:07,042 iteration 3670 : loss : 0.023674, loss_ce: 0.010748
2022-01-21 22:04:08,205 iteration 3671 : loss : 0.043634, loss_ce: 0.010296
2022-01-21 22:04:09,362 iteration 3672 : loss : 0.028994, loss_ce: 0.008082
 54%|██████████████▌            | 216/400 [1:18:59<1:07:47, 22.11s/it]2022-01-21 22:04:10,579 iteration 3673 : loss : 0.025614, loss_ce: 0.010508
2022-01-21 22:04:11,830 iteration 3674 : loss : 0.022049, loss_ce: 0.010723
2022-01-21 22:04:13,078 iteration 3675 : loss : 0.042731, loss_ce: 0.016061
2022-01-21 22:04:14,315 iteration 3676 : loss : 0.034790, loss_ce: 0.010230
2022-01-21 22:04:15,527 iteration 3677 : loss : 0.024466, loss_ce: 0.011215
2022-01-21 22:04:16,789 iteration 3678 : loss : 0.037361, loss_ce: 0.012404
2022-01-21 22:04:17,896 iteration 3679 : loss : 0.021533, loss_ce: 0.007911
2022-01-21 22:04:19,030 iteration 3680 : loss : 0.019758, loss_ce: 0.007294
2022-01-21 22:04:20,207 iteration 3681 : loss : 0.060528, loss_ce: 0.020357
2022-01-21 22:04:21,307 iteration 3682 : loss : 0.019965, loss_ce: 0.006184
2022-01-21 22:04:22,470 iteration 3683 : loss : 0.029678, loss_ce: 0.013231
2022-01-21 22:04:23,585 iteration 3684 : loss : 0.020706, loss_ce: 0.006914
2022-01-21 22:04:24,744 iteration 3685 : loss : 0.023357, loss_ce: 0.007914
2022-01-21 22:04:25,986 iteration 3686 : loss : 0.028693, loss_ce: 0.010567
2022-01-21 22:04:27,239 iteration 3687 : loss : 0.033594, loss_ce: 0.013899
2022-01-21 22:04:28,445 iteration 3688 : loss : 0.030389, loss_ce: 0.011158
2022-01-21 22:04:29,657 iteration 3689 : loss : 0.033706, loss_ce: 0.009667
 54%|██████████████▋            | 217/400 [1:19:19<1:05:45, 21.56s/it]2022-01-21 22:04:31,008 iteration 3690 : loss : 0.028994, loss_ce: 0.013897
2022-01-21 22:04:32,175 iteration 3691 : loss : 0.030458, loss_ce: 0.007590
2022-01-21 22:04:33,383 iteration 3692 : loss : 0.025070, loss_ce: 0.007520
2022-01-21 22:04:34,518 iteration 3693 : loss : 0.018891, loss_ce: 0.005254
2022-01-21 22:04:35,724 iteration 3694 : loss : 0.025316, loss_ce: 0.008247
2022-01-21 22:04:36,922 iteration 3695 : loss : 0.023175, loss_ce: 0.008823
2022-01-21 22:04:38,058 iteration 3696 : loss : 0.019362, loss_ce: 0.007318
2022-01-21 22:04:39,192 iteration 3697 : loss : 0.053334, loss_ce: 0.015696
2022-01-21 22:04:40,451 iteration 3698 : loss : 0.028991, loss_ce: 0.009931
2022-01-21 22:04:41,638 iteration 3699 : loss : 0.025951, loss_ce: 0.012489
2022-01-21 22:04:42,809 iteration 3700 : loss : 0.023350, loss_ce: 0.007598
2022-01-21 22:04:43,920 iteration 3701 : loss : 0.027146, loss_ce: 0.013358
2022-01-21 22:04:45,132 iteration 3702 : loss : 0.022661, loss_ce: 0.008470
2022-01-21 22:04:46,316 iteration 3703 : loss : 0.022584, loss_ce: 0.008100
2022-01-21 22:04:47,492 iteration 3704 : loss : 0.025831, loss_ce: 0.011035
2022-01-21 22:04:48,682 iteration 3705 : loss : 0.028651, loss_ce: 0.012857
2022-01-21 22:04:49,804 iteration 3706 : loss : 0.027500, loss_ce: 0.009323
 55%|██████████████▋            | 218/400 [1:19:39<1:04:07, 21.14s/it]2022-01-21 22:04:51,065 iteration 3707 : loss : 0.089780, loss_ce: 0.013734
2022-01-21 22:04:52,361 iteration 3708 : loss : 0.028671, loss_ce: 0.008422
2022-01-21 22:04:53,550 iteration 3709 : loss : 0.024237, loss_ce: 0.007680
2022-01-21 22:04:54,648 iteration 3710 : loss : 0.023545, loss_ce: 0.008611
2022-01-21 22:04:55,936 iteration 3711 : loss : 0.033919, loss_ce: 0.014206
2022-01-21 22:04:57,075 iteration 3712 : loss : 0.034719, loss_ce: 0.012896
2022-01-21 22:04:58,193 iteration 3713 : loss : 0.019584, loss_ce: 0.007032
2022-01-21 22:04:59,398 iteration 3714 : loss : 0.042625, loss_ce: 0.016921
2022-01-21 22:05:00,548 iteration 3715 : loss : 0.031499, loss_ce: 0.012803
2022-01-21 22:05:01,725 iteration 3716 : loss : 0.028601, loss_ce: 0.012607
2022-01-21 22:05:02,915 iteration 3717 : loss : 0.024046, loss_ce: 0.009696
2022-01-21 22:05:04,137 iteration 3718 : loss : 0.032579, loss_ce: 0.011228
2022-01-21 22:05:05,419 iteration 3719 : loss : 0.035385, loss_ce: 0.012258
2022-01-21 22:05:06,678 iteration 3720 : loss : 0.026611, loss_ce: 0.010594
2022-01-21 22:05:07,877 iteration 3721 : loss : 0.031106, loss_ce: 0.013455
2022-01-21 22:05:09,125 iteration 3722 : loss : 0.044630, loss_ce: 0.014750
2022-01-21 22:05:10,288 iteration 3723 : loss : 0.023104, loss_ce: 0.009565
 55%|██████████████▊            | 219/400 [1:20:00<1:03:09, 20.94s/it]2022-01-21 22:05:11,524 iteration 3724 : loss : 0.034531, loss_ce: 0.018033
2022-01-21 22:05:12,750 iteration 3725 : loss : 0.029714, loss_ce: 0.011390
2022-01-21 22:05:13,920 iteration 3726 : loss : 0.026213, loss_ce: 0.011255
2022-01-21 22:05:15,105 iteration 3727 : loss : 0.019443, loss_ce: 0.006199
2022-01-21 22:05:16,200 iteration 3728 : loss : 0.021876, loss_ce: 0.009945
2022-01-21 22:05:17,420 iteration 3729 : loss : 0.028360, loss_ce: 0.010313
2022-01-21 22:05:18,560 iteration 3730 : loss : 0.025361, loss_ce: 0.008756
2022-01-21 22:05:19,788 iteration 3731 : loss : 0.033237, loss_ce: 0.014763
2022-01-21 22:05:20,967 iteration 3732 : loss : 0.024878, loss_ce: 0.011779
2022-01-21 22:05:22,082 iteration 3733 : loss : 0.019020, loss_ce: 0.005812
2022-01-21 22:05:23,292 iteration 3734 : loss : 0.031547, loss_ce: 0.010377
2022-01-21 22:05:24,535 iteration 3735 : loss : 0.028106, loss_ce: 0.009911
2022-01-21 22:05:25,746 iteration 3736 : loss : 0.031142, loss_ce: 0.013512
2022-01-21 22:05:26,982 iteration 3737 : loss : 0.034152, loss_ce: 0.013458
2022-01-21 22:05:28,162 iteration 3738 : loss : 0.052950, loss_ce: 0.016480
2022-01-21 22:05:29,336 iteration 3739 : loss : 0.025150, loss_ce: 0.007010
2022-01-21 22:05:29,336 Training Data Eval:
2022-01-21 22:05:35,029   Average segmentation loss on training set: 0.0170
2022-01-21 22:05:35,029 Validation Data Eval:
2022-01-21 22:05:36,998   Average segmentation loss on validation set: 0.0680
2022-01-21 22:05:38,129 iteration 3740 : loss : 0.034746, loss_ce: 0.013962
 55%|██████████████▊            | 220/400 [1:20:28<1:09:02, 23.01s/it]2022-01-21 22:05:39,372 iteration 3741 : loss : 0.024793, loss_ce: 0.011150
2022-01-21 22:05:40,541 iteration 3742 : loss : 0.021337, loss_ce: 0.007357
2022-01-21 22:05:41,695 iteration 3743 : loss : 0.020777, loss_ce: 0.006003
2022-01-21 22:05:42,894 iteration 3744 : loss : 0.025285, loss_ce: 0.010757
2022-01-21 22:05:44,158 iteration 3745 : loss : 0.030283, loss_ce: 0.017592
2022-01-21 22:05:45,316 iteration 3746 : loss : 0.043734, loss_ce: 0.011734
2022-01-21 22:05:46,529 iteration 3747 : loss : 0.034054, loss_ce: 0.016767
2022-01-21 22:05:47,760 iteration 3748 : loss : 0.036700, loss_ce: 0.012760
2022-01-21 22:05:48,950 iteration 3749 : loss : 0.021976, loss_ce: 0.006240
2022-01-21 22:05:50,228 iteration 3750 : loss : 0.037954, loss_ce: 0.015077
2022-01-21 22:05:51,398 iteration 3751 : loss : 0.036727, loss_ce: 0.018627
2022-01-21 22:05:52,549 iteration 3752 : loss : 0.031122, loss_ce: 0.011754
2022-01-21 22:05:53,713 iteration 3753 : loss : 0.030160, loss_ce: 0.011864
2022-01-21 22:05:54,829 iteration 3754 : loss : 0.027042, loss_ce: 0.012806
2022-01-21 22:05:56,011 iteration 3755 : loss : 0.024770, loss_ce: 0.008403
2022-01-21 22:05:57,164 iteration 3756 : loss : 0.020138, loss_ce: 0.006880
2022-01-21 22:05:58,344 iteration 3757 : loss : 0.033842, loss_ce: 0.013005
 55%|██████████████▉            | 221/400 [1:20:48<1:06:09, 22.17s/it]2022-01-21 22:05:59,619 iteration 3758 : loss : 0.032478, loss_ce: 0.011846
2022-01-21 22:06:00,853 iteration 3759 : loss : 0.030254, loss_ce: 0.012283
2022-01-21 22:06:02,072 iteration 3760 : loss : 0.049529, loss_ce: 0.022126
2022-01-21 22:06:03,263 iteration 3761 : loss : 0.027691, loss_ce: 0.013215
2022-01-21 22:06:04,500 iteration 3762 : loss : 0.035058, loss_ce: 0.014585
2022-01-21 22:06:05,760 iteration 3763 : loss : 0.038511, loss_ce: 0.015514
2022-01-21 22:06:06,914 iteration 3764 : loss : 0.030366, loss_ce: 0.006966
2022-01-21 22:06:08,018 iteration 3765 : loss : 0.025735, loss_ce: 0.008889
2022-01-21 22:06:09,149 iteration 3766 : loss : 0.020526, loss_ce: 0.006332
2022-01-21 22:06:10,331 iteration 3767 : loss : 0.026189, loss_ce: 0.009191
2022-01-21 22:06:11,574 iteration 3768 : loss : 0.028347, loss_ce: 0.010624
2022-01-21 22:06:12,759 iteration 3769 : loss : 0.031203, loss_ce: 0.010779
2022-01-21 22:06:13,991 iteration 3770 : loss : 0.021555, loss_ce: 0.009539
2022-01-21 22:06:15,203 iteration 3771 : loss : 0.033364, loss_ce: 0.014637
2022-01-21 22:06:16,426 iteration 3772 : loss : 0.038452, loss_ce: 0.010737
2022-01-21 22:06:17,615 iteration 3773 : loss : 0.026754, loss_ce: 0.008986
2022-01-21 22:06:18,813 iteration 3774 : loss : 0.030456, loss_ce: 0.014911
 56%|██████████████▉            | 222/400 [1:21:08<1:04:15, 21.66s/it]2022-01-21 22:06:20,082 iteration 3775 : loss : 0.032573, loss_ce: 0.012836
2022-01-21 22:06:21,267 iteration 3776 : loss : 0.019505, loss_ce: 0.007631
2022-01-21 22:06:22,449 iteration 3777 : loss : 0.033767, loss_ce: 0.010014
2022-01-21 22:06:23,682 iteration 3778 : loss : 0.042265, loss_ce: 0.016229
2022-01-21 22:06:24,813 iteration 3779 : loss : 0.023184, loss_ce: 0.008908
2022-01-21 22:06:26,052 iteration 3780 : loss : 0.035559, loss_ce: 0.018865
2022-01-21 22:06:27,274 iteration 3781 : loss : 0.027748, loss_ce: 0.009235
2022-01-21 22:06:28,516 iteration 3782 : loss : 0.031267, loss_ce: 0.011687
2022-01-21 22:06:29,752 iteration 3783 : loss : 0.025960, loss_ce: 0.013364
2022-01-21 22:06:30,884 iteration 3784 : loss : 0.025275, loss_ce: 0.006835
2022-01-21 22:06:32,068 iteration 3785 : loss : 0.037290, loss_ce: 0.009862
2022-01-21 22:06:33,251 iteration 3786 : loss : 0.028107, loss_ce: 0.011175
2022-01-21 22:06:34,379 iteration 3787 : loss : 0.028232, loss_ce: 0.011393
2022-01-21 22:06:35,573 iteration 3788 : loss : 0.028779, loss_ce: 0.009854
2022-01-21 22:06:36,757 iteration 3789 : loss : 0.028296, loss_ce: 0.012081
2022-01-21 22:06:37,906 iteration 3790 : loss : 0.025523, loss_ce: 0.009269
2022-01-21 22:06:39,136 iteration 3791 : loss : 0.022266, loss_ce: 0.008556
 56%|███████████████            | 223/400 [1:21:29<1:02:42, 21.26s/it]2022-01-21 22:06:40,318 iteration 3792 : loss : 0.025120, loss_ce: 0.009330
2022-01-21 22:06:41,430 iteration 3793 : loss : 0.018313, loss_ce: 0.004605
2022-01-21 22:06:42,581 iteration 3794 : loss : 0.023989, loss_ce: 0.009919
2022-01-21 22:06:43,729 iteration 3795 : loss : 0.021501, loss_ce: 0.006894
2022-01-21 22:06:44,966 iteration 3796 : loss : 0.019202, loss_ce: 0.005417
2022-01-21 22:06:46,171 iteration 3797 : loss : 0.021148, loss_ce: 0.006654
2022-01-21 22:06:47,303 iteration 3798 : loss : 0.019862, loss_ce: 0.007301
2022-01-21 22:06:48,563 iteration 3799 : loss : 0.043682, loss_ce: 0.021298
2022-01-21 22:06:49,881 iteration 3800 : loss : 0.042599, loss_ce: 0.020200
2022-01-21 22:06:51,148 iteration 3801 : loss : 0.033880, loss_ce: 0.010233
2022-01-21 22:06:52,389 iteration 3802 : loss : 0.026714, loss_ce: 0.010851
2022-01-21 22:06:53,565 iteration 3803 : loss : 0.025151, loss_ce: 0.009777
2022-01-21 22:06:54,752 iteration 3804 : loss : 0.026610, loss_ce: 0.009453
2022-01-21 22:06:55,931 iteration 3805 : loss : 0.025072, loss_ce: 0.010918
2022-01-21 22:06:57,030 iteration 3806 : loss : 0.020996, loss_ce: 0.009607
2022-01-21 22:06:58,230 iteration 3807 : loss : 0.026653, loss_ce: 0.009051
2022-01-21 22:06:59,388 iteration 3808 : loss : 0.033575, loss_ce: 0.014444
 56%|███████████████            | 224/400 [1:21:49<1:01:28, 20.96s/it]2022-01-21 22:07:00,643 iteration 3809 : loss : 0.031334, loss_ce: 0.013023
2022-01-21 22:07:01,857 iteration 3810 : loss : 0.022261, loss_ce: 0.008007
2022-01-21 22:07:03,013 iteration 3811 : loss : 0.043975, loss_ce: 0.018172
2022-01-21 22:07:04,205 iteration 3812 : loss : 0.022090, loss_ce: 0.007104
2022-01-21 22:07:05,305 iteration 3813 : loss : 0.024272, loss_ce: 0.010305
2022-01-21 22:07:06,535 iteration 3814 : loss : 0.030906, loss_ce: 0.014426
2022-01-21 22:07:07,809 iteration 3815 : loss : 0.022215, loss_ce: 0.008242
2022-01-21 22:07:08,946 iteration 3816 : loss : 0.016146, loss_ce: 0.005581
2022-01-21 22:07:10,022 iteration 3817 : loss : 0.035367, loss_ce: 0.012290
2022-01-21 22:07:11,174 iteration 3818 : loss : 0.025791, loss_ce: 0.007221
2022-01-21 22:07:12,388 iteration 3819 : loss : 0.039478, loss_ce: 0.014195
2022-01-21 22:07:13,498 iteration 3820 : loss : 0.018425, loss_ce: 0.007597
2022-01-21 22:07:14,736 iteration 3821 : loss : 0.025376, loss_ce: 0.009882
2022-01-21 22:07:15,898 iteration 3822 : loss : 0.035206, loss_ce: 0.011481
2022-01-21 22:07:17,041 iteration 3823 : loss : 0.031134, loss_ce: 0.009835
2022-01-21 22:07:18,249 iteration 3824 : loss : 0.036226, loss_ce: 0.013405
2022-01-21 22:07:18,249 Training Data Eval:
2022-01-21 22:07:23,930   Average segmentation loss on training set: 0.0180
2022-01-21 22:07:23,930 Validation Data Eval:
2022-01-21 22:07:25,894   Average segmentation loss on validation set: 0.0698
2022-01-21 22:07:26,991 iteration 3825 : loss : 0.020052, loss_ce: 0.007316
 56%|███████████████▏           | 225/400 [1:22:16<1:06:56, 22.95s/it]2022-01-21 22:07:28,287 iteration 3826 : loss : 0.035238, loss_ce: 0.016066
2022-01-21 22:07:29,536 iteration 3827 : loss : 0.032696, loss_ce: 0.012127
2022-01-21 22:07:30,669 iteration 3828 : loss : 0.022846, loss_ce: 0.014272
2022-01-21 22:07:31,804 iteration 3829 : loss : 0.019917, loss_ce: 0.008271
2022-01-21 22:07:33,059 iteration 3830 : loss : 0.038957, loss_ce: 0.011886
2022-01-21 22:07:34,290 iteration 3831 : loss : 0.021071, loss_ce: 0.008018
2022-01-21 22:07:35,491 iteration 3832 : loss : 0.026675, loss_ce: 0.012892
2022-01-21 22:07:36,695 iteration 3833 : loss : 0.050784, loss_ce: 0.016529
2022-01-21 22:07:37,827 iteration 3834 : loss : 0.024884, loss_ce: 0.007296
2022-01-21 22:07:39,037 iteration 3835 : loss : 0.033525, loss_ce: 0.007590
2022-01-21 22:07:40,151 iteration 3836 : loss : 0.020082, loss_ce: 0.009439
2022-01-21 22:07:41,246 iteration 3837 : loss : 0.021445, loss_ce: 0.009236
2022-01-21 22:07:42,461 iteration 3838 : loss : 0.024546, loss_ce: 0.010801
2022-01-21 22:07:43,594 iteration 3839 : loss : 0.025434, loss_ce: 0.007638
2022-01-21 22:07:44,781 iteration 3840 : loss : 0.020629, loss_ce: 0.008591
2022-01-21 22:07:45,880 iteration 3841 : loss : 0.022158, loss_ce: 0.008746
2022-01-21 22:07:47,085 iteration 3842 : loss : 0.057578, loss_ce: 0.015380
 56%|███████████████▎           | 226/400 [1:22:37<1:04:04, 22.09s/it]2022-01-21 22:07:48,306 iteration 3843 : loss : 0.032100, loss_ce: 0.009912
2022-01-21 22:07:49,539 iteration 3844 : loss : 0.028203, loss_ce: 0.010134
2022-01-21 22:07:50,623 iteration 3845 : loss : 0.029140, loss_ce: 0.011644
2022-01-21 22:07:51,778 iteration 3846 : loss : 0.032217, loss_ce: 0.013829
2022-01-21 22:07:53,056 iteration 3847 : loss : 0.032741, loss_ce: 0.011810
2022-01-21 22:07:54,202 iteration 3848 : loss : 0.025609, loss_ce: 0.010037
2022-01-21 22:07:55,344 iteration 3849 : loss : 0.024125, loss_ce: 0.009110
2022-01-21 22:07:56,585 iteration 3850 : loss : 0.031274, loss_ce: 0.011376
2022-01-21 22:07:57,845 iteration 3851 : loss : 0.071646, loss_ce: 0.023640
2022-01-21 22:07:59,070 iteration 3852 : loss : 0.030375, loss_ce: 0.010745
2022-01-21 22:08:00,246 iteration 3853 : loss : 0.024582, loss_ce: 0.010243
2022-01-21 22:08:01,338 iteration 3854 : loss : 0.021737, loss_ce: 0.007821
2022-01-21 22:08:02,491 iteration 3855 : loss : 0.020884, loss_ce: 0.006086
2022-01-21 22:08:03,766 iteration 3856 : loss : 0.033776, loss_ce: 0.017295
2022-01-21 22:08:04,920 iteration 3857 : loss : 0.034866, loss_ce: 0.010298
2022-01-21 22:08:06,078 iteration 3858 : loss : 0.026292, loss_ce: 0.011691
2022-01-21 22:08:07,207 iteration 3859 : loss : 0.028547, loss_ce: 0.011811
 57%|███████████████▎           | 227/400 [1:22:57<1:01:59, 21.50s/it]2022-01-21 22:08:08,386 iteration 3860 : loss : 0.022520, loss_ce: 0.010899
2022-01-21 22:08:09,533 iteration 3861 : loss : 0.025780, loss_ce: 0.011987
2022-01-21 22:08:10,659 iteration 3862 : loss : 0.021839, loss_ce: 0.006416
2022-01-21 22:08:11,850 iteration 3863 : loss : 0.028240, loss_ce: 0.014224
2022-01-21 22:08:12,953 iteration 3864 : loss : 0.023417, loss_ce: 0.009602
2022-01-21 22:08:14,146 iteration 3865 : loss : 0.028477, loss_ce: 0.011411
2022-01-21 22:08:15,313 iteration 3866 : loss : 0.023362, loss_ce: 0.011100
2022-01-21 22:08:16,523 iteration 3867 : loss : 0.037815, loss_ce: 0.014188
2022-01-21 22:08:17,633 iteration 3868 : loss : 0.023057, loss_ce: 0.009418
2022-01-21 22:08:18,874 iteration 3869 : loss : 0.043116, loss_ce: 0.011060
2022-01-21 22:08:20,030 iteration 3870 : loss : 0.024063, loss_ce: 0.008310
2022-01-21 22:08:21,250 iteration 3871 : loss : 0.035124, loss_ce: 0.013927
2022-01-21 22:08:22,416 iteration 3872 : loss : 0.042832, loss_ce: 0.012847
2022-01-21 22:08:23,570 iteration 3873 : loss : 0.029504, loss_ce: 0.008439
2022-01-21 22:08:24,799 iteration 3874 : loss : 0.022380, loss_ce: 0.007176
2022-01-21 22:08:26,007 iteration 3875 : loss : 0.031557, loss_ce: 0.008376
2022-01-21 22:08:27,270 iteration 3876 : loss : 0.031022, loss_ce: 0.014846
 57%|███████████████▍           | 228/400 [1:23:17<1:00:24, 21.07s/it]2022-01-21 22:08:28,469 iteration 3877 : loss : 0.021637, loss_ce: 0.008663
2022-01-21 22:08:29,678 iteration 3878 : loss : 0.030825, loss_ce: 0.010970
2022-01-21 22:08:30,916 iteration 3879 : loss : 0.021258, loss_ce: 0.010777
2022-01-21 22:08:32,096 iteration 3880 : loss : 0.020677, loss_ce: 0.007153
2022-01-21 22:08:33,298 iteration 3881 : loss : 0.029052, loss_ce: 0.008328
2022-01-21 22:08:34,518 iteration 3882 : loss : 0.020320, loss_ce: 0.009087
2022-01-21 22:08:35,704 iteration 3883 : loss : 0.025512, loss_ce: 0.008401
2022-01-21 22:08:36,891 iteration 3884 : loss : 0.022303, loss_ce: 0.006921
2022-01-21 22:08:38,027 iteration 3885 : loss : 0.022093, loss_ce: 0.006871
2022-01-21 22:08:39,246 iteration 3886 : loss : 0.022324, loss_ce: 0.008812
2022-01-21 22:08:40,443 iteration 3887 : loss : 0.026497, loss_ce: 0.009758
2022-01-21 22:08:41,687 iteration 3888 : loss : 0.031784, loss_ce: 0.016456
2022-01-21 22:08:42,836 iteration 3889 : loss : 0.028863, loss_ce: 0.009086
2022-01-21 22:08:43,988 iteration 3890 : loss : 0.019454, loss_ce: 0.007067
2022-01-21 22:08:45,204 iteration 3891 : loss : 0.033811, loss_ce: 0.017787
2022-01-21 22:08:46,390 iteration 3892 : loss : 0.026058, loss_ce: 0.008594
2022-01-21 22:08:47,538 iteration 3893 : loss : 0.027307, loss_ce: 0.006693
 57%|████████████████▌            | 229/400 [1:23:37<59:21, 20.83s/it]2022-01-21 22:08:48,766 iteration 3894 : loss : 0.027361, loss_ce: 0.010510
2022-01-21 22:08:49,982 iteration 3895 : loss : 0.023958, loss_ce: 0.012439
2022-01-21 22:08:51,100 iteration 3896 : loss : 0.018533, loss_ce: 0.007534
2022-01-21 22:08:52,333 iteration 3897 : loss : 0.018880, loss_ce: 0.005540
2022-01-21 22:08:53,538 iteration 3898 : loss : 0.028232, loss_ce: 0.009473
2022-01-21 22:08:54,726 iteration 3899 : loss : 0.020469, loss_ce: 0.006117
2022-01-21 22:08:55,925 iteration 3900 : loss : 0.019772, loss_ce: 0.008696
2022-01-21 22:08:57,020 iteration 3901 : loss : 0.021978, loss_ce: 0.010692
2022-01-21 22:08:58,196 iteration 3902 : loss : 0.016378, loss_ce: 0.005442
2022-01-21 22:08:59,320 iteration 3903 : loss : 0.018339, loss_ce: 0.005844
2022-01-21 22:09:00,509 iteration 3904 : loss : 0.019700, loss_ce: 0.008128
2022-01-21 22:09:01,687 iteration 3905 : loss : 0.031363, loss_ce: 0.016614
2022-01-21 22:09:02,872 iteration 3906 : loss : 0.025020, loss_ce: 0.010420
2022-01-21 22:09:04,045 iteration 3907 : loss : 0.028529, loss_ce: 0.008261
2022-01-21 22:09:05,135 iteration 3908 : loss : 0.023213, loss_ce: 0.008032
2022-01-21 22:09:06,238 iteration 3909 : loss : 0.022996, loss_ce: 0.008960
2022-01-21 22:09:06,238 Training Data Eval:
2022-01-21 22:09:11,944   Average segmentation loss on training set: 0.0160
2022-01-21 22:09:11,945 Validation Data Eval:
2022-01-21 22:09:13,919   Average segmentation loss on validation set: 0.0571
2022-01-21 22:09:18,025 Found new lowest validation loss at iteration 3909! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 22:09:19,259 iteration 3910 : loss : 0.025001, loss_ce: 0.010566
 57%|███████████████▌           | 230/400 [1:24:09<1:08:16, 24.09s/it]2022-01-21 22:09:20,396 iteration 3911 : loss : 0.019641, loss_ce: 0.008838
2022-01-21 22:09:21,543 iteration 3912 : loss : 0.030847, loss_ce: 0.009517
2022-01-21 22:09:22,722 iteration 3913 : loss : 0.024096, loss_ce: 0.010983
2022-01-21 22:09:23,802 iteration 3914 : loss : 0.015456, loss_ce: 0.006725
2022-01-21 22:09:24,997 iteration 3915 : loss : 0.026502, loss_ce: 0.008183
2022-01-21 22:09:26,182 iteration 3916 : loss : 0.018654, loss_ce: 0.006921
2022-01-21 22:09:27,391 iteration 3917 : loss : 0.027933, loss_ce: 0.007973
2022-01-21 22:09:28,561 iteration 3918 : loss : 0.020947, loss_ce: 0.006123
2022-01-21 22:09:29,727 iteration 3919 : loss : 0.020919, loss_ce: 0.006550
2022-01-21 22:09:30,930 iteration 3920 : loss : 0.025921, loss_ce: 0.006134
2022-01-21 22:09:32,097 iteration 3921 : loss : 0.025507, loss_ce: 0.009138
2022-01-21 22:09:33,303 iteration 3922 : loss : 0.028981, loss_ce: 0.007782
2022-01-21 22:09:34,569 iteration 3923 : loss : 0.048556, loss_ce: 0.023799
2022-01-21 22:09:35,713 iteration 3924 : loss : 0.026451, loss_ce: 0.009857
2022-01-21 22:09:36,816 iteration 3925 : loss : 0.020100, loss_ce: 0.009461
2022-01-21 22:09:38,123 iteration 3926 : loss : 0.028827, loss_ce: 0.013189
2022-01-21 22:09:39,325 iteration 3927 : loss : 0.024858, loss_ce: 0.011532
 58%|███████████████▌           | 231/400 [1:24:29<1:04:28, 22.89s/it]2022-01-21 22:09:40,543 iteration 3928 : loss : 0.022583, loss_ce: 0.008860
2022-01-21 22:09:41,675 iteration 3929 : loss : 0.030119, loss_ce: 0.021267
2022-01-21 22:09:42,846 iteration 3930 : loss : 0.023713, loss_ce: 0.006790
2022-01-21 22:09:43,955 iteration 3931 : loss : 0.022122, loss_ce: 0.005237
2022-01-21 22:09:45,132 iteration 3932 : loss : 0.029420, loss_ce: 0.011104
2022-01-21 22:09:46,283 iteration 3933 : loss : 0.026977, loss_ce: 0.012578
2022-01-21 22:09:47,480 iteration 3934 : loss : 0.032101, loss_ce: 0.012164
2022-01-21 22:09:48,648 iteration 3935 : loss : 0.023672, loss_ce: 0.008460
2022-01-21 22:09:49,775 iteration 3936 : loss : 0.022627, loss_ce: 0.007809
2022-01-21 22:09:50,947 iteration 3937 : loss : 0.028570, loss_ce: 0.008323
2022-01-21 22:09:52,113 iteration 3938 : loss : 0.029214, loss_ce: 0.007803
2022-01-21 22:09:53,341 iteration 3939 : loss : 0.034485, loss_ce: 0.010300
2022-01-21 22:09:54,520 iteration 3940 : loss : 0.026540, loss_ce: 0.011539
2022-01-21 22:09:55,697 iteration 3941 : loss : 0.020148, loss_ce: 0.006185
2022-01-21 22:09:56,839 iteration 3942 : loss : 0.031054, loss_ce: 0.016004
2022-01-21 22:09:57,971 iteration 3943 : loss : 0.022687, loss_ce: 0.009883
2022-01-21 22:09:59,115 iteration 3944 : loss : 0.026850, loss_ce: 0.008714
 58%|███████████████▋           | 232/400 [1:24:49<1:01:29, 21.96s/it]2022-01-21 22:10:00,391 iteration 3945 : loss : 0.029424, loss_ce: 0.010280
2022-01-21 22:10:01,548 iteration 3946 : loss : 0.018071, loss_ce: 0.007255
2022-01-21 22:10:02,685 iteration 3947 : loss : 0.022651, loss_ce: 0.009715
2022-01-21 22:10:03,896 iteration 3948 : loss : 0.030966, loss_ce: 0.013615
2022-01-21 22:10:05,122 iteration 3949 : loss : 0.027194, loss_ce: 0.007966
2022-01-21 22:10:06,271 iteration 3950 : loss : 0.021628, loss_ce: 0.010135
2022-01-21 22:10:07,393 iteration 3951 : loss : 0.032424, loss_ce: 0.007232
2022-01-21 22:10:08,661 iteration 3952 : loss : 0.026718, loss_ce: 0.014998
2022-01-21 22:10:09,833 iteration 3953 : loss : 0.020171, loss_ce: 0.008459
2022-01-21 22:10:10,958 iteration 3954 : loss : 0.018935, loss_ce: 0.006796
2022-01-21 22:10:12,161 iteration 3955 : loss : 0.025457, loss_ce: 0.011078
2022-01-21 22:10:13,374 iteration 3956 : loss : 0.034547, loss_ce: 0.017513
2022-01-21 22:10:14,598 iteration 3957 : loss : 0.034729, loss_ce: 0.009451
2022-01-21 22:10:15,831 iteration 3958 : loss : 0.026429, loss_ce: 0.012115
2022-01-21 22:10:16,918 iteration 3959 : loss : 0.029057, loss_ce: 0.007252
2022-01-21 22:10:18,126 iteration 3960 : loss : 0.028827, loss_ce: 0.010390
2022-01-21 22:10:19,273 iteration 3961 : loss : 0.026182, loss_ce: 0.007328
 58%|████████████████▉            | 233/400 [1:25:09<59:37, 21.42s/it]2022-01-21 22:10:20,522 iteration 3962 : loss : 0.031889, loss_ce: 0.012717
2022-01-21 22:10:21,752 iteration 3963 : loss : 0.026195, loss_ce: 0.011807
2022-01-21 22:10:22,884 iteration 3964 : loss : 0.017177, loss_ce: 0.005260
2022-01-21 22:10:24,074 iteration 3965 : loss : 0.018410, loss_ce: 0.008339
2022-01-21 22:10:25,336 iteration 3966 : loss : 0.024748, loss_ce: 0.011510
2022-01-21 22:10:26,517 iteration 3967 : loss : 0.028634, loss_ce: 0.007386
2022-01-21 22:10:27,686 iteration 3968 : loss : 0.019960, loss_ce: 0.007021
2022-01-21 22:10:28,824 iteration 3969 : loss : 0.021031, loss_ce: 0.006603
2022-01-21 22:10:30,002 iteration 3970 : loss : 0.043580, loss_ce: 0.011514
2022-01-21 22:10:31,171 iteration 3971 : loss : 0.018452, loss_ce: 0.005811
2022-01-21 22:10:32,353 iteration 3972 : loss : 0.034341, loss_ce: 0.014146
2022-01-21 22:10:33,591 iteration 3973 : loss : 0.023742, loss_ce: 0.009785
2022-01-21 22:10:34,825 iteration 3974 : loss : 0.020592, loss_ce: 0.009646
2022-01-21 22:10:35,999 iteration 3975 : loss : 0.026721, loss_ce: 0.008110
2022-01-21 22:10:37,165 iteration 3976 : loss : 0.023125, loss_ce: 0.008028
2022-01-21 22:10:38,374 iteration 3977 : loss : 0.029590, loss_ce: 0.011423
2022-01-21 22:10:39,563 iteration 3978 : loss : 0.022412, loss_ce: 0.009357
 58%|████████████████▉            | 234/400 [1:25:29<58:19, 21.08s/it]2022-01-21 22:10:40,864 iteration 3979 : loss : 0.027297, loss_ce: 0.013212
2022-01-21 22:10:41,971 iteration 3980 : loss : 0.022313, loss_ce: 0.009088
2022-01-21 22:10:43,146 iteration 3981 : loss : 0.038629, loss_ce: 0.008989
2022-01-21 22:10:44,335 iteration 3982 : loss : 0.020167, loss_ce: 0.009855
2022-01-21 22:10:45,527 iteration 3983 : loss : 0.033337, loss_ce: 0.011330
2022-01-21 22:10:46,747 iteration 3984 : loss : 0.023957, loss_ce: 0.011010
2022-01-21 22:10:47,964 iteration 3985 : loss : 0.022135, loss_ce: 0.007393
2022-01-21 22:10:49,189 iteration 3986 : loss : 0.025774, loss_ce: 0.008469
2022-01-21 22:10:50,326 iteration 3987 : loss : 0.023762, loss_ce: 0.010638
2022-01-21 22:10:51,492 iteration 3988 : loss : 0.039472, loss_ce: 0.017996
2022-01-21 22:10:52,686 iteration 3989 : loss : 0.019724, loss_ce: 0.007651
2022-01-21 22:10:53,878 iteration 3990 : loss : 0.047737, loss_ce: 0.023621
2022-01-21 22:10:55,095 iteration 3991 : loss : 0.025500, loss_ce: 0.012163
2022-01-21 22:10:56,306 iteration 3992 : loss : 0.025458, loss_ce: 0.009130
2022-01-21 22:10:57,488 iteration 3993 : loss : 0.022823, loss_ce: 0.008799
2022-01-21 22:10:58,708 iteration 3994 : loss : 0.021224, loss_ce: 0.006835
2022-01-21 22:10:58,708 Training Data Eval:
2022-01-21 22:11:04,388   Average segmentation loss on training set: 0.0199
2022-01-21 22:11:04,388 Validation Data Eval:
2022-01-21 22:11:06,352   Average segmentation loss on validation set: 0.0627
2022-01-21 22:11:07,627 iteration 3995 : loss : 0.036419, loss_ce: 0.012430
 59%|███████████████▊           | 235/400 [1:25:57<1:03:43, 23.17s/it]2022-01-21 22:11:08,844 iteration 3996 : loss : 0.032856, loss_ce: 0.015894
2022-01-21 22:11:09,978 iteration 3997 : loss : 0.028651, loss_ce: 0.013797
2022-01-21 22:11:11,087 iteration 3998 : loss : 0.037962, loss_ce: 0.011475
2022-01-21 22:11:12,320 iteration 3999 : loss : 0.036184, loss_ce: 0.010733
2022-01-21 22:11:13,503 iteration 4000 : loss : 0.020382, loss_ce: 0.008376
2022-01-21 22:11:14,716 iteration 4001 : loss : 0.022384, loss_ce: 0.012707
2022-01-21 22:11:15,813 iteration 4002 : loss : 0.019397, loss_ce: 0.007061
2022-01-21 22:11:17,038 iteration 4003 : loss : 0.027846, loss_ce: 0.009822
2022-01-21 22:11:18,259 iteration 4004 : loss : 0.033131, loss_ce: 0.012473
2022-01-21 22:11:19,465 iteration 4005 : loss : 0.023483, loss_ce: 0.009222
2022-01-21 22:11:20,590 iteration 4006 : loss : 0.029546, loss_ce: 0.010450
2022-01-21 22:11:21,766 iteration 4007 : loss : 0.027279, loss_ce: 0.009804
2022-01-21 22:11:22,923 iteration 4008 : loss : 0.020992, loss_ce: 0.009336
2022-01-21 22:11:24,097 iteration 4009 : loss : 0.019679, loss_ce: 0.006734
2022-01-21 22:11:25,285 iteration 4010 : loss : 0.037154, loss_ce: 0.019078
2022-01-21 22:11:26,447 iteration 4011 : loss : 0.030268, loss_ce: 0.010674
2022-01-21 22:11:27,632 iteration 4012 : loss : 0.024319, loss_ce: 0.009674
 59%|███████████████▉           | 236/400 [1:26:17<1:00:45, 22.23s/it]2022-01-21 22:11:28,756 iteration 4013 : loss : 0.017252, loss_ce: 0.008539
2022-01-21 22:11:29,989 iteration 4014 : loss : 0.024561, loss_ce: 0.010751
2022-01-21 22:11:31,112 iteration 4015 : loss : 0.024009, loss_ce: 0.010919
2022-01-21 22:11:32,353 iteration 4016 : loss : 0.022306, loss_ce: 0.008186
2022-01-21 22:11:33,544 iteration 4017 : loss : 0.037149, loss_ce: 0.010196
2022-01-21 22:11:34,655 iteration 4018 : loss : 0.022049, loss_ce: 0.008129
2022-01-21 22:11:35,837 iteration 4019 : loss : 0.027188, loss_ce: 0.010691
2022-01-21 22:11:36,988 iteration 4020 : loss : 0.021426, loss_ce: 0.006910
2022-01-21 22:11:38,182 iteration 4021 : loss : 0.032124, loss_ce: 0.009354
2022-01-21 22:11:39,443 iteration 4022 : loss : 0.026591, loss_ce: 0.008836
2022-01-21 22:11:40,567 iteration 4023 : loss : 0.022479, loss_ce: 0.009924
2022-01-21 22:11:41,785 iteration 4024 : loss : 0.022659, loss_ce: 0.006700
2022-01-21 22:11:42,975 iteration 4025 : loss : 0.023074, loss_ce: 0.007074
2022-01-21 22:11:44,211 iteration 4026 : loss : 0.026840, loss_ce: 0.008381
2022-01-21 22:11:45,313 iteration 4027 : loss : 0.020525, loss_ce: 0.006402
2022-01-21 22:11:46,611 iteration 4028 : loss : 0.028529, loss_ce: 0.013304
2022-01-21 22:11:47,893 iteration 4029 : loss : 0.030894, loss_ce: 0.011167
 59%|█████████████████▏           | 237/400 [1:26:37<58:46, 21.64s/it]2022-01-21 22:11:49,114 iteration 4030 : loss : 0.023315, loss_ce: 0.009303
2022-01-21 22:11:50,283 iteration 4031 : loss : 0.039537, loss_ce: 0.023809
2022-01-21 22:11:51,396 iteration 4032 : loss : 0.018824, loss_ce: 0.005721
2022-01-21 22:11:52,530 iteration 4033 : loss : 0.022214, loss_ce: 0.008481
2022-01-21 22:11:53,737 iteration 4034 : loss : 0.032187, loss_ce: 0.013337
2022-01-21 22:11:54,954 iteration 4035 : loss : 0.027186, loss_ce: 0.008335
2022-01-21 22:11:56,151 iteration 4036 : loss : 0.021917, loss_ce: 0.009224
2022-01-21 22:11:57,287 iteration 4037 : loss : 0.018717, loss_ce: 0.009223
2022-01-21 22:11:58,457 iteration 4038 : loss : 0.022461, loss_ce: 0.009924
2022-01-21 22:11:59,645 iteration 4039 : loss : 0.041039, loss_ce: 0.011422
2022-01-21 22:12:00,807 iteration 4040 : loss : 0.028473, loss_ce: 0.008299
2022-01-21 22:12:02,032 iteration 4041 : loss : 0.029532, loss_ce: 0.011671
2022-01-21 22:12:03,250 iteration 4042 : loss : 0.026996, loss_ce: 0.009531
2022-01-21 22:12:04,438 iteration 4043 : loss : 0.024522, loss_ce: 0.010101
2022-01-21 22:12:05,612 iteration 4044 : loss : 0.022518, loss_ce: 0.008867
2022-01-21 22:12:06,803 iteration 4045 : loss : 0.019693, loss_ce: 0.005913
2022-01-21 22:12:08,025 iteration 4046 : loss : 0.035446, loss_ce: 0.011417
 60%|█████████████████▎           | 238/400 [1:26:57<57:11, 21.18s/it]2022-01-21 22:12:09,281 iteration 4047 : loss : 0.024617, loss_ce: 0.010457
2022-01-21 22:12:10,450 iteration 4048 : loss : 0.027101, loss_ce: 0.009242
2022-01-21 22:12:11,625 iteration 4049 : loss : 0.019025, loss_ce: 0.005453
2022-01-21 22:12:12,750 iteration 4050 : loss : 0.027894, loss_ce: 0.008943
2022-01-21 22:12:13,917 iteration 4051 : loss : 0.023670, loss_ce: 0.010618
2022-01-21 22:12:15,041 iteration 4052 : loss : 0.017899, loss_ce: 0.007276
2022-01-21 22:12:16,233 iteration 4053 : loss : 0.056206, loss_ce: 0.017095
2022-01-21 22:12:17,441 iteration 4054 : loss : 0.020050, loss_ce: 0.008037
2022-01-21 22:12:18,622 iteration 4055 : loss : 0.020770, loss_ce: 0.008997
2022-01-21 22:12:19,801 iteration 4056 : loss : 0.023741, loss_ce: 0.010289
2022-01-21 22:12:20,918 iteration 4057 : loss : 0.023510, loss_ce: 0.008022
2022-01-21 22:12:22,050 iteration 4058 : loss : 0.026833, loss_ce: 0.011285
2022-01-21 22:12:23,262 iteration 4059 : loss : 0.024929, loss_ce: 0.008984
2022-01-21 22:12:24,393 iteration 4060 : loss : 0.021067, loss_ce: 0.008396
2022-01-21 22:12:25,486 iteration 4061 : loss : 0.022945, loss_ce: 0.010744
2022-01-21 22:12:26,629 iteration 4062 : loss : 0.017918, loss_ce: 0.008059
2022-01-21 22:12:27,847 iteration 4063 : loss : 0.026252, loss_ce: 0.009280
 60%|█████████████████▎           | 239/400 [1:27:17<55:44, 20.77s/it]2022-01-21 22:12:29,074 iteration 4064 : loss : 0.027450, loss_ce: 0.012567
2022-01-21 22:12:30,214 iteration 4065 : loss : 0.026945, loss_ce: 0.007277
2022-01-21 22:12:31,385 iteration 4066 : loss : 0.017754, loss_ce: 0.006143
2022-01-21 22:12:32,556 iteration 4067 : loss : 0.020993, loss_ce: 0.007409
2022-01-21 22:12:33,756 iteration 4068 : loss : 0.026572, loss_ce: 0.010454
2022-01-21 22:12:34,961 iteration 4069 : loss : 0.046168, loss_ce: 0.024217
2022-01-21 22:12:36,092 iteration 4070 : loss : 0.021589, loss_ce: 0.006182
2022-01-21 22:12:37,269 iteration 4071 : loss : 0.032303, loss_ce: 0.009719
2022-01-21 22:12:38,453 iteration 4072 : loss : 0.023853, loss_ce: 0.008643
2022-01-21 22:12:39,656 iteration 4073 : loss : 0.027729, loss_ce: 0.010566
2022-01-21 22:12:40,832 iteration 4074 : loss : 0.022278, loss_ce: 0.008360
2022-01-21 22:12:42,096 iteration 4075 : loss : 0.033589, loss_ce: 0.010999
2022-01-21 22:12:43,300 iteration 4076 : loss : 0.017378, loss_ce: 0.007160
2022-01-21 22:12:44,536 iteration 4077 : loss : 0.023627, loss_ce: 0.009110
2022-01-21 22:12:45,777 iteration 4078 : loss : 0.025029, loss_ce: 0.009527
2022-01-21 22:12:46,929 iteration 4079 : loss : 0.024504, loss_ce: 0.008542
2022-01-21 22:12:46,929 Training Data Eval:
2022-01-21 22:12:52,600   Average segmentation loss on training set: 0.0174
2022-01-21 22:12:52,601 Validation Data Eval:
2022-01-21 22:12:54,568   Average segmentation loss on validation set: 0.0617
2022-01-21 22:12:55,811 iteration 4080 : loss : 0.031899, loss_ce: 0.014101
 60%|████████████████▏          | 240/400 [1:27:45<1:01:09, 22.94s/it]2022-01-21 22:12:57,015 iteration 4081 : loss : 0.027433, loss_ce: 0.011641
2022-01-21 22:12:58,183 iteration 4082 : loss : 0.023849, loss_ce: 0.009394
2022-01-21 22:12:59,339 iteration 4083 : loss : 0.018471, loss_ce: 0.007979
2022-01-21 22:13:00,545 iteration 4084 : loss : 0.029608, loss_ce: 0.009070
2022-01-21 22:13:01,798 iteration 4085 : loss : 0.029619, loss_ce: 0.009945
2022-01-21 22:13:03,045 iteration 4086 : loss : 0.023584, loss_ce: 0.010916
2022-01-21 22:13:04,206 iteration 4087 : loss : 0.025271, loss_ce: 0.007321
2022-01-21 22:13:05,376 iteration 4088 : loss : 0.023504, loss_ce: 0.009230
2022-01-21 22:13:06,578 iteration 4089 : loss : 0.032317, loss_ce: 0.011280
2022-01-21 22:13:07,784 iteration 4090 : loss : 0.020955, loss_ce: 0.008455
2022-01-21 22:13:08,938 iteration 4091 : loss : 0.032488, loss_ce: 0.010350
2022-01-21 22:13:10,113 iteration 4092 : loss : 0.016551, loss_ce: 0.006169
2022-01-21 22:13:11,282 iteration 4093 : loss : 0.021374, loss_ce: 0.008938
2022-01-21 22:13:12,425 iteration 4094 : loss : 0.019140, loss_ce: 0.005823
2022-01-21 22:13:13,584 iteration 4095 : loss : 0.026860, loss_ce: 0.011103
2022-01-21 22:13:14,754 iteration 4096 : loss : 0.020617, loss_ce: 0.008806
2022-01-21 22:13:15,940 iteration 4097 : loss : 0.030380, loss_ce: 0.014127
 60%|█████████████████▍           | 241/400 [1:28:05<58:32, 22.09s/it]2022-01-21 22:13:17,209 iteration 4098 : loss : 0.024486, loss_ce: 0.009083
2022-01-21 22:13:18,365 iteration 4099 : loss : 0.034367, loss_ce: 0.009255
2022-01-21 22:13:19,484 iteration 4100 : loss : 0.018336, loss_ce: 0.007806
2022-01-21 22:13:20,627 iteration 4101 : loss : 0.020013, loss_ce: 0.007523
2022-01-21 22:13:21,811 iteration 4102 : loss : 0.046512, loss_ce: 0.022068
2022-01-21 22:13:22,961 iteration 4103 : loss : 0.022219, loss_ce: 0.009319
2022-01-21 22:13:24,091 iteration 4104 : loss : 0.019815, loss_ce: 0.008442
2022-01-21 22:13:25,276 iteration 4105 : loss : 0.038243, loss_ce: 0.014761
2022-01-21 22:13:26,400 iteration 4106 : loss : 0.028559, loss_ce: 0.005721
2022-01-21 22:13:27,668 iteration 4107 : loss : 0.021616, loss_ce: 0.011412
2022-01-21 22:13:28,893 iteration 4108 : loss : 0.031344, loss_ce: 0.011003
2022-01-21 22:13:30,016 iteration 4109 : loss : 0.027033, loss_ce: 0.006176
2022-01-21 22:13:31,208 iteration 4110 : loss : 0.026419, loss_ce: 0.011950
2022-01-21 22:13:32,451 iteration 4111 : loss : 0.025987, loss_ce: 0.010549
2022-01-21 22:13:33,608 iteration 4112 : loss : 0.030537, loss_ce: 0.009808
2022-01-21 22:13:34,802 iteration 4113 : loss : 0.026431, loss_ce: 0.010825
2022-01-21 22:13:36,053 iteration 4114 : loss : 0.033590, loss_ce: 0.011365
 60%|█████████████████▌           | 242/400 [1:28:25<56:37, 21.50s/it]2022-01-21 22:13:37,259 iteration 4115 : loss : 0.023610, loss_ce: 0.006294
2022-01-21 22:13:38,375 iteration 4116 : loss : 0.019470, loss_ce: 0.008099
2022-01-21 22:13:39,680 iteration 4117 : loss : 0.039022, loss_ce: 0.011154
2022-01-21 22:13:40,973 iteration 4118 : loss : 0.022471, loss_ce: 0.011371
2022-01-21 22:13:42,183 iteration 4119 : loss : 0.025315, loss_ce: 0.011022
2022-01-21 22:13:43,380 iteration 4120 : loss : 0.044205, loss_ce: 0.008079
2022-01-21 22:13:44,574 iteration 4121 : loss : 0.021226, loss_ce: 0.009380
2022-01-21 22:13:45,727 iteration 4122 : loss : 0.025231, loss_ce: 0.008880
2022-01-21 22:13:46,977 iteration 4123 : loss : 0.029642, loss_ce: 0.009844
2022-01-21 22:13:48,100 iteration 4124 : loss : 0.024183, loss_ce: 0.009229
2022-01-21 22:13:49,338 iteration 4125 : loss : 0.031747, loss_ce: 0.008818
2022-01-21 22:13:50,528 iteration 4126 : loss : 0.024985, loss_ce: 0.012686
2022-01-21 22:13:51,742 iteration 4127 : loss : 0.027142, loss_ce: 0.010978
2022-01-21 22:13:52,892 iteration 4128 : loss : 0.023756, loss_ce: 0.012018
2022-01-21 22:13:54,133 iteration 4129 : loss : 0.024249, loss_ce: 0.009368
2022-01-21 22:13:55,303 iteration 4130 : loss : 0.018946, loss_ce: 0.009449
2022-01-21 22:13:56,403 iteration 4131 : loss : 0.015939, loss_ce: 0.004547
 61%|█████████████████▌           | 243/400 [1:28:46<55:21, 21.15s/it]2022-01-21 22:13:57,687 iteration 4132 : loss : 0.024265, loss_ce: 0.009651
2022-01-21 22:13:58,915 iteration 4133 : loss : 0.025778, loss_ce: 0.012005
2022-01-21 22:14:00,028 iteration 4134 : loss : 0.022121, loss_ce: 0.009434
2022-01-21 22:14:01,257 iteration 4135 : loss : 0.020726, loss_ce: 0.007912
2022-01-21 22:14:02,435 iteration 4136 : loss : 0.023129, loss_ce: 0.010653
2022-01-21 22:14:03,587 iteration 4137 : loss : 0.021988, loss_ce: 0.010738
2022-01-21 22:14:04,725 iteration 4138 : loss : 0.019579, loss_ce: 0.008820
2022-01-21 22:14:05,925 iteration 4139 : loss : 0.033577, loss_ce: 0.009122
2022-01-21 22:14:07,162 iteration 4140 : loss : 0.034861, loss_ce: 0.010500
2022-01-21 22:14:08,329 iteration 4141 : loss : 0.037918, loss_ce: 0.012555
2022-01-21 22:14:09,526 iteration 4142 : loss : 0.036530, loss_ce: 0.009022
2022-01-21 22:14:10,750 iteration 4143 : loss : 0.024606, loss_ce: 0.006437
2022-01-21 22:14:11,910 iteration 4144 : loss : 0.022661, loss_ce: 0.008363
2022-01-21 22:14:13,065 iteration 4145 : loss : 0.016975, loss_ce: 0.004911
2022-01-21 22:14:14,239 iteration 4146 : loss : 0.023758, loss_ce: 0.007218
2022-01-21 22:14:15,390 iteration 4147 : loss : 0.032613, loss_ce: 0.013272
2022-01-21 22:14:16,480 iteration 4148 : loss : 0.016919, loss_ce: 0.006002
 61%|█████████████████▋           | 244/400 [1:29:06<54:09, 20.83s/it]2022-01-21 22:14:17,818 iteration 4149 : loss : 0.038057, loss_ce: 0.012935
2022-01-21 22:14:18,920 iteration 4150 : loss : 0.019263, loss_ce: 0.005319
2022-01-21 22:14:20,123 iteration 4151 : loss : 0.023319, loss_ce: 0.010323
2022-01-21 22:14:21,219 iteration 4152 : loss : 0.028613, loss_ce: 0.011246
2022-01-21 22:14:22,420 iteration 4153 : loss : 0.043200, loss_ce: 0.014374
2022-01-21 22:14:23,617 iteration 4154 : loss : 0.049017, loss_ce: 0.020260
2022-01-21 22:14:24,867 iteration 4155 : loss : 0.036203, loss_ce: 0.010723
2022-01-21 22:14:25,957 iteration 4156 : loss : 0.016554, loss_ce: 0.006346
2022-01-21 22:14:27,158 iteration 4157 : loss : 0.029330, loss_ce: 0.011099
2022-01-21 22:14:28,329 iteration 4158 : loss : 0.026210, loss_ce: 0.010483
2022-01-21 22:14:29,539 iteration 4159 : loss : 0.023326, loss_ce: 0.008589
2022-01-21 22:14:30,714 iteration 4160 : loss : 0.024927, loss_ce: 0.011638
2022-01-21 22:14:31,894 iteration 4161 : loss : 0.021572, loss_ce: 0.008577
2022-01-21 22:14:33,042 iteration 4162 : loss : 0.016785, loss_ce: 0.006195
2022-01-21 22:14:34,248 iteration 4163 : loss : 0.035299, loss_ce: 0.008690
2022-01-21 22:14:35,465 iteration 4164 : loss : 0.019490, loss_ce: 0.008138
2022-01-21 22:14:35,465 Training Data Eval:
2022-01-21 22:14:41,144   Average segmentation loss on training set: 0.0164
2022-01-21 22:14:41,145 Validation Data Eval:
2022-01-21 22:14:43,120   Average segmentation loss on validation set: 0.0519
2022-01-21 22:14:47,176 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-21 22:14:48,423 iteration 4165 : loss : 0.026559, loss_ce: 0.011359
 61%|████████████████▌          | 245/400 [1:29:38<1:02:25, 24.17s/it]2022-01-21 22:14:49,608 iteration 4166 : loss : 0.019286, loss_ce: 0.008558
2022-01-21 22:14:50,803 iteration 4167 : loss : 0.028348, loss_ce: 0.008512
2022-01-21 22:14:52,013 iteration 4168 : loss : 0.042451, loss_ce: 0.016311
2022-01-21 22:14:53,210 iteration 4169 : loss : 0.021492, loss_ce: 0.008107
2022-01-21 22:14:54,429 iteration 4170 : loss : 0.027239, loss_ce: 0.012208
2022-01-21 22:14:55,574 iteration 4171 : loss : 0.020902, loss_ce: 0.009727
2022-01-21 22:14:56,730 iteration 4172 : loss : 0.023500, loss_ce: 0.009214
2022-01-21 22:14:57,821 iteration 4173 : loss : 0.018272, loss_ce: 0.005951
2022-01-21 22:14:59,032 iteration 4174 : loss : 0.028151, loss_ce: 0.011038
2022-01-21 22:15:00,225 iteration 4175 : loss : 0.023041, loss_ce: 0.006376
2022-01-21 22:15:01,445 iteration 4176 : loss : 0.027696, loss_ce: 0.009209
2022-01-21 22:15:02,557 iteration 4177 : loss : 0.021046, loss_ce: 0.009597
2022-01-21 22:15:03,720 iteration 4178 : loss : 0.017394, loss_ce: 0.007117
2022-01-21 22:15:04,936 iteration 4179 : loss : 0.026165, loss_ce: 0.009594
2022-01-21 22:15:06,183 iteration 4180 : loss : 0.024985, loss_ce: 0.008611
2022-01-21 22:15:07,381 iteration 4181 : loss : 0.023424, loss_ce: 0.009924
2022-01-21 22:15:08,611 iteration 4182 : loss : 0.023812, loss_ce: 0.009617
 62%|█████████████████▊           | 246/400 [1:29:58<58:57, 22.97s/it]2022-01-21 22:15:09,830 iteration 4183 : loss : 0.039948, loss_ce: 0.009135
2022-01-21 22:15:10,988 iteration 4184 : loss : 0.022981, loss_ce: 0.007244
2022-01-21 22:15:12,193 iteration 4185 : loss : 0.034739, loss_ce: 0.011166
2022-01-21 22:15:13,354 iteration 4186 : loss : 0.024259, loss_ce: 0.009293
2022-01-21 22:15:14,492 iteration 4187 : loss : 0.023234, loss_ce: 0.009305
2022-01-21 22:15:15,649 iteration 4188 : loss : 0.025815, loss_ce: 0.010533
2022-01-21 22:15:16,751 iteration 4189 : loss : 0.022126, loss_ce: 0.007735
2022-01-21 22:15:18,020 iteration 4190 : loss : 0.026083, loss_ce: 0.011956
2022-01-21 22:15:19,241 iteration 4191 : loss : 0.019949, loss_ce: 0.004986
2022-01-21 22:15:20,364 iteration 4192 : loss : 0.018842, loss_ce: 0.010349
2022-01-21 22:15:21,474 iteration 4193 : loss : 0.018943, loss_ce: 0.006016
2022-01-21 22:15:22,637 iteration 4194 : loss : 0.024028, loss_ce: 0.007985
2022-01-21 22:15:23,770 iteration 4195 : loss : 0.019226, loss_ce: 0.008782
2022-01-21 22:15:24,900 iteration 4196 : loss : 0.018080, loss_ce: 0.007147
2022-01-21 22:15:26,035 iteration 4197 : loss : 0.017860, loss_ce: 0.007103
2022-01-21 22:15:27,150 iteration 4198 : loss : 0.023616, loss_ce: 0.005550
2022-01-21 22:15:28,353 iteration 4199 : loss : 0.023247, loss_ce: 0.010072
 62%|█████████████████▉           | 247/400 [1:30:18<56:05, 22.00s/it]2022-01-21 22:15:29,562 iteration 4200 : loss : 0.019965, loss_ce: 0.006656
2022-01-21 22:15:30,778 iteration 4201 : loss : 0.042031, loss_ce: 0.020363
2022-01-21 22:15:32,026 iteration 4202 : loss : 0.023597, loss_ce: 0.009713
2022-01-21 22:15:33,280 iteration 4203 : loss : 0.030614, loss_ce: 0.011499
2022-01-21 22:15:34,500 iteration 4204 : loss : 0.016932, loss_ce: 0.007025
2022-01-21 22:15:35,540 iteration 4205 : loss : 0.015074, loss_ce: 0.005164
2022-01-21 22:15:36,686 iteration 4206 : loss : 0.026096, loss_ce: 0.007825
2022-01-21 22:15:37,820 iteration 4207 : loss : 0.017439, loss_ce: 0.008373
2022-01-21 22:15:39,028 iteration 4208 : loss : 0.023712, loss_ce: 0.007795
2022-01-21 22:15:40,191 iteration 4209 : loss : 0.021464, loss_ce: 0.006027
2022-01-21 22:15:41,339 iteration 4210 : loss : 0.017863, loss_ce: 0.006021
2022-01-21 22:15:42,522 iteration 4211 : loss : 0.018999, loss_ce: 0.007376
2022-01-21 22:15:43,669 iteration 4212 : loss : 0.016614, loss_ce: 0.006772
2022-01-21 22:15:44,901 iteration 4213 : loss : 0.019494, loss_ce: 0.006015
2022-01-21 22:15:46,131 iteration 4214 : loss : 0.027312, loss_ce: 0.011978
2022-01-21 22:15:47,349 iteration 4215 : loss : 0.027336, loss_ce: 0.008017
2022-01-21 22:15:48,518 iteration 4216 : loss : 0.031195, loss_ce: 0.012480
 62%|█████████████████▉           | 248/400 [1:30:38<54:20, 21.45s/it]2022-01-21 22:15:49,813 iteration 4217 : loss : 0.036220, loss_ce: 0.010389
2022-01-21 22:15:51,074 iteration 4218 : loss : 0.021100, loss_ce: 0.010437
2022-01-21 22:15:52,274 iteration 4219 : loss : 0.025866, loss_ce: 0.010935
2022-01-21 22:15:53,454 iteration 4220 : loss : 0.020167, loss_ce: 0.006418
2022-01-21 22:15:54,663 iteration 4221 : loss : 0.031690, loss_ce: 0.010863
2022-01-21 22:15:55,891 iteration 4222 : loss : 0.017421, loss_ce: 0.007571
2022-01-21 22:15:57,194 iteration 4223 : loss : 0.034561, loss_ce: 0.007978
2022-01-21 22:15:58,374 iteration 4224 : loss : 0.025072, loss_ce: 0.008282
2022-01-21 22:15:59,596 iteration 4225 : loss : 0.022515, loss_ce: 0.011137
2022-01-21 22:16:00,864 iteration 4226 : loss : 0.021865, loss_ce: 0.008233
2022-01-21 22:16:02,023 iteration 4227 : loss : 0.024872, loss_ce: 0.007867
2022-01-21 22:16:03,229 iteration 4228 : loss : 0.029850, loss_ce: 0.015164
2022-01-21 22:16:04,368 iteration 4229 : loss : 0.019829, loss_ce: 0.007514
2022-01-21 22:16:05,593 iteration 4230 : loss : 0.026017, loss_ce: 0.009214
2022-01-21 22:16:06,799 iteration 4231 : loss : 0.031049, loss_ce: 0.009437
2022-01-21 22:16:08,027 iteration 4232 : loss : 0.028839, loss_ce: 0.012412
2022-01-21 22:16:09,161 iteration 4233 : loss : 0.021163, loss_ce: 0.007485
 62%|██████████████████           | 249/400 [1:30:59<53:22, 21.21s/it]2022-01-21 22:16:10,429 iteration 4234 : loss : 0.024411, loss_ce: 0.010595
2022-01-21 22:16:11,572 iteration 4235 : loss : 0.019236, loss_ce: 0.007396
2022-01-21 22:16:12,800 iteration 4236 : loss : 0.040209, loss_ce: 0.022660
2022-01-21 22:16:13,976 iteration 4237 : loss : 0.017445, loss_ce: 0.008306
2022-01-21 22:16:15,234 iteration 4238 : loss : 0.032910, loss_ce: 0.010255
2022-01-21 22:16:16,344 iteration 4239 : loss : 0.022625, loss_ce: 0.006178
2022-01-21 22:16:17,603 iteration 4240 : loss : 0.023674, loss_ce: 0.008798
2022-01-21 22:16:18,773 iteration 4241 : loss : 0.019632, loss_ce: 0.006680
2022-01-21 22:16:19,920 iteration 4242 : loss : 0.036049, loss_ce: 0.010552
2022-01-21 22:16:21,092 iteration 4243 : loss : 0.026511, loss_ce: 0.009697
2022-01-21 22:16:22,318 iteration 4244 : loss : 0.023077, loss_ce: 0.008453
2022-01-21 22:16:23,515 iteration 4245 : loss : 0.037545, loss_ce: 0.008312
2022-01-21 22:16:24,681 iteration 4246 : loss : 0.023316, loss_ce: 0.010842
2022-01-21 22:16:25,839 iteration 4247 : loss : 0.023283, loss_ce: 0.005229
2022-01-21 22:16:27,047 iteration 4248 : loss : 0.029029, loss_ce: 0.013120
2022-01-21 22:16:28,230 iteration 4249 : loss : 0.034271, loss_ce: 0.016068
2022-01-21 22:16:28,231 Training Data Eval:
2022-01-21 22:16:33,887   Average segmentation loss on training set: 0.0169
2022-01-21 22:16:33,888 Validation Data Eval:
2022-01-21 22:16:35,858   Average segmentation loss on validation set: 0.0696
2022-01-21 22:16:37,066 iteration 4250 : loss : 0.024256, loss_ce: 0.007102
 62%|██████████████████▏          | 250/400 [1:31:26<58:02, 23.22s/it]2022-01-21 22:16:38,346 iteration 4251 : loss : 0.023369, loss_ce: 0.009159
2022-01-21 22:16:39,568 iteration 4252 : loss : 0.028040, loss_ce: 0.010346
2022-01-21 22:16:40,783 iteration 4253 : loss : 0.027810, loss_ce: 0.009167
2022-01-21 22:16:42,046 iteration 4254 : loss : 0.025401, loss_ce: 0.010507
2022-01-21 22:16:43,150 iteration 4255 : loss : 0.017098, loss_ce: 0.006641
2022-01-21 22:16:44,321 iteration 4256 : loss : 0.024108, loss_ce: 0.006299
2022-01-21 22:16:45,572 iteration 4257 : loss : 0.025618, loss_ce: 0.008968
2022-01-21 22:16:46,725 iteration 4258 : loss : 0.019562, loss_ce: 0.006826
2022-01-21 22:16:47,911 iteration 4259 : loss : 0.034062, loss_ce: 0.011283
2022-01-21 22:16:49,098 iteration 4260 : loss : 0.025055, loss_ce: 0.007599
2022-01-21 22:16:50,297 iteration 4261 : loss : 0.022101, loss_ce: 0.008655
2022-01-21 22:16:51,567 iteration 4262 : loss : 0.019751, loss_ce: 0.008594
2022-01-21 22:16:52,754 iteration 4263 : loss : 0.018179, loss_ce: 0.007193
2022-01-21 22:16:53,880 iteration 4264 : loss : 0.027666, loss_ce: 0.008750
2022-01-21 22:16:55,049 iteration 4265 : loss : 0.029059, loss_ce: 0.011063
2022-01-21 22:16:56,228 iteration 4266 : loss : 0.023146, loss_ce: 0.008604
2022-01-21 22:16:57,410 iteration 4267 : loss : 0.020350, loss_ce: 0.009591
 63%|██████████████████▏          | 251/400 [1:31:47<55:30, 22.35s/it]2022-01-21 22:16:58,630 iteration 4268 : loss : 0.021940, loss_ce: 0.008974
2022-01-21 22:16:59,764 iteration 4269 : loss : 0.019284, loss_ce: 0.006750
2022-01-21 22:17:00,911 iteration 4270 : loss : 0.034058, loss_ce: 0.004940
2022-01-21 22:17:02,045 iteration 4271 : loss : 0.017670, loss_ce: 0.007969
2022-01-21 22:17:03,264 iteration 4272 : loss : 0.023585, loss_ce: 0.007655
2022-01-21 22:17:04,459 iteration 4273 : loss : 0.023882, loss_ce: 0.009729
2022-01-21 22:17:05,682 iteration 4274 : loss : 0.026351, loss_ce: 0.011736
2022-01-21 22:17:06,742 iteration 4275 : loss : 0.018691, loss_ce: 0.007602
2022-01-21 22:17:07,870 iteration 4276 : loss : 0.025873, loss_ce: 0.008131
2022-01-21 22:17:09,007 iteration 4277 : loss : 0.016070, loss_ce: 0.006797
2022-01-21 22:17:10,155 iteration 4278 : loss : 0.031325, loss_ce: 0.008794
2022-01-21 22:17:11,267 iteration 4279 : loss : 0.017527, loss_ce: 0.005603
2022-01-21 22:17:12,395 iteration 4280 : loss : 0.026880, loss_ce: 0.008397
2022-01-21 22:17:13,682 iteration 4281 : loss : 0.030735, loss_ce: 0.015856
2022-01-21 22:17:14,868 iteration 4282 : loss : 0.021404, loss_ce: 0.008659
2022-01-21 22:17:15,957 iteration 4283 : loss : 0.019412, loss_ce: 0.008209
2022-01-21 22:17:17,112 iteration 4284 : loss : 0.021058, loss_ce: 0.009346
 63%|██████████████████▎          | 252/400 [1:32:07<53:10, 21.56s/it]2022-01-21 22:17:18,371 iteration 4285 : loss : 0.025490, loss_ce: 0.011411
2022-01-21 22:17:19,582 iteration 4286 : loss : 0.021588, loss_ce: 0.006465
2022-01-21 22:17:20,809 iteration 4287 : loss : 0.032208, loss_ce: 0.012854
2022-01-21 22:17:21,987 iteration 4288 : loss : 0.017874, loss_ce: 0.005316
2022-01-21 22:17:23,186 iteration 4289 : loss : 0.023810, loss_ce: 0.006721
2022-01-21 22:17:24,415 iteration 4290 : loss : 0.030101, loss_ce: 0.011588
2022-01-21 22:17:25,527 iteration 4291 : loss : 0.020026, loss_ce: 0.006670
2022-01-21 22:17:26,765 iteration 4292 : loss : 0.022900, loss_ce: 0.007650
2022-01-21 22:17:27,967 iteration 4293 : loss : 0.034166, loss_ce: 0.014302
2022-01-21 22:17:29,151 iteration 4294 : loss : 0.021497, loss_ce: 0.010682
2022-01-21 22:17:30,375 iteration 4295 : loss : 0.024015, loss_ce: 0.009998
2022-01-21 22:17:31,485 iteration 4296 : loss : 0.017089, loss_ce: 0.006979
2022-01-21 22:17:32,674 iteration 4297 : loss : 0.022522, loss_ce: 0.007441
2022-01-21 22:17:33,817 iteration 4298 : loss : 0.017717, loss_ce: 0.005729
2022-01-21 22:17:35,076 iteration 4299 : loss : 0.031353, loss_ce: 0.011232
2022-01-21 22:17:36,301 iteration 4300 : loss : 0.027374, loss_ce: 0.008010
2022-01-21 22:17:37,470 iteration 4301 : loss : 0.018892, loss_ce: 0.006930
 63%|██████████████████▎          | 253/400 [1:32:27<51:55, 21.20s/it]2022-01-21 22:17:38,709 iteration 4302 : loss : 0.017973, loss_ce: 0.007441
2022-01-21 22:17:39,940 iteration 4303 : loss : 0.024695, loss_ce: 0.007865
2022-01-21 22:17:41,063 iteration 4304 : loss : 0.019063, loss_ce: 0.006867
2022-01-21 22:17:42,262 iteration 4305 : loss : 0.024335, loss_ce: 0.007054
2022-01-21 22:17:43,411 iteration 4306 : loss : 0.021544, loss_ce: 0.006846
2022-01-21 22:17:44,569 iteration 4307 : loss : 0.020827, loss_ce: 0.006876
2022-01-21 22:17:45,798 iteration 4308 : loss : 0.029550, loss_ce: 0.010256
2022-01-21 22:17:46,943 iteration 4309 : loss : 0.023966, loss_ce: 0.007649
2022-01-21 22:17:48,149 iteration 4310 : loss : 0.022445, loss_ce: 0.009842
2022-01-21 22:17:49,339 iteration 4311 : loss : 0.021615, loss_ce: 0.010144
2022-01-21 22:17:50,622 iteration 4312 : loss : 0.028722, loss_ce: 0.011634
2022-01-21 22:17:51,808 iteration 4313 : loss : 0.021722, loss_ce: 0.007650
2022-01-21 22:17:52,985 iteration 4314 : loss : 0.023016, loss_ce: 0.007642
2022-01-21 22:17:54,129 iteration 4315 : loss : 0.020720, loss_ce: 0.009184
2022-01-21 22:17:55,360 iteration 4316 : loss : 0.025349, loss_ce: 0.008712
2022-01-21 22:17:56,523 iteration 4317 : loss : 0.034580, loss_ce: 0.010652
2022-01-21 22:17:57,685 iteration 4318 : loss : 0.021420, loss_ce: 0.010468
 64%|██████████████████▍          | 254/400 [1:32:47<50:51, 20.90s/it]2022-01-21 22:17:58,961 iteration 4319 : loss : 0.031141, loss_ce: 0.009766
2022-01-21 22:18:00,192 iteration 4320 : loss : 0.027425, loss_ce: 0.011726
2022-01-21 22:18:01,431 iteration 4321 : loss : 0.020474, loss_ce: 0.008448
2022-01-21 22:18:02,629 iteration 4322 : loss : 0.026617, loss_ce: 0.007493
2022-01-21 22:18:03,785 iteration 4323 : loss : 0.017714, loss_ce: 0.005886
2022-01-21 22:18:04,985 iteration 4324 : loss : 0.022917, loss_ce: 0.008510
2022-01-21 22:18:06,276 iteration 4325 : loss : 0.042352, loss_ce: 0.008626
2022-01-21 22:18:07,469 iteration 4326 : loss : 0.020644, loss_ce: 0.010797
2022-01-21 22:18:08,616 iteration 4327 : loss : 0.019210, loss_ce: 0.006909
2022-01-21 22:18:09,775 iteration 4328 : loss : 0.022846, loss_ce: 0.009038
2022-01-21 22:18:10,998 iteration 4329 : loss : 0.023840, loss_ce: 0.009322
2022-01-21 22:18:12,136 iteration 4330 : loss : 0.017860, loss_ce: 0.006169
2022-01-21 22:18:13,439 iteration 4331 : loss : 0.046376, loss_ce: 0.012096
2022-01-21 22:18:14,680 iteration 4332 : loss : 0.040382, loss_ce: 0.018092
2022-01-21 22:18:15,794 iteration 4333 : loss : 0.021532, loss_ce: 0.006423
2022-01-21 22:18:16,927 iteration 4334 : loss : 0.019323, loss_ce: 0.007476
2022-01-21 22:18:16,927 Training Data Eval:
2022-01-21 22:18:22,612   Average segmentation loss on training set: 0.0147
2022-01-21 22:18:22,612 Validation Data Eval:
2022-01-21 22:18:24,580   Average segmentation loss on validation set: 0.0683
2022-01-21 22:18:25,819 iteration 4335 : loss : 0.057892, loss_ce: 0.032685
 64%|██████████████████▍          | 255/400 [1:33:15<55:45, 23.07s/it]2022-01-21 22:18:27,035 iteration 4336 : loss : 0.026948, loss_ce: 0.009851
2022-01-21 22:18:28,240 iteration 4337 : loss : 0.023633, loss_ce: 0.008911
2022-01-21 22:18:29,514 iteration 4338 : loss : 0.026806, loss_ce: 0.011206
2022-01-21 22:18:30,670 iteration 4339 : loss : 0.033697, loss_ce: 0.009559
2022-01-21 22:18:31,866 iteration 4340 : loss : 0.025176, loss_ce: 0.009422
2022-01-21 22:18:33,074 iteration 4341 : loss : 0.030060, loss_ce: 0.013422
2022-01-21 22:18:34,248 iteration 4342 : loss : 0.038366, loss_ce: 0.012161
2022-01-21 22:18:35,442 iteration 4343 : loss : 0.021980, loss_ce: 0.006776
2022-01-21 22:18:36,589 iteration 4344 : loss : 0.025085, loss_ce: 0.008651
2022-01-21 22:18:37,770 iteration 4345 : loss : 0.024425, loss_ce: 0.007298
2022-01-21 22:18:38,919 iteration 4346 : loss : 0.020304, loss_ce: 0.009339
2022-01-21 22:18:40,139 iteration 4347 : loss : 0.030806, loss_ce: 0.010016
2022-01-21 22:18:41,332 iteration 4348 : loss : 0.021030, loss_ce: 0.010871
2022-01-21 22:18:42,518 iteration 4349 : loss : 0.021502, loss_ce: 0.006479
2022-01-21 22:18:43,671 iteration 4350 : loss : 0.023195, loss_ce: 0.010663
2022-01-21 22:18:44,787 iteration 4351 : loss : 0.016398, loss_ce: 0.007127
2022-01-21 22:18:45,940 iteration 4352 : loss : 0.016037, loss_ce: 0.006284
 64%|██████████████████▌          | 256/400 [1:33:35<53:15, 22.19s/it]2022-01-21 22:18:47,185 iteration 4353 : loss : 0.024780, loss_ce: 0.008215
2022-01-21 22:18:48,446 iteration 4354 : loss : 0.028630, loss_ce: 0.008358
2022-01-21 22:18:49,584 iteration 4355 : loss : 0.017871, loss_ce: 0.006140
2022-01-21 22:18:50,795 iteration 4356 : loss : 0.032715, loss_ce: 0.018231
2022-01-21 22:18:51,987 iteration 4357 : loss : 0.031267, loss_ce: 0.012308
2022-01-21 22:18:53,141 iteration 4358 : loss : 0.024332, loss_ce: 0.010182
2022-01-21 22:18:54,305 iteration 4359 : loss : 0.017423, loss_ce: 0.007041
2022-01-21 22:18:55,474 iteration 4360 : loss : 0.032431, loss_ce: 0.011347
2022-01-21 22:18:56,705 iteration 4361 : loss : 0.029928, loss_ce: 0.014139
2022-01-21 22:18:57,860 iteration 4362 : loss : 0.025910, loss_ce: 0.008196
2022-01-21 22:18:58,972 iteration 4363 : loss : 0.020617, loss_ce: 0.010496
2022-01-21 22:19:00,196 iteration 4364 : loss : 0.028829, loss_ce: 0.010905
2022-01-21 22:19:01,373 iteration 4365 : loss : 0.022145, loss_ce: 0.008678
2022-01-21 22:19:02,446 iteration 4366 : loss : 0.016646, loss_ce: 0.007171
2022-01-21 22:19:03,614 iteration 4367 : loss : 0.037093, loss_ce: 0.012839
2022-01-21 22:19:04,854 iteration 4368 : loss : 0.024847, loss_ce: 0.010311
2022-01-21 22:19:05,986 iteration 4369 : loss : 0.024835, loss_ce: 0.006204
 64%|██████████████████▋          | 257/400 [1:33:55<51:20, 21.54s/it]2022-01-21 22:19:07,225 iteration 4370 : loss : 0.052388, loss_ce: 0.016098
2022-01-21 22:19:08,421 iteration 4371 : loss : 0.025146, loss_ce: 0.011746
2022-01-21 22:19:09,527 iteration 4372 : loss : 0.019847, loss_ce: 0.008953
2022-01-21 22:19:10,741 iteration 4373 : loss : 0.019518, loss_ce: 0.006371
2022-01-21 22:19:11,903 iteration 4374 : loss : 0.018783, loss_ce: 0.008755
2022-01-21 22:19:13,023 iteration 4375 : loss : 0.021914, loss_ce: 0.010031
2022-01-21 22:19:14,178 iteration 4376 : loss : 0.026853, loss_ce: 0.010204
2022-01-21 22:19:15,448 iteration 4377 : loss : 0.029381, loss_ce: 0.008800
2022-01-21 22:19:16,665 iteration 4378 : loss : 0.021056, loss_ce: 0.008266
2022-01-21 22:19:17,943 iteration 4379 : loss : 0.034685, loss_ce: 0.015766
2022-01-21 22:19:19,145 iteration 4380 : loss : 0.020284, loss_ce: 0.008323
2022-01-21 22:19:20,366 iteration 4381 : loss : 0.029179, loss_ce: 0.012158
2022-01-21 22:19:21,538 iteration 4382 : loss : 0.025381, loss_ce: 0.009127
2022-01-21 22:19:22,713 iteration 4383 : loss : 0.027639, loss_ce: 0.007541
2022-01-21 22:19:23,904 iteration 4384 : loss : 0.026507, loss_ce: 0.009713
2022-01-21 22:19:25,006 iteration 4385 : loss : 0.019454, loss_ce: 0.009315
2022-01-21 22:19:26,198 iteration 4386 : loss : 0.030956, loss_ce: 0.012583
 64%|██████████████████▋          | 258/400 [1:34:16<50:02, 21.15s/it]2022-01-21 22:19:27,410 iteration 4387 : loss : 0.017697, loss_ce: 0.006117
2022-01-21 22:19:28,631 iteration 4388 : loss : 0.028481, loss_ce: 0.013060
2022-01-21 22:19:29,754 iteration 4389 : loss : 0.016146, loss_ce: 0.006775
2022-01-21 22:19:30,874 iteration 4390 : loss : 0.022840, loss_ce: 0.009264
2022-01-21 22:19:32,040 iteration 4391 : loss : 0.021112, loss_ce: 0.007813
2022-01-21 22:19:33,251 iteration 4392 : loss : 0.020679, loss_ce: 0.009723
2022-01-21 22:19:34,356 iteration 4393 : loss : 0.020033, loss_ce: 0.006384
2022-01-21 22:19:35,603 iteration 4394 : loss : 0.020644, loss_ce: 0.010570
2022-01-21 22:19:36,830 iteration 4395 : loss : 0.017475, loss_ce: 0.006574
2022-01-21 22:19:38,080 iteration 4396 : loss : 0.019137, loss_ce: 0.007453
2022-01-21 22:19:39,256 iteration 4397 : loss : 0.027141, loss_ce: 0.009810
2022-01-21 22:19:40,406 iteration 4398 : loss : 0.028200, loss_ce: 0.007764
2022-01-21 22:19:41,581 iteration 4399 : loss : 0.032094, loss_ce: 0.009069
2022-01-21 22:19:42,724 iteration 4400 : loss : 0.018612, loss_ce: 0.007797
2022-01-21 22:19:43,879 iteration 4401 : loss : 0.020165, loss_ce: 0.008346
2022-01-21 22:19:45,004 iteration 4402 : loss : 0.017640, loss_ce: 0.005489
2022-01-21 22:19:46,177 iteration 4403 : loss : 0.025526, loss_ce: 0.007867
 65%|██████████████████▊          | 259/400 [1:34:36<48:51, 20.79s/it]2022-01-21 22:19:47,343 iteration 4404 : loss : 0.015334, loss_ce: 0.007376
2022-01-21 22:19:48,545 iteration 4405 : loss : 0.018706, loss_ce: 0.005302
2022-01-21 22:19:49,738 iteration 4406 : loss : 0.025252, loss_ce: 0.007944
2022-01-21 22:19:50,866 iteration 4407 : loss : 0.024338, loss_ce: 0.009059
2022-01-21 22:19:51,957 iteration 4408 : loss : 0.022786, loss_ce: 0.005389
2022-01-21 22:19:53,136 iteration 4409 : loss : 0.014825, loss_ce: 0.005701
2022-01-21 22:19:54,318 iteration 4410 : loss : 0.025523, loss_ce: 0.008069
2022-01-21 22:19:55,563 iteration 4411 : loss : 0.018454, loss_ce: 0.008258
2022-01-21 22:19:56,694 iteration 4412 : loss : 0.018784, loss_ce: 0.007933
2022-01-21 22:19:57,931 iteration 4413 : loss : 0.026710, loss_ce: 0.008503
2022-01-21 22:19:59,028 iteration 4414 : loss : 0.016447, loss_ce: 0.006355
2022-01-21 22:20:00,217 iteration 4415 : loss : 0.021904, loss_ce: 0.010147
2022-01-21 22:20:01,366 iteration 4416 : loss : 0.024402, loss_ce: 0.005623
2022-01-21 22:20:02,537 iteration 4417 : loss : 0.021803, loss_ce: 0.007509
2022-01-21 22:20:03,731 iteration 4418 : loss : 0.025601, loss_ce: 0.010764
2022-01-21 22:20:04,932 iteration 4419 : loss : 0.021116, loss_ce: 0.006957
2022-01-21 22:20:04,933 Training Data Eval:
2022-01-21 22:20:10,646   Average segmentation loss on training set: 0.0130
2022-01-21 22:20:10,646 Validation Data Eval:
2022-01-21 22:20:12,611   Average segmentation loss on validation set: 0.0609
2022-01-21 22:20:13,736 iteration 4420 : loss : 0.013599, loss_ce: 0.005523
 65%|██████████████████▊          | 260/400 [1:35:03<53:15, 22.82s/it]2022-01-21 22:20:14,975 iteration 4421 : loss : 0.016943, loss_ce: 0.005584
2022-01-21 22:20:16,201 iteration 4422 : loss : 0.019483, loss_ce: 0.006450
2022-01-21 22:20:17,486 iteration 4423 : loss : 0.028597, loss_ce: 0.015064
2022-01-21 22:20:18,728 iteration 4424 : loss : 0.030682, loss_ce: 0.012305
2022-01-21 22:20:19,849 iteration 4425 : loss : 0.018419, loss_ce: 0.007521
2022-01-21 22:20:21,082 iteration 4426 : loss : 0.020457, loss_ce: 0.007006
2022-01-21 22:20:22,291 iteration 4427 : loss : 0.043271, loss_ce: 0.011430
2022-01-21 22:20:23,515 iteration 4428 : loss : 0.020739, loss_ce: 0.008648
2022-01-21 22:20:24,763 iteration 4429 : loss : 0.028918, loss_ce: 0.009737
2022-01-21 22:20:25,927 iteration 4430 : loss : 0.021763, loss_ce: 0.007003
2022-01-21 22:20:27,089 iteration 4431 : loss : 0.017951, loss_ce: 0.007254
2022-01-21 22:20:28,248 iteration 4432 : loss : 0.014919, loss_ce: 0.005657
2022-01-21 22:20:29,412 iteration 4433 : loss : 0.021570, loss_ce: 0.009748
2022-01-21 22:20:30,573 iteration 4434 : loss : 0.016322, loss_ce: 0.006005
2022-01-21 22:20:31,785 iteration 4435 : loss : 0.035589, loss_ce: 0.012666
2022-01-21 22:20:33,078 iteration 4436 : loss : 0.036811, loss_ce: 0.017142
2022-01-21 22:20:34,204 iteration 4437 : loss : 0.020653, loss_ce: 0.007623
 65%|██████████████████▉          | 261/400 [1:35:24<51:14, 22.12s/it]2022-01-21 22:20:35,488 iteration 4438 : loss : 0.021006, loss_ce: 0.007082
2022-01-21 22:20:36,636 iteration 4439 : loss : 0.021201, loss_ce: 0.007481
2022-01-21 22:20:37,861 iteration 4440 : loss : 0.026188, loss_ce: 0.008932
2022-01-21 22:20:39,085 iteration 4441 : loss : 0.021407, loss_ce: 0.009617
2022-01-21 22:20:40,220 iteration 4442 : loss : 0.017576, loss_ce: 0.009166
2022-01-21 22:20:41,408 iteration 4443 : loss : 0.022809, loss_ce: 0.009818
2022-01-21 22:20:42,558 iteration 4444 : loss : 0.020733, loss_ce: 0.007204
2022-01-21 22:20:43,746 iteration 4445 : loss : 0.023424, loss_ce: 0.008624
2022-01-21 22:20:44,960 iteration 4446 : loss : 0.018963, loss_ce: 0.007146
2022-01-21 22:20:46,162 iteration 4447 : loss : 0.027619, loss_ce: 0.010713
2022-01-21 22:20:47,333 iteration 4448 : loss : 0.029720, loss_ce: 0.007019
2022-01-21 22:20:48,529 iteration 4449 : loss : 0.022328, loss_ce: 0.010935
2022-01-21 22:20:49,763 iteration 4450 : loss : 0.018731, loss_ce: 0.006502
2022-01-21 22:20:50,882 iteration 4451 : loss : 0.020044, loss_ce: 0.007208
2022-01-21 22:20:52,071 iteration 4452 : loss : 0.018564, loss_ce: 0.007446
2022-01-21 22:20:53,344 iteration 4453 : loss : 0.025778, loss_ce: 0.009297
2022-01-21 22:20:54,556 iteration 4454 : loss : 0.023793, loss_ce: 0.011633
 66%|██████████████████▉          | 262/400 [1:35:44<49:39, 21.59s/it]2022-01-21 22:20:55,854 iteration 4455 : loss : 0.020888, loss_ce: 0.007006
2022-01-21 22:20:57,045 iteration 4456 : loss : 0.024451, loss_ce: 0.011168
2022-01-21 22:20:58,150 iteration 4457 : loss : 0.016757, loss_ce: 0.008007
2022-01-21 22:20:59,350 iteration 4458 : loss : 0.021387, loss_ce: 0.008772
2022-01-21 22:21:00,479 iteration 4459 : loss : 0.017562, loss_ce: 0.006847
2022-01-21 22:21:01,653 iteration 4460 : loss : 0.017968, loss_ce: 0.006450
2022-01-21 22:21:02,778 iteration 4461 : loss : 0.018864, loss_ce: 0.008436
2022-01-21 22:21:03,916 iteration 4462 : loss : 0.015593, loss_ce: 0.005858
2022-01-21 22:21:05,054 iteration 4463 : loss : 0.015725, loss_ce: 0.005407
2022-01-21 22:21:06,178 iteration 4464 : loss : 0.019325, loss_ce: 0.007013
2022-01-21 22:21:07,380 iteration 4465 : loss : 0.024546, loss_ce: 0.009543
2022-01-21 22:21:08,592 iteration 4466 : loss : 0.024461, loss_ce: 0.007279
2022-01-21 22:21:09,778 iteration 4467 : loss : 0.015908, loss_ce: 0.005852
2022-01-21 22:21:10,940 iteration 4468 : loss : 0.017093, loss_ce: 0.005874
2022-01-21 22:21:12,063 iteration 4469 : loss : 0.024823, loss_ce: 0.005867
2022-01-21 22:21:13,268 iteration 4470 : loss : 0.024361, loss_ce: 0.008874
2022-01-21 22:21:14,488 iteration 4471 : loss : 0.018533, loss_ce: 0.005217
 66%|███████████████████          | 263/400 [1:36:04<48:09, 21.09s/it]2022-01-21 22:21:15,679 iteration 4472 : loss : 0.017098, loss_ce: 0.007326
2022-01-21 22:21:16,836 iteration 4473 : loss : 0.023302, loss_ce: 0.008630
2022-01-21 22:21:18,033 iteration 4474 : loss : 0.021369, loss_ce: 0.008535
2022-01-21 22:21:19,176 iteration 4475 : loss : 0.018755, loss_ce: 0.008027
2022-01-21 22:21:20,259 iteration 4476 : loss : 0.016231, loss_ce: 0.005478
2022-01-21 22:21:21,435 iteration 4477 : loss : 0.027656, loss_ce: 0.010338
2022-01-21 22:21:22,616 iteration 4478 : loss : 0.028506, loss_ce: 0.009150
2022-01-21 22:21:23,797 iteration 4479 : loss : 0.034169, loss_ce: 0.006430
2022-01-21 22:21:24,931 iteration 4480 : loss : 0.015868, loss_ce: 0.006344
2022-01-21 22:21:26,052 iteration 4481 : loss : 0.015036, loss_ce: 0.006131
2022-01-21 22:21:27,284 iteration 4482 : loss : 0.023720, loss_ce: 0.007088
2022-01-21 22:21:28,551 iteration 4483 : loss : 0.030470, loss_ce: 0.012630
2022-01-21 22:21:29,782 iteration 4484 : loss : 0.030820, loss_ce: 0.010309
2022-01-21 22:21:30,933 iteration 4485 : loss : 0.019761, loss_ce: 0.005989
2022-01-21 22:21:32,215 iteration 4486 : loss : 0.024915, loss_ce: 0.010540
2022-01-21 22:21:33,355 iteration 4487 : loss : 0.019993, loss_ce: 0.008281
2022-01-21 22:21:34,520 iteration 4488 : loss : 0.021399, loss_ce: 0.010060
 66%|███████████████████▏         | 264/400 [1:36:24<47:05, 20.78s/it]2022-01-21 22:21:35,779 iteration 4489 : loss : 0.024074, loss_ce: 0.010347
2022-01-21 22:21:36,971 iteration 4490 : loss : 0.017754, loss_ce: 0.006932
2022-01-21 22:21:38,230 iteration 4491 : loss : 0.032351, loss_ce: 0.012191
2022-01-21 22:21:39,435 iteration 4492 : loss : 0.018411, loss_ce: 0.006604
2022-01-21 22:21:40,681 iteration 4493 : loss : 0.043538, loss_ce: 0.014157
2022-01-21 22:21:41,782 iteration 4494 : loss : 0.016983, loss_ce: 0.006694
2022-01-21 22:21:42,993 iteration 4495 : loss : 0.022107, loss_ce: 0.008857
2022-01-21 22:21:44,209 iteration 4496 : loss : 0.022075, loss_ce: 0.006858
2022-01-21 22:21:45,338 iteration 4497 : loss : 0.022056, loss_ce: 0.006203
2022-01-21 22:21:46,598 iteration 4498 : loss : 0.025081, loss_ce: 0.011799
2022-01-21 22:21:47,899 iteration 4499 : loss : 0.039357, loss_ce: 0.018140
2022-01-21 22:21:49,065 iteration 4500 : loss : 0.022663, loss_ce: 0.008859
2022-01-21 22:21:50,198 iteration 4501 : loss : 0.023763, loss_ce: 0.008193
2022-01-21 22:21:51,328 iteration 4502 : loss : 0.019643, loss_ce: 0.007268
2022-01-21 22:21:52,563 iteration 4503 : loss : 0.019361, loss_ce: 0.007818
2022-01-21 22:21:53,740 iteration 4504 : loss : 0.030011, loss_ce: 0.008655
2022-01-21 22:21:53,741 Training Data Eval:
2022-01-21 22:21:59,411   Average segmentation loss on training set: 0.0150
2022-01-21 22:21:59,412 Validation Data Eval:
2022-01-21 22:22:01,383   Average segmentation loss on validation set: 0.0750
2022-01-21 22:22:02,487 iteration 4505 : loss : 0.017305, loss_ce: 0.006719
 66%|███████████████████▏         | 265/400 [1:36:52<51:35, 22.93s/it]2022-01-21 22:22:03,748 iteration 4506 : loss : 0.027720, loss_ce: 0.008787
2022-01-21 22:22:04,895 iteration 4507 : loss : 0.015042, loss_ce: 0.004716
2022-01-21 22:22:06,123 iteration 4508 : loss : 0.035011, loss_ce: 0.010772
2022-01-21 22:22:07,319 iteration 4509 : loss : 0.028428, loss_ce: 0.008626
2022-01-21 22:22:08,505 iteration 4510 : loss : 0.019611, loss_ce: 0.007900
2022-01-21 22:22:09,647 iteration 4511 : loss : 0.028447, loss_ce: 0.009347
2022-01-21 22:22:10,816 iteration 4512 : loss : 0.013421, loss_ce: 0.005493
2022-01-21 22:22:12,008 iteration 4513 : loss : 0.019292, loss_ce: 0.009353
2022-01-21 22:22:13,121 iteration 4514 : loss : 0.018543, loss_ce: 0.006788
2022-01-21 22:22:14,280 iteration 4515 : loss : 0.031414, loss_ce: 0.010445
2022-01-21 22:22:15,558 iteration 4516 : loss : 0.029372, loss_ce: 0.011505
2022-01-21 22:22:16,728 iteration 4517 : loss : 0.021642, loss_ce: 0.009097
2022-01-21 22:22:17,937 iteration 4518 : loss : 0.021727, loss_ce: 0.006400
2022-01-21 22:22:19,124 iteration 4519 : loss : 0.023289, loss_ce: 0.010264
2022-01-21 22:22:20,253 iteration 4520 : loss : 0.021632, loss_ce: 0.008175
2022-01-21 22:22:21,449 iteration 4521 : loss : 0.024105, loss_ce: 0.009207
2022-01-21 22:22:22,578 iteration 4522 : loss : 0.019539, loss_ce: 0.010136
 66%|███████████████████▎         | 266/400 [1:37:12<49:18, 22.08s/it]2022-01-21 22:22:23,858 iteration 4523 : loss : 0.024388, loss_ce: 0.009855
2022-01-21 22:22:24,966 iteration 4524 : loss : 0.015182, loss_ce: 0.006047
2022-01-21 22:22:26,206 iteration 4525 : loss : 0.031577, loss_ce: 0.009041
2022-01-21 22:22:27,401 iteration 4526 : loss : 0.025687, loss_ce: 0.009485
2022-01-21 22:22:28,591 iteration 4527 : loss : 0.020207, loss_ce: 0.008940
2022-01-21 22:22:29,827 iteration 4528 : loss : 0.015957, loss_ce: 0.005912
2022-01-21 22:22:30,998 iteration 4529 : loss : 0.020461, loss_ce: 0.008591
2022-01-21 22:22:32,201 iteration 4530 : loss : 0.027579, loss_ce: 0.011987
2022-01-21 22:22:33,331 iteration 4531 : loss : 0.020269, loss_ce: 0.008719
2022-01-21 22:22:34,550 iteration 4532 : loss : 0.027390, loss_ce: 0.012271
2022-01-21 22:22:35,803 iteration 4533 : loss : 0.027401, loss_ce: 0.010268
2022-01-21 22:22:37,105 iteration 4534 : loss : 0.019556, loss_ce: 0.007101
2022-01-21 22:22:38,221 iteration 4535 : loss : 0.023381, loss_ce: 0.007386
2022-01-21 22:22:39,425 iteration 4536 : loss : 0.026095, loss_ce: 0.012982
2022-01-21 22:22:40,687 iteration 4537 : loss : 0.034740, loss_ce: 0.013261
2022-01-21 22:22:41,847 iteration 4538 : loss : 0.018855, loss_ce: 0.006603
2022-01-21 22:22:43,053 iteration 4539 : loss : 0.021309, loss_ce: 0.008759
 67%|███████████████████▎         | 267/400 [1:37:32<47:52, 21.60s/it]2022-01-21 22:22:44,325 iteration 4540 : loss : 0.029604, loss_ce: 0.008314
2022-01-21 22:22:45,444 iteration 4541 : loss : 0.018058, loss_ce: 0.006168
2022-01-21 22:22:46,630 iteration 4542 : loss : 0.018684, loss_ce: 0.004937
2022-01-21 22:22:47,734 iteration 4543 : loss : 0.017539, loss_ce: 0.007098
2022-01-21 22:22:48,945 iteration 4544 : loss : 0.026793, loss_ce: 0.010415
2022-01-21 22:22:50,189 iteration 4545 : loss : 0.034416, loss_ce: 0.015189
2022-01-21 22:22:51,393 iteration 4546 : loss : 0.021014, loss_ce: 0.007936
2022-01-21 22:22:52,592 iteration 4547 : loss : 0.024039, loss_ce: 0.013622
2022-01-21 22:22:53,765 iteration 4548 : loss : 0.023289, loss_ce: 0.008896
2022-01-21 22:22:55,022 iteration 4549 : loss : 0.026763, loss_ce: 0.010214
2022-01-21 22:22:56,274 iteration 4550 : loss : 0.030996, loss_ce: 0.010363
2022-01-21 22:22:57,509 iteration 4551 : loss : 0.055357, loss_ce: 0.012030
2022-01-21 22:22:58,611 iteration 4552 : loss : 0.015287, loss_ce: 0.006207
2022-01-21 22:22:59,737 iteration 4553 : loss : 0.024713, loss_ce: 0.009435
2022-01-21 22:23:00,899 iteration 4554 : loss : 0.018692, loss_ce: 0.006948
2022-01-21 22:23:02,126 iteration 4555 : loss : 0.029628, loss_ce: 0.011174
2022-01-21 22:23:03,301 iteration 4556 : loss : 0.019453, loss_ce: 0.009167
 67%|███████████████████▍         | 268/400 [1:37:53<46:37, 21.19s/it]2022-01-21 22:23:04,551 iteration 4557 : loss : 0.020752, loss_ce: 0.009297
2022-01-21 22:23:05,800 iteration 4558 : loss : 0.043896, loss_ce: 0.022561
2022-01-21 22:23:06,968 iteration 4559 : loss : 0.028658, loss_ce: 0.007027
2022-01-21 22:23:08,128 iteration 4560 : loss : 0.017484, loss_ce: 0.005313
2022-01-21 22:23:09,307 iteration 4561 : loss : 0.029326, loss_ce: 0.007663
2022-01-21 22:23:10,477 iteration 4562 : loss : 0.032644, loss_ce: 0.011584
2022-01-21 22:23:11,622 iteration 4563 : loss : 0.017626, loss_ce: 0.005668
2022-01-21 22:23:12,802 iteration 4564 : loss : 0.031043, loss_ce: 0.009020
2022-01-21 22:23:13,941 iteration 4565 : loss : 0.022066, loss_ce: 0.008458
2022-01-21 22:23:15,056 iteration 4566 : loss : 0.019862, loss_ce: 0.008168
2022-01-21 22:23:16,242 iteration 4567 : loss : 0.027706, loss_ce: 0.013170
2022-01-21 22:23:17,407 iteration 4568 : loss : 0.022389, loss_ce: 0.006010
2022-01-21 22:23:18,588 iteration 4569 : loss : 0.018769, loss_ce: 0.007246
2022-01-21 22:23:19,716 iteration 4570 : loss : 0.023502, loss_ce: 0.009580
2022-01-21 22:23:20,860 iteration 4571 : loss : 0.018294, loss_ce: 0.008985
2022-01-21 22:23:22,014 iteration 4572 : loss : 0.017743, loss_ce: 0.005586
2022-01-21 22:23:23,194 iteration 4573 : loss : 0.021260, loss_ce: 0.009155
 67%|███████████████████▌         | 269/400 [1:38:13<45:25, 20.80s/it]2022-01-21 22:23:24,403 iteration 4574 : loss : 0.022065, loss_ce: 0.007214
2022-01-21 22:23:25,539 iteration 4575 : loss : 0.022256, loss_ce: 0.010083
2022-01-21 22:23:26,742 iteration 4576 : loss : 0.017757, loss_ce: 0.009203
2022-01-21 22:23:27,978 iteration 4577 : loss : 0.025175, loss_ce: 0.009792
2022-01-21 22:23:29,160 iteration 4578 : loss : 0.023068, loss_ce: 0.009586
2022-01-21 22:23:30,327 iteration 4579 : loss : 0.021291, loss_ce: 0.009517
2022-01-21 22:23:31,487 iteration 4580 : loss : 0.024686, loss_ce: 0.010678
2022-01-21 22:23:32,751 iteration 4581 : loss : 0.021236, loss_ce: 0.006646
2022-01-21 22:23:33,935 iteration 4582 : loss : 0.018078, loss_ce: 0.008231
2022-01-21 22:23:35,123 iteration 4583 : loss : 0.016117, loss_ce: 0.005765
2022-01-21 22:23:36,269 iteration 4584 : loss : 0.023522, loss_ce: 0.009439
2022-01-21 22:23:37,470 iteration 4585 : loss : 0.026441, loss_ce: 0.007267
2022-01-21 22:23:38,618 iteration 4586 : loss : 0.017988, loss_ce: 0.007166
2022-01-21 22:23:39,874 iteration 4587 : loss : 0.034199, loss_ce: 0.011122
2022-01-21 22:23:41,028 iteration 4588 : loss : 0.015999, loss_ce: 0.003558
2022-01-21 22:23:42,201 iteration 4589 : loss : 0.018669, loss_ce: 0.007699
2022-01-21 22:23:42,201 Training Data Eval:
2022-01-21 22:23:47,911   Average segmentation loss on training set: 0.0134
2022-01-21 22:23:47,911 Validation Data Eval:
2022-01-21 22:23:49,882   Average segmentation loss on validation set: 0.0633
2022-01-21 22:23:51,175 iteration 4590 : loss : 0.024934, loss_ce: 0.008713
 68%|███████████████████▌         | 270/400 [1:38:41<49:44, 22.95s/it]2022-01-21 22:23:52,330 iteration 4591 : loss : 0.015081, loss_ce: 0.004405
2022-01-21 22:23:53,510 iteration 4592 : loss : 0.024141, loss_ce: 0.008881
2022-01-21 22:23:54,606 iteration 4593 : loss : 0.018431, loss_ce: 0.005672
2022-01-21 22:23:55,757 iteration 4594 : loss : 0.016109, loss_ce: 0.006189
2022-01-21 22:23:56,951 iteration 4595 : loss : 0.023182, loss_ce: 0.005505
2022-01-21 22:23:58,212 iteration 4596 : loss : 0.036302, loss_ce: 0.012522
2022-01-21 22:23:59,383 iteration 4597 : loss : 0.016291, loss_ce: 0.007104
2022-01-21 22:24:00,475 iteration 4598 : loss : 0.017544, loss_ce: 0.007868
2022-01-21 22:24:01,615 iteration 4599 : loss : 0.021552, loss_ce: 0.005843
2022-01-21 22:24:02,852 iteration 4600 : loss : 0.017621, loss_ce: 0.008670
2022-01-21 22:24:04,127 iteration 4601 : loss : 0.022808, loss_ce: 0.011402
2022-01-21 22:24:05,228 iteration 4602 : loss : 0.017362, loss_ce: 0.006286
2022-01-21 22:24:06,339 iteration 4603 : loss : 0.015842, loss_ce: 0.006844
2022-01-21 22:24:07,545 iteration 4604 : loss : 0.019665, loss_ce: 0.007338
2022-01-21 22:24:08,742 iteration 4605 : loss : 0.023134, loss_ce: 0.005740
2022-01-21 22:24:09,975 iteration 4606 : loss : 0.021337, loss_ce: 0.007030
2022-01-21 22:24:11,089 iteration 4607 : loss : 0.014936, loss_ce: 0.007638
 68%|███████████████████▋         | 271/400 [1:39:01<47:23, 22.05s/it]2022-01-21 22:24:12,339 iteration 4608 : loss : 0.021930, loss_ce: 0.006873
2022-01-21 22:24:13,588 iteration 4609 : loss : 0.034229, loss_ce: 0.017699
2022-01-21 22:24:14,803 iteration 4610 : loss : 0.027598, loss_ce: 0.007300
2022-01-21 22:24:15,977 iteration 4611 : loss : 0.019666, loss_ce: 0.008029
2022-01-21 22:24:17,084 iteration 4612 : loss : 0.017124, loss_ce: 0.007155
2022-01-21 22:24:18,272 iteration 4613 : loss : 0.020388, loss_ce: 0.008019
2022-01-21 22:24:19,477 iteration 4614 : loss : 0.020430, loss_ce: 0.008712
2022-01-21 22:24:20,689 iteration 4615 : loss : 0.029395, loss_ce: 0.010611
2022-01-21 22:24:21,937 iteration 4616 : loss : 0.022490, loss_ce: 0.007042
2022-01-21 22:24:23,060 iteration 4617 : loss : 0.022719, loss_ce: 0.010995
2022-01-21 22:24:24,272 iteration 4618 : loss : 0.027661, loss_ce: 0.011777
2022-01-21 22:24:25,492 iteration 4619 : loss : 0.023905, loss_ce: 0.007725
2022-01-21 22:24:26,712 iteration 4620 : loss : 0.021180, loss_ce: 0.006539
2022-01-21 22:24:27,955 iteration 4621 : loss : 0.022936, loss_ce: 0.008072
2022-01-21 22:24:29,134 iteration 4622 : loss : 0.020656, loss_ce: 0.007416
2022-01-21 22:24:30,290 iteration 4623 : loss : 0.031092, loss_ce: 0.010863
2022-01-21 22:24:31,467 iteration 4624 : loss : 0.019346, loss_ce: 0.007652
 68%|███████████████████▋         | 272/400 [1:39:21<45:57, 21.54s/it]2022-01-21 22:24:32,681 iteration 4625 : loss : 0.019475, loss_ce: 0.008857
2022-01-21 22:24:33,831 iteration 4626 : loss : 0.015378, loss_ce: 0.005218
2022-01-21 22:24:35,008 iteration 4627 : loss : 0.016479, loss_ce: 0.005189
2022-01-21 22:24:36,147 iteration 4628 : loss : 0.019294, loss_ce: 0.007113
2022-01-21 22:24:37,279 iteration 4629 : loss : 0.018095, loss_ce: 0.007491
2022-01-21 22:24:38,432 iteration 4630 : loss : 0.019226, loss_ce: 0.006708
2022-01-21 22:24:39,681 iteration 4631 : loss : 0.023580, loss_ce: 0.010120
2022-01-21 22:24:40,870 iteration 4632 : loss : 0.013726, loss_ce: 0.004461
2022-01-21 22:24:42,058 iteration 4633 : loss : 0.017179, loss_ce: 0.006960
2022-01-21 22:24:43,158 iteration 4634 : loss : 0.015842, loss_ce: 0.007147
2022-01-21 22:24:44,364 iteration 4635 : loss : 0.019889, loss_ce: 0.006237
2022-01-21 22:24:45,543 iteration 4636 : loss : 0.020457, loss_ce: 0.007668
2022-01-21 22:24:46,717 iteration 4637 : loss : 0.018852, loss_ce: 0.006628
2022-01-21 22:24:47,932 iteration 4638 : loss : 0.027441, loss_ce: 0.013105
2022-01-21 22:24:49,194 iteration 4639 : loss : 0.029992, loss_ce: 0.008752
2022-01-21 22:24:50,410 iteration 4640 : loss : 0.019152, loss_ce: 0.007459
2022-01-21 22:24:51,561 iteration 4641 : loss : 0.015808, loss_ce: 0.006438
 68%|███████████████████▊         | 273/400 [1:39:41<44:40, 21.11s/it]2022-01-21 22:24:52,832 iteration 4642 : loss : 0.023074, loss_ce: 0.006783
2022-01-21 22:24:54,049 iteration 4643 : loss : 0.030870, loss_ce: 0.013212
2022-01-21 22:24:55,257 iteration 4644 : loss : 0.016166, loss_ce: 0.006250
2022-01-21 22:24:56,595 iteration 4645 : loss : 0.029772, loss_ce: 0.014758
2022-01-21 22:24:57,752 iteration 4646 : loss : 0.017293, loss_ce: 0.007301
2022-01-21 22:24:58,910 iteration 4647 : loss : 0.020030, loss_ce: 0.008468
2022-01-21 22:25:00,005 iteration 4648 : loss : 0.013915, loss_ce: 0.005462
2022-01-21 22:25:01,203 iteration 4649 : loss : 0.025683, loss_ce: 0.010855
2022-01-21 22:25:02,369 iteration 4650 : loss : 0.022369, loss_ce: 0.007651
2022-01-21 22:25:03,557 iteration 4651 : loss : 0.020596, loss_ce: 0.008148
2022-01-21 22:25:04,748 iteration 4652 : loss : 0.020047, loss_ce: 0.008161
2022-01-21 22:25:05,928 iteration 4653 : loss : 0.024196, loss_ce: 0.011367
2022-01-21 22:25:07,117 iteration 4654 : loss : 0.026959, loss_ce: 0.012249
2022-01-21 22:25:08,319 iteration 4655 : loss : 0.018854, loss_ce: 0.006437
2022-01-21 22:25:09,567 iteration 4656 : loss : 0.036441, loss_ce: 0.007576
2022-01-21 22:25:10,741 iteration 4657 : loss : 0.034399, loss_ce: 0.004135
2022-01-21 22:25:11,882 iteration 4658 : loss : 0.019502, loss_ce: 0.004403
 68%|███████████████████▊         | 274/400 [1:40:01<43:50, 20.87s/it]2022-01-21 22:25:13,099 iteration 4659 : loss : 0.023638, loss_ce: 0.010166
2022-01-21 22:25:14,317 iteration 4660 : loss : 0.020950, loss_ce: 0.005662
2022-01-21 22:25:15,501 iteration 4661 : loss : 0.021030, loss_ce: 0.011586
2022-01-21 22:25:16,788 iteration 4662 : loss : 0.028232, loss_ce: 0.014794
2022-01-21 22:25:17,919 iteration 4663 : loss : 0.027986, loss_ce: 0.007985
2022-01-21 22:25:19,112 iteration 4664 : loss : 0.023183, loss_ce: 0.007239
2022-01-21 22:25:20,438 iteration 4665 : loss : 0.025390, loss_ce: 0.009230
2022-01-21 22:25:21,575 iteration 4666 : loss : 0.018311, loss_ce: 0.007089
2022-01-21 22:25:22,747 iteration 4667 : loss : 0.020200, loss_ce: 0.009017
2022-01-21 22:25:23,913 iteration 4668 : loss : 0.022758, loss_ce: 0.005488
2022-01-21 22:25:25,155 iteration 4669 : loss : 0.018477, loss_ce: 0.007759
2022-01-21 22:25:26,408 iteration 4670 : loss : 0.020783, loss_ce: 0.008489
2022-01-21 22:25:27,527 iteration 4671 : loss : 0.016191, loss_ce: 0.004804
2022-01-21 22:25:28,825 iteration 4672 : loss : 0.053099, loss_ce: 0.027021
2022-01-21 22:25:30,051 iteration 4673 : loss : 0.024819, loss_ce: 0.008455
2022-01-21 22:25:31,313 iteration 4674 : loss : 0.024375, loss_ce: 0.013613
2022-01-21 22:25:31,313 Training Data Eval:
2022-01-21 22:25:36,986   Average segmentation loss on training set: 0.0143
2022-01-21 22:25:36,987 Validation Data Eval:
2022-01-21 22:25:38,958   Average segmentation loss on validation set: 0.0636
2022-01-21 22:25:40,112 iteration 4675 : loss : 0.020378, loss_ce: 0.008063
 69%|███████████████████▉         | 275/400 [1:40:30<48:05, 23.08s/it]2022-01-21 22:25:41,409 iteration 4676 : loss : 0.021908, loss_ce: 0.007270
2022-01-21 22:25:42,567 iteration 4677 : loss : 0.021875, loss_ce: 0.008757
2022-01-21 22:25:43,740 iteration 4678 : loss : 0.026866, loss_ce: 0.008317
2022-01-21 22:25:44,927 iteration 4679 : loss : 0.019242, loss_ce: 0.010225
2022-01-21 22:25:46,067 iteration 4680 : loss : 0.017989, loss_ce: 0.006160
2022-01-21 22:25:47,257 iteration 4681 : loss : 0.023574, loss_ce: 0.008286
2022-01-21 22:25:48,378 iteration 4682 : loss : 0.025324, loss_ce: 0.007170
2022-01-21 22:25:49,552 iteration 4683 : loss : 0.022289, loss_ce: 0.009627
2022-01-21 22:25:50,768 iteration 4684 : loss : 0.020385, loss_ce: 0.009606
2022-01-21 22:25:51,958 iteration 4685 : loss : 0.015844, loss_ce: 0.006995
2022-01-21 22:25:53,060 iteration 4686 : loss : 0.015354, loss_ce: 0.005120
2022-01-21 22:25:54,288 iteration 4687 : loss : 0.022219, loss_ce: 0.009781
2022-01-21 22:25:55,537 iteration 4688 : loss : 0.020192, loss_ce: 0.006347
2022-01-21 22:25:56,803 iteration 4689 : loss : 0.022749, loss_ce: 0.007881
2022-01-21 22:25:57,977 iteration 4690 : loss : 0.025380, loss_ce: 0.005776
2022-01-21 22:25:59,119 iteration 4691 : loss : 0.021788, loss_ce: 0.007986
2022-01-21 22:26:00,289 iteration 4692 : loss : 0.019002, loss_ce: 0.007952
 69%|████████████████████         | 276/400 [1:40:50<45:54, 22.21s/it]2022-01-21 22:26:01,533 iteration 4693 : loss : 0.017824, loss_ce: 0.006683
2022-01-21 22:26:02,686 iteration 4694 : loss : 0.018507, loss_ce: 0.005840
2022-01-21 22:26:03,932 iteration 4695 : loss : 0.021330, loss_ce: 0.007948
2022-01-21 22:26:05,136 iteration 4696 : loss : 0.033073, loss_ce: 0.013798
2022-01-21 22:26:06,374 iteration 4697 : loss : 0.022759, loss_ce: 0.009528
2022-01-21 22:26:07,464 iteration 4698 : loss : 0.015359, loss_ce: 0.005540
2022-01-21 22:26:08,641 iteration 4699 : loss : 0.021664, loss_ce: 0.007796
2022-01-21 22:26:09,831 iteration 4700 : loss : 0.026980, loss_ce: 0.008495
2022-01-21 22:26:11,021 iteration 4701 : loss : 0.023243, loss_ce: 0.009672
2022-01-21 22:26:12,128 iteration 4702 : loss : 0.020933, loss_ce: 0.007790
2022-01-21 22:26:13,340 iteration 4703 : loss : 0.020043, loss_ce: 0.007609
2022-01-21 22:26:14,527 iteration 4704 : loss : 0.034896, loss_ce: 0.008058
2022-01-21 22:26:15,653 iteration 4705 : loss : 0.015154, loss_ce: 0.005763
2022-01-21 22:26:16,800 iteration 4706 : loss : 0.021382, loss_ce: 0.008994
2022-01-21 22:26:18,044 iteration 4707 : loss : 0.031775, loss_ce: 0.015940
2022-01-21 22:26:19,217 iteration 4708 : loss : 0.031985, loss_ce: 0.007805
2022-01-21 22:26:20,378 iteration 4709 : loss : 0.024771, loss_ce: 0.008789
 69%|████████████████████         | 277/400 [1:41:10<44:13, 21.57s/it]2022-01-21 22:26:21,671 iteration 4710 : loss : 0.044058, loss_ce: 0.014130
2022-01-21 22:26:22,828 iteration 4711 : loss : 0.024136, loss_ce: 0.010229
2022-01-21 22:26:24,009 iteration 4712 : loss : 0.020180, loss_ce: 0.008486
2022-01-21 22:26:25,153 iteration 4713 : loss : 0.016559, loss_ce: 0.006059
2022-01-21 22:26:26,299 iteration 4714 : loss : 0.015703, loss_ce: 0.006571
2022-01-21 22:26:27,554 iteration 4715 : loss : 0.041378, loss_ce: 0.012315
2022-01-21 22:26:28,734 iteration 4716 : loss : 0.016312, loss_ce: 0.006384
2022-01-21 22:26:29,916 iteration 4717 : loss : 0.019682, loss_ce: 0.005470
2022-01-21 22:26:31,081 iteration 4718 : loss : 0.017472, loss_ce: 0.006123
2022-01-21 22:26:32,226 iteration 4719 : loss : 0.015532, loss_ce: 0.005602
2022-01-21 22:26:33,457 iteration 4720 : loss : 0.023621, loss_ce: 0.008923
2022-01-21 22:26:34,633 iteration 4721 : loss : 0.020027, loss_ce: 0.006309
2022-01-21 22:26:35,810 iteration 4722 : loss : 0.019502, loss_ce: 0.007161
2022-01-21 22:26:37,027 iteration 4723 : loss : 0.024785, loss_ce: 0.006157
2022-01-21 22:26:38,155 iteration 4724 : loss : 0.018407, loss_ce: 0.008628
2022-01-21 22:26:39,309 iteration 4725 : loss : 0.022180, loss_ce: 0.008820
2022-01-21 22:26:40,450 iteration 4726 : loss : 0.028141, loss_ce: 0.009996
 70%|████████████████████▏        | 278/400 [1:41:30<42:57, 21.12s/it]2022-01-21 22:26:41,675 iteration 4727 : loss : 0.023187, loss_ce: 0.007667
2022-01-21 22:26:42,871 iteration 4728 : loss : 0.027727, loss_ce: 0.010435
2022-01-21 22:26:44,083 iteration 4729 : loss : 0.013255, loss_ce: 0.004115
2022-01-21 22:26:45,273 iteration 4730 : loss : 0.021389, loss_ce: 0.007335
2022-01-21 22:26:46,453 iteration 4731 : loss : 0.031498, loss_ce: 0.008194
2022-01-21 22:26:47,578 iteration 4732 : loss : 0.019997, loss_ce: 0.008154
2022-01-21 22:26:48,851 iteration 4733 : loss : 0.030360, loss_ce: 0.013142
2022-01-21 22:26:50,035 iteration 4734 : loss : 0.019713, loss_ce: 0.007735
2022-01-21 22:26:51,157 iteration 4735 : loss : 0.016078, loss_ce: 0.006259
2022-01-21 22:26:52,392 iteration 4736 : loss : 0.025521, loss_ce: 0.011477
2022-01-21 22:26:53,596 iteration 4737 : loss : 0.032353, loss_ce: 0.016562
2022-01-21 22:26:54,905 iteration 4738 : loss : 0.039967, loss_ce: 0.011729
2022-01-21 22:26:56,122 iteration 4739 : loss : 0.015295, loss_ce: 0.006263
2022-01-21 22:26:57,320 iteration 4740 : loss : 0.016190, loss_ce: 0.004309
2022-01-21 22:26:58,505 iteration 4741 : loss : 0.020283, loss_ce: 0.009536
2022-01-21 22:26:59,715 iteration 4742 : loss : 0.024765, loss_ce: 0.011927
2022-01-21 22:27:01,062 iteration 4743 : loss : 0.033893, loss_ce: 0.015417
 70%|████████████████████▏        | 279/400 [1:41:50<42:17, 20.97s/it]2022-01-21 22:27:02,345 iteration 4744 : loss : 0.018341, loss_ce: 0.006398
2022-01-21 22:27:03,558 iteration 4745 : loss : 0.023010, loss_ce: 0.009532
2022-01-21 22:27:04,747 iteration 4746 : loss : 0.026908, loss_ce: 0.008886
2022-01-21 22:27:05,865 iteration 4747 : loss : 0.028510, loss_ce: 0.020081
2022-01-21 22:27:07,140 iteration 4748 : loss : 0.019624, loss_ce: 0.006696
2022-01-21 22:27:08,266 iteration 4749 : loss : 0.019872, loss_ce: 0.008191
2022-01-21 22:27:09,466 iteration 4750 : loss : 0.041166, loss_ce: 0.015384
2022-01-21 22:27:10,675 iteration 4751 : loss : 0.022684, loss_ce: 0.010288
2022-01-21 22:27:11,855 iteration 4752 : loss : 0.025539, loss_ce: 0.007149
2022-01-21 22:27:13,012 iteration 4753 : loss : 0.014132, loss_ce: 0.004875
2022-01-21 22:27:14,209 iteration 4754 : loss : 0.021176, loss_ce: 0.009678
2022-01-21 22:27:15,474 iteration 4755 : loss : 0.029902, loss_ce: 0.007832
2022-01-21 22:27:16,691 iteration 4756 : loss : 0.024945, loss_ce: 0.008678
2022-01-21 22:27:17,883 iteration 4757 : loss : 0.027411, loss_ce: 0.015142
2022-01-21 22:27:19,147 iteration 4758 : loss : 0.024191, loss_ce: 0.007803
2022-01-21 22:27:20,331 iteration 4759 : loss : 0.025908, loss_ce: 0.013839
2022-01-21 22:27:20,331 Training Data Eval:
2022-01-21 22:27:26,037   Average segmentation loss on training set: 0.0132
2022-01-21 22:27:26,037 Validation Data Eval:
2022-01-21 22:27:28,008   Average segmentation loss on validation set: 0.0617
2022-01-21 22:27:29,208 iteration 4760 : loss : 0.029744, loss_ce: 0.010176
 70%|████████████████████▎        | 280/400 [1:42:19<46:14, 23.12s/it]2022-01-21 22:27:30,375 iteration 4761 : loss : 0.019108, loss_ce: 0.006696
2022-01-21 22:27:31,644 iteration 4762 : loss : 0.026176, loss_ce: 0.008149
2022-01-21 22:27:32,849 iteration 4763 : loss : 0.020500, loss_ce: 0.008627
2022-01-21 22:27:33,977 iteration 4764 : loss : 0.024890, loss_ce: 0.009205
2022-01-21 22:27:35,135 iteration 4765 : loss : 0.021688, loss_ce: 0.009293
2022-01-21 22:27:36,275 iteration 4766 : loss : 0.025470, loss_ce: 0.008751
2022-01-21 22:27:37,502 iteration 4767 : loss : 0.031938, loss_ce: 0.012720
2022-01-21 22:27:38,776 iteration 4768 : loss : 0.026155, loss_ce: 0.011312
2022-01-21 22:27:40,034 iteration 4769 : loss : 0.038513, loss_ce: 0.010674
2022-01-21 22:27:41,228 iteration 4770 : loss : 0.017167, loss_ce: 0.008511
2022-01-21 22:27:42,386 iteration 4771 : loss : 0.020915, loss_ce: 0.009318
2022-01-21 22:27:43,559 iteration 4772 : loss : 0.013631, loss_ce: 0.004230
2022-01-21 22:27:44,714 iteration 4773 : loss : 0.020636, loss_ce: 0.009633
2022-01-21 22:27:45,862 iteration 4774 : loss : 0.014602, loss_ce: 0.005702
2022-01-21 22:27:47,057 iteration 4775 : loss : 0.028936, loss_ce: 0.011504
2022-01-21 22:27:48,234 iteration 4776 : loss : 0.021273, loss_ce: 0.008089
2022-01-21 22:27:49,408 iteration 4777 : loss : 0.018451, loss_ce: 0.006259
 70%|████████████████████▎        | 281/400 [1:42:39<44:07, 22.25s/it]2022-01-21 22:27:50,695 iteration 4778 : loss : 0.019731, loss_ce: 0.007143
2022-01-21 22:27:51,845 iteration 4779 : loss : 0.022497, loss_ce: 0.008337
2022-01-21 22:27:52,990 iteration 4780 : loss : 0.024780, loss_ce: 0.005767
2022-01-21 22:27:54,137 iteration 4781 : loss : 0.016377, loss_ce: 0.008197
2022-01-21 22:27:55,377 iteration 4782 : loss : 0.032193, loss_ce: 0.011849
2022-01-21 22:27:56,501 iteration 4783 : loss : 0.019271, loss_ce: 0.005526
2022-01-21 22:27:57,739 iteration 4784 : loss : 0.024612, loss_ce: 0.010828
2022-01-21 22:27:59,000 iteration 4785 : loss : 0.025316, loss_ce: 0.012310
2022-01-21 22:28:00,174 iteration 4786 : loss : 0.018664, loss_ce: 0.007407
2022-01-21 22:28:01,389 iteration 4787 : loss : 0.022978, loss_ce: 0.005327
2022-01-21 22:28:02,590 iteration 4788 : loss : 0.020800, loss_ce: 0.008518
2022-01-21 22:28:03,787 iteration 4789 : loss : 0.017497, loss_ce: 0.006696
2022-01-21 22:28:04,966 iteration 4790 : loss : 0.016792, loss_ce: 0.007196
2022-01-21 22:28:06,124 iteration 4791 : loss : 0.015402, loss_ce: 0.005985
2022-01-21 22:28:07,293 iteration 4792 : loss : 0.022422, loss_ce: 0.010275
2022-01-21 22:28:08,506 iteration 4793 : loss : 0.021087, loss_ce: 0.010972
2022-01-21 22:28:09,672 iteration 4794 : loss : 0.032330, loss_ce: 0.006047
 70%|████████████████████▍        | 282/400 [1:42:59<42:34, 21.65s/it]2022-01-21 22:28:10,835 iteration 4795 : loss : 0.016818, loss_ce: 0.005329
2022-01-21 22:28:11,960 iteration 4796 : loss : 0.017893, loss_ce: 0.006976
2022-01-21 22:28:13,098 iteration 4797 : loss : 0.018418, loss_ce: 0.006423
2022-01-21 22:28:14,336 iteration 4798 : loss : 0.040869, loss_ce: 0.017221
2022-01-21 22:28:15,520 iteration 4799 : loss : 0.031289, loss_ce: 0.006721
2022-01-21 22:28:16,713 iteration 4800 : loss : 0.039253, loss_ce: 0.017262
2022-01-21 22:28:17,901 iteration 4801 : loss : 0.016383, loss_ce: 0.006794
2022-01-21 22:28:18,990 iteration 4802 : loss : 0.016665, loss_ce: 0.005386
2022-01-21 22:28:20,177 iteration 4803 : loss : 0.020669, loss_ce: 0.009396
2022-01-21 22:28:21,330 iteration 4804 : loss : 0.020742, loss_ce: 0.005558
2022-01-21 22:28:22,533 iteration 4805 : loss : 0.021014, loss_ce: 0.007242
2022-01-21 22:28:23,674 iteration 4806 : loss : 0.019939, loss_ce: 0.005710
2022-01-21 22:28:24,935 iteration 4807 : loss : 0.026906, loss_ce: 0.009654
2022-01-21 22:28:26,318 iteration 4808 : loss : 0.027623, loss_ce: 0.010500
2022-01-21 22:28:27,426 iteration 4809 : loss : 0.017472, loss_ce: 0.007711
2022-01-21 22:28:28,650 iteration 4810 : loss : 0.019340, loss_ce: 0.007528
2022-01-21 22:28:29,816 iteration 4811 : loss : 0.016374, loss_ce: 0.006871
 71%|████████████████████▌        | 283/400 [1:43:19<41:20, 21.20s/it]2022-01-21 22:28:31,009 iteration 4812 : loss : 0.025398, loss_ce: 0.009313
2022-01-21 22:28:32,206 iteration 4813 : loss : 0.022806, loss_ce: 0.007931
2022-01-21 22:28:33,347 iteration 4814 : loss : 0.020504, loss_ce: 0.010170
2022-01-21 22:28:34,536 iteration 4815 : loss : 0.030396, loss_ce: 0.010964
2022-01-21 22:28:35,684 iteration 4816 : loss : 0.019404, loss_ce: 0.007314
2022-01-21 22:28:36,749 iteration 4817 : loss : 0.017486, loss_ce: 0.005860
2022-01-21 22:28:37,962 iteration 4818 : loss : 0.029366, loss_ce: 0.014577
2022-01-21 22:28:39,162 iteration 4819 : loss : 0.018598, loss_ce: 0.005945
2022-01-21 22:28:40,396 iteration 4820 : loss : 0.022060, loss_ce: 0.010010
2022-01-21 22:28:41,565 iteration 4821 : loss : 0.019405, loss_ce: 0.009330
2022-01-21 22:28:42,774 iteration 4822 : loss : 0.021891, loss_ce: 0.007516
2022-01-21 22:28:43,932 iteration 4823 : loss : 0.025545, loss_ce: 0.008799
2022-01-21 22:28:45,164 iteration 4824 : loss : 0.019580, loss_ce: 0.006585
2022-01-21 22:28:46,334 iteration 4825 : loss : 0.015008, loss_ce: 0.004743
2022-01-21 22:28:47,482 iteration 4826 : loss : 0.032801, loss_ce: 0.012123
2022-01-21 22:28:48,767 iteration 4827 : loss : 0.025676, loss_ce: 0.009767
2022-01-21 22:28:50,010 iteration 4828 : loss : 0.035038, loss_ce: 0.013533
 71%|████████████████████▌        | 284/400 [1:43:39<40:24, 20.90s/it]2022-01-21 22:28:51,264 iteration 4829 : loss : 0.021754, loss_ce: 0.007486
2022-01-21 22:28:52,390 iteration 4830 : loss : 0.018121, loss_ce: 0.005602
2022-01-21 22:28:53,656 iteration 4831 : loss : 0.039243, loss_ce: 0.013665
2022-01-21 22:28:54,832 iteration 4832 : loss : 0.019750, loss_ce: 0.008388
2022-01-21 22:28:56,073 iteration 4833 : loss : 0.031996, loss_ce: 0.012068
2022-01-21 22:28:57,352 iteration 4834 : loss : 0.017259, loss_ce: 0.006013
2022-01-21 22:28:58,526 iteration 4835 : loss : 0.023388, loss_ce: 0.008705
2022-01-21 22:28:59,713 iteration 4836 : loss : 0.024890, loss_ce: 0.007619
2022-01-21 22:29:00,854 iteration 4837 : loss : 0.022632, loss_ce: 0.004763
2022-01-21 22:29:02,071 iteration 4838 : loss : 0.025231, loss_ce: 0.011174
2022-01-21 22:29:03,285 iteration 4839 : loss : 0.021004, loss_ce: 0.010032
2022-01-21 22:29:04,478 iteration 4840 : loss : 0.024129, loss_ce: 0.009159
2022-01-21 22:29:05,735 iteration 4841 : loss : 0.015937, loss_ce: 0.005307
2022-01-21 22:29:06,948 iteration 4842 : loss : 0.019832, loss_ce: 0.008524
2022-01-21 22:29:08,152 iteration 4843 : loss : 0.022133, loss_ce: 0.009107
2022-01-21 22:29:09,273 iteration 4844 : loss : 0.015062, loss_ce: 0.006921
2022-01-21 22:29:09,273 Training Data Eval:
2022-01-21 22:29:14,937   Average segmentation loss on training set: 0.0132
2022-01-21 22:29:14,937 Validation Data Eval:
2022-01-21 22:29:16,904   Average segmentation loss on validation set: 0.0581
2022-01-21 22:29:18,047 iteration 4845 : loss : 0.023934, loss_ce: 0.007437
 71%|████████████████████▋        | 285/400 [1:44:07<44:09, 23.04s/it]2022-01-21 22:29:19,285 iteration 4846 : loss : 0.016908, loss_ce: 0.005854
2022-01-21 22:29:20,445 iteration 4847 : loss : 0.017956, loss_ce: 0.004730
2022-01-21 22:29:21,730 iteration 4848 : loss : 0.023897, loss_ce: 0.009710
2022-01-21 22:29:22,896 iteration 4849 : loss : 0.018838, loss_ce: 0.008067
2022-01-21 22:29:24,112 iteration 4850 : loss : 0.036402, loss_ce: 0.006066
2022-01-21 22:29:25,324 iteration 4851 : loss : 0.018482, loss_ce: 0.008019
2022-01-21 22:29:26,479 iteration 4852 : loss : 0.020213, loss_ce: 0.008144
2022-01-21 22:29:27,636 iteration 4853 : loss : 0.020477, loss_ce: 0.006869
2022-01-21 22:29:28,751 iteration 4854 : loss : 0.014343, loss_ce: 0.005390
2022-01-21 22:29:29,935 iteration 4855 : loss : 0.018950, loss_ce: 0.006330
2022-01-21 22:29:31,140 iteration 4856 : loss : 0.020780, loss_ce: 0.007593
2022-01-21 22:29:32,363 iteration 4857 : loss : 0.020721, loss_ce: 0.010309
2022-01-21 22:29:33,552 iteration 4858 : loss : 0.020255, loss_ce: 0.008375
2022-01-21 22:29:34,676 iteration 4859 : loss : 0.014594, loss_ce: 0.006249
2022-01-21 22:29:35,832 iteration 4860 : loss : 0.025469, loss_ce: 0.005802
2022-01-21 22:29:36,941 iteration 4861 : loss : 0.018338, loss_ce: 0.005998
2022-01-21 22:29:38,192 iteration 4862 : loss : 0.017911, loss_ce: 0.005502
 72%|████████████████████▋        | 286/400 [1:44:28<42:07, 22.17s/it]2022-01-21 22:29:39,443 iteration 4863 : loss : 0.022296, loss_ce: 0.006104
2022-01-21 22:29:40,654 iteration 4864 : loss : 0.032196, loss_ce: 0.009726
2022-01-21 22:29:41,852 iteration 4865 : loss : 0.020017, loss_ce: 0.007374
2022-01-21 22:29:43,046 iteration 4866 : loss : 0.028935, loss_ce: 0.011361
2022-01-21 22:29:44,261 iteration 4867 : loss : 0.054014, loss_ce: 0.016844
2022-01-21 22:29:45,454 iteration 4868 : loss : 0.018102, loss_ce: 0.008858
2022-01-21 22:29:46,604 iteration 4869 : loss : 0.026696, loss_ce: 0.008702
2022-01-21 22:29:47,688 iteration 4870 : loss : 0.016927, loss_ce: 0.006091
2022-01-21 22:29:48,834 iteration 4871 : loss : 0.020768, loss_ce: 0.006532
2022-01-21 22:29:50,011 iteration 4872 : loss : 0.015326, loss_ce: 0.006700
2022-01-21 22:29:51,187 iteration 4873 : loss : 0.021595, loss_ce: 0.007636
2022-01-21 22:29:52,369 iteration 4874 : loss : 0.019449, loss_ce: 0.006491
2022-01-21 22:29:53,520 iteration 4875 : loss : 0.022096, loss_ce: 0.005892
2022-01-21 22:29:54,619 iteration 4876 : loss : 0.016216, loss_ce: 0.006910
2022-01-21 22:29:55,769 iteration 4877 : loss : 0.014113, loss_ce: 0.004783
2022-01-21 22:29:56,953 iteration 4878 : loss : 0.028604, loss_ce: 0.010169
2022-01-21 22:29:58,176 iteration 4879 : loss : 0.017760, loss_ce: 0.005341
 72%|████████████████████▊        | 287/400 [1:44:48<40:31, 21.52s/it]2022-01-21 22:29:59,436 iteration 4880 : loss : 0.021234, loss_ce: 0.007436
2022-01-21 22:30:00,554 iteration 4881 : loss : 0.013817, loss_ce: 0.004606
2022-01-21 22:30:01,670 iteration 4882 : loss : 0.014990, loss_ce: 0.003479
2022-01-21 22:30:02,871 iteration 4883 : loss : 0.018914, loss_ce: 0.007598
2022-01-21 22:30:04,007 iteration 4884 : loss : 0.020660, loss_ce: 0.009087
2022-01-21 22:30:05,184 iteration 4885 : loss : 0.026387, loss_ce: 0.007997
2022-01-21 22:30:06,391 iteration 4886 : loss : 0.019031, loss_ce: 0.006405
2022-01-21 22:30:07,546 iteration 4887 : loss : 0.022868, loss_ce: 0.009673
2022-01-21 22:30:08,735 iteration 4888 : loss : 0.022990, loss_ce: 0.005928
2022-01-21 22:30:09,894 iteration 4889 : loss : 0.018596, loss_ce: 0.007941
2022-01-21 22:30:11,084 iteration 4890 : loss : 0.024407, loss_ce: 0.009677
2022-01-21 22:30:12,274 iteration 4891 : loss : 0.030762, loss_ce: 0.014661
2022-01-21 22:30:13,459 iteration 4892 : loss : 0.018958, loss_ce: 0.008734
2022-01-21 22:30:14,798 iteration 4893 : loss : 0.024321, loss_ce: 0.007664
2022-01-21 22:30:15,979 iteration 4894 : loss : 0.023105, loss_ce: 0.010545
2022-01-21 22:30:17,151 iteration 4895 : loss : 0.022243, loss_ce: 0.010610
2022-01-21 22:30:18,310 iteration 4896 : loss : 0.020947, loss_ce: 0.007441
 72%|████████████████████▉        | 288/400 [1:45:08<39:23, 21.10s/it]2022-01-21 22:30:19,478 iteration 4897 : loss : 0.018165, loss_ce: 0.008779
2022-01-21 22:30:20,642 iteration 4898 : loss : 0.015141, loss_ce: 0.005452
2022-01-21 22:30:21,766 iteration 4899 : loss : 0.024232, loss_ce: 0.011869
2022-01-21 22:30:23,005 iteration 4900 : loss : 0.038036, loss_ce: 0.015064
2022-01-21 22:30:24,193 iteration 4901 : loss : 0.016187, loss_ce: 0.005144
2022-01-21 22:30:25,336 iteration 4902 : loss : 0.018231, loss_ce: 0.004224
2022-01-21 22:30:26,522 iteration 4903 : loss : 0.037181, loss_ce: 0.018145
2022-01-21 22:30:27,696 iteration 4904 : loss : 0.028369, loss_ce: 0.013697
2022-01-21 22:30:28,856 iteration 4905 : loss : 0.018341, loss_ce: 0.008074
2022-01-21 22:30:30,012 iteration 4906 : loss : 0.018905, loss_ce: 0.006694
2022-01-21 22:30:31,188 iteration 4907 : loss : 0.018662, loss_ce: 0.006744
2022-01-21 22:30:32,271 iteration 4908 : loss : 0.021052, loss_ce: 0.005644
2022-01-21 22:30:33,442 iteration 4909 : loss : 0.020396, loss_ce: 0.005925
2022-01-21 22:30:34,593 iteration 4910 : loss : 0.021677, loss_ce: 0.004685
2022-01-21 22:30:35,849 iteration 4911 : loss : 0.021632, loss_ce: 0.008789
2022-01-21 22:30:37,084 iteration 4912 : loss : 0.027694, loss_ce: 0.008495
2022-01-21 22:30:38,234 iteration 4913 : loss : 0.020668, loss_ce: 0.007107
 72%|████████████████████▉        | 289/400 [1:45:28<38:23, 20.75s/it]2022-01-21 22:30:39,401 iteration 4914 : loss : 0.019678, loss_ce: 0.006331
2022-01-21 22:30:40,610 iteration 4915 : loss : 0.020955, loss_ce: 0.007911
2022-01-21 22:30:41,807 iteration 4916 : loss : 0.021280, loss_ce: 0.006362
2022-01-21 22:30:42,985 iteration 4917 : loss : 0.019810, loss_ce: 0.008022
2022-01-21 22:30:44,127 iteration 4918 : loss : 0.017555, loss_ce: 0.007926
2022-01-21 22:30:45,259 iteration 4919 : loss : 0.018375, loss_ce: 0.007330
2022-01-21 22:30:46,457 iteration 4920 : loss : 0.020350, loss_ce: 0.009378
2022-01-21 22:30:47,620 iteration 4921 : loss : 0.014742, loss_ce: 0.003095
2022-01-21 22:30:48,785 iteration 4922 : loss : 0.019206, loss_ce: 0.003523
2022-01-21 22:30:49,962 iteration 4923 : loss : 0.026269, loss_ce: 0.009194
2022-01-21 22:30:51,161 iteration 4924 : loss : 0.026688, loss_ce: 0.008806
2022-01-21 22:30:52,462 iteration 4925 : loss : 0.028685, loss_ce: 0.013081
2022-01-21 22:30:53,622 iteration 4926 : loss : 0.023355, loss_ce: 0.007782
2022-01-21 22:30:54,863 iteration 4927 : loss : 0.019379, loss_ce: 0.007249
2022-01-21 22:30:56,112 iteration 4928 : loss : 0.025027, loss_ce: 0.011496
2022-01-21 22:30:57,345 iteration 4929 : loss : 0.027543, loss_ce: 0.009849
2022-01-21 22:30:57,345 Training Data Eval:
2022-01-21 22:31:03,008   Average segmentation loss on training set: 0.0120
2022-01-21 22:31:03,009 Validation Data Eval:
2022-01-21 22:31:04,977   Average segmentation loss on validation set: 0.0624
2022-01-21 22:31:06,163 iteration 4930 : loss : 0.015344, loss_ce: 0.006542
 72%|█████████████████████        | 290/400 [1:45:56<41:59, 22.91s/it]2022-01-21 22:31:07,444 iteration 4931 : loss : 0.020286, loss_ce: 0.009256
2022-01-21 22:31:08,591 iteration 4932 : loss : 0.014082, loss_ce: 0.005319
2022-01-21 22:31:09,732 iteration 4933 : loss : 0.020173, loss_ce: 0.006883
2022-01-21 22:31:10,917 iteration 4934 : loss : 0.018064, loss_ce: 0.008188
2022-01-21 22:31:12,129 iteration 4935 : loss : 0.025467, loss_ce: 0.007765
2022-01-21 22:31:13,317 iteration 4936 : loss : 0.013617, loss_ce: 0.005567
2022-01-21 22:31:14,521 iteration 4937 : loss : 0.019067, loss_ce: 0.007015
2022-01-21 22:31:15,700 iteration 4938 : loss : 0.024940, loss_ce: 0.009380
2022-01-21 22:31:16,949 iteration 4939 : loss : 0.034988, loss_ce: 0.013462
2022-01-21 22:31:18,089 iteration 4940 : loss : 0.019967, loss_ce: 0.005230
2022-01-21 22:31:19,261 iteration 4941 : loss : 0.016805, loss_ce: 0.006014
2022-01-21 22:31:20,480 iteration 4942 : loss : 0.019193, loss_ce: 0.007590
2022-01-21 22:31:21,627 iteration 4943 : loss : 0.013419, loss_ce: 0.004230
2022-01-21 22:31:22,802 iteration 4944 : loss : 0.025352, loss_ce: 0.011162
2022-01-21 22:31:24,064 iteration 4945 : loss : 0.021152, loss_ce: 0.005650
2022-01-21 22:31:25,302 iteration 4946 : loss : 0.047693, loss_ce: 0.020003
2022-01-21 22:31:26,584 iteration 4947 : loss : 0.028012, loss_ce: 0.010325
 73%|█████████████████████        | 291/400 [1:46:16<40:15, 22.16s/it]2022-01-21 22:31:27,879 iteration 4948 : loss : 0.027996, loss_ce: 0.011089
2022-01-21 22:31:29,042 iteration 4949 : loss : 0.015594, loss_ce: 0.005916
2022-01-21 22:31:30,185 iteration 4950 : loss : 0.020148, loss_ce: 0.007089
2022-01-21 22:31:31,351 iteration 4951 : loss : 0.019031, loss_ce: 0.007028
2022-01-21 22:31:32,458 iteration 4952 : loss : 0.022778, loss_ce: 0.009276
2022-01-21 22:31:33,674 iteration 4953 : loss : 0.021427, loss_ce: 0.008128
2022-01-21 22:31:34,801 iteration 4954 : loss : 0.021463, loss_ce: 0.007841
2022-01-21 22:31:35,958 iteration 4955 : loss : 0.014488, loss_ce: 0.005465
2022-01-21 22:31:37,122 iteration 4956 : loss : 0.019028, loss_ce: 0.007204
2022-01-21 22:31:38,288 iteration 4957 : loss : 0.027602, loss_ce: 0.012449
2022-01-21 22:31:39,469 iteration 4958 : loss : 0.026702, loss_ce: 0.013628
2022-01-21 22:31:40,567 iteration 4959 : loss : 0.014412, loss_ce: 0.004533
2022-01-21 22:31:41,742 iteration 4960 : loss : 0.018736, loss_ce: 0.006737
2022-01-21 22:31:42,875 iteration 4961 : loss : 0.016844, loss_ce: 0.006175
2022-01-21 22:31:44,089 iteration 4962 : loss : 0.024572, loss_ce: 0.011172
2022-01-21 22:31:45,220 iteration 4963 : loss : 0.017447, loss_ce: 0.006852
2022-01-21 22:31:46,479 iteration 4964 : loss : 0.028759, loss_ce: 0.010607
 73%|█████████████████████▏       | 292/400 [1:46:36<38:39, 21.48s/it]2022-01-21 22:31:47,778 iteration 4965 : loss : 0.035784, loss_ce: 0.015552
2022-01-21 22:31:49,077 iteration 4966 : loss : 0.024876, loss_ce: 0.009866
2022-01-21 22:31:50,212 iteration 4967 : loss : 0.013928, loss_ce: 0.005761
2022-01-21 22:31:51,398 iteration 4968 : loss : 0.020039, loss_ce: 0.008246
2022-01-21 22:31:52,554 iteration 4969 : loss : 0.027090, loss_ce: 0.005660
2022-01-21 22:31:53,690 iteration 4970 : loss : 0.012258, loss_ce: 0.004450
2022-01-21 22:31:54,911 iteration 4971 : loss : 0.022282, loss_ce: 0.009005
2022-01-21 22:31:56,156 iteration 4972 : loss : 0.019696, loss_ce: 0.006270
2022-01-21 22:31:57,317 iteration 4973 : loss : 0.016886, loss_ce: 0.006301
2022-01-21 22:31:58,470 iteration 4974 : loss : 0.018225, loss_ce: 0.007621
2022-01-21 22:31:59,628 iteration 4975 : loss : 0.019504, loss_ce: 0.006637
2022-01-21 22:32:00,782 iteration 4976 : loss : 0.027302, loss_ce: 0.011140
2022-01-21 22:32:02,053 iteration 4977 : loss : 0.020811, loss_ce: 0.010530
2022-01-21 22:32:03,229 iteration 4978 : loss : 0.057340, loss_ce: 0.016209
2022-01-21 22:32:04,418 iteration 4979 : loss : 0.022664, loss_ce: 0.011833
2022-01-21 22:32:05,515 iteration 4980 : loss : 0.013395, loss_ce: 0.005065
2022-01-21 22:32:06,689 iteration 4981 : loss : 0.021968, loss_ce: 0.007388
 73%|█████████████████████▏       | 293/400 [1:46:56<37:37, 21.10s/it]2022-01-21 22:32:07,913 iteration 4982 : loss : 0.019538, loss_ce: 0.009255
2022-01-21 22:32:09,066 iteration 4983 : loss : 0.020096, loss_ce: 0.007986
2022-01-21 22:32:10,303 iteration 4984 : loss : 0.025042, loss_ce: 0.009829
2022-01-21 22:32:11,500 iteration 4985 : loss : 0.016328, loss_ce: 0.005172
2022-01-21 22:32:12,766 iteration 4986 : loss : 0.024522, loss_ce: 0.010021
2022-01-21 22:32:13,927 iteration 4987 : loss : 0.016656, loss_ce: 0.007206
2022-01-21 22:32:15,093 iteration 4988 : loss : 0.016986, loss_ce: 0.007711
2022-01-21 22:32:16,254 iteration 4989 : loss : 0.019443, loss_ce: 0.006543
2022-01-21 22:32:17,520 iteration 4990 : loss : 0.017333, loss_ce: 0.006311
2022-01-21 22:32:18,706 iteration 4991 : loss : 0.018197, loss_ce: 0.004821
2022-01-21 22:32:19,885 iteration 4992 : loss : 0.015668, loss_ce: 0.006986
2022-01-21 22:32:21,127 iteration 4993 : loss : 0.021107, loss_ce: 0.009186
2022-01-21 22:32:22,399 iteration 4994 : loss : 0.026562, loss_ce: 0.006441
2022-01-21 22:32:23,587 iteration 4995 : loss : 0.022320, loss_ce: 0.008170
2022-01-21 22:32:24,771 iteration 4996 : loss : 0.020380, loss_ce: 0.007405
2022-01-21 22:32:26,029 iteration 4997 : loss : 0.021676, loss_ce: 0.007915
2022-01-21 22:32:27,163 iteration 4998 : loss : 0.015979, loss_ce: 0.005641
 74%|█████████████████████▎       | 294/400 [1:47:17<36:56, 20.91s/it]2022-01-21 22:32:28,444 iteration 4999 : loss : 0.027413, loss_ce: 0.010424
2022-01-21 22:32:29,566 iteration 5000 : loss : 0.017427, loss_ce: 0.007059
2022-01-21 22:32:30,722 iteration 5001 : loss : 0.028153, loss_ce: 0.011708
2022-01-21 22:32:31,929 iteration 5002 : loss : 0.021040, loss_ce: 0.008528
2022-01-21 22:32:33,080 iteration 5003 : loss : 0.027675, loss_ce: 0.008230
2022-01-21 22:32:34,331 iteration 5004 : loss : 0.023134, loss_ce: 0.007821
2022-01-21 22:32:35,481 iteration 5005 : loss : 0.019382, loss_ce: 0.006692
2022-01-21 22:32:36,696 iteration 5006 : loss : 0.023105, loss_ce: 0.006375
2022-01-21 22:32:37,852 iteration 5007 : loss : 0.017054, loss_ce: 0.006742
2022-01-21 22:32:38,973 iteration 5008 : loss : 0.018586, loss_ce: 0.006182
2022-01-21 22:32:40,145 iteration 5009 : loss : 0.020853, loss_ce: 0.006935
2022-01-21 22:32:41,433 iteration 5010 : loss : 0.029919, loss_ce: 0.010599
2022-01-21 22:32:42,626 iteration 5011 : loss : 0.020172, loss_ce: 0.011291
2022-01-21 22:32:43,868 iteration 5012 : loss : 0.024904, loss_ce: 0.012051
2022-01-21 22:32:45,211 iteration 5013 : loss : 0.021550, loss_ce: 0.008834
2022-01-21 22:32:46,313 iteration 5014 : loss : 0.016273, loss_ce: 0.005971
2022-01-21 22:32:46,313 Training Data Eval:
2022-01-21 22:32:52,019   Average segmentation loss on training set: 0.0116
2022-01-21 22:32:52,020 Validation Data Eval:
2022-01-21 22:32:53,997   Average segmentation loss on validation set: 0.0575
2022-01-21 22:32:55,159 iteration 5015 : loss : 0.015654, loss_ce: 0.003732
 74%|█████████████████████▍       | 295/400 [1:47:45<40:18, 23.03s/it]2022-01-21 22:32:56,347 iteration 5016 : loss : 0.021297, loss_ce: 0.007937
2022-01-21 22:32:57,499 iteration 5017 : loss : 0.015942, loss_ce: 0.004756
2022-01-21 22:32:58,827 iteration 5018 : loss : 0.020313, loss_ce: 0.006777
2022-01-21 22:32:59,972 iteration 5019 : loss : 0.032039, loss_ce: 0.010915
2022-01-21 22:33:01,179 iteration 5020 : loss : 0.015629, loss_ce: 0.007096
2022-01-21 22:33:02,439 iteration 5021 : loss : 0.022048, loss_ce: 0.007465
2022-01-21 22:33:03,675 iteration 5022 : loss : 0.023544, loss_ce: 0.010165
2022-01-21 22:33:04,886 iteration 5023 : loss : 0.013691, loss_ce: 0.005615
2022-01-21 22:33:06,044 iteration 5024 : loss : 0.013728, loss_ce: 0.004891
2022-01-21 22:33:07,188 iteration 5025 : loss : 0.014512, loss_ce: 0.005573
2022-01-21 22:33:08,377 iteration 5026 : loss : 0.022964, loss_ce: 0.009244
2022-01-21 22:33:09,554 iteration 5027 : loss : 0.015224, loss_ce: 0.005091
2022-01-21 22:33:10,753 iteration 5028 : loss : 0.018400, loss_ce: 0.007045
2022-01-21 22:33:11,895 iteration 5029 : loss : 0.015484, loss_ce: 0.006207
2022-01-21 22:33:13,097 iteration 5030 : loss : 0.025427, loss_ce: 0.008729
2022-01-21 22:33:14,356 iteration 5031 : loss : 0.020921, loss_ce: 0.008942
2022-01-21 22:33:15,611 iteration 5032 : loss : 0.027597, loss_ce: 0.010113
 74%|█████████████████████▍       | 296/400 [1:48:05<38:35, 22.26s/it]2022-01-21 22:33:16,872 iteration 5033 : loss : 0.025046, loss_ce: 0.013590
2022-01-21 22:33:18,054 iteration 5034 : loss : 0.023862, loss_ce: 0.006593
2022-01-21 22:33:19,219 iteration 5035 : loss : 0.020736, loss_ce: 0.008351
2022-01-21 22:33:20,340 iteration 5036 : loss : 0.014724, loss_ce: 0.005167
2022-01-21 22:33:21,489 iteration 5037 : loss : 0.015529, loss_ce: 0.006206
2022-01-21 22:33:22,794 iteration 5038 : loss : 0.036119, loss_ce: 0.019480
2022-01-21 22:33:23,955 iteration 5039 : loss : 0.015582, loss_ce: 0.004816
2022-01-21 22:33:25,176 iteration 5040 : loss : 0.020804, loss_ce: 0.009623
2022-01-21 22:33:26,359 iteration 5041 : loss : 0.018786, loss_ce: 0.006917
2022-01-21 22:33:27,534 iteration 5042 : loss : 0.013172, loss_ce: 0.005236
2022-01-21 22:33:28,680 iteration 5043 : loss : 0.017375, loss_ce: 0.005940
2022-01-21 22:33:29,868 iteration 5044 : loss : 0.013969, loss_ce: 0.004630
2022-01-21 22:33:30,960 iteration 5045 : loss : 0.013739, loss_ce: 0.004209
2022-01-21 22:33:32,149 iteration 5046 : loss : 0.022738, loss_ce: 0.008748
2022-01-21 22:33:33,297 iteration 5047 : loss : 0.019262, loss_ce: 0.007534
2022-01-21 22:33:34,424 iteration 5048 : loss : 0.017079, loss_ce: 0.006446
2022-01-21 22:33:35,672 iteration 5049 : loss : 0.029809, loss_ce: 0.012516
 74%|█████████████████████▌       | 297/400 [1:48:25<37:04, 21.60s/it]2022-01-21 22:33:36,895 iteration 5050 : loss : 0.026280, loss_ce: 0.007199
2022-01-21 22:33:38,024 iteration 5051 : loss : 0.017820, loss_ce: 0.007859
2022-01-21 22:33:39,235 iteration 5052 : loss : 0.017127, loss_ce: 0.007994
2022-01-21 22:33:40,359 iteration 5053 : loss : 0.016819, loss_ce: 0.006420
2022-01-21 22:33:41,557 iteration 5054 : loss : 0.017245, loss_ce: 0.007447
2022-01-21 22:33:42,701 iteration 5055 : loss : 0.018375, loss_ce: 0.007308
2022-01-21 22:33:43,853 iteration 5056 : loss : 0.036384, loss_ce: 0.012533
2022-01-21 22:33:45,019 iteration 5057 : loss : 0.018494, loss_ce: 0.008278
2022-01-21 22:33:46,167 iteration 5058 : loss : 0.020051, loss_ce: 0.006882
2022-01-21 22:33:47,346 iteration 5059 : loss : 0.019319, loss_ce: 0.009138
2022-01-21 22:33:48,581 iteration 5060 : loss : 0.033218, loss_ce: 0.007144
2022-01-21 22:33:49,768 iteration 5061 : loss : 0.018779, loss_ce: 0.009706
2022-01-21 22:33:51,004 iteration 5062 : loss : 0.020397, loss_ce: 0.007171
2022-01-21 22:33:52,152 iteration 5063 : loss : 0.018503, loss_ce: 0.007064
2022-01-21 22:33:53,343 iteration 5064 : loss : 0.021699, loss_ce: 0.005764
2022-01-21 22:33:54,589 iteration 5065 : loss : 0.035688, loss_ce: 0.010714
2022-01-21 22:33:55,665 iteration 5066 : loss : 0.016720, loss_ce: 0.007241
 74%|█████████████████████▌       | 298/400 [1:48:45<35:53, 21.12s/it]2022-01-21 22:33:57,003 iteration 5067 : loss : 0.018922, loss_ce: 0.006446
2022-01-21 22:33:58,169 iteration 5068 : loss : 0.014754, loss_ce: 0.004786
2022-01-21 22:33:59,315 iteration 5069 : loss : 0.021542, loss_ce: 0.007605
2022-01-21 22:34:00,480 iteration 5070 : loss : 0.017396, loss_ce: 0.009070
2022-01-21 22:34:01,710 iteration 5071 : loss : 0.021378, loss_ce: 0.010330
2022-01-21 22:34:02,917 iteration 5072 : loss : 0.022832, loss_ce: 0.007897
2022-01-21 22:34:04,150 iteration 5073 : loss : 0.025644, loss_ce: 0.005787
2022-01-21 22:34:05,368 iteration 5074 : loss : 0.019978, loss_ce: 0.008341
2022-01-21 22:34:06,484 iteration 5075 : loss : 0.019160, loss_ce: 0.008602
2022-01-21 22:34:07,597 iteration 5076 : loss : 0.021507, loss_ce: 0.009242
2022-01-21 22:34:08,827 iteration 5077 : loss : 0.024722, loss_ce: 0.008803
2022-01-21 22:34:10,019 iteration 5078 : loss : 0.019190, loss_ce: 0.006498
2022-01-21 22:34:11,183 iteration 5079 : loss : 0.012598, loss_ce: 0.004387
2022-01-21 22:34:12,386 iteration 5080 : loss : 0.015012, loss_ce: 0.005852
2022-01-21 22:34:13,593 iteration 5081 : loss : 0.037924, loss_ce: 0.021942
2022-01-21 22:34:14,748 iteration 5082 : loss : 0.019617, loss_ce: 0.005175
2022-01-21 22:34:15,897 iteration 5083 : loss : 0.026916, loss_ce: 0.010207
 75%|█████████████████████▋       | 299/400 [1:49:05<35:06, 20.85s/it]2022-01-21 22:34:17,149 iteration 5084 : loss : 0.019041, loss_ce: 0.008080
2022-01-21 22:34:18,421 iteration 5085 : loss : 0.024037, loss_ce: 0.008672
2022-01-21 22:34:19,534 iteration 5086 : loss : 0.015197, loss_ce: 0.005012
2022-01-21 22:34:20,730 iteration 5087 : loss : 0.017394, loss_ce: 0.004262
2022-01-21 22:34:21,851 iteration 5088 : loss : 0.013457, loss_ce: 0.006409
2022-01-21 22:34:23,014 iteration 5089 : loss : 0.019381, loss_ce: 0.007463
2022-01-21 22:34:24,218 iteration 5090 : loss : 0.024464, loss_ce: 0.011422
2022-01-21 22:34:25,432 iteration 5091 : loss : 0.028357, loss_ce: 0.009512
2022-01-21 22:34:26,601 iteration 5092 : loss : 0.020992, loss_ce: 0.004744
2022-01-21 22:34:27,784 iteration 5093 : loss : 0.020467, loss_ce: 0.007026
2022-01-21 22:34:28,982 iteration 5094 : loss : 0.017220, loss_ce: 0.005265
2022-01-21 22:34:30,185 iteration 5095 : loss : 0.016498, loss_ce: 0.007013
2022-01-21 22:34:31,440 iteration 5096 : loss : 0.021344, loss_ce: 0.005692
2022-01-21 22:34:32,673 iteration 5097 : loss : 0.022567, loss_ce: 0.013059
2022-01-21 22:34:33,853 iteration 5098 : loss : 0.020486, loss_ce: 0.008852
2022-01-21 22:34:35,070 iteration 5099 : loss : 0.018708, loss_ce: 0.007162
2022-01-21 22:34:35,070 Training Data Eval:
2022-01-21 22:34:40,767   Average segmentation loss on training set: 0.0119
2022-01-21 22:34:40,768 Validation Data Eval:
2022-01-21 22:34:42,736   Average segmentation loss on validation set: 0.0635
2022-01-21 22:34:43,890 iteration 5100 : loss : 0.018581, loss_ce: 0.005999
 75%|█████████████████████▊       | 300/400 [1:49:33<38:19, 23.00s/it]2022-01-21 22:34:45,159 iteration 5101 : loss : 0.024251, loss_ce: 0.005485
2022-01-21 22:34:46,406 iteration 5102 : loss : 0.025215, loss_ce: 0.010978
2022-01-21 22:34:47,552 iteration 5103 : loss : 0.022423, loss_ce: 0.008563
2022-01-21 22:34:48,730 iteration 5104 : loss : 0.055857, loss_ce: 0.013828
2022-01-21 22:34:49,889 iteration 5105 : loss : 0.016193, loss_ce: 0.005200
2022-01-21 22:34:51,067 iteration 5106 : loss : 0.031417, loss_ce: 0.012797
2022-01-21 22:34:52,264 iteration 5107 : loss : 0.020016, loss_ce: 0.007682
2022-01-21 22:34:53,470 iteration 5108 : loss : 0.021891, loss_ce: 0.009029
2022-01-21 22:34:54,653 iteration 5109 : loss : 0.017252, loss_ce: 0.006481
2022-01-21 22:34:55,745 iteration 5110 : loss : 0.016328, loss_ce: 0.005990
2022-01-21 22:34:56,948 iteration 5111 : loss : 0.024223, loss_ce: 0.006711
2022-01-21 22:34:58,076 iteration 5112 : loss : 0.013570, loss_ce: 0.005709
2022-01-21 22:34:59,328 iteration 5113 : loss : 0.021266, loss_ce: 0.007732
2022-01-21 22:35:00,463 iteration 5114 : loss : 0.013108, loss_ce: 0.005090
2022-01-21 22:35:01,613 iteration 5115 : loss : 0.018210, loss_ce: 0.009729
2022-01-21 22:35:02,802 iteration 5116 : loss : 0.018889, loss_ce: 0.007172
2022-01-21 22:35:03,994 iteration 5117 : loss : 0.018368, loss_ce: 0.006137
 75%|█████████████████████▊       | 301/400 [1:49:53<36:30, 22.13s/it]2022-01-21 22:35:05,249 iteration 5118 : loss : 0.017270, loss_ce: 0.007294
2022-01-21 22:35:06,435 iteration 5119 : loss : 0.023863, loss_ce: 0.009012
2022-01-21 22:35:07,706 iteration 5120 : loss : 0.013535, loss_ce: 0.003484
2022-01-21 22:35:08,850 iteration 5121 : loss : 0.017148, loss_ce: 0.006604
2022-01-21 22:35:10,004 iteration 5122 : loss : 0.021672, loss_ce: 0.006581
2022-01-21 22:35:11,181 iteration 5123 : loss : 0.018487, loss_ce: 0.009591
2022-01-21 22:35:12,323 iteration 5124 : loss : 0.019344, loss_ce: 0.004152
2022-01-21 22:35:13,514 iteration 5125 : loss : 0.018536, loss_ce: 0.007238
2022-01-21 22:35:14,667 iteration 5126 : loss : 0.016136, loss_ce: 0.006101
2022-01-21 22:35:15,869 iteration 5127 : loss : 0.024731, loss_ce: 0.008487
2022-01-21 22:35:17,154 iteration 5128 : loss : 0.021931, loss_ce: 0.007588
2022-01-21 22:35:18,407 iteration 5129 : loss : 0.024162, loss_ce: 0.008785
2022-01-21 22:35:19,526 iteration 5130 : loss : 0.014658, loss_ce: 0.005509
2022-01-21 22:35:20,739 iteration 5131 : loss : 0.016954, loss_ce: 0.004676
2022-01-21 22:35:21,938 iteration 5132 : loss : 0.020199, loss_ce: 0.009823
2022-01-21 22:35:23,075 iteration 5133 : loss : 0.017525, loss_ce: 0.007044
2022-01-21 22:35:24,200 iteration 5134 : loss : 0.018413, loss_ce: 0.008204
 76%|█████████████████████▉       | 302/400 [1:50:14<35:12, 21.55s/it]2022-01-21 22:35:25,435 iteration 5135 : loss : 0.018124, loss_ce: 0.006943
2022-01-21 22:35:26,694 iteration 5136 : loss : 0.016786, loss_ce: 0.006225
2022-01-21 22:35:27,955 iteration 5137 : loss : 0.021862, loss_ce: 0.006984
2022-01-21 22:35:29,225 iteration 5138 : loss : 0.021423, loss_ce: 0.010048
2022-01-21 22:35:30,349 iteration 5139 : loss : 0.012115, loss_ce: 0.003775
2022-01-21 22:35:31,589 iteration 5140 : loss : 0.031801, loss_ce: 0.015419
2022-01-21 22:35:32,711 iteration 5141 : loss : 0.015270, loss_ce: 0.007672
2022-01-21 22:35:33,986 iteration 5142 : loss : 0.029155, loss_ce: 0.011675
2022-01-21 22:35:35,113 iteration 5143 : loss : 0.013660, loss_ce: 0.005098
2022-01-21 22:35:36,230 iteration 5144 : loss : 0.014541, loss_ce: 0.006296
2022-01-21 22:35:37,439 iteration 5145 : loss : 0.023380, loss_ce: 0.008758
2022-01-21 22:35:38,752 iteration 5146 : loss : 0.028706, loss_ce: 0.007229
2022-01-21 22:35:39,953 iteration 5147 : loss : 0.016866, loss_ce: 0.007621
2022-01-21 22:35:41,164 iteration 5148 : loss : 0.019319, loss_ce: 0.006565
2022-01-21 22:35:42,317 iteration 5149 : loss : 0.016144, loss_ce: 0.005708
2022-01-21 22:35:43,473 iteration 5150 : loss : 0.017479, loss_ce: 0.006795
2022-01-21 22:35:44,592 iteration 5151 : loss : 0.016943, loss_ce: 0.005913
 76%|█████████████████████▉       | 303/400 [1:50:34<34:16, 21.20s/it]2022-01-21 22:35:45,868 iteration 5152 : loss : 0.024928, loss_ce: 0.006180
2022-01-21 22:35:46,994 iteration 5153 : loss : 0.013132, loss_ce: 0.005944
2022-01-21 22:35:48,220 iteration 5154 : loss : 0.023446, loss_ce: 0.009009
2022-01-21 22:35:49,345 iteration 5155 : loss : 0.011144, loss_ce: 0.003895
2022-01-21 22:35:50,502 iteration 5156 : loss : 0.018626, loss_ce: 0.007497
2022-01-21 22:35:51,740 iteration 5157 : loss : 0.016814, loss_ce: 0.006534
2022-01-21 22:35:52,946 iteration 5158 : loss : 0.017252, loss_ce: 0.006135
2022-01-21 22:35:54,181 iteration 5159 : loss : 0.033213, loss_ce: 0.009901
2022-01-21 22:35:55,423 iteration 5160 : loss : 0.017344, loss_ce: 0.007533
2022-01-21 22:35:56,664 iteration 5161 : loss : 0.020893, loss_ce: 0.008599
2022-01-21 22:35:57,811 iteration 5162 : loss : 0.014235, loss_ce: 0.004012
2022-01-21 22:35:58,977 iteration 5163 : loss : 0.026188, loss_ce: 0.009390
2022-01-21 22:36:00,099 iteration 5164 : loss : 0.018390, loss_ce: 0.009417
2022-01-21 22:36:01,285 iteration 5165 : loss : 0.017542, loss_ce: 0.005318
2022-01-21 22:36:02,489 iteration 5166 : loss : 0.017955, loss_ce: 0.007958
2022-01-21 22:36:03,622 iteration 5167 : loss : 0.016852, loss_ce: 0.007543
2022-01-21 22:36:04,862 iteration 5168 : loss : 0.030878, loss_ce: 0.013063
 76%|██████████████████████       | 304/400 [1:50:54<33:28, 20.92s/it]2022-01-21 22:36:06,051 iteration 5169 : loss : 0.017229, loss_ce: 0.006549
2022-01-21 22:36:07,237 iteration 5170 : loss : 0.018088, loss_ce: 0.007164
2022-01-21 22:36:08,397 iteration 5171 : loss : 0.024175, loss_ce: 0.006837
2022-01-21 22:36:09,593 iteration 5172 : loss : 0.022416, loss_ce: 0.010397
2022-01-21 22:36:10,746 iteration 5173 : loss : 0.016856, loss_ce: 0.007676
2022-01-21 22:36:11,958 iteration 5174 : loss : 0.020559, loss_ce: 0.007429
2022-01-21 22:36:13,222 iteration 5175 : loss : 0.021913, loss_ce: 0.007401
2022-01-21 22:36:14,407 iteration 5176 : loss : 0.018374, loss_ce: 0.006138
2022-01-21 22:36:15,713 iteration 5177 : loss : 0.027828, loss_ce: 0.012403
2022-01-21 22:36:16,884 iteration 5178 : loss : 0.020617, loss_ce: 0.004091
2022-01-21 22:36:18,122 iteration 5179 : loss : 0.019566, loss_ce: 0.008909
2022-01-21 22:36:19,310 iteration 5180 : loss : 0.019805, loss_ce: 0.007807
2022-01-21 22:36:20,545 iteration 5181 : loss : 0.026806, loss_ce: 0.011930
2022-01-21 22:36:21,779 iteration 5182 : loss : 0.023687, loss_ce: 0.008271
2022-01-21 22:36:23,015 iteration 5183 : loss : 0.023915, loss_ce: 0.006833
2022-01-21 22:36:24,291 iteration 5184 : loss : 0.018545, loss_ce: 0.008729
2022-01-21 22:36:24,291 Training Data Eval:
2022-01-21 22:36:29,979   Average segmentation loss on training set: 0.0118
2022-01-21 22:36:29,979 Validation Data Eval:
2022-01-21 22:36:31,946   Average segmentation loss on validation set: 0.0689
2022-01-21 22:36:33,143 iteration 5185 : loss : 0.018766, loss_ce: 0.008533
 76%|██████████████████████       | 305/400 [1:51:23<36:37, 23.13s/it]2022-01-21 22:36:34,388 iteration 5186 : loss : 0.016288, loss_ce: 0.007485
2022-01-21 22:36:35,624 iteration 5187 : loss : 0.017088, loss_ce: 0.006505
2022-01-21 22:36:36,754 iteration 5188 : loss : 0.017774, loss_ce: 0.005149
2022-01-21 22:36:37,940 iteration 5189 : loss : 0.016321, loss_ce: 0.006667
2022-01-21 22:36:39,059 iteration 5190 : loss : 0.019996, loss_ce: 0.008662
2022-01-21 22:36:40,196 iteration 5191 : loss : 0.016104, loss_ce: 0.005770
2022-01-21 22:36:41,429 iteration 5192 : loss : 0.013634, loss_ce: 0.005526
2022-01-21 22:36:42,625 iteration 5193 : loss : 0.027180, loss_ce: 0.014071
2022-01-21 22:36:43,811 iteration 5194 : loss : 0.020402, loss_ce: 0.007533
2022-01-21 22:36:45,013 iteration 5195 : loss : 0.022578, loss_ce: 0.007542
2022-01-21 22:36:46,321 iteration 5196 : loss : 0.032817, loss_ce: 0.009507
2022-01-21 22:36:47,421 iteration 5197 : loss : 0.016238, loss_ce: 0.004983
2022-01-21 22:36:48,653 iteration 5198 : loss : 0.025360, loss_ce: 0.010521
2022-01-21 22:36:49,885 iteration 5199 : loss : 0.021414, loss_ce: 0.008560
2022-01-21 22:36:51,108 iteration 5200 : loss : 0.016566, loss_ce: 0.005378
2022-01-21 22:36:52,273 iteration 5201 : loss : 0.014811, loss_ce: 0.004293
2022-01-21 22:36:53,460 iteration 5202 : loss : 0.024477, loss_ce: 0.009515
 76%|██████████████████████▏      | 306/400 [1:51:43<34:55, 22.29s/it]2022-01-21 22:36:54,607 iteration 5203 : loss : 0.016561, loss_ce: 0.004673
2022-01-21 22:36:55,823 iteration 5204 : loss : 0.020472, loss_ce: 0.007170
2022-01-21 22:36:57,024 iteration 5205 : loss : 0.017295, loss_ce: 0.006753
2022-01-21 22:36:58,149 iteration 5206 : loss : 0.013649, loss_ce: 0.005658
2022-01-21 22:36:59,312 iteration 5207 : loss : 0.018064, loss_ce: 0.007340
2022-01-21 22:37:00,565 iteration 5208 : loss : 0.027425, loss_ce: 0.011272
2022-01-21 22:37:01,774 iteration 5209 : loss : 0.019042, loss_ce: 0.008310
2022-01-21 22:37:02,945 iteration 5210 : loss : 0.013629, loss_ce: 0.004280
2022-01-21 22:37:04,086 iteration 5211 : loss : 0.015073, loss_ce: 0.004281
2022-01-21 22:37:05,281 iteration 5212 : loss : 0.018225, loss_ce: 0.005693
2022-01-21 22:37:06,494 iteration 5213 : loss : 0.022811, loss_ce: 0.007774
2022-01-21 22:37:07,669 iteration 5214 : loss : 0.020999, loss_ce: 0.012444
2022-01-21 22:37:08,827 iteration 5215 : loss : 0.018730, loss_ce: 0.007110
2022-01-21 22:37:09,997 iteration 5216 : loss : 0.018624, loss_ce: 0.007185
2022-01-21 22:37:11,133 iteration 5217 : loss : 0.014883, loss_ce: 0.005076
2022-01-21 22:37:12,288 iteration 5218 : loss : 0.021030, loss_ce: 0.006819
2022-01-21 22:37:13,485 iteration 5219 : loss : 0.022667, loss_ce: 0.010006
 77%|██████████████████████▎      | 307/400 [1:52:03<33:29, 21.61s/it]2022-01-21 22:37:14,795 iteration 5220 : loss : 0.027040, loss_ce: 0.010391
2022-01-21 22:37:15,955 iteration 5221 : loss : 0.013725, loss_ce: 0.005492
2022-01-21 22:37:17,055 iteration 5222 : loss : 0.016828, loss_ce: 0.003951
2022-01-21 22:37:18,218 iteration 5223 : loss : 0.017057, loss_ce: 0.007254
2022-01-21 22:37:19,468 iteration 5224 : loss : 0.026705, loss_ce: 0.010076
2022-01-21 22:37:20,584 iteration 5225 : loss : 0.014138, loss_ce: 0.003936
2022-01-21 22:37:21,890 iteration 5226 : loss : 0.026213, loss_ce: 0.009790
2022-01-21 22:37:22,988 iteration 5227 : loss : 0.015545, loss_ce: 0.005622
2022-01-21 22:37:24,089 iteration 5228 : loss : 0.013312, loss_ce: 0.005438
2022-01-21 22:37:25,229 iteration 5229 : loss : 0.015921, loss_ce: 0.006705
2022-01-21 22:37:26,428 iteration 5230 : loss : 0.020216, loss_ce: 0.011319
2022-01-21 22:37:27,634 iteration 5231 : loss : 0.022281, loss_ce: 0.006682
2022-01-21 22:37:28,777 iteration 5232 : loss : 0.020097, loss_ce: 0.009383
2022-01-21 22:37:29,996 iteration 5233 : loss : 0.017076, loss_ce: 0.006997
2022-01-21 22:37:31,090 iteration 5234 : loss : 0.011657, loss_ce: 0.004290
2022-01-21 22:37:32,355 iteration 5235 : loss : 0.029070, loss_ce: 0.009904
2022-01-21 22:37:33,514 iteration 5236 : loss : 0.019315, loss_ce: 0.007448
 77%|██████████████████████▎      | 308/400 [1:52:23<32:24, 21.13s/it]2022-01-21 22:37:34,774 iteration 5237 : loss : 0.016900, loss_ce: 0.005166
2022-01-21 22:37:35,965 iteration 5238 : loss : 0.014440, loss_ce: 0.006209
2022-01-21 22:37:37,149 iteration 5239 : loss : 0.015789, loss_ce: 0.004370
2022-01-21 22:37:38,427 iteration 5240 : loss : 0.018344, loss_ce: 0.005827
2022-01-21 22:37:39,650 iteration 5241 : loss : 0.029339, loss_ce: 0.012030
2022-01-21 22:37:40,871 iteration 5242 : loss : 0.020736, loss_ce: 0.007414
2022-01-21 22:37:42,067 iteration 5243 : loss : 0.019782, loss_ce: 0.007690
2022-01-21 22:37:43,275 iteration 5244 : loss : 0.027254, loss_ce: 0.011933
2022-01-21 22:37:44,467 iteration 5245 : loss : 0.017608, loss_ce: 0.005659
2022-01-21 22:37:45,562 iteration 5246 : loss : 0.013180, loss_ce: 0.006122
2022-01-21 22:37:46,736 iteration 5247 : loss : 0.016288, loss_ce: 0.005663
2022-01-21 22:37:47,948 iteration 5248 : loss : 0.017324, loss_ce: 0.006156
2022-01-21 22:37:49,115 iteration 5249 : loss : 0.018876, loss_ce: 0.008013
2022-01-21 22:37:50,297 iteration 5250 : loss : 0.021145, loss_ce: 0.009891
2022-01-21 22:37:51,532 iteration 5251 : loss : 0.014155, loss_ce: 0.005035
2022-01-21 22:37:52,703 iteration 5252 : loss : 0.016125, loss_ce: 0.005422
2022-01-21 22:37:53,910 iteration 5253 : loss : 0.016313, loss_ce: 0.006674
 77%|██████████████████████▍      | 309/400 [1:52:43<31:43, 20.91s/it]2022-01-21 22:37:55,079 iteration 5254 : loss : 0.014453, loss_ce: 0.005190
2022-01-21 22:37:56,312 iteration 5255 : loss : 0.016149, loss_ce: 0.005269
2022-01-21 22:37:57,510 iteration 5256 : loss : 0.016080, loss_ce: 0.006803
2022-01-21 22:37:58,778 iteration 5257 : loss : 0.020101, loss_ce: 0.005853
2022-01-21 22:37:59,918 iteration 5258 : loss : 0.019231, loss_ce: 0.007657
2022-01-21 22:38:01,130 iteration 5259 : loss : 0.024285, loss_ce: 0.006779
2022-01-21 22:38:02,293 iteration 5260 : loss : 0.016533, loss_ce: 0.006853
2022-01-21 22:38:03,469 iteration 5261 : loss : 0.015181, loss_ce: 0.006450
2022-01-21 22:38:04,585 iteration 5262 : loss : 0.010617, loss_ce: 0.004691
2022-01-21 22:38:05,772 iteration 5263 : loss : 0.032311, loss_ce: 0.011420
2022-01-21 22:38:06,924 iteration 5264 : loss : 0.015636, loss_ce: 0.005067
2022-01-21 22:38:08,025 iteration 5265 : loss : 0.020212, loss_ce: 0.007041
2022-01-21 22:38:09,207 iteration 5266 : loss : 0.024404, loss_ce: 0.010274
2022-01-21 22:38:10,336 iteration 5267 : loss : 0.017260, loss_ce: 0.006906
2022-01-21 22:38:11,580 iteration 5268 : loss : 0.018099, loss_ce: 0.006927
2022-01-21 22:38:12,836 iteration 5269 : loss : 0.025105, loss_ce: 0.013275
2022-01-21 22:38:12,836 Training Data Eval:
2022-01-21 22:38:18,527   Average segmentation loss on training set: 0.0114
2022-01-21 22:38:18,527 Validation Data Eval:
2022-01-21 22:38:20,487   Average segmentation loss on validation set: 0.0624
2022-01-21 22:38:21,711 iteration 5270 : loss : 0.021895, loss_ce: 0.009288
 78%|██████████████████████▍      | 310/400 [1:53:11<34:27, 22.98s/it]2022-01-21 22:38:22,985 iteration 5271 : loss : 0.017953, loss_ce: 0.007502
2022-01-21 22:38:24,170 iteration 5272 : loss : 0.023472, loss_ce: 0.008802
2022-01-21 22:38:25,347 iteration 5273 : loss : 0.020415, loss_ce: 0.010074
2022-01-21 22:38:26,485 iteration 5274 : loss : 0.015474, loss_ce: 0.005291
2022-01-21 22:38:27,687 iteration 5275 : loss : 0.034265, loss_ce: 0.012371
2022-01-21 22:38:28,890 iteration 5276 : loss : 0.018707, loss_ce: 0.006045
2022-01-21 22:38:30,009 iteration 5277 : loss : 0.020039, loss_ce: 0.005731
2022-01-21 22:38:31,314 iteration 5278 : loss : 0.022033, loss_ce: 0.009025
2022-01-21 22:38:32,489 iteration 5279 : loss : 0.039584, loss_ce: 0.009808
2022-01-21 22:38:33,737 iteration 5280 : loss : 0.016307, loss_ce: 0.006000
2022-01-21 22:38:34,924 iteration 5281 : loss : 0.020225, loss_ce: 0.009882
2022-01-21 22:38:36,146 iteration 5282 : loss : 0.018898, loss_ce: 0.006601
2022-01-21 22:38:37,322 iteration 5283 : loss : 0.028650, loss_ce: 0.008770
2022-01-21 22:38:38,527 iteration 5284 : loss : 0.015105, loss_ce: 0.006541
2022-01-21 22:38:39,732 iteration 5285 : loss : 0.024278, loss_ce: 0.012811
2022-01-21 22:38:40,968 iteration 5286 : loss : 0.017059, loss_ce: 0.006341
2022-01-21 22:38:42,254 iteration 5287 : loss : 0.027928, loss_ce: 0.013215
 78%|██████████████████████▌      | 311/400 [1:53:32<33:00, 22.25s/it]2022-01-21 22:38:43,452 iteration 5288 : loss : 0.019521, loss_ce: 0.006872
2022-01-21 22:38:44,649 iteration 5289 : loss : 0.020171, loss_ce: 0.006884
2022-01-21 22:38:45,881 iteration 5290 : loss : 0.034006, loss_ce: 0.011441
2022-01-21 22:38:47,117 iteration 5291 : loss : 0.023985, loss_ce: 0.008577
2022-01-21 22:38:48,349 iteration 5292 : loss : 0.020142, loss_ce: 0.007655
2022-01-21 22:38:49,512 iteration 5293 : loss : 0.019694, loss_ce: 0.006177
2022-01-21 22:38:50,768 iteration 5294 : loss : 0.022713, loss_ce: 0.010650
2022-01-21 22:38:51,917 iteration 5295 : loss : 0.017120, loss_ce: 0.006939
2022-01-21 22:38:53,107 iteration 5296 : loss : 0.022670, loss_ce: 0.006681
2022-01-21 22:38:54,375 iteration 5297 : loss : 0.036911, loss_ce: 0.010216
2022-01-21 22:38:55,510 iteration 5298 : loss : 0.017515, loss_ce: 0.008099
2022-01-21 22:38:56,756 iteration 5299 : loss : 0.021965, loss_ce: 0.009063
2022-01-21 22:38:57,876 iteration 5300 : loss : 0.018127, loss_ce: 0.007205
2022-01-21 22:38:59,064 iteration 5301 : loss : 0.028237, loss_ce: 0.011084
2022-01-21 22:39:00,210 iteration 5302 : loss : 0.016621, loss_ce: 0.008371
2022-01-21 22:39:01,289 iteration 5303 : loss : 0.014224, loss_ce: 0.004978
2022-01-21 22:39:02,529 iteration 5304 : loss : 0.028843, loss_ce: 0.010672
 78%|██████████████████████▌      | 312/400 [1:53:52<31:45, 21.66s/it]2022-01-21 22:39:03,767 iteration 5305 : loss : 0.023190, loss_ce: 0.008708
2022-01-21 22:39:04,978 iteration 5306 : loss : 0.026802, loss_ce: 0.010247
2022-01-21 22:39:06,164 iteration 5307 : loss : 0.019094, loss_ce: 0.007361
2022-01-21 22:39:07,386 iteration 5308 : loss : 0.021760, loss_ce: 0.010114
2022-01-21 22:39:08,566 iteration 5309 : loss : 0.025412, loss_ce: 0.009345
2022-01-21 22:39:09,746 iteration 5310 : loss : 0.016994, loss_ce: 0.007793
2022-01-21 22:39:10,941 iteration 5311 : loss : 0.018237, loss_ce: 0.006454
2022-01-21 22:39:12,124 iteration 5312 : loss : 0.020009, loss_ce: 0.005866
2022-01-21 22:39:13,347 iteration 5313 : loss : 0.027318, loss_ce: 0.008136
2022-01-21 22:39:14,490 iteration 5314 : loss : 0.017747, loss_ce: 0.007680
2022-01-21 22:39:15,710 iteration 5315 : loss : 0.021245, loss_ce: 0.008769
2022-01-21 22:39:16,781 iteration 5316 : loss : 0.013312, loss_ce: 0.006214
2022-01-21 22:39:17,973 iteration 5317 : loss : 0.019374, loss_ce: 0.007402
2022-01-21 22:39:19,189 iteration 5318 : loss : 0.021174, loss_ce: 0.006337
2022-01-21 22:39:20,421 iteration 5319 : loss : 0.025914, loss_ce: 0.008475
2022-01-21 22:39:21,649 iteration 5320 : loss : 0.029041, loss_ce: 0.012911
2022-01-21 22:39:22,777 iteration 5321 : loss : 0.024939, loss_ce: 0.004956
 78%|██████████████████████▋      | 313/400 [1:54:12<30:47, 21.24s/it]2022-01-21 22:39:24,066 iteration 5322 : loss : 0.018335, loss_ce: 0.008275
2022-01-21 22:39:25,319 iteration 5323 : loss : 0.016433, loss_ce: 0.006161
2022-01-21 22:39:26,516 iteration 5324 : loss : 0.022529, loss_ce: 0.009541
2022-01-21 22:39:27,716 iteration 5325 : loss : 0.019480, loss_ce: 0.007451
2022-01-21 22:39:28,988 iteration 5326 : loss : 0.020887, loss_ce: 0.005681
2022-01-21 22:39:30,198 iteration 5327 : loss : 0.021967, loss_ce: 0.008101
2022-01-21 22:39:31,377 iteration 5328 : loss : 0.021458, loss_ce: 0.008188
2022-01-21 22:39:32,564 iteration 5329 : loss : 0.018945, loss_ce: 0.007092
2022-01-21 22:39:33,750 iteration 5330 : loss : 0.020598, loss_ce: 0.010122
2022-01-21 22:39:34,873 iteration 5331 : loss : 0.018572, loss_ce: 0.007284
2022-01-21 22:39:36,230 iteration 5332 : loss : 0.028833, loss_ce: 0.012646
2022-01-21 22:39:37,406 iteration 5333 : loss : 0.016478, loss_ce: 0.006237
2022-01-21 22:39:38,493 iteration 5334 : loss : 0.014320, loss_ce: 0.004282
2022-01-21 22:39:39,678 iteration 5335 : loss : 0.027082, loss_ce: 0.009221
2022-01-21 22:39:40,849 iteration 5336 : loss : 0.021007, loss_ce: 0.006936
2022-01-21 22:39:42,030 iteration 5337 : loss : 0.018228, loss_ce: 0.007174
2022-01-21 22:39:43,224 iteration 5338 : loss : 0.025730, loss_ce: 0.009290
 78%|██████████████████████▊      | 314/400 [1:54:33<30:05, 21.00s/it]2022-01-21 22:39:44,455 iteration 5339 : loss : 0.024582, loss_ce: 0.009219
2022-01-21 22:39:45,608 iteration 5340 : loss : 0.015200, loss_ce: 0.005867
2022-01-21 22:39:46,859 iteration 5341 : loss : 0.023773, loss_ce: 0.009693
2022-01-21 22:39:48,084 iteration 5342 : loss : 0.018696, loss_ce: 0.006005
2022-01-21 22:39:49,295 iteration 5343 : loss : 0.028797, loss_ce: 0.012920
2022-01-21 22:39:50,437 iteration 5344 : loss : 0.014955, loss_ce: 0.006454
2022-01-21 22:39:51,592 iteration 5345 : loss : 0.014938, loss_ce: 0.005619
2022-01-21 22:39:52,743 iteration 5346 : loss : 0.020296, loss_ce: 0.008245
2022-01-21 22:39:53,939 iteration 5347 : loss : 0.013198, loss_ce: 0.005261
2022-01-21 22:39:55,074 iteration 5348 : loss : 0.019707, loss_ce: 0.007719
2022-01-21 22:39:56,224 iteration 5349 : loss : 0.018707, loss_ce: 0.006656
2022-01-21 22:39:57,392 iteration 5350 : loss : 0.018708, loss_ce: 0.005946
2022-01-21 22:39:58,519 iteration 5351 : loss : 0.015654, loss_ce: 0.005827
2022-01-21 22:39:59,757 iteration 5352 : loss : 0.017044, loss_ce: 0.006480
2022-01-21 22:40:00,952 iteration 5353 : loss : 0.015883, loss_ce: 0.006338
2022-01-21 22:40:02,083 iteration 5354 : loss : 0.018554, loss_ce: 0.008490
2022-01-21 22:40:02,083 Training Data Eval:
2022-01-21 22:40:07,764   Average segmentation loss on training set: 0.0112
2022-01-21 22:40:07,764 Validation Data Eval:
2022-01-21 22:40:09,731   Average segmentation loss on validation set: 0.0657
2022-01-21 22:40:10,906 iteration 5355 : loss : 0.019035, loss_ce: 0.007983
 79%|██████████████████████▊      | 315/400 [1:55:00<32:35, 23.00s/it]2022-01-21 22:40:12,183 iteration 5356 : loss : 0.029019, loss_ce: 0.013012
2022-01-21 22:40:13,324 iteration 5357 : loss : 0.010851, loss_ce: 0.003721
2022-01-21 22:40:14,459 iteration 5358 : loss : 0.015948, loss_ce: 0.007335
2022-01-21 22:40:15,593 iteration 5359 : loss : 0.015095, loss_ce: 0.005217
2022-01-21 22:40:16,812 iteration 5360 : loss : 0.017623, loss_ce: 0.007034
2022-01-21 22:40:17,973 iteration 5361 : loss : 0.019445, loss_ce: 0.008694
2022-01-21 22:40:19,177 iteration 5362 : loss : 0.015638, loss_ce: 0.005804
2022-01-21 22:40:20,500 iteration 5363 : loss : 0.019418, loss_ce: 0.007658
2022-01-21 22:40:21,680 iteration 5364 : loss : 0.020776, loss_ce: 0.004771
2022-01-21 22:40:22,883 iteration 5365 : loss : 0.022544, loss_ce: 0.007176
2022-01-21 22:40:24,043 iteration 5366 : loss : 0.015666, loss_ce: 0.006196
2022-01-21 22:40:25,130 iteration 5367 : loss : 0.017000, loss_ce: 0.005635
2022-01-21 22:40:26,411 iteration 5368 : loss : 0.021847, loss_ce: 0.008974
2022-01-21 22:40:27,567 iteration 5369 : loss : 0.011360, loss_ce: 0.004352
2022-01-21 22:40:28,717 iteration 5370 : loss : 0.016789, loss_ce: 0.008014
2022-01-21 22:40:29,886 iteration 5371 : loss : 0.017177, loss_ce: 0.004897
2022-01-21 22:40:30,979 iteration 5372 : loss : 0.014832, loss_ce: 0.006231
 79%|██████████████████████▉      | 316/400 [1:55:20<30:58, 22.13s/it]2022-01-21 22:40:32,191 iteration 5373 : loss : 0.018167, loss_ce: 0.007460
2022-01-21 22:40:33,332 iteration 5374 : loss : 0.029272, loss_ce: 0.006701
2022-01-21 22:40:34,513 iteration 5375 : loss : 0.022906, loss_ce: 0.009190
2022-01-21 22:40:35,704 iteration 5376 : loss : 0.020058, loss_ce: 0.006755
2022-01-21 22:40:36,900 iteration 5377 : loss : 0.022453, loss_ce: 0.005390
2022-01-21 22:40:38,095 iteration 5378 : loss : 0.022491, loss_ce: 0.008441
2022-01-21 22:40:39,272 iteration 5379 : loss : 0.018718, loss_ce: 0.006541
2022-01-21 22:40:40,379 iteration 5380 : loss : 0.015843, loss_ce: 0.007914
2022-01-21 22:40:41,618 iteration 5381 : loss : 0.018232, loss_ce: 0.007370
2022-01-21 22:40:42,794 iteration 5382 : loss : 0.023555, loss_ce: 0.007653
2022-01-21 22:40:43,961 iteration 5383 : loss : 0.020273, loss_ce: 0.009926
2022-01-21 22:40:45,117 iteration 5384 : loss : 0.013718, loss_ce: 0.005920
2022-01-21 22:40:46,313 iteration 5385 : loss : 0.022387, loss_ce: 0.008286
2022-01-21 22:40:47,457 iteration 5386 : loss : 0.019224, loss_ce: 0.007533
2022-01-21 22:40:48,726 iteration 5387 : loss : 0.018348, loss_ce: 0.006557
2022-01-21 22:40:49,931 iteration 5388 : loss : 0.017337, loss_ce: 0.005060
2022-01-21 22:40:51,182 iteration 5389 : loss : 0.018408, loss_ce: 0.007775
 79%|██████████████████████▉      | 317/400 [1:55:41<29:48, 21.55s/it]2022-01-21 22:40:52,386 iteration 5390 : loss : 0.014516, loss_ce: 0.004923
2022-01-21 22:40:53,647 iteration 5391 : loss : 0.040311, loss_ce: 0.013087
2022-01-21 22:40:54,815 iteration 5392 : loss : 0.024176, loss_ce: 0.007524
2022-01-21 22:40:55,953 iteration 5393 : loss : 0.013647, loss_ce: 0.004509
2022-01-21 22:40:57,116 iteration 5394 : loss : 0.016076, loss_ce: 0.004910
2022-01-21 22:40:58,289 iteration 5395 : loss : 0.021500, loss_ce: 0.008528
2022-01-21 22:40:59,435 iteration 5396 : loss : 0.018887, loss_ce: 0.007276
2022-01-21 22:41:00,648 iteration 5397 : loss : 0.021254, loss_ce: 0.008909
2022-01-21 22:41:01,969 iteration 5398 : loss : 0.021019, loss_ce: 0.006728
2022-01-21 22:41:03,191 iteration 5399 : loss : 0.027216, loss_ce: 0.007299
2022-01-21 22:41:04,349 iteration 5400 : loss : 0.029665, loss_ce: 0.014515
2022-01-21 22:41:05,560 iteration 5401 : loss : 0.018576, loss_ce: 0.010059
2022-01-21 22:41:06,719 iteration 5402 : loss : 0.017536, loss_ce: 0.009035
2022-01-21 22:41:07,898 iteration 5403 : loss : 0.016771, loss_ce: 0.006814
2022-01-21 22:41:09,113 iteration 5404 : loss : 0.013474, loss_ce: 0.005740
2022-01-21 22:41:10,398 iteration 5405 : loss : 0.023005, loss_ce: 0.008253
2022-01-21 22:41:11,537 iteration 5406 : loss : 0.014897, loss_ce: 0.006870
 80%|███████████████████████      | 318/400 [1:56:01<28:57, 21.19s/it]2022-01-21 22:41:12,752 iteration 5407 : loss : 0.016526, loss_ce: 0.007146
2022-01-21 22:41:13,913 iteration 5408 : loss : 0.020800, loss_ce: 0.007791
2022-01-21 22:41:15,020 iteration 5409 : loss : 0.014717, loss_ce: 0.005096
2022-01-21 22:41:16,212 iteration 5410 : loss : 0.017999, loss_ce: 0.006793
2022-01-21 22:41:17,339 iteration 5411 : loss : 0.017811, loss_ce: 0.007411
2022-01-21 22:41:18,536 iteration 5412 : loss : 0.019369, loss_ce: 0.007991
2022-01-21 22:41:19,689 iteration 5413 : loss : 0.013916, loss_ce: 0.005782
2022-01-21 22:41:20,873 iteration 5414 : loss : 0.015687, loss_ce: 0.006393
2022-01-21 22:41:22,154 iteration 5415 : loss : 0.022015, loss_ce: 0.007622
2022-01-21 22:41:23,295 iteration 5416 : loss : 0.015517, loss_ce: 0.005616
2022-01-21 22:41:24,467 iteration 5417 : loss : 0.015676, loss_ce: 0.004936
2022-01-21 22:41:25,721 iteration 5418 : loss : 0.016724, loss_ce: 0.007094
2022-01-21 22:41:26,843 iteration 5419 : loss : 0.016604, loss_ce: 0.006687
2022-01-21 22:41:27,957 iteration 5420 : loss : 0.016804, loss_ce: 0.006551
2022-01-21 22:41:29,180 iteration 5421 : loss : 0.018360, loss_ce: 0.006157
2022-01-21 22:41:30,420 iteration 5422 : loss : 0.021028, loss_ce: 0.004569
2022-01-21 22:41:31,659 iteration 5423 : loss : 0.020569, loss_ce: 0.008820
 80%|███████████████████████▏     | 319/400 [1:56:21<28:10, 20.87s/it]2022-01-21 22:41:32,894 iteration 5424 : loss : 0.017997, loss_ce: 0.005520
2022-01-21 22:41:34,042 iteration 5425 : loss : 0.021559, loss_ce: 0.005247
2022-01-21 22:41:35,278 iteration 5426 : loss : 0.031355, loss_ce: 0.015189
2022-01-21 22:41:36,387 iteration 5427 : loss : 0.015964, loss_ce: 0.004672
2022-01-21 22:41:37,530 iteration 5428 : loss : 0.012518, loss_ce: 0.004464
2022-01-21 22:41:38,685 iteration 5429 : loss : 0.019244, loss_ce: 0.007545
2022-01-21 22:41:39,967 iteration 5430 : loss : 0.014029, loss_ce: 0.004432
2022-01-21 22:41:41,132 iteration 5431 : loss : 0.021992, loss_ce: 0.008506
2022-01-21 22:41:42,286 iteration 5432 : loss : 0.025525, loss_ce: 0.013453
2022-01-21 22:41:43,525 iteration 5433 : loss : 0.015568, loss_ce: 0.006772
2022-01-21 22:41:44,683 iteration 5434 : loss : 0.017221, loss_ce: 0.006300
2022-01-21 22:41:45,962 iteration 5435 : loss : 0.024904, loss_ce: 0.013607
2022-01-21 22:41:47,140 iteration 5436 : loss : 0.015457, loss_ce: 0.006402
2022-01-21 22:41:48,205 iteration 5437 : loss : 0.012606, loss_ce: 0.004877
2022-01-21 22:41:49,477 iteration 5438 : loss : 0.019280, loss_ce: 0.008346
2022-01-21 22:41:50,623 iteration 5439 : loss : 0.010965, loss_ce: 0.004017
2022-01-21 22:41:50,623 Training Data Eval:
2022-01-21 22:41:56,303   Average segmentation loss on training set: 0.0106
2022-01-21 22:41:56,303 Validation Data Eval:
2022-01-21 22:41:58,281   Average segmentation loss on validation set: 0.0607
2022-01-21 22:41:59,501 iteration 5440 : loss : 0.029666, loss_ce: 0.007659
 80%|███████████████████████▏     | 320/400 [1:56:49<30:36, 22.96s/it]2022-01-21 22:42:00,635 iteration 5441 : loss : 0.013021, loss_ce: 0.004182
2022-01-21 22:42:01,811 iteration 5442 : loss : 0.019286, loss_ce: 0.006405
2022-01-21 22:42:03,015 iteration 5443 : loss : 0.013215, loss_ce: 0.004100
2022-01-21 22:42:04,213 iteration 5444 : loss : 0.015448, loss_ce: 0.005756
2022-01-21 22:42:05,477 iteration 5445 : loss : 0.026240, loss_ce: 0.010019
2022-01-21 22:42:06,625 iteration 5446 : loss : 0.018861, loss_ce: 0.005957
2022-01-21 22:42:07,789 iteration 5447 : loss : 0.020629, loss_ce: 0.008595
2022-01-21 22:42:08,983 iteration 5448 : loss : 0.022980, loss_ce: 0.008036
2022-01-21 22:42:10,152 iteration 5449 : loss : 0.016421, loss_ce: 0.005499
2022-01-21 22:42:11,387 iteration 5450 : loss : 0.019094, loss_ce: 0.009066
2022-01-21 22:42:12,561 iteration 5451 : loss : 0.018872, loss_ce: 0.006975
2022-01-21 22:42:13,793 iteration 5452 : loss : 0.017084, loss_ce: 0.006894
2022-01-21 22:42:14,987 iteration 5453 : loss : 0.014925, loss_ce: 0.005460
2022-01-21 22:42:16,073 iteration 5454 : loss : 0.011544, loss_ce: 0.005261
2022-01-21 22:42:17,345 iteration 5455 : loss : 0.025333, loss_ce: 0.010517
2022-01-21 22:42:18,592 iteration 5456 : loss : 0.017917, loss_ce: 0.007094
2022-01-21 22:42:19,775 iteration 5457 : loss : 0.020816, loss_ce: 0.007238
 80%|███████████████████████▎     | 321/400 [1:57:09<29:10, 22.16s/it]2022-01-21 22:42:20,982 iteration 5458 : loss : 0.017107, loss_ce: 0.006202
2022-01-21 22:42:22,123 iteration 5459 : loss : 0.015326, loss_ce: 0.005590
2022-01-21 22:42:23,328 iteration 5460 : loss : 0.019900, loss_ce: 0.008164
2022-01-21 22:42:24,539 iteration 5461 : loss : 0.020115, loss_ce: 0.008386
2022-01-21 22:42:25,725 iteration 5462 : loss : 0.016119, loss_ce: 0.004015
2022-01-21 22:42:26,885 iteration 5463 : loss : 0.016940, loss_ce: 0.005964
2022-01-21 22:42:28,051 iteration 5464 : loss : 0.017247, loss_ce: 0.005924
2022-01-21 22:42:29,181 iteration 5465 : loss : 0.024014, loss_ce: 0.011875
2022-01-21 22:42:30,445 iteration 5466 : loss : 0.020436, loss_ce: 0.008004
2022-01-21 22:42:31,611 iteration 5467 : loss : 0.015368, loss_ce: 0.008116
2022-01-21 22:42:32,807 iteration 5468 : loss : 0.024972, loss_ce: 0.012478
2022-01-21 22:42:33,932 iteration 5469 : loss : 0.014122, loss_ce: 0.004447
2022-01-21 22:42:35,151 iteration 5470 : loss : 0.024816, loss_ce: 0.008910
2022-01-21 22:42:36,332 iteration 5471 : loss : 0.015635, loss_ce: 0.006096
2022-01-21 22:42:37,568 iteration 5472 : loss : 0.016845, loss_ce: 0.006171
2022-01-21 22:42:38,790 iteration 5473 : loss : 0.022475, loss_ce: 0.007447
2022-01-21 22:42:40,014 iteration 5474 : loss : 0.019711, loss_ce: 0.008606
 80%|███████████████████████▎     | 322/400 [1:57:29<28:03, 21.58s/it]2022-01-21 22:42:41,232 iteration 5475 : loss : 0.012440, loss_ce: 0.003297
2022-01-21 22:42:42,388 iteration 5476 : loss : 0.023956, loss_ce: 0.007014
2022-01-21 22:42:43,541 iteration 5477 : loss : 0.013491, loss_ce: 0.005205
2022-01-21 22:42:44,719 iteration 5478 : loss : 0.024354, loss_ce: 0.010062
2022-01-21 22:42:45,990 iteration 5479 : loss : 0.020252, loss_ce: 0.009659
2022-01-21 22:42:47,235 iteration 5480 : loss : 0.023115, loss_ce: 0.009747
2022-01-21 22:42:48,416 iteration 5481 : loss : 0.016644, loss_ce: 0.005421
2022-01-21 22:42:49,595 iteration 5482 : loss : 0.013220, loss_ce: 0.004441
2022-01-21 22:42:50,787 iteration 5483 : loss : 0.018226, loss_ce: 0.006739
2022-01-21 22:42:51,940 iteration 5484 : loss : 0.021521, loss_ce: 0.010887
2022-01-21 22:42:53,024 iteration 5485 : loss : 0.015823, loss_ce: 0.005848
2022-01-21 22:42:54,284 iteration 5486 : loss : 0.018938, loss_ce: 0.006848
2022-01-21 22:42:55,605 iteration 5487 : loss : 0.028157, loss_ce: 0.012890
2022-01-21 22:42:56,790 iteration 5488 : loss : 0.023597, loss_ce: 0.009296
2022-01-21 22:42:57,968 iteration 5489 : loss : 0.015036, loss_ce: 0.005930
2022-01-21 22:42:59,118 iteration 5490 : loss : 0.027772, loss_ce: 0.010233
2022-01-21 22:43:00,283 iteration 5491 : loss : 0.015528, loss_ce: 0.005526
 81%|███████████████████████▍     | 323/400 [1:57:50<27:11, 21.18s/it]2022-01-21 22:43:01,522 iteration 5492 : loss : 0.025505, loss_ce: 0.011693
2022-01-21 22:43:02,687 iteration 5493 : loss : 0.017470, loss_ce: 0.007187
2022-01-21 22:43:03,814 iteration 5494 : loss : 0.017996, loss_ce: 0.004704
2022-01-21 22:43:05,056 iteration 5495 : loss : 0.039797, loss_ce: 0.007806
2022-01-21 22:43:06,198 iteration 5496 : loss : 0.012640, loss_ce: 0.004299
2022-01-21 22:43:07,379 iteration 5497 : loss : 0.013165, loss_ce: 0.003611
2022-01-21 22:43:08,579 iteration 5498 : loss : 0.021937, loss_ce: 0.011676
2022-01-21 22:43:09,752 iteration 5499 : loss : 0.019464, loss_ce: 0.007493
2022-01-21 22:43:10,959 iteration 5500 : loss : 0.037006, loss_ce: 0.013721
2022-01-21 22:43:12,229 iteration 5501 : loss : 0.030469, loss_ce: 0.011988
2022-01-21 22:43:13,455 iteration 5502 : loss : 0.028234, loss_ce: 0.009985
2022-01-21 22:43:14,613 iteration 5503 : loss : 0.019588, loss_ce: 0.005536
2022-01-21 22:43:15,818 iteration 5504 : loss : 0.021082, loss_ce: 0.009045
2022-01-21 22:43:17,006 iteration 5505 : loss : 0.016566, loss_ce: 0.006534
2022-01-21 22:43:18,146 iteration 5506 : loss : 0.020489, loss_ce: 0.007489
2022-01-21 22:43:19,349 iteration 5507 : loss : 0.022941, loss_ce: 0.007227
2022-01-21 22:43:20,548 iteration 5508 : loss : 0.019124, loss_ce: 0.008826
 81%|███████████████████████▍     | 324/400 [1:58:10<26:29, 20.91s/it]2022-01-21 22:43:21,772 iteration 5509 : loss : 0.018341, loss_ce: 0.005571
2022-01-21 22:43:23,082 iteration 5510 : loss : 0.030170, loss_ce: 0.011421
2022-01-21 22:43:24,271 iteration 5511 : loss : 0.023392, loss_ce: 0.012904
2022-01-21 22:43:25,513 iteration 5512 : loss : 0.032865, loss_ce: 0.008051
2022-01-21 22:43:26,663 iteration 5513 : loss : 0.020903, loss_ce: 0.004385
2022-01-21 22:43:27,898 iteration 5514 : loss : 0.018683, loss_ce: 0.006892
2022-01-21 22:43:29,161 iteration 5515 : loss : 0.050861, loss_ce: 0.018352
2022-01-21 22:43:30,268 iteration 5516 : loss : 0.014969, loss_ce: 0.005720
2022-01-21 22:43:31,479 iteration 5517 : loss : 0.019502, loss_ce: 0.006456
2022-01-21 22:43:32,645 iteration 5518 : loss : 0.017862, loss_ce: 0.007518
2022-01-21 22:43:33,802 iteration 5519 : loss : 0.024023, loss_ce: 0.007261
2022-01-21 22:43:35,005 iteration 5520 : loss : 0.027372, loss_ce: 0.009698
2022-01-21 22:43:36,313 iteration 5521 : loss : 0.024999, loss_ce: 0.008704
2022-01-21 22:43:37,436 iteration 5522 : loss : 0.014458, loss_ce: 0.006550
2022-01-21 22:43:38,628 iteration 5523 : loss : 0.019191, loss_ce: 0.007167
2022-01-21 22:43:39,834 iteration 5524 : loss : 0.024333, loss_ce: 0.011454
2022-01-21 22:43:39,834 Training Data Eval:
2022-01-21 22:43:45,536   Average segmentation loss on training set: 0.0128
2022-01-21 22:43:45,536 Validation Data Eval:
2022-01-21 22:43:47,502   Average segmentation loss on validation set: 0.0676
2022-01-21 22:43:48,731 iteration 5525 : loss : 0.030922, loss_ce: 0.012705
 81%|███████████████████████▌     | 325/400 [1:58:38<28:51, 23.09s/it]2022-01-21 22:43:50,062 iteration 5526 : loss : 0.018796, loss_ce: 0.007621
2022-01-21 22:43:51,212 iteration 5527 : loss : 0.021073, loss_ce: 0.007155
2022-01-21 22:43:52,420 iteration 5528 : loss : 0.024763, loss_ce: 0.007733
2022-01-21 22:43:53,579 iteration 5529 : loss : 0.015743, loss_ce: 0.005321
2022-01-21 22:43:54,703 iteration 5530 : loss : 0.014221, loss_ce: 0.003593
2022-01-21 22:43:55,895 iteration 5531 : loss : 0.013941, loss_ce: 0.005049
2022-01-21 22:43:57,002 iteration 5532 : loss : 0.015016, loss_ce: 0.005242
2022-01-21 22:43:58,208 iteration 5533 : loss : 0.015814, loss_ce: 0.006440
2022-01-21 22:43:59,406 iteration 5534 : loss : 0.019574, loss_ce: 0.007298
2022-01-21 22:44:00,610 iteration 5535 : loss : 0.015184, loss_ce: 0.006130
2022-01-21 22:44:01,785 iteration 5536 : loss : 0.022467, loss_ce: 0.006395
2022-01-21 22:44:02,959 iteration 5537 : loss : 0.014298, loss_ce: 0.004069
2022-01-21 22:44:04,126 iteration 5538 : loss : 0.017529, loss_ce: 0.008696
2022-01-21 22:44:05,314 iteration 5539 : loss : 0.016475, loss_ce: 0.007135
2022-01-21 22:44:06,519 iteration 5540 : loss : 0.015604, loss_ce: 0.005397
2022-01-21 22:44:07,629 iteration 5541 : loss : 0.023062, loss_ce: 0.011480
2022-01-21 22:44:08,778 iteration 5542 : loss : 0.019854, loss_ce: 0.009075
 82%|███████████████████████▋     | 326/400 [1:58:58<27:21, 22.18s/it]2022-01-21 22:44:10,067 iteration 5543 : loss : 0.024205, loss_ce: 0.010306
2022-01-21 22:44:11,355 iteration 5544 : loss : 0.026630, loss_ce: 0.008915
2022-01-21 22:44:12,597 iteration 5545 : loss : 0.021095, loss_ce: 0.008049
2022-01-21 22:44:13,716 iteration 5546 : loss : 0.012240, loss_ce: 0.005531
2022-01-21 22:44:14,924 iteration 5547 : loss : 0.018896, loss_ce: 0.007267
2022-01-21 22:44:16,072 iteration 5548 : loss : 0.015171, loss_ce: 0.005338
2022-01-21 22:44:17,238 iteration 5549 : loss : 0.016438, loss_ce: 0.006336
2022-01-21 22:44:18,438 iteration 5550 : loss : 0.024742, loss_ce: 0.012188
2022-01-21 22:44:19,638 iteration 5551 : loss : 0.016396, loss_ce: 0.003899
2022-01-21 22:44:20,920 iteration 5552 : loss : 0.023655, loss_ce: 0.006981
2022-01-21 22:44:22,131 iteration 5553 : loss : 0.018414, loss_ce: 0.006849
2022-01-21 22:44:23,407 iteration 5554 : loss : 0.017388, loss_ce: 0.004393
2022-01-21 22:44:24,659 iteration 5555 : loss : 0.036483, loss_ce: 0.020353
2022-01-21 22:44:25,886 iteration 5556 : loss : 0.016303, loss_ce: 0.007198
2022-01-21 22:44:27,112 iteration 5557 : loss : 0.022130, loss_ce: 0.008588
2022-01-21 22:44:28,283 iteration 5558 : loss : 0.029157, loss_ce: 0.010247
2022-01-21 22:44:29,406 iteration 5559 : loss : 0.015228, loss_ce: 0.005293
 82%|███████████████████████▋     | 327/400 [1:59:19<26:25, 21.71s/it]2022-01-21 22:44:30,634 iteration 5560 : loss : 0.016159, loss_ce: 0.005895
2022-01-21 22:44:31,904 iteration 5561 : loss : 0.020162, loss_ce: 0.005151
2022-01-21 22:44:33,106 iteration 5562 : loss : 0.022006, loss_ce: 0.007462
2022-01-21 22:44:34,345 iteration 5563 : loss : 0.031267, loss_ce: 0.010484
2022-01-21 22:44:35,452 iteration 5564 : loss : 0.020146, loss_ce: 0.005574
2022-01-21 22:44:36,655 iteration 5565 : loss : 0.026680, loss_ce: 0.007748
2022-01-21 22:44:37,801 iteration 5566 : loss : 0.013354, loss_ce: 0.004240
2022-01-21 22:44:39,043 iteration 5567 : loss : 0.017913, loss_ce: 0.009356
2022-01-21 22:44:40,277 iteration 5568 : loss : 0.026423, loss_ce: 0.012764
2022-01-21 22:44:41,515 iteration 5569 : loss : 0.041843, loss_ce: 0.019671
2022-01-21 22:44:42,712 iteration 5570 : loss : 0.019396, loss_ce: 0.008829
2022-01-21 22:44:43,895 iteration 5571 : loss : 0.022220, loss_ce: 0.006561
2022-01-21 22:44:44,988 iteration 5572 : loss : 0.013252, loss_ce: 0.004669
2022-01-21 22:44:46,207 iteration 5573 : loss : 0.022998, loss_ce: 0.008732
2022-01-21 22:44:47,347 iteration 5574 : loss : 0.047470, loss_ce: 0.023211
2022-01-21 22:44:48,468 iteration 5575 : loss : 0.015259, loss_ce: 0.005569
2022-01-21 22:44:49,566 iteration 5576 : loss : 0.014866, loss_ce: 0.004439
 82%|███████████████████████▊     | 328/400 [1:59:39<25:29, 21.25s/it]2022-01-21 22:44:50,848 iteration 5577 : loss : 0.021692, loss_ce: 0.007000
2022-01-21 22:44:52,037 iteration 5578 : loss : 0.019387, loss_ce: 0.007883
2022-01-21 22:44:53,321 iteration 5579 : loss : 0.024286, loss_ce: 0.006845
2022-01-21 22:44:54,567 iteration 5580 : loss : 0.026761, loss_ce: 0.007914
2022-01-21 22:44:55,773 iteration 5581 : loss : 0.024955, loss_ce: 0.010257
2022-01-21 22:44:56,942 iteration 5582 : loss : 0.019669, loss_ce: 0.007623
2022-01-21 22:44:58,082 iteration 5583 : loss : 0.013215, loss_ce: 0.004111
2022-01-21 22:44:59,237 iteration 5584 : loss : 0.018837, loss_ce: 0.007116
2022-01-21 22:45:00,345 iteration 5585 : loss : 0.015658, loss_ce: 0.005041
2022-01-21 22:45:01,480 iteration 5586 : loss : 0.016066, loss_ce: 0.007285
2022-01-21 22:45:02,738 iteration 5587 : loss : 0.018890, loss_ce: 0.008100
2022-01-21 22:45:03,915 iteration 5588 : loss : 0.019054, loss_ce: 0.008005
2022-01-21 22:45:05,159 iteration 5589 : loss : 0.021158, loss_ce: 0.006665
2022-01-21 22:45:06,289 iteration 5590 : loss : 0.014061, loss_ce: 0.006069
2022-01-21 22:45:07,493 iteration 5591 : loss : 0.026074, loss_ce: 0.008840
2022-01-21 22:45:08,692 iteration 5592 : loss : 0.019955, loss_ce: 0.007798
2022-01-21 22:45:09,798 iteration 5593 : loss : 0.015282, loss_ce: 0.007438
 82%|███████████████████████▊     | 329/400 [1:59:59<24:46, 20.94s/it]2022-01-21 22:45:11,035 iteration 5594 : loss : 0.016633, loss_ce: 0.004688
2022-01-21 22:45:12,170 iteration 5595 : loss : 0.013687, loss_ce: 0.004904
2022-01-21 22:45:13,422 iteration 5596 : loss : 0.032392, loss_ce: 0.009654
2022-01-21 22:45:14,630 iteration 5597 : loss : 0.018913, loss_ce: 0.008449
2022-01-21 22:45:15,930 iteration 5598 : loss : 0.028335, loss_ce: 0.013153
2022-01-21 22:45:17,194 iteration 5599 : loss : 0.016913, loss_ce: 0.005873
2022-01-21 22:45:18,328 iteration 5600 : loss : 0.013132, loss_ce: 0.004783
2022-01-21 22:45:19,531 iteration 5601 : loss : 0.017239, loss_ce: 0.005803
2022-01-21 22:45:20,722 iteration 5602 : loss : 0.017487, loss_ce: 0.006454
2022-01-21 22:45:21,913 iteration 5603 : loss : 0.024500, loss_ce: 0.011842
2022-01-21 22:45:23,104 iteration 5604 : loss : 0.025686, loss_ce: 0.007782
2022-01-21 22:45:24,251 iteration 5605 : loss : 0.016090, loss_ce: 0.007048
2022-01-21 22:45:25,473 iteration 5606 : loss : 0.027655, loss_ce: 0.009280
2022-01-21 22:45:26,606 iteration 5607 : loss : 0.017090, loss_ce: 0.007416
2022-01-21 22:45:27,822 iteration 5608 : loss : 0.014671, loss_ce: 0.007134
2022-01-21 22:45:28,966 iteration 5609 : loss : 0.014847, loss_ce: 0.005272
2022-01-21 22:45:28,966 Training Data Eval:
2022-01-21 22:45:34,647   Average segmentation loss on training set: 0.0110
2022-01-21 22:45:34,647 Validation Data Eval:
2022-01-21 22:45:36,617   Average segmentation loss on validation set: 0.0578
2022-01-21 22:45:37,831 iteration 5610 : loss : 0.028651, loss_ce: 0.011504
 82%|███████████████████████▉     | 330/400 [2:00:27<26:55, 23.07s/it]2022-01-21 22:45:39,024 iteration 5611 : loss : 0.012742, loss_ce: 0.004999
2022-01-21 22:45:40,255 iteration 5612 : loss : 0.024786, loss_ce: 0.007566
2022-01-21 22:45:41,411 iteration 5613 : loss : 0.022910, loss_ce: 0.004685
2022-01-21 22:45:42,572 iteration 5614 : loss : 0.018519, loss_ce: 0.006712
2022-01-21 22:45:43,747 iteration 5615 : loss : 0.019480, loss_ce: 0.009128
2022-01-21 22:45:44,928 iteration 5616 : loss : 0.015680, loss_ce: 0.004534
2022-01-21 22:45:46,256 iteration 5617 : loss : 0.029602, loss_ce: 0.010595
2022-01-21 22:45:47,491 iteration 5618 : loss : 0.014796, loss_ce: 0.004552
2022-01-21 22:45:48,690 iteration 5619 : loss : 0.014074, loss_ce: 0.006691
2022-01-21 22:45:49,820 iteration 5620 : loss : 0.015484, loss_ce: 0.005872
2022-01-21 22:45:50,943 iteration 5621 : loss : 0.018947, loss_ce: 0.007161
2022-01-21 22:45:52,035 iteration 5622 : loss : 0.013081, loss_ce: 0.005570
2022-01-21 22:45:53,268 iteration 5623 : loss : 0.013388, loss_ce: 0.004259
2022-01-21 22:45:54,433 iteration 5624 : loss : 0.016909, loss_ce: 0.005894
2022-01-21 22:45:55,599 iteration 5625 : loss : 0.016448, loss_ce: 0.007296
2022-01-21 22:45:56,801 iteration 5626 : loss : 0.016347, loss_ce: 0.005859
2022-01-21 22:45:57,979 iteration 5627 : loss : 0.013384, loss_ce: 0.005620
 83%|███████████████████████▉     | 331/400 [2:00:47<25:31, 22.19s/it]2022-01-21 22:45:59,220 iteration 5628 : loss : 0.015058, loss_ce: 0.007194
2022-01-21 22:46:00,413 iteration 5629 : loss : 0.018625, loss_ce: 0.006984
2022-01-21 22:46:01,620 iteration 5630 : loss : 0.018258, loss_ce: 0.007327
2022-01-21 22:46:02,836 iteration 5631 : loss : 0.018992, loss_ce: 0.010227
2022-01-21 22:46:04,101 iteration 5632 : loss : 0.019666, loss_ce: 0.007196
2022-01-21 22:46:05,204 iteration 5633 : loss : 0.020912, loss_ce: 0.005448
2022-01-21 22:46:06,441 iteration 5634 : loss : 0.028363, loss_ce: 0.007838
2022-01-21 22:46:07,623 iteration 5635 : loss : 0.014884, loss_ce: 0.005667
2022-01-21 22:46:08,734 iteration 5636 : loss : 0.028723, loss_ce: 0.007336
2022-01-21 22:46:09,993 iteration 5637 : loss : 0.019549, loss_ce: 0.008761
2022-01-21 22:46:11,178 iteration 5638 : loss : 0.016273, loss_ce: 0.007637
2022-01-21 22:46:12,378 iteration 5639 : loss : 0.018860, loss_ce: 0.006175
2022-01-21 22:46:13,563 iteration 5640 : loss : 0.023544, loss_ce: 0.008537
2022-01-21 22:46:14,696 iteration 5641 : loss : 0.013907, loss_ce: 0.004980
2022-01-21 22:46:15,986 iteration 5642 : loss : 0.016553, loss_ce: 0.007866
2022-01-21 22:46:17,095 iteration 5643 : loss : 0.015123, loss_ce: 0.007122
2022-01-21 22:46:18,259 iteration 5644 : loss : 0.019397, loss_ce: 0.008534
 83%|████████████████████████     | 332/400 [2:01:08<24:30, 21.62s/it]2022-01-21 22:46:19,439 iteration 5645 : loss : 0.018361, loss_ce: 0.005149
2022-01-21 22:46:20,602 iteration 5646 : loss : 0.016015, loss_ce: 0.004455
2022-01-21 22:46:21,717 iteration 5647 : loss : 0.012500, loss_ce: 0.004447
2022-01-21 22:46:22,898 iteration 5648 : loss : 0.018377, loss_ce: 0.009334
2022-01-21 22:46:24,034 iteration 5649 : loss : 0.012963, loss_ce: 0.003672
2022-01-21 22:46:25,277 iteration 5650 : loss : 0.017817, loss_ce: 0.006573
2022-01-21 22:46:26,445 iteration 5651 : loss : 0.018642, loss_ce: 0.007817
2022-01-21 22:46:27,638 iteration 5652 : loss : 0.017869, loss_ce: 0.005595
2022-01-21 22:46:28,815 iteration 5653 : loss : 0.018072, loss_ce: 0.004810
2022-01-21 22:46:29,989 iteration 5654 : loss : 0.016723, loss_ce: 0.006865
2022-01-21 22:46:31,084 iteration 5655 : loss : 0.016687, loss_ce: 0.008694
2022-01-21 22:46:32,345 iteration 5656 : loss : 0.027980, loss_ce: 0.010194
2022-01-21 22:46:33,581 iteration 5657 : loss : 0.021854, loss_ce: 0.007930
2022-01-21 22:46:34,817 iteration 5658 : loss : 0.064662, loss_ce: 0.038363
2022-01-21 22:46:35,962 iteration 5659 : loss : 0.018770, loss_ce: 0.008661
2022-01-21 22:46:37,169 iteration 5660 : loss : 0.033882, loss_ce: 0.010050
2022-01-21 22:46:38,350 iteration 5661 : loss : 0.019494, loss_ce: 0.007607
 83%|████████████████████████▏    | 333/400 [2:01:28<23:37, 21.16s/it]2022-01-21 22:46:39,584 iteration 5662 : loss : 0.019620, loss_ce: 0.008209
2022-01-21 22:46:40,729 iteration 5663 : loss : 0.021593, loss_ce: 0.007153
2022-01-21 22:46:41,914 iteration 5664 : loss : 0.020124, loss_ce: 0.008672
2022-01-21 22:46:43,046 iteration 5665 : loss : 0.014447, loss_ce: 0.005685
2022-01-21 22:46:44,239 iteration 5666 : loss : 0.018548, loss_ce: 0.006099
2022-01-21 22:46:45,473 iteration 5667 : loss : 0.015598, loss_ce: 0.006236
2022-01-21 22:46:46,665 iteration 5668 : loss : 0.019595, loss_ce: 0.007336
2022-01-21 22:46:47,791 iteration 5669 : loss : 0.017196, loss_ce: 0.006348
2022-01-21 22:46:48,946 iteration 5670 : loss : 0.022273, loss_ce: 0.007397
2022-01-21 22:46:50,084 iteration 5671 : loss : 0.015941, loss_ce: 0.006442
2022-01-21 22:46:51,358 iteration 5672 : loss : 0.026261, loss_ce: 0.011218
2022-01-21 22:46:52,523 iteration 5673 : loss : 0.024220, loss_ce: 0.009073
2022-01-21 22:46:53,699 iteration 5674 : loss : 0.019421, loss_ce: 0.005791
2022-01-21 22:46:54,840 iteration 5675 : loss : 0.013955, loss_ce: 0.006448
2022-01-21 22:46:56,077 iteration 5676 : loss : 0.020643, loss_ce: 0.008337
2022-01-21 22:46:57,247 iteration 5677 : loss : 0.022441, loss_ce: 0.006946
2022-01-21 22:46:58,516 iteration 5678 : loss : 0.017872, loss_ce: 0.007536
 84%|████████████████████████▏    | 334/400 [2:01:48<22:56, 20.86s/it]2022-01-21 22:46:59,795 iteration 5679 : loss : 0.017614, loss_ce: 0.006037
2022-01-21 22:47:00,940 iteration 5680 : loss : 0.018990, loss_ce: 0.008231
2022-01-21 22:47:02,138 iteration 5681 : loss : 0.016463, loss_ce: 0.006305
2022-01-21 22:47:03,305 iteration 5682 : loss : 0.016252, loss_ce: 0.006134
2022-01-21 22:47:04,524 iteration 5683 : loss : 0.022328, loss_ce: 0.008905
2022-01-21 22:47:05,778 iteration 5684 : loss : 0.021523, loss_ce: 0.007866
2022-01-21 22:47:07,008 iteration 5685 : loss : 0.015921, loss_ce: 0.004557
2022-01-21 22:47:08,192 iteration 5686 : loss : 0.023345, loss_ce: 0.010836
2022-01-21 22:47:09,340 iteration 5687 : loss : 0.012777, loss_ce: 0.003096
2022-01-21 22:47:10,511 iteration 5688 : loss : 0.021093, loss_ce: 0.006146
2022-01-21 22:47:11,677 iteration 5689 : loss : 0.018806, loss_ce: 0.009777
2022-01-21 22:47:12,884 iteration 5690 : loss : 0.019081, loss_ce: 0.009765
2022-01-21 22:47:14,039 iteration 5691 : loss : 0.013023, loss_ce: 0.003586
2022-01-21 22:47:15,189 iteration 5692 : loss : 0.012452, loss_ce: 0.004300
2022-01-21 22:47:16,395 iteration 5693 : loss : 0.024366, loss_ce: 0.011983
2022-01-21 22:47:17,617 iteration 5694 : loss : 0.020951, loss_ce: 0.008195
2022-01-21 22:47:17,617 Training Data Eval:
2022-01-21 22:47:23,321   Average segmentation loss on training set: 0.0101
2022-01-21 22:47:23,321 Validation Data Eval:
2022-01-21 22:47:25,292   Average segmentation loss on validation set: 0.0576
2022-01-21 22:47:26,442 iteration 5695 : loss : 0.018303, loss_ce: 0.006008
 84%|████████████████████████▎    | 335/400 [2:02:16<24:53, 22.98s/it]2022-01-21 22:47:27,662 iteration 5696 : loss : 0.014084, loss_ce: 0.004685
2022-01-21 22:47:28,909 iteration 5697 : loss : 0.018873, loss_ce: 0.007688
2022-01-21 22:47:30,099 iteration 5698 : loss : 0.017416, loss_ce: 0.006608
2022-01-21 22:47:31,352 iteration 5699 : loss : 0.022985, loss_ce: 0.007956
2022-01-21 22:47:32,538 iteration 5700 : loss : 0.019386, loss_ce: 0.007459
2022-01-21 22:47:33,705 iteration 5701 : loss : 0.019134, loss_ce: 0.009396
2022-01-21 22:47:34,908 iteration 5702 : loss : 0.015930, loss_ce: 0.005399
2022-01-21 22:47:36,082 iteration 5703 : loss : 0.012285, loss_ce: 0.005107
2022-01-21 22:47:37,295 iteration 5704 : loss : 0.029532, loss_ce: 0.015696
2022-01-21 22:47:38,499 iteration 5705 : loss : 0.014564, loss_ce: 0.004813
2022-01-21 22:47:39,650 iteration 5706 : loss : 0.015029, loss_ce: 0.003052
2022-01-21 22:47:40,949 iteration 5707 : loss : 0.026397, loss_ce: 0.010066
2022-01-21 22:47:42,123 iteration 5708 : loss : 0.017990, loss_ce: 0.008515
2022-01-21 22:47:43,326 iteration 5709 : loss : 0.021211, loss_ce: 0.010097
2022-01-21 22:47:44,599 iteration 5710 : loss : 0.020791, loss_ce: 0.008081
2022-01-21 22:47:45,753 iteration 5711 : loss : 0.033214, loss_ce: 0.023271
2022-01-21 22:47:46,917 iteration 5712 : loss : 0.018844, loss_ce: 0.008256
 84%|████████████████████████▎    | 336/400 [2:02:36<23:42, 22.23s/it]2022-01-21 22:47:48,117 iteration 5713 : loss : 0.015957, loss_ce: 0.004527
2022-01-21 22:47:49,267 iteration 5714 : loss : 0.014638, loss_ce: 0.005104
2022-01-21 22:47:50,415 iteration 5715 : loss : 0.020124, loss_ce: 0.008401
2022-01-21 22:47:51,608 iteration 5716 : loss : 0.016202, loss_ce: 0.007795
2022-01-21 22:47:52,833 iteration 5717 : loss : 0.016661, loss_ce: 0.006401
2022-01-21 22:47:53,954 iteration 5718 : loss : 0.020050, loss_ce: 0.006267
2022-01-21 22:47:55,159 iteration 5719 : loss : 0.012234, loss_ce: 0.004705
2022-01-21 22:47:56,311 iteration 5720 : loss : 0.020202, loss_ce: 0.008444
2022-01-21 22:47:57,396 iteration 5721 : loss : 0.012759, loss_ce: 0.003474
2022-01-21 22:47:58,560 iteration 5722 : loss : 0.014424, loss_ce: 0.004902
2022-01-21 22:47:59,724 iteration 5723 : loss : 0.021585, loss_ce: 0.011240
2022-01-21 22:48:00,821 iteration 5724 : loss : 0.012778, loss_ce: 0.004613
2022-01-21 22:48:02,027 iteration 5725 : loss : 0.016776, loss_ce: 0.007464
2022-01-21 22:48:03,154 iteration 5726 : loss : 0.014247, loss_ce: 0.006100
2022-01-21 22:48:04,324 iteration 5727 : loss : 0.015502, loss_ce: 0.005061
2022-01-21 22:48:05,479 iteration 5728 : loss : 0.018364, loss_ce: 0.008308
2022-01-21 22:48:06,686 iteration 5729 : loss : 0.015757, loss_ce: 0.005748
 84%|████████████████████████▍    | 337/400 [2:02:56<22:33, 21.49s/it]2022-01-21 22:48:07,936 iteration 5730 : loss : 0.018174, loss_ce: 0.004643
2022-01-21 22:48:09,168 iteration 5731 : loss : 0.011959, loss_ce: 0.004680
2022-01-21 22:48:10,340 iteration 5732 : loss : 0.017292, loss_ce: 0.004961
2022-01-21 22:48:11,489 iteration 5733 : loss : 0.015661, loss_ce: 0.004838
2022-01-21 22:48:12,670 iteration 5734 : loss : 0.020124, loss_ce: 0.005684
2022-01-21 22:48:13,853 iteration 5735 : loss : 0.019484, loss_ce: 0.010961
2022-01-21 22:48:15,022 iteration 5736 : loss : 0.016670, loss_ce: 0.009085
2022-01-21 22:48:16,183 iteration 5737 : loss : 0.028092, loss_ce: 0.015670
2022-01-21 22:48:17,335 iteration 5738 : loss : 0.010035, loss_ce: 0.004111
2022-01-21 22:48:18,456 iteration 5739 : loss : 0.013809, loss_ce: 0.005762
2022-01-21 22:48:19,663 iteration 5740 : loss : 0.034788, loss_ce: 0.014153
2022-01-21 22:48:20,852 iteration 5741 : loss : 0.020903, loss_ce: 0.012532
2022-01-21 22:48:22,043 iteration 5742 : loss : 0.017722, loss_ce: 0.007285
2022-01-21 22:48:23,192 iteration 5743 : loss : 0.013328, loss_ce: 0.005544
2022-01-21 22:48:24,419 iteration 5744 : loss : 0.015651, loss_ce: 0.006455
2022-01-21 22:48:25,602 iteration 5745 : loss : 0.019329, loss_ce: 0.005228
2022-01-21 22:48:26,714 iteration 5746 : loss : 0.021840, loss_ce: 0.005206
 84%|████████████████████████▌    | 338/400 [2:03:16<21:45, 21.05s/it]2022-01-21 22:48:27,982 iteration 5747 : loss : 0.016816, loss_ce: 0.005496
2022-01-21 22:48:29,202 iteration 5748 : loss : 0.017866, loss_ce: 0.006916
2022-01-21 22:48:30,428 iteration 5749 : loss : 0.016007, loss_ce: 0.006651
2022-01-21 22:48:31,695 iteration 5750 : loss : 0.022500, loss_ce: 0.007549
2022-01-21 22:48:32,818 iteration 5751 : loss : 0.020551, loss_ce: 0.007666
2022-01-21 22:48:34,029 iteration 5752 : loss : 0.015702, loss_ce: 0.005118
2022-01-21 22:48:35,196 iteration 5753 : loss : 0.019849, loss_ce: 0.007235
2022-01-21 22:48:36,309 iteration 5754 : loss : 0.013351, loss_ce: 0.005192
2022-01-21 22:48:37,489 iteration 5755 : loss : 0.017948, loss_ce: 0.008974
2022-01-21 22:48:38,669 iteration 5756 : loss : 0.017475, loss_ce: 0.005670
2022-01-21 22:48:39,830 iteration 5757 : loss : 0.014257, loss_ce: 0.007023
2022-01-21 22:48:41,008 iteration 5758 : loss : 0.026091, loss_ce: 0.005182
2022-01-21 22:48:42,211 iteration 5759 : loss : 0.014617, loss_ce: 0.006738
2022-01-21 22:48:43,465 iteration 5760 : loss : 0.023679, loss_ce: 0.008870
2022-01-21 22:48:44,574 iteration 5761 : loss : 0.012149, loss_ce: 0.004388
2022-01-21 22:48:45,919 iteration 5762 : loss : 0.020471, loss_ce: 0.007914
2022-01-21 22:48:47,097 iteration 5763 : loss : 0.018484, loss_ce: 0.007295
 85%|████████████████████████▌    | 339/400 [2:03:37<21:12, 20.85s/it]2022-01-21 22:48:48,349 iteration 5764 : loss : 0.023545, loss_ce: 0.009890
2022-01-21 22:48:49,573 iteration 5765 : loss : 0.018363, loss_ce: 0.005566
2022-01-21 22:48:50,766 iteration 5766 : loss : 0.013449, loss_ce: 0.005507
2022-01-21 22:48:51,972 iteration 5767 : loss : 0.016516, loss_ce: 0.006859
2022-01-21 22:48:53,268 iteration 5768 : loss : 0.028623, loss_ce: 0.010156
2022-01-21 22:48:54,448 iteration 5769 : loss : 0.012898, loss_ce: 0.004833
2022-01-21 22:48:55,628 iteration 5770 : loss : 0.019516, loss_ce: 0.008015
2022-01-21 22:48:56,809 iteration 5771 : loss : 0.017521, loss_ce: 0.007835
2022-01-21 22:48:58,002 iteration 5772 : loss : 0.021338, loss_ce: 0.007924
2022-01-21 22:48:59,268 iteration 5773 : loss : 0.017558, loss_ce: 0.006992
2022-01-21 22:49:00,523 iteration 5774 : loss : 0.022216, loss_ce: 0.010592
2022-01-21 22:49:01,803 iteration 5775 : loss : 0.021533, loss_ce: 0.007184
2022-01-21 22:49:02,949 iteration 5776 : loss : 0.019656, loss_ce: 0.007998
2022-01-21 22:49:04,105 iteration 5777 : loss : 0.016805, loss_ce: 0.006663
2022-01-21 22:49:05,320 iteration 5778 : loss : 0.021229, loss_ce: 0.006654
2022-01-21 22:49:06,501 iteration 5779 : loss : 0.014791, loss_ce: 0.005943
2022-01-21 22:49:06,501 Training Data Eval:
2022-01-21 22:49:12,188   Average segmentation loss on training set: 0.0099
2022-01-21 22:49:12,188 Validation Data Eval:
2022-01-21 22:49:14,153   Average segmentation loss on validation set: 0.0606
2022-01-21 22:49:15,370 iteration 5780 : loss : 0.015358, loss_ce: 0.006168
 85%|████████████████████████▋    | 340/400 [2:04:05<23:04, 23.08s/it]2022-01-21 22:49:16,731 iteration 5781 : loss : 0.037068, loss_ce: 0.013880
2022-01-21 22:49:17,833 iteration 5782 : loss : 0.013233, loss_ce: 0.006493
2022-01-21 22:49:18,964 iteration 5783 : loss : 0.016836, loss_ce: 0.006510
2022-01-21 22:49:20,103 iteration 5784 : loss : 0.016327, loss_ce: 0.006121
2022-01-21 22:49:21,209 iteration 5785 : loss : 0.013895, loss_ce: 0.006225
2022-01-21 22:49:22,398 iteration 5786 : loss : 0.021224, loss_ce: 0.004783
2022-01-21 22:49:23,559 iteration 5787 : loss : 0.017755, loss_ce: 0.007078
2022-01-21 22:49:24,643 iteration 5788 : loss : 0.019629, loss_ce: 0.007267
2022-01-21 22:49:25,745 iteration 5789 : loss : 0.011255, loss_ce: 0.004398
2022-01-21 22:49:26,940 iteration 5790 : loss : 0.011818, loss_ce: 0.004336
2022-01-21 22:49:28,102 iteration 5791 : loss : 0.014302, loss_ce: 0.006126
2022-01-21 22:49:29,227 iteration 5792 : loss : 0.013217, loss_ce: 0.004968
2022-01-21 22:49:30,442 iteration 5793 : loss : 0.018786, loss_ce: 0.006592
2022-01-21 22:49:31,694 iteration 5794 : loss : 0.017914, loss_ce: 0.008071
2022-01-21 22:49:32,830 iteration 5795 : loss : 0.010710, loss_ce: 0.004339
2022-01-21 22:49:34,022 iteration 5796 : loss : 0.013805, loss_ce: 0.006282
2022-01-21 22:49:35,207 iteration 5797 : loss : 0.035197, loss_ce: 0.018439
 85%|████████████████████████▋    | 341/400 [2:04:25<21:44, 22.11s/it]2022-01-21 22:49:36,532 iteration 5798 : loss : 0.014277, loss_ce: 0.004162
2022-01-21 22:49:37,708 iteration 5799 : loss : 0.015428, loss_ce: 0.004675
2022-01-21 22:49:38,871 iteration 5800 : loss : 0.015906, loss_ce: 0.004761
2022-01-21 22:49:39,961 iteration 5801 : loss : 0.011060, loss_ce: 0.003989
2022-01-21 22:49:41,163 iteration 5802 : loss : 0.014108, loss_ce: 0.006727
2022-01-21 22:49:42,270 iteration 5803 : loss : 0.013314, loss_ce: 0.004588
2022-01-21 22:49:43,546 iteration 5804 : loss : 0.024714, loss_ce: 0.009608
2022-01-21 22:49:44,697 iteration 5805 : loss : 0.020206, loss_ce: 0.010203
2022-01-21 22:49:45,821 iteration 5806 : loss : 0.014375, loss_ce: 0.005225
2022-01-21 22:49:47,013 iteration 5807 : loss : 0.014470, loss_ce: 0.005568
2022-01-21 22:49:48,166 iteration 5808 : loss : 0.016454, loss_ce: 0.006936
2022-01-21 22:49:49,432 iteration 5809 : loss : 0.023482, loss_ce: 0.008238
2022-01-21 22:49:50,548 iteration 5810 : loss : 0.018513, loss_ce: 0.005051
2022-01-21 22:49:51,714 iteration 5811 : loss : 0.014194, loss_ce: 0.005877
2022-01-21 22:49:52,917 iteration 5812 : loss : 0.025730, loss_ce: 0.010784
2022-01-21 22:49:54,052 iteration 5813 : loss : 0.015433, loss_ce: 0.004686
2022-01-21 22:49:55,228 iteration 5814 : loss : 0.017193, loss_ce: 0.007319
 86%|████████████████████████▊    | 342/400 [2:04:45<20:45, 21.48s/it]2022-01-21 22:49:56,569 iteration 5815 : loss : 0.024818, loss_ce: 0.010466
2022-01-21 22:49:57,693 iteration 5816 : loss : 0.014673, loss_ce: 0.004647
2022-01-21 22:49:58,880 iteration 5817 : loss : 0.014042, loss_ce: 0.003856
2022-01-21 22:50:00,037 iteration 5818 : loss : 0.015555, loss_ce: 0.005035
2022-01-21 22:50:01,308 iteration 5819 : loss : 0.017143, loss_ce: 0.007209
2022-01-21 22:50:02,487 iteration 5820 : loss : 0.014865, loss_ce: 0.007302
2022-01-21 22:50:03,653 iteration 5821 : loss : 0.017964, loss_ce: 0.005971
2022-01-21 22:50:04,899 iteration 5822 : loss : 0.017677, loss_ce: 0.005129
2022-01-21 22:50:06,097 iteration 5823 : loss : 0.014339, loss_ce: 0.004949
2022-01-21 22:50:07,282 iteration 5824 : loss : 0.012410, loss_ce: 0.004959
2022-01-21 22:50:08,455 iteration 5825 : loss : 0.015723, loss_ce: 0.006752
2022-01-21 22:50:09,600 iteration 5826 : loss : 0.017505, loss_ce: 0.005630
2022-01-21 22:50:10,727 iteration 5827 : loss : 0.020901, loss_ce: 0.005416
2022-01-21 22:50:11,816 iteration 5828 : loss : 0.010377, loss_ce: 0.004549
2022-01-21 22:50:12,991 iteration 5829 : loss : 0.014176, loss_ce: 0.005619
2022-01-21 22:50:14,184 iteration 5830 : loss : 0.019585, loss_ce: 0.007534
2022-01-21 22:50:15,416 iteration 5831 : loss : 0.017510, loss_ce: 0.006700
 86%|████████████████████████▊    | 343/400 [2:05:05<20:02, 21.09s/it]2022-01-21 22:50:16,740 iteration 5832 : loss : 0.019535, loss_ce: 0.008595
2022-01-21 22:50:17,901 iteration 5833 : loss : 0.011286, loss_ce: 0.003779
2022-01-21 22:50:19,156 iteration 5834 : loss : 0.021425, loss_ce: 0.009413
2022-01-21 22:50:20,491 iteration 5835 : loss : 0.037139, loss_ce: 0.019779
2022-01-21 22:50:21,659 iteration 5836 : loss : 0.019720, loss_ce: 0.007921
2022-01-21 22:50:22,921 iteration 5837 : loss : 0.020148, loss_ce: 0.009188
2022-01-21 22:50:24,178 iteration 5838 : loss : 0.044872, loss_ce: 0.017038
2022-01-21 22:50:25,296 iteration 5839 : loss : 0.015435, loss_ce: 0.005251
2022-01-21 22:50:26,661 iteration 5840 : loss : 0.026224, loss_ce: 0.014057
2022-01-21 22:50:27,841 iteration 5841 : loss : 0.012179, loss_ce: 0.004589
2022-01-21 22:50:29,095 iteration 5842 : loss : 0.017033, loss_ce: 0.006795
2022-01-21 22:50:30,349 iteration 5843 : loss : 0.018534, loss_ce: 0.005413
2022-01-21 22:50:31,558 iteration 5844 : loss : 0.019087, loss_ce: 0.005422
2022-01-21 22:50:32,793 iteration 5845 : loss : 0.021029, loss_ce: 0.007454
2022-01-21 22:50:33,985 iteration 5846 : loss : 0.014520, loss_ce: 0.006838
2022-01-21 22:50:35,160 iteration 5847 : loss : 0.036261, loss_ce: 0.011270
2022-01-21 22:50:36,269 iteration 5848 : loss : 0.014745, loss_ce: 0.004505
 86%|████████████████████████▉    | 344/400 [2:05:26<19:37, 21.02s/it]2022-01-21 22:50:37,445 iteration 5849 : loss : 0.018354, loss_ce: 0.005981
2022-01-21 22:50:38,689 iteration 5850 : loss : 0.025647, loss_ce: 0.007008
2022-01-21 22:50:39,830 iteration 5851 : loss : 0.014366, loss_ce: 0.006061
2022-01-21 22:50:40,977 iteration 5852 : loss : 0.018332, loss_ce: 0.005874
2022-01-21 22:50:42,094 iteration 5853 : loss : 0.035691, loss_ce: 0.008164
2022-01-21 22:50:43,261 iteration 5854 : loss : 0.018740, loss_ce: 0.006926
2022-01-21 22:50:44,419 iteration 5855 : loss : 0.017873, loss_ce: 0.004947
2022-01-21 22:50:45,542 iteration 5856 : loss : 0.014226, loss_ce: 0.006400
2022-01-21 22:50:46,744 iteration 5857 : loss : 0.018760, loss_ce: 0.008525
2022-01-21 22:50:47,903 iteration 5858 : loss : 0.019863, loss_ce: 0.004850
2022-01-21 22:50:49,107 iteration 5859 : loss : 0.021119, loss_ce: 0.009972
2022-01-21 22:50:50,309 iteration 5860 : loss : 0.013842, loss_ce: 0.005115
2022-01-21 22:50:51,510 iteration 5861 : loss : 0.018051, loss_ce: 0.008466
2022-01-21 22:50:52,674 iteration 5862 : loss : 0.019166, loss_ce: 0.006955
2022-01-21 22:50:53,844 iteration 5863 : loss : 0.018123, loss_ce: 0.007078
2022-01-21 22:50:55,005 iteration 5864 : loss : 0.022772, loss_ce: 0.009136
2022-01-21 22:50:55,005 Training Data Eval:
2022-01-21 22:51:00,729   Average segmentation loss on training set: 0.0110
2022-01-21 22:51:00,729 Validation Data Eval:
2022-01-21 22:51:02,708   Average segmentation loss on validation set: 0.0670
2022-01-21 22:51:03,852 iteration 5865 : loss : 0.014805, loss_ce: 0.005302
 86%|█████████████████████████    | 345/400 [2:05:53<21:04, 22.99s/it]2022-01-21 22:51:05,101 iteration 5866 : loss : 0.017391, loss_ce: 0.006301
2022-01-21 22:51:06,291 iteration 5867 : loss : 0.020098, loss_ce: 0.009035
2022-01-21 22:51:07,401 iteration 5868 : loss : 0.013287, loss_ce: 0.005065
2022-01-21 22:51:08,552 iteration 5869 : loss : 0.011719, loss_ce: 0.004141
2022-01-21 22:51:09,649 iteration 5870 : loss : 0.014886, loss_ce: 0.005420
2022-01-21 22:51:10,806 iteration 5871 : loss : 0.015715, loss_ce: 0.006750
2022-01-21 22:51:11,962 iteration 5872 : loss : 0.013520, loss_ce: 0.005546
2022-01-21 22:51:13,073 iteration 5873 : loss : 0.013607, loss_ce: 0.006380
2022-01-21 22:51:14,190 iteration 5874 : loss : 0.030775, loss_ce: 0.007249
2022-01-21 22:51:15,428 iteration 5875 : loss : 0.017243, loss_ce: 0.008358
2022-01-21 22:51:16,691 iteration 5876 : loss : 0.023352, loss_ce: 0.010548
2022-01-21 22:51:17,893 iteration 5877 : loss : 0.030568, loss_ce: 0.012012
2022-01-21 22:51:19,116 iteration 5878 : loss : 0.044444, loss_ce: 0.014089
2022-01-21 22:51:20,265 iteration 5879 : loss : 0.022922, loss_ce: 0.006889
2022-01-21 22:51:21,426 iteration 5880 : loss : 0.017098, loss_ce: 0.006626
2022-01-21 22:51:22,641 iteration 5881 : loss : 0.050816, loss_ce: 0.014458
2022-01-21 22:51:23,799 iteration 5882 : loss : 0.014823, loss_ce: 0.005352
 86%|█████████████████████████    | 346/400 [2:06:13<19:52, 22.08s/it]2022-01-21 22:51:25,132 iteration 5883 : loss : 0.030706, loss_ce: 0.011469
2022-01-21 22:51:26,275 iteration 5884 : loss : 0.018663, loss_ce: 0.008329
2022-01-21 22:51:27,512 iteration 5885 : loss : 0.027543, loss_ce: 0.009636
2022-01-21 22:51:28,657 iteration 5886 : loss : 0.011206, loss_ce: 0.003528
2022-01-21 22:51:29,808 iteration 5887 : loss : 0.022023, loss_ce: 0.006024
2022-01-21 22:51:30,900 iteration 5888 : loss : 0.013858, loss_ce: 0.005698
2022-01-21 22:51:32,048 iteration 5889 : loss : 0.016968, loss_ce: 0.007345
2022-01-21 22:51:33,264 iteration 5890 : loss : 0.019721, loss_ce: 0.008158
2022-01-21 22:51:34,489 iteration 5891 : loss : 0.024211, loss_ce: 0.007604
2022-01-21 22:51:35,740 iteration 5892 : loss : 0.016128, loss_ce: 0.008003
2022-01-21 22:51:36,845 iteration 5893 : loss : 0.014203, loss_ce: 0.003801
2022-01-21 22:51:37,981 iteration 5894 : loss : 0.015347, loss_ce: 0.004226
2022-01-21 22:51:39,188 iteration 5895 : loss : 0.021833, loss_ce: 0.008544
2022-01-21 22:51:40,283 iteration 5896 : loss : 0.014017, loss_ce: 0.004534
2022-01-21 22:51:41,473 iteration 5897 : loss : 0.018079, loss_ce: 0.008126
2022-01-21 22:51:42,706 iteration 5898 : loss : 0.020310, loss_ce: 0.008063
2022-01-21 22:51:43,864 iteration 5899 : loss : 0.017504, loss_ce: 0.005926
 87%|█████████████████████████▏   | 347/400 [2:06:33<18:58, 21.47s/it]2022-01-21 22:51:45,004 iteration 5900 : loss : 0.012470, loss_ce: 0.005010
2022-01-21 22:51:46,139 iteration 5901 : loss : 0.013118, loss_ce: 0.005507
2022-01-21 22:51:47,233 iteration 5902 : loss : 0.012480, loss_ce: 0.004844
2022-01-21 22:51:48,370 iteration 5903 : loss : 0.016184, loss_ce: 0.006740
2022-01-21 22:51:49,554 iteration 5904 : loss : 0.020855, loss_ce: 0.005669
2022-01-21 22:51:50,774 iteration 5905 : loss : 0.020819, loss_ce: 0.010297
2022-01-21 22:51:52,009 iteration 5906 : loss : 0.020927, loss_ce: 0.005335
2022-01-21 22:51:53,124 iteration 5907 : loss : 0.012909, loss_ce: 0.005544
2022-01-21 22:51:54,298 iteration 5908 : loss : 0.020961, loss_ce: 0.006957
2022-01-21 22:51:55,514 iteration 5909 : loss : 0.016252, loss_ce: 0.008409
2022-01-21 22:51:56,691 iteration 5910 : loss : 0.012515, loss_ce: 0.004108
2022-01-21 22:51:57,906 iteration 5911 : loss : 0.019456, loss_ce: 0.004314
2022-01-21 22:51:59,105 iteration 5912 : loss : 0.019155, loss_ce: 0.004679
2022-01-21 22:52:00,273 iteration 5913 : loss : 0.014835, loss_ce: 0.006236
2022-01-21 22:52:01,429 iteration 5914 : loss : 0.015064, loss_ce: 0.007325
2022-01-21 22:52:02,634 iteration 5915 : loss : 0.015195, loss_ce: 0.008115
2022-01-21 22:52:03,757 iteration 5916 : loss : 0.016279, loss_ce: 0.005375
 87%|█████████████████████████▏   | 348/400 [2:06:53<18:11, 21.00s/it]2022-01-21 22:52:04,939 iteration 5917 : loss : 0.014467, loss_ce: 0.005883
2022-01-21 22:52:06,186 iteration 5918 : loss : 0.024328, loss_ce: 0.011696
2022-01-21 22:52:07,437 iteration 5919 : loss : 0.018080, loss_ce: 0.006438
2022-01-21 22:52:08,689 iteration 5920 : loss : 0.016343, loss_ce: 0.005679
2022-01-21 22:52:09,859 iteration 5921 : loss : 0.020820, loss_ce: 0.007061
2022-01-21 22:52:11,079 iteration 5922 : loss : 0.015127, loss_ce: 0.007407
2022-01-21 22:52:12,273 iteration 5923 : loss : 0.022867, loss_ce: 0.009050
2022-01-21 22:52:13,377 iteration 5924 : loss : 0.013855, loss_ce: 0.004838
2022-01-21 22:52:14,543 iteration 5925 : loss : 0.016651, loss_ce: 0.005565
2022-01-21 22:52:15,785 iteration 5926 : loss : 0.031337, loss_ce: 0.012254
2022-01-21 22:52:16,923 iteration 5927 : loss : 0.011995, loss_ce: 0.005171
2022-01-21 22:52:18,162 iteration 5928 : loss : 0.014759, loss_ce: 0.006279
2022-01-21 22:52:19,371 iteration 5929 : loss : 0.019069, loss_ce: 0.008831
2022-01-21 22:52:20,620 iteration 5930 : loss : 0.018621, loss_ce: 0.007554
2022-01-21 22:52:21,756 iteration 5931 : loss : 0.017807, loss_ce: 0.007891
2022-01-21 22:52:22,949 iteration 5932 : loss : 0.016286, loss_ce: 0.005459
2022-01-21 22:52:24,176 iteration 5933 : loss : 0.026064, loss_ce: 0.007293
 87%|█████████████████████████▎   | 349/400 [2:07:14<17:41, 20.82s/it]2022-01-21 22:52:25,415 iteration 5934 : loss : 0.012141, loss_ce: 0.003869
2022-01-21 22:52:26,614 iteration 5935 : loss : 0.014003, loss_ce: 0.004131
2022-01-21 22:52:27,909 iteration 5936 : loss : 0.022813, loss_ce: 0.007784
2022-01-21 22:52:29,176 iteration 5937 : loss : 0.035904, loss_ce: 0.015281
2022-01-21 22:52:30,378 iteration 5938 : loss : 0.028131, loss_ce: 0.011369
2022-01-21 22:52:31,543 iteration 5939 : loss : 0.018353, loss_ce: 0.008032
2022-01-21 22:52:32,750 iteration 5940 : loss : 0.016065, loss_ce: 0.007427
2022-01-21 22:52:33,846 iteration 5941 : loss : 0.013397, loss_ce: 0.006218
2022-01-21 22:52:35,062 iteration 5942 : loss : 0.018689, loss_ce: 0.005947
2022-01-21 22:52:36,179 iteration 5943 : loss : 0.011014, loss_ce: 0.004075
2022-01-21 22:52:37,354 iteration 5944 : loss : 0.017429, loss_ce: 0.006369
2022-01-21 22:52:38,518 iteration 5945 : loss : 0.015812, loss_ce: 0.005074
2022-01-21 22:52:39,642 iteration 5946 : loss : 0.019382, loss_ce: 0.007195
2022-01-21 22:52:40,762 iteration 5947 : loss : 0.019306, loss_ce: 0.007320
2022-01-21 22:52:41,998 iteration 5948 : loss : 0.018188, loss_ce: 0.007681
2022-01-21 22:52:43,133 iteration 5949 : loss : 0.012701, loss_ce: 0.005391
2022-01-21 22:52:43,133 Training Data Eval:
2022-01-21 22:52:48,817   Average segmentation loss on training set: 0.0095
2022-01-21 22:52:48,817 Validation Data Eval:
2022-01-21 22:52:50,784   Average segmentation loss on validation set: 0.0638
2022-01-21 22:52:52,028 iteration 5950 : loss : 0.015895, loss_ce: 0.004601
 88%|█████████████████████████▍   | 350/400 [2:07:41<19:06, 22.93s/it]2022-01-21 22:52:53,222 iteration 5951 : loss : 0.015289, loss_ce: 0.004793
2022-01-21 22:52:54,412 iteration 5952 : loss : 0.014886, loss_ce: 0.007820
2022-01-21 22:52:55,608 iteration 5953 : loss : 0.023407, loss_ce: 0.009784
2022-01-21 22:52:56,862 iteration 5954 : loss : 0.024690, loss_ce: 0.007701
2022-01-21 22:52:58,027 iteration 5955 : loss : 0.015126, loss_ce: 0.005494
2022-01-21 22:52:59,278 iteration 5956 : loss : 0.017278, loss_ce: 0.005395
2022-01-21 22:53:00,443 iteration 5957 : loss : 0.017311, loss_ce: 0.004849
2022-01-21 22:53:01,584 iteration 5958 : loss : 0.019933, loss_ce: 0.008642
2022-01-21 22:53:02,752 iteration 5959 : loss : 0.013869, loss_ce: 0.004589
2022-01-21 22:53:03,886 iteration 5960 : loss : 0.009843, loss_ce: 0.003126
2022-01-21 22:53:05,077 iteration 5961 : loss : 0.018699, loss_ce: 0.007248
2022-01-21 22:53:06,305 iteration 5962 : loss : 0.019326, loss_ce: 0.008233
2022-01-21 22:53:07,416 iteration 5963 : loss : 0.011953, loss_ce: 0.005180
2022-01-21 22:53:08,755 iteration 5964 : loss : 0.025605, loss_ce: 0.009909
2022-01-21 22:53:09,918 iteration 5965 : loss : 0.014600, loss_ce: 0.005204
2022-01-21 22:53:11,143 iteration 5966 : loss : 0.021257, loss_ce: 0.007902
2022-01-21 22:53:12,293 iteration 5967 : loss : 0.020980, loss_ce: 0.007161
 88%|█████████████████████████▍   | 351/400 [2:08:02<18:04, 22.13s/it]2022-01-21 22:53:13,498 iteration 5968 : loss : 0.015458, loss_ce: 0.006942
2022-01-21 22:53:14,720 iteration 5969 : loss : 0.026998, loss_ce: 0.006848
2022-01-21 22:53:15,909 iteration 5970 : loss : 0.016233, loss_ce: 0.005819
2022-01-21 22:53:17,007 iteration 5971 : loss : 0.012504, loss_ce: 0.005025
2022-01-21 22:53:18,151 iteration 5972 : loss : 0.014808, loss_ce: 0.005798
2022-01-21 22:53:19,338 iteration 5973 : loss : 0.011529, loss_ce: 0.005088
2022-01-21 22:53:20,466 iteration 5974 : loss : 0.014983, loss_ce: 0.005089
2022-01-21 22:53:21,675 iteration 5975 : loss : 0.018223, loss_ce: 0.005807
2022-01-21 22:53:22,868 iteration 5976 : loss : 0.025928, loss_ce: 0.006725
2022-01-21 22:53:24,071 iteration 5977 : loss : 0.015205, loss_ce: 0.005690
2022-01-21 22:53:25,258 iteration 5978 : loss : 0.016114, loss_ce: 0.007190
2022-01-21 22:53:26,399 iteration 5979 : loss : 0.013339, loss_ce: 0.005794
2022-01-21 22:53:27,625 iteration 5980 : loss : 0.011391, loss_ce: 0.003910
2022-01-21 22:53:28,835 iteration 5981 : loss : 0.017934, loss_ce: 0.006780
2022-01-21 22:53:30,069 iteration 5982 : loss : 0.023239, loss_ce: 0.008307
2022-01-21 22:53:31,188 iteration 5983 : loss : 0.017284, loss_ce: 0.008308
2022-01-21 22:53:32,323 iteration 5984 : loss : 0.023570, loss_ce: 0.006527
 88%|█████████████████████████▌   | 352/400 [2:08:22<17:12, 21.50s/it]2022-01-21 22:53:33,644 iteration 5985 : loss : 0.026282, loss_ce: 0.012328
2022-01-21 22:53:34,801 iteration 5986 : loss : 0.013042, loss_ce: 0.005359
2022-01-21 22:53:36,033 iteration 5987 : loss : 0.042682, loss_ce: 0.005674
2022-01-21 22:53:37,299 iteration 5988 : loss : 0.015206, loss_ce: 0.007092
2022-01-21 22:53:38,465 iteration 5989 : loss : 0.016974, loss_ce: 0.007141
2022-01-21 22:53:39,674 iteration 5990 : loss : 0.039079, loss_ce: 0.022475
2022-01-21 22:53:40,771 iteration 5991 : loss : 0.012832, loss_ce: 0.004463
2022-01-21 22:53:41,988 iteration 5992 : loss : 0.022259, loss_ce: 0.006175
2022-01-21 22:53:43,116 iteration 5993 : loss : 0.009776, loss_ce: 0.003107
2022-01-21 22:53:44,278 iteration 5994 : loss : 0.020596, loss_ce: 0.006398
2022-01-21 22:53:45,486 iteration 5995 : loss : 0.024204, loss_ce: 0.009229
2022-01-21 22:53:46,740 iteration 5996 : loss : 0.016943, loss_ce: 0.005509
2022-01-21 22:53:47,998 iteration 5997 : loss : 0.020651, loss_ce: 0.008952
2022-01-21 22:53:49,139 iteration 5998 : loss : 0.013475, loss_ce: 0.004597
2022-01-21 22:53:50,343 iteration 5999 : loss : 0.028171, loss_ce: 0.008129
2022-01-21 22:53:51,550 iteration 6000 : loss : 0.022208, loss_ce: 0.009558
2022-01-21 22:53:52,798 iteration 6001 : loss : 0.027339, loss_ce: 0.009386
 88%|█████████████████████████▌   | 353/400 [2:08:42<16:36, 21.19s/it]2022-01-21 22:53:54,038 iteration 6002 : loss : 0.014891, loss_ce: 0.006721
2022-01-21 22:53:55,271 iteration 6003 : loss : 0.018474, loss_ce: 0.006116
2022-01-21 22:53:56,458 iteration 6004 : loss : 0.017447, loss_ce: 0.008306
2022-01-21 22:53:57,682 iteration 6005 : loss : 0.018608, loss_ce: 0.007681
2022-01-21 22:53:58,806 iteration 6006 : loss : 0.014214, loss_ce: 0.006989
2022-01-21 22:53:59,985 iteration 6007 : loss : 0.014661, loss_ce: 0.005685
2022-01-21 22:54:01,161 iteration 6008 : loss : 0.014126, loss_ce: 0.004876
2022-01-21 22:54:02,423 iteration 6009 : loss : 0.021566, loss_ce: 0.008813
2022-01-21 22:54:03,523 iteration 6010 : loss : 0.012252, loss_ce: 0.004962
2022-01-21 22:54:04,723 iteration 6011 : loss : 0.018783, loss_ce: 0.006803
2022-01-21 22:54:05,900 iteration 6012 : loss : 0.022575, loss_ce: 0.007216
2022-01-21 22:54:07,177 iteration 6013 : loss : 0.022660, loss_ce: 0.008489
2022-01-21 22:54:08,350 iteration 6014 : loss : 0.017600, loss_ce: 0.006415
2022-01-21 22:54:09,492 iteration 6015 : loss : 0.019108, loss_ce: 0.006645
2022-01-21 22:54:10,677 iteration 6016 : loss : 0.014970, loss_ce: 0.004173
2022-01-21 22:54:11,803 iteration 6017 : loss : 0.021254, loss_ce: 0.005298
2022-01-21 22:54:13,071 iteration 6018 : loss : 0.017983, loss_ce: 0.006229
 88%|█████████████████████████▋   | 354/400 [2:09:02<16:02, 20.92s/it]2022-01-21 22:54:14,334 iteration 6019 : loss : 0.020900, loss_ce: 0.007495
2022-01-21 22:54:15,514 iteration 6020 : loss : 0.015212, loss_ce: 0.006822
2022-01-21 22:54:16,687 iteration 6021 : loss : 0.013853, loss_ce: 0.004592
2022-01-21 22:54:17,890 iteration 6022 : loss : 0.015245, loss_ce: 0.006131
2022-01-21 22:54:18,987 iteration 6023 : loss : 0.011085, loss_ce: 0.003795
2022-01-21 22:54:20,225 iteration 6024 : loss : 0.020119, loss_ce: 0.008300
2022-01-21 22:54:21,456 iteration 6025 : loss : 0.019580, loss_ce: 0.007653
2022-01-21 22:54:22,677 iteration 6026 : loss : 0.017381, loss_ce: 0.005574
2022-01-21 22:54:23,832 iteration 6027 : loss : 0.014188, loss_ce: 0.005930
2022-01-21 22:54:24,974 iteration 6028 : loss : 0.014559, loss_ce: 0.006044
2022-01-21 22:54:26,200 iteration 6029 : loss : 0.020282, loss_ce: 0.008045
2022-01-21 22:54:27,334 iteration 6030 : loss : 0.013695, loss_ce: 0.004673
2022-01-21 22:54:28,615 iteration 6031 : loss : 0.023126, loss_ce: 0.006107
2022-01-21 22:54:29,838 iteration 6032 : loss : 0.014018, loss_ce: 0.004316
2022-01-21 22:54:31,056 iteration 6033 : loss : 0.019913, loss_ce: 0.008981
2022-01-21 22:54:32,317 iteration 6034 : loss : 0.014230, loss_ce: 0.004180
2022-01-21 22:54:32,317 Training Data Eval:
2022-01-21 22:54:38,016   Average segmentation loss on training set: 0.0094
2022-01-21 22:54:38,016 Validation Data Eval:
2022-01-21 22:54:39,992   Average segmentation loss on validation set: 0.0582
2022-01-21 22:54:41,121 iteration 6035 : loss : 0.014557, loss_ce: 0.003591
 89%|█████████████████████████▋   | 355/400 [2:09:31<17:17, 23.06s/it]2022-01-21 22:54:42,371 iteration 6036 : loss : 0.017158, loss_ce: 0.005950
2022-01-21 22:54:43,627 iteration 6037 : loss : 0.018552, loss_ce: 0.006637
2022-01-21 22:54:44,776 iteration 6038 : loss : 0.019040, loss_ce: 0.007395
2022-01-21 22:54:45,963 iteration 6039 : loss : 0.019261, loss_ce: 0.009840
2022-01-21 22:54:47,141 iteration 6040 : loss : 0.013435, loss_ce: 0.005442
2022-01-21 22:54:48,439 iteration 6041 : loss : 0.031929, loss_ce: 0.011563
2022-01-21 22:54:49,683 iteration 6042 : loss : 0.017385, loss_ce: 0.006347
2022-01-21 22:54:50,871 iteration 6043 : loss : 0.013630, loss_ce: 0.006176
2022-01-21 22:54:52,040 iteration 6044 : loss : 0.014534, loss_ce: 0.004430
2022-01-21 22:54:53,272 iteration 6045 : loss : 0.030243, loss_ce: 0.010300
2022-01-21 22:54:54,456 iteration 6046 : loss : 0.018379, loss_ce: 0.005429
2022-01-21 22:54:55,608 iteration 6047 : loss : 0.016519, loss_ce: 0.003956
2022-01-21 22:54:56,890 iteration 6048 : loss : 0.026986, loss_ce: 0.004543
2022-01-21 22:54:58,126 iteration 6049 : loss : 0.019300, loss_ce: 0.008792
2022-01-21 22:54:59,280 iteration 6050 : loss : 0.013504, loss_ce: 0.005704
2022-01-21 22:55:00,521 iteration 6051 : loss : 0.017289, loss_ce: 0.007691
2022-01-21 22:55:01,621 iteration 6052 : loss : 0.017709, loss_ce: 0.005154
 89%|█████████████████████████▊   | 356/400 [2:09:51<16:20, 22.29s/it]2022-01-21 22:55:02,811 iteration 6053 : loss : 0.015078, loss_ce: 0.007035
2022-01-21 22:55:04,078 iteration 6054 : loss : 0.026349, loss_ce: 0.009986
2022-01-21 22:55:05,246 iteration 6055 : loss : 0.013474, loss_ce: 0.004738
2022-01-21 22:55:06,400 iteration 6056 : loss : 0.014109, loss_ce: 0.005300
2022-01-21 22:55:07,547 iteration 6057 : loss : 0.015037, loss_ce: 0.004816
2022-01-21 22:55:08,776 iteration 6058 : loss : 0.014762, loss_ce: 0.006317
2022-01-21 22:55:09,902 iteration 6059 : loss : 0.012203, loss_ce: 0.004786
2022-01-21 22:55:11,141 iteration 6060 : loss : 0.015512, loss_ce: 0.006933
2022-01-21 22:55:12,268 iteration 6061 : loss : 0.016967, loss_ce: 0.007175
2022-01-21 22:55:13,539 iteration 6062 : loss : 0.024855, loss_ce: 0.012718
2022-01-21 22:55:14,802 iteration 6063 : loss : 0.025072, loss_ce: 0.010955
2022-01-21 22:55:15,999 iteration 6064 : loss : 0.031839, loss_ce: 0.008310
2022-01-21 22:55:17,263 iteration 6065 : loss : 0.019140, loss_ce: 0.009345
2022-01-21 22:55:18,435 iteration 6066 : loss : 0.012296, loss_ce: 0.004366
2022-01-21 22:55:19,577 iteration 6067 : loss : 0.025642, loss_ce: 0.004546
2022-01-21 22:55:20,853 iteration 6068 : loss : 0.023508, loss_ce: 0.008896
2022-01-21 22:55:22,018 iteration 6069 : loss : 0.015521, loss_ce: 0.002564
 89%|█████████████████████████▉   | 357/400 [2:10:11<15:34, 21.72s/it]2022-01-21 22:55:23,284 iteration 6070 : loss : 0.017025, loss_ce: 0.007864
2022-01-21 22:55:24,520 iteration 6071 : loss : 0.017738, loss_ce: 0.004688
2022-01-21 22:55:25,712 iteration 6072 : loss : 0.013499, loss_ce: 0.004650
2022-01-21 22:55:26,929 iteration 6073 : loss : 0.017448, loss_ce: 0.006709
2022-01-21 22:55:28,131 iteration 6074 : loss : 0.013086, loss_ce: 0.004142
2022-01-21 22:55:29,389 iteration 6075 : loss : 0.016509, loss_ce: 0.006987
2022-01-21 22:55:30,553 iteration 6076 : loss : 0.014829, loss_ce: 0.005813
2022-01-21 22:55:31,708 iteration 6077 : loss : 0.014938, loss_ce: 0.006978
2022-01-21 22:55:32,874 iteration 6078 : loss : 0.014844, loss_ce: 0.004739
2022-01-21 22:55:34,063 iteration 6079 : loss : 0.017108, loss_ce: 0.003604
2022-01-21 22:55:35,251 iteration 6080 : loss : 0.015446, loss_ce: 0.004795
2022-01-21 22:55:36,355 iteration 6081 : loss : 0.016793, loss_ce: 0.005074
2022-01-21 22:55:37,595 iteration 6082 : loss : 0.019245, loss_ce: 0.007756
2022-01-21 22:55:38,855 iteration 6083 : loss : 0.030023, loss_ce: 0.012685
2022-01-21 22:55:39,996 iteration 6084 : loss : 0.019358, loss_ce: 0.005847
2022-01-21 22:55:41,131 iteration 6085 : loss : 0.013125, loss_ce: 0.006553
2022-01-21 22:55:42,438 iteration 6086 : loss : 0.025979, loss_ce: 0.010122
 90%|█████████████████████████▉   | 358/400 [2:10:32<14:55, 21.33s/it]2022-01-21 22:55:43,670 iteration 6087 : loss : 0.025151, loss_ce: 0.008071
2022-01-21 22:55:44,858 iteration 6088 : loss : 0.012895, loss_ce: 0.004137
2022-01-21 22:55:46,102 iteration 6089 : loss : 0.016826, loss_ce: 0.007832
2022-01-21 22:55:47,262 iteration 6090 : loss : 0.013688, loss_ce: 0.004262
2022-01-21 22:55:48,400 iteration 6091 : loss : 0.009865, loss_ce: 0.002804
2022-01-21 22:55:49,651 iteration 6092 : loss : 0.021387, loss_ce: 0.007807
2022-01-21 22:55:50,934 iteration 6093 : loss : 0.016225, loss_ce: 0.006549
2022-01-21 22:55:52,179 iteration 6094 : loss : 0.018927, loss_ce: 0.009788
2022-01-21 22:55:53,300 iteration 6095 : loss : 0.016015, loss_ce: 0.004725
2022-01-21 22:55:54,558 iteration 6096 : loss : 0.018644, loss_ce: 0.004473
2022-01-21 22:55:55,689 iteration 6097 : loss : 0.013695, loss_ce: 0.007004
2022-01-21 22:55:56,889 iteration 6098 : loss : 0.014055, loss_ce: 0.006830
2022-01-21 22:55:58,070 iteration 6099 : loss : 0.016226, loss_ce: 0.007242
2022-01-21 22:55:59,274 iteration 6100 : loss : 0.025662, loss_ce: 0.008127
2022-01-21 22:56:00,535 iteration 6101 : loss : 0.030073, loss_ce: 0.011959
2022-01-21 22:56:01,677 iteration 6102 : loss : 0.015819, loss_ce: 0.006518
2022-01-21 22:56:02,884 iteration 6103 : loss : 0.020106, loss_ce: 0.007644
 90%|██████████████████████████   | 359/400 [2:10:52<14:23, 21.07s/it]2022-01-21 22:56:04,157 iteration 6104 : loss : 0.013212, loss_ce: 0.005060
2022-01-21 22:56:05,316 iteration 6105 : loss : 0.016567, loss_ce: 0.005129
2022-01-21 22:56:06,443 iteration 6106 : loss : 0.010595, loss_ce: 0.004322
2022-01-21 22:56:07,572 iteration 6107 : loss : 0.011156, loss_ce: 0.004428
2022-01-21 22:56:08,747 iteration 6108 : loss : 0.019937, loss_ce: 0.006667
2022-01-21 22:56:09,972 iteration 6109 : loss : 0.021518, loss_ce: 0.009030
2022-01-21 22:56:11,095 iteration 6110 : loss : 0.017273, loss_ce: 0.007922
2022-01-21 22:56:12,279 iteration 6111 : loss : 0.018507, loss_ce: 0.006524
2022-01-21 22:56:13,505 iteration 6112 : loss : 0.016485, loss_ce: 0.005103
2022-01-21 22:56:14,682 iteration 6113 : loss : 0.019327, loss_ce: 0.006955
2022-01-21 22:56:15,872 iteration 6114 : loss : 0.020658, loss_ce: 0.008645
2022-01-21 22:56:17,113 iteration 6115 : loss : 0.023490, loss_ce: 0.006617
2022-01-21 22:56:18,288 iteration 6116 : loss : 0.015430, loss_ce: 0.005215
2022-01-21 22:56:19,437 iteration 6117 : loss : 0.020738, loss_ce: 0.007860
2022-01-21 22:56:20,649 iteration 6118 : loss : 0.015391, loss_ce: 0.007881
2022-01-21 22:56:21,820 iteration 6119 : loss : 0.017969, loss_ce: 0.007296
2022-01-21 22:56:21,820 Training Data Eval:
2022-01-21 22:56:27,528   Average segmentation loss on training set: 0.0094
2022-01-21 22:56:27,528 Validation Data Eval:
2022-01-21 22:56:29,501   Average segmentation loss on validation set: 0.0604
2022-01-21 22:56:30,723 iteration 6120 : loss : 0.024173, loss_ce: 0.009610
 90%|██████████████████████████   | 360/400 [2:11:20<15:23, 23.10s/it]2022-01-21 22:56:31,985 iteration 6121 : loss : 0.015683, loss_ce: 0.005523
2022-01-21 22:56:33,172 iteration 6122 : loss : 0.021896, loss_ce: 0.008438
2022-01-21 22:56:34,342 iteration 6123 : loss : 0.015469, loss_ce: 0.005229
2022-01-21 22:56:35,603 iteration 6124 : loss : 0.022183, loss_ce: 0.007931
2022-01-21 22:56:36,794 iteration 6125 : loss : 0.016821, loss_ce: 0.005656
2022-01-21 22:56:38,086 iteration 6126 : loss : 0.021197, loss_ce: 0.008731
2022-01-21 22:56:39,378 iteration 6127 : loss : 0.025866, loss_ce: 0.014095
2022-01-21 22:56:40,561 iteration 6128 : loss : 0.014404, loss_ce: 0.005131
2022-01-21 22:56:41,700 iteration 6129 : loss : 0.019660, loss_ce: 0.006399
2022-01-21 22:56:42,898 iteration 6130 : loss : 0.020967, loss_ce: 0.009283
2022-01-21 22:56:44,047 iteration 6131 : loss : 0.018354, loss_ce: 0.005416
2022-01-21 22:56:45,285 iteration 6132 : loss : 0.017884, loss_ce: 0.006087
2022-01-21 22:56:46,515 iteration 6133 : loss : 0.017489, loss_ce: 0.007828
2022-01-21 22:56:47,672 iteration 6134 : loss : 0.015472, loss_ce: 0.005113
2022-01-21 22:56:48,797 iteration 6135 : loss : 0.014402, loss_ce: 0.006863
2022-01-21 22:56:49,937 iteration 6136 : loss : 0.010962, loss_ce: 0.003206
2022-01-21 22:56:51,087 iteration 6137 : loss : 0.015277, loss_ce: 0.005501
 90%|██████████████████████████▏  | 361/400 [2:11:41<14:28, 22.28s/it]2022-01-21 22:56:52,265 iteration 6138 : loss : 0.020762, loss_ce: 0.008316
2022-01-21 22:56:53,416 iteration 6139 : loss : 0.013066, loss_ce: 0.002511
2022-01-21 22:56:54,554 iteration 6140 : loss : 0.015404, loss_ce: 0.005224
2022-01-21 22:56:55,668 iteration 6141 : loss : 0.015263, loss_ce: 0.006909
2022-01-21 22:56:56,886 iteration 6142 : loss : 0.015975, loss_ce: 0.006667
2022-01-21 22:56:58,016 iteration 6143 : loss : 0.013838, loss_ce: 0.006330
2022-01-21 22:56:59,276 iteration 6144 : loss : 0.020283, loss_ce: 0.009296
2022-01-21 22:57:00,417 iteration 6145 : loss : 0.016871, loss_ce: 0.007359
2022-01-21 22:57:01,518 iteration 6146 : loss : 0.014231, loss_ce: 0.004474
2022-01-21 22:57:02,676 iteration 6147 : loss : 0.013149, loss_ce: 0.004911
2022-01-21 22:57:03,833 iteration 6148 : loss : 0.013498, loss_ce: 0.005604
2022-01-21 22:57:04,973 iteration 6149 : loss : 0.014660, loss_ce: 0.005003
2022-01-21 22:57:06,178 iteration 6150 : loss : 0.022060, loss_ce: 0.008384
2022-01-21 22:57:07,497 iteration 6151 : loss : 0.013962, loss_ce: 0.003956
2022-01-21 22:57:08,672 iteration 6152 : loss : 0.014363, loss_ce: 0.005979
2022-01-21 22:57:09,875 iteration 6153 : loss : 0.019951, loss_ce: 0.009574
2022-01-21 22:57:11,136 iteration 6154 : loss : 0.027954, loss_ce: 0.009922
 90%|██████████████████████████▏  | 362/400 [2:12:01<13:41, 21.61s/it]2022-01-21 22:57:12,436 iteration 6155 : loss : 0.020517, loss_ce: 0.008901
2022-01-21 22:57:13,570 iteration 6156 : loss : 0.010897, loss_ce: 0.004611
2022-01-21 22:57:14,738 iteration 6157 : loss : 0.012606, loss_ce: 0.004007
2022-01-21 22:57:15,939 iteration 6158 : loss : 0.023552, loss_ce: 0.008452
2022-01-21 22:57:17,073 iteration 6159 : loss : 0.019733, loss_ce: 0.006518
2022-01-21 22:57:18,242 iteration 6160 : loss : 0.013278, loss_ce: 0.005381
2022-01-21 22:57:19,433 iteration 6161 : loss : 0.014026, loss_ce: 0.003730
2022-01-21 22:57:20,656 iteration 6162 : loss : 0.024495, loss_ce: 0.004833
2022-01-21 22:57:21,850 iteration 6163 : loss : 0.018789, loss_ce: 0.008215
2022-01-21 22:57:23,090 iteration 6164 : loss : 0.021346, loss_ce: 0.009552
2022-01-21 22:57:24,268 iteration 6165 : loss : 0.020346, loss_ce: 0.008401
2022-01-21 22:57:25,441 iteration 6166 : loss : 0.011325, loss_ce: 0.004397
2022-01-21 22:57:26,589 iteration 6167 : loss : 0.016584, loss_ce: 0.006697
2022-01-21 22:57:27,812 iteration 6168 : loss : 0.024848, loss_ce: 0.009207
2022-01-21 22:57:29,017 iteration 6169 : loss : 0.020062, loss_ce: 0.005908
2022-01-21 22:57:30,180 iteration 6170 : loss : 0.016373, loss_ce: 0.005820
2022-01-21 22:57:31,322 iteration 6171 : loss : 0.012622, loss_ce: 0.004821
 91%|██████████████████████████▎  | 363/400 [2:12:21<13:03, 21.18s/it]2022-01-21 22:57:32,514 iteration 6172 : loss : 0.017738, loss_ce: 0.007669
2022-01-21 22:57:33,784 iteration 6173 : loss : 0.021335, loss_ce: 0.008278
2022-01-21 22:57:34,959 iteration 6174 : loss : 0.016694, loss_ce: 0.006162
2022-01-21 22:57:36,183 iteration 6175 : loss : 0.025728, loss_ce: 0.013322
2022-01-21 22:57:37,381 iteration 6176 : loss : 0.020608, loss_ce: 0.009579
2022-01-21 22:57:38,653 iteration 6177 : loss : 0.020790, loss_ce: 0.008650
2022-01-21 22:57:39,840 iteration 6178 : loss : 0.014087, loss_ce: 0.005982
2022-01-21 22:57:41,023 iteration 6179 : loss : 0.012795, loss_ce: 0.006020
2022-01-21 22:57:42,215 iteration 6180 : loss : 0.015105, loss_ce: 0.005669
2022-01-21 22:57:43,314 iteration 6181 : loss : 0.012455, loss_ce: 0.004075
2022-01-21 22:57:44,503 iteration 6182 : loss : 0.018469, loss_ce: 0.004944
2022-01-21 22:57:45,758 iteration 6183 : loss : 0.014796, loss_ce: 0.005747
2022-01-21 22:57:46,972 iteration 6184 : loss : 0.027653, loss_ce: 0.008648
2022-01-21 22:57:48,141 iteration 6185 : loss : 0.017788, loss_ce: 0.006728
2022-01-21 22:57:49,333 iteration 6186 : loss : 0.022173, loss_ce: 0.007121
2022-01-21 22:57:50,572 iteration 6187 : loss : 0.018332, loss_ce: 0.006062
2022-01-21 22:57:51,671 iteration 6188 : loss : 0.013696, loss_ce: 0.004714
 91%|██████████████████████████▍  | 364/400 [2:12:41<12:33, 20.94s/it]2022-01-21 22:57:52,841 iteration 6189 : loss : 0.011946, loss_ce: 0.003441
2022-01-21 22:57:53,933 iteration 6190 : loss : 0.014448, loss_ce: 0.005221
2022-01-21 22:57:55,239 iteration 6191 : loss : 0.022320, loss_ce: 0.009089
2022-01-21 22:57:56,469 iteration 6192 : loss : 0.013128, loss_ce: 0.004297
2022-01-21 22:57:57,540 iteration 6193 : loss : 0.010809, loss_ce: 0.004068
2022-01-21 22:57:58,712 iteration 6194 : loss : 0.013802, loss_ce: 0.004857
2022-01-21 22:57:59,927 iteration 6195 : loss : 0.014386, loss_ce: 0.005710
2022-01-21 22:58:01,149 iteration 6196 : loss : 0.012808, loss_ce: 0.005414
2022-01-21 22:58:02,351 iteration 6197 : loss : 0.015654, loss_ce: 0.007889
2022-01-21 22:58:03,535 iteration 6198 : loss : 0.014578, loss_ce: 0.005040
2022-01-21 22:58:04,719 iteration 6199 : loss : 0.020638, loss_ce: 0.004821
2022-01-21 22:58:05,816 iteration 6200 : loss : 0.010863, loss_ce: 0.005157
2022-01-21 22:58:07,005 iteration 6201 : loss : 0.024516, loss_ce: 0.007870
2022-01-21 22:58:08,139 iteration 6202 : loss : 0.013093, loss_ce: 0.005354
2022-01-21 22:58:09,282 iteration 6203 : loss : 0.019162, loss_ce: 0.004790
2022-01-21 22:58:10,482 iteration 6204 : loss : 0.013354, loss_ce: 0.005567
2022-01-21 22:58:10,482 Training Data Eval:
2022-01-21 22:58:16,154   Average segmentation loss on training set: 0.0091
2022-01-21 22:58:16,154 Validation Data Eval:
2022-01-21 22:58:18,122   Average segmentation loss on validation set: 0.0709
2022-01-21 22:58:19,317 iteration 6205 : loss : 0.020362, loss_ce: 0.005571
 91%|██████████████████████████▍  | 365/400 [2:13:09<13:23, 22.95s/it]2022-01-21 22:58:20,583 iteration 6206 : loss : 0.016858, loss_ce: 0.008306
2022-01-21 22:58:21,741 iteration 6207 : loss : 0.017107, loss_ce: 0.005196
2022-01-21 22:58:22,992 iteration 6208 : loss : 0.022942, loss_ce: 0.008132
2022-01-21 22:58:24,150 iteration 6209 : loss : 0.015932, loss_ce: 0.004253
2022-01-21 22:58:25,284 iteration 6210 : loss : 0.015722, loss_ce: 0.005892
2022-01-21 22:58:26,495 iteration 6211 : loss : 0.028309, loss_ce: 0.013942
2022-01-21 22:58:27,644 iteration 6212 : loss : 0.013725, loss_ce: 0.004322
2022-01-21 22:58:28,797 iteration 6213 : loss : 0.025143, loss_ce: 0.006773
2022-01-21 22:58:29,947 iteration 6214 : loss : 0.018349, loss_ce: 0.003278
2022-01-21 22:58:31,153 iteration 6215 : loss : 0.016890, loss_ce: 0.008050
2022-01-21 22:58:32,342 iteration 6216 : loss : 0.025226, loss_ce: 0.007630
2022-01-21 22:58:33,449 iteration 6217 : loss : 0.012308, loss_ce: 0.003945
2022-01-21 22:58:34,628 iteration 6218 : loss : 0.017464, loss_ce: 0.009675
2022-01-21 22:58:35,777 iteration 6219 : loss : 0.013447, loss_ce: 0.004518
2022-01-21 22:58:36,948 iteration 6220 : loss : 0.015935, loss_ce: 0.004526
2022-01-21 22:58:38,210 iteration 6221 : loss : 0.018798, loss_ce: 0.008943
2022-01-21 22:58:39,413 iteration 6222 : loss : 0.016316, loss_ce: 0.008521
 92%|██████████████████████████▌  | 366/400 [2:13:29<12:31, 22.09s/it]2022-01-21 22:58:40,676 iteration 6223 : loss : 0.027472, loss_ce: 0.006263
2022-01-21 22:58:41,837 iteration 6224 : loss : 0.014896, loss_ce: 0.004492
2022-01-21 22:58:43,006 iteration 6225 : loss : 0.015686, loss_ce: 0.005923
2022-01-21 22:58:44,260 iteration 6226 : loss : 0.019883, loss_ce: 0.008489
2022-01-21 22:58:45,439 iteration 6227 : loss : 0.013321, loss_ce: 0.003089
2022-01-21 22:58:46,637 iteration 6228 : loss : 0.020878, loss_ce: 0.008091
2022-01-21 22:58:47,755 iteration 6229 : loss : 0.012920, loss_ce: 0.005312
2022-01-21 22:58:48,890 iteration 6230 : loss : 0.018008, loss_ce: 0.007329
2022-01-21 22:58:50,074 iteration 6231 : loss : 0.014867, loss_ce: 0.006698
2022-01-21 22:58:51,274 iteration 6232 : loss : 0.016136, loss_ce: 0.006225
2022-01-21 22:58:52,434 iteration 6233 : loss : 0.015492, loss_ce: 0.006699
2022-01-21 22:58:53,632 iteration 6234 : loss : 0.014361, loss_ce: 0.005359
2022-01-21 22:58:54,887 iteration 6235 : loss : 0.020209, loss_ce: 0.004937
2022-01-21 22:58:55,992 iteration 6236 : loss : 0.011018, loss_ce: 0.004225
2022-01-21 22:58:57,160 iteration 6237 : loss : 0.012898, loss_ce: 0.005380
2022-01-21 22:58:58,276 iteration 6238 : loss : 0.008879, loss_ce: 0.003234
2022-01-21 22:58:59,415 iteration 6239 : loss : 0.011229, loss_ce: 0.004640
 92%|██████████████████████████▌  | 367/400 [2:13:49<11:48, 21.47s/it]2022-01-21 22:59:00,695 iteration 6240 : loss : 0.015431, loss_ce: 0.005786
2022-01-21 22:59:01,921 iteration 6241 : loss : 0.026041, loss_ce: 0.011824
2022-01-21 22:59:03,154 iteration 6242 : loss : 0.013553, loss_ce: 0.005003
2022-01-21 22:59:04,262 iteration 6243 : loss : 0.012551, loss_ce: 0.004549
2022-01-21 22:59:05,400 iteration 6244 : loss : 0.012250, loss_ce: 0.003566
2022-01-21 22:59:06,555 iteration 6245 : loss : 0.018174, loss_ce: 0.006517
2022-01-21 22:59:07,699 iteration 6246 : loss : 0.018335, loss_ce: 0.006980
2022-01-21 22:59:08,843 iteration 6247 : loss : 0.017399, loss_ce: 0.004200
2022-01-21 22:59:10,065 iteration 6248 : loss : 0.022406, loss_ce: 0.008810
2022-01-21 22:59:11,223 iteration 6249 : loss : 0.015214, loss_ce: 0.005231
2022-01-21 22:59:12,429 iteration 6250 : loss : 0.027271, loss_ce: 0.013146
2022-01-21 22:59:13,699 iteration 6251 : loss : 0.013654, loss_ce: 0.005292
2022-01-21 22:59:14,920 iteration 6252 : loss : 0.030853, loss_ce: 0.005658
2022-01-21 22:59:16,069 iteration 6253 : loss : 0.017797, loss_ce: 0.005468
2022-01-21 22:59:17,178 iteration 6254 : loss : 0.012067, loss_ce: 0.004991
2022-01-21 22:59:18,407 iteration 6255 : loss : 0.012836, loss_ce: 0.004247
2022-01-21 22:59:19,583 iteration 6256 : loss : 0.013500, loss_ce: 0.004804
 92%|██████████████████████████▋  | 368/400 [2:14:09<11:14, 21.08s/it]2022-01-21 22:59:20,843 iteration 6257 : loss : 0.011045, loss_ce: 0.003669
2022-01-21 22:59:21,966 iteration 6258 : loss : 0.012100, loss_ce: 0.004175
2022-01-21 22:59:23,201 iteration 6259 : loss : 0.015009, loss_ce: 0.005983
2022-01-21 22:59:24,508 iteration 6260 : loss : 0.031698, loss_ce: 0.007982
2022-01-21 22:59:25,697 iteration 6261 : loss : 0.017007, loss_ce: 0.007476
2022-01-21 22:59:26,927 iteration 6262 : loss : 0.017506, loss_ce: 0.008063
2022-01-21 22:59:28,077 iteration 6263 : loss : 0.013671, loss_ce: 0.004681
2022-01-21 22:59:29,202 iteration 6264 : loss : 0.014436, loss_ce: 0.005928
2022-01-21 22:59:30,379 iteration 6265 : loss : 0.014404, loss_ce: 0.004791
2022-01-21 22:59:31,536 iteration 6266 : loss : 0.011787, loss_ce: 0.004196
2022-01-21 22:59:32,878 iteration 6267 : loss : 0.022883, loss_ce: 0.008848
2022-01-21 22:59:34,056 iteration 6268 : loss : 0.013963, loss_ce: 0.004889
2022-01-21 22:59:35,242 iteration 6269 : loss : 0.014254, loss_ce: 0.005554
2022-01-21 22:59:36,396 iteration 6270 : loss : 0.014029, loss_ce: 0.006296
2022-01-21 22:59:37,648 iteration 6271 : loss : 0.015076, loss_ce: 0.006061
2022-01-21 22:59:38,788 iteration 6272 : loss : 0.017183, loss_ce: 0.005941
2022-01-21 22:59:40,057 iteration 6273 : loss : 0.015684, loss_ce: 0.005603
 92%|██████████████████████████▊  | 369/400 [2:14:29<10:47, 20.89s/it]2022-01-21 22:59:41,392 iteration 6274 : loss : 0.020059, loss_ce: 0.007720
2022-01-21 22:59:42,542 iteration 6275 : loss : 0.014739, loss_ce: 0.003857
2022-01-21 22:59:43,652 iteration 6276 : loss : 0.016533, loss_ce: 0.006067
2022-01-21 22:59:44,830 iteration 6277 : loss : 0.012001, loss_ce: 0.004881
2022-01-21 22:59:46,073 iteration 6278 : loss : 0.019966, loss_ce: 0.007819
2022-01-21 22:59:47,306 iteration 6279 : loss : 0.017339, loss_ce: 0.005820
2022-01-21 22:59:48,430 iteration 6280 : loss : 0.013817, loss_ce: 0.005040
2022-01-21 22:59:49,581 iteration 6281 : loss : 0.017279, loss_ce: 0.005130
2022-01-21 22:59:50,752 iteration 6282 : loss : 0.020930, loss_ce: 0.009740
2022-01-21 22:59:52,009 iteration 6283 : loss : 0.024244, loss_ce: 0.010810
2022-01-21 22:59:53,213 iteration 6284 : loss : 0.011979, loss_ce: 0.003644
2022-01-21 22:59:54,412 iteration 6285 : loss : 0.018890, loss_ce: 0.009012
2022-01-21 22:59:55,644 iteration 6286 : loss : 0.019178, loss_ce: 0.009362
2022-01-21 22:59:56,827 iteration 6287 : loss : 0.014783, loss_ce: 0.006434
2022-01-21 22:59:57,936 iteration 6288 : loss : 0.012452, loss_ce: 0.004740
2022-01-21 22:59:59,090 iteration 6289 : loss : 0.013343, loss_ce: 0.005800
2022-01-21 22:59:59,090 Training Data Eval:
2022-01-21 23:00:04,749   Average segmentation loss on training set: 0.0089
2022-01-21 23:00:04,749 Validation Data Eval:
2022-01-21 23:00:06,714   Average segmentation loss on validation set: 0.0607
2022-01-21 23:00:07,880 iteration 6290 : loss : 0.015107, loss_ce: 0.005838
 92%|██████████████████████████▊  | 370/400 [2:14:57<11:29, 22.97s/it]2022-01-21 23:00:09,094 iteration 6291 : loss : 0.015458, loss_ce: 0.005046
2022-01-21 23:00:10,179 iteration 6292 : loss : 0.015998, loss_ce: 0.004587
2022-01-21 23:00:11,314 iteration 6293 : loss : 0.018135, loss_ce: 0.004486
2022-01-21 23:00:12,569 iteration 6294 : loss : 0.023969, loss_ce: 0.006917
2022-01-21 23:00:13,746 iteration 6295 : loss : 0.013253, loss_ce: 0.005573
2022-01-21 23:00:14,851 iteration 6296 : loss : 0.013175, loss_ce: 0.005064
2022-01-21 23:00:16,085 iteration 6297 : loss : 0.027095, loss_ce: 0.011297
2022-01-21 23:00:17,258 iteration 6298 : loss : 0.020799, loss_ce: 0.010650
2022-01-21 23:00:18,430 iteration 6299 : loss : 0.013223, loss_ce: 0.004795
2022-01-21 23:00:19,651 iteration 6300 : loss : 0.013058, loss_ce: 0.003816
2022-01-21 23:00:20,844 iteration 6301 : loss : 0.015059, loss_ce: 0.007198
2022-01-21 23:00:22,090 iteration 6302 : loss : 0.026601, loss_ce: 0.013954
2022-01-21 23:00:23,241 iteration 6303 : loss : 0.015463, loss_ce: 0.006307
2022-01-21 23:00:24,441 iteration 6304 : loss : 0.019002, loss_ce: 0.007949
2022-01-21 23:00:25,589 iteration 6305 : loss : 0.015002, loss_ce: 0.004989
2022-01-21 23:00:26,766 iteration 6306 : loss : 0.012924, loss_ce: 0.005883
2022-01-21 23:00:27,923 iteration 6307 : loss : 0.014949, loss_ce: 0.005263
 93%|██████████████████████████▉  | 371/400 [2:15:17<10:40, 22.10s/it]2022-01-21 23:00:29,201 iteration 6308 : loss : 0.018834, loss_ce: 0.007810
2022-01-21 23:00:30,357 iteration 6309 : loss : 0.034517, loss_ce: 0.009526
2022-01-21 23:00:31,534 iteration 6310 : loss : 0.011973, loss_ce: 0.004837
2022-01-21 23:00:32,768 iteration 6311 : loss : 0.021377, loss_ce: 0.006477
2022-01-21 23:00:33,927 iteration 6312 : loss : 0.015071, loss_ce: 0.006509
2022-01-21 23:00:35,124 iteration 6313 : loss : 0.028583, loss_ce: 0.007943
2022-01-21 23:00:36,347 iteration 6314 : loss : 0.016747, loss_ce: 0.006700
2022-01-21 23:00:37,504 iteration 6315 : loss : 0.017085, loss_ce: 0.007717
2022-01-21 23:00:38,613 iteration 6316 : loss : 0.013041, loss_ce: 0.003974
2022-01-21 23:00:39,713 iteration 6317 : loss : 0.018148, loss_ce: 0.006269
2022-01-21 23:00:40,933 iteration 6318 : loss : 0.016738, loss_ce: 0.006146
2022-01-21 23:00:42,087 iteration 6319 : loss : 0.017085, loss_ce: 0.006490
2022-01-21 23:00:43,262 iteration 6320 : loss : 0.012448, loss_ce: 0.005292
2022-01-21 23:00:44,435 iteration 6321 : loss : 0.014041, loss_ce: 0.005297
2022-01-21 23:00:45,693 iteration 6322 : loss : 0.025168, loss_ce: 0.008912
2022-01-21 23:00:46,963 iteration 6323 : loss : 0.048815, loss_ce: 0.009865
2022-01-21 23:00:48,125 iteration 6324 : loss : 0.016606, loss_ce: 0.006837
 93%|██████████████████████████▉  | 372/400 [2:15:38<10:02, 21.53s/it]2022-01-21 23:00:49,316 iteration 6325 : loss : 0.012330, loss_ce: 0.005637
2022-01-21 23:00:50,429 iteration 6326 : loss : 0.010368, loss_ce: 0.004016
2022-01-21 23:00:51,651 iteration 6327 : loss : 0.017018, loss_ce: 0.006517
2022-01-21 23:00:52,815 iteration 6328 : loss : 0.011096, loss_ce: 0.003718
2022-01-21 23:00:53,938 iteration 6329 : loss : 0.013555, loss_ce: 0.003673
2022-01-21 23:00:55,113 iteration 6330 : loss : 0.013100, loss_ce: 0.004236
2022-01-21 23:00:56,471 iteration 6331 : loss : 0.019769, loss_ce: 0.006909
2022-01-21 23:00:57,618 iteration 6332 : loss : 0.014672, loss_ce: 0.005892
2022-01-21 23:00:58,825 iteration 6333 : loss : 0.013185, loss_ce: 0.003470
2022-01-21 23:01:00,000 iteration 6334 : loss : 0.017748, loss_ce: 0.007681
2022-01-21 23:01:01,278 iteration 6335 : loss : 0.030387, loss_ce: 0.011368
2022-01-21 23:01:02,389 iteration 6336 : loss : 0.009480, loss_ce: 0.003466
2022-01-21 23:01:03,589 iteration 6337 : loss : 0.020158, loss_ce: 0.008179
2022-01-21 23:01:04,861 iteration 6338 : loss : 0.025179, loss_ce: 0.003865
2022-01-21 23:01:06,017 iteration 6339 : loss : 0.016215, loss_ce: 0.006885
2022-01-21 23:01:07,167 iteration 6340 : loss : 0.015794, loss_ce: 0.008488
2022-01-21 23:01:08,359 iteration 6341 : loss : 0.014830, loss_ce: 0.005368
 93%|███████████████████████████  | 373/400 [2:15:58<09:30, 21.14s/it]2022-01-21 23:01:09,609 iteration 6342 : loss : 0.017175, loss_ce: 0.006498
2022-01-21 23:01:10,772 iteration 6343 : loss : 0.016705, loss_ce: 0.004702
2022-01-21 23:01:12,025 iteration 6344 : loss : 0.021293, loss_ce: 0.009391
2022-01-21 23:01:13,200 iteration 6345 : loss : 0.016043, loss_ce: 0.004349
2022-01-21 23:01:14,345 iteration 6346 : loss : 0.012503, loss_ce: 0.004975
2022-01-21 23:01:15,563 iteration 6347 : loss : 0.022124, loss_ce: 0.010032
2022-01-21 23:01:16,706 iteration 6348 : loss : 0.014614, loss_ce: 0.006406
2022-01-21 23:01:17,877 iteration 6349 : loss : 0.012830, loss_ce: 0.003953
2022-01-21 23:01:19,053 iteration 6350 : loss : 0.017735, loss_ce: 0.007924
2022-01-21 23:01:20,252 iteration 6351 : loss : 0.019145, loss_ce: 0.008508
2022-01-21 23:01:21,478 iteration 6352 : loss : 0.016907, loss_ce: 0.005840
2022-01-21 23:01:22,769 iteration 6353 : loss : 0.023054, loss_ce: 0.006588
2022-01-21 23:01:23,926 iteration 6354 : loss : 0.014829, loss_ce: 0.003739
2022-01-21 23:01:25,176 iteration 6355 : loss : 0.014062, loss_ce: 0.004833
2022-01-21 23:01:26,448 iteration 6356 : loss : 0.020686, loss_ce: 0.006892
2022-01-21 23:01:27,657 iteration 6357 : loss : 0.015795, loss_ce: 0.008709
2022-01-21 23:01:28,904 iteration 6358 : loss : 0.018518, loss_ce: 0.006049
 94%|███████████████████████████  | 374/400 [2:16:18<09:04, 20.96s/it]2022-01-21 23:01:30,146 iteration 6359 : loss : 0.012687, loss_ce: 0.004080
2022-01-21 23:01:31,217 iteration 6360 : loss : 0.009834, loss_ce: 0.003415
2022-01-21 23:01:32,471 iteration 6361 : loss : 0.013534, loss_ce: 0.004882
2022-01-21 23:01:33,662 iteration 6362 : loss : 0.017013, loss_ce: 0.007300
2022-01-21 23:01:34,941 iteration 6363 : loss : 0.020482, loss_ce: 0.006482
2022-01-21 23:01:36,166 iteration 6364 : loss : 0.018763, loss_ce: 0.004979
2022-01-21 23:01:37,349 iteration 6365 : loss : 0.025436, loss_ce: 0.010994
2022-01-21 23:01:38,530 iteration 6366 : loss : 0.016733, loss_ce: 0.005885
2022-01-21 23:01:39,771 iteration 6367 : loss : 0.045150, loss_ce: 0.018239
2022-01-21 23:01:40,985 iteration 6368 : loss : 0.027946, loss_ce: 0.007761
2022-01-21 23:01:42,168 iteration 6369 : loss : 0.017321, loss_ce: 0.004066
2022-01-21 23:01:43,380 iteration 6370 : loss : 0.018502, loss_ce: 0.008994
2022-01-21 23:01:44,513 iteration 6371 : loss : 0.011204, loss_ce: 0.004482
2022-01-21 23:01:45,712 iteration 6372 : loss : 0.014401, loss_ce: 0.005553
2022-01-21 23:01:46,849 iteration 6373 : loss : 0.012008, loss_ce: 0.005469
2022-01-21 23:01:47,938 iteration 6374 : loss : 0.011302, loss_ce: 0.004395
2022-01-21 23:01:47,938 Training Data Eval:
2022-01-21 23:01:53,597   Average segmentation loss on training set: 0.0088
2022-01-21 23:01:53,598 Validation Data Eval:
2022-01-21 23:01:55,563   Average segmentation loss on validation set: 0.0624
2022-01-21 23:01:56,770 iteration 6375 : loss : 0.013728, loss_ce: 0.006692
 94%|███████████████████████████▏ | 375/400 [2:16:46<09:35, 23.03s/it]2022-01-21 23:01:58,077 iteration 6376 : loss : 0.018752, loss_ce: 0.007114
2022-01-21 23:01:59,277 iteration 6377 : loss : 0.016827, loss_ce: 0.004137
2022-01-21 23:02:00,437 iteration 6378 : loss : 0.017431, loss_ce: 0.008411
2022-01-21 23:02:01,620 iteration 6379 : loss : 0.015375, loss_ce: 0.006631
2022-01-21 23:02:02,861 iteration 6380 : loss : 0.023357, loss_ce: 0.006454
2022-01-21 23:02:04,103 iteration 6381 : loss : 0.019896, loss_ce: 0.008286
2022-01-21 23:02:05,289 iteration 6382 : loss : 0.013596, loss_ce: 0.006495
2022-01-21 23:02:06,519 iteration 6383 : loss : 0.016279, loss_ce: 0.005433
2022-01-21 23:02:07,759 iteration 6384 : loss : 0.016793, loss_ce: 0.006177
2022-01-21 23:02:08,817 iteration 6385 : loss : 0.010312, loss_ce: 0.003960
2022-01-21 23:02:10,047 iteration 6386 : loss : 0.023120, loss_ce: 0.008048
2022-01-21 23:02:11,264 iteration 6387 : loss : 0.020231, loss_ce: 0.011383
2022-01-21 23:02:12,385 iteration 6388 : loss : 0.015791, loss_ce: 0.007377
2022-01-21 23:02:13,611 iteration 6389 : loss : 0.012257, loss_ce: 0.004930
2022-01-21 23:02:14,819 iteration 6390 : loss : 0.026151, loss_ce: 0.008307
2022-01-21 23:02:16,054 iteration 6391 : loss : 0.014710, loss_ce: 0.006469
2022-01-21 23:02:17,291 iteration 6392 : loss : 0.023652, loss_ce: 0.005353
 94%|███████████████████████████▎ | 376/400 [2:17:07<08:54, 22.28s/it]2022-01-21 23:02:18,492 iteration 6393 : loss : 0.011660, loss_ce: 0.005894
2022-01-21 23:02:19,656 iteration 6394 : loss : 0.013814, loss_ce: 0.006592
2022-01-21 23:02:20,796 iteration 6395 : loss : 0.010499, loss_ce: 0.003165
2022-01-21 23:02:22,001 iteration 6396 : loss : 0.017700, loss_ce: 0.007087
2022-01-21 23:02:23,235 iteration 6397 : loss : 0.021122, loss_ce: 0.006358
2022-01-21 23:02:24,470 iteration 6398 : loss : 0.016950, loss_ce: 0.005704
2022-01-21 23:02:25,592 iteration 6399 : loss : 0.014111, loss_ce: 0.003756
2022-01-21 23:02:26,749 iteration 6400 : loss : 0.011400, loss_ce: 0.004000
2022-01-21 23:02:27,853 iteration 6401 : loss : 0.011036, loss_ce: 0.004074
2022-01-21 23:02:29,076 iteration 6402 : loss : 0.016050, loss_ce: 0.007147
2022-01-21 23:02:30,222 iteration 6403 : loss : 0.014707, loss_ce: 0.005818
2022-01-21 23:02:31,336 iteration 6404 : loss : 0.013077, loss_ce: 0.006870
2022-01-21 23:02:32,646 iteration 6405 : loss : 0.020652, loss_ce: 0.008049
2022-01-21 23:02:33,773 iteration 6406 : loss : 0.010614, loss_ce: 0.003940
2022-01-21 23:02:34,971 iteration 6407 : loss : 0.020671, loss_ce: 0.008550
2022-01-21 23:02:36,187 iteration 6408 : loss : 0.017079, loss_ce: 0.006271
2022-01-21 23:02:37,317 iteration 6409 : loss : 0.012404, loss_ce: 0.004505
 94%|███████████████████████████▎ | 377/400 [2:17:27<08:16, 21.61s/it]2022-01-21 23:02:38,492 iteration 6410 : loss : 0.012932, loss_ce: 0.004844
2022-01-21 23:02:39,645 iteration 6411 : loss : 0.013425, loss_ce: 0.004936
2022-01-21 23:02:40,884 iteration 6412 : loss : 0.017153, loss_ce: 0.005680
2022-01-21 23:02:42,076 iteration 6413 : loss : 0.014167, loss_ce: 0.006019
2022-01-21 23:02:43,300 iteration 6414 : loss : 0.021079, loss_ce: 0.009966
2022-01-21 23:02:44,524 iteration 6415 : loss : 0.012379, loss_ce: 0.003677
2022-01-21 23:02:45,652 iteration 6416 : loss : 0.018697, loss_ce: 0.007160
2022-01-21 23:02:46,867 iteration 6417 : loss : 0.024824, loss_ce: 0.007690
2022-01-21 23:02:48,047 iteration 6418 : loss : 0.013965, loss_ce: 0.005858
2022-01-21 23:02:49,227 iteration 6419 : loss : 0.015969, loss_ce: 0.006282
2022-01-21 23:02:50,436 iteration 6420 : loss : 0.020161, loss_ce: 0.008462
2022-01-21 23:02:51,657 iteration 6421 : loss : 0.013416, loss_ce: 0.005381
2022-01-21 23:02:52,822 iteration 6422 : loss : 0.018202, loss_ce: 0.007565
2022-01-21 23:02:54,014 iteration 6423 : loss : 0.011394, loss_ce: 0.004804
2022-01-21 23:02:55,145 iteration 6424 : loss : 0.018455, loss_ce: 0.005500
2022-01-21 23:02:56,449 iteration 6425 : loss : 0.019284, loss_ce: 0.007141
2022-01-21 23:02:57,570 iteration 6426 : loss : 0.018632, loss_ce: 0.006161
 94%|███████████████████████████▍ | 378/400 [2:17:47<07:46, 21.20s/it]2022-01-21 23:02:58,832 iteration 6427 : loss : 0.017945, loss_ce: 0.006675
2022-01-21 23:03:00,057 iteration 6428 : loss : 0.019627, loss_ce: 0.005866
2022-01-21 23:03:01,226 iteration 6429 : loss : 0.014829, loss_ce: 0.006099
2022-01-21 23:03:02,471 iteration 6430 : loss : 0.013870, loss_ce: 0.006440
2022-01-21 23:03:03,647 iteration 6431 : loss : 0.022243, loss_ce: 0.006461
2022-01-21 23:03:04,822 iteration 6432 : loss : 0.017922, loss_ce: 0.006921
2022-01-21 23:03:05,998 iteration 6433 : loss : 0.014252, loss_ce: 0.003862
2022-01-21 23:03:07,185 iteration 6434 : loss : 0.022559, loss_ce: 0.008601
2022-01-21 23:03:08,268 iteration 6435 : loss : 0.011217, loss_ce: 0.003574
2022-01-21 23:03:09,392 iteration 6436 : loss : 0.013442, loss_ce: 0.007121
2022-01-21 23:03:10,501 iteration 6437 : loss : 0.016292, loss_ce: 0.007502
2022-01-21 23:03:11,595 iteration 6438 : loss : 0.010930, loss_ce: 0.005010
2022-01-21 23:03:12,831 iteration 6439 : loss : 0.019506, loss_ce: 0.006148
2022-01-21 23:03:14,012 iteration 6440 : loss : 0.011639, loss_ce: 0.003766
2022-01-21 23:03:15,204 iteration 6441 : loss : 0.011889, loss_ce: 0.004694
2022-01-21 23:03:16,378 iteration 6442 : loss : 0.011650, loss_ce: 0.004952
2022-01-21 23:03:17,527 iteration 6443 : loss : 0.013697, loss_ce: 0.004801
 95%|███████████████████████████▍ | 379/400 [2:18:07<07:17, 20.82s/it]2022-01-21 23:03:18,718 iteration 6444 : loss : 0.015288, loss_ce: 0.007363
2022-01-21 23:03:19,859 iteration 6445 : loss : 0.010186, loss_ce: 0.003842
2022-01-21 23:03:21,030 iteration 6446 : loss : 0.020635, loss_ce: 0.006984
2022-01-21 23:03:22,200 iteration 6447 : loss : 0.011972, loss_ce: 0.005014
2022-01-21 23:03:23,373 iteration 6448 : loss : 0.021532, loss_ce: 0.004476
2022-01-21 23:03:24,568 iteration 6449 : loss : 0.017864, loss_ce: 0.006340
2022-01-21 23:03:25,801 iteration 6450 : loss : 0.019414, loss_ce: 0.005228
2022-01-21 23:03:26,963 iteration 6451 : loss : 0.014441, loss_ce: 0.005219
2022-01-21 23:03:28,187 iteration 6452 : loss : 0.019524, loss_ce: 0.005460
2022-01-21 23:03:29,348 iteration 6453 : loss : 0.013985, loss_ce: 0.006128
2022-01-21 23:03:30,524 iteration 6454 : loss : 0.017323, loss_ce: 0.006122
2022-01-21 23:03:31,649 iteration 6455 : loss : 0.014339, loss_ce: 0.005669
2022-01-21 23:03:32,847 iteration 6456 : loss : 0.015660, loss_ce: 0.008164
2022-01-21 23:03:33,998 iteration 6457 : loss : 0.011222, loss_ce: 0.004770
2022-01-21 23:03:35,128 iteration 6458 : loss : 0.013137, loss_ce: 0.007163
2022-01-21 23:03:36,365 iteration 6459 : loss : 0.014512, loss_ce: 0.005436
2022-01-21 23:03:36,366 Training Data Eval:
2022-01-21 23:03:42,049   Average segmentation loss on training set: 0.0085
2022-01-21 23:03:42,049 Validation Data Eval:
2022-01-21 23:03:44,016   Average segmentation loss on validation set: 0.0595
2022-01-21 23:03:45,270 iteration 6460 : loss : 0.020005, loss_ce: 0.006265
 95%|███████████████████████████▌ | 380/400 [2:18:35<07:37, 22.90s/it]2022-01-21 23:03:46,464 iteration 6461 : loss : 0.011221, loss_ce: 0.003514
2022-01-21 23:03:47,653 iteration 6462 : loss : 0.014065, loss_ce: 0.005526
2022-01-21 23:03:48,782 iteration 6463 : loss : 0.020842, loss_ce: 0.011497
2022-01-21 23:03:49,936 iteration 6464 : loss : 0.014680, loss_ce: 0.005387
2022-01-21 23:03:51,107 iteration 6465 : loss : 0.012976, loss_ce: 0.004315
2022-01-21 23:03:52,276 iteration 6466 : loss : 0.015063, loss_ce: 0.006036
2022-01-21 23:03:53,455 iteration 6467 : loss : 0.020416, loss_ce: 0.010597
2022-01-21 23:03:54,584 iteration 6468 : loss : 0.015572, loss_ce: 0.005241
2022-01-21 23:03:55,805 iteration 6469 : loss : 0.017863, loss_ce: 0.004492
2022-01-21 23:03:57,005 iteration 6470 : loss : 0.012508, loss_ce: 0.005023
2022-01-21 23:03:58,196 iteration 6471 : loss : 0.014964, loss_ce: 0.005803
2022-01-21 23:03:59,326 iteration 6472 : loss : 0.020759, loss_ce: 0.007058
2022-01-21 23:04:00,539 iteration 6473 : loss : 0.015285, loss_ce: 0.006150
2022-01-21 23:04:01,749 iteration 6474 : loss : 0.011261, loss_ce: 0.004375
2022-01-21 23:04:02,972 iteration 6475 : loss : 0.020871, loss_ce: 0.006300
2022-01-21 23:04:04,175 iteration 6476 : loss : 0.015341, loss_ce: 0.005305
2022-01-21 23:04:05,368 iteration 6477 : loss : 0.016478, loss_ce: 0.007615
 95%|███████████████████████████▌ | 381/400 [2:18:55<06:59, 22.06s/it]2022-01-21 23:04:06,597 iteration 6478 : loss : 0.013467, loss_ce: 0.005470
2022-01-21 23:04:07,783 iteration 6479 : loss : 0.019245, loss_ce: 0.005528
2022-01-21 23:04:08,935 iteration 6480 : loss : 0.011486, loss_ce: 0.004019
2022-01-21 23:04:10,243 iteration 6481 : loss : 0.021624, loss_ce: 0.006818
2022-01-21 23:04:11,397 iteration 6482 : loss : 0.012895, loss_ce: 0.005082
2022-01-21 23:04:12,635 iteration 6483 : loss : 0.019789, loss_ce: 0.007794
2022-01-21 23:04:13,722 iteration 6484 : loss : 0.016849, loss_ce: 0.005865
2022-01-21 23:04:14,904 iteration 6485 : loss : 0.013767, loss_ce: 0.004237
2022-01-21 23:04:16,107 iteration 6486 : loss : 0.014156, loss_ce: 0.005428
2022-01-21 23:04:17,316 iteration 6487 : loss : 0.015581, loss_ce: 0.006381
2022-01-21 23:04:18,542 iteration 6488 : loss : 0.012882, loss_ce: 0.004585
2022-01-21 23:04:19,729 iteration 6489 : loss : 0.019141, loss_ce: 0.007827
2022-01-21 23:04:20,899 iteration 6490 : loss : 0.015941, loss_ce: 0.005337
2022-01-21 23:04:22,038 iteration 6491 : loss : 0.015222, loss_ce: 0.007274
2022-01-21 23:04:23,173 iteration 6492 : loss : 0.010547, loss_ce: 0.005643
2022-01-21 23:04:24,332 iteration 6493 : loss : 0.019510, loss_ce: 0.006485
2022-01-21 23:04:25,532 iteration 6494 : loss : 0.012963, loss_ce: 0.005038
 96%|███████████████████████████▋ | 382/400 [2:19:15<06:26, 21.49s/it]2022-01-21 23:04:26,691 iteration 6495 : loss : 0.012393, loss_ce: 0.005369
2022-01-21 23:04:27,859 iteration 6496 : loss : 0.015457, loss_ce: 0.005158
2022-01-21 23:04:29,073 iteration 6497 : loss : 0.010766, loss_ce: 0.005468
2022-01-21 23:04:30,221 iteration 6498 : loss : 0.018244, loss_ce: 0.004497
2022-01-21 23:04:31,387 iteration 6499 : loss : 0.021340, loss_ce: 0.005071
2022-01-21 23:04:32,664 iteration 6500 : loss : 0.022089, loss_ce: 0.006398
2022-01-21 23:04:33,914 iteration 6501 : loss : 0.017542, loss_ce: 0.008160
2022-01-21 23:04:35,110 iteration 6502 : loss : 0.012382, loss_ce: 0.004267
2022-01-21 23:04:36,312 iteration 6503 : loss : 0.015133, loss_ce: 0.005855
2022-01-21 23:04:37,514 iteration 6504 : loss : 0.016336, loss_ce: 0.007570
2022-01-21 23:04:38,632 iteration 6505 : loss : 0.011078, loss_ce: 0.004289
2022-01-21 23:04:39,828 iteration 6506 : loss : 0.013901, loss_ce: 0.003568
2022-01-21 23:04:40,978 iteration 6507 : loss : 0.015265, loss_ce: 0.006465
2022-01-21 23:04:42,071 iteration 6508 : loss : 0.013478, loss_ce: 0.004676
2022-01-21 23:04:43,238 iteration 6509 : loss : 0.012597, loss_ce: 0.004191
2022-01-21 23:04:44,308 iteration 6510 : loss : 0.009665, loss_ce: 0.003687
2022-01-21 23:04:45,506 iteration 6511 : loss : 0.013115, loss_ce: 0.004996
 96%|███████████████████████████▊ | 383/400 [2:19:35<05:57, 21.04s/it]2022-01-21 23:04:46,755 iteration 6512 : loss : 0.023582, loss_ce: 0.006705
2022-01-21 23:04:47,999 iteration 6513 : loss : 0.013940, loss_ce: 0.005010
2022-01-21 23:04:49,191 iteration 6514 : loss : 0.017282, loss_ce: 0.005120
2022-01-21 23:04:50,430 iteration 6515 : loss : 0.021483, loss_ce: 0.007082
2022-01-21 23:04:51,584 iteration 6516 : loss : 0.010865, loss_ce: 0.004398
2022-01-21 23:04:52,713 iteration 6517 : loss : 0.013724, loss_ce: 0.006215
2022-01-21 23:04:53,907 iteration 6518 : loss : 0.016620, loss_ce: 0.006008
2022-01-21 23:04:55,153 iteration 6519 : loss : 0.021354, loss_ce: 0.009970
2022-01-21 23:04:56,274 iteration 6520 : loss : 0.015639, loss_ce: 0.006884
2022-01-21 23:04:57,485 iteration 6521 : loss : 0.016426, loss_ce: 0.006764
2022-01-21 23:04:58,677 iteration 6522 : loss : 0.015572, loss_ce: 0.005433
2022-01-21 23:04:59,891 iteration 6523 : loss : 0.016328, loss_ce: 0.007075
2022-01-21 23:05:01,098 iteration 6524 : loss : 0.019363, loss_ce: 0.006553
2022-01-21 23:05:02,333 iteration 6525 : loss : 0.016002, loss_ce: 0.005199
2022-01-21 23:05:03,515 iteration 6526 : loss : 0.013627, loss_ce: 0.005276
2022-01-21 23:05:04,655 iteration 6527 : loss : 0.016048, loss_ce: 0.005684
2022-01-21 23:05:05,798 iteration 6528 : loss : 0.012979, loss_ce: 0.004913
 96%|███████████████████████████▊ | 384/400 [2:19:55<05:33, 20.81s/it]2022-01-21 23:05:07,180 iteration 6529 : loss : 0.018310, loss_ce: 0.008266
2022-01-21 23:05:08,360 iteration 6530 : loss : 0.016703, loss_ce: 0.007072
2022-01-21 23:05:09,635 iteration 6531 : loss : 0.019555, loss_ce: 0.007432
2022-01-21 23:05:10,837 iteration 6532 : loss : 0.020523, loss_ce: 0.009104
2022-01-21 23:05:12,080 iteration 6533 : loss : 0.029535, loss_ce: 0.006996
2022-01-21 23:05:13,411 iteration 6534 : loss : 0.025526, loss_ce: 0.006203
2022-01-21 23:05:14,533 iteration 6535 : loss : 0.016767, loss_ce: 0.003197
2022-01-21 23:05:15,726 iteration 6536 : loss : 0.022553, loss_ce: 0.007521
2022-01-21 23:05:16,910 iteration 6537 : loss : 0.021253, loss_ce: 0.009628
2022-01-21 23:05:18,122 iteration 6538 : loss : 0.018907, loss_ce: 0.008757
2022-01-21 23:05:19,407 iteration 6539 : loss : 0.020386, loss_ce: 0.007093
2022-01-21 23:05:20,589 iteration 6540 : loss : 0.015415, loss_ce: 0.007241
2022-01-21 23:05:21,754 iteration 6541 : loss : 0.013919, loss_ce: 0.005917
2022-01-21 23:05:22,988 iteration 6542 : loss : 0.021953, loss_ce: 0.009734
2022-01-21 23:05:24,200 iteration 6543 : loss : 0.039266, loss_ce: 0.014732
2022-01-21 23:05:25,314 iteration 6544 : loss : 0.010096, loss_ce: 0.003373
2022-01-21 23:05:25,314 Training Data Eval:
2022-01-21 23:05:31,010   Average segmentation loss on training set: 0.0084
2022-01-21 23:05:31,010 Validation Data Eval:
2022-01-21 23:05:32,971   Average segmentation loss on validation set: 0.0622
2022-01-21 23:05:34,037 iteration 6545 : loss : 0.009022, loss_ce: 0.002089
 96%|███████████████████████████▉ | 385/400 [2:20:23<05:45, 23.04s/it]2022-01-21 23:05:35,287 iteration 6546 : loss : 0.018174, loss_ce: 0.005666
2022-01-21 23:05:36,650 iteration 6547 : loss : 0.020464, loss_ce: 0.008016
2022-01-21 23:05:37,750 iteration 6548 : loss : 0.014336, loss_ce: 0.008879
2022-01-21 23:05:38,840 iteration 6549 : loss : 0.012019, loss_ce: 0.004440
2022-01-21 23:05:39,991 iteration 6550 : loss : 0.012760, loss_ce: 0.005207
2022-01-21 23:05:41,209 iteration 6551 : loss : 0.016884, loss_ce: 0.007930
2022-01-21 23:05:42,300 iteration 6552 : loss : 0.012689, loss_ce: 0.005867
2022-01-21 23:05:43,548 iteration 6553 : loss : 0.018159, loss_ce: 0.007115
2022-01-21 23:05:44,729 iteration 6554 : loss : 0.020524, loss_ce: 0.006434
2022-01-21 23:05:45,982 iteration 6555 : loss : 0.021673, loss_ce: 0.008760
2022-01-21 23:05:47,204 iteration 6556 : loss : 0.015648, loss_ce: 0.004392
2022-01-21 23:05:48,338 iteration 6557 : loss : 0.015167, loss_ce: 0.004857
2022-01-21 23:05:49,476 iteration 6558 : loss : 0.017258, loss_ce: 0.004646
2022-01-21 23:05:50,685 iteration 6559 : loss : 0.021300, loss_ce: 0.009739
2022-01-21 23:05:51,948 iteration 6560 : loss : 0.041022, loss_ce: 0.008429
2022-01-21 23:05:53,084 iteration 6561 : loss : 0.014508, loss_ce: 0.005603
2022-01-21 23:05:54,183 iteration 6562 : loss : 0.009366, loss_ce: 0.003046
 96%|███████████████████████████▉ | 386/400 [2:20:44<05:10, 22.17s/it]2022-01-21 23:05:55,387 iteration 6563 : loss : 0.014925, loss_ce: 0.006868
2022-01-21 23:05:56,524 iteration 6564 : loss : 0.016378, loss_ce: 0.003933
2022-01-21 23:05:57,630 iteration 6565 : loss : 0.010451, loss_ce: 0.002912
2022-01-21 23:05:58,772 iteration 6566 : loss : 0.010908, loss_ce: 0.004199
2022-01-21 23:05:59,984 iteration 6567 : loss : 0.022465, loss_ce: 0.007449
2022-01-21 23:06:01,184 iteration 6568 : loss : 0.017790, loss_ce: 0.006138
2022-01-21 23:06:02,422 iteration 6569 : loss : 0.018467, loss_ce: 0.006423
2022-01-21 23:06:03,601 iteration 6570 : loss : 0.016709, loss_ce: 0.004580
2022-01-21 23:06:04,909 iteration 6571 : loss : 0.021872, loss_ce: 0.009632
2022-01-21 23:06:06,033 iteration 6572 : loss : 0.012164, loss_ce: 0.005170
2022-01-21 23:06:07,275 iteration 6573 : loss : 0.034851, loss_ce: 0.010509
2022-01-21 23:06:08,438 iteration 6574 : loss : 0.010561, loss_ce: 0.002978
2022-01-21 23:06:09,695 iteration 6575 : loss : 0.021127, loss_ce: 0.007155
2022-01-21 23:06:10,889 iteration 6576 : loss : 0.015681, loss_ce: 0.006683
2022-01-21 23:06:12,037 iteration 6577 : loss : 0.014314, loss_ce: 0.004455
2022-01-21 23:06:13,246 iteration 6578 : loss : 0.010746, loss_ce: 0.003485
2022-01-21 23:06:14,401 iteration 6579 : loss : 0.017461, loss_ce: 0.007470
 97%|████████████████████████████ | 387/400 [2:21:04<04:40, 21.58s/it]2022-01-21 23:06:15,678 iteration 6580 : loss : 0.018177, loss_ce: 0.007804
2022-01-21 23:06:16,808 iteration 6581 : loss : 0.011626, loss_ce: 0.003421
2022-01-21 23:06:18,077 iteration 6582 : loss : 0.024539, loss_ce: 0.008293
2022-01-21 23:06:19,269 iteration 6583 : loss : 0.026616, loss_ce: 0.007794
2022-01-21 23:06:20,408 iteration 6584 : loss : 0.015774, loss_ce: 0.006196
2022-01-21 23:06:21,506 iteration 6585 : loss : 0.012311, loss_ce: 0.003874
2022-01-21 23:06:22,655 iteration 6586 : loss : 0.014005, loss_ce: 0.002845
2022-01-21 23:06:23,765 iteration 6587 : loss : 0.011666, loss_ce: 0.005531
2022-01-21 23:06:24,957 iteration 6588 : loss : 0.011147, loss_ce: 0.005239
2022-01-21 23:06:26,154 iteration 6589 : loss : 0.012799, loss_ce: 0.005142
2022-01-21 23:06:27,308 iteration 6590 : loss : 0.012382, loss_ce: 0.005458
2022-01-21 23:06:28,470 iteration 6591 : loss : 0.010118, loss_ce: 0.003599
2022-01-21 23:06:29,728 iteration 6592 : loss : 0.012977, loss_ce: 0.006559
2022-01-21 23:06:30,818 iteration 6593 : loss : 0.010473, loss_ce: 0.005379
2022-01-21 23:06:31,967 iteration 6594 : loss : 0.012272, loss_ce: 0.004225
2022-01-21 23:06:33,180 iteration 6595 : loss : 0.014280, loss_ce: 0.004384
2022-01-21 23:06:34,307 iteration 6596 : loss : 0.011802, loss_ce: 0.003247
 97%|████████████████████████████▏| 388/400 [2:21:24<04:13, 21.08s/it]2022-01-21 23:06:35,482 iteration 6597 : loss : 0.011403, loss_ce: 0.005694
2022-01-21 23:06:36,705 iteration 6598 : loss : 0.015522, loss_ce: 0.002721
2022-01-21 23:06:37,945 iteration 6599 : loss : 0.016927, loss_ce: 0.007003
2022-01-21 23:06:39,076 iteration 6600 : loss : 0.012630, loss_ce: 0.005538
2022-01-21 23:06:40,350 iteration 6601 : loss : 0.016786, loss_ce: 0.007429
2022-01-21 23:06:41,579 iteration 6602 : loss : 0.018737, loss_ce: 0.007209
2022-01-21 23:06:42,728 iteration 6603 : loss : 0.012512, loss_ce: 0.005190
2022-01-21 23:06:43,945 iteration 6604 : loss : 0.017742, loss_ce: 0.008338
2022-01-21 23:06:45,104 iteration 6605 : loss : 0.015962, loss_ce: 0.008831
2022-01-21 23:06:46,357 iteration 6606 : loss : 0.018346, loss_ce: 0.005666
2022-01-21 23:06:47,608 iteration 6607 : loss : 0.021803, loss_ce: 0.008654
2022-01-21 23:06:48,731 iteration 6608 : loss : 0.014837, loss_ce: 0.006810
2022-01-21 23:06:49,963 iteration 6609 : loss : 0.019609, loss_ce: 0.008081
2022-01-21 23:06:51,123 iteration 6610 : loss : 0.013692, loss_ce: 0.005142
2022-01-21 23:06:52,283 iteration 6611 : loss : 0.009964, loss_ce: 0.002430
2022-01-21 23:06:53,458 iteration 6612 : loss : 0.013271, loss_ce: 0.003402
2022-01-21 23:06:54,681 iteration 6613 : loss : 0.015816, loss_ce: 0.005506
 97%|████████████████████████████▏| 389/400 [2:21:44<03:49, 20.87s/it]2022-01-21 23:06:55,870 iteration 6614 : loss : 0.011350, loss_ce: 0.003881
2022-01-21 23:06:56,976 iteration 6615 : loss : 0.008817, loss_ce: 0.003373
2022-01-21 23:06:58,185 iteration 6616 : loss : 0.014453, loss_ce: 0.005218
2022-01-21 23:06:59,348 iteration 6617 : loss : 0.025281, loss_ce: 0.009229
2022-01-21 23:07:00,609 iteration 6618 : loss : 0.018439, loss_ce: 0.006800
2022-01-21 23:07:01,795 iteration 6619 : loss : 0.015898, loss_ce: 0.005236
2022-01-21 23:07:02,988 iteration 6620 : loss : 0.014647, loss_ce: 0.004428
2022-01-21 23:07:04,227 iteration 6621 : loss : 0.018414, loss_ce: 0.006298
2022-01-21 23:07:05,386 iteration 6622 : loss : 0.014281, loss_ce: 0.006312
2022-01-21 23:07:06,513 iteration 6623 : loss : 0.014212, loss_ce: 0.004463
2022-01-21 23:07:07,681 iteration 6624 : loss : 0.014868, loss_ce: 0.006275
2022-01-21 23:07:08,879 iteration 6625 : loss : 0.033942, loss_ce: 0.013044
2022-01-21 23:07:10,060 iteration 6626 : loss : 0.020548, loss_ce: 0.009348
2022-01-21 23:07:11,288 iteration 6627 : loss : 0.021663, loss_ce: 0.009142
2022-01-21 23:07:12,504 iteration 6628 : loss : 0.017597, loss_ce: 0.007494
2022-01-21 23:07:13,804 iteration 6629 : loss : 0.019430, loss_ce: 0.004780
2022-01-21 23:07:13,804 Training Data Eval:
2022-01-21 23:07:19,498   Average segmentation loss on training set: 0.0083
2022-01-21 23:07:19,498 Validation Data Eval:
2022-01-21 23:07:21,458   Average segmentation loss on validation set: 0.0682
2022-01-21 23:07:22,607 iteration 6630 : loss : 0.014254, loss_ce: 0.005091
 98%|████████████████████████████▎| 390/400 [2:22:12<03:49, 22.98s/it]2022-01-21 23:07:23,828 iteration 6631 : loss : 0.019513, loss_ce: 0.006003
2022-01-21 23:07:24,974 iteration 6632 : loss : 0.012507, loss_ce: 0.006416
2022-01-21 23:07:26,191 iteration 6633 : loss : 0.018792, loss_ce: 0.004815
2022-01-21 23:07:27,350 iteration 6634 : loss : 0.012149, loss_ce: 0.004584
2022-01-21 23:07:28,524 iteration 6635 : loss : 0.017102, loss_ce: 0.007274
2022-01-21 23:07:29,712 iteration 6636 : loss : 0.010057, loss_ce: 0.004679
2022-01-21 23:07:30,851 iteration 6637 : loss : 0.015492, loss_ce: 0.005499
2022-01-21 23:07:32,082 iteration 6638 : loss : 0.033945, loss_ce: 0.007753
2022-01-21 23:07:33,320 iteration 6639 : loss : 0.013541, loss_ce: 0.005531
2022-01-21 23:07:34,488 iteration 6640 : loss : 0.012787, loss_ce: 0.004187
2022-01-21 23:07:35,689 iteration 6641 : loss : 0.014612, loss_ce: 0.004374
2022-01-21 23:07:36,885 iteration 6642 : loss : 0.016552, loss_ce: 0.007393
2022-01-21 23:07:38,079 iteration 6643 : loss : 0.015912, loss_ce: 0.006552
2022-01-21 23:07:39,380 iteration 6644 : loss : 0.026517, loss_ce: 0.009906
2022-01-21 23:07:40,535 iteration 6645 : loss : 0.013893, loss_ce: 0.005679
2022-01-21 23:07:41,818 iteration 6646 : loss : 0.020951, loss_ce: 0.006294
2022-01-21 23:07:42,992 iteration 6647 : loss : 0.018291, loss_ce: 0.006581
 98%|████████████████████████████▎| 391/400 [2:22:32<03:19, 22.21s/it]2022-01-21 23:07:44,201 iteration 6648 : loss : 0.017365, loss_ce: 0.003903
2022-01-21 23:07:45,419 iteration 6649 : loss : 0.014284, loss_ce: 0.003882
2022-01-21 23:07:46,683 iteration 6650 : loss : 0.019074, loss_ce: 0.008884
2022-01-21 23:07:47,975 iteration 6651 : loss : 0.024119, loss_ce: 0.009637
2022-01-21 23:07:49,159 iteration 6652 : loss : 0.013541, loss_ce: 0.005779
2022-01-21 23:07:50,276 iteration 6653 : loss : 0.010659, loss_ce: 0.004378
2022-01-21 23:07:51,448 iteration 6654 : loss : 0.015172, loss_ce: 0.005365
2022-01-21 23:07:52,672 iteration 6655 : loss : 0.019135, loss_ce: 0.007043
2022-01-21 23:07:53,890 iteration 6656 : loss : 0.018324, loss_ce: 0.007020
2022-01-21 23:07:55,092 iteration 6657 : loss : 0.010717, loss_ce: 0.002862
2022-01-21 23:07:56,319 iteration 6658 : loss : 0.013111, loss_ce: 0.004602
2022-01-21 23:07:57,514 iteration 6659 : loss : 0.015914, loss_ce: 0.006771
2022-01-21 23:07:58,760 iteration 6660 : loss : 0.024489, loss_ce: 0.011237
2022-01-21 23:07:59,970 iteration 6661 : loss : 0.013197, loss_ce: 0.005493
2022-01-21 23:08:01,194 iteration 6662 : loss : 0.017073, loss_ce: 0.004187
2022-01-21 23:08:02,402 iteration 6663 : loss : 0.016285, loss_ce: 0.005767
2022-01-21 23:08:03,631 iteration 6664 : loss : 0.016930, loss_ce: 0.009020
 98%|████████████████████████████▍| 392/400 [2:22:53<02:53, 21.74s/it]2022-01-21 23:08:04,887 iteration 6665 : loss : 0.019642, loss_ce: 0.006002
2022-01-21 23:08:06,188 iteration 6666 : loss : 0.024481, loss_ce: 0.006938
2022-01-21 23:08:07,415 iteration 6667 : loss : 0.029339, loss_ce: 0.004886
2022-01-21 23:08:08,526 iteration 6668 : loss : 0.015403, loss_ce: 0.007391
2022-01-21 23:08:09,698 iteration 6669 : loss : 0.019258, loss_ce: 0.007454
2022-01-21 23:08:10,873 iteration 6670 : loss : 0.012971, loss_ce: 0.005837
2022-01-21 23:08:12,087 iteration 6671 : loss : 0.021720, loss_ce: 0.007308
2022-01-21 23:08:13,313 iteration 6672 : loss : 0.016569, loss_ce: 0.005211
2022-01-21 23:08:14,495 iteration 6673 : loss : 0.020480, loss_ce: 0.004492
2022-01-21 23:08:15,678 iteration 6674 : loss : 0.016858, loss_ce: 0.007973
2022-01-21 23:08:16,950 iteration 6675 : loss : 0.022478, loss_ce: 0.010807
2022-01-21 23:08:18,106 iteration 6676 : loss : 0.013924, loss_ce: 0.005547
2022-01-21 23:08:19,244 iteration 6677 : loss : 0.016126, loss_ce: 0.005180
2022-01-21 23:08:20,425 iteration 6678 : loss : 0.013128, loss_ce: 0.006252
2022-01-21 23:08:21,656 iteration 6679 : loss : 0.017796, loss_ce: 0.006710
2022-01-21 23:08:22,792 iteration 6680 : loss : 0.010053, loss_ce: 0.003639
2022-01-21 23:08:23,899 iteration 6681 : loss : 0.010228, loss_ce: 0.003391
 98%|████████████████████████████▍| 393/400 [2:23:13<02:29, 21.30s/it]2022-01-21 23:08:25,213 iteration 6682 : loss : 0.020225, loss_ce: 0.009250
2022-01-21 23:08:26,357 iteration 6683 : loss : 0.013251, loss_ce: 0.005160
2022-01-21 23:08:27,542 iteration 6684 : loss : 0.012316, loss_ce: 0.005711
2022-01-21 23:08:28,675 iteration 6685 : loss : 0.022377, loss_ce: 0.007768
2022-01-21 23:08:29,926 iteration 6686 : loss : 0.016362, loss_ce: 0.006686
2022-01-21 23:08:31,099 iteration 6687 : loss : 0.012793, loss_ce: 0.004540
2022-01-21 23:08:32,295 iteration 6688 : loss : 0.016347, loss_ce: 0.006210
2022-01-21 23:08:33,402 iteration 6689 : loss : 0.008516, loss_ce: 0.002284
2022-01-21 23:08:34,581 iteration 6690 : loss : 0.008635, loss_ce: 0.002513
2022-01-21 23:08:35,803 iteration 6691 : loss : 0.018412, loss_ce: 0.006541
2022-01-21 23:08:36,950 iteration 6692 : loss : 0.017930, loss_ce: 0.007076
2022-01-21 23:08:38,114 iteration 6693 : loss : 0.016018, loss_ce: 0.005656
2022-01-21 23:08:39,319 iteration 6694 : loss : 0.017199, loss_ce: 0.004966
2022-01-21 23:08:40,475 iteration 6695 : loss : 0.015340, loss_ce: 0.004957
2022-01-21 23:08:41,654 iteration 6696 : loss : 0.011880, loss_ce: 0.004662
2022-01-21 23:08:42,825 iteration 6697 : loss : 0.014192, loss_ce: 0.004866
2022-01-21 23:08:44,077 iteration 6698 : loss : 0.015187, loss_ce: 0.004798
 98%|████████████████████████████▌| 394/400 [2:23:34<02:05, 20.96s/it]2022-01-21 23:08:45,278 iteration 6699 : loss : 0.013115, loss_ce: 0.004641
2022-01-21 23:08:46,524 iteration 6700 : loss : 0.018675, loss_ce: 0.005607
2022-01-21 23:08:47,700 iteration 6701 : loss : 0.011653, loss_ce: 0.003653
2022-01-21 23:08:48,826 iteration 6702 : loss : 0.010528, loss_ce: 0.005129
2022-01-21 23:08:49,931 iteration 6703 : loss : 0.011240, loss_ce: 0.003783
2022-01-21 23:08:51,147 iteration 6704 : loss : 0.018768, loss_ce: 0.008782
2022-01-21 23:08:52,273 iteration 6705 : loss : 0.016964, loss_ce: 0.008201
2022-01-21 23:08:53,522 iteration 6706 : loss : 0.013320, loss_ce: 0.004201
2022-01-21 23:08:54,644 iteration 6707 : loss : 0.010146, loss_ce: 0.004207
2022-01-21 23:08:55,825 iteration 6708 : loss : 0.018454, loss_ce: 0.008039
2022-01-21 23:08:57,015 iteration 6709 : loss : 0.019931, loss_ce: 0.008705
2022-01-21 23:08:58,232 iteration 6710 : loss : 0.030966, loss_ce: 0.013987
2022-01-21 23:08:59,447 iteration 6711 : loss : 0.014160, loss_ce: 0.003911
2022-01-21 23:09:00,720 iteration 6712 : loss : 0.016788, loss_ce: 0.006463
2022-01-21 23:09:01,852 iteration 6713 : loss : 0.012240, loss_ce: 0.004740
2022-01-21 23:09:03,037 iteration 6714 : loss : 0.015512, loss_ce: 0.004799
2022-01-21 23:09:03,037 Training Data Eval:
2022-01-21 23:09:08,733   Average segmentation loss on training set: 0.0084
2022-01-21 23:09:08,733 Validation Data Eval:
2022-01-21 23:09:10,706   Average segmentation loss on validation set: 0.0601
2022-01-21 23:09:11,835 iteration 6715 : loss : 0.014452, loss_ce: 0.005199
 99%|████████████████████████████▋| 395/400 [2:24:01<01:54, 23.00s/it]2022-01-21 23:09:13,051 iteration 6716 : loss : 0.015597, loss_ce: 0.007118
2022-01-21 23:09:14,202 iteration 6717 : loss : 0.012976, loss_ce: 0.005466
2022-01-21 23:09:15,378 iteration 6718 : loss : 0.016680, loss_ce: 0.006012
2022-01-21 23:09:16,518 iteration 6719 : loss : 0.014258, loss_ce: 0.005151
2022-01-21 23:09:17,673 iteration 6720 : loss : 0.011734, loss_ce: 0.003280
2022-01-21 23:09:18,811 iteration 6721 : loss : 0.011263, loss_ce: 0.003628
2022-01-21 23:09:20,068 iteration 6722 : loss : 0.016292, loss_ce: 0.006980
2022-01-21 23:09:21,155 iteration 6723 : loss : 0.012003, loss_ce: 0.003609
2022-01-21 23:09:22,326 iteration 6724 : loss : 0.017710, loss_ce: 0.006288
2022-01-21 23:09:23,528 iteration 6725 : loss : 0.013185, loss_ce: 0.004226
2022-01-21 23:09:24,757 iteration 6726 : loss : 0.015217, loss_ce: 0.006766
2022-01-21 23:09:26,040 iteration 6727 : loss : 0.017933, loss_ce: 0.006287
2022-01-21 23:09:27,219 iteration 6728 : loss : 0.014846, loss_ce: 0.005159
2022-01-21 23:09:28,393 iteration 6729 : loss : 0.018257, loss_ce: 0.005253
2022-01-21 23:09:29,528 iteration 6730 : loss : 0.010563, loss_ce: 0.004082
2022-01-21 23:09:30,702 iteration 6731 : loss : 0.013283, loss_ce: 0.005041
2022-01-21 23:09:31,926 iteration 6732 : loss : 0.014782, loss_ce: 0.005703
 99%|████████████████████████████▋| 396/400 [2:24:21<01:28, 22.13s/it]2022-01-21 23:09:33,131 iteration 6733 : loss : 0.010521, loss_ce: 0.003722
2022-01-21 23:09:34,418 iteration 6734 : loss : 0.016598, loss_ce: 0.006210
2022-01-21 23:09:35,559 iteration 6735 : loss : 0.010526, loss_ce: 0.004041
2022-01-21 23:09:36,791 iteration 6736 : loss : 0.017814, loss_ce: 0.006679
2022-01-21 23:09:38,017 iteration 6737 : loss : 0.016706, loss_ce: 0.005740
2022-01-21 23:09:39,115 iteration 6738 : loss : 0.012831, loss_ce: 0.003667
2022-01-21 23:09:40,263 iteration 6739 : loss : 0.012868, loss_ce: 0.004835
2022-01-21 23:09:41,473 iteration 6740 : loss : 0.011291, loss_ce: 0.004676
2022-01-21 23:09:42,631 iteration 6741 : loss : 0.011415, loss_ce: 0.004141
2022-01-21 23:09:43,778 iteration 6742 : loss : 0.013614, loss_ce: 0.004456
2022-01-21 23:09:44,983 iteration 6743 : loss : 0.018555, loss_ce: 0.008827
2022-01-21 23:09:46,188 iteration 6744 : loss : 0.018336, loss_ce: 0.008382
2022-01-21 23:09:47,329 iteration 6745 : loss : 0.012530, loss_ce: 0.004748
2022-01-21 23:09:48,521 iteration 6746 : loss : 0.018274, loss_ce: 0.006820
2022-01-21 23:09:49,760 iteration 6747 : loss : 0.030184, loss_ce: 0.008777
2022-01-21 23:09:50,989 iteration 6748 : loss : 0.016155, loss_ce: 0.005259
2022-01-21 23:09:52,184 iteration 6749 : loss : 0.015509, loss_ce: 0.006357
 99%|████████████████████████████▊| 397/400 [2:24:42<01:04, 21.57s/it]2022-01-21 23:09:53,440 iteration 6750 : loss : 0.017079, loss_ce: 0.006769
2022-01-21 23:09:54,728 iteration 6751 : loss : 0.015317, loss_ce: 0.004735
2022-01-21 23:09:55,982 iteration 6752 : loss : 0.023714, loss_ce: 0.011201
2022-01-21 23:09:57,159 iteration 6753 : loss : 0.038115, loss_ce: 0.019983
2022-01-21 23:09:58,416 iteration 6754 : loss : 0.018485, loss_ce: 0.007175
2022-01-21 23:09:59,567 iteration 6755 : loss : 0.011558, loss_ce: 0.003115
2022-01-21 23:10:00,645 iteration 6756 : loss : 0.009406, loss_ce: 0.004235
2022-01-21 23:10:01,758 iteration 6757 : loss : 0.011623, loss_ce: 0.004758
2022-01-21 23:10:02,915 iteration 6758 : loss : 0.011464, loss_ce: 0.005394
2022-01-21 23:10:04,129 iteration 6759 : loss : 0.016905, loss_ce: 0.004625
2022-01-21 23:10:05,281 iteration 6760 : loss : 0.012360, loss_ce: 0.005060
2022-01-21 23:10:06,434 iteration 6761 : loss : 0.014434, loss_ce: 0.005311
2022-01-21 23:10:07,623 iteration 6762 : loss : 0.018343, loss_ce: 0.005339
2022-01-21 23:10:08,799 iteration 6763 : loss : 0.015645, loss_ce: 0.007444
2022-01-21 23:10:10,050 iteration 6764 : loss : 0.018173, loss_ce: 0.006407
2022-01-21 23:10:11,256 iteration 6765 : loss : 0.017414, loss_ce: 0.004518
2022-01-21 23:10:12,425 iteration 6766 : loss : 0.013192, loss_ce: 0.005747
100%|████████████████████████████▊| 398/400 [2:25:02<00:42, 21.17s/it]2022-01-21 23:10:13,706 iteration 6767 : loss : 0.023457, loss_ce: 0.009805
2022-01-21 23:10:14,864 iteration 6768 : loss : 0.014129, loss_ce: 0.004504
2022-01-21 23:10:16,018 iteration 6769 : loss : 0.012097, loss_ce: 0.003875
2022-01-21 23:10:17,211 iteration 6770 : loss : 0.025454, loss_ce: 0.007928
2022-01-21 23:10:18,367 iteration 6771 : loss : 0.016242, loss_ce: 0.007601
2022-01-21 23:10:19,551 iteration 6772 : loss : 0.013765, loss_ce: 0.005665
2022-01-21 23:10:20,663 iteration 6773 : loss : 0.010882, loss_ce: 0.004180
2022-01-21 23:10:21,824 iteration 6774 : loss : 0.019452, loss_ce: 0.006216
2022-01-21 23:10:22,961 iteration 6775 : loss : 0.016695, loss_ce: 0.003667
2022-01-21 23:10:24,128 iteration 6776 : loss : 0.014679, loss_ce: 0.005426
2022-01-21 23:10:25,309 iteration 6777 : loss : 0.015277, loss_ce: 0.006100
2022-01-21 23:10:26,438 iteration 6778 : loss : 0.012628, loss_ce: 0.004434
2022-01-21 23:10:27,596 iteration 6779 : loss : 0.010601, loss_ce: 0.004993
2022-01-21 23:10:28,809 iteration 6780 : loss : 0.013901, loss_ce: 0.005198
2022-01-21 23:10:30,000 iteration 6781 : loss : 0.014849, loss_ce: 0.006149
2022-01-21 23:10:31,150 iteration 6782 : loss : 0.013266, loss_ce: 0.005327
2022-01-21 23:10:32,387 iteration 6783 : loss : 0.024998, loss_ce: 0.010241
100%|████████████████████████████▉| 399/400 [2:25:22<00:20, 20.81s/it]2022-01-21 23:10:33,536 iteration 6784 : loss : 0.011695, loss_ce: 0.006045
2022-01-21 23:10:34,693 iteration 6785 : loss : 0.012441, loss_ce: 0.004052
2022-01-21 23:10:35,905 iteration 6786 : loss : 0.014187, loss_ce: 0.005470
2022-01-21 23:10:37,075 iteration 6787 : loss : 0.018814, loss_ce: 0.004846
2022-01-21 23:10:38,247 iteration 6788 : loss : 0.015392, loss_ce: 0.007542
2022-01-21 23:10:39,493 iteration 6789 : loss : 0.026955, loss_ce: 0.010786
2022-01-21 23:10:40,678 iteration 6790 : loss : 0.016728, loss_ce: 0.007293
2022-01-21 23:10:41,924 iteration 6791 : loss : 0.021799, loss_ce: 0.006913
2022-01-21 23:10:43,094 iteration 6792 : loss : 0.025971, loss_ce: 0.011065
2022-01-21 23:10:44,195 iteration 6793 : loss : 0.010017, loss_ce: 0.003681
2022-01-21 23:10:45,410 iteration 6794 : loss : 0.018588, loss_ce: 0.006766
2022-01-21 23:10:46,536 iteration 6795 : loss : 0.010108, loss_ce: 0.004233
2022-01-21 23:10:47,702 iteration 6796 : loss : 0.011495, loss_ce: 0.002781
2022-01-21 23:10:48,852 iteration 6797 : loss : 0.013871, loss_ce: 0.004821
2022-01-21 23:10:50,079 iteration 6798 : loss : 0.019357, loss_ce: 0.007011
2022-01-21 23:10:51,242 iteration 6799 : loss : 0.016098, loss_ce: 0.005637
2022-01-21 23:10:51,242 Training Data Eval:
2022-01-21 23:10:56,949   Average segmentation loss on training set: 0.0081
2022-01-21 23:10:56,949 Validation Data Eval:
2022-01-21 23:10:58,906   Average segmentation loss on validation set: 0.0647
2022-01-21 23:11:00,076 iteration 6800 : loss : 0.015934, loss_ce: 0.006155
100%|█████████████████████████████| 400/400 [2:25:50<00:00, 22.87s/it]100%|█████████████████████████████| 400/400 [2:25:50<00:00, 21.88s/it]
