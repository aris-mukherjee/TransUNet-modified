2022-01-20 15:40:11,468 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-20 15:40:11,469 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-20 15:40:11,469 ============================================================
2022-01-20 15:40:11,469 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-20 15:40:11,469 ============================================================
2022-01-20 15:40:11,469 Loading data...
2022-01-20 15:40:11,469 Reading NCI - RUNMC images...
2022-01-20 15:40:11,469 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-20 15:40:11,472 Already preprocessed this configuration. Loading now!
2022-01-20 15:40:11,494 Training Images: (256, 256, 286)
2022-01-20 15:40:11,494 Training Labels: (256, 256, 286)
2022-01-20 15:40:11,494 Validation Images: (256, 256, 98)
2022-01-20 15:40:11,494 Validation Labels: (256, 256, 98)
2022-01-20 15:40:11,494 ============================================================
2022-01-20 15:40:11,517 17 iterations per epoch. 6800 max iterations 

  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-20 15:40:15,104 iteration 1 : loss : 0.765507, loss_ce: 0.862203
2022-01-20 15:40:16,333 iteration 2 : loss : 0.724417, loss_ce: 0.775930
2022-01-20 15:40:17,531 iteration 3 : loss : 0.686810, loss_ce: 0.694277
2022-01-20 15:40:18,807 iteration 4 : loss : 0.633328, loss_ce: 0.645075
2022-01-20 15:40:19,984 iteration 5 : loss : 0.606758, loss_ce: 0.568409
2022-01-20 15:40:21,287 iteration 6 : loss : 0.562914, loss_ce: 0.510330
2022-01-20 15:40:22,562 iteration 7 : loss : 0.544551, loss_ce: 0.467368
2022-01-20 15:40:23,837 iteration 8 : loss : 0.506057, loss_ce: 0.417697
2022-01-20 15:40:24,979 iteration 9 : loss : 0.470426, loss_ce: 0.398128
2022-01-20 15:40:26,268 iteration 10 : loss : 0.456269, loss_ce: 0.361855
2022-01-20 15:40:27,555 iteration 11 : loss : 0.437914, loss_ce: 0.325216
2022-01-20 15:40:28,890 iteration 12 : loss : 0.419916, loss_ce: 0.305483
2022-01-20 15:40:30,115 iteration 13 : loss : 0.399958, loss_ce: 0.268624
2022-01-20 15:40:31,444 iteration 14 : loss : 0.397992, loss_ce: 0.257848
2022-01-20 15:40:32,697 iteration 15 : loss : 0.370580, loss_ce: 0.228627
2022-01-20 15:40:33,923 iteration 16 : loss : 0.376727, loss_ce: 0.231729
2022-01-20 15:40:35,118 iteration 17 : loss : 0.370463, loss_ce: 0.200598

  0%|                               | 1/400 [00:23<2:37:33, 23.69s/it]2022-01-20 15:40:36,487 iteration 18 : loss : 0.363516, loss_ce: 0.214544
2022-01-20 15:40:37,770 iteration 19 : loss : 0.344116, loss_ce: 0.170243
2022-01-20 15:40:39,148 iteration 20 : loss : 0.333605, loss_ce: 0.175646
2022-01-20 15:40:40,376 iteration 21 : loss : 0.364505, loss_ce: 0.171584
2022-01-20 15:40:41,540 iteration 22 : loss : 0.320336, loss_ce: 0.154379
2022-01-20 15:40:42,846 iteration 23 : loss : 0.322433, loss_ce: 0.157462
2022-01-20 15:40:44,156 iteration 24 : loss : 0.290029, loss_ce: 0.152319
2022-01-20 15:40:45,491 iteration 25 : loss : 0.323366, loss_ce: 0.188919
2022-01-20 15:40:46,739 iteration 26 : loss : 0.316382, loss_ce: 0.166951
2022-01-20 15:40:47,929 iteration 27 : loss : 0.312681, loss_ce: 0.163428
2022-01-20 15:40:49,100 iteration 28 : loss : 0.244769, loss_ce: 0.119235
2022-01-20 15:40:50,389 iteration 29 : loss : 0.319065, loss_ce: 0.156730
2022-01-20 15:40:51,626 iteration 30 : loss : 0.271064, loss_ce: 0.129016
2022-01-20 15:40:52,855 iteration 31 : loss : 0.242056, loss_ce: 0.099365
2022-01-20 15:40:54,132 iteration 32 : loss : 0.281177, loss_ce: 0.149297
2022-01-20 15:40:55,469 iteration 33 : loss : 0.286876, loss_ce: 0.136888
2022-01-20 15:40:56,872 iteration 34 : loss : 0.220150, loss_ce: 0.098801

  0%|▏                              | 2/400 [00:45<2:29:29, 22.54s/it]2022-01-20 15:40:58,257 iteration 35 : loss : 0.230790, loss_ce: 0.111047
2022-01-20 15:40:59,562 iteration 36 : loss : 0.275086, loss_ce: 0.101493
2022-01-20 15:41:00,887 iteration 37 : loss : 0.241728, loss_ce: 0.100962
2022-01-20 15:41:02,179 iteration 38 : loss : 0.265456, loss_ce: 0.104689
2022-01-20 15:41:03,371 iteration 39 : loss : 0.277932, loss_ce: 0.124247
2022-01-20 15:41:04,655 iteration 40 : loss : 0.313580, loss_ce: 0.144833
2022-01-20 15:41:05,853 iteration 41 : loss : 0.199000, loss_ce: 0.090237
2022-01-20 15:41:07,185 iteration 42 : loss : 0.308322, loss_ce: 0.159262
2022-01-20 15:41:08,481 iteration 43 : loss : 0.240811, loss_ce: 0.117018
2022-01-20 15:41:09,684 iteration 44 : loss : 0.261865, loss_ce: 0.145994
2022-01-20 15:41:11,065 iteration 45 : loss : 0.269702, loss_ce: 0.116816
2022-01-20 15:41:12,366 iteration 46 : loss : 0.241829, loss_ce: 0.109469
2022-01-20 15:41:13,675 iteration 47 : loss : 0.253295, loss_ce: 0.095519
2022-01-20 15:41:14,983 iteration 48 : loss : 0.234202, loss_ce: 0.104033
2022-01-20 15:41:16,338 iteration 49 : loss : 0.308718, loss_ce: 0.137566
2022-01-20 15:41:17,691 iteration 50 : loss : 0.243508, loss_ce: 0.098391
2022-01-20 15:41:19,054 iteration 51 : loss : 0.218882, loss_ce: 0.091181

  1%|▏                              | 3/400 [01:07<2:28:02, 22.38s/it]2022-01-20 15:41:20,335 iteration 52 : loss : 0.277050, loss_ce: 0.107536
2022-01-20 15:41:21,540 iteration 53 : loss : 0.227244, loss_ce: 0.103833
2022-01-20 15:41:22,906 iteration 54 : loss : 0.199240, loss_ce: 0.083206
2022-01-20 15:41:24,234 iteration 55 : loss : 0.242880, loss_ce: 0.089672
2022-01-20 15:41:25,573 iteration 56 : loss : 0.408361, loss_ce: 0.216578
2022-01-20 15:41:26,833 iteration 57 : loss : 0.328530, loss_ce: 0.159536
2022-01-20 15:41:28,078 iteration 58 : loss : 0.369330, loss_ce: 0.178699
2022-01-20 15:41:29,314 iteration 59 : loss : 0.314120, loss_ce: 0.134817
2022-01-20 15:41:30,580 iteration 60 : loss : 0.316472, loss_ce: 0.146929
2022-01-20 15:41:31,856 iteration 61 : loss : 0.241320, loss_ce: 0.105851
2022-01-20 15:41:33,224 iteration 62 : loss : 0.285579, loss_ce: 0.109334
2022-01-20 15:41:34,472 iteration 63 : loss : 0.269925, loss_ce: 0.127762
2022-01-20 15:41:35,794 iteration 64 : loss : 0.287370, loss_ce: 0.120564
2022-01-20 15:41:37,111 iteration 65 : loss : 0.258293, loss_ce: 0.103559
2022-01-20 15:41:38,470 iteration 66 : loss : 0.275327, loss_ce: 0.118346
2022-01-20 15:41:39,745 iteration 67 : loss : 0.252439, loss_ce: 0.116257
2022-01-20 15:41:40,960 iteration 68 : loss : 0.240174, loss_ce: 0.104369

  1%|▎                              | 4/400 [01:29<2:26:26, 22.19s/it]2022-01-20 15:41:42,361 iteration 69 : loss : 0.277055, loss_ce: 0.121304
2022-01-20 15:41:43,634 iteration 70 : loss : 0.315492, loss_ce: 0.121653
2022-01-20 15:41:44,931 iteration 71 : loss : 0.288202, loss_ce: 0.152307
2022-01-20 15:41:46,251 iteration 72 : loss : 0.246589, loss_ce: 0.105332
2022-01-20 15:41:47,596 iteration 73 : loss : 0.227442, loss_ce: 0.084063
2022-01-20 15:41:48,926 iteration 74 : loss : 0.218025, loss_ce: 0.089844
2022-01-20 15:41:50,202 iteration 75 : loss : 0.223726, loss_ce: 0.108371
2022-01-20 15:41:51,411 iteration 76 : loss : 0.246972, loss_ce: 0.117719
2022-01-20 15:41:52,737 iteration 77 : loss : 0.273727, loss_ce: 0.123645
2022-01-20 15:41:54,074 iteration 78 : loss : 0.234824, loss_ce: 0.095431
2022-01-20 15:41:55,400 iteration 79 : loss : 0.264941, loss_ce: 0.102849
2022-01-20 15:41:56,598 iteration 80 : loss : 0.225630, loss_ce: 0.084570
2022-01-20 15:41:57,977 iteration 81 : loss : 0.311884, loss_ce: 0.141538
2022-01-20 15:41:59,242 iteration 82 : loss : 0.296307, loss_ce: 0.099069
2022-01-20 15:42:00,475 iteration 83 : loss : 0.306345, loss_ce: 0.097416
2022-01-20 15:42:01,882 iteration 84 : loss : 0.304022, loss_ce: 0.141547
2022-01-20 15:42:01,883 Training Data Eval:
2022-01-20 15:42:08,419   Average segmentation loss on training set: 0.3338
2022-01-20 15:42:08,419 Validation Data Eval:
2022-01-20 15:42:10,866   Average segmentation loss on validation set: 0.3874
2022-01-20 15:42:16,006 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 15:42:17,210 iteration 85 : loss : 0.294167, loss_ce: 0.144578

  1%|▍                              | 5/400 [02:05<2:59:29, 27.26s/it]2022-01-20 15:42:18,557 iteration 86 : loss : 0.230577, loss_ce: 0.110595
2022-01-20 15:42:19,776 iteration 87 : loss : 0.263210, loss_ce: 0.111167
2022-01-20 15:42:20,951 iteration 88 : loss : 0.236213, loss_ce: 0.119571
2022-01-20 15:42:22,210 iteration 89 : loss : 0.278693, loss_ce: 0.105235
2022-01-20 15:42:23,444 iteration 90 : loss : 0.223034, loss_ce: 0.095740
2022-01-20 15:42:24,742 iteration 91 : loss : 0.238844, loss_ce: 0.108505
2022-01-20 15:42:26,055 iteration 92 : loss : 0.236392, loss_ce: 0.087721
2022-01-20 15:42:27,264 iteration 93 : loss : 0.224250, loss_ce: 0.078846
2022-01-20 15:42:28,598 iteration 94 : loss : 0.218048, loss_ce: 0.095484
2022-01-20 15:42:29,892 iteration 95 : loss : 0.256504, loss_ce: 0.118400
2022-01-20 15:42:31,267 iteration 96 : loss : 0.237548, loss_ce: 0.099202
2022-01-20 15:42:32,564 iteration 97 : loss : 0.233868, loss_ce: 0.089236
2022-01-20 15:42:33,894 iteration 98 : loss : 0.275629, loss_ce: 0.110309
2022-01-20 15:42:35,183 iteration 99 : loss : 0.312715, loss_ce: 0.122188
2022-01-20 15:42:36,522 iteration 100 : loss : 0.240204, loss_ce: 0.101649
2022-01-20 15:42:37,806 iteration 101 : loss : 0.219205, loss_ce: 0.094294
2022-01-20 15:42:39,078 iteration 102 : loss : 0.239986, loss_ce: 0.113382

  2%|▍                              | 6/400 [02:27<2:46:57, 25.42s/it]2022-01-20 15:42:40,471 iteration 103 : loss : 0.257642, loss_ce: 0.098724
2022-01-20 15:42:41,830 iteration 104 : loss : 0.250413, loss_ce: 0.106527
2022-01-20 15:42:43,225 iteration 105 : loss : 0.167347, loss_ce: 0.065572
2022-01-20 15:42:44,644 iteration 106 : loss : 0.233265, loss_ce: 0.095142
2022-01-20 15:42:45,975 iteration 107 : loss : 0.251270, loss_ce: 0.090739
2022-01-20 15:42:47,268 iteration 108 : loss : 0.231688, loss_ce: 0.078529
2022-01-20 15:42:48,498 iteration 109 : loss : 0.270012, loss_ce: 0.105393
2022-01-20 15:42:49,787 iteration 110 : loss : 0.215533, loss_ce: 0.090016
2022-01-20 15:42:51,159 iteration 111 : loss : 0.194251, loss_ce: 0.091093
2022-01-20 15:42:52,448 iteration 112 : loss : 0.238325, loss_ce: 0.095934
2022-01-20 15:42:53,675 iteration 113 : loss : 0.227218, loss_ce: 0.089408
2022-01-20 15:42:55,024 iteration 114 : loss : 0.223671, loss_ce: 0.086040
2022-01-20 15:42:56,303 iteration 115 : loss : 0.181954, loss_ce: 0.094343
2022-01-20 15:42:57,642 iteration 116 : loss : 0.246019, loss_ce: 0.122494
2022-01-20 15:42:58,906 iteration 117 : loss : 0.231864, loss_ce: 0.097239
2022-01-20 15:43:00,199 iteration 118 : loss : 0.262272, loss_ce: 0.117182
2022-01-20 15:43:01,513 iteration 119 : loss : 0.180627, loss_ce: 0.064750

  2%|▌                              | 7/400 [02:50<2:40:08, 24.45s/it]2022-01-20 15:43:02,940 iteration 120 : loss : 0.194068, loss_ce: 0.081876
2022-01-20 15:43:04,273 iteration 121 : loss : 0.268924, loss_ce: 0.107307
2022-01-20 15:43:05,491 iteration 122 : loss : 0.226971, loss_ce: 0.101509
2022-01-20 15:43:06,849 iteration 123 : loss : 0.186249, loss_ce: 0.081483
2022-01-20 15:43:08,196 iteration 124 : loss : 0.222241, loss_ce: 0.083880
2022-01-20 15:43:09,492 iteration 125 : loss : 0.228651, loss_ce: 0.099465
2022-01-20 15:43:10,844 iteration 126 : loss : 0.264217, loss_ce: 0.101778
2022-01-20 15:43:12,212 iteration 127 : loss : 0.178828, loss_ce: 0.069140
2022-01-20 15:43:13,580 iteration 128 : loss : 0.157578, loss_ce: 0.069582
2022-01-20 15:43:14,846 iteration 129 : loss : 0.224178, loss_ce: 0.091605
2022-01-20 15:43:16,223 iteration 130 : loss : 0.239488, loss_ce: 0.116861
2022-01-20 15:43:17,531 iteration 131 : loss : 0.241936, loss_ce: 0.119784
2022-01-20 15:43:18,791 iteration 132 : loss : 0.226625, loss_ce: 0.087739
2022-01-20 15:43:20,173 iteration 133 : loss : 0.219405, loss_ce: 0.070371
2022-01-20 15:43:21,487 iteration 134 : loss : 0.265784, loss_ce: 0.103748
2022-01-20 15:43:22,811 iteration 135 : loss : 0.224694, loss_ce: 0.094880
2022-01-20 15:43:24,089 iteration 136 : loss : 0.216436, loss_ce: 0.098337

  2%|▌                              | 8/400 [03:12<2:35:49, 23.85s/it]2022-01-20 15:43:25,370 iteration 137 : loss : 0.158589, loss_ce: 0.053778
2022-01-20 15:43:26,625 iteration 138 : loss : 0.200671, loss_ce: 0.103207
2022-01-20 15:43:27,999 iteration 139 : loss : 0.193251, loss_ce: 0.071699
2022-01-20 15:43:29,420 iteration 140 : loss : 0.245634, loss_ce: 0.095530
2022-01-20 15:43:30,730 iteration 141 : loss : 0.202834, loss_ce: 0.079025
2022-01-20 15:43:31,973 iteration 142 : loss : 0.160074, loss_ce: 0.060380
2022-01-20 15:43:33,215 iteration 143 : loss : 0.219141, loss_ce: 0.089238
2022-01-20 15:43:34,563 iteration 144 : loss : 0.204730, loss_ce: 0.074150
2022-01-20 15:43:36,062 iteration 145 : loss : 0.161836, loss_ce: 0.069248
2022-01-20 15:43:37,325 iteration 146 : loss : 0.177640, loss_ce: 0.065429
2022-01-20 15:43:38,610 iteration 147 : loss : 0.206690, loss_ce: 0.085399
2022-01-20 15:43:39,928 iteration 148 : loss : 0.172902, loss_ce: 0.077653
2022-01-20 15:43:41,260 iteration 149 : loss : 0.191781, loss_ce: 0.073553
2022-01-20 15:43:42,558 iteration 150 : loss : 0.241312, loss_ce: 0.129851
2022-01-20 15:43:43,870 iteration 151 : loss : 0.161966, loss_ce: 0.071217
2022-01-20 15:43:45,243 iteration 152 : loss : 0.147296, loss_ce: 0.063247
2022-01-20 15:43:46,612 iteration 153 : loss : 0.159835, loss_ce: 0.068304

  2%|▋                              | 9/400 [03:35<2:32:43, 23.44s/it]2022-01-20 15:43:47,968 iteration 154 : loss : 0.163945, loss_ce: 0.061273
2022-01-20 15:43:49,290 iteration 155 : loss : 0.191274, loss_ce: 0.071446
2022-01-20 15:43:50,601 iteration 156 : loss : 0.147385, loss_ce: 0.056366
2022-01-20 15:43:51,931 iteration 157 : loss : 0.234593, loss_ce: 0.085156
2022-01-20 15:43:53,252 iteration 158 : loss : 0.165419, loss_ce: 0.075574
2022-01-20 15:43:54,574 iteration 159 : loss : 0.217004, loss_ce: 0.084166
2022-01-20 15:43:56,701 iteration 160 : loss : 0.261736, loss_ce: 0.096554
2022-01-20 15:43:57,993 iteration 161 : loss : 0.144670, loss_ce: 0.061454
2022-01-20 15:43:59,360 iteration 162 : loss : 0.156776, loss_ce: 0.064938
2022-01-20 15:44:00,553 iteration 163 : loss : 0.128712, loss_ce: 0.053600
2022-01-20 15:44:01,929 iteration 164 : loss : 0.154575, loss_ce: 0.056777
2022-01-20 15:44:03,216 iteration 165 : loss : 0.148653, loss_ce: 0.053314
2022-01-20 15:44:04,606 iteration 166 : loss : 0.192927, loss_ce: 0.071174
2022-01-20 15:44:05,977 iteration 167 : loss : 0.156616, loss_ce: 0.071326
2022-01-20 15:44:07,339 iteration 168 : loss : 0.153879, loss_ce: 0.064321
2022-01-20 15:44:08,644 iteration 169 : loss : 0.161118, loss_ce: 0.067882
2022-01-20 15:44:08,645 Training Data Eval:
2022-01-20 15:44:15,189   Average segmentation loss on training set: 0.2638
2022-01-20 15:44:15,190 Validation Data Eval:
2022-01-20 15:44:17,600   Average segmentation loss on validation set: 0.2313
2022-01-20 15:44:23,669 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 15:44:24,890 iteration 170 : loss : 0.163119, loss_ce: 0.064371

  2%|▊                             | 10/400 [04:13<3:02:07, 28.02s/it]2022-01-20 15:44:26,223 iteration 171 : loss : 0.187453, loss_ce: 0.084210
2022-01-20 15:44:27,348 iteration 172 : loss : 0.263592, loss_ce: 0.097972
2022-01-20 15:44:28,517 iteration 173 : loss : 0.133457, loss_ce: 0.054671
2022-01-20 15:44:29,849 iteration 174 : loss : 0.212787, loss_ce: 0.075723
2022-01-20 15:44:31,070 iteration 175 : loss : 0.184937, loss_ce: 0.069616
2022-01-20 15:44:32,435 iteration 176 : loss : 0.197153, loss_ce: 0.067009
2022-01-20 15:44:33,673 iteration 177 : loss : 0.235164, loss_ce: 0.086016
2022-01-20 15:44:34,987 iteration 178 : loss : 0.182447, loss_ce: 0.053771
2022-01-20 15:44:36,279 iteration 179 : loss : 0.162460, loss_ce: 0.067814
2022-01-20 15:44:37,571 iteration 180 : loss : 0.207807, loss_ce: 0.071284
2022-01-20 15:44:38,910 iteration 181 : loss : 0.158943, loss_ce: 0.057703
2022-01-20 15:44:40,244 iteration 182 : loss : 0.157936, loss_ce: 0.062762
2022-01-20 15:44:41,609 iteration 183 : loss : 0.137605, loss_ce: 0.050922
2022-01-20 15:44:42,922 iteration 184 : loss : 0.169342, loss_ce: 0.072463
2022-01-20 15:44:44,204 iteration 185 : loss : 0.182186, loss_ce: 0.078534
2022-01-20 15:44:45,478 iteration 186 : loss : 0.161038, loss_ce: 0.067844
2022-01-20 15:44:46,728 iteration 187 : loss : 0.193272, loss_ce: 0.090089
  3%|▊                             | 11/400 [04:35<2:49:22, 26.12s/it]2022-01-20 15:44:48,117 iteration 188 : loss : 0.188476, loss_ce: 0.083320
2022-01-20 15:44:49,463 iteration 189 : loss : 0.190140, loss_ce: 0.080985
2022-01-20 15:44:50,838 iteration 190 : loss : 0.177757, loss_ce: 0.060147
2022-01-20 15:44:52,145 iteration 191 : loss : 0.185535, loss_ce: 0.081428
2022-01-20 15:44:53,350 iteration 192 : loss : 0.155783, loss_ce: 0.066762
2022-01-20 15:44:54,607 iteration 193 : loss : 0.235659, loss_ce: 0.088964
2022-01-20 15:44:55,857 iteration 194 : loss : 0.221710, loss_ce: 0.096768
2022-01-20 15:44:57,259 iteration 195 : loss : 0.142921, loss_ce: 0.061053
2022-01-20 15:44:58,599 iteration 196 : loss : 0.178446, loss_ce: 0.064838
2022-01-20 15:44:59,909 iteration 197 : loss : 0.157993, loss_ce: 0.060194
2022-01-20 15:45:01,252 iteration 198 : loss : 0.175640, loss_ce: 0.076459
2022-01-20 15:45:02,589 iteration 199 : loss : 0.138141, loss_ce: 0.061174
2022-01-20 15:45:03,874 iteration 200 : loss : 0.199905, loss_ce: 0.064021
2022-01-20 15:45:05,176 iteration 201 : loss : 0.180788, loss_ce: 0.074729
2022-01-20 15:45:06,367 iteration 202 : loss : 0.154516, loss_ce: 0.048677
2022-01-20 15:45:07,752 iteration 203 : loss : 0.140488, loss_ce: 0.055214
2022-01-20 15:45:09,077 iteration 204 : loss : 0.166408, loss_ce: 0.077080
  3%|▉                             | 12/400 [04:57<2:41:32, 24.98s/it]2022-01-20 15:45:10,547 iteration 205 : loss : 0.150592, loss_ce: 0.056261
2022-01-20 15:45:11,885 iteration 206 : loss : 0.227866, loss_ce: 0.088381
2022-01-20 15:45:13,301 iteration 207 : loss : 0.144664, loss_ce: 0.056456
2022-01-20 15:45:14,693 iteration 208 : loss : 0.167815, loss_ce: 0.078100
2022-01-20 15:45:16,065 iteration 209 : loss : 0.217885, loss_ce: 0.093612
2022-01-20 15:45:17,400 iteration 210 : loss : 0.172226, loss_ce: 0.078778
2022-01-20 15:45:18,757 iteration 211 : loss : 0.166685, loss_ce: 0.067251
2022-01-20 15:45:20,146 iteration 212 : loss : 0.164362, loss_ce: 0.068778
2022-01-20 15:45:21,523 iteration 213 : loss : 0.177488, loss_ce: 0.076456
2022-01-20 15:45:22,824 iteration 214 : loss : 0.202330, loss_ce: 0.079900
2022-01-20 15:45:24,104 iteration 215 : loss : 0.143460, loss_ce: 0.058426
2022-01-20 15:45:25,494 iteration 216 : loss : 0.149143, loss_ce: 0.060010
2022-01-20 15:45:26,891 iteration 217 : loss : 0.179757, loss_ce: 0.069932
2022-01-20 15:45:28,180 iteration 218 : loss : 0.160728, loss_ce: 0.065923
2022-01-20 15:45:29,477 iteration 219 : loss : 0.146563, loss_ce: 0.062905
2022-01-20 15:45:30,825 iteration 220 : loss : 0.112755, loss_ce: 0.041127
2022-01-20 15:45:32,191 iteration 221 : loss : 0.167818, loss_ce: 0.063653
  3%|▉                             | 13/400 [05:20<2:37:26, 24.41s/it]2022-01-20 15:45:33,574 iteration 222 : loss : 0.128232, loss_ce: 0.050101
2022-01-20 15:45:34,869 iteration 223 : loss : 0.240490, loss_ce: 0.117763
2022-01-20 15:45:36,166 iteration 224 : loss : 0.153741, loss_ce: 0.050876
2022-01-20 15:45:37,617 iteration 225 : loss : 0.144805, loss_ce: 0.069192
2022-01-20 15:45:38,965 iteration 226 : loss : 0.146877, loss_ce: 0.060895
2022-01-20 15:45:40,260 iteration 227 : loss : 0.159369, loss_ce: 0.063550
2022-01-20 15:45:41,557 iteration 228 : loss : 0.125278, loss_ce: 0.041898
2022-01-20 15:45:42,902 iteration 229 : loss : 0.203326, loss_ce: 0.070130
2022-01-20 15:45:44,165 iteration 230 : loss : 0.117339, loss_ce: 0.046772
2022-01-20 15:45:45,489 iteration 231 : loss : 0.141696, loss_ce: 0.051050
2022-01-20 15:45:46,800 iteration 232 : loss : 0.159617, loss_ce: 0.067971
2022-01-20 15:45:48,028 iteration 233 : loss : 0.145596, loss_ce: 0.068206
2022-01-20 15:45:49,323 iteration 234 : loss : 0.168276, loss_ce: 0.066202
2022-01-20 15:45:50,593 iteration 235 : loss : 0.161213, loss_ce: 0.064019
2022-01-20 15:45:51,907 iteration 236 : loss : 0.249705, loss_ce: 0.088178
2022-01-20 15:45:53,165 iteration 237 : loss : 0.214568, loss_ce: 0.109255
2022-01-20 15:45:54,516 iteration 238 : loss : 0.145836, loss_ce: 0.052306
  4%|█                             | 14/400 [05:43<2:33:01, 23.79s/it]2022-01-20 15:45:55,882 iteration 239 : loss : 0.144801, loss_ce: 0.049729
2022-01-20 15:45:57,282 iteration 240 : loss : 0.141987, loss_ce: 0.049531
2022-01-20 15:45:58,640 iteration 241 : loss : 0.177030, loss_ce: 0.063347
2022-01-20 15:45:59,921 iteration 242 : loss : 0.134630, loss_ce: 0.051032
2022-01-20 15:46:01,213 iteration 243 : loss : 0.143184, loss_ce: 0.049910
2022-01-20 15:46:02,517 iteration 244 : loss : 0.160151, loss_ce: 0.062965
2022-01-20 15:46:03,773 iteration 245 : loss : 0.173011, loss_ce: 0.060695
2022-01-20 15:46:05,066 iteration 246 : loss : 0.190906, loss_ce: 0.059908
2022-01-20 15:46:06,412 iteration 247 : loss : 0.189508, loss_ce: 0.068873
2022-01-20 15:46:07,760 iteration 248 : loss : 0.136509, loss_ce: 0.057614
2022-01-20 15:46:09,044 iteration 249 : loss : 0.175837, loss_ce: 0.062410
2022-01-20 15:46:10,342 iteration 250 : loss : 0.211162, loss_ce: 0.072787
2022-01-20 15:46:11,585 iteration 251 : loss : 0.142021, loss_ce: 0.062355
2022-01-20 15:46:12,981 iteration 252 : loss : 0.142769, loss_ce: 0.062402
2022-01-20 15:46:14,286 iteration 253 : loss : 0.143063, loss_ce: 0.054040
2022-01-20 15:46:15,566 iteration 254 : loss : 0.148468, loss_ce: 0.064996
2022-01-20 15:46:15,566 Training Data Eval:
2022-01-20 15:46:22,108   Average segmentation loss on training set: 0.1231
2022-01-20 15:46:22,108 Validation Data Eval:
2022-01-20 15:46:24,332   Average segmentation loss on validation set: 0.1299
2022-01-20 15:46:30,216 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 15:46:31,424 iteration 255 : loss : 0.185892, loss_ce: 0.088866
  4%|█▏                            | 15/400 [06:19<2:57:58, 27.74s/it]2022-01-20 15:46:32,663 iteration 256 : loss : 0.141202, loss_ce: 0.059309
2022-01-20 15:46:33,852 iteration 257 : loss : 0.141100, loss_ce: 0.054920
2022-01-20 15:46:35,151 iteration 258 : loss : 0.131625, loss_ce: 0.058368
2022-01-20 15:46:36,413 iteration 259 : loss : 0.158286, loss_ce: 0.065850
2022-01-20 15:46:37,608 iteration 260 : loss : 0.124217, loss_ce: 0.066321
2022-01-20 15:46:38,894 iteration 261 : loss : 0.164467, loss_ce: 0.060437
2022-01-20 15:46:40,212 iteration 262 : loss : 0.235466, loss_ce: 0.101118
2022-01-20 15:46:41,407 iteration 263 : loss : 0.139755, loss_ce: 0.056484
2022-01-20 15:46:42,734 iteration 264 : loss : 0.186392, loss_ce: 0.059378
2022-01-20 15:46:44,149 iteration 265 : loss : 0.156309, loss_ce: 0.070054
2022-01-20 15:46:45,498 iteration 266 : loss : 0.156361, loss_ce: 0.063314
2022-01-20 15:46:46,919 iteration 267 : loss : 0.117712, loss_ce: 0.035928
2022-01-20 15:46:48,265 iteration 268 : loss : 0.135967, loss_ce: 0.050234
2022-01-20 15:46:49,602 iteration 269 : loss : 0.186782, loss_ce: 0.074325
2022-01-20 15:46:50,903 iteration 270 : loss : 0.163297, loss_ce: 0.062855
2022-01-20 15:46:52,183 iteration 271 : loss : 0.140883, loss_ce: 0.062633
2022-01-20 15:46:53,446 iteration 272 : loss : 0.143488, loss_ce: 0.058072
  4%|█▏                            | 16/400 [06:42<2:46:32, 26.02s/it]2022-01-20 15:46:54,889 iteration 273 : loss : 0.143766, loss_ce: 0.057017
2022-01-20 15:46:56,196 iteration 274 : loss : 0.187124, loss_ce: 0.087879
2022-01-20 15:46:57,482 iteration 275 : loss : 0.181965, loss_ce: 0.052534
2022-01-20 15:46:58,782 iteration 276 : loss : 0.112870, loss_ce: 0.043730
2022-01-20 15:47:00,091 iteration 277 : loss : 0.100169, loss_ce: 0.038273
2022-01-20 15:47:01,431 iteration 278 : loss : 0.200627, loss_ce: 0.082693
2022-01-20 15:47:02,752 iteration 279 : loss : 0.159927, loss_ce: 0.058446
2022-01-20 15:47:04,068 iteration 280 : loss : 0.139275, loss_ce: 0.062345
2022-01-20 15:47:05,445 iteration 281 : loss : 0.114061, loss_ce: 0.059368
2022-01-20 15:47:06,791 iteration 282 : loss : 0.129702, loss_ce: 0.045884
2022-01-20 15:47:08,092 iteration 283 : loss : 0.143018, loss_ce: 0.057159
2022-01-20 15:47:09,433 iteration 284 : loss : 0.138043, loss_ce: 0.083210
2022-01-20 15:47:10,797 iteration 285 : loss : 0.127759, loss_ce: 0.043763
2022-01-20 15:47:12,013 iteration 286 : loss : 0.116819, loss_ce: 0.045430
2022-01-20 15:47:13,331 iteration 287 : loss : 0.114821, loss_ce: 0.050302
2022-01-20 15:47:14,662 iteration 288 : loss : 0.130987, loss_ce: 0.049385
2022-01-20 15:47:15,948 iteration 289 : loss : 0.118040, loss_ce: 0.040880
  4%|█▎                            | 17/400 [07:04<2:39:19, 24.96s/it]2022-01-20 15:47:17,370 iteration 290 : loss : 0.156788, loss_ce: 0.061880
2022-01-20 15:47:18,627 iteration 291 : loss : 0.132840, loss_ce: 0.043186
2022-01-20 15:47:19,888 iteration 292 : loss : 0.115730, loss_ce: 0.051489
2022-01-20 15:47:21,255 iteration 293 : loss : 0.097589, loss_ce: 0.039352
2022-01-20 15:47:22,553 iteration 294 : loss : 0.093874, loss_ce: 0.047268
2022-01-20 15:47:23,911 iteration 295 : loss : 0.114275, loss_ce: 0.051998
2022-01-20 15:47:25,288 iteration 296 : loss : 0.133648, loss_ce: 0.053367
2022-01-20 15:47:26,622 iteration 297 : loss : 0.102003, loss_ce: 0.050786
2022-01-20 15:47:27,929 iteration 298 : loss : 0.147518, loss_ce: 0.065252
2022-01-20 15:47:29,163 iteration 299 : loss : 0.146036, loss_ce: 0.059198
2022-01-20 15:47:30,438 iteration 300 : loss : 0.129987, loss_ce: 0.055237
2022-01-20 15:47:31,667 iteration 301 : loss : 0.164532, loss_ce: 0.059070
2022-01-20 15:47:33,058 iteration 302 : loss : 0.156675, loss_ce: 0.057950
2022-01-20 15:47:34,418 iteration 303 : loss : 0.132551, loss_ce: 0.045798
2022-01-20 15:47:35,784 iteration 304 : loss : 0.140377, loss_ce: 0.064016
2022-01-20 15:47:37,074 iteration 305 : loss : 0.096684, loss_ce: 0.042571
2022-01-20 15:47:38,386 iteration 306 : loss : 0.147193, loss_ce: 0.056894
  4%|█▎                            | 18/400 [07:26<2:34:05, 24.20s/it]2022-01-20 15:47:39,697 iteration 307 : loss : 0.169432, loss_ce: 0.062879
2022-01-20 15:47:40,943 iteration 308 : loss : 0.115977, loss_ce: 0.046592
2022-01-20 15:47:42,203 iteration 309 : loss : 0.144450, loss_ce: 0.067909
2022-01-20 15:47:43,530 iteration 310 : loss : 0.160580, loss_ce: 0.064910
2022-01-20 15:47:44,889 iteration 311 : loss : 0.122903, loss_ce: 0.046626
2022-01-20 15:47:46,254 iteration 312 : loss : 0.095240, loss_ce: 0.041470
2022-01-20 15:47:47,524 iteration 313 : loss : 0.115238, loss_ce: 0.048520
2022-01-20 15:47:48,855 iteration 314 : loss : 0.123996, loss_ce: 0.056247
2022-01-20 15:47:50,230 iteration 315 : loss : 0.139627, loss_ce: 0.059253
2022-01-20 15:47:51,536 iteration 316 : loss : 0.141235, loss_ce: 0.054029
2022-01-20 15:47:52,784 iteration 317 : loss : 0.132182, loss_ce: 0.048061
2022-01-20 15:47:54,070 iteration 318 : loss : 0.118595, loss_ce: 0.047004
2022-01-20 15:47:55,453 iteration 319 : loss : 0.111929, loss_ce: 0.043932
2022-01-20 15:47:56,737 iteration 320 : loss : 0.128945, loss_ce: 0.044209
2022-01-20 15:47:57,987 iteration 321 : loss : 0.107651, loss_ce: 0.053206
2022-01-20 15:47:59,307 iteration 322 : loss : 0.096073, loss_ce: 0.041173
2022-01-20 15:48:00,678 iteration 323 : loss : 0.122500, loss_ce: 0.049054
  5%|█▍                            | 19/400 [07:49<2:30:03, 23.63s/it]2022-01-20 15:48:01,975 iteration 324 : loss : 0.149095, loss_ce: 0.059016
2022-01-20 15:48:03,283 iteration 325 : loss : 0.145637, loss_ce: 0.049425
2022-01-20 15:48:04,578 iteration 326 : loss : 0.110565, loss_ce: 0.043325
2022-01-20 15:48:05,979 iteration 327 : loss : 0.135766, loss_ce: 0.052390
2022-01-20 15:48:07,327 iteration 328 : loss : 0.118566, loss_ce: 0.048777
2022-01-20 15:48:08,649 iteration 329 : loss : 0.108687, loss_ce: 0.040855
2022-01-20 15:48:09,867 iteration 330 : loss : 0.095725, loss_ce: 0.036127
2022-01-20 15:48:11,245 iteration 331 : loss : 0.099522, loss_ce: 0.034114
2022-01-20 15:48:12,607 iteration 332 : loss : 0.115144, loss_ce: 0.052108
2022-01-20 15:48:13,846 iteration 333 : loss : 0.099730, loss_ce: 0.035957
2022-01-20 15:48:15,196 iteration 334 : loss : 0.137543, loss_ce: 0.068012
2022-01-20 15:48:16,477 iteration 335 : loss : 0.133380, loss_ce: 0.040481
2022-01-20 15:48:17,833 iteration 336 : loss : 0.091053, loss_ce: 0.034784
2022-01-20 15:48:19,116 iteration 337 : loss : 0.099534, loss_ce: 0.040400
2022-01-20 15:48:20,360 iteration 338 : loss : 0.132759, loss_ce: 0.064930
2022-01-20 15:48:21,682 iteration 339 : loss : 0.100173, loss_ce: 0.041752
2022-01-20 15:48:21,682 Training Data Eval:
2022-01-20 15:48:28,274   Average segmentation loss on training set: 0.0869
2022-01-20 15:48:28,274 Validation Data Eval:
2022-01-20 15:48:30,527   Average segmentation loss on validation set: 0.1025
2022-01-20 15:48:36,864 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 15:48:38,126 iteration 340 : loss : 0.134070, loss_ce: 0.053538
  5%|█▌                            | 20/400 [08:26<2:55:55, 27.78s/it]2022-01-20 15:48:39,499 iteration 341 : loss : 0.113144, loss_ce: 0.048541
2022-01-20 15:48:40,826 iteration 342 : loss : 0.094849, loss_ce: 0.041207
2022-01-20 15:48:42,232 iteration 343 : loss : 0.120954, loss_ce: 0.058976
2022-01-20 15:48:43,485 iteration 344 : loss : 0.132226, loss_ce: 0.043560
2022-01-20 15:48:44,766 iteration 345 : loss : 0.126973, loss_ce: 0.047196
2022-01-20 15:48:46,109 iteration 346 : loss : 0.119987, loss_ce: 0.045024
2022-01-20 15:48:47,330 iteration 347 : loss : 0.080789, loss_ce: 0.035011
2022-01-20 15:48:48,714 iteration 348 : loss : 0.131233, loss_ce: 0.052211
2022-01-20 15:48:49,969 iteration 349 : loss : 0.119719, loss_ce: 0.052561
2022-01-20 15:48:51,133 iteration 350 : loss : 0.115277, loss_ce: 0.044209
2022-01-20 15:48:52,510 iteration 351 : loss : 0.125085, loss_ce: 0.041058
2022-01-20 15:48:53,826 iteration 352 : loss : 0.124345, loss_ce: 0.046035
2022-01-20 15:48:55,254 iteration 353 : loss : 0.085459, loss_ce: 0.033427
2022-01-20 15:48:56,596 iteration 354 : loss : 0.109263, loss_ce: 0.046214
2022-01-20 15:48:57,979 iteration 355 : loss : 0.139784, loss_ce: 0.052401
2022-01-20 15:48:59,232 iteration 356 : loss : 0.133590, loss_ce: 0.053061
2022-01-20 15:49:00,513 iteration 357 : loss : 0.138092, loss_ce: 0.063293
  5%|█▌                            | 21/400 [08:49<2:45:15, 26.16s/it]2022-01-20 15:49:01,957 iteration 358 : loss : 0.096302, loss_ce: 0.037665
2022-01-20 15:49:03,329 iteration 359 : loss : 0.084771, loss_ce: 0.041424
2022-01-20 15:49:04,636 iteration 360 : loss : 0.179262, loss_ce: 0.054904
2022-01-20 15:49:05,984 iteration 361 : loss : 0.166296, loss_ce: 0.052646
2022-01-20 15:49:07,207 iteration 362 : loss : 0.115134, loss_ce: 0.040211
2022-01-20 15:49:08,616 iteration 363 : loss : 0.135996, loss_ce: 0.068940
2022-01-20 15:49:09,942 iteration 364 : loss : 0.134127, loss_ce: 0.060332
2022-01-20 15:49:11,242 iteration 365 : loss : 0.106388, loss_ce: 0.041428
2022-01-20 15:49:12,556 iteration 366 : loss : 0.120748, loss_ce: 0.048242
2022-01-20 15:49:13,921 iteration 367 : loss : 0.126897, loss_ce: 0.057980
2022-01-20 15:49:15,173 iteration 368 : loss : 0.122557, loss_ce: 0.040653
2022-01-20 15:49:16,525 iteration 369 : loss : 0.100779, loss_ce: 0.047446
2022-01-20 15:49:17,747 iteration 370 : loss : 0.130293, loss_ce: 0.041374
2022-01-20 15:49:19,132 iteration 371 : loss : 0.103556, loss_ce: 0.051609
2022-01-20 15:49:20,506 iteration 372 : loss : 0.122396, loss_ce: 0.040890
2022-01-20 15:49:21,838 iteration 373 : loss : 0.095484, loss_ce: 0.034788
2022-01-20 15:49:23,126 iteration 374 : loss : 0.095681, loss_ce: 0.042223
  6%|█▋                            | 22/400 [09:11<2:38:05, 25.09s/it]2022-01-20 15:49:24,542 iteration 375 : loss : 0.110486, loss_ce: 0.046746
2022-01-20 15:49:25,883 iteration 376 : loss : 0.109545, loss_ce: 0.042338
2022-01-20 15:49:27,223 iteration 377 : loss : 0.134909, loss_ce: 0.040343
2022-01-20 15:49:28,549 iteration 378 : loss : 0.137962, loss_ce: 0.058161
2022-01-20 15:49:29,787 iteration 379 : loss : 0.114262, loss_ce: 0.040029
2022-01-20 15:49:31,138 iteration 380 : loss : 0.089808, loss_ce: 0.039994
2022-01-20 15:49:32,347 iteration 381 : loss : 0.079337, loss_ce: 0.028351
2022-01-20 15:49:33,791 iteration 382 : loss : 0.113718, loss_ce: 0.047048
2022-01-20 15:49:35,151 iteration 383 : loss : 0.116858, loss_ce: 0.045780
2022-01-20 15:49:36,453 iteration 384 : loss : 0.093926, loss_ce: 0.039320
2022-01-20 15:49:37,713 iteration 385 : loss : 0.093152, loss_ce: 0.039666
2022-01-20 15:49:39,070 iteration 386 : loss : 0.133611, loss_ce: 0.048760
2022-01-20 15:49:40,424 iteration 387 : loss : 0.111211, loss_ce: 0.043692
2022-01-20 15:49:41,810 iteration 388 : loss : 0.122938, loss_ce: 0.051474
2022-01-20 15:49:43,092 iteration 389 : loss : 0.150198, loss_ce: 0.049708
2022-01-20 15:49:44,439 iteration 390 : loss : 0.107363, loss_ce: 0.053381
2022-01-20 15:49:45,719 iteration 391 : loss : 0.103587, loss_ce: 0.034530
  6%|█▋                            | 23/400 [09:34<2:32:57, 24.34s/it]2022-01-20 15:49:47,233 iteration 392 : loss : 0.078963, loss_ce: 0.034892
2022-01-20 15:49:48,518 iteration 393 : loss : 0.128359, loss_ce: 0.060169
2022-01-20 15:49:49,855 iteration 394 : loss : 0.131306, loss_ce: 0.048422
2022-01-20 15:49:51,143 iteration 395 : loss : 0.120875, loss_ce: 0.053549
2022-01-20 15:49:52,519 iteration 396 : loss : 0.100147, loss_ce: 0.040744
2022-01-20 15:49:53,883 iteration 397 : loss : 0.102607, loss_ce: 0.045953
2022-01-20 15:49:55,237 iteration 398 : loss : 0.125396, loss_ce: 0.053710
2022-01-20 15:49:56,553 iteration 399 : loss : 0.098902, loss_ce: 0.036147
2022-01-20 15:49:57,949 iteration 400 : loss : 0.099718, loss_ce: 0.046232
2022-01-20 15:49:59,200 iteration 401 : loss : 0.130069, loss_ce: 0.040029
2022-01-20 15:50:00,596 iteration 402 : loss : 0.133336, loss_ce: 0.058285
2022-01-20 15:50:02,021 iteration 403 : loss : 0.106075, loss_ce: 0.041031
2022-01-20 15:50:03,340 iteration 404 : loss : 0.082988, loss_ce: 0.024740
2022-01-20 15:50:04,705 iteration 405 : loss : 0.119012, loss_ce: 0.039107
2022-01-20 15:50:05,987 iteration 406 : loss : 0.095817, loss_ce: 0.041046
2022-01-20 15:50:07,272 iteration 407 : loss : 0.087473, loss_ce: 0.037230
2022-01-20 15:50:08,547 iteration 408 : loss : 0.105151, loss_ce: 0.035733
  6%|█▊                            | 24/400 [09:57<2:29:41, 23.89s/it]2022-01-20 15:50:10,072 iteration 409 : loss : 0.087485, loss_ce: 0.035609
2022-01-20 15:50:11,370 iteration 410 : loss : 0.100232, loss_ce: 0.038524
2022-01-20 15:50:12,702 iteration 411 : loss : 0.087109, loss_ce: 0.029667
2022-01-20 15:50:14,002 iteration 412 : loss : 0.101507, loss_ce: 0.039235
2022-01-20 15:50:15,294 iteration 413 : loss : 0.091898, loss_ce: 0.035888
2022-01-20 15:50:16,627 iteration 414 : loss : 0.093594, loss_ce: 0.041493
2022-01-20 15:50:18,014 iteration 415 : loss : 0.138864, loss_ce: 0.080585
2022-01-20 15:50:19,195 iteration 416 : loss : 0.106965, loss_ce: 0.035318
2022-01-20 15:50:20,512 iteration 417 : loss : 0.141275, loss_ce: 0.053726
2022-01-20 15:50:21,853 iteration 418 : loss : 0.080602, loss_ce: 0.030042
2022-01-20 15:50:23,157 iteration 419 : loss : 0.144949, loss_ce: 0.055760
2022-01-20 15:50:24,497 iteration 420 : loss : 0.075440, loss_ce: 0.028801
2022-01-20 15:50:25,732 iteration 421 : loss : 0.113258, loss_ce: 0.031850
2022-01-20 15:50:27,111 iteration 422 : loss : 0.100221, loss_ce: 0.034154
2022-01-20 15:50:28,413 iteration 423 : loss : 0.103541, loss_ce: 0.039844
2022-01-20 15:50:29,712 iteration 424 : loss : 0.108665, loss_ce: 0.054066
2022-01-20 15:50:29,712 Training Data Eval:
2022-01-20 15:50:36,230   Average segmentation loss on training set: 0.1408
2022-01-20 15:50:36,231 Validation Data Eval:
2022-01-20 15:50:38,426   Average segmentation loss on validation set: 0.2295
2022-01-20 15:50:39,817 iteration 425 : loss : 0.108740, loss_ce: 0.042039
  6%|█▉                            | 25/400 [10:28<2:43:08, 26.10s/it]2022-01-20 15:50:41,243 iteration 426 : loss : 0.090953, loss_ce: 0.035235
2022-01-20 15:50:42,501 iteration 427 : loss : 0.100530, loss_ce: 0.038914
2022-01-20 15:50:43,921 iteration 428 : loss : 0.134999, loss_ce: 0.058398
2022-01-20 15:50:45,196 iteration 429 : loss : 0.101558, loss_ce: 0.034034
2022-01-20 15:50:46,420 iteration 430 : loss : 0.104231, loss_ce: 0.046170
2022-01-20 15:50:47,784 iteration 431 : loss : 0.088630, loss_ce: 0.041036
2022-01-20 15:50:49,121 iteration 432 : loss : 0.089259, loss_ce: 0.031811
2022-01-20 15:50:50,368 iteration 433 : loss : 0.097654, loss_ce: 0.038381
2022-01-20 15:50:51,631 iteration 434 : loss : 0.100462, loss_ce: 0.033080
2022-01-20 15:50:52,968 iteration 435 : loss : 0.090983, loss_ce: 0.032850
2022-01-20 15:50:54,315 iteration 436 : loss : 0.124220, loss_ce: 0.036274
2022-01-20 15:50:55,581 iteration 437 : loss : 0.128886, loss_ce: 0.051096
2022-01-20 15:50:56,845 iteration 438 : loss : 0.114896, loss_ce: 0.042680
2022-01-20 15:50:58,121 iteration 439 : loss : 0.105433, loss_ce: 0.040796
2022-01-20 15:50:59,585 iteration 440 : loss : 0.121312, loss_ce: 0.048900
2022-01-20 15:51:00,879 iteration 441 : loss : 0.091396, loss_ce: 0.045012
2022-01-20 15:51:02,150 iteration 442 : loss : 0.064698, loss_ce: 0.025042
  6%|█▉                            | 26/400 [10:50<2:35:40, 24.97s/it]2022-01-20 15:51:03,555 iteration 443 : loss : 0.086457, loss_ce: 0.037222
2022-01-20 15:51:04,813 iteration 444 : loss : 0.096401, loss_ce: 0.035328
2022-01-20 15:51:06,054 iteration 445 : loss : 0.101162, loss_ce: 0.039521
2022-01-20 15:51:07,341 iteration 446 : loss : 0.098753, loss_ce: 0.033405
2022-01-20 15:51:08,718 iteration 447 : loss : 0.088631, loss_ce: 0.033990
2022-01-20 15:51:09,940 iteration 448 : loss : 0.119608, loss_ce: 0.046083
2022-01-20 15:51:11,215 iteration 449 : loss : 0.089614, loss_ce: 0.025095
2022-01-20 15:51:12,453 iteration 450 : loss : 0.109988, loss_ce: 0.057025
2022-01-20 15:51:13,763 iteration 451 : loss : 0.133711, loss_ce: 0.050920
2022-01-20 15:51:15,087 iteration 452 : loss : 0.100313, loss_ce: 0.033018
2022-01-20 15:51:16,373 iteration 453 : loss : 0.055677, loss_ce: 0.024667
2022-01-20 15:51:17,793 iteration 454 : loss : 0.097129, loss_ce: 0.048160
2022-01-20 15:51:19,141 iteration 455 : loss : 0.087786, loss_ce: 0.036893
2022-01-20 15:51:20,438 iteration 456 : loss : 0.083963, loss_ce: 0.030506
2022-01-20 15:51:21,726 iteration 457 : loss : 0.088175, loss_ce: 0.044567
2022-01-20 15:51:23,014 iteration 458 : loss : 0.091531, loss_ce: 0.045623
2022-01-20 15:51:24,328 iteration 459 : loss : 0.134447, loss_ce: 0.053596
  7%|██                            | 27/400 [11:12<2:30:01, 24.13s/it]2022-01-20 15:51:25,623 iteration 460 : loss : 0.098815, loss_ce: 0.044565
2022-01-20 15:51:26,899 iteration 461 : loss : 0.088643, loss_ce: 0.040019
2022-01-20 15:51:28,284 iteration 462 : loss : 0.114057, loss_ce: 0.041685
2022-01-20 15:51:29,614 iteration 463 : loss : 0.110069, loss_ce: 0.036558
2022-01-20 15:51:31,082 iteration 464 : loss : 0.140344, loss_ce: 0.055734
2022-01-20 15:51:32,448 iteration 465 : loss : 0.108315, loss_ce: 0.045236
2022-01-20 15:51:33,738 iteration 466 : loss : 0.098122, loss_ce: 0.037467
2022-01-20 15:51:35,054 iteration 467 : loss : 0.114338, loss_ce: 0.042566
2022-01-20 15:51:36,352 iteration 468 : loss : 0.075167, loss_ce: 0.027980
2022-01-20 15:51:37,714 iteration 469 : loss : 0.109339, loss_ce: 0.047305
2022-01-20 15:51:39,036 iteration 470 : loss : 0.099136, loss_ce: 0.040028
2022-01-20 15:51:40,366 iteration 471 : loss : 0.278212, loss_ce: 0.167767
2022-01-20 15:51:41,709 iteration 472 : loss : 0.063891, loss_ce: 0.025086
2022-01-20 15:51:43,044 iteration 473 : loss : 0.139328, loss_ce: 0.068482
2022-01-20 15:51:44,316 iteration 474 : loss : 0.203069, loss_ce: 0.082688
2022-01-20 15:51:45,632 iteration 475 : loss : 0.140189, loss_ce: 0.055606
2022-01-20 15:51:47,039 iteration 476 : loss : 0.082467, loss_ce: 0.037326
  7%|██                            | 28/400 [11:35<2:26:58, 23.71s/it]2022-01-20 15:51:48,403 iteration 477 : loss : 0.062945, loss_ce: 0.027728
2022-01-20 15:51:49,643 iteration 478 : loss : 0.082519, loss_ce: 0.036449
2022-01-20 15:51:51,003 iteration 479 : loss : 0.127596, loss_ce: 0.047842
2022-01-20 15:51:52,326 iteration 480 : loss : 0.115498, loss_ce: 0.033738
2022-01-20 15:51:53,595 iteration 481 : loss : 0.122355, loss_ce: 0.038454
2022-01-20 15:51:55,006 iteration 482 : loss : 0.112183, loss_ce: 0.042430
2022-01-20 15:51:56,256 iteration 483 : loss : 0.137648, loss_ce: 0.063146
2022-01-20 15:51:57,606 iteration 484 : loss : 0.140100, loss_ce: 0.046359
2022-01-20 15:51:58,959 iteration 485 : loss : 0.171411, loss_ce: 0.056528
2022-01-20 15:52:00,411 iteration 486 : loss : 0.115674, loss_ce: 0.050606
2022-01-20 15:52:01,737 iteration 487 : loss : 0.158341, loss_ce: 0.046776
2022-01-20 15:52:02,973 iteration 488 : loss : 0.123769, loss_ce: 0.051259
2022-01-20 15:52:04,332 iteration 489 : loss : 0.118725, loss_ce: 0.060947
2022-01-20 15:52:05,650 iteration 490 : loss : 0.108001, loss_ce: 0.052121
2022-01-20 15:52:07,031 iteration 491 : loss : 0.191031, loss_ce: 0.069885
2022-01-20 15:52:08,312 iteration 492 : loss : 0.101645, loss_ce: 0.058023
2022-01-20 15:52:09,580 iteration 493 : loss : 0.093385, loss_ce: 0.041899
  7%|██▏                           | 29/400 [11:58<2:24:26, 23.36s/it]2022-01-20 15:52:10,965 iteration 494 : loss : 0.152316, loss_ce: 0.058935
2022-01-20 15:52:12,203 iteration 495 : loss : 0.131396, loss_ce: 0.042697
2022-01-20 15:52:13,521 iteration 496 : loss : 0.145590, loss_ce: 0.059811
2022-01-20 15:52:14,918 iteration 497 : loss : 0.119158, loss_ce: 0.056789
2022-01-20 15:52:16,356 iteration 498 : loss : 0.139826, loss_ce: 0.075629
2022-01-20 15:52:17,705 iteration 499 : loss : 0.096669, loss_ce: 0.035997
2022-01-20 15:52:19,172 iteration 500 : loss : 0.111469, loss_ce: 0.042824
2022-01-20 15:52:20,491 iteration 501 : loss : 0.108662, loss_ce: 0.037672
2022-01-20 15:52:21,762 iteration 502 : loss : 0.093305, loss_ce: 0.042175
2022-01-20 15:52:23,204 iteration 503 : loss : 0.117397, loss_ce: 0.038644
2022-01-20 15:52:24,656 iteration 504 : loss : 0.117329, loss_ce: 0.045861
2022-01-20 15:52:25,938 iteration 505 : loss : 0.098184, loss_ce: 0.041138
2022-01-20 15:52:27,291 iteration 506 : loss : 0.109565, loss_ce: 0.044342
2022-01-20 15:52:28,675 iteration 507 : loss : 0.093614, loss_ce: 0.037489
2022-01-20 15:52:29,990 iteration 508 : loss : 0.078784, loss_ce: 0.032669
2022-01-20 15:52:31,332 iteration 509 : loss : 0.077010, loss_ce: 0.035461
2022-01-20 15:52:31,332 Training Data Eval:
2022-01-20 15:52:37,863   Average segmentation loss on training set: 0.0904
2022-01-20 15:52:37,864 Validation Data Eval:
2022-01-20 15:52:40,102   Average segmentation loss on validation set: 0.1648
2022-01-20 15:52:41,343 iteration 510 : loss : 0.103454, loss_ce: 0.039285
  8%|██▎                           | 30/400 [12:29<2:39:34, 25.88s/it]2022-01-20 15:52:42,605 iteration 511 : loss : 0.072999, loss_ce: 0.030748
2022-01-20 15:52:44,105 iteration 512 : loss : 0.125766, loss_ce: 0.047218
2022-01-20 15:52:45,362 iteration 513 : loss : 0.109894, loss_ce: 0.055116
2022-01-20 15:52:46,718 iteration 514 : loss : 0.116512, loss_ce: 0.043492
2022-01-20 15:52:48,006 iteration 515 : loss : 0.074866, loss_ce: 0.029769
2022-01-20 15:52:49,231 iteration 516 : loss : 0.069398, loss_ce: 0.033745
2022-01-20 15:52:50,724 iteration 517 : loss : 0.098402, loss_ce: 0.038577
2022-01-20 15:52:52,080 iteration 518 : loss : 0.115010, loss_ce: 0.056803
2022-01-20 15:52:53,361 iteration 519 : loss : 0.069812, loss_ce: 0.028364
2022-01-20 15:52:54,630 iteration 520 : loss : 0.125058, loss_ce: 0.053508
2022-01-20 15:52:56,064 iteration 521 : loss : 0.187609, loss_ce: 0.046092
2022-01-20 15:52:57,341 iteration 522 : loss : 0.076880, loss_ce: 0.029016
2022-01-20 15:52:58,710 iteration 523 : loss : 0.070562, loss_ce: 0.029300
2022-01-20 15:52:59,894 iteration 524 : loss : 0.092343, loss_ce: 0.046546
2022-01-20 15:53:01,200 iteration 525 : loss : 0.067891, loss_ce: 0.026938
2022-01-20 15:53:02,549 iteration 526 : loss : 0.087281, loss_ce: 0.029989
2022-01-20 15:53:03,858 iteration 527 : loss : 0.092766, loss_ce: 0.038036
  8%|██▎                           | 31/400 [12:52<2:32:58, 24.87s/it]2022-01-20 15:53:05,309 iteration 528 : loss : 0.060197, loss_ce: 0.024169
2022-01-20 15:53:06,615 iteration 529 : loss : 0.086883, loss_ce: 0.041741
2022-01-20 15:53:07,884 iteration 530 : loss : 0.060315, loss_ce: 0.023530
2022-01-20 15:53:09,236 iteration 531 : loss : 0.146738, loss_ce: 0.056567
2022-01-20 15:53:10,453 iteration 532 : loss : 0.120498, loss_ce: 0.036810
2022-01-20 15:53:11,790 iteration 533 : loss : 0.077288, loss_ce: 0.034357
2022-01-20 15:53:13,113 iteration 534 : loss : 0.134156, loss_ce: 0.068481
2022-01-20 15:53:14,439 iteration 535 : loss : 0.097881, loss_ce: 0.041296
2022-01-20 15:53:15,680 iteration 536 : loss : 0.094375, loss_ce: 0.043532
2022-01-20 15:53:17,002 iteration 537 : loss : 0.096959, loss_ce: 0.041478
2022-01-20 15:53:18,312 iteration 538 : loss : 0.073156, loss_ce: 0.027268
2022-01-20 15:53:19,600 iteration 539 : loss : 0.116547, loss_ce: 0.042790
2022-01-20 15:53:20,869 iteration 540 : loss : 0.078241, loss_ce: 0.034847
2022-01-20 15:53:22,178 iteration 541 : loss : 0.085927, loss_ce: 0.042104
2022-01-20 15:53:23,417 iteration 542 : loss : 0.096907, loss_ce: 0.034735
2022-01-20 15:53:24,682 iteration 543 : loss : 0.108256, loss_ce: 0.036684
2022-01-20 15:53:25,977 iteration 544 : loss : 0.082718, loss_ce: 0.029623
  8%|██▍                           | 32/400 [13:14<2:27:29, 24.05s/it]2022-01-20 15:53:27,340 iteration 545 : loss : 0.102928, loss_ce: 0.040998
2022-01-20 15:53:28,654 iteration 546 : loss : 0.077377, loss_ce: 0.027855
2022-01-20 15:53:29,992 iteration 547 : loss : 0.105285, loss_ce: 0.042337
2022-01-20 15:53:31,220 iteration 548 : loss : 0.106156, loss_ce: 0.040896
2022-01-20 15:53:32,540 iteration 549 : loss : 0.081688, loss_ce: 0.033564
2022-01-20 15:53:33,966 iteration 550 : loss : 0.097970, loss_ce: 0.032933
2022-01-20 15:53:35,310 iteration 551 : loss : 0.077593, loss_ce: 0.027838
2022-01-20 15:53:36,671 iteration 552 : loss : 0.115371, loss_ce: 0.053362
2022-01-20 15:53:38,038 iteration 553 : loss : 0.127656, loss_ce: 0.063344
2022-01-20 15:53:39,270 iteration 554 : loss : 0.082186, loss_ce: 0.032402
2022-01-20 15:53:40,617 iteration 555 : loss : 0.077135, loss_ce: 0.038970
2022-01-20 15:53:42,021 iteration 556 : loss : 0.109496, loss_ce: 0.049120
2022-01-20 15:53:43,303 iteration 557 : loss : 0.115306, loss_ce: 0.062625
2022-01-20 15:53:44,553 iteration 558 : loss : 0.138279, loss_ce: 0.055835
2022-01-20 15:53:45,874 iteration 559 : loss : 0.103331, loss_ce: 0.043137
2022-01-20 15:53:47,224 iteration 560 : loss : 0.102467, loss_ce: 0.040781
2022-01-20 15:53:48,479 iteration 561 : loss : 0.155511, loss_ce: 0.047229
  8%|██▍                           | 33/400 [13:37<2:24:15, 23.58s/it]2022-01-20 15:53:49,848 iteration 562 : loss : 0.086630, loss_ce: 0.032862
2022-01-20 15:53:51,190 iteration 563 : loss : 0.094594, loss_ce: 0.039865
2022-01-20 15:53:52,587 iteration 564 : loss : 0.107251, loss_ce: 0.053678
2022-01-20 15:53:53,936 iteration 565 : loss : 0.134249, loss_ce: 0.072096
2022-01-20 15:53:55,169 iteration 566 : loss : 0.067745, loss_ce: 0.025421
2022-01-20 15:53:56,539 iteration 567 : loss : 0.095933, loss_ce: 0.030823
2022-01-20 15:53:57,823 iteration 568 : loss : 0.089356, loss_ce: 0.034215
2022-01-20 15:53:59,134 iteration 569 : loss : 0.058621, loss_ce: 0.020297
2022-01-20 15:54:00,538 iteration 570 : loss : 0.104443, loss_ce: 0.043497
2022-01-20 15:54:01,889 iteration 571 : loss : 0.087246, loss_ce: 0.031718
2022-01-20 15:54:03,225 iteration 572 : loss : 0.079031, loss_ce: 0.027285
2022-01-20 15:54:04,500 iteration 573 : loss : 0.085630, loss_ce: 0.032638
2022-01-20 15:54:05,795 iteration 574 : loss : 0.092063, loss_ce: 0.037514
2022-01-20 15:54:07,159 iteration 575 : loss : 0.090469, loss_ce: 0.035000
2022-01-20 15:54:08,476 iteration 576 : loss : 0.097033, loss_ce: 0.049766
2022-01-20 15:54:09,809 iteration 577 : loss : 0.158830, loss_ce: 0.053298
2022-01-20 15:54:11,141 iteration 578 : loss : 0.092109, loss_ce: 0.032835
  8%|██▌                           | 34/400 [13:59<2:22:09, 23.30s/it]2022-01-20 15:54:12,500 iteration 579 : loss : 0.077625, loss_ce: 0.026004
2022-01-20 15:54:13,800 iteration 580 : loss : 0.068478, loss_ce: 0.029379
2022-01-20 15:54:15,126 iteration 581 : loss : 0.073037, loss_ce: 0.032923
2022-01-20 15:54:16,456 iteration 582 : loss : 0.068054, loss_ce: 0.028591
2022-01-20 15:54:17,740 iteration 583 : loss : 0.115453, loss_ce: 0.057970
2022-01-20 15:54:18,932 iteration 584 : loss : 0.061090, loss_ce: 0.025016
2022-01-20 15:54:20,195 iteration 585 : loss : 0.068430, loss_ce: 0.025614
2022-01-20 15:54:21,546 iteration 586 : loss : 0.078919, loss_ce: 0.039386
2022-01-20 15:54:22,841 iteration 587 : loss : 0.068507, loss_ce: 0.026375
2022-01-20 15:54:24,197 iteration 588 : loss : 0.102724, loss_ce: 0.035725
2022-01-20 15:54:25,518 iteration 589 : loss : 0.067306, loss_ce: 0.028670
2022-01-20 15:54:26,791 iteration 590 : loss : 0.091705, loss_ce: 0.047328
2022-01-20 15:54:28,091 iteration 591 : loss : 0.069862, loss_ce: 0.028646
2022-01-20 15:54:29,389 iteration 592 : loss : 0.084277, loss_ce: 0.030249
2022-01-20 15:54:30,754 iteration 593 : loss : 0.093560, loss_ce: 0.034068
2022-01-20 15:54:32,146 iteration 594 : loss : 0.078411, loss_ce: 0.042320
2022-01-20 15:54:32,146 Training Data Eval:
2022-01-20 15:54:38,718   Average segmentation loss on training set: 0.0700
2022-01-20 15:54:38,718 Validation Data Eval:
2022-01-20 15:54:40,943   Average segmentation loss on validation set: 0.1161
2022-01-20 15:54:42,304 iteration 595 : loss : 0.084365, loss_ce: 0.028792
  9%|██▋                           | 35/400 [14:30<2:36:07, 25.66s/it]2022-01-20 15:54:43,619 iteration 596 : loss : 0.050479, loss_ce: 0.022276
2022-01-20 15:54:44,935 iteration 597 : loss : 0.110779, loss_ce: 0.047562
2022-01-20 15:54:46,268 iteration 598 : loss : 0.066441, loss_ce: 0.025937
2022-01-20 15:54:47,644 iteration 599 : loss : 0.061614, loss_ce: 0.023864
2022-01-20 15:54:48,860 iteration 600 : loss : 0.075125, loss_ce: 0.038474
2022-01-20 15:54:50,168 iteration 601 : loss : 0.071587, loss_ce: 0.026087
2022-01-20 15:54:51,532 iteration 602 : loss : 0.093733, loss_ce: 0.047187
2022-01-20 15:54:52,735 iteration 603 : loss : 0.088708, loss_ce: 0.033188
2022-01-20 15:54:54,027 iteration 604 : loss : 0.077523, loss_ce: 0.033566
2022-01-20 15:54:55,346 iteration 605 : loss : 0.069108, loss_ce: 0.025902
2022-01-20 15:54:56,633 iteration 606 : loss : 0.110991, loss_ce: 0.047684
2022-01-20 15:54:57,938 iteration 607 : loss : 0.078830, loss_ce: 0.026272
2022-01-20 15:54:59,356 iteration 608 : loss : 0.079986, loss_ce: 0.030373
2022-01-20 15:55:00,640 iteration 609 : loss : 0.060245, loss_ce: 0.023879
2022-01-20 15:55:02,012 iteration 610 : loss : 0.078577, loss_ce: 0.030407
2022-01-20 15:55:03,316 iteration 611 : loss : 0.088176, loss_ce: 0.032420
2022-01-20 15:55:04,635 iteration 612 : loss : 0.074701, loss_ce: 0.032835
  9%|██▋                           | 36/400 [14:53<2:29:36, 24.66s/it]2022-01-20 15:55:06,021 iteration 613 : loss : 0.067900, loss_ce: 0.032938
2022-01-20 15:55:07,443 iteration 614 : loss : 0.063989, loss_ce: 0.026550
2022-01-20 15:55:08,738 iteration 615 : loss : 0.068354, loss_ce: 0.024494
2022-01-20 15:55:09,987 iteration 616 : loss : 0.092616, loss_ce: 0.055345
2022-01-20 15:55:11,307 iteration 617 : loss : 0.092289, loss_ce: 0.038539
2022-01-20 15:55:12,573 iteration 618 : loss : 0.082009, loss_ce: 0.033018
2022-01-20 15:55:13,874 iteration 619 : loss : 0.090764, loss_ce: 0.029066
2022-01-20 15:55:15,273 iteration 620 : loss : 0.101748, loss_ce: 0.036766
2022-01-20 15:55:16,540 iteration 621 : loss : 0.065934, loss_ce: 0.026067
2022-01-20 15:55:17,854 iteration 622 : loss : 0.059324, loss_ce: 0.024844
2022-01-20 15:55:19,219 iteration 623 : loss : 0.108076, loss_ce: 0.026017
2022-01-20 15:55:20,497 iteration 624 : loss : 0.080597, loss_ce: 0.032102
2022-01-20 15:55:21,743 iteration 625 : loss : 0.092675, loss_ce: 0.035007
2022-01-20 15:55:23,000 iteration 626 : loss : 0.060592, loss_ce: 0.023942
2022-01-20 15:55:24,283 iteration 627 : loss : 0.082654, loss_ce: 0.028112
2022-01-20 15:55:25,570 iteration 628 : loss : 0.096679, loss_ce: 0.053044
2022-01-20 15:55:26,910 iteration 629 : loss : 0.077351, loss_ce: 0.027604
  9%|██▊                           | 37/400 [15:15<2:24:53, 23.95s/it]2022-01-20 15:55:28,256 iteration 630 : loss : 0.059648, loss_ce: 0.023852
2022-01-20 15:55:29,599 iteration 631 : loss : 0.086432, loss_ce: 0.045431
2022-01-20 15:55:30,927 iteration 632 : loss : 0.105430, loss_ce: 0.043027
2022-01-20 15:55:32,291 iteration 633 : loss : 0.075693, loss_ce: 0.030233
2022-01-20 15:55:33,672 iteration 634 : loss : 0.073654, loss_ce: 0.034525
2022-01-20 15:55:34,981 iteration 635 : loss : 0.133684, loss_ce: 0.045807
2022-01-20 15:55:36,391 iteration 636 : loss : 0.095213, loss_ce: 0.054415
2022-01-20 15:55:37,654 iteration 637 : loss : 0.082474, loss_ce: 0.032789
2022-01-20 15:55:38,935 iteration 638 : loss : 0.114601, loss_ce: 0.053930
2022-01-20 15:55:40,310 iteration 639 : loss : 0.078546, loss_ce: 0.034538
2022-01-20 15:55:41,602 iteration 640 : loss : 0.085414, loss_ce: 0.031720
2022-01-20 15:55:42,937 iteration 641 : loss : 0.061804, loss_ce: 0.024679
2022-01-20 15:55:44,268 iteration 642 : loss : 0.077603, loss_ce: 0.030367
2022-01-20 15:55:45,583 iteration 643 : loss : 0.068368, loss_ce: 0.027382
2022-01-20 15:55:46,888 iteration 644 : loss : 0.061550, loss_ce: 0.023049
2022-01-20 15:55:48,210 iteration 645 : loss : 0.104939, loss_ce: 0.046009
2022-01-20 15:55:49,516 iteration 646 : loss : 0.069955, loss_ce: 0.032559
 10%|██▊                           | 38/400 [15:38<2:22:03, 23.54s/it]2022-01-20 15:55:50,880 iteration 647 : loss : 0.112265, loss_ce: 0.037315
2022-01-20 15:55:52,161 iteration 648 : loss : 0.103397, loss_ce: 0.057090
2022-01-20 15:55:53,444 iteration 649 : loss : 0.063306, loss_ce: 0.027854
2022-01-20 15:55:54,824 iteration 650 : loss : 0.130821, loss_ce: 0.046698
2022-01-20 15:55:56,209 iteration 651 : loss : 0.053892, loss_ce: 0.018791
2022-01-20 15:55:57,495 iteration 652 : loss : 0.064268, loss_ce: 0.026858
2022-01-20 15:55:58,814 iteration 653 : loss : 0.062552, loss_ce: 0.028358
2022-01-20 15:56:00,188 iteration 654 : loss : 0.058495, loss_ce: 0.024654
2022-01-20 15:56:01,470 iteration 655 : loss : 0.085339, loss_ce: 0.030766
2022-01-20 15:56:02,870 iteration 656 : loss : 0.096107, loss_ce: 0.035173
2022-01-20 15:56:04,214 iteration 657 : loss : 0.090538, loss_ce: 0.036573
2022-01-20 15:56:05,550 iteration 658 : loss : 0.099659, loss_ce: 0.037908
2022-01-20 15:56:06,928 iteration 659 : loss : 0.061347, loss_ce: 0.020581
2022-01-20 15:56:08,268 iteration 660 : loss : 0.080308, loss_ce: 0.033017
2022-01-20 15:56:09,597 iteration 661 : loss : 0.066355, loss_ce: 0.031185
2022-01-20 15:56:10,942 iteration 662 : loss : 0.073988, loss_ce: 0.031290
2022-01-20 15:56:12,255 iteration 663 : loss : 0.111288, loss_ce: 0.047245
 10%|██▉                           | 39/400 [16:00<2:20:12, 23.30s/it]2022-01-20 15:56:13,584 iteration 664 : loss : 0.102758, loss_ce: 0.049331
2022-01-20 15:56:14,941 iteration 665 : loss : 0.081688, loss_ce: 0.027347
2022-01-20 15:56:16,277 iteration 666 : loss : 0.095202, loss_ce: 0.030036
2022-01-20 15:56:17,656 iteration 667 : loss : 0.077490, loss_ce: 0.030289
2022-01-20 15:56:18,953 iteration 668 : loss : 0.057631, loss_ce: 0.021405
2022-01-20 15:56:20,328 iteration 669 : loss : 0.078515, loss_ce: 0.036651
2022-01-20 15:56:21,692 iteration 670 : loss : 0.113808, loss_ce: 0.045040
2022-01-20 15:56:23,023 iteration 671 : loss : 0.090450, loss_ce: 0.037650
2022-01-20 15:56:24,251 iteration 672 : loss : 0.076871, loss_ce: 0.033497
2022-01-20 15:56:25,552 iteration 673 : loss : 0.087524, loss_ce: 0.034941
2022-01-20 15:56:27,010 iteration 674 : loss : 0.072007, loss_ce: 0.032836
2022-01-20 15:56:28,314 iteration 675 : loss : 0.085521, loss_ce: 0.030842
2022-01-20 15:56:29,615 iteration 676 : loss : 0.075683, loss_ce: 0.035781
2022-01-20 15:56:31,054 iteration 677 : loss : 0.057645, loss_ce: 0.025968
2022-01-20 15:56:32,383 iteration 678 : loss : 0.096732, loss_ce: 0.029854
2022-01-20 15:56:33,641 iteration 679 : loss : 0.085209, loss_ce: 0.036514
2022-01-20 15:56:33,641 Training Data Eval:
2022-01-20 15:56:40,164   Average segmentation loss on training set: 0.0670
2022-01-20 15:56:40,165 Validation Data Eval:
2022-01-20 15:56:42,376   Average segmentation loss on validation set: 0.1474
2022-01-20 15:56:43,662 iteration 680 : loss : 0.080715, loss_ce: 0.032922
 10%|███                           | 40/400 [16:32<2:34:24, 25.74s/it]2022-01-20 15:56:45,210 iteration 681 : loss : 0.082819, loss_ce: 0.036069
2022-01-20 15:56:46,518 iteration 682 : loss : 0.082618, loss_ce: 0.031501
2022-01-20 15:56:47,784 iteration 683 : loss : 0.083593, loss_ce: 0.022780
2022-01-20 15:56:49,183 iteration 684 : loss : 0.088495, loss_ce: 0.037030
2022-01-20 15:56:50,588 iteration 685 : loss : 0.079170, loss_ce: 0.037589
2022-01-20 15:56:51,958 iteration 686 : loss : 0.086430, loss_ce: 0.043900
2022-01-20 15:56:53,320 iteration 687 : loss : 0.066813, loss_ce: 0.030556
2022-01-20 15:56:54,718 iteration 688 : loss : 0.069981, loss_ce: 0.028053
2022-01-20 15:56:56,071 iteration 689 : loss : 0.068583, loss_ce: 0.031853
2022-01-20 15:56:57,376 iteration 690 : loss : 0.073246, loss_ce: 0.030587
2022-01-20 15:56:58,742 iteration 691 : loss : 0.072890, loss_ce: 0.030145
2022-01-20 15:56:59,983 iteration 692 : loss : 0.056622, loss_ce: 0.025049
2022-01-20 15:57:01,272 iteration 693 : loss : 0.060720, loss_ce: 0.023614
2022-01-20 15:57:02,602 iteration 694 : loss : 0.116435, loss_ce: 0.045043
2022-01-20 15:57:03,920 iteration 695 : loss : 0.094185, loss_ce: 0.033816
2022-01-20 15:57:05,200 iteration 696 : loss : 0.161734, loss_ce: 0.040095
2022-01-20 15:57:06,418 iteration 697 : loss : 0.060321, loss_ce: 0.027201
 10%|███                           | 41/400 [16:54<2:28:38, 24.84s/it]2022-01-20 15:57:07,818 iteration 698 : loss : 0.073726, loss_ce: 0.032928
2022-01-20 15:57:09,150 iteration 699 : loss : 0.070835, loss_ce: 0.026042
2022-01-20 15:57:10,411 iteration 700 : loss : 0.073404, loss_ce: 0.028542
2022-01-20 15:57:11,679 iteration 701 : loss : 0.076047, loss_ce: 0.027227
2022-01-20 15:57:13,042 iteration 702 : loss : 0.088422, loss_ce: 0.035775
2022-01-20 15:57:14,367 iteration 703 : loss : 0.093289, loss_ce: 0.028476
2022-01-20 15:57:15,801 iteration 704 : loss : 0.105374, loss_ce: 0.036059
2022-01-20 15:57:17,168 iteration 705 : loss : 0.077870, loss_ce: 0.038027
2022-01-20 15:57:18,538 iteration 706 : loss : 0.101852, loss_ce: 0.027946
2022-01-20 15:57:19,824 iteration 707 : loss : 0.080955, loss_ce: 0.036110
2022-01-20 15:57:21,143 iteration 708 : loss : 0.062331, loss_ce: 0.022044
2022-01-20 15:57:22,483 iteration 709 : loss : 0.086706, loss_ce: 0.032742
2022-01-20 15:57:23,725 iteration 710 : loss : 0.070587, loss_ce: 0.032789
2022-01-20 15:57:25,098 iteration 711 : loss : 0.058284, loss_ce: 0.025967
2022-01-20 15:57:26,396 iteration 712 : loss : 0.126350, loss_ce: 0.043891
2022-01-20 15:57:27,626 iteration 713 : loss : 0.045800, loss_ce: 0.019599
2022-01-20 15:57:28,884 iteration 714 : loss : 0.072570, loss_ce: 0.025486
 10%|███▏                          | 42/400 [17:17<2:23:57, 24.13s/it]2022-01-20 15:57:30,340 iteration 715 : loss : 0.078974, loss_ce: 0.038192
2022-01-20 15:57:31,651 iteration 716 : loss : 0.072694, loss_ce: 0.030754
2022-01-20 15:57:32,965 iteration 717 : loss : 0.102434, loss_ce: 0.041689
2022-01-20 15:57:34,285 iteration 718 : loss : 0.090411, loss_ce: 0.035334
2022-01-20 15:57:35,700 iteration 719 : loss : 0.078480, loss_ce: 0.029659
2022-01-20 15:57:36,987 iteration 720 : loss : 0.093336, loss_ce: 0.031623
2022-01-20 15:57:38,370 iteration 721 : loss : 0.077901, loss_ce: 0.030177
2022-01-20 15:57:39,718 iteration 722 : loss : 0.069349, loss_ce: 0.030710
2022-01-20 15:57:41,007 iteration 723 : loss : 0.064914, loss_ce: 0.024139
2022-01-20 15:57:42,459 iteration 724 : loss : 0.082077, loss_ce: 0.036938
2022-01-20 15:57:43,699 iteration 725 : loss : 0.063132, loss_ce: 0.022428
2022-01-20 15:57:45,026 iteration 726 : loss : 0.108156, loss_ce: 0.031270
2022-01-20 15:57:46,401 iteration 727 : loss : 0.095905, loss_ce: 0.025863
2022-01-20 15:57:47,913 iteration 728 : loss : 0.088149, loss_ce: 0.043262
2022-01-20 15:57:49,103 iteration 729 : loss : 0.052650, loss_ce: 0.021345
2022-01-20 15:57:50,437 iteration 730 : loss : 0.063424, loss_ce: 0.027054
2022-01-20 15:57:51,785 iteration 731 : loss : 0.079758, loss_ce: 0.028291
 11%|███▏                          | 43/400 [17:40<2:21:20, 23.76s/it]2022-01-20 15:57:53,309 iteration 732 : loss : 0.059165, loss_ce: 0.025858
2022-01-20 15:57:54,674 iteration 733 : loss : 0.105833, loss_ce: 0.046705
2022-01-20 15:57:55,963 iteration 734 : loss : 0.077590, loss_ce: 0.029077
2022-01-20 15:57:57,339 iteration 735 : loss : 0.069453, loss_ce: 0.025836
2022-01-20 15:57:58,718 iteration 736 : loss : 0.071136, loss_ce: 0.027885
2022-01-20 15:58:00,134 iteration 737 : loss : 0.059617, loss_ce: 0.020214
2022-01-20 15:58:01,482 iteration 738 : loss : 0.046352, loss_ce: 0.020229
2022-01-20 15:58:02,804 iteration 739 : loss : 0.069094, loss_ce: 0.029850
2022-01-20 15:58:04,131 iteration 740 : loss : 0.073061, loss_ce: 0.036276
2022-01-20 15:58:05,494 iteration 741 : loss : 0.062371, loss_ce: 0.027021
2022-01-20 15:58:06,910 iteration 742 : loss : 0.099520, loss_ce: 0.029199
2022-01-20 15:58:08,201 iteration 743 : loss : 0.062944, loss_ce: 0.024587
2022-01-20 15:58:09,524 iteration 744 : loss : 0.069342, loss_ce: 0.025500
2022-01-20 15:58:10,834 iteration 745 : loss : 0.044777, loss_ce: 0.018589
2022-01-20 15:58:12,180 iteration 746 : loss : 0.112980, loss_ce: 0.054682
2022-01-20 15:58:13,557 iteration 747 : loss : 0.088798, loss_ce: 0.027981
2022-01-20 15:58:14,809 iteration 748 : loss : 0.062671, loss_ce: 0.027173
 11%|███▎                          | 44/400 [18:03<2:19:41, 23.54s/it]2022-01-20 15:58:16,216 iteration 749 : loss : 0.061486, loss_ce: 0.026822
2022-01-20 15:58:17,592 iteration 750 : loss : 0.092640, loss_ce: 0.041745
2022-01-20 15:58:18,842 iteration 751 : loss : 0.066834, loss_ce: 0.028341
2022-01-20 15:58:20,189 iteration 752 : loss : 0.067849, loss_ce: 0.027255
2022-01-20 15:58:21,631 iteration 753 : loss : 0.083974, loss_ce: 0.035736
2022-01-20 15:58:22,953 iteration 754 : loss : 0.093238, loss_ce: 0.037115
2022-01-20 15:58:24,322 iteration 755 : loss : 0.062736, loss_ce: 0.025445
2022-01-20 15:58:25,621 iteration 756 : loss : 0.069521, loss_ce: 0.034151
2022-01-20 15:58:26,955 iteration 757 : loss : 0.071013, loss_ce: 0.026066
2022-01-20 15:58:28,335 iteration 758 : loss : 0.066640, loss_ce: 0.028117
2022-01-20 15:58:29,613 iteration 759 : loss : 0.050490, loss_ce: 0.020969
2022-01-20 15:58:31,009 iteration 760 : loss : 0.099593, loss_ce: 0.034370
2022-01-20 15:58:32,434 iteration 761 : loss : 0.068329, loss_ce: 0.023299
2022-01-20 15:58:33,851 iteration 762 : loss : 0.063009, loss_ce: 0.027660
2022-01-20 15:58:35,212 iteration 763 : loss : 0.063016, loss_ce: 0.028221
2022-01-20 15:58:36,530 iteration 764 : loss : 0.069963, loss_ce: 0.031667
2022-01-20 15:58:36,530 Training Data Eval:
2022-01-20 15:58:43,244   Average segmentation loss on training set: 0.0751
2022-01-20 15:58:43,245 Validation Data Eval:
2022-01-20 15:58:45,513   Average segmentation loss on validation set: 0.1654
2022-01-20 15:58:46,881 iteration 765 : loss : 0.066926, loss_ce: 0.030359
 11%|███▍                          | 45/400 [18:35<2:34:25, 26.10s/it]2022-01-20 15:58:48,237 iteration 766 : loss : 0.098599, loss_ce: 0.038147
2022-01-20 15:58:49,608 iteration 767 : loss : 0.075875, loss_ce: 0.030089
2022-01-20 15:58:50,833 iteration 768 : loss : 0.069808, loss_ce: 0.025133
2022-01-20 15:58:52,171 iteration 769 : loss : 0.176613, loss_ce: 0.033988
2022-01-20 15:58:53,476 iteration 770 : loss : 0.062481, loss_ce: 0.024362
2022-01-20 15:58:54,880 iteration 771 : loss : 0.072894, loss_ce: 0.026336
2022-01-20 15:58:56,261 iteration 772 : loss : 0.075447, loss_ce: 0.032596
2022-01-20 15:58:57,583 iteration 773 : loss : 0.069697, loss_ce: 0.024788
2022-01-20 15:58:58,901 iteration 774 : loss : 0.067360, loss_ce: 0.029253
2022-01-20 15:59:00,208 iteration 775 : loss : 0.067017, loss_ce: 0.026044
2022-01-20 15:59:01,452 iteration 776 : loss : 0.074753, loss_ce: 0.030429
2022-01-20 15:59:02,877 iteration 777 : loss : 0.067978, loss_ce: 0.026103
2022-01-20 15:59:04,239 iteration 778 : loss : 0.046312, loss_ce: 0.018348
2022-01-20 15:59:05,598 iteration 779 : loss : 0.067820, loss_ce: 0.035861
2022-01-20 15:59:06,893 iteration 780 : loss : 0.064438, loss_ce: 0.024293
2022-01-20 15:59:08,299 iteration 781 : loss : 0.067221, loss_ce: 0.029667
2022-01-20 15:59:09,696 iteration 782 : loss : 0.092788, loss_ce: 0.036479
 12%|███▍                          | 46/400 [18:58<2:28:09, 25.11s/it]2022-01-20 15:59:11,163 iteration 783 : loss : 0.045430, loss_ce: 0.020173
2022-01-20 15:59:12,517 iteration 784 : loss : 0.093052, loss_ce: 0.035186
2022-01-20 15:59:13,901 iteration 785 : loss : 0.051490, loss_ce: 0.022326
2022-01-20 15:59:15,235 iteration 786 : loss : 0.065598, loss_ce: 0.024640
2022-01-20 15:59:16,588 iteration 787 : loss : 0.066574, loss_ce: 0.030435
2022-01-20 15:59:17,968 iteration 788 : loss : 0.074638, loss_ce: 0.023953
2022-01-20 15:59:19,460 iteration 789 : loss : 0.113897, loss_ce: 0.067244
2022-01-20 15:59:20,861 iteration 790 : loss : 0.066637, loss_ce: 0.023638
2022-01-20 15:59:22,172 iteration 791 : loss : 0.068757, loss_ce: 0.024532
2022-01-20 15:59:23,559 iteration 792 : loss : 0.087298, loss_ce: 0.035358
2022-01-20 15:59:24,802 iteration 793 : loss : 0.093902, loss_ce: 0.037194
2022-01-20 15:59:26,150 iteration 794 : loss : 0.048285, loss_ce: 0.020285
2022-01-20 15:59:27,518 iteration 795 : loss : 0.059092, loss_ce: 0.024929
2022-01-20 15:59:28,874 iteration 796 : loss : 0.070412, loss_ce: 0.028544
2022-01-20 15:59:30,171 iteration 797 : loss : 0.061679, loss_ce: 0.026268
2022-01-20 15:59:31,471 iteration 798 : loss : 0.126583, loss_ce: 0.034007
2022-01-20 15:59:32,840 iteration 799 : loss : 0.059404, loss_ce: 0.022184
 12%|███▌                          | 47/400 [19:21<2:24:16, 24.52s/it]2022-01-20 15:59:34,279 iteration 800 : loss : 0.062077, loss_ce: 0.019504
2022-01-20 15:59:35,548 iteration 801 : loss : 0.095490, loss_ce: 0.033631
2022-01-20 15:59:36,873 iteration 802 : loss : 0.090467, loss_ce: 0.041235
2022-01-20 15:59:38,287 iteration 803 : loss : 0.103249, loss_ce: 0.058915
2022-01-20 15:59:39,552 iteration 804 : loss : 0.066176, loss_ce: 0.028323
2022-01-20 15:59:40,822 iteration 805 : loss : 0.126654, loss_ce: 0.027535
2022-01-20 15:59:42,175 iteration 806 : loss : 0.069875, loss_ce: 0.026155
2022-01-20 15:59:43,587 iteration 807 : loss : 0.060450, loss_ce: 0.023181
2022-01-20 15:59:44,968 iteration 808 : loss : 0.076026, loss_ce: 0.027055
2022-01-20 15:59:46,280 iteration 809 : loss : 0.109599, loss_ce: 0.034646
2022-01-20 15:59:47,660 iteration 810 : loss : 0.089234, loss_ce: 0.028721
2022-01-20 15:59:48,946 iteration 811 : loss : 0.044010, loss_ce: 0.017299
2022-01-20 15:59:50,361 iteration 812 : loss : 0.103592, loss_ce: 0.040457
2022-01-20 15:59:51,669 iteration 813 : loss : 0.059869, loss_ce: 0.023777
2022-01-20 15:59:53,006 iteration 814 : loss : 0.062170, loss_ce: 0.026942
2022-01-20 15:59:54,386 iteration 815 : loss : 0.068834, loss_ce: 0.024215
2022-01-20 15:59:55,582 iteration 816 : loss : 0.058232, loss_ce: 0.020289
 12%|███▌                          | 48/400 [19:44<2:20:44, 23.99s/it]2022-01-20 15:59:56,936 iteration 817 : loss : 0.051232, loss_ce: 0.020669
2022-01-20 15:59:58,281 iteration 818 : loss : 0.081556, loss_ce: 0.031050
2022-01-20 15:59:59,585 iteration 819 : loss : 0.061557, loss_ce: 0.023400
2022-01-20 16:00:01,008 iteration 820 : loss : 0.083240, loss_ce: 0.033539
2022-01-20 16:00:02,215 iteration 821 : loss : 0.081342, loss_ce: 0.029412
2022-01-20 16:00:03,552 iteration 822 : loss : 0.058690, loss_ce: 0.021660
2022-01-20 16:00:04,846 iteration 823 : loss : 0.060332, loss_ce: 0.021009
2022-01-20 16:00:06,119 iteration 824 : loss : 0.066653, loss_ce: 0.028756
2022-01-20 16:00:07,406 iteration 825 : loss : 0.058412, loss_ce: 0.018062
2022-01-20 16:00:08,770 iteration 826 : loss : 0.072638, loss_ce: 0.034096
2022-01-20 16:00:10,051 iteration 827 : loss : 0.099376, loss_ce: 0.026847
2022-01-20 16:00:11,405 iteration 828 : loss : 0.057755, loss_ce: 0.027051
2022-01-20 16:00:12,698 iteration 829 : loss : 0.079969, loss_ce: 0.028566
2022-01-20 16:00:14,107 iteration 830 : loss : 0.069513, loss_ce: 0.023793
2022-01-20 16:00:15,426 iteration 831 : loss : 0.068354, loss_ce: 0.031520
2022-01-20 16:00:16,718 iteration 832 : loss : 0.052887, loss_ce: 0.023790
2022-01-20 16:00:17,984 iteration 833 : loss : 0.062114, loss_ce: 0.030585
 12%|███▋                          | 49/400 [20:06<2:17:32, 23.51s/it]2022-01-20 16:00:19,317 iteration 834 : loss : 0.082436, loss_ce: 0.027055
2022-01-20 16:00:20,665 iteration 835 : loss : 0.065711, loss_ce: 0.026443
2022-01-20 16:00:21,994 iteration 836 : loss : 0.046096, loss_ce: 0.021316
2022-01-20 16:00:23,301 iteration 837 : loss : 0.056659, loss_ce: 0.025420
2022-01-20 16:00:24,602 iteration 838 : loss : 0.081699, loss_ce: 0.031453
2022-01-20 16:00:26,012 iteration 839 : loss : 0.061535, loss_ce: 0.020496
2022-01-20 16:00:27,364 iteration 840 : loss : 0.076336, loss_ce: 0.026773
2022-01-20 16:00:28,701 iteration 841 : loss : 0.070732, loss_ce: 0.042116
2022-01-20 16:00:30,155 iteration 842 : loss : 0.082814, loss_ce: 0.029695
2022-01-20 16:00:31,443 iteration 843 : loss : 0.052520, loss_ce: 0.019066
2022-01-20 16:00:32,795 iteration 844 : loss : 0.096177, loss_ce: 0.047159
2022-01-20 16:00:34,073 iteration 845 : loss : 0.063380, loss_ce: 0.027597
2022-01-20 16:00:35,394 iteration 846 : loss : 0.077487, loss_ce: 0.029908
2022-01-20 16:00:36,752 iteration 847 : loss : 0.071916, loss_ce: 0.029915
2022-01-20 16:00:37,966 iteration 848 : loss : 0.054643, loss_ce: 0.022038
2022-01-20 16:00:39,309 iteration 849 : loss : 0.064555, loss_ce: 0.028367
2022-01-20 16:00:39,310 Training Data Eval:
2022-01-20 16:00:45,792   Average segmentation loss on training set: 0.1203
2022-01-20 16:00:45,793 Validation Data Eval:
2022-01-20 16:00:47,991   Average segmentation loss on validation set: 0.1208
2022-01-20 16:00:49,380 iteration 850 : loss : 0.072634, loss_ce: 0.026158
 12%|███▊                          | 50/400 [20:37<2:30:56, 25.88s/it]2022-01-20 16:00:50,765 iteration 851 : loss : 0.060626, loss_ce: 0.029081
2022-01-20 16:00:52,102 iteration 852 : loss : 0.078338, loss_ce: 0.024819
2022-01-20 16:00:53,444 iteration 853 : loss : 0.091517, loss_ce: 0.034571
2022-01-20 16:00:54,676 iteration 854 : loss : 0.068800, loss_ce: 0.028831
2022-01-20 16:00:55,881 iteration 855 : loss : 0.043701, loss_ce: 0.017643
2022-01-20 16:00:57,143 iteration 856 : loss : 0.066676, loss_ce: 0.026365
2022-01-20 16:00:58,546 iteration 857 : loss : 0.050262, loss_ce: 0.019557
2022-01-20 16:00:59,835 iteration 858 : loss : 0.079490, loss_ce: 0.025081
2022-01-20 16:01:01,223 iteration 859 : loss : 0.081935, loss_ce: 0.029288
2022-01-20 16:01:02,554 iteration 860 : loss : 0.100519, loss_ce: 0.035637
2022-01-20 16:01:03,855 iteration 861 : loss : 0.063231, loss_ce: 0.022175
2022-01-20 16:01:05,150 iteration 862 : loss : 0.064744, loss_ce: 0.018944
2022-01-20 16:01:06,384 iteration 863 : loss : 0.091130, loss_ce: 0.041060
2022-01-20 16:01:07,695 iteration 864 : loss : 0.076245, loss_ce: 0.032912
2022-01-20 16:01:08,938 iteration 865 : loss : 0.053174, loss_ce: 0.025821
2022-01-20 16:01:10,200 iteration 866 : loss : 0.052319, loss_ce: 0.019972
2022-01-20 16:01:11,463 iteration 867 : loss : 0.072976, loss_ce: 0.033384
 13%|███▊                          | 51/400 [21:00<2:23:53, 24.74s/it]2022-01-20 16:01:12,847 iteration 868 : loss : 0.064008, loss_ce: 0.026915
2022-01-20 16:01:14,100 iteration 869 : loss : 0.068099, loss_ce: 0.028463
2022-01-20 16:01:15,420 iteration 870 : loss : 0.122008, loss_ce: 0.025166
2022-01-20 16:01:16,754 iteration 871 : loss : 0.072406, loss_ce: 0.027293
2022-01-20 16:01:17,989 iteration 872 : loss : 0.043262, loss_ce: 0.019895
2022-01-20 16:01:19,265 iteration 873 : loss : 0.045361, loss_ce: 0.017096
2022-01-20 16:01:20,596 iteration 874 : loss : 0.074998, loss_ce: 0.031672
2022-01-20 16:01:21,922 iteration 875 : loss : 0.083016, loss_ce: 0.039754
2022-01-20 16:01:23,210 iteration 876 : loss : 0.072420, loss_ce: 0.030842
2022-01-20 16:01:24,455 iteration 877 : loss : 0.045521, loss_ce: 0.014228
2022-01-20 16:01:25,710 iteration 878 : loss : 0.046546, loss_ce: 0.016304
2022-01-20 16:01:27,021 iteration 879 : loss : 0.080264, loss_ce: 0.030171
2022-01-20 16:01:28,287 iteration 880 : loss : 0.046288, loss_ce: 0.018662
2022-01-20 16:01:29,640 iteration 881 : loss : 0.057165, loss_ce: 0.023157
2022-01-20 16:01:30,922 iteration 882 : loss : 0.059542, loss_ce: 0.027896
2022-01-20 16:01:32,202 iteration 883 : loss : 0.086055, loss_ce: 0.030265
2022-01-20 16:01:33,653 iteration 884 : loss : 0.064410, loss_ce: 0.021725
 13%|███▉                          | 52/400 [21:22<2:19:02, 23.97s/it]2022-01-20 16:01:35,097 iteration 885 : loss : 0.067426, loss_ce: 0.031404
2022-01-20 16:01:36,386 iteration 886 : loss : 0.060819, loss_ce: 0.020151
2022-01-20 16:01:37,675 iteration 887 : loss : 0.069184, loss_ce: 0.029748
2022-01-20 16:01:38,990 iteration 888 : loss : 0.077383, loss_ce: 0.026015
2022-01-20 16:01:40,265 iteration 889 : loss : 0.072124, loss_ce: 0.022559
2022-01-20 16:01:41,637 iteration 890 : loss : 0.075451, loss_ce: 0.038492
2022-01-20 16:01:42,976 iteration 891 : loss : 0.083271, loss_ce: 0.042314
2022-01-20 16:01:44,287 iteration 892 : loss : 0.087784, loss_ce: 0.026947
2022-01-20 16:01:45,679 iteration 893 : loss : 0.058100, loss_ce: 0.023636
2022-01-20 16:01:46,990 iteration 894 : loss : 0.079190, loss_ce: 0.033620
2022-01-20 16:01:48,318 iteration 895 : loss : 0.059611, loss_ce: 0.020567
2022-01-20 16:01:49,676 iteration 896 : loss : 0.098397, loss_ce: 0.033511
2022-01-20 16:01:50,901 iteration 897 : loss : 0.042867, loss_ce: 0.017060
2022-01-20 16:01:52,320 iteration 898 : loss : 0.066250, loss_ce: 0.029333
2022-01-20 16:01:53,615 iteration 899 : loss : 0.069017, loss_ce: 0.023808
2022-01-20 16:01:54,940 iteration 900 : loss : 0.076819, loss_ce: 0.029970
2022-01-20 16:01:56,235 iteration 901 : loss : 0.065363, loss_ce: 0.037798
 13%|███▉                          | 53/400 [21:44<2:16:15, 23.56s/it]2022-01-20 16:01:57,614 iteration 902 : loss : 0.047842, loss_ce: 0.020138
2022-01-20 16:01:58,961 iteration 903 : loss : 0.048831, loss_ce: 0.017112
2022-01-20 16:02:00,235 iteration 904 : loss : 0.072606, loss_ce: 0.036364
2022-01-20 16:02:01,486 iteration 905 : loss : 0.105541, loss_ce: 0.025490
2022-01-20 16:02:02,770 iteration 906 : loss : 0.058397, loss_ce: 0.021974
2022-01-20 16:02:04,141 iteration 907 : loss : 0.046819, loss_ce: 0.023794
2022-01-20 16:02:05,388 iteration 908 : loss : 0.050443, loss_ce: 0.027477
2022-01-20 16:02:06,729 iteration 909 : loss : 0.075727, loss_ce: 0.040848
2022-01-20 16:02:08,049 iteration 910 : loss : 0.105522, loss_ce: 0.038545
2022-01-20 16:02:09,385 iteration 911 : loss : 0.066343, loss_ce: 0.024924
2022-01-20 16:02:10,630 iteration 912 : loss : 0.069703, loss_ce: 0.023822
2022-01-20 16:02:11,990 iteration 913 : loss : 0.071380, loss_ce: 0.025663
2022-01-20 16:02:13,267 iteration 914 : loss : 0.052626, loss_ce: 0.023016
2022-01-20 16:02:14,608 iteration 915 : loss : 0.078717, loss_ce: 0.039199
2022-01-20 16:02:15,894 iteration 916 : loss : 0.077916, loss_ce: 0.027185
2022-01-20 16:02:17,210 iteration 917 : loss : 0.069218, loss_ce: 0.022228
2022-01-20 16:02:18,519 iteration 918 : loss : 0.068791, loss_ce: 0.022106
 14%|████                          | 54/400 [22:07<2:13:38, 23.17s/it]2022-01-20 16:02:19,966 iteration 919 : loss : 0.064032, loss_ce: 0.024765
2022-01-20 16:02:21,216 iteration 920 : loss : 0.109974, loss_ce: 0.076064
2022-01-20 16:02:22,630 iteration 921 : loss : 0.059212, loss_ce: 0.024168
2022-01-20 16:02:23,837 iteration 922 : loss : 0.049051, loss_ce: 0.023067
2022-01-20 16:02:25,107 iteration 923 : loss : 0.066242, loss_ce: 0.025255
2022-01-20 16:02:26,409 iteration 924 : loss : 0.056791, loss_ce: 0.018531
2022-01-20 16:02:27,652 iteration 925 : loss : 0.051799, loss_ce: 0.018938
2022-01-20 16:02:28,891 iteration 926 : loss : 0.064031, loss_ce: 0.021545
2022-01-20 16:02:30,206 iteration 927 : loss : 0.079221, loss_ce: 0.035046
2022-01-20 16:02:31,463 iteration 928 : loss : 0.063190, loss_ce: 0.023595
2022-01-20 16:02:32,934 iteration 929 : loss : 0.078371, loss_ce: 0.037690
2022-01-20 16:02:34,247 iteration 930 : loss : 0.059790, loss_ce: 0.034227
2022-01-20 16:02:35,567 iteration 931 : loss : 0.060117, loss_ce: 0.023603
2022-01-20 16:02:36,890 iteration 932 : loss : 0.080898, loss_ce: 0.025236
2022-01-20 16:02:38,358 iteration 933 : loss : 0.115290, loss_ce: 0.037863
2022-01-20 16:02:39,664 iteration 934 : loss : 0.065017, loss_ce: 0.024858
2022-01-20 16:02:39,664 Training Data Eval:
2022-01-20 16:02:46,202   Average segmentation loss on training set: 0.0522
2022-01-20 16:02:46,203 Validation Data Eval:
2022-01-20 16:02:48,428   Average segmentation loss on validation set: 0.1077
2022-01-20 16:02:49,713 iteration 935 : loss : 0.052945, loss_ce: 0.017294
 14%|████▏                         | 55/400 [22:38<2:27:04, 25.58s/it]2022-01-20 16:02:51,064 iteration 936 : loss : 0.075294, loss_ce: 0.018336
2022-01-20 16:02:52,345 iteration 937 : loss : 0.058895, loss_ce: 0.023281
2022-01-20 16:02:53,688 iteration 938 : loss : 0.065120, loss_ce: 0.030315
2022-01-20 16:02:54,995 iteration 939 : loss : 0.104116, loss_ce: 0.050353
2022-01-20 16:02:56,268 iteration 940 : loss : 0.071318, loss_ce: 0.033096
2022-01-20 16:02:57,591 iteration 941 : loss : 0.090164, loss_ce: 0.028203
2022-01-20 16:02:58,882 iteration 942 : loss : 0.058437, loss_ce: 0.018511
2022-01-20 16:03:00,109 iteration 943 : loss : 0.083079, loss_ce: 0.026726
2022-01-20 16:03:01,385 iteration 944 : loss : 0.048932, loss_ce: 0.019404
2022-01-20 16:03:02,672 iteration 945 : loss : 0.089141, loss_ce: 0.050655
2022-01-20 16:03:03,983 iteration 946 : loss : 0.050334, loss_ce: 0.017746
2022-01-20 16:03:05,413 iteration 947 : loss : 0.063187, loss_ce: 0.026846
2022-01-20 16:03:06,674 iteration 948 : loss : 0.072956, loss_ce: 0.029959
2022-01-20 16:03:08,010 iteration 949 : loss : 0.048785, loss_ce: 0.017640
2022-01-20 16:03:09,348 iteration 950 : loss : 0.091397, loss_ce: 0.029654
2022-01-20 16:03:10,733 iteration 951 : loss : 0.060956, loss_ce: 0.026323
2022-01-20 16:03:11,974 iteration 952 : loss : 0.104429, loss_ce: 0.034411
 14%|████▏                         | 56/400 [23:00<2:20:57, 24.59s/it]2022-01-20 16:03:13,355 iteration 953 : loss : 0.051246, loss_ce: 0.017256
2022-01-20 16:03:14,762 iteration 954 : loss : 0.049112, loss_ce: 0.015629
2022-01-20 16:03:16,036 iteration 955 : loss : 0.038182, loss_ce: 0.014567
2022-01-20 16:03:17,323 iteration 956 : loss : 0.052962, loss_ce: 0.021550
2022-01-20 16:03:18,498 iteration 957 : loss : 0.086179, loss_ce: 0.032291
2022-01-20 16:03:19,775 iteration 958 : loss : 0.060230, loss_ce: 0.018589
2022-01-20 16:03:21,018 iteration 959 : loss : 0.058748, loss_ce: 0.026717
2022-01-20 16:03:22,273 iteration 960 : loss : 0.050841, loss_ce: 0.019362
2022-01-20 16:03:23,584 iteration 961 : loss : 0.082379, loss_ce: 0.029767
2022-01-20 16:03:24,875 iteration 962 : loss : 0.041529, loss_ce: 0.015392
2022-01-20 16:03:26,218 iteration 963 : loss : 0.059924, loss_ce: 0.021877
2022-01-20 16:03:27,535 iteration 964 : loss : 0.085326, loss_ce: 0.037285
2022-01-20 16:03:28,821 iteration 965 : loss : 0.051565, loss_ce: 0.020942
2022-01-20 16:03:30,221 iteration 966 : loss : 0.085723, loss_ce: 0.046820
2022-01-20 16:03:31,525 iteration 967 : loss : 0.120692, loss_ce: 0.047317
2022-01-20 16:03:32,853 iteration 968 : loss : 0.059086, loss_ce: 0.025118
2022-01-20 16:03:34,224 iteration 969 : loss : 0.057896, loss_ce: 0.023177
 14%|████▎                         | 57/400 [23:22<2:16:32, 23.88s/it]2022-01-20 16:03:35,588 iteration 970 : loss : 0.044730, loss_ce: 0.017954
2022-01-20 16:03:36,986 iteration 971 : loss : 0.105094, loss_ce: 0.043423
2022-01-20 16:03:38,232 iteration 972 : loss : 0.054166, loss_ce: 0.022166
2022-01-20 16:03:39,496 iteration 973 : loss : 0.053120, loss_ce: 0.019615
2022-01-20 16:03:40,809 iteration 974 : loss : 0.054512, loss_ce: 0.019042
2022-01-20 16:03:42,079 iteration 975 : loss : 0.068381, loss_ce: 0.027149
2022-01-20 16:03:43,357 iteration 976 : loss : 0.084046, loss_ce: 0.029287
2022-01-20 16:03:44,731 iteration 977 : loss : 0.064143, loss_ce: 0.022877
2022-01-20 16:03:46,078 iteration 978 : loss : 0.070662, loss_ce: 0.029842
2022-01-20 16:03:47,422 iteration 979 : loss : 0.051474, loss_ce: 0.023779
2022-01-20 16:03:48,658 iteration 980 : loss : 0.065335, loss_ce: 0.021397
2022-01-20 16:03:50,032 iteration 981 : loss : 0.075314, loss_ce: 0.028224
2022-01-20 16:03:51,259 iteration 982 : loss : 0.066315, loss_ce: 0.034275
2022-01-20 16:03:52,594 iteration 983 : loss : 0.076178, loss_ce: 0.029817
2022-01-20 16:03:53,903 iteration 984 : loss : 0.073104, loss_ce: 0.033776
2022-01-20 16:03:55,198 iteration 985 : loss : 0.066359, loss_ce: 0.024394
2022-01-20 16:03:56,497 iteration 986 : loss : 0.084521, loss_ce: 0.027632
 14%|████▎                         | 58/400 [23:45<2:13:22, 23.40s/it]2022-01-20 16:03:57,870 iteration 987 : loss : 0.044058, loss_ce: 0.019937
2022-01-20 16:03:59,257 iteration 988 : loss : 0.058950, loss_ce: 0.026368
2022-01-20 16:04:00,518 iteration 989 : loss : 0.066609, loss_ce: 0.023071
2022-01-20 16:04:01,898 iteration 990 : loss : 0.054837, loss_ce: 0.027819
2022-01-20 16:04:03,252 iteration 991 : loss : 0.076906, loss_ce: 0.039142
2022-01-20 16:04:04,501 iteration 992 : loss : 0.077171, loss_ce: 0.024849
2022-01-20 16:04:05,941 iteration 993 : loss : 0.050215, loss_ce: 0.021738
2022-01-20 16:04:07,302 iteration 994 : loss : 0.061440, loss_ce: 0.019883
2022-01-20 16:04:08,628 iteration 995 : loss : 0.054774, loss_ce: 0.019765
2022-01-20 16:04:09,921 iteration 996 : loss : 0.045519, loss_ce: 0.017548
2022-01-20 16:04:11,292 iteration 997 : loss : 0.073549, loss_ce: 0.032393
2022-01-20 16:04:12,645 iteration 998 : loss : 0.061026, loss_ce: 0.022262
2022-01-20 16:04:14,082 iteration 999 : loss : 0.048659, loss_ce: 0.018881
2022-01-20 16:04:15,448 iteration 1000 : loss : 0.066532, loss_ce: 0.027676
2022-01-20 16:04:16,814 iteration 1001 : loss : 0.059708, loss_ce: 0.021532
2022-01-20 16:04:18,099 iteration 1002 : loss : 0.044711, loss_ce: 0.015337
2022-01-20 16:04:19,412 iteration 1003 : loss : 0.067343, loss_ce: 0.026764
 15%|████▍                         | 59/400 [24:07<2:12:10, 23.26s/it]2022-01-20 16:04:20,800 iteration 1004 : loss : 0.046950, loss_ce: 0.019279
2022-01-20 16:04:22,219 iteration 1005 : loss : 0.078600, loss_ce: 0.026142
2022-01-20 16:04:23,567 iteration 1006 : loss : 0.067864, loss_ce: 0.034772
2022-01-20 16:04:24,930 iteration 1007 : loss : 0.051693, loss_ce: 0.020136
2022-01-20 16:04:26,296 iteration 1008 : loss : 0.090733, loss_ce: 0.028781
2022-01-20 16:04:27,659 iteration 1009 : loss : 0.074351, loss_ce: 0.027688
2022-01-20 16:04:28,953 iteration 1010 : loss : 0.042229, loss_ce: 0.016853
2022-01-20 16:04:30,269 iteration 1011 : loss : 0.047717, loss_ce: 0.018726
2022-01-20 16:04:31,686 iteration 1012 : loss : 0.076916, loss_ce: 0.026102
2022-01-20 16:04:32,970 iteration 1013 : loss : 0.064221, loss_ce: 0.019748
2022-01-20 16:04:34,322 iteration 1014 : loss : 0.055171, loss_ce: 0.023670
2022-01-20 16:04:35,627 iteration 1015 : loss : 0.061827, loss_ce: 0.028750
2022-01-20 16:04:36,863 iteration 1016 : loss : 0.053582, loss_ce: 0.027528
2022-01-20 16:04:38,297 iteration 1017 : loss : 0.063424, loss_ce: 0.019743
2022-01-20 16:04:39,679 iteration 1018 : loss : 0.052744, loss_ce: 0.021486
2022-01-20 16:04:41,068 iteration 1019 : loss : 0.078141, loss_ce: 0.030320
2022-01-20 16:04:41,068 Training Data Eval:
2022-01-20 16:04:47,585   Average segmentation loss on training set: 0.0460
2022-01-20 16:04:47,585 Validation Data Eval:
2022-01-20 16:04:49,797   Average segmentation loss on validation set: 0.0933
2022-01-20 16:04:55,791 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 16:04:57,149 iteration 1020 : loss : 0.064917, loss_ce: 0.020170
 15%|████▌                         | 60/400 [24:45<2:36:25, 27.60s/it]2022-01-20 16:04:58,570 iteration 1021 : loss : 0.069093, loss_ce: 0.028376
2022-01-20 16:04:59,813 iteration 1022 : loss : 0.062648, loss_ce: 0.023489
2022-01-20 16:05:01,028 iteration 1023 : loss : 0.101314, loss_ce: 0.030011
2022-01-20 16:05:02,323 iteration 1024 : loss : 0.048873, loss_ce: 0.026514
2022-01-20 16:05:03,542 iteration 1025 : loss : 0.078686, loss_ce: 0.030644
2022-01-20 16:05:04,834 iteration 1026 : loss : 0.069862, loss_ce: 0.022945
2022-01-20 16:05:06,072 iteration 1027 : loss : 0.061064, loss_ce: 0.031658
2022-01-20 16:05:07,276 iteration 1028 : loss : 0.060296, loss_ce: 0.017776
2022-01-20 16:05:08,554 iteration 1029 : loss : 0.059447, loss_ce: 0.019510
2022-01-20 16:05:09,875 iteration 1030 : loss : 0.050521, loss_ce: 0.018642
2022-01-20 16:05:11,268 iteration 1031 : loss : 0.052515, loss_ce: 0.019427
2022-01-20 16:05:12,505 iteration 1032 : loss : 0.051105, loss_ce: 0.018819
2022-01-20 16:05:13,874 iteration 1033 : loss : 0.064968, loss_ce: 0.022763
2022-01-20 16:05:15,256 iteration 1034 : loss : 0.054408, loss_ce: 0.025794
2022-01-20 16:05:16,601 iteration 1035 : loss : 0.065591, loss_ce: 0.023599
2022-01-20 16:05:17,998 iteration 1036 : loss : 0.061727, loss_ce: 0.027834
2022-01-20 16:05:19,177 iteration 1037 : loss : 0.050859, loss_ce: 0.022560
 15%|████▌                         | 61/400 [25:07<2:26:29, 25.93s/it]2022-01-20 16:05:20,487 iteration 1038 : loss : 0.040652, loss_ce: 0.017746
2022-01-20 16:05:21,808 iteration 1039 : loss : 0.061066, loss_ce: 0.030256
2022-01-20 16:05:23,055 iteration 1040 : loss : 0.079977, loss_ce: 0.039074
2022-01-20 16:05:24,454 iteration 1041 : loss : 0.050376, loss_ce: 0.021477
2022-01-20 16:05:25,829 iteration 1042 : loss : 0.058858, loss_ce: 0.021297
2022-01-20 16:05:27,076 iteration 1043 : loss : 0.056745, loss_ce: 0.023071
2022-01-20 16:05:28,365 iteration 1044 : loss : 0.051175, loss_ce: 0.020710
2022-01-20 16:05:29,641 iteration 1045 : loss : 0.050526, loss_ce: 0.025658
2022-01-20 16:05:30,967 iteration 1046 : loss : 0.069610, loss_ce: 0.024742
2022-01-20 16:05:32,361 iteration 1047 : loss : 0.065627, loss_ce: 0.027594
2022-01-20 16:05:33,667 iteration 1048 : loss : 0.052967, loss_ce: 0.022038
2022-01-20 16:05:34,903 iteration 1049 : loss : 0.060723, loss_ce: 0.022594
2022-01-20 16:05:36,178 iteration 1050 : loss : 0.044249, loss_ce: 0.017377
2022-01-20 16:05:37,501 iteration 1051 : loss : 0.057075, loss_ce: 0.020473
2022-01-20 16:05:38,803 iteration 1052 : loss : 0.068076, loss_ce: 0.033282
2022-01-20 16:05:40,239 iteration 1053 : loss : 0.051247, loss_ce: 0.020919
2022-01-20 16:05:41,535 iteration 1054 : loss : 0.061966, loss_ce: 0.020676
 16%|████▋                         | 62/400 [25:30<2:20:01, 24.86s/it]2022-01-20 16:05:42,894 iteration 1055 : loss : 0.054026, loss_ce: 0.019122
2022-01-20 16:05:44,202 iteration 1056 : loss : 0.063885, loss_ce: 0.029520
2022-01-20 16:05:45,546 iteration 1057 : loss : 0.078575, loss_ce: 0.020783
2022-01-20 16:05:46,795 iteration 1058 : loss : 0.040477, loss_ce: 0.017837
2022-01-20 16:05:48,205 iteration 1059 : loss : 0.063101, loss_ce: 0.026579
2022-01-20 16:05:49,497 iteration 1060 : loss : 0.054084, loss_ce: 0.025599
2022-01-20 16:05:50,851 iteration 1061 : loss : 0.054128, loss_ce: 0.021147
2022-01-20 16:05:52,159 iteration 1062 : loss : 0.053038, loss_ce: 0.020568
2022-01-20 16:05:53,556 iteration 1063 : loss : 0.048618, loss_ce: 0.016158
2022-01-20 16:05:54,827 iteration 1064 : loss : 0.062132, loss_ce: 0.027759
2022-01-20 16:05:56,058 iteration 1065 : loss : 0.057926, loss_ce: 0.021524
2022-01-20 16:05:57,388 iteration 1066 : loss : 0.051918, loss_ce: 0.024212
2022-01-20 16:05:58,834 iteration 1067 : loss : 0.074205, loss_ce: 0.038763
2022-01-20 16:06:00,188 iteration 1068 : loss : 0.074581, loss_ce: 0.028331
2022-01-20 16:06:01,421 iteration 1069 : loss : 0.062985, loss_ce: 0.024541
2022-01-20 16:06:02,831 iteration 1070 : loss : 0.050342, loss_ce: 0.017990
2022-01-20 16:06:04,129 iteration 1071 : loss : 0.050255, loss_ce: 0.018313
 16%|████▋                         | 63/400 [25:52<2:15:47, 24.18s/it]2022-01-20 16:06:05,468 iteration 1072 : loss : 0.053855, loss_ce: 0.021095
2022-01-20 16:06:06,880 iteration 1073 : loss : 0.069433, loss_ce: 0.024430
2022-01-20 16:06:08,161 iteration 1074 : loss : 0.042363, loss_ce: 0.018047
2022-01-20 16:06:09,482 iteration 1075 : loss : 0.047985, loss_ce: 0.016590
2022-01-20 16:06:10,750 iteration 1076 : loss : 0.050287, loss_ce: 0.018293
2022-01-20 16:06:12,105 iteration 1077 : loss : 0.107289, loss_ce: 0.037614
2022-01-20 16:06:13,337 iteration 1078 : loss : 0.060797, loss_ce: 0.026950
2022-01-20 16:06:14,642 iteration 1079 : loss : 0.069644, loss_ce: 0.033542
2022-01-20 16:06:15,995 iteration 1080 : loss : 0.055628, loss_ce: 0.021218
2022-01-20 16:06:17,339 iteration 1081 : loss : 0.048121, loss_ce: 0.019856
2022-01-20 16:06:18,658 iteration 1082 : loss : 0.069396, loss_ce: 0.033995
2022-01-20 16:06:19,966 iteration 1083 : loss : 0.075468, loss_ce: 0.025423
2022-01-20 16:06:21,334 iteration 1084 : loss : 0.121901, loss_ce: 0.036332
2022-01-20 16:06:22,613 iteration 1085 : loss : 0.062202, loss_ce: 0.021436
2022-01-20 16:06:23,957 iteration 1086 : loss : 0.051273, loss_ce: 0.016927
2022-01-20 16:06:25,190 iteration 1087 : loss : 0.044403, loss_ce: 0.018691
2022-01-20 16:06:26,472 iteration 1088 : loss : 0.055115, loss_ce: 0.024837
 16%|████▊                         | 64/400 [26:15<2:12:19, 23.63s/it]2022-01-20 16:06:27,735 iteration 1089 : loss : 0.048696, loss_ce: 0.020111
2022-01-20 16:06:29,047 iteration 1090 : loss : 0.059412, loss_ce: 0.021638
2022-01-20 16:06:30,404 iteration 1091 : loss : 0.065415, loss_ce: 0.033723
2022-01-20 16:06:31,722 iteration 1092 : loss : 0.061211, loss_ce: 0.018728
2022-01-20 16:06:33,059 iteration 1093 : loss : 0.067608, loss_ce: 0.023612
2022-01-20 16:06:34,503 iteration 1094 : loss : 0.137331, loss_ce: 0.033573
2022-01-20 16:06:35,770 iteration 1095 : loss : 0.044853, loss_ce: 0.014847
2022-01-20 16:06:37,034 iteration 1096 : loss : 0.044273, loss_ce: 0.020829
2022-01-20 16:06:38,275 iteration 1097 : loss : 0.058924, loss_ce: 0.024924
2022-01-20 16:06:39,658 iteration 1098 : loss : 0.077475, loss_ce: 0.039271
2022-01-20 16:06:40,963 iteration 1099 : loss : 0.059019, loss_ce: 0.023756
2022-01-20 16:06:42,347 iteration 1100 : loss : 0.072806, loss_ce: 0.034237
2022-01-20 16:06:43,729 iteration 1101 : loss : 0.056594, loss_ce: 0.023353
2022-01-20 16:06:45,040 iteration 1102 : loss : 0.075906, loss_ce: 0.031618
2022-01-20 16:06:46,380 iteration 1103 : loss : 0.040478, loss_ce: 0.017635
2022-01-20 16:06:47,695 iteration 1104 : loss : 0.050769, loss_ce: 0.021683
2022-01-20 16:06:47,696 Training Data Eval:
2022-01-20 16:06:54,310   Average segmentation loss on training set: 0.0500
2022-01-20 16:06:54,310 Validation Data Eval:
2022-01-20 16:06:56,543   Average segmentation loss on validation set: 0.0787
2022-01-20 16:07:02,792 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 16:07:04,073 iteration 1105 : loss : 0.046116, loss_ce: 0.019756
 16%|████▉                         | 65/400 [26:52<2:35:20, 27.82s/it]2022-01-20 16:07:05,430 iteration 1106 : loss : 0.052564, loss_ce: 0.019543
2022-01-20 16:07:06,679 iteration 1107 : loss : 0.050737, loss_ce: 0.021756
2022-01-20 16:07:07,896 iteration 1108 : loss : 0.056778, loss_ce: 0.018949
2022-01-20 16:07:09,234 iteration 1109 : loss : 0.073615, loss_ce: 0.027123
2022-01-20 16:07:10,479 iteration 1110 : loss : 0.055028, loss_ce: 0.022886
2022-01-20 16:07:11,839 iteration 1111 : loss : 0.108745, loss_ce: 0.035494
2022-01-20 16:07:13,038 iteration 1112 : loss : 0.046945, loss_ce: 0.020285
2022-01-20 16:07:14,304 iteration 1113 : loss : 0.044701, loss_ce: 0.018413
2022-01-20 16:07:15,632 iteration 1114 : loss : 0.052624, loss_ce: 0.018632
2022-01-20 16:07:16,985 iteration 1115 : loss : 0.049969, loss_ce: 0.016414
2022-01-20 16:07:18,243 iteration 1116 : loss : 0.053286, loss_ce: 0.023088
2022-01-20 16:07:19,529 iteration 1117 : loss : 0.058916, loss_ce: 0.024434
2022-01-20 16:07:20,897 iteration 1118 : loss : 0.056646, loss_ce: 0.024175
2022-01-20 16:07:22,251 iteration 1119 : loss : 0.047590, loss_ce: 0.020607
2022-01-20 16:07:23,580 iteration 1120 : loss : 0.053276, loss_ce: 0.014889
2022-01-20 16:07:24,868 iteration 1121 : loss : 0.041602, loss_ce: 0.019930
2022-01-20 16:07:26,121 iteration 1122 : loss : 0.049690, loss_ce: 0.015746
 16%|████▉                         | 66/400 [27:14<2:25:13, 26.09s/it]2022-01-20 16:07:27,611 iteration 1123 : loss : 0.041022, loss_ce: 0.014959
2022-01-20 16:07:28,923 iteration 1124 : loss : 0.038510, loss_ce: 0.018230
2022-01-20 16:07:30,190 iteration 1125 : loss : 0.043340, loss_ce: 0.012985
2022-01-20 16:07:31,479 iteration 1126 : loss : 0.057467, loss_ce: 0.018608
2022-01-20 16:07:32,768 iteration 1127 : loss : 0.045561, loss_ce: 0.017502
2022-01-20 16:07:34,164 iteration 1128 : loss : 0.050740, loss_ce: 0.022054
2022-01-20 16:07:35,582 iteration 1129 : loss : 0.066288, loss_ce: 0.028338
2022-01-20 16:07:36,831 iteration 1130 : loss : 0.052782, loss_ce: 0.020568
2022-01-20 16:07:38,204 iteration 1131 : loss : 0.067597, loss_ce: 0.027701
2022-01-20 16:07:39,613 iteration 1132 : loss : 0.052075, loss_ce: 0.018684
2022-01-20 16:07:41,000 iteration 1133 : loss : 0.052459, loss_ce: 0.024184
2022-01-20 16:07:42,377 iteration 1134 : loss : 0.066959, loss_ce: 0.023011
2022-01-20 16:07:43,635 iteration 1135 : loss : 0.062309, loss_ce: 0.022621
2022-01-20 16:07:44,915 iteration 1136 : loss : 0.037395, loss_ce: 0.017504
2022-01-20 16:07:46,213 iteration 1137 : loss : 0.056993, loss_ce: 0.025900
2022-01-20 16:07:47,570 iteration 1138 : loss : 0.067707, loss_ce: 0.026607
2022-01-20 16:07:48,833 iteration 1139 : loss : 0.055539, loss_ce: 0.026388
 17%|█████                         | 67/400 [27:37<2:19:10, 25.08s/it]2022-01-20 16:07:50,213 iteration 1140 : loss : 0.046833, loss_ce: 0.020220
2022-01-20 16:07:51,544 iteration 1141 : loss : 0.080748, loss_ce: 0.040064
2022-01-20 16:07:52,984 iteration 1142 : loss : 0.047415, loss_ce: 0.019804
2022-01-20 16:07:54,308 iteration 1143 : loss : 0.050931, loss_ce: 0.020855
2022-01-20 16:07:55,642 iteration 1144 : loss : 0.057620, loss_ce: 0.017653
2022-01-20 16:07:56,964 iteration 1145 : loss : 0.054140, loss_ce: 0.018989
2022-01-20 16:07:58,256 iteration 1146 : loss : 0.038830, loss_ce: 0.015442
2022-01-20 16:07:59,563 iteration 1147 : loss : 0.041646, loss_ce: 0.015812
2022-01-20 16:08:00,850 iteration 1148 : loss : 0.054499, loss_ce: 0.022314
2022-01-20 16:08:02,163 iteration 1149 : loss : 0.036128, loss_ce: 0.017709
2022-01-20 16:08:03,441 iteration 1150 : loss : 0.069068, loss_ce: 0.028058
2022-01-20 16:08:04,733 iteration 1151 : loss : 0.034705, loss_ce: 0.015623
2022-01-20 16:08:05,997 iteration 1152 : loss : 0.057099, loss_ce: 0.022444
2022-01-20 16:08:07,401 iteration 1153 : loss : 0.073318, loss_ce: 0.025318
2022-01-20 16:08:08,743 iteration 1154 : loss : 0.037202, loss_ce: 0.013868
2022-01-20 16:08:10,106 iteration 1155 : loss : 0.056767, loss_ce: 0.019368
2022-01-20 16:08:11,552 iteration 1156 : loss : 0.054590, loss_ce: 0.017046
 17%|█████                         | 68/400 [28:00<2:14:49, 24.36s/it]2022-01-20 16:08:12,960 iteration 1157 : loss : 0.057066, loss_ce: 0.022813
2022-01-20 16:08:14,262 iteration 1158 : loss : 0.052812, loss_ce: 0.017837
2022-01-20 16:08:15,476 iteration 1159 : loss : 0.045076, loss_ce: 0.018511
2022-01-20 16:08:16,775 iteration 1160 : loss : 0.046776, loss_ce: 0.024231
2022-01-20 16:08:18,124 iteration 1161 : loss : 0.052072, loss_ce: 0.017937
2022-01-20 16:08:19,473 iteration 1162 : loss : 0.042003, loss_ce: 0.016077
2022-01-20 16:08:20,792 iteration 1163 : loss : 0.047977, loss_ce: 0.024646
2022-01-20 16:08:22,179 iteration 1164 : loss : 0.059076, loss_ce: 0.026227
2022-01-20 16:08:23,395 iteration 1165 : loss : 0.039346, loss_ce: 0.018779
2022-01-20 16:08:24,659 iteration 1166 : loss : 0.059883, loss_ce: 0.021308
2022-01-20 16:08:25,988 iteration 1167 : loss : 0.052949, loss_ce: 0.023559
2022-01-20 16:08:27,376 iteration 1168 : loss : 0.099907, loss_ce: 0.029981
2022-01-20 16:08:28,624 iteration 1169 : loss : 0.077101, loss_ce: 0.022087
2022-01-20 16:08:29,975 iteration 1170 : loss : 0.053507, loss_ce: 0.016531
2022-01-20 16:08:31,414 iteration 1171 : loss : 0.119482, loss_ce: 0.035313
2022-01-20 16:08:32,632 iteration 1172 : loss : 0.047339, loss_ce: 0.018141
2022-01-20 16:08:33,868 iteration 1173 : loss : 0.039862, loss_ce: 0.013934
 17%|█████▏                        | 69/400 [28:22<2:11:02, 23.75s/it]2022-01-20 16:08:35,284 iteration 1174 : loss : 0.049951, loss_ce: 0.018256
2022-01-20 16:08:36,673 iteration 1175 : loss : 0.097273, loss_ce: 0.042223
2022-01-20 16:08:37,939 iteration 1176 : loss : 0.086263, loss_ce: 0.034938
2022-01-20 16:08:39,225 iteration 1177 : loss : 0.072421, loss_ce: 0.033183
2022-01-20 16:08:40,480 iteration 1178 : loss : 0.039852, loss_ce: 0.016425
2022-01-20 16:08:41,857 iteration 1179 : loss : 0.052103, loss_ce: 0.021199
2022-01-20 16:08:43,194 iteration 1180 : loss : 0.057808, loss_ce: 0.024555
2022-01-20 16:08:44,446 iteration 1181 : loss : 0.060908, loss_ce: 0.022322
2022-01-20 16:08:45,739 iteration 1182 : loss : 0.049909, loss_ce: 0.023043
2022-01-20 16:08:47,054 iteration 1183 : loss : 0.061727, loss_ce: 0.033499
2022-01-20 16:08:48,383 iteration 1184 : loss : 0.103467, loss_ce: 0.054119
2022-01-20 16:08:49,671 iteration 1185 : loss : 0.051266, loss_ce: 0.028417
2022-01-20 16:08:51,001 iteration 1186 : loss : 0.056202, loss_ce: 0.018546
2022-01-20 16:08:52,247 iteration 1187 : loss : 0.036858, loss_ce: 0.017091
2022-01-20 16:08:53,602 iteration 1188 : loss : 0.069846, loss_ce: 0.028592
2022-01-20 16:08:54,963 iteration 1189 : loss : 0.096034, loss_ce: 0.025854
2022-01-20 16:08:54,963 Training Data Eval:
2022-01-20 16:09:01,454   Average segmentation loss on training set: 0.0550
2022-01-20 16:09:01,455 Validation Data Eval:
2022-01-20 16:09:03,660   Average segmentation loss on validation set: 0.0845
2022-01-20 16:09:04,944 iteration 1190 : loss : 0.055159, loss_ce: 0.017358
 18%|█████▎                        | 70/400 [28:53<2:22:42, 25.95s/it]2022-01-20 16:09:06,326 iteration 1191 : loss : 0.045752, loss_ce: 0.018568
2022-01-20 16:09:07,597 iteration 1192 : loss : 0.068697, loss_ce: 0.038618
2022-01-20 16:09:08,815 iteration 1193 : loss : 0.057607, loss_ce: 0.020691
2022-01-20 16:09:10,132 iteration 1194 : loss : 0.061240, loss_ce: 0.018025
2022-01-20 16:09:11,442 iteration 1195 : loss : 0.054234, loss_ce: 0.022192
2022-01-20 16:09:12,776 iteration 1196 : loss : 0.042715, loss_ce: 0.017689
2022-01-20 16:09:14,134 iteration 1197 : loss : 0.069979, loss_ce: 0.022450
2022-01-20 16:09:15,401 iteration 1198 : loss : 0.040189, loss_ce: 0.013149
2022-01-20 16:09:16,690 iteration 1199 : loss : 0.062403, loss_ce: 0.031481
2022-01-20 16:09:17,931 iteration 1200 : loss : 0.056428, loss_ce: 0.022347
2022-01-20 16:09:19,227 iteration 1201 : loss : 0.059511, loss_ce: 0.020429
2022-01-20 16:09:20,614 iteration 1202 : loss : 0.070176, loss_ce: 0.031166
2022-01-20 16:09:21,989 iteration 1203 : loss : 0.049958, loss_ce: 0.021455
2022-01-20 16:09:23,239 iteration 1204 : loss : 0.069727, loss_ce: 0.022118
2022-01-20 16:09:24,625 iteration 1205 : loss : 0.053750, loss_ce: 0.026317
2022-01-20 16:09:25,893 iteration 1206 : loss : 0.060536, loss_ce: 0.022397
2022-01-20 16:09:27,276 iteration 1207 : loss : 0.059515, loss_ce: 0.028307
 18%|█████▎                        | 71/400 [29:15<2:16:20, 24.86s/it]2022-01-20 16:09:28,633 iteration 1208 : loss : 0.054717, loss_ce: 0.023252
2022-01-20 16:09:29,945 iteration 1209 : loss : 0.048517, loss_ce: 0.017493
2022-01-20 16:09:31,174 iteration 1210 : loss : 0.036381, loss_ce: 0.014566
2022-01-20 16:09:32,557 iteration 1211 : loss : 0.057054, loss_ce: 0.027587
2022-01-20 16:09:33,848 iteration 1212 : loss : 0.046462, loss_ce: 0.019620
2022-01-20 16:09:35,058 iteration 1213 : loss : 0.035175, loss_ce: 0.012877
2022-01-20 16:09:36,464 iteration 1214 : loss : 0.065545, loss_ce: 0.028409
2022-01-20 16:09:37,762 iteration 1215 : loss : 0.045301, loss_ce: 0.019673
2022-01-20 16:09:39,055 iteration 1216 : loss : 0.045013, loss_ce: 0.018633
2022-01-20 16:09:40,488 iteration 1217 : loss : 0.063055, loss_ce: 0.025916
2022-01-20 16:09:41,716 iteration 1218 : loss : 0.046568, loss_ce: 0.020784
2022-01-20 16:09:43,184 iteration 1219 : loss : 0.058873, loss_ce: 0.027102
2022-01-20 16:09:44,469 iteration 1220 : loss : 0.050366, loss_ce: 0.019939
2022-01-20 16:09:45,843 iteration 1221 : loss : 0.051809, loss_ce: 0.017673
2022-01-20 16:09:47,106 iteration 1222 : loss : 0.055798, loss_ce: 0.020399
2022-01-20 16:09:48,379 iteration 1223 : loss : 0.054801, loss_ce: 0.020298
2022-01-20 16:09:49,680 iteration 1224 : loss : 0.105893, loss_ce: 0.044547
 18%|█████▍                        | 72/400 [29:38<2:11:53, 24.13s/it]2022-01-20 16:09:51,049 iteration 1225 : loss : 0.047774, loss_ce: 0.014080
2022-01-20 16:09:52,382 iteration 1226 : loss : 0.041253, loss_ce: 0.013264
2022-01-20 16:09:53,641 iteration 1227 : loss : 0.072419, loss_ce: 0.030141
2022-01-20 16:09:54,919 iteration 1228 : loss : 0.116810, loss_ce: 0.044703
2022-01-20 16:09:56,356 iteration 1229 : loss : 0.073971, loss_ce: 0.037162
2022-01-20 16:09:57,702 iteration 1230 : loss : 0.046584, loss_ce: 0.020934
2022-01-20 16:09:59,016 iteration 1231 : loss : 0.041403, loss_ce: 0.016999
2022-01-20 16:10:00,291 iteration 1232 : loss : 0.075332, loss_ce: 0.032785
2022-01-20 16:10:01,668 iteration 1233 : loss : 0.059237, loss_ce: 0.021932
2022-01-20 16:10:03,105 iteration 1234 : loss : 0.053475, loss_ce: 0.024801
2022-01-20 16:10:04,313 iteration 1235 : loss : 0.086607, loss_ce: 0.033564
2022-01-20 16:10:05,665 iteration 1236 : loss : 0.062778, loss_ce: 0.030072
2022-01-20 16:10:06,971 iteration 1237 : loss : 0.058017, loss_ce: 0.021412
2022-01-20 16:10:08,217 iteration 1238 : loss : 0.076336, loss_ce: 0.032764
2022-01-20 16:10:09,510 iteration 1239 : loss : 0.049315, loss_ce: 0.022024
2022-01-20 16:10:10,906 iteration 1240 : loss : 0.086598, loss_ce: 0.028320
2022-01-20 16:10:12,207 iteration 1241 : loss : 0.053428, loss_ce: 0.020242
 18%|█████▍                        | 73/400 [30:00<2:08:53, 23.65s/it]2022-01-20 16:10:13,625 iteration 1242 : loss : 0.062348, loss_ce: 0.036115
2022-01-20 16:10:14,945 iteration 1243 : loss : 0.050080, loss_ce: 0.017564
2022-01-20 16:10:16,371 iteration 1244 : loss : 0.070890, loss_ce: 0.024852
2022-01-20 16:10:17,768 iteration 1245 : loss : 0.046218, loss_ce: 0.017596
2022-01-20 16:10:19,084 iteration 1246 : loss : 0.054548, loss_ce: 0.023259
2022-01-20 16:10:20,592 iteration 1247 : loss : 0.068140, loss_ce: 0.024847
2022-01-20 16:10:21,881 iteration 1248 : loss : 0.055317, loss_ce: 0.022700
2022-01-20 16:10:23,197 iteration 1249 : loss : 0.058966, loss_ce: 0.024614
2022-01-20 16:10:24,527 iteration 1250 : loss : 0.130196, loss_ce: 0.034384
2022-01-20 16:10:25,914 iteration 1251 : loss : 0.051031, loss_ce: 0.024204
2022-01-20 16:10:27,162 iteration 1252 : loss : 0.068214, loss_ce: 0.022705
2022-01-20 16:10:28,469 iteration 1253 : loss : 0.050856, loss_ce: 0.024075
2022-01-20 16:10:29,790 iteration 1254 : loss : 0.052461, loss_ce: 0.017311
2022-01-20 16:10:31,234 iteration 1255 : loss : 0.068360, loss_ce: 0.026389
2022-01-20 16:10:32,532 iteration 1256 : loss : 0.040835, loss_ce: 0.013460
2022-01-20 16:10:33,745 iteration 1257 : loss : 0.043295, loss_ce: 0.015339
2022-01-20 16:10:34,983 iteration 1258 : loss : 0.049397, loss_ce: 0.021899
 18%|█████▌                        | 74/400 [30:23<2:07:03, 23.39s/it]2022-01-20 16:10:36,354 iteration 1259 : loss : 0.056123, loss_ce: 0.019928
2022-01-20 16:10:37,808 iteration 1260 : loss : 0.054705, loss_ce: 0.022783
2022-01-20 16:10:39,121 iteration 1261 : loss : 0.047190, loss_ce: 0.016278
2022-01-20 16:10:40,383 iteration 1262 : loss : 0.044831, loss_ce: 0.014614
2022-01-20 16:10:41,711 iteration 1263 : loss : 0.047575, loss_ce: 0.019279
2022-01-20 16:10:43,067 iteration 1264 : loss : 0.043030, loss_ce: 0.018047
2022-01-20 16:10:44,398 iteration 1265 : loss : 0.058371, loss_ce: 0.025702
2022-01-20 16:10:45,691 iteration 1266 : loss : 0.036616, loss_ce: 0.015213
2022-01-20 16:10:46,975 iteration 1267 : loss : 0.074386, loss_ce: 0.034537
2022-01-20 16:10:48,261 iteration 1268 : loss : 0.047055, loss_ce: 0.017124
2022-01-20 16:10:49,569 iteration 1269 : loss : 0.054622, loss_ce: 0.026000
2022-01-20 16:10:50,906 iteration 1270 : loss : 0.033791, loss_ce: 0.014588
2022-01-20 16:10:52,308 iteration 1271 : loss : 0.095345, loss_ce: 0.048279
2022-01-20 16:10:53,518 iteration 1272 : loss : 0.038363, loss_ce: 0.012321
2022-01-20 16:10:54,799 iteration 1273 : loss : 0.057820, loss_ce: 0.017766
2022-01-20 16:10:56,161 iteration 1274 : loss : 0.061717, loss_ce: 0.028311
2022-01-20 16:10:56,161 Training Data Eval:
2022-01-20 16:11:02,738   Average segmentation loss on training set: 0.0420
2022-01-20 16:11:02,738 Validation Data Eval:
2022-01-20 16:11:04,980   Average segmentation loss on validation set: 0.1030
2022-01-20 16:11:06,265 iteration 1275 : loss : 0.058238, loss_ce: 0.022397
 19%|█████▋                        | 75/400 [30:54<2:19:31, 25.76s/it]2022-01-20 16:11:07,613 iteration 1276 : loss : 0.045832, loss_ce: 0.019536
2022-01-20 16:11:09,044 iteration 1277 : loss : 0.077427, loss_ce: 0.027586
2022-01-20 16:11:10,336 iteration 1278 : loss : 0.083952, loss_ce: 0.034076
2022-01-20 16:11:11,623 iteration 1279 : loss : 0.050631, loss_ce: 0.017286
2022-01-20 16:11:12,963 iteration 1280 : loss : 0.041540, loss_ce: 0.017624
2022-01-20 16:11:14,232 iteration 1281 : loss : 0.060193, loss_ce: 0.024452
2022-01-20 16:11:15,549 iteration 1282 : loss : 0.039537, loss_ce: 0.015841
2022-01-20 16:11:16,793 iteration 1283 : loss : 0.066096, loss_ce: 0.020152
2022-01-20 16:11:18,100 iteration 1284 : loss : 0.041343, loss_ce: 0.015033
2022-01-20 16:11:19,338 iteration 1285 : loss : 0.044476, loss_ce: 0.014119
2022-01-20 16:11:20,717 iteration 1286 : loss : 0.082456, loss_ce: 0.025957
2022-01-20 16:11:22,069 iteration 1287 : loss : 0.042692, loss_ce: 0.017618
2022-01-20 16:11:23,333 iteration 1288 : loss : 0.055148, loss_ce: 0.020341
2022-01-20 16:11:24,637 iteration 1289 : loss : 0.075087, loss_ce: 0.028429
2022-01-20 16:11:25,896 iteration 1290 : loss : 0.106182, loss_ce: 0.030870
2022-01-20 16:11:27,160 iteration 1291 : loss : 0.059352, loss_ce: 0.022403
2022-01-20 16:11:28,431 iteration 1292 : loss : 0.060803, loss_ce: 0.032606
 19%|█████▋                        | 76/400 [31:16<2:13:15, 24.68s/it]2022-01-20 16:11:29,906 iteration 1293 : loss : 0.064405, loss_ce: 0.030669
2022-01-20 16:11:31,117 iteration 1294 : loss : 0.045021, loss_ce: 0.019123
2022-01-20 16:11:32,477 iteration 1295 : loss : 0.073415, loss_ce: 0.025704
2022-01-20 16:11:33,804 iteration 1296 : loss : 0.079284, loss_ce: 0.021903
2022-01-20 16:11:34,994 iteration 1297 : loss : 0.039036, loss_ce: 0.015965
2022-01-20 16:11:36,382 iteration 1298 : loss : 0.063308, loss_ce: 0.024329
2022-01-20 16:11:37,663 iteration 1299 : loss : 0.044692, loss_ce: 0.018417
2022-01-20 16:11:39,057 iteration 1300 : loss : 0.100382, loss_ce: 0.032493
2022-01-20 16:11:40,456 iteration 1301 : loss : 0.085515, loss_ce: 0.025493
2022-01-20 16:11:41,676 iteration 1302 : loss : 0.061429, loss_ce: 0.022829
2022-01-20 16:11:43,023 iteration 1303 : loss : 0.064754, loss_ce: 0.022875
2022-01-20 16:11:44,343 iteration 1304 : loss : 0.048137, loss_ce: 0.020864
2022-01-20 16:11:45,746 iteration 1305 : loss : 0.055753, loss_ce: 0.020133
2022-01-20 16:11:47,067 iteration 1306 : loss : 0.047318, loss_ce: 0.021493
2022-01-20 16:11:48,328 iteration 1307 : loss : 0.057854, loss_ce: 0.020589
2022-01-20 16:11:49,642 iteration 1308 : loss : 0.066478, loss_ce: 0.030012
2022-01-20 16:11:50,920 iteration 1309 : loss : 0.048757, loss_ce: 0.019271
 19%|█████▊                        | 77/400 [31:39<2:09:19, 24.02s/it]2022-01-20 16:11:52,282 iteration 1310 : loss : 0.061321, loss_ce: 0.022645
2022-01-20 16:11:53,704 iteration 1311 : loss : 0.073563, loss_ce: 0.024348
2022-01-20 16:11:55,007 iteration 1312 : loss : 0.054938, loss_ce: 0.016541
2022-01-20 16:11:56,297 iteration 1313 : loss : 0.047001, loss_ce: 0.017168
2022-01-20 16:11:57,672 iteration 1314 : loss : 0.059266, loss_ce: 0.027479
2022-01-20 16:11:59,067 iteration 1315 : loss : 0.054252, loss_ce: 0.029365
2022-01-20 16:12:00,350 iteration 1316 : loss : 0.057762, loss_ce: 0.025531
2022-01-20 16:12:01,613 iteration 1317 : loss : 0.041929, loss_ce: 0.016714
2022-01-20 16:12:02,884 iteration 1318 : loss : 0.045854, loss_ce: 0.017326
2022-01-20 16:12:04,241 iteration 1319 : loss : 0.047122, loss_ce: 0.016462
2022-01-20 16:12:05,489 iteration 1320 : loss : 0.051081, loss_ce: 0.019458
2022-01-20 16:12:06,821 iteration 1321 : loss : 0.064907, loss_ce: 0.030781
2022-01-20 16:12:08,115 iteration 1322 : loss : 0.046741, loss_ce: 0.017126
2022-01-20 16:12:09,496 iteration 1323 : loss : 0.045608, loss_ce: 0.014518
2022-01-20 16:12:10,887 iteration 1324 : loss : 0.065672, loss_ce: 0.029418
2022-01-20 16:12:12,181 iteration 1325 : loss : 0.047873, loss_ce: 0.020529
2022-01-20 16:12:13,499 iteration 1326 : loss : 0.051196, loss_ce: 0.019737
 20%|█████▊                        | 78/400 [32:02<2:06:35, 23.59s/it]2022-01-20 16:12:14,853 iteration 1327 : loss : 0.037950, loss_ce: 0.014141
2022-01-20 16:12:16,179 iteration 1328 : loss : 0.038432, loss_ce: 0.015825
2022-01-20 16:12:17,495 iteration 1329 : loss : 0.072054, loss_ce: 0.029331
2022-01-20 16:12:18,888 iteration 1330 : loss : 0.066054, loss_ce: 0.021519
2022-01-20 16:12:20,193 iteration 1331 : loss : 0.052384, loss_ce: 0.021532
2022-01-20 16:12:21,475 iteration 1332 : loss : 0.067519, loss_ce: 0.024242
2022-01-20 16:12:22,764 iteration 1333 : loss : 0.044694, loss_ce: 0.018775
2022-01-20 16:12:24,124 iteration 1334 : loss : 0.032559, loss_ce: 0.012848
2022-01-20 16:12:25,470 iteration 1335 : loss : 0.046015, loss_ce: 0.018366
2022-01-20 16:12:26,739 iteration 1336 : loss : 0.048510, loss_ce: 0.021354
2022-01-20 16:12:28,140 iteration 1337 : loss : 0.087344, loss_ce: 0.030958
2022-01-20 16:12:29,458 iteration 1338 : loss : 0.037561, loss_ce: 0.016471
2022-01-20 16:12:30,768 iteration 1339 : loss : 0.054869, loss_ce: 0.021277
2022-01-20 16:12:32,067 iteration 1340 : loss : 0.038541, loss_ce: 0.016279
2022-01-20 16:12:33,448 iteration 1341 : loss : 0.057583, loss_ce: 0.021540
2022-01-20 16:12:34,885 iteration 1342 : loss : 0.061636, loss_ce: 0.021245
2022-01-20 16:12:36,141 iteration 1343 : loss : 0.046827, loss_ce: 0.016148
 20%|█████▉                        | 79/400 [32:24<2:04:39, 23.30s/it]2022-01-20 16:12:37,594 iteration 1344 : loss : 0.043440, loss_ce: 0.015290
2022-01-20 16:12:38,919 iteration 1345 : loss : 0.053827, loss_ce: 0.014860
2022-01-20 16:12:40,321 iteration 1346 : loss : 0.057555, loss_ce: 0.020943
2022-01-20 16:12:41,660 iteration 1347 : loss : 0.047552, loss_ce: 0.020645
2022-01-20 16:12:42,956 iteration 1348 : loss : 0.057187, loss_ce: 0.025828
2022-01-20 16:12:44,303 iteration 1349 : loss : 0.061764, loss_ce: 0.024942
2022-01-20 16:12:45,625 iteration 1350 : loss : 0.050996, loss_ce: 0.015342
2022-01-20 16:12:47,047 iteration 1351 : loss : 0.072669, loss_ce: 0.028376
2022-01-20 16:12:48,317 iteration 1352 : loss : 0.057933, loss_ce: 0.024882
2022-01-20 16:12:49,646 iteration 1353 : loss : 0.036733, loss_ce: 0.015587
2022-01-20 16:12:50,976 iteration 1354 : loss : 0.049476, loss_ce: 0.018736
2022-01-20 16:12:52,225 iteration 1355 : loss : 0.057118, loss_ce: 0.019752
2022-01-20 16:12:53,641 iteration 1356 : loss : 0.062614, loss_ce: 0.024835
2022-01-20 16:12:54,894 iteration 1357 : loss : 0.043677, loss_ce: 0.021313
2022-01-20 16:12:56,191 iteration 1358 : loss : 0.054089, loss_ce: 0.028604
2022-01-20 16:12:57,610 iteration 1359 : loss : 0.060833, loss_ce: 0.033830
2022-01-20 16:12:57,611 Training Data Eval:
2022-01-20 16:13:04,267   Average segmentation loss on training set: 0.0566
2022-01-20 16:13:04,268 Validation Data Eval:
2022-01-20 16:13:06,514   Average segmentation loss on validation set: 0.0896
2022-01-20 16:13:07,864 iteration 1360 : loss : 0.043920, loss_ce: 0.016731
 20%|██████                        | 80/400 [32:56<2:17:45, 25.83s/it]2022-01-20 16:13:09,299 iteration 1361 : loss : 0.059943, loss_ce: 0.020315
2022-01-20 16:13:10,594 iteration 1362 : loss : 0.051949, loss_ce: 0.016023
2022-01-20 16:13:11,927 iteration 1363 : loss : 0.042822, loss_ce: 0.019554
2022-01-20 16:13:13,161 iteration 1364 : loss : 0.053096, loss_ce: 0.025047
2022-01-20 16:13:14,446 iteration 1365 : loss : 0.047741, loss_ce: 0.015080
2022-01-20 16:13:15,853 iteration 1366 : loss : 0.056743, loss_ce: 0.021844
2022-01-20 16:13:17,173 iteration 1367 : loss : 0.053033, loss_ce: 0.028356
2022-01-20 16:13:18,668 iteration 1368 : loss : 0.058040, loss_ce: 0.021308
2022-01-20 16:13:19,954 iteration 1369 : loss : 0.043862, loss_ce: 0.016339
2022-01-20 16:13:21,213 iteration 1370 : loss : 0.046267, loss_ce: 0.021876
2022-01-20 16:13:22,522 iteration 1371 : loss : 0.045197, loss_ce: 0.016226
2022-01-20 16:13:23,996 iteration 1372 : loss : 0.059882, loss_ce: 0.021702
2022-01-20 16:13:25,283 iteration 1373 : loss : 0.048759, loss_ce: 0.020958
2022-01-20 16:13:26,536 iteration 1374 : loss : 0.042383, loss_ce: 0.015145
2022-01-20 16:13:27,823 iteration 1375 : loss : 0.048508, loss_ce: 0.019673
2022-01-20 16:13:29,134 iteration 1376 : loss : 0.037601, loss_ce: 0.011649
2022-01-20 16:13:30,546 iteration 1377 : loss : 0.054912, loss_ce: 0.029162
 20%|██████                        | 81/400 [33:19<2:12:18, 24.89s/it]2022-01-20 16:13:32,014 iteration 1378 : loss : 0.058151, loss_ce: 0.027592
2022-01-20 16:13:33,364 iteration 1379 : loss : 0.051380, loss_ce: 0.022367
2022-01-20 16:13:34,666 iteration 1380 : loss : 0.077570, loss_ce: 0.026239
2022-01-20 16:13:36,035 iteration 1381 : loss : 0.033052, loss_ce: 0.013241
2022-01-20 16:13:37,369 iteration 1382 : loss : 0.064613, loss_ce: 0.028011
2022-01-20 16:13:38,623 iteration 1383 : loss : 0.085911, loss_ce: 0.026623
2022-01-20 16:13:39,977 iteration 1384 : loss : 0.063749, loss_ce: 0.026301
2022-01-20 16:13:41,319 iteration 1385 : loss : 0.032536, loss_ce: 0.013311
2022-01-20 16:13:42,619 iteration 1386 : loss : 0.066349, loss_ce: 0.027638
2022-01-20 16:13:44,065 iteration 1387 : loss : 0.065517, loss_ce: 0.020991
2022-01-20 16:13:45,363 iteration 1388 : loss : 0.046036, loss_ce: 0.017335
2022-01-20 16:13:46,677 iteration 1389 : loss : 0.043740, loss_ce: 0.016510
2022-01-20 16:13:48,048 iteration 1390 : loss : 0.047905, loss_ce: 0.019767
2022-01-20 16:13:49,440 iteration 1391 : loss : 0.048874, loss_ce: 0.012207
2022-01-20 16:13:50,804 iteration 1392 : loss : 0.056393, loss_ce: 0.017015
2022-01-20 16:13:52,139 iteration 1393 : loss : 0.037259, loss_ce: 0.011320
2022-01-20 16:13:53,463 iteration 1394 : loss : 0.041180, loss_ce: 0.019609
 20%|██████▏                       | 82/400 [33:42<2:08:46, 24.30s/it]2022-01-20 16:13:54,891 iteration 1395 : loss : 0.037260, loss_ce: 0.014435
2022-01-20 16:13:56,173 iteration 1396 : loss : 0.040854, loss_ce: 0.016444
2022-01-20 16:13:57,518 iteration 1397 : loss : 0.057603, loss_ce: 0.019329
2022-01-20 16:13:58,949 iteration 1398 : loss : 0.032406, loss_ce: 0.014587
2022-01-20 16:14:00,317 iteration 1399 : loss : 0.054076, loss_ce: 0.025370
2022-01-20 16:14:01,618 iteration 1400 : loss : 0.058804, loss_ce: 0.028910
2022-01-20 16:14:02,931 iteration 1401 : loss : 0.054635, loss_ce: 0.019261
2022-01-20 16:14:04,178 iteration 1402 : loss : 0.038274, loss_ce: 0.016082
2022-01-20 16:14:05,645 iteration 1403 : loss : 0.056566, loss_ce: 0.021679
2022-01-20 16:14:07,018 iteration 1404 : loss : 0.053053, loss_ce: 0.020056
2022-01-20 16:14:08,379 iteration 1405 : loss : 0.044025, loss_ce: 0.020520
2022-01-20 16:14:09,710 iteration 1406 : loss : 0.046604, loss_ce: 0.016942
2022-01-20 16:14:10,981 iteration 1407 : loss : 0.047030, loss_ce: 0.024846
2022-01-20 16:14:12,292 iteration 1408 : loss : 0.050063, loss_ce: 0.014629
2022-01-20 16:14:13,728 iteration 1409 : loss : 0.052687, loss_ce: 0.016062
2022-01-20 16:14:15,091 iteration 1410 : loss : 0.067123, loss_ce: 0.027779
2022-01-20 16:14:16,405 iteration 1411 : loss : 0.046031, loss_ce: 0.021336
 21%|██████▏                       | 83/400 [34:04<2:06:11, 23.89s/it]2022-01-20 16:14:17,698 iteration 1412 : loss : 0.070484, loss_ce: 0.021251
2022-01-20 16:14:19,083 iteration 1413 : loss : 0.058114, loss_ce: 0.021372
2022-01-20 16:14:20,402 iteration 1414 : loss : 0.039027, loss_ce: 0.018414
2022-01-20 16:14:21,648 iteration 1415 : loss : 0.036585, loss_ce: 0.013052
2022-01-20 16:14:22,975 iteration 1416 : loss : 0.037043, loss_ce: 0.012955
2022-01-20 16:14:24,342 iteration 1417 : loss : 0.069369, loss_ce: 0.029632
2022-01-20 16:14:25,584 iteration 1418 : loss : 0.033214, loss_ce: 0.010649
2022-01-20 16:14:27,045 iteration 1419 : loss : 0.050928, loss_ce: 0.019391
2022-01-20 16:14:28,418 iteration 1420 : loss : 0.054489, loss_ce: 0.016085
2022-01-20 16:14:29,694 iteration 1421 : loss : 0.041234, loss_ce: 0.017612
2022-01-20 16:14:31,005 iteration 1422 : loss : 0.038930, loss_ce: 0.014332
2022-01-20 16:14:32,270 iteration 1423 : loss : 0.065039, loss_ce: 0.028777
2022-01-20 16:14:33,631 iteration 1424 : loss : 0.046117, loss_ce: 0.016892
2022-01-20 16:14:35,027 iteration 1425 : loss : 0.062188, loss_ce: 0.027342
2022-01-20 16:14:36,208 iteration 1426 : loss : 0.043339, loss_ce: 0.016562
2022-01-20 16:14:37,508 iteration 1427 : loss : 0.042064, loss_ce: 0.017853
2022-01-20 16:14:38,840 iteration 1428 : loss : 0.057484, loss_ce: 0.026345
 21%|██████▎                       | 84/400 [34:27<2:03:30, 23.45s/it]2022-01-20 16:14:40,319 iteration 1429 : loss : 0.068989, loss_ce: 0.030504
2022-01-20 16:14:41,574 iteration 1430 : loss : 0.049337, loss_ce: 0.016168
2022-01-20 16:14:42,863 iteration 1431 : loss : 0.057260, loss_ce: 0.025878
2022-01-20 16:14:44,187 iteration 1432 : loss : 0.046640, loss_ce: 0.018553
2022-01-20 16:14:45,608 iteration 1433 : loss : 0.055739, loss_ce: 0.021533
2022-01-20 16:14:47,003 iteration 1434 : loss : 0.047791, loss_ce: 0.018691
2022-01-20 16:14:48,213 iteration 1435 : loss : 0.044972, loss_ce: 0.012755
2022-01-20 16:14:49,614 iteration 1436 : loss : 0.063044, loss_ce: 0.031681
2022-01-20 16:14:50,860 iteration 1437 : loss : 0.071983, loss_ce: 0.016504
2022-01-20 16:14:52,083 iteration 1438 : loss : 0.040783, loss_ce: 0.018560
2022-01-20 16:14:53,405 iteration 1439 : loss : 0.038279, loss_ce: 0.011877
2022-01-20 16:14:54,812 iteration 1440 : loss : 0.047179, loss_ce: 0.018993
2022-01-20 16:14:56,097 iteration 1441 : loss : 0.030645, loss_ce: 0.013136
2022-01-20 16:14:57,358 iteration 1442 : loss : 0.046192, loss_ce: 0.016642
2022-01-20 16:14:58,716 iteration 1443 : loss : 0.059230, loss_ce: 0.027254
2022-01-20 16:15:00,093 iteration 1444 : loss : 0.029757, loss_ce: 0.014897
2022-01-20 16:15:00,093 Training Data Eval:
2022-01-20 16:15:06,611   Average segmentation loss on training set: 0.0394
2022-01-20 16:15:06,611 Validation Data Eval:
2022-01-20 16:15:08,821   Average segmentation loss on validation set: 0.0905
2022-01-20 16:15:10,183 iteration 1445 : loss : 0.046077, loss_ce: 0.016096
 21%|██████▍                       | 85/400 [34:58<2:15:33, 25.82s/it]2022-01-20 16:15:11,619 iteration 1446 : loss : 0.056263, loss_ce: 0.025595
2022-01-20 16:15:12,978 iteration 1447 : loss : 0.067511, loss_ce: 0.024439
2022-01-20 16:15:14,258 iteration 1448 : loss : 0.042248, loss_ce: 0.021923
2022-01-20 16:15:15,571 iteration 1449 : loss : 0.060390, loss_ce: 0.021772
2022-01-20 16:15:16,788 iteration 1450 : loss : 0.047969, loss_ce: 0.019579
2022-01-20 16:15:18,056 iteration 1451 : loss : 0.043063, loss_ce: 0.013867
2022-01-20 16:15:19,386 iteration 1452 : loss : 0.077229, loss_ce: 0.019688
2022-01-20 16:15:20,759 iteration 1453 : loss : 0.028374, loss_ce: 0.008985
2022-01-20 16:15:22,017 iteration 1454 : loss : 0.046745, loss_ce: 0.019370
2022-01-20 16:15:23,297 iteration 1455 : loss : 0.042581, loss_ce: 0.018564
2022-01-20 16:15:24,624 iteration 1456 : loss : 0.054899, loss_ce: 0.018138
2022-01-20 16:15:25,950 iteration 1457 : loss : 0.039256, loss_ce: 0.018668
2022-01-20 16:15:27,242 iteration 1458 : loss : 0.037888, loss_ce: 0.013033
2022-01-20 16:15:28,452 iteration 1459 : loss : 0.036440, loss_ce: 0.014744
2022-01-20 16:15:29,825 iteration 1460 : loss : 0.072642, loss_ce: 0.037851
2022-01-20 16:15:31,126 iteration 1461 : loss : 0.046619, loss_ce: 0.015367
2022-01-20 16:15:32,429 iteration 1462 : loss : 0.040527, loss_ce: 0.016880
 22%|██████▍                       | 86/400 [35:20<2:09:30, 24.75s/it]2022-01-20 16:15:33,778 iteration 1463 : loss : 0.044840, loss_ce: 0.021126
2022-01-20 16:15:35,115 iteration 1464 : loss : 0.050691, loss_ce: 0.015735
2022-01-20 16:15:36,481 iteration 1465 : loss : 0.058961, loss_ce: 0.027729
2022-01-20 16:15:37,783 iteration 1466 : loss : 0.041363, loss_ce: 0.015350
2022-01-20 16:15:39,077 iteration 1467 : loss : 0.049909, loss_ce: 0.019315
2022-01-20 16:15:40,416 iteration 1468 : loss : 0.039438, loss_ce: 0.014759
2022-01-20 16:15:41,757 iteration 1469 : loss : 0.028842, loss_ce: 0.012891
2022-01-20 16:15:43,079 iteration 1470 : loss : 0.041487, loss_ce: 0.015464
2022-01-20 16:15:44,310 iteration 1471 : loss : 0.035861, loss_ce: 0.012190
2022-01-20 16:15:45,606 iteration 1472 : loss : 0.045509, loss_ce: 0.016323
2022-01-20 16:15:46,986 iteration 1473 : loss : 0.048640, loss_ce: 0.027812
2022-01-20 16:15:48,217 iteration 1474 : loss : 0.045259, loss_ce: 0.017788
2022-01-20 16:15:49,505 iteration 1475 : loss : 0.048866, loss_ce: 0.015066
2022-01-20 16:15:50,871 iteration 1476 : loss : 0.060118, loss_ce: 0.032856
2022-01-20 16:15:52,172 iteration 1477 : loss : 0.040923, loss_ce: 0.012679
2022-01-20 16:15:53,544 iteration 1478 : loss : 0.051024, loss_ce: 0.019188
2022-01-20 16:15:54,871 iteration 1479 : loss : 0.064320, loss_ce: 0.023822
 22%|██████▌                       | 87/400 [35:43<2:05:29, 24.06s/it]2022-01-20 16:15:56,243 iteration 1480 : loss : 0.046340, loss_ce: 0.025650
2022-01-20 16:15:57,627 iteration 1481 : loss : 0.038842, loss_ce: 0.016226
2022-01-20 16:15:58,895 iteration 1482 : loss : 0.039810, loss_ce: 0.017803
2022-01-20 16:16:00,125 iteration 1483 : loss : 0.035650, loss_ce: 0.014816
2022-01-20 16:16:01,379 iteration 1484 : loss : 0.041603, loss_ce: 0.018060
2022-01-20 16:16:02,667 iteration 1485 : loss : 0.054246, loss_ce: 0.022917
2022-01-20 16:16:03,987 iteration 1486 : loss : 0.055232, loss_ce: 0.018668
2022-01-20 16:16:05,396 iteration 1487 : loss : 0.046980, loss_ce: 0.017685
2022-01-20 16:16:06,714 iteration 1488 : loss : 0.039076, loss_ce: 0.014318
2022-01-20 16:16:08,082 iteration 1489 : loss : 0.027492, loss_ce: 0.010234
2022-01-20 16:16:09,431 iteration 1490 : loss : 0.029084, loss_ce: 0.012758
2022-01-20 16:16:10,718 iteration 1491 : loss : 0.041873, loss_ce: 0.014469
2022-01-20 16:16:12,106 iteration 1492 : loss : 0.042476, loss_ce: 0.016736
2022-01-20 16:16:13,574 iteration 1493 : loss : 0.087896, loss_ce: 0.054984
2022-01-20 16:16:14,965 iteration 1494 : loss : 0.066400, loss_ce: 0.020075
2022-01-20 16:16:16,324 iteration 1495 : loss : 0.050962, loss_ce: 0.016345
2022-01-20 16:16:17,681 iteration 1496 : loss : 0.040689, loss_ce: 0.016188
 22%|██████▌                       | 88/400 [36:06<2:03:09, 23.68s/it]2022-01-20 16:16:19,089 iteration 1497 : loss : 0.034708, loss_ce: 0.014849
2022-01-20 16:16:20,329 iteration 1498 : loss : 0.027874, loss_ce: 0.011414
2022-01-20 16:16:21,615 iteration 1499 : loss : 0.038293, loss_ce: 0.016577
2022-01-20 16:16:23,109 iteration 1500 : loss : 0.062629, loss_ce: 0.022623
2022-01-20 16:16:24,352 iteration 1501 : loss : 0.030172, loss_ce: 0.010303
2022-01-20 16:16:25,696 iteration 1502 : loss : 0.062502, loss_ce: 0.021849
2022-01-20 16:16:27,110 iteration 1503 : loss : 0.054575, loss_ce: 0.019352
2022-01-20 16:16:28,415 iteration 1504 : loss : 0.045008, loss_ce: 0.018687
2022-01-20 16:16:29,703 iteration 1505 : loss : 0.037372, loss_ce: 0.014943
2022-01-20 16:16:31,089 iteration 1506 : loss : 0.046930, loss_ce: 0.015970
2022-01-20 16:16:32,380 iteration 1507 : loss : 0.036262, loss_ce: 0.017488
2022-01-20 16:16:33,729 iteration 1508 : loss : 0.156497, loss_ce: 0.041263
2022-01-20 16:16:35,033 iteration 1509 : loss : 0.051071, loss_ce: 0.021507
2022-01-20 16:16:36,323 iteration 1510 : loss : 0.056556, loss_ce: 0.018182
2022-01-20 16:16:37,738 iteration 1511 : loss : 0.061846, loss_ce: 0.035756
2022-01-20 16:16:39,044 iteration 1512 : loss : 0.047365, loss_ce: 0.017671
2022-01-20 16:16:40,360 iteration 1513 : loss : 0.047256, loss_ce: 0.018166
 22%|██████▋                       | 89/400 [36:28<2:01:12, 23.38s/it]2022-01-20 16:16:41,796 iteration 1514 : loss : 0.076068, loss_ce: 0.034675
2022-01-20 16:16:43,112 iteration 1515 : loss : 0.048822, loss_ce: 0.020387
2022-01-20 16:16:44,460 iteration 1516 : loss : 0.069723, loss_ce: 0.036778
2022-01-20 16:16:45,733 iteration 1517 : loss : 0.046604, loss_ce: 0.020597
2022-01-20 16:16:46,970 iteration 1518 : loss : 0.036845, loss_ce: 0.015971
2022-01-20 16:16:48,265 iteration 1519 : loss : 0.039034, loss_ce: 0.015312
2022-01-20 16:16:49,746 iteration 1520 : loss : 0.058323, loss_ce: 0.024719
2022-01-20 16:16:51,016 iteration 1521 : loss : 0.041542, loss_ce: 0.014800
2022-01-20 16:16:52,398 iteration 1522 : loss : 0.056135, loss_ce: 0.017040
2022-01-20 16:16:53,720 iteration 1523 : loss : 0.041272, loss_ce: 0.016870
2022-01-20 16:16:54,965 iteration 1524 : loss : 0.034340, loss_ce: 0.012535
2022-01-20 16:16:56,250 iteration 1525 : loss : 0.041153, loss_ce: 0.017376
2022-01-20 16:16:57,537 iteration 1526 : loss : 0.038832, loss_ce: 0.013986
2022-01-20 16:16:58,935 iteration 1527 : loss : 0.043963, loss_ce: 0.017211
2022-01-20 16:17:00,281 iteration 1528 : loss : 0.041587, loss_ce: 0.016047
2022-01-20 16:17:01,571 iteration 1529 : loss : 0.045411, loss_ce: 0.012479
2022-01-20 16:17:01,572 Training Data Eval:
2022-01-20 16:17:08,171   Average segmentation loss on training set: 0.0373
2022-01-20 16:17:08,172 Validation Data Eval:
2022-01-20 16:17:10,442   Average segmentation loss on validation set: 0.1022
2022-01-20 16:17:11,751 iteration 1530 : loss : 0.047796, loss_ce: 0.022476
 22%|██████▊                       | 90/400 [37:00<2:13:13, 25.79s/it]2022-01-20 16:17:13,191 iteration 1531 : loss : 0.054549, loss_ce: 0.023576
2022-01-20 16:17:14,558 iteration 1532 : loss : 0.057828, loss_ce: 0.019064
2022-01-20 16:17:15,825 iteration 1533 : loss : 0.037624, loss_ce: 0.012869
2022-01-20 16:17:17,118 iteration 1534 : loss : 0.034199, loss_ce: 0.016108
2022-01-20 16:17:18,383 iteration 1535 : loss : 0.043321, loss_ce: 0.019794
2022-01-20 16:17:19,718 iteration 1536 : loss : 0.042119, loss_ce: 0.011419
2022-01-20 16:17:21,000 iteration 1537 : loss : 0.044613, loss_ce: 0.026375
2022-01-20 16:17:22,193 iteration 1538 : loss : 0.070848, loss_ce: 0.017693
2022-01-20 16:17:23,476 iteration 1539 : loss : 0.042071, loss_ce: 0.018780
2022-01-20 16:17:24,804 iteration 1540 : loss : 0.038801, loss_ce: 0.017720
2022-01-20 16:17:26,176 iteration 1541 : loss : 0.044403, loss_ce: 0.018244
2022-01-20 16:17:27,605 iteration 1542 : loss : 0.044498, loss_ce: 0.018472
2022-01-20 16:17:28,928 iteration 1543 : loss : 0.053666, loss_ce: 0.013995
2022-01-20 16:17:30,274 iteration 1544 : loss : 0.038650, loss_ce: 0.017582
2022-01-20 16:17:31,536 iteration 1545 : loss : 0.055949, loss_ce: 0.019368
2022-01-20 16:17:32,855 iteration 1546 : loss : 0.050168, loss_ce: 0.018333
2022-01-20 16:17:34,214 iteration 1547 : loss : 0.033044, loss_ce: 0.013955
 23%|██████▊                       | 91/400 [37:22<2:07:40, 24.79s/it]2022-01-20 16:17:35,609 iteration 1548 : loss : 0.048902, loss_ce: 0.014431
2022-01-20 16:17:36,855 iteration 1549 : loss : 0.048425, loss_ce: 0.017137
2022-01-20 16:17:38,228 iteration 1550 : loss : 0.046219, loss_ce: 0.012364
2022-01-20 16:17:39,561 iteration 1551 : loss : 0.069055, loss_ce: 0.023312
2022-01-20 16:17:40,855 iteration 1552 : loss : 0.046788, loss_ce: 0.012221
2022-01-20 16:17:42,211 iteration 1553 : loss : 0.046224, loss_ce: 0.021421
2022-01-20 16:17:43,435 iteration 1554 : loss : 0.048962, loss_ce: 0.026035
2022-01-20 16:17:44,721 iteration 1555 : loss : 0.036020, loss_ce: 0.012834
2022-01-20 16:17:46,141 iteration 1556 : loss : 0.054084, loss_ce: 0.023725
2022-01-20 16:17:47,448 iteration 1557 : loss : 0.042198, loss_ce: 0.012329
2022-01-20 16:17:48,683 iteration 1558 : loss : 0.043175, loss_ce: 0.015052
2022-01-20 16:17:50,088 iteration 1559 : loss : 0.055077, loss_ce: 0.021588
2022-01-20 16:17:51,359 iteration 1560 : loss : 0.038551, loss_ce: 0.019698
2022-01-20 16:17:52,673 iteration 1561 : loss : 0.033131, loss_ce: 0.012736
2022-01-20 16:17:53,977 iteration 1562 : loss : 0.045249, loss_ce: 0.022404
2022-01-20 16:17:55,309 iteration 1563 : loss : 0.063269, loss_ce: 0.028784
2022-01-20 16:17:56,583 iteration 1564 : loss : 0.050063, loss_ce: 0.017297
 23%|██████▉                       | 92/400 [37:45<2:03:31, 24.06s/it]2022-01-20 16:17:57,902 iteration 1565 : loss : 0.030852, loss_ce: 0.014801
2022-01-20 16:17:59,253 iteration 1566 : loss : 0.062744, loss_ce: 0.017318
2022-01-20 16:18:00,570 iteration 1567 : loss : 0.038912, loss_ce: 0.016489
2022-01-20 16:18:01,995 iteration 1568 : loss : 0.046155, loss_ce: 0.015845
2022-01-20 16:18:03,297 iteration 1569 : loss : 0.041620, loss_ce: 0.019154
2022-01-20 16:18:04,614 iteration 1570 : loss : 0.036713, loss_ce: 0.012736
2022-01-20 16:18:05,915 iteration 1571 : loss : 0.050483, loss_ce: 0.016176
2022-01-20 16:18:07,319 iteration 1572 : loss : 0.061656, loss_ce: 0.023294
2022-01-20 16:18:08,530 iteration 1573 : loss : 0.038627, loss_ce: 0.017746
2022-01-20 16:18:09,879 iteration 1574 : loss : 0.049279, loss_ce: 0.020340
2022-01-20 16:18:11,266 iteration 1575 : loss : 0.044270, loss_ce: 0.018234
2022-01-20 16:18:12,642 iteration 1576 : loss : 0.036483, loss_ce: 0.017058
2022-01-20 16:18:13,851 iteration 1577 : loss : 0.034079, loss_ce: 0.011582
2022-01-20 16:18:15,126 iteration 1578 : loss : 0.039134, loss_ce: 0.013115
2022-01-20 16:18:16,498 iteration 1579 : loss : 0.057207, loss_ce: 0.018735
2022-01-20 16:18:17,837 iteration 1580 : loss : 0.065502, loss_ce: 0.023558
2022-01-20 16:18:19,290 iteration 1581 : loss : 0.055849, loss_ce: 0.023750
 23%|██████▉                       | 93/400 [38:07<2:01:02, 23.66s/it]2022-01-20 16:18:20,684 iteration 1582 : loss : 0.036231, loss_ce: 0.013280
2022-01-20 16:18:22,013 iteration 1583 : loss : 0.041343, loss_ce: 0.016523
2022-01-20 16:18:23,241 iteration 1584 : loss : 0.047535, loss_ce: 0.014346
2022-01-20 16:18:24,564 iteration 1585 : loss : 0.070168, loss_ce: 0.023774
2022-01-20 16:18:25,971 iteration 1586 : loss : 0.057314, loss_ce: 0.016013
2022-01-20 16:18:27,297 iteration 1587 : loss : 0.056279, loss_ce: 0.017727
2022-01-20 16:18:28,683 iteration 1588 : loss : 0.055605, loss_ce: 0.026206
2022-01-20 16:18:29,995 iteration 1589 : loss : 0.045031, loss_ce: 0.011722
2022-01-20 16:18:31,346 iteration 1590 : loss : 0.054085, loss_ce: 0.023038
2022-01-20 16:18:32,623 iteration 1591 : loss : 0.072010, loss_ce: 0.037256
2022-01-20 16:18:33,919 iteration 1592 : loss : 0.060237, loss_ce: 0.026442
2022-01-20 16:18:35,310 iteration 1593 : loss : 0.048535, loss_ce: 0.016519
2022-01-20 16:18:36,644 iteration 1594 : loss : 0.039989, loss_ce: 0.021059
2022-01-20 16:18:37,986 iteration 1595 : loss : 0.071525, loss_ce: 0.030129
2022-01-20 16:18:39,296 iteration 1596 : loss : 0.036606, loss_ce: 0.015092
2022-01-20 16:18:40,566 iteration 1597 : loss : 0.050444, loss_ce: 0.016986
2022-01-20 16:18:41,928 iteration 1598 : loss : 0.041061, loss_ce: 0.020785
 24%|███████                       | 94/400 [38:30<1:59:05, 23.35s/it]2022-01-20 16:18:43,338 iteration 1599 : loss : 0.032881, loss_ce: 0.014120
2022-01-20 16:18:44,604 iteration 1600 : loss : 0.041743, loss_ce: 0.016233
2022-01-20 16:18:45,924 iteration 1601 : loss : 0.066949, loss_ce: 0.024630
2022-01-20 16:18:47,207 iteration 1602 : loss : 0.052207, loss_ce: 0.025236
2022-01-20 16:18:48,602 iteration 1603 : loss : 0.051044, loss_ce: 0.020457
2022-01-20 16:18:49,878 iteration 1604 : loss : 0.071209, loss_ce: 0.030559
2022-01-20 16:18:51,268 iteration 1605 : loss : 0.040489, loss_ce: 0.014151
2022-01-20 16:18:52,626 iteration 1606 : loss : 0.038566, loss_ce: 0.011977
2022-01-20 16:18:53,932 iteration 1607 : loss : 0.041729, loss_ce: 0.016628
2022-01-20 16:18:55,272 iteration 1608 : loss : 0.030407, loss_ce: 0.010086
2022-01-20 16:18:56,622 iteration 1609 : loss : 0.035761, loss_ce: 0.012778
2022-01-20 16:18:57,917 iteration 1610 : loss : 0.052662, loss_ce: 0.023449
2022-01-20 16:18:59,244 iteration 1611 : loss : 0.054971, loss_ce: 0.018905
2022-01-20 16:19:00,552 iteration 1612 : loss : 0.047936, loss_ce: 0.021907
2022-01-20 16:19:01,871 iteration 1613 : loss : 0.050155, loss_ce: 0.020110
2022-01-20 16:19:03,197 iteration 1614 : loss : 0.055829, loss_ce: 0.019937
2022-01-20 16:19:03,198 Training Data Eval:
2022-01-20 16:19:09,729   Average segmentation loss on training set: 0.0514
2022-01-20 16:19:09,729 Validation Data Eval:
2022-01-20 16:19:11,948   Average segmentation loss on validation set: 0.0776
2022-01-20 16:19:17,940 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 16:19:19,271 iteration 1615 : loss : 0.044784, loss_ce: 0.021962
 24%|███████▏                      | 95/400 [39:07<2:20:02, 27.55s/it]2022-01-20 16:19:20,552 iteration 1616 : loss : 0.052509, loss_ce: 0.018668
2022-01-20 16:19:21,730 iteration 1617 : loss : 0.028117, loss_ce: 0.012668
2022-01-20 16:19:22,973 iteration 1618 : loss : 0.024401, loss_ce: 0.009367
2022-01-20 16:19:24,274 iteration 1619 : loss : 0.031604, loss_ce: 0.015434
2022-01-20 16:19:25,447 iteration 1620 : loss : 0.063105, loss_ce: 0.031354
2022-01-20 16:19:26,737 iteration 1621 : loss : 0.040825, loss_ce: 0.016326
2022-01-20 16:19:27,956 iteration 1622 : loss : 0.058234, loss_ce: 0.019477
2022-01-20 16:19:29,127 iteration 1623 : loss : 0.034504, loss_ce: 0.017866
2022-01-20 16:19:30,396 iteration 1624 : loss : 0.046208, loss_ce: 0.021019
2022-01-20 16:19:31,625 iteration 1625 : loss : 0.035934, loss_ce: 0.019341
2022-01-20 16:19:32,917 iteration 1626 : loss : 0.035992, loss_ce: 0.013652
2022-01-20 16:19:34,200 iteration 1627 : loss : 0.075204, loss_ce: 0.025691
2022-01-20 16:19:35,552 iteration 1628 : loss : 0.048435, loss_ce: 0.013429
2022-01-20 16:19:36,885 iteration 1629 : loss : 0.061066, loss_ce: 0.026552
2022-01-20 16:19:38,137 iteration 1630 : loss : 0.045437, loss_ce: 0.014779
2022-01-20 16:19:39,461 iteration 1631 : loss : 0.037569, loss_ce: 0.015476
2022-01-20 16:19:40,656 iteration 1632 : loss : 0.031952, loss_ce: 0.012520
 24%|███████▏                      | 96/400 [39:29<2:10:12, 25.70s/it]2022-01-20 16:19:42,092 iteration 1633 : loss : 0.042517, loss_ce: 0.014578
2022-01-20 16:19:43,420 iteration 1634 : loss : 0.037695, loss_ce: 0.016464
2022-01-20 16:19:44,697 iteration 1635 : loss : 0.044484, loss_ce: 0.019078
2022-01-20 16:19:45,890 iteration 1636 : loss : 0.035539, loss_ce: 0.013959
2022-01-20 16:19:47,270 iteration 1637 : loss : 0.039885, loss_ce: 0.013419
2022-01-20 16:19:48,605 iteration 1638 : loss : 0.045829, loss_ce: 0.016453
2022-01-20 16:19:49,994 iteration 1639 : loss : 0.047992, loss_ce: 0.021483
2022-01-20 16:19:51,305 iteration 1640 : loss : 0.045862, loss_ce: 0.017171
2022-01-20 16:19:52,649 iteration 1641 : loss : 0.039085, loss_ce: 0.015542
2022-01-20 16:19:54,076 iteration 1642 : loss : 0.062935, loss_ce: 0.021131
2022-01-20 16:19:55,410 iteration 1643 : loss : 0.044194, loss_ce: 0.017657
2022-01-20 16:19:56,735 iteration 1644 : loss : 0.062469, loss_ce: 0.024905
2022-01-20 16:19:57,944 iteration 1645 : loss : 0.044412, loss_ce: 0.013301
2022-01-20 16:19:59,248 iteration 1646 : loss : 0.038291, loss_ce: 0.014506
2022-01-20 16:20:00,642 iteration 1647 : loss : 0.049791, loss_ce: 0.025592
2022-01-20 16:20:01,931 iteration 1648 : loss : 0.055121, loss_ce: 0.025124
2022-01-20 16:20:03,343 iteration 1649 : loss : 0.045524, loss_ce: 0.011934
 24%|███████▎                      | 97/400 [39:51<2:05:12, 24.79s/it]2022-01-20 16:20:04,711 iteration 1650 : loss : 0.033727, loss_ce: 0.010814
2022-01-20 16:20:06,093 iteration 1651 : loss : 0.082043, loss_ce: 0.034765
2022-01-20 16:20:07,469 iteration 1652 : loss : 0.088190, loss_ce: 0.024380
2022-01-20 16:20:08,823 iteration 1653 : loss : 0.049485, loss_ce: 0.021769
2022-01-20 16:20:10,118 iteration 1654 : loss : 0.041547, loss_ce: 0.013218
2022-01-20 16:20:11,417 iteration 1655 : loss : 0.056015, loss_ce: 0.016908
2022-01-20 16:20:12,722 iteration 1656 : loss : 0.037620, loss_ce: 0.017058
2022-01-20 16:20:14,140 iteration 1657 : loss : 0.048261, loss_ce: 0.020330
2022-01-20 16:20:15,406 iteration 1658 : loss : 0.039536, loss_ce: 0.015306
2022-01-20 16:20:16,739 iteration 1659 : loss : 0.048810, loss_ce: 0.019319
2022-01-20 16:20:18,191 iteration 1660 : loss : 0.050320, loss_ce: 0.022630
2022-01-20 16:20:19,499 iteration 1661 : loss : 0.048768, loss_ce: 0.018635
2022-01-20 16:20:20,785 iteration 1662 : loss : 0.038413, loss_ce: 0.013960
2022-01-20 16:20:22,164 iteration 1663 : loss : 0.054809, loss_ce: 0.021705
2022-01-20 16:20:23,540 iteration 1664 : loss : 0.050462, loss_ce: 0.019501
2022-01-20 16:20:24,820 iteration 1665 : loss : 0.027369, loss_ce: 0.011425
2022-01-20 16:20:26,100 iteration 1666 : loss : 0.035761, loss_ce: 0.014222
 24%|███████▎                      | 98/400 [40:14<2:01:43, 24.18s/it]2022-01-20 16:20:27,476 iteration 1667 : loss : 0.035961, loss_ce: 0.016632
2022-01-20 16:20:28,851 iteration 1668 : loss : 0.049208, loss_ce: 0.021114
2022-01-20 16:20:30,146 iteration 1669 : loss : 0.035162, loss_ce: 0.014279
2022-01-20 16:20:31,450 iteration 1670 : loss : 0.044539, loss_ce: 0.015729
2022-01-20 16:20:32,789 iteration 1671 : loss : 0.044213, loss_ce: 0.016133
2022-01-20 16:20:34,067 iteration 1672 : loss : 0.043975, loss_ce: 0.015085
2022-01-20 16:20:35,327 iteration 1673 : loss : 0.033922, loss_ce: 0.013443
2022-01-20 16:20:36,705 iteration 1674 : loss : 0.035929, loss_ce: 0.014160
2022-01-20 16:20:37,996 iteration 1675 : loss : 0.036771, loss_ce: 0.014098
2022-01-20 16:20:39,376 iteration 1676 : loss : 0.035616, loss_ce: 0.015670
2022-01-20 16:20:40,763 iteration 1677 : loss : 0.046363, loss_ce: 0.020977
2022-01-20 16:20:42,127 iteration 1678 : loss : 0.053774, loss_ce: 0.014848
2022-01-20 16:20:43,497 iteration 1679 : loss : 0.034339, loss_ce: 0.008769
2022-01-20 16:20:44,841 iteration 1680 : loss : 0.059244, loss_ce: 0.033403
2022-01-20 16:20:46,148 iteration 1681 : loss : 0.050099, loss_ce: 0.013895
2022-01-20 16:20:47,427 iteration 1682 : loss : 0.062647, loss_ce: 0.036478
2022-01-20 16:20:48,776 iteration 1683 : loss : 0.053148, loss_ce: 0.024337
 25%|███████▍                      | 99/400 [40:37<1:59:03, 23.73s/it]2022-01-20 16:20:50,165 iteration 1684 : loss : 0.027805, loss_ce: 0.009481
2022-01-20 16:20:51,440 iteration 1685 : loss : 0.034782, loss_ce: 0.012868
2022-01-20 16:20:52,829 iteration 1686 : loss : 0.041180, loss_ce: 0.014832
2022-01-20 16:20:54,091 iteration 1687 : loss : 0.038662, loss_ce: 0.013038
2022-01-20 16:20:55,433 iteration 1688 : loss : 0.037002, loss_ce: 0.013871
2022-01-20 16:20:56,772 iteration 1689 : loss : 0.079951, loss_ce: 0.034469
2022-01-20 16:20:58,021 iteration 1690 : loss : 0.037772, loss_ce: 0.011960
2022-01-20 16:20:59,281 iteration 1691 : loss : 0.053266, loss_ce: 0.017935
2022-01-20 16:21:00,614 iteration 1692 : loss : 0.031619, loss_ce: 0.013234
2022-01-20 16:21:02,007 iteration 1693 : loss : 0.036290, loss_ce: 0.013890
2022-01-20 16:21:03,373 iteration 1694 : loss : 0.043139, loss_ce: 0.015326
2022-01-20 16:21:04,662 iteration 1695 : loss : 0.036796, loss_ce: 0.012215
2022-01-20 16:21:05,983 iteration 1696 : loss : 0.051620, loss_ce: 0.024584
2022-01-20 16:21:07,335 iteration 1697 : loss : 0.040064, loss_ce: 0.019007
2022-01-20 16:21:08,674 iteration 1698 : loss : 0.031742, loss_ce: 0.011723
2022-01-20 16:21:09,972 iteration 1699 : loss : 0.037112, loss_ce: 0.016970
2022-01-20 16:21:09,972 Training Data Eval:
2022-01-20 16:21:16,628   Average segmentation loss on training set: 0.0311
2022-01-20 16:21:16,629 Validation Data Eval:
2022-01-20 16:21:18,901   Average segmentation loss on validation set: 0.1003
2022-01-20 16:21:20,268 iteration 1700 : loss : 0.034540, loss_ce: 0.014386
 25%|███████▎                     | 100/400 [41:08<2:10:18, 26.06s/it]2022-01-20 16:21:21,682 iteration 1701 : loss : 0.031112, loss_ce: 0.012354
2022-01-20 16:21:23,022 iteration 1702 : loss : 0.037522, loss_ce: 0.015227
2022-01-20 16:21:24,443 iteration 1703 : loss : 0.054572, loss_ce: 0.021430
2022-01-20 16:21:25,779 iteration 1704 : loss : 0.035570, loss_ce: 0.017892
2022-01-20 16:21:27,169 iteration 1705 : loss : 0.047021, loss_ce: 0.018278
2022-01-20 16:21:28,594 iteration 1706 : loss : 0.050325, loss_ce: 0.023702
2022-01-20 16:21:29,922 iteration 1707 : loss : 0.042566, loss_ce: 0.020962
2022-01-20 16:21:31,279 iteration 1708 : loss : 0.093482, loss_ce: 0.032410
2022-01-20 16:21:32,616 iteration 1709 : loss : 0.041696, loss_ce: 0.018888
2022-01-20 16:21:34,000 iteration 1710 : loss : 0.039287, loss_ce: 0.015565
2022-01-20 16:21:35,336 iteration 1711 : loss : 0.042625, loss_ce: 0.015703
2022-01-20 16:21:36,594 iteration 1712 : loss : 0.029493, loss_ce: 0.014061
2022-01-20 16:21:37,954 iteration 1713 : loss : 0.044084, loss_ce: 0.012755
2022-01-20 16:21:39,362 iteration 1714 : loss : 0.047313, loss_ce: 0.014871
2022-01-20 16:21:40,743 iteration 1715 : loss : 0.042807, loss_ce: 0.018586
2022-01-20 16:21:41,983 iteration 1716 : loss : 0.037853, loss_ce: 0.011888
2022-01-20 16:21:43,370 iteration 1717 : loss : 0.069546, loss_ce: 0.023578
 25%|███████▎                     | 101/400 [41:31<2:05:25, 25.17s/it]2022-01-20 16:21:44,753 iteration 1718 : loss : 0.043959, loss_ce: 0.021028
2022-01-20 16:21:46,049 iteration 1719 : loss : 0.064671, loss_ce: 0.014429
2022-01-20 16:21:47,412 iteration 1720 : loss : 0.036379, loss_ce: 0.012804
2022-01-20 16:21:48,689 iteration 1721 : loss : 0.040202, loss_ce: 0.012956
2022-01-20 16:21:50,043 iteration 1722 : loss : 0.036891, loss_ce: 0.012144
2022-01-20 16:21:51,315 iteration 1723 : loss : 0.060601, loss_ce: 0.018771
2022-01-20 16:21:52,678 iteration 1724 : loss : 0.034981, loss_ce: 0.011429
2022-01-20 16:21:54,032 iteration 1725 : loss : 0.045481, loss_ce: 0.012389
2022-01-20 16:21:55,392 iteration 1726 : loss : 0.040586, loss_ce: 0.015764
2022-01-20 16:21:56,838 iteration 1727 : loss : 0.051820, loss_ce: 0.022550
2022-01-20 16:21:58,094 iteration 1728 : loss : 0.030644, loss_ce: 0.010172
2022-01-20 16:21:59,459 iteration 1729 : loss : 0.038632, loss_ce: 0.014158
2022-01-20 16:22:00,868 iteration 1730 : loss : 0.033455, loss_ce: 0.015050
2022-01-20 16:22:02,199 iteration 1731 : loss : 0.045363, loss_ce: 0.023973
2022-01-20 16:22:03,510 iteration 1732 : loss : 0.047893, loss_ce: 0.018118
2022-01-20 16:22:04,789 iteration 1733 : loss : 0.033004, loss_ce: 0.013340
2022-01-20 16:22:06,103 iteration 1734 : loss : 0.039038, loss_ce: 0.015573
 26%|███████▍                     | 102/400 [41:54<2:01:22, 24.44s/it]2022-01-20 16:22:07,628 iteration 1735 : loss : 0.037799, loss_ce: 0.014912
2022-01-20 16:22:08,908 iteration 1736 : loss : 0.041588, loss_ce: 0.016982
2022-01-20 16:22:10,360 iteration 1737 : loss : 0.041649, loss_ce: 0.016837
2022-01-20 16:22:11,676 iteration 1738 : loss : 0.031829, loss_ce: 0.015304
2022-01-20 16:22:12,939 iteration 1739 : loss : 0.034537, loss_ce: 0.013870
2022-01-20 16:22:14,324 iteration 1740 : loss : 0.039595, loss_ce: 0.016682
2022-01-20 16:22:15,677 iteration 1741 : loss : 0.035579, loss_ce: 0.011969
2022-01-20 16:22:17,028 iteration 1742 : loss : 0.046797, loss_ce: 0.016725
2022-01-20 16:22:18,258 iteration 1743 : loss : 0.037101, loss_ce: 0.011621
2022-01-20 16:22:19,661 iteration 1744 : loss : 0.073397, loss_ce: 0.031468
2022-01-20 16:22:21,042 iteration 1745 : loss : 0.064093, loss_ce: 0.023722
2022-01-20 16:22:22,352 iteration 1746 : loss : 0.043263, loss_ce: 0.020795
2022-01-20 16:22:23,622 iteration 1747 : loss : 0.036930, loss_ce: 0.015292
2022-01-20 16:22:24,965 iteration 1748 : loss : 0.036125, loss_ce: 0.013779
2022-01-20 16:22:26,171 iteration 1749 : loss : 0.042605, loss_ce: 0.013862
2022-01-20 16:22:27,523 iteration 1750 : loss : 0.119837, loss_ce: 0.027834
2022-01-20 16:22:28,947 iteration 1751 : loss : 0.035540, loss_ce: 0.013551
 26%|███████▍                     | 103/400 [42:17<1:58:37, 23.96s/it]2022-01-20 16:22:30,396 iteration 1752 : loss : 0.092960, loss_ce: 0.025578
2022-01-20 16:22:31,595 iteration 1753 : loss : 0.042895, loss_ce: 0.012875
2022-01-20 16:22:32,970 iteration 1754 : loss : 0.045694, loss_ce: 0.019558
2022-01-20 16:22:34,248 iteration 1755 : loss : 0.043197, loss_ce: 0.018864
2022-01-20 16:22:35,577 iteration 1756 : loss : 0.073922, loss_ce: 0.031313
2022-01-20 16:22:36,837 iteration 1757 : loss : 0.037231, loss_ce: 0.016116
2022-01-20 16:22:38,132 iteration 1758 : loss : 0.042749, loss_ce: 0.021527
2022-01-20 16:22:39,402 iteration 1759 : loss : 0.035783, loss_ce: 0.011478
2022-01-20 16:22:40,675 iteration 1760 : loss : 0.058260, loss_ce: 0.018738
2022-01-20 16:22:42,038 iteration 1761 : loss : 0.059664, loss_ce: 0.020981
2022-01-20 16:22:43,256 iteration 1762 : loss : 0.041383, loss_ce: 0.017547
2022-01-20 16:22:44,514 iteration 1763 : loss : 0.044063, loss_ce: 0.018372
2022-01-20 16:22:45,729 iteration 1764 : loss : 0.031835, loss_ce: 0.009681
2022-01-20 16:22:47,060 iteration 1765 : loss : 0.046152, loss_ce: 0.023264
2022-01-20 16:22:48,435 iteration 1766 : loss : 0.051950, loss_ce: 0.028684
2022-01-20 16:22:49,710 iteration 1767 : loss : 0.036761, loss_ce: 0.017025
2022-01-20 16:22:51,025 iteration 1768 : loss : 0.046280, loss_ce: 0.018433
 26%|███████▌                     | 104/400 [42:39<1:55:25, 23.40s/it]2022-01-20 16:22:52,394 iteration 1769 : loss : 0.044734, loss_ce: 0.018348
2022-01-20 16:22:53,661 iteration 1770 : loss : 0.036201, loss_ce: 0.015537
2022-01-20 16:22:54,902 iteration 1771 : loss : 0.046343, loss_ce: 0.019675
2022-01-20 16:22:56,172 iteration 1772 : loss : 0.037060, loss_ce: 0.019869
2022-01-20 16:22:57,528 iteration 1773 : loss : 0.067436, loss_ce: 0.021190
2022-01-20 16:22:58,842 iteration 1774 : loss : 0.035734, loss_ce: 0.012530
2022-01-20 16:23:00,183 iteration 1775 : loss : 0.046172, loss_ce: 0.018300
2022-01-20 16:23:01,437 iteration 1776 : loss : 0.032463, loss_ce: 0.016437
2022-01-20 16:23:02,702 iteration 1777 : loss : 0.036963, loss_ce: 0.013035
2022-01-20 16:23:03,951 iteration 1778 : loss : 0.043556, loss_ce: 0.015948
2022-01-20 16:23:05,306 iteration 1779 : loss : 0.053203, loss_ce: 0.016070
2022-01-20 16:23:06,617 iteration 1780 : loss : 0.054619, loss_ce: 0.025894
2022-01-20 16:23:07,861 iteration 1781 : loss : 0.039689, loss_ce: 0.015823
2022-01-20 16:23:09,211 iteration 1782 : loss : 0.036813, loss_ce: 0.014033
2022-01-20 16:23:10,542 iteration 1783 : loss : 0.039880, loss_ce: 0.015012
2022-01-20 16:23:11,811 iteration 1784 : loss : 0.039257, loss_ce: 0.014502
2022-01-20 16:23:11,811 Training Data Eval:
2022-01-20 16:23:18,328   Average segmentation loss on training set: 0.0308
2022-01-20 16:23:18,328 Validation Data Eval:
2022-01-20 16:23:20,551   Average segmentation loss on validation set: 0.0892
2022-01-20 16:23:21,931 iteration 1785 : loss : 0.057089, loss_ce: 0.021063
 26%|███████▌                     | 105/400 [43:10<2:06:05, 25.65s/it]2022-01-20 16:23:23,319 iteration 1786 : loss : 0.037223, loss_ce: 0.016739
2022-01-20 16:23:24,540 iteration 1787 : loss : 0.067762, loss_ce: 0.023989
2022-01-20 16:23:25,907 iteration 1788 : loss : 0.051435, loss_ce: 0.027440
2022-01-20 16:23:27,252 iteration 1789 : loss : 0.028754, loss_ce: 0.010871
2022-01-20 16:23:28,576 iteration 1790 : loss : 0.030985, loss_ce: 0.013769
2022-01-20 16:23:29,956 iteration 1791 : loss : 0.041686, loss_ce: 0.016700
2022-01-20 16:23:31,218 iteration 1792 : loss : 0.061532, loss_ce: 0.024614
2022-01-20 16:23:32,505 iteration 1793 : loss : 0.052620, loss_ce: 0.020028
2022-01-20 16:23:33,803 iteration 1794 : loss : 0.033195, loss_ce: 0.013370
2022-01-20 16:23:35,159 iteration 1795 : loss : 0.039946, loss_ce: 0.015344
2022-01-20 16:23:36,463 iteration 1796 : loss : 0.047903, loss_ce: 0.025258
2022-01-20 16:23:37,870 iteration 1797 : loss : 0.052564, loss_ce: 0.019791
2022-01-20 16:23:39,248 iteration 1798 : loss : 0.036921, loss_ce: 0.012802
2022-01-20 16:23:40,518 iteration 1799 : loss : 0.045498, loss_ce: 0.017923
2022-01-20 16:23:41,846 iteration 1800 : loss : 0.033161, loss_ce: 0.011060
2022-01-20 16:23:43,104 iteration 1801 : loss : 0.029746, loss_ce: 0.010406
2022-01-20 16:23:44,401 iteration 1802 : loss : 0.042379, loss_ce: 0.015483
 26%|███████▋                     | 106/400 [43:32<2:01:00, 24.69s/it]2022-01-20 16:23:45,855 iteration 1803 : loss : 0.047371, loss_ce: 0.017737
2022-01-20 16:23:47,230 iteration 1804 : loss : 0.037427, loss_ce: 0.010935
2022-01-20 16:23:48,503 iteration 1805 : loss : 0.036028, loss_ce: 0.011200
2022-01-20 16:23:49,777 iteration 1806 : loss : 0.043288, loss_ce: 0.020302
2022-01-20 16:23:51,058 iteration 1807 : loss : 0.038637, loss_ce: 0.014404
2022-01-20 16:23:52,367 iteration 1808 : loss : 0.030211, loss_ce: 0.013612
2022-01-20 16:23:53,637 iteration 1809 : loss : 0.027142, loss_ce: 0.010788
2022-01-20 16:23:54,836 iteration 1810 : loss : 0.026267, loss_ce: 0.010249
2022-01-20 16:23:56,193 iteration 1811 : loss : 0.036129, loss_ce: 0.016447
2022-01-20 16:23:57,573 iteration 1812 : loss : 0.042667, loss_ce: 0.016583
2022-01-20 16:23:59,014 iteration 1813 : loss : 0.037212, loss_ce: 0.011642
2022-01-20 16:24:00,347 iteration 1814 : loss : 0.033200, loss_ce: 0.015280
2022-01-20 16:24:01,587 iteration 1815 : loss : 0.032249, loss_ce: 0.009082
2022-01-20 16:24:02,811 iteration 1816 : loss : 0.035721, loss_ce: 0.014214
2022-01-20 16:24:04,206 iteration 1817 : loss : 0.040374, loss_ce: 0.014799
2022-01-20 16:24:05,514 iteration 1818 : loss : 0.057088, loss_ce: 0.023891
2022-01-20 16:24:06,874 iteration 1819 : loss : 0.042381, loss_ce: 0.017608
 27%|███████▊                     | 107/400 [43:55<1:57:20, 24.03s/it]2022-01-20 16:24:08,323 iteration 1820 : loss : 0.038368, loss_ce: 0.018445
2022-01-20 16:24:09,594 iteration 1821 : loss : 0.033525, loss_ce: 0.015225
2022-01-20 16:24:10,897 iteration 1822 : loss : 0.035974, loss_ce: 0.013824
2022-01-20 16:24:12,117 iteration 1823 : loss : 0.034038, loss_ce: 0.010763
2022-01-20 16:24:13,312 iteration 1824 : loss : 0.028165, loss_ce: 0.011746
2022-01-20 16:24:14,673 iteration 1825 : loss : 0.047502, loss_ce: 0.019175
2022-01-20 16:24:15,883 iteration 1826 : loss : 0.039426, loss_ce: 0.019293
2022-01-20 16:24:17,299 iteration 1827 : loss : 0.119600, loss_ce: 0.042087
2022-01-20 16:24:18,581 iteration 1828 : loss : 0.040313, loss_ce: 0.015770
2022-01-20 16:24:19,854 iteration 1829 : loss : 0.049116, loss_ce: 0.015067
2022-01-20 16:24:21,141 iteration 1830 : loss : 0.035941, loss_ce: 0.014922
2022-01-20 16:24:22,531 iteration 1831 : loss : 0.073079, loss_ce: 0.047039
2022-01-20 16:24:23,823 iteration 1832 : loss : 0.034444, loss_ce: 0.010890
2022-01-20 16:24:25,125 iteration 1833 : loss : 0.034544, loss_ce: 0.017344
2022-01-20 16:24:26,536 iteration 1834 : loss : 0.034502, loss_ce: 0.013768
2022-01-20 16:24:27,808 iteration 1835 : loss : 0.040733, loss_ce: 0.020034
2022-01-20 16:24:29,105 iteration 1836 : loss : 0.048061, loss_ce: 0.016080
 27%|███████▊                     | 108/400 [44:17<1:54:19, 23.49s/it]2022-01-20 16:24:30,532 iteration 1837 : loss : 0.037814, loss_ce: 0.015362
2022-01-20 16:24:31,901 iteration 1838 : loss : 0.039707, loss_ce: 0.017448
2022-01-20 16:24:33,172 iteration 1839 : loss : 0.041945, loss_ce: 0.016715
2022-01-20 16:24:34,392 iteration 1840 : loss : 0.036081, loss_ce: 0.016867
2022-01-20 16:24:35,738 iteration 1841 : loss : 0.043523, loss_ce: 0.020021
2022-01-20 16:24:37,111 iteration 1842 : loss : 0.049551, loss_ce: 0.016941
2022-01-20 16:24:38,358 iteration 1843 : loss : 0.034193, loss_ce: 0.015909
2022-01-20 16:24:39,675 iteration 1844 : loss : 0.032077, loss_ce: 0.012060
2022-01-20 16:24:40,903 iteration 1845 : loss : 0.031269, loss_ce: 0.013190
2022-01-20 16:24:42,308 iteration 1846 : loss : 0.034506, loss_ce: 0.014140
2022-01-20 16:24:43,672 iteration 1847 : loss : 0.042163, loss_ce: 0.018023
2022-01-20 16:24:44,978 iteration 1848 : loss : 0.032975, loss_ce: 0.014652
2022-01-20 16:24:46,192 iteration 1849 : loss : 0.029718, loss_ce: 0.014184
2022-01-20 16:24:47,508 iteration 1850 : loss : 0.042848, loss_ce: 0.011284
2022-01-20 16:24:48,860 iteration 1851 : loss : 0.045297, loss_ce: 0.018790
2022-01-20 16:24:50,176 iteration 1852 : loss : 0.027857, loss_ce: 0.011693
2022-01-20 16:24:51,503 iteration 1853 : loss : 0.046131, loss_ce: 0.011530
 27%|███████▉                     | 109/400 [44:40<1:52:20, 23.16s/it]2022-01-20 16:24:52,857 iteration 1854 : loss : 0.035835, loss_ce: 0.012821
2022-01-20 16:24:54,156 iteration 1855 : loss : 0.032455, loss_ce: 0.010366
2022-01-20 16:24:55,481 iteration 1856 : loss : 0.033331, loss_ce: 0.008821
2022-01-20 16:24:56,810 iteration 1857 : loss : 0.062092, loss_ce: 0.020484
2022-01-20 16:24:58,128 iteration 1858 : loss : 0.039839, loss_ce: 0.022162
2022-01-20 16:24:59,395 iteration 1859 : loss : 0.031016, loss_ce: 0.015487
2022-01-20 16:25:00,843 iteration 1860 : loss : 0.043827, loss_ce: 0.019112
2022-01-20 16:25:02,188 iteration 1861 : loss : 0.039795, loss_ce: 0.014470
2022-01-20 16:25:03,494 iteration 1862 : loss : 0.033315, loss_ce: 0.015951
2022-01-20 16:25:04,859 iteration 1863 : loss : 0.039009, loss_ce: 0.015695
2022-01-20 16:25:06,192 iteration 1864 : loss : 0.027418, loss_ce: 0.010615
2022-01-20 16:25:07,596 iteration 1865 : loss : 0.047603, loss_ce: 0.024751
2022-01-20 16:25:08,979 iteration 1866 : loss : 0.034463, loss_ce: 0.016545
2022-01-20 16:25:10,311 iteration 1867 : loss : 0.077385, loss_ce: 0.024489
2022-01-20 16:25:11,594 iteration 1868 : loss : 0.034244, loss_ce: 0.017031
2022-01-20 16:25:12,910 iteration 1869 : loss : 0.047025, loss_ce: 0.015504
2022-01-20 16:25:12,910 Training Data Eval:
2022-01-20 16:25:19,492   Average segmentation loss on training set: 0.0278
2022-01-20 16:25:19,492 Validation Data Eval:
2022-01-20 16:25:21,735   Average segmentation loss on validation set: 0.0808
2022-01-20 16:25:23,006 iteration 1870 : loss : 0.034048, loss_ce: 0.010123
 28%|███████▉                     | 110/400 [45:11<2:04:01, 25.66s/it]2022-01-20 16:25:24,363 iteration 1871 : loss : 0.038289, loss_ce: 0.017127
2022-01-20 16:25:25,617 iteration 1872 : loss : 0.042119, loss_ce: 0.013765
2022-01-20 16:25:26,950 iteration 1873 : loss : 0.043164, loss_ce: 0.020411
2022-01-20 16:25:28,332 iteration 1874 : loss : 0.041624, loss_ce: 0.017405
2022-01-20 16:25:29,728 iteration 1875 : loss : 0.040958, loss_ce: 0.025010
2022-01-20 16:25:31,116 iteration 1876 : loss : 0.042216, loss_ce: 0.012390
2022-01-20 16:25:32,474 iteration 1877 : loss : 0.037664, loss_ce: 0.011730
2022-01-20 16:25:33,717 iteration 1878 : loss : 0.032905, loss_ce: 0.011440
2022-01-20 16:25:34,980 iteration 1879 : loss : 0.030448, loss_ce: 0.012793
2022-01-20 16:25:36,238 iteration 1880 : loss : 0.030540, loss_ce: 0.011593
2022-01-20 16:25:37,498 iteration 1881 : loss : 0.027905, loss_ce: 0.009929
2022-01-20 16:25:38,830 iteration 1882 : loss : 0.060157, loss_ce: 0.017776
2022-01-20 16:25:40,081 iteration 1883 : loss : 0.033397, loss_ce: 0.013408
2022-01-20 16:25:41,470 iteration 1884 : loss : 0.031888, loss_ce: 0.012391
2022-01-20 16:25:42,715 iteration 1885 : loss : 0.031085, loss_ce: 0.011423
2022-01-20 16:25:44,048 iteration 1886 : loss : 0.038392, loss_ce: 0.018118
2022-01-20 16:25:45,312 iteration 1887 : loss : 0.034933, loss_ce: 0.011986
 28%|████████                     | 111/400 [45:33<1:58:45, 24.66s/it]2022-01-20 16:25:46,724 iteration 1888 : loss : 0.050546, loss_ce: 0.016818
2022-01-20 16:25:48,106 iteration 1889 : loss : 0.038097, loss_ce: 0.015881
2022-01-20 16:25:49,319 iteration 1890 : loss : 0.023693, loss_ce: 0.008330
2022-01-20 16:25:50,628 iteration 1891 : loss : 0.046129, loss_ce: 0.025137
2022-01-20 16:25:51,924 iteration 1892 : loss : 0.036866, loss_ce: 0.010744
2022-01-20 16:25:53,274 iteration 1893 : loss : 0.040109, loss_ce: 0.013941
2022-01-20 16:25:54,575 iteration 1894 : loss : 0.056002, loss_ce: 0.029958
2022-01-20 16:25:55,911 iteration 1895 : loss : 0.038677, loss_ce: 0.012374
2022-01-20 16:25:57,222 iteration 1896 : loss : 0.030036, loss_ce: 0.012831
2022-01-20 16:25:58,536 iteration 1897 : loss : 0.041690, loss_ce: 0.017877
2022-01-20 16:25:59,932 iteration 1898 : loss : 0.037108, loss_ce: 0.014504
2022-01-20 16:26:01,155 iteration 1899 : loss : 0.027643, loss_ce: 0.010892
2022-01-20 16:26:02,538 iteration 1900 : loss : 0.042179, loss_ce: 0.019441
2022-01-20 16:26:03,960 iteration 1901 : loss : 0.050467, loss_ce: 0.020690
2022-01-20 16:26:05,253 iteration 1902 : loss : 0.048300, loss_ce: 0.016739
2022-01-20 16:26:06,615 iteration 1903 : loss : 0.056046, loss_ce: 0.024228
2022-01-20 16:26:07,990 iteration 1904 : loss : 0.052314, loss_ce: 0.017029
 28%|████████                     | 112/400 [45:56<1:55:31, 24.07s/it]2022-01-20 16:26:09,426 iteration 1905 : loss : 0.039727, loss_ce: 0.017276
2022-01-20 16:26:10,747 iteration 1906 : loss : 0.036340, loss_ce: 0.011645
2022-01-20 16:26:12,054 iteration 1907 : loss : 0.030355, loss_ce: 0.012864
2022-01-20 16:26:13,499 iteration 1908 : loss : 0.037617, loss_ce: 0.011190
2022-01-20 16:26:14,846 iteration 1909 : loss : 0.041191, loss_ce: 0.015812
2022-01-20 16:26:16,201 iteration 1910 : loss : 0.064066, loss_ce: 0.016342
2022-01-20 16:26:17,595 iteration 1911 : loss : 0.034351, loss_ce: 0.011388
2022-01-20 16:26:18,827 iteration 1912 : loss : 0.031834, loss_ce: 0.011313
2022-01-20 16:26:20,154 iteration 1913 : loss : 0.046237, loss_ce: 0.022163
2022-01-20 16:26:21,488 iteration 1914 : loss : 0.035542, loss_ce: 0.015858
2022-01-20 16:26:22,832 iteration 1915 : loss : 0.034774, loss_ce: 0.014518
2022-01-20 16:26:24,129 iteration 1916 : loss : 0.051118, loss_ce: 0.021096
2022-01-20 16:26:25,436 iteration 1917 : loss : 0.045044, loss_ce: 0.021722
2022-01-20 16:26:26,787 iteration 1918 : loss : 0.055911, loss_ce: 0.020460
2022-01-20 16:26:28,066 iteration 1919 : loss : 0.050741, loss_ce: 0.022648
2022-01-20 16:26:29,357 iteration 1920 : loss : 0.034219, loss_ce: 0.015028
2022-01-20 16:26:30,756 iteration 1921 : loss : 0.055191, loss_ce: 0.025604
 28%|████████▏                    | 113/400 [46:19<1:53:14, 23.67s/it]2022-01-20 16:26:32,095 iteration 1922 : loss : 0.039625, loss_ce: 0.019734
2022-01-20 16:26:33,398 iteration 1923 : loss : 0.037554, loss_ce: 0.016921
2022-01-20 16:26:34,761 iteration 1924 : loss : 0.044262, loss_ce: 0.020513
2022-01-20 16:26:36,080 iteration 1925 : loss : 0.047086, loss_ce: 0.017623
2022-01-20 16:26:37,379 iteration 1926 : loss : 0.028119, loss_ce: 0.011376
2022-01-20 16:26:38,678 iteration 1927 : loss : 0.040651, loss_ce: 0.015162
2022-01-20 16:26:40,104 iteration 1928 : loss : 0.046717, loss_ce: 0.021195
2022-01-20 16:26:41,372 iteration 1929 : loss : 0.035454, loss_ce: 0.013130
2022-01-20 16:26:42,643 iteration 1930 : loss : 0.033261, loss_ce: 0.015257
2022-01-20 16:26:43,989 iteration 1931 : loss : 0.070374, loss_ce: 0.015382
2022-01-20 16:26:45,366 iteration 1932 : loss : 0.041301, loss_ce: 0.014541
2022-01-20 16:26:46,742 iteration 1933 : loss : 0.050382, loss_ce: 0.026388
2022-01-20 16:26:47,949 iteration 1934 : loss : 0.028172, loss_ce: 0.012445
2022-01-20 16:26:49,287 iteration 1935 : loss : 0.057752, loss_ce: 0.020126
2022-01-20 16:26:50,686 iteration 1936 : loss : 0.049605, loss_ce: 0.021485
2022-01-20 16:26:51,929 iteration 1937 : loss : 0.051649, loss_ce: 0.014948
2022-01-20 16:26:53,176 iteration 1938 : loss : 0.039691, loss_ce: 0.013560
 28%|████████▎                    | 114/400 [46:41<1:51:03, 23.30s/it]2022-01-20 16:26:54,532 iteration 1939 : loss : 0.029450, loss_ce: 0.008820
2022-01-20 16:26:55,962 iteration 1940 : loss : 0.039233, loss_ce: 0.016805
2022-01-20 16:26:57,374 iteration 1941 : loss : 0.041840, loss_ce: 0.016018
2022-01-20 16:26:58,709 iteration 1942 : loss : 0.040796, loss_ce: 0.014255
2022-01-20 16:26:59,992 iteration 1943 : loss : 0.032070, loss_ce: 0.013259
2022-01-20 16:27:01,296 iteration 1944 : loss : 0.034160, loss_ce: 0.013025
2022-01-20 16:27:02,558 iteration 1945 : loss : 0.049929, loss_ce: 0.016649
2022-01-20 16:27:03,876 iteration 1946 : loss : 0.040102, loss_ce: 0.014604
2022-01-20 16:27:05,238 iteration 1947 : loss : 0.047704, loss_ce: 0.022138
2022-01-20 16:27:06,566 iteration 1948 : loss : 0.058546, loss_ce: 0.017253
2022-01-20 16:27:07,867 iteration 1949 : loss : 0.044941, loss_ce: 0.025512
2022-01-20 16:27:09,127 iteration 1950 : loss : 0.028935, loss_ce: 0.012458
2022-01-20 16:27:10,509 iteration 1951 : loss : 0.050331, loss_ce: 0.016637
2022-01-20 16:27:11,863 iteration 1952 : loss : 0.050491, loss_ce: 0.015569
2022-01-20 16:27:13,257 iteration 1953 : loss : 0.054960, loss_ce: 0.027555
2022-01-20 16:27:14,592 iteration 1954 : loss : 0.029835, loss_ce: 0.012889
2022-01-20 16:27:14,592 Training Data Eval:
2022-01-20 16:27:21,173   Average segmentation loss on training set: 0.0263
2022-01-20 16:27:21,174 Validation Data Eval:
2022-01-20 16:27:23,413   Average segmentation loss on validation set: 0.0929
2022-01-20 16:27:24,763 iteration 1955 : loss : 0.045902, loss_ce: 0.013253
 29%|████████▎                    | 115/400 [47:13<2:02:28, 25.79s/it]2022-01-20 16:27:26,102 iteration 1956 : loss : 0.054114, loss_ce: 0.013314
2022-01-20 16:27:27,503 iteration 1957 : loss : 0.035826, loss_ce: 0.013947
2022-01-20 16:27:28,916 iteration 1958 : loss : 0.051690, loss_ce: 0.018760
2022-01-20 16:27:30,245 iteration 1959 : loss : 0.040084, loss_ce: 0.013826
2022-01-20 16:27:31,490 iteration 1960 : loss : 0.038573, loss_ce: 0.016891
2022-01-20 16:27:32,839 iteration 1961 : loss : 0.045497, loss_ce: 0.021651
2022-01-20 16:27:34,205 iteration 1962 : loss : 0.038753, loss_ce: 0.018866
2022-01-20 16:27:35,463 iteration 1963 : loss : 0.031445, loss_ce: 0.011492
2022-01-20 16:27:36,743 iteration 1964 : loss : 0.028699, loss_ce: 0.012496
2022-01-20 16:27:38,025 iteration 1965 : loss : 0.035356, loss_ce: 0.014807
2022-01-20 16:27:39,427 iteration 1966 : loss : 0.042066, loss_ce: 0.017536
2022-01-20 16:27:40,811 iteration 1967 : loss : 0.047656, loss_ce: 0.015262
2022-01-20 16:27:42,185 iteration 1968 : loss : 0.035130, loss_ce: 0.015070
2022-01-20 16:27:43,534 iteration 1969 : loss : 0.049540, loss_ce: 0.022183
2022-01-20 16:27:44,842 iteration 1970 : loss : 0.041283, loss_ce: 0.012551
2022-01-20 16:27:46,210 iteration 1971 : loss : 0.042661, loss_ce: 0.018964
2022-01-20 16:27:47,484 iteration 1972 : loss : 0.079474, loss_ce: 0.025620
 29%|████████▍                    | 116/400 [47:36<1:57:40, 24.86s/it]2022-01-20 16:27:48,706 iteration 1973 : loss : 0.032115, loss_ce: 0.012576
2022-01-20 16:27:50,044 iteration 1974 : loss : 0.038587, loss_ce: 0.015476
2022-01-20 16:27:51,355 iteration 1975 : loss : 0.024934, loss_ce: 0.008638
2022-01-20 16:27:52,746 iteration 1976 : loss : 0.048569, loss_ce: 0.018811
2022-01-20 16:27:54,073 iteration 1977 : loss : 0.042143, loss_ce: 0.012455
2022-01-20 16:27:55,298 iteration 1978 : loss : 0.024316, loss_ce: 0.011104
2022-01-20 16:27:56,536 iteration 1979 : loss : 0.041720, loss_ce: 0.018988
2022-01-20 16:27:57,893 iteration 1980 : loss : 0.038834, loss_ce: 0.016830
2022-01-20 16:27:59,190 iteration 1981 : loss : 0.033709, loss_ce: 0.011009
2022-01-20 16:28:00,431 iteration 1982 : loss : 0.044768, loss_ce: 0.014996
2022-01-20 16:28:01,839 iteration 1983 : loss : 0.052110, loss_ce: 0.024887
2022-01-20 16:28:03,093 iteration 1984 : loss : 0.032827, loss_ce: 0.009109
2022-01-20 16:28:04,443 iteration 1985 : loss : 0.026796, loss_ce: 0.010406
2022-01-20 16:28:05,792 iteration 1986 : loss : 0.048925, loss_ce: 0.024389
2022-01-20 16:28:07,196 iteration 1987 : loss : 0.031392, loss_ce: 0.012855
2022-01-20 16:28:08,467 iteration 1988 : loss : 0.036770, loss_ce: 0.010426
2022-01-20 16:28:09,791 iteration 1989 : loss : 0.047900, loss_ce: 0.025703
 29%|████████▍                    | 117/400 [47:58<1:53:40, 24.10s/it]2022-01-20 16:28:11,091 iteration 1990 : loss : 0.025491, loss_ce: 0.011057
2022-01-20 16:28:12,373 iteration 1991 : loss : 0.028567, loss_ce: 0.010017
2022-01-20 16:28:13,732 iteration 1992 : loss : 0.036522, loss_ce: 0.012542
2022-01-20 16:28:15,194 iteration 1993 : loss : 0.046985, loss_ce: 0.024807
2022-01-20 16:28:16,456 iteration 1994 : loss : 0.031968, loss_ce: 0.012046
2022-01-20 16:28:17,780 iteration 1995 : loss : 0.054579, loss_ce: 0.013498
2022-01-20 16:28:19,125 iteration 1996 : loss : 0.040800, loss_ce: 0.012430
2022-01-20 16:28:20,455 iteration 1997 : loss : 0.036202, loss_ce: 0.012702
2022-01-20 16:28:21,792 iteration 1998 : loss : 0.036224, loss_ce: 0.013449
2022-01-20 16:28:23,104 iteration 1999 : loss : 0.037862, loss_ce: 0.016101
2022-01-20 16:28:24,512 iteration 2000 : loss : 0.035589, loss_ce: 0.009373
2022-01-20 16:28:25,806 iteration 2001 : loss : 0.030838, loss_ce: 0.012841
2022-01-20 16:28:27,206 iteration 2002 : loss : 0.038871, loss_ce: 0.022436
2022-01-20 16:28:28,467 iteration 2003 : loss : 0.038192, loss_ce: 0.015600
2022-01-20 16:28:29,812 iteration 2004 : loss : 0.057879, loss_ce: 0.015113
2022-01-20 16:28:31,175 iteration 2005 : loss : 0.049518, loss_ce: 0.018193
2022-01-20 16:28:32,538 iteration 2006 : loss : 0.043664, loss_ce: 0.015594
 30%|████████▌                    | 118/400 [48:21<1:51:21, 23.69s/it]2022-01-20 16:28:33,957 iteration 2007 : loss : 0.032875, loss_ce: 0.013543
2022-01-20 16:28:35,211 iteration 2008 : loss : 0.038552, loss_ce: 0.014146
2022-01-20 16:28:36,500 iteration 2009 : loss : 0.063905, loss_ce: 0.019069
2022-01-20 16:28:37,765 iteration 2010 : loss : 0.049050, loss_ce: 0.018602
2022-01-20 16:28:39,086 iteration 2011 : loss : 0.032794, loss_ce: 0.014797
2022-01-20 16:28:40,423 iteration 2012 : loss : 0.048001, loss_ce: 0.018095
2022-01-20 16:28:41,786 iteration 2013 : loss : 0.036586, loss_ce: 0.013566
2022-01-20 16:28:43,129 iteration 2014 : loss : 0.040225, loss_ce: 0.015283
2022-01-20 16:28:44,365 iteration 2015 : loss : 0.031306, loss_ce: 0.011436
2022-01-20 16:28:45,675 iteration 2016 : loss : 0.041732, loss_ce: 0.011560
2022-01-20 16:28:46,893 iteration 2017 : loss : 0.028189, loss_ce: 0.010660
2022-01-20 16:28:48,213 iteration 2018 : loss : 0.071999, loss_ce: 0.032907
2022-01-20 16:28:49,472 iteration 2019 : loss : 0.032190, loss_ce: 0.013159
2022-01-20 16:28:50,812 iteration 2020 : loss : 0.059604, loss_ce: 0.026192
2022-01-20 16:28:52,170 iteration 2021 : loss : 0.030434, loss_ce: 0.011279
2022-01-20 16:28:53,546 iteration 2022 : loss : 0.051549, loss_ce: 0.028679
2022-01-20 16:28:54,872 iteration 2023 : loss : 0.046902, loss_ce: 0.016323
 30%|████████▋                    | 119/400 [48:43<1:49:02, 23.28s/it]2022-01-20 16:28:56,284 iteration 2024 : loss : 0.038332, loss_ce: 0.015161
2022-01-20 16:28:57,527 iteration 2025 : loss : 0.030253, loss_ce: 0.010861
2022-01-20 16:28:58,798 iteration 2026 : loss : 0.039254, loss_ce: 0.016408
2022-01-20 16:29:00,155 iteration 2027 : loss : 0.031024, loss_ce: 0.010358
2022-01-20 16:29:01,501 iteration 2028 : loss : 0.054220, loss_ce: 0.021786
2022-01-20 16:29:02,737 iteration 2029 : loss : 0.030126, loss_ce: 0.013922
2022-01-20 16:29:04,070 iteration 2030 : loss : 0.035073, loss_ce: 0.014920
2022-01-20 16:29:05,401 iteration 2031 : loss : 0.026419, loss_ce: 0.009905
2022-01-20 16:29:06,743 iteration 2032 : loss : 0.038661, loss_ce: 0.014948
2022-01-20 16:29:08,032 iteration 2033 : loss : 0.047396, loss_ce: 0.013888
2022-01-20 16:29:09,264 iteration 2034 : loss : 0.033369, loss_ce: 0.012492
2022-01-20 16:29:10,512 iteration 2035 : loss : 0.025561, loss_ce: 0.011513
2022-01-20 16:29:11,861 iteration 2036 : loss : 0.037727, loss_ce: 0.015711
2022-01-20 16:29:13,177 iteration 2037 : loss : 0.033428, loss_ce: 0.011205
2022-01-20 16:29:14,445 iteration 2038 : loss : 0.029241, loss_ce: 0.010027
2022-01-20 16:29:15,785 iteration 2039 : loss : 0.045903, loss_ce: 0.020368
2022-01-20 16:29:15,786 Training Data Eval:
2022-01-20 16:29:22,402   Average segmentation loss on training set: 0.0250
2022-01-20 16:29:22,402 Validation Data Eval:
2022-01-20 16:29:24,678   Average segmentation loss on validation set: 0.0720
2022-01-20 16:29:30,660 Found new lowest validation loss at iteration 2039! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 16:29:31,908 iteration 2040 : loss : 0.027874, loss_ce: 0.009263
 30%|████████▋                    | 120/400 [49:20<2:07:54, 27.41s/it]2022-01-20 16:29:33,202 iteration 2041 : loss : 0.033541, loss_ce: 0.012561
2022-01-20 16:29:34,437 iteration 2042 : loss : 0.025280, loss_ce: 0.009936
2022-01-20 16:29:35,690 iteration 2043 : loss : 0.027352, loss_ce: 0.011788
2022-01-20 16:29:37,005 iteration 2044 : loss : 0.026917, loss_ce: 0.010383
2022-01-20 16:29:38,356 iteration 2045 : loss : 0.039993, loss_ce: 0.018371
2022-01-20 16:29:39,648 iteration 2046 : loss : 0.039818, loss_ce: 0.014510
2022-01-20 16:29:40,924 iteration 2047 : loss : 0.033066, loss_ce: 0.011932
2022-01-20 16:29:42,089 iteration 2048 : loss : 0.033135, loss_ce: 0.011863
2022-01-20 16:29:43,317 iteration 2049 : loss : 0.031928, loss_ce: 0.012133
2022-01-20 16:29:44,649 iteration 2050 : loss : 0.040592, loss_ce: 0.011192
2022-01-20 16:29:45,999 iteration 2051 : loss : 0.043780, loss_ce: 0.017150
2022-01-20 16:29:47,270 iteration 2052 : loss : 0.029699, loss_ce: 0.014388
2022-01-20 16:29:48,527 iteration 2053 : loss : 0.025250, loss_ce: 0.008085
2022-01-20 16:29:49,848 iteration 2054 : loss : 0.044376, loss_ce: 0.015049
2022-01-20 16:29:51,192 iteration 2055 : loss : 0.049165, loss_ce: 0.022327
2022-01-20 16:29:52,526 iteration 2056 : loss : 0.042262, loss_ce: 0.020086
2022-01-20 16:29:53,883 iteration 2057 : loss : 0.030291, loss_ce: 0.011654
 30%|████████▊                    | 121/400 [49:42<1:59:53, 25.78s/it]2022-01-20 16:29:55,356 iteration 2058 : loss : 0.036097, loss_ce: 0.016589
2022-01-20 16:29:56,708 iteration 2059 : loss : 0.031592, loss_ce: 0.010228
2022-01-20 16:29:58,087 iteration 2060 : loss : 0.033208, loss_ce: 0.010850
2022-01-20 16:29:59,381 iteration 2061 : loss : 0.025793, loss_ce: 0.011282
2022-01-20 16:30:00,652 iteration 2062 : loss : 0.039131, loss_ce: 0.015078
2022-01-20 16:30:01,953 iteration 2063 : loss : 0.022463, loss_ce: 0.009863
2022-01-20 16:30:03,321 iteration 2064 : loss : 0.026066, loss_ce: 0.011519
2022-01-20 16:30:04,691 iteration 2065 : loss : 0.035038, loss_ce: 0.013049
2022-01-20 16:30:06,079 iteration 2066 : loss : 0.040143, loss_ce: 0.013322
2022-01-20 16:30:07,372 iteration 2067 : loss : 0.039098, loss_ce: 0.016323
2022-01-20 16:30:08,765 iteration 2068 : loss : 0.040890, loss_ce: 0.022074
2022-01-20 16:30:10,165 iteration 2069 : loss : 0.041026, loss_ce: 0.011206
2022-01-20 16:30:11,465 iteration 2070 : loss : 0.028215, loss_ce: 0.010902
2022-01-20 16:30:12,767 iteration 2071 : loss : 0.035952, loss_ce: 0.015432
2022-01-20 16:30:14,032 iteration 2072 : loss : 0.026760, loss_ce: 0.012484
2022-01-20 16:30:15,304 iteration 2073 : loss : 0.028939, loss_ce: 0.009369
2022-01-20 16:30:16,649 iteration 2074 : loss : 0.047782, loss_ce: 0.013056
 30%|████████▊                    | 122/400 [50:05<1:55:15, 24.88s/it]2022-01-20 16:30:18,047 iteration 2075 : loss : 0.036122, loss_ce: 0.012900
2022-01-20 16:30:19,439 iteration 2076 : loss : 0.043699, loss_ce: 0.014508
2022-01-20 16:30:20,774 iteration 2077 : loss : 0.031305, loss_ce: 0.012225
2022-01-20 16:30:22,041 iteration 2078 : loss : 0.032375, loss_ce: 0.013579
2022-01-20 16:30:23,346 iteration 2079 : loss : 0.024051, loss_ce: 0.008844
2022-01-20 16:30:24,723 iteration 2080 : loss : 0.032147, loss_ce: 0.010591
2022-01-20 16:30:26,070 iteration 2081 : loss : 0.038072, loss_ce: 0.015264
2022-01-20 16:30:27,394 iteration 2082 : loss : 0.035756, loss_ce: 0.013132
2022-01-20 16:30:28,698 iteration 2083 : loss : 0.023569, loss_ce: 0.007957
2022-01-20 16:30:30,025 iteration 2084 : loss : 0.039376, loss_ce: 0.014958
2022-01-20 16:30:31,300 iteration 2085 : loss : 0.039448, loss_ce: 0.016277
2022-01-20 16:30:32,598 iteration 2086 : loss : 0.027052, loss_ce: 0.011985
2022-01-20 16:30:33,859 iteration 2087 : loss : 0.038279, loss_ce: 0.011627
2022-01-20 16:30:35,312 iteration 2088 : loss : 0.045712, loss_ce: 0.021594
2022-01-20 16:30:36,604 iteration 2089 : loss : 0.029040, loss_ce: 0.010566
2022-01-20 16:30:37,964 iteration 2090 : loss : 0.035361, loss_ce: 0.012118
2022-01-20 16:30:39,272 iteration 2091 : loss : 0.030953, loss_ce: 0.012573
 31%|████████▉                    | 123/400 [50:27<1:51:42, 24.20s/it]2022-01-20 16:30:40,628 iteration 2092 : loss : 0.026122, loss_ce: 0.010433
2022-01-20 16:30:42,046 iteration 2093 : loss : 0.058349, loss_ce: 0.025548
2022-01-20 16:30:43,388 iteration 2094 : loss : 0.026446, loss_ce: 0.011565
2022-01-20 16:30:44,720 iteration 2095 : loss : 0.032141, loss_ce: 0.013852
2022-01-20 16:30:46,081 iteration 2096 : loss : 0.043369, loss_ce: 0.014956
2022-01-20 16:30:47,345 iteration 2097 : loss : 0.029761, loss_ce: 0.014794
2022-01-20 16:30:48,731 iteration 2098 : loss : 0.036343, loss_ce: 0.012699
2022-01-20 16:30:50,106 iteration 2099 : loss : 0.041753, loss_ce: 0.014511
2022-01-20 16:30:51,529 iteration 2100 : loss : 0.033284, loss_ce: 0.014022
2022-01-20 16:30:52,855 iteration 2101 : loss : 0.048166, loss_ce: 0.013286
2022-01-20 16:30:54,131 iteration 2102 : loss : 0.032098, loss_ce: 0.013187
2022-01-20 16:30:55,575 iteration 2103 : loss : 0.051003, loss_ce: 0.022864
2022-01-20 16:30:56,939 iteration 2104 : loss : 0.031779, loss_ce: 0.012789
2022-01-20 16:30:58,226 iteration 2105 : loss : 0.033527, loss_ce: 0.010077
2022-01-20 16:30:59,643 iteration 2106 : loss : 0.079019, loss_ce: 0.022576
2022-01-20 16:31:00,978 iteration 2107 : loss : 0.037727, loss_ce: 0.014647
2022-01-20 16:31:02,327 iteration 2108 : loss : 0.034283, loss_ce: 0.016118
 31%|████████▉                    | 124/400 [50:50<1:49:44, 23.86s/it]2022-01-20 16:31:03,727 iteration 2109 : loss : 0.050137, loss_ce: 0.021268
2022-01-20 16:31:05,048 iteration 2110 : loss : 0.049837, loss_ce: 0.017476
2022-01-20 16:31:06,533 iteration 2111 : loss : 0.051724, loss_ce: 0.019945
2022-01-20 16:31:08,014 iteration 2112 : loss : 0.046221, loss_ce: 0.023245
2022-01-20 16:31:09,308 iteration 2113 : loss : 0.041051, loss_ce: 0.019088
2022-01-20 16:31:10,618 iteration 2114 : loss : 0.037695, loss_ce: 0.015866
2022-01-20 16:31:11,835 iteration 2115 : loss : 0.042396, loss_ce: 0.013986
2022-01-20 16:31:13,208 iteration 2116 : loss : 0.027966, loss_ce: 0.011279
2022-01-20 16:31:14,631 iteration 2117 : loss : 0.051744, loss_ce: 0.017075
2022-01-20 16:31:15,950 iteration 2118 : loss : 0.035631, loss_ce: 0.014932
2022-01-20 16:31:17,303 iteration 2119 : loss : 0.047768, loss_ce: 0.019151
2022-01-20 16:31:18,631 iteration 2120 : loss : 0.045081, loss_ce: 0.015986
2022-01-20 16:31:20,067 iteration 2121 : loss : 0.042888, loss_ce: 0.016650
2022-01-20 16:31:21,334 iteration 2122 : loss : 0.045157, loss_ce: 0.019978
2022-01-20 16:31:22,633 iteration 2123 : loss : 0.038623, loss_ce: 0.021421
2022-01-20 16:31:23,998 iteration 2124 : loss : 0.033734, loss_ce: 0.011743
2022-01-20 16:31:23,998 Training Data Eval:
2022-01-20 16:31:30,565   Average segmentation loss on training set: 0.0249
2022-01-20 16:31:30,566 Validation Data Eval:
2022-01-20 16:31:32,826   Average segmentation loss on validation set: 0.0700
2022-01-20 16:31:38,819 Found new lowest validation loss at iteration 2124! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 16:31:40,117 iteration 2125 : loss : 0.026059, loss_ce: 0.009383
 31%|█████████                    | 125/400 [51:28<2:08:30, 28.04s/it]2022-01-20 16:31:41,431 iteration 2126 : loss : 0.028478, loss_ce: 0.010057
2022-01-20 16:31:42,767 iteration 2127 : loss : 0.032575, loss_ce: 0.013493
2022-01-20 16:31:43,964 iteration 2128 : loss : 0.034768, loss_ce: 0.017399
2022-01-20 16:31:45,233 iteration 2129 : loss : 0.026370, loss_ce: 0.010876
2022-01-20 16:31:46,421 iteration 2130 : loss : 0.049014, loss_ce: 0.018506
2022-01-20 16:31:47,776 iteration 2131 : loss : 0.052841, loss_ce: 0.024303
2022-01-20 16:31:49,122 iteration 2132 : loss : 0.041117, loss_ce: 0.015058
2022-01-20 16:31:50,443 iteration 2133 : loss : 0.050665, loss_ce: 0.019075
2022-01-20 16:31:51,768 iteration 2134 : loss : 0.054341, loss_ce: 0.017486
2022-01-20 16:31:53,109 iteration 2135 : loss : 0.040593, loss_ce: 0.013391
2022-01-20 16:31:54,454 iteration 2136 : loss : 0.042430, loss_ce: 0.016025
2022-01-20 16:31:55,791 iteration 2137 : loss : 0.055865, loss_ce: 0.014117
2022-01-20 16:31:57,074 iteration 2138 : loss : 0.044176, loss_ce: 0.013596
2022-01-20 16:31:58,304 iteration 2139 : loss : 0.031718, loss_ce: 0.014593
2022-01-20 16:31:59,586 iteration 2140 : loss : 0.036521, loss_ce: 0.011916
2022-01-20 16:32:00,914 iteration 2141 : loss : 0.043151, loss_ce: 0.016901
2022-01-20 16:32:02,235 iteration 2142 : loss : 0.049610, loss_ce: 0.029337
 32%|█████████▏                   | 126/400 [51:50<1:59:56, 26.26s/it]2022-01-20 16:32:03,647 iteration 2143 : loss : 0.041704, loss_ce: 0.016121
2022-01-20 16:32:04,946 iteration 2144 : loss : 0.040218, loss_ce: 0.010661
2022-01-20 16:32:06,158 iteration 2145 : loss : 0.028788, loss_ce: 0.014051
2022-01-20 16:32:07,631 iteration 2146 : loss : 0.054371, loss_ce: 0.019750
2022-01-20 16:32:08,949 iteration 2147 : loss : 0.030614, loss_ce: 0.012476
2022-01-20 16:32:10,259 iteration 2148 : loss : 0.044140, loss_ce: 0.015812
2022-01-20 16:32:11,596 iteration 2149 : loss : 0.048673, loss_ce: 0.019346
2022-01-20 16:32:12,984 iteration 2150 : loss : 0.036704, loss_ce: 0.013183
2022-01-20 16:32:14,367 iteration 2151 : loss : 0.048228, loss_ce: 0.018170
2022-01-20 16:32:15,621 iteration 2152 : loss : 0.037222, loss_ce: 0.014216
2022-01-20 16:32:16,912 iteration 2153 : loss : 0.060925, loss_ce: 0.015284
2022-01-20 16:32:18,162 iteration 2154 : loss : 0.029900, loss_ce: 0.013589
2022-01-20 16:32:19,448 iteration 2155 : loss : 0.037682, loss_ce: 0.014690
2022-01-20 16:32:20,804 iteration 2156 : loss : 0.039437, loss_ce: 0.014366
2022-01-20 16:32:22,143 iteration 2157 : loss : 0.037102, loss_ce: 0.018436
2022-01-20 16:32:23,426 iteration 2158 : loss : 0.041180, loss_ce: 0.018289
2022-01-20 16:32:24,804 iteration 2159 : loss : 0.071310, loss_ce: 0.025261
 32%|█████████▏                   | 127/400 [52:13<1:54:27, 25.16s/it]2022-01-20 16:32:26,106 iteration 2160 : loss : 0.034578, loss_ce: 0.010508
2022-01-20 16:32:27,455 iteration 2161 : loss : 0.036617, loss_ce: 0.014393
2022-01-20 16:32:28,785 iteration 2162 : loss : 0.032661, loss_ce: 0.012263
2022-01-20 16:32:30,017 iteration 2163 : loss : 0.037780, loss_ce: 0.011338
2022-01-20 16:32:31,373 iteration 2164 : loss : 0.033929, loss_ce: 0.015876
2022-01-20 16:32:32,696 iteration 2165 : loss : 0.027584, loss_ce: 0.008433
2022-01-20 16:32:34,078 iteration 2166 : loss : 0.044495, loss_ce: 0.021769
2022-01-20 16:32:35,399 iteration 2167 : loss : 0.034445, loss_ce: 0.016649
2022-01-20 16:32:36,715 iteration 2168 : loss : 0.040659, loss_ce: 0.017586
2022-01-20 16:32:38,060 iteration 2169 : loss : 0.029008, loss_ce: 0.011024
2022-01-20 16:32:39,346 iteration 2170 : loss : 0.034309, loss_ce: 0.011082
2022-01-20 16:32:40,658 iteration 2171 : loss : 0.022962, loss_ce: 0.007765
2022-01-20 16:32:41,878 iteration 2172 : loss : 0.030336, loss_ce: 0.014370
2022-01-20 16:32:43,205 iteration 2173 : loss : 0.041743, loss_ce: 0.013331
2022-01-20 16:32:44,561 iteration 2174 : loss : 0.039075, loss_ce: 0.014195
2022-01-20 16:32:45,812 iteration 2175 : loss : 0.049727, loss_ce: 0.015763
2022-01-20 16:32:47,093 iteration 2176 : loss : 0.043760, loss_ce: 0.022866
 32%|█████████▎                   | 128/400 [52:35<1:50:06, 24.29s/it]2022-01-20 16:32:48,526 iteration 2177 : loss : 0.036905, loss_ce: 0.010849
2022-01-20 16:32:49,766 iteration 2178 : loss : 0.026490, loss_ce: 0.011003
2022-01-20 16:32:51,059 iteration 2179 : loss : 0.029398, loss_ce: 0.012660
2022-01-20 16:32:52,435 iteration 2180 : loss : 0.030451, loss_ce: 0.009318
2022-01-20 16:32:53,712 iteration 2181 : loss : 0.030581, loss_ce: 0.009623
2022-01-20 16:32:55,006 iteration 2182 : loss : 0.053383, loss_ce: 0.018432
2022-01-20 16:32:56,279 iteration 2183 : loss : 0.037708, loss_ce: 0.013348
2022-01-20 16:32:57,523 iteration 2184 : loss : 0.043398, loss_ce: 0.019286
2022-01-20 16:32:58,739 iteration 2185 : loss : 0.029385, loss_ce: 0.011257
2022-01-20 16:33:00,182 iteration 2186 : loss : 0.063214, loss_ce: 0.024708
2022-01-20 16:33:01,405 iteration 2187 : loss : 0.038978, loss_ce: 0.018567
2022-01-20 16:33:02,754 iteration 2188 : loss : 0.038719, loss_ce: 0.016811
2022-01-20 16:33:04,017 iteration 2189 : loss : 0.037133, loss_ce: 0.015643
2022-01-20 16:33:05,379 iteration 2190 : loss : 0.031853, loss_ce: 0.012068
2022-01-20 16:33:06,592 iteration 2191 : loss : 0.030404, loss_ce: 0.012387
2022-01-20 16:33:07,892 iteration 2192 : loss : 0.053390, loss_ce: 0.021458
2022-01-20 16:33:09,277 iteration 2193 : loss : 0.050125, loss_ce: 0.022171
 32%|█████████▎                   | 129/400 [52:57<1:46:52, 23.66s/it]2022-01-20 16:33:10,604 iteration 2194 : loss : 0.042163, loss_ce: 0.016739
2022-01-20 16:33:11,863 iteration 2195 : loss : 0.041518, loss_ce: 0.014001
2022-01-20 16:33:13,178 iteration 2196 : loss : 0.034419, loss_ce: 0.016953
2022-01-20 16:33:14,526 iteration 2197 : loss : 0.055161, loss_ce: 0.019000
2022-01-20 16:33:15,805 iteration 2198 : loss : 0.030451, loss_ce: 0.014592
2022-01-20 16:33:17,283 iteration 2199 : loss : 0.068299, loss_ce: 0.039324
2022-01-20 16:33:18,579 iteration 2200 : loss : 0.035366, loss_ce: 0.014733
2022-01-20 16:33:19,887 iteration 2201 : loss : 0.046898, loss_ce: 0.015023
2022-01-20 16:33:21,179 iteration 2202 : loss : 0.095359, loss_ce: 0.034466
2022-01-20 16:33:22,538 iteration 2203 : loss : 0.032488, loss_ce: 0.011193
2022-01-20 16:33:23,901 iteration 2204 : loss : 0.035672, loss_ce: 0.012632
2022-01-20 16:33:25,101 iteration 2205 : loss : 0.030782, loss_ce: 0.012316
2022-01-20 16:33:26,358 iteration 2206 : loss : 0.026784, loss_ce: 0.012635
2022-01-20 16:33:27,701 iteration 2207 : loss : 0.046318, loss_ce: 0.020022
2022-01-20 16:33:29,023 iteration 2208 : loss : 0.056766, loss_ce: 0.022110
2022-01-20 16:33:30,422 iteration 2209 : loss : 0.053498, loss_ce: 0.019851
2022-01-20 16:33:30,423 Training Data Eval:
2022-01-20 16:33:37,129   Average segmentation loss on training set: 0.0276
2022-01-20 16:33:37,129 Validation Data Eval:
2022-01-20 16:33:39,394   Average segmentation loss on validation set: 0.0810
2022-01-20 16:33:40,751 iteration 2210 : loss : 0.043933, loss_ce: 0.017201
 32%|█████████▍                   | 130/400 [53:29<1:57:01, 26.00s/it]2022-01-20 16:33:42,141 iteration 2211 : loss : 0.038773, loss_ce: 0.018534
2022-01-20 16:33:43,369 iteration 2212 : loss : 0.030972, loss_ce: 0.011253
2022-01-20 16:33:44,636 iteration 2213 : loss : 0.024960, loss_ce: 0.009873
2022-01-20 16:33:45,981 iteration 2214 : loss : 0.029980, loss_ce: 0.012477
2022-01-20 16:33:47,289 iteration 2215 : loss : 0.033306, loss_ce: 0.015018
2022-01-20 16:33:48,571 iteration 2216 : loss : 0.031319, loss_ce: 0.014670
2022-01-20 16:33:49,807 iteration 2217 : loss : 0.031989, loss_ce: 0.015656
2022-01-20 16:33:51,145 iteration 2218 : loss : 0.061946, loss_ce: 0.024964
2022-01-20 16:33:52,457 iteration 2219 : loss : 0.039150, loss_ce: 0.017003
2022-01-20 16:33:53,789 iteration 2220 : loss : 0.032446, loss_ce: 0.016375
2022-01-20 16:33:55,176 iteration 2221 : loss : 0.031457, loss_ce: 0.014414
2022-01-20 16:33:56,450 iteration 2222 : loss : 0.049056, loss_ce: 0.013919
2022-01-20 16:33:57,902 iteration 2223 : loss : 0.056002, loss_ce: 0.018597
2022-01-20 16:33:59,178 iteration 2224 : loss : 0.052342, loss_ce: 0.015572
2022-01-20 16:34:00,477 iteration 2225 : loss : 0.048078, loss_ce: 0.017242
2022-01-20 16:34:01,956 iteration 2226 : loss : 0.048744, loss_ce: 0.016817
2022-01-20 16:34:03,336 iteration 2227 : loss : 0.047016, loss_ce: 0.017046
 33%|█████████▍                   | 131/400 [53:51<1:51:59, 24.98s/it]2022-01-20 16:34:04,771 iteration 2228 : loss : 0.041786, loss_ce: 0.014755
2022-01-20 16:34:06,120 iteration 2229 : loss : 0.045359, loss_ce: 0.020977
2022-01-20 16:34:07,418 iteration 2230 : loss : 0.045978, loss_ce: 0.018372
2022-01-20 16:34:08,700 iteration 2231 : loss : 0.021681, loss_ce: 0.009423
2022-01-20 16:34:09,994 iteration 2232 : loss : 0.027713, loss_ce: 0.010038
2022-01-20 16:34:11,292 iteration 2233 : loss : 0.030051, loss_ce: 0.008782
2022-01-20 16:34:12,646 iteration 2234 : loss : 0.042298, loss_ce: 0.016179
2022-01-20 16:34:13,893 iteration 2235 : loss : 0.038704, loss_ce: 0.016304
2022-01-20 16:34:15,172 iteration 2236 : loss : 0.029653, loss_ce: 0.011061
2022-01-20 16:34:16,488 iteration 2237 : loss : 0.040179, loss_ce: 0.019260
2022-01-20 16:34:17,776 iteration 2238 : loss : 0.054499, loss_ce: 0.017011
2022-01-20 16:34:19,123 iteration 2239 : loss : 0.041870, loss_ce: 0.014494
2022-01-20 16:34:20,373 iteration 2240 : loss : 0.027433, loss_ce: 0.010476
2022-01-20 16:34:21,729 iteration 2241 : loss : 0.032718, loss_ce: 0.012992
2022-01-20 16:34:22,969 iteration 2242 : loss : 0.037638, loss_ce: 0.016326
2022-01-20 16:34:24,228 iteration 2243 : loss : 0.035385, loss_ce: 0.009350
2022-01-20 16:34:25,534 iteration 2244 : loss : 0.027315, loss_ce: 0.010982
 33%|█████████▌                   | 132/400 [54:14<1:47:50, 24.14s/it]2022-01-20 16:34:26,872 iteration 2245 : loss : 0.025024, loss_ce: 0.009542
2022-01-20 16:34:28,206 iteration 2246 : loss : 0.034378, loss_ce: 0.014627
2022-01-20 16:34:29,516 iteration 2247 : loss : 0.043786, loss_ce: 0.015592
2022-01-20 16:34:30,721 iteration 2248 : loss : 0.022018, loss_ce: 0.009866
2022-01-20 16:34:32,112 iteration 2249 : loss : 0.039286, loss_ce: 0.016620
2022-01-20 16:34:33,600 iteration 2250 : loss : 0.034851, loss_ce: 0.015508
2022-01-20 16:34:34,832 iteration 2251 : loss : 0.027421, loss_ce: 0.011505
2022-01-20 16:34:36,175 iteration 2252 : loss : 0.035781, loss_ce: 0.012792
2022-01-20 16:34:37,442 iteration 2253 : loss : 0.048429, loss_ce: 0.014686
2022-01-20 16:34:38,828 iteration 2254 : loss : 0.040165, loss_ce: 0.021050
2022-01-20 16:34:40,196 iteration 2255 : loss : 0.034139, loss_ce: 0.015480
2022-01-20 16:34:41,604 iteration 2256 : loss : 0.057551, loss_ce: 0.026484
2022-01-20 16:34:42,880 iteration 2257 : loss : 0.038681, loss_ce: 0.011833
2022-01-20 16:34:44,188 iteration 2258 : loss : 0.034696, loss_ce: 0.013644
2022-01-20 16:34:45,544 iteration 2259 : loss : 0.045438, loss_ce: 0.016830
2022-01-20 16:34:46,872 iteration 2260 : loss : 0.042829, loss_ce: 0.017679
2022-01-20 16:34:48,131 iteration 2261 : loss : 0.044714, loss_ce: 0.010536
 33%|█████████▋                   | 133/400 [54:36<1:45:23, 23.68s/it]2022-01-20 16:34:49,636 iteration 2262 : loss : 0.044994, loss_ce: 0.020034
2022-01-20 16:34:50,950 iteration 2263 : loss : 0.030785, loss_ce: 0.011785
2022-01-20 16:34:52,286 iteration 2264 : loss : 0.039890, loss_ce: 0.011798
2022-01-20 16:34:53,619 iteration 2265 : loss : 0.029350, loss_ce: 0.010806
2022-01-20 16:34:54,913 iteration 2266 : loss : 0.030368, loss_ce: 0.011081
2022-01-20 16:34:56,218 iteration 2267 : loss : 0.031173, loss_ce: 0.010674
2022-01-20 16:34:57,444 iteration 2268 : loss : 0.031777, loss_ce: 0.013368
2022-01-20 16:34:58,783 iteration 2269 : loss : 0.051012, loss_ce: 0.022553
2022-01-20 16:35:00,045 iteration 2270 : loss : 0.034569, loss_ce: 0.013428
2022-01-20 16:35:01,312 iteration 2271 : loss : 0.053696, loss_ce: 0.029378
2022-01-20 16:35:02,560 iteration 2272 : loss : 0.030427, loss_ce: 0.011385
2022-01-20 16:35:03,916 iteration 2273 : loss : 0.049647, loss_ce: 0.015085
2022-01-20 16:35:05,141 iteration 2274 : loss : 0.030005, loss_ce: 0.008527
2022-01-20 16:35:06,416 iteration 2275 : loss : 0.028811, loss_ce: 0.012578
2022-01-20 16:35:07,719 iteration 2276 : loss : 0.036485, loss_ce: 0.010532
2022-01-20 16:35:09,001 iteration 2277 : loss : 0.031629, loss_ce: 0.014232
2022-01-20 16:35:10,309 iteration 2278 : loss : 0.031430, loss_ce: 0.013808
 34%|█████████▋                   | 134/400 [54:58<1:42:59, 23.23s/it]2022-01-20 16:35:11,795 iteration 2279 : loss : 0.046716, loss_ce: 0.022626
2022-01-20 16:35:13,153 iteration 2280 : loss : 0.031266, loss_ce: 0.013238
2022-01-20 16:35:14,396 iteration 2281 : loss : 0.027115, loss_ce: 0.009462
2022-01-20 16:35:15,868 iteration 2282 : loss : 0.035752, loss_ce: 0.013766
2022-01-20 16:35:17,175 iteration 2283 : loss : 0.028139, loss_ce: 0.010838
2022-01-20 16:35:18,650 iteration 2284 : loss : 0.045637, loss_ce: 0.016487
2022-01-20 16:35:19,954 iteration 2285 : loss : 0.027171, loss_ce: 0.009383
2022-01-20 16:35:21,289 iteration 2286 : loss : 0.026052, loss_ce: 0.009195
2022-01-20 16:35:22,707 iteration 2287 : loss : 0.041982, loss_ce: 0.010806
2022-01-20 16:35:23,990 iteration 2288 : loss : 0.036099, loss_ce: 0.014255
2022-01-20 16:35:25,384 iteration 2289 : loss : 0.029127, loss_ce: 0.011176
2022-01-20 16:35:26,768 iteration 2290 : loss : 0.023439, loss_ce: 0.008957
2022-01-20 16:35:28,124 iteration 2291 : loss : 0.035258, loss_ce: 0.012924
2022-01-20 16:35:29,565 iteration 2292 : loss : 0.045076, loss_ce: 0.013914
2022-01-20 16:35:30,862 iteration 2293 : loss : 0.052731, loss_ce: 0.024975
2022-01-20 16:35:32,206 iteration 2294 : loss : 0.030922, loss_ce: 0.013456
2022-01-20 16:35:32,206 Training Data Eval:
2022-01-20 16:35:38,967   Average segmentation loss on training set: 0.0219
2022-01-20 16:35:38,967 Validation Data Eval:
2022-01-20 16:35:41,250   Average segmentation loss on validation set: 0.0831
2022-01-20 16:35:42,630 iteration 2295 : loss : 0.028554, loss_ce: 0.010244
 34%|█████████▊                   | 135/400 [55:31<1:54:38, 25.96s/it]2022-01-20 16:35:44,067 iteration 2296 : loss : 0.033192, loss_ce: 0.011823
2022-01-20 16:35:45,451 iteration 2297 : loss : 0.030908, loss_ce: 0.010231
2022-01-20 16:35:46,970 iteration 2298 : loss : 0.047407, loss_ce: 0.017455
2022-01-20 16:35:48,337 iteration 2299 : loss : 0.049191, loss_ce: 0.013931
2022-01-20 16:35:49,816 iteration 2300 : loss : 0.037093, loss_ce: 0.013169
2022-01-20 16:35:51,188 iteration 2301 : loss : 0.032581, loss_ce: 0.013930
2022-01-20 16:35:52,547 iteration 2302 : loss : 0.028815, loss_ce: 0.013801
2022-01-20 16:35:53,878 iteration 2303 : loss : 0.040819, loss_ce: 0.012500
2022-01-20 16:35:55,154 iteration 2304 : loss : 0.038083, loss_ce: 0.015826
2022-01-20 16:35:56,572 iteration 2305 : loss : 0.032216, loss_ce: 0.011458
2022-01-20 16:35:57,891 iteration 2306 : loss : 0.029543, loss_ce: 0.010565
2022-01-20 16:35:59,192 iteration 2307 : loss : 0.029998, loss_ce: 0.009643
2022-01-20 16:36:00,534 iteration 2308 : loss : 0.038301, loss_ce: 0.017728
2022-01-20 16:36:01,939 iteration 2309 : loss : 0.033323, loss_ce: 0.012977
2022-01-20 16:36:03,356 iteration 2310 : loss : 0.039923, loss_ce: 0.018433
2022-01-20 16:36:04,855 iteration 2311 : loss : 0.029078, loss_ce: 0.010611
2022-01-20 16:36:06,251 iteration 2312 : loss : 0.031558, loss_ce: 0.015472
 34%|█████████▊                   | 136/400 [55:54<1:51:07, 25.26s/it]2022-01-20 16:36:07,695 iteration 2313 : loss : 0.037676, loss_ce: 0.016382
2022-01-20 16:36:09,019 iteration 2314 : loss : 0.035619, loss_ce: 0.014528
2022-01-20 16:36:10,406 iteration 2315 : loss : 0.034064, loss_ce: 0.014252
2022-01-20 16:36:11,822 iteration 2316 : loss : 0.026576, loss_ce: 0.012955
2022-01-20 16:36:13,105 iteration 2317 : loss : 0.035220, loss_ce: 0.013540
2022-01-20 16:36:14,554 iteration 2318 : loss : 0.028328, loss_ce: 0.013718
2022-01-20 16:36:16,025 iteration 2319 : loss : 0.047837, loss_ce: 0.016458
2022-01-20 16:36:17,333 iteration 2320 : loss : 0.033601, loss_ce: 0.016367
2022-01-20 16:36:18,710 iteration 2321 : loss : 0.044719, loss_ce: 0.014699
2022-01-20 16:36:20,083 iteration 2322 : loss : 0.030417, loss_ce: 0.011557
2022-01-20 16:36:21,524 iteration 2323 : loss : 0.076244, loss_ce: 0.021762
2022-01-20 16:36:22,893 iteration 2324 : loss : 0.031020, loss_ce: 0.009893
2022-01-20 16:36:24,243 iteration 2325 : loss : 0.031175, loss_ce: 0.016683
2022-01-20 16:36:25,638 iteration 2326 : loss : 0.030487, loss_ce: 0.016178
2022-01-20 16:36:26,965 iteration 2327 : loss : 0.032542, loss_ce: 0.012900
2022-01-20 16:36:28,423 iteration 2328 : loss : 0.045083, loss_ce: 0.015803
2022-01-20 16:36:29,780 iteration 2329 : loss : 0.054137, loss_ce: 0.020071
 34%|█████████▉                   | 137/400 [56:18<1:48:26, 24.74s/it]2022-01-20 16:36:31,184 iteration 2330 : loss : 0.028015, loss_ce: 0.011293
2022-01-20 16:36:32,468 iteration 2331 : loss : 0.037498, loss_ce: 0.009841
2022-01-20 16:36:33,946 iteration 2332 : loss : 0.048694, loss_ce: 0.023886
2022-01-20 16:36:35,252 iteration 2333 : loss : 0.027926, loss_ce: 0.014944
2022-01-20 16:36:36,617 iteration 2334 : loss : 0.047695, loss_ce: 0.010518
2022-01-20 16:36:38,126 iteration 2335 : loss : 0.045504, loss_ce: 0.021235
2022-01-20 16:36:39,455 iteration 2336 : loss : 0.034824, loss_ce: 0.016541
2022-01-20 16:36:40,825 iteration 2337 : loss : 0.033053, loss_ce: 0.011145
2022-01-20 16:36:42,236 iteration 2338 : loss : 0.037391, loss_ce: 0.013661
2022-01-20 16:36:43,592 iteration 2339 : loss : 0.059368, loss_ce: 0.021351
2022-01-20 16:36:44,992 iteration 2340 : loss : 0.047676, loss_ce: 0.019810
2022-01-20 16:36:46,346 iteration 2341 : loss : 0.032991, loss_ce: 0.011954
2022-01-20 16:36:47,707 iteration 2342 : loss : 0.035542, loss_ce: 0.011528
2022-01-20 16:36:49,044 iteration 2343 : loss : 0.028860, loss_ce: 0.010395
2022-01-20 16:36:50,284 iteration 2344 : loss : 0.025667, loss_ce: 0.009988
2022-01-20 16:36:51,577 iteration 2345 : loss : 0.032977, loss_ce: 0.013529
2022-01-20 16:36:52,802 iteration 2346 : loss : 0.031822, loss_ce: 0.011696
 34%|██████████                   | 138/400 [56:41<1:45:46, 24.22s/it]2022-01-20 16:36:54,249 iteration 2347 : loss : 0.041046, loss_ce: 0.014916
2022-01-20 16:36:55,530 iteration 2348 : loss : 0.032661, loss_ce: 0.010664
2022-01-20 16:36:56,862 iteration 2349 : loss : 0.054656, loss_ce: 0.028344
2022-01-20 16:36:58,097 iteration 2350 : loss : 0.028022, loss_ce: 0.014273
2022-01-20 16:36:59,429 iteration 2351 : loss : 0.037780, loss_ce: 0.013853
2022-01-20 16:37:00,878 iteration 2352 : loss : 0.034576, loss_ce: 0.014745
2022-01-20 16:37:02,090 iteration 2353 : loss : 0.026498, loss_ce: 0.011593
2022-01-20 16:37:03,411 iteration 2354 : loss : 0.046654, loss_ce: 0.012406
2022-01-20 16:37:04,662 iteration 2355 : loss : 0.035018, loss_ce: 0.018359
2022-01-20 16:37:06,104 iteration 2356 : loss : 0.040756, loss_ce: 0.014201
2022-01-20 16:37:07,500 iteration 2357 : loss : 0.038706, loss_ce: 0.018032
2022-01-20 16:37:08,924 iteration 2358 : loss : 0.057249, loss_ce: 0.020879
2022-01-20 16:37:10,313 iteration 2359 : loss : 0.045200, loss_ce: 0.010614
2022-01-20 16:37:11,511 iteration 2360 : loss : 0.044255, loss_ce: 0.007527
2022-01-20 16:37:12,750 iteration 2361 : loss : 0.041900, loss_ce: 0.014099
2022-01-20 16:37:14,072 iteration 2362 : loss : 0.041308, loss_ce: 0.017137
2022-01-20 16:37:15,389 iteration 2363 : loss : 0.041279, loss_ce: 0.014017
 35%|██████████                   | 139/400 [57:03<1:43:14, 23.73s/it]2022-01-20 16:37:16,776 iteration 2364 : loss : 0.051875, loss_ce: 0.021608
2022-01-20 16:37:18,013 iteration 2365 : loss : 0.034979, loss_ce: 0.012447
2022-01-20 16:37:19,349 iteration 2366 : loss : 0.032488, loss_ce: 0.014322
2022-01-20 16:37:20,633 iteration 2367 : loss : 0.038422, loss_ce: 0.011199
2022-01-20 16:37:22,050 iteration 2368 : loss : 0.073632, loss_ce: 0.024822
2022-01-20 16:37:23,350 iteration 2369 : loss : 0.045790, loss_ce: 0.015023
2022-01-20 16:37:24,619 iteration 2370 : loss : 0.026387, loss_ce: 0.008344
2022-01-20 16:37:25,937 iteration 2371 : loss : 0.048909, loss_ce: 0.022187
2022-01-20 16:37:27,177 iteration 2372 : loss : 0.028028, loss_ce: 0.014425
2022-01-20 16:37:28,495 iteration 2373 : loss : 0.032060, loss_ce: 0.012396
2022-01-20 16:37:29,851 iteration 2374 : loss : 0.034173, loss_ce: 0.012597
2022-01-20 16:37:31,088 iteration 2375 : loss : 0.030783, loss_ce: 0.010495
2022-01-20 16:37:32,453 iteration 2376 : loss : 0.037189, loss_ce: 0.016424
2022-01-20 16:37:33,749 iteration 2377 : loss : 0.048092, loss_ce: 0.012250
2022-01-20 16:37:35,164 iteration 2378 : loss : 0.043186, loss_ce: 0.020433
2022-01-20 16:37:36,502 iteration 2379 : loss : 0.036206, loss_ce: 0.011574
2022-01-20 16:37:36,502 Training Data Eval:
2022-01-20 16:37:42,973   Average segmentation loss on training set: 0.0309
2022-01-20 16:37:42,974 Validation Data Eval:
2022-01-20 16:37:45,192   Average segmentation loss on validation set: 0.0752
2022-01-20 16:37:46,644 iteration 2380 : loss : 0.035621, loss_ce: 0.014103
 35%|██████████▏                  | 140/400 [57:35<1:52:36, 25.98s/it]2022-01-20 16:37:47,950 iteration 2381 : loss : 0.032922, loss_ce: 0.011008
2022-01-20 16:37:49,302 iteration 2382 : loss : 0.042980, loss_ce: 0.022109
2022-01-20 16:37:50,657 iteration 2383 : loss : 0.055764, loss_ce: 0.028951
2022-01-20 16:37:51,943 iteration 2384 : loss : 0.031179, loss_ce: 0.009716
2022-01-20 16:37:53,257 iteration 2385 : loss : 0.053870, loss_ce: 0.027390
2022-01-20 16:37:54,655 iteration 2386 : loss : 0.041453, loss_ce: 0.015048
2022-01-20 16:37:55,918 iteration 2387 : loss : 0.037986, loss_ce: 0.012985
2022-01-20 16:37:57,245 iteration 2388 : loss : 0.023362, loss_ce: 0.010103
2022-01-20 16:37:58,501 iteration 2389 : loss : 0.051809, loss_ce: 0.020080
2022-01-20 16:37:59,825 iteration 2390 : loss : 0.032151, loss_ce: 0.013532
2022-01-20 16:38:01,084 iteration 2391 : loss : 0.032527, loss_ce: 0.011839
2022-01-20 16:38:02,316 iteration 2392 : loss : 0.029111, loss_ce: 0.012240
2022-01-20 16:38:03,555 iteration 2393 : loss : 0.030861, loss_ce: 0.015576
2022-01-20 16:38:04,870 iteration 2394 : loss : 0.044955, loss_ce: 0.009645
2022-01-20 16:38:06,324 iteration 2395 : loss : 0.039613, loss_ce: 0.014197
2022-01-20 16:38:07,704 iteration 2396 : loss : 0.028338, loss_ce: 0.010859
2022-01-20 16:38:09,011 iteration 2397 : loss : 0.037466, loss_ce: 0.012255
 35%|██████████▏                  | 141/400 [57:57<1:47:29, 24.90s/it]2022-01-20 16:38:10,499 iteration 2398 : loss : 0.045774, loss_ce: 0.022905
2022-01-20 16:38:11,709 iteration 2399 : loss : 0.032705, loss_ce: 0.011609
2022-01-20 16:38:12,975 iteration 2400 : loss : 0.026377, loss_ce: 0.007062
2022-01-20 16:38:14,299 iteration 2401 : loss : 0.034101, loss_ce: 0.012260
2022-01-20 16:38:15,561 iteration 2402 : loss : 0.032916, loss_ce: 0.013319
2022-01-20 16:38:16,856 iteration 2403 : loss : 0.026306, loss_ce: 0.009571
2022-01-20 16:38:18,114 iteration 2404 : loss : 0.032778, loss_ce: 0.015550
2022-01-20 16:38:19,407 iteration 2405 : loss : 0.028571, loss_ce: 0.010305
2022-01-20 16:38:20,780 iteration 2406 : loss : 0.039192, loss_ce: 0.017036
2022-01-20 16:38:22,015 iteration 2407 : loss : 0.032128, loss_ce: 0.010894
2022-01-20 16:38:23,310 iteration 2408 : loss : 0.029227, loss_ce: 0.011637
2022-01-20 16:38:24,617 iteration 2409 : loss : 0.036120, loss_ce: 0.013765
2022-01-20 16:38:25,958 iteration 2410 : loss : 0.059102, loss_ce: 0.014861
2022-01-20 16:38:27,190 iteration 2411 : loss : 0.024521, loss_ce: 0.008007
2022-01-20 16:38:28,564 iteration 2412 : loss : 0.034328, loss_ce: 0.011665
2022-01-20 16:38:29,960 iteration 2413 : loss : 0.042149, loss_ce: 0.019681
2022-01-20 16:38:31,317 iteration 2414 : loss : 0.044540, loss_ce: 0.019444
 36%|██████████▎                  | 142/400 [58:19<1:43:42, 24.12s/it]2022-01-20 16:38:32,682 iteration 2415 : loss : 0.028431, loss_ce: 0.009430
2022-01-20 16:38:33,979 iteration 2416 : loss : 0.038612, loss_ce: 0.017096
2022-01-20 16:38:35,301 iteration 2417 : loss : 0.029536, loss_ce: 0.009307
2022-01-20 16:38:36,649 iteration 2418 : loss : 0.041400, loss_ce: 0.012156
2022-01-20 16:38:37,955 iteration 2419 : loss : 0.046376, loss_ce: 0.023427
2022-01-20 16:38:39,193 iteration 2420 : loss : 0.027640, loss_ce: 0.009983
2022-01-20 16:38:40,617 iteration 2421 : loss : 0.041444, loss_ce: 0.012295
2022-01-20 16:38:41,944 iteration 2422 : loss : 0.055517, loss_ce: 0.018897
2022-01-20 16:38:43,249 iteration 2423 : loss : 0.028866, loss_ce: 0.012444
2022-01-20 16:38:44,486 iteration 2424 : loss : 0.030968, loss_ce: 0.010509
2022-01-20 16:38:45,886 iteration 2425 : loss : 0.036358, loss_ce: 0.015281
2022-01-20 16:38:47,197 iteration 2426 : loss : 0.032316, loss_ce: 0.013391
2022-01-20 16:38:48,632 iteration 2427 : loss : 0.067955, loss_ce: 0.020359
2022-01-20 16:38:50,041 iteration 2428 : loss : 0.044091, loss_ce: 0.018160
2022-01-20 16:38:51,470 iteration 2429 : loss : 0.039987, loss_ce: 0.016387
2022-01-20 16:38:52,820 iteration 2430 : loss : 0.035969, loss_ce: 0.013778
2022-01-20 16:38:54,107 iteration 2431 : loss : 0.022158, loss_ce: 0.010482
 36%|██████████▎                  | 143/400 [58:42<1:41:37, 23.73s/it]2022-01-20 16:38:55,554 iteration 2432 : loss : 0.028255, loss_ce: 0.011827
2022-01-20 16:38:56,894 iteration 2433 : loss : 0.068266, loss_ce: 0.023583
2022-01-20 16:38:58,232 iteration 2434 : loss : 0.021936, loss_ce: 0.005981
2022-01-20 16:38:59,717 iteration 2435 : loss : 0.035677, loss_ce: 0.020485
2022-01-20 16:39:00,942 iteration 2436 : loss : 0.023964, loss_ce: 0.008786
2022-01-20 16:39:02,199 iteration 2437 : loss : 0.026863, loss_ce: 0.011364
2022-01-20 16:39:03,680 iteration 2438 : loss : 0.036907, loss_ce: 0.014775
2022-01-20 16:39:05,039 iteration 2439 : loss : 0.041492, loss_ce: 0.020014
2022-01-20 16:39:06,322 iteration 2440 : loss : 0.030987, loss_ce: 0.009869
2022-01-20 16:39:07,595 iteration 2441 : loss : 0.036484, loss_ce: 0.009999
2022-01-20 16:39:08,856 iteration 2442 : loss : 0.033252, loss_ce: 0.011138
2022-01-20 16:39:10,091 iteration 2443 : loss : 0.036034, loss_ce: 0.016765
2022-01-20 16:39:11,447 iteration 2444 : loss : 0.024186, loss_ce: 0.008817
2022-01-20 16:39:12,673 iteration 2445 : loss : 0.041292, loss_ce: 0.009078
2022-01-20 16:39:14,109 iteration 2446 : loss : 0.027374, loss_ce: 0.008819
2022-01-20 16:39:15,515 iteration 2447 : loss : 0.041165, loss_ce: 0.018701
2022-01-20 16:39:16,836 iteration 2448 : loss : 0.026984, loss_ce: 0.009237
 36%|██████████▍                  | 144/400 [59:05<1:39:57, 23.43s/it]2022-01-20 16:39:18,185 iteration 2449 : loss : 0.039708, loss_ce: 0.017891
2022-01-20 16:39:19,573 iteration 2450 : loss : 0.038964, loss_ce: 0.012313
2022-01-20 16:39:20,955 iteration 2451 : loss : 0.029670, loss_ce: 0.010511
2022-01-20 16:39:22,183 iteration 2452 : loss : 0.022009, loss_ce: 0.010320
2022-01-20 16:39:23,482 iteration 2453 : loss : 0.064536, loss_ce: 0.018969
2022-01-20 16:39:24,841 iteration 2454 : loss : 0.029440, loss_ce: 0.013530
2022-01-20 16:39:26,196 iteration 2455 : loss : 0.040755, loss_ce: 0.018921
2022-01-20 16:39:27,663 iteration 2456 : loss : 0.046759, loss_ce: 0.020449
2022-01-20 16:39:28,975 iteration 2457 : loss : 0.041963, loss_ce: 0.013267
2022-01-20 16:39:30,370 iteration 2458 : loss : 0.034110, loss_ce: 0.010445
2022-01-20 16:39:31,625 iteration 2459 : loss : 0.044725, loss_ce: 0.014270
2022-01-20 16:39:32,933 iteration 2460 : loss : 0.033175, loss_ce: 0.008492
2022-01-20 16:39:34,281 iteration 2461 : loss : 0.031394, loss_ce: 0.010523
2022-01-20 16:39:35,592 iteration 2462 : loss : 0.023669, loss_ce: 0.010591
2022-01-20 16:39:36,965 iteration 2463 : loss : 0.029033, loss_ce: 0.011366
2022-01-20 16:39:38,399 iteration 2464 : loss : 0.034244, loss_ce: 0.016993
2022-01-20 16:39:38,399 Training Data Eval:
2022-01-20 16:39:45,140   Average segmentation loss on training set: 0.0209
2022-01-20 16:39:45,140 Validation Data Eval:
2022-01-20 16:39:47,423   Average segmentation loss on validation set: 0.0773
2022-01-20 16:39:48,739 iteration 2465 : loss : 0.033993, loss_ce: 0.012093
 36%|██████████▌                  | 145/400 [59:37<1:50:21, 25.97s/it]2022-01-20 16:39:50,112 iteration 2466 : loss : 0.025861, loss_ce: 0.009890
2022-01-20 16:39:51,494 iteration 2467 : loss : 0.037497, loss_ce: 0.022674
2022-01-20 16:39:52,763 iteration 2468 : loss : 0.030706, loss_ce: 0.014091
2022-01-20 16:39:54,013 iteration 2469 : loss : 0.018311, loss_ce: 0.008829
2022-01-20 16:39:55,393 iteration 2470 : loss : 0.042668, loss_ce: 0.018976
2022-01-20 16:39:56,781 iteration 2471 : loss : 0.032055, loss_ce: 0.012684
2022-01-20 16:39:58,201 iteration 2472 : loss : 0.034271, loss_ce: 0.013154
2022-01-20 16:39:59,427 iteration 2473 : loss : 0.032257, loss_ce: 0.013795
2022-01-20 16:40:00,767 iteration 2474 : loss : 0.036980, loss_ce: 0.014592
2022-01-20 16:40:02,014 iteration 2475 : loss : 0.023086, loss_ce: 0.010428
2022-01-20 16:40:03,427 iteration 2476 : loss : 0.043200, loss_ce: 0.011557
2022-01-20 16:40:04,752 iteration 2477 : loss : 0.032046, loss_ce: 0.013002
2022-01-20 16:40:06,072 iteration 2478 : loss : 0.024093, loss_ce: 0.006980
2022-01-20 16:40:07,532 iteration 2479 : loss : 0.026896, loss_ce: 0.008503
2022-01-20 16:40:08,933 iteration 2480 : loss : 0.038659, loss_ce: 0.017223
2022-01-20 16:40:10,235 iteration 2481 : loss : 0.028186, loss_ce: 0.011074
2022-01-20 16:40:11,573 iteration 2482 : loss : 0.028211, loss_ce: 0.010288
 36%|█████████▊                 | 146/400 [1:00:00<1:45:57, 25.03s/it]2022-01-20 16:40:12,966 iteration 2483 : loss : 0.029356, loss_ce: 0.010717
2022-01-20 16:40:14,341 iteration 2484 : loss : 0.026344, loss_ce: 0.008628
2022-01-20 16:40:15,787 iteration 2485 : loss : 0.031626, loss_ce: 0.011220
2022-01-20 16:40:17,041 iteration 2486 : loss : 0.023141, loss_ce: 0.010529
2022-01-20 16:40:18,325 iteration 2487 : loss : 0.029234, loss_ce: 0.010713
2022-01-20 16:40:19,703 iteration 2488 : loss : 0.031089, loss_ce: 0.009420
2022-01-20 16:40:21,089 iteration 2489 : loss : 0.036843, loss_ce: 0.014803
2022-01-20 16:40:22,380 iteration 2490 : loss : 0.027075, loss_ce: 0.011444
2022-01-20 16:40:23,721 iteration 2491 : loss : 0.030112, loss_ce: 0.012525
2022-01-20 16:40:25,006 iteration 2492 : loss : 0.040254, loss_ce: 0.015834
2022-01-20 16:40:26,316 iteration 2493 : loss : 0.022636, loss_ce: 0.007482
2022-01-20 16:40:27,596 iteration 2494 : loss : 0.030582, loss_ce: 0.011755
2022-01-20 16:40:28,918 iteration 2495 : loss : 0.033100, loss_ce: 0.010390
2022-01-20 16:40:30,292 iteration 2496 : loss : 0.041182, loss_ce: 0.010570
2022-01-20 16:40:31,596 iteration 2497 : loss : 0.032798, loss_ce: 0.014103
2022-01-20 16:40:32,815 iteration 2498 : loss : 0.029107, loss_ce: 0.013524
2022-01-20 16:40:34,198 iteration 2499 : loss : 0.031812, loss_ce: 0.014526
 37%|█████████▉                 | 147/400 [1:00:22<1:42:28, 24.30s/it]2022-01-20 16:40:35,609 iteration 2500 : loss : 0.037166, loss_ce: 0.014993
2022-01-20 16:40:36,874 iteration 2501 : loss : 0.027695, loss_ce: 0.009039
2022-01-20 16:40:38,181 iteration 2502 : loss : 0.026920, loss_ce: 0.009354
2022-01-20 16:40:39,504 iteration 2503 : loss : 0.027311, loss_ce: 0.012016
2022-01-20 16:40:40,852 iteration 2504 : loss : 0.032674, loss_ce: 0.011218
2022-01-20 16:40:42,083 iteration 2505 : loss : 0.022151, loss_ce: 0.009461
2022-01-20 16:40:43,346 iteration 2506 : loss : 0.049217, loss_ce: 0.012687
2022-01-20 16:40:44,699 iteration 2507 : loss : 0.022569, loss_ce: 0.008568
2022-01-20 16:40:45,974 iteration 2508 : loss : 0.025869, loss_ce: 0.012815
2022-01-20 16:40:47,354 iteration 2509 : loss : 0.032711, loss_ce: 0.013313
2022-01-20 16:40:48,642 iteration 2510 : loss : 0.036946, loss_ce: 0.011953
2022-01-20 16:40:49,896 iteration 2511 : loss : 0.024981, loss_ce: 0.011778
2022-01-20 16:40:51,278 iteration 2512 : loss : 0.038231, loss_ce: 0.013697
2022-01-20 16:40:52,548 iteration 2513 : loss : 0.028690, loss_ce: 0.011144
2022-01-20 16:40:53,906 iteration 2514 : loss : 0.033735, loss_ce: 0.010585
2022-01-20 16:40:55,179 iteration 2515 : loss : 0.025243, loss_ce: 0.011616
2022-01-20 16:40:56,661 iteration 2516 : loss : 0.032433, loss_ce: 0.013484
 37%|█████████▉                 | 148/400 [1:00:45<1:39:46, 23.76s/it]2022-01-20 16:40:58,046 iteration 2517 : loss : 0.042304, loss_ce: 0.017372
2022-01-20 16:40:59,373 iteration 2518 : loss : 0.035840, loss_ce: 0.010702
2022-01-20 16:41:00,595 iteration 2519 : loss : 0.019693, loss_ce: 0.006223
2022-01-20 16:41:01,942 iteration 2520 : loss : 0.027756, loss_ce: 0.012625
2022-01-20 16:41:03,269 iteration 2521 : loss : 0.032950, loss_ce: 0.017168
2022-01-20 16:41:04,620 iteration 2522 : loss : 0.035063, loss_ce: 0.015149
2022-01-20 16:41:05,938 iteration 2523 : loss : 0.034564, loss_ce: 0.010424
2022-01-20 16:41:07,306 iteration 2524 : loss : 0.037480, loss_ce: 0.016733
2022-01-20 16:41:08,582 iteration 2525 : loss : 0.028963, loss_ce: 0.008990
2022-01-20 16:41:09,842 iteration 2526 : loss : 0.028625, loss_ce: 0.009634
2022-01-20 16:41:11,189 iteration 2527 : loss : 0.034329, loss_ce: 0.014686
2022-01-20 16:41:12,507 iteration 2528 : loss : 0.031739, loss_ce: 0.015455
2022-01-20 16:41:13,857 iteration 2529 : loss : 0.042589, loss_ce: 0.016098
2022-01-20 16:41:15,105 iteration 2530 : loss : 0.027307, loss_ce: 0.009957
2022-01-20 16:41:16,456 iteration 2531 : loss : 0.042957, loss_ce: 0.014555
2022-01-20 16:41:17,873 iteration 2532 : loss : 0.028336, loss_ce: 0.013772
2022-01-20 16:41:19,114 iteration 2533 : loss : 0.041260, loss_ce: 0.011517
 37%|██████████                 | 149/400 [1:01:07<1:37:43, 23.36s/it]2022-01-20 16:41:20,503 iteration 2534 : loss : 0.031844, loss_ce: 0.012699
2022-01-20 16:41:21,714 iteration 2535 : loss : 0.031706, loss_ce: 0.013284
2022-01-20 16:41:22,990 iteration 2536 : loss : 0.021186, loss_ce: 0.009663
2022-01-20 16:41:24,422 iteration 2537 : loss : 0.033678, loss_ce: 0.015871
2022-01-20 16:41:25,608 iteration 2538 : loss : 0.026305, loss_ce: 0.009042
2022-01-20 16:41:26,876 iteration 2539 : loss : 0.024905, loss_ce: 0.010056
2022-01-20 16:41:28,215 iteration 2540 : loss : 0.030234, loss_ce: 0.012430
2022-01-20 16:41:29,640 iteration 2541 : loss : 0.029719, loss_ce: 0.010546
2022-01-20 16:41:30,971 iteration 2542 : loss : 0.033217, loss_ce: 0.011533
2022-01-20 16:41:32,402 iteration 2543 : loss : 0.034840, loss_ce: 0.011417
2022-01-20 16:41:33,818 iteration 2544 : loss : 0.040798, loss_ce: 0.015373
2022-01-20 16:41:35,087 iteration 2545 : loss : 0.029849, loss_ce: 0.014478
2022-01-20 16:41:36,617 iteration 2546 : loss : 0.050690, loss_ce: 0.021074
2022-01-20 16:41:37,988 iteration 2547 : loss : 0.041322, loss_ce: 0.013282
2022-01-20 16:41:39,391 iteration 2548 : loss : 0.039411, loss_ce: 0.017694
2022-01-20 16:41:40,678 iteration 2549 : loss : 0.040825, loss_ce: 0.016768
2022-01-20 16:41:40,679 Training Data Eval:
2022-01-20 16:41:47,305   Average segmentation loss on training set: 0.0242
2022-01-20 16:41:47,306 Validation Data Eval:
2022-01-20 16:41:49,563   Average segmentation loss on validation set: 0.0804
2022-01-20 16:41:50,899 iteration 2550 : loss : 0.034752, loss_ce: 0.008513
 38%|██████████▏                | 150/400 [1:01:39<1:47:52, 25.89s/it]2022-01-20 16:41:52,288 iteration 2551 : loss : 0.047171, loss_ce: 0.019946
2022-01-20 16:41:53,622 iteration 2552 : loss : 0.020727, loss_ce: 0.008619
2022-01-20 16:41:54,956 iteration 2553 : loss : 0.022512, loss_ce: 0.007866
2022-01-20 16:41:56,259 iteration 2554 : loss : 0.029120, loss_ce: 0.014001
2022-01-20 16:41:57,551 iteration 2555 : loss : 0.027251, loss_ce: 0.011078
2022-01-20 16:41:58,875 iteration 2556 : loss : 0.031108, loss_ce: 0.011761
2022-01-20 16:42:00,182 iteration 2557 : loss : 0.030533, loss_ce: 0.012612
2022-01-20 16:42:01,468 iteration 2558 : loss : 0.022571, loss_ce: 0.007817
2022-01-20 16:42:02,722 iteration 2559 : loss : 0.031720, loss_ce: 0.014471
2022-01-20 16:42:04,136 iteration 2560 : loss : 0.027284, loss_ce: 0.008640
2022-01-20 16:42:05,439 iteration 2561 : loss : 0.031089, loss_ce: 0.010370
2022-01-20 16:42:06,770 iteration 2562 : loss : 0.024395, loss_ce: 0.009868
2022-01-20 16:42:08,011 iteration 2563 : loss : 0.038710, loss_ce: 0.014730
2022-01-20 16:42:09,290 iteration 2564 : loss : 0.021990, loss_ce: 0.010003
2022-01-20 16:42:10,567 iteration 2565 : loss : 0.021086, loss_ce: 0.008488
2022-01-20 16:42:11,805 iteration 2566 : loss : 0.023371, loss_ce: 0.008372
2022-01-20 16:42:13,116 iteration 2567 : loss : 0.036081, loss_ce: 0.008473
 38%|██████████▏                | 151/400 [1:02:01<1:42:52, 24.79s/it]2022-01-20 16:42:14,487 iteration 2568 : loss : 0.027745, loss_ce: 0.012623
2022-01-20 16:42:15,802 iteration 2569 : loss : 0.021105, loss_ce: 0.008062
2022-01-20 16:42:17,234 iteration 2570 : loss : 0.031875, loss_ce: 0.010655
2022-01-20 16:42:18,543 iteration 2571 : loss : 0.026124, loss_ce: 0.007259
2022-01-20 16:42:19,786 iteration 2572 : loss : 0.029065, loss_ce: 0.009098
2022-01-20 16:42:21,078 iteration 2573 : loss : 0.035126, loss_ce: 0.013957
2022-01-20 16:42:22,341 iteration 2574 : loss : 0.028067, loss_ce: 0.012756
2022-01-20 16:42:23,576 iteration 2575 : loss : 0.024807, loss_ce: 0.008488
2022-01-20 16:42:24,818 iteration 2576 : loss : 0.027978, loss_ce: 0.008120
2022-01-20 16:42:26,166 iteration 2577 : loss : 0.035732, loss_ce: 0.018722
2022-01-20 16:42:27,440 iteration 2578 : loss : 0.028338, loss_ce: 0.009308
2022-01-20 16:42:28,766 iteration 2579 : loss : 0.029997, loss_ce: 0.010386
2022-01-20 16:42:30,007 iteration 2580 : loss : 0.033513, loss_ce: 0.009737
2022-01-20 16:42:31,334 iteration 2581 : loss : 0.030231, loss_ce: 0.012992
2022-01-20 16:42:32,711 iteration 2582 : loss : 0.024026, loss_ce: 0.011919
2022-01-20 16:42:33,990 iteration 2583 : loss : 0.029682, loss_ce: 0.014263
2022-01-20 16:42:35,279 iteration 2584 : loss : 0.041352, loss_ce: 0.013220
 38%|██████████▎                | 152/400 [1:02:23<1:39:12, 24.00s/it]2022-01-20 16:42:36,657 iteration 2585 : loss : 0.028988, loss_ce: 0.009777
2022-01-20 16:42:38,165 iteration 2586 : loss : 0.045118, loss_ce: 0.015294
2022-01-20 16:42:39,552 iteration 2587 : loss : 0.029970, loss_ce: 0.010700
2022-01-20 16:42:40,858 iteration 2588 : loss : 0.046113, loss_ce: 0.018000
2022-01-20 16:42:42,089 iteration 2589 : loss : 0.041457, loss_ce: 0.011011
2022-01-20 16:42:43,456 iteration 2590 : loss : 0.043767, loss_ce: 0.017406
2022-01-20 16:42:44,762 iteration 2591 : loss : 0.026707, loss_ce: 0.011248
2022-01-20 16:42:46,028 iteration 2592 : loss : 0.027700, loss_ce: 0.014804
2022-01-20 16:42:47,247 iteration 2593 : loss : 0.030966, loss_ce: 0.014965
2022-01-20 16:42:48,572 iteration 2594 : loss : 0.042804, loss_ce: 0.020894
2022-01-20 16:42:49,814 iteration 2595 : loss : 0.023648, loss_ce: 0.007644
2022-01-20 16:42:51,087 iteration 2596 : loss : 0.034739, loss_ce: 0.011283
2022-01-20 16:42:52,378 iteration 2597 : loss : 0.029722, loss_ce: 0.010350
2022-01-20 16:42:53,693 iteration 2598 : loss : 0.026497, loss_ce: 0.011130
2022-01-20 16:42:55,024 iteration 2599 : loss : 0.029068, loss_ce: 0.011581
2022-01-20 16:42:56,299 iteration 2600 : loss : 0.028821, loss_ce: 0.011964
2022-01-20 16:42:57,554 iteration 2601 : loss : 0.026404, loss_ce: 0.010190
 38%|██████████▎                | 153/400 [1:02:46<1:36:40, 23.48s/it]2022-01-20 16:42:58,899 iteration 2602 : loss : 0.030993, loss_ce: 0.011520
2022-01-20 16:43:00,224 iteration 2603 : loss : 0.044908, loss_ce: 0.010286
2022-01-20 16:43:01,530 iteration 2604 : loss : 0.028202, loss_ce: 0.010537
2022-01-20 16:43:02,839 iteration 2605 : loss : 0.042169, loss_ce: 0.012919
2022-01-20 16:43:04,171 iteration 2606 : loss : 0.033144, loss_ce: 0.012199
2022-01-20 16:43:05,528 iteration 2607 : loss : 0.026339, loss_ce: 0.011543
2022-01-20 16:43:06,820 iteration 2608 : loss : 0.029742, loss_ce: 0.011163
2022-01-20 16:43:08,209 iteration 2609 : loss : 0.027815, loss_ce: 0.010297
2022-01-20 16:43:09,572 iteration 2610 : loss : 0.028557, loss_ce: 0.009465
2022-01-20 16:43:10,974 iteration 2611 : loss : 0.040639, loss_ce: 0.017675
2022-01-20 16:43:12,343 iteration 2612 : loss : 0.037681, loss_ce: 0.012962
2022-01-20 16:43:13,752 iteration 2613 : loss : 0.032217, loss_ce: 0.012363
2022-01-20 16:43:15,125 iteration 2614 : loss : 0.028051, loss_ce: 0.011450
2022-01-20 16:43:16,467 iteration 2615 : loss : 0.046504, loss_ce: 0.022949
2022-01-20 16:43:17,853 iteration 2616 : loss : 0.032075, loss_ce: 0.013947
2022-01-20 16:43:19,185 iteration 2617 : loss : 0.030354, loss_ce: 0.011169
2022-01-20 16:43:20,558 iteration 2618 : loss : 0.028413, loss_ce: 0.008758
 38%|██████████▍                | 154/400 [1:03:09<1:35:41, 23.34s/it]2022-01-20 16:43:22,078 iteration 2619 : loss : 0.037446, loss_ce: 0.016199
2022-01-20 16:43:23,408 iteration 2620 : loss : 0.034606, loss_ce: 0.011159
2022-01-20 16:43:24,601 iteration 2621 : loss : 0.033068, loss_ce: 0.012650
2022-01-20 16:43:25,946 iteration 2622 : loss : 0.054916, loss_ce: 0.021636
2022-01-20 16:43:27,226 iteration 2623 : loss : 0.024517, loss_ce: 0.009870
2022-01-20 16:43:28,607 iteration 2624 : loss : 0.041731, loss_ce: 0.015379
2022-01-20 16:43:30,015 iteration 2625 : loss : 0.031205, loss_ce: 0.012914
2022-01-20 16:43:31,356 iteration 2626 : loss : 0.024947, loss_ce: 0.009567
2022-01-20 16:43:32,574 iteration 2627 : loss : 0.023254, loss_ce: 0.011938
2022-01-20 16:43:33,828 iteration 2628 : loss : 0.023021, loss_ce: 0.009144
2022-01-20 16:43:35,055 iteration 2629 : loss : 0.028375, loss_ce: 0.007295
2022-01-20 16:43:36,419 iteration 2630 : loss : 0.046907, loss_ce: 0.008480
2022-01-20 16:43:37,677 iteration 2631 : loss : 0.035496, loss_ce: 0.016852
2022-01-20 16:43:38,962 iteration 2632 : loss : 0.028288, loss_ce: 0.009508
2022-01-20 16:43:40,315 iteration 2633 : loss : 0.020600, loss_ce: 0.006788
2022-01-20 16:43:41,625 iteration 2634 : loss : 0.028402, loss_ce: 0.010229
2022-01-20 16:43:41,625 Training Data Eval:
2022-01-20 16:43:48,312   Average segmentation loss on training set: 0.0269
2022-01-20 16:43:48,312 Validation Data Eval:
2022-01-20 16:43:50,575   Average segmentation loss on validation set: 0.1311
2022-01-20 16:43:51,879 iteration 2635 : loss : 0.032596, loss_ce: 0.013458
 39%|██████████▍                | 155/400 [1:03:40<1:45:03, 25.73s/it]2022-01-20 16:43:53,202 iteration 2636 : loss : 0.021459, loss_ce: 0.006938
2022-01-20 16:43:54,502 iteration 2637 : loss : 0.020900, loss_ce: 0.009082
2022-01-20 16:43:55,912 iteration 2638 : loss : 0.037038, loss_ce: 0.014630
2022-01-20 16:43:57,212 iteration 2639 : loss : 0.023366, loss_ce: 0.008938
2022-01-20 16:43:58,541 iteration 2640 : loss : 0.033760, loss_ce: 0.011464
2022-01-20 16:43:59,843 iteration 2641 : loss : 0.027071, loss_ce: 0.011118
2022-01-20 16:44:01,188 iteration 2642 : loss : 0.055558, loss_ce: 0.019272
2022-01-20 16:44:02,479 iteration 2643 : loss : 0.028405, loss_ce: 0.011218
2022-01-20 16:44:03,821 iteration 2644 : loss : 0.029425, loss_ce: 0.014645
2022-01-20 16:44:05,058 iteration 2645 : loss : 0.025598, loss_ce: 0.010879
2022-01-20 16:44:06,323 iteration 2646 : loss : 0.026662, loss_ce: 0.007665
2022-01-20 16:44:07,706 iteration 2647 : loss : 0.038055, loss_ce: 0.015993
2022-01-20 16:44:08,963 iteration 2648 : loss : 0.026171, loss_ce: 0.009188
2022-01-20 16:44:10,266 iteration 2649 : loss : 0.032649, loss_ce: 0.010311
2022-01-20 16:44:11,705 iteration 2650 : loss : 0.028590, loss_ce: 0.010069
2022-01-20 16:44:12,991 iteration 2651 : loss : 0.023349, loss_ce: 0.009500
2022-01-20 16:44:14,379 iteration 2652 : loss : 0.029624, loss_ce: 0.011914
 39%|██████████▌                | 156/400 [1:04:02<1:40:41, 24.76s/it]2022-01-20 16:44:15,821 iteration 2653 : loss : 0.030335, loss_ce: 0.011654
2022-01-20 16:44:17,070 iteration 2654 : loss : 0.021495, loss_ce: 0.008484
2022-01-20 16:44:18,378 iteration 2655 : loss : 0.031739, loss_ce: 0.014936
2022-01-20 16:44:19,682 iteration 2656 : loss : 0.022733, loss_ce: 0.011247
2022-01-20 16:44:21,040 iteration 2657 : loss : 0.026543, loss_ce: 0.010896
2022-01-20 16:44:22,420 iteration 2658 : loss : 0.056131, loss_ce: 0.018649
2022-01-20 16:44:23,751 iteration 2659 : loss : 0.030028, loss_ce: 0.012641
2022-01-20 16:44:25,155 iteration 2660 : loss : 0.031757, loss_ce: 0.013523
2022-01-20 16:44:26,372 iteration 2661 : loss : 0.028301, loss_ce: 0.008656
2022-01-20 16:44:27,760 iteration 2662 : loss : 0.033803, loss_ce: 0.012232
2022-01-20 16:44:29,126 iteration 2663 : loss : 0.049901, loss_ce: 0.020606
2022-01-20 16:44:30,364 iteration 2664 : loss : 0.034900, loss_ce: 0.011933
2022-01-20 16:44:31,638 iteration 2665 : loss : 0.014273, loss_ce: 0.005522
2022-01-20 16:44:33,028 iteration 2666 : loss : 0.029438, loss_ce: 0.010041
2022-01-20 16:44:34,277 iteration 2667 : loss : 0.024568, loss_ce: 0.009208
2022-01-20 16:44:35,662 iteration 2668 : loss : 0.030464, loss_ce: 0.012247
2022-01-20 16:44:36,951 iteration 2669 : loss : 0.021193, loss_ce: 0.005487
 39%|██████████▌                | 157/400 [1:04:25<1:37:38, 24.11s/it]2022-01-20 16:44:38,241 iteration 2670 : loss : 0.025271, loss_ce: 0.010271
2022-01-20 16:44:39,466 iteration 2671 : loss : 0.023921, loss_ce: 0.009576
2022-01-20 16:44:40,746 iteration 2672 : loss : 0.034685, loss_ce: 0.011184
2022-01-20 16:44:42,012 iteration 2673 : loss : 0.024874, loss_ce: 0.007686
2022-01-20 16:44:43,344 iteration 2674 : loss : 0.021014, loss_ce: 0.007250
2022-01-20 16:44:44,708 iteration 2675 : loss : 0.026020, loss_ce: 0.009290
2022-01-20 16:44:45,992 iteration 2676 : loss : 0.026464, loss_ce: 0.008465
2022-01-20 16:44:47,286 iteration 2677 : loss : 0.024183, loss_ce: 0.009956
2022-01-20 16:44:48,522 iteration 2678 : loss : 0.023582, loss_ce: 0.010724
2022-01-20 16:44:49,849 iteration 2679 : loss : 0.033807, loss_ce: 0.013882
2022-01-20 16:44:51,229 iteration 2680 : loss : 0.025954, loss_ce: 0.012056
2022-01-20 16:44:52,536 iteration 2681 : loss : 0.029177, loss_ce: 0.010681
2022-01-20 16:44:53,873 iteration 2682 : loss : 0.025929, loss_ce: 0.010627
2022-01-20 16:44:55,142 iteration 2683 : loss : 0.031159, loss_ce: 0.013998
2022-01-20 16:44:56,464 iteration 2684 : loss : 0.027199, loss_ce: 0.011961
2022-01-20 16:44:57,812 iteration 2685 : loss : 0.028364, loss_ce: 0.012567
2022-01-20 16:44:59,151 iteration 2686 : loss : 0.058427, loss_ce: 0.013065
 40%|██████████▋                | 158/400 [1:04:47<1:34:55, 23.54s/it]2022-01-20 16:45:00,479 iteration 2687 : loss : 0.027355, loss_ce: 0.011119
2022-01-20 16:45:01,764 iteration 2688 : loss : 0.026344, loss_ce: 0.009023
2022-01-20 16:45:03,017 iteration 2689 : loss : 0.032320, loss_ce: 0.010201
2022-01-20 16:45:04,383 iteration 2690 : loss : 0.044493, loss_ce: 0.009178
2022-01-20 16:45:05,618 iteration 2691 : loss : 0.022194, loss_ce: 0.008579
2022-01-20 16:45:06,862 iteration 2692 : loss : 0.049062, loss_ce: 0.019807
2022-01-20 16:45:08,094 iteration 2693 : loss : 0.022290, loss_ce: 0.009287
2022-01-20 16:45:09,408 iteration 2694 : loss : 0.025804, loss_ce: 0.011044
2022-01-20 16:45:10,705 iteration 2695 : loss : 0.040920, loss_ce: 0.021921
2022-01-20 16:45:12,000 iteration 2696 : loss : 0.023836, loss_ce: 0.010255
2022-01-20 16:45:13,265 iteration 2697 : loss : 0.031656, loss_ce: 0.014570
2022-01-20 16:45:14,530 iteration 2698 : loss : 0.029324, loss_ce: 0.009913
2022-01-20 16:45:15,820 iteration 2699 : loss : 0.040427, loss_ce: 0.018177
2022-01-20 16:45:17,082 iteration 2700 : loss : 0.050404, loss_ce: 0.017797
2022-01-20 16:45:18,514 iteration 2701 : loss : 0.042005, loss_ce: 0.015934
2022-01-20 16:45:19,851 iteration 2702 : loss : 0.028112, loss_ce: 0.014542
2022-01-20 16:45:21,228 iteration 2703 : loss : 0.042003, loss_ce: 0.015714
 40%|██████████▋                | 159/400 [1:05:09<1:32:46, 23.10s/it]2022-01-20 16:45:22,666 iteration 2704 : loss : 0.041182, loss_ce: 0.013739
2022-01-20 16:45:23,901 iteration 2705 : loss : 0.020931, loss_ce: 0.008996
2022-01-20 16:45:25,247 iteration 2706 : loss : 0.046794, loss_ce: 0.021146
2022-01-20 16:45:26,526 iteration 2707 : loss : 0.035222, loss_ce: 0.018949
2022-01-20 16:45:27,869 iteration 2708 : loss : 0.034547, loss_ce: 0.012827
2022-01-20 16:45:29,157 iteration 2709 : loss : 0.030799, loss_ce: 0.013818
2022-01-20 16:45:30,383 iteration 2710 : loss : 0.022590, loss_ce: 0.009405
2022-01-20 16:45:31,716 iteration 2711 : loss : 0.024461, loss_ce: 0.009182
2022-01-20 16:45:33,070 iteration 2712 : loss : 0.025780, loss_ce: 0.007712
2022-01-20 16:45:34,325 iteration 2713 : loss : 0.024649, loss_ce: 0.013241
2022-01-20 16:45:35,697 iteration 2714 : loss : 0.027659, loss_ce: 0.009910
2022-01-20 16:45:37,041 iteration 2715 : loss : 0.037035, loss_ce: 0.011096
2022-01-20 16:45:38,389 iteration 2716 : loss : 0.025836, loss_ce: 0.008368
2022-01-20 16:45:39,679 iteration 2717 : loss : 0.036699, loss_ce: 0.017596
2022-01-20 16:45:41,030 iteration 2718 : loss : 0.038234, loss_ce: 0.014461
2022-01-20 16:45:42,303 iteration 2719 : loss : 0.027179, loss_ce: 0.009622
2022-01-20 16:45:42,304 Training Data Eval:
2022-01-20 16:45:48,808   Average segmentation loss on training set: 0.0205
2022-01-20 16:45:48,808 Validation Data Eval:
2022-01-20 16:45:51,027   Average segmentation loss on validation set: 0.0897
2022-01-20 16:45:52,294 iteration 2720 : loss : 0.033745, loss_ce: 0.011231
 40%|██████████▊                | 160/400 [1:05:40<1:41:56, 25.48s/it]2022-01-20 16:45:53,698 iteration 2721 : loss : 0.026991, loss_ce: 0.011108
2022-01-20 16:45:55,014 iteration 2722 : loss : 0.052239, loss_ce: 0.022164
2022-01-20 16:45:56,347 iteration 2723 : loss : 0.025264, loss_ce: 0.009103
2022-01-20 16:45:57,659 iteration 2724 : loss : 0.036612, loss_ce: 0.016774
2022-01-20 16:45:58,931 iteration 2725 : loss : 0.027690, loss_ce: 0.009488
2022-01-20 16:46:00,401 iteration 2726 : loss : 0.043467, loss_ce: 0.013528
2022-01-20 16:46:01,763 iteration 2727 : loss : 0.031695, loss_ce: 0.012645
2022-01-20 16:46:03,084 iteration 2728 : loss : 0.020093, loss_ce: 0.007654
2022-01-20 16:46:04,372 iteration 2729 : loss : 0.039833, loss_ce: 0.015852
2022-01-20 16:46:05,612 iteration 2730 : loss : 0.023232, loss_ce: 0.008589
2022-01-20 16:46:06,944 iteration 2731 : loss : 0.025162, loss_ce: 0.009728
2022-01-20 16:46:08,347 iteration 2732 : loss : 0.034971, loss_ce: 0.014804
2022-01-20 16:46:09,677 iteration 2733 : loss : 0.031655, loss_ce: 0.010666
2022-01-20 16:46:11,000 iteration 2734 : loss : 0.028865, loss_ce: 0.009916
2022-01-20 16:46:12,418 iteration 2735 : loss : 0.042378, loss_ce: 0.014906
2022-01-20 16:46:13,713 iteration 2736 : loss : 0.023848, loss_ce: 0.010882
2022-01-20 16:46:15,058 iteration 2737 : loss : 0.030667, loss_ce: 0.011613
 40%|██████████▊                | 161/400 [1:06:03<1:38:16, 24.67s/it]2022-01-20 16:46:16,356 iteration 2738 : loss : 0.019038, loss_ce: 0.007126
2022-01-20 16:46:17,737 iteration 2739 : loss : 0.030302, loss_ce: 0.012271
2022-01-20 16:46:19,130 iteration 2740 : loss : 0.035490, loss_ce: 0.017967
2022-01-20 16:46:20,389 iteration 2741 : loss : 0.027463, loss_ce: 0.010190
2022-01-20 16:46:21,609 iteration 2742 : loss : 0.031321, loss_ce: 0.010254
2022-01-20 16:46:22,941 iteration 2743 : loss : 0.028814, loss_ce: 0.010187
2022-01-20 16:46:24,400 iteration 2744 : loss : 0.048201, loss_ce: 0.019102
2022-01-20 16:46:25,691 iteration 2745 : loss : 0.034364, loss_ce: 0.012727
2022-01-20 16:46:26,964 iteration 2746 : loss : 0.021862, loss_ce: 0.007288
2022-01-20 16:46:28,396 iteration 2747 : loss : 0.043786, loss_ce: 0.018931
2022-01-20 16:46:29,655 iteration 2748 : loss : 0.024004, loss_ce: 0.009142
2022-01-20 16:46:30,975 iteration 2749 : loss : 0.025293, loss_ce: 0.011861
2022-01-20 16:46:32,269 iteration 2750 : loss : 0.031821, loss_ce: 0.010665
2022-01-20 16:46:33,561 iteration 2751 : loss : 0.035828, loss_ce: 0.009127
2022-01-20 16:46:34,834 iteration 2752 : loss : 0.025081, loss_ce: 0.010047
2022-01-20 16:46:36,129 iteration 2753 : loss : 0.032024, loss_ce: 0.012801
2022-01-20 16:46:37,453 iteration 2754 : loss : 0.053591, loss_ce: 0.018782
 40%|██████████▉                | 162/400 [1:06:26<1:35:09, 23.99s/it]2022-01-20 16:46:38,817 iteration 2755 : loss : 0.025827, loss_ce: 0.009780
2022-01-20 16:46:40,124 iteration 2756 : loss : 0.033920, loss_ce: 0.014509
2022-01-20 16:46:41,378 iteration 2757 : loss : 0.025895, loss_ce: 0.010303
2022-01-20 16:46:42,682 iteration 2758 : loss : 0.038527, loss_ce: 0.017866
2022-01-20 16:46:43,985 iteration 2759 : loss : 0.028958, loss_ce: 0.012669
2022-01-20 16:46:45,372 iteration 2760 : loss : 0.046782, loss_ce: 0.012063
2022-01-20 16:46:46,664 iteration 2761 : loss : 0.029778, loss_ce: 0.011701
2022-01-20 16:46:47,945 iteration 2762 : loss : 0.028276, loss_ce: 0.011560
2022-01-20 16:46:49,238 iteration 2763 : loss : 0.030119, loss_ce: 0.013642
2022-01-20 16:46:50,474 iteration 2764 : loss : 0.027819, loss_ce: 0.011435
2022-01-20 16:46:51,779 iteration 2765 : loss : 0.031353, loss_ce: 0.012819
2022-01-20 16:46:53,146 iteration 2766 : loss : 0.037077, loss_ce: 0.014293
2022-01-20 16:46:54,369 iteration 2767 : loss : 0.032785, loss_ce: 0.007831
2022-01-20 16:46:55,797 iteration 2768 : loss : 0.030703, loss_ce: 0.011512
2022-01-20 16:46:57,067 iteration 2769 : loss : 0.025946, loss_ce: 0.008002
2022-01-20 16:46:58,314 iteration 2770 : loss : 0.024092, loss_ce: 0.011764
2022-01-20 16:46:59,612 iteration 2771 : loss : 0.034997, loss_ce: 0.015957
 41%|███████████                | 163/400 [1:06:48<1:32:35, 23.44s/it]2022-01-20 16:47:01,071 iteration 2772 : loss : 0.028458, loss_ce: 0.009427
2022-01-20 16:47:02,295 iteration 2773 : loss : 0.031972, loss_ce: 0.009911
2022-01-20 16:47:03,572 iteration 2774 : loss : 0.024379, loss_ce: 0.009812
2022-01-20 16:47:04,882 iteration 2775 : loss : 0.025381, loss_ce: 0.011978
2022-01-20 16:47:06,197 iteration 2776 : loss : 0.031495, loss_ce: 0.013922
2022-01-20 16:47:07,548 iteration 2777 : loss : 0.038296, loss_ce: 0.015618
2022-01-20 16:47:08,769 iteration 2778 : loss : 0.027842, loss_ce: 0.012630
2022-01-20 16:47:10,125 iteration 2779 : loss : 0.048125, loss_ce: 0.022485
2022-01-20 16:47:11,520 iteration 2780 : loss : 0.039271, loss_ce: 0.017104
2022-01-20 16:47:12,733 iteration 2781 : loss : 0.026414, loss_ce: 0.011056
2022-01-20 16:47:14,076 iteration 2782 : loss : 0.026625, loss_ce: 0.011083
2022-01-20 16:47:15,457 iteration 2783 : loss : 0.033186, loss_ce: 0.012330
2022-01-20 16:47:16,875 iteration 2784 : loss : 0.036825, loss_ce: 0.018221
2022-01-20 16:47:18,105 iteration 2785 : loss : 0.023250, loss_ce: 0.008273
2022-01-20 16:47:19,429 iteration 2786 : loss : 0.046231, loss_ce: 0.013884
2022-01-20 16:47:20,827 iteration 2787 : loss : 0.033030, loss_ce: 0.008342
2022-01-20 16:47:22,126 iteration 2788 : loss : 0.025624, loss_ce: 0.007500
 41%|███████████                | 164/400 [1:07:10<1:31:05, 23.16s/it]2022-01-20 16:47:23,505 iteration 2789 : loss : 0.023975, loss_ce: 0.011652
2022-01-20 16:47:24,771 iteration 2790 : loss : 0.038395, loss_ce: 0.011663
2022-01-20 16:47:26,113 iteration 2791 : loss : 0.022412, loss_ce: 0.006864
2022-01-20 16:47:27,477 iteration 2792 : loss : 0.040883, loss_ce: 0.011188
2022-01-20 16:47:28,783 iteration 2793 : loss : 0.036770, loss_ce: 0.018767
2022-01-20 16:47:30,100 iteration 2794 : loss : 0.027887, loss_ce: 0.011341
2022-01-20 16:47:31,485 iteration 2795 : loss : 0.027898, loss_ce: 0.011282
2022-01-20 16:47:32,893 iteration 2796 : loss : 0.038887, loss_ce: 0.016413
2022-01-20 16:47:34,234 iteration 2797 : loss : 0.028767, loss_ce: 0.012635
2022-01-20 16:47:35,615 iteration 2798 : loss : 0.030899, loss_ce: 0.008604
2022-01-20 16:47:36,978 iteration 2799 : loss : 0.029677, loss_ce: 0.010970
2022-01-20 16:47:38,318 iteration 2800 : loss : 0.025852, loss_ce: 0.013665
2022-01-20 16:47:39,612 iteration 2801 : loss : 0.031855, loss_ce: 0.017575
2022-01-20 16:47:40,859 iteration 2802 : loss : 0.021560, loss_ce: 0.009345
2022-01-20 16:47:42,284 iteration 2803 : loss : 0.033629, loss_ce: 0.012140
2022-01-20 16:47:43,593 iteration 2804 : loss : 0.036930, loss_ce: 0.014787
2022-01-20 16:47:43,593 Training Data Eval:
2022-01-20 16:47:50,106   Average segmentation loss on training set: 0.0237
2022-01-20 16:47:50,107 Validation Data Eval:
2022-01-20 16:47:52,341   Average segmentation loss on validation set: 0.0730
2022-01-20 16:47:53,640 iteration 2805 : loss : 0.036894, loss_ce: 0.013689
 41%|███████████▏               | 165/400 [1:07:42<1:40:31, 25.67s/it]2022-01-20 16:47:55,066 iteration 2806 : loss : 0.026333, loss_ce: 0.008926
2022-01-20 16:47:56,543 iteration 2807 : loss : 0.042569, loss_ce: 0.015004
2022-01-20 16:47:57,741 iteration 2808 : loss : 0.024498, loss_ce: 0.012742
2022-01-20 16:47:59,053 iteration 2809 : loss : 0.030859, loss_ce: 0.012687
2022-01-20 16:48:00,419 iteration 2810 : loss : 0.028578, loss_ce: 0.010766
2022-01-20 16:48:01,695 iteration 2811 : loss : 0.023389, loss_ce: 0.009311
2022-01-20 16:48:03,011 iteration 2812 : loss : 0.027273, loss_ce: 0.010266
2022-01-20 16:48:04,349 iteration 2813 : loss : 0.027808, loss_ce: 0.007945
2022-01-20 16:48:05,655 iteration 2814 : loss : 0.031498, loss_ce: 0.012579
2022-01-20 16:48:06,908 iteration 2815 : loss : 0.025793, loss_ce: 0.011071
2022-01-20 16:48:08,160 iteration 2816 : loss : 0.026641, loss_ce: 0.011417
2022-01-20 16:48:09,432 iteration 2817 : loss : 0.026530, loss_ce: 0.008516
2022-01-20 16:48:10,830 iteration 2818 : loss : 0.028270, loss_ce: 0.008099
2022-01-20 16:48:12,183 iteration 2819 : loss : 0.033914, loss_ce: 0.018420
2022-01-20 16:48:13,607 iteration 2820 : loss : 0.027518, loss_ce: 0.011211
2022-01-20 16:48:14,909 iteration 2821 : loss : 0.026310, loss_ce: 0.012080
2022-01-20 16:48:16,173 iteration 2822 : loss : 0.023310, loss_ce: 0.007160
 42%|███████████▏               | 166/400 [1:08:04<1:36:25, 24.72s/it]2022-01-20 16:48:17,629 iteration 2823 : loss : 0.058305, loss_ce: 0.018491
2022-01-20 16:48:18,875 iteration 2824 : loss : 0.020635, loss_ce: 0.007525
2022-01-20 16:48:20,211 iteration 2825 : loss : 0.055506, loss_ce: 0.034426
2022-01-20 16:48:21,472 iteration 2826 : loss : 0.022197, loss_ce: 0.009621
2022-01-20 16:48:22,818 iteration 2827 : loss : 0.030439, loss_ce: 0.015277
2022-01-20 16:48:24,143 iteration 2828 : loss : 0.025674, loss_ce: 0.011298
2022-01-20 16:48:25,576 iteration 2829 : loss : 0.031340, loss_ce: 0.013123
2022-01-20 16:48:26,806 iteration 2830 : loss : 0.018733, loss_ce: 0.008543
2022-01-20 16:48:28,124 iteration 2831 : loss : 0.039357, loss_ce: 0.017235
2022-01-20 16:48:29,486 iteration 2832 : loss : 0.037450, loss_ce: 0.011954
2022-01-20 16:48:30,855 iteration 2833 : loss : 0.028077, loss_ce: 0.010979
2022-01-20 16:48:32,143 iteration 2834 : loss : 0.040659, loss_ce: 0.014161
2022-01-20 16:48:33,491 iteration 2835 : loss : 0.053017, loss_ce: 0.015402
2022-01-20 16:48:34,870 iteration 2836 : loss : 0.026699, loss_ce: 0.011647
2022-01-20 16:48:36,170 iteration 2837 : loss : 0.034354, loss_ce: 0.009656
2022-01-20 16:48:37,397 iteration 2838 : loss : 0.021142, loss_ce: 0.006840
2022-01-20 16:48:38,728 iteration 2839 : loss : 0.036930, loss_ce: 0.014724
 42%|███████████▎               | 167/400 [1:08:27<1:33:29, 24.08s/it]2022-01-20 16:48:40,069 iteration 2840 : loss : 0.034539, loss_ce: 0.016804
2022-01-20 16:48:41,376 iteration 2841 : loss : 0.028791, loss_ce: 0.010796
2022-01-20 16:48:42,687 iteration 2842 : loss : 0.056328, loss_ce: 0.015736
2022-01-20 16:48:43,911 iteration 2843 : loss : 0.027589, loss_ce: 0.011255
2022-01-20 16:48:45,128 iteration 2844 : loss : 0.017635, loss_ce: 0.005898
2022-01-20 16:48:46,426 iteration 2845 : loss : 0.032840, loss_ce: 0.013134
2022-01-20 16:48:47,848 iteration 2846 : loss : 0.037120, loss_ce: 0.012251
2022-01-20 16:48:49,198 iteration 2847 : loss : 0.045379, loss_ce: 0.014444
2022-01-20 16:48:50,503 iteration 2848 : loss : 0.042339, loss_ce: 0.012229
2022-01-20 16:48:51,845 iteration 2849 : loss : 0.032099, loss_ce: 0.013778
2022-01-20 16:48:53,152 iteration 2850 : loss : 0.029970, loss_ce: 0.013890
2022-01-20 16:48:54,559 iteration 2851 : loss : 0.035811, loss_ce: 0.014546
2022-01-20 16:48:55,819 iteration 2852 : loss : 0.028049, loss_ce: 0.008713
2022-01-20 16:48:57,158 iteration 2853 : loss : 0.047892, loss_ce: 0.014559
2022-01-20 16:48:58,410 iteration 2854 : loss : 0.029108, loss_ce: 0.007943
2022-01-20 16:48:59,686 iteration 2855 : loss : 0.027256, loss_ce: 0.012356
2022-01-20 16:49:00,908 iteration 2856 : loss : 0.025275, loss_ce: 0.011724
 42%|███████████▎               | 168/400 [1:08:49<1:30:54, 23.51s/it]2022-01-20 16:49:02,295 iteration 2857 : loss : 0.030429, loss_ce: 0.013539
2022-01-20 16:49:03,732 iteration 2858 : loss : 0.036351, loss_ce: 0.011006
2022-01-20 16:49:05,083 iteration 2859 : loss : 0.038252, loss_ce: 0.012700
2022-01-20 16:49:06,425 iteration 2860 : loss : 0.031834, loss_ce: 0.011512
2022-01-20 16:49:07,748 iteration 2861 : loss : 0.035146, loss_ce: 0.008810
2022-01-20 16:49:09,099 iteration 2862 : loss : 0.037670, loss_ce: 0.010978
2022-01-20 16:49:10,354 iteration 2863 : loss : 0.026771, loss_ce: 0.011231
2022-01-20 16:49:11,658 iteration 2864 : loss : 0.029248, loss_ce: 0.010869
2022-01-20 16:49:12,961 iteration 2865 : loss : 0.026512, loss_ce: 0.010950
2022-01-20 16:49:14,265 iteration 2866 : loss : 0.024420, loss_ce: 0.008365
2022-01-20 16:49:15,670 iteration 2867 : loss : 0.039876, loss_ce: 0.013465
2022-01-20 16:49:17,019 iteration 2868 : loss : 0.036596, loss_ce: 0.014227
2022-01-20 16:49:18,380 iteration 2869 : loss : 0.028624, loss_ce: 0.010661
2022-01-20 16:49:19,797 iteration 2870 : loss : 0.028226, loss_ce: 0.010859
2022-01-20 16:49:21,032 iteration 2871 : loss : 0.034131, loss_ce: 0.022457
2022-01-20 16:49:22,297 iteration 2872 : loss : 0.030985, loss_ce: 0.014302
2022-01-20 16:49:23,594 iteration 2873 : loss : 0.024715, loss_ce: 0.010362
 42%|███████████▍               | 169/400 [1:09:12<1:29:33, 23.26s/it]2022-01-20 16:49:24,971 iteration 2874 : loss : 0.021214, loss_ce: 0.007876
2022-01-20 16:49:26,359 iteration 2875 : loss : 0.027038, loss_ce: 0.010459
2022-01-20 16:49:27,623 iteration 2876 : loss : 0.033954, loss_ce: 0.011767
2022-01-20 16:49:28,847 iteration 2877 : loss : 0.022693, loss_ce: 0.007072
2022-01-20 16:49:30,144 iteration 2878 : loss : 0.025126, loss_ce: 0.007522
2022-01-20 16:49:31,377 iteration 2879 : loss : 0.026120, loss_ce: 0.011733
2022-01-20 16:49:32,719 iteration 2880 : loss : 0.030204, loss_ce: 0.015549
2022-01-20 16:49:33,939 iteration 2881 : loss : 0.020509, loss_ce: 0.008829
2022-01-20 16:49:35,202 iteration 2882 : loss : 0.041610, loss_ce: 0.012203
2022-01-20 16:49:36,545 iteration 2883 : loss : 0.032303, loss_ce: 0.010535
2022-01-20 16:49:37,901 iteration 2884 : loss : 0.043025, loss_ce: 0.020564
2022-01-20 16:49:39,207 iteration 2885 : loss : 0.020273, loss_ce: 0.007985
2022-01-20 16:49:40,460 iteration 2886 : loss : 0.026577, loss_ce: 0.008998
2022-01-20 16:49:41,703 iteration 2887 : loss : 0.025095, loss_ce: 0.009025
2022-01-20 16:49:43,041 iteration 2888 : loss : 0.021018, loss_ce: 0.008347
2022-01-20 16:49:44,343 iteration 2889 : loss : 0.027229, loss_ce: 0.011916
2022-01-20 16:49:44,343 Training Data Eval:
2022-01-20 16:49:50,833   Average segmentation loss on training set: 0.0182
2022-01-20 16:49:50,833 Validation Data Eval:
2022-01-20 16:49:53,047   Average segmentation loss on validation set: 0.0738
2022-01-20 16:49:54,342 iteration 2890 : loss : 0.028780, loss_ce: 0.012057
 42%|███████████▍               | 170/400 [1:09:42<1:37:46, 25.51s/it]2022-01-20 16:49:55,711 iteration 2891 : loss : 0.020508, loss_ce: 0.009046
2022-01-20 16:49:57,048 iteration 2892 : loss : 0.029069, loss_ce: 0.010552
2022-01-20 16:49:58,277 iteration 2893 : loss : 0.021381, loss_ce: 0.009100
2022-01-20 16:49:59,562 iteration 2894 : loss : 0.023092, loss_ce: 0.009847
2022-01-20 16:50:00,837 iteration 2895 : loss : 0.026436, loss_ce: 0.009243
2022-01-20 16:50:02,159 iteration 2896 : loss : 0.035508, loss_ce: 0.011760
2022-01-20 16:50:03,610 iteration 2897 : loss : 0.047449, loss_ce: 0.011855
2022-01-20 16:50:04,950 iteration 2898 : loss : 0.040317, loss_ce: 0.012548
2022-01-20 16:50:06,264 iteration 2899 : loss : 0.027877, loss_ce: 0.013226
2022-01-20 16:50:07,713 iteration 2900 : loss : 0.041934, loss_ce: 0.019283
2022-01-20 16:50:09,044 iteration 2901 : loss : 0.024217, loss_ce: 0.009592
2022-01-20 16:50:10,324 iteration 2902 : loss : 0.027536, loss_ce: 0.012435
2022-01-20 16:50:11,644 iteration 2903 : loss : 0.039365, loss_ce: 0.011990
2022-01-20 16:50:12,947 iteration 2904 : loss : 0.027166, loss_ce: 0.011882
2022-01-20 16:50:14,301 iteration 2905 : loss : 0.027463, loss_ce: 0.012529
2022-01-20 16:50:15,563 iteration 2906 : loss : 0.028746, loss_ce: 0.012401
2022-01-20 16:50:16,868 iteration 2907 : loss : 0.027832, loss_ce: 0.010822
 43%|███████████▌               | 171/400 [1:10:05<1:33:55, 24.61s/it]2022-01-20 16:50:18,251 iteration 2908 : loss : 0.027679, loss_ce: 0.009735
2022-01-20 16:50:19,614 iteration 2909 : loss : 0.035417, loss_ce: 0.010839
2022-01-20 16:50:20,960 iteration 2910 : loss : 0.024894, loss_ce: 0.009751
2022-01-20 16:50:22,325 iteration 2911 : loss : 0.035397, loss_ce: 0.013166
2022-01-20 16:50:23,586 iteration 2912 : loss : 0.023458, loss_ce: 0.008932
2022-01-20 16:50:24,920 iteration 2913 : loss : 0.030759, loss_ce: 0.011393
2022-01-20 16:50:26,266 iteration 2914 : loss : 0.025107, loss_ce: 0.010309
2022-01-20 16:50:27,588 iteration 2915 : loss : 0.031984, loss_ce: 0.017191
2022-01-20 16:50:28,883 iteration 2916 : loss : 0.035635, loss_ce: 0.013938
2022-01-20 16:50:30,201 iteration 2917 : loss : 0.026357, loss_ce: 0.009406
2022-01-20 16:50:31,430 iteration 2918 : loss : 0.021258, loss_ce: 0.009833
2022-01-20 16:50:32,753 iteration 2919 : loss : 0.024796, loss_ce: 0.009042
2022-01-20 16:50:34,035 iteration 2920 : loss : 0.026059, loss_ce: 0.010600
2022-01-20 16:50:35,334 iteration 2921 : loss : 0.024701, loss_ce: 0.011018
2022-01-20 16:50:36,624 iteration 2922 : loss : 0.052422, loss_ce: 0.013198
2022-01-20 16:50:38,014 iteration 2923 : loss : 0.038622, loss_ce: 0.010542
2022-01-20 16:50:39,361 iteration 2924 : loss : 0.022878, loss_ce: 0.009858
 43%|███████████▌               | 172/400 [1:10:27<1:31:07, 23.98s/it]2022-01-20 16:50:40,741 iteration 2925 : loss : 0.030584, loss_ce: 0.016097
2022-01-20 16:50:41,974 iteration 2926 : loss : 0.023956, loss_ce: 0.008176
2022-01-20 16:50:43,294 iteration 2927 : loss : 0.022906, loss_ce: 0.008163
2022-01-20 16:50:44,652 iteration 2928 : loss : 0.040150, loss_ce: 0.021426
2022-01-20 16:50:45,919 iteration 2929 : loss : 0.036911, loss_ce: 0.009750
2022-01-20 16:50:47,184 iteration 2930 : loss : 0.028630, loss_ce: 0.012773
2022-01-20 16:50:48,483 iteration 2931 : loss : 0.061894, loss_ce: 0.011709
2022-01-20 16:50:49,862 iteration 2932 : loss : 0.050822, loss_ce: 0.021611
2022-01-20 16:50:51,193 iteration 2933 : loss : 0.043247, loss_ce: 0.017751
2022-01-20 16:50:52,558 iteration 2934 : loss : 0.027944, loss_ce: 0.011289
2022-01-20 16:50:53,830 iteration 2935 : loss : 0.029131, loss_ce: 0.009725
2022-01-20 16:50:55,140 iteration 2936 : loss : 0.036168, loss_ce: 0.014949
2022-01-20 16:50:56,484 iteration 2937 : loss : 0.024807, loss_ce: 0.011748
2022-01-20 16:50:57,842 iteration 2938 : loss : 0.044145, loss_ce: 0.017014
2022-01-20 16:50:59,075 iteration 2939 : loss : 0.035205, loss_ce: 0.010486
2022-01-20 16:51:00,390 iteration 2940 : loss : 0.039396, loss_ce: 0.014229
2022-01-20 16:51:01,704 iteration 2941 : loss : 0.048144, loss_ce: 0.020088
 43%|███████████▋               | 173/400 [1:10:50<1:28:51, 23.49s/it]2022-01-20 16:51:03,186 iteration 2942 : loss : 0.033625, loss_ce: 0.014608
2022-01-20 16:51:04,552 iteration 2943 : loss : 0.025935, loss_ce: 0.010191
2022-01-20 16:51:05,894 iteration 2944 : loss : 0.048116, loss_ce: 0.017702
2022-01-20 16:51:07,224 iteration 2945 : loss : 0.045980, loss_ce: 0.020204
2022-01-20 16:51:08,620 iteration 2946 : loss : 0.028828, loss_ce: 0.011963
2022-01-20 16:51:09,899 iteration 2947 : loss : 0.033473, loss_ce: 0.011070
2022-01-20 16:51:11,238 iteration 2948 : loss : 0.029770, loss_ce: 0.012916
2022-01-20 16:51:12,518 iteration 2949 : loss : 0.030839, loss_ce: 0.011274
2022-01-20 16:51:13,746 iteration 2950 : loss : 0.022212, loss_ce: 0.008999
2022-01-20 16:51:15,066 iteration 2951 : loss : 0.025996, loss_ce: 0.007558
2022-01-20 16:51:16,296 iteration 2952 : loss : 0.079824, loss_ce: 0.018982
2022-01-20 16:51:17,682 iteration 2953 : loss : 0.035503, loss_ce: 0.014125
2022-01-20 16:51:18,997 iteration 2954 : loss : 0.041931, loss_ce: 0.021465
2022-01-20 16:51:20,304 iteration 2955 : loss : 0.040015, loss_ce: 0.011429
2022-01-20 16:51:21,555 iteration 2956 : loss : 0.042835, loss_ce: 0.023706
2022-01-20 16:51:22,800 iteration 2957 : loss : 0.038115, loss_ce: 0.013313
2022-01-20 16:51:24,114 iteration 2958 : loss : 0.037850, loss_ce: 0.015651
 44%|███████████▋               | 174/400 [1:11:12<1:27:15, 23.16s/it]2022-01-20 16:51:25,512 iteration 2959 : loss : 0.026520, loss_ce: 0.011751
2022-01-20 16:51:26,798 iteration 2960 : loss : 0.032400, loss_ce: 0.015108
2022-01-20 16:51:28,143 iteration 2961 : loss : 0.031217, loss_ce: 0.013852
2022-01-20 16:51:29,484 iteration 2962 : loss : 0.028958, loss_ce: 0.009818
2022-01-20 16:51:30,756 iteration 2963 : loss : 0.025716, loss_ce: 0.011639
2022-01-20 16:51:32,021 iteration 2964 : loss : 0.035345, loss_ce: 0.012751
2022-01-20 16:51:33,264 iteration 2965 : loss : 0.041739, loss_ce: 0.016925
2022-01-20 16:51:34,494 iteration 2966 : loss : 0.036871, loss_ce: 0.017646
2022-01-20 16:51:35,820 iteration 2967 : loss : 0.038331, loss_ce: 0.018012
2022-01-20 16:51:37,233 iteration 2968 : loss : 0.068088, loss_ce: 0.021772
2022-01-20 16:51:38,572 iteration 2969 : loss : 0.030072, loss_ce: 0.011778
2022-01-20 16:51:39,848 iteration 2970 : loss : 0.028215, loss_ce: 0.009553
2022-01-20 16:51:41,072 iteration 2971 : loss : 0.043358, loss_ce: 0.021131
2022-01-20 16:51:42,429 iteration 2972 : loss : 0.050241, loss_ce: 0.019704
2022-01-20 16:51:43,718 iteration 2973 : loss : 0.034270, loss_ce: 0.013406
2022-01-20 16:51:45,125 iteration 2974 : loss : 0.024122, loss_ce: 0.008105
2022-01-20 16:51:45,125 Training Data Eval:
2022-01-20 16:51:51,698   Average segmentation loss on training set: 0.0224
2022-01-20 16:51:51,699 Validation Data Eval:
2022-01-20 16:51:53,928   Average segmentation loss on validation set: 0.0956
2022-01-20 16:51:55,286 iteration 2975 : loss : 0.030372, loss_ce: 0.007385
 44%|███████████▊               | 175/400 [1:11:43<1:35:52, 25.57s/it]2022-01-20 16:51:56,755 iteration 2976 : loss : 0.046235, loss_ce: 0.027528
2022-01-20 16:51:57,979 iteration 2977 : loss : 0.032886, loss_ce: 0.014624
2022-01-20 16:51:59,201 iteration 2978 : loss : 0.020052, loss_ce: 0.007722
2022-01-20 16:52:00,558 iteration 2979 : loss : 0.022137, loss_ce: 0.007563
2022-01-20 16:52:02,005 iteration 2980 : loss : 0.043207, loss_ce: 0.020444
2022-01-20 16:52:03,320 iteration 2981 : loss : 0.028732, loss_ce: 0.008755
2022-01-20 16:52:04,709 iteration 2982 : loss : 0.036117, loss_ce: 0.016430
2022-01-20 16:52:06,013 iteration 2983 : loss : 0.029338, loss_ce: 0.013630
2022-01-20 16:52:07,389 iteration 2984 : loss : 0.036050, loss_ce: 0.015716
2022-01-20 16:52:08,732 iteration 2985 : loss : 0.032551, loss_ce: 0.009352
2022-01-20 16:52:10,103 iteration 2986 : loss : 0.043653, loss_ce: 0.017084
2022-01-20 16:52:11,360 iteration 2987 : loss : 0.031155, loss_ce: 0.014022
2022-01-20 16:52:12,649 iteration 2988 : loss : 0.021168, loss_ce: 0.007287
2022-01-20 16:52:13,984 iteration 2989 : loss : 0.022626, loss_ce: 0.006785
2022-01-20 16:52:15,310 iteration 2990 : loss : 0.037748, loss_ce: 0.014707
2022-01-20 16:52:16,701 iteration 2991 : loss : 0.023047, loss_ce: 0.008017
2022-01-20 16:52:18,155 iteration 2992 : loss : 0.044439, loss_ce: 0.017631
 44%|███████████▉               | 176/400 [1:12:06<1:32:25, 24.75s/it]2022-01-20 16:52:19,430 iteration 2993 : loss : 0.023214, loss_ce: 0.007564
2022-01-20 16:52:20,710 iteration 2994 : loss : 0.027473, loss_ce: 0.009758
2022-01-20 16:52:22,122 iteration 2995 : loss : 0.031097, loss_ce: 0.013974
2022-01-20 16:52:23,421 iteration 2996 : loss : 0.024780, loss_ce: 0.008482
2022-01-20 16:52:24,717 iteration 2997 : loss : 0.025034, loss_ce: 0.008946
2022-01-20 16:52:26,014 iteration 2998 : loss : 0.025128, loss_ce: 0.009018
2022-01-20 16:52:27,377 iteration 2999 : loss : 0.030921, loss_ce: 0.011218
2022-01-20 16:52:28,674 iteration 3000 : loss : 0.049723, loss_ce: 0.015046
2022-01-20 16:52:30,032 iteration 3001 : loss : 0.021546, loss_ce: 0.008871
2022-01-20 16:52:31,256 iteration 3002 : loss : 0.030974, loss_ce: 0.012463
2022-01-20 16:52:32,629 iteration 3003 : loss : 0.032207, loss_ce: 0.011917
2022-01-20 16:52:33,856 iteration 3004 : loss : 0.022342, loss_ce: 0.008739
2022-01-20 16:52:35,216 iteration 3005 : loss : 0.040129, loss_ce: 0.013043
2022-01-20 16:52:36,591 iteration 3006 : loss : 0.037330, loss_ce: 0.013869
2022-01-20 16:52:37,895 iteration 3007 : loss : 0.021367, loss_ce: 0.008035
2022-01-20 16:52:39,374 iteration 3008 : loss : 0.035779, loss_ce: 0.016237
2022-01-20 16:52:40,705 iteration 3009 : loss : 0.024060, loss_ce: 0.012733
 44%|███████████▉               | 177/400 [1:12:29<1:29:32, 24.09s/it]2022-01-20 16:52:42,100 iteration 3010 : loss : 0.021291, loss_ce: 0.008062
2022-01-20 16:52:43,433 iteration 3011 : loss : 0.029680, loss_ce: 0.009447
2022-01-20 16:52:44,736 iteration 3012 : loss : 0.028297, loss_ce: 0.010130
2022-01-20 16:52:46,030 iteration 3013 : loss : 0.020188, loss_ce: 0.008013
2022-01-20 16:52:47,438 iteration 3014 : loss : 0.025863, loss_ce: 0.009836
2022-01-20 16:52:48,771 iteration 3015 : loss : 0.037910, loss_ce: 0.015960
2022-01-20 16:52:50,083 iteration 3016 : loss : 0.027712, loss_ce: 0.009600
2022-01-20 16:52:51,387 iteration 3017 : loss : 0.029511, loss_ce: 0.008765
2022-01-20 16:52:52,656 iteration 3018 : loss : 0.016467, loss_ce: 0.004848
2022-01-20 16:52:53,955 iteration 3019 : loss : 0.037550, loss_ce: 0.012691
2022-01-20 16:52:55,151 iteration 3020 : loss : 0.025197, loss_ce: 0.012242
2022-01-20 16:52:56,393 iteration 3021 : loss : 0.023961, loss_ce: 0.008178
2022-01-20 16:52:57,700 iteration 3022 : loss : 0.026257, loss_ce: 0.007964
2022-01-20 16:52:58,992 iteration 3023 : loss : 0.023087, loss_ce: 0.011384
2022-01-20 16:53:00,307 iteration 3024 : loss : 0.031951, loss_ce: 0.012054
2022-01-20 16:53:01,517 iteration 3025 : loss : 0.028016, loss_ce: 0.012534
2022-01-20 16:53:02,870 iteration 3026 : loss : 0.023178, loss_ce: 0.010466
 44%|████████████               | 178/400 [1:12:51<1:27:00, 23.52s/it]2022-01-20 16:53:04,242 iteration 3027 : loss : 0.026211, loss_ce: 0.012368
2022-01-20 16:53:05,534 iteration 3028 : loss : 0.032438, loss_ce: 0.013100
2022-01-20 16:53:06,850 iteration 3029 : loss : 0.023235, loss_ce: 0.010420
2022-01-20 16:53:08,277 iteration 3030 : loss : 0.032506, loss_ce: 0.013377
2022-01-20 16:53:09,477 iteration 3031 : loss : 0.021502, loss_ce: 0.009202
2022-01-20 16:53:10,775 iteration 3032 : loss : 0.025279, loss_ce: 0.008687
2022-01-20 16:53:12,107 iteration 3033 : loss : 0.022693, loss_ce: 0.011842
2022-01-20 16:53:13,381 iteration 3034 : loss : 0.018432, loss_ce: 0.006104
2022-01-20 16:53:14,784 iteration 3035 : loss : 0.037103, loss_ce: 0.010144
2022-01-20 16:53:16,108 iteration 3036 : loss : 0.021268, loss_ce: 0.009142
2022-01-20 16:53:17,467 iteration 3037 : loss : 0.019914, loss_ce: 0.007217
2022-01-20 16:53:18,677 iteration 3038 : loss : 0.018775, loss_ce: 0.004413
2022-01-20 16:53:20,158 iteration 3039 : loss : 0.055920, loss_ce: 0.022157
2022-01-20 16:53:21,388 iteration 3040 : loss : 0.019752, loss_ce: 0.008404
2022-01-20 16:53:22,645 iteration 3041 : loss : 0.024657, loss_ce: 0.009278
2022-01-20 16:53:23,900 iteration 3042 : loss : 0.022287, loss_ce: 0.009429
2022-01-20 16:53:25,331 iteration 3043 : loss : 0.024631, loss_ce: 0.008954
 45%|████████████               | 179/400 [1:13:13<1:25:27, 23.20s/it]2022-01-20 16:53:26,734 iteration 3044 : loss : 0.031616, loss_ce: 0.011834
2022-01-20 16:53:28,014 iteration 3045 : loss : 0.024619, loss_ce: 0.009676
2022-01-20 16:53:29,276 iteration 3046 : loss : 0.027024, loss_ce: 0.009643
2022-01-20 16:53:30,712 iteration 3047 : loss : 0.029755, loss_ce: 0.012343
2022-01-20 16:53:32,078 iteration 3048 : loss : 0.025393, loss_ce: 0.013427
2022-01-20 16:53:33,342 iteration 3049 : loss : 0.023858, loss_ce: 0.008968
2022-01-20 16:53:34,748 iteration 3050 : loss : 0.026433, loss_ce: 0.012342
2022-01-20 16:53:36,097 iteration 3051 : loss : 0.044278, loss_ce: 0.012705
2022-01-20 16:53:37,495 iteration 3052 : loss : 0.035155, loss_ce: 0.013855
2022-01-20 16:53:38,834 iteration 3053 : loss : 0.023580, loss_ce: 0.010513
2022-01-20 16:53:40,163 iteration 3054 : loss : 0.038498, loss_ce: 0.013130
2022-01-20 16:53:41,515 iteration 3055 : loss : 0.049386, loss_ce: 0.019214
2022-01-20 16:53:42,830 iteration 3056 : loss : 0.028426, loss_ce: 0.009106
2022-01-20 16:53:44,111 iteration 3057 : loss : 0.016996, loss_ce: 0.005850
2022-01-20 16:53:45,516 iteration 3058 : loss : 0.035015, loss_ce: 0.011764
2022-01-20 16:53:46,920 iteration 3059 : loss : 0.036979, loss_ce: 0.014826
2022-01-20 16:53:46,920 Training Data Eval:
2022-01-20 16:53:53,436   Average segmentation loss on training set: 0.0220
2022-01-20 16:53:53,436 Validation Data Eval:
2022-01-20 16:53:55,692   Average segmentation loss on validation set: 0.1198
2022-01-20 16:53:57,027 iteration 3060 : loss : 0.024675, loss_ce: 0.010007
 45%|████████████▏              | 180/400 [1:13:45<1:34:25, 25.75s/it]2022-01-20 16:53:58,386 iteration 3061 : loss : 0.024768, loss_ce: 0.008897
2022-01-20 16:53:59,741 iteration 3062 : loss : 0.024484, loss_ce: 0.008101
2022-01-20 16:54:01,037 iteration 3063 : loss : 0.032179, loss_ce: 0.009644
2022-01-20 16:54:02,415 iteration 3064 : loss : 0.038678, loss_ce: 0.019278
2022-01-20 16:54:03,722 iteration 3065 : loss : 0.041230, loss_ce: 0.011888
2022-01-20 16:54:05,020 iteration 3066 : loss : 0.062947, loss_ce: 0.020929
2022-01-20 16:54:06,348 iteration 3067 : loss : 0.031291, loss_ce: 0.013676
2022-01-20 16:54:07,736 iteration 3068 : loss : 0.020562, loss_ce: 0.007069
2022-01-20 16:54:09,110 iteration 3069 : loss : 0.043655, loss_ce: 0.009301
2022-01-20 16:54:10,355 iteration 3070 : loss : 0.023154, loss_ce: 0.009122
2022-01-20 16:54:11,752 iteration 3071 : loss : 0.030351, loss_ce: 0.012965
2022-01-20 16:54:13,090 iteration 3072 : loss : 0.025600, loss_ce: 0.010471
2022-01-20 16:54:14,348 iteration 3073 : loss : 0.031431, loss_ce: 0.012171
2022-01-20 16:54:15,773 iteration 3074 : loss : 0.040994, loss_ce: 0.017990
2022-01-20 16:54:17,130 iteration 3075 : loss : 0.019799, loss_ce: 0.006691
2022-01-20 16:54:18,413 iteration 3076 : loss : 0.033307, loss_ce: 0.014765
2022-01-20 16:54:19,800 iteration 3077 : loss : 0.042726, loss_ce: 0.021583
 45%|████████████▏              | 181/400 [1:14:08<1:30:43, 24.86s/it]2022-01-20 16:54:21,043 iteration 3078 : loss : 0.019374, loss_ce: 0.007685
2022-01-20 16:54:22,401 iteration 3079 : loss : 0.032120, loss_ce: 0.010271
2022-01-20 16:54:23,714 iteration 3080 : loss : 0.030368, loss_ce: 0.013744
2022-01-20 16:54:24,991 iteration 3081 : loss : 0.026923, loss_ce: 0.007623
2022-01-20 16:54:26,310 iteration 3082 : loss : 0.021624, loss_ce: 0.008627
2022-01-20 16:54:27,622 iteration 3083 : loss : 0.034645, loss_ce: 0.015194
2022-01-20 16:54:28,912 iteration 3084 : loss : 0.020762, loss_ce: 0.008089
2022-01-20 16:54:30,231 iteration 3085 : loss : 0.041808, loss_ce: 0.009005
2022-01-20 16:54:31,496 iteration 3086 : loss : 0.022012, loss_ce: 0.008535
2022-01-20 16:54:32,745 iteration 3087 : loss : 0.023926, loss_ce: 0.007741
2022-01-20 16:54:33,988 iteration 3088 : loss : 0.023268, loss_ce: 0.007769
2022-01-20 16:54:35,246 iteration 3089 : loss : 0.026941, loss_ce: 0.010555
2022-01-20 16:54:36,584 iteration 3090 : loss : 0.033272, loss_ce: 0.010691
2022-01-20 16:54:37,851 iteration 3091 : loss : 0.036027, loss_ce: 0.012706
2022-01-20 16:54:39,084 iteration 3092 : loss : 0.022627, loss_ce: 0.010570
2022-01-20 16:54:40,398 iteration 3093 : loss : 0.020165, loss_ce: 0.006280
2022-01-20 16:54:41,679 iteration 3094 : loss : 0.031396, loss_ce: 0.015475
 46%|████████████▎              | 182/400 [1:14:30<1:27:02, 23.96s/it]2022-01-20 16:54:43,112 iteration 3095 : loss : 0.022451, loss_ce: 0.008186
2022-01-20 16:54:44,386 iteration 3096 : loss : 0.023770, loss_ce: 0.009589
2022-01-20 16:54:45,658 iteration 3097 : loss : 0.024528, loss_ce: 0.009361
2022-01-20 16:54:46,908 iteration 3098 : loss : 0.021874, loss_ce: 0.007291
2022-01-20 16:54:48,288 iteration 3099 : loss : 0.050156, loss_ce: 0.016350
2022-01-20 16:54:49,540 iteration 3100 : loss : 0.024744, loss_ce: 0.008603
2022-01-20 16:54:50,840 iteration 3101 : loss : 0.023870, loss_ce: 0.010575
2022-01-20 16:54:52,194 iteration 3102 : loss : 0.022398, loss_ce: 0.008352
2022-01-20 16:54:53,467 iteration 3103 : loss : 0.026261, loss_ce: 0.008219
2022-01-20 16:54:54,765 iteration 3104 : loss : 0.026449, loss_ce: 0.007847
2022-01-20 16:54:56,040 iteration 3105 : loss : 0.023175, loss_ce: 0.007657
2022-01-20 16:54:57,501 iteration 3106 : loss : 0.031759, loss_ce: 0.013723
2022-01-20 16:54:58,789 iteration 3107 : loss : 0.038619, loss_ce: 0.016500
2022-01-20 16:55:00,013 iteration 3108 : loss : 0.021711, loss_ce: 0.007828
2022-01-20 16:55:01,396 iteration 3109 : loss : 0.032657, loss_ce: 0.016110
2022-01-20 16:55:02,760 iteration 3110 : loss : 0.034657, loss_ce: 0.014806
2022-01-20 16:55:04,023 iteration 3111 : loss : 0.033009, loss_ce: 0.010080
 46%|████████████▎              | 183/400 [1:14:52<1:24:54, 23.48s/it]2022-01-20 16:55:05,347 iteration 3112 : loss : 0.018409, loss_ce: 0.007071
2022-01-20 16:55:06,656 iteration 3113 : loss : 0.032729, loss_ce: 0.014626
2022-01-20 16:55:08,099 iteration 3114 : loss : 0.050476, loss_ce: 0.013064
2022-01-20 16:55:09,467 iteration 3115 : loss : 0.033982, loss_ce: 0.013988
2022-01-20 16:55:10,787 iteration 3116 : loss : 0.029440, loss_ce: 0.011915
2022-01-20 16:55:12,077 iteration 3117 : loss : 0.026464, loss_ce: 0.011800
2022-01-20 16:55:13,437 iteration 3118 : loss : 0.039154, loss_ce: 0.015248
2022-01-20 16:55:14,769 iteration 3119 : loss : 0.030484, loss_ce: 0.011160
2022-01-20 16:55:16,071 iteration 3120 : loss : 0.023746, loss_ce: 0.007461
2022-01-20 16:55:17,394 iteration 3121 : loss : 0.029786, loss_ce: 0.008601
2022-01-20 16:55:18,769 iteration 3122 : loss : 0.063103, loss_ce: 0.026300
2022-01-20 16:55:20,076 iteration 3123 : loss : 0.021083, loss_ce: 0.008579
2022-01-20 16:55:21,406 iteration 3124 : loss : 0.024912, loss_ce: 0.010427
2022-01-20 16:55:22,733 iteration 3125 : loss : 0.042603, loss_ce: 0.020987
2022-01-20 16:55:23,979 iteration 3126 : loss : 0.023676, loss_ce: 0.009521
2022-01-20 16:55:25,309 iteration 3127 : loss : 0.026257, loss_ce: 0.011548
2022-01-20 16:55:26,540 iteration 3128 : loss : 0.020007, loss_ce: 0.006795
 46%|████████████▍              | 184/400 [1:15:15<1:23:27, 23.19s/it]2022-01-20 16:55:27,952 iteration 3129 : loss : 0.026115, loss_ce: 0.009443
2022-01-20 16:55:29,292 iteration 3130 : loss : 0.026597, loss_ce: 0.009560
2022-01-20 16:55:30,670 iteration 3131 : loss : 0.042921, loss_ce: 0.018964
2022-01-20 16:55:31,948 iteration 3132 : loss : 0.027006, loss_ce: 0.011767
2022-01-20 16:55:33,174 iteration 3133 : loss : 0.032877, loss_ce: 0.015526
2022-01-20 16:55:34,479 iteration 3134 : loss : 0.018726, loss_ce: 0.006439
2022-01-20 16:55:35,785 iteration 3135 : loss : 0.030236, loss_ce: 0.011712
2022-01-20 16:55:37,161 iteration 3136 : loss : 0.043586, loss_ce: 0.017305
2022-01-20 16:55:38,500 iteration 3137 : loss : 0.024732, loss_ce: 0.011532
2022-01-20 16:55:39,849 iteration 3138 : loss : 0.026358, loss_ce: 0.012098
2022-01-20 16:55:41,242 iteration 3139 : loss : 0.037928, loss_ce: 0.012597
2022-01-20 16:55:42,598 iteration 3140 : loss : 0.048534, loss_ce: 0.015228
2022-01-20 16:55:43,958 iteration 3141 : loss : 0.023766, loss_ce: 0.009340
2022-01-20 16:55:45,263 iteration 3142 : loss : 0.027159, loss_ce: 0.010140
2022-01-20 16:55:46,635 iteration 3143 : loss : 0.026470, loss_ce: 0.010606
2022-01-20 16:55:48,015 iteration 3144 : loss : 0.024882, loss_ce: 0.011898
2022-01-20 16:55:48,015 Training Data Eval:
2022-01-20 16:55:54,531   Average segmentation loss on training set: 0.0166
2022-01-20 16:55:54,531 Validation Data Eval:
2022-01-20 16:55:56,750   Average segmentation loss on validation set: 0.0730
2022-01-20 16:55:57,960 iteration 3145 : loss : 0.020899, loss_ce: 0.008027
 46%|████████████▍              | 185/400 [1:15:46<1:31:56, 25.66s/it]2022-01-20 16:55:59,244 iteration 3146 : loss : 0.021605, loss_ce: 0.008008
2022-01-20 16:56:00,536 iteration 3147 : loss : 0.025048, loss_ce: 0.010404
2022-01-20 16:56:01,837 iteration 3148 : loss : 0.022391, loss_ce: 0.007816
2022-01-20 16:56:03,108 iteration 3149 : loss : 0.019064, loss_ce: 0.006458
2022-01-20 16:56:04,411 iteration 3150 : loss : 0.036826, loss_ce: 0.015098
2022-01-20 16:56:05,699 iteration 3151 : loss : 0.029389, loss_ce: 0.006643
2022-01-20 16:56:07,005 iteration 3152 : loss : 0.022692, loss_ce: 0.009471
2022-01-20 16:56:08,356 iteration 3153 : loss : 0.039732, loss_ce: 0.016336
2022-01-20 16:56:09,647 iteration 3154 : loss : 0.021152, loss_ce: 0.010206
2022-01-20 16:56:10,957 iteration 3155 : loss : 0.026585, loss_ce: 0.009316
2022-01-20 16:56:12,354 iteration 3156 : loss : 0.047377, loss_ce: 0.020167
2022-01-20 16:56:13,728 iteration 3157 : loss : 0.024129, loss_ce: 0.008641
2022-01-20 16:56:15,044 iteration 3158 : loss : 0.027170, loss_ce: 0.011061
2022-01-20 16:56:16,367 iteration 3159 : loss : 0.029211, loss_ce: 0.011995
2022-01-20 16:56:17,691 iteration 3160 : loss : 0.021485, loss_ce: 0.009026
2022-01-20 16:56:18,969 iteration 3161 : loss : 0.026421, loss_ce: 0.009810
2022-01-20 16:56:20,378 iteration 3162 : loss : 0.031865, loss_ce: 0.011909
 46%|████████████▌              | 186/400 [1:16:08<1:28:03, 24.69s/it]2022-01-20 16:56:21,828 iteration 3163 : loss : 0.025082, loss_ce: 0.011402
2022-01-20 16:56:23,164 iteration 3164 : loss : 0.020486, loss_ce: 0.007636
2022-01-20 16:56:24,459 iteration 3165 : loss : 0.018844, loss_ce: 0.006996
2022-01-20 16:56:25,843 iteration 3166 : loss : 0.028174, loss_ce: 0.008144
2022-01-20 16:56:27,156 iteration 3167 : loss : 0.017980, loss_ce: 0.007360
2022-01-20 16:56:28,604 iteration 3168 : loss : 0.036412, loss_ce: 0.017429
2022-01-20 16:56:30,044 iteration 3169 : loss : 0.029905, loss_ce: 0.014121
2022-01-20 16:56:31,317 iteration 3170 : loss : 0.022289, loss_ce: 0.009853
2022-01-20 16:56:32,548 iteration 3171 : loss : 0.018807, loss_ce: 0.008768
2022-01-20 16:56:33,894 iteration 3172 : loss : 0.030683, loss_ce: 0.010710
2022-01-20 16:56:35,263 iteration 3173 : loss : 0.026191, loss_ce: 0.010887
2022-01-20 16:56:36,579 iteration 3174 : loss : 0.027661, loss_ce: 0.012436
2022-01-20 16:56:38,001 iteration 3175 : loss : 0.038660, loss_ce: 0.011206
2022-01-20 16:56:39,300 iteration 3176 : loss : 0.028182, loss_ce: 0.009531
2022-01-20 16:56:40,660 iteration 3177 : loss : 0.040065, loss_ce: 0.012529
2022-01-20 16:56:41,894 iteration 3178 : loss : 0.021812, loss_ce: 0.007200
2022-01-20 16:56:43,178 iteration 3179 : loss : 0.033065, loss_ce: 0.009311
 47%|████████████▌              | 187/400 [1:16:31<1:25:37, 24.12s/it]2022-01-20 16:56:44,617 iteration 3180 : loss : 0.040483, loss_ce: 0.017652
2022-01-20 16:56:45,878 iteration 3181 : loss : 0.019179, loss_ce: 0.007022
2022-01-20 16:56:47,209 iteration 3182 : loss : 0.017487, loss_ce: 0.006393
2022-01-20 16:56:48,496 iteration 3183 : loss : 0.022898, loss_ce: 0.006063
2022-01-20 16:56:49,833 iteration 3184 : loss : 0.030151, loss_ce: 0.009608
2022-01-20 16:56:51,219 iteration 3185 : loss : 0.028216, loss_ce: 0.010696
2022-01-20 16:56:52,478 iteration 3186 : loss : 0.022416, loss_ce: 0.011100
2022-01-20 16:56:53,846 iteration 3187 : loss : 0.018488, loss_ce: 0.006897
2022-01-20 16:56:55,190 iteration 3188 : loss : 0.021081, loss_ce: 0.009508
2022-01-20 16:56:56,568 iteration 3189 : loss : 0.027957, loss_ce: 0.011503
2022-01-20 16:56:57,925 iteration 3190 : loss : 0.025043, loss_ce: 0.008765
2022-01-20 16:56:59,405 iteration 3191 : loss : 0.041971, loss_ce: 0.014660
2022-01-20 16:57:00,710 iteration 3192 : loss : 0.031714, loss_ce: 0.009103
2022-01-20 16:57:02,129 iteration 3193 : loss : 0.023483, loss_ce: 0.009987
2022-01-20 16:57:03,543 iteration 3194 : loss : 0.029031, loss_ce: 0.008756
2022-01-20 16:57:04,919 iteration 3195 : loss : 0.023711, loss_ce: 0.010378
2022-01-20 16:57:06,272 iteration 3196 : loss : 0.032269, loss_ce: 0.014193
 47%|████████████▋              | 188/400 [1:16:54<1:24:08, 23.81s/it]2022-01-20 16:57:07,617 iteration 3197 : loss : 0.021356, loss_ce: 0.008455
2022-01-20 16:57:08,951 iteration 3198 : loss : 0.026091, loss_ce: 0.011613
2022-01-20 16:57:10,302 iteration 3199 : loss : 0.023465, loss_ce: 0.010043
2022-01-20 16:57:11,749 iteration 3200 : loss : 0.020905, loss_ce: 0.008481
2022-01-20 16:57:13,098 iteration 3201 : loss : 0.031625, loss_ce: 0.009126
2022-01-20 16:57:14,422 iteration 3202 : loss : 0.027550, loss_ce: 0.009485
2022-01-20 16:57:15,869 iteration 3203 : loss : 0.025885, loss_ce: 0.010953
2022-01-20 16:57:17,184 iteration 3204 : loss : 0.022390, loss_ce: 0.007411
2022-01-20 16:57:18,579 iteration 3205 : loss : 0.022849, loss_ce: 0.006524
2022-01-20 16:57:19,916 iteration 3206 : loss : 0.025059, loss_ce: 0.011123
2022-01-20 16:57:21,351 iteration 3207 : loss : 0.050434, loss_ce: 0.023819
2022-01-20 16:57:22,615 iteration 3208 : loss : 0.023884, loss_ce: 0.006292
2022-01-20 16:57:23,899 iteration 3209 : loss : 0.021662, loss_ce: 0.010843
2022-01-20 16:57:25,126 iteration 3210 : loss : 0.029243, loss_ce: 0.014702
2022-01-20 16:57:26,446 iteration 3211 : loss : 0.028054, loss_ce: 0.007481
2022-01-20 16:57:27,743 iteration 3212 : loss : 0.033786, loss_ce: 0.013561
2022-01-20 16:57:29,062 iteration 3213 : loss : 0.025250, loss_ce: 0.007220
 47%|████████████▊              | 189/400 [1:17:17<1:22:40, 23.51s/it]2022-01-20 16:57:30,450 iteration 3214 : loss : 0.023094, loss_ce: 0.010902
2022-01-20 16:57:31,863 iteration 3215 : loss : 0.029635, loss_ce: 0.010457
2022-01-20 16:57:33,236 iteration 3216 : loss : 0.026805, loss_ce: 0.009247
2022-01-20 16:57:34,622 iteration 3217 : loss : 0.050389, loss_ce: 0.010052
2022-01-20 16:57:35,951 iteration 3218 : loss : 0.025318, loss_ce: 0.009650
2022-01-20 16:57:37,236 iteration 3219 : loss : 0.027163, loss_ce: 0.011542
2022-01-20 16:57:38,594 iteration 3220 : loss : 0.030646, loss_ce: 0.012192
2022-01-20 16:57:39,878 iteration 3221 : loss : 0.022500, loss_ce: 0.009115
2022-01-20 16:57:41,206 iteration 3222 : loss : 0.034081, loss_ce: 0.019801
2022-01-20 16:57:42,554 iteration 3223 : loss : 0.031992, loss_ce: 0.010584
2022-01-20 16:57:43,932 iteration 3224 : loss : 0.023245, loss_ce: 0.008041
2022-01-20 16:57:45,224 iteration 3225 : loss : 0.024372, loss_ce: 0.008508
2022-01-20 16:57:46,645 iteration 3226 : loss : 0.029201, loss_ce: 0.008798
2022-01-20 16:57:47,972 iteration 3227 : loss : 0.029922, loss_ce: 0.012991
2022-01-20 16:57:49,207 iteration 3228 : loss : 0.021712, loss_ce: 0.009719
2022-01-20 16:57:50,613 iteration 3229 : loss : 0.024586, loss_ce: 0.009328
2022-01-20 16:57:50,613 Training Data Eval:
2022-01-20 16:57:57,155   Average segmentation loss on training set: 0.0186
2022-01-20 16:57:57,155 Validation Data Eval:
2022-01-20 16:57:59,397   Average segmentation loss on validation set: 0.1057
2022-01-20 16:58:00,841 iteration 3230 : loss : 0.037161, loss_ce: 0.013929
 48%|████████████▊              | 190/400 [1:17:49<1:30:56, 25.99s/it]2022-01-20 16:58:02,182 iteration 3231 : loss : 0.035305, loss_ce: 0.013400
2022-01-20 16:58:03,503 iteration 3232 : loss : 0.023100, loss_ce: 0.010634
2022-01-20 16:58:04,801 iteration 3233 : loss : 0.018189, loss_ce: 0.006497
2022-01-20 16:58:06,069 iteration 3234 : loss : 0.023677, loss_ce: 0.007428
2022-01-20 16:58:07,356 iteration 3235 : loss : 0.019515, loss_ce: 0.005083
2022-01-20 16:58:08,707 iteration 3236 : loss : 0.021724, loss_ce: 0.009035
2022-01-20 16:58:10,072 iteration 3237 : loss : 0.023084, loss_ce: 0.009872
2022-01-20 16:58:11,407 iteration 3238 : loss : 0.029711, loss_ce: 0.006893
2022-01-20 16:58:12,726 iteration 3239 : loss : 0.022594, loss_ce: 0.008540
2022-01-20 16:58:14,066 iteration 3240 : loss : 0.024887, loss_ce: 0.008374
2022-01-20 16:58:15,444 iteration 3241 : loss : 0.034134, loss_ce: 0.013094
2022-01-20 16:58:16,869 iteration 3242 : loss : 0.028828, loss_ce: 0.012817
2022-01-20 16:58:18,135 iteration 3243 : loss : 0.025193, loss_ce: 0.011701
2022-01-20 16:58:19,444 iteration 3244 : loss : 0.036316, loss_ce: 0.009517
2022-01-20 16:58:20,733 iteration 3245 : loss : 0.024277, loss_ce: 0.010676
2022-01-20 16:58:22,126 iteration 3246 : loss : 0.025928, loss_ce: 0.010417
2022-01-20 16:58:23,470 iteration 3247 : loss : 0.021978, loss_ce: 0.009072
 48%|████████████▉              | 191/400 [1:18:12<1:27:01, 24.98s/it]2022-01-20 16:58:25,036 iteration 3248 : loss : 0.027399, loss_ce: 0.013260
2022-01-20 16:58:26,254 iteration 3249 : loss : 0.019633, loss_ce: 0.005805
2022-01-20 16:58:27,595 iteration 3250 : loss : 0.026416, loss_ce: 0.009587
2022-01-20 16:58:28,923 iteration 3251 : loss : 0.024509, loss_ce: 0.005557
2022-01-20 16:58:30,191 iteration 3252 : loss : 0.024939, loss_ce: 0.009961
2022-01-20 16:58:31,548 iteration 3253 : loss : 0.035552, loss_ce: 0.017670
2022-01-20 16:58:32,865 iteration 3254 : loss : 0.019801, loss_ce: 0.006420
2022-01-20 16:58:34,238 iteration 3255 : loss : 0.021966, loss_ce: 0.007671
2022-01-20 16:58:35,480 iteration 3256 : loss : 0.020117, loss_ce: 0.011927
2022-01-20 16:58:36,777 iteration 3257 : loss : 0.027069, loss_ce: 0.008464
2022-01-20 16:58:38,171 iteration 3258 : loss : 0.024892, loss_ce: 0.009743
2022-01-20 16:58:39,488 iteration 3259 : loss : 0.021701, loss_ce: 0.008396
2022-01-20 16:58:40,769 iteration 3260 : loss : 0.020084, loss_ce: 0.007626
2022-01-20 16:58:42,157 iteration 3261 : loss : 0.027448, loss_ce: 0.009551
2022-01-20 16:58:43,449 iteration 3262 : loss : 0.039173, loss_ce: 0.016401
2022-01-20 16:58:44,751 iteration 3263 : loss : 0.033890, loss_ce: 0.010118
2022-01-20 16:58:46,056 iteration 3264 : loss : 0.027564, loss_ce: 0.009415
 48%|████████████▉              | 192/400 [1:18:34<1:24:06, 24.26s/it]2022-01-20 16:58:47,321 iteration 3265 : loss : 0.017274, loss_ce: 0.006311
2022-01-20 16:58:48,675 iteration 3266 : loss : 0.020677, loss_ce: 0.008587
2022-01-20 16:58:49,940 iteration 3267 : loss : 0.022083, loss_ce: 0.009987
2022-01-20 16:58:51,388 iteration 3268 : loss : 0.033149, loss_ce: 0.015226
2022-01-20 16:58:52,645 iteration 3269 : loss : 0.026961, loss_ce: 0.011880
2022-01-20 16:58:53,909 iteration 3270 : loss : 0.022181, loss_ce: 0.008552
2022-01-20 16:58:55,301 iteration 3271 : loss : 0.028997, loss_ce: 0.008844
2022-01-20 16:58:56,588 iteration 3272 : loss : 0.020516, loss_ce: 0.007257
2022-01-20 16:58:57,862 iteration 3273 : loss : 0.031413, loss_ce: 0.013987
2022-01-20 16:58:59,229 iteration 3274 : loss : 0.022984, loss_ce: 0.007412
2022-01-20 16:59:00,493 iteration 3275 : loss : 0.019166, loss_ce: 0.008572
2022-01-20 16:59:01,807 iteration 3276 : loss : 0.029252, loss_ce: 0.009521
2022-01-20 16:59:03,191 iteration 3277 : loss : 0.022712, loss_ce: 0.009385
2022-01-20 16:59:04,495 iteration 3278 : loss : 0.023614, loss_ce: 0.009032
2022-01-20 16:59:05,859 iteration 3279 : loss : 0.030850, loss_ce: 0.011074
2022-01-20 16:59:07,183 iteration 3280 : loss : 0.023141, loss_ce: 0.011118
2022-01-20 16:59:08,495 iteration 3281 : loss : 0.018269, loss_ce: 0.005680
 48%|█████████████              | 193/400 [1:18:57<1:21:49, 23.72s/it]2022-01-20 16:59:09,833 iteration 3282 : loss : 0.030513, loss_ce: 0.014132
2022-01-20 16:59:11,252 iteration 3283 : loss : 0.045311, loss_ce: 0.015859
2022-01-20 16:59:12,517 iteration 3284 : loss : 0.028253, loss_ce: 0.013679
2022-01-20 16:59:13,738 iteration 3285 : loss : 0.018240, loss_ce: 0.006511
2022-01-20 16:59:15,119 iteration 3286 : loss : 0.026322, loss_ce: 0.007731
2022-01-20 16:59:16,478 iteration 3287 : loss : 0.029938, loss_ce: 0.014622
2022-01-20 16:59:17,786 iteration 3288 : loss : 0.021215, loss_ce: 0.008255
2022-01-20 16:59:19,108 iteration 3289 : loss : 0.025455, loss_ce: 0.007893
2022-01-20 16:59:20,359 iteration 3290 : loss : 0.019362, loss_ce: 0.005356
2022-01-20 16:59:21,740 iteration 3291 : loss : 0.024212, loss_ce: 0.007410
2022-01-20 16:59:23,029 iteration 3292 : loss : 0.027418, loss_ce: 0.011848
2022-01-20 16:59:24,281 iteration 3293 : loss : 0.022014, loss_ce: 0.008626
2022-01-20 16:59:25,552 iteration 3294 : loss : 0.032129, loss_ce: 0.016165
2022-01-20 16:59:26,855 iteration 3295 : loss : 0.023489, loss_ce: 0.011216
2022-01-20 16:59:28,172 iteration 3296 : loss : 0.023605, loss_ce: 0.008631
2022-01-20 16:59:29,447 iteration 3297 : loss : 0.027011, loss_ce: 0.010531
2022-01-20 16:59:30,679 iteration 3298 : loss : 0.019810, loss_ce: 0.007797
 48%|█████████████              | 194/400 [1:19:19<1:19:51, 23.26s/it]2022-01-20 16:59:32,004 iteration 3299 : loss : 0.019891, loss_ce: 0.007845
2022-01-20 16:59:33,281 iteration 3300 : loss : 0.025636, loss_ce: 0.009545
2022-01-20 16:59:34,638 iteration 3301 : loss : 0.069517, loss_ce: 0.023088
2022-01-20 16:59:35,872 iteration 3302 : loss : 0.022387, loss_ce: 0.007826
2022-01-20 16:59:37,232 iteration 3303 : loss : 0.033070, loss_ce: 0.011936
2022-01-20 16:59:38,564 iteration 3304 : loss : 0.043941, loss_ce: 0.024528
2022-01-20 16:59:39,908 iteration 3305 : loss : 0.034483, loss_ce: 0.013140
2022-01-20 16:59:41,165 iteration 3306 : loss : 0.020559, loss_ce: 0.008924
2022-01-20 16:59:42,558 iteration 3307 : loss : 0.022843, loss_ce: 0.008728
2022-01-20 16:59:43,980 iteration 3308 : loss : 0.026496, loss_ce: 0.008989
2022-01-20 16:59:45,315 iteration 3309 : loss : 0.019295, loss_ce: 0.008077
2022-01-20 16:59:46,696 iteration 3310 : loss : 0.030085, loss_ce: 0.007595
2022-01-20 16:59:47,982 iteration 3311 : loss : 0.022274, loss_ce: 0.006501
2022-01-20 16:59:49,220 iteration 3312 : loss : 0.018457, loss_ce: 0.008443
2022-01-20 16:59:50,582 iteration 3313 : loss : 0.041801, loss_ce: 0.017553
2022-01-20 16:59:51,763 iteration 3314 : loss : 0.020279, loss_ce: 0.008452
2022-01-20 16:59:51,763 Training Data Eval:
2022-01-20 16:59:58,266   Average segmentation loss on training set: 0.0166
2022-01-20 16:59:58,267 Validation Data Eval:
2022-01-20 17:00:00,468   Average segmentation loss on validation set: 0.0844
2022-01-20 17:00:01,736 iteration 3315 : loss : 0.023213, loss_ce: 0.009482
 49%|█████████████▏             | 195/400 [1:19:50<1:27:26, 25.60s/it]2022-01-20 17:00:03,089 iteration 3316 : loss : 0.024982, loss_ce: 0.005982
2022-01-20 17:00:04,413 iteration 3317 : loss : 0.031646, loss_ce: 0.010978
2022-01-20 17:00:05,727 iteration 3318 : loss : 0.023567, loss_ce: 0.009336
2022-01-20 17:00:06,966 iteration 3319 : loss : 0.019907, loss_ce: 0.007757
2022-01-20 17:00:08,376 iteration 3320 : loss : 0.027940, loss_ce: 0.009656
2022-01-20 17:00:09,613 iteration 3321 : loss : 0.021959, loss_ce: 0.009936
2022-01-20 17:00:10,821 iteration 3322 : loss : 0.020013, loss_ce: 0.006519
2022-01-20 17:00:12,147 iteration 3323 : loss : 0.035051, loss_ce: 0.016252
2022-01-20 17:00:13,456 iteration 3324 : loss : 0.027212, loss_ce: 0.008425
2022-01-20 17:00:14,844 iteration 3325 : loss : 0.028707, loss_ce: 0.009524
2022-01-20 17:00:16,162 iteration 3326 : loss : 0.028195, loss_ce: 0.009961
2022-01-20 17:00:17,626 iteration 3327 : loss : 0.036679, loss_ce: 0.011362
2022-01-20 17:00:18,877 iteration 3328 : loss : 0.020694, loss_ce: 0.009805
2022-01-20 17:00:20,128 iteration 3329 : loss : 0.020683, loss_ce: 0.007633
2022-01-20 17:00:21,451 iteration 3330 : loss : 0.026162, loss_ce: 0.012724
2022-01-20 17:00:22,659 iteration 3331 : loss : 0.016796, loss_ce: 0.006943
2022-01-20 17:00:23,869 iteration 3332 : loss : 0.018809, loss_ce: 0.005988
 49%|█████████████▏             | 196/400 [1:20:12<1:23:29, 24.56s/it]2022-01-20 17:00:25,239 iteration 3333 : loss : 0.022225, loss_ce: 0.008978
2022-01-20 17:00:26,544 iteration 3334 : loss : 0.025071, loss_ce: 0.010587
2022-01-20 17:00:27,913 iteration 3335 : loss : 0.030106, loss_ce: 0.011933
2022-01-20 17:00:29,158 iteration 3336 : loss : 0.020939, loss_ce: 0.007603
2022-01-20 17:00:30,415 iteration 3337 : loss : 0.021717, loss_ce: 0.008087
2022-01-20 17:00:31,771 iteration 3338 : loss : 0.024106, loss_ce: 0.009823
2022-01-20 17:00:33,128 iteration 3339 : loss : 0.033340, loss_ce: 0.011239
2022-01-20 17:00:34,435 iteration 3340 : loss : 0.031409, loss_ce: 0.012082
2022-01-20 17:00:35,695 iteration 3341 : loss : 0.019828, loss_ce: 0.008620
2022-01-20 17:00:36,967 iteration 3342 : loss : 0.023600, loss_ce: 0.013203
2022-01-20 17:00:38,263 iteration 3343 : loss : 0.026485, loss_ce: 0.010330
2022-01-20 17:00:39,634 iteration 3344 : loss : 0.023368, loss_ce: 0.006565
2022-01-20 17:00:41,006 iteration 3345 : loss : 0.027868, loss_ce: 0.013187
2022-01-20 17:00:42,313 iteration 3346 : loss : 0.030977, loss_ce: 0.010172
2022-01-20 17:00:43,591 iteration 3347 : loss : 0.020404, loss_ce: 0.006923
2022-01-20 17:00:44,982 iteration 3348 : loss : 0.023001, loss_ce: 0.009523
2022-01-20 17:00:46,227 iteration 3349 : loss : 0.031014, loss_ce: 0.008404
 49%|█████████████▎             | 197/400 [1:20:34<1:20:51, 23.90s/it]2022-01-20 17:00:47,552 iteration 3350 : loss : 0.018525, loss_ce: 0.008479
2022-01-20 17:00:48,888 iteration 3351 : loss : 0.022054, loss_ce: 0.007596
2022-01-20 17:00:50,147 iteration 3352 : loss : 0.021031, loss_ce: 0.007248
2022-01-20 17:00:51,445 iteration 3353 : loss : 0.025589, loss_ce: 0.007830
2022-01-20 17:00:52,699 iteration 3354 : loss : 0.020794, loss_ce: 0.005385
2022-01-20 17:00:54,010 iteration 3355 : loss : 0.020445, loss_ce: 0.007630
2022-01-20 17:00:55,264 iteration 3356 : loss : 0.055116, loss_ce: 0.033226
2022-01-20 17:00:56,524 iteration 3357 : loss : 0.019525, loss_ce: 0.008257
2022-01-20 17:00:57,819 iteration 3358 : loss : 0.022190, loss_ce: 0.007010
2022-01-20 17:00:59,098 iteration 3359 : loss : 0.025043, loss_ce: 0.010764
2022-01-20 17:01:00,448 iteration 3360 : loss : 0.019502, loss_ce: 0.006193
2022-01-20 17:01:01,752 iteration 3361 : loss : 0.026192, loss_ce: 0.010439
2022-01-20 17:01:03,011 iteration 3362 : loss : 0.022715, loss_ce: 0.008412
2022-01-20 17:01:04,218 iteration 3363 : loss : 0.022979, loss_ce: 0.007300
2022-01-20 17:01:05,594 iteration 3364 : loss : 0.023093, loss_ce: 0.009173
2022-01-20 17:01:06,875 iteration 3365 : loss : 0.020626, loss_ce: 0.008339
2022-01-20 17:01:08,164 iteration 3366 : loss : 0.019125, loss_ce: 0.007627
 50%|█████████████▎             | 198/400 [1:20:56<1:18:28, 23.31s/it]2022-01-20 17:01:09,643 iteration 3367 : loss : 0.029116, loss_ce: 0.011080
2022-01-20 17:01:10,923 iteration 3368 : loss : 0.026520, loss_ce: 0.013329
2022-01-20 17:01:12,233 iteration 3369 : loss : 0.024824, loss_ce: 0.011105
2022-01-20 17:01:13,476 iteration 3370 : loss : 0.022870, loss_ce: 0.006510
2022-01-20 17:01:14,769 iteration 3371 : loss : 0.020333, loss_ce: 0.007700
2022-01-20 17:01:16,134 iteration 3372 : loss : 0.040261, loss_ce: 0.011970
2022-01-20 17:01:17,442 iteration 3373 : loss : 0.020974, loss_ce: 0.007622
2022-01-20 17:01:18,826 iteration 3374 : loss : 0.017750, loss_ce: 0.007381
2022-01-20 17:01:20,229 iteration 3375 : loss : 0.038337, loss_ce: 0.009947
2022-01-20 17:01:21,431 iteration 3376 : loss : 0.016691, loss_ce: 0.005410
2022-01-20 17:01:22,788 iteration 3377 : loss : 0.026567, loss_ce: 0.010801
2022-01-20 17:01:24,053 iteration 3378 : loss : 0.027019, loss_ce: 0.008855
2022-01-20 17:01:25,407 iteration 3379 : loss : 0.025501, loss_ce: 0.008811
2022-01-20 17:01:26,658 iteration 3380 : loss : 0.021131, loss_ce: 0.006747
2022-01-20 17:01:27,978 iteration 3381 : loss : 0.027157, loss_ce: 0.013917
2022-01-20 17:01:29,316 iteration 3382 : loss : 0.027404, loss_ce: 0.008837
2022-01-20 17:01:30,605 iteration 3383 : loss : 0.018262, loss_ce: 0.007738
 50%|█████████████▍             | 199/400 [1:21:19<1:17:12, 23.05s/it]2022-01-20 17:01:31,973 iteration 3384 : loss : 0.022630, loss_ce: 0.008882
2022-01-20 17:01:33,242 iteration 3385 : loss : 0.027976, loss_ce: 0.010893
2022-01-20 17:01:34,502 iteration 3386 : loss : 0.022312, loss_ce: 0.008059
2022-01-20 17:01:35,760 iteration 3387 : loss : 0.031998, loss_ce: 0.010648
2022-01-20 17:01:37,127 iteration 3388 : loss : 0.038623, loss_ce: 0.013541
2022-01-20 17:01:38,360 iteration 3389 : loss : 0.021699, loss_ce: 0.006786
2022-01-20 17:01:39,679 iteration 3390 : loss : 0.024628, loss_ce: 0.010056
2022-01-20 17:01:41,084 iteration 3391 : loss : 0.023203, loss_ce: 0.012058
2022-01-20 17:01:42,430 iteration 3392 : loss : 0.028072, loss_ce: 0.012747
2022-01-20 17:01:43,646 iteration 3393 : loss : 0.021993, loss_ce: 0.009702
2022-01-20 17:01:44,924 iteration 3394 : loss : 0.022755, loss_ce: 0.007711
2022-01-20 17:01:46,235 iteration 3395 : loss : 0.026830, loss_ce: 0.012785
2022-01-20 17:01:47,551 iteration 3396 : loss : 0.032894, loss_ce: 0.013201
2022-01-20 17:01:48,784 iteration 3397 : loss : 0.022827, loss_ce: 0.010828
2022-01-20 17:01:50,233 iteration 3398 : loss : 0.037623, loss_ce: 0.015039
2022-01-20 17:01:51,551 iteration 3399 : loss : 0.023548, loss_ce: 0.011221
2022-01-20 17:01:51,552 Training Data Eval:
2022-01-20 17:01:58,033   Average segmentation loss on training set: 0.0162
2022-01-20 17:01:58,034 Validation Data Eval:
2022-01-20 17:02:00,261   Average segmentation loss on validation set: 0.0745
2022-01-20 17:02:01,599 iteration 3400 : loss : 0.027095, loss_ce: 0.008500
 50%|█████████████▌             | 200/400 [1:21:50<1:24:45, 25.43s/it]2022-01-20 17:02:03,028 iteration 3401 : loss : 0.027492, loss_ce: 0.010905
2022-01-20 17:02:04,350 iteration 3402 : loss : 0.027110, loss_ce: 0.011211
2022-01-20 17:02:05,742 iteration 3403 : loss : 0.028230, loss_ce: 0.011450
2022-01-20 17:02:06,985 iteration 3404 : loss : 0.023097, loss_ce: 0.007972
2022-01-20 17:02:08,267 iteration 3405 : loss : 0.022193, loss_ce: 0.005828
2022-01-20 17:02:09,491 iteration 3406 : loss : 0.018410, loss_ce: 0.008628
2022-01-20 17:02:10,759 iteration 3407 : loss : 0.021628, loss_ce: 0.007695
2022-01-20 17:02:12,093 iteration 3408 : loss : 0.021846, loss_ce: 0.008635
2022-01-20 17:02:13,395 iteration 3409 : loss : 0.022219, loss_ce: 0.004432
2022-01-20 17:02:14,691 iteration 3410 : loss : 0.021354, loss_ce: 0.008675
2022-01-20 17:02:16,038 iteration 3411 : loss : 0.022853, loss_ce: 0.006918
2022-01-20 17:02:17,411 iteration 3412 : loss : 0.023118, loss_ce: 0.010462
2022-01-20 17:02:18,815 iteration 3413 : loss : 0.024721, loss_ce: 0.012059
2022-01-20 17:02:20,188 iteration 3414 : loss : 0.032659, loss_ce: 0.011086
2022-01-20 17:02:21,386 iteration 3415 : loss : 0.019117, loss_ce: 0.007843
2022-01-20 17:02:22,735 iteration 3416 : loss : 0.025411, loss_ce: 0.010807
2022-01-20 17:02:24,024 iteration 3417 : loss : 0.019710, loss_ce: 0.007954
 50%|█████████████▌             | 201/400 [1:22:12<1:21:21, 24.53s/it]2022-01-20 17:02:25,503 iteration 3418 : loss : 0.043679, loss_ce: 0.011722
2022-01-20 17:02:26,834 iteration 3419 : loss : 0.044304, loss_ce: 0.020551
2022-01-20 17:02:28,100 iteration 3420 : loss : 0.024299, loss_ce: 0.013156
2022-01-20 17:02:29,433 iteration 3421 : loss : 0.033014, loss_ce: 0.010727
2022-01-20 17:02:30,762 iteration 3422 : loss : 0.034545, loss_ce: 0.013144
2022-01-20 17:02:32,153 iteration 3423 : loss : 0.027340, loss_ce: 0.012073
2022-01-20 17:02:33,405 iteration 3424 : loss : 0.018573, loss_ce: 0.005944
2022-01-20 17:02:34,747 iteration 3425 : loss : 0.029416, loss_ce: 0.014093
2022-01-20 17:02:36,053 iteration 3426 : loss : 0.019987, loss_ce: 0.005450
2022-01-20 17:02:37,500 iteration 3427 : loss : 0.034815, loss_ce: 0.012913
2022-01-20 17:02:38,827 iteration 3428 : loss : 0.021586, loss_ce: 0.008068
2022-01-20 17:02:40,171 iteration 3429 : loss : 0.029444, loss_ce: 0.014217
2022-01-20 17:02:41,521 iteration 3430 : loss : 0.021416, loss_ce: 0.007102
2022-01-20 17:02:42,913 iteration 3431 : loss : 0.033236, loss_ce: 0.011863
2022-01-20 17:02:44,209 iteration 3432 : loss : 0.025861, loss_ce: 0.007611
2022-01-20 17:02:45,558 iteration 3433 : loss : 0.022807, loss_ce: 0.006997
2022-01-20 17:02:46,889 iteration 3434 : loss : 0.020601, loss_ce: 0.005981
 50%|█████████████▋             | 202/400 [1:22:35<1:19:18, 24.03s/it]2022-01-20 17:02:48,245 iteration 3435 : loss : 0.021053, loss_ce: 0.009561
2022-01-20 17:02:49,582 iteration 3436 : loss : 0.031815, loss_ce: 0.011033
2022-01-20 17:02:50,886 iteration 3437 : loss : 0.018187, loss_ce: 0.005987
2022-01-20 17:02:52,227 iteration 3438 : loss : 0.025670, loss_ce: 0.012783
2022-01-20 17:02:53,647 iteration 3439 : loss : 0.021301, loss_ce: 0.008188
2022-01-20 17:02:55,055 iteration 3440 : loss : 0.034100, loss_ce: 0.011428
2022-01-20 17:02:56,253 iteration 3441 : loss : 0.019811, loss_ce: 0.009365
2022-01-20 17:02:57,544 iteration 3442 : loss : 0.016796, loss_ce: 0.005002
2022-01-20 17:02:58,935 iteration 3443 : loss : 0.020273, loss_ce: 0.006786
2022-01-20 17:03:00,228 iteration 3444 : loss : 0.027142, loss_ce: 0.008859
2022-01-20 17:03:01,592 iteration 3445 : loss : 0.021366, loss_ce: 0.007163
2022-01-20 17:03:02,903 iteration 3446 : loss : 0.024051, loss_ce: 0.008106
2022-01-20 17:03:04,223 iteration 3447 : loss : 0.025639, loss_ce: 0.014506
2022-01-20 17:03:05,459 iteration 3448 : loss : 0.022386, loss_ce: 0.007917
2022-01-20 17:03:06,796 iteration 3449 : loss : 0.030327, loss_ce: 0.008998
2022-01-20 17:03:08,166 iteration 3450 : loss : 0.021948, loss_ce: 0.007916
2022-01-20 17:03:09,417 iteration 3451 : loss : 0.017704, loss_ce: 0.007219
 51%|█████████████▋             | 203/400 [1:22:57<1:17:25, 23.58s/it]2022-01-20 17:03:10,813 iteration 3452 : loss : 0.024823, loss_ce: 0.009383
2022-01-20 17:03:12,169 iteration 3453 : loss : 0.027996, loss_ce: 0.008763
2022-01-20 17:03:13,556 iteration 3454 : loss : 0.054978, loss_ce: 0.016888
2022-01-20 17:03:14,895 iteration 3455 : loss : 0.022393, loss_ce: 0.009880
2022-01-20 17:03:16,234 iteration 3456 : loss : 0.027933, loss_ce: 0.009097
2022-01-20 17:03:17,571 iteration 3457 : loss : 0.022966, loss_ce: 0.009119
2022-01-20 17:03:18,920 iteration 3458 : loss : 0.021423, loss_ce: 0.010765
2022-01-20 17:03:20,321 iteration 3459 : loss : 0.026537, loss_ce: 0.011816
2022-01-20 17:03:21,660 iteration 3460 : loss : 0.023836, loss_ce: 0.008436
2022-01-20 17:03:22,963 iteration 3461 : loss : 0.023226, loss_ce: 0.009613
2022-01-20 17:03:24,210 iteration 3462 : loss : 0.022099, loss_ce: 0.008091
2022-01-20 17:03:25,431 iteration 3463 : loss : 0.017351, loss_ce: 0.005895
2022-01-20 17:03:26,733 iteration 3464 : loss : 0.025397, loss_ce: 0.009941
2022-01-20 17:03:27,995 iteration 3465 : loss : 0.029603, loss_ce: 0.011245
2022-01-20 17:03:29,342 iteration 3466 : loss : 0.018779, loss_ce: 0.007171
2022-01-20 17:03:30,748 iteration 3467 : loss : 0.022623, loss_ce: 0.008235
2022-01-20 17:03:32,178 iteration 3468 : loss : 0.020855, loss_ce: 0.005990
 51%|█████████████▊             | 204/400 [1:23:20<1:16:13, 23.33s/it]2022-01-20 17:03:33,447 iteration 3469 : loss : 0.020300, loss_ce: 0.007802
2022-01-20 17:03:34,907 iteration 3470 : loss : 0.028744, loss_ce: 0.009524
2022-01-20 17:03:36,261 iteration 3471 : loss : 0.023828, loss_ce: 0.008314
2022-01-20 17:03:37,635 iteration 3472 : loss : 0.025154, loss_ce: 0.011816
2022-01-20 17:03:39,010 iteration 3473 : loss : 0.037385, loss_ce: 0.018696
2022-01-20 17:03:40,298 iteration 3474 : loss : 0.022726, loss_ce: 0.009010
2022-01-20 17:03:41,710 iteration 3475 : loss : 0.031175, loss_ce: 0.011886
2022-01-20 17:03:43,018 iteration 3476 : loss : 0.020591, loss_ce: 0.007414
2022-01-20 17:03:44,379 iteration 3477 : loss : 0.028700, loss_ce: 0.008610
2022-01-20 17:03:45,708 iteration 3478 : loss : 0.020508, loss_ce: 0.007069
2022-01-20 17:03:46,989 iteration 3479 : loss : 0.021680, loss_ce: 0.009072
2022-01-20 17:03:48,258 iteration 3480 : loss : 0.025111, loss_ce: 0.011878
2022-01-20 17:03:49,585 iteration 3481 : loss : 0.022333, loss_ce: 0.012141
2022-01-20 17:03:50,821 iteration 3482 : loss : 0.023416, loss_ce: 0.007803
2022-01-20 17:03:52,205 iteration 3483 : loss : 0.022027, loss_ce: 0.007876
2022-01-20 17:03:53,501 iteration 3484 : loss : 0.027228, loss_ce: 0.008232
2022-01-20 17:03:53,502 Training Data Eval:
2022-01-20 17:04:00,031   Average segmentation loss on training set: 0.0155
2022-01-20 17:04:00,031 Validation Data Eval:
2022-01-20 17:04:02,253   Average segmentation loss on validation set: 0.0728
2022-01-20 17:04:03,569 iteration 3485 : loss : 0.018869, loss_ce: 0.007354
 51%|█████████████▊             | 205/400 [1:23:52<1:23:41, 25.75s/it]2022-01-20 17:04:04,899 iteration 3486 : loss : 0.017700, loss_ce: 0.005943
2022-01-20 17:04:06,209 iteration 3487 : loss : 0.025834, loss_ce: 0.009986
2022-01-20 17:04:07,573 iteration 3488 : loss : 0.020648, loss_ce: 0.012143
2022-01-20 17:04:08,830 iteration 3489 : loss : 0.045195, loss_ce: 0.017018
2022-01-20 17:04:10,223 iteration 3490 : loss : 0.025955, loss_ce: 0.011083
2022-01-20 17:04:11,578 iteration 3491 : loss : 0.024510, loss_ce: 0.012320
2022-01-20 17:04:12,803 iteration 3492 : loss : 0.018546, loss_ce: 0.005359
2022-01-20 17:04:14,219 iteration 3493 : loss : 0.049452, loss_ce: 0.010312
2022-01-20 17:04:15,555 iteration 3494 : loss : 0.021219, loss_ce: 0.010862
2022-01-20 17:04:16,768 iteration 3495 : loss : 0.018525, loss_ce: 0.007765
2022-01-20 17:04:18,112 iteration 3496 : loss : 0.032489, loss_ce: 0.008477
2022-01-20 17:04:19,497 iteration 3497 : loss : 0.024353, loss_ce: 0.012151
2022-01-20 17:04:20,806 iteration 3498 : loss : 0.030179, loss_ce: 0.013435
2022-01-20 17:04:22,181 iteration 3499 : loss : 0.038087, loss_ce: 0.010515
2022-01-20 17:04:23,463 iteration 3500 : loss : 0.023304, loss_ce: 0.006677
2022-01-20 17:04:24,804 iteration 3501 : loss : 0.022982, loss_ce: 0.008331
2022-01-20 17:04:26,125 iteration 3502 : loss : 0.033651, loss_ce: 0.011377
 52%|█████████████▉             | 206/400 [1:24:14<1:20:09, 24.79s/it]2022-01-20 17:04:27,427 iteration 3503 : loss : 0.017856, loss_ce: 0.008064
2022-01-20 17:04:28,764 iteration 3504 : loss : 0.022200, loss_ce: 0.008068
2022-01-20 17:04:30,091 iteration 3505 : loss : 0.022880, loss_ce: 0.011397
2022-01-20 17:04:31,510 iteration 3506 : loss : 0.028385, loss_ce: 0.010195
2022-01-20 17:04:32,793 iteration 3507 : loss : 0.018493, loss_ce: 0.007880
2022-01-20 17:04:34,045 iteration 3508 : loss : 0.020555, loss_ce: 0.006540
2022-01-20 17:04:35,336 iteration 3509 : loss : 0.026939, loss_ce: 0.011228
2022-01-20 17:04:36,761 iteration 3510 : loss : 0.023928, loss_ce: 0.009452
2022-01-20 17:04:38,045 iteration 3511 : loss : 0.021819, loss_ce: 0.009405
2022-01-20 17:04:39,375 iteration 3512 : loss : 0.026068, loss_ce: 0.008856
2022-01-20 17:04:40,613 iteration 3513 : loss : 0.032158, loss_ce: 0.010123
2022-01-20 17:04:41,832 iteration 3514 : loss : 0.016649, loss_ce: 0.007531
2022-01-20 17:04:43,107 iteration 3515 : loss : 0.017272, loss_ce: 0.005847
2022-01-20 17:04:44,467 iteration 3516 : loss : 0.025764, loss_ce: 0.008640
2022-01-20 17:04:45,782 iteration 3517 : loss : 0.022109, loss_ce: 0.008283
2022-01-20 17:04:47,030 iteration 3518 : loss : 0.015525, loss_ce: 0.006813
2022-01-20 17:04:48,299 iteration 3519 : loss : 0.025093, loss_ce: 0.009508
 52%|█████████████▉             | 207/400 [1:24:36<1:17:13, 24.01s/it]2022-01-20 17:04:49,657 iteration 3520 : loss : 0.021695, loss_ce: 0.007322
2022-01-20 17:04:50,996 iteration 3521 : loss : 0.023817, loss_ce: 0.010093
2022-01-20 17:04:52,329 iteration 3522 : loss : 0.024364, loss_ce: 0.011739
2022-01-20 17:04:53,748 iteration 3523 : loss : 0.028015, loss_ce: 0.010098
2022-01-20 17:04:55,022 iteration 3524 : loss : 0.028139, loss_ce: 0.008285
2022-01-20 17:04:56,352 iteration 3525 : loss : 0.026542, loss_ce: 0.011424
2022-01-20 17:04:57,665 iteration 3526 : loss : 0.021978, loss_ce: 0.010415
2022-01-20 17:04:59,005 iteration 3527 : loss : 0.025608, loss_ce: 0.009191
2022-01-20 17:05:00,253 iteration 3528 : loss : 0.022445, loss_ce: 0.013447
2022-01-20 17:05:01,573 iteration 3529 : loss : 0.021744, loss_ce: 0.007182
2022-01-20 17:05:02,873 iteration 3530 : loss : 0.030585, loss_ce: 0.010702
2022-01-20 17:05:04,208 iteration 3531 : loss : 0.023952, loss_ce: 0.009913
2022-01-20 17:05:05,483 iteration 3532 : loss : 0.017262, loss_ce: 0.005933
2022-01-20 17:05:06,738 iteration 3533 : loss : 0.021844, loss_ce: 0.008588
2022-01-20 17:05:08,022 iteration 3534 : loss : 0.020731, loss_ce: 0.010965
2022-01-20 17:05:09,263 iteration 3535 : loss : 0.020312, loss_ce: 0.007091
2022-01-20 17:05:10,503 iteration 3536 : loss : 0.020624, loss_ce: 0.005690
 52%|██████████████             | 208/400 [1:24:59<1:15:05, 23.47s/it]2022-01-20 17:05:11,829 iteration 3537 : loss : 0.028063, loss_ce: 0.010381
2022-01-20 17:05:13,122 iteration 3538 : loss : 0.038733, loss_ce: 0.010145
2022-01-20 17:05:14,461 iteration 3539 : loss : 0.020757, loss_ce: 0.009821
2022-01-20 17:05:15,710 iteration 3540 : loss : 0.021820, loss_ce: 0.005401
2022-01-20 17:05:17,093 iteration 3541 : loss : 0.021953, loss_ce: 0.008964
2022-01-20 17:05:18,363 iteration 3542 : loss : 0.044972, loss_ce: 0.010854
2022-01-20 17:05:19,706 iteration 3543 : loss : 0.021232, loss_ce: 0.009902
2022-01-20 17:05:21,060 iteration 3544 : loss : 0.023297, loss_ce: 0.008687
2022-01-20 17:05:22,331 iteration 3545 : loss : 0.019299, loss_ce: 0.006526
2022-01-20 17:05:23,544 iteration 3546 : loss : 0.023481, loss_ce: 0.010646
2022-01-20 17:05:24,899 iteration 3547 : loss : 0.031109, loss_ce: 0.010477
2022-01-20 17:05:26,241 iteration 3548 : loss : 0.023843, loss_ce: 0.008585
2022-01-20 17:05:27,537 iteration 3549 : loss : 0.024038, loss_ce: 0.010805
2022-01-20 17:05:28,787 iteration 3550 : loss : 0.017201, loss_ce: 0.005718
2022-01-20 17:05:30,164 iteration 3551 : loss : 0.049613, loss_ce: 0.017213
2022-01-20 17:05:31,540 iteration 3552 : loss : 0.050747, loss_ce: 0.024603
2022-01-20 17:05:32,913 iteration 3553 : loss : 0.031033, loss_ce: 0.012069
 52%|██████████████             | 209/400 [1:25:21<1:13:40, 23.14s/it]2022-01-20 17:05:34,276 iteration 3554 : loss : 0.023175, loss_ce: 0.008682
2022-01-20 17:05:35,648 iteration 3555 : loss : 0.024849, loss_ce: 0.011115
2022-01-20 17:05:36,967 iteration 3556 : loss : 0.033601, loss_ce: 0.011216
2022-01-20 17:05:38,272 iteration 3557 : loss : 0.018615, loss_ce: 0.008407
2022-01-20 17:05:39,532 iteration 3558 : loss : 0.020824, loss_ce: 0.007406
2022-01-20 17:05:40,917 iteration 3559 : loss : 0.029129, loss_ce: 0.010400
2022-01-20 17:05:42,217 iteration 3560 : loss : 0.029783, loss_ce: 0.009086
2022-01-20 17:05:43,554 iteration 3561 : loss : 0.024195, loss_ce: 0.012114
2022-01-20 17:05:44,920 iteration 3562 : loss : 0.027120, loss_ce: 0.010540
2022-01-20 17:05:46,224 iteration 3563 : loss : 0.020293, loss_ce: 0.007584
2022-01-20 17:05:47,567 iteration 3564 : loss : 0.033268, loss_ce: 0.009784
2022-01-20 17:05:48,813 iteration 3565 : loss : 0.020378, loss_ce: 0.008257
2022-01-20 17:05:50,005 iteration 3566 : loss : 0.018997, loss_ce: 0.007222
2022-01-20 17:05:51,249 iteration 3567 : loss : 0.028858, loss_ce: 0.009574
2022-01-20 17:05:52,594 iteration 3568 : loss : 0.026776, loss_ce: 0.009027
2022-01-20 17:05:53,851 iteration 3569 : loss : 0.021160, loss_ce: 0.009213
2022-01-20 17:05:53,879 Training Data Eval:
2022-01-20 17:06:00,403   Average segmentation loss on training set: 0.0171
2022-01-20 17:06:00,403 Validation Data Eval:
2022-01-20 17:06:02,615   Average segmentation loss on validation set: 0.1253
2022-01-20 17:06:03,898 iteration 3570 : loss : 0.023284, loss_ce: 0.006012
 52%|██████████████▏            | 210/400 [1:25:52<1:20:44, 25.50s/it]2022-01-20 17:06:05,289 iteration 3571 : loss : 0.025143, loss_ce: 0.010472
2022-01-20 17:06:06,667 iteration 3572 : loss : 0.022165, loss_ce: 0.007916
2022-01-20 17:06:07,996 iteration 3573 : loss : 0.023686, loss_ce: 0.008928
2022-01-20 17:06:09,254 iteration 3574 : loss : 0.020114, loss_ce: 0.009479
2022-01-20 17:06:10,500 iteration 3575 : loss : 0.027316, loss_ce: 0.011045
2022-01-20 17:06:11,759 iteration 3576 : loss : 0.033351, loss_ce: 0.010157
2022-01-20 17:06:13,096 iteration 3577 : loss : 0.023961, loss_ce: 0.009613
2022-01-20 17:06:14,383 iteration 3578 : loss : 0.025957, loss_ce: 0.011585
2022-01-20 17:06:15,701 iteration 3579 : loss : 0.025546, loss_ce: 0.009600
2022-01-20 17:06:17,064 iteration 3580 : loss : 0.023431, loss_ce: 0.010511
2022-01-20 17:06:18,420 iteration 3581 : loss : 0.026754, loss_ce: 0.009239
2022-01-20 17:06:19,756 iteration 3582 : loss : 0.027334, loss_ce: 0.008655
2022-01-20 17:06:21,061 iteration 3583 : loss : 0.034645, loss_ce: 0.008221
2022-01-20 17:06:22,293 iteration 3584 : loss : 0.020532, loss_ce: 0.007486
2022-01-20 17:06:23,581 iteration 3585 : loss : 0.016315, loss_ce: 0.006493
2022-01-20 17:06:24,839 iteration 3586 : loss : 0.024403, loss_ce: 0.008839
2022-01-20 17:06:26,146 iteration 3587 : loss : 0.017790, loss_ce: 0.007912
 53%|██████████████▏            | 211/400 [1:26:14<1:17:14, 24.52s/it]2022-01-20 17:06:27,572 iteration 3588 : loss : 0.017215, loss_ce: 0.006646
2022-01-20 17:06:28,952 iteration 3589 : loss : 0.030171, loss_ce: 0.008446
2022-01-20 17:06:30,258 iteration 3590 : loss : 0.018317, loss_ce: 0.005235
2022-01-20 17:06:31,503 iteration 3591 : loss : 0.019412, loss_ce: 0.006434
2022-01-20 17:06:32,801 iteration 3592 : loss : 0.028842, loss_ce: 0.012567
2022-01-20 17:06:34,141 iteration 3593 : loss : 0.024070, loss_ce: 0.011643
2022-01-20 17:06:35,445 iteration 3594 : loss : 0.023741, loss_ce: 0.007244
2022-01-20 17:06:36,746 iteration 3595 : loss : 0.026538, loss_ce: 0.008855
2022-01-20 17:06:38,007 iteration 3596 : loss : 0.020782, loss_ce: 0.008637
2022-01-20 17:06:39,332 iteration 3597 : loss : 0.022288, loss_ce: 0.009534
2022-01-20 17:06:40,671 iteration 3598 : loss : 0.023836, loss_ce: 0.012099
2022-01-20 17:06:42,013 iteration 3599 : loss : 0.031828, loss_ce: 0.010495
2022-01-20 17:06:43,253 iteration 3600 : loss : 0.022111, loss_ce: 0.012592
2022-01-20 17:06:44,585 iteration 3601 : loss : 0.020867, loss_ce: 0.008108
2022-01-20 17:06:45,940 iteration 3602 : loss : 0.023402, loss_ce: 0.008479
2022-01-20 17:06:47,217 iteration 3603 : loss : 0.024513, loss_ce: 0.011828
2022-01-20 17:06:48,537 iteration 3604 : loss : 0.033171, loss_ce: 0.009805
 53%|██████████████▎            | 212/400 [1:26:37<1:14:50, 23.88s/it]2022-01-20 17:06:50,011 iteration 3605 : loss : 0.033438, loss_ce: 0.011902
2022-01-20 17:06:51,237 iteration 3606 : loss : 0.027028, loss_ce: 0.006169
2022-01-20 17:06:52,442 iteration 3607 : loss : 0.013330, loss_ce: 0.004697
2022-01-20 17:06:53,828 iteration 3608 : loss : 0.027024, loss_ce: 0.009306
2022-01-20 17:06:55,201 iteration 3609 : loss : 0.048448, loss_ce: 0.018866
2022-01-20 17:06:56,466 iteration 3610 : loss : 0.014736, loss_ce: 0.006013
2022-01-20 17:06:57,787 iteration 3611 : loss : 0.033092, loss_ce: 0.017836
2022-01-20 17:06:59,060 iteration 3612 : loss : 0.023990, loss_ce: 0.010858
2022-01-20 17:07:00,380 iteration 3613 : loss : 0.045926, loss_ce: 0.022688
2022-01-20 17:07:01,672 iteration 3614 : loss : 0.021440, loss_ce: 0.008435
2022-01-20 17:07:02,970 iteration 3615 : loss : 0.030012, loss_ce: 0.008881
2022-01-20 17:07:04,268 iteration 3616 : loss : 0.028462, loss_ce: 0.013513
2022-01-20 17:07:05,602 iteration 3617 : loss : 0.019448, loss_ce: 0.008705
2022-01-20 17:07:06,924 iteration 3618 : loss : 0.025379, loss_ce: 0.008921
2022-01-20 17:07:08,210 iteration 3619 : loss : 0.021791, loss_ce: 0.007601
2022-01-20 17:07:09,537 iteration 3620 : loss : 0.043842, loss_ce: 0.014522
2022-01-20 17:07:10,834 iteration 3621 : loss : 0.024135, loss_ce: 0.010798
 53%|██████████████▍            | 213/400 [1:26:59<1:12:57, 23.41s/it]2022-01-20 17:07:12,208 iteration 3622 : loss : 0.022047, loss_ce: 0.006983
2022-01-20 17:07:13,521 iteration 3623 : loss : 0.036225, loss_ce: 0.013652
2022-01-20 17:07:14,841 iteration 3624 : loss : 0.037358, loss_ce: 0.016758
2022-01-20 17:07:16,050 iteration 3625 : loss : 0.025539, loss_ce: 0.010124
2022-01-20 17:07:17,365 iteration 3626 : loss : 0.024362, loss_ce: 0.007529
2022-01-20 17:07:18,706 iteration 3627 : loss : 0.029808, loss_ce: 0.012627
2022-01-20 17:07:20,043 iteration 3628 : loss : 0.030761, loss_ce: 0.010708
2022-01-20 17:07:21,422 iteration 3629 : loss : 0.026770, loss_ce: 0.011653
2022-01-20 17:07:22,740 iteration 3630 : loss : 0.023765, loss_ce: 0.010824
2022-01-20 17:07:24,046 iteration 3631 : loss : 0.035515, loss_ce: 0.012881
2022-01-20 17:07:25,396 iteration 3632 : loss : 0.022876, loss_ce: 0.011943
2022-01-20 17:07:26,752 iteration 3633 : loss : 0.048834, loss_ce: 0.027341
2022-01-20 17:07:28,029 iteration 3634 : loss : 0.026918, loss_ce: 0.008913
2022-01-20 17:07:29,479 iteration 3635 : loss : 0.031655, loss_ce: 0.014627
2022-01-20 17:07:30,701 iteration 3636 : loss : 0.021843, loss_ce: 0.009963
2022-01-20 17:07:32,016 iteration 3637 : loss : 0.024801, loss_ce: 0.010083
2022-01-20 17:07:33,358 iteration 3638 : loss : 0.022609, loss_ce: 0.007870
 54%|██████████████▍            | 214/400 [1:27:21<1:11:45, 23.15s/it]2022-01-20 17:07:34,746 iteration 3639 : loss : 0.046588, loss_ce: 0.012292
2022-01-20 17:07:36,112 iteration 3640 : loss : 0.049216, loss_ce: 0.015672
2022-01-20 17:07:37,458 iteration 3641 : loss : 0.020332, loss_ce: 0.007821
2022-01-20 17:07:38,736 iteration 3642 : loss : 0.028640, loss_ce: 0.012833
2022-01-20 17:07:40,071 iteration 3643 : loss : 0.036366, loss_ce: 0.011812
2022-01-20 17:07:41,422 iteration 3644 : loss : 0.023306, loss_ce: 0.008626
2022-01-20 17:07:42,818 iteration 3645 : loss : 0.038915, loss_ce: 0.009974
2022-01-20 17:07:44,157 iteration 3646 : loss : 0.025566, loss_ce: 0.011915
2022-01-20 17:07:45,434 iteration 3647 : loss : 0.023001, loss_ce: 0.009401
2022-01-20 17:07:46,768 iteration 3648 : loss : 0.036738, loss_ce: 0.014798
2022-01-20 17:07:47,970 iteration 3649 : loss : 0.026664, loss_ce: 0.009971
2022-01-20 17:07:49,304 iteration 3650 : loss : 0.022765, loss_ce: 0.009158
2022-01-20 17:07:50,569 iteration 3651 : loss : 0.023457, loss_ce: 0.008849
2022-01-20 17:07:51,804 iteration 3652 : loss : 0.022646, loss_ce: 0.009123
2022-01-20 17:07:53,164 iteration 3653 : loss : 0.072144, loss_ce: 0.039134
2022-01-20 17:07:54,442 iteration 3654 : loss : 0.023337, loss_ce: 0.009823
2022-01-20 17:07:54,442 Training Data Eval:
2022-01-20 17:08:00,956   Average segmentation loss on training set: 0.0200
2022-01-20 17:08:00,957 Validation Data Eval:
2022-01-20 17:08:03,178   Average segmentation loss on validation set: 0.0861
2022-01-20 17:08:04,667 iteration 3655 : loss : 0.033953, loss_ce: 0.012071
 54%|██████████████▌            | 215/400 [1:27:53<1:18:53, 25.59s/it]2022-01-20 17:08:06,014 iteration 3656 : loss : 0.022473, loss_ce: 0.007715
2022-01-20 17:08:07,352 iteration 3657 : loss : 0.021603, loss_ce: 0.009125
2022-01-20 17:08:08,642 iteration 3658 : loss : 0.034264, loss_ce: 0.017262
2022-01-20 17:08:09,870 iteration 3659 : loss : 0.033280, loss_ce: 0.011337
2022-01-20 17:08:11,257 iteration 3660 : loss : 0.030258, loss_ce: 0.012110
2022-01-20 17:08:12,539 iteration 3661 : loss : 0.028704, loss_ce: 0.011525
2022-01-20 17:08:13,778 iteration 3662 : loss : 0.022342, loss_ce: 0.010425
2022-01-20 17:08:15,074 iteration 3663 : loss : 0.021110, loss_ce: 0.007738
2022-01-20 17:08:16,413 iteration 3664 : loss : 0.023905, loss_ce: 0.007243
2022-01-20 17:08:17,838 iteration 3665 : loss : 0.039342, loss_ce: 0.009236
2022-01-20 17:08:19,188 iteration 3666 : loss : 0.028618, loss_ce: 0.012478
2022-01-20 17:08:20,462 iteration 3667 : loss : 0.023535, loss_ce: 0.008696
2022-01-20 17:08:21,754 iteration 3668 : loss : 0.029728, loss_ce: 0.011198
2022-01-20 17:08:23,079 iteration 3669 : loss : 0.044577, loss_ce: 0.016292
2022-01-20 17:08:24,309 iteration 3670 : loss : 0.020116, loss_ce: 0.009184
2022-01-20 17:08:25,600 iteration 3671 : loss : 0.034764, loss_ce: 0.009939
2022-01-20 17:08:26,880 iteration 3672 : loss : 0.028567, loss_ce: 0.007322
 54%|██████████████▌            | 216/400 [1:28:15<1:15:22, 24.58s/it]2022-01-20 17:08:28,225 iteration 3673 : loss : 0.018239, loss_ce: 0.007840
2022-01-20 17:08:29,608 iteration 3674 : loss : 0.018668, loss_ce: 0.008811
2022-01-20 17:08:30,996 iteration 3675 : loss : 0.027406, loss_ce: 0.013341
2022-01-20 17:08:32,357 iteration 3676 : loss : 0.026535, loss_ce: 0.008748
2022-01-20 17:08:33,692 iteration 3677 : loss : 0.024671, loss_ce: 0.011769
2022-01-20 17:08:35,088 iteration 3678 : loss : 0.026923, loss_ce: 0.009084
2022-01-20 17:08:36,309 iteration 3679 : loss : 0.020196, loss_ce: 0.007922
2022-01-20 17:08:37,560 iteration 3680 : loss : 0.019299, loss_ce: 0.007517
2022-01-20 17:08:38,876 iteration 3681 : loss : 0.033079, loss_ce: 0.009211
2022-01-20 17:08:40,105 iteration 3682 : loss : 0.018440, loss_ce: 0.005965
2022-01-20 17:08:41,415 iteration 3683 : loss : 0.020062, loss_ce: 0.008716
2022-01-20 17:08:42,659 iteration 3684 : loss : 0.027204, loss_ce: 0.009319
2022-01-20 17:08:43,944 iteration 3685 : loss : 0.016928, loss_ce: 0.005893
2022-01-20 17:08:45,337 iteration 3686 : loss : 0.024386, loss_ce: 0.009506
2022-01-20 17:08:46,725 iteration 3687 : loss : 0.028208, loss_ce: 0.011388
2022-01-20 17:08:48,060 iteration 3688 : loss : 0.030974, loss_ce: 0.011830
2022-01-20 17:08:49,414 iteration 3689 : loss : 0.035919, loss_ce: 0.009953
 54%|██████████████▋            | 217/400 [1:28:37<1:13:05, 23.97s/it]2022-01-20 17:08:50,937 iteration 3690 : loss : 0.025389, loss_ce: 0.012408
2022-01-20 17:08:52,232 iteration 3691 : loss : 0.027128, loss_ce: 0.007700
2022-01-20 17:08:53,580 iteration 3692 : loss : 0.025083, loss_ce: 0.008647
2022-01-20 17:08:54,844 iteration 3693 : loss : 0.015751, loss_ce: 0.003992
2022-01-20 17:08:56,204 iteration 3694 : loss : 0.031956, loss_ce: 0.010802
2022-01-20 17:08:57,533 iteration 3695 : loss : 0.022992, loss_ce: 0.008105
2022-01-20 17:08:58,795 iteration 3696 : loss : 0.015458, loss_ce: 0.005960
2022-01-20 17:09:00,059 iteration 3697 : loss : 0.021278, loss_ce: 0.007035
2022-01-20 17:09:01,461 iteration 3698 : loss : 0.023065, loss_ce: 0.007118
2022-01-20 17:09:02,763 iteration 3699 : loss : 0.021276, loss_ce: 0.010313
2022-01-20 17:09:04,058 iteration 3700 : loss : 0.017884, loss_ce: 0.005811
2022-01-20 17:09:05,297 iteration 3701 : loss : 0.028117, loss_ce: 0.017277
2022-01-20 17:09:06,662 iteration 3702 : loss : 0.024332, loss_ce: 0.009928
2022-01-20 17:09:07,974 iteration 3703 : loss : 0.017452, loss_ce: 0.006416
2022-01-20 17:09:09,266 iteration 3704 : loss : 0.024341, loss_ce: 0.008532
2022-01-20 17:09:10,582 iteration 3705 : loss : 0.029368, loss_ce: 0.014431
2022-01-20 17:09:11,820 iteration 3706 : loss : 0.019042, loss_ce: 0.006701
 55%|██████████████▋            | 218/400 [1:29:00<1:11:16, 23.50s/it]2022-01-20 17:09:13,212 iteration 3707 : loss : 0.065693, loss_ce: 0.010632
2022-01-20 17:09:14,634 iteration 3708 : loss : 0.041214, loss_ce: 0.012672
2022-01-20 17:09:15,921 iteration 3709 : loss : 0.022264, loss_ce: 0.006732
2022-01-20 17:09:17,127 iteration 3710 : loss : 0.017631, loss_ce: 0.006947
2022-01-20 17:09:18,556 iteration 3711 : loss : 0.025613, loss_ce: 0.011807
2022-01-20 17:09:19,803 iteration 3712 : loss : 0.030140, loss_ce: 0.010833
2022-01-20 17:09:21,034 iteration 3713 : loss : 0.018125, loss_ce: 0.007045
2022-01-20 17:09:22,388 iteration 3714 : loss : 0.035679, loss_ce: 0.018703
2022-01-20 17:09:23,667 iteration 3715 : loss : 0.018886, loss_ce: 0.007064
2022-01-20 17:09:24,981 iteration 3716 : loss : 0.035345, loss_ce: 0.014300
2022-01-20 17:09:26,311 iteration 3717 : loss : 0.019298, loss_ce: 0.008631
2022-01-20 17:09:27,679 iteration 3718 : loss : 0.026117, loss_ce: 0.008833
2022-01-20 17:09:29,117 iteration 3719 : loss : 0.023254, loss_ce: 0.007905
2022-01-20 17:09:30,513 iteration 3720 : loss : 0.019848, loss_ce: 0.008575
2022-01-20 17:09:31,821 iteration 3721 : loss : 0.025288, loss_ce: 0.010297
2022-01-20 17:09:33,194 iteration 3722 : loss : 0.025633, loss_ce: 0.007778
2022-01-20 17:09:34,464 iteration 3723 : loss : 0.026807, loss_ce: 0.011418
 55%|██████████████▊            | 219/400 [1:29:22<1:10:06, 23.24s/it]2022-01-20 17:09:35,809 iteration 3724 : loss : 0.024160, loss_ce: 0.012081
2022-01-20 17:09:37,153 iteration 3725 : loss : 0.034535, loss_ce: 0.013358
2022-01-20 17:09:38,434 iteration 3726 : loss : 0.021409, loss_ce: 0.009351
2022-01-20 17:09:39,751 iteration 3727 : loss : 0.017996, loss_ce: 0.006273
2022-01-20 17:09:40,976 iteration 3728 : loss : 0.018114, loss_ce: 0.008383
2022-01-20 17:09:42,335 iteration 3729 : loss : 0.035974, loss_ce: 0.009296
2022-01-20 17:09:43,592 iteration 3730 : loss : 0.018388, loss_ce: 0.006827
2022-01-20 17:09:44,966 iteration 3731 : loss : 0.030332, loss_ce: 0.010710
2022-01-20 17:09:46,269 iteration 3732 : loss : 0.021342, loss_ce: 0.010751
2022-01-20 17:09:47,510 iteration 3733 : loss : 0.017644, loss_ce: 0.004822
2022-01-20 17:09:48,874 iteration 3734 : loss : 0.025603, loss_ce: 0.008329
2022-01-20 17:09:50,267 iteration 3735 : loss : 0.025573, loss_ce: 0.009627
2022-01-20 17:09:51,611 iteration 3736 : loss : 0.042708, loss_ce: 0.017871
2022-01-20 17:09:53,014 iteration 3737 : loss : 0.033021, loss_ce: 0.014968
2022-01-20 17:09:54,349 iteration 3738 : loss : 0.028595, loss_ce: 0.008655
2022-01-20 17:09:55,687 iteration 3739 : loss : 0.029173, loss_ce: 0.011436
2022-01-20 17:09:55,687 Training Data Eval:
2022-01-20 17:10:02,420   Average segmentation loss on training set: 0.0162
2022-01-20 17:10:02,420 Validation Data Eval:
2022-01-20 17:10:04,689   Average segmentation loss on validation set: 0.0805
2022-01-20 17:10:06,008 iteration 3740 : loss : 0.024156, loss_ce: 0.007585
 55%|██████████████▊            | 220/400 [1:29:54<1:17:11, 25.73s/it]2022-01-20 17:10:07,411 iteration 3741 : loss : 0.034101, loss_ce: 0.015658
2022-01-20 17:10:08,706 iteration 3742 : loss : 0.022864, loss_ce: 0.008359
2022-01-20 17:10:09,988 iteration 3743 : loss : 0.020595, loss_ce: 0.006137
2022-01-20 17:10:11,329 iteration 3744 : loss : 0.025526, loss_ce: 0.009878
2022-01-20 17:10:12,731 iteration 3745 : loss : 0.028531, loss_ce: 0.015871
2022-01-20 17:10:14,018 iteration 3746 : loss : 0.032251, loss_ce: 0.010808
2022-01-20 17:10:15,370 iteration 3747 : loss : 0.028163, loss_ce: 0.013054
2022-01-20 17:10:16,738 iteration 3748 : loss : 0.024819, loss_ce: 0.009146
2022-01-20 17:10:18,048 iteration 3749 : loss : 0.021065, loss_ce: 0.005782
2022-01-20 17:10:19,476 iteration 3750 : loss : 0.032268, loss_ce: 0.011863
2022-01-20 17:10:20,773 iteration 3751 : loss : 0.043801, loss_ce: 0.030706
2022-01-20 17:10:22,048 iteration 3752 : loss : 0.032990, loss_ce: 0.013300
2022-01-20 17:10:23,342 iteration 3753 : loss : 0.031851, loss_ce: 0.010671
2022-01-20 17:10:24,579 iteration 3754 : loss : 0.031838, loss_ce: 0.017074
2022-01-20 17:10:25,906 iteration 3755 : loss : 0.041299, loss_ce: 0.020934
2022-01-20 17:10:27,181 iteration 3756 : loss : 0.022565, loss_ce: 0.008768
2022-01-20 17:10:28,493 iteration 3757 : loss : 0.033669, loss_ce: 0.013441
 55%|██████████████▉            | 221/400 [1:30:17<1:13:52, 24.76s/it]2022-01-20 17:10:29,910 iteration 3758 : loss : 0.026333, loss_ce: 0.010967
2022-01-20 17:10:31,267 iteration 3759 : loss : 0.026162, loss_ce: 0.012134
2022-01-20 17:10:32,610 iteration 3760 : loss : 0.042123, loss_ce: 0.019725
2022-01-20 17:10:33,923 iteration 3761 : loss : 0.022043, loss_ce: 0.011317
2022-01-20 17:10:35,287 iteration 3762 : loss : 0.036402, loss_ce: 0.015350
2022-01-20 17:10:36,648 iteration 3763 : loss : 0.038126, loss_ce: 0.019230
2022-01-20 17:10:37,912 iteration 3764 : loss : 0.041552, loss_ce: 0.012416
2022-01-20 17:10:39,154 iteration 3765 : loss : 0.026733, loss_ce: 0.010932
2022-01-20 17:10:40,441 iteration 3766 : loss : 0.025354, loss_ce: 0.009164
2022-01-20 17:10:41,783 iteration 3767 : loss : 0.024397, loss_ce: 0.008567
2022-01-20 17:10:43,202 iteration 3768 : loss : 0.027959, loss_ce: 0.009630
2022-01-20 17:10:44,552 iteration 3769 : loss : 0.027020, loss_ce: 0.010006
2022-01-20 17:10:45,966 iteration 3770 : loss : 0.020617, loss_ce: 0.008783
2022-01-20 17:10:47,343 iteration 3771 : loss : 0.032219, loss_ce: 0.017396
2022-01-20 17:10:48,734 iteration 3772 : loss : 0.043001, loss_ce: 0.012046
2022-01-20 17:10:50,097 iteration 3773 : loss : 0.027576, loss_ce: 0.009862
2022-01-20 17:10:51,462 iteration 3774 : loss : 0.025460, loss_ce: 0.011970
 56%|██████████████▉            | 222/400 [1:30:40<1:11:52, 24.22s/it]2022-01-20 17:10:52,920 iteration 3775 : loss : 0.032046, loss_ce: 0.012130
2022-01-20 17:10:54,250 iteration 3776 : loss : 0.017535, loss_ce: 0.007108
2022-01-20 17:10:55,600 iteration 3777 : loss : 0.023102, loss_ce: 0.007674
2022-01-20 17:10:57,008 iteration 3778 : loss : 0.029666, loss_ce: 0.012777
2022-01-20 17:10:58,304 iteration 3779 : loss : 0.025039, loss_ce: 0.010211
2022-01-20 17:10:59,730 iteration 3780 : loss : 0.028803, loss_ce: 0.013868
2022-01-20 17:11:01,150 iteration 3781 : loss : 0.030068, loss_ce: 0.009820
2022-01-20 17:11:02,589 iteration 3782 : loss : 0.034681, loss_ce: 0.012470
2022-01-20 17:11:04,019 iteration 3783 : loss : 0.024282, loss_ce: 0.011908
2022-01-20 17:11:05,337 iteration 3784 : loss : 0.022655, loss_ce: 0.006253
2022-01-20 17:11:06,700 iteration 3785 : loss : 0.034295, loss_ce: 0.009889
2022-01-20 17:11:08,053 iteration 3786 : loss : 0.020791, loss_ce: 0.008605
2022-01-20 17:11:09,346 iteration 3787 : loss : 0.025472, loss_ce: 0.011147
2022-01-20 17:11:10,704 iteration 3788 : loss : 0.031143, loss_ce: 0.010880
2022-01-20 17:11:12,032 iteration 3789 : loss : 0.025353, loss_ce: 0.009291
2022-01-20 17:11:13,331 iteration 3790 : loss : 0.022647, loss_ce: 0.008399
2022-01-20 17:11:14,731 iteration 3791 : loss : 0.021756, loss_ce: 0.008294
 56%|███████████████            | 223/400 [1:31:03<1:10:36, 23.94s/it]2022-01-20 17:11:16,080 iteration 3792 : loss : 0.019177, loss_ce: 0.007036
2022-01-20 17:11:17,325 iteration 3793 : loss : 0.016818, loss_ce: 0.004121
2022-01-20 17:11:18,631 iteration 3794 : loss : 0.022540, loss_ce: 0.009811
2022-01-20 17:11:19,924 iteration 3795 : loss : 0.018445, loss_ce: 0.005853
2022-01-20 17:11:21,320 iteration 3796 : loss : 0.037342, loss_ce: 0.011709
2022-01-20 17:11:22,672 iteration 3797 : loss : 0.017317, loss_ce: 0.005117
2022-01-20 17:11:23,947 iteration 3798 : loss : 0.018445, loss_ce: 0.007087
2022-01-20 17:11:25,381 iteration 3799 : loss : 0.029742, loss_ce: 0.011090
2022-01-20 17:11:26,868 iteration 3800 : loss : 0.039424, loss_ce: 0.019918
2022-01-20 17:11:28,279 iteration 3801 : loss : 0.024910, loss_ce: 0.007016
2022-01-20 17:11:29,665 iteration 3802 : loss : 0.021422, loss_ce: 0.007873
2022-01-20 17:11:30,981 iteration 3803 : loss : 0.029383, loss_ce: 0.009891
2022-01-20 17:11:32,304 iteration 3804 : loss : 0.018229, loss_ce: 0.006325
2022-01-20 17:11:33,632 iteration 3805 : loss : 0.024224, loss_ce: 0.008349
2022-01-20 17:11:34,875 iteration 3806 : loss : 0.020131, loss_ce: 0.008902
2022-01-20 17:11:36,240 iteration 3807 : loss : 0.023956, loss_ce: 0.007913
2022-01-20 17:11:37,529 iteration 3808 : loss : 0.027843, loss_ce: 0.011462
 56%|███████████████            | 224/400 [1:31:26<1:09:12, 23.59s/it]2022-01-20 17:11:38,921 iteration 3809 : loss : 0.020148, loss_ce: 0.008821
2022-01-20 17:11:40,269 iteration 3810 : loss : 0.028149, loss_ce: 0.011490
2022-01-20 17:11:41,547 iteration 3811 : loss : 0.018603, loss_ce: 0.006521
2022-01-20 17:11:42,882 iteration 3812 : loss : 0.030051, loss_ce: 0.011534
2022-01-20 17:11:44,099 iteration 3813 : loss : 0.018997, loss_ce: 0.008153
2022-01-20 17:11:45,470 iteration 3814 : loss : 0.028157, loss_ce: 0.013608
2022-01-20 17:11:46,896 iteration 3815 : loss : 0.022266, loss_ce: 0.008433
2022-01-20 17:11:48,168 iteration 3816 : loss : 0.014847, loss_ce: 0.005491
2022-01-20 17:11:49,389 iteration 3817 : loss : 0.016744, loss_ce: 0.005715
2022-01-20 17:11:50,706 iteration 3818 : loss : 0.019394, loss_ce: 0.005302
2022-01-20 17:11:52,095 iteration 3819 : loss : 0.032072, loss_ce: 0.011906
2022-01-20 17:11:53,349 iteration 3820 : loss : 0.016031, loss_ce: 0.006710
2022-01-20 17:11:54,762 iteration 3821 : loss : 0.025903, loss_ce: 0.015154
2022-01-20 17:11:56,083 iteration 3822 : loss : 0.023563, loss_ce: 0.007161
2022-01-20 17:11:57,393 iteration 3823 : loss : 0.027180, loss_ce: 0.008563
2022-01-20 17:11:58,769 iteration 3824 : loss : 0.024635, loss_ce: 0.009305
2022-01-20 17:11:58,769 Training Data Eval:
2022-01-20 17:12:05,453   Average segmentation loss on training set: 0.0147
2022-01-20 17:12:05,454 Validation Data Eval:
2022-01-20 17:12:07,691   Average segmentation loss on validation set: 0.0976
2022-01-20 17:12:08,925 iteration 3825 : loss : 0.017165, loss_ce: 0.005923
 56%|███████████████▏           | 225/400 [1:31:57<1:15:39, 25.94s/it]2022-01-20 17:12:10,398 iteration 3826 : loss : 0.036968, loss_ce: 0.019211
2022-01-20 17:12:11,785 iteration 3827 : loss : 0.020136, loss_ce: 0.008428
2022-01-20 17:12:13,034 iteration 3828 : loss : 0.020348, loss_ce: 0.012618
2022-01-20 17:12:14,302 iteration 3829 : loss : 0.013991, loss_ce: 0.005635
2022-01-20 17:12:15,724 iteration 3830 : loss : 0.027511, loss_ce: 0.008436
2022-01-20 17:12:17,117 iteration 3831 : loss : 0.019021, loss_ce: 0.007591
2022-01-20 17:12:18,462 iteration 3832 : loss : 0.021473, loss_ce: 0.009825
2022-01-20 17:12:19,811 iteration 3833 : loss : 0.032998, loss_ce: 0.010833
2022-01-20 17:12:21,101 iteration 3834 : loss : 0.019106, loss_ce: 0.006042
2022-01-20 17:12:22,498 iteration 3835 : loss : 0.041982, loss_ce: 0.009630
2022-01-20 17:12:23,795 iteration 3836 : loss : 0.016611, loss_ce: 0.007544
2022-01-20 17:12:25,059 iteration 3837 : loss : 0.016633, loss_ce: 0.007090
2022-01-20 17:12:26,469 iteration 3838 : loss : 0.020002, loss_ce: 0.008391
2022-01-20 17:12:27,756 iteration 3839 : loss : 0.030053, loss_ce: 0.009422
2022-01-20 17:12:29,128 iteration 3840 : loss : 0.019491, loss_ce: 0.008161
2022-01-20 17:12:30,389 iteration 3841 : loss : 0.018966, loss_ce: 0.007152
2022-01-20 17:12:31,780 iteration 3842 : loss : 0.070149, loss_ce: 0.013479
 56%|███████████████▎           | 226/400 [1:32:20<1:12:31, 25.01s/it]2022-01-20 17:12:33,185 iteration 3843 : loss : 0.022904, loss_ce: 0.008158
2022-01-20 17:12:34,605 iteration 3844 : loss : 0.028106, loss_ce: 0.010289
2022-01-20 17:12:35,862 iteration 3845 : loss : 0.035924, loss_ce: 0.011272
2022-01-20 17:12:37,210 iteration 3846 : loss : 0.036354, loss_ce: 0.015400
2022-01-20 17:12:38,710 iteration 3847 : loss : 0.052691, loss_ce: 0.023913
2022-01-20 17:12:40,052 iteration 3848 : loss : 0.030319, loss_ce: 0.009968
2022-01-20 17:12:41,386 iteration 3849 : loss : 0.022550, loss_ce: 0.008719
2022-01-20 17:12:42,831 iteration 3850 : loss : 0.046792, loss_ce: 0.014916
2022-01-20 17:12:44,282 iteration 3851 : loss : 0.066821, loss_ce: 0.021957
2022-01-20 17:12:45,677 iteration 3852 : loss : 0.025474, loss_ce: 0.008938
2022-01-20 17:12:47,027 iteration 3853 : loss : 0.028537, loss_ce: 0.010350
2022-01-20 17:12:48,295 iteration 3854 : loss : 0.019085, loss_ce: 0.008153
2022-01-20 17:12:49,641 iteration 3855 : loss : 0.030426, loss_ce: 0.007930
2022-01-20 17:12:51,130 iteration 3856 : loss : 0.024871, loss_ce: 0.011712
2022-01-20 17:12:52,470 iteration 3857 : loss : 0.038185, loss_ce: 0.011498
2022-01-20 17:12:53,822 iteration 3858 : loss : 0.028640, loss_ce: 0.014396
2022-01-20 17:12:55,139 iteration 3859 : loss : 0.023527, loss_ce: 0.010936
 57%|███████████████▎           | 227/400 [1:32:43<1:10:41, 24.52s/it]2022-01-20 17:12:56,507 iteration 3860 : loss : 0.019689, loss_ce: 0.009035
2022-01-20 17:12:57,830 iteration 3861 : loss : 0.024606, loss_ce: 0.011249
2022-01-20 17:12:59,120 iteration 3862 : loss : 0.027530, loss_ce: 0.007481
2022-01-20 17:13:00,479 iteration 3863 : loss : 0.026301, loss_ce: 0.012487
2022-01-20 17:13:01,717 iteration 3864 : loss : 0.025807, loss_ce: 0.010145
2022-01-20 17:13:03,084 iteration 3865 : loss : 0.032316, loss_ce: 0.014375
2022-01-20 17:13:04,414 iteration 3866 : loss : 0.023468, loss_ce: 0.011614
2022-01-20 17:13:05,793 iteration 3867 : loss : 0.031862, loss_ce: 0.011764
2022-01-20 17:13:07,051 iteration 3868 : loss : 0.019167, loss_ce: 0.008491
2022-01-20 17:13:08,485 iteration 3869 : loss : 0.033641, loss_ce: 0.009014
2022-01-20 17:13:09,797 iteration 3870 : loss : 0.029368, loss_ce: 0.010061
2022-01-20 17:13:11,232 iteration 3871 : loss : 0.029618, loss_ce: 0.012633
2022-01-20 17:13:12,578 iteration 3872 : loss : 0.019626, loss_ce: 0.006271
2022-01-20 17:13:13,905 iteration 3873 : loss : 0.015667, loss_ce: 0.004551
2022-01-20 17:13:15,315 iteration 3874 : loss : 0.023524, loss_ce: 0.007623
2022-01-20 17:13:16,679 iteration 3875 : loss : 0.028481, loss_ce: 0.008767
2022-01-20 17:13:18,108 iteration 3876 : loss : 0.026633, loss_ce: 0.010444
 57%|███████████████▍           | 228/400 [1:33:06<1:08:57, 24.05s/it]2022-01-20 17:13:19,436 iteration 3877 : loss : 0.027345, loss_ce: 0.012952
2022-01-20 17:13:20,792 iteration 3878 : loss : 0.027725, loss_ce: 0.009621
2022-01-20 17:13:22,187 iteration 3879 : loss : 0.021680, loss_ce: 0.011317
2022-01-20 17:13:23,501 iteration 3880 : loss : 0.018787, loss_ce: 0.006581
2022-01-20 17:13:24,854 iteration 3881 : loss : 0.026293, loss_ce: 0.008100
2022-01-20 17:13:26,244 iteration 3882 : loss : 0.022192, loss_ce: 0.010506
2022-01-20 17:13:27,582 iteration 3883 : loss : 0.028578, loss_ce: 0.011746
2022-01-20 17:13:28,918 iteration 3884 : loss : 0.016105, loss_ce: 0.005470
2022-01-20 17:13:30,196 iteration 3885 : loss : 0.018570, loss_ce: 0.005842
2022-01-20 17:13:31,578 iteration 3886 : loss : 0.023631, loss_ce: 0.009333
2022-01-20 17:13:32,934 iteration 3887 : loss : 0.022427, loss_ce: 0.008173
2022-01-20 17:13:34,331 iteration 3888 : loss : 0.026544, loss_ce: 0.014666
2022-01-20 17:13:35,609 iteration 3889 : loss : 0.027609, loss_ce: 0.009606
2022-01-20 17:13:36,906 iteration 3890 : loss : 0.015143, loss_ce: 0.004710
2022-01-20 17:13:38,270 iteration 3891 : loss : 0.064296, loss_ce: 0.040998
2022-01-20 17:13:39,581 iteration 3892 : loss : 0.021800, loss_ce: 0.007166
2022-01-20 17:13:40,846 iteration 3893 : loss : 0.029564, loss_ce: 0.007932
 57%|███████████████▍           | 229/400 [1:33:29<1:07:25, 23.66s/it]2022-01-20 17:13:42,212 iteration 3894 : loss : 0.028236, loss_ce: 0.010962
2022-01-20 17:13:43,568 iteration 3895 : loss : 0.025283, loss_ce: 0.013858
2022-01-20 17:13:44,806 iteration 3896 : loss : 0.025491, loss_ce: 0.008073
2022-01-20 17:13:46,174 iteration 3897 : loss : 0.021281, loss_ce: 0.006848
2022-01-20 17:13:47,514 iteration 3898 : loss : 0.029681, loss_ce: 0.010600
2022-01-20 17:13:48,830 iteration 3899 : loss : 0.022779, loss_ce: 0.007050
2022-01-20 17:13:50,146 iteration 3900 : loss : 0.017191, loss_ce: 0.007710
2022-01-20 17:13:51,350 iteration 3901 : loss : 0.019250, loss_ce: 0.009165
2022-01-20 17:13:52,669 iteration 3902 : loss : 0.016125, loss_ce: 0.005492
2022-01-20 17:13:53,915 iteration 3903 : loss : 0.019854, loss_ce: 0.006431
2022-01-20 17:13:55,240 iteration 3904 : loss : 0.022232, loss_ce: 0.008620
2022-01-20 17:13:56,550 iteration 3905 : loss : 0.021880, loss_ce: 0.011223
2022-01-20 17:13:57,861 iteration 3906 : loss : 0.019532, loss_ce: 0.007030
2022-01-20 17:13:59,148 iteration 3907 : loss : 0.021169, loss_ce: 0.006542
2022-01-20 17:14:00,342 iteration 3908 : loss : 0.021895, loss_ce: 0.007439
2022-01-20 17:14:01,546 iteration 3909 : loss : 0.022149, loss_ce: 0.008828
2022-01-20 17:14:01,546 Training Data Eval:
2022-01-20 17:14:08,021   Average segmentation loss on training set: 0.0149
2022-01-20 17:14:08,022 Validation Data Eval:
2022-01-20 17:14:10,252   Average segmentation loss on validation set: 0.0813
2022-01-20 17:14:11,581 iteration 3910 : loss : 0.026229, loss_ce: 0.011437
 57%|███████████████▌           | 230/400 [1:34:00<1:13:02, 25.78s/it]2022-01-20 17:14:12,877 iteration 3911 : loss : 0.017925, loss_ce: 0.007771
2022-01-20 17:14:14,179 iteration 3912 : loss : 0.025859, loss_ce: 0.007771
2022-01-20 17:14:15,505 iteration 3913 : loss : 0.027139, loss_ce: 0.012116
2022-01-20 17:14:16,728 iteration 3914 : loss : 0.014592, loss_ce: 0.006455
2022-01-20 17:14:18,095 iteration 3915 : loss : 0.023367, loss_ce: 0.006908
2022-01-20 17:14:19,431 iteration 3916 : loss : 0.020531, loss_ce: 0.007722
2022-01-20 17:14:20,809 iteration 3917 : loss : 0.022097, loss_ce: 0.006214
2022-01-20 17:14:22,136 iteration 3918 : loss : 0.020786, loss_ce: 0.006708
2022-01-20 17:14:23,470 iteration 3919 : loss : 0.022195, loss_ce: 0.007912
2022-01-20 17:14:24,837 iteration 3920 : loss : 0.028426, loss_ce: 0.007201
2022-01-20 17:14:26,174 iteration 3921 : loss : 0.018661, loss_ce: 0.006248
2022-01-20 17:14:27,549 iteration 3922 : loss : 0.025266, loss_ce: 0.006724
2022-01-20 17:14:28,991 iteration 3923 : loss : 0.034800, loss_ce: 0.016746
2022-01-20 17:14:30,272 iteration 3924 : loss : 0.021430, loss_ce: 0.008062
2022-01-20 17:14:31,512 iteration 3925 : loss : 0.017736, loss_ce: 0.008026
2022-01-20 17:14:32,983 iteration 3926 : loss : 0.033673, loss_ce: 0.014660
2022-01-20 17:14:34,321 iteration 3927 : loss : 0.026190, loss_ce: 0.012307
 58%|███████████████▌           | 231/400 [1:34:22<1:10:02, 24.87s/it]2022-01-20 17:14:35,657 iteration 3928 : loss : 0.019213, loss_ce: 0.006982
2022-01-20 17:14:36,917 iteration 3929 : loss : 0.022618, loss_ce: 0.014159
2022-01-20 17:14:38,221 iteration 3930 : loss : 0.019489, loss_ce: 0.005590
2022-01-20 17:14:39,442 iteration 3931 : loss : 0.022222, loss_ce: 0.004934
2022-01-20 17:14:40,762 iteration 3932 : loss : 0.022419, loss_ce: 0.007734
2022-01-20 17:14:42,049 iteration 3933 : loss : 0.018141, loss_ce: 0.008461
2022-01-20 17:14:43,380 iteration 3934 : loss : 0.031023, loss_ce: 0.010981
2022-01-20 17:14:44,661 iteration 3935 : loss : 0.034193, loss_ce: 0.012049
2022-01-20 17:14:45,914 iteration 3936 : loss : 0.022649, loss_ce: 0.009168
2022-01-20 17:14:47,216 iteration 3937 : loss : 0.022577, loss_ce: 0.006666
2022-01-20 17:14:48,520 iteration 3938 : loss : 0.031674, loss_ce: 0.008247
2022-01-20 17:14:49,889 iteration 3939 : loss : 0.037320, loss_ce: 0.008673
2022-01-20 17:14:51,182 iteration 3940 : loss : 0.022701, loss_ce: 0.010856
2022-01-20 17:14:52,480 iteration 3941 : loss : 0.021065, loss_ce: 0.007027
2022-01-20 17:14:53,743 iteration 3942 : loss : 0.018220, loss_ce: 0.009537
2022-01-20 17:14:55,002 iteration 3943 : loss : 0.020941, loss_ce: 0.008813
2022-01-20 17:14:56,265 iteration 3944 : loss : 0.026058, loss_ce: 0.008319
 58%|███████████████▋           | 232/400 [1:34:44<1:07:10, 23.99s/it]2022-01-20 17:14:57,672 iteration 3945 : loss : 0.022404, loss_ce: 0.007112
2022-01-20 17:14:58,918 iteration 3946 : loss : 0.017240, loss_ce: 0.006682
2022-01-20 17:15:00,148 iteration 3947 : loss : 0.018635, loss_ce: 0.007785
2022-01-20 17:15:01,513 iteration 3948 : loss : 0.021620, loss_ce: 0.009758
2022-01-20 17:15:02,874 iteration 3949 : loss : 0.024548, loss_ce: 0.007769
2022-01-20 17:15:04,145 iteration 3950 : loss : 0.018196, loss_ce: 0.008333
2022-01-20 17:15:05,390 iteration 3951 : loss : 0.016095, loss_ce: 0.003603
2022-01-20 17:15:06,814 iteration 3952 : loss : 0.022868, loss_ce: 0.010348
2022-01-20 17:15:08,125 iteration 3953 : loss : 0.016373, loss_ce: 0.006836
2022-01-20 17:15:09,375 iteration 3954 : loss : 0.015721, loss_ce: 0.005675
2022-01-20 17:15:10,715 iteration 3955 : loss : 0.021660, loss_ce: 0.008850
2022-01-20 17:15:12,082 iteration 3956 : loss : 0.022861, loss_ce: 0.012437
2022-01-20 17:15:13,460 iteration 3957 : loss : 0.027771, loss_ce: 0.008022
2022-01-20 17:15:14,835 iteration 3958 : loss : 0.022737, loss_ce: 0.011369
2022-01-20 17:15:16,040 iteration 3959 : loss : 0.015837, loss_ce: 0.004183
2022-01-20 17:15:17,396 iteration 3960 : loss : 0.042682, loss_ce: 0.016887
2022-01-20 17:15:18,673 iteration 3961 : loss : 0.021358, loss_ce: 0.005599
 58%|███████████████▋           | 233/400 [1:35:07<1:05:27, 23.52s/it]2022-01-20 17:15:20,062 iteration 3962 : loss : 0.027221, loss_ce: 0.010933
2022-01-20 17:15:21,435 iteration 3963 : loss : 0.022249, loss_ce: 0.008741
2022-01-20 17:15:22,677 iteration 3964 : loss : 0.015813, loss_ce: 0.004656
2022-01-20 17:15:23,988 iteration 3965 : loss : 0.018445, loss_ce: 0.009737
2022-01-20 17:15:25,390 iteration 3966 : loss : 0.021654, loss_ce: 0.009826
2022-01-20 17:15:26,692 iteration 3967 : loss : 0.026814, loss_ce: 0.006185
2022-01-20 17:15:28,000 iteration 3968 : loss : 0.022125, loss_ce: 0.008716
2022-01-20 17:15:29,260 iteration 3969 : loss : 0.020202, loss_ce: 0.006862
2022-01-20 17:15:30,558 iteration 3970 : loss : 0.035337, loss_ce: 0.008311
2022-01-20 17:15:31,855 iteration 3971 : loss : 0.018541, loss_ce: 0.006036
2022-01-20 17:15:33,151 iteration 3972 : loss : 0.031470, loss_ce: 0.012322
2022-01-20 17:15:34,521 iteration 3973 : loss : 0.021081, loss_ce: 0.008770
2022-01-20 17:15:35,872 iteration 3974 : loss : 0.018098, loss_ce: 0.009060
2022-01-20 17:15:37,166 iteration 3975 : loss : 0.029632, loss_ce: 0.007400
2022-01-20 17:15:38,450 iteration 3976 : loss : 0.018151, loss_ce: 0.006696
2022-01-20 17:15:39,801 iteration 3977 : loss : 0.019785, loss_ce: 0.008826
2022-01-20 17:15:41,131 iteration 3978 : loss : 0.023010, loss_ce: 0.010702
 58%|███████████████▊           | 234/400 [1:35:29<1:04:10, 23.20s/it]2022-01-20 17:15:42,592 iteration 3979 : loss : 0.030270, loss_ce: 0.015513
2022-01-20 17:15:43,806 iteration 3980 : loss : 0.018671, loss_ce: 0.007916
2022-01-20 17:15:45,107 iteration 3981 : loss : 0.022674, loss_ce: 0.006629
2022-01-20 17:15:46,426 iteration 3982 : loss : 0.019069, loss_ce: 0.009587
2022-01-20 17:15:47,738 iteration 3983 : loss : 0.034915, loss_ce: 0.009541
2022-01-20 17:15:49,089 iteration 3984 : loss : 0.026264, loss_ce: 0.011487
2022-01-20 17:15:50,418 iteration 3985 : loss : 0.022358, loss_ce: 0.007361
2022-01-20 17:15:51,777 iteration 3986 : loss : 0.033961, loss_ce: 0.009779
2022-01-20 17:15:53,022 iteration 3987 : loss : 0.021936, loss_ce: 0.009516
2022-01-20 17:15:54,314 iteration 3988 : loss : 0.021976, loss_ce: 0.008857
2022-01-20 17:15:55,644 iteration 3989 : loss : 0.023529, loss_ce: 0.009201
2022-01-20 17:15:56,968 iteration 3990 : loss : 0.026661, loss_ce: 0.012143
2022-01-20 17:15:58,311 iteration 3991 : loss : 0.027579, loss_ce: 0.014731
2022-01-20 17:15:59,646 iteration 3992 : loss : 0.018938, loss_ce: 0.007683
2022-01-20 17:16:00,946 iteration 3993 : loss : 0.020222, loss_ce: 0.008191
2022-01-20 17:16:02,300 iteration 3994 : loss : 0.016923, loss_ce: 0.005473
2022-01-20 17:16:02,300 Training Data Eval:
2022-01-20 17:16:08,866   Average segmentation loss on training set: 0.0143
2022-01-20 17:16:08,866 Validation Data Eval:
2022-01-20 17:16:11,122   Average segmentation loss on validation set: 0.0689
2022-01-20 17:16:16,979 Found new lowest validation loss at iteration 3994! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 17:16:18,391 iteration 3995 : loss : 0.019169, loss_ce: 0.006477
 59%|███████████████▊           | 235/400 [1:36:06<1:15:23, 27.41s/it]2022-01-20 17:16:19,684 iteration 3996 : loss : 0.020640, loss_ce: 0.009475
2022-01-20 17:16:20,865 iteration 3997 : loss : 0.019347, loss_ce: 0.009604
2022-01-20 17:16:22,030 iteration 3998 : loss : 0.018712, loss_ce: 0.006401
2022-01-20 17:16:23,337 iteration 3999 : loss : 0.026343, loss_ce: 0.007687
2022-01-20 17:16:24,586 iteration 4000 : loss : 0.018349, loss_ce: 0.007719
2022-01-20 17:16:25,883 iteration 4001 : loss : 0.021704, loss_ce: 0.011392
2022-01-20 17:16:27,025 iteration 4002 : loss : 0.018853, loss_ce: 0.006558
2022-01-20 17:16:28,332 iteration 4003 : loss : 0.027085, loss_ce: 0.009115
2022-01-20 17:16:29,629 iteration 4004 : loss : 0.025980, loss_ce: 0.010668
2022-01-20 17:16:30,923 iteration 4005 : loss : 0.021394, loss_ce: 0.009307
2022-01-20 17:16:32,168 iteration 4006 : loss : 0.019643, loss_ce: 0.006286
2022-01-20 17:16:33,477 iteration 4007 : loss : 0.022116, loss_ce: 0.007563
2022-01-20 17:16:34,772 iteration 4008 : loss : 0.015348, loss_ce: 0.007197
2022-01-20 17:16:36,064 iteration 4009 : loss : 0.014879, loss_ce: 0.004908
2022-01-20 17:16:37,378 iteration 4010 : loss : 0.017610, loss_ce: 0.006881
2022-01-20 17:16:38,650 iteration 4011 : loss : 0.024318, loss_ce: 0.007797
2022-01-20 17:16:39,952 iteration 4012 : loss : 0.021297, loss_ce: 0.008013
 59%|███████████████▉           | 236/400 [1:36:28<1:10:08, 25.66s/it]2022-01-20 17:16:41,192 iteration 4013 : loss : 0.014189, loss_ce: 0.006664
2022-01-20 17:16:42,550 iteration 4014 : loss : 0.018399, loss_ce: 0.007268
2022-01-20 17:16:43,782 iteration 4015 : loss : 0.016270, loss_ce: 0.007277
2022-01-20 17:16:45,140 iteration 4016 : loss : 0.019082, loss_ce: 0.006866
2022-01-20 17:16:46,448 iteration 4017 : loss : 0.022569, loss_ce: 0.005769
2022-01-20 17:16:47,653 iteration 4018 : loss : 0.019514, loss_ce: 0.007113
2022-01-20 17:16:48,958 iteration 4019 : loss : 0.030438, loss_ce: 0.010079
2022-01-20 17:16:50,230 iteration 4020 : loss : 0.020023, loss_ce: 0.006815
2022-01-20 17:16:51,566 iteration 4021 : loss : 0.027397, loss_ce: 0.006790
2022-01-20 17:16:52,972 iteration 4022 : loss : 0.028525, loss_ce: 0.010053
2022-01-20 17:16:54,200 iteration 4023 : loss : 0.014541, loss_ce: 0.006526
2022-01-20 17:16:55,561 iteration 4024 : loss : 0.019142, loss_ce: 0.004763
2022-01-20 17:16:56,882 iteration 4025 : loss : 0.022467, loss_ce: 0.008737
2022-01-20 17:16:58,265 iteration 4026 : loss : 0.022159, loss_ce: 0.006202
2022-01-20 17:16:59,501 iteration 4027 : loss : 0.017420, loss_ce: 0.005780
2022-01-20 17:17:00,977 iteration 4028 : loss : 0.023087, loss_ce: 0.010432
2022-01-20 17:17:02,411 iteration 4029 : loss : 0.023750, loss_ce: 0.008524
 59%|███████████████▉           | 237/400 [1:36:50<1:07:06, 24.70s/it]2022-01-20 17:17:03,766 iteration 4030 : loss : 0.016750, loss_ce: 0.006858
2022-01-20 17:17:05,066 iteration 4031 : loss : 0.018281, loss_ce: 0.007586
2022-01-20 17:17:06,298 iteration 4032 : loss : 0.015189, loss_ce: 0.004421
2022-01-20 17:17:07,571 iteration 4033 : loss : 0.025050, loss_ce: 0.009587
2022-01-20 17:17:08,942 iteration 4034 : loss : 0.021042, loss_ce: 0.009488
2022-01-20 17:17:10,298 iteration 4035 : loss : 0.026381, loss_ce: 0.009590
2022-01-20 17:17:11,621 iteration 4036 : loss : 0.015905, loss_ce: 0.006275
2022-01-20 17:17:12,869 iteration 4037 : loss : 0.016655, loss_ce: 0.008778
2022-01-20 17:17:14,166 iteration 4038 : loss : 0.023718, loss_ce: 0.010227
2022-01-20 17:17:15,487 iteration 4039 : loss : 0.027043, loss_ce: 0.008455
2022-01-20 17:17:16,778 iteration 4040 : loss : 0.016119, loss_ce: 0.005372
2022-01-20 17:17:18,149 iteration 4041 : loss : 0.018908, loss_ce: 0.007635
2022-01-20 17:17:19,492 iteration 4042 : loss : 0.018707, loss_ce: 0.006765
2022-01-20 17:17:20,819 iteration 4043 : loss : 0.016292, loss_ce: 0.006131
2022-01-20 17:17:22,113 iteration 4044 : loss : 0.019687, loss_ce: 0.008239
2022-01-20 17:17:23,430 iteration 4045 : loss : 0.023342, loss_ce: 0.007119
2022-01-20 17:17:24,792 iteration 4046 : loss : 0.025718, loss_ce: 0.008056
 60%|████████████████           | 238/400 [1:37:13<1:04:48, 24.00s/it]2022-01-20 17:17:26,176 iteration 4047 : loss : 0.018913, loss_ce: 0.008384
2022-01-20 17:17:27,451 iteration 4048 : loss : 0.023877, loss_ce: 0.007092
2022-01-20 17:17:28,741 iteration 4049 : loss : 0.013932, loss_ce: 0.003992
2022-01-20 17:17:29,989 iteration 4050 : loss : 0.031570, loss_ce: 0.011633
2022-01-20 17:17:31,286 iteration 4051 : loss : 0.015174, loss_ce: 0.006030
2022-01-20 17:17:32,531 iteration 4052 : loss : 0.014561, loss_ce: 0.005799
2022-01-20 17:17:33,844 iteration 4053 : loss : 0.026580, loss_ce: 0.006730
2022-01-20 17:17:35,181 iteration 4054 : loss : 0.019794, loss_ce: 0.007812
2022-01-20 17:17:36,478 iteration 4055 : loss : 0.017507, loss_ce: 0.007664
2022-01-20 17:17:37,777 iteration 4056 : loss : 0.019091, loss_ce: 0.008954
2022-01-20 17:17:39,011 iteration 4057 : loss : 0.015304, loss_ce: 0.004247
2022-01-20 17:17:40,269 iteration 4058 : loss : 0.015131, loss_ce: 0.006388
2022-01-20 17:17:41,609 iteration 4059 : loss : 0.022418, loss_ce: 0.008726
2022-01-20 17:17:42,862 iteration 4060 : loss : 0.022969, loss_ce: 0.010257
2022-01-20 17:17:44,071 iteration 4061 : loss : 0.016661, loss_ce: 0.007545
2022-01-20 17:17:45,354 iteration 4062 : loss : 0.015848, loss_ce: 0.006974
2022-01-20 17:17:46,705 iteration 4063 : loss : 0.024554, loss_ce: 0.009251
 60%|████████████████▏          | 239/400 [1:37:35<1:02:43, 23.38s/it]2022-01-20 17:17:48,040 iteration 4064 : loss : 0.028052, loss_ce: 0.013397
2022-01-20 17:17:49,276 iteration 4065 : loss : 0.019221, loss_ce: 0.005186
2022-01-20 17:17:50,561 iteration 4066 : loss : 0.017061, loss_ce: 0.006480
2022-01-20 17:17:51,843 iteration 4067 : loss : 0.016618, loss_ce: 0.005614
2022-01-20 17:17:53,181 iteration 4068 : loss : 0.022700, loss_ce: 0.009462
2022-01-20 17:17:54,498 iteration 4069 : loss : 0.035665, loss_ce: 0.019823
2022-01-20 17:17:55,747 iteration 4070 : loss : 0.017854, loss_ce: 0.005014
2022-01-20 17:17:57,088 iteration 4071 : loss : 0.019613, loss_ce: 0.007033
2022-01-20 17:17:58,394 iteration 4072 : loss : 0.018326, loss_ce: 0.006863
2022-01-20 17:17:59,733 iteration 4073 : loss : 0.022664, loss_ce: 0.009327
2022-01-20 17:18:01,036 iteration 4074 : loss : 0.019604, loss_ce: 0.007982
2022-01-20 17:18:02,443 iteration 4075 : loss : 0.030439, loss_ce: 0.010034
2022-01-20 17:18:03,758 iteration 4076 : loss : 0.013397, loss_ce: 0.005456
2022-01-20 17:18:05,111 iteration 4077 : loss : 0.025051, loss_ce: 0.009858
2022-01-20 17:18:06,465 iteration 4078 : loss : 0.028808, loss_ce: 0.008944
2022-01-20 17:18:07,722 iteration 4079 : loss : 0.021577, loss_ce: 0.008321
2022-01-20 17:18:07,722 Training Data Eval:
2022-01-20 17:18:14,212   Average segmentation loss on training set: 0.0130
2022-01-20 17:18:14,212 Validation Data Eval:
2022-01-20 17:18:16,432   Average segmentation loss on validation set: 0.0824
2022-01-20 17:18:17,832 iteration 4080 : loss : 0.033675, loss_ce: 0.013714
 60%|████████████████▏          | 240/400 [1:38:06<1:08:32, 25.70s/it]2022-01-20 17:18:19,158 iteration 4081 : loss : 0.016214, loss_ce: 0.006650
2022-01-20 17:18:20,437 iteration 4082 : loss : 0.019378, loss_ce: 0.006885
2022-01-20 17:18:21,710 iteration 4083 : loss : 0.015567, loss_ce: 0.006968
2022-01-20 17:18:23,074 iteration 4084 : loss : 0.022556, loss_ce: 0.008154
2022-01-20 17:18:24,452 iteration 4085 : loss : 0.025339, loss_ce: 0.008120
2022-01-20 17:18:25,803 iteration 4086 : loss : 0.023928, loss_ce: 0.010431
2022-01-20 17:18:27,072 iteration 4087 : loss : 0.016372, loss_ce: 0.004871
2022-01-20 17:18:28,359 iteration 4088 : loss : 0.018109, loss_ce: 0.007027
2022-01-20 17:18:29,684 iteration 4089 : loss : 0.024020, loss_ce: 0.009039
2022-01-20 17:18:31,018 iteration 4090 : loss : 0.020035, loss_ce: 0.008336
2022-01-20 17:18:32,285 iteration 4091 : loss : 0.014560, loss_ce: 0.005162
2022-01-20 17:18:33,584 iteration 4092 : loss : 0.014384, loss_ce: 0.005345
2022-01-20 17:18:34,872 iteration 4093 : loss : 0.019625, loss_ce: 0.008566
2022-01-20 17:18:36,136 iteration 4094 : loss : 0.013837, loss_ce: 0.004812
2022-01-20 17:18:37,423 iteration 4095 : loss : 0.016884, loss_ce: 0.006107
2022-01-20 17:18:38,714 iteration 4096 : loss : 0.018347, loss_ce: 0.007448
2022-01-20 17:18:40,026 iteration 4097 : loss : 0.020724, loss_ce: 0.009108
 60%|████████████████▎          | 241/400 [1:38:28<1:05:18, 24.65s/it]2022-01-20 17:18:41,435 iteration 4098 : loss : 0.024398, loss_ce: 0.008864
2022-01-20 17:18:42,706 iteration 4099 : loss : 0.031177, loss_ce: 0.007006
2022-01-20 17:18:43,937 iteration 4100 : loss : 0.018520, loss_ce: 0.008358
2022-01-20 17:18:45,203 iteration 4101 : loss : 0.016596, loss_ce: 0.006494
2022-01-20 17:18:46,517 iteration 4102 : loss : 0.019688, loss_ce: 0.008271
2022-01-20 17:18:47,794 iteration 4103 : loss : 0.017276, loss_ce: 0.006921
2022-01-20 17:18:49,053 iteration 4104 : loss : 0.013902, loss_ce: 0.006060
2022-01-20 17:18:50,388 iteration 4105 : loss : 0.017174, loss_ce: 0.006679
2022-01-20 17:18:51,666 iteration 4106 : loss : 0.021450, loss_ce: 0.004298
2022-01-20 17:18:53,104 iteration 4107 : loss : 0.026220, loss_ce: 0.015008
2022-01-20 17:18:54,477 iteration 4108 : loss : 0.036558, loss_ce: 0.013608
2022-01-20 17:18:55,753 iteration 4109 : loss : 0.014814, loss_ce: 0.003905
2022-01-20 17:18:57,118 iteration 4110 : loss : 0.021193, loss_ce: 0.010801
2022-01-20 17:18:58,513 iteration 4111 : loss : 0.024352, loss_ce: 0.010877
2022-01-20 17:18:59,805 iteration 4112 : loss : 0.024868, loss_ce: 0.009566
2022-01-20 17:19:01,138 iteration 4113 : loss : 0.017615, loss_ce: 0.007306
2022-01-20 17:19:02,547 iteration 4114 : loss : 0.026073, loss_ce: 0.010262
 60%|████████████████▎          | 242/400 [1:38:51<1:03:14, 24.01s/it]2022-01-20 17:19:03,882 iteration 4115 : loss : 0.020117, loss_ce: 0.005625
2022-01-20 17:19:05,132 iteration 4116 : loss : 0.017154, loss_ce: 0.007739
2022-01-20 17:19:06,594 iteration 4117 : loss : 0.025906, loss_ce: 0.007392
2022-01-20 17:19:08,025 iteration 4118 : loss : 0.026677, loss_ce: 0.010949
2022-01-20 17:19:09,362 iteration 4119 : loss : 0.018942, loss_ce: 0.008669
2022-01-20 17:19:10,678 iteration 4120 : loss : 0.033156, loss_ce: 0.006050
2022-01-20 17:19:11,998 iteration 4121 : loss : 0.016939, loss_ce: 0.008210
2022-01-20 17:19:13,283 iteration 4122 : loss : 0.018473, loss_ce: 0.006338
2022-01-20 17:19:14,665 iteration 4123 : loss : 0.024765, loss_ce: 0.008377
2022-01-20 17:19:15,904 iteration 4124 : loss : 0.019872, loss_ce: 0.007751
2022-01-20 17:19:17,282 iteration 4125 : loss : 0.023038, loss_ce: 0.006934
2022-01-20 17:19:18,608 iteration 4126 : loss : 0.017746, loss_ce: 0.008102
2022-01-20 17:19:19,950 iteration 4127 : loss : 0.017700, loss_ce: 0.007579
2022-01-20 17:19:21,214 iteration 4128 : loss : 0.018663, loss_ce: 0.009615
2022-01-20 17:19:22,574 iteration 4129 : loss : 0.022001, loss_ce: 0.008554
2022-01-20 17:19:23,869 iteration 4130 : loss : 0.018153, loss_ce: 0.009286
2022-01-20 17:19:25,073 iteration 4131 : loss : 0.018591, loss_ce: 0.005105
 61%|████████████████▍          | 243/400 [1:39:13<1:01:40, 23.57s/it]2022-01-20 17:19:26,490 iteration 4132 : loss : 0.022001, loss_ce: 0.008511
2022-01-20 17:19:27,839 iteration 4133 : loss : 0.021359, loss_ce: 0.008395
2022-01-20 17:19:29,042 iteration 4134 : loss : 0.018142, loss_ce: 0.007480
2022-01-20 17:19:30,405 iteration 4135 : loss : 0.017548, loss_ce: 0.007638
2022-01-20 17:19:31,701 iteration 4136 : loss : 0.021327, loss_ce: 0.010081
2022-01-20 17:19:32,969 iteration 4137 : loss : 0.020811, loss_ce: 0.010532
2022-01-20 17:19:34,228 iteration 4138 : loss : 0.016604, loss_ce: 0.007537
2022-01-20 17:19:35,569 iteration 4139 : loss : 0.030766, loss_ce: 0.012070
2022-01-20 17:19:36,926 iteration 4140 : loss : 0.020915, loss_ce: 0.006068
2022-01-20 17:19:38,215 iteration 4141 : loss : 0.020508, loss_ce: 0.004539
2022-01-20 17:19:39,528 iteration 4142 : loss : 0.034506, loss_ce: 0.010077
2022-01-20 17:19:40,879 iteration 4143 : loss : 0.022813, loss_ce: 0.005726
2022-01-20 17:19:42,153 iteration 4144 : loss : 0.017609, loss_ce: 0.006783
2022-01-20 17:19:43,417 iteration 4145 : loss : 0.016405, loss_ce: 0.004691
2022-01-20 17:19:44,715 iteration 4146 : loss : 0.019734, loss_ce: 0.005817
2022-01-20 17:19:45,987 iteration 4147 : loss : 0.024818, loss_ce: 0.010452
2022-01-20 17:19:47,198 iteration 4148 : loss : 0.012661, loss_ce: 0.004640
 61%|████████████████▍          | 244/400 [1:39:35<1:00:09, 23.14s/it]2022-01-20 17:19:48,700 iteration 4149 : loss : 0.027420, loss_ce: 0.010937
2022-01-20 17:19:49,898 iteration 4150 : loss : 0.018196, loss_ce: 0.005395
2022-01-20 17:19:51,222 iteration 4151 : loss : 0.020822, loss_ce: 0.010491
2022-01-20 17:19:52,425 iteration 4152 : loss : 0.016027, loss_ce: 0.006230
2022-01-20 17:19:53,782 iteration 4153 : loss : 0.033980, loss_ce: 0.009253
2022-01-20 17:19:55,119 iteration 4154 : loss : 0.023536, loss_ce: 0.009133
2022-01-20 17:19:56,511 iteration 4155 : loss : 0.019299, loss_ce: 0.007178
2022-01-20 17:19:57,720 iteration 4156 : loss : 0.012352, loss_ce: 0.004753
2022-01-20 17:19:59,079 iteration 4157 : loss : 0.021454, loss_ce: 0.007777
2022-01-20 17:20:00,408 iteration 4158 : loss : 0.024586, loss_ce: 0.010742
2022-01-20 17:20:01,762 iteration 4159 : loss : 0.028120, loss_ce: 0.010384
2022-01-20 17:20:03,072 iteration 4160 : loss : 0.020440, loss_ce: 0.009470
2022-01-20 17:20:04,383 iteration 4161 : loss : 0.015197, loss_ce: 0.005823
2022-01-20 17:20:05,656 iteration 4162 : loss : 0.018057, loss_ce: 0.006378
2022-01-20 17:20:06,997 iteration 4163 : loss : 0.025316, loss_ce: 0.007092
2022-01-20 17:20:08,348 iteration 4164 : loss : 0.025668, loss_ce: 0.011067
2022-01-20 17:20:08,349 Training Data Eval:
2022-01-20 17:20:14,883   Average segmentation loss on training set: 0.0129
2022-01-20 17:20:14,883 Validation Data Eval:
2022-01-20 17:20:17,109   Average segmentation loss on validation set: 0.0684
2022-01-20 17:20:22,939 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 17:20:24,240 iteration 4165 : loss : 0.018746, loss_ce: 0.008840
 61%|████████████████▌          | 245/400 [1:40:12<1:10:32, 27.31s/it]2022-01-20 17:20:25,485 iteration 4166 : loss : 0.017278, loss_ce: 0.006968
2022-01-20 17:20:26,748 iteration 4167 : loss : 0.035900, loss_ce: 0.008344
2022-01-20 17:20:28,043 iteration 4168 : loss : 0.017643, loss_ce: 0.007232
2022-01-20 17:20:29,313 iteration 4169 : loss : 0.019878, loss_ce: 0.008286
2022-01-20 17:20:30,665 iteration 4170 : loss : 0.027478, loss_ce: 0.011813
2022-01-20 17:20:31,868 iteration 4171 : loss : 0.024636, loss_ce: 0.013164
2022-01-20 17:20:33,096 iteration 4172 : loss : 0.024557, loss_ce: 0.009669
2022-01-20 17:20:34,245 iteration 4173 : loss : 0.018032, loss_ce: 0.006013
2022-01-20 17:20:35,558 iteration 4174 : loss : 0.036996, loss_ce: 0.012200
2022-01-20 17:20:36,891 iteration 4175 : loss : 0.025248, loss_ce: 0.006924
2022-01-20 17:20:38,272 iteration 4176 : loss : 0.027031, loss_ce: 0.009176
2022-01-20 17:20:39,528 iteration 4177 : loss : 0.017042, loss_ce: 0.007956
2022-01-20 17:20:40,835 iteration 4178 : loss : 0.016854, loss_ce: 0.007006
2022-01-20 17:20:42,195 iteration 4179 : loss : 0.022612, loss_ce: 0.007729
2022-01-20 17:20:43,597 iteration 4180 : loss : 0.025273, loss_ce: 0.008619
2022-01-20 17:20:44,955 iteration 4181 : loss : 0.025162, loss_ce: 0.011092
2022-01-20 17:20:46,322 iteration 4182 : loss : 0.025221, loss_ce: 0.011880
 62%|████████████████▌          | 246/400 [1:40:34<1:06:03, 25.74s/it]2022-01-20 17:20:47,680 iteration 4183 : loss : 0.021072, loss_ce: 0.005943
2022-01-20 17:20:48,959 iteration 4184 : loss : 0.024897, loss_ce: 0.009137
2022-01-20 17:20:50,304 iteration 4185 : loss : 0.024463, loss_ce: 0.008360
2022-01-20 17:20:51,587 iteration 4186 : loss : 0.021454, loss_ce: 0.008103
2022-01-20 17:20:52,839 iteration 4187 : loss : 0.019619, loss_ce: 0.007803
2022-01-20 17:20:54,134 iteration 4188 : loss : 0.021156, loss_ce: 0.007962
2022-01-20 17:20:55,367 iteration 4189 : loss : 0.020022, loss_ce: 0.006986
2022-01-20 17:20:56,776 iteration 4190 : loss : 0.020638, loss_ce: 0.009291
2022-01-20 17:20:58,124 iteration 4191 : loss : 0.019926, loss_ce: 0.005015
2022-01-20 17:20:59,346 iteration 4192 : loss : 0.016318, loss_ce: 0.007804
2022-01-20 17:21:00,560 iteration 4193 : loss : 0.016276, loss_ce: 0.004873
2022-01-20 17:21:01,861 iteration 4194 : loss : 0.028598, loss_ce: 0.009984
2022-01-20 17:21:03,130 iteration 4195 : loss : 0.016917, loss_ce: 0.007151
2022-01-20 17:21:04,385 iteration 4196 : loss : 0.015746, loss_ce: 0.005966
2022-01-20 17:21:05,639 iteration 4197 : loss : 0.019592, loss_ce: 0.007454
2022-01-20 17:21:06,873 iteration 4198 : loss : 0.018122, loss_ce: 0.004120
2022-01-20 17:21:08,224 iteration 4199 : loss : 0.025939, loss_ce: 0.010609
 62%|████████████████▋          | 247/400 [1:40:56<1:02:41, 24.59s/it]2022-01-20 17:21:09,580 iteration 4200 : loss : 0.019280, loss_ce: 0.006287
2022-01-20 17:21:10,915 iteration 4201 : loss : 0.020929, loss_ce: 0.010137
2022-01-20 17:21:12,304 iteration 4202 : loss : 0.015559, loss_ce: 0.006329
2022-01-20 17:21:13,691 iteration 4203 : loss : 0.038096, loss_ce: 0.015895
2022-01-20 17:21:15,034 iteration 4204 : loss : 0.015628, loss_ce: 0.006087
2022-01-20 17:21:16,190 iteration 4205 : loss : 0.013494, loss_ce: 0.004635
2022-01-20 17:21:17,505 iteration 4206 : loss : 0.014271, loss_ce: 0.004893
2022-01-20 17:21:18,814 iteration 4207 : loss : 0.013409, loss_ce: 0.006577
2022-01-20 17:21:20,201 iteration 4208 : loss : 0.023379, loss_ce: 0.009162
2022-01-20 17:21:21,502 iteration 4209 : loss : 0.016313, loss_ce: 0.005537
2022-01-20 17:21:22,804 iteration 4210 : loss : 0.013820, loss_ce: 0.004935
2022-01-20 17:21:24,151 iteration 4211 : loss : 0.015666, loss_ce: 0.006140
2022-01-20 17:21:25,437 iteration 4212 : loss : 0.015128, loss_ce: 0.006238
2022-01-20 17:21:26,829 iteration 4213 : loss : 0.017187, loss_ce: 0.005348
2022-01-20 17:21:28,215 iteration 4214 : loss : 0.021984, loss_ce: 0.009237
2022-01-20 17:21:29,560 iteration 4215 : loss : 0.026833, loss_ce: 0.006298
2022-01-20 17:21:30,864 iteration 4216 : loss : 0.028148, loss_ce: 0.011994
 62%|████████████████▋          | 248/400 [1:41:19<1:00:48, 24.00s/it]2022-01-20 17:21:32,313 iteration 4217 : loss : 0.036867, loss_ce: 0.012609
2022-01-20 17:21:33,700 iteration 4218 : loss : 0.020126, loss_ce: 0.009693
2022-01-20 17:21:35,020 iteration 4219 : loss : 0.020300, loss_ce: 0.008060
2022-01-20 17:21:36,322 iteration 4220 : loss : 0.018615, loss_ce: 0.006903
2022-01-20 17:21:37,675 iteration 4221 : loss : 0.025652, loss_ce: 0.008371
2022-01-20 17:21:39,051 iteration 4222 : loss : 0.017753, loss_ce: 0.008162
2022-01-20 17:21:40,514 iteration 4223 : loss : 0.033269, loss_ce: 0.010585
2022-01-20 17:21:41,833 iteration 4224 : loss : 0.018890, loss_ce: 0.007586
2022-01-20 17:21:43,210 iteration 4225 : loss : 0.020089, loss_ce: 0.009312
2022-01-20 17:21:44,643 iteration 4226 : loss : 0.021030, loss_ce: 0.007288
2022-01-20 17:21:45,953 iteration 4227 : loss : 0.024892, loss_ce: 0.007861
2022-01-20 17:21:47,326 iteration 4228 : loss : 0.021305, loss_ce: 0.010327
2022-01-20 17:21:48,609 iteration 4229 : loss : 0.017106, loss_ce: 0.006554
2022-01-20 17:21:50,002 iteration 4230 : loss : 0.018807, loss_ce: 0.006057
2022-01-20 17:21:51,354 iteration 4231 : loss : 0.017857, loss_ce: 0.006164
2022-01-20 17:21:52,738 iteration 4232 : loss : 0.023014, loss_ce: 0.009115
2022-01-20 17:21:54,000 iteration 4233 : loss : 0.019146, loss_ce: 0.006452
 62%|██████████████████           | 249/400 [1:41:42<59:45, 23.74s/it]2022-01-20 17:21:55,444 iteration 4234 : loss : 0.019821, loss_ce: 0.008408
2022-01-20 17:21:56,702 iteration 4235 : loss : 0.015857, loss_ce: 0.006121
2022-01-20 17:21:58,090 iteration 4236 : loss : 0.038335, loss_ce: 0.021371
2022-01-20 17:21:59,403 iteration 4237 : loss : 0.021727, loss_ce: 0.010952
2022-01-20 17:22:00,814 iteration 4238 : loss : 0.029616, loss_ce: 0.009298
2022-01-20 17:22:02,051 iteration 4239 : loss : 0.020044, loss_ce: 0.005871
2022-01-20 17:22:03,463 iteration 4240 : loss : 0.020479, loss_ce: 0.006321
2022-01-20 17:22:04,749 iteration 4241 : loss : 0.017458, loss_ce: 0.005783
2022-01-20 17:22:06,030 iteration 4242 : loss : 0.021150, loss_ce: 0.006160
2022-01-20 17:22:07,326 iteration 4243 : loss : 0.018750, loss_ce: 0.006394
2022-01-20 17:22:08,691 iteration 4244 : loss : 0.018582, loss_ce: 0.006278
2022-01-20 17:22:10,024 iteration 4245 : loss : 0.027343, loss_ce: 0.005972
2022-01-20 17:22:11,314 iteration 4246 : loss : 0.020953, loss_ce: 0.009577
2022-01-20 17:22:12,603 iteration 4247 : loss : 0.019450, loss_ce: 0.004524
2022-01-20 17:22:13,952 iteration 4248 : loss : 0.042689, loss_ce: 0.014028
2022-01-20 17:22:15,260 iteration 4249 : loss : 0.020476, loss_ce: 0.009279
2022-01-20 17:22:15,260 Training Data Eval:
2022-01-20 17:22:21,775   Average segmentation loss on training set: 0.0151
2022-01-20 17:22:21,776 Validation Data Eval:
2022-01-20 17:22:24,004   Average segmentation loss on validation set: 0.0896
2022-01-20 17:22:25,368 iteration 4250 : loss : 0.017948, loss_ce: 0.006287
 62%|████████████████▉          | 250/400 [1:42:13<1:05:04, 26.03s/it]2022-01-20 17:22:26,812 iteration 4251 : loss : 0.024557, loss_ce: 0.008980
2022-01-20 17:22:28,154 iteration 4252 : loss : 0.018599, loss_ce: 0.007270
2022-01-20 17:22:29,490 iteration 4253 : loss : 0.024423, loss_ce: 0.008887
2022-01-20 17:22:30,887 iteration 4254 : loss : 0.021238, loss_ce: 0.008611
2022-01-20 17:22:32,097 iteration 4255 : loss : 0.013105, loss_ce: 0.005187
2022-01-20 17:22:33,399 iteration 4256 : loss : 0.018871, loss_ce: 0.005027
2022-01-20 17:22:34,796 iteration 4257 : loss : 0.022634, loss_ce: 0.007494
2022-01-20 17:22:36,060 iteration 4258 : loss : 0.014903, loss_ce: 0.005330
2022-01-20 17:22:37,381 iteration 4259 : loss : 0.019170, loss_ce: 0.006761
2022-01-20 17:22:38,696 iteration 4260 : loss : 0.021219, loss_ce: 0.007016
2022-01-20 17:22:40,014 iteration 4261 : loss : 0.017380, loss_ce: 0.007274
2022-01-20 17:22:41,424 iteration 4262 : loss : 0.020687, loss_ce: 0.010096
2022-01-20 17:22:42,736 iteration 4263 : loss : 0.015766, loss_ce: 0.006045
2022-01-20 17:22:43,979 iteration 4264 : loss : 0.028187, loss_ce: 0.008014
2022-01-20 17:22:45,263 iteration 4265 : loss : 0.017916, loss_ce: 0.006176
2022-01-20 17:22:46,569 iteration 4266 : loss : 0.020315, loss_ce: 0.007214
2022-01-20 17:22:47,882 iteration 4267 : loss : 0.020419, loss_ce: 0.009964
 63%|████████████████▉          | 251/400 [1:42:36<1:02:01, 24.97s/it]2022-01-20 17:22:49,254 iteration 4268 : loss : 0.018070, loss_ce: 0.007765
2022-01-20 17:22:50,507 iteration 4269 : loss : 0.018712, loss_ce: 0.005881
2022-01-20 17:22:51,785 iteration 4270 : loss : 0.022652, loss_ce: 0.003239
2022-01-20 17:22:53,042 iteration 4271 : loss : 0.015177, loss_ce: 0.006758
2022-01-20 17:22:54,401 iteration 4272 : loss : 0.026379, loss_ce: 0.010684
2022-01-20 17:22:55,733 iteration 4273 : loss : 0.019652, loss_ce: 0.008466
2022-01-20 17:22:57,081 iteration 4274 : loss : 0.021350, loss_ce: 0.009793
2022-01-20 17:22:58,258 iteration 4275 : loss : 0.014987, loss_ce: 0.006327
2022-01-20 17:22:59,531 iteration 4276 : loss : 0.019270, loss_ce: 0.006349
2022-01-20 17:23:00,813 iteration 4277 : loss : 0.017655, loss_ce: 0.006869
2022-01-20 17:23:02,131 iteration 4278 : loss : 0.029099, loss_ce: 0.007734
2022-01-20 17:23:03,379 iteration 4279 : loss : 0.011539, loss_ce: 0.003754
2022-01-20 17:23:04,649 iteration 4280 : loss : 0.018807, loss_ce: 0.005601
2022-01-20 17:23:06,109 iteration 4281 : loss : 0.018727, loss_ce: 0.008572
2022-01-20 17:23:07,440 iteration 4282 : loss : 0.021999, loss_ce: 0.009036
2022-01-20 17:23:08,666 iteration 4283 : loss : 0.015774, loss_ce: 0.006512
2022-01-20 17:23:09,983 iteration 4284 : loss : 0.017949, loss_ce: 0.008350
 63%|██████████████████▎          | 252/400 [1:42:58<59:28, 24.11s/it]2022-01-20 17:23:11,427 iteration 4285 : loss : 0.027283, loss_ce: 0.012737
2022-01-20 17:23:12,801 iteration 4286 : loss : 0.017120, loss_ce: 0.004743
2022-01-20 17:23:14,188 iteration 4287 : loss : 0.029938, loss_ce: 0.011888
2022-01-20 17:23:15,517 iteration 4288 : loss : 0.025485, loss_ce: 0.008899
2022-01-20 17:23:16,864 iteration 4289 : loss : 0.018232, loss_ce: 0.005716
2022-01-20 17:23:18,243 iteration 4290 : loss : 0.039766, loss_ce: 0.012617
2022-01-20 17:23:19,480 iteration 4291 : loss : 0.019027, loss_ce: 0.006581
2022-01-20 17:23:20,875 iteration 4292 : loss : 0.018771, loss_ce: 0.006999
2022-01-20 17:23:22,203 iteration 4293 : loss : 0.021798, loss_ce: 0.009936
2022-01-20 17:23:23,523 iteration 4294 : loss : 0.019728, loss_ce: 0.009417
2022-01-20 17:23:24,881 iteration 4295 : loss : 0.021939, loss_ce: 0.010552
2022-01-20 17:23:26,125 iteration 4296 : loss : 0.014956, loss_ce: 0.006282
2022-01-20 17:23:27,461 iteration 4297 : loss : 0.022115, loss_ce: 0.007494
2022-01-20 17:23:28,734 iteration 4298 : loss : 0.017276, loss_ce: 0.005354
2022-01-20 17:23:30,136 iteration 4299 : loss : 0.026317, loss_ce: 0.009906
2022-01-20 17:23:31,498 iteration 4300 : loss : 0.023483, loss_ce: 0.007097
2022-01-20 17:23:32,786 iteration 4301 : loss : 0.016832, loss_ce: 0.006486
 63%|██████████████████▎          | 253/400 [1:43:21<58:06, 23.72s/it]2022-01-20 17:23:34,193 iteration 4302 : loss : 0.016224, loss_ce: 0.006718
2022-01-20 17:23:35,558 iteration 4303 : loss : 0.020571, loss_ce: 0.007124
2022-01-20 17:23:36,805 iteration 4304 : loss : 0.015333, loss_ce: 0.005687
2022-01-20 17:23:38,145 iteration 4305 : loss : 0.021994, loss_ce: 0.006171
2022-01-20 17:23:39,433 iteration 4306 : loss : 0.022609, loss_ce: 0.006949
2022-01-20 17:23:40,720 iteration 4307 : loss : 0.014601, loss_ce: 0.005142
2022-01-20 17:23:42,083 iteration 4308 : loss : 0.021442, loss_ce: 0.007097
2022-01-20 17:23:43,341 iteration 4309 : loss : 0.038265, loss_ce: 0.010562
2022-01-20 17:23:44,679 iteration 4310 : loss : 0.019083, loss_ce: 0.009415
2022-01-20 17:23:45,994 iteration 4311 : loss : 0.016210, loss_ce: 0.007195
2022-01-20 17:23:47,415 iteration 4312 : loss : 0.029085, loss_ce: 0.010669
2022-01-20 17:23:48,707 iteration 4313 : loss : 0.020470, loss_ce: 0.007104
2022-01-20 17:23:49,988 iteration 4314 : loss : 0.026307, loss_ce: 0.007380
2022-01-20 17:23:51,245 iteration 4315 : loss : 0.019724, loss_ce: 0.009952
2022-01-20 17:23:52,618 iteration 4316 : loss : 0.023430, loss_ce: 0.009166
2022-01-20 17:23:53,896 iteration 4317 : loss : 0.048718, loss_ce: 0.019265
2022-01-20 17:23:55,172 iteration 4318 : loss : 0.018063, loss_ce: 0.008808
 64%|██████████████████▍          | 254/400 [1:43:43<56:44, 23.32s/it]2022-01-20 17:23:56,596 iteration 4319 : loss : 0.028037, loss_ce: 0.008861
2022-01-20 17:23:57,954 iteration 4320 : loss : 0.028266, loss_ce: 0.011161
2022-01-20 17:23:59,354 iteration 4321 : loss : 0.026209, loss_ce: 0.013283
2022-01-20 17:24:00,664 iteration 4322 : loss : 0.023254, loss_ce: 0.007236
2022-01-20 17:24:01,928 iteration 4323 : loss : 0.014612, loss_ce: 0.004598
2022-01-20 17:24:03,273 iteration 4324 : loss : 0.024573, loss_ce: 0.008979
2022-01-20 17:24:04,707 iteration 4325 : loss : 0.034668, loss_ce: 0.008622
2022-01-20 17:24:06,011 iteration 4326 : loss : 0.022651, loss_ce: 0.012857
2022-01-20 17:24:07,268 iteration 4327 : loss : 0.018780, loss_ce: 0.007694
2022-01-20 17:24:08,551 iteration 4328 : loss : 0.034897, loss_ce: 0.012718
2022-01-20 17:24:09,895 iteration 4329 : loss : 0.019580, loss_ce: 0.007282
2022-01-20 17:24:11,153 iteration 4330 : loss : 0.016754, loss_ce: 0.006524
2022-01-20 17:24:12,605 iteration 4331 : loss : 0.031477, loss_ce: 0.010132
2022-01-20 17:24:13,959 iteration 4332 : loss : 0.026423, loss_ce: 0.012361
2022-01-20 17:24:15,169 iteration 4333 : loss : 0.015512, loss_ce: 0.005162
2022-01-20 17:24:16,404 iteration 4334 : loss : 0.016041, loss_ce: 0.006562
2022-01-20 17:24:16,404 Training Data Eval:
2022-01-20 17:24:22,933   Average segmentation loss on training set: 0.0126
2022-01-20 17:24:22,934 Validation Data Eval:
2022-01-20 17:24:25,156   Average segmentation loss on validation set: 0.0733
2022-01-20 17:24:26,538 iteration 4335 : loss : 0.039570, loss_ce: 0.022340
 64%|█████████████████▏         | 255/400 [1:44:15<1:02:11, 25.73s/it]2022-01-20 17:24:27,898 iteration 4336 : loss : 0.016019, loss_ce: 0.006305
2022-01-20 17:24:29,229 iteration 4337 : loss : 0.020851, loss_ce: 0.007665
2022-01-20 17:24:30,638 iteration 4338 : loss : 0.028251, loss_ce: 0.011059
2022-01-20 17:24:31,915 iteration 4339 : loss : 0.025816, loss_ce: 0.007492
2022-01-20 17:24:33,241 iteration 4340 : loss : 0.022779, loss_ce: 0.009637
2022-01-20 17:24:34,591 iteration 4341 : loss : 0.048761, loss_ce: 0.025579
2022-01-20 17:24:35,890 iteration 4342 : loss : 0.033454, loss_ce: 0.011003
2022-01-20 17:24:37,234 iteration 4343 : loss : 0.014678, loss_ce: 0.004733
2022-01-20 17:24:38,526 iteration 4344 : loss : 0.026702, loss_ce: 0.009110
2022-01-20 17:24:39,846 iteration 4345 : loss : 0.018790, loss_ce: 0.005659
2022-01-20 17:24:41,123 iteration 4346 : loss : 0.016764, loss_ce: 0.007407
2022-01-20 17:24:42,489 iteration 4347 : loss : 0.027802, loss_ce: 0.010892
2022-01-20 17:24:43,829 iteration 4348 : loss : 0.021540, loss_ce: 0.011667
2022-01-20 17:24:45,136 iteration 4349 : loss : 0.023063, loss_ce: 0.007549
2022-01-20 17:24:46,413 iteration 4350 : loss : 0.018522, loss_ce: 0.007672
2022-01-20 17:24:47,649 iteration 4351 : loss : 0.016198, loss_ce: 0.007090
2022-01-20 17:24:48,936 iteration 4352 : loss : 0.014428, loss_ce: 0.005475
 64%|██████████████████▌          | 256/400 [1:44:37<59:21, 24.74s/it]2022-01-20 17:24:50,347 iteration 4353 : loss : 0.019139, loss_ce: 0.006988
2022-01-20 17:24:51,738 iteration 4354 : loss : 0.026554, loss_ce: 0.009613
2022-01-20 17:24:52,973 iteration 4355 : loss : 0.020974, loss_ce: 0.007064
2022-01-20 17:24:54,311 iteration 4356 : loss : 0.030178, loss_ce: 0.015180
2022-01-20 17:24:55,617 iteration 4357 : loss : 0.028795, loss_ce: 0.011290
2022-01-20 17:24:56,883 iteration 4358 : loss : 0.020584, loss_ce: 0.009816
2022-01-20 17:24:58,180 iteration 4359 : loss : 0.014819, loss_ce: 0.005509
2022-01-20 17:24:59,473 iteration 4360 : loss : 0.026099, loss_ce: 0.008483
2022-01-20 17:25:00,857 iteration 4361 : loss : 0.022438, loss_ce: 0.010112
2022-01-20 17:25:02,139 iteration 4362 : loss : 0.015958, loss_ce: 0.005249
2022-01-20 17:25:03,375 iteration 4363 : loss : 0.016753, loss_ce: 0.008305
2022-01-20 17:25:04,739 iteration 4364 : loss : 0.026839, loss_ce: 0.011788
2022-01-20 17:25:06,034 iteration 4365 : loss : 0.021067, loss_ce: 0.009834
2022-01-20 17:25:07,220 iteration 4366 : loss : 0.014311, loss_ce: 0.006085
2022-01-20 17:25:08,521 iteration 4367 : loss : 0.018518, loss_ce: 0.006247
2022-01-20 17:25:09,910 iteration 4368 : loss : 0.034530, loss_ce: 0.013598
2022-01-20 17:25:11,156 iteration 4369 : loss : 0.022060, loss_ce: 0.005995
 64%|██████████████████▋          | 257/400 [1:44:59<57:09, 23.98s/it]2022-01-20 17:25:12,557 iteration 4370 : loss : 0.030809, loss_ce: 0.007503
2022-01-20 17:25:13,884 iteration 4371 : loss : 0.019889, loss_ce: 0.009447
2022-01-20 17:25:15,118 iteration 4372 : loss : 0.015165, loss_ce: 0.006549
2022-01-20 17:25:16,476 iteration 4373 : loss : 0.024408, loss_ce: 0.008326
2022-01-20 17:25:17,775 iteration 4374 : loss : 0.017082, loss_ce: 0.007965
2022-01-20 17:25:19,003 iteration 4375 : loss : 0.020546, loss_ce: 0.009483
2022-01-20 17:25:20,279 iteration 4376 : loss : 0.018808, loss_ce: 0.006458
2022-01-20 17:25:21,683 iteration 4377 : loss : 0.024349, loss_ce: 0.009296
2022-01-20 17:25:23,011 iteration 4378 : loss : 0.022159, loss_ce: 0.008129
2022-01-20 17:25:24,413 iteration 4379 : loss : 0.027458, loss_ce: 0.012359
2022-01-20 17:25:25,737 iteration 4380 : loss : 0.016163, loss_ce: 0.007643
2022-01-20 17:25:27,088 iteration 4381 : loss : 0.025615, loss_ce: 0.013981
2022-01-20 17:25:28,395 iteration 4382 : loss : 0.022893, loss_ce: 0.009179
2022-01-20 17:25:29,711 iteration 4383 : loss : 0.024374, loss_ce: 0.006980
2022-01-20 17:25:31,035 iteration 4384 : loss : 0.026143, loss_ce: 0.009316
2022-01-20 17:25:32,270 iteration 4385 : loss : 0.018305, loss_ce: 0.009578
2022-01-20 17:25:33,612 iteration 4386 : loss : 0.021276, loss_ce: 0.008354
 64%|██████████████████▋          | 258/400 [1:45:22<55:40, 23.52s/it]2022-01-20 17:25:34,986 iteration 4387 : loss : 0.017887, loss_ce: 0.008031
2022-01-20 17:25:36,358 iteration 4388 : loss : 0.015220, loss_ce: 0.006455
2022-01-20 17:25:37,598 iteration 4389 : loss : 0.014108, loss_ce: 0.006159
2022-01-20 17:25:38,841 iteration 4390 : loss : 0.017468, loss_ce: 0.006790
2022-01-20 17:25:40,147 iteration 4391 : loss : 0.024562, loss_ce: 0.010084
2022-01-20 17:25:41,496 iteration 4392 : loss : 0.021355, loss_ce: 0.010584
2022-01-20 17:25:42,726 iteration 4393 : loss : 0.021094, loss_ce: 0.006592
2022-01-20 17:25:44,128 iteration 4394 : loss : 0.019079, loss_ce: 0.007502
2022-01-20 17:25:45,489 iteration 4395 : loss : 0.019651, loss_ce: 0.006241
2022-01-20 17:25:46,891 iteration 4396 : loss : 0.021792, loss_ce: 0.007977
2022-01-20 17:25:48,195 iteration 4397 : loss : 0.031802, loss_ce: 0.011643
2022-01-20 17:25:49,486 iteration 4398 : loss : 0.021543, loss_ce: 0.005979
2022-01-20 17:25:50,806 iteration 4399 : loss : 0.014773, loss_ce: 0.005068
2022-01-20 17:25:52,087 iteration 4400 : loss : 0.014911, loss_ce: 0.006338
2022-01-20 17:25:53,372 iteration 4401 : loss : 0.017259, loss_ce: 0.007785
2022-01-20 17:25:54,618 iteration 4402 : loss : 0.016610, loss_ce: 0.005292
2022-01-20 17:25:55,936 iteration 4403 : loss : 0.036280, loss_ce: 0.010460
 65%|██████████████████▊          | 259/400 [1:45:44<54:25, 23.16s/it]2022-01-20 17:25:57,241 iteration 4404 : loss : 0.016167, loss_ce: 0.007891
2022-01-20 17:25:58,580 iteration 4405 : loss : 0.016368, loss_ce: 0.004840
2022-01-20 17:25:59,887 iteration 4406 : loss : 0.018892, loss_ce: 0.006258
2022-01-20 17:26:01,132 iteration 4407 : loss : 0.019903, loss_ce: 0.006639
2022-01-20 17:26:02,358 iteration 4408 : loss : 0.022739, loss_ce: 0.005720
2022-01-20 17:26:03,696 iteration 4409 : loss : 0.016301, loss_ce: 0.006326
2022-01-20 17:26:05,015 iteration 4410 : loss : 0.027993, loss_ce: 0.008876
2022-01-20 17:26:06,393 iteration 4411 : loss : 0.014602, loss_ce: 0.006457
2022-01-20 17:26:07,635 iteration 4412 : loss : 0.017835, loss_ce: 0.007274
2022-01-20 17:26:09,022 iteration 4413 : loss : 0.021298, loss_ce: 0.006432
2022-01-20 17:26:10,227 iteration 4414 : loss : 0.016267, loss_ce: 0.005979
2022-01-20 17:26:11,549 iteration 4415 : loss : 0.026122, loss_ce: 0.010437
2022-01-20 17:26:12,827 iteration 4416 : loss : 0.021904, loss_ce: 0.005313
2022-01-20 17:26:14,140 iteration 4417 : loss : 0.019643, loss_ce: 0.006862
2022-01-20 17:26:15,464 iteration 4418 : loss : 0.022518, loss_ce: 0.010734
2022-01-20 17:26:16,788 iteration 4419 : loss : 0.023962, loss_ce: 0.007509
2022-01-20 17:26:16,789 Training Data Eval:
2022-01-20 17:26:23,297   Average segmentation loss on training set: 0.0121
2022-01-20 17:26:23,297 Validation Data Eval:
2022-01-20 17:26:25,498   Average segmentation loss on validation set: 0.0753
2022-01-20 17:26:26,760 iteration 4420 : loss : 0.013536, loss_ce: 0.005445
 65%|██████████████████▊          | 260/400 [1:46:15<59:24, 25.46s/it]2022-01-20 17:26:28,153 iteration 4421 : loss : 0.018501, loss_ce: 0.005739
2022-01-20 17:26:29,505 iteration 4422 : loss : 0.023875, loss_ce: 0.008503
2022-01-20 17:26:30,920 iteration 4423 : loss : 0.025254, loss_ce: 0.009981
2022-01-20 17:26:32,281 iteration 4424 : loss : 0.024873, loss_ce: 0.012044
2022-01-20 17:26:33,514 iteration 4425 : loss : 0.013582, loss_ce: 0.004922
2022-01-20 17:26:34,873 iteration 4426 : loss : 0.017234, loss_ce: 0.006505
2022-01-20 17:26:36,217 iteration 4427 : loss : 0.020336, loss_ce: 0.005075
2022-01-20 17:26:37,568 iteration 4428 : loss : 0.018004, loss_ce: 0.006550
2022-01-20 17:26:38,949 iteration 4429 : loss : 0.028578, loss_ce: 0.009906
2022-01-20 17:26:40,237 iteration 4430 : loss : 0.028575, loss_ce: 0.009234
2022-01-20 17:26:41,529 iteration 4431 : loss : 0.018368, loss_ce: 0.007366
2022-01-20 17:26:42,859 iteration 4432 : loss : 0.015919, loss_ce: 0.005845
2022-01-20 17:26:44,163 iteration 4433 : loss : 0.016874, loss_ce: 0.006721
2022-01-20 17:26:45,449 iteration 4434 : loss : 0.017294, loss_ce: 0.006158
2022-01-20 17:26:46,796 iteration 4435 : loss : 0.024475, loss_ce: 0.008238
2022-01-20 17:26:48,241 iteration 4436 : loss : 0.035419, loss_ce: 0.017688
2022-01-20 17:26:49,483 iteration 4437 : loss : 0.019774, loss_ce: 0.008327
 65%|██████████████████▉          | 261/400 [1:46:38<57:04, 24.64s/it]2022-01-20 17:26:50,914 iteration 4438 : loss : 0.029017, loss_ce: 0.007917
2022-01-20 17:26:52,171 iteration 4439 : loss : 0.022920, loss_ce: 0.008424
2022-01-20 17:26:53,521 iteration 4440 : loss : 0.027278, loss_ce: 0.010602
2022-01-20 17:26:54,876 iteration 4441 : loss : 0.021553, loss_ce: 0.009871
2022-01-20 17:26:56,124 iteration 4442 : loss : 0.016663, loss_ce: 0.008298
2022-01-20 17:26:57,438 iteration 4443 : loss : 0.017761, loss_ce: 0.007841
2022-01-20 17:26:58,712 iteration 4444 : loss : 0.025457, loss_ce: 0.009077
2022-01-20 17:27:00,031 iteration 4445 : loss : 0.022585, loss_ce: 0.009972
2022-01-20 17:27:01,367 iteration 4446 : loss : 0.037632, loss_ce: 0.012267
2022-01-20 17:27:02,696 iteration 4447 : loss : 0.027409, loss_ce: 0.009767
2022-01-20 17:27:03,972 iteration 4448 : loss : 0.022163, loss_ce: 0.006639
2022-01-20 17:27:05,286 iteration 4449 : loss : 0.019674, loss_ce: 0.009059
2022-01-20 17:27:06,656 iteration 4450 : loss : 0.018343, loss_ce: 0.006861
2022-01-20 17:27:07,887 iteration 4451 : loss : 0.017661, loss_ce: 0.005860
2022-01-20 17:27:09,211 iteration 4452 : loss : 0.015762, loss_ce: 0.006395
2022-01-20 17:27:10,609 iteration 4453 : loss : 0.025333, loss_ce: 0.009703
2022-01-20 17:27:11,936 iteration 4454 : loss : 0.019607, loss_ce: 0.008272
 66%|██████████████████▉          | 262/400 [1:47:00<55:09, 23.98s/it]2022-01-20 17:27:13,394 iteration 4455 : loss : 0.016427, loss_ce: 0.006246
2022-01-20 17:27:14,690 iteration 4456 : loss : 0.020790, loss_ce: 0.009747
2022-01-20 17:27:15,897 iteration 4457 : loss : 0.013738, loss_ce: 0.006509
2022-01-20 17:27:17,233 iteration 4458 : loss : 0.020378, loss_ce: 0.008251
2022-01-20 17:27:18,461 iteration 4459 : loss : 0.013739, loss_ce: 0.005545
2022-01-20 17:27:19,761 iteration 4460 : loss : 0.016162, loss_ce: 0.005683
2022-01-20 17:27:21,008 iteration 4461 : loss : 0.016583, loss_ce: 0.007546
2022-01-20 17:27:22,272 iteration 4462 : loss : 0.044069, loss_ce: 0.024191
2022-01-20 17:27:23,535 iteration 4463 : loss : 0.016281, loss_ce: 0.005698
2022-01-20 17:27:24,793 iteration 4464 : loss : 0.016289, loss_ce: 0.006251
2022-01-20 17:27:26,137 iteration 4465 : loss : 0.022580, loss_ce: 0.009070
2022-01-20 17:27:27,489 iteration 4466 : loss : 0.020824, loss_ce: 0.007116
2022-01-20 17:27:28,806 iteration 4467 : loss : 0.017134, loss_ce: 0.006251
2022-01-20 17:27:30,102 iteration 4468 : loss : 0.013630, loss_ce: 0.004523
2022-01-20 17:27:31,346 iteration 4469 : loss : 0.021911, loss_ce: 0.005361
2022-01-20 17:27:32,682 iteration 4470 : loss : 0.029654, loss_ce: 0.009961
2022-01-20 17:27:34,038 iteration 4471 : loss : 0.017893, loss_ce: 0.006044
 66%|███████████████████          | 263/400 [1:47:22<53:28, 23.42s/it]2022-01-20 17:27:35,355 iteration 4472 : loss : 0.014183, loss_ce: 0.005771
2022-01-20 17:27:36,640 iteration 4473 : loss : 0.019248, loss_ce: 0.007394
2022-01-20 17:27:37,970 iteration 4474 : loss : 0.016444, loss_ce: 0.005469
2022-01-20 17:27:39,232 iteration 4475 : loss : 0.016618, loss_ce: 0.007479
2022-01-20 17:27:40,433 iteration 4476 : loss : 0.016057, loss_ce: 0.005470
2022-01-20 17:27:41,764 iteration 4477 : loss : 0.020846, loss_ce: 0.008364
2022-01-20 17:27:43,065 iteration 4478 : loss : 0.030874, loss_ce: 0.011248
2022-01-20 17:27:44,363 iteration 4479 : loss : 0.023318, loss_ce: 0.007499
2022-01-20 17:27:45,611 iteration 4480 : loss : 0.015628, loss_ce: 0.006530
2022-01-20 17:27:46,858 iteration 4481 : loss : 0.015629, loss_ce: 0.006628
2022-01-20 17:27:48,229 iteration 4482 : loss : 0.019036, loss_ce: 0.006179
2022-01-20 17:27:49,626 iteration 4483 : loss : 0.024946, loss_ce: 0.008898
2022-01-20 17:27:50,980 iteration 4484 : loss : 0.031928, loss_ce: 0.011646
2022-01-20 17:27:52,228 iteration 4485 : loss : 0.015594, loss_ce: 0.004680
2022-01-20 17:27:53,645 iteration 4486 : loss : 0.023455, loss_ce: 0.009337
2022-01-20 17:27:54,889 iteration 4487 : loss : 0.016812, loss_ce: 0.007240
2022-01-20 17:27:56,162 iteration 4488 : loss : 0.019693, loss_ce: 0.008669
 66%|███████████████████▏         | 264/400 [1:47:44<52:12, 23.03s/it]2022-01-20 17:27:57,562 iteration 4489 : loss : 0.022801, loss_ce: 0.009228
2022-01-20 17:27:58,862 iteration 4490 : loss : 0.025954, loss_ce: 0.008422
2022-01-20 17:28:00,244 iteration 4491 : loss : 0.033591, loss_ce: 0.013587
2022-01-20 17:28:01,565 iteration 4492 : loss : 0.018035, loss_ce: 0.007284
2022-01-20 17:28:02,938 iteration 4493 : loss : 0.035311, loss_ce: 0.009676
2022-01-20 17:28:04,142 iteration 4494 : loss : 0.015969, loss_ce: 0.006207
2022-01-20 17:28:05,487 iteration 4495 : loss : 0.023168, loss_ce: 0.010479
2022-01-20 17:28:06,832 iteration 4496 : loss : 0.027040, loss_ce: 0.007413
2022-01-20 17:28:08,066 iteration 4497 : loss : 0.018969, loss_ce: 0.005412
2022-01-20 17:28:09,460 iteration 4498 : loss : 0.032958, loss_ce: 0.014171
2022-01-20 17:28:10,893 iteration 4499 : loss : 0.027714, loss_ce: 0.012532
2022-01-20 17:28:12,152 iteration 4500 : loss : 0.017149, loss_ce: 0.007325
2022-01-20 17:28:13,397 iteration 4501 : loss : 0.020001, loss_ce: 0.007394
2022-01-20 17:28:14,644 iteration 4502 : loss : 0.016210, loss_ce: 0.005963
2022-01-20 17:28:16,025 iteration 4503 : loss : 0.027579, loss_ce: 0.013582
2022-01-20 17:28:17,307 iteration 4504 : loss : 0.022424, loss_ce: 0.006404
2022-01-20 17:28:17,307 Training Data Eval:
2022-01-20 17:28:23,816   Average segmentation loss on training set: 0.0136
2022-01-20 17:28:23,816 Validation Data Eval:
2022-01-20 17:28:26,032   Average segmentation loss on validation set: 0.0973
2022-01-20 17:28:27,270 iteration 4505 : loss : 0.014337, loss_ce: 0.005820
 66%|███████████████████▏         | 265/400 [1:48:15<57:16, 25.45s/it]2022-01-20 17:28:28,703 iteration 4506 : loss : 0.024097, loss_ce: 0.007498
2022-01-20 17:28:29,958 iteration 4507 : loss : 0.013689, loss_ce: 0.004447
2022-01-20 17:28:31,322 iteration 4508 : loss : 0.031373, loss_ce: 0.009413
2022-01-20 17:28:32,658 iteration 4509 : loss : 0.023111, loss_ce: 0.007571
2022-01-20 17:28:33,984 iteration 4510 : loss : 0.015813, loss_ce: 0.006152
2022-01-20 17:28:35,262 iteration 4511 : loss : 0.019681, loss_ce: 0.006837
2022-01-20 17:28:36,568 iteration 4512 : loss : 0.013666, loss_ce: 0.005631
2022-01-20 17:28:37,911 iteration 4513 : loss : 0.020102, loss_ce: 0.010125
2022-01-20 17:28:39,149 iteration 4514 : loss : 0.015338, loss_ce: 0.005750
2022-01-20 17:28:40,442 iteration 4515 : loss : 0.018846, loss_ce: 0.006744
2022-01-20 17:28:41,878 iteration 4516 : loss : 0.048850, loss_ce: 0.017334
2022-01-20 17:28:43,193 iteration 4517 : loss : 0.018751, loss_ce: 0.006155
2022-01-20 17:28:44,556 iteration 4518 : loss : 0.018928, loss_ce: 0.005778
2022-01-20 17:28:45,906 iteration 4519 : loss : 0.022198, loss_ce: 0.010382
2022-01-20 17:28:47,191 iteration 4520 : loss : 0.016210, loss_ce: 0.005710
2022-01-20 17:28:48,559 iteration 4521 : loss : 0.020371, loss_ce: 0.006898
2022-01-20 17:28:49,833 iteration 4522 : loss : 0.014956, loss_ce: 0.007478
 66%|███████████████████▎         | 266/400 [1:48:38<54:54, 24.59s/it]2022-01-20 17:28:51,303 iteration 4523 : loss : 0.017339, loss_ce: 0.006574
2022-01-20 17:28:52,547 iteration 4524 : loss : 0.011432, loss_ce: 0.004177
2022-01-20 17:28:53,956 iteration 4525 : loss : 0.030555, loss_ce: 0.010292
2022-01-20 17:28:55,293 iteration 4526 : loss : 0.017159, loss_ce: 0.007079
2022-01-20 17:28:56,621 iteration 4527 : loss : 0.018671, loss_ce: 0.008344
2022-01-20 17:28:57,998 iteration 4528 : loss : 0.022742, loss_ce: 0.007507
2022-01-20 17:28:59,308 iteration 4529 : loss : 0.018162, loss_ce: 0.006801
2022-01-20 17:29:00,649 iteration 4530 : loss : 0.026833, loss_ce: 0.012175
2022-01-20 17:29:01,907 iteration 4531 : loss : 0.019966, loss_ce: 0.008613
2022-01-20 17:29:03,266 iteration 4532 : loss : 0.024993, loss_ce: 0.010739
2022-01-20 17:29:04,659 iteration 4533 : loss : 0.019006, loss_ce: 0.007198
2022-01-20 17:29:06,094 iteration 4534 : loss : 0.021658, loss_ce: 0.007829
2022-01-20 17:29:07,313 iteration 4535 : loss : 0.017453, loss_ce: 0.005620
2022-01-20 17:29:08,658 iteration 4536 : loss : 0.018031, loss_ce: 0.010109
2022-01-20 17:29:10,055 iteration 4537 : loss : 0.024698, loss_ce: 0.010092
2022-01-20 17:29:11,323 iteration 4538 : loss : 0.018362, loss_ce: 0.005827
2022-01-20 17:29:12,688 iteration 4539 : loss : 0.020138, loss_ce: 0.007788
 67%|███████████████████▎         | 267/400 [1:49:01<53:20, 24.06s/it]2022-01-20 17:29:14,104 iteration 4540 : loss : 0.017068, loss_ce: 0.004606
2022-01-20 17:29:15,334 iteration 4541 : loss : 0.014568, loss_ce: 0.005259
2022-01-20 17:29:16,646 iteration 4542 : loss : 0.021948, loss_ce: 0.004354
2022-01-20 17:29:17,837 iteration 4543 : loss : 0.016103, loss_ce: 0.006376
2022-01-20 17:29:19,165 iteration 4544 : loss : 0.023182, loss_ce: 0.010310
2022-01-20 17:29:20,538 iteration 4545 : loss : 0.021086, loss_ce: 0.009500
2022-01-20 17:29:21,867 iteration 4546 : loss : 0.020925, loss_ce: 0.007800
2022-01-20 17:29:23,193 iteration 4547 : loss : 0.019579, loss_ce: 0.008955
2022-01-20 17:29:24,496 iteration 4548 : loss : 0.018334, loss_ce: 0.006284
2022-01-20 17:29:25,897 iteration 4549 : loss : 0.017824, loss_ce: 0.006642
2022-01-20 17:29:27,285 iteration 4550 : loss : 0.025229, loss_ce: 0.007601
2022-01-20 17:29:28,659 iteration 4551 : loss : 0.026638, loss_ce: 0.005823
2022-01-20 17:29:29,894 iteration 4552 : loss : 0.012818, loss_ce: 0.004990
2022-01-20 17:29:31,173 iteration 4553 : loss : 0.026148, loss_ce: 0.010314
2022-01-20 17:29:32,495 iteration 4554 : loss : 0.016095, loss_ce: 0.005687
2022-01-20 17:29:33,893 iteration 4555 : loss : 0.023187, loss_ce: 0.008795
2022-01-20 17:29:35,233 iteration 4556 : loss : 0.014694, loss_ce: 0.006528
 67%|███████████████████▍         | 268/400 [1:49:23<51:56, 23.61s/it]2022-01-20 17:29:36,671 iteration 4557 : loss : 0.024450, loss_ce: 0.011575
2022-01-20 17:29:38,093 iteration 4558 : loss : 0.024974, loss_ce: 0.011625
2022-01-20 17:29:39,416 iteration 4559 : loss : 0.030356, loss_ce: 0.009045
2022-01-20 17:29:40,732 iteration 4560 : loss : 0.015432, loss_ce: 0.004370
2022-01-20 17:29:42,085 iteration 4561 : loss : 0.018114, loss_ce: 0.005258
2022-01-20 17:29:43,432 iteration 4562 : loss : 0.027696, loss_ce: 0.011139
2022-01-20 17:29:44,715 iteration 4563 : loss : 0.015016, loss_ce: 0.004897
2022-01-20 17:29:46,046 iteration 4564 : loss : 0.026656, loss_ce: 0.007920
2022-01-20 17:29:47,330 iteration 4565 : loss : 0.018202, loss_ce: 0.007061
2022-01-20 17:29:48,587 iteration 4566 : loss : 0.016863, loss_ce: 0.007965
2022-01-20 17:29:49,916 iteration 4567 : loss : 0.018949, loss_ce: 0.007540
2022-01-20 17:29:51,220 iteration 4568 : loss : 0.016865, loss_ce: 0.005163
2022-01-20 17:29:52,532 iteration 4569 : loss : 0.020211, loss_ce: 0.009408
2022-01-20 17:29:53,796 iteration 4570 : loss : 0.016116, loss_ce: 0.006690
2022-01-20 17:29:55,075 iteration 4571 : loss : 0.014983, loss_ce: 0.008494
2022-01-20 17:29:56,371 iteration 4572 : loss : 0.016481, loss_ce: 0.005344
2022-01-20 17:29:57,682 iteration 4573 : loss : 0.015667, loss_ce: 0.006725
 67%|███████████████████▌         | 269/400 [1:49:46<50:47, 23.26s/it]2022-01-20 17:29:59,032 iteration 4574 : loss : 0.015689, loss_ce: 0.004938
2022-01-20 17:30:00,278 iteration 4575 : loss : 0.013488, loss_ce: 0.005353
2022-01-20 17:30:01,608 iteration 4576 : loss : 0.015151, loss_ce: 0.007892
2022-01-20 17:30:02,976 iteration 4577 : loss : 0.018057, loss_ce: 0.006262
2022-01-20 17:30:04,295 iteration 4578 : loss : 0.023196, loss_ce: 0.011194
2022-01-20 17:30:05,587 iteration 4579 : loss : 0.024686, loss_ce: 0.012732
2022-01-20 17:30:06,871 iteration 4580 : loss : 0.014473, loss_ce: 0.006319
2022-01-20 17:30:08,283 iteration 4581 : loss : 0.024695, loss_ce: 0.007520
2022-01-20 17:30:09,583 iteration 4582 : loss : 0.025221, loss_ce: 0.010859
2022-01-20 17:30:10,886 iteration 4583 : loss : 0.019416, loss_ce: 0.008240
2022-01-20 17:30:12,147 iteration 4584 : loss : 0.019593, loss_ce: 0.007234
2022-01-20 17:30:13,464 iteration 4585 : loss : 0.019810, loss_ce: 0.005799
2022-01-20 17:30:14,772 iteration 4586 : loss : 0.015490, loss_ce: 0.007016
2022-01-20 17:30:16,162 iteration 4587 : loss : 0.022414, loss_ce: 0.007972
2022-01-20 17:30:17,430 iteration 4588 : loss : 0.016324, loss_ce: 0.003603
2022-01-20 17:30:18,730 iteration 4589 : loss : 0.016448, loss_ce: 0.007141
2022-01-20 17:30:18,730 Training Data Eval:
2022-01-20 17:30:25,255   Average segmentation loss on training set: 0.0111
2022-01-20 17:30:25,256 Validation Data Eval:
2022-01-20 17:30:27,490   Average segmentation loss on validation set: 0.0745
2022-01-20 17:30:28,945 iteration 4590 : loss : 0.022152, loss_ce: 0.008380
 68%|███████████████████▌         | 270/400 [1:50:17<55:35, 25.66s/it]2022-01-20 17:30:30,255 iteration 4591 : loss : 0.012952, loss_ce: 0.004101
2022-01-20 17:30:31,551 iteration 4592 : loss : 0.019074, loss_ce: 0.006430
2022-01-20 17:30:32,767 iteration 4593 : loss : 0.013359, loss_ce: 0.004225
2022-01-20 17:30:34,058 iteration 4594 : loss : 0.033112, loss_ce: 0.017406
2022-01-20 17:30:35,385 iteration 4595 : loss : 0.021946, loss_ce: 0.005107
2022-01-20 17:30:36,780 iteration 4596 : loss : 0.020507, loss_ce: 0.006598
2022-01-20 17:30:38,080 iteration 4597 : loss : 0.015935, loss_ce: 0.006910
2022-01-20 17:30:39,295 iteration 4598 : loss : 0.018014, loss_ce: 0.008697
2022-01-20 17:30:40,560 iteration 4599 : loss : 0.020090, loss_ce: 0.005022
2022-01-20 17:30:41,931 iteration 4600 : loss : 0.024751, loss_ce: 0.013480
2022-01-20 17:30:43,340 iteration 4601 : loss : 0.022490, loss_ce: 0.010916
2022-01-20 17:30:44,539 iteration 4602 : loss : 0.015763, loss_ce: 0.005896
2022-01-20 17:30:45,774 iteration 4603 : loss : 0.014198, loss_ce: 0.006418
2022-01-20 17:30:47,130 iteration 4604 : loss : 0.028432, loss_ce: 0.008491
2022-01-20 17:30:48,478 iteration 4605 : loss : 0.023231, loss_ce: 0.006562
2022-01-20 17:30:49,870 iteration 4606 : loss : 0.025706, loss_ce: 0.007184
2022-01-20 17:30:51,118 iteration 4607 : loss : 0.014697, loss_ce: 0.007855
 68%|███████████████████▋         | 271/400 [1:50:39<52:55, 24.62s/it]2022-01-20 17:30:52,552 iteration 4608 : loss : 0.040735, loss_ce: 0.011414
2022-01-20 17:30:53,939 iteration 4609 : loss : 0.022647, loss_ce: 0.010078
2022-01-20 17:30:55,284 iteration 4610 : loss : 0.024238, loss_ce: 0.006058
2022-01-20 17:30:56,585 iteration 4611 : loss : 0.019488, loss_ce: 0.007807
2022-01-20 17:30:57,809 iteration 4612 : loss : 0.014460, loss_ce: 0.005358
2022-01-20 17:30:59,158 iteration 4613 : loss : 0.018280, loss_ce: 0.007318
2022-01-20 17:31:00,510 iteration 4614 : loss : 0.017189, loss_ce: 0.006961
2022-01-20 17:31:01,869 iteration 4615 : loss : 0.028271, loss_ce: 0.010296
2022-01-20 17:31:03,257 iteration 4616 : loss : 0.027498, loss_ce: 0.010531
2022-01-20 17:31:04,495 iteration 4617 : loss : 0.021509, loss_ce: 0.009352
2022-01-20 17:31:05,841 iteration 4618 : loss : 0.028655, loss_ce: 0.010312
2022-01-20 17:31:07,206 iteration 4619 : loss : 0.019538, loss_ce: 0.007034
2022-01-20 17:31:08,570 iteration 4620 : loss : 0.016493, loss_ce: 0.004914
2022-01-20 17:31:09,949 iteration 4621 : loss : 0.021523, loss_ce: 0.007735
2022-01-20 17:31:11,241 iteration 4622 : loss : 0.018804, loss_ce: 0.005931
2022-01-20 17:31:12,515 iteration 4623 : loss : 0.024753, loss_ce: 0.008727
2022-01-20 17:31:13,823 iteration 4624 : loss : 0.019024, loss_ce: 0.008046
 68%|███████████████████▋         | 272/400 [1:51:02<51:17, 24.04s/it]2022-01-20 17:31:15,187 iteration 4625 : loss : 0.019253, loss_ce: 0.009110
2022-01-20 17:31:16,461 iteration 4626 : loss : 0.014051, loss_ce: 0.004581
2022-01-20 17:31:17,777 iteration 4627 : loss : 0.015821, loss_ce: 0.005273
2022-01-20 17:31:19,057 iteration 4628 : loss : 0.021552, loss_ce: 0.007378
2022-01-20 17:31:20,326 iteration 4629 : loss : 0.017980, loss_ce: 0.007192
2022-01-20 17:31:21,627 iteration 4630 : loss : 0.022528, loss_ce: 0.007559
2022-01-20 17:31:23,042 iteration 4631 : loss : 0.022885, loss_ce: 0.008490
2022-01-20 17:31:24,385 iteration 4632 : loss : 0.015737, loss_ce: 0.005380
2022-01-20 17:31:25,709 iteration 4633 : loss : 0.017405, loss_ce: 0.006611
2022-01-20 17:31:26,931 iteration 4634 : loss : 0.013946, loss_ce: 0.006065
2022-01-20 17:31:28,288 iteration 4635 : loss : 0.024564, loss_ce: 0.008501
2022-01-20 17:31:29,593 iteration 4636 : loss : 0.017380, loss_ce: 0.005957
2022-01-20 17:31:30,900 iteration 4637 : loss : 0.018666, loss_ce: 0.007184
2022-01-20 17:31:32,252 iteration 4638 : loss : 0.021272, loss_ce: 0.010662
2022-01-20 17:31:33,649 iteration 4639 : loss : 0.020772, loss_ce: 0.006327
2022-01-20 17:31:34,979 iteration 4640 : loss : 0.022346, loss_ce: 0.008786
2022-01-20 17:31:36,245 iteration 4641 : loss : 0.014777, loss_ce: 0.006223
 68%|███████████████████▊         | 273/400 [1:51:24<49:51, 23.56s/it]2022-01-20 17:31:37,661 iteration 4642 : loss : 0.045500, loss_ce: 0.012837
2022-01-20 17:31:39,007 iteration 4643 : loss : 0.029828, loss_ce: 0.013098
2022-01-20 17:31:40,333 iteration 4644 : loss : 0.017009, loss_ce: 0.007274
2022-01-20 17:31:41,814 iteration 4645 : loss : 0.026689, loss_ce: 0.011582
2022-01-20 17:31:43,071 iteration 4646 : loss : 0.014502, loss_ce: 0.006079
2022-01-20 17:31:44,330 iteration 4647 : loss : 0.018149, loss_ce: 0.007473
2022-01-20 17:31:45,521 iteration 4648 : loss : 0.014639, loss_ce: 0.005836
2022-01-20 17:31:46,843 iteration 4649 : loss : 0.019616, loss_ce: 0.008468
2022-01-20 17:31:48,138 iteration 4650 : loss : 0.015357, loss_ce: 0.005923
2022-01-20 17:31:49,455 iteration 4651 : loss : 0.017459, loss_ce: 0.006685
2022-01-20 17:31:50,774 iteration 4652 : loss : 0.023087, loss_ce: 0.009639
2022-01-20 17:31:52,100 iteration 4653 : loss : 0.015283, loss_ce: 0.006000
2022-01-20 17:31:53,415 iteration 4654 : loss : 0.017354, loss_ce: 0.008300
2022-01-20 17:31:54,734 iteration 4655 : loss : 0.020458, loss_ce: 0.005965
2022-01-20 17:31:56,122 iteration 4656 : loss : 0.045945, loss_ce: 0.007160
2022-01-20 17:31:57,403 iteration 4657 : loss : 0.043573, loss_ce: 0.006738
2022-01-20 17:31:58,657 iteration 4658 : loss : 0.016878, loss_ce: 0.004386
 68%|███████████████████▊         | 274/400 [1:51:47<48:45, 23.21s/it]2022-01-20 17:32:00,019 iteration 4659 : loss : 0.027367, loss_ce: 0.010577
2022-01-20 17:32:01,372 iteration 4660 : loss : 0.018334, loss_ce: 0.004181
2022-01-20 17:32:02,692 iteration 4661 : loss : 0.019821, loss_ce: 0.009928
2022-01-20 17:32:04,137 iteration 4662 : loss : 0.021546, loss_ce: 0.011090
2022-01-20 17:32:05,382 iteration 4663 : loss : 0.016874, loss_ce: 0.004928
2022-01-20 17:32:06,709 iteration 4664 : loss : 0.021670, loss_ce: 0.006447
2022-01-20 17:32:08,194 iteration 4665 : loss : 0.025572, loss_ce: 0.008158
2022-01-20 17:32:09,436 iteration 4666 : loss : 0.016013, loss_ce: 0.006048
2022-01-20 17:32:10,730 iteration 4667 : loss : 0.024897, loss_ce: 0.009804
2022-01-20 17:32:12,015 iteration 4668 : loss : 0.021090, loss_ce: 0.004968
2022-01-20 17:32:13,412 iteration 4669 : loss : 0.019365, loss_ce: 0.008841
2022-01-20 17:32:14,804 iteration 4670 : loss : 0.023508, loss_ce: 0.010643
2022-01-20 17:32:16,029 iteration 4671 : loss : 0.015477, loss_ce: 0.004999
2022-01-20 17:32:17,458 iteration 4672 : loss : 0.022312, loss_ce: 0.008438
2022-01-20 17:32:18,783 iteration 4673 : loss : 0.019700, loss_ce: 0.006818
2022-01-20 17:32:20,162 iteration 4674 : loss : 0.025499, loss_ce: 0.013929
2022-01-20 17:32:20,162 Training Data Eval:
2022-01-20 17:32:26,677   Average segmentation loss on training set: 0.0124
2022-01-20 17:32:26,677 Validation Data Eval:
2022-01-20 17:32:28,880   Average segmentation loss on validation set: 0.0712
2022-01-20 17:32:30,161 iteration 4675 : loss : 0.018323, loss_ce: 0.007304
 69%|███████████████████▉         | 275/400 [1:52:18<53:32, 25.70s/it]2022-01-20 17:32:31,617 iteration 4676 : loss : 0.019869, loss_ce: 0.006556
2022-01-20 17:32:32,891 iteration 4677 : loss : 0.019220, loss_ce: 0.007642
2022-01-20 17:32:34,188 iteration 4678 : loss : 0.027566, loss_ce: 0.007895
2022-01-20 17:32:35,499 iteration 4679 : loss : 0.019834, loss_ce: 0.010353
2022-01-20 17:32:36,751 iteration 4680 : loss : 0.019137, loss_ce: 0.006385
2022-01-20 17:32:38,066 iteration 4681 : loss : 0.022282, loss_ce: 0.006981
2022-01-20 17:32:39,315 iteration 4682 : loss : 0.021794, loss_ce: 0.004823
2022-01-20 17:32:40,622 iteration 4683 : loss : 0.030899, loss_ce: 0.016064
2022-01-20 17:32:41,973 iteration 4684 : loss : 0.026619, loss_ce: 0.011699
2022-01-20 17:32:43,284 iteration 4685 : loss : 0.020895, loss_ce: 0.009485
2022-01-20 17:32:44,485 iteration 4686 : loss : 0.016898, loss_ce: 0.005579
2022-01-20 17:32:45,838 iteration 4687 : loss : 0.017106, loss_ce: 0.007689
2022-01-20 17:32:47,218 iteration 4688 : loss : 0.023249, loss_ce: 0.008287
2022-01-20 17:32:48,604 iteration 4689 : loss : 0.022374, loss_ce: 0.008241
2022-01-20 17:32:49,868 iteration 4690 : loss : 0.018372, loss_ce: 0.005018
2022-01-20 17:32:51,106 iteration 4691 : loss : 0.020843, loss_ce: 0.007512
2022-01-20 17:32:52,396 iteration 4692 : loss : 0.017165, loss_ce: 0.006899
 69%|████████████████████         | 276/400 [1:52:40<50:58, 24.66s/it]2022-01-20 17:32:53,797 iteration 4693 : loss : 0.018096, loss_ce: 0.007402
2022-01-20 17:32:55,050 iteration 4694 : loss : 0.015498, loss_ce: 0.004445
2022-01-20 17:32:56,419 iteration 4695 : loss : 0.016325, loss_ce: 0.005855
2022-01-20 17:32:57,741 iteration 4696 : loss : 0.032611, loss_ce: 0.014519
2022-01-20 17:32:59,115 iteration 4697 : loss : 0.023303, loss_ce: 0.009953
2022-01-20 17:33:00,310 iteration 4698 : loss : 0.015739, loss_ce: 0.006276
2022-01-20 17:33:01,608 iteration 4699 : loss : 0.018970, loss_ce: 0.007229
2022-01-20 17:33:02,926 iteration 4700 : loss : 0.023700, loss_ce: 0.007566
2022-01-20 17:33:04,227 iteration 4701 : loss : 0.023498, loss_ce: 0.009474
2022-01-20 17:33:05,437 iteration 4702 : loss : 0.017087, loss_ce: 0.005759
2022-01-20 17:33:06,792 iteration 4703 : loss : 0.019289, loss_ce: 0.006513
2022-01-20 17:33:08,102 iteration 4704 : loss : 0.025387, loss_ce: 0.007348
2022-01-20 17:33:09,331 iteration 4705 : loss : 0.013749, loss_ce: 0.005336
2022-01-20 17:33:10,595 iteration 4706 : loss : 0.018538, loss_ce: 0.008026
2022-01-20 17:33:11,981 iteration 4707 : loss : 0.018798, loss_ce: 0.007864
2022-01-20 17:33:13,262 iteration 4708 : loss : 0.023471, loss_ce: 0.005481
2022-01-20 17:33:14,532 iteration 4709 : loss : 0.018279, loss_ce: 0.006907
 69%|████████████████████         | 277/400 [1:53:03<48:59, 23.90s/it]2022-01-20 17:33:15,970 iteration 4710 : loss : 0.026624, loss_ce: 0.008923
2022-01-20 17:33:17,219 iteration 4711 : loss : 0.019714, loss_ce: 0.009010
2022-01-20 17:33:18,512 iteration 4712 : loss : 0.015945, loss_ce: 0.006830
2022-01-20 17:33:19,773 iteration 4713 : loss : 0.013313, loss_ce: 0.005158
2022-01-20 17:33:21,047 iteration 4714 : loss : 0.012437, loss_ce: 0.005555
2022-01-20 17:33:22,452 iteration 4715 : loss : 0.030045, loss_ce: 0.010530
2022-01-20 17:33:23,757 iteration 4716 : loss : 0.013743, loss_ce: 0.005332
2022-01-20 17:33:25,069 iteration 4717 : loss : 0.025807, loss_ce: 0.007187
2022-01-20 17:33:26,343 iteration 4718 : loss : 0.021248, loss_ce: 0.007211
2022-01-20 17:33:27,610 iteration 4719 : loss : 0.012753, loss_ce: 0.004448
2022-01-20 17:33:28,984 iteration 4720 : loss : 0.015411, loss_ce: 0.006139
2022-01-20 17:33:30,280 iteration 4721 : loss : 0.015979, loss_ce: 0.005304
2022-01-20 17:33:31,583 iteration 4722 : loss : 0.017685, loss_ce: 0.007166
2022-01-20 17:33:32,924 iteration 4723 : loss : 0.022771, loss_ce: 0.005915
2022-01-20 17:33:34,172 iteration 4724 : loss : 0.017836, loss_ce: 0.009174
2022-01-20 17:33:35,459 iteration 4725 : loss : 0.020773, loss_ce: 0.009451
2022-01-20 17:33:36,726 iteration 4726 : loss : 0.017860, loss_ce: 0.005840
 70%|████████████████████▏        | 278/400 [1:53:25<47:33, 23.39s/it]2022-01-20 17:33:38,100 iteration 4727 : loss : 0.019754, loss_ce: 0.006895
2022-01-20 17:33:39,429 iteration 4728 : loss : 0.022696, loss_ce: 0.008422
2022-01-20 17:33:40,761 iteration 4729 : loss : 0.011675, loss_ce: 0.003651
2022-01-20 17:33:42,070 iteration 4730 : loss : 0.019686, loss_ce: 0.008773
2022-01-20 17:33:43,389 iteration 4731 : loss : 0.023800, loss_ce: 0.006162
2022-01-20 17:33:44,620 iteration 4732 : loss : 0.014973, loss_ce: 0.006535
2022-01-20 17:33:46,031 iteration 4733 : loss : 0.019224, loss_ce: 0.009404
2022-01-20 17:33:47,332 iteration 4734 : loss : 0.018985, loss_ce: 0.007940
2022-01-20 17:33:48,561 iteration 4735 : loss : 0.013708, loss_ce: 0.005309
2022-01-20 17:33:49,926 iteration 4736 : loss : 0.021975, loss_ce: 0.008937
2022-01-20 17:33:51,259 iteration 4737 : loss : 0.022807, loss_ce: 0.013600
2022-01-20 17:33:52,702 iteration 4738 : loss : 0.026267, loss_ce: 0.008339
2022-01-20 17:33:54,032 iteration 4739 : loss : 0.010903, loss_ce: 0.003935
2022-01-20 17:33:55,330 iteration 4740 : loss : 0.019277, loss_ce: 0.004966
2022-01-20 17:33:56,612 iteration 4741 : loss : 0.024605, loss_ce: 0.011901
2022-01-20 17:33:57,925 iteration 4742 : loss : 0.020294, loss_ce: 0.009966
2022-01-20 17:33:59,419 iteration 4743 : loss : 0.040144, loss_ce: 0.022756
 70%|████████████████████▏        | 279/400 [1:53:47<46:44, 23.18s/it]2022-01-20 17:34:00,838 iteration 4744 : loss : 0.015108, loss_ce: 0.005125
2022-01-20 17:34:02,152 iteration 4745 : loss : 0.019401, loss_ce: 0.008759
2022-01-20 17:34:03,456 iteration 4746 : loss : 0.019529, loss_ce: 0.006481
2022-01-20 17:34:04,691 iteration 4747 : loss : 0.012245, loss_ce: 0.005957
2022-01-20 17:34:06,117 iteration 4748 : loss : 0.036817, loss_ce: 0.018008
2022-01-20 17:34:07,350 iteration 4749 : loss : 0.021183, loss_ce: 0.009184
2022-01-20 17:34:08,674 iteration 4750 : loss : 0.019781, loss_ce: 0.005700
2022-01-20 17:34:10,001 iteration 4751 : loss : 0.021769, loss_ce: 0.009592
2022-01-20 17:34:11,301 iteration 4752 : loss : 0.022298, loss_ce: 0.006575
2022-01-20 17:34:12,562 iteration 4753 : loss : 0.014241, loss_ce: 0.004921
2022-01-20 17:34:13,880 iteration 4754 : loss : 0.016302, loss_ce: 0.007239
2022-01-20 17:34:15,278 iteration 4755 : loss : 0.018377, loss_ce: 0.006009
2022-01-20 17:34:16,610 iteration 4756 : loss : 0.023788, loss_ce: 0.006956
2022-01-20 17:34:17,911 iteration 4757 : loss : 0.017469, loss_ce: 0.008969
2022-01-20 17:34:19,296 iteration 4758 : loss : 0.020184, loss_ce: 0.006458
2022-01-20 17:34:20,581 iteration 4759 : loss : 0.024572, loss_ce: 0.013523
2022-01-20 17:34:20,581 Training Data Eval:
2022-01-20 17:34:27,060   Average segmentation loss on training set: 0.0121
2022-01-20 17:34:27,060 Validation Data Eval:
2022-01-20 17:34:29,255   Average segmentation loss on validation set: 0.0786
2022-01-20 17:34:30,591 iteration 4760 : loss : 0.028606, loss_ce: 0.010419
 70%|████████████████████▎        | 280/400 [1:54:19<51:09, 25.58s/it]2022-01-20 17:34:31,888 iteration 4761 : loss : 0.016571, loss_ce: 0.005409
2022-01-20 17:34:33,285 iteration 4762 : loss : 0.025633, loss_ce: 0.007501
2022-01-20 17:34:34,603 iteration 4763 : loss : 0.016824, loss_ce: 0.007296
2022-01-20 17:34:35,834 iteration 4764 : loss : 0.015454, loss_ce: 0.006298
2022-01-20 17:34:37,111 iteration 4765 : loss : 0.017613, loss_ce: 0.007410
2022-01-20 17:34:38,378 iteration 4766 : loss : 0.018533, loss_ce: 0.005317
2022-01-20 17:34:39,737 iteration 4767 : loss : 0.023465, loss_ce: 0.010861
2022-01-20 17:34:41,153 iteration 4768 : loss : 0.020464, loss_ce: 0.008539
2022-01-20 17:34:42,537 iteration 4769 : loss : 0.028493, loss_ce: 0.008526
2022-01-20 17:34:43,851 iteration 4770 : loss : 0.017188, loss_ce: 0.008587
2022-01-20 17:34:45,111 iteration 4771 : loss : 0.017839, loss_ce: 0.007756
2022-01-20 17:34:46,405 iteration 4772 : loss : 0.012421, loss_ce: 0.003665
2022-01-20 17:34:47,673 iteration 4773 : loss : 0.016568, loss_ce: 0.007212
2022-01-20 17:34:48,943 iteration 4774 : loss : 0.013166, loss_ce: 0.005340
2022-01-20 17:34:50,262 iteration 4775 : loss : 0.024684, loss_ce: 0.010409
2022-01-20 17:34:51,553 iteration 4776 : loss : 0.016225, loss_ce: 0.005713
2022-01-20 17:34:52,843 iteration 4777 : loss : 0.014655, loss_ce: 0.005041
 70%|████████████████████▎        | 281/400 [1:54:41<48:44, 24.58s/it]2022-01-20 17:34:54,275 iteration 4778 : loss : 0.022309, loss_ce: 0.008238
2022-01-20 17:34:55,529 iteration 4779 : loss : 0.015505, loss_ce: 0.005135
2022-01-20 17:34:56,786 iteration 4780 : loss : 0.021236, loss_ce: 0.005995
2022-01-20 17:34:58,054 iteration 4781 : loss : 0.012741, loss_ce: 0.005950
2022-01-20 17:34:59,412 iteration 4782 : loss : 0.017289, loss_ce: 0.006087
2022-01-20 17:35:00,641 iteration 4783 : loss : 0.017881, loss_ce: 0.006035
2022-01-20 17:35:02,013 iteration 4784 : loss : 0.018139, loss_ce: 0.007433
2022-01-20 17:35:03,408 iteration 4785 : loss : 0.023420, loss_ce: 0.010762
2022-01-20 17:35:04,688 iteration 4786 : loss : 0.023019, loss_ce: 0.009019
2022-01-20 17:35:06,027 iteration 4787 : loss : 0.033355, loss_ce: 0.008854
2022-01-20 17:35:07,328 iteration 4788 : loss : 0.019420, loss_ce: 0.008408
2022-01-20 17:35:08,646 iteration 4789 : loss : 0.014499, loss_ce: 0.005648
2022-01-20 17:35:09,944 iteration 4790 : loss : 0.016982, loss_ce: 0.006877
2022-01-20 17:35:11,204 iteration 4791 : loss : 0.013848, loss_ce: 0.005153
2022-01-20 17:35:12,491 iteration 4792 : loss : 0.024366, loss_ce: 0.012064
2022-01-20 17:35:13,825 iteration 4793 : loss : 0.019394, loss_ce: 0.010430
2022-01-20 17:35:15,120 iteration 4794 : loss : 0.025559, loss_ce: 0.005534
 70%|████████████████████▍        | 282/400 [1:55:03<46:58, 23.89s/it]2022-01-20 17:35:16,421 iteration 4795 : loss : 0.023240, loss_ce: 0.006629
2022-01-20 17:35:17,659 iteration 4796 : loss : 0.018484, loss_ce: 0.007312
2022-01-20 17:35:18,909 iteration 4797 : loss : 0.021345, loss_ce: 0.010446
2022-01-20 17:35:20,270 iteration 4798 : loss : 0.021426, loss_ce: 0.009584
2022-01-20 17:35:21,568 iteration 4799 : loss : 0.024632, loss_ce: 0.005912
2022-01-20 17:35:22,869 iteration 4800 : loss : 0.029174, loss_ce: 0.014322
2022-01-20 17:35:24,182 iteration 4801 : loss : 0.018604, loss_ce: 0.007541
2022-01-20 17:35:25,385 iteration 4802 : loss : 0.013209, loss_ce: 0.004511
2022-01-20 17:35:26,700 iteration 4803 : loss : 0.016434, loss_ce: 0.007025
2022-01-20 17:35:27,966 iteration 4804 : loss : 0.020505, loss_ce: 0.005907
2022-01-20 17:35:29,294 iteration 4805 : loss : 0.025460, loss_ce: 0.012894
2022-01-20 17:35:30,549 iteration 4806 : loss : 0.018402, loss_ce: 0.005248
2022-01-20 17:35:31,934 iteration 4807 : loss : 0.024887, loss_ce: 0.010008
2022-01-20 17:35:33,469 iteration 4808 : loss : 0.023613, loss_ce: 0.008780
2022-01-20 17:35:34,646 iteration 4809 : loss : 0.018847, loss_ce: 0.010179
2022-01-20 17:35:35,989 iteration 4810 : loss : 0.022425, loss_ce: 0.008486
2022-01-20 17:35:37,262 iteration 4811 : loss : 0.014520, loss_ce: 0.005371
 71%|████████████████████▌        | 283/400 [1:55:25<45:33, 23.37s/it]2022-01-20 17:35:38,591 iteration 4812 : loss : 0.018958, loss_ce: 0.006813
2022-01-20 17:35:39,893 iteration 4813 : loss : 0.020021, loss_ce: 0.007413
2022-01-20 17:35:41,147 iteration 4814 : loss : 0.017031, loss_ce: 0.008828
2022-01-20 17:35:42,470 iteration 4815 : loss : 0.020878, loss_ce: 0.007382
2022-01-20 17:35:43,738 iteration 4816 : loss : 0.022038, loss_ce: 0.008723
2022-01-20 17:35:44,927 iteration 4817 : loss : 0.014807, loss_ce: 0.005141
2022-01-20 17:35:46,299 iteration 4818 : loss : 0.027708, loss_ce: 0.012812
2022-01-20 17:35:47,643 iteration 4819 : loss : 0.017016, loss_ce: 0.005233
2022-01-20 17:35:49,014 iteration 4820 : loss : 0.021075, loss_ce: 0.008254
2022-01-20 17:35:50,304 iteration 4821 : loss : 0.017611, loss_ce: 0.008311
2022-01-20 17:35:51,638 iteration 4822 : loss : 0.020950, loss_ce: 0.006428
2022-01-20 17:35:52,917 iteration 4823 : loss : 0.019613, loss_ce: 0.007301
2022-01-20 17:35:54,288 iteration 4824 : loss : 0.017867, loss_ce: 0.007248
2022-01-20 17:35:55,593 iteration 4825 : loss : 0.012390, loss_ce: 0.003931
2022-01-20 17:35:56,867 iteration 4826 : loss : 0.022128, loss_ce: 0.007637
2022-01-20 17:35:58,300 iteration 4827 : loss : 0.023033, loss_ce: 0.008444
2022-01-20 17:35:59,673 iteration 4828 : loss : 0.026317, loss_ce: 0.011677
 71%|████████████████████▌        | 284/400 [1:55:48<44:37, 23.08s/it]2022-01-20 17:36:01,069 iteration 4829 : loss : 0.017967, loss_ce: 0.006849
2022-01-20 17:36:02,293 iteration 4830 : loss : 0.017980, loss_ce: 0.006282
2022-01-20 17:36:03,693 iteration 4831 : loss : 0.030764, loss_ce: 0.009878
2022-01-20 17:36:04,979 iteration 4832 : loss : 0.019891, loss_ce: 0.008798
2022-01-20 17:36:06,349 iteration 4833 : loss : 0.014557, loss_ce: 0.004305
2022-01-20 17:36:07,744 iteration 4834 : loss : 0.015647, loss_ce: 0.005362
2022-01-20 17:36:09,023 iteration 4835 : loss : 0.019879, loss_ce: 0.007725
2022-01-20 17:36:10,318 iteration 4836 : loss : 0.024560, loss_ce: 0.007309
2022-01-20 17:36:11,562 iteration 4837 : loss : 0.019583, loss_ce: 0.004211
2022-01-20 17:36:12,903 iteration 4838 : loss : 0.017619, loss_ce: 0.007156
2022-01-20 17:36:14,241 iteration 4839 : loss : 0.017347, loss_ce: 0.009031
2022-01-20 17:36:15,557 iteration 4840 : loss : 0.021594, loss_ce: 0.008230
2022-01-20 17:36:16,952 iteration 4841 : loss : 0.027389, loss_ce: 0.009871
2022-01-20 17:36:18,287 iteration 4842 : loss : 0.017297, loss_ce: 0.006966
2022-01-20 17:36:19,595 iteration 4843 : loss : 0.018395, loss_ce: 0.007908
2022-01-20 17:36:20,838 iteration 4844 : loss : 0.014515, loss_ce: 0.006674
2022-01-20 17:36:20,838 Training Data Eval:
2022-01-20 17:36:27,340   Average segmentation loss on training set: 0.0133
2022-01-20 17:36:27,341 Validation Data Eval:
2022-01-20 17:36:29,597   Average segmentation loss on validation set: 0.0642
2022-01-20 17:36:35,392 Found new lowest validation loss at iteration 4844! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed100.pth
2022-01-20 17:36:36,625 iteration 4845 : loss : 0.020793, loss_ce: 0.007353
 71%|████████████████████▋        | 285/400 [1:56:25<52:12, 27.24s/it]2022-01-20 17:36:37,965 iteration 4846 : loss : 0.015941, loss_ce: 0.005478
2022-01-20 17:36:39,187 iteration 4847 : loss : 0.023654, loss_ce: 0.007774
2022-01-20 17:36:40,563 iteration 4848 : loss : 0.027542, loss_ce: 0.011798
2022-01-20 17:36:41,800 iteration 4849 : loss : 0.016457, loss_ce: 0.007366
2022-01-20 17:36:43,092 iteration 4850 : loss : 0.048113, loss_ce: 0.012910
2022-01-20 17:36:44,376 iteration 4851 : loss : 0.015975, loss_ce: 0.007337
2022-01-20 17:36:45,597 iteration 4852 : loss : 0.018190, loss_ce: 0.007449
2022-01-20 17:36:46,813 iteration 4853 : loss : 0.018523, loss_ce: 0.007542
2022-01-20 17:36:48,021 iteration 4854 : loss : 0.014067, loss_ce: 0.005601
2022-01-20 17:36:49,357 iteration 4855 : loss : 0.014615, loss_ce: 0.005569
2022-01-20 17:36:50,728 iteration 4856 : loss : 0.019277, loss_ce: 0.007410
2022-01-20 17:36:52,113 iteration 4857 : loss : 0.020916, loss_ce: 0.011001
2022-01-20 17:36:53,439 iteration 4858 : loss : 0.021278, loss_ce: 0.009145
2022-01-20 17:36:54,690 iteration 4859 : loss : 0.012189, loss_ce: 0.004700
2022-01-20 17:36:55,977 iteration 4860 : loss : 0.020866, loss_ce: 0.005817
2022-01-20 17:36:57,217 iteration 4861 : loss : 0.020045, loss_ce: 0.005851
2022-01-20 17:36:58,620 iteration 4862 : loss : 0.020522, loss_ce: 0.006870
 72%|████████████████████▋        | 286/400 [1:56:47<48:46, 25.67s/it]2022-01-20 17:37:00,023 iteration 4863 : loss : 0.018548, loss_ce: 0.006608
2022-01-20 17:37:01,355 iteration 4864 : loss : 0.018212, loss_ce: 0.006188
2022-01-20 17:37:02,673 iteration 4865 : loss : 0.019533, loss_ce: 0.009056
2022-01-20 17:37:03,981 iteration 4866 : loss : 0.025921, loss_ce: 0.011034
2022-01-20 17:37:05,320 iteration 4867 : loss : 0.020775, loss_ce: 0.008063
2022-01-20 17:37:06,637 iteration 4868 : loss : 0.018660, loss_ce: 0.009079
2022-01-20 17:37:07,901 iteration 4869 : loss : 0.019777, loss_ce: 0.007229
2022-01-20 17:37:09,111 iteration 4870 : loss : 0.015935, loss_ce: 0.006419
2022-01-20 17:37:10,401 iteration 4871 : loss : 0.018829, loss_ce: 0.005578
2022-01-20 17:37:11,728 iteration 4872 : loss : 0.023102, loss_ce: 0.011366
2022-01-20 17:37:13,046 iteration 4873 : loss : 0.020244, loss_ce: 0.007754
2022-01-20 17:37:14,361 iteration 4874 : loss : 0.015099, loss_ce: 0.005277
2022-01-20 17:37:15,641 iteration 4875 : loss : 0.021352, loss_ce: 0.005817
2022-01-20 17:37:16,855 iteration 4876 : loss : 0.014863, loss_ce: 0.006235
2022-01-20 17:37:18,137 iteration 4877 : loss : 0.012619, loss_ce: 0.004451
2022-01-20 17:37:19,447 iteration 4878 : loss : 0.026891, loss_ce: 0.009347
2022-01-20 17:37:20,807 iteration 4879 : loss : 0.017993, loss_ce: 0.006046
 72%|████████████████████▊        | 287/400 [1:57:09<46:22, 24.62s/it]2022-01-20 17:37:22,193 iteration 4880 : loss : 0.015830, loss_ce: 0.005218
2022-01-20 17:37:23,406 iteration 4881 : loss : 0.012401, loss_ce: 0.004068
2022-01-20 17:37:24,638 iteration 4882 : loss : 0.013851, loss_ce: 0.003289
2022-01-20 17:37:25,975 iteration 4883 : loss : 0.021146, loss_ce: 0.007756
2022-01-20 17:37:27,230 iteration 4884 : loss : 0.018175, loss_ce: 0.007860
2022-01-20 17:37:28,543 iteration 4885 : loss : 0.016321, loss_ce: 0.005383
2022-01-20 17:37:29,879 iteration 4886 : loss : 0.018175, loss_ce: 0.006312
2022-01-20 17:37:31,152 iteration 4887 : loss : 0.018969, loss_ce: 0.007345
2022-01-20 17:37:32,472 iteration 4888 : loss : 0.017976, loss_ce: 0.004358
2022-01-20 17:37:33,759 iteration 4889 : loss : 0.014513, loss_ce: 0.005716
2022-01-20 17:37:35,072 iteration 4890 : loss : 0.018686, loss_ce: 0.007616
2022-01-20 17:37:36,376 iteration 4891 : loss : 0.017094, loss_ce: 0.007994
2022-01-20 17:37:37,688 iteration 4892 : loss : 0.017705, loss_ce: 0.008675
2022-01-20 17:37:39,181 iteration 4893 : loss : 0.021447, loss_ce: 0.007065
2022-01-20 17:37:40,474 iteration 4894 : loss : 0.015654, loss_ce: 0.006627
2022-01-20 17:37:41,756 iteration 4895 : loss : 0.015209, loss_ce: 0.006584
2022-01-20 17:37:43,035 iteration 4896 : loss : 0.014909, loss_ce: 0.005576
 72%|████████████████████▉        | 288/400 [1:57:31<44:37, 23.91s/it]2022-01-20 17:37:44,323 iteration 4897 : loss : 0.012752, loss_ce: 0.006040
2022-01-20 17:37:45,601 iteration 4898 : loss : 0.012046, loss_ce: 0.004318
2022-01-20 17:37:46,845 iteration 4899 : loss : 0.017838, loss_ce: 0.009975
2022-01-20 17:37:48,226 iteration 4900 : loss : 0.027915, loss_ce: 0.010930
2022-01-20 17:37:49,530 iteration 4901 : loss : 0.013000, loss_ce: 0.004017
2022-01-20 17:37:50,779 iteration 4902 : loss : 0.014563, loss_ce: 0.003198
2022-01-20 17:37:52,088 iteration 4903 : loss : 0.013881, loss_ce: 0.005451
2022-01-20 17:37:53,370 iteration 4904 : loss : 0.024726, loss_ce: 0.013615
2022-01-20 17:37:54,648 iteration 4905 : loss : 0.013059, loss_ce: 0.005657
2022-01-20 17:37:55,928 iteration 4906 : loss : 0.018952, loss_ce: 0.006686
2022-01-20 17:37:57,241 iteration 4907 : loss : 0.018148, loss_ce: 0.006251
2022-01-20 17:37:58,424 iteration 4908 : loss : 0.016416, loss_ce: 0.004305
2022-01-20 17:37:59,717 iteration 4909 : loss : 0.016921, loss_ce: 0.004851
2022-01-20 17:38:00,980 iteration 4910 : loss : 0.015908, loss_ce: 0.003665
2022-01-20 17:38:02,372 iteration 4911 : loss : 0.016902, loss_ce: 0.007202
2022-01-20 17:38:03,727 iteration 4912 : loss : 0.032821, loss_ce: 0.010377
2022-01-20 17:38:04,981 iteration 4913 : loss : 0.016178, loss_ce: 0.005782
 72%|████████████████████▉        | 289/400 [1:57:53<43:08, 23.32s/it]2022-01-20 17:38:06,264 iteration 4914 : loss : 0.015920, loss_ce: 0.004461
2022-01-20 17:38:07,598 iteration 4915 : loss : 0.017738, loss_ce: 0.006191
2022-01-20 17:38:08,935 iteration 4916 : loss : 0.027230, loss_ce: 0.007583
2022-01-20 17:38:10,236 iteration 4917 : loss : 0.023967, loss_ce: 0.010667
2022-01-20 17:38:11,508 iteration 4918 : loss : 0.014231, loss_ce: 0.006506
2022-01-20 17:38:12,777 iteration 4919 : loss : 0.016432, loss_ce: 0.006157
2022-01-20 17:38:14,122 iteration 4920 : loss : 0.018207, loss_ce: 0.008993
2022-01-20 17:38:15,407 iteration 4921 : loss : 0.012912, loss_ce: 0.002684
2022-01-20 17:38:16,701 iteration 4922 : loss : 0.015003, loss_ce: 0.002937
2022-01-20 17:38:18,009 iteration 4923 : loss : 0.019461, loss_ce: 0.007899
2022-01-20 17:38:19,344 iteration 4924 : loss : 0.023798, loss_ce: 0.010909
2022-01-20 17:38:20,791 iteration 4925 : loss : 0.026188, loss_ce: 0.011981
2022-01-20 17:38:22,051 iteration 4926 : loss : 0.018233, loss_ce: 0.006113
2022-01-20 17:38:23,417 iteration 4927 : loss : 0.013945, loss_ce: 0.005090
2022-01-20 17:38:24,789 iteration 4928 : loss : 0.023675, loss_ce: 0.012494
2022-01-20 17:38:26,146 iteration 4929 : loss : 0.032326, loss_ce: 0.010658
2022-01-20 17:38:26,146 Training Data Eval:
2022-01-20 17:38:32,622   Average segmentation loss on training set: 0.0101
2022-01-20 17:38:32,623 Validation Data Eval:
2022-01-20 17:38:34,845   Average segmentation loss on validation set: 0.0755
2022-01-20 17:38:36,167 iteration 4930 : loss : 0.012626, loss_ce: 0.005285
 72%|█████████████████████        | 290/400 [1:58:24<47:04, 25.68s/it]2022-01-20 17:38:37,577 iteration 4931 : loss : 0.019815, loss_ce: 0.010879
2022-01-20 17:38:38,827 iteration 4932 : loss : 0.014943, loss_ce: 0.005573
2022-01-20 17:38:40,063 iteration 4933 : loss : 0.018640, loss_ce: 0.006444
2022-01-20 17:38:41,372 iteration 4934 : loss : 0.016603, loss_ce: 0.007753
2022-01-20 17:38:42,709 iteration 4935 : loss : 0.018225, loss_ce: 0.005274
2022-01-20 17:38:44,020 iteration 4936 : loss : 0.013450, loss_ce: 0.005769
2022-01-20 17:38:45,346 iteration 4937 : loss : 0.016081, loss_ce: 0.005982
2022-01-20 17:38:46,650 iteration 4938 : loss : 0.022030, loss_ce: 0.006501
2022-01-20 17:38:48,012 iteration 4939 : loss : 0.018349, loss_ce: 0.007965
2022-01-20 17:38:49,254 iteration 4940 : loss : 0.020814, loss_ce: 0.006390
2022-01-20 17:38:50,539 iteration 4941 : loss : 0.015388, loss_ce: 0.006094
2022-01-20 17:38:51,888 iteration 4942 : loss : 0.017567, loss_ce: 0.006895
2022-01-20 17:38:53,142 iteration 4943 : loss : 0.011021, loss_ce: 0.003427
2022-01-20 17:38:54,440 iteration 4944 : loss : 0.018698, loss_ce: 0.008445
2022-01-20 17:38:55,837 iteration 4945 : loss : 0.016966, loss_ce: 0.004859
2022-01-20 17:38:57,190 iteration 4946 : loss : 0.029442, loss_ce: 0.017744
2022-01-20 17:38:58,601 iteration 4947 : loss : 0.022020, loss_ce: 0.007945
 73%|█████████████████████        | 291/400 [1:58:47<44:53, 24.71s/it]2022-01-20 17:39:00,036 iteration 4948 : loss : 0.020231, loss_ce: 0.007613
2022-01-20 17:39:01,302 iteration 4949 : loss : 0.015860, loss_ce: 0.006000
2022-01-20 17:39:02,552 iteration 4950 : loss : 0.017230, loss_ce: 0.006552
2022-01-20 17:39:03,841 iteration 4951 : loss : 0.019645, loss_ce: 0.006764
2022-01-20 17:39:05,058 iteration 4952 : loss : 0.016640, loss_ce: 0.006441
2022-01-20 17:39:06,422 iteration 4953 : loss : 0.015916, loss_ce: 0.006611
2022-01-20 17:39:07,664 iteration 4954 : loss : 0.022942, loss_ce: 0.010235
2022-01-20 17:39:08,948 iteration 4955 : loss : 0.013990, loss_ce: 0.005533
2022-01-20 17:39:10,246 iteration 4956 : loss : 0.020415, loss_ce: 0.006496
2022-01-20 17:39:11,569 iteration 4957 : loss : 0.012270, loss_ce: 0.005097
2022-01-20 17:39:12,907 iteration 4958 : loss : 0.017619, loss_ce: 0.007547
2022-01-20 17:39:14,148 iteration 4959 : loss : 0.013477, loss_ce: 0.004512
2022-01-20 17:39:15,497 iteration 4960 : loss : 0.016117, loss_ce: 0.005309
2022-01-20 17:39:16,784 iteration 4961 : loss : 0.016264, loss_ce: 0.006271
2022-01-20 17:39:18,163 iteration 4962 : loss : 0.015178, loss_ce: 0.006338
2022-01-20 17:39:19,416 iteration 4963 : loss : 0.015086, loss_ce: 0.006402
2022-01-20 17:39:20,827 iteration 4964 : loss : 0.016368, loss_ce: 0.006673
 73%|█████████████████████▏       | 292/400 [1:59:09<43:07, 23.96s/it]2022-01-20 17:39:22,269 iteration 4965 : loss : 0.022905, loss_ce: 0.006700
2022-01-20 17:39:23,715 iteration 4966 : loss : 0.026083, loss_ce: 0.008089
2022-01-20 17:39:24,967 iteration 4967 : loss : 0.011603, loss_ce: 0.004863
2022-01-20 17:39:26,297 iteration 4968 : loss : 0.015124, loss_ce: 0.006598
2022-01-20 17:39:27,591 iteration 4969 : loss : 0.015453, loss_ce: 0.003641
2022-01-20 17:39:28,869 iteration 4970 : loss : 0.011474, loss_ce: 0.004317
2022-01-20 17:39:30,226 iteration 4971 : loss : 0.018373, loss_ce: 0.007717
2022-01-20 17:39:31,602 iteration 4972 : loss : 0.016334, loss_ce: 0.004996
2022-01-20 17:39:32,874 iteration 4973 : loss : 0.013302, loss_ce: 0.005241
2022-01-20 17:39:34,141 iteration 4974 : loss : 0.020146, loss_ce: 0.008057
2022-01-20 17:39:35,426 iteration 4975 : loss : 0.015443, loss_ce: 0.004987
2022-01-20 17:39:36,713 iteration 4976 : loss : 0.026521, loss_ce: 0.010393
2022-01-20 17:39:38,131 iteration 4977 : loss : 0.027241, loss_ce: 0.015061
2022-01-20 17:39:39,420 iteration 4978 : loss : 0.026602, loss_ce: 0.007525
2022-01-20 17:39:40,723 iteration 4979 : loss : 0.017117, loss_ce: 0.007863
2022-01-20 17:39:41,924 iteration 4980 : loss : 0.011377, loss_ce: 0.004040
2022-01-20 17:39:43,245 iteration 4981 : loss : 0.024006, loss_ce: 0.008182
 73%|█████████████████████▏       | 293/400 [1:59:31<41:53, 23.49s/it]2022-01-20 17:39:44,602 iteration 4982 : loss : 0.021452, loss_ce: 0.009872
2022-01-20 17:39:45,856 iteration 4983 : loss : 0.011775, loss_ce: 0.004151
2022-01-20 17:39:47,226 iteration 4984 : loss : 0.020663, loss_ce: 0.008901
2022-01-20 17:39:48,550 iteration 4985 : loss : 0.015657, loss_ce: 0.005247
2022-01-20 17:39:49,948 iteration 4986 : loss : 0.019724, loss_ce: 0.008918
2022-01-20 17:39:51,216 iteration 4987 : loss : 0.014594, loss_ce: 0.006555
2022-01-20 17:39:52,504 iteration 4988 : loss : 0.017117, loss_ce: 0.007177
2022-01-20 17:39:53,792 iteration 4989 : loss : 0.016716, loss_ce: 0.005654
2022-01-20 17:39:55,203 iteration 4990 : loss : 0.021520, loss_ce: 0.007948
2022-01-20 17:39:56,515 iteration 4991 : loss : 0.014398, loss_ce: 0.003912
2022-01-20 17:39:57,821 iteration 4992 : loss : 0.016495, loss_ce: 0.007417
2022-01-20 17:39:59,186 iteration 4993 : loss : 0.019359, loss_ce: 0.008201
2022-01-20 17:40:00,578 iteration 4994 : loss : 0.016328, loss_ce: 0.004231
2022-01-20 17:40:01,881 iteration 4995 : loss : 0.020888, loss_ce: 0.007658
2022-01-20 17:40:03,179 iteration 4996 : loss : 0.018202, loss_ce: 0.006330
2022-01-20 17:40:04,561 iteration 4997 : loss : 0.020017, loss_ce: 0.007420
2022-01-20 17:40:05,797 iteration 4998 : loss : 0.014538, loss_ce: 0.005552
 74%|█████████████████████▎       | 294/400 [1:59:54<41:00, 23.22s/it]2022-01-20 17:40:07,206 iteration 4999 : loss : 0.019346, loss_ce: 0.007321
2022-01-20 17:40:08,440 iteration 5000 : loss : 0.012840, loss_ce: 0.004691
2022-01-20 17:40:09,715 iteration 5001 : loss : 0.020517, loss_ce: 0.007363
2022-01-20 17:40:11,054 iteration 5002 : loss : 0.018270, loss_ce: 0.006776
2022-01-20 17:40:12,354 iteration 5003 : loss : 0.024347, loss_ce: 0.006293
2022-01-20 17:40:13,735 iteration 5004 : loss : 0.024027, loss_ce: 0.008486
2022-01-20 17:40:15,004 iteration 5005 : loss : 0.021289, loss_ce: 0.007068
2022-01-20 17:40:16,350 iteration 5006 : loss : 0.023763, loss_ce: 0.006510
2022-01-20 17:40:17,616 iteration 5007 : loss : 0.026425, loss_ce: 0.008510
2022-01-20 17:40:18,849 iteration 5008 : loss : 0.016946, loss_ce: 0.005385
2022-01-20 17:40:20,152 iteration 5009 : loss : 0.017684, loss_ce: 0.005604
2022-01-20 17:40:21,568 iteration 5010 : loss : 0.029036, loss_ce: 0.011936
2022-01-20 17:40:22,872 iteration 5011 : loss : 0.022282, loss_ce: 0.014722
2022-01-20 17:40:24,237 iteration 5012 : loss : 0.018984, loss_ce: 0.007770
2022-01-20 17:40:25,714 iteration 5013 : loss : 0.017666, loss_ce: 0.006721
2022-01-20 17:40:26,905 iteration 5014 : loss : 0.013971, loss_ce: 0.004924
2022-01-20 17:40:26,905 Training Data Eval:
2022-01-20 17:40:33,398   Average segmentation loss on training set: 0.0105
2022-01-20 17:40:33,399 Validation Data Eval:
2022-01-20 17:40:35,612   Average segmentation loss on validation set: 0.0793
2022-01-20 17:40:36,901 iteration 5015 : loss : 0.013898, loss_ce: 0.002690
 74%|█████████████████████▍       | 295/400 [2:00:25<44:45, 25.58s/it]2022-01-20 17:40:38,221 iteration 5016 : loss : 0.025123, loss_ce: 0.009090
2022-01-20 17:40:39,500 iteration 5017 : loss : 0.015736, loss_ce: 0.004360
2022-01-20 17:40:40,987 iteration 5018 : loss : 0.019279, loss_ce: 0.007444
2022-01-20 17:40:42,241 iteration 5019 : loss : 0.023705, loss_ce: 0.009019
2022-01-20 17:40:43,583 iteration 5020 : loss : 0.015915, loss_ce: 0.007341
2022-01-20 17:40:44,979 iteration 5021 : loss : 0.021885, loss_ce: 0.006752
2022-01-20 17:40:46,343 iteration 5022 : loss : 0.028880, loss_ce: 0.014538
2022-01-20 17:40:47,669 iteration 5023 : loss : 0.016677, loss_ce: 0.006193
2022-01-20 17:40:48,942 iteration 5024 : loss : 0.013165, loss_ce: 0.004862
2022-01-20 17:40:50,218 iteration 5025 : loss : 0.015609, loss_ce: 0.005946
2022-01-20 17:40:51,554 iteration 5026 : loss : 0.020062, loss_ce: 0.008925
2022-01-20 17:40:52,861 iteration 5027 : loss : 0.013607, loss_ce: 0.004891
2022-01-20 17:40:54,178 iteration 5028 : loss : 0.021911, loss_ce: 0.007840
2022-01-20 17:40:55,434 iteration 5029 : loss : 0.015099, loss_ce: 0.006527
2022-01-20 17:40:56,758 iteration 5030 : loss : 0.021053, loss_ce: 0.007162
2022-01-20 17:40:58,143 iteration 5031 : loss : 0.020258, loss_ce: 0.008060
2022-01-20 17:40:59,535 iteration 5032 : loss : 0.019259, loss_ce: 0.007475
 74%|█████████████████████▍       | 296/400 [2:00:48<42:48, 24.70s/it]2022-01-20 17:41:00,915 iteration 5033 : loss : 0.022799, loss_ce: 0.013402
2022-01-20 17:41:02,207 iteration 5034 : loss : 0.021303, loss_ce: 0.005413
2022-01-20 17:41:03,495 iteration 5035 : loss : 0.015829, loss_ce: 0.005442
2022-01-20 17:41:04,732 iteration 5036 : loss : 0.012554, loss_ce: 0.004446
2022-01-20 17:41:06,013 iteration 5037 : loss : 0.013103, loss_ce: 0.005022
2022-01-20 17:41:07,474 iteration 5038 : loss : 0.029617, loss_ce: 0.014920
2022-01-20 17:41:08,736 iteration 5039 : loss : 0.013260, loss_ce: 0.004406
2022-01-20 17:41:10,080 iteration 5040 : loss : 0.018129, loss_ce: 0.008153
2022-01-20 17:41:11,379 iteration 5041 : loss : 0.016986, loss_ce: 0.005882
2022-01-20 17:41:12,674 iteration 5042 : loss : 0.022801, loss_ce: 0.009511
2022-01-20 17:41:13,951 iteration 5043 : loss : 0.018274, loss_ce: 0.006455
2022-01-20 17:41:15,279 iteration 5044 : loss : 0.016807, loss_ce: 0.006892
2022-01-20 17:41:16,483 iteration 5045 : loss : 0.015850, loss_ce: 0.004792
2022-01-20 17:41:17,803 iteration 5046 : loss : 0.019043, loss_ce: 0.006155
2022-01-20 17:41:19,072 iteration 5047 : loss : 0.015867, loss_ce: 0.005957
2022-01-20 17:41:20,320 iteration 5048 : loss : 0.010806, loss_ce: 0.004283
2022-01-20 17:41:21,715 iteration 5049 : loss : 0.022264, loss_ce: 0.009498
 74%|█████████████████████▌       | 297/400 [2:01:10<41:05, 23.94s/it]2022-01-20 17:41:23,063 iteration 5050 : loss : 0.020487, loss_ce: 0.005001
2022-01-20 17:41:24,290 iteration 5051 : loss : 0.017776, loss_ce: 0.008374
2022-01-20 17:41:25,627 iteration 5052 : loss : 0.018118, loss_ce: 0.008341
2022-01-20 17:41:26,868 iteration 5053 : loss : 0.013649, loss_ce: 0.004943
2022-01-20 17:41:28,204 iteration 5054 : loss : 0.013429, loss_ce: 0.005980
2022-01-20 17:41:29,467 iteration 5055 : loss : 0.012884, loss_ce: 0.004538
2022-01-20 17:41:30,734 iteration 5056 : loss : 0.019056, loss_ce: 0.006364
2022-01-20 17:41:32,021 iteration 5057 : loss : 0.014193, loss_ce: 0.006621
2022-01-20 17:41:33,294 iteration 5058 : loss : 0.017580, loss_ce: 0.006611
2022-01-20 17:41:34,592 iteration 5059 : loss : 0.016590, loss_ce: 0.007559
2022-01-20 17:41:35,957 iteration 5060 : loss : 0.025923, loss_ce: 0.006477
2022-01-20 17:41:37,262 iteration 5061 : loss : 0.013909, loss_ce: 0.006306
2022-01-20 17:41:38,637 iteration 5062 : loss : 0.019679, loss_ce: 0.007404
2022-01-20 17:41:39,898 iteration 5063 : loss : 0.012614, loss_ce: 0.004542
2022-01-20 17:41:41,217 iteration 5064 : loss : 0.022666, loss_ce: 0.005922
2022-01-20 17:41:42,606 iteration 5065 : loss : 0.033710, loss_ce: 0.010633
2022-01-20 17:41:43,793 iteration 5066 : loss : 0.014303, loss_ce: 0.006344
 74%|█████████████████████▌       | 298/400 [2:01:32<39:44, 23.38s/it]2022-01-20 17:41:45,290 iteration 5067 : loss : 0.019310, loss_ce: 0.006665
2022-01-20 17:41:46,567 iteration 5068 : loss : 0.015955, loss_ce: 0.004887
2022-01-20 17:41:47,813 iteration 5069 : loss : 0.015032, loss_ce: 0.005200
2022-01-20 17:41:49,081 iteration 5070 : loss : 0.017804, loss_ce: 0.009322
2022-01-20 17:41:50,444 iteration 5071 : loss : 0.021292, loss_ce: 0.009059
2022-01-20 17:41:51,773 iteration 5072 : loss : 0.018588, loss_ce: 0.005798
2022-01-20 17:41:53,138 iteration 5073 : loss : 0.024554, loss_ce: 0.005957
2022-01-20 17:41:54,472 iteration 5074 : loss : 0.018009, loss_ce: 0.006776
2022-01-20 17:41:55,686 iteration 5075 : loss : 0.021080, loss_ce: 0.009011
2022-01-20 17:41:56,922 iteration 5076 : loss : 0.013649, loss_ce: 0.005366
2022-01-20 17:41:58,296 iteration 5077 : loss : 0.016849, loss_ce: 0.006178
2022-01-20 17:41:59,596 iteration 5078 : loss : 0.021287, loss_ce: 0.008267
2022-01-20 17:42:00,869 iteration 5079 : loss : 0.011236, loss_ce: 0.004117
2022-01-20 17:42:02,198 iteration 5080 : loss : 0.017852, loss_ce: 0.007246
2022-01-20 17:42:03,519 iteration 5081 : loss : 0.029240, loss_ce: 0.014181
2022-01-20 17:42:04,795 iteration 5082 : loss : 0.017752, loss_ce: 0.004887
2022-01-20 17:42:06,066 iteration 5083 : loss : 0.037891, loss_ce: 0.012272
 75%|█████████████████████▋       | 299/400 [2:01:54<38:48, 23.05s/it]2022-01-20 17:42:07,442 iteration 5084 : loss : 0.019200, loss_ce: 0.008636
2022-01-20 17:42:08,848 iteration 5085 : loss : 0.020194, loss_ce: 0.007282
2022-01-20 17:42:10,067 iteration 5086 : loss : 0.012329, loss_ce: 0.003888
2022-01-20 17:42:11,389 iteration 5087 : loss : 0.016594, loss_ce: 0.004432
2022-01-20 17:42:12,613 iteration 5088 : loss : 0.010212, loss_ce: 0.004809
2022-01-20 17:42:13,887 iteration 5089 : loss : 0.016976, loss_ce: 0.006510
2022-01-20 17:42:15,234 iteration 5090 : loss : 0.021174, loss_ce: 0.009037
2022-01-20 17:42:16,562 iteration 5091 : loss : 0.022117, loss_ce: 0.007190
2022-01-20 17:42:17,855 iteration 5092 : loss : 0.032008, loss_ce: 0.007397
2022-01-20 17:42:19,165 iteration 5093 : loss : 0.014198, loss_ce: 0.005181
2022-01-20 17:42:20,486 iteration 5094 : loss : 0.016379, loss_ce: 0.005371
2022-01-20 17:42:21,816 iteration 5095 : loss : 0.018220, loss_ce: 0.009083
2022-01-20 17:42:23,197 iteration 5096 : loss : 0.017582, loss_ce: 0.004614
2022-01-20 17:42:24,543 iteration 5097 : loss : 0.025582, loss_ce: 0.016016
2022-01-20 17:42:25,828 iteration 5098 : loss : 0.020897, loss_ce: 0.009762
2022-01-20 17:42:27,176 iteration 5099 : loss : 0.018664, loss_ce: 0.008147
2022-01-20 17:42:27,176 Training Data Eval:
2022-01-20 17:42:33,648   Average segmentation loss on training set: 0.0095
2022-01-20 17:42:33,648 Validation Data Eval:
2022-01-20 17:42:35,837   Average segmentation loss on validation set: 0.0769
2022-01-20 17:42:37,118 iteration 5100 : loss : 0.015213, loss_ce: 0.004831
 75%|█████████████████████▊       | 300/400 [2:02:25<42:25, 25.45s/it]2022-01-20 17:42:38,510 iteration 5101 : loss : 0.018694, loss_ce: 0.006793
2022-01-20 17:42:39,888 iteration 5102 : loss : 0.016424, loss_ce: 0.007395
2022-01-20 17:42:41,132 iteration 5103 : loss : 0.022711, loss_ce: 0.010519
2022-01-20 17:42:42,440 iteration 5104 : loss : 0.020607, loss_ce: 0.006676
2022-01-20 17:42:43,725 iteration 5105 : loss : 0.018135, loss_ce: 0.006056
2022-01-20 17:42:45,037 iteration 5106 : loss : 0.031720, loss_ce: 0.014027
2022-01-20 17:42:46,360 iteration 5107 : loss : 0.022420, loss_ce: 0.008251
2022-01-20 17:42:47,701 iteration 5108 : loss : 0.020392, loss_ce: 0.008680
2022-01-20 17:42:49,002 iteration 5109 : loss : 0.015619, loss_ce: 0.006806
2022-01-20 17:42:50,212 iteration 5110 : loss : 0.011816, loss_ce: 0.004616
2022-01-20 17:42:51,560 iteration 5111 : loss : 0.017110, loss_ce: 0.005130
2022-01-20 17:42:52,805 iteration 5112 : loss : 0.013153, loss_ce: 0.006025
2022-01-20 17:42:54,187 iteration 5113 : loss : 0.030904, loss_ce: 0.014585
2022-01-20 17:42:55,420 iteration 5114 : loss : 0.013254, loss_ce: 0.005096
2022-01-20 17:42:56,672 iteration 5115 : loss : 0.018285, loss_ce: 0.010203
2022-01-20 17:42:57,983 iteration 5116 : loss : 0.019055, loss_ce: 0.007745
2022-01-20 17:42:59,306 iteration 5117 : loss : 0.015403, loss_ce: 0.005711
 75%|█████████████████████▊       | 301/400 [2:02:47<40:22, 24.47s/it]2022-01-20 17:43:00,693 iteration 5118 : loss : 0.016851, loss_ce: 0.006711
2022-01-20 17:43:02,000 iteration 5119 : loss : 0.020325, loss_ce: 0.007285
2022-01-20 17:43:03,391 iteration 5120 : loss : 0.020551, loss_ce: 0.006676
2022-01-20 17:43:04,631 iteration 5121 : loss : 0.016534, loss_ce: 0.006562
2022-01-20 17:43:05,894 iteration 5122 : loss : 0.015058, loss_ce: 0.004514
2022-01-20 17:43:07,191 iteration 5123 : loss : 0.019413, loss_ce: 0.011733
2022-01-20 17:43:08,462 iteration 5124 : loss : 0.018432, loss_ce: 0.004408
2022-01-20 17:43:09,785 iteration 5125 : loss : 0.014255, loss_ce: 0.005272
2022-01-20 17:43:11,052 iteration 5126 : loss : 0.013719, loss_ce: 0.005469
2022-01-20 17:43:12,376 iteration 5127 : loss : 0.030449, loss_ce: 0.010589
2022-01-20 17:43:13,794 iteration 5128 : loss : 0.023279, loss_ce: 0.007139
2022-01-20 17:43:15,169 iteration 5129 : loss : 0.017510, loss_ce: 0.006529
2022-01-20 17:43:16,399 iteration 5130 : loss : 0.012862, loss_ce: 0.005294
2022-01-20 17:43:17,752 iteration 5131 : loss : 0.015225, loss_ce: 0.004135
2022-01-20 17:43:19,082 iteration 5132 : loss : 0.013737, loss_ce: 0.005981
2022-01-20 17:43:20,354 iteration 5133 : loss : 0.015769, loss_ce: 0.006876
2022-01-20 17:43:21,629 iteration 5134 : loss : 0.009769, loss_ce: 0.003385
 76%|█████████████████████▉       | 302/400 [2:03:10<38:55, 23.83s/it]2022-01-20 17:43:23,014 iteration 5135 : loss : 0.014162, loss_ce: 0.005059
2022-01-20 17:43:24,433 iteration 5136 : loss : 0.020206, loss_ce: 0.008031
2022-01-20 17:43:25,841 iteration 5137 : loss : 0.020528, loss_ce: 0.006252
2022-01-20 17:43:27,263 iteration 5138 : loss : 0.038157, loss_ce: 0.020997
2022-01-20 17:43:28,503 iteration 5139 : loss : 0.019480, loss_ce: 0.006153
2022-01-20 17:43:29,885 iteration 5140 : loss : 0.024700, loss_ce: 0.011387
2022-01-20 17:43:31,140 iteration 5141 : loss : 0.014263, loss_ce: 0.007180
2022-01-20 17:43:32,572 iteration 5142 : loss : 0.026916, loss_ce: 0.010755
2022-01-20 17:43:33,815 iteration 5143 : loss : 0.012572, loss_ce: 0.004537
2022-01-20 17:43:35,054 iteration 5144 : loss : 0.014101, loss_ce: 0.006451
2022-01-20 17:43:36,395 iteration 5145 : loss : 0.017403, loss_ce: 0.006517
2022-01-20 17:43:37,854 iteration 5146 : loss : 0.028274, loss_ce: 0.007459
2022-01-20 17:43:39,157 iteration 5147 : loss : 0.013461, loss_ce: 0.006228
2022-01-20 17:43:40,490 iteration 5148 : loss : 0.016598, loss_ce: 0.006197
2022-01-20 17:43:41,747 iteration 5149 : loss : 0.014995, loss_ce: 0.005292
2022-01-20 17:43:43,043 iteration 5150 : loss : 0.016971, loss_ce: 0.007470
2022-01-20 17:43:44,290 iteration 5151 : loss : 0.017104, loss_ce: 0.006101
 76%|█████████████████████▉       | 303/400 [2:03:32<37:57, 23.48s/it]2022-01-20 17:43:45,711 iteration 5152 : loss : 0.019842, loss_ce: 0.005030
2022-01-20 17:43:46,938 iteration 5153 : loss : 0.012500, loss_ce: 0.006221
2022-01-20 17:43:48,296 iteration 5154 : loss : 0.021320, loss_ce: 0.008117
2022-01-20 17:43:49,513 iteration 5155 : loss : 0.010761, loss_ce: 0.003767
2022-01-20 17:43:50,781 iteration 5156 : loss : 0.038055, loss_ce: 0.016483
2022-01-20 17:43:52,150 iteration 5157 : loss : 0.014104, loss_ce: 0.005485
2022-01-20 17:43:53,467 iteration 5158 : loss : 0.016260, loss_ce: 0.005726
2022-01-20 17:43:54,827 iteration 5159 : loss : 0.037460, loss_ce: 0.011535
2022-01-20 17:43:56,201 iteration 5160 : loss : 0.016678, loss_ce: 0.007966
2022-01-20 17:43:57,570 iteration 5161 : loss : 0.018922, loss_ce: 0.008648
2022-01-20 17:43:58,838 iteration 5162 : loss : 0.014895, loss_ce: 0.004344
2022-01-20 17:44:00,141 iteration 5163 : loss : 0.019862, loss_ce: 0.007012
2022-01-20 17:44:01,382 iteration 5164 : loss : 0.015755, loss_ce: 0.009094
2022-01-20 17:44:02,695 iteration 5165 : loss : 0.016288, loss_ce: 0.004498
2022-01-20 17:44:04,025 iteration 5166 : loss : 0.018390, loss_ce: 0.008504
2022-01-20 17:44:05,280 iteration 5167 : loss : 0.012169, loss_ce: 0.005244
2022-01-20 17:44:06,651 iteration 5168 : loss : 0.020614, loss_ce: 0.008377
 76%|██████████████████████       | 304/400 [2:03:55<37:01, 23.14s/it]2022-01-20 17:44:07,966 iteration 5169 : loss : 0.015849, loss_ce: 0.006320
2022-01-20 17:44:09,272 iteration 5170 : loss : 0.015545, loss_ce: 0.007523
2022-01-20 17:44:10,542 iteration 5171 : loss : 0.018357, loss_ce: 0.005017
2022-01-20 17:44:11,870 iteration 5172 : loss : 0.016449, loss_ce: 0.006252
2022-01-20 17:44:13,146 iteration 5173 : loss : 0.017516, loss_ce: 0.009431
2022-01-20 17:44:14,499 iteration 5174 : loss : 0.021556, loss_ce: 0.009755
2022-01-20 17:44:15,884 iteration 5175 : loss : 0.030942, loss_ce: 0.011352
2022-01-20 17:44:17,174 iteration 5176 : loss : 0.019678, loss_ce: 0.006014
2022-01-20 17:44:18,603 iteration 5177 : loss : 0.030478, loss_ce: 0.013934
2022-01-20 17:44:19,885 iteration 5178 : loss : 0.014600, loss_ce: 0.003092
2022-01-20 17:44:21,255 iteration 5179 : loss : 0.019530, loss_ce: 0.008524
2022-01-20 17:44:22,568 iteration 5180 : loss : 0.018233, loss_ce: 0.007694
2022-01-20 17:44:23,923 iteration 5181 : loss : 0.022433, loss_ce: 0.009541
2022-01-20 17:44:25,289 iteration 5182 : loss : 0.022983, loss_ce: 0.008036
2022-01-20 17:44:26,646 iteration 5183 : loss : 0.016851, loss_ce: 0.005817
2022-01-20 17:44:28,057 iteration 5184 : loss : 0.017384, loss_ce: 0.008995
2022-01-20 17:44:28,057 Training Data Eval:
2022-01-20 17:44:34,533   Average segmentation loss on training set: 0.0102
2022-01-20 17:44:34,534 Validation Data Eval:
2022-01-20 17:44:36,752   Average segmentation loss on validation set: 0.0684
2022-01-20 17:44:38,080 iteration 5185 : loss : 0.021459, loss_ce: 0.011019
 76%|██████████████████████       | 305/400 [2:04:26<40:34, 25.63s/it]2022-01-20 17:44:39,457 iteration 5186 : loss : 0.020019, loss_ce: 0.008943
2022-01-20 17:44:40,821 iteration 5187 : loss : 0.015174, loss_ce: 0.006132
2022-01-20 17:44:42,064 iteration 5188 : loss : 0.014055, loss_ce: 0.004354
2022-01-20 17:44:43,394 iteration 5189 : loss : 0.014067, loss_ce: 0.006020
2022-01-20 17:44:44,669 iteration 5190 : loss : 0.015961, loss_ce: 0.006595
2022-01-20 17:44:45,932 iteration 5191 : loss : 0.016358, loss_ce: 0.006299
2022-01-20 17:44:47,291 iteration 5192 : loss : 0.018227, loss_ce: 0.008250
2022-01-20 17:44:48,625 iteration 5193 : loss : 0.023674, loss_ce: 0.011668
2022-01-20 17:44:49,940 iteration 5194 : loss : 0.016707, loss_ce: 0.006583
2022-01-20 17:44:51,267 iteration 5195 : loss : 0.016725, loss_ce: 0.005034
2022-01-20 17:44:52,708 iteration 5196 : loss : 0.024084, loss_ce: 0.006927
2022-01-20 17:44:53,901 iteration 5197 : loss : 0.016881, loss_ce: 0.004871
2022-01-20 17:44:55,265 iteration 5198 : loss : 0.024863, loss_ce: 0.009758
2022-01-20 17:44:56,626 iteration 5199 : loss : 0.019154, loss_ce: 0.006868
2022-01-20 17:44:57,961 iteration 5200 : loss : 0.013441, loss_ce: 0.004098
2022-01-20 17:44:59,240 iteration 5201 : loss : 0.014779, loss_ce: 0.004136
2022-01-20 17:45:00,559 iteration 5202 : loss : 0.021235, loss_ce: 0.008214
 76%|██████████████████████▏      | 306/400 [2:04:49<38:40, 24.69s/it]2022-01-20 17:45:01,828 iteration 5203 : loss : 0.014463, loss_ce: 0.004195
2022-01-20 17:45:03,186 iteration 5204 : loss : 0.017536, loss_ce: 0.007273
2022-01-20 17:45:04,514 iteration 5205 : loss : 0.017490, loss_ce: 0.005936
2022-01-20 17:45:05,765 iteration 5206 : loss : 0.012528, loss_ce: 0.005394
2022-01-20 17:45:07,071 iteration 5207 : loss : 0.012893, loss_ce: 0.005304
2022-01-20 17:45:08,470 iteration 5208 : loss : 0.018536, loss_ce: 0.006391
2022-01-20 17:45:09,790 iteration 5209 : loss : 0.018224, loss_ce: 0.006873
2022-01-20 17:45:11,073 iteration 5210 : loss : 0.014841, loss_ce: 0.005514
2022-01-20 17:45:12,339 iteration 5211 : loss : 0.015663, loss_ce: 0.004042
2022-01-20 17:45:13,666 iteration 5212 : loss : 0.017190, loss_ce: 0.005244
2022-01-20 17:45:15,007 iteration 5213 : loss : 0.029722, loss_ce: 0.009561
2022-01-20 17:45:16,295 iteration 5214 : loss : 0.015286, loss_ce: 0.008814
2022-01-20 17:45:17,570 iteration 5215 : loss : 0.023031, loss_ce: 0.008969
2022-01-20 17:45:18,851 iteration 5216 : loss : 0.020358, loss_ce: 0.008033
2022-01-20 17:45:20,130 iteration 5217 : loss : 0.012104, loss_ce: 0.004055
2022-01-20 17:45:21,415 iteration 5218 : loss : 0.015997, loss_ce: 0.005190
2022-01-20 17:45:22,746 iteration 5219 : loss : 0.018660, loss_ce: 0.008257
 77%|██████████████████████▎      | 307/400 [2:05:11<37:05, 23.93s/it]2022-01-20 17:45:24,217 iteration 5220 : loss : 0.022238, loss_ce: 0.007739
2022-01-20 17:45:25,484 iteration 5221 : loss : 0.015627, loss_ce: 0.007659
2022-01-20 17:45:26,690 iteration 5222 : loss : 0.019348, loss_ce: 0.003904
2022-01-20 17:45:27,980 iteration 5223 : loss : 0.014746, loss_ce: 0.005622
2022-01-20 17:45:29,365 iteration 5224 : loss : 0.025976, loss_ce: 0.010382
2022-01-20 17:45:30,593 iteration 5225 : loss : 0.013949, loss_ce: 0.004016
2022-01-20 17:45:32,044 iteration 5226 : loss : 0.018049, loss_ce: 0.007493
2022-01-20 17:45:33,242 iteration 5227 : loss : 0.013601, loss_ce: 0.004857
2022-01-20 17:45:34,469 iteration 5228 : loss : 0.011078, loss_ce: 0.004699
2022-01-20 17:45:35,744 iteration 5229 : loss : 0.016220, loss_ce: 0.006753
2022-01-20 17:45:37,083 iteration 5230 : loss : 0.018105, loss_ce: 0.008899
2022-01-20 17:45:38,414 iteration 5231 : loss : 0.037110, loss_ce: 0.012324
2022-01-20 17:45:39,669 iteration 5232 : loss : 0.015804, loss_ce: 0.006661
2022-01-20 17:45:41,011 iteration 5233 : loss : 0.022317, loss_ce: 0.008374
2022-01-20 17:45:42,218 iteration 5234 : loss : 0.011946, loss_ce: 0.004215
2022-01-20 17:45:43,630 iteration 5235 : loss : 0.021459, loss_ce: 0.007607
2022-01-20 17:45:44,918 iteration 5236 : loss : 0.019015, loss_ce: 0.007318
 77%|██████████████████████▎      | 308/400 [2:05:33<35:53, 23.40s/it]2022-01-20 17:45:46,318 iteration 5237 : loss : 0.024875, loss_ce: 0.010697
2022-01-20 17:45:47,630 iteration 5238 : loss : 0.014797, loss_ce: 0.007120
2022-01-20 17:45:48,946 iteration 5239 : loss : 0.012674, loss_ce: 0.003852
2022-01-20 17:45:50,353 iteration 5240 : loss : 0.017433, loss_ce: 0.006003
2022-01-20 17:45:51,702 iteration 5241 : loss : 0.023032, loss_ce: 0.011669
2022-01-20 17:45:53,046 iteration 5242 : loss : 0.025105, loss_ce: 0.010937
2022-01-20 17:45:54,377 iteration 5243 : loss : 0.016043, loss_ce: 0.005245
2022-01-20 17:45:55,720 iteration 5244 : loss : 0.019004, loss_ce: 0.006910
2022-01-20 17:45:57,049 iteration 5245 : loss : 0.017416, loss_ce: 0.005967
2022-01-20 17:45:58,249 iteration 5246 : loss : 0.011217, loss_ce: 0.005326
2022-01-20 17:45:59,567 iteration 5247 : loss : 0.013689, loss_ce: 0.004679
2022-01-20 17:46:00,922 iteration 5248 : loss : 0.016420, loss_ce: 0.006473
2022-01-20 17:46:02,210 iteration 5249 : loss : 0.018900, loss_ce: 0.008717
2022-01-20 17:46:03,503 iteration 5250 : loss : 0.017200, loss_ce: 0.007983
2022-01-20 17:46:04,871 iteration 5251 : loss : 0.012782, loss_ce: 0.004469
2022-01-20 17:46:06,154 iteration 5252 : loss : 0.017256, loss_ce: 0.005438
2022-01-20 17:46:07,491 iteration 5253 : loss : 0.011393, loss_ce: 0.004605
 77%|██████████████████████▍      | 309/400 [2:05:56<35:07, 23.16s/it]2022-01-20 17:46:08,777 iteration 5254 : loss : 0.012748, loss_ce: 0.004695
2022-01-20 17:46:10,133 iteration 5255 : loss : 0.017455, loss_ce: 0.005405
2022-01-20 17:46:11,454 iteration 5256 : loss : 0.011860, loss_ce: 0.004479
2022-01-20 17:46:12,841 iteration 5257 : loss : 0.033816, loss_ce: 0.010850
2022-01-20 17:46:14,082 iteration 5258 : loss : 0.021047, loss_ce: 0.008772
2022-01-20 17:46:15,407 iteration 5259 : loss : 0.022382, loss_ce: 0.007332
2022-01-20 17:46:16,680 iteration 5260 : loss : 0.032206, loss_ce: 0.011358
2022-01-20 17:46:17,981 iteration 5261 : loss : 0.018297, loss_ce: 0.007632
2022-01-20 17:46:19,216 iteration 5262 : loss : 0.010047, loss_ce: 0.004643
2022-01-20 17:46:20,530 iteration 5263 : loss : 0.018162, loss_ce: 0.006892
2022-01-20 17:46:21,811 iteration 5264 : loss : 0.015579, loss_ce: 0.005453
2022-01-20 17:46:23,037 iteration 5265 : loss : 0.012386, loss_ce: 0.004511
2022-01-20 17:46:24,354 iteration 5266 : loss : 0.021671, loss_ce: 0.008613
2022-01-20 17:46:25,591 iteration 5267 : loss : 0.014561, loss_ce: 0.005392
2022-01-20 17:46:26,961 iteration 5268 : loss : 0.018278, loss_ce: 0.007364
2022-01-20 17:46:28,345 iteration 5269 : loss : 0.019183, loss_ce: 0.008463
2022-01-20 17:46:28,345 Training Data Eval:
2022-01-20 17:46:34,905   Average segmentation loss on training set: 0.0096
2022-01-20 17:46:34,906 Validation Data Eval:
2022-01-20 17:46:37,137   Average segmentation loss on validation set: 0.0810
2022-01-20 17:46:38,518 iteration 5270 : loss : 0.039033, loss_ce: 0.021415
 78%|██████████████████████▍      | 310/400 [2:06:27<38:16, 25.51s/it]2022-01-20 17:46:39,937 iteration 5271 : loss : 0.017144, loss_ce: 0.007681
2022-01-20 17:46:41,253 iteration 5272 : loss : 0.019981, loss_ce: 0.007177
2022-01-20 17:46:42,557 iteration 5273 : loss : 0.021104, loss_ce: 0.008073
2022-01-20 17:46:43,811 iteration 5274 : loss : 0.015019, loss_ce: 0.004846
2022-01-20 17:46:45,155 iteration 5275 : loss : 0.024013, loss_ce: 0.007867
2022-01-20 17:46:46,504 iteration 5276 : loss : 0.013986, loss_ce: 0.004838
2022-01-20 17:46:47,753 iteration 5277 : loss : 0.016125, loss_ce: 0.004825
2022-01-20 17:46:49,236 iteration 5278 : loss : 0.016581, loss_ce: 0.006588
2022-01-20 17:46:50,538 iteration 5279 : loss : 0.018418, loss_ce: 0.005471
2022-01-20 17:46:51,923 iteration 5280 : loss : 0.018806, loss_ce: 0.006641
2022-01-20 17:46:53,233 iteration 5281 : loss : 0.015730, loss_ce: 0.007673
2022-01-20 17:46:54,580 iteration 5282 : loss : 0.017239, loss_ce: 0.005903
2022-01-20 17:46:55,896 iteration 5283 : loss : 0.015352, loss_ce: 0.004561
2022-01-20 17:46:57,238 iteration 5284 : loss : 0.015290, loss_ce: 0.007331
2022-01-20 17:46:58,571 iteration 5285 : loss : 0.017948, loss_ce: 0.008130
2022-01-20 17:46:59,939 iteration 5286 : loss : 0.013349, loss_ce: 0.005086
2022-01-20 17:47:01,361 iteration 5287 : loss : 0.020289, loss_ce: 0.009231
 78%|██████████████████████▌      | 311/400 [2:06:49<36:39, 24.72s/it]2022-01-20 17:47:02,664 iteration 5288 : loss : 0.017059, loss_ce: 0.006204
2022-01-20 17:47:03,982 iteration 5289 : loss : 0.021500, loss_ce: 0.006843
2022-01-20 17:47:05,345 iteration 5290 : loss : 0.017011, loss_ce: 0.007266
2022-01-20 17:47:06,714 iteration 5291 : loss : 0.017624, loss_ce: 0.007431
2022-01-20 17:47:08,061 iteration 5292 : loss : 0.013868, loss_ce: 0.005530
2022-01-20 17:47:09,341 iteration 5293 : loss : 0.015462, loss_ce: 0.004855
2022-01-20 17:47:10,730 iteration 5294 : loss : 0.021630, loss_ce: 0.009600
2022-01-20 17:47:11,994 iteration 5295 : loss : 0.011132, loss_ce: 0.004283
2022-01-20 17:47:13,316 iteration 5296 : loss : 0.019647, loss_ce: 0.006155
2022-01-20 17:47:14,734 iteration 5297 : loss : 0.020151, loss_ce: 0.007050
2022-01-20 17:47:16,003 iteration 5298 : loss : 0.013658, loss_ce: 0.006177
2022-01-20 17:47:17,414 iteration 5299 : loss : 0.020307, loss_ce: 0.009266
2022-01-20 17:47:18,662 iteration 5300 : loss : 0.014588, loss_ce: 0.005497
2022-01-20 17:47:20,026 iteration 5301 : loss : 0.025426, loss_ce: 0.009716
2022-01-20 17:47:21,350 iteration 5302 : loss : 0.013176, loss_ce: 0.005966
2022-01-20 17:47:22,599 iteration 5303 : loss : 0.012436, loss_ce: 0.004413
2022-01-20 17:47:24,022 iteration 5304 : loss : 0.020256, loss_ce: 0.007753
 78%|██████████████████████▌      | 312/400 [2:07:12<35:20, 24.10s/it]2022-01-20 17:47:25,448 iteration 5305 : loss : 0.018188, loss_ce: 0.006061
2022-01-20 17:47:26,829 iteration 5306 : loss : 0.026873, loss_ce: 0.009444
2022-01-20 17:47:28,183 iteration 5307 : loss : 0.012596, loss_ce: 0.004812
2022-01-20 17:47:29,585 iteration 5308 : loss : 0.016165, loss_ce: 0.006152
2022-01-20 17:47:30,926 iteration 5309 : loss : 0.014455, loss_ce: 0.006028
2022-01-20 17:47:32,272 iteration 5310 : loss : 0.013164, loss_ce: 0.005637
2022-01-20 17:47:33,645 iteration 5311 : loss : 0.016153, loss_ce: 0.006152
2022-01-20 17:47:35,016 iteration 5312 : loss : 0.012829, loss_ce: 0.003954
2022-01-20 17:47:36,426 iteration 5313 : loss : 0.024525, loss_ce: 0.005862
2022-01-20 17:47:37,743 iteration 5314 : loss : 0.014026, loss_ce: 0.006007
2022-01-20 17:47:39,154 iteration 5315 : loss : 0.017114, loss_ce: 0.007049
2022-01-20 17:47:40,393 iteration 5316 : loss : 0.011226, loss_ce: 0.005012
2022-01-20 17:47:41,773 iteration 5317 : loss : 0.019091, loss_ce: 0.007952
2022-01-20 17:47:43,183 iteration 5318 : loss : 0.019893, loss_ce: 0.006997
2022-01-20 17:47:44,583 iteration 5319 : loss : 0.027772, loss_ce: 0.009545
2022-01-20 17:47:45,975 iteration 5320 : loss : 0.023280, loss_ce: 0.010066
2022-01-20 17:47:47,247 iteration 5321 : loss : 0.021171, loss_ce: 0.004117
 78%|██████████████████████▋      | 313/400 [2:07:35<34:33, 23.84s/it]2022-01-20 17:47:48,715 iteration 5322 : loss : 0.022114, loss_ce: 0.011003
2022-01-20 17:47:50,128 iteration 5323 : loss : 0.017810, loss_ce: 0.006079
2022-01-20 17:47:51,459 iteration 5324 : loss : 0.012812, loss_ce: 0.006004
2022-01-20 17:47:52,793 iteration 5325 : loss : 0.017375, loss_ce: 0.006926
2022-01-20 17:47:54,217 iteration 5326 : loss : 0.025047, loss_ce: 0.007430
2022-01-20 17:47:55,572 iteration 5327 : loss : 0.021903, loss_ce: 0.007928
2022-01-20 17:47:56,895 iteration 5328 : loss : 0.014421, loss_ce: 0.005807
2022-01-20 17:47:58,243 iteration 5329 : loss : 0.015050, loss_ce: 0.005700
2022-01-20 17:47:59,589 iteration 5330 : loss : 0.024833, loss_ce: 0.008839
2022-01-20 17:48:00,869 iteration 5331 : loss : 0.014107, loss_ce: 0.005477
2022-01-20 17:48:02,413 iteration 5332 : loss : 0.029336, loss_ce: 0.013532
2022-01-20 17:48:03,722 iteration 5333 : loss : 0.018154, loss_ce: 0.006065
2022-01-20 17:48:04,936 iteration 5334 : loss : 0.013199, loss_ce: 0.003926
2022-01-20 17:48:06,276 iteration 5335 : loss : 0.017392, loss_ce: 0.005436
2022-01-20 17:48:07,583 iteration 5336 : loss : 0.018275, loss_ce: 0.007101
2022-01-20 17:48:08,900 iteration 5337 : loss : 0.017825, loss_ce: 0.007826
2022-01-20 17:48:10,237 iteration 5338 : loss : 0.021396, loss_ce: 0.008855
 78%|██████████████████████▊      | 314/400 [2:07:58<33:48, 23.58s/it]2022-01-20 17:48:11,587 iteration 5339 : loss : 0.014534, loss_ce: 0.005506
2022-01-20 17:48:12,854 iteration 5340 : loss : 0.014095, loss_ce: 0.005423
2022-01-20 17:48:14,237 iteration 5341 : loss : 0.015390, loss_ce: 0.003797
2022-01-20 17:48:15,593 iteration 5342 : loss : 0.016645, loss_ce: 0.005735
2022-01-20 17:48:16,929 iteration 5343 : loss : 0.017605, loss_ce: 0.005885
2022-01-20 17:48:18,190 iteration 5344 : loss : 0.013492, loss_ce: 0.005603
2022-01-20 17:48:19,476 iteration 5345 : loss : 0.016653, loss_ce: 0.007692
2022-01-20 17:48:20,770 iteration 5346 : loss : 0.016541, loss_ce: 0.006322
2022-01-20 17:48:22,126 iteration 5347 : loss : 0.013587, loss_ce: 0.005384
2022-01-20 17:48:23,412 iteration 5348 : loss : 0.024300, loss_ce: 0.007610
2022-01-20 17:48:24,726 iteration 5349 : loss : 0.015587, loss_ce: 0.005520
2022-01-20 17:48:26,064 iteration 5350 : loss : 0.018792, loss_ce: 0.005761
2022-01-20 17:48:27,355 iteration 5351 : loss : 0.011666, loss_ce: 0.004342
2022-01-20 17:48:28,779 iteration 5352 : loss : 0.016209, loss_ce: 0.006613
2022-01-20 17:48:30,132 iteration 5353 : loss : 0.014473, loss_ce: 0.005933
2022-01-20 17:48:31,416 iteration 5354 : loss : 0.013262, loss_ce: 0.005381
2022-01-20 17:48:31,416 Training Data Eval:
2022-01-20 17:48:38,078   Average segmentation loss on training set: 0.0091
2022-01-20 17:48:38,078 Validation Data Eval:
2022-01-20 17:48:40,342   Average segmentation loss on validation set: 0.0778
2022-01-20 17:48:41,676 iteration 5355 : loss : 0.018233, loss_ce: 0.008374
 79%|██████████████████████▊      | 315/400 [2:08:30<36:44, 25.94s/it]2022-01-20 17:48:43,113 iteration 5356 : loss : 0.018363, loss_ce: 0.008193
2022-01-20 17:48:44,396 iteration 5357 : loss : 0.009734, loss_ce: 0.003812
2022-01-20 17:48:45,676 iteration 5358 : loss : 0.014432, loss_ce: 0.005883
2022-01-20 17:48:46,961 iteration 5359 : loss : 0.012590, loss_ce: 0.003948
2022-01-20 17:48:48,360 iteration 5360 : loss : 0.015899, loss_ce: 0.005693
2022-01-20 17:48:49,677 iteration 5361 : loss : 0.014601, loss_ce: 0.006348
2022-01-20 17:48:51,040 iteration 5362 : loss : 0.012963, loss_ce: 0.004637
2022-01-20 17:48:52,556 iteration 5363 : loss : 0.022879, loss_ce: 0.008814
2022-01-20 17:48:53,889 iteration 5364 : loss : 0.021166, loss_ce: 0.005246
2022-01-20 17:48:55,262 iteration 5365 : loss : 0.017929, loss_ce: 0.005389
2022-01-20 17:48:56,578 iteration 5366 : loss : 0.014979, loss_ce: 0.005228
2022-01-20 17:48:57,831 iteration 5367 : loss : 0.020288, loss_ce: 0.007774
2022-01-20 17:48:59,309 iteration 5368 : loss : 0.021007, loss_ce: 0.006892
2022-01-20 17:49:00,636 iteration 5369 : loss : 0.010759, loss_ce: 0.004054
2022-01-20 17:49:01,965 iteration 5370 : loss : 0.012936, loss_ce: 0.005599
2022-01-20 17:49:03,317 iteration 5371 : loss : 0.016200, loss_ce: 0.004555
2022-01-20 17:49:04,583 iteration 5372 : loss : 0.011137, loss_ce: 0.004286
 79%|██████████████████████▉      | 316/400 [2:08:53<35:02, 25.03s/it]2022-01-20 17:49:05,971 iteration 5373 : loss : 0.015445, loss_ce: 0.005767
2022-01-20 17:49:07,266 iteration 5374 : loss : 0.041536, loss_ce: 0.010368
2022-01-20 17:49:08,615 iteration 5375 : loss : 0.017348, loss_ce: 0.006124
2022-01-20 17:49:09,968 iteration 5376 : loss : 0.014914, loss_ce: 0.005100
2022-01-20 17:49:11,322 iteration 5377 : loss : 0.032888, loss_ce: 0.007915
2022-01-20 17:49:12,672 iteration 5378 : loss : 0.017755, loss_ce: 0.005571
2022-01-20 17:49:13,978 iteration 5379 : loss : 0.012714, loss_ce: 0.005131
2022-01-20 17:49:15,233 iteration 5380 : loss : 0.013637, loss_ce: 0.006180
2022-01-20 17:49:16,648 iteration 5381 : loss : 0.016858, loss_ce: 0.007013
2022-01-20 17:49:17,964 iteration 5382 : loss : 0.024892, loss_ce: 0.009390
2022-01-20 17:49:19,258 iteration 5383 : loss : 0.019827, loss_ce: 0.009515
2022-01-20 17:49:20,540 iteration 5384 : loss : 0.015690, loss_ce: 0.006691
2022-01-20 17:49:21,873 iteration 5385 : loss : 0.039445, loss_ce: 0.016806
2022-01-20 17:49:23,152 iteration 5386 : loss : 0.015052, loss_ce: 0.005732
2022-01-20 17:49:24,564 iteration 5387 : loss : 0.019692, loss_ce: 0.006795
2022-01-20 17:49:25,886 iteration 5388 : loss : 0.013465, loss_ce: 0.004263
2022-01-20 17:49:27,259 iteration 5389 : loss : 0.019228, loss_ce: 0.007910
 79%|██████████████████████▉      | 317/400 [2:09:15<33:38, 24.32s/it]2022-01-20 17:49:28,579 iteration 5390 : loss : 0.013160, loss_ce: 0.004222
2022-01-20 17:49:29,971 iteration 5391 : loss : 0.026329, loss_ce: 0.010023
2022-01-20 17:49:31,260 iteration 5392 : loss : 0.024191, loss_ce: 0.006930
2022-01-20 17:49:32,518 iteration 5393 : loss : 0.015137, loss_ce: 0.005119
2022-01-20 17:49:33,816 iteration 5394 : loss : 0.014851, loss_ce: 0.004677
2022-01-20 17:49:35,111 iteration 5395 : loss : 0.027796, loss_ce: 0.009669
2022-01-20 17:49:36,377 iteration 5396 : loss : 0.019784, loss_ce: 0.008411
2022-01-20 17:49:37,730 iteration 5397 : loss : 0.019705, loss_ce: 0.007822
2022-01-20 17:49:39,203 iteration 5398 : loss : 0.034816, loss_ce: 0.011270
2022-01-20 17:49:40,553 iteration 5399 : loss : 0.021253, loss_ce: 0.007187
2022-01-20 17:49:41,820 iteration 5400 : loss : 0.022165, loss_ce: 0.009583
2022-01-20 17:49:43,159 iteration 5401 : loss : 0.023057, loss_ce: 0.013077
2022-01-20 17:49:44,432 iteration 5402 : loss : 0.013990, loss_ce: 0.007063
2022-01-20 17:49:45,734 iteration 5403 : loss : 0.018541, loss_ce: 0.009270
2022-01-20 17:49:47,079 iteration 5404 : loss : 0.012542, loss_ce: 0.005362
2022-01-20 17:49:48,513 iteration 5405 : loss : 0.020246, loss_ce: 0.007212
2022-01-20 17:49:49,751 iteration 5406 : loss : 0.013286, loss_ce: 0.006292
 80%|███████████████████████      | 318/400 [2:09:38<32:29, 23.77s/it]2022-01-20 17:49:51,077 iteration 5407 : loss : 0.016748, loss_ce: 0.006451
2022-01-20 17:49:52,354 iteration 5408 : loss : 0.015731, loss_ce: 0.006179
2022-01-20 17:49:53,581 iteration 5409 : loss : 0.014579, loss_ce: 0.004887
2022-01-20 17:49:54,923 iteration 5410 : loss : 0.018717, loss_ce: 0.008634
2022-01-20 17:49:56,185 iteration 5411 : loss : 0.017167, loss_ce: 0.007025
2022-01-20 17:49:57,534 iteration 5412 : loss : 0.016095, loss_ce: 0.006102
2022-01-20 17:49:58,819 iteration 5413 : loss : 0.015507, loss_ce: 0.006193
2022-01-20 17:50:00,155 iteration 5414 : loss : 0.013826, loss_ce: 0.005513
2022-01-20 17:50:01,594 iteration 5415 : loss : 0.022096, loss_ce: 0.007611
2022-01-20 17:50:02,856 iteration 5416 : loss : 0.018161, loss_ce: 0.008348
2022-01-20 17:50:04,165 iteration 5417 : loss : 0.012985, loss_ce: 0.004283
2022-01-20 17:50:05,576 iteration 5418 : loss : 0.021672, loss_ce: 0.008012
2022-01-20 17:50:06,815 iteration 5419 : loss : 0.015266, loss_ce: 0.006468
2022-01-20 17:50:08,068 iteration 5420 : loss : 0.013246, loss_ce: 0.005398
2022-01-20 17:50:09,437 iteration 5421 : loss : 0.019602, loss_ce: 0.007653
2022-01-20 17:50:10,821 iteration 5422 : loss : 0.031645, loss_ce: 0.007410
2022-01-20 17:50:12,192 iteration 5423 : loss : 0.015976, loss_ce: 0.006538
 80%|███████████████████████▏     | 319/400 [2:10:00<31:33, 23.37s/it]2022-01-20 17:50:13,551 iteration 5424 : loss : 0.015155, loss_ce: 0.004694
2022-01-20 17:50:14,824 iteration 5425 : loss : 0.021334, loss_ce: 0.005868
2022-01-20 17:50:16,208 iteration 5426 : loss : 0.023314, loss_ce: 0.011674
2022-01-20 17:50:17,418 iteration 5427 : loss : 0.013918, loss_ce: 0.004261
2022-01-20 17:50:18,696 iteration 5428 : loss : 0.010853, loss_ce: 0.003738
2022-01-20 17:50:19,986 iteration 5429 : loss : 0.016322, loss_ce: 0.005578
2022-01-20 17:50:21,432 iteration 5430 : loss : 0.014191, loss_ce: 0.004959
2022-01-20 17:50:22,723 iteration 5431 : loss : 0.016258, loss_ce: 0.006937
2022-01-20 17:50:24,000 iteration 5432 : loss : 0.017236, loss_ce: 0.007781
2022-01-20 17:50:25,410 iteration 5433 : loss : 0.013382, loss_ce: 0.005576
2022-01-20 17:50:26,715 iteration 5434 : loss : 0.014054, loss_ce: 0.005518
2022-01-20 17:50:28,171 iteration 5435 : loss : 0.024733, loss_ce: 0.011900
2022-01-20 17:50:29,484 iteration 5436 : loss : 0.014701, loss_ce: 0.006433
2022-01-20 17:50:30,659 iteration 5437 : loss : 0.011857, loss_ce: 0.004570
2022-01-20 17:50:32,103 iteration 5438 : loss : 0.020575, loss_ce: 0.007933
2022-01-20 17:50:33,373 iteration 5439 : loss : 0.017406, loss_ce: 0.006184
2022-01-20 17:50:33,374 Training Data Eval:
2022-01-20 17:50:39,948   Average segmentation loss on training set: 0.0091
2022-01-20 17:50:39,948 Validation Data Eval:
2022-01-20 17:50:42,183   Average segmentation loss on validation set: 0.0693
2022-01-20 17:50:43,564 iteration 5440 : loss : 0.027046, loss_ce: 0.008282
 80%|███████████████████████▏     | 320/400 [2:10:32<34:21, 25.77s/it]2022-01-20 17:50:44,822 iteration 5441 : loss : 0.012519, loss_ce: 0.003865
2022-01-20 17:50:46,142 iteration 5442 : loss : 0.017426, loss_ce: 0.006026
2022-01-20 17:50:47,513 iteration 5443 : loss : 0.013424, loss_ce: 0.004088
2022-01-20 17:50:48,856 iteration 5444 : loss : 0.015898, loss_ce: 0.006112
2022-01-20 17:50:50,298 iteration 5445 : loss : 0.022308, loss_ce: 0.009165
2022-01-20 17:50:51,583 iteration 5446 : loss : 0.018113, loss_ce: 0.005788
2022-01-20 17:50:52,918 iteration 5447 : loss : 0.018821, loss_ce: 0.007882
2022-01-20 17:50:54,284 iteration 5448 : loss : 0.019659, loss_ce: 0.006840
2022-01-20 17:50:55,639 iteration 5449 : loss : 0.018810, loss_ce: 0.005956
2022-01-20 17:50:57,089 iteration 5450 : loss : 0.024016, loss_ce: 0.012913
2022-01-20 17:50:58,459 iteration 5451 : loss : 0.018855, loss_ce: 0.007888
2022-01-20 17:50:59,897 iteration 5452 : loss : 0.016216, loss_ce: 0.006235
2022-01-20 17:51:01,290 iteration 5453 : loss : 0.018131, loss_ce: 0.007385
2022-01-20 17:51:02,542 iteration 5454 : loss : 0.009855, loss_ce: 0.004731
2022-01-20 17:51:04,041 iteration 5455 : loss : 0.025564, loss_ce: 0.009430
2022-01-20 17:51:05,492 iteration 5456 : loss : 0.017876, loss_ce: 0.007130
2022-01-20 17:51:06,867 iteration 5457 : loss : 0.023682, loss_ce: 0.008048
 80%|███████████████████████▎     | 321/400 [2:10:55<32:57, 25.03s/it]2022-01-20 17:51:08,270 iteration 5458 : loss : 0.015764, loss_ce: 0.006277
2022-01-20 17:51:09,595 iteration 5459 : loss : 0.016718, loss_ce: 0.007023
2022-01-20 17:51:10,990 iteration 5460 : loss : 0.028451, loss_ce: 0.014149
2022-01-20 17:51:12,385 iteration 5461 : loss : 0.018083, loss_ce: 0.007643
2022-01-20 17:51:13,731 iteration 5462 : loss : 0.017960, loss_ce: 0.006102
2022-01-20 17:51:15,063 iteration 5463 : loss : 0.016161, loss_ce: 0.006221
2022-01-20 17:51:16,406 iteration 5464 : loss : 0.017141, loss_ce: 0.007137
2022-01-20 17:51:17,714 iteration 5465 : loss : 0.015776, loss_ce: 0.004910
2022-01-20 17:51:19,149 iteration 5466 : loss : 0.017486, loss_ce: 0.006967
2022-01-20 17:51:20,498 iteration 5467 : loss : 0.014657, loss_ce: 0.007396
2022-01-20 17:51:21,874 iteration 5468 : loss : 0.022487, loss_ce: 0.009623
2022-01-20 17:51:23,173 iteration 5469 : loss : 0.011498, loss_ce: 0.003909
2022-01-20 17:51:24,581 iteration 5470 : loss : 0.017971, loss_ce: 0.006794
2022-01-20 17:51:25,916 iteration 5471 : loss : 0.015637, loss_ce: 0.005522
2022-01-20 17:51:27,344 iteration 5472 : loss : 0.016673, loss_ce: 0.007341
2022-01-20 17:51:28,725 iteration 5473 : loss : 0.021446, loss_ce: 0.006680
2022-01-20 17:51:30,110 iteration 5474 : loss : 0.020438, loss_ce: 0.009045
 80%|███████████████████████▎     | 322/400 [2:11:18<31:50, 24.50s/it]2022-01-20 17:51:31,501 iteration 5475 : loss : 0.013023, loss_ce: 0.003510
2022-01-20 17:51:32,813 iteration 5476 : loss : 0.031372, loss_ce: 0.009173
2022-01-20 17:51:34,132 iteration 5477 : loss : 0.013910, loss_ce: 0.006532
2022-01-20 17:51:35,485 iteration 5478 : loss : 0.015954, loss_ce: 0.007088
2022-01-20 17:51:36,940 iteration 5479 : loss : 0.016459, loss_ce: 0.007701
2022-01-20 17:51:38,341 iteration 5480 : loss : 0.019671, loss_ce: 0.008810
2022-01-20 17:51:39,658 iteration 5481 : loss : 0.014301, loss_ce: 0.003947
2022-01-20 17:51:40,972 iteration 5482 : loss : 0.011624, loss_ce: 0.003823
2022-01-20 17:51:42,304 iteration 5483 : loss : 0.014311, loss_ce: 0.005628
2022-01-20 17:51:43,594 iteration 5484 : loss : 0.016197, loss_ce: 0.006792
2022-01-20 17:51:44,819 iteration 5485 : loss : 0.013545, loss_ce: 0.004890
2022-01-20 17:51:46,238 iteration 5486 : loss : 0.020745, loss_ce: 0.007861
2022-01-20 17:51:47,720 iteration 5487 : loss : 0.021622, loss_ce: 0.008654
2022-01-20 17:51:49,017 iteration 5488 : loss : 0.017611, loss_ce: 0.006449
2022-01-20 17:51:50,316 iteration 5489 : loss : 0.014265, loss_ce: 0.005387
2022-01-20 17:51:51,594 iteration 5490 : loss : 0.029153, loss_ce: 0.009784
2022-01-20 17:51:52,898 iteration 5491 : loss : 0.014117, loss_ce: 0.005208
 81%|███████████████████████▍     | 323/400 [2:11:41<30:46, 23.98s/it]2022-01-20 17:51:54,289 iteration 5492 : loss : 0.017075, loss_ce: 0.005844
2022-01-20 17:51:55,584 iteration 5493 : loss : 0.015232, loss_ce: 0.006453
2022-01-20 17:51:56,841 iteration 5494 : loss : 0.015711, loss_ce: 0.004078
2022-01-20 17:51:58,224 iteration 5495 : loss : 0.021084, loss_ce: 0.004227
2022-01-20 17:51:59,489 iteration 5496 : loss : 0.011683, loss_ce: 0.003609
2022-01-20 17:52:00,811 iteration 5497 : loss : 0.011122, loss_ce: 0.003368
2022-01-20 17:52:02,148 iteration 5498 : loss : 0.014383, loss_ce: 0.007987
2022-01-20 17:52:03,448 iteration 5499 : loss : 0.014960, loss_ce: 0.005773
2022-01-20 17:52:04,787 iteration 5500 : loss : 0.017078, loss_ce: 0.006670
2022-01-20 17:52:06,204 iteration 5501 : loss : 0.017291, loss_ce: 0.007323
2022-01-20 17:52:07,554 iteration 5502 : loss : 0.019843, loss_ce: 0.007515
2022-01-20 17:52:08,821 iteration 5503 : loss : 0.018316, loss_ce: 0.004869
2022-01-20 17:52:10,150 iteration 5504 : loss : 0.016142, loss_ce: 0.007473
2022-01-20 17:52:11,463 iteration 5505 : loss : 0.016267, loss_ce: 0.006550
2022-01-20 17:52:12,716 iteration 5506 : loss : 0.015932, loss_ce: 0.005947
2022-01-20 17:52:14,041 iteration 5507 : loss : 0.016159, loss_ce: 0.005139
2022-01-20 17:52:15,354 iteration 5508 : loss : 0.019227, loss_ce: 0.007371
 81%|███████████████████████▍     | 324/400 [2:12:03<29:47, 23.52s/it]2022-01-20 17:52:16,693 iteration 5509 : loss : 0.014910, loss_ce: 0.004862
2022-01-20 17:52:18,137 iteration 5510 : loss : 0.018745, loss_ce: 0.005605
2022-01-20 17:52:19,444 iteration 5511 : loss : 0.016961, loss_ce: 0.008623
2022-01-20 17:52:20,821 iteration 5512 : loss : 0.014880, loss_ce: 0.002528
2022-01-20 17:52:22,081 iteration 5513 : loss : 0.016169, loss_ce: 0.003659
2022-01-20 17:52:23,444 iteration 5514 : loss : 0.015136, loss_ce: 0.006412
2022-01-20 17:52:24,842 iteration 5515 : loss : 0.023345, loss_ce: 0.007011
2022-01-20 17:52:26,045 iteration 5516 : loss : 0.010401, loss_ce: 0.004094
2022-01-20 17:52:27,382 iteration 5517 : loss : 0.021821, loss_ce: 0.007189
2022-01-20 17:52:28,660 iteration 5518 : loss : 0.018404, loss_ce: 0.007613
2022-01-20 17:52:29,932 iteration 5519 : loss : 0.015196, loss_ce: 0.004551
2022-01-20 17:52:31,267 iteration 5520 : loss : 0.023294, loss_ce: 0.008452
2022-01-20 17:52:32,719 iteration 5521 : loss : 0.020239, loss_ce: 0.007318
2022-01-20 17:52:33,942 iteration 5522 : loss : 0.011496, loss_ce: 0.004852
2022-01-20 17:52:35,259 iteration 5523 : loss : 0.015802, loss_ce: 0.006283
2022-01-20 17:52:36,590 iteration 5524 : loss : 0.024685, loss_ce: 0.010852
2022-01-20 17:52:36,590 Training Data Eval:
2022-01-20 17:52:43,090   Average segmentation loss on training set: 0.0100
2022-01-20 17:52:43,091 Validation Data Eval:
2022-01-20 17:52:45,291   Average segmentation loss on validation set: 0.0893
2022-01-20 17:52:46,664 iteration 5525 : loss : 0.020170, loss_ce: 0.008562
 81%|███████████████████████▌     | 325/400 [2:12:35<32:19, 25.86s/it]2022-01-20 17:52:48,146 iteration 5526 : loss : 0.018871, loss_ce: 0.007371
2022-01-20 17:52:49,405 iteration 5527 : loss : 0.013856, loss_ce: 0.004507
2022-01-20 17:52:50,757 iteration 5528 : loss : 0.023150, loss_ce: 0.009041
2022-01-20 17:52:52,043 iteration 5529 : loss : 0.015122, loss_ce: 0.005105
2022-01-20 17:52:53,293 iteration 5530 : loss : 0.012352, loss_ce: 0.003086
2022-01-20 17:52:54,619 iteration 5531 : loss : 0.012834, loss_ce: 0.004674
2022-01-20 17:52:55,829 iteration 5532 : loss : 0.016701, loss_ce: 0.005195
2022-01-20 17:52:57,180 iteration 5533 : loss : 0.013218, loss_ce: 0.005607
2022-01-20 17:52:58,503 iteration 5534 : loss : 0.019259, loss_ce: 0.006324
2022-01-20 17:52:59,835 iteration 5535 : loss : 0.014706, loss_ce: 0.005882
2022-01-20 17:53:01,129 iteration 5536 : loss : 0.013761, loss_ce: 0.004268
2022-01-20 17:53:02,442 iteration 5537 : loss : 0.013471, loss_ce: 0.003685
2022-01-20 17:53:03,736 iteration 5538 : loss : 0.013024, loss_ce: 0.006621
2022-01-20 17:53:05,065 iteration 5539 : loss : 0.017652, loss_ce: 0.008854
2022-01-20 17:53:06,382 iteration 5540 : loss : 0.011090, loss_ce: 0.003788
2022-01-20 17:53:07,598 iteration 5541 : loss : 0.015715, loss_ce: 0.006064
2022-01-20 17:53:08,872 iteration 5542 : loss : 0.019724, loss_ce: 0.007668
 82%|███████████████████████▋     | 326/400 [2:12:57<30:32, 24.76s/it]2022-01-20 17:53:10,316 iteration 5543 : loss : 0.021609, loss_ce: 0.008739
2022-01-20 17:53:11,749 iteration 5544 : loss : 0.019988, loss_ce: 0.006558
2022-01-20 17:53:13,137 iteration 5545 : loss : 0.020275, loss_ce: 0.007882
2022-01-20 17:53:14,355 iteration 5546 : loss : 0.010537, loss_ce: 0.004862
2022-01-20 17:53:15,694 iteration 5547 : loss : 0.013675, loss_ce: 0.005396
2022-01-20 17:53:16,966 iteration 5548 : loss : 0.019648, loss_ce: 0.006144
2022-01-20 17:53:18,269 iteration 5549 : loss : 0.013912, loss_ce: 0.005505
2022-01-20 17:53:19,609 iteration 5550 : loss : 0.025542, loss_ce: 0.010420
2022-01-20 17:53:20,942 iteration 5551 : loss : 0.014241, loss_ce: 0.003196
2022-01-20 17:53:22,368 iteration 5552 : loss : 0.037081, loss_ce: 0.008538
2022-01-20 17:53:23,706 iteration 5553 : loss : 0.029703, loss_ce: 0.009740
2022-01-20 17:53:25,113 iteration 5554 : loss : 0.024679, loss_ce: 0.006315
2022-01-20 17:53:26,486 iteration 5555 : loss : 0.022931, loss_ce: 0.009503
2022-01-20 17:53:27,838 iteration 5556 : loss : 0.014955, loss_ce: 0.006382
2022-01-20 17:53:29,182 iteration 5557 : loss : 0.018045, loss_ce: 0.005425
2022-01-20 17:53:30,464 iteration 5558 : loss : 0.018055, loss_ce: 0.006186
2022-01-20 17:53:31,702 iteration 5559 : loss : 0.016198, loss_ce: 0.005811
 82%|███████████████████████▋     | 327/400 [2:13:20<29:25, 24.19s/it]2022-01-20 17:53:33,075 iteration 5560 : loss : 0.018762, loss_ce: 0.007056
2022-01-20 17:53:34,471 iteration 5561 : loss : 0.027049, loss_ce: 0.007618
2022-01-20 17:53:35,789 iteration 5562 : loss : 0.022500, loss_ce: 0.006723
2022-01-20 17:53:37,152 iteration 5563 : loss : 0.017947, loss_ce: 0.005483
2022-01-20 17:53:38,377 iteration 5564 : loss : 0.019340, loss_ce: 0.006166
2022-01-20 17:53:39,718 iteration 5565 : loss : 0.022426, loss_ce: 0.006599
2022-01-20 17:53:40,977 iteration 5566 : loss : 0.012905, loss_ce: 0.004113
2022-01-20 17:53:42,337 iteration 5567 : loss : 0.015207, loss_ce: 0.008261
2022-01-20 17:53:43,700 iteration 5568 : loss : 0.020327, loss_ce: 0.009364
2022-01-20 17:53:45,067 iteration 5569 : loss : 0.019080, loss_ce: 0.009554
2022-01-20 17:53:46,364 iteration 5570 : loss : 0.017023, loss_ce: 0.008704
2022-01-20 17:53:47,659 iteration 5571 : loss : 0.019230, loss_ce: 0.005473
2022-01-20 17:53:48,859 iteration 5572 : loss : 0.012944, loss_ce: 0.004360
2022-01-20 17:53:50,223 iteration 5573 : loss : 0.021771, loss_ce: 0.008799
2022-01-20 17:53:51,479 iteration 5574 : loss : 0.014817, loss_ce: 0.005644
2022-01-20 17:53:52,724 iteration 5575 : loss : 0.012410, loss_ce: 0.004523
2022-01-20 17:53:53,937 iteration 5576 : loss : 0.015777, loss_ce: 0.004592
 82%|███████████████████████▊     | 328/400 [2:13:42<28:19, 23.60s/it]2022-01-20 17:53:55,373 iteration 5577 : loss : 0.024088, loss_ce: 0.008430
2022-01-20 17:53:56,680 iteration 5578 : loss : 0.012690, loss_ce: 0.004100
2022-01-20 17:53:58,096 iteration 5579 : loss : 0.021444, loss_ce: 0.005693
2022-01-20 17:53:59,448 iteration 5580 : loss : 0.016486, loss_ce: 0.004955
2022-01-20 17:54:00,777 iteration 5581 : loss : 0.017313, loss_ce: 0.008333
2022-01-20 17:54:02,056 iteration 5582 : loss : 0.016752, loss_ce: 0.006513
2022-01-20 17:54:03,294 iteration 5583 : loss : 0.011415, loss_ce: 0.003301
2022-01-20 17:54:04,576 iteration 5584 : loss : 0.013522, loss_ce: 0.004961
2022-01-20 17:54:05,802 iteration 5585 : loss : 0.013300, loss_ce: 0.004588
2022-01-20 17:54:07,067 iteration 5586 : loss : 0.014059, loss_ce: 0.005950
2022-01-20 17:54:08,459 iteration 5587 : loss : 0.016624, loss_ce: 0.006668
2022-01-20 17:54:09,755 iteration 5588 : loss : 0.017422, loss_ce: 0.007756
2022-01-20 17:54:11,123 iteration 5589 : loss : 0.021978, loss_ce: 0.006881
2022-01-20 17:54:12,355 iteration 5590 : loss : 0.014161, loss_ce: 0.006052
2022-01-20 17:54:13,684 iteration 5591 : loss : 0.021565, loss_ce: 0.007660
2022-01-20 17:54:15,006 iteration 5592 : loss : 0.018674, loss_ce: 0.007744
2022-01-20 17:54:16,206 iteration 5593 : loss : 0.012181, loss_ce: 0.005638
 82%|███████████████████████▊     | 329/400 [2:14:04<27:27, 23.20s/it]2022-01-20 17:54:17,562 iteration 5594 : loss : 0.010863, loss_ce: 0.003619
2022-01-20 17:54:18,809 iteration 5595 : loss : 0.012628, loss_ce: 0.005330
2022-01-20 17:54:20,189 iteration 5596 : loss : 0.022570, loss_ce: 0.007232
2022-01-20 17:54:21,511 iteration 5597 : loss : 0.017256, loss_ce: 0.007231
2022-01-20 17:54:22,932 iteration 5598 : loss : 0.020591, loss_ce: 0.009474
2022-01-20 17:54:24,308 iteration 5599 : loss : 0.014376, loss_ce: 0.004936
2022-01-20 17:54:25,536 iteration 5600 : loss : 0.012195, loss_ce: 0.004490
2022-01-20 17:54:26,861 iteration 5601 : loss : 0.015052, loss_ce: 0.005318
2022-01-20 17:54:28,177 iteration 5602 : loss : 0.014655, loss_ce: 0.004853
2022-01-20 17:54:29,500 iteration 5603 : loss : 0.018615, loss_ce: 0.008565
2022-01-20 17:54:30,812 iteration 5604 : loss : 0.019557, loss_ce: 0.006371
2022-01-20 17:54:32,072 iteration 5605 : loss : 0.013063, loss_ce: 0.005940
2022-01-20 17:54:33,408 iteration 5606 : loss : 0.022915, loss_ce: 0.007418
2022-01-20 17:54:34,640 iteration 5607 : loss : 0.016251, loss_ce: 0.007086
2022-01-20 17:54:35,969 iteration 5608 : loss : 0.014250, loss_ce: 0.006582
2022-01-20 17:54:37,233 iteration 5609 : loss : 0.013665, loss_ce: 0.004936
2022-01-20 17:54:37,234 Training Data Eval:
2022-01-20 17:54:43,807   Average segmentation loss on training set: 0.0088
2022-01-20 17:54:43,808 Validation Data Eval:
2022-01-20 17:54:46,031   Average segmentation loss on validation set: 0.0778
2022-01-20 17:54:47,372 iteration 5610 : loss : 0.021818, loss_ce: 0.009379
 82%|███████████████████████▉     | 330/400 [2:14:35<29:51, 25.59s/it]2022-01-20 17:54:48,682 iteration 5611 : loss : 0.009541, loss_ce: 0.003673
2022-01-20 17:54:50,050 iteration 5612 : loss : 0.022282, loss_ce: 0.007350
2022-01-20 17:54:51,320 iteration 5613 : loss : 0.041446, loss_ce: 0.013353
2022-01-20 17:54:52,602 iteration 5614 : loss : 0.016310, loss_ce: 0.005732
2022-01-20 17:54:53,905 iteration 5615 : loss : 0.018607, loss_ce: 0.009192
2022-01-20 17:54:55,210 iteration 5616 : loss : 0.013270, loss_ce: 0.003853
2022-01-20 17:54:56,684 iteration 5617 : loss : 0.020398, loss_ce: 0.006701
2022-01-20 17:54:58,035 iteration 5618 : loss : 0.022430, loss_ce: 0.006689
2022-01-20 17:54:59,345 iteration 5619 : loss : 0.013611, loss_ce: 0.006642
2022-01-20 17:55:00,599 iteration 5620 : loss : 0.012890, loss_ce: 0.004871
2022-01-20 17:55:01,851 iteration 5621 : loss : 0.015458, loss_ce: 0.006075
2022-01-20 17:55:03,081 iteration 5622 : loss : 0.011955, loss_ce: 0.005274
2022-01-20 17:55:04,466 iteration 5623 : loss : 0.012925, loss_ce: 0.005190
2022-01-20 17:55:05,774 iteration 5624 : loss : 0.013187, loss_ce: 0.005204
2022-01-20 17:55:07,082 iteration 5625 : loss : 0.022370, loss_ce: 0.009929
2022-01-20 17:55:08,439 iteration 5626 : loss : 0.018284, loss_ce: 0.007832
2022-01-20 17:55:09,742 iteration 5627 : loss : 0.016907, loss_ce: 0.006632
 83%|███████████████████████▉     | 331/400 [2:14:58<28:19, 24.62s/it]2022-01-20 17:55:11,116 iteration 5628 : loss : 0.016010, loss_ce: 0.007330
2022-01-20 17:55:12,433 iteration 5629 : loss : 0.014427, loss_ce: 0.005661
2022-01-20 17:55:13,770 iteration 5630 : loss : 0.014425, loss_ce: 0.005418
2022-01-20 17:55:15,113 iteration 5631 : loss : 0.015670, loss_ce: 0.007938
2022-01-20 17:55:16,512 iteration 5632 : loss : 0.024413, loss_ce: 0.008512
2022-01-20 17:55:17,716 iteration 5633 : loss : 0.022503, loss_ce: 0.005312
2022-01-20 17:55:19,090 iteration 5634 : loss : 0.029562, loss_ce: 0.007975
2022-01-20 17:55:20,382 iteration 5635 : loss : 0.014949, loss_ce: 0.006172
2022-01-20 17:55:21,607 iteration 5636 : loss : 0.044019, loss_ce: 0.009472
2022-01-20 17:55:23,016 iteration 5637 : loss : 0.013515, loss_ce: 0.005622
2022-01-20 17:55:24,309 iteration 5638 : loss : 0.016118, loss_ce: 0.007414
2022-01-20 17:55:25,636 iteration 5639 : loss : 0.016220, loss_ce: 0.004985
2022-01-20 17:55:26,942 iteration 5640 : loss : 0.016081, loss_ce: 0.005528
2022-01-20 17:55:28,207 iteration 5641 : loss : 0.014747, loss_ce: 0.005019
2022-01-20 17:55:29,643 iteration 5642 : loss : 0.018354, loss_ce: 0.008508
2022-01-20 17:55:30,861 iteration 5643 : loss : 0.018114, loss_ce: 0.010143
2022-01-20 17:55:32,164 iteration 5644 : loss : 0.015988, loss_ce: 0.007365
 83%|████████████████████████     | 332/400 [2:15:20<27:09, 23.97s/it]2022-01-20 17:55:33,473 iteration 5645 : loss : 0.011707, loss_ce: 0.003632
2022-01-20 17:55:34,754 iteration 5646 : loss : 0.014213, loss_ce: 0.003912
2022-01-20 17:55:35,991 iteration 5647 : loss : 0.010984, loss_ce: 0.003839
2022-01-20 17:55:37,307 iteration 5648 : loss : 0.012676, loss_ce: 0.005768
2022-01-20 17:55:38,564 iteration 5649 : loss : 0.011807, loss_ce: 0.003220
2022-01-20 17:55:39,938 iteration 5650 : loss : 0.018774, loss_ce: 0.006671
2022-01-20 17:55:41,227 iteration 5651 : loss : 0.015648, loss_ce: 0.006412
2022-01-20 17:55:42,539 iteration 5652 : loss : 0.015124, loss_ce: 0.004486
2022-01-20 17:55:43,836 iteration 5653 : loss : 0.015877, loss_ce: 0.004862
2022-01-20 17:55:45,133 iteration 5654 : loss : 0.021696, loss_ce: 0.008658
2022-01-20 17:55:46,336 iteration 5655 : loss : 0.012783, loss_ce: 0.006163
2022-01-20 17:55:47,743 iteration 5656 : loss : 0.018731, loss_ce: 0.007269
2022-01-20 17:55:49,108 iteration 5657 : loss : 0.040677, loss_ce: 0.012895
2022-01-20 17:55:50,455 iteration 5658 : loss : 0.022293, loss_ce: 0.010485
2022-01-20 17:55:51,717 iteration 5659 : loss : 0.023566, loss_ce: 0.012600
2022-01-20 17:55:53,064 iteration 5660 : loss : 0.016583, loss_ce: 0.006036
2022-01-20 17:55:54,384 iteration 5661 : loss : 0.015911, loss_ce: 0.007648
 83%|████████████████████████▏    | 333/400 [2:15:42<26:10, 23.44s/it]2022-01-20 17:55:55,761 iteration 5662 : loss : 0.019447, loss_ce: 0.006881
2022-01-20 17:55:57,034 iteration 5663 : loss : 0.012586, loss_ce: 0.003779
2022-01-20 17:55:58,359 iteration 5664 : loss : 0.025760, loss_ce: 0.011713
2022-01-20 17:55:59,617 iteration 5665 : loss : 0.011820, loss_ce: 0.004133
2022-01-20 17:56:00,941 iteration 5666 : loss : 0.019883, loss_ce: 0.004131
2022-01-20 17:56:02,307 iteration 5667 : loss : 0.012881, loss_ce: 0.004509
2022-01-20 17:56:03,636 iteration 5668 : loss : 0.017350, loss_ce: 0.006493
2022-01-20 17:56:04,888 iteration 5669 : loss : 0.013485, loss_ce: 0.005249
2022-01-20 17:56:06,182 iteration 5670 : loss : 0.016089, loss_ce: 0.005234
2022-01-20 17:56:07,444 iteration 5671 : loss : 0.015813, loss_ce: 0.006424
2022-01-20 17:56:08,872 iteration 5672 : loss : 0.022130, loss_ce: 0.012637
2022-01-20 17:56:10,152 iteration 5673 : loss : 0.014840, loss_ce: 0.005563
2022-01-20 17:56:11,463 iteration 5674 : loss : 0.012230, loss_ce: 0.003623
2022-01-20 17:56:12,728 iteration 5675 : loss : 0.011142, loss_ce: 0.005044
2022-01-20 17:56:14,096 iteration 5676 : loss : 0.021373, loss_ce: 0.009508
2022-01-20 17:56:15,376 iteration 5677 : loss : 0.020574, loss_ce: 0.005882
2022-01-20 17:56:16,782 iteration 5678 : loss : 0.021006, loss_ce: 0.007462
 84%|████████████████████████▏    | 334/400 [2:16:05<25:26, 23.13s/it]2022-01-20 17:56:18,180 iteration 5679 : loss : 0.014981, loss_ce: 0.005345
2022-01-20 17:56:19,429 iteration 5680 : loss : 0.013051, loss_ce: 0.005444
2022-01-20 17:56:20,749 iteration 5681 : loss : 0.021044, loss_ce: 0.010600
2022-01-20 17:56:22,031 iteration 5682 : loss : 0.017624, loss_ce: 0.006050
2022-01-20 17:56:23,370 iteration 5683 : loss : 0.019950, loss_ce: 0.006996
2022-01-20 17:56:24,754 iteration 5684 : loss : 0.017596, loss_ce: 0.005903
2022-01-20 17:56:26,092 iteration 5685 : loss : 0.013104, loss_ce: 0.003938
2022-01-20 17:56:27,379 iteration 5686 : loss : 0.016957, loss_ce: 0.006823
2022-01-20 17:56:28,635 iteration 5687 : loss : 0.009777, loss_ce: 0.002586
2022-01-20 17:56:29,929 iteration 5688 : loss : 0.020074, loss_ce: 0.006782
2022-01-20 17:56:31,212 iteration 5689 : loss : 0.015171, loss_ce: 0.006615
2022-01-20 17:56:32,547 iteration 5690 : loss : 0.018317, loss_ce: 0.009754
2022-01-20 17:56:33,836 iteration 5691 : loss : 0.013997, loss_ce: 0.003816
2022-01-20 17:56:35,109 iteration 5692 : loss : 0.012894, loss_ce: 0.004503
2022-01-20 17:56:36,463 iteration 5693 : loss : 0.018725, loss_ce: 0.008107
2022-01-20 17:56:37,827 iteration 5694 : loss : 0.021622, loss_ce: 0.007929
2022-01-20 17:56:37,827 Training Data Eval:
2022-01-20 17:56:44,393   Average segmentation loss on training set: 0.0100
2022-01-20 17:56:44,393 Validation Data Eval:
2022-01-20 17:56:46,647   Average segmentation loss on validation set: 0.0738
2022-01-20 17:56:47,958 iteration 5695 : loss : 0.028038, loss_ce: 0.010794
 84%|████████████████████████▎    | 335/400 [2:16:36<27:40, 25.54s/it]2022-01-20 17:56:49,322 iteration 5696 : loss : 0.014377, loss_ce: 0.004709
2022-01-20 17:56:50,701 iteration 5697 : loss : 0.024532, loss_ce: 0.010333
2022-01-20 17:56:52,021 iteration 5698 : loss : 0.014611, loss_ce: 0.005829
2022-01-20 17:56:53,417 iteration 5699 : loss : 0.019282, loss_ce: 0.006703
2022-01-20 17:56:54,723 iteration 5700 : loss : 0.014463, loss_ce: 0.004999
2022-01-20 17:56:56,000 iteration 5701 : loss : 0.014966, loss_ce: 0.007667
2022-01-20 17:56:57,333 iteration 5702 : loss : 0.010468, loss_ce: 0.003632
2022-01-20 17:56:58,632 iteration 5703 : loss : 0.011391, loss_ce: 0.005019
2022-01-20 17:56:59,994 iteration 5704 : loss : 0.022447, loss_ce: 0.009413
2022-01-20 17:57:01,326 iteration 5705 : loss : 0.016262, loss_ce: 0.006434
2022-01-20 17:57:02,595 iteration 5706 : loss : 0.013796, loss_ce: 0.002998
2022-01-20 17:57:04,040 iteration 5707 : loss : 0.018634, loss_ce: 0.007150
2022-01-20 17:57:05,321 iteration 5708 : loss : 0.024832, loss_ce: 0.008759
2022-01-20 17:57:06,647 iteration 5709 : loss : 0.023856, loss_ce: 0.010709
2022-01-20 17:57:08,058 iteration 5710 : loss : 0.014675, loss_ce: 0.005889
2022-01-20 17:57:09,320 iteration 5711 : loss : 0.027662, loss_ce: 0.018113
2022-01-20 17:57:10,612 iteration 5712 : loss : 0.014748, loss_ce: 0.006864
 84%|████████████████████████▎    | 336/400 [2:16:59<26:19, 24.68s/it]2022-01-20 17:57:11,933 iteration 5713 : loss : 0.020900, loss_ce: 0.006554
2022-01-20 17:57:13,209 iteration 5714 : loss : 0.012989, loss_ce: 0.004800
2022-01-20 17:57:14,488 iteration 5715 : loss : 0.012131, loss_ce: 0.005007
2022-01-20 17:57:15,802 iteration 5716 : loss : 0.013853, loss_ce: 0.006465
2022-01-20 17:57:17,152 iteration 5717 : loss : 0.015719, loss_ce: 0.005938
2022-01-20 17:57:18,379 iteration 5718 : loss : 0.016098, loss_ce: 0.004964
2022-01-20 17:57:19,732 iteration 5719 : loss : 0.015938, loss_ce: 0.006050
2022-01-20 17:57:21,004 iteration 5720 : loss : 0.016292, loss_ce: 0.007065
2022-01-20 17:57:22,197 iteration 5721 : loss : 0.012389, loss_ce: 0.003434
2022-01-20 17:57:23,490 iteration 5722 : loss : 0.011917, loss_ce: 0.004016
2022-01-20 17:57:24,771 iteration 5723 : loss : 0.014590, loss_ce: 0.005465
2022-01-20 17:57:25,975 iteration 5724 : loss : 0.011258, loss_ce: 0.004543
2022-01-20 17:57:27,318 iteration 5725 : loss : 0.016114, loss_ce: 0.006962
2022-01-20 17:57:28,564 iteration 5726 : loss : 0.014428, loss_ce: 0.006335
2022-01-20 17:57:29,848 iteration 5727 : loss : 0.019536, loss_ce: 0.006267
2022-01-20 17:57:31,116 iteration 5728 : loss : 0.019144, loss_ce: 0.009383
2022-01-20 17:57:32,449 iteration 5729 : loss : 0.016660, loss_ce: 0.007448
 84%|████████████████████████▍    | 337/400 [2:17:20<25:00, 23.82s/it]2022-01-20 17:57:33,819 iteration 5730 : loss : 0.022143, loss_ce: 0.007389
2022-01-20 17:57:35,167 iteration 5731 : loss : 0.011240, loss_ce: 0.004679
2022-01-20 17:57:36,451 iteration 5732 : loss : 0.018833, loss_ce: 0.007089
2022-01-20 17:57:37,704 iteration 5733 : loss : 0.018249, loss_ce: 0.006578
2022-01-20 17:57:39,007 iteration 5734 : loss : 0.031026, loss_ce: 0.009135
2022-01-20 17:57:40,359 iteration 5735 : loss : 0.014072, loss_ce: 0.006949
2022-01-20 17:57:41,652 iteration 5736 : loss : 0.015880, loss_ce: 0.008156
2022-01-20 17:57:42,931 iteration 5737 : loss : 0.024197, loss_ce: 0.009933
2022-01-20 17:57:44,202 iteration 5738 : loss : 0.010453, loss_ce: 0.004359
2022-01-20 17:57:45,441 iteration 5739 : loss : 0.013401, loss_ce: 0.005468
2022-01-20 17:57:46,769 iteration 5740 : loss : 0.021341, loss_ce: 0.006524
2022-01-20 17:57:48,074 iteration 5741 : loss : 0.016735, loss_ce: 0.008885
2022-01-20 17:57:49,388 iteration 5742 : loss : 0.023088, loss_ce: 0.008951
2022-01-20 17:57:50,650 iteration 5743 : loss : 0.014115, loss_ce: 0.006157
2022-01-20 17:57:52,005 iteration 5744 : loss : 0.012546, loss_ce: 0.004874
2022-01-20 17:57:53,308 iteration 5745 : loss : 0.015594, loss_ce: 0.005120
2022-01-20 17:57:54,526 iteration 5746 : loss : 0.011811, loss_ce: 0.003015
 84%|████████████████████████▌    | 338/400 [2:17:43<24:04, 23.30s/it]2022-01-20 17:57:55,929 iteration 5747 : loss : 0.023079, loss_ce: 0.007108
2022-01-20 17:57:57,252 iteration 5748 : loss : 0.019067, loss_ce: 0.006466
2022-01-20 17:57:58,603 iteration 5749 : loss : 0.014833, loss_ce: 0.005820
2022-01-20 17:57:59,989 iteration 5750 : loss : 0.014950, loss_ce: 0.004243
2022-01-20 17:58:01,215 iteration 5751 : loss : 0.012350, loss_ce: 0.004766
2022-01-20 17:58:02,541 iteration 5752 : loss : 0.012448, loss_ce: 0.004032
2022-01-20 17:58:03,826 iteration 5753 : loss : 0.035382, loss_ce: 0.014729
2022-01-20 17:58:05,055 iteration 5754 : loss : 0.011705, loss_ce: 0.004190
2022-01-20 17:58:06,362 iteration 5755 : loss : 0.016432, loss_ce: 0.007543
2022-01-20 17:58:07,672 iteration 5756 : loss : 0.012067, loss_ce: 0.003895
2022-01-20 17:58:08,953 iteration 5757 : loss : 0.015089, loss_ce: 0.007517
2022-01-20 17:58:10,258 iteration 5758 : loss : 0.016001, loss_ce: 0.003453
2022-01-20 17:58:11,564 iteration 5759 : loss : 0.015217, loss_ce: 0.007194
2022-01-20 17:58:12,954 iteration 5760 : loss : 0.015101, loss_ce: 0.005930
2022-01-20 17:58:14,153 iteration 5761 : loss : 0.010439, loss_ce: 0.003765
2022-01-20 17:58:15,650 iteration 5762 : loss : 0.023148, loss_ce: 0.008881
2022-01-20 17:58:16,928 iteration 5763 : loss : 0.015432, loss_ce: 0.006144
 85%|████████████████████████▌    | 339/400 [2:18:05<23:24, 23.03s/it]2022-01-20 17:58:18,306 iteration 5764 : loss : 0.013985, loss_ce: 0.005838
2022-01-20 17:58:19,636 iteration 5765 : loss : 0.015534, loss_ce: 0.004254
2022-01-20 17:58:20,951 iteration 5766 : loss : 0.014943, loss_ce: 0.005824
2022-01-20 17:58:22,263 iteration 5767 : loss : 0.013527, loss_ce: 0.005585
2022-01-20 17:58:23,685 iteration 5768 : loss : 0.020208, loss_ce: 0.006973
2022-01-20 17:58:24,967 iteration 5769 : loss : 0.010097, loss_ce: 0.003720
2022-01-20 17:58:26,255 iteration 5770 : loss : 0.013033, loss_ce: 0.005291
2022-01-20 17:58:27,550 iteration 5771 : loss : 0.019850, loss_ce: 0.009369
2022-01-20 17:58:28,868 iteration 5772 : loss : 0.020384, loss_ce: 0.007851
2022-01-20 17:58:30,275 iteration 5773 : loss : 0.012827, loss_ce: 0.005456
2022-01-20 17:58:31,661 iteration 5774 : loss : 0.022479, loss_ce: 0.010573
2022-01-20 17:58:33,063 iteration 5775 : loss : 0.017183, loss_ce: 0.005436
2022-01-20 17:58:34,303 iteration 5776 : loss : 0.012989, loss_ce: 0.004485
2022-01-20 17:58:35,573 iteration 5777 : loss : 0.015602, loss_ce: 0.006186
2022-01-20 17:58:36,923 iteration 5778 : loss : 0.022827, loss_ce: 0.006719
2022-01-20 17:58:38,221 iteration 5779 : loss : 0.018476, loss_ce: 0.007575
2022-01-20 17:58:38,222 Training Data Eval:
2022-01-20 17:58:44,726   Average segmentation loss on training set: 0.0082
2022-01-20 17:58:44,726 Validation Data Eval:
2022-01-20 17:58:46,919   Average segmentation loss on validation set: 0.0723
2022-01-20 17:58:48,286 iteration 5780 : loss : 0.012128, loss_ce: 0.004573
 85%|████████████████████████▋    | 340/400 [2:18:36<25:31, 25.53s/it]2022-01-20 17:58:49,786 iteration 5781 : loss : 0.028136, loss_ce: 0.008946
2022-01-20 17:58:50,991 iteration 5782 : loss : 0.009987, loss_ce: 0.004911
2022-01-20 17:58:52,232 iteration 5783 : loss : 0.020648, loss_ce: 0.008223
2022-01-20 17:58:53,498 iteration 5784 : loss : 0.017361, loss_ce: 0.007187
2022-01-20 17:58:54,719 iteration 5785 : loss : 0.012004, loss_ce: 0.004970
2022-01-20 17:58:56,026 iteration 5786 : loss : 0.038480, loss_ce: 0.007810
2022-01-20 17:58:57,318 iteration 5787 : loss : 0.013938, loss_ce: 0.005682
2022-01-20 17:58:58,530 iteration 5788 : loss : 0.012670, loss_ce: 0.004969
2022-01-20 17:58:59,770 iteration 5789 : loss : 0.010591, loss_ce: 0.004193
2022-01-20 17:59:01,113 iteration 5790 : loss : 0.010964, loss_ce: 0.003880
2022-01-20 17:59:02,407 iteration 5791 : loss : 0.018837, loss_ce: 0.009524
2022-01-20 17:59:03,663 iteration 5792 : loss : 0.011697, loss_ce: 0.004409
2022-01-20 17:59:05,029 iteration 5793 : loss : 0.017595, loss_ce: 0.006721
2022-01-20 17:59:06,414 iteration 5794 : loss : 0.015176, loss_ce: 0.006278
2022-01-20 17:59:07,666 iteration 5795 : loss : 0.010364, loss_ce: 0.004352
2022-01-20 17:59:08,986 iteration 5796 : loss : 0.013552, loss_ce: 0.006049
2022-01-20 17:59:10,300 iteration 5797 : loss : 0.013589, loss_ce: 0.004809
 85%|████████████████████████▋    | 341/400 [2:18:58<24:04, 24.47s/it]2022-01-20 17:59:11,767 iteration 5798 : loss : 0.014897, loss_ce: 0.004451
2022-01-20 17:59:13,041 iteration 5799 : loss : 0.012914, loss_ce: 0.003592
2022-01-20 17:59:14,320 iteration 5800 : loss : 0.012774, loss_ce: 0.003676
2022-01-20 17:59:15,520 iteration 5801 : loss : 0.009333, loss_ce: 0.003321
2022-01-20 17:59:16,856 iteration 5802 : loss : 0.014287, loss_ce: 0.007107
2022-01-20 17:59:18,080 iteration 5803 : loss : 0.011639, loss_ce: 0.004119
2022-01-20 17:59:19,485 iteration 5804 : loss : 0.029055, loss_ce: 0.009821
2022-01-20 17:59:20,736 iteration 5805 : loss : 0.019594, loss_ce: 0.010567
2022-01-20 17:59:21,961 iteration 5806 : loss : 0.016590, loss_ce: 0.006388
2022-01-20 17:59:23,279 iteration 5807 : loss : 0.015327, loss_ce: 0.006931
2022-01-20 17:59:24,562 iteration 5808 : loss : 0.018123, loss_ce: 0.007753
2022-01-20 17:59:25,980 iteration 5809 : loss : 0.020671, loss_ce: 0.006046
2022-01-20 17:59:27,210 iteration 5810 : loss : 0.015248, loss_ce: 0.003838
2022-01-20 17:59:28,507 iteration 5811 : loss : 0.013484, loss_ce: 0.005915
2022-01-20 17:59:29,848 iteration 5812 : loss : 0.021438, loss_ce: 0.009576
2022-01-20 17:59:31,109 iteration 5813 : loss : 0.014816, loss_ce: 0.004384
2022-01-20 17:59:32,425 iteration 5814 : loss : 0.023408, loss_ce: 0.009170
 86%|████████████████████████▊    | 342/400 [2:19:20<22:58, 23.77s/it]2022-01-20 17:59:33,914 iteration 5815 : loss : 0.016386, loss_ce: 0.006682
2022-01-20 17:59:35,140 iteration 5816 : loss : 0.013695, loss_ce: 0.004427
2022-01-20 17:59:36,463 iteration 5817 : loss : 0.014722, loss_ce: 0.003927
2022-01-20 17:59:37,755 iteration 5818 : loss : 0.013981, loss_ce: 0.004833
2022-01-20 17:59:39,156 iteration 5819 : loss : 0.016560, loss_ce: 0.007070
2022-01-20 17:59:40,446 iteration 5820 : loss : 0.012328, loss_ce: 0.005394
2022-01-20 17:59:41,728 iteration 5821 : loss : 0.018659, loss_ce: 0.006364
2022-01-20 17:59:43,107 iteration 5822 : loss : 0.017332, loss_ce: 0.005787
2022-01-20 17:59:44,440 iteration 5823 : loss : 0.011573, loss_ce: 0.003774
2022-01-20 17:59:45,752 iteration 5824 : loss : 0.016027, loss_ce: 0.005475
2022-01-20 17:59:47,058 iteration 5825 : loss : 0.015959, loss_ce: 0.007660
2022-01-20 17:59:48,355 iteration 5826 : loss : 0.027487, loss_ce: 0.008263
2022-01-20 17:59:49,614 iteration 5827 : loss : 0.020345, loss_ce: 0.005446
2022-01-20 17:59:50,828 iteration 5828 : loss : 0.009470, loss_ce: 0.004139
2022-01-20 17:59:52,144 iteration 5829 : loss : 0.012557, loss_ce: 0.004886
2022-01-20 17:59:53,468 iteration 5830 : loss : 0.016320, loss_ce: 0.006673
2022-01-20 17:59:54,838 iteration 5831 : loss : 0.013409, loss_ce: 0.005151
 86%|████████████████████████▊    | 343/400 [2:19:43<22:11, 23.36s/it]2022-01-20 17:59:56,296 iteration 5832 : loss : 0.015126, loss_ce: 0.006014
2022-01-20 17:59:57,569 iteration 5833 : loss : 0.011768, loss_ce: 0.004421
2022-01-20 17:59:58,962 iteration 5834 : loss : 0.020421, loss_ce: 0.008156
2022-01-20 18:00:00,441 iteration 5835 : loss : 0.025673, loss_ce: 0.009090
2022-01-20 18:00:01,709 iteration 5836 : loss : 0.030200, loss_ce: 0.011708
2022-01-20 18:00:03,101 iteration 5837 : loss : 0.019035, loss_ce: 0.008187
2022-01-20 18:00:04,485 iteration 5838 : loss : 0.017750, loss_ce: 0.005265
2022-01-20 18:00:05,710 iteration 5839 : loss : 0.016472, loss_ce: 0.005861
2022-01-20 18:00:07,235 iteration 5840 : loss : 0.024647, loss_ce: 0.010743
2022-01-20 18:00:08,525 iteration 5841 : loss : 0.014373, loss_ce: 0.005884
2022-01-20 18:00:09,903 iteration 5842 : loss : 0.016948, loss_ce: 0.006803
2022-01-20 18:00:11,295 iteration 5843 : loss : 0.016104, loss_ce: 0.005654
2022-01-20 18:00:12,622 iteration 5844 : loss : 0.020521, loss_ce: 0.004739
2022-01-20 18:00:13,987 iteration 5845 : loss : 0.027371, loss_ce: 0.011740
2022-01-20 18:00:15,287 iteration 5846 : loss : 0.014115, loss_ce: 0.006164
2022-01-20 18:00:16,578 iteration 5847 : loss : 0.013850, loss_ce: 0.004848
2022-01-20 18:00:17,801 iteration 5848 : loss : 0.011589, loss_ce: 0.003619
 86%|████████████████████████▉    | 344/400 [2:20:06<21:41, 23.24s/it]2022-01-20 18:00:19,113 iteration 5849 : loss : 0.012573, loss_ce: 0.004205
2022-01-20 18:00:20,492 iteration 5850 : loss : 0.021737, loss_ce: 0.006189
2022-01-20 18:00:21,744 iteration 5851 : loss : 0.028065, loss_ce: 0.016240
2022-01-20 18:00:23,015 iteration 5852 : loss : 0.013450, loss_ce: 0.005052
2022-01-20 18:00:24,247 iteration 5853 : loss : 0.018025, loss_ce: 0.005718
2022-01-20 18:00:25,548 iteration 5854 : loss : 0.021328, loss_ce: 0.006881
2022-01-20 18:00:26,833 iteration 5855 : loss : 0.014046, loss_ce: 0.003738
2022-01-20 18:00:28,069 iteration 5856 : loss : 0.011411, loss_ce: 0.004798
2022-01-20 18:00:29,397 iteration 5857 : loss : 0.012678, loss_ce: 0.005339
2022-01-20 18:00:30,661 iteration 5858 : loss : 0.020280, loss_ce: 0.006166
2022-01-20 18:00:32,017 iteration 5859 : loss : 0.016165, loss_ce: 0.008211
2022-01-20 18:00:33,332 iteration 5860 : loss : 0.012466, loss_ce: 0.005118
2022-01-20 18:00:34,652 iteration 5861 : loss : 0.015915, loss_ce: 0.007733
2022-01-20 18:00:35,925 iteration 5862 : loss : 0.010571, loss_ce: 0.004305
2022-01-20 18:00:37,205 iteration 5863 : loss : 0.019280, loss_ce: 0.007516
2022-01-20 18:00:38,485 iteration 5864 : loss : 0.014268, loss_ce: 0.005439
2022-01-20 18:00:38,485 Training Data Eval:
2022-01-20 18:00:44,999   Average segmentation loss on training set: 0.0085
2022-01-20 18:00:44,999 Validation Data Eval:
2022-01-20 18:00:47,223   Average segmentation loss on validation set: 0.0692
2022-01-20 18:00:48,506 iteration 5865 : loss : 0.012207, loss_ce: 0.004366
 86%|█████████████████████████    | 345/400 [2:20:37<23:21, 25.48s/it]2022-01-20 18:00:49,900 iteration 5866 : loss : 0.027122, loss_ce: 0.009606
2022-01-20 18:00:51,222 iteration 5867 : loss : 0.012495, loss_ce: 0.005272
2022-01-20 18:00:52,444 iteration 5868 : loss : 0.010828, loss_ce: 0.004282
2022-01-20 18:00:53,712 iteration 5869 : loss : 0.011482, loss_ce: 0.004273
2022-01-20 18:00:54,922 iteration 5870 : loss : 0.013156, loss_ce: 0.004859
2022-01-20 18:00:56,213 iteration 5871 : loss : 0.013011, loss_ce: 0.005928
2022-01-20 18:00:57,535 iteration 5872 : loss : 0.013177, loss_ce: 0.005909
2022-01-20 18:00:58,764 iteration 5873 : loss : 0.012302, loss_ce: 0.005533
2022-01-20 18:01:00,015 iteration 5874 : loss : 0.019620, loss_ce: 0.004582
2022-01-20 18:01:01,412 iteration 5875 : loss : 0.014483, loss_ce: 0.006433
2022-01-20 18:01:02,811 iteration 5876 : loss : 0.022818, loss_ce: 0.009689
2022-01-20 18:01:04,147 iteration 5877 : loss : 0.014695, loss_ce: 0.005286
2022-01-20 18:01:05,495 iteration 5878 : loss : 0.019180, loss_ce: 0.004911
2022-01-20 18:01:06,749 iteration 5879 : loss : 0.015093, loss_ce: 0.004063
2022-01-20 18:01:08,025 iteration 5880 : loss : 0.017156, loss_ce: 0.006127
2022-01-20 18:01:09,372 iteration 5881 : loss : 0.034928, loss_ce: 0.008017
2022-01-20 18:01:10,652 iteration 5882 : loss : 0.012485, loss_ce: 0.004468
 86%|█████████████████████████    | 346/400 [2:20:59<22:01, 24.48s/it]2022-01-20 18:01:12,136 iteration 5883 : loss : 0.017593, loss_ce: 0.006381
2022-01-20 18:01:13,382 iteration 5884 : loss : 0.015941, loss_ce: 0.006990
2022-01-20 18:01:14,738 iteration 5885 : loss : 0.024846, loss_ce: 0.006175
2022-01-20 18:01:15,994 iteration 5886 : loss : 0.008302, loss_ce: 0.002739
2022-01-20 18:01:17,272 iteration 5887 : loss : 0.019096, loss_ce: 0.005503
2022-01-20 18:01:18,477 iteration 5888 : loss : 0.011462, loss_ce: 0.004945
2022-01-20 18:01:19,781 iteration 5889 : loss : 0.019979, loss_ce: 0.008076
2022-01-20 18:01:21,150 iteration 5890 : loss : 0.035007, loss_ce: 0.015503
2022-01-20 18:01:22,516 iteration 5891 : loss : 0.020148, loss_ce: 0.006692
2022-01-20 18:01:23,900 iteration 5892 : loss : 0.014414, loss_ce: 0.006611
2022-01-20 18:01:25,133 iteration 5893 : loss : 0.011956, loss_ce: 0.003422
2022-01-20 18:01:26,411 iteration 5894 : loss : 0.011947, loss_ce: 0.003738
2022-01-20 18:01:27,793 iteration 5895 : loss : 0.022904, loss_ce: 0.009097
2022-01-20 18:01:29,002 iteration 5896 : loss : 0.011973, loss_ce: 0.004165
2022-01-20 18:01:30,339 iteration 5897 : loss : 0.014740, loss_ce: 0.006383
2022-01-20 18:01:31,710 iteration 5898 : loss : 0.020397, loss_ce: 0.008251
2022-01-20 18:01:33,001 iteration 5899 : loss : 0.017392, loss_ce: 0.005328
 87%|█████████████████████████▏   | 347/400 [2:21:21<21:03, 23.84s/it]2022-01-20 18:01:34,260 iteration 5900 : loss : 0.009044, loss_ce: 0.003722
2022-01-20 18:01:35,526 iteration 5901 : loss : 0.012147, loss_ce: 0.005112
2022-01-20 18:01:36,754 iteration 5902 : loss : 0.010586, loss_ce: 0.004174
2022-01-20 18:01:38,021 iteration 5903 : loss : 0.016109, loss_ce: 0.006281
2022-01-20 18:01:39,342 iteration 5904 : loss : 0.014948, loss_ce: 0.004782
2022-01-20 18:01:40,688 iteration 5905 : loss : 0.017704, loss_ce: 0.008490
2022-01-20 18:01:42,062 iteration 5906 : loss : 0.013434, loss_ce: 0.003225
2022-01-20 18:01:43,275 iteration 5907 : loss : 0.010403, loss_ce: 0.004715
2022-01-20 18:01:44,566 iteration 5908 : loss : 0.014966, loss_ce: 0.004999
2022-01-20 18:01:45,944 iteration 5909 : loss : 0.014096, loss_ce: 0.006877
2022-01-20 18:01:47,232 iteration 5910 : loss : 0.011911, loss_ce: 0.003785
2022-01-20 18:01:48,581 iteration 5911 : loss : 0.021146, loss_ce: 0.005450
2022-01-20 18:01:49,892 iteration 5912 : loss : 0.023125, loss_ce: 0.005452
2022-01-20 18:01:51,179 iteration 5913 : loss : 0.015185, loss_ce: 0.007271
2022-01-20 18:01:52,450 iteration 5914 : loss : 0.014289, loss_ce: 0.007282
2022-01-20 18:01:53,777 iteration 5915 : loss : 0.015496, loss_ce: 0.007661
2022-01-20 18:01:55,008 iteration 5916 : loss : 0.010966, loss_ce: 0.003806
 87%|█████████████████████████▏   | 348/400 [2:21:43<20:11, 23.29s/it]2022-01-20 18:01:56,304 iteration 5917 : loss : 0.015851, loss_ce: 0.006983
2022-01-20 18:01:57,694 iteration 5918 : loss : 0.023346, loss_ce: 0.012391
2022-01-20 18:01:59,084 iteration 5919 : loss : 0.020064, loss_ce: 0.007651
2022-01-20 18:02:00,458 iteration 5920 : loss : 0.014209, loss_ce: 0.004802
2022-01-20 18:02:01,729 iteration 5921 : loss : 0.016531, loss_ce: 0.005379
2022-01-20 18:02:03,076 iteration 5922 : loss : 0.019025, loss_ce: 0.010310
2022-01-20 18:02:04,398 iteration 5923 : loss : 0.014811, loss_ce: 0.006346
2022-01-20 18:02:05,616 iteration 5924 : loss : 0.011143, loss_ce: 0.003787
2022-01-20 18:02:06,928 iteration 5925 : loss : 0.013285, loss_ce: 0.004527
2022-01-20 18:02:08,336 iteration 5926 : loss : 0.016164, loss_ce: 0.004307
2022-01-20 18:02:09,608 iteration 5927 : loss : 0.010255, loss_ce: 0.004401
2022-01-20 18:02:10,988 iteration 5928 : loss : 0.017913, loss_ce: 0.007774
2022-01-20 18:02:12,325 iteration 5929 : loss : 0.014358, loss_ce: 0.006383
2022-01-20 18:02:13,717 iteration 5930 : loss : 0.013183, loss_ce: 0.005001
2022-01-20 18:02:14,956 iteration 5931 : loss : 0.014148, loss_ce: 0.006210
2022-01-20 18:02:16,276 iteration 5932 : loss : 0.011879, loss_ce: 0.004012
2022-01-20 18:02:17,633 iteration 5933 : loss : 0.028556, loss_ce: 0.007804
 87%|█████████████████████████▎   | 349/400 [2:22:06<19:37, 23.09s/it]2022-01-20 18:02:19,039 iteration 5934 : loss : 0.009933, loss_ce: 0.003279
2022-01-20 18:02:20,373 iteration 5935 : loss : 0.014290, loss_ce: 0.004221
2022-01-20 18:02:21,819 iteration 5936 : loss : 0.021967, loss_ce: 0.007086
2022-01-20 18:02:23,215 iteration 5937 : loss : 0.014850, loss_ce: 0.006174
2022-01-20 18:02:24,536 iteration 5938 : loss : 0.015968, loss_ce: 0.005247
2022-01-20 18:02:25,820 iteration 5939 : loss : 0.017130, loss_ce: 0.007092
2022-01-20 18:02:27,170 iteration 5940 : loss : 0.014795, loss_ce: 0.006007
2022-01-20 18:02:28,413 iteration 5941 : loss : 0.010626, loss_ce: 0.004952
2022-01-20 18:02:29,781 iteration 5942 : loss : 0.031940, loss_ce: 0.009825
2022-01-20 18:02:31,008 iteration 5943 : loss : 0.009297, loss_ce: 0.003454
2022-01-20 18:02:32,316 iteration 5944 : loss : 0.019313, loss_ce: 0.006068
2022-01-20 18:02:33,601 iteration 5945 : loss : 0.011037, loss_ce: 0.003550
2022-01-20 18:02:34,851 iteration 5946 : loss : 0.015925, loss_ce: 0.005925
2022-01-20 18:02:36,096 iteration 5947 : loss : 0.012372, loss_ce: 0.004806
2022-01-20 18:02:37,470 iteration 5948 : loss : 0.020129, loss_ce: 0.009575
2022-01-20 18:02:38,729 iteration 5949 : loss : 0.012453, loss_ce: 0.005969
2022-01-20 18:02:38,729 Training Data Eval:
2022-01-20 18:02:45,241   Average segmentation loss on training set: 0.0083
2022-01-20 18:02:45,241 Validation Data Eval:
2022-01-20 18:02:47,443   Average segmentation loss on validation set: 0.0905
2022-01-20 18:02:48,835 iteration 5950 : loss : 0.026761, loss_ce: 0.007276
 88%|█████████████████████████▍   | 350/400 [2:22:37<21:16, 25.54s/it]2022-01-20 18:02:50,202 iteration 5951 : loss : 0.010414, loss_ce: 0.002729
2022-01-20 18:02:51,501 iteration 5952 : loss : 0.012281, loss_ce: 0.006061
2022-01-20 18:02:52,814 iteration 5953 : loss : 0.013434, loss_ce: 0.005913
2022-01-20 18:02:54,203 iteration 5954 : loss : 0.034879, loss_ce: 0.011336
2022-01-20 18:02:55,485 iteration 5955 : loss : 0.011618, loss_ce: 0.004189
2022-01-20 18:02:56,874 iteration 5956 : loss : 0.022851, loss_ce: 0.006899
2022-01-20 18:02:58,154 iteration 5957 : loss : 0.014297, loss_ce: 0.004452
2022-01-20 18:02:59,417 iteration 5958 : loss : 0.011477, loss_ce: 0.005054
2022-01-20 18:03:00,713 iteration 5959 : loss : 0.012426, loss_ce: 0.004094
2022-01-20 18:03:01,966 iteration 5960 : loss : 0.008161, loss_ce: 0.002504
2022-01-20 18:03:03,301 iteration 5961 : loss : 0.014082, loss_ce: 0.005525
2022-01-20 18:03:04,673 iteration 5962 : loss : 0.017961, loss_ce: 0.008147
2022-01-20 18:03:05,906 iteration 5963 : loss : 0.012340, loss_ce: 0.005322
2022-01-20 18:03:07,407 iteration 5964 : loss : 0.035388, loss_ce: 0.015275
2022-01-20 18:03:08,666 iteration 5965 : loss : 0.014527, loss_ce: 0.005738
2022-01-20 18:03:10,004 iteration 5966 : loss : 0.020492, loss_ce: 0.008067
2022-01-20 18:03:11,262 iteration 5967 : loss : 0.016444, loss_ce: 0.005372
 88%|█████████████████████████▍   | 351/400 [2:22:59<20:04, 24.59s/it]2022-01-20 18:03:12,598 iteration 5968 : loss : 0.013187, loss_ce: 0.006024
2022-01-20 18:03:13,959 iteration 5969 : loss : 0.028141, loss_ce: 0.008492
2022-01-20 18:03:15,280 iteration 5970 : loss : 0.013819, loss_ce: 0.004500
2022-01-20 18:03:16,494 iteration 5971 : loss : 0.011254, loss_ce: 0.004485
2022-01-20 18:03:17,757 iteration 5972 : loss : 0.014397, loss_ce: 0.005435
2022-01-20 18:03:19,079 iteration 5973 : loss : 0.010157, loss_ce: 0.004280
2022-01-20 18:03:20,325 iteration 5974 : loss : 0.012431, loss_ce: 0.004485
2022-01-20 18:03:21,664 iteration 5975 : loss : 0.021637, loss_ce: 0.007036
2022-01-20 18:03:22,998 iteration 5976 : loss : 0.019251, loss_ce: 0.005086
2022-01-20 18:03:24,338 iteration 5977 : loss : 0.014286, loss_ce: 0.004821
2022-01-20 18:03:25,669 iteration 5978 : loss : 0.012792, loss_ce: 0.005232
2022-01-20 18:03:26,936 iteration 5979 : loss : 0.011364, loss_ce: 0.004300
2022-01-20 18:03:28,317 iteration 5980 : loss : 0.009034, loss_ce: 0.003422
2022-01-20 18:03:29,716 iteration 5981 : loss : 0.025614, loss_ce: 0.012363
2022-01-20 18:03:31,122 iteration 5982 : loss : 0.022363, loss_ce: 0.008733
2022-01-20 18:03:32,388 iteration 5983 : loss : 0.011452, loss_ce: 0.005262
2022-01-20 18:03:33,687 iteration 5984 : loss : 0.013253, loss_ce: 0.004087
 88%|█████████████████████████▌   | 352/400 [2:23:22<19:09, 23.94s/it]2022-01-20 18:03:35,211 iteration 5985 : loss : 0.021174, loss_ce: 0.009497
2022-01-20 18:03:36,504 iteration 5986 : loss : 0.012910, loss_ce: 0.005262
2022-01-20 18:03:37,897 iteration 5987 : loss : 0.029351, loss_ce: 0.005014
2022-01-20 18:03:39,328 iteration 5988 : loss : 0.015321, loss_ce: 0.007174
2022-01-20 18:03:40,654 iteration 5989 : loss : 0.013267, loss_ce: 0.005215
2022-01-20 18:03:42,016 iteration 5990 : loss : 0.016023, loss_ce: 0.008329
2022-01-20 18:03:43,253 iteration 5991 : loss : 0.010768, loss_ce: 0.003870
2022-01-20 18:03:44,635 iteration 5992 : loss : 0.015550, loss_ce: 0.004192
2022-01-20 18:03:45,906 iteration 5993 : loss : 0.008339, loss_ce: 0.002872
2022-01-20 18:03:47,224 iteration 5994 : loss : 0.016172, loss_ce: 0.005304
2022-01-20 18:03:48,583 iteration 5995 : loss : 0.027267, loss_ce: 0.009817
2022-01-20 18:03:49,999 iteration 5996 : loss : 0.015382, loss_ce: 0.005000
2022-01-20 18:03:51,392 iteration 5997 : loss : 0.025394, loss_ce: 0.011963
2022-01-20 18:03:52,677 iteration 5998 : loss : 0.011091, loss_ce: 0.003983
2022-01-20 18:03:54,050 iteration 5999 : loss : 0.020106, loss_ce: 0.005367
2022-01-20 18:03:55,437 iteration 6000 : loss : 0.019908, loss_ce: 0.008858
2022-01-20 18:03:56,881 iteration 6001 : loss : 0.029471, loss_ce: 0.010135
 88%|█████████████████████████▌   | 353/400 [2:23:45<18:34, 23.72s/it]2022-01-20 18:03:58,297 iteration 6002 : loss : 0.017563, loss_ce: 0.006820
2022-01-20 18:03:59,703 iteration 6003 : loss : 0.017684, loss_ce: 0.005644
2022-01-20 18:04:01,038 iteration 6004 : loss : 0.014581, loss_ce: 0.006951
2022-01-20 18:04:02,425 iteration 6005 : loss : 0.011844, loss_ce: 0.005058
2022-01-20 18:04:03,709 iteration 6006 : loss : 0.012328, loss_ce: 0.006106
2022-01-20 18:04:05,049 iteration 6007 : loss : 0.012983, loss_ce: 0.004558
2022-01-20 18:04:06,362 iteration 6008 : loss : 0.013694, loss_ce: 0.004388
2022-01-20 18:04:07,782 iteration 6009 : loss : 0.021031, loss_ce: 0.007201
2022-01-20 18:04:08,993 iteration 6010 : loss : 0.010106, loss_ce: 0.004121
2022-01-20 18:04:10,342 iteration 6011 : loss : 0.029354, loss_ce: 0.010620
2022-01-20 18:04:11,655 iteration 6012 : loss : 0.018536, loss_ce: 0.005346
2022-01-20 18:04:13,095 iteration 6013 : loss : 0.017100, loss_ce: 0.006412
2022-01-20 18:04:14,401 iteration 6014 : loss : 0.013194, loss_ce: 0.004939
2022-01-20 18:04:15,671 iteration 6015 : loss : 0.016724, loss_ce: 0.006174
2022-01-20 18:04:16,998 iteration 6016 : loss : 0.012834, loss_ce: 0.003456
2022-01-20 18:04:18,254 iteration 6017 : loss : 0.020351, loss_ce: 0.005380
2022-01-20 18:04:19,676 iteration 6018 : loss : 0.016846, loss_ce: 0.006652
 88%|█████████████████████████▋   | 354/400 [2:24:08<17:58, 23.44s/it]2022-01-20 18:04:21,089 iteration 6019 : loss : 0.019183, loss_ce: 0.007485
2022-01-20 18:04:22,382 iteration 6020 : loss : 0.016647, loss_ce: 0.006853
2022-01-20 18:04:23,677 iteration 6021 : loss : 0.014176, loss_ce: 0.004697
2022-01-20 18:04:25,005 iteration 6022 : loss : 0.011187, loss_ce: 0.004454
2022-01-20 18:04:26,237 iteration 6023 : loss : 0.010829, loss_ce: 0.003560
2022-01-20 18:04:27,624 iteration 6024 : loss : 0.016080, loss_ce: 0.006657
2022-01-20 18:04:29,004 iteration 6025 : loss : 0.014810, loss_ce: 0.005919
2022-01-20 18:04:30,374 iteration 6026 : loss : 0.023072, loss_ce: 0.007452
2022-01-20 18:04:31,661 iteration 6027 : loss : 0.014759, loss_ce: 0.006534
2022-01-20 18:04:32,945 iteration 6028 : loss : 0.018134, loss_ce: 0.006963
2022-01-20 18:04:34,330 iteration 6029 : loss : 0.019223, loss_ce: 0.009095
2022-01-20 18:04:35,584 iteration 6030 : loss : 0.010848, loss_ce: 0.003800
2022-01-20 18:04:37,007 iteration 6031 : loss : 0.023094, loss_ce: 0.006127
2022-01-20 18:04:38,366 iteration 6032 : loss : 0.016125, loss_ce: 0.005237
2022-01-20 18:04:39,715 iteration 6033 : loss : 0.017588, loss_ce: 0.008311
2022-01-20 18:04:41,116 iteration 6034 : loss : 0.014129, loss_ce: 0.004178
2022-01-20 18:04:41,116 Training Data Eval:
2022-01-20 18:04:47,651   Average segmentation loss on training set: 0.0079
2022-01-20 18:04:47,652 Validation Data Eval:
2022-01-20 18:04:49,890   Average segmentation loss on validation set: 0.0686
2022-01-20 18:04:51,151 iteration 6035 : loss : 0.030494, loss_ce: 0.007399
 89%|█████████████████████████▋   | 355/400 [2:24:39<19:23, 25.85s/it]2022-01-20 18:04:52,561 iteration 6036 : loss : 0.019781, loss_ce: 0.007181
2022-01-20 18:04:53,939 iteration 6037 : loss : 0.023483, loss_ce: 0.008614
2022-01-20 18:04:55,196 iteration 6038 : loss : 0.017961, loss_ce: 0.007234
2022-01-20 18:04:56,498 iteration 6039 : loss : 0.019053, loss_ce: 0.010934
2022-01-20 18:04:57,787 iteration 6040 : loss : 0.011777, loss_ce: 0.005036
2022-01-20 18:04:59,225 iteration 6041 : loss : 0.028554, loss_ce: 0.010075
2022-01-20 18:05:00,592 iteration 6042 : loss : 0.019552, loss_ce: 0.007463
2022-01-20 18:05:01,899 iteration 6043 : loss : 0.012579, loss_ce: 0.005512
2022-01-20 18:05:03,192 iteration 6044 : loss : 0.015468, loss_ce: 0.005286
2022-01-20 18:05:04,557 iteration 6045 : loss : 0.022939, loss_ce: 0.008433
2022-01-20 18:05:05,866 iteration 6046 : loss : 0.014287, loss_ce: 0.004320
2022-01-20 18:05:07,152 iteration 6047 : loss : 0.013067, loss_ce: 0.003277
2022-01-20 18:05:08,603 iteration 6048 : loss : 0.038599, loss_ce: 0.009119
2022-01-20 18:05:09,973 iteration 6049 : loss : 0.017267, loss_ce: 0.007660
2022-01-20 18:05:11,253 iteration 6050 : loss : 0.016302, loss_ce: 0.006771
2022-01-20 18:05:12,638 iteration 6051 : loss : 0.014853, loss_ce: 0.006377
2022-01-20 18:05:13,851 iteration 6052 : loss : 0.012696, loss_ce: 0.003003
 89%|█████████████████████████▊   | 356/400 [2:25:02<18:15, 24.90s/it]2022-01-20 18:05:15,192 iteration 6053 : loss : 0.012889, loss_ce: 0.006067
2022-01-20 18:05:16,617 iteration 6054 : loss : 0.019204, loss_ce: 0.008179
2022-01-20 18:05:17,900 iteration 6055 : loss : 0.014950, loss_ce: 0.005059
2022-01-20 18:05:19,168 iteration 6056 : loss : 0.012757, loss_ce: 0.004757
2022-01-20 18:05:20,432 iteration 6057 : loss : 0.017286, loss_ce: 0.005268
2022-01-20 18:05:21,825 iteration 6058 : loss : 0.013522, loss_ce: 0.005546
2022-01-20 18:05:23,070 iteration 6059 : loss : 0.010981, loss_ce: 0.004295
2022-01-20 18:05:24,459 iteration 6060 : loss : 0.011213, loss_ce: 0.004353
2022-01-20 18:05:25,704 iteration 6061 : loss : 0.013914, loss_ce: 0.006149
2022-01-20 18:05:27,118 iteration 6062 : loss : 0.020834, loss_ce: 0.010282
2022-01-20 18:05:28,515 iteration 6063 : loss : 0.022742, loss_ce: 0.007978
2022-01-20 18:05:29,830 iteration 6064 : loss : 0.026295, loss_ce: 0.006526
2022-01-20 18:05:31,233 iteration 6065 : loss : 0.020077, loss_ce: 0.010679
2022-01-20 18:05:32,525 iteration 6066 : loss : 0.012206, loss_ce: 0.004604
2022-01-20 18:05:33,788 iteration 6067 : loss : 0.023165, loss_ce: 0.004534
2022-01-20 18:05:35,213 iteration 6068 : loss : 0.033357, loss_ce: 0.012015
2022-01-20 18:05:36,491 iteration 6069 : loss : 0.015041, loss_ce: 0.002660
 89%|█████████████████████████▉   | 357/400 [2:25:25<17:21, 24.23s/it]2022-01-20 18:05:37,929 iteration 6070 : loss : 0.018176, loss_ce: 0.010360
2022-01-20 18:05:39,275 iteration 6071 : loss : 0.019117, loss_ce: 0.006555
2022-01-20 18:05:40,597 iteration 6072 : loss : 0.013679, loss_ce: 0.004405
2022-01-20 18:05:41,939 iteration 6073 : loss : 0.022268, loss_ce: 0.007898
2022-01-20 18:05:43,265 iteration 6074 : loss : 0.016113, loss_ce: 0.005027
2022-01-20 18:05:44,653 iteration 6075 : loss : 0.014337, loss_ce: 0.006450
2022-01-20 18:05:45,933 iteration 6076 : loss : 0.012343, loss_ce: 0.005012
2022-01-20 18:05:47,196 iteration 6077 : loss : 0.013159, loss_ce: 0.005965
2022-01-20 18:05:48,481 iteration 6078 : loss : 0.017276, loss_ce: 0.006001
2022-01-20 18:05:49,810 iteration 6079 : loss : 0.017872, loss_ce: 0.004993
2022-01-20 18:05:51,125 iteration 6080 : loss : 0.017269, loss_ce: 0.004747
2022-01-20 18:05:52,334 iteration 6081 : loss : 0.014065, loss_ce: 0.004385
2022-01-20 18:05:53,703 iteration 6082 : loss : 0.024227, loss_ce: 0.010086
2022-01-20 18:05:55,097 iteration 6083 : loss : 0.020606, loss_ce: 0.008291
2022-01-20 18:05:56,341 iteration 6084 : loss : 0.021561, loss_ce: 0.010410
2022-01-20 18:05:57,595 iteration 6085 : loss : 0.015937, loss_ce: 0.007688
2022-01-20 18:05:59,018 iteration 6086 : loss : 0.027586, loss_ce: 0.011028
 90%|█████████████████████████▉   | 358/400 [2:25:47<16:35, 23.71s/it]2022-01-20 18:06:00,411 iteration 6087 : loss : 0.019406, loss_ce: 0.006095
2022-01-20 18:06:01,714 iteration 6088 : loss : 0.019575, loss_ce: 0.006214
2022-01-20 18:06:03,074 iteration 6089 : loss : 0.018931, loss_ce: 0.008756
2022-01-20 18:06:04,348 iteration 6090 : loss : 0.016805, loss_ce: 0.004933
2022-01-20 18:06:05,596 iteration 6091 : loss : 0.010230, loss_ce: 0.002954
2022-01-20 18:06:06,987 iteration 6092 : loss : 0.016785, loss_ce: 0.005780
2022-01-20 18:06:08,402 iteration 6093 : loss : 0.017963, loss_ce: 0.008096
2022-01-20 18:06:09,770 iteration 6094 : loss : 0.013298, loss_ce: 0.006092
2022-01-20 18:06:10,992 iteration 6095 : loss : 0.018019, loss_ce: 0.004382
2022-01-20 18:06:12,393 iteration 6096 : loss : 0.022073, loss_ce: 0.004556
2022-01-20 18:06:13,647 iteration 6097 : loss : 0.013805, loss_ce: 0.007202
2022-01-20 18:06:15,042 iteration 6098 : loss : 0.016016, loss_ce: 0.008996
2022-01-20 18:06:16,343 iteration 6099 : loss : 0.015137, loss_ce: 0.007057
2022-01-20 18:06:17,687 iteration 6100 : loss : 0.019616, loss_ce: 0.005973
2022-01-20 18:06:19,090 iteration 6101 : loss : 0.017714, loss_ce: 0.007674
2022-01-20 18:06:20,350 iteration 6102 : loss : 0.013493, loss_ce: 0.005885
2022-01-20 18:06:21,685 iteration 6103 : loss : 0.020004, loss_ce: 0.004951
 90%|██████████████████████████   | 359/400 [2:26:10<15:59, 23.40s/it]2022-01-20 18:06:23,118 iteration 6104 : loss : 0.016958, loss_ce: 0.007244
2022-01-20 18:06:24,387 iteration 6105 : loss : 0.016236, loss_ce: 0.004503
2022-01-20 18:06:25,634 iteration 6106 : loss : 0.010876, loss_ce: 0.004485
2022-01-20 18:06:26,885 iteration 6107 : loss : 0.009375, loss_ce: 0.003904
2022-01-20 18:06:28,193 iteration 6108 : loss : 0.015291, loss_ce: 0.004818
2022-01-20 18:06:29,562 iteration 6109 : loss : 0.014895, loss_ce: 0.007045
2022-01-20 18:06:30,817 iteration 6110 : loss : 0.013554, loss_ce: 0.006990
2022-01-20 18:06:32,156 iteration 6111 : loss : 0.021131, loss_ce: 0.007011
2022-01-20 18:06:33,547 iteration 6112 : loss : 0.013146, loss_ce: 0.004078
2022-01-20 18:06:34,884 iteration 6113 : loss : 0.016735, loss_ce: 0.005374
2022-01-20 18:06:36,228 iteration 6114 : loss : 0.024638, loss_ce: 0.012142
2022-01-20 18:06:37,635 iteration 6115 : loss : 0.016124, loss_ce: 0.004465
2022-01-20 18:06:38,959 iteration 6116 : loss : 0.012864, loss_ce: 0.004285
2022-01-20 18:06:40,253 iteration 6117 : loss : 0.016436, loss_ce: 0.006154
2022-01-20 18:06:41,596 iteration 6118 : loss : 0.013641, loss_ce: 0.007247
2022-01-20 18:06:42,894 iteration 6119 : loss : 0.014223, loss_ce: 0.006068
2022-01-20 18:06:42,895 Training Data Eval:
2022-01-20 18:06:49,456   Average segmentation loss on training set: 0.0080
2022-01-20 18:06:49,457 Validation Data Eval:
2022-01-20 18:06:51,711   Average segmentation loss on validation set: 0.0690
2022-01-20 18:06:53,118 iteration 6120 : loss : 0.020008, loss_ce: 0.006820
 90%|██████████████████████████   | 360/400 [2:26:41<17:12, 25.81s/it]2022-01-20 18:06:54,571 iteration 6121 : loss : 0.013500, loss_ce: 0.004382
2022-01-20 18:06:55,905 iteration 6122 : loss : 0.014333, loss_ce: 0.005841
2022-01-20 18:06:57,234 iteration 6123 : loss : 0.014181, loss_ce: 0.004823
2022-01-20 18:06:58,666 iteration 6124 : loss : 0.017547, loss_ce: 0.006307
2022-01-20 18:07:00,011 iteration 6125 : loss : 0.012598, loss_ce: 0.004266
2022-01-20 18:07:01,465 iteration 6126 : loss : 0.017730, loss_ce: 0.006933
2022-01-20 18:07:02,911 iteration 6127 : loss : 0.019984, loss_ce: 0.009896
2022-01-20 18:07:04,224 iteration 6128 : loss : 0.014052, loss_ce: 0.005294
2022-01-20 18:07:05,481 iteration 6129 : loss : 0.018466, loss_ce: 0.005812
2022-01-20 18:07:06,817 iteration 6130 : loss : 0.016084, loss_ce: 0.006733
2022-01-20 18:07:08,083 iteration 6131 : loss : 0.013582, loss_ce: 0.004216
2022-01-20 18:07:09,460 iteration 6132 : loss : 0.015508, loss_ce: 0.005943
2022-01-20 18:07:10,823 iteration 6133 : loss : 0.015951, loss_ce: 0.006530
2022-01-20 18:07:12,107 iteration 6134 : loss : 0.013177, loss_ce: 0.005031
2022-01-20 18:07:13,370 iteration 6135 : loss : 0.013297, loss_ce: 0.006167
2022-01-20 18:07:14,649 iteration 6136 : loss : 0.010611, loss_ce: 0.002866
2022-01-20 18:07:15,924 iteration 6137 : loss : 0.015347, loss_ce: 0.006373
 90%|██████████████████████████▏  | 361/400 [2:27:04<16:11, 24.91s/it]2022-01-20 18:07:17,249 iteration 6138 : loss : 0.015620, loss_ce: 0.005403
2022-01-20 18:07:18,519 iteration 6139 : loss : 0.011630, loss_ce: 0.002483
2022-01-20 18:07:19,779 iteration 6140 : loss : 0.013020, loss_ce: 0.004371
2022-01-20 18:07:21,010 iteration 6141 : loss : 0.016362, loss_ce: 0.008442
2022-01-20 18:07:22,361 iteration 6142 : loss : 0.014718, loss_ce: 0.006501
2022-01-20 18:07:23,617 iteration 6143 : loss : 0.012841, loss_ce: 0.005631
2022-01-20 18:07:25,032 iteration 6144 : loss : 0.023791, loss_ce: 0.011121
2022-01-20 18:07:26,294 iteration 6145 : loss : 0.013161, loss_ce: 0.005466
2022-01-20 18:07:27,526 iteration 6146 : loss : 0.013606, loss_ce: 0.003754
2022-01-20 18:07:28,827 iteration 6147 : loss : 0.013532, loss_ce: 0.005054
2022-01-20 18:07:30,117 iteration 6148 : loss : 0.014758, loss_ce: 0.005924
2022-01-20 18:07:31,382 iteration 6149 : loss : 0.020576, loss_ce: 0.007835
2022-01-20 18:07:32,722 iteration 6150 : loss : 0.011834, loss_ce: 0.004245
2022-01-20 18:07:34,180 iteration 6151 : loss : 0.019107, loss_ce: 0.007088
2022-01-20 18:07:35,468 iteration 6152 : loss : 0.012853, loss_ce: 0.005515
2022-01-20 18:07:36,794 iteration 6153 : loss : 0.011484, loss_ce: 0.004338
2022-01-20 18:07:38,184 iteration 6154 : loss : 0.021675, loss_ce: 0.007518
 90%|██████████████████████████▏  | 362/400 [2:27:26<15:16, 24.11s/it]2022-01-20 18:07:39,624 iteration 6155 : loss : 0.026476, loss_ce: 0.010278
2022-01-20 18:07:40,853 iteration 6156 : loss : 0.009874, loss_ce: 0.004080
2022-01-20 18:07:42,130 iteration 6157 : loss : 0.010275, loss_ce: 0.003159
2022-01-20 18:07:43,452 iteration 6158 : loss : 0.022464, loss_ce: 0.008139
2022-01-20 18:07:44,703 iteration 6159 : loss : 0.018182, loss_ce: 0.005430
2022-01-20 18:07:46,007 iteration 6160 : loss : 0.013157, loss_ce: 0.005470
2022-01-20 18:07:47,323 iteration 6161 : loss : 0.013814, loss_ce: 0.004229
2022-01-20 18:07:48,678 iteration 6162 : loss : 0.018773, loss_ce: 0.003789
2022-01-20 18:07:50,002 iteration 6163 : loss : 0.014655, loss_ce: 0.007034
2022-01-20 18:07:51,387 iteration 6164 : loss : 0.015577, loss_ce: 0.007033
2022-01-20 18:07:52,690 iteration 6165 : loss : 0.017132, loss_ce: 0.007288
2022-01-20 18:07:53,995 iteration 6166 : loss : 0.010139, loss_ce: 0.004283
2022-01-20 18:07:55,263 iteration 6167 : loss : 0.012497, loss_ce: 0.005038
2022-01-20 18:07:56,623 iteration 6168 : loss : 0.014800, loss_ce: 0.005475
2022-01-20 18:07:57,951 iteration 6169 : loss : 0.026938, loss_ce: 0.011879
2022-01-20 18:07:59,232 iteration 6170 : loss : 0.012898, loss_ce: 0.004777
2022-01-20 18:08:00,494 iteration 6171 : loss : 0.011188, loss_ce: 0.004462
 91%|██████████████████████████▎  | 363/400 [2:27:49<14:32, 23.57s/it]2022-01-20 18:08:01,864 iteration 6172 : loss : 0.011315, loss_ce: 0.003838
2022-01-20 18:08:03,258 iteration 6173 : loss : 0.027965, loss_ce: 0.011126
2022-01-20 18:08:04,550 iteration 6174 : loss : 0.012816, loss_ce: 0.004559
2022-01-20 18:08:05,903 iteration 6175 : loss : 0.020968, loss_ce: 0.008408
2022-01-20 18:08:07,217 iteration 6176 : loss : 0.012079, loss_ce: 0.004705
2022-01-20 18:08:08,625 iteration 6177 : loss : 0.028874, loss_ce: 0.013879
2022-01-20 18:08:09,935 iteration 6178 : loss : 0.014052, loss_ce: 0.006523
2022-01-20 18:08:11,242 iteration 6179 : loss : 0.011788, loss_ce: 0.005640
2022-01-20 18:08:12,567 iteration 6180 : loss : 0.010547, loss_ce: 0.003406
2022-01-20 18:08:13,780 iteration 6181 : loss : 0.009676, loss_ce: 0.003239
2022-01-20 18:08:15,116 iteration 6182 : loss : 0.018703, loss_ce: 0.005394
2022-01-20 18:08:16,525 iteration 6183 : loss : 0.014808, loss_ce: 0.006041
2022-01-20 18:08:17,901 iteration 6184 : loss : 0.025098, loss_ce: 0.007738
2022-01-20 18:08:19,190 iteration 6185 : loss : 0.014350, loss_ce: 0.005395
2022-01-20 18:08:20,510 iteration 6186 : loss : 0.014226, loss_ce: 0.004978
2022-01-20 18:08:21,891 iteration 6187 : loss : 0.011686, loss_ce: 0.004218
2022-01-20 18:08:23,105 iteration 6188 : loss : 0.012909, loss_ce: 0.004362
 91%|██████████████████████████▍  | 364/400 [2:28:11<13:58, 23.28s/it]2022-01-20 18:08:24,399 iteration 6189 : loss : 0.011658, loss_ce: 0.003069
2022-01-20 18:08:25,607 iteration 6190 : loss : 0.013170, loss_ce: 0.004400
2022-01-20 18:08:27,071 iteration 6191 : loss : 0.020154, loss_ce: 0.007664
2022-01-20 18:08:28,424 iteration 6192 : loss : 0.010670, loss_ce: 0.003804
2022-01-20 18:08:29,601 iteration 6193 : loss : 0.008547, loss_ce: 0.003350
2022-01-20 18:08:30,907 iteration 6194 : loss : 0.012951, loss_ce: 0.004646
2022-01-20 18:08:32,261 iteration 6195 : loss : 0.012353, loss_ce: 0.004905
2022-01-20 18:08:33,617 iteration 6196 : loss : 0.012389, loss_ce: 0.005239
2022-01-20 18:08:34,935 iteration 6197 : loss : 0.014279, loss_ce: 0.007037
2022-01-20 18:08:36,224 iteration 6198 : loss : 0.014199, loss_ce: 0.005773
2022-01-20 18:08:37,520 iteration 6199 : loss : 0.014302, loss_ce: 0.004213
2022-01-20 18:08:38,731 iteration 6200 : loss : 0.008757, loss_ce: 0.003968
2022-01-20 18:08:40,058 iteration 6201 : loss : 0.021010, loss_ce: 0.007242
2022-01-20 18:08:41,311 iteration 6202 : loss : 0.011820, loss_ce: 0.004879
2022-01-20 18:08:42,573 iteration 6203 : loss : 0.011367, loss_ce: 0.002879
2022-01-20 18:08:43,898 iteration 6204 : loss : 0.013133, loss_ce: 0.005749
2022-01-20 18:08:43,898 Training Data Eval:
2022-01-20 18:08:50,399   Average segmentation loss on training set: 0.0078
2022-01-20 18:08:50,399 Validation Data Eval:
2022-01-20 18:08:52,617   Average segmentation loss on validation set: 0.0756
2022-01-20 18:08:53,954 iteration 6205 : loss : 0.022322, loss_ce: 0.007003
 91%|██████████████████████████▍  | 365/400 [2:28:42<14:54, 25.56s/it]2022-01-20 18:08:55,380 iteration 6206 : loss : 0.013113, loss_ce: 0.006361
2022-01-20 18:08:56,641 iteration 6207 : loss : 0.011986, loss_ce: 0.003400
2022-01-20 18:08:58,033 iteration 6208 : loss : 0.021990, loss_ce: 0.011770
2022-01-20 18:08:59,300 iteration 6209 : loss : 0.011668, loss_ce: 0.003209
2022-01-20 18:09:00,541 iteration 6210 : loss : 0.012965, loss_ce: 0.004858
2022-01-20 18:09:01,877 iteration 6211 : loss : 0.016159, loss_ce: 0.006922
2022-01-20 18:09:03,146 iteration 6212 : loss : 0.013127, loss_ce: 0.004176
2022-01-20 18:09:04,426 iteration 6213 : loss : 0.018616, loss_ce: 0.006581
2022-01-20 18:09:05,700 iteration 6214 : loss : 0.015961, loss_ce: 0.003262
2022-01-20 18:09:07,042 iteration 6215 : loss : 0.015433, loss_ce: 0.007191
2022-01-20 18:09:08,348 iteration 6216 : loss : 0.021054, loss_ce: 0.006743
2022-01-20 18:09:09,557 iteration 6217 : loss : 0.012586, loss_ce: 0.004393
2022-01-20 18:09:10,860 iteration 6218 : loss : 0.010095, loss_ce: 0.004814
2022-01-20 18:09:12,133 iteration 6219 : loss : 0.013335, loss_ce: 0.004932
2022-01-20 18:09:13,432 iteration 6220 : loss : 0.014548, loss_ce: 0.004594
2022-01-20 18:09:14,823 iteration 6221 : loss : 0.013817, loss_ce: 0.006172
2022-01-20 18:09:16,124 iteration 6222 : loss : 0.016827, loss_ce: 0.007590
 92%|██████████████████████████▌  | 366/400 [2:29:04<13:54, 24.54s/it]2022-01-20 18:09:17,503 iteration 6223 : loss : 0.022534, loss_ce: 0.006609
2022-01-20 18:09:18,768 iteration 6224 : loss : 0.015315, loss_ce: 0.004901
2022-01-20 18:09:20,046 iteration 6225 : loss : 0.015535, loss_ce: 0.005968
2022-01-20 18:09:21,440 iteration 6226 : loss : 0.018658, loss_ce: 0.007767
2022-01-20 18:09:22,744 iteration 6227 : loss : 0.021597, loss_ce: 0.005169
2022-01-20 18:09:24,083 iteration 6228 : loss : 0.016105, loss_ce: 0.006316
2022-01-20 18:09:25,323 iteration 6229 : loss : 0.010993, loss_ce: 0.004567
2022-01-20 18:09:26,583 iteration 6230 : loss : 0.015022, loss_ce: 0.006157
2022-01-20 18:09:27,913 iteration 6231 : loss : 0.012290, loss_ce: 0.005402
2022-01-20 18:09:29,248 iteration 6232 : loss : 0.013990, loss_ce: 0.005735
2022-01-20 18:09:30,547 iteration 6233 : loss : 0.013735, loss_ce: 0.006048
2022-01-20 18:09:31,887 iteration 6234 : loss : 0.018485, loss_ce: 0.006682
2022-01-20 18:09:33,291 iteration 6235 : loss : 0.025728, loss_ce: 0.005633
2022-01-20 18:09:34,503 iteration 6236 : loss : 0.010875, loss_ce: 0.004402
2022-01-20 18:09:35,806 iteration 6237 : loss : 0.016067, loss_ce: 0.007543
2022-01-20 18:09:37,050 iteration 6238 : loss : 0.007452, loss_ce: 0.002779
2022-01-20 18:09:38,315 iteration 6239 : loss : 0.010697, loss_ce: 0.004576
 92%|██████████████████████████▌  | 367/400 [2:29:26<13:06, 23.83s/it]2022-01-20 18:09:39,730 iteration 6240 : loss : 0.017128, loss_ce: 0.007586
2022-01-20 18:09:41,078 iteration 6241 : loss : 0.021542, loss_ce: 0.010078
2022-01-20 18:09:42,422 iteration 6242 : loss : 0.011438, loss_ce: 0.004194
2022-01-20 18:09:43,643 iteration 6243 : loss : 0.015061, loss_ce: 0.005545
2022-01-20 18:09:44,901 iteration 6244 : loss : 0.010666, loss_ce: 0.003202
2022-01-20 18:09:46,180 iteration 6245 : loss : 0.012031, loss_ce: 0.004631
2022-01-20 18:09:47,440 iteration 6246 : loss : 0.014253, loss_ce: 0.005519
2022-01-20 18:09:48,699 iteration 6247 : loss : 0.014216, loss_ce: 0.003548
2022-01-20 18:09:50,089 iteration 6248 : loss : 0.015466, loss_ce: 0.006639
2022-01-20 18:09:51,362 iteration 6249 : loss : 0.013615, loss_ce: 0.005212
2022-01-20 18:09:52,688 iteration 6250 : loss : 0.015781, loss_ce: 0.006831
2022-01-20 18:09:54,097 iteration 6251 : loss : 0.012958, loss_ce: 0.004682
2022-01-20 18:09:55,473 iteration 6252 : loss : 0.027852, loss_ce: 0.007703
2022-01-20 18:09:56,741 iteration 6253 : loss : 0.011248, loss_ce: 0.003788
2022-01-20 18:09:57,974 iteration 6254 : loss : 0.010329, loss_ce: 0.004288
2022-01-20 18:09:59,362 iteration 6255 : loss : 0.013221, loss_ce: 0.004951
2022-01-20 18:10:00,676 iteration 6256 : loss : 0.012083, loss_ce: 0.004391
 92%|██████████████████████████▋  | 368/400 [2:29:49<12:28, 23.39s/it]2022-01-20 18:10:02,087 iteration 6257 : loss : 0.013236, loss_ce: 0.004498
2022-01-20 18:10:03,343 iteration 6258 : loss : 0.009903, loss_ce: 0.003351
2022-01-20 18:10:04,734 iteration 6259 : loss : 0.015915, loss_ce: 0.006026
2022-01-20 18:10:06,205 iteration 6260 : loss : 0.022793, loss_ce: 0.005227
2022-01-20 18:10:07,542 iteration 6261 : loss : 0.017230, loss_ce: 0.008987
2022-01-20 18:10:08,917 iteration 6262 : loss : 0.014635, loss_ce: 0.005434
2022-01-20 18:10:10,196 iteration 6263 : loss : 0.014024, loss_ce: 0.004631
2022-01-20 18:10:11,446 iteration 6264 : loss : 0.012792, loss_ce: 0.005074
2022-01-20 18:10:12,768 iteration 6265 : loss : 0.017217, loss_ce: 0.006027
2022-01-20 18:10:14,051 iteration 6266 : loss : 0.010748, loss_ce: 0.003857
2022-01-20 18:10:15,555 iteration 6267 : loss : 0.019628, loss_ce: 0.008469
2022-01-20 18:10:16,842 iteration 6268 : loss : 0.016061, loss_ce: 0.006028
2022-01-20 18:10:18,153 iteration 6269 : loss : 0.012891, loss_ce: 0.004887
2022-01-20 18:10:19,429 iteration 6270 : loss : 0.013734, loss_ce: 0.006114
2022-01-20 18:10:20,838 iteration 6271 : loss : 0.014505, loss_ce: 0.005803
2022-01-20 18:10:22,082 iteration 6272 : loss : 0.026962, loss_ce: 0.008669
2022-01-20 18:10:23,476 iteration 6273 : loss : 0.016681, loss_ce: 0.006282
 92%|██████████████████████████▊  | 369/400 [2:30:12<11:59, 23.21s/it]2022-01-20 18:10:24,942 iteration 6274 : loss : 0.015679, loss_ce: 0.005821
2022-01-20 18:10:26,198 iteration 6275 : loss : 0.015959, loss_ce: 0.004169
2022-01-20 18:10:27,433 iteration 6276 : loss : 0.012535, loss_ce: 0.005168
2022-01-20 18:10:28,746 iteration 6277 : loss : 0.013913, loss_ce: 0.006337
2022-01-20 18:10:30,138 iteration 6278 : loss : 0.015419, loss_ce: 0.006016
2022-01-20 18:10:31,504 iteration 6279 : loss : 0.017444, loss_ce: 0.005605
2022-01-20 18:10:32,753 iteration 6280 : loss : 0.012773, loss_ce: 0.004221
2022-01-20 18:10:34,044 iteration 6281 : loss : 0.013937, loss_ce: 0.004013
2022-01-20 18:10:35,352 iteration 6282 : loss : 0.020322, loss_ce: 0.012107
2022-01-20 18:10:36,745 iteration 6283 : loss : 0.020827, loss_ce: 0.008505
2022-01-20 18:10:38,064 iteration 6284 : loss : 0.011678, loss_ce: 0.003642
2022-01-20 18:10:39,389 iteration 6285 : loss : 0.017087, loss_ce: 0.009848
2022-01-20 18:10:40,754 iteration 6286 : loss : 0.018569, loss_ce: 0.011265
2022-01-20 18:10:42,063 iteration 6287 : loss : 0.012740, loss_ce: 0.005171
2022-01-20 18:10:43,281 iteration 6288 : loss : 0.011598, loss_ce: 0.004140
2022-01-20 18:10:44,570 iteration 6289 : loss : 0.013253, loss_ce: 0.005305
2022-01-20 18:10:44,570 Training Data Eval:
2022-01-20 18:10:51,079   Average segmentation loss on training set: 0.0074
2022-01-20 18:10:51,080 Validation Data Eval:
2022-01-20 18:10:53,314   Average segmentation loss on validation set: 0.0716
2022-01-20 18:10:54,634 iteration 6290 : loss : 0.010291, loss_ce: 0.003655
 92%|██████████████████████████▊  | 370/400 [2:30:43<12:47, 25.60s/it]2022-01-20 18:10:55,973 iteration 6291 : loss : 0.014325, loss_ce: 0.004266
2022-01-20 18:10:57,179 iteration 6292 : loss : 0.010980, loss_ce: 0.003392
2022-01-20 18:10:58,456 iteration 6293 : loss : 0.014365, loss_ce: 0.003892
2022-01-20 18:10:59,873 iteration 6294 : loss : 0.022694, loss_ce: 0.006643
2022-01-20 18:11:01,183 iteration 6295 : loss : 0.013019, loss_ce: 0.004654
2022-01-20 18:11:02,411 iteration 6296 : loss : 0.012268, loss_ce: 0.004792
2022-01-20 18:11:03,811 iteration 6297 : loss : 0.022219, loss_ce: 0.011386
2022-01-20 18:11:05,138 iteration 6298 : loss : 0.014819, loss_ce: 0.007139
2022-01-20 18:11:06,474 iteration 6299 : loss : 0.015305, loss_ce: 0.006155
2022-01-20 18:11:07,852 iteration 6300 : loss : 0.013815, loss_ce: 0.003593
2022-01-20 18:11:09,196 iteration 6301 : loss : 0.012519, loss_ce: 0.005847
2022-01-20 18:11:10,591 iteration 6302 : loss : 0.015900, loss_ce: 0.006141
2022-01-20 18:11:11,872 iteration 6303 : loss : 0.011177, loss_ce: 0.004230
2022-01-20 18:11:13,220 iteration 6304 : loss : 0.017604, loss_ce: 0.007274
2022-01-20 18:11:14,519 iteration 6305 : loss : 0.012500, loss_ce: 0.004381
2022-01-20 18:11:15,849 iteration 6306 : loss : 0.015729, loss_ce: 0.008392
2022-01-20 18:11:17,152 iteration 6307 : loss : 0.011116, loss_ce: 0.003811
 93%|██████████████████████████▉  | 371/400 [2:31:05<11:55, 24.68s/it]2022-01-20 18:11:18,574 iteration 6308 : loss : 0.014899, loss_ce: 0.005386
2022-01-20 18:11:19,854 iteration 6309 : loss : 0.014452, loss_ce: 0.004123
2022-01-20 18:11:21,172 iteration 6310 : loss : 0.010331, loss_ce: 0.004002
2022-01-20 18:11:22,561 iteration 6311 : loss : 0.033974, loss_ce: 0.010892
2022-01-20 18:11:23,854 iteration 6312 : loss : 0.011244, loss_ce: 0.005035
2022-01-20 18:11:25,193 iteration 6313 : loss : 0.023025, loss_ce: 0.005886
2022-01-20 18:11:26,552 iteration 6314 : loss : 0.012613, loss_ce: 0.004652
2022-01-20 18:11:27,836 iteration 6315 : loss : 0.018709, loss_ce: 0.007919
2022-01-20 18:11:29,063 iteration 6316 : loss : 0.013477, loss_ce: 0.003894
2022-01-20 18:11:30,292 iteration 6317 : loss : 0.012915, loss_ce: 0.004533
2022-01-20 18:11:31,668 iteration 6318 : loss : 0.014908, loss_ce: 0.005574
2022-01-20 18:11:32,956 iteration 6319 : loss : 0.013754, loss_ce: 0.005288
2022-01-20 18:11:34,261 iteration 6320 : loss : 0.011495, loss_ce: 0.005290
2022-01-20 18:11:35,559 iteration 6321 : loss : 0.012093, loss_ce: 0.004446
2022-01-20 18:11:36,955 iteration 6322 : loss : 0.026974, loss_ce: 0.009332
2022-01-20 18:11:38,363 iteration 6323 : loss : 0.022051, loss_ce: 0.007881
2022-01-20 18:11:39,656 iteration 6324 : loss : 0.034524, loss_ce: 0.022697
 93%|██████████████████████████▉  | 372/400 [2:31:28<11:12, 24.03s/it]2022-01-20 18:11:40,976 iteration 6325 : loss : 0.012899, loss_ce: 0.005788
2022-01-20 18:11:42,211 iteration 6326 : loss : 0.010042, loss_ce: 0.004547
2022-01-20 18:11:43,582 iteration 6327 : loss : 0.012722, loss_ce: 0.005041
2022-01-20 18:11:44,858 iteration 6328 : loss : 0.010436, loss_ce: 0.003195
2022-01-20 18:11:46,105 iteration 6329 : loss : 0.014328, loss_ce: 0.004072
2022-01-20 18:11:47,414 iteration 6330 : loss : 0.011394, loss_ce: 0.003617
2022-01-20 18:11:48,944 iteration 6331 : loss : 0.019224, loss_ce: 0.006997
2022-01-20 18:11:50,193 iteration 6332 : loss : 0.012176, loss_ce: 0.004884
2022-01-20 18:11:51,527 iteration 6333 : loss : 0.013622, loss_ce: 0.004078
2022-01-20 18:11:52,824 iteration 6334 : loss : 0.011726, loss_ce: 0.005560
2022-01-20 18:11:54,237 iteration 6335 : loss : 0.021427, loss_ce: 0.008981
2022-01-20 18:11:55,453 iteration 6336 : loss : 0.007873, loss_ce: 0.002995
2022-01-20 18:11:56,785 iteration 6337 : loss : 0.016230, loss_ce: 0.006198
2022-01-20 18:11:58,195 iteration 6338 : loss : 0.024356, loss_ce: 0.004388
2022-01-20 18:11:59,475 iteration 6339 : loss : 0.021949, loss_ce: 0.010292
2022-01-20 18:12:00,748 iteration 6340 : loss : 0.012680, loss_ce: 0.006920
2022-01-20 18:12:02,066 iteration 6341 : loss : 0.017196, loss_ce: 0.005642
 93%|███████████████████████████  | 373/400 [2:31:50<10:35, 23.54s/it]2022-01-20 18:12:03,432 iteration 6342 : loss : 0.016733, loss_ce: 0.006215
2022-01-20 18:12:04,700 iteration 6343 : loss : 0.019405, loss_ce: 0.005585
2022-01-20 18:12:06,089 iteration 6344 : loss : 0.019862, loss_ce: 0.008232
2022-01-20 18:12:07,382 iteration 6345 : loss : 0.015619, loss_ce: 0.004873
2022-01-20 18:12:08,642 iteration 6346 : loss : 0.013769, loss_ce: 0.005522
2022-01-20 18:12:09,987 iteration 6347 : loss : 0.017632, loss_ce: 0.008300
2022-01-20 18:12:11,250 iteration 6348 : loss : 0.014688, loss_ce: 0.005992
2022-01-20 18:12:12,541 iteration 6349 : loss : 0.012509, loss_ce: 0.003802
2022-01-20 18:12:13,852 iteration 6350 : loss : 0.011475, loss_ce: 0.003904
2022-01-20 18:12:15,185 iteration 6351 : loss : 0.013738, loss_ce: 0.005857
2022-01-20 18:12:16,546 iteration 6352 : loss : 0.015535, loss_ce: 0.005342
2022-01-20 18:12:17,962 iteration 6353 : loss : 0.038669, loss_ce: 0.013710
2022-01-20 18:12:19,220 iteration 6354 : loss : 0.013229, loss_ce: 0.003575
2022-01-20 18:12:20,603 iteration 6355 : loss : 0.019340, loss_ce: 0.006719
2022-01-20 18:12:22,007 iteration 6356 : loss : 0.026141, loss_ce: 0.008056
2022-01-20 18:12:23,335 iteration 6357 : loss : 0.015051, loss_ce: 0.007445
2022-01-20 18:12:24,712 iteration 6358 : loss : 0.013237, loss_ce: 0.004202
 94%|███████████████████████████  | 374/400 [2:32:13<10:05, 23.27s/it]2022-01-20 18:12:26,067 iteration 6359 : loss : 0.012704, loss_ce: 0.004254
2022-01-20 18:12:27,246 iteration 6360 : loss : 0.008347, loss_ce: 0.002917
2022-01-20 18:12:28,642 iteration 6361 : loss : 0.019523, loss_ce: 0.006716
2022-01-20 18:12:29,963 iteration 6362 : loss : 0.011410, loss_ce: 0.004406
2022-01-20 18:12:31,385 iteration 6363 : loss : 0.021939, loss_ce: 0.007313
2022-01-20 18:12:32,749 iteration 6364 : loss : 0.010854, loss_ce: 0.003180
2022-01-20 18:12:34,058 iteration 6365 : loss : 0.014632, loss_ce: 0.006188
2022-01-20 18:12:35,369 iteration 6366 : loss : 0.013988, loss_ce: 0.005039
2022-01-20 18:12:36,742 iteration 6367 : loss : 0.040768, loss_ce: 0.023009
2022-01-20 18:12:38,089 iteration 6368 : loss : 0.019400, loss_ce: 0.004981
2022-01-20 18:12:39,397 iteration 6369 : loss : 0.011890, loss_ce: 0.002864
2022-01-20 18:12:40,741 iteration 6370 : loss : 0.016881, loss_ce: 0.008484
2022-01-20 18:12:41,994 iteration 6371 : loss : 0.009885, loss_ce: 0.004011
2022-01-20 18:12:43,334 iteration 6372 : loss : 0.016862, loss_ce: 0.007198
2022-01-20 18:12:44,595 iteration 6373 : loss : 0.010736, loss_ce: 0.004889
2022-01-20 18:12:45,799 iteration 6374 : loss : 0.009987, loss_ce: 0.003810
2022-01-20 18:12:45,799 Training Data Eval:
2022-01-20 18:12:52,397   Average segmentation loss on training set: 0.0075
2022-01-20 18:12:52,398 Validation Data Eval:
2022-01-20 18:12:54,650   Average segmentation loss on validation set: 0.0721
2022-01-20 18:12:56,027 iteration 6375 : loss : 0.023591, loss_ce: 0.014554
 94%|███████████████████████████▏ | 375/400 [2:32:44<10:42, 25.68s/it]2022-01-20 18:12:57,493 iteration 6376 : loss : 0.014943, loss_ce: 0.005243
2022-01-20 18:12:58,820 iteration 6377 : loss : 0.014535, loss_ce: 0.003661
2022-01-20 18:13:00,097 iteration 6378 : loss : 0.012694, loss_ce: 0.006449
2022-01-20 18:13:01,415 iteration 6379 : loss : 0.013037, loss_ce: 0.005362
2022-01-20 18:13:02,793 iteration 6380 : loss : 0.019357, loss_ce: 0.006199
2022-01-20 18:13:04,187 iteration 6381 : loss : 0.014924, loss_ce: 0.006152
2022-01-20 18:13:05,508 iteration 6382 : loss : 0.016243, loss_ce: 0.007882
2022-01-20 18:13:06,877 iteration 6383 : loss : 0.015805, loss_ce: 0.005793
2022-01-20 18:13:08,259 iteration 6384 : loss : 0.017371, loss_ce: 0.007072
2022-01-20 18:13:09,433 iteration 6385 : loss : 0.008456, loss_ce: 0.003430
2022-01-20 18:13:10,823 iteration 6386 : loss : 0.017344, loss_ce: 0.005504
2022-01-20 18:13:12,191 iteration 6387 : loss : 0.014596, loss_ce: 0.006436
2022-01-20 18:13:13,437 iteration 6388 : loss : 0.012785, loss_ce: 0.005764
2022-01-20 18:13:14,815 iteration 6389 : loss : 0.019547, loss_ce: 0.009446
2022-01-20 18:13:16,170 iteration 6390 : loss : 0.023369, loss_ce: 0.010745
2022-01-20 18:13:17,539 iteration 6391 : loss : 0.016336, loss_ce: 0.006922
2022-01-20 18:13:18,920 iteration 6392 : loss : 0.029125, loss_ce: 0.006070
 94%|███████████████████████████▎ | 376/400 [2:33:07<09:56, 24.84s/it]2022-01-20 18:13:20,259 iteration 6393 : loss : 0.012275, loss_ce: 0.006092
2022-01-20 18:13:21,558 iteration 6394 : loss : 0.010203, loss_ce: 0.004534
2022-01-20 18:13:22,833 iteration 6395 : loss : 0.008750, loss_ce: 0.002593
2022-01-20 18:13:24,191 iteration 6396 : loss : 0.014538, loss_ce: 0.005670
2022-01-20 18:13:25,561 iteration 6397 : loss : 0.015037, loss_ce: 0.004873
2022-01-20 18:13:26,931 iteration 6398 : loss : 0.013217, loss_ce: 0.004405
2022-01-20 18:13:28,159 iteration 6399 : loss : 0.014112, loss_ce: 0.003940
2022-01-20 18:13:29,448 iteration 6400 : loss : 0.011225, loss_ce: 0.004090
2022-01-20 18:13:30,682 iteration 6401 : loss : 0.008708, loss_ce: 0.003327
2022-01-20 18:13:32,045 iteration 6402 : loss : 0.016123, loss_ce: 0.006607
2022-01-20 18:13:33,313 iteration 6403 : loss : 0.013983, loss_ce: 0.006155
2022-01-20 18:13:34,549 iteration 6404 : loss : 0.009949, loss_ce: 0.004732
2022-01-20 18:13:36,011 iteration 6405 : loss : 0.021675, loss_ce: 0.008560
2022-01-20 18:13:37,231 iteration 6406 : loss : 0.009651, loss_ce: 0.003649
2022-01-20 18:13:38,548 iteration 6407 : loss : 0.018555, loss_ce: 0.007420
2022-01-20 18:13:39,895 iteration 6408 : loss : 0.015396, loss_ce: 0.005206
2022-01-20 18:13:41,146 iteration 6409 : loss : 0.009331, loss_ce: 0.003078
 94%|███████████████████████████▎ | 377/400 [2:33:29<09:13, 24.06s/it]2022-01-20 18:13:42,451 iteration 6410 : loss : 0.010990, loss_ce: 0.004055
2022-01-20 18:13:43,739 iteration 6411 : loss : 0.010841, loss_ce: 0.003990
2022-01-20 18:13:45,120 iteration 6412 : loss : 0.013112, loss_ce: 0.003954
2022-01-20 18:13:46,430 iteration 6413 : loss : 0.014609, loss_ce: 0.006674
2022-01-20 18:13:47,774 iteration 6414 : loss : 0.012436, loss_ce: 0.004816
2022-01-20 18:13:49,122 iteration 6415 : loss : 0.013771, loss_ce: 0.004092
2022-01-20 18:13:50,353 iteration 6416 : loss : 0.012016, loss_ce: 0.004537
2022-01-20 18:13:51,693 iteration 6417 : loss : 0.016054, loss_ce: 0.004867
2022-01-20 18:13:52,993 iteration 6418 : loss : 0.015610, loss_ce: 0.006713
2022-01-20 18:13:54,291 iteration 6419 : loss : 0.012356, loss_ce: 0.005110
2022-01-20 18:13:55,621 iteration 6420 : loss : 0.026718, loss_ce: 0.010097
2022-01-20 18:13:56,973 iteration 6421 : loss : 0.011797, loss_ce: 0.004816
2022-01-20 18:13:58,263 iteration 6422 : loss : 0.017227, loss_ce: 0.006289
2022-01-20 18:13:59,584 iteration 6423 : loss : 0.011080, loss_ce: 0.004318
2022-01-20 18:14:00,842 iteration 6424 : loss : 0.011360, loss_ce: 0.003449
2022-01-20 18:14:02,319 iteration 6425 : loss : 0.014843, loss_ce: 0.005165
2022-01-20 18:14:03,563 iteration 6426 : loss : 0.015732, loss_ce: 0.005224
 94%|███████████████████████████▍ | 378/400 [2:33:52<08:38, 23.57s/it]2022-01-20 18:14:04,967 iteration 6427 : loss : 0.017471, loss_ce: 0.007070
2022-01-20 18:14:06,330 iteration 6428 : loss : 0.016538, loss_ce: 0.005388
2022-01-20 18:14:07,614 iteration 6429 : loss : 0.012632, loss_ce: 0.004925
2022-01-20 18:14:08,995 iteration 6430 : loss : 0.013042, loss_ce: 0.006472
2022-01-20 18:14:10,291 iteration 6431 : loss : 0.018801, loss_ce: 0.005514
2022-01-20 18:14:11,598 iteration 6432 : loss : 0.012411, loss_ce: 0.004375
2022-01-20 18:14:12,923 iteration 6433 : loss : 0.011865, loss_ce: 0.003440
2022-01-20 18:14:14,240 iteration 6434 : loss : 0.026831, loss_ce: 0.009935
2022-01-20 18:14:15,443 iteration 6435 : loss : 0.009362, loss_ce: 0.003117
2022-01-20 18:14:16,699 iteration 6436 : loss : 0.010453, loss_ce: 0.005446
2022-01-20 18:14:17,943 iteration 6437 : loss : 0.011294, loss_ce: 0.004463
2022-01-20 18:14:19,173 iteration 6438 : loss : 0.009242, loss_ce: 0.004278
2022-01-20 18:14:20,551 iteration 6439 : loss : 0.017147, loss_ce: 0.005386
2022-01-20 18:14:21,879 iteration 6440 : loss : 0.010740, loss_ce: 0.003853
2022-01-20 18:14:23,194 iteration 6441 : loss : 0.010860, loss_ce: 0.004339
2022-01-20 18:14:24,495 iteration 6442 : loss : 0.010107, loss_ce: 0.004568
2022-01-20 18:14:25,762 iteration 6443 : loss : 0.012761, loss_ce: 0.004910
 95%|███████████████████████████▍ | 379/400 [2:34:14<08:06, 23.16s/it]2022-01-20 18:14:27,098 iteration 6444 : loss : 0.012383, loss_ce: 0.005882
2022-01-20 18:14:28,360 iteration 6445 : loss : 0.009190, loss_ce: 0.003427
2022-01-20 18:14:29,669 iteration 6446 : loss : 0.014914, loss_ce: 0.005211
2022-01-20 18:14:30,989 iteration 6447 : loss : 0.010942, loss_ce: 0.004830
2022-01-20 18:14:32,309 iteration 6448 : loss : 0.017518, loss_ce: 0.003655
2022-01-20 18:14:33,655 iteration 6449 : loss : 0.016272, loss_ce: 0.005989
2022-01-20 18:14:35,038 iteration 6450 : loss : 0.015236, loss_ce: 0.004419
2022-01-20 18:14:36,333 iteration 6451 : loss : 0.013795, loss_ce: 0.004901
2022-01-20 18:14:37,702 iteration 6452 : loss : 0.020433, loss_ce: 0.004308
2022-01-20 18:14:38,998 iteration 6453 : loss : 0.011349, loss_ce: 0.005230
2022-01-20 18:14:40,322 iteration 6454 : loss : 0.015635, loss_ce: 0.005476
2022-01-20 18:14:41,583 iteration 6455 : loss : 0.012647, loss_ce: 0.004660
2022-01-20 18:14:42,914 iteration 6456 : loss : 0.015280, loss_ce: 0.006825
2022-01-20 18:14:44,207 iteration 6457 : loss : 0.009612, loss_ce: 0.003811
2022-01-20 18:14:45,463 iteration 6458 : loss : 0.016844, loss_ce: 0.010035
2022-01-20 18:14:46,844 iteration 6459 : loss : 0.014054, loss_ce: 0.005170
2022-01-20 18:14:46,844 Training Data Eval:
2022-01-20 18:14:53,485   Average segmentation loss on training set: 0.0071
2022-01-20 18:14:53,485 Validation Data Eval:
2022-01-20 18:14:55,754   Average segmentation loss on validation set: 0.0702
2022-01-20 18:14:57,169 iteration 6460 : loss : 0.012235, loss_ce: 0.004158
 95%|███████████████████████████▌ | 380/400 [2:34:45<08:32, 25.63s/it]2022-01-20 18:14:58,514 iteration 6461 : loss : 0.012089, loss_ce: 0.004066
2022-01-20 18:14:59,835 iteration 6462 : loss : 0.017946, loss_ce: 0.008932
2022-01-20 18:15:01,101 iteration 6463 : loss : 0.011249, loss_ce: 0.005357
2022-01-20 18:15:02,406 iteration 6464 : loss : 0.011684, loss_ce: 0.004461
2022-01-20 18:15:03,711 iteration 6465 : loss : 0.016535, loss_ce: 0.005261
2022-01-20 18:15:05,026 iteration 6466 : loss : 0.013766, loss_ce: 0.005674
2022-01-20 18:15:06,337 iteration 6467 : loss : 0.014942, loss_ce: 0.006701
2022-01-20 18:15:07,585 iteration 6468 : loss : 0.009362, loss_ce: 0.003353
2022-01-20 18:15:08,959 iteration 6469 : loss : 0.015360, loss_ce: 0.004079
2022-01-20 18:15:10,300 iteration 6470 : loss : 0.010880, loss_ce: 0.004240
2022-01-20 18:15:11,626 iteration 6471 : loss : 0.012591, loss_ce: 0.005232
2022-01-20 18:15:12,874 iteration 6472 : loss : 0.013328, loss_ce: 0.004544
2022-01-20 18:15:14,226 iteration 6473 : loss : 0.017845, loss_ce: 0.006606
2022-01-20 18:15:15,563 iteration 6474 : loss : 0.010263, loss_ce: 0.004308
2022-01-20 18:15:16,925 iteration 6475 : loss : 0.012879, loss_ce: 0.004493
2022-01-20 18:15:18,257 iteration 6476 : loss : 0.017096, loss_ce: 0.008300
2022-01-20 18:15:19,573 iteration 6477 : loss : 0.014050, loss_ce: 0.005730
 95%|███████████████████████████▌ | 381/400 [2:35:08<07:48, 24.66s/it]2022-01-20 18:15:20,933 iteration 6478 : loss : 0.012894, loss_ce: 0.005340
2022-01-20 18:15:22,244 iteration 6479 : loss : 0.015958, loss_ce: 0.005762
2022-01-20 18:15:23,518 iteration 6480 : loss : 0.009979, loss_ce: 0.003579
2022-01-20 18:15:24,983 iteration 6481 : loss : 0.019260, loss_ce: 0.006068
2022-01-20 18:15:26,241 iteration 6482 : loss : 0.011400, loss_ce: 0.004508
2022-01-20 18:15:27,608 iteration 6483 : loss : 0.019735, loss_ce: 0.007982
2022-01-20 18:15:28,813 iteration 6484 : loss : 0.015995, loss_ce: 0.005478
2022-01-20 18:15:30,129 iteration 6485 : loss : 0.011124, loss_ce: 0.003293
2022-01-20 18:15:31,454 iteration 6486 : loss : 0.013949, loss_ce: 0.004629
2022-01-20 18:15:32,807 iteration 6487 : loss : 0.013935, loss_ce: 0.005816
2022-01-20 18:15:34,168 iteration 6488 : loss : 0.010045, loss_ce: 0.003576
2022-01-20 18:15:35,474 iteration 6489 : loss : 0.021136, loss_ce: 0.006614
2022-01-20 18:15:36,765 iteration 6490 : loss : 0.011664, loss_ce: 0.003991
2022-01-20 18:15:38,020 iteration 6491 : loss : 0.011946, loss_ce: 0.005556
2022-01-20 18:15:39,280 iteration 6492 : loss : 0.010975, loss_ce: 0.006448
2022-01-20 18:15:40,575 iteration 6493 : loss : 0.020184, loss_ce: 0.007033
2022-01-20 18:15:41,915 iteration 6494 : loss : 0.013615, loss_ce: 0.005068
 96%|███████████████████████████▋ | 382/400 [2:35:30<07:11, 23.97s/it]2022-01-20 18:15:43,201 iteration 6495 : loss : 0.019682, loss_ce: 0.010221
2022-01-20 18:15:44,485 iteration 6496 : loss : 0.015138, loss_ce: 0.005303
2022-01-20 18:15:45,823 iteration 6497 : loss : 0.008996, loss_ce: 0.004405
2022-01-20 18:15:47,080 iteration 6498 : loss : 0.011918, loss_ce: 0.003112
2022-01-20 18:15:48,363 iteration 6499 : loss : 0.021014, loss_ce: 0.004144
2022-01-20 18:15:49,779 iteration 6500 : loss : 0.022700, loss_ce: 0.006608
2022-01-20 18:15:51,153 iteration 6501 : loss : 0.014390, loss_ce: 0.007273
2022-01-20 18:15:52,460 iteration 6502 : loss : 0.012964, loss_ce: 0.004596
2022-01-20 18:15:53,771 iteration 6503 : loss : 0.013746, loss_ce: 0.005402
2022-01-20 18:15:55,103 iteration 6504 : loss : 0.016340, loss_ce: 0.007625
2022-01-20 18:15:56,337 iteration 6505 : loss : 0.009542, loss_ce: 0.003532
2022-01-20 18:15:57,672 iteration 6506 : loss : 0.017280, loss_ce: 0.006519
2022-01-20 18:15:58,952 iteration 6507 : loss : 0.011426, loss_ce: 0.004557
2022-01-20 18:16:00,161 iteration 6508 : loss : 0.010848, loss_ce: 0.004214
2022-01-20 18:16:01,460 iteration 6509 : loss : 0.011918, loss_ce: 0.004116
2022-01-20 18:16:02,656 iteration 6510 : loss : 0.008214, loss_ce: 0.003161
2022-01-20 18:16:03,989 iteration 6511 : loss : 0.013928, loss_ce: 0.006227
 96%|███████████████████████████▊ | 383/400 [2:35:52<06:37, 23.40s/it]2022-01-20 18:16:05,386 iteration 6512 : loss : 0.017201, loss_ce: 0.006609
2022-01-20 18:16:06,743 iteration 6513 : loss : 0.013305, loss_ce: 0.005160
2022-01-20 18:16:08,046 iteration 6514 : loss : 0.021280, loss_ce: 0.006200
2022-01-20 18:16:09,412 iteration 6515 : loss : 0.020871, loss_ce: 0.007348
2022-01-20 18:16:10,679 iteration 6516 : loss : 0.011050, loss_ce: 0.004345
2022-01-20 18:16:11,938 iteration 6517 : loss : 0.014433, loss_ce: 0.006806
2022-01-20 18:16:13,283 iteration 6518 : loss : 0.018588, loss_ce: 0.006910
2022-01-20 18:16:14,666 iteration 6519 : loss : 0.017194, loss_ce: 0.007513
2022-01-20 18:16:15,899 iteration 6520 : loss : 0.011233, loss_ce: 0.004466
2022-01-20 18:16:17,242 iteration 6521 : loss : 0.016551, loss_ce: 0.007132
2022-01-20 18:16:18,564 iteration 6522 : loss : 0.016787, loss_ce: 0.005245
2022-01-20 18:16:19,903 iteration 6523 : loss : 0.013460, loss_ce: 0.005709
2022-01-20 18:16:21,227 iteration 6524 : loss : 0.015882, loss_ce: 0.005925
2022-01-20 18:16:22,570 iteration 6525 : loss : 0.016961, loss_ce: 0.006270
2022-01-20 18:16:23,870 iteration 6526 : loss : 0.014244, loss_ce: 0.005792
2022-01-20 18:16:25,127 iteration 6527 : loss : 0.015601, loss_ce: 0.005277
2022-01-20 18:16:26,388 iteration 6528 : loss : 0.012232, loss_ce: 0.004755
 96%|███████████████████████████▊ | 384/400 [2:36:14<06:09, 23.10s/it]2022-01-20 18:16:27,943 iteration 6529 : loss : 0.013871, loss_ce: 0.005983
2022-01-20 18:16:29,226 iteration 6530 : loss : 0.019163, loss_ce: 0.009316
2022-01-20 18:16:30,633 iteration 6531 : loss : 0.021741, loss_ce: 0.007700
2022-01-20 18:16:31,949 iteration 6532 : loss : 0.020563, loss_ce: 0.008947
2022-01-20 18:16:33,317 iteration 6533 : loss : 0.016141, loss_ce: 0.005919
2022-01-20 18:16:34,795 iteration 6534 : loss : 0.019064, loss_ce: 0.004593
2022-01-20 18:16:36,018 iteration 6535 : loss : 0.018830, loss_ce: 0.004023
2022-01-20 18:16:37,325 iteration 6536 : loss : 0.017100, loss_ce: 0.007023
2022-01-20 18:16:38,654 iteration 6537 : loss : 0.010668, loss_ce: 0.004001
2022-01-20 18:16:39,999 iteration 6538 : loss : 0.020511, loss_ce: 0.010421
2022-01-20 18:16:41,427 iteration 6539 : loss : 0.021440, loss_ce: 0.008982
2022-01-20 18:16:42,736 iteration 6540 : loss : 0.011600, loss_ce: 0.005500
2022-01-20 18:16:44,030 iteration 6541 : loss : 0.012011, loss_ce: 0.004952
2022-01-20 18:16:45,402 iteration 6542 : loss : 0.022939, loss_ce: 0.010425
2022-01-20 18:16:46,739 iteration 6543 : loss : 0.014597, loss_ce: 0.005481
2022-01-20 18:16:47,962 iteration 6544 : loss : 0.009482, loss_ce: 0.003287
2022-01-20 18:16:47,963 Training Data Eval:
2022-01-20 18:16:54,478   Average segmentation loss on training set: 0.0071
2022-01-20 18:16:54,478 Validation Data Eval:
2022-01-20 18:16:56,698   Average segmentation loss on validation set: 0.0735
2022-01-20 18:16:57,898 iteration 6545 : loss : 0.007729, loss_ce: 0.001779
 96%|███████████████████████████▉ | 385/400 [2:36:46<06:24, 25.62s/it]2022-01-20 18:16:59,343 iteration 6546 : loss : 0.021216, loss_ce: 0.006824
2022-01-20 18:17:00,857 iteration 6547 : loss : 0.019461, loss_ce: 0.007613
2022-01-20 18:17:02,053 iteration 6548 : loss : 0.010368, loss_ce: 0.006102
2022-01-20 18:17:03,244 iteration 6549 : loss : 0.007391, loss_ce: 0.002500
2022-01-20 18:17:04,523 iteration 6550 : loss : 0.009466, loss_ce: 0.004050
2022-01-20 18:17:05,885 iteration 6551 : loss : 0.013301, loss_ce: 0.006283
2022-01-20 18:17:07,094 iteration 6552 : loss : 0.011459, loss_ce: 0.005346
2022-01-20 18:17:08,490 iteration 6553 : loss : 0.019259, loss_ce: 0.007643
2022-01-20 18:17:09,791 iteration 6554 : loss : 0.014425, loss_ce: 0.004414
2022-01-20 18:17:11,169 iteration 6555 : loss : 0.018143, loss_ce: 0.007128
2022-01-20 18:17:12,509 iteration 6556 : loss : 0.019033, loss_ce: 0.005848
2022-01-20 18:17:13,748 iteration 6557 : loss : 0.012097, loss_ce: 0.003934
2022-01-20 18:17:14,999 iteration 6558 : loss : 0.015731, loss_ce: 0.004493
2022-01-20 18:17:16,347 iteration 6559 : loss : 0.019757, loss_ce: 0.008161
2022-01-20 18:17:17,749 iteration 6560 : loss : 0.025995, loss_ce: 0.006562
2022-01-20 18:17:18,990 iteration 6561 : loss : 0.011502, loss_ce: 0.004853
2022-01-20 18:17:20,179 iteration 6562 : loss : 0.008829, loss_ce: 0.002797
 96%|███████████████████████████▉ | 386/400 [2:37:08<05:44, 24.62s/it]2022-01-20 18:17:21,541 iteration 6563 : loss : 0.010386, loss_ce: 0.004755
2022-01-20 18:17:22,819 iteration 6564 : loss : 0.014811, loss_ce: 0.004564
2022-01-20 18:17:24,063 iteration 6565 : loss : 0.008692, loss_ce: 0.002425
2022-01-20 18:17:25,346 iteration 6566 : loss : 0.012133, loss_ce: 0.004442
2022-01-20 18:17:26,681 iteration 6567 : loss : 0.013891, loss_ce: 0.005570
2022-01-20 18:17:28,008 iteration 6568 : loss : 0.015362, loss_ce: 0.005863
2022-01-20 18:17:29,374 iteration 6569 : loss : 0.017844, loss_ce: 0.005578
2022-01-20 18:17:30,671 iteration 6570 : loss : 0.012635, loss_ce: 0.003133
2022-01-20 18:17:32,113 iteration 6571 : loss : 0.017330, loss_ce: 0.008454
2022-01-20 18:17:33,335 iteration 6572 : loss : 0.009094, loss_ce: 0.003970
2022-01-20 18:17:34,706 iteration 6573 : loss : 0.042514, loss_ce: 0.013580
2022-01-20 18:17:35,992 iteration 6574 : loss : 0.012011, loss_ce: 0.004306
2022-01-20 18:17:37,391 iteration 6575 : loss : 0.022690, loss_ce: 0.007981
2022-01-20 18:17:38,715 iteration 6576 : loss : 0.017872, loss_ce: 0.006846
2022-01-20 18:17:39,988 iteration 6577 : loss : 0.010697, loss_ce: 0.003452
2022-01-20 18:17:41,343 iteration 6578 : loss : 0.012210, loss_ce: 0.005407
2022-01-20 18:17:42,631 iteration 6579 : loss : 0.013140, loss_ce: 0.005917
 97%|████████████████████████████ | 387/400 [2:37:31<05:11, 23.97s/it]2022-01-20 18:17:44,075 iteration 6580 : loss : 0.017435, loss_ce: 0.007608
2022-01-20 18:17:45,337 iteration 6581 : loss : 0.010284, loss_ce: 0.003118
2022-01-20 18:17:46,757 iteration 6582 : loss : 0.016115, loss_ce: 0.005004
2022-01-20 18:17:48,083 iteration 6583 : loss : 0.023653, loss_ce: 0.009316
2022-01-20 18:17:49,343 iteration 6584 : loss : 0.021173, loss_ce: 0.007613
2022-01-20 18:17:50,561 iteration 6585 : loss : 0.009454, loss_ce: 0.002972
2022-01-20 18:17:51,842 iteration 6586 : loss : 0.011390, loss_ce: 0.002431
2022-01-20 18:17:53,085 iteration 6587 : loss : 0.011205, loss_ce: 0.005086
2022-01-20 18:17:54,425 iteration 6588 : loss : 0.010054, loss_ce: 0.005084
2022-01-20 18:17:55,757 iteration 6589 : loss : 0.012252, loss_ce: 0.004943
2022-01-20 18:17:57,040 iteration 6590 : loss : 0.012560, loss_ce: 0.005676
2022-01-20 18:17:58,337 iteration 6591 : loss : 0.009364, loss_ce: 0.003243
2022-01-20 18:17:59,738 iteration 6592 : loss : 0.013612, loss_ce: 0.006653
2022-01-20 18:18:00,944 iteration 6593 : loss : 0.008959, loss_ce: 0.004741
2022-01-20 18:18:02,228 iteration 6594 : loss : 0.012978, loss_ce: 0.005104
2022-01-20 18:18:03,572 iteration 6595 : loss : 0.017399, loss_ce: 0.005161
2022-01-20 18:18:04,816 iteration 6596 : loss : 0.009868, loss_ce: 0.002877
 97%|████████████████████████████▏| 388/400 [2:37:53<04:41, 23.44s/it]2022-01-20 18:18:06,142 iteration 6597 : loss : 0.009127, loss_ce: 0.003961
2022-01-20 18:18:07,503 iteration 6598 : loss : 0.019710, loss_ce: 0.003212
2022-01-20 18:18:08,881 iteration 6599 : loss : 0.015284, loss_ce: 0.005450
2022-01-20 18:18:10,137 iteration 6600 : loss : 0.011165, loss_ce: 0.004225
2022-01-20 18:18:11,569 iteration 6601 : loss : 0.014610, loss_ce: 0.006389
2022-01-20 18:18:12,919 iteration 6602 : loss : 0.015927, loss_ce: 0.006045
2022-01-20 18:18:14,183 iteration 6603 : loss : 0.011792, loss_ce: 0.005251
2022-01-20 18:18:15,545 iteration 6604 : loss : 0.010959, loss_ce: 0.005218
2022-01-20 18:18:16,830 iteration 6605 : loss : 0.011666, loss_ce: 0.005474
2022-01-20 18:18:18,206 iteration 6606 : loss : 0.016328, loss_ce: 0.005568
2022-01-20 18:18:19,588 iteration 6607 : loss : 0.017464, loss_ce: 0.006590
2022-01-20 18:18:20,816 iteration 6608 : loss : 0.014332, loss_ce: 0.005766
2022-01-20 18:18:22,184 iteration 6609 : loss : 0.014308, loss_ce: 0.006306
2022-01-20 18:18:23,470 iteration 6610 : loss : 0.016608, loss_ce: 0.006376
2022-01-20 18:18:24,754 iteration 6611 : loss : 0.008955, loss_ce: 0.002259
2022-01-20 18:18:26,058 iteration 6612 : loss : 0.017440, loss_ce: 0.005108
2022-01-20 18:18:27,428 iteration 6613 : loss : 0.013505, loss_ce: 0.004743
 97%|████████████████████████████▏| 389/400 [2:38:15<04:15, 23.19s/it]2022-01-20 18:18:28,753 iteration 6614 : loss : 0.008501, loss_ce: 0.002962
2022-01-20 18:18:29,978 iteration 6615 : loss : 0.008670, loss_ce: 0.003353
2022-01-20 18:18:31,350 iteration 6616 : loss : 0.015997, loss_ce: 0.005751
2022-01-20 18:18:32,650 iteration 6617 : loss : 0.014609, loss_ce: 0.005534
2022-01-20 18:18:34,081 iteration 6618 : loss : 0.018717, loss_ce: 0.008224
2022-01-20 18:18:35,428 iteration 6619 : loss : 0.016300, loss_ce: 0.005350
2022-01-20 18:18:36,769 iteration 6620 : loss : 0.011889, loss_ce: 0.004068
2022-01-20 18:18:38,160 iteration 6621 : loss : 0.015026, loss_ce: 0.004758
2022-01-20 18:18:39,457 iteration 6622 : loss : 0.013200, loss_ce: 0.006315
2022-01-20 18:18:40,709 iteration 6623 : loss : 0.014739, loss_ce: 0.004715
2022-01-20 18:18:42,021 iteration 6624 : loss : 0.013288, loss_ce: 0.005570
2022-01-20 18:18:43,362 iteration 6625 : loss : 0.017567, loss_ce: 0.006245
2022-01-20 18:18:44,669 iteration 6626 : loss : 0.016850, loss_ce: 0.006735
2022-01-20 18:18:46,026 iteration 6627 : loss : 0.016885, loss_ce: 0.006173
2022-01-20 18:18:47,380 iteration 6628 : loss : 0.014852, loss_ce: 0.006436
2022-01-20 18:18:48,824 iteration 6629 : loss : 0.015977, loss_ce: 0.004186
2022-01-20 18:18:48,824 Training Data Eval:
2022-01-20 18:18:55,332   Average segmentation loss on training set: 0.0070
2022-01-20 18:18:55,333 Validation Data Eval:
2022-01-20 18:18:57,587   Average segmentation loss on validation set: 0.0798
2022-01-20 18:18:58,893 iteration 6630 : loss : 0.014167, loss_ce: 0.006241
 98%|████████████████████████████▎| 390/400 [2:38:47<04:16, 25.67s/it]2022-01-20 18:19:00,260 iteration 6631 : loss : 0.014496, loss_ce: 0.005047
2022-01-20 18:19:01,535 iteration 6632 : loss : 0.010365, loss_ce: 0.004888
2022-01-20 18:19:02,900 iteration 6633 : loss : 0.016197, loss_ce: 0.004396
2022-01-20 18:19:04,183 iteration 6634 : loss : 0.012418, loss_ce: 0.005060
2022-01-20 18:19:05,506 iteration 6635 : loss : 0.014271, loss_ce: 0.005355
2022-01-20 18:19:06,826 iteration 6636 : loss : 0.009772, loss_ce: 0.004821
2022-01-20 18:19:08,096 iteration 6637 : loss : 0.014033, loss_ce: 0.004838
2022-01-20 18:19:09,472 iteration 6638 : loss : 0.021308, loss_ce: 0.005009
2022-01-20 18:19:10,839 iteration 6639 : loss : 0.012901, loss_ce: 0.005382
2022-01-20 18:19:12,120 iteration 6640 : loss : 0.009980, loss_ce: 0.003251
2022-01-20 18:19:13,449 iteration 6641 : loss : 0.011165, loss_ce: 0.003333
2022-01-20 18:19:14,791 iteration 6642 : loss : 0.011985, loss_ce: 0.005305
2022-01-20 18:19:16,126 iteration 6643 : loss : 0.013494, loss_ce: 0.004613
2022-01-20 18:19:17,573 iteration 6644 : loss : 0.030413, loss_ce: 0.013332
2022-01-20 18:19:18,837 iteration 6645 : loss : 0.011706, loss_ce: 0.004981
2022-01-20 18:19:20,254 iteration 6646 : loss : 0.021299, loss_ce: 0.005776
2022-01-20 18:19:21,538 iteration 6647 : loss : 0.013140, loss_ce: 0.004775
 98%|████████████████████████████▎| 391/400 [2:39:10<03:42, 24.77s/it]2022-01-20 18:19:22,882 iteration 6648 : loss : 0.016212, loss_ce: 0.003719
2022-01-20 18:19:24,239 iteration 6649 : loss : 0.013668, loss_ce: 0.003724
2022-01-20 18:19:25,651 iteration 6650 : loss : 0.016298, loss_ce: 0.006106
2022-01-20 18:19:27,078 iteration 6651 : loss : 0.016870, loss_ce: 0.006920
2022-01-20 18:19:28,359 iteration 6652 : loss : 0.010048, loss_ce: 0.004280
2022-01-20 18:19:29,576 iteration 6653 : loss : 0.009113, loss_ce: 0.003767
2022-01-20 18:19:30,874 iteration 6654 : loss : 0.011802, loss_ce: 0.003689
2022-01-20 18:19:32,235 iteration 6655 : loss : 0.016897, loss_ce: 0.006423
2022-01-20 18:19:33,600 iteration 6656 : loss : 0.014576, loss_ce: 0.005818
2022-01-20 18:19:34,932 iteration 6657 : loss : 0.009363, loss_ce: 0.002667
2022-01-20 18:19:36,293 iteration 6658 : loss : 0.011571, loss_ce: 0.004174
2022-01-20 18:19:37,615 iteration 6659 : loss : 0.015975, loss_ce: 0.007145
2022-01-20 18:19:39,009 iteration 6660 : loss : 0.020508, loss_ce: 0.009068
2022-01-20 18:19:40,353 iteration 6661 : loss : 0.012799, loss_ce: 0.004641
2022-01-20 18:19:41,700 iteration 6662 : loss : 0.018737, loss_ce: 0.005042
2022-01-20 18:19:43,012 iteration 6663 : loss : 0.014841, loss_ce: 0.004867
2022-01-20 18:19:44,364 iteration 6664 : loss : 0.018398, loss_ce: 0.009534
 98%|████████████████████████████▍| 392/400 [2:39:32<03:13, 24.18s/it]2022-01-20 18:19:45,750 iteration 6665 : loss : 0.016605, loss_ce: 0.005241
2022-01-20 18:19:47,176 iteration 6666 : loss : 0.021839, loss_ce: 0.006681
2022-01-20 18:19:48,510 iteration 6667 : loss : 0.017705, loss_ce: 0.002820
2022-01-20 18:19:49,730 iteration 6668 : loss : 0.011303, loss_ce: 0.005870
2022-01-20 18:19:51,038 iteration 6669 : loss : 0.015116, loss_ce: 0.005642
2022-01-20 18:19:52,373 iteration 6670 : loss : 0.016261, loss_ce: 0.006664
2022-01-20 18:19:53,714 iteration 6671 : loss : 0.012562, loss_ce: 0.004375
2022-01-20 18:19:55,069 iteration 6672 : loss : 0.012325, loss_ce: 0.003478
2022-01-20 18:19:56,356 iteration 6673 : loss : 0.024180, loss_ce: 0.005962
2022-01-20 18:19:57,652 iteration 6674 : loss : 0.017433, loss_ce: 0.007658
2022-01-20 18:19:59,052 iteration 6675 : loss : 0.019738, loss_ce: 0.010048
2022-01-20 18:20:00,334 iteration 6676 : loss : 0.011055, loss_ce: 0.004432
2022-01-20 18:20:01,595 iteration 6677 : loss : 0.012371, loss_ce: 0.004308
2022-01-20 18:20:02,905 iteration 6678 : loss : 0.011813, loss_ce: 0.005557
2022-01-20 18:20:04,279 iteration 6679 : loss : 0.014368, loss_ce: 0.006035
2022-01-20 18:20:05,526 iteration 6680 : loss : 0.008824, loss_ce: 0.003260
2022-01-20 18:20:06,761 iteration 6681 : loss : 0.008778, loss_ce: 0.002868
 98%|████████████████████████████▍| 393/400 [2:39:55<02:45, 23.65s/it]2022-01-20 18:20:08,242 iteration 6682 : loss : 0.018808, loss_ce: 0.009410
2022-01-20 18:20:09,497 iteration 6683 : loss : 0.010926, loss_ce: 0.004422
2022-01-20 18:20:10,816 iteration 6684 : loss : 0.009496, loss_ce: 0.004373
2022-01-20 18:20:12,079 iteration 6685 : loss : 0.017409, loss_ce: 0.006471
2022-01-20 18:20:13,477 iteration 6686 : loss : 0.015223, loss_ce: 0.006917
2022-01-20 18:20:14,779 iteration 6687 : loss : 0.014923, loss_ce: 0.005474
2022-01-20 18:20:16,100 iteration 6688 : loss : 0.014192, loss_ce: 0.005632
2022-01-20 18:20:17,336 iteration 6689 : loss : 0.009337, loss_ce: 0.002629
2022-01-20 18:20:18,651 iteration 6690 : loss : 0.007301, loss_ce: 0.002172
2022-01-20 18:20:20,006 iteration 6691 : loss : 0.015336, loss_ce: 0.005083
2022-01-20 18:20:21,280 iteration 6692 : loss : 0.017516, loss_ce: 0.006639
2022-01-20 18:20:22,578 iteration 6693 : loss : 0.013467, loss_ce: 0.004569
2022-01-20 18:20:23,921 iteration 6694 : loss : 0.017132, loss_ce: 0.005836
2022-01-20 18:20:25,192 iteration 6695 : loss : 0.018391, loss_ce: 0.006609
2022-01-20 18:20:26,497 iteration 6696 : loss : 0.009554, loss_ce: 0.003765
2022-01-20 18:20:27,806 iteration 6697 : loss : 0.011016, loss_ce: 0.003823
2022-01-20 18:20:29,212 iteration 6698 : loss : 0.014554, loss_ce: 0.005401
 98%|████████████████████████████▌| 394/400 [2:40:17<02:19, 23.29s/it]2022-01-20 18:20:30,559 iteration 6699 : loss : 0.010142, loss_ce: 0.003714
2022-01-20 18:20:31,953 iteration 6700 : loss : 0.019386, loss_ce: 0.005459
2022-01-20 18:20:33,255 iteration 6701 : loss : 0.009658, loss_ce: 0.003322
2022-01-20 18:20:34,504 iteration 6702 : loss : 0.009598, loss_ce: 0.004541
2022-01-20 18:20:35,766 iteration 6703 : loss : 0.009751, loss_ce: 0.003281
2022-01-20 18:20:37,150 iteration 6704 : loss : 0.015350, loss_ce: 0.008464
2022-01-20 18:20:38,410 iteration 6705 : loss : 0.013070, loss_ce: 0.006249
2022-01-20 18:20:39,826 iteration 6706 : loss : 0.011398, loss_ce: 0.003707
2022-01-20 18:20:41,076 iteration 6707 : loss : 0.010189, loss_ce: 0.004490
2022-01-20 18:20:42,414 iteration 6708 : loss : 0.014382, loss_ce: 0.005038
2022-01-20 18:20:43,751 iteration 6709 : loss : 0.013949, loss_ce: 0.006058
2022-01-20 18:20:45,120 iteration 6710 : loss : 0.043125, loss_ce: 0.015236
2022-01-20 18:20:46,476 iteration 6711 : loss : 0.014311, loss_ce: 0.004450
2022-01-20 18:20:47,901 iteration 6712 : loss : 0.016670, loss_ce: 0.007314
2022-01-20 18:20:49,150 iteration 6713 : loss : 0.008987, loss_ce: 0.003400
2022-01-20 18:20:50,473 iteration 6714 : loss : 0.012735, loss_ce: 0.004715
2022-01-20 18:20:50,473 Training Data Eval:
2022-01-20 18:20:57,050   Average segmentation loss on training set: 0.0071
2022-01-20 18:20:57,051 Validation Data Eval:
2022-01-20 18:20:59,331   Average segmentation loss on validation set: 0.0694
2022-01-20 18:21:00,626 iteration 6715 : loss : 0.012131, loss_ce: 0.004532
 99%|████████████████████████████▋| 395/400 [2:40:49<02:08, 25.72s/it]2022-01-20 18:21:02,001 iteration 6716 : loss : 0.012032, loss_ce: 0.005480
2022-01-20 18:21:03,283 iteration 6717 : loss : 0.011206, loss_ce: 0.004885
2022-01-20 18:21:04,589 iteration 6718 : loss : 0.015560, loss_ce: 0.005612
2022-01-20 18:21:05,869 iteration 6719 : loss : 0.012291, loss_ce: 0.004851
2022-01-20 18:21:07,163 iteration 6720 : loss : 0.011378, loss_ce: 0.003610
2022-01-20 18:21:08,439 iteration 6721 : loss : 0.010662, loss_ce: 0.003612
2022-01-20 18:21:09,846 iteration 6722 : loss : 0.015431, loss_ce: 0.006729
2022-01-20 18:21:11,052 iteration 6723 : loss : 0.010930, loss_ce: 0.003390
2022-01-20 18:21:12,362 iteration 6724 : loss : 0.013727, loss_ce: 0.004238
2022-01-20 18:21:13,711 iteration 6725 : loss : 0.010747, loss_ce: 0.003589
2022-01-20 18:21:15,068 iteration 6726 : loss : 0.018089, loss_ce: 0.008281
2022-01-20 18:21:16,496 iteration 6727 : loss : 0.021421, loss_ce: 0.007392
2022-01-20 18:21:17,796 iteration 6728 : loss : 0.016583, loss_ce: 0.005837
2022-01-20 18:21:19,103 iteration 6729 : loss : 0.019862, loss_ce: 0.005484
2022-01-20 18:21:20,370 iteration 6730 : loss : 0.010768, loss_ce: 0.004474
2022-01-20 18:21:21,693 iteration 6731 : loss : 0.012284, loss_ce: 0.004529
2022-01-20 18:21:23,061 iteration 6732 : loss : 0.014057, loss_ce: 0.005915
 99%|████████████████████████████▋| 396/400 [2:41:11<01:38, 24.74s/it]2022-01-20 18:21:24,429 iteration 6733 : loss : 0.009328, loss_ce: 0.003355
2022-01-20 18:21:25,857 iteration 6734 : loss : 0.020818, loss_ce: 0.007793
2022-01-20 18:21:27,121 iteration 6735 : loss : 0.009770, loss_ce: 0.004495
2022-01-20 18:21:28,500 iteration 6736 : loss : 0.016622, loss_ce: 0.007219
2022-01-20 18:21:29,882 iteration 6737 : loss : 0.015442, loss_ce: 0.005777
2022-01-20 18:21:31,101 iteration 6738 : loss : 0.012514, loss_ce: 0.003778
2022-01-20 18:21:32,388 iteration 6739 : loss : 0.014064, loss_ce: 0.006457
2022-01-20 18:21:33,744 iteration 6740 : loss : 0.009854, loss_ce: 0.004538
2022-01-20 18:21:35,034 iteration 6741 : loss : 0.009054, loss_ce: 0.003085
2022-01-20 18:21:36,303 iteration 6742 : loss : 0.011146, loss_ce: 0.003464
2022-01-20 18:21:37,647 iteration 6743 : loss : 0.012304, loss_ce: 0.005623
2022-01-20 18:21:38,990 iteration 6744 : loss : 0.026201, loss_ce: 0.010170
2022-01-20 18:21:40,259 iteration 6745 : loss : 0.014371, loss_ce: 0.005671
2022-01-20 18:21:41,596 iteration 6746 : loss : 0.012053, loss_ce: 0.004684
2022-01-20 18:21:42,967 iteration 6747 : loss : 0.014831, loss_ce: 0.003576
2022-01-20 18:21:44,314 iteration 6748 : loss : 0.022987, loss_ce: 0.006499
2022-01-20 18:21:45,629 iteration 6749 : loss : 0.012758, loss_ce: 0.005502
 99%|████████████████████████████▊| 397/400 [2:41:34<01:12, 24.09s/it]2022-01-20 18:21:47,044 iteration 6750 : loss : 0.010466, loss_ce: 0.003484
2022-01-20 18:21:48,467 iteration 6751 : loss : 0.018316, loss_ce: 0.005938
2022-01-20 18:21:49,848 iteration 6752 : loss : 0.014834, loss_ce: 0.006221
2022-01-20 18:21:51,140 iteration 6753 : loss : 0.013972, loss_ce: 0.005693
2022-01-20 18:21:52,537 iteration 6754 : loss : 0.015555, loss_ce: 0.005895
2022-01-20 18:21:53,799 iteration 6755 : loss : 0.009093, loss_ce: 0.002249
2022-01-20 18:21:54,992 iteration 6756 : loss : 0.007965, loss_ce: 0.003645
2022-01-20 18:21:56,233 iteration 6757 : loss : 0.011491, loss_ce: 0.004772
2022-01-20 18:21:57,520 iteration 6758 : loss : 0.012297, loss_ce: 0.006147
2022-01-20 18:21:58,879 iteration 6759 : loss : 0.026635, loss_ce: 0.009162
2022-01-20 18:22:00,157 iteration 6760 : loss : 0.010358, loss_ce: 0.004432
2022-01-20 18:22:01,443 iteration 6761 : loss : 0.012274, loss_ce: 0.004263
2022-01-20 18:22:02,755 iteration 6762 : loss : 0.014751, loss_ce: 0.004273
2022-01-20 18:22:04,063 iteration 6763 : loss : 0.012206, loss_ce: 0.005825
2022-01-20 18:22:05,448 iteration 6764 : loss : 0.012167, loss_ce: 0.004399
2022-01-20 18:22:06,791 iteration 6765 : loss : 0.017643, loss_ce: 0.004314
2022-01-20 18:22:08,074 iteration 6766 : loss : 0.009709, loss_ce: 0.004067
100%|████████████████████████████▊| 398/400 [2:41:56<00:47, 23.59s/it]2022-01-20 18:22:09,518 iteration 6767 : loss : 0.023209, loss_ce: 0.010107
2022-01-20 18:22:10,781 iteration 6768 : loss : 0.010546, loss_ce: 0.003213
2022-01-20 18:22:12,064 iteration 6769 : loss : 0.009829, loss_ce: 0.003204
2022-01-20 18:22:13,392 iteration 6770 : loss : 0.017605, loss_ce: 0.005196
2022-01-20 18:22:14,672 iteration 6771 : loss : 0.013310, loss_ce: 0.005676
2022-01-20 18:22:15,989 iteration 6772 : loss : 0.012430, loss_ce: 0.005451
2022-01-20 18:22:17,210 iteration 6773 : loss : 0.009173, loss_ce: 0.003540
2022-01-20 18:22:18,511 iteration 6774 : loss : 0.019028, loss_ce: 0.007712
2022-01-20 18:22:19,766 iteration 6775 : loss : 0.011047, loss_ce: 0.002452
2022-01-20 18:22:21,070 iteration 6776 : loss : 0.017075, loss_ce: 0.005552
2022-01-20 18:22:22,386 iteration 6777 : loss : 0.014768, loss_ce: 0.006263
2022-01-20 18:22:23,627 iteration 6778 : loss : 0.011850, loss_ce: 0.004364
2022-01-20 18:22:24,918 iteration 6779 : loss : 0.016251, loss_ce: 0.006606
2022-01-20 18:22:26,270 iteration 6780 : loss : 0.012927, loss_ce: 0.004720
2022-01-20 18:22:27,581 iteration 6781 : loss : 0.010460, loss_ce: 0.004166
2022-01-20 18:22:28,844 iteration 6782 : loss : 0.013655, loss_ce: 0.005580
2022-01-20 18:22:30,218 iteration 6783 : loss : 0.013024, loss_ce: 0.005041
100%|████████████████████████████▉| 399/400 [2:42:18<00:23, 23.16s/it]2022-01-20 18:22:31,507 iteration 6784 : loss : 0.011048, loss_ce: 0.005802
2022-01-20 18:22:32,793 iteration 6785 : loss : 0.013405, loss_ce: 0.004014
2022-01-20 18:22:34,130 iteration 6786 : loss : 0.012710, loss_ce: 0.004937
2022-01-20 18:22:35,417 iteration 6787 : loss : 0.014113, loss_ce: 0.003838
2022-01-20 18:22:36,726 iteration 6788 : loss : 0.012239, loss_ce: 0.005762
2022-01-20 18:22:38,128 iteration 6789 : loss : 0.021480, loss_ce: 0.005304
2022-01-20 18:22:39,449 iteration 6790 : loss : 0.013154, loss_ce: 0.005281
2022-01-20 18:22:40,843 iteration 6791 : loss : 0.017627, loss_ce: 0.005672
2022-01-20 18:22:42,139 iteration 6792 : loss : 0.015770, loss_ce: 0.006168
2022-01-20 18:22:43,368 iteration 6793 : loss : 0.009878, loss_ce: 0.003955
2022-01-20 18:22:44,726 iteration 6794 : loss : 0.013769, loss_ce: 0.004741
2022-01-20 18:22:45,973 iteration 6795 : loss : 0.015641, loss_ce: 0.007551
2022-01-20 18:22:47,279 iteration 6796 : loss : 0.010390, loss_ce: 0.002563
2022-01-20 18:22:48,564 iteration 6797 : loss : 0.018066, loss_ce: 0.007033
2022-01-20 18:22:49,925 iteration 6798 : loss : 0.015110, loss_ce: 0.004955
2022-01-20 18:22:51,210 iteration 6799 : loss : 0.013549, loss_ce: 0.004422
2022-01-20 18:22:51,211 Training Data Eval:
2022-01-20 18:22:57,705   Average segmentation loss on training set: 0.0068
2022-01-20 18:22:57,705 Validation Data Eval:
2022-01-20 18:22:59,932   Average segmentation loss on validation set: 0.0761
2022-01-20 18:23:01,241 iteration 6800 : loss : 0.013457, loss_ce: 0.005520
100%|█████████████████████████████| 400/400 [2:42:49<00:00, 25.52s/it]100%|█████████████████████████████| 400/400 [2:42:49<00:00, 24.42s/it]
