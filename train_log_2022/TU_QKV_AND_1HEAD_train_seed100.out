2022-01-15 23:39:39,052 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:39,052 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:39,053 ============================================================
2022-01-15 23:39:39,053 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:39,053 ============================================================
2022-01-15 23:39:39,053 Loading data...
2022-01-15 23:39:39,053 Reading NCI - RUNMC images...
2022-01-15 23:39:39,053 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-15 23:39:39,054 Already preprocessed this configuration. Loading now!
2022-01-15 23:39:39,073 Training Images: (256, 256, 286)
2022-01-15 23:39:39,073 Training Labels: (256, 256, 286)
2022-01-15 23:39:39,073 Validation Images: (256, 256, 98)
2022-01-15 23:39:39,073 Validation Labels: (256, 256, 98)
2022-01-15 23:39:39,073 ============================================================
2022-01-15 23:39:39,107 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-15 23:39:41,873 iteration 1 : loss : 1.112635, loss_ce: 1.444488
2022-01-15 23:39:42,807 iteration 2 : loss : 1.059071, loss_ce: 1.331463
2022-01-15 23:39:43,706 iteration 3 : loss : 0.982622, loss_ce: 1.192004
2022-01-15 23:39:44,667 iteration 4 : loss : 0.903156, loss_ce: 1.085394
2022-01-15 23:39:45,541 iteration 5 : loss : 0.882801, loss_ce: 1.025352
2022-01-15 23:39:46,542 iteration 6 : loss : 0.833067, loss_ce: 0.950743
2022-01-15 23:39:47,510 iteration 7 : loss : 0.811488, loss_ce: 0.906757
2022-01-15 23:39:48,480 iteration 8 : loss : 0.778382, loss_ce: 0.855479
2022-01-15 23:39:49,321 iteration 9 : loss : 0.733127, loss_ce: 0.809886
2022-01-15 23:39:50,294 iteration 10 : loss : 0.709493, loss_ce: 0.763929
2022-01-15 23:39:51,271 iteration 11 : loss : 0.696515, loss_ce: 0.731326
2022-01-15 23:39:52,282 iteration 12 : loss : 0.667213, loss_ce: 0.690464
2022-01-15 23:39:53,193 iteration 13 : loss : 0.647464, loss_ce: 0.644601
2022-01-15 23:39:54,210 iteration 14 : loss : 0.622477, loss_ce: 0.609053
2022-01-15 23:39:55,150 iteration 15 : loss : 0.595327, loss_ce: 0.566942
2022-01-15 23:39:56,067 iteration 16 : loss : 0.572601, loss_ce: 0.534067
2022-01-15 23:39:56,958 iteration 17 : loss : 0.563179, loss_ce: 0.487555
  0%|                               | 1/400 [00:17<1:59:17, 17.94s/it]2022-01-15 23:39:58,018 iteration 18 : loss : 0.523610, loss_ce: 0.461275
2022-01-15 23:39:58,984 iteration 19 : loss : 0.522350, loss_ce: 0.421001
2022-01-15 23:40:00,041 iteration 20 : loss : 0.485511, loss_ce: 0.399743
2022-01-15 23:40:00,959 iteration 21 : loss : 0.475445, loss_ce: 0.369905
2022-01-15 23:40:01,820 iteration 22 : loss : 0.448348, loss_ce: 0.332889
2022-01-15 23:40:02,817 iteration 23 : loss : 0.434611, loss_ce: 0.311459
2022-01-15 23:40:03,806 iteration 24 : loss : 0.398395, loss_ce: 0.289019
2022-01-15 23:40:04,824 iteration 25 : loss : 0.414865, loss_ce: 0.306870
2022-01-15 23:40:05,754 iteration 26 : loss : 0.377459, loss_ce: 0.257264
2022-01-15 23:40:06,634 iteration 27 : loss : 0.385757, loss_ce: 0.247578
2022-01-15 23:40:07,503 iteration 28 : loss : 0.356964, loss_ce: 0.222638
2022-01-15 23:40:08,465 iteration 29 : loss : 0.372021, loss_ce: 0.230732
2022-01-15 23:40:09,357 iteration 30 : loss : 0.339646, loss_ce: 0.201827
2022-01-15 23:40:10,236 iteration 31 : loss : 0.332400, loss_ce: 0.178243
2022-01-15 23:40:11,153 iteration 32 : loss : 0.337495, loss_ce: 0.213881
2022-01-15 23:40:12,123 iteration 33 : loss : 0.332176, loss_ce: 0.187727
2022-01-15 23:40:13,166 iteration 34 : loss : 0.289051, loss_ce: 0.150902
  0%|▏                              | 2/400 [00:34<1:52:08, 16.91s/it]2022-01-15 23:40:14,199 iteration 35 : loss : 0.296656, loss_ce: 0.159321
2022-01-15 23:40:15,150 iteration 36 : loss : 0.318245, loss_ce: 0.135229
2022-01-15 23:40:16,128 iteration 37 : loss : 0.282813, loss_ce: 0.130762
2022-01-15 23:40:17,075 iteration 38 : loss : 0.295573, loss_ce: 0.133747
2022-01-15 23:40:17,922 iteration 39 : loss : 0.314756, loss_ce: 0.147382
2022-01-15 23:40:18,832 iteration 40 : loss : 0.335137, loss_ce: 0.167413
2022-01-15 23:40:19,659 iteration 41 : loss : 0.270875, loss_ce: 0.129406
2022-01-15 23:40:20,622 iteration 42 : loss : 0.318864, loss_ce: 0.156623
2022-01-15 23:40:21,570 iteration 43 : loss : 0.251900, loss_ce: 0.117517
2022-01-15 23:40:22,414 iteration 44 : loss : 0.285231, loss_ce: 0.148680
2022-01-15 23:40:23,422 iteration 45 : loss : 0.289968, loss_ce: 0.123618
2022-01-15 23:40:24,363 iteration 46 : loss : 0.277639, loss_ce: 0.124837
2022-01-15 23:40:25,303 iteration 47 : loss : 0.271826, loss_ce: 0.109236
2022-01-15 23:40:26,241 iteration 48 : loss : 0.250939, loss_ce: 0.114722
2022-01-15 23:40:27,232 iteration 49 : loss : 0.311547, loss_ce: 0.135824
2022-01-15 23:40:28,223 iteration 50 : loss : 0.259508, loss_ce: 0.110932
2022-01-15 23:40:29,233 iteration 51 : loss : 0.243444, loss_ce: 0.107467
  1%|▏                              | 3/400 [00:50<1:49:20, 16.52s/it]2022-01-15 23:40:30,177 iteration 52 : loss : 0.269098, loss_ce: 0.111992
2022-01-15 23:40:31,025 iteration 53 : loss : 0.243807, loss_ce: 0.115737
2022-01-15 23:40:32,026 iteration 54 : loss : 0.255011, loss_ce: 0.106579
2022-01-15 23:40:32,995 iteration 55 : loss : 0.312581, loss_ce: 0.123925
2022-01-15 23:40:33,973 iteration 56 : loss : 0.291573, loss_ce: 0.140382
2022-01-15 23:40:34,872 iteration 57 : loss : 0.272508, loss_ce: 0.128787
2022-01-15 23:40:35,742 iteration 58 : loss : 0.291848, loss_ce: 0.151760
2022-01-15 23:40:36,622 iteration 59 : loss : 0.273537, loss_ce: 0.132609
2022-01-15 23:40:37,524 iteration 60 : loss : 0.256686, loss_ce: 0.131187
2022-01-15 23:40:38,438 iteration 61 : loss : 0.267893, loss_ce: 0.130004
2022-01-15 23:40:39,444 iteration 62 : loss : 0.297764, loss_ce: 0.121191
2022-01-15 23:40:40,337 iteration 63 : loss : 0.277118, loss_ce: 0.123584
2022-01-15 23:40:41,296 iteration 64 : loss : 0.326857, loss_ce: 0.131030
2022-01-15 23:40:42,240 iteration 65 : loss : 0.248811, loss_ce: 0.091759
2022-01-15 23:40:43,237 iteration 66 : loss : 0.270889, loss_ce: 0.110095
2022-01-15 23:40:44,155 iteration 67 : loss : 0.248989, loss_ce: 0.108710
2022-01-15 23:40:45,014 iteration 68 : loss : 0.250485, loss_ce: 0.109276
  1%|▎                              | 4/400 [01:05<1:47:06, 16.23s/it]2022-01-15 23:40:46,053 iteration 69 : loss : 0.296010, loss_ce: 0.138616
2022-01-15 23:40:46,958 iteration 70 : loss : 0.308420, loss_ce: 0.134192
2022-01-15 23:40:47,883 iteration 71 : loss : 0.276186, loss_ce: 0.146995
2022-01-15 23:40:48,827 iteration 72 : loss : 0.263377, loss_ce: 0.122340
2022-01-15 23:40:49,800 iteration 73 : loss : 0.270308, loss_ce: 0.114879
2022-01-15 23:40:50,756 iteration 74 : loss : 0.242594, loss_ce: 0.101525
2022-01-15 23:40:51,665 iteration 75 : loss : 0.245151, loss_ce: 0.121545
2022-01-15 23:40:52,514 iteration 76 : loss : 0.269044, loss_ce: 0.126983
2022-01-15 23:40:53,470 iteration 77 : loss : 0.290348, loss_ce: 0.132688
2022-01-15 23:40:54,410 iteration 78 : loss : 0.232586, loss_ce: 0.093659
2022-01-15 23:40:55,361 iteration 79 : loss : 0.277878, loss_ce: 0.114073
2022-01-15 23:40:56,205 iteration 80 : loss : 0.256019, loss_ce: 0.102319
2022-01-15 23:40:57,212 iteration 81 : loss : 0.280205, loss_ce: 0.125941
2022-01-15 23:40:58,125 iteration 82 : loss : 0.275069, loss_ce: 0.101706
2022-01-15 23:40:59,006 iteration 83 : loss : 0.290975, loss_ce: 0.092072
2022-01-15 23:41:00,036 iteration 84 : loss : 0.329224, loss_ce: 0.141511
2022-01-15 23:41:00,037 Training Data Eval:
2022-01-15 23:41:04,407   Average segmentation loss on training set: 0.3493
2022-01-15 23:41:04,408 Validation Data Eval:
2022-01-15 23:41:05,869   Average segmentation loss on validation set: 0.3935
2022-01-15 23:41:06,750 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-15 23:41:07,614 iteration 85 : loss : 0.329661, loss_ce: 0.149965
  1%|▍                              | 5/400 [01:28<2:01:59, 18.53s/it]2022-01-15 23:41:08,656 iteration 86 : loss : 0.279691, loss_ce: 0.123717
2022-01-15 23:41:09,571 iteration 87 : loss : 0.294857, loss_ce: 0.115970
2022-01-15 23:41:10,445 iteration 88 : loss : 0.283025, loss_ce: 0.131466
2022-01-15 23:41:11,390 iteration 89 : loss : 0.302149, loss_ce: 0.111487
2022-01-15 23:41:12,316 iteration 90 : loss : 0.277045, loss_ce: 0.111768
2022-01-15 23:41:13,299 iteration 91 : loss : 0.283950, loss_ce: 0.118626
2022-01-15 23:41:14,293 iteration 92 : loss : 0.273708, loss_ce: 0.088359
2022-01-15 23:41:15,163 iteration 93 : loss : 0.264620, loss_ce: 0.082134
2022-01-15 23:41:16,136 iteration 94 : loss : 0.283929, loss_ce: 0.104910
2022-01-15 23:41:17,061 iteration 95 : loss : 0.311072, loss_ce: 0.131095
2022-01-15 23:41:18,066 iteration 96 : loss : 0.273999, loss_ce: 0.097954
2022-01-15 23:41:19,013 iteration 97 : loss : 0.262045, loss_ce: 0.095252
2022-01-15 23:41:19,988 iteration 98 : loss : 0.293701, loss_ce: 0.112319
2022-01-15 23:41:20,910 iteration 99 : loss : 0.310093, loss_ce: 0.116668
2022-01-15 23:41:21,885 iteration 100 : loss : 0.280639, loss_ce: 0.114969
2022-01-15 23:41:22,800 iteration 101 : loss : 0.270936, loss_ce: 0.117413
2022-01-15 23:41:23,701 iteration 102 : loss : 0.271291, loss_ce: 0.130773
  2%|▍                              | 6/400 [01:44<1:56:12, 17.70s/it]2022-01-15 23:41:24,730 iteration 103 : loss : 0.263866, loss_ce: 0.097552
2022-01-15 23:41:25,729 iteration 104 : loss : 0.255504, loss_ce: 0.097954
2022-01-15 23:41:26,725 iteration 105 : loss : 0.216447, loss_ce: 0.082519
2022-01-15 23:41:27,800 iteration 106 : loss : 0.246398, loss_ce: 0.093714
2022-01-15 23:41:28,782 iteration 107 : loss : 0.287137, loss_ce: 0.094831
2022-01-15 23:41:29,718 iteration 108 : loss : 0.248069, loss_ce: 0.078081
2022-01-15 23:41:30,577 iteration 109 : loss : 0.321835, loss_ce: 0.137616
2022-01-15 23:41:31,472 iteration 110 : loss : 0.245932, loss_ce: 0.100048
2022-01-15 23:41:32,467 iteration 111 : loss : 0.227909, loss_ce: 0.097180
2022-01-15 23:41:33,395 iteration 112 : loss : 0.241918, loss_ce: 0.097334
2022-01-15 23:41:34,265 iteration 113 : loss : 0.232920, loss_ce: 0.087926
2022-01-15 23:41:35,240 iteration 114 : loss : 0.236428, loss_ce: 0.089438
2022-01-15 23:41:36,153 iteration 115 : loss : 0.210626, loss_ce: 0.097775
2022-01-15 23:41:37,121 iteration 116 : loss : 0.252783, loss_ce: 0.122025
2022-01-15 23:41:38,021 iteration 117 : loss : 0.228710, loss_ce: 0.095645
2022-01-15 23:41:38,937 iteration 118 : loss : 0.239204, loss_ce: 0.107925
2022-01-15 23:41:39,882 iteration 119 : loss : 0.188984, loss_ce: 0.070202
  2%|▌                              | 7/400 [02:00<1:52:40, 17.20s/it]2022-01-15 23:41:40,959 iteration 120 : loss : 0.244784, loss_ce: 0.107921
2022-01-15 23:41:41,939 iteration 121 : loss : 0.285548, loss_ce: 0.116372
2022-01-15 23:41:42,802 iteration 122 : loss : 0.240137, loss_ce: 0.103753
2022-01-15 23:41:43,786 iteration 123 : loss : 0.218340, loss_ce: 0.089569
2022-01-15 23:41:44,775 iteration 124 : loss : 0.278679, loss_ce: 0.104590
2022-01-15 23:41:45,704 iteration 125 : loss : 0.211453, loss_ce: 0.101319
2022-01-15 23:41:46,681 iteration 126 : loss : 0.271830, loss_ce: 0.104990
2022-01-15 23:41:47,668 iteration 127 : loss : 0.207691, loss_ce: 0.084116
2022-01-15 23:41:48,668 iteration 128 : loss : 0.217227, loss_ce: 0.092089
2022-01-15 23:41:49,573 iteration 129 : loss : 0.201822, loss_ce: 0.069211
2022-01-15 23:41:50,582 iteration 130 : loss : 0.223611, loss_ce: 0.099244
2022-01-15 23:41:51,524 iteration 131 : loss : 0.239978, loss_ce: 0.106166
2022-01-15 23:41:52,413 iteration 132 : loss : 0.208775, loss_ce: 0.071631
2022-01-15 23:41:53,410 iteration 133 : loss : 0.226767, loss_ce: 0.080525
2022-01-15 23:41:54,358 iteration 134 : loss : 0.223606, loss_ce: 0.086090
2022-01-15 23:41:55,315 iteration 135 : loss : 0.244740, loss_ce: 0.096105
2022-01-15 23:41:56,238 iteration 136 : loss : 0.229538, loss_ce: 0.099323
  2%|▌                              | 8/400 [02:17<1:50:36, 16.93s/it]2022-01-15 23:41:57,162 iteration 137 : loss : 0.191716, loss_ce: 0.063841
2022-01-15 23:41:58,048 iteration 138 : loss : 0.202035, loss_ce: 0.090525
2022-01-15 23:41:59,113 iteration 139 : loss : 0.214967, loss_ce: 0.075660
2022-01-15 23:42:00,165 iteration 140 : loss : 0.224272, loss_ce: 0.086039
2022-01-15 23:42:01,125 iteration 141 : loss : 0.219524, loss_ce: 0.078034
2022-01-15 23:42:02,011 iteration 142 : loss : 0.182728, loss_ce: 0.061482
2022-01-15 23:42:02,894 iteration 143 : loss : 0.240703, loss_ce: 0.092539
2022-01-15 23:42:03,878 iteration 144 : loss : 0.211923, loss_ce: 0.073809
2022-01-15 23:42:05,009 iteration 145 : loss : 0.218013, loss_ce: 0.093853
2022-01-15 23:42:05,926 iteration 146 : loss : 0.196190, loss_ce: 0.069230
2022-01-15 23:42:06,854 iteration 147 : loss : 0.221342, loss_ce: 0.087723
2022-01-15 23:42:07,803 iteration 148 : loss : 0.213078, loss_ce: 0.088394
2022-01-15 23:42:08,763 iteration 149 : loss : 0.204637, loss_ce: 0.072943
2022-01-15 23:42:09,700 iteration 150 : loss : 0.257074, loss_ce: 0.117528
2022-01-15 23:42:10,643 iteration 151 : loss : 0.204376, loss_ce: 0.077083
2022-01-15 23:42:11,654 iteration 152 : loss : 0.171522, loss_ce: 0.062404
2022-01-15 23:42:12,667 iteration 153 : loss : 0.177324, loss_ce: 0.067535
  2%|▋                              | 9/400 [02:33<1:49:18, 16.77s/it]2022-01-15 23:42:13,677 iteration 154 : loss : 0.188706, loss_ce: 0.063804
2022-01-15 23:42:14,653 iteration 155 : loss : 0.217406, loss_ce: 0.081866
2022-01-15 23:42:15,613 iteration 156 : loss : 0.181105, loss_ce: 0.067292
2022-01-15 23:42:16,584 iteration 157 : loss : 0.208780, loss_ce: 0.072188
2022-01-15 23:42:17,541 iteration 158 : loss : 0.208318, loss_ce: 0.086799
2022-01-15 23:42:18,490 iteration 159 : loss : 0.219482, loss_ce: 0.082647
2022-01-15 23:42:19,422 iteration 160 : loss : 0.267969, loss_ce: 0.098181
2022-01-15 23:42:20,398 iteration 161 : loss : 0.195316, loss_ce: 0.075939
2022-01-15 23:42:21,434 iteration 162 : loss : 0.183089, loss_ce: 0.069031
2022-01-15 23:42:22,281 iteration 163 : loss : 0.170633, loss_ce: 0.058424
2022-01-15 23:42:23,277 iteration 164 : loss : 0.175207, loss_ce: 0.057081
2022-01-15 23:42:24,201 iteration 165 : loss : 0.162327, loss_ce: 0.050221
2022-01-15 23:42:25,215 iteration 166 : loss : 0.226337, loss_ce: 0.083625
2022-01-15 23:42:26,219 iteration 167 : loss : 0.198085, loss_ce: 0.074499
2022-01-15 23:42:27,214 iteration 168 : loss : 0.198611, loss_ce: 0.073965
2022-01-15 23:42:28,156 iteration 169 : loss : 0.206847, loss_ce: 0.084693
2022-01-15 23:42:28,157 Training Data Eval:
2022-01-15 23:42:32,542   Average segmentation loss on training set: 0.2045
2022-01-15 23:42:32,542 Validation Data Eval:
2022-01-15 23:42:33,999   Average segmentation loss on validation set: 0.2007
2022-01-15 23:42:34,860 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-15 23:42:35,750 iteration 170 : loss : 0.189320, loss_ce: 0.069685
  2%|▊                             | 10/400 [02:56<2:01:41, 18.72s/it]2022-01-15 23:42:36,774 iteration 171 : loss : 0.208870, loss_ce: 0.086682
2022-01-15 23:42:37,595 iteration 172 : loss : 0.246018, loss_ce: 0.086455
2022-01-15 23:42:38,460 iteration 173 : loss : 0.169499, loss_ce: 0.059890
2022-01-15 23:42:39,468 iteration 174 : loss : 0.232457, loss_ce: 0.081284
2022-01-15 23:42:40,384 iteration 175 : loss : 0.204570, loss_ce: 0.079738
2022-01-15 23:42:41,430 iteration 176 : loss : 0.206577, loss_ce: 0.072867
2022-01-15 23:42:42,365 iteration 177 : loss : 0.255158, loss_ce: 0.084248
2022-01-15 23:42:43,365 iteration 178 : loss : 0.184102, loss_ce: 0.052938
2022-01-15 23:42:44,346 iteration 179 : loss : 0.214225, loss_ce: 0.074910
2022-01-15 23:42:45,328 iteration 180 : loss : 0.216417, loss_ce: 0.066047
2022-01-15 23:42:46,320 iteration 181 : loss : 0.181432, loss_ce: 0.054065
2022-01-15 23:42:47,302 iteration 182 : loss : 0.175502, loss_ce: 0.056167
2022-01-15 23:42:48,295 iteration 183 : loss : 0.192626, loss_ce: 0.062121
2022-01-15 23:42:49,245 iteration 184 : loss : 0.188963, loss_ce: 0.074090
2022-01-15 23:42:50,149 iteration 185 : loss : 0.186321, loss_ce: 0.076320
2022-01-15 23:42:51,050 iteration 186 : loss : 0.207360, loss_ce: 0.086521
2022-01-15 23:42:51,929 iteration 187 : loss : 0.226431, loss_ce: 0.098375
  3%|▊                             | 11/400 [03:12<1:56:19, 17.94s/it]2022-01-15 23:42:52,950 iteration 188 : loss : 0.231254, loss_ce: 0.100472
2022-01-15 23:42:53,940 iteration 189 : loss : 0.235970, loss_ce: 0.095959
2022-01-15 23:42:54,956 iteration 190 : loss : 0.205000, loss_ce: 0.073216
2022-01-15 23:42:55,916 iteration 191 : loss : 0.205655, loss_ce: 0.078898
2022-01-15 23:42:56,764 iteration 192 : loss : 0.195569, loss_ce: 0.077588
2022-01-15 23:42:57,648 iteration 193 : loss : 0.235775, loss_ce: 0.085029
2022-01-15 23:42:58,522 iteration 194 : loss : 0.229327, loss_ce: 0.081066
2022-01-15 23:42:59,547 iteration 195 : loss : 0.188393, loss_ce: 0.067635
2022-01-15 23:43:00,525 iteration 196 : loss : 0.186005, loss_ce: 0.052078
2022-01-15 23:43:01,482 iteration 197 : loss : 0.190849, loss_ce: 0.069410
2022-01-15 23:43:02,468 iteration 198 : loss : 0.256099, loss_ce: 0.101642
2022-01-15 23:43:03,448 iteration 199 : loss : 0.205819, loss_ce: 0.085437
2022-01-15 23:43:04,370 iteration 200 : loss : 0.207347, loss_ce: 0.068948
2022-01-15 23:43:05,304 iteration 201 : loss : 0.201606, loss_ce: 0.069137
2022-01-15 23:43:06,127 iteration 202 : loss : 0.196486, loss_ce: 0.067635
2022-01-15 23:43:07,127 iteration 203 : loss : 0.176326, loss_ce: 0.064438
2022-01-15 23:43:08,049 iteration 204 : loss : 0.203847, loss_ce: 0.090749
  3%|▉                             | 12/400 [03:29<1:52:28, 17.39s/it]2022-01-15 23:43:09,164 iteration 205 : loss : 0.205757, loss_ce: 0.078043
2022-01-15 23:43:10,119 iteration 206 : loss : 0.266382, loss_ce: 0.104005
2022-01-15 23:43:11,146 iteration 207 : loss : 0.229024, loss_ce: 0.087787
2022-01-15 23:43:12,144 iteration 208 : loss : 0.195105, loss_ce: 0.084491
2022-01-15 23:43:13,117 iteration 209 : loss : 0.200834, loss_ce: 0.075668
2022-01-15 23:43:14,047 iteration 210 : loss : 0.172550, loss_ce: 0.065231
2022-01-15 23:43:15,000 iteration 211 : loss : 0.171361, loss_ce: 0.062239
2022-01-15 23:43:16,008 iteration 212 : loss : 0.198530, loss_ce: 0.080297
2022-01-15 23:43:17,007 iteration 213 : loss : 0.175656, loss_ce: 0.065630
2022-01-15 23:43:17,939 iteration 214 : loss : 0.197891, loss_ce: 0.071512
2022-01-15 23:43:18,841 iteration 215 : loss : 0.198808, loss_ce: 0.072113
2022-01-15 23:43:19,839 iteration 216 : loss : 0.178042, loss_ce: 0.062814
2022-01-15 23:43:20,850 iteration 217 : loss : 0.196858, loss_ce: 0.070844
2022-01-15 23:43:21,777 iteration 218 : loss : 0.198774, loss_ce: 0.078993
2022-01-15 23:43:22,695 iteration 219 : loss : 0.174532, loss_ce: 0.071998
2022-01-15 23:43:23,650 iteration 220 : loss : 0.164715, loss_ce: 0.057777
2022-01-15 23:43:24,640 iteration 221 : loss : 0.211796, loss_ce: 0.078026
  3%|▉                             | 13/400 [03:45<1:50:34, 17.14s/it]2022-01-15 23:43:25,657 iteration 222 : loss : 0.191609, loss_ce: 0.069993
2022-01-15 23:43:26,577 iteration 223 : loss : 0.257444, loss_ce: 0.117186
2022-01-15 23:43:27,498 iteration 224 : loss : 0.185074, loss_ce: 0.057196
2022-01-15 23:43:28,570 iteration 225 : loss : 0.166452, loss_ce: 0.062510
2022-01-15 23:43:29,547 iteration 226 : loss : 0.196577, loss_ce: 0.069061
2022-01-15 23:43:30,479 iteration 227 : loss : 0.187582, loss_ce: 0.064622
2022-01-15 23:43:31,408 iteration 228 : loss : 0.169428, loss_ce: 0.055419
2022-01-15 23:43:32,373 iteration 229 : loss : 0.177942, loss_ce: 0.062641
2022-01-15 23:43:33,261 iteration 230 : loss : 0.158258, loss_ce: 0.061125
2022-01-15 23:43:34,211 iteration 231 : loss : 0.166266, loss_ce: 0.058376
2022-01-15 23:43:35,139 iteration 232 : loss : 0.187820, loss_ce: 0.071285
2022-01-15 23:43:36,002 iteration 233 : loss : 0.168997, loss_ce: 0.068021
2022-01-15 23:43:36,925 iteration 234 : loss : 0.165621, loss_ce: 0.056096
2022-01-15 23:43:37,818 iteration 235 : loss : 0.169742, loss_ce: 0.057165
2022-01-15 23:43:38,748 iteration 236 : loss : 0.234351, loss_ce: 0.090360
2022-01-15 23:43:39,627 iteration 237 : loss : 0.224168, loss_ce: 0.102565
2022-01-15 23:43:40,606 iteration 238 : loss : 0.179801, loss_ce: 0.056599
  4%|█                             | 14/400 [04:01<1:48:02, 16.79s/it]2022-01-15 23:43:41,604 iteration 239 : loss : 0.187558, loss_ce: 0.063638
2022-01-15 23:43:42,637 iteration 240 : loss : 0.169498, loss_ce: 0.050845
2022-01-15 23:43:43,631 iteration 241 : loss : 0.190705, loss_ce: 0.067400
2022-01-15 23:43:44,556 iteration 242 : loss : 0.140885, loss_ce: 0.048610
2022-01-15 23:43:45,479 iteration 243 : loss : 0.153872, loss_ce: 0.053519
2022-01-15 23:43:46,411 iteration 244 : loss : 0.192295, loss_ce: 0.075694
2022-01-15 23:43:47,296 iteration 245 : loss : 0.169881, loss_ce: 0.053175
2022-01-15 23:43:48,210 iteration 246 : loss : 0.205685, loss_ce: 0.064411
2022-01-15 23:43:49,176 iteration 247 : loss : 0.190652, loss_ce: 0.072632
2022-01-15 23:43:50,155 iteration 248 : loss : 0.159940, loss_ce: 0.067018
2022-01-15 23:43:51,079 iteration 249 : loss : 0.159413, loss_ce: 0.057922
2022-01-15 23:43:52,006 iteration 250 : loss : 0.186536, loss_ce: 0.059872
2022-01-15 23:43:52,882 iteration 251 : loss : 0.144726, loss_ce: 0.057514
2022-01-15 23:43:53,905 iteration 252 : loss : 0.173318, loss_ce: 0.077582
2022-01-15 23:43:54,853 iteration 253 : loss : 0.146826, loss_ce: 0.052993
2022-01-15 23:43:55,769 iteration 254 : loss : 0.159410, loss_ce: 0.065888
2022-01-15 23:43:55,769 Training Data Eval:
2022-01-15 23:44:00,152   Average segmentation loss on training set: 0.1996
2022-01-15 23:44:00,152 Validation Data Eval:
2022-01-15 23:44:01,611   Average segmentation loss on validation set: 0.2418
2022-01-15 23:44:02,473 iteration 255 : loss : 0.215543, loss_ce: 0.101641
  4%|█▏                            | 15/400 [04:23<1:57:33, 18.32s/it]2022-01-15 23:44:03,408 iteration 256 : loss : 0.164432, loss_ce: 0.062405
2022-01-15 23:44:04,298 iteration 257 : loss : 0.174159, loss_ce: 0.070298
2022-01-15 23:44:05,284 iteration 258 : loss : 0.154481, loss_ce: 0.064490
2022-01-15 23:44:06,228 iteration 259 : loss : 0.173967, loss_ce: 0.063332
2022-01-15 23:44:07,120 iteration 260 : loss : 0.131164, loss_ce: 0.068762
2022-01-15 23:44:08,090 iteration 261 : loss : 0.158589, loss_ce: 0.060798
2022-01-15 23:44:09,085 iteration 262 : loss : 0.214838, loss_ce: 0.085108
2022-01-15 23:44:09,973 iteration 263 : loss : 0.174979, loss_ce: 0.069609
2022-01-15 23:44:10,962 iteration 264 : loss : 0.219480, loss_ce: 0.066369
2022-01-15 23:44:12,013 iteration 265 : loss : 0.223983, loss_ce: 0.111601
2022-01-15 23:44:12,980 iteration 266 : loss : 0.202096, loss_ce: 0.074935
2022-01-15 23:44:14,022 iteration 267 : loss : 0.134586, loss_ce: 0.042789
2022-01-15 23:44:14,991 iteration 268 : loss : 0.160885, loss_ce: 0.058046
2022-01-15 23:44:15,948 iteration 269 : loss : 0.220841, loss_ce: 0.087296
2022-01-15 23:44:16,879 iteration 270 : loss : 0.270640, loss_ce: 0.101131
2022-01-15 23:44:17,797 iteration 271 : loss : 0.170558, loss_ce: 0.067087
2022-01-15 23:44:18,686 iteration 272 : loss : 0.141356, loss_ce: 0.051566
  4%|█▏                            | 16/400 [04:39<1:53:12, 17.69s/it]2022-01-15 23:44:19,751 iteration 273 : loss : 0.207794, loss_ce: 0.079224
2022-01-15 23:44:20,696 iteration 274 : loss : 0.247793, loss_ce: 0.119642
2022-01-15 23:44:21,624 iteration 275 : loss : 0.254487, loss_ce: 0.075504
2022-01-15 23:44:22,544 iteration 276 : loss : 0.145888, loss_ce: 0.053928
2022-01-15 23:44:23,454 iteration 277 : loss : 0.148420, loss_ce: 0.051539
2022-01-15 23:44:24,402 iteration 278 : loss : 0.226802, loss_ce: 0.097002
2022-01-15 23:44:25,334 iteration 279 : loss : 0.164521, loss_ce: 0.061122
2022-01-15 23:44:26,271 iteration 280 : loss : 0.198125, loss_ce: 0.086888
2022-01-15 23:44:27,264 iteration 281 : loss : 0.175097, loss_ce: 0.076041
2022-01-15 23:44:28,237 iteration 282 : loss : 0.122906, loss_ce: 0.042716
2022-01-15 23:44:29,151 iteration 283 : loss : 0.142002, loss_ce: 0.052169
2022-01-15 23:44:30,114 iteration 284 : loss : 0.141752, loss_ce: 0.072711
2022-01-15 23:44:31,103 iteration 285 : loss : 0.170436, loss_ce: 0.054420
2022-01-15 23:44:31,945 iteration 286 : loss : 0.186831, loss_ce: 0.070981
2022-01-15 23:44:32,879 iteration 287 : loss : 0.192905, loss_ce: 0.075646
2022-01-15 23:44:33,831 iteration 288 : loss : 0.153659, loss_ce: 0.060130
2022-01-15 23:44:34,744 iteration 289 : loss : 0.192526, loss_ce: 0.070417
  4%|█▎                            | 17/400 [04:55<1:49:46, 17.20s/it]2022-01-15 23:44:35,788 iteration 290 : loss : 0.180315, loss_ce: 0.078074
2022-01-15 23:44:36,682 iteration 291 : loss : 0.151266, loss_ce: 0.053673
2022-01-15 23:44:37,565 iteration 292 : loss : 0.147215, loss_ce: 0.058605
2022-01-15 23:44:38,553 iteration 293 : loss : 0.188403, loss_ce: 0.071056
2022-01-15 23:44:39,473 iteration 294 : loss : 0.148340, loss_ce: 0.051076
2022-01-15 23:44:40,468 iteration 295 : loss : 0.162244, loss_ce: 0.069743
2022-01-15 23:44:41,476 iteration 296 : loss : 0.184718, loss_ce: 0.069342
2022-01-15 23:44:42,446 iteration 297 : loss : 0.142656, loss_ce: 0.061485
2022-01-15 23:44:43,370 iteration 298 : loss : 0.148224, loss_ce: 0.061880
2022-01-15 23:44:44,236 iteration 299 : loss : 0.203648, loss_ce: 0.074413
2022-01-15 23:44:45,143 iteration 300 : loss : 0.186983, loss_ce: 0.079355
2022-01-15 23:44:45,990 iteration 301 : loss : 0.190798, loss_ce: 0.070310
2022-01-15 23:44:46,992 iteration 302 : loss : 0.201852, loss_ce: 0.063937
2022-01-15 23:44:47,980 iteration 303 : loss : 0.140555, loss_ce: 0.048060
2022-01-15 23:44:48,974 iteration 304 : loss : 0.206557, loss_ce: 0.089093
2022-01-15 23:44:49,887 iteration 305 : loss : 0.151864, loss_ce: 0.061103
2022-01-15 23:44:50,814 iteration 306 : loss : 0.211657, loss_ce: 0.080851
  4%|█▎                            | 18/400 [05:11<1:47:20, 16.86s/it]2022-01-15 23:44:51,750 iteration 307 : loss : 0.226128, loss_ce: 0.080105
2022-01-15 23:44:52,608 iteration 308 : loss : 0.173088, loss_ce: 0.060417
2022-01-15 23:44:53,482 iteration 309 : loss : 0.179004, loss_ce: 0.081111
2022-01-15 23:44:54,427 iteration 310 : loss : 0.180143, loss_ce: 0.075134
2022-01-15 23:44:55,406 iteration 311 : loss : 0.175236, loss_ce: 0.070480
2022-01-15 23:44:56,395 iteration 312 : loss : 0.160319, loss_ce: 0.062941
2022-01-15 23:44:57,300 iteration 313 : loss : 0.169342, loss_ce: 0.064434
2022-01-15 23:44:58,253 iteration 314 : loss : 0.142431, loss_ce: 0.064927
2022-01-15 23:44:59,254 iteration 315 : loss : 0.171807, loss_ce: 0.067907
2022-01-15 23:45:00,202 iteration 316 : loss : 0.160795, loss_ce: 0.057976
2022-01-15 23:45:01,086 iteration 317 : loss : 0.173069, loss_ce: 0.064418
2022-01-15 23:45:01,990 iteration 318 : loss : 0.162504, loss_ce: 0.061582
2022-01-15 23:45:02,997 iteration 319 : loss : 0.140335, loss_ce: 0.053467
2022-01-15 23:45:03,906 iteration 320 : loss : 0.195100, loss_ce: 0.063749
2022-01-15 23:45:04,779 iteration 321 : loss : 0.174269, loss_ce: 0.072993
2022-01-15 23:45:05,722 iteration 322 : loss : 0.157983, loss_ce: 0.056337
2022-01-15 23:45:06,720 iteration 323 : loss : 0.192074, loss_ce: 0.073362
  5%|█▍                            | 19/400 [05:27<1:45:14, 16.57s/it]2022-01-15 23:45:07,650 iteration 324 : loss : 0.192168, loss_ce: 0.070432
2022-01-15 23:45:08,577 iteration 325 : loss : 0.166539, loss_ce: 0.055322
2022-01-15 23:45:09,501 iteration 326 : loss : 0.167464, loss_ce: 0.062526
2022-01-15 23:45:10,532 iteration 327 : loss : 0.169436, loss_ce: 0.057989
2022-01-15 23:45:11,526 iteration 328 : loss : 0.159874, loss_ce: 0.060780
2022-01-15 23:45:12,480 iteration 329 : loss : 0.175844, loss_ce: 0.063367
2022-01-15 23:45:13,325 iteration 330 : loss : 0.144479, loss_ce: 0.058147
2022-01-15 23:45:14,321 iteration 331 : loss : 0.147387, loss_ce: 0.049847
2022-01-15 23:45:15,316 iteration 332 : loss : 0.159446, loss_ce: 0.059232
2022-01-15 23:45:16,196 iteration 333 : loss : 0.146262, loss_ce: 0.051889
2022-01-15 23:45:17,181 iteration 334 : loss : 0.163602, loss_ce: 0.075944
2022-01-15 23:45:18,091 iteration 335 : loss : 0.201045, loss_ce: 0.064975
2022-01-15 23:45:19,075 iteration 336 : loss : 0.138890, loss_ce: 0.053238
2022-01-15 23:45:19,977 iteration 337 : loss : 0.155686, loss_ce: 0.054752
2022-01-15 23:45:20,840 iteration 338 : loss : 0.165836, loss_ce: 0.073800
2022-01-15 23:45:21,772 iteration 339 : loss : 0.135298, loss_ce: 0.047492
2022-01-15 23:45:21,772 Training Data Eval:
2022-01-15 23:45:26,152   Average segmentation loss on training set: 0.4334
2022-01-15 23:45:26,152 Validation Data Eval:
2022-01-15 23:45:27,616   Average segmentation loss on validation set: 0.5065
2022-01-15 23:45:28,522 iteration 340 : loss : 0.168597, loss_ce: 0.067717
  5%|█▌                            | 20/400 [05:49<1:54:53, 18.14s/it]2022-01-15 23:45:29,577 iteration 341 : loss : 0.188607, loss_ce: 0.076973
2022-01-15 23:45:30,592 iteration 342 : loss : 0.139812, loss_ce: 0.058532
2022-01-15 23:45:31,666 iteration 343 : loss : 0.192705, loss_ce: 0.091975
2022-01-15 23:45:32,606 iteration 344 : loss : 0.183225, loss_ce: 0.058575
2022-01-15 23:45:33,575 iteration 345 : loss : 0.188260, loss_ce: 0.075919
2022-01-15 23:45:34,606 iteration 346 : loss : 0.194783, loss_ce: 0.073123
2022-01-15 23:45:35,516 iteration 347 : loss : 0.159903, loss_ce: 0.056002
2022-01-15 23:45:36,572 iteration 348 : loss : 0.167783, loss_ce: 0.064573
2022-01-15 23:45:37,515 iteration 349 : loss : 0.157805, loss_ce: 0.066302
2022-01-15 23:45:38,359 iteration 350 : loss : 0.146877, loss_ce: 0.056391
2022-01-15 23:45:39,374 iteration 351 : loss : 0.171297, loss_ce: 0.054791
2022-01-15 23:45:40,320 iteration 352 : loss : 0.178217, loss_ce: 0.065936
2022-01-15 23:45:41,370 iteration 353 : loss : 0.148257, loss_ce: 0.054271
2022-01-15 23:45:42,347 iteration 354 : loss : 0.154280, loss_ce: 0.065874
2022-01-15 23:45:43,377 iteration 355 : loss : 0.150172, loss_ce: 0.053343
2022-01-15 23:45:44,278 iteration 356 : loss : 0.171982, loss_ce: 0.067876
2022-01-15 23:45:45,200 iteration 357 : loss : 0.168522, loss_ce: 0.064956
  5%|█▌                            | 21/400 [06:06<1:51:50, 17.71s/it]2022-01-15 23:45:46,294 iteration 358 : loss : 0.178298, loss_ce: 0.062925
2022-01-15 23:45:47,312 iteration 359 : loss : 0.149270, loss_ce: 0.059025
2022-01-15 23:45:48,268 iteration 360 : loss : 0.221442, loss_ce: 0.064347
2022-01-15 23:45:49,256 iteration 361 : loss : 0.194462, loss_ce: 0.064871
2022-01-15 23:45:50,114 iteration 362 : loss : 0.148937, loss_ce: 0.055853
2022-01-15 23:45:51,142 iteration 363 : loss : 0.175855, loss_ce: 0.080576
2022-01-15 23:45:52,109 iteration 364 : loss : 0.219860, loss_ce: 0.104749
2022-01-15 23:45:53,040 iteration 365 : loss : 0.167248, loss_ce: 0.056328
2022-01-15 23:45:53,978 iteration 366 : loss : 0.123082, loss_ce: 0.044992
2022-01-15 23:45:54,971 iteration 367 : loss : 0.167945, loss_ce: 0.070925
2022-01-15 23:45:55,858 iteration 368 : loss : 0.216074, loss_ce: 0.073246
2022-01-15 23:45:56,841 iteration 369 : loss : 0.182418, loss_ce: 0.079073
2022-01-15 23:45:57,698 iteration 370 : loss : 0.206690, loss_ce: 0.063353
2022-01-15 23:45:58,705 iteration 371 : loss : 0.155052, loss_ce: 0.069022
2022-01-15 23:45:59,716 iteration 372 : loss : 0.139641, loss_ce: 0.046873
2022-01-15 23:46:00,680 iteration 373 : loss : 0.149611, loss_ce: 0.048811
2022-01-15 23:46:01,595 iteration 374 : loss : 0.134091, loss_ce: 0.051231
  6%|█▋                            | 22/400 [06:22<1:49:02, 17.31s/it]2022-01-15 23:46:02,655 iteration 375 : loss : 0.157814, loss_ce: 0.055307
2022-01-15 23:46:03,642 iteration 376 : loss : 0.171077, loss_ce: 0.058282
2022-01-15 23:46:04,632 iteration 377 : loss : 0.164532, loss_ce: 0.047200
2022-01-15 23:46:05,609 iteration 378 : loss : 0.192778, loss_ce: 0.087199
2022-01-15 23:46:06,498 iteration 379 : loss : 0.164535, loss_ce: 0.052875
2022-01-15 23:46:07,483 iteration 380 : loss : 0.150539, loss_ce: 0.064403
2022-01-15 23:46:08,329 iteration 381 : loss : 0.116069, loss_ce: 0.040058
2022-01-15 23:46:09,392 iteration 382 : loss : 0.148062, loss_ce: 0.063609
2022-01-15 23:46:10,388 iteration 383 : loss : 0.176734, loss_ce: 0.066991
2022-01-15 23:46:11,331 iteration 384 : loss : 0.162217, loss_ce: 0.066695
2022-01-15 23:46:12,237 iteration 385 : loss : 0.122079, loss_ce: 0.047616
2022-01-15 23:46:13,222 iteration 386 : loss : 0.199470, loss_ce: 0.077440
2022-01-15 23:46:14,195 iteration 387 : loss : 0.190079, loss_ce: 0.074214
2022-01-15 23:46:15,210 iteration 388 : loss : 0.138363, loss_ce: 0.055407
2022-01-15 23:46:16,126 iteration 389 : loss : 0.193909, loss_ce: 0.061651
2022-01-15 23:46:17,109 iteration 390 : loss : 0.154823, loss_ce: 0.074194
2022-01-15 23:46:18,023 iteration 391 : loss : 0.172125, loss_ce: 0.057414
  6%|█▋                            | 23/400 [06:38<1:47:05, 17.04s/it]2022-01-15 23:46:19,169 iteration 392 : loss : 0.134619, loss_ce: 0.054913
2022-01-15 23:46:20,076 iteration 393 : loss : 0.174398, loss_ce: 0.074201
2022-01-15 23:46:21,042 iteration 394 : loss : 0.180059, loss_ce: 0.064800
2022-01-15 23:46:21,969 iteration 395 : loss : 0.178001, loss_ce: 0.083679
2022-01-15 23:46:22,969 iteration 396 : loss : 0.128158, loss_ce: 0.050533
2022-01-15 23:46:23,962 iteration 397 : loss : 0.150401, loss_ce: 0.054194
2022-01-15 23:46:24,937 iteration 398 : loss : 0.158206, loss_ce: 0.064307
2022-01-15 23:46:25,876 iteration 399 : loss : 0.121149, loss_ce: 0.041580
2022-01-15 23:46:26,888 iteration 400 : loss : 0.140043, loss_ce: 0.054515
2022-01-15 23:46:27,755 iteration 401 : loss : 0.161954, loss_ce: 0.051742
2022-01-15 23:46:28,758 iteration 402 : loss : 0.173926, loss_ce: 0.065217
2022-01-15 23:46:29,800 iteration 403 : loss : 0.171111, loss_ce: 0.056300
2022-01-15 23:46:30,754 iteration 404 : loss : 0.140892, loss_ce: 0.040857
2022-01-15 23:46:31,750 iteration 405 : loss : 0.168843, loss_ce: 0.055223
2022-01-15 23:46:32,662 iteration 406 : loss : 0.139006, loss_ce: 0.059324
2022-01-15 23:46:33,568 iteration 407 : loss : 0.140985, loss_ce: 0.054145
2022-01-15 23:46:34,473 iteration 408 : loss : 0.120674, loss_ce: 0.042720
  6%|█▊                            | 24/400 [06:55<1:45:40, 16.86s/it]2022-01-15 23:46:35,623 iteration 409 : loss : 0.113019, loss_ce: 0.040570
2022-01-15 23:46:36,564 iteration 410 : loss : 0.152918, loss_ce: 0.049446
2022-01-15 23:46:37,548 iteration 411 : loss : 0.117876, loss_ce: 0.039041
2022-01-15 23:46:38,491 iteration 412 : loss : 0.157757, loss_ce: 0.060419
2022-01-15 23:46:39,421 iteration 413 : loss : 0.138573, loss_ce: 0.056538
2022-01-15 23:46:40,381 iteration 414 : loss : 0.130752, loss_ce: 0.054803
2022-01-15 23:46:41,390 iteration 415 : loss : 0.156187, loss_ce: 0.073363
2022-01-15 23:46:42,211 iteration 416 : loss : 0.146419, loss_ce: 0.047874
2022-01-15 23:46:43,147 iteration 417 : loss : 0.184891, loss_ce: 0.066421
2022-01-15 23:46:44,108 iteration 418 : loss : 0.146760, loss_ce: 0.044294
2022-01-15 23:46:45,033 iteration 419 : loss : 0.219954, loss_ce: 0.085477
2022-01-15 23:46:45,988 iteration 420 : loss : 0.142863, loss_ce: 0.053284
2022-01-15 23:46:46,837 iteration 421 : loss : 0.165175, loss_ce: 0.041447
2022-01-15 23:46:47,819 iteration 422 : loss : 0.161616, loss_ce: 0.054231
2022-01-15 23:46:48,735 iteration 423 : loss : 0.154473, loss_ce: 0.055856
2022-01-15 23:46:49,649 iteration 424 : loss : 0.167609, loss_ce: 0.066367
2022-01-15 23:46:49,649 Training Data Eval:
2022-01-15 23:46:54,048   Average segmentation loss on training set: 0.3595
2022-01-15 23:46:54,048 Validation Data Eval:
2022-01-15 23:46:55,503   Average segmentation loss on validation set: 0.4605
2022-01-15 23:46:56,502 iteration 425 : loss : 0.197537, loss_ce: 0.082907
  6%|█▉                            | 25/400 [07:17<1:55:05, 18.41s/it]2022-01-15 23:46:57,555 iteration 426 : loss : 0.154420, loss_ce: 0.067902
2022-01-15 23:46:58,458 iteration 427 : loss : 0.139733, loss_ce: 0.052614
2022-01-15 23:46:59,512 iteration 428 : loss : 0.152140, loss_ce: 0.062808
2022-01-15 23:47:00,434 iteration 429 : loss : 0.151195, loss_ce: 0.052556
2022-01-15 23:47:01,296 iteration 430 : loss : 0.157133, loss_ce: 0.063395
2022-01-15 23:47:02,274 iteration 431 : loss : 0.128718, loss_ce: 0.056601
2022-01-15 23:47:03,242 iteration 432 : loss : 0.132678, loss_ce: 0.043208
2022-01-15 23:47:04,117 iteration 433 : loss : 0.145030, loss_ce: 0.051863
2022-01-15 23:47:05,008 iteration 434 : loss : 0.128251, loss_ce: 0.039065
2022-01-15 23:47:05,960 iteration 435 : loss : 0.112926, loss_ce: 0.038538
2022-01-15 23:47:06,942 iteration 436 : loss : 0.170542, loss_ce: 0.050367
2022-01-15 23:47:07,849 iteration 437 : loss : 0.159302, loss_ce: 0.060142
2022-01-15 23:47:08,752 iteration 438 : loss : 0.169875, loss_ce: 0.057841
2022-01-15 23:47:09,671 iteration 439 : loss : 0.135337, loss_ce: 0.048041
2022-01-15 23:47:10,755 iteration 440 : loss : 0.170487, loss_ce: 0.063450
2022-01-15 23:47:11,688 iteration 441 : loss : 0.141841, loss_ce: 0.067670
2022-01-15 23:47:12,596 iteration 442 : loss : 0.109636, loss_ce: 0.039130
  6%|█▉                            | 26/400 [07:33<1:50:27, 17.72s/it]2022-01-15 23:47:13,650 iteration 443 : loss : 0.178747, loss_ce: 0.072595
2022-01-15 23:47:14,551 iteration 444 : loss : 0.156345, loss_ce: 0.063546
2022-01-15 23:47:15,437 iteration 445 : loss : 0.201224, loss_ce: 0.087006
2022-01-15 23:47:16,356 iteration 446 : loss : 0.153463, loss_ce: 0.054592
2022-01-15 23:47:17,345 iteration 447 : loss : 0.122711, loss_ce: 0.041742
2022-01-15 23:47:18,205 iteration 448 : loss : 0.181481, loss_ce: 0.062042
2022-01-15 23:47:19,106 iteration 449 : loss : 0.188951, loss_ce: 0.048733
2022-01-15 23:47:19,960 iteration 450 : loss : 0.146001, loss_ce: 0.058067
2022-01-15 23:47:20,884 iteration 451 : loss : 0.159581, loss_ce: 0.056358
2022-01-15 23:47:21,827 iteration 452 : loss : 0.136465, loss_ce: 0.040586
2022-01-15 23:47:22,741 iteration 453 : loss : 0.155600, loss_ce: 0.054410
2022-01-15 23:47:23,783 iteration 454 : loss : 0.152531, loss_ce: 0.063563
2022-01-15 23:47:24,769 iteration 455 : loss : 0.135583, loss_ce: 0.057725
2022-01-15 23:47:25,706 iteration 456 : loss : 0.143780, loss_ce: 0.048335
2022-01-15 23:47:26,625 iteration 457 : loss : 0.140973, loss_ce: 0.070599
2022-01-15 23:47:27,541 iteration 458 : loss : 0.162216, loss_ce: 0.083276
2022-01-15 23:47:28,487 iteration 459 : loss : 0.161600, loss_ce: 0.068266
  7%|██                            | 27/400 [07:49<1:46:44, 17.17s/it]2022-01-15 23:47:29,431 iteration 460 : loss : 0.158356, loss_ce: 0.072546
2022-01-15 23:47:30,339 iteration 461 : loss : 0.122602, loss_ce: 0.049618
2022-01-15 23:47:31,355 iteration 462 : loss : 0.159325, loss_ce: 0.056409
2022-01-15 23:47:32,308 iteration 463 : loss : 0.197265, loss_ce: 0.066266
2022-01-15 23:47:33,404 iteration 464 : loss : 0.201023, loss_ce: 0.077886
2022-01-15 23:47:34,398 iteration 465 : loss : 0.161441, loss_ce: 0.053284
2022-01-15 23:47:35,312 iteration 466 : loss : 0.149600, loss_ce: 0.054081
2022-01-15 23:47:36,243 iteration 467 : loss : 0.158364, loss_ce: 0.060643
2022-01-15 23:47:37,157 iteration 468 : loss : 0.094672, loss_ce: 0.037055
2022-01-15 23:47:38,145 iteration 469 : loss : 0.111279, loss_ce: 0.047858
2022-01-15 23:47:39,090 iteration 470 : loss : 0.106992, loss_ce: 0.045905
2022-01-15 23:47:40,034 iteration 471 : loss : 0.237324, loss_ce: 0.128547
2022-01-15 23:47:41,019 iteration 472 : loss : 0.109320, loss_ce: 0.049734
2022-01-15 23:47:41,977 iteration 473 : loss : 0.157058, loss_ce: 0.056372
2022-01-15 23:47:42,878 iteration 474 : loss : 0.161255, loss_ce: 0.051437
2022-01-15 23:47:43,812 iteration 475 : loss : 0.182101, loss_ce: 0.058093
2022-01-15 23:47:44,837 iteration 476 : loss : 0.130653, loss_ce: 0.047908
  7%|██                            | 28/400 [08:05<1:44:55, 16.92s/it]2022-01-15 23:47:45,841 iteration 477 : loss : 0.112715, loss_ce: 0.044056
2022-01-15 23:47:46,717 iteration 478 : loss : 0.126448, loss_ce: 0.055167
2022-01-15 23:47:47,700 iteration 479 : loss : 0.156959, loss_ce: 0.050066
2022-01-15 23:47:48,644 iteration 480 : loss : 0.176611, loss_ce: 0.060465
2022-01-15 23:47:49,538 iteration 481 : loss : 0.167513, loss_ce: 0.044151
2022-01-15 23:47:50,563 iteration 482 : loss : 0.156312, loss_ce: 0.055473
2022-01-15 23:47:51,438 iteration 483 : loss : 0.163056, loss_ce: 0.079390
2022-01-15 23:47:52,393 iteration 484 : loss : 0.151501, loss_ce: 0.051332
2022-01-15 23:47:53,348 iteration 485 : loss : 0.161372, loss_ce: 0.065050
2022-01-15 23:47:54,405 iteration 486 : loss : 0.121312, loss_ce: 0.042900
2022-01-15 23:47:55,342 iteration 487 : loss : 0.166542, loss_ce: 0.054233
2022-01-15 23:47:56,198 iteration 488 : loss : 0.138064, loss_ce: 0.058071
2022-01-15 23:47:57,170 iteration 489 : loss : 0.143760, loss_ce: 0.061359
2022-01-15 23:47:58,106 iteration 490 : loss : 0.170189, loss_ce: 0.077111
2022-01-15 23:47:59,107 iteration 491 : loss : 0.172673, loss_ce: 0.053631
2022-01-15 23:48:00,012 iteration 492 : loss : 0.135455, loss_ce: 0.064405
2022-01-15 23:48:00,911 iteration 493 : loss : 0.141368, loss_ce: 0.064288
  7%|██▏                           | 29/400 [08:21<1:43:05, 16.67s/it]2022-01-15 23:48:01,915 iteration 494 : loss : 0.173451, loss_ce: 0.071282
2022-01-15 23:48:02,788 iteration 495 : loss : 0.151019, loss_ce: 0.050092
2022-01-15 23:48:03,735 iteration 496 : loss : 0.139333, loss_ce: 0.047691
2022-01-15 23:48:04,759 iteration 497 : loss : 0.166704, loss_ce: 0.060178
2022-01-15 23:48:05,815 iteration 498 : loss : 0.169010, loss_ce: 0.087273
2022-01-15 23:48:06,796 iteration 499 : loss : 0.145818, loss_ce: 0.045737
2022-01-15 23:48:07,882 iteration 500 : loss : 0.148792, loss_ce: 0.052829
2022-01-15 23:48:08,838 iteration 501 : loss : 0.131867, loss_ce: 0.040484
2022-01-15 23:48:09,728 iteration 502 : loss : 0.134832, loss_ce: 0.052957
2022-01-15 23:48:10,783 iteration 503 : loss : 0.127288, loss_ce: 0.035888
2022-01-15 23:48:11,854 iteration 504 : loss : 0.139636, loss_ce: 0.046750
2022-01-15 23:48:12,777 iteration 505 : loss : 0.126570, loss_ce: 0.047003
2022-01-15 23:48:13,754 iteration 506 : loss : 0.165331, loss_ce: 0.054517
2022-01-15 23:48:14,766 iteration 507 : loss : 0.101771, loss_ce: 0.035759
2022-01-15 23:48:15,716 iteration 508 : loss : 0.138240, loss_ce: 0.058357
2022-01-15 23:48:16,695 iteration 509 : loss : 0.137374, loss_ce: 0.058234
2022-01-15 23:48:16,696 Training Data Eval:
2022-01-15 23:48:21,087   Average segmentation loss on training set: 0.4158
2022-01-15 23:48:21,088 Validation Data Eval:
2022-01-15 23:48:22,545   Average segmentation loss on validation set: 0.3325
2022-01-15 23:48:23,379 iteration 510 : loss : 0.157151, loss_ce: 0.059944
  8%|██▎                           | 30/400 [08:44<1:53:30, 18.41s/it]2022-01-15 23:48:24,237 iteration 511 : loss : 0.112216, loss_ce: 0.047594
2022-01-15 23:48:25,338 iteration 512 : loss : 0.163338, loss_ce: 0.064611
2022-01-15 23:48:26,221 iteration 513 : loss : 0.169399, loss_ce: 0.083914
2022-01-15 23:48:27,201 iteration 514 : loss : 0.168833, loss_ce: 0.060895
2022-01-15 23:48:28,113 iteration 515 : loss : 0.129241, loss_ce: 0.045943
2022-01-15 23:48:28,961 iteration 516 : loss : 0.096953, loss_ce: 0.042650
2022-01-15 23:48:30,059 iteration 517 : loss : 0.159482, loss_ce: 0.063180
2022-01-15 23:48:31,034 iteration 518 : loss : 0.194627, loss_ce: 0.083971
2022-01-15 23:48:31,933 iteration 519 : loss : 0.105410, loss_ce: 0.041617
2022-01-15 23:48:32,828 iteration 520 : loss : 0.155797, loss_ce: 0.073244
2022-01-15 23:48:33,867 iteration 521 : loss : 0.223770, loss_ce: 0.059256
2022-01-15 23:48:34,767 iteration 522 : loss : 0.124435, loss_ce: 0.050059
2022-01-15 23:48:35,745 iteration 523 : loss : 0.129820, loss_ce: 0.052278
2022-01-15 23:48:36,557 iteration 524 : loss : 0.174151, loss_ce: 0.081269
2022-01-15 23:48:37,481 iteration 525 : loss : 0.129617, loss_ce: 0.049175
2022-01-15 23:48:38,450 iteration 526 : loss : 0.117012, loss_ce: 0.042225
2022-01-15 23:48:39,380 iteration 527 : loss : 0.147706, loss_ce: 0.056827
  8%|██▎                           | 31/400 [09:00<1:48:47, 17.69s/it]2022-01-15 23:48:40,442 iteration 528 : loss : 0.088119, loss_ce: 0.033888
2022-01-15 23:48:41,382 iteration 529 : loss : 0.134795, loss_ce: 0.060480
2022-01-15 23:48:42,296 iteration 530 : loss : 0.108492, loss_ce: 0.042538
2022-01-15 23:48:43,293 iteration 531 : loss : 0.183919, loss_ce: 0.066712
2022-01-15 23:48:44,154 iteration 532 : loss : 0.190996, loss_ce: 0.056271
2022-01-15 23:48:45,123 iteration 533 : loss : 0.120235, loss_ce: 0.048332
2022-01-15 23:48:46,079 iteration 534 : loss : 0.174066, loss_ce: 0.087535
2022-01-15 23:48:47,031 iteration 535 : loss : 0.152222, loss_ce: 0.063092
2022-01-15 23:48:47,893 iteration 536 : loss : 0.157524, loss_ce: 0.085112
2022-01-15 23:48:48,823 iteration 537 : loss : 0.170887, loss_ce: 0.068235
2022-01-15 23:48:49,751 iteration 538 : loss : 0.121360, loss_ce: 0.045173
2022-01-15 23:48:50,649 iteration 539 : loss : 0.159217, loss_ce: 0.058920
2022-01-15 23:48:51,530 iteration 540 : loss : 0.152516, loss_ce: 0.069423
2022-01-15 23:48:52,451 iteration 541 : loss : 0.143285, loss_ce: 0.060261
2022-01-15 23:48:53,318 iteration 542 : loss : 0.146819, loss_ce: 0.046553
2022-01-15 23:48:54,205 iteration 543 : loss : 0.203578, loss_ce: 0.071425
2022-01-15 23:48:55,122 iteration 544 : loss : 0.142269, loss_ce: 0.050744
  8%|██▍                           | 32/400 [09:16<1:44:55, 17.11s/it]2022-01-15 23:48:56,118 iteration 545 : loss : 0.174026, loss_ce: 0.061754
2022-01-15 23:48:57,063 iteration 546 : loss : 0.115696, loss_ce: 0.039260
2022-01-15 23:48:58,001 iteration 547 : loss : 0.167126, loss_ce: 0.064965
2022-01-15 23:48:58,862 iteration 548 : loss : 0.153003, loss_ce: 0.048568
2022-01-15 23:48:59,812 iteration 549 : loss : 0.132527, loss_ce: 0.055322
2022-01-15 23:49:00,858 iteration 550 : loss : 0.174497, loss_ce: 0.079564
2022-01-15 23:49:01,833 iteration 551 : loss : 0.164762, loss_ce: 0.056129
2022-01-15 23:49:02,834 iteration 552 : loss : 0.147989, loss_ce: 0.064911
2022-01-15 23:49:03,844 iteration 553 : loss : 0.169788, loss_ce: 0.079774
2022-01-15 23:49:04,722 iteration 554 : loss : 0.099979, loss_ce: 0.039292
2022-01-15 23:49:05,687 iteration 555 : loss : 0.126797, loss_ce: 0.049240
2022-01-15 23:49:06,725 iteration 556 : loss : 0.115650, loss_ce: 0.042630
2022-01-15 23:49:07,652 iteration 557 : loss : 0.140012, loss_ce: 0.059991
2022-01-15 23:49:08,552 iteration 558 : loss : 0.147925, loss_ce: 0.048896
2022-01-15 23:49:09,516 iteration 559 : loss : 0.149424, loss_ce: 0.053943
2022-01-15 23:49:10,500 iteration 560 : loss : 0.147810, loss_ce: 0.054399
2022-01-15 23:49:11,390 iteration 561 : loss : 0.179742, loss_ce: 0.056823
  8%|██▍                           | 33/400 [09:32<1:43:05, 16.85s/it]2022-01-15 23:49:12,373 iteration 562 : loss : 0.131447, loss_ce: 0.049223
2022-01-15 23:49:13,337 iteration 563 : loss : 0.115389, loss_ce: 0.048618
2022-01-15 23:49:14,346 iteration 564 : loss : 0.106666, loss_ce: 0.053619
2022-01-15 23:49:15,314 iteration 565 : loss : 0.194236, loss_ce: 0.094192
2022-01-15 23:49:16,173 iteration 566 : loss : 0.124916, loss_ce: 0.047010
2022-01-15 23:49:17,167 iteration 567 : loss : 0.154711, loss_ce: 0.046948
2022-01-15 23:49:18,074 iteration 568 : loss : 0.149099, loss_ce: 0.060984
2022-01-15 23:49:19,006 iteration 569 : loss : 0.118288, loss_ce: 0.037838
2022-01-15 23:49:20,038 iteration 570 : loss : 0.156131, loss_ce: 0.066880
2022-01-15 23:49:21,037 iteration 571 : loss : 0.130698, loss_ce: 0.048926
2022-01-15 23:49:22,024 iteration 572 : loss : 0.143398, loss_ce: 0.049039
2022-01-15 23:49:22,942 iteration 573 : loss : 0.128857, loss_ce: 0.042093
2022-01-15 23:49:23,868 iteration 574 : loss : 0.112380, loss_ce: 0.049678
2022-01-15 23:49:24,859 iteration 575 : loss : 0.154879, loss_ce: 0.063929
2022-01-15 23:49:25,804 iteration 576 : loss : 0.142883, loss_ce: 0.063085
2022-01-15 23:49:26,766 iteration 577 : loss : 0.217894, loss_ce: 0.071994
2022-01-15 23:49:27,731 iteration 578 : loss : 0.117679, loss_ce: 0.040735
  8%|██▌                           | 34/400 [09:48<1:41:50, 16.70s/it]2022-01-15 23:49:28,731 iteration 579 : loss : 0.128431, loss_ce: 0.037922
2022-01-15 23:49:29,667 iteration 580 : loss : 0.103827, loss_ce: 0.044367
2022-01-15 23:49:30,624 iteration 581 : loss : 0.152332, loss_ce: 0.061315
2022-01-15 23:49:31,589 iteration 582 : loss : 0.114573, loss_ce: 0.043828
2022-01-15 23:49:32,513 iteration 583 : loss : 0.171281, loss_ce: 0.075288
2022-01-15 23:49:33,345 iteration 584 : loss : 0.137337, loss_ce: 0.048845
2022-01-15 23:49:34,232 iteration 585 : loss : 0.129989, loss_ce: 0.053000
2022-01-15 23:49:35,214 iteration 586 : loss : 0.113639, loss_ce: 0.052444
2022-01-15 23:49:36,142 iteration 587 : loss : 0.134088, loss_ce: 0.048451
2022-01-15 23:49:37,125 iteration 588 : loss : 0.105403, loss_ce: 0.038877
2022-01-15 23:49:38,067 iteration 589 : loss : 0.116179, loss_ce: 0.045886
2022-01-15 23:49:38,968 iteration 590 : loss : 0.159445, loss_ce: 0.078535
2022-01-15 23:49:39,891 iteration 591 : loss : 0.101866, loss_ce: 0.040409
2022-01-15 23:49:40,808 iteration 592 : loss : 0.160763, loss_ce: 0.061948
2022-01-15 23:49:41,792 iteration 593 : loss : 0.111787, loss_ce: 0.039895
2022-01-15 23:49:42,796 iteration 594 : loss : 0.145692, loss_ce: 0.058286
2022-01-15 23:49:42,797 Training Data Eval:
2022-01-15 23:49:47,195   Average segmentation loss on training set: 0.1037
2022-01-15 23:49:47,196 Validation Data Eval:
2022-01-15 23:49:48,657   Average segmentation loss on validation set: 0.1480
2022-01-15 23:49:49,533 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-15 23:49:50,501 iteration 595 : loss : 0.123962, loss_ce: 0.039016
  9%|██▋                           | 35/400 [10:11<1:52:40, 18.52s/it]2022-01-15 23:49:51,450 iteration 596 : loss : 0.075557, loss_ce: 0.031652
2022-01-15 23:49:52,396 iteration 597 : loss : 0.127418, loss_ce: 0.055860
2022-01-15 23:49:53,359 iteration 598 : loss : 0.129389, loss_ce: 0.045099
2022-01-15 23:49:54,354 iteration 599 : loss : 0.093351, loss_ce: 0.036451
2022-01-15 23:49:55,202 iteration 600 : loss : 0.112890, loss_ce: 0.048214
2022-01-15 23:49:56,134 iteration 601 : loss : 0.127389, loss_ce: 0.047568
2022-01-15 23:49:57,131 iteration 602 : loss : 0.124987, loss_ce: 0.058424
2022-01-15 23:49:57,966 iteration 603 : loss : 0.152970, loss_ce: 0.066267
2022-01-15 23:49:58,884 iteration 604 : loss : 0.140329, loss_ce: 0.058173
2022-01-15 23:49:59,820 iteration 605 : loss : 0.134400, loss_ce: 0.054773
2022-01-15 23:50:00,715 iteration 606 : loss : 0.126411, loss_ce: 0.050727
2022-01-15 23:50:01,636 iteration 607 : loss : 0.155178, loss_ce: 0.056741
2022-01-15 23:50:02,692 iteration 608 : loss : 0.140172, loss_ce: 0.045076
2022-01-15 23:50:03,605 iteration 609 : loss : 0.109808, loss_ce: 0.041647
2022-01-15 23:50:04,603 iteration 610 : loss : 0.132176, loss_ce: 0.053190
2022-01-15 23:50:05,536 iteration 611 : loss : 0.158319, loss_ce: 0.056709
2022-01-15 23:50:06,468 iteration 612 : loss : 0.123587, loss_ce: 0.049341
  9%|██▋                           | 36/400 [10:27<1:47:41, 17.75s/it]2022-01-15 23:50:07,488 iteration 613 : loss : 0.122215, loss_ce: 0.051824
2022-01-15 23:50:08,548 iteration 614 : loss : 0.110485, loss_ce: 0.044726
2022-01-15 23:50:09,486 iteration 615 : loss : 0.101296, loss_ce: 0.037315
2022-01-15 23:50:10,365 iteration 616 : loss : 0.145225, loss_ce: 0.075623
2022-01-15 23:50:11,298 iteration 617 : loss : 0.133517, loss_ce: 0.057082
2022-01-15 23:50:12,179 iteration 618 : loss : 0.197097, loss_ce: 0.080917
2022-01-15 23:50:13,095 iteration 619 : loss : 0.138947, loss_ce: 0.050289
2022-01-15 23:50:14,127 iteration 620 : loss : 0.140459, loss_ce: 0.062509
2022-01-15 23:50:15,031 iteration 621 : loss : 0.141232, loss_ce: 0.057388
2022-01-15 23:50:15,984 iteration 622 : loss : 0.115259, loss_ce: 0.046045
2022-01-15 23:50:16,992 iteration 623 : loss : 0.128016, loss_ce: 0.031992
2022-01-15 23:50:17,911 iteration 624 : loss : 0.145397, loss_ce: 0.048051
2022-01-15 23:50:18,779 iteration 625 : loss : 0.194294, loss_ce: 0.065382
2022-01-15 23:50:19,652 iteration 626 : loss : 0.121807, loss_ce: 0.043755
2022-01-15 23:50:20,555 iteration 627 : loss : 0.101774, loss_ce: 0.031438
2022-01-15 23:50:21,464 iteration 628 : loss : 0.133922, loss_ce: 0.072060
2022-01-15 23:50:22,428 iteration 629 : loss : 0.106501, loss_ce: 0.037790
  9%|██▊                           | 37/400 [10:43<1:44:09, 17.22s/it]2022-01-15 23:50:23,412 iteration 630 : loss : 0.092950, loss_ce: 0.037967
2022-01-15 23:50:24,388 iteration 631 : loss : 0.151262, loss_ce: 0.075998
2022-01-15 23:50:25,337 iteration 632 : loss : 0.149036, loss_ce: 0.057875
2022-01-15 23:50:26,320 iteration 633 : loss : 0.121451, loss_ce: 0.052196
2022-01-15 23:50:27,322 iteration 634 : loss : 0.123125, loss_ce: 0.053972
2022-01-15 23:50:28,251 iteration 635 : loss : 0.202317, loss_ce: 0.073796
2022-01-15 23:50:29,275 iteration 636 : loss : 0.168241, loss_ce: 0.082799
2022-01-15 23:50:30,172 iteration 637 : loss : 0.187129, loss_ce: 0.063571
2022-01-15 23:50:31,078 iteration 638 : loss : 0.188122, loss_ce: 0.085983
2022-01-15 23:50:32,059 iteration 639 : loss : 0.154407, loss_ce: 0.061279
2022-01-15 23:50:32,975 iteration 640 : loss : 0.153487, loss_ce: 0.053878
2022-01-15 23:50:33,938 iteration 641 : loss : 0.146041, loss_ce: 0.064993
2022-01-15 23:50:34,900 iteration 642 : loss : 0.121521, loss_ce: 0.040106
2022-01-15 23:50:35,837 iteration 643 : loss : 0.130589, loss_ce: 0.053300
2022-01-15 23:50:36,771 iteration 644 : loss : 0.127333, loss_ce: 0.050315
2022-01-15 23:50:37,733 iteration 645 : loss : 0.185450, loss_ce: 0.076800
2022-01-15 23:50:38,665 iteration 646 : loss : 0.114125, loss_ce: 0.050526
 10%|██▊                           | 38/400 [10:59<1:42:06, 16.92s/it]2022-01-15 23:50:39,659 iteration 647 : loss : 0.152944, loss_ce: 0.042840
2022-01-15 23:50:40,555 iteration 648 : loss : 0.139926, loss_ce: 0.063003
2022-01-15 23:50:41,445 iteration 649 : loss : 0.115917, loss_ce: 0.050033
2022-01-15 23:50:42,428 iteration 650 : loss : 0.180805, loss_ce: 0.046409
2022-01-15 23:50:43,403 iteration 651 : loss : 0.112457, loss_ce: 0.038651
2022-01-15 23:50:44,288 iteration 652 : loss : 0.097882, loss_ce: 0.041009
2022-01-15 23:50:45,193 iteration 653 : loss : 0.113439, loss_ce: 0.055488
2022-01-15 23:50:46,140 iteration 654 : loss : 0.102971, loss_ce: 0.037612
2022-01-15 23:50:47,002 iteration 655 : loss : 0.135802, loss_ce: 0.050083
2022-01-15 23:50:47,991 iteration 656 : loss : 0.122358, loss_ce: 0.044131
2022-01-15 23:50:48,924 iteration 657 : loss : 0.130151, loss_ce: 0.045561
2022-01-15 23:50:49,855 iteration 658 : loss : 0.148420, loss_ce: 0.054170
2022-01-15 23:50:50,843 iteration 659 : loss : 0.144156, loss_ce: 0.049011
2022-01-15 23:50:51,806 iteration 660 : loss : 0.102072, loss_ce: 0.041412
2022-01-15 23:50:52,756 iteration 661 : loss : 0.089020, loss_ce: 0.039582
2022-01-15 23:50:53,727 iteration 662 : loss : 0.140649, loss_ce: 0.058815
2022-01-15 23:50:54,666 iteration 663 : loss : 0.133056, loss_ce: 0.060153
 10%|██▉                           | 39/400 [11:15<1:40:09, 16.65s/it]2022-01-15 23:50:55,631 iteration 664 : loss : 0.181778, loss_ce: 0.096766
2022-01-15 23:50:56,608 iteration 665 : loss : 0.111898, loss_ce: 0.035221
2022-01-15 23:50:57,561 iteration 666 : loss : 0.127475, loss_ce: 0.043432
2022-01-15 23:50:58,570 iteration 667 : loss : 0.137943, loss_ce: 0.052085
2022-01-15 23:50:59,505 iteration 668 : loss : 0.086592, loss_ce: 0.033113
2022-01-15 23:51:00,516 iteration 669 : loss : 0.131148, loss_ce: 0.059373
2022-01-15 23:51:01,508 iteration 670 : loss : 0.160382, loss_ce: 0.060606
2022-01-15 23:51:02,467 iteration 671 : loss : 0.115074, loss_ce: 0.047337
2022-01-15 23:51:03,321 iteration 672 : loss : 0.107118, loss_ce: 0.042874
2022-01-15 23:51:04,243 iteration 673 : loss : 0.131561, loss_ce: 0.047787
2022-01-15 23:51:05,337 iteration 674 : loss : 0.121662, loss_ce: 0.057216
2022-01-15 23:51:06,292 iteration 675 : loss : 0.115579, loss_ce: 0.039284
2022-01-15 23:51:07,222 iteration 676 : loss : 0.126888, loss_ce: 0.041029
2022-01-15 23:51:08,291 iteration 677 : loss : 0.096112, loss_ce: 0.038496
2022-01-15 23:51:09,267 iteration 678 : loss : 0.164670, loss_ce: 0.043204
2022-01-15 23:51:10,165 iteration 679 : loss : 0.123561, loss_ce: 0.055333
2022-01-15 23:51:10,165 Training Data Eval:
2022-01-15 23:51:14,544   Average segmentation loss on training set: 0.1842
2022-01-15 23:51:14,544 Validation Data Eval:
2022-01-15 23:51:16,009   Average segmentation loss on validation set: 0.2869
2022-01-15 23:51:16,899 iteration 680 : loss : 0.104240, loss_ce: 0.039985
 10%|███                           | 40/400 [11:37<1:49:56, 18.32s/it]2022-01-15 23:51:18,039 iteration 681 : loss : 0.096969, loss_ce: 0.037991
2022-01-15 23:51:18,978 iteration 682 : loss : 0.142422, loss_ce: 0.050906
2022-01-15 23:51:19,874 iteration 683 : loss : 0.128995, loss_ce: 0.033721
2022-01-15 23:51:20,889 iteration 684 : loss : 0.112165, loss_ce: 0.041306
2022-01-15 23:51:21,917 iteration 685 : loss : 0.150942, loss_ce: 0.049370
2022-01-15 23:51:22,912 iteration 686 : loss : 0.132799, loss_ce: 0.062683
2022-01-15 23:51:23,904 iteration 687 : loss : 0.110677, loss_ce: 0.049922
2022-01-15 23:51:24,934 iteration 688 : loss : 0.122040, loss_ce: 0.048531
2022-01-15 23:51:25,930 iteration 689 : loss : 0.118006, loss_ce: 0.059898
2022-01-15 23:51:26,873 iteration 690 : loss : 0.117860, loss_ce: 0.049163
2022-01-15 23:51:27,870 iteration 691 : loss : 0.131424, loss_ce: 0.050350
2022-01-15 23:51:28,756 iteration 692 : loss : 0.085110, loss_ce: 0.038581
2022-01-15 23:51:29,673 iteration 693 : loss : 0.108201, loss_ce: 0.040780
2022-01-15 23:51:30,616 iteration 694 : loss : 0.174368, loss_ce: 0.052524
2022-01-15 23:51:31,559 iteration 695 : loss : 0.118698, loss_ce: 0.040225
2022-01-15 23:51:32,468 iteration 696 : loss : 0.187528, loss_ce: 0.045494
2022-01-15 23:51:33,318 iteration 697 : loss : 0.088205, loss_ce: 0.037373
 10%|███                           | 41/400 [11:54<1:46:13, 17.75s/it]2022-01-15 23:51:34,345 iteration 698 : loss : 0.088415, loss_ce: 0.039546
2022-01-15 23:51:35,315 iteration 699 : loss : 0.098650, loss_ce: 0.037850
2022-01-15 23:51:36,219 iteration 700 : loss : 0.146203, loss_ce: 0.049043
2022-01-15 23:51:37,130 iteration 701 : loss : 0.158560, loss_ce: 0.053195
2022-01-15 23:51:38,124 iteration 702 : loss : 0.089935, loss_ce: 0.036866
2022-01-15 23:51:39,086 iteration 703 : loss : 0.148521, loss_ce: 0.046855
2022-01-15 23:51:40,124 iteration 704 : loss : 0.117467, loss_ce: 0.038030
2022-01-15 23:51:41,127 iteration 705 : loss : 0.114338, loss_ce: 0.051289
2022-01-15 23:51:42,138 iteration 706 : loss : 0.133719, loss_ce: 0.044055
2022-01-15 23:51:43,064 iteration 707 : loss : 0.135363, loss_ce: 0.050435
2022-01-15 23:51:44,030 iteration 708 : loss : 0.106289, loss_ce: 0.035990
2022-01-15 23:51:45,004 iteration 709 : loss : 0.129243, loss_ce: 0.050888
2022-01-15 23:51:45,892 iteration 710 : loss : 0.095116, loss_ce: 0.043023
2022-01-15 23:51:46,884 iteration 711 : loss : 0.105107, loss_ce: 0.040594
2022-01-15 23:51:47,812 iteration 712 : loss : 0.164918, loss_ce: 0.059817
2022-01-15 23:51:48,682 iteration 713 : loss : 0.123275, loss_ce: 0.056375
2022-01-15 23:51:49,566 iteration 714 : loss : 0.095902, loss_ce: 0.036144
 10%|███▏                          | 42/400 [12:10<1:43:13, 17.30s/it]2022-01-15 23:51:50,641 iteration 715 : loss : 0.095946, loss_ce: 0.044822
2022-01-15 23:51:51,567 iteration 716 : loss : 0.108795, loss_ce: 0.042456
2022-01-15 23:51:52,482 iteration 717 : loss : 0.132329, loss_ce: 0.044369
2022-01-15 23:51:53,417 iteration 718 : loss : 0.146424, loss_ce: 0.059606
2022-01-15 23:51:54,437 iteration 719 : loss : 0.101901, loss_ce: 0.038533
2022-01-15 23:51:55,341 iteration 720 : loss : 0.129110, loss_ce: 0.039491
2022-01-15 23:51:56,337 iteration 721 : loss : 0.116971, loss_ce: 0.039148
2022-01-15 23:51:57,298 iteration 722 : loss : 0.115880, loss_ce: 0.040113
2022-01-15 23:51:58,200 iteration 723 : loss : 0.088641, loss_ce: 0.031317
2022-01-15 23:51:59,255 iteration 724 : loss : 0.117218, loss_ce: 0.047617
2022-01-15 23:52:00,138 iteration 725 : loss : 0.092204, loss_ce: 0.038139
2022-01-15 23:52:01,089 iteration 726 : loss : 0.145477, loss_ce: 0.040142
2022-01-15 23:52:02,080 iteration 727 : loss : 0.166258, loss_ce: 0.053948
2022-01-15 23:52:03,202 iteration 728 : loss : 0.138047, loss_ce: 0.074479
2022-01-15 23:52:04,034 iteration 729 : loss : 0.066420, loss_ce: 0.028984
2022-01-15 23:52:04,990 iteration 730 : loss : 0.113808, loss_ce: 0.055327
2022-01-15 23:52:05,945 iteration 731 : loss : 0.108073, loss_ce: 0.038646
 11%|███▏                          | 43/400 [12:26<1:41:15, 17.02s/it]2022-01-15 23:52:07,064 iteration 732 : loss : 0.096160, loss_ce: 0.040808
2022-01-15 23:52:08,038 iteration 733 : loss : 0.186484, loss_ce: 0.084648
2022-01-15 23:52:08,925 iteration 734 : loss : 0.123262, loss_ce: 0.041958
2022-01-15 23:52:09,860 iteration 735 : loss : 0.092529, loss_ce: 0.033023
2022-01-15 23:52:10,813 iteration 736 : loss : 0.119237, loss_ce: 0.043429
2022-01-15 23:52:11,811 iteration 737 : loss : 0.089033, loss_ce: 0.029966
2022-01-15 23:52:12,759 iteration 738 : loss : 0.083543, loss_ce: 0.032897
2022-01-15 23:52:13,683 iteration 739 : loss : 0.132633, loss_ce: 0.057782
2022-01-15 23:52:14,608 iteration 740 : loss : 0.154944, loss_ce: 0.067166
2022-01-15 23:52:15,560 iteration 741 : loss : 0.106952, loss_ce: 0.040593
2022-01-15 23:52:16,582 iteration 742 : loss : 0.149367, loss_ce: 0.050777
2022-01-15 23:52:17,498 iteration 743 : loss : 0.123241, loss_ce: 0.041559
2022-01-15 23:52:18,421 iteration 744 : loss : 0.127397, loss_ce: 0.044165
2022-01-15 23:52:19,321 iteration 745 : loss : 0.087240, loss_ce: 0.038587
2022-01-15 23:52:20,255 iteration 746 : loss : 0.217115, loss_ce: 0.104991
2022-01-15 23:52:21,225 iteration 747 : loss : 0.154308, loss_ce: 0.047592
2022-01-15 23:52:22,068 iteration 748 : loss : 0.094968, loss_ce: 0.041279
 11%|███▎                          | 44/400 [12:43<1:39:25, 16.76s/it]2022-01-15 23:52:23,084 iteration 749 : loss : 0.111213, loss_ce: 0.050192
2022-01-15 23:52:24,070 iteration 750 : loss : 0.117727, loss_ce: 0.051496
2022-01-15 23:52:24,942 iteration 751 : loss : 0.097621, loss_ce: 0.040688
2022-01-15 23:52:25,889 iteration 752 : loss : 0.118615, loss_ce: 0.039915
2022-01-15 23:52:26,931 iteration 753 : loss : 0.105452, loss_ce: 0.042086
2022-01-15 23:52:27,855 iteration 754 : loss : 0.120045, loss_ce: 0.041277
2022-01-15 23:52:28,803 iteration 755 : loss : 0.076622, loss_ce: 0.030016
2022-01-15 23:52:29,685 iteration 756 : loss : 0.116417, loss_ce: 0.045158
2022-01-15 23:52:30,590 iteration 757 : loss : 0.114870, loss_ce: 0.043507
2022-01-15 23:52:31,541 iteration 758 : loss : 0.104580, loss_ce: 0.039334
2022-01-15 23:52:32,389 iteration 759 : loss : 0.085518, loss_ce: 0.030275
2022-01-15 23:52:33,352 iteration 760 : loss : 0.146660, loss_ce: 0.050400
2022-01-15 23:52:34,339 iteration 761 : loss : 0.103054, loss_ce: 0.032713
2022-01-15 23:52:35,312 iteration 762 : loss : 0.129028, loss_ce: 0.055532
2022-01-15 23:52:36,237 iteration 763 : loss : 0.099108, loss_ce: 0.038714
2022-01-15 23:52:37,126 iteration 764 : loss : 0.111665, loss_ce: 0.045076
2022-01-15 23:52:37,126 Training Data Eval:
2022-01-15 23:52:41,509   Average segmentation loss on training set: 0.1245
2022-01-15 23:52:41,510 Validation Data Eval:
2022-01-15 23:52:42,959   Average segmentation loss on validation set: 0.1386
2022-01-15 23:52:43,810 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-15 23:52:44,760 iteration 765 : loss : 0.096624, loss_ce: 0.038243
 11%|███▍                          | 45/400 [13:05<1:49:40, 18.54s/it]2022-01-15 23:52:45,740 iteration 766 : loss : 0.147417, loss_ce: 0.057395
2022-01-15 23:52:46,724 iteration 767 : loss : 0.134401, loss_ce: 0.052761
2022-01-15 23:52:47,557 iteration 768 : loss : 0.110185, loss_ce: 0.036964
2022-01-15 23:52:48,490 iteration 769 : loss : 0.196573, loss_ce: 0.044049
2022-01-15 23:52:49,368 iteration 770 : loss : 0.082460, loss_ce: 0.031148
2022-01-15 23:52:50,376 iteration 771 : loss : 0.086904, loss_ce: 0.028756
2022-01-15 23:52:51,376 iteration 772 : loss : 0.094592, loss_ce: 0.041837
2022-01-15 23:52:52,332 iteration 773 : loss : 0.086135, loss_ce: 0.030950
2022-01-15 23:52:53,275 iteration 774 : loss : 0.098539, loss_ce: 0.042891
2022-01-15 23:52:54,195 iteration 775 : loss : 0.093896, loss_ce: 0.034646
2022-01-15 23:52:55,036 iteration 776 : loss : 0.100968, loss_ce: 0.043593
2022-01-15 23:52:56,029 iteration 777 : loss : 0.121815, loss_ce: 0.048960
2022-01-15 23:52:56,972 iteration 778 : loss : 0.079565, loss_ce: 0.033075
2022-01-15 23:52:57,924 iteration 779 : loss : 0.103539, loss_ce: 0.052481
2022-01-15 23:52:58,800 iteration 780 : loss : 0.129844, loss_ce: 0.052144
2022-01-15 23:52:59,787 iteration 781 : loss : 0.100348, loss_ce: 0.044223
2022-01-15 23:53:00,771 iteration 782 : loss : 0.139884, loss_ce: 0.049021
 12%|███▍                          | 46/400 [13:21<1:44:52, 17.77s/it]2022-01-15 23:53:01,825 iteration 783 : loss : 0.082997, loss_ce: 0.039736
2022-01-15 23:53:02,778 iteration 784 : loss : 0.144074, loss_ce: 0.052089
2022-01-15 23:53:03,764 iteration 785 : loss : 0.102482, loss_ce: 0.048468
2022-01-15 23:53:04,696 iteration 786 : loss : 0.156725, loss_ce: 0.057149
2022-01-15 23:53:05,639 iteration 787 : loss : 0.127743, loss_ce: 0.059337
2022-01-15 23:53:06,614 iteration 788 : loss : 0.098681, loss_ce: 0.033976
2022-01-15 23:53:07,693 iteration 789 : loss : 0.142863, loss_ce: 0.077737
2022-01-15 23:53:08,706 iteration 790 : loss : 0.078723, loss_ce: 0.027060
2022-01-15 23:53:09,626 iteration 791 : loss : 0.141632, loss_ce: 0.052048
2022-01-15 23:53:10,600 iteration 792 : loss : 0.084435, loss_ce: 0.037282
2022-01-15 23:53:11,448 iteration 793 : loss : 0.118254, loss_ce: 0.041419
2022-01-15 23:53:12,369 iteration 794 : loss : 0.094860, loss_ce: 0.034310
2022-01-15 23:53:13,312 iteration 795 : loss : 0.090268, loss_ce: 0.036017
2022-01-15 23:53:14,252 iteration 796 : loss : 0.111803, loss_ce: 0.045140
2022-01-15 23:53:15,146 iteration 797 : loss : 0.097693, loss_ce: 0.040753
2022-01-15 23:53:16,051 iteration 798 : loss : 0.182127, loss_ce: 0.055016
2022-01-15 23:53:17,022 iteration 799 : loss : 0.089922, loss_ce: 0.029373
 12%|███▌                          | 47/400 [13:37<1:41:53, 17.32s/it]2022-01-15 23:53:18,079 iteration 800 : loss : 0.095263, loss_ce: 0.027108
2022-01-15 23:53:18,974 iteration 801 : loss : 0.117554, loss_ce: 0.040145
2022-01-15 23:53:19,903 iteration 802 : loss : 0.122897, loss_ce: 0.058549
2022-01-15 23:53:20,919 iteration 803 : loss : 0.140254, loss_ce: 0.080341
2022-01-15 23:53:21,790 iteration 804 : loss : 0.115757, loss_ce: 0.054757
2022-01-15 23:53:22,658 iteration 805 : loss : 0.195963, loss_ce: 0.040819
2022-01-15 23:53:23,596 iteration 806 : loss : 0.119934, loss_ce: 0.034456
2022-01-15 23:53:24,625 iteration 807 : loss : 0.120600, loss_ce: 0.051454
2022-01-15 23:53:25,612 iteration 808 : loss : 0.127305, loss_ce: 0.046634
2022-01-15 23:53:26,540 iteration 809 : loss : 0.161036, loss_ce: 0.047875
2022-01-15 23:53:27,540 iteration 810 : loss : 0.146651, loss_ce: 0.050862
2022-01-15 23:53:28,444 iteration 811 : loss : 0.066644, loss_ce: 0.028567
2022-01-15 23:53:29,455 iteration 812 : loss : 0.133045, loss_ce: 0.055054
2022-01-15 23:53:30,386 iteration 813 : loss : 0.075233, loss_ce: 0.029725
2022-01-15 23:53:31,344 iteration 814 : loss : 0.090735, loss_ce: 0.036375
2022-01-15 23:53:32,339 iteration 815 : loss : 0.089813, loss_ce: 0.034779
2022-01-15 23:53:33,150 iteration 816 : loss : 0.088444, loss_ce: 0.031075
 12%|███▌                          | 48/400 [13:54<1:39:31, 16.96s/it]2022-01-15 23:53:34,116 iteration 817 : loss : 0.082872, loss_ce: 0.032947
2022-01-15 23:53:35,081 iteration 818 : loss : 0.110666, loss_ce: 0.044798
2022-01-15 23:53:36,020 iteration 819 : loss : 0.087234, loss_ce: 0.034128
2022-01-15 23:53:37,070 iteration 820 : loss : 0.092446, loss_ce: 0.035704
2022-01-15 23:53:37,919 iteration 821 : loss : 0.114678, loss_ce: 0.039055
2022-01-15 23:53:38,890 iteration 822 : loss : 0.083521, loss_ce: 0.032348
2022-01-15 23:53:39,824 iteration 823 : loss : 0.120516, loss_ce: 0.041645
2022-01-15 23:53:40,733 iteration 824 : loss : 0.101556, loss_ce: 0.041725
2022-01-15 23:53:41,672 iteration 825 : loss : 0.080550, loss_ce: 0.024134
2022-01-15 23:53:42,638 iteration 826 : loss : 0.083085, loss_ce: 0.034660
2022-01-15 23:53:43,557 iteration 827 : loss : 0.158522, loss_ce: 0.047751
2022-01-15 23:53:44,547 iteration 828 : loss : 0.084021, loss_ce: 0.037459
2022-01-15 23:53:45,480 iteration 829 : loss : 0.134616, loss_ce: 0.044537
2022-01-15 23:53:46,527 iteration 830 : loss : 0.086886, loss_ce: 0.027573
2022-01-15 23:53:47,478 iteration 831 : loss : 0.129599, loss_ce: 0.048952
2022-01-15 23:53:48,399 iteration 832 : loss : 0.066621, loss_ce: 0.026327
2022-01-15 23:53:49,290 iteration 833 : loss : 0.085595, loss_ce: 0.042568
 12%|███▋                          | 49/400 [14:10<1:37:46, 16.71s/it]2022-01-15 23:53:50,245 iteration 834 : loss : 0.120442, loss_ce: 0.044148
2022-01-15 23:53:51,216 iteration 835 : loss : 0.117335, loss_ce: 0.053691
2022-01-15 23:53:52,176 iteration 836 : loss : 0.097143, loss_ce: 0.042459
2022-01-15 23:53:53,093 iteration 837 : loss : 0.095453, loss_ce: 0.040102
2022-01-15 23:53:54,002 iteration 838 : loss : 0.128186, loss_ce: 0.049378
2022-01-15 23:53:55,012 iteration 839 : loss : 0.081839, loss_ce: 0.027213
2022-01-15 23:53:55,971 iteration 840 : loss : 0.130322, loss_ce: 0.051345
2022-01-15 23:53:56,924 iteration 841 : loss : 0.101455, loss_ce: 0.052660
2022-01-15 23:53:57,999 iteration 842 : loss : 0.128155, loss_ce: 0.052008
2022-01-15 23:53:58,919 iteration 843 : loss : 0.086724, loss_ce: 0.031393
2022-01-15 23:53:59,906 iteration 844 : loss : 0.117293, loss_ce: 0.046320
2022-01-15 23:54:00,811 iteration 845 : loss : 0.092749, loss_ce: 0.035850
2022-01-15 23:54:01,754 iteration 846 : loss : 0.110068, loss_ce: 0.033605
2022-01-15 23:54:02,746 iteration 847 : loss : 0.100108, loss_ce: 0.035595
2022-01-15 23:54:03,599 iteration 848 : loss : 0.067186, loss_ce: 0.026002
2022-01-15 23:54:04,569 iteration 849 : loss : 0.095373, loss_ce: 0.039911
2022-01-15 23:54:04,569 Training Data Eval:
2022-01-15 23:54:08,955   Average segmentation loss on training set: 0.1040
2022-01-15 23:54:08,956 Validation Data Eval:
2022-01-15 23:54:10,412   Average segmentation loss on validation set: 0.1153
2022-01-15 23:54:11,296 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-15 23:54:12,301 iteration 850 : loss : 0.122869, loss_ce: 0.042237
 12%|███▊                          | 50/400 [14:33<1:48:30, 18.60s/it]2022-01-15 23:54:13,335 iteration 851 : loss : 0.082000, loss_ce: 0.039845
2022-01-15 23:54:14,320 iteration 852 : loss : 0.102628, loss_ce: 0.041252
2022-01-15 23:54:15,315 iteration 853 : loss : 0.111167, loss_ce: 0.044082
2022-01-15 23:54:16,201 iteration 854 : loss : 0.101005, loss_ce: 0.039387
2022-01-15 23:54:17,040 iteration 855 : loss : 0.070134, loss_ce: 0.027497
2022-01-15 23:54:17,929 iteration 856 : loss : 0.121771, loss_ce: 0.043542
2022-01-15 23:54:18,959 iteration 857 : loss : 0.082745, loss_ce: 0.035313
2022-01-15 23:54:19,893 iteration 858 : loss : 0.112663, loss_ce: 0.039628
2022-01-15 23:54:20,932 iteration 859 : loss : 0.104197, loss_ce: 0.037731
2022-01-15 23:54:21,928 iteration 860 : loss : 0.108471, loss_ce: 0.037116
2022-01-15 23:54:22,865 iteration 861 : loss : 0.116937, loss_ce: 0.039101
2022-01-15 23:54:23,801 iteration 862 : loss : 0.090666, loss_ce: 0.024916
2022-01-15 23:54:24,662 iteration 863 : loss : 0.145201, loss_ce: 0.067804
2022-01-15 23:54:25,591 iteration 864 : loss : 0.078571, loss_ce: 0.035593
2022-01-15 23:54:26,463 iteration 865 : loss : 0.097455, loss_ce: 0.042976
2022-01-15 23:54:27,347 iteration 866 : loss : 0.066444, loss_ce: 0.025510
2022-01-15 23:54:28,242 iteration 867 : loss : 0.125275, loss_ce: 0.050211
 13%|███▊                          | 51/400 [14:49<1:43:34, 17.81s/it]2022-01-15 23:54:29,268 iteration 868 : loss : 0.079485, loss_ce: 0.029803
2022-01-15 23:54:30,171 iteration 869 : loss : 0.087075, loss_ce: 0.039233
2022-01-15 23:54:31,137 iteration 870 : loss : 0.131599, loss_ce: 0.035187
2022-01-15 23:54:32,101 iteration 871 : loss : 0.081990, loss_ce: 0.032310
2022-01-15 23:54:32,971 iteration 872 : loss : 0.059933, loss_ce: 0.023816
2022-01-15 23:54:33,853 iteration 873 : loss : 0.063521, loss_ce: 0.029156
2022-01-15 23:54:34,815 iteration 874 : loss : 0.096031, loss_ce: 0.043203
2022-01-15 23:54:35,770 iteration 875 : loss : 0.122400, loss_ce: 0.052364
2022-01-15 23:54:36,697 iteration 876 : loss : 0.097463, loss_ce: 0.038738
2022-01-15 23:54:37,568 iteration 877 : loss : 0.083433, loss_ce: 0.031320
2022-01-15 23:54:38,455 iteration 878 : loss : 0.078999, loss_ce: 0.027615
2022-01-15 23:54:39,397 iteration 879 : loss : 0.085530, loss_ce: 0.031877
2022-01-15 23:54:40,285 iteration 880 : loss : 0.064242, loss_ce: 0.026828
2022-01-15 23:54:41,264 iteration 881 : loss : 0.084669, loss_ce: 0.033755
2022-01-15 23:54:42,172 iteration 882 : loss : 0.073850, loss_ce: 0.031048
2022-01-15 23:54:43,078 iteration 883 : loss : 0.120183, loss_ce: 0.040579
2022-01-15 23:54:44,141 iteration 884 : loss : 0.100964, loss_ce: 0.036332
 13%|███▉                          | 52/400 [15:05<1:39:56, 17.23s/it]2022-01-15 23:54:45,216 iteration 885 : loss : 0.134890, loss_ce: 0.060135
2022-01-15 23:54:46,144 iteration 886 : loss : 0.104607, loss_ce: 0.039567
2022-01-15 23:54:47,059 iteration 887 : loss : 0.098819, loss_ce: 0.043833
2022-01-15 23:54:48,007 iteration 888 : loss : 0.094362, loss_ce: 0.036811
2022-01-15 23:54:48,908 iteration 889 : loss : 0.081022, loss_ce: 0.027940
2022-01-15 23:54:49,896 iteration 890 : loss : 0.086045, loss_ce: 0.037059
2022-01-15 23:54:50,863 iteration 891 : loss : 0.100788, loss_ce: 0.052646
2022-01-15 23:54:51,807 iteration 892 : loss : 0.114926, loss_ce: 0.036838
2022-01-15 23:54:52,835 iteration 893 : loss : 0.096528, loss_ce: 0.038044
2022-01-15 23:54:53,780 iteration 894 : loss : 0.092140, loss_ce: 0.033138
2022-01-15 23:54:54,744 iteration 895 : loss : 0.083652, loss_ce: 0.032826
2022-01-15 23:54:55,748 iteration 896 : loss : 0.113433, loss_ce: 0.035369
2022-01-15 23:54:56,616 iteration 897 : loss : 0.060248, loss_ce: 0.022232
2022-01-15 23:54:57,670 iteration 898 : loss : 0.100138, loss_ce: 0.035776
2022-01-15 23:54:58,611 iteration 899 : loss : 0.090786, loss_ce: 0.032188
2022-01-15 23:54:59,578 iteration 900 : loss : 0.113220, loss_ce: 0.040076
2022-01-15 23:55:00,504 iteration 901 : loss : 0.097014, loss_ce: 0.055750
 13%|███▉                          | 53/400 [15:21<1:38:10, 16.98s/it]2022-01-15 23:55:01,522 iteration 902 : loss : 0.062500, loss_ce: 0.025026
2022-01-15 23:55:02,499 iteration 903 : loss : 0.084940, loss_ce: 0.031568
2022-01-15 23:55:03,417 iteration 904 : loss : 0.097252, loss_ce: 0.043992
2022-01-15 23:55:04,303 iteration 905 : loss : 0.160218, loss_ce: 0.048785
2022-01-15 23:55:05,180 iteration 906 : loss : 0.082542, loss_ce: 0.032609
2022-01-15 23:55:06,171 iteration 907 : loss : 0.054541, loss_ce: 0.026533
2022-01-15 23:55:07,049 iteration 908 : loss : 0.083004, loss_ce: 0.045699
2022-01-15 23:55:08,019 iteration 909 : loss : 0.126251, loss_ce: 0.063454
2022-01-15 23:55:08,965 iteration 910 : loss : 0.100976, loss_ce: 0.033471
2022-01-15 23:55:09,924 iteration 911 : loss : 0.106244, loss_ce: 0.036448
2022-01-15 23:55:10,771 iteration 912 : loss : 0.089887, loss_ce: 0.032116
2022-01-15 23:55:11,757 iteration 913 : loss : 0.091611, loss_ce: 0.037631
2022-01-15 23:55:12,659 iteration 914 : loss : 0.081317, loss_ce: 0.035377
2022-01-15 23:55:13,629 iteration 915 : loss : 0.093259, loss_ce: 0.039101
2022-01-15 23:55:14,540 iteration 916 : loss : 0.112434, loss_ce: 0.045583
2022-01-15 23:55:15,472 iteration 917 : loss : 0.081836, loss_ce: 0.028255
2022-01-15 23:55:16,400 iteration 918 : loss : 0.124349, loss_ce: 0.042177
 14%|████                          | 54/400 [15:37<1:36:00, 16.65s/it]2022-01-15 23:55:17,474 iteration 919 : loss : 0.070412, loss_ce: 0.028656
2022-01-15 23:55:18,352 iteration 920 : loss : 0.126284, loss_ce: 0.072272
2022-01-15 23:55:19,382 iteration 921 : loss : 0.077272, loss_ce: 0.034720
2022-01-15 23:55:20,217 iteration 922 : loss : 0.076446, loss_ce: 0.032970
2022-01-15 23:55:21,093 iteration 923 : loss : 0.103920, loss_ce: 0.036229
2022-01-15 23:55:22,016 iteration 924 : loss : 0.071878, loss_ce: 0.023293
2022-01-15 23:55:22,887 iteration 925 : loss : 0.059855, loss_ce: 0.021336
2022-01-15 23:55:23,758 iteration 926 : loss : 0.077917, loss_ce: 0.027385
2022-01-15 23:55:24,701 iteration 927 : loss : 0.074942, loss_ce: 0.032609
2022-01-15 23:55:25,581 iteration 928 : loss : 0.084437, loss_ce: 0.032385
2022-01-15 23:55:26,672 iteration 929 : loss : 0.092491, loss_ce: 0.039843
2022-01-15 23:55:27,625 iteration 930 : loss : 0.096777, loss_ce: 0.056214
2022-01-15 23:55:28,589 iteration 931 : loss : 0.090104, loss_ce: 0.032810
2022-01-15 23:55:29,546 iteration 932 : loss : 0.132051, loss_ce: 0.040589
2022-01-15 23:55:30,643 iteration 933 : loss : 0.129513, loss_ce: 0.038162
2022-01-15 23:55:31,577 iteration 934 : loss : 0.088012, loss_ce: 0.034119
2022-01-15 23:55:31,577 Training Data Eval:
2022-01-15 23:55:35,972   Average segmentation loss on training set: 0.1043
2022-01-15 23:55:35,973 Validation Data Eval:
2022-01-15 23:55:37,428   Average segmentation loss on validation set: 0.1974
2022-01-15 23:55:38,326 iteration 935 : loss : 0.079259, loss_ce: 0.025953
 14%|████▏                         | 55/400 [15:59<1:44:49, 18.23s/it]2022-01-15 23:55:39,301 iteration 936 : loss : 0.100926, loss_ce: 0.025156
2022-01-15 23:55:40,211 iteration 937 : loss : 0.082764, loss_ce: 0.031085
2022-01-15 23:55:41,170 iteration 938 : loss : 0.087635, loss_ce: 0.042932
2022-01-15 23:55:42,103 iteration 939 : loss : 0.102259, loss_ce: 0.041573
2022-01-15 23:55:43,004 iteration 940 : loss : 0.099842, loss_ce: 0.038732
2022-01-15 23:55:43,965 iteration 941 : loss : 0.114692, loss_ce: 0.036938
2022-01-15 23:55:44,880 iteration 942 : loss : 0.095229, loss_ce: 0.027404
2022-01-15 23:55:45,730 iteration 943 : loss : 0.152745, loss_ce: 0.055139
2022-01-15 23:55:46,623 iteration 944 : loss : 0.079551, loss_ce: 0.032297
2022-01-15 23:55:47,526 iteration 945 : loss : 0.100393, loss_ce: 0.062257
2022-01-15 23:55:48,462 iteration 946 : loss : 0.076885, loss_ce: 0.030101
2022-01-15 23:55:49,515 iteration 947 : loss : 0.096979, loss_ce: 0.038874
2022-01-15 23:55:50,415 iteration 948 : loss : 0.110010, loss_ce: 0.044123
2022-01-15 23:55:51,376 iteration 949 : loss : 0.072641, loss_ce: 0.027003
2022-01-15 23:55:52,349 iteration 950 : loss : 0.195903, loss_ce: 0.054050
2022-01-15 23:55:53,375 iteration 951 : loss : 0.082585, loss_ce: 0.038569
2022-01-15 23:55:54,255 iteration 952 : loss : 0.118133, loss_ce: 0.031864
 14%|████▏                         | 56/400 [16:15<1:40:34, 17.54s/it]2022-01-15 23:55:55,260 iteration 953 : loss : 0.064991, loss_ce: 0.022583
2022-01-15 23:55:56,310 iteration 954 : loss : 0.064715, loss_ce: 0.021422
2022-01-15 23:55:57,235 iteration 955 : loss : 0.053915, loss_ce: 0.021888
2022-01-15 23:55:58,157 iteration 956 : loss : 0.070923, loss_ce: 0.027774
2022-01-15 23:55:58,966 iteration 957 : loss : 0.099282, loss_ce: 0.032630
2022-01-15 23:55:59,870 iteration 958 : loss : 0.070726, loss_ce: 0.024196
2022-01-15 23:56:00,745 iteration 959 : loss : 0.084543, loss_ce: 0.033740
2022-01-15 23:56:01,617 iteration 960 : loss : 0.070116, loss_ce: 0.027868
2022-01-15 23:56:02,556 iteration 961 : loss : 0.102405, loss_ce: 0.043179
2022-01-15 23:56:03,459 iteration 962 : loss : 0.069112, loss_ce: 0.023074
2022-01-15 23:56:04,435 iteration 963 : loss : 0.074721, loss_ce: 0.028083
2022-01-15 23:56:05,393 iteration 964 : loss : 0.068932, loss_ce: 0.028838
2022-01-15 23:56:06,311 iteration 965 : loss : 0.049156, loss_ce: 0.020100
2022-01-15 23:56:07,344 iteration 966 : loss : 0.128417, loss_ce: 0.056783
2022-01-15 23:56:08,278 iteration 967 : loss : 0.140166, loss_ce: 0.058146
2022-01-15 23:56:09,235 iteration 968 : loss : 0.098980, loss_ce: 0.044195
2022-01-15 23:56:10,225 iteration 969 : loss : 0.079116, loss_ce: 0.031217
 14%|████▎                         | 57/400 [16:31<1:37:34, 17.07s/it]2022-01-15 23:56:11,215 iteration 970 : loss : 0.071151, loss_ce: 0.026141
2022-01-15 23:56:12,242 iteration 971 : loss : 0.084925, loss_ce: 0.032309
2022-01-15 23:56:13,119 iteration 972 : loss : 0.062668, loss_ce: 0.023585
2022-01-15 23:56:13,995 iteration 973 : loss : 0.065003, loss_ce: 0.025405
2022-01-15 23:56:14,922 iteration 974 : loss : 0.084995, loss_ce: 0.036867
2022-01-15 23:56:15,802 iteration 975 : loss : 0.100173, loss_ce: 0.036849
2022-01-15 23:56:16,699 iteration 976 : loss : 0.116529, loss_ce: 0.039773
2022-01-15 23:56:17,698 iteration 977 : loss : 0.100324, loss_ce: 0.030837
2022-01-15 23:56:18,683 iteration 978 : loss : 0.116416, loss_ce: 0.053245
2022-01-15 23:56:19,668 iteration 979 : loss : 0.069902, loss_ce: 0.029449
2022-01-15 23:56:20,540 iteration 980 : loss : 0.082146, loss_ce: 0.028071
2022-01-15 23:56:21,546 iteration 981 : loss : 0.082345, loss_ce: 0.032086
2022-01-15 23:56:22,418 iteration 982 : loss : 0.086450, loss_ce: 0.042550
2022-01-15 23:56:23,382 iteration 983 : loss : 0.071603, loss_ce: 0.031851
2022-01-15 23:56:24,324 iteration 984 : loss : 0.096600, loss_ce: 0.046025
2022-01-15 23:56:25,255 iteration 985 : loss : 0.100088, loss_ce: 0.033101
2022-01-15 23:56:26,184 iteration 986 : loss : 0.113373, loss_ce: 0.037458
 14%|████▎                         | 58/400 [16:47<1:35:23, 16.74s/it]2022-01-15 23:56:27,193 iteration 987 : loss : 0.067220, loss_ce: 0.030717
2022-01-15 23:56:28,217 iteration 988 : loss : 0.091354, loss_ce: 0.039743
2022-01-15 23:56:29,120 iteration 989 : loss : 0.092477, loss_ce: 0.034465
2022-01-15 23:56:30,128 iteration 990 : loss : 0.080991, loss_ce: 0.041240
2022-01-15 23:56:31,118 iteration 991 : loss : 0.086031, loss_ce: 0.039484
2022-01-15 23:56:32,000 iteration 992 : loss : 0.099101, loss_ce: 0.036558
2022-01-15 23:56:33,072 iteration 993 : loss : 0.083496, loss_ce: 0.034906
2022-01-15 23:56:34,070 iteration 994 : loss : 0.115783, loss_ce: 0.033412
2022-01-15 23:56:35,037 iteration 995 : loss : 0.081028, loss_ce: 0.029370
2022-01-15 23:56:35,950 iteration 996 : loss : 0.054659, loss_ce: 0.022415
2022-01-15 23:56:36,923 iteration 997 : loss : 0.097086, loss_ce: 0.046401
2022-01-15 23:56:37,871 iteration 998 : loss : 0.100045, loss_ce: 0.033383
2022-01-15 23:56:38,906 iteration 999 : loss : 0.070203, loss_ce: 0.029560
2022-01-15 23:56:39,875 iteration 1000 : loss : 0.089556, loss_ce: 0.040361
2022-01-15 23:56:40,843 iteration 1001 : loss : 0.096676, loss_ce: 0.036695
2022-01-15 23:56:41,718 iteration 1002 : loss : 0.056978, loss_ce: 0.018537
2022-01-15 23:56:42,624 iteration 1003 : loss : 0.086627, loss_ce: 0.033712
 15%|████▍                         | 59/400 [17:03<1:34:37, 16.65s/it]2022-01-15 23:56:43,607 iteration 1004 : loss : 0.087982, loss_ce: 0.032609
2022-01-15 23:56:44,648 iteration 1005 : loss : 0.120750, loss_ce: 0.038642
2022-01-15 23:56:45,599 iteration 1006 : loss : 0.095311, loss_ce: 0.044809
2022-01-15 23:56:46,573 iteration 1007 : loss : 0.079336, loss_ce: 0.033791
2022-01-15 23:56:47,533 iteration 1008 : loss : 0.097586, loss_ce: 0.033591
2022-01-15 23:56:48,494 iteration 1009 : loss : 0.086137, loss_ce: 0.031963
2022-01-15 23:56:49,398 iteration 1010 : loss : 0.075634, loss_ce: 0.032620
2022-01-15 23:56:50,324 iteration 1011 : loss : 0.059506, loss_ce: 0.024552
2022-01-15 23:56:51,344 iteration 1012 : loss : 0.122791, loss_ce: 0.040014
2022-01-15 23:56:52,253 iteration 1013 : loss : 0.091652, loss_ce: 0.029005
2022-01-15 23:56:53,236 iteration 1014 : loss : 0.072958, loss_ce: 0.026612
2022-01-15 23:56:54,164 iteration 1015 : loss : 0.092485, loss_ce: 0.043160
2022-01-15 23:56:55,017 iteration 1016 : loss : 0.081086, loss_ce: 0.042404
2022-01-15 23:56:56,061 iteration 1017 : loss : 0.072278, loss_ce: 0.026717
2022-01-15 23:56:57,065 iteration 1018 : loss : 0.064740, loss_ce: 0.026040
2022-01-15 23:56:58,087 iteration 1019 : loss : 0.116774, loss_ce: 0.047003
2022-01-15 23:56:58,087 Training Data Eval:
2022-01-15 23:57:02,476   Average segmentation loss on training set: 0.0610
2022-01-15 23:57:02,477 Validation Data Eval:
2022-01-15 23:57:03,940   Average segmentation loss on validation set: 0.1024
2022-01-15 23:57:04,812 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-15 23:57:05,808 iteration 1020 : loss : 0.077706, loss_ce: 0.029426
 15%|████▌                         | 60/400 [17:26<1:45:28, 18.61s/it]2022-01-15 23:57:06,915 iteration 1021 : loss : 0.097045, loss_ce: 0.037594
2022-01-15 23:57:07,856 iteration 1022 : loss : 0.084068, loss_ce: 0.033176
2022-01-15 23:57:08,766 iteration 1023 : loss : 0.122287, loss_ce: 0.042299
2022-01-15 23:57:09,754 iteration 1024 : loss : 0.055972, loss_ce: 0.026697
2022-01-15 23:57:10,665 iteration 1025 : loss : 0.092710, loss_ce: 0.038729
2022-01-15 23:57:11,641 iteration 1026 : loss : 0.082179, loss_ce: 0.027007
2022-01-15 23:57:12,571 iteration 1027 : loss : 0.085920, loss_ce: 0.044788
2022-01-15 23:57:13,465 iteration 1028 : loss : 0.090474, loss_ce: 0.027669
2022-01-15 23:57:14,433 iteration 1029 : loss : 0.129919, loss_ce: 0.044780
2022-01-15 23:57:15,398 iteration 1030 : loss : 0.066479, loss_ce: 0.024346
2022-01-15 23:57:16,414 iteration 1031 : loss : 0.069202, loss_ce: 0.027411
2022-01-15 23:57:17,294 iteration 1032 : loss : 0.058640, loss_ce: 0.021783
2022-01-15 23:57:18,299 iteration 1033 : loss : 0.085142, loss_ce: 0.028978
2022-01-15 23:57:19,323 iteration 1034 : loss : 0.064903, loss_ce: 0.031351
2022-01-15 23:57:20,308 iteration 1035 : loss : 0.149125, loss_ce: 0.065132
2022-01-15 23:57:21,357 iteration 1036 : loss : 0.074753, loss_ce: 0.029516
2022-01-15 23:57:22,183 iteration 1037 : loss : 0.070840, loss_ce: 0.032586
 15%|████▌                         | 61/400 [17:43<1:41:21, 17.94s/it]2022-01-15 23:57:23,134 iteration 1038 : loss : 0.063339, loss_ce: 0.028992
2022-01-15 23:57:24,080 iteration 1039 : loss : 0.087109, loss_ce: 0.033331
2022-01-15 23:57:24,955 iteration 1040 : loss : 0.082247, loss_ce: 0.028905
2022-01-15 23:57:25,976 iteration 1041 : loss : 0.068601, loss_ce: 0.023869
2022-01-15 23:57:26,993 iteration 1042 : loss : 0.086139, loss_ce: 0.031594
2022-01-15 23:57:27,896 iteration 1043 : loss : 0.054722, loss_ce: 0.020494
2022-01-15 23:57:28,829 iteration 1044 : loss : 0.071456, loss_ce: 0.027540
2022-01-15 23:57:29,748 iteration 1045 : loss : 0.084649, loss_ce: 0.044625
2022-01-15 23:57:30,694 iteration 1046 : loss : 0.072020, loss_ce: 0.027331
2022-01-15 23:57:31,730 iteration 1047 : loss : 0.086579, loss_ce: 0.035794
2022-01-15 23:57:32,683 iteration 1048 : loss : 0.111521, loss_ce: 0.040224
2022-01-15 23:57:33,556 iteration 1049 : loss : 0.078829, loss_ce: 0.030243
2022-01-15 23:57:34,455 iteration 1050 : loss : 0.055807, loss_ce: 0.021472
2022-01-15 23:57:35,403 iteration 1051 : loss : 0.082315, loss_ce: 0.033383
2022-01-15 23:57:36,347 iteration 1052 : loss : 0.089566, loss_ce: 0.044232
2022-01-15 23:57:37,409 iteration 1053 : loss : 0.068995, loss_ce: 0.027905
2022-01-15 23:57:38,329 iteration 1054 : loss : 0.079525, loss_ce: 0.029830
 16%|████▋                         | 62/400 [17:59<1:38:00, 17.40s/it]2022-01-15 23:57:39,324 iteration 1055 : loss : 0.070923, loss_ce: 0.025743
2022-01-15 23:57:40,261 iteration 1056 : loss : 0.092924, loss_ce: 0.040960
2022-01-15 23:57:41,240 iteration 1057 : loss : 0.129895, loss_ce: 0.033880
2022-01-15 23:57:42,115 iteration 1058 : loss : 0.059768, loss_ce: 0.024634
2022-01-15 23:57:43,137 iteration 1059 : loss : 0.054902, loss_ce: 0.024588
2022-01-15 23:57:44,058 iteration 1060 : loss : 0.083986, loss_ce: 0.037596
2022-01-15 23:57:45,048 iteration 1061 : loss : 0.062190, loss_ce: 0.024666
2022-01-15 23:57:45,995 iteration 1062 : loss : 0.068101, loss_ce: 0.026033
2022-01-15 23:57:47,028 iteration 1063 : loss : 0.070456, loss_ce: 0.024405
2022-01-15 23:57:47,942 iteration 1064 : loss : 0.069436, loss_ce: 0.032768
2022-01-15 23:57:48,796 iteration 1065 : loss : 0.115481, loss_ce: 0.043841
2022-01-15 23:57:49,755 iteration 1066 : loss : 0.075480, loss_ce: 0.032629
2022-01-15 23:57:50,845 iteration 1067 : loss : 0.085943, loss_ce: 0.033074
2022-01-15 23:57:51,849 iteration 1068 : loss : 0.141225, loss_ce: 0.054219
2022-01-15 23:57:52,732 iteration 1069 : loss : 0.095554, loss_ce: 0.036331
2022-01-15 23:57:53,783 iteration 1070 : loss : 0.073414, loss_ce: 0.027796
2022-01-15 23:57:54,722 iteration 1071 : loss : 0.076685, loss_ce: 0.031349
 16%|████▋                         | 63/400 [18:15<1:36:01, 17.10s/it]2022-01-15 23:57:55,700 iteration 1072 : loss : 0.080276, loss_ce: 0.032313
2022-01-15 23:57:56,751 iteration 1073 : loss : 0.095178, loss_ce: 0.037198
2022-01-15 23:57:57,673 iteration 1074 : loss : 0.048393, loss_ce: 0.021768
2022-01-15 23:57:58,631 iteration 1075 : loss : 0.063826, loss_ce: 0.023357
2022-01-15 23:57:59,535 iteration 1076 : loss : 0.076831, loss_ce: 0.032599
2022-01-15 23:58:00,531 iteration 1077 : loss : 0.152650, loss_ce: 0.061016
2022-01-15 23:58:01,405 iteration 1078 : loss : 0.092788, loss_ce: 0.037700
2022-01-15 23:58:02,348 iteration 1079 : loss : 0.080792, loss_ce: 0.036118
2022-01-15 23:58:03,320 iteration 1080 : loss : 0.058697, loss_ce: 0.022887
2022-01-15 23:58:04,294 iteration 1081 : loss : 0.069846, loss_ce: 0.026090
2022-01-15 23:58:05,254 iteration 1082 : loss : 0.093257, loss_ce: 0.036330
2022-01-15 23:58:06,211 iteration 1083 : loss : 0.080020, loss_ce: 0.026592
2022-01-15 23:58:07,224 iteration 1084 : loss : 0.111380, loss_ce: 0.030231
2022-01-15 23:58:08,156 iteration 1085 : loss : 0.095772, loss_ce: 0.037431
2022-01-15 23:58:09,139 iteration 1086 : loss : 0.086864, loss_ce: 0.030756
2022-01-15 23:58:10,036 iteration 1087 : loss : 0.059948, loss_ce: 0.026226
2022-01-15 23:58:10,953 iteration 1088 : loss : 0.072330, loss_ce: 0.034505
 16%|████▊                         | 64/400 [18:31<1:34:18, 16.84s/it]2022-01-15 23:58:11,855 iteration 1089 : loss : 0.062539, loss_ce: 0.025904
2022-01-15 23:58:12,798 iteration 1090 : loss : 0.077028, loss_ce: 0.028709
2022-01-15 23:58:13,786 iteration 1091 : loss : 0.083026, loss_ce: 0.043951
2022-01-15 23:58:14,749 iteration 1092 : loss : 0.084036, loss_ce: 0.025249
2022-01-15 23:58:15,719 iteration 1093 : loss : 0.070526, loss_ce: 0.023874
2022-01-15 23:58:16,798 iteration 1094 : loss : 0.208681, loss_ce: 0.063516
2022-01-15 23:58:17,678 iteration 1095 : loss : 0.074233, loss_ce: 0.026484
2022-01-15 23:58:18,579 iteration 1096 : loss : 0.063741, loss_ce: 0.028230
2022-01-15 23:58:19,455 iteration 1097 : loss : 0.061755, loss_ce: 0.023432
2022-01-15 23:58:20,465 iteration 1098 : loss : 0.088198, loss_ce: 0.039736
2022-01-15 23:58:21,412 iteration 1099 : loss : 0.061937, loss_ce: 0.019893
2022-01-15 23:58:22,426 iteration 1100 : loss : 0.078249, loss_ce: 0.033886
2022-01-15 23:58:23,449 iteration 1101 : loss : 0.087880, loss_ce: 0.034957
2022-01-15 23:58:24,395 iteration 1102 : loss : 0.097427, loss_ce: 0.032067
2022-01-15 23:58:25,364 iteration 1103 : loss : 0.061381, loss_ce: 0.027127
2022-01-15 23:58:26,297 iteration 1104 : loss : 0.077809, loss_ce: 0.032344
2022-01-15 23:58:26,297 Training Data Eval:
2022-01-15 23:58:30,695   Average segmentation loss on training set: 0.0662
2022-01-15 23:58:30,695 Validation Data Eval:
2022-01-15 23:58:32,153   Average segmentation loss on validation set: 0.1144
2022-01-15 23:58:33,082 iteration 1105 : loss : 0.069979, loss_ce: 0.031137
 16%|████▉                         | 65/400 [18:54<1:42:53, 18.43s/it]2022-01-15 23:58:34,139 iteration 1106 : loss : 0.084245, loss_ce: 0.032354
2022-01-15 23:58:35,082 iteration 1107 : loss : 0.065612, loss_ce: 0.026630
2022-01-15 23:58:35,999 iteration 1108 : loss : 0.073000, loss_ce: 0.022514
2022-01-15 23:58:37,024 iteration 1109 : loss : 0.085788, loss_ce: 0.032751
2022-01-15 23:58:37,966 iteration 1110 : loss : 0.053951, loss_ce: 0.023638
2022-01-15 23:58:39,005 iteration 1111 : loss : 0.097101, loss_ce: 0.029417
2022-01-15 23:58:39,901 iteration 1112 : loss : 0.071127, loss_ce: 0.032453
2022-01-15 23:58:40,846 iteration 1113 : loss : 0.073110, loss_ce: 0.026827
2022-01-15 23:58:41,808 iteration 1114 : loss : 0.094233, loss_ce: 0.032181
2022-01-15 23:58:42,780 iteration 1115 : loss : 0.062078, loss_ce: 0.023235
2022-01-15 23:58:43,643 iteration 1116 : loss : 0.080779, loss_ce: 0.038686
2022-01-15 23:58:44,534 iteration 1117 : loss : 0.083105, loss_ce: 0.032826
2022-01-15 23:58:45,509 iteration 1118 : loss : 0.071205, loss_ce: 0.030765
2022-01-15 23:58:46,494 iteration 1119 : loss : 0.070581, loss_ce: 0.028082
2022-01-15 23:58:47,452 iteration 1120 : loss : 0.075734, loss_ce: 0.022721
2022-01-15 23:58:48,367 iteration 1121 : loss : 0.048376, loss_ce: 0.022310
2022-01-15 23:58:49,235 iteration 1122 : loss : 0.071901, loss_ce: 0.022254
 16%|████▉                         | 66/400 [19:10<1:38:46, 17.74s/it]2022-01-15 23:58:50,339 iteration 1123 : loss : 0.046034, loss_ce: 0.017991
2022-01-15 23:58:51,285 iteration 1124 : loss : 0.052118, loss_ce: 0.025072
2022-01-15 23:58:52,185 iteration 1125 : loss : 0.090916, loss_ce: 0.023955
2022-01-15 23:58:53,101 iteration 1126 : loss : 0.075491, loss_ce: 0.022915
2022-01-15 23:58:54,011 iteration 1127 : loss : 0.082291, loss_ce: 0.032745
2022-01-15 23:58:55,037 iteration 1128 : loss : 0.051431, loss_ce: 0.023038
2022-01-15 23:58:56,086 iteration 1129 : loss : 0.065607, loss_ce: 0.028481
2022-01-15 23:58:56,965 iteration 1130 : loss : 0.078454, loss_ce: 0.032635
2022-01-15 23:58:57,962 iteration 1131 : loss : 0.080851, loss_ce: 0.032758
2022-01-15 23:58:59,001 iteration 1132 : loss : 0.066803, loss_ce: 0.025928
2022-01-15 23:59:00,022 iteration 1133 : loss : 0.069768, loss_ce: 0.033249
2022-01-15 23:59:01,041 iteration 1134 : loss : 0.073451, loss_ce: 0.023452
2022-01-15 23:59:01,953 iteration 1135 : loss : 0.098188, loss_ce: 0.039777
2022-01-15 23:59:02,876 iteration 1136 : loss : 0.045961, loss_ce: 0.020108
2022-01-15 23:59:03,793 iteration 1137 : loss : 0.082414, loss_ce: 0.037225
2022-01-15 23:59:04,769 iteration 1138 : loss : 0.072604, loss_ce: 0.030044
2022-01-15 23:59:05,657 iteration 1139 : loss : 0.065318, loss_ce: 0.027721
 17%|█████                         | 67/400 [19:26<1:36:17, 17.35s/it]2022-01-15 23:59:06,663 iteration 1140 : loss : 0.061418, loss_ce: 0.023360
2022-01-15 23:59:07,634 iteration 1141 : loss : 0.091219, loss_ce: 0.043642
2022-01-15 23:59:08,710 iteration 1142 : loss : 0.068237, loss_ce: 0.032877
2022-01-15 23:59:09,683 iteration 1143 : loss : 0.080571, loss_ce: 0.031058
2022-01-15 23:59:10,664 iteration 1144 : loss : 0.083077, loss_ce: 0.030194
2022-01-15 23:59:11,618 iteration 1145 : loss : 0.081520, loss_ce: 0.032172
2022-01-15 23:59:12,543 iteration 1146 : loss : 0.054913, loss_ce: 0.021328
2022-01-15 23:59:13,466 iteration 1147 : loss : 0.059796, loss_ce: 0.021686
2022-01-15 23:59:14,379 iteration 1148 : loss : 0.063940, loss_ce: 0.025038
2022-01-15 23:59:15,320 iteration 1149 : loss : 0.042272, loss_ce: 0.020378
2022-01-15 23:59:16,230 iteration 1150 : loss : 0.070092, loss_ce: 0.023705
2022-01-15 23:59:17,152 iteration 1151 : loss : 0.053775, loss_ce: 0.024431
2022-01-15 23:59:18,048 iteration 1152 : loss : 0.083184, loss_ce: 0.039306
2022-01-15 23:59:19,090 iteration 1153 : loss : 0.110419, loss_ce: 0.036962
2022-01-15 23:59:20,079 iteration 1154 : loss : 0.070777, loss_ce: 0.028407
2022-01-15 23:59:21,082 iteration 1155 : loss : 0.081054, loss_ce: 0.028864
2022-01-15 23:59:22,152 iteration 1156 : loss : 0.072903, loss_ce: 0.028363
 17%|█████                         | 68/400 [19:43<1:34:33, 17.09s/it]2022-01-15 23:59:23,185 iteration 1157 : loss : 0.082430, loss_ce: 0.035638
2022-01-15 23:59:24,125 iteration 1158 : loss : 0.075684, loss_ce: 0.029112
2022-01-15 23:59:24,966 iteration 1159 : loss : 0.067323, loss_ce: 0.028131
2022-01-15 23:59:25,877 iteration 1160 : loss : 0.077718, loss_ce: 0.036731
2022-01-15 23:59:26,847 iteration 1161 : loss : 0.071837, loss_ce: 0.024003
2022-01-15 23:59:27,812 iteration 1162 : loss : 0.058955, loss_ce: 0.023469
2022-01-15 23:59:28,758 iteration 1163 : loss : 0.053162, loss_ce: 0.025893
2022-01-15 23:59:29,769 iteration 1164 : loss : 0.071372, loss_ce: 0.029697
2022-01-15 23:59:30,636 iteration 1165 : loss : 0.061085, loss_ce: 0.026494
2022-01-15 23:59:31,529 iteration 1166 : loss : 0.082296, loss_ce: 0.024799
2022-01-15 23:59:32,482 iteration 1167 : loss : 0.076100, loss_ce: 0.035079
2022-01-15 23:59:33,500 iteration 1168 : loss : 0.100356, loss_ce: 0.029584
2022-01-15 23:59:34,376 iteration 1169 : loss : 0.078709, loss_ce: 0.024546
2022-01-15 23:59:35,343 iteration 1170 : loss : 0.070038, loss_ce: 0.020717
2022-01-15 23:59:36,418 iteration 1171 : loss : 0.139339, loss_ce: 0.040225
2022-01-15 23:59:37,293 iteration 1172 : loss : 0.064998, loss_ce: 0.023937
2022-01-15 23:59:38,165 iteration 1173 : loss : 0.054843, loss_ce: 0.020196
 17%|█████▏                        | 69/400 [19:59<1:32:30, 16.77s/it]2022-01-15 23:59:39,212 iteration 1174 : loss : 0.064428, loss_ce: 0.024402
2022-01-15 23:59:40,250 iteration 1175 : loss : 0.091706, loss_ce: 0.040770
2022-01-15 23:59:41,168 iteration 1176 : loss : 0.082408, loss_ce: 0.029500
2022-01-15 23:59:42,085 iteration 1177 : loss : 0.078986, loss_ce: 0.034277
2022-01-15 23:59:42,964 iteration 1178 : loss : 0.098049, loss_ce: 0.035292
2022-01-15 23:59:43,965 iteration 1179 : loss : 0.061453, loss_ce: 0.027512
2022-01-15 23:59:44,942 iteration 1180 : loss : 0.059607, loss_ce: 0.024026
2022-01-15 23:59:45,824 iteration 1181 : loss : 0.078487, loss_ce: 0.027788
2022-01-15 23:59:46,749 iteration 1182 : loss : 0.060052, loss_ce: 0.025667
2022-01-15 23:59:47,680 iteration 1183 : loss : 0.056883, loss_ce: 0.025771
2022-01-15 23:59:48,637 iteration 1184 : loss : 0.120028, loss_ce: 0.045988
2022-01-15 23:59:49,567 iteration 1185 : loss : 0.076583, loss_ce: 0.043238
2022-01-15 23:59:50,526 iteration 1186 : loss : 0.064639, loss_ce: 0.020290
2022-01-15 23:59:51,405 iteration 1187 : loss : 0.046506, loss_ce: 0.019975
2022-01-15 23:59:52,387 iteration 1188 : loss : 0.075851, loss_ce: 0.029745
2022-01-15 23:59:53,383 iteration 1189 : loss : 0.102348, loss_ce: 0.024167
2022-01-15 23:59:53,383 Training Data Eval:
2022-01-15 23:59:57,778   Average segmentation loss on training set: 0.0583
2022-01-15 23:59:57,778 Validation Data Eval:
2022-01-15 23:59:59,241   Average segmentation loss on validation set: 0.1070
2022-01-16 00:00:00,138 iteration 1190 : loss : 0.071086, loss_ce: 0.026012
 18%|█████▎                        | 70/400 [20:21<1:40:47, 18.33s/it]2022-01-16 00:00:01,149 iteration 1191 : loss : 0.059600, loss_ce: 0.024086
2022-01-16 00:00:02,069 iteration 1192 : loss : 0.123154, loss_ce: 0.058538
2022-01-16 00:00:02,917 iteration 1193 : loss : 0.062556, loss_ce: 0.023106
2022-01-16 00:00:03,860 iteration 1194 : loss : 0.063214, loss_ce: 0.021335
2022-01-16 00:00:04,802 iteration 1195 : loss : 0.071286, loss_ce: 0.028187
2022-01-16 00:00:05,767 iteration 1196 : loss : 0.062029, loss_ce: 0.024619
2022-01-16 00:00:06,754 iteration 1197 : loss : 0.109264, loss_ce: 0.032781
2022-01-16 00:00:07,618 iteration 1198 : loss : 0.052030, loss_ce: 0.019256
2022-01-16 00:00:08,544 iteration 1199 : loss : 0.095319, loss_ce: 0.051259
2022-01-16 00:00:09,404 iteration 1200 : loss : 0.072743, loss_ce: 0.027623
2022-01-16 00:00:10,302 iteration 1201 : loss : 0.093729, loss_ce: 0.029482
2022-01-16 00:00:11,305 iteration 1202 : loss : 0.068515, loss_ce: 0.028203
2022-01-16 00:00:12,306 iteration 1203 : loss : 0.072053, loss_ce: 0.031577
2022-01-16 00:00:13,175 iteration 1204 : loss : 0.063968, loss_ce: 0.021070
2022-01-16 00:00:14,156 iteration 1205 : loss : 0.069630, loss_ce: 0.031658
2022-01-16 00:00:15,086 iteration 1206 : loss : 0.063411, loss_ce: 0.022875
2022-01-16 00:00:16,088 iteration 1207 : loss : 0.074793, loss_ce: 0.033267
 18%|█████▎                        | 71/400 [20:37<1:36:34, 17.61s/it]2022-01-16 00:00:17,060 iteration 1208 : loss : 0.093214, loss_ce: 0.036870
2022-01-16 00:00:18,011 iteration 1209 : loss : 0.063657, loss_ce: 0.025492
2022-01-16 00:00:18,875 iteration 1210 : loss : 0.056109, loss_ce: 0.021194
2022-01-16 00:00:19,878 iteration 1211 : loss : 0.060358, loss_ce: 0.027284
2022-01-16 00:00:20,807 iteration 1212 : loss : 0.058091, loss_ce: 0.024673
2022-01-16 00:00:21,638 iteration 1213 : loss : 0.044860, loss_ce: 0.017241
2022-01-16 00:00:22,659 iteration 1214 : loss : 0.091034, loss_ce: 0.040396
2022-01-16 00:00:23,583 iteration 1215 : loss : 0.049962, loss_ce: 0.021748
2022-01-16 00:00:24,504 iteration 1216 : loss : 0.056779, loss_ce: 0.020477
2022-01-16 00:00:25,568 iteration 1217 : loss : 0.097813, loss_ce: 0.037425
2022-01-16 00:00:26,443 iteration 1218 : loss : 0.064893, loss_ce: 0.025832
2022-01-16 00:00:27,538 iteration 1219 : loss : 0.072582, loss_ce: 0.034679
2022-01-16 00:00:28,476 iteration 1220 : loss : 0.064108, loss_ce: 0.027471
2022-01-16 00:00:29,494 iteration 1221 : loss : 0.074203, loss_ce: 0.027432
2022-01-16 00:00:30,406 iteration 1222 : loss : 0.072836, loss_ce: 0.024600
2022-01-16 00:00:31,316 iteration 1223 : loss : 0.070650, loss_ce: 0.024974
2022-01-16 00:00:32,242 iteration 1224 : loss : 0.115366, loss_ce: 0.046492
 18%|█████▍                        | 72/400 [20:53<1:33:54, 17.18s/it]2022-01-16 00:00:33,243 iteration 1225 : loss : 0.062670, loss_ce: 0.019586
2022-01-16 00:00:34,208 iteration 1226 : loss : 0.064062, loss_ce: 0.020666
2022-01-16 00:00:35,094 iteration 1227 : loss : 0.066210, loss_ce: 0.022525
2022-01-16 00:00:35,990 iteration 1228 : loss : 0.096715, loss_ce: 0.032908
2022-01-16 00:00:37,057 iteration 1229 : loss : 0.077908, loss_ce: 0.043167
2022-01-16 00:00:38,068 iteration 1230 : loss : 0.068923, loss_ce: 0.025062
2022-01-16 00:00:39,031 iteration 1231 : loss : 0.048505, loss_ce: 0.018735
2022-01-16 00:00:39,940 iteration 1232 : loss : 0.074731, loss_ce: 0.036298
2022-01-16 00:00:40,947 iteration 1233 : loss : 0.054709, loss_ce: 0.020749
2022-01-16 00:00:42,010 iteration 1234 : loss : 0.074421, loss_ce: 0.029459
2022-01-16 00:00:42,875 iteration 1235 : loss : 0.098137, loss_ce: 0.035652
2022-01-16 00:00:43,870 iteration 1236 : loss : 0.079363, loss_ce: 0.041005
2022-01-16 00:00:44,810 iteration 1237 : loss : 0.095095, loss_ce: 0.030190
2022-01-16 00:00:45,689 iteration 1238 : loss : 0.083833, loss_ce: 0.029844
2022-01-16 00:00:46,614 iteration 1239 : loss : 0.052397, loss_ce: 0.024027
2022-01-16 00:00:47,643 iteration 1240 : loss : 0.073462, loss_ce: 0.025740
2022-01-16 00:00:48,586 iteration 1241 : loss : 0.072448, loss_ce: 0.034098
 18%|█████▍                        | 73/400 [21:09<1:32:16, 16.93s/it]2022-01-16 00:00:49,652 iteration 1242 : loss : 0.083400, loss_ce: 0.043507
2022-01-16 00:00:50,600 iteration 1243 : loss : 0.062229, loss_ce: 0.023607
2022-01-16 00:00:51,653 iteration 1244 : loss : 0.081468, loss_ce: 0.031220
2022-01-16 00:00:52,678 iteration 1245 : loss : 0.064698, loss_ce: 0.023920
2022-01-16 00:00:53,616 iteration 1246 : loss : 0.069807, loss_ce: 0.031448
2022-01-16 00:00:54,753 iteration 1247 : loss : 0.107174, loss_ce: 0.039267
2022-01-16 00:00:55,664 iteration 1248 : loss : 0.063793, loss_ce: 0.025967
2022-01-16 00:00:56,600 iteration 1249 : loss : 0.094650, loss_ce: 0.053322
2022-01-16 00:00:57,559 iteration 1250 : loss : 0.073178, loss_ce: 0.017595
2022-01-16 00:00:58,574 iteration 1251 : loss : 0.055706, loss_ce: 0.025345
2022-01-16 00:00:59,460 iteration 1252 : loss : 0.082310, loss_ce: 0.029010
2022-01-16 00:01:00,394 iteration 1253 : loss : 0.069568, loss_ce: 0.028065
2022-01-16 00:01:01,340 iteration 1254 : loss : 0.048581, loss_ce: 0.017637
2022-01-16 00:01:02,403 iteration 1255 : loss : 0.071841, loss_ce: 0.029685
2022-01-16 00:01:03,343 iteration 1256 : loss : 0.053681, loss_ce: 0.018906
2022-01-16 00:01:04,179 iteration 1257 : loss : 0.048032, loss_ce: 0.018332
2022-01-16 00:01:05,024 iteration 1258 : loss : 0.050211, loss_ce: 0.023759
 18%|█████▌                        | 74/400 [21:25<1:31:10, 16.78s/it]2022-01-16 00:01:05,980 iteration 1259 : loss : 0.062747, loss_ce: 0.022831
2022-01-16 00:01:07,036 iteration 1260 : loss : 0.047983, loss_ce: 0.019364
2022-01-16 00:01:07,957 iteration 1261 : loss : 0.066108, loss_ce: 0.023382
2022-01-16 00:01:08,834 iteration 1262 : loss : 0.046317, loss_ce: 0.016977
2022-01-16 00:01:09,767 iteration 1263 : loss : 0.055222, loss_ce: 0.020856
2022-01-16 00:01:10,724 iteration 1264 : loss : 0.061237, loss_ce: 0.028546
2022-01-16 00:01:11,666 iteration 1265 : loss : 0.060046, loss_ce: 0.023571
2022-01-16 00:01:12,565 iteration 1266 : loss : 0.042657, loss_ce: 0.017375
2022-01-16 00:01:13,454 iteration 1267 : loss : 0.082699, loss_ce: 0.044631
2022-01-16 00:01:14,353 iteration 1268 : loss : 0.047102, loss_ce: 0.018150
2022-01-16 00:01:15,270 iteration 1269 : loss : 0.070045, loss_ce: 0.035803
2022-01-16 00:01:16,209 iteration 1270 : loss : 0.044919, loss_ce: 0.020008
2022-01-16 00:01:17,221 iteration 1271 : loss : 0.071256, loss_ce: 0.031969
2022-01-16 00:01:18,051 iteration 1272 : loss : 0.051843, loss_ce: 0.018782
2022-01-16 00:01:18,941 iteration 1273 : loss : 0.084556, loss_ce: 0.028877
2022-01-16 00:01:19,908 iteration 1274 : loss : 0.087025, loss_ce: 0.041293
2022-01-16 00:01:19,908 Training Data Eval:
2022-01-16 00:01:24,311   Average segmentation loss on training set: 0.0656
2022-01-16 00:01:24,311 Validation Data Eval:
2022-01-16 00:01:25,769   Average segmentation loss on validation set: 0.1205
2022-01-16 00:01:26,656 iteration 1275 : loss : 0.068369, loss_ce: 0.026340
 19%|█████▋                        | 75/400 [21:47<1:38:47, 18.24s/it]2022-01-16 00:01:27,645 iteration 1276 : loss : 0.053063, loss_ce: 0.024082
2022-01-16 00:01:28,707 iteration 1277 : loss : 0.081157, loss_ce: 0.027973
2022-01-16 00:01:29,655 iteration 1278 : loss : 0.072553, loss_ce: 0.031909
2022-01-16 00:01:30,579 iteration 1279 : loss : 0.070642, loss_ce: 0.025560
2022-01-16 00:01:31,548 iteration 1280 : loss : 0.079183, loss_ce: 0.032755
2022-01-16 00:01:32,440 iteration 1281 : loss : 0.070443, loss_ce: 0.026930
2022-01-16 00:01:33,367 iteration 1282 : loss : 0.046616, loss_ce: 0.018392
2022-01-16 00:01:34,221 iteration 1283 : loss : 0.103906, loss_ce: 0.027962
2022-01-16 00:01:35,137 iteration 1284 : loss : 0.060539, loss_ce: 0.019449
2022-01-16 00:01:36,007 iteration 1285 : loss : 0.047332, loss_ce: 0.017084
2022-01-16 00:01:36,998 iteration 1286 : loss : 0.082348, loss_ce: 0.030564
2022-01-16 00:01:37,983 iteration 1287 : loss : 0.072909, loss_ce: 0.034079
2022-01-16 00:01:38,875 iteration 1288 : loss : 0.063130, loss_ce: 0.026510
2022-01-16 00:01:39,810 iteration 1289 : loss : 0.093976, loss_ce: 0.034858
2022-01-16 00:01:40,707 iteration 1290 : loss : 0.120716, loss_ce: 0.044462
2022-01-16 00:01:41,597 iteration 1291 : loss : 0.072834, loss_ce: 0.024937
2022-01-16 00:01:42,480 iteration 1292 : loss : 0.064973, loss_ce: 0.035966
 19%|█████▋                        | 76/400 [22:03<1:34:33, 17.51s/it]2022-01-16 00:01:43,578 iteration 1293 : loss : 0.083985, loss_ce: 0.037532
2022-01-16 00:01:44,434 iteration 1294 : loss : 0.046505, loss_ce: 0.019495
2022-01-16 00:01:45,418 iteration 1295 : loss : 0.078332, loss_ce: 0.025655
2022-01-16 00:01:46,372 iteration 1296 : loss : 0.076065, loss_ce: 0.027741
2022-01-16 00:01:47,192 iteration 1297 : loss : 0.056710, loss_ce: 0.025671
2022-01-16 00:01:48,203 iteration 1298 : loss : 0.078238, loss_ce: 0.031447
2022-01-16 00:01:49,113 iteration 1299 : loss : 0.049584, loss_ce: 0.019814
2022-01-16 00:01:50,136 iteration 1300 : loss : 0.090733, loss_ce: 0.026933
2022-01-16 00:01:51,166 iteration 1301 : loss : 0.087387, loss_ce: 0.026027
2022-01-16 00:01:52,037 iteration 1302 : loss : 0.072504, loss_ce: 0.026234
2022-01-16 00:01:53,021 iteration 1303 : loss : 0.071663, loss_ce: 0.022852
2022-01-16 00:01:53,971 iteration 1304 : loss : 0.073844, loss_ce: 0.031827
2022-01-16 00:01:55,006 iteration 1305 : loss : 0.066471, loss_ce: 0.023655
2022-01-16 00:01:55,969 iteration 1306 : loss : 0.056447, loss_ce: 0.021933
2022-01-16 00:01:56,875 iteration 1307 : loss : 0.063950, loss_ce: 0.025474
2022-01-16 00:01:57,819 iteration 1308 : loss : 0.072227, loss_ce: 0.035982
2022-01-16 00:01:58,723 iteration 1309 : loss : 0.057371, loss_ce: 0.022688
 19%|█████▊                        | 77/400 [22:19<1:32:13, 17.13s/it]2022-01-16 00:01:59,704 iteration 1310 : loss : 0.060799, loss_ce: 0.023905
2022-01-16 00:02:00,759 iteration 1311 : loss : 0.074041, loss_ce: 0.024456
2022-01-16 00:02:01,706 iteration 1312 : loss : 0.063441, loss_ce: 0.021573
2022-01-16 00:02:02,640 iteration 1313 : loss : 0.058177, loss_ce: 0.024290
2022-01-16 00:02:03,643 iteration 1314 : loss : 0.084994, loss_ce: 0.037448
2022-01-16 00:02:04,667 iteration 1315 : loss : 0.056124, loss_ce: 0.026837
2022-01-16 00:02:05,578 iteration 1316 : loss : 0.080459, loss_ce: 0.031496
2022-01-16 00:02:06,454 iteration 1317 : loss : 0.066236, loss_ce: 0.023728
2022-01-16 00:02:07,325 iteration 1318 : loss : 0.062613, loss_ce: 0.024433
2022-01-16 00:02:08,289 iteration 1319 : loss : 0.080230, loss_ce: 0.033674
2022-01-16 00:02:09,154 iteration 1320 : loss : 0.050744, loss_ce: 0.018853
2022-01-16 00:02:10,091 iteration 1321 : loss : 0.073910, loss_ce: 0.031315
2022-01-16 00:02:11,004 iteration 1322 : loss : 0.067478, loss_ce: 0.029207
2022-01-16 00:02:12,000 iteration 1323 : loss : 0.060885, loss_ce: 0.020018
2022-01-16 00:02:13,033 iteration 1324 : loss : 0.050265, loss_ce: 0.020796
2022-01-16 00:02:13,972 iteration 1325 : loss : 0.051751, loss_ce: 0.022627
2022-01-16 00:02:14,914 iteration 1326 : loss : 0.077667, loss_ce: 0.028506
 20%|█████▊                        | 78/400 [22:35<1:30:25, 16.85s/it]2022-01-16 00:02:15,902 iteration 1327 : loss : 0.046781, loss_ce: 0.018940
2022-01-16 00:02:16,855 iteration 1328 : loss : 0.049292, loss_ce: 0.020574
2022-01-16 00:02:17,794 iteration 1329 : loss : 0.071172, loss_ce: 0.028376
2022-01-16 00:02:18,821 iteration 1330 : loss : 0.052193, loss_ce: 0.017811
2022-01-16 00:02:19,764 iteration 1331 : loss : 0.053253, loss_ce: 0.022142
2022-01-16 00:02:20,677 iteration 1332 : loss : 0.057782, loss_ce: 0.023413
2022-01-16 00:02:21,594 iteration 1333 : loss : 0.056279, loss_ce: 0.022546
2022-01-16 00:02:22,584 iteration 1334 : loss : 0.042884, loss_ce: 0.016603
2022-01-16 00:02:23,564 iteration 1335 : loss : 0.041872, loss_ce: 0.017265
2022-01-16 00:02:24,460 iteration 1336 : loss : 0.053750, loss_ce: 0.023739
2022-01-16 00:02:25,463 iteration 1337 : loss : 0.084089, loss_ce: 0.034426
2022-01-16 00:02:26,376 iteration 1338 : loss : 0.042171, loss_ce: 0.018284
2022-01-16 00:02:27,275 iteration 1339 : loss : 0.079913, loss_ce: 0.029308
2022-01-16 00:02:28,165 iteration 1340 : loss : 0.044378, loss_ce: 0.017908
2022-01-16 00:02:29,130 iteration 1341 : loss : 0.086464, loss_ce: 0.030510
2022-01-16 00:02:30,163 iteration 1342 : loss : 0.084673, loss_ce: 0.029898
2022-01-16 00:02:31,012 iteration 1343 : loss : 0.061071, loss_ce: 0.021958
 20%|█████▉                        | 79/400 [22:51<1:28:55, 16.62s/it]2022-01-16 00:02:32,050 iteration 1344 : loss : 0.059519, loss_ce: 0.022139
2022-01-16 00:02:32,950 iteration 1345 : loss : 0.062964, loss_ce: 0.015125
2022-01-16 00:02:33,943 iteration 1346 : loss : 0.064295, loss_ce: 0.021013
2022-01-16 00:02:34,887 iteration 1347 : loss : 0.043959, loss_ce: 0.019742
2022-01-16 00:02:35,788 iteration 1348 : loss : 0.088104, loss_ce: 0.039433
2022-01-16 00:02:36,730 iteration 1349 : loss : 0.098161, loss_ce: 0.035650
2022-01-16 00:02:37,654 iteration 1350 : loss : 0.100094, loss_ce: 0.032624
2022-01-16 00:02:38,690 iteration 1351 : loss : 0.088252, loss_ce: 0.034411
2022-01-16 00:02:39,572 iteration 1352 : loss : 0.080943, loss_ce: 0.035554
2022-01-16 00:02:40,514 iteration 1353 : loss : 0.061422, loss_ce: 0.030513
2022-01-16 00:02:41,464 iteration 1354 : loss : 0.070772, loss_ce: 0.023499
2022-01-16 00:02:42,330 iteration 1355 : loss : 0.056836, loss_ce: 0.016878
2022-01-16 00:02:43,353 iteration 1356 : loss : 0.069103, loss_ce: 0.021524
2022-01-16 00:02:44,232 iteration 1357 : loss : 0.051244, loss_ce: 0.025753
2022-01-16 00:02:45,136 iteration 1358 : loss : 0.059479, loss_ce: 0.025794
2022-01-16 00:02:46,170 iteration 1359 : loss : 0.063463, loss_ce: 0.033034
2022-01-16 00:02:46,170 Training Data Eval:
2022-01-16 00:02:50,563   Average segmentation loss on training set: 0.0527
2022-01-16 00:02:50,564 Validation Data Eval:
2022-01-16 00:02:52,022   Average segmentation loss on validation set: 0.0947
2022-01-16 00:02:52,893 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-16 00:02:53,846 iteration 1360 : loss : 0.063530, loss_ce: 0.025068
 20%|██████                        | 80/400 [23:14<1:38:35, 18.49s/it]2022-01-16 00:02:54,918 iteration 1361 : loss : 0.092077, loss_ce: 0.027215
2022-01-16 00:02:55,843 iteration 1362 : loss : 0.065199, loss_ce: 0.020262
2022-01-16 00:02:56,803 iteration 1363 : loss : 0.051941, loss_ce: 0.019671
2022-01-16 00:02:57,667 iteration 1364 : loss : 0.076691, loss_ce: 0.036439
2022-01-16 00:02:58,566 iteration 1365 : loss : 0.056527, loss_ce: 0.020260
2022-01-16 00:02:59,589 iteration 1366 : loss : 0.085070, loss_ce: 0.032483
2022-01-16 00:03:00,553 iteration 1367 : loss : 0.072202, loss_ce: 0.039715
2022-01-16 00:03:01,700 iteration 1368 : loss : 0.066165, loss_ce: 0.025740
2022-01-16 00:03:02,642 iteration 1369 : loss : 0.065775, loss_ce: 0.022849
2022-01-16 00:03:03,546 iteration 1370 : loss : 0.058006, loss_ce: 0.026451
2022-01-16 00:03:04,485 iteration 1371 : loss : 0.054442, loss_ce: 0.021900
2022-01-16 00:03:05,582 iteration 1372 : loss : 0.079856, loss_ce: 0.034271
2022-01-16 00:03:06,509 iteration 1373 : loss : 0.064132, loss_ce: 0.029018
2022-01-16 00:03:07,408 iteration 1374 : loss : 0.074524, loss_ce: 0.025522
2022-01-16 00:03:08,320 iteration 1375 : loss : 0.044040, loss_ce: 0.018213
2022-01-16 00:03:09,262 iteration 1376 : loss : 0.047098, loss_ce: 0.013267
2022-01-16 00:03:10,272 iteration 1377 : loss : 0.054610, loss_ce: 0.028079
 20%|██████                        | 81/400 [23:31<1:35:00, 17.87s/it]2022-01-16 00:03:11,395 iteration 1378 : loss : 0.062885, loss_ce: 0.032607
2022-01-16 00:03:12,403 iteration 1379 : loss : 0.066851, loss_ce: 0.029587
2022-01-16 00:03:13,364 iteration 1380 : loss : 0.088138, loss_ce: 0.028613
2022-01-16 00:03:14,377 iteration 1381 : loss : 0.060757, loss_ce: 0.023997
2022-01-16 00:03:15,356 iteration 1382 : loss : 0.087044, loss_ce: 0.029188
2022-01-16 00:03:16,247 iteration 1383 : loss : 0.071559, loss_ce: 0.020826
2022-01-16 00:03:17,237 iteration 1384 : loss : 0.062016, loss_ce: 0.025591
2022-01-16 00:03:18,214 iteration 1385 : loss : 0.046227, loss_ce: 0.019258
2022-01-16 00:03:19,150 iteration 1386 : loss : 0.088086, loss_ce: 0.030051
2022-01-16 00:03:20,215 iteration 1387 : loss : 0.084065, loss_ce: 0.028907
2022-01-16 00:03:21,153 iteration 1388 : loss : 0.055479, loss_ce: 0.021526
2022-01-16 00:03:22,083 iteration 1389 : loss : 0.071320, loss_ce: 0.026957
2022-01-16 00:03:23,066 iteration 1390 : loss : 0.053101, loss_ce: 0.019009
2022-01-16 00:03:24,035 iteration 1391 : loss : 0.065527, loss_ce: 0.019588
2022-01-16 00:03:25,000 iteration 1392 : loss : 0.060387, loss_ce: 0.017001
2022-01-16 00:03:25,927 iteration 1393 : loss : 0.048792, loss_ce: 0.014889
2022-01-16 00:03:26,864 iteration 1394 : loss : 0.048970, loss_ce: 0.022114
 20%|██████▏                       | 82/400 [23:47<1:32:40, 17.49s/it]2022-01-16 00:03:27,875 iteration 1395 : loss : 0.055649, loss_ce: 0.022931
2022-01-16 00:03:28,784 iteration 1396 : loss : 0.053418, loss_ce: 0.022571
2022-01-16 00:03:29,744 iteration 1397 : loss : 0.093132, loss_ce: 0.027031
2022-01-16 00:03:30,790 iteration 1398 : loss : 0.057990, loss_ce: 0.022785
2022-01-16 00:03:31,770 iteration 1399 : loss : 0.065833, loss_ce: 0.030453
2022-01-16 00:03:32,700 iteration 1400 : loss : 0.055574, loss_ce: 0.024219
2022-01-16 00:03:33,620 iteration 1401 : loss : 0.075007, loss_ce: 0.024886
2022-01-16 00:03:34,484 iteration 1402 : loss : 0.054717, loss_ce: 0.021619
2022-01-16 00:03:35,546 iteration 1403 : loss : 0.069915, loss_ce: 0.025502
2022-01-16 00:03:36,554 iteration 1404 : loss : 0.071940, loss_ce: 0.028088
2022-01-16 00:03:37,550 iteration 1405 : loss : 0.068870, loss_ce: 0.032796
2022-01-16 00:03:38,514 iteration 1406 : loss : 0.068092, loss_ce: 0.024382
2022-01-16 00:03:39,410 iteration 1407 : loss : 0.057723, loss_ce: 0.029616
2022-01-16 00:03:40,329 iteration 1408 : loss : 0.081144, loss_ce: 0.026914
2022-01-16 00:03:41,361 iteration 1409 : loss : 0.096935, loss_ce: 0.031601
2022-01-16 00:03:42,343 iteration 1410 : loss : 0.068202, loss_ce: 0.022880
2022-01-16 00:03:43,268 iteration 1411 : loss : 0.046969, loss_ce: 0.019128
 21%|██████▏                       | 83/400 [24:04<1:30:38, 17.16s/it]2022-01-16 00:03:44,179 iteration 1412 : loss : 0.057080, loss_ce: 0.019397
2022-01-16 00:03:45,176 iteration 1413 : loss : 0.056503, loss_ce: 0.019601
2022-01-16 00:03:46,123 iteration 1414 : loss : 0.060722, loss_ce: 0.029657
2022-01-16 00:03:46,994 iteration 1415 : loss : 0.069735, loss_ce: 0.024354
2022-01-16 00:03:47,941 iteration 1416 : loss : 0.041289, loss_ce: 0.013023
2022-01-16 00:03:48,937 iteration 1417 : loss : 0.055817, loss_ce: 0.020807
2022-01-16 00:03:49,811 iteration 1418 : loss : 0.047577, loss_ce: 0.015353
2022-01-16 00:03:50,884 iteration 1419 : loss : 0.070661, loss_ce: 0.022768
2022-01-16 00:03:51,892 iteration 1420 : loss : 0.055592, loss_ce: 0.019575
2022-01-16 00:03:52,799 iteration 1421 : loss : 0.055807, loss_ce: 0.027394
2022-01-16 00:03:53,744 iteration 1422 : loss : 0.071162, loss_ce: 0.026436
2022-01-16 00:03:54,650 iteration 1423 : loss : 0.072688, loss_ce: 0.029381
2022-01-16 00:03:55,644 iteration 1424 : loss : 0.065175, loss_ce: 0.024367
2022-01-16 00:03:56,674 iteration 1425 : loss : 0.083973, loss_ce: 0.030236
2022-01-16 00:03:57,483 iteration 1426 : loss : 0.053885, loss_ce: 0.022245
2022-01-16 00:03:58,395 iteration 1427 : loss : 0.061257, loss_ce: 0.026634
2022-01-16 00:03:59,342 iteration 1428 : loss : 0.073255, loss_ce: 0.030208
 21%|██████▎                       | 84/400 [24:20<1:28:39, 16.83s/it]2022-01-16 00:04:00,466 iteration 1429 : loss : 0.081593, loss_ce: 0.034810
2022-01-16 00:04:01,368 iteration 1430 : loss : 0.072772, loss_ce: 0.026673
2022-01-16 00:04:02,299 iteration 1431 : loss : 0.058435, loss_ce: 0.029562
2022-01-16 00:04:03,263 iteration 1432 : loss : 0.088948, loss_ce: 0.036118
2022-01-16 00:04:04,305 iteration 1433 : loss : 0.068043, loss_ce: 0.024216
2022-01-16 00:04:05,314 iteration 1434 : loss : 0.060666, loss_ce: 0.024264
2022-01-16 00:04:06,156 iteration 1435 : loss : 0.063982, loss_ce: 0.021610
2022-01-16 00:04:07,178 iteration 1436 : loss : 0.064765, loss_ce: 0.029284
2022-01-16 00:04:08,048 iteration 1437 : loss : 0.110560, loss_ce: 0.025765
2022-01-16 00:04:08,885 iteration 1438 : loss : 0.055302, loss_ce: 0.025336
2022-01-16 00:04:09,821 iteration 1439 : loss : 0.040230, loss_ce: 0.013199
2022-01-16 00:04:10,848 iteration 1440 : loss : 0.051613, loss_ce: 0.023122
2022-01-16 00:04:11,761 iteration 1441 : loss : 0.040118, loss_ce: 0.015180
2022-01-16 00:04:12,646 iteration 1442 : loss : 0.055859, loss_ce: 0.021720
2022-01-16 00:04:13,624 iteration 1443 : loss : 0.079533, loss_ce: 0.032269
2022-01-16 00:04:14,638 iteration 1444 : loss : 0.045362, loss_ce: 0.020568
2022-01-16 00:04:14,638 Training Data Eval:
2022-01-16 00:04:19,046   Average segmentation loss on training set: 0.0720
2022-01-16 00:04:19,046 Validation Data Eval:
2022-01-16 00:04:20,506   Average segmentation loss on validation set: 0.2035
2022-01-16 00:04:21,482 iteration 1445 : loss : 0.056368, loss_ce: 0.018306
 21%|██████▍                       | 85/400 [24:42<1:36:44, 18.43s/it]2022-01-16 00:04:22,552 iteration 1446 : loss : 0.050987, loss_ce: 0.016518
2022-01-16 00:04:23,552 iteration 1447 : loss : 0.066142, loss_ce: 0.027086
2022-01-16 00:04:24,484 iteration 1448 : loss : 0.055521, loss_ce: 0.028230
2022-01-16 00:04:25,439 iteration 1449 : loss : 0.067334, loss_ce: 0.023326
2022-01-16 00:04:26,282 iteration 1450 : loss : 0.052504, loss_ce: 0.021354
2022-01-16 00:04:27,171 iteration 1451 : loss : 0.058726, loss_ce: 0.019262
2022-01-16 00:04:28,119 iteration 1452 : loss : 0.103844, loss_ce: 0.023698
2022-01-16 00:04:29,126 iteration 1453 : loss : 0.072314, loss_ce: 0.022257
2022-01-16 00:04:30,025 iteration 1454 : loss : 0.055210, loss_ce: 0.024400
2022-01-16 00:04:30,938 iteration 1455 : loss : 0.050079, loss_ce: 0.020243
2022-01-16 00:04:31,887 iteration 1456 : loss : 0.051420, loss_ce: 0.017125
2022-01-16 00:04:32,847 iteration 1457 : loss : 0.054042, loss_ce: 0.023356
2022-01-16 00:04:33,783 iteration 1458 : loss : 0.048409, loss_ce: 0.017860
2022-01-16 00:04:34,617 iteration 1459 : loss : 0.047072, loss_ce: 0.019797
2022-01-16 00:04:35,610 iteration 1460 : loss : 0.070019, loss_ce: 0.034202
2022-01-16 00:04:36,541 iteration 1461 : loss : 0.055682, loss_ce: 0.017634
2022-01-16 00:04:37,479 iteration 1462 : loss : 0.051064, loss_ce: 0.020616
 22%|██████▍                       | 86/400 [24:58<1:32:36, 17.70s/it]2022-01-16 00:04:38,468 iteration 1463 : loss : 0.053110, loss_ce: 0.022631
2022-01-16 00:04:39,448 iteration 1464 : loss : 0.065780, loss_ce: 0.020386
2022-01-16 00:04:40,460 iteration 1465 : loss : 0.062428, loss_ce: 0.028467
2022-01-16 00:04:41,405 iteration 1466 : loss : 0.054057, loss_ce: 0.018500
2022-01-16 00:04:42,335 iteration 1467 : loss : 0.070158, loss_ce: 0.027154
2022-01-16 00:04:43,298 iteration 1468 : loss : 0.063562, loss_ce: 0.022837
2022-01-16 00:04:44,275 iteration 1469 : loss : 0.057742, loss_ce: 0.028646
2022-01-16 00:04:45,229 iteration 1470 : loss : 0.045947, loss_ce: 0.016571
2022-01-16 00:04:46,097 iteration 1471 : loss : 0.062021, loss_ce: 0.021438
2022-01-16 00:04:47,027 iteration 1472 : loss : 0.057839, loss_ce: 0.021887
2022-01-16 00:04:48,038 iteration 1473 : loss : 0.045268, loss_ce: 0.023085
2022-01-16 00:04:48,922 iteration 1474 : loss : 0.051219, loss_ce: 0.019610
2022-01-16 00:04:49,859 iteration 1475 : loss : 0.057277, loss_ce: 0.021458
2022-01-16 00:04:50,851 iteration 1476 : loss : 0.069295, loss_ce: 0.035541
2022-01-16 00:04:51,786 iteration 1477 : loss : 0.062767, loss_ce: 0.021654
2022-01-16 00:04:52,786 iteration 1478 : loss : 0.089870, loss_ce: 0.033040
2022-01-16 00:04:53,755 iteration 1479 : loss : 0.091077, loss_ce: 0.042625
 22%|██████▌                       | 87/400 [25:14<1:30:05, 17.27s/it]2022-01-16 00:04:54,766 iteration 1480 : loss : 0.059302, loss_ce: 0.032838
2022-01-16 00:04:55,791 iteration 1481 : loss : 0.059623, loss_ce: 0.027272
2022-01-16 00:04:56,711 iteration 1482 : loss : 0.044097, loss_ce: 0.019654
2022-01-16 00:04:57,583 iteration 1483 : loss : 0.049256, loss_ce: 0.019981
2022-01-16 00:04:58,464 iteration 1484 : loss : 0.055525, loss_ce: 0.023687
2022-01-16 00:04:59,359 iteration 1485 : loss : 0.065839, loss_ce: 0.024726
2022-01-16 00:05:00,271 iteration 1486 : loss : 0.074536, loss_ce: 0.023394
2022-01-16 00:05:01,284 iteration 1487 : loss : 0.058980, loss_ce: 0.023659
2022-01-16 00:05:02,228 iteration 1488 : loss : 0.046912, loss_ce: 0.017702
2022-01-16 00:05:03,190 iteration 1489 : loss : 0.052526, loss_ce: 0.020093
2022-01-16 00:05:04,125 iteration 1490 : loss : 0.044295, loss_ce: 0.018250
2022-01-16 00:05:04,995 iteration 1491 : loss : 0.073443, loss_ce: 0.027811
2022-01-16 00:05:05,959 iteration 1492 : loss : 0.072481, loss_ce: 0.035146
2022-01-16 00:05:07,017 iteration 1493 : loss : 0.050721, loss_ce: 0.018834
2022-01-16 00:05:07,991 iteration 1494 : loss : 0.071788, loss_ce: 0.021699
2022-01-16 00:05:08,933 iteration 1495 : loss : 0.080039, loss_ce: 0.032192
2022-01-16 00:05:09,876 iteration 1496 : loss : 0.057335, loss_ce: 0.020306
 22%|██████▌                       | 88/400 [25:30<1:28:01, 16.93s/it]2022-01-16 00:05:10,845 iteration 1497 : loss : 0.045229, loss_ce: 0.018570
2022-01-16 00:05:11,665 iteration 1498 : loss : 0.040877, loss_ce: 0.017957
2022-01-16 00:05:12,530 iteration 1499 : loss : 0.055387, loss_ce: 0.025315
2022-01-16 00:05:13,603 iteration 1500 : loss : 0.083938, loss_ce: 0.029690
2022-01-16 00:05:14,462 iteration 1501 : loss : 0.056947, loss_ce: 0.016707
2022-01-16 00:05:15,409 iteration 1502 : loss : 0.071422, loss_ce: 0.028224
2022-01-16 00:05:16,424 iteration 1503 : loss : 0.056105, loss_ce: 0.018274
2022-01-16 00:05:17,334 iteration 1504 : loss : 0.051673, loss_ce: 0.021814
2022-01-16 00:05:18,218 iteration 1505 : loss : 0.054543, loss_ce: 0.019340
2022-01-16 00:05:19,207 iteration 1506 : loss : 0.052436, loss_ce: 0.018294
2022-01-16 00:05:20,114 iteration 1507 : loss : 0.044501, loss_ce: 0.020072
2022-01-16 00:05:21,064 iteration 1508 : loss : 0.135880, loss_ce: 0.026795
2022-01-16 00:05:21,981 iteration 1509 : loss : 0.065517, loss_ce: 0.025709
2022-01-16 00:05:22,886 iteration 1510 : loss : 0.069527, loss_ce: 0.022383
2022-01-16 00:05:23,930 iteration 1511 : loss : 0.080317, loss_ce: 0.043404
2022-01-16 00:05:24,874 iteration 1512 : loss : 0.057088, loss_ce: 0.020306
2022-01-16 00:05:25,820 iteration 1513 : loss : 0.057934, loss_ce: 0.023285
 22%|██████▋                       | 89/400 [25:46<1:26:11, 16.63s/it]2022-01-16 00:05:26,846 iteration 1514 : loss : 0.070590, loss_ce: 0.027553
2022-01-16 00:05:27,798 iteration 1515 : loss : 0.041758, loss_ce: 0.019664
2022-01-16 00:05:28,775 iteration 1516 : loss : 0.073452, loss_ce: 0.034806
2022-01-16 00:05:29,680 iteration 1517 : loss : 0.051849, loss_ce: 0.023182
2022-01-16 00:05:30,545 iteration 1518 : loss : 0.056563, loss_ce: 0.023025
2022-01-16 00:05:31,463 iteration 1519 : loss : 0.053545, loss_ce: 0.022943
2022-01-16 00:05:32,565 iteration 1520 : loss : 0.088058, loss_ce: 0.035184
2022-01-16 00:05:33,459 iteration 1521 : loss : 0.055255, loss_ce: 0.017588
2022-01-16 00:05:34,466 iteration 1522 : loss : 0.069053, loss_ce: 0.018040
2022-01-16 00:05:35,413 iteration 1523 : loss : 0.056953, loss_ce: 0.021191
2022-01-16 00:05:36,290 iteration 1524 : loss : 0.053231, loss_ce: 0.017442
2022-01-16 00:05:37,204 iteration 1525 : loss : 0.045188, loss_ce: 0.019835
2022-01-16 00:05:38,118 iteration 1526 : loss : 0.069908, loss_ce: 0.027344
2022-01-16 00:05:39,135 iteration 1527 : loss : 0.044070, loss_ce: 0.018387
2022-01-16 00:05:40,115 iteration 1528 : loss : 0.050324, loss_ce: 0.018874
2022-01-16 00:05:41,044 iteration 1529 : loss : 0.071275, loss_ce: 0.024085
2022-01-16 00:05:41,044 Training Data Eval:
2022-01-16 00:05:45,425   Average segmentation loss on training set: 0.0470
2022-01-16 00:05:45,426 Validation Data Eval:
2022-01-16 00:05:46,881   Average segmentation loss on validation set: 0.1307
2022-01-16 00:05:47,773 iteration 1530 : loss : 0.059033, loss_ce: 0.025722
 22%|██████▊                       | 90/400 [26:08<1:34:11, 18.23s/it]2022-01-16 00:05:48,810 iteration 1531 : loss : 0.065209, loss_ce: 0.028681
2022-01-16 00:05:49,788 iteration 1532 : loss : 0.082339, loss_ce: 0.023965
2022-01-16 00:05:50,677 iteration 1533 : loss : 0.066509, loss_ce: 0.024215
2022-01-16 00:05:51,592 iteration 1534 : loss : 0.050443, loss_ce: 0.028157
2022-01-16 00:05:52,481 iteration 1535 : loss : 0.061160, loss_ce: 0.026367
2022-01-16 00:05:53,433 iteration 1536 : loss : 0.059549, loss_ce: 0.020151
2022-01-16 00:05:54,332 iteration 1537 : loss : 0.049711, loss_ce: 0.025300
2022-01-16 00:05:55,151 iteration 1538 : loss : 0.109226, loss_ce: 0.033632
2022-01-16 00:05:56,016 iteration 1539 : loss : 0.053819, loss_ce: 0.023799
2022-01-16 00:05:56,964 iteration 1540 : loss : 0.055375, loss_ce: 0.026087
2022-01-16 00:05:57,952 iteration 1541 : loss : 0.056673, loss_ce: 0.022624
2022-01-16 00:05:58,991 iteration 1542 : loss : 0.062983, loss_ce: 0.025492
2022-01-16 00:05:59,941 iteration 1543 : loss : 0.083750, loss_ce: 0.020366
2022-01-16 00:06:00,892 iteration 1544 : loss : 0.056218, loss_ce: 0.022718
2022-01-16 00:06:01,760 iteration 1545 : loss : 0.061900, loss_ce: 0.023128
2022-01-16 00:06:02,665 iteration 1546 : loss : 0.064608, loss_ce: 0.022787
2022-01-16 00:06:03,625 iteration 1547 : loss : 0.053579, loss_ce: 0.021955
 23%|██████▊                       | 91/400 [26:24<1:30:12, 17.52s/it]2022-01-16 00:06:04,612 iteration 1548 : loss : 0.058240, loss_ce: 0.016962
2022-01-16 00:06:05,470 iteration 1549 : loss : 0.054547, loss_ce: 0.020636
2022-01-16 00:06:06,445 iteration 1550 : loss : 0.052290, loss_ce: 0.016751
2022-01-16 00:06:07,398 iteration 1551 : loss : 0.077628, loss_ce: 0.027778
2022-01-16 00:06:08,313 iteration 1552 : loss : 0.055864, loss_ce: 0.016813
2022-01-16 00:06:09,289 iteration 1553 : loss : 0.059180, loss_ce: 0.028749
2022-01-16 00:06:10,127 iteration 1554 : loss : 0.065432, loss_ce: 0.031501
2022-01-16 00:06:11,014 iteration 1555 : loss : 0.051525, loss_ce: 0.017716
2022-01-16 00:06:12,055 iteration 1556 : loss : 0.090428, loss_ce: 0.037864
2022-01-16 00:06:12,978 iteration 1557 : loss : 0.055449, loss_ce: 0.017955
2022-01-16 00:06:13,843 iteration 1558 : loss : 0.054531, loss_ce: 0.021795
2022-01-16 00:06:14,855 iteration 1559 : loss : 0.060389, loss_ce: 0.025374
2022-01-16 00:06:15,753 iteration 1560 : loss : 0.046305, loss_ce: 0.026439
2022-01-16 00:06:16,696 iteration 1561 : loss : 0.046629, loss_ce: 0.019508
2022-01-16 00:06:17,628 iteration 1562 : loss : 0.062310, loss_ce: 0.029742
2022-01-16 00:06:18,585 iteration 1563 : loss : 0.076076, loss_ce: 0.025123
2022-01-16 00:06:19,496 iteration 1564 : loss : 0.063457, loss_ce: 0.023412
 23%|██████▉                       | 92/400 [26:40<1:27:22, 17.02s/it]2022-01-16 00:06:20,449 iteration 1565 : loss : 0.047515, loss_ce: 0.025188
2022-01-16 00:06:21,425 iteration 1566 : loss : 0.075942, loss_ce: 0.020815
2022-01-16 00:06:22,373 iteration 1567 : loss : 0.051977, loss_ce: 0.022718
2022-01-16 00:06:23,423 iteration 1568 : loss : 0.052479, loss_ce: 0.019587
2022-01-16 00:06:24,362 iteration 1569 : loss : 0.046087, loss_ce: 0.019998
2022-01-16 00:06:25,312 iteration 1570 : loss : 0.059322, loss_ce: 0.021587
2022-01-16 00:06:26,254 iteration 1571 : loss : 0.060415, loss_ce: 0.022581
2022-01-16 00:06:27,295 iteration 1572 : loss : 0.067096, loss_ce: 0.026132
2022-01-16 00:06:28,148 iteration 1573 : loss : 0.036906, loss_ce: 0.017470
2022-01-16 00:06:29,115 iteration 1574 : loss : 0.053629, loss_ce: 0.019450
2022-01-16 00:06:30,136 iteration 1575 : loss : 0.051495, loss_ce: 0.019482
2022-01-16 00:06:31,153 iteration 1576 : loss : 0.040036, loss_ce: 0.017641
2022-01-16 00:06:32,004 iteration 1577 : loss : 0.047216, loss_ce: 0.016352
2022-01-16 00:06:32,914 iteration 1578 : loss : 0.045866, loss_ce: 0.014346
2022-01-16 00:06:33,918 iteration 1579 : loss : 0.053260, loss_ce: 0.018984
2022-01-16 00:06:34,899 iteration 1580 : loss : 0.071362, loss_ce: 0.020947
2022-01-16 00:06:35,981 iteration 1581 : loss : 0.048793, loss_ce: 0.022578
 23%|██████▉                       | 93/400 [26:56<1:26:16, 16.86s/it]2022-01-16 00:06:37,023 iteration 1582 : loss : 0.051133, loss_ce: 0.019425
2022-01-16 00:06:37,990 iteration 1583 : loss : 0.052662, loss_ce: 0.021614
2022-01-16 00:06:38,851 iteration 1584 : loss : 0.061329, loss_ce: 0.021159
2022-01-16 00:06:39,792 iteration 1585 : loss : 0.104769, loss_ce: 0.031830
2022-01-16 00:06:40,803 iteration 1586 : loss : 0.045699, loss_ce: 0.013962
2022-01-16 00:06:41,756 iteration 1587 : loss : 0.068715, loss_ce: 0.019825
2022-01-16 00:06:42,769 iteration 1588 : loss : 0.042880, loss_ce: 0.020897
2022-01-16 00:06:43,711 iteration 1589 : loss : 0.063046, loss_ce: 0.020789
2022-01-16 00:06:44,683 iteration 1590 : loss : 0.057827, loss_ce: 0.025554
2022-01-16 00:06:45,579 iteration 1591 : loss : 0.072632, loss_ce: 0.033168
2022-01-16 00:06:46,480 iteration 1592 : loss : 0.073006, loss_ce: 0.031121
2022-01-16 00:06:47,493 iteration 1593 : loss : 0.057196, loss_ce: 0.019576
2022-01-16 00:06:48,459 iteration 1594 : loss : 0.053361, loss_ce: 0.027466
2022-01-16 00:06:49,428 iteration 1595 : loss : 0.064475, loss_ce: 0.025015
2022-01-16 00:06:50,373 iteration 1596 : loss : 0.045222, loss_ce: 0.019362
2022-01-16 00:06:51,275 iteration 1597 : loss : 0.063681, loss_ce: 0.021823
2022-01-16 00:06:52,259 iteration 1598 : loss : 0.043770, loss_ce: 0.019629
 24%|███████                       | 94/400 [27:13<1:25:06, 16.69s/it]2022-01-16 00:06:53,297 iteration 1599 : loss : 0.045289, loss_ce: 0.019956
2022-01-16 00:06:54,204 iteration 1600 : loss : 0.070492, loss_ce: 0.023895
2022-01-16 00:06:55,140 iteration 1601 : loss : 0.085391, loss_ce: 0.031324
2022-01-16 00:06:56,049 iteration 1602 : loss : 0.061175, loss_ce: 0.030302
2022-01-16 00:06:57,067 iteration 1603 : loss : 0.082607, loss_ce: 0.030830
2022-01-16 00:06:57,984 iteration 1604 : loss : 0.063019, loss_ce: 0.027735
2022-01-16 00:06:59,008 iteration 1605 : loss : 0.038123, loss_ce: 0.013456
2022-01-16 00:07:00,005 iteration 1606 : loss : 0.073690, loss_ce: 0.018193
2022-01-16 00:07:00,951 iteration 1607 : loss : 0.047943, loss_ce: 0.018515
2022-01-16 00:07:01,918 iteration 1608 : loss : 0.037714, loss_ce: 0.013800
2022-01-16 00:07:02,886 iteration 1609 : loss : 0.045126, loss_ce: 0.016817
2022-01-16 00:07:03,816 iteration 1610 : loss : 0.074605, loss_ce: 0.035514
2022-01-16 00:07:04,782 iteration 1611 : loss : 0.072880, loss_ce: 0.026831
2022-01-16 00:07:05,730 iteration 1612 : loss : 0.051904, loss_ce: 0.023419
2022-01-16 00:07:06,685 iteration 1613 : loss : 0.043864, loss_ce: 0.016685
2022-01-16 00:07:07,650 iteration 1614 : loss : 0.053215, loss_ce: 0.018819
2022-01-16 00:07:07,650 Training Data Eval:
2022-01-16 00:07:12,024   Average segmentation loss on training set: 0.0393
2022-01-16 00:07:12,025 Validation Data Eval:
2022-01-16 00:07:13,477   Average segmentation loss on validation set: 0.0987
2022-01-16 00:07:14,452 iteration 1615 : loss : 0.067593, loss_ce: 0.034271
 24%|███████▏                      | 95/400 [27:35<1:33:13, 18.34s/it]2022-01-16 00:07:15,427 iteration 1616 : loss : 0.046310, loss_ce: 0.014201
2022-01-16 00:07:16,298 iteration 1617 : loss : 0.036748, loss_ce: 0.017011
2022-01-16 00:07:17,230 iteration 1618 : loss : 0.033378, loss_ce: 0.013137
2022-01-16 00:07:18,218 iteration 1619 : loss : 0.035825, loss_ce: 0.016498
2022-01-16 00:07:19,090 iteration 1620 : loss : 0.047863, loss_ce: 0.020237
2022-01-16 00:07:20,061 iteration 1621 : loss : 0.055765, loss_ce: 0.021344
2022-01-16 00:07:20,973 iteration 1622 : loss : 0.059486, loss_ce: 0.020096
2022-01-16 00:07:21,839 iteration 1623 : loss : 0.041367, loss_ce: 0.018826
2022-01-16 00:07:22,785 iteration 1624 : loss : 0.048897, loss_ce: 0.017517
2022-01-16 00:07:23,628 iteration 1625 : loss : 0.042371, loss_ce: 0.022200
2022-01-16 00:07:24,519 iteration 1626 : loss : 0.045462, loss_ce: 0.018041
2022-01-16 00:07:25,397 iteration 1627 : loss : 0.070292, loss_ce: 0.017870
2022-01-16 00:07:26,359 iteration 1628 : loss : 0.056639, loss_ce: 0.016399
2022-01-16 00:07:27,314 iteration 1629 : loss : 0.059724, loss_ce: 0.028891
2022-01-16 00:07:28,178 iteration 1630 : loss : 0.047305, loss_ce: 0.017541
2022-01-16 00:07:29,106 iteration 1631 : loss : 0.051517, loss_ce: 0.021703
2022-01-16 00:07:29,920 iteration 1632 : loss : 0.040897, loss_ce: 0.015333
 24%|███████▏                      | 96/400 [27:50<1:28:33, 17.48s/it]2022-01-16 00:07:30,986 iteration 1633 : loss : 0.041883, loss_ce: 0.014521
2022-01-16 00:07:31,959 iteration 1634 : loss : 0.055405, loss_ce: 0.024749
2022-01-16 00:07:32,873 iteration 1635 : loss : 0.054048, loss_ce: 0.025080
2022-01-16 00:07:33,698 iteration 1636 : loss : 0.050443, loss_ce: 0.017979
2022-01-16 00:07:34,692 iteration 1637 : loss : 0.058063, loss_ce: 0.018511
2022-01-16 00:07:35,648 iteration 1638 : loss : 0.057964, loss_ce: 0.020540
2022-01-16 00:07:36,652 iteration 1639 : loss : 0.059024, loss_ce: 0.022912
2022-01-16 00:07:37,582 iteration 1640 : loss : 0.046367, loss_ce: 0.018788
2022-01-16 00:07:38,553 iteration 1641 : loss : 0.068602, loss_ce: 0.027468
2022-01-16 00:07:39,606 iteration 1642 : loss : 0.087981, loss_ce: 0.030677
2022-01-16 00:07:40,580 iteration 1643 : loss : 0.036718, loss_ce: 0.013984
2022-01-16 00:07:41,542 iteration 1644 : loss : 0.072805, loss_ce: 0.031611
2022-01-16 00:07:42,383 iteration 1645 : loss : 0.056216, loss_ce: 0.018637
2022-01-16 00:07:43,300 iteration 1646 : loss : 0.055128, loss_ce: 0.026104
2022-01-16 00:07:44,312 iteration 1647 : loss : 0.068754, loss_ce: 0.036142
2022-01-16 00:07:45,235 iteration 1648 : loss : 0.046724, loss_ce: 0.020136
2022-01-16 00:07:46,275 iteration 1649 : loss : 0.083381, loss_ce: 0.021516
 24%|███████▎                      | 97/400 [28:07<1:26:33, 17.14s/it]2022-01-16 00:07:47,291 iteration 1650 : loss : 0.035397, loss_ce: 0.010868
2022-01-16 00:07:48,303 iteration 1651 : loss : 0.070627, loss_ce: 0.030564
2022-01-16 00:07:49,310 iteration 1652 : loss : 0.087801, loss_ce: 0.027384
2022-01-16 00:07:50,297 iteration 1653 : loss : 0.059174, loss_ce: 0.028378
2022-01-16 00:07:51,227 iteration 1654 : loss : 0.052366, loss_ce: 0.016333
2022-01-16 00:07:52,146 iteration 1655 : loss : 0.064568, loss_ce: 0.020720
2022-01-16 00:07:53,057 iteration 1656 : loss : 0.032954, loss_ce: 0.015371
2022-01-16 00:07:54,072 iteration 1657 : loss : 0.057456, loss_ce: 0.025983
2022-01-16 00:07:54,956 iteration 1658 : loss : 0.035919, loss_ce: 0.015298
2022-01-16 00:07:55,899 iteration 1659 : loss : 0.058913, loss_ce: 0.024775
2022-01-16 00:07:56,974 iteration 1660 : loss : 0.061996, loss_ce: 0.026998
2022-01-16 00:07:57,926 iteration 1661 : loss : 0.046468, loss_ce: 0.016911
2022-01-16 00:07:58,847 iteration 1662 : loss : 0.049366, loss_ce: 0.019354
2022-01-16 00:07:59,850 iteration 1663 : loss : 0.066047, loss_ce: 0.028375
2022-01-16 00:08:00,851 iteration 1664 : loss : 0.062134, loss_ce: 0.025039
2022-01-16 00:08:01,751 iteration 1665 : loss : 0.027997, loss_ce: 0.013083
2022-01-16 00:08:02,655 iteration 1666 : loss : 0.038312, loss_ce: 0.016121
 24%|███████▎                      | 98/400 [28:23<1:25:07, 16.91s/it]2022-01-16 00:08:03,661 iteration 1667 : loss : 0.041944, loss_ce: 0.018746
2022-01-16 00:08:04,670 iteration 1668 : loss : 0.059166, loss_ce: 0.024182
2022-01-16 00:08:05,596 iteration 1669 : loss : 0.045508, loss_ce: 0.018224
2022-01-16 00:08:06,527 iteration 1670 : loss : 0.062228, loss_ce: 0.021491
2022-01-16 00:08:07,497 iteration 1671 : loss : 0.051890, loss_ce: 0.020438
2022-01-16 00:08:08,413 iteration 1672 : loss : 0.049770, loss_ce: 0.016384
2022-01-16 00:08:09,307 iteration 1673 : loss : 0.041331, loss_ce: 0.019584
2022-01-16 00:08:10,312 iteration 1674 : loss : 0.053523, loss_ce: 0.020604
2022-01-16 00:08:11,227 iteration 1675 : loss : 0.043207, loss_ce: 0.015812
2022-01-16 00:08:12,217 iteration 1676 : loss : 0.040258, loss_ce: 0.017938
2022-01-16 00:08:13,223 iteration 1677 : loss : 0.047656, loss_ce: 0.018428
2022-01-16 00:08:14,201 iteration 1678 : loss : 0.080761, loss_ce: 0.021535
2022-01-16 00:08:15,192 iteration 1679 : loss : 0.039144, loss_ce: 0.010251
2022-01-16 00:08:16,161 iteration 1680 : loss : 0.045891, loss_ce: 0.022222
2022-01-16 00:08:17,102 iteration 1681 : loss : 0.107801, loss_ce: 0.035140
2022-01-16 00:08:18,006 iteration 1682 : loss : 0.053841, loss_ce: 0.024110
2022-01-16 00:08:18,985 iteration 1683 : loss : 0.056734, loss_ce: 0.024847
 25%|███████▍                      | 99/400 [28:39<1:23:58, 16.74s/it]2022-01-16 00:08:20,005 iteration 1684 : loss : 0.072235, loss_ce: 0.035954
2022-01-16 00:08:20,902 iteration 1685 : loss : 0.043016, loss_ce: 0.016489
2022-01-16 00:08:21,901 iteration 1686 : loss : 0.053207, loss_ce: 0.018818
2022-01-16 00:08:22,790 iteration 1687 : loss : 0.046855, loss_ce: 0.016250
2022-01-16 00:08:23,752 iteration 1688 : loss : 0.051123, loss_ce: 0.019168
2022-01-16 00:08:24,718 iteration 1689 : loss : 0.099489, loss_ce: 0.047328
2022-01-16 00:08:25,583 iteration 1690 : loss : 0.042358, loss_ce: 0.013839
2022-01-16 00:08:26,457 iteration 1691 : loss : 0.064192, loss_ce: 0.021728
2022-01-16 00:08:27,404 iteration 1692 : loss : 0.037616, loss_ce: 0.015551
2022-01-16 00:08:28,407 iteration 1693 : loss : 0.047482, loss_ce: 0.016207
2022-01-16 00:08:29,391 iteration 1694 : loss : 0.055939, loss_ce: 0.015262
2022-01-16 00:08:30,300 iteration 1695 : loss : 0.053991, loss_ce: 0.014478
2022-01-16 00:08:31,246 iteration 1696 : loss : 0.061453, loss_ce: 0.027664
2022-01-16 00:08:32,209 iteration 1697 : loss : 0.050024, loss_ce: 0.023843
2022-01-16 00:08:33,177 iteration 1698 : loss : 0.034709, loss_ce: 0.013771
2022-01-16 00:08:34,093 iteration 1699 : loss : 0.055487, loss_ce: 0.024537
2022-01-16 00:08:34,093 Training Data Eval:
2022-01-16 00:08:38,475   Average segmentation loss on training set: 0.0572
2022-01-16 00:08:38,476 Validation Data Eval:
2022-01-16 00:08:39,928   Average segmentation loss on validation set: 0.1110
2022-01-16 00:08:40,875 iteration 1700 : loss : 0.049477, loss_ce: 0.019272
 25%|███████▎                     | 100/400 [29:01<1:31:25, 18.28s/it]2022-01-16 00:08:41,882 iteration 1701 : loss : 0.049206, loss_ce: 0.020952
2022-01-16 00:08:42,822 iteration 1702 : loss : 0.056001, loss_ce: 0.020881
2022-01-16 00:08:43,836 iteration 1703 : loss : 0.074833, loss_ce: 0.030259
2022-01-16 00:08:44,771 iteration 1704 : loss : 0.045017, loss_ce: 0.020929
2022-01-16 00:08:45,748 iteration 1705 : loss : 0.053821, loss_ce: 0.022067
2022-01-16 00:08:46,767 iteration 1706 : loss : 0.062388, loss_ce: 0.024203
2022-01-16 00:08:47,683 iteration 1707 : loss : 0.043891, loss_ce: 0.020299
2022-01-16 00:08:48,622 iteration 1708 : loss : 0.095432, loss_ce: 0.026096
2022-01-16 00:08:49,548 iteration 1709 : loss : 0.068893, loss_ce: 0.030198
2022-01-16 00:08:50,538 iteration 1710 : loss : 0.059638, loss_ce: 0.019809
2022-01-16 00:08:51,475 iteration 1711 : loss : 0.045014, loss_ce: 0.017365
2022-01-16 00:08:52,343 iteration 1712 : loss : 0.036576, loss_ce: 0.016435
2022-01-16 00:08:53,304 iteration 1713 : loss : 0.063208, loss_ce: 0.021623
2022-01-16 00:08:54,327 iteration 1714 : loss : 0.058911, loss_ce: 0.021774
2022-01-16 00:08:55,329 iteration 1715 : loss : 0.051912, loss_ce: 0.022328
2022-01-16 00:08:56,199 iteration 1716 : loss : 0.053931, loss_ce: 0.017970
2022-01-16 00:08:57,194 iteration 1717 : loss : 0.075261, loss_ce: 0.019229
 25%|███████▎                     | 101/400 [29:18<1:28:09, 17.69s/it]2022-01-16 00:08:58,213 iteration 1718 : loss : 0.048673, loss_ce: 0.022984
2022-01-16 00:08:59,143 iteration 1719 : loss : 0.081275, loss_ce: 0.014982
2022-01-16 00:09:00,126 iteration 1720 : loss : 0.043327, loss_ce: 0.016835
2022-01-16 00:09:01,029 iteration 1721 : loss : 0.045141, loss_ce: 0.015139
2022-01-16 00:09:02,001 iteration 1722 : loss : 0.052978, loss_ce: 0.017692
2022-01-16 00:09:02,893 iteration 1723 : loss : 0.082009, loss_ce: 0.027339
2022-01-16 00:09:03,862 iteration 1724 : loss : 0.042055, loss_ce: 0.017288
2022-01-16 00:09:04,807 iteration 1725 : loss : 0.060514, loss_ce: 0.021305
2022-01-16 00:09:05,757 iteration 1726 : loss : 0.052562, loss_ce: 0.021536
2022-01-16 00:09:06,783 iteration 1727 : loss : 0.059807, loss_ce: 0.024878
2022-01-16 00:09:07,643 iteration 1728 : loss : 0.042608, loss_ce: 0.014628
2022-01-16 00:09:08,603 iteration 1729 : loss : 0.059079, loss_ce: 0.020871
2022-01-16 00:09:09,607 iteration 1730 : loss : 0.042217, loss_ce: 0.020131
2022-01-16 00:09:10,534 iteration 1731 : loss : 0.059164, loss_ce: 0.030000
2022-01-16 00:09:11,451 iteration 1732 : loss : 0.058397, loss_ce: 0.024776
2022-01-16 00:09:12,343 iteration 1733 : loss : 0.045201, loss_ce: 0.022314
2022-01-16 00:09:13,253 iteration 1734 : loss : 0.049731, loss_ce: 0.020645
 26%|███████▍                     | 102/400 [29:34<1:25:26, 17.20s/it]2022-01-16 00:09:14,399 iteration 1735 : loss : 0.053452, loss_ce: 0.023471
2022-01-16 00:09:15,308 iteration 1736 : loss : 0.051400, loss_ce: 0.022540
2022-01-16 00:09:16,381 iteration 1737 : loss : 0.072420, loss_ce: 0.028606
2022-01-16 00:09:17,323 iteration 1738 : loss : 0.039035, loss_ce: 0.018476
2022-01-16 00:09:18,194 iteration 1739 : loss : 0.045196, loss_ce: 0.015809
2022-01-16 00:09:19,185 iteration 1740 : loss : 0.037031, loss_ce: 0.015201
2022-01-16 00:09:20,164 iteration 1741 : loss : 0.041438, loss_ce: 0.015287
2022-01-16 00:09:21,147 iteration 1742 : loss : 0.047876, loss_ce: 0.017393
2022-01-16 00:09:22,009 iteration 1743 : loss : 0.052497, loss_ce: 0.015839
2022-01-16 00:09:23,023 iteration 1744 : loss : 0.047273, loss_ce: 0.017506
2022-01-16 00:09:24,023 iteration 1745 : loss : 0.061439, loss_ce: 0.025598
2022-01-16 00:09:24,975 iteration 1746 : loss : 0.062113, loss_ce: 0.028632
2022-01-16 00:09:25,884 iteration 1747 : loss : 0.040875, loss_ce: 0.017744
2022-01-16 00:09:26,849 iteration 1748 : loss : 0.041066, loss_ce: 0.014964
2022-01-16 00:09:27,681 iteration 1749 : loss : 0.037870, loss_ce: 0.012482
2022-01-16 00:09:28,632 iteration 1750 : loss : 0.096944, loss_ce: 0.018502
2022-01-16 00:09:29,680 iteration 1751 : loss : 0.046585, loss_ce: 0.017643
 26%|███████▍                     | 103/400 [29:50<1:24:00, 16.97s/it]2022-01-16 00:09:30,773 iteration 1752 : loss : 0.105932, loss_ce: 0.027987
2022-01-16 00:09:31,620 iteration 1753 : loss : 0.050781, loss_ce: 0.016159
2022-01-16 00:09:32,627 iteration 1754 : loss : 0.060791, loss_ce: 0.021916
2022-01-16 00:09:33,528 iteration 1755 : loss : 0.052600, loss_ce: 0.022884
2022-01-16 00:09:34,479 iteration 1756 : loss : 0.060881, loss_ce: 0.024251
2022-01-16 00:09:35,369 iteration 1757 : loss : 0.045189, loss_ce: 0.019139
2022-01-16 00:09:36,291 iteration 1758 : loss : 0.049419, loss_ce: 0.027269
2022-01-16 00:09:37,185 iteration 1759 : loss : 0.041233, loss_ce: 0.010776
2022-01-16 00:09:38,082 iteration 1760 : loss : 0.058180, loss_ce: 0.018167
2022-01-16 00:09:39,075 iteration 1761 : loss : 0.064343, loss_ce: 0.024038
2022-01-16 00:09:39,921 iteration 1762 : loss : 0.042369, loss_ce: 0.017858
2022-01-16 00:09:40,802 iteration 1763 : loss : 0.055520, loss_ce: 0.020432
2022-01-16 00:09:41,632 iteration 1764 : loss : 0.034783, loss_ce: 0.010575
2022-01-16 00:09:42,589 iteration 1765 : loss : 0.048246, loss_ce: 0.023086
2022-01-16 00:09:43,590 iteration 1766 : loss : 0.063856, loss_ce: 0.034141
2022-01-16 00:09:44,508 iteration 1767 : loss : 0.048894, loss_ce: 0.022745
2022-01-16 00:09:45,469 iteration 1768 : loss : 0.060310, loss_ce: 0.021167
 26%|███████▌                     | 104/400 [30:06<1:21:58, 16.62s/it]2022-01-16 00:09:46,487 iteration 1769 : loss : 0.044326, loss_ce: 0.017491
2022-01-16 00:09:47,391 iteration 1770 : loss : 0.046538, loss_ce: 0.018842
2022-01-16 00:09:48,241 iteration 1771 : loss : 0.051152, loss_ce: 0.020492
2022-01-16 00:09:49,116 iteration 1772 : loss : 0.044016, loss_ce: 0.022291
2022-01-16 00:09:50,098 iteration 1773 : loss : 0.078533, loss_ce: 0.025809
2022-01-16 00:09:51,055 iteration 1774 : loss : 0.032877, loss_ce: 0.012078
2022-01-16 00:09:52,029 iteration 1775 : loss : 0.047027, loss_ce: 0.018398
2022-01-16 00:09:52,927 iteration 1776 : loss : 0.042077, loss_ce: 0.021140
2022-01-16 00:09:53,808 iteration 1777 : loss : 0.041932, loss_ce: 0.016803
2022-01-16 00:09:54,672 iteration 1778 : loss : 0.042364, loss_ce: 0.014925
2022-01-16 00:09:55,662 iteration 1779 : loss : 0.053186, loss_ce: 0.016959
2022-01-16 00:09:56,601 iteration 1780 : loss : 0.065141, loss_ce: 0.031416
2022-01-16 00:09:57,479 iteration 1781 : loss : 0.048953, loss_ce: 0.019731
2022-01-16 00:09:58,447 iteration 1782 : loss : 0.040202, loss_ce: 0.015465
2022-01-16 00:09:59,403 iteration 1783 : loss : 0.039913, loss_ce: 0.014064
2022-01-16 00:10:00,304 iteration 1784 : loss : 0.049359, loss_ce: 0.019697
2022-01-16 00:10:00,304 Training Data Eval:
2022-01-16 00:10:04,693   Average segmentation loss on training set: 0.0548
2022-01-16 00:10:04,693 Validation Data Eval:
2022-01-16 00:10:06,156   Average segmentation loss on validation set: 0.1427
2022-01-16 00:10:07,137 iteration 1785 : loss : 0.046214, loss_ce: 0.018549
 26%|███████▌                     | 105/400 [30:28<1:29:08, 18.13s/it]2022-01-16 00:10:08,159 iteration 1786 : loss : 0.044915, loss_ce: 0.023413
2022-01-16 00:10:09,011 iteration 1787 : loss : 0.053535, loss_ce: 0.021190
2022-01-16 00:10:10,006 iteration 1788 : loss : 0.044992, loss_ce: 0.023861
2022-01-16 00:10:10,979 iteration 1789 : loss : 0.045131, loss_ce: 0.015718
2022-01-16 00:10:11,928 iteration 1790 : loss : 0.049296, loss_ce: 0.022792
2022-01-16 00:10:12,932 iteration 1791 : loss : 0.043826, loss_ce: 0.017115
2022-01-16 00:10:13,817 iteration 1792 : loss : 0.043108, loss_ce: 0.016378
2022-01-16 00:10:14,726 iteration 1793 : loss : 0.077139, loss_ce: 0.027568
2022-01-16 00:10:15,656 iteration 1794 : loss : 0.043816, loss_ce: 0.018424
2022-01-16 00:10:16,634 iteration 1795 : loss : 0.049632, loss_ce: 0.018307
2022-01-16 00:10:17,563 iteration 1796 : loss : 0.046298, loss_ce: 0.020986
2022-01-16 00:10:18,595 iteration 1797 : loss : 0.071132, loss_ce: 0.027591
2022-01-16 00:10:19,613 iteration 1798 : loss : 0.048815, loss_ce: 0.018785
2022-01-16 00:10:20,525 iteration 1799 : loss : 0.044613, loss_ce: 0.018828
2022-01-16 00:10:21,487 iteration 1800 : loss : 0.035899, loss_ce: 0.013854
2022-01-16 00:10:22,377 iteration 1801 : loss : 0.038952, loss_ce: 0.013005
2022-01-16 00:10:23,291 iteration 1802 : loss : 0.057695, loss_ce: 0.020242
 26%|███████▋                     | 106/400 [30:44<1:25:55, 17.54s/it]2022-01-16 00:10:24,382 iteration 1803 : loss : 0.058620, loss_ce: 0.022817
2022-01-16 00:10:25,393 iteration 1804 : loss : 0.057665, loss_ce: 0.017619
2022-01-16 00:10:26,307 iteration 1805 : loss : 0.044511, loss_ce: 0.012789
2022-01-16 00:10:27,210 iteration 1806 : loss : 0.044293, loss_ce: 0.018438
2022-01-16 00:10:28,112 iteration 1807 : loss : 0.063480, loss_ce: 0.022456
2022-01-16 00:10:29,040 iteration 1808 : loss : 0.046456, loss_ce: 0.018962
2022-01-16 00:10:29,939 iteration 1809 : loss : 0.033129, loss_ce: 0.013353
2022-01-16 00:10:30,770 iteration 1810 : loss : 0.033103, loss_ce: 0.012316
2022-01-16 00:10:31,758 iteration 1811 : loss : 0.049323, loss_ce: 0.021555
2022-01-16 00:10:32,770 iteration 1812 : loss : 0.041230, loss_ce: 0.015598
2022-01-16 00:10:33,846 iteration 1813 : loss : 0.046731, loss_ce: 0.016606
2022-01-16 00:10:34,816 iteration 1814 : loss : 0.043812, loss_ce: 0.020301
2022-01-16 00:10:35,696 iteration 1815 : loss : 0.048459, loss_ce: 0.017982
2022-01-16 00:10:36,541 iteration 1816 : loss : 0.040458, loss_ce: 0.016197
2022-01-16 00:10:37,546 iteration 1817 : loss : 0.050613, loss_ce: 0.019215
2022-01-16 00:10:38,484 iteration 1818 : loss : 0.054592, loss_ce: 0.020869
2022-01-16 00:10:39,469 iteration 1819 : loss : 0.044051, loss_ce: 0.017220
 27%|███████▊                     | 107/400 [31:00<1:23:39, 17.13s/it]2022-01-16 00:10:40,563 iteration 1820 : loss : 0.031641, loss_ce: 0.014115
2022-01-16 00:10:41,482 iteration 1821 : loss : 0.032842, loss_ce: 0.013447
2022-01-16 00:10:42,432 iteration 1822 : loss : 0.044618, loss_ce: 0.015468
2022-01-16 00:10:43,290 iteration 1823 : loss : 0.041234, loss_ce: 0.013236
2022-01-16 00:10:44,105 iteration 1824 : loss : 0.034647, loss_ce: 0.013506
2022-01-16 00:10:45,083 iteration 1825 : loss : 0.049893, loss_ce: 0.018985
2022-01-16 00:10:45,922 iteration 1826 : loss : 0.046497, loss_ce: 0.024019
2022-01-16 00:10:46,966 iteration 1827 : loss : 0.168847, loss_ce: 0.053062
2022-01-16 00:10:47,888 iteration 1828 : loss : 0.042945, loss_ce: 0.015804
2022-01-16 00:10:48,801 iteration 1829 : loss : 0.046806, loss_ce: 0.016659
2022-01-16 00:10:49,715 iteration 1830 : loss : 0.048290, loss_ce: 0.019715
2022-01-16 00:10:50,729 iteration 1831 : loss : 0.053921, loss_ce: 0.032059
2022-01-16 00:10:51,651 iteration 1832 : loss : 0.046770, loss_ce: 0.014153
2022-01-16 00:10:52,585 iteration 1833 : loss : 0.055137, loss_ce: 0.026486
2022-01-16 00:10:53,625 iteration 1834 : loss : 0.056939, loss_ce: 0.021826
2022-01-16 00:10:54,542 iteration 1835 : loss : 0.059361, loss_ce: 0.032694
2022-01-16 00:10:55,476 iteration 1836 : loss : 0.056936, loss_ce: 0.020326
 27%|███████▊                     | 108/400 [31:16<1:21:43, 16.79s/it]2022-01-16 00:10:56,537 iteration 1837 : loss : 0.040256, loss_ce: 0.015713
2022-01-16 00:10:57,537 iteration 1838 : loss : 0.043996, loss_ce: 0.018879
2022-01-16 00:10:58,455 iteration 1839 : loss : 0.069290, loss_ce: 0.027168
2022-01-16 00:10:59,314 iteration 1840 : loss : 0.047997, loss_ce: 0.021248
2022-01-16 00:11:00,288 iteration 1841 : loss : 0.054239, loss_ce: 0.022419
2022-01-16 00:11:01,291 iteration 1842 : loss : 0.092371, loss_ce: 0.029535
2022-01-16 00:11:02,168 iteration 1843 : loss : 0.046675, loss_ce: 0.020562
2022-01-16 00:11:03,109 iteration 1844 : loss : 0.063711, loss_ce: 0.026543
2022-01-16 00:11:03,975 iteration 1845 : loss : 0.043371, loss_ce: 0.017561
2022-01-16 00:11:05,015 iteration 1846 : loss : 0.049253, loss_ce: 0.018659
2022-01-16 00:11:06,007 iteration 1847 : loss : 0.074237, loss_ce: 0.033301
2022-01-16 00:11:06,953 iteration 1848 : loss : 0.045859, loss_ce: 0.016627
2022-01-16 00:11:07,802 iteration 1849 : loss : 0.038380, loss_ce: 0.016376
2022-01-16 00:11:08,745 iteration 1850 : loss : 0.096584, loss_ce: 0.025003
2022-01-16 00:11:09,716 iteration 1851 : loss : 0.063434, loss_ce: 0.022699
2022-01-16 00:11:10,662 iteration 1852 : loss : 0.049065, loss_ce: 0.019733
2022-01-16 00:11:11,617 iteration 1853 : loss : 0.067755, loss_ce: 0.017809
 27%|███████▉                     | 109/400 [31:32<1:20:30, 16.60s/it]2022-01-16 00:11:12,601 iteration 1854 : loss : 0.047121, loss_ce: 0.021838
2022-01-16 00:11:13,527 iteration 1855 : loss : 0.048579, loss_ce: 0.015846
2022-01-16 00:11:14,473 iteration 1856 : loss : 0.042924, loss_ce: 0.010156
2022-01-16 00:11:15,415 iteration 1857 : loss : 0.055249, loss_ce: 0.024505
2022-01-16 00:11:16,334 iteration 1858 : loss : 0.064971, loss_ce: 0.032171
2022-01-16 00:11:17,213 iteration 1859 : loss : 0.052487, loss_ce: 0.024745
2022-01-16 00:11:18,269 iteration 1860 : loss : 0.123916, loss_ce: 0.055745
2022-01-16 00:11:19,236 iteration 1861 : loss : 0.053146, loss_ce: 0.019080
2022-01-16 00:11:20,165 iteration 1862 : loss : 0.044371, loss_ce: 0.019045
2022-01-16 00:11:21,158 iteration 1863 : loss : 0.049453, loss_ce: 0.019718
2022-01-16 00:11:22,112 iteration 1864 : loss : 0.037377, loss_ce: 0.015849
2022-01-16 00:11:23,147 iteration 1865 : loss : 0.043012, loss_ce: 0.022385
2022-01-16 00:11:24,152 iteration 1866 : loss : 0.045801, loss_ce: 0.022281
2022-01-16 00:11:25,116 iteration 1867 : loss : 0.124186, loss_ce: 0.038866
2022-01-16 00:11:26,027 iteration 1868 : loss : 0.045965, loss_ce: 0.022462
2022-01-16 00:11:26,965 iteration 1869 : loss : 0.059392, loss_ce: 0.024379
2022-01-16 00:11:26,965 Training Data Eval:
2022-01-16 00:11:31,362   Average segmentation loss on training set: 0.0422
2022-01-16 00:11:31,363 Validation Data Eval:
2022-01-16 00:11:32,822   Average segmentation loss on validation set: 0.0695
2022-01-16 00:11:33,682 Found new lowest validation loss at iteration 1869! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-16 00:11:34,550 iteration 1870 : loss : 0.054628, loss_ce: 0.018608
 28%|███████▉                     | 110/400 [31:55<1:29:23, 18.50s/it]2022-01-16 00:11:35,531 iteration 1871 : loss : 0.039545, loss_ce: 0.017576
2022-01-16 00:11:36,418 iteration 1872 : loss : 0.037691, loss_ce: 0.013621
2022-01-16 00:11:37,368 iteration 1873 : loss : 0.066470, loss_ce: 0.028879
2022-01-16 00:11:38,367 iteration 1874 : loss : 0.053514, loss_ce: 0.023751
2022-01-16 00:11:39,393 iteration 1875 : loss : 0.049693, loss_ce: 0.028910
2022-01-16 00:11:40,416 iteration 1876 : loss : 0.049131, loss_ce: 0.013959
2022-01-16 00:11:41,416 iteration 1877 : loss : 0.047284, loss_ce: 0.013640
2022-01-16 00:11:42,308 iteration 1878 : loss : 0.049304, loss_ce: 0.016877
2022-01-16 00:11:43,209 iteration 1879 : loss : 0.043129, loss_ce: 0.019690
2022-01-16 00:11:44,098 iteration 1880 : loss : 0.044008, loss_ce: 0.014431
2022-01-16 00:11:44,985 iteration 1881 : loss : 0.029384, loss_ce: 0.010138
2022-01-16 00:11:45,925 iteration 1882 : loss : 0.056954, loss_ce: 0.013938
2022-01-16 00:11:46,792 iteration 1883 : loss : 0.040045, loss_ce: 0.016029
2022-01-16 00:11:47,801 iteration 1884 : loss : 0.041894, loss_ce: 0.016578
2022-01-16 00:11:48,689 iteration 1885 : loss : 0.037623, loss_ce: 0.013808
2022-01-16 00:11:49,651 iteration 1886 : loss : 0.049688, loss_ce: 0.020355
2022-01-16 00:11:50,540 iteration 1887 : loss : 0.043819, loss_ce: 0.016596
 28%|████████                     | 111/400 [32:11<1:25:28, 17.75s/it]2022-01-16 00:11:51,581 iteration 1888 : loss : 0.039826, loss_ce: 0.013215
2022-01-16 00:11:52,606 iteration 1889 : loss : 0.052662, loss_ce: 0.023802
2022-01-16 00:11:53,471 iteration 1890 : loss : 0.033877, loss_ce: 0.012321
2022-01-16 00:11:54,412 iteration 1891 : loss : 0.040628, loss_ce: 0.020803
2022-01-16 00:11:55,344 iteration 1892 : loss : 0.042225, loss_ce: 0.014894
2022-01-16 00:11:56,319 iteration 1893 : loss : 0.061660, loss_ce: 0.022080
2022-01-16 00:11:57,247 iteration 1894 : loss : 0.069540, loss_ce: 0.025972
2022-01-16 00:11:58,211 iteration 1895 : loss : 0.042454, loss_ce: 0.014326
2022-01-16 00:11:59,156 iteration 1896 : loss : 0.038327, loss_ce: 0.016552
2022-01-16 00:12:00,092 iteration 1897 : loss : 0.075529, loss_ce: 0.028191
2022-01-16 00:12:01,120 iteration 1898 : loss : 0.041614, loss_ce: 0.016684
2022-01-16 00:12:01,984 iteration 1899 : loss : 0.032901, loss_ce: 0.011965
2022-01-16 00:12:02,995 iteration 1900 : loss : 0.061032, loss_ce: 0.025587
2022-01-16 00:12:04,037 iteration 1901 : loss : 0.049133, loss_ce: 0.017162
2022-01-16 00:12:04,968 iteration 1902 : loss : 0.079717, loss_ce: 0.029576
2022-01-16 00:12:05,957 iteration 1903 : loss : 0.047148, loss_ce: 0.021181
2022-01-16 00:12:06,960 iteration 1904 : loss : 0.055189, loss_ce: 0.017840
 28%|████████                     | 112/400 [32:27<1:23:17, 17.35s/it]2022-01-16 00:12:08,022 iteration 1905 : loss : 0.048807, loss_ce: 0.020478
2022-01-16 00:12:08,974 iteration 1906 : loss : 0.054434, loss_ce: 0.016179
2022-01-16 00:12:09,909 iteration 1907 : loss : 0.043250, loss_ce: 0.015979
2022-01-16 00:12:10,986 iteration 1908 : loss : 0.050794, loss_ce: 0.014867
2022-01-16 00:12:11,966 iteration 1909 : loss : 0.041389, loss_ce: 0.016648
2022-01-16 00:12:12,949 iteration 1910 : loss : 0.088202, loss_ce: 0.017000
2022-01-16 00:12:13,953 iteration 1911 : loss : 0.035714, loss_ce: 0.011689
2022-01-16 00:12:14,815 iteration 1912 : loss : 0.040724, loss_ce: 0.015460
2022-01-16 00:12:15,763 iteration 1913 : loss : 0.051303, loss_ce: 0.020686
2022-01-16 00:12:16,717 iteration 1914 : loss : 0.044251, loss_ce: 0.019559
2022-01-16 00:12:17,688 iteration 1915 : loss : 0.046274, loss_ce: 0.021546
2022-01-16 00:12:18,627 iteration 1916 : loss : 0.053070, loss_ce: 0.021148
2022-01-16 00:12:19,569 iteration 1917 : loss : 0.059879, loss_ce: 0.026988
2022-01-16 00:12:20,543 iteration 1918 : loss : 0.047566, loss_ce: 0.014635
2022-01-16 00:12:21,451 iteration 1919 : loss : 0.038851, loss_ce: 0.014412
2022-01-16 00:12:22,365 iteration 1920 : loss : 0.050716, loss_ce: 0.021340
2022-01-16 00:12:23,385 iteration 1921 : loss : 0.068231, loss_ce: 0.028878
 28%|████████▏                    | 113/400 [32:44<1:21:39, 17.07s/it]2022-01-16 00:12:24,364 iteration 1922 : loss : 0.046144, loss_ce: 0.021761
2022-01-16 00:12:25,302 iteration 1923 : loss : 0.037167, loss_ce: 0.018376
2022-01-16 00:12:26,302 iteration 1924 : loss : 0.042211, loss_ce: 0.018872
2022-01-16 00:12:27,260 iteration 1925 : loss : 0.079265, loss_ce: 0.038987
2022-01-16 00:12:28,174 iteration 1926 : loss : 0.041838, loss_ce: 0.016526
2022-01-16 00:12:29,084 iteration 1927 : loss : 0.047825, loss_ce: 0.018540
2022-01-16 00:12:30,119 iteration 1928 : loss : 0.051729, loss_ce: 0.025070
2022-01-16 00:12:31,017 iteration 1929 : loss : 0.047048, loss_ce: 0.016829
2022-01-16 00:12:31,906 iteration 1930 : loss : 0.036733, loss_ce: 0.017250
2022-01-16 00:12:32,877 iteration 1931 : loss : 0.097936, loss_ce: 0.027539
2022-01-16 00:12:33,889 iteration 1932 : loss : 0.056340, loss_ce: 0.020762
2022-01-16 00:12:34,899 iteration 1933 : loss : 0.060488, loss_ce: 0.032564
2022-01-16 00:12:35,742 iteration 1934 : loss : 0.031458, loss_ce: 0.013485
2022-01-16 00:12:36,693 iteration 1935 : loss : 0.058951, loss_ce: 0.020778
2022-01-16 00:12:37,717 iteration 1936 : loss : 0.049886, loss_ce: 0.024485
2022-01-16 00:12:38,594 iteration 1937 : loss : 0.049045, loss_ce: 0.015343
2022-01-16 00:12:39,451 iteration 1938 : loss : 0.051299, loss_ce: 0.017452
 28%|████████▎                    | 114/400 [33:00<1:19:55, 16.77s/it]2022-01-16 00:12:40,414 iteration 1939 : loss : 0.032020, loss_ce: 0.009812
2022-01-16 00:12:41,465 iteration 1940 : loss : 0.044541, loss_ce: 0.019910
2022-01-16 00:12:42,511 iteration 1941 : loss : 0.053252, loss_ce: 0.022275
2022-01-16 00:12:43,492 iteration 1942 : loss : 0.071541, loss_ce: 0.025652
2022-01-16 00:12:44,416 iteration 1943 : loss : 0.041897, loss_ce: 0.019145
2022-01-16 00:12:45,364 iteration 1944 : loss : 0.036737, loss_ce: 0.014024
2022-01-16 00:12:46,265 iteration 1945 : loss : 0.061353, loss_ce: 0.021176
2022-01-16 00:12:47,210 iteration 1946 : loss : 0.046708, loss_ce: 0.017767
2022-01-16 00:12:48,190 iteration 1947 : loss : 0.058667, loss_ce: 0.027565
2022-01-16 00:12:49,135 iteration 1948 : loss : 0.092223, loss_ce: 0.028795
2022-01-16 00:12:50,051 iteration 1949 : loss : 0.059533, loss_ce: 0.031682
2022-01-16 00:12:50,928 iteration 1950 : loss : 0.033263, loss_ce: 0.014190
2022-01-16 00:12:51,931 iteration 1951 : loss : 0.058259, loss_ce: 0.019160
2022-01-16 00:12:52,909 iteration 1952 : loss : 0.059914, loss_ce: 0.019636
2022-01-16 00:12:53,933 iteration 1953 : loss : 0.054955, loss_ce: 0.025769
2022-01-16 00:12:54,897 iteration 1954 : loss : 0.035631, loss_ce: 0.017572
2022-01-16 00:12:54,897 Training Data Eval:
2022-01-16 00:12:59,294   Average segmentation loss on training set: 0.0406
2022-01-16 00:12:59,294 Validation Data Eval:
2022-01-16 00:13:00,751   Average segmentation loss on validation set: 0.1576
2022-01-16 00:13:01,711 iteration 1955 : loss : 0.062538, loss_ce: 0.018771
 29%|████████▎                    | 115/400 [33:22<1:27:29, 18.42s/it]2022-01-16 00:13:02,686 iteration 1956 : loss : 0.072163, loss_ce: 0.019583
2022-01-16 00:13:03,724 iteration 1957 : loss : 0.065171, loss_ce: 0.029919
2022-01-16 00:13:04,768 iteration 1958 : loss : 0.048578, loss_ce: 0.018037
2022-01-16 00:13:05,734 iteration 1959 : loss : 0.049214, loss_ce: 0.019030
2022-01-16 00:13:06,606 iteration 1960 : loss : 0.041065, loss_ce: 0.014873
2022-01-16 00:13:07,579 iteration 1961 : loss : 0.055945, loss_ce: 0.027943
2022-01-16 00:13:08,568 iteration 1962 : loss : 0.046176, loss_ce: 0.020281
2022-01-16 00:13:09,454 iteration 1963 : loss : 0.038597, loss_ce: 0.015183
2022-01-16 00:13:10,342 iteration 1964 : loss : 0.040741, loss_ce: 0.019673
2022-01-16 00:13:11,236 iteration 1965 : loss : 0.047163, loss_ce: 0.019502
2022-01-16 00:13:12,252 iteration 1966 : loss : 0.063822, loss_ce: 0.027680
2022-01-16 00:13:13,274 iteration 1967 : loss : 0.052932, loss_ce: 0.018661
2022-01-16 00:13:14,275 iteration 1968 : loss : 0.053871, loss_ce: 0.032120
2022-01-16 00:13:15,259 iteration 1969 : loss : 0.060354, loss_ce: 0.021474
2022-01-16 00:13:16,189 iteration 1970 : loss : 0.058597, loss_ce: 0.018589
2022-01-16 00:13:17,188 iteration 1971 : loss : 0.054503, loss_ce: 0.022480
2022-01-16 00:13:18,101 iteration 1972 : loss : 0.091476, loss_ce: 0.029436
 29%|████████▍                    | 116/400 [33:39<1:24:16, 17.81s/it]2022-01-16 00:13:18,970 iteration 1973 : loss : 0.041346, loss_ce: 0.016404
2022-01-16 00:13:19,934 iteration 1974 : loss : 0.050746, loss_ce: 0.018709
2022-01-16 00:13:20,868 iteration 1975 : loss : 0.036022, loss_ce: 0.012533
2022-01-16 00:13:21,884 iteration 1976 : loss : 0.036392, loss_ce: 0.014867
2022-01-16 00:13:22,831 iteration 1977 : loss : 0.044277, loss_ce: 0.013401
2022-01-16 00:13:23,690 iteration 1978 : loss : 0.034184, loss_ce: 0.014288
2022-01-16 00:13:24,543 iteration 1979 : loss : 0.036908, loss_ce: 0.013653
2022-01-16 00:13:25,500 iteration 1980 : loss : 0.049577, loss_ce: 0.021638
2022-01-16 00:13:26,397 iteration 1981 : loss : 0.046847, loss_ce: 0.013766
2022-01-16 00:13:27,241 iteration 1982 : loss : 0.059777, loss_ce: 0.021030
2022-01-16 00:13:28,250 iteration 1983 : loss : 0.047487, loss_ce: 0.023293
2022-01-16 00:13:29,117 iteration 1984 : loss : 0.043043, loss_ce: 0.011683
2022-01-16 00:13:30,068 iteration 1985 : loss : 0.031208, loss_ce: 0.011146
2022-01-16 00:13:31,018 iteration 1986 : loss : 0.048973, loss_ce: 0.023593
2022-01-16 00:13:32,017 iteration 1987 : loss : 0.033603, loss_ce: 0.013089
2022-01-16 00:13:32,892 iteration 1988 : loss : 0.045581, loss_ce: 0.013097
2022-01-16 00:13:33,813 iteration 1989 : loss : 0.044991, loss_ce: 0.021941
 29%|████████▍                    | 117/400 [33:54<1:21:02, 17.18s/it]2022-01-16 00:13:34,718 iteration 1990 : loss : 0.033984, loss_ce: 0.014835
2022-01-16 00:13:35,606 iteration 1991 : loss : 0.043456, loss_ce: 0.019141
2022-01-16 00:13:36,577 iteration 1992 : loss : 0.045969, loss_ce: 0.017297
2022-01-16 00:13:37,656 iteration 1993 : loss : 0.042957, loss_ce: 0.021052
2022-01-16 00:13:38,547 iteration 1994 : loss : 0.034944, loss_ce: 0.014554
2022-01-16 00:13:39,484 iteration 1995 : loss : 0.080161, loss_ce: 0.022775
2022-01-16 00:13:40,438 iteration 1996 : loss : 0.050733, loss_ce: 0.014750
2022-01-16 00:13:41,377 iteration 1997 : loss : 0.031694, loss_ce: 0.010816
2022-01-16 00:13:42,320 iteration 1998 : loss : 0.047401, loss_ce: 0.019233
2022-01-16 00:13:43,243 iteration 1999 : loss : 0.049678, loss_ce: 0.020844
2022-01-16 00:13:44,270 iteration 2000 : loss : 0.046216, loss_ce: 0.015690
2022-01-16 00:13:45,198 iteration 2001 : loss : 0.052098, loss_ce: 0.020458
2022-01-16 00:13:46,210 iteration 2002 : loss : 0.044218, loss_ce: 0.020505
2022-01-16 00:13:47,107 iteration 2003 : loss : 0.044609, loss_ce: 0.018732
2022-01-16 00:13:48,069 iteration 2004 : loss : 0.057326, loss_ce: 0.017999
2022-01-16 00:13:49,057 iteration 2005 : loss : 0.054661, loss_ce: 0.020611
2022-01-16 00:13:50,034 iteration 2006 : loss : 0.063141, loss_ce: 0.023981
 30%|████████▌                    | 118/400 [34:10<1:19:23, 16.89s/it]2022-01-16 00:13:51,071 iteration 2007 : loss : 0.046142, loss_ce: 0.020779
2022-01-16 00:13:51,963 iteration 2008 : loss : 0.047738, loss_ce: 0.020391
2022-01-16 00:13:52,884 iteration 2009 : loss : 0.074656, loss_ce: 0.024875
2022-01-16 00:13:53,756 iteration 2010 : loss : 0.050522, loss_ce: 0.020965
2022-01-16 00:13:54,678 iteration 2011 : loss : 0.043764, loss_ce: 0.019801
2022-01-16 00:13:55,637 iteration 2012 : loss : 0.069897, loss_ce: 0.023784
2022-01-16 00:13:56,636 iteration 2013 : loss : 0.055148, loss_ce: 0.023474
2022-01-16 00:13:57,620 iteration 2014 : loss : 0.030832, loss_ce: 0.012266
2022-01-16 00:13:58,491 iteration 2015 : loss : 0.049248, loss_ce: 0.018327
2022-01-16 00:13:59,419 iteration 2016 : loss : 0.050123, loss_ce: 0.017544
2022-01-16 00:14:00,253 iteration 2017 : loss : 0.036044, loss_ce: 0.015171
2022-01-16 00:14:01,193 iteration 2018 : loss : 0.038471, loss_ce: 0.014785
2022-01-16 00:14:02,074 iteration 2019 : loss : 0.038872, loss_ce: 0.017160
2022-01-16 00:14:03,019 iteration 2020 : loss : 0.057760, loss_ce: 0.020392
2022-01-16 00:14:03,995 iteration 2021 : loss : 0.046717, loss_ce: 0.017061
2022-01-16 00:14:05,002 iteration 2022 : loss : 0.061835, loss_ce: 0.028689
2022-01-16 00:14:05,936 iteration 2023 : loss : 0.056829, loss_ce: 0.016301
 30%|████████▋                    | 119/400 [34:26<1:17:42, 16.59s/it]2022-01-16 00:14:06,974 iteration 2024 : loss : 0.049706, loss_ce: 0.020211
2022-01-16 00:14:07,853 iteration 2025 : loss : 0.033666, loss_ce: 0.012026
2022-01-16 00:14:08,749 iteration 2026 : loss : 0.053218, loss_ce: 0.021567
2022-01-16 00:14:09,723 iteration 2027 : loss : 0.052461, loss_ce: 0.017361
2022-01-16 00:14:10,693 iteration 2028 : loss : 0.048450, loss_ce: 0.018626
2022-01-16 00:14:11,561 iteration 2029 : loss : 0.039800, loss_ce: 0.019030
2022-01-16 00:14:12,516 iteration 2030 : loss : 0.053210, loss_ce: 0.018727
2022-01-16 00:14:13,487 iteration 2031 : loss : 0.062046, loss_ce: 0.021020
2022-01-16 00:14:14,464 iteration 2032 : loss : 0.048026, loss_ce: 0.016952
2022-01-16 00:14:15,393 iteration 2033 : loss : 0.060734, loss_ce: 0.017218
2022-01-16 00:14:16,255 iteration 2034 : loss : 0.031943, loss_ce: 0.011004
2022-01-16 00:14:17,116 iteration 2035 : loss : 0.032995, loss_ce: 0.014739
2022-01-16 00:14:18,092 iteration 2036 : loss : 0.035071, loss_ce: 0.014787
2022-01-16 00:14:19,031 iteration 2037 : loss : 0.058151, loss_ce: 0.019736
2022-01-16 00:14:19,923 iteration 2038 : loss : 0.037454, loss_ce: 0.013509
2022-01-16 00:14:20,885 iteration 2039 : loss : 0.043151, loss_ce: 0.018191
2022-01-16 00:14:20,886 Training Data Eval:
2022-01-16 00:14:25,276   Average segmentation loss on training set: 0.0328
2022-01-16 00:14:25,277 Validation Data Eval:
2022-01-16 00:14:26,749   Average segmentation loss on validation set: 0.0849
2022-01-16 00:14:27,649 iteration 2040 : loss : 0.038366, loss_ce: 0.012461
 30%|████████▋                    | 120/400 [34:48<1:24:36, 18.13s/it]2022-01-16 00:14:28,637 iteration 2041 : loss : 0.037441, loss_ce: 0.013905
2022-01-16 00:14:29,556 iteration 2042 : loss : 0.035289, loss_ce: 0.015999
2022-01-16 00:14:30,498 iteration 2043 : loss : 0.042288, loss_ce: 0.019493
2022-01-16 00:14:31,498 iteration 2044 : loss : 0.046071, loss_ce: 0.017447
2022-01-16 00:14:32,525 iteration 2045 : loss : 0.039359, loss_ce: 0.014773
2022-01-16 00:14:33,505 iteration 2046 : loss : 0.053005, loss_ce: 0.019867
2022-01-16 00:14:34,465 iteration 2047 : loss : 0.030783, loss_ce: 0.012032
2022-01-16 00:14:35,324 iteration 2048 : loss : 0.041778, loss_ce: 0.013650
2022-01-16 00:14:36,238 iteration 2049 : loss : 0.033911, loss_ce: 0.012187
2022-01-16 00:14:37,216 iteration 2050 : loss : 0.050639, loss_ce: 0.015499
2022-01-16 00:14:38,201 iteration 2051 : loss : 0.047854, loss_ce: 0.017815
2022-01-16 00:14:39,102 iteration 2052 : loss : 0.034245, loss_ce: 0.017113
2022-01-16 00:14:39,997 iteration 2053 : loss : 0.040503, loss_ce: 0.013825
2022-01-16 00:14:40,946 iteration 2054 : loss : 0.053126, loss_ce: 0.018472
2022-01-16 00:14:41,911 iteration 2055 : loss : 0.058631, loss_ce: 0.026937
2022-01-16 00:14:42,869 iteration 2056 : loss : 0.048764, loss_ce: 0.020900
2022-01-16 00:14:43,845 iteration 2057 : loss : 0.037271, loss_ce: 0.015098
 30%|████████▊                    | 121/400 [35:04<1:21:37, 17.55s/it]2022-01-16 00:14:44,944 iteration 2058 : loss : 0.035495, loss_ce: 0.016961
2022-01-16 00:14:45,927 iteration 2059 : loss : 0.041075, loss_ce: 0.014150
2022-01-16 00:14:46,932 iteration 2060 : loss : 0.078025, loss_ce: 0.032951
2022-01-16 00:14:47,843 iteration 2061 : loss : 0.035268, loss_ce: 0.015382
2022-01-16 00:14:48,713 iteration 2062 : loss : 0.032263, loss_ce: 0.011172
2022-01-16 00:14:49,600 iteration 2063 : loss : 0.029088, loss_ce: 0.012650
2022-01-16 00:14:50,551 iteration 2064 : loss : 0.026235, loss_ce: 0.012565
2022-01-16 00:14:51,509 iteration 2065 : loss : 0.052407, loss_ce: 0.018841
2022-01-16 00:14:52,509 iteration 2066 : loss : 0.043880, loss_ce: 0.016055
2022-01-16 00:14:53,428 iteration 2067 : loss : 0.044319, loss_ce: 0.015779
2022-01-16 00:14:54,438 iteration 2068 : loss : 0.039507, loss_ce: 0.018296
2022-01-16 00:14:55,455 iteration 2069 : loss : 0.055052, loss_ce: 0.014675
2022-01-16 00:14:56,376 iteration 2070 : loss : 0.031629, loss_ce: 0.011425
2022-01-16 00:14:57,299 iteration 2071 : loss : 0.045896, loss_ce: 0.019509
2022-01-16 00:14:58,178 iteration 2072 : loss : 0.039279, loss_ce: 0.017326
2022-01-16 00:14:59,042 iteration 2073 : loss : 0.042279, loss_ce: 0.013818
2022-01-16 00:14:59,984 iteration 2074 : loss : 0.053753, loss_ce: 0.014440
 30%|████████▊                    | 122/400 [35:20<1:19:21, 17.13s/it]2022-01-16 00:15:01,009 iteration 2075 : loss : 0.049955, loss_ce: 0.017380
2022-01-16 00:15:02,020 iteration 2076 : loss : 0.053484, loss_ce: 0.014931
2022-01-16 00:15:02,982 iteration 2077 : loss : 0.036424, loss_ce: 0.013353
2022-01-16 00:15:03,873 iteration 2078 : loss : 0.039549, loss_ce: 0.017560
2022-01-16 00:15:04,785 iteration 2079 : loss : 0.035674, loss_ce: 0.013140
2022-01-16 00:15:05,791 iteration 2080 : loss : 0.039263, loss_ce: 0.013356
2022-01-16 00:15:06,759 iteration 2081 : loss : 0.051188, loss_ce: 0.021145
2022-01-16 00:15:07,701 iteration 2082 : loss : 0.044789, loss_ce: 0.016121
2022-01-16 00:15:08,626 iteration 2083 : loss : 0.034728, loss_ce: 0.012511
2022-01-16 00:15:09,559 iteration 2084 : loss : 0.045772, loss_ce: 0.016007
2022-01-16 00:15:10,457 iteration 2085 : loss : 0.042424, loss_ce: 0.019293
2022-01-16 00:15:11,386 iteration 2086 : loss : 0.040312, loss_ce: 0.017916
2022-01-16 00:15:12,268 iteration 2087 : loss : 0.047713, loss_ce: 0.016469
2022-01-16 00:15:13,327 iteration 2088 : loss : 0.081442, loss_ce: 0.042294
2022-01-16 00:15:14,246 iteration 2089 : loss : 0.033456, loss_ce: 0.011653
2022-01-16 00:15:15,231 iteration 2090 : loss : 0.043937, loss_ce: 0.016542
2022-01-16 00:15:16,168 iteration 2091 : loss : 0.032950, loss_ce: 0.014436
 31%|████████▉                    | 123/400 [35:37<1:17:44, 16.84s/it]2022-01-16 00:15:17,154 iteration 2092 : loss : 0.034540, loss_ce: 0.012931
2022-01-16 00:15:18,197 iteration 2093 : loss : 0.070049, loss_ce: 0.029308
2022-01-16 00:15:19,184 iteration 2094 : loss : 0.033099, loss_ce: 0.016012
2022-01-16 00:15:20,169 iteration 2095 : loss : 0.043825, loss_ce: 0.017899
2022-01-16 00:15:21,180 iteration 2096 : loss : 0.047810, loss_ce: 0.017292
2022-01-16 00:15:22,081 iteration 2097 : loss : 0.046870, loss_ce: 0.024121
2022-01-16 00:15:23,090 iteration 2098 : loss : 0.047646, loss_ce: 0.018592
2022-01-16 00:15:24,087 iteration 2099 : loss : 0.053896, loss_ce: 0.021967
2022-01-16 00:15:25,141 iteration 2100 : loss : 0.048966, loss_ce: 0.019033
2022-01-16 00:15:26,107 iteration 2101 : loss : 0.052683, loss_ce: 0.015648
2022-01-16 00:15:27,022 iteration 2102 : loss : 0.038152, loss_ce: 0.016629
2022-01-16 00:15:28,087 iteration 2103 : loss : 0.057407, loss_ce: 0.027120
2022-01-16 00:15:29,087 iteration 2104 : loss : 0.031676, loss_ce: 0.012592
2022-01-16 00:15:30,009 iteration 2105 : loss : 0.049918, loss_ce: 0.017583
2022-01-16 00:15:31,051 iteration 2106 : loss : 0.056091, loss_ce: 0.019176
2022-01-16 00:15:32,014 iteration 2107 : loss : 0.047767, loss_ce: 0.017543
2022-01-16 00:15:32,994 iteration 2108 : loss : 0.038538, loss_ce: 0.014079
 31%|████████▉                    | 124/400 [35:53<1:17:26, 16.84s/it]2022-01-16 00:15:34,005 iteration 2109 : loss : 0.051444, loss_ce: 0.018173
2022-01-16 00:15:34,941 iteration 2110 : loss : 0.035903, loss_ce: 0.011447
2022-01-16 00:15:36,020 iteration 2111 : loss : 0.063575, loss_ce: 0.021340
2022-01-16 00:15:37,119 iteration 2112 : loss : 0.033284, loss_ce: 0.013927
2022-01-16 00:15:38,041 iteration 2113 : loss : 0.041715, loss_ce: 0.016186
2022-01-16 00:15:38,969 iteration 2114 : loss : 0.040792, loss_ce: 0.017327
2022-01-16 00:15:39,786 iteration 2115 : loss : 0.062901, loss_ce: 0.018228
2022-01-16 00:15:40,752 iteration 2116 : loss : 0.040727, loss_ce: 0.016107
2022-01-16 00:15:41,777 iteration 2117 : loss : 0.036284, loss_ce: 0.011875
2022-01-16 00:15:42,717 iteration 2118 : loss : 0.048501, loss_ce: 0.019634
2022-01-16 00:15:43,698 iteration 2119 : loss : 0.039746, loss_ce: 0.014433
2022-01-16 00:15:44,647 iteration 2120 : loss : 0.058402, loss_ce: 0.022994
2022-01-16 00:15:45,701 iteration 2121 : loss : 0.067566, loss_ce: 0.026578
2022-01-16 00:15:46,597 iteration 2122 : loss : 0.042113, loss_ce: 0.016076
2022-01-16 00:15:47,510 iteration 2123 : loss : 0.049601, loss_ce: 0.027751
2022-01-16 00:15:48,495 iteration 2124 : loss : 0.038665, loss_ce: 0.014004
2022-01-16 00:15:48,495 Training Data Eval:
2022-01-16 00:15:52,881   Average segmentation loss on training set: 0.0304
2022-01-16 00:15:52,882 Validation Data Eval:
2022-01-16 00:15:54,347   Average segmentation loss on validation set: 0.0922
2022-01-16 00:15:55,294 iteration 2125 : loss : 0.027351, loss_ce: 0.009380
 31%|█████████                    | 125/400 [36:16<1:24:41, 18.48s/it]2022-01-16 00:15:56,293 iteration 2126 : loss : 0.028280, loss_ce: 0.010002
2022-01-16 00:15:57,311 iteration 2127 : loss : 0.033815, loss_ce: 0.013290
2022-01-16 00:15:58,203 iteration 2128 : loss : 0.034714, loss_ce: 0.017243
2022-01-16 00:15:59,159 iteration 2129 : loss : 0.038287, loss_ce: 0.014678
2022-01-16 00:16:00,036 iteration 2130 : loss : 0.054479, loss_ce: 0.017499
2022-01-16 00:16:01,068 iteration 2131 : loss : 0.070854, loss_ce: 0.028399
2022-01-16 00:16:02,102 iteration 2132 : loss : 0.045981, loss_ce: 0.017420
2022-01-16 00:16:03,102 iteration 2133 : loss : 0.051123, loss_ce: 0.018401
2022-01-16 00:16:04,107 iteration 2134 : loss : 0.087017, loss_ce: 0.029188
2022-01-16 00:16:05,079 iteration 2135 : loss : 0.053925, loss_ce: 0.017554
2022-01-16 00:16:06,045 iteration 2136 : loss : 0.040361, loss_ce: 0.015023
2022-01-16 00:16:07,000 iteration 2137 : loss : 0.053519, loss_ce: 0.016109
2022-01-16 00:16:07,906 iteration 2138 : loss : 0.054493, loss_ce: 0.017562
2022-01-16 00:16:08,767 iteration 2139 : loss : 0.040174, loss_ce: 0.020268
2022-01-16 00:16:09,677 iteration 2140 : loss : 0.043320, loss_ce: 0.013621
2022-01-16 00:16:10,623 iteration 2141 : loss : 0.043557, loss_ce: 0.017072
2022-01-16 00:16:11,572 iteration 2142 : loss : 0.062224, loss_ce: 0.031819
 32%|█████████▏                   | 126/400 [36:32<1:21:22, 17.82s/it]2022-01-16 00:16:12,619 iteration 2143 : loss : 0.041123, loss_ce: 0.011332
2022-01-16 00:16:13,558 iteration 2144 : loss : 0.041703, loss_ce: 0.014068
2022-01-16 00:16:14,410 iteration 2145 : loss : 0.033357, loss_ce: 0.016777
2022-01-16 00:16:15,513 iteration 2146 : loss : 0.060676, loss_ce: 0.022233
2022-01-16 00:16:16,485 iteration 2147 : loss : 0.051734, loss_ce: 0.019026
2022-01-16 00:16:17,442 iteration 2148 : loss : 0.060699, loss_ce: 0.025982
2022-01-16 00:16:18,416 iteration 2149 : loss : 0.054905, loss_ce: 0.021686
2022-01-16 00:16:19,425 iteration 2150 : loss : 0.044421, loss_ce: 0.014409
2022-01-16 00:16:20,438 iteration 2151 : loss : 0.052896, loss_ce: 0.022713
2022-01-16 00:16:21,322 iteration 2152 : loss : 0.032395, loss_ce: 0.013085
2022-01-16 00:16:22,232 iteration 2153 : loss : 0.043040, loss_ce: 0.011688
2022-01-16 00:16:23,097 iteration 2154 : loss : 0.037731, loss_ce: 0.016570
2022-01-16 00:16:23,993 iteration 2155 : loss : 0.048821, loss_ce: 0.018665
2022-01-16 00:16:24,977 iteration 2156 : loss : 0.066384, loss_ce: 0.024339
2022-01-16 00:16:25,943 iteration 2157 : loss : 0.038158, loss_ce: 0.015345
2022-01-16 00:16:26,863 iteration 2158 : loss : 0.046260, loss_ce: 0.019207
2022-01-16 00:16:27,861 iteration 2159 : loss : 0.063303, loss_ce: 0.018968
 32%|█████████▏                   | 127/400 [36:48<1:18:59, 17.36s/it]2022-01-16 00:16:28,793 iteration 2160 : loss : 0.029988, loss_ce: 0.009968
2022-01-16 00:16:29,763 iteration 2161 : loss : 0.046556, loss_ce: 0.015647
2022-01-16 00:16:30,709 iteration 2162 : loss : 0.034468, loss_ce: 0.013443
2022-01-16 00:16:31,546 iteration 2163 : loss : 0.038244, loss_ce: 0.012110
2022-01-16 00:16:32,499 iteration 2164 : loss : 0.047904, loss_ce: 0.022434
2022-01-16 00:16:33,447 iteration 2165 : loss : 0.026715, loss_ce: 0.008621
2022-01-16 00:16:34,454 iteration 2166 : loss : 0.047840, loss_ce: 0.026390
2022-01-16 00:16:35,403 iteration 2167 : loss : 0.036321, loss_ce: 0.017524
2022-01-16 00:16:36,343 iteration 2168 : loss : 0.035566, loss_ce: 0.012668
2022-01-16 00:16:37,315 iteration 2169 : loss : 0.036870, loss_ce: 0.013693
2022-01-16 00:16:38,225 iteration 2170 : loss : 0.038282, loss_ce: 0.012156
2022-01-16 00:16:39,154 iteration 2171 : loss : 0.023167, loss_ce: 0.007566
2022-01-16 00:16:39,989 iteration 2172 : loss : 0.037234, loss_ce: 0.017594
2022-01-16 00:16:40,924 iteration 2173 : loss : 0.047208, loss_ce: 0.014365
2022-01-16 00:16:41,906 iteration 2174 : loss : 0.040597, loss_ce: 0.017231
2022-01-16 00:16:42,796 iteration 2175 : loss : 0.043943, loss_ce: 0.013385
2022-01-16 00:16:43,703 iteration 2176 : loss : 0.035960, loss_ce: 0.016010
 32%|█████████▎                   | 128/400 [37:04<1:16:36, 16.90s/it]2022-01-16 00:16:44,770 iteration 2177 : loss : 0.056232, loss_ce: 0.019351
2022-01-16 00:16:45,652 iteration 2178 : loss : 0.032328, loss_ce: 0.013160
2022-01-16 00:16:46,583 iteration 2179 : loss : 0.038383, loss_ce: 0.016756
2022-01-16 00:16:47,559 iteration 2180 : loss : 0.031331, loss_ce: 0.009010
2022-01-16 00:16:48,477 iteration 2181 : loss : 0.034595, loss_ce: 0.010792
2022-01-16 00:16:49,399 iteration 2182 : loss : 0.033525, loss_ce: 0.010663
2022-01-16 00:16:50,292 iteration 2183 : loss : 0.050795, loss_ce: 0.016130
2022-01-16 00:16:51,159 iteration 2184 : loss : 0.041692, loss_ce: 0.019197
2022-01-16 00:16:51,999 iteration 2185 : loss : 0.036507, loss_ce: 0.014383
2022-01-16 00:16:53,058 iteration 2186 : loss : 0.052009, loss_ce: 0.021245
2022-01-16 00:16:53,924 iteration 2187 : loss : 0.040617, loss_ce: 0.021932
2022-01-16 00:16:54,900 iteration 2188 : loss : 0.048822, loss_ce: 0.019224
2022-01-16 00:16:55,789 iteration 2189 : loss : 0.042014, loss_ce: 0.016018
2022-01-16 00:16:56,780 iteration 2190 : loss : 0.043045, loss_ce: 0.015543
2022-01-16 00:16:57,636 iteration 2191 : loss : 0.032258, loss_ce: 0.013420
2022-01-16 00:16:58,568 iteration 2192 : loss : 0.043408, loss_ce: 0.017130
2022-01-16 00:16:59,581 iteration 2193 : loss : 0.044367, loss_ce: 0.019130
 32%|█████████▎                   | 129/400 [37:20<1:14:58, 16.60s/it]2022-01-16 00:17:00,554 iteration 2194 : loss : 0.039162, loss_ce: 0.016770
2022-01-16 00:17:01,450 iteration 2195 : loss : 0.042921, loss_ce: 0.014761
2022-01-16 00:17:02,401 iteration 2196 : loss : 0.033191, loss_ce: 0.014012
2022-01-16 00:17:03,383 iteration 2197 : loss : 0.062927, loss_ce: 0.020897
2022-01-16 00:17:04,293 iteration 2198 : loss : 0.028830, loss_ce: 0.013675
2022-01-16 00:17:05,401 iteration 2199 : loss : 0.040168, loss_ce: 0.017903
2022-01-16 00:17:06,342 iteration 2200 : loss : 0.037384, loss_ce: 0.013536
2022-01-16 00:17:07,291 iteration 2201 : loss : 0.047022, loss_ce: 0.014739
2022-01-16 00:17:08,220 iteration 2202 : loss : 0.049238, loss_ce: 0.012885
2022-01-16 00:17:09,204 iteration 2203 : loss : 0.034994, loss_ce: 0.011794
2022-01-16 00:17:10,200 iteration 2204 : loss : 0.034794, loss_ce: 0.011821
2022-01-16 00:17:11,024 iteration 2205 : loss : 0.039139, loss_ce: 0.016245
2022-01-16 00:17:11,882 iteration 2206 : loss : 0.031843, loss_ce: 0.015067
2022-01-16 00:17:12,819 iteration 2207 : loss : 0.046625, loss_ce: 0.017970
2022-01-16 00:17:13,741 iteration 2208 : loss : 0.028087, loss_ce: 0.011879
2022-01-16 00:17:14,749 iteration 2209 : loss : 0.036934, loss_ce: 0.012308
2022-01-16 00:17:14,749 Training Data Eval:
2022-01-16 00:17:19,141   Average segmentation loss on training set: 0.0273
2022-01-16 00:17:19,141 Validation Data Eval:
2022-01-16 00:17:20,592   Average segmentation loss on validation set: 0.0876
2022-01-16 00:17:21,540 iteration 2210 : loss : 0.032710, loss_ce: 0.011085
 32%|█████████▍                   | 130/400 [37:42<1:21:55, 18.20s/it]2022-01-16 00:17:22,551 iteration 2211 : loss : 0.039746, loss_ce: 0.018845
2022-01-16 00:17:23,403 iteration 2212 : loss : 0.030740, loss_ce: 0.009807
2022-01-16 00:17:24,281 iteration 2213 : loss : 0.031371, loss_ce: 0.010887
2022-01-16 00:17:25,230 iteration 2214 : loss : 0.028243, loss_ce: 0.011071
2022-01-16 00:17:26,147 iteration 2215 : loss : 0.039826, loss_ce: 0.012833
2022-01-16 00:17:27,031 iteration 2216 : loss : 0.037163, loss_ce: 0.015241
2022-01-16 00:17:27,884 iteration 2217 : loss : 0.036767, loss_ce: 0.016589
2022-01-16 00:17:28,825 iteration 2218 : loss : 0.046504, loss_ce: 0.017255
2022-01-16 00:17:29,737 iteration 2219 : loss : 0.033161, loss_ce: 0.013820
2022-01-16 00:17:30,688 iteration 2220 : loss : 0.029570, loss_ce: 0.015516
2022-01-16 00:17:31,695 iteration 2221 : loss : 0.038726, loss_ce: 0.016579
2022-01-16 00:17:32,593 iteration 2222 : loss : 0.062420, loss_ce: 0.019469
2022-01-16 00:17:33,660 iteration 2223 : loss : 0.047966, loss_ce: 0.016934
2022-01-16 00:17:34,565 iteration 2224 : loss : 0.062525, loss_ce: 0.015411
2022-01-16 00:17:35,489 iteration 2225 : loss : 0.033963, loss_ce: 0.012643
2022-01-16 00:17:36,573 iteration 2226 : loss : 0.035567, loss_ce: 0.013317
2022-01-16 00:17:37,577 iteration 2227 : loss : 0.044274, loss_ce: 0.016627
 33%|█████████▍                   | 131/400 [37:58<1:18:42, 17.55s/it]2022-01-16 00:17:38,635 iteration 2228 : loss : 0.068785, loss_ce: 0.026427
2022-01-16 00:17:39,606 iteration 2229 : loss : 0.044305, loss_ce: 0.019504
2022-01-16 00:17:40,515 iteration 2230 : loss : 0.044990, loss_ce: 0.016796
2022-01-16 00:17:41,397 iteration 2231 : loss : 0.025216, loss_ce: 0.011193
2022-01-16 00:17:42,276 iteration 2232 : loss : 0.030756, loss_ce: 0.010162
2022-01-16 00:17:43,165 iteration 2233 : loss : 0.034076, loss_ce: 0.011097
2022-01-16 00:17:44,127 iteration 2234 : loss : 0.058036, loss_ce: 0.021394
2022-01-16 00:17:44,993 iteration 2235 : loss : 0.044246, loss_ce: 0.021664
2022-01-16 00:17:45,883 iteration 2236 : loss : 0.033614, loss_ce: 0.012589
2022-01-16 00:17:46,807 iteration 2237 : loss : 0.040319, loss_ce: 0.016873
2022-01-16 00:17:47,707 iteration 2238 : loss : 0.056425, loss_ce: 0.018402
2022-01-16 00:17:48,667 iteration 2239 : loss : 0.033505, loss_ce: 0.011253
2022-01-16 00:17:49,522 iteration 2240 : loss : 0.029084, loss_ce: 0.011142
2022-01-16 00:17:50,488 iteration 2241 : loss : 0.035183, loss_ce: 0.013996
2022-01-16 00:17:51,361 iteration 2242 : loss : 0.040094, loss_ce: 0.017165
2022-01-16 00:17:52,230 iteration 2243 : loss : 0.035510, loss_ce: 0.012588
2022-01-16 00:17:53,142 iteration 2244 : loss : 0.030979, loss_ce: 0.012946
 33%|█████████▌                   | 132/400 [38:14<1:15:44, 16.96s/it]2022-01-16 00:17:54,103 iteration 2245 : loss : 0.028094, loss_ce: 0.011034
2022-01-16 00:17:55,061 iteration 2246 : loss : 0.055518, loss_ce: 0.027853
2022-01-16 00:17:55,992 iteration 2247 : loss : 0.038309, loss_ce: 0.015869
2022-01-16 00:17:56,819 iteration 2248 : loss : 0.027125, loss_ce: 0.011082
2022-01-16 00:17:57,815 iteration 2249 : loss : 0.046318, loss_ce: 0.017457
2022-01-16 00:17:58,883 iteration 2250 : loss : 0.041747, loss_ce: 0.017901
2022-01-16 00:17:59,739 iteration 2251 : loss : 0.056319, loss_ce: 0.023520
2022-01-16 00:18:00,695 iteration 2252 : loss : 0.039148, loss_ce: 0.015356
2022-01-16 00:18:01,576 iteration 2253 : loss : 0.056993, loss_ce: 0.019644
2022-01-16 00:18:02,571 iteration 2254 : loss : 0.059948, loss_ce: 0.025641
2022-01-16 00:18:03,557 iteration 2255 : loss : 0.033434, loss_ce: 0.015265
2022-01-16 00:18:04,591 iteration 2256 : loss : 0.055032, loss_ce: 0.020404
2022-01-16 00:18:05,507 iteration 2257 : loss : 0.056143, loss_ce: 0.015971
2022-01-16 00:18:06,436 iteration 2258 : loss : 0.054562, loss_ce: 0.026379
2022-01-16 00:18:07,417 iteration 2259 : loss : 0.047741, loss_ce: 0.016889
2022-01-16 00:18:08,370 iteration 2260 : loss : 0.053834, loss_ce: 0.019148
2022-01-16 00:18:09,259 iteration 2261 : loss : 0.050094, loss_ce: 0.010634
 33%|█████████▋                   | 133/400 [38:30<1:14:21, 16.71s/it]2022-01-16 00:18:10,396 iteration 2262 : loss : 0.040393, loss_ce: 0.015714
2022-01-16 00:18:11,354 iteration 2263 : loss : 0.040100, loss_ce: 0.015712
2022-01-16 00:18:12,329 iteration 2264 : loss : 0.040247, loss_ce: 0.012362
2022-01-16 00:18:13,303 iteration 2265 : loss : 0.032569, loss_ce: 0.013336
2022-01-16 00:18:14,233 iteration 2266 : loss : 0.041949, loss_ce: 0.014187
2022-01-16 00:18:15,180 iteration 2267 : loss : 0.043621, loss_ce: 0.016995
2022-01-16 00:18:16,034 iteration 2268 : loss : 0.048421, loss_ce: 0.017526
2022-01-16 00:18:16,991 iteration 2269 : loss : 0.043441, loss_ce: 0.017948
2022-01-16 00:18:17,874 iteration 2270 : loss : 0.040670, loss_ce: 0.016803
2022-01-16 00:18:18,772 iteration 2271 : loss : 0.053271, loss_ce: 0.029190
2022-01-16 00:18:19,645 iteration 2272 : loss : 0.040084, loss_ce: 0.011482
2022-01-16 00:18:20,625 iteration 2273 : loss : 0.043344, loss_ce: 0.012616
2022-01-16 00:18:21,493 iteration 2274 : loss : 0.035089, loss_ce: 0.011332
2022-01-16 00:18:22,403 iteration 2275 : loss : 0.036187, loss_ce: 0.016387
2022-01-16 00:18:23,347 iteration 2276 : loss : 0.050696, loss_ce: 0.014763
2022-01-16 00:18:24,251 iteration 2277 : loss : 0.041347, loss_ce: 0.018161
2022-01-16 00:18:25,182 iteration 2278 : loss : 0.034034, loss_ce: 0.014634
 34%|█████████▋                   | 134/400 [38:46<1:13:01, 16.47s/it]2022-01-16 00:18:26,285 iteration 2279 : loss : 0.054674, loss_ce: 0.030265
2022-01-16 00:18:27,256 iteration 2280 : loss : 0.030939, loss_ce: 0.013817
2022-01-16 00:18:28,111 iteration 2281 : loss : 0.034068, loss_ce: 0.013801
2022-01-16 00:18:29,167 iteration 2282 : loss : 0.048302, loss_ce: 0.018616
2022-01-16 00:18:30,061 iteration 2283 : loss : 0.036345, loss_ce: 0.013419
2022-01-16 00:18:31,105 iteration 2284 : loss : 0.063744, loss_ce: 0.021922
2022-01-16 00:18:31,996 iteration 2285 : loss : 0.034973, loss_ce: 0.012697
2022-01-16 00:18:32,907 iteration 2286 : loss : 0.033667, loss_ce: 0.010855
2022-01-16 00:18:33,892 iteration 2287 : loss : 0.040825, loss_ce: 0.010028
2022-01-16 00:18:34,748 iteration 2288 : loss : 0.044100, loss_ce: 0.015889
2022-01-16 00:18:35,704 iteration 2289 : loss : 0.035953, loss_ce: 0.012377
2022-01-16 00:18:36,646 iteration 2290 : loss : 0.036307, loss_ce: 0.014097
2022-01-16 00:18:37,560 iteration 2291 : loss : 0.037395, loss_ce: 0.014067
2022-01-16 00:18:38,565 iteration 2292 : loss : 0.048576, loss_ce: 0.014266
2022-01-16 00:18:39,426 iteration 2293 : loss : 0.058957, loss_ce: 0.027780
2022-01-16 00:18:40,336 iteration 2294 : loss : 0.037964, loss_ce: 0.016727
2022-01-16 00:18:40,336 Training Data Eval:
2022-01-16 00:18:44,730   Average segmentation loss on training set: 0.0292
2022-01-16 00:18:44,730 Validation Data Eval:
2022-01-16 00:18:46,193   Average segmentation loss on validation set: 0.1013
2022-01-16 00:18:47,121 iteration 2295 : loss : 0.031418, loss_ce: 0.012168
 34%|█████████▊                   | 135/400 [39:08<1:19:59, 18.11s/it]2022-01-16 00:18:48,117 iteration 2296 : loss : 0.036537, loss_ce: 0.013666
2022-01-16 00:18:49,056 iteration 2297 : loss : 0.044817, loss_ce: 0.011871
2022-01-16 00:18:50,116 iteration 2298 : loss : 0.055944, loss_ce: 0.019742
2022-01-16 00:18:51,040 iteration 2299 : loss : 0.037156, loss_ce: 0.010758
2022-01-16 00:18:52,066 iteration 2300 : loss : 0.045885, loss_ce: 0.016747
2022-01-16 00:18:52,989 iteration 2301 : loss : 0.036169, loss_ce: 0.016698
2022-01-16 00:18:53,905 iteration 2302 : loss : 0.052364, loss_ce: 0.026073
2022-01-16 00:18:54,794 iteration 2303 : loss : 0.049198, loss_ce: 0.016663
2022-01-16 00:18:55,632 iteration 2304 : loss : 0.061465, loss_ce: 0.028384
2022-01-16 00:18:56,599 iteration 2305 : loss : 0.048591, loss_ce: 0.015239
2022-01-16 00:18:57,480 iteration 2306 : loss : 0.044083, loss_ce: 0.017528
2022-01-16 00:18:58,344 iteration 2307 : loss : 0.034821, loss_ce: 0.013932
2022-01-16 00:18:59,241 iteration 2308 : loss : 0.047456, loss_ce: 0.025158
2022-01-16 00:19:00,199 iteration 2309 : loss : 0.044536, loss_ce: 0.017511
2022-01-16 00:19:01,159 iteration 2310 : loss : 0.046704, loss_ce: 0.021036
2022-01-16 00:19:02,195 iteration 2311 : loss : 0.039443, loss_ce: 0.014779
2022-01-16 00:19:03,142 iteration 2312 : loss : 0.055840, loss_ce: 0.031120
 34%|█████████▊                   | 136/400 [39:24<1:16:55, 17.48s/it]2022-01-16 00:19:04,137 iteration 2313 : loss : 0.040148, loss_ce: 0.018711
2022-01-16 00:19:05,019 iteration 2314 : loss : 0.044992, loss_ce: 0.019464
2022-01-16 00:19:05,961 iteration 2315 : loss : 0.031795, loss_ce: 0.011843
2022-01-16 00:19:06,935 iteration 2316 : loss : 0.037254, loss_ce: 0.016111
2022-01-16 00:19:07,787 iteration 2317 : loss : 0.059407, loss_ce: 0.027451
2022-01-16 00:19:08,795 iteration 2318 : loss : 0.033237, loss_ce: 0.015297
2022-01-16 00:19:09,825 iteration 2319 : loss : 0.046292, loss_ce: 0.014781
2022-01-16 00:19:10,710 iteration 2320 : loss : 0.043832, loss_ce: 0.020204
2022-01-16 00:19:11,642 iteration 2321 : loss : 0.044885, loss_ce: 0.015743
2022-01-16 00:19:12,595 iteration 2322 : loss : 0.037177, loss_ce: 0.019973
2022-01-16 00:19:13,609 iteration 2323 : loss : 0.047664, loss_ce: 0.013513
2022-01-16 00:19:14,566 iteration 2324 : loss : 0.043990, loss_ce: 0.013108
2022-01-16 00:19:15,501 iteration 2325 : loss : 0.048107, loss_ce: 0.025501
2022-01-16 00:19:16,484 iteration 2326 : loss : 0.042031, loss_ce: 0.023520
2022-01-16 00:19:17,404 iteration 2327 : loss : 0.036577, loss_ce: 0.013230
2022-01-16 00:19:18,441 iteration 2328 : loss : 0.034976, loss_ce: 0.011823
2022-01-16 00:19:19,370 iteration 2329 : loss : 0.063689, loss_ce: 0.020517
 34%|█████████▉                   | 137/400 [39:40<1:14:59, 17.11s/it]2022-01-16 00:19:20,353 iteration 2330 : loss : 0.030738, loss_ce: 0.012642
2022-01-16 00:19:21,233 iteration 2331 : loss : 0.045656, loss_ce: 0.012709
2022-01-16 00:19:22,256 iteration 2332 : loss : 0.038186, loss_ce: 0.018526
2022-01-16 00:19:23,127 iteration 2333 : loss : 0.031046, loss_ce: 0.016784
2022-01-16 00:19:24,050 iteration 2334 : loss : 0.048329, loss_ce: 0.012148
2022-01-16 00:19:25,105 iteration 2335 : loss : 0.044081, loss_ce: 0.019648
2022-01-16 00:19:26,007 iteration 2336 : loss : 0.041748, loss_ce: 0.019447
2022-01-16 00:19:26,943 iteration 2337 : loss : 0.040239, loss_ce: 0.013560
2022-01-16 00:19:27,921 iteration 2338 : loss : 0.041056, loss_ce: 0.015556
2022-01-16 00:19:28,858 iteration 2339 : loss : 0.050428, loss_ce: 0.016909
2022-01-16 00:19:29,836 iteration 2340 : loss : 0.044812, loss_ce: 0.018044
2022-01-16 00:19:30,781 iteration 2341 : loss : 0.038456, loss_ce: 0.014121
2022-01-16 00:19:31,748 iteration 2342 : loss : 0.024053, loss_ce: 0.008202
2022-01-16 00:19:32,693 iteration 2343 : loss : 0.032526, loss_ce: 0.010529
2022-01-16 00:19:33,541 iteration 2344 : loss : 0.030650, loss_ce: 0.010351
2022-01-16 00:19:34,430 iteration 2345 : loss : 0.032685, loss_ce: 0.012843
2022-01-16 00:19:35,283 iteration 2346 : loss : 0.041122, loss_ce: 0.014126
 34%|██████████                   | 138/400 [39:56<1:13:07, 16.75s/it]2022-01-16 00:19:36,318 iteration 2347 : loss : 0.040439, loss_ce: 0.014704
2022-01-16 00:19:37,227 iteration 2348 : loss : 0.038909, loss_ce: 0.012631
2022-01-16 00:19:38,185 iteration 2349 : loss : 0.055935, loss_ce: 0.033767
2022-01-16 00:19:39,038 iteration 2350 : loss : 0.039264, loss_ce: 0.022058
2022-01-16 00:19:39,995 iteration 2351 : loss : 0.053172, loss_ce: 0.017826
2022-01-16 00:19:41,031 iteration 2352 : loss : 0.046001, loss_ce: 0.023246
2022-01-16 00:19:41,880 iteration 2353 : loss : 0.031362, loss_ce: 0.013853
2022-01-16 00:19:42,830 iteration 2354 : loss : 0.053837, loss_ce: 0.016455
2022-01-16 00:19:43,706 iteration 2355 : loss : 0.044744, loss_ce: 0.020483
2022-01-16 00:19:44,742 iteration 2356 : loss : 0.035627, loss_ce: 0.013003
2022-01-16 00:19:45,752 iteration 2357 : loss : 0.040684, loss_ce: 0.017813
2022-01-16 00:19:46,784 iteration 2358 : loss : 0.059850, loss_ce: 0.026375
2022-01-16 00:19:47,782 iteration 2359 : loss : 0.045252, loss_ce: 0.011776
2022-01-16 00:19:48,615 iteration 2360 : loss : 0.076452, loss_ce: 0.015576
2022-01-16 00:19:49,479 iteration 2361 : loss : 0.031412, loss_ce: 0.011468
2022-01-16 00:19:50,411 iteration 2362 : loss : 0.044247, loss_ce: 0.017591
2022-01-16 00:19:51,346 iteration 2363 : loss : 0.039076, loss_ce: 0.013207
 35%|██████████                   | 139/400 [40:12<1:11:58, 16.55s/it]2022-01-16 00:19:52,354 iteration 2364 : loss : 0.074404, loss_ce: 0.035919
2022-01-16 00:19:53,223 iteration 2365 : loss : 0.044701, loss_ce: 0.015196
2022-01-16 00:19:54,181 iteration 2366 : loss : 0.042572, loss_ce: 0.018471
2022-01-16 00:19:55,088 iteration 2367 : loss : 0.071468, loss_ce: 0.020678
2022-01-16 00:19:56,121 iteration 2368 : loss : 0.046124, loss_ce: 0.012782
2022-01-16 00:19:57,046 iteration 2369 : loss : 0.050793, loss_ce: 0.017219
2022-01-16 00:19:57,936 iteration 2370 : loss : 0.032151, loss_ce: 0.009968
2022-01-16 00:19:58,883 iteration 2371 : loss : 0.043338, loss_ce: 0.016440
2022-01-16 00:19:59,748 iteration 2372 : loss : 0.033812, loss_ce: 0.017223
2022-01-16 00:20:00,694 iteration 2373 : loss : 0.027642, loss_ce: 0.010119
2022-01-16 00:20:01,684 iteration 2374 : loss : 0.035782, loss_ce: 0.013729
2022-01-16 00:20:02,558 iteration 2375 : loss : 0.049165, loss_ce: 0.017055
2022-01-16 00:20:03,547 iteration 2376 : loss : 0.051018, loss_ce: 0.026229
2022-01-16 00:20:04,476 iteration 2377 : loss : 0.031528, loss_ce: 0.007386
2022-01-16 00:20:05,522 iteration 2378 : loss : 0.046963, loss_ce: 0.026665
2022-01-16 00:20:06,498 iteration 2379 : loss : 0.047025, loss_ce: 0.014991
2022-01-16 00:20:06,498 Training Data Eval:
2022-01-16 00:20:10,883   Average segmentation loss on training set: 0.0269
2022-01-16 00:20:10,883 Validation Data Eval:
2022-01-16 00:20:12,344   Average segmentation loss on validation set: 0.1052
2022-01-16 00:20:13,409 iteration 2380 : loss : 0.034965, loss_ce: 0.013218
 35%|██████████▏                  | 140/400 [40:34<1:18:50, 18.19s/it]2022-01-16 00:20:14,356 iteration 2381 : loss : 0.047838, loss_ce: 0.015181
2022-01-16 00:20:15,350 iteration 2382 : loss : 0.042902, loss_ce: 0.019406
2022-01-16 00:20:16,347 iteration 2383 : loss : 0.057414, loss_ce: 0.018675
2022-01-16 00:20:17,287 iteration 2384 : loss : 0.034242, loss_ce: 0.011210
2022-01-16 00:20:18,248 iteration 2385 : loss : 0.040782, loss_ce: 0.019176
2022-01-16 00:20:19,287 iteration 2386 : loss : 0.077855, loss_ce: 0.028005
2022-01-16 00:20:20,196 iteration 2387 : loss : 0.045926, loss_ce: 0.016910
2022-01-16 00:20:21,158 iteration 2388 : loss : 0.025892, loss_ce: 0.010137
2022-01-16 00:20:22,041 iteration 2389 : loss : 0.044075, loss_ce: 0.017864
2022-01-16 00:20:22,988 iteration 2390 : loss : 0.026479, loss_ce: 0.011474
2022-01-16 00:20:23,882 iteration 2391 : loss : 0.035683, loss_ce: 0.012586
2022-01-16 00:20:24,747 iteration 2392 : loss : 0.035461, loss_ce: 0.014538
2022-01-16 00:20:25,624 iteration 2393 : loss : 0.042390, loss_ce: 0.021055
2022-01-16 00:20:26,570 iteration 2394 : loss : 0.095538, loss_ce: 0.024628
2022-01-16 00:20:27,658 iteration 2395 : loss : 0.042814, loss_ce: 0.014806
2022-01-16 00:20:28,687 iteration 2396 : loss : 0.027534, loss_ce: 0.010778
2022-01-16 00:20:29,635 iteration 2397 : loss : 0.051916, loss_ce: 0.020158
 35%|██████████▏                  | 141/400 [40:50<1:16:00, 17.61s/it]2022-01-16 00:20:30,768 iteration 2398 : loss : 0.048865, loss_ce: 0.025227
2022-01-16 00:20:31,636 iteration 2399 : loss : 0.036908, loss_ce: 0.014497
2022-01-16 00:20:32,553 iteration 2400 : loss : 0.033407, loss_ce: 0.008960
2022-01-16 00:20:33,494 iteration 2401 : loss : 0.041596, loss_ce: 0.015782
2022-01-16 00:20:34,403 iteration 2402 : loss : 0.037479, loss_ce: 0.015139
2022-01-16 00:20:35,335 iteration 2403 : loss : 0.029208, loss_ce: 0.010858
2022-01-16 00:20:36,235 iteration 2404 : loss : 0.040282, loss_ce: 0.020058
2022-01-16 00:20:37,166 iteration 2405 : loss : 0.032604, loss_ce: 0.012135
2022-01-16 00:20:38,176 iteration 2406 : loss : 0.043840, loss_ce: 0.020659
2022-01-16 00:20:39,058 iteration 2407 : loss : 0.041298, loss_ce: 0.013892
2022-01-16 00:20:39,988 iteration 2408 : loss : 0.039376, loss_ce: 0.017373
2022-01-16 00:20:40,935 iteration 2409 : loss : 0.040500, loss_ce: 0.015087
2022-01-16 00:20:41,915 iteration 2410 : loss : 0.064381, loss_ce: 0.015692
2022-01-16 00:20:42,797 iteration 2411 : loss : 0.034081, loss_ce: 0.012213
2022-01-16 00:20:43,803 iteration 2412 : loss : 0.050966, loss_ce: 0.019108
2022-01-16 00:20:44,842 iteration 2413 : loss : 0.035738, loss_ce: 0.018320
2022-01-16 00:20:45,840 iteration 2414 : loss : 0.041052, loss_ce: 0.015094
 36%|██████████▎                  | 142/400 [41:06<1:13:53, 17.18s/it]2022-01-16 00:20:46,864 iteration 2415 : loss : 0.036851, loss_ce: 0.013230
2022-01-16 00:20:47,805 iteration 2416 : loss : 0.046403, loss_ce: 0.021397
2022-01-16 00:20:48,764 iteration 2417 : loss : 0.041830, loss_ce: 0.012565
2022-01-16 00:20:49,737 iteration 2418 : loss : 0.048402, loss_ce: 0.014633
2022-01-16 00:20:50,678 iteration 2419 : loss : 0.045508, loss_ce: 0.021226
2022-01-16 00:20:51,562 iteration 2420 : loss : 0.031241, loss_ce: 0.012206
2022-01-16 00:20:52,621 iteration 2421 : loss : 0.042161, loss_ce: 0.011557
2022-01-16 00:20:53,606 iteration 2422 : loss : 0.048527, loss_ce: 0.015432
2022-01-16 00:20:54,568 iteration 2423 : loss : 0.038047, loss_ce: 0.015340
2022-01-16 00:20:55,443 iteration 2424 : loss : 0.035956, loss_ce: 0.011740
2022-01-16 00:20:56,471 iteration 2425 : loss : 0.032430, loss_ce: 0.015478
2022-01-16 00:20:57,413 iteration 2426 : loss : 0.028878, loss_ce: 0.010636
2022-01-16 00:20:58,469 iteration 2427 : loss : 0.052600, loss_ce: 0.015291
2022-01-16 00:20:59,504 iteration 2428 : loss : 0.052840, loss_ce: 0.027486
2022-01-16 00:21:00,553 iteration 2429 : loss : 0.041345, loss_ce: 0.016834
2022-01-16 00:21:01,521 iteration 2430 : loss : 0.041367, loss_ce: 0.018276
2022-01-16 00:21:02,424 iteration 2431 : loss : 0.030002, loss_ce: 0.014066
 36%|██████████▎                  | 143/400 [41:23<1:12:51, 17.01s/it]2022-01-16 00:21:03,480 iteration 2432 : loss : 0.032415, loss_ce: 0.014474
2022-01-16 00:21:04,440 iteration 2433 : loss : 0.050428, loss_ce: 0.019696
2022-01-16 00:21:05,393 iteration 2434 : loss : 0.028059, loss_ce: 0.007792
2022-01-16 00:21:06,474 iteration 2435 : loss : 0.034594, loss_ce: 0.018490
2022-01-16 00:21:07,318 iteration 2436 : loss : 0.034687, loss_ce: 0.011926
2022-01-16 00:21:08,189 iteration 2437 : loss : 0.033130, loss_ce: 0.014157
2022-01-16 00:21:09,279 iteration 2438 : loss : 0.037467, loss_ce: 0.014417
2022-01-16 00:21:10,247 iteration 2439 : loss : 0.035702, loss_ce: 0.014242
2022-01-16 00:21:11,172 iteration 2440 : loss : 0.033885, loss_ce: 0.010770
2022-01-16 00:21:12,083 iteration 2441 : loss : 0.046790, loss_ce: 0.012702
2022-01-16 00:21:12,974 iteration 2442 : loss : 0.039364, loss_ce: 0.013216
2022-01-16 00:21:13,834 iteration 2443 : loss : 0.030367, loss_ce: 0.013681
2022-01-16 00:21:14,812 iteration 2444 : loss : 0.028175, loss_ce: 0.010610
2022-01-16 00:21:15,647 iteration 2445 : loss : 0.058835, loss_ce: 0.013048
2022-01-16 00:21:16,694 iteration 2446 : loss : 0.044069, loss_ce: 0.016351
2022-01-16 00:21:17,721 iteration 2447 : loss : 0.053285, loss_ce: 0.024921
2022-01-16 00:21:18,678 iteration 2448 : loss : 0.046464, loss_ce: 0.016919
 36%|██████████▍                  | 144/400 [41:39<1:11:36, 16.78s/it]2022-01-16 00:21:19,659 iteration 2449 : loss : 0.044819, loss_ce: 0.018455
2022-01-16 00:21:20,680 iteration 2450 : loss : 0.050032, loss_ce: 0.018333
2022-01-16 00:21:21,698 iteration 2451 : loss : 0.039153, loss_ce: 0.015234
2022-01-16 00:21:22,564 iteration 2452 : loss : 0.025487, loss_ce: 0.011220
2022-01-16 00:21:23,490 iteration 2453 : loss : 0.061727, loss_ce: 0.021569
2022-01-16 00:21:24,464 iteration 2454 : loss : 0.037553, loss_ce: 0.017352
2022-01-16 00:21:25,434 iteration 2455 : loss : 0.048993, loss_ce: 0.023608
2022-01-16 00:21:26,531 iteration 2456 : loss : 0.098390, loss_ce: 0.041856
2022-01-16 00:21:27,482 iteration 2457 : loss : 0.049069, loss_ce: 0.017285
2022-01-16 00:21:28,513 iteration 2458 : loss : 0.042473, loss_ce: 0.014147
2022-01-16 00:21:29,412 iteration 2459 : loss : 0.044000, loss_ce: 0.014687
2022-01-16 00:21:30,349 iteration 2460 : loss : 0.037391, loss_ce: 0.011391
2022-01-16 00:21:31,314 iteration 2461 : loss : 0.047700, loss_ce: 0.016691
2022-01-16 00:21:32,235 iteration 2462 : loss : 0.028123, loss_ce: 0.012480
2022-01-16 00:21:33,207 iteration 2463 : loss : 0.027760, loss_ce: 0.010107
2022-01-16 00:21:34,239 iteration 2464 : loss : 0.044244, loss_ce: 0.021651
2022-01-16 00:21:34,239 Training Data Eval:
2022-01-16 00:21:38,628   Average segmentation loss on training set: 0.0349
2022-01-16 00:21:38,628 Validation Data Eval:
2022-01-16 00:21:40,087   Average segmentation loss on validation set: 0.1529
2022-01-16 00:21:40,985 iteration 2465 : loss : 0.034490, loss_ce: 0.011870
 36%|██████████▌                  | 145/400 [42:01<1:18:21, 18.44s/it]2022-01-16 00:21:41,956 iteration 2466 : loss : 0.035183, loss_ce: 0.014013
2022-01-16 00:21:42,948 iteration 2467 : loss : 0.044235, loss_ce: 0.027312
2022-01-16 00:21:43,843 iteration 2468 : loss : 0.029732, loss_ce: 0.012791
2022-01-16 00:21:44,698 iteration 2469 : loss : 0.024713, loss_ce: 0.012151
2022-01-16 00:21:45,679 iteration 2470 : loss : 0.043554, loss_ce: 0.017188
2022-01-16 00:21:46,670 iteration 2471 : loss : 0.058051, loss_ce: 0.023625
2022-01-16 00:21:47,716 iteration 2472 : loss : 0.041721, loss_ce: 0.016458
2022-01-16 00:21:48,582 iteration 2473 : loss : 0.038790, loss_ce: 0.017049
2022-01-16 00:21:49,555 iteration 2474 : loss : 0.040202, loss_ce: 0.013872
2022-01-16 00:21:50,429 iteration 2475 : loss : 0.028373, loss_ce: 0.011505
2022-01-16 00:21:51,452 iteration 2476 : loss : 0.050967, loss_ce: 0.013603
2022-01-16 00:21:52,384 iteration 2477 : loss : 0.025709, loss_ce: 0.009792
2022-01-16 00:21:53,308 iteration 2478 : loss : 0.052053, loss_ce: 0.013424
2022-01-16 00:21:54,379 iteration 2479 : loss : 0.030761, loss_ce: 0.009003
2022-01-16 00:21:55,402 iteration 2480 : loss : 0.050864, loss_ce: 0.018785
2022-01-16 00:21:56,321 iteration 2481 : loss : 0.031575, loss_ce: 0.012375
2022-01-16 00:21:57,272 iteration 2482 : loss : 0.042339, loss_ce: 0.014408
 36%|██████████▌                  | 146/400 [42:18<1:15:19, 17.80s/it]2022-01-16 00:21:58,294 iteration 2483 : loss : 0.038661, loss_ce: 0.015865
2022-01-16 00:21:59,310 iteration 2484 : loss : 0.063736, loss_ce: 0.016633
2022-01-16 00:22:00,380 iteration 2485 : loss : 0.048542, loss_ce: 0.017990
2022-01-16 00:22:01,272 iteration 2486 : loss : 0.035697, loss_ce: 0.015954
2022-01-16 00:22:02,191 iteration 2487 : loss : 0.036252, loss_ce: 0.012396
2022-01-16 00:22:03,195 iteration 2488 : loss : 0.028029, loss_ce: 0.009020
2022-01-16 00:22:04,207 iteration 2489 : loss : 0.038272, loss_ce: 0.015144
2022-01-16 00:22:05,121 iteration 2490 : loss : 0.035787, loss_ce: 0.013650
2022-01-16 00:22:06,079 iteration 2491 : loss : 0.045757, loss_ce: 0.016626
2022-01-16 00:22:06,976 iteration 2492 : loss : 0.042560, loss_ce: 0.014240
2022-01-16 00:22:07,896 iteration 2493 : loss : 0.036054, loss_ce: 0.010602
2022-01-16 00:22:08,777 iteration 2494 : loss : 0.033871, loss_ce: 0.013629
2022-01-16 00:22:09,703 iteration 2495 : loss : 0.050856, loss_ce: 0.015520
2022-01-16 00:22:10,695 iteration 2496 : loss : 0.041855, loss_ce: 0.012584
2022-01-16 00:22:11,632 iteration 2497 : loss : 0.045994, loss_ce: 0.018729
2022-01-16 00:22:12,487 iteration 2498 : loss : 0.039240, loss_ce: 0.017247
2022-01-16 00:22:13,501 iteration 2499 : loss : 0.044765, loss_ce: 0.018692
 37%|██████████▋                  | 147/400 [42:34<1:13:01, 17.32s/it]2022-01-16 00:22:14,538 iteration 2500 : loss : 0.046825, loss_ce: 0.015901
2022-01-16 00:22:15,424 iteration 2501 : loss : 0.039395, loss_ce: 0.014197
2022-01-16 00:22:16,351 iteration 2502 : loss : 0.032015, loss_ce: 0.011834
2022-01-16 00:22:17,306 iteration 2503 : loss : 0.037449, loss_ce: 0.018845
2022-01-16 00:22:18,281 iteration 2504 : loss : 0.036850, loss_ce: 0.012518
2022-01-16 00:22:19,153 iteration 2505 : loss : 0.028132, loss_ce: 0.013856
2022-01-16 00:22:20,050 iteration 2506 : loss : 0.048225, loss_ce: 0.012270
2022-01-16 00:22:21,029 iteration 2507 : loss : 0.027698, loss_ce: 0.009309
2022-01-16 00:22:21,945 iteration 2508 : loss : 0.035094, loss_ce: 0.016638
2022-01-16 00:22:22,944 iteration 2509 : loss : 0.053423, loss_ce: 0.020865
2022-01-16 00:22:23,862 iteration 2510 : loss : 0.044012, loss_ce: 0.015481
2022-01-16 00:22:24,735 iteration 2511 : loss : 0.031390, loss_ce: 0.014303
2022-01-16 00:22:25,731 iteration 2512 : loss : 0.035226, loss_ce: 0.011757
2022-01-16 00:22:26,633 iteration 2513 : loss : 0.038496, loss_ce: 0.016267
2022-01-16 00:22:27,615 iteration 2514 : loss : 0.042867, loss_ce: 0.014751
2022-01-16 00:22:28,526 iteration 2515 : loss : 0.031208, loss_ce: 0.015680
2022-01-16 00:22:29,643 iteration 2516 : loss : 0.045535, loss_ce: 0.016297
 37%|██████████▋                  | 148/400 [42:50<1:11:16, 16.97s/it]2022-01-16 00:22:30,681 iteration 2517 : loss : 0.040894, loss_ce: 0.012422
2022-01-16 00:22:31,674 iteration 2518 : loss : 0.039600, loss_ce: 0.012188
2022-01-16 00:22:32,546 iteration 2519 : loss : 0.022299, loss_ce: 0.007375
2022-01-16 00:22:33,532 iteration 2520 : loss : 0.047461, loss_ce: 0.023593
2022-01-16 00:22:34,498 iteration 2521 : loss : 0.035766, loss_ce: 0.016907
2022-01-16 00:22:35,469 iteration 2522 : loss : 0.054330, loss_ce: 0.019250
2022-01-16 00:22:36,419 iteration 2523 : loss : 0.055306, loss_ce: 0.017180
2022-01-16 00:22:37,420 iteration 2524 : loss : 0.028486, loss_ce: 0.012079
2022-01-16 00:22:38,340 iteration 2525 : loss : 0.028418, loss_ce: 0.008785
2022-01-16 00:22:39,221 iteration 2526 : loss : 0.036675, loss_ce: 0.012761
2022-01-16 00:22:40,191 iteration 2527 : loss : 0.060866, loss_ce: 0.030877
2022-01-16 00:22:41,128 iteration 2528 : loss : 0.038349, loss_ce: 0.017273
2022-01-16 00:22:42,109 iteration 2529 : loss : 0.037686, loss_ce: 0.014091
2022-01-16 00:22:42,976 iteration 2530 : loss : 0.031580, loss_ce: 0.011693
2022-01-16 00:22:43,939 iteration 2531 : loss : 0.038128, loss_ce: 0.013140
2022-01-16 00:22:44,980 iteration 2532 : loss : 0.037746, loss_ce: 0.017638
2022-01-16 00:22:45,857 iteration 2533 : loss : 0.079409, loss_ce: 0.023695
 37%|██████████▊                  | 149/400 [43:06<1:10:01, 16.74s/it]2022-01-16 00:22:46,876 iteration 2534 : loss : 0.041814, loss_ce: 0.018358
2022-01-16 00:22:47,716 iteration 2535 : loss : 0.038627, loss_ce: 0.015357
2022-01-16 00:22:48,603 iteration 2536 : loss : 0.024132, loss_ce: 0.010867
2022-01-16 00:22:49,646 iteration 2537 : loss : 0.047412, loss_ce: 0.024563
2022-01-16 00:22:50,446 iteration 2538 : loss : 0.032345, loss_ce: 0.011080
2022-01-16 00:22:51,302 iteration 2539 : loss : 0.041474, loss_ce: 0.026173
2022-01-16 00:22:52,226 iteration 2540 : loss : 0.049596, loss_ce: 0.022361
2022-01-16 00:22:53,242 iteration 2541 : loss : 0.040518, loss_ce: 0.018531
2022-01-16 00:22:54,180 iteration 2542 : loss : 0.046669, loss_ce: 0.015735
2022-01-16 00:22:55,215 iteration 2543 : loss : 0.056140, loss_ce: 0.018276
2022-01-16 00:22:56,252 iteration 2544 : loss : 0.041407, loss_ce: 0.017261
2022-01-16 00:22:57,146 iteration 2545 : loss : 0.038382, loss_ce: 0.017862
2022-01-16 00:22:58,292 iteration 2546 : loss : 0.054789, loss_ce: 0.018693
2022-01-16 00:22:59,306 iteration 2547 : loss : 0.055284, loss_ce: 0.020910
2022-01-16 00:23:00,343 iteration 2548 : loss : 0.033121, loss_ce: 0.013300
2022-01-16 00:23:01,283 iteration 2549 : loss : 0.041976, loss_ce: 0.014303
2022-01-16 00:23:01,284 Training Data Eval:
2022-01-16 00:23:05,667   Average segmentation loss on training set: 0.0277
2022-01-16 00:23:05,667 Validation Data Eval:
2022-01-16 00:23:07,116   Average segmentation loss on validation set: 0.0775
2022-01-16 00:23:08,043 iteration 2550 : loss : 0.051368, loss_ce: 0.013540
 38%|██████████▉                  | 150/400 [43:28<1:16:33, 18.38s/it]2022-01-16 00:23:09,050 iteration 2551 : loss : 0.033541, loss_ce: 0.011538
2022-01-16 00:23:10,012 iteration 2552 : loss : 0.032381, loss_ce: 0.013671
2022-01-16 00:23:10,968 iteration 2553 : loss : 0.030682, loss_ce: 0.011131
2022-01-16 00:23:11,896 iteration 2554 : loss : 0.039362, loss_ce: 0.015104
2022-01-16 00:23:12,803 iteration 2555 : loss : 0.041207, loss_ce: 0.017400
2022-01-16 00:23:13,747 iteration 2556 : loss : 0.037917, loss_ce: 0.017818
2022-01-16 00:23:14,678 iteration 2557 : loss : 0.038354, loss_ce: 0.014782
2022-01-16 00:23:15,587 iteration 2558 : loss : 0.029957, loss_ce: 0.010252
2022-01-16 00:23:16,458 iteration 2559 : loss : 0.041263, loss_ce: 0.020782
2022-01-16 00:23:17,501 iteration 2560 : loss : 0.035682, loss_ce: 0.011698
2022-01-16 00:23:18,441 iteration 2561 : loss : 0.049691, loss_ce: 0.017302
2022-01-16 00:23:19,406 iteration 2562 : loss : 0.038483, loss_ce: 0.016171
2022-01-16 00:23:20,266 iteration 2563 : loss : 0.037405, loss_ce: 0.014914
2022-01-16 00:23:21,147 iteration 2564 : loss : 0.029819, loss_ce: 0.012700
2022-01-16 00:23:22,029 iteration 2565 : loss : 0.023328, loss_ce: 0.009191
2022-01-16 00:23:22,874 iteration 2566 : loss : 0.029106, loss_ce: 0.011235
2022-01-16 00:23:23,785 iteration 2567 : loss : 0.047017, loss_ce: 0.012490
 38%|██████████▉                  | 151/400 [43:44<1:12:59, 17.59s/it]2022-01-16 00:23:24,767 iteration 2568 : loss : 0.035401, loss_ce: 0.013057
2022-01-16 00:23:25,689 iteration 2569 : loss : 0.026729, loss_ce: 0.010434
2022-01-16 00:23:26,722 iteration 2570 : loss : 0.035664, loss_ce: 0.011827
2022-01-16 00:23:27,652 iteration 2571 : loss : 0.036312, loss_ce: 0.010766
2022-01-16 00:23:28,509 iteration 2572 : loss : 0.047013, loss_ce: 0.014349
2022-01-16 00:23:29,416 iteration 2573 : loss : 0.029532, loss_ce: 0.011131
2022-01-16 00:23:30,299 iteration 2574 : loss : 0.035218, loss_ce: 0.015596
2022-01-16 00:23:31,151 iteration 2575 : loss : 0.030041, loss_ce: 0.010345
2022-01-16 00:23:32,012 iteration 2576 : loss : 0.028061, loss_ce: 0.007977
2022-01-16 00:23:32,979 iteration 2577 : loss : 0.043607, loss_ce: 0.023226
2022-01-16 00:23:33,880 iteration 2578 : loss : 0.047142, loss_ce: 0.018122
2022-01-16 00:23:34,823 iteration 2579 : loss : 0.051187, loss_ce: 0.018560
2022-01-16 00:23:35,702 iteration 2580 : loss : 0.031351, loss_ce: 0.010194
2022-01-16 00:23:36,659 iteration 2581 : loss : 0.045965, loss_ce: 0.019113
2022-01-16 00:23:37,664 iteration 2582 : loss : 0.024966, loss_ce: 0.011294
2022-01-16 00:23:38,565 iteration 2583 : loss : 0.031017, loss_ce: 0.014061
2022-01-16 00:23:39,471 iteration 2584 : loss : 0.042385, loss_ce: 0.014391
 38%|███████████                  | 152/400 [44:00<1:10:20, 17.02s/it]2022-01-16 00:23:40,476 iteration 2585 : loss : 0.029325, loss_ce: 0.010577
2022-01-16 00:23:41,609 iteration 2586 : loss : 0.061418, loss_ce: 0.020729
2022-01-16 00:23:42,634 iteration 2587 : loss : 0.047573, loss_ce: 0.015299
2022-01-16 00:23:43,583 iteration 2588 : loss : 0.042381, loss_ce: 0.016241
2022-01-16 00:23:44,440 iteration 2589 : loss : 0.042230, loss_ce: 0.011990
2022-01-16 00:23:45,425 iteration 2590 : loss : 0.046694, loss_ce: 0.017971
2022-01-16 00:23:46,362 iteration 2591 : loss : 0.024669, loss_ce: 0.010555
2022-01-16 00:23:47,249 iteration 2592 : loss : 0.025610, loss_ce: 0.012360
2022-01-16 00:23:48,074 iteration 2593 : loss : 0.037849, loss_ce: 0.016907
2022-01-16 00:23:49,005 iteration 2594 : loss : 0.051964, loss_ce: 0.022261
2022-01-16 00:23:49,875 iteration 2595 : loss : 0.032688, loss_ce: 0.010314
2022-01-16 00:23:50,771 iteration 2596 : loss : 0.053779, loss_ce: 0.015301
2022-01-16 00:23:51,685 iteration 2597 : loss : 0.030981, loss_ce: 0.011765
2022-01-16 00:23:52,626 iteration 2598 : loss : 0.036004, loss_ce: 0.014623
2022-01-16 00:23:53,569 iteration 2599 : loss : 0.027170, loss_ce: 0.010903
2022-01-16 00:23:54,464 iteration 2600 : loss : 0.033525, loss_ce: 0.014416
2022-01-16 00:23:55,330 iteration 2601 : loss : 0.032659, loss_ce: 0.012752
 38%|███████████                  | 153/400 [44:16<1:08:37, 16.67s/it]2022-01-16 00:23:56,303 iteration 2602 : loss : 0.039846, loss_ce: 0.014125
2022-01-16 00:23:57,248 iteration 2603 : loss : 0.059312, loss_ce: 0.017715
2022-01-16 00:23:58,186 iteration 2604 : loss : 0.029481, loss_ce: 0.010864
2022-01-16 00:23:59,122 iteration 2605 : loss : 0.043393, loss_ce: 0.012737
2022-01-16 00:24:00,066 iteration 2606 : loss : 0.033225, loss_ce: 0.012443
2022-01-16 00:24:01,023 iteration 2607 : loss : 0.060666, loss_ce: 0.030018
2022-01-16 00:24:01,909 iteration 2608 : loss : 0.033245, loss_ce: 0.012695
2022-01-16 00:24:02,897 iteration 2609 : loss : 0.033547, loss_ce: 0.015633
2022-01-16 00:24:03,869 iteration 2610 : loss : 0.038638, loss_ce: 0.013508
2022-01-16 00:24:04,872 iteration 2611 : loss : 0.050597, loss_ce: 0.022617
2022-01-16 00:24:05,851 iteration 2612 : loss : 0.041626, loss_ce: 0.014524
2022-01-16 00:24:06,869 iteration 2613 : loss : 0.033766, loss_ce: 0.013999
2022-01-16 00:24:07,863 iteration 2614 : loss : 0.036663, loss_ce: 0.015032
2022-01-16 00:24:08,825 iteration 2615 : loss : 0.037675, loss_ce: 0.017118
2022-01-16 00:24:09,830 iteration 2616 : loss : 0.059769, loss_ce: 0.024520
2022-01-16 00:24:10,790 iteration 2617 : loss : 0.037535, loss_ce: 0.013151
2022-01-16 00:24:11,781 iteration 2618 : loss : 0.030686, loss_ce: 0.009045
 38%|███████████▏                 | 154/400 [44:32<1:08:04, 16.61s/it]2022-01-16 00:24:12,932 iteration 2619 : loss : 0.043393, loss_ce: 0.017481
2022-01-16 00:24:13,910 iteration 2620 : loss : 0.042693, loss_ce: 0.015052
2022-01-16 00:24:14,740 iteration 2621 : loss : 0.035803, loss_ce: 0.013546
2022-01-16 00:24:15,706 iteration 2622 : loss : 0.064949, loss_ce: 0.022817
2022-01-16 00:24:16,599 iteration 2623 : loss : 0.026502, loss_ce: 0.010419
2022-01-16 00:24:17,598 iteration 2624 : loss : 0.046598, loss_ce: 0.016871
2022-01-16 00:24:18,603 iteration 2625 : loss : 0.033572, loss_ce: 0.014112
2022-01-16 00:24:19,579 iteration 2626 : loss : 0.030538, loss_ce: 0.012161
2022-01-16 00:24:20,443 iteration 2627 : loss : 0.031529, loss_ce: 0.016824
2022-01-16 00:24:21,324 iteration 2628 : loss : 0.029515, loss_ce: 0.011222
2022-01-16 00:24:22,165 iteration 2629 : loss : 0.035966, loss_ce: 0.009616
2022-01-16 00:24:23,132 iteration 2630 : loss : 0.088464, loss_ce: 0.020696
2022-01-16 00:24:23,995 iteration 2631 : loss : 0.044171, loss_ce: 0.021111
2022-01-16 00:24:24,867 iteration 2632 : loss : 0.032710, loss_ce: 0.011564
2022-01-16 00:24:25,816 iteration 2633 : loss : 0.025404, loss_ce: 0.008882
2022-01-16 00:24:26,726 iteration 2634 : loss : 0.029401, loss_ce: 0.009566
2022-01-16 00:24:26,726 Training Data Eval:
2022-01-16 00:24:31,106   Average segmentation loss on training set: 0.0285
2022-01-16 00:24:31,106 Validation Data Eval:
2022-01-16 00:24:32,555   Average segmentation loss on validation set: 0.1065
2022-01-16 00:24:33,446 iteration 2635 : loss : 0.040796, loss_ce: 0.016262
 39%|███████████▏                 | 155/400 [44:54<1:13:59, 18.12s/it]2022-01-16 00:24:34,383 iteration 2636 : loss : 0.029436, loss_ce: 0.009173
2022-01-16 00:24:35,288 iteration 2637 : loss : 0.035464, loss_ce: 0.015725
2022-01-16 00:24:36,315 iteration 2638 : loss : 0.056037, loss_ce: 0.019629
2022-01-16 00:24:37,243 iteration 2639 : loss : 0.033999, loss_ce: 0.012698
2022-01-16 00:24:38,193 iteration 2640 : loss : 0.045893, loss_ce: 0.015190
2022-01-16 00:24:39,115 iteration 2641 : loss : 0.040738, loss_ce: 0.016181
2022-01-16 00:24:40,081 iteration 2642 : loss : 0.031965, loss_ce: 0.010111
2022-01-16 00:24:40,999 iteration 2643 : loss : 0.045502, loss_ce: 0.021909
2022-01-16 00:24:41,959 iteration 2644 : loss : 0.046956, loss_ce: 0.024141
2022-01-16 00:24:42,830 iteration 2645 : loss : 0.032312, loss_ce: 0.013735
2022-01-16 00:24:43,717 iteration 2646 : loss : 0.030546, loss_ce: 0.009086
2022-01-16 00:24:44,723 iteration 2647 : loss : 0.057798, loss_ce: 0.025383
2022-01-16 00:24:45,624 iteration 2648 : loss : 0.034052, loss_ce: 0.012083
2022-01-16 00:24:46,561 iteration 2649 : loss : 0.043963, loss_ce: 0.015875
2022-01-16 00:24:47,621 iteration 2650 : loss : 0.035436, loss_ce: 0.013547
2022-01-16 00:24:48,534 iteration 2651 : loss : 0.032265, loss_ce: 0.012582
2022-01-16 00:24:49,545 iteration 2652 : loss : 0.028952, loss_ce: 0.011572
 39%|███████████▎                 | 156/400 [45:10<1:11:13, 17.51s/it]2022-01-16 00:24:50,606 iteration 2653 : loss : 0.046118, loss_ce: 0.016440
2022-01-16 00:24:51,472 iteration 2654 : loss : 0.024002, loss_ce: 0.009783
2022-01-16 00:24:52,383 iteration 2655 : loss : 0.032472, loss_ce: 0.013470
2022-01-16 00:24:53,288 iteration 2656 : loss : 0.029404, loss_ce: 0.014850
2022-01-16 00:24:54,247 iteration 2657 : loss : 0.031250, loss_ce: 0.012333
2022-01-16 00:24:55,246 iteration 2658 : loss : 0.049064, loss_ce: 0.016745
2022-01-16 00:24:56,210 iteration 2659 : loss : 0.042573, loss_ce: 0.016664
2022-01-16 00:24:57,242 iteration 2660 : loss : 0.037584, loss_ce: 0.016180
2022-01-16 00:24:58,083 iteration 2661 : loss : 0.032309, loss_ce: 0.010517
2022-01-16 00:24:59,088 iteration 2662 : loss : 0.043378, loss_ce: 0.016825
2022-01-16 00:25:00,073 iteration 2663 : loss : 0.062805, loss_ce: 0.023917
2022-01-16 00:25:00,935 iteration 2664 : loss : 0.044168, loss_ce: 0.015812
2022-01-16 00:25:01,833 iteration 2665 : loss : 0.019981, loss_ce: 0.008048
2022-01-16 00:25:02,851 iteration 2666 : loss : 0.043951, loss_ce: 0.015895
2022-01-16 00:25:03,737 iteration 2667 : loss : 0.043389, loss_ce: 0.017271
2022-01-16 00:25:04,744 iteration 2668 : loss : 0.039183, loss_ce: 0.015366
2022-01-16 00:25:05,659 iteration 2669 : loss : 0.038932, loss_ce: 0.011512
 39%|███████████▍                 | 157/400 [45:26<1:09:14, 17.10s/it]2022-01-16 00:25:06,581 iteration 2670 : loss : 0.030574, loss_ce: 0.012547
2022-01-16 00:25:07,429 iteration 2671 : loss : 0.046902, loss_ce: 0.019058
2022-01-16 00:25:08,326 iteration 2672 : loss : 0.054154, loss_ce: 0.017380
2022-01-16 00:25:09,218 iteration 2673 : loss : 0.035738, loss_ce: 0.010962
2022-01-16 00:25:10,175 iteration 2674 : loss : 0.042210, loss_ce: 0.013706
2022-01-16 00:25:11,163 iteration 2675 : loss : 0.028207, loss_ce: 0.010559
2022-01-16 00:25:12,079 iteration 2676 : loss : 0.025831, loss_ce: 0.009367
2022-01-16 00:25:12,999 iteration 2677 : loss : 0.029585, loss_ce: 0.011582
2022-01-16 00:25:13,864 iteration 2678 : loss : 0.032374, loss_ce: 0.015780
2022-01-16 00:25:14,803 iteration 2679 : loss : 0.037759, loss_ce: 0.014937
2022-01-16 00:25:15,809 iteration 2680 : loss : 0.040280, loss_ce: 0.018182
2022-01-16 00:25:16,745 iteration 2681 : loss : 0.035030, loss_ce: 0.012077
2022-01-16 00:25:17,725 iteration 2682 : loss : 0.026906, loss_ce: 0.011195
2022-01-16 00:25:18,626 iteration 2683 : loss : 0.042278, loss_ce: 0.018442
2022-01-16 00:25:19,578 iteration 2684 : loss : 0.033986, loss_ce: 0.014570
2022-01-16 00:25:20,559 iteration 2685 : loss : 0.036699, loss_ce: 0.015301
2022-01-16 00:25:21,541 iteration 2686 : loss : 0.079644, loss_ce: 0.015526
 40%|███████████▍                 | 158/400 [45:42<1:07:29, 16.73s/it]2022-01-16 00:25:22,509 iteration 2687 : loss : 0.046642, loss_ce: 0.020530
2022-01-16 00:25:23,415 iteration 2688 : loss : 0.028692, loss_ce: 0.011167
2022-01-16 00:25:24,300 iteration 2689 : loss : 0.055728, loss_ce: 0.018958
2022-01-16 00:25:25,281 iteration 2690 : loss : 0.096527, loss_ce: 0.025166
2022-01-16 00:25:26,155 iteration 2691 : loss : 0.022284, loss_ce: 0.008786
2022-01-16 00:25:27,041 iteration 2692 : loss : 0.030939, loss_ce: 0.011821
2022-01-16 00:25:27,919 iteration 2693 : loss : 0.038849, loss_ce: 0.014767
2022-01-16 00:25:28,870 iteration 2694 : loss : 0.036129, loss_ce: 0.013247
2022-01-16 00:25:29,793 iteration 2695 : loss : 0.068444, loss_ce: 0.039255
2022-01-16 00:25:30,713 iteration 2696 : loss : 0.045140, loss_ce: 0.022319
2022-01-16 00:25:31,603 iteration 2697 : loss : 0.050889, loss_ce: 0.021463
2022-01-16 00:25:32,490 iteration 2698 : loss : 0.035458, loss_ce: 0.010180
2022-01-16 00:25:33,397 iteration 2699 : loss : 0.037804, loss_ce: 0.016549
2022-01-16 00:25:34,283 iteration 2700 : loss : 0.044274, loss_ce: 0.014533
2022-01-16 00:25:35,337 iteration 2701 : loss : 0.038798, loss_ce: 0.011142
2022-01-16 00:25:36,318 iteration 2702 : loss : 0.039365, loss_ce: 0.018775
2022-01-16 00:25:37,327 iteration 2703 : loss : 0.036708, loss_ce: 0.014271
 40%|███████████▌                 | 159/400 [45:58<1:06:04, 16.45s/it]2022-01-16 00:25:38,410 iteration 2704 : loss : 0.049636, loss_ce: 0.016237
2022-01-16 00:25:39,301 iteration 2705 : loss : 0.029945, loss_ce: 0.014316
2022-01-16 00:25:40,284 iteration 2706 : loss : 0.077682, loss_ce: 0.031724
2022-01-16 00:25:41,202 iteration 2707 : loss : 0.030951, loss_ce: 0.015213
2022-01-16 00:25:42,172 iteration 2708 : loss : 0.034655, loss_ce: 0.013990
2022-01-16 00:25:43,097 iteration 2709 : loss : 0.033438, loss_ce: 0.013550
2022-01-16 00:25:43,959 iteration 2710 : loss : 0.027034, loss_ce: 0.011399
2022-01-16 00:25:44,916 iteration 2711 : loss : 0.032619, loss_ce: 0.011197
2022-01-16 00:25:45,887 iteration 2712 : loss : 0.032932, loss_ce: 0.010864
2022-01-16 00:25:46,770 iteration 2713 : loss : 0.037220, loss_ce: 0.017769
2022-01-16 00:25:47,774 iteration 2714 : loss : 0.043618, loss_ce: 0.018971
2022-01-16 00:25:48,758 iteration 2715 : loss : 0.041759, loss_ce: 0.014265
2022-01-16 00:25:49,744 iteration 2716 : loss : 0.041537, loss_ce: 0.013451
2022-01-16 00:25:50,669 iteration 2717 : loss : 0.038364, loss_ce: 0.014862
2022-01-16 00:25:51,649 iteration 2718 : loss : 0.055694, loss_ce: 0.020936
2022-01-16 00:25:52,563 iteration 2719 : loss : 0.035724, loss_ce: 0.013545
2022-01-16 00:25:52,563 Training Data Eval:
2022-01-16 00:25:56,947   Average segmentation loss on training set: 0.0225
2022-01-16 00:25:56,947 Validation Data Eval:
2022-01-16 00:25:58,400   Average segmentation loss on validation set: 0.0746
2022-01-16 00:25:59,272 iteration 2720 : loss : 0.026291, loss_ce: 0.008829
 40%|███████████▌                 | 160/400 [46:20<1:12:22, 18.09s/it]2022-01-16 00:26:00,299 iteration 2721 : loss : 0.028306, loss_ce: 0.012396
2022-01-16 00:26:01,249 iteration 2722 : loss : 0.038521, loss_ce: 0.015810
2022-01-16 00:26:02,223 iteration 2723 : loss : 0.027538, loss_ce: 0.009624
2022-01-16 00:26:03,174 iteration 2724 : loss : 0.043724, loss_ce: 0.016051
2022-01-16 00:26:04,091 iteration 2725 : loss : 0.033604, loss_ce: 0.011299
2022-01-16 00:26:05,183 iteration 2726 : loss : 0.055036, loss_ce: 0.017013
2022-01-16 00:26:06,186 iteration 2727 : loss : 0.040336, loss_ce: 0.016350
2022-01-16 00:26:07,127 iteration 2728 : loss : 0.036966, loss_ce: 0.014201
2022-01-16 00:26:08,055 iteration 2729 : loss : 0.049779, loss_ce: 0.019707
2022-01-16 00:26:08,920 iteration 2730 : loss : 0.034492, loss_ce: 0.012103
2022-01-16 00:26:09,868 iteration 2731 : loss : 0.031977, loss_ce: 0.012035
2022-01-16 00:26:10,876 iteration 2732 : loss : 0.039567, loss_ce: 0.018003
2022-01-16 00:26:11,837 iteration 2733 : loss : 0.030365, loss_ce: 0.011012
2022-01-16 00:26:12,783 iteration 2734 : loss : 0.036395, loss_ce: 0.011881
2022-01-16 00:26:13,828 iteration 2735 : loss : 0.036889, loss_ce: 0.011028
2022-01-16 00:26:14,757 iteration 2736 : loss : 0.026319, loss_ce: 0.011475
2022-01-16 00:26:15,736 iteration 2737 : loss : 0.044696, loss_ce: 0.018833
 40%|███████████▋                 | 161/400 [46:36<1:10:07, 17.61s/it]2022-01-16 00:26:16,678 iteration 2738 : loss : 0.022607, loss_ce: 0.008769
2022-01-16 00:26:17,691 iteration 2739 : loss : 0.039891, loss_ce: 0.014902
2022-01-16 00:26:18,725 iteration 2740 : loss : 0.038783, loss_ce: 0.015260
2022-01-16 00:26:19,634 iteration 2741 : loss : 0.027568, loss_ce: 0.009776
2022-01-16 00:26:20,498 iteration 2742 : loss : 0.040602, loss_ce: 0.012184
2022-01-16 00:26:21,459 iteration 2743 : loss : 0.032327, loss_ce: 0.011560
2022-01-16 00:26:22,547 iteration 2744 : loss : 0.055732, loss_ce: 0.020749
2022-01-16 00:26:23,480 iteration 2745 : loss : 0.027050, loss_ce: 0.008819
2022-01-16 00:26:24,398 iteration 2746 : loss : 0.029667, loss_ce: 0.010823
2022-01-16 00:26:25,448 iteration 2747 : loss : 0.043148, loss_ce: 0.015978
2022-01-16 00:26:26,355 iteration 2748 : loss : 0.035239, loss_ce: 0.012848
2022-01-16 00:26:27,312 iteration 2749 : loss : 0.030949, loss_ce: 0.014064
2022-01-16 00:26:28,230 iteration 2750 : loss : 0.039229, loss_ce: 0.012692
2022-01-16 00:26:29,145 iteration 2751 : loss : 0.050368, loss_ce: 0.014346
2022-01-16 00:26:30,039 iteration 2752 : loss : 0.038506, loss_ce: 0.017709
2022-01-16 00:26:30,954 iteration 2753 : loss : 0.051830, loss_ce: 0.024950
2022-01-16 00:26:31,906 iteration 2754 : loss : 0.049839, loss_ce: 0.017620
 40%|███████████▋                 | 162/400 [46:52<1:08:07, 17.18s/it]2022-01-16 00:26:32,911 iteration 2755 : loss : 0.029631, loss_ce: 0.011082
2022-01-16 00:26:33,866 iteration 2756 : loss : 0.038327, loss_ce: 0.017864
2022-01-16 00:26:34,759 iteration 2757 : loss : 0.026911, loss_ce: 0.010303
2022-01-16 00:26:35,683 iteration 2758 : loss : 0.051172, loss_ce: 0.021553
2022-01-16 00:26:36,605 iteration 2759 : loss : 0.028578, loss_ce: 0.011079
2022-01-16 00:26:37,588 iteration 2760 : loss : 0.049137, loss_ce: 0.011416
2022-01-16 00:26:38,524 iteration 2761 : loss : 0.030348, loss_ce: 0.011803
2022-01-16 00:26:39,448 iteration 2762 : loss : 0.037416, loss_ce: 0.013243
2022-01-16 00:26:40,370 iteration 2763 : loss : 0.036109, loss_ce: 0.015292
2022-01-16 00:26:41,233 iteration 2764 : loss : 0.036156, loss_ce: 0.016088
2022-01-16 00:26:42,160 iteration 2765 : loss : 0.041731, loss_ce: 0.016873
2022-01-16 00:26:43,155 iteration 2766 : loss : 0.036262, loss_ce: 0.012687
2022-01-16 00:26:44,021 iteration 2767 : loss : 0.033234, loss_ce: 0.008591
2022-01-16 00:26:45,083 iteration 2768 : loss : 0.027813, loss_ce: 0.012063
2022-01-16 00:26:46,005 iteration 2769 : loss : 0.030128, loss_ce: 0.010329
2022-01-16 00:26:46,877 iteration 2770 : loss : 0.030276, loss_ce: 0.014431
2022-01-16 00:26:47,798 iteration 2771 : loss : 0.034203, loss_ce: 0.016192
 41%|███████████▊                 | 163/400 [47:08<1:06:19, 16.79s/it]2022-01-16 00:26:48,874 iteration 2772 : loss : 0.042480, loss_ce: 0.013646
2022-01-16 00:26:49,739 iteration 2773 : loss : 0.035027, loss_ce: 0.014113
2022-01-16 00:26:50,643 iteration 2774 : loss : 0.031045, loss_ce: 0.013348
2022-01-16 00:26:51,580 iteration 2775 : loss : 0.032446, loss_ce: 0.012584
2022-01-16 00:26:52,523 iteration 2776 : loss : 0.041251, loss_ce: 0.016999
2022-01-16 00:26:53,503 iteration 2777 : loss : 0.041954, loss_ce: 0.016407
2022-01-16 00:26:54,355 iteration 2778 : loss : 0.029022, loss_ce: 0.011918
2022-01-16 00:26:55,332 iteration 2779 : loss : 0.037745, loss_ce: 0.015969
2022-01-16 00:26:56,355 iteration 2780 : loss : 0.038357, loss_ce: 0.016729
2022-01-16 00:26:57,206 iteration 2781 : loss : 0.033882, loss_ce: 0.013626
2022-01-16 00:26:58,172 iteration 2782 : loss : 0.031950, loss_ce: 0.012899
2022-01-16 00:26:59,185 iteration 2783 : loss : 0.031630, loss_ce: 0.011461
2022-01-16 00:27:00,239 iteration 2784 : loss : 0.043203, loss_ce: 0.020747
2022-01-16 00:27:01,112 iteration 2785 : loss : 0.027414, loss_ce: 0.008870
2022-01-16 00:27:02,070 iteration 2786 : loss : 0.036908, loss_ce: 0.011612
2022-01-16 00:27:03,102 iteration 2787 : loss : 0.052057, loss_ce: 0.012269
2022-01-16 00:27:04,064 iteration 2788 : loss : 0.031835, loss_ce: 0.009225
 41%|███████████▉                 | 164/400 [47:25<1:05:24, 16.63s/it]2022-01-16 00:27:05,080 iteration 2789 : loss : 0.028355, loss_ce: 0.013202
2022-01-16 00:27:05,989 iteration 2790 : loss : 0.043339, loss_ce: 0.013499
2022-01-16 00:27:06,948 iteration 2791 : loss : 0.032319, loss_ce: 0.009273
2022-01-16 00:27:07,949 iteration 2792 : loss : 0.041984, loss_ce: 0.010248
2022-01-16 00:27:08,901 iteration 2793 : loss : 0.052969, loss_ce: 0.027611
2022-01-16 00:27:09,862 iteration 2794 : loss : 0.034222, loss_ce: 0.013162
2022-01-16 00:27:10,875 iteration 2795 : loss : 0.045065, loss_ce: 0.019180
2022-01-16 00:27:11,930 iteration 2796 : loss : 0.052174, loss_ce: 0.021703
2022-01-16 00:27:12,923 iteration 2797 : loss : 0.045016, loss_ce: 0.019407
2022-01-16 00:27:13,964 iteration 2798 : loss : 0.043261, loss_ce: 0.013083
2022-01-16 00:27:14,969 iteration 2799 : loss : 0.045131, loss_ce: 0.016017
2022-01-16 00:27:15,951 iteration 2800 : loss : 0.059486, loss_ce: 0.036799
2022-01-16 00:27:16,876 iteration 2801 : loss : 0.038327, loss_ce: 0.016288
2022-01-16 00:27:17,745 iteration 2802 : loss : 0.029267, loss_ce: 0.012590
2022-01-16 00:27:18,793 iteration 2803 : loss : 0.050149, loss_ce: 0.018768
2022-01-16 00:27:19,746 iteration 2804 : loss : 0.045815, loss_ce: 0.021324
2022-01-16 00:27:19,746 Training Data Eval:
2022-01-16 00:27:24,132   Average segmentation loss on training set: 0.0508
2022-01-16 00:27:24,132 Validation Data Eval:
2022-01-16 00:27:25,591   Average segmentation loss on validation set: 0.0921
2022-01-16 00:27:26,500 iteration 2805 : loss : 0.049996, loss_ce: 0.018422
 41%|███████████▉                 | 165/400 [47:47<1:11:57, 18.37s/it]2022-01-16 00:27:27,536 iteration 2806 : loss : 0.076949, loss_ce: 0.028661
2022-01-16 00:27:28,643 iteration 2807 : loss : 0.034733, loss_ce: 0.014820
2022-01-16 00:27:29,485 iteration 2808 : loss : 0.032954, loss_ce: 0.016147
2022-01-16 00:27:30,424 iteration 2809 : loss : 0.067145, loss_ce: 0.035480
2022-01-16 00:27:31,408 iteration 2810 : loss : 0.045612, loss_ce: 0.021227
2022-01-16 00:27:32,314 iteration 2811 : loss : 0.035567, loss_ce: 0.012893
2022-01-16 00:27:33,255 iteration 2812 : loss : 0.031677, loss_ce: 0.012413
2022-01-16 00:27:34,232 iteration 2813 : loss : 0.026719, loss_ce: 0.008491
2022-01-16 00:27:35,176 iteration 2814 : loss : 0.040212, loss_ce: 0.017008
2022-01-16 00:27:36,070 iteration 2815 : loss : 0.028858, loss_ce: 0.012956
2022-01-16 00:27:36,955 iteration 2816 : loss : 0.038813, loss_ce: 0.018220
2022-01-16 00:27:37,855 iteration 2817 : loss : 0.028366, loss_ce: 0.009666
2022-01-16 00:27:38,876 iteration 2818 : loss : 0.043477, loss_ce: 0.013055
2022-01-16 00:27:39,862 iteration 2819 : loss : 0.035819, loss_ce: 0.017034
2022-01-16 00:27:40,931 iteration 2820 : loss : 0.056193, loss_ce: 0.024056
2022-01-16 00:27:41,877 iteration 2821 : loss : 0.037372, loss_ce: 0.016545
2022-01-16 00:27:42,785 iteration 2822 : loss : 0.044885, loss_ce: 0.013092
 42%|████████████                 | 166/400 [48:03<1:09:12, 17.74s/it]2022-01-16 00:27:43,877 iteration 2823 : loss : 0.064842, loss_ce: 0.021776
2022-01-16 00:27:44,765 iteration 2824 : loss : 0.025462, loss_ce: 0.009734
2022-01-16 00:27:45,734 iteration 2825 : loss : 0.051002, loss_ce: 0.028715
2022-01-16 00:27:46,630 iteration 2826 : loss : 0.027609, loss_ce: 0.010928
2022-01-16 00:27:47,599 iteration 2827 : loss : 0.035643, loss_ce: 0.017643
2022-01-16 00:27:48,554 iteration 2828 : loss : 0.040822, loss_ce: 0.020273
2022-01-16 00:27:49,625 iteration 2829 : loss : 0.033322, loss_ce: 0.014105
2022-01-16 00:27:50,499 iteration 2830 : loss : 0.025697, loss_ce: 0.012260
2022-01-16 00:27:51,441 iteration 2831 : loss : 0.039801, loss_ce: 0.015903
2022-01-16 00:27:52,427 iteration 2832 : loss : 0.051350, loss_ce: 0.016418
2022-01-16 00:27:53,434 iteration 2833 : loss : 0.042974, loss_ce: 0.016468
2022-01-16 00:27:54,366 iteration 2834 : loss : 0.055805, loss_ce: 0.017693
2022-01-16 00:27:55,354 iteration 2835 : loss : 0.067202, loss_ce: 0.018777
2022-01-16 00:27:56,364 iteration 2836 : loss : 0.036573, loss_ce: 0.014423
2022-01-16 00:27:57,314 iteration 2837 : loss : 0.051005, loss_ce: 0.012405
2022-01-16 00:27:58,185 iteration 2838 : loss : 0.027860, loss_ce: 0.008952
2022-01-16 00:27:59,167 iteration 2839 : loss : 0.046218, loss_ce: 0.018433
 42%|████████████                 | 167/400 [48:20<1:07:19, 17.34s/it]2022-01-16 00:28:00,158 iteration 2840 : loss : 0.046488, loss_ce: 0.023454
2022-01-16 00:28:01,120 iteration 2841 : loss : 0.030620, loss_ce: 0.011556
2022-01-16 00:28:02,070 iteration 2842 : loss : 0.059849, loss_ce: 0.018371
2022-01-16 00:28:02,931 iteration 2843 : loss : 0.036889, loss_ce: 0.014111
2022-01-16 00:28:03,771 iteration 2844 : loss : 0.024872, loss_ce: 0.009399
2022-01-16 00:28:04,674 iteration 2845 : loss : 0.039704, loss_ce: 0.015053
2022-01-16 00:28:05,729 iteration 2846 : loss : 0.043480, loss_ce: 0.012950
2022-01-16 00:28:06,729 iteration 2847 : loss : 0.043923, loss_ce: 0.015642
2022-01-16 00:28:07,680 iteration 2848 : loss : 0.043826, loss_ce: 0.012572
2022-01-16 00:28:08,653 iteration 2849 : loss : 0.038666, loss_ce: 0.015189
2022-01-16 00:28:09,596 iteration 2850 : loss : 0.047755, loss_ce: 0.025352
2022-01-16 00:28:10,632 iteration 2851 : loss : 0.038311, loss_ce: 0.013679
2022-01-16 00:28:11,535 iteration 2852 : loss : 0.032498, loss_ce: 0.010021
2022-01-16 00:28:12,501 iteration 2853 : loss : 0.033411, loss_ce: 0.010252
2022-01-16 00:28:13,372 iteration 2854 : loss : 0.035417, loss_ce: 0.009833
2022-01-16 00:28:14,270 iteration 2855 : loss : 0.029821, loss_ce: 0.013312
2022-01-16 00:28:15,114 iteration 2856 : loss : 0.024326, loss_ce: 0.011354
 42%|████████████▏                | 168/400 [48:36<1:05:26, 16.93s/it]2022-01-16 00:28:16,124 iteration 2857 : loss : 0.040890, loss_ce: 0.018429
2022-01-16 00:28:17,197 iteration 2858 : loss : 0.042627, loss_ce: 0.013233
2022-01-16 00:28:18,229 iteration 2859 : loss : 0.035333, loss_ce: 0.014100
2022-01-16 00:28:19,219 iteration 2860 : loss : 0.035417, loss_ce: 0.013269
2022-01-16 00:28:20,180 iteration 2861 : loss : 0.029341, loss_ce: 0.008192
2022-01-16 00:28:21,169 iteration 2862 : loss : 0.052393, loss_ce: 0.014339
2022-01-16 00:28:22,066 iteration 2863 : loss : 0.023158, loss_ce: 0.008521
2022-01-16 00:28:22,994 iteration 2864 : loss : 0.036224, loss_ce: 0.014429
2022-01-16 00:28:23,921 iteration 2865 : loss : 0.031395, loss_ce: 0.012096
2022-01-16 00:28:24,843 iteration 2866 : loss : 0.026743, loss_ce: 0.009413
2022-01-16 00:28:25,882 iteration 2867 : loss : 0.037446, loss_ce: 0.014124
2022-01-16 00:28:26,872 iteration 2868 : loss : 0.050058, loss_ce: 0.020074
2022-01-16 00:28:27,874 iteration 2869 : loss : 0.040980, loss_ce: 0.015277
2022-01-16 00:28:28,926 iteration 2870 : loss : 0.034042, loss_ce: 0.013015
2022-01-16 00:28:29,805 iteration 2871 : loss : 0.047022, loss_ce: 0.023488
2022-01-16 00:28:30,716 iteration 2872 : loss : 0.036089, loss_ce: 0.017246
2022-01-16 00:28:31,639 iteration 2873 : loss : 0.029975, loss_ce: 0.013208
 42%|████████████▎                | 169/400 [48:52<1:04:41, 16.81s/it]2022-01-16 00:28:32,645 iteration 2874 : loss : 0.023075, loss_ce: 0.008914
2022-01-16 00:28:33,663 iteration 2875 : loss : 0.028293, loss_ce: 0.012145
2022-01-16 00:28:34,564 iteration 2876 : loss : 0.040853, loss_ce: 0.015545
2022-01-16 00:28:35,428 iteration 2877 : loss : 0.035176, loss_ce: 0.012845
2022-01-16 00:28:36,348 iteration 2878 : loss : 0.032584, loss_ce: 0.010870
2022-01-16 00:28:37,200 iteration 2879 : loss : 0.029658, loss_ce: 0.012870
2022-01-16 00:28:38,161 iteration 2880 : loss : 0.029690, loss_ce: 0.014614
2022-01-16 00:28:39,013 iteration 2881 : loss : 0.024645, loss_ce: 0.011409
2022-01-16 00:28:39,905 iteration 2882 : loss : 0.053266, loss_ce: 0.019947
2022-01-16 00:28:40,876 iteration 2883 : loss : 0.039160, loss_ce: 0.011318
2022-01-16 00:28:41,858 iteration 2884 : loss : 0.037476, loss_ce: 0.015241
2022-01-16 00:28:42,803 iteration 2885 : loss : 0.030228, loss_ce: 0.012442
2022-01-16 00:28:43,701 iteration 2886 : loss : 0.030347, loss_ce: 0.010030
2022-01-16 00:28:44,587 iteration 2887 : loss : 0.032580, loss_ce: 0.010641
2022-01-16 00:28:45,559 iteration 2888 : loss : 0.028371, loss_ce: 0.012139
2022-01-16 00:28:46,498 iteration 2889 : loss : 0.043338, loss_ce: 0.015806
2022-01-16 00:28:46,498 Training Data Eval:
2022-01-16 00:28:50,889   Average segmentation loss on training set: 0.0249
2022-01-16 00:28:50,889 Validation Data Eval:
2022-01-16 00:28:52,349   Average segmentation loss on validation set: 0.0752
2022-01-16 00:28:53,251 iteration 2890 : loss : 0.035328, loss_ce: 0.015285
 42%|████████████▎                | 170/400 [49:14<1:09:56, 18.25s/it]2022-01-16 00:28:54,235 iteration 2891 : loss : 0.034883, loss_ce: 0.013999
2022-01-16 00:28:55,191 iteration 2892 : loss : 0.038755, loss_ce: 0.015751
2022-01-16 00:28:56,039 iteration 2893 : loss : 0.023433, loss_ce: 0.009176
2022-01-16 00:28:56,924 iteration 2894 : loss : 0.024423, loss_ce: 0.009194
2022-01-16 00:28:57,808 iteration 2895 : loss : 0.054939, loss_ce: 0.020958
2022-01-16 00:28:58,727 iteration 2896 : loss : 0.050389, loss_ce: 0.021514
2022-01-16 00:28:59,785 iteration 2897 : loss : 0.084560, loss_ce: 0.023874
2022-01-16 00:29:00,751 iteration 2898 : loss : 0.043312, loss_ce: 0.014849
2022-01-16 00:29:01,695 iteration 2899 : loss : 0.041765, loss_ce: 0.019474
2022-01-16 00:29:02,780 iteration 2900 : loss : 0.057101, loss_ce: 0.023299
2022-01-16 00:29:03,760 iteration 2901 : loss : 0.038535, loss_ce: 0.014212
2022-01-16 00:29:04,677 iteration 2902 : loss : 0.036843, loss_ce: 0.015890
2022-01-16 00:29:05,629 iteration 2903 : loss : 0.031239, loss_ce: 0.009463
2022-01-16 00:29:06,554 iteration 2904 : loss : 0.032248, loss_ce: 0.013713
2022-01-16 00:29:07,531 iteration 2905 : loss : 0.033661, loss_ce: 0.015848
2022-01-16 00:29:08,427 iteration 2906 : loss : 0.032404, loss_ce: 0.013368
2022-01-16 00:29:09,366 iteration 2907 : loss : 0.027684, loss_ce: 0.011663
 43%|████████████▍                | 171/400 [49:30<1:07:11, 17.60s/it]2022-01-16 00:29:10,393 iteration 2908 : loss : 0.026773, loss_ce: 0.009874
2022-01-16 00:29:11,387 iteration 2909 : loss : 0.037468, loss_ce: 0.013753
2022-01-16 00:29:12,373 iteration 2910 : loss : 0.029058, loss_ce: 0.013617
2022-01-16 00:29:13,376 iteration 2911 : loss : 0.036859, loss_ce: 0.014077
2022-01-16 00:29:14,278 iteration 2912 : loss : 0.023387, loss_ce: 0.009349
2022-01-16 00:29:15,229 iteration 2913 : loss : 0.035296, loss_ce: 0.013212
2022-01-16 00:29:16,216 iteration 2914 : loss : 0.036781, loss_ce: 0.015294
2022-01-16 00:29:17,171 iteration 2915 : loss : 0.039219, loss_ce: 0.020393
2022-01-16 00:29:18,113 iteration 2916 : loss : 0.032981, loss_ce: 0.013820
2022-01-16 00:29:19,052 iteration 2917 : loss : 0.031871, loss_ce: 0.012612
2022-01-16 00:29:19,911 iteration 2918 : loss : 0.028696, loss_ce: 0.012401
2022-01-16 00:29:20,853 iteration 2919 : loss : 0.036288, loss_ce: 0.013638
2022-01-16 00:29:21,767 iteration 2920 : loss : 0.026880, loss_ce: 0.011106
2022-01-16 00:29:22,693 iteration 2921 : loss : 0.033114, loss_ce: 0.014891
2022-01-16 00:29:23,610 iteration 2922 : loss : 0.036683, loss_ce: 0.011973
2022-01-16 00:29:24,628 iteration 2923 : loss : 0.032883, loss_ce: 0.009682
2022-01-16 00:29:25,612 iteration 2924 : loss : 0.029240, loss_ce: 0.013355
 43%|████████████▍                | 172/400 [49:46<1:05:21, 17.20s/it]2022-01-16 00:29:26,632 iteration 2925 : loss : 0.033733, loss_ce: 0.016672
2022-01-16 00:29:27,507 iteration 2926 : loss : 0.028529, loss_ce: 0.010073
2022-01-16 00:29:28,451 iteration 2927 : loss : 0.022422, loss_ce: 0.008026
2022-01-16 00:29:29,429 iteration 2928 : loss : 0.038827, loss_ce: 0.015713
2022-01-16 00:29:30,320 iteration 2929 : loss : 0.032995, loss_ce: 0.008524
2022-01-16 00:29:31,202 iteration 2930 : loss : 0.024892, loss_ce: 0.011022
2022-01-16 00:29:32,131 iteration 2931 : loss : 0.051124, loss_ce: 0.015690
2022-01-16 00:29:33,153 iteration 2932 : loss : 0.030809, loss_ce: 0.013838
2022-01-16 00:29:34,137 iteration 2933 : loss : 0.039400, loss_ce: 0.018471
2022-01-16 00:29:35,154 iteration 2934 : loss : 0.030328, loss_ce: 0.013783
2022-01-16 00:29:36,071 iteration 2935 : loss : 0.026991, loss_ce: 0.008476
2022-01-16 00:29:37,009 iteration 2936 : loss : 0.045187, loss_ce: 0.022272
2022-01-16 00:29:37,969 iteration 2937 : loss : 0.032991, loss_ce: 0.014841
2022-01-16 00:29:38,940 iteration 2938 : loss : 0.046785, loss_ce: 0.018176
2022-01-16 00:29:39,783 iteration 2939 : loss : 0.036645, loss_ce: 0.010959
2022-01-16 00:29:40,695 iteration 2940 : loss : 0.033660, loss_ce: 0.013216
2022-01-16 00:29:41,612 iteration 2941 : loss : 0.033687, loss_ce: 0.014849
 43%|████████████▌                | 173/400 [50:02<1:03:42, 16.84s/it]2022-01-16 00:29:42,723 iteration 2942 : loss : 0.035706, loss_ce: 0.016802
2022-01-16 00:29:43,719 iteration 2943 : loss : 0.031743, loss_ce: 0.016122
2022-01-16 00:29:44,682 iteration 2944 : loss : 0.050817, loss_ce: 0.022601
2022-01-16 00:29:45,626 iteration 2945 : loss : 0.029301, loss_ce: 0.012536
2022-01-16 00:29:46,639 iteration 2946 : loss : 0.033528, loss_ce: 0.013755
2022-01-16 00:29:47,545 iteration 2947 : loss : 0.035612, loss_ce: 0.012731
2022-01-16 00:29:48,510 iteration 2948 : loss : 0.029863, loss_ce: 0.012829
2022-01-16 00:29:49,417 iteration 2949 : loss : 0.035540, loss_ce: 0.014126
2022-01-16 00:29:50,267 iteration 2950 : loss : 0.025039, loss_ce: 0.009965
2022-01-16 00:29:51,195 iteration 2951 : loss : 0.028233, loss_ce: 0.009628
2022-01-16 00:29:52,034 iteration 2952 : loss : 0.118383, loss_ce: 0.027632
2022-01-16 00:29:53,036 iteration 2953 : loss : 0.037045, loss_ce: 0.014853
2022-01-16 00:29:53,980 iteration 2954 : loss : 0.026290, loss_ce: 0.011575
2022-01-16 00:29:54,924 iteration 2955 : loss : 0.051833, loss_ce: 0.010185
2022-01-16 00:29:55,800 iteration 2956 : loss : 0.048113, loss_ce: 0.024450
2022-01-16 00:29:56,670 iteration 2957 : loss : 0.040675, loss_ce: 0.015177
2022-01-16 00:29:57,609 iteration 2958 : loss : 0.052501, loss_ce: 0.019558
 44%|████████████▌                | 174/400 [50:18<1:02:28, 16.59s/it]2022-01-16 00:29:58,655 iteration 2959 : loss : 0.056876, loss_ce: 0.028722
2022-01-16 00:29:59,586 iteration 2960 : loss : 0.046225, loss_ce: 0.020448
2022-01-16 00:30:00,573 iteration 2961 : loss : 0.035736, loss_ce: 0.016462
2022-01-16 00:30:01,550 iteration 2962 : loss : 0.075286, loss_ce: 0.022592
2022-01-16 00:30:02,458 iteration 2963 : loss : 0.030264, loss_ce: 0.013630
2022-01-16 00:30:03,354 iteration 2964 : loss : 0.040977, loss_ce: 0.015092
2022-01-16 00:30:04,213 iteration 2965 : loss : 0.066314, loss_ce: 0.025522
2022-01-16 00:30:05,049 iteration 2966 : loss : 0.036552, loss_ce: 0.013363
2022-01-16 00:30:06,003 iteration 2967 : loss : 0.041350, loss_ce: 0.018753
2022-01-16 00:30:07,046 iteration 2968 : loss : 0.098577, loss_ce: 0.031809
2022-01-16 00:30:08,036 iteration 2969 : loss : 0.026302, loss_ce: 0.010613
2022-01-16 00:30:08,954 iteration 2970 : loss : 0.040675, loss_ce: 0.013405
2022-01-16 00:30:09,823 iteration 2971 : loss : 0.032115, loss_ce: 0.013982
2022-01-16 00:30:10,804 iteration 2972 : loss : 0.044186, loss_ce: 0.014354
2022-01-16 00:30:11,703 iteration 2973 : loss : 0.032195, loss_ce: 0.011715
2022-01-16 00:30:12,706 iteration 2974 : loss : 0.030298, loss_ce: 0.009996
2022-01-16 00:30:12,707 Training Data Eval:
2022-01-16 00:30:17,105   Average segmentation loss on training set: 0.0327
2022-01-16 00:30:17,105 Validation Data Eval:
2022-01-16 00:30:18,570   Average segmentation loss on validation set: 0.1436
2022-01-16 00:30:19,532 iteration 2975 : loss : 0.036259, loss_ce: 0.010834
 44%|████████████▋                | 175/400 [50:40<1:08:12, 18.19s/it]2022-01-16 00:30:20,630 iteration 2976 : loss : 0.039884, loss_ce: 0.022466
2022-01-16 00:30:21,493 iteration 2977 : loss : 0.033295, loss_ce: 0.013672
2022-01-16 00:30:22,335 iteration 2978 : loss : 0.050536, loss_ce: 0.020017
2022-01-16 00:30:23,305 iteration 2979 : loss : 0.049144, loss_ce: 0.017694
2022-01-16 00:30:24,383 iteration 2980 : loss : 0.031689, loss_ce: 0.012584
2022-01-16 00:30:25,340 iteration 2981 : loss : 0.037746, loss_ce: 0.010956
2022-01-16 00:30:26,372 iteration 2982 : loss : 0.037358, loss_ce: 0.016474
2022-01-16 00:30:27,305 iteration 2983 : loss : 0.037730, loss_ce: 0.017823
2022-01-16 00:30:28,319 iteration 2984 : loss : 0.029525, loss_ce: 0.011579
2022-01-16 00:30:29,288 iteration 2985 : loss : 0.050963, loss_ce: 0.013950
2022-01-16 00:30:30,294 iteration 2986 : loss : 0.047437, loss_ce: 0.017387
2022-01-16 00:30:31,178 iteration 2987 : loss : 0.035923, loss_ce: 0.016277
2022-01-16 00:30:32,087 iteration 2988 : loss : 0.037309, loss_ce: 0.014376
2022-01-16 00:30:33,042 iteration 2989 : loss : 0.038730, loss_ce: 0.010725
2022-01-16 00:30:34,014 iteration 2990 : loss : 0.047016, loss_ce: 0.018375
2022-01-16 00:30:35,048 iteration 2991 : loss : 0.034861, loss_ce: 0.014246
2022-01-16 00:30:36,149 iteration 2992 : loss : 0.037794, loss_ce: 0.015684
 44%|████████████▊                | 176/400 [50:57<1:06:07, 17.71s/it]2022-01-16 00:30:37,086 iteration 2993 : loss : 0.029340, loss_ce: 0.009161
2022-01-16 00:30:38,012 iteration 2994 : loss : 0.032379, loss_ce: 0.011395
2022-01-16 00:30:39,094 iteration 2995 : loss : 0.041176, loss_ce: 0.016650
2022-01-16 00:30:40,037 iteration 2996 : loss : 0.023703, loss_ce: 0.008838
2022-01-16 00:30:40,976 iteration 2997 : loss : 0.023751, loss_ce: 0.008796
2022-01-16 00:30:41,905 iteration 2998 : loss : 0.023448, loss_ce: 0.006721
2022-01-16 00:30:42,896 iteration 2999 : loss : 0.041723, loss_ce: 0.015216
2022-01-16 00:30:43,832 iteration 3000 : loss : 0.055253, loss_ce: 0.015034
2022-01-16 00:30:44,820 iteration 3001 : loss : 0.026346, loss_ce: 0.010810
2022-01-16 00:30:45,670 iteration 3002 : loss : 0.063281, loss_ce: 0.025365
2022-01-16 00:30:46,673 iteration 3003 : loss : 0.031969, loss_ce: 0.012659
2022-01-16 00:30:47,527 iteration 3004 : loss : 0.034300, loss_ce: 0.013246
2022-01-16 00:30:48,494 iteration 3005 : loss : 0.046447, loss_ce: 0.017536
2022-01-16 00:30:49,469 iteration 3006 : loss : 0.034025, loss_ce: 0.012531
2022-01-16 00:30:50,385 iteration 3007 : loss : 0.032953, loss_ce: 0.012310
2022-01-16 00:30:51,454 iteration 3008 : loss : 0.033224, loss_ce: 0.013448
2022-01-16 00:30:52,386 iteration 3009 : loss : 0.032532, loss_ce: 0.018196
 44%|████████████▊                | 177/400 [51:13<1:04:11, 17.27s/it]2022-01-16 00:30:53,380 iteration 3010 : loss : 0.031003, loss_ce: 0.012234
2022-01-16 00:30:54,311 iteration 3011 : loss : 0.033901, loss_ce: 0.011367
2022-01-16 00:30:55,209 iteration 3012 : loss : 0.036156, loss_ce: 0.012310
2022-01-16 00:30:56,102 iteration 3013 : loss : 0.026412, loss_ce: 0.010006
2022-01-16 00:30:57,117 iteration 3014 : loss : 0.034955, loss_ce: 0.014840
2022-01-16 00:30:58,071 iteration 3015 : loss : 0.027674, loss_ce: 0.009982
2022-01-16 00:30:59,002 iteration 3016 : loss : 0.034564, loss_ce: 0.012184
2022-01-16 00:30:59,923 iteration 3017 : loss : 0.040214, loss_ce: 0.012570
2022-01-16 00:31:00,808 iteration 3018 : loss : 0.027955, loss_ce: 0.007610
2022-01-16 00:31:01,718 iteration 3019 : loss : 0.034101, loss_ce: 0.013167
2022-01-16 00:31:02,529 iteration 3020 : loss : 0.032108, loss_ce: 0.015586
2022-01-16 00:31:03,362 iteration 3021 : loss : 0.029497, loss_ce: 0.010178
2022-01-16 00:31:04,269 iteration 3022 : loss : 0.041348, loss_ce: 0.010508
2022-01-16 00:31:05,185 iteration 3023 : loss : 0.032845, loss_ce: 0.017046
2022-01-16 00:31:06,124 iteration 3024 : loss : 0.032583, loss_ce: 0.012422
2022-01-16 00:31:06,948 iteration 3025 : loss : 0.028184, loss_ce: 0.010970
2022-01-16 00:31:07,919 iteration 3026 : loss : 0.023774, loss_ce: 0.011289
 44%|████████████▉                | 178/400 [51:28<1:01:59, 16.75s/it]2022-01-16 00:31:08,931 iteration 3027 : loss : 0.027426, loss_ce: 0.012584
2022-01-16 00:31:09,856 iteration 3028 : loss : 0.033228, loss_ce: 0.013535
2022-01-16 00:31:10,801 iteration 3029 : loss : 0.038705, loss_ce: 0.017152
2022-01-16 00:31:11,841 iteration 3030 : loss : 0.033966, loss_ce: 0.012046
2022-01-16 00:31:12,677 iteration 3031 : loss : 0.023684, loss_ce: 0.008923
2022-01-16 00:31:13,595 iteration 3032 : loss : 0.026166, loss_ce: 0.007975
2022-01-16 00:31:14,558 iteration 3033 : loss : 0.031150, loss_ce: 0.016558
2022-01-16 00:31:15,472 iteration 3034 : loss : 0.041211, loss_ce: 0.012565
2022-01-16 00:31:16,496 iteration 3035 : loss : 0.034604, loss_ce: 0.011549
2022-01-16 00:31:17,451 iteration 3036 : loss : 0.028113, loss_ce: 0.012109
2022-01-16 00:31:18,449 iteration 3037 : loss : 0.022772, loss_ce: 0.007964
2022-01-16 00:31:19,310 iteration 3038 : loss : 0.029642, loss_ce: 0.006935
2022-01-16 00:31:20,427 iteration 3039 : loss : 0.078638, loss_ce: 0.028896
2022-01-16 00:31:21,309 iteration 3040 : loss : 0.030198, loss_ce: 0.012637
2022-01-16 00:31:22,208 iteration 3041 : loss : 0.033727, loss_ce: 0.012693
2022-01-16 00:31:23,092 iteration 3042 : loss : 0.027338, loss_ce: 0.012356
2022-01-16 00:31:24,147 iteration 3043 : loss : 0.026771, loss_ce: 0.009997
 45%|████████████▉                | 179/400 [51:45<1:01:07, 16.59s/it]2022-01-16 00:31:25,195 iteration 3044 : loss : 0.046707, loss_ce: 0.017752
2022-01-16 00:31:26,115 iteration 3045 : loss : 0.028797, loss_ce: 0.010650
2022-01-16 00:31:27,022 iteration 3046 : loss : 0.033930, loss_ce: 0.012393
2022-01-16 00:31:28,087 iteration 3047 : loss : 0.033798, loss_ce: 0.013199
2022-01-16 00:31:29,104 iteration 3048 : loss : 0.037208, loss_ce: 0.021731
2022-01-16 00:31:30,016 iteration 3049 : loss : 0.037097, loss_ce: 0.013608
2022-01-16 00:31:31,062 iteration 3050 : loss : 0.048295, loss_ce: 0.023542
2022-01-16 00:31:32,050 iteration 3051 : loss : 0.049280, loss_ce: 0.015556
2022-01-16 00:31:33,090 iteration 3052 : loss : 0.039622, loss_ce: 0.014089
2022-01-16 00:31:34,064 iteration 3053 : loss : 0.026029, loss_ce: 0.010509
2022-01-16 00:31:35,032 iteration 3054 : loss : 0.058758, loss_ce: 0.021661
2022-01-16 00:31:36,012 iteration 3055 : loss : 0.035059, loss_ce: 0.015672
2022-01-16 00:31:36,959 iteration 3056 : loss : 0.032886, loss_ce: 0.013455
2022-01-16 00:31:37,849 iteration 3057 : loss : 0.024298, loss_ce: 0.008691
2022-01-16 00:31:38,871 iteration 3058 : loss : 0.041494, loss_ce: 0.013320
2022-01-16 00:31:39,902 iteration 3059 : loss : 0.032835, loss_ce: 0.012446
2022-01-16 00:31:39,902 Training Data Eval:
2022-01-16 00:31:44,289   Average segmentation loss on training set: 0.0274
2022-01-16 00:31:44,289 Validation Data Eval:
2022-01-16 00:31:45,756   Average segmentation loss on validation set: 0.1190
2022-01-16 00:31:46,684 iteration 3060 : loss : 0.039386, loss_ce: 0.015122
 45%|█████████████                | 180/400 [52:07<1:07:23, 18.38s/it]2022-01-16 00:31:47,663 iteration 3061 : loss : 0.033501, loss_ce: 0.013072
2022-01-16 00:31:48,640 iteration 3062 : loss : 0.037870, loss_ce: 0.011414
2022-01-16 00:31:49,555 iteration 3063 : loss : 0.041291, loss_ce: 0.014707
2022-01-16 00:31:50,552 iteration 3064 : loss : 0.039076, loss_ce: 0.022266
2022-01-16 00:31:51,484 iteration 3065 : loss : 0.044927, loss_ce: 0.013903
2022-01-16 00:31:52,411 iteration 3066 : loss : 0.024246, loss_ce: 0.005396
2022-01-16 00:31:53,362 iteration 3067 : loss : 0.033111, loss_ce: 0.015527
2022-01-16 00:31:54,380 iteration 3068 : loss : 0.026342, loss_ce: 0.010237
2022-01-16 00:31:55,396 iteration 3069 : loss : 0.064367, loss_ce: 0.015714
2022-01-16 00:31:56,268 iteration 3070 : loss : 0.032435, loss_ce: 0.013136
2022-01-16 00:31:57,295 iteration 3071 : loss : 0.034199, loss_ce: 0.013569
2022-01-16 00:31:58,264 iteration 3072 : loss : 0.036515, loss_ce: 0.015649
2022-01-16 00:31:59,165 iteration 3073 : loss : 0.041690, loss_ce: 0.014806
2022-01-16 00:32:00,226 iteration 3074 : loss : 0.048884, loss_ce: 0.023113
2022-01-16 00:32:01,230 iteration 3075 : loss : 0.035223, loss_ce: 0.014800
2022-01-16 00:32:02,161 iteration 3076 : loss : 0.037396, loss_ce: 0.018546
2022-01-16 00:32:03,196 iteration 3077 : loss : 0.056814, loss_ce: 0.029796
 45%|█████████████                | 181/400 [52:24<1:05:02, 17.82s/it]2022-01-16 00:32:04,092 iteration 3078 : loss : 0.023214, loss_ce: 0.009296
2022-01-16 00:32:05,089 iteration 3079 : loss : 0.053942, loss_ce: 0.019098
2022-01-16 00:32:06,034 iteration 3080 : loss : 0.031736, loss_ce: 0.013127
2022-01-16 00:32:06,952 iteration 3081 : loss : 0.046955, loss_ce: 0.013679
2022-01-16 00:32:07,909 iteration 3082 : loss : 0.029395, loss_ce: 0.010722
2022-01-16 00:32:08,863 iteration 3083 : loss : 0.046434, loss_ce: 0.021618
2022-01-16 00:32:09,790 iteration 3084 : loss : 0.030918, loss_ce: 0.011426
2022-01-16 00:32:10,734 iteration 3085 : loss : 0.069274, loss_ce: 0.013765
2022-01-16 00:32:11,634 iteration 3086 : loss : 0.032260, loss_ce: 0.013079
2022-01-16 00:32:12,518 iteration 3087 : loss : 0.030358, loss_ce: 0.008691
2022-01-16 00:32:13,401 iteration 3088 : loss : 0.029769, loss_ce: 0.010923
2022-01-16 00:32:14,283 iteration 3089 : loss : 0.039407, loss_ce: 0.016279
2022-01-16 00:32:15,236 iteration 3090 : loss : 0.053752, loss_ce: 0.018013
2022-01-16 00:32:16,131 iteration 3091 : loss : 0.048589, loss_ce: 0.018545
2022-01-16 00:32:16,978 iteration 3092 : loss : 0.032163, loss_ce: 0.014856
2022-01-16 00:32:17,900 iteration 3093 : loss : 0.028851, loss_ce: 0.009471
2022-01-16 00:32:18,795 iteration 3094 : loss : 0.048877, loss_ce: 0.024968
 46%|█████████████▏               | 182/400 [52:39<1:02:17, 17.15s/it]2022-01-16 00:32:19,853 iteration 3095 : loss : 0.027759, loss_ce: 0.009450
2022-01-16 00:32:20,767 iteration 3096 : loss : 0.028195, loss_ce: 0.011076
2022-01-16 00:32:21,685 iteration 3097 : loss : 0.053790, loss_ce: 0.020098
2022-01-16 00:32:22,568 iteration 3098 : loss : 0.030203, loss_ce: 0.011147
2022-01-16 00:32:23,574 iteration 3099 : loss : 0.047822, loss_ce: 0.013990
2022-01-16 00:32:24,456 iteration 3100 : loss : 0.032725, loss_ce: 0.010408
2022-01-16 00:32:25,388 iteration 3101 : loss : 0.036195, loss_ce: 0.015594
2022-01-16 00:32:26,377 iteration 3102 : loss : 0.047606, loss_ce: 0.015459
2022-01-16 00:32:27,295 iteration 3103 : loss : 0.030922, loss_ce: 0.009293
2022-01-16 00:32:28,229 iteration 3104 : loss : 0.026689, loss_ce: 0.008420
2022-01-16 00:32:29,137 iteration 3105 : loss : 0.027730, loss_ce: 0.009968
2022-01-16 00:32:30,234 iteration 3106 : loss : 0.040680, loss_ce: 0.014003
2022-01-16 00:32:31,167 iteration 3107 : loss : 0.035745, loss_ce: 0.014235
2022-01-16 00:32:32,033 iteration 3108 : loss : 0.037796, loss_ce: 0.016066
2022-01-16 00:32:33,033 iteration 3109 : loss : 0.039395, loss_ce: 0.020507
2022-01-16 00:32:34,039 iteration 3110 : loss : 0.041727, loss_ce: 0.018065
2022-01-16 00:32:34,937 iteration 3111 : loss : 0.033743, loss_ce: 0.010279
 46%|█████████████▎               | 183/400 [52:55<1:00:55, 16.85s/it]2022-01-16 00:32:35,899 iteration 3112 : loss : 0.021427, loss_ce: 0.008316
2022-01-16 00:32:36,832 iteration 3113 : loss : 0.033776, loss_ce: 0.013455
2022-01-16 00:32:37,898 iteration 3114 : loss : 0.063567, loss_ce: 0.019405
2022-01-16 00:32:38,905 iteration 3115 : loss : 0.029360, loss_ce: 0.013328
2022-01-16 00:32:39,867 iteration 3116 : loss : 0.033860, loss_ce: 0.013697
2022-01-16 00:32:40,799 iteration 3117 : loss : 0.031571, loss_ce: 0.012854
2022-01-16 00:32:41,806 iteration 3118 : loss : 0.038198, loss_ce: 0.014331
2022-01-16 00:32:42,788 iteration 3119 : loss : 0.030939, loss_ce: 0.011676
2022-01-16 00:32:43,748 iteration 3120 : loss : 0.025645, loss_ce: 0.008371
2022-01-16 00:32:44,726 iteration 3121 : loss : 0.038334, loss_ce: 0.009875
2022-01-16 00:32:45,747 iteration 3122 : loss : 0.034695, loss_ce: 0.009896
2022-01-16 00:32:46,703 iteration 3123 : loss : 0.026260, loss_ce: 0.011239
2022-01-16 00:32:47,670 iteration 3124 : loss : 0.036099, loss_ce: 0.015280
2022-01-16 00:32:48,636 iteration 3125 : loss : 0.035467, loss_ce: 0.017180
2022-01-16 00:32:49,519 iteration 3126 : loss : 0.036733, loss_ce: 0.013721
2022-01-16 00:32:50,475 iteration 3127 : loss : 0.031823, loss_ce: 0.012676
2022-01-16 00:32:51,334 iteration 3128 : loss : 0.028009, loss_ce: 0.010000
 46%|█████████████▎               | 184/400 [53:12<1:00:09, 16.71s/it]2022-01-16 00:32:52,378 iteration 3129 : loss : 0.032773, loss_ce: 0.012031
2022-01-16 00:32:53,350 iteration 3130 : loss : 0.028874, loss_ce: 0.010823
2022-01-16 00:32:54,367 iteration 3131 : loss : 0.038155, loss_ce: 0.016844
2022-01-16 00:32:55,289 iteration 3132 : loss : 0.025263, loss_ce: 0.010244
2022-01-16 00:32:56,161 iteration 3133 : loss : 0.028710, loss_ce: 0.009419
2022-01-16 00:32:57,104 iteration 3134 : loss : 0.024125, loss_ce: 0.007718
2022-01-16 00:32:58,041 iteration 3135 : loss : 0.032280, loss_ce: 0.009893
2022-01-16 00:32:59,048 iteration 3136 : loss : 0.045810, loss_ce: 0.017696
2022-01-16 00:33:00,012 iteration 3137 : loss : 0.037030, loss_ce: 0.016568
2022-01-16 00:33:01,001 iteration 3138 : loss : 0.048720, loss_ce: 0.024809
2022-01-16 00:33:02,028 iteration 3139 : loss : 0.034086, loss_ce: 0.011773
2022-01-16 00:33:03,018 iteration 3140 : loss : 0.044135, loss_ce: 0.017104
2022-01-16 00:33:04,019 iteration 3141 : loss : 0.024882, loss_ce: 0.009119
2022-01-16 00:33:04,968 iteration 3142 : loss : 0.027421, loss_ce: 0.009884
2022-01-16 00:33:05,984 iteration 3143 : loss : 0.026437, loss_ce: 0.011134
2022-01-16 00:33:07,018 iteration 3144 : loss : 0.029716, loss_ce: 0.013801
2022-01-16 00:33:07,018 Training Data Eval:
2022-01-16 00:33:11,406   Average segmentation loss on training set: 0.0212
2022-01-16 00:33:11,406 Validation Data Eval:
2022-01-16 00:33:12,865   Average segmentation loss on validation set: 0.0790
2022-01-16 00:33:13,685 iteration 3145 : loss : 0.029473, loss_ce: 0.010350
 46%|█████████████▍               | 185/400 [53:34<1:05:57, 18.41s/it]2022-01-16 00:33:14,589 iteration 3146 : loss : 0.024989, loss_ce: 0.008774
2022-01-16 00:33:15,497 iteration 3147 : loss : 0.033188, loss_ce: 0.013949
2022-01-16 00:33:16,422 iteration 3148 : loss : 0.026732, loss_ce: 0.008644
2022-01-16 00:33:17,325 iteration 3149 : loss : 0.032329, loss_ce: 0.011802
2022-01-16 00:33:18,244 iteration 3150 : loss : 0.043326, loss_ce: 0.020704
2022-01-16 00:33:19,141 iteration 3151 : loss : 0.032281, loss_ce: 0.008180
2022-01-16 00:33:20,050 iteration 3152 : loss : 0.027249, loss_ce: 0.010550
2022-01-16 00:33:21,004 iteration 3153 : loss : 0.028980, loss_ce: 0.011228
2022-01-16 00:33:21,903 iteration 3154 : loss : 0.030473, loss_ce: 0.014066
2022-01-16 00:33:22,814 iteration 3155 : loss : 0.030515, loss_ce: 0.010583
2022-01-16 00:33:23,820 iteration 3156 : loss : 0.043683, loss_ce: 0.018861
2022-01-16 00:33:24,795 iteration 3157 : loss : 0.044518, loss_ce: 0.019981
2022-01-16 00:33:25,717 iteration 3158 : loss : 0.035041, loss_ce: 0.014375
2022-01-16 00:33:26,652 iteration 3159 : loss : 0.032738, loss_ce: 0.012468
2022-01-16 00:33:27,585 iteration 3160 : loss : 0.030174, loss_ce: 0.011811
2022-01-16 00:33:28,461 iteration 3161 : loss : 0.028390, loss_ce: 0.010433
2022-01-16 00:33:29,476 iteration 3162 : loss : 0.024965, loss_ce: 0.009283
 46%|█████████████▍               | 186/400 [53:50<1:02:51, 17.62s/it]2022-01-16 00:33:30,559 iteration 3163 : loss : 0.028656, loss_ce: 0.011674
2022-01-16 00:33:31,542 iteration 3164 : loss : 0.026078, loss_ce: 0.009519
2022-01-16 00:33:32,464 iteration 3165 : loss : 0.030026, loss_ce: 0.011298
2022-01-16 00:33:33,468 iteration 3166 : loss : 0.032100, loss_ce: 0.011625
2022-01-16 00:33:34,411 iteration 3167 : loss : 0.021116, loss_ce: 0.008343
2022-01-16 00:33:35,498 iteration 3168 : loss : 0.039380, loss_ce: 0.017667
2022-01-16 00:33:36,550 iteration 3169 : loss : 0.032534, loss_ce: 0.015951
2022-01-16 00:33:37,468 iteration 3170 : loss : 0.028924, loss_ce: 0.012869
2022-01-16 00:33:38,336 iteration 3171 : loss : 0.028673, loss_ce: 0.016628
2022-01-16 00:33:39,302 iteration 3172 : loss : 0.029570, loss_ce: 0.011905
2022-01-16 00:33:40,297 iteration 3173 : loss : 0.029668, loss_ce: 0.009947
2022-01-16 00:33:41,236 iteration 3174 : loss : 0.041335, loss_ce: 0.017491
2022-01-16 00:33:42,285 iteration 3175 : loss : 0.043881, loss_ce: 0.012851
2022-01-16 00:33:43,220 iteration 3176 : loss : 0.031988, loss_ce: 0.010619
2022-01-16 00:33:44,224 iteration 3177 : loss : 0.049540, loss_ce: 0.015489
2022-01-16 00:33:45,106 iteration 3178 : loss : 0.028533, loss_ce: 0.010428
2022-01-16 00:33:46,021 iteration 3179 : loss : 0.037221, loss_ce: 0.011085
 47%|█████████████▌               | 187/400 [54:06<1:01:24, 17.30s/it]2022-01-16 00:33:47,085 iteration 3180 : loss : 0.039778, loss_ce: 0.014907
2022-01-16 00:33:47,989 iteration 3181 : loss : 0.032781, loss_ce: 0.012248
2022-01-16 00:33:48,947 iteration 3182 : loss : 0.023934, loss_ce: 0.008437
2022-01-16 00:33:49,862 iteration 3183 : loss : 0.027208, loss_ce: 0.006743
2022-01-16 00:33:50,814 iteration 3184 : loss : 0.030069, loss_ce: 0.011527
2022-01-16 00:33:51,800 iteration 3185 : loss : 0.031598, loss_ce: 0.011041
2022-01-16 00:33:52,655 iteration 3186 : loss : 0.033576, loss_ce: 0.015873
2022-01-16 00:33:53,609 iteration 3187 : loss : 0.022370, loss_ce: 0.008632
2022-01-16 00:33:54,538 iteration 3188 : loss : 0.026142, loss_ce: 0.011011
2022-01-16 00:33:55,504 iteration 3189 : loss : 0.035684, loss_ce: 0.015476
2022-01-16 00:33:56,437 iteration 3190 : loss : 0.033549, loss_ce: 0.012517
2022-01-16 00:33:57,508 iteration 3191 : loss : 0.036975, loss_ce: 0.009186
2022-01-16 00:33:58,405 iteration 3192 : loss : 0.031748, loss_ce: 0.009766
2022-01-16 00:33:59,404 iteration 3193 : loss : 0.031616, loss_ce: 0.013599
2022-01-16 00:34:00,399 iteration 3194 : loss : 0.039798, loss_ce: 0.011988
2022-01-16 00:34:01,357 iteration 3195 : loss : 0.025839, loss_ce: 0.011602
2022-01-16 00:34:02,303 iteration 3196 : loss : 0.026636, loss_ce: 0.010941
 47%|█████████████▋               | 188/400 [54:23<1:00:02, 16.99s/it]2022-01-16 00:34:03,237 iteration 3197 : loss : 0.025396, loss_ce: 0.010408
2022-01-16 00:34:04,160 iteration 3198 : loss : 0.026177, loss_ce: 0.010066
2022-01-16 00:34:05,102 iteration 3199 : loss : 0.031580, loss_ce: 0.014707
2022-01-16 00:34:06,153 iteration 3200 : loss : 0.028469, loss_ce: 0.013431
2022-01-16 00:34:07,122 iteration 3201 : loss : 0.068995, loss_ce: 0.015334
2022-01-16 00:34:08,070 iteration 3202 : loss : 0.040806, loss_ce: 0.014585
2022-01-16 00:34:09,135 iteration 3203 : loss : 0.031427, loss_ce: 0.015993
2022-01-16 00:34:10,078 iteration 3204 : loss : 0.028105, loss_ce: 0.009089
2022-01-16 00:34:11,092 iteration 3205 : loss : 0.035762, loss_ce: 0.010300
2022-01-16 00:34:12,051 iteration 3206 : loss : 0.027025, loss_ce: 0.009560
2022-01-16 00:34:13,102 iteration 3207 : loss : 0.049716, loss_ce: 0.022257
2022-01-16 00:34:13,989 iteration 3208 : loss : 0.034261, loss_ce: 0.010360
2022-01-16 00:34:14,883 iteration 3209 : loss : 0.032272, loss_ce: 0.015647
2022-01-16 00:34:15,719 iteration 3210 : loss : 0.024517, loss_ce: 0.011415
2022-01-16 00:34:16,638 iteration 3211 : loss : 0.031130, loss_ce: 0.007969
2022-01-16 00:34:17,547 iteration 3212 : loss : 0.027076, loss_ce: 0.009410
2022-01-16 00:34:18,489 iteration 3213 : loss : 0.031496, loss_ce: 0.008802
 47%|██████████████▋                | 189/400 [54:39<58:54, 16.75s/it]2022-01-16 00:34:19,513 iteration 3214 : loss : 0.032633, loss_ce: 0.014155
2022-01-16 00:34:20,551 iteration 3215 : loss : 0.028299, loss_ce: 0.010494
2022-01-16 00:34:21,560 iteration 3216 : loss : 0.030116, loss_ce: 0.010529
2022-01-16 00:34:22,567 iteration 3217 : loss : 0.053272, loss_ce: 0.010400
2022-01-16 00:34:23,538 iteration 3218 : loss : 0.031424, loss_ce: 0.011359
2022-01-16 00:34:24,457 iteration 3219 : loss : 0.028172, loss_ce: 0.012394
2022-01-16 00:34:25,448 iteration 3220 : loss : 0.031614, loss_ce: 0.012380
2022-01-16 00:34:26,357 iteration 3221 : loss : 0.025386, loss_ce: 0.010272
2022-01-16 00:34:27,315 iteration 3222 : loss : 0.041572, loss_ce: 0.022116
2022-01-16 00:34:28,294 iteration 3223 : loss : 0.028847, loss_ce: 0.007690
2022-01-16 00:34:29,303 iteration 3224 : loss : 0.026141, loss_ce: 0.008294
2022-01-16 00:34:30,233 iteration 3225 : loss : 0.035991, loss_ce: 0.012316
2022-01-16 00:34:31,321 iteration 3226 : loss : 0.030584, loss_ce: 0.011133
2022-01-16 00:34:32,292 iteration 3227 : loss : 0.029694, loss_ce: 0.011967
2022-01-16 00:34:33,161 iteration 3228 : loss : 0.024558, loss_ce: 0.010853
2022-01-16 00:34:34,185 iteration 3229 : loss : 0.030717, loss_ce: 0.014596
2022-01-16 00:34:34,185 Training Data Eval:
2022-01-16 00:34:38,573   Average segmentation loss on training set: 0.0223
2022-01-16 00:34:38,573 Validation Data Eval:
2022-01-16 00:34:40,030   Average segmentation loss on validation set: 0.0659
2022-01-16 00:34:40,905 Found new lowest validation loss at iteration 3229! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed100.pth
2022-01-16 00:34:41,946 iteration 3230 : loss : 0.039799, loss_ce: 0.015868
 48%|█████████████▊               | 190/400 [55:02<1:05:39, 18.76s/it]2022-01-16 00:34:42,923 iteration 3231 : loss : 0.044565, loss_ce: 0.014579
2022-01-16 00:34:43,859 iteration 3232 : loss : 0.025446, loss_ce: 0.011352
2022-01-16 00:34:44,783 iteration 3233 : loss : 0.032928, loss_ce: 0.010672
2022-01-16 00:34:45,665 iteration 3234 : loss : 0.037600, loss_ce: 0.012834
2022-01-16 00:34:46,559 iteration 3235 : loss : 0.025250, loss_ce: 0.006740
2022-01-16 00:34:47,527 iteration 3236 : loss : 0.037071, loss_ce: 0.016632
2022-01-16 00:34:48,516 iteration 3237 : loss : 0.028967, loss_ce: 0.012484
2022-01-16 00:34:49,473 iteration 3238 : loss : 0.034698, loss_ce: 0.008411
2022-01-16 00:34:50,409 iteration 3239 : loss : 0.025197, loss_ce: 0.009769
2022-01-16 00:34:51,365 iteration 3240 : loss : 0.030330, loss_ce: 0.009879
2022-01-16 00:34:52,361 iteration 3241 : loss : 0.036342, loss_ce: 0.014862
2022-01-16 00:34:53,409 iteration 3242 : loss : 0.030444, loss_ce: 0.013929
2022-01-16 00:34:54,321 iteration 3243 : loss : 0.029824, loss_ce: 0.015106
2022-01-16 00:34:55,255 iteration 3244 : loss : 0.028347, loss_ce: 0.009865
2022-01-16 00:34:56,165 iteration 3245 : loss : 0.028674, loss_ce: 0.010810
2022-01-16 00:34:57,177 iteration 3246 : loss : 0.044997, loss_ce: 0.018456
2022-01-16 00:34:58,146 iteration 3247 : loss : 0.030412, loss_ce: 0.011832
 48%|█████████████▊               | 191/400 [55:19<1:02:41, 18.00s/it]2022-01-16 00:34:59,340 iteration 3248 : loss : 0.043324, loss_ce: 0.021159
2022-01-16 00:35:00,205 iteration 3249 : loss : 0.024679, loss_ce: 0.007314
2022-01-16 00:35:01,179 iteration 3250 : loss : 0.030495, loss_ce: 0.010831
2022-01-16 00:35:02,130 iteration 3251 : loss : 0.075288, loss_ce: 0.019268
2022-01-16 00:35:03,017 iteration 3252 : loss : 0.028111, loss_ce: 0.010781
2022-01-16 00:35:03,987 iteration 3253 : loss : 0.029375, loss_ce: 0.012536
2022-01-16 00:35:04,938 iteration 3254 : loss : 0.029056, loss_ce: 0.008805
2022-01-16 00:35:05,931 iteration 3255 : loss : 0.037975, loss_ce: 0.014991
2022-01-16 00:35:06,817 iteration 3256 : loss : 0.025761, loss_ce: 0.015322
2022-01-16 00:35:07,741 iteration 3257 : loss : 0.048615, loss_ce: 0.017574
2022-01-16 00:35:08,765 iteration 3258 : loss : 0.034886, loss_ce: 0.014920
2022-01-16 00:35:09,705 iteration 3259 : loss : 0.034886, loss_ce: 0.013861
2022-01-16 00:35:10,617 iteration 3260 : loss : 0.027069, loss_ce: 0.010660
2022-01-16 00:35:11,618 iteration 3261 : loss : 0.033893, loss_ce: 0.012881
2022-01-16 00:35:12,546 iteration 3262 : loss : 0.040840, loss_ce: 0.017987
2022-01-16 00:35:13,471 iteration 3263 : loss : 0.045954, loss_ce: 0.013768
2022-01-16 00:35:14,386 iteration 3264 : loss : 0.037195, loss_ce: 0.012710
 48%|█████████████▉               | 192/400 [55:35<1:00:33, 17.47s/it]2022-01-16 00:35:15,271 iteration 3265 : loss : 0.021149, loss_ce: 0.008240
2022-01-16 00:35:16,241 iteration 3266 : loss : 0.024586, loss_ce: 0.010140
2022-01-16 00:35:17,132 iteration 3267 : loss : 0.026697, loss_ce: 0.012125
2022-01-16 00:35:18,189 iteration 3268 : loss : 0.030771, loss_ce: 0.012728
2022-01-16 00:35:19,071 iteration 3269 : loss : 0.030155, loss_ce: 0.011781
2022-01-16 00:35:19,953 iteration 3270 : loss : 0.024537, loss_ce: 0.009580
2022-01-16 00:35:20,964 iteration 3271 : loss : 0.025248, loss_ce: 0.009027
2022-01-16 00:35:21,874 iteration 3272 : loss : 0.026257, loss_ce: 0.010148
2022-01-16 00:35:22,766 iteration 3273 : loss : 0.036519, loss_ce: 0.014529
2022-01-16 00:35:23,742 iteration 3274 : loss : 0.033137, loss_ce: 0.011527
2022-01-16 00:35:24,631 iteration 3275 : loss : 0.021195, loss_ce: 0.008948
2022-01-16 00:35:25,566 iteration 3276 : loss : 0.027611, loss_ce: 0.009032
2022-01-16 00:35:26,567 iteration 3277 : loss : 0.025777, loss_ce: 0.010530
2022-01-16 00:35:27,499 iteration 3278 : loss : 0.030997, loss_ce: 0.011486
2022-01-16 00:35:28,488 iteration 3279 : loss : 0.040387, loss_ce: 0.019573
2022-01-16 00:35:29,447 iteration 3280 : loss : 0.032364, loss_ce: 0.013853
2022-01-16 00:35:30,396 iteration 3281 : loss : 0.022332, loss_ce: 0.006618
 48%|██████████████▉                | 193/400 [55:51<58:45, 17.03s/it]2022-01-16 00:35:31,364 iteration 3282 : loss : 0.026176, loss_ce: 0.011366
2022-01-16 00:35:32,417 iteration 3283 : loss : 0.042493, loss_ce: 0.014304
2022-01-16 00:35:33,330 iteration 3284 : loss : 0.031276, loss_ce: 0.016027
2022-01-16 00:35:34,170 iteration 3285 : loss : 0.026356, loss_ce: 0.010858
2022-01-16 00:35:35,167 iteration 3286 : loss : 0.027993, loss_ce: 0.008275
2022-01-16 00:35:36,147 iteration 3287 : loss : 0.033230, loss_ce: 0.015035
2022-01-16 00:35:37,096 iteration 3288 : loss : 0.030049, loss_ce: 0.011201
2022-01-16 00:35:38,050 iteration 3289 : loss : 0.037285, loss_ce: 0.011443
2022-01-16 00:35:38,937 iteration 3290 : loss : 0.022956, loss_ce: 0.006291
2022-01-16 00:35:39,939 iteration 3291 : loss : 0.025901, loss_ce: 0.008922
2022-01-16 00:35:40,856 iteration 3292 : loss : 0.032072, loss_ce: 0.013364
2022-01-16 00:35:41,722 iteration 3293 : loss : 0.020813, loss_ce: 0.007881
2022-01-16 00:35:42,602 iteration 3294 : loss : 0.036858, loss_ce: 0.014666
2022-01-16 00:35:43,531 iteration 3295 : loss : 0.027372, loss_ce: 0.012255
2022-01-16 00:35:44,482 iteration 3296 : loss : 0.025998, loss_ce: 0.008679
2022-01-16 00:35:45,391 iteration 3297 : loss : 0.042556, loss_ce: 0.017541
2022-01-16 00:35:46,247 iteration 3298 : loss : 0.029174, loss_ce: 0.011885
 48%|███████████████                | 194/400 [56:07<57:15, 16.68s/it]2022-01-16 00:35:47,201 iteration 3299 : loss : 0.022566, loss_ce: 0.008709
2022-01-16 00:35:48,105 iteration 3300 : loss : 0.034534, loss_ce: 0.018311
2022-01-16 00:35:49,084 iteration 3301 : loss : 0.026633, loss_ce: 0.008184
2022-01-16 00:35:49,954 iteration 3302 : loss : 0.027046, loss_ce: 0.009552
2022-01-16 00:35:50,945 iteration 3303 : loss : 0.032437, loss_ce: 0.011977
2022-01-16 00:35:51,911 iteration 3304 : loss : 0.024288, loss_ce: 0.013559
2022-01-16 00:35:52,890 iteration 3305 : loss : 0.030418, loss_ce: 0.011277
2022-01-16 00:35:53,787 iteration 3306 : loss : 0.026454, loss_ce: 0.011391
2022-01-16 00:35:54,813 iteration 3307 : loss : 0.027305, loss_ce: 0.010161
2022-01-16 00:35:55,840 iteration 3308 : loss : 0.033178, loss_ce: 0.013426
2022-01-16 00:35:56,804 iteration 3309 : loss : 0.026124, loss_ce: 0.012278
2022-01-16 00:35:57,824 iteration 3310 : loss : 0.034670, loss_ce: 0.010642
2022-01-16 00:35:58,751 iteration 3311 : loss : 0.025208, loss_ce: 0.008235
2022-01-16 00:35:59,633 iteration 3312 : loss : 0.020740, loss_ce: 0.009649
2022-01-16 00:36:00,622 iteration 3313 : loss : 0.029223, loss_ce: 0.010881
2022-01-16 00:36:01,435 iteration 3314 : loss : 0.026265, loss_ce: 0.011185
2022-01-16 00:36:01,436 Training Data Eval:
2022-01-16 00:36:05,823   Average segmentation loss on training set: 0.0224
2022-01-16 00:36:05,823 Validation Data Eval:
2022-01-16 00:36:07,274   Average segmentation loss on validation set: 0.1306
2022-01-16 00:36:08,153 iteration 3315 : loss : 0.030584, loss_ce: 0.011761
 49%|██████████████▏              | 195/400 [56:29<1:02:19, 18.24s/it]2022-01-16 00:36:09,134 iteration 3316 : loss : 0.024885, loss_ce: 0.006306
2022-01-16 00:36:10,088 iteration 3317 : loss : 0.043642, loss_ce: 0.016245
2022-01-16 00:36:11,036 iteration 3318 : loss : 0.028758, loss_ce: 0.012712
2022-01-16 00:36:11,919 iteration 3319 : loss : 0.022381, loss_ce: 0.009019
2022-01-16 00:36:12,966 iteration 3320 : loss : 0.025884, loss_ce: 0.009474
2022-01-16 00:36:13,834 iteration 3321 : loss : 0.019859, loss_ce: 0.009486
2022-01-16 00:36:14,672 iteration 3322 : loss : 0.020994, loss_ce: 0.007619
2022-01-16 00:36:15,622 iteration 3323 : loss : 0.037373, loss_ce: 0.019395
2022-01-16 00:36:16,558 iteration 3324 : loss : 0.026435, loss_ce: 0.009098
2022-01-16 00:36:17,566 iteration 3325 : loss : 0.034735, loss_ce: 0.012017
2022-01-16 00:36:18,523 iteration 3326 : loss : 0.024524, loss_ce: 0.009562
2022-01-16 00:36:19,629 iteration 3327 : loss : 0.048132, loss_ce: 0.017404
2022-01-16 00:36:20,534 iteration 3328 : loss : 0.024737, loss_ce: 0.012374
2022-01-16 00:36:21,436 iteration 3329 : loss : 0.025578, loss_ce: 0.009731
2022-01-16 00:36:22,391 iteration 3330 : loss : 0.033749, loss_ce: 0.016449
2022-01-16 00:36:23,233 iteration 3331 : loss : 0.023513, loss_ce: 0.009495
2022-01-16 00:36:24,058 iteration 3332 : loss : 0.025341, loss_ce: 0.008349
 49%|███████████████▏               | 196/400 [56:45<59:39, 17.54s/it]2022-01-16 00:36:25,054 iteration 3333 : loss : 0.030124, loss_ce: 0.011930
2022-01-16 00:36:26,004 iteration 3334 : loss : 0.030045, loss_ce: 0.016006
2022-01-16 00:36:27,012 iteration 3335 : loss : 0.029582, loss_ce: 0.012525
2022-01-16 00:36:27,897 iteration 3336 : loss : 0.025116, loss_ce: 0.008546
2022-01-16 00:36:28,769 iteration 3337 : loss : 0.023709, loss_ce: 0.008671
2022-01-16 00:36:29,742 iteration 3338 : loss : 0.035320, loss_ce: 0.011411
2022-01-16 00:36:30,734 iteration 3339 : loss : 0.043510, loss_ce: 0.014109
2022-01-16 00:36:31,684 iteration 3340 : loss : 0.034535, loss_ce: 0.012660
2022-01-16 00:36:32,584 iteration 3341 : loss : 0.026273, loss_ce: 0.011259
2022-01-16 00:36:33,477 iteration 3342 : loss : 0.029739, loss_ce: 0.016280
2022-01-16 00:36:34,394 iteration 3343 : loss : 0.031089, loss_ce: 0.014306
2022-01-16 00:36:35,391 iteration 3344 : loss : 0.029513, loss_ce: 0.009051
2022-01-16 00:36:36,394 iteration 3345 : loss : 0.023599, loss_ce: 0.011197
2022-01-16 00:36:37,343 iteration 3346 : loss : 0.036786, loss_ce: 0.011684
2022-01-16 00:36:38,261 iteration 3347 : loss : 0.021574, loss_ce: 0.007804
2022-01-16 00:36:39,279 iteration 3348 : loss : 0.026410, loss_ce: 0.011261
2022-01-16 00:36:40,164 iteration 3349 : loss : 0.038548, loss_ce: 0.010799
 49%|███████████████▎               | 197/400 [57:01<57:53, 17.11s/it]2022-01-16 00:36:41,115 iteration 3350 : loss : 0.026070, loss_ce: 0.011783
2022-01-16 00:36:42,087 iteration 3351 : loss : 0.020534, loss_ce: 0.007383
2022-01-16 00:36:42,980 iteration 3352 : loss : 0.029771, loss_ce: 0.009628
2022-01-16 00:36:43,914 iteration 3353 : loss : 0.023966, loss_ce: 0.007474
2022-01-16 00:36:44,812 iteration 3354 : loss : 0.027210, loss_ce: 0.007981
2022-01-16 00:36:45,754 iteration 3355 : loss : 0.024586, loss_ce: 0.010072
2022-01-16 00:36:46,642 iteration 3356 : loss : 0.036387, loss_ce: 0.015576
2022-01-16 00:36:47,525 iteration 3357 : loss : 0.022336, loss_ce: 0.008818
2022-01-16 00:36:48,446 iteration 3358 : loss : 0.022744, loss_ce: 0.007270
2022-01-16 00:36:49,356 iteration 3359 : loss : 0.026504, loss_ce: 0.012639
2022-01-16 00:36:50,341 iteration 3360 : loss : 0.021612, loss_ce: 0.006755
2022-01-16 00:36:51,285 iteration 3361 : loss : 0.026894, loss_ce: 0.010481
2022-01-16 00:36:52,182 iteration 3362 : loss : 0.033824, loss_ce: 0.012623
2022-01-16 00:36:53,010 iteration 3363 : loss : 0.031126, loss_ce: 0.011184
2022-01-16 00:36:53,995 iteration 3364 : loss : 0.026929, loss_ce: 0.009965
2022-01-16 00:36:54,914 iteration 3365 : loss : 0.021576, loss_ce: 0.009270
2022-01-16 00:36:55,833 iteration 3366 : loss : 0.024692, loss_ce: 0.009558
 50%|███████████████▎               | 198/400 [57:16<56:09, 16.68s/it]2022-01-16 00:36:56,945 iteration 3367 : loss : 0.036578, loss_ce: 0.013974
2022-01-16 00:36:57,876 iteration 3368 : loss : 0.024351, loss_ce: 0.011759
2022-01-16 00:36:58,830 iteration 3369 : loss : 0.027131, loss_ce: 0.013328
2022-01-16 00:36:59,709 iteration 3370 : loss : 0.027623, loss_ce: 0.007443
2022-01-16 00:37:00,627 iteration 3371 : loss : 0.020820, loss_ce: 0.008109
2022-01-16 00:37:01,626 iteration 3372 : loss : 0.032431, loss_ce: 0.009107
2022-01-16 00:37:02,580 iteration 3373 : loss : 0.024124, loss_ce: 0.009871
2022-01-16 00:37:03,605 iteration 3374 : loss : 0.022716, loss_ce: 0.009121
2022-01-16 00:37:04,659 iteration 3375 : loss : 0.030974, loss_ce: 0.010658
2022-01-16 00:37:05,516 iteration 3376 : loss : 0.019667, loss_ce: 0.006638
2022-01-16 00:37:06,502 iteration 3377 : loss : 0.024139, loss_ce: 0.010094
2022-01-16 00:37:07,400 iteration 3378 : loss : 0.029974, loss_ce: 0.009190
2022-01-16 00:37:08,368 iteration 3379 : loss : 0.024616, loss_ce: 0.008298
2022-01-16 00:37:09,248 iteration 3380 : loss : 0.022429, loss_ce: 0.006627
2022-01-16 00:37:10,201 iteration 3381 : loss : 0.030517, loss_ce: 0.016345
2022-01-16 00:37:11,170 iteration 3382 : loss : 0.036133, loss_ce: 0.015532
2022-01-16 00:37:12,099 iteration 3383 : loss : 0.023552, loss_ce: 0.010529
 50%|███████████████▍               | 199/400 [57:33<55:27, 16.56s/it]2022-01-16 00:37:13,108 iteration 3384 : loss : 0.028262, loss_ce: 0.012582
2022-01-16 00:37:14,017 iteration 3385 : loss : 0.024214, loss_ce: 0.009912
2022-01-16 00:37:14,908 iteration 3386 : loss : 0.021622, loss_ce: 0.006951
2022-01-16 00:37:15,782 iteration 3387 : loss : 0.035052, loss_ce: 0.010642
2022-01-16 00:37:16,771 iteration 3388 : loss : 0.033165, loss_ce: 0.011827
2022-01-16 00:37:17,651 iteration 3389 : loss : 0.025011, loss_ce: 0.007829
2022-01-16 00:37:18,594 iteration 3390 : loss : 0.031987, loss_ce: 0.013463
2022-01-16 00:37:19,636 iteration 3391 : loss : 0.023403, loss_ce: 0.010844
2022-01-16 00:37:20,627 iteration 3392 : loss : 0.024754, loss_ce: 0.010096
2022-01-16 00:37:21,499 iteration 3393 : loss : 0.026640, loss_ce: 0.010931
2022-01-16 00:37:22,419 iteration 3394 : loss : 0.026030, loss_ce: 0.008634
2022-01-16 00:37:23,360 iteration 3395 : loss : 0.022874, loss_ce: 0.008948
2022-01-16 00:37:24,302 iteration 3396 : loss : 0.026290, loss_ce: 0.009277
2022-01-16 00:37:25,171 iteration 3397 : loss : 0.026736, loss_ce: 0.009537
2022-01-16 00:37:26,253 iteration 3398 : loss : 0.030582, loss_ce: 0.010074
2022-01-16 00:37:27,209 iteration 3399 : loss : 0.026446, loss_ce: 0.012678
2022-01-16 00:37:27,209 Training Data Eval:
2022-01-16 00:37:31,584   Average segmentation loss on training set: 0.0215
2022-01-16 00:37:31,585 Validation Data Eval:
2022-01-16 00:37:33,041   Average segmentation loss on validation set: 0.0721
2022-01-16 00:37:33,976 iteration 3400 : loss : 0.033326, loss_ce: 0.008795
 50%|██████████████▌              | 200/400 [57:54<1:00:29, 18.15s/it]2022-01-16 00:37:35,024 iteration 3401 : loss : 0.034238, loss_ce: 0.016169
2022-01-16 00:37:35,993 iteration 3402 : loss : 0.026943, loss_ce: 0.009785
2022-01-16 00:37:37,034 iteration 3403 : loss : 0.032543, loss_ce: 0.013255
2022-01-16 00:37:37,929 iteration 3404 : loss : 0.026905, loss_ce: 0.009775
2022-01-16 00:37:38,844 iteration 3405 : loss : 0.024789, loss_ce: 0.006482
2022-01-16 00:37:39,706 iteration 3406 : loss : 0.026248, loss_ce: 0.012552
2022-01-16 00:37:40,596 iteration 3407 : loss : 0.028478, loss_ce: 0.010451
2022-01-16 00:37:41,530 iteration 3408 : loss : 0.019736, loss_ce: 0.006915
2022-01-16 00:37:42,456 iteration 3409 : loss : 0.032670, loss_ce: 0.007158
2022-01-16 00:37:43,381 iteration 3410 : loss : 0.028706, loss_ce: 0.011661
2022-01-16 00:37:44,360 iteration 3411 : loss : 0.039529, loss_ce: 0.012033
2022-01-16 00:37:45,368 iteration 3412 : loss : 0.025136, loss_ce: 0.010553
2022-01-16 00:37:46,410 iteration 3413 : loss : 0.027297, loss_ce: 0.011825
2022-01-16 00:37:47,418 iteration 3414 : loss : 0.037283, loss_ce: 0.012217
2022-01-16 00:37:48,254 iteration 3415 : loss : 0.022741, loss_ce: 0.008743
2022-01-16 00:37:49,221 iteration 3416 : loss : 0.028880, loss_ce: 0.012139
2022-01-16 00:37:50,137 iteration 3417 : loss : 0.022483, loss_ce: 0.009506
 50%|███████████████▌               | 201/400 [58:11<58:13, 17.56s/it]2022-01-16 00:37:51,246 iteration 3418 : loss : 0.041819, loss_ce: 0.012116
2022-01-16 00:37:52,209 iteration 3419 : loss : 0.025899, loss_ce: 0.012507
2022-01-16 00:37:53,091 iteration 3420 : loss : 0.026618, loss_ce: 0.013464
2022-01-16 00:37:54,038 iteration 3421 : loss : 0.036178, loss_ce: 0.011558
2022-01-16 00:37:54,971 iteration 3422 : loss : 0.030242, loss_ce: 0.009918
2022-01-16 00:37:55,970 iteration 3423 : loss : 0.034832, loss_ce: 0.015923
2022-01-16 00:37:56,845 iteration 3424 : loss : 0.026049, loss_ce: 0.009350
2022-01-16 00:37:57,795 iteration 3425 : loss : 0.034920, loss_ce: 0.019273
2022-01-16 00:37:58,706 iteration 3426 : loss : 0.021680, loss_ce: 0.006770
2022-01-16 00:37:59,766 iteration 3427 : loss : 0.046803, loss_ce: 0.016631
2022-01-16 00:38:00,727 iteration 3428 : loss : 0.025644, loss_ce: 0.012696
2022-01-16 00:38:01,697 iteration 3429 : loss : 0.023023, loss_ce: 0.010309
2022-01-16 00:38:02,665 iteration 3430 : loss : 0.020143, loss_ce: 0.006772
2022-01-16 00:38:03,671 iteration 3431 : loss : 0.027843, loss_ce: 0.010682
2022-01-16 00:38:04,573 iteration 3432 : loss : 0.029179, loss_ce: 0.008254
2022-01-16 00:38:05,519 iteration 3433 : loss : 0.027625, loss_ce: 0.007483
2022-01-16 00:38:06,427 iteration 3434 : loss : 0.022622, loss_ce: 0.006219
 50%|███████████████▋               | 202/400 [58:27<56:40, 17.18s/it]2022-01-16 00:38:07,369 iteration 3435 : loss : 0.023758, loss_ce: 0.011517
2022-01-16 00:38:08,283 iteration 3436 : loss : 0.029683, loss_ce: 0.012909
2022-01-16 00:38:09,166 iteration 3437 : loss : 0.021769, loss_ce: 0.007178
2022-01-16 00:38:10,090 iteration 3438 : loss : 0.039383, loss_ce: 0.018656
2022-01-16 00:38:11,108 iteration 3439 : loss : 0.029024, loss_ce: 0.010954
2022-01-16 00:38:12,129 iteration 3440 : loss : 0.036800, loss_ce: 0.011391
2022-01-16 00:38:12,956 iteration 3441 : loss : 0.026370, loss_ce: 0.013204
2022-01-16 00:38:13,852 iteration 3442 : loss : 0.019638, loss_ce: 0.005597
2022-01-16 00:38:14,825 iteration 3443 : loss : 0.025509, loss_ce: 0.010002
2022-01-16 00:38:15,728 iteration 3444 : loss : 0.027142, loss_ce: 0.010232
2022-01-16 00:38:16,699 iteration 3445 : loss : 0.021816, loss_ce: 0.007993
2022-01-16 00:38:17,628 iteration 3446 : loss : 0.025527, loss_ce: 0.009104
2022-01-16 00:38:18,571 iteration 3447 : loss : 0.028833, loss_ce: 0.014674
2022-01-16 00:38:19,424 iteration 3448 : loss : 0.027254, loss_ce: 0.009026
2022-01-16 00:38:20,369 iteration 3449 : loss : 0.040404, loss_ce: 0.011937
2022-01-16 00:38:21,360 iteration 3450 : loss : 0.031364, loss_ce: 0.010409
2022-01-16 00:38:22,244 iteration 3451 : loss : 0.020348, loss_ce: 0.008604
 51%|███████████████▋               | 203/400 [58:43<55:03, 16.77s/it]2022-01-16 00:38:23,241 iteration 3452 : loss : 0.023141, loss_ce: 0.007801
2022-01-16 00:38:24,235 iteration 3453 : loss : 0.032718, loss_ce: 0.010230
2022-01-16 00:38:25,240 iteration 3454 : loss : 0.030826, loss_ce: 0.009903
2022-01-16 00:38:26,208 iteration 3455 : loss : 0.032596, loss_ce: 0.013899
2022-01-16 00:38:27,169 iteration 3456 : loss : 0.026720, loss_ce: 0.010273
2022-01-16 00:38:28,146 iteration 3457 : loss : 0.030391, loss_ce: 0.010996
2022-01-16 00:38:29,132 iteration 3458 : loss : 0.023562, loss_ce: 0.010726
2022-01-16 00:38:30,169 iteration 3459 : loss : 0.032054, loss_ce: 0.015008
2022-01-16 00:38:31,155 iteration 3460 : loss : 0.029859, loss_ce: 0.010585
2022-01-16 00:38:32,104 iteration 3461 : loss : 0.038272, loss_ce: 0.014671
2022-01-16 00:38:32,993 iteration 3462 : loss : 0.021187, loss_ce: 0.007761
2022-01-16 00:38:33,850 iteration 3463 : loss : 0.023317, loss_ce: 0.007133
2022-01-16 00:38:34,771 iteration 3464 : loss : 0.025113, loss_ce: 0.010126
2022-01-16 00:38:35,654 iteration 3465 : loss : 0.030477, loss_ce: 0.010107
2022-01-16 00:38:36,621 iteration 3466 : loss : 0.021699, loss_ce: 0.008005
2022-01-16 00:38:37,665 iteration 3467 : loss : 0.029276, loss_ce: 0.011205
2022-01-16 00:38:38,747 iteration 3468 : loss : 0.024573, loss_ce: 0.007991
 51%|███████████████▊               | 204/400 [58:59<54:30, 16.69s/it]2022-01-16 00:38:39,676 iteration 3469 : loss : 0.021853, loss_ce: 0.008853
2022-01-16 00:38:40,777 iteration 3470 : loss : 0.039753, loss_ce: 0.011281
2022-01-16 00:38:41,771 iteration 3471 : loss : 0.033044, loss_ce: 0.011473
2022-01-16 00:38:42,778 iteration 3472 : loss : 0.027831, loss_ce: 0.010497
2022-01-16 00:38:43,793 iteration 3473 : loss : 0.023586, loss_ce: 0.009887
2022-01-16 00:38:44,707 iteration 3474 : loss : 0.034425, loss_ce: 0.011627
2022-01-16 00:38:45,745 iteration 3475 : loss : 0.045497, loss_ce: 0.018071
2022-01-16 00:38:46,678 iteration 3476 : loss : 0.022281, loss_ce: 0.007810
2022-01-16 00:38:47,674 iteration 3477 : loss : 0.042966, loss_ce: 0.014438
2022-01-16 00:38:48,640 iteration 3478 : loss : 0.032072, loss_ce: 0.010304
2022-01-16 00:38:49,566 iteration 3479 : loss : 0.033673, loss_ce: 0.014699
2022-01-16 00:38:50,459 iteration 3480 : loss : 0.025548, loss_ce: 0.009859
2022-01-16 00:38:51,406 iteration 3481 : loss : 0.028304, loss_ce: 0.016818
2022-01-16 00:38:52,268 iteration 3482 : loss : 0.029382, loss_ce: 0.008630
2022-01-16 00:38:53,276 iteration 3483 : loss : 0.032726, loss_ce: 0.013317
2022-01-16 00:38:54,216 iteration 3484 : loss : 0.028878, loss_ce: 0.008172
2022-01-16 00:38:54,216 Training Data Eval:
2022-01-16 00:38:58,606   Average segmentation loss on training set: 0.0197
2022-01-16 00:38:58,607 Validation Data Eval:
2022-01-16 00:39:00,068   Average segmentation loss on validation set: 0.0866
2022-01-16 00:39:01,002 iteration 3485 : loss : 0.025964, loss_ce: 0.009320
 51%|███████████████▉               | 205/400 [59:21<59:39, 18.36s/it]2022-01-16 00:39:01,967 iteration 3486 : loss : 0.022833, loss_ce: 0.007190
2022-01-16 00:39:02,913 iteration 3487 : loss : 0.031675, loss_ce: 0.012961
2022-01-16 00:39:03,905 iteration 3488 : loss : 0.041781, loss_ce: 0.026633
2022-01-16 00:39:04,801 iteration 3489 : loss : 0.029694, loss_ce: 0.010680
2022-01-16 00:39:05,815 iteration 3490 : loss : 0.028653, loss_ce: 0.011436
2022-01-16 00:39:06,795 iteration 3491 : loss : 0.028051, loss_ce: 0.011746
2022-01-16 00:39:07,641 iteration 3492 : loss : 0.024955, loss_ce: 0.006596
2022-01-16 00:39:08,667 iteration 3493 : loss : 0.032279, loss_ce: 0.007595
2022-01-16 00:39:09,634 iteration 3494 : loss : 0.028307, loss_ce: 0.014699
2022-01-16 00:39:10,473 iteration 3495 : loss : 0.019995, loss_ce: 0.008411
2022-01-16 00:39:11,436 iteration 3496 : loss : 0.061136, loss_ce: 0.014558
2022-01-16 00:39:12,444 iteration 3497 : loss : 0.027942, loss_ce: 0.014914
2022-01-16 00:39:13,393 iteration 3498 : loss : 0.023937, loss_ce: 0.009248
2022-01-16 00:39:14,402 iteration 3499 : loss : 0.073655, loss_ce: 0.022135
2022-01-16 00:39:15,322 iteration 3500 : loss : 0.030306, loss_ce: 0.008689
2022-01-16 00:39:16,281 iteration 3501 : loss : 0.027793, loss_ce: 0.009835
2022-01-16 00:39:17,230 iteration 3502 : loss : 0.031299, loss_ce: 0.010083
 52%|███████████████▉               | 206/400 [59:38<57:17, 17.72s/it]2022-01-16 00:39:18,161 iteration 3503 : loss : 0.020158, loss_ce: 0.009646
2022-01-16 00:39:19,118 iteration 3504 : loss : 0.031288, loss_ce: 0.010619
2022-01-16 00:39:20,055 iteration 3505 : loss : 0.029249, loss_ce: 0.015590
2022-01-16 00:39:21,095 iteration 3506 : loss : 0.033166, loss_ce: 0.011068
2022-01-16 00:39:22,007 iteration 3507 : loss : 0.022432, loss_ce: 0.008549
2022-01-16 00:39:22,860 iteration 3508 : loss : 0.026405, loss_ce: 0.008355
2022-01-16 00:39:23,776 iteration 3509 : loss : 0.031143, loss_ce: 0.012329
2022-01-16 00:39:24,826 iteration 3510 : loss : 0.028290, loss_ce: 0.010400
2022-01-16 00:39:25,742 iteration 3511 : loss : 0.023567, loss_ce: 0.010338
2022-01-16 00:39:26,701 iteration 3512 : loss : 0.026985, loss_ce: 0.009322
2022-01-16 00:39:27,576 iteration 3513 : loss : 0.032508, loss_ce: 0.010007
2022-01-16 00:39:28,428 iteration 3514 : loss : 0.018015, loss_ce: 0.007694
2022-01-16 00:39:29,337 iteration 3515 : loss : 0.024497, loss_ce: 0.009401
2022-01-16 00:39:30,309 iteration 3516 : loss : 0.028834, loss_ce: 0.010009
2022-01-16 00:39:31,249 iteration 3517 : loss : 0.026098, loss_ce: 0.009851
2022-01-16 00:39:32,128 iteration 3518 : loss : 0.020651, loss_ce: 0.009018
2022-01-16 00:39:33,021 iteration 3519 : loss : 0.031023, loss_ce: 0.011137
 52%|████████████████               | 207/400 [59:53<55:08, 17.14s/it]2022-01-16 00:39:34,003 iteration 3520 : loss : 0.025068, loss_ce: 0.008822
2022-01-16 00:39:34,974 iteration 3521 : loss : 0.027942, loss_ce: 0.011311
2022-01-16 00:39:35,949 iteration 3522 : loss : 0.035508, loss_ce: 0.016740
2022-01-16 00:39:37,010 iteration 3523 : loss : 0.035158, loss_ce: 0.012470
2022-01-16 00:39:37,931 iteration 3524 : loss : 0.042537, loss_ce: 0.009730
2022-01-16 00:39:38,903 iteration 3525 : loss : 0.030533, loss_ce: 0.013135
2022-01-16 00:39:39,868 iteration 3526 : loss : 0.026409, loss_ce: 0.012580
2022-01-16 00:39:40,840 iteration 3527 : loss : 0.020453, loss_ce: 0.006435
2022-01-16 00:39:41,729 iteration 3528 : loss : 0.023065, loss_ce: 0.011550
2022-01-16 00:39:42,675 iteration 3529 : loss : 0.031365, loss_ce: 0.010239
2022-01-16 00:39:43,598 iteration 3530 : loss : 0.032025, loss_ce: 0.010144
2022-01-16 00:39:44,568 iteration 3531 : loss : 0.027955, loss_ce: 0.010868
2022-01-16 00:39:45,472 iteration 3532 : loss : 0.022387, loss_ce: 0.007639
2022-01-16 00:39:46,355 iteration 3533 : loss : 0.027366, loss_ce: 0.011243
2022-01-16 00:39:47,251 iteration 3534 : loss : 0.033406, loss_ce: 0.020382
2022-01-16 00:39:48,118 iteration 3535 : loss : 0.019885, loss_ce: 0.006612
2022-01-16 00:39:48,991 iteration 3536 : loss : 0.021484, loss_ce: 0.007784
 52%|███████████████              | 208/400 [1:00:09<53:43, 16.79s/it]2022-01-16 00:39:49,960 iteration 3537 : loss : 0.027556, loss_ce: 0.010054
2022-01-16 00:39:50,893 iteration 3538 : loss : 0.040421, loss_ce: 0.011482
2022-01-16 00:39:51,869 iteration 3539 : loss : 0.028345, loss_ce: 0.013054
2022-01-16 00:39:52,751 iteration 3540 : loss : 0.026307, loss_ce: 0.005396
2022-01-16 00:39:53,755 iteration 3541 : loss : 0.019827, loss_ce: 0.008253
2022-01-16 00:39:54,664 iteration 3542 : loss : 0.023563, loss_ce: 0.006941
2022-01-16 00:39:55,630 iteration 3543 : loss : 0.025386, loss_ce: 0.012765
2022-01-16 00:39:56,626 iteration 3544 : loss : 0.026578, loss_ce: 0.009777
2022-01-16 00:39:57,533 iteration 3545 : loss : 0.027155, loss_ce: 0.009761
2022-01-16 00:39:58,372 iteration 3546 : loss : 0.024404, loss_ce: 0.011786
2022-01-16 00:39:59,351 iteration 3547 : loss : 0.026500, loss_ce: 0.009224
2022-01-16 00:40:00,331 iteration 3548 : loss : 0.022117, loss_ce: 0.007322
2022-01-16 00:40:01,276 iteration 3549 : loss : 0.024354, loss_ce: 0.011237
2022-01-16 00:40:02,162 iteration 3550 : loss : 0.023867, loss_ce: 0.007548
2022-01-16 00:40:03,169 iteration 3551 : loss : 0.038394, loss_ce: 0.012033
2022-01-16 00:40:04,173 iteration 3552 : loss : 0.031339, loss_ce: 0.011996
2022-01-16 00:40:05,181 iteration 3553 : loss : 0.032945, loss_ce: 0.012530
 52%|███████████████▏             | 209/400 [1:00:26<52:51, 16.61s/it]2022-01-16 00:40:06,172 iteration 3554 : loss : 0.023454, loss_ce: 0.010058
2022-01-16 00:40:07,163 iteration 3555 : loss : 0.030274, loss_ce: 0.013540
2022-01-16 00:40:08,090 iteration 3556 : loss : 0.031810, loss_ce: 0.010113
2022-01-16 00:40:08,999 iteration 3557 : loss : 0.024132, loss_ce: 0.011148
2022-01-16 00:40:09,861 iteration 3558 : loss : 0.023556, loss_ce: 0.007717
2022-01-16 00:40:10,897 iteration 3559 : loss : 0.030500, loss_ce: 0.011650
2022-01-16 00:40:11,819 iteration 3560 : loss : 0.028948, loss_ce: 0.008479
2022-01-16 00:40:12,791 iteration 3561 : loss : 0.026640, loss_ce: 0.012458
2022-01-16 00:40:13,728 iteration 3562 : loss : 0.026327, loss_ce: 0.009275
2022-01-16 00:40:14,662 iteration 3563 : loss : 0.022717, loss_ce: 0.007667
2022-01-16 00:40:15,631 iteration 3564 : loss : 0.026111, loss_ce: 0.008188
2022-01-16 00:40:16,504 iteration 3565 : loss : 0.022574, loss_ce: 0.008783
2022-01-16 00:40:17,325 iteration 3566 : loss : 0.019236, loss_ce: 0.007262
2022-01-16 00:40:18,180 iteration 3567 : loss : 0.026148, loss_ce: 0.008398
2022-01-16 00:40:19,152 iteration 3568 : loss : 0.020075, loss_ce: 0.007254
2022-01-16 00:40:20,038 iteration 3569 : loss : 0.019895, loss_ce: 0.008563
2022-01-16 00:40:20,038 Training Data Eval:
2022-01-16 00:40:24,425   Average segmentation loss on training set: 0.0170
2022-01-16 00:40:24,425 Validation Data Eval:
2022-01-16 00:40:25,885   Average segmentation loss on validation set: 0.0674
2022-01-16 00:40:26,777 iteration 3570 : loss : 0.022566, loss_ce: 0.007541
 52%|███████████████▏             | 210/400 [1:00:47<57:20, 18.11s/it]2022-01-16 00:40:27,800 iteration 3571 : loss : 0.032741, loss_ce: 0.013153
2022-01-16 00:40:28,811 iteration 3572 : loss : 0.023049, loss_ce: 0.008537
2022-01-16 00:40:29,772 iteration 3573 : loss : 0.030590, loss_ce: 0.011107
2022-01-16 00:40:30,669 iteration 3574 : loss : 0.021225, loss_ce: 0.010563
2022-01-16 00:40:31,556 iteration 3575 : loss : 0.023566, loss_ce: 0.009085
2022-01-16 00:40:32,458 iteration 3576 : loss : 0.027594, loss_ce: 0.009610
2022-01-16 00:40:33,427 iteration 3577 : loss : 0.024498, loss_ce: 0.009355
2022-01-16 00:40:34,348 iteration 3578 : loss : 0.023821, loss_ce: 0.010295
2022-01-16 00:40:35,293 iteration 3579 : loss : 0.021821, loss_ce: 0.007552
2022-01-16 00:40:36,274 iteration 3580 : loss : 0.037659, loss_ce: 0.016175
2022-01-16 00:40:37,255 iteration 3581 : loss : 0.033838, loss_ce: 0.010593
2022-01-16 00:40:38,216 iteration 3582 : loss : 0.051269, loss_ce: 0.020693
2022-01-16 00:40:39,145 iteration 3583 : loss : 0.034258, loss_ce: 0.009211
2022-01-16 00:40:39,995 iteration 3584 : loss : 0.022846, loss_ce: 0.008078
2022-01-16 00:40:40,894 iteration 3585 : loss : 0.029748, loss_ce: 0.013235
2022-01-16 00:40:41,762 iteration 3586 : loss : 0.017975, loss_ce: 0.005320
2022-01-16 00:40:42,697 iteration 3587 : loss : 0.018008, loss_ce: 0.007813
 53%|███████████████▎             | 211/400 [1:01:03<54:57, 17.45s/it]2022-01-16 00:40:43,753 iteration 3588 : loss : 0.021229, loss_ce: 0.008269
2022-01-16 00:40:44,772 iteration 3589 : loss : 0.051497, loss_ce: 0.011842
2022-01-16 00:40:45,725 iteration 3590 : loss : 0.030741, loss_ce: 0.008401
2022-01-16 00:40:46,640 iteration 3591 : loss : 0.024467, loss_ce: 0.007710
2022-01-16 00:40:47,563 iteration 3592 : loss : 0.019511, loss_ce: 0.007503
2022-01-16 00:40:48,534 iteration 3593 : loss : 0.030968, loss_ce: 0.015896
2022-01-16 00:40:49,464 iteration 3594 : loss : 0.032704, loss_ce: 0.008958
2022-01-16 00:40:50,383 iteration 3595 : loss : 0.031733, loss_ce: 0.011606
2022-01-16 00:40:51,277 iteration 3596 : loss : 0.026606, loss_ce: 0.010972
2022-01-16 00:40:52,222 iteration 3597 : loss : 0.024594, loss_ce: 0.009794
2022-01-16 00:40:53,196 iteration 3598 : loss : 0.033206, loss_ce: 0.013827
2022-01-16 00:40:54,169 iteration 3599 : loss : 0.063265, loss_ce: 0.017582
2022-01-16 00:40:55,053 iteration 3600 : loss : 0.023749, loss_ce: 0.012410
2022-01-16 00:40:56,014 iteration 3601 : loss : 0.021524, loss_ce: 0.008086
2022-01-16 00:40:56,990 iteration 3602 : loss : 0.032746, loss_ce: 0.012939
2022-01-16 00:40:57,897 iteration 3603 : loss : 0.026958, loss_ce: 0.012558
2022-01-16 00:40:58,824 iteration 3604 : loss : 0.043831, loss_ce: 0.012546
 53%|███████████████▎             | 212/400 [1:01:19<53:26, 17.05s/it]2022-01-16 00:40:59,944 iteration 3605 : loss : 0.034308, loss_ce: 0.013254
2022-01-16 00:41:00,821 iteration 3606 : loss : 0.040477, loss_ce: 0.009731
2022-01-16 00:41:01,652 iteration 3607 : loss : 0.015225, loss_ce: 0.005101
2022-01-16 00:41:02,647 iteration 3608 : loss : 0.040382, loss_ce: 0.014095
2022-01-16 00:41:03,636 iteration 3609 : loss : 0.041037, loss_ce: 0.015518
2022-01-16 00:41:04,506 iteration 3610 : loss : 0.017582, loss_ce: 0.007103
2022-01-16 00:41:05,429 iteration 3611 : loss : 0.030308, loss_ce: 0.014086
2022-01-16 00:41:06,313 iteration 3612 : loss : 0.022830, loss_ce: 0.009937
2022-01-16 00:41:07,254 iteration 3613 : loss : 0.026640, loss_ce: 0.009517
2022-01-16 00:41:08,149 iteration 3614 : loss : 0.031412, loss_ce: 0.011537
2022-01-16 00:41:09,067 iteration 3615 : loss : 0.026605, loss_ce: 0.008723
2022-01-16 00:41:09,983 iteration 3616 : loss : 0.024104, loss_ce: 0.010861
2022-01-16 00:41:10,946 iteration 3617 : loss : 0.032086, loss_ce: 0.015877
2022-01-16 00:41:11,917 iteration 3618 : loss : 0.022937, loss_ce: 0.008041
2022-01-16 00:41:12,833 iteration 3619 : loss : 0.021736, loss_ce: 0.007434
2022-01-16 00:41:13,782 iteration 3620 : loss : 0.026251, loss_ce: 0.008514
2022-01-16 00:41:14,699 iteration 3621 : loss : 0.021241, loss_ce: 0.009828
 53%|███████████████▍             | 213/400 [1:01:35<52:02, 16.70s/it]2022-01-16 00:41:15,713 iteration 3622 : loss : 0.024617, loss_ce: 0.007264
2022-01-16 00:41:16,661 iteration 3623 : loss : 0.028021, loss_ce: 0.010614
2022-01-16 00:41:17,619 iteration 3624 : loss : 0.031311, loss_ce: 0.012969
2022-01-16 00:41:18,471 iteration 3625 : loss : 0.023899, loss_ce: 0.009326
2022-01-16 00:41:19,422 iteration 3626 : loss : 0.030181, loss_ce: 0.009421
2022-01-16 00:41:20,393 iteration 3627 : loss : 0.044173, loss_ce: 0.019350
2022-01-16 00:41:21,367 iteration 3628 : loss : 0.046572, loss_ce: 0.015976
2022-01-16 00:41:22,382 iteration 3629 : loss : 0.045211, loss_ce: 0.020009
2022-01-16 00:41:23,339 iteration 3630 : loss : 0.032293, loss_ce: 0.015070
2022-01-16 00:41:24,286 iteration 3631 : loss : 0.022909, loss_ce: 0.008017
2022-01-16 00:41:25,271 iteration 3632 : loss : 0.028101, loss_ce: 0.014922
2022-01-16 00:41:26,257 iteration 3633 : loss : 0.033103, loss_ce: 0.010003
2022-01-16 00:41:27,155 iteration 3634 : loss : 0.036943, loss_ce: 0.014452
2022-01-16 00:41:28,223 iteration 3635 : loss : 0.030679, loss_ce: 0.015497
2022-01-16 00:41:29,073 iteration 3636 : loss : 0.019798, loss_ce: 0.009153
2022-01-16 00:41:30,007 iteration 3637 : loss : 0.020977, loss_ce: 0.007916
2022-01-16 00:41:30,970 iteration 3638 : loss : 0.023017, loss_ce: 0.008414
 54%|███████████████▌             | 214/400 [1:01:51<51:22, 16.57s/it]2022-01-16 00:41:31,996 iteration 3639 : loss : 0.047487, loss_ce: 0.015006
2022-01-16 00:41:32,983 iteration 3640 : loss : 0.029718, loss_ce: 0.009463
2022-01-16 00:41:33,968 iteration 3641 : loss : 0.025687, loss_ce: 0.009109
2022-01-16 00:41:34,880 iteration 3642 : loss : 0.030777, loss_ce: 0.013055
2022-01-16 00:41:35,853 iteration 3643 : loss : 0.028917, loss_ce: 0.009306
2022-01-16 00:41:36,829 iteration 3644 : loss : 0.023649, loss_ce: 0.010189
2022-01-16 00:41:37,864 iteration 3645 : loss : 0.039353, loss_ce: 0.012179
2022-01-16 00:41:38,839 iteration 3646 : loss : 0.027644, loss_ce: 0.012175
2022-01-16 00:41:39,762 iteration 3647 : loss : 0.022368, loss_ce: 0.009100
2022-01-16 00:41:40,730 iteration 3648 : loss : 0.029889, loss_ce: 0.012189
2022-01-16 00:41:41,562 iteration 3649 : loss : 0.025449, loss_ce: 0.009933
2022-01-16 00:41:42,516 iteration 3650 : loss : 0.027205, loss_ce: 0.011000
2022-01-16 00:41:43,409 iteration 3651 : loss : 0.022901, loss_ce: 0.008695
2022-01-16 00:41:44,275 iteration 3652 : loss : 0.025526, loss_ce: 0.010834
2022-01-16 00:41:45,266 iteration 3653 : loss : 0.045693, loss_ce: 0.019045
2022-01-16 00:41:46,183 iteration 3654 : loss : 0.022789, loss_ce: 0.009057
2022-01-16 00:41:46,183 Training Data Eval:
2022-01-16 00:41:50,578   Average segmentation loss on training set: 0.0177
2022-01-16 00:41:50,578 Validation Data Eval:
2022-01-16 00:41:52,042   Average segmentation loss on validation set: 0.0858
2022-01-16 00:41:53,126 iteration 3655 : loss : 0.050014, loss_ce: 0.018688
 54%|███████████████▌             | 215/400 [1:02:14<56:14, 18.24s/it]2022-01-16 00:41:54,114 iteration 3656 : loss : 0.026722, loss_ce: 0.008869
2022-01-16 00:41:55,099 iteration 3657 : loss : 0.022744, loss_ce: 0.009697
2022-01-16 00:41:56,037 iteration 3658 : loss : 0.020357, loss_ce: 0.009078
2022-01-16 00:41:56,910 iteration 3659 : loss : 0.028152, loss_ce: 0.010224
2022-01-16 00:41:57,932 iteration 3660 : loss : 0.026934, loss_ce: 0.010658
2022-01-16 00:41:58,864 iteration 3661 : loss : 0.034742, loss_ce: 0.014016
2022-01-16 00:41:59,740 iteration 3662 : loss : 0.025181, loss_ce: 0.011099
2022-01-16 00:42:00,667 iteration 3663 : loss : 0.023165, loss_ce: 0.008372
2022-01-16 00:42:01,634 iteration 3664 : loss : 0.024923, loss_ce: 0.006931
2022-01-16 00:42:02,689 iteration 3665 : loss : 0.035019, loss_ce: 0.010221
2022-01-16 00:42:03,689 iteration 3666 : loss : 0.025047, loss_ce: 0.010663
2022-01-16 00:42:04,603 iteration 3667 : loss : 0.029874, loss_ce: 0.010855
2022-01-16 00:42:05,525 iteration 3668 : loss : 0.035081, loss_ce: 0.013994
2022-01-16 00:42:06,486 iteration 3669 : loss : 0.040730, loss_ce: 0.013023
2022-01-16 00:42:07,354 iteration 3670 : loss : 0.025756, loss_ce: 0.011185
2022-01-16 00:42:08,272 iteration 3671 : loss : 0.040650, loss_ce: 0.010679
2022-01-16 00:42:09,184 iteration 3672 : loss : 0.037754, loss_ce: 0.010561
 54%|███████████████▋             | 216/400 [1:02:30<53:56, 17.59s/it]2022-01-16 00:42:10,168 iteration 3673 : loss : 0.022361, loss_ce: 0.008842
2022-01-16 00:42:11,186 iteration 3674 : loss : 0.021588, loss_ce: 0.010273
2022-01-16 00:42:12,206 iteration 3675 : loss : 0.030894, loss_ce: 0.012070
2022-01-16 00:42:13,211 iteration 3676 : loss : 0.026686, loss_ce: 0.007434
2022-01-16 00:42:14,180 iteration 3677 : loss : 0.024128, loss_ce: 0.010641
2022-01-16 00:42:15,208 iteration 3678 : loss : 0.030571, loss_ce: 0.009173
2022-01-16 00:42:16,066 iteration 3679 : loss : 0.021219, loss_ce: 0.007006
2022-01-16 00:42:16,950 iteration 3680 : loss : 0.022808, loss_ce: 0.009501
2022-01-16 00:42:17,889 iteration 3681 : loss : 0.044018, loss_ce: 0.017460
2022-01-16 00:42:18,738 iteration 3682 : loss : 0.019598, loss_ce: 0.006146
2022-01-16 00:42:19,665 iteration 3683 : loss : 0.025294, loss_ce: 0.010571
2022-01-16 00:42:20,533 iteration 3684 : loss : 0.026597, loss_ce: 0.010013
2022-01-16 00:42:21,441 iteration 3685 : loss : 0.021557, loss_ce: 0.007808
2022-01-16 00:42:22,457 iteration 3686 : loss : 0.022347, loss_ce: 0.009543
2022-01-16 00:42:23,481 iteration 3687 : loss : 0.037785, loss_ce: 0.017271
2022-01-16 00:42:24,456 iteration 3688 : loss : 0.027060, loss_ce: 0.010512
2022-01-16 00:42:25,437 iteration 3689 : loss : 0.028398, loss_ce: 0.008643
 54%|███████████████▋             | 217/400 [1:02:46<52:25, 17.19s/it]2022-01-16 00:42:26,579 iteration 3690 : loss : 0.022997, loss_ce: 0.009810
2022-01-16 00:42:27,498 iteration 3691 : loss : 0.066542, loss_ce: 0.022547
2022-01-16 00:42:28,466 iteration 3692 : loss : 0.024257, loss_ce: 0.006730
2022-01-16 00:42:29,352 iteration 3693 : loss : 0.017964, loss_ce: 0.005012
2022-01-16 00:42:30,316 iteration 3694 : loss : 0.027794, loss_ce: 0.008498
2022-01-16 00:42:31,271 iteration 3695 : loss : 0.026205, loss_ce: 0.009385
2022-01-16 00:42:32,161 iteration 3696 : loss : 0.017063, loss_ce: 0.006819
2022-01-16 00:42:33,048 iteration 3697 : loss : 0.038331, loss_ce: 0.011444
2022-01-16 00:42:34,075 iteration 3698 : loss : 0.044314, loss_ce: 0.013432
2022-01-16 00:42:35,017 iteration 3699 : loss : 0.031308, loss_ce: 0.015337
2022-01-16 00:42:35,948 iteration 3700 : loss : 0.025626, loss_ce: 0.008073
2022-01-16 00:42:36,811 iteration 3701 : loss : 0.024227, loss_ce: 0.012614
2022-01-16 00:42:37,788 iteration 3702 : loss : 0.035532, loss_ce: 0.012602
2022-01-16 00:42:38,731 iteration 3703 : loss : 0.019748, loss_ce: 0.006416
2022-01-16 00:42:39,665 iteration 3704 : loss : 0.027000, loss_ce: 0.009995
2022-01-16 00:42:40,620 iteration 3705 : loss : 0.028608, loss_ce: 0.013945
2022-01-16 00:42:41,492 iteration 3706 : loss : 0.027288, loss_ce: 0.007913
 55%|███████████████▊             | 218/400 [1:03:02<51:06, 16.85s/it]2022-01-16 00:42:42,515 iteration 3707 : loss : 0.072609, loss_ce: 0.010675
2022-01-16 00:42:43,583 iteration 3708 : loss : 0.043330, loss_ce: 0.013253
2022-01-16 00:42:44,529 iteration 3709 : loss : 0.025754, loss_ce: 0.007621
2022-01-16 00:42:45,375 iteration 3710 : loss : 0.020596, loss_ce: 0.008037
2022-01-16 00:42:46,429 iteration 3711 : loss : 0.027956, loss_ce: 0.011216
2022-01-16 00:42:47,315 iteration 3712 : loss : 0.038641, loss_ce: 0.012892
2022-01-16 00:42:48,180 iteration 3713 : loss : 0.019387, loss_ce: 0.007532
2022-01-16 00:42:49,157 iteration 3714 : loss : 0.042630, loss_ce: 0.020041
2022-01-16 00:42:50,062 iteration 3715 : loss : 0.021397, loss_ce: 0.008171
2022-01-16 00:42:50,998 iteration 3716 : loss : 0.034391, loss_ce: 0.014011
2022-01-16 00:42:51,953 iteration 3717 : loss : 0.030378, loss_ce: 0.015803
2022-01-16 00:42:52,935 iteration 3718 : loss : 0.031375, loss_ce: 0.010109
2022-01-16 00:42:53,983 iteration 3719 : loss : 0.030460, loss_ce: 0.010677
2022-01-16 00:42:55,018 iteration 3720 : loss : 0.030151, loss_ce: 0.012356
2022-01-16 00:42:55,971 iteration 3721 : loss : 0.026654, loss_ce: 0.010991
2022-01-16 00:42:56,988 iteration 3722 : loss : 0.032024, loss_ce: 0.009575
2022-01-16 00:42:57,908 iteration 3723 : loss : 0.031959, loss_ce: 0.016489
 55%|███████████████▉             | 219/400 [1:03:18<50:25, 16.71s/it]2022-01-16 00:42:58,900 iteration 3724 : loss : 0.029150, loss_ce: 0.015606
2022-01-16 00:42:59,886 iteration 3725 : loss : 0.028361, loss_ce: 0.011019
2022-01-16 00:43:00,818 iteration 3726 : loss : 0.034223, loss_ce: 0.014310
2022-01-16 00:43:01,769 iteration 3727 : loss : 0.020321, loss_ce: 0.007454
2022-01-16 00:43:02,614 iteration 3728 : loss : 0.023038, loss_ce: 0.010708
2022-01-16 00:43:03,587 iteration 3729 : loss : 0.026290, loss_ce: 0.009100
2022-01-16 00:43:04,480 iteration 3730 : loss : 0.024307, loss_ce: 0.008486
2022-01-16 00:43:05,474 iteration 3731 : loss : 0.034799, loss_ce: 0.016592
2022-01-16 00:43:06,408 iteration 3732 : loss : 0.026075, loss_ce: 0.011587
2022-01-16 00:43:07,268 iteration 3733 : loss : 0.019256, loss_ce: 0.005356
2022-01-16 00:43:08,242 iteration 3734 : loss : 0.035566, loss_ce: 0.011822
2022-01-16 00:43:09,251 iteration 3735 : loss : 0.026060, loss_ce: 0.008946
2022-01-16 00:43:10,214 iteration 3736 : loss : 0.026671, loss_ce: 0.011178
2022-01-16 00:43:11,222 iteration 3737 : loss : 0.034582, loss_ce: 0.015299
2022-01-16 00:43:12,164 iteration 3738 : loss : 0.040211, loss_ce: 0.013457
2022-01-16 00:43:13,097 iteration 3739 : loss : 0.033326, loss_ce: 0.010288
2022-01-16 00:43:13,097 Training Data Eval:
2022-01-16 00:43:17,473   Average segmentation loss on training set: 0.0179
2022-01-16 00:43:17,473 Validation Data Eval:
2022-01-16 00:43:18,933   Average segmentation loss on validation set: 0.0834
2022-01-16 00:43:19,808 iteration 3740 : loss : 0.028312, loss_ce: 0.008476
 55%|███████████████▉             | 220/400 [1:03:40<54:49, 18.28s/it]2022-01-16 00:43:20,823 iteration 3741 : loss : 0.035051, loss_ce: 0.019722
2022-01-16 00:43:21,743 iteration 3742 : loss : 0.022618, loss_ce: 0.008080
2022-01-16 00:43:22,651 iteration 3743 : loss : 0.024527, loss_ce: 0.006698
2022-01-16 00:43:23,610 iteration 3744 : loss : 0.029246, loss_ce: 0.014689
2022-01-16 00:43:24,636 iteration 3745 : loss : 0.029433, loss_ce: 0.016237
2022-01-16 00:43:25,549 iteration 3746 : loss : 0.033376, loss_ce: 0.009216
2022-01-16 00:43:26,534 iteration 3747 : loss : 0.031463, loss_ce: 0.013485
2022-01-16 00:43:27,539 iteration 3748 : loss : 0.029015, loss_ce: 0.011375
2022-01-16 00:43:28,485 iteration 3749 : loss : 0.026017, loss_ce: 0.007688
2022-01-16 00:43:29,541 iteration 3750 : loss : 0.036724, loss_ce: 0.014243
2022-01-16 00:43:30,470 iteration 3751 : loss : 0.032975, loss_ce: 0.016186
2022-01-16 00:43:31,379 iteration 3752 : loss : 0.024349, loss_ce: 0.009352
2022-01-16 00:43:32,298 iteration 3753 : loss : 0.025901, loss_ce: 0.008532
2022-01-16 00:43:33,154 iteration 3754 : loss : 0.027374, loss_ce: 0.013541
2022-01-16 00:43:34,097 iteration 3755 : loss : 0.025676, loss_ce: 0.010153
2022-01-16 00:43:34,998 iteration 3756 : loss : 0.020180, loss_ce: 0.007305
2022-01-16 00:43:35,936 iteration 3757 : loss : 0.026453, loss_ce: 0.010141
 55%|████████████████             | 221/400 [1:03:56<52:36, 17.63s/it]2022-01-16 00:43:36,992 iteration 3758 : loss : 0.044545, loss_ce: 0.018126
2022-01-16 00:43:37,980 iteration 3759 : loss : 0.032152, loss_ce: 0.012402
2022-01-16 00:43:38,962 iteration 3760 : loss : 0.029450, loss_ce: 0.013305
2022-01-16 00:43:39,919 iteration 3761 : loss : 0.022357, loss_ce: 0.011055
2022-01-16 00:43:40,914 iteration 3762 : loss : 0.030379, loss_ce: 0.012215
2022-01-16 00:43:41,916 iteration 3763 : loss : 0.042514, loss_ce: 0.029206
2022-01-16 00:43:42,819 iteration 3764 : loss : 0.025301, loss_ce: 0.006171
2022-01-16 00:43:43,668 iteration 3765 : loss : 0.026596, loss_ce: 0.009360
2022-01-16 00:43:44,560 iteration 3766 : loss : 0.022544, loss_ce: 0.007014
2022-01-16 00:43:45,500 iteration 3767 : loss : 0.023779, loss_ce: 0.008813
2022-01-16 00:43:46,513 iteration 3768 : loss : 0.026935, loss_ce: 0.008831
2022-01-16 00:43:47,457 iteration 3769 : loss : 0.036785, loss_ce: 0.012953
2022-01-16 00:43:48,462 iteration 3770 : loss : 0.025608, loss_ce: 0.009414
2022-01-16 00:43:49,439 iteration 3771 : loss : 0.033370, loss_ce: 0.017895
2022-01-16 00:43:50,437 iteration 3772 : loss : 0.037317, loss_ce: 0.009790
2022-01-16 00:43:51,388 iteration 3773 : loss : 0.027257, loss_ce: 0.009460
2022-01-16 00:43:52,348 iteration 3774 : loss : 0.029794, loss_ce: 0.014106
 56%|████████████████             | 222/400 [1:04:13<51:13, 17.27s/it]2022-01-16 00:43:53,408 iteration 3775 : loss : 0.040050, loss_ce: 0.016653
2022-01-16 00:43:54,356 iteration 3776 : loss : 0.019464, loss_ce: 0.007309
2022-01-16 00:43:55,296 iteration 3777 : loss : 0.023099, loss_ce: 0.008138
2022-01-16 00:43:56,301 iteration 3778 : loss : 0.032856, loss_ce: 0.013590
2022-01-16 00:43:57,190 iteration 3779 : loss : 0.026205, loss_ce: 0.009799
2022-01-16 00:43:58,191 iteration 3780 : loss : 0.052583, loss_ce: 0.034065
2022-01-16 00:43:59,176 iteration 3781 : loss : 0.026275, loss_ce: 0.010103
2022-01-16 00:44:00,186 iteration 3782 : loss : 0.030082, loss_ce: 0.010914
2022-01-16 00:44:01,181 iteration 3783 : loss : 0.022776, loss_ce: 0.010915
2022-01-16 00:44:02,068 iteration 3784 : loss : 0.023107, loss_ce: 0.006609
2022-01-16 00:44:03,012 iteration 3785 : loss : 0.036118, loss_ce: 0.010211
2022-01-16 00:44:03,954 iteration 3786 : loss : 0.031668, loss_ce: 0.013072
2022-01-16 00:44:04,840 iteration 3787 : loss : 0.050732, loss_ce: 0.031644
2022-01-16 00:44:05,803 iteration 3788 : loss : 0.029034, loss_ce: 0.009053
2022-01-16 00:44:06,745 iteration 3789 : loss : 0.023064, loss_ce: 0.008444
2022-01-16 00:44:07,649 iteration 3790 : loss : 0.027299, loss_ce: 0.010980
2022-01-16 00:44:08,655 iteration 3791 : loss : 0.025384, loss_ce: 0.010729
 56%|████████████████▏            | 223/400 [1:04:29<50:05, 16.98s/it]2022-01-16 00:44:09,621 iteration 3792 : loss : 0.025983, loss_ce: 0.010296
2022-01-16 00:44:10,479 iteration 3793 : loss : 0.018767, loss_ce: 0.005180
2022-01-16 00:44:11,389 iteration 3794 : loss : 0.021146, loss_ce: 0.009507
2022-01-16 00:44:12,287 iteration 3795 : loss : 0.028659, loss_ce: 0.008371
2022-01-16 00:44:13,293 iteration 3796 : loss : 0.021944, loss_ce: 0.007778
2022-01-16 00:44:14,266 iteration 3797 : loss : 0.022354, loss_ce: 0.007407
2022-01-16 00:44:15,151 iteration 3798 : loss : 0.020607, loss_ce: 0.007883
2022-01-16 00:44:16,187 iteration 3799 : loss : 0.029395, loss_ce: 0.010390
2022-01-16 00:44:17,286 iteration 3800 : loss : 0.060199, loss_ce: 0.028874
2022-01-16 00:44:18,327 iteration 3801 : loss : 0.034858, loss_ce: 0.010371
2022-01-16 00:44:19,341 iteration 3802 : loss : 0.031800, loss_ce: 0.012358
2022-01-16 00:44:20,274 iteration 3803 : loss : 0.030238, loss_ce: 0.012312
2022-01-16 00:44:21,219 iteration 3804 : loss : 0.027242, loss_ce: 0.009506
2022-01-16 00:44:22,164 iteration 3805 : loss : 0.028557, loss_ce: 0.010416
2022-01-16 00:44:23,015 iteration 3806 : loss : 0.023960, loss_ce: 0.010558
2022-01-16 00:44:23,979 iteration 3807 : loss : 0.024218, loss_ce: 0.008214
2022-01-16 00:44:24,892 iteration 3808 : loss : 0.026363, loss_ce: 0.011472
 56%|████████████████▏            | 224/400 [1:04:45<49:08, 16.75s/it]2022-01-16 00:44:25,914 iteration 3809 : loss : 0.026863, loss_ce: 0.012405
2022-01-16 00:44:26,889 iteration 3810 : loss : 0.029177, loss_ce: 0.009907
2022-01-16 00:44:27,794 iteration 3811 : loss : 0.020433, loss_ce: 0.007720
2022-01-16 00:44:28,751 iteration 3812 : loss : 0.025478, loss_ce: 0.008290
2022-01-16 00:44:29,593 iteration 3813 : loss : 0.024124, loss_ce: 0.010555
2022-01-16 00:44:30,584 iteration 3814 : loss : 0.039299, loss_ce: 0.021122
2022-01-16 00:44:31,624 iteration 3815 : loss : 0.023545, loss_ce: 0.009718
2022-01-16 00:44:32,515 iteration 3816 : loss : 0.019653, loss_ce: 0.007612
2022-01-16 00:44:33,340 iteration 3817 : loss : 0.018852, loss_ce: 0.006521
2022-01-16 00:44:34,245 iteration 3818 : loss : 0.028213, loss_ce: 0.007484
2022-01-16 00:44:35,227 iteration 3819 : loss : 0.031229, loss_ce: 0.014021
2022-01-16 00:44:36,085 iteration 3820 : loss : 0.019985, loss_ce: 0.008463
2022-01-16 00:44:37,090 iteration 3821 : loss : 0.028638, loss_ce: 0.012486
2022-01-16 00:44:38,004 iteration 3822 : loss : 0.034668, loss_ce: 0.011364
2022-01-16 00:44:38,897 iteration 3823 : loss : 0.031947, loss_ce: 0.011433
2022-01-16 00:44:39,868 iteration 3824 : loss : 0.031590, loss_ce: 0.012079
2022-01-16 00:44:39,868 Training Data Eval:
2022-01-16 00:44:44,262   Average segmentation loss on training set: 0.0192
2022-01-16 00:44:44,262 Validation Data Eval:
2022-01-16 00:44:45,717   Average segmentation loss on validation set: 0.0985
2022-01-16 00:44:46,551 iteration 3825 : loss : 0.024335, loss_ce: 0.008219
 56%|████████████████▎            | 225/400 [1:05:07<53:09, 18.23s/it]2022-01-16 00:44:47,632 iteration 3826 : loss : 0.034532, loss_ce: 0.015800
2022-01-16 00:44:48,643 iteration 3827 : loss : 0.024729, loss_ce: 0.010206
2022-01-16 00:44:49,526 iteration 3828 : loss : 0.029661, loss_ce: 0.016477
2022-01-16 00:44:50,416 iteration 3829 : loss : 0.016154, loss_ce: 0.006013
2022-01-16 00:44:51,441 iteration 3830 : loss : 0.038609, loss_ce: 0.011292
2022-01-16 00:44:52,443 iteration 3831 : loss : 0.025334, loss_ce: 0.010165
2022-01-16 00:44:53,410 iteration 3832 : loss : 0.027119, loss_ce: 0.012609
2022-01-16 00:44:54,377 iteration 3833 : loss : 0.038669, loss_ce: 0.013154
2022-01-16 00:44:55,264 iteration 3834 : loss : 0.032729, loss_ce: 0.012094
2022-01-16 00:44:56,229 iteration 3835 : loss : 0.075943, loss_ce: 0.019502
2022-01-16 00:44:57,094 iteration 3836 : loss : 0.024473, loss_ce: 0.011830
2022-01-16 00:44:57,934 iteration 3837 : loss : 0.021677, loss_ce: 0.009331
2022-01-16 00:44:58,916 iteration 3838 : loss : 0.032903, loss_ce: 0.014371
2022-01-16 00:44:59,796 iteration 3839 : loss : 0.023088, loss_ce: 0.007074
2022-01-16 00:45:00,746 iteration 3840 : loss : 0.027201, loss_ce: 0.011823
2022-01-16 00:45:01,595 iteration 3841 : loss : 0.022375, loss_ce: 0.009348
2022-01-16 00:45:02,570 iteration 3842 : loss : 0.047935, loss_ce: 0.016517
 56%|████████████████▍            | 226/400 [1:05:23<50:56, 17.57s/it]2022-01-16 00:45:03,571 iteration 3843 : loss : 0.023835, loss_ce: 0.008218
2022-01-16 00:45:04,569 iteration 3844 : loss : 0.029433, loss_ce: 0.011114
2022-01-16 00:45:05,405 iteration 3845 : loss : 0.024240, loss_ce: 0.008672
2022-01-16 00:45:06,317 iteration 3846 : loss : 0.033127, loss_ce: 0.014644
2022-01-16 00:45:07,360 iteration 3847 : loss : 0.029189, loss_ce: 0.010979
2022-01-16 00:45:08,268 iteration 3848 : loss : 0.025119, loss_ce: 0.008834
2022-01-16 00:45:09,171 iteration 3849 : loss : 0.023175, loss_ce: 0.008501
2022-01-16 00:45:10,175 iteration 3850 : loss : 0.029128, loss_ce: 0.008968
2022-01-16 00:45:11,205 iteration 3851 : loss : 0.083668, loss_ce: 0.021706
2022-01-16 00:45:12,194 iteration 3852 : loss : 0.026497, loss_ce: 0.009733
2022-01-16 00:45:13,131 iteration 3853 : loss : 0.023041, loss_ce: 0.008240
2022-01-16 00:45:13,975 iteration 3854 : loss : 0.019401, loss_ce: 0.007870
2022-01-16 00:45:14,881 iteration 3855 : loss : 0.029555, loss_ce: 0.008381
2022-01-16 00:45:15,931 iteration 3856 : loss : 0.030806, loss_ce: 0.014130
2022-01-16 00:45:16,845 iteration 3857 : loss : 0.029984, loss_ce: 0.009651
2022-01-16 00:45:17,761 iteration 3858 : loss : 0.029061, loss_ce: 0.013118
2022-01-16 00:45:18,644 iteration 3859 : loss : 0.025341, loss_ce: 0.010899
 57%|████████████████▍            | 227/400 [1:05:39<49:21, 17.12s/it]2022-01-16 00:45:19,599 iteration 3860 : loss : 0.023602, loss_ce: 0.011192
2022-01-16 00:45:20,498 iteration 3861 : loss : 0.027577, loss_ce: 0.011487
2022-01-16 00:45:21,375 iteration 3862 : loss : 0.029093, loss_ce: 0.008545
2022-01-16 00:45:22,324 iteration 3863 : loss : 0.028508, loss_ce: 0.013099
2022-01-16 00:45:23,166 iteration 3864 : loss : 0.021714, loss_ce: 0.009081
2022-01-16 00:45:24,125 iteration 3865 : loss : 0.028007, loss_ce: 0.011934
2022-01-16 00:45:25,047 iteration 3866 : loss : 0.025959, loss_ce: 0.012129
2022-01-16 00:45:26,020 iteration 3867 : loss : 0.031417, loss_ce: 0.010881
2022-01-16 00:45:26,876 iteration 3868 : loss : 0.023758, loss_ce: 0.009747
2022-01-16 00:45:27,891 iteration 3869 : loss : 0.036310, loss_ce: 0.010970
2022-01-16 00:45:28,797 iteration 3870 : loss : 0.030576, loss_ce: 0.010908
2022-01-16 00:45:29,785 iteration 3871 : loss : 0.027882, loss_ce: 0.010286
2022-01-16 00:45:30,713 iteration 3872 : loss : 0.026449, loss_ce: 0.009070
2022-01-16 00:45:31,622 iteration 3873 : loss : 0.022628, loss_ce: 0.006755
2022-01-16 00:45:32,619 iteration 3874 : loss : 0.021358, loss_ce: 0.006732
2022-01-16 00:45:33,586 iteration 3875 : loss : 0.039025, loss_ce: 0.008930
2022-01-16 00:45:34,625 iteration 3876 : loss : 0.038632, loss_ce: 0.016165
 57%|████████████████▌            | 228/400 [1:05:55<48:05, 16.78s/it]2022-01-16 00:45:35,615 iteration 3877 : loss : 0.031240, loss_ce: 0.017301
2022-01-16 00:45:36,586 iteration 3878 : loss : 0.024653, loss_ce: 0.009895
2022-01-16 00:45:37,594 iteration 3879 : loss : 0.023540, loss_ce: 0.012257
2022-01-16 00:45:38,540 iteration 3880 : loss : 0.023691, loss_ce: 0.007761
2022-01-16 00:45:39,503 iteration 3881 : loss : 0.033381, loss_ce: 0.011550
2022-01-16 00:45:40,496 iteration 3882 : loss : 0.024351, loss_ce: 0.010822
2022-01-16 00:45:41,445 iteration 3883 : loss : 0.024418, loss_ce: 0.008236
2022-01-16 00:45:42,388 iteration 3884 : loss : 0.026564, loss_ce: 0.008244
2022-01-16 00:45:43,276 iteration 3885 : loss : 0.022106, loss_ce: 0.006668
2022-01-16 00:45:44,258 iteration 3886 : loss : 0.040433, loss_ce: 0.020930
2022-01-16 00:45:45,215 iteration 3887 : loss : 0.024767, loss_ce: 0.009027
2022-01-16 00:45:46,224 iteration 3888 : loss : 0.035975, loss_ce: 0.021665
2022-01-16 00:45:47,132 iteration 3889 : loss : 0.025878, loss_ce: 0.007740
2022-01-16 00:45:48,047 iteration 3890 : loss : 0.020782, loss_ce: 0.007710
2022-01-16 00:45:49,032 iteration 3891 : loss : 0.040056, loss_ce: 0.017896
2022-01-16 00:45:49,978 iteration 3892 : loss : 0.027397, loss_ce: 0.009990
2022-01-16 00:45:50,879 iteration 3893 : loss : 0.032542, loss_ce: 0.009799
 57%|████████████████▌            | 229/400 [1:06:11<47:21, 16.62s/it]2022-01-16 00:45:51,877 iteration 3894 : loss : 0.033645, loss_ce: 0.013003
2022-01-16 00:45:52,859 iteration 3895 : loss : 0.025194, loss_ce: 0.012432
2022-01-16 00:45:53,737 iteration 3896 : loss : 0.020545, loss_ce: 0.007691
2022-01-16 00:45:54,734 iteration 3897 : loss : 0.021730, loss_ce: 0.006565
2022-01-16 00:45:55,705 iteration 3898 : loss : 0.025191, loss_ce: 0.008593
2022-01-16 00:45:56,661 iteration 3899 : loss : 0.024981, loss_ce: 0.008294
2022-01-16 00:45:57,620 iteration 3900 : loss : 0.019755, loss_ce: 0.008702
2022-01-16 00:45:58,456 iteration 3901 : loss : 0.020079, loss_ce: 0.009974
2022-01-16 00:45:59,393 iteration 3902 : loss : 0.017780, loss_ce: 0.006136
2022-01-16 00:46:00,275 iteration 3903 : loss : 0.019629, loss_ce: 0.006124
2022-01-16 00:46:01,222 iteration 3904 : loss : 0.021769, loss_ce: 0.009538
2022-01-16 00:46:02,169 iteration 3905 : loss : 0.028201, loss_ce: 0.014448
2022-01-16 00:46:03,108 iteration 3906 : loss : 0.024029, loss_ce: 0.007253
2022-01-16 00:46:04,036 iteration 3907 : loss : 0.029863, loss_ce: 0.009288
2022-01-16 00:46:04,879 iteration 3908 : loss : 0.023542, loss_ce: 0.007942
2022-01-16 00:46:05,729 iteration 3909 : loss : 0.023261, loss_ce: 0.009578
2022-01-16 00:46:05,730 Training Data Eval:
2022-01-16 00:46:10,123   Average segmentation loss on training set: 0.0174
2022-01-16 00:46:10,123 Validation Data Eval:
2022-01-16 00:46:11,586   Average segmentation loss on validation set: 0.0825
2022-01-16 00:46:12,512 iteration 3910 : loss : 0.028242, loss_ce: 0.012112
 57%|████████████████▋            | 230/400 [1:06:33<51:20, 18.12s/it]2022-01-16 00:46:13,419 iteration 3911 : loss : 0.018761, loss_ce: 0.008492
2022-01-16 00:46:14,333 iteration 3912 : loss : 0.029392, loss_ce: 0.009855
2022-01-16 00:46:15,277 iteration 3913 : loss : 0.024851, loss_ce: 0.011684
2022-01-16 00:46:16,109 iteration 3914 : loss : 0.020656, loss_ce: 0.009546
2022-01-16 00:46:17,071 iteration 3915 : loss : 0.028945, loss_ce: 0.008534
2022-01-16 00:46:18,019 iteration 3916 : loss : 0.024424, loss_ce: 0.008991
2022-01-16 00:46:18,992 iteration 3917 : loss : 0.026698, loss_ce: 0.008403
2022-01-16 00:46:19,925 iteration 3918 : loss : 0.018658, loss_ce: 0.006164
2022-01-16 00:46:20,854 iteration 3919 : loss : 0.029544, loss_ce: 0.009846
2022-01-16 00:46:21,817 iteration 3920 : loss : 0.032407, loss_ce: 0.011979
2022-01-16 00:46:22,744 iteration 3921 : loss : 0.022977, loss_ce: 0.006546
2022-01-16 00:46:23,717 iteration 3922 : loss : 0.029771, loss_ce: 0.008507
2022-01-16 00:46:24,762 iteration 3923 : loss : 0.037896, loss_ce: 0.016623
2022-01-16 00:46:25,668 iteration 3924 : loss : 0.029451, loss_ce: 0.011433
2022-01-16 00:46:26,515 iteration 3925 : loss : 0.020574, loss_ce: 0.008911
2022-01-16 00:46:27,594 iteration 3926 : loss : 0.026060, loss_ce: 0.011270
2022-01-16 00:46:28,560 iteration 3927 : loss : 0.029728, loss_ce: 0.014739
 58%|████████████████▋            | 231/400 [1:06:49<49:17, 17.50s/it]2022-01-16 00:46:29,544 iteration 3928 : loss : 0.021780, loss_ce: 0.008028
2022-01-16 00:46:30,426 iteration 3929 : loss : 0.023831, loss_ce: 0.014310
2022-01-16 00:46:31,358 iteration 3930 : loss : 0.024176, loss_ce: 0.007278
2022-01-16 00:46:32,201 iteration 3931 : loss : 0.024667, loss_ce: 0.006178
2022-01-16 00:46:33,147 iteration 3932 : loss : 0.026963, loss_ce: 0.009203
2022-01-16 00:46:34,059 iteration 3933 : loss : 0.024238, loss_ce: 0.011269
2022-01-16 00:46:35,014 iteration 3934 : loss : 0.028574, loss_ce: 0.009690
2022-01-16 00:46:35,932 iteration 3935 : loss : 0.030200, loss_ce: 0.010614
2022-01-16 00:46:36,813 iteration 3936 : loss : 0.024876, loss_ce: 0.009432
2022-01-16 00:46:37,747 iteration 3937 : loss : 0.047012, loss_ce: 0.014149
2022-01-16 00:46:38,678 iteration 3938 : loss : 0.021561, loss_ce: 0.006934
2022-01-16 00:46:39,675 iteration 3939 : loss : 0.036218, loss_ce: 0.008351
2022-01-16 00:46:40,600 iteration 3940 : loss : 0.028034, loss_ce: 0.012868
2022-01-16 00:46:41,534 iteration 3941 : loss : 0.022526, loss_ce: 0.006502
2022-01-16 00:46:42,423 iteration 3942 : loss : 0.025278, loss_ce: 0.012752
2022-01-16 00:46:43,311 iteration 3943 : loss : 0.032819, loss_ce: 0.012935
2022-01-16 00:46:44,214 iteration 3944 : loss : 0.029735, loss_ce: 0.009304
 58%|████████████████▊            | 232/400 [1:07:05<47:27, 16.95s/it]2022-01-16 00:46:45,265 iteration 3945 : loss : 0.026196, loss_ce: 0.007691
2022-01-16 00:46:46,170 iteration 3946 : loss : 0.020253, loss_ce: 0.007823
2022-01-16 00:46:47,059 iteration 3947 : loss : 0.024699, loss_ce: 0.010422
2022-01-16 00:46:48,033 iteration 3948 : loss : 0.031522, loss_ce: 0.015024
2022-01-16 00:46:49,030 iteration 3949 : loss : 0.029922, loss_ce: 0.009058
2022-01-16 00:46:49,933 iteration 3950 : loss : 0.019742, loss_ce: 0.009188
2022-01-16 00:46:50,802 iteration 3951 : loss : 0.022688, loss_ce: 0.005055
2022-01-16 00:46:51,841 iteration 3952 : loss : 0.021304, loss_ce: 0.009044
2022-01-16 00:46:52,783 iteration 3953 : loss : 0.021440, loss_ce: 0.008463
2022-01-16 00:46:53,663 iteration 3954 : loss : 0.019028, loss_ce: 0.006899
2022-01-16 00:46:54,625 iteration 3955 : loss : 0.023005, loss_ce: 0.009860
2022-01-16 00:46:55,608 iteration 3956 : loss : 0.029651, loss_ce: 0.016624
2022-01-16 00:46:56,607 iteration 3957 : loss : 0.042085, loss_ce: 0.013497
2022-01-16 00:46:57,608 iteration 3958 : loss : 0.028181, loss_ce: 0.013331
2022-01-16 00:46:58,451 iteration 3959 : loss : 0.018939, loss_ce: 0.004807
2022-01-16 00:46:59,420 iteration 3960 : loss : 0.029483, loss_ce: 0.011135
2022-01-16 00:47:00,321 iteration 3961 : loss : 0.021948, loss_ce: 0.005332
 58%|████████████████▉            | 233/400 [1:07:21<46:28, 16.69s/it]2022-01-16 00:47:01,336 iteration 3962 : loss : 0.034537, loss_ce: 0.013257
2022-01-16 00:47:02,338 iteration 3963 : loss : 0.037392, loss_ce: 0.013776
2022-01-16 00:47:03,219 iteration 3964 : loss : 0.019188, loss_ce: 0.005861
2022-01-16 00:47:04,168 iteration 3965 : loss : 0.024609, loss_ce: 0.010474
2022-01-16 00:47:05,201 iteration 3966 : loss : 0.030306, loss_ce: 0.014642
2022-01-16 00:47:06,143 iteration 3967 : loss : 0.034975, loss_ce: 0.010065
2022-01-16 00:47:07,075 iteration 3968 : loss : 0.020116, loss_ce: 0.007091
2022-01-16 00:47:07,970 iteration 3969 : loss : 0.020404, loss_ce: 0.006212
2022-01-16 00:47:08,901 iteration 3970 : loss : 0.031356, loss_ce: 0.007775
2022-01-16 00:47:09,823 iteration 3971 : loss : 0.021060, loss_ce: 0.007215
2022-01-16 00:47:10,760 iteration 3972 : loss : 0.029440, loss_ce: 0.011734
2022-01-16 00:47:11,768 iteration 3973 : loss : 0.029842, loss_ce: 0.012385
2022-01-16 00:47:12,770 iteration 3974 : loss : 0.024995, loss_ce: 0.012211
2022-01-16 00:47:13,699 iteration 3975 : loss : 0.029856, loss_ce: 0.008469
2022-01-16 00:47:14,619 iteration 3976 : loss : 0.023487, loss_ce: 0.008033
2022-01-16 00:47:15,585 iteration 3977 : loss : 0.030176, loss_ce: 0.014086
2022-01-16 00:47:16,530 iteration 3978 : loss : 0.021700, loss_ce: 0.009113
 58%|████████████████▉            | 234/400 [1:07:37<45:46, 16.55s/it]2022-01-16 00:47:17,612 iteration 3979 : loss : 0.027517, loss_ce: 0.013337
2022-01-16 00:47:18,461 iteration 3980 : loss : 0.025206, loss_ce: 0.010039
2022-01-16 00:47:19,387 iteration 3981 : loss : 0.033971, loss_ce: 0.010654
2022-01-16 00:47:20,336 iteration 3982 : loss : 0.022667, loss_ce: 0.010593
2022-01-16 00:47:21,288 iteration 3983 : loss : 0.039148, loss_ce: 0.011244
2022-01-16 00:47:22,266 iteration 3984 : loss : 0.036669, loss_ce: 0.017384
2022-01-16 00:47:23,244 iteration 3985 : loss : 0.026751, loss_ce: 0.008996
2022-01-16 00:47:24,246 iteration 3986 : loss : 0.039606, loss_ce: 0.014163
2022-01-16 00:47:25,132 iteration 3987 : loss : 0.033023, loss_ce: 0.017599
2022-01-16 00:47:26,052 iteration 3988 : loss : 0.025369, loss_ce: 0.008775
2022-01-16 00:47:27,012 iteration 3989 : loss : 0.026743, loss_ce: 0.010034
2022-01-16 00:47:27,964 iteration 3990 : loss : 0.024927, loss_ce: 0.009855
2022-01-16 00:47:28,935 iteration 3991 : loss : 0.024705, loss_ce: 0.010830
2022-01-16 00:47:29,908 iteration 3992 : loss : 0.027953, loss_ce: 0.011165
2022-01-16 00:47:30,855 iteration 3993 : loss : 0.024837, loss_ce: 0.009822
2022-01-16 00:47:31,838 iteration 3994 : loss : 0.018441, loss_ce: 0.005766
2022-01-16 00:47:31,838 Training Data Eval:
2022-01-16 00:47:36,234   Average segmentation loss on training set: 0.0168
2022-01-16 00:47:36,235 Validation Data Eval:
2022-01-16 00:47:37,697   Average segmentation loss on validation set: 0.0762
2022-01-16 00:47:38,740 iteration 3995 : loss : 0.023878, loss_ce: 0.007215
 59%|█████████████████            | 235/400 [1:07:59<50:10, 18.24s/it]2022-01-16 00:47:39,735 iteration 3996 : loss : 0.022938, loss_ce: 0.010253
2022-01-16 00:47:40,618 iteration 3997 : loss : 0.025299, loss_ce: 0.011821
2022-01-16 00:47:41,479 iteration 3998 : loss : 0.024305, loss_ce: 0.007216
2022-01-16 00:47:42,472 iteration 3999 : loss : 0.047412, loss_ce: 0.015351
2022-01-16 00:47:43,410 iteration 4000 : loss : 0.022008, loss_ce: 0.009394
2022-01-16 00:47:44,389 iteration 4001 : loss : 0.021549, loss_ce: 0.011838
2022-01-16 00:47:45,234 iteration 4002 : loss : 0.021819, loss_ce: 0.008032
2022-01-16 00:47:46,224 iteration 4003 : loss : 0.052671, loss_ce: 0.016638
2022-01-16 00:47:47,210 iteration 4004 : loss : 0.027307, loss_ce: 0.011304
2022-01-16 00:47:48,172 iteration 4005 : loss : 0.022928, loss_ce: 0.008442
2022-01-16 00:47:49,051 iteration 4006 : loss : 0.037849, loss_ce: 0.012111
2022-01-16 00:47:49,979 iteration 4007 : loss : 0.029383, loss_ce: 0.009706
2022-01-16 00:47:50,888 iteration 4008 : loss : 0.019352, loss_ce: 0.008853
2022-01-16 00:47:51,820 iteration 4009 : loss : 0.017466, loss_ce: 0.006219
2022-01-16 00:47:52,764 iteration 4010 : loss : 0.029612, loss_ce: 0.010861
2022-01-16 00:47:53,679 iteration 4011 : loss : 0.026216, loss_ce: 0.009736
2022-01-16 00:47:54,625 iteration 4012 : loss : 0.025380, loss_ce: 0.009660
 59%|█████████████████            | 236/400 [1:08:15<47:56, 17.54s/it]2022-01-16 00:47:55,503 iteration 4013 : loss : 0.016920, loss_ce: 0.008235
2022-01-16 00:47:56,491 iteration 4014 : loss : 0.019695, loss_ce: 0.008345
2022-01-16 00:47:57,365 iteration 4015 : loss : 0.019271, loss_ce: 0.008694
2022-01-16 00:47:58,362 iteration 4016 : loss : 0.028424, loss_ce: 0.012142
2022-01-16 00:47:59,315 iteration 4017 : loss : 0.044343, loss_ce: 0.009790
2022-01-16 00:48:00,172 iteration 4018 : loss : 0.027531, loss_ce: 0.009240
2022-01-16 00:48:01,115 iteration 4019 : loss : 0.026158, loss_ce: 0.010105
2022-01-16 00:48:02,027 iteration 4020 : loss : 0.022153, loss_ce: 0.007030
2022-01-16 00:48:02,982 iteration 4021 : loss : 0.031146, loss_ce: 0.009640
2022-01-16 00:48:04,012 iteration 4022 : loss : 0.030754, loss_ce: 0.010425
2022-01-16 00:48:04,879 iteration 4023 : loss : 0.019147, loss_ce: 0.008623
2022-01-16 00:48:05,864 iteration 4024 : loss : 0.027166, loss_ce: 0.007452
2022-01-16 00:48:06,811 iteration 4025 : loss : 0.023325, loss_ce: 0.007546
2022-01-16 00:48:07,808 iteration 4026 : loss : 0.031424, loss_ce: 0.009578
2022-01-16 00:48:08,660 iteration 4027 : loss : 0.027901, loss_ce: 0.008197
2022-01-16 00:48:09,734 iteration 4028 : loss : 0.021036, loss_ce: 0.010435
2022-01-16 00:48:10,783 iteration 4029 : loss : 0.041079, loss_ce: 0.015214
 59%|█████████████████▏           | 237/400 [1:08:31<46:31, 17.13s/it]2022-01-16 00:48:11,778 iteration 4030 : loss : 0.024497, loss_ce: 0.008952
2022-01-16 00:48:12,705 iteration 4031 : loss : 0.024348, loss_ce: 0.011392
2022-01-16 00:48:13,559 iteration 4032 : loss : 0.020166, loss_ce: 0.005914
2022-01-16 00:48:14,439 iteration 4033 : loss : 0.021349, loss_ce: 0.008345
2022-01-16 00:48:15,410 iteration 4034 : loss : 0.033773, loss_ce: 0.017559
2022-01-16 00:48:16,387 iteration 4035 : loss : 0.027429, loss_ce: 0.008789
2022-01-16 00:48:17,343 iteration 4036 : loss : 0.020664, loss_ce: 0.008865
2022-01-16 00:48:18,232 iteration 4037 : loss : 0.021260, loss_ce: 0.010859
2022-01-16 00:48:19,156 iteration 4038 : loss : 0.041202, loss_ce: 0.020922
2022-01-16 00:48:20,103 iteration 4039 : loss : 0.038258, loss_ce: 0.012127
2022-01-16 00:48:21,024 iteration 4040 : loss : 0.029474, loss_ce: 0.009413
2022-01-16 00:48:22,015 iteration 4041 : loss : 0.027493, loss_ce: 0.010264
2022-01-16 00:48:22,992 iteration 4042 : loss : 0.031207, loss_ce: 0.011374
2022-01-16 00:48:23,942 iteration 4043 : loss : 0.025179, loss_ce: 0.009986
2022-01-16 00:48:24,872 iteration 4044 : loss : 0.033997, loss_ce: 0.015903
2022-01-16 00:48:25,823 iteration 4045 : loss : 0.043204, loss_ce: 0.010580
2022-01-16 00:48:26,818 iteration 4046 : loss : 0.035870, loss_ce: 0.011603
 60%|█████████████████▎           | 238/400 [1:08:47<45:20, 16.79s/it]2022-01-16 00:48:27,849 iteration 4047 : loss : 0.024831, loss_ce: 0.009273
2022-01-16 00:48:28,780 iteration 4048 : loss : 0.031922, loss_ce: 0.009945
2022-01-16 00:48:29,707 iteration 4049 : loss : 0.019962, loss_ce: 0.006174
2022-01-16 00:48:30,580 iteration 4050 : loss : 0.026749, loss_ce: 0.008212
2022-01-16 00:48:31,510 iteration 4051 : loss : 0.022334, loss_ce: 0.008844
2022-01-16 00:48:32,390 iteration 4052 : loss : 0.020422, loss_ce: 0.007764
2022-01-16 00:48:33,347 iteration 4053 : loss : 0.047577, loss_ce: 0.012020
2022-01-16 00:48:34,326 iteration 4054 : loss : 0.019812, loss_ce: 0.007203
2022-01-16 00:48:35,275 iteration 4055 : loss : 0.019196, loss_ce: 0.008200
2022-01-16 00:48:36,211 iteration 4056 : loss : 0.023030, loss_ce: 0.010144
2022-01-16 00:48:37,079 iteration 4057 : loss : 0.023280, loss_ce: 0.005995
2022-01-16 00:48:37,968 iteration 4058 : loss : 0.018092, loss_ce: 0.006696
2022-01-16 00:48:38,933 iteration 4059 : loss : 0.030945, loss_ce: 0.010576
2022-01-16 00:48:39,821 iteration 4060 : loss : 0.027951, loss_ce: 0.010946
2022-01-16 00:48:40,661 iteration 4061 : loss : 0.021046, loss_ce: 0.009034
2022-01-16 00:48:41,556 iteration 4062 : loss : 0.019377, loss_ce: 0.008509
2022-01-16 00:48:42,544 iteration 4063 : loss : 0.024701, loss_ce: 0.009454
 60%|█████████████████▎           | 239/400 [1:09:03<44:12, 16.47s/it]2022-01-16 00:48:43,538 iteration 4064 : loss : 0.021454, loss_ce: 0.007883
2022-01-16 00:48:44,433 iteration 4065 : loss : 0.028389, loss_ce: 0.007198
2022-01-16 00:48:45,358 iteration 4066 : loss : 0.021995, loss_ce: 0.008087
2022-01-16 00:48:46,279 iteration 4067 : loss : 0.022860, loss_ce: 0.007869
2022-01-16 00:48:47,240 iteration 4068 : loss : 0.035182, loss_ce: 0.014166
2022-01-16 00:48:48,199 iteration 4069 : loss : 0.034616, loss_ce: 0.019173
2022-01-16 00:48:49,082 iteration 4070 : loss : 0.023686, loss_ce: 0.006916
2022-01-16 00:48:50,018 iteration 4071 : loss : 0.025188, loss_ce: 0.008394
2022-01-16 00:48:50,959 iteration 4072 : loss : 0.021429, loss_ce: 0.008154
2022-01-16 00:48:51,920 iteration 4073 : loss : 0.027634, loss_ce: 0.011759
2022-01-16 00:48:52,864 iteration 4074 : loss : 0.020475, loss_ce: 0.008076
2022-01-16 00:48:53,901 iteration 4075 : loss : 0.038235, loss_ce: 0.013766
2022-01-16 00:48:54,864 iteration 4076 : loss : 0.016750, loss_ce: 0.006868
2022-01-16 00:48:55,871 iteration 4077 : loss : 0.029283, loss_ce: 0.012079
2022-01-16 00:48:56,879 iteration 4078 : loss : 0.024941, loss_ce: 0.009534
2022-01-16 00:48:57,781 iteration 4079 : loss : 0.024595, loss_ce: 0.008682
2022-01-16 00:48:57,781 Training Data Eval:
2022-01-16 00:49:02,164   Average segmentation loss on training set: 0.0160
2022-01-16 00:49:02,165 Validation Data Eval:
2022-01-16 00:49:03,622   Average segmentation loss on validation set: 0.0777
2022-01-16 00:49:04,631 iteration 4080 : loss : 0.035726, loss_ce: 0.013887
 60%|█████████████████▍           | 240/400 [1:09:25<48:26, 18.16s/it]2022-01-16 00:49:05,599 iteration 4081 : loss : 0.022511, loss_ce: 0.008645
2022-01-16 00:49:06,522 iteration 4082 : loss : 0.019938, loss_ce: 0.007210
2022-01-16 00:49:07,438 iteration 4083 : loss : 0.018271, loss_ce: 0.008104
2022-01-16 00:49:08,411 iteration 4084 : loss : 0.026338, loss_ce: 0.009377
2022-01-16 00:49:09,434 iteration 4085 : loss : 0.029846, loss_ce: 0.009531
2022-01-16 00:49:10,434 iteration 4086 : loss : 0.036103, loss_ce: 0.017637
2022-01-16 00:49:11,354 iteration 4087 : loss : 0.024910, loss_ce: 0.007549
2022-01-16 00:49:12,278 iteration 4088 : loss : 0.025688, loss_ce: 0.010899
2022-01-16 00:49:13,250 iteration 4089 : loss : 0.026173, loss_ce: 0.010032
2022-01-16 00:49:14,225 iteration 4090 : loss : 0.018100, loss_ce: 0.007069
2022-01-16 00:49:15,129 iteration 4091 : loss : 0.024288, loss_ce: 0.008315
2022-01-16 00:49:16,065 iteration 4092 : loss : 0.021885, loss_ce: 0.009241
2022-01-16 00:49:16,987 iteration 4093 : loss : 0.023253, loss_ce: 0.010035
2022-01-16 00:49:17,876 iteration 4094 : loss : 0.019313, loss_ce: 0.006558
2022-01-16 00:49:18,788 iteration 4095 : loss : 0.024071, loss_ce: 0.009444
2022-01-16 00:49:19,715 iteration 4096 : loss : 0.022884, loss_ce: 0.009995
2022-01-16 00:49:20,659 iteration 4097 : loss : 0.032200, loss_ce: 0.017455
 60%|█████████████████▍           | 241/400 [1:09:41<46:25, 17.52s/it]2022-01-16 00:49:21,698 iteration 4098 : loss : 0.029432, loss_ce: 0.012509
2022-01-16 00:49:22,607 iteration 4099 : loss : 0.039939, loss_ce: 0.011318
2022-01-16 00:49:23,479 iteration 4100 : loss : 0.019566, loss_ce: 0.008220
2022-01-16 00:49:24,375 iteration 4101 : loss : 0.018914, loss_ce: 0.007209
2022-01-16 00:49:25,316 iteration 4102 : loss : 0.025896, loss_ce: 0.010573
2022-01-16 00:49:26,214 iteration 4103 : loss : 0.016683, loss_ce: 0.006981
2022-01-16 00:49:27,090 iteration 4104 : loss : 0.019836, loss_ce: 0.008762
2022-01-16 00:49:28,036 iteration 4105 : loss : 0.024597, loss_ce: 0.009471
2022-01-16 00:49:28,906 iteration 4106 : loss : 0.032091, loss_ce: 0.005728
2022-01-16 00:49:29,948 iteration 4107 : loss : 0.021353, loss_ce: 0.010947
2022-01-16 00:49:30,933 iteration 4108 : loss : 0.028445, loss_ce: 0.010195
2022-01-16 00:49:31,807 iteration 4109 : loss : 0.022069, loss_ce: 0.005334
2022-01-16 00:49:32,758 iteration 4110 : loss : 0.025314, loss_ce: 0.011113
2022-01-16 00:49:33,756 iteration 4111 : loss : 0.027919, loss_ce: 0.009938
2022-01-16 00:49:34,658 iteration 4112 : loss : 0.029489, loss_ce: 0.011451
2022-01-16 00:49:35,614 iteration 4113 : loss : 0.022285, loss_ce: 0.008728
2022-01-16 00:49:36,635 iteration 4114 : loss : 0.038126, loss_ce: 0.015326
 60%|█████████████████▌           | 242/400 [1:09:57<44:55, 17.06s/it]2022-01-16 00:49:37,598 iteration 4115 : loss : 0.022400, loss_ce: 0.006524
2022-01-16 00:49:38,468 iteration 4116 : loss : 0.019058, loss_ce: 0.008084
2022-01-16 00:49:39,553 iteration 4117 : loss : 0.026492, loss_ce: 0.007312
2022-01-16 00:49:40,608 iteration 4118 : loss : 0.027947, loss_ce: 0.013917
2022-01-16 00:49:41,582 iteration 4119 : loss : 0.022836, loss_ce: 0.009934
2022-01-16 00:49:42,540 iteration 4120 : loss : 0.040041, loss_ce: 0.008113
2022-01-16 00:49:43,490 iteration 4121 : loss : 0.019415, loss_ce: 0.009411
2022-01-16 00:49:44,398 iteration 4122 : loss : 0.025369, loss_ce: 0.008541
2022-01-16 00:49:45,411 iteration 4123 : loss : 0.026731, loss_ce: 0.009341
2022-01-16 00:49:46,280 iteration 4124 : loss : 0.027399, loss_ce: 0.009424
2022-01-16 00:49:47,288 iteration 4125 : loss : 0.035311, loss_ce: 0.010753
2022-01-16 00:49:48,239 iteration 4126 : loss : 0.018985, loss_ce: 0.008401
2022-01-16 00:49:49,217 iteration 4127 : loss : 0.021158, loss_ce: 0.008477
2022-01-16 00:49:50,121 iteration 4128 : loss : 0.021821, loss_ce: 0.011197
2022-01-16 00:49:51,126 iteration 4129 : loss : 0.045608, loss_ce: 0.020347
2022-01-16 00:49:52,059 iteration 4130 : loss : 0.022794, loss_ce: 0.011524
2022-01-16 00:49:52,899 iteration 4131 : loss : 0.017539, loss_ce: 0.005046
 61%|█████████████████▌           | 243/400 [1:10:13<44:00, 16.82s/it]2022-01-16 00:49:53,950 iteration 4132 : loss : 0.029836, loss_ce: 0.011621
2022-01-16 00:49:54,946 iteration 4133 : loss : 0.031846, loss_ce: 0.012714
2022-01-16 00:49:55,796 iteration 4134 : loss : 0.021036, loss_ce: 0.008469
2022-01-16 00:49:56,788 iteration 4135 : loss : 0.026864, loss_ce: 0.009513
2022-01-16 00:49:57,725 iteration 4136 : loss : 0.021576, loss_ce: 0.010204
2022-01-16 00:49:58,630 iteration 4137 : loss : 0.045822, loss_ce: 0.027922
2022-01-16 00:49:59,520 iteration 4138 : loss : 0.019153, loss_ce: 0.008543
2022-01-16 00:50:00,491 iteration 4139 : loss : 0.032886, loss_ce: 0.010098
2022-01-16 00:50:01,487 iteration 4140 : loss : 0.029193, loss_ce: 0.008468
2022-01-16 00:50:02,421 iteration 4141 : loss : 0.037579, loss_ce: 0.010201
2022-01-16 00:50:03,376 iteration 4142 : loss : 0.038169, loss_ce: 0.010184
2022-01-16 00:50:04,368 iteration 4143 : loss : 0.026941, loss_ce: 0.007101
2022-01-16 00:50:05,283 iteration 4144 : loss : 0.025874, loss_ce: 0.009945
2022-01-16 00:50:06,191 iteration 4145 : loss : 0.020951, loss_ce: 0.005712
2022-01-16 00:50:07,123 iteration 4146 : loss : 0.030539, loss_ce: 0.008992
2022-01-16 00:50:08,026 iteration 4147 : loss : 0.024767, loss_ce: 0.008633
2022-01-16 00:50:08,865 iteration 4148 : loss : 0.018250, loss_ce: 0.006463
 61%|█████████████████▋           | 244/400 [1:10:29<43:04, 16.57s/it]2022-01-16 00:50:09,996 iteration 4149 : loss : 0.042339, loss_ce: 0.016218
2022-01-16 00:50:10,852 iteration 4150 : loss : 0.023116, loss_ce: 0.006469
2022-01-16 00:50:11,818 iteration 4151 : loss : 0.025301, loss_ce: 0.012950
2022-01-16 00:50:12,653 iteration 4152 : loss : 0.029533, loss_ce: 0.012560
2022-01-16 00:50:13,614 iteration 4153 : loss : 0.041385, loss_ce: 0.013519
2022-01-16 00:50:14,570 iteration 4154 : loss : 0.030618, loss_ce: 0.013013
2022-01-16 00:50:15,580 iteration 4155 : loss : 0.026209, loss_ce: 0.009894
2022-01-16 00:50:16,415 iteration 4156 : loss : 0.016197, loss_ce: 0.005856
2022-01-16 00:50:17,379 iteration 4157 : loss : 0.030022, loss_ce: 0.010064
2022-01-16 00:50:18,309 iteration 4158 : loss : 0.031696, loss_ce: 0.013154
2022-01-16 00:50:19,279 iteration 4159 : loss : 0.019111, loss_ce: 0.007737
2022-01-16 00:50:20,211 iteration 4160 : loss : 0.029395, loss_ce: 0.014375
2022-01-16 00:50:21,148 iteration 4161 : loss : 0.036552, loss_ce: 0.015784
2022-01-16 00:50:22,050 iteration 4162 : loss : 0.021864, loss_ce: 0.007817
2022-01-16 00:50:23,025 iteration 4163 : loss : 0.033707, loss_ce: 0.009033
2022-01-16 00:50:24,002 iteration 4164 : loss : 0.023120, loss_ce: 0.009410
2022-01-16 00:50:24,002 Training Data Eval:
2022-01-16 00:50:28,381   Average segmentation loss on training set: 0.0188
2022-01-16 00:50:28,381 Validation Data Eval:
2022-01-16 00:50:29,842   Average segmentation loss on validation set: 0.0879
2022-01-16 00:50:30,777 iteration 4165 : loss : 0.027377, loss_ce: 0.011708
 61%|█████████████████▊           | 245/400 [1:10:51<46:56, 18.17s/it]2022-01-16 00:50:31,723 iteration 4166 : loss : 0.023554, loss_ce: 0.010470
2022-01-16 00:50:32,681 iteration 4167 : loss : 0.043905, loss_ce: 0.011102
2022-01-16 00:50:33,659 iteration 4168 : loss : 0.027005, loss_ce: 0.010093
2022-01-16 00:50:34,609 iteration 4169 : loss : 0.023493, loss_ce: 0.009797
2022-01-16 00:50:35,592 iteration 4170 : loss : 0.026588, loss_ce: 0.010419
2022-01-16 00:50:36,487 iteration 4171 : loss : 0.035249, loss_ce: 0.018822
2022-01-16 00:50:37,401 iteration 4172 : loss : 0.023782, loss_ce: 0.008856
2022-01-16 00:50:38,245 iteration 4173 : loss : 0.019714, loss_ce: 0.006604
2022-01-16 00:50:39,226 iteration 4174 : loss : 0.026388, loss_ce: 0.008619
2022-01-16 00:50:40,182 iteration 4175 : loss : 0.023347, loss_ce: 0.007564
2022-01-16 00:50:41,166 iteration 4176 : loss : 0.034458, loss_ce: 0.010962
2022-01-16 00:50:42,032 iteration 4177 : loss : 0.019691, loss_ce: 0.008763
2022-01-16 00:50:42,953 iteration 4178 : loss : 0.017269, loss_ce: 0.007270
2022-01-16 00:50:43,931 iteration 4179 : loss : 0.021522, loss_ce: 0.007393
2022-01-16 00:50:44,957 iteration 4180 : loss : 0.025726, loss_ce: 0.008012
2022-01-16 00:50:45,923 iteration 4181 : loss : 0.032484, loss_ce: 0.014571
2022-01-16 00:50:46,921 iteration 4182 : loss : 0.023991, loss_ce: 0.010022
 62%|█████████████████▊           | 246/400 [1:11:07<45:04, 17.56s/it]2022-01-16 00:50:47,913 iteration 4183 : loss : 0.031963, loss_ce: 0.009297
2022-01-16 00:50:48,829 iteration 4184 : loss : 0.024400, loss_ce: 0.007936
2022-01-16 00:50:49,800 iteration 4185 : loss : 0.027066, loss_ce: 0.008931
2022-01-16 00:50:50,709 iteration 4186 : loss : 0.023279, loss_ce: 0.008605
2022-01-16 00:50:51,592 iteration 4187 : loss : 0.024557, loss_ce: 0.009837
2022-01-16 00:50:52,506 iteration 4188 : loss : 0.022009, loss_ce: 0.009225
2022-01-16 00:50:53,358 iteration 4189 : loss : 0.023747, loss_ce: 0.008183
2022-01-16 00:50:54,388 iteration 4190 : loss : 0.029185, loss_ce: 0.011410
2022-01-16 00:50:55,376 iteration 4191 : loss : 0.021524, loss_ce: 0.004905
2022-01-16 00:50:56,246 iteration 4192 : loss : 0.021200, loss_ce: 0.011130
2022-01-16 00:50:57,090 iteration 4193 : loss : 0.020031, loss_ce: 0.006460
2022-01-16 00:50:58,014 iteration 4194 : loss : 0.026929, loss_ce: 0.010137
2022-01-16 00:50:58,902 iteration 4195 : loss : 0.020022, loss_ce: 0.008347
2022-01-16 00:50:59,787 iteration 4196 : loss : 0.017885, loss_ce: 0.006812
2022-01-16 00:51:00,670 iteration 4197 : loss : 0.017774, loss_ce: 0.007190
2022-01-16 00:51:01,533 iteration 4198 : loss : 0.025425, loss_ce: 0.005736
2022-01-16 00:51:02,501 iteration 4199 : loss : 0.021834, loss_ce: 0.009246
 62%|█████████████████▉           | 247/400 [1:11:23<43:15, 16.97s/it]2022-01-16 00:51:03,493 iteration 4200 : loss : 0.021381, loss_ce: 0.007199
2022-01-16 00:51:04,473 iteration 4201 : loss : 0.032975, loss_ce: 0.017334
2022-01-16 00:51:05,491 iteration 4202 : loss : 0.021969, loss_ce: 0.009726
2022-01-16 00:51:06,509 iteration 4203 : loss : 0.023749, loss_ce: 0.008586
2022-01-16 00:51:07,491 iteration 4204 : loss : 0.021400, loss_ce: 0.009676
2022-01-16 00:51:08,267 iteration 4205 : loss : 0.014945, loss_ce: 0.005105
2022-01-16 00:51:09,161 iteration 4206 : loss : 0.020221, loss_ce: 0.006659
2022-01-16 00:51:10,055 iteration 4207 : loss : 0.016483, loss_ce: 0.007677
2022-01-16 00:51:11,025 iteration 4208 : loss : 0.034162, loss_ce: 0.013732
2022-01-16 00:51:11,935 iteration 4209 : loss : 0.018465, loss_ce: 0.006006
2022-01-16 00:51:12,837 iteration 4210 : loss : 0.032875, loss_ce: 0.016392
2022-01-16 00:51:13,785 iteration 4211 : loss : 0.019718, loss_ce: 0.008061
2022-01-16 00:51:14,681 iteration 4212 : loss : 0.016251, loss_ce: 0.006767
2022-01-16 00:51:15,683 iteration 4213 : loss : 0.024311, loss_ce: 0.010124
2022-01-16 00:51:16,684 iteration 4214 : loss : 0.026631, loss_ce: 0.010922
2022-01-16 00:51:17,664 iteration 4215 : loss : 0.029241, loss_ce: 0.007341
2022-01-16 00:51:18,595 iteration 4216 : loss : 0.023630, loss_ce: 0.009573
 62%|█████████████████▉           | 248/400 [1:11:39<42:19, 16.71s/it]2022-01-16 00:51:19,683 iteration 4217 : loss : 0.045436, loss_ce: 0.015948
2022-01-16 00:51:20,709 iteration 4218 : loss : 0.026846, loss_ce: 0.014639
2022-01-16 00:51:21,675 iteration 4219 : loss : 0.029072, loss_ce: 0.013195
2022-01-16 00:51:22,610 iteration 4220 : loss : 0.028484, loss_ce: 0.009634
2022-01-16 00:51:23,581 iteration 4221 : loss : 0.024718, loss_ce: 0.008826
2022-01-16 00:51:24,569 iteration 4222 : loss : 0.022037, loss_ce: 0.009261
2022-01-16 00:51:25,652 iteration 4223 : loss : 0.039377, loss_ce: 0.010657
2022-01-16 00:51:26,590 iteration 4224 : loss : 0.027765, loss_ce: 0.008326
2022-01-16 00:51:27,577 iteration 4225 : loss : 0.025913, loss_ce: 0.011880
2022-01-16 00:51:28,613 iteration 4226 : loss : 0.026558, loss_ce: 0.010811
2022-01-16 00:51:29,527 iteration 4227 : loss : 0.028261, loss_ce: 0.009154
2022-01-16 00:51:30,504 iteration 4228 : loss : 0.025430, loss_ce: 0.012999
2022-01-16 00:51:31,394 iteration 4229 : loss : 0.023696, loss_ce: 0.008864
2022-01-16 00:51:32,389 iteration 4230 : loss : 0.024480, loss_ce: 0.007058
2022-01-16 00:51:33,363 iteration 4231 : loss : 0.017762, loss_ce: 0.006302
2022-01-16 00:51:34,364 iteration 4232 : loss : 0.039349, loss_ce: 0.017105
2022-01-16 00:51:35,247 iteration 4233 : loss : 0.026200, loss_ce: 0.009487
 62%|██████████████████           | 249/400 [1:11:56<42:00, 16.69s/it]2022-01-16 00:51:36,306 iteration 4234 : loss : 0.027348, loss_ce: 0.012045
2022-01-16 00:51:37,199 iteration 4235 : loss : 0.022974, loss_ce: 0.009256
2022-01-16 00:51:38,198 iteration 4236 : loss : 0.029430, loss_ce: 0.015719
2022-01-16 00:51:39,130 iteration 4237 : loss : 0.018682, loss_ce: 0.009179
2022-01-16 00:51:40,148 iteration 4238 : loss : 0.031448, loss_ce: 0.009988
2022-01-16 00:51:41,008 iteration 4239 : loss : 0.028248, loss_ce: 0.007970
2022-01-16 00:51:42,034 iteration 4240 : loss : 0.025924, loss_ce: 0.007764
2022-01-16 00:51:42,961 iteration 4241 : loss : 0.020962, loss_ce: 0.006918
2022-01-16 00:51:43,861 iteration 4242 : loss : 0.038074, loss_ce: 0.012644
2022-01-16 00:51:44,782 iteration 4243 : loss : 0.028837, loss_ce: 0.011136
2022-01-16 00:51:45,773 iteration 4244 : loss : 0.024942, loss_ce: 0.008415
2022-01-16 00:51:46,729 iteration 4245 : loss : 0.031147, loss_ce: 0.007790
2022-01-16 00:51:47,646 iteration 4246 : loss : 0.021111, loss_ce: 0.010553
2022-01-16 00:51:48,554 iteration 4247 : loss : 0.021201, loss_ce: 0.005242
2022-01-16 00:51:49,528 iteration 4248 : loss : 0.034566, loss_ce: 0.011974
2022-01-16 00:51:50,470 iteration 4249 : loss : 0.038860, loss_ce: 0.018789
2022-01-16 00:51:50,471 Training Data Eval:
2022-01-16 00:51:54,853   Average segmentation loss on training set: 0.0154
2022-01-16 00:51:54,853 Validation Data Eval:
2022-01-16 00:51:56,312   Average segmentation loss on validation set: 0.0848
2022-01-16 00:51:57,278 iteration 4250 : loss : 0.028250, loss_ce: 0.008179
 62%|██████████████████▏          | 250/400 [1:12:18<45:43, 18.29s/it]2022-01-16 00:51:58,347 iteration 4251 : loss : 0.021539, loss_ce: 0.008022
2022-01-16 00:51:59,325 iteration 4252 : loss : 0.023474, loss_ce: 0.010559
2022-01-16 00:52:00,292 iteration 4253 : loss : 0.026621, loss_ce: 0.010349
2022-01-16 00:52:01,330 iteration 4254 : loss : 0.022442, loss_ce: 0.009275
2022-01-16 00:52:02,206 iteration 4255 : loss : 0.015744, loss_ce: 0.005750
2022-01-16 00:52:03,137 iteration 4256 : loss : 0.020303, loss_ce: 0.005239
2022-01-16 00:52:04,158 iteration 4257 : loss : 0.029978, loss_ce: 0.010887
2022-01-16 00:52:05,070 iteration 4258 : loss : 0.018948, loss_ce: 0.006846
2022-01-16 00:52:06,013 iteration 4259 : loss : 0.025297, loss_ce: 0.009818
2022-01-16 00:52:06,959 iteration 4260 : loss : 0.022816, loss_ce: 0.007365
2022-01-16 00:52:07,921 iteration 4261 : loss : 0.017049, loss_ce: 0.006667
2022-01-16 00:52:08,972 iteration 4262 : loss : 0.021811, loss_ce: 0.010885
2022-01-16 00:52:09,923 iteration 4263 : loss : 0.017878, loss_ce: 0.007133
2022-01-16 00:52:10,802 iteration 4264 : loss : 0.037748, loss_ce: 0.011670
2022-01-16 00:52:11,723 iteration 4265 : loss : 0.026353, loss_ce: 0.010018
2022-01-16 00:52:12,665 iteration 4266 : loss : 0.024023, loss_ce: 0.009233
2022-01-16 00:52:13,610 iteration 4267 : loss : 0.021826, loss_ce: 0.010476
 63%|██████████████████▏          | 251/400 [1:12:34<43:57, 17.70s/it]2022-01-16 00:52:14,614 iteration 4268 : loss : 0.026958, loss_ce: 0.010508
2022-01-16 00:52:15,497 iteration 4269 : loss : 0.016893, loss_ce: 0.006060
2022-01-16 00:52:16,398 iteration 4270 : loss : 0.021572, loss_ce: 0.003429
2022-01-16 00:52:17,287 iteration 4271 : loss : 0.018017, loss_ce: 0.007976
2022-01-16 00:52:18,274 iteration 4272 : loss : 0.021244, loss_ce: 0.007359
2022-01-16 00:52:19,230 iteration 4273 : loss : 0.021346, loss_ce: 0.009696
2022-01-16 00:52:20,205 iteration 4274 : loss : 0.028404, loss_ce: 0.013172
2022-01-16 00:52:21,007 iteration 4275 : loss : 0.017331, loss_ce: 0.006960
2022-01-16 00:52:21,887 iteration 4276 : loss : 0.033912, loss_ce: 0.011137
2022-01-16 00:52:22,782 iteration 4277 : loss : 0.015493, loss_ce: 0.006374
2022-01-16 00:52:23,690 iteration 4278 : loss : 0.025558, loss_ce: 0.007568
2022-01-16 00:52:24,547 iteration 4279 : loss : 0.019323, loss_ce: 0.006239
2022-01-16 00:52:25,414 iteration 4280 : loss : 0.019571, loss_ce: 0.005731
2022-01-16 00:52:26,482 iteration 4281 : loss : 0.025126, loss_ce: 0.010737
2022-01-16 00:52:27,432 iteration 4282 : loss : 0.019591, loss_ce: 0.007841
2022-01-16 00:52:28,276 iteration 4283 : loss : 0.019880, loss_ce: 0.008252
2022-01-16 00:52:29,187 iteration 4284 : loss : 0.025826, loss_ce: 0.011594
 63%|██████████████████▎          | 252/400 [1:12:50<42:05, 17.07s/it]2022-01-16 00:52:30,240 iteration 4285 : loss : 0.031807, loss_ce: 0.015721
2022-01-16 00:52:31,216 iteration 4286 : loss : 0.026449, loss_ce: 0.008530
2022-01-16 00:52:32,210 iteration 4287 : loss : 0.029081, loss_ce: 0.012306
2022-01-16 00:52:33,151 iteration 4288 : loss : 0.029174, loss_ce: 0.008296
2022-01-16 00:52:34,111 iteration 4289 : loss : 0.019398, loss_ce: 0.006070
2022-01-16 00:52:35,106 iteration 4290 : loss : 0.028009, loss_ce: 0.009908
2022-01-16 00:52:35,975 iteration 4291 : loss : 0.022374, loss_ce: 0.007576
2022-01-16 00:52:36,986 iteration 4292 : loss : 0.020361, loss_ce: 0.007415
2022-01-16 00:52:37,947 iteration 4293 : loss : 0.030512, loss_ce: 0.013073
2022-01-16 00:52:38,892 iteration 4294 : loss : 0.031783, loss_ce: 0.015001
2022-01-16 00:52:39,886 iteration 4295 : loss : 0.020439, loss_ce: 0.008560
2022-01-16 00:52:40,753 iteration 4296 : loss : 0.016304, loss_ce: 0.006872
2022-01-16 00:52:41,698 iteration 4297 : loss : 0.019196, loss_ce: 0.006703
2022-01-16 00:52:42,595 iteration 4298 : loss : 0.019944, loss_ce: 0.006512
2022-01-16 00:52:43,617 iteration 4299 : loss : 0.027504, loss_ce: 0.012143
2022-01-16 00:52:44,611 iteration 4300 : loss : 0.020967, loss_ce: 0.006120
2022-01-16 00:52:45,540 iteration 4301 : loss : 0.019746, loss_ce: 0.007241
 63%|██████████████████▎          | 253/400 [1:13:06<41:16, 16.85s/it]2022-01-16 00:52:46,571 iteration 4302 : loss : 0.024807, loss_ce: 0.011294
2022-01-16 00:52:47,567 iteration 4303 : loss : 0.023614, loss_ce: 0.008485
2022-01-16 00:52:48,440 iteration 4304 : loss : 0.017628, loss_ce: 0.006381
2022-01-16 00:52:49,403 iteration 4305 : loss : 0.024955, loss_ce: 0.007233
2022-01-16 00:52:50,311 iteration 4306 : loss : 0.024718, loss_ce: 0.008867
2022-01-16 00:52:51,224 iteration 4307 : loss : 0.021279, loss_ce: 0.007714
2022-01-16 00:52:52,222 iteration 4308 : loss : 0.034693, loss_ce: 0.011988
2022-01-16 00:52:53,121 iteration 4309 : loss : 0.020297, loss_ce: 0.006081
2022-01-16 00:52:54,088 iteration 4310 : loss : 0.019566, loss_ce: 0.008869
2022-01-16 00:52:55,043 iteration 4311 : loss : 0.020617, loss_ce: 0.009315
2022-01-16 00:52:56,100 iteration 4312 : loss : 0.027734, loss_ce: 0.010322
2022-01-16 00:52:57,038 iteration 4313 : loss : 0.023844, loss_ce: 0.008480
2022-01-16 00:52:57,971 iteration 4314 : loss : 0.018860, loss_ce: 0.006691
2022-01-16 00:52:58,869 iteration 4315 : loss : 0.023133, loss_ce: 0.008420
2022-01-16 00:52:59,873 iteration 4316 : loss : 0.027539, loss_ce: 0.009733
2022-01-16 00:53:00,790 iteration 4317 : loss : 0.026086, loss_ce: 0.010025
2022-01-16 00:53:01,705 iteration 4318 : loss : 0.022090, loss_ce: 0.010294
 64%|██████████████████▍          | 254/400 [1:13:22<40:30, 16.64s/it]2022-01-16 00:53:02,767 iteration 4319 : loss : 0.024166, loss_ce: 0.008257
2022-01-16 00:53:03,772 iteration 4320 : loss : 0.033013, loss_ce: 0.012193
2022-01-16 00:53:04,788 iteration 4321 : loss : 0.018508, loss_ce: 0.008708
2022-01-16 00:53:05,754 iteration 4322 : loss : 0.025286, loss_ce: 0.007742
2022-01-16 00:53:06,661 iteration 4323 : loss : 0.020666, loss_ce: 0.007650
2022-01-16 00:53:07,626 iteration 4324 : loss : 0.027028, loss_ce: 0.010958
2022-01-16 00:53:08,693 iteration 4325 : loss : 0.029981, loss_ce: 0.010049
2022-01-16 00:53:09,649 iteration 4326 : loss : 0.023853, loss_ce: 0.012783
2022-01-16 00:53:10,551 iteration 4327 : loss : 0.019562, loss_ce: 0.007685
2022-01-16 00:53:11,469 iteration 4328 : loss : 0.034243, loss_ce: 0.015437
2022-01-16 00:53:12,447 iteration 4329 : loss : 0.025815, loss_ce: 0.011197
2022-01-16 00:53:13,342 iteration 4330 : loss : 0.016859, loss_ce: 0.005883
2022-01-16 00:53:14,423 iteration 4331 : loss : 0.039263, loss_ce: 0.009770
2022-01-16 00:53:15,423 iteration 4332 : loss : 0.025584, loss_ce: 0.010839
2022-01-16 00:53:16,292 iteration 4333 : loss : 0.021303, loss_ce: 0.006416
2022-01-16 00:53:17,179 iteration 4334 : loss : 0.017708, loss_ce: 0.007302
2022-01-16 00:53:17,180 Training Data Eval:
2022-01-16 00:53:21,568   Average segmentation loss on training set: 0.0165
2022-01-16 00:53:21,568 Validation Data Eval:
2022-01-16 00:53:23,028   Average segmentation loss on validation set: 0.0782
2022-01-16 00:53:24,032 iteration 4335 : loss : 0.038852, loss_ce: 0.021732
 64%|██████████████████▍          | 255/400 [1:13:44<44:20, 18.35s/it]2022-01-16 00:53:25,034 iteration 4336 : loss : 0.022695, loss_ce: 0.008377
2022-01-16 00:53:25,998 iteration 4337 : loss : 0.026836, loss_ce: 0.011281
2022-01-16 00:53:27,039 iteration 4338 : loss : 0.034233, loss_ce: 0.013893
2022-01-16 00:53:27,948 iteration 4339 : loss : 0.028835, loss_ce: 0.008199
2022-01-16 00:53:28,912 iteration 4340 : loss : 0.019609, loss_ce: 0.007666
2022-01-16 00:53:29,886 iteration 4341 : loss : 0.032776, loss_ce: 0.013403
2022-01-16 00:53:30,814 iteration 4342 : loss : 0.032664, loss_ce: 0.010300
2022-01-16 00:53:31,775 iteration 4343 : loss : 0.016134, loss_ce: 0.005104
2022-01-16 00:53:32,678 iteration 4344 : loss : 0.024256, loss_ce: 0.007969
2022-01-16 00:53:33,611 iteration 4345 : loss : 0.028823, loss_ce: 0.008951
2022-01-16 00:53:34,511 iteration 4346 : loss : 0.019779, loss_ce: 0.008549
2022-01-16 00:53:35,493 iteration 4347 : loss : 0.030221, loss_ce: 0.009101
2022-01-16 00:53:36,453 iteration 4348 : loss : 0.029414, loss_ce: 0.015717
2022-01-16 00:53:37,396 iteration 4349 : loss : 0.022593, loss_ce: 0.007195
2022-01-16 00:53:38,308 iteration 4350 : loss : 0.019429, loss_ce: 0.007572
2022-01-16 00:53:39,178 iteration 4351 : loss : 0.023073, loss_ce: 0.010788
2022-01-16 00:53:40,090 iteration 4352 : loss : 0.019712, loss_ce: 0.007977
 64%|██████████████████▌          | 256/400 [1:14:01<42:23, 17.67s/it]2022-01-16 00:53:41,122 iteration 4353 : loss : 0.017649, loss_ce: 0.007026
2022-01-16 00:53:42,156 iteration 4354 : loss : 0.026938, loss_ce: 0.007864
2022-01-16 00:53:43,044 iteration 4355 : loss : 0.024298, loss_ce: 0.008668
2022-01-16 00:53:44,019 iteration 4356 : loss : 0.027422, loss_ce: 0.012517
2022-01-16 00:53:44,975 iteration 4357 : loss : 0.029723, loss_ce: 0.010832
2022-01-16 00:53:45,886 iteration 4358 : loss : 0.019912, loss_ce: 0.008435
2022-01-16 00:53:46,809 iteration 4359 : loss : 0.015426, loss_ce: 0.005320
2022-01-16 00:53:47,730 iteration 4360 : loss : 0.021520, loss_ce: 0.007465
2022-01-16 00:53:48,725 iteration 4361 : loss : 0.031417, loss_ce: 0.013764
2022-01-16 00:53:49,633 iteration 4362 : loss : 0.019401, loss_ce: 0.006298
2022-01-16 00:53:50,494 iteration 4363 : loss : 0.023052, loss_ce: 0.010850
2022-01-16 00:53:51,490 iteration 4364 : loss : 0.027182, loss_ce: 0.009568
2022-01-16 00:53:52,420 iteration 4365 : loss : 0.024952, loss_ce: 0.010101
2022-01-16 00:53:53,242 iteration 4366 : loss : 0.017603, loss_ce: 0.007667
2022-01-16 00:53:54,162 iteration 4367 : loss : 0.031978, loss_ce: 0.011191
2022-01-16 00:53:55,180 iteration 4368 : loss : 0.024653, loss_ce: 0.009388
2022-01-16 00:53:56,061 iteration 4369 : loss : 0.026105, loss_ce: 0.006956
 64%|██████████████████▋          | 257/400 [1:14:17<40:53, 17.15s/it]2022-01-16 00:53:57,080 iteration 4370 : loss : 0.027129, loss_ce: 0.005762
2022-01-16 00:53:58,025 iteration 4371 : loss : 0.022416, loss_ce: 0.010469
2022-01-16 00:53:58,886 iteration 4372 : loss : 0.018557, loss_ce: 0.008161
2022-01-16 00:53:59,871 iteration 4373 : loss : 0.021890, loss_ce: 0.006765
2022-01-16 00:54:00,800 iteration 4374 : loss : 0.019765, loss_ce: 0.008639
2022-01-16 00:54:01,666 iteration 4375 : loss : 0.021858, loss_ce: 0.008827
2022-01-16 00:54:02,578 iteration 4376 : loss : 0.023006, loss_ce: 0.009153
2022-01-16 00:54:03,608 iteration 4377 : loss : 0.029238, loss_ce: 0.011836
2022-01-16 00:54:04,592 iteration 4378 : loss : 0.022425, loss_ce: 0.008202
2022-01-16 00:54:05,641 iteration 4379 : loss : 0.043435, loss_ce: 0.019329
2022-01-16 00:54:06,609 iteration 4380 : loss : 0.021596, loss_ce: 0.010083
2022-01-16 00:54:07,594 iteration 4381 : loss : 0.032167, loss_ce: 0.013337
2022-01-16 00:54:08,525 iteration 4382 : loss : 0.020104, loss_ce: 0.007231
2022-01-16 00:54:09,462 iteration 4383 : loss : 0.024237, loss_ce: 0.006736
2022-01-16 00:54:10,409 iteration 4384 : loss : 0.022858, loss_ce: 0.007802
2022-01-16 00:54:11,255 iteration 4385 : loss : 0.019236, loss_ce: 0.008904
2022-01-16 00:54:12,204 iteration 4386 : loss : 0.024626, loss_ce: 0.009778
 64%|██████████████████▋          | 258/400 [1:14:33<39:53, 16.85s/it]2022-01-16 00:54:13,202 iteration 4387 : loss : 0.020225, loss_ce: 0.007518
2022-01-16 00:54:14,185 iteration 4388 : loss : 0.023596, loss_ce: 0.010609
2022-01-16 00:54:15,062 iteration 4389 : loss : 0.018717, loss_ce: 0.008110
2022-01-16 00:54:15,932 iteration 4390 : loss : 0.026751, loss_ce: 0.009119
2022-01-16 00:54:16,855 iteration 4391 : loss : 0.029578, loss_ce: 0.014207
2022-01-16 00:54:17,831 iteration 4392 : loss : 0.028632, loss_ce: 0.012615
2022-01-16 00:54:18,688 iteration 4393 : loss : 0.030770, loss_ce: 0.014189
2022-01-16 00:54:19,703 iteration 4394 : loss : 0.025616, loss_ce: 0.009776
2022-01-16 00:54:20,692 iteration 4395 : loss : 0.021651, loss_ce: 0.008238
2022-01-16 00:54:21,715 iteration 4396 : loss : 0.021041, loss_ce: 0.007725
2022-01-16 00:54:22,646 iteration 4397 : loss : 0.030834, loss_ce: 0.011188
2022-01-16 00:54:23,549 iteration 4398 : loss : 0.023619, loss_ce: 0.006929
2022-01-16 00:54:24,479 iteration 4399 : loss : 0.028571, loss_ce: 0.011089
2022-01-16 00:54:25,371 iteration 4400 : loss : 0.019225, loss_ce: 0.007947
2022-01-16 00:54:26,282 iteration 4401 : loss : 0.022447, loss_ce: 0.010101
2022-01-16 00:54:27,148 iteration 4402 : loss : 0.018995, loss_ce: 0.005968
2022-01-16 00:54:28,080 iteration 4403 : loss : 0.026007, loss_ce: 0.007495
 65%|██████████████████▊          | 259/400 [1:14:49<38:54, 16.56s/it]2022-01-16 00:54:29,028 iteration 4404 : loss : 0.020045, loss_ce: 0.009103
2022-01-16 00:54:29,996 iteration 4405 : loss : 0.027714, loss_ce: 0.007444
2022-01-16 00:54:30,950 iteration 4406 : loss : 0.025468, loss_ce: 0.008435
2022-01-16 00:54:31,827 iteration 4407 : loss : 0.018462, loss_ce: 0.006857
2022-01-16 00:54:32,668 iteration 4408 : loss : 0.023886, loss_ce: 0.006166
2022-01-16 00:54:33,604 iteration 4409 : loss : 0.019605, loss_ce: 0.009366
2022-01-16 00:54:34,549 iteration 4410 : loss : 0.025322, loss_ce: 0.009086
2022-01-16 00:54:35,560 iteration 4411 : loss : 0.016960, loss_ce: 0.007732
2022-01-16 00:54:36,437 iteration 4412 : loss : 0.022983, loss_ce: 0.009864
2022-01-16 00:54:37,449 iteration 4413 : loss : 0.031547, loss_ce: 0.009173
2022-01-16 00:54:38,290 iteration 4414 : loss : 0.017921, loss_ce: 0.007454
2022-01-16 00:54:39,241 iteration 4415 : loss : 0.023862, loss_ce: 0.009930
2022-01-16 00:54:40,140 iteration 4416 : loss : 0.035566, loss_ce: 0.007097
2022-01-16 00:54:41,076 iteration 4417 : loss : 0.036286, loss_ce: 0.012008
2022-01-16 00:54:42,027 iteration 4418 : loss : 0.022953, loss_ce: 0.010051
2022-01-16 00:54:42,990 iteration 4419 : loss : 0.021384, loss_ce: 0.007041
2022-01-16 00:54:42,990 Training Data Eval:
2022-01-16 00:54:47,388   Average segmentation loss on training set: 0.0149
2022-01-16 00:54:47,389 Validation Data Eval:
2022-01-16 00:54:48,843   Average segmentation loss on validation set: 0.0781
2022-01-16 00:54:49,717 iteration 4420 : loss : 0.017450, loss_ce: 0.007155
 65%|██████████████████▊          | 260/400 [1:15:10<42:11, 18.08s/it]2022-01-16 00:54:50,740 iteration 4421 : loss : 0.021259, loss_ce: 0.006511
2022-01-16 00:54:51,738 iteration 4422 : loss : 0.027684, loss_ce: 0.009698
2022-01-16 00:54:52,796 iteration 4423 : loss : 0.026199, loss_ce: 0.010640
2022-01-16 00:54:53,811 iteration 4424 : loss : 0.031238, loss_ce: 0.011724
2022-01-16 00:54:54,690 iteration 4425 : loss : 0.020094, loss_ce: 0.007000
2022-01-16 00:54:55,679 iteration 4426 : loss : 0.026270, loss_ce: 0.008695
2022-01-16 00:54:56,655 iteration 4427 : loss : 0.028209, loss_ce: 0.006962
2022-01-16 00:54:57,651 iteration 4428 : loss : 0.021513, loss_ce: 0.007586
2022-01-16 00:54:58,667 iteration 4429 : loss : 0.026817, loss_ce: 0.008941
2022-01-16 00:54:59,599 iteration 4430 : loss : 0.021654, loss_ce: 0.007196
2022-01-16 00:55:00,513 iteration 4431 : loss : 0.023625, loss_ce: 0.010080
2022-01-16 00:55:01,438 iteration 4432 : loss : 0.014914, loss_ce: 0.005555
2022-01-16 00:55:02,364 iteration 4433 : loss : 0.020691, loss_ce: 0.007387
2022-01-16 00:55:03,282 iteration 4434 : loss : 0.018658, loss_ce: 0.006568
2022-01-16 00:55:04,266 iteration 4435 : loss : 0.031381, loss_ce: 0.011492
2022-01-16 00:55:05,342 iteration 4436 : loss : 0.029370, loss_ce: 0.013450
2022-01-16 00:55:06,224 iteration 4437 : loss : 0.019964, loss_ce: 0.007008
 65%|██████████████████▉          | 261/400 [1:15:27<40:47, 17.61s/it]2022-01-16 00:55:07,298 iteration 4438 : loss : 0.038441, loss_ce: 0.015193
2022-01-16 00:55:08,201 iteration 4439 : loss : 0.028871, loss_ce: 0.009624
2022-01-16 00:55:09,192 iteration 4440 : loss : 0.024717, loss_ce: 0.008545
2022-01-16 00:55:10,185 iteration 4441 : loss : 0.023856, loss_ce: 0.011150
2022-01-16 00:55:11,077 iteration 4442 : loss : 0.018276, loss_ce: 0.008232
2022-01-16 00:55:12,024 iteration 4443 : loss : 0.017280, loss_ce: 0.007600
2022-01-16 00:55:12,925 iteration 4444 : loss : 0.020450, loss_ce: 0.006949
2022-01-16 00:55:13,877 iteration 4445 : loss : 0.026359, loss_ce: 0.010442
2022-01-16 00:55:14,846 iteration 4446 : loss : 0.022669, loss_ce: 0.008984
2022-01-16 00:55:15,815 iteration 4447 : loss : 0.028036, loss_ce: 0.010498
2022-01-16 00:55:16,742 iteration 4448 : loss : 0.035837, loss_ce: 0.009550
2022-01-16 00:55:17,696 iteration 4449 : loss : 0.022562, loss_ce: 0.009945
2022-01-16 00:55:18,702 iteration 4450 : loss : 0.021183, loss_ce: 0.006967
2022-01-16 00:55:19,570 iteration 4451 : loss : 0.023864, loss_ce: 0.007914
2022-01-16 00:55:20,516 iteration 4452 : loss : 0.036004, loss_ce: 0.016857
2022-01-16 00:55:21,559 iteration 4453 : loss : 0.033113, loss_ce: 0.015142
2022-01-16 00:55:22,531 iteration 4454 : loss : 0.027908, loss_ce: 0.012898
 66%|██████████████████▉          | 262/400 [1:15:43<39:36, 17.22s/it]2022-01-16 00:55:23,630 iteration 4455 : loss : 0.027130, loss_ce: 0.011139
2022-01-16 00:55:24,585 iteration 4456 : loss : 0.023433, loss_ce: 0.009962
2022-01-16 00:55:25,433 iteration 4457 : loss : 0.017759, loss_ce: 0.008818
2022-01-16 00:55:26,399 iteration 4458 : loss : 0.026599, loss_ce: 0.012946
2022-01-16 00:55:27,274 iteration 4459 : loss : 0.021195, loss_ce: 0.008097
2022-01-16 00:55:28,207 iteration 4460 : loss : 0.018141, loss_ce: 0.006891
2022-01-16 00:55:29,090 iteration 4461 : loss : 0.023768, loss_ce: 0.010651
2022-01-16 00:55:29,982 iteration 4462 : loss : 0.020247, loss_ce: 0.008077
2022-01-16 00:55:30,868 iteration 4463 : loss : 0.025606, loss_ce: 0.010163
2022-01-16 00:55:31,744 iteration 4464 : loss : 0.022078, loss_ce: 0.009160
2022-01-16 00:55:32,709 iteration 4465 : loss : 0.025106, loss_ce: 0.010412
2022-01-16 00:55:33,685 iteration 4466 : loss : 0.027966, loss_ce: 0.009808
2022-01-16 00:55:34,625 iteration 4467 : loss : 0.021327, loss_ce: 0.007814
2022-01-16 00:55:35,547 iteration 4468 : loss : 0.017404, loss_ce: 0.005651
2022-01-16 00:55:36,420 iteration 4469 : loss : 0.026268, loss_ce: 0.007391
2022-01-16 00:55:37,390 iteration 4470 : loss : 0.038963, loss_ce: 0.013032
2022-01-16 00:55:38,381 iteration 4471 : loss : 0.023262, loss_ce: 0.007087
 66%|███████████████████          | 263/400 [1:15:59<38:22, 16.81s/it]2022-01-16 00:55:39,351 iteration 4472 : loss : 0.027899, loss_ce: 0.012594
2022-01-16 00:55:40,271 iteration 4473 : loss : 0.025153, loss_ce: 0.009502
2022-01-16 00:55:41,232 iteration 4474 : loss : 0.017227, loss_ce: 0.005536
2022-01-16 00:55:42,123 iteration 4475 : loss : 0.020553, loss_ce: 0.009365
2022-01-16 00:55:42,952 iteration 4476 : loss : 0.017735, loss_ce: 0.005810
2022-01-16 00:55:43,882 iteration 4477 : loss : 0.019560, loss_ce: 0.007193
2022-01-16 00:55:44,823 iteration 4478 : loss : 0.026208, loss_ce: 0.007968
2022-01-16 00:55:45,765 iteration 4479 : loss : 0.031230, loss_ce: 0.007169
2022-01-16 00:55:46,646 iteration 4480 : loss : 0.018694, loss_ce: 0.007738
2022-01-16 00:55:47,514 iteration 4481 : loss : 0.014880, loss_ce: 0.005771
2022-01-16 00:55:48,515 iteration 4482 : loss : 0.027203, loss_ce: 0.009097
2022-01-16 00:55:49,553 iteration 4483 : loss : 0.025960, loss_ce: 0.009750
2022-01-16 00:55:50,556 iteration 4484 : loss : 0.025436, loss_ce: 0.008325
2022-01-16 00:55:51,463 iteration 4485 : loss : 0.017441, loss_ce: 0.005459
2022-01-16 00:55:52,516 iteration 4486 : loss : 0.024833, loss_ce: 0.010333
2022-01-16 00:55:53,414 iteration 4487 : loss : 0.023220, loss_ce: 0.010778
2022-01-16 00:55:54,336 iteration 4488 : loss : 0.032111, loss_ce: 0.014933
 66%|███████████████████▏         | 264/400 [1:16:15<37:31, 16.56s/it]2022-01-16 00:55:55,390 iteration 4489 : loss : 0.036643, loss_ce: 0.013909
2022-01-16 00:55:56,343 iteration 4490 : loss : 0.018217, loss_ce: 0.006630
2022-01-16 00:55:57,374 iteration 4491 : loss : 0.029699, loss_ce: 0.010839
2022-01-16 00:55:58,338 iteration 4492 : loss : 0.024740, loss_ce: 0.009587
2022-01-16 00:55:59,352 iteration 4493 : loss : 0.045253, loss_ce: 0.019170
2022-01-16 00:56:00,197 iteration 4494 : loss : 0.023628, loss_ce: 0.009200
2022-01-16 00:56:01,169 iteration 4495 : loss : 0.026284, loss_ce: 0.012753
2022-01-16 00:56:02,155 iteration 4496 : loss : 0.035324, loss_ce: 0.009865
2022-01-16 00:56:03,029 iteration 4497 : loss : 0.025890, loss_ce: 0.008524
2022-01-16 00:56:04,059 iteration 4498 : loss : 0.035809, loss_ce: 0.015569
2022-01-16 00:56:05,140 iteration 4499 : loss : 0.026287, loss_ce: 0.010472
2022-01-16 00:56:06,075 iteration 4500 : loss : 0.018645, loss_ce: 0.008038
2022-01-16 00:56:06,970 iteration 4501 : loss : 0.020179, loss_ce: 0.007516
2022-01-16 00:56:07,854 iteration 4502 : loss : 0.018761, loss_ce: 0.006852
2022-01-16 00:56:08,858 iteration 4503 : loss : 0.027482, loss_ce: 0.012987
2022-01-16 00:56:09,793 iteration 4504 : loss : 0.038415, loss_ce: 0.014008
2022-01-16 00:56:09,793 Training Data Eval:
2022-01-16 00:56:14,191   Average segmentation loss on training set: 0.0151
2022-01-16 00:56:14,191 Validation Data Eval:
2022-01-16 00:56:15,657   Average segmentation loss on validation set: 0.0714
2022-01-16 00:56:16,506 iteration 4505 : loss : 0.018192, loss_ce: 0.007150
 66%|███████████████████▏         | 265/400 [1:16:37<41:02, 18.24s/it]2022-01-16 00:56:17,562 iteration 4506 : loss : 0.023579, loss_ce: 0.007245
2022-01-16 00:56:18,457 iteration 4507 : loss : 0.015164, loss_ce: 0.004359
2022-01-16 00:56:19,449 iteration 4508 : loss : 0.028395, loss_ce: 0.008299
2022-01-16 00:56:20,406 iteration 4509 : loss : 0.022958, loss_ce: 0.007413
2022-01-16 00:56:21,349 iteration 4510 : loss : 0.018674, loss_ce: 0.006985
2022-01-16 00:56:22,245 iteration 4511 : loss : 0.021076, loss_ce: 0.007490
2022-01-16 00:56:23,175 iteration 4512 : loss : 0.016976, loss_ce: 0.007234
2022-01-16 00:56:24,133 iteration 4513 : loss : 0.019847, loss_ce: 0.009961
2022-01-16 00:56:25,000 iteration 4514 : loss : 0.017970, loss_ce: 0.006693
2022-01-16 00:56:25,912 iteration 4515 : loss : 0.024589, loss_ce: 0.008723
2022-01-16 00:56:26,971 iteration 4516 : loss : 0.023721, loss_ce: 0.009255
2022-01-16 00:56:27,901 iteration 4517 : loss : 0.023113, loss_ce: 0.007936
2022-01-16 00:56:28,871 iteration 4518 : loss : 0.019235, loss_ce: 0.005782
2022-01-16 00:56:29,812 iteration 4519 : loss : 0.021971, loss_ce: 0.010284
2022-01-16 00:56:30,700 iteration 4520 : loss : 0.019248, loss_ce: 0.006481
2022-01-16 00:56:31,656 iteration 4521 : loss : 0.029140, loss_ce: 0.008851
2022-01-16 00:56:32,535 iteration 4522 : loss : 0.019422, loss_ce: 0.009042
 66%|███████████████████▎         | 266/400 [1:16:53<39:15, 17.58s/it]2022-01-16 00:56:33,605 iteration 4523 : loss : 0.019278, loss_ce: 0.007138
2022-01-16 00:56:34,464 iteration 4524 : loss : 0.014317, loss_ce: 0.005153
2022-01-16 00:56:35,478 iteration 4525 : loss : 0.038734, loss_ce: 0.010584
2022-01-16 00:56:36,435 iteration 4526 : loss : 0.018727, loss_ce: 0.007671
2022-01-16 00:56:37,383 iteration 4527 : loss : 0.019076, loss_ce: 0.008083
2022-01-16 00:56:38,380 iteration 4528 : loss : 0.018585, loss_ce: 0.006448
2022-01-16 00:56:39,301 iteration 4529 : loss : 0.031783, loss_ce: 0.011570
2022-01-16 00:56:40,265 iteration 4530 : loss : 0.025053, loss_ce: 0.010535
2022-01-16 00:56:41,148 iteration 4531 : loss : 0.021458, loss_ce: 0.008480
2022-01-16 00:56:42,135 iteration 4532 : loss : 0.019566, loss_ce: 0.008211
2022-01-16 00:56:43,160 iteration 4533 : loss : 0.026710, loss_ce: 0.010216
2022-01-16 00:56:44,263 iteration 4534 : loss : 0.019109, loss_ce: 0.006660
2022-01-16 00:56:45,120 iteration 4535 : loss : 0.021598, loss_ce: 0.007187
2022-01-16 00:56:46,088 iteration 4536 : loss : 0.017268, loss_ce: 0.008808
2022-01-16 00:56:47,116 iteration 4537 : loss : 0.030006, loss_ce: 0.012682
2022-01-16 00:56:48,042 iteration 4538 : loss : 0.024593, loss_ce: 0.007823
2022-01-16 00:56:49,019 iteration 4539 : loss : 0.042739, loss_ce: 0.018162
 67%|███████████████████▎         | 267/400 [1:17:09<38:13, 17.25s/it]2022-01-16 00:56:50,081 iteration 4540 : loss : 0.028885, loss_ce: 0.009522
2022-01-16 00:56:50,943 iteration 4541 : loss : 0.017375, loss_ce: 0.006163
2022-01-16 00:56:51,888 iteration 4542 : loss : 0.019861, loss_ce: 0.005238
2022-01-16 00:56:52,726 iteration 4543 : loss : 0.025001, loss_ce: 0.009398
2022-01-16 00:56:53,699 iteration 4544 : loss : 0.032472, loss_ce: 0.017058
2022-01-16 00:56:54,716 iteration 4545 : loss : 0.045870, loss_ce: 0.021236
2022-01-16 00:56:55,690 iteration 4546 : loss : 0.045193, loss_ce: 0.014440
2022-01-16 00:56:56,656 iteration 4547 : loss : 0.024587, loss_ce: 0.011013
2022-01-16 00:56:57,598 iteration 4548 : loss : 0.028210, loss_ce: 0.010879
2022-01-16 00:56:58,625 iteration 4549 : loss : 0.029436, loss_ce: 0.012550
2022-01-16 00:56:59,643 iteration 4550 : loss : 0.029121, loss_ce: 0.009149
2022-01-16 00:57:00,649 iteration 4551 : loss : 0.044431, loss_ce: 0.009555
2022-01-16 00:57:01,503 iteration 4552 : loss : 0.014528, loss_ce: 0.005952
2022-01-16 00:57:02,388 iteration 4553 : loss : 0.033132, loss_ce: 0.011977
2022-01-16 00:57:03,306 iteration 4554 : loss : 0.020117, loss_ce: 0.007930
2022-01-16 00:57:04,298 iteration 4555 : loss : 0.034172, loss_ce: 0.012151
2022-01-16 00:57:05,235 iteration 4556 : loss : 0.024077, loss_ce: 0.011500
 67%|███████████████████▍         | 268/400 [1:17:26<37:15, 16.94s/it]2022-01-16 00:57:06,276 iteration 4557 : loss : 0.024367, loss_ce: 0.011849
2022-01-16 00:57:07,296 iteration 4558 : loss : 0.032324, loss_ce: 0.014232
2022-01-16 00:57:08,224 iteration 4559 : loss : 0.032796, loss_ce: 0.008502
2022-01-16 00:57:09,136 iteration 4560 : loss : 0.021088, loss_ce: 0.005698
2022-01-16 00:57:10,070 iteration 4561 : loss : 0.029453, loss_ce: 0.008898
2022-01-16 00:57:11,005 iteration 4562 : loss : 0.028768, loss_ce: 0.010854
2022-01-16 00:57:11,900 iteration 4563 : loss : 0.030826, loss_ce: 0.011604
2022-01-16 00:57:12,837 iteration 4564 : loss : 0.029103, loss_ce: 0.008573
2022-01-16 00:57:13,734 iteration 4565 : loss : 0.021100, loss_ce: 0.007970
2022-01-16 00:57:14,602 iteration 4566 : loss : 0.023201, loss_ce: 0.010424
2022-01-16 00:57:15,547 iteration 4567 : loss : 0.029487, loss_ce: 0.011956
2022-01-16 00:57:16,470 iteration 4568 : loss : 0.025829, loss_ce: 0.006775
2022-01-16 00:57:17,406 iteration 4569 : loss : 0.021847, loss_ce: 0.008383
2022-01-16 00:57:18,290 iteration 4570 : loss : 0.019856, loss_ce: 0.008129
2022-01-16 00:57:19,186 iteration 4571 : loss : 0.022119, loss_ce: 0.011349
2022-01-16 00:57:20,092 iteration 4572 : loss : 0.019068, loss_ce: 0.006550
2022-01-16 00:57:21,024 iteration 4573 : loss : 0.023382, loss_ce: 0.009726
 67%|███████████████████▌         | 269/400 [1:17:41<36:13, 16.60s/it]2022-01-16 00:57:22,015 iteration 4574 : loss : 0.023198, loss_ce: 0.007854
2022-01-16 00:57:22,907 iteration 4575 : loss : 0.020485, loss_ce: 0.008382
2022-01-16 00:57:23,876 iteration 4576 : loss : 0.016108, loss_ce: 0.008777
2022-01-16 00:57:24,868 iteration 4577 : loss : 0.021984, loss_ce: 0.007539
2022-01-16 00:57:25,808 iteration 4578 : loss : 0.020476, loss_ce: 0.008904
2022-01-16 00:57:26,725 iteration 4579 : loss : 0.023425, loss_ce: 0.010271
2022-01-16 00:57:27,639 iteration 4580 : loss : 0.019050, loss_ce: 0.007916
2022-01-16 00:57:28,680 iteration 4581 : loss : 0.035942, loss_ce: 0.010406
2022-01-16 00:57:29,622 iteration 4582 : loss : 0.021010, loss_ce: 0.008955
2022-01-16 00:57:30,570 iteration 4583 : loss : 0.021520, loss_ce: 0.008817
2022-01-16 00:57:31,479 iteration 4584 : loss : 0.022294, loss_ce: 0.007833
2022-01-16 00:57:32,441 iteration 4585 : loss : 0.022637, loss_ce: 0.006490
2022-01-16 00:57:33,346 iteration 4586 : loss : 0.020721, loss_ce: 0.009885
2022-01-16 00:57:34,373 iteration 4587 : loss : 0.023382, loss_ce: 0.007340
2022-01-16 00:57:35,278 iteration 4588 : loss : 0.016558, loss_ce: 0.004156
2022-01-16 00:57:36,208 iteration 4589 : loss : 0.020012, loss_ce: 0.008280
2022-01-16 00:57:36,208 Training Data Eval:
2022-01-16 00:57:40,606   Average segmentation loss on training set: 0.0146
2022-01-16 00:57:40,606 Validation Data Eval:
2022-01-16 00:57:42,069   Average segmentation loss on validation set: 0.1074
2022-01-16 00:57:43,131 iteration 4590 : loss : 0.024478, loss_ce: 0.008510
 68%|███████████████████▌         | 270/400 [1:18:04<39:31, 18.24s/it]2022-01-16 00:57:44,060 iteration 4591 : loss : 0.017637, loss_ce: 0.004975
2022-01-16 00:57:44,995 iteration 4592 : loss : 0.028199, loss_ce: 0.011359
2022-01-16 00:57:45,844 iteration 4593 : loss : 0.017668, loss_ce: 0.005179
2022-01-16 00:57:46,752 iteration 4594 : loss : 0.014925, loss_ce: 0.005733
2022-01-16 00:57:47,709 iteration 4595 : loss : 0.033644, loss_ce: 0.007285
2022-01-16 00:57:48,729 iteration 4596 : loss : 0.029326, loss_ce: 0.009863
2022-01-16 00:57:49,662 iteration 4597 : loss : 0.015677, loss_ce: 0.006462
2022-01-16 00:57:50,505 iteration 4598 : loss : 0.019113, loss_ce: 0.008696
2022-01-16 00:57:51,397 iteration 4599 : loss : 0.021837, loss_ce: 0.006102
2022-01-16 00:57:52,397 iteration 4600 : loss : 0.016097, loss_ce: 0.007369
2022-01-16 00:57:53,447 iteration 4601 : loss : 0.021915, loss_ce: 0.010196
2022-01-16 00:57:54,288 iteration 4602 : loss : 0.018716, loss_ce: 0.006532
2022-01-16 00:57:55,149 iteration 4603 : loss : 0.018660, loss_ce: 0.007783
2022-01-16 00:57:56,112 iteration 4604 : loss : 0.025472, loss_ce: 0.008498
2022-01-16 00:57:57,070 iteration 4605 : loss : 0.025171, loss_ce: 0.006152
2022-01-16 00:57:58,069 iteration 4606 : loss : 0.023280, loss_ce: 0.007667
2022-01-16 00:57:58,926 iteration 4607 : loss : 0.018508, loss_ce: 0.009386
 68%|███████████████████▋         | 271/400 [1:18:19<37:39, 17.51s/it]2022-01-16 00:57:59,967 iteration 4608 : loss : 0.019907, loss_ce: 0.006750
2022-01-16 00:58:00,980 iteration 4609 : loss : 0.023529, loss_ce: 0.010991
2022-01-16 00:58:01,963 iteration 4610 : loss : 0.024222, loss_ce: 0.006860
2022-01-16 00:58:02,895 iteration 4611 : loss : 0.023222, loss_ce: 0.010252
2022-01-16 00:58:03,748 iteration 4612 : loss : 0.017846, loss_ce: 0.006588
2022-01-16 00:58:04,702 iteration 4613 : loss : 0.020794, loss_ce: 0.009586
2022-01-16 00:58:05,673 iteration 4614 : loss : 0.021644, loss_ce: 0.008874
2022-01-16 00:58:06,652 iteration 4615 : loss : 0.023207, loss_ce: 0.009110
2022-01-16 00:58:07,669 iteration 4616 : loss : 0.022044, loss_ce: 0.009372
2022-01-16 00:58:08,545 iteration 4617 : loss : 0.018499, loss_ce: 0.007664
2022-01-16 00:58:09,526 iteration 4618 : loss : 0.030550, loss_ce: 0.009964
2022-01-16 00:58:10,513 iteration 4619 : loss : 0.025925, loss_ce: 0.009246
2022-01-16 00:58:11,502 iteration 4620 : loss : 0.019540, loss_ce: 0.005674
2022-01-16 00:58:12,518 iteration 4621 : loss : 0.025886, loss_ce: 0.008774
2022-01-16 00:58:13,456 iteration 4622 : loss : 0.019586, loss_ce: 0.006575
2022-01-16 00:58:14,368 iteration 4623 : loss : 0.027102, loss_ce: 0.009184
2022-01-16 00:58:15,303 iteration 4624 : loss : 0.021593, loss_ce: 0.008885
 68%|███████████████████▋         | 272/400 [1:18:36<36:37, 17.17s/it]2022-01-16 00:58:16,298 iteration 4625 : loss : 0.018416, loss_ce: 0.007531
2022-01-16 00:58:17,203 iteration 4626 : loss : 0.018455, loss_ce: 0.006277
2022-01-16 00:58:18,136 iteration 4627 : loss : 0.017362, loss_ce: 0.005520
2022-01-16 00:58:19,025 iteration 4628 : loss : 0.021635, loss_ce: 0.007871
2022-01-16 00:58:19,908 iteration 4629 : loss : 0.023893, loss_ce: 0.009517
2022-01-16 00:58:20,818 iteration 4630 : loss : 0.025502, loss_ce: 0.008493
2022-01-16 00:58:21,839 iteration 4631 : loss : 0.024277, loss_ce: 0.009129
2022-01-16 00:58:22,789 iteration 4632 : loss : 0.014947, loss_ce: 0.004886
2022-01-16 00:58:23,730 iteration 4633 : loss : 0.019354, loss_ce: 0.007218
2022-01-16 00:58:24,572 iteration 4634 : loss : 0.016058, loss_ce: 0.007091
2022-01-16 00:58:25,545 iteration 4635 : loss : 0.020150, loss_ce: 0.006317
2022-01-16 00:58:26,485 iteration 4636 : loss : 0.023478, loss_ce: 0.008740
2022-01-16 00:58:27,413 iteration 4637 : loss : 0.017030, loss_ce: 0.006041
2022-01-16 00:58:28,394 iteration 4638 : loss : 0.021686, loss_ce: 0.009528
2022-01-16 00:58:29,424 iteration 4639 : loss : 0.024026, loss_ce: 0.007843
2022-01-16 00:58:30,404 iteration 4640 : loss : 0.018159, loss_ce: 0.007310
2022-01-16 00:58:31,310 iteration 4641 : loss : 0.014623, loss_ce: 0.006392
 68%|███████████████████▊         | 273/400 [1:18:52<35:36, 16.82s/it]2022-01-16 00:58:32,373 iteration 4642 : loss : 0.048735, loss_ce: 0.015919
2022-01-16 00:58:33,363 iteration 4643 : loss : 0.024296, loss_ce: 0.010271
2022-01-16 00:58:34,331 iteration 4644 : loss : 0.018400, loss_ce: 0.006817
2022-01-16 00:58:35,448 iteration 4645 : loss : 0.019134, loss_ce: 0.008053
2022-01-16 00:58:36,362 iteration 4646 : loss : 0.015734, loss_ce: 0.006194
2022-01-16 00:58:37,275 iteration 4647 : loss : 0.018247, loss_ce: 0.008083
2022-01-16 00:58:38,115 iteration 4648 : loss : 0.016628, loss_ce: 0.006330
2022-01-16 00:58:39,078 iteration 4649 : loss : 0.021574, loss_ce: 0.008642
2022-01-16 00:58:40,002 iteration 4650 : loss : 0.016854, loss_ce: 0.005928
2022-01-16 00:58:40,953 iteration 4651 : loss : 0.020334, loss_ce: 0.007456
2022-01-16 00:58:41,908 iteration 4652 : loss : 0.021665, loss_ce: 0.008438
2022-01-16 00:58:42,846 iteration 4653 : loss : 0.019641, loss_ce: 0.007100
2022-01-16 00:58:43,798 iteration 4654 : loss : 0.021088, loss_ce: 0.010047
2022-01-16 00:58:44,758 iteration 4655 : loss : 0.020022, loss_ce: 0.006547
2022-01-16 00:58:45,785 iteration 4656 : loss : 0.037185, loss_ce: 0.006741
2022-01-16 00:58:46,721 iteration 4657 : loss : 0.053548, loss_ce: 0.007279
2022-01-16 00:58:47,621 iteration 4658 : loss : 0.021580, loss_ce: 0.005426
 68%|███████████████████▊         | 274/400 [1:19:08<35:00, 16.67s/it]2022-01-16 00:58:48,622 iteration 4659 : loss : 0.026297, loss_ce: 0.009496
2022-01-16 00:58:49,607 iteration 4660 : loss : 0.024585, loss_ce: 0.005797
2022-01-16 00:58:50,558 iteration 4661 : loss : 0.023845, loss_ce: 0.012610
2022-01-16 00:58:51,629 iteration 4662 : loss : 0.032731, loss_ce: 0.016873
2022-01-16 00:58:52,512 iteration 4663 : loss : 0.021052, loss_ce: 0.007094
2022-01-16 00:58:53,470 iteration 4664 : loss : 0.033397, loss_ce: 0.009634
2022-01-16 00:58:54,586 iteration 4665 : loss : 0.026245, loss_ce: 0.008153
2022-01-16 00:58:55,475 iteration 4666 : loss : 0.019337, loss_ce: 0.007631
2022-01-16 00:58:56,407 iteration 4667 : loss : 0.023170, loss_ce: 0.008773
2022-01-16 00:58:57,331 iteration 4668 : loss : 0.027195, loss_ce: 0.006674
2022-01-16 00:58:58,344 iteration 4669 : loss : 0.030642, loss_ce: 0.014818
2022-01-16 00:58:59,362 iteration 4670 : loss : 0.026264, loss_ce: 0.011071
2022-01-16 00:59:00,231 iteration 4671 : loss : 0.022103, loss_ce: 0.007078
2022-01-16 00:59:01,311 iteration 4672 : loss : 0.024271, loss_ce: 0.008986
2022-01-16 00:59:02,307 iteration 4673 : loss : 0.025389, loss_ce: 0.007537
2022-01-16 00:59:03,340 iteration 4674 : loss : 0.025723, loss_ce: 0.013098
2022-01-16 00:59:03,340 Training Data Eval:
2022-01-16 00:59:07,727   Average segmentation loss on training set: 0.0171
2022-01-16 00:59:07,727 Validation Data Eval:
2022-01-16 00:59:09,187   Average segmentation loss on validation set: 0.0847
2022-01-16 00:59:10,090 iteration 4675 : loss : 0.023865, loss_ce: 0.008975
 69%|███████████████████▉         | 275/400 [1:19:31<38:21, 18.41s/it]2022-01-16 00:59:11,176 iteration 4676 : loss : 0.026104, loss_ce: 0.007769
2022-01-16 00:59:12,102 iteration 4677 : loss : 0.030160, loss_ce: 0.013035
2022-01-16 00:59:13,036 iteration 4678 : loss : 0.038957, loss_ce: 0.011611
2022-01-16 00:59:13,981 iteration 4679 : loss : 0.020721, loss_ce: 0.010855
2022-01-16 00:59:14,880 iteration 4680 : loss : 0.024799, loss_ce: 0.008595
2022-01-16 00:59:15,831 iteration 4681 : loss : 0.020635, loss_ce: 0.006751
2022-01-16 00:59:16,708 iteration 4682 : loss : 0.023431, loss_ce: 0.005422
2022-01-16 00:59:17,642 iteration 4683 : loss : 0.035918, loss_ce: 0.017171
2022-01-16 00:59:18,627 iteration 4684 : loss : 0.025052, loss_ce: 0.010762
2022-01-16 00:59:19,582 iteration 4685 : loss : 0.026241, loss_ce: 0.013762
2022-01-16 00:59:20,428 iteration 4686 : loss : 0.021987, loss_ce: 0.007399
2022-01-16 00:59:21,423 iteration 4687 : loss : 0.018193, loss_ce: 0.007613
2022-01-16 00:59:22,444 iteration 4688 : loss : 0.024053, loss_ce: 0.007384
2022-01-16 00:59:23,483 iteration 4689 : loss : 0.032464, loss_ce: 0.013153
2022-01-16 00:59:24,413 iteration 4690 : loss : 0.026814, loss_ce: 0.008007
2022-01-16 00:59:25,307 iteration 4691 : loss : 0.018061, loss_ce: 0.006586
2022-01-16 00:59:26,234 iteration 4692 : loss : 0.022771, loss_ce: 0.010621
 69%|████████████████████         | 276/400 [1:19:47<36:38, 17.73s/it]2022-01-16 00:59:27,273 iteration 4693 : loss : 0.033074, loss_ce: 0.016055
2022-01-16 00:59:28,176 iteration 4694 : loss : 0.018040, loss_ce: 0.005646
2022-01-16 00:59:29,189 iteration 4695 : loss : 0.025634, loss_ce: 0.009923
2022-01-16 00:59:30,161 iteration 4696 : loss : 0.024419, loss_ce: 0.010253
2022-01-16 00:59:31,175 iteration 4697 : loss : 0.032303, loss_ce: 0.015341
2022-01-16 00:59:32,013 iteration 4698 : loss : 0.019460, loss_ce: 0.007632
2022-01-16 00:59:32,945 iteration 4699 : loss : 0.021765, loss_ce: 0.008199
2022-01-16 00:59:33,904 iteration 4700 : loss : 0.028715, loss_ce: 0.009320
2022-01-16 00:59:34,853 iteration 4701 : loss : 0.026764, loss_ce: 0.011826
2022-01-16 00:59:35,705 iteration 4702 : loss : 0.020487, loss_ce: 0.007613
2022-01-16 00:59:36,689 iteration 4703 : loss : 0.023469, loss_ce: 0.009450
2022-01-16 00:59:37,638 iteration 4704 : loss : 0.023230, loss_ce: 0.005547
2022-01-16 00:59:38,517 iteration 4705 : loss : 0.020331, loss_ce: 0.009089
2022-01-16 00:59:39,413 iteration 4706 : loss : 0.021473, loss_ce: 0.009773
2022-01-16 00:59:40,423 iteration 4707 : loss : 0.034189, loss_ce: 0.017279
2022-01-16 00:59:41,351 iteration 4708 : loss : 0.025948, loss_ce: 0.006297
2022-01-16 00:59:42,266 iteration 4709 : loss : 0.025199, loss_ce: 0.009940
 69%|████████████████████         | 277/400 [1:20:03<35:17, 17.22s/it]2022-01-16 00:59:43,351 iteration 4710 : loss : 0.030383, loss_ce: 0.011295
2022-01-16 00:59:44,261 iteration 4711 : loss : 0.025830, loss_ce: 0.011648
2022-01-16 00:59:45,205 iteration 4712 : loss : 0.019866, loss_ce: 0.007758
2022-01-16 00:59:46,110 iteration 4713 : loss : 0.017163, loss_ce: 0.006533
2022-01-16 00:59:47,011 iteration 4714 : loss : 0.019161, loss_ce: 0.008576
2022-01-16 00:59:48,043 iteration 4715 : loss : 0.027617, loss_ce: 0.008293
2022-01-16 00:59:48,986 iteration 4716 : loss : 0.018903, loss_ce: 0.007341
2022-01-16 00:59:49,926 iteration 4717 : loss : 0.032345, loss_ce: 0.010382
2022-01-16 00:59:50,853 iteration 4718 : loss : 0.015503, loss_ce: 0.005394
2022-01-16 00:59:51,759 iteration 4719 : loss : 0.017550, loss_ce: 0.006359
2022-01-16 00:59:52,764 iteration 4720 : loss : 0.020632, loss_ce: 0.007684
2022-01-16 00:59:53,703 iteration 4721 : loss : 0.016683, loss_ce: 0.005579
2022-01-16 00:59:54,636 iteration 4722 : loss : 0.024412, loss_ce: 0.009786
2022-01-16 00:59:55,613 iteration 4723 : loss : 0.041306, loss_ce: 0.010744
2022-01-16 00:59:56,493 iteration 4724 : loss : 0.022017, loss_ce: 0.012064
2022-01-16 00:59:57,405 iteration 4725 : loss : 0.020390, loss_ce: 0.008899
2022-01-16 00:59:58,301 iteration 4726 : loss : 0.024517, loss_ce: 0.007861
 70%|████████████████████▏        | 278/400 [1:20:19<34:17, 16.87s/it]2022-01-16 00:59:59,309 iteration 4727 : loss : 0.021392, loss_ce: 0.007569
2022-01-16 01:00:00,276 iteration 4728 : loss : 0.039563, loss_ce: 0.016826
2022-01-16 01:00:01,251 iteration 4729 : loss : 0.019224, loss_ce: 0.005543
2022-01-16 01:00:02,209 iteration 4730 : loss : 0.032474, loss_ce: 0.013747
2022-01-16 01:00:03,147 iteration 4731 : loss : 0.027669, loss_ce: 0.007413
2022-01-16 01:00:04,019 iteration 4732 : loss : 0.019074, loss_ce: 0.008101
2022-01-16 01:00:05,068 iteration 4733 : loss : 0.027802, loss_ce: 0.012482
2022-01-16 01:00:06,016 iteration 4734 : loss : 0.019663, loss_ce: 0.007758
2022-01-16 01:00:06,894 iteration 4735 : loss : 0.020368, loss_ce: 0.009225
2022-01-16 01:00:07,895 iteration 4736 : loss : 0.026928, loss_ce: 0.009762
2022-01-16 01:00:08,864 iteration 4737 : loss : 0.019954, loss_ce: 0.008626
2022-01-16 01:00:09,949 iteration 4738 : loss : 0.031228, loss_ce: 0.008870
2022-01-16 01:00:10,941 iteration 4739 : loss : 0.015981, loss_ce: 0.006229
2022-01-16 01:00:11,907 iteration 4740 : loss : 0.017566, loss_ce: 0.004411
2022-01-16 01:00:12,850 iteration 4741 : loss : 0.021864, loss_ce: 0.009991
2022-01-16 01:00:13,815 iteration 4742 : loss : 0.023774, loss_ce: 0.010070
2022-01-16 01:00:14,948 iteration 4743 : loss : 0.035120, loss_ce: 0.015304
 70%|████████████████████▏        | 279/400 [1:20:35<33:52, 16.80s/it]2022-01-16 01:00:16,024 iteration 4744 : loss : 0.024026, loss_ce: 0.008498
2022-01-16 01:00:16,996 iteration 4745 : loss : 0.020174, loss_ce: 0.008029
2022-01-16 01:00:17,941 iteration 4746 : loss : 0.027417, loss_ce: 0.008479
2022-01-16 01:00:18,814 iteration 4747 : loss : 0.016944, loss_ce: 0.008553
2022-01-16 01:00:19,862 iteration 4748 : loss : 0.018249, loss_ce: 0.006371
2022-01-16 01:00:20,735 iteration 4749 : loss : 0.025224, loss_ce: 0.010367
2022-01-16 01:00:21,700 iteration 4750 : loss : 0.026274, loss_ce: 0.007972
2022-01-16 01:00:22,676 iteration 4751 : loss : 0.019706, loss_ce: 0.008664
2022-01-16 01:00:23,613 iteration 4752 : loss : 0.031675, loss_ce: 0.009338
2022-01-16 01:00:24,524 iteration 4753 : loss : 0.017441, loss_ce: 0.005495
2022-01-16 01:00:25,486 iteration 4754 : loss : 0.022236, loss_ce: 0.009813
2022-01-16 01:00:26,528 iteration 4755 : loss : 0.031726, loss_ce: 0.007132
2022-01-16 01:00:27,509 iteration 4756 : loss : 0.020629, loss_ce: 0.005845
2022-01-16 01:00:28,460 iteration 4757 : loss : 0.023880, loss_ce: 0.011928
2022-01-16 01:00:29,498 iteration 4758 : loss : 0.026711, loss_ce: 0.008883
2022-01-16 01:00:30,447 iteration 4759 : loss : 0.039344, loss_ce: 0.020249
2022-01-16 01:00:30,447 Training Data Eval:
2022-01-16 01:00:34,838   Average segmentation loss on training set: 0.0165
2022-01-16 01:00:34,839 Validation Data Eval:
2022-01-16 01:00:36,302   Average segmentation loss on validation set: 0.1059
2022-01-16 01:00:37,264 iteration 4760 : loss : 0.029448, loss_ce: 0.008822
 70%|████████████████████▎        | 280/400 [1:20:58<36:54, 18.45s/it]2022-01-16 01:00:38,214 iteration 4761 : loss : 0.017269, loss_ce: 0.005603
2022-01-16 01:00:39,254 iteration 4762 : loss : 0.031751, loss_ce: 0.009581
2022-01-16 01:00:40,227 iteration 4763 : loss : 0.026579, loss_ce: 0.011626
2022-01-16 01:00:41,113 iteration 4764 : loss : 0.023698, loss_ce: 0.009124
2022-01-16 01:00:42,030 iteration 4765 : loss : 0.023193, loss_ce: 0.009654
2022-01-16 01:00:42,929 iteration 4766 : loss : 0.018811, loss_ce: 0.005489
2022-01-16 01:00:43,926 iteration 4767 : loss : 0.025184, loss_ce: 0.010035
2022-01-16 01:00:44,981 iteration 4768 : loss : 0.025883, loss_ce: 0.011351
2022-01-16 01:00:46,019 iteration 4769 : loss : 0.028613, loss_ce: 0.009763
2022-01-16 01:00:46,980 iteration 4770 : loss : 0.022874, loss_ce: 0.012043
2022-01-16 01:00:47,895 iteration 4771 : loss : 0.019867, loss_ce: 0.008090
2022-01-16 01:00:48,825 iteration 4772 : loss : 0.017886, loss_ce: 0.005962
2022-01-16 01:00:49,735 iteration 4773 : loss : 0.020398, loss_ce: 0.007822
2022-01-16 01:00:50,635 iteration 4774 : loss : 0.016240, loss_ce: 0.006497
2022-01-16 01:00:51,595 iteration 4775 : loss : 0.028166, loss_ce: 0.010239
2022-01-16 01:00:52,532 iteration 4776 : loss : 0.018154, loss_ce: 0.006499
2022-01-16 01:00:53,461 iteration 4777 : loss : 0.017329, loss_ce: 0.006047
 70%|████████████████████▎        | 281/400 [1:21:14<35:15, 17.78s/it]2022-01-16 01:00:54,544 iteration 4778 : loss : 0.023723, loss_ce: 0.007968
2022-01-16 01:00:55,448 iteration 4779 : loss : 0.016187, loss_ce: 0.005413
2022-01-16 01:00:56,356 iteration 4780 : loss : 0.024016, loss_ce: 0.006456
2022-01-16 01:00:57,266 iteration 4781 : loss : 0.019444, loss_ce: 0.008400
2022-01-16 01:00:58,262 iteration 4782 : loss : 0.041460, loss_ce: 0.012581
2022-01-16 01:00:59,130 iteration 4783 : loss : 0.021807, loss_ce: 0.006120
2022-01-16 01:01:00,142 iteration 4784 : loss : 0.020194, loss_ce: 0.007377
2022-01-16 01:01:01,183 iteration 4785 : loss : 0.025110, loss_ce: 0.011173
2022-01-16 01:01:02,126 iteration 4786 : loss : 0.016236, loss_ce: 0.006113
2022-01-16 01:01:03,113 iteration 4787 : loss : 0.023848, loss_ce: 0.007271
2022-01-16 01:01:04,078 iteration 4788 : loss : 0.019524, loss_ce: 0.008976
2022-01-16 01:01:05,045 iteration 4789 : loss : 0.017626, loss_ce: 0.006746
2022-01-16 01:01:05,995 iteration 4790 : loss : 0.019758, loss_ce: 0.008505
2022-01-16 01:01:06,906 iteration 4791 : loss : 0.017377, loss_ce: 0.006473
2022-01-16 01:01:07,843 iteration 4792 : loss : 0.024605, loss_ce: 0.011978
2022-01-16 01:01:08,821 iteration 4793 : loss : 0.022655, loss_ce: 0.011899
2022-01-16 01:01:09,752 iteration 4794 : loss : 0.035408, loss_ce: 0.007096
 70%|████████████████████▍        | 282/400 [1:21:30<34:04, 17.33s/it]2022-01-16 01:01:10,695 iteration 4795 : loss : 0.019381, loss_ce: 0.005790
2022-01-16 01:01:11,576 iteration 4796 : loss : 0.017879, loss_ce: 0.007079
2022-01-16 01:01:12,468 iteration 4797 : loss : 0.015626, loss_ce: 0.005450
2022-01-16 01:01:13,472 iteration 4798 : loss : 0.023351, loss_ce: 0.010079
2022-01-16 01:01:14,416 iteration 4799 : loss : 0.022358, loss_ce: 0.005230
2022-01-16 01:01:15,382 iteration 4800 : loss : 0.035974, loss_ce: 0.014577
2022-01-16 01:01:16,337 iteration 4801 : loss : 0.019300, loss_ce: 0.008931
2022-01-16 01:01:17,186 iteration 4802 : loss : 0.015826, loss_ce: 0.004783
2022-01-16 01:01:18,130 iteration 4803 : loss : 0.020857, loss_ce: 0.008665
2022-01-16 01:01:19,033 iteration 4804 : loss : 0.020019, loss_ce: 0.005699
2022-01-16 01:01:20,005 iteration 4805 : loss : 0.021051, loss_ce: 0.007097
2022-01-16 01:01:20,910 iteration 4806 : loss : 0.018374, loss_ce: 0.005196
2022-01-16 01:01:21,944 iteration 4807 : loss : 0.024158, loss_ce: 0.010239
2022-01-16 01:01:23,120 iteration 4808 : loss : 0.027502, loss_ce: 0.010153
2022-01-16 01:01:23,966 iteration 4809 : loss : 0.016305, loss_ce: 0.007027
2022-01-16 01:01:24,954 iteration 4810 : loss : 0.032568, loss_ce: 0.010997
2022-01-16 01:01:25,879 iteration 4811 : loss : 0.018761, loss_ce: 0.006783
 71%|████████████████████▌        | 283/400 [1:21:46<33:05, 16.97s/it]2022-01-16 01:01:26,852 iteration 4812 : loss : 0.017717, loss_ce: 0.006686
2022-01-16 01:01:27,812 iteration 4813 : loss : 0.022516, loss_ce: 0.008225
2022-01-16 01:01:28,709 iteration 4814 : loss : 0.016742, loss_ce: 0.008229
2022-01-16 01:01:29,660 iteration 4815 : loss : 0.017726, loss_ce: 0.006293
2022-01-16 01:01:30,559 iteration 4816 : loss : 0.019915, loss_ce: 0.007068
2022-01-16 01:01:31,366 iteration 4817 : loss : 0.018126, loss_ce: 0.006038
2022-01-16 01:01:32,346 iteration 4818 : loss : 0.029614, loss_ce: 0.013051
2022-01-16 01:01:33,310 iteration 4819 : loss : 0.024263, loss_ce: 0.007247
2022-01-16 01:01:34,317 iteration 4820 : loss : 0.019068, loss_ce: 0.008202
2022-01-16 01:01:35,239 iteration 4821 : loss : 0.022102, loss_ce: 0.011381
2022-01-16 01:01:36,207 iteration 4822 : loss : 0.025955, loss_ce: 0.007566
2022-01-16 01:01:37,115 iteration 4823 : loss : 0.019930, loss_ce: 0.008552
2022-01-16 01:01:38,121 iteration 4824 : loss : 0.021118, loss_ce: 0.007854
2022-01-16 01:01:39,055 iteration 4825 : loss : 0.014933, loss_ce: 0.004442
2022-01-16 01:01:39,967 iteration 4826 : loss : 0.030968, loss_ce: 0.010293
2022-01-16 01:01:41,025 iteration 4827 : loss : 0.023214, loss_ce: 0.006630
2022-01-16 01:01:42,039 iteration 4828 : loss : 0.021055, loss_ce: 0.008026
 71%|████████████████████▌        | 284/400 [1:22:03<32:20, 16.73s/it]2022-01-16 01:01:43,090 iteration 4829 : loss : 0.017045, loss_ce: 0.006415
2022-01-16 01:01:43,975 iteration 4830 : loss : 0.018226, loss_ce: 0.006133
2022-01-16 01:01:45,014 iteration 4831 : loss : 0.042457, loss_ce: 0.013990
2022-01-16 01:01:45,949 iteration 4832 : loss : 0.019713, loss_ce: 0.007802
2022-01-16 01:01:46,966 iteration 4833 : loss : 0.019011, loss_ce: 0.005388
2022-01-16 01:01:48,015 iteration 4834 : loss : 0.021822, loss_ce: 0.007971
2022-01-16 01:01:48,946 iteration 4835 : loss : 0.019254, loss_ce: 0.007246
2022-01-16 01:01:49,890 iteration 4836 : loss : 0.023949, loss_ce: 0.007415
2022-01-16 01:01:50,778 iteration 4837 : loss : 0.021739, loss_ce: 0.004462
2022-01-16 01:01:51,763 iteration 4838 : loss : 0.022086, loss_ce: 0.010060
2022-01-16 01:01:52,742 iteration 4839 : loss : 0.023069, loss_ce: 0.011021
2022-01-16 01:01:53,705 iteration 4840 : loss : 0.023114, loss_ce: 0.008907
2022-01-16 01:01:54,734 iteration 4841 : loss : 0.016885, loss_ce: 0.005564
2022-01-16 01:01:55,713 iteration 4842 : loss : 0.023173, loss_ce: 0.010930
2022-01-16 01:01:56,670 iteration 4843 : loss : 0.029164, loss_ce: 0.009628
2022-01-16 01:01:57,548 iteration 4844 : loss : 0.017475, loss_ce: 0.008362
2022-01-16 01:01:57,549 Training Data Eval:
2022-01-16 01:02:01,932   Average segmentation loss on training set: 0.0138
2022-01-16 01:02:01,932 Validation Data Eval:
2022-01-16 01:02:03,396   Average segmentation loss on validation set: 0.0822
2022-01-16 01:02:04,289 iteration 4845 : loss : 0.023948, loss_ce: 0.007660
 71%|████████████████████▋        | 285/400 [1:22:25<35:14, 18.38s/it]2022-01-16 01:02:05,325 iteration 4846 : loss : 0.020882, loss_ce: 0.007075
2022-01-16 01:02:06,243 iteration 4847 : loss : 0.021306, loss_ce: 0.006142
2022-01-16 01:02:07,301 iteration 4848 : loss : 0.023774, loss_ce: 0.009876
2022-01-16 01:02:08,230 iteration 4849 : loss : 0.017186, loss_ce: 0.007505
2022-01-16 01:02:09,204 iteration 4850 : loss : 0.047421, loss_ce: 0.008357
2022-01-16 01:02:10,183 iteration 4851 : loss : 0.018810, loss_ce: 0.008302
2022-01-16 01:02:11,095 iteration 4852 : loss : 0.021271, loss_ce: 0.008777
2022-01-16 01:02:12,004 iteration 4853 : loss : 0.025377, loss_ce: 0.011367
2022-01-16 01:02:12,867 iteration 4854 : loss : 0.019580, loss_ce: 0.007020
2022-01-16 01:02:13,813 iteration 4855 : loss : 0.019552, loss_ce: 0.006701
2022-01-16 01:02:14,780 iteration 4856 : loss : 0.023606, loss_ce: 0.009023
2022-01-16 01:02:15,762 iteration 4857 : loss : 0.024931, loss_ce: 0.011901
2022-01-16 01:02:16,710 iteration 4858 : loss : 0.020944, loss_ce: 0.008619
2022-01-16 01:02:17,591 iteration 4859 : loss : 0.015393, loss_ce: 0.006166
2022-01-16 01:02:18,501 iteration 4860 : loss : 0.019349, loss_ce: 0.005151
2022-01-16 01:02:19,358 iteration 4861 : loss : 0.024948, loss_ce: 0.006977
2022-01-16 01:02:20,385 iteration 4862 : loss : 0.021666, loss_ce: 0.007206
 72%|████████████████████▋        | 286/400 [1:22:41<33:37, 17.70s/it]2022-01-16 01:02:21,424 iteration 4863 : loss : 0.018956, loss_ce: 0.005863
2022-01-16 01:02:22,402 iteration 4864 : loss : 0.023937, loss_ce: 0.008835
2022-01-16 01:02:23,362 iteration 4865 : loss : 0.021472, loss_ce: 0.008078
2022-01-16 01:02:24,313 iteration 4866 : loss : 0.038486, loss_ce: 0.015363
2022-01-16 01:02:25,291 iteration 4867 : loss : 0.037392, loss_ce: 0.012783
2022-01-16 01:02:26,244 iteration 4868 : loss : 0.029463, loss_ce: 0.017976
2022-01-16 01:02:27,153 iteration 4869 : loss : 0.021224, loss_ce: 0.006744
2022-01-16 01:02:27,987 iteration 4870 : loss : 0.018041, loss_ce: 0.006892
2022-01-16 01:02:28,882 iteration 4871 : loss : 0.025704, loss_ce: 0.007972
2022-01-16 01:02:29,817 iteration 4872 : loss : 0.017773, loss_ce: 0.008055
2022-01-16 01:02:30,756 iteration 4873 : loss : 0.021276, loss_ce: 0.006566
2022-01-16 01:02:31,693 iteration 4874 : loss : 0.018400, loss_ce: 0.006698
2022-01-16 01:02:32,600 iteration 4875 : loss : 0.031400, loss_ce: 0.008321
2022-01-16 01:02:33,442 iteration 4876 : loss : 0.018508, loss_ce: 0.007909
2022-01-16 01:02:34,345 iteration 4877 : loss : 0.014300, loss_ce: 0.004745
2022-01-16 01:02:35,289 iteration 4878 : loss : 0.030006, loss_ce: 0.010374
2022-01-16 01:02:36,276 iteration 4879 : loss : 0.020545, loss_ce: 0.006551
 72%|████████████████████▊        | 287/400 [1:22:57<32:18, 17.16s/it]2022-01-16 01:02:37,308 iteration 4880 : loss : 0.018190, loss_ce: 0.005604
2022-01-16 01:02:38,177 iteration 4881 : loss : 0.014160, loss_ce: 0.004288
2022-01-16 01:02:39,048 iteration 4882 : loss : 0.018447, loss_ce: 0.004233
2022-01-16 01:02:40,017 iteration 4883 : loss : 0.024199, loss_ce: 0.009355
2022-01-16 01:02:40,909 iteration 4884 : loss : 0.027846, loss_ce: 0.011998
2022-01-16 01:02:41,852 iteration 4885 : loss : 0.017824, loss_ce: 0.005178
2022-01-16 01:02:42,821 iteration 4886 : loss : 0.020335, loss_ce: 0.006649
2022-01-16 01:02:43,730 iteration 4887 : loss : 0.034063, loss_ce: 0.013553
2022-01-16 01:02:44,685 iteration 4888 : loss : 0.022557, loss_ce: 0.005426
2022-01-16 01:02:45,602 iteration 4889 : loss : 0.019342, loss_ce: 0.007539
2022-01-16 01:02:46,556 iteration 4890 : loss : 0.024145, loss_ce: 0.010416
2022-01-16 01:02:47,502 iteration 4891 : loss : 0.019935, loss_ce: 0.009069
2022-01-16 01:02:48,449 iteration 4892 : loss : 0.027894, loss_ce: 0.014615
2022-01-16 01:02:49,570 iteration 4893 : loss : 0.024012, loss_ce: 0.008747
2022-01-16 01:02:50,515 iteration 4894 : loss : 0.018691, loss_ce: 0.008055
2022-01-16 01:02:51,441 iteration 4895 : loss : 0.019091, loss_ce: 0.008438
2022-01-16 01:02:52,356 iteration 4896 : loss : 0.020930, loss_ce: 0.007089
 72%|████████████████████▉        | 288/400 [1:23:13<31:25, 16.83s/it]2022-01-16 01:02:53,288 iteration 4897 : loss : 0.019853, loss_ce: 0.009740
2022-01-16 01:02:54,211 iteration 4898 : loss : 0.015218, loss_ce: 0.005407
2022-01-16 01:02:55,090 iteration 4899 : loss : 0.022003, loss_ce: 0.010056
2022-01-16 01:02:56,097 iteration 4900 : loss : 0.033596, loss_ce: 0.013786
2022-01-16 01:02:57,050 iteration 4901 : loss : 0.021699, loss_ce: 0.006768
2022-01-16 01:02:57,943 iteration 4902 : loss : 0.017433, loss_ce: 0.003671
2022-01-16 01:02:58,897 iteration 4903 : loss : 0.018691, loss_ce: 0.007457
2022-01-16 01:02:59,821 iteration 4904 : loss : 0.023516, loss_ce: 0.012040
2022-01-16 01:03:00,731 iteration 4905 : loss : 0.020581, loss_ce: 0.009387
2022-01-16 01:03:01,642 iteration 4906 : loss : 0.019671, loss_ce: 0.006918
2022-01-16 01:03:02,589 iteration 4907 : loss : 0.025475, loss_ce: 0.008932
2022-01-16 01:03:03,422 iteration 4908 : loss : 0.020951, loss_ce: 0.005471
2022-01-16 01:03:04,350 iteration 4909 : loss : 0.023464, loss_ce: 0.007822
2022-01-16 01:03:05,253 iteration 4910 : loss : 0.020272, loss_ce: 0.004748
2022-01-16 01:03:06,281 iteration 4911 : loss : 0.017407, loss_ce: 0.007147
2022-01-16 01:03:07,291 iteration 4912 : loss : 0.036770, loss_ce: 0.012999
2022-01-16 01:03:08,196 iteration 4913 : loss : 0.024641, loss_ce: 0.007654
 72%|████████████████████▉        | 289/400 [1:23:29<30:35, 16.53s/it]2022-01-16 01:03:09,121 iteration 4914 : loss : 0.019161, loss_ce: 0.006204
2022-01-16 01:03:10,091 iteration 4915 : loss : 0.022348, loss_ce: 0.008436
2022-01-16 01:03:11,050 iteration 4916 : loss : 0.023477, loss_ce: 0.007012
2022-01-16 01:03:11,989 iteration 4917 : loss : 0.017808, loss_ce: 0.006594
2022-01-16 01:03:12,886 iteration 4918 : loss : 0.015212, loss_ce: 0.006415
2022-01-16 01:03:13,768 iteration 4919 : loss : 0.019402, loss_ce: 0.007139
2022-01-16 01:03:14,727 iteration 4920 : loss : 0.019902, loss_ce: 0.009779
2022-01-16 01:03:15,643 iteration 4921 : loss : 0.021451, loss_ce: 0.005343
2022-01-16 01:03:16,565 iteration 4922 : loss : 0.023512, loss_ce: 0.004118
2022-01-16 01:03:17,501 iteration 4923 : loss : 0.022016, loss_ce: 0.008014
2022-01-16 01:03:18,464 iteration 4924 : loss : 0.023819, loss_ce: 0.009018
2022-01-16 01:03:19,540 iteration 4925 : loss : 0.019534, loss_ce: 0.008822
2022-01-16 01:03:20,450 iteration 4926 : loss : 0.021896, loss_ce: 0.008442
2022-01-16 01:03:21,455 iteration 4927 : loss : 0.019457, loss_ce: 0.007173
2022-01-16 01:03:22,480 iteration 4928 : loss : 0.023597, loss_ce: 0.010554
2022-01-16 01:03:23,489 iteration 4929 : loss : 0.029365, loss_ce: 0.011788
2022-01-16 01:03:23,489 Training Data Eval:
2022-01-16 01:03:27,886   Average segmentation loss on training set: 0.0125
2022-01-16 01:03:27,886 Validation Data Eval:
2022-01-16 01:03:29,354   Average segmentation loss on validation set: 0.0783
2022-01-16 01:03:30,303 iteration 4930 : loss : 0.015838, loss_ce: 0.006582
 72%|█████████████████████        | 290/400 [1:23:51<33:22, 18.21s/it]2022-01-16 01:03:31,359 iteration 4931 : loss : 0.018040, loss_ce: 0.008054
2022-01-16 01:03:32,263 iteration 4932 : loss : 0.014639, loss_ce: 0.005833
2022-01-16 01:03:33,150 iteration 4933 : loss : 0.021412, loss_ce: 0.007334
2022-01-16 01:03:34,102 iteration 4934 : loss : 0.022296, loss_ce: 0.010084
2022-01-16 01:03:35,076 iteration 4935 : loss : 0.020921, loss_ce: 0.006730
2022-01-16 01:03:36,023 iteration 4936 : loss : 0.018941, loss_ce: 0.007864
2022-01-16 01:03:36,993 iteration 4937 : loss : 0.018369, loss_ce: 0.006911
2022-01-16 01:03:37,968 iteration 4938 : loss : 0.019938, loss_ce: 0.006463
2022-01-16 01:03:38,974 iteration 4939 : loss : 0.019979, loss_ce: 0.007813
2022-01-16 01:03:39,870 iteration 4940 : loss : 0.025116, loss_ce: 0.007487
2022-01-16 01:03:40,809 iteration 4941 : loss : 0.016105, loss_ce: 0.005411
2022-01-16 01:03:41,796 iteration 4942 : loss : 0.028978, loss_ce: 0.011006
2022-01-16 01:03:42,690 iteration 4943 : loss : 0.013085, loss_ce: 0.004100
2022-01-16 01:03:43,632 iteration 4944 : loss : 0.021041, loss_ce: 0.009117
2022-01-16 01:03:44,668 iteration 4945 : loss : 0.021448, loss_ce: 0.006374
2022-01-16 01:03:45,674 iteration 4946 : loss : 0.039358, loss_ce: 0.017995
2022-01-16 01:03:46,727 iteration 4947 : loss : 0.023583, loss_ce: 0.009104
 73%|█████████████████████        | 291/400 [1:24:07<32:06, 17.67s/it]2022-01-16 01:03:47,809 iteration 4948 : loss : 0.022951, loss_ce: 0.008680
2022-01-16 01:03:48,725 iteration 4949 : loss : 0.017076, loss_ce: 0.006312
2022-01-16 01:03:49,619 iteration 4950 : loss : 0.022028, loss_ce: 0.007893
2022-01-16 01:03:50,543 iteration 4951 : loss : 0.033412, loss_ce: 0.012424
2022-01-16 01:03:51,393 iteration 4952 : loss : 0.021042, loss_ce: 0.008494
2022-01-16 01:03:52,377 iteration 4953 : loss : 0.014523, loss_ce: 0.005540
2022-01-16 01:03:53,252 iteration 4954 : loss : 0.019495, loss_ce: 0.007368
2022-01-16 01:03:54,167 iteration 4955 : loss : 0.014014, loss_ce: 0.005496
2022-01-16 01:03:55,085 iteration 4956 : loss : 0.017962, loss_ce: 0.006186
2022-01-16 01:03:56,018 iteration 4957 : loss : 0.015950, loss_ce: 0.006797
2022-01-16 01:03:56,963 iteration 4958 : loss : 0.022189, loss_ce: 0.009948
2022-01-16 01:03:57,802 iteration 4959 : loss : 0.015441, loss_ce: 0.005002
2022-01-16 01:03:58,726 iteration 4960 : loss : 0.020843, loss_ce: 0.006811
2022-01-16 01:03:59,609 iteration 4961 : loss : 0.016659, loss_ce: 0.006078
2022-01-16 01:04:00,589 iteration 4962 : loss : 0.020341, loss_ce: 0.008346
2022-01-16 01:04:01,467 iteration 4963 : loss : 0.018540, loss_ce: 0.007620
2022-01-16 01:04:02,496 iteration 4964 : loss : 0.021073, loss_ce: 0.007980
 73%|█████████████████████▏       | 292/400 [1:24:23<30:46, 17.10s/it]2022-01-16 01:04:03,570 iteration 4965 : loss : 0.024530, loss_ce: 0.007890
2022-01-16 01:04:04,640 iteration 4966 : loss : 0.026317, loss_ce: 0.007707
2022-01-16 01:04:05,525 iteration 4967 : loss : 0.013654, loss_ce: 0.005482
2022-01-16 01:04:06,469 iteration 4968 : loss : 0.020671, loss_ce: 0.008547
2022-01-16 01:04:07,377 iteration 4969 : loss : 0.026357, loss_ce: 0.005233
2022-01-16 01:04:08,268 iteration 4970 : loss : 0.014364, loss_ce: 0.005366
2022-01-16 01:04:09,255 iteration 4971 : loss : 0.019420, loss_ce: 0.007703
2022-01-16 01:04:10,267 iteration 4972 : loss : 0.017898, loss_ce: 0.005735
2022-01-16 01:04:11,183 iteration 4973 : loss : 0.016268, loss_ce: 0.006773
2022-01-16 01:04:12,088 iteration 4974 : loss : 0.019348, loss_ce: 0.007082
2022-01-16 01:04:12,999 iteration 4975 : loss : 0.025861, loss_ce: 0.009155
2022-01-16 01:04:13,904 iteration 4976 : loss : 0.019516, loss_ce: 0.007823
2022-01-16 01:04:14,943 iteration 4977 : loss : 0.021566, loss_ce: 0.010964
2022-01-16 01:04:15,881 iteration 4978 : loss : 0.041828, loss_ce: 0.011633
2022-01-16 01:04:16,826 iteration 4979 : loss : 0.019382, loss_ce: 0.009672
2022-01-16 01:04:17,664 iteration 4980 : loss : 0.013739, loss_ce: 0.005003
2022-01-16 01:04:18,595 iteration 4981 : loss : 0.021360, loss_ce: 0.007446
 73%|█████████████████████▏       | 293/400 [1:24:39<29:57, 16.80s/it]2022-01-16 01:04:19,591 iteration 4982 : loss : 0.026602, loss_ce: 0.010207
2022-01-16 01:04:20,495 iteration 4983 : loss : 0.014375, loss_ce: 0.004861
2022-01-16 01:04:21,499 iteration 4984 : loss : 0.024068, loss_ce: 0.008657
2022-01-16 01:04:22,456 iteration 4985 : loss : 0.017641, loss_ce: 0.005667
2022-01-16 01:04:23,497 iteration 4986 : loss : 0.025714, loss_ce: 0.011437
2022-01-16 01:04:24,409 iteration 4987 : loss : 0.019041, loss_ce: 0.008225
2022-01-16 01:04:25,328 iteration 4988 : loss : 0.019155, loss_ce: 0.008621
2022-01-16 01:04:26,239 iteration 4989 : loss : 0.019434, loss_ce: 0.006760
2022-01-16 01:04:27,273 iteration 4990 : loss : 0.020577, loss_ce: 0.006050
2022-01-16 01:04:28,229 iteration 4991 : loss : 0.026521, loss_ce: 0.006613
2022-01-16 01:04:29,170 iteration 4992 : loss : 0.019187, loss_ce: 0.008631
2022-01-16 01:04:30,174 iteration 4993 : loss : 0.018345, loss_ce: 0.007827
2022-01-16 01:04:31,210 iteration 4994 : loss : 0.022518, loss_ce: 0.005333
2022-01-16 01:04:32,151 iteration 4995 : loss : 0.022600, loss_ce: 0.007397
2022-01-16 01:04:33,093 iteration 4996 : loss : 0.020485, loss_ce: 0.007458
2022-01-16 01:04:34,122 iteration 4997 : loss : 0.024594, loss_ce: 0.009877
2022-01-16 01:04:35,010 iteration 4998 : loss : 0.017188, loss_ce: 0.006172
 74%|█████████████████████▎       | 294/400 [1:24:55<29:28, 16.69s/it]2022-01-16 01:04:36,058 iteration 4999 : loss : 0.017779, loss_ce: 0.006991
2022-01-16 01:04:36,934 iteration 5000 : loss : 0.016683, loss_ce: 0.006006
2022-01-16 01:04:37,839 iteration 5001 : loss : 0.021218, loss_ce: 0.007193
2022-01-16 01:04:38,812 iteration 5002 : loss : 0.022734, loss_ce: 0.009548
2022-01-16 01:04:39,720 iteration 5003 : loss : 0.020837, loss_ce: 0.006266
2022-01-16 01:04:40,732 iteration 5004 : loss : 0.028321, loss_ce: 0.009317
2022-01-16 01:04:41,637 iteration 5005 : loss : 0.017553, loss_ce: 0.005704
2022-01-16 01:04:42,619 iteration 5006 : loss : 0.019281, loss_ce: 0.004852
2022-01-16 01:04:43,527 iteration 5007 : loss : 0.016873, loss_ce: 0.006533
2022-01-16 01:04:44,390 iteration 5008 : loss : 0.021980, loss_ce: 0.007444
2022-01-16 01:04:45,314 iteration 5009 : loss : 0.025905, loss_ce: 0.008180
2022-01-16 01:04:46,363 iteration 5010 : loss : 0.030566, loss_ce: 0.011360
2022-01-16 01:04:47,315 iteration 5011 : loss : 0.023353, loss_ce: 0.014096
2022-01-16 01:04:48,328 iteration 5012 : loss : 0.031439, loss_ce: 0.013927
2022-01-16 01:04:49,451 iteration 5013 : loss : 0.018125, loss_ce: 0.007146
2022-01-16 01:04:50,301 iteration 5014 : loss : 0.015125, loss_ce: 0.005283
2022-01-16 01:04:50,301 Training Data Eval:
2022-01-16 01:04:54,682   Average segmentation loss on training set: 0.0123
2022-01-16 01:04:54,682 Validation Data Eval:
2022-01-16 01:04:56,150   Average segmentation loss on validation set: 0.0884
2022-01-16 01:04:57,061 iteration 5015 : loss : 0.016979, loss_ce: 0.003326
 74%|█████████████████████▍       | 295/400 [1:25:18<32:00, 18.29s/it]2022-01-16 01:04:58,006 iteration 5016 : loss : 0.024400, loss_ce: 0.009456
2022-01-16 01:04:58,915 iteration 5017 : loss : 0.017302, loss_ce: 0.005227
2022-01-16 01:05:00,020 iteration 5018 : loss : 0.019917, loss_ce: 0.006755
2022-01-16 01:05:00,915 iteration 5019 : loss : 0.014751, loss_ce: 0.004406
2022-01-16 01:05:01,885 iteration 5020 : loss : 0.020461, loss_ce: 0.009839
2022-01-16 01:05:02,912 iteration 5021 : loss : 0.016699, loss_ce: 0.006337
2022-01-16 01:05:03,917 iteration 5022 : loss : 0.039712, loss_ce: 0.017237
2022-01-16 01:05:04,889 iteration 5023 : loss : 0.017821, loss_ce: 0.007015
2022-01-16 01:05:05,806 iteration 5024 : loss : 0.014348, loss_ce: 0.005246
2022-01-16 01:05:06,700 iteration 5025 : loss : 0.020945, loss_ce: 0.008964
2022-01-16 01:05:07,648 iteration 5026 : loss : 0.022200, loss_ce: 0.009873
2022-01-16 01:05:08,586 iteration 5027 : loss : 0.016998, loss_ce: 0.005323
2022-01-16 01:05:09,539 iteration 5028 : loss : 0.016744, loss_ce: 0.006465
2022-01-16 01:05:10,429 iteration 5029 : loss : 0.015843, loss_ce: 0.006068
2022-01-16 01:05:11,394 iteration 5030 : loss : 0.025583, loss_ce: 0.008856
2022-01-16 01:05:12,414 iteration 5031 : loss : 0.026952, loss_ce: 0.012309
2022-01-16 01:05:13,436 iteration 5032 : loss : 0.022289, loss_ce: 0.008171
 74%|█████████████████████▍       | 296/400 [1:25:34<30:43, 17.72s/it]2022-01-16 01:05:14,458 iteration 5033 : loss : 0.020372, loss_ce: 0.010164
2022-01-16 01:05:15,396 iteration 5034 : loss : 0.027493, loss_ce: 0.007377
2022-01-16 01:05:16,316 iteration 5035 : loss : 0.025098, loss_ce: 0.010422
2022-01-16 01:05:17,183 iteration 5036 : loss : 0.015291, loss_ce: 0.005240
2022-01-16 01:05:18,088 iteration 5037 : loss : 0.015493, loss_ce: 0.006145
2022-01-16 01:05:19,176 iteration 5038 : loss : 0.024458, loss_ce: 0.011427
2022-01-16 01:05:20,090 iteration 5039 : loss : 0.020862, loss_ce: 0.008548
2022-01-16 01:05:21,071 iteration 5040 : loss : 0.022639, loss_ce: 0.009779
2022-01-16 01:05:22,012 iteration 5041 : loss : 0.018233, loss_ce: 0.006255
2022-01-16 01:05:22,941 iteration 5042 : loss : 0.017355, loss_ce: 0.006757
2022-01-16 01:05:23,837 iteration 5043 : loss : 0.019341, loss_ce: 0.006832
2022-01-16 01:05:24,783 iteration 5044 : loss : 0.014137, loss_ce: 0.004545
2022-01-16 01:05:25,618 iteration 5045 : loss : 0.012829, loss_ce: 0.003969
2022-01-16 01:05:26,561 iteration 5046 : loss : 0.023379, loss_ce: 0.011515
2022-01-16 01:05:27,461 iteration 5047 : loss : 0.017223, loss_ce: 0.006904
2022-01-16 01:05:28,334 iteration 5048 : loss : 0.012998, loss_ce: 0.005448
2022-01-16 01:05:29,350 iteration 5049 : loss : 0.024096, loss_ce: 0.009937
 74%|█████████████████████▌       | 297/400 [1:25:50<29:29, 17.18s/it]2022-01-16 01:05:30,340 iteration 5050 : loss : 0.027983, loss_ce: 0.007365
2022-01-16 01:05:31,216 iteration 5051 : loss : 0.016628, loss_ce: 0.007297
2022-01-16 01:05:32,194 iteration 5052 : loss : 0.016108, loss_ce: 0.007211
2022-01-16 01:05:33,067 iteration 5053 : loss : 0.016527, loss_ce: 0.006064
2022-01-16 01:05:34,028 iteration 5054 : loss : 0.014860, loss_ce: 0.006291
2022-01-16 01:05:34,930 iteration 5055 : loss : 0.015057, loss_ce: 0.005430
2022-01-16 01:05:35,839 iteration 5056 : loss : 0.023046, loss_ce: 0.007009
2022-01-16 01:05:36,760 iteration 5057 : loss : 0.017354, loss_ce: 0.007751
2022-01-16 01:05:37,657 iteration 5058 : loss : 0.022683, loss_ce: 0.008626
2022-01-16 01:05:38,589 iteration 5059 : loss : 0.020000, loss_ce: 0.009334
2022-01-16 01:05:39,588 iteration 5060 : loss : 0.027672, loss_ce: 0.006999
2022-01-16 01:05:40,533 iteration 5061 : loss : 0.023437, loss_ce: 0.010418
2022-01-16 01:05:41,537 iteration 5062 : loss : 0.016372, loss_ce: 0.005833
2022-01-16 01:05:42,439 iteration 5063 : loss : 0.015877, loss_ce: 0.006158
2022-01-16 01:05:43,391 iteration 5064 : loss : 0.018479, loss_ce: 0.004358
2022-01-16 01:05:44,406 iteration 5065 : loss : 0.033448, loss_ce: 0.012055
2022-01-16 01:05:45,225 iteration 5066 : loss : 0.017074, loss_ce: 0.007615
 74%|█████████████████████▌       | 298/400 [1:26:06<28:31, 16.78s/it]2022-01-16 01:05:46,338 iteration 5067 : loss : 0.025776, loss_ce: 0.009170
2022-01-16 01:05:47,261 iteration 5068 : loss : 0.015626, loss_ce: 0.004964
2022-01-16 01:05:48,158 iteration 5069 : loss : 0.018958, loss_ce: 0.006377
2022-01-16 01:05:49,071 iteration 5070 : loss : 0.016715, loss_ce: 0.008079
2022-01-16 01:05:50,065 iteration 5071 : loss : 0.016614, loss_ce: 0.007397
2022-01-16 01:05:51,032 iteration 5072 : loss : 0.017433, loss_ce: 0.005275
2022-01-16 01:05:52,034 iteration 5073 : loss : 0.032429, loss_ce: 0.008284
2022-01-16 01:05:53,018 iteration 5074 : loss : 0.021006, loss_ce: 0.007656
2022-01-16 01:05:53,872 iteration 5075 : loss : 0.020301, loss_ce: 0.009140
2022-01-16 01:05:54,729 iteration 5076 : loss : 0.017672, loss_ce: 0.006701
2022-01-16 01:05:55,724 iteration 5077 : loss : 0.025435, loss_ce: 0.009320
2022-01-16 01:05:56,674 iteration 5078 : loss : 0.017479, loss_ce: 0.005948
2022-01-16 01:05:57,590 iteration 5079 : loss : 0.013224, loss_ce: 0.004516
2022-01-16 01:05:58,552 iteration 5080 : loss : 0.016128, loss_ce: 0.006752
2022-01-16 01:05:59,519 iteration 5081 : loss : 0.021045, loss_ce: 0.009627
2022-01-16 01:06:00,430 iteration 5082 : loss : 0.019516, loss_ce: 0.005343
2022-01-16 01:06:01,333 iteration 5083 : loss : 0.020847, loss_ce: 0.007647
 75%|█████████████████████▋       | 299/400 [1:26:22<27:55, 16.59s/it]2022-01-16 01:06:02,352 iteration 5084 : loss : 0.020461, loss_ce: 0.009918
2022-01-16 01:06:03,398 iteration 5085 : loss : 0.022177, loss_ce: 0.008530
2022-01-16 01:06:04,249 iteration 5086 : loss : 0.014596, loss_ce: 0.004253
2022-01-16 01:06:05,201 iteration 5087 : loss : 0.017858, loss_ce: 0.004359
2022-01-16 01:06:06,065 iteration 5088 : loss : 0.013321, loss_ce: 0.006099
2022-01-16 01:06:06,979 iteration 5089 : loss : 0.017760, loss_ce: 0.006570
2022-01-16 01:06:07,945 iteration 5090 : loss : 0.025122, loss_ce: 0.010435
2022-01-16 01:06:08,919 iteration 5091 : loss : 0.028404, loss_ce: 0.009565
2022-01-16 01:06:09,846 iteration 5092 : loss : 0.022340, loss_ce: 0.005536
2022-01-16 01:06:10,791 iteration 5093 : loss : 0.016276, loss_ce: 0.005723
2022-01-16 01:06:11,744 iteration 5094 : loss : 0.016557, loss_ce: 0.005052
2022-01-16 01:06:12,706 iteration 5095 : loss : 0.018340, loss_ce: 0.007640
2022-01-16 01:06:13,723 iteration 5096 : loss : 0.023188, loss_ce: 0.006298
2022-01-16 01:06:14,717 iteration 5097 : loss : 0.023453, loss_ce: 0.012072
2022-01-16 01:06:15,655 iteration 5098 : loss : 0.018092, loss_ce: 0.007230
2022-01-16 01:06:16,643 iteration 5099 : loss : 0.019887, loss_ce: 0.006819
2022-01-16 01:06:16,643 Training Data Eval:
2022-01-16 01:06:21,030   Average segmentation loss on training set: 0.0121
2022-01-16 01:06:21,030 Validation Data Eval:
2022-01-16 01:06:22,487   Average segmentation loss on validation set: 0.0836
2022-01-16 01:06:23,385 iteration 5100 : loss : 0.018214, loss_ce: 0.005536
 75%|█████████████████████▊       | 300/400 [1:26:44<30:22, 18.23s/it]2022-01-16 01:06:24,420 iteration 5101 : loss : 0.029270, loss_ce: 0.008655
2022-01-16 01:06:25,440 iteration 5102 : loss : 0.021034, loss_ce: 0.010578
2022-01-16 01:06:26,337 iteration 5103 : loss : 0.017957, loss_ce: 0.006086
2022-01-16 01:06:27,272 iteration 5104 : loss : 0.021493, loss_ce: 0.006243
2022-01-16 01:06:28,178 iteration 5105 : loss : 0.019137, loss_ce: 0.005882
2022-01-16 01:06:29,116 iteration 5106 : loss : 0.024340, loss_ce: 0.010063
2022-01-16 01:06:30,072 iteration 5107 : loss : 0.020649, loss_ce: 0.008025
2022-01-16 01:06:31,039 iteration 5108 : loss : 0.019244, loss_ce: 0.007688
2022-01-16 01:06:31,981 iteration 5109 : loss : 0.018056, loss_ce: 0.007148
2022-01-16 01:06:32,819 iteration 5110 : loss : 0.018388, loss_ce: 0.006808
2022-01-16 01:06:33,779 iteration 5111 : loss : 0.024221, loss_ce: 0.006965
2022-01-16 01:06:34,653 iteration 5112 : loss : 0.014752, loss_ce: 0.006141
2022-01-16 01:06:35,674 iteration 5113 : loss : 0.024118, loss_ce: 0.007773
2022-01-16 01:06:36,562 iteration 5114 : loss : 0.020564, loss_ce: 0.009169
2022-01-16 01:06:37,461 iteration 5115 : loss : 0.021128, loss_ce: 0.009340
2022-01-16 01:06:38,409 iteration 5116 : loss : 0.023549, loss_ce: 0.008384
2022-01-16 01:06:39,363 iteration 5117 : loss : 0.022498, loss_ce: 0.007716
 75%|█████████████████████▊       | 301/400 [1:27:00<28:57, 17.55s/it]2022-01-16 01:06:40,389 iteration 5118 : loss : 0.018301, loss_ce: 0.007208
2022-01-16 01:06:41,341 iteration 5119 : loss : 0.026314, loss_ce: 0.009160
2022-01-16 01:06:42,380 iteration 5120 : loss : 0.017914, loss_ce: 0.004674
2022-01-16 01:06:43,280 iteration 5121 : loss : 0.016895, loss_ce: 0.006310
2022-01-16 01:06:44,187 iteration 5122 : loss : 0.019057, loss_ce: 0.005650
2022-01-16 01:06:45,123 iteration 5123 : loss : 0.019172, loss_ce: 0.010302
2022-01-16 01:06:46,018 iteration 5124 : loss : 0.029274, loss_ce: 0.006052
2022-01-16 01:06:46,969 iteration 5125 : loss : 0.021229, loss_ce: 0.007462
2022-01-16 01:06:47,872 iteration 5126 : loss : 0.019262, loss_ce: 0.007525
2022-01-16 01:06:48,835 iteration 5127 : loss : 0.032042, loss_ce: 0.011799
2022-01-16 01:06:49,896 iteration 5128 : loss : 0.024557, loss_ce: 0.008327
2022-01-16 01:06:50,918 iteration 5129 : loss : 0.021451, loss_ce: 0.007666
2022-01-16 01:06:51,792 iteration 5130 : loss : 0.016545, loss_ce: 0.006098
2022-01-16 01:06:52,758 iteration 5131 : loss : 0.019257, loss_ce: 0.005089
2022-01-16 01:06:53,722 iteration 5132 : loss : 0.023686, loss_ce: 0.012176
2022-01-16 01:06:54,616 iteration 5133 : loss : 0.018896, loss_ce: 0.007846
2022-01-16 01:06:55,496 iteration 5134 : loss : 0.012408, loss_ce: 0.004117
 76%|█████████████████████▉       | 302/400 [1:27:16<27:58, 17.13s/it]2022-01-16 01:06:56,491 iteration 5135 : loss : 0.016638, loss_ce: 0.005552
2022-01-16 01:06:57,522 iteration 5136 : loss : 0.021185, loss_ce: 0.008075
2022-01-16 01:06:58,548 iteration 5137 : loss : 0.024222, loss_ce: 0.007496
2022-01-16 01:06:59,600 iteration 5138 : loss : 0.021704, loss_ce: 0.010339
2022-01-16 01:07:00,466 iteration 5139 : loss : 0.013444, loss_ce: 0.004082
2022-01-16 01:07:01,465 iteration 5140 : loss : 0.022166, loss_ce: 0.010199
2022-01-16 01:07:02,342 iteration 5141 : loss : 0.016329, loss_ce: 0.007729
2022-01-16 01:07:03,388 iteration 5142 : loss : 0.025124, loss_ce: 0.008566
2022-01-16 01:07:04,267 iteration 5143 : loss : 0.013922, loss_ce: 0.005370
2022-01-16 01:07:05,134 iteration 5144 : loss : 0.016115, loss_ce: 0.007117
2022-01-16 01:07:06,097 iteration 5145 : loss : 0.022523, loss_ce: 0.007513
2022-01-16 01:07:07,189 iteration 5146 : loss : 0.026642, loss_ce: 0.006768
2022-01-16 01:07:08,139 iteration 5147 : loss : 0.014337, loss_ce: 0.006656
2022-01-16 01:07:09,118 iteration 5148 : loss : 0.023776, loss_ce: 0.008566
2022-01-16 01:07:10,025 iteration 5149 : loss : 0.017428, loss_ce: 0.005997
2022-01-16 01:07:10,934 iteration 5150 : loss : 0.016642, loss_ce: 0.005894
2022-01-16 01:07:11,807 iteration 5151 : loss : 0.026142, loss_ce: 0.009845
 76%|█████████████████████▉       | 303/400 [1:27:32<27:17, 16.88s/it]2022-01-16 01:07:12,853 iteration 5152 : loss : 0.020645, loss_ce: 0.005183
2022-01-16 01:07:13,720 iteration 5153 : loss : 0.016634, loss_ce: 0.008594
2022-01-16 01:07:14,707 iteration 5154 : loss : 0.021706, loss_ce: 0.007826
2022-01-16 01:07:15,575 iteration 5155 : loss : 0.010917, loss_ce: 0.003699
2022-01-16 01:07:16,497 iteration 5156 : loss : 0.025172, loss_ce: 0.009654
2022-01-16 01:07:17,499 iteration 5157 : loss : 0.027538, loss_ce: 0.011002
2022-01-16 01:07:18,462 iteration 5158 : loss : 0.017238, loss_ce: 0.006144
2022-01-16 01:07:19,461 iteration 5159 : loss : 0.028235, loss_ce: 0.009595
2022-01-16 01:07:20,473 iteration 5160 : loss : 0.017456, loss_ce: 0.006932
2022-01-16 01:07:21,481 iteration 5161 : loss : 0.018594, loss_ce: 0.007485
2022-01-16 01:07:22,391 iteration 5162 : loss : 0.018646, loss_ce: 0.005563
2022-01-16 01:07:23,314 iteration 5163 : loss : 0.028237, loss_ce: 0.011660
2022-01-16 01:07:24,188 iteration 5164 : loss : 0.016876, loss_ce: 0.008932
2022-01-16 01:07:25,130 iteration 5165 : loss : 0.017824, loss_ce: 0.005439
2022-01-16 01:07:26,088 iteration 5166 : loss : 0.017077, loss_ce: 0.007982
2022-01-16 01:07:26,980 iteration 5167 : loss : 0.016660, loss_ce: 0.007083
2022-01-16 01:07:27,981 iteration 5168 : loss : 0.021523, loss_ce: 0.008981
 76%|██████████████████████       | 304/400 [1:27:48<26:39, 16.67s/it]2022-01-16 01:07:28,940 iteration 5169 : loss : 0.018752, loss_ce: 0.007107
2022-01-16 01:07:29,888 iteration 5170 : loss : 0.017244, loss_ce: 0.007466
2022-01-16 01:07:30,796 iteration 5171 : loss : 0.024344, loss_ce: 0.007091
2022-01-16 01:07:31,744 iteration 5172 : loss : 0.026812, loss_ce: 0.009022
2022-01-16 01:07:32,648 iteration 5173 : loss : 0.024358, loss_ce: 0.011217
2022-01-16 01:07:33,622 iteration 5174 : loss : 0.018458, loss_ce: 0.007096
2022-01-16 01:07:34,654 iteration 5175 : loss : 0.032433, loss_ce: 0.011072
2022-01-16 01:07:35,594 iteration 5176 : loss : 0.018345, loss_ce: 0.006006
2022-01-16 01:07:36,672 iteration 5177 : loss : 0.029268, loss_ce: 0.012316
2022-01-16 01:07:37,597 iteration 5178 : loss : 0.019875, loss_ce: 0.003863
2022-01-16 01:07:38,601 iteration 5179 : loss : 0.018351, loss_ce: 0.008011
2022-01-16 01:07:39,546 iteration 5180 : loss : 0.016748, loss_ce: 0.006478
2022-01-16 01:07:40,538 iteration 5181 : loss : 0.025684, loss_ce: 0.010819
2022-01-16 01:07:41,543 iteration 5182 : loss : 0.029384, loss_ce: 0.010203
2022-01-16 01:07:42,549 iteration 5183 : loss : 0.023517, loss_ce: 0.006834
2022-01-16 01:07:43,597 iteration 5184 : loss : 0.019261, loss_ce: 0.009577
2022-01-16 01:07:43,598 Training Data Eval:
2022-01-16 01:07:47,981   Average segmentation loss on training set: 0.0119
2022-01-16 01:07:47,981 Validation Data Eval:
2022-01-16 01:07:49,441   Average segmentation loss on validation set: 0.0796
2022-01-16 01:07:50,394 iteration 5185 : loss : 0.017027, loss_ce: 0.007449
 76%|██████████████████████       | 305/400 [1:28:11<29:07, 18.39s/it]2022-01-16 01:07:51,413 iteration 5186 : loss : 0.020855, loss_ce: 0.009669
2022-01-16 01:07:52,415 iteration 5187 : loss : 0.027926, loss_ce: 0.014376
2022-01-16 01:07:53,280 iteration 5188 : loss : 0.019353, loss_ce: 0.005274
2022-01-16 01:07:54,224 iteration 5189 : loss : 0.020147, loss_ce: 0.008392
2022-01-16 01:07:55,089 iteration 5190 : loss : 0.019884, loss_ce: 0.008375
2022-01-16 01:07:55,971 iteration 5191 : loss : 0.016067, loss_ce: 0.005560
2022-01-16 01:07:56,959 iteration 5192 : loss : 0.027935, loss_ce: 0.009409
2022-01-16 01:07:57,924 iteration 5193 : loss : 0.021358, loss_ce: 0.009914
2022-01-16 01:07:58,867 iteration 5194 : loss : 0.021708, loss_ce: 0.008574
2022-01-16 01:07:59,835 iteration 5195 : loss : 0.022163, loss_ce: 0.008132
2022-01-16 01:08:00,922 iteration 5196 : loss : 0.026766, loss_ce: 0.006426
2022-01-16 01:08:01,766 iteration 5197 : loss : 0.013326, loss_ce: 0.003926
2022-01-16 01:08:02,762 iteration 5198 : loss : 0.026921, loss_ce: 0.011106
2022-01-16 01:08:03,757 iteration 5199 : loss : 0.017366, loss_ce: 0.006536
2022-01-16 01:08:04,734 iteration 5200 : loss : 0.018304, loss_ce: 0.005620
2022-01-16 01:08:05,645 iteration 5201 : loss : 0.017174, loss_ce: 0.005122
2022-01-16 01:08:06,589 iteration 5202 : loss : 0.017695, loss_ce: 0.006542
 76%|██████████████████████▏      | 306/400 [1:28:27<27:47, 17.73s/it]2022-01-16 01:08:07,501 iteration 5203 : loss : 0.016030, loss_ce: 0.004473
2022-01-16 01:08:08,474 iteration 5204 : loss : 0.020763, loss_ce: 0.007901
2022-01-16 01:08:09,430 iteration 5205 : loss : 0.015338, loss_ce: 0.005707
2022-01-16 01:08:10,306 iteration 5206 : loss : 0.014346, loss_ce: 0.005926
2022-01-16 01:08:11,227 iteration 5207 : loss : 0.015935, loss_ce: 0.006482
2022-01-16 01:08:12,245 iteration 5208 : loss : 0.022669, loss_ce: 0.008752
2022-01-16 01:08:13,210 iteration 5209 : loss : 0.025427, loss_ce: 0.009978
2022-01-16 01:08:14,135 iteration 5210 : loss : 0.015203, loss_ce: 0.004972
2022-01-16 01:08:15,034 iteration 5211 : loss : 0.014839, loss_ce: 0.004048
2022-01-16 01:08:15,983 iteration 5212 : loss : 0.019900, loss_ce: 0.005916
2022-01-16 01:08:16,957 iteration 5213 : loss : 0.029776, loss_ce: 0.010605
2022-01-16 01:08:17,886 iteration 5214 : loss : 0.022569, loss_ce: 0.012395
2022-01-16 01:08:18,803 iteration 5215 : loss : 0.022437, loss_ce: 0.008133
2022-01-16 01:08:19,725 iteration 5216 : loss : 0.014663, loss_ce: 0.005790
2022-01-16 01:08:20,613 iteration 5217 : loss : 0.014192, loss_ce: 0.004482
2022-01-16 01:08:21,534 iteration 5218 : loss : 0.025061, loss_ce: 0.009256
2022-01-16 01:08:22,497 iteration 5219 : loss : 0.024696, loss_ce: 0.011389
 77%|██████████████████████▎      | 307/400 [1:28:43<26:38, 17.18s/it]2022-01-16 01:08:23,584 iteration 5220 : loss : 0.028669, loss_ce: 0.011295
2022-01-16 01:08:24,501 iteration 5221 : loss : 0.016645, loss_ce: 0.006409
2022-01-16 01:08:25,346 iteration 5222 : loss : 0.016840, loss_ce: 0.004188
2022-01-16 01:08:26,263 iteration 5223 : loss : 0.018569, loss_ce: 0.007345
2022-01-16 01:08:27,284 iteration 5224 : loss : 0.024203, loss_ce: 0.008929
2022-01-16 01:08:28,150 iteration 5225 : loss : 0.015693, loss_ce: 0.004192
2022-01-16 01:08:29,224 iteration 5226 : loss : 0.023306, loss_ce: 0.008292
2022-01-16 01:08:30,065 iteration 5227 : loss : 0.014997, loss_ce: 0.005253
2022-01-16 01:08:30,918 iteration 5228 : loss : 0.013179, loss_ce: 0.005473
2022-01-16 01:08:31,809 iteration 5229 : loss : 0.017664, loss_ce: 0.007218
2022-01-16 01:08:32,772 iteration 5230 : loss : 0.019987, loss_ce: 0.010220
2022-01-16 01:08:33,744 iteration 5231 : loss : 0.036613, loss_ce: 0.011171
2022-01-16 01:08:34,636 iteration 5232 : loss : 0.017339, loss_ce: 0.007280
2022-01-16 01:08:35,617 iteration 5233 : loss : 0.021642, loss_ce: 0.008671
2022-01-16 01:08:36,460 iteration 5234 : loss : 0.012767, loss_ce: 0.004504
2022-01-16 01:08:37,491 iteration 5235 : loss : 0.023441, loss_ce: 0.008102
2022-01-16 01:08:38,416 iteration 5236 : loss : 0.021879, loss_ce: 0.008336
 77%|██████████████████████▎      | 308/400 [1:28:59<25:45, 16.80s/it]2022-01-16 01:08:39,448 iteration 5237 : loss : 0.017756, loss_ce: 0.005345
2022-01-16 01:08:40,394 iteration 5238 : loss : 0.016434, loss_ce: 0.007402
2022-01-16 01:08:41,334 iteration 5239 : loss : 0.014602, loss_ce: 0.004052
2022-01-16 01:08:42,375 iteration 5240 : loss : 0.026047, loss_ce: 0.008953
2022-01-16 01:08:43,352 iteration 5241 : loss : 0.019579, loss_ce: 0.008332
2022-01-16 01:08:44,327 iteration 5242 : loss : 0.021015, loss_ce: 0.008064
2022-01-16 01:08:45,289 iteration 5243 : loss : 0.017091, loss_ce: 0.005822
2022-01-16 01:08:46,264 iteration 5244 : loss : 0.022079, loss_ce: 0.007967
2022-01-16 01:08:47,217 iteration 5245 : loss : 0.020459, loss_ce: 0.007156
2022-01-16 01:08:48,039 iteration 5246 : loss : 0.011799, loss_ce: 0.005293
2022-01-16 01:08:48,974 iteration 5247 : loss : 0.017543, loss_ce: 0.006068
2022-01-16 01:08:49,953 iteration 5248 : loss : 0.016272, loss_ce: 0.005646
2022-01-16 01:08:50,871 iteration 5249 : loss : 0.021386, loss_ce: 0.009123
2022-01-16 01:08:51,807 iteration 5250 : loss : 0.019568, loss_ce: 0.008869
2022-01-16 01:08:52,817 iteration 5251 : loss : 0.015716, loss_ce: 0.006431
2022-01-16 01:08:53,748 iteration 5252 : loss : 0.030789, loss_ce: 0.008363
2022-01-16 01:08:54,722 iteration 5253 : loss : 0.016075, loss_ce: 0.006080
 77%|██████████████████████▍      | 309/400 [1:29:15<25:15, 16.66s/it]2022-01-16 01:08:55,649 iteration 5254 : loss : 0.014500, loss_ce: 0.005217
2022-01-16 01:08:56,646 iteration 5255 : loss : 0.022779, loss_ce: 0.006761
2022-01-16 01:08:57,614 iteration 5256 : loss : 0.015270, loss_ce: 0.005941
2022-01-16 01:08:58,647 iteration 5257 : loss : 0.023361, loss_ce: 0.005928
2022-01-16 01:08:59,539 iteration 5258 : loss : 0.023175, loss_ce: 0.009875
2022-01-16 01:09:00,513 iteration 5259 : loss : 0.028804, loss_ce: 0.007958
2022-01-16 01:09:01,429 iteration 5260 : loss : 0.017574, loss_ce: 0.007320
2022-01-16 01:09:02,367 iteration 5261 : loss : 0.015373, loss_ce: 0.006501
2022-01-16 01:09:03,236 iteration 5262 : loss : 0.011801, loss_ce: 0.005174
2022-01-16 01:09:04,184 iteration 5263 : loss : 0.019635, loss_ce: 0.006255
2022-01-16 01:09:05,095 iteration 5264 : loss : 0.017279, loss_ce: 0.005717
2022-01-16 01:09:05,945 iteration 5265 : loss : 0.015000, loss_ce: 0.005067
2022-01-16 01:09:06,889 iteration 5266 : loss : 0.018216, loss_ce: 0.007064
2022-01-16 01:09:07,758 iteration 5267 : loss : 0.019910, loss_ce: 0.007292
2022-01-16 01:09:08,767 iteration 5268 : loss : 0.017133, loss_ce: 0.006861
2022-01-16 01:09:09,800 iteration 5269 : loss : 0.029833, loss_ce: 0.012300
2022-01-16 01:09:09,801 Training Data Eval:
2022-01-16 01:09:14,187   Average segmentation loss on training set: 0.0124
2022-01-16 01:09:14,187 Validation Data Eval:
2022-01-16 01:09:15,643   Average segmentation loss on validation set: 0.0772
2022-01-16 01:09:16,632 iteration 5270 : loss : 0.027216, loss_ce: 0.013626
 78%|██████████████████████▍      | 310/400 [1:29:37<27:20, 18.23s/it]2022-01-16 01:09:17,682 iteration 5271 : loss : 0.020110, loss_ce: 0.008814
2022-01-16 01:09:18,628 iteration 5272 : loss : 0.025664, loss_ce: 0.009841
2022-01-16 01:09:19,561 iteration 5273 : loss : 0.030412, loss_ce: 0.012234
2022-01-16 01:09:20,448 iteration 5274 : loss : 0.024265, loss_ce: 0.007782
2022-01-16 01:09:21,416 iteration 5275 : loss : 0.028860, loss_ce: 0.009149
2022-01-16 01:09:22,380 iteration 5276 : loss : 0.024215, loss_ce: 0.008911
2022-01-16 01:09:23,244 iteration 5277 : loss : 0.020675, loss_ce: 0.006341
2022-01-16 01:09:24,326 iteration 5278 : loss : 0.027132, loss_ce: 0.011646
2022-01-16 01:09:25,255 iteration 5279 : loss : 0.017414, loss_ce: 0.005072
2022-01-16 01:09:26,271 iteration 5280 : loss : 0.018457, loss_ce: 0.006521
2022-01-16 01:09:27,216 iteration 5281 : loss : 0.019835, loss_ce: 0.010344
2022-01-16 01:09:28,197 iteration 5282 : loss : 0.018672, loss_ce: 0.006394
2022-01-16 01:09:29,138 iteration 5283 : loss : 0.022564, loss_ce: 0.008239
2022-01-16 01:09:30,113 iteration 5284 : loss : 0.019930, loss_ce: 0.008261
2022-01-16 01:09:31,076 iteration 5285 : loss : 0.024907, loss_ce: 0.010359
2022-01-16 01:09:32,080 iteration 5286 : loss : 0.017376, loss_ce: 0.006270
2022-01-16 01:09:33,142 iteration 5287 : loss : 0.023961, loss_ce: 0.009388
 78%|██████████████████████▌      | 311/400 [1:29:54<26:16, 17.72s/it]2022-01-16 01:09:34,101 iteration 5288 : loss : 0.020978, loss_ce: 0.008444
2022-01-16 01:09:35,053 iteration 5289 : loss : 0.017217, loss_ce: 0.005730
2022-01-16 01:09:36,053 iteration 5290 : loss : 0.019944, loss_ce: 0.007611
2022-01-16 01:09:37,059 iteration 5291 : loss : 0.027087, loss_ce: 0.012662
2022-01-16 01:09:38,046 iteration 5292 : loss : 0.014177, loss_ce: 0.005084
2022-01-16 01:09:38,969 iteration 5293 : loss : 0.021946, loss_ce: 0.006543
2022-01-16 01:09:39,989 iteration 5294 : loss : 0.027184, loss_ce: 0.012874
2022-01-16 01:09:40,888 iteration 5295 : loss : 0.013281, loss_ce: 0.004876
2022-01-16 01:09:41,835 iteration 5296 : loss : 0.024675, loss_ce: 0.007263
2022-01-16 01:09:42,871 iteration 5297 : loss : 0.021881, loss_ce: 0.006395
2022-01-16 01:09:43,763 iteration 5298 : loss : 0.015870, loss_ce: 0.006675
2022-01-16 01:09:44,781 iteration 5299 : loss : 0.023853, loss_ce: 0.010576
2022-01-16 01:09:45,642 iteration 5300 : loss : 0.019757, loss_ce: 0.007547
2022-01-16 01:09:46,586 iteration 5301 : loss : 0.034306, loss_ce: 0.012656
2022-01-16 01:09:47,492 iteration 5302 : loss : 0.015876, loss_ce: 0.006735
2022-01-16 01:09:48,311 iteration 5303 : loss : 0.014505, loss_ce: 0.005510
2022-01-16 01:09:49,301 iteration 5304 : loss : 0.020862, loss_ce: 0.008176
 78%|██████████████████████▌      | 312/400 [1:30:10<25:17, 17.25s/it]2022-01-16 01:09:50,315 iteration 5305 : loss : 0.019477, loss_ce: 0.006542
2022-01-16 01:09:51,285 iteration 5306 : loss : 0.028304, loss_ce: 0.009218
2022-01-16 01:09:52,231 iteration 5307 : loss : 0.017446, loss_ce: 0.006430
2022-01-16 01:09:53,217 iteration 5308 : loss : 0.035830, loss_ce: 0.016467
2022-01-16 01:09:54,151 iteration 5309 : loss : 0.018533, loss_ce: 0.006934
2022-01-16 01:09:55,086 iteration 5310 : loss : 0.019877, loss_ce: 0.009083
2022-01-16 01:09:56,039 iteration 5311 : loss : 0.018834, loss_ce: 0.007485
2022-01-16 01:09:56,982 iteration 5312 : loss : 0.015512, loss_ce: 0.005026
2022-01-16 01:09:57,967 iteration 5313 : loss : 0.034785, loss_ce: 0.008119
2022-01-16 01:09:58,864 iteration 5314 : loss : 0.018940, loss_ce: 0.008214
2022-01-16 01:09:59,843 iteration 5315 : loss : 0.022931, loss_ce: 0.010607
2022-01-16 01:10:00,653 iteration 5316 : loss : 0.013998, loss_ce: 0.006133
2022-01-16 01:10:01,609 iteration 5317 : loss : 0.019538, loss_ce: 0.007150
2022-01-16 01:10:02,602 iteration 5318 : loss : 0.019756, loss_ce: 0.006607
2022-01-16 01:10:03,600 iteration 5319 : loss : 0.019040, loss_ce: 0.006938
2022-01-16 01:10:04,599 iteration 5320 : loss : 0.043222, loss_ce: 0.022752
2022-01-16 01:10:05,479 iteration 5321 : loss : 0.025741, loss_ce: 0.005026
 78%|██████████████████████▋      | 313/400 [1:30:26<24:32, 16.93s/it]2022-01-16 01:10:06,542 iteration 5322 : loss : 0.017255, loss_ce: 0.007800
2022-01-16 01:10:07,568 iteration 5323 : loss : 0.016446, loss_ce: 0.005895
2022-01-16 01:10:08,529 iteration 5324 : loss : 0.016667, loss_ce: 0.006623
2022-01-16 01:10:09,491 iteration 5325 : loss : 0.017373, loss_ce: 0.006548
2022-01-16 01:10:10,535 iteration 5326 : loss : 0.030148, loss_ce: 0.008114
2022-01-16 01:10:11,512 iteration 5327 : loss : 0.031272, loss_ce: 0.011618
2022-01-16 01:10:12,453 iteration 5328 : loss : 0.017184, loss_ce: 0.006777
2022-01-16 01:10:13,403 iteration 5329 : loss : 0.017335, loss_ce: 0.006394
2022-01-16 01:10:14,345 iteration 5330 : loss : 0.022405, loss_ce: 0.009154
2022-01-16 01:10:15,220 iteration 5331 : loss : 0.012949, loss_ce: 0.005173
2022-01-16 01:10:16,359 iteration 5332 : loss : 0.032717, loss_ce: 0.014637
2022-01-16 01:10:17,296 iteration 5333 : loss : 0.020646, loss_ce: 0.008529
2022-01-16 01:10:18,128 iteration 5334 : loss : 0.019931, loss_ce: 0.006969
2022-01-16 01:10:19,073 iteration 5335 : loss : 0.019189, loss_ce: 0.005708
2022-01-16 01:10:19,993 iteration 5336 : loss : 0.032152, loss_ce: 0.010946
2022-01-16 01:10:20,939 iteration 5337 : loss : 0.019032, loss_ce: 0.007606
2022-01-16 01:10:21,901 iteration 5338 : loss : 0.025546, loss_ce: 0.009837
 78%|██████████████████████▊      | 314/400 [1:30:42<24:02, 16.78s/it]2022-01-16 01:10:22,892 iteration 5339 : loss : 0.020086, loss_ce: 0.007903
2022-01-16 01:10:23,801 iteration 5340 : loss : 0.016844, loss_ce: 0.006244
2022-01-16 01:10:24,825 iteration 5341 : loss : 0.024204, loss_ce: 0.006360
2022-01-16 01:10:25,822 iteration 5342 : loss : 0.016366, loss_ce: 0.005359
2022-01-16 01:10:26,796 iteration 5343 : loss : 0.017575, loss_ce: 0.006831
2022-01-16 01:10:27,698 iteration 5344 : loss : 0.014087, loss_ce: 0.005969
2022-01-16 01:10:28,615 iteration 5345 : loss : 0.017743, loss_ce: 0.007607
2022-01-16 01:10:29,515 iteration 5346 : loss : 0.020564, loss_ce: 0.007648
2022-01-16 01:10:30,477 iteration 5347 : loss : 0.017612, loss_ce: 0.006535
2022-01-16 01:10:31,363 iteration 5348 : loss : 0.017458, loss_ce: 0.007152
2022-01-16 01:10:32,263 iteration 5349 : loss : 0.020533, loss_ce: 0.006957
2022-01-16 01:10:33,191 iteration 5350 : loss : 0.017793, loss_ce: 0.005641
2022-01-16 01:10:34,063 iteration 5351 : loss : 0.018558, loss_ce: 0.007441
2022-01-16 01:10:35,061 iteration 5352 : loss : 0.020088, loss_ce: 0.007725
2022-01-16 01:10:36,014 iteration 5353 : loss : 0.023351, loss_ce: 0.009953
2022-01-16 01:10:36,901 iteration 5354 : loss : 0.016329, loss_ce: 0.007139
2022-01-16 01:10:36,901 Training Data Eval:
2022-01-16 01:10:41,283   Average segmentation loss on training set: 0.0121
2022-01-16 01:10:41,283 Validation Data Eval:
2022-01-16 01:10:42,743   Average segmentation loss on validation set: 0.0752
2022-01-16 01:10:43,673 iteration 5355 : loss : 0.024709, loss_ce: 0.012221
 79%|██████████████████████▊      | 315/400 [1:31:04<25:53, 18.27s/it]2022-01-16 01:10:44,731 iteration 5356 : loss : 0.020144, loss_ce: 0.008977
2022-01-16 01:10:45,631 iteration 5357 : loss : 0.012642, loss_ce: 0.004657
2022-01-16 01:10:46,521 iteration 5358 : loss : 0.018169, loss_ce: 0.007466
2022-01-16 01:10:47,411 iteration 5359 : loss : 0.015586, loss_ce: 0.005140
2022-01-16 01:10:48,398 iteration 5360 : loss : 0.017283, loss_ce: 0.006545
2022-01-16 01:10:49,313 iteration 5361 : loss : 0.021815, loss_ce: 0.009919
2022-01-16 01:10:50,271 iteration 5362 : loss : 0.014470, loss_ce: 0.005298
2022-01-16 01:10:51,371 iteration 5363 : loss : 0.019804, loss_ce: 0.007864
2022-01-16 01:10:52,313 iteration 5364 : loss : 0.025425, loss_ce: 0.007531
2022-01-16 01:10:53,275 iteration 5365 : loss : 0.023922, loss_ce: 0.008341
2022-01-16 01:10:54,189 iteration 5366 : loss : 0.023834, loss_ce: 0.008087
2022-01-16 01:10:55,031 iteration 5367 : loss : 0.015085, loss_ce: 0.005236
2022-01-16 01:10:56,085 iteration 5368 : loss : 0.021256, loss_ce: 0.007661
2022-01-16 01:10:56,996 iteration 5369 : loss : 0.014731, loss_ce: 0.005598
2022-01-16 01:10:57,904 iteration 5370 : loss : 0.017302, loss_ce: 0.007681
2022-01-16 01:10:58,826 iteration 5371 : loss : 0.018135, loss_ce: 0.005657
2022-01-16 01:10:59,669 iteration 5372 : loss : 0.014190, loss_ce: 0.005495
 79%|██████████████████████▉      | 316/400 [1:31:20<24:37, 17.59s/it]2022-01-16 01:11:00,646 iteration 5373 : loss : 0.029002, loss_ce: 0.014864
2022-01-16 01:11:01,547 iteration 5374 : loss : 0.023294, loss_ce: 0.006788
2022-01-16 01:11:02,498 iteration 5375 : loss : 0.030620, loss_ce: 0.012664
2022-01-16 01:11:03,442 iteration 5376 : loss : 0.016121, loss_ce: 0.005786
2022-01-16 01:11:04,405 iteration 5377 : loss : 0.019890, loss_ce: 0.005110
2022-01-16 01:11:05,366 iteration 5378 : loss : 0.017763, loss_ce: 0.005297
2022-01-16 01:11:06,284 iteration 5379 : loss : 0.019196, loss_ce: 0.006952
2022-01-16 01:11:07,143 iteration 5380 : loss : 0.016639, loss_ce: 0.006996
2022-01-16 01:11:08,151 iteration 5381 : loss : 0.022357, loss_ce: 0.009557
2022-01-16 01:11:09,087 iteration 5382 : loss : 0.022421, loss_ce: 0.008556
2022-01-16 01:11:10,010 iteration 5383 : loss : 0.022389, loss_ce: 0.010609
2022-01-16 01:11:10,921 iteration 5384 : loss : 0.016499, loss_ce: 0.008672
2022-01-16 01:11:11,877 iteration 5385 : loss : 0.021460, loss_ce: 0.007532
2022-01-16 01:11:12,773 iteration 5386 : loss : 0.019121, loss_ce: 0.008121
2022-01-16 01:11:13,818 iteration 5387 : loss : 0.020553, loss_ce: 0.008313
2022-01-16 01:11:14,792 iteration 5388 : loss : 0.016475, loss_ce: 0.004762
2022-01-16 01:11:15,817 iteration 5389 : loss : 0.022786, loss_ce: 0.009494
 79%|██████████████████████▉      | 317/400 [1:31:36<23:44, 17.16s/it]2022-01-16 01:11:16,783 iteration 5390 : loss : 0.015353, loss_ce: 0.005089
2022-01-16 01:11:17,815 iteration 5391 : loss : 0.026004, loss_ce: 0.009927
2022-01-16 01:11:18,738 iteration 5392 : loss : 0.021469, loss_ce: 0.006870
2022-01-16 01:11:19,634 iteration 5393 : loss : 0.017881, loss_ce: 0.006291
2022-01-16 01:11:20,568 iteration 5394 : loss : 0.014508, loss_ce: 0.004476
2022-01-16 01:11:21,503 iteration 5395 : loss : 0.037852, loss_ce: 0.011230
2022-01-16 01:11:22,404 iteration 5396 : loss : 0.019554, loss_ce: 0.007697
2022-01-16 01:11:23,388 iteration 5397 : loss : 0.025708, loss_ce: 0.011251
2022-01-16 01:11:24,486 iteration 5398 : loss : 0.028322, loss_ce: 0.008333
2022-01-16 01:11:25,481 iteration 5399 : loss : 0.018898, loss_ce: 0.005597
2022-01-16 01:11:26,393 iteration 5400 : loss : 0.016348, loss_ce: 0.006860
2022-01-16 01:11:27,362 iteration 5401 : loss : 0.018763, loss_ce: 0.010015
2022-01-16 01:11:28,271 iteration 5402 : loss : 0.017243, loss_ce: 0.008838
2022-01-16 01:11:29,214 iteration 5403 : loss : 0.016974, loss_ce: 0.007390
2022-01-16 01:11:30,185 iteration 5404 : loss : 0.013344, loss_ce: 0.005376
2022-01-16 01:11:31,245 iteration 5405 : loss : 0.025991, loss_ce: 0.008384
2022-01-16 01:11:32,135 iteration 5406 : loss : 0.016783, loss_ce: 0.007775
 80%|███████████████████████      | 318/400 [1:31:53<23:06, 16.90s/it]2022-01-16 01:11:33,113 iteration 5407 : loss : 0.017107, loss_ce: 0.007551
2022-01-16 01:11:34,033 iteration 5408 : loss : 0.021425, loss_ce: 0.008186
2022-01-16 01:11:34,880 iteration 5409 : loss : 0.016226, loss_ce: 0.005490
2022-01-16 01:11:35,828 iteration 5410 : loss : 0.024201, loss_ce: 0.008495
2022-01-16 01:11:36,711 iteration 5411 : loss : 0.014607, loss_ce: 0.005552
2022-01-16 01:11:37,659 iteration 5412 : loss : 0.017414, loss_ce: 0.006775
2022-01-16 01:11:38,566 iteration 5413 : loss : 0.017222, loss_ce: 0.007421
2022-01-16 01:11:39,516 iteration 5414 : loss : 0.015388, loss_ce: 0.006129
2022-01-16 01:11:40,567 iteration 5415 : loss : 0.025740, loss_ce: 0.008260
2022-01-16 01:11:41,466 iteration 5416 : loss : 0.016204, loss_ce: 0.005645
2022-01-16 01:11:42,394 iteration 5417 : loss : 0.013731, loss_ce: 0.004461
2022-01-16 01:11:43,419 iteration 5418 : loss : 0.018400, loss_ce: 0.007472
2022-01-16 01:11:44,287 iteration 5419 : loss : 0.016937, loss_ce: 0.007253
2022-01-16 01:11:45,174 iteration 5420 : loss : 0.018452, loss_ce: 0.007208
2022-01-16 01:11:46,154 iteration 5421 : loss : 0.018435, loss_ce: 0.006914
2022-01-16 01:11:47,166 iteration 5422 : loss : 0.020120, loss_ce: 0.004218
2022-01-16 01:11:48,167 iteration 5423 : loss : 0.018925, loss_ce: 0.008193
 80%|███████████████████████▏     | 319/400 [1:32:09<22:28, 16.65s/it]2022-01-16 01:11:49,173 iteration 5424 : loss : 0.021116, loss_ce: 0.006479
2022-01-16 01:11:50,075 iteration 5425 : loss : 0.026390, loss_ce: 0.006088
2022-01-16 01:11:51,074 iteration 5426 : loss : 0.023034, loss_ce: 0.010378
2022-01-16 01:11:51,927 iteration 5427 : loss : 0.017962, loss_ce: 0.005615
2022-01-16 01:11:52,826 iteration 5428 : loss : 0.011895, loss_ce: 0.004200
2022-01-16 01:11:53,734 iteration 5429 : loss : 0.022569, loss_ce: 0.008464
2022-01-16 01:11:54,793 iteration 5430 : loss : 0.014276, loss_ce: 0.004324
2022-01-16 01:11:55,721 iteration 5431 : loss : 0.018389, loss_ce: 0.007395
2022-01-16 01:11:56,634 iteration 5432 : loss : 0.015941, loss_ce: 0.006799
2022-01-16 01:11:57,633 iteration 5433 : loss : 0.016251, loss_ce: 0.006707
2022-01-16 01:11:58,546 iteration 5434 : loss : 0.019192, loss_ce: 0.007223
2022-01-16 01:11:59,598 iteration 5435 : loss : 0.022291, loss_ce: 0.011180
2022-01-16 01:12:00,531 iteration 5436 : loss : 0.013469, loss_ce: 0.004995
2022-01-16 01:12:01,342 iteration 5437 : loss : 0.012851, loss_ce: 0.004879
2022-01-16 01:12:02,390 iteration 5438 : loss : 0.023639, loss_ce: 0.008945
2022-01-16 01:12:03,287 iteration 5439 : loss : 0.013276, loss_ce: 0.005752
2022-01-16 01:12:03,288 Training Data Eval:
2022-01-16 01:12:07,672   Average segmentation loss on training set: 0.0116
2022-01-16 01:12:07,672 Validation Data Eval:
2022-01-16 01:12:09,133   Average segmentation loss on validation set: 0.0701
2022-01-16 01:12:10,111 iteration 5440 : loss : 0.033214, loss_ce: 0.009417
 80%|███████████████████████▏     | 320/400 [1:32:31<24:18, 18.23s/it]2022-01-16 01:12:10,995 iteration 5441 : loss : 0.013892, loss_ce: 0.004234
2022-01-16 01:12:11,928 iteration 5442 : loss : 0.017875, loss_ce: 0.007144
2022-01-16 01:12:12,897 iteration 5443 : loss : 0.017142, loss_ce: 0.006223
2022-01-16 01:12:13,858 iteration 5444 : loss : 0.018175, loss_ce: 0.006420
2022-01-16 01:12:14,896 iteration 5445 : loss : 0.027411, loss_ce: 0.010066
2022-01-16 01:12:15,797 iteration 5446 : loss : 0.024453, loss_ce: 0.008251
2022-01-16 01:12:16,718 iteration 5447 : loss : 0.025797, loss_ce: 0.012512
2022-01-16 01:12:17,675 iteration 5448 : loss : 0.017186, loss_ce: 0.006592
2022-01-16 01:12:18,599 iteration 5449 : loss : 0.017579, loss_ce: 0.006139
2022-01-16 01:12:19,608 iteration 5450 : loss : 0.019181, loss_ce: 0.009823
2022-01-16 01:12:20,534 iteration 5451 : loss : 0.019023, loss_ce: 0.007422
2022-01-16 01:12:21,535 iteration 5452 : loss : 0.016751, loss_ce: 0.006658
2022-01-16 01:12:22,490 iteration 5453 : loss : 0.014919, loss_ce: 0.005185
2022-01-16 01:12:23,314 iteration 5454 : loss : 0.012125, loss_ce: 0.005590
2022-01-16 01:12:24,358 iteration 5455 : loss : 0.026510, loss_ce: 0.010256
2022-01-16 01:12:25,372 iteration 5456 : loss : 0.019042, loss_ce: 0.007490
2022-01-16 01:12:26,313 iteration 5457 : loss : 0.017469, loss_ce: 0.005991
 80%|███████████████████████▎     | 321/400 [1:32:47<23:12, 17.63s/it]2022-01-16 01:12:27,284 iteration 5458 : loss : 0.018553, loss_ce: 0.007800
2022-01-16 01:12:28,178 iteration 5459 : loss : 0.014564, loss_ce: 0.005279
2022-01-16 01:12:29,145 iteration 5460 : loss : 0.023028, loss_ce: 0.009417
2022-01-16 01:12:30,122 iteration 5461 : loss : 0.019352, loss_ce: 0.008420
2022-01-16 01:12:31,067 iteration 5462 : loss : 0.015289, loss_ce: 0.003830
2022-01-16 01:12:31,984 iteration 5463 : loss : 0.014729, loss_ce: 0.005909
2022-01-16 01:12:32,903 iteration 5464 : loss : 0.017529, loss_ce: 0.006516
2022-01-16 01:12:33,782 iteration 5465 : loss : 0.017180, loss_ce: 0.005672
2022-01-16 01:12:34,807 iteration 5466 : loss : 0.017432, loss_ce: 0.006791
2022-01-16 01:12:35,729 iteration 5467 : loss : 0.016298, loss_ce: 0.007908
2022-01-16 01:12:36,681 iteration 5468 : loss : 0.028890, loss_ce: 0.014225
2022-01-16 01:12:37,553 iteration 5469 : loss : 0.014343, loss_ce: 0.004662
2022-01-16 01:12:38,534 iteration 5470 : loss : 0.018428, loss_ce: 0.006331
2022-01-16 01:12:39,476 iteration 5471 : loss : 0.016010, loss_ce: 0.005211
2022-01-16 01:12:40,475 iteration 5472 : loss : 0.018483, loss_ce: 0.006849
2022-01-16 01:12:41,456 iteration 5473 : loss : 0.018202, loss_ce: 0.005779
2022-01-16 01:12:42,445 iteration 5474 : loss : 0.019899, loss_ce: 0.008501
 80%|███████████████████████▎     | 322/400 [1:33:03<22:19, 17.18s/it]2022-01-16 01:12:43,439 iteration 5475 : loss : 0.015838, loss_ce: 0.004207
2022-01-16 01:12:44,350 iteration 5476 : loss : 0.019889, loss_ce: 0.005569
2022-01-16 01:12:45,253 iteration 5477 : loss : 0.015088, loss_ce: 0.006317
2022-01-16 01:12:46,183 iteration 5478 : loss : 0.020608, loss_ce: 0.008610
2022-01-16 01:12:47,221 iteration 5479 : loss : 0.019241, loss_ce: 0.008608
2022-01-16 01:12:48,236 iteration 5480 : loss : 0.023009, loss_ce: 0.008528
2022-01-16 01:12:49,177 iteration 5481 : loss : 0.016169, loss_ce: 0.004381
2022-01-16 01:12:50,108 iteration 5482 : loss : 0.015238, loss_ce: 0.005043
2022-01-16 01:12:51,058 iteration 5483 : loss : 0.017062, loss_ce: 0.007499
2022-01-16 01:12:51,965 iteration 5484 : loss : 0.015208, loss_ce: 0.006257
2022-01-16 01:12:52,798 iteration 5485 : loss : 0.013405, loss_ce: 0.004719
2022-01-16 01:12:53,830 iteration 5486 : loss : 0.024503, loss_ce: 0.009768
2022-01-16 01:12:54,930 iteration 5487 : loss : 0.025534, loss_ce: 0.010806
2022-01-16 01:12:55,871 iteration 5488 : loss : 0.016630, loss_ce: 0.005958
2022-01-16 01:12:56,802 iteration 5489 : loss : 0.023462, loss_ce: 0.009660
2022-01-16 01:12:57,707 iteration 5490 : loss : 0.027130, loss_ce: 0.009167
2022-01-16 01:12:58,624 iteration 5491 : loss : 0.019199, loss_ce: 0.006507
 81%|███████████████████████▍     | 323/400 [1:33:19<21:39, 16.87s/it]2022-01-16 01:12:59,628 iteration 5492 : loss : 0.016934, loss_ce: 0.006546
2022-01-16 01:13:00,536 iteration 5493 : loss : 0.016049, loss_ce: 0.006702
2022-01-16 01:13:01,414 iteration 5494 : loss : 0.020129, loss_ce: 0.005098
2022-01-16 01:13:02,413 iteration 5495 : loss : 0.032756, loss_ce: 0.005147
2022-01-16 01:13:03,304 iteration 5496 : loss : 0.012559, loss_ce: 0.003883
2022-01-16 01:13:04,238 iteration 5497 : loss : 0.013947, loss_ce: 0.004159
2022-01-16 01:13:05,204 iteration 5498 : loss : 0.016666, loss_ce: 0.008334
2022-01-16 01:13:06,134 iteration 5499 : loss : 0.017881, loss_ce: 0.006963
2022-01-16 01:13:07,105 iteration 5500 : loss : 0.025366, loss_ce: 0.010882
2022-01-16 01:13:08,140 iteration 5501 : loss : 0.023484, loss_ce: 0.009476
2022-01-16 01:13:09,129 iteration 5502 : loss : 0.021114, loss_ce: 0.007793
2022-01-16 01:13:10,038 iteration 5503 : loss : 0.017709, loss_ce: 0.005243
2022-01-16 01:13:11,003 iteration 5504 : loss : 0.020295, loss_ce: 0.009169
2022-01-16 01:13:11,955 iteration 5505 : loss : 0.022709, loss_ce: 0.010159
2022-01-16 01:13:12,846 iteration 5506 : loss : 0.018073, loss_ce: 0.006419
2022-01-16 01:13:13,814 iteration 5507 : loss : 0.021968, loss_ce: 0.006501
2022-01-16 01:13:14,759 iteration 5508 : loss : 0.016937, loss_ce: 0.007453
 81%|███████████████████████▍     | 324/400 [1:33:35<21:05, 16.65s/it]2022-01-16 01:13:15,746 iteration 5509 : loss : 0.019423, loss_ce: 0.007030
2022-01-16 01:13:16,829 iteration 5510 : loss : 0.027072, loss_ce: 0.009698
2022-01-16 01:13:17,779 iteration 5511 : loss : 0.023401, loss_ce: 0.011373
2022-01-16 01:13:18,792 iteration 5512 : loss : 0.020630, loss_ce: 0.003478
2022-01-16 01:13:19,695 iteration 5513 : loss : 0.017253, loss_ce: 0.004148
2022-01-16 01:13:20,691 iteration 5514 : loss : 0.020300, loss_ce: 0.008274
2022-01-16 01:13:21,725 iteration 5515 : loss : 0.022478, loss_ce: 0.006573
2022-01-16 01:13:22,577 iteration 5516 : loss : 0.014404, loss_ce: 0.005556
2022-01-16 01:13:23,548 iteration 5517 : loss : 0.040889, loss_ce: 0.013614
2022-01-16 01:13:24,473 iteration 5518 : loss : 0.018206, loss_ce: 0.008088
2022-01-16 01:13:25,384 iteration 5519 : loss : 0.017505, loss_ce: 0.005184
2022-01-16 01:13:26,352 iteration 5520 : loss : 0.036974, loss_ce: 0.014286
2022-01-16 01:13:27,436 iteration 5521 : loss : 0.020620, loss_ce: 0.007673
2022-01-16 01:13:28,312 iteration 5522 : loss : 0.016008, loss_ce: 0.007082
2022-01-16 01:13:29,261 iteration 5523 : loss : 0.017720, loss_ce: 0.006887
2022-01-16 01:13:30,226 iteration 5524 : loss : 0.025053, loss_ce: 0.013008
2022-01-16 01:13:30,226 Training Data Eval:
2022-01-16 01:13:34,621   Average segmentation loss on training set: 0.0121
2022-01-16 01:13:34,621 Validation Data Eval:
2022-01-16 01:13:36,079   Average segmentation loss on validation set: 0.0964
2022-01-16 01:13:37,067 iteration 5525 : loss : 0.023753, loss_ce: 0.009943
 81%|███████████████████████▌     | 325/400 [1:33:58<22:56, 18.35s/it]2022-01-16 01:13:38,178 iteration 5526 : loss : 0.020516, loss_ce: 0.008112
2022-01-16 01:13:39,083 iteration 5527 : loss : 0.015727, loss_ce: 0.004953
2022-01-16 01:13:40,055 iteration 5528 : loss : 0.017125, loss_ce: 0.005657
2022-01-16 01:13:40,966 iteration 5529 : loss : 0.020257, loss_ce: 0.008264
2022-01-16 01:13:41,839 iteration 5530 : loss : 0.013893, loss_ce: 0.003483
2022-01-16 01:13:42,786 iteration 5531 : loss : 0.014960, loss_ce: 0.005861
2022-01-16 01:13:43,628 iteration 5532 : loss : 0.016000, loss_ce: 0.005390
2022-01-16 01:13:44,603 iteration 5533 : loss : 0.015156, loss_ce: 0.006376
2022-01-16 01:13:45,568 iteration 5534 : loss : 0.025311, loss_ce: 0.008484
2022-01-16 01:13:46,536 iteration 5535 : loss : 0.017382, loss_ce: 0.006979
2022-01-16 01:13:47,466 iteration 5536 : loss : 0.016946, loss_ce: 0.004928
2022-01-16 01:13:48,398 iteration 5537 : loss : 0.017010, loss_ce: 0.005943
2022-01-16 01:13:49,324 iteration 5538 : loss : 0.016662, loss_ce: 0.009754
2022-01-16 01:13:50,276 iteration 5539 : loss : 0.017600, loss_ce: 0.007417
2022-01-16 01:13:51,240 iteration 5540 : loss : 0.012745, loss_ce: 0.004101
2022-01-16 01:13:52,100 iteration 5541 : loss : 0.019420, loss_ce: 0.007736
2022-01-16 01:13:53,006 iteration 5542 : loss : 0.016496, loss_ce: 0.006647
 82%|███████████████████████▋     | 326/400 [1:34:13<21:44, 17.63s/it]2022-01-16 01:13:54,068 iteration 5543 : loss : 0.024595, loss_ce: 0.009904
2022-01-16 01:13:55,131 iteration 5544 : loss : 0.026358, loss_ce: 0.007766
2022-01-16 01:13:56,144 iteration 5545 : loss : 0.022375, loss_ce: 0.007524
2022-01-16 01:13:57,004 iteration 5546 : loss : 0.012197, loss_ce: 0.005643
2022-01-16 01:13:57,971 iteration 5547 : loss : 0.017617, loss_ce: 0.007142
2022-01-16 01:13:58,868 iteration 5548 : loss : 0.018072, loss_ce: 0.006631
2022-01-16 01:13:59,796 iteration 5549 : loss : 0.017377, loss_ce: 0.006819
2022-01-16 01:14:00,760 iteration 5550 : loss : 0.024407, loss_ce: 0.010560
2022-01-16 01:14:01,734 iteration 5551 : loss : 0.017864, loss_ce: 0.004459
2022-01-16 01:14:02,789 iteration 5552 : loss : 0.027307, loss_ce: 0.006983
2022-01-16 01:14:03,767 iteration 5553 : loss : 0.016805, loss_ce: 0.006555
2022-01-16 01:14:04,813 iteration 5554 : loss : 0.019752, loss_ce: 0.005170
2022-01-16 01:14:05,840 iteration 5555 : loss : 0.014467, loss_ce: 0.005915
2022-01-16 01:14:06,839 iteration 5556 : loss : 0.020619, loss_ce: 0.009200
2022-01-16 01:14:07,835 iteration 5557 : loss : 0.017441, loss_ce: 0.005093
2022-01-16 01:14:08,761 iteration 5558 : loss : 0.019532, loss_ce: 0.006182
2022-01-16 01:14:09,636 iteration 5559 : loss : 0.015126, loss_ce: 0.005245
 82%|███████████████████████▋     | 327/400 [1:34:30<21:05, 17.33s/it]2022-01-16 01:14:10,641 iteration 5560 : loss : 0.023346, loss_ce: 0.008187
2022-01-16 01:14:11,677 iteration 5561 : loss : 0.017355, loss_ce: 0.004669
2022-01-16 01:14:12,640 iteration 5562 : loss : 0.023099, loss_ce: 0.007717
2022-01-16 01:14:13,654 iteration 5563 : loss : 0.024512, loss_ce: 0.007469
2022-01-16 01:14:14,514 iteration 5564 : loss : 0.017613, loss_ce: 0.005305
2022-01-16 01:14:15,476 iteration 5565 : loss : 0.020815, loss_ce: 0.005740
2022-01-16 01:14:16,375 iteration 5566 : loss : 0.014830, loss_ce: 0.005865
2022-01-16 01:14:17,374 iteration 5567 : loss : 0.016923, loss_ce: 0.008220
2022-01-16 01:14:18,373 iteration 5568 : loss : 0.020247, loss_ce: 0.009500
2022-01-16 01:14:19,376 iteration 5569 : loss : 0.024760, loss_ce: 0.012445
2022-01-16 01:14:20,325 iteration 5570 : loss : 0.018080, loss_ce: 0.008665
2022-01-16 01:14:21,270 iteration 5571 : loss : 0.024372, loss_ce: 0.007197
2022-01-16 01:14:22,112 iteration 5572 : loss : 0.013592, loss_ce: 0.004834
2022-01-16 01:14:23,106 iteration 5573 : loss : 0.019046, loss_ce: 0.007013
2022-01-16 01:14:24,006 iteration 5574 : loss : 0.015408, loss_ce: 0.005817
2022-01-16 01:14:24,878 iteration 5575 : loss : 0.013472, loss_ce: 0.005005
2022-01-16 01:14:25,713 iteration 5576 : loss : 0.017612, loss_ce: 0.005254
 82%|███████████████████████▊     | 328/400 [1:34:46<20:20, 16.95s/it]2022-01-16 01:14:26,770 iteration 5577 : loss : 0.031156, loss_ce: 0.009952
2022-01-16 01:14:27,723 iteration 5578 : loss : 0.017101, loss_ce: 0.006569
2022-01-16 01:14:28,778 iteration 5579 : loss : 0.025229, loss_ce: 0.005831
2022-01-16 01:14:29,792 iteration 5580 : loss : 0.019840, loss_ce: 0.006786
2022-01-16 01:14:30,770 iteration 5581 : loss : 0.019462, loss_ce: 0.008367
2022-01-16 01:14:31,705 iteration 5582 : loss : 0.020881, loss_ce: 0.008484
2022-01-16 01:14:32,593 iteration 5583 : loss : 0.013911, loss_ce: 0.003950
2022-01-16 01:14:33,510 iteration 5584 : loss : 0.017201, loss_ce: 0.006596
2022-01-16 01:14:34,377 iteration 5585 : loss : 0.018837, loss_ce: 0.006108
2022-01-16 01:14:35,258 iteration 5586 : loss : 0.014647, loss_ce: 0.005872
2022-01-16 01:14:36,288 iteration 5587 : loss : 0.020807, loss_ce: 0.008806
2022-01-16 01:14:37,229 iteration 5588 : loss : 0.025029, loss_ce: 0.009806
2022-01-16 01:14:38,242 iteration 5589 : loss : 0.020239, loss_ce: 0.006111
2022-01-16 01:14:39,125 iteration 5590 : loss : 0.014449, loss_ce: 0.006280
2022-01-16 01:14:40,092 iteration 5591 : loss : 0.018052, loss_ce: 0.006122
2022-01-16 01:14:41,053 iteration 5592 : loss : 0.023346, loss_ce: 0.009693
2022-01-16 01:14:41,904 iteration 5593 : loss : 0.014799, loss_ce: 0.007492
 82%|███████████████████████▊     | 329/400 [1:35:02<19:47, 16.72s/it]2022-01-16 01:14:42,909 iteration 5594 : loss : 0.013276, loss_ce: 0.003864
2022-01-16 01:14:43,794 iteration 5595 : loss : 0.014361, loss_ce: 0.005670
2022-01-16 01:14:44,822 iteration 5596 : loss : 0.021944, loss_ce: 0.005474
2022-01-16 01:14:45,788 iteration 5597 : loss : 0.018641, loss_ce: 0.008307
2022-01-16 01:14:46,866 iteration 5598 : loss : 0.028033, loss_ce: 0.013890
2022-01-16 01:14:47,907 iteration 5599 : loss : 0.016487, loss_ce: 0.005612
2022-01-16 01:14:48,786 iteration 5600 : loss : 0.013788, loss_ce: 0.005166
2022-01-16 01:14:49,746 iteration 5601 : loss : 0.016058, loss_ce: 0.005246
2022-01-16 01:14:50,694 iteration 5602 : loss : 0.017062, loss_ce: 0.006321
2022-01-16 01:14:51,649 iteration 5603 : loss : 0.037666, loss_ce: 0.018744
2022-01-16 01:14:52,602 iteration 5604 : loss : 0.026961, loss_ce: 0.009639
2022-01-16 01:14:53,499 iteration 5605 : loss : 0.015720, loss_ce: 0.007777
2022-01-16 01:14:54,477 iteration 5606 : loss : 0.021509, loss_ce: 0.007476
2022-01-16 01:14:55,370 iteration 5607 : loss : 0.017455, loss_ce: 0.007509
2022-01-16 01:14:56,347 iteration 5608 : loss : 0.016906, loss_ce: 0.008470
2022-01-16 01:14:57,246 iteration 5609 : loss : 0.015433, loss_ce: 0.005739
2022-01-16 01:14:57,246 Training Data Eval:
2022-01-16 01:15:01,641   Average segmentation loss on training set: 0.0122
2022-01-16 01:15:01,642 Validation Data Eval:
2022-01-16 01:15:03,123   Average segmentation loss on validation set: 0.0814
2022-01-16 01:15:04,093 iteration 5610 : loss : 0.020290, loss_ce: 0.008208
 82%|███████████████████████▉     | 330/400 [1:35:25<21:25, 18.37s/it]2022-01-16 01:15:05,046 iteration 5611 : loss : 0.012200, loss_ce: 0.004666
2022-01-16 01:15:06,048 iteration 5612 : loss : 0.024763, loss_ce: 0.008154
2022-01-16 01:15:06,957 iteration 5613 : loss : 0.021305, loss_ce: 0.004136
2022-01-16 01:15:07,870 iteration 5614 : loss : 0.019320, loss_ce: 0.007159
2022-01-16 01:15:08,807 iteration 5615 : loss : 0.019003, loss_ce: 0.008119
2022-01-16 01:15:09,744 iteration 5616 : loss : 0.015602, loss_ce: 0.004504
2022-01-16 01:15:10,855 iteration 5617 : loss : 0.027991, loss_ce: 0.010222
2022-01-16 01:15:11,859 iteration 5618 : loss : 0.022026, loss_ce: 0.006959
2022-01-16 01:15:12,815 iteration 5619 : loss : 0.015904, loss_ce: 0.006893
2022-01-16 01:15:13,699 iteration 5620 : loss : 0.016580, loss_ce: 0.006029
2022-01-16 01:15:14,575 iteration 5621 : loss : 0.018532, loss_ce: 0.006254
2022-01-16 01:15:15,413 iteration 5622 : loss : 0.014027, loss_ce: 0.005795
2022-01-16 01:15:16,417 iteration 5623 : loss : 0.016384, loss_ce: 0.005511
2022-01-16 01:15:17,340 iteration 5624 : loss : 0.013239, loss_ce: 0.004560
2022-01-16 01:15:18,264 iteration 5625 : loss : 0.018638, loss_ce: 0.007549
2022-01-16 01:15:19,231 iteration 5626 : loss : 0.017729, loss_ce: 0.006415
2022-01-16 01:15:20,164 iteration 5627 : loss : 0.016841, loss_ce: 0.007439
 83%|███████████████████████▉     | 331/400 [1:35:41<20:19, 17.67s/it]2022-01-16 01:15:21,166 iteration 5628 : loss : 0.013745, loss_ce: 0.004871
2022-01-16 01:15:22,114 iteration 5629 : loss : 0.020697, loss_ce: 0.007698
2022-01-16 01:15:23,085 iteration 5630 : loss : 0.012922, loss_ce: 0.004668
2022-01-16 01:15:24,062 iteration 5631 : loss : 0.016451, loss_ce: 0.008286
2022-01-16 01:15:25,095 iteration 5632 : loss : 0.024392, loss_ce: 0.008713
2022-01-16 01:15:25,945 iteration 5633 : loss : 0.016676, loss_ce: 0.004287
2022-01-16 01:15:26,956 iteration 5634 : loss : 0.025308, loss_ce: 0.007481
2022-01-16 01:15:27,895 iteration 5635 : loss : 0.016280, loss_ce: 0.006101
2022-01-16 01:15:28,756 iteration 5636 : loss : 0.017642, loss_ce: 0.004907
2022-01-16 01:15:29,784 iteration 5637 : loss : 0.021456, loss_ce: 0.009669
2022-01-16 01:15:30,730 iteration 5638 : loss : 0.018840, loss_ce: 0.009427
2022-01-16 01:15:31,691 iteration 5639 : loss : 0.020186, loss_ce: 0.006073
2022-01-16 01:15:32,634 iteration 5640 : loss : 0.031780, loss_ce: 0.014269
2022-01-16 01:15:33,524 iteration 5641 : loss : 0.017716, loss_ce: 0.006327
2022-01-16 01:15:34,583 iteration 5642 : loss : 0.020582, loss_ce: 0.009785
2022-01-16 01:15:35,436 iteration 5643 : loss : 0.022533, loss_ce: 0.012636
2022-01-16 01:15:36,360 iteration 5644 : loss : 0.015962, loss_ce: 0.006852
 83%|████████████████████████     | 332/400 [1:35:57<19:31, 17.24s/it]2022-01-16 01:15:37,312 iteration 5645 : loss : 0.015473, loss_ce: 0.004853
2022-01-16 01:15:38,227 iteration 5646 : loss : 0.016843, loss_ce: 0.004749
2022-01-16 01:15:39,090 iteration 5647 : loss : 0.013870, loss_ce: 0.004526
2022-01-16 01:15:40,029 iteration 5648 : loss : 0.020055, loss_ce: 0.008901
2022-01-16 01:15:40,920 iteration 5649 : loss : 0.013352, loss_ce: 0.003802
2022-01-16 01:15:41,918 iteration 5650 : loss : 0.019848, loss_ce: 0.008036
2022-01-16 01:15:42,843 iteration 5651 : loss : 0.016935, loss_ce: 0.007143
2022-01-16 01:15:43,799 iteration 5652 : loss : 0.016383, loss_ce: 0.005081
2022-01-16 01:15:44,732 iteration 5653 : loss : 0.017978, loss_ce: 0.005325
2022-01-16 01:15:45,666 iteration 5654 : loss : 0.016533, loss_ce: 0.006366
2022-01-16 01:15:46,510 iteration 5655 : loss : 0.015490, loss_ce: 0.007124
2022-01-16 01:15:47,548 iteration 5656 : loss : 0.024279, loss_ce: 0.008138
2022-01-16 01:15:48,549 iteration 5657 : loss : 0.025153, loss_ce: 0.008959
2022-01-16 01:15:49,547 iteration 5658 : loss : 0.026488, loss_ce: 0.010895
2022-01-16 01:15:50,450 iteration 5659 : loss : 0.017184, loss_ce: 0.006916
2022-01-16 01:15:51,423 iteration 5660 : loss : 0.025839, loss_ce: 0.008484
2022-01-16 01:15:52,360 iteration 5661 : loss : 0.016809, loss_ce: 0.007812
 83%|████████████████████████▏    | 333/400 [1:36:13<18:49, 16.86s/it]2022-01-16 01:15:53,358 iteration 5662 : loss : 0.023213, loss_ce: 0.008757
2022-01-16 01:15:54,255 iteration 5663 : loss : 0.016642, loss_ce: 0.005244
2022-01-16 01:15:55,202 iteration 5664 : loss : 0.016714, loss_ce: 0.007477
2022-01-16 01:15:56,085 iteration 5665 : loss : 0.011787, loss_ce: 0.004707
2022-01-16 01:15:57,039 iteration 5666 : loss : 0.019874, loss_ce: 0.004818
2022-01-16 01:15:58,033 iteration 5667 : loss : 0.015206, loss_ce: 0.005963
2022-01-16 01:15:58,988 iteration 5668 : loss : 0.029952, loss_ce: 0.012249
2022-01-16 01:15:59,863 iteration 5669 : loss : 0.013193, loss_ce: 0.004839
2022-01-16 01:16:00,779 iteration 5670 : loss : 0.015386, loss_ce: 0.005602
2022-01-16 01:16:01,665 iteration 5671 : loss : 0.021495, loss_ce: 0.008323
2022-01-16 01:16:02,715 iteration 5672 : loss : 0.022413, loss_ce: 0.011141
2022-01-16 01:16:03,638 iteration 5673 : loss : 0.022423, loss_ce: 0.007639
2022-01-16 01:16:04,572 iteration 5674 : loss : 0.014219, loss_ce: 0.003908
2022-01-16 01:16:05,465 iteration 5675 : loss : 0.013006, loss_ce: 0.005947
2022-01-16 01:16:06,470 iteration 5676 : loss : 0.022468, loss_ce: 0.008485
2022-01-16 01:16:07,400 iteration 5677 : loss : 0.022684, loss_ce: 0.006080
2022-01-16 01:16:08,437 iteration 5678 : loss : 0.016206, loss_ce: 0.006534
 84%|████████████████████████▏    | 334/400 [1:36:29<18:17, 16.62s/it]2022-01-16 01:16:09,483 iteration 5679 : loss : 0.016589, loss_ce: 0.006249
2022-01-16 01:16:10,377 iteration 5680 : loss : 0.018440, loss_ce: 0.007575
2022-01-16 01:16:11,339 iteration 5681 : loss : 0.022195, loss_ce: 0.009699
2022-01-16 01:16:12,264 iteration 5682 : loss : 0.013758, loss_ce: 0.005377
2022-01-16 01:16:13,241 iteration 5683 : loss : 0.021891, loss_ce: 0.009317
2022-01-16 01:16:14,257 iteration 5684 : loss : 0.025996, loss_ce: 0.008301
2022-01-16 01:16:15,243 iteration 5685 : loss : 0.015628, loss_ce: 0.004198
2022-01-16 01:16:16,182 iteration 5686 : loss : 0.032509, loss_ce: 0.014358
2022-01-16 01:16:17,084 iteration 5687 : loss : 0.011753, loss_ce: 0.003112
2022-01-16 01:16:18,012 iteration 5688 : loss : 0.021571, loss_ce: 0.006336
2022-01-16 01:16:18,935 iteration 5689 : loss : 0.015656, loss_ce: 0.006995
2022-01-16 01:16:19,906 iteration 5690 : loss : 0.033037, loss_ce: 0.019177
2022-01-16 01:16:20,824 iteration 5691 : loss : 0.015709, loss_ce: 0.004378
2022-01-16 01:16:21,721 iteration 5692 : loss : 0.014851, loss_ce: 0.005039
2022-01-16 01:16:22,694 iteration 5693 : loss : 0.023155, loss_ce: 0.011019
2022-01-16 01:16:23,683 iteration 5694 : loss : 0.024807, loss_ce: 0.009194
2022-01-16 01:16:23,683 Training Data Eval:
2022-01-16 01:16:28,072   Average segmentation loss on training set: 0.0115
2022-01-16 01:16:28,072 Validation Data Eval:
2022-01-16 01:16:29,534   Average segmentation loss on validation set: 0.0724
2022-01-16 01:16:30,435 iteration 5695 : loss : 0.019089, loss_ce: 0.006077
 84%|████████████████████████▎    | 335/400 [1:36:51<19:45, 18.24s/it]2022-01-16 01:16:31,421 iteration 5696 : loss : 0.015572, loss_ce: 0.005296
2022-01-16 01:16:32,432 iteration 5697 : loss : 0.018287, loss_ce: 0.006611
2022-01-16 01:16:33,386 iteration 5698 : loss : 0.015164, loss_ce: 0.006061
2022-01-16 01:16:34,415 iteration 5699 : loss : 0.023100, loss_ce: 0.007857
2022-01-16 01:16:35,364 iteration 5700 : loss : 0.017034, loss_ce: 0.006076
2022-01-16 01:16:36,285 iteration 5701 : loss : 0.019630, loss_ce: 0.009508
2022-01-16 01:16:37,239 iteration 5702 : loss : 0.012528, loss_ce: 0.004686
2022-01-16 01:16:38,167 iteration 5703 : loss : 0.013170, loss_ce: 0.005607
2022-01-16 01:16:39,147 iteration 5704 : loss : 0.016981, loss_ce: 0.007592
2022-01-16 01:16:40,115 iteration 5705 : loss : 0.015534, loss_ce: 0.006711
2022-01-16 01:16:41,015 iteration 5706 : loss : 0.017439, loss_ce: 0.004299
2022-01-16 01:16:42,087 iteration 5707 : loss : 0.022255, loss_ce: 0.008240
2022-01-16 01:16:43,011 iteration 5708 : loss : 0.017121, loss_ce: 0.007874
2022-01-16 01:16:43,971 iteration 5709 : loss : 0.022842, loss_ce: 0.010398
2022-01-16 01:16:45,009 iteration 5710 : loss : 0.018344, loss_ce: 0.007186
2022-01-16 01:16:45,921 iteration 5711 : loss : 0.029209, loss_ce: 0.015446
2022-01-16 01:16:46,846 iteration 5712 : loss : 0.016597, loss_ce: 0.007258
 84%|████████████████████████▎    | 336/400 [1:37:07<18:52, 17.69s/it]2022-01-16 01:16:47,808 iteration 5713 : loss : 0.021924, loss_ce: 0.007153
2022-01-16 01:16:48,715 iteration 5714 : loss : 0.015984, loss_ce: 0.006001
2022-01-16 01:16:49,616 iteration 5715 : loss : 0.014171, loss_ce: 0.005508
2022-01-16 01:16:50,568 iteration 5716 : loss : 0.014031, loss_ce: 0.005851
2022-01-16 01:16:51,556 iteration 5717 : loss : 0.018774, loss_ce: 0.006598
2022-01-16 01:16:52,429 iteration 5718 : loss : 0.019910, loss_ce: 0.006199
2022-01-16 01:16:53,405 iteration 5719 : loss : 0.014747, loss_ce: 0.005670
2022-01-16 01:16:54,314 iteration 5720 : loss : 0.017783, loss_ce: 0.007648
2022-01-16 01:16:55,144 iteration 5721 : loss : 0.013207, loss_ce: 0.003553
2022-01-16 01:16:56,064 iteration 5722 : loss : 0.014458, loss_ce: 0.004918
2022-01-16 01:16:56,983 iteration 5723 : loss : 0.016049, loss_ce: 0.006141
2022-01-16 01:16:57,816 iteration 5724 : loss : 0.014371, loss_ce: 0.004671
2022-01-16 01:16:58,787 iteration 5725 : loss : 0.016267, loss_ce: 0.007502
2022-01-16 01:16:59,664 iteration 5726 : loss : 0.017465, loss_ce: 0.007186
2022-01-16 01:17:00,585 iteration 5727 : loss : 0.015883, loss_ce: 0.005519
2022-01-16 01:17:01,496 iteration 5728 : loss : 0.016748, loss_ce: 0.007721
2022-01-16 01:17:02,464 iteration 5729 : loss : 0.018654, loss_ce: 0.007595
 84%|████████████████████████▍    | 337/400 [1:37:23<17:55, 17.07s/it]2022-01-16 01:17:03,485 iteration 5730 : loss : 0.023818, loss_ce: 0.006520
2022-01-16 01:17:04,477 iteration 5731 : loss : 0.014838, loss_ce: 0.006867
2022-01-16 01:17:05,405 iteration 5732 : loss : 0.019730, loss_ce: 0.005726
2022-01-16 01:17:06,297 iteration 5733 : loss : 0.017839, loss_ce: 0.004587
2022-01-16 01:17:07,239 iteration 5734 : loss : 0.023997, loss_ce: 0.006387
2022-01-16 01:17:08,184 iteration 5735 : loss : 0.019240, loss_ce: 0.010377
2022-01-16 01:17:09,109 iteration 5736 : loss : 0.017457, loss_ce: 0.009941
2022-01-16 01:17:10,026 iteration 5737 : loss : 0.025407, loss_ce: 0.009894
2022-01-16 01:17:10,933 iteration 5738 : loss : 0.011117, loss_ce: 0.004233
2022-01-16 01:17:11,806 iteration 5739 : loss : 0.014503, loss_ce: 0.005806
2022-01-16 01:17:12,774 iteration 5740 : loss : 0.016873, loss_ce: 0.006197
2022-01-16 01:17:13,726 iteration 5741 : loss : 0.017309, loss_ce: 0.008484
2022-01-16 01:17:14,675 iteration 5742 : loss : 0.025540, loss_ce: 0.010368
2022-01-16 01:17:15,574 iteration 5743 : loss : 0.016858, loss_ce: 0.007504
2022-01-16 01:17:16,563 iteration 5744 : loss : 0.016721, loss_ce: 0.006741
2022-01-16 01:17:17,502 iteration 5745 : loss : 0.016451, loss_ce: 0.004743
2022-01-16 01:17:18,353 iteration 5746 : loss : 0.014186, loss_ce: 0.003336
 84%|████████████████████████▌    | 338/400 [1:37:39<17:16, 16.71s/it]2022-01-16 01:17:19,381 iteration 5747 : loss : 0.016517, loss_ce: 0.005791
2022-01-16 01:17:20,352 iteration 5748 : loss : 0.016077, loss_ce: 0.004580
2022-01-16 01:17:21,344 iteration 5749 : loss : 0.016150, loss_ce: 0.006621
2022-01-16 01:17:22,377 iteration 5750 : loss : 0.018405, loss_ce: 0.005156
2022-01-16 01:17:23,246 iteration 5751 : loss : 0.014668, loss_ce: 0.005756
2022-01-16 01:17:24,211 iteration 5752 : loss : 0.017291, loss_ce: 0.005635
2022-01-16 01:17:25,133 iteration 5753 : loss : 0.020666, loss_ce: 0.007732
2022-01-16 01:17:25,995 iteration 5754 : loss : 0.014098, loss_ce: 0.005361
2022-01-16 01:17:26,932 iteration 5755 : loss : 0.016061, loss_ce: 0.007148
2022-01-16 01:17:27,868 iteration 5756 : loss : 0.015540, loss_ce: 0.004719
2022-01-16 01:17:28,784 iteration 5757 : loss : 0.014952, loss_ce: 0.007138
2022-01-16 01:17:29,723 iteration 5758 : loss : 0.020601, loss_ce: 0.004664
2022-01-16 01:17:30,676 iteration 5759 : loss : 0.016487, loss_ce: 0.007845
2022-01-16 01:17:31,704 iteration 5760 : loss : 0.016858, loss_ce: 0.006479
2022-01-16 01:17:32,557 iteration 5761 : loss : 0.013140, loss_ce: 0.005126
2022-01-16 01:17:33,689 iteration 5762 : loss : 0.027294, loss_ce: 0.011162
2022-01-16 01:17:34,626 iteration 5763 : loss : 0.016614, loss_ce: 0.006587
 85%|████████████████████████▌    | 339/400 [1:37:55<16:51, 16.58s/it]2022-01-16 01:17:35,647 iteration 5764 : loss : 0.017840, loss_ce: 0.006403
2022-01-16 01:17:36,628 iteration 5765 : loss : 0.022297, loss_ce: 0.006630
2022-01-16 01:17:37,582 iteration 5766 : loss : 0.017745, loss_ce: 0.007575
2022-01-16 01:17:38,544 iteration 5767 : loss : 0.016162, loss_ce: 0.006170
2022-01-16 01:17:39,613 iteration 5768 : loss : 0.025742, loss_ce: 0.008408
2022-01-16 01:17:40,544 iteration 5769 : loss : 0.014841, loss_ce: 0.005639
2022-01-16 01:17:41,480 iteration 5770 : loss : 0.017409, loss_ce: 0.006723
2022-01-16 01:17:42,421 iteration 5771 : loss : 0.017559, loss_ce: 0.007787
2022-01-16 01:17:43,367 iteration 5772 : loss : 0.018505, loss_ce: 0.007109
2022-01-16 01:17:44,401 iteration 5773 : loss : 0.014519, loss_ce: 0.005853
2022-01-16 01:17:45,429 iteration 5774 : loss : 0.022292, loss_ce: 0.011055
2022-01-16 01:17:46,469 iteration 5775 : loss : 0.021811, loss_ce: 0.007650
2022-01-16 01:17:47,376 iteration 5776 : loss : 0.014814, loss_ce: 0.005091
2022-01-16 01:17:48,282 iteration 5777 : loss : 0.023311, loss_ce: 0.009293
2022-01-16 01:17:49,258 iteration 5778 : loss : 0.022740, loss_ce: 0.007668
2022-01-16 01:17:50,198 iteration 5779 : loss : 0.020675, loss_ce: 0.008261
2022-01-16 01:17:50,198 Training Data Eval:
2022-01-16 01:17:54,579   Average segmentation loss on training set: 0.0101
2022-01-16 01:17:54,580 Validation Data Eval:
2022-01-16 01:17:56,033   Average segmentation loss on validation set: 0.0918
2022-01-16 01:17:57,014 iteration 5780 : loss : 0.016465, loss_ce: 0.006123
 85%|████████████████████████▋    | 340/400 [1:38:17<18:19, 18.32s/it]2022-01-16 01:17:58,153 iteration 5781 : loss : 0.031158, loss_ce: 0.012714
2022-01-16 01:17:58,992 iteration 5782 : loss : 0.013492, loss_ce: 0.006683
2022-01-16 01:17:59,865 iteration 5783 : loss : 0.016781, loss_ce: 0.006694
2022-01-16 01:18:00,757 iteration 5784 : loss : 0.016666, loss_ce: 0.006026
2022-01-16 01:18:01,616 iteration 5785 : loss : 0.014001, loss_ce: 0.006161
2022-01-16 01:18:02,566 iteration 5786 : loss : 0.022699, loss_ce: 0.005838
2022-01-16 01:18:03,482 iteration 5787 : loss : 0.016791, loss_ce: 0.006610
2022-01-16 01:18:04,305 iteration 5788 : loss : 0.013608, loss_ce: 0.005133
2022-01-16 01:18:05,150 iteration 5789 : loss : 0.011794, loss_ce: 0.004619
2022-01-16 01:18:06,106 iteration 5790 : loss : 0.011862, loss_ce: 0.004238
2022-01-16 01:18:07,027 iteration 5791 : loss : 0.013600, loss_ce: 0.006006
2022-01-16 01:18:07,900 iteration 5792 : loss : 0.012850, loss_ce: 0.004875
2022-01-16 01:18:08,881 iteration 5793 : loss : 0.016446, loss_ce: 0.005776
2022-01-16 01:18:09,897 iteration 5794 : loss : 0.021353, loss_ce: 0.009417
2022-01-16 01:18:10,784 iteration 5795 : loss : 0.011945, loss_ce: 0.005118
2022-01-16 01:18:11,735 iteration 5796 : loss : 0.015133, loss_ce: 0.006118
2022-01-16 01:18:12,675 iteration 5797 : loss : 0.017349, loss_ce: 0.006317
 85%|████████████████████████▋    | 341/400 [1:38:33<17:13, 17.53s/it]2022-01-16 01:18:13,769 iteration 5798 : loss : 0.017511, loss_ce: 0.005046
2022-01-16 01:18:14,696 iteration 5799 : loss : 0.014020, loss_ce: 0.004114
2022-01-16 01:18:15,612 iteration 5800 : loss : 0.015128, loss_ce: 0.004169
2022-01-16 01:18:16,449 iteration 5801 : loss : 0.010640, loss_ce: 0.003751
2022-01-16 01:18:17,411 iteration 5802 : loss : 0.014758, loss_ce: 0.006901
2022-01-16 01:18:18,271 iteration 5803 : loss : 0.013209, loss_ce: 0.004521
2022-01-16 01:18:19,312 iteration 5804 : loss : 0.022841, loss_ce: 0.007737
2022-01-16 01:18:20,211 iteration 5805 : loss : 0.014302, loss_ce: 0.006781
2022-01-16 01:18:21,083 iteration 5806 : loss : 0.012664, loss_ce: 0.004687
2022-01-16 01:18:22,035 iteration 5807 : loss : 0.013805, loss_ce: 0.004963
2022-01-16 01:18:22,944 iteration 5808 : loss : 0.025549, loss_ce: 0.010763
2022-01-16 01:18:23,983 iteration 5809 : loss : 0.022264, loss_ce: 0.006445
2022-01-16 01:18:24,846 iteration 5810 : loss : 0.018658, loss_ce: 0.004817
2022-01-16 01:18:25,760 iteration 5811 : loss : 0.015632, loss_ce: 0.006406
2022-01-16 01:18:26,726 iteration 5812 : loss : 0.017003, loss_ce: 0.007121
2022-01-16 01:18:27,613 iteration 5813 : loss : 0.018926, loss_ce: 0.006395
2022-01-16 01:18:28,548 iteration 5814 : loss : 0.019908, loss_ce: 0.007651
 86%|████████████████████████▊    | 342/400 [1:38:49<16:27, 17.03s/it]2022-01-16 01:18:29,668 iteration 5815 : loss : 0.028011, loss_ce: 0.013224
2022-01-16 01:18:30,538 iteration 5816 : loss : 0.015363, loss_ce: 0.004651
2022-01-16 01:18:31,489 iteration 5817 : loss : 0.013330, loss_ce: 0.003800
2022-01-16 01:18:32,406 iteration 5818 : loss : 0.014490, loss_ce: 0.004729
2022-01-16 01:18:33,446 iteration 5819 : loss : 0.016842, loss_ce: 0.007061
2022-01-16 01:18:34,378 iteration 5820 : loss : 0.012823, loss_ce: 0.005353
2022-01-16 01:18:35,293 iteration 5821 : loss : 0.017547, loss_ce: 0.006253
2022-01-16 01:18:36,303 iteration 5822 : loss : 0.021922, loss_ce: 0.007031
2022-01-16 01:18:37,265 iteration 5823 : loss : 0.011889, loss_ce: 0.003710
2022-01-16 01:18:38,205 iteration 5824 : loss : 0.013378, loss_ce: 0.004798
2022-01-16 01:18:39,132 iteration 5825 : loss : 0.018779, loss_ce: 0.007890
2022-01-16 01:18:40,032 iteration 5826 : loss : 0.015726, loss_ce: 0.004547
2022-01-16 01:18:40,915 iteration 5827 : loss : 0.018234, loss_ce: 0.004588
2022-01-16 01:18:41,748 iteration 5828 : loss : 0.011663, loss_ce: 0.004941
2022-01-16 01:18:42,680 iteration 5829 : loss : 0.016480, loss_ce: 0.006233
2022-01-16 01:18:43,636 iteration 5830 : loss : 0.020767, loss_ce: 0.007548
2022-01-16 01:18:44,633 iteration 5831 : loss : 0.015881, loss_ce: 0.006158
 86%|████████████████████████▊    | 343/400 [1:39:05<15:54, 16.75s/it]2022-01-16 01:18:45,734 iteration 5832 : loss : 0.016320, loss_ce: 0.006933
2022-01-16 01:18:46,646 iteration 5833 : loss : 0.011187, loss_ce: 0.003691
2022-01-16 01:18:47,676 iteration 5834 : loss : 0.026262, loss_ce: 0.010197
2022-01-16 01:18:48,790 iteration 5835 : loss : 0.029875, loss_ce: 0.012782
2022-01-16 01:18:49,717 iteration 5836 : loss : 0.023054, loss_ce: 0.011266
2022-01-16 01:18:50,746 iteration 5837 : loss : 0.024159, loss_ce: 0.011111
2022-01-16 01:18:51,771 iteration 5838 : loss : 0.026536, loss_ce: 0.008349
2022-01-16 01:18:52,639 iteration 5839 : loss : 0.017512, loss_ce: 0.005581
2022-01-16 01:18:53,793 iteration 5840 : loss : 0.019478, loss_ce: 0.008804
2022-01-16 01:18:54,733 iteration 5841 : loss : 0.017851, loss_ce: 0.006612
2022-01-16 01:18:55,751 iteration 5842 : loss : 0.019802, loss_ce: 0.007957
2022-01-16 01:18:56,777 iteration 5843 : loss : 0.018962, loss_ce: 0.006787
2022-01-16 01:18:57,754 iteration 5844 : loss : 0.020135, loss_ce: 0.005350
2022-01-16 01:18:58,755 iteration 5845 : loss : 0.017408, loss_ce: 0.005782
2022-01-16 01:18:59,714 iteration 5846 : loss : 0.022421, loss_ce: 0.007667
2022-01-16 01:19:00,650 iteration 5847 : loss : 0.015858, loss_ce: 0.004873
2022-01-16 01:19:01,509 iteration 5848 : loss : 0.017885, loss_ce: 0.005251
 86%|████████████████████████▉    | 344/400 [1:39:22<15:39, 16.78s/it]2022-01-16 01:19:02,448 iteration 5849 : loss : 0.016105, loss_ce: 0.005445
2022-01-16 01:19:03,455 iteration 5850 : loss : 0.020641, loss_ce: 0.006133
2022-01-16 01:19:04,348 iteration 5851 : loss : 0.021717, loss_ce: 0.011019
2022-01-16 01:19:05,247 iteration 5852 : loss : 0.015497, loss_ce: 0.005044
2022-01-16 01:19:06,114 iteration 5853 : loss : 0.021457, loss_ce: 0.005767
2022-01-16 01:19:07,041 iteration 5854 : loss : 0.020157, loss_ce: 0.007616
2022-01-16 01:19:07,956 iteration 5855 : loss : 0.021615, loss_ce: 0.005220
2022-01-16 01:19:08,822 iteration 5856 : loss : 0.014263, loss_ce: 0.006541
2022-01-16 01:19:09,783 iteration 5857 : loss : 0.017420, loss_ce: 0.007528
2022-01-16 01:19:10,688 iteration 5858 : loss : 0.018514, loss_ce: 0.005487
2022-01-16 01:19:11,650 iteration 5859 : loss : 0.017165, loss_ce: 0.008778
2022-01-16 01:19:12,617 iteration 5860 : loss : 0.013386, loss_ce: 0.004771
2022-01-16 01:19:13,577 iteration 5861 : loss : 0.016535, loss_ce: 0.007311
2022-01-16 01:19:14,502 iteration 5862 : loss : 0.012586, loss_ce: 0.004791
2022-01-16 01:19:15,426 iteration 5863 : loss : 0.027126, loss_ce: 0.009411
2022-01-16 01:19:16,346 iteration 5864 : loss : 0.020308, loss_ce: 0.007368
2022-01-16 01:19:16,347 Training Data Eval:
2022-01-16 01:19:20,731   Average segmentation loss on training set: 0.0103
2022-01-16 01:19:20,731 Validation Data Eval:
2022-01-16 01:19:22,193   Average segmentation loss on validation set: 0.0753
2022-01-16 01:19:23,085 iteration 5865 : loss : 0.014537, loss_ce: 0.005186
 86%|█████████████████████████    | 345/400 [1:39:44<16:42, 18.22s/it]2022-01-16 01:19:24,104 iteration 5866 : loss : 0.028166, loss_ce: 0.009067
2022-01-16 01:19:25,054 iteration 5867 : loss : 0.015065, loss_ce: 0.006334
2022-01-16 01:19:25,911 iteration 5868 : loss : 0.014064, loss_ce: 0.005648
2022-01-16 01:19:26,810 iteration 5869 : loss : 0.012215, loss_ce: 0.004532
2022-01-16 01:19:27,647 iteration 5870 : loss : 0.014388, loss_ce: 0.005057
2022-01-16 01:19:28,559 iteration 5871 : loss : 0.014836, loss_ce: 0.006472
2022-01-16 01:19:29,470 iteration 5872 : loss : 0.015730, loss_ce: 0.007544
2022-01-16 01:19:30,321 iteration 5873 : loss : 0.014788, loss_ce: 0.006715
2022-01-16 01:19:31,175 iteration 5874 : loss : 0.025770, loss_ce: 0.005578
2022-01-16 01:19:32,180 iteration 5875 : loss : 0.016624, loss_ce: 0.007063
2022-01-16 01:19:33,202 iteration 5876 : loss : 0.027748, loss_ce: 0.012354
2022-01-16 01:19:34,165 iteration 5877 : loss : 0.019176, loss_ce: 0.006675
2022-01-16 01:19:35,150 iteration 5878 : loss : 0.024894, loss_ce: 0.007591
2022-01-16 01:19:36,047 iteration 5879 : loss : 0.018670, loss_ce: 0.005025
2022-01-16 01:19:36,961 iteration 5880 : loss : 0.016630, loss_ce: 0.006033
2022-01-16 01:19:37,942 iteration 5881 : loss : 0.025465, loss_ce: 0.008060
2022-01-16 01:19:38,852 iteration 5882 : loss : 0.015360, loss_ce: 0.005562
 86%|█████████████████████████    | 346/400 [1:39:59<15:44, 17.48s/it]2022-01-16 01:19:39,967 iteration 5883 : loss : 0.018234, loss_ce: 0.006770
2022-01-16 01:19:40,858 iteration 5884 : loss : 0.021602, loss_ce: 0.008452
2022-01-16 01:19:41,859 iteration 5885 : loss : 0.021455, loss_ce: 0.005576
2022-01-16 01:19:42,756 iteration 5886 : loss : 0.010917, loss_ce: 0.003540
2022-01-16 01:19:43,660 iteration 5887 : loss : 0.022559, loss_ce: 0.006442
2022-01-16 01:19:44,488 iteration 5888 : loss : 0.013069, loss_ce: 0.005611
2022-01-16 01:19:45,393 iteration 5889 : loss : 0.014255, loss_ce: 0.006086
2022-01-16 01:19:46,371 iteration 5890 : loss : 0.017135, loss_ce: 0.007149
2022-01-16 01:19:47,356 iteration 5891 : loss : 0.022404, loss_ce: 0.006755
2022-01-16 01:19:48,369 iteration 5892 : loss : 0.016733, loss_ce: 0.007410
2022-01-16 01:19:49,221 iteration 5893 : loss : 0.013458, loss_ce: 0.003408
2022-01-16 01:19:50,102 iteration 5894 : loss : 0.012174, loss_ce: 0.003445
2022-01-16 01:19:51,068 iteration 5895 : loss : 0.019110, loss_ce: 0.007921
2022-01-16 01:19:51,904 iteration 5896 : loss : 0.013629, loss_ce: 0.004554
2022-01-16 01:19:52,849 iteration 5897 : loss : 0.018065, loss_ce: 0.009189
2022-01-16 01:19:53,847 iteration 5898 : loss : 0.019843, loss_ce: 0.007751
2022-01-16 01:19:54,769 iteration 5899 : loss : 0.019637, loss_ce: 0.006728
 87%|█████████████████████████▏   | 347/400 [1:40:15<15:01, 17.02s/it]2022-01-16 01:19:55,659 iteration 5900 : loss : 0.013739, loss_ce: 0.005765
2022-01-16 01:19:56,548 iteration 5901 : loss : 0.012935, loss_ce: 0.005339
2022-01-16 01:19:57,387 iteration 5902 : loss : 0.014181, loss_ce: 0.005466
2022-01-16 01:19:58,275 iteration 5903 : loss : 0.016548, loss_ce: 0.006591
2022-01-16 01:19:59,220 iteration 5904 : loss : 0.019631, loss_ce: 0.005186
2022-01-16 01:20:00,195 iteration 5905 : loss : 0.019841, loss_ce: 0.010143
2022-01-16 01:20:01,198 iteration 5906 : loss : 0.023940, loss_ce: 0.006608
2022-01-16 01:20:02,055 iteration 5907 : loss : 0.012795, loss_ce: 0.005531
2022-01-16 01:20:02,989 iteration 5908 : loss : 0.023053, loss_ce: 0.007053
2022-01-16 01:20:03,974 iteration 5909 : loss : 0.018119, loss_ce: 0.008136
2022-01-16 01:20:04,903 iteration 5910 : loss : 0.014122, loss_ce: 0.004569
2022-01-16 01:20:05,874 iteration 5911 : loss : 0.018044, loss_ce: 0.004637
2022-01-16 01:20:06,826 iteration 5912 : loss : 0.027395, loss_ce: 0.006703
2022-01-16 01:20:07,757 iteration 5913 : loss : 0.017593, loss_ce: 0.007216
2022-01-16 01:20:08,671 iteration 5914 : loss : 0.015530, loss_ce: 0.007385
2022-01-16 01:20:09,644 iteration 5915 : loss : 0.017825, loss_ce: 0.009188
2022-01-16 01:20:10,520 iteration 5916 : loss : 0.013955, loss_ce: 0.004872
 87%|█████████████████████████▏   | 348/400 [1:40:31<14:25, 16.63s/it]2022-01-16 01:20:11,466 iteration 5917 : loss : 0.016199, loss_ce: 0.006780
2022-01-16 01:20:12,484 iteration 5918 : loss : 0.030085, loss_ce: 0.016125
2022-01-16 01:20:13,505 iteration 5919 : loss : 0.020058, loss_ce: 0.006707
2022-01-16 01:20:14,533 iteration 5920 : loss : 0.017561, loss_ce: 0.006532
2022-01-16 01:20:15,465 iteration 5921 : loss : 0.017510, loss_ce: 0.005838
2022-01-16 01:20:16,452 iteration 5922 : loss : 0.020561, loss_ce: 0.009954
2022-01-16 01:20:17,409 iteration 5923 : loss : 0.016060, loss_ce: 0.006412
2022-01-16 01:20:18,255 iteration 5924 : loss : 0.018355, loss_ce: 0.007425
2022-01-16 01:20:19,178 iteration 5925 : loss : 0.017737, loss_ce: 0.005694
2022-01-16 01:20:20,190 iteration 5926 : loss : 0.021042, loss_ce: 0.006117
2022-01-16 01:20:21,084 iteration 5927 : loss : 0.012289, loss_ce: 0.005063
2022-01-16 01:20:22,082 iteration 5928 : loss : 0.015129, loss_ce: 0.006404
2022-01-16 01:20:23,052 iteration 5929 : loss : 0.021404, loss_ce: 0.009256
2022-01-16 01:20:24,074 iteration 5930 : loss : 0.025368, loss_ce: 0.009551
2022-01-16 01:20:24,961 iteration 5931 : loss : 0.020374, loss_ce: 0.008068
2022-01-16 01:20:25,916 iteration 5932 : loss : 0.012642, loss_ce: 0.003765
2022-01-16 01:20:26,897 iteration 5933 : loss : 0.025193, loss_ce: 0.006886
 87%|█████████████████████████▎   | 349/400 [1:40:47<14:04, 16.56s/it]2022-01-16 01:20:27,928 iteration 5934 : loss : 0.011881, loss_ce: 0.003681
2022-01-16 01:20:28,883 iteration 5935 : loss : 0.013540, loss_ce: 0.004185
2022-01-16 01:20:29,951 iteration 5936 : loss : 0.018569, loss_ce: 0.005973
2022-01-16 01:20:30,983 iteration 5937 : loss : 0.019127, loss_ce: 0.008181
2022-01-16 01:20:31,955 iteration 5938 : loss : 0.023834, loss_ce: 0.008753
2022-01-16 01:20:32,873 iteration 5939 : loss : 0.021454, loss_ce: 0.008100
2022-01-16 01:20:33,848 iteration 5940 : loss : 0.017440, loss_ce: 0.007302
2022-01-16 01:20:34,689 iteration 5941 : loss : 0.014687, loss_ce: 0.006561
2022-01-16 01:20:35,672 iteration 5942 : loss : 0.019305, loss_ce: 0.006307
2022-01-16 01:20:36,540 iteration 5943 : loss : 0.011280, loss_ce: 0.004198
2022-01-16 01:20:37,474 iteration 5944 : loss : 0.013713, loss_ce: 0.004913
2022-01-16 01:20:38,391 iteration 5945 : loss : 0.013819, loss_ce: 0.004535
2022-01-16 01:20:39,270 iteration 5946 : loss : 0.015827, loss_ce: 0.006460
2022-01-16 01:20:40,138 iteration 5947 : loss : 0.013849, loss_ce: 0.005106
2022-01-16 01:20:41,138 iteration 5948 : loss : 0.017736, loss_ce: 0.007499
2022-01-16 01:20:42,025 iteration 5949 : loss : 0.014947, loss_ce: 0.005930
2022-01-16 01:20:42,025 Training Data Eval:
2022-01-16 01:20:46,420   Average segmentation loss on training set: 0.0097
2022-01-16 01:20:46,421 Validation Data Eval:
2022-01-16 01:20:47,878   Average segmentation loss on validation set: 0.0827
2022-01-16 01:20:48,891 iteration 5950 : loss : 0.021302, loss_ce: 0.005861
 88%|█████████████████████████▍   | 350/400 [1:41:09<15:09, 18.19s/it]2022-01-16 01:20:49,854 iteration 5951 : loss : 0.012841, loss_ce: 0.003287
2022-01-16 01:20:50,802 iteration 5952 : loss : 0.016268, loss_ce: 0.008038
2022-01-16 01:20:51,756 iteration 5953 : loss : 0.019587, loss_ce: 0.007997
2022-01-16 01:20:52,783 iteration 5954 : loss : 0.029245, loss_ce: 0.008848
2022-01-16 01:20:53,709 iteration 5955 : loss : 0.015046, loss_ce: 0.005157
2022-01-16 01:20:54,733 iteration 5956 : loss : 0.021602, loss_ce: 0.007572
2022-01-16 01:20:55,656 iteration 5957 : loss : 0.020237, loss_ce: 0.005145
2022-01-16 01:20:56,553 iteration 5958 : loss : 0.013739, loss_ce: 0.006026
2022-01-16 01:20:57,481 iteration 5959 : loss : 0.018463, loss_ce: 0.005746
2022-01-16 01:20:58,363 iteration 5960 : loss : 0.013417, loss_ce: 0.004299
2022-01-16 01:20:59,322 iteration 5961 : loss : 0.019721, loss_ce: 0.007265
2022-01-16 01:21:00,316 iteration 5962 : loss : 0.017633, loss_ce: 0.006942
2022-01-16 01:21:01,170 iteration 5963 : loss : 0.012127, loss_ce: 0.005235
2022-01-16 01:21:02,290 iteration 5964 : loss : 0.031263, loss_ce: 0.012693
2022-01-16 01:21:03,200 iteration 5965 : loss : 0.016431, loss_ce: 0.006865
2022-01-16 01:21:04,185 iteration 5966 : loss : 0.018546, loss_ce: 0.007048
2022-01-16 01:21:05,083 iteration 5967 : loss : 0.021310, loss_ce: 0.007225
 88%|█████████████████████████▍   | 351/400 [1:41:26<14:21, 17.59s/it]2022-01-16 01:21:06,062 iteration 5968 : loss : 0.017289, loss_ce: 0.007524
2022-01-16 01:21:07,048 iteration 5969 : loss : 0.018287, loss_ce: 0.005296
2022-01-16 01:21:07,999 iteration 5970 : loss : 0.013334, loss_ce: 0.004654
2022-01-16 01:21:08,842 iteration 5971 : loss : 0.013258, loss_ce: 0.005207
2022-01-16 01:21:09,732 iteration 5972 : loss : 0.027472, loss_ce: 0.010773
2022-01-16 01:21:10,674 iteration 5973 : loss : 0.011867, loss_ce: 0.004731
2022-01-16 01:21:11,550 iteration 5974 : loss : 0.017624, loss_ce: 0.005954
2022-01-16 01:21:12,524 iteration 5975 : loss : 0.024072, loss_ce: 0.007359
2022-01-16 01:21:13,472 iteration 5976 : loss : 0.045033, loss_ce: 0.013645
2022-01-16 01:21:14,445 iteration 5977 : loss : 0.014968, loss_ce: 0.005172
2022-01-16 01:21:15,395 iteration 5978 : loss : 0.018736, loss_ce: 0.007684
2022-01-16 01:21:16,286 iteration 5979 : loss : 0.015200, loss_ce: 0.005806
2022-01-16 01:21:17,273 iteration 5980 : loss : 0.011233, loss_ce: 0.003668
2022-01-16 01:21:18,244 iteration 5981 : loss : 0.023794, loss_ce: 0.009643
2022-01-16 01:21:19,250 iteration 5982 : loss : 0.022494, loss_ce: 0.009084
2022-01-16 01:21:20,112 iteration 5983 : loss : 0.014502, loss_ce: 0.006880
2022-01-16 01:21:20,995 iteration 5984 : loss : 0.016211, loss_ce: 0.004983
 88%|█████████████████████████▌   | 352/400 [1:41:41<13:40, 17.09s/it]2022-01-16 01:21:22,125 iteration 5985 : loss : 0.027968, loss_ce: 0.011594
2022-01-16 01:21:23,034 iteration 5986 : loss : 0.014820, loss_ce: 0.006300
2022-01-16 01:21:24,032 iteration 5987 : loss : 0.096620, loss_ce: 0.017781
2022-01-16 01:21:25,065 iteration 5988 : loss : 0.021073, loss_ce: 0.009893
2022-01-16 01:21:25,997 iteration 5989 : loss : 0.016991, loss_ce: 0.006525
2022-01-16 01:21:26,977 iteration 5990 : loss : 0.018127, loss_ce: 0.009835
2022-01-16 01:21:27,829 iteration 5991 : loss : 0.016697, loss_ce: 0.005810
2022-01-16 01:21:28,814 iteration 5992 : loss : 0.020593, loss_ce: 0.006197
2022-01-16 01:21:29,698 iteration 5993 : loss : 0.010409, loss_ce: 0.003275
2022-01-16 01:21:30,624 iteration 5994 : loss : 0.026667, loss_ce: 0.008051
2022-01-16 01:21:31,586 iteration 5995 : loss : 0.019914, loss_ce: 0.007541
2022-01-16 01:21:32,608 iteration 5996 : loss : 0.018437, loss_ce: 0.006647
2022-01-16 01:21:33,624 iteration 5997 : loss : 0.018810, loss_ce: 0.008217
2022-01-16 01:21:34,515 iteration 5998 : loss : 0.015788, loss_ce: 0.005555
2022-01-16 01:21:35,484 iteration 5999 : loss : 0.027603, loss_ce: 0.007926
2022-01-16 01:21:36,453 iteration 6000 : loss : 0.023091, loss_ce: 0.009911
2022-01-16 01:21:37,468 iteration 6001 : loss : 0.024981, loss_ce: 0.008592
 88%|█████████████████████████▌   | 353/400 [1:41:58<13:14, 16.90s/it]2022-01-16 01:21:38,489 iteration 6002 : loss : 0.017367, loss_ce: 0.008287
2022-01-16 01:21:39,492 iteration 6003 : loss : 0.019686, loss_ce: 0.006565
2022-01-16 01:21:40,441 iteration 6004 : loss : 0.013669, loss_ce: 0.005667
2022-01-16 01:21:41,420 iteration 6005 : loss : 0.017998, loss_ce: 0.007737
2022-01-16 01:21:42,291 iteration 6006 : loss : 0.014941, loss_ce: 0.007205
2022-01-16 01:21:43,229 iteration 6007 : loss : 0.021257, loss_ce: 0.008453
2022-01-16 01:21:44,167 iteration 6008 : loss : 0.019279, loss_ce: 0.007374
2022-01-16 01:21:45,198 iteration 6009 : loss : 0.031382, loss_ce: 0.012936
2022-01-16 01:21:46,038 iteration 6010 : loss : 0.013424, loss_ce: 0.005485
2022-01-16 01:21:47,004 iteration 6011 : loss : 0.021217, loss_ce: 0.007413
2022-01-16 01:21:47,942 iteration 6012 : loss : 0.024514, loss_ce: 0.006721
2022-01-16 01:21:48,993 iteration 6013 : loss : 0.028352, loss_ce: 0.009659
2022-01-16 01:21:49,929 iteration 6014 : loss : 0.018888, loss_ce: 0.007271
2022-01-16 01:21:50,828 iteration 6015 : loss : 0.014848, loss_ce: 0.005315
2022-01-16 01:21:51,772 iteration 6016 : loss : 0.016858, loss_ce: 0.005142
2022-01-16 01:21:52,646 iteration 6017 : loss : 0.021297, loss_ce: 0.005925
2022-01-16 01:21:53,681 iteration 6018 : loss : 0.018577, loss_ce: 0.008232
 88%|█████████████████████████▋   | 354/400 [1:42:14<12:48, 16.70s/it]2022-01-16 01:21:54,744 iteration 6019 : loss : 0.023330, loss_ce: 0.008884
2022-01-16 01:21:55,685 iteration 6020 : loss : 0.015573, loss_ce: 0.006038
2022-01-16 01:21:56,621 iteration 6021 : loss : 0.018804, loss_ce: 0.006957
2022-01-16 01:21:57,575 iteration 6022 : loss : 0.023828, loss_ce: 0.011240
2022-01-16 01:21:58,426 iteration 6023 : loss : 0.012051, loss_ce: 0.004012
2022-01-16 01:21:59,429 iteration 6024 : loss : 0.025002, loss_ce: 0.009640
2022-01-16 01:22:00,429 iteration 6025 : loss : 0.021290, loss_ce: 0.008491
2022-01-16 01:22:01,423 iteration 6026 : loss : 0.018353, loss_ce: 0.006919
2022-01-16 01:22:02,330 iteration 6027 : loss : 0.014847, loss_ce: 0.006518
2022-01-16 01:22:03,218 iteration 6028 : loss : 0.016440, loss_ce: 0.006819
2022-01-16 01:22:04,209 iteration 6029 : loss : 0.032548, loss_ce: 0.014016
2022-01-16 01:22:05,096 iteration 6030 : loss : 0.015503, loss_ce: 0.005188
2022-01-16 01:22:06,144 iteration 6031 : loss : 0.032985, loss_ce: 0.008208
2022-01-16 01:22:07,135 iteration 6032 : loss : 0.017912, loss_ce: 0.005466
2022-01-16 01:22:08,118 iteration 6033 : loss : 0.021713, loss_ce: 0.009687
2022-01-16 01:22:09,152 iteration 6034 : loss : 0.015742, loss_ce: 0.005055
2022-01-16 01:22:09,152 Training Data Eval:
2022-01-16 01:22:13,534   Average segmentation loss on training set: 0.0101
2022-01-16 01:22:13,534 Validation Data Eval:
2022-01-16 01:22:14,993   Average segmentation loss on validation set: 0.0906
2022-01-16 01:22:15,855 iteration 6035 : loss : 0.014499, loss_ce: 0.003879
 89%|█████████████████████████▋   | 355/400 [1:42:36<13:45, 18.34s/it]2022-01-16 01:22:16,892 iteration 6036 : loss : 0.018288, loss_ce: 0.005928
2022-01-16 01:22:17,909 iteration 6037 : loss : 0.020627, loss_ce: 0.008034
2022-01-16 01:22:18,816 iteration 6038 : loss : 0.021729, loss_ce: 0.008399
2022-01-16 01:22:19,761 iteration 6039 : loss : 0.017088, loss_ce: 0.007389
2022-01-16 01:22:20,694 iteration 6040 : loss : 0.014268, loss_ce: 0.006740
2022-01-16 01:22:21,769 iteration 6041 : loss : 0.030731, loss_ce: 0.009444
2022-01-16 01:22:22,783 iteration 6042 : loss : 0.022379, loss_ce: 0.009814
2022-01-16 01:22:23,736 iteration 6043 : loss : 0.015254, loss_ce: 0.006399
2022-01-16 01:22:24,657 iteration 6044 : loss : 0.017753, loss_ce: 0.005255
2022-01-16 01:22:25,652 iteration 6045 : loss : 0.018548, loss_ce: 0.006530
2022-01-16 01:22:26,598 iteration 6046 : loss : 0.019119, loss_ce: 0.005819
2022-01-16 01:22:27,504 iteration 6047 : loss : 0.017416, loss_ce: 0.004568
2022-01-16 01:22:28,557 iteration 6048 : loss : 0.025459, loss_ce: 0.004343
2022-01-16 01:22:29,551 iteration 6049 : loss : 0.015310, loss_ce: 0.006947
2022-01-16 01:22:30,459 iteration 6050 : loss : 0.016093, loss_ce: 0.006616
2022-01-16 01:22:31,470 iteration 6051 : loss : 0.016144, loss_ce: 0.006598
2022-01-16 01:22:32,316 iteration 6052 : loss : 0.013965, loss_ce: 0.003590
 89%|█████████████████████████▊   | 356/400 [1:42:53<13:02, 17.77s/it]2022-01-16 01:22:33,285 iteration 6053 : loss : 0.018308, loss_ce: 0.008140
2022-01-16 01:22:34,328 iteration 6054 : loss : 0.028657, loss_ce: 0.012076
2022-01-16 01:22:35,252 iteration 6055 : loss : 0.013623, loss_ce: 0.004833
2022-01-16 01:22:36,155 iteration 6056 : loss : 0.015118, loss_ce: 0.005611
2022-01-16 01:22:37,049 iteration 6057 : loss : 0.015217, loss_ce: 0.004985
2022-01-16 01:22:38,046 iteration 6058 : loss : 0.017708, loss_ce: 0.008327
2022-01-16 01:22:38,915 iteration 6059 : loss : 0.011938, loss_ce: 0.004586
2022-01-16 01:22:39,916 iteration 6060 : loss : 0.013209, loss_ce: 0.005242
2022-01-16 01:22:40,792 iteration 6061 : loss : 0.016698, loss_ce: 0.007013
2022-01-16 01:22:41,831 iteration 6062 : loss : 0.016910, loss_ce: 0.007881
2022-01-16 01:22:42,862 iteration 6063 : loss : 0.021763, loss_ce: 0.006964
2022-01-16 01:22:43,809 iteration 6064 : loss : 0.028490, loss_ce: 0.008273
2022-01-16 01:22:44,847 iteration 6065 : loss : 0.021339, loss_ce: 0.010566
2022-01-16 01:22:45,776 iteration 6066 : loss : 0.014794, loss_ce: 0.005238
2022-01-16 01:22:46,664 iteration 6067 : loss : 0.019493, loss_ce: 0.004079
2022-01-16 01:22:47,709 iteration 6068 : loss : 0.028484, loss_ce: 0.008769
2022-01-16 01:22:48,621 iteration 6069 : loss : 0.018127, loss_ce: 0.002609
 89%|█████████████████████████▉   | 357/400 [1:43:09<12:25, 17.33s/it]2022-01-16 01:22:49,680 iteration 6070 : loss : 0.022276, loss_ce: 0.011889
2022-01-16 01:22:50,672 iteration 6071 : loss : 0.016102, loss_ce: 0.004630
2022-01-16 01:22:51,628 iteration 6072 : loss : 0.014378, loss_ce: 0.004791
2022-01-16 01:22:52,611 iteration 6073 : loss : 0.019837, loss_ce: 0.006837
2022-01-16 01:22:53,573 iteration 6074 : loss : 0.014084, loss_ce: 0.004055
2022-01-16 01:22:54,595 iteration 6075 : loss : 0.015841, loss_ce: 0.006538
2022-01-16 01:22:55,513 iteration 6076 : loss : 0.017825, loss_ce: 0.008105
2022-01-16 01:22:56,417 iteration 6077 : loss : 0.015723, loss_ce: 0.006806
2022-01-16 01:22:57,339 iteration 6078 : loss : 0.015699, loss_ce: 0.004860
2022-01-16 01:22:58,295 iteration 6079 : loss : 0.025940, loss_ce: 0.007850
2022-01-16 01:22:59,240 iteration 6080 : loss : 0.016028, loss_ce: 0.004932
2022-01-16 01:23:00,088 iteration 6081 : loss : 0.018821, loss_ce: 0.006427
2022-01-16 01:23:01,090 iteration 6082 : loss : 0.024257, loss_ce: 0.009518
2022-01-16 01:23:02,119 iteration 6083 : loss : 0.023463, loss_ce: 0.009099
2022-01-16 01:23:03,005 iteration 6084 : loss : 0.015397, loss_ce: 0.004442
2022-01-16 01:23:03,894 iteration 6085 : loss : 0.014767, loss_ce: 0.007313
2022-01-16 01:23:04,974 iteration 6086 : loss : 0.029793, loss_ce: 0.011686
 90%|█████████████████████████▉   | 358/400 [1:43:25<11:55, 17.04s/it]2022-01-16 01:23:05,989 iteration 6087 : loss : 0.021442, loss_ce: 0.006019
2022-01-16 01:23:06,937 iteration 6088 : loss : 0.014775, loss_ce: 0.004819
2022-01-16 01:23:07,939 iteration 6089 : loss : 0.018011, loss_ce: 0.008282
2022-01-16 01:23:08,856 iteration 6090 : loss : 0.014991, loss_ce: 0.004983
2022-01-16 01:23:09,748 iteration 6091 : loss : 0.009865, loss_ce: 0.002839
2022-01-16 01:23:10,770 iteration 6092 : loss : 0.018452, loss_ce: 0.006575
2022-01-16 01:23:11,831 iteration 6093 : loss : 0.017036, loss_ce: 0.007330
2022-01-16 01:23:12,854 iteration 6094 : loss : 0.021757, loss_ce: 0.009757
2022-01-16 01:23:13,727 iteration 6095 : loss : 0.014495, loss_ce: 0.004062
2022-01-16 01:23:14,757 iteration 6096 : loss : 0.024947, loss_ce: 0.006559
2022-01-16 01:23:15,639 iteration 6097 : loss : 0.014951, loss_ce: 0.007693
2022-01-16 01:23:16,602 iteration 6098 : loss : 0.014838, loss_ce: 0.007569
2022-01-16 01:23:17,538 iteration 6099 : loss : 0.019358, loss_ce: 0.009627
2022-01-16 01:23:18,516 iteration 6100 : loss : 0.032472, loss_ce: 0.009731
2022-01-16 01:23:19,551 iteration 6101 : loss : 0.025767, loss_ce: 0.011542
2022-01-16 01:23:20,444 iteration 6102 : loss : 0.020657, loss_ce: 0.008166
2022-01-16 01:23:21,408 iteration 6103 : loss : 0.022080, loss_ce: 0.006884
 90%|██████████████████████████   | 359/400 [1:43:42<11:31, 16.86s/it]2022-01-16 01:23:22,474 iteration 6104 : loss : 0.015331, loss_ce: 0.005946
2022-01-16 01:23:23,390 iteration 6105 : loss : 0.014959, loss_ce: 0.004412
2022-01-16 01:23:24,270 iteration 6106 : loss : 0.011262, loss_ce: 0.004713
2022-01-16 01:23:25,152 iteration 6107 : loss : 0.013826, loss_ce: 0.005773
2022-01-16 01:23:26,080 iteration 6108 : loss : 0.017559, loss_ce: 0.007385
2022-01-16 01:23:27,066 iteration 6109 : loss : 0.022439, loss_ce: 0.009189
2022-01-16 01:23:27,943 iteration 6110 : loss : 0.013777, loss_ce: 0.006258
2022-01-16 01:23:28,894 iteration 6111 : loss : 0.028793, loss_ce: 0.010288
2022-01-16 01:23:29,888 iteration 6112 : loss : 0.022117, loss_ce: 0.007425
2022-01-16 01:23:30,821 iteration 6113 : loss : 0.029232, loss_ce: 0.013417
2022-01-16 01:23:31,799 iteration 6114 : loss : 0.021934, loss_ce: 0.010838
2022-01-16 01:23:32,804 iteration 6115 : loss : 0.017775, loss_ce: 0.005017
2022-01-16 01:23:33,739 iteration 6116 : loss : 0.014740, loss_ce: 0.004741
2022-01-16 01:23:34,649 iteration 6117 : loss : 0.016485, loss_ce: 0.006091
2022-01-16 01:23:35,617 iteration 6118 : loss : 0.017491, loss_ce: 0.009369
2022-01-16 01:23:36,544 iteration 6119 : loss : 0.015231, loss_ce: 0.006585
2022-01-16 01:23:36,544 Training Data Eval:
2022-01-16 01:23:40,921   Average segmentation loss on training set: 0.0097
2022-01-16 01:23:40,921 Validation Data Eval:
2022-01-16 01:23:42,384   Average segmentation loss on validation set: 0.0790
2022-01-16 01:23:43,368 iteration 6120 : loss : 0.025357, loss_ce: 0.009659
 90%|██████████████████████████   | 360/400 [1:44:04<12:15, 18.39s/it]2022-01-16 01:23:44,424 iteration 6121 : loss : 0.017578, loss_ce: 0.005163
2022-01-16 01:23:45,373 iteration 6122 : loss : 0.015645, loss_ce: 0.006409
2022-01-16 01:23:46,299 iteration 6123 : loss : 0.015870, loss_ce: 0.006347
2022-01-16 01:23:47,329 iteration 6124 : loss : 0.020932, loss_ce: 0.007190
2022-01-16 01:23:48,278 iteration 6125 : loss : 0.015078, loss_ce: 0.004707
2022-01-16 01:23:49,345 iteration 6126 : loss : 0.018900, loss_ce: 0.006987
2022-01-16 01:23:50,408 iteration 6127 : loss : 0.022305, loss_ce: 0.010733
2022-01-16 01:23:51,348 iteration 6128 : loss : 0.016920, loss_ce: 0.006122
2022-01-16 01:23:52,238 iteration 6129 : loss : 0.016592, loss_ce: 0.005412
2022-01-16 01:23:53,195 iteration 6130 : loss : 0.018367, loss_ce: 0.008301
2022-01-16 01:23:54,088 iteration 6131 : loss : 0.016829, loss_ce: 0.005042
2022-01-16 01:23:55,094 iteration 6132 : loss : 0.021363, loss_ce: 0.006429
2022-01-16 01:23:56,082 iteration 6133 : loss : 0.016320, loss_ce: 0.006726
2022-01-16 01:23:57,001 iteration 6134 : loss : 0.013445, loss_ce: 0.004599
2022-01-16 01:23:57,880 iteration 6135 : loss : 0.014636, loss_ce: 0.006620
2022-01-16 01:23:58,775 iteration 6136 : loss : 0.013150, loss_ce: 0.004195
2022-01-16 01:23:59,673 iteration 6137 : loss : 0.024024, loss_ce: 0.007459
 90%|██████████████████████████▏  | 361/400 [1:44:20<11:32, 17.76s/it]2022-01-16 01:24:00,632 iteration 6138 : loss : 0.024269, loss_ce: 0.008200
2022-01-16 01:24:01,536 iteration 6139 : loss : 0.013036, loss_ce: 0.002719
2022-01-16 01:24:02,426 iteration 6140 : loss : 0.017488, loss_ce: 0.005925
2022-01-16 01:24:03,294 iteration 6141 : loss : 0.014003, loss_ce: 0.006238
2022-01-16 01:24:04,270 iteration 6142 : loss : 0.016255, loss_ce: 0.006512
2022-01-16 01:24:05,155 iteration 6143 : loss : 0.017786, loss_ce: 0.007626
2022-01-16 01:24:06,188 iteration 6144 : loss : 0.016275, loss_ce: 0.006827
2022-01-16 01:24:07,075 iteration 6145 : loss : 0.016086, loss_ce: 0.006426
2022-01-16 01:24:07,925 iteration 6146 : loss : 0.015910, loss_ce: 0.005017
2022-01-16 01:24:08,839 iteration 6147 : loss : 0.017387, loss_ce: 0.006381
2022-01-16 01:24:09,753 iteration 6148 : loss : 0.020602, loss_ce: 0.009094
2022-01-16 01:24:10,647 iteration 6149 : loss : 0.012202, loss_ce: 0.004429
2022-01-16 01:24:11,621 iteration 6150 : loss : 0.020140, loss_ce: 0.007071
2022-01-16 01:24:12,720 iteration 6151 : loss : 0.015524, loss_ce: 0.004378
2022-01-16 01:24:13,652 iteration 6152 : loss : 0.013232, loss_ce: 0.005150
2022-01-16 01:24:14,625 iteration 6153 : loss : 0.017279, loss_ce: 0.006208
2022-01-16 01:24:15,658 iteration 6154 : loss : 0.021032, loss_ce: 0.007418
 90%|██████████████████████████▏  | 362/400 [1:44:36<10:54, 17.23s/it]2022-01-16 01:24:16,751 iteration 6155 : loss : 0.024652, loss_ce: 0.009368
2022-01-16 01:24:17,642 iteration 6156 : loss : 0.011818, loss_ce: 0.004854
2022-01-16 01:24:18,568 iteration 6157 : loss : 0.011425, loss_ce: 0.003570
2022-01-16 01:24:19,535 iteration 6158 : loss : 0.020021, loss_ce: 0.007141
2022-01-16 01:24:20,426 iteration 6159 : loss : 0.025235, loss_ce: 0.009439
2022-01-16 01:24:21,352 iteration 6160 : loss : 0.012805, loss_ce: 0.004833
2022-01-16 01:24:22,305 iteration 6161 : loss : 0.014592, loss_ce: 0.004252
2022-01-16 01:24:23,294 iteration 6162 : loss : 0.017382, loss_ce: 0.003955
2022-01-16 01:24:24,252 iteration 6163 : loss : 0.018388, loss_ce: 0.007449
2022-01-16 01:24:25,251 iteration 6164 : loss : 0.017666, loss_ce: 0.008028
2022-01-16 01:24:26,186 iteration 6165 : loss : 0.019936, loss_ce: 0.008917
2022-01-16 01:24:27,116 iteration 6166 : loss : 0.015860, loss_ce: 0.006585
2022-01-16 01:24:28,012 iteration 6167 : loss : 0.017301, loss_ce: 0.007038
2022-01-16 01:24:29,005 iteration 6168 : loss : 0.023649, loss_ce: 0.008845
2022-01-16 01:24:29,975 iteration 6169 : loss : 0.017958, loss_ce: 0.005407
2022-01-16 01:24:30,888 iteration 6170 : loss : 0.015835, loss_ce: 0.005968
2022-01-16 01:24:31,778 iteration 6171 : loss : 0.012024, loss_ce: 0.004444
 91%|██████████████████████████▎  | 363/400 [1:44:52<10:25, 16.90s/it]2022-01-16 01:24:32,747 iteration 6172 : loss : 0.017252, loss_ce: 0.007268
2022-01-16 01:24:33,777 iteration 6173 : loss : 0.020050, loss_ce: 0.007432
2022-01-16 01:24:34,712 iteration 6174 : loss : 0.014209, loss_ce: 0.005411
2022-01-16 01:24:35,705 iteration 6175 : loss : 0.020020, loss_ce: 0.007746
2022-01-16 01:24:36,665 iteration 6176 : loss : 0.014909, loss_ce: 0.005224
2022-01-16 01:24:37,707 iteration 6177 : loss : 0.021895, loss_ce: 0.009373
2022-01-16 01:24:38,658 iteration 6178 : loss : 0.019692, loss_ce: 0.008398
2022-01-16 01:24:39,601 iteration 6179 : loss : 0.013478, loss_ce: 0.006221
2022-01-16 01:24:40,546 iteration 6180 : loss : 0.016206, loss_ce: 0.005983
2022-01-16 01:24:41,379 iteration 6181 : loss : 0.011602, loss_ce: 0.003896
2022-01-16 01:24:42,332 iteration 6182 : loss : 0.019229, loss_ce: 0.004641
2022-01-16 01:24:43,354 iteration 6183 : loss : 0.021892, loss_ce: 0.008726
2022-01-16 01:24:44,323 iteration 6184 : loss : 0.025061, loss_ce: 0.007055
2022-01-16 01:24:45,246 iteration 6185 : loss : 0.024751, loss_ce: 0.008442
2022-01-16 01:24:46,200 iteration 6186 : loss : 0.015960, loss_ce: 0.005069
2022-01-16 01:24:47,213 iteration 6187 : loss : 0.014034, loss_ce: 0.004986
2022-01-16 01:24:48,059 iteration 6188 : loss : 0.014416, loss_ce: 0.004636
 91%|██████████████████████████▍  | 364/400 [1:45:09<10:01, 16.71s/it]2022-01-16 01:24:48,984 iteration 6189 : loss : 0.012032, loss_ce: 0.003140
2022-01-16 01:24:49,821 iteration 6190 : loss : 0.015591, loss_ce: 0.005359
2022-01-16 01:24:50,901 iteration 6191 : loss : 0.024457, loss_ce: 0.009042
2022-01-16 01:24:51,898 iteration 6192 : loss : 0.015729, loss_ce: 0.005673
2022-01-16 01:24:52,717 iteration 6193 : loss : 0.010777, loss_ce: 0.003990
2022-01-16 01:24:53,646 iteration 6194 : loss : 0.018135, loss_ce: 0.006702
2022-01-16 01:24:54,624 iteration 6195 : loss : 0.014691, loss_ce: 0.005743
2022-01-16 01:24:55,607 iteration 6196 : loss : 0.014410, loss_ce: 0.006557
2022-01-16 01:24:56,570 iteration 6197 : loss : 0.014958, loss_ce: 0.007729
2022-01-16 01:24:57,511 iteration 6198 : loss : 0.012731, loss_ce: 0.004532
2022-01-16 01:24:58,452 iteration 6199 : loss : 0.019872, loss_ce: 0.005918
2022-01-16 01:24:59,300 iteration 6200 : loss : 0.011795, loss_ce: 0.005447
2022-01-16 01:25:00,243 iteration 6201 : loss : 0.034170, loss_ce: 0.011759
2022-01-16 01:25:01,131 iteration 6202 : loss : 0.015026, loss_ce: 0.005986
2022-01-16 01:25:02,027 iteration 6203 : loss : 0.014017, loss_ce: 0.003400
2022-01-16 01:25:02,987 iteration 6204 : loss : 0.012201, loss_ce: 0.004952
2022-01-16 01:25:03,033 Training Data Eval:
2022-01-16 01:25:07,420   Average segmentation loss on training set: 0.0095
2022-01-16 01:25:07,421 Validation Data Eval:
2022-01-16 01:25:08,882   Average segmentation loss on validation set: 0.0953
2022-01-16 01:25:09,832 iteration 6205 : loss : 0.018453, loss_ce: 0.005499
 91%|██████████████████████████▍  | 365/400 [1:45:30<10:38, 18.24s/it]2022-01-16 01:25:10,858 iteration 6206 : loss : 0.019124, loss_ce: 0.009632
2022-01-16 01:25:11,762 iteration 6207 : loss : 0.016167, loss_ce: 0.004511
2022-01-16 01:25:12,785 iteration 6208 : loss : 0.031578, loss_ce: 0.009479
2022-01-16 01:25:13,697 iteration 6209 : loss : 0.016392, loss_ce: 0.004652
2022-01-16 01:25:14,575 iteration 6210 : loss : 0.017357, loss_ce: 0.006325
2022-01-16 01:25:15,549 iteration 6211 : loss : 0.017705, loss_ce: 0.007950
2022-01-16 01:25:16,450 iteration 6212 : loss : 0.014167, loss_ce: 0.004875
2022-01-16 01:25:17,354 iteration 6213 : loss : 0.031156, loss_ce: 0.008475
2022-01-16 01:25:18,256 iteration 6214 : loss : 0.016501, loss_ce: 0.003947
2022-01-16 01:25:19,223 iteration 6215 : loss : 0.017058, loss_ce: 0.007814
2022-01-16 01:25:20,166 iteration 6216 : loss : 0.030088, loss_ce: 0.008260
2022-01-16 01:25:21,012 iteration 6217 : loss : 0.014323, loss_ce: 0.004877
2022-01-16 01:25:21,948 iteration 6218 : loss : 0.015870, loss_ce: 0.007419
2022-01-16 01:25:22,855 iteration 6219 : loss : 0.017858, loss_ce: 0.007205
2022-01-16 01:25:23,780 iteration 6220 : loss : 0.015548, loss_ce: 0.004605
2022-01-16 01:25:24,815 iteration 6221 : loss : 0.018783, loss_ce: 0.009048
2022-01-16 01:25:25,774 iteration 6222 : loss : 0.015365, loss_ce: 0.007114
 92%|██████████████████████████▌  | 366/400 [1:45:46<09:56, 17.55s/it]2022-01-16 01:25:26,811 iteration 6223 : loss : 0.027420, loss_ce: 0.006839
2022-01-16 01:25:27,729 iteration 6224 : loss : 0.019167, loss_ce: 0.005728
2022-01-16 01:25:28,654 iteration 6225 : loss : 0.022635, loss_ce: 0.008549
2022-01-16 01:25:29,677 iteration 6226 : loss : 0.017420, loss_ce: 0.006242
2022-01-16 01:25:30,617 iteration 6227 : loss : 0.017874, loss_ce: 0.004593
2022-01-16 01:25:31,577 iteration 6228 : loss : 0.017260, loss_ce: 0.007402
2022-01-16 01:25:32,445 iteration 6229 : loss : 0.014926, loss_ce: 0.006372
2022-01-16 01:25:33,335 iteration 6230 : loss : 0.015000, loss_ce: 0.006428
2022-01-16 01:25:34,283 iteration 6231 : loss : 0.014334, loss_ce: 0.005855
2022-01-16 01:25:35,238 iteration 6232 : loss : 0.020920, loss_ce: 0.007781
2022-01-16 01:25:36,156 iteration 6233 : loss : 0.015935, loss_ce: 0.007090
2022-01-16 01:25:37,121 iteration 6234 : loss : 0.016291, loss_ce: 0.005944
2022-01-16 01:25:38,157 iteration 6235 : loss : 0.023428, loss_ce: 0.005317
2022-01-16 01:25:39,006 iteration 6236 : loss : 0.011715, loss_ce: 0.004753
2022-01-16 01:25:39,928 iteration 6237 : loss : 0.015805, loss_ce: 0.006064
2022-01-16 01:25:40,789 iteration 6238 : loss : 0.009448, loss_ce: 0.003375
2022-01-16 01:25:41,684 iteration 6239 : loss : 0.012097, loss_ce: 0.004897
 92%|██████████████████████████▌  | 367/400 [1:46:02<09:22, 17.05s/it]2022-01-16 01:25:42,737 iteration 6240 : loss : 0.015402, loss_ce: 0.006459
2022-01-16 01:25:43,721 iteration 6241 : loss : 0.018022, loss_ce: 0.008152
2022-01-16 01:25:44,711 iteration 6242 : loss : 0.016317, loss_ce: 0.006534
2022-01-16 01:25:45,569 iteration 6243 : loss : 0.013079, loss_ce: 0.004603
2022-01-16 01:25:46,456 iteration 6244 : loss : 0.019159, loss_ce: 0.005420
2022-01-16 01:25:47,363 iteration 6245 : loss : 0.016759, loss_ce: 0.006006
2022-01-16 01:25:48,255 iteration 6246 : loss : 0.023111, loss_ce: 0.008825
2022-01-16 01:25:49,147 iteration 6247 : loss : 0.017879, loss_ce: 0.004833
2022-01-16 01:25:50,137 iteration 6248 : loss : 0.019784, loss_ce: 0.008062
2022-01-16 01:25:51,044 iteration 6249 : loss : 0.021026, loss_ce: 0.007735
2022-01-16 01:25:52,011 iteration 6250 : loss : 0.025071, loss_ce: 0.013307
2022-01-16 01:25:53,051 iteration 6251 : loss : 0.016644, loss_ce: 0.005417
2022-01-16 01:25:54,038 iteration 6252 : loss : 0.024684, loss_ce: 0.005541
2022-01-16 01:25:54,940 iteration 6253 : loss : 0.017686, loss_ce: 0.004918
2022-01-16 01:25:55,793 iteration 6254 : loss : 0.011910, loss_ce: 0.004692
2022-01-16 01:25:56,786 iteration 6255 : loss : 0.013038, loss_ce: 0.004259
2022-01-16 01:25:57,726 iteration 6256 : loss : 0.013955, loss_ce: 0.005481
 92%|██████████████████████████▋  | 368/400 [1:46:18<08:55, 16.75s/it]2022-01-16 01:25:58,760 iteration 6257 : loss : 0.011711, loss_ce: 0.003859
2022-01-16 01:25:59,634 iteration 6258 : loss : 0.012852, loss_ce: 0.004244
2022-01-16 01:26:00,630 iteration 6259 : loss : 0.013387, loss_ce: 0.004985
2022-01-16 01:26:01,704 iteration 6260 : loss : 0.041815, loss_ce: 0.012258
2022-01-16 01:26:02,664 iteration 6261 : loss : 0.018683, loss_ce: 0.008337
2022-01-16 01:26:03,664 iteration 6262 : loss : 0.013476, loss_ce: 0.005417
2022-01-16 01:26:04,568 iteration 6263 : loss : 0.020367, loss_ce: 0.006572
2022-01-16 01:26:05,443 iteration 6264 : loss : 0.016003, loss_ce: 0.006565
2022-01-16 01:26:06,378 iteration 6265 : loss : 0.017518, loss_ce: 0.007673
2022-01-16 01:26:07,282 iteration 6266 : loss : 0.012980, loss_ce: 0.004741
2022-01-16 01:26:08,405 iteration 6267 : loss : 0.023563, loss_ce: 0.009727
2022-01-16 01:26:09,339 iteration 6268 : loss : 0.015978, loss_ce: 0.005228
2022-01-16 01:26:10,281 iteration 6269 : loss : 0.016558, loss_ce: 0.005985
2022-01-16 01:26:11,189 iteration 6270 : loss : 0.015303, loss_ce: 0.006467
2022-01-16 01:26:12,213 iteration 6271 : loss : 0.020989, loss_ce: 0.008389
2022-01-16 01:26:13,104 iteration 6272 : loss : 0.019909, loss_ce: 0.005503
2022-01-16 01:26:14,140 iteration 6273 : loss : 0.021518, loss_ce: 0.008437
 92%|██████████████████████████▊  | 369/400 [1:46:35<08:36, 16.65s/it]2022-01-16 01:26:15,255 iteration 6274 : loss : 0.016624, loss_ce: 0.005941
2022-01-16 01:26:16,164 iteration 6275 : loss : 0.024429, loss_ce: 0.006667
2022-01-16 01:26:17,032 iteration 6276 : loss : 0.014216, loss_ce: 0.005795
2022-01-16 01:26:17,970 iteration 6277 : loss : 0.012449, loss_ce: 0.004544
2022-01-16 01:26:18,981 iteration 6278 : loss : 0.021677, loss_ce: 0.008291
2022-01-16 01:26:19,981 iteration 6279 : loss : 0.022981, loss_ce: 0.008342
2022-01-16 01:26:20,859 iteration 6280 : loss : 0.015539, loss_ce: 0.005321
2022-01-16 01:26:21,770 iteration 6281 : loss : 0.024137, loss_ce: 0.006630
2022-01-16 01:26:22,702 iteration 6282 : loss : 0.018748, loss_ce: 0.009434
2022-01-16 01:26:23,737 iteration 6283 : loss : 0.021000, loss_ce: 0.009061
2022-01-16 01:26:24,711 iteration 6284 : loss : 0.014850, loss_ce: 0.004757
2022-01-16 01:26:25,675 iteration 6285 : loss : 0.015628, loss_ce: 0.006981
2022-01-16 01:26:26,676 iteration 6286 : loss : 0.017880, loss_ce: 0.008772
2022-01-16 01:26:27,618 iteration 6287 : loss : 0.017119, loss_ce: 0.006593
2022-01-16 01:26:28,467 iteration 6288 : loss : 0.013753, loss_ce: 0.004714
2022-01-16 01:26:29,381 iteration 6289 : loss : 0.020783, loss_ce: 0.010295
2022-01-16 01:26:29,382 Training Data Eval:
2022-01-16 01:26:33,774   Average segmentation loss on training set: 0.0093
2022-01-16 01:26:33,775 Validation Data Eval:
2022-01-16 01:26:35,238   Average segmentation loss on validation set: 0.0861
2022-01-16 01:26:36,163 iteration 6290 : loss : 0.013899, loss_ce: 0.005353
 92%|██████████████████████████▊  | 370/400 [1:46:57<09:07, 18.26s/it]2022-01-16 01:26:37,131 iteration 6291 : loss : 0.013146, loss_ce: 0.004081
2022-01-16 01:26:37,967 iteration 6292 : loss : 0.014391, loss_ce: 0.004361
2022-01-16 01:26:38,854 iteration 6293 : loss : 0.014128, loss_ce: 0.003793
2022-01-16 01:26:39,875 iteration 6294 : loss : 0.031839, loss_ce: 0.009378
2022-01-16 01:26:40,811 iteration 6295 : loss : 0.012864, loss_ce: 0.004888
2022-01-16 01:26:41,662 iteration 6296 : loss : 0.012748, loss_ce: 0.004991
2022-01-16 01:26:42,662 iteration 6297 : loss : 0.018774, loss_ce: 0.009258
2022-01-16 01:26:43,594 iteration 6298 : loss : 0.016359, loss_ce: 0.007671
2022-01-16 01:26:44,523 iteration 6299 : loss : 0.018379, loss_ce: 0.006722
2022-01-16 01:26:45,505 iteration 6300 : loss : 0.027282, loss_ce: 0.008451
2022-01-16 01:26:46,460 iteration 6301 : loss : 0.013878, loss_ce: 0.006464
2022-01-16 01:26:47,478 iteration 6302 : loss : 0.020247, loss_ce: 0.008320
2022-01-16 01:26:48,380 iteration 6303 : loss : 0.015749, loss_ce: 0.005857
2022-01-16 01:26:49,342 iteration 6304 : loss : 0.017636, loss_ce: 0.007123
2022-01-16 01:26:50,243 iteration 6305 : loss : 0.017899, loss_ce: 0.005731
2022-01-16 01:26:51,175 iteration 6306 : loss : 0.019331, loss_ce: 0.008625
2022-01-16 01:26:52,082 iteration 6307 : loss : 0.014390, loss_ce: 0.004618
 93%|██████████████████████████▉  | 371/400 [1:47:13<08:29, 17.56s/it]2022-01-16 01:26:53,129 iteration 6308 : loss : 0.019326, loss_ce: 0.007387
2022-01-16 01:26:54,040 iteration 6309 : loss : 0.029794, loss_ce: 0.008292
2022-01-16 01:26:54,971 iteration 6310 : loss : 0.013050, loss_ce: 0.005277
2022-01-16 01:26:55,974 iteration 6311 : loss : 0.022330, loss_ce: 0.007401
2022-01-16 01:26:56,887 iteration 6312 : loss : 0.012302, loss_ce: 0.005478
2022-01-16 01:26:57,845 iteration 6313 : loss : 0.021061, loss_ce: 0.005763
2022-01-16 01:26:58,833 iteration 6314 : loss : 0.014144, loss_ce: 0.004961
2022-01-16 01:26:59,751 iteration 6315 : loss : 0.027365, loss_ce: 0.011651
2022-01-16 01:27:00,608 iteration 6316 : loss : 0.015052, loss_ce: 0.004903
2022-01-16 01:27:01,459 iteration 6317 : loss : 0.014888, loss_ce: 0.005154
2022-01-16 01:27:02,438 iteration 6318 : loss : 0.019120, loss_ce: 0.007142
2022-01-16 01:27:03,345 iteration 6319 : loss : 0.017125, loss_ce: 0.006779
2022-01-16 01:27:04,277 iteration 6320 : loss : 0.015035, loss_ce: 0.007637
2022-01-16 01:27:05,204 iteration 6321 : loss : 0.020032, loss_ce: 0.006570
2022-01-16 01:27:06,230 iteration 6322 : loss : 0.031467, loss_ce: 0.009755
2022-01-16 01:27:07,266 iteration 6323 : loss : 0.031492, loss_ce: 0.007115
2022-01-16 01:27:08,182 iteration 6324 : loss : 0.018560, loss_ce: 0.008035
 93%|██████████████████████████▉  | 372/400 [1:47:29<07:59, 17.12s/it]2022-01-16 01:27:09,136 iteration 6325 : loss : 0.015203, loss_ce: 0.007119
2022-01-16 01:27:09,989 iteration 6326 : loss : 0.010958, loss_ce: 0.004300
2022-01-16 01:27:10,983 iteration 6327 : loss : 0.014698, loss_ce: 0.005574
2022-01-16 01:27:11,902 iteration 6328 : loss : 0.014451, loss_ce: 0.004292
2022-01-16 01:27:12,773 iteration 6329 : loss : 0.014191, loss_ce: 0.004084
2022-01-16 01:27:13,706 iteration 6330 : loss : 0.013839, loss_ce: 0.004843
2022-01-16 01:27:14,853 iteration 6331 : loss : 0.025893, loss_ce: 0.008671
2022-01-16 01:27:15,752 iteration 6332 : loss : 0.016257, loss_ce: 0.006106
2022-01-16 01:27:16,716 iteration 6333 : loss : 0.012977, loss_ce: 0.003522
2022-01-16 01:27:17,658 iteration 6334 : loss : 0.019709, loss_ce: 0.009185
2022-01-16 01:27:18,705 iteration 6335 : loss : 0.018463, loss_ce: 0.007355
2022-01-16 01:27:19,568 iteration 6336 : loss : 0.016599, loss_ce: 0.006721
2022-01-16 01:27:20,531 iteration 6337 : loss : 0.015082, loss_ce: 0.005509
2022-01-16 01:27:21,579 iteration 6338 : loss : 0.028216, loss_ce: 0.004657
2022-01-16 01:27:22,493 iteration 6339 : loss : 0.021113, loss_ce: 0.008781
2022-01-16 01:27:23,397 iteration 6340 : loss : 0.015361, loss_ce: 0.009138
2022-01-16 01:27:24,353 iteration 6341 : loss : 0.013602, loss_ce: 0.004524
 93%|███████████████████████████  | 373/400 [1:47:45<07:34, 16.84s/it]2022-01-16 01:27:25,364 iteration 6342 : loss : 0.024715, loss_ce: 0.008965
2022-01-16 01:27:26,282 iteration 6343 : loss : 0.015555, loss_ce: 0.004528
2022-01-16 01:27:27,301 iteration 6344 : loss : 0.026967, loss_ce: 0.012026
2022-01-16 01:27:28,237 iteration 6345 : loss : 0.014569, loss_ce: 0.004052
2022-01-16 01:27:29,133 iteration 6346 : loss : 0.015466, loss_ce: 0.005718
2022-01-16 01:27:30,106 iteration 6347 : loss : 0.018316, loss_ce: 0.009317
2022-01-16 01:27:31,005 iteration 6348 : loss : 0.014336, loss_ce: 0.006088
2022-01-16 01:27:31,935 iteration 6349 : loss : 0.016679, loss_ce: 0.005389
2022-01-16 01:27:32,875 iteration 6350 : loss : 0.012809, loss_ce: 0.004358
2022-01-16 01:27:33,837 iteration 6351 : loss : 0.013179, loss_ce: 0.006253
2022-01-16 01:27:34,828 iteration 6352 : loss : 0.015380, loss_ce: 0.005489
2022-01-16 01:27:35,889 iteration 6353 : loss : 0.033263, loss_ce: 0.010845
2022-01-16 01:27:36,799 iteration 6354 : loss : 0.015534, loss_ce: 0.003912
2022-01-16 01:27:37,821 iteration 6355 : loss : 0.014589, loss_ce: 0.004892
2022-01-16 01:27:38,862 iteration 6356 : loss : 0.024167, loss_ce: 0.007655
2022-01-16 01:27:39,837 iteration 6357 : loss : 0.013557, loss_ce: 0.006328
2022-01-16 01:27:40,853 iteration 6358 : loss : 0.019919, loss_ce: 0.006657
 94%|███████████████████████████  | 374/400 [1:48:01<07:15, 16.74s/it]2022-01-16 01:27:41,864 iteration 6359 : loss : 0.013547, loss_ce: 0.004463
2022-01-16 01:27:42,679 iteration 6360 : loss : 0.010515, loss_ce: 0.003894
2022-01-16 01:27:43,703 iteration 6361 : loss : 0.014199, loss_ce: 0.004894
2022-01-16 01:27:44,659 iteration 6362 : loss : 0.014484, loss_ce: 0.006623
2022-01-16 01:27:45,707 iteration 6363 : loss : 0.031215, loss_ce: 0.009698
2022-01-16 01:27:46,699 iteration 6364 : loss : 0.012475, loss_ce: 0.003402
2022-01-16 01:27:47,643 iteration 6365 : loss : 0.020798, loss_ce: 0.009652
2022-01-16 01:27:48,574 iteration 6366 : loss : 0.016279, loss_ce: 0.005766
2022-01-16 01:27:49,585 iteration 6367 : loss : 0.017225, loss_ce: 0.007301
2022-01-16 01:27:50,565 iteration 6368 : loss : 0.026339, loss_ce: 0.007971
2022-01-16 01:27:51,506 iteration 6369 : loss : 0.015524, loss_ce: 0.003627
2022-01-16 01:27:52,479 iteration 6370 : loss : 0.018384, loss_ce: 0.008805
2022-01-16 01:27:53,366 iteration 6371 : loss : 0.012012, loss_ce: 0.004847
2022-01-16 01:27:54,326 iteration 6372 : loss : 0.022006, loss_ce: 0.009127
2022-01-16 01:27:55,207 iteration 6373 : loss : 0.012203, loss_ce: 0.005388
2022-01-16 01:27:56,041 iteration 6374 : loss : 0.012000, loss_ce: 0.004686
2022-01-16 01:27:56,041 Training Data Eval:
2022-01-16 01:28:00,419   Average segmentation loss on training set: 0.0091
2022-01-16 01:28:00,419 Validation Data Eval:
2022-01-16 01:28:01,880   Average segmentation loss on validation set: 0.0857
2022-01-16 01:28:02,853 iteration 6375 : loss : 0.015021, loss_ce: 0.007379
 94%|███████████████████████████▏ | 375/400 [1:48:23<07:37, 18.31s/it]2022-01-16 01:28:03,939 iteration 6376 : loss : 0.016227, loss_ce: 0.005539
2022-01-16 01:28:04,901 iteration 6377 : loss : 0.027162, loss_ce: 0.005667
2022-01-16 01:28:05,815 iteration 6378 : loss : 0.015108, loss_ce: 0.007441
2022-01-16 01:28:06,762 iteration 6379 : loss : 0.016502, loss_ce: 0.006940
2022-01-16 01:28:07,764 iteration 6380 : loss : 0.021241, loss_ce: 0.007541
2022-01-16 01:28:08,781 iteration 6381 : loss : 0.018931, loss_ce: 0.007890
2022-01-16 01:28:09,731 iteration 6382 : loss : 0.015491, loss_ce: 0.007473
2022-01-16 01:28:10,716 iteration 6383 : loss : 0.026422, loss_ce: 0.008660
2022-01-16 01:28:11,723 iteration 6384 : loss : 0.016607, loss_ce: 0.006454
2022-01-16 01:28:12,516 iteration 6385 : loss : 0.011396, loss_ce: 0.004695
2022-01-16 01:28:13,505 iteration 6386 : loss : 0.020352, loss_ce: 0.006253
2022-01-16 01:28:14,488 iteration 6387 : loss : 0.015433, loss_ce: 0.007430
2022-01-16 01:28:15,355 iteration 6388 : loss : 0.012020, loss_ce: 0.005672
2022-01-16 01:28:16,352 iteration 6389 : loss : 0.013922, loss_ce: 0.005697
2022-01-16 01:28:17,323 iteration 6390 : loss : 0.020214, loss_ce: 0.006695
2022-01-16 01:28:18,317 iteration 6391 : loss : 0.014789, loss_ce: 0.005789
2022-01-16 01:28:19,325 iteration 6392 : loss : 0.020678, loss_ce: 0.004690
 94%|███████████████████████████▎ | 376/400 [1:48:40<07:06, 17.76s/it]2022-01-16 01:28:20,291 iteration 6393 : loss : 0.012222, loss_ce: 0.005769
2022-01-16 01:28:21,213 iteration 6394 : loss : 0.012267, loss_ce: 0.005308
2022-01-16 01:28:22,102 iteration 6395 : loss : 0.010602, loss_ce: 0.003063
2022-01-16 01:28:23,070 iteration 6396 : loss : 0.015389, loss_ce: 0.005918
2022-01-16 01:28:24,062 iteration 6397 : loss : 0.017501, loss_ce: 0.005308
2022-01-16 01:28:25,066 iteration 6398 : loss : 0.017154, loss_ce: 0.006096
2022-01-16 01:28:25,968 iteration 6399 : loss : 0.016183, loss_ce: 0.004660
2022-01-16 01:28:26,880 iteration 6400 : loss : 0.012396, loss_ce: 0.005098
2022-01-16 01:28:27,736 iteration 6401 : loss : 0.012551, loss_ce: 0.004399
2022-01-16 01:28:28,713 iteration 6402 : loss : 0.015202, loss_ce: 0.006143
2022-01-16 01:28:29,608 iteration 6403 : loss : 0.014526, loss_ce: 0.005818
2022-01-16 01:28:30,475 iteration 6404 : loss : 0.012528, loss_ce: 0.006029
2022-01-16 01:28:31,562 iteration 6405 : loss : 0.020656, loss_ce: 0.007515
2022-01-16 01:28:32,436 iteration 6406 : loss : 0.011355, loss_ce: 0.004603
2022-01-16 01:28:33,390 iteration 6407 : loss : 0.020937, loss_ce: 0.007394
2022-01-16 01:28:34,368 iteration 6408 : loss : 0.028804, loss_ce: 0.010064
2022-01-16 01:28:35,250 iteration 6409 : loss : 0.010494, loss_ce: 0.003376
 94%|███████████████████████████▎ | 377/400 [1:48:56<06:35, 17.21s/it]2022-01-16 01:28:36,179 iteration 6410 : loss : 0.011625, loss_ce: 0.004263
2022-01-16 01:28:37,082 iteration 6411 : loss : 0.014584, loss_ce: 0.005423
2022-01-16 01:28:38,082 iteration 6412 : loss : 0.018432, loss_ce: 0.005468
2022-01-16 01:28:39,025 iteration 6413 : loss : 0.019517, loss_ce: 0.008283
2022-01-16 01:28:40,014 iteration 6414 : loss : 0.016050, loss_ce: 0.006451
2022-01-16 01:28:41,002 iteration 6415 : loss : 0.013037, loss_ce: 0.004016
2022-01-16 01:28:41,881 iteration 6416 : loss : 0.016886, loss_ce: 0.006230
2022-01-16 01:28:42,862 iteration 6417 : loss : 0.020489, loss_ce: 0.005608
2022-01-16 01:28:43,797 iteration 6418 : loss : 0.014630, loss_ce: 0.006378
2022-01-16 01:28:44,737 iteration 6419 : loss : 0.016622, loss_ce: 0.006542
2022-01-16 01:28:45,706 iteration 6420 : loss : 0.018975, loss_ce: 0.008726
2022-01-16 01:28:46,697 iteration 6421 : loss : 0.016450, loss_ce: 0.006694
2022-01-16 01:28:47,622 iteration 6422 : loss : 0.015255, loss_ce: 0.005970
2022-01-16 01:28:48,568 iteration 6423 : loss : 0.015564, loss_ce: 0.006636
2022-01-16 01:28:49,450 iteration 6424 : loss : 0.015036, loss_ce: 0.004751
2022-01-16 01:28:50,533 iteration 6425 : loss : 0.019546, loss_ce: 0.006893
2022-01-16 01:28:51,408 iteration 6426 : loss : 0.013832, loss_ce: 0.004690
 94%|███████████████████████████▍ | 378/400 [1:49:12<06:11, 16.90s/it]2022-01-16 01:28:52,441 iteration 6427 : loss : 0.017635, loss_ce: 0.007101
2022-01-16 01:28:53,429 iteration 6428 : loss : 0.021577, loss_ce: 0.006150
2022-01-16 01:28:54,359 iteration 6429 : loss : 0.015347, loss_ce: 0.006787
2022-01-16 01:28:55,369 iteration 6430 : loss : 0.017648, loss_ce: 0.009596
2022-01-16 01:28:56,303 iteration 6431 : loss : 0.022531, loss_ce: 0.006215
2022-01-16 01:28:57,243 iteration 6432 : loss : 0.015561, loss_ce: 0.005274
2022-01-16 01:28:58,188 iteration 6433 : loss : 0.017014, loss_ce: 0.005321
2022-01-16 01:28:59,134 iteration 6434 : loss : 0.021053, loss_ce: 0.008687
2022-01-16 01:28:59,964 iteration 6435 : loss : 0.010896, loss_ce: 0.003510
2022-01-16 01:29:00,839 iteration 6436 : loss : 0.011910, loss_ce: 0.005990
2022-01-16 01:29:01,693 iteration 6437 : loss : 0.012626, loss_ce: 0.004427
2022-01-16 01:29:02,542 iteration 6438 : loss : 0.011215, loss_ce: 0.005290
2022-01-16 01:29:03,545 iteration 6439 : loss : 0.021904, loss_ce: 0.007252
2022-01-16 01:29:04,493 iteration 6440 : loss : 0.013631, loss_ce: 0.004458
2022-01-16 01:29:05,449 iteration 6441 : loss : 0.013018, loss_ce: 0.005742
2022-01-16 01:29:06,388 iteration 6442 : loss : 0.014221, loss_ce: 0.006201
2022-01-16 01:29:07,292 iteration 6443 : loss : 0.013110, loss_ce: 0.004703
 95%|███████████████████████████▍ | 379/400 [1:49:28<05:48, 16.59s/it]2022-01-16 01:29:08,265 iteration 6444 : loss : 0.013621, loss_ce: 0.005856
2022-01-16 01:29:09,155 iteration 6445 : loss : 0.010473, loss_ce: 0.003915
2022-01-16 01:29:10,082 iteration 6446 : loss : 0.017750, loss_ce: 0.006345
2022-01-16 01:29:11,014 iteration 6447 : loss : 0.011246, loss_ce: 0.004657
2022-01-16 01:29:11,939 iteration 6448 : loss : 0.021539, loss_ce: 0.004845
2022-01-16 01:29:12,898 iteration 6449 : loss : 0.018159, loss_ce: 0.005779
2022-01-16 01:29:13,900 iteration 6450 : loss : 0.019921, loss_ce: 0.005515
2022-01-16 01:29:14,817 iteration 6451 : loss : 0.013801, loss_ce: 0.004977
2022-01-16 01:29:15,795 iteration 6452 : loss : 0.026787, loss_ce: 0.009266
2022-01-16 01:29:16,709 iteration 6453 : loss : 0.018954, loss_ce: 0.010195
2022-01-16 01:29:17,649 iteration 6454 : loss : 0.013735, loss_ce: 0.004512
2022-01-16 01:29:18,529 iteration 6455 : loss : 0.013043, loss_ce: 0.004839
2022-01-16 01:29:19,476 iteration 6456 : loss : 0.018399, loss_ce: 0.008362
2022-01-16 01:29:20,388 iteration 6457 : loss : 0.011965, loss_ce: 0.004980
2022-01-16 01:29:21,272 iteration 6458 : loss : 0.013967, loss_ce: 0.008677
2022-01-16 01:29:22,273 iteration 6459 : loss : 0.020762, loss_ce: 0.007976
2022-01-16 01:29:22,273 Training Data Eval:
2022-01-16 01:29:26,672   Average segmentation loss on training set: 0.0088
2022-01-16 01:29:26,672 Validation Data Eval:
2022-01-16 01:29:28,147   Average segmentation loss on validation set: 0.0819
2022-01-16 01:29:29,167 iteration 6460 : loss : 0.014020, loss_ce: 0.004734
 95%|███████████████████████████▌ | 380/400 [1:49:50<06:03, 18.17s/it]2022-01-16 01:29:30,147 iteration 6461 : loss : 0.012550, loss_ce: 0.003993
2022-01-16 01:29:31,098 iteration 6462 : loss : 0.016929, loss_ce: 0.006936
2022-01-16 01:29:31,974 iteration 6463 : loss : 0.012889, loss_ce: 0.005487
2022-01-16 01:29:32,882 iteration 6464 : loss : 0.012240, loss_ce: 0.004809
2022-01-16 01:29:33,809 iteration 6465 : loss : 0.011229, loss_ce: 0.004159
2022-01-16 01:29:34,732 iteration 6466 : loss : 0.015964, loss_ce: 0.007117
2022-01-16 01:29:35,666 iteration 6467 : loss : 0.015073, loss_ce: 0.007002
2022-01-16 01:29:36,539 iteration 6468 : loss : 0.012673, loss_ce: 0.004572
2022-01-16 01:29:37,521 iteration 6469 : loss : 0.020904, loss_ce: 0.006025
2022-01-16 01:29:38,487 iteration 6470 : loss : 0.013337, loss_ce: 0.005394
2022-01-16 01:29:39,445 iteration 6471 : loss : 0.016251, loss_ce: 0.006542
2022-01-16 01:29:40,330 iteration 6472 : loss : 0.022188, loss_ce: 0.007944
2022-01-16 01:29:41,306 iteration 6473 : loss : 0.016951, loss_ce: 0.007410
2022-01-16 01:29:42,274 iteration 6474 : loss : 0.012954, loss_ce: 0.005290
2022-01-16 01:29:43,265 iteration 6475 : loss : 0.016619, loss_ce: 0.005604
2022-01-16 01:29:44,234 iteration 6476 : loss : 0.021422, loss_ce: 0.008138
2022-01-16 01:29:45,184 iteration 6477 : loss : 0.015188, loss_ce: 0.006610
 95%|███████████████████████████▌ | 381/400 [1:50:06<05:33, 17.53s/it]2022-01-16 01:29:46,193 iteration 6478 : loss : 0.013578, loss_ce: 0.005268
2022-01-16 01:29:47,139 iteration 6479 : loss : 0.016684, loss_ce: 0.005365
2022-01-16 01:29:48,048 iteration 6480 : loss : 0.014785, loss_ce: 0.005679
2022-01-16 01:29:49,143 iteration 6481 : loss : 0.019893, loss_ce: 0.006042
2022-01-16 01:29:50,059 iteration 6482 : loss : 0.013817, loss_ce: 0.006912
2022-01-16 01:29:51,056 iteration 6483 : loss : 0.018346, loss_ce: 0.007579
2022-01-16 01:29:51,890 iteration 6484 : loss : 0.015451, loss_ce: 0.005114
2022-01-16 01:29:52,829 iteration 6485 : loss : 0.011825, loss_ce: 0.003369
2022-01-16 01:29:53,784 iteration 6486 : loss : 0.035316, loss_ce: 0.013809
2022-01-16 01:29:54,765 iteration 6487 : loss : 0.014560, loss_ce: 0.006300
2022-01-16 01:29:55,756 iteration 6488 : loss : 0.012039, loss_ce: 0.004023
2022-01-16 01:29:56,695 iteration 6489 : loss : 0.020894, loss_ce: 0.005256
2022-01-16 01:29:57,623 iteration 6490 : loss : 0.012429, loss_ce: 0.004264
2022-01-16 01:29:58,508 iteration 6491 : loss : 0.013932, loss_ce: 0.006307
2022-01-16 01:29:59,393 iteration 6492 : loss : 0.010323, loss_ce: 0.005311
2022-01-16 01:30:00,314 iteration 6493 : loss : 0.016698, loss_ce: 0.006220
2022-01-16 01:30:01,273 iteration 6494 : loss : 0.019726, loss_ce: 0.006990
 96%|███████████████████████████▋ | 382/400 [1:50:22<05:07, 17.10s/it]2022-01-16 01:30:02,204 iteration 6495 : loss : 0.012319, loss_ce: 0.005211
2022-01-16 01:30:03,131 iteration 6496 : loss : 0.020289, loss_ce: 0.006181
2022-01-16 01:30:04,104 iteration 6497 : loss : 0.011101, loss_ce: 0.005580
2022-01-16 01:30:04,998 iteration 6498 : loss : 0.014893, loss_ce: 0.003451
2022-01-16 01:30:05,921 iteration 6499 : loss : 0.040412, loss_ce: 0.012672
2022-01-16 01:30:06,966 iteration 6500 : loss : 0.028010, loss_ce: 0.007980
2022-01-16 01:30:07,988 iteration 6501 : loss : 0.016662, loss_ce: 0.007931
2022-01-16 01:30:08,952 iteration 6502 : loss : 0.013064, loss_ce: 0.004385
2022-01-16 01:30:09,904 iteration 6503 : loss : 0.015570, loss_ce: 0.005494
2022-01-16 01:30:10,875 iteration 6504 : loss : 0.015865, loss_ce: 0.006912
2022-01-16 01:30:11,744 iteration 6505 : loss : 0.012074, loss_ce: 0.004450
2022-01-16 01:30:12,710 iteration 6506 : loss : 0.017357, loss_ce: 0.005148
2022-01-16 01:30:13,616 iteration 6507 : loss : 0.022203, loss_ce: 0.011016
2022-01-16 01:30:14,453 iteration 6508 : loss : 0.014655, loss_ce: 0.005356
2022-01-16 01:30:15,370 iteration 6509 : loss : 0.013707, loss_ce: 0.004509
2022-01-16 01:30:16,183 iteration 6510 : loss : 0.010210, loss_ce: 0.003930
2022-01-16 01:30:17,140 iteration 6511 : loss : 0.015475, loss_ce: 0.006572
 96%|███████████████████████████▊ | 383/400 [1:50:38<04:44, 16.73s/it]2022-01-16 01:30:18,171 iteration 6512 : loss : 0.018374, loss_ce: 0.006054
2022-01-16 01:30:19,180 iteration 6513 : loss : 0.015794, loss_ce: 0.005661
2022-01-16 01:30:20,138 iteration 6514 : loss : 0.021107, loss_ce: 0.006591
2022-01-16 01:30:21,142 iteration 6515 : loss : 0.028703, loss_ce: 0.011307
2022-01-16 01:30:22,046 iteration 6516 : loss : 0.014120, loss_ce: 0.005589
2022-01-16 01:30:22,934 iteration 6517 : loss : 0.017444, loss_ce: 0.008886
2022-01-16 01:30:23,892 iteration 6518 : loss : 0.016508, loss_ce: 0.005928
2022-01-16 01:30:24,903 iteration 6519 : loss : 0.018605, loss_ce: 0.007889
2022-01-16 01:30:25,772 iteration 6520 : loss : 0.019345, loss_ce: 0.008497
2022-01-16 01:30:26,750 iteration 6521 : loss : 0.013624, loss_ce: 0.005346
2022-01-16 01:30:27,701 iteration 6522 : loss : 0.015508, loss_ce: 0.005267
2022-01-16 01:30:28,674 iteration 6523 : loss : 0.015027, loss_ce: 0.005596
2022-01-16 01:30:29,642 iteration 6524 : loss : 0.017486, loss_ce: 0.005616
2022-01-16 01:30:30,633 iteration 6525 : loss : 0.025104, loss_ce: 0.007992
2022-01-16 01:30:31,579 iteration 6526 : loss : 0.014956, loss_ce: 0.006225
2022-01-16 01:30:32,472 iteration 6527 : loss : 0.016692, loss_ce: 0.005654
2022-01-16 01:30:33,367 iteration 6528 : loss : 0.013408, loss_ce: 0.005175
 96%|███████████████████████████▊ | 384/400 [1:50:54<04:25, 16.58s/it]2022-01-16 01:30:34,561 iteration 6529 : loss : 0.017029, loss_ce: 0.008163
2022-01-16 01:30:35,497 iteration 6530 : loss : 0.016417, loss_ce: 0.007417
2022-01-16 01:30:36,547 iteration 6531 : loss : 0.022883, loss_ce: 0.008551
2022-01-16 01:30:37,505 iteration 6532 : loss : 0.026629, loss_ce: 0.010644
2022-01-16 01:30:38,507 iteration 6533 : loss : 0.024028, loss_ce: 0.005255
2022-01-16 01:30:39,618 iteration 6534 : loss : 0.021523, loss_ce: 0.006249
2022-01-16 01:30:40,497 iteration 6535 : loss : 0.021520, loss_ce: 0.004329
2022-01-16 01:30:41,441 iteration 6536 : loss : 0.028225, loss_ce: 0.009477
2022-01-16 01:30:42,394 iteration 6537 : loss : 0.013762, loss_ce: 0.005294
2022-01-16 01:30:43,367 iteration 6538 : loss : 0.020081, loss_ce: 0.010319
2022-01-16 01:30:44,420 iteration 6539 : loss : 0.023203, loss_ce: 0.008711
2022-01-16 01:30:45,366 iteration 6540 : loss : 0.013262, loss_ce: 0.005915
2022-01-16 01:30:46,286 iteration 6541 : loss : 0.012368, loss_ce: 0.005025
2022-01-16 01:30:47,293 iteration 6542 : loss : 0.022512, loss_ce: 0.008864
2022-01-16 01:30:48,271 iteration 6543 : loss : 0.015260, loss_ce: 0.005853
2022-01-16 01:30:49,132 iteration 6544 : loss : 0.011308, loss_ce: 0.003903
2022-01-16 01:30:49,132 Training Data Eval:
2022-01-16 01:30:53,518   Average segmentation loss on training set: 0.0087
2022-01-16 01:30:53,518 Validation Data Eval:
2022-01-16 01:30:54,970   Average segmentation loss on validation set: 0.0800
2022-01-16 01:30:55,776 iteration 6545 : loss : 0.009986, loss_ce: 0.002222
 96%|███████████████████████████▉ | 385/400 [1:51:16<04:34, 18.33s/it]2022-01-16 01:30:56,812 iteration 6546 : loss : 0.023939, loss_ce: 0.007723
2022-01-16 01:30:57,967 iteration 6547 : loss : 0.021118, loss_ce: 0.008276
2022-01-16 01:30:58,817 iteration 6548 : loss : 0.012021, loss_ce: 0.006887
2022-01-16 01:30:59,677 iteration 6549 : loss : 0.013272, loss_ce: 0.005115
2022-01-16 01:31:00,583 iteration 6550 : loss : 0.011833, loss_ce: 0.004597
2022-01-16 01:31:01,573 iteration 6551 : loss : 0.015284, loss_ce: 0.006662
2022-01-16 01:31:02,408 iteration 6552 : loss : 0.013881, loss_ce: 0.006429
2022-01-16 01:31:03,425 iteration 6553 : loss : 0.024431, loss_ce: 0.008958
2022-01-16 01:31:04,368 iteration 6554 : loss : 0.017638, loss_ce: 0.005701
2022-01-16 01:31:05,387 iteration 6555 : loss : 0.019480, loss_ce: 0.007699
2022-01-16 01:31:06,374 iteration 6556 : loss : 0.015380, loss_ce: 0.004496
2022-01-16 01:31:07,260 iteration 6557 : loss : 0.014041, loss_ce: 0.004444
2022-01-16 01:31:08,145 iteration 6558 : loss : 0.015222, loss_ce: 0.004477
2022-01-16 01:31:09,122 iteration 6559 : loss : 0.022322, loss_ce: 0.009550
2022-01-16 01:31:10,167 iteration 6560 : loss : 0.033622, loss_ce: 0.006908
2022-01-16 01:31:11,067 iteration 6561 : loss : 0.013670, loss_ce: 0.005394
2022-01-16 01:31:11,903 iteration 6562 : loss : 0.010027, loss_ce: 0.003227
 96%|███████████████████████████▉ | 386/400 [1:51:32<04:07, 17.67s/it]2022-01-16 01:31:12,894 iteration 6563 : loss : 0.010851, loss_ce: 0.004618
2022-01-16 01:31:13,785 iteration 6564 : loss : 0.036456, loss_ce: 0.009274
2022-01-16 01:31:14,646 iteration 6565 : loss : 0.010604, loss_ce: 0.002878
2022-01-16 01:31:15,550 iteration 6566 : loss : 0.012458, loss_ce: 0.005215
2022-01-16 01:31:16,522 iteration 6567 : loss : 0.014686, loss_ce: 0.005601
2022-01-16 01:31:17,488 iteration 6568 : loss : 0.017810, loss_ce: 0.006057
2022-01-16 01:31:18,499 iteration 6569 : loss : 0.016337, loss_ce: 0.005446
2022-01-16 01:31:19,442 iteration 6570 : loss : 0.018821, loss_ce: 0.005296
2022-01-16 01:31:20,527 iteration 6571 : loss : 0.017245, loss_ce: 0.007643
2022-01-16 01:31:21,402 iteration 6572 : loss : 0.011398, loss_ce: 0.004893
2022-01-16 01:31:22,415 iteration 6573 : loss : 0.027029, loss_ce: 0.010819
2022-01-16 01:31:23,328 iteration 6574 : loss : 0.011026, loss_ce: 0.003312
2022-01-16 01:31:24,354 iteration 6575 : loss : 0.017498, loss_ce: 0.006177
2022-01-16 01:31:25,305 iteration 6576 : loss : 0.018895, loss_ce: 0.008955
2022-01-16 01:31:26,211 iteration 6577 : loss : 0.013988, loss_ce: 0.004446
2022-01-16 01:31:27,193 iteration 6578 : loss : 0.014162, loss_ce: 0.005233
2022-01-16 01:31:28,102 iteration 6579 : loss : 0.016094, loss_ce: 0.006943
 97%|████████████████████████████ | 387/400 [1:51:49<03:43, 17.22s/it]2022-01-16 01:31:29,168 iteration 6580 : loss : 0.019507, loss_ce: 0.008717
2022-01-16 01:31:30,054 iteration 6581 : loss : 0.013041, loss_ce: 0.003846
2022-01-16 01:31:31,095 iteration 6582 : loss : 0.020634, loss_ce: 0.006575
2022-01-16 01:31:32,049 iteration 6583 : loss : 0.020521, loss_ce: 0.007381
2022-01-16 01:31:32,944 iteration 6584 : loss : 0.021876, loss_ce: 0.009186
2022-01-16 01:31:33,790 iteration 6585 : loss : 0.012330, loss_ce: 0.003838
2022-01-16 01:31:34,699 iteration 6586 : loss : 0.016446, loss_ce: 0.003984
2022-01-16 01:31:35,560 iteration 6587 : loss : 0.012743, loss_ce: 0.005867
2022-01-16 01:31:36,516 iteration 6588 : loss : 0.010514, loss_ce: 0.004702
2022-01-16 01:31:37,477 iteration 6589 : loss : 0.013949, loss_ce: 0.005836
2022-01-16 01:31:38,387 iteration 6590 : loss : 0.014685, loss_ce: 0.006202
2022-01-16 01:31:39,307 iteration 6591 : loss : 0.010384, loss_ce: 0.003644
2022-01-16 01:31:40,327 iteration 6592 : loss : 0.014713, loss_ce: 0.007868
2022-01-16 01:31:41,167 iteration 6593 : loss : 0.011573, loss_ce: 0.005961
2022-01-16 01:31:42,071 iteration 6594 : loss : 0.009750, loss_ce: 0.003320
2022-01-16 01:31:43,057 iteration 6595 : loss : 0.015914, loss_ce: 0.005036
2022-01-16 01:31:43,937 iteration 6596 : loss : 0.016600, loss_ce: 0.004905
 97%|████████████████████████████▏| 388/400 [1:52:04<03:21, 16.81s/it]2022-01-16 01:31:44,896 iteration 6597 : loss : 0.016242, loss_ce: 0.008583
2022-01-16 01:31:45,890 iteration 6598 : loss : 0.017787, loss_ce: 0.003067
2022-01-16 01:31:46,899 iteration 6599 : loss : 0.015122, loss_ce: 0.005253
2022-01-16 01:31:47,780 iteration 6600 : loss : 0.012276, loss_ce: 0.004997
2022-01-16 01:31:48,830 iteration 6601 : loss : 0.014138, loss_ce: 0.005550
2022-01-16 01:31:49,819 iteration 6602 : loss : 0.015608, loss_ce: 0.006168
2022-01-16 01:31:50,720 iteration 6603 : loss : 0.013816, loss_ce: 0.006595
2022-01-16 01:31:51,709 iteration 6604 : loss : 0.013887, loss_ce: 0.006517
2022-01-16 01:31:52,628 iteration 6605 : loss : 0.020406, loss_ce: 0.008880
2022-01-16 01:31:53,651 iteration 6606 : loss : 0.016504, loss_ce: 0.005482
2022-01-16 01:31:54,671 iteration 6607 : loss : 0.017250, loss_ce: 0.006641
2022-01-16 01:31:55,551 iteration 6608 : loss : 0.017651, loss_ce: 0.007506
2022-01-16 01:31:56,551 iteration 6609 : loss : 0.015458, loss_ce: 0.007190
2022-01-16 01:31:57,473 iteration 6610 : loss : 0.011678, loss_ce: 0.004234
2022-01-16 01:31:58,390 iteration 6611 : loss : 0.010385, loss_ce: 0.002369
2022-01-16 01:31:59,322 iteration 6612 : loss : 0.013043, loss_ce: 0.003427
2022-01-16 01:32:00,307 iteration 6613 : loss : 0.014560, loss_ce: 0.005040
 97%|████████████████████████████▏| 389/400 [1:52:21<03:03, 16.68s/it]2022-01-16 01:32:01,278 iteration 6614 : loss : 0.011735, loss_ce: 0.004877
2022-01-16 01:32:02,136 iteration 6615 : loss : 0.009312, loss_ce: 0.003466
2022-01-16 01:32:03,113 iteration 6616 : loss : 0.031217, loss_ce: 0.009913
2022-01-16 01:32:04,029 iteration 6617 : loss : 0.024361, loss_ce: 0.009531
2022-01-16 01:32:05,058 iteration 6618 : loss : 0.018457, loss_ce: 0.006705
2022-01-16 01:32:06,005 iteration 6619 : loss : 0.017521, loss_ce: 0.006564
2022-01-16 01:32:06,959 iteration 6620 : loss : 0.013559, loss_ce: 0.004718
2022-01-16 01:32:07,973 iteration 6621 : loss : 0.017426, loss_ce: 0.005591
2022-01-16 01:32:08,893 iteration 6622 : loss : 0.016257, loss_ce: 0.007437
2022-01-16 01:32:09,772 iteration 6623 : loss : 0.014500, loss_ce: 0.005230
2022-01-16 01:32:10,700 iteration 6624 : loss : 0.015426, loss_ce: 0.006314
2022-01-16 01:32:11,667 iteration 6625 : loss : 0.020873, loss_ce: 0.007958
2022-01-16 01:32:12,609 iteration 6626 : loss : 0.021425, loss_ce: 0.008087
2022-01-16 01:32:13,599 iteration 6627 : loss : 0.019406, loss_ce: 0.006921
2022-01-16 01:32:14,581 iteration 6628 : loss : 0.016401, loss_ce: 0.006632
2022-01-16 01:32:15,660 iteration 6629 : loss : 0.017572, loss_ce: 0.004335
2022-01-16 01:32:15,660 Training Data Eval:
2022-01-16 01:32:20,052   Average segmentation loss on training set: 0.0087
2022-01-16 01:32:20,052 Validation Data Eval:
2022-01-16 01:32:21,510   Average segmentation loss on validation set: 0.0831
2022-01-16 01:32:22,414 iteration 6630 : loss : 0.015611, loss_ce: 0.006689
 98%|████████████████████████████▎| 390/400 [1:52:43<03:03, 18.30s/it]2022-01-16 01:32:23,405 iteration 6631 : loss : 0.015535, loss_ce: 0.004933
2022-01-16 01:32:24,307 iteration 6632 : loss : 0.012046, loss_ce: 0.005529
2022-01-16 01:32:25,291 iteration 6633 : loss : 0.017433, loss_ce: 0.004651
2022-01-16 01:32:26,204 iteration 6634 : loss : 0.012687, loss_ce: 0.004770
2022-01-16 01:32:27,143 iteration 6635 : loss : 0.014539, loss_ce: 0.005469
2022-01-16 01:32:28,090 iteration 6636 : loss : 0.011351, loss_ce: 0.005360
2022-01-16 01:32:28,986 iteration 6637 : loss : 0.013462, loss_ce: 0.004457
2022-01-16 01:32:29,990 iteration 6638 : loss : 0.036653, loss_ce: 0.007809
2022-01-16 01:32:30,998 iteration 6639 : loss : 0.016189, loss_ce: 0.006585
2022-01-16 01:32:31,926 iteration 6640 : loss : 0.012715, loss_ce: 0.003932
2022-01-16 01:32:32,885 iteration 6641 : loss : 0.013819, loss_ce: 0.004480
2022-01-16 01:32:33,837 iteration 6642 : loss : 0.019184, loss_ce: 0.009170
2022-01-16 01:32:34,796 iteration 6643 : loss : 0.017163, loss_ce: 0.006080
2022-01-16 01:32:35,877 iteration 6644 : loss : 0.031952, loss_ce: 0.013812
2022-01-16 01:32:36,794 iteration 6645 : loss : 0.011909, loss_ce: 0.005193
2022-01-16 01:32:37,859 iteration 6646 : loss : 0.021060, loss_ce: 0.006304
2022-01-16 01:32:38,793 iteration 6647 : loss : 0.021863, loss_ce: 0.007769
 98%|████████████████████████████▎| 391/400 [1:52:59<02:39, 17.73s/it]2022-01-16 01:32:39,778 iteration 6648 : loss : 0.016121, loss_ce: 0.003810
2022-01-16 01:32:40,764 iteration 6649 : loss : 0.015913, loss_ce: 0.004570
2022-01-16 01:32:41,798 iteration 6650 : loss : 0.018207, loss_ce: 0.008751
2022-01-16 01:32:42,868 iteration 6651 : loss : 0.025128, loss_ce: 0.010908
2022-01-16 01:32:43,812 iteration 6652 : loss : 0.012483, loss_ce: 0.004987
2022-01-16 01:32:44,702 iteration 6653 : loss : 0.010862, loss_ce: 0.004341
2022-01-16 01:32:45,627 iteration 6654 : loss : 0.015127, loss_ce: 0.005009
2022-01-16 01:32:46,613 iteration 6655 : loss : 0.017057, loss_ce: 0.006239
2022-01-16 01:32:47,590 iteration 6656 : loss : 0.023751, loss_ce: 0.009382
2022-01-16 01:32:48,553 iteration 6657 : loss : 0.011138, loss_ce: 0.003322
2022-01-16 01:32:49,555 iteration 6658 : loss : 0.025606, loss_ce: 0.008608
2022-01-16 01:32:50,516 iteration 6659 : loss : 0.019282, loss_ce: 0.008540
2022-01-16 01:32:51,534 iteration 6660 : loss : 0.017224, loss_ce: 0.007201
2022-01-16 01:32:52,514 iteration 6661 : loss : 0.012742, loss_ce: 0.005262
2022-01-16 01:32:53,507 iteration 6662 : loss : 0.017272, loss_ce: 0.004162
2022-01-16 01:32:54,469 iteration 6663 : loss : 0.019965, loss_ce: 0.006634
2022-01-16 01:32:55,467 iteration 6664 : loss : 0.018612, loss_ce: 0.009754
 98%|████████████████████████████▍| 392/400 [1:53:16<02:19, 17.41s/it]2022-01-16 01:32:56,516 iteration 6665 : loss : 0.015804, loss_ce: 0.004449
2022-01-16 01:32:57,598 iteration 6666 : loss : 0.042529, loss_ce: 0.011063
2022-01-16 01:32:58,585 iteration 6667 : loss : 0.016858, loss_ce: 0.003188
2022-01-16 01:32:59,450 iteration 6668 : loss : 0.012918, loss_ce: 0.006286
2022-01-16 01:33:00,382 iteration 6669 : loss : 0.016417, loss_ce: 0.006505
2022-01-16 01:33:01,317 iteration 6670 : loss : 0.016168, loss_ce: 0.007513
2022-01-16 01:33:02,294 iteration 6671 : loss : 0.016654, loss_ce: 0.005637
2022-01-16 01:33:03,293 iteration 6672 : loss : 0.016714, loss_ce: 0.005163
2022-01-16 01:33:04,233 iteration 6673 : loss : 0.020296, loss_ce: 0.005194
2022-01-16 01:33:05,178 iteration 6674 : loss : 0.020117, loss_ce: 0.009887
2022-01-16 01:33:06,217 iteration 6675 : loss : 0.018295, loss_ce: 0.008479
2022-01-16 01:33:07,135 iteration 6676 : loss : 0.014017, loss_ce: 0.005633
2022-01-16 01:33:08,027 iteration 6677 : loss : 0.014095, loss_ce: 0.004953
2022-01-16 01:33:08,969 iteration 6678 : loss : 0.012579, loss_ce: 0.006115
2022-01-16 01:33:09,971 iteration 6679 : loss : 0.015272, loss_ce: 0.005984
2022-01-16 01:33:10,855 iteration 6680 : loss : 0.011562, loss_ce: 0.003994
2022-01-16 01:33:11,714 iteration 6681 : loss : 0.012946, loss_ce: 0.004129
 98%|████████████████████████████▍| 393/400 [1:53:32<01:59, 17.06s/it]2022-01-16 01:33:12,826 iteration 6682 : loss : 0.017759, loss_ce: 0.007866
2022-01-16 01:33:13,721 iteration 6683 : loss : 0.012524, loss_ce: 0.004844
2022-01-16 01:33:14,667 iteration 6684 : loss : 0.013055, loss_ce: 0.006057
2022-01-16 01:33:15,556 iteration 6685 : loss : 0.017050, loss_ce: 0.006111
2022-01-16 01:33:16,585 iteration 6686 : loss : 0.016169, loss_ce: 0.007233
2022-01-16 01:33:17,518 iteration 6687 : loss : 0.024608, loss_ce: 0.007804
2022-01-16 01:33:18,470 iteration 6688 : loss : 0.014737, loss_ce: 0.005380
2022-01-16 01:33:19,332 iteration 6689 : loss : 0.009102, loss_ce: 0.002248
2022-01-16 01:33:20,271 iteration 6690 : loss : 0.008717, loss_ce: 0.002448
2022-01-16 01:33:21,264 iteration 6691 : loss : 0.020084, loss_ce: 0.007900
2022-01-16 01:33:22,170 iteration 6692 : loss : 0.024299, loss_ce: 0.008364
2022-01-16 01:33:23,097 iteration 6693 : loss : 0.020244, loss_ce: 0.006765
2022-01-16 01:33:24,064 iteration 6694 : loss : 0.016074, loss_ce: 0.006098
2022-01-16 01:33:24,967 iteration 6695 : loss : 0.014956, loss_ce: 0.004762
2022-01-16 01:33:25,914 iteration 6696 : loss : 0.011800, loss_ce: 0.004585
2022-01-16 01:33:26,849 iteration 6697 : loss : 0.012708, loss_ce: 0.004368
2022-01-16 01:33:27,875 iteration 6698 : loss : 0.014260, loss_ce: 0.004471
 98%|████████████████████████████▌| 394/400 [1:53:48<01:40, 16.79s/it]2022-01-16 01:33:28,859 iteration 6699 : loss : 0.021613, loss_ce: 0.011726
2022-01-16 01:33:29,871 iteration 6700 : loss : 0.018853, loss_ce: 0.005630
2022-01-16 01:33:30,802 iteration 6701 : loss : 0.023287, loss_ce: 0.005989
2022-01-16 01:33:31,668 iteration 6702 : loss : 0.010661, loss_ce: 0.005067
2022-01-16 01:33:32,524 iteration 6703 : loss : 0.012713, loss_ce: 0.004034
2022-01-16 01:33:33,502 iteration 6704 : loss : 0.018542, loss_ce: 0.009163
2022-01-16 01:33:34,382 iteration 6705 : loss : 0.015224, loss_ce: 0.006973
2022-01-16 01:33:35,399 iteration 6706 : loss : 0.014069, loss_ce: 0.004945
2022-01-16 01:33:36,277 iteration 6707 : loss : 0.010433, loss_ce: 0.003988
2022-01-16 01:33:37,219 iteration 6708 : loss : 0.014827, loss_ce: 0.005394
2022-01-16 01:33:38,173 iteration 6709 : loss : 0.018889, loss_ce: 0.008541
2022-01-16 01:33:39,165 iteration 6710 : loss : 0.019199, loss_ce: 0.005087
2022-01-16 01:33:40,153 iteration 6711 : loss : 0.014884, loss_ce: 0.003651
2022-01-16 01:33:41,204 iteration 6712 : loss : 0.016674, loss_ce: 0.007537
2022-01-16 01:33:42,083 iteration 6713 : loss : 0.011063, loss_ce: 0.004098
2022-01-16 01:33:43,036 iteration 6714 : loss : 0.014009, loss_ce: 0.004853
2022-01-16 01:33:43,037 Training Data Eval:
2022-01-16 01:33:47,430   Average segmentation loss on training set: 0.0087
2022-01-16 01:33:47,430 Validation Data Eval:
2022-01-16 01:33:48,898   Average segmentation loss on validation set: 0.0753
2022-01-16 01:33:49,782 iteration 6715 : loss : 0.014922, loss_ce: 0.005628
 99%|████████████████████████████▋| 395/400 [1:54:10<01:31, 18.33s/it]2022-01-16 01:33:50,776 iteration 6716 : loss : 0.013278, loss_ce: 0.005919
2022-01-16 01:33:51,685 iteration 6717 : loss : 0.014542, loss_ce: 0.005865
2022-01-16 01:33:52,624 iteration 6718 : loss : 0.014359, loss_ce: 0.005154
2022-01-16 01:33:53,525 iteration 6719 : loss : 0.015980, loss_ce: 0.006038
2022-01-16 01:33:54,430 iteration 6720 : loss : 0.013695, loss_ce: 0.003528
2022-01-16 01:33:55,316 iteration 6721 : loss : 0.010994, loss_ce: 0.003623
2022-01-16 01:33:56,346 iteration 6722 : loss : 0.021369, loss_ce: 0.008715
2022-01-16 01:33:57,185 iteration 6723 : loss : 0.013258, loss_ce: 0.004033
2022-01-16 01:33:58,118 iteration 6724 : loss : 0.022850, loss_ce: 0.006639
2022-01-16 01:33:59,087 iteration 6725 : loss : 0.011782, loss_ce: 0.003881
2022-01-16 01:34:00,078 iteration 6726 : loss : 0.017064, loss_ce: 0.007340
2022-01-16 01:34:01,144 iteration 6727 : loss : 0.018123, loss_ce: 0.005500
2022-01-16 01:34:02,088 iteration 6728 : loss : 0.017980, loss_ce: 0.006303
2022-01-16 01:34:03,024 iteration 6729 : loss : 0.012041, loss_ce: 0.003817
2022-01-16 01:34:03,916 iteration 6730 : loss : 0.010523, loss_ce: 0.003813
2022-01-16 01:34:04,846 iteration 6731 : loss : 0.015121, loss_ce: 0.005675
2022-01-16 01:34:05,831 iteration 6732 : loss : 0.016463, loss_ce: 0.006114
 99%|████████████████████████████▋| 396/400 [1:54:26<01:10, 17.64s/it]2022-01-16 01:34:06,826 iteration 6733 : loss : 0.011661, loss_ce: 0.004220
2022-01-16 01:34:07,883 iteration 6734 : loss : 0.017810, loss_ce: 0.007469
2022-01-16 01:34:08,783 iteration 6735 : loss : 0.011488, loss_ce: 0.004285
2022-01-16 01:34:09,778 iteration 6736 : loss : 0.017533, loss_ce: 0.006492
2022-01-16 01:34:10,771 iteration 6737 : loss : 0.016077, loss_ce: 0.005847
2022-01-16 01:34:11,612 iteration 6738 : loss : 0.012470, loss_ce: 0.003331
2022-01-16 01:34:12,508 iteration 6739 : loss : 0.013643, loss_ce: 0.005207
2022-01-16 01:34:13,488 iteration 6740 : loss : 0.010737, loss_ce: 0.004658
2022-01-16 01:34:14,409 iteration 6741 : loss : 0.014232, loss_ce: 0.006235
2022-01-16 01:34:15,306 iteration 6742 : loss : 0.013375, loss_ce: 0.004173
2022-01-16 01:34:16,281 iteration 6743 : loss : 0.017892, loss_ce: 0.007424
2022-01-16 01:34:17,256 iteration 6744 : loss : 0.020211, loss_ce: 0.008800
2022-01-16 01:34:18,150 iteration 6745 : loss : 0.013215, loss_ce: 0.004928
2022-01-16 01:34:19,098 iteration 6746 : loss : 0.014280, loss_ce: 0.005434
2022-01-16 01:34:20,103 iteration 6747 : loss : 0.017434, loss_ce: 0.003642
2022-01-16 01:34:21,093 iteration 6748 : loss : 0.020189, loss_ce: 0.006241
2022-01-16 01:34:22,055 iteration 6749 : loss : 0.012761, loss_ce: 0.005551
 99%|████████████████████████████▊| 397/400 [1:54:43<00:51, 17.22s/it]2022-01-16 01:34:23,101 iteration 6750 : loss : 0.011942, loss_ce: 0.004167
2022-01-16 01:34:24,165 iteration 6751 : loss : 0.022734, loss_ce: 0.008596
2022-01-16 01:34:25,185 iteration 6752 : loss : 0.019846, loss_ce: 0.008545
2022-01-16 01:34:26,122 iteration 6753 : loss : 0.023706, loss_ce: 0.009098
2022-01-16 01:34:27,149 iteration 6754 : loss : 0.019157, loss_ce: 0.008456
2022-01-16 01:34:28,052 iteration 6755 : loss : 0.012749, loss_ce: 0.002792
2022-01-16 01:34:28,878 iteration 6756 : loss : 0.009231, loss_ce: 0.004217
2022-01-16 01:34:29,743 iteration 6757 : loss : 0.013017, loss_ce: 0.005257
2022-01-16 01:34:30,657 iteration 6758 : loss : 0.015068, loss_ce: 0.007669
2022-01-16 01:34:31,637 iteration 6759 : loss : 0.018032, loss_ce: 0.005394
2022-01-16 01:34:32,547 iteration 6760 : loss : 0.012429, loss_ce: 0.004946
2022-01-16 01:34:33,461 iteration 6761 : loss : 0.014619, loss_ce: 0.005747
2022-01-16 01:34:34,409 iteration 6762 : loss : 0.014885, loss_ce: 0.004575
2022-01-16 01:34:35,346 iteration 6763 : loss : 0.012836, loss_ce: 0.005991
2022-01-16 01:34:36,358 iteration 6764 : loss : 0.016356, loss_ce: 0.005812
2022-01-16 01:34:37,324 iteration 6765 : loss : 0.016212, loss_ce: 0.004269
2022-01-16 01:34:38,249 iteration 6766 : loss : 0.015541, loss_ce: 0.007946
100%|████████████████████████████▊| 398/400 [1:54:59<00:33, 16.91s/it]2022-01-16 01:34:39,325 iteration 6767 : loss : 0.019471, loss_ce: 0.008143
2022-01-16 01:34:40,234 iteration 6768 : loss : 0.013203, loss_ce: 0.003897
2022-01-16 01:34:41,148 iteration 6769 : loss : 0.011285, loss_ce: 0.003750
2022-01-16 01:34:42,097 iteration 6770 : loss : 0.027721, loss_ce: 0.008936
2022-01-16 01:34:43,008 iteration 6771 : loss : 0.014128, loss_ce: 0.005638
2022-01-16 01:34:43,961 iteration 6772 : loss : 0.015336, loss_ce: 0.006474
2022-01-16 01:34:44,824 iteration 6773 : loss : 0.011509, loss_ce: 0.004271
2022-01-16 01:34:45,741 iteration 6774 : loss : 0.017023, loss_ce: 0.005680
2022-01-16 01:34:46,627 iteration 6775 : loss : 0.015499, loss_ce: 0.003122
2022-01-16 01:34:47,557 iteration 6776 : loss : 0.011458, loss_ce: 0.004116
2022-01-16 01:34:48,498 iteration 6777 : loss : 0.018830, loss_ce: 0.008219
2022-01-16 01:34:49,373 iteration 6778 : loss : 0.013140, loss_ce: 0.004965
2022-01-16 01:34:50,287 iteration 6779 : loss : 0.011720, loss_ce: 0.005202
2022-01-16 01:34:51,273 iteration 6780 : loss : 0.016284, loss_ce: 0.004996
2022-01-16 01:34:52,225 iteration 6781 : loss : 0.012590, loss_ce: 0.005101
2022-01-16 01:34:53,130 iteration 6782 : loss : 0.013077, loss_ce: 0.005175
2022-01-16 01:34:54,129 iteration 6783 : loss : 0.025361, loss_ce: 0.007391
100%|████████████████████████████▉| 399/400 [1:55:15<00:16, 16.60s/it]2022-01-16 01:34:55,057 iteration 6784 : loss : 0.012044, loss_ce: 0.006415
2022-01-16 01:34:55,972 iteration 6785 : loss : 0.014945, loss_ce: 0.004486
2022-01-16 01:34:56,955 iteration 6786 : loss : 0.014009, loss_ce: 0.005283
2022-01-16 01:34:57,883 iteration 6787 : loss : 0.017721, loss_ce: 0.005018
2022-01-16 01:34:58,820 iteration 6788 : loss : 0.016950, loss_ce: 0.008810
2022-01-16 01:34:59,838 iteration 6789 : loss : 0.019789, loss_ce: 0.005629
2022-01-16 01:35:00,784 iteration 6790 : loss : 0.016017, loss_ce: 0.006398
2022-01-16 01:35:01,800 iteration 6791 : loss : 0.026651, loss_ce: 0.007164
2022-01-16 01:35:02,723 iteration 6792 : loss : 0.016350, loss_ce: 0.007173
2022-01-16 01:35:03,569 iteration 6793 : loss : 0.011462, loss_ce: 0.004252
2022-01-16 01:35:04,538 iteration 6794 : loss : 0.019106, loss_ce: 0.007200
2022-01-16 01:35:05,417 iteration 6795 : loss : 0.012473, loss_ce: 0.004660
2022-01-16 01:35:06,343 iteration 6796 : loss : 0.013372, loss_ce: 0.003360
2022-01-16 01:35:07,249 iteration 6797 : loss : 0.014100, loss_ce: 0.004834
2022-01-16 01:35:08,233 iteration 6798 : loss : 0.015141, loss_ce: 0.005051
2022-01-16 01:35:09,159 iteration 6799 : loss : 0.014913, loss_ce: 0.004871
2022-01-16 01:35:09,159 Training Data Eval:
2022-01-16 01:35:13,551   Average segmentation loss on training set: 0.0083
2022-01-16 01:35:13,552 Validation Data Eval:
2022-01-16 01:35:15,016   Average segmentation loss on validation set: 0.0819
2022-01-16 01:35:15,937 iteration 6800 : loss : 0.013513, loss_ce: 0.005448
100%|█████████████████████████████| 400/400 [1:55:36<00:00, 18.16s/it]100%|█████████████████████████████| 400/400 [1:55:36<00:00, 17.34s/it]
