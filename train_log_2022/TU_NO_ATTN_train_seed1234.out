2022-01-21 18:01:44,393 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-21 18:01:44,394 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-21 18:01:44,394 ============================================================
2022-01-21 18:01:44,394 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-21 18:01:44,394 ============================================================
2022-01-21 18:01:44,394 Loading data...
2022-01-21 18:01:44,394 Reading NCI - RUNMC images...
2022-01-21 18:01:44,394 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-21 18:01:44,398 Already preprocessed this configuration. Loading now!
2022-01-21 18:01:44,421 Training Images: (256, 256, 286)
2022-01-21 18:01:44,421 Training Labels: (256, 256, 286)
2022-01-21 18:01:44,421 Validation Images: (256, 256, 98)
2022-01-21 18:01:44,422 Validation Labels: (256, 256, 98)
2022-01-21 18:01:44,422 ============================================================
2022-01-21 18:01:44,451 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-21 18:01:47,968 iteration 1 : loss : 0.844908, loss_ce: 0.977741
2022-01-21 18:01:49,137 iteration 2 : loss : 0.778477, loss_ce: 0.873699
2022-01-21 18:01:50,418 iteration 3 : loss : 0.733848, loss_ce: 0.805788
2022-01-21 18:01:51,603 iteration 4 : loss : 0.706842, loss_ce: 0.743819
2022-01-21 18:01:52,794 iteration 5 : loss : 0.650853, loss_ce: 0.670125
2022-01-21 18:01:54,002 iteration 6 : loss : 0.618445, loss_ce: 0.604240
2022-01-21 18:01:55,271 iteration 7 : loss : 0.572552, loss_ce: 0.552772
2022-01-21 18:01:56,479 iteration 8 : loss : 0.554471, loss_ce: 0.492364
2022-01-21 18:01:57,710 iteration 9 : loss : 0.510219, loss_ce: 0.483493
2022-01-21 18:01:58,973 iteration 10 : loss : 0.500416, loss_ce: 0.409814
2022-01-21 18:02:00,288 iteration 11 : loss : 0.466147, loss_ce: 0.387493
2022-01-21 18:02:01,489 iteration 12 : loss : 0.446177, loss_ce: 0.349878
2022-01-21 18:02:02,670 iteration 13 : loss : 0.446344, loss_ce: 0.327479
2022-01-21 18:02:03,825 iteration 14 : loss : 0.398962, loss_ce: 0.291230
2022-01-21 18:02:05,050 iteration 15 : loss : 0.377628, loss_ce: 0.263716
2022-01-21 18:02:06,258 iteration 16 : loss : 0.432272, loss_ce: 0.283807
2022-01-21 18:02:07,464 iteration 17 : loss : 0.335952, loss_ce: 0.232613
  0%|                               | 1/400 [00:23<2:33:29, 23.08s/it]2022-01-21 18:02:08,762 iteration 18 : loss : 0.374091, loss_ce: 0.212535
2022-01-21 18:02:09,897 iteration 19 : loss : 0.325743, loss_ce: 0.195813
2022-01-21 18:02:11,174 iteration 20 : loss : 0.313261, loss_ce: 0.176710
2022-01-21 18:02:12,354 iteration 21 : loss : 0.359873, loss_ce: 0.174664
2022-01-21 18:02:13,555 iteration 22 : loss : 0.335949, loss_ce: 0.189210
2022-01-21 18:02:14,841 iteration 23 : loss : 0.288001, loss_ce: 0.141827
2022-01-21 18:02:16,047 iteration 24 : loss : 0.313817, loss_ce: 0.159753
2022-01-21 18:02:17,307 iteration 25 : loss : 0.396918, loss_ce: 0.233699
2022-01-21 18:02:18,502 iteration 26 : loss : 0.290605, loss_ce: 0.144755
2022-01-21 18:02:19,637 iteration 27 : loss : 0.283463, loss_ce: 0.148213
2022-01-21 18:02:20,783 iteration 28 : loss : 0.281290, loss_ce: 0.137549
2022-01-21 18:02:22,034 iteration 29 : loss : 0.281986, loss_ce: 0.135577
2022-01-21 18:02:23,275 iteration 30 : loss : 0.323170, loss_ce: 0.163747
2022-01-21 18:02:24,427 iteration 31 : loss : 0.265430, loss_ce: 0.130641
2022-01-21 18:02:25,700 iteration 32 : loss : 0.280840, loss_ce: 0.146812
2022-01-21 18:02:26,946 iteration 33 : loss : 0.286074, loss_ce: 0.154963
2022-01-21 18:02:28,202 iteration 34 : loss : 0.291758, loss_ce: 0.162472
  0%|▏                              | 2/400 [00:43<2:23:52, 21.69s/it]2022-01-21 18:02:29,493 iteration 35 : loss : 0.239917, loss_ce: 0.109770
2022-01-21 18:02:30,760 iteration 36 : loss : 0.265212, loss_ce: 0.135700
2022-01-21 18:02:32,036 iteration 37 : loss : 0.262772, loss_ce: 0.116443
2022-01-21 18:02:33,219 iteration 38 : loss : 0.258250, loss_ce: 0.123125
2022-01-21 18:02:34,417 iteration 39 : loss : 0.271475, loss_ce: 0.128469
2022-01-21 18:02:35,699 iteration 40 : loss : 0.272169, loss_ce: 0.135309
2022-01-21 18:02:36,965 iteration 41 : loss : 0.320846, loss_ce: 0.156786
2022-01-21 18:02:38,214 iteration 42 : loss : 0.254763, loss_ce: 0.125657
2022-01-21 18:02:39,434 iteration 43 : loss : 0.267503, loss_ce: 0.125945
2022-01-21 18:02:40,817 iteration 44 : loss : 0.232750, loss_ce: 0.111850
2022-01-21 18:02:42,139 iteration 45 : loss : 0.231846, loss_ce: 0.111389
2022-01-21 18:02:43,481 iteration 46 : loss : 0.247157, loss_ce: 0.105236
2022-01-21 18:02:44,854 iteration 47 : loss : 0.217315, loss_ce: 0.086535
2022-01-21 18:02:46,197 iteration 48 : loss : 0.234181, loss_ce: 0.099375
2022-01-21 18:02:47,589 iteration 49 : loss : 0.286266, loss_ce: 0.132963
2022-01-21 18:02:48,870 iteration 50 : loss : 0.334696, loss_ce: 0.147521
2022-01-21 18:02:50,143 iteration 51 : loss : 0.281640, loss_ce: 0.132593
  1%|▏                              | 3/400 [01:05<2:24:15, 21.80s/it]2022-01-21 18:02:51,558 iteration 52 : loss : 0.286528, loss_ce: 0.143209
2022-01-21 18:02:52,924 iteration 53 : loss : 0.261606, loss_ce: 0.121542
2022-01-21 18:02:54,248 iteration 54 : loss : 0.242260, loss_ce: 0.105454
2022-01-21 18:02:55,594 iteration 55 : loss : 0.271494, loss_ce: 0.134928
2022-01-21 18:02:56,919 iteration 56 : loss : 0.266076, loss_ce: 0.115758
2022-01-21 18:02:58,272 iteration 57 : loss : 0.230881, loss_ce: 0.097710
2022-01-21 18:02:59,617 iteration 58 : loss : 0.304810, loss_ce: 0.132018
2022-01-21 18:03:00,936 iteration 59 : loss : 0.209328, loss_ce: 0.096060
2022-01-21 18:03:02,280 iteration 60 : loss : 0.297293, loss_ce: 0.131349
2022-01-21 18:03:03,620 iteration 61 : loss : 0.254660, loss_ce: 0.127206
2022-01-21 18:03:04,949 iteration 62 : loss : 0.319805, loss_ce: 0.125929
2022-01-21 18:03:06,204 iteration 63 : loss : 0.293044, loss_ce: 0.145238
2022-01-21 18:03:07,519 iteration 64 : loss : 0.318129, loss_ce: 0.147109
2022-01-21 18:03:08,786 iteration 65 : loss : 0.252612, loss_ce: 0.102208
2022-01-21 18:03:10,090 iteration 66 : loss : 0.212740, loss_ce: 0.090894
2022-01-21 18:03:11,470 iteration 67 : loss : 0.244174, loss_ce: 0.087501
2022-01-21 18:03:12,795 iteration 68 : loss : 0.245522, loss_ce: 0.111029
  1%|▎                              | 4/400 [01:28<2:26:05, 22.14s/it]2022-01-21 18:03:14,174 iteration 69 : loss : 0.235676, loss_ce: 0.103170
2022-01-21 18:03:15,582 iteration 70 : loss : 0.232370, loss_ce: 0.099320
2022-01-21 18:03:16,880 iteration 71 : loss : 0.215119, loss_ce: 0.087193
2022-01-21 18:03:18,219 iteration 72 : loss : 0.210357, loss_ce: 0.085035
2022-01-21 18:03:19,507 iteration 73 : loss : 0.258469, loss_ce: 0.127304
2022-01-21 18:03:20,762 iteration 74 : loss : 0.207160, loss_ce: 0.089373
2022-01-21 18:03:22,053 iteration 75 : loss : 0.233202, loss_ce: 0.105080
2022-01-21 18:03:23,336 iteration 76 : loss : 0.215648, loss_ce: 0.095885
2022-01-21 18:03:24,538 iteration 77 : loss : 0.236164, loss_ce: 0.112609
2022-01-21 18:03:25,850 iteration 78 : loss : 0.255220, loss_ce: 0.117272
2022-01-21 18:03:27,131 iteration 79 : loss : 0.281086, loss_ce: 0.108019
2022-01-21 18:03:28,398 iteration 80 : loss : 0.255643, loss_ce: 0.113517
2022-01-21 18:03:29,657 iteration 81 : loss : 0.227363, loss_ce: 0.094648
2022-01-21 18:03:30,942 iteration 82 : loss : 0.235279, loss_ce: 0.087451
2022-01-21 18:03:32,221 iteration 83 : loss : 0.247234, loss_ce: 0.085907
2022-01-21 18:03:33,599 iteration 84 : loss : 0.242517, loss_ce: 0.132101
2022-01-21 18:03:33,599 Training Data Eval:
2022-01-21 18:03:40,121   Average segmentation loss on training set: 0.3696
2022-01-21 18:03:40,121 Validation Data Eval:
2022-01-21 18:03:42,604   Average segmentation loss on validation set: 0.4065
2022-01-21 18:03:46,751 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:03:47,943 iteration 85 : loss : 0.260600, loss_ce: 0.107366
  1%|▍                              | 5/400 [02:03<2:56:36, 26.83s/it]2022-01-21 18:03:49,204 iteration 86 : loss : 0.262244, loss_ce: 0.093384
2022-01-21 18:03:50,535 iteration 87 : loss : 0.205974, loss_ce: 0.088344
2022-01-21 18:03:51,727 iteration 88 : loss : 0.205279, loss_ce: 0.099728
2022-01-21 18:03:53,042 iteration 89 : loss : 0.251561, loss_ce: 0.115805
2022-01-21 18:03:54,376 iteration 90 : loss : 0.232130, loss_ce: 0.101755
2022-01-21 18:03:55,768 iteration 91 : loss : 0.228690, loss_ce: 0.124357
2022-01-21 18:03:57,036 iteration 92 : loss : 0.208081, loss_ce: 0.091647
2022-01-21 18:03:58,356 iteration 93 : loss : 0.262097, loss_ce: 0.098158
2022-01-21 18:03:59,664 iteration 94 : loss : 0.230103, loss_ce: 0.096706
2022-01-21 18:04:01,109 iteration 95 : loss : 0.220561, loss_ce: 0.101355
2022-01-21 18:04:02,405 iteration 96 : loss : 0.214853, loss_ce: 0.101010
2022-01-21 18:04:03,705 iteration 97 : loss : 0.251113, loss_ce: 0.107995
2022-01-21 18:04:05,021 iteration 98 : loss : 0.212847, loss_ce: 0.095300
2022-01-21 18:04:06,402 iteration 99 : loss : 0.216490, loss_ce: 0.099466
2022-01-21 18:04:07,743 iteration 100 : loss : 0.228403, loss_ce: 0.101414
2022-01-21 18:04:09,064 iteration 101 : loss : 0.147435, loss_ce: 0.062543
2022-01-21 18:04:10,315 iteration 102 : loss : 0.203840, loss_ce: 0.082938
  2%|▍                              | 6/400 [02:25<2:46:14, 25.32s/it]2022-01-21 18:04:11,765 iteration 103 : loss : 0.193092, loss_ce: 0.085160
2022-01-21 18:04:13,165 iteration 104 : loss : 0.255233, loss_ce: 0.111029
2022-01-21 18:04:14,612 iteration 105 : loss : 0.223333, loss_ce: 0.087186
2022-01-21 18:04:15,896 iteration 106 : loss : 0.228535, loss_ce: 0.093123
2022-01-21 18:04:17,374 iteration 107 : loss : 0.171313, loss_ce: 0.080035
2022-01-21 18:04:18,635 iteration 108 : loss : 0.249249, loss_ce: 0.109914
2022-01-21 18:04:19,929 iteration 109 : loss : 0.179954, loss_ce: 0.083011
2022-01-21 18:04:21,172 iteration 110 : loss : 0.155219, loss_ce: 0.076038
2022-01-21 18:04:22,512 iteration 111 : loss : 0.223194, loss_ce: 0.113569
2022-01-21 18:04:23,766 iteration 112 : loss : 0.184287, loss_ce: 0.070565
2022-01-21 18:04:25,086 iteration 113 : loss : 0.235367, loss_ce: 0.115465
2022-01-21 18:04:26,370 iteration 114 : loss : 0.218784, loss_ce: 0.071978
2022-01-21 18:04:27,673 iteration 115 : loss : 0.176553, loss_ce: 0.073239
2022-01-21 18:04:29,034 iteration 116 : loss : 0.229792, loss_ce: 0.111900
2022-01-21 18:04:30,390 iteration 117 : loss : 0.213649, loss_ce: 0.101911
2022-01-21 18:04:31,718 iteration 118 : loss : 0.217005, loss_ce: 0.095559
2022-01-21 18:04:33,067 iteration 119 : loss : 0.169646, loss_ce: 0.068944
  2%|▌                              | 7/400 [02:48<2:40:19, 24.48s/it]2022-01-21 18:04:34,388 iteration 120 : loss : 0.303486, loss_ce: 0.163024
2022-01-21 18:04:35,645 iteration 121 : loss : 0.165449, loss_ce: 0.074613
2022-01-21 18:04:37,013 iteration 122 : loss : 0.179621, loss_ce: 0.066523
2022-01-21 18:04:38,349 iteration 123 : loss : 0.186989, loss_ce: 0.072317
2022-01-21 18:04:39,658 iteration 124 : loss : 0.183679, loss_ce: 0.076825
2022-01-21 18:04:40,927 iteration 125 : loss : 0.185818, loss_ce: 0.087553
2022-01-21 18:04:42,262 iteration 126 : loss : 0.187405, loss_ce: 0.064822
2022-01-21 18:04:43,527 iteration 127 : loss : 0.172307, loss_ce: 0.074510
2022-01-21 18:04:44,823 iteration 128 : loss : 0.175469, loss_ce: 0.075848
2022-01-21 18:04:46,195 iteration 129 : loss : 0.169318, loss_ce: 0.064901
2022-01-21 18:04:47,497 iteration 130 : loss : 0.164399, loss_ce: 0.062834
2022-01-21 18:04:48,903 iteration 131 : loss : 0.173734, loss_ce: 0.094456
2022-01-21 18:04:50,323 iteration 132 : loss : 0.190035, loss_ce: 0.056764
2022-01-21 18:04:51,617 iteration 133 : loss : 0.196197, loss_ce: 0.076975
2022-01-21 18:04:53,007 iteration 134 : loss : 0.175185, loss_ce: 0.069913
2022-01-21 18:04:54,414 iteration 135 : loss : 0.200636, loss_ce: 0.086724
2022-01-21 18:04:55,725 iteration 136 : loss : 0.155743, loss_ce: 0.071814
  2%|▌                              | 8/400 [03:11<2:36:07, 23.90s/it]2022-01-21 18:04:57,147 iteration 137 : loss : 0.205675, loss_ce: 0.072360
2022-01-21 18:04:58,439 iteration 138 : loss : 0.187802, loss_ce: 0.105583
2022-01-21 18:04:59,790 iteration 139 : loss : 0.180535, loss_ce: 0.077822
2022-01-21 18:05:01,110 iteration 140 : loss : 0.188136, loss_ce: 0.069054
2022-01-21 18:05:02,478 iteration 141 : loss : 0.180016, loss_ce: 0.083835
2022-01-21 18:05:03,855 iteration 142 : loss : 0.209430, loss_ce: 0.097394
2022-01-21 18:05:05,264 iteration 143 : loss : 0.197737, loss_ce: 0.082866
2022-01-21 18:05:06,635 iteration 144 : loss : 0.174293, loss_ce: 0.066753
2022-01-21 18:05:07,955 iteration 145 : loss : 0.198713, loss_ce: 0.082820
2022-01-21 18:05:09,313 iteration 146 : loss : 0.136007, loss_ce: 0.062031
2022-01-21 18:05:10,680 iteration 147 : loss : 0.182496, loss_ce: 0.070714
2022-01-21 18:05:11,921 iteration 148 : loss : 0.149948, loss_ce: 0.064127
2022-01-21 18:05:13,227 iteration 149 : loss : 0.239550, loss_ce: 0.114765
2022-01-21 18:05:14,510 iteration 150 : loss : 0.187517, loss_ce: 0.070673
2022-01-21 18:05:15,799 iteration 151 : loss : 0.235209, loss_ce: 0.109442
2022-01-21 18:05:17,098 iteration 152 : loss : 0.216363, loss_ce: 0.073960
2022-01-21 18:05:18,443 iteration 153 : loss : 0.210768, loss_ce: 0.086268
  2%|▋                              | 9/400 [03:34<2:33:20, 23.53s/it]2022-01-21 18:05:19,746 iteration 154 : loss : 0.219858, loss_ce: 0.093687
2022-01-21 18:05:21,077 iteration 155 : loss : 0.195018, loss_ce: 0.069467
2022-01-21 18:05:22,485 iteration 156 : loss : 0.171284, loss_ce: 0.070314
2022-01-21 18:05:23,837 iteration 157 : loss : 0.237740, loss_ce: 0.087507
2022-01-21 18:05:25,286 iteration 158 : loss : 0.206552, loss_ce: 0.085321
2022-01-21 18:05:26,496 iteration 159 : loss : 0.148274, loss_ce: 0.057396
2022-01-21 18:05:27,895 iteration 160 : loss : 0.161336, loss_ce: 0.054030
2022-01-21 18:05:29,288 iteration 161 : loss : 0.200576, loss_ce: 0.071237
2022-01-21 18:05:30,682 iteration 162 : loss : 0.188509, loss_ce: 0.085564
2022-01-21 18:05:32,011 iteration 163 : loss : 0.177592, loss_ce: 0.071872
2022-01-21 18:05:33,356 iteration 164 : loss : 0.169374, loss_ce: 0.059597
2022-01-21 18:05:34,671 iteration 165 : loss : 0.199611, loss_ce: 0.081139
2022-01-21 18:05:35,970 iteration 166 : loss : 0.158420, loss_ce: 0.058687
2022-01-21 18:05:37,290 iteration 167 : loss : 0.131319, loss_ce: 0.049423
2022-01-21 18:05:38,647 iteration 168 : loss : 0.181801, loss_ce: 0.086303
2022-01-21 18:05:39,980 iteration 169 : loss : 0.150996, loss_ce: 0.072748
2022-01-21 18:05:39,980 Training Data Eval:
2022-01-21 18:05:46,508   Average segmentation loss on training set: 0.3302
2022-01-21 18:05:46,508 Validation Data Eval:
2022-01-21 18:05:48,744   Average segmentation loss on validation set: 0.2877
2022-01-21 18:05:53,013 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:05:54,290 iteration 170 : loss : 0.141307, loss_ce: 0.059309
  2%|▊                             | 10/400 [04:09<2:57:38, 27.33s/it]2022-01-21 18:05:55,562 iteration 171 : loss : 0.188470, loss_ce: 0.077777
2022-01-21 18:05:56,812 iteration 172 : loss : 0.181638, loss_ce: 0.084955
2022-01-21 18:05:58,112 iteration 173 : loss : 0.102485, loss_ce: 0.049003
2022-01-21 18:05:59,385 iteration 174 : loss : 0.184929, loss_ce: 0.085836
2022-01-21 18:06:00,656 iteration 175 : loss : 0.186307, loss_ce: 0.074717
2022-01-21 18:06:02,007 iteration 176 : loss : 0.158895, loss_ce: 0.072010
2022-01-21 18:06:03,324 iteration 177 : loss : 0.140263, loss_ce: 0.053921
2022-01-21 18:06:04,643 iteration 178 : loss : 0.153890, loss_ce: 0.064601
2022-01-21 18:06:05,960 iteration 179 : loss : 0.173976, loss_ce: 0.071184
2022-01-21 18:06:07,256 iteration 180 : loss : 0.147540, loss_ce: 0.052555
2022-01-21 18:06:08,607 iteration 181 : loss : 0.175951, loss_ce: 0.075173
2022-01-21 18:06:09,898 iteration 182 : loss : 0.120258, loss_ce: 0.048000
2022-01-21 18:06:11,169 iteration 183 : loss : 0.161025, loss_ce: 0.059589
2022-01-21 18:06:12,397 iteration 184 : loss : 0.180390, loss_ce: 0.067633
2022-01-21 18:06:13,745 iteration 185 : loss : 0.185942, loss_ce: 0.076187
2022-01-21 18:06:15,097 iteration 186 : loss : 0.193327, loss_ce: 0.091068
2022-01-21 18:06:16,480 iteration 187 : loss : 0.174386, loss_ce: 0.071010
  3%|▊                             | 11/400 [04:32<2:46:59, 25.76s/it]2022-01-21 18:06:17,874 iteration 188 : loss : 0.188936, loss_ce: 0.077823
2022-01-21 18:06:19,213 iteration 189 : loss : 0.144052, loss_ce: 0.057780
2022-01-21 18:06:20,566 iteration 190 : loss : 0.137262, loss_ce: 0.047610
2022-01-21 18:06:21,867 iteration 191 : loss : 0.144534, loss_ce: 0.056340
2022-01-21 18:06:23,121 iteration 192 : loss : 0.143525, loss_ce: 0.062798
2022-01-21 18:06:24,497 iteration 193 : loss : 0.140609, loss_ce: 0.054440
2022-01-21 18:06:25,801 iteration 194 : loss : 0.174185, loss_ce: 0.056546
2022-01-21 18:06:27,085 iteration 195 : loss : 0.143188, loss_ce: 0.060823
2022-01-21 18:06:28,322 iteration 196 : loss : 0.142260, loss_ce: 0.055476
2022-01-21 18:06:29,649 iteration 197 : loss : 0.146851, loss_ce: 0.053618
2022-01-21 18:06:31,006 iteration 198 : loss : 0.134307, loss_ce: 0.060559
2022-01-21 18:06:32,291 iteration 199 : loss : 0.161303, loss_ce: 0.062924
2022-01-21 18:06:33,595 iteration 200 : loss : 0.136242, loss_ce: 0.058512
2022-01-21 18:06:34,932 iteration 201 : loss : 0.114306, loss_ce: 0.046041
2022-01-21 18:06:36,289 iteration 202 : loss : 0.172439, loss_ce: 0.074684
2022-01-21 18:06:37,568 iteration 203 : loss : 0.136802, loss_ce: 0.056985
2022-01-21 18:06:38,981 iteration 204 : loss : 0.224957, loss_ce: 0.094393
  3%|▉                             | 12/400 [04:54<2:40:09, 24.77s/it]2022-01-21 18:06:40,309 iteration 205 : loss : 0.135601, loss_ce: 0.059431
2022-01-21 18:06:41,623 iteration 206 : loss : 0.155092, loss_ce: 0.050618
2022-01-21 18:06:42,960 iteration 207 : loss : 0.118536, loss_ce: 0.051510
2022-01-21 18:06:44,260 iteration 208 : loss : 0.208436, loss_ce: 0.060776
2022-01-21 18:06:45,657 iteration 209 : loss : 0.208212, loss_ce: 0.091257
2022-01-21 18:06:46,887 iteration 210 : loss : 0.127617, loss_ce: 0.044270
2022-01-21 18:06:48,251 iteration 211 : loss : 0.187202, loss_ce: 0.086601
2022-01-21 18:06:49,590 iteration 212 : loss : 0.174824, loss_ce: 0.069661
2022-01-21 18:06:51,025 iteration 213 : loss : 0.140511, loss_ce: 0.068939
2022-01-21 18:06:52,350 iteration 214 : loss : 0.129550, loss_ce: 0.046391
2022-01-21 18:06:53,680 iteration 215 : loss : 0.173319, loss_ce: 0.075372
2022-01-21 18:06:55,164 iteration 216 : loss : 0.145896, loss_ce: 0.056389
2022-01-21 18:06:56,592 iteration 217 : loss : 0.124854, loss_ce: 0.045717
2022-01-21 18:06:57,938 iteration 218 : loss : 0.140373, loss_ce: 0.067246
2022-01-21 18:06:59,167 iteration 219 : loss : 0.112795, loss_ce: 0.048432
2022-01-21 18:07:00,515 iteration 220 : loss : 0.119376, loss_ce: 0.052680
2022-01-21 18:07:01,851 iteration 221 : loss : 0.164093, loss_ce: 0.061139
  3%|▉                             | 13/400 [05:17<2:36:02, 24.19s/it]2022-01-21 18:07:03,236 iteration 222 : loss : 0.153760, loss_ce: 0.066292
2022-01-21 18:07:04,610 iteration 223 : loss : 0.128730, loss_ce: 0.052832
2022-01-21 18:07:05,935 iteration 224 : loss : 0.202417, loss_ce: 0.108385
2022-01-21 18:07:07,363 iteration 225 : loss : 0.269421, loss_ce: 0.074805
2022-01-21 18:07:08,685 iteration 226 : loss : 0.179883, loss_ce: 0.069703
2022-01-21 18:07:10,059 iteration 227 : loss : 0.194983, loss_ce: 0.083722
2022-01-21 18:07:11,385 iteration 228 : loss : 0.160498, loss_ce: 0.070019
2022-01-21 18:07:12,665 iteration 229 : loss : 0.142656, loss_ce: 0.049818
2022-01-21 18:07:13,999 iteration 230 : loss : 0.142769, loss_ce: 0.053403
2022-01-21 18:07:15,376 iteration 231 : loss : 0.170839, loss_ce: 0.069182
2022-01-21 18:07:16,743 iteration 232 : loss : 0.118246, loss_ce: 0.051913
2022-01-21 18:07:18,024 iteration 233 : loss : 0.142663, loss_ce: 0.056774
2022-01-21 18:07:19,414 iteration 234 : loss : 0.182393, loss_ce: 0.089743
2022-01-21 18:07:20,721 iteration 235 : loss : 0.119116, loss_ce: 0.047840
2022-01-21 18:07:22,070 iteration 236 : loss : 0.104395, loss_ce: 0.041064
2022-01-21 18:07:23,377 iteration 237 : loss : 0.118699, loss_ce: 0.050236
2022-01-21 18:07:24,699 iteration 238 : loss : 0.125135, loss_ce: 0.055380
  4%|█                             | 14/400 [05:40<2:33:01, 23.79s/it]2022-01-21 18:07:26,011 iteration 239 : loss : 0.149726, loss_ce: 0.050258
2022-01-21 18:07:27,376 iteration 240 : loss : 0.134093, loss_ce: 0.063240
2022-01-21 18:07:28,740 iteration 241 : loss : 0.172038, loss_ce: 0.074066
2022-01-21 18:07:30,085 iteration 242 : loss : 0.136238, loss_ce: 0.075292
2022-01-21 18:07:31,558 iteration 243 : loss : 0.140383, loss_ce: 0.059755
2022-01-21 18:07:32,838 iteration 244 : loss : 0.180214, loss_ce: 0.043967
2022-01-21 18:07:34,184 iteration 245 : loss : 0.138644, loss_ce: 0.064902
2022-01-21 18:07:35,570 iteration 246 : loss : 0.131487, loss_ce: 0.058366
2022-01-21 18:07:36,889 iteration 247 : loss : 0.192522, loss_ce: 0.067957
2022-01-21 18:07:38,209 iteration 248 : loss : 0.141652, loss_ce: 0.051824
2022-01-21 18:07:39,507 iteration 249 : loss : 0.194756, loss_ce: 0.107353
2022-01-21 18:07:40,824 iteration 250 : loss : 0.169220, loss_ce: 0.066122
2022-01-21 18:07:42,083 iteration 251 : loss : 0.181156, loss_ce: 0.062826
2022-01-21 18:07:43,396 iteration 252 : loss : 0.091207, loss_ce: 0.037468
2022-01-21 18:07:44,745 iteration 253 : loss : 0.154709, loss_ce: 0.061295
2022-01-21 18:07:46,156 iteration 254 : loss : 0.219253, loss_ce: 0.067342
2022-01-21 18:07:46,156 Training Data Eval:
2022-01-21 18:07:52,677   Average segmentation loss on training set: 0.1690
2022-01-21 18:07:52,678 Validation Data Eval:
2022-01-21 18:07:54,912   Average segmentation loss on validation set: 0.1731
2022-01-21 18:07:59,026 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:08:00,228 iteration 255 : loss : 0.146393, loss_ce: 0.061969
  4%|█▏                            | 15/400 [06:15<2:55:21, 27.33s/it]2022-01-21 18:08:01,515 iteration 256 : loss : 0.163676, loss_ce: 0.063536
2022-01-21 18:08:02,787 iteration 257 : loss : 0.145941, loss_ce: 0.062079
2022-01-21 18:08:04,114 iteration 258 : loss : 0.163543, loss_ce: 0.062637
2022-01-21 18:08:05,301 iteration 259 : loss : 0.120147, loss_ce: 0.050274
2022-01-21 18:08:06,678 iteration 260 : loss : 0.136278, loss_ce: 0.058441
2022-01-21 18:08:08,031 iteration 261 : loss : 0.212612, loss_ce: 0.069854
2022-01-21 18:08:09,457 iteration 262 : loss : 0.151127, loss_ce: 0.068579
2022-01-21 18:08:10,798 iteration 263 : loss : 0.138637, loss_ce: 0.059642
2022-01-21 18:08:12,164 iteration 264 : loss : 0.131823, loss_ce: 0.056353
2022-01-21 18:08:13,465 iteration 265 : loss : 0.110747, loss_ce: 0.046408
2022-01-21 18:08:14,828 iteration 266 : loss : 0.130297, loss_ce: 0.053625
2022-01-21 18:08:16,154 iteration 267 : loss : 0.147243, loss_ce: 0.043073
2022-01-21 18:08:17,492 iteration 268 : loss : 0.175162, loss_ce: 0.075791
2022-01-21 18:08:19,028 iteration 269 : loss : 0.158602, loss_ce: 0.048952
2022-01-21 18:08:20,469 iteration 270 : loss : 0.102574, loss_ce: 0.040797
2022-01-21 18:08:21,680 iteration 271 : loss : 0.156522, loss_ce: 0.046148
2022-01-21 18:08:23,014 iteration 272 : loss : 0.113939, loss_ce: 0.054168
  4%|█▏                            | 16/400 [06:38<2:46:08, 25.96s/it]2022-01-21 18:08:24,337 iteration 273 : loss : 0.110006, loss_ce: 0.041094
2022-01-21 18:08:25,607 iteration 274 : loss : 0.098700, loss_ce: 0.037547
2022-01-21 18:08:26,885 iteration 275 : loss : 0.103376, loss_ce: 0.041661
2022-01-21 18:08:28,218 iteration 276 : loss : 0.119808, loss_ce: 0.056270
2022-01-21 18:08:29,577 iteration 277 : loss : 0.129250, loss_ce: 0.046742
2022-01-21 18:08:30,778 iteration 278 : loss : 0.143780, loss_ce: 0.044208
2022-01-21 18:08:32,046 iteration 279 : loss : 0.133554, loss_ce: 0.045991
2022-01-21 18:08:33,311 iteration 280 : loss : 0.139341, loss_ce: 0.061780
2022-01-21 18:08:34,635 iteration 281 : loss : 0.106735, loss_ce: 0.043261
2022-01-21 18:08:35,937 iteration 282 : loss : 0.186486, loss_ce: 0.078528
2022-01-21 18:08:37,217 iteration 283 : loss : 0.146404, loss_ce: 0.076196
2022-01-21 18:08:38,602 iteration 284 : loss : 0.168929, loss_ce: 0.071386
2022-01-21 18:08:39,865 iteration 285 : loss : 0.146666, loss_ce: 0.049565
2022-01-21 18:08:41,143 iteration 286 : loss : 0.128015, loss_ce: 0.059810
2022-01-21 18:08:42,552 iteration 287 : loss : 0.125705, loss_ce: 0.058004
2022-01-21 18:08:43,934 iteration 288 : loss : 0.150517, loss_ce: 0.061210
2022-01-21 18:08:45,239 iteration 289 : loss : 0.128820, loss_ce: 0.047970
  4%|█▎                            | 17/400 [07:00<2:38:32, 24.84s/it]2022-01-21 18:08:46,614 iteration 290 : loss : 0.125208, loss_ce: 0.047328
2022-01-21 18:08:47,901 iteration 291 : loss : 0.116565, loss_ce: 0.047704
2022-01-21 18:08:49,191 iteration 292 : loss : 0.120176, loss_ce: 0.052812
2022-01-21 18:08:50,492 iteration 293 : loss : 0.121016, loss_ce: 0.054008
2022-01-21 18:08:51,821 iteration 294 : loss : 0.129287, loss_ce: 0.055408
2022-01-21 18:08:53,245 iteration 295 : loss : 0.120587, loss_ce: 0.038472
2022-01-21 18:08:54,541 iteration 296 : loss : 0.118256, loss_ce: 0.036617
2022-01-21 18:08:55,867 iteration 297 : loss : 0.113323, loss_ce: 0.036055
2022-01-21 18:08:57,155 iteration 298 : loss : 0.089440, loss_ce: 0.034934
2022-01-21 18:08:58,472 iteration 299 : loss : 0.124272, loss_ce: 0.044106
2022-01-21 18:08:59,793 iteration 300 : loss : 0.143012, loss_ce: 0.046067
2022-01-21 18:09:01,125 iteration 301 : loss : 0.141199, loss_ce: 0.072953
2022-01-21 18:09:02,511 iteration 302 : loss : 0.099690, loss_ce: 0.041269
2022-01-21 18:09:03,876 iteration 303 : loss : 0.166993, loss_ce: 0.066713
2022-01-21 18:09:05,220 iteration 304 : loss : 0.144509, loss_ce: 0.060560
2022-01-21 18:09:06,601 iteration 305 : loss : 0.122133, loss_ce: 0.046213
2022-01-21 18:09:07,975 iteration 306 : loss : 0.091911, loss_ce: 0.043845
  4%|█▎                            | 18/400 [07:23<2:34:06, 24.21s/it]2022-01-21 18:09:09,358 iteration 307 : loss : 0.156709, loss_ce: 0.058249
2022-01-21 18:09:10,648 iteration 308 : loss : 0.107777, loss_ce: 0.053294
2022-01-21 18:09:11,997 iteration 309 : loss : 0.223596, loss_ce: 0.092505
2022-01-21 18:09:13,368 iteration 310 : loss : 0.126504, loss_ce: 0.055197
2022-01-21 18:09:14,653 iteration 311 : loss : 0.139830, loss_ce: 0.041886
2022-01-21 18:09:15,973 iteration 312 : loss : 0.125863, loss_ce: 0.054081
2022-01-21 18:09:17,310 iteration 313 : loss : 0.161561, loss_ce: 0.086363
2022-01-21 18:09:18,567 iteration 314 : loss : 0.098955, loss_ce: 0.041652
2022-01-21 18:09:19,876 iteration 315 : loss : 0.105983, loss_ce: 0.041963
2022-01-21 18:09:21,218 iteration 316 : loss : 0.135149, loss_ce: 0.050765
2022-01-21 18:09:22,547 iteration 317 : loss : 0.171246, loss_ce: 0.062762
2022-01-21 18:09:23,891 iteration 318 : loss : 0.103525, loss_ce: 0.045784
2022-01-21 18:09:25,159 iteration 319 : loss : 0.101454, loss_ce: 0.045349
2022-01-21 18:09:26,565 iteration 320 : loss : 0.131997, loss_ce: 0.056193
2022-01-21 18:09:27,930 iteration 321 : loss : 0.134611, loss_ce: 0.045555
2022-01-21 18:09:29,257 iteration 322 : loss : 0.182480, loss_ce: 0.080055
2022-01-21 18:09:30,644 iteration 323 : loss : 0.126658, loss_ce: 0.043379
  5%|█▍                            | 19/400 [07:46<2:30:46, 23.74s/it]2022-01-21 18:09:32,008 iteration 324 : loss : 0.122385, loss_ce: 0.046553
2022-01-21 18:09:33,341 iteration 325 : loss : 0.144362, loss_ce: 0.045663
2022-01-21 18:09:34,704 iteration 326 : loss : 0.111209, loss_ce: 0.048206
2022-01-21 18:09:36,134 iteration 327 : loss : 0.147324, loss_ce: 0.062855
2022-01-21 18:09:37,454 iteration 328 : loss : 0.097641, loss_ce: 0.045513
2022-01-21 18:09:38,816 iteration 329 : loss : 0.132279, loss_ce: 0.065335
2022-01-21 18:09:40,188 iteration 330 : loss : 0.122207, loss_ce: 0.045071
2022-01-21 18:09:41,469 iteration 331 : loss : 0.104304, loss_ce: 0.049968
2022-01-21 18:09:42,778 iteration 332 : loss : 0.130993, loss_ce: 0.051178
2022-01-21 18:09:44,129 iteration 333 : loss : 0.111357, loss_ce: 0.054242
2022-01-21 18:09:45,465 iteration 334 : loss : 0.127396, loss_ce: 0.060333
2022-01-21 18:09:46,770 iteration 335 : loss : 0.153665, loss_ce: 0.052383
2022-01-21 18:09:48,147 iteration 336 : loss : 0.094441, loss_ce: 0.037025
2022-01-21 18:09:49,475 iteration 337 : loss : 0.094823, loss_ce: 0.029836
2022-01-21 18:09:50,760 iteration 338 : loss : 0.147650, loss_ce: 0.076895
2022-01-21 18:09:52,053 iteration 339 : loss : 0.149803, loss_ce: 0.048835
2022-01-21 18:09:52,054 Training Data Eval:
2022-01-21 18:09:58,580   Average segmentation loss on training set: 0.1345
2022-01-21 18:09:58,581 Validation Data Eval:
2022-01-21 18:10:00,817   Average segmentation loss on validation set: 0.1748
2022-01-21 18:10:02,193 iteration 340 : loss : 0.149051, loss_ce: 0.064673
  5%|█▌                            | 20/400 [08:17<2:45:12, 26.09s/it]2022-01-21 18:10:03,613 iteration 341 : loss : 0.095912, loss_ce: 0.041118
2022-01-21 18:10:04,971 iteration 342 : loss : 0.113257, loss_ce: 0.038277
2022-01-21 18:10:06,297 iteration 343 : loss : 0.133377, loss_ce: 0.052552
2022-01-21 18:10:07,669 iteration 344 : loss : 0.140994, loss_ce: 0.070190
2022-01-21 18:10:08,990 iteration 345 : loss : 0.120361, loss_ce: 0.036997
2022-01-21 18:10:10,386 iteration 346 : loss : 0.149930, loss_ce: 0.057329
2022-01-21 18:10:11,662 iteration 347 : loss : 0.114760, loss_ce: 0.052000
2022-01-21 18:10:13,013 iteration 348 : loss : 0.167228, loss_ce: 0.069762
2022-01-21 18:10:14,475 iteration 349 : loss : 0.146794, loss_ce: 0.082731
2022-01-21 18:10:15,801 iteration 350 : loss : 0.128230, loss_ce: 0.051710
2022-01-21 18:10:17,184 iteration 351 : loss : 0.131255, loss_ce: 0.059756
2022-01-21 18:10:18,552 iteration 352 : loss : 0.125423, loss_ce: 0.046316
2022-01-21 18:10:19,830 iteration 353 : loss : 0.114730, loss_ce: 0.043996
2022-01-21 18:10:21,165 iteration 354 : loss : 0.157143, loss_ce: 0.058591
2022-01-21 18:10:22,554 iteration 355 : loss : 0.155419, loss_ce: 0.063459
2022-01-21 18:10:24,010 iteration 356 : loss : 0.103502, loss_ce: 0.041188
2022-01-21 18:10:25,276 iteration 357 : loss : 0.100008, loss_ce: 0.041169
  5%|█▌                            | 21/400 [08:40<2:39:04, 25.18s/it]2022-01-21 18:10:26,681 iteration 358 : loss : 0.143263, loss_ce: 0.064156
2022-01-21 18:10:28,085 iteration 359 : loss : 0.149527, loss_ce: 0.059078
2022-01-21 18:10:29,365 iteration 360 : loss : 0.093892, loss_ce: 0.034943
2022-01-21 18:10:30,735 iteration 361 : loss : 0.150941, loss_ce: 0.058215
2022-01-21 18:10:32,159 iteration 362 : loss : 0.136778, loss_ce: 0.037953
2022-01-21 18:10:33,571 iteration 363 : loss : 0.137303, loss_ce: 0.058322
2022-01-21 18:10:34,935 iteration 364 : loss : 0.141059, loss_ce: 0.055262
2022-01-21 18:10:36,176 iteration 365 : loss : 0.126938, loss_ce: 0.059064
2022-01-21 18:10:37,549 iteration 366 : loss : 0.162377, loss_ce: 0.079853
2022-01-21 18:10:38,810 iteration 367 : loss : 0.110292, loss_ce: 0.044260
2022-01-21 18:10:40,185 iteration 368 : loss : 0.121436, loss_ce: 0.045451
2022-01-21 18:10:41,591 iteration 369 : loss : 0.167130, loss_ce: 0.055101
2022-01-21 18:10:42,984 iteration 370 : loss : 0.108207, loss_ce: 0.053113
2022-01-21 18:10:44,336 iteration 371 : loss : 0.175758, loss_ce: 0.054894
2022-01-21 18:10:45,697 iteration 372 : loss : 0.224733, loss_ce: 0.117545
2022-01-21 18:10:46,975 iteration 373 : loss : 0.143714, loss_ce: 0.045870
2022-01-21 18:10:48,284 iteration 374 : loss : 0.124867, loss_ce: 0.048543
  6%|█▋                            | 22/400 [09:03<2:34:33, 24.53s/it]2022-01-21 18:10:49,714 iteration 375 : loss : 0.174464, loss_ce: 0.069274
2022-01-21 18:10:51,001 iteration 376 : loss : 0.085548, loss_ce: 0.029245
2022-01-21 18:10:52,318 iteration 377 : loss : 0.112392, loss_ce: 0.030177
2022-01-21 18:10:53,714 iteration 378 : loss : 0.153690, loss_ce: 0.054684
2022-01-21 18:10:54,961 iteration 379 : loss : 0.107516, loss_ce: 0.047257
2022-01-21 18:10:56,325 iteration 380 : loss : 0.091340, loss_ce: 0.033391
2022-01-21 18:10:57,654 iteration 381 : loss : 0.077465, loss_ce: 0.030381
2022-01-21 18:10:58,900 iteration 382 : loss : 0.113191, loss_ce: 0.055097
2022-01-21 18:11:00,227 iteration 383 : loss : 0.164270, loss_ce: 0.064571
2022-01-21 18:11:01,577 iteration 384 : loss : 0.093544, loss_ce: 0.041313
2022-01-21 18:11:02,908 iteration 385 : loss : 0.074853, loss_ce: 0.031293
2022-01-21 18:11:04,244 iteration 386 : loss : 0.122607, loss_ce: 0.039782
2022-01-21 18:11:05,599 iteration 387 : loss : 0.147818, loss_ce: 0.054327
2022-01-21 18:11:06,969 iteration 388 : loss : 0.131694, loss_ce: 0.047765
2022-01-21 18:11:08,328 iteration 389 : loss : 0.185629, loss_ce: 0.077352
2022-01-21 18:11:09,642 iteration 390 : loss : 0.104849, loss_ce: 0.043259
2022-01-21 18:11:10,954 iteration 391 : loss : 0.156744, loss_ce: 0.087131
  6%|█▋                            | 23/400 [09:26<2:30:36, 23.97s/it]2022-01-21 18:11:12,354 iteration 392 : loss : 0.102081, loss_ce: 0.052340
2022-01-21 18:11:13,645 iteration 393 : loss : 0.096635, loss_ce: 0.035430
2022-01-21 18:11:15,030 iteration 394 : loss : 0.108616, loss_ce: 0.042503
2022-01-21 18:11:16,383 iteration 395 : loss : 0.108303, loss_ce: 0.047144
2022-01-21 18:11:17,688 iteration 396 : loss : 0.120349, loss_ce: 0.045882
2022-01-21 18:11:19,015 iteration 397 : loss : 0.101078, loss_ce: 0.040770
2022-01-21 18:11:20,374 iteration 398 : loss : 0.084489, loss_ce: 0.035931
2022-01-21 18:11:21,601 iteration 399 : loss : 0.105907, loss_ce: 0.045189
2022-01-21 18:11:22,940 iteration 400 : loss : 0.091603, loss_ce: 0.034355
2022-01-21 18:11:24,329 iteration 401 : loss : 0.091085, loss_ce: 0.045867
2022-01-21 18:11:25,641 iteration 402 : loss : 0.071788, loss_ce: 0.031799
2022-01-21 18:11:26,948 iteration 403 : loss : 0.086073, loss_ce: 0.030436
2022-01-21 18:11:28,309 iteration 404 : loss : 0.102634, loss_ce: 0.042586
2022-01-21 18:11:29,715 iteration 405 : loss : 0.108337, loss_ce: 0.042478
2022-01-21 18:11:31,022 iteration 406 : loss : 0.101710, loss_ce: 0.040037
2022-01-21 18:11:32,295 iteration 407 : loss : 0.103848, loss_ce: 0.036103
2022-01-21 18:11:33,611 iteration 408 : loss : 0.125645, loss_ce: 0.044592
  6%|█▊                            | 24/400 [09:49<2:27:46, 23.58s/it]2022-01-21 18:11:35,015 iteration 409 : loss : 0.114597, loss_ce: 0.057459
2022-01-21 18:11:36,371 iteration 410 : loss : 0.108794, loss_ce: 0.041667
2022-01-21 18:11:37,696 iteration 411 : loss : 0.157108, loss_ce: 0.044232
2022-01-21 18:11:38,929 iteration 412 : loss : 0.075017, loss_ce: 0.028456
2022-01-21 18:11:40,254 iteration 413 : loss : 0.093747, loss_ce: 0.031259
2022-01-21 18:11:41,528 iteration 414 : loss : 0.122785, loss_ce: 0.055185
2022-01-21 18:11:42,747 iteration 415 : loss : 0.082246, loss_ce: 0.031181
2022-01-21 18:11:44,054 iteration 416 : loss : 0.129324, loss_ce: 0.062032
2022-01-21 18:11:45,337 iteration 417 : loss : 0.144518, loss_ce: 0.055389
2022-01-21 18:11:46,721 iteration 418 : loss : 0.124123, loss_ce: 0.052233
2022-01-21 18:11:48,020 iteration 419 : loss : 0.111364, loss_ce: 0.065677
2022-01-21 18:11:49,356 iteration 420 : loss : 0.106945, loss_ce: 0.036708
2022-01-21 18:11:50,627 iteration 421 : loss : 0.128992, loss_ce: 0.052900
2022-01-21 18:11:51,899 iteration 422 : loss : 0.119393, loss_ce: 0.046917
2022-01-21 18:11:53,177 iteration 423 : loss : 0.133761, loss_ce: 0.045255
2022-01-21 18:11:54,511 iteration 424 : loss : 0.122602, loss_ce: 0.055077
2022-01-21 18:11:54,512 Training Data Eval:
2022-01-21 18:12:01,029   Average segmentation loss on training set: 0.1105
2022-01-21 18:12:01,030 Validation Data Eval:
2022-01-21 18:12:03,267   Average segmentation loss on validation set: 0.1278
2022-01-21 18:12:07,383 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:12:08,594 iteration 425 : loss : 0.109226, loss_ce: 0.045811
  6%|█▉                            | 25/400 [10:24<2:48:44, 27.00s/it]2022-01-21 18:12:09,800 iteration 426 : loss : 0.115546, loss_ce: 0.042365
2022-01-21 18:12:11,060 iteration 427 : loss : 0.098056, loss_ce: 0.037081
2022-01-21 18:12:12,305 iteration 428 : loss : 0.099831, loss_ce: 0.042297
2022-01-21 18:12:13,569 iteration 429 : loss : 0.124291, loss_ce: 0.063874
2022-01-21 18:12:14,834 iteration 430 : loss : 0.110451, loss_ce: 0.039262
2022-01-21 18:12:16,123 iteration 431 : loss : 0.171036, loss_ce: 0.063933
2022-01-21 18:12:17,478 iteration 432 : loss : 0.090447, loss_ce: 0.035628
2022-01-21 18:12:18,866 iteration 433 : loss : 0.099040, loss_ce: 0.040274
2022-01-21 18:12:20,205 iteration 434 : loss : 0.072118, loss_ce: 0.030225
2022-01-21 18:12:21,473 iteration 435 : loss : 0.060207, loss_ce: 0.024581
2022-01-21 18:12:22,776 iteration 436 : loss : 0.090872, loss_ce: 0.036074
2022-01-21 18:12:24,087 iteration 437 : loss : 0.125399, loss_ce: 0.067542
2022-01-21 18:12:25,347 iteration 438 : loss : 0.128544, loss_ce: 0.047885
2022-01-21 18:12:26,678 iteration 439 : loss : 0.107147, loss_ce: 0.033624
2022-01-21 18:12:27,983 iteration 440 : loss : 0.091873, loss_ce: 0.034730
2022-01-21 18:12:29,347 iteration 441 : loss : 0.099678, loss_ce: 0.038290
2022-01-21 18:12:30,693 iteration 442 : loss : 0.092119, loss_ce: 0.044580
  6%|█▉                            | 26/400 [10:46<2:39:08, 25.53s/it]2022-01-21 18:12:32,037 iteration 443 : loss : 0.102333, loss_ce: 0.047255
2022-01-21 18:12:33,307 iteration 444 : loss : 0.106710, loss_ce: 0.041998
2022-01-21 18:12:34,611 iteration 445 : loss : 0.132455, loss_ce: 0.043863
2022-01-21 18:12:36,056 iteration 446 : loss : 0.132488, loss_ce: 0.049483
2022-01-21 18:12:37,444 iteration 447 : loss : 0.102729, loss_ce: 0.055825
2022-01-21 18:12:38,817 iteration 448 : loss : 0.212815, loss_ce: 0.055781
2022-01-21 18:12:40,147 iteration 449 : loss : 0.097166, loss_ce: 0.044305
2022-01-21 18:12:41,451 iteration 450 : loss : 0.111133, loss_ce: 0.033261
2022-01-21 18:12:42,853 iteration 451 : loss : 0.069975, loss_ce: 0.027630
2022-01-21 18:12:44,215 iteration 452 : loss : 0.074208, loss_ce: 0.029237
2022-01-21 18:12:45,574 iteration 453 : loss : 0.111563, loss_ce: 0.049115
2022-01-21 18:12:46,929 iteration 454 : loss : 0.124047, loss_ce: 0.041785
2022-01-21 18:12:48,319 iteration 455 : loss : 0.068909, loss_ce: 0.026229
2022-01-21 18:12:49,668 iteration 456 : loss : 0.102056, loss_ce: 0.033709
2022-01-21 18:12:51,008 iteration 457 : loss : 0.122469, loss_ce: 0.045050
2022-01-21 18:12:52,417 iteration 458 : loss : 0.119459, loss_ce: 0.055315
2022-01-21 18:12:53,685 iteration 459 : loss : 0.080428, loss_ce: 0.028229
  7%|██                            | 27/400 [11:09<2:33:58, 24.77s/it]2022-01-21 18:12:55,076 iteration 460 : loss : 0.078573, loss_ce: 0.034902
2022-01-21 18:12:56,431 iteration 461 : loss : 0.079959, loss_ce: 0.032893
2022-01-21 18:12:57,746 iteration 462 : loss : 0.095336, loss_ce: 0.040887
2022-01-21 18:12:59,139 iteration 463 : loss : 0.126388, loss_ce: 0.074389
2022-01-21 18:13:00,477 iteration 464 : loss : 0.077123, loss_ce: 0.032966
2022-01-21 18:13:01,761 iteration 465 : loss : 0.105450, loss_ce: 0.034203
2022-01-21 18:13:03,077 iteration 466 : loss : 0.094616, loss_ce: 0.039353
2022-01-21 18:13:04,379 iteration 467 : loss : 0.105103, loss_ce: 0.037074
2022-01-21 18:13:05,804 iteration 468 : loss : 0.099572, loss_ce: 0.049795
2022-01-21 18:13:07,109 iteration 469 : loss : 0.063914, loss_ce: 0.023102
2022-01-21 18:13:08,435 iteration 470 : loss : 0.095102, loss_ce: 0.033728
2022-01-21 18:13:09,756 iteration 471 : loss : 0.104444, loss_ce: 0.033621
2022-01-21 18:13:11,137 iteration 472 : loss : 0.109230, loss_ce: 0.047826
2022-01-21 18:13:12,608 iteration 473 : loss : 0.089251, loss_ce: 0.036005
2022-01-21 18:13:14,029 iteration 474 : loss : 0.134410, loss_ce: 0.049298
2022-01-21 18:13:15,337 iteration 475 : loss : 0.073210, loss_ce: 0.031025
2022-01-21 18:13:16,726 iteration 476 : loss : 0.112227, loss_ce: 0.054811
  7%|██                            | 28/400 [11:32<2:30:20, 24.25s/it]2022-01-21 18:13:18,093 iteration 477 : loss : 0.108006, loss_ce: 0.035823
2022-01-21 18:13:19,480 iteration 478 : loss : 0.078299, loss_ce: 0.029048
2022-01-21 18:13:20,805 iteration 479 : loss : 0.094355, loss_ce: 0.036957
2022-01-21 18:13:22,159 iteration 480 : loss : 0.088997, loss_ce: 0.040551
2022-01-21 18:13:23,412 iteration 481 : loss : 0.125506, loss_ce: 0.049927
2022-01-21 18:13:24,756 iteration 482 : loss : 0.121007, loss_ce: 0.037957
2022-01-21 18:13:26,112 iteration 483 : loss : 0.089987, loss_ce: 0.033213
2022-01-21 18:13:27,484 iteration 484 : loss : 0.149900, loss_ce: 0.064935
2022-01-21 18:13:28,802 iteration 485 : loss : 0.073454, loss_ce: 0.034597
2022-01-21 18:13:30,102 iteration 486 : loss : 0.120412, loss_ce: 0.033892
2022-01-21 18:13:31,484 iteration 487 : loss : 0.071603, loss_ce: 0.029945
2022-01-21 18:13:32,756 iteration 488 : loss : 0.098835, loss_ce: 0.038518
2022-01-21 18:13:34,086 iteration 489 : loss : 0.102844, loss_ce: 0.046555
2022-01-21 18:13:35,307 iteration 490 : loss : 0.096066, loss_ce: 0.034840
2022-01-21 18:13:36,645 iteration 491 : loss : 0.106185, loss_ce: 0.049388
2022-01-21 18:13:37,956 iteration 492 : loss : 0.078221, loss_ce: 0.039352
2022-01-21 18:13:39,317 iteration 493 : loss : 0.094184, loss_ce: 0.041628
  7%|██▏                           | 29/400 [11:54<2:26:52, 23.75s/it]2022-01-21 18:13:40,683 iteration 494 : loss : 0.073957, loss_ce: 0.034296
2022-01-21 18:13:42,055 iteration 495 : loss : 0.089525, loss_ce: 0.033009
2022-01-21 18:13:43,374 iteration 496 : loss : 0.109482, loss_ce: 0.053404
2022-01-21 18:13:44,736 iteration 497 : loss : 0.143895, loss_ce: 0.076408
2022-01-21 18:13:46,130 iteration 498 : loss : 0.103352, loss_ce: 0.047356
2022-01-21 18:13:47,395 iteration 499 : loss : 0.075178, loss_ce: 0.033087
2022-01-21 18:13:48,674 iteration 500 : loss : 0.088011, loss_ce: 0.031508
2022-01-21 18:13:49,955 iteration 501 : loss : 0.112675, loss_ce: 0.052660
2022-01-21 18:13:51,342 iteration 502 : loss : 0.097157, loss_ce: 0.043898
2022-01-21 18:13:52,636 iteration 503 : loss : 0.144435, loss_ce: 0.047306
2022-01-21 18:13:53,989 iteration 504 : loss : 0.109318, loss_ce: 0.035517
2022-01-21 18:13:55,273 iteration 505 : loss : 0.085581, loss_ce: 0.034953
2022-01-21 18:13:56,690 iteration 506 : loss : 0.071971, loss_ce: 0.029553
2022-01-21 18:13:58,030 iteration 507 : loss : 0.109514, loss_ce: 0.035326
2022-01-21 18:13:59,364 iteration 508 : loss : 0.128941, loss_ce: 0.053249
2022-01-21 18:14:00,743 iteration 509 : loss : 0.082214, loss_ce: 0.029652
2022-01-21 18:14:00,743 Training Data Eval:
2022-01-21 18:14:07,252   Average segmentation loss on training set: 0.0691
2022-01-21 18:14:07,252 Validation Data Eval:
2022-01-21 18:14:09,485   Average segmentation loss on validation set: 0.1171
2022-01-21 18:14:13,625 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:14:14,904 iteration 510 : loss : 0.095855, loss_ce: 0.045887
  8%|██▎                           | 30/400 [12:30<2:48:21, 27.30s/it]2022-01-21 18:14:16,181 iteration 511 : loss : 0.127378, loss_ce: 0.064345
2022-01-21 18:14:17,359 iteration 512 : loss : 0.195659, loss_ce: 0.082606
2022-01-21 18:14:18,556 iteration 513 : loss : 0.073754, loss_ce: 0.026735
2022-01-21 18:14:19,834 iteration 514 : loss : 0.071780, loss_ce: 0.030995
2022-01-21 18:14:21,128 iteration 515 : loss : 0.107278, loss_ce: 0.051844
2022-01-21 18:14:22,477 iteration 516 : loss : 0.081362, loss_ce: 0.032613
2022-01-21 18:14:23,863 iteration 517 : loss : 0.097276, loss_ce: 0.052603
2022-01-21 18:14:25,141 iteration 518 : loss : 0.104741, loss_ce: 0.038975
2022-01-21 18:14:26,470 iteration 519 : loss : 0.075107, loss_ce: 0.033514
2022-01-21 18:14:27,744 iteration 520 : loss : 0.067267, loss_ce: 0.025253
2022-01-21 18:14:29,067 iteration 521 : loss : 0.091415, loss_ce: 0.036151
2022-01-21 18:14:30,431 iteration 522 : loss : 0.125772, loss_ce: 0.044187
2022-01-21 18:14:31,828 iteration 523 : loss : 0.096113, loss_ce: 0.041353
2022-01-21 18:14:33,249 iteration 524 : loss : 0.090162, loss_ce: 0.036218
2022-01-21 18:14:34,578 iteration 525 : loss : 0.149749, loss_ce: 0.068274
2022-01-21 18:14:35,897 iteration 526 : loss : 0.102976, loss_ce: 0.044329
2022-01-21 18:14:37,225 iteration 527 : loss : 0.090839, loss_ce: 0.032999
  8%|██▎                           | 31/400 [12:52<2:38:43, 25.81s/it]2022-01-21 18:14:38,563 iteration 528 : loss : 0.079739, loss_ce: 0.037649
2022-01-21 18:14:39,900 iteration 529 : loss : 0.098378, loss_ce: 0.035682
2022-01-21 18:14:41,189 iteration 530 : loss : 0.125329, loss_ce: 0.044391
2022-01-21 18:14:42,460 iteration 531 : loss : 0.085590, loss_ce: 0.027424
2022-01-21 18:14:43,752 iteration 532 : loss : 0.090571, loss_ce: 0.038431
2022-01-21 18:14:45,169 iteration 533 : loss : 0.053013, loss_ce: 0.019821
2022-01-21 18:14:46,445 iteration 534 : loss : 0.083550, loss_ce: 0.038523
2022-01-21 18:14:47,816 iteration 535 : loss : 0.089601, loss_ce: 0.030863
2022-01-21 18:14:49,220 iteration 536 : loss : 0.111243, loss_ce: 0.047770
2022-01-21 18:14:50,639 iteration 537 : loss : 0.120571, loss_ce: 0.038707
2022-01-21 18:14:51,996 iteration 538 : loss : 0.079455, loss_ce: 0.035249
2022-01-21 18:14:53,307 iteration 539 : loss : 0.087316, loss_ce: 0.034316
2022-01-21 18:14:54,652 iteration 540 : loss : 0.088627, loss_ce: 0.031634
2022-01-21 18:14:55,960 iteration 541 : loss : 0.089787, loss_ce: 0.037645
2022-01-21 18:14:57,288 iteration 542 : loss : 0.075972, loss_ce: 0.032354
2022-01-21 18:14:58,564 iteration 543 : loss : 0.062926, loss_ce: 0.023519
2022-01-21 18:14:59,872 iteration 544 : loss : 0.067401, loss_ce: 0.024822
  8%|██▍                           | 32/400 [13:15<2:32:28, 24.86s/it]2022-01-21 18:15:01,262 iteration 545 : loss : 0.063346, loss_ce: 0.030318
2022-01-21 18:15:02,586 iteration 546 : loss : 0.084898, loss_ce: 0.034317
2022-01-21 18:15:03,915 iteration 547 : loss : 0.088642, loss_ce: 0.034325
2022-01-21 18:15:05,229 iteration 548 : loss : 0.151823, loss_ce: 0.055114
2022-01-21 18:15:06,587 iteration 549 : loss : 0.060850, loss_ce: 0.024359
2022-01-21 18:15:07,881 iteration 550 : loss : 0.083916, loss_ce: 0.032928
2022-01-21 18:15:09,203 iteration 551 : loss : 0.080445, loss_ce: 0.032650
2022-01-21 18:15:10,499 iteration 552 : loss : 0.068356, loss_ce: 0.024841
2022-01-21 18:15:11,857 iteration 553 : loss : 0.075215, loss_ce: 0.031750
2022-01-21 18:15:13,122 iteration 554 : loss : 0.073750, loss_ce: 0.033472
2022-01-21 18:15:14,438 iteration 555 : loss : 0.077777, loss_ce: 0.022319
2022-01-21 18:15:15,803 iteration 556 : loss : 0.082547, loss_ce: 0.037637
2022-01-21 18:15:17,049 iteration 557 : loss : 0.083653, loss_ce: 0.032126
2022-01-21 18:15:18,405 iteration 558 : loss : 0.100026, loss_ce: 0.030682
2022-01-21 18:15:19,724 iteration 559 : loss : 0.077870, loss_ce: 0.029499
2022-01-21 18:15:21,062 iteration 560 : loss : 0.078397, loss_ce: 0.020575
2022-01-21 18:15:22,426 iteration 561 : loss : 0.121598, loss_ce: 0.069460
  8%|██▍                           | 33/400 [13:38<2:27:50, 24.17s/it]2022-01-21 18:15:23,901 iteration 562 : loss : 0.111321, loss_ce: 0.048375
2022-01-21 18:15:25,138 iteration 563 : loss : 0.081874, loss_ce: 0.033527
2022-01-21 18:15:26,485 iteration 564 : loss : 0.081822, loss_ce: 0.043784
2022-01-21 18:15:27,836 iteration 565 : loss : 0.063520, loss_ce: 0.027716
2022-01-21 18:15:29,214 iteration 566 : loss : 0.086418, loss_ce: 0.039215
2022-01-21 18:15:30,517 iteration 567 : loss : 0.079511, loss_ce: 0.027975
2022-01-21 18:15:31,812 iteration 568 : loss : 0.141148, loss_ce: 0.045639
2022-01-21 18:15:33,135 iteration 569 : loss : 0.097156, loss_ce: 0.038086
2022-01-21 18:15:34,501 iteration 570 : loss : 0.063890, loss_ce: 0.027423
2022-01-21 18:15:35,809 iteration 571 : loss : 0.162426, loss_ce: 0.072750
2022-01-21 18:15:37,157 iteration 572 : loss : 0.084824, loss_ce: 0.030328
2022-01-21 18:15:38,451 iteration 573 : loss : 0.083678, loss_ce: 0.038575
2022-01-21 18:15:39,783 iteration 574 : loss : 0.086569, loss_ce: 0.030229
2022-01-21 18:15:41,169 iteration 575 : loss : 0.090789, loss_ce: 0.024637
2022-01-21 18:15:42,542 iteration 576 : loss : 0.094950, loss_ce: 0.038690
2022-01-21 18:15:43,867 iteration 577 : loss : 0.089857, loss_ce: 0.041733
2022-01-21 18:15:45,154 iteration 578 : loss : 0.077824, loss_ce: 0.033072
  8%|██▌                           | 34/400 [14:00<2:24:47, 23.74s/it]2022-01-21 18:15:46,684 iteration 579 : loss : 0.093146, loss_ce: 0.047682
2022-01-21 18:15:48,030 iteration 580 : loss : 0.099097, loss_ce: 0.037684
2022-01-21 18:15:49,408 iteration 581 : loss : 0.114414, loss_ce: 0.043154
2022-01-21 18:15:50,725 iteration 582 : loss : 0.084046, loss_ce: 0.033149
2022-01-21 18:15:52,061 iteration 583 : loss : 0.144700, loss_ce: 0.045521
2022-01-21 18:15:53,359 iteration 584 : loss : 0.076573, loss_ce: 0.033160
2022-01-21 18:15:54,738 iteration 585 : loss : 0.072736, loss_ce: 0.030229
2022-01-21 18:15:56,031 iteration 586 : loss : 0.104496, loss_ce: 0.037011
2022-01-21 18:15:57,314 iteration 587 : loss : 0.068835, loss_ce: 0.031617
2022-01-21 18:15:58,663 iteration 588 : loss : 0.086103, loss_ce: 0.030132
2022-01-21 18:15:59,977 iteration 589 : loss : 0.076005, loss_ce: 0.031298
2022-01-21 18:16:01,307 iteration 590 : loss : 0.086269, loss_ce: 0.030754
2022-01-21 18:16:02,641 iteration 591 : loss : 0.095287, loss_ce: 0.041566
2022-01-21 18:16:03,976 iteration 592 : loss : 0.091391, loss_ce: 0.034913
2022-01-21 18:16:05,339 iteration 593 : loss : 0.060981, loss_ce: 0.023275
2022-01-21 18:16:06,687 iteration 594 : loss : 0.079925, loss_ce: 0.034264
2022-01-21 18:16:06,688 Training Data Eval:
2022-01-21 18:16:13,203   Average segmentation loss on training set: 0.2440
2022-01-21 18:16:13,203 Validation Data Eval:
2022-01-21 18:16:15,438   Average segmentation loss on validation set: 0.2328
2022-01-21 18:16:16,830 iteration 595 : loss : 0.100629, loss_ce: 0.055138
  9%|██▋                           | 35/400 [14:32<2:38:53, 26.12s/it]2022-01-21 18:16:18,204 iteration 596 : loss : 0.092525, loss_ce: 0.040919
2022-01-21 18:16:19,499 iteration 597 : loss : 0.114117, loss_ce: 0.039626
2022-01-21 18:16:20,788 iteration 598 : loss : 0.064242, loss_ce: 0.023280
2022-01-21 18:16:22,097 iteration 599 : loss : 0.086076, loss_ce: 0.031468
2022-01-21 18:16:23,404 iteration 600 : loss : 0.082182, loss_ce: 0.036307
2022-01-21 18:16:24,739 iteration 601 : loss : 0.104166, loss_ce: 0.044494
2022-01-21 18:16:26,090 iteration 602 : loss : 0.062050, loss_ce: 0.025512
2022-01-21 18:16:27,349 iteration 603 : loss : 0.083473, loss_ce: 0.028227
2022-01-21 18:16:28,625 iteration 604 : loss : 0.065010, loss_ce: 0.022554
2022-01-21 18:16:29,884 iteration 605 : loss : 0.085685, loss_ce: 0.029800
2022-01-21 18:16:31,347 iteration 606 : loss : 0.089357, loss_ce: 0.036007
2022-01-21 18:16:32,665 iteration 607 : loss : 0.091480, loss_ce: 0.036759
2022-01-21 18:16:33,987 iteration 608 : loss : 0.068168, loss_ce: 0.032419
2022-01-21 18:16:35,230 iteration 609 : loss : 0.072598, loss_ce: 0.026367
2022-01-21 18:16:36,600 iteration 610 : loss : 0.057124, loss_ce: 0.026472
2022-01-21 18:16:38,023 iteration 611 : loss : 0.094697, loss_ce: 0.046408
2022-01-21 18:16:39,372 iteration 612 : loss : 0.060608, loss_ce: 0.019996
  9%|██▋                           | 36/400 [14:54<2:31:57, 25.05s/it]2022-01-21 18:16:40,769 iteration 613 : loss : 0.069309, loss_ce: 0.029996
2022-01-21 18:16:42,059 iteration 614 : loss : 0.076236, loss_ce: 0.027737
2022-01-21 18:16:43,344 iteration 615 : loss : 0.114733, loss_ce: 0.053496
2022-01-21 18:16:44,745 iteration 616 : loss : 0.083313, loss_ce: 0.036013
2022-01-21 18:16:46,035 iteration 617 : loss : 0.082006, loss_ce: 0.036945
2022-01-21 18:16:47,369 iteration 618 : loss : 0.157463, loss_ce: 0.040047
2022-01-21 18:16:48,706 iteration 619 : loss : 0.175232, loss_ce: 0.079429
2022-01-21 18:16:50,139 iteration 620 : loss : 0.168011, loss_ce: 0.049849
2022-01-21 18:16:51,477 iteration 621 : loss : 0.066163, loss_ce: 0.022902
2022-01-21 18:16:52,930 iteration 622 : loss : 0.106038, loss_ce: 0.044503
2022-01-21 18:16:54,355 iteration 623 : loss : 0.105480, loss_ce: 0.045321
2022-01-21 18:16:55,675 iteration 624 : loss : 0.097007, loss_ce: 0.026610
2022-01-21 18:16:56,956 iteration 625 : loss : 0.065666, loss_ce: 0.027730
2022-01-21 18:16:58,331 iteration 626 : loss : 0.068595, loss_ce: 0.024172
2022-01-21 18:16:59,715 iteration 627 : loss : 0.084494, loss_ce: 0.034040
2022-01-21 18:17:01,144 iteration 628 : loss : 0.073178, loss_ce: 0.026165
2022-01-21 18:17:02,462 iteration 629 : loss : 0.075700, loss_ce: 0.032244
  9%|██▊                           | 37/400 [15:18<2:27:58, 24.46s/it]2022-01-21 18:17:03,865 iteration 630 : loss : 0.072040, loss_ce: 0.032330
2022-01-21 18:17:05,173 iteration 631 : loss : 0.043951, loss_ce: 0.020190
2022-01-21 18:17:06,483 iteration 632 : loss : 0.088706, loss_ce: 0.034735
2022-01-21 18:17:07,889 iteration 633 : loss : 0.067256, loss_ce: 0.024688
2022-01-21 18:17:09,229 iteration 634 : loss : 0.119737, loss_ce: 0.041245
2022-01-21 18:17:10,666 iteration 635 : loss : 0.083321, loss_ce: 0.035505
2022-01-21 18:17:12,023 iteration 636 : loss : 0.076763, loss_ce: 0.030955
2022-01-21 18:17:13,293 iteration 637 : loss : 0.082794, loss_ce: 0.033050
2022-01-21 18:17:14,700 iteration 638 : loss : 0.123830, loss_ce: 0.038262
2022-01-21 18:17:15,993 iteration 639 : loss : 0.065918, loss_ce: 0.027740
2022-01-21 18:17:17,261 iteration 640 : loss : 0.132888, loss_ce: 0.035898
2022-01-21 18:17:18,532 iteration 641 : loss : 0.072429, loss_ce: 0.030783
2022-01-21 18:17:19,814 iteration 642 : loss : 0.085011, loss_ce: 0.024302
2022-01-21 18:17:21,124 iteration 643 : loss : 0.082810, loss_ce: 0.031123
2022-01-21 18:17:22,443 iteration 644 : loss : 0.087547, loss_ce: 0.037971
2022-01-21 18:17:23,726 iteration 645 : loss : 0.066931, loss_ce: 0.021267
2022-01-21 18:17:25,116 iteration 646 : loss : 0.084099, loss_ce: 0.039729
 10%|██▊                           | 38/400 [15:40<2:24:17, 23.92s/it]2022-01-21 18:17:26,462 iteration 647 : loss : 0.115293, loss_ce: 0.043044
2022-01-21 18:17:27,789 iteration 648 : loss : 0.096783, loss_ce: 0.040720
2022-01-21 18:17:29,144 iteration 649 : loss : 0.087882, loss_ce: 0.032832
2022-01-21 18:17:30,546 iteration 650 : loss : 0.086504, loss_ce: 0.032641
2022-01-21 18:17:31,875 iteration 651 : loss : 0.059440, loss_ce: 0.023877
2022-01-21 18:17:33,099 iteration 652 : loss : 0.049414, loss_ce: 0.018884
2022-01-21 18:17:34,497 iteration 653 : loss : 0.093020, loss_ce: 0.034235
2022-01-21 18:17:35,775 iteration 654 : loss : 0.097187, loss_ce: 0.035325
2022-01-21 18:17:37,103 iteration 655 : loss : 0.111442, loss_ce: 0.041065
2022-01-21 18:17:38,442 iteration 656 : loss : 0.071831, loss_ce: 0.026889
2022-01-21 18:17:39,847 iteration 657 : loss : 0.053550, loss_ce: 0.021589
2022-01-21 18:17:41,201 iteration 658 : loss : 0.082712, loss_ce: 0.030241
2022-01-21 18:17:42,562 iteration 659 : loss : 0.082524, loss_ce: 0.030481
2022-01-21 18:17:43,865 iteration 660 : loss : 0.062248, loss_ce: 0.027661
2022-01-21 18:17:45,216 iteration 661 : loss : 0.081944, loss_ce: 0.038430
2022-01-21 18:17:46,642 iteration 662 : loss : 0.149252, loss_ce: 0.044335
2022-01-21 18:17:47,978 iteration 663 : loss : 0.077141, loss_ce: 0.031037
 10%|██▉                           | 39/400 [16:03<2:21:59, 23.60s/it]2022-01-21 18:17:49,375 iteration 664 : loss : 0.072197, loss_ce: 0.028802
2022-01-21 18:17:50,632 iteration 665 : loss : 0.071747, loss_ce: 0.031379
2022-01-21 18:17:51,949 iteration 666 : loss : 0.055658, loss_ce: 0.018255
2022-01-21 18:17:53,314 iteration 667 : loss : 0.051372, loss_ce: 0.021114
2022-01-21 18:17:54,650 iteration 668 : loss : 0.085515, loss_ce: 0.035366
2022-01-21 18:17:55,958 iteration 669 : loss : 0.057461, loss_ce: 0.022474
2022-01-21 18:17:57,411 iteration 670 : loss : 0.067912, loss_ce: 0.023838
2022-01-21 18:17:58,719 iteration 671 : loss : 0.079525, loss_ce: 0.025329
2022-01-21 18:18:00,116 iteration 672 : loss : 0.056454, loss_ce: 0.019870
2022-01-21 18:18:01,489 iteration 673 : loss : 0.078781, loss_ce: 0.033001
2022-01-21 18:18:02,846 iteration 674 : loss : 0.062424, loss_ce: 0.030537
2022-01-21 18:18:04,233 iteration 675 : loss : 0.128597, loss_ce: 0.060394
2022-01-21 18:18:05,555 iteration 676 : loss : 0.077826, loss_ce: 0.030314
2022-01-21 18:18:06,894 iteration 677 : loss : 0.067375, loss_ce: 0.031860
2022-01-21 18:18:08,262 iteration 678 : loss : 0.081516, loss_ce: 0.029578
2022-01-21 18:18:09,607 iteration 679 : loss : 0.079576, loss_ce: 0.035253
2022-01-21 18:18:09,607 Training Data Eval:
2022-01-21 18:18:16,122   Average segmentation loss on training set: 0.0602
2022-01-21 18:18:16,122 Validation Data Eval:
2022-01-21 18:18:18,354   Average segmentation loss on validation set: 0.1441
2022-01-21 18:18:19,686 iteration 680 : loss : 0.061619, loss_ce: 0.021742
 10%|███                           | 40/400 [16:35<2:36:11, 26.03s/it]2022-01-21 18:18:21,080 iteration 681 : loss : 0.056682, loss_ce: 0.020936
2022-01-21 18:18:22,332 iteration 682 : loss : 0.089142, loss_ce: 0.023642
2022-01-21 18:18:23,659 iteration 683 : loss : 0.079611, loss_ce: 0.035824
2022-01-21 18:18:24,946 iteration 684 : loss : 0.060553, loss_ce: 0.020549
2022-01-21 18:18:26,341 iteration 685 : loss : 0.066618, loss_ce: 0.026132
2022-01-21 18:18:27,669 iteration 686 : loss : 0.096466, loss_ce: 0.037277
2022-01-21 18:18:28,997 iteration 687 : loss : 0.066980, loss_ce: 0.029609
2022-01-21 18:18:30,302 iteration 688 : loss : 0.056314, loss_ce: 0.017615
2022-01-21 18:18:31,660 iteration 689 : loss : 0.059237, loss_ce: 0.026570
2022-01-21 18:18:32,979 iteration 690 : loss : 0.060856, loss_ce: 0.021726
2022-01-21 18:18:34,316 iteration 691 : loss : 0.071578, loss_ce: 0.029923
2022-01-21 18:18:35,703 iteration 692 : loss : 0.058276, loss_ce: 0.021027
2022-01-21 18:18:36,971 iteration 693 : loss : 0.081196, loss_ce: 0.043069
2022-01-21 18:18:38,311 iteration 694 : loss : 0.059975, loss_ce: 0.025462
2022-01-21 18:18:39,605 iteration 695 : loss : 0.073829, loss_ce: 0.028617
2022-01-21 18:18:41,002 iteration 696 : loss : 0.076153, loss_ce: 0.029804
2022-01-21 18:18:42,335 iteration 697 : loss : 0.060653, loss_ce: 0.022338
 10%|███                           | 41/400 [16:57<2:29:42, 25.02s/it]2022-01-21 18:18:43,670 iteration 698 : loss : 0.064122, loss_ce: 0.020384
2022-01-21 18:18:45,042 iteration 699 : loss : 0.064063, loss_ce: 0.029133
2022-01-21 18:18:46,349 iteration 700 : loss : 0.072567, loss_ce: 0.033733
2022-01-21 18:18:47,657 iteration 701 : loss : 0.072896, loss_ce: 0.032950
2022-01-21 18:18:49,023 iteration 702 : loss : 0.130318, loss_ce: 0.046544
2022-01-21 18:18:50,434 iteration 703 : loss : 0.045757, loss_ce: 0.021108
2022-01-21 18:18:51,703 iteration 704 : loss : 0.049395, loss_ce: 0.020260
2022-01-21 18:18:53,030 iteration 705 : loss : 0.093875, loss_ce: 0.035050
2022-01-21 18:18:54,372 iteration 706 : loss : 0.070810, loss_ce: 0.025875
2022-01-21 18:18:55,635 iteration 707 : loss : 0.071293, loss_ce: 0.034469
2022-01-21 18:18:56,961 iteration 708 : loss : 0.047192, loss_ce: 0.016659
2022-01-21 18:18:58,282 iteration 709 : loss : 0.092574, loss_ce: 0.037819
2022-01-21 18:18:59,644 iteration 710 : loss : 0.083824, loss_ce: 0.034544
2022-01-21 18:19:00,999 iteration 711 : loss : 0.069611, loss_ce: 0.028523
2022-01-21 18:19:02,418 iteration 712 : loss : 0.055483, loss_ce: 0.020198
2022-01-21 18:19:03,742 iteration 713 : loss : 0.059887, loss_ce: 0.026543
2022-01-21 18:19:05,139 iteration 714 : loss : 0.082968, loss_ce: 0.028822
 10%|███▏                          | 42/400 [17:20<2:25:19, 24.36s/it]2022-01-21 18:19:06,558 iteration 715 : loss : 0.054734, loss_ce: 0.019786
2022-01-21 18:19:07,944 iteration 716 : loss : 0.054132, loss_ce: 0.023838
2022-01-21 18:19:09,277 iteration 717 : loss : 0.083790, loss_ce: 0.031258
2022-01-21 18:19:10,622 iteration 718 : loss : 0.067162, loss_ce: 0.033600
2022-01-21 18:19:12,023 iteration 719 : loss : 0.072491, loss_ce: 0.027661
2022-01-21 18:19:13,357 iteration 720 : loss : 0.071505, loss_ce: 0.026137
2022-01-21 18:19:14,684 iteration 721 : loss : 0.058599, loss_ce: 0.020083
2022-01-21 18:19:16,002 iteration 722 : loss : 0.086016, loss_ce: 0.027841
2022-01-21 18:19:17,374 iteration 723 : loss : 0.084148, loss_ce: 0.040250
2022-01-21 18:19:18,681 iteration 724 : loss : 0.106776, loss_ce: 0.050963
2022-01-21 18:19:20,072 iteration 725 : loss : 0.093442, loss_ce: 0.030119
2022-01-21 18:19:21,396 iteration 726 : loss : 0.071665, loss_ce: 0.029851
2022-01-21 18:19:22,654 iteration 727 : loss : 0.083114, loss_ce: 0.033525
2022-01-21 18:19:24,019 iteration 728 : loss : 0.060970, loss_ce: 0.023504
2022-01-21 18:19:25,393 iteration 729 : loss : 0.056513, loss_ce: 0.023549
2022-01-21 18:19:26,740 iteration 730 : loss : 0.070178, loss_ce: 0.025731
2022-01-21 18:19:27,985 iteration 731 : loss : 0.057293, loss_ce: 0.019177
 11%|███▏                          | 43/400 [17:43<2:22:13, 23.90s/it]2022-01-21 18:19:29,295 iteration 732 : loss : 0.055533, loss_ce: 0.025610
2022-01-21 18:19:30,545 iteration 733 : loss : 0.066360, loss_ce: 0.031139
2022-01-21 18:19:31,912 iteration 734 : loss : 0.084169, loss_ce: 0.034458
2022-01-21 18:19:33,225 iteration 735 : loss : 0.083816, loss_ce: 0.031246
2022-01-21 18:19:34,520 iteration 736 : loss : 0.072853, loss_ce: 0.032131
2022-01-21 18:19:35,962 iteration 737 : loss : 0.084722, loss_ce: 0.036487
2022-01-21 18:19:37,206 iteration 738 : loss : 0.068098, loss_ce: 0.029226
2022-01-21 18:19:38,566 iteration 739 : loss : 0.070591, loss_ce: 0.030935
2022-01-21 18:19:39,872 iteration 740 : loss : 0.062687, loss_ce: 0.024127
2022-01-21 18:19:41,163 iteration 741 : loss : 0.061120, loss_ce: 0.021571
2022-01-21 18:19:42,413 iteration 742 : loss : 0.070704, loss_ce: 0.029502
2022-01-21 18:19:43,744 iteration 743 : loss : 0.061228, loss_ce: 0.023519
2022-01-21 18:19:45,106 iteration 744 : loss : 0.058946, loss_ce: 0.022589
2022-01-21 18:19:46,395 iteration 745 : loss : 0.101414, loss_ce: 0.021215
2022-01-21 18:19:47,691 iteration 746 : loss : 0.061400, loss_ce: 0.022405
2022-01-21 18:19:48,985 iteration 747 : loss : 0.068269, loss_ce: 0.027392
2022-01-21 18:19:50,263 iteration 748 : loss : 0.074197, loss_ce: 0.033093
 11%|███▎                          | 44/400 [18:05<2:18:55, 23.42s/it]2022-01-21 18:19:51,567 iteration 749 : loss : 0.158204, loss_ce: 0.029159
2022-01-21 18:19:52,866 iteration 750 : loss : 0.065729, loss_ce: 0.027175
2022-01-21 18:19:54,205 iteration 751 : loss : 0.049053, loss_ce: 0.013718
2022-01-21 18:19:55,507 iteration 752 : loss : 0.104467, loss_ce: 0.048265
2022-01-21 18:19:56,777 iteration 753 : loss : 0.078022, loss_ce: 0.038289
2022-01-21 18:19:58,058 iteration 754 : loss : 0.094050, loss_ce: 0.034127
2022-01-21 18:19:59,289 iteration 755 : loss : 0.083101, loss_ce: 0.041425
2022-01-21 18:20:00,528 iteration 756 : loss : 0.055159, loss_ce: 0.021202
2022-01-21 18:20:01,836 iteration 757 : loss : 0.092777, loss_ce: 0.041321
2022-01-21 18:20:03,242 iteration 758 : loss : 0.090285, loss_ce: 0.039590
2022-01-21 18:20:04,698 iteration 759 : loss : 0.105163, loss_ce: 0.034287
2022-01-21 18:20:06,002 iteration 760 : loss : 0.092702, loss_ce: 0.055575
2022-01-21 18:20:07,351 iteration 761 : loss : 0.065265, loss_ce: 0.028613
2022-01-21 18:20:08,720 iteration 762 : loss : 0.093122, loss_ce: 0.035102
2022-01-21 18:20:10,095 iteration 763 : loss : 0.060392, loss_ce: 0.026767
2022-01-21 18:20:11,392 iteration 764 : loss : 0.063956, loss_ce: 0.027846
2022-01-21 18:20:11,392 Training Data Eval:
2022-01-21 18:20:17,907   Average segmentation loss on training set: 0.0659
2022-01-21 18:20:17,908 Validation Data Eval:
2022-01-21 18:20:20,139   Average segmentation loss on validation set: 0.1345
2022-01-21 18:20:21,626 iteration 765 : loss : 0.100078, loss_ce: 0.039517
 11%|███▍                          | 45/400 [18:37<2:32:38, 25.80s/it]2022-01-21 18:20:23,048 iteration 766 : loss : 0.110709, loss_ce: 0.047306
2022-01-21 18:20:24,409 iteration 767 : loss : 0.060872, loss_ce: 0.021458
2022-01-21 18:20:25,755 iteration 768 : loss : 0.111795, loss_ce: 0.042024
2022-01-21 18:20:27,121 iteration 769 : loss : 0.068614, loss_ce: 0.027938
2022-01-21 18:20:28,371 iteration 770 : loss : 0.063862, loss_ce: 0.024083
2022-01-21 18:20:29,702 iteration 771 : loss : 0.103349, loss_ce: 0.026427
2022-01-21 18:20:31,035 iteration 772 : loss : 0.057855, loss_ce: 0.021511
2022-01-21 18:20:32,388 iteration 773 : loss : 0.138547, loss_ce: 0.041501
2022-01-21 18:20:33,824 iteration 774 : loss : 0.087682, loss_ce: 0.038807
2022-01-21 18:20:35,129 iteration 775 : loss : 0.093876, loss_ce: 0.049912
2022-01-21 18:20:36,412 iteration 776 : loss : 0.072665, loss_ce: 0.026857
2022-01-21 18:20:37,915 iteration 777 : loss : 0.092276, loss_ce: 0.039771
2022-01-21 18:20:39,173 iteration 778 : loss : 0.107444, loss_ce: 0.035436
2022-01-21 18:20:40,560 iteration 779 : loss : 0.092621, loss_ce: 0.045448
2022-01-21 18:20:41,950 iteration 780 : loss : 0.080020, loss_ce: 0.029801
2022-01-21 18:20:43,237 iteration 781 : loss : 0.066563, loss_ce: 0.034425
2022-01-21 18:20:44,482 iteration 782 : loss : 0.054353, loss_ce: 0.026067
 12%|███▍                          | 46/400 [19:00<2:27:00, 24.92s/it]2022-01-21 18:20:45,842 iteration 783 : loss : 0.072048, loss_ce: 0.036181
2022-01-21 18:20:47,130 iteration 784 : loss : 0.085835, loss_ce: 0.028875
2022-01-21 18:20:48,464 iteration 785 : loss : 0.073447, loss_ce: 0.033640
2022-01-21 18:20:49,767 iteration 786 : loss : 0.081442, loss_ce: 0.030922
2022-01-21 18:20:51,080 iteration 787 : loss : 0.063875, loss_ce: 0.024805
2022-01-21 18:20:52,466 iteration 788 : loss : 0.081244, loss_ce: 0.035915
2022-01-21 18:20:53,706 iteration 789 : loss : 0.087677, loss_ce: 0.028720
2022-01-21 18:20:55,078 iteration 790 : loss : 0.065283, loss_ce: 0.022761
2022-01-21 18:20:56,401 iteration 791 : loss : 0.057105, loss_ce: 0.024153
2022-01-21 18:20:57,666 iteration 792 : loss : 0.066019, loss_ce: 0.030253
2022-01-21 18:20:59,054 iteration 793 : loss : 0.112950, loss_ce: 0.059960
2022-01-21 18:21:00,289 iteration 794 : loss : 0.061429, loss_ce: 0.026701
2022-01-21 18:21:01,547 iteration 795 : loss : 0.062333, loss_ce: 0.021423
2022-01-21 18:21:02,809 iteration 796 : loss : 0.071077, loss_ce: 0.032676
2022-01-21 18:21:04,168 iteration 797 : loss : 0.089588, loss_ce: 0.030564
2022-01-21 18:21:05,466 iteration 798 : loss : 0.067650, loss_ce: 0.025505
2022-01-21 18:21:06,715 iteration 799 : loss : 0.050922, loss_ce: 0.023718
 12%|███▌                          | 47/400 [19:22<2:21:51, 24.11s/it]2022-01-21 18:21:08,176 iteration 800 : loss : 0.062821, loss_ce: 0.020954
2022-01-21 18:21:09,517 iteration 801 : loss : 0.059070, loss_ce: 0.023719
2022-01-21 18:21:10,842 iteration 802 : loss : 0.091242, loss_ce: 0.029572
2022-01-21 18:21:12,185 iteration 803 : loss : 0.061892, loss_ce: 0.032144
2022-01-21 18:21:13,597 iteration 804 : loss : 0.088768, loss_ce: 0.041041
2022-01-21 18:21:15,070 iteration 805 : loss : 0.056400, loss_ce: 0.019550
2022-01-21 18:21:16,377 iteration 806 : loss : 0.101618, loss_ce: 0.050852
2022-01-21 18:21:17,648 iteration 807 : loss : 0.064671, loss_ce: 0.024078
2022-01-21 18:21:19,012 iteration 808 : loss : 0.085579, loss_ce: 0.042792
2022-01-21 18:21:20,346 iteration 809 : loss : 0.071634, loss_ce: 0.021818
2022-01-21 18:21:21,639 iteration 810 : loss : 0.075558, loss_ce: 0.025120
2022-01-21 18:21:22,899 iteration 811 : loss : 0.086708, loss_ce: 0.043535
2022-01-21 18:21:24,191 iteration 812 : loss : 0.053698, loss_ce: 0.022503
2022-01-21 18:21:25,509 iteration 813 : loss : 0.122073, loss_ce: 0.033526
2022-01-21 18:21:26,940 iteration 814 : loss : 0.103433, loss_ce: 0.034065
2022-01-21 18:21:28,336 iteration 815 : loss : 0.090019, loss_ce: 0.035988
2022-01-21 18:21:29,679 iteration 816 : loss : 0.061422, loss_ce: 0.021959
 12%|███▌                          | 48/400 [19:45<2:19:25, 23.77s/it]2022-01-21 18:21:31,037 iteration 817 : loss : 0.055090, loss_ce: 0.022316
2022-01-21 18:21:32,306 iteration 818 : loss : 0.059617, loss_ce: 0.022638
2022-01-21 18:21:33,627 iteration 819 : loss : 0.055774, loss_ce: 0.018247
2022-01-21 18:21:34,878 iteration 820 : loss : 0.059360, loss_ce: 0.018616
2022-01-21 18:21:36,257 iteration 821 : loss : 0.054703, loss_ce: 0.018513
2022-01-21 18:21:37,617 iteration 822 : loss : 0.088079, loss_ce: 0.029855
2022-01-21 18:21:38,887 iteration 823 : loss : 0.049097, loss_ce: 0.017990
2022-01-21 18:21:40,155 iteration 824 : loss : 0.065708, loss_ce: 0.028586
2022-01-21 18:21:41,467 iteration 825 : loss : 0.064514, loss_ce: 0.023260
2022-01-21 18:21:42,777 iteration 826 : loss : 0.096072, loss_ce: 0.024181
2022-01-21 18:21:44,088 iteration 827 : loss : 0.125914, loss_ce: 0.039170
2022-01-21 18:21:45,399 iteration 828 : loss : 0.054766, loss_ce: 0.019377
2022-01-21 18:21:46,737 iteration 829 : loss : 0.070320, loss_ce: 0.025639
2022-01-21 18:21:48,114 iteration 830 : loss : 0.052700, loss_ce: 0.017443
2022-01-21 18:21:49,436 iteration 831 : loss : 0.061578, loss_ce: 0.024586
2022-01-21 18:21:50,736 iteration 832 : loss : 0.042417, loss_ce: 0.014500
2022-01-21 18:21:52,111 iteration 833 : loss : 0.142803, loss_ce: 0.090543
 12%|███▋                          | 49/400 [20:07<2:16:41, 23.37s/it]2022-01-21 18:21:53,472 iteration 834 : loss : 0.061693, loss_ce: 0.023433
2022-01-21 18:21:54,702 iteration 835 : loss : 0.077960, loss_ce: 0.020954
2022-01-21 18:21:56,031 iteration 836 : loss : 0.062820, loss_ce: 0.026465
2022-01-21 18:21:57,301 iteration 837 : loss : 0.047774, loss_ce: 0.025315
2022-01-21 18:21:58,544 iteration 838 : loss : 0.065678, loss_ce: 0.025376
2022-01-21 18:21:59,883 iteration 839 : loss : 0.074839, loss_ce: 0.033885
2022-01-21 18:22:01,187 iteration 840 : loss : 0.086152, loss_ce: 0.033038
2022-01-21 18:22:02,456 iteration 841 : loss : 0.060292, loss_ce: 0.027483
2022-01-21 18:22:03,762 iteration 842 : loss : 0.083509, loss_ce: 0.036716
2022-01-21 18:22:05,170 iteration 843 : loss : 0.064522, loss_ce: 0.023404
2022-01-21 18:22:06,476 iteration 844 : loss : 0.064178, loss_ce: 0.021631
2022-01-21 18:22:07,818 iteration 845 : loss : 0.078953, loss_ce: 0.028374
2022-01-21 18:22:09,259 iteration 846 : loss : 0.055720, loss_ce: 0.025082
2022-01-21 18:22:10,596 iteration 847 : loss : 0.074000, loss_ce: 0.030060
2022-01-21 18:22:11,823 iteration 848 : loss : 0.055266, loss_ce: 0.023112
2022-01-21 18:22:13,155 iteration 849 : loss : 0.059338, loss_ce: 0.019813
2022-01-21 18:22:13,155 Training Data Eval:
2022-01-21 18:22:19,665   Average segmentation loss on training set: 0.0476
2022-01-21 18:22:19,665 Validation Data Eval:
2022-01-21 18:22:21,893   Average segmentation loss on validation set: 0.1128
2022-01-21 18:22:26,221 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:22:27,499 iteration 850 : loss : 0.066857, loss_ce: 0.020552
 12%|███▊                          | 50/400 [20:43<2:37:20, 26.97s/it]2022-01-21 18:22:28,772 iteration 851 : loss : 0.051688, loss_ce: 0.019840
2022-01-21 18:22:29,962 iteration 852 : loss : 0.047421, loss_ce: 0.018499
2022-01-21 18:22:31,257 iteration 853 : loss : 0.076228, loss_ce: 0.034873
2022-01-21 18:22:32,575 iteration 854 : loss : 0.053808, loss_ce: 0.014998
2022-01-21 18:22:33,914 iteration 855 : loss : 0.055429, loss_ce: 0.023245
2022-01-21 18:22:35,274 iteration 856 : loss : 0.054415, loss_ce: 0.018070
2022-01-21 18:22:36,567 iteration 857 : loss : 0.051161, loss_ce: 0.021151
2022-01-21 18:22:37,795 iteration 858 : loss : 0.051857, loss_ce: 0.022775
2022-01-21 18:22:39,100 iteration 859 : loss : 0.064368, loss_ce: 0.023262
2022-01-21 18:22:40,363 iteration 860 : loss : 0.069369, loss_ce: 0.021194
2022-01-21 18:22:41,744 iteration 861 : loss : 0.069268, loss_ce: 0.029252
2022-01-21 18:22:42,993 iteration 862 : loss : 0.064596, loss_ce: 0.020441
2022-01-21 18:22:44,385 iteration 863 : loss : 0.079193, loss_ce: 0.033305
2022-01-21 18:22:45,747 iteration 864 : loss : 0.058186, loss_ce: 0.025955
2022-01-21 18:22:46,993 iteration 865 : loss : 0.047932, loss_ce: 0.019460
2022-01-21 18:22:48,373 iteration 866 : loss : 0.075391, loss_ce: 0.041167
2022-01-21 18:22:49,627 iteration 867 : loss : 0.034286, loss_ce: 0.013537
 13%|███▊                          | 51/400 [21:05<2:28:26, 25.52s/it]2022-01-21 18:22:51,023 iteration 868 : loss : 0.109764, loss_ce: 0.036213
2022-01-21 18:22:52,340 iteration 869 : loss : 0.063211, loss_ce: 0.025986
2022-01-21 18:22:53,567 iteration 870 : loss : 0.048426, loss_ce: 0.018100
2022-01-21 18:22:54,832 iteration 871 : loss : 0.057765, loss_ce: 0.021231
2022-01-21 18:22:56,118 iteration 872 : loss : 0.056074, loss_ce: 0.029206
2022-01-21 18:22:57,507 iteration 873 : loss : 0.053372, loss_ce: 0.018920
2022-01-21 18:22:58,740 iteration 874 : loss : 0.043029, loss_ce: 0.018700
2022-01-21 18:23:00,199 iteration 875 : loss : 0.086985, loss_ce: 0.036191
2022-01-21 18:23:01,519 iteration 876 : loss : 0.039108, loss_ce: 0.018448
2022-01-21 18:23:02,738 iteration 877 : loss : 0.040630, loss_ce: 0.016551
2022-01-21 18:23:04,098 iteration 878 : loss : 0.068142, loss_ce: 0.028648
2022-01-21 18:23:05,387 iteration 879 : loss : 0.057051, loss_ce: 0.021478
2022-01-21 18:23:06,730 iteration 880 : loss : 0.055805, loss_ce: 0.017991
2022-01-21 18:23:08,016 iteration 881 : loss : 0.074921, loss_ce: 0.031287
2022-01-21 18:23:09,377 iteration 882 : loss : 0.067665, loss_ce: 0.027834
2022-01-21 18:23:10,692 iteration 883 : loss : 0.063436, loss_ce: 0.030344
2022-01-21 18:23:12,102 iteration 884 : loss : 0.071889, loss_ce: 0.033162
 13%|███▉                          | 52/400 [21:27<2:22:43, 24.61s/it]2022-01-21 18:23:13,501 iteration 885 : loss : 0.070517, loss_ce: 0.027739
2022-01-21 18:23:14,860 iteration 886 : loss : 0.059276, loss_ce: 0.025828
2022-01-21 18:23:16,228 iteration 887 : loss : 0.106590, loss_ce: 0.051894
2022-01-21 18:23:17,557 iteration 888 : loss : 0.068268, loss_ce: 0.029294
2022-01-21 18:23:18,949 iteration 889 : loss : 0.064309, loss_ce: 0.023994
2022-01-21 18:23:20,384 iteration 890 : loss : 0.063418, loss_ce: 0.022034
2022-01-21 18:23:21,720 iteration 891 : loss : 0.058153, loss_ce: 0.021916
2022-01-21 18:23:23,048 iteration 892 : loss : 0.062491, loss_ce: 0.029155
2022-01-21 18:23:24,354 iteration 893 : loss : 0.057796, loss_ce: 0.020139
2022-01-21 18:23:25,782 iteration 894 : loss : 0.074661, loss_ce: 0.026648
2022-01-21 18:23:27,079 iteration 895 : loss : 0.081512, loss_ce: 0.020439
2022-01-21 18:23:28,465 iteration 896 : loss : 0.091030, loss_ce: 0.035736
2022-01-21 18:23:29,877 iteration 897 : loss : 0.086058, loss_ce: 0.039316
2022-01-21 18:23:31,183 iteration 898 : loss : 0.066646, loss_ce: 0.038225
2022-01-21 18:23:32,495 iteration 899 : loss : 0.062398, loss_ce: 0.026809
2022-01-21 18:23:33,765 iteration 900 : loss : 0.059032, loss_ce: 0.027718
2022-01-21 18:23:35,057 iteration 901 : loss : 0.081630, loss_ce: 0.025209
 13%|███▉                          | 53/400 [21:50<2:19:25, 24.11s/it]2022-01-21 18:23:36,451 iteration 902 : loss : 0.076755, loss_ce: 0.029353
2022-01-21 18:23:37,866 iteration 903 : loss : 0.059394, loss_ce: 0.023571
2022-01-21 18:23:39,237 iteration 904 : loss : 0.089699, loss_ce: 0.031026
2022-01-21 18:23:40,584 iteration 905 : loss : 0.090152, loss_ce: 0.040571
2022-01-21 18:23:41,906 iteration 906 : loss : 0.062817, loss_ce: 0.029773
2022-01-21 18:23:43,296 iteration 907 : loss : 0.050944, loss_ce: 0.015370
2022-01-21 18:23:44,527 iteration 908 : loss : 0.046160, loss_ce: 0.018016
2022-01-21 18:23:45,877 iteration 909 : loss : 0.056262, loss_ce: 0.023475
2022-01-21 18:23:47,134 iteration 910 : loss : 0.065423, loss_ce: 0.027724
2022-01-21 18:23:48,451 iteration 911 : loss : 0.049584, loss_ce: 0.018796
2022-01-21 18:23:49,757 iteration 912 : loss : 0.048690, loss_ce: 0.016573
2022-01-21 18:23:51,054 iteration 913 : loss : 0.070751, loss_ce: 0.022013
2022-01-21 18:23:52,369 iteration 914 : loss : 0.106857, loss_ce: 0.053090
2022-01-21 18:23:53,651 iteration 915 : loss : 0.169515, loss_ce: 0.049433
2022-01-21 18:23:54,939 iteration 916 : loss : 0.049237, loss_ce: 0.015765
2022-01-21 18:23:56,282 iteration 917 : loss : 0.065021, loss_ce: 0.025965
2022-01-21 18:23:57,646 iteration 918 : loss : 0.073980, loss_ce: 0.023931
 14%|████                          | 54/400 [22:13<2:16:23, 23.65s/it]2022-01-21 18:23:59,050 iteration 919 : loss : 0.048960, loss_ce: 0.019723
2022-01-21 18:24:00,396 iteration 920 : loss : 0.065343, loss_ce: 0.027346
2022-01-21 18:24:01,767 iteration 921 : loss : 0.083050, loss_ce: 0.030930
2022-01-21 18:24:03,154 iteration 922 : loss : 0.070566, loss_ce: 0.030114
2022-01-21 18:24:04,455 iteration 923 : loss : 0.047508, loss_ce: 0.020884
2022-01-21 18:24:05,828 iteration 924 : loss : 0.077221, loss_ce: 0.027105
2022-01-21 18:24:07,113 iteration 925 : loss : 0.045129, loss_ce: 0.017791
2022-01-21 18:24:08,490 iteration 926 : loss : 0.071926, loss_ce: 0.031564
2022-01-21 18:24:09,748 iteration 927 : loss : 0.068235, loss_ce: 0.022433
2022-01-21 18:24:11,062 iteration 928 : loss : 0.054325, loss_ce: 0.024184
2022-01-21 18:24:12,446 iteration 929 : loss : 0.057527, loss_ce: 0.024700
2022-01-21 18:24:13,790 iteration 930 : loss : 0.063174, loss_ce: 0.026457
2022-01-21 18:24:15,140 iteration 931 : loss : 0.099996, loss_ce: 0.023928
2022-01-21 18:24:16,472 iteration 932 : loss : 0.048312, loss_ce: 0.015675
2022-01-21 18:24:17,768 iteration 933 : loss : 0.103859, loss_ce: 0.042306
2022-01-21 18:24:19,094 iteration 934 : loss : 0.044674, loss_ce: 0.017675
2022-01-21 18:24:19,094 Training Data Eval:
2022-01-21 18:24:25,624   Average segmentation loss on training set: 0.0754
2022-01-21 18:24:25,625 Validation Data Eval:
2022-01-21 18:24:27,862   Average segmentation loss on validation set: 0.1810
2022-01-21 18:24:29,283 iteration 935 : loss : 0.121581, loss_ce: 0.044252
 14%|████▏                         | 55/400 [22:44<2:29:46, 26.05s/it]2022-01-21 18:24:30,625 iteration 936 : loss : 0.052559, loss_ce: 0.017908
2022-01-21 18:24:31,968 iteration 937 : loss : 0.058581, loss_ce: 0.019322
2022-01-21 18:24:33,343 iteration 938 : loss : 0.054236, loss_ce: 0.019114
2022-01-21 18:24:34,624 iteration 939 : loss : 0.061714, loss_ce: 0.021531
2022-01-21 18:24:35,970 iteration 940 : loss : 0.075842, loss_ce: 0.030328
2022-01-21 18:24:37,401 iteration 941 : loss : 0.061815, loss_ce: 0.023707
2022-01-21 18:24:38,684 iteration 942 : loss : 0.057997, loss_ce: 0.019624
2022-01-21 18:24:39,988 iteration 943 : loss : 0.055896, loss_ce: 0.025313
2022-01-21 18:24:41,265 iteration 944 : loss : 0.053801, loss_ce: 0.021212
2022-01-21 18:24:42,556 iteration 945 : loss : 0.061610, loss_ce: 0.021876
2022-01-21 18:24:43,846 iteration 946 : loss : 0.050683, loss_ce: 0.022265
2022-01-21 18:24:45,128 iteration 947 : loss : 0.053288, loss_ce: 0.018072
2022-01-21 18:24:46,402 iteration 948 : loss : 0.084086, loss_ce: 0.026101
2022-01-21 18:24:47,709 iteration 949 : loss : 0.053652, loss_ce: 0.019340
2022-01-21 18:24:49,008 iteration 950 : loss : 0.098318, loss_ce: 0.044802
2022-01-21 18:24:50,367 iteration 951 : loss : 0.088574, loss_ce: 0.064803
2022-01-21 18:24:51,642 iteration 952 : loss : 0.061259, loss_ce: 0.024372
 14%|████▏                         | 56/400 [23:07<2:23:00, 24.94s/it]2022-01-21 18:24:53,027 iteration 953 : loss : 0.056720, loss_ce: 0.019147
2022-01-21 18:24:54,401 iteration 954 : loss : 0.042615, loss_ce: 0.017067
2022-01-21 18:24:55,654 iteration 955 : loss : 0.036282, loss_ce: 0.014871
2022-01-21 18:24:57,018 iteration 956 : loss : 0.065665, loss_ce: 0.026938
2022-01-21 18:24:58,358 iteration 957 : loss : 0.065837, loss_ce: 0.026294
2022-01-21 18:24:59,716 iteration 958 : loss : 0.068632, loss_ce: 0.023513
2022-01-21 18:25:01,138 iteration 959 : loss : 0.053842, loss_ce: 0.023441
2022-01-21 18:25:02,617 iteration 960 : loss : 0.066499, loss_ce: 0.030666
2022-01-21 18:25:03,910 iteration 961 : loss : 0.081708, loss_ce: 0.023257
2022-01-21 18:25:05,170 iteration 962 : loss : 0.059467, loss_ce: 0.017444
2022-01-21 18:25:06,570 iteration 963 : loss : 0.062462, loss_ce: 0.023548
2022-01-21 18:25:07,932 iteration 964 : loss : 0.059831, loss_ce: 0.028949
2022-01-21 18:25:09,237 iteration 965 : loss : 0.040543, loss_ce: 0.018573
2022-01-21 18:25:10,567 iteration 966 : loss : 0.053912, loss_ce: 0.021167
2022-01-21 18:25:11,912 iteration 967 : loss : 0.044434, loss_ce: 0.018353
2022-01-21 18:25:13,194 iteration 968 : loss : 0.118045, loss_ce: 0.044163
2022-01-21 18:25:14,540 iteration 969 : loss : 0.049440, loss_ce: 0.020461
 14%|████▎                         | 57/400 [23:30<2:19:04, 24.33s/it]2022-01-21 18:25:15,887 iteration 970 : loss : 0.060552, loss_ce: 0.028891
2022-01-21 18:25:17,240 iteration 971 : loss : 0.051102, loss_ce: 0.014717
2022-01-21 18:25:18,505 iteration 972 : loss : 0.049846, loss_ce: 0.023020
2022-01-21 18:25:19,850 iteration 973 : loss : 0.053895, loss_ce: 0.016146
2022-01-21 18:25:21,119 iteration 974 : loss : 0.048466, loss_ce: 0.018770
2022-01-21 18:25:22,495 iteration 975 : loss : 0.066688, loss_ce: 0.021230
2022-01-21 18:25:23,799 iteration 976 : loss : 0.048844, loss_ce: 0.019838
2022-01-21 18:25:25,112 iteration 977 : loss : 0.042443, loss_ce: 0.014595
2022-01-21 18:25:26,457 iteration 978 : loss : 0.042477, loss_ce: 0.016193
2022-01-21 18:25:27,756 iteration 979 : loss : 0.086788, loss_ce: 0.043620
2022-01-21 18:25:29,058 iteration 980 : loss : 0.040994, loss_ce: 0.013577
2022-01-21 18:25:30,477 iteration 981 : loss : 0.051091, loss_ce: 0.025133
2022-01-21 18:25:31,778 iteration 982 : loss : 0.050249, loss_ce: 0.026019
2022-01-21 18:25:33,152 iteration 983 : loss : 0.104971, loss_ce: 0.032608
2022-01-21 18:25:34,403 iteration 984 : loss : 0.059417, loss_ce: 0.027903
2022-01-21 18:25:35,728 iteration 985 : loss : 0.047306, loss_ce: 0.015032
2022-01-21 18:25:37,104 iteration 986 : loss : 0.058084, loss_ce: 0.021986
 14%|████▎                         | 58/400 [23:52<2:15:40, 23.80s/it]2022-01-21 18:25:38,538 iteration 987 : loss : 0.044860, loss_ce: 0.020930
2022-01-21 18:25:39,890 iteration 988 : loss : 0.073963, loss_ce: 0.033881
2022-01-21 18:25:41,233 iteration 989 : loss : 0.070522, loss_ce: 0.034741
2022-01-21 18:25:42,558 iteration 990 : loss : 0.059102, loss_ce: 0.027881
2022-01-21 18:25:43,879 iteration 991 : loss : 0.048632, loss_ce: 0.021699
2022-01-21 18:25:45,285 iteration 992 : loss : 0.052117, loss_ce: 0.024813
2022-01-21 18:25:46,649 iteration 993 : loss : 0.047642, loss_ce: 0.019813
2022-01-21 18:25:48,089 iteration 994 : loss : 0.076859, loss_ce: 0.031656
2022-01-21 18:25:49,437 iteration 995 : loss : 0.090646, loss_ce: 0.028361
2022-01-21 18:25:50,833 iteration 996 : loss : 0.041032, loss_ce: 0.018148
2022-01-21 18:25:52,222 iteration 997 : loss : 0.077371, loss_ce: 0.029792
2022-01-21 18:25:53,503 iteration 998 : loss : 0.079492, loss_ce: 0.026215
2022-01-21 18:25:54,889 iteration 999 : loss : 0.062278, loss_ce: 0.024970
2022-01-21 18:25:56,183 iteration 1000 : loss : 0.054606, loss_ce: 0.016713
2022-01-21 18:25:57,483 iteration 1001 : loss : 0.086789, loss_ce: 0.019579
2022-01-21 18:25:58,909 iteration 1002 : loss : 0.047918, loss_ce: 0.018910
2022-01-21 18:26:00,323 iteration 1003 : loss : 0.094820, loss_ce: 0.034788
 15%|████▍                         | 59/400 [24:15<2:14:16, 23.63s/it]2022-01-21 18:26:01,698 iteration 1004 : loss : 0.129427, loss_ce: 0.060488
2022-01-21 18:26:03,030 iteration 1005 : loss : 0.070533, loss_ce: 0.025184
2022-01-21 18:26:04,465 iteration 1006 : loss : 0.077146, loss_ce: 0.029350
2022-01-21 18:26:05,763 iteration 1007 : loss : 0.065355, loss_ce: 0.030874
2022-01-21 18:26:07,061 iteration 1008 : loss : 0.102739, loss_ce: 0.040726
2022-01-21 18:26:08,355 iteration 1009 : loss : 0.065181, loss_ce: 0.024931
2022-01-21 18:26:09,660 iteration 1010 : loss : 0.063023, loss_ce: 0.024518
2022-01-21 18:26:11,057 iteration 1011 : loss : 0.063811, loss_ce: 0.026862
2022-01-21 18:26:12,381 iteration 1012 : loss : 0.049579, loss_ce: 0.020325
2022-01-21 18:26:13,656 iteration 1013 : loss : 0.052271, loss_ce: 0.016928
2022-01-21 18:26:15,013 iteration 1014 : loss : 0.085814, loss_ce: 0.035738
2022-01-21 18:26:16,280 iteration 1015 : loss : 0.049629, loss_ce: 0.018710
2022-01-21 18:26:17,633 iteration 1016 : loss : 0.054897, loss_ce: 0.022601
2022-01-21 18:26:18,873 iteration 1017 : loss : 0.044390, loss_ce: 0.015459
2022-01-21 18:26:20,105 iteration 1018 : loss : 0.067869, loss_ce: 0.028730
2022-01-21 18:26:21,424 iteration 1019 : loss : 0.108104, loss_ce: 0.045704
2022-01-21 18:26:21,424 Training Data Eval:
2022-01-21 18:26:27,971   Average segmentation loss on training set: 0.0505
2022-01-21 18:26:27,972 Validation Data Eval:
2022-01-21 18:26:30,210   Average segmentation loss on validation set: 0.1496
2022-01-21 18:26:31,491 iteration 1020 : loss : 0.042166, loss_ce: 0.015066
 15%|████▌                         | 60/400 [24:47<2:26:42, 25.89s/it]2022-01-21 18:26:32,951 iteration 1021 : loss : 0.072458, loss_ce: 0.016720
2022-01-21 18:26:34,278 iteration 1022 : loss : 0.052270, loss_ce: 0.022791
2022-01-21 18:26:35,625 iteration 1023 : loss : 0.084821, loss_ce: 0.025541
2022-01-21 18:26:37,026 iteration 1024 : loss : 0.045558, loss_ce: 0.017488
2022-01-21 18:26:38,413 iteration 1025 : loss : 0.047873, loss_ce: 0.020637
2022-01-21 18:26:39,652 iteration 1026 : loss : 0.049788, loss_ce: 0.016914
2022-01-21 18:26:41,039 iteration 1027 : loss : 0.063984, loss_ce: 0.025015
2022-01-21 18:26:42,414 iteration 1028 : loss : 0.059483, loss_ce: 0.025856
2022-01-21 18:26:43,735 iteration 1029 : loss : 0.053843, loss_ce: 0.022514
2022-01-21 18:26:45,069 iteration 1030 : loss : 0.069658, loss_ce: 0.024014
2022-01-21 18:26:46,462 iteration 1031 : loss : 0.088839, loss_ce: 0.039350
2022-01-21 18:26:47,832 iteration 1032 : loss : 0.063759, loss_ce: 0.031280
2022-01-21 18:26:49,145 iteration 1033 : loss : 0.056089, loss_ce: 0.018303
2022-01-21 18:26:50,559 iteration 1034 : loss : 0.081171, loss_ce: 0.030610
2022-01-21 18:26:51,919 iteration 1035 : loss : 0.045480, loss_ce: 0.018744
2022-01-21 18:26:53,286 iteration 1036 : loss : 0.069448, loss_ce: 0.027276
2022-01-21 18:26:54,598 iteration 1037 : loss : 0.046704, loss_ce: 0.015475
 15%|████▌                         | 61/400 [25:10<2:21:32, 25.05s/it]2022-01-21 18:26:56,005 iteration 1038 : loss : 0.039556, loss_ce: 0.014940
2022-01-21 18:26:57,354 iteration 1039 : loss : 0.045960, loss_ce: 0.021338
2022-01-21 18:26:58,730 iteration 1040 : loss : 0.074530, loss_ce: 0.031256
2022-01-21 18:27:00,086 iteration 1041 : loss : 0.059405, loss_ce: 0.024407
2022-01-21 18:27:01,456 iteration 1042 : loss : 0.056588, loss_ce: 0.022925
2022-01-21 18:27:02,808 iteration 1043 : loss : 0.078545, loss_ce: 0.025072
2022-01-21 18:27:04,180 iteration 1044 : loss : 0.044750, loss_ce: 0.016742
2022-01-21 18:27:05,424 iteration 1045 : loss : 0.051151, loss_ce: 0.021634
2022-01-21 18:27:06,703 iteration 1046 : loss : 0.086279, loss_ce: 0.019393
2022-01-21 18:27:08,091 iteration 1047 : loss : 0.091252, loss_ce: 0.038609
2022-01-21 18:27:09,427 iteration 1048 : loss : 0.062450, loss_ce: 0.023684
2022-01-21 18:27:10,775 iteration 1049 : loss : 0.067200, loss_ce: 0.020020
2022-01-21 18:27:12,178 iteration 1050 : loss : 0.095791, loss_ce: 0.025291
2022-01-21 18:27:13,508 iteration 1051 : loss : 0.078520, loss_ce: 0.029923
2022-01-21 18:27:14,847 iteration 1052 : loss : 0.084113, loss_ce: 0.033276
2022-01-21 18:27:16,112 iteration 1053 : loss : 0.068587, loss_ce: 0.019834
2022-01-21 18:27:17,526 iteration 1054 : loss : 0.080107, loss_ce: 0.038828
 16%|████▋                         | 62/400 [25:33<2:17:33, 24.42s/it]2022-01-21 18:27:18,912 iteration 1055 : loss : 0.050719, loss_ce: 0.017074
2022-01-21 18:27:20,220 iteration 1056 : loss : 0.072959, loss_ce: 0.034052
2022-01-21 18:27:21,533 iteration 1057 : loss : 0.084729, loss_ce: 0.040950
2022-01-21 18:27:22,863 iteration 1058 : loss : 0.050365, loss_ce: 0.021716
2022-01-21 18:27:24,111 iteration 1059 : loss : 0.051521, loss_ce: 0.018601
2022-01-21 18:27:25,421 iteration 1060 : loss : 0.037868, loss_ce: 0.014166
2022-01-21 18:27:26,772 iteration 1061 : loss : 0.053802, loss_ce: 0.021580
2022-01-21 18:27:28,112 iteration 1062 : loss : 0.074293, loss_ce: 0.029274
2022-01-21 18:27:29,503 iteration 1063 : loss : 0.104278, loss_ce: 0.036969
2022-01-21 18:27:30,820 iteration 1064 : loss : 0.073534, loss_ce: 0.022907
2022-01-21 18:27:32,082 iteration 1065 : loss : 0.050591, loss_ce: 0.020620
2022-01-21 18:27:33,442 iteration 1066 : loss : 0.036834, loss_ce: 0.015893
2022-01-21 18:27:34,750 iteration 1067 : loss : 0.145341, loss_ce: 0.029080
2022-01-21 18:27:36,122 iteration 1068 : loss : 0.061735, loss_ce: 0.028093
2022-01-21 18:27:37,477 iteration 1069 : loss : 0.094321, loss_ce: 0.044742
2022-01-21 18:27:38,803 iteration 1070 : loss : 0.055938, loss_ce: 0.022187
2022-01-21 18:27:40,112 iteration 1071 : loss : 0.058771, loss_ce: 0.029133
 16%|████▋                         | 63/400 [25:55<2:14:02, 23.87s/it]2022-01-21 18:27:41,573 iteration 1072 : loss : 0.068055, loss_ce: 0.023611
2022-01-21 18:27:42,879 iteration 1073 : loss : 0.087160, loss_ce: 0.022072
2022-01-21 18:27:44,187 iteration 1074 : loss : 0.052733, loss_ce: 0.021223
2022-01-21 18:27:45,539 iteration 1075 : loss : 0.062811, loss_ce: 0.021055
2022-01-21 18:27:46,806 iteration 1076 : loss : 0.047586, loss_ce: 0.016791
2022-01-21 18:27:48,115 iteration 1077 : loss : 0.055292, loss_ce: 0.018427
2022-01-21 18:27:49,506 iteration 1078 : loss : 0.107872, loss_ce: 0.055817
2022-01-21 18:27:50,788 iteration 1079 : loss : 0.048411, loss_ce: 0.018881
2022-01-21 18:27:52,066 iteration 1080 : loss : 0.043044, loss_ce: 0.018045
2022-01-21 18:27:53,417 iteration 1081 : loss : 0.060222, loss_ce: 0.021391
2022-01-21 18:27:54,764 iteration 1082 : loss : 0.056492, loss_ce: 0.029749
2022-01-21 18:27:56,139 iteration 1083 : loss : 0.067019, loss_ce: 0.026941
2022-01-21 18:27:57,444 iteration 1084 : loss : 0.063740, loss_ce: 0.033389
2022-01-21 18:27:58,852 iteration 1085 : loss : 0.073069, loss_ce: 0.027934
2022-01-21 18:28:00,155 iteration 1086 : loss : 0.049466, loss_ce: 0.019203
2022-01-21 18:28:01,477 iteration 1087 : loss : 0.067120, loss_ce: 0.029672
2022-01-21 18:28:02,849 iteration 1088 : loss : 0.049345, loss_ce: 0.020333
 16%|████▊                         | 64/400 [26:18<2:11:45, 23.53s/it]2022-01-21 18:28:04,187 iteration 1089 : loss : 0.068695, loss_ce: 0.024948
2022-01-21 18:28:05,488 iteration 1090 : loss : 0.057335, loss_ce: 0.027066
2022-01-21 18:28:06,812 iteration 1091 : loss : 0.042975, loss_ce: 0.019861
2022-01-21 18:28:08,134 iteration 1092 : loss : 0.040557, loss_ce: 0.015614
2022-01-21 18:28:09,477 iteration 1093 : loss : 0.089177, loss_ce: 0.033327
2022-01-21 18:28:10,855 iteration 1094 : loss : 0.040970, loss_ce: 0.016250
2022-01-21 18:28:12,132 iteration 1095 : loss : 0.039546, loss_ce: 0.016805
2022-01-21 18:28:13,544 iteration 1096 : loss : 0.053248, loss_ce: 0.022382
2022-01-21 18:28:14,888 iteration 1097 : loss : 0.054433, loss_ce: 0.020849
2022-01-21 18:28:16,175 iteration 1098 : loss : 0.045963, loss_ce: 0.019868
2022-01-21 18:28:17,525 iteration 1099 : loss : 0.052411, loss_ce: 0.016263
2022-01-21 18:28:18,929 iteration 1100 : loss : 0.050327, loss_ce: 0.016507
2022-01-21 18:28:20,253 iteration 1101 : loss : 0.053280, loss_ce: 0.022565
2022-01-21 18:28:21,653 iteration 1102 : loss : 0.068780, loss_ce: 0.023002
2022-01-21 18:28:22,965 iteration 1103 : loss : 0.069780, loss_ce: 0.022419
2022-01-21 18:28:24,271 iteration 1104 : loss : 0.061385, loss_ce: 0.024245
2022-01-21 18:28:24,271 Training Data Eval:
2022-01-21 18:28:30,797   Average segmentation loss on training set: 0.0798
2022-01-21 18:28:30,797 Validation Data Eval:
2022-01-21 18:28:33,037   Average segmentation loss on validation set: 0.2406
2022-01-21 18:28:34,414 iteration 1105 : loss : 0.062601, loss_ce: 0.016942
 16%|████▉                         | 65/400 [26:50<2:24:49, 25.94s/it]2022-01-21 18:28:35,712 iteration 1106 : loss : 0.054110, loss_ce: 0.017254
2022-01-21 18:28:37,017 iteration 1107 : loss : 0.057430, loss_ce: 0.028985
2022-01-21 18:28:38,349 iteration 1108 : loss : 0.082143, loss_ce: 0.021607
2022-01-21 18:28:39,615 iteration 1109 : loss : 0.053545, loss_ce: 0.021822
2022-01-21 18:28:40,945 iteration 1110 : loss : 0.054513, loss_ce: 0.024987
2022-01-21 18:28:42,250 iteration 1111 : loss : 0.043223, loss_ce: 0.018913
2022-01-21 18:28:43,555 iteration 1112 : loss : 0.069717, loss_ce: 0.028438
2022-01-21 18:28:44,844 iteration 1113 : loss : 0.064987, loss_ce: 0.020134
2022-01-21 18:28:46,223 iteration 1114 : loss : 0.059325, loss_ce: 0.026040
2022-01-21 18:28:47,677 iteration 1115 : loss : 0.056442, loss_ce: 0.029616
2022-01-21 18:28:49,054 iteration 1116 : loss : 0.076393, loss_ce: 0.022239
2022-01-21 18:28:50,497 iteration 1117 : loss : 0.045950, loss_ce: 0.015703
2022-01-21 18:28:51,873 iteration 1118 : loss : 0.081949, loss_ce: 0.024590
2022-01-21 18:28:53,175 iteration 1119 : loss : 0.050999, loss_ce: 0.020220
2022-01-21 18:28:54,469 iteration 1120 : loss : 0.061858, loss_ce: 0.019176
2022-01-21 18:28:55,812 iteration 1121 : loss : 0.088291, loss_ce: 0.032268
2022-01-21 18:28:57,143 iteration 1122 : loss : 0.077770, loss_ce: 0.037332
 16%|████▉                         | 66/400 [27:12<2:19:01, 24.98s/it]2022-01-21 18:28:58,468 iteration 1123 : loss : 0.129006, loss_ce: 0.060939
2022-01-21 18:28:59,831 iteration 1124 : loss : 0.052513, loss_ce: 0.022825
2022-01-21 18:29:01,152 iteration 1125 : loss : 0.046643, loss_ce: 0.014928
2022-01-21 18:29:02,461 iteration 1126 : loss : 0.052378, loss_ce: 0.019621
2022-01-21 18:29:03,758 iteration 1127 : loss : 0.072368, loss_ce: 0.024759
2022-01-21 18:29:05,140 iteration 1128 : loss : 0.070768, loss_ce: 0.030082
2022-01-21 18:29:06,521 iteration 1129 : loss : 0.057765, loss_ce: 0.016861
2022-01-21 18:29:07,828 iteration 1130 : loss : 0.055899, loss_ce: 0.026173
2022-01-21 18:29:09,136 iteration 1131 : loss : 0.070101, loss_ce: 0.027061
2022-01-21 18:29:10,498 iteration 1132 : loss : 0.050279, loss_ce: 0.020002
2022-01-21 18:29:11,761 iteration 1133 : loss : 0.032157, loss_ce: 0.014728
2022-01-21 18:29:13,085 iteration 1134 : loss : 0.067655, loss_ce: 0.024371
2022-01-21 18:29:14,372 iteration 1135 : loss : 0.051143, loss_ce: 0.022180
2022-01-21 18:29:15,686 iteration 1136 : loss : 0.043310, loss_ce: 0.015255
2022-01-21 18:29:16,978 iteration 1137 : loss : 0.076766, loss_ce: 0.030837
2022-01-21 18:29:18,342 iteration 1138 : loss : 0.055452, loss_ce: 0.025304
2022-01-21 18:29:19,681 iteration 1139 : loss : 0.080413, loss_ce: 0.028989
 17%|█████                         | 67/400 [27:35<2:14:33, 24.24s/it]2022-01-21 18:29:21,049 iteration 1140 : loss : 0.051935, loss_ce: 0.019328
2022-01-21 18:29:22,335 iteration 1141 : loss : 0.042715, loss_ce: 0.016023
2022-01-21 18:29:23,720 iteration 1142 : loss : 0.060606, loss_ce: 0.025317
2022-01-21 18:29:25,045 iteration 1143 : loss : 0.051101, loss_ce: 0.020171
2022-01-21 18:29:26,408 iteration 1144 : loss : 0.068373, loss_ce: 0.033533
2022-01-21 18:29:27,685 iteration 1145 : loss : 0.052179, loss_ce: 0.018518
2022-01-21 18:29:29,024 iteration 1146 : loss : 0.066288, loss_ce: 0.029456
2022-01-21 18:29:30,265 iteration 1147 : loss : 0.048241, loss_ce: 0.018086
2022-01-21 18:29:31,635 iteration 1148 : loss : 0.071628, loss_ce: 0.024705
2022-01-21 18:29:32,908 iteration 1149 : loss : 0.049236, loss_ce: 0.022369
2022-01-21 18:29:34,235 iteration 1150 : loss : 0.056771, loss_ce: 0.022202
2022-01-21 18:29:35,592 iteration 1151 : loss : 0.047048, loss_ce: 0.018348
2022-01-21 18:29:37,045 iteration 1152 : loss : 0.047184, loss_ce: 0.019804
2022-01-21 18:29:38,287 iteration 1153 : loss : 0.054690, loss_ce: 0.019167
2022-01-21 18:29:39,645 iteration 1154 : loss : 0.073471, loss_ce: 0.024576
2022-01-21 18:29:40,929 iteration 1155 : loss : 0.057769, loss_ce: 0.017888
2022-01-21 18:29:42,305 iteration 1156 : loss : 0.060729, loss_ce: 0.030140
 17%|█████                         | 68/400 [27:57<2:11:27, 23.76s/it]2022-01-21 18:29:43,651 iteration 1157 : loss : 0.092751, loss_ce: 0.028394
2022-01-21 18:29:44,991 iteration 1158 : loss : 0.049022, loss_ce: 0.018106
2022-01-21 18:29:46,398 iteration 1159 : loss : 0.043085, loss_ce: 0.012877
2022-01-21 18:29:47,840 iteration 1160 : loss : 0.089752, loss_ce: 0.038753
2022-01-21 18:29:49,225 iteration 1161 : loss : 0.046843, loss_ce: 0.023316
2022-01-21 18:29:50,577 iteration 1162 : loss : 0.057098, loss_ce: 0.019658
2022-01-21 18:29:51,883 iteration 1163 : loss : 0.049544, loss_ce: 0.020128
2022-01-21 18:29:53,200 iteration 1164 : loss : 0.063661, loss_ce: 0.025463
2022-01-21 18:29:54,523 iteration 1165 : loss : 0.050451, loss_ce: 0.022875
2022-01-21 18:29:55,924 iteration 1166 : loss : 0.040457, loss_ce: 0.014341
2022-01-21 18:29:57,217 iteration 1167 : loss : 0.043493, loss_ce: 0.020880
2022-01-21 18:29:58,528 iteration 1168 : loss : 0.044147, loss_ce: 0.018765
2022-01-21 18:29:59,821 iteration 1169 : loss : 0.046626, loss_ce: 0.018749
2022-01-21 18:30:01,117 iteration 1170 : loss : 0.062102, loss_ce: 0.023960
2022-01-21 18:30:02,456 iteration 1171 : loss : 0.054997, loss_ce: 0.019121
2022-01-21 18:30:03,793 iteration 1172 : loss : 0.048385, loss_ce: 0.020257
2022-01-21 18:30:05,149 iteration 1173 : loss : 0.056809, loss_ce: 0.019924
 17%|█████▏                        | 69/400 [28:20<2:09:32, 23.48s/it]2022-01-21 18:30:06,496 iteration 1174 : loss : 0.068140, loss_ce: 0.021904
2022-01-21 18:30:07,825 iteration 1175 : loss : 0.041974, loss_ce: 0.016998
2022-01-21 18:30:09,144 iteration 1176 : loss : 0.057825, loss_ce: 0.026213
2022-01-21 18:30:10,430 iteration 1177 : loss : 0.046410, loss_ce: 0.018709
2022-01-21 18:30:11,792 iteration 1178 : loss : 0.042581, loss_ce: 0.012044
2022-01-21 18:30:13,205 iteration 1179 : loss : 0.061489, loss_ce: 0.025393
2022-01-21 18:30:14,501 iteration 1180 : loss : 0.056847, loss_ce: 0.027084
2022-01-21 18:30:15,821 iteration 1181 : loss : 0.060447, loss_ce: 0.023676
2022-01-21 18:30:17,163 iteration 1182 : loss : 0.053077, loss_ce: 0.018720
2022-01-21 18:30:18,437 iteration 1183 : loss : 0.050565, loss_ce: 0.019091
2022-01-21 18:30:19,723 iteration 1184 : loss : 0.037314, loss_ce: 0.016788
2022-01-21 18:30:21,085 iteration 1185 : loss : 0.040730, loss_ce: 0.015592
2022-01-21 18:30:22,377 iteration 1186 : loss : 0.043157, loss_ce: 0.017903
2022-01-21 18:30:23,763 iteration 1187 : loss : 0.053072, loss_ce: 0.019197
2022-01-21 18:30:25,050 iteration 1188 : loss : 0.066276, loss_ce: 0.025182
2022-01-21 18:30:26,450 iteration 1189 : loss : 0.055257, loss_ce: 0.025497
2022-01-21 18:30:26,451 Training Data Eval:
2022-01-21 18:30:32,972   Average segmentation loss on training set: 0.0405
2022-01-21 18:30:32,972 Validation Data Eval:
2022-01-21 18:30:35,212   Average segmentation loss on validation set: 0.0722
2022-01-21 18:30:39,419 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:30:40,660 iteration 1190 : loss : 0.048795, loss_ce: 0.023059
 18%|█████▎                        | 70/400 [28:56<2:29:01, 27.09s/it]2022-01-21 18:30:41,985 iteration 1191 : loss : 0.059003, loss_ce: 0.024154
2022-01-21 18:30:43,155 iteration 1192 : loss : 0.039603, loss_ce: 0.017669
2022-01-21 18:30:44,452 iteration 1193 : loss : 0.065463, loss_ce: 0.020237
2022-01-21 18:30:45,702 iteration 1194 : loss : 0.048968, loss_ce: 0.014228
2022-01-21 18:30:46,961 iteration 1195 : loss : 0.039815, loss_ce: 0.017816
2022-01-21 18:30:48,237 iteration 1196 : loss : 0.041070, loss_ce: 0.016879
2022-01-21 18:30:49,474 iteration 1197 : loss : 0.039105, loss_ce: 0.013370
2022-01-21 18:30:50,838 iteration 1198 : loss : 0.046654, loss_ce: 0.022330
2022-01-21 18:30:52,162 iteration 1199 : loss : 0.052939, loss_ce: 0.020105
2022-01-21 18:30:53,469 iteration 1200 : loss : 0.059626, loss_ce: 0.017364
2022-01-21 18:30:54,736 iteration 1201 : loss : 0.041707, loss_ce: 0.018381
2022-01-21 18:30:56,077 iteration 1202 : loss : 0.045057, loss_ce: 0.016027
2022-01-21 18:30:57,409 iteration 1203 : loss : 0.058574, loss_ce: 0.020537
2022-01-21 18:30:58,730 iteration 1204 : loss : 0.047091, loss_ce: 0.015680
2022-01-21 18:31:00,063 iteration 1205 : loss : 0.080018, loss_ce: 0.038456
2022-01-21 18:31:01,397 iteration 1206 : loss : 0.043445, loss_ce: 0.016096
2022-01-21 18:31:02,773 iteration 1207 : loss : 0.041081, loss_ce: 0.013457
 18%|█████▎                        | 71/400 [29:18<2:20:22, 25.60s/it]2022-01-21 18:31:04,175 iteration 1208 : loss : 0.054730, loss_ce: 0.026179
2022-01-21 18:31:05,508 iteration 1209 : loss : 0.045446, loss_ce: 0.017759
2022-01-21 18:31:06,838 iteration 1210 : loss : 0.044241, loss_ce: 0.016657
2022-01-21 18:31:08,113 iteration 1211 : loss : 0.051867, loss_ce: 0.025082
2022-01-21 18:31:09,368 iteration 1212 : loss : 0.063826, loss_ce: 0.017774
2022-01-21 18:31:10,808 iteration 1213 : loss : 0.053420, loss_ce: 0.022358
2022-01-21 18:31:12,132 iteration 1214 : loss : 0.037720, loss_ce: 0.016248
2022-01-21 18:31:13,468 iteration 1215 : loss : 0.082606, loss_ce: 0.033213
2022-01-21 18:31:14,909 iteration 1216 : loss : 0.046441, loss_ce: 0.016678
2022-01-21 18:31:16,253 iteration 1217 : loss : 0.044182, loss_ce: 0.013813
2022-01-21 18:31:17,536 iteration 1218 : loss : 0.043525, loss_ce: 0.016441
2022-01-21 18:31:18,787 iteration 1219 : loss : 0.049877, loss_ce: 0.017235
2022-01-21 18:31:20,099 iteration 1220 : loss : 0.040374, loss_ce: 0.016143
2022-01-21 18:31:21,382 iteration 1221 : loss : 0.055809, loss_ce: 0.020868
2022-01-21 18:31:22,769 iteration 1222 : loss : 0.047331, loss_ce: 0.016072
2022-01-21 18:31:24,069 iteration 1223 : loss : 0.071567, loss_ce: 0.034936
2022-01-21 18:31:25,432 iteration 1224 : loss : 0.064606, loss_ce: 0.025345
 18%|█████▍                        | 72/400 [29:41<2:15:06, 24.72s/it]2022-01-21 18:31:26,772 iteration 1225 : loss : 0.042052, loss_ce: 0.016270
2022-01-21 18:31:28,141 iteration 1226 : loss : 0.051101, loss_ce: 0.022919
2022-01-21 18:31:29,416 iteration 1227 : loss : 0.066992, loss_ce: 0.025304
2022-01-21 18:31:30,722 iteration 1228 : loss : 0.035262, loss_ce: 0.013351
2022-01-21 18:31:31,971 iteration 1229 : loss : 0.052624, loss_ce: 0.016384
2022-01-21 18:31:33,247 iteration 1230 : loss : 0.055263, loss_ce: 0.020787
2022-01-21 18:31:34,598 iteration 1231 : loss : 0.059235, loss_ce: 0.025388
2022-01-21 18:31:35,877 iteration 1232 : loss : 0.058666, loss_ce: 0.023985
2022-01-21 18:31:37,165 iteration 1233 : loss : 0.041855, loss_ce: 0.015367
2022-01-21 18:31:38,520 iteration 1234 : loss : 0.044970, loss_ce: 0.019718
2022-01-21 18:31:39,869 iteration 1235 : loss : 0.077848, loss_ce: 0.024548
2022-01-21 18:31:41,149 iteration 1236 : loss : 0.044511, loss_ce: 0.017696
2022-01-21 18:31:42,380 iteration 1237 : loss : 0.054705, loss_ce: 0.022708
2022-01-21 18:31:43,745 iteration 1238 : loss : 0.033732, loss_ce: 0.012234
2022-01-21 18:31:45,011 iteration 1239 : loss : 0.037359, loss_ce: 0.014295
2022-01-21 18:31:46,285 iteration 1240 : loss : 0.042915, loss_ce: 0.017685
2022-01-21 18:31:47,561 iteration 1241 : loss : 0.041657, loss_ce: 0.019997
 18%|█████▍                        | 73/400 [30:03<2:10:28, 23.94s/it]2022-01-21 18:31:48,944 iteration 1242 : loss : 0.065742, loss_ce: 0.037376
2022-01-21 18:31:50,224 iteration 1243 : loss : 0.056926, loss_ce: 0.021649
2022-01-21 18:31:51,513 iteration 1244 : loss : 0.042846, loss_ce: 0.017454
2022-01-21 18:31:52,847 iteration 1245 : loss : 0.060298, loss_ce: 0.019748
2022-01-21 18:31:54,174 iteration 1246 : loss : 0.053995, loss_ce: 0.016782
2022-01-21 18:31:55,460 iteration 1247 : loss : 0.040370, loss_ce: 0.016547
2022-01-21 18:31:56,801 iteration 1248 : loss : 0.065688, loss_ce: 0.025222
2022-01-21 18:31:58,081 iteration 1249 : loss : 0.044114, loss_ce: 0.014119
2022-01-21 18:31:59,500 iteration 1250 : loss : 0.053166, loss_ce: 0.022517
2022-01-21 18:32:00,942 iteration 1251 : loss : 0.049463, loss_ce: 0.022952
2022-01-21 18:32:02,297 iteration 1252 : loss : 0.042595, loss_ce: 0.017321
2022-01-21 18:32:03,543 iteration 1253 : loss : 0.040149, loss_ce: 0.014005
2022-01-21 18:32:04,865 iteration 1254 : loss : 0.041191, loss_ce: 0.021421
2022-01-21 18:32:06,198 iteration 1255 : loss : 0.047052, loss_ce: 0.019108
2022-01-21 18:32:07,504 iteration 1256 : loss : 0.051610, loss_ce: 0.021085
2022-01-21 18:32:08,816 iteration 1257 : loss : 0.058523, loss_ce: 0.017106
2022-01-21 18:32:10,151 iteration 1258 : loss : 0.034090, loss_ce: 0.014325
 18%|█████▌                        | 74/400 [30:25<2:07:51, 23.53s/it]2022-01-21 18:32:11,465 iteration 1259 : loss : 0.039901, loss_ce: 0.017730
2022-01-21 18:32:12,838 iteration 1260 : loss : 0.040706, loss_ce: 0.018227
2022-01-21 18:32:14,138 iteration 1261 : loss : 0.045813, loss_ce: 0.014836
2022-01-21 18:32:15,538 iteration 1262 : loss : 0.074657, loss_ce: 0.034678
2022-01-21 18:32:16,966 iteration 1263 : loss : 0.085426, loss_ce: 0.031256
2022-01-21 18:32:18,271 iteration 1264 : loss : 0.038896, loss_ce: 0.017450
2022-01-21 18:32:19,652 iteration 1265 : loss : 0.046423, loss_ce: 0.023974
2022-01-21 18:32:21,033 iteration 1266 : loss : 0.047986, loss_ce: 0.017962
2022-01-21 18:32:22,386 iteration 1267 : loss : 0.042907, loss_ce: 0.016134
2022-01-21 18:32:23,678 iteration 1268 : loss : 0.078323, loss_ce: 0.025158
2022-01-21 18:32:25,076 iteration 1269 : loss : 0.095139, loss_ce: 0.025283
2022-01-21 18:32:26,440 iteration 1270 : loss : 0.047523, loss_ce: 0.021159
2022-01-21 18:32:27,762 iteration 1271 : loss : 0.048428, loss_ce: 0.024334
2022-01-21 18:32:29,009 iteration 1272 : loss : 0.047414, loss_ce: 0.015406
2022-01-21 18:32:30,307 iteration 1273 : loss : 0.042478, loss_ce: 0.015545
2022-01-21 18:32:31,627 iteration 1274 : loss : 0.052720, loss_ce: 0.015095
2022-01-21 18:32:31,627 Training Data Eval:
2022-01-21 18:32:38,156   Average segmentation loss on training set: 0.0360
2022-01-21 18:32:38,156 Validation Data Eval:
2022-01-21 18:32:40,397   Average segmentation loss on validation set: 0.0765
2022-01-21 18:32:41,703 iteration 1275 : loss : 0.049232, loss_ce: 0.017953
 19%|█████▋                        | 75/400 [30:57<2:20:30, 25.94s/it]2022-01-21 18:32:42,976 iteration 1276 : loss : 0.048983, loss_ce: 0.018284
2022-01-21 18:32:44,400 iteration 1277 : loss : 0.070865, loss_ce: 0.032893
2022-01-21 18:32:45,688 iteration 1278 : loss : 0.033150, loss_ce: 0.010976
2022-01-21 18:32:47,108 iteration 1279 : loss : 0.048461, loss_ce: 0.019248
2022-01-21 18:32:48,453 iteration 1280 : loss : 0.071995, loss_ce: 0.036682
2022-01-21 18:32:49,790 iteration 1281 : loss : 0.080568, loss_ce: 0.037922
2022-01-21 18:32:51,054 iteration 1282 : loss : 0.030393, loss_ce: 0.013790
2022-01-21 18:32:52,435 iteration 1283 : loss : 0.080990, loss_ce: 0.032559
2022-01-21 18:32:53,713 iteration 1284 : loss : 0.045898, loss_ce: 0.017398
2022-01-21 18:32:55,103 iteration 1285 : loss : 0.049041, loss_ce: 0.017491
2022-01-21 18:32:56,519 iteration 1286 : loss : 0.135467, loss_ce: 0.041014
2022-01-21 18:32:57,825 iteration 1287 : loss : 0.041800, loss_ce: 0.021291
2022-01-21 18:32:59,109 iteration 1288 : loss : 0.052001, loss_ce: 0.022014
2022-01-21 18:33:00,439 iteration 1289 : loss : 0.048461, loss_ce: 0.020818
2022-01-21 18:33:01,797 iteration 1290 : loss : 0.064724, loss_ce: 0.024870
2022-01-21 18:33:03,168 iteration 1291 : loss : 0.068133, loss_ce: 0.028954
2022-01-21 18:33:04,553 iteration 1292 : loss : 0.045619, loss_ce: 0.018372
 19%|█████▋                        | 76/400 [31:20<2:15:04, 25.01s/it]2022-01-21 18:33:05,948 iteration 1293 : loss : 0.044526, loss_ce: 0.019330
2022-01-21 18:33:07,312 iteration 1294 : loss : 0.057118, loss_ce: 0.021027
2022-01-21 18:33:08,715 iteration 1295 : loss : 0.060563, loss_ce: 0.016117
2022-01-21 18:33:10,072 iteration 1296 : loss : 0.060016, loss_ce: 0.020191
2022-01-21 18:33:11,361 iteration 1297 : loss : 0.046943, loss_ce: 0.023504
2022-01-21 18:33:12,620 iteration 1298 : loss : 0.035267, loss_ce: 0.013563
2022-01-21 18:33:13,951 iteration 1299 : loss : 0.051638, loss_ce: 0.025099
2022-01-21 18:33:15,265 iteration 1300 : loss : 0.070762, loss_ce: 0.021284
2022-01-21 18:33:16,618 iteration 1301 : loss : 0.060948, loss_ce: 0.021258
2022-01-21 18:33:17,915 iteration 1302 : loss : 0.061344, loss_ce: 0.029431
2022-01-21 18:33:19,221 iteration 1303 : loss : 0.048697, loss_ce: 0.021173
2022-01-21 18:33:20,554 iteration 1304 : loss : 0.047754, loss_ce: 0.018991
2022-01-21 18:33:21,873 iteration 1305 : loss : 0.055426, loss_ce: 0.023125
2022-01-21 18:33:23,235 iteration 1306 : loss : 0.084664, loss_ce: 0.028969
2022-01-21 18:33:24,604 iteration 1307 : loss : 0.037289, loss_ce: 0.019419
2022-01-21 18:33:25,941 iteration 1308 : loss : 0.074725, loss_ce: 0.019618
2022-01-21 18:33:27,204 iteration 1309 : loss : 0.043797, loss_ce: 0.015645
 19%|█████▊                        | 77/400 [31:42<2:10:50, 24.31s/it]2022-01-21 18:33:28,641 iteration 1310 : loss : 0.049037, loss_ce: 0.018460
2022-01-21 18:33:29,942 iteration 1311 : loss : 0.058768, loss_ce: 0.025946
2022-01-21 18:33:31,233 iteration 1312 : loss : 0.053602, loss_ce: 0.018896
2022-01-21 18:33:32,526 iteration 1313 : loss : 0.068083, loss_ce: 0.015972
2022-01-21 18:33:33,861 iteration 1314 : loss : 0.056078, loss_ce: 0.029280
2022-01-21 18:33:35,212 iteration 1315 : loss : 0.053518, loss_ce: 0.018651
2022-01-21 18:33:36,653 iteration 1316 : loss : 0.065476, loss_ce: 0.026139
2022-01-21 18:33:37,974 iteration 1317 : loss : 0.066943, loss_ce: 0.036969
2022-01-21 18:33:39,382 iteration 1318 : loss : 0.112067, loss_ce: 0.026479
2022-01-21 18:33:40,751 iteration 1319 : loss : 0.050530, loss_ce: 0.022333
2022-01-21 18:33:42,059 iteration 1320 : loss : 0.035615, loss_ce: 0.015199
2022-01-21 18:33:43,412 iteration 1321 : loss : 0.068404, loss_ce: 0.018984
2022-01-21 18:33:44,681 iteration 1322 : loss : 0.076674, loss_ce: 0.034320
2022-01-21 18:33:45,992 iteration 1323 : loss : 0.059237, loss_ce: 0.019764
2022-01-21 18:33:47,340 iteration 1324 : loss : 0.044950, loss_ce: 0.018781
2022-01-21 18:33:48,731 iteration 1325 : loss : 0.082382, loss_ce: 0.028607
2022-01-21 18:33:49,964 iteration 1326 : loss : 0.041662, loss_ce: 0.015751
 20%|█████▊                        | 78/400 [32:05<2:07:56, 23.84s/it]2022-01-21 18:33:51,295 iteration 1327 : loss : 0.081019, loss_ce: 0.027173
2022-01-21 18:33:52,645 iteration 1328 : loss : 0.054793, loss_ce: 0.025356
2022-01-21 18:33:53,971 iteration 1329 : loss : 0.041047, loss_ce: 0.017941
2022-01-21 18:33:55,263 iteration 1330 : loss : 0.096223, loss_ce: 0.027428
2022-01-21 18:33:56,524 iteration 1331 : loss : 0.051486, loss_ce: 0.024783
2022-01-21 18:33:57,797 iteration 1332 : loss : 0.046706, loss_ce: 0.015646
2022-01-21 18:33:59,101 iteration 1333 : loss : 0.065340, loss_ce: 0.019453
2022-01-21 18:34:00,426 iteration 1334 : loss : 0.044878, loss_ce: 0.016522
2022-01-21 18:34:01,718 iteration 1335 : loss : 0.038777, loss_ce: 0.013284
2022-01-21 18:34:03,014 iteration 1336 : loss : 0.045002, loss_ce: 0.017930
2022-01-21 18:34:04,393 iteration 1337 : loss : 0.056267, loss_ce: 0.024142
2022-01-21 18:34:05,749 iteration 1338 : loss : 0.045460, loss_ce: 0.013616
2022-01-21 18:34:07,100 iteration 1339 : loss : 0.043731, loss_ce: 0.022221
2022-01-21 18:34:08,449 iteration 1340 : loss : 0.054238, loss_ce: 0.023758
2022-01-21 18:34:09,787 iteration 1341 : loss : 0.057554, loss_ce: 0.020374
2022-01-21 18:34:11,105 iteration 1342 : loss : 0.063281, loss_ce: 0.025801
2022-01-21 18:34:12,374 iteration 1343 : loss : 0.042718, loss_ce: 0.015189
 20%|█████▉                        | 79/400 [32:27<2:05:15, 23.41s/it]2022-01-21 18:34:13,737 iteration 1344 : loss : 0.060338, loss_ce: 0.023881
2022-01-21 18:34:15,131 iteration 1345 : loss : 0.058610, loss_ce: 0.022130
2022-01-21 18:34:16,435 iteration 1346 : loss : 0.057866, loss_ce: 0.026334
2022-01-21 18:34:17,823 iteration 1347 : loss : 0.034734, loss_ce: 0.015587
2022-01-21 18:34:19,257 iteration 1348 : loss : 0.073949, loss_ce: 0.025843
2022-01-21 18:34:20,591 iteration 1349 : loss : 0.059845, loss_ce: 0.025544
2022-01-21 18:34:21,918 iteration 1350 : loss : 0.044243, loss_ce: 0.019188
2022-01-21 18:34:23,243 iteration 1351 : loss : 0.044148, loss_ce: 0.020996
2022-01-21 18:34:24,625 iteration 1352 : loss : 0.051280, loss_ce: 0.023686
2022-01-21 18:34:25,982 iteration 1353 : loss : 0.060538, loss_ce: 0.020059
2022-01-21 18:34:27,357 iteration 1354 : loss : 0.049913, loss_ce: 0.016681
2022-01-21 18:34:28,790 iteration 1355 : loss : 0.156533, loss_ce: 0.038257
2022-01-21 18:34:30,145 iteration 1356 : loss : 0.048628, loss_ce: 0.019985
2022-01-21 18:34:31,513 iteration 1357 : loss : 0.041420, loss_ce: 0.017856
2022-01-21 18:34:32,897 iteration 1358 : loss : 0.061411, loss_ce: 0.021334
2022-01-21 18:34:34,228 iteration 1359 : loss : 0.059223, loss_ce: 0.025163
2022-01-21 18:34:34,228 Training Data Eval:
2022-01-21 18:34:40,759   Average segmentation loss on training set: 0.0755
2022-01-21 18:34:40,759 Validation Data Eval:
2022-01-21 18:34:42,994   Average segmentation loss on validation set: 0.1851
2022-01-21 18:34:44,377 iteration 1360 : loss : 0.047885, loss_ce: 0.011392
 20%|██████                        | 80/400 [32:59<2:18:36, 25.99s/it]2022-01-21 18:34:45,846 iteration 1361 : loss : 0.075295, loss_ce: 0.031714
2022-01-21 18:34:47,184 iteration 1362 : loss : 0.046867, loss_ce: 0.014771
2022-01-21 18:34:48,671 iteration 1363 : loss : 0.077112, loss_ce: 0.029719
2022-01-21 18:34:49,879 iteration 1364 : loss : 0.061533, loss_ce: 0.015664
2022-01-21 18:34:51,273 iteration 1365 : loss : 0.054241, loss_ce: 0.023243
2022-01-21 18:34:52,630 iteration 1366 : loss : 0.062960, loss_ce: 0.024565
2022-01-21 18:34:53,952 iteration 1367 : loss : 0.042278, loss_ce: 0.017069
2022-01-21 18:34:55,292 iteration 1368 : loss : 0.071558, loss_ce: 0.041957
2022-01-21 18:34:56,593 iteration 1369 : loss : 0.048861, loss_ce: 0.017230
2022-01-21 18:34:57,965 iteration 1370 : loss : 0.052869, loss_ce: 0.023951
2022-01-21 18:34:59,270 iteration 1371 : loss : 0.039651, loss_ce: 0.014951
2022-01-21 18:35:00,566 iteration 1372 : loss : 0.047957, loss_ce: 0.018104
2022-01-21 18:35:01,851 iteration 1373 : loss : 0.044808, loss_ce: 0.016743
2022-01-21 18:35:03,191 iteration 1374 : loss : 0.053077, loss_ce: 0.016783
2022-01-21 18:35:04,548 iteration 1375 : loss : 0.098169, loss_ce: 0.055303
2022-01-21 18:35:05,886 iteration 1376 : loss : 0.051023, loss_ce: 0.014849
2022-01-21 18:35:07,208 iteration 1377 : loss : 0.032700, loss_ce: 0.012013
 20%|██████                        | 81/400 [33:22<2:13:08, 25.04s/it]2022-01-21 18:35:08,509 iteration 1378 : loss : 0.063987, loss_ce: 0.022446
2022-01-21 18:35:09,882 iteration 1379 : loss : 0.033739, loss_ce: 0.012708
2022-01-21 18:35:11,221 iteration 1380 : loss : 0.048053, loss_ce: 0.019928
2022-01-21 18:35:12,640 iteration 1381 : loss : 0.043640, loss_ce: 0.018412
2022-01-21 18:35:13,894 iteration 1382 : loss : 0.037118, loss_ce: 0.013838
2022-01-21 18:35:15,292 iteration 1383 : loss : 0.047728, loss_ce: 0.016727
2022-01-21 18:35:16,631 iteration 1384 : loss : 0.047446, loss_ce: 0.017269
2022-01-21 18:35:17,899 iteration 1385 : loss : 0.049478, loss_ce: 0.017419
2022-01-21 18:35:19,195 iteration 1386 : loss : 0.051867, loss_ce: 0.020456
2022-01-21 18:35:20,504 iteration 1387 : loss : 0.047342, loss_ce: 0.017164
2022-01-21 18:35:21,830 iteration 1388 : loss : 0.044500, loss_ce: 0.014450
2022-01-21 18:35:23,157 iteration 1389 : loss : 0.074584, loss_ce: 0.032628
2022-01-21 18:35:24,526 iteration 1390 : loss : 0.033707, loss_ce: 0.013788
2022-01-21 18:35:25,920 iteration 1391 : loss : 0.055340, loss_ce: 0.020739
2022-01-21 18:35:27,291 iteration 1392 : loss : 0.046786, loss_ce: 0.025019
2022-01-21 18:35:28,595 iteration 1393 : loss : 0.041239, loss_ce: 0.014897
2022-01-21 18:35:29,980 iteration 1394 : loss : 0.045377, loss_ce: 0.020697
 20%|██████▏                       | 82/400 [33:45<2:09:06, 24.36s/it]2022-01-21 18:35:31,329 iteration 1395 : loss : 0.057065, loss_ce: 0.020784
2022-01-21 18:35:32,636 iteration 1396 : loss : 0.039071, loss_ce: 0.017037
2022-01-21 18:35:34,018 iteration 1397 : loss : 0.057378, loss_ce: 0.019381
2022-01-21 18:35:35,417 iteration 1398 : loss : 0.050577, loss_ce: 0.021122
2022-01-21 18:35:36,671 iteration 1399 : loss : 0.041986, loss_ce: 0.019145
2022-01-21 18:35:37,918 iteration 1400 : loss : 0.042202, loss_ce: 0.013711
2022-01-21 18:35:39,301 iteration 1401 : loss : 0.065988, loss_ce: 0.024276
2022-01-21 18:35:40,649 iteration 1402 : loss : 0.058278, loss_ce: 0.021422
2022-01-21 18:35:41,930 iteration 1403 : loss : 0.046377, loss_ce: 0.017692
2022-01-21 18:35:43,203 iteration 1404 : loss : 0.028392, loss_ce: 0.011982
2022-01-21 18:35:44,527 iteration 1405 : loss : 0.049538, loss_ce: 0.015480
2022-01-21 18:35:45,861 iteration 1406 : loss : 0.054950, loss_ce: 0.021941
2022-01-21 18:35:47,237 iteration 1407 : loss : 0.031902, loss_ce: 0.012165
2022-01-21 18:35:48,562 iteration 1408 : loss : 0.049465, loss_ce: 0.016677
2022-01-21 18:35:49,901 iteration 1409 : loss : 0.063367, loss_ce: 0.022121
2022-01-21 18:35:51,303 iteration 1410 : loss : 0.043001, loss_ce: 0.017165
2022-01-21 18:35:52,607 iteration 1411 : loss : 0.038247, loss_ce: 0.013228
 21%|██████▏                       | 83/400 [34:08<2:05:57, 23.84s/it]2022-01-21 18:35:53,944 iteration 1412 : loss : 0.044743, loss_ce: 0.018766
2022-01-21 18:35:55,336 iteration 1413 : loss : 0.056424, loss_ce: 0.018277
2022-01-21 18:35:56,650 iteration 1414 : loss : 0.053679, loss_ce: 0.018770
2022-01-21 18:35:58,031 iteration 1415 : loss : 0.066195, loss_ce: 0.015368
2022-01-21 18:35:59,343 iteration 1416 : loss : 0.041600, loss_ce: 0.017011
2022-01-21 18:36:00,639 iteration 1417 : loss : 0.047747, loss_ce: 0.014970
2022-01-21 18:36:01,939 iteration 1418 : loss : 0.046422, loss_ce: 0.020973
2022-01-21 18:36:03,209 iteration 1419 : loss : 0.051265, loss_ce: 0.020148
2022-01-21 18:36:04,580 iteration 1420 : loss : 0.056474, loss_ce: 0.025682
2022-01-21 18:36:05,987 iteration 1421 : loss : 0.066015, loss_ce: 0.027428
2022-01-21 18:36:07,347 iteration 1422 : loss : 0.044027, loss_ce: 0.015497
2022-01-21 18:36:08,616 iteration 1423 : loss : 0.048529, loss_ce: 0.020433
2022-01-21 18:36:09,971 iteration 1424 : loss : 0.039319, loss_ce: 0.016757
2022-01-21 18:36:11,320 iteration 1425 : loss : 0.034250, loss_ce: 0.014175
2022-01-21 18:36:12,603 iteration 1426 : loss : 0.050145, loss_ce: 0.022881
2022-01-21 18:36:13,923 iteration 1427 : loss : 0.055518, loss_ce: 0.021173
2022-01-21 18:36:15,154 iteration 1428 : loss : 0.056408, loss_ce: 0.022866
 21%|██████▎                       | 84/400 [34:30<2:03:31, 23.45s/it]2022-01-21 18:36:16,589 iteration 1429 : loss : 0.048081, loss_ce: 0.022912
2022-01-21 18:36:17,874 iteration 1430 : loss : 0.131074, loss_ce: 0.034171
2022-01-21 18:36:19,195 iteration 1431 : loss : 0.066096, loss_ce: 0.036388
2022-01-21 18:36:20,540 iteration 1432 : loss : 0.056036, loss_ce: 0.026108
2022-01-21 18:36:21,918 iteration 1433 : loss : 0.072081, loss_ce: 0.027002
2022-01-21 18:36:23,222 iteration 1434 : loss : 0.053419, loss_ce: 0.024068
2022-01-21 18:36:24,571 iteration 1435 : loss : 0.047774, loss_ce: 0.020458
2022-01-21 18:36:25,934 iteration 1436 : loss : 0.064486, loss_ce: 0.026280
2022-01-21 18:36:27,306 iteration 1437 : loss : 0.058320, loss_ce: 0.023003
2022-01-21 18:36:28,650 iteration 1438 : loss : 0.037653, loss_ce: 0.018329
2022-01-21 18:36:30,031 iteration 1439 : loss : 0.049696, loss_ce: 0.020170
2022-01-21 18:36:31,399 iteration 1440 : loss : 0.045179, loss_ce: 0.019446
2022-01-21 18:36:32,714 iteration 1441 : loss : 0.039649, loss_ce: 0.018525
2022-01-21 18:36:34,054 iteration 1442 : loss : 0.053625, loss_ce: 0.022259
2022-01-21 18:36:35,414 iteration 1443 : loss : 0.070100, loss_ce: 0.024293
2022-01-21 18:36:36,751 iteration 1444 : loss : 0.077608, loss_ce: 0.021986
2022-01-21 18:36:36,751 Training Data Eval:
2022-01-21 18:36:43,280   Average segmentation loss on training set: 0.0369
2022-01-21 18:36:43,280 Validation Data Eval:
2022-01-21 18:36:45,507   Average segmentation loss on validation set: 0.1060
2022-01-21 18:36:46,835 iteration 1445 : loss : 0.045100, loss_ce: 0.013740
 21%|██████▍                       | 85/400 [35:02<2:16:04, 25.92s/it]2022-01-21 18:36:48,288 iteration 1446 : loss : 0.049434, loss_ce: 0.014879
2022-01-21 18:36:49,608 iteration 1447 : loss : 0.046459, loss_ce: 0.016504
2022-01-21 18:36:50,875 iteration 1448 : loss : 0.051930, loss_ce: 0.029340
2022-01-21 18:36:52,230 iteration 1449 : loss : 0.045672, loss_ce: 0.016267
2022-01-21 18:36:53,657 iteration 1450 : loss : 0.042856, loss_ce: 0.020503
2022-01-21 18:36:55,096 iteration 1451 : loss : 0.045384, loss_ce: 0.018815
2022-01-21 18:36:56,403 iteration 1452 : loss : 0.047350, loss_ce: 0.012282
2022-01-21 18:36:57,709 iteration 1453 : loss : 0.041946, loss_ce: 0.022985
2022-01-21 18:36:59,063 iteration 1454 : loss : 0.069525, loss_ce: 0.023622
2022-01-21 18:37:00,354 iteration 1455 : loss : 0.038369, loss_ce: 0.016102
2022-01-21 18:37:01,768 iteration 1456 : loss : 0.080898, loss_ce: 0.020127
2022-01-21 18:37:03,097 iteration 1457 : loss : 0.049028, loss_ce: 0.022220
2022-01-21 18:37:04,414 iteration 1458 : loss : 0.038917, loss_ce: 0.012775
2022-01-21 18:37:05,701 iteration 1459 : loss : 0.041597, loss_ce: 0.012125
2022-01-21 18:37:07,098 iteration 1460 : loss : 0.079931, loss_ce: 0.033427
2022-01-21 18:37:08,437 iteration 1461 : loss : 0.050086, loss_ce: 0.021877
2022-01-21 18:37:09,822 iteration 1462 : loss : 0.048582, loss_ce: 0.021204
 22%|██████▍                       | 86/400 [35:25<2:11:03, 25.04s/it]2022-01-21 18:37:11,185 iteration 1463 : loss : 0.046105, loss_ce: 0.020127
2022-01-21 18:37:12,487 iteration 1464 : loss : 0.039429, loss_ce: 0.016757
2022-01-21 18:37:13,851 iteration 1465 : loss : 0.066785, loss_ce: 0.021304
2022-01-21 18:37:15,217 iteration 1466 : loss : 0.045314, loss_ce: 0.020260
2022-01-21 18:37:16,556 iteration 1467 : loss : 0.039593, loss_ce: 0.016880
2022-01-21 18:37:17,867 iteration 1468 : loss : 0.040920, loss_ce: 0.020854
2022-01-21 18:37:19,195 iteration 1469 : loss : 0.044592, loss_ce: 0.015135
2022-01-21 18:37:20,561 iteration 1470 : loss : 0.091209, loss_ce: 0.028335
2022-01-21 18:37:21,917 iteration 1471 : loss : 0.057733, loss_ce: 0.031933
2022-01-21 18:37:23,147 iteration 1472 : loss : 0.040448, loss_ce: 0.013345
2022-01-21 18:37:24,565 iteration 1473 : loss : 0.056850, loss_ce: 0.024433
2022-01-21 18:37:25,943 iteration 1474 : loss : 0.082986, loss_ce: 0.032933
2022-01-21 18:37:27,270 iteration 1475 : loss : 0.040011, loss_ce: 0.018026
2022-01-21 18:37:28,688 iteration 1476 : loss : 0.064976, loss_ce: 0.021586
2022-01-21 18:37:30,064 iteration 1477 : loss : 0.037101, loss_ce: 0.012832
2022-01-21 18:37:31,470 iteration 1478 : loss : 0.056210, loss_ce: 0.020749
2022-01-21 18:37:32,763 iteration 1479 : loss : 0.039846, loss_ce: 0.014666
 22%|██████▌                       | 87/400 [35:48<2:07:20, 24.41s/it]2022-01-21 18:37:34,142 iteration 1480 : loss : 0.050493, loss_ce: 0.016338
2022-01-21 18:37:35,450 iteration 1481 : loss : 0.037289, loss_ce: 0.015358
2022-01-21 18:37:36,775 iteration 1482 : loss : 0.039095, loss_ce: 0.016256
2022-01-21 18:37:38,184 iteration 1483 : loss : 0.050962, loss_ce: 0.019930
2022-01-21 18:37:39,639 iteration 1484 : loss : 0.081796, loss_ce: 0.026963
2022-01-21 18:37:41,040 iteration 1485 : loss : 0.049987, loss_ce: 0.023579
2022-01-21 18:37:42,354 iteration 1486 : loss : 0.046994, loss_ce: 0.018189
2022-01-21 18:37:43,688 iteration 1487 : loss : 0.054458, loss_ce: 0.024914
2022-01-21 18:37:45,040 iteration 1488 : loss : 0.057825, loss_ce: 0.025810
2022-01-21 18:37:46,400 iteration 1489 : loss : 0.032283, loss_ce: 0.012504
2022-01-21 18:37:47,768 iteration 1490 : loss : 0.043742, loss_ce: 0.018195
2022-01-21 18:37:49,178 iteration 1491 : loss : 0.054068, loss_ce: 0.023231
2022-01-21 18:37:50,474 iteration 1492 : loss : 0.040149, loss_ce: 0.015191
2022-01-21 18:37:51,852 iteration 1493 : loss : 0.064395, loss_ce: 0.022083
2022-01-21 18:37:53,159 iteration 1494 : loss : 0.038892, loss_ce: 0.015602
2022-01-21 18:37:54,471 iteration 1495 : loss : 0.048559, loss_ce: 0.020675
2022-01-21 18:37:55,806 iteration 1496 : loss : 0.072401, loss_ce: 0.020912
 22%|██████▌                       | 88/400 [36:11<2:04:47, 24.00s/it]2022-01-21 18:37:57,132 iteration 1497 : loss : 0.054039, loss_ce: 0.030202
2022-01-21 18:37:58,435 iteration 1498 : loss : 0.038849, loss_ce: 0.011757
2022-01-21 18:37:59,803 iteration 1499 : loss : 0.056536, loss_ce: 0.026861
2022-01-21 18:38:01,065 iteration 1500 : loss : 0.051396, loss_ce: 0.019747
2022-01-21 18:38:02,385 iteration 1501 : loss : 0.060114, loss_ce: 0.017352
2022-01-21 18:38:03,747 iteration 1502 : loss : 0.042763, loss_ce: 0.015825
2022-01-21 18:38:05,061 iteration 1503 : loss : 0.032196, loss_ce: 0.014004
2022-01-21 18:38:06,377 iteration 1504 : loss : 0.043707, loss_ce: 0.013860
2022-01-21 18:38:07,647 iteration 1505 : loss : 0.040635, loss_ce: 0.013862
2022-01-21 18:38:08,968 iteration 1506 : loss : 0.050653, loss_ce: 0.016981
2022-01-21 18:38:10,293 iteration 1507 : loss : 0.059278, loss_ce: 0.019966
2022-01-21 18:38:11,589 iteration 1508 : loss : 0.047118, loss_ce: 0.021613
2022-01-21 18:38:12,907 iteration 1509 : loss : 0.047903, loss_ce: 0.016283
2022-01-21 18:38:14,195 iteration 1510 : loss : 0.031201, loss_ce: 0.012172
2022-01-21 18:38:15,540 iteration 1511 : loss : 0.046028, loss_ce: 0.022330
2022-01-21 18:38:16,827 iteration 1512 : loss : 0.042219, loss_ce: 0.018363
2022-01-21 18:38:18,167 iteration 1513 : loss : 0.053178, loss_ce: 0.026148
 22%|██████▋                       | 89/400 [36:33<2:01:50, 23.51s/it]2022-01-21 18:38:19,513 iteration 1514 : loss : 0.052555, loss_ce: 0.018144
2022-01-21 18:38:20,840 iteration 1515 : loss : 0.047819, loss_ce: 0.018740
2022-01-21 18:38:22,186 iteration 1516 : loss : 0.045755, loss_ce: 0.019364
2022-01-21 18:38:23,507 iteration 1517 : loss : 0.040062, loss_ce: 0.020065
2022-01-21 18:38:24,862 iteration 1518 : loss : 0.035650, loss_ce: 0.010413
2022-01-21 18:38:26,168 iteration 1519 : loss : 0.049600, loss_ce: 0.020574
2022-01-21 18:38:27,467 iteration 1520 : loss : 0.058653, loss_ce: 0.020918
2022-01-21 18:38:28,769 iteration 1521 : loss : 0.038777, loss_ce: 0.013358
2022-01-21 18:38:30,197 iteration 1522 : loss : 0.037812, loss_ce: 0.013412
2022-01-21 18:38:31,471 iteration 1523 : loss : 0.041285, loss_ce: 0.019660
2022-01-21 18:38:32,825 iteration 1524 : loss : 0.056922, loss_ce: 0.022634
2022-01-21 18:38:34,126 iteration 1525 : loss : 0.034975, loss_ce: 0.014340
2022-01-21 18:38:35,512 iteration 1526 : loss : 0.042929, loss_ce: 0.017705
2022-01-21 18:38:36,902 iteration 1527 : loss : 0.048572, loss_ce: 0.023336
2022-01-21 18:38:38,272 iteration 1528 : loss : 0.043449, loss_ce: 0.015624
2022-01-21 18:38:39,567 iteration 1529 : loss : 0.053851, loss_ce: 0.020779
2022-01-21 18:38:39,568 Training Data Eval:
2022-01-21 18:38:46,104   Average segmentation loss on training set: 0.0316
2022-01-21 18:38:46,104 Validation Data Eval:
2022-01-21 18:38:48,339   Average segmentation loss on validation set: 0.0656
2022-01-21 18:38:52,474 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:38:53,699 iteration 1530 : loss : 0.053763, loss_ce: 0.026468
 22%|██████▊                       | 90/400 [37:09<2:20:06, 27.12s/it]2022-01-21 18:38:55,084 iteration 1531 : loss : 0.050056, loss_ce: 0.020086
2022-01-21 18:38:56,354 iteration 1532 : loss : 0.044127, loss_ce: 0.019053
2022-01-21 18:38:57,538 iteration 1533 : loss : 0.034502, loss_ce: 0.016616
2022-01-21 18:38:58,851 iteration 1534 : loss : 0.095394, loss_ce: 0.034721
2022-01-21 18:39:00,145 iteration 1535 : loss : 0.039127, loss_ce: 0.015208
2022-01-21 18:39:01,441 iteration 1536 : loss : 0.059918, loss_ce: 0.030235
2022-01-21 18:39:02,731 iteration 1537 : loss : 0.049604, loss_ce: 0.014496
2022-01-21 18:39:04,003 iteration 1538 : loss : 0.122656, loss_ce: 0.021067
2022-01-21 18:39:05,322 iteration 1539 : loss : 0.044699, loss_ce: 0.017165
2022-01-21 18:39:06,651 iteration 1540 : loss : 0.067309, loss_ce: 0.030681
2022-01-21 18:39:07,891 iteration 1541 : loss : 0.044160, loss_ce: 0.014403
2022-01-21 18:39:09,221 iteration 1542 : loss : 0.072694, loss_ce: 0.030954
2022-01-21 18:39:10,527 iteration 1543 : loss : 0.052772, loss_ce: 0.015113
2022-01-21 18:39:11,789 iteration 1544 : loss : 0.056916, loss_ce: 0.019945
2022-01-21 18:39:13,109 iteration 1545 : loss : 0.053002, loss_ce: 0.019994
2022-01-21 18:39:14,414 iteration 1546 : loss : 0.045067, loss_ce: 0.018605
2022-01-21 18:39:15,720 iteration 1547 : loss : 0.056308, loss_ce: 0.019931
 23%|██████▊                       | 91/400 [37:31<2:11:46, 25.59s/it]2022-01-21 18:39:17,080 iteration 1548 : loss : 0.036448, loss_ce: 0.013761
2022-01-21 18:39:18,347 iteration 1549 : loss : 0.041921, loss_ce: 0.019126
2022-01-21 18:39:19,764 iteration 1550 : loss : 0.055990, loss_ce: 0.023833
2022-01-21 18:39:21,084 iteration 1551 : loss : 0.056318, loss_ce: 0.024333
2022-01-21 18:39:22,410 iteration 1552 : loss : 0.044061, loss_ce: 0.018458
2022-01-21 18:39:23,652 iteration 1553 : loss : 0.030528, loss_ce: 0.015822
2022-01-21 18:39:24,930 iteration 1554 : loss : 0.057384, loss_ce: 0.021928
2022-01-21 18:39:26,308 iteration 1555 : loss : 0.048677, loss_ce: 0.016446
2022-01-21 18:39:27,756 iteration 1556 : loss : 0.050656, loss_ce: 0.017830
2022-01-21 18:39:29,148 iteration 1557 : loss : 0.071946, loss_ce: 0.016128
2022-01-21 18:39:30,480 iteration 1558 : loss : 0.044666, loss_ce: 0.012597
2022-01-21 18:39:31,914 iteration 1559 : loss : 0.046205, loss_ce: 0.019616
2022-01-21 18:39:33,222 iteration 1560 : loss : 0.041529, loss_ce: 0.012174
2022-01-21 18:39:34,534 iteration 1561 : loss : 0.078369, loss_ce: 0.029753
2022-01-21 18:39:35,868 iteration 1562 : loss : 0.059528, loss_ce: 0.028052
2022-01-21 18:39:37,186 iteration 1563 : loss : 0.067173, loss_ce: 0.036354
2022-01-21 18:39:38,519 iteration 1564 : loss : 0.053201, loss_ce: 0.018904
 23%|██████▉                       | 92/400 [37:54<2:07:03, 24.75s/it]2022-01-21 18:39:39,917 iteration 1565 : loss : 0.038713, loss_ce: 0.014647
2022-01-21 18:39:41,225 iteration 1566 : loss : 0.073209, loss_ce: 0.033947
2022-01-21 18:39:42,587 iteration 1567 : loss : 0.089984, loss_ce: 0.023650
2022-01-21 18:39:44,019 iteration 1568 : loss : 0.047603, loss_ce: 0.020983
2022-01-21 18:39:45,328 iteration 1569 : loss : 0.063185, loss_ce: 0.026841
2022-01-21 18:39:46,670 iteration 1570 : loss : 0.039886, loss_ce: 0.016327
2022-01-21 18:39:47,981 iteration 1571 : loss : 0.047359, loss_ce: 0.019395
2022-01-21 18:39:49,305 iteration 1572 : loss : 0.052320, loss_ce: 0.025682
2022-01-21 18:39:50,699 iteration 1573 : loss : 0.081111, loss_ce: 0.025748
2022-01-21 18:39:52,034 iteration 1574 : loss : 0.038120, loss_ce: 0.017179
2022-01-21 18:39:53,388 iteration 1575 : loss : 0.058703, loss_ce: 0.029387
2022-01-21 18:39:54,697 iteration 1576 : loss : 0.058518, loss_ce: 0.019529
2022-01-21 18:39:55,979 iteration 1577 : loss : 0.104148, loss_ce: 0.037339
2022-01-21 18:39:57,211 iteration 1578 : loss : 0.037503, loss_ce: 0.013978
2022-01-21 18:39:58,521 iteration 1579 : loss : 0.038743, loss_ce: 0.014527
2022-01-21 18:39:59,866 iteration 1580 : loss : 0.045706, loss_ce: 0.016386
2022-01-21 18:40:01,214 iteration 1581 : loss : 0.039034, loss_ce: 0.016730
 23%|██████▉                       | 93/400 [38:16<2:03:29, 24.14s/it]2022-01-21 18:40:02,624 iteration 1582 : loss : 0.037709, loss_ce: 0.019843
2022-01-21 18:40:03,959 iteration 1583 : loss : 0.062944, loss_ce: 0.018044
2022-01-21 18:40:05,240 iteration 1584 : loss : 0.039611, loss_ce: 0.014123
2022-01-21 18:40:06,554 iteration 1585 : loss : 0.040244, loss_ce: 0.018357
2022-01-21 18:40:07,802 iteration 1586 : loss : 0.036971, loss_ce: 0.016026
2022-01-21 18:40:09,098 iteration 1587 : loss : 0.044736, loss_ce: 0.014776
2022-01-21 18:40:10,401 iteration 1588 : loss : 0.037756, loss_ce: 0.011513
2022-01-21 18:40:11,722 iteration 1589 : loss : 0.037873, loss_ce: 0.015732
2022-01-21 18:40:13,130 iteration 1590 : loss : 0.046187, loss_ce: 0.016772
2022-01-21 18:40:14,437 iteration 1591 : loss : 0.048800, loss_ce: 0.023114
2022-01-21 18:40:15,678 iteration 1592 : loss : 0.040635, loss_ce: 0.019452
2022-01-21 18:40:17,010 iteration 1593 : loss : 0.062289, loss_ce: 0.020874
2022-01-21 18:40:18,321 iteration 1594 : loss : 0.053736, loss_ce: 0.018604
2022-01-21 18:40:19,593 iteration 1595 : loss : 0.042320, loss_ce: 0.020721
2022-01-21 18:40:20,834 iteration 1596 : loss : 0.046130, loss_ce: 0.016048
2022-01-21 18:40:22,172 iteration 1597 : loss : 0.082001, loss_ce: 0.019118
2022-01-21 18:40:23,524 iteration 1598 : loss : 0.051366, loss_ce: 0.019474
 24%|███████                       | 94/400 [38:39<2:00:17, 23.59s/it]2022-01-21 18:40:24,928 iteration 1599 : loss : 0.046381, loss_ce: 0.019402
2022-01-21 18:40:26,236 iteration 1600 : loss : 0.039391, loss_ce: 0.019205
2022-01-21 18:40:27,599 iteration 1601 : loss : 0.057546, loss_ce: 0.021616
2022-01-21 18:40:28,935 iteration 1602 : loss : 0.057641, loss_ce: 0.018165
2022-01-21 18:40:30,247 iteration 1603 : loss : 0.042142, loss_ce: 0.017255
2022-01-21 18:40:31,551 iteration 1604 : loss : 0.059639, loss_ce: 0.017763
2022-01-21 18:40:32,856 iteration 1605 : loss : 0.043890, loss_ce: 0.016516
2022-01-21 18:40:34,187 iteration 1606 : loss : 0.042360, loss_ce: 0.017529
2022-01-21 18:40:35,503 iteration 1607 : loss : 0.066120, loss_ce: 0.027251
2022-01-21 18:40:36,907 iteration 1608 : loss : 0.068558, loss_ce: 0.028666
2022-01-21 18:40:38,215 iteration 1609 : loss : 0.041652, loss_ce: 0.020050
2022-01-21 18:40:39,635 iteration 1610 : loss : 0.058524, loss_ce: 0.019724
2022-01-21 18:40:41,042 iteration 1611 : loss : 0.052397, loss_ce: 0.023517
2022-01-21 18:40:42,466 iteration 1612 : loss : 0.037758, loss_ce: 0.014776
2022-01-21 18:40:43,805 iteration 1613 : loss : 0.067416, loss_ce: 0.025305
2022-01-21 18:40:45,195 iteration 1614 : loss : 0.047023, loss_ce: 0.020231
2022-01-21 18:40:45,195 Training Data Eval:
2022-01-21 18:40:51,711   Average segmentation loss on training set: 0.0413
2022-01-21 18:40:51,711 Validation Data Eval:
2022-01-21 18:40:53,945   Average segmentation loss on validation set: 0.0795
2022-01-21 18:40:55,317 iteration 1615 : loss : 0.061161, loss_ce: 0.022729
 24%|███████▏                      | 95/400 [39:10<2:12:25, 26.05s/it]2022-01-21 18:40:56,688 iteration 1616 : loss : 0.055603, loss_ce: 0.021702
2022-01-21 18:40:58,001 iteration 1617 : loss : 0.041123, loss_ce: 0.020565
2022-01-21 18:40:59,272 iteration 1618 : loss : 0.048849, loss_ce: 0.022085
2022-01-21 18:41:00,590 iteration 1619 : loss : 0.052381, loss_ce: 0.032102
2022-01-21 18:41:02,030 iteration 1620 : loss : 0.038669, loss_ce: 0.013294
2022-01-21 18:41:03,477 iteration 1621 : loss : 0.045324, loss_ce: 0.015994
2022-01-21 18:41:04,804 iteration 1622 : loss : 0.046045, loss_ce: 0.017833
2022-01-21 18:41:06,086 iteration 1623 : loss : 0.031175, loss_ce: 0.010876
2022-01-21 18:41:07,429 iteration 1624 : loss : 0.037429, loss_ce: 0.013837
2022-01-21 18:41:08,691 iteration 1625 : loss : 0.036424, loss_ce: 0.013597
2022-01-21 18:41:09,994 iteration 1626 : loss : 0.043756, loss_ce: 0.017379
2022-01-21 18:41:11,443 iteration 1627 : loss : 0.055923, loss_ce: 0.021860
2022-01-21 18:41:12,865 iteration 1628 : loss : 0.041414, loss_ce: 0.016133
2022-01-21 18:41:14,168 iteration 1629 : loss : 0.032437, loss_ce: 0.011553
2022-01-21 18:41:15,451 iteration 1630 : loss : 0.035869, loss_ce: 0.015036
2022-01-21 18:41:16,738 iteration 1631 : loss : 0.056355, loss_ce: 0.015197
2022-01-21 18:41:18,035 iteration 1632 : loss : 0.036953, loss_ce: 0.015813
 24%|███████▏                      | 96/400 [39:33<2:06:54, 25.05s/it]2022-01-21 18:41:19,402 iteration 1633 : loss : 0.040141, loss_ce: 0.014425
2022-01-21 18:41:20,751 iteration 1634 : loss : 0.045300, loss_ce: 0.016798
2022-01-21 18:41:22,051 iteration 1635 : loss : 0.051226, loss_ce: 0.017040
2022-01-21 18:41:23,304 iteration 1636 : loss : 0.040751, loss_ce: 0.020210
2022-01-21 18:41:24,645 iteration 1637 : loss : 0.035197, loss_ce: 0.011724
2022-01-21 18:41:25,964 iteration 1638 : loss : 0.039125, loss_ce: 0.017879
2022-01-21 18:41:27,346 iteration 1639 : loss : 0.047796, loss_ce: 0.022603
2022-01-21 18:41:28,639 iteration 1640 : loss : 0.057422, loss_ce: 0.017407
2022-01-21 18:41:30,039 iteration 1641 : loss : 0.067637, loss_ce: 0.027689
2022-01-21 18:41:31,321 iteration 1642 : loss : 0.030776, loss_ce: 0.011272
2022-01-21 18:41:32,580 iteration 1643 : loss : 0.036926, loss_ce: 0.012641
2022-01-21 18:41:33,959 iteration 1644 : loss : 0.042096, loss_ce: 0.017253
2022-01-21 18:41:35,375 iteration 1645 : loss : 0.044387, loss_ce: 0.020712
2022-01-21 18:41:36,668 iteration 1646 : loss : 0.046389, loss_ce: 0.017095
2022-01-21 18:41:37,971 iteration 1647 : loss : 0.064493, loss_ce: 0.020840
2022-01-21 18:41:39,215 iteration 1648 : loss : 0.032541, loss_ce: 0.014364
2022-01-21 18:41:40,477 iteration 1649 : loss : 0.049616, loss_ce: 0.022412
 24%|███████▎                      | 97/400 [39:56<2:02:33, 24.27s/it]2022-01-21 18:41:41,954 iteration 1650 : loss : 0.063974, loss_ce: 0.034784
2022-01-21 18:41:43,264 iteration 1651 : loss : 0.048693, loss_ce: 0.014108
2022-01-21 18:41:44,603 iteration 1652 : loss : 0.055993, loss_ce: 0.016270
2022-01-21 18:41:45,906 iteration 1653 : loss : 0.040856, loss_ce: 0.012975
2022-01-21 18:41:47,217 iteration 1654 : loss : 0.042589, loss_ce: 0.014652
2022-01-21 18:41:48,496 iteration 1655 : loss : 0.040132, loss_ce: 0.014728
2022-01-21 18:41:49,863 iteration 1656 : loss : 0.052404, loss_ce: 0.020167
2022-01-21 18:41:51,177 iteration 1657 : loss : 0.050012, loss_ce: 0.020541
2022-01-21 18:41:52,550 iteration 1658 : loss : 0.061716, loss_ce: 0.036121
2022-01-21 18:41:53,955 iteration 1659 : loss : 0.055459, loss_ce: 0.022990
2022-01-21 18:41:55,293 iteration 1660 : loss : 0.031843, loss_ce: 0.011425
2022-01-21 18:41:56,563 iteration 1661 : loss : 0.042050, loss_ce: 0.013711
2022-01-21 18:41:57,928 iteration 1662 : loss : 0.049608, loss_ce: 0.017046
2022-01-21 18:41:59,315 iteration 1663 : loss : 0.035178, loss_ce: 0.015039
2022-01-21 18:42:00,644 iteration 1664 : loss : 0.054721, loss_ce: 0.019717
2022-01-21 18:42:01,953 iteration 1665 : loss : 0.042907, loss_ce: 0.018150
2022-01-21 18:42:03,291 iteration 1666 : loss : 0.046808, loss_ce: 0.013520
 24%|███████▎                      | 98/400 [40:18<1:59:56, 23.83s/it]2022-01-21 18:42:04,606 iteration 1667 : loss : 0.031876, loss_ce: 0.015517
2022-01-21 18:42:06,007 iteration 1668 : loss : 0.054679, loss_ce: 0.016562
2022-01-21 18:42:07,366 iteration 1669 : loss : 0.049285, loss_ce: 0.018097
2022-01-21 18:42:08,621 iteration 1670 : loss : 0.024819, loss_ce: 0.008583
2022-01-21 18:42:09,899 iteration 1671 : loss : 0.046889, loss_ce: 0.023749
2022-01-21 18:42:11,286 iteration 1672 : loss : 0.056911, loss_ce: 0.025917
2022-01-21 18:42:12,652 iteration 1673 : loss : 0.051152, loss_ce: 0.018070
2022-01-21 18:42:14,077 iteration 1674 : loss : 0.067342, loss_ce: 0.027860
2022-01-21 18:42:15,381 iteration 1675 : loss : 0.048562, loss_ce: 0.014656
2022-01-21 18:42:16,765 iteration 1676 : loss : 0.041439, loss_ce: 0.018286
2022-01-21 18:42:18,114 iteration 1677 : loss : 0.082425, loss_ce: 0.031781
2022-01-21 18:42:19,491 iteration 1678 : loss : 0.038468, loss_ce: 0.018291
2022-01-21 18:42:20,803 iteration 1679 : loss : 0.071919, loss_ce: 0.034092
2022-01-21 18:42:22,165 iteration 1680 : loss : 0.049084, loss_ce: 0.022171
2022-01-21 18:42:23,482 iteration 1681 : loss : 0.052648, loss_ce: 0.022562
2022-01-21 18:42:24,811 iteration 1682 : loss : 0.042489, loss_ce: 0.018843
2022-01-21 18:42:26,105 iteration 1683 : loss : 0.051644, loss_ce: 0.022763
 25%|███████▍                      | 99/400 [40:41<1:58:01, 23.53s/it]2022-01-21 18:42:27,505 iteration 1684 : loss : 0.049481, loss_ce: 0.017817
2022-01-21 18:42:28,795 iteration 1685 : loss : 0.042235, loss_ce: 0.021220
2022-01-21 18:42:30,052 iteration 1686 : loss : 0.035119, loss_ce: 0.014339
2022-01-21 18:42:31,344 iteration 1687 : loss : 0.038351, loss_ce: 0.015764
2022-01-21 18:42:32,680 iteration 1688 : loss : 0.050200, loss_ce: 0.022011
2022-01-21 18:42:33,965 iteration 1689 : loss : 0.051703, loss_ce: 0.018037
2022-01-21 18:42:35,317 iteration 1690 : loss : 0.055814, loss_ce: 0.024210
2022-01-21 18:42:36,635 iteration 1691 : loss : 0.030183, loss_ce: 0.012149
2022-01-21 18:42:38,005 iteration 1692 : loss : 0.060434, loss_ce: 0.023029
2022-01-21 18:42:39,402 iteration 1693 : loss : 0.047973, loss_ce: 0.023018
2022-01-21 18:42:40,762 iteration 1694 : loss : 0.036859, loss_ce: 0.014475
2022-01-21 18:42:42,014 iteration 1695 : loss : 0.035779, loss_ce: 0.011315
2022-01-21 18:42:43,322 iteration 1696 : loss : 0.053136, loss_ce: 0.019818
2022-01-21 18:42:44,689 iteration 1697 : loss : 0.058783, loss_ce: 0.019179
2022-01-21 18:42:45,999 iteration 1698 : loss : 0.032100, loss_ce: 0.009390
2022-01-21 18:42:47,222 iteration 1699 : loss : 0.038538, loss_ce: 0.017969
2022-01-21 18:42:47,223 Training Data Eval:
2022-01-21 18:42:53,755   Average segmentation loss on training set: 0.0313
2022-01-21 18:42:53,756 Validation Data Eval:
2022-01-21 18:42:55,994   Average segmentation loss on validation set: 0.0768
2022-01-21 18:42:57,335 iteration 1700 : loss : 0.048845, loss_ce: 0.014962
 25%|███████▎                     | 100/400 [41:12<2:09:10, 25.84s/it]2022-01-21 18:42:58,745 iteration 1701 : loss : 0.044752, loss_ce: 0.018207
2022-01-21 18:43:00,082 iteration 1702 : loss : 0.051892, loss_ce: 0.024048
2022-01-21 18:43:01,356 iteration 1703 : loss : 0.033537, loss_ce: 0.013772
2022-01-21 18:43:02,753 iteration 1704 : loss : 0.039519, loss_ce: 0.014752
2022-01-21 18:43:04,085 iteration 1705 : loss : 0.041717, loss_ce: 0.019059
2022-01-21 18:43:05,428 iteration 1706 : loss : 0.039917, loss_ce: 0.018067
2022-01-21 18:43:06,750 iteration 1707 : loss : 0.038701, loss_ce: 0.015901
2022-01-21 18:43:08,105 iteration 1708 : loss : 0.031008, loss_ce: 0.010999
2022-01-21 18:43:09,367 iteration 1709 : loss : 0.039313, loss_ce: 0.016443
2022-01-21 18:43:10,612 iteration 1710 : loss : 0.028848, loss_ce: 0.012779
2022-01-21 18:43:11,941 iteration 1711 : loss : 0.036302, loss_ce: 0.012473
2022-01-21 18:43:13,216 iteration 1712 : loss : 0.045230, loss_ce: 0.015416
2022-01-21 18:43:14,482 iteration 1713 : loss : 0.032631, loss_ce: 0.011728
2022-01-21 18:43:15,886 iteration 1714 : loss : 0.060186, loss_ce: 0.018591
2022-01-21 18:43:17,246 iteration 1715 : loss : 0.070321, loss_ce: 0.019308
2022-01-21 18:43:18,652 iteration 1716 : loss : 0.055736, loss_ce: 0.019379
2022-01-21 18:43:19,977 iteration 1717 : loss : 0.038267, loss_ce: 0.015800
 25%|███████▎                     | 101/400 [41:35<2:03:59, 24.88s/it]2022-01-21 18:43:21,313 iteration 1718 : loss : 0.042702, loss_ce: 0.015026
2022-01-21 18:43:22,660 iteration 1719 : loss : 0.048171, loss_ce: 0.019176
2022-01-21 18:43:23,893 iteration 1720 : loss : 0.039023, loss_ce: 0.012705
2022-01-21 18:43:25,210 iteration 1721 : loss : 0.046044, loss_ce: 0.019200
2022-01-21 18:43:26,588 iteration 1722 : loss : 0.031531, loss_ce: 0.010423
2022-01-21 18:43:27,912 iteration 1723 : loss : 0.052590, loss_ce: 0.021664
2022-01-21 18:43:29,276 iteration 1724 : loss : 0.033338, loss_ce: 0.010964
2022-01-21 18:43:30,722 iteration 1725 : loss : 0.087128, loss_ce: 0.031709
2022-01-21 18:43:32,127 iteration 1726 : loss : 0.057015, loss_ce: 0.015667
2022-01-21 18:43:33,465 iteration 1727 : loss : 0.036966, loss_ce: 0.017648
2022-01-21 18:43:34,781 iteration 1728 : loss : 0.037885, loss_ce: 0.012395
2022-01-21 18:43:36,100 iteration 1729 : loss : 0.034084, loss_ce: 0.015569
2022-01-21 18:43:37,446 iteration 1730 : loss : 0.036450, loss_ce: 0.016527
2022-01-21 18:43:38,840 iteration 1731 : loss : 0.040056, loss_ce: 0.015989
2022-01-21 18:43:40,175 iteration 1732 : loss : 0.029140, loss_ce: 0.014120
2022-01-21 18:43:41,584 iteration 1733 : loss : 0.046384, loss_ce: 0.019616
2022-01-21 18:43:42,871 iteration 1734 : loss : 0.032081, loss_ce: 0.011553
 26%|███████▍                     | 102/400 [41:58<2:00:36, 24.28s/it]2022-01-21 18:43:44,202 iteration 1735 : loss : 0.040469, loss_ce: 0.014876
2022-01-21 18:43:45,514 iteration 1736 : loss : 0.030612, loss_ce: 0.012088
2022-01-21 18:43:46,846 iteration 1737 : loss : 0.031476, loss_ce: 0.013323
2022-01-21 18:43:48,144 iteration 1738 : loss : 0.038479, loss_ce: 0.013363
2022-01-21 18:43:49,567 iteration 1739 : loss : 0.037971, loss_ce: 0.016843
2022-01-21 18:43:50,941 iteration 1740 : loss : 0.059886, loss_ce: 0.023238
2022-01-21 18:43:52,264 iteration 1741 : loss : 0.031241, loss_ce: 0.012244
2022-01-21 18:43:53,696 iteration 1742 : loss : 0.056183, loss_ce: 0.023278
2022-01-21 18:43:55,012 iteration 1743 : loss : 0.041224, loss_ce: 0.011573
2022-01-21 18:43:56,370 iteration 1744 : loss : 0.035389, loss_ce: 0.013974
2022-01-21 18:43:57,840 iteration 1745 : loss : 0.042176, loss_ce: 0.020802
2022-01-21 18:43:59,163 iteration 1746 : loss : 0.031931, loss_ce: 0.013841
2022-01-21 18:44:00,471 iteration 1747 : loss : 0.027072, loss_ce: 0.010924
2022-01-21 18:44:01,809 iteration 1748 : loss : 0.032132, loss_ce: 0.012170
2022-01-21 18:44:03,140 iteration 1749 : loss : 0.047243, loss_ce: 0.016291
2022-01-21 18:44:04,416 iteration 1750 : loss : 0.033483, loss_ce: 0.013961
2022-01-21 18:44:05,831 iteration 1751 : loss : 0.043526, loss_ce: 0.016552
 26%|███████▍                     | 103/400 [42:21<1:58:13, 23.88s/it]2022-01-21 18:44:07,174 iteration 1752 : loss : 0.027775, loss_ce: 0.010319
2022-01-21 18:44:08,462 iteration 1753 : loss : 0.053123, loss_ce: 0.025195
2022-01-21 18:44:09,770 iteration 1754 : loss : 0.032024, loss_ce: 0.012234
2022-01-21 18:44:11,095 iteration 1755 : loss : 0.031995, loss_ce: 0.013648
2022-01-21 18:44:12,437 iteration 1756 : loss : 0.040862, loss_ce: 0.019082
2022-01-21 18:44:13,827 iteration 1757 : loss : 0.045086, loss_ce: 0.020897
2022-01-21 18:44:15,196 iteration 1758 : loss : 0.080057, loss_ce: 0.030735
2022-01-21 18:44:16,454 iteration 1759 : loss : 0.063858, loss_ce: 0.017893
2022-01-21 18:44:17,768 iteration 1760 : loss : 0.047944, loss_ce: 0.021165
2022-01-21 18:44:19,054 iteration 1761 : loss : 0.025035, loss_ce: 0.009767
2022-01-21 18:44:20,372 iteration 1762 : loss : 0.042924, loss_ce: 0.016656
2022-01-21 18:44:21,621 iteration 1763 : loss : 0.044857, loss_ce: 0.020638
2022-01-21 18:44:23,038 iteration 1764 : loss : 0.027886, loss_ce: 0.007963
2022-01-21 18:44:24,378 iteration 1765 : loss : 0.042022, loss_ce: 0.014461
2022-01-21 18:44:25,766 iteration 1766 : loss : 0.045757, loss_ce: 0.018080
2022-01-21 18:44:27,197 iteration 1767 : loss : 0.032213, loss_ce: 0.011724
2022-01-21 18:44:28,518 iteration 1768 : loss : 0.054660, loss_ce: 0.022224
 26%|███████▌                     | 104/400 [42:44<1:56:04, 23.53s/it]2022-01-21 18:44:29,932 iteration 1769 : loss : 0.042493, loss_ce: 0.017721
2022-01-21 18:44:31,248 iteration 1770 : loss : 0.034741, loss_ce: 0.010846
2022-01-21 18:44:32,536 iteration 1771 : loss : 0.026818, loss_ce: 0.009123
2022-01-21 18:44:33,919 iteration 1772 : loss : 0.054215, loss_ce: 0.028598
2022-01-21 18:44:35,275 iteration 1773 : loss : 0.051330, loss_ce: 0.020932
2022-01-21 18:44:36,572 iteration 1774 : loss : 0.038466, loss_ce: 0.013178
2022-01-21 18:44:37,880 iteration 1775 : loss : 0.036762, loss_ce: 0.013257
2022-01-21 18:44:39,176 iteration 1776 : loss : 0.055056, loss_ce: 0.021941
2022-01-21 18:44:40,454 iteration 1777 : loss : 0.032707, loss_ce: 0.013742
2022-01-21 18:44:41,825 iteration 1778 : loss : 0.043594, loss_ce: 0.021246
2022-01-21 18:44:43,159 iteration 1779 : loss : 0.031363, loss_ce: 0.013839
2022-01-21 18:44:44,513 iteration 1780 : loss : 0.052953, loss_ce: 0.015734
2022-01-21 18:44:45,867 iteration 1781 : loss : 0.042556, loss_ce: 0.014175
2022-01-21 18:44:47,127 iteration 1782 : loss : 0.064409, loss_ce: 0.016911
2022-01-21 18:44:48,418 iteration 1783 : loss : 0.040476, loss_ce: 0.016305
2022-01-21 18:44:49,771 iteration 1784 : loss : 0.045069, loss_ce: 0.023881
2022-01-21 18:44:49,771 Training Data Eval:
2022-01-21 18:44:56,310   Average segmentation loss on training set: 0.0334
2022-01-21 18:44:56,310 Validation Data Eval:
2022-01-21 18:44:58,543   Average segmentation loss on validation set: 0.1450
2022-01-21 18:44:59,869 iteration 1785 : loss : 0.033564, loss_ce: 0.015214
 26%|███████▌                     | 105/400 [43:15<2:07:12, 25.87s/it]2022-01-21 18:45:01,280 iteration 1786 : loss : 0.039426, loss_ce: 0.011667
2022-01-21 18:45:02,560 iteration 1787 : loss : 0.040858, loss_ce: 0.009152
2022-01-21 18:45:03,896 iteration 1788 : loss : 0.040376, loss_ce: 0.015816
2022-01-21 18:45:05,238 iteration 1789 : loss : 0.040118, loss_ce: 0.020209
2022-01-21 18:45:06,707 iteration 1790 : loss : 0.036432, loss_ce: 0.012938
2022-01-21 18:45:08,056 iteration 1791 : loss : 0.031799, loss_ce: 0.013920
2022-01-21 18:45:09,408 iteration 1792 : loss : 0.033617, loss_ce: 0.012128
2022-01-21 18:45:10,772 iteration 1793 : loss : 0.071766, loss_ce: 0.036070
2022-01-21 18:45:12,095 iteration 1794 : loss : 0.050664, loss_ce: 0.029085
2022-01-21 18:45:13,326 iteration 1795 : loss : 0.034079, loss_ce: 0.013948
2022-01-21 18:45:14,732 iteration 1796 : loss : 0.036384, loss_ce: 0.016387
2022-01-21 18:45:16,014 iteration 1797 : loss : 0.042061, loss_ce: 0.018043
2022-01-21 18:45:17,348 iteration 1798 : loss : 0.046612, loss_ce: 0.016651
2022-01-21 18:45:18,741 iteration 1799 : loss : 0.038201, loss_ce: 0.014756
2022-01-21 18:45:20,016 iteration 1800 : loss : 0.035405, loss_ce: 0.012025
2022-01-21 18:45:21,345 iteration 1801 : loss : 0.059897, loss_ce: 0.019648
2022-01-21 18:45:22,721 iteration 1802 : loss : 0.045658, loss_ce: 0.015637
 26%|███████▋                     | 106/400 [43:38<2:02:19, 24.97s/it]2022-01-21 18:45:24,138 iteration 1803 : loss : 0.045337, loss_ce: 0.017060
2022-01-21 18:45:25,409 iteration 1804 : loss : 0.038351, loss_ce: 0.012793
2022-01-21 18:45:26,859 iteration 1805 : loss : 0.044131, loss_ce: 0.015238
2022-01-21 18:45:28,276 iteration 1806 : loss : 0.055868, loss_ce: 0.027359
2022-01-21 18:45:29,602 iteration 1807 : loss : 0.046849, loss_ce: 0.018485
2022-01-21 18:45:30,974 iteration 1808 : loss : 0.030470, loss_ce: 0.013349
2022-01-21 18:45:32,286 iteration 1809 : loss : 0.038896, loss_ce: 0.018060
2022-01-21 18:45:33,653 iteration 1810 : loss : 0.049925, loss_ce: 0.022714
2022-01-21 18:45:34,968 iteration 1811 : loss : 0.044404, loss_ce: 0.015178
2022-01-21 18:45:36,274 iteration 1812 : loss : 0.043775, loss_ce: 0.014169
2022-01-21 18:45:37,603 iteration 1813 : loss : 0.044951, loss_ce: 0.020123
2022-01-21 18:45:38,913 iteration 1814 : loss : 0.030465, loss_ce: 0.012001
2022-01-21 18:45:40,315 iteration 1815 : loss : 0.054356, loss_ce: 0.019134
2022-01-21 18:45:41,661 iteration 1816 : loss : 0.036138, loss_ce: 0.014927
2022-01-21 18:45:43,068 iteration 1817 : loss : 0.060781, loss_ce: 0.027428
2022-01-21 18:45:44,344 iteration 1818 : loss : 0.029604, loss_ce: 0.009704
2022-01-21 18:45:45,724 iteration 1819 : loss : 0.060069, loss_ce: 0.018504
 27%|███████▊                     | 107/400 [44:01<1:59:02, 24.38s/it]2022-01-21 18:45:46,994 iteration 1820 : loss : 0.031199, loss_ce: 0.012791
2022-01-21 18:45:48,436 iteration 1821 : loss : 0.044761, loss_ce: 0.017183
2022-01-21 18:45:49,816 iteration 1822 : loss : 0.051261, loss_ce: 0.025992
2022-01-21 18:45:51,222 iteration 1823 : loss : 0.060785, loss_ce: 0.028472
2022-01-21 18:45:52,586 iteration 1824 : loss : 0.051482, loss_ce: 0.014539
2022-01-21 18:45:53,879 iteration 1825 : loss : 0.044856, loss_ce: 0.018172
2022-01-21 18:45:55,279 iteration 1826 : loss : 0.042096, loss_ce: 0.013023
2022-01-21 18:45:56,566 iteration 1827 : loss : 0.029071, loss_ce: 0.010118
2022-01-21 18:45:57,910 iteration 1828 : loss : 0.034423, loss_ce: 0.012257
2022-01-21 18:45:59,209 iteration 1829 : loss : 0.048442, loss_ce: 0.019957
2022-01-21 18:46:00,629 iteration 1830 : loss : 0.031331, loss_ce: 0.011030
2022-01-21 18:46:01,974 iteration 1831 : loss : 0.029831, loss_ce: 0.011755
2022-01-21 18:46:03,283 iteration 1832 : loss : 0.033013, loss_ce: 0.013760
2022-01-21 18:46:04,556 iteration 1833 : loss : 0.034235, loss_ce: 0.015865
2022-01-21 18:46:05,878 iteration 1834 : loss : 0.047347, loss_ce: 0.014796
2022-01-21 18:46:07,211 iteration 1835 : loss : 0.033556, loss_ce: 0.012095
2022-01-21 18:46:08,508 iteration 1836 : loss : 0.054192, loss_ce: 0.017544
 27%|███████▊                     | 108/400 [44:24<1:56:18, 23.90s/it]2022-01-21 18:46:09,913 iteration 1837 : loss : 0.034575, loss_ce: 0.012164
2022-01-21 18:46:11,170 iteration 1838 : loss : 0.030082, loss_ce: 0.013170
2022-01-21 18:46:12,456 iteration 1839 : loss : 0.049687, loss_ce: 0.018132
2022-01-21 18:46:13,799 iteration 1840 : loss : 0.033007, loss_ce: 0.014323
2022-01-21 18:46:15,068 iteration 1841 : loss : 0.039705, loss_ce: 0.013696
2022-01-21 18:46:16,377 iteration 1842 : loss : 0.040622, loss_ce: 0.011676
2022-01-21 18:46:17,730 iteration 1843 : loss : 0.032431, loss_ce: 0.015514
2022-01-21 18:46:19,040 iteration 1844 : loss : 0.038460, loss_ce: 0.012877
2022-01-21 18:46:20,341 iteration 1845 : loss : 0.036597, loss_ce: 0.010036
2022-01-21 18:46:21,740 iteration 1846 : loss : 0.034848, loss_ce: 0.014953
2022-01-21 18:46:23,036 iteration 1847 : loss : 0.036462, loss_ce: 0.011031
2022-01-21 18:46:24,352 iteration 1848 : loss : 0.043273, loss_ce: 0.017138
2022-01-21 18:46:25,651 iteration 1849 : loss : 0.051030, loss_ce: 0.020795
2022-01-21 18:46:27,101 iteration 1850 : loss : 0.046351, loss_ce: 0.018157
2022-01-21 18:46:28,432 iteration 1851 : loss : 0.068651, loss_ce: 0.019105
2022-01-21 18:46:29,781 iteration 1852 : loss : 0.046478, loss_ce: 0.018994
2022-01-21 18:46:31,087 iteration 1853 : loss : 0.034732, loss_ce: 0.014743
 27%|███████▉                     | 109/400 [44:46<1:53:59, 23.50s/it]2022-01-21 18:46:32,429 iteration 1854 : loss : 0.035842, loss_ce: 0.013568
2022-01-21 18:46:33,810 iteration 1855 : loss : 0.039802, loss_ce: 0.014732
2022-01-21 18:46:35,200 iteration 1856 : loss : 0.046700, loss_ce: 0.014690
2022-01-21 18:46:36,595 iteration 1857 : loss : 0.027727, loss_ce: 0.010917
2022-01-21 18:46:37,942 iteration 1858 : loss : 0.035407, loss_ce: 0.013706
2022-01-21 18:46:39,294 iteration 1859 : loss : 0.045586, loss_ce: 0.020880
2022-01-21 18:46:40,590 iteration 1860 : loss : 0.034316, loss_ce: 0.011718
2022-01-21 18:46:41,976 iteration 1861 : loss : 0.045819, loss_ce: 0.018940
2022-01-21 18:46:43,257 iteration 1862 : loss : 0.031493, loss_ce: 0.014903
2022-01-21 18:46:44,586 iteration 1863 : loss : 0.067997, loss_ce: 0.037928
2022-01-21 18:46:45,950 iteration 1864 : loss : 0.066015, loss_ce: 0.022768
2022-01-21 18:46:47,187 iteration 1865 : loss : 0.029144, loss_ce: 0.013505
2022-01-21 18:46:48,583 iteration 1866 : loss : 0.026013, loss_ce: 0.013603
2022-01-21 18:46:49,916 iteration 1867 : loss : 0.025701, loss_ce: 0.011662
2022-01-21 18:46:51,209 iteration 1868 : loss : 0.046602, loss_ce: 0.018683
2022-01-21 18:46:52,500 iteration 1869 : loss : 0.076283, loss_ce: 0.028945
2022-01-21 18:46:52,500 Training Data Eval:
2022-01-21 18:46:59,027   Average segmentation loss on training set: 0.0473
2022-01-21 18:46:59,027 Validation Data Eval:
2022-01-21 18:47:01,269   Average segmentation loss on validation set: 0.1015
2022-01-21 18:47:02,635 iteration 1870 : loss : 0.042459, loss_ce: 0.017598
 28%|███████▉                     | 110/400 [45:18<2:05:16, 25.92s/it]2022-01-21 18:47:04,057 iteration 1871 : loss : 0.041232, loss_ce: 0.015619
2022-01-21 18:47:05,492 iteration 1872 : loss : 0.053788, loss_ce: 0.017381
2022-01-21 18:47:06,779 iteration 1873 : loss : 0.036407, loss_ce: 0.013664
2022-01-21 18:47:08,182 iteration 1874 : loss : 0.061530, loss_ce: 0.031011
2022-01-21 18:47:09,432 iteration 1875 : loss : 0.035577, loss_ce: 0.011841
2022-01-21 18:47:10,834 iteration 1876 : loss : 0.028321, loss_ce: 0.008004
2022-01-21 18:47:12,215 iteration 1877 : loss : 0.065208, loss_ce: 0.029192
2022-01-21 18:47:13,522 iteration 1878 : loss : 0.042124, loss_ce: 0.018282
2022-01-21 18:47:14,822 iteration 1879 : loss : 0.040630, loss_ce: 0.014786
2022-01-21 18:47:16,112 iteration 1880 : loss : 0.045339, loss_ce: 0.021351
2022-01-21 18:47:17,440 iteration 1881 : loss : 0.043804, loss_ce: 0.014800
2022-01-21 18:47:18,720 iteration 1882 : loss : 0.035935, loss_ce: 0.012398
2022-01-21 18:47:19,963 iteration 1883 : loss : 0.039488, loss_ce: 0.013555
2022-01-21 18:47:21,319 iteration 1884 : loss : 0.045537, loss_ce: 0.017605
2022-01-21 18:47:22,557 iteration 1885 : loss : 0.026507, loss_ce: 0.010447
2022-01-21 18:47:23,962 iteration 1886 : loss : 0.047780, loss_ce: 0.021532
2022-01-21 18:47:25,361 iteration 1887 : loss : 0.045474, loss_ce: 0.020795
 28%|████████                     | 111/400 [45:40<2:00:13, 24.96s/it]2022-01-21 18:47:26,717 iteration 1888 : loss : 0.033680, loss_ce: 0.014242
2022-01-21 18:47:28,102 iteration 1889 : loss : 0.048551, loss_ce: 0.022520
2022-01-21 18:47:29,469 iteration 1890 : loss : 0.039399, loss_ce: 0.013084
2022-01-21 18:47:30,847 iteration 1891 : loss : 0.046865, loss_ce: 0.017138
2022-01-21 18:47:32,192 iteration 1892 : loss : 0.036363, loss_ce: 0.015381
2022-01-21 18:47:33,543 iteration 1893 : loss : 0.053484, loss_ce: 0.035608
2022-01-21 18:47:34,870 iteration 1894 : loss : 0.041093, loss_ce: 0.018565
2022-01-21 18:47:36,192 iteration 1895 : loss : 0.038926, loss_ce: 0.011215
2022-01-21 18:47:37,645 iteration 1896 : loss : 0.049575, loss_ce: 0.024106
2022-01-21 18:47:38,967 iteration 1897 : loss : 0.050124, loss_ce: 0.013765
2022-01-21 18:47:40,358 iteration 1898 : loss : 0.035036, loss_ce: 0.012545
2022-01-21 18:47:41,688 iteration 1899 : loss : 0.040096, loss_ce: 0.020579
2022-01-21 18:47:42,939 iteration 1900 : loss : 0.028191, loss_ce: 0.011770
2022-01-21 18:47:44,267 iteration 1901 : loss : 0.040050, loss_ce: 0.015964
2022-01-21 18:47:45,622 iteration 1902 : loss : 0.050175, loss_ce: 0.024479
2022-01-21 18:47:47,008 iteration 1903 : loss : 0.042817, loss_ce: 0.013744
2022-01-21 18:47:48,448 iteration 1904 : loss : 0.057964, loss_ce: 0.021033
 28%|████████                     | 112/400 [46:04<1:57:06, 24.40s/it]2022-01-21 18:47:49,767 iteration 1905 : loss : 0.024187, loss_ce: 0.010417
2022-01-21 18:47:51,158 iteration 1906 : loss : 0.038172, loss_ce: 0.013908
2022-01-21 18:47:52,605 iteration 1907 : loss : 0.035890, loss_ce: 0.013910
2022-01-21 18:47:53,973 iteration 1908 : loss : 0.046510, loss_ce: 0.019175
2022-01-21 18:47:55,375 iteration 1909 : loss : 0.034948, loss_ce: 0.018421
2022-01-21 18:47:56,764 iteration 1910 : loss : 0.025785, loss_ce: 0.012109
2022-01-21 18:47:58,221 iteration 1911 : loss : 0.033137, loss_ce: 0.014676
2022-01-21 18:47:59,602 iteration 1912 : loss : 0.035385, loss_ce: 0.010193
2022-01-21 18:48:00,937 iteration 1913 : loss : 0.031789, loss_ce: 0.011376
2022-01-21 18:48:02,234 iteration 1914 : loss : 0.029908, loss_ce: 0.012673
2022-01-21 18:48:03,575 iteration 1915 : loss : 0.057340, loss_ce: 0.020566
2022-01-21 18:48:04,909 iteration 1916 : loss : 0.045641, loss_ce: 0.021187
2022-01-21 18:48:06,272 iteration 1917 : loss : 0.039746, loss_ce: 0.015773
2022-01-21 18:48:07,565 iteration 1918 : loss : 0.042641, loss_ce: 0.018048
2022-01-21 18:48:08,880 iteration 1919 : loss : 0.030648, loss_ce: 0.013841
2022-01-21 18:48:10,202 iteration 1920 : loss : 0.029109, loss_ce: 0.010037
2022-01-21 18:48:11,574 iteration 1921 : loss : 0.039566, loss_ce: 0.015007
 28%|████████▏                    | 113/400 [46:27<1:54:52, 24.01s/it]2022-01-21 18:48:12,893 iteration 1922 : loss : 0.035596, loss_ce: 0.014320
2022-01-21 18:48:14,148 iteration 1923 : loss : 0.021951, loss_ce: 0.009207
2022-01-21 18:48:15,501 iteration 1924 : loss : 0.043597, loss_ce: 0.021642
2022-01-21 18:48:16,779 iteration 1925 : loss : 0.038504, loss_ce: 0.017396
2022-01-21 18:48:18,072 iteration 1926 : loss : 0.030684, loss_ce: 0.013080
2022-01-21 18:48:19,439 iteration 1927 : loss : 0.043310, loss_ce: 0.017228
2022-01-21 18:48:20,820 iteration 1928 : loss : 0.029366, loss_ce: 0.011662
2022-01-21 18:48:22,124 iteration 1929 : loss : 0.035363, loss_ce: 0.016923
2022-01-21 18:48:23,453 iteration 1930 : loss : 0.043962, loss_ce: 0.013241
2022-01-21 18:48:24,753 iteration 1931 : loss : 0.036289, loss_ce: 0.010627
2022-01-21 18:48:26,083 iteration 1932 : loss : 0.034862, loss_ce: 0.010863
2022-01-21 18:48:27,413 iteration 1933 : loss : 0.049807, loss_ce: 0.017351
2022-01-21 18:48:28,625 iteration 1934 : loss : 0.031793, loss_ce: 0.014904
2022-01-21 18:48:29,920 iteration 1935 : loss : 0.043080, loss_ce: 0.019076
2022-01-21 18:48:31,288 iteration 1936 : loss : 0.026367, loss_ce: 0.009352
2022-01-21 18:48:32,647 iteration 1937 : loss : 0.026767, loss_ce: 0.011467
2022-01-21 18:48:34,007 iteration 1938 : loss : 0.042969, loss_ce: 0.013087
 28%|████████▎                    | 114/400 [46:49<1:52:13, 23.54s/it]2022-01-21 18:48:35,317 iteration 1939 : loss : 0.025506, loss_ce: 0.011287
2022-01-21 18:48:36,617 iteration 1940 : loss : 0.027537, loss_ce: 0.010741
2022-01-21 18:48:37,997 iteration 1941 : loss : 0.036368, loss_ce: 0.017780
2022-01-21 18:48:39,318 iteration 1942 : loss : 0.044702, loss_ce: 0.015340
2022-01-21 18:48:40,569 iteration 1943 : loss : 0.030180, loss_ce: 0.010632
2022-01-21 18:48:41,862 iteration 1944 : loss : 0.028712, loss_ce: 0.010605
2022-01-21 18:48:43,170 iteration 1945 : loss : 0.030214, loss_ce: 0.014757
2022-01-21 18:48:44,479 iteration 1946 : loss : 0.043575, loss_ce: 0.016549
2022-01-21 18:48:45,777 iteration 1947 : loss : 0.034631, loss_ce: 0.013925
2022-01-21 18:48:47,071 iteration 1948 : loss : 0.029529, loss_ce: 0.012619
2022-01-21 18:48:48,318 iteration 1949 : loss : 0.031359, loss_ce: 0.015903
2022-01-21 18:48:49,676 iteration 1950 : loss : 0.035797, loss_ce: 0.012484
2022-01-21 18:48:51,102 iteration 1951 : loss : 0.036664, loss_ce: 0.012943
2022-01-21 18:48:52,377 iteration 1952 : loss : 0.026927, loss_ce: 0.007573
2022-01-21 18:48:53,716 iteration 1953 : loss : 0.036390, loss_ce: 0.019388
2022-01-21 18:48:55,117 iteration 1954 : loss : 0.042308, loss_ce: 0.014183
2022-01-21 18:48:55,117 Training Data Eval:
2022-01-21 18:49:01,641   Average segmentation loss on training set: 0.0245
2022-01-21 18:49:01,642 Validation Data Eval:
2022-01-21 18:49:03,875   Average segmentation loss on validation set: 0.0661
2022-01-21 18:49:05,177 iteration 1955 : loss : 0.030187, loss_ce: 0.011067
 29%|████████▎                    | 115/400 [47:20<2:02:41, 25.83s/it]2022-01-21 18:49:06,589 iteration 1956 : loss : 0.035786, loss_ce: 0.013160
2022-01-21 18:49:07,862 iteration 1957 : loss : 0.031817, loss_ce: 0.013902
2022-01-21 18:49:09,165 iteration 1958 : loss : 0.025721, loss_ce: 0.011686
2022-01-21 18:49:10,571 iteration 1959 : loss : 0.072208, loss_ce: 0.021058
2022-01-21 18:49:11,876 iteration 1960 : loss : 0.034911, loss_ce: 0.011848
2022-01-21 18:49:13,210 iteration 1961 : loss : 0.042701, loss_ce: 0.016078
2022-01-21 18:49:14,529 iteration 1962 : loss : 0.033863, loss_ce: 0.014470
2022-01-21 18:49:15,873 iteration 1963 : loss : 0.034559, loss_ce: 0.013950
2022-01-21 18:49:17,183 iteration 1964 : loss : 0.044531, loss_ce: 0.014848
2022-01-21 18:49:18,473 iteration 1965 : loss : 0.032160, loss_ce: 0.015156
2022-01-21 18:49:19,754 iteration 1966 : loss : 0.036929, loss_ce: 0.016420
2022-01-21 18:49:21,027 iteration 1967 : loss : 0.044565, loss_ce: 0.013112
2022-01-21 18:49:22,279 iteration 1968 : loss : 0.036867, loss_ce: 0.018849
2022-01-21 18:49:23,628 iteration 1969 : loss : 0.033417, loss_ce: 0.014055
2022-01-21 18:49:25,083 iteration 1970 : loss : 0.035614, loss_ce: 0.012420
2022-01-21 18:49:26,320 iteration 1971 : loss : 0.026983, loss_ce: 0.008517
2022-01-21 18:49:27,754 iteration 1972 : loss : 0.039309, loss_ce: 0.015187
 29%|████████▍                    | 116/400 [47:43<1:57:38, 24.85s/it]2022-01-21 18:49:29,041 iteration 1973 : loss : 0.028738, loss_ce: 0.010981
2022-01-21 18:49:30,297 iteration 1974 : loss : 0.042236, loss_ce: 0.020779
2022-01-21 18:49:31,695 iteration 1975 : loss : 0.032868, loss_ce: 0.012309
2022-01-21 18:49:32,941 iteration 1976 : loss : 0.030150, loss_ce: 0.012666
2022-01-21 18:49:34,348 iteration 1977 : loss : 0.041257, loss_ce: 0.018100
2022-01-21 18:49:35,638 iteration 1978 : loss : 0.036457, loss_ce: 0.016413
2022-01-21 18:49:36,940 iteration 1979 : loss : 0.032803, loss_ce: 0.016223
2022-01-21 18:49:38,305 iteration 1980 : loss : 0.036460, loss_ce: 0.011614
2022-01-21 18:49:39,587 iteration 1981 : loss : 0.028410, loss_ce: 0.011238
2022-01-21 18:49:40,971 iteration 1982 : loss : 0.036273, loss_ce: 0.014022
2022-01-21 18:49:42,386 iteration 1983 : loss : 0.037317, loss_ce: 0.015308
2022-01-21 18:49:43,677 iteration 1984 : loss : 0.039791, loss_ce: 0.011906
2022-01-21 18:49:44,977 iteration 1985 : loss : 0.030055, loss_ce: 0.010518
2022-01-21 18:49:46,263 iteration 1986 : loss : 0.046047, loss_ce: 0.021711
2022-01-21 18:49:47,546 iteration 1987 : loss : 0.025593, loss_ce: 0.009532
2022-01-21 18:49:48,956 iteration 1988 : loss : 0.030645, loss_ce: 0.012210
2022-01-21 18:49:50,281 iteration 1989 : loss : 0.028852, loss_ce: 0.012197
 29%|████████▍                    | 117/400 [48:05<1:53:55, 24.15s/it]2022-01-21 18:49:51,643 iteration 1990 : loss : 0.047554, loss_ce: 0.018646
2022-01-21 18:49:52,882 iteration 1991 : loss : 0.031733, loss_ce: 0.014123
2022-01-21 18:49:54,238 iteration 1992 : loss : 0.027468, loss_ce: 0.011597
2022-01-21 18:49:55,552 iteration 1993 : loss : 0.047752, loss_ce: 0.012568
2022-01-21 18:49:56,909 iteration 1994 : loss : 0.030133, loss_ce: 0.012343
2022-01-21 18:49:58,233 iteration 1995 : loss : 0.041515, loss_ce: 0.013934
2022-01-21 18:49:59,568 iteration 1996 : loss : 0.039461, loss_ce: 0.017518
2022-01-21 18:50:00,899 iteration 1997 : loss : 0.035823, loss_ce: 0.015127
2022-01-21 18:50:02,259 iteration 1998 : loss : 0.040470, loss_ce: 0.017348
2022-01-21 18:50:03,604 iteration 1999 : loss : 0.042043, loss_ce: 0.021572
2022-01-21 18:50:05,055 iteration 2000 : loss : 0.054429, loss_ce: 0.012659
2022-01-21 18:50:06,392 iteration 2001 : loss : 0.050404, loss_ce: 0.017679
2022-01-21 18:50:07,649 iteration 2002 : loss : 0.029537, loss_ce: 0.012961
2022-01-21 18:50:08,852 iteration 2003 : loss : 0.021879, loss_ce: 0.010048
2022-01-21 18:50:10,132 iteration 2004 : loss : 0.033412, loss_ce: 0.008817
2022-01-21 18:50:11,500 iteration 2005 : loss : 0.023224, loss_ce: 0.007865
2022-01-21 18:50:12,852 iteration 2006 : loss : 0.043623, loss_ce: 0.013727
 30%|████████▌                    | 118/400 [48:28<1:51:17, 23.68s/it]2022-01-21 18:50:14,275 iteration 2007 : loss : 0.039593, loss_ce: 0.014409
2022-01-21 18:50:15,728 iteration 2008 : loss : 0.031120, loss_ce: 0.010845
2022-01-21 18:50:17,059 iteration 2009 : loss : 0.032945, loss_ce: 0.013193
2022-01-21 18:50:18,385 iteration 2010 : loss : 0.042133, loss_ce: 0.018711
2022-01-21 18:50:19,800 iteration 2011 : loss : 0.034047, loss_ce: 0.013175
2022-01-21 18:50:21,137 iteration 2012 : loss : 0.031866, loss_ce: 0.015010
2022-01-21 18:50:22,391 iteration 2013 : loss : 0.028660, loss_ce: 0.012408
2022-01-21 18:50:23,693 iteration 2014 : loss : 0.037017, loss_ce: 0.011983
2022-01-21 18:50:25,056 iteration 2015 : loss : 0.033040, loss_ce: 0.013670
2022-01-21 18:50:26,369 iteration 2016 : loss : 0.051457, loss_ce: 0.016944
2022-01-21 18:50:27,740 iteration 2017 : loss : 0.027499, loss_ce: 0.008023
2022-01-21 18:50:29,177 iteration 2018 : loss : 0.055783, loss_ce: 0.024895
2022-01-21 18:50:30,489 iteration 2019 : loss : 0.047194, loss_ce: 0.017748
2022-01-21 18:50:31,793 iteration 2020 : loss : 0.024264, loss_ce: 0.008238
2022-01-21 18:50:33,146 iteration 2021 : loss : 0.036043, loss_ce: 0.011755
2022-01-21 18:50:34,502 iteration 2022 : loss : 0.036623, loss_ce: 0.016805
2022-01-21 18:50:35,899 iteration 2023 : loss : 0.035059, loss_ce: 0.012573
 30%|████████▋                    | 119/400 [48:51<1:50:00, 23.49s/it]2022-01-21 18:50:37,221 iteration 2024 : loss : 0.027909, loss_ce: 0.008585
2022-01-21 18:50:38,567 iteration 2025 : loss : 0.032151, loss_ce: 0.014576
2022-01-21 18:50:39,953 iteration 2026 : loss : 0.038936, loss_ce: 0.019486
2022-01-21 18:50:41,268 iteration 2027 : loss : 0.036319, loss_ce: 0.009814
2022-01-21 18:50:42,548 iteration 2028 : loss : 0.026335, loss_ce: 0.014072
2022-01-21 18:50:43,855 iteration 2029 : loss : 0.035123, loss_ce: 0.014313
2022-01-21 18:50:45,146 iteration 2030 : loss : 0.033650, loss_ce: 0.013043
2022-01-21 18:50:46,475 iteration 2031 : loss : 0.027103, loss_ce: 0.009926
2022-01-21 18:50:47,892 iteration 2032 : loss : 0.045233, loss_ce: 0.018257
2022-01-21 18:50:49,335 iteration 2033 : loss : 0.051281, loss_ce: 0.024030
2022-01-21 18:50:50,632 iteration 2034 : loss : 0.036839, loss_ce: 0.013888
2022-01-21 18:50:51,967 iteration 2035 : loss : 0.035433, loss_ce: 0.012205
2022-01-21 18:50:53,344 iteration 2036 : loss : 0.030017, loss_ce: 0.013498
2022-01-21 18:50:54,674 iteration 2037 : loss : 0.047878, loss_ce: 0.013535
2022-01-21 18:50:56,042 iteration 2038 : loss : 0.040016, loss_ce: 0.016928
2022-01-21 18:50:57,461 iteration 2039 : loss : 0.037798, loss_ce: 0.014305
2022-01-21 18:50:57,461 Training Data Eval:
2022-01-21 18:51:03,970   Average segmentation loss on training set: 0.0221
2022-01-21 18:51:03,971 Validation Data Eval:
2022-01-21 18:51:06,194   Average segmentation loss on validation set: 0.0653
2022-01-21 18:51:10,361 Found new lowest validation loss at iteration 2039! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:51:11,660 iteration 2040 : loss : 0.050967, loss_ce: 0.020169
 30%|████████▋                    | 120/400 [49:27<2:06:48, 27.17s/it]2022-01-21 18:51:12,966 iteration 2041 : loss : 0.038879, loss_ce: 0.010208
2022-01-21 18:51:14,167 iteration 2042 : loss : 0.035912, loss_ce: 0.014125
2022-01-21 18:51:15,362 iteration 2043 : loss : 0.026909, loss_ce: 0.009378
2022-01-21 18:51:16,617 iteration 2044 : loss : 0.040133, loss_ce: 0.015986
2022-01-21 18:51:17,898 iteration 2045 : loss : 0.028456, loss_ce: 0.009127
2022-01-21 18:51:19,232 iteration 2046 : loss : 0.039070, loss_ce: 0.015936
2022-01-21 18:51:20,534 iteration 2047 : loss : 0.033809, loss_ce: 0.012335
2022-01-21 18:51:21,867 iteration 2048 : loss : 0.062292, loss_ce: 0.027999
2022-01-21 18:51:23,171 iteration 2049 : loss : 0.037729, loss_ce: 0.008114
2022-01-21 18:51:24,514 iteration 2050 : loss : 0.045188, loss_ce: 0.019546
2022-01-21 18:51:25,861 iteration 2051 : loss : 0.041816, loss_ce: 0.017488
2022-01-21 18:51:27,135 iteration 2052 : loss : 0.045411, loss_ce: 0.017134
2022-01-21 18:51:28,473 iteration 2053 : loss : 0.054311, loss_ce: 0.017707
2022-01-21 18:51:29,780 iteration 2054 : loss : 0.042845, loss_ce: 0.017924
2022-01-21 18:51:31,097 iteration 2055 : loss : 0.048484, loss_ce: 0.013546
2022-01-21 18:51:32,473 iteration 2056 : loss : 0.038137, loss_ce: 0.016440
2022-01-21 18:51:33,756 iteration 2057 : loss : 0.036746, loss_ce: 0.014308
 30%|████████▊                    | 121/400 [49:49<1:59:15, 25.65s/it]2022-01-21 18:51:35,127 iteration 2058 : loss : 0.033231, loss_ce: 0.014124
2022-01-21 18:51:36,517 iteration 2059 : loss : 0.046840, loss_ce: 0.017034
2022-01-21 18:51:37,761 iteration 2060 : loss : 0.034564, loss_ce: 0.011956
2022-01-21 18:51:39,119 iteration 2061 : loss : 0.038407, loss_ce: 0.016037
2022-01-21 18:51:40,424 iteration 2062 : loss : 0.038926, loss_ce: 0.016343
2022-01-21 18:51:41,744 iteration 2063 : loss : 0.060661, loss_ce: 0.011089
2022-01-21 18:51:43,015 iteration 2064 : loss : 0.025346, loss_ce: 0.008670
2022-01-21 18:51:44,314 iteration 2065 : loss : 0.060573, loss_ce: 0.016811
2022-01-21 18:51:45,637 iteration 2066 : loss : 0.049768, loss_ce: 0.015278
2022-01-21 18:51:46,988 iteration 2067 : loss : 0.034665, loss_ce: 0.013103
2022-01-21 18:51:48,374 iteration 2068 : loss : 0.027271, loss_ce: 0.012101
2022-01-21 18:51:49,675 iteration 2069 : loss : 0.032548, loss_ce: 0.009934
2022-01-21 18:51:51,051 iteration 2070 : loss : 0.032801, loss_ce: 0.013348
2022-01-21 18:51:52,440 iteration 2071 : loss : 0.034323, loss_ce: 0.011847
2022-01-21 18:51:53,780 iteration 2072 : loss : 0.033212, loss_ce: 0.011742
2022-01-21 18:51:55,167 iteration 2073 : loss : 0.052276, loss_ce: 0.020403
2022-01-21 18:51:56,533 iteration 2074 : loss : 0.034181, loss_ce: 0.018130
 30%|████████▊                    | 122/400 [50:12<1:54:51, 24.79s/it]2022-01-21 18:51:57,874 iteration 2075 : loss : 0.034431, loss_ce: 0.012579
2022-01-21 18:51:59,211 iteration 2076 : loss : 0.038658, loss_ce: 0.011184
2022-01-21 18:52:00,572 iteration 2077 : loss : 0.030725, loss_ce: 0.012634
2022-01-21 18:52:02,019 iteration 2078 : loss : 0.056238, loss_ce: 0.020905
2022-01-21 18:52:03,332 iteration 2079 : loss : 0.047078, loss_ce: 0.014096
2022-01-21 18:52:04,716 iteration 2080 : loss : 0.062001, loss_ce: 0.020195
2022-01-21 18:52:05,958 iteration 2081 : loss : 0.033264, loss_ce: 0.012115
2022-01-21 18:52:07,185 iteration 2082 : loss : 0.024647, loss_ce: 0.008588
2022-01-21 18:52:08,496 iteration 2083 : loss : 0.035011, loss_ce: 0.017356
2022-01-21 18:52:09,809 iteration 2084 : loss : 0.041356, loss_ce: 0.018141
2022-01-21 18:52:11,087 iteration 2085 : loss : 0.049754, loss_ce: 0.012573
2022-01-21 18:52:12,401 iteration 2086 : loss : 0.039515, loss_ce: 0.016727
2022-01-21 18:52:13,693 iteration 2087 : loss : 0.042927, loss_ce: 0.017831
2022-01-21 18:52:15,103 iteration 2088 : loss : 0.032418, loss_ce: 0.012132
2022-01-21 18:52:16,485 iteration 2089 : loss : 0.045940, loss_ce: 0.024962
2022-01-21 18:52:17,761 iteration 2090 : loss : 0.027903, loss_ce: 0.011320
2022-01-21 18:52:19,146 iteration 2091 : loss : 0.031574, loss_ce: 0.014073
 31%|████████▉                    | 123/400 [50:34<1:51:25, 24.13s/it]2022-01-21 18:52:20,449 iteration 2092 : loss : 0.023766, loss_ce: 0.009817
2022-01-21 18:52:21,770 iteration 2093 : loss : 0.055145, loss_ce: 0.020809
2022-01-21 18:52:23,102 iteration 2094 : loss : 0.044693, loss_ce: 0.009284
2022-01-21 18:52:24,373 iteration 2095 : loss : 0.024437, loss_ce: 0.010347
2022-01-21 18:52:25,799 iteration 2096 : loss : 0.036848, loss_ce: 0.016346
2022-01-21 18:52:27,165 iteration 2097 : loss : 0.068209, loss_ce: 0.021808
2022-01-21 18:52:28,519 iteration 2098 : loss : 0.043747, loss_ce: 0.014692
2022-01-21 18:52:29,879 iteration 2099 : loss : 0.039619, loss_ce: 0.013273
2022-01-21 18:52:31,269 iteration 2100 : loss : 0.047502, loss_ce: 0.027052
2022-01-21 18:52:32,630 iteration 2101 : loss : 0.031555, loss_ce: 0.010063
2022-01-21 18:52:34,031 iteration 2102 : loss : 0.052735, loss_ce: 0.027152
2022-01-21 18:52:35,294 iteration 2103 : loss : 0.035206, loss_ce: 0.015796
2022-01-21 18:52:36,573 iteration 2104 : loss : 0.039970, loss_ce: 0.012393
2022-01-21 18:52:38,013 iteration 2105 : loss : 0.050692, loss_ce: 0.015375
2022-01-21 18:52:39,325 iteration 2106 : loss : 0.030717, loss_ce: 0.012711
2022-01-21 18:52:40,763 iteration 2107 : loss : 0.040909, loss_ce: 0.014864
2022-01-21 18:52:42,133 iteration 2108 : loss : 0.045886, loss_ce: 0.017365
 31%|████████▉                    | 124/400 [50:57<1:49:26, 23.79s/it]2022-01-21 18:52:43,523 iteration 2109 : loss : 0.039838, loss_ce: 0.015355
2022-01-21 18:52:44,912 iteration 2110 : loss : 0.052784, loss_ce: 0.022643
2022-01-21 18:52:46,352 iteration 2111 : loss : 0.055489, loss_ce: 0.018594
2022-01-21 18:52:47,719 iteration 2112 : loss : 0.054710, loss_ce: 0.023407
2022-01-21 18:52:49,037 iteration 2113 : loss : 0.034759, loss_ce: 0.016303
2022-01-21 18:52:50,421 iteration 2114 : loss : 0.037398, loss_ce: 0.019095
2022-01-21 18:52:51,799 iteration 2115 : loss : 0.036894, loss_ce: 0.012764
2022-01-21 18:52:53,160 iteration 2116 : loss : 0.039655, loss_ce: 0.013952
2022-01-21 18:52:54,518 iteration 2117 : loss : 0.034815, loss_ce: 0.015034
2022-01-21 18:52:55,911 iteration 2118 : loss : 0.041515, loss_ce: 0.011517
2022-01-21 18:52:57,304 iteration 2119 : loss : 0.048461, loss_ce: 0.016788
2022-01-21 18:52:58,668 iteration 2120 : loss : 0.043921, loss_ce: 0.012057
2022-01-21 18:52:59,916 iteration 2121 : loss : 0.029724, loss_ce: 0.010052
2022-01-21 18:53:01,234 iteration 2122 : loss : 0.041708, loss_ce: 0.013860
2022-01-21 18:53:02,647 iteration 2123 : loss : 0.073369, loss_ce: 0.035231
2022-01-21 18:53:04,083 iteration 2124 : loss : 0.055994, loss_ce: 0.024224
2022-01-21 18:53:04,084 Training Data Eval:
2022-01-21 18:53:10,644   Average segmentation loss on training set: 0.0290
2022-01-21 18:53:10,644 Validation Data Eval:
2022-01-21 18:53:12,883   Average segmentation loss on validation set: 0.0655
2022-01-21 18:53:14,253 iteration 2125 : loss : 0.057209, loss_ce: 0.029823
 31%|█████████                    | 125/400 [51:29<2:00:30, 26.29s/it]2022-01-21 18:53:15,694 iteration 2126 : loss : 0.030462, loss_ce: 0.011846
2022-01-21 18:53:17,068 iteration 2127 : loss : 0.055766, loss_ce: 0.029843
2022-01-21 18:53:18,441 iteration 2128 : loss : 0.039632, loss_ce: 0.013300
2022-01-21 18:53:19,742 iteration 2129 : loss : 0.044597, loss_ce: 0.016530
2022-01-21 18:53:21,124 iteration 2130 : loss : 0.078197, loss_ce: 0.026343
2022-01-21 18:53:22,447 iteration 2131 : loss : 0.049995, loss_ce: 0.014717
2022-01-21 18:53:23,787 iteration 2132 : loss : 0.038845, loss_ce: 0.016399
2022-01-21 18:53:25,203 iteration 2133 : loss : 0.062179, loss_ce: 0.020019
2022-01-21 18:53:26,476 iteration 2134 : loss : 0.034353, loss_ce: 0.015922
2022-01-21 18:53:27,817 iteration 2135 : loss : 0.048140, loss_ce: 0.016380
2022-01-21 18:53:29,151 iteration 2136 : loss : 0.038637, loss_ce: 0.014787
2022-01-21 18:53:30,495 iteration 2137 : loss : 0.048818, loss_ce: 0.019859
2022-01-21 18:53:31,798 iteration 2138 : loss : 0.036947, loss_ce: 0.015432
2022-01-21 18:53:33,187 iteration 2139 : loss : 0.042679, loss_ce: 0.018039
2022-01-21 18:53:34,523 iteration 2140 : loss : 0.060540, loss_ce: 0.034594
2022-01-21 18:53:35,918 iteration 2141 : loss : 0.035352, loss_ce: 0.012785
2022-01-21 18:53:37,214 iteration 2142 : loss : 0.039377, loss_ce: 0.012008
 32%|█████████▏                   | 126/400 [51:52<1:55:29, 25.29s/it]2022-01-21 18:53:38,513 iteration 2143 : loss : 0.033634, loss_ce: 0.012733
2022-01-21 18:53:39,861 iteration 2144 : loss : 0.037259, loss_ce: 0.011324
2022-01-21 18:53:41,224 iteration 2145 : loss : 0.042174, loss_ce: 0.014020
2022-01-21 18:53:42,500 iteration 2146 : loss : 0.019877, loss_ce: 0.008866
2022-01-21 18:53:43,849 iteration 2147 : loss : 0.053346, loss_ce: 0.018941
2022-01-21 18:53:45,154 iteration 2148 : loss : 0.034562, loss_ce: 0.014601
2022-01-21 18:53:46,483 iteration 2149 : loss : 0.035091, loss_ce: 0.013537
2022-01-21 18:53:47,780 iteration 2150 : loss : 0.033049, loss_ce: 0.012658
2022-01-21 18:53:49,174 iteration 2151 : loss : 0.043078, loss_ce: 0.017727
2022-01-21 18:53:50,461 iteration 2152 : loss : 0.029483, loss_ce: 0.011478
2022-01-21 18:53:51,733 iteration 2153 : loss : 0.025834, loss_ce: 0.010090
2022-01-21 18:53:53,192 iteration 2154 : loss : 0.050095, loss_ce: 0.017571
2022-01-21 18:53:54,520 iteration 2155 : loss : 0.035116, loss_ce: 0.013569
2022-01-21 18:53:55,797 iteration 2156 : loss : 0.038853, loss_ce: 0.016484
2022-01-21 18:53:57,264 iteration 2157 : loss : 0.072762, loss_ce: 0.024645
2022-01-21 18:53:58,687 iteration 2158 : loss : 0.045577, loss_ce: 0.021876
2022-01-21 18:54:00,044 iteration 2159 : loss : 0.044839, loss_ce: 0.013922
 32%|█████████▏                   | 127/400 [52:15<1:51:42, 24.55s/it]2022-01-21 18:54:01,369 iteration 2160 : loss : 0.033791, loss_ce: 0.013501
2022-01-21 18:54:02,647 iteration 2161 : loss : 0.028411, loss_ce: 0.009356
2022-01-21 18:54:03,956 iteration 2162 : loss : 0.048690, loss_ce: 0.015980
2022-01-21 18:54:05,251 iteration 2163 : loss : 0.034866, loss_ce: 0.012398
2022-01-21 18:54:06,614 iteration 2164 : loss : 0.030941, loss_ce: 0.014480
2022-01-21 18:54:07,960 iteration 2165 : loss : 0.042377, loss_ce: 0.014910
2022-01-21 18:54:09,241 iteration 2166 : loss : 0.042140, loss_ce: 0.019230
2022-01-21 18:54:10,490 iteration 2167 : loss : 0.030492, loss_ce: 0.012284
2022-01-21 18:54:11,787 iteration 2168 : loss : 0.032854, loss_ce: 0.013375
2022-01-21 18:54:13,134 iteration 2169 : loss : 0.039913, loss_ce: 0.015744
2022-01-21 18:54:14,351 iteration 2170 : loss : 0.028988, loss_ce: 0.009557
2022-01-21 18:54:15,648 iteration 2171 : loss : 0.035320, loss_ce: 0.014377
2022-01-21 18:54:16,940 iteration 2172 : loss : 0.044635, loss_ce: 0.014143
2022-01-21 18:54:18,219 iteration 2173 : loss : 0.033555, loss_ce: 0.007816
2022-01-21 18:54:19,541 iteration 2174 : loss : 0.040619, loss_ce: 0.016621
2022-01-21 18:54:20,950 iteration 2175 : loss : 0.029216, loss_ce: 0.012086
2022-01-21 18:54:22,166 iteration 2176 : loss : 0.028213, loss_ce: 0.012700
 32%|█████████▎                   | 128/400 [52:37<1:48:00, 23.82s/it]2022-01-21 18:54:23,453 iteration 2177 : loss : 0.057357, loss_ce: 0.033775
2022-01-21 18:54:24,774 iteration 2178 : loss : 0.045606, loss_ce: 0.014967
2022-01-21 18:54:26,169 iteration 2179 : loss : 0.038669, loss_ce: 0.012619
2022-01-21 18:54:27,541 iteration 2180 : loss : 0.033400, loss_ce: 0.013398
2022-01-21 18:54:28,798 iteration 2181 : loss : 0.026886, loss_ce: 0.009619
2022-01-21 18:54:30,120 iteration 2182 : loss : 0.039626, loss_ce: 0.015017
2022-01-21 18:54:31,463 iteration 2183 : loss : 0.064129, loss_ce: 0.017698
2022-01-21 18:54:32,734 iteration 2184 : loss : 0.039850, loss_ce: 0.018800
2022-01-21 18:54:34,007 iteration 2185 : loss : 0.028930, loss_ce: 0.011055
2022-01-21 18:54:35,408 iteration 2186 : loss : 0.038069, loss_ce: 0.015163
2022-01-21 18:54:36,820 iteration 2187 : loss : 0.037200, loss_ce: 0.013601
2022-01-21 18:54:38,295 iteration 2188 : loss : 0.058394, loss_ce: 0.029858
2022-01-21 18:54:39,753 iteration 2189 : loss : 0.048560, loss_ce: 0.016002
2022-01-21 18:54:41,104 iteration 2190 : loss : 0.061196, loss_ce: 0.025500
2022-01-21 18:54:42,460 iteration 2191 : loss : 0.029748, loss_ce: 0.011834
2022-01-21 18:54:43,758 iteration 2192 : loss : 0.042989, loss_ce: 0.015524
2022-01-21 18:54:45,105 iteration 2193 : loss : 0.027554, loss_ce: 0.009850
 32%|█████████▎                   | 129/400 [53:00<1:46:24, 23.56s/it]2022-01-21 18:54:46,496 iteration 2194 : loss : 0.048538, loss_ce: 0.019082
2022-01-21 18:54:47,847 iteration 2195 : loss : 0.050255, loss_ce: 0.026006
2022-01-21 18:54:49,229 iteration 2196 : loss : 0.053127, loss_ce: 0.023365
2022-01-21 18:54:50,645 iteration 2197 : loss : 0.035608, loss_ce: 0.012514
2022-01-21 18:54:51,976 iteration 2198 : loss : 0.042057, loss_ce: 0.012198
2022-01-21 18:54:53,318 iteration 2199 : loss : 0.037938, loss_ce: 0.016869
2022-01-21 18:54:54,726 iteration 2200 : loss : 0.107075, loss_ce: 0.026333
2022-01-21 18:54:56,004 iteration 2201 : loss : 0.026685, loss_ce: 0.009899
2022-01-21 18:54:57,436 iteration 2202 : loss : 0.072266, loss_ce: 0.028051
2022-01-21 18:54:58,797 iteration 2203 : loss : 0.037991, loss_ce: 0.010968
2022-01-21 18:55:00,070 iteration 2204 : loss : 0.033184, loss_ce: 0.009704
2022-01-21 18:55:01,413 iteration 2205 : loss : 0.040181, loss_ce: 0.019025
2022-01-21 18:55:02,837 iteration 2206 : loss : 0.038278, loss_ce: 0.015349
2022-01-21 18:55:04,202 iteration 2207 : loss : 0.038534, loss_ce: 0.011649
2022-01-21 18:55:05,598 iteration 2208 : loss : 0.059942, loss_ce: 0.015744
2022-01-21 18:55:06,934 iteration 2209 : loss : 0.042206, loss_ce: 0.016594
2022-01-21 18:55:06,934 Training Data Eval:
2022-01-21 18:55:13,462   Average segmentation loss on training set: 0.0273
2022-01-21 18:55:13,462 Validation Data Eval:
2022-01-21 18:55:15,702   Average segmentation loss on validation set: 0.0683
2022-01-21 18:55:17,057 iteration 2210 : loss : 0.044027, loss_ce: 0.022287
 32%|█████████▍                   | 130/400 [53:32<1:57:20, 26.08s/it]2022-01-21 18:55:18,431 iteration 2211 : loss : 0.037961, loss_ce: 0.011515
2022-01-21 18:55:19,713 iteration 2212 : loss : 0.041472, loss_ce: 0.018011
2022-01-21 18:55:21,047 iteration 2213 : loss : 0.038280, loss_ce: 0.010562
2022-01-21 18:55:22,297 iteration 2214 : loss : 0.034819, loss_ce: 0.010907
2022-01-21 18:55:23,544 iteration 2215 : loss : 0.023098, loss_ce: 0.008913
2022-01-21 18:55:24,837 iteration 2216 : loss : 0.035386, loss_ce: 0.016401
2022-01-21 18:55:26,109 iteration 2217 : loss : 0.039134, loss_ce: 0.020898
2022-01-21 18:55:27,407 iteration 2218 : loss : 0.027427, loss_ce: 0.009168
2022-01-21 18:55:28,757 iteration 2219 : loss : 0.049016, loss_ce: 0.023265
2022-01-21 18:55:30,167 iteration 2220 : loss : 0.038649, loss_ce: 0.017923
2022-01-21 18:55:31,564 iteration 2221 : loss : 0.046019, loss_ce: 0.014925
2022-01-21 18:55:32,811 iteration 2222 : loss : 0.032758, loss_ce: 0.013098
2022-01-21 18:55:34,081 iteration 2223 : loss : 0.037236, loss_ce: 0.013477
2022-01-21 18:55:35,473 iteration 2224 : loss : 0.038682, loss_ce: 0.013981
2022-01-21 18:55:36,823 iteration 2225 : loss : 0.043988, loss_ce: 0.015205
2022-01-21 18:55:38,221 iteration 2226 : loss : 0.053193, loss_ce: 0.029419
2022-01-21 18:55:39,599 iteration 2227 : loss : 0.059970, loss_ce: 0.017422
 33%|█████████▍                   | 131/400 [53:55<1:52:09, 25.02s/it]2022-01-21 18:55:41,048 iteration 2228 : loss : 0.035065, loss_ce: 0.015659
2022-01-21 18:55:42,394 iteration 2229 : loss : 0.036529, loss_ce: 0.012256
2022-01-21 18:55:43,872 iteration 2230 : loss : 0.053146, loss_ce: 0.023408
2022-01-21 18:55:45,198 iteration 2231 : loss : 0.040863, loss_ce: 0.021435
2022-01-21 18:55:46,516 iteration 2232 : loss : 0.039549, loss_ce: 0.019946
2022-01-21 18:55:48,028 iteration 2233 : loss : 0.063153, loss_ce: 0.020400
2022-01-21 18:55:49,394 iteration 2234 : loss : 0.036917, loss_ce: 0.009665
2022-01-21 18:55:50,732 iteration 2235 : loss : 0.037153, loss_ce: 0.014579
2022-01-21 18:55:52,049 iteration 2236 : loss : 0.024272, loss_ce: 0.009374
2022-01-21 18:55:53,399 iteration 2237 : loss : 0.042574, loss_ce: 0.020305
2022-01-21 18:55:54,681 iteration 2238 : loss : 0.030257, loss_ce: 0.009094
2022-01-21 18:55:55,986 iteration 2239 : loss : 0.027580, loss_ce: 0.007079
2022-01-21 18:55:57,234 iteration 2240 : loss : 0.054113, loss_ce: 0.013784
2022-01-21 18:55:58,553 iteration 2241 : loss : 0.026436, loss_ce: 0.009985
2022-01-21 18:55:59,940 iteration 2242 : loss : 0.050899, loss_ce: 0.017815
2022-01-21 18:56:01,312 iteration 2243 : loss : 0.054531, loss_ce: 0.027152
2022-01-21 18:56:02,629 iteration 2244 : loss : 0.019455, loss_ce: 0.006586
 33%|█████████▌                   | 132/400 [54:18<1:49:04, 24.42s/it]2022-01-21 18:56:03,986 iteration 2245 : loss : 0.043013, loss_ce: 0.012364
2022-01-21 18:56:05,222 iteration 2246 : loss : 0.026317, loss_ce: 0.008491
2022-01-21 18:56:06,563 iteration 2247 : loss : 0.036285, loss_ce: 0.016064
2022-01-21 18:56:07,959 iteration 2248 : loss : 0.044542, loss_ce: 0.018795
2022-01-21 18:56:09,291 iteration 2249 : loss : 0.029766, loss_ce: 0.015208
2022-01-21 18:56:10,626 iteration 2250 : loss : 0.030533, loss_ce: 0.010866
2022-01-21 18:56:11,985 iteration 2251 : loss : 0.028097, loss_ce: 0.013096
2022-01-21 18:56:13,320 iteration 2252 : loss : 0.037764, loss_ce: 0.013597
2022-01-21 18:56:14,746 iteration 2253 : loss : 0.041139, loss_ce: 0.014138
2022-01-21 18:56:16,126 iteration 2254 : loss : 0.029312, loss_ce: 0.012347
2022-01-21 18:56:17,461 iteration 2255 : loss : 0.026996, loss_ce: 0.011053
2022-01-21 18:56:18,777 iteration 2256 : loss : 0.025106, loss_ce: 0.010741
2022-01-21 18:56:20,060 iteration 2257 : loss : 0.042464, loss_ce: 0.015939
2022-01-21 18:56:21,336 iteration 2258 : loss : 0.048508, loss_ce: 0.019273
2022-01-21 18:56:22,729 iteration 2259 : loss : 0.035278, loss_ce: 0.014431
2022-01-21 18:56:23,993 iteration 2260 : loss : 0.034363, loss_ce: 0.012952
2022-01-21 18:56:25,341 iteration 2261 : loss : 0.037397, loss_ce: 0.016708
 33%|█████████▋                   | 133/400 [54:40<1:46:23, 23.91s/it]2022-01-21 18:56:26,661 iteration 2262 : loss : 0.032222, loss_ce: 0.017217
2022-01-21 18:56:28,052 iteration 2263 : loss : 0.053139, loss_ce: 0.018709
2022-01-21 18:56:29,478 iteration 2264 : loss : 0.033203, loss_ce: 0.009937
2022-01-21 18:56:30,833 iteration 2265 : loss : 0.034110, loss_ce: 0.013318
2022-01-21 18:56:32,137 iteration 2266 : loss : 0.030433, loss_ce: 0.013189
2022-01-21 18:56:33,450 iteration 2267 : loss : 0.021736, loss_ce: 0.007884
2022-01-21 18:56:34,779 iteration 2268 : loss : 0.036353, loss_ce: 0.013907
2022-01-21 18:56:36,068 iteration 2269 : loss : 0.028936, loss_ce: 0.015807
2022-01-21 18:56:37,392 iteration 2270 : loss : 0.040326, loss_ce: 0.012745
2022-01-21 18:56:38,689 iteration 2271 : loss : 0.031771, loss_ce: 0.011172
2022-01-21 18:56:40,004 iteration 2272 : loss : 0.045096, loss_ce: 0.021345
2022-01-21 18:56:41,353 iteration 2273 : loss : 0.024968, loss_ce: 0.007662
2022-01-21 18:56:42,703 iteration 2274 : loss : 0.030456, loss_ce: 0.009087
2022-01-21 18:56:44,089 iteration 2275 : loss : 0.037750, loss_ce: 0.014457
2022-01-21 18:56:45,361 iteration 2276 : loss : 0.029488, loss_ce: 0.011379
2022-01-21 18:56:46,700 iteration 2277 : loss : 0.040739, loss_ce: 0.012942
2022-01-21 18:56:47,978 iteration 2278 : loss : 0.027910, loss_ce: 0.010093
 34%|█████████▋                   | 134/400 [55:03<1:44:17, 23.53s/it]2022-01-21 18:56:49,279 iteration 2279 : loss : 0.118436, loss_ce: 0.063495
2022-01-21 18:56:50,613 iteration 2280 : loss : 0.031800, loss_ce: 0.014039
2022-01-21 18:56:51,934 iteration 2281 : loss : 0.036596, loss_ce: 0.008841
2022-01-21 18:56:53,294 iteration 2282 : loss : 0.031320, loss_ce: 0.011006
2022-01-21 18:56:54,698 iteration 2283 : loss : 0.060293, loss_ce: 0.030418
2022-01-21 18:56:56,003 iteration 2284 : loss : 0.029944, loss_ce: 0.013346
2022-01-21 18:56:57,312 iteration 2285 : loss : 0.029245, loss_ce: 0.011491
2022-01-21 18:56:58,622 iteration 2286 : loss : 0.030052, loss_ce: 0.012458
2022-01-21 18:56:59,936 iteration 2287 : loss : 0.027594, loss_ce: 0.011313
2022-01-21 18:57:01,305 iteration 2288 : loss : 0.036025, loss_ce: 0.013368
2022-01-21 18:57:02,590 iteration 2289 : loss : 0.029881, loss_ce: 0.009451
2022-01-21 18:57:03,974 iteration 2290 : loss : 0.033706, loss_ce: 0.017908
2022-01-21 18:57:05,298 iteration 2291 : loss : 0.025731, loss_ce: 0.009837
2022-01-21 18:57:06,606 iteration 2292 : loss : 0.035827, loss_ce: 0.015377
2022-01-21 18:57:07,852 iteration 2293 : loss : 0.032203, loss_ce: 0.017458
2022-01-21 18:57:09,214 iteration 2294 : loss : 0.050664, loss_ce: 0.018768
2022-01-21 18:57:09,214 Training Data Eval:
2022-01-21 18:57:15,751   Average segmentation loss on training set: 0.0232
2022-01-21 18:57:15,751 Validation Data Eval:
2022-01-21 18:57:17,986   Average segmentation loss on validation set: 0.0607
2022-01-21 18:57:22,126 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 18:57:23,449 iteration 2295 : loss : 0.030713, loss_ce: 0.014684
 34%|█████████▊                   | 135/400 [55:39<1:59:44, 27.11s/it]2022-01-21 18:57:24,634 iteration 2296 : loss : 0.023055, loss_ce: 0.009095
2022-01-21 18:57:25,841 iteration 2297 : loss : 0.026779, loss_ce: 0.011957
2022-01-21 18:57:27,053 iteration 2298 : loss : 0.021924, loss_ce: 0.009476
2022-01-21 18:57:28,404 iteration 2299 : loss : 0.043534, loss_ce: 0.020751
2022-01-21 18:57:29,699 iteration 2300 : loss : 0.027407, loss_ce: 0.012481
2022-01-21 18:57:31,101 iteration 2301 : loss : 0.026030, loss_ce: 0.007881
2022-01-21 18:57:32,468 iteration 2302 : loss : 0.038036, loss_ce: 0.014654
2022-01-21 18:57:33,818 iteration 2303 : loss : 0.028087, loss_ce: 0.009373
2022-01-21 18:57:35,226 iteration 2304 : loss : 0.048437, loss_ce: 0.015390
2022-01-21 18:57:36,593 iteration 2305 : loss : 0.031186, loss_ce: 0.012942
2022-01-21 18:57:38,027 iteration 2306 : loss : 0.026566, loss_ce: 0.012235
2022-01-21 18:57:39,341 iteration 2307 : loss : 0.041560, loss_ce: 0.014428
2022-01-21 18:57:40,625 iteration 2308 : loss : 0.030557, loss_ce: 0.010084
2022-01-21 18:57:41,926 iteration 2309 : loss : 0.031608, loss_ce: 0.015044
2022-01-21 18:57:43,320 iteration 2310 : loss : 0.027559, loss_ce: 0.010735
2022-01-21 18:57:44,573 iteration 2311 : loss : 0.039572, loss_ce: 0.011859
2022-01-21 18:57:45,915 iteration 2312 : loss : 0.035064, loss_ce: 0.012049
 34%|█████████▊                   | 136/400 [56:01<1:53:08, 25.71s/it]2022-01-21 18:57:47,320 iteration 2313 : loss : 0.035061, loss_ce: 0.013192
2022-01-21 18:57:48,547 iteration 2314 : loss : 0.022890, loss_ce: 0.007437
2022-01-21 18:57:49,827 iteration 2315 : loss : 0.027608, loss_ce: 0.010164
2022-01-21 18:57:51,231 iteration 2316 : loss : 0.067978, loss_ce: 0.035202
2022-01-21 18:57:52,491 iteration 2317 : loss : 0.022175, loss_ce: 0.007013
2022-01-21 18:57:53,790 iteration 2318 : loss : 0.033371, loss_ce: 0.017996
2022-01-21 18:57:55,116 iteration 2319 : loss : 0.035314, loss_ce: 0.013724
2022-01-21 18:57:56,520 iteration 2320 : loss : 0.049399, loss_ce: 0.018757
2022-01-21 18:57:57,841 iteration 2321 : loss : 0.040620, loss_ce: 0.017027
2022-01-21 18:57:59,179 iteration 2322 : loss : 0.035584, loss_ce: 0.017498
2022-01-21 18:58:00,419 iteration 2323 : loss : 0.038185, loss_ce: 0.015384
2022-01-21 18:58:01,730 iteration 2324 : loss : 0.031219, loss_ce: 0.012890
2022-01-21 18:58:02,937 iteration 2325 : loss : 0.026950, loss_ce: 0.011712
2022-01-21 18:58:04,238 iteration 2326 : loss : 0.050203, loss_ce: 0.009743
2022-01-21 18:58:05,520 iteration 2327 : loss : 0.029877, loss_ce: 0.011012
2022-01-21 18:58:06,836 iteration 2328 : loss : 0.037044, loss_ce: 0.015797
2022-01-21 18:58:08,107 iteration 2329 : loss : 0.031489, loss_ce: 0.011997
 34%|█████████▉                   | 137/400 [56:23<1:48:05, 24.66s/it]2022-01-21 18:58:09,484 iteration 2330 : loss : 0.048125, loss_ce: 0.021759
2022-01-21 18:58:10,762 iteration 2331 : loss : 0.036200, loss_ce: 0.014813
2022-01-21 18:58:12,170 iteration 2332 : loss : 0.036464, loss_ce: 0.014766
2022-01-21 18:58:13,492 iteration 2333 : loss : 0.047546, loss_ce: 0.021686
2022-01-21 18:58:14,937 iteration 2334 : loss : 0.025918, loss_ce: 0.011164
2022-01-21 18:58:16,376 iteration 2335 : loss : 0.041572, loss_ce: 0.018741
2022-01-21 18:58:17,777 iteration 2336 : loss : 0.036016, loss_ce: 0.015512
2022-01-21 18:58:19,110 iteration 2337 : loss : 0.060075, loss_ce: 0.024519
2022-01-21 18:58:20,471 iteration 2338 : loss : 0.051819, loss_ce: 0.019256
2022-01-21 18:58:21,828 iteration 2339 : loss : 0.054685, loss_ce: 0.018207
2022-01-21 18:58:23,096 iteration 2340 : loss : 0.028990, loss_ce: 0.011422
2022-01-21 18:58:24,440 iteration 2341 : loss : 0.032350, loss_ce: 0.013173
2022-01-21 18:58:25,791 iteration 2342 : loss : 0.037173, loss_ce: 0.016150
2022-01-21 18:58:27,247 iteration 2343 : loss : 0.034046, loss_ce: 0.011469
2022-01-21 18:58:28,538 iteration 2344 : loss : 0.088027, loss_ce: 0.032592
2022-01-21 18:58:29,833 iteration 2345 : loss : 0.045556, loss_ce: 0.021517
2022-01-21 18:58:31,148 iteration 2346 : loss : 0.063027, loss_ce: 0.024566
 34%|██████████                   | 138/400 [56:46<1:45:33, 24.17s/it]2022-01-21 18:58:32,607 iteration 2347 : loss : 0.042802, loss_ce: 0.017192
2022-01-21 18:58:33,954 iteration 2348 : loss : 0.029081, loss_ce: 0.010139
2022-01-21 18:58:35,261 iteration 2349 : loss : 0.033113, loss_ce: 0.013086
2022-01-21 18:58:36,584 iteration 2350 : loss : 0.047610, loss_ce: 0.013305
2022-01-21 18:58:37,989 iteration 2351 : loss : 0.053191, loss_ce: 0.024811
2022-01-21 18:58:39,275 iteration 2352 : loss : 0.025859, loss_ce: 0.012887
2022-01-21 18:58:40,572 iteration 2353 : loss : 0.032195, loss_ce: 0.015069
2022-01-21 18:58:41,850 iteration 2354 : loss : 0.026389, loss_ce: 0.011353
2022-01-21 18:58:43,142 iteration 2355 : loss : 0.040501, loss_ce: 0.014059
2022-01-21 18:58:44,526 iteration 2356 : loss : 0.035525, loss_ce: 0.015275
2022-01-21 18:58:45,863 iteration 2357 : loss : 0.064432, loss_ce: 0.019119
2022-01-21 18:58:47,206 iteration 2358 : loss : 0.036458, loss_ce: 0.013012
2022-01-21 18:58:48,508 iteration 2359 : loss : 0.042166, loss_ce: 0.013631
2022-01-21 18:58:49,785 iteration 2360 : loss : 0.049889, loss_ce: 0.014092
2022-01-21 18:58:51,109 iteration 2361 : loss : 0.031017, loss_ce: 0.010832
2022-01-21 18:58:52,555 iteration 2362 : loss : 0.044393, loss_ce: 0.017940
2022-01-21 18:58:53,890 iteration 2363 : loss : 0.032918, loss_ce: 0.012975
 35%|██████████                   | 139/400 [57:09<1:43:17, 23.75s/it]2022-01-21 18:58:55,336 iteration 2364 : loss : 0.025110, loss_ce: 0.008580
2022-01-21 18:58:56,758 iteration 2365 : loss : 0.034422, loss_ce: 0.015565
2022-01-21 18:58:58,140 iteration 2366 : loss : 0.044797, loss_ce: 0.019433
2022-01-21 18:58:59,419 iteration 2367 : loss : 0.027624, loss_ce: 0.006898
2022-01-21 18:59:00,697 iteration 2368 : loss : 0.031312, loss_ce: 0.012598
2022-01-21 18:59:02,030 iteration 2369 : loss : 0.036511, loss_ce: 0.012007
2022-01-21 18:59:03,342 iteration 2370 : loss : 0.035595, loss_ce: 0.013213
2022-01-21 18:59:04,706 iteration 2371 : loss : 0.028597, loss_ce: 0.010951
2022-01-21 18:59:05,993 iteration 2372 : loss : 0.042428, loss_ce: 0.012355
2022-01-21 18:59:07,303 iteration 2373 : loss : 0.033807, loss_ce: 0.011615
2022-01-21 18:59:08,573 iteration 2374 : loss : 0.033103, loss_ce: 0.013144
2022-01-21 18:59:09,863 iteration 2375 : loss : 0.025562, loss_ce: 0.008379
2022-01-21 18:59:11,206 iteration 2376 : loss : 0.034445, loss_ce: 0.015805
2022-01-21 18:59:12,545 iteration 2377 : loss : 0.036254, loss_ce: 0.017177
2022-01-21 18:59:13,881 iteration 2378 : loss : 0.022751, loss_ce: 0.008636
2022-01-21 18:59:15,249 iteration 2379 : loss : 0.037694, loss_ce: 0.017889
2022-01-21 18:59:15,249 Training Data Eval:
2022-01-21 18:59:21,771   Average segmentation loss on training set: 0.0218
2022-01-21 18:59:21,772 Validation Data Eval:
2022-01-21 18:59:24,004   Average segmentation loss on validation set: 0.0798
2022-01-21 18:59:25,293 iteration 2380 : loss : 0.023945, loss_ce: 0.010839
 35%|██████████▏                  | 140/400 [57:40<1:52:50, 26.04s/it]2022-01-21 18:59:26,609 iteration 2381 : loss : 0.030811, loss_ce: 0.010737
2022-01-21 18:59:27,967 iteration 2382 : loss : 0.031226, loss_ce: 0.010887
2022-01-21 18:59:29,254 iteration 2383 : loss : 0.023723, loss_ce: 0.008120
2022-01-21 18:59:30,626 iteration 2384 : loss : 0.037079, loss_ce: 0.015796
2022-01-21 18:59:32,017 iteration 2385 : loss : 0.035914, loss_ce: 0.014714
2022-01-21 18:59:33,342 iteration 2386 : loss : 0.029156, loss_ce: 0.009604
2022-01-21 18:59:34,636 iteration 2387 : loss : 0.029548, loss_ce: 0.009836
2022-01-21 18:59:35,963 iteration 2388 : loss : 0.038366, loss_ce: 0.016408
2022-01-21 18:59:37,227 iteration 2389 : loss : 0.015883, loss_ce: 0.005006
2022-01-21 18:59:38,565 iteration 2390 : loss : 0.031531, loss_ce: 0.015237
2022-01-21 18:59:39,873 iteration 2391 : loss : 0.033252, loss_ce: 0.019081
2022-01-21 18:59:41,230 iteration 2392 : loss : 0.040694, loss_ce: 0.016002
2022-01-21 18:59:42,582 iteration 2393 : loss : 0.029786, loss_ce: 0.010658
2022-01-21 18:59:43,817 iteration 2394 : loss : 0.032712, loss_ce: 0.010827
2022-01-21 18:59:45,194 iteration 2395 : loss : 0.025449, loss_ce: 0.010642
2022-01-21 18:59:46,477 iteration 2396 : loss : 0.028041, loss_ce: 0.012501
2022-01-21 18:59:47,831 iteration 2397 : loss : 0.029020, loss_ce: 0.011775
 35%|██████████▏                  | 141/400 [58:03<1:47:53, 24.99s/it]2022-01-21 18:59:49,191 iteration 2398 : loss : 0.043105, loss_ce: 0.014388
2022-01-21 18:59:50,484 iteration 2399 : loss : 0.028185, loss_ce: 0.008512
2022-01-21 18:59:51,871 iteration 2400 : loss : 0.036818, loss_ce: 0.019187
2022-01-21 18:59:53,203 iteration 2401 : loss : 0.025422, loss_ce: 0.008450
2022-01-21 18:59:54,582 iteration 2402 : loss : 0.028951, loss_ce: 0.013759
2022-01-21 18:59:55,876 iteration 2403 : loss : 0.032411, loss_ce: 0.012894
2022-01-21 18:59:57,149 iteration 2404 : loss : 0.024020, loss_ce: 0.010460
2022-01-21 18:59:58,391 iteration 2405 : loss : 0.031458, loss_ce: 0.010245
2022-01-21 18:59:59,847 iteration 2406 : loss : 0.036517, loss_ce: 0.012588
2022-01-21 19:00:01,109 iteration 2407 : loss : 0.033966, loss_ce: 0.017739
2022-01-21 19:00:02,374 iteration 2408 : loss : 0.021648, loss_ce: 0.008938
2022-01-21 19:00:03,753 iteration 2409 : loss : 0.024035, loss_ce: 0.007881
2022-01-21 19:00:05,135 iteration 2410 : loss : 0.038184, loss_ce: 0.016161
2022-01-21 19:00:06,495 iteration 2411 : loss : 0.032814, loss_ce: 0.009439
2022-01-21 19:00:07,780 iteration 2412 : loss : 0.019152, loss_ce: 0.007943
2022-01-21 19:00:09,178 iteration 2413 : loss : 0.041750, loss_ce: 0.017072
2022-01-21 19:00:10,519 iteration 2414 : loss : 0.026394, loss_ce: 0.010221
 36%|██████████▎                  | 142/400 [58:26<1:44:29, 24.30s/it]2022-01-21 19:00:11,902 iteration 2415 : loss : 0.054946, loss_ce: 0.018535
2022-01-21 19:00:13,209 iteration 2416 : loss : 0.023419, loss_ce: 0.008040
2022-01-21 19:00:14,540 iteration 2417 : loss : 0.024216, loss_ce: 0.008418
2022-01-21 19:00:15,952 iteration 2418 : loss : 0.026451, loss_ce: 0.009394
2022-01-21 19:00:17,293 iteration 2419 : loss : 0.035456, loss_ce: 0.018114
2022-01-21 19:00:18,726 iteration 2420 : loss : 0.043083, loss_ce: 0.019505
2022-01-21 19:00:20,139 iteration 2421 : loss : 0.040656, loss_ce: 0.014231
2022-01-21 19:00:21,525 iteration 2422 : loss : 0.035627, loss_ce: 0.013433
2022-01-21 19:00:22,858 iteration 2423 : loss : 0.030999, loss_ce: 0.010091
2022-01-21 19:00:24,170 iteration 2424 : loss : 0.024139, loss_ce: 0.010472
2022-01-21 19:00:25,605 iteration 2425 : loss : 0.034536, loss_ce: 0.009462
2022-01-21 19:00:26,921 iteration 2426 : loss : 0.032434, loss_ce: 0.009340
2022-01-21 19:00:28,159 iteration 2427 : loss : 0.026829, loss_ce: 0.011398
2022-01-21 19:00:29,443 iteration 2428 : loss : 0.029156, loss_ce: 0.008269
2022-01-21 19:00:30,734 iteration 2429 : loss : 0.036577, loss_ce: 0.014494
2022-01-21 19:00:32,025 iteration 2430 : loss : 0.020102, loss_ce: 0.007688
2022-01-21 19:00:33,351 iteration 2431 : loss : 0.030128, loss_ce: 0.016382
 36%|██████████▎                  | 143/400 [58:48<1:42:11, 23.86s/it]2022-01-21 19:00:34,673 iteration 2432 : loss : 0.026435, loss_ce: 0.008568
2022-01-21 19:00:35,985 iteration 2433 : loss : 0.030230, loss_ce: 0.012877
2022-01-21 19:00:37,316 iteration 2434 : loss : 0.029784, loss_ce: 0.010732
2022-01-21 19:00:38,729 iteration 2435 : loss : 0.047778, loss_ce: 0.023377
2022-01-21 19:00:39,976 iteration 2436 : loss : 0.025279, loss_ce: 0.011786
2022-01-21 19:00:41,348 iteration 2437 : loss : 0.028909, loss_ce: 0.010218
2022-01-21 19:00:42,730 iteration 2438 : loss : 0.050035, loss_ce: 0.015271
2022-01-21 19:00:44,095 iteration 2439 : loss : 0.032005, loss_ce: 0.010127
2022-01-21 19:00:45,478 iteration 2440 : loss : 0.046202, loss_ce: 0.017798
2022-01-21 19:00:46,796 iteration 2441 : loss : 0.029980, loss_ce: 0.010728
2022-01-21 19:00:48,099 iteration 2442 : loss : 0.029372, loss_ce: 0.013224
2022-01-21 19:00:49,354 iteration 2443 : loss : 0.027859, loss_ce: 0.010420
2022-01-21 19:00:50,676 iteration 2444 : loss : 0.035983, loss_ce: 0.014946
2022-01-21 19:00:52,017 iteration 2445 : loss : 0.035746, loss_ce: 0.013936
2022-01-21 19:00:53,427 iteration 2446 : loss : 0.027428, loss_ce: 0.011519
2022-01-21 19:00:54,691 iteration 2447 : loss : 0.026799, loss_ce: 0.008430
2022-01-21 19:00:56,064 iteration 2448 : loss : 0.025138, loss_ce: 0.008926
 36%|██████████▍                  | 144/400 [59:11<1:40:19, 23.51s/it]2022-01-21 19:00:57,361 iteration 2449 : loss : 0.033780, loss_ce: 0.011597
2022-01-21 19:00:58,622 iteration 2450 : loss : 0.022127, loss_ce: 0.011126
2022-01-21 19:00:59,924 iteration 2451 : loss : 0.027329, loss_ce: 0.008518
2022-01-21 19:01:01,202 iteration 2452 : loss : 0.031753, loss_ce: 0.011769
2022-01-21 19:01:02,531 iteration 2453 : loss : 0.041099, loss_ce: 0.015572
2022-01-21 19:01:03,828 iteration 2454 : loss : 0.034755, loss_ce: 0.014493
2022-01-21 19:01:05,102 iteration 2455 : loss : 0.026537, loss_ce: 0.012922
2022-01-21 19:01:06,361 iteration 2456 : loss : 0.030139, loss_ce: 0.012120
2022-01-21 19:01:07,663 iteration 2457 : loss : 0.030602, loss_ce: 0.011283
2022-01-21 19:01:08,935 iteration 2458 : loss : 0.028210, loss_ce: 0.011467
2022-01-21 19:01:10,163 iteration 2459 : loss : 0.019346, loss_ce: 0.007470
2022-01-21 19:01:11,452 iteration 2460 : loss : 0.032732, loss_ce: 0.008418
2022-01-21 19:01:12,837 iteration 2461 : loss : 0.027065, loss_ce: 0.008979
2022-01-21 19:01:14,188 iteration 2462 : loss : 0.035418, loss_ce: 0.012290
2022-01-21 19:01:15,491 iteration 2463 : loss : 0.028361, loss_ce: 0.012359
2022-01-21 19:01:16,837 iteration 2464 : loss : 0.034843, loss_ce: 0.017017
2022-01-21 19:01:16,837 Training Data Eval:
2022-01-21 19:01:23,361   Average segmentation loss on training set: 0.0211
2022-01-21 19:01:23,361 Validation Data Eval:
2022-01-21 19:01:25,596   Average segmentation loss on validation set: 0.0688
2022-01-21 19:01:26,902 iteration 2465 : loss : 0.030998, loss_ce: 0.012614
 36%|██████████▌                  | 145/400 [59:42<1:49:16, 25.71s/it]2022-01-21 19:01:28,327 iteration 2466 : loss : 0.034995, loss_ce: 0.012864
2022-01-21 19:01:29,728 iteration 2467 : loss : 0.031752, loss_ce: 0.012662
2022-01-21 19:01:31,030 iteration 2468 : loss : 0.029833, loss_ce: 0.012742
2022-01-21 19:01:32,301 iteration 2469 : loss : 0.025908, loss_ce: 0.012277
2022-01-21 19:01:33,615 iteration 2470 : loss : 0.028511, loss_ce: 0.008887
2022-01-21 19:01:35,017 iteration 2471 : loss : 0.039945, loss_ce: 0.014907
2022-01-21 19:01:36,306 iteration 2472 : loss : 0.040466, loss_ce: 0.014892
2022-01-21 19:01:37,682 iteration 2473 : loss : 0.040157, loss_ce: 0.015969
2022-01-21 19:01:38,972 iteration 2474 : loss : 0.027913, loss_ce: 0.010261
2022-01-21 19:01:40,294 iteration 2475 : loss : 0.025680, loss_ce: 0.009510
2022-01-21 19:01:41,563 iteration 2476 : loss : 0.041412, loss_ce: 0.023082
2022-01-21 19:01:42,970 iteration 2477 : loss : 0.038011, loss_ce: 0.014696
2022-01-21 19:01:44,328 iteration 2478 : loss : 0.027037, loss_ce: 0.009879
2022-01-21 19:01:45,572 iteration 2479 : loss : 0.035726, loss_ce: 0.010796
2022-01-21 19:01:46,898 iteration 2480 : loss : 0.032953, loss_ce: 0.012840
2022-01-21 19:01:48,283 iteration 2481 : loss : 0.029468, loss_ce: 0.012313
2022-01-21 19:01:49,576 iteration 2482 : loss : 0.022598, loss_ce: 0.010279
 36%|█████████▊                 | 146/400 [1:00:05<1:44:59, 24.80s/it]2022-01-21 19:01:51,021 iteration 2483 : loss : 0.037410, loss_ce: 0.019201
2022-01-21 19:01:52,375 iteration 2484 : loss : 0.032583, loss_ce: 0.007803
2022-01-21 19:01:53,666 iteration 2485 : loss : 0.026048, loss_ce: 0.011555
2022-01-21 19:01:54,979 iteration 2486 : loss : 0.029396, loss_ce: 0.011260
2022-01-21 19:01:56,283 iteration 2487 : loss : 0.029956, loss_ce: 0.009678
2022-01-21 19:01:57,670 iteration 2488 : loss : 0.036346, loss_ce: 0.012759
2022-01-21 19:01:58,978 iteration 2489 : loss : 0.031896, loss_ce: 0.013490
2022-01-21 19:02:00,346 iteration 2490 : loss : 0.058953, loss_ce: 0.023257
2022-01-21 19:02:01,750 iteration 2491 : loss : 0.041779, loss_ce: 0.023167
2022-01-21 19:02:02,984 iteration 2492 : loss : 0.022872, loss_ce: 0.008756
2022-01-21 19:02:04,332 iteration 2493 : loss : 0.026865, loss_ce: 0.011580
2022-01-21 19:02:05,638 iteration 2494 : loss : 0.041772, loss_ce: 0.012810
2022-01-21 19:02:06,937 iteration 2495 : loss : 0.039834, loss_ce: 0.021918
2022-01-21 19:02:08,443 iteration 2496 : loss : 0.061014, loss_ce: 0.020464
2022-01-21 19:02:09,814 iteration 2497 : loss : 0.043509, loss_ce: 0.017394
2022-01-21 19:02:11,199 iteration 2498 : loss : 0.031765, loss_ce: 0.012175
2022-01-21 19:02:12,465 iteration 2499 : loss : 0.046253, loss_ce: 0.012367
 37%|█████████▉                 | 147/400 [1:00:28<1:42:09, 24.23s/it]2022-01-21 19:02:13,810 iteration 2500 : loss : 0.027584, loss_ce: 0.009961
2022-01-21 19:02:15,127 iteration 2501 : loss : 0.027054, loss_ce: 0.007195
2022-01-21 19:02:16,521 iteration 2502 : loss : 0.047715, loss_ce: 0.017344
2022-01-21 19:02:17,792 iteration 2503 : loss : 0.029881, loss_ce: 0.011225
2022-01-21 19:02:19,084 iteration 2504 : loss : 0.026995, loss_ce: 0.009608
2022-01-21 19:02:20,445 iteration 2505 : loss : 0.044570, loss_ce: 0.018095
2022-01-21 19:02:21,765 iteration 2506 : loss : 0.038118, loss_ce: 0.011909
2022-01-21 19:02:23,040 iteration 2507 : loss : 0.030132, loss_ce: 0.014518
2022-01-21 19:02:24,335 iteration 2508 : loss : 0.026609, loss_ce: 0.009014
2022-01-21 19:02:25,639 iteration 2509 : loss : 0.032376, loss_ce: 0.010965
2022-01-21 19:02:26,929 iteration 2510 : loss : 0.025155, loss_ce: 0.011229
2022-01-21 19:02:28,259 iteration 2511 : loss : 0.030199, loss_ce: 0.013550
2022-01-21 19:02:29,611 iteration 2512 : loss : 0.028517, loss_ce: 0.010510
2022-01-21 19:02:30,991 iteration 2513 : loss : 0.048221, loss_ce: 0.013925
2022-01-21 19:02:32,330 iteration 2514 : loss : 0.032562, loss_ce: 0.010023
2022-01-21 19:02:33,642 iteration 2515 : loss : 0.026158, loss_ce: 0.014784
2022-01-21 19:02:34,946 iteration 2516 : loss : 0.027521, loss_ce: 0.013599
 37%|█████████▉                 | 148/400 [1:00:50<1:39:33, 23.70s/it]2022-01-21 19:02:36,286 iteration 2517 : loss : 0.024786, loss_ce: 0.009703
2022-01-21 19:02:37,610 iteration 2518 : loss : 0.040429, loss_ce: 0.012588
2022-01-21 19:02:38,957 iteration 2519 : loss : 0.028379, loss_ce: 0.009865
2022-01-21 19:02:40,281 iteration 2520 : loss : 0.038139, loss_ce: 0.016427
2022-01-21 19:02:41,590 iteration 2521 : loss : 0.032222, loss_ce: 0.013178
2022-01-21 19:02:42,925 iteration 2522 : loss : 0.037372, loss_ce: 0.020743
2022-01-21 19:02:44,300 iteration 2523 : loss : 0.031446, loss_ce: 0.009776
2022-01-21 19:02:45,606 iteration 2524 : loss : 0.027417, loss_ce: 0.011226
2022-01-21 19:02:46,947 iteration 2525 : loss : 0.026431, loss_ce: 0.012011
2022-01-21 19:02:48,296 iteration 2526 : loss : 0.035025, loss_ce: 0.013871
2022-01-21 19:02:49,627 iteration 2527 : loss : 0.032613, loss_ce: 0.012152
2022-01-21 19:02:50,978 iteration 2528 : loss : 0.042059, loss_ce: 0.017511
2022-01-21 19:02:52,316 iteration 2529 : loss : 0.035741, loss_ce: 0.012936
2022-01-21 19:02:53,655 iteration 2530 : loss : 0.029180, loss_ce: 0.013627
2022-01-21 19:02:55,058 iteration 2531 : loss : 0.040571, loss_ce: 0.015639
2022-01-21 19:02:56,391 iteration 2532 : loss : 0.028676, loss_ce: 0.009479
2022-01-21 19:02:57,733 iteration 2533 : loss : 0.036540, loss_ce: 0.009579
 37%|██████████                 | 149/400 [1:01:13<1:38:00, 23.43s/it]2022-01-21 19:02:59,027 iteration 2534 : loss : 0.031645, loss_ce: 0.013942
2022-01-21 19:03:00,425 iteration 2535 : loss : 0.028887, loss_ce: 0.009198
2022-01-21 19:03:01,714 iteration 2536 : loss : 0.025183, loss_ce: 0.012246
2022-01-21 19:03:03,011 iteration 2537 : loss : 0.028555, loss_ce: 0.011007
2022-01-21 19:03:04,236 iteration 2538 : loss : 0.020741, loss_ce: 0.008734
2022-01-21 19:03:05,583 iteration 2539 : loss : 0.031032, loss_ce: 0.013626
2022-01-21 19:03:06,861 iteration 2540 : loss : 0.025019, loss_ce: 0.008238
2022-01-21 19:03:08,159 iteration 2541 : loss : 0.025346, loss_ce: 0.010964
2022-01-21 19:03:09,419 iteration 2542 : loss : 0.021696, loss_ce: 0.007464
2022-01-21 19:03:10,679 iteration 2543 : loss : 0.026223, loss_ce: 0.008900
2022-01-21 19:03:12,002 iteration 2544 : loss : 0.038614, loss_ce: 0.012595
2022-01-21 19:03:13,443 iteration 2545 : loss : 0.022033, loss_ce: 0.008768
2022-01-21 19:03:14,894 iteration 2546 : loss : 0.039480, loss_ce: 0.018182
2022-01-21 19:03:16,165 iteration 2547 : loss : 0.026922, loss_ce: 0.011889
2022-01-21 19:03:17,519 iteration 2548 : loss : 0.034096, loss_ce: 0.015380
2022-01-21 19:03:18,855 iteration 2549 : loss : 0.053051, loss_ce: 0.019978
2022-01-21 19:03:18,855 Training Data Eval:
2022-01-21 19:03:25,373   Average segmentation loss on training set: 0.0214
2022-01-21 19:03:25,373 Validation Data Eval:
2022-01-21 19:03:27,604   Average segmentation loss on validation set: 0.0948
2022-01-21 19:03:28,893 iteration 2550 : loss : 0.026313, loss_ce: 0.007734
 38%|██████████▏                | 150/400 [1:01:44<1:47:17, 25.75s/it]2022-01-21 19:03:30,239 iteration 2551 : loss : 0.024052, loss_ce: 0.011294
2022-01-21 19:03:31,622 iteration 2552 : loss : 0.022385, loss_ce: 0.009040
2022-01-21 19:03:32,874 iteration 2553 : loss : 0.018439, loss_ce: 0.006071
2022-01-21 19:03:34,199 iteration 2554 : loss : 0.034019, loss_ce: 0.012872
2022-01-21 19:03:35,504 iteration 2555 : loss : 0.037418, loss_ce: 0.009133
2022-01-21 19:03:36,877 iteration 2556 : loss : 0.032040, loss_ce: 0.014978
2022-01-21 19:03:38,186 iteration 2557 : loss : 0.036916, loss_ce: 0.019309
2022-01-21 19:03:39,518 iteration 2558 : loss : 0.035546, loss_ce: 0.019214
2022-01-21 19:03:40,928 iteration 2559 : loss : 0.027111, loss_ce: 0.010687
2022-01-21 19:03:42,251 iteration 2560 : loss : 0.026769, loss_ce: 0.013976
2022-01-21 19:03:43,665 iteration 2561 : loss : 0.035369, loss_ce: 0.013127
2022-01-21 19:03:45,009 iteration 2562 : loss : 0.033769, loss_ce: 0.013656
2022-01-21 19:03:46,368 iteration 2563 : loss : 0.036515, loss_ce: 0.016704
2022-01-21 19:03:47,652 iteration 2564 : loss : 0.029010, loss_ce: 0.012370
2022-01-21 19:03:48,937 iteration 2565 : loss : 0.028480, loss_ce: 0.010209
2022-01-21 19:03:50,239 iteration 2566 : loss : 0.036401, loss_ce: 0.014095
2022-01-21 19:03:51,575 iteration 2567 : loss : 0.040834, loss_ce: 0.012840
 38%|██████████▏                | 151/400 [1:02:07<1:43:01, 24.83s/it]2022-01-21 19:03:52,962 iteration 2568 : loss : 0.039253, loss_ce: 0.017660
2022-01-21 19:03:54,267 iteration 2569 : loss : 0.032958, loss_ce: 0.015158
2022-01-21 19:03:55,575 iteration 2570 : loss : 0.034739, loss_ce: 0.013139
2022-01-21 19:03:56,888 iteration 2571 : loss : 0.022765, loss_ce: 0.008617
2022-01-21 19:03:58,149 iteration 2572 : loss : 0.036686, loss_ce: 0.010743
2022-01-21 19:03:59,417 iteration 2573 : loss : 0.030912, loss_ce: 0.012331
2022-01-21 19:04:00,714 iteration 2574 : loss : 0.035845, loss_ce: 0.012533
2022-01-21 19:04:02,151 iteration 2575 : loss : 0.051398, loss_ce: 0.023835
2022-01-21 19:04:03,492 iteration 2576 : loss : 0.023170, loss_ce: 0.008830
2022-01-21 19:04:04,823 iteration 2577 : loss : 0.032085, loss_ce: 0.012322
2022-01-21 19:04:06,161 iteration 2578 : loss : 0.036100, loss_ce: 0.010553
2022-01-21 19:04:07,425 iteration 2579 : loss : 0.031443, loss_ce: 0.008911
2022-01-21 19:04:08,806 iteration 2580 : loss : 0.043827, loss_ce: 0.010463
2022-01-21 19:04:10,179 iteration 2581 : loss : 0.038901, loss_ce: 0.015401
2022-01-21 19:04:11,581 iteration 2582 : loss : 0.034272, loss_ce: 0.013163
2022-01-21 19:04:12,895 iteration 2583 : loss : 0.021546, loss_ce: 0.008160
2022-01-21 19:04:14,131 iteration 2584 : loss : 0.032379, loss_ce: 0.014193
 38%|██████████▎                | 152/400 [1:02:29<1:39:48, 24.15s/it]2022-01-21 19:04:15,493 iteration 2585 : loss : 0.022416, loss_ce: 0.007023
2022-01-21 19:04:16,828 iteration 2586 : loss : 0.034679, loss_ce: 0.017707
2022-01-21 19:04:18,090 iteration 2587 : loss : 0.028218, loss_ce: 0.011166
2022-01-21 19:04:19,386 iteration 2588 : loss : 0.032188, loss_ce: 0.013901
2022-01-21 19:04:20,748 iteration 2589 : loss : 0.037512, loss_ce: 0.011242
2022-01-21 19:04:22,119 iteration 2590 : loss : 0.028716, loss_ce: 0.011740
2022-01-21 19:04:23,408 iteration 2591 : loss : 0.026543, loss_ce: 0.008004
2022-01-21 19:04:24,701 iteration 2592 : loss : 0.029258, loss_ce: 0.009899
2022-01-21 19:04:26,000 iteration 2593 : loss : 0.026886, loss_ce: 0.011650
2022-01-21 19:04:27,449 iteration 2594 : loss : 0.045478, loss_ce: 0.017065
2022-01-21 19:04:28,812 iteration 2595 : loss : 0.035704, loss_ce: 0.012590
2022-01-21 19:04:30,104 iteration 2596 : loss : 0.023051, loss_ce: 0.010906
2022-01-21 19:04:31,373 iteration 2597 : loss : 0.030633, loss_ce: 0.011104
2022-01-21 19:04:32,672 iteration 2598 : loss : 0.027201, loss_ce: 0.010386
2022-01-21 19:04:33,981 iteration 2599 : loss : 0.028475, loss_ce: 0.006619
2022-01-21 19:04:35,291 iteration 2600 : loss : 0.026858, loss_ce: 0.009750
2022-01-21 19:04:36,556 iteration 2601 : loss : 0.029516, loss_ce: 0.012072
 38%|██████████▎                | 153/400 [1:02:52<1:37:16, 23.63s/it]2022-01-21 19:04:37,941 iteration 2602 : loss : 0.024159, loss_ce: 0.009943
2022-01-21 19:04:39,192 iteration 2603 : loss : 0.020132, loss_ce: 0.008214
2022-01-21 19:04:40,489 iteration 2604 : loss : 0.026146, loss_ce: 0.009789
2022-01-21 19:04:41,931 iteration 2605 : loss : 0.024073, loss_ce: 0.008131
2022-01-21 19:04:43,247 iteration 2606 : loss : 0.030844, loss_ce: 0.011914
2022-01-21 19:04:44,573 iteration 2607 : loss : 0.028861, loss_ce: 0.010361
2022-01-21 19:04:45,836 iteration 2608 : loss : 0.025035, loss_ce: 0.010980
2022-01-21 19:04:47,117 iteration 2609 : loss : 0.029437, loss_ce: 0.008998
2022-01-21 19:04:48,554 iteration 2610 : loss : 0.037430, loss_ce: 0.014694
2022-01-21 19:04:49,850 iteration 2611 : loss : 0.032229, loss_ce: 0.009453
2022-01-21 19:04:51,073 iteration 2612 : loss : 0.024119, loss_ce: 0.011434
2022-01-21 19:04:52,364 iteration 2613 : loss : 0.029783, loss_ce: 0.009293
2022-01-21 19:04:53,743 iteration 2614 : loss : 0.038368, loss_ce: 0.010974
2022-01-21 19:04:55,030 iteration 2615 : loss : 0.024872, loss_ce: 0.009694
2022-01-21 19:04:56,324 iteration 2616 : loss : 0.028303, loss_ce: 0.010725
2022-01-21 19:04:57,723 iteration 2617 : loss : 0.032388, loss_ce: 0.008206
2022-01-21 19:04:59,064 iteration 2618 : loss : 0.047613, loss_ce: 0.022882
 38%|██████████▍                | 154/400 [1:03:14<1:35:30, 23.29s/it]2022-01-21 19:05:00,482 iteration 2619 : loss : 0.031788, loss_ce: 0.008856
2022-01-21 19:05:01,778 iteration 2620 : loss : 0.030433, loss_ce: 0.011895
2022-01-21 19:05:03,132 iteration 2621 : loss : 0.026719, loss_ce: 0.008646
2022-01-21 19:05:04,480 iteration 2622 : loss : 0.042392, loss_ce: 0.022901
2022-01-21 19:05:05,841 iteration 2623 : loss : 0.074445, loss_ce: 0.041951
2022-01-21 19:05:07,122 iteration 2624 : loss : 0.025004, loss_ce: 0.007980
2022-01-21 19:05:08,423 iteration 2625 : loss : 0.026299, loss_ce: 0.010263
2022-01-21 19:05:09,808 iteration 2626 : loss : 0.032064, loss_ce: 0.014296
2022-01-21 19:05:11,159 iteration 2627 : loss : 0.070613, loss_ce: 0.022230
2022-01-21 19:05:12,438 iteration 2628 : loss : 0.028605, loss_ce: 0.010374
2022-01-21 19:05:13,819 iteration 2629 : loss : 0.042112, loss_ce: 0.015270
2022-01-21 19:05:15,092 iteration 2630 : loss : 0.026512, loss_ce: 0.008012
2022-01-21 19:05:16,428 iteration 2631 : loss : 0.026982, loss_ce: 0.011293
2022-01-21 19:05:17,782 iteration 2632 : loss : 0.043037, loss_ce: 0.017073
2022-01-21 19:05:19,066 iteration 2633 : loss : 0.027602, loss_ce: 0.012534
2022-01-21 19:05:20,406 iteration 2634 : loss : 0.028613, loss_ce: 0.010014
2022-01-21 19:05:20,406 Training Data Eval:
2022-01-21 19:05:26,917   Average segmentation loss on training set: 0.0236
2022-01-21 19:05:26,918 Validation Data Eval:
2022-01-21 19:05:29,150   Average segmentation loss on validation set: 0.0716
2022-01-21 19:05:30,538 iteration 2635 : loss : 0.041392, loss_ce: 0.018049
 39%|██████████▍                | 155/400 [1:03:46<1:45:07, 25.75s/it]2022-01-21 19:05:31,863 iteration 2636 : loss : 0.025627, loss_ce: 0.008340
2022-01-21 19:05:33,318 iteration 2637 : loss : 0.057363, loss_ce: 0.015873
2022-01-21 19:05:34,650 iteration 2638 : loss : 0.026477, loss_ce: 0.010352
2022-01-21 19:05:35,866 iteration 2639 : loss : 0.021798, loss_ce: 0.007970
2022-01-21 19:05:37,141 iteration 2640 : loss : 0.027246, loss_ce: 0.010977
2022-01-21 19:05:38,546 iteration 2641 : loss : 0.031121, loss_ce: 0.011379
2022-01-21 19:05:39,920 iteration 2642 : loss : 0.042847, loss_ce: 0.011140
2022-01-21 19:05:41,287 iteration 2643 : loss : 0.044505, loss_ce: 0.013173
2022-01-21 19:05:42,579 iteration 2644 : loss : 0.032584, loss_ce: 0.009723
2022-01-21 19:05:43,869 iteration 2645 : loss : 0.025667, loss_ce: 0.012608
2022-01-21 19:05:45,171 iteration 2646 : loss : 0.040639, loss_ce: 0.013715
2022-01-21 19:05:46,541 iteration 2647 : loss : 0.035827, loss_ce: 0.017648
2022-01-21 19:05:47,785 iteration 2648 : loss : 0.020588, loss_ce: 0.009279
2022-01-21 19:05:49,140 iteration 2649 : loss : 0.058902, loss_ce: 0.023085
2022-01-21 19:05:50,493 iteration 2650 : loss : 0.037347, loss_ce: 0.014795
2022-01-21 19:05:51,790 iteration 2651 : loss : 0.039902, loss_ce: 0.015283
2022-01-21 19:05:53,115 iteration 2652 : loss : 0.031203, loss_ce: 0.014192
 39%|██████████▌                | 156/400 [1:04:08<1:40:50, 24.80s/it]2022-01-21 19:05:54,571 iteration 2653 : loss : 0.035189, loss_ce: 0.014378
2022-01-21 19:05:55,897 iteration 2654 : loss : 0.027011, loss_ce: 0.010724
2022-01-21 19:05:57,166 iteration 2655 : loss : 0.023047, loss_ce: 0.008262
2022-01-21 19:05:58,413 iteration 2656 : loss : 0.026909, loss_ce: 0.011836
2022-01-21 19:05:59,679 iteration 2657 : loss : 0.029767, loss_ce: 0.011410
2022-01-21 19:06:00,964 iteration 2658 : loss : 0.023374, loss_ce: 0.009977
2022-01-21 19:06:02,397 iteration 2659 : loss : 0.029542, loss_ce: 0.013582
2022-01-21 19:06:03,716 iteration 2660 : loss : 0.027336, loss_ce: 0.010029
2022-01-21 19:06:04,953 iteration 2661 : loss : 0.030823, loss_ce: 0.012881
2022-01-21 19:06:06,318 iteration 2662 : loss : 0.030333, loss_ce: 0.012824
2022-01-21 19:06:07,592 iteration 2663 : loss : 0.036526, loss_ce: 0.016080
2022-01-21 19:06:08,972 iteration 2664 : loss : 0.022966, loss_ce: 0.007643
2022-01-21 19:06:10,273 iteration 2665 : loss : 0.024203, loss_ce: 0.009220
2022-01-21 19:06:11,601 iteration 2666 : loss : 0.031378, loss_ce: 0.009654
2022-01-21 19:06:12,955 iteration 2667 : loss : 0.019982, loss_ce: 0.007792
2022-01-21 19:06:14,304 iteration 2668 : loss : 0.031452, loss_ce: 0.011065
2022-01-21 19:06:15,672 iteration 2669 : loss : 0.056803, loss_ce: 0.021476
 39%|██████████▌                | 157/400 [1:04:31<1:37:42, 24.13s/it]2022-01-21 19:06:17,059 iteration 2670 : loss : 0.055362, loss_ce: 0.018999
2022-01-21 19:06:18,405 iteration 2671 : loss : 0.028658, loss_ce: 0.008572
2022-01-21 19:06:19,756 iteration 2672 : loss : 0.033915, loss_ce: 0.015132
2022-01-21 19:06:21,132 iteration 2673 : loss : 0.042751, loss_ce: 0.013555
2022-01-21 19:06:22,420 iteration 2674 : loss : 0.029087, loss_ce: 0.014170
2022-01-21 19:06:23,799 iteration 2675 : loss : 0.030672, loss_ce: 0.010580
2022-01-21 19:06:25,143 iteration 2676 : loss : 0.031438, loss_ce: 0.008561
2022-01-21 19:06:26,405 iteration 2677 : loss : 0.041072, loss_ce: 0.018622
2022-01-21 19:06:27,655 iteration 2678 : loss : 0.022021, loss_ce: 0.006858
2022-01-21 19:06:29,004 iteration 2679 : loss : 0.029277, loss_ce: 0.011901
2022-01-21 19:06:30,384 iteration 2680 : loss : 0.037410, loss_ce: 0.020474
2022-01-21 19:06:31,696 iteration 2681 : loss : 0.030241, loss_ce: 0.015201
2022-01-21 19:06:32,961 iteration 2682 : loss : 0.029340, loss_ce: 0.010850
2022-01-21 19:06:34,292 iteration 2683 : loss : 0.033240, loss_ce: 0.014951
2022-01-21 19:06:35,612 iteration 2684 : loss : 0.037548, loss_ce: 0.010512
2022-01-21 19:06:36,943 iteration 2685 : loss : 0.029140, loss_ce: 0.013467
2022-01-21 19:06:38,254 iteration 2686 : loss : 0.022458, loss_ce: 0.008206
 40%|██████████▋                | 158/400 [1:04:53<1:35:26, 23.66s/it]2022-01-21 19:06:39,590 iteration 2687 : loss : 0.017948, loss_ce: 0.007632
2022-01-21 19:06:40,891 iteration 2688 : loss : 0.034395, loss_ce: 0.012608
2022-01-21 19:06:42,103 iteration 2689 : loss : 0.024034, loss_ce: 0.008630
2022-01-21 19:06:43,404 iteration 2690 : loss : 0.026631, loss_ce: 0.011508
2022-01-21 19:06:44,740 iteration 2691 : loss : 0.025707, loss_ce: 0.008960
2022-01-21 19:06:46,050 iteration 2692 : loss : 0.025594, loss_ce: 0.007771
2022-01-21 19:06:47,332 iteration 2693 : loss : 0.030291, loss_ce: 0.010865
2022-01-21 19:06:48,563 iteration 2694 : loss : 0.026745, loss_ce: 0.009401
2022-01-21 19:06:49,925 iteration 2695 : loss : 0.050039, loss_ce: 0.018210
2022-01-21 19:06:51,348 iteration 2696 : loss : 0.039168, loss_ce: 0.016558
2022-01-21 19:06:52,727 iteration 2697 : loss : 0.024949, loss_ce: 0.013077
2022-01-21 19:06:53,993 iteration 2698 : loss : 0.019208, loss_ce: 0.007669
2022-01-21 19:06:55,276 iteration 2699 : loss : 0.025257, loss_ce: 0.008431
2022-01-21 19:06:56,554 iteration 2700 : loss : 0.037697, loss_ce: 0.010725
2022-01-21 19:06:57,877 iteration 2701 : loss : 0.034212, loss_ce: 0.016154
2022-01-21 19:06:59,234 iteration 2702 : loss : 0.038337, loss_ce: 0.009008
2022-01-21 19:07:00,594 iteration 2703 : loss : 0.043917, loss_ce: 0.017855
 40%|██████████▋                | 159/400 [1:05:16<1:33:26, 23.26s/it]2022-01-21 19:07:01,902 iteration 2704 : loss : 0.019768, loss_ce: 0.005752
2022-01-21 19:07:03,170 iteration 2705 : loss : 0.033124, loss_ce: 0.013767
2022-01-21 19:07:04,518 iteration 2706 : loss : 0.040677, loss_ce: 0.019876
2022-01-21 19:07:05,831 iteration 2707 : loss : 0.026664, loss_ce: 0.009645
2022-01-21 19:07:07,128 iteration 2708 : loss : 0.032746, loss_ce: 0.011272
2022-01-21 19:07:08,511 iteration 2709 : loss : 0.045381, loss_ce: 0.014821
2022-01-21 19:07:09,880 iteration 2710 : loss : 0.034555, loss_ce: 0.014763
2022-01-21 19:07:11,175 iteration 2711 : loss : 0.022033, loss_ce: 0.007535
2022-01-21 19:07:12,482 iteration 2712 : loss : 0.030352, loss_ce: 0.009762
2022-01-21 19:07:13,815 iteration 2713 : loss : 0.022193, loss_ce: 0.008399
2022-01-21 19:07:15,140 iteration 2714 : loss : 0.031645, loss_ce: 0.015015
2022-01-21 19:07:16,447 iteration 2715 : loss : 0.023848, loss_ce: 0.013197
2022-01-21 19:07:17,755 iteration 2716 : loss : 0.065248, loss_ce: 0.020293
2022-01-21 19:07:19,011 iteration 2717 : loss : 0.025335, loss_ce: 0.009403
2022-01-21 19:07:20,358 iteration 2718 : loss : 0.030956, loss_ce: 0.011202
2022-01-21 19:07:21,649 iteration 2719 : loss : 0.021599, loss_ce: 0.009241
2022-01-21 19:07:21,649 Training Data Eval:
2022-01-21 19:07:28,174   Average segmentation loss on training set: 0.0198
2022-01-21 19:07:28,215 Validation Data Eval:
2022-01-21 19:07:30,450   Average segmentation loss on validation set: 0.0726
2022-01-21 19:07:31,749 iteration 2720 : loss : 0.024490, loss_ce: 0.009844
 40%|██████████▊                | 160/400 [1:05:47<1:42:30, 25.63s/it]2022-01-21 19:07:33,109 iteration 2721 : loss : 0.037023, loss_ce: 0.015643
2022-01-21 19:07:34,457 iteration 2722 : loss : 0.025866, loss_ce: 0.012591
2022-01-21 19:07:35,852 iteration 2723 : loss : 0.032480, loss_ce: 0.015285
2022-01-21 19:07:37,122 iteration 2724 : loss : 0.029458, loss_ce: 0.009117
2022-01-21 19:07:38,417 iteration 2725 : loss : 0.042351, loss_ce: 0.012787
2022-01-21 19:07:39,804 iteration 2726 : loss : 0.026915, loss_ce: 0.009122
2022-01-21 19:07:41,121 iteration 2727 : loss : 0.025547, loss_ce: 0.009047
2022-01-21 19:07:42,483 iteration 2728 : loss : 0.033102, loss_ce: 0.014703
2022-01-21 19:07:43,837 iteration 2729 : loss : 0.036352, loss_ce: 0.016167
2022-01-21 19:07:45,227 iteration 2730 : loss : 0.039288, loss_ce: 0.015816
2022-01-21 19:07:46,541 iteration 2731 : loss : 0.029466, loss_ce: 0.011587
2022-01-21 19:07:47,773 iteration 2732 : loss : 0.021758, loss_ce: 0.008530
2022-01-21 19:07:49,083 iteration 2733 : loss : 0.024295, loss_ce: 0.010618
2022-01-21 19:07:50,411 iteration 2734 : loss : 0.050859, loss_ce: 0.014142
2022-01-21 19:07:51,738 iteration 2735 : loss : 0.029808, loss_ce: 0.014788
2022-01-21 19:07:53,040 iteration 2736 : loss : 0.027903, loss_ce: 0.009178
2022-01-21 19:07:54,342 iteration 2737 : loss : 0.027270, loss_ce: 0.007186
 40%|██████████▊                | 161/400 [1:06:09<1:38:27, 24.72s/it]2022-01-21 19:07:55,747 iteration 2738 : loss : 0.051627, loss_ce: 0.032361
2022-01-21 19:07:57,017 iteration 2739 : loss : 0.022632, loss_ce: 0.006836
2022-01-21 19:07:58,422 iteration 2740 : loss : 0.034613, loss_ce: 0.012937
2022-01-21 19:07:59,740 iteration 2741 : loss : 0.034451, loss_ce: 0.014712
2022-01-21 19:08:01,074 iteration 2742 : loss : 0.026986, loss_ce: 0.010281
2022-01-21 19:08:02,336 iteration 2743 : loss : 0.025583, loss_ce: 0.009243
2022-01-21 19:08:03,649 iteration 2744 : loss : 0.019308, loss_ce: 0.006501
2022-01-21 19:08:04,924 iteration 2745 : loss : 0.023428, loss_ce: 0.007243
2022-01-21 19:08:06,338 iteration 2746 : loss : 0.048153, loss_ce: 0.011069
2022-01-21 19:08:07,633 iteration 2747 : loss : 0.024790, loss_ce: 0.011308
2022-01-21 19:08:08,996 iteration 2748 : loss : 0.026673, loss_ce: 0.006735
2022-01-21 19:08:10,390 iteration 2749 : loss : 0.027594, loss_ce: 0.011448
2022-01-21 19:08:11,702 iteration 2750 : loss : 0.032465, loss_ce: 0.013348
2022-01-21 19:08:13,021 iteration 2751 : loss : 0.032913, loss_ce: 0.009049
2022-01-21 19:08:14,438 iteration 2752 : loss : 0.041800, loss_ce: 0.016107
2022-01-21 19:08:15,862 iteration 2753 : loss : 0.037812, loss_ce: 0.015788
2022-01-21 19:08:17,202 iteration 2754 : loss : 0.026874, loss_ce: 0.013637
 40%|██████████▉                | 162/400 [1:06:32<1:35:50, 24.16s/it]2022-01-21 19:08:18,438 iteration 2755 : loss : 0.020782, loss_ce: 0.006503
2022-01-21 19:08:19,769 iteration 2756 : loss : 0.025945, loss_ce: 0.010357
2022-01-21 19:08:21,091 iteration 2757 : loss : 0.030121, loss_ce: 0.015113
2022-01-21 19:08:22,410 iteration 2758 : loss : 0.026560, loss_ce: 0.009676
2022-01-21 19:08:23,728 iteration 2759 : loss : 0.031154, loss_ce: 0.011193
2022-01-21 19:08:25,051 iteration 2760 : loss : 0.026037, loss_ce: 0.013003
2022-01-21 19:08:26,413 iteration 2761 : loss : 0.029291, loss_ce: 0.009977
2022-01-21 19:08:27,727 iteration 2762 : loss : 0.023784, loss_ce: 0.010751
2022-01-21 19:08:29,079 iteration 2763 : loss : 0.035625, loss_ce: 0.011848
2022-01-21 19:08:30,340 iteration 2764 : loss : 0.018937, loss_ce: 0.006843
2022-01-21 19:08:31,762 iteration 2765 : loss : 0.021328, loss_ce: 0.006717
2022-01-21 19:08:33,012 iteration 2766 : loss : 0.022315, loss_ce: 0.006987
2022-01-21 19:08:34,344 iteration 2767 : loss : 0.029979, loss_ce: 0.011826
2022-01-21 19:08:35,640 iteration 2768 : loss : 0.026335, loss_ce: 0.010027
2022-01-21 19:08:36,889 iteration 2769 : loss : 0.023866, loss_ce: 0.009981
2022-01-21 19:08:38,173 iteration 2770 : loss : 0.028472, loss_ce: 0.011966
2022-01-21 19:08:39,488 iteration 2771 : loss : 0.023646, loss_ce: 0.009922
 41%|███████████                | 163/400 [1:06:55<1:33:13, 23.60s/it]2022-01-21 19:08:40,778 iteration 2772 : loss : 0.028662, loss_ce: 0.009524
2022-01-21 19:08:42,108 iteration 2773 : loss : 0.022336, loss_ce: 0.008818
2022-01-21 19:08:43,433 iteration 2774 : loss : 0.029408, loss_ce: 0.006810
2022-01-21 19:08:44,772 iteration 2775 : loss : 0.026927, loss_ce: 0.011726
2022-01-21 19:08:46,073 iteration 2776 : loss : 0.025774, loss_ce: 0.010225
2022-01-21 19:08:47,455 iteration 2777 : loss : 0.023790, loss_ce: 0.008993
2022-01-21 19:08:48,734 iteration 2778 : loss : 0.023556, loss_ce: 0.007622
2022-01-21 19:08:50,020 iteration 2779 : loss : 0.024153, loss_ce: 0.009699
2022-01-21 19:08:51,325 iteration 2780 : loss : 0.022851, loss_ce: 0.012325
2022-01-21 19:08:52,764 iteration 2781 : loss : 0.033548, loss_ce: 0.012908
2022-01-21 19:08:54,160 iteration 2782 : loss : 0.021613, loss_ce: 0.009933
2022-01-21 19:08:55,469 iteration 2783 : loss : 0.028073, loss_ce: 0.008029
2022-01-21 19:08:56,683 iteration 2784 : loss : 0.021197, loss_ce: 0.005459
2022-01-21 19:08:57,951 iteration 2785 : loss : 0.022495, loss_ce: 0.010003
2022-01-21 19:08:59,208 iteration 2786 : loss : 0.022431, loss_ce: 0.009295
2022-01-21 19:09:00,489 iteration 2787 : loss : 0.019686, loss_ce: 0.007737
2022-01-21 19:09:01,931 iteration 2788 : loss : 0.040914, loss_ce: 0.017319
 41%|███████████                | 164/400 [1:07:17<1:31:27, 23.25s/it]2022-01-21 19:09:03,309 iteration 2789 : loss : 0.021167, loss_ce: 0.006991
2022-01-21 19:09:04,720 iteration 2790 : loss : 0.051718, loss_ce: 0.022578
2022-01-21 19:09:05,978 iteration 2791 : loss : 0.021077, loss_ce: 0.006374
2022-01-21 19:09:07,277 iteration 2792 : loss : 0.025120, loss_ce: 0.010211
2022-01-21 19:09:08,595 iteration 2793 : loss : 0.040944, loss_ce: 0.014376
2022-01-21 19:09:09,969 iteration 2794 : loss : 0.029519, loss_ce: 0.013943
2022-01-21 19:09:11,280 iteration 2795 : loss : 0.033542, loss_ce: 0.014194
2022-01-21 19:09:12,567 iteration 2796 : loss : 0.032573, loss_ce: 0.010257
2022-01-21 19:09:13,926 iteration 2797 : loss : 0.025694, loss_ce: 0.012537
2022-01-21 19:09:15,267 iteration 2798 : loss : 0.034758, loss_ce: 0.009159
2022-01-21 19:09:16,679 iteration 2799 : loss : 0.032093, loss_ce: 0.010828
2022-01-21 19:09:18,019 iteration 2800 : loss : 0.041704, loss_ce: 0.021351
2022-01-21 19:09:19,256 iteration 2801 : loss : 0.024048, loss_ce: 0.007468
2022-01-21 19:09:20,532 iteration 2802 : loss : 0.018935, loss_ce: 0.005732
2022-01-21 19:09:21,870 iteration 2803 : loss : 0.038068, loss_ce: 0.018419
2022-01-21 19:09:23,105 iteration 2804 : loss : 0.025491, loss_ce: 0.010160
2022-01-21 19:09:23,105 Training Data Eval:
2022-01-21 19:09:29,642   Average segmentation loss on training set: 0.0183
2022-01-21 19:09:29,643 Validation Data Eval:
2022-01-21 19:09:31,873   Average segmentation loss on validation set: 0.0758
2022-01-21 19:09:33,283 iteration 2805 : loss : 0.036293, loss_ce: 0.012684
 41%|███████████▏               | 165/400 [1:07:48<1:40:35, 25.68s/it]2022-01-21 19:09:34,718 iteration 2806 : loss : 0.026101, loss_ce: 0.010259
2022-01-21 19:09:36,124 iteration 2807 : loss : 0.032028, loss_ce: 0.010163
2022-01-21 19:09:37,498 iteration 2808 : loss : 0.037641, loss_ce: 0.011422
2022-01-21 19:09:38,843 iteration 2809 : loss : 0.032420, loss_ce: 0.013002
2022-01-21 19:09:40,098 iteration 2810 : loss : 0.038669, loss_ce: 0.012018
2022-01-21 19:09:41,464 iteration 2811 : loss : 0.030193, loss_ce: 0.016562
2022-01-21 19:09:42,719 iteration 2812 : loss : 0.016993, loss_ce: 0.007094
2022-01-21 19:09:44,106 iteration 2813 : loss : 0.045050, loss_ce: 0.019302
2022-01-21 19:09:45,440 iteration 2814 : loss : 0.024939, loss_ce: 0.009264
2022-01-21 19:09:46,758 iteration 2815 : loss : 0.029908, loss_ce: 0.014203
2022-01-21 19:09:48,077 iteration 2816 : loss : 0.025007, loss_ce: 0.008835
2022-01-21 19:09:49,477 iteration 2817 : loss : 0.035951, loss_ce: 0.008070
2022-01-21 19:09:50,858 iteration 2818 : loss : 0.040768, loss_ce: 0.016666
2022-01-21 19:09:52,161 iteration 2819 : loss : 0.031442, loss_ce: 0.013730
2022-01-21 19:09:53,583 iteration 2820 : loss : 0.050785, loss_ce: 0.014760
2022-01-21 19:09:54,978 iteration 2821 : loss : 0.044226, loss_ce: 0.015407
2022-01-21 19:09:56,341 iteration 2822 : loss : 0.031828, loss_ce: 0.012784
 42%|███████████▏               | 166/400 [1:08:11<1:37:05, 24.90s/it]2022-01-21 19:09:57,813 iteration 2823 : loss : 0.034421, loss_ce: 0.013775
2022-01-21 19:09:59,114 iteration 2824 : loss : 0.023605, loss_ce: 0.010548
2022-01-21 19:10:00,450 iteration 2825 : loss : 0.045262, loss_ce: 0.020991
2022-01-21 19:10:01,880 iteration 2826 : loss : 0.036175, loss_ce: 0.013845
2022-01-21 19:10:03,329 iteration 2827 : loss : 0.035309, loss_ce: 0.011725
2022-01-21 19:10:04,685 iteration 2828 : loss : 0.027741, loss_ce: 0.009510
2022-01-21 19:10:06,007 iteration 2829 : loss : 0.031044, loss_ce: 0.014501
2022-01-21 19:10:07,323 iteration 2830 : loss : 0.032283, loss_ce: 0.010606
2022-01-21 19:10:08,552 iteration 2831 : loss : 0.024271, loss_ce: 0.010726
2022-01-21 19:10:10,007 iteration 2832 : loss : 0.033097, loss_ce: 0.013337
2022-01-21 19:10:11,318 iteration 2833 : loss : 0.033396, loss_ce: 0.012202
2022-01-21 19:10:12,708 iteration 2834 : loss : 0.031984, loss_ce: 0.011201
2022-01-21 19:10:14,067 iteration 2835 : loss : 0.039778, loss_ce: 0.012493
2022-01-21 19:10:15,392 iteration 2836 : loss : 0.026348, loss_ce: 0.009696
2022-01-21 19:10:16,786 iteration 2837 : loss : 0.035854, loss_ce: 0.014286
2022-01-21 19:10:18,050 iteration 2838 : loss : 0.018008, loss_ce: 0.007706
2022-01-21 19:10:19,415 iteration 2839 : loss : 0.021109, loss_ce: 0.007137
 42%|███████████▎               | 167/400 [1:08:35<1:34:33, 24.35s/it]2022-01-21 19:10:20,841 iteration 2840 : loss : 0.037234, loss_ce: 0.016596
2022-01-21 19:10:22,156 iteration 2841 : loss : 0.026288, loss_ce: 0.007712
2022-01-21 19:10:23,474 iteration 2842 : loss : 0.026427, loss_ce: 0.010239
2022-01-21 19:10:24,849 iteration 2843 : loss : 0.032057, loss_ce: 0.010606
2022-01-21 19:10:26,193 iteration 2844 : loss : 0.031137, loss_ce: 0.013353
2022-01-21 19:10:27,519 iteration 2845 : loss : 0.033541, loss_ce: 0.012857
2022-01-21 19:10:28,852 iteration 2846 : loss : 0.020516, loss_ce: 0.006987
2022-01-21 19:10:30,058 iteration 2847 : loss : 0.017258, loss_ce: 0.009042
2022-01-21 19:10:31,398 iteration 2848 : loss : 0.029263, loss_ce: 0.009895
2022-01-21 19:10:32,779 iteration 2849 : loss : 0.024626, loss_ce: 0.009691
2022-01-21 19:10:34,157 iteration 2850 : loss : 0.028564, loss_ce: 0.011825
2022-01-21 19:10:35,538 iteration 2851 : loss : 0.023875, loss_ce: 0.008858
2022-01-21 19:10:36,887 iteration 2852 : loss : 0.031075, loss_ce: 0.009314
2022-01-21 19:10:38,278 iteration 2853 : loss : 0.021577, loss_ce: 0.008259
2022-01-21 19:10:39,633 iteration 2854 : loss : 0.027985, loss_ce: 0.009118
2022-01-21 19:10:40,930 iteration 2855 : loss : 0.033664, loss_ce: 0.018755
2022-01-21 19:10:42,296 iteration 2856 : loss : 0.031591, loss_ce: 0.015860
 42%|███████████▎               | 168/400 [1:08:57<1:32:26, 23.91s/it]2022-01-21 19:10:43,578 iteration 2857 : loss : 0.024051, loss_ce: 0.008517
2022-01-21 19:10:44,914 iteration 2858 : loss : 0.023545, loss_ce: 0.010579
2022-01-21 19:10:46,206 iteration 2859 : loss : 0.019087, loss_ce: 0.007637
2022-01-21 19:10:47,569 iteration 2860 : loss : 0.030555, loss_ce: 0.010151
2022-01-21 19:10:48,809 iteration 2861 : loss : 0.027589, loss_ce: 0.012236
2022-01-21 19:10:50,221 iteration 2862 : loss : 0.055865, loss_ce: 0.017830
2022-01-21 19:10:51,500 iteration 2863 : loss : 0.034670, loss_ce: 0.009379
2022-01-21 19:10:52,854 iteration 2864 : loss : 0.025037, loss_ce: 0.009561
2022-01-21 19:10:54,221 iteration 2865 : loss : 0.045375, loss_ce: 0.016701
2022-01-21 19:10:55,528 iteration 2866 : loss : 0.035688, loss_ce: 0.012740
2022-01-21 19:10:56,958 iteration 2867 : loss : 0.027968, loss_ce: 0.011143
2022-01-21 19:10:58,246 iteration 2868 : loss : 0.036071, loss_ce: 0.013204
2022-01-21 19:10:59,659 iteration 2869 : loss : 0.035053, loss_ce: 0.012600
2022-01-21 19:11:01,014 iteration 2870 : loss : 0.025019, loss_ce: 0.008027
2022-01-21 19:11:02,307 iteration 2871 : loss : 0.024202, loss_ce: 0.008952
2022-01-21 19:11:03,559 iteration 2872 : loss : 0.028046, loss_ce: 0.011155
2022-01-21 19:11:04,934 iteration 2873 : loss : 0.031056, loss_ce: 0.011483
 42%|███████████▍               | 169/400 [1:09:20<1:30:35, 23.53s/it]2022-01-21 19:11:06,341 iteration 2874 : loss : 0.032110, loss_ce: 0.010314
2022-01-21 19:11:07,688 iteration 2875 : loss : 0.025068, loss_ce: 0.010547
2022-01-21 19:11:09,021 iteration 2876 : loss : 0.031808, loss_ce: 0.013276
2022-01-21 19:11:10,405 iteration 2877 : loss : 0.032446, loss_ce: 0.008863
2022-01-21 19:11:11,736 iteration 2878 : loss : 0.027532, loss_ce: 0.013000
2022-01-21 19:11:13,115 iteration 2879 : loss : 0.029123, loss_ce: 0.009972
2022-01-21 19:11:14,506 iteration 2880 : loss : 0.035663, loss_ce: 0.010826
2022-01-21 19:11:15,847 iteration 2881 : loss : 0.025838, loss_ce: 0.010510
2022-01-21 19:11:17,237 iteration 2882 : loss : 0.031954, loss_ce: 0.018641
2022-01-21 19:11:18,537 iteration 2883 : loss : 0.031185, loss_ce: 0.012804
2022-01-21 19:11:19,852 iteration 2884 : loss : 0.032066, loss_ce: 0.015643
2022-01-21 19:11:21,203 iteration 2885 : loss : 0.033881, loss_ce: 0.014365
2022-01-21 19:11:22,451 iteration 2886 : loss : 0.028945, loss_ce: 0.009515
2022-01-21 19:11:23,849 iteration 2887 : loss : 0.028050, loss_ce: 0.013743
2022-01-21 19:11:25,191 iteration 2888 : loss : 0.051167, loss_ce: 0.012680
2022-01-21 19:11:26,630 iteration 2889 : loss : 0.048982, loss_ce: 0.021604
2022-01-21 19:11:26,630 Training Data Eval:
2022-01-21 19:11:33,153   Average segmentation loss on training set: 0.0178
2022-01-21 19:11:33,154 Validation Data Eval:
2022-01-21 19:11:35,383   Average segmentation loss on validation set: 0.0603
2022-01-21 19:11:39,511 Found new lowest validation loss at iteration 2889! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 19:11:40,797 iteration 2890 : loss : 0.025751, loss_ce: 0.009145
 42%|███████████▍               | 170/400 [1:09:56<1:44:22, 27.23s/it]2022-01-21 19:11:42,092 iteration 2891 : loss : 0.022467, loss_ce: 0.009497
2022-01-21 19:11:43,401 iteration 2892 : loss : 0.045197, loss_ce: 0.014241
2022-01-21 19:11:44,589 iteration 2893 : loss : 0.030314, loss_ce: 0.010481
2022-01-21 19:11:45,910 iteration 2894 : loss : 0.034188, loss_ce: 0.010093
2022-01-21 19:11:47,270 iteration 2895 : loss : 0.034071, loss_ce: 0.015275
2022-01-21 19:11:48,570 iteration 2896 : loss : 0.019834, loss_ce: 0.006720
2022-01-21 19:11:49,906 iteration 2897 : loss : 0.034030, loss_ce: 0.013215
2022-01-21 19:11:51,180 iteration 2898 : loss : 0.026912, loss_ce: 0.012726
2022-01-21 19:11:52,537 iteration 2899 : loss : 0.032415, loss_ce: 0.011935
2022-01-21 19:11:53,859 iteration 2900 : loss : 0.022306, loss_ce: 0.007610
2022-01-21 19:11:55,199 iteration 2901 : loss : 0.024662, loss_ce: 0.007000
2022-01-21 19:11:56,461 iteration 2902 : loss : 0.028552, loss_ce: 0.009342
2022-01-21 19:11:57,750 iteration 2903 : loss : 0.027460, loss_ce: 0.012839
2022-01-21 19:11:59,032 iteration 2904 : loss : 0.030028, loss_ce: 0.011382
2022-01-21 19:12:00,285 iteration 2905 : loss : 0.024700, loss_ce: 0.012774
2022-01-21 19:12:01,648 iteration 2906 : loss : 0.028005, loss_ce: 0.015034
2022-01-21 19:12:02,938 iteration 2907 : loss : 0.030873, loss_ce: 0.011920
 43%|███████████▌               | 171/400 [1:10:18<1:38:06, 25.70s/it]2022-01-21 19:12:04,344 iteration 2908 : loss : 0.031214, loss_ce: 0.015126
2022-01-21 19:12:05,729 iteration 2909 : loss : 0.041631, loss_ce: 0.023473
2022-01-21 19:12:07,068 iteration 2910 : loss : 0.027144, loss_ce: 0.011406
2022-01-21 19:12:08,443 iteration 2911 : loss : 0.029322, loss_ce: 0.010600
2022-01-21 19:12:09,743 iteration 2912 : loss : 0.029832, loss_ce: 0.012819
2022-01-21 19:12:11,143 iteration 2913 : loss : 0.041508, loss_ce: 0.019228
2022-01-21 19:12:12,450 iteration 2914 : loss : 0.038358, loss_ce: 0.012756
2022-01-21 19:12:13,768 iteration 2915 : loss : 0.021029, loss_ce: 0.008114
2022-01-21 19:12:15,112 iteration 2916 : loss : 0.029794, loss_ce: 0.012778
2022-01-21 19:12:16,379 iteration 2917 : loss : 0.020705, loss_ce: 0.008951
2022-01-21 19:12:17,668 iteration 2918 : loss : 0.019416, loss_ce: 0.004717
2022-01-21 19:12:18,996 iteration 2919 : loss : 0.026914, loss_ce: 0.007191
2022-01-21 19:12:20,349 iteration 2920 : loss : 0.028098, loss_ce: 0.011820
2022-01-21 19:12:21,666 iteration 2921 : loss : 0.031168, loss_ce: 0.016595
2022-01-21 19:12:22,923 iteration 2922 : loss : 0.028414, loss_ce: 0.010305
2022-01-21 19:12:24,219 iteration 2923 : loss : 0.027834, loss_ce: 0.008757
2022-01-21 19:12:25,547 iteration 2924 : loss : 0.047340, loss_ce: 0.018534
 43%|███████████▌               | 172/400 [1:10:41<1:34:08, 24.77s/it]2022-01-21 19:12:26,814 iteration 2925 : loss : 0.019504, loss_ce: 0.009745
2022-01-21 19:12:28,226 iteration 2926 : loss : 0.031116, loss_ce: 0.014349
2022-01-21 19:12:29,547 iteration 2927 : loss : 0.020149, loss_ce: 0.008316
2022-01-21 19:12:30,758 iteration 2928 : loss : 0.023271, loss_ce: 0.007606
2022-01-21 19:12:32,056 iteration 2929 : loss : 0.021853, loss_ce: 0.009547
2022-01-21 19:12:33,459 iteration 2930 : loss : 0.036688, loss_ce: 0.015824
2022-01-21 19:12:34,760 iteration 2931 : loss : 0.028010, loss_ce: 0.011225
2022-01-21 19:12:36,037 iteration 2932 : loss : 0.031781, loss_ce: 0.011341
2022-01-21 19:12:37,433 iteration 2933 : loss : 0.033697, loss_ce: 0.011185
2022-01-21 19:12:38,755 iteration 2934 : loss : 0.026808, loss_ce: 0.008614
2022-01-21 19:12:40,088 iteration 2935 : loss : 0.025108, loss_ce: 0.007817
2022-01-21 19:12:41,406 iteration 2936 : loss : 0.036423, loss_ce: 0.011812
2022-01-21 19:12:42,754 iteration 2937 : loss : 0.027498, loss_ce: 0.012765
2022-01-21 19:12:44,124 iteration 2938 : loss : 0.033351, loss_ce: 0.009413
2022-01-21 19:12:45,498 iteration 2939 : loss : 0.030538, loss_ce: 0.009530
2022-01-21 19:12:46,931 iteration 2940 : loss : 0.069418, loss_ce: 0.040534
2022-01-21 19:12:48,211 iteration 2941 : loss : 0.022112, loss_ce: 0.008413
 43%|███████████▋               | 173/400 [1:11:03<1:31:20, 24.14s/it]2022-01-21 19:12:49,525 iteration 2942 : loss : 0.017964, loss_ce: 0.005691
2022-01-21 19:12:50,880 iteration 2943 : loss : 0.034765, loss_ce: 0.009787
2022-01-21 19:12:52,169 iteration 2944 : loss : 0.023171, loss_ce: 0.011252
2022-01-21 19:12:53,505 iteration 2945 : loss : 0.027349, loss_ce: 0.008181
2022-01-21 19:12:54,730 iteration 2946 : loss : 0.033248, loss_ce: 0.013252
2022-01-21 19:12:56,023 iteration 2947 : loss : 0.033653, loss_ce: 0.012739
2022-01-21 19:12:57,311 iteration 2948 : loss : 0.027419, loss_ce: 0.007688
2022-01-21 19:12:58,696 iteration 2949 : loss : 0.033908, loss_ce: 0.012522
2022-01-21 19:13:00,043 iteration 2950 : loss : 0.020919, loss_ce: 0.008422
2022-01-21 19:13:01,416 iteration 2951 : loss : 0.029212, loss_ce: 0.013448
2022-01-21 19:13:02,774 iteration 2952 : loss : 0.021966, loss_ce: 0.007680
2022-01-21 19:13:04,164 iteration 2953 : loss : 0.041507, loss_ce: 0.018171
2022-01-21 19:13:05,592 iteration 2954 : loss : 0.053191, loss_ce: 0.012416
2022-01-21 19:13:06,887 iteration 2955 : loss : 0.022277, loss_ce: 0.010240
2022-01-21 19:13:08,192 iteration 2956 : loss : 0.019447, loss_ce: 0.007298
2022-01-21 19:13:09,465 iteration 2957 : loss : 0.024004, loss_ce: 0.009259
2022-01-21 19:13:10,800 iteration 2958 : loss : 0.031426, loss_ce: 0.015748
 44%|███████████▋               | 174/400 [1:11:26<1:29:10, 23.67s/it]2022-01-21 19:13:12,141 iteration 2959 : loss : 0.023688, loss_ce: 0.007423
2022-01-21 19:13:13,448 iteration 2960 : loss : 0.025977, loss_ce: 0.011322
2022-01-21 19:13:14,787 iteration 2961 : loss : 0.036651, loss_ce: 0.013733
2022-01-21 19:13:16,270 iteration 2962 : loss : 0.033617, loss_ce: 0.013524
2022-01-21 19:13:17,624 iteration 2963 : loss : 0.029513, loss_ce: 0.010281
2022-01-21 19:13:18,863 iteration 2964 : loss : 0.025775, loss_ce: 0.009905
2022-01-21 19:13:20,198 iteration 2965 : loss : 0.023789, loss_ce: 0.011697
2022-01-21 19:13:21,568 iteration 2966 : loss : 0.027184, loss_ce: 0.009361
2022-01-21 19:13:22,887 iteration 2967 : loss : 0.029254, loss_ce: 0.009951
2022-01-21 19:13:24,217 iteration 2968 : loss : 0.029404, loss_ce: 0.012089
2022-01-21 19:13:25,527 iteration 2969 : loss : 0.022901, loss_ce: 0.010529
2022-01-21 19:13:26,871 iteration 2970 : loss : 0.032147, loss_ce: 0.013157
2022-01-21 19:13:28,179 iteration 2971 : loss : 0.020799, loss_ce: 0.007978
2022-01-21 19:13:29,497 iteration 2972 : loss : 0.026459, loss_ce: 0.012090
2022-01-21 19:13:30,771 iteration 2973 : loss : 0.023944, loss_ce: 0.006436
2022-01-21 19:13:32,147 iteration 2974 : loss : 0.034511, loss_ce: 0.010719
2022-01-21 19:13:32,147 Training Data Eval:
2022-01-21 19:13:38,665   Average segmentation loss on training set: 0.0163
2022-01-21 19:13:38,666 Validation Data Eval:
2022-01-21 19:13:40,902   Average segmentation loss on validation set: 0.0682
2022-01-21 19:13:42,201 iteration 2975 : loss : 0.018658, loss_ce: 0.006924
 44%|███████████▊               | 175/400 [1:11:57<1:37:28, 25.99s/it]2022-01-21 19:13:43,479 iteration 2976 : loss : 0.018413, loss_ce: 0.007887
2022-01-21 19:13:44,834 iteration 2977 : loss : 0.032192, loss_ce: 0.014341
2022-01-21 19:13:46,170 iteration 2978 : loss : 0.029342, loss_ce: 0.013324
2022-01-21 19:13:47,545 iteration 2979 : loss : 0.023317, loss_ce: 0.007453
2022-01-21 19:13:48,909 iteration 2980 : loss : 0.025144, loss_ce: 0.006729
2022-01-21 19:13:50,338 iteration 2981 : loss : 0.053894, loss_ce: 0.021817
2022-01-21 19:13:51,671 iteration 2982 : loss : 0.020271, loss_ce: 0.008141
2022-01-21 19:13:53,016 iteration 2983 : loss : 0.024708, loss_ce: 0.009701
2022-01-21 19:13:54,356 iteration 2984 : loss : 0.036504, loss_ce: 0.012674
2022-01-21 19:13:55,724 iteration 2985 : loss : 0.029877, loss_ce: 0.011475
2022-01-21 19:13:56,994 iteration 2986 : loss : 0.021659, loss_ce: 0.009606
2022-01-21 19:13:58,327 iteration 2987 : loss : 0.030037, loss_ce: 0.009789
2022-01-21 19:13:59,704 iteration 2988 : loss : 0.028412, loss_ce: 0.011638
2022-01-21 19:14:01,074 iteration 2989 : loss : 0.028714, loss_ce: 0.010715
2022-01-21 19:14:02,343 iteration 2990 : loss : 0.019419, loss_ce: 0.007824
2022-01-21 19:14:03,672 iteration 2991 : loss : 0.029157, loss_ce: 0.011839
2022-01-21 19:14:05,064 iteration 2992 : loss : 0.024339, loss_ce: 0.009530
 44%|███████████▉               | 176/400 [1:12:20<1:33:32, 25.05s/it]2022-01-21 19:14:06,378 iteration 2993 : loss : 0.029203, loss_ce: 0.014320
2022-01-21 19:14:07,719 iteration 2994 : loss : 0.038025, loss_ce: 0.008465
2022-01-21 19:14:09,025 iteration 2995 : loss : 0.021303, loss_ce: 0.007014
2022-01-21 19:14:10,343 iteration 2996 : loss : 0.018206, loss_ce: 0.008859
2022-01-21 19:14:11,664 iteration 2997 : loss : 0.028666, loss_ce: 0.008333
2022-01-21 19:14:12,999 iteration 2998 : loss : 0.033808, loss_ce: 0.017795
2022-01-21 19:14:14,384 iteration 2999 : loss : 0.081015, loss_ce: 0.017230
2022-01-21 19:14:15,790 iteration 3000 : loss : 0.038668, loss_ce: 0.015051
2022-01-21 19:14:17,193 iteration 3001 : loss : 0.058432, loss_ce: 0.011060
2022-01-21 19:14:18,469 iteration 3002 : loss : 0.023993, loss_ce: 0.008915
2022-01-21 19:14:19,768 iteration 3003 : loss : 0.027338, loss_ce: 0.009776
2022-01-21 19:14:21,079 iteration 3004 : loss : 0.021318, loss_ce: 0.008646
2022-01-21 19:14:22,412 iteration 3005 : loss : 0.024842, loss_ce: 0.010527
2022-01-21 19:14:23,775 iteration 3006 : loss : 0.026737, loss_ce: 0.011011
2022-01-21 19:14:25,136 iteration 3007 : loss : 0.033397, loss_ce: 0.014053
2022-01-21 19:14:26,498 iteration 3008 : loss : 0.039438, loss_ce: 0.014577
2022-01-21 19:14:27,756 iteration 3009 : loss : 0.029963, loss_ce: 0.013159
 44%|███████████▉               | 177/400 [1:12:43<1:30:29, 24.35s/it]2022-01-21 19:14:29,243 iteration 3010 : loss : 0.036070, loss_ce: 0.011372
2022-01-21 19:14:30,611 iteration 3011 : loss : 0.026352, loss_ce: 0.012282
2022-01-21 19:14:31,892 iteration 3012 : loss : 0.023231, loss_ce: 0.009824
2022-01-21 19:14:33,154 iteration 3013 : loss : 0.045187, loss_ce: 0.016045
2022-01-21 19:14:34,489 iteration 3014 : loss : 0.033195, loss_ce: 0.013316
2022-01-21 19:14:35,807 iteration 3015 : loss : 0.032364, loss_ce: 0.007719
2022-01-21 19:14:37,121 iteration 3016 : loss : 0.039286, loss_ce: 0.015051
2022-01-21 19:14:38,418 iteration 3017 : loss : 0.040727, loss_ce: 0.025310
2022-01-21 19:14:39,709 iteration 3018 : loss : 0.021713, loss_ce: 0.009162
2022-01-21 19:14:40,963 iteration 3019 : loss : 0.022906, loss_ce: 0.008759
2022-01-21 19:14:42,310 iteration 3020 : loss : 0.038007, loss_ce: 0.013102
2022-01-21 19:14:43,647 iteration 3021 : loss : 0.019216, loss_ce: 0.007428
2022-01-21 19:14:44,956 iteration 3022 : loss : 0.024427, loss_ce: 0.009374
2022-01-21 19:14:46,285 iteration 3023 : loss : 0.033759, loss_ce: 0.011620
2022-01-21 19:14:47,696 iteration 3024 : loss : 0.040338, loss_ce: 0.019829
2022-01-21 19:14:49,081 iteration 3025 : loss : 0.030436, loss_ce: 0.013611
2022-01-21 19:14:50,363 iteration 3026 : loss : 0.031852, loss_ce: 0.013584
 44%|████████████               | 178/400 [1:13:05<1:28:08, 23.82s/it]2022-01-21 19:14:51,786 iteration 3027 : loss : 0.039840, loss_ce: 0.014982
2022-01-21 19:14:53,070 iteration 3028 : loss : 0.028394, loss_ce: 0.011942
2022-01-21 19:14:54,413 iteration 3029 : loss : 0.019685, loss_ce: 0.007773
2022-01-21 19:14:55,708 iteration 3030 : loss : 0.026893, loss_ce: 0.011207
2022-01-21 19:14:57,036 iteration 3031 : loss : 0.039186, loss_ce: 0.014433
2022-01-21 19:14:58,322 iteration 3032 : loss : 0.030550, loss_ce: 0.010359
2022-01-21 19:14:59,679 iteration 3033 : loss : 0.036539, loss_ce: 0.011923
2022-01-21 19:15:01,055 iteration 3034 : loss : 0.049389, loss_ce: 0.020934
2022-01-21 19:15:02,406 iteration 3035 : loss : 0.026863, loss_ce: 0.010788
2022-01-21 19:15:03,714 iteration 3036 : loss : 0.031093, loss_ce: 0.016777
2022-01-21 19:15:05,039 iteration 3037 : loss : 0.025403, loss_ce: 0.009368
2022-01-21 19:15:06,400 iteration 3038 : loss : 0.040896, loss_ce: 0.014875
2022-01-21 19:15:07,666 iteration 3039 : loss : 0.035585, loss_ce: 0.010426
2022-01-21 19:15:09,000 iteration 3040 : loss : 0.041450, loss_ce: 0.011416
2022-01-21 19:15:10,403 iteration 3041 : loss : 0.034074, loss_ce: 0.013782
2022-01-21 19:15:11,727 iteration 3042 : loss : 0.026023, loss_ce: 0.011246
2022-01-21 19:15:13,230 iteration 3043 : loss : 0.042645, loss_ce: 0.013158
 45%|████████████               | 179/400 [1:13:28<1:26:41, 23.54s/it]2022-01-21 19:15:14,616 iteration 3044 : loss : 0.037367, loss_ce: 0.015592
2022-01-21 19:15:15,894 iteration 3045 : loss : 0.025277, loss_ce: 0.009092
2022-01-21 19:15:17,194 iteration 3046 : loss : 0.022660, loss_ce: 0.007318
2022-01-21 19:15:18,629 iteration 3047 : loss : 0.033925, loss_ce: 0.017364
2022-01-21 19:15:19,923 iteration 3048 : loss : 0.035347, loss_ce: 0.013206
2022-01-21 19:15:21,253 iteration 3049 : loss : 0.060431, loss_ce: 0.031308
2022-01-21 19:15:22,616 iteration 3050 : loss : 0.028296, loss_ce: 0.013363
2022-01-21 19:15:23,955 iteration 3051 : loss : 0.042772, loss_ce: 0.011379
2022-01-21 19:15:25,271 iteration 3052 : loss : 0.025639, loss_ce: 0.009090
2022-01-21 19:15:26,687 iteration 3053 : loss : 0.023704, loss_ce: 0.010861
2022-01-21 19:15:27,971 iteration 3054 : loss : 0.024911, loss_ce: 0.006889
2022-01-21 19:15:29,326 iteration 3055 : loss : 0.032533, loss_ce: 0.011888
2022-01-21 19:15:30,626 iteration 3056 : loss : 0.026354, loss_ce: 0.010177
2022-01-21 19:15:31,894 iteration 3057 : loss : 0.025081, loss_ce: 0.010082
2022-01-21 19:15:33,238 iteration 3058 : loss : 0.020473, loss_ce: 0.008257
2022-01-21 19:15:34,597 iteration 3059 : loss : 0.025100, loss_ce: 0.008091
2022-01-21 19:15:34,597 Training Data Eval:
2022-01-21 19:15:41,116   Average segmentation loss on training set: 0.0233
2022-01-21 19:15:41,117 Validation Data Eval:
2022-01-21 19:15:43,355   Average segmentation loss on validation set: 0.0641
2022-01-21 19:15:44,647 iteration 3060 : loss : 0.026952, loss_ce: 0.013079
 45%|████████████▏              | 180/400 [1:14:00<1:34:58, 25.90s/it]2022-01-21 19:15:45,932 iteration 3061 : loss : 0.027277, loss_ce: 0.010312
2022-01-21 19:15:47,258 iteration 3062 : loss : 0.034300, loss_ce: 0.012228
2022-01-21 19:15:48,616 iteration 3063 : loss : 0.027854, loss_ce: 0.011432
2022-01-21 19:15:49,979 iteration 3064 : loss : 0.024907, loss_ce: 0.010884
2022-01-21 19:15:51,208 iteration 3065 : loss : 0.019444, loss_ce: 0.006746
2022-01-21 19:15:52,496 iteration 3066 : loss : 0.028181, loss_ce: 0.012941
2022-01-21 19:15:53,842 iteration 3067 : loss : 0.036315, loss_ce: 0.015855
2022-01-21 19:15:55,183 iteration 3068 : loss : 0.030484, loss_ce: 0.010132
2022-01-21 19:15:56,511 iteration 3069 : loss : 0.026445, loss_ce: 0.007693
2022-01-21 19:15:57,844 iteration 3070 : loss : 0.019496, loss_ce: 0.008424
2022-01-21 19:15:59,119 iteration 3071 : loss : 0.021519, loss_ce: 0.007984
2022-01-21 19:16:00,384 iteration 3072 : loss : 0.025991, loss_ce: 0.009496
2022-01-21 19:16:01,697 iteration 3073 : loss : 0.027745, loss_ce: 0.011866
2022-01-21 19:16:03,092 iteration 3074 : loss : 0.028464, loss_ce: 0.012074
2022-01-21 19:16:04,448 iteration 3075 : loss : 0.023722, loss_ce: 0.008398
2022-01-21 19:16:05,844 iteration 3076 : loss : 0.052561, loss_ce: 0.024484
2022-01-21 19:16:07,126 iteration 3077 : loss : 0.036559, loss_ce: 0.013052
 45%|████████████▏              | 181/400 [1:14:22<1:30:47, 24.87s/it]2022-01-21 19:16:08,437 iteration 3078 : loss : 0.021451, loss_ce: 0.008396
2022-01-21 19:16:09,872 iteration 3079 : loss : 0.022101, loss_ce: 0.007680
2022-01-21 19:16:11,124 iteration 3080 : loss : 0.024234, loss_ce: 0.007071
2022-01-21 19:16:12,478 iteration 3081 : loss : 0.032789, loss_ce: 0.011321
2022-01-21 19:16:13,786 iteration 3082 : loss : 0.025459, loss_ce: 0.006514
2022-01-21 19:16:15,171 iteration 3083 : loss : 0.026388, loss_ce: 0.010268
2022-01-21 19:16:16,382 iteration 3084 : loss : 0.021075, loss_ce: 0.008991
2022-01-21 19:16:17,724 iteration 3085 : loss : 0.037048, loss_ce: 0.014916
2022-01-21 19:16:19,150 iteration 3086 : loss : 0.034890, loss_ce: 0.019685
2022-01-21 19:16:20,454 iteration 3087 : loss : 0.028245, loss_ce: 0.011257
2022-01-21 19:16:21,794 iteration 3088 : loss : 0.025967, loss_ce: 0.007833
2022-01-21 19:16:23,212 iteration 3089 : loss : 0.036029, loss_ce: 0.011743
2022-01-21 19:16:24,461 iteration 3090 : loss : 0.023694, loss_ce: 0.010273
2022-01-21 19:16:25,787 iteration 3091 : loss : 0.030794, loss_ce: 0.014991
2022-01-21 19:16:27,255 iteration 3092 : loss : 0.034854, loss_ce: 0.011559
2022-01-21 19:16:28,549 iteration 3093 : loss : 0.022518, loss_ce: 0.010143
2022-01-21 19:16:29,884 iteration 3094 : loss : 0.036099, loss_ce: 0.013667
 46%|████████████▎              | 182/400 [1:14:45<1:28:04, 24.24s/it]2022-01-21 19:16:31,248 iteration 3095 : loss : 0.025562, loss_ce: 0.009711
2022-01-21 19:16:32,593 iteration 3096 : loss : 0.020294, loss_ce: 0.008723
2022-01-21 19:16:33,899 iteration 3097 : loss : 0.020461, loss_ce: 0.007084
2022-01-21 19:16:35,180 iteration 3098 : loss : 0.020659, loss_ce: 0.008377
2022-01-21 19:16:36,504 iteration 3099 : loss : 0.022279, loss_ce: 0.008117
2022-01-21 19:16:37,772 iteration 3100 : loss : 0.038989, loss_ce: 0.012146
2022-01-21 19:16:39,145 iteration 3101 : loss : 0.021864, loss_ce: 0.008238
2022-01-21 19:16:40,470 iteration 3102 : loss : 0.031963, loss_ce: 0.013173
2022-01-21 19:16:41,808 iteration 3103 : loss : 0.026842, loss_ce: 0.010350
2022-01-21 19:16:43,091 iteration 3104 : loss : 0.033943, loss_ce: 0.018892
2022-01-21 19:16:44,351 iteration 3105 : loss : 0.018633, loss_ce: 0.007722
2022-01-21 19:16:45,659 iteration 3106 : loss : 0.027251, loss_ce: 0.013565
2022-01-21 19:16:46,959 iteration 3107 : loss : 0.022635, loss_ce: 0.006816
2022-01-21 19:16:48,303 iteration 3108 : loss : 0.033086, loss_ce: 0.010151
2022-01-21 19:16:49,658 iteration 3109 : loss : 0.027802, loss_ce: 0.010739
2022-01-21 19:16:51,020 iteration 3110 : loss : 0.031159, loss_ce: 0.013773
2022-01-21 19:16:52,359 iteration 3111 : loss : 0.029353, loss_ce: 0.012148
 46%|████████████▎              | 183/400 [1:15:07<1:25:44, 23.71s/it]2022-01-21 19:16:53,763 iteration 3112 : loss : 0.029934, loss_ce: 0.010723
2022-01-21 19:16:55,058 iteration 3113 : loss : 0.031381, loss_ce: 0.012018
2022-01-21 19:16:56,446 iteration 3114 : loss : 0.030067, loss_ce: 0.009610
2022-01-21 19:16:57,801 iteration 3115 : loss : 0.022995, loss_ce: 0.009751
2022-01-21 19:16:59,131 iteration 3116 : loss : 0.022489, loss_ce: 0.010240
2022-01-21 19:17:00,538 iteration 3117 : loss : 0.020399, loss_ce: 0.008344
2022-01-21 19:17:01,853 iteration 3118 : loss : 0.030790, loss_ce: 0.011747
2022-01-21 19:17:03,301 iteration 3119 : loss : 0.030289, loss_ce: 0.008893
2022-01-21 19:17:04,600 iteration 3120 : loss : 0.023267, loss_ce: 0.009203
2022-01-21 19:17:06,007 iteration 3121 : loss : 0.024032, loss_ce: 0.010891
2022-01-21 19:17:07,334 iteration 3122 : loss : 0.025289, loss_ce: 0.006563
2022-01-21 19:17:08,735 iteration 3123 : loss : 0.033029, loss_ce: 0.013729
2022-01-21 19:17:09,995 iteration 3124 : loss : 0.017714, loss_ce: 0.006918
2022-01-21 19:17:11,322 iteration 3125 : loss : 0.029072, loss_ce: 0.008611
2022-01-21 19:17:12,719 iteration 3126 : loss : 0.024580, loss_ce: 0.010915
2022-01-21 19:17:14,132 iteration 3127 : loss : 0.025158, loss_ce: 0.008804
2022-01-21 19:17:15,538 iteration 3128 : loss : 0.032328, loss_ce: 0.011170
 46%|████████████▍              | 184/400 [1:15:31<1:24:47, 23.55s/it]2022-01-21 19:17:16,893 iteration 3129 : loss : 0.025557, loss_ce: 0.009306
2022-01-21 19:17:18,336 iteration 3130 : loss : 0.025453, loss_ce: 0.009328
2022-01-21 19:17:19,664 iteration 3131 : loss : 0.029109, loss_ce: 0.011363
2022-01-21 19:17:21,007 iteration 3132 : loss : 0.021367, loss_ce: 0.006190
2022-01-21 19:17:22,356 iteration 3133 : loss : 0.036186, loss_ce: 0.012370
2022-01-21 19:17:23,663 iteration 3134 : loss : 0.023115, loss_ce: 0.011892
2022-01-21 19:17:24,995 iteration 3135 : loss : 0.023271, loss_ce: 0.010548
2022-01-21 19:17:26,317 iteration 3136 : loss : 0.025389, loss_ce: 0.011427
2022-01-21 19:17:27,783 iteration 3137 : loss : 0.032172, loss_ce: 0.012931
2022-01-21 19:17:29,199 iteration 3138 : loss : 0.034265, loss_ce: 0.014551
2022-01-21 19:17:30,476 iteration 3139 : loss : 0.020998, loss_ce: 0.006940
2022-01-21 19:17:31,766 iteration 3140 : loss : 0.024978, loss_ce: 0.010756
2022-01-21 19:17:33,122 iteration 3141 : loss : 0.032964, loss_ce: 0.013569
2022-01-21 19:17:34,442 iteration 3142 : loss : 0.026097, loss_ce: 0.008761
2022-01-21 19:17:35,831 iteration 3143 : loss : 0.038964, loss_ce: 0.014413
2022-01-21 19:17:37,152 iteration 3144 : loss : 0.023743, loss_ce: 0.008099
2022-01-21 19:17:37,152 Training Data Eval:
2022-01-21 19:17:43,723   Average segmentation loss on training set: 0.0214
2022-01-21 19:17:43,723 Validation Data Eval:
2022-01-21 19:17:45,964   Average segmentation loss on validation set: 0.1088
2022-01-21 19:17:47,260 iteration 3145 : loss : 0.017492, loss_ce: 0.007144
 46%|████████████▍              | 185/400 [1:16:02<1:33:10, 26.00s/it]2022-01-21 19:17:48,794 iteration 3146 : loss : 0.041295, loss_ce: 0.014318
2022-01-21 19:17:50,184 iteration 3147 : loss : 0.030694, loss_ce: 0.014832
2022-01-21 19:17:51,459 iteration 3148 : loss : 0.037123, loss_ce: 0.012340
2022-01-21 19:17:52,855 iteration 3149 : loss : 0.038025, loss_ce: 0.010736
2022-01-21 19:17:54,238 iteration 3150 : loss : 0.021886, loss_ce: 0.007603
2022-01-21 19:17:55,615 iteration 3151 : loss : 0.031832, loss_ce: 0.013718
2022-01-21 19:17:56,990 iteration 3152 : loss : 0.027616, loss_ce: 0.010481
2022-01-21 19:17:58,344 iteration 3153 : loss : 0.026662, loss_ce: 0.012503
2022-01-21 19:17:59,772 iteration 3154 : loss : 0.029311, loss_ce: 0.010662
2022-01-21 19:18:01,155 iteration 3155 : loss : 0.022765, loss_ce: 0.008137
2022-01-21 19:18:02,440 iteration 3156 : loss : 0.022036, loss_ce: 0.007657
2022-01-21 19:18:03,797 iteration 3157 : loss : 0.022591, loss_ce: 0.009417
2022-01-21 19:18:05,088 iteration 3158 : loss : 0.031884, loss_ce: 0.007268
2022-01-21 19:18:06,460 iteration 3159 : loss : 0.028644, loss_ce: 0.014199
2022-01-21 19:18:07,829 iteration 3160 : loss : 0.024815, loss_ce: 0.009745
2022-01-21 19:18:09,241 iteration 3161 : loss : 0.022681, loss_ce: 0.008308
2022-01-21 19:18:10,595 iteration 3162 : loss : 0.024370, loss_ce: 0.008918
 46%|████████████▌              | 186/400 [1:16:26<1:29:53, 25.20s/it]2022-01-21 19:18:11,932 iteration 3163 : loss : 0.021292, loss_ce: 0.007904
2022-01-21 19:18:13,386 iteration 3164 : loss : 0.054803, loss_ce: 0.024994
2022-01-21 19:18:14,763 iteration 3165 : loss : 0.024678, loss_ce: 0.008995
2022-01-21 19:18:16,054 iteration 3166 : loss : 0.027453, loss_ce: 0.010642
2022-01-21 19:18:17,437 iteration 3167 : loss : 0.024146, loss_ce: 0.008303
2022-01-21 19:18:18,765 iteration 3168 : loss : 0.025520, loss_ce: 0.010095
2022-01-21 19:18:20,124 iteration 3169 : loss : 0.026131, loss_ce: 0.011047
2022-01-21 19:18:21,448 iteration 3170 : loss : 0.021766, loss_ce: 0.009743
2022-01-21 19:18:22,664 iteration 3171 : loss : 0.022715, loss_ce: 0.006141
2022-01-21 19:18:23,953 iteration 3172 : loss : 0.024478, loss_ce: 0.009601
2022-01-21 19:18:25,275 iteration 3173 : loss : 0.038318, loss_ce: 0.011911
2022-01-21 19:18:26,571 iteration 3174 : loss : 0.025441, loss_ce: 0.010769
2022-01-21 19:18:27,837 iteration 3175 : loss : 0.040569, loss_ce: 0.012667
2022-01-21 19:18:29,240 iteration 3176 : loss : 0.028766, loss_ce: 0.008654
2022-01-21 19:18:30,569 iteration 3177 : loss : 0.022670, loss_ce: 0.007923
2022-01-21 19:18:31,992 iteration 3178 : loss : 0.026150, loss_ce: 0.007259
2022-01-21 19:18:33,327 iteration 3179 : loss : 0.032524, loss_ce: 0.015503
 47%|████████████▌              | 187/400 [1:16:48<1:26:50, 24.46s/it]2022-01-21 19:18:34,708 iteration 3180 : loss : 0.035849, loss_ce: 0.015819
2022-01-21 19:18:36,009 iteration 3181 : loss : 0.022125, loss_ce: 0.010282
2022-01-21 19:18:37,285 iteration 3182 : loss : 0.035187, loss_ce: 0.019707
2022-01-21 19:18:38,663 iteration 3183 : loss : 0.032186, loss_ce: 0.010784
2022-01-21 19:18:39,991 iteration 3184 : loss : 0.030995, loss_ce: 0.010689
2022-01-21 19:18:41,323 iteration 3185 : loss : 0.032268, loss_ce: 0.010305
2022-01-21 19:18:42,692 iteration 3186 : loss : 0.023988, loss_ce: 0.010965
2022-01-21 19:18:44,066 iteration 3187 : loss : 0.020553, loss_ce: 0.008818
2022-01-21 19:18:45,450 iteration 3188 : loss : 0.031750, loss_ce: 0.012787
2022-01-21 19:18:46,775 iteration 3189 : loss : 0.025262, loss_ce: 0.009077
2022-01-21 19:18:48,203 iteration 3190 : loss : 0.027864, loss_ce: 0.009786
2022-01-21 19:18:49,583 iteration 3191 : loss : 0.026738, loss_ce: 0.010302
2022-01-21 19:18:50,855 iteration 3192 : loss : 0.027848, loss_ce: 0.005594
2022-01-21 19:18:52,181 iteration 3193 : loss : 0.020042, loss_ce: 0.007614
2022-01-21 19:18:53,632 iteration 3194 : loss : 0.034628, loss_ce: 0.016271
2022-01-21 19:18:54,973 iteration 3195 : loss : 0.028801, loss_ce: 0.012595
2022-01-21 19:18:56,307 iteration 3196 : loss : 0.022951, loss_ce: 0.010157
 47%|████████████▋              | 188/400 [1:17:11<1:24:51, 24.02s/it]2022-01-21 19:18:57,662 iteration 3197 : loss : 0.019179, loss_ce: 0.007579
2022-01-21 19:18:59,035 iteration 3198 : loss : 0.028570, loss_ce: 0.015156
2022-01-21 19:19:00,389 iteration 3199 : loss : 0.024219, loss_ce: 0.005929
2022-01-21 19:19:01,761 iteration 3200 : loss : 0.029114, loss_ce: 0.009692
2022-01-21 19:19:03,137 iteration 3201 : loss : 0.038931, loss_ce: 0.018512
2022-01-21 19:19:04,515 iteration 3202 : loss : 0.033887, loss_ce: 0.011032
2022-01-21 19:19:05,774 iteration 3203 : loss : 0.023282, loss_ce: 0.010836
2022-01-21 19:19:07,018 iteration 3204 : loss : 0.019157, loss_ce: 0.008058
2022-01-21 19:19:08,263 iteration 3205 : loss : 0.026086, loss_ce: 0.009167
2022-01-21 19:19:09,473 iteration 3206 : loss : 0.016832, loss_ce: 0.005025
2022-01-21 19:19:10,827 iteration 3207 : loss : 0.025719, loss_ce: 0.009226
2022-01-21 19:19:12,150 iteration 3208 : loss : 0.025643, loss_ce: 0.009745
2022-01-21 19:19:13,449 iteration 3209 : loss : 0.021325, loss_ce: 0.007690
2022-01-21 19:19:14,803 iteration 3210 : loss : 0.026727, loss_ce: 0.012308
2022-01-21 19:19:16,071 iteration 3211 : loss : 0.018219, loss_ce: 0.005550
2022-01-21 19:19:17,471 iteration 3212 : loss : 0.027152, loss_ce: 0.011522
2022-01-21 19:19:18,876 iteration 3213 : loss : 0.027431, loss_ce: 0.009486
 47%|████████████▊              | 189/400 [1:17:34<1:22:55, 23.58s/it]2022-01-21 19:19:20,191 iteration 3214 : loss : 0.018622, loss_ce: 0.008465
2022-01-21 19:19:21,518 iteration 3215 : loss : 0.021721, loss_ce: 0.009305
2022-01-21 19:19:22,843 iteration 3216 : loss : 0.026960, loss_ce: 0.010615
2022-01-21 19:19:24,201 iteration 3217 : loss : 0.031682, loss_ce: 0.013394
2022-01-21 19:19:25,531 iteration 3218 : loss : 0.042210, loss_ce: 0.014837
2022-01-21 19:19:26,856 iteration 3219 : loss : 0.025515, loss_ce: 0.009162
2022-01-21 19:19:28,135 iteration 3220 : loss : 0.017384, loss_ce: 0.007408
2022-01-21 19:19:29,561 iteration 3221 : loss : 0.043320, loss_ce: 0.017761
2022-01-21 19:19:30,863 iteration 3222 : loss : 0.034537, loss_ce: 0.008788
2022-01-21 19:19:32,216 iteration 3223 : loss : 0.021784, loss_ce: 0.009360
2022-01-21 19:19:33,632 iteration 3224 : loss : 0.028103, loss_ce: 0.008946
2022-01-21 19:19:34,961 iteration 3225 : loss : 0.027160, loss_ce: 0.012912
2022-01-21 19:19:36,289 iteration 3226 : loss : 0.025875, loss_ce: 0.010247
2022-01-21 19:19:37,632 iteration 3227 : loss : 0.045388, loss_ce: 0.015856
2022-01-21 19:19:38,936 iteration 3228 : loss : 0.032540, loss_ce: 0.010044
2022-01-21 19:19:40,206 iteration 3229 : loss : 0.027736, loss_ce: 0.007795
2022-01-21 19:19:40,207 Training Data Eval:
2022-01-21 19:19:46,739   Average segmentation loss on training set: 0.0209
2022-01-21 19:19:46,740 Validation Data Eval:
2022-01-21 19:19:48,974   Average segmentation loss on validation set: 0.0788
2022-01-21 19:19:50,231 iteration 3230 : loss : 0.024499, loss_ce: 0.008261
 48%|████████████▊              | 190/400 [1:18:05<1:30:41, 25.91s/it]2022-01-21 19:19:51,553 iteration 3231 : loss : 0.037225, loss_ce: 0.008962
2022-01-21 19:19:52,857 iteration 3232 : loss : 0.022362, loss_ce: 0.007425
2022-01-21 19:19:54,191 iteration 3233 : loss : 0.028044, loss_ce: 0.012835
2022-01-21 19:19:55,546 iteration 3234 : loss : 0.024502, loss_ce: 0.009971
2022-01-21 19:19:56,894 iteration 3235 : loss : 0.040579, loss_ce: 0.011748
2022-01-21 19:19:58,162 iteration 3236 : loss : 0.020367, loss_ce: 0.010475
2022-01-21 19:19:59,581 iteration 3237 : loss : 0.024750, loss_ce: 0.010584
2022-01-21 19:20:00,920 iteration 3238 : loss : 0.021177, loss_ce: 0.009765
2022-01-21 19:20:02,252 iteration 3239 : loss : 0.022348, loss_ce: 0.008668
2022-01-21 19:20:03,529 iteration 3240 : loss : 0.030347, loss_ce: 0.007723
2022-01-21 19:20:04,784 iteration 3241 : loss : 0.026722, loss_ce: 0.006261
2022-01-21 19:20:06,116 iteration 3242 : loss : 0.035766, loss_ce: 0.012043
2022-01-21 19:20:07,376 iteration 3243 : loss : 0.028088, loss_ce: 0.010184
2022-01-21 19:20:08,724 iteration 3244 : loss : 0.033489, loss_ce: 0.013029
2022-01-21 19:20:10,011 iteration 3245 : loss : 0.021066, loss_ce: 0.009774
2022-01-21 19:20:11,402 iteration 3246 : loss : 0.041064, loss_ce: 0.023092
2022-01-21 19:20:12,696 iteration 3247 : loss : 0.026125, loss_ce: 0.011175
 48%|████████████▉              | 191/400 [1:18:28<1:26:39, 24.88s/it]2022-01-21 19:20:14,013 iteration 3248 : loss : 0.019733, loss_ce: 0.007309
2022-01-21 19:20:15,291 iteration 3249 : loss : 0.020860, loss_ce: 0.007740
2022-01-21 19:20:16,596 iteration 3250 : loss : 0.034699, loss_ce: 0.011976
2022-01-21 19:20:17,905 iteration 3251 : loss : 0.020834, loss_ce: 0.008573
2022-01-21 19:20:19,238 iteration 3252 : loss : 0.020690, loss_ce: 0.006657
2022-01-21 19:20:20,545 iteration 3253 : loss : 0.019894, loss_ce: 0.009205
2022-01-21 19:20:21,844 iteration 3254 : loss : 0.026202, loss_ce: 0.009874
2022-01-21 19:20:23,081 iteration 3255 : loss : 0.024277, loss_ce: 0.010451
2022-01-21 19:20:24,387 iteration 3256 : loss : 0.019843, loss_ce: 0.006677
2022-01-21 19:20:25,665 iteration 3257 : loss : 0.020811, loss_ce: 0.008047
2022-01-21 19:20:26,994 iteration 3258 : loss : 0.027715, loss_ce: 0.011241
2022-01-21 19:20:28,261 iteration 3259 : loss : 0.022523, loss_ce: 0.009093
2022-01-21 19:20:29,594 iteration 3260 : loss : 0.025543, loss_ce: 0.010406
2022-01-21 19:20:30,888 iteration 3261 : loss : 0.034803, loss_ce: 0.009700
2022-01-21 19:20:32,250 iteration 3262 : loss : 0.029913, loss_ce: 0.010758
2022-01-21 19:20:33,680 iteration 3263 : loss : 0.019569, loss_ce: 0.006404
2022-01-21 19:20:35,013 iteration 3264 : loss : 0.029196, loss_ce: 0.012676
 48%|████████████▉              | 192/400 [1:18:50<1:23:35, 24.11s/it]2022-01-21 19:20:36,320 iteration 3265 : loss : 0.019812, loss_ce: 0.008302
2022-01-21 19:20:37,691 iteration 3266 : loss : 0.026927, loss_ce: 0.011888
2022-01-21 19:20:39,035 iteration 3267 : loss : 0.022192, loss_ce: 0.009226
2022-01-21 19:20:40,318 iteration 3268 : loss : 0.024402, loss_ce: 0.009756
2022-01-21 19:20:41,698 iteration 3269 : loss : 0.029757, loss_ce: 0.012592
2022-01-21 19:20:43,103 iteration 3270 : loss : 0.036441, loss_ce: 0.010460
2022-01-21 19:20:44,479 iteration 3271 : loss : 0.029735, loss_ce: 0.010587
2022-01-21 19:20:45,858 iteration 3272 : loss : 0.020379, loss_ce: 0.008402
2022-01-21 19:20:47,126 iteration 3273 : loss : 0.022777, loss_ce: 0.006770
2022-01-21 19:20:48,439 iteration 3274 : loss : 0.020614, loss_ce: 0.009953
2022-01-21 19:20:49,826 iteration 3275 : loss : 0.024099, loss_ce: 0.005931
2022-01-21 19:20:51,125 iteration 3276 : loss : 0.028634, loss_ce: 0.010585
2022-01-21 19:20:52,480 iteration 3277 : loss : 0.022269, loss_ce: 0.010779
2022-01-21 19:20:53,813 iteration 3278 : loss : 0.020756, loss_ce: 0.007374
2022-01-21 19:20:55,104 iteration 3279 : loss : 0.020338, loss_ce: 0.007453
2022-01-21 19:20:56,417 iteration 3280 : loss : 0.018713, loss_ce: 0.006001
2022-01-21 19:20:57,684 iteration 3281 : loss : 0.016566, loss_ce: 0.004945
 48%|█████████████              | 193/400 [1:19:13<1:21:41, 23.68s/it]2022-01-21 19:20:59,076 iteration 3282 : loss : 0.030971, loss_ce: 0.012885
2022-01-21 19:21:00,400 iteration 3283 : loss : 0.021354, loss_ce: 0.006988
2022-01-21 19:21:01,724 iteration 3284 : loss : 0.033038, loss_ce: 0.015894
2022-01-21 19:21:03,032 iteration 3285 : loss : 0.042820, loss_ce: 0.023135
2022-01-21 19:21:04,343 iteration 3286 : loss : 0.015416, loss_ce: 0.005589
2022-01-21 19:21:05,676 iteration 3287 : loss : 0.021375, loss_ce: 0.008651
2022-01-21 19:21:06,947 iteration 3288 : loss : 0.024431, loss_ce: 0.013117
2022-01-21 19:21:08,229 iteration 3289 : loss : 0.027471, loss_ce: 0.008439
2022-01-21 19:21:09,599 iteration 3290 : loss : 0.037250, loss_ce: 0.010482
2022-01-21 19:21:10,987 iteration 3291 : loss : 0.033273, loss_ce: 0.011414
2022-01-21 19:21:12,328 iteration 3292 : loss : 0.031978, loss_ce: 0.010635
2022-01-21 19:21:13,648 iteration 3293 : loss : 0.020594, loss_ce: 0.009741
2022-01-21 19:21:14,942 iteration 3294 : loss : 0.024290, loss_ce: 0.010399
2022-01-21 19:21:16,350 iteration 3295 : loss : 0.070468, loss_ce: 0.032098
2022-01-21 19:21:17,699 iteration 3296 : loss : 0.033256, loss_ce: 0.011016
2022-01-21 19:21:18,957 iteration 3297 : loss : 0.017561, loss_ce: 0.007696
2022-01-21 19:21:20,319 iteration 3298 : loss : 0.025574, loss_ce: 0.010795
 48%|█████████████              | 194/400 [1:19:35<1:20:13, 23.37s/it]2022-01-21 19:21:21,611 iteration 3299 : loss : 0.018565, loss_ce: 0.007749
2022-01-21 19:21:22,903 iteration 3300 : loss : 0.028619, loss_ce: 0.010183
2022-01-21 19:21:24,282 iteration 3301 : loss : 0.030428, loss_ce: 0.013729
2022-01-21 19:21:25,611 iteration 3302 : loss : 0.020415, loss_ce: 0.008643
2022-01-21 19:21:26,917 iteration 3303 : loss : 0.021459, loss_ce: 0.009294
2022-01-21 19:21:28,243 iteration 3304 : loss : 0.024276, loss_ce: 0.009178
2022-01-21 19:21:29,595 iteration 3305 : loss : 0.024835, loss_ce: 0.009066
2022-01-21 19:21:30,972 iteration 3306 : loss : 0.029094, loss_ce: 0.011234
2022-01-21 19:21:32,267 iteration 3307 : loss : 0.024841, loss_ce: 0.010779
2022-01-21 19:21:33,599 iteration 3308 : loss : 0.025737, loss_ce: 0.011653
2022-01-21 19:21:34,917 iteration 3309 : loss : 0.032086, loss_ce: 0.006910
2022-01-21 19:21:36,319 iteration 3310 : loss : 0.053334, loss_ce: 0.025850
2022-01-21 19:21:37,741 iteration 3311 : loss : 0.021473, loss_ce: 0.007441
2022-01-21 19:21:39,016 iteration 3312 : loss : 0.022850, loss_ce: 0.007632
2022-01-21 19:21:40,302 iteration 3313 : loss : 0.019831, loss_ce: 0.007123
2022-01-21 19:21:41,690 iteration 3314 : loss : 0.030506, loss_ce: 0.011755
2022-01-21 19:21:41,691 Training Data Eval:
2022-01-21 19:21:48,211   Average segmentation loss on training set: 0.0168
2022-01-21 19:21:48,211 Validation Data Eval:
2022-01-21 19:21:50,456   Average segmentation loss on validation set: 0.0648
2022-01-21 19:21:51,731 iteration 3315 : loss : 0.018630, loss_ce: 0.008546
 49%|█████████████▏             | 195/400 [1:20:07<1:28:04, 25.78s/it]2022-01-21 19:21:53,045 iteration 3316 : loss : 0.015801, loss_ce: 0.005938
2022-01-21 19:21:54,339 iteration 3317 : loss : 0.023491, loss_ce: 0.009343
2022-01-21 19:21:55,759 iteration 3318 : loss : 0.029439, loss_ce: 0.012088
2022-01-21 19:21:57,054 iteration 3319 : loss : 0.020428, loss_ce: 0.007385
2022-01-21 19:21:58,358 iteration 3320 : loss : 0.018597, loss_ce: 0.006433
2022-01-21 19:21:59,692 iteration 3321 : loss : 0.022627, loss_ce: 0.006436
2022-01-21 19:22:01,022 iteration 3322 : loss : 0.022871, loss_ce: 0.009819
2022-01-21 19:22:02,298 iteration 3323 : loss : 0.020513, loss_ce: 0.006603
2022-01-21 19:22:03,698 iteration 3324 : loss : 0.033334, loss_ce: 0.014752
2022-01-21 19:22:04,977 iteration 3325 : loss : 0.033892, loss_ce: 0.010175
2022-01-21 19:22:06,332 iteration 3326 : loss : 0.025656, loss_ce: 0.009989
2022-01-21 19:22:07,756 iteration 3327 : loss : 0.033772, loss_ce: 0.010452
2022-01-21 19:22:09,089 iteration 3328 : loss : 0.027796, loss_ce: 0.010753
2022-01-21 19:22:10,380 iteration 3329 : loss : 0.021558, loss_ce: 0.008683
2022-01-21 19:22:11,691 iteration 3330 : loss : 0.040901, loss_ce: 0.012928
2022-01-21 19:22:13,032 iteration 3331 : loss : 0.021753, loss_ce: 0.008868
2022-01-21 19:22:14,269 iteration 3332 : loss : 0.016972, loss_ce: 0.007966
 49%|█████████████▏             | 196/400 [1:20:29<1:24:21, 24.81s/it]2022-01-21 19:22:15,609 iteration 3333 : loss : 0.020828, loss_ce: 0.007665
2022-01-21 19:22:16,947 iteration 3334 : loss : 0.023959, loss_ce: 0.009989
2022-01-21 19:22:18,191 iteration 3335 : loss : 0.016380, loss_ce: 0.007040
2022-01-21 19:22:19,514 iteration 3336 : loss : 0.028769, loss_ce: 0.009580
2022-01-21 19:22:20,884 iteration 3337 : loss : 0.033774, loss_ce: 0.015547
2022-01-21 19:22:22,302 iteration 3338 : loss : 0.044856, loss_ce: 0.023694
2022-01-21 19:22:23,629 iteration 3339 : loss : 0.029381, loss_ce: 0.007755
2022-01-21 19:22:24,928 iteration 3340 : loss : 0.024416, loss_ce: 0.007818
2022-01-21 19:22:26,246 iteration 3341 : loss : 0.019033, loss_ce: 0.006970
2022-01-21 19:22:27,617 iteration 3342 : loss : 0.036208, loss_ce: 0.016966
2022-01-21 19:22:28,969 iteration 3343 : loss : 0.029465, loss_ce: 0.009849
2022-01-21 19:22:30,308 iteration 3344 : loss : 0.036009, loss_ce: 0.013843
2022-01-21 19:22:31,613 iteration 3345 : loss : 0.021430, loss_ce: 0.007679
2022-01-21 19:22:32,943 iteration 3346 : loss : 0.020915, loss_ce: 0.009667
2022-01-21 19:22:34,305 iteration 3347 : loss : 0.037650, loss_ce: 0.010537
2022-01-21 19:22:35,721 iteration 3348 : loss : 0.033710, loss_ce: 0.011674
2022-01-21 19:22:37,070 iteration 3349 : loss : 0.032269, loss_ce: 0.013267
 49%|█████████████▎             | 197/400 [1:20:52<1:21:53, 24.21s/it]2022-01-21 19:22:38,392 iteration 3350 : loss : 0.021175, loss_ce: 0.007839
2022-01-21 19:22:39,669 iteration 3351 : loss : 0.027215, loss_ce: 0.012724
2022-01-21 19:22:40,969 iteration 3352 : loss : 0.022406, loss_ce: 0.007857
2022-01-21 19:22:42,315 iteration 3353 : loss : 0.025513, loss_ce: 0.010163
2022-01-21 19:22:43,658 iteration 3354 : loss : 0.025261, loss_ce: 0.007886
2022-01-21 19:22:45,053 iteration 3355 : loss : 0.030634, loss_ce: 0.017550
2022-01-21 19:22:46,423 iteration 3356 : loss : 0.028107, loss_ce: 0.007852
2022-01-21 19:22:47,802 iteration 3357 : loss : 0.022127, loss_ce: 0.006943
2022-01-21 19:22:49,204 iteration 3358 : loss : 0.022927, loss_ce: 0.008259
2022-01-21 19:22:50,564 iteration 3359 : loss : 0.030207, loss_ce: 0.011795
2022-01-21 19:22:51,987 iteration 3360 : loss : 0.033076, loss_ce: 0.014412
2022-01-21 19:22:53,264 iteration 3361 : loss : 0.030231, loss_ce: 0.009818
2022-01-21 19:22:54,552 iteration 3362 : loss : 0.018652, loss_ce: 0.007802
2022-01-21 19:22:55,828 iteration 3363 : loss : 0.020812, loss_ce: 0.009443
2022-01-21 19:22:57,177 iteration 3364 : loss : 0.026325, loss_ce: 0.009105
2022-01-21 19:22:58,455 iteration 3365 : loss : 0.018568, loss_ce: 0.009317
2022-01-21 19:22:59,777 iteration 3366 : loss : 0.023780, loss_ce: 0.009228
 50%|█████████████▎             | 198/400 [1:21:15<1:19:58, 23.76s/it]2022-01-21 19:23:01,137 iteration 3367 : loss : 0.025567, loss_ce: 0.007683
2022-01-21 19:23:02,451 iteration 3368 : loss : 0.024908, loss_ce: 0.011628
2022-01-21 19:23:03,801 iteration 3369 : loss : 0.021018, loss_ce: 0.007682
2022-01-21 19:23:05,153 iteration 3370 : loss : 0.028884, loss_ce: 0.013080
2022-01-21 19:23:06,397 iteration 3371 : loss : 0.014901, loss_ce: 0.005727
2022-01-21 19:23:07,702 iteration 3372 : loss : 0.021690, loss_ce: 0.010895
2022-01-21 19:23:09,015 iteration 3373 : loss : 0.021597, loss_ce: 0.011604
2022-01-21 19:23:10,285 iteration 3374 : loss : 0.019870, loss_ce: 0.008978
2022-01-21 19:23:11,563 iteration 3375 : loss : 0.022029, loss_ce: 0.008674
2022-01-21 19:23:12,851 iteration 3376 : loss : 0.022917, loss_ce: 0.009235
2022-01-21 19:23:14,222 iteration 3377 : loss : 0.021858, loss_ce: 0.006350
2022-01-21 19:23:15,536 iteration 3378 : loss : 0.032181, loss_ce: 0.010483
2022-01-21 19:23:16,771 iteration 3379 : loss : 0.016895, loss_ce: 0.007360
2022-01-21 19:23:18,150 iteration 3380 : loss : 0.032995, loss_ce: 0.013469
2022-01-21 19:23:19,408 iteration 3381 : loss : 0.040971, loss_ce: 0.007122
2022-01-21 19:23:20,732 iteration 3382 : loss : 0.025414, loss_ce: 0.009237
2022-01-21 19:23:22,038 iteration 3383 : loss : 0.021319, loss_ce: 0.007586
 50%|█████████████▍             | 199/400 [1:21:37<1:18:04, 23.31s/it]2022-01-21 19:23:23,348 iteration 3384 : loss : 0.022024, loss_ce: 0.007956
2022-01-21 19:23:24,717 iteration 3385 : loss : 0.023215, loss_ce: 0.009950
2022-01-21 19:23:26,100 iteration 3386 : loss : 0.026840, loss_ce: 0.012221
2022-01-21 19:23:27,464 iteration 3387 : loss : 0.026797, loss_ce: 0.009603
2022-01-21 19:23:28,733 iteration 3388 : loss : 0.021916, loss_ce: 0.007966
2022-01-21 19:23:30,082 iteration 3389 : loss : 0.029539, loss_ce: 0.011976
2022-01-21 19:23:31,338 iteration 3390 : loss : 0.026377, loss_ce: 0.007717
2022-01-21 19:23:32,763 iteration 3391 : loss : 0.031229, loss_ce: 0.009589
2022-01-21 19:23:34,126 iteration 3392 : loss : 0.022282, loss_ce: 0.009496
2022-01-21 19:23:35,483 iteration 3393 : loss : 0.021576, loss_ce: 0.007536
2022-01-21 19:23:36,717 iteration 3394 : loss : 0.019245, loss_ce: 0.006505
2022-01-21 19:23:38,148 iteration 3395 : loss : 0.026480, loss_ce: 0.008403
2022-01-21 19:23:39,497 iteration 3396 : loss : 0.037583, loss_ce: 0.015232
2022-01-21 19:23:40,801 iteration 3397 : loss : 0.021758, loss_ce: 0.008958
2022-01-21 19:23:42,164 iteration 3398 : loss : 0.023654, loss_ce: 0.007425
2022-01-21 19:23:43,502 iteration 3399 : loss : 0.018669, loss_ce: 0.007926
2022-01-21 19:23:43,502 Training Data Eval:
2022-01-21 19:23:50,014   Average segmentation loss on training set: 0.0151
2022-01-21 19:23:50,014 Validation Data Eval:
2022-01-21 19:23:52,242   Average segmentation loss on validation set: 0.0671
2022-01-21 19:23:53,565 iteration 3400 : loss : 0.022120, loss_ce: 0.007467
 50%|█████████████▌             | 200/400 [1:22:09<1:25:54, 25.77s/it]2022-01-21 19:23:55,064 iteration 3401 : loss : 0.026207, loss_ce: 0.011527
2022-01-21 19:23:56,447 iteration 3402 : loss : 0.022918, loss_ce: 0.008552
2022-01-21 19:23:57,754 iteration 3403 : loss : 0.020688, loss_ce: 0.010116
2022-01-21 19:23:59,056 iteration 3404 : loss : 0.016904, loss_ce: 0.005901
2022-01-21 19:24:00,360 iteration 3405 : loss : 0.023776, loss_ce: 0.009185
2022-01-21 19:24:01,737 iteration 3406 : loss : 0.026360, loss_ce: 0.008696
2022-01-21 19:24:03,071 iteration 3407 : loss : 0.027428, loss_ce: 0.012202
2022-01-21 19:24:04,419 iteration 3408 : loss : 0.019532, loss_ce: 0.007773
2022-01-21 19:24:05,779 iteration 3409 : loss : 0.021353, loss_ce: 0.008738
2022-01-21 19:24:07,127 iteration 3410 : loss : 0.029224, loss_ce: 0.010348
2022-01-21 19:24:08,517 iteration 3411 : loss : 0.036505, loss_ce: 0.012426
2022-01-21 19:24:09,789 iteration 3412 : loss : 0.023311, loss_ce: 0.007774
2022-01-21 19:24:11,047 iteration 3413 : loss : 0.015281, loss_ce: 0.006537
2022-01-21 19:24:12,393 iteration 3414 : loss : 0.030759, loss_ce: 0.007160
2022-01-21 19:24:13,768 iteration 3415 : loss : 0.022874, loss_ce: 0.008388
2022-01-21 19:24:15,143 iteration 3416 : loss : 0.027309, loss_ce: 0.010381
2022-01-21 19:24:16,561 iteration 3417 : loss : 0.031029, loss_ce: 0.011546
 50%|█████████████▌             | 201/400 [1:22:32<1:22:42, 24.94s/it]2022-01-21 19:24:17,940 iteration 3418 : loss : 0.018988, loss_ce: 0.007860
2022-01-21 19:24:19,305 iteration 3419 : loss : 0.020644, loss_ce: 0.007106
2022-01-21 19:24:20,733 iteration 3420 : loss : 0.025566, loss_ce: 0.007811
2022-01-21 19:24:22,084 iteration 3421 : loss : 0.037602, loss_ce: 0.016881
2022-01-21 19:24:23,359 iteration 3422 : loss : 0.020649, loss_ce: 0.006984
2022-01-21 19:24:24,690 iteration 3423 : loss : 0.016395, loss_ce: 0.006847
2022-01-21 19:24:26,020 iteration 3424 : loss : 0.037239, loss_ce: 0.016619
2022-01-21 19:24:27,298 iteration 3425 : loss : 0.023025, loss_ce: 0.011469
2022-01-21 19:24:28,632 iteration 3426 : loss : 0.027594, loss_ce: 0.009570
2022-01-21 19:24:29,981 iteration 3427 : loss : 0.026253, loss_ce: 0.008395
2022-01-21 19:24:31,333 iteration 3428 : loss : 0.019784, loss_ce: 0.007345
2022-01-21 19:24:32,715 iteration 3429 : loss : 0.029442, loss_ce: 0.011428
2022-01-21 19:24:34,097 iteration 3430 : loss : 0.024083, loss_ce: 0.010768
2022-01-21 19:24:35,354 iteration 3431 : loss : 0.019732, loss_ce: 0.008131
2022-01-21 19:24:36,643 iteration 3432 : loss : 0.020399, loss_ce: 0.006706
2022-01-21 19:24:37,931 iteration 3433 : loss : 0.019536, loss_ce: 0.006630
2022-01-21 19:24:39,304 iteration 3434 : loss : 0.043446, loss_ce: 0.014838
 50%|█████████████▋             | 202/400 [1:22:54<1:20:07, 24.28s/it]2022-01-21 19:24:40,591 iteration 3435 : loss : 0.021203, loss_ce: 0.006496
2022-01-21 19:24:41,886 iteration 3436 : loss : 0.017341, loss_ce: 0.006188
2022-01-21 19:24:43,313 iteration 3437 : loss : 0.023233, loss_ce: 0.011059
2022-01-21 19:24:44,719 iteration 3438 : loss : 0.022712, loss_ce: 0.011579
2022-01-21 19:24:46,096 iteration 3439 : loss : 0.046357, loss_ce: 0.023274
2022-01-21 19:24:47,397 iteration 3440 : loss : 0.018768, loss_ce: 0.007000
2022-01-21 19:24:48,718 iteration 3441 : loss : 0.034764, loss_ce: 0.013005
2022-01-21 19:24:50,154 iteration 3442 : loss : 0.027964, loss_ce: 0.008999
2022-01-21 19:24:51,527 iteration 3443 : loss : 0.033317, loss_ce: 0.010217
2022-01-21 19:24:52,907 iteration 3444 : loss : 0.023683, loss_ce: 0.008803
2022-01-21 19:24:54,246 iteration 3445 : loss : 0.038011, loss_ce: 0.012234
2022-01-21 19:24:55,576 iteration 3446 : loss : 0.020609, loss_ce: 0.008584
2022-01-21 19:24:56,892 iteration 3447 : loss : 0.022766, loss_ce: 0.007710
2022-01-21 19:24:58,276 iteration 3448 : loss : 0.032476, loss_ce: 0.008592
2022-01-21 19:24:59,635 iteration 3449 : loss : 0.032050, loss_ce: 0.014366
2022-01-21 19:25:00,969 iteration 3450 : loss : 0.030109, loss_ce: 0.012936
2022-01-21 19:25:02,378 iteration 3451 : loss : 0.025675, loss_ce: 0.010481
 51%|█████████████▋             | 203/400 [1:23:17<1:18:31, 23.92s/it]2022-01-21 19:25:03,743 iteration 3452 : loss : 0.022793, loss_ce: 0.009473
2022-01-21 19:25:05,054 iteration 3453 : loss : 0.023173, loss_ce: 0.009000
2022-01-21 19:25:06,350 iteration 3454 : loss : 0.019626, loss_ce: 0.007022
2022-01-21 19:25:07,750 iteration 3455 : loss : 0.029279, loss_ce: 0.013440
2022-01-21 19:25:09,042 iteration 3456 : loss : 0.019959, loss_ce: 0.006450
2022-01-21 19:25:10,467 iteration 3457 : loss : 0.035377, loss_ce: 0.013724
2022-01-21 19:25:11,838 iteration 3458 : loss : 0.032589, loss_ce: 0.012522
2022-01-21 19:25:13,169 iteration 3459 : loss : 0.022383, loss_ce: 0.009210
2022-01-21 19:25:14,487 iteration 3460 : loss : 0.023372, loss_ce: 0.009394
2022-01-21 19:25:15,809 iteration 3461 : loss : 0.023780, loss_ce: 0.009681
2022-01-21 19:25:17,119 iteration 3462 : loss : 0.021400, loss_ce: 0.008924
2022-01-21 19:25:18,483 iteration 3463 : loss : 0.032374, loss_ce: 0.013987
2022-01-21 19:25:19,758 iteration 3464 : loss : 0.019300, loss_ce: 0.007008
2022-01-21 19:25:21,135 iteration 3465 : loss : 0.028004, loss_ce: 0.009027
2022-01-21 19:25:22,482 iteration 3466 : loss : 0.019638, loss_ce: 0.006050
2022-01-21 19:25:23,811 iteration 3467 : loss : 0.026684, loss_ce: 0.014781
2022-01-21 19:25:25,129 iteration 3468 : loss : 0.030922, loss_ce: 0.012524
 51%|█████████████▊             | 204/400 [1:23:40<1:16:59, 23.57s/it]2022-01-21 19:25:26,461 iteration 3469 : loss : 0.020542, loss_ce: 0.006409
2022-01-21 19:25:27,839 iteration 3470 : loss : 0.035314, loss_ce: 0.012635
2022-01-21 19:25:29,098 iteration 3471 : loss : 0.018908, loss_ce: 0.006922
2022-01-21 19:25:30,449 iteration 3472 : loss : 0.022485, loss_ce: 0.010272
2022-01-21 19:25:31,903 iteration 3473 : loss : 0.039621, loss_ce: 0.012831
2022-01-21 19:25:33,234 iteration 3474 : loss : 0.024198, loss_ce: 0.006996
2022-01-21 19:25:34,630 iteration 3475 : loss : 0.041462, loss_ce: 0.012626
2022-01-21 19:25:35,926 iteration 3476 : loss : 0.025179, loss_ce: 0.007138
2022-01-21 19:25:37,282 iteration 3477 : loss : 0.026027, loss_ce: 0.007644
2022-01-21 19:25:38,611 iteration 3478 : loss : 0.023786, loss_ce: 0.009197
2022-01-21 19:25:39,903 iteration 3479 : loss : 0.023587, loss_ce: 0.010191
2022-01-21 19:25:41,147 iteration 3480 : loss : 0.026819, loss_ce: 0.010813
2022-01-21 19:25:42,466 iteration 3481 : loss : 0.033177, loss_ce: 0.012827
2022-01-21 19:25:43,789 iteration 3482 : loss : 0.025897, loss_ce: 0.009808
2022-01-21 19:25:45,176 iteration 3483 : loss : 0.025647, loss_ce: 0.011304
2022-01-21 19:25:46,417 iteration 3484 : loss : 0.023432, loss_ce: 0.008583
2022-01-21 19:25:46,418 Training Data Eval:
2022-01-21 19:25:52,932   Average segmentation loss on training set: 0.0188
2022-01-21 19:25:52,933 Validation Data Eval:
2022-01-21 19:25:55,167   Average segmentation loss on validation set: 0.0637
2022-01-21 19:25:56,583 iteration 3485 : loss : 0.039894, loss_ce: 0.017061
 51%|█████████████▊             | 205/400 [1:24:12<1:24:17, 25.94s/it]2022-01-21 19:25:57,945 iteration 3486 : loss : 0.033278, loss_ce: 0.014328
2022-01-21 19:25:59,216 iteration 3487 : loss : 0.022401, loss_ce: 0.009530
2022-01-21 19:26:00,548 iteration 3488 : loss : 0.032504, loss_ce: 0.013614
2022-01-21 19:26:01,860 iteration 3489 : loss : 0.025376, loss_ce: 0.008888
2022-01-21 19:26:03,207 iteration 3490 : loss : 0.034019, loss_ce: 0.011543
2022-01-21 19:26:04,595 iteration 3491 : loss : 0.027170, loss_ce: 0.009517
2022-01-21 19:26:05,861 iteration 3492 : loss : 0.027334, loss_ce: 0.009400
2022-01-21 19:26:07,290 iteration 3493 : loss : 0.027898, loss_ce: 0.011257
2022-01-21 19:26:08,652 iteration 3494 : loss : 0.026273, loss_ce: 0.006894
2022-01-21 19:26:09,969 iteration 3495 : loss : 0.025052, loss_ce: 0.007688
2022-01-21 19:26:11,330 iteration 3496 : loss : 0.018688, loss_ce: 0.007149
2022-01-21 19:26:12,689 iteration 3497 : loss : 0.031024, loss_ce: 0.012143
2022-01-21 19:26:14,133 iteration 3498 : loss : 0.030388, loss_ce: 0.012390
2022-01-21 19:26:15,432 iteration 3499 : loss : 0.024477, loss_ce: 0.009053
2022-01-21 19:26:16,676 iteration 3500 : loss : 0.016663, loss_ce: 0.005580
2022-01-21 19:26:17,956 iteration 3501 : loss : 0.029681, loss_ce: 0.013730
2022-01-21 19:26:19,297 iteration 3502 : loss : 0.025329, loss_ce: 0.009427
 52%|█████████████▉             | 206/400 [1:24:34<1:20:43, 24.97s/it]2022-01-21 19:26:20,684 iteration 3503 : loss : 0.031599, loss_ce: 0.014198
2022-01-21 19:26:21,987 iteration 3504 : loss : 0.021826, loss_ce: 0.006918
2022-01-21 19:26:23,213 iteration 3505 : loss : 0.017797, loss_ce: 0.008618
2022-01-21 19:26:24,555 iteration 3506 : loss : 0.028702, loss_ce: 0.008236
2022-01-21 19:26:25,865 iteration 3507 : loss : 0.022853, loss_ce: 0.006009
2022-01-21 19:26:27,306 iteration 3508 : loss : 0.034905, loss_ce: 0.017305
2022-01-21 19:26:28,656 iteration 3509 : loss : 0.021453, loss_ce: 0.008409
2022-01-21 19:26:29,930 iteration 3510 : loss : 0.027976, loss_ce: 0.012812
2022-01-21 19:26:31,222 iteration 3511 : loss : 0.026904, loss_ce: 0.012025
2022-01-21 19:26:32,615 iteration 3512 : loss : 0.041022, loss_ce: 0.013857
2022-01-21 19:26:33,947 iteration 3513 : loss : 0.021518, loss_ce: 0.006362
2022-01-21 19:26:35,396 iteration 3514 : loss : 0.036879, loss_ce: 0.018783
2022-01-21 19:26:36,707 iteration 3515 : loss : 0.030320, loss_ce: 0.008386
2022-01-21 19:26:38,007 iteration 3516 : loss : 0.021937, loss_ce: 0.008159
2022-01-21 19:26:39,312 iteration 3517 : loss : 0.019858, loss_ce: 0.007679
2022-01-21 19:26:40,624 iteration 3518 : loss : 0.020619, loss_ce: 0.009501
2022-01-21 19:26:41,970 iteration 3519 : loss : 0.024703, loss_ce: 0.009511
 52%|█████████████▉             | 207/400 [1:24:57<1:18:05, 24.28s/it]2022-01-21 19:26:43,351 iteration 3520 : loss : 0.039300, loss_ce: 0.015907
2022-01-21 19:26:44,645 iteration 3521 : loss : 0.029543, loss_ce: 0.014697
2022-01-21 19:26:45,905 iteration 3522 : loss : 0.019845, loss_ce: 0.009185
2022-01-21 19:26:47,214 iteration 3523 : loss : 0.017203, loss_ce: 0.006234
2022-01-21 19:26:48,570 iteration 3524 : loss : 0.020082, loss_ce: 0.008158
2022-01-21 19:26:49,992 iteration 3525 : loss : 0.025366, loss_ce: 0.009815
2022-01-21 19:26:51,348 iteration 3526 : loss : 0.032168, loss_ce: 0.010699
2022-01-21 19:26:52,718 iteration 3527 : loss : 0.053101, loss_ce: 0.014832
2022-01-21 19:26:54,173 iteration 3528 : loss : 0.060415, loss_ce: 0.025321
2022-01-21 19:26:55,534 iteration 3529 : loss : 0.028789, loss_ce: 0.007096
2022-01-21 19:26:56,923 iteration 3530 : loss : 0.017845, loss_ce: 0.006678
2022-01-21 19:26:58,205 iteration 3531 : loss : 0.029769, loss_ce: 0.009164
2022-01-21 19:26:59,602 iteration 3532 : loss : 0.036714, loss_ce: 0.017971
2022-01-21 19:27:00,914 iteration 3533 : loss : 0.026188, loss_ce: 0.007512
2022-01-21 19:27:02,266 iteration 3534 : loss : 0.040974, loss_ce: 0.017774
2022-01-21 19:27:03,673 iteration 3535 : loss : 0.034547, loss_ce: 0.012953
2022-01-21 19:27:05,041 iteration 3536 : loss : 0.031355, loss_ce: 0.013756
 52%|██████████████             | 208/400 [1:25:20<1:16:31, 23.92s/it]2022-01-21 19:27:06,331 iteration 3537 : loss : 0.031623, loss_ce: 0.013156
2022-01-21 19:27:07,586 iteration 3538 : loss : 0.020335, loss_ce: 0.008669
2022-01-21 19:27:08,862 iteration 3539 : loss : 0.019858, loss_ce: 0.008296
2022-01-21 19:27:10,080 iteration 3540 : loss : 0.020185, loss_ce: 0.005586
2022-01-21 19:27:11,477 iteration 3541 : loss : 0.033493, loss_ce: 0.012818
2022-01-21 19:27:12,804 iteration 3542 : loss : 0.027980, loss_ce: 0.012030
2022-01-21 19:27:14,242 iteration 3543 : loss : 0.040468, loss_ce: 0.011961
2022-01-21 19:27:15,496 iteration 3544 : loss : 0.018101, loss_ce: 0.006846
2022-01-21 19:27:16,813 iteration 3545 : loss : 0.020980, loss_ce: 0.008857
2022-01-21 19:27:18,070 iteration 3546 : loss : 0.019789, loss_ce: 0.006969
2022-01-21 19:27:19,396 iteration 3547 : loss : 0.022176, loss_ce: 0.010005
2022-01-21 19:27:20,668 iteration 3548 : loss : 0.027372, loss_ce: 0.008875
2022-01-21 19:27:22,002 iteration 3549 : loss : 0.026202, loss_ce: 0.011511
2022-01-21 19:27:23,367 iteration 3550 : loss : 0.021337, loss_ce: 0.009280
2022-01-21 19:27:24,758 iteration 3551 : loss : 0.038408, loss_ce: 0.013556
2022-01-21 19:27:26,146 iteration 3552 : loss : 0.063932, loss_ce: 0.021370
2022-01-21 19:27:27,552 iteration 3553 : loss : 0.032291, loss_ce: 0.015535
 52%|██████████████             | 209/400 [1:25:43<1:14:47, 23.50s/it]2022-01-21 19:27:28,930 iteration 3554 : loss : 0.031310, loss_ce: 0.013635
2022-01-21 19:27:30,233 iteration 3555 : loss : 0.019302, loss_ce: 0.006371
2022-01-21 19:27:31,539 iteration 3556 : loss : 0.021648, loss_ce: 0.009524
2022-01-21 19:27:32,951 iteration 3557 : loss : 0.025050, loss_ce: 0.007189
2022-01-21 19:27:34,232 iteration 3558 : loss : 0.046500, loss_ce: 0.011480
2022-01-21 19:27:35,542 iteration 3559 : loss : 0.021260, loss_ce: 0.007013
2022-01-21 19:27:36,759 iteration 3560 : loss : 0.019666, loss_ce: 0.009208
2022-01-21 19:27:38,160 iteration 3561 : loss : 0.031700, loss_ce: 0.013543
2022-01-21 19:27:39,454 iteration 3562 : loss : 0.024412, loss_ce: 0.008690
2022-01-21 19:27:40,814 iteration 3563 : loss : 0.022920, loss_ce: 0.007895
2022-01-21 19:27:42,152 iteration 3564 : loss : 0.035876, loss_ce: 0.013076
2022-01-21 19:27:43,590 iteration 3565 : loss : 0.032611, loss_ce: 0.010265
2022-01-21 19:27:44,934 iteration 3566 : loss : 0.023997, loss_ce: 0.008570
2022-01-21 19:27:46,347 iteration 3567 : loss : 0.038110, loss_ce: 0.017755
2022-01-21 19:27:47,736 iteration 3568 : loss : 0.025549, loss_ce: 0.009573
2022-01-21 19:27:49,123 iteration 3569 : loss : 0.043321, loss_ce: 0.009480
2022-01-21 19:27:49,124 Training Data Eval:
2022-01-21 19:27:55,637   Average segmentation loss on training set: 0.0163
2022-01-21 19:27:55,638 Validation Data Eval:
2022-01-21 19:27:57,872   Average segmentation loss on validation set: 0.0649
2022-01-21 19:27:59,218 iteration 3570 : loss : 0.031067, loss_ce: 0.012205
 52%|██████████████▏            | 210/400 [1:26:14<1:22:09, 25.95s/it]2022-01-21 19:28:00,580 iteration 3571 : loss : 0.021826, loss_ce: 0.009159
2022-01-21 19:28:01,914 iteration 3572 : loss : 0.019648, loss_ce: 0.005504
2022-01-21 19:28:03,242 iteration 3573 : loss : 0.029496, loss_ce: 0.011156
2022-01-21 19:28:04,541 iteration 3574 : loss : 0.018151, loss_ce: 0.007473
2022-01-21 19:28:05,845 iteration 3575 : loss : 0.026133, loss_ce: 0.011997
2022-01-21 19:28:07,190 iteration 3576 : loss : 0.025010, loss_ce: 0.009025
2022-01-21 19:28:08,571 iteration 3577 : loss : 0.020951, loss_ce: 0.009908
2022-01-21 19:28:09,949 iteration 3578 : loss : 0.030273, loss_ce: 0.012701
2022-01-21 19:28:11,255 iteration 3579 : loss : 0.019161, loss_ce: 0.007495
2022-01-21 19:28:12,613 iteration 3580 : loss : 0.023662, loss_ce: 0.008117
2022-01-21 19:28:13,905 iteration 3581 : loss : 0.024463, loss_ce: 0.005993
2022-01-21 19:28:15,223 iteration 3582 : loss : 0.018754, loss_ce: 0.007082
2022-01-21 19:28:16,588 iteration 3583 : loss : 0.024743, loss_ce: 0.009580
2022-01-21 19:28:17,883 iteration 3584 : loss : 0.018939, loss_ce: 0.006778
2022-01-21 19:28:19,196 iteration 3585 : loss : 0.020720, loss_ce: 0.007372
2022-01-21 19:28:20,460 iteration 3586 : loss : 0.021318, loss_ce: 0.007541
2022-01-21 19:28:21,781 iteration 3587 : loss : 0.019621, loss_ce: 0.008471
 53%|██████████████▏            | 211/400 [1:26:37<1:18:31, 24.93s/it]2022-01-21 19:28:23,062 iteration 3588 : loss : 0.022864, loss_ce: 0.007759
2022-01-21 19:28:24,425 iteration 3589 : loss : 0.026625, loss_ce: 0.009290
2022-01-21 19:28:25,748 iteration 3590 : loss : 0.020761, loss_ce: 0.009576
2022-01-21 19:28:27,056 iteration 3591 : loss : 0.028950, loss_ce: 0.010187
2022-01-21 19:28:28,439 iteration 3592 : loss : 0.018715, loss_ce: 0.007342
2022-01-21 19:28:29,782 iteration 3593 : loss : 0.038134, loss_ce: 0.010477
2022-01-21 19:28:31,125 iteration 3594 : loss : 0.016883, loss_ce: 0.005081
2022-01-21 19:28:32,583 iteration 3595 : loss : 0.050858, loss_ce: 0.011605
2022-01-21 19:28:33,837 iteration 3596 : loss : 0.031719, loss_ce: 0.015731
2022-01-21 19:28:35,241 iteration 3597 : loss : 0.025533, loss_ce: 0.008695
2022-01-21 19:28:36,567 iteration 3598 : loss : 0.060223, loss_ce: 0.034205
2022-01-21 19:28:37,910 iteration 3599 : loss : 0.027055, loss_ce: 0.011347
2022-01-21 19:28:39,221 iteration 3600 : loss : 0.021738, loss_ce: 0.009621
2022-01-21 19:28:40,545 iteration 3601 : loss : 0.027067, loss_ce: 0.012789
2022-01-21 19:28:41,844 iteration 3602 : loss : 0.022507, loss_ce: 0.009969
2022-01-21 19:28:43,127 iteration 3603 : loss : 0.018387, loss_ce: 0.007525
2022-01-21 19:28:44,399 iteration 3604 : loss : 0.019223, loss_ce: 0.007589
 53%|██████████████▎            | 212/400 [1:26:59<1:15:56, 24.24s/it]2022-01-21 19:28:45,749 iteration 3605 : loss : 0.019025, loss_ce: 0.007306
2022-01-21 19:28:47,074 iteration 3606 : loss : 0.026109, loss_ce: 0.009362
2022-01-21 19:28:48,335 iteration 3607 : loss : 0.018855, loss_ce: 0.006932
2022-01-21 19:28:49,598 iteration 3608 : loss : 0.020297, loss_ce: 0.009442
2022-01-21 19:28:50,946 iteration 3609 : loss : 0.021654, loss_ce: 0.006741
2022-01-21 19:28:52,233 iteration 3610 : loss : 0.020603, loss_ce: 0.008960
2022-01-21 19:28:53,591 iteration 3611 : loss : 0.024026, loss_ce: 0.010980
2022-01-21 19:28:54,970 iteration 3612 : loss : 0.020776, loss_ce: 0.007243
2022-01-21 19:28:56,302 iteration 3613 : loss : 0.020749, loss_ce: 0.007076
2022-01-21 19:28:57,671 iteration 3614 : loss : 0.017203, loss_ce: 0.005351
2022-01-21 19:28:58,970 iteration 3615 : loss : 0.021974, loss_ce: 0.006695
2022-01-21 19:29:00,365 iteration 3616 : loss : 0.021516, loss_ce: 0.007037
2022-01-21 19:29:01,676 iteration 3617 : loss : 0.024182, loss_ce: 0.009267
2022-01-21 19:29:02,993 iteration 3618 : loss : 0.024381, loss_ce: 0.013151
2022-01-21 19:29:04,304 iteration 3619 : loss : 0.020768, loss_ce: 0.008704
2022-01-21 19:29:05,661 iteration 3620 : loss : 0.039452, loss_ce: 0.017279
2022-01-21 19:29:06,973 iteration 3621 : loss : 0.025018, loss_ce: 0.009174
 53%|██████████████▍            | 213/400 [1:27:22<1:13:59, 23.74s/it]2022-01-21 19:29:08,395 iteration 3622 : loss : 0.033445, loss_ce: 0.011133
2022-01-21 19:29:09,723 iteration 3623 : loss : 0.018758, loss_ce: 0.007312
2022-01-21 19:29:11,127 iteration 3624 : loss : 0.018488, loss_ce: 0.005658
2022-01-21 19:29:12,523 iteration 3625 : loss : 0.032218, loss_ce: 0.013505
2022-01-21 19:29:13,850 iteration 3626 : loss : 0.022778, loss_ce: 0.008827
2022-01-21 19:29:15,218 iteration 3627 : loss : 0.025275, loss_ce: 0.014111
2022-01-21 19:29:16,563 iteration 3628 : loss : 0.018902, loss_ce: 0.005884
2022-01-21 19:29:17,969 iteration 3629 : loss : 0.023044, loss_ce: 0.011345
2022-01-21 19:29:19,300 iteration 3630 : loss : 0.018225, loss_ce: 0.007630
2022-01-21 19:29:20,565 iteration 3631 : loss : 0.019911, loss_ce: 0.008404
2022-01-21 19:29:21,828 iteration 3632 : loss : 0.017765, loss_ce: 0.007696
2022-01-21 19:29:23,213 iteration 3633 : loss : 0.026921, loss_ce: 0.011412
2022-01-21 19:29:24,530 iteration 3634 : loss : 0.023869, loss_ce: 0.008802
2022-01-21 19:29:25,811 iteration 3635 : loss : 0.018800, loss_ce: 0.006640
2022-01-21 19:29:27,092 iteration 3636 : loss : 0.019880, loss_ce: 0.008788
2022-01-21 19:29:28,475 iteration 3637 : loss : 0.030943, loss_ce: 0.008442
2022-01-21 19:29:29,744 iteration 3638 : loss : 0.017846, loss_ce: 0.006131
 54%|██████████████▍            | 214/400 [1:27:45<1:12:41, 23.45s/it]2022-01-21 19:29:31,083 iteration 3639 : loss : 0.017723, loss_ce: 0.007886
2022-01-21 19:29:32,451 iteration 3640 : loss : 0.017447, loss_ce: 0.005979
2022-01-21 19:29:33,781 iteration 3641 : loss : 0.020726, loss_ce: 0.006659
2022-01-21 19:29:35,153 iteration 3642 : loss : 0.033949, loss_ce: 0.014175
2022-01-21 19:29:36,474 iteration 3643 : loss : 0.022660, loss_ce: 0.009993
2022-01-21 19:29:37,786 iteration 3644 : loss : 0.020605, loss_ce: 0.009301
2022-01-21 19:29:39,073 iteration 3645 : loss : 0.021746, loss_ce: 0.007700
2022-01-21 19:29:40,408 iteration 3646 : loss : 0.019053, loss_ce: 0.006498
2022-01-21 19:29:41,779 iteration 3647 : loss : 0.022063, loss_ce: 0.008187
2022-01-21 19:29:43,217 iteration 3648 : loss : 0.036381, loss_ce: 0.014091
2022-01-21 19:29:44,566 iteration 3649 : loss : 0.024357, loss_ce: 0.007256
2022-01-21 19:29:45,896 iteration 3650 : loss : 0.026471, loss_ce: 0.008129
2022-01-21 19:29:47,246 iteration 3651 : loss : 0.030649, loss_ce: 0.016167
2022-01-21 19:29:48,544 iteration 3652 : loss : 0.021784, loss_ce: 0.009157
2022-01-21 19:29:49,936 iteration 3653 : loss : 0.030903, loss_ce: 0.007907
2022-01-21 19:29:51,278 iteration 3654 : loss : 0.018376, loss_ce: 0.004835
2022-01-21 19:29:51,278 Training Data Eval:
2022-01-21 19:29:57,804   Average segmentation loss on training set: 0.0144
2022-01-21 19:29:57,804 Validation Data Eval:
2022-01-21 19:30:00,036   Average segmentation loss on validation set: 0.0711
2022-01-21 19:30:01,267 iteration 3655 : loss : 0.019149, loss_ce: 0.007026
 54%|██████████████▌            | 215/400 [1:28:16<1:19:46, 25.87s/it]2022-01-21 19:30:02,690 iteration 3656 : loss : 0.045984, loss_ce: 0.009641
2022-01-21 19:30:03,988 iteration 3657 : loss : 0.020229, loss_ce: 0.010049
2022-01-21 19:30:05,316 iteration 3658 : loss : 0.020479, loss_ce: 0.008212
2022-01-21 19:30:06,679 iteration 3659 : loss : 0.020918, loss_ce: 0.006190
2022-01-21 19:30:08,103 iteration 3660 : loss : 0.039704, loss_ce: 0.013518
2022-01-21 19:30:09,538 iteration 3661 : loss : 0.021978, loss_ce: 0.009497
2022-01-21 19:30:10,788 iteration 3662 : loss : 0.019607, loss_ce: 0.006929
2022-01-21 19:30:12,080 iteration 3663 : loss : 0.016191, loss_ce: 0.005395
2022-01-21 19:30:13,385 iteration 3664 : loss : 0.022610, loss_ce: 0.006311
2022-01-21 19:30:14,701 iteration 3665 : loss : 0.021018, loss_ce: 0.009339
2022-01-21 19:30:16,133 iteration 3666 : loss : 0.038782, loss_ce: 0.016742
2022-01-21 19:30:17,509 iteration 3667 : loss : 0.024976, loss_ce: 0.010536
2022-01-21 19:30:18,884 iteration 3668 : loss : 0.028882, loss_ce: 0.011998
2022-01-21 19:30:20,229 iteration 3669 : loss : 0.023043, loss_ce: 0.011622
2022-01-21 19:30:21,534 iteration 3670 : loss : 0.032213, loss_ce: 0.009287
2022-01-21 19:30:22,902 iteration 3671 : loss : 0.025555, loss_ce: 0.008771
2022-01-21 19:30:24,187 iteration 3672 : loss : 0.020918, loss_ce: 0.008960
 54%|██████████████▌            | 216/400 [1:28:39<1:16:37, 24.98s/it]2022-01-21 19:30:25,540 iteration 3673 : loss : 0.024408, loss_ce: 0.011138
2022-01-21 19:30:26,873 iteration 3674 : loss : 0.025744, loss_ce: 0.010794
2022-01-21 19:30:28,184 iteration 3675 : loss : 0.020643, loss_ce: 0.012468
2022-01-21 19:30:29,493 iteration 3676 : loss : 0.034963, loss_ce: 0.013418
2022-01-21 19:30:30,805 iteration 3677 : loss : 0.024752, loss_ce: 0.012102
2022-01-21 19:30:32,207 iteration 3678 : loss : 0.030424, loss_ce: 0.011872
2022-01-21 19:30:33,522 iteration 3679 : loss : 0.021360, loss_ce: 0.008288
2022-01-21 19:30:34,822 iteration 3680 : loss : 0.025920, loss_ce: 0.008364
2022-01-21 19:30:36,193 iteration 3681 : loss : 0.030379, loss_ce: 0.012282
2022-01-21 19:30:37,501 iteration 3682 : loss : 0.027621, loss_ce: 0.011399
2022-01-21 19:30:38,869 iteration 3683 : loss : 0.055189, loss_ce: 0.006833
2022-01-21 19:30:40,168 iteration 3684 : loss : 0.013076, loss_ce: 0.003623
2022-01-21 19:30:41,474 iteration 3685 : loss : 0.038752, loss_ce: 0.021733
2022-01-21 19:30:42,819 iteration 3686 : loss : 0.034307, loss_ce: 0.012429
2022-01-21 19:30:44,146 iteration 3687 : loss : 0.025201, loss_ce: 0.008744
2022-01-21 19:30:45,462 iteration 3688 : loss : 0.031094, loss_ce: 0.014542
2022-01-21 19:30:46,722 iteration 3689 : loss : 0.022115, loss_ce: 0.008239
 54%|██████████████▋            | 217/400 [1:29:02<1:13:58, 24.25s/it]2022-01-21 19:30:48,045 iteration 3690 : loss : 0.025983, loss_ce: 0.006153
2022-01-21 19:30:49,447 iteration 3691 : loss : 0.037380, loss_ce: 0.007481
2022-01-21 19:30:50,780 iteration 3692 : loss : 0.024994, loss_ce: 0.011521
2022-01-21 19:30:52,177 iteration 3693 : loss : 0.037376, loss_ce: 0.013651
2022-01-21 19:30:53,514 iteration 3694 : loss : 0.022269, loss_ce: 0.010394
2022-01-21 19:30:54,800 iteration 3695 : loss : 0.020243, loss_ce: 0.008111
2022-01-21 19:30:56,173 iteration 3696 : loss : 0.027796, loss_ce: 0.014264
2022-01-21 19:30:57,493 iteration 3697 : loss : 0.025339, loss_ce: 0.007652
2022-01-21 19:30:58,825 iteration 3698 : loss : 0.032926, loss_ce: 0.012036
2022-01-21 19:31:00,217 iteration 3699 : loss : 0.035297, loss_ce: 0.016787
2022-01-21 19:31:01,549 iteration 3700 : loss : 0.021973, loss_ce: 0.009954
2022-01-21 19:31:02,851 iteration 3701 : loss : 0.020581, loss_ce: 0.008988
2022-01-21 19:31:04,143 iteration 3702 : loss : 0.037155, loss_ce: 0.015893
2022-01-21 19:31:05,576 iteration 3703 : loss : 0.031777, loss_ce: 0.014265
2022-01-21 19:31:06,865 iteration 3704 : loss : 0.019003, loss_ce: 0.005762
2022-01-21 19:31:08,145 iteration 3705 : loss : 0.018295, loss_ce: 0.005757
2022-01-21 19:31:09,418 iteration 3706 : loss : 0.017293, loss_ce: 0.004762
 55%|██████████████▋            | 218/400 [1:29:25<1:12:08, 23.78s/it]2022-01-21 19:31:10,774 iteration 3707 : loss : 0.030409, loss_ce: 0.011096
2022-01-21 19:31:12,112 iteration 3708 : loss : 0.020597, loss_ce: 0.008538
2022-01-21 19:31:13,441 iteration 3709 : loss : 0.022457, loss_ce: 0.007250
2022-01-21 19:31:14,812 iteration 3710 : loss : 0.022258, loss_ce: 0.007457
2022-01-21 19:31:16,117 iteration 3711 : loss : 0.019650, loss_ce: 0.007192
2022-01-21 19:31:17,467 iteration 3712 : loss : 0.037697, loss_ce: 0.012745
2022-01-21 19:31:18,750 iteration 3713 : loss : 0.028170, loss_ce: 0.012435
2022-01-21 19:31:20,044 iteration 3714 : loss : 0.017561, loss_ce: 0.006576
2022-01-21 19:31:21,378 iteration 3715 : loss : 0.025546, loss_ce: 0.011290
2022-01-21 19:31:22,669 iteration 3716 : loss : 0.024137, loss_ce: 0.008750
2022-01-21 19:31:24,013 iteration 3717 : loss : 0.017881, loss_ce: 0.007081
2022-01-21 19:31:25,397 iteration 3718 : loss : 0.025489, loss_ce: 0.011655
2022-01-21 19:31:26,670 iteration 3719 : loss : 0.017721, loss_ce: 0.004640
2022-01-21 19:31:28,014 iteration 3720 : loss : 0.017646, loss_ce: 0.008711
2022-01-21 19:31:29,346 iteration 3721 : loss : 0.022107, loss_ce: 0.009909
2022-01-21 19:31:30,660 iteration 3722 : loss : 0.019068, loss_ce: 0.007123
2022-01-21 19:31:31,950 iteration 3723 : loss : 0.025760, loss_ce: 0.006872
 55%|██████████████▊            | 219/400 [1:29:47<1:10:36, 23.41s/it]2022-01-21 19:31:33,244 iteration 3724 : loss : 0.018286, loss_ce: 0.008632
2022-01-21 19:31:34,524 iteration 3725 : loss : 0.026328, loss_ce: 0.010416
2022-01-21 19:31:35,906 iteration 3726 : loss : 0.030695, loss_ce: 0.014585
2022-01-21 19:31:37,240 iteration 3727 : loss : 0.018630, loss_ce: 0.007142
2022-01-21 19:31:38,582 iteration 3728 : loss : 0.022827, loss_ce: 0.006268
2022-01-21 19:31:39,868 iteration 3729 : loss : 0.018030, loss_ce: 0.004732
2022-01-21 19:31:41,175 iteration 3730 : loss : 0.019673, loss_ce: 0.008337
2022-01-21 19:31:42,477 iteration 3731 : loss : 0.026318, loss_ce: 0.008122
2022-01-21 19:31:43,828 iteration 3732 : loss : 0.025588, loss_ce: 0.008943
2022-01-21 19:31:45,106 iteration 3733 : loss : 0.024452, loss_ce: 0.009167
2022-01-21 19:31:46,445 iteration 3734 : loss : 0.026765, loss_ce: 0.012548
2022-01-21 19:31:47,774 iteration 3735 : loss : 0.044333, loss_ce: 0.011386
2022-01-21 19:31:49,152 iteration 3736 : loss : 0.032118, loss_ce: 0.013644
2022-01-21 19:31:50,438 iteration 3737 : loss : 0.024058, loss_ce: 0.007920
2022-01-21 19:31:51,758 iteration 3738 : loss : 0.018117, loss_ce: 0.006153
2022-01-21 19:31:53,034 iteration 3739 : loss : 0.018124, loss_ce: 0.007410
2022-01-21 19:31:53,035 Training Data Eval:
2022-01-21 19:31:59,562   Average segmentation loss on training set: 0.0143
2022-01-21 19:31:59,562 Validation Data Eval:
2022-01-21 19:32:01,804   Average segmentation loss on validation set: 0.0701
2022-01-21 19:32:03,284 iteration 3740 : loss : 0.030665, loss_ce: 0.014573
 55%|██████████████▊            | 220/400 [1:30:18<1:17:21, 25.78s/it]2022-01-21 19:32:04,768 iteration 3741 : loss : 0.032618, loss_ce: 0.010026
2022-01-21 19:32:06,091 iteration 3742 : loss : 0.024838, loss_ce: 0.013122
2022-01-21 19:32:07,415 iteration 3743 : loss : 0.027593, loss_ce: 0.009084
2022-01-21 19:32:08,790 iteration 3744 : loss : 0.026236, loss_ce: 0.009230
2022-01-21 19:32:10,184 iteration 3745 : loss : 0.027578, loss_ce: 0.010068
2022-01-21 19:32:11,581 iteration 3746 : loss : 0.022472, loss_ce: 0.008669
2022-01-21 19:32:12,902 iteration 3747 : loss : 0.022055, loss_ce: 0.006966
2022-01-21 19:32:14,207 iteration 3748 : loss : 0.018121, loss_ce: 0.008182
2022-01-21 19:32:15,585 iteration 3749 : loss : 0.032672, loss_ce: 0.012085
2022-01-21 19:32:16,991 iteration 3750 : loss : 0.026326, loss_ce: 0.011006
2022-01-21 19:32:18,345 iteration 3751 : loss : 0.025579, loss_ce: 0.007330
2022-01-21 19:32:19,657 iteration 3752 : loss : 0.024696, loss_ce: 0.007181
2022-01-21 19:32:20,939 iteration 3753 : loss : 0.021091, loss_ce: 0.005975
2022-01-21 19:32:22,273 iteration 3754 : loss : 0.016865, loss_ce: 0.005791
2022-01-21 19:32:23,651 iteration 3755 : loss : 0.025367, loss_ce: 0.012840
2022-01-21 19:32:24,910 iteration 3756 : loss : 0.022147, loss_ce: 0.011000
2022-01-21 19:32:26,186 iteration 3757 : loss : 0.017655, loss_ce: 0.007961
 55%|██████████████▉            | 221/400 [1:30:41<1:14:21, 24.92s/it]2022-01-21 19:32:27,625 iteration 3758 : loss : 0.024007, loss_ce: 0.008639
2022-01-21 19:32:28,911 iteration 3759 : loss : 0.018384, loss_ce: 0.006279
2022-01-21 19:32:30,221 iteration 3760 : loss : 0.016381, loss_ce: 0.006914
2022-01-21 19:32:31,594 iteration 3761 : loss : 0.023240, loss_ce: 0.008968
2022-01-21 19:32:32,984 iteration 3762 : loss : 0.020905, loss_ce: 0.009734
2022-01-21 19:32:34,409 iteration 3763 : loss : 0.020459, loss_ce: 0.007063
2022-01-21 19:32:35,732 iteration 3764 : loss : 0.022058, loss_ce: 0.007325
2022-01-21 19:32:37,016 iteration 3765 : loss : 0.017452, loss_ce: 0.007283
2022-01-21 19:32:38,396 iteration 3766 : loss : 0.029017, loss_ce: 0.010041
2022-01-21 19:32:39,722 iteration 3767 : loss : 0.019767, loss_ce: 0.007726
2022-01-21 19:32:41,012 iteration 3768 : loss : 0.023498, loss_ce: 0.006909
2022-01-21 19:32:42,306 iteration 3769 : loss : 0.016868, loss_ce: 0.007290
2022-01-21 19:32:43,664 iteration 3770 : loss : 0.021757, loss_ce: 0.004951
2022-01-21 19:32:45,114 iteration 3771 : loss : 0.025707, loss_ce: 0.009208
2022-01-21 19:32:46,503 iteration 3772 : loss : 0.024685, loss_ce: 0.006415
2022-01-21 19:32:47,859 iteration 3773 : loss : 0.016143, loss_ce: 0.006164
2022-01-21 19:32:49,259 iteration 3774 : loss : 0.037744, loss_ce: 0.018413
 56%|██████████████▉            | 222/400 [1:31:04<1:12:17, 24.37s/it]2022-01-21 19:32:50,611 iteration 3775 : loss : 0.020151, loss_ce: 0.007480
2022-01-21 19:32:51,862 iteration 3776 : loss : 0.022461, loss_ce: 0.009722
2022-01-21 19:32:53,172 iteration 3777 : loss : 0.015999, loss_ce: 0.004365
2022-01-21 19:32:54,457 iteration 3778 : loss : 0.017018, loss_ce: 0.006683
2022-01-21 19:32:55,745 iteration 3779 : loss : 0.022606, loss_ce: 0.010210
2022-01-21 19:32:57,082 iteration 3780 : loss : 0.023298, loss_ce: 0.007657
2022-01-21 19:32:58,415 iteration 3781 : loss : 0.023103, loss_ce: 0.009147
2022-01-21 19:32:59,765 iteration 3782 : loss : 0.046086, loss_ce: 0.007975
2022-01-21 19:33:01,115 iteration 3783 : loss : 0.021797, loss_ce: 0.008732
2022-01-21 19:33:02,471 iteration 3784 : loss : 0.019540, loss_ce: 0.009368
2022-01-21 19:33:03,772 iteration 3785 : loss : 0.022111, loss_ce: 0.008837
2022-01-21 19:33:05,069 iteration 3786 : loss : 0.016153, loss_ce: 0.006120
2022-01-21 19:33:06,355 iteration 3787 : loss : 0.021636, loss_ce: 0.008479
2022-01-21 19:33:07,750 iteration 3788 : loss : 0.029743, loss_ce: 0.008185
2022-01-21 19:33:09,073 iteration 3789 : loss : 0.019015, loss_ce: 0.005071
2022-01-21 19:33:10,433 iteration 3790 : loss : 0.036559, loss_ce: 0.012764
2022-01-21 19:33:11,790 iteration 3791 : loss : 0.023312, loss_ce: 0.010783
 56%|███████████████            | 223/400 [1:31:27<1:10:15, 23.82s/it]2022-01-21 19:33:13,123 iteration 3792 : loss : 0.014217, loss_ce: 0.004983
2022-01-21 19:33:14,496 iteration 3793 : loss : 0.020752, loss_ce: 0.006638
2022-01-21 19:33:15,847 iteration 3794 : loss : 0.024097, loss_ce: 0.009739
2022-01-21 19:33:17,175 iteration 3795 : loss : 0.016550, loss_ce: 0.005333
2022-01-21 19:33:18,410 iteration 3796 : loss : 0.014774, loss_ce: 0.004968
2022-01-21 19:33:19,713 iteration 3797 : loss : 0.018797, loss_ce: 0.006946
2022-01-21 19:33:20,974 iteration 3798 : loss : 0.017572, loss_ce: 0.006608
2022-01-21 19:33:22,281 iteration 3799 : loss : 0.031397, loss_ce: 0.011500
2022-01-21 19:33:23,588 iteration 3800 : loss : 0.014907, loss_ce: 0.004650
2022-01-21 19:33:24,895 iteration 3801 : loss : 0.033163, loss_ce: 0.006553
2022-01-21 19:33:26,188 iteration 3802 : loss : 0.020467, loss_ce: 0.010324
2022-01-21 19:33:27,504 iteration 3803 : loss : 0.015244, loss_ce: 0.004980
2022-01-21 19:33:28,821 iteration 3804 : loss : 0.028308, loss_ce: 0.010259
2022-01-21 19:33:30,113 iteration 3805 : loss : 0.021817, loss_ce: 0.008673
2022-01-21 19:33:31,402 iteration 3806 : loss : 0.024445, loss_ce: 0.012011
2022-01-21 19:33:32,760 iteration 3807 : loss : 0.031692, loss_ce: 0.011325
2022-01-21 19:33:34,095 iteration 3808 : loss : 0.030480, loss_ce: 0.010843
 56%|███████████████            | 224/400 [1:31:49<1:08:31, 23.36s/it]2022-01-21 19:33:35,399 iteration 3809 : loss : 0.014227, loss_ce: 0.004474
2022-01-21 19:33:36,699 iteration 3810 : loss : 0.017363, loss_ce: 0.006402
2022-01-21 19:33:38,014 iteration 3811 : loss : 0.020666, loss_ce: 0.005305
2022-01-21 19:33:39,348 iteration 3812 : loss : 0.026194, loss_ce: 0.012422
2022-01-21 19:33:40,655 iteration 3813 : loss : 0.019995, loss_ce: 0.009454
2022-01-21 19:33:42,005 iteration 3814 : loss : 0.024725, loss_ce: 0.008666
2022-01-21 19:33:43,328 iteration 3815 : loss : 0.023633, loss_ce: 0.007671
2022-01-21 19:33:44,665 iteration 3816 : loss : 0.018362, loss_ce: 0.006711
2022-01-21 19:33:45,939 iteration 3817 : loss : 0.027095, loss_ce: 0.010124
2022-01-21 19:33:47,292 iteration 3818 : loss : 0.019576, loss_ce: 0.008694
2022-01-21 19:33:48,666 iteration 3819 : loss : 0.025834, loss_ce: 0.012418
2022-01-21 19:33:50,014 iteration 3820 : loss : 0.023072, loss_ce: 0.007784
2022-01-21 19:33:51,376 iteration 3821 : loss : 0.027500, loss_ce: 0.013280
2022-01-21 19:33:52,669 iteration 3822 : loss : 0.024779, loss_ce: 0.007545
2022-01-21 19:33:54,073 iteration 3823 : loss : 0.024885, loss_ce: 0.008315
2022-01-21 19:33:55,413 iteration 3824 : loss : 0.029426, loss_ce: 0.010053
2022-01-21 19:33:55,420 Training Data Eval:
2022-01-21 19:34:01,935   Average segmentation loss on training set: 0.0135
2022-01-21 19:34:01,936 Validation Data Eval:
2022-01-21 19:34:04,175   Average segmentation loss on validation set: 0.0644
2022-01-21 19:34:05,573 iteration 3825 : loss : 0.034900, loss_ce: 0.014807
 56%|███████████████▏           | 225/400 [1:32:21<1:15:14, 25.80s/it]2022-01-21 19:34:06,954 iteration 3826 : loss : 0.019210, loss_ce: 0.008357
2022-01-21 19:34:08,238 iteration 3827 : loss : 0.028986, loss_ce: 0.009430
2022-01-21 19:34:09,580 iteration 3828 : loss : 0.019232, loss_ce: 0.006980
2022-01-21 19:34:10,912 iteration 3829 : loss : 0.024554, loss_ce: 0.006568
2022-01-21 19:34:12,205 iteration 3830 : loss : 0.016306, loss_ce: 0.005507
2022-01-21 19:34:13,484 iteration 3831 : loss : 0.023378, loss_ce: 0.007835
2022-01-21 19:34:14,758 iteration 3832 : loss : 0.022147, loss_ce: 0.005103
2022-01-21 19:34:16,080 iteration 3833 : loss : 0.021758, loss_ce: 0.011853
2022-01-21 19:34:17,439 iteration 3834 : loss : 0.024390, loss_ce: 0.011664
2022-01-21 19:34:18,779 iteration 3835 : loss : 0.024733, loss_ce: 0.009634
2022-01-21 19:34:20,110 iteration 3836 : loss : 0.022190, loss_ce: 0.008275
2022-01-21 19:34:21,462 iteration 3837 : loss : 0.027375, loss_ce: 0.009547
2022-01-21 19:34:22,876 iteration 3838 : loss : 0.040092, loss_ce: 0.013282
2022-01-21 19:34:24,200 iteration 3839 : loss : 0.026755, loss_ce: 0.014530
2022-01-21 19:34:25,537 iteration 3840 : loss : 0.023511, loss_ce: 0.005770
2022-01-21 19:34:26,829 iteration 3841 : loss : 0.020744, loss_ce: 0.007706
2022-01-21 19:34:28,177 iteration 3842 : loss : 0.037684, loss_ce: 0.020372
 56%|███████████████▎           | 226/400 [1:32:43<1:12:01, 24.84s/it]2022-01-21 19:34:29,506 iteration 3843 : loss : 0.020130, loss_ce: 0.008159
2022-01-21 19:34:30,873 iteration 3844 : loss : 0.027062, loss_ce: 0.008086
2022-01-21 19:34:32,230 iteration 3845 : loss : 0.018939, loss_ce: 0.008625
2022-01-21 19:34:33,519 iteration 3846 : loss : 0.016421, loss_ce: 0.006062
2022-01-21 19:34:34,834 iteration 3847 : loss : 0.019448, loss_ce: 0.007732
2022-01-21 19:34:36,207 iteration 3848 : loss : 0.022736, loss_ce: 0.011310
2022-01-21 19:34:37,634 iteration 3849 : loss : 0.027211, loss_ce: 0.010561
2022-01-21 19:34:39,049 iteration 3850 : loss : 0.033538, loss_ce: 0.008876
2022-01-21 19:34:40,391 iteration 3851 : loss : 0.016327, loss_ce: 0.006705
2022-01-21 19:34:41,747 iteration 3852 : loss : 0.035466, loss_ce: 0.011408
2022-01-21 19:34:43,033 iteration 3853 : loss : 0.018478, loss_ce: 0.005335
2022-01-21 19:34:44,389 iteration 3854 : loss : 0.019255, loss_ce: 0.005877
2022-01-21 19:34:45,851 iteration 3855 : loss : 0.026956, loss_ce: 0.008921
2022-01-21 19:34:47,061 iteration 3856 : loss : 0.019660, loss_ce: 0.008737
2022-01-21 19:34:48,370 iteration 3857 : loss : 0.023527, loss_ce: 0.010921
2022-01-21 19:34:49,608 iteration 3858 : loss : 0.017670, loss_ce: 0.007045
2022-01-21 19:34:50,922 iteration 3859 : loss : 0.019319, loss_ce: 0.008892
 57%|███████████████▎           | 227/400 [1:33:06<1:09:48, 24.21s/it]2022-01-21 19:34:52,285 iteration 3860 : loss : 0.018295, loss_ce: 0.006976
2022-01-21 19:34:53,685 iteration 3861 : loss : 0.029103, loss_ce: 0.012856
2022-01-21 19:34:55,042 iteration 3862 : loss : 0.024004, loss_ce: 0.008687
2022-01-21 19:34:56,389 iteration 3863 : loss : 0.030638, loss_ce: 0.011662
2022-01-21 19:34:57,756 iteration 3864 : loss : 0.023290, loss_ce: 0.008540
2022-01-21 19:34:59,079 iteration 3865 : loss : 0.023434, loss_ce: 0.007788
2022-01-21 19:35:00,520 iteration 3866 : loss : 0.029243, loss_ce: 0.008963
2022-01-21 19:35:01,841 iteration 3867 : loss : 0.021250, loss_ce: 0.006921
2022-01-21 19:35:03,230 iteration 3868 : loss : 0.027010, loss_ce: 0.007370
2022-01-21 19:35:04,588 iteration 3869 : loss : 0.049254, loss_ce: 0.036085
2022-01-21 19:35:05,969 iteration 3870 : loss : 0.021001, loss_ce: 0.008929
2022-01-21 19:35:07,332 iteration 3871 : loss : 0.043405, loss_ce: 0.014959
2022-01-21 19:35:08,628 iteration 3872 : loss : 0.022857, loss_ce: 0.008004
2022-01-21 19:35:09,923 iteration 3873 : loss : 0.019712, loss_ce: 0.009938
2022-01-21 19:35:11,274 iteration 3874 : loss : 0.024342, loss_ce: 0.010288
2022-01-21 19:35:12,622 iteration 3875 : loss : 0.031996, loss_ce: 0.013058
2022-01-21 19:35:13,976 iteration 3876 : loss : 0.058856, loss_ce: 0.024127
 57%|███████████████▍           | 228/400 [1:33:29<1:08:24, 23.87s/it]2022-01-21 19:35:15,318 iteration 3877 : loss : 0.019738, loss_ce: 0.007631
2022-01-21 19:35:16,679 iteration 3878 : loss : 0.030383, loss_ce: 0.012198
2022-01-21 19:35:17,987 iteration 3879 : loss : 0.020203, loss_ce: 0.007497
2022-01-21 19:35:19,350 iteration 3880 : loss : 0.018966, loss_ce: 0.008028
2022-01-21 19:35:20,655 iteration 3881 : loss : 0.023535, loss_ce: 0.010005
2022-01-21 19:35:22,076 iteration 3882 : loss : 0.033489, loss_ce: 0.007791
2022-01-21 19:35:23,461 iteration 3883 : loss : 0.036296, loss_ce: 0.012150
2022-01-21 19:35:24,819 iteration 3884 : loss : 0.019364, loss_ce: 0.007582
2022-01-21 19:35:26,199 iteration 3885 : loss : 0.043381, loss_ce: 0.010520
2022-01-21 19:35:27,581 iteration 3886 : loss : 0.029908, loss_ce: 0.012978
2022-01-21 19:35:28,870 iteration 3887 : loss : 0.019200, loss_ce: 0.007082
2022-01-21 19:35:30,243 iteration 3888 : loss : 0.024350, loss_ce: 0.012655
2022-01-21 19:35:31,585 iteration 3889 : loss : 0.018812, loss_ce: 0.006953
2022-01-21 19:35:33,020 iteration 3890 : loss : 0.032046, loss_ce: 0.010467
2022-01-21 19:35:34,330 iteration 3891 : loss : 0.029289, loss_ce: 0.011095
2022-01-21 19:35:35,668 iteration 3892 : loss : 0.020547, loss_ce: 0.008877
2022-01-21 19:35:37,036 iteration 3893 : loss : 0.024628, loss_ce: 0.007674
 57%|███████████████▍           | 229/400 [1:33:52<1:07:19, 23.62s/it]2022-01-21 19:35:38,390 iteration 3894 : loss : 0.022040, loss_ce: 0.006813
2022-01-21 19:35:39,685 iteration 3895 : loss : 0.020460, loss_ce: 0.007286
2022-01-21 19:35:41,020 iteration 3896 : loss : 0.021575, loss_ce: 0.008776
2022-01-21 19:35:42,391 iteration 3897 : loss : 0.022533, loss_ce: 0.009187
2022-01-21 19:35:43,758 iteration 3898 : loss : 0.034375, loss_ce: 0.010764
2022-01-21 19:35:45,026 iteration 3899 : loss : 0.026212, loss_ce: 0.009101
2022-01-21 19:35:46,326 iteration 3900 : loss : 0.029618, loss_ce: 0.012755
2022-01-21 19:35:47,605 iteration 3901 : loss : 0.021406, loss_ce: 0.008936
2022-01-21 19:35:48,892 iteration 3902 : loss : 0.021772, loss_ce: 0.007177
2022-01-21 19:35:50,146 iteration 3903 : loss : 0.021060, loss_ce: 0.005763
2022-01-21 19:35:51,454 iteration 3904 : loss : 0.021536, loss_ce: 0.005794
2022-01-21 19:35:52,767 iteration 3905 : loss : 0.044925, loss_ce: 0.014210
2022-01-21 19:35:54,010 iteration 3906 : loss : 0.014895, loss_ce: 0.006154
2022-01-21 19:35:55,236 iteration 3907 : loss : 0.016072, loss_ce: 0.005579
2022-01-21 19:35:56,485 iteration 3908 : loss : 0.015348, loss_ce: 0.005752
2022-01-21 19:35:57,800 iteration 3909 : loss : 0.020785, loss_ce: 0.010290
2022-01-21 19:35:57,800 Training Data Eval:
2022-01-21 19:36:04,324   Average segmentation loss on training set: 0.0133
2022-01-21 19:36:04,324 Validation Data Eval:
2022-01-21 19:36:06,557   Average segmentation loss on validation set: 0.0636
2022-01-21 19:36:07,948 iteration 3910 : loss : 0.020877, loss_ce: 0.007187
 57%|███████████████▌           | 230/400 [1:34:23<1:13:07, 25.81s/it]2022-01-21 19:36:09,268 iteration 3911 : loss : 0.017863, loss_ce: 0.007140
2022-01-21 19:36:10,621 iteration 3912 : loss : 0.021180, loss_ce: 0.007999
2022-01-21 19:36:11,941 iteration 3913 : loss : 0.018232, loss_ce: 0.007602
2022-01-21 19:36:13,258 iteration 3914 : loss : 0.014476, loss_ce: 0.006940
2022-01-21 19:36:14,569 iteration 3915 : loss : 0.024251, loss_ce: 0.009807
2022-01-21 19:36:15,848 iteration 3916 : loss : 0.017282, loss_ce: 0.006034
2022-01-21 19:36:17,201 iteration 3917 : loss : 0.037733, loss_ce: 0.012160
2022-01-21 19:36:18,553 iteration 3918 : loss : 0.034339, loss_ce: 0.010739
2022-01-21 19:36:20,007 iteration 3919 : loss : 0.030078, loss_ce: 0.008621
2022-01-21 19:36:21,296 iteration 3920 : loss : 0.018760, loss_ce: 0.007809
2022-01-21 19:36:22,617 iteration 3921 : loss : 0.019470, loss_ce: 0.008523
2022-01-21 19:36:23,984 iteration 3922 : loss : 0.026143, loss_ce: 0.010433
2022-01-21 19:36:25,290 iteration 3923 : loss : 0.019614, loss_ce: 0.009929
2022-01-21 19:36:26,567 iteration 3924 : loss : 0.021550, loss_ce: 0.005496
2022-01-21 19:36:27,967 iteration 3925 : loss : 0.024003, loss_ce: 0.009105
2022-01-21 19:36:29,341 iteration 3926 : loss : 0.022583, loss_ce: 0.007271
2022-01-21 19:36:30,663 iteration 3927 : loss : 0.018135, loss_ce: 0.007243
 58%|███████████████▌           | 231/400 [1:34:46<1:10:05, 24.88s/it]2022-01-21 19:36:32,079 iteration 3928 : loss : 0.035840, loss_ce: 0.018777
2022-01-21 19:36:33,408 iteration 3929 : loss : 0.030776, loss_ce: 0.013981
2022-01-21 19:36:34,791 iteration 3930 : loss : 0.020174, loss_ce: 0.007635
2022-01-21 19:36:36,163 iteration 3931 : loss : 0.036016, loss_ce: 0.017443
2022-01-21 19:36:37,537 iteration 3932 : loss : 0.028993, loss_ce: 0.009474
2022-01-21 19:36:38,947 iteration 3933 : loss : 0.029064, loss_ce: 0.011517
2022-01-21 19:36:40,311 iteration 3934 : loss : 0.023990, loss_ce: 0.010261
2022-01-21 19:36:41,570 iteration 3935 : loss : 0.016627, loss_ce: 0.006802
2022-01-21 19:36:43,029 iteration 3936 : loss : 0.024481, loss_ce: 0.010806
2022-01-21 19:36:44,319 iteration 3937 : loss : 0.027058, loss_ce: 0.012916
2022-01-21 19:36:45,700 iteration 3938 : loss : 0.055310, loss_ce: 0.011198
2022-01-21 19:36:46,955 iteration 3939 : loss : 0.032529, loss_ce: 0.010044
2022-01-21 19:36:48,254 iteration 3940 : loss : 0.025004, loss_ce: 0.009303
2022-01-21 19:36:49,578 iteration 3941 : loss : 0.021886, loss_ce: 0.009539
2022-01-21 19:36:50,958 iteration 3942 : loss : 0.036555, loss_ce: 0.016133
2022-01-21 19:36:52,256 iteration 3943 : loss : 0.021269, loss_ce: 0.005576
2022-01-21 19:36:53,643 iteration 3944 : loss : 0.047237, loss_ce: 0.017267
 58%|███████████████▋           | 232/400 [1:35:09<1:08:04, 24.31s/it]2022-01-21 19:36:55,026 iteration 3945 : loss : 0.029556, loss_ce: 0.013318
2022-01-21 19:36:56,265 iteration 3946 : loss : 0.018949, loss_ce: 0.009191
2022-01-21 19:36:57,579 iteration 3947 : loss : 0.021888, loss_ce: 0.006628
2022-01-21 19:36:59,035 iteration 3948 : loss : 0.034669, loss_ce: 0.011028
2022-01-21 19:37:00,406 iteration 3949 : loss : 0.029400, loss_ce: 0.011580
2022-01-21 19:37:01,805 iteration 3950 : loss : 0.026033, loss_ce: 0.007541
2022-01-21 19:37:03,075 iteration 3951 : loss : 0.019419, loss_ce: 0.007764
2022-01-21 19:37:04,447 iteration 3952 : loss : 0.024340, loss_ce: 0.009734
2022-01-21 19:37:05,837 iteration 3953 : loss : 0.033098, loss_ce: 0.011218
2022-01-21 19:37:07,156 iteration 3954 : loss : 0.022622, loss_ce: 0.007091
2022-01-21 19:37:08,469 iteration 3955 : loss : 0.016894, loss_ce: 0.006089
2022-01-21 19:37:09,917 iteration 3956 : loss : 0.027493, loss_ce: 0.012556
2022-01-21 19:37:11,210 iteration 3957 : loss : 0.022843, loss_ce: 0.009605
2022-01-21 19:37:12,513 iteration 3958 : loss : 0.021774, loss_ce: 0.008111
2022-01-21 19:37:13,930 iteration 3959 : loss : 0.025754, loss_ce: 0.007459
2022-01-21 19:37:15,238 iteration 3960 : loss : 0.019446, loss_ce: 0.009538
2022-01-21 19:37:16,562 iteration 3961 : loss : 0.018301, loss_ce: 0.006514
 58%|███████████████▋           | 233/400 [1:35:32<1:06:29, 23.89s/it]2022-01-21 19:37:17,961 iteration 3962 : loss : 0.022755, loss_ce: 0.007779
2022-01-21 19:37:19,293 iteration 3963 : loss : 0.047496, loss_ce: 0.027729
2022-01-21 19:37:20,713 iteration 3964 : loss : 0.023755, loss_ce: 0.010405
2022-01-21 19:37:22,000 iteration 3965 : loss : 0.020766, loss_ce: 0.005952
2022-01-21 19:37:23,375 iteration 3966 : loss : 0.036326, loss_ce: 0.011783
2022-01-21 19:37:24,718 iteration 3967 : loss : 0.023592, loss_ce: 0.009193
2022-01-21 19:37:25,952 iteration 3968 : loss : 0.021312, loss_ce: 0.007784
2022-01-21 19:37:27,295 iteration 3969 : loss : 0.022937, loss_ce: 0.006979
2022-01-21 19:37:28,612 iteration 3970 : loss : 0.026123, loss_ce: 0.007898
2022-01-21 19:37:29,836 iteration 3971 : loss : 0.015881, loss_ce: 0.006391
2022-01-21 19:37:31,185 iteration 3972 : loss : 0.026164, loss_ce: 0.007979
2022-01-21 19:37:32,461 iteration 3973 : loss : 0.031934, loss_ce: 0.017587
2022-01-21 19:37:33,699 iteration 3974 : loss : 0.021347, loss_ce: 0.005894
2022-01-21 19:37:35,037 iteration 3975 : loss : 0.019103, loss_ce: 0.007290
2022-01-21 19:37:36,429 iteration 3976 : loss : 0.028054, loss_ce: 0.011338
2022-01-21 19:37:37,814 iteration 3977 : loss : 0.021099, loss_ce: 0.010041
2022-01-21 19:37:39,229 iteration 3978 : loss : 0.040335, loss_ce: 0.012539
 58%|███████████████▊           | 234/400 [1:35:54<1:05:05, 23.53s/it]2022-01-21 19:37:40,599 iteration 3979 : loss : 0.019710, loss_ce: 0.007211
2022-01-21 19:37:41,965 iteration 3980 : loss : 0.021906, loss_ce: 0.007152
2022-01-21 19:37:43,276 iteration 3981 : loss : 0.024706, loss_ce: 0.012057
2022-01-21 19:37:44,501 iteration 3982 : loss : 0.017001, loss_ce: 0.005776
2022-01-21 19:37:45,748 iteration 3983 : loss : 0.018169, loss_ce: 0.008376
2022-01-21 19:37:47,037 iteration 3984 : loss : 0.015814, loss_ce: 0.006160
2022-01-21 19:37:48,382 iteration 3985 : loss : 0.039107, loss_ce: 0.018806
2022-01-21 19:37:49,797 iteration 3986 : loss : 0.023390, loss_ce: 0.010793
2022-01-21 19:37:51,156 iteration 3987 : loss : 0.028316, loss_ce: 0.011018
2022-01-21 19:37:52,483 iteration 3988 : loss : 0.019451, loss_ce: 0.009802
2022-01-21 19:37:53,785 iteration 3989 : loss : 0.018261, loss_ce: 0.003788
2022-01-21 19:37:55,087 iteration 3990 : loss : 0.031751, loss_ce: 0.009329
2022-01-21 19:37:56,472 iteration 3991 : loss : 0.023001, loss_ce: 0.005210
2022-01-21 19:37:57,815 iteration 3992 : loss : 0.024748, loss_ce: 0.008137
2022-01-21 19:37:59,191 iteration 3993 : loss : 0.043291, loss_ce: 0.015417
2022-01-21 19:38:00,498 iteration 3994 : loss : 0.019088, loss_ce: 0.008387
2022-01-21 19:38:00,498 Training Data Eval:
2022-01-21 19:38:07,025   Average segmentation loss on training set: 0.0141
2022-01-21 19:38:07,026 Validation Data Eval:
2022-01-21 19:38:09,265   Average segmentation loss on validation set: 0.0602
2022-01-21 19:38:13,401 Found new lowest validation loss at iteration 3994! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 19:38:14,579 iteration 3995 : loss : 0.017577, loss_ce: 0.007033
 59%|███████████████▊           | 235/400 [1:36:30<1:14:27, 27.07s/it]2022-01-21 19:38:15,899 iteration 3996 : loss : 0.019473, loss_ce: 0.006078
2022-01-21 19:38:17,061 iteration 3997 : loss : 0.020567, loss_ce: 0.006319
2022-01-21 19:38:18,297 iteration 3998 : loss : 0.037149, loss_ce: 0.016356
2022-01-21 19:38:19,536 iteration 3999 : loss : 0.027619, loss_ce: 0.008005
2022-01-21 19:38:20,890 iteration 4000 : loss : 0.019648, loss_ce: 0.008939
2022-01-21 19:38:22,149 iteration 4001 : loss : 0.017884, loss_ce: 0.006452
2022-01-21 19:38:23,477 iteration 4002 : loss : 0.020847, loss_ce: 0.008220
2022-01-21 19:38:24,811 iteration 4003 : loss : 0.021763, loss_ce: 0.009360
2022-01-21 19:38:26,175 iteration 4004 : loss : 0.022839, loss_ce: 0.005837
2022-01-21 19:38:27,504 iteration 4005 : loss : 0.020432, loss_ce: 0.009598
2022-01-21 19:38:28,778 iteration 4006 : loss : 0.018399, loss_ce: 0.007294
2022-01-21 19:38:30,151 iteration 4007 : loss : 0.023990, loss_ce: 0.007112
2022-01-21 19:38:31,440 iteration 4008 : loss : 0.018389, loss_ce: 0.007095
2022-01-21 19:38:32,759 iteration 4009 : loss : 0.021330, loss_ce: 0.009104
2022-01-21 19:38:34,143 iteration 4010 : loss : 0.025907, loss_ce: 0.011274
2022-01-21 19:38:35,419 iteration 4011 : loss : 0.017044, loss_ce: 0.004883
2022-01-21 19:38:36,821 iteration 4012 : loss : 0.031612, loss_ce: 0.016402
 59%|███████████████▉           | 236/400 [1:36:52<1:10:02, 25.62s/it]2022-01-21 19:38:38,266 iteration 4013 : loss : 0.030392, loss_ce: 0.008981
2022-01-21 19:38:39,543 iteration 4014 : loss : 0.017527, loss_ce: 0.005414
2022-01-21 19:38:40,925 iteration 4015 : loss : 0.026092, loss_ce: 0.010459
2022-01-21 19:38:42,295 iteration 4016 : loss : 0.017224, loss_ce: 0.005882
2022-01-21 19:38:43,681 iteration 4017 : loss : 0.026961, loss_ce: 0.007687
2022-01-21 19:38:44,971 iteration 4018 : loss : 0.021084, loss_ce: 0.008442
2022-01-21 19:38:46,292 iteration 4019 : loss : 0.018730, loss_ce: 0.009442
2022-01-21 19:38:47,568 iteration 4020 : loss : 0.022920, loss_ce: 0.014623
2022-01-21 19:38:48,865 iteration 4021 : loss : 0.017566, loss_ce: 0.007930
2022-01-21 19:38:50,216 iteration 4022 : loss : 0.022398, loss_ce: 0.010373
2022-01-21 19:38:51,545 iteration 4023 : loss : 0.016967, loss_ce: 0.006162
2022-01-21 19:38:52,808 iteration 4024 : loss : 0.016851, loss_ce: 0.006000
2022-01-21 19:38:54,092 iteration 4025 : loss : 0.021699, loss_ce: 0.007862
2022-01-21 19:38:55,454 iteration 4026 : loss : 0.019352, loss_ce: 0.008167
2022-01-21 19:38:56,803 iteration 4027 : loss : 0.022780, loss_ce: 0.008258
2022-01-21 19:38:58,181 iteration 4028 : loss : 0.025530, loss_ce: 0.008799
2022-01-21 19:38:59,467 iteration 4029 : loss : 0.021255, loss_ce: 0.008938
 59%|███████████████▉           | 237/400 [1:37:15<1:07:11, 24.73s/it]2022-01-21 19:39:00,900 iteration 4030 : loss : 0.025544, loss_ce: 0.011263
2022-01-21 19:39:02,259 iteration 4031 : loss : 0.049216, loss_ce: 0.013019
2022-01-21 19:39:03,579 iteration 4032 : loss : 0.028533, loss_ce: 0.012185
2022-01-21 19:39:04,905 iteration 4033 : loss : 0.049667, loss_ce: 0.019348
2022-01-21 19:39:06,167 iteration 4034 : loss : 0.023002, loss_ce: 0.008297
2022-01-21 19:39:07,469 iteration 4035 : loss : 0.017238, loss_ce: 0.005341
2022-01-21 19:39:08,830 iteration 4036 : loss : 0.026448, loss_ce: 0.008975
2022-01-21 19:39:10,106 iteration 4037 : loss : 0.015203, loss_ce: 0.007029
2022-01-21 19:39:11,497 iteration 4038 : loss : 0.029611, loss_ce: 0.010204
2022-01-21 19:39:12,911 iteration 4039 : loss : 0.036771, loss_ce: 0.014274
2022-01-21 19:39:14,324 iteration 4040 : loss : 0.027952, loss_ce: 0.011244
2022-01-21 19:39:15,717 iteration 4041 : loss : 0.022515, loss_ce: 0.007107
2022-01-21 19:39:17,020 iteration 4042 : loss : 0.019780, loss_ce: 0.007227
2022-01-21 19:39:18,360 iteration 4043 : loss : 0.176115, loss_ce: 0.005924
2022-01-21 19:39:19,655 iteration 4044 : loss : 0.020845, loss_ce: 0.008033
2022-01-21 19:39:20,973 iteration 4045 : loss : 0.018986, loss_ce: 0.009355
2022-01-21 19:39:22,353 iteration 4046 : loss : 0.044869, loss_ce: 0.029956
 60%|████████████████           | 238/400 [1:37:37<1:05:16, 24.18s/it]2022-01-21 19:39:23,807 iteration 4047 : loss : 0.028864, loss_ce: 0.013307
2022-01-21 19:39:25,180 iteration 4048 : loss : 0.035809, loss_ce: 0.013449
2022-01-21 19:39:26,477 iteration 4049 : loss : 0.018057, loss_ce: 0.006879
2022-01-21 19:39:27,843 iteration 4050 : loss : 0.020044, loss_ce: 0.008372
2022-01-21 19:39:29,279 iteration 4051 : loss : 0.075332, loss_ce: 0.022403
2022-01-21 19:39:30,549 iteration 4052 : loss : 0.020508, loss_ce: 0.007632
2022-01-21 19:39:31,791 iteration 4053 : loss : 0.019485, loss_ce: 0.006318
2022-01-21 19:39:33,067 iteration 4054 : loss : 0.024554, loss_ce: 0.006948
2022-01-21 19:39:34,377 iteration 4055 : loss : 0.020467, loss_ce: 0.008873
2022-01-21 19:39:35,719 iteration 4056 : loss : 0.019715, loss_ce: 0.008944
2022-01-21 19:39:36,999 iteration 4057 : loss : 0.019678, loss_ce: 0.006048
2022-01-21 19:39:38,315 iteration 4058 : loss : 0.015848, loss_ce: 0.005721
2022-01-21 19:39:39,743 iteration 4059 : loss : 0.035638, loss_ce: 0.015545
2022-01-21 19:39:41,083 iteration 4060 : loss : 0.028873, loss_ce: 0.013180
2022-01-21 19:39:42,416 iteration 4061 : loss : 0.022049, loss_ce: 0.009037
2022-01-21 19:39:43,778 iteration 4062 : loss : 0.026954, loss_ce: 0.010017
2022-01-21 19:39:45,127 iteration 4063 : loss : 0.045194, loss_ce: 0.012343
 60%|████████████████▏          | 239/400 [1:38:00<1:03:44, 23.75s/it]2022-01-21 19:39:46,471 iteration 4064 : loss : 0.023583, loss_ce: 0.005685
2022-01-21 19:39:47,770 iteration 4065 : loss : 0.018825, loss_ce: 0.006602
2022-01-21 19:39:49,159 iteration 4066 : loss : 0.033392, loss_ce: 0.012638
2022-01-21 19:39:50,458 iteration 4067 : loss : 0.017799, loss_ce: 0.007217
2022-01-21 19:39:51,783 iteration 4068 : loss : 0.025084, loss_ce: 0.009321
2022-01-21 19:39:53,138 iteration 4069 : loss : 0.017699, loss_ce: 0.006957
2022-01-21 19:39:54,489 iteration 4070 : loss : 0.025455, loss_ce: 0.009541
2022-01-21 19:39:55,879 iteration 4071 : loss : 0.032368, loss_ce: 0.010420
2022-01-21 19:39:57,202 iteration 4072 : loss : 0.017922, loss_ce: 0.005655
2022-01-21 19:39:58,497 iteration 4073 : loss : 0.023712, loss_ce: 0.007871
2022-01-21 19:39:59,821 iteration 4074 : loss : 0.018621, loss_ce: 0.008039
2022-01-21 19:40:01,192 iteration 4075 : loss : 0.021372, loss_ce: 0.007956
2022-01-21 19:40:02,474 iteration 4076 : loss : 0.022005, loss_ce: 0.008896
2022-01-21 19:40:03,790 iteration 4077 : loss : 0.017771, loss_ce: 0.006631
2022-01-21 19:40:05,173 iteration 4078 : loss : 0.023083, loss_ce: 0.008966
2022-01-21 19:40:06,535 iteration 4079 : loss : 0.021695, loss_ce: 0.009098
2022-01-21 19:40:06,535 Training Data Eval:
2022-01-21 19:40:13,058   Average segmentation loss on training set: 0.0151
2022-01-21 19:40:13,059 Validation Data Eval:
2022-01-21 19:40:15,293   Average segmentation loss on validation set: 0.0958
2022-01-21 19:40:16,671 iteration 4080 : loss : 0.021593, loss_ce: 0.009387
 60%|████████████████▏          | 240/400 [1:38:32<1:09:35, 26.09s/it]2022-01-21 19:40:18,067 iteration 4081 : loss : 0.034538, loss_ce: 0.013176
2022-01-21 19:40:19,407 iteration 4082 : loss : 0.016839, loss_ce: 0.006255
2022-01-21 19:40:20,689 iteration 4083 : loss : 0.017946, loss_ce: 0.007148
2022-01-21 19:40:22,015 iteration 4084 : loss : 0.017324, loss_ce: 0.004944
2022-01-21 19:40:23,294 iteration 4085 : loss : 0.034513, loss_ce: 0.010420
2022-01-21 19:40:24,741 iteration 4086 : loss : 0.027313, loss_ce: 0.009586
2022-01-21 19:40:26,090 iteration 4087 : loss : 0.022277, loss_ce: 0.005374
2022-01-21 19:40:27,354 iteration 4088 : loss : 0.022351, loss_ce: 0.010832
2022-01-21 19:40:28,678 iteration 4089 : loss : 0.029788, loss_ce: 0.009897
2022-01-21 19:40:29,915 iteration 4090 : loss : 0.019423, loss_ce: 0.005898
2022-01-21 19:40:31,228 iteration 4091 : loss : 0.024813, loss_ce: 0.008972
2022-01-21 19:40:32,567 iteration 4092 : loss : 0.018302, loss_ce: 0.006836
2022-01-21 19:40:33,908 iteration 4093 : loss : 0.038256, loss_ce: 0.015071
2022-01-21 19:40:35,206 iteration 4094 : loss : 0.021707, loss_ce: 0.009346
2022-01-21 19:40:36,547 iteration 4095 : loss : 0.022274, loss_ce: 0.009852
2022-01-21 19:40:37,840 iteration 4096 : loss : 0.019341, loss_ce: 0.009953
2022-01-21 19:40:39,149 iteration 4097 : loss : 0.018068, loss_ce: 0.005981
 60%|████████████████▎          | 241/400 [1:38:54<1:06:16, 25.01s/it]2022-01-21 19:40:40,492 iteration 4098 : loss : 0.026068, loss_ce: 0.011464
2022-01-21 19:40:41,783 iteration 4099 : loss : 0.031790, loss_ce: 0.008506
2022-01-21 19:40:43,115 iteration 4100 : loss : 0.021248, loss_ce: 0.007495
2022-01-21 19:40:44,487 iteration 4101 : loss : 0.023710, loss_ce: 0.007985
2022-01-21 19:40:45,854 iteration 4102 : loss : 0.026249, loss_ce: 0.011474
2022-01-21 19:40:47,203 iteration 4103 : loss : 0.025524, loss_ce: 0.011501
2022-01-21 19:40:48,539 iteration 4104 : loss : 0.020391, loss_ce: 0.007901
2022-01-21 19:40:49,884 iteration 4105 : loss : 0.020405, loss_ce: 0.009432
2022-01-21 19:40:51,203 iteration 4106 : loss : 0.023437, loss_ce: 0.009357
2022-01-21 19:40:52,513 iteration 4107 : loss : 0.018359, loss_ce: 0.006375
2022-01-21 19:40:53,839 iteration 4108 : loss : 0.021077, loss_ce: 0.009493
2022-01-21 19:40:55,111 iteration 4109 : loss : 0.015992, loss_ce: 0.005618
2022-01-21 19:40:56,474 iteration 4110 : loss : 0.023191, loss_ce: 0.010125
2022-01-21 19:40:57,951 iteration 4111 : loss : 0.023185, loss_ce: 0.011357
2022-01-21 19:40:59,248 iteration 4112 : loss : 0.019093, loss_ce: 0.006373
2022-01-21 19:41:00,613 iteration 4113 : loss : 0.036573, loss_ce: 0.010213
2022-01-21 19:41:01,938 iteration 4114 : loss : 0.021696, loss_ce: 0.010036
 60%|████████████████▎          | 242/400 [1:39:17<1:04:05, 24.34s/it]2022-01-21 19:41:03,263 iteration 4115 : loss : 0.021779, loss_ce: 0.010697
2022-01-21 19:41:04,644 iteration 4116 : loss : 0.018246, loss_ce: 0.005595
2022-01-21 19:41:05,915 iteration 4117 : loss : 0.015301, loss_ce: 0.005544
2022-01-21 19:41:07,303 iteration 4118 : loss : 0.031529, loss_ce: 0.011987
2022-01-21 19:41:08,747 iteration 4119 : loss : 0.032801, loss_ce: 0.008582
2022-01-21 19:41:10,102 iteration 4120 : loss : 0.025541, loss_ce: 0.006784
2022-01-21 19:41:11,394 iteration 4121 : loss : 0.020194, loss_ce: 0.007260
2022-01-21 19:41:12,715 iteration 4122 : loss : 0.031994, loss_ce: 0.008785
2022-01-21 19:41:13,987 iteration 4123 : loss : 0.012375, loss_ce: 0.005089
2022-01-21 19:41:15,354 iteration 4124 : loss : 0.019798, loss_ce: 0.009174
2022-01-21 19:41:16,706 iteration 4125 : loss : 0.031871, loss_ce: 0.015128
2022-01-21 19:41:18,049 iteration 4126 : loss : 0.023139, loss_ce: 0.008793
2022-01-21 19:41:19,334 iteration 4127 : loss : 0.015000, loss_ce: 0.007334
2022-01-21 19:41:20,767 iteration 4128 : loss : 0.055821, loss_ce: 0.015716
2022-01-21 19:41:22,035 iteration 4129 : loss : 0.023328, loss_ce: 0.005396
2022-01-21 19:41:23,294 iteration 4130 : loss : 0.020488, loss_ce: 0.006189
2022-01-21 19:41:24,603 iteration 4131 : loss : 0.017942, loss_ce: 0.008673
 61%|████████████████▍          | 243/400 [1:39:40<1:02:22, 23.84s/it]2022-01-21 19:41:26,017 iteration 4132 : loss : 0.023398, loss_ce: 0.007452
2022-01-21 19:41:27,364 iteration 4133 : loss : 0.019226, loss_ce: 0.005628
2022-01-21 19:41:28,724 iteration 4134 : loss : 0.024143, loss_ce: 0.010614
2022-01-21 19:41:29,975 iteration 4135 : loss : 0.019260, loss_ce: 0.007918
2022-01-21 19:41:31,294 iteration 4136 : loss : 0.020415, loss_ce: 0.009193
2022-01-21 19:41:32,549 iteration 4137 : loss : 0.019221, loss_ce: 0.006360
2022-01-21 19:41:33,898 iteration 4138 : loss : 0.021694, loss_ce: 0.008859
2022-01-21 19:41:35,252 iteration 4139 : loss : 0.018703, loss_ce: 0.007945
2022-01-21 19:41:36,593 iteration 4140 : loss : 0.016400, loss_ce: 0.007337
2022-01-21 19:41:37,940 iteration 4141 : loss : 0.019180, loss_ce: 0.006230
2022-01-21 19:41:39,343 iteration 4142 : loss : 0.038694, loss_ce: 0.012463
2022-01-21 19:41:40,581 iteration 4143 : loss : 0.019819, loss_ce: 0.006038
2022-01-21 19:41:41,841 iteration 4144 : loss : 0.017909, loss_ce: 0.003650
2022-01-21 19:41:43,215 iteration 4145 : loss : 0.022406, loss_ce: 0.008982
2022-01-21 19:41:44,512 iteration 4146 : loss : 0.016620, loss_ce: 0.007017
2022-01-21 19:41:45,855 iteration 4147 : loss : 0.020205, loss_ce: 0.006967
2022-01-21 19:41:47,152 iteration 4148 : loss : 0.023645, loss_ce: 0.007831
 61%|████████████████▍          | 244/400 [1:40:02<1:00:58, 23.45s/it]2022-01-21 19:41:48,436 iteration 4149 : loss : 0.018280, loss_ce: 0.005640
2022-01-21 19:41:49,773 iteration 4150 : loss : 0.019402, loss_ce: 0.005392
2022-01-21 19:41:51,143 iteration 4151 : loss : 0.026278, loss_ce: 0.009026
2022-01-21 19:41:52,479 iteration 4152 : loss : 0.020122, loss_ce: 0.007623
2022-01-21 19:41:53,735 iteration 4153 : loss : 0.015592, loss_ce: 0.005850
2022-01-21 19:41:55,072 iteration 4154 : loss : 0.019501, loss_ce: 0.006221
2022-01-21 19:41:56,393 iteration 4155 : loss : 0.029820, loss_ce: 0.008703
2022-01-21 19:41:57,657 iteration 4156 : loss : 0.017317, loss_ce: 0.006344
2022-01-21 19:41:59,034 iteration 4157 : loss : 0.028078, loss_ce: 0.015526
2022-01-21 19:42:00,325 iteration 4158 : loss : 0.023361, loss_ce: 0.008406
2022-01-21 19:42:01,629 iteration 4159 : loss : 0.015101, loss_ce: 0.005977
2022-01-21 19:42:03,062 iteration 4160 : loss : 0.036404, loss_ce: 0.012432
2022-01-21 19:42:04,468 iteration 4161 : loss : 0.031212, loss_ce: 0.009556
2022-01-21 19:42:05,870 iteration 4162 : loss : 0.025945, loss_ce: 0.009495
2022-01-21 19:42:07,260 iteration 4163 : loss : 0.034267, loss_ce: 0.014601
2022-01-21 19:42:08,595 iteration 4164 : loss : 0.027074, loss_ce: 0.011642
2022-01-21 19:42:08,595 Training Data Eval:
2022-01-21 19:42:15,133   Average segmentation loss on training set: 0.0145
2022-01-21 19:42:15,134 Validation Data Eval:
2022-01-21 19:42:17,374   Average segmentation loss on validation set: 0.0723
2022-01-21 19:42:18,729 iteration 4165 : loss : 0.022457, loss_ce: 0.006962
 61%|████████████████▌          | 245/400 [1:40:34<1:06:52, 25.89s/it]2022-01-21 19:42:20,086 iteration 4166 : loss : 0.016002, loss_ce: 0.006397
2022-01-21 19:42:21,339 iteration 4167 : loss : 0.017579, loss_ce: 0.005576
2022-01-21 19:42:22,617 iteration 4168 : loss : 0.014910, loss_ce: 0.005740
2022-01-21 19:42:23,896 iteration 4169 : loss : 0.017484, loss_ce: 0.008150
2022-01-21 19:42:25,329 iteration 4170 : loss : 0.031072, loss_ce: 0.014151
2022-01-21 19:42:26,582 iteration 4171 : loss : 0.016937, loss_ce: 0.004699
2022-01-21 19:42:27,897 iteration 4172 : loss : 0.025878, loss_ce: 0.011885
2022-01-21 19:42:29,249 iteration 4173 : loss : 0.022177, loss_ce: 0.006447
2022-01-21 19:42:30,551 iteration 4174 : loss : 0.019399, loss_ce: 0.005492
2022-01-21 19:42:31,826 iteration 4175 : loss : 0.017155, loss_ce: 0.006557
2022-01-21 19:42:33,131 iteration 4176 : loss : 0.020206, loss_ce: 0.008330
2022-01-21 19:42:34,494 iteration 4177 : loss : 0.020819, loss_ce: 0.007280
2022-01-21 19:42:35,772 iteration 4178 : loss : 0.022025, loss_ce: 0.010144
2022-01-21 19:42:37,076 iteration 4179 : loss : 0.019904, loss_ce: 0.009381
2022-01-21 19:42:38,369 iteration 4180 : loss : 0.016665, loss_ce: 0.005191
2022-01-21 19:42:39,681 iteration 4181 : loss : 0.025795, loss_ce: 0.011476
2022-01-21 19:42:40,998 iteration 4182 : loss : 0.019084, loss_ce: 0.005302
 62%|████████████████▌          | 246/400 [1:40:56<1:03:39, 24.80s/it]2022-01-21 19:42:42,374 iteration 4183 : loss : 0.020693, loss_ce: 0.006386
2022-01-21 19:42:43,734 iteration 4184 : loss : 0.016208, loss_ce: 0.006678
2022-01-21 19:42:45,059 iteration 4185 : loss : 0.019811, loss_ce: 0.008324
2022-01-21 19:42:46,365 iteration 4186 : loss : 0.019728, loss_ce: 0.005519
2022-01-21 19:42:47,732 iteration 4187 : loss : 0.024279, loss_ce: 0.008329
2022-01-21 19:42:49,016 iteration 4188 : loss : 0.025312, loss_ce: 0.008151
2022-01-21 19:42:50,442 iteration 4189 : loss : 0.020875, loss_ce: 0.008644
2022-01-21 19:42:51,827 iteration 4190 : loss : 0.023781, loss_ce: 0.010046
2022-01-21 19:42:53,222 iteration 4191 : loss : 0.031318, loss_ce: 0.013315
2022-01-21 19:42:54,458 iteration 4192 : loss : 0.013177, loss_ce: 0.004041
2022-01-21 19:42:55,800 iteration 4193 : loss : 0.020413, loss_ce: 0.009919
2022-01-21 19:42:57,166 iteration 4194 : loss : 0.017681, loss_ce: 0.006042
2022-01-21 19:42:58,475 iteration 4195 : loss : 0.017715, loss_ce: 0.004994
2022-01-21 19:42:59,838 iteration 4196 : loss : 0.016791, loss_ce: 0.007503
2022-01-21 19:43:01,148 iteration 4197 : loss : 0.016899, loss_ce: 0.004627
2022-01-21 19:43:02,463 iteration 4198 : loss : 0.017443, loss_ce: 0.006449
2022-01-21 19:43:03,728 iteration 4199 : loss : 0.015722, loss_ce: 0.006046
 62%|████████████████▋          | 247/400 [1:41:19<1:01:39, 24.18s/it]2022-01-21 19:43:05,091 iteration 4200 : loss : 0.018063, loss_ce: 0.006526
2022-01-21 19:43:06,445 iteration 4201 : loss : 0.017312, loss_ce: 0.007110
2022-01-21 19:43:07,795 iteration 4202 : loss : 0.018741, loss_ce: 0.008094
2022-01-21 19:43:09,216 iteration 4203 : loss : 0.019789, loss_ce: 0.009246
2022-01-21 19:43:10,527 iteration 4204 : loss : 0.016932, loss_ce: 0.006843
2022-01-21 19:43:11,846 iteration 4205 : loss : 0.015136, loss_ce: 0.005927
2022-01-21 19:43:13,290 iteration 4206 : loss : 0.023228, loss_ce: 0.006998
2022-01-21 19:43:14,656 iteration 4207 : loss : 0.018373, loss_ce: 0.008241
2022-01-21 19:43:15,900 iteration 4208 : loss : 0.013314, loss_ce: 0.004913
2022-01-21 19:43:17,195 iteration 4209 : loss : 0.018916, loss_ce: 0.008297
2022-01-21 19:43:18,493 iteration 4210 : loss : 0.017038, loss_ce: 0.006841
2022-01-21 19:43:19,835 iteration 4211 : loss : 0.018707, loss_ce: 0.007679
2022-01-21 19:43:21,214 iteration 4212 : loss : 0.018113, loss_ce: 0.006945
2022-01-21 19:43:22,510 iteration 4213 : loss : 0.023239, loss_ce: 0.007887
2022-01-21 19:43:23,873 iteration 4214 : loss : 0.024753, loss_ce: 0.009156
2022-01-21 19:43:25,192 iteration 4215 : loss : 0.025299, loss_ce: 0.007446
2022-01-21 19:43:26,506 iteration 4216 : loss : 0.015741, loss_ce: 0.005426
 62%|████████████████▋          | 248/400 [1:41:42<1:00:11, 23.76s/it]2022-01-21 19:43:27,915 iteration 4217 : loss : 0.024094, loss_ce: 0.007675
2022-01-21 19:43:29,222 iteration 4218 : loss : 0.018559, loss_ce: 0.006314
2022-01-21 19:43:30,515 iteration 4219 : loss : 0.020491, loss_ce: 0.008056
2022-01-21 19:43:31,750 iteration 4220 : loss : 0.020871, loss_ce: 0.004975
2022-01-21 19:43:33,165 iteration 4221 : loss : 0.023195, loss_ce: 0.010142
2022-01-21 19:43:34,585 iteration 4222 : loss : 0.021786, loss_ce: 0.006065
2022-01-21 19:43:35,892 iteration 4223 : loss : 0.019745, loss_ce: 0.006404
2022-01-21 19:43:37,276 iteration 4224 : loss : 0.038182, loss_ce: 0.011560
2022-01-21 19:43:38,627 iteration 4225 : loss : 0.020334, loss_ce: 0.005744
2022-01-21 19:43:40,004 iteration 4226 : loss : 0.028977, loss_ce: 0.015503
2022-01-21 19:43:41,362 iteration 4227 : loss : 0.016095, loss_ce: 0.006495
2022-01-21 19:43:42,644 iteration 4228 : loss : 0.019603, loss_ce: 0.008359
2022-01-21 19:43:43,964 iteration 4229 : loss : 0.020989, loss_ce: 0.007150
2022-01-21 19:43:45,271 iteration 4230 : loss : 0.022093, loss_ce: 0.010012
2022-01-21 19:43:46,639 iteration 4231 : loss : 0.019020, loss_ce: 0.007515
2022-01-21 19:43:48,009 iteration 4232 : loss : 0.022888, loss_ce: 0.007602
2022-01-21 19:43:49,331 iteration 4233 : loss : 0.017420, loss_ce: 0.008597
 62%|██████████████████           | 249/400 [1:42:04<59:06, 23.49s/it]2022-01-21 19:43:50,640 iteration 4234 : loss : 0.021105, loss_ce: 0.004504
2022-01-21 19:43:51,900 iteration 4235 : loss : 0.012272, loss_ce: 0.004551
2022-01-21 19:43:53,249 iteration 4236 : loss : 0.017710, loss_ce: 0.006905
2022-01-21 19:43:54,529 iteration 4237 : loss : 0.016797, loss_ce: 0.006586
2022-01-21 19:43:55,848 iteration 4238 : loss : 0.045926, loss_ce: 0.024551
2022-01-21 19:43:57,301 iteration 4239 : loss : 0.037644, loss_ce: 0.015108
2022-01-21 19:43:58,645 iteration 4240 : loss : 0.018930, loss_ce: 0.005652
2022-01-21 19:43:59,889 iteration 4241 : loss : 0.015113, loss_ce: 0.006886
2022-01-21 19:44:01,223 iteration 4242 : loss : 0.021909, loss_ce: 0.006606
2022-01-21 19:44:02,524 iteration 4243 : loss : 0.022650, loss_ce: 0.008435
2022-01-21 19:44:03,773 iteration 4244 : loss : 0.013600, loss_ce: 0.006570
2022-01-21 19:44:05,145 iteration 4245 : loss : 0.020158, loss_ce: 0.008050
2022-01-21 19:44:06,554 iteration 4246 : loss : 0.021428, loss_ce: 0.005751
2022-01-21 19:44:07,912 iteration 4247 : loss : 0.018204, loss_ce: 0.007530
2022-01-21 19:44:09,183 iteration 4248 : loss : 0.021370, loss_ce: 0.008956
2022-01-21 19:44:10,568 iteration 4249 : loss : 0.023004, loss_ce: 0.007377
2022-01-21 19:44:10,568 Training Data Eval:
2022-01-21 19:44:17,102   Average segmentation loss on training set: 0.0122
2022-01-21 19:44:17,102 Validation Data Eval:
2022-01-21 19:44:19,338   Average segmentation loss on validation set: 0.0688
2022-01-21 19:44:20,652 iteration 4250 : loss : 0.028362, loss_ce: 0.009630
 62%|████████████████▉          | 250/400 [1:42:36<1:04:34, 25.83s/it]2022-01-21 19:44:22,080 iteration 4251 : loss : 0.016109, loss_ce: 0.004390
2022-01-21 19:44:23,453 iteration 4252 : loss : 0.017093, loss_ce: 0.007711
2022-01-21 19:44:24,785 iteration 4253 : loss : 0.022648, loss_ce: 0.007940
2022-01-21 19:44:26,153 iteration 4254 : loss : 0.017632, loss_ce: 0.006994
2022-01-21 19:44:27,533 iteration 4255 : loss : 0.028079, loss_ce: 0.010177
2022-01-21 19:44:28,769 iteration 4256 : loss : 0.015472, loss_ce: 0.006749
2022-01-21 19:44:30,091 iteration 4257 : loss : 0.022246, loss_ce: 0.008861
2022-01-21 19:44:31,345 iteration 4258 : loss : 0.022641, loss_ce: 0.007217
2022-01-21 19:44:32,691 iteration 4259 : loss : 0.021565, loss_ce: 0.008769
2022-01-21 19:44:34,043 iteration 4260 : loss : 0.025907, loss_ce: 0.007077
2022-01-21 19:44:35,397 iteration 4261 : loss : 0.019808, loss_ce: 0.008087
2022-01-21 19:44:36,683 iteration 4262 : loss : 0.016784, loss_ce: 0.006968
2022-01-21 19:44:38,029 iteration 4263 : loss : 0.020313, loss_ce: 0.009008
2022-01-21 19:44:39,409 iteration 4264 : loss : 0.021558, loss_ce: 0.008294
2022-01-21 19:44:40,732 iteration 4265 : loss : 0.021227, loss_ce: 0.005589
2022-01-21 19:44:42,091 iteration 4266 : loss : 0.022192, loss_ce: 0.006982
2022-01-21 19:44:43,467 iteration 4267 : loss : 0.019182, loss_ce: 0.006964
 63%|████████████████▉          | 251/400 [1:42:59<1:01:53, 24.92s/it]2022-01-21 19:44:44,839 iteration 4268 : loss : 0.017585, loss_ce: 0.003820
2022-01-21 19:44:46,152 iteration 4269 : loss : 0.027977, loss_ce: 0.011860
2022-01-21 19:44:47,444 iteration 4270 : loss : 0.020047, loss_ce: 0.010579
2022-01-21 19:44:48,695 iteration 4271 : loss : 0.015671, loss_ce: 0.005832
2022-01-21 19:44:50,011 iteration 4272 : loss : 0.020145, loss_ce: 0.008918
2022-01-21 19:44:51,267 iteration 4273 : loss : 0.016367, loss_ce: 0.006607
2022-01-21 19:44:52,674 iteration 4274 : loss : 0.017084, loss_ce: 0.007489
2022-01-21 19:44:53,976 iteration 4275 : loss : 0.016873, loss_ce: 0.005443
2022-01-21 19:44:55,349 iteration 4276 : loss : 0.019155, loss_ce: 0.004803
2022-01-21 19:44:56,726 iteration 4277 : loss : 0.017668, loss_ce: 0.005426
2022-01-21 19:44:58,098 iteration 4278 : loss : 0.025412, loss_ce: 0.008000
2022-01-21 19:44:59,408 iteration 4279 : loss : 0.020149, loss_ce: 0.010544
2022-01-21 19:45:00,748 iteration 4280 : loss : 0.019808, loss_ce: 0.006766
2022-01-21 19:45:02,088 iteration 4281 : loss : 0.024153, loss_ce: 0.007168
2022-01-21 19:45:03,353 iteration 4282 : loss : 0.018208, loss_ce: 0.007225
2022-01-21 19:45:04,669 iteration 4283 : loss : 0.023124, loss_ce: 0.007526
2022-01-21 19:45:05,961 iteration 4284 : loss : 0.015358, loss_ce: 0.005765
 63%|██████████████████▎          | 252/400 [1:43:21<59:40, 24.19s/it]2022-01-21 19:45:07,263 iteration 4285 : loss : 0.019156, loss_ce: 0.005620
2022-01-21 19:45:08,634 iteration 4286 : loss : 0.026138, loss_ce: 0.010292
2022-01-21 19:45:09,917 iteration 4287 : loss : 0.027978, loss_ce: 0.013384
2022-01-21 19:45:11,197 iteration 4288 : loss : 0.019732, loss_ce: 0.008828
2022-01-21 19:45:12,528 iteration 4289 : loss : 0.019422, loss_ce: 0.007448
2022-01-21 19:45:13,838 iteration 4290 : loss : 0.017704, loss_ce: 0.004478
2022-01-21 19:45:15,187 iteration 4291 : loss : 0.023124, loss_ce: 0.009546
2022-01-21 19:45:16,535 iteration 4292 : loss : 0.045513, loss_ce: 0.023831
2022-01-21 19:45:17,868 iteration 4293 : loss : 0.037199, loss_ce: 0.010478
2022-01-21 19:45:19,167 iteration 4294 : loss : 0.024723, loss_ce: 0.007577
2022-01-21 19:45:20,593 iteration 4295 : loss : 0.024383, loss_ce: 0.009088
2022-01-21 19:45:21,923 iteration 4296 : loss : 0.037670, loss_ce: 0.015594
2022-01-21 19:45:23,274 iteration 4297 : loss : 0.042379, loss_ce: 0.016011
2022-01-21 19:45:24,572 iteration 4298 : loss : 0.018455, loss_ce: 0.008985
2022-01-21 19:45:25,943 iteration 4299 : loss : 0.016923, loss_ce: 0.007052
2022-01-21 19:45:27,347 iteration 4300 : loss : 0.028888, loss_ce: 0.013305
2022-01-21 19:45:28,742 iteration 4301 : loss : 0.018334, loss_ce: 0.007329
 63%|██████████████████▎          | 253/400 [1:43:44<58:14, 23.77s/it]2022-01-21 19:45:30,157 iteration 4302 : loss : 0.026525, loss_ce: 0.011919
2022-01-21 19:45:31,550 iteration 4303 : loss : 0.038365, loss_ce: 0.006973
2022-01-21 19:45:32,845 iteration 4304 : loss : 0.018949, loss_ce: 0.007105
2022-01-21 19:45:34,147 iteration 4305 : loss : 0.019649, loss_ce: 0.008673
2022-01-21 19:45:35,452 iteration 4306 : loss : 0.015671, loss_ce: 0.004837
2022-01-21 19:45:36,718 iteration 4307 : loss : 0.017752, loss_ce: 0.008698
2022-01-21 19:45:38,073 iteration 4308 : loss : 0.021788, loss_ce: 0.007840
2022-01-21 19:45:39,460 iteration 4309 : loss : 0.024560, loss_ce: 0.008956
2022-01-21 19:45:40,796 iteration 4310 : loss : 0.015489, loss_ce: 0.005900
2022-01-21 19:45:42,082 iteration 4311 : loss : 0.021792, loss_ce: 0.008307
2022-01-21 19:45:43,356 iteration 4312 : loss : 0.021427, loss_ce: 0.007428
2022-01-21 19:45:44,642 iteration 4313 : loss : 0.016093, loss_ce: 0.008183
2022-01-21 19:45:45,935 iteration 4314 : loss : 0.017640, loss_ce: 0.006061
2022-01-21 19:45:47,292 iteration 4315 : loss : 0.022054, loss_ce: 0.007354
2022-01-21 19:45:48,579 iteration 4316 : loss : 0.021189, loss_ce: 0.007010
2022-01-21 19:45:49,961 iteration 4317 : loss : 0.026980, loss_ce: 0.009904
2022-01-21 19:45:51,234 iteration 4318 : loss : 0.022759, loss_ce: 0.009252
 64%|██████████████████▍          | 254/400 [1:44:06<56:54, 23.39s/it]2022-01-21 19:45:52,644 iteration 4319 : loss : 0.027613, loss_ce: 0.009418
2022-01-21 19:45:54,006 iteration 4320 : loss : 0.024403, loss_ce: 0.009797
2022-01-21 19:45:55,237 iteration 4321 : loss : 0.020950, loss_ce: 0.006421
2022-01-21 19:45:56,557 iteration 4322 : loss : 0.020241, loss_ce: 0.006714
2022-01-21 19:45:57,827 iteration 4323 : loss : 0.016577, loss_ce: 0.007680
2022-01-21 19:45:59,256 iteration 4324 : loss : 0.030832, loss_ce: 0.014227
2022-01-21 19:46:00,590 iteration 4325 : loss : 0.019565, loss_ce: 0.008237
2022-01-21 19:46:01,894 iteration 4326 : loss : 0.021677, loss_ce: 0.009680
2022-01-21 19:46:03,250 iteration 4327 : loss : 0.028228, loss_ce: 0.008920
2022-01-21 19:46:04,539 iteration 4328 : loss : 0.024241, loss_ce: 0.007938
2022-01-21 19:46:05,927 iteration 4329 : loss : 0.038961, loss_ce: 0.008431
2022-01-21 19:46:07,293 iteration 4330 : loss : 0.028191, loss_ce: 0.013364
2022-01-21 19:46:08,708 iteration 4331 : loss : 0.062288, loss_ce: 0.017340
2022-01-21 19:46:10,087 iteration 4332 : loss : 0.024872, loss_ce: 0.008144
2022-01-21 19:46:11,490 iteration 4333 : loss : 0.039891, loss_ce: 0.017361
2022-01-21 19:46:12,826 iteration 4334 : loss : 0.020897, loss_ce: 0.009916
2022-01-21 19:46:12,826 Training Data Eval:
2022-01-21 19:46:19,362   Average segmentation loss on training set: 0.0157
2022-01-21 19:46:19,362 Validation Data Eval:
2022-01-21 19:46:21,596   Average segmentation loss on validation set: 0.1062
2022-01-21 19:46:22,963 iteration 4335 : loss : 0.039038, loss_ce: 0.008933
 64%|█████████████████▏         | 255/400 [1:44:38<1:02:33, 25.89s/it]2022-01-21 19:46:24,219 iteration 4336 : loss : 0.013779, loss_ce: 0.006837
2022-01-21 19:46:25,619 iteration 4337 : loss : 0.022439, loss_ce: 0.009402
2022-01-21 19:46:26,944 iteration 4338 : loss : 0.018475, loss_ce: 0.005860
2022-01-21 19:46:28,222 iteration 4339 : loss : 0.026032, loss_ce: 0.013212
2022-01-21 19:46:29,582 iteration 4340 : loss : 0.043486, loss_ce: 0.023047
2022-01-21 19:46:30,855 iteration 4341 : loss : 0.017659, loss_ce: 0.005822
2022-01-21 19:46:32,223 iteration 4342 : loss : 0.027886, loss_ce: 0.007835
2022-01-21 19:46:33,586 iteration 4343 : loss : 0.022109, loss_ce: 0.006542
2022-01-21 19:46:34,944 iteration 4344 : loss : 0.021982, loss_ce: 0.011056
2022-01-21 19:46:36,367 iteration 4345 : loss : 0.029578, loss_ce: 0.012479
2022-01-21 19:46:37,630 iteration 4346 : loss : 0.020534, loss_ce: 0.006421
2022-01-21 19:46:38,968 iteration 4347 : loss : 0.018326, loss_ce: 0.008758
2022-01-21 19:46:40,245 iteration 4348 : loss : 0.017140, loss_ce: 0.008561
2022-01-21 19:46:41,480 iteration 4349 : loss : 0.018706, loss_ce: 0.005509
2022-01-21 19:46:42,714 iteration 4350 : loss : 0.022732, loss_ce: 0.008510
2022-01-21 19:46:44,054 iteration 4351 : loss : 0.022374, loss_ce: 0.006604
2022-01-21 19:46:45,380 iteration 4352 : loss : 0.021587, loss_ce: 0.009013
 64%|██████████████████▌          | 256/400 [1:45:00<59:38, 24.85s/it]2022-01-21 19:46:46,700 iteration 4353 : loss : 0.025780, loss_ce: 0.009122
2022-01-21 19:46:48,101 iteration 4354 : loss : 0.030436, loss_ce: 0.017171
2022-01-21 19:46:49,476 iteration 4355 : loss : 0.029748, loss_ce: 0.011395
2022-01-21 19:46:50,894 iteration 4356 : loss : 0.017819, loss_ce: 0.004897
2022-01-21 19:46:52,268 iteration 4357 : loss : 0.020975, loss_ce: 0.009920
2022-01-21 19:46:53,662 iteration 4358 : loss : 0.025580, loss_ce: 0.008883
2022-01-21 19:46:55,023 iteration 4359 : loss : 0.030353, loss_ce: 0.009818
2022-01-21 19:46:56,339 iteration 4360 : loss : 0.023830, loss_ce: 0.010444
2022-01-21 19:46:57,723 iteration 4361 : loss : 0.024503, loss_ce: 0.010275
2022-01-21 19:46:59,055 iteration 4362 : loss : 0.019102, loss_ce: 0.008605
2022-01-21 19:47:00,384 iteration 4363 : loss : 0.022344, loss_ce: 0.010136
2022-01-21 19:47:01,737 iteration 4364 : loss : 0.020247, loss_ce: 0.008107
2022-01-21 19:47:03,158 iteration 4365 : loss : 0.026861, loss_ce: 0.015065
2022-01-21 19:47:04,437 iteration 4366 : loss : 0.018563, loss_ce: 0.005693
2022-01-21 19:47:05,662 iteration 4367 : loss : 0.018715, loss_ce: 0.007854
2022-01-21 19:47:06,921 iteration 4368 : loss : 0.020601, loss_ce: 0.006632
2022-01-21 19:47:08,257 iteration 4369 : loss : 0.020062, loss_ce: 0.007979
 64%|██████████████████▋          | 257/400 [1:45:23<57:48, 24.26s/it]2022-01-21 19:47:09,631 iteration 4370 : loss : 0.017703, loss_ce: 0.006408
2022-01-21 19:47:10,980 iteration 4371 : loss : 0.022562, loss_ce: 0.012330
2022-01-21 19:47:12,340 iteration 4372 : loss : 0.022996, loss_ce: 0.008777
2022-01-21 19:47:13,695 iteration 4373 : loss : 0.017922, loss_ce: 0.009611
2022-01-21 19:47:15,062 iteration 4374 : loss : 0.023811, loss_ce: 0.007887
2022-01-21 19:47:16,422 iteration 4375 : loss : 0.025589, loss_ce: 0.011743
2022-01-21 19:47:17,727 iteration 4376 : loss : 0.019795, loss_ce: 0.007244
2022-01-21 19:47:19,035 iteration 4377 : loss : 0.019438, loss_ce: 0.005577
2022-01-21 19:47:20,298 iteration 4378 : loss : 0.014623, loss_ce: 0.005152
2022-01-21 19:47:21,570 iteration 4379 : loss : 0.022808, loss_ce: 0.008357
2022-01-21 19:47:22,814 iteration 4380 : loss : 0.016307, loss_ce: 0.005521
2022-01-21 19:47:24,166 iteration 4381 : loss : 0.027959, loss_ce: 0.009845
2022-01-21 19:47:25,493 iteration 4382 : loss : 0.029853, loss_ce: 0.005288
2022-01-21 19:47:26,789 iteration 4383 : loss : 0.020400, loss_ce: 0.006422
2022-01-21 19:47:28,174 iteration 4384 : loss : 0.021865, loss_ce: 0.008534
2022-01-21 19:47:29,556 iteration 4385 : loss : 0.023041, loss_ce: 0.007829
2022-01-21 19:47:30,845 iteration 4386 : loss : 0.018505, loss_ce: 0.008909
 64%|██████████████████▋          | 258/400 [1:45:46<56:13, 23.76s/it]2022-01-21 19:47:32,149 iteration 4387 : loss : 0.016888, loss_ce: 0.005041
2022-01-21 19:47:33,477 iteration 4388 : loss : 0.030350, loss_ce: 0.013258
2022-01-21 19:47:34,810 iteration 4389 : loss : 0.040492, loss_ce: 0.012823
2022-01-21 19:47:36,077 iteration 4390 : loss : 0.016227, loss_ce: 0.004763
2022-01-21 19:47:37,421 iteration 4391 : loss : 0.025026, loss_ce: 0.008091
2022-01-21 19:47:38,738 iteration 4392 : loss : 0.016786, loss_ce: 0.005093
2022-01-21 19:47:40,136 iteration 4393 : loss : 0.018268, loss_ce: 0.007276
2022-01-21 19:47:41,506 iteration 4394 : loss : 0.019772, loss_ce: 0.007547
2022-01-21 19:47:42,941 iteration 4395 : loss : 0.026214, loss_ce: 0.009759
2022-01-21 19:47:44,244 iteration 4396 : loss : 0.017793, loss_ce: 0.005789
2022-01-21 19:47:45,681 iteration 4397 : loss : 0.026537, loss_ce: 0.014076
2022-01-21 19:47:46,962 iteration 4398 : loss : 0.019336, loss_ce: 0.007665
2022-01-21 19:47:48,341 iteration 4399 : loss : 0.023848, loss_ce: 0.009746
2022-01-21 19:47:49,689 iteration 4400 : loss : 0.028024, loss_ce: 0.007878
2022-01-21 19:47:51,161 iteration 4401 : loss : 0.030785, loss_ce: 0.011708
2022-01-21 19:47:52,509 iteration 4402 : loss : 0.027210, loss_ce: 0.008607
2022-01-21 19:47:53,864 iteration 4403 : loss : 0.018854, loss_ce: 0.006822
 65%|██████████████████▊          | 259/400 [1:46:09<55:18, 23.54s/it]2022-01-21 19:47:55,202 iteration 4404 : loss : 0.020504, loss_ce: 0.008896
2022-01-21 19:47:56,571 iteration 4405 : loss : 0.022106, loss_ce: 0.009710
2022-01-21 19:47:57,926 iteration 4406 : loss : 0.017028, loss_ce: 0.006525
2022-01-21 19:47:59,324 iteration 4407 : loss : 0.025132, loss_ce: 0.009099
2022-01-21 19:48:00,637 iteration 4408 : loss : 0.016124, loss_ce: 0.006506
2022-01-21 19:48:01,995 iteration 4409 : loss : 0.018035, loss_ce: 0.005553
2022-01-21 19:48:03,475 iteration 4410 : loss : 0.044640, loss_ce: 0.014222
2022-01-21 19:48:04,860 iteration 4411 : loss : 0.019422, loss_ce: 0.008493
2022-01-21 19:48:06,194 iteration 4412 : loss : 0.023306, loss_ce: 0.008859
2022-01-21 19:48:07,551 iteration 4413 : loss : 0.017019, loss_ce: 0.005291
2022-01-21 19:48:08,824 iteration 4414 : loss : 0.017233, loss_ce: 0.005334
2022-01-21 19:48:10,191 iteration 4415 : loss : 0.022661, loss_ce: 0.007090
2022-01-21 19:48:11,585 iteration 4416 : loss : 0.026948, loss_ce: 0.008506
2022-01-21 19:48:12,919 iteration 4417 : loss : 0.017140, loss_ce: 0.005060
2022-01-21 19:48:14,267 iteration 4418 : loss : 0.025697, loss_ce: 0.010591
2022-01-21 19:48:15,652 iteration 4419 : loss : 0.020212, loss_ce: 0.005632
2022-01-21 19:48:15,652 Training Data Eval:
2022-01-21 19:48:22,179   Average segmentation loss on training set: 0.0140
2022-01-21 19:48:22,180 Validation Data Eval:
2022-01-21 19:48:24,412   Average segmentation loss on validation set: 0.0680
2022-01-21 19:48:25,684 iteration 4420 : loss : 0.015451, loss_ce: 0.006883
 65%|█████████████████▌         | 260/400 [1:46:41<1:00:43, 26.02s/it]2022-01-21 19:48:27,022 iteration 4421 : loss : 0.019594, loss_ce: 0.006780
2022-01-21 19:48:28,368 iteration 4422 : loss : 0.022261, loss_ce: 0.008693
2022-01-21 19:48:29,759 iteration 4423 : loss : 0.022115, loss_ce: 0.008484
2022-01-21 19:48:31,035 iteration 4424 : loss : 0.016707, loss_ce: 0.005324
2022-01-21 19:48:32,303 iteration 4425 : loss : 0.017852, loss_ce: 0.006048
2022-01-21 19:48:33,691 iteration 4426 : loss : 0.018327, loss_ce: 0.007870
2022-01-21 19:48:34,964 iteration 4427 : loss : 0.015371, loss_ce: 0.006921
2022-01-21 19:48:36,191 iteration 4428 : loss : 0.013138, loss_ce: 0.005903
2022-01-21 19:48:37,439 iteration 4429 : loss : 0.017044, loss_ce: 0.005611
2022-01-21 19:48:38,694 iteration 4430 : loss : 0.015690, loss_ce: 0.007102
2022-01-21 19:48:40,033 iteration 4431 : loss : 0.025341, loss_ce: 0.012287
2022-01-21 19:48:41,403 iteration 4432 : loss : 0.029198, loss_ce: 0.015054
2022-01-21 19:48:42,707 iteration 4433 : loss : 0.025389, loss_ce: 0.006509
2022-01-21 19:48:43,970 iteration 4434 : loss : 0.012786, loss_ce: 0.005286
2022-01-21 19:48:45,294 iteration 4435 : loss : 0.020032, loss_ce: 0.004220
2022-01-21 19:48:46,613 iteration 4436 : loss : 0.016760, loss_ce: 0.006530
2022-01-21 19:48:47,996 iteration 4437 : loss : 0.021899, loss_ce: 0.008010
 65%|██████████████████▉          | 261/400 [1:47:03<57:42, 24.91s/it]2022-01-21 19:48:49,429 iteration 4438 : loss : 0.050176, loss_ce: 0.013669
2022-01-21 19:48:50,788 iteration 4439 : loss : 0.022835, loss_ce: 0.008396
2022-01-21 19:48:52,128 iteration 4440 : loss : 0.017536, loss_ce: 0.005876
2022-01-21 19:48:53,570 iteration 4441 : loss : 0.028759, loss_ce: 0.010673
2022-01-21 19:48:54,966 iteration 4442 : loss : 0.016941, loss_ce: 0.008183
2022-01-21 19:48:56,324 iteration 4443 : loss : 0.030080, loss_ce: 0.011242
2022-01-21 19:48:57,584 iteration 4444 : loss : 0.019493, loss_ce: 0.006406
2022-01-21 19:48:58,897 iteration 4445 : loss : 0.036247, loss_ce: 0.012826
2022-01-21 19:49:00,253 iteration 4446 : loss : 0.026429, loss_ce: 0.012888
2022-01-21 19:49:01,560 iteration 4447 : loss : 0.019390, loss_ce: 0.006164
2022-01-21 19:49:02,914 iteration 4448 : loss : 0.027284, loss_ce: 0.009614
2022-01-21 19:49:04,253 iteration 4449 : loss : 0.028026, loss_ce: 0.011808
2022-01-21 19:49:05,644 iteration 4450 : loss : 0.033319, loss_ce: 0.010657
2022-01-21 19:49:06,943 iteration 4451 : loss : 0.018322, loss_ce: 0.006901
2022-01-21 19:49:08,293 iteration 4452 : loss : 0.021848, loss_ce: 0.009261
2022-01-21 19:49:09,598 iteration 4453 : loss : 0.015491, loss_ce: 0.005455
2022-01-21 19:49:10,905 iteration 4454 : loss : 0.024357, loss_ce: 0.009103
 66%|██████████████████▉          | 262/400 [1:47:26<55:54, 24.31s/it]2022-01-21 19:49:12,290 iteration 4455 : loss : 0.018844, loss_ce: 0.005014
2022-01-21 19:49:13,536 iteration 4456 : loss : 0.015657, loss_ce: 0.006052
2022-01-21 19:49:14,885 iteration 4457 : loss : 0.016096, loss_ce: 0.006773
2022-01-21 19:49:16,318 iteration 4458 : loss : 0.034121, loss_ce: 0.012865
2022-01-21 19:49:17,814 iteration 4459 : loss : 0.023599, loss_ce: 0.009996
2022-01-21 19:49:19,111 iteration 4460 : loss : 0.017116, loss_ce: 0.006074
2022-01-21 19:49:20,451 iteration 4461 : loss : 0.021588, loss_ce: 0.006561
2022-01-21 19:49:21,826 iteration 4462 : loss : 0.022418, loss_ce: 0.009438
2022-01-21 19:49:23,144 iteration 4463 : loss : 0.024525, loss_ce: 0.009691
2022-01-21 19:49:24,450 iteration 4464 : loss : 0.014768, loss_ce: 0.004961
2022-01-21 19:49:25,700 iteration 4465 : loss : 0.019947, loss_ce: 0.004438
2022-01-21 19:49:26,976 iteration 4466 : loss : 0.019009, loss_ce: 0.005306
2022-01-21 19:49:28,301 iteration 4467 : loss : 0.027630, loss_ce: 0.015284
2022-01-21 19:49:29,660 iteration 4468 : loss : 0.024690, loss_ce: 0.010539
2022-01-21 19:49:31,064 iteration 4469 : loss : 0.025110, loss_ce: 0.011982
2022-01-21 19:49:32,451 iteration 4470 : loss : 0.021637, loss_ce: 0.008697
2022-01-21 19:49:33,864 iteration 4471 : loss : 0.024183, loss_ce: 0.006771
 66%|███████████████████          | 263/400 [1:47:49<54:34, 23.90s/it]2022-01-21 19:49:35,200 iteration 4472 : loss : 0.016495, loss_ce: 0.007673
2022-01-21 19:49:36,491 iteration 4473 : loss : 0.030166, loss_ce: 0.011564
2022-01-21 19:49:37,829 iteration 4474 : loss : 0.015948, loss_ce: 0.007549
2022-01-21 19:49:39,154 iteration 4475 : loss : 0.019705, loss_ce: 0.005870
2022-01-21 19:49:40,445 iteration 4476 : loss : 0.019319, loss_ce: 0.006379
2022-01-21 19:49:41,751 iteration 4477 : loss : 0.018960, loss_ce: 0.008312
2022-01-21 19:49:43,186 iteration 4478 : loss : 0.025701, loss_ce: 0.011743
2022-01-21 19:49:44,523 iteration 4479 : loss : 0.029375, loss_ce: 0.008105
2022-01-21 19:49:45,871 iteration 4480 : loss : 0.020997, loss_ce: 0.007686
2022-01-21 19:49:47,164 iteration 4481 : loss : 0.022474, loss_ce: 0.008788
2022-01-21 19:49:48,437 iteration 4482 : loss : 0.016549, loss_ce: 0.004807
2022-01-21 19:49:49,734 iteration 4483 : loss : 0.043173, loss_ce: 0.011071
2022-01-21 19:49:51,066 iteration 4484 : loss : 0.013107, loss_ce: 0.004395
2022-01-21 19:49:52,323 iteration 4485 : loss : 0.016067, loss_ce: 0.006065
2022-01-21 19:49:53,707 iteration 4486 : loss : 0.019905, loss_ce: 0.006837
2022-01-21 19:49:55,063 iteration 4487 : loss : 0.021174, loss_ce: 0.009199
2022-01-21 19:49:56,343 iteration 4488 : loss : 0.018964, loss_ce: 0.007777
 66%|███████████████████▏         | 264/400 [1:48:11<53:12, 23.47s/it]2022-01-21 19:49:57,745 iteration 4489 : loss : 0.025234, loss_ce: 0.011804
2022-01-21 19:49:59,070 iteration 4490 : loss : 0.033376, loss_ce: 0.015578
2022-01-21 19:50:00,501 iteration 4491 : loss : 0.031694, loss_ce: 0.010835
2022-01-21 19:50:01,803 iteration 4492 : loss : 0.021369, loss_ce: 0.006120
2022-01-21 19:50:03,214 iteration 4493 : loss : 0.033246, loss_ce: 0.020981
2022-01-21 19:50:04,511 iteration 4494 : loss : 0.020963, loss_ce: 0.007551
2022-01-21 19:50:05,851 iteration 4495 : loss : 0.030982, loss_ce: 0.007567
2022-01-21 19:50:07,199 iteration 4496 : loss : 0.037766, loss_ce: 0.009604
2022-01-21 19:50:08,422 iteration 4497 : loss : 0.019362, loss_ce: 0.009569
2022-01-21 19:50:09,741 iteration 4498 : loss : 0.024297, loss_ce: 0.008337
2022-01-21 19:50:11,033 iteration 4499 : loss : 0.016440, loss_ce: 0.006497
2022-01-21 19:50:12,359 iteration 4500 : loss : 0.027151, loss_ce: 0.009673
2022-01-21 19:50:13,657 iteration 4501 : loss : 0.033039, loss_ce: 0.019587
2022-01-21 19:50:14,968 iteration 4502 : loss : 0.023842, loss_ce: 0.009580
2022-01-21 19:50:16,373 iteration 4503 : loss : 0.023265, loss_ce: 0.007749
2022-01-21 19:50:17,612 iteration 4504 : loss : 0.022963, loss_ce: 0.008505
2022-01-21 19:50:17,613 Training Data Eval:
2022-01-21 19:50:24,142   Average segmentation loss on training set: 0.0167
2022-01-21 19:50:24,142 Validation Data Eval:
2022-01-21 19:50:26,385   Average segmentation loss on validation set: 0.0849
2022-01-21 19:50:27,717 iteration 4505 : loss : 0.022485, loss_ce: 0.008233
 66%|███████████████████▏         | 265/400 [1:48:43<58:09, 25.85s/it]2022-01-21 19:50:29,110 iteration 4506 : loss : 0.022972, loss_ce: 0.008034
2022-01-21 19:50:30,515 iteration 4507 : loss : 0.037189, loss_ce: 0.013663
2022-01-21 19:50:31,850 iteration 4508 : loss : 0.020753, loss_ce: 0.006092
2022-01-21 19:50:33,112 iteration 4509 : loss : 0.023693, loss_ce: 0.007983
2022-01-21 19:50:34,441 iteration 4510 : loss : 0.019681, loss_ce: 0.006692
2022-01-21 19:50:35,865 iteration 4511 : loss : 0.025197, loss_ce: 0.011161
2022-01-21 19:50:37,106 iteration 4512 : loss : 0.017823, loss_ce: 0.006260
2022-01-21 19:50:38,405 iteration 4513 : loss : 0.018945, loss_ce: 0.006591
2022-01-21 19:50:39,697 iteration 4514 : loss : 0.021188, loss_ce: 0.008288
2022-01-21 19:50:41,011 iteration 4515 : loss : 0.020491, loss_ce: 0.008973
2022-01-21 19:50:42,347 iteration 4516 : loss : 0.018402, loss_ce: 0.007840
2022-01-21 19:50:43,705 iteration 4517 : loss : 0.024196, loss_ce: 0.009207
2022-01-21 19:50:45,015 iteration 4518 : loss : 0.017426, loss_ce: 0.007661
2022-01-21 19:50:46,269 iteration 4519 : loss : 0.030547, loss_ce: 0.009593
2022-01-21 19:50:47,598 iteration 4520 : loss : 0.018832, loss_ce: 0.004793
2022-01-21 19:50:48,942 iteration 4521 : loss : 0.017281, loss_ce: 0.007207
2022-01-21 19:50:50,326 iteration 4522 : loss : 0.022254, loss_ce: 0.007612
 66%|███████████████████▎         | 266/400 [1:49:05<55:33, 24.88s/it]2022-01-21 19:50:51,765 iteration 4523 : loss : 0.028119, loss_ce: 0.013391
2022-01-21 19:50:53,113 iteration 4524 : loss : 0.026151, loss_ce: 0.008863
2022-01-21 19:50:54,473 iteration 4525 : loss : 0.021203, loss_ce: 0.009223
2022-01-21 19:50:55,801 iteration 4526 : loss : 0.017406, loss_ce: 0.004720
2022-01-21 19:50:57,055 iteration 4527 : loss : 0.020522, loss_ce: 0.007294
2022-01-21 19:50:58,343 iteration 4528 : loss : 0.021274, loss_ce: 0.006906
2022-01-21 19:50:59,690 iteration 4529 : loss : 0.024806, loss_ce: 0.011011
2022-01-21 19:51:00,982 iteration 4530 : loss : 0.020372, loss_ce: 0.005974
2022-01-21 19:51:02,308 iteration 4531 : loss : 0.022007, loss_ce: 0.007281
2022-01-21 19:51:03,663 iteration 4532 : loss : 0.013697, loss_ce: 0.004660
2022-01-21 19:51:04,966 iteration 4533 : loss : 0.038508, loss_ce: 0.019882
2022-01-21 19:51:06,276 iteration 4534 : loss : 0.028417, loss_ce: 0.008030
2022-01-21 19:51:07,635 iteration 4535 : loss : 0.018381, loss_ce: 0.007378
2022-01-21 19:51:08,984 iteration 4536 : loss : 0.019246, loss_ce: 0.007201
2022-01-21 19:51:10,323 iteration 4537 : loss : 0.022007, loss_ce: 0.009257
2022-01-21 19:51:11,645 iteration 4538 : loss : 0.023716, loss_ce: 0.008842
2022-01-21 19:51:12,969 iteration 4539 : loss : 0.017031, loss_ce: 0.006690
 67%|███████████████████▎         | 267/400 [1:49:28<53:39, 24.21s/it]2022-01-21 19:51:14,307 iteration 4540 : loss : 0.013966, loss_ce: 0.005002
2022-01-21 19:51:15,666 iteration 4541 : loss : 0.019635, loss_ce: 0.009001
2022-01-21 19:51:16,947 iteration 4542 : loss : 0.018784, loss_ce: 0.006864
2022-01-21 19:51:18,249 iteration 4543 : loss : 0.023217, loss_ce: 0.008621
2022-01-21 19:51:19,535 iteration 4544 : loss : 0.022057, loss_ce: 0.008327
2022-01-21 19:51:20,927 iteration 4545 : loss : 0.024188, loss_ce: 0.011179
2022-01-21 19:51:22,363 iteration 4546 : loss : 0.029130, loss_ce: 0.012863
2022-01-21 19:51:23,786 iteration 4547 : loss : 0.025769, loss_ce: 0.009853
2022-01-21 19:51:25,057 iteration 4548 : loss : 0.016615, loss_ce: 0.005851
2022-01-21 19:51:26,332 iteration 4549 : loss : 0.019454, loss_ce: 0.007221
2022-01-21 19:51:27,667 iteration 4550 : loss : 0.022051, loss_ce: 0.008955
2022-01-21 19:51:29,019 iteration 4551 : loss : 0.030060, loss_ce: 0.012211
2022-01-21 19:51:30,430 iteration 4552 : loss : 0.043207, loss_ce: 0.012767
2022-01-21 19:51:31,782 iteration 4553 : loss : 0.020758, loss_ce: 0.007871
2022-01-21 19:51:33,068 iteration 4554 : loss : 0.018005, loss_ce: 0.007848
2022-01-21 19:51:34,382 iteration 4555 : loss : 0.020225, loss_ce: 0.007856
2022-01-21 19:51:35,700 iteration 4556 : loss : 0.031449, loss_ce: 0.008700
 67%|███████████████████▍         | 268/400 [1:49:51<52:16, 23.76s/it]2022-01-21 19:51:37,031 iteration 4557 : loss : 0.016750, loss_ce: 0.007108
2022-01-21 19:51:38,390 iteration 4558 : loss : 0.021481, loss_ce: 0.007096
2022-01-21 19:51:39,790 iteration 4559 : loss : 0.024522, loss_ce: 0.011236
2022-01-21 19:51:41,155 iteration 4560 : loss : 0.021764, loss_ce: 0.012058
2022-01-21 19:51:42,445 iteration 4561 : loss : 0.014022, loss_ce: 0.004685
2022-01-21 19:51:43,783 iteration 4562 : loss : 0.019292, loss_ce: 0.007347
2022-01-21 19:51:45,095 iteration 4563 : loss : 0.020628, loss_ce: 0.008434
2022-01-21 19:51:46,394 iteration 4564 : loss : 0.014044, loss_ce: 0.005926
2022-01-21 19:51:47,713 iteration 4565 : loss : 0.020967, loss_ce: 0.008551
2022-01-21 19:51:49,054 iteration 4566 : loss : 0.029172, loss_ce: 0.013976
2022-01-21 19:51:50,377 iteration 4567 : loss : 0.021843, loss_ce: 0.008642
2022-01-21 19:51:51,624 iteration 4568 : loss : 0.016803, loss_ce: 0.005576
2022-01-21 19:51:52,891 iteration 4569 : loss : 0.032697, loss_ce: 0.014680
2022-01-21 19:51:54,172 iteration 4570 : loss : 0.022081, loss_ce: 0.008464
2022-01-21 19:51:55,534 iteration 4571 : loss : 0.023698, loss_ce: 0.010810
2022-01-21 19:51:56,891 iteration 4572 : loss : 0.024135, loss_ce: 0.008511
2022-01-21 19:51:58,268 iteration 4573 : loss : 0.024533, loss_ce: 0.007761
 67%|███████████████████▌         | 269/400 [1:50:13<51:05, 23.40s/it]2022-01-21 19:51:59,573 iteration 4574 : loss : 0.013566, loss_ce: 0.004480
2022-01-21 19:52:00,927 iteration 4575 : loss : 0.016546, loss_ce: 0.004389
2022-01-21 19:52:02,183 iteration 4576 : loss : 0.019859, loss_ce: 0.007378
2022-01-21 19:52:03,455 iteration 4577 : loss : 0.015699, loss_ce: 0.007441
2022-01-21 19:52:04,781 iteration 4578 : loss : 0.020559, loss_ce: 0.008337
2022-01-21 19:52:06,058 iteration 4579 : loss : 0.019722, loss_ce: 0.008844
2022-01-21 19:52:07,354 iteration 4580 : loss : 0.016517, loss_ce: 0.006113
2022-01-21 19:52:08,675 iteration 4581 : loss : 0.021160, loss_ce: 0.010317
2022-01-21 19:52:09,994 iteration 4582 : loss : 0.035819, loss_ce: 0.019433
2022-01-21 19:52:11,303 iteration 4583 : loss : 0.020217, loss_ce: 0.007927
2022-01-21 19:52:12,604 iteration 4584 : loss : 0.016217, loss_ce: 0.005725
2022-01-21 19:52:13,946 iteration 4585 : loss : 0.027034, loss_ce: 0.009221
2022-01-21 19:52:15,217 iteration 4586 : loss : 0.015223, loss_ce: 0.006067
2022-01-21 19:52:16,506 iteration 4587 : loss : 0.013287, loss_ce: 0.003989
2022-01-21 19:52:17,795 iteration 4588 : loss : 0.019639, loss_ce: 0.007653
2022-01-21 19:52:19,137 iteration 4589 : loss : 0.024418, loss_ce: 0.007297
2022-01-21 19:52:19,137 Training Data Eval:
2022-01-21 19:52:25,666   Average segmentation loss on training set: 0.0118
2022-01-21 19:52:25,667 Validation Data Eval:
2022-01-21 19:52:27,905   Average segmentation loss on validation set: 0.0612
2022-01-21 19:52:29,207 iteration 4590 : loss : 0.016385, loss_ce: 0.007034
 68%|███████████████████▌         | 270/400 [1:50:44<55:36, 25.67s/it]2022-01-21 19:52:30,573 iteration 4591 : loss : 0.024408, loss_ce: 0.007247
2022-01-21 19:52:31,947 iteration 4592 : loss : 0.023440, loss_ce: 0.007809
2022-01-21 19:52:33,300 iteration 4593 : loss : 0.021668, loss_ce: 0.010274
2022-01-21 19:52:34,692 iteration 4594 : loss : 0.040160, loss_ce: 0.010874
2022-01-21 19:52:36,009 iteration 4595 : loss : 0.019191, loss_ce: 0.006821
2022-01-21 19:52:37,304 iteration 4596 : loss : 0.019701, loss_ce: 0.005734
2022-01-21 19:52:38,643 iteration 4597 : loss : 0.014449, loss_ce: 0.006399
2022-01-21 19:52:40,033 iteration 4598 : loss : 0.027789, loss_ce: 0.011557
2022-01-21 19:52:41,398 iteration 4599 : loss : 0.016343, loss_ce: 0.009001
2022-01-21 19:52:42,706 iteration 4600 : loss : 0.019982, loss_ce: 0.007062
2022-01-21 19:52:44,056 iteration 4601 : loss : 0.022072, loss_ce: 0.008748
2022-01-21 19:52:45,483 iteration 4602 : loss : 0.030203, loss_ce: 0.008821
2022-01-21 19:52:46,828 iteration 4603 : loss : 0.025199, loss_ce: 0.008587
2022-01-21 19:52:48,204 iteration 4604 : loss : 0.019795, loss_ce: 0.008406
2022-01-21 19:52:49,584 iteration 4605 : loss : 0.051591, loss_ce: 0.009032
2022-01-21 19:52:50,960 iteration 4606 : loss : 0.020447, loss_ce: 0.008189
2022-01-21 19:52:52,340 iteration 4607 : loss : 0.022125, loss_ce: 0.011237
 68%|███████████████████▋         | 271/400 [1:51:07<53:32, 24.91s/it]2022-01-21 19:52:53,668 iteration 4608 : loss : 0.015373, loss_ce: 0.006426
2022-01-21 19:52:55,006 iteration 4609 : loss : 0.032132, loss_ce: 0.014147
2022-01-21 19:52:56,281 iteration 4610 : loss : 0.017275, loss_ce: 0.004968
2022-01-21 19:52:57,551 iteration 4611 : loss : 0.022415, loss_ce: 0.009114
2022-01-21 19:52:58,803 iteration 4612 : loss : 0.017036, loss_ce: 0.004950
2022-01-21 19:53:00,132 iteration 4613 : loss : 0.020238, loss_ce: 0.006495
2022-01-21 19:53:01,464 iteration 4614 : loss : 0.016084, loss_ce: 0.007164
2022-01-21 19:53:02,835 iteration 4615 : loss : 0.018254, loss_ce: 0.007523
2022-01-21 19:53:04,277 iteration 4616 : loss : 0.032087, loss_ce: 0.015588
2022-01-21 19:53:05,623 iteration 4617 : loss : 0.018657, loss_ce: 0.006610
2022-01-21 19:53:06,902 iteration 4618 : loss : 0.022498, loss_ce: 0.006024
2022-01-21 19:53:08,191 iteration 4619 : loss : 0.013446, loss_ce: 0.005816
2022-01-21 19:53:09,574 iteration 4620 : loss : 0.016261, loss_ce: 0.004385
2022-01-21 19:53:10,889 iteration 4621 : loss : 0.019254, loss_ce: 0.009409
2022-01-21 19:53:12,220 iteration 4622 : loss : 0.034207, loss_ce: 0.010352
2022-01-21 19:53:13,538 iteration 4623 : loss : 0.025814, loss_ce: 0.008888
2022-01-21 19:53:14,875 iteration 4624 : loss : 0.014985, loss_ce: 0.006647
 68%|███████████████████▋         | 272/400 [1:51:30<51:36, 24.19s/it]2022-01-21 19:53:16,285 iteration 4625 : loss : 0.040157, loss_ce: 0.026201
2022-01-21 19:53:17,675 iteration 4626 : loss : 0.028724, loss_ce: 0.013453
2022-01-21 19:53:19,104 iteration 4627 : loss : 0.022755, loss_ce: 0.009257
2022-01-21 19:53:20,408 iteration 4628 : loss : 0.045703, loss_ce: 0.015678
2022-01-21 19:53:21,670 iteration 4629 : loss : 0.018696, loss_ce: 0.005754
2022-01-21 19:53:22,987 iteration 4630 : loss : 0.020373, loss_ce: 0.008001
2022-01-21 19:53:24,327 iteration 4631 : loss : 0.018755, loss_ce: 0.006334
2022-01-21 19:53:25,658 iteration 4632 : loss : 0.020178, loss_ce: 0.006566
2022-01-21 19:53:26,966 iteration 4633 : loss : 0.023820, loss_ce: 0.008661
2022-01-21 19:53:28,254 iteration 4634 : loss : 0.017738, loss_ce: 0.008507
2022-01-21 19:53:29,499 iteration 4635 : loss : 0.015506, loss_ce: 0.005993
2022-01-21 19:53:30,903 iteration 4636 : loss : 0.020154, loss_ce: 0.007325
2022-01-21 19:53:32,205 iteration 4637 : loss : 0.021952, loss_ce: 0.007270
2022-01-21 19:53:33,641 iteration 4638 : loss : 0.030021, loss_ce: 0.013165
2022-01-21 19:53:35,014 iteration 4639 : loss : 0.024398, loss_ce: 0.009551
2022-01-21 19:53:36,464 iteration 4640 : loss : 0.027938, loss_ce: 0.009844
2022-01-21 19:53:37,844 iteration 4641 : loss : 0.027889, loss_ce: 0.011775
 68%|███████████████████▊         | 273/400 [1:51:53<50:26, 23.83s/it]2022-01-21 19:53:39,206 iteration 4642 : loss : 0.023272, loss_ce: 0.005072
2022-01-21 19:53:40,535 iteration 4643 : loss : 0.018922, loss_ce: 0.006127
2022-01-21 19:53:41,923 iteration 4644 : loss : 0.024173, loss_ce: 0.007948
2022-01-21 19:53:43,323 iteration 4645 : loss : 0.022553, loss_ce: 0.009875
2022-01-21 19:53:44,682 iteration 4646 : loss : 0.036453, loss_ce: 0.010861
2022-01-21 19:53:45,945 iteration 4647 : loss : 0.015842, loss_ce: 0.005254
2022-01-21 19:53:47,247 iteration 4648 : loss : 0.018188, loss_ce: 0.005901
2022-01-21 19:53:48,589 iteration 4649 : loss : 0.019252, loss_ce: 0.007882
2022-01-21 19:53:49,974 iteration 4650 : loss : 0.027576, loss_ce: 0.010305
2022-01-21 19:53:51,253 iteration 4651 : loss : 0.022783, loss_ce: 0.009854
2022-01-21 19:53:52,660 iteration 4652 : loss : 0.020572, loss_ce: 0.008429
2022-01-21 19:53:53,969 iteration 4653 : loss : 0.023924, loss_ce: 0.009834
2022-01-21 19:53:55,282 iteration 4654 : loss : 0.021675, loss_ce: 0.006879
2022-01-21 19:53:56,678 iteration 4655 : loss : 0.028925, loss_ce: 0.012599
2022-01-21 19:53:58,097 iteration 4656 : loss : 0.024011, loss_ce: 0.010576
2022-01-21 19:53:59,475 iteration 4657 : loss : 0.019070, loss_ce: 0.008527
2022-01-21 19:54:00,843 iteration 4658 : loss : 0.039386, loss_ce: 0.020434
 68%|███████████████████▊         | 274/400 [1:52:16<49:30, 23.58s/it]2022-01-21 19:54:02,248 iteration 4659 : loss : 0.022233, loss_ce: 0.009522
2022-01-21 19:54:03,642 iteration 4660 : loss : 0.029646, loss_ce: 0.013618
2022-01-21 19:54:05,009 iteration 4661 : loss : 0.024767, loss_ce: 0.008444
2022-01-21 19:54:06,299 iteration 4662 : loss : 0.017635, loss_ce: 0.007138
2022-01-21 19:54:07,662 iteration 4663 : loss : 0.018803, loss_ce: 0.007510
2022-01-21 19:54:08,972 iteration 4664 : loss : 0.016996, loss_ce: 0.006646
2022-01-21 19:54:10,295 iteration 4665 : loss : 0.018460, loss_ce: 0.006019
2022-01-21 19:54:11,523 iteration 4666 : loss : 0.015224, loss_ce: 0.004929
2022-01-21 19:54:12,811 iteration 4667 : loss : 0.015997, loss_ce: 0.005700
2022-01-21 19:54:14,267 iteration 4668 : loss : 0.024588, loss_ce: 0.012397
2022-01-21 19:54:15,553 iteration 4669 : loss : 0.015793, loss_ce: 0.006489
2022-01-21 19:54:16,844 iteration 4670 : loss : 0.030175, loss_ce: 0.013673
2022-01-21 19:54:18,122 iteration 4671 : loss : 0.021990, loss_ce: 0.007033
2022-01-21 19:54:19,549 iteration 4672 : loss : 0.032313, loss_ce: 0.011838
2022-01-21 19:54:20,937 iteration 4673 : loss : 0.024363, loss_ce: 0.011260
2022-01-21 19:54:22,207 iteration 4674 : loss : 0.015686, loss_ce: 0.004622
2022-01-21 19:54:22,207 Training Data Eval:
2022-01-21 19:54:28,732   Average segmentation loss on training set: 0.0122
2022-01-21 19:54:28,732 Validation Data Eval:
2022-01-21 19:54:30,968   Average segmentation loss on validation set: 0.0629
2022-01-21 19:54:32,347 iteration 4675 : loss : 0.019339, loss_ce: 0.007046
 69%|███████████████████▉         | 275/400 [1:52:47<54:04, 25.96s/it]2022-01-21 19:54:33,815 iteration 4676 : loss : 0.024834, loss_ce: 0.007589
2022-01-21 19:54:35,132 iteration 4677 : loss : 0.023790, loss_ce: 0.008003
2022-01-21 19:54:36,484 iteration 4678 : loss : 0.021633, loss_ce: 0.006535
2022-01-21 19:54:37,886 iteration 4679 : loss : 0.042545, loss_ce: 0.009681
2022-01-21 19:54:39,216 iteration 4680 : loss : 0.018209, loss_ce: 0.008232
2022-01-21 19:54:40,534 iteration 4681 : loss : 0.059468, loss_ce: 0.021085
2022-01-21 19:54:41,837 iteration 4682 : loss : 0.019426, loss_ce: 0.007349
2022-01-21 19:54:43,067 iteration 4683 : loss : 0.027663, loss_ce: 0.006831
2022-01-21 19:54:44,451 iteration 4684 : loss : 0.025850, loss_ce: 0.011894
2022-01-21 19:54:45,806 iteration 4685 : loss : 0.039316, loss_ce: 0.013241
2022-01-21 19:54:47,134 iteration 4686 : loss : 0.024268, loss_ce: 0.007542
2022-01-21 19:54:48,441 iteration 4687 : loss : 0.019364, loss_ce: 0.007902
2022-01-21 19:54:49,693 iteration 4688 : loss : 0.017664, loss_ce: 0.007913
2022-01-21 19:54:50,951 iteration 4689 : loss : 0.013412, loss_ce: 0.005711
2022-01-21 19:54:52,228 iteration 4690 : loss : 0.019116, loss_ce: 0.007808
2022-01-21 19:54:53,595 iteration 4691 : loss : 0.029702, loss_ce: 0.016112
2022-01-21 19:54:54,902 iteration 4692 : loss : 0.021552, loss_ce: 0.005976
 69%|████████████████████         | 276/400 [1:53:10<51:32, 24.94s/it]2022-01-21 19:54:56,333 iteration 4693 : loss : 0.031054, loss_ce: 0.010959
2022-01-21 19:54:57,691 iteration 4694 : loss : 0.023920, loss_ce: 0.008584
2022-01-21 19:54:58,882 iteration 4695 : loss : 0.014917, loss_ce: 0.004540
2022-01-21 19:55:00,279 iteration 4696 : loss : 0.030470, loss_ce: 0.013598
2022-01-21 19:55:01,578 iteration 4697 : loss : 0.022966, loss_ce: 0.007986
2022-01-21 19:55:02,911 iteration 4698 : loss : 0.021238, loss_ce: 0.009515
2022-01-21 19:55:04,299 iteration 4699 : loss : 0.017704, loss_ce: 0.007767
2022-01-21 19:55:05,587 iteration 4700 : loss : 0.027771, loss_ce: 0.012118
2022-01-21 19:55:07,014 iteration 4701 : loss : 0.022261, loss_ce: 0.008910
2022-01-21 19:55:08,322 iteration 4702 : loss : 0.018802, loss_ce: 0.007418
2022-01-21 19:55:09,610 iteration 4703 : loss : 0.016602, loss_ce: 0.004153
2022-01-21 19:55:10,938 iteration 4704 : loss : 0.018014, loss_ce: 0.006351
2022-01-21 19:55:12,136 iteration 4705 : loss : 0.014841, loss_ce: 0.006113
2022-01-21 19:55:13,458 iteration 4706 : loss : 0.025820, loss_ce: 0.008682
2022-01-21 19:55:14,838 iteration 4707 : loss : 0.019922, loss_ce: 0.007207
2022-01-21 19:55:16,229 iteration 4708 : loss : 0.019042, loss_ce: 0.006724
2022-01-21 19:55:17,597 iteration 4709 : loss : 0.027003, loss_ce: 0.009092
 69%|████████████████████         | 277/400 [1:53:33<49:44, 24.26s/it]2022-01-21 19:55:18,995 iteration 4710 : loss : 0.020911, loss_ce: 0.004427
2022-01-21 19:55:20,467 iteration 4711 : loss : 0.022506, loss_ce: 0.008841
2022-01-21 19:55:21,781 iteration 4712 : loss : 0.020640, loss_ce: 0.009181
2022-01-21 19:55:23,104 iteration 4713 : loss : 0.017127, loss_ce: 0.006450
2022-01-21 19:55:24,449 iteration 4714 : loss : 0.017834, loss_ce: 0.005762
2022-01-21 19:55:25,843 iteration 4715 : loss : 0.045451, loss_ce: 0.012082
2022-01-21 19:55:27,200 iteration 4716 : loss : 0.019973, loss_ce: 0.006812
2022-01-21 19:55:28,522 iteration 4717 : loss : 0.021000, loss_ce: 0.006917
2022-01-21 19:55:29,787 iteration 4718 : loss : 0.013955, loss_ce: 0.004852
2022-01-21 19:55:31,053 iteration 4719 : loss : 0.018367, loss_ce: 0.008952
2022-01-21 19:55:32,342 iteration 4720 : loss : 0.017660, loss_ce: 0.006975
2022-01-21 19:55:33,651 iteration 4721 : loss : 0.020057, loss_ce: 0.007791
2022-01-21 19:55:35,030 iteration 4722 : loss : 0.028583, loss_ce: 0.009471
2022-01-21 19:55:36,357 iteration 4723 : loss : 0.013560, loss_ce: 0.005143
2022-01-21 19:55:37,620 iteration 4724 : loss : 0.014273, loss_ce: 0.005490
2022-01-21 19:55:38,880 iteration 4725 : loss : 0.018939, loss_ce: 0.007846
2022-01-21 19:55:40,202 iteration 4726 : loss : 0.020966, loss_ce: 0.008816
 70%|████████████████████▏        | 278/400 [1:53:55<48:19, 23.77s/it]2022-01-21 19:55:41,625 iteration 4727 : loss : 0.019773, loss_ce: 0.006372
2022-01-21 19:55:42,899 iteration 4728 : loss : 0.015115, loss_ce: 0.005764
2022-01-21 19:55:44,184 iteration 4729 : loss : 0.016410, loss_ce: 0.005738
2022-01-21 19:55:45,469 iteration 4730 : loss : 0.014078, loss_ce: 0.004592
2022-01-21 19:55:46,848 iteration 4731 : loss : 0.026284, loss_ce: 0.009336
2022-01-21 19:55:48,188 iteration 4732 : loss : 0.026296, loss_ce: 0.008880
2022-01-21 19:55:49,521 iteration 4733 : loss : 0.016837, loss_ce: 0.005955
2022-01-21 19:55:50,826 iteration 4734 : loss : 0.017828, loss_ce: 0.006221
2022-01-21 19:55:52,242 iteration 4735 : loss : 0.019596, loss_ce: 0.006628
2022-01-21 19:55:53,504 iteration 4736 : loss : 0.019334, loss_ce: 0.007699
2022-01-21 19:55:54,904 iteration 4737 : loss : 0.022777, loss_ce: 0.009572
2022-01-21 19:55:56,231 iteration 4738 : loss : 0.016216, loss_ce: 0.005464
2022-01-21 19:55:57,554 iteration 4739 : loss : 0.017555, loss_ce: 0.005868
2022-01-21 19:55:58,923 iteration 4740 : loss : 0.022681, loss_ce: 0.011321
2022-01-21 19:56:00,230 iteration 4741 : loss : 0.015623, loss_ce: 0.005090
2022-01-21 19:56:01,548 iteration 4742 : loss : 0.019231, loss_ce: 0.009719
2022-01-21 19:56:02,954 iteration 4743 : loss : 0.023034, loss_ce: 0.007704
 70%|████████████████████▏        | 279/400 [1:54:18<47:18, 23.46s/it]2022-01-21 19:56:04,378 iteration 4744 : loss : 0.018652, loss_ce: 0.006375
2022-01-21 19:56:05,712 iteration 4745 : loss : 0.021141, loss_ce: 0.006178
2022-01-21 19:56:07,004 iteration 4746 : loss : 0.020843, loss_ce: 0.010601
2022-01-21 19:56:08,307 iteration 4747 : loss : 0.019167, loss_ce: 0.006551
2022-01-21 19:56:09,644 iteration 4748 : loss : 0.022570, loss_ce: 0.009618
2022-01-21 19:56:10,981 iteration 4749 : loss : 0.023817, loss_ce: 0.008054
2022-01-21 19:56:12,362 iteration 4750 : loss : 0.018414, loss_ce: 0.006685
2022-01-21 19:56:13,672 iteration 4751 : loss : 0.016506, loss_ce: 0.005934
2022-01-21 19:56:15,032 iteration 4752 : loss : 0.014142, loss_ce: 0.004793
2022-01-21 19:56:16,413 iteration 4753 : loss : 0.022035, loss_ce: 0.007255
2022-01-21 19:56:17,771 iteration 4754 : loss : 0.015817, loss_ce: 0.005008
2022-01-21 19:56:19,208 iteration 4755 : loss : 0.021351, loss_ce: 0.005731
2022-01-21 19:56:20,511 iteration 4756 : loss : 0.017104, loss_ce: 0.008341
2022-01-21 19:56:21,827 iteration 4757 : loss : 0.024690, loss_ce: 0.010427
2022-01-21 19:56:23,120 iteration 4758 : loss : 0.017332, loss_ce: 0.005629
2022-01-21 19:56:24,447 iteration 4759 : loss : 0.014688, loss_ce: 0.005237
2022-01-21 19:56:24,447 Training Data Eval:
2022-01-21 19:56:30,977   Average segmentation loss on training set: 0.0114
2022-01-21 19:56:30,978 Validation Data Eval:
2022-01-21 19:56:33,207   Average segmentation loss on validation set: 0.0682
2022-01-21 19:56:34,501 iteration 4760 : loss : 0.019948, loss_ce: 0.010222
 70%|████████████████████▎        | 280/400 [1:54:50<51:46, 25.89s/it]2022-01-21 19:56:35,852 iteration 4761 : loss : 0.015798, loss_ce: 0.005216
2022-01-21 19:56:37,213 iteration 4762 : loss : 0.019909, loss_ce: 0.007684
2022-01-21 19:56:38,486 iteration 4763 : loss : 0.015802, loss_ce: 0.006570
2022-01-21 19:56:39,855 iteration 4764 : loss : 0.018594, loss_ce: 0.007135
2022-01-21 19:56:41,163 iteration 4765 : loss : 0.028835, loss_ce: 0.013270
2022-01-21 19:56:42,557 iteration 4766 : loss : 0.022091, loss_ce: 0.007603
2022-01-21 19:56:43,913 iteration 4767 : loss : 0.018591, loss_ce: 0.007197
2022-01-21 19:56:45,200 iteration 4768 : loss : 0.016588, loss_ce: 0.005468
2022-01-21 19:56:46,569 iteration 4769 : loss : 0.023781, loss_ce: 0.009759
2022-01-21 19:56:47,944 iteration 4770 : loss : 0.016150, loss_ce: 0.006112
2022-01-21 19:56:49,214 iteration 4771 : loss : 0.014591, loss_ce: 0.004999
2022-01-21 19:56:50,594 iteration 4772 : loss : 0.021358, loss_ce: 0.009191
2022-01-21 19:56:51,956 iteration 4773 : loss : 0.019236, loss_ce: 0.006721
2022-01-21 19:56:53,312 iteration 4774 : loss : 0.015298, loss_ce: 0.006480
2022-01-21 19:56:54,607 iteration 4775 : loss : 0.041840, loss_ce: 0.011711
2022-01-21 19:56:55,930 iteration 4776 : loss : 0.014440, loss_ce: 0.007378
2022-01-21 19:56:57,391 iteration 4777 : loss : 0.022662, loss_ce: 0.011027
 70%|████████████████████▎        | 281/400 [1:55:12<49:33, 24.99s/it]2022-01-21 19:56:58,692 iteration 4778 : loss : 0.012482, loss_ce: 0.003267
2022-01-21 19:56:59,997 iteration 4779 : loss : 0.022799, loss_ce: 0.007163
2022-01-21 19:57:01,250 iteration 4780 : loss : 0.012553, loss_ce: 0.004189
2022-01-21 19:57:02,552 iteration 4781 : loss : 0.024190, loss_ce: 0.008246
2022-01-21 19:57:03,929 iteration 4782 : loss : 0.019466, loss_ce: 0.009297
2022-01-21 19:57:05,257 iteration 4783 : loss : 0.018334, loss_ce: 0.008061
2022-01-21 19:57:06,524 iteration 4784 : loss : 0.018853, loss_ce: 0.006745
2022-01-21 19:57:07,923 iteration 4785 : loss : 0.019183, loss_ce: 0.006647
2022-01-21 19:57:09,274 iteration 4786 : loss : 0.020387, loss_ce: 0.008751
2022-01-21 19:57:10,628 iteration 4787 : loss : 0.017555, loss_ce: 0.005762
2022-01-21 19:57:11,991 iteration 4788 : loss : 0.019611, loss_ce: 0.006843
2022-01-21 19:57:13,260 iteration 4789 : loss : 0.014815, loss_ce: 0.007088
2022-01-21 19:57:14,683 iteration 4790 : loss : 0.030587, loss_ce: 0.011697
2022-01-21 19:57:16,002 iteration 4791 : loss : 0.018724, loss_ce: 0.008384
2022-01-21 19:57:17,383 iteration 4792 : loss : 0.037247, loss_ce: 0.009744
2022-01-21 19:57:18,672 iteration 4793 : loss : 0.016372, loss_ce: 0.006495
2022-01-21 19:57:19,915 iteration 4794 : loss : 0.023288, loss_ce: 0.005319
 70%|████████████████████▍        | 282/400 [1:55:35<47:41, 24.25s/it]2022-01-21 19:57:21,309 iteration 4795 : loss : 0.021181, loss_ce: 0.006170
2022-01-21 19:57:22,656 iteration 4796 : loss : 0.017567, loss_ce: 0.005327
2022-01-21 19:57:24,010 iteration 4797 : loss : 0.030616, loss_ce: 0.016510
2022-01-21 19:57:25,413 iteration 4798 : loss : 0.030500, loss_ce: 0.009108
2022-01-21 19:57:26,749 iteration 4799 : loss : 0.014313, loss_ce: 0.004658
2022-01-21 19:57:28,087 iteration 4800 : loss : 0.028275, loss_ce: 0.007649
2022-01-21 19:57:29,498 iteration 4801 : loss : 0.017585, loss_ce: 0.007083
2022-01-21 19:57:30,757 iteration 4802 : loss : 0.016171, loss_ce: 0.006436
2022-01-21 19:57:32,064 iteration 4803 : loss : 0.017795, loss_ce: 0.007357
2022-01-21 19:57:33,460 iteration 4804 : loss : 0.050458, loss_ce: 0.008980
2022-01-21 19:57:34,844 iteration 4805 : loss : 0.030514, loss_ce: 0.013203
2022-01-21 19:57:36,243 iteration 4806 : loss : 0.025636, loss_ce: 0.010960
2022-01-21 19:57:37,507 iteration 4807 : loss : 0.018686, loss_ce: 0.007617
2022-01-21 19:57:38,763 iteration 4808 : loss : 0.017785, loss_ce: 0.007303
2022-01-21 19:57:40,133 iteration 4809 : loss : 0.024187, loss_ce: 0.011886
2022-01-21 19:57:41,456 iteration 4810 : loss : 0.029975, loss_ce: 0.008506
2022-01-21 19:57:42,800 iteration 4811 : loss : 0.018736, loss_ce: 0.005940
 71%|████████████████████▌        | 283/400 [1:55:58<46:29, 23.84s/it]2022-01-21 19:57:44,115 iteration 4812 : loss : 0.020872, loss_ce: 0.007690
2022-01-21 19:57:45,463 iteration 4813 : loss : 0.027915, loss_ce: 0.006599
2022-01-21 19:57:46,834 iteration 4814 : loss : 0.024946, loss_ce: 0.006593
2022-01-21 19:57:48,102 iteration 4815 : loss : 0.016085, loss_ce: 0.007191
2022-01-21 19:57:49,541 iteration 4816 : loss : 0.030039, loss_ce: 0.012248
2022-01-21 19:57:50,858 iteration 4817 : loss : 0.019653, loss_ce: 0.007508
2022-01-21 19:57:52,174 iteration 4818 : loss : 0.018838, loss_ce: 0.006656
2022-01-21 19:57:53,415 iteration 4819 : loss : 0.022098, loss_ce: 0.010146
2022-01-21 19:57:54,710 iteration 4820 : loss : 0.020060, loss_ce: 0.007160
2022-01-21 19:57:56,127 iteration 4821 : loss : 0.019909, loss_ce: 0.008511
2022-01-21 19:57:57,535 iteration 4822 : loss : 0.018363, loss_ce: 0.006351
2022-01-21 19:57:58,862 iteration 4823 : loss : 0.019226, loss_ce: 0.007146
2022-01-21 19:58:00,223 iteration 4824 : loss : 0.023525, loss_ce: 0.008523
2022-01-21 19:58:01,527 iteration 4825 : loss : 0.018250, loss_ce: 0.006812
2022-01-21 19:58:02,826 iteration 4826 : loss : 0.021271, loss_ce: 0.005993
2022-01-21 19:58:04,134 iteration 4827 : loss : 0.018627, loss_ce: 0.007090
2022-01-21 19:58:05,427 iteration 4828 : loss : 0.038502, loss_ce: 0.015700
 71%|████████████████████▌        | 284/400 [1:56:21<45:23, 23.48s/it]2022-01-21 19:58:06,743 iteration 4829 : loss : 0.018401, loss_ce: 0.006089
2022-01-21 19:58:08,103 iteration 4830 : loss : 0.019588, loss_ce: 0.008546
2022-01-21 19:58:09,442 iteration 4831 : loss : 0.017084, loss_ce: 0.006565
2022-01-21 19:58:10,800 iteration 4832 : loss : 0.015961, loss_ce: 0.005260
2022-01-21 19:58:12,170 iteration 4833 : loss : 0.024079, loss_ce: 0.009272
2022-01-21 19:58:13,440 iteration 4834 : loss : 0.015627, loss_ce: 0.005158
2022-01-21 19:58:14,879 iteration 4835 : loss : 0.020902, loss_ce: 0.009876
2022-01-21 19:58:16,219 iteration 4836 : loss : 0.018500, loss_ce: 0.005737
2022-01-21 19:58:17,598 iteration 4837 : loss : 0.019369, loss_ce: 0.005372
2022-01-21 19:58:18,907 iteration 4838 : loss : 0.013520, loss_ce: 0.003891
2022-01-21 19:58:20,262 iteration 4839 : loss : 0.025703, loss_ce: 0.009720
2022-01-21 19:58:21,592 iteration 4840 : loss : 0.016900, loss_ce: 0.008069
2022-01-21 19:58:22,851 iteration 4841 : loss : 0.011704, loss_ce: 0.003948
2022-01-21 19:58:24,188 iteration 4842 : loss : 0.017580, loss_ce: 0.006557
2022-01-21 19:58:25,610 iteration 4843 : loss : 0.016779, loss_ce: 0.004960
2022-01-21 19:58:26,943 iteration 4844 : loss : 0.029577, loss_ce: 0.009978
2022-01-21 19:58:26,943 Training Data Eval:
2022-01-21 19:58:33,466   Average segmentation loss on training set: 0.0116
2022-01-21 19:58:33,466 Validation Data Eval:
2022-01-21 19:58:35,705   Average segmentation loss on validation set: 0.0584
2022-01-21 19:58:39,859 Found new lowest validation loss at iteration 4844! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed1234.pth
2022-01-21 19:58:41,143 iteration 4845 : loss : 0.018748, loss_ce: 0.008561
 71%|████████████████████▋        | 285/400 [1:56:56<52:02, 27.15s/it]2022-01-21 19:58:42,368 iteration 4846 : loss : 0.017108, loss_ce: 0.007202
2022-01-21 19:58:43,555 iteration 4847 : loss : 0.018379, loss_ce: 0.007252
2022-01-21 19:58:44,822 iteration 4848 : loss : 0.019195, loss_ce: 0.009332
2022-01-21 19:58:46,102 iteration 4849 : loss : 0.021843, loss_ce: 0.006317
2022-01-21 19:58:47,366 iteration 4850 : loss : 0.017821, loss_ce: 0.005068
2022-01-21 19:58:48,797 iteration 4851 : loss : 0.016328, loss_ce: 0.006336
2022-01-21 19:58:50,120 iteration 4852 : loss : 0.017925, loss_ce: 0.005837
2022-01-21 19:58:51,459 iteration 4853 : loss : 0.019743, loss_ce: 0.009003
2022-01-21 19:58:52,797 iteration 4854 : loss : 0.015115, loss_ce: 0.006470
2022-01-21 19:58:54,098 iteration 4855 : loss : 0.017644, loss_ce: 0.004997
2022-01-21 19:58:55,518 iteration 4856 : loss : 0.021991, loss_ce: 0.008356
2022-01-21 19:58:56,818 iteration 4857 : loss : 0.011994, loss_ce: 0.004534
2022-01-21 19:58:58,225 iteration 4858 : loss : 0.019310, loss_ce: 0.006931
2022-01-21 19:58:59,496 iteration 4859 : loss : 0.011748, loss_ce: 0.004581
2022-01-21 19:59:00,868 iteration 4860 : loss : 0.032251, loss_ce: 0.015393
2022-01-21 19:59:02,171 iteration 4861 : loss : 0.017333, loss_ce: 0.005604
2022-01-21 19:59:03,539 iteration 4862 : loss : 0.016723, loss_ce: 0.007518
 72%|████████████████████▋        | 286/400 [1:57:19<48:52, 25.72s/it]2022-01-21 19:59:04,987 iteration 4863 : loss : 0.023581, loss_ce: 0.006711
2022-01-21 19:59:06,316 iteration 4864 : loss : 0.011808, loss_ce: 0.004127
2022-01-21 19:59:07,624 iteration 4865 : loss : 0.014015, loss_ce: 0.006596
2022-01-21 19:59:09,021 iteration 4866 : loss : 0.017069, loss_ce: 0.005682
2022-01-21 19:59:10,365 iteration 4867 : loss : 0.016947, loss_ce: 0.005772
2022-01-21 19:59:11,598 iteration 4868 : loss : 0.015129, loss_ce: 0.006313
2022-01-21 19:59:13,021 iteration 4869 : loss : 0.022744, loss_ce: 0.010661
2022-01-21 19:59:14,348 iteration 4870 : loss : 0.023953, loss_ce: 0.006982
2022-01-21 19:59:15,779 iteration 4871 : loss : 0.021108, loss_ce: 0.008245
2022-01-21 19:59:17,043 iteration 4872 : loss : 0.012868, loss_ce: 0.003803
2022-01-21 19:59:18,466 iteration 4873 : loss : 0.015142, loss_ce: 0.005753
2022-01-21 19:59:19,823 iteration 4874 : loss : 0.023453, loss_ce: 0.007141
2022-01-21 19:59:21,139 iteration 4875 : loss : 0.018741, loss_ce: 0.007378
2022-01-21 19:59:22,382 iteration 4876 : loss : 0.018149, loss_ce: 0.005436
2022-01-21 19:59:23,761 iteration 4877 : loss : 0.018340, loss_ce: 0.009150
2022-01-21 19:59:25,171 iteration 4878 : loss : 0.030351, loss_ce: 0.008521
2022-01-21 19:59:26,507 iteration 4879 : loss : 0.012191, loss_ce: 0.004323
 72%|████████████████████▊        | 287/400 [1:57:42<46:53, 24.89s/it]2022-01-21 19:59:27,849 iteration 4880 : loss : 0.015337, loss_ce: 0.006165
2022-01-21 19:59:29,122 iteration 4881 : loss : 0.014225, loss_ce: 0.005900
2022-01-21 19:59:30,360 iteration 4882 : loss : 0.014149, loss_ce: 0.005902
2022-01-21 19:59:31,710 iteration 4883 : loss : 0.018921, loss_ce: 0.008530
2022-01-21 19:59:33,077 iteration 4884 : loss : 0.017691, loss_ce: 0.004985
2022-01-21 19:59:34,298 iteration 4885 : loss : 0.012865, loss_ce: 0.004943
2022-01-21 19:59:35,615 iteration 4886 : loss : 0.022694, loss_ce: 0.006024
2022-01-21 19:59:36,879 iteration 4887 : loss : 0.012192, loss_ce: 0.003678
2022-01-21 19:59:38,228 iteration 4888 : loss : 0.016771, loss_ce: 0.004914
2022-01-21 19:59:39,561 iteration 4889 : loss : 0.023935, loss_ce: 0.014342
2022-01-21 19:59:40,846 iteration 4890 : loss : 0.014854, loss_ce: 0.007720
2022-01-21 19:59:42,057 iteration 4891 : loss : 0.011725, loss_ce: 0.004110
2022-01-21 19:59:43,417 iteration 4892 : loss : 0.021670, loss_ce: 0.009381
2022-01-21 19:59:44,744 iteration 4893 : loss : 0.020896, loss_ce: 0.010066
2022-01-21 19:59:46,055 iteration 4894 : loss : 0.013692, loss_ce: 0.006101
2022-01-21 19:59:47,353 iteration 4895 : loss : 0.019703, loss_ce: 0.004151
2022-01-21 19:59:48,631 iteration 4896 : loss : 0.021656, loss_ce: 0.006139
 72%|████████████████████▉        | 288/400 [1:58:04<44:55, 24.07s/it]2022-01-21 19:59:49,960 iteration 4897 : loss : 0.014252, loss_ce: 0.005625
2022-01-21 19:59:51,344 iteration 4898 : loss : 0.026413, loss_ce: 0.013738
2022-01-21 19:59:52,674 iteration 4899 : loss : 0.012973, loss_ce: 0.003913
2022-01-21 19:59:53,959 iteration 4900 : loss : 0.016191, loss_ce: 0.005843
2022-01-21 19:59:55,261 iteration 4901 : loss : 0.026721, loss_ce: 0.007742
2022-01-21 19:59:56,557 iteration 4902 : loss : 0.029334, loss_ce: 0.015007
2022-01-21 19:59:57,901 iteration 4903 : loss : 0.014167, loss_ce: 0.006332
2022-01-21 19:59:59,121 iteration 4904 : loss : 0.013619, loss_ce: 0.004173
2022-01-21 20:00:00,399 iteration 4905 : loss : 0.017672, loss_ce: 0.005138
2022-01-21 20:00:01,752 iteration 4906 : loss : 0.018614, loss_ce: 0.006673
2022-01-21 20:00:03,028 iteration 4907 : loss : 0.019181, loss_ce: 0.006724
2022-01-21 20:00:04,426 iteration 4908 : loss : 0.021358, loss_ce: 0.010027
2022-01-21 20:00:05,779 iteration 4909 : loss : 0.016747, loss_ce: 0.005511
2022-01-21 20:00:07,059 iteration 4910 : loss : 0.015876, loss_ce: 0.007792
2022-01-21 20:00:08,353 iteration 4911 : loss : 0.012279, loss_ce: 0.004361
2022-01-21 20:00:09,677 iteration 4912 : loss : 0.016159, loss_ce: 0.007461
2022-01-21 20:00:10,991 iteration 4913 : loss : 0.025925, loss_ce: 0.009604
 72%|████████████████████▉        | 289/400 [1:58:26<43:34, 23.55s/it]2022-01-21 20:00:12,392 iteration 4914 : loss : 0.018384, loss_ce: 0.006425
2022-01-21 20:00:13,685 iteration 4915 : loss : 0.021953, loss_ce: 0.007910
2022-01-21 20:00:14,979 iteration 4916 : loss : 0.015512, loss_ce: 0.003921
2022-01-21 20:00:16,306 iteration 4917 : loss : 0.018424, loss_ce: 0.005398
2022-01-21 20:00:17,656 iteration 4918 : loss : 0.016491, loss_ce: 0.006128
2022-01-21 20:00:19,128 iteration 4919 : loss : 0.026095, loss_ce: 0.011581
2022-01-21 20:00:20,442 iteration 4920 : loss : 0.015915, loss_ce: 0.006774
2022-01-21 20:00:21,724 iteration 4921 : loss : 0.017915, loss_ce: 0.009767
2022-01-21 20:00:22,979 iteration 4922 : loss : 0.013732, loss_ce: 0.003518
2022-01-21 20:00:24,352 iteration 4923 : loss : 0.020800, loss_ce: 0.008777
2022-01-21 20:00:25,746 iteration 4924 : loss : 0.019395, loss_ce: 0.010217
2022-01-21 20:00:27,095 iteration 4925 : loss : 0.018105, loss_ce: 0.006419
2022-01-21 20:00:28,476 iteration 4926 : loss : 0.017254, loss_ce: 0.007660
2022-01-21 20:00:29,787 iteration 4927 : loss : 0.016503, loss_ce: 0.005167
2022-01-21 20:00:31,172 iteration 4928 : loss : 0.026042, loss_ce: 0.009464
2022-01-21 20:00:32,581 iteration 4929 : loss : 0.022019, loss_ce: 0.009870
2022-01-21 20:00:32,581 Training Data Eval:
2022-01-21 20:00:39,104   Average segmentation loss on training set: 0.0116
2022-01-21 20:00:39,104 Validation Data Eval:
2022-01-21 20:00:41,342   Average segmentation loss on validation set: 0.0606
2022-01-21 20:00:42,675 iteration 4930 : loss : 0.020697, loss_ce: 0.005590
 72%|█████████████████████        | 290/400 [1:58:58<47:39, 25.99s/it]2022-01-21 20:00:44,027 iteration 4931 : loss : 0.014685, loss_ce: 0.006376
2022-01-21 20:00:45,383 iteration 4932 : loss : 0.019594, loss_ce: 0.009945
2022-01-21 20:00:46,651 iteration 4933 : loss : 0.014223, loss_ce: 0.006800
2022-01-21 20:00:48,036 iteration 4934 : loss : 0.025988, loss_ce: 0.007386
2022-01-21 20:00:49,366 iteration 4935 : loss : 0.019538, loss_ce: 0.006638
2022-01-21 20:00:50,721 iteration 4936 : loss : 0.023496, loss_ce: 0.009301
2022-01-21 20:00:52,064 iteration 4937 : loss : 0.016188, loss_ce: 0.007537
2022-01-21 20:00:53,457 iteration 4938 : loss : 0.033185, loss_ce: 0.013750
2022-01-21 20:00:54,839 iteration 4939 : loss : 0.020800, loss_ce: 0.007256
2022-01-21 20:00:56,150 iteration 4940 : loss : 0.019946, loss_ce: 0.008026
2022-01-21 20:00:57,496 iteration 4941 : loss : 0.017748, loss_ce: 0.008508
2022-01-21 20:00:58,842 iteration 4942 : loss : 0.016669, loss_ce: 0.005159
2022-01-21 20:01:00,269 iteration 4943 : loss : 0.027376, loss_ce: 0.006631
2022-01-21 20:01:01,602 iteration 4944 : loss : 0.017310, loss_ce: 0.005602
2022-01-21 20:01:02,974 iteration 4945 : loss : 0.017467, loss_ce: 0.006513
2022-01-21 20:01:04,364 iteration 4946 : loss : 0.027753, loss_ce: 0.009611
2022-01-21 20:01:05,681 iteration 4947 : loss : 0.016942, loss_ce: 0.005210
 73%|█████████████████████        | 291/400 [1:59:21<45:35, 25.10s/it]2022-01-21 20:01:07,075 iteration 4948 : loss : 0.042494, loss_ce: 0.014376
2022-01-21 20:01:08,381 iteration 4949 : loss : 0.024944, loss_ce: 0.011382
2022-01-21 20:01:09,751 iteration 4950 : loss : 0.024267, loss_ce: 0.010361
2022-01-21 20:01:11,113 iteration 4951 : loss : 0.019520, loss_ce: 0.006199
2022-01-21 20:01:12,469 iteration 4952 : loss : 0.014782, loss_ce: 0.008024
2022-01-21 20:01:13,845 iteration 4953 : loss : 0.016838, loss_ce: 0.006117
2022-01-21 20:01:15,158 iteration 4954 : loss : 0.016586, loss_ce: 0.005774
2022-01-21 20:01:16,425 iteration 4955 : loss : 0.027645, loss_ce: 0.008256
2022-01-21 20:01:17,743 iteration 4956 : loss : 0.018178, loss_ce: 0.005467
2022-01-21 20:01:18,985 iteration 4957 : loss : 0.015788, loss_ce: 0.007168
2022-01-21 20:01:20,326 iteration 4958 : loss : 0.022258, loss_ce: 0.010739
2022-01-21 20:01:21,665 iteration 4959 : loss : 0.018813, loss_ce: 0.006549
2022-01-21 20:01:22,920 iteration 4960 : loss : 0.016089, loss_ce: 0.006279
2022-01-21 20:01:24,256 iteration 4961 : loss : 0.017102, loss_ce: 0.006605
2022-01-21 20:01:25,529 iteration 4962 : loss : 0.019248, loss_ce: 0.004197
2022-01-21 20:01:26,834 iteration 4963 : loss : 0.015241, loss_ce: 0.005622
2022-01-21 20:01:28,210 iteration 4964 : loss : 0.026341, loss_ce: 0.011122
 73%|█████████████████████▏       | 292/400 [1:59:43<43:47, 24.33s/it]2022-01-21 20:01:29,656 iteration 4965 : loss : 0.021974, loss_ce: 0.008877
2022-01-21 20:01:31,044 iteration 4966 : loss : 0.036286, loss_ce: 0.017870
2022-01-21 20:01:32,384 iteration 4967 : loss : 0.017501, loss_ce: 0.006909
2022-01-21 20:01:33,743 iteration 4968 : loss : 0.018851, loss_ce: 0.008326
2022-01-21 20:01:35,194 iteration 4969 : loss : 0.031626, loss_ce: 0.011550
2022-01-21 20:01:36,483 iteration 4970 : loss : 0.016589, loss_ce: 0.008198
2022-01-21 20:01:37,790 iteration 4971 : loss : 0.015693, loss_ce: 0.007973
2022-01-21 20:01:39,157 iteration 4972 : loss : 0.023186, loss_ce: 0.009171
2022-01-21 20:01:40,496 iteration 4973 : loss : 0.018062, loss_ce: 0.006322
2022-01-21 20:01:41,952 iteration 4974 : loss : 0.023190, loss_ce: 0.007873
2022-01-21 20:01:43,273 iteration 4975 : loss : 0.019489, loss_ce: 0.006454
2022-01-21 20:01:44,542 iteration 4976 : loss : 0.019274, loss_ce: 0.007108
2022-01-21 20:01:45,902 iteration 4977 : loss : 0.029359, loss_ce: 0.006355
2022-01-21 20:01:47,217 iteration 4978 : loss : 0.017806, loss_ce: 0.004989
2022-01-21 20:01:48,549 iteration 4979 : loss : 0.017666, loss_ce: 0.006603
2022-01-21 20:01:49,891 iteration 4980 : loss : 0.021421, loss_ce: 0.006776
2022-01-21 20:01:51,218 iteration 4981 : loss : 0.019133, loss_ce: 0.007123
 73%|█████████████████████▏       | 293/400 [2:00:06<42:40, 23.93s/it]2022-01-21 20:01:52,568 iteration 4982 : loss : 0.016092, loss_ce: 0.007763
2022-01-21 20:01:53,873 iteration 4983 : loss : 0.018315, loss_ce: 0.008447
2022-01-21 20:01:55,304 iteration 4984 : loss : 0.019808, loss_ce: 0.007521
2022-01-21 20:01:56,567 iteration 4985 : loss : 0.014030, loss_ce: 0.003793
2022-01-21 20:01:57,977 iteration 4986 : loss : 0.029378, loss_ce: 0.012011
2022-01-21 20:01:59,256 iteration 4987 : loss : 0.018294, loss_ce: 0.005597
2022-01-21 20:02:00,598 iteration 4988 : loss : 0.019706, loss_ce: 0.005550
2022-01-21 20:02:01,984 iteration 4989 : loss : 0.023186, loss_ce: 0.009691
2022-01-21 20:02:03,393 iteration 4990 : loss : 0.018064, loss_ce: 0.007331
2022-01-21 20:02:04,742 iteration 4991 : loss : 0.020620, loss_ce: 0.006141
2022-01-21 20:02:05,984 iteration 4992 : loss : 0.013857, loss_ce: 0.006538
2022-01-21 20:02:07,295 iteration 4993 : loss : 0.018783, loss_ce: 0.007019
2022-01-21 20:02:08,571 iteration 4994 : loss : 0.020610, loss_ce: 0.006496
2022-01-21 20:02:09,863 iteration 4995 : loss : 0.016228, loss_ce: 0.006794
2022-01-21 20:02:11,249 iteration 4996 : loss : 0.023001, loss_ce: 0.007592
2022-01-21 20:02:12,507 iteration 4997 : loss : 0.015292, loss_ce: 0.004621
2022-01-21 20:02:13,779 iteration 4998 : loss : 0.016123, loss_ce: 0.006251
 74%|█████████████████████▎       | 294/400 [2:00:29<41:33, 23.52s/it]2022-01-21 20:02:15,114 iteration 4999 : loss : 0.013993, loss_ce: 0.005136
2022-01-21 20:02:16,424 iteration 5000 : loss : 0.019156, loss_ce: 0.008642
2022-01-21 20:02:17,738 iteration 5001 : loss : 0.014426, loss_ce: 0.006339
2022-01-21 20:02:19,045 iteration 5002 : loss : 0.011728, loss_ce: 0.004044
2022-01-21 20:02:20,405 iteration 5003 : loss : 0.025929, loss_ce: 0.007153
2022-01-21 20:02:21,724 iteration 5004 : loss : 0.023046, loss_ce: 0.008855
2022-01-21 20:02:23,046 iteration 5005 : loss : 0.023249, loss_ce: 0.010173
2022-01-21 20:02:24,431 iteration 5006 : loss : 0.016749, loss_ce: 0.006777
2022-01-21 20:02:25,798 iteration 5007 : loss : 0.020078, loss_ce: 0.008482
2022-01-21 20:02:27,172 iteration 5008 : loss : 0.023226, loss_ce: 0.008843
2022-01-21 20:02:28,543 iteration 5009 : loss : 0.015210, loss_ce: 0.003823
2022-01-21 20:02:29,901 iteration 5010 : loss : 0.029087, loss_ce: 0.009389
2022-01-21 20:02:31,212 iteration 5011 : loss : 0.015911, loss_ce: 0.007026
2022-01-21 20:02:32,555 iteration 5012 : loss : 0.020393, loss_ce: 0.008343
2022-01-21 20:02:33,826 iteration 5013 : loss : 0.014091, loss_ce: 0.005445
2022-01-21 20:02:35,145 iteration 5014 : loss : 0.027502, loss_ce: 0.010075
2022-01-21 20:02:35,146 Training Data Eval:
2022-01-21 20:02:41,659   Average segmentation loss on training set: 0.0107
2022-01-21 20:02:41,660 Validation Data Eval:
2022-01-21 20:02:43,896   Average segmentation loss on validation set: 0.0639
2022-01-21 20:02:45,219 iteration 5015 : loss : 0.015765, loss_ce: 0.004643
 74%|█████████████████████▍       | 295/400 [2:01:00<45:18, 25.89s/it]2022-01-21 20:02:46,579 iteration 5016 : loss : 0.018143, loss_ce: 0.008507
2022-01-21 20:02:47,881 iteration 5017 : loss : 0.019805, loss_ce: 0.010017
2022-01-21 20:02:49,198 iteration 5018 : loss : 0.016751, loss_ce: 0.007754
2022-01-21 20:02:50,540 iteration 5019 : loss : 0.015205, loss_ce: 0.005111
2022-01-21 20:02:51,895 iteration 5020 : loss : 0.021355, loss_ce: 0.006196
2022-01-21 20:02:53,275 iteration 5021 : loss : 0.018659, loss_ce: 0.009592
2022-01-21 20:02:54,555 iteration 5022 : loss : 0.014263, loss_ce: 0.004456
2022-01-21 20:02:55,883 iteration 5023 : loss : 0.024605, loss_ce: 0.006934
2022-01-21 20:02:57,308 iteration 5024 : loss : 0.035255, loss_ce: 0.007436
2022-01-21 20:02:58,706 iteration 5025 : loss : 0.024095, loss_ce: 0.004863
2022-01-21 20:03:00,051 iteration 5026 : loss : 0.028391, loss_ce: 0.010029
2022-01-21 20:03:01,352 iteration 5027 : loss : 0.016524, loss_ce: 0.007175
2022-01-21 20:03:02,667 iteration 5028 : loss : 0.020393, loss_ce: 0.007049
2022-01-21 20:03:04,080 iteration 5029 : loss : 0.021534, loss_ce: 0.005743
2022-01-21 20:03:05,410 iteration 5030 : loss : 0.016315, loss_ce: 0.009000
2022-01-21 20:03:06,809 iteration 5031 : loss : 0.020121, loss_ce: 0.009784
2022-01-21 20:03:08,148 iteration 5032 : loss : 0.015395, loss_ce: 0.007181
 74%|█████████████████████▍       | 296/400 [2:01:23<43:20, 25.01s/it]2022-01-21 20:03:09,634 iteration 5033 : loss : 0.033083, loss_ce: 0.014093
2022-01-21 20:03:10,955 iteration 5034 : loss : 0.025311, loss_ce: 0.006835
2022-01-21 20:03:12,254 iteration 5035 : loss : 0.016112, loss_ce: 0.007033
2022-01-21 20:03:13,563 iteration 5036 : loss : 0.020143, loss_ce: 0.007962
2022-01-21 20:03:14,902 iteration 5037 : loss : 0.019862, loss_ce: 0.007691
2022-01-21 20:03:16,203 iteration 5038 : loss : 0.023733, loss_ce: 0.004856
2022-01-21 20:03:17,616 iteration 5039 : loss : 0.021395, loss_ce: 0.010459
2022-01-21 20:03:18,956 iteration 5040 : loss : 0.037845, loss_ce: 0.011119
2022-01-21 20:03:20,352 iteration 5041 : loss : 0.017252, loss_ce: 0.006371
2022-01-21 20:03:21,648 iteration 5042 : loss : 0.013517, loss_ce: 0.005381
2022-01-21 20:03:22,985 iteration 5043 : loss : 0.015134, loss_ce: 0.006780
2022-01-21 20:03:24,324 iteration 5044 : loss : 0.037229, loss_ce: 0.019278
2022-01-21 20:03:25,707 iteration 5045 : loss : 0.018262, loss_ce: 0.007791
2022-01-21 20:03:27,058 iteration 5046 : loss : 0.028611, loss_ce: 0.007719
2022-01-21 20:03:28,374 iteration 5047 : loss : 0.022517, loss_ce: 0.006705
2022-01-21 20:03:29,677 iteration 5048 : loss : 0.020013, loss_ce: 0.007894
2022-01-21 20:03:30,986 iteration 5049 : loss : 0.028534, loss_ce: 0.014741
 74%|█████████████████████▌       | 297/400 [2:01:46<41:48, 24.36s/it]2022-01-21 20:03:32,364 iteration 5050 : loss : 0.018996, loss_ce: 0.005891
2022-01-21 20:03:33,679 iteration 5051 : loss : 0.028857, loss_ce: 0.009706
2022-01-21 20:03:35,000 iteration 5052 : loss : 0.019216, loss_ce: 0.008290
2022-01-21 20:03:36,311 iteration 5053 : loss : 0.015173, loss_ce: 0.005889
2022-01-21 20:03:37,639 iteration 5054 : loss : 0.018457, loss_ce: 0.005425
2022-01-21 20:03:38,949 iteration 5055 : loss : 0.021492, loss_ce: 0.007227
2022-01-21 20:03:40,245 iteration 5056 : loss : 0.023288, loss_ce: 0.005853
2022-01-21 20:03:41,621 iteration 5057 : loss : 0.019151, loss_ce: 0.009659
2022-01-21 20:03:43,021 iteration 5058 : loss : 0.025583, loss_ce: 0.009485
2022-01-21 20:03:44,235 iteration 5059 : loss : 0.032628, loss_ce: 0.006972
2022-01-21 20:03:45,564 iteration 5060 : loss : 0.025756, loss_ce: 0.006857
2022-01-21 20:03:46,923 iteration 5061 : loss : 0.018927, loss_ce: 0.007503
2022-01-21 20:03:48,271 iteration 5062 : loss : 0.022194, loss_ce: 0.007338
2022-01-21 20:03:49,659 iteration 5063 : loss : 0.019653, loss_ce: 0.007241
2022-01-21 20:03:50,956 iteration 5064 : loss : 0.022137, loss_ce: 0.008362
2022-01-21 20:03:52,255 iteration 5065 : loss : 0.017298, loss_ce: 0.006431
2022-01-21 20:03:53,593 iteration 5066 : loss : 0.017765, loss_ce: 0.010012
 74%|█████████████████████▌       | 298/400 [2:02:09<40:30, 23.83s/it]2022-01-21 20:03:55,046 iteration 5067 : loss : 0.019464, loss_ce: 0.008022
2022-01-21 20:03:56,404 iteration 5068 : loss : 0.021928, loss_ce: 0.010793
2022-01-21 20:03:57,756 iteration 5069 : loss : 0.025166, loss_ce: 0.008907
2022-01-21 20:03:59,077 iteration 5070 : loss : 0.016343, loss_ce: 0.004501
2022-01-21 20:04:00,471 iteration 5071 : loss : 0.018324, loss_ce: 0.007717
2022-01-21 20:04:01,690 iteration 5072 : loss : 0.015594, loss_ce: 0.005264
2022-01-21 20:04:03,012 iteration 5073 : loss : 0.018742, loss_ce: 0.010962
2022-01-21 20:04:04,375 iteration 5074 : loss : 0.019209, loss_ce: 0.005787
2022-01-21 20:04:05,709 iteration 5075 : loss : 0.017419, loss_ce: 0.007778
2022-01-21 20:04:07,096 iteration 5076 : loss : 0.015309, loss_ce: 0.006533
2022-01-21 20:04:08,398 iteration 5077 : loss : 0.015667, loss_ce: 0.005336
2022-01-21 20:04:09,739 iteration 5078 : loss : 0.013664, loss_ce: 0.003750
2022-01-21 20:04:11,044 iteration 5079 : loss : 0.016017, loss_ce: 0.005995
2022-01-21 20:04:12,384 iteration 5080 : loss : 0.018708, loss_ce: 0.006226
2022-01-21 20:04:13,750 iteration 5081 : loss : 0.020266, loss_ce: 0.009573
2022-01-21 20:04:15,143 iteration 5082 : loss : 0.029483, loss_ce: 0.013179
2022-01-21 20:04:16,496 iteration 5083 : loss : 0.016627, loss_ce: 0.004989
 75%|█████████████████████▋       | 299/400 [2:02:32<39:38, 23.55s/it]2022-01-21 20:04:17,845 iteration 5084 : loss : 0.019292, loss_ce: 0.007550
2022-01-21 20:04:19,176 iteration 5085 : loss : 0.024295, loss_ce: 0.007945
2022-01-21 20:04:20,477 iteration 5086 : loss : 0.015421, loss_ce: 0.005571
2022-01-21 20:04:21,861 iteration 5087 : loss : 0.026320, loss_ce: 0.014027
2022-01-21 20:04:23,212 iteration 5088 : loss : 0.015956, loss_ce: 0.006047
2022-01-21 20:04:24,500 iteration 5089 : loss : 0.016349, loss_ce: 0.005333
2022-01-21 20:04:25,803 iteration 5090 : loss : 0.019309, loss_ce: 0.006725
2022-01-21 20:04:27,228 iteration 5091 : loss : 0.038565, loss_ce: 0.021986
2022-01-21 20:04:28,565 iteration 5092 : loss : 0.011608, loss_ce: 0.005482
2022-01-21 20:04:29,864 iteration 5093 : loss : 0.015314, loss_ce: 0.006971
2022-01-21 20:04:31,135 iteration 5094 : loss : 0.014143, loss_ce: 0.005317
2022-01-21 20:04:32,508 iteration 5095 : loss : 0.019163, loss_ce: 0.006446
2022-01-21 20:04:33,793 iteration 5096 : loss : 0.013481, loss_ce: 0.005307
2022-01-21 20:04:35,091 iteration 5097 : loss : 0.013922, loss_ce: 0.006081
2022-01-21 20:04:36,438 iteration 5098 : loss : 0.019355, loss_ce: 0.006191
2022-01-21 20:04:37,759 iteration 5099 : loss : 0.014550, loss_ce: 0.004858
2022-01-21 20:04:37,759 Training Data Eval:
2022-01-21 20:04:44,278   Average segmentation loss on training set: 0.0106
2022-01-21 20:04:44,278 Validation Data Eval:
2022-01-21 20:04:46,507   Average segmentation loss on validation set: 0.0704
2022-01-21 20:04:47,825 iteration 5100 : loss : 0.013073, loss_ce: 0.005892
 75%|█████████████████████▊       | 300/400 [2:03:03<43:08, 25.89s/it]2022-01-21 20:04:49,210 iteration 5101 : loss : 0.016440, loss_ce: 0.006913
2022-01-21 20:04:50,508 iteration 5102 : loss : 0.013091, loss_ce: 0.005235
2022-01-21 20:04:51,826 iteration 5103 : loss : 0.015638, loss_ce: 0.006434
2022-01-21 20:04:53,224 iteration 5104 : loss : 0.018298, loss_ce: 0.007618
2022-01-21 20:04:54,501 iteration 5105 : loss : 0.016200, loss_ce: 0.005403
2022-01-21 20:04:55,903 iteration 5106 : loss : 0.016938, loss_ce: 0.006119
2022-01-21 20:04:57,182 iteration 5107 : loss : 0.014649, loss_ce: 0.005648
2022-01-21 20:04:58,540 iteration 5108 : loss : 0.020794, loss_ce: 0.007140
2022-01-21 20:04:59,873 iteration 5109 : loss : 0.030475, loss_ce: 0.009526
2022-01-21 20:05:01,194 iteration 5110 : loss : 0.020306, loss_ce: 0.010570
2022-01-21 20:05:02,565 iteration 5111 : loss : 0.016326, loss_ce: 0.005251
2022-01-21 20:05:03,845 iteration 5112 : loss : 0.015216, loss_ce: 0.004574
2022-01-21 20:05:05,234 iteration 5113 : loss : 0.043263, loss_ce: 0.007420
2022-01-21 20:05:06,549 iteration 5114 : loss : 0.021453, loss_ce: 0.011278
2022-01-21 20:05:07,842 iteration 5115 : loss : 0.016557, loss_ce: 0.004235
2022-01-21 20:05:09,141 iteration 5116 : loss : 0.012874, loss_ce: 0.005336
2022-01-21 20:05:10,529 iteration 5117 : loss : 0.016559, loss_ce: 0.008010
 75%|█████████████████████▊       | 301/400 [2:03:26<41:08, 24.93s/it]2022-01-21 20:05:11,910 iteration 5118 : loss : 0.015074, loss_ce: 0.005910
2022-01-21 20:05:13,252 iteration 5119 : loss : 0.017974, loss_ce: 0.006524
2022-01-21 20:05:14,550 iteration 5120 : loss : 0.031774, loss_ce: 0.009667
2022-01-21 20:05:15,874 iteration 5121 : loss : 0.017136, loss_ce: 0.007793
2022-01-21 20:05:17,159 iteration 5122 : loss : 0.016181, loss_ce: 0.006340
2022-01-21 20:05:18,480 iteration 5123 : loss : 0.025855, loss_ce: 0.007445
2022-01-21 20:05:19,832 iteration 5124 : loss : 0.019771, loss_ce: 0.008732
2022-01-21 20:05:21,069 iteration 5125 : loss : 0.017376, loss_ce: 0.008432
2022-01-21 20:05:22,339 iteration 5126 : loss : 0.018401, loss_ce: 0.005497
2022-01-21 20:05:23,704 iteration 5127 : loss : 0.021262, loss_ce: 0.006888
2022-01-21 20:05:25,004 iteration 5128 : loss : 0.012349, loss_ce: 0.004782
2022-01-21 20:05:26,350 iteration 5129 : loss : 0.017210, loss_ce: 0.004966
2022-01-21 20:05:27,678 iteration 5130 : loss : 0.016995, loss_ce: 0.005191
2022-01-21 20:05:28,923 iteration 5131 : loss : 0.011092, loss_ce: 0.003877
2022-01-21 20:05:30,237 iteration 5132 : loss : 0.015525, loss_ce: 0.006511
2022-01-21 20:05:31,523 iteration 5133 : loss : 0.031997, loss_ce: 0.007758
2022-01-21 20:05:32,792 iteration 5134 : loss : 0.020541, loss_ce: 0.008973
 76%|█████████████████████▉       | 302/400 [2:03:48<39:24, 24.13s/it]2022-01-21 20:05:34,299 iteration 5135 : loss : 0.021519, loss_ce: 0.008201
2022-01-21 20:05:35,625 iteration 5136 : loss : 0.023447, loss_ce: 0.008072
2022-01-21 20:05:37,002 iteration 5137 : loss : 0.018438, loss_ce: 0.006742
2022-01-21 20:05:38,291 iteration 5138 : loss : 0.018594, loss_ce: 0.007854
2022-01-21 20:05:39,622 iteration 5139 : loss : 0.018986, loss_ce: 0.007211
2022-01-21 20:05:41,038 iteration 5140 : loss : 0.017747, loss_ce: 0.007008
2022-01-21 20:05:42,326 iteration 5141 : loss : 0.019315, loss_ce: 0.006488
2022-01-21 20:05:43,667 iteration 5142 : loss : 0.030023, loss_ce: 0.010190
2022-01-21 20:05:44,916 iteration 5143 : loss : 0.014929, loss_ce: 0.005720
2022-01-21 20:05:46,272 iteration 5144 : loss : 0.025898, loss_ce: 0.011936
2022-01-21 20:05:47,520 iteration 5145 : loss : 0.014221, loss_ce: 0.004837
2022-01-21 20:05:48,914 iteration 5146 : loss : 0.025715, loss_ce: 0.009819
2022-01-21 20:05:50,317 iteration 5147 : loss : 0.018701, loss_ce: 0.006559
2022-01-21 20:05:51,627 iteration 5148 : loss : 0.022388, loss_ce: 0.009202
2022-01-21 20:05:52,931 iteration 5149 : loss : 0.035145, loss_ce: 0.009431
2022-01-21 20:05:54,236 iteration 5150 : loss : 0.013536, loss_ce: 0.005398
2022-01-21 20:05:55,576 iteration 5151 : loss : 0.041975, loss_ce: 0.009030
 76%|█████████████████████▉       | 303/400 [2:04:11<38:21, 23.73s/it]2022-01-21 20:05:56,898 iteration 5152 : loss : 0.019156, loss_ce: 0.004028
2022-01-21 20:05:58,133 iteration 5153 : loss : 0.012359, loss_ce: 0.004689
2022-01-21 20:05:59,521 iteration 5154 : loss : 0.019601, loss_ce: 0.008508
2022-01-21 20:06:00,786 iteration 5155 : loss : 0.013523, loss_ce: 0.004716
2022-01-21 20:06:02,095 iteration 5156 : loss : 0.015487, loss_ce: 0.005982
2022-01-21 20:06:03,353 iteration 5157 : loss : 0.014170, loss_ce: 0.004376
2022-01-21 20:06:04,661 iteration 5158 : loss : 0.018916, loss_ce: 0.005844
2022-01-21 20:06:06,039 iteration 5159 : loss : 0.023062, loss_ce: 0.007735
2022-01-21 20:06:07,303 iteration 5160 : loss : 0.012707, loss_ce: 0.004457
2022-01-21 20:06:08,613 iteration 5161 : loss : 0.017098, loss_ce: 0.006164
2022-01-21 20:06:09,879 iteration 5162 : loss : 0.016446, loss_ce: 0.007501
2022-01-21 20:06:11,214 iteration 5163 : loss : 0.015673, loss_ce: 0.006281
2022-01-21 20:06:12,556 iteration 5164 : loss : 0.017728, loss_ce: 0.007941
2022-01-21 20:06:13,813 iteration 5165 : loss : 0.014766, loss_ce: 0.004624
2022-01-21 20:06:15,132 iteration 5166 : loss : 0.014988, loss_ce: 0.006317
2022-01-21 20:06:16,469 iteration 5167 : loss : 0.020949, loss_ce: 0.007626
2022-01-21 20:06:17,845 iteration 5168 : loss : 0.025805, loss_ce: 0.008755
 76%|██████████████████████       | 304/400 [2:04:33<37:15, 23.29s/it]2022-01-21 20:06:19,323 iteration 5169 : loss : 0.027121, loss_ce: 0.012302
2022-01-21 20:06:20,597 iteration 5170 : loss : 0.013717, loss_ce: 0.004299
2022-01-21 20:06:21,978 iteration 5171 : loss : 0.015846, loss_ce: 0.006858
2022-01-21 20:06:23,229 iteration 5172 : loss : 0.016048, loss_ce: 0.005194
2022-01-21 20:06:24,423 iteration 5173 : loss : 0.012009, loss_ce: 0.005113
2022-01-21 20:06:25,812 iteration 5174 : loss : 0.021330, loss_ce: 0.008782
2022-01-21 20:06:27,097 iteration 5175 : loss : 0.016221, loss_ce: 0.007363
2022-01-21 20:06:28,549 iteration 5176 : loss : 0.018331, loss_ce: 0.006432
2022-01-21 20:06:29,835 iteration 5177 : loss : 0.017286, loss_ce: 0.007249
2022-01-21 20:06:31,142 iteration 5178 : loss : 0.014470, loss_ce: 0.004577
2022-01-21 20:06:32,517 iteration 5179 : loss : 0.014506, loss_ce: 0.003983
2022-01-21 20:06:33,839 iteration 5180 : loss : 0.015670, loss_ce: 0.005237
2022-01-21 20:06:35,117 iteration 5181 : loss : 0.011816, loss_ce: 0.002769
2022-01-21 20:06:36,436 iteration 5182 : loss : 0.020872, loss_ce: 0.009779
2022-01-21 20:06:37,734 iteration 5183 : loss : 0.016315, loss_ce: 0.007057
2022-01-21 20:06:39,019 iteration 5184 : loss : 0.018951, loss_ce: 0.006547
2022-01-21 20:06:39,019 Training Data Eval:
2022-01-21 20:06:45,543   Average segmentation loss on training set: 0.0101
2022-01-21 20:06:45,543 Validation Data Eval:
2022-01-21 20:06:47,774   Average segmentation loss on validation set: 0.0660
2022-01-21 20:06:49,081 iteration 5185 : loss : 0.019687, loss_ce: 0.007835
 76%|██████████████████████       | 305/400 [2:05:04<40:39, 25.67s/it]2022-01-21 20:06:50,458 iteration 5186 : loss : 0.014621, loss_ce: 0.006701
2022-01-21 20:06:51,725 iteration 5187 : loss : 0.016456, loss_ce: 0.006543
2022-01-21 20:06:53,030 iteration 5188 : loss : 0.014653, loss_ce: 0.005897
2022-01-21 20:06:54,316 iteration 5189 : loss : 0.015077, loss_ce: 0.006474
2022-01-21 20:06:55,584 iteration 5190 : loss : 0.019973, loss_ce: 0.008302
2022-01-21 20:06:56,954 iteration 5191 : loss : 0.025050, loss_ce: 0.008444
2022-01-21 20:06:58,306 iteration 5192 : loss : 0.017104, loss_ce: 0.005540
2022-01-21 20:06:59,576 iteration 5193 : loss : 0.010653, loss_ce: 0.003538
2022-01-21 20:07:00,926 iteration 5194 : loss : 0.022214, loss_ce: 0.007958
2022-01-21 20:07:02,216 iteration 5195 : loss : 0.014070, loss_ce: 0.004451
2022-01-21 20:07:03,437 iteration 5196 : loss : 0.011556, loss_ce: 0.002672
2022-01-21 20:07:04,692 iteration 5197 : loss : 0.011849, loss_ce: 0.004066
2022-01-21 20:07:05,970 iteration 5198 : loss : 0.016407, loss_ce: 0.009378
2022-01-21 20:07:07,316 iteration 5199 : loss : 0.013343, loss_ce: 0.004456
2022-01-21 20:07:08,630 iteration 5200 : loss : 0.026947, loss_ce: 0.007578
2022-01-21 20:07:09,962 iteration 5201 : loss : 0.014900, loss_ce: 0.004734
2022-01-21 20:07:11,360 iteration 5202 : loss : 0.020210, loss_ce: 0.008779
 76%|██████████████████████▏      | 306/400 [2:05:26<38:37, 24.65s/it]2022-01-21 20:07:12,691 iteration 5203 : loss : 0.013970, loss_ce: 0.005050
2022-01-21 20:07:13,987 iteration 5204 : loss : 0.015968, loss_ce: 0.006545
2022-01-21 20:07:15,432 iteration 5205 : loss : 0.029300, loss_ce: 0.011367
2022-01-21 20:07:16,753 iteration 5206 : loss : 0.019160, loss_ce: 0.006635
2022-01-21 20:07:18,081 iteration 5207 : loss : 0.016862, loss_ce: 0.007559
2022-01-21 20:07:19,477 iteration 5208 : loss : 0.017717, loss_ce: 0.006874
2022-01-21 20:07:20,751 iteration 5209 : loss : 0.014842, loss_ce: 0.005999
2022-01-21 20:07:22,118 iteration 5210 : loss : 0.019537, loss_ce: 0.007410
2022-01-21 20:07:23,461 iteration 5211 : loss : 0.019815, loss_ce: 0.007070
2022-01-21 20:07:24,787 iteration 5212 : loss : 0.018111, loss_ce: 0.006729
2022-01-21 20:07:26,004 iteration 5213 : loss : 0.012105, loss_ce: 0.004409
2022-01-21 20:07:27,419 iteration 5214 : loss : 0.028203, loss_ce: 0.012232
2022-01-21 20:07:28,776 iteration 5215 : loss : 0.017572, loss_ce: 0.005328
2022-01-21 20:07:30,155 iteration 5216 : loss : 0.019478, loss_ce: 0.006428
2022-01-21 20:07:31,569 iteration 5217 : loss : 0.020353, loss_ce: 0.006850
2022-01-21 20:07:32,854 iteration 5218 : loss : 0.019531, loss_ce: 0.003118
2022-01-21 20:07:34,267 iteration 5219 : loss : 0.015103, loss_ce: 0.004649
 77%|██████████████████████▎      | 307/400 [2:05:49<37:24, 24.13s/it]2022-01-21 20:07:35,618 iteration 5220 : loss : 0.019612, loss_ce: 0.005686
2022-01-21 20:07:36,934 iteration 5221 : loss : 0.016083, loss_ce: 0.004875
2022-01-21 20:07:38,200 iteration 5222 : loss : 0.012415, loss_ce: 0.004677
2022-01-21 20:07:39,564 iteration 5223 : loss : 0.017995, loss_ce: 0.006669
2022-01-21 20:07:40,875 iteration 5224 : loss : 0.014032, loss_ce: 0.003864
2022-01-21 20:07:42,251 iteration 5225 : loss : 0.015258, loss_ce: 0.005026
2022-01-21 20:07:43,562 iteration 5226 : loss : 0.021357, loss_ce: 0.007596
2022-01-21 20:07:44,970 iteration 5227 : loss : 0.019073, loss_ce: 0.008524
2022-01-21 20:07:46,261 iteration 5228 : loss : 0.013818, loss_ce: 0.004919
2022-01-21 20:07:47,704 iteration 5229 : loss : 0.021594, loss_ce: 0.010255
2022-01-21 20:07:48,926 iteration 5230 : loss : 0.011461, loss_ce: 0.005017
2022-01-21 20:07:50,271 iteration 5231 : loss : 0.027731, loss_ce: 0.012099
2022-01-21 20:07:51,603 iteration 5232 : loss : 0.017604, loss_ce: 0.005664
2022-01-21 20:07:52,966 iteration 5233 : loss : 0.017918, loss_ce: 0.007222
2022-01-21 20:07:54,260 iteration 5234 : loss : 0.017790, loss_ce: 0.007102
2022-01-21 20:07:55,595 iteration 5235 : loss : 0.016413, loss_ce: 0.005489
2022-01-21 20:07:56,971 iteration 5236 : loss : 0.020020, loss_ce: 0.007971
 77%|██████████████████████▎      | 308/400 [2:06:12<36:20, 23.70s/it]2022-01-21 20:07:58,216 iteration 5237 : loss : 0.012270, loss_ce: 0.005076
2022-01-21 20:07:59,574 iteration 5238 : loss : 0.015562, loss_ce: 0.006304
2022-01-21 20:08:00,919 iteration 5239 : loss : 0.014948, loss_ce: 0.004999
2022-01-21 20:08:02,285 iteration 5240 : loss : 0.173797, loss_ce: 0.004289
2022-01-21 20:08:03,582 iteration 5241 : loss : 0.016401, loss_ce: 0.006965
2022-01-21 20:08:04,906 iteration 5242 : loss : 0.018695, loss_ce: 0.007993
2022-01-21 20:08:06,310 iteration 5243 : loss : 0.023646, loss_ce: 0.008326
2022-01-21 20:08:07,676 iteration 5244 : loss : 0.014452, loss_ce: 0.006177
2022-01-21 20:08:09,014 iteration 5245 : loss : 0.016975, loss_ce: 0.005794
2022-01-21 20:08:10,361 iteration 5246 : loss : 0.019627, loss_ce: 0.004994
2022-01-21 20:08:11,609 iteration 5247 : loss : 0.012306, loss_ce: 0.005044
2022-01-21 20:08:12,973 iteration 5248 : loss : 0.014218, loss_ce: 0.004519
2022-01-21 20:08:14,384 iteration 5249 : loss : 0.025885, loss_ce: 0.008708
2022-01-21 20:08:15,743 iteration 5250 : loss : 0.019563, loss_ce: 0.009371
2022-01-21 20:08:16,995 iteration 5251 : loss : 0.012515, loss_ce: 0.004213
2022-01-21 20:08:18,332 iteration 5252 : loss : 0.014615, loss_ce: 0.005695
2022-01-21 20:08:19,690 iteration 5253 : loss : 0.024478, loss_ce: 0.007143
 77%|██████████████████████▍      | 309/400 [2:06:35<35:30, 23.41s/it]2022-01-21 20:08:21,052 iteration 5254 : loss : 0.011670, loss_ce: 0.003893
2022-01-21 20:08:22,372 iteration 5255 : loss : 0.015828, loss_ce: 0.008390
2022-01-21 20:08:23,635 iteration 5256 : loss : 0.016934, loss_ce: 0.006401
2022-01-21 20:08:24,968 iteration 5257 : loss : 0.016689, loss_ce: 0.006449
2022-01-21 20:08:26,337 iteration 5258 : loss : 0.026638, loss_ce: 0.008338
2022-01-21 20:08:27,612 iteration 5259 : loss : 0.016866, loss_ce: 0.004146
2022-01-21 20:08:28,954 iteration 5260 : loss : 0.015405, loss_ce: 0.005698
2022-01-21 20:08:30,301 iteration 5261 : loss : 0.018352, loss_ce: 0.007572
2022-01-21 20:08:31,630 iteration 5262 : loss : 0.011599, loss_ce: 0.004615
2022-01-21 20:08:32,966 iteration 5263 : loss : 0.015261, loss_ce: 0.005996
2022-01-21 20:08:34,241 iteration 5264 : loss : 0.015129, loss_ce: 0.007685
2022-01-21 20:08:35,607 iteration 5265 : loss : 0.019236, loss_ce: 0.006704
2022-01-21 20:08:37,018 iteration 5266 : loss : 0.019019, loss_ce: 0.006254
2022-01-21 20:08:38,344 iteration 5267 : loss : 0.039825, loss_ce: 0.011151
2022-01-21 20:08:39,691 iteration 5268 : loss : 0.024670, loss_ce: 0.006130
2022-01-21 20:08:41,135 iteration 5269 : loss : 0.032903, loss_ce: 0.012437
2022-01-21 20:08:41,135 Training Data Eval:
2022-01-21 20:08:47,653   Average segmentation loss on training set: 0.0093
2022-01-21 20:08:47,654 Validation Data Eval:
2022-01-21 20:08:49,888   Average segmentation loss on validation set: 0.0682
2022-01-21 20:08:51,207 iteration 5270 : loss : 0.014554, loss_ce: 0.006226
 78%|██████████████████████▍      | 310/400 [2:07:06<38:45, 25.84s/it]2022-01-21 20:08:52,544 iteration 5271 : loss : 0.016010, loss_ce: 0.005817
2022-01-21 20:08:53,896 iteration 5272 : loss : 0.023017, loss_ce: 0.011546
2022-01-21 20:08:55,191 iteration 5273 : loss : 0.012753, loss_ce: 0.003144
2022-01-21 20:08:56,497 iteration 5274 : loss : 0.018769, loss_ce: 0.006676
2022-01-21 20:08:57,746 iteration 5275 : loss : 0.012713, loss_ce: 0.005630
2022-01-21 20:08:59,095 iteration 5276 : loss : 0.024324, loss_ce: 0.012334
2022-01-21 20:09:00,427 iteration 5277 : loss : 0.015675, loss_ce: 0.005731
2022-01-21 20:09:01,674 iteration 5278 : loss : 0.013858, loss_ce: 0.005292
2022-01-21 20:09:02,998 iteration 5279 : loss : 0.017077, loss_ce: 0.007093
2022-01-21 20:09:04,453 iteration 5280 : loss : 0.024652, loss_ce: 0.009523
2022-01-21 20:09:05,761 iteration 5281 : loss : 0.014553, loss_ce: 0.004822
2022-01-21 20:09:07,020 iteration 5282 : loss : 0.011500, loss_ce: 0.003501
2022-01-21 20:09:08,350 iteration 5283 : loss : 0.020989, loss_ce: 0.006768
2022-01-21 20:09:09,695 iteration 5284 : loss : 0.028225, loss_ce: 0.008235
2022-01-21 20:09:11,010 iteration 5285 : loss : 0.014261, loss_ce: 0.006293
2022-01-21 20:09:12,256 iteration 5286 : loss : 0.012895, loss_ce: 0.005555
2022-01-21 20:09:13,562 iteration 5287 : loss : 0.014956, loss_ce: 0.003175
 78%|██████████████████████▌      | 311/400 [2:07:29<36:46, 24.79s/it]2022-01-21 20:09:14,959 iteration 5288 : loss : 0.020144, loss_ce: 0.008054
2022-01-21 20:09:16,317 iteration 5289 : loss : 0.016892, loss_ce: 0.006819
2022-01-21 20:09:17,631 iteration 5290 : loss : 0.054889, loss_ce: 0.012628
2022-01-21 20:09:18,929 iteration 5291 : loss : 0.034765, loss_ce: 0.010396
2022-01-21 20:09:20,292 iteration 5292 : loss : 0.018521, loss_ce: 0.007229
2022-01-21 20:09:21,632 iteration 5293 : loss : 0.018291, loss_ce: 0.007662
2022-01-21 20:09:23,002 iteration 5294 : loss : 0.026637, loss_ce: 0.010473
2022-01-21 20:09:24,423 iteration 5295 : loss : 0.026628, loss_ce: 0.008245
2022-01-21 20:09:25,794 iteration 5296 : loss : 0.024445, loss_ce: 0.006845
2022-01-21 20:09:27,173 iteration 5297 : loss : 0.012912, loss_ce: 0.004609
2022-01-21 20:09:28,548 iteration 5298 : loss : 0.020295, loss_ce: 0.007267
2022-01-21 20:09:29,914 iteration 5299 : loss : 0.015222, loss_ce: 0.005689
2022-01-21 20:09:31,300 iteration 5300 : loss : 0.018726, loss_ce: 0.006205
2022-01-21 20:09:32,566 iteration 5301 : loss : 0.018855, loss_ce: 0.006284
2022-01-21 20:09:33,832 iteration 5302 : loss : 0.013715, loss_ce: 0.006615
2022-01-21 20:09:35,110 iteration 5303 : loss : 0.014357, loss_ce: 0.005519
2022-01-21 20:09:36,365 iteration 5304 : loss : 0.013856, loss_ce: 0.004989
 78%|██████████████████████▌      | 312/400 [2:07:51<35:29, 24.20s/it]2022-01-21 20:09:37,756 iteration 5305 : loss : 0.019636, loss_ce: 0.007134
2022-01-21 20:09:39,185 iteration 5306 : loss : 0.016722, loss_ce: 0.007118
2022-01-21 20:09:40,633 iteration 5307 : loss : 0.024381, loss_ce: 0.008439
2022-01-21 20:09:42,039 iteration 5308 : loss : 0.025577, loss_ce: 0.009110
2022-01-21 20:09:43,431 iteration 5309 : loss : 0.021209, loss_ce: 0.007317
2022-01-21 20:09:44,736 iteration 5310 : loss : 0.014070, loss_ce: 0.006789
2022-01-21 20:09:46,026 iteration 5311 : loss : 0.017871, loss_ce: 0.004832
2022-01-21 20:09:47,412 iteration 5312 : loss : 0.015772, loss_ce: 0.007630
2022-01-21 20:09:48,856 iteration 5313 : loss : 0.024702, loss_ce: 0.006145
2022-01-21 20:09:50,203 iteration 5314 : loss : 0.016159, loss_ce: 0.005572
2022-01-21 20:09:51,598 iteration 5315 : loss : 0.021962, loss_ce: 0.005291
2022-01-21 20:09:52,981 iteration 5316 : loss : 0.031179, loss_ce: 0.013635
2022-01-21 20:09:54,311 iteration 5317 : loss : 0.020488, loss_ce: 0.008643
2022-01-21 20:09:55,609 iteration 5318 : loss : 0.018352, loss_ce: 0.006559
2022-01-21 20:09:56,995 iteration 5319 : loss : 0.016580, loss_ce: 0.006300
2022-01-21 20:09:58,370 iteration 5320 : loss : 0.028536, loss_ce: 0.014787
2022-01-21 20:09:59,762 iteration 5321 : loss : 0.019845, loss_ce: 0.008686
 78%|██████████████████████▋      | 313/400 [2:08:15<34:44, 23.96s/it]2022-01-21 20:10:01,060 iteration 5322 : loss : 0.013056, loss_ce: 0.005735
2022-01-21 20:10:02,405 iteration 5323 : loss : 0.019523, loss_ce: 0.007334
2022-01-21 20:10:03,672 iteration 5324 : loss : 0.017334, loss_ce: 0.006129
2022-01-21 20:10:04,967 iteration 5325 : loss : 0.016021, loss_ce: 0.003989
2022-01-21 20:10:06,331 iteration 5326 : loss : 0.018895, loss_ce: 0.006612
2022-01-21 20:10:07,624 iteration 5327 : loss : 0.017393, loss_ce: 0.005959
2022-01-21 20:10:08,933 iteration 5328 : loss : 0.016573, loss_ce: 0.008574
2022-01-21 20:10:10,308 iteration 5329 : loss : 0.025319, loss_ce: 0.008439
2022-01-21 20:10:11,659 iteration 5330 : loss : 0.027128, loss_ce: 0.010923
2022-01-21 20:10:12,984 iteration 5331 : loss : 0.017430, loss_ce: 0.005060
2022-01-21 20:10:14,321 iteration 5332 : loss : 0.017072, loss_ce: 0.005883
2022-01-21 20:10:15,694 iteration 5333 : loss : 0.016924, loss_ce: 0.008047
2022-01-21 20:10:17,046 iteration 5334 : loss : 0.025212, loss_ce: 0.009190
2022-01-21 20:10:18,420 iteration 5335 : loss : 0.017493, loss_ce: 0.005285
2022-01-21 20:10:19,766 iteration 5336 : loss : 0.015986, loss_ce: 0.006087
2022-01-21 20:10:21,063 iteration 5337 : loss : 0.013465, loss_ce: 0.005149
2022-01-21 20:10:22,359 iteration 5338 : loss : 0.016896, loss_ce: 0.006943
 78%|██████████████████████▊      | 314/400 [2:08:37<33:44, 23.55s/it]2022-01-21 20:10:23,883 iteration 5339 : loss : 0.028321, loss_ce: 0.010613
2022-01-21 20:10:25,267 iteration 5340 : loss : 0.027640, loss_ce: 0.015789
2022-01-21 20:10:26,623 iteration 5341 : loss : 0.026255, loss_ce: 0.004825
2022-01-21 20:10:27,965 iteration 5342 : loss : 0.014511, loss_ce: 0.007547
2022-01-21 20:10:29,271 iteration 5343 : loss : 0.014402, loss_ce: 0.004469
2022-01-21 20:10:30,622 iteration 5344 : loss : 0.018943, loss_ce: 0.006218
2022-01-21 20:10:31,946 iteration 5345 : loss : 0.014124, loss_ce: 0.004888
2022-01-21 20:10:33,309 iteration 5346 : loss : 0.027845, loss_ce: 0.008596
2022-01-21 20:10:34,686 iteration 5347 : loss : 0.014166, loss_ce: 0.004030
2022-01-21 20:10:36,075 iteration 5348 : loss : 0.015684, loss_ce: 0.004124
2022-01-21 20:10:37,422 iteration 5349 : loss : 0.021473, loss_ce: 0.007749
2022-01-21 20:10:38,686 iteration 5350 : loss : 0.012351, loss_ce: 0.004462
2022-01-21 20:10:39,959 iteration 5351 : loss : 0.020990, loss_ce: 0.008234
2022-01-21 20:10:41,331 iteration 5352 : loss : 0.016186, loss_ce: 0.006914
2022-01-21 20:10:42,712 iteration 5353 : loss : 0.012811, loss_ce: 0.004578
2022-01-21 20:10:44,017 iteration 5354 : loss : 0.017689, loss_ce: 0.007621
2022-01-21 20:10:44,017 Training Data Eval:
2022-01-21 20:10:50,543   Average segmentation loss on training set: 0.0114
2022-01-21 20:10:50,544 Validation Data Eval:
2022-01-21 20:10:52,783   Average segmentation loss on validation set: 0.0654
2022-01-21 20:10:54,054 iteration 5355 : loss : 0.018375, loss_ce: 0.006848
 79%|██████████████████████▊      | 315/400 [2:09:09<36:49, 25.99s/it]2022-01-21 20:10:55,434 iteration 5356 : loss : 0.015966, loss_ce: 0.006887
2022-01-21 20:10:56,696 iteration 5357 : loss : 0.019828, loss_ce: 0.004311
2022-01-21 20:10:58,156 iteration 5358 : loss : 0.026798, loss_ce: 0.011555
2022-01-21 20:10:59,419 iteration 5359 : loss : 0.012578, loss_ce: 0.004695
2022-01-21 20:11:00,770 iteration 5360 : loss : 0.016587, loss_ce: 0.006542
2022-01-21 20:11:02,116 iteration 5361 : loss : 0.023830, loss_ce: 0.007939
2022-01-21 20:11:03,485 iteration 5362 : loss : 0.017347, loss_ce: 0.005238
2022-01-21 20:11:04,822 iteration 5363 : loss : 0.015270, loss_ce: 0.006295
2022-01-21 20:11:06,158 iteration 5364 : loss : 0.022407, loss_ce: 0.004546
2022-01-21 20:11:07,475 iteration 5365 : loss : 0.014313, loss_ce: 0.005408
2022-01-21 20:11:08,827 iteration 5366 : loss : 0.017474, loss_ce: 0.006610
2022-01-21 20:11:10,205 iteration 5367 : loss : 0.012532, loss_ce: 0.005088
2022-01-21 20:11:11,520 iteration 5368 : loss : 0.011800, loss_ce: 0.005121
2022-01-21 20:11:12,868 iteration 5369 : loss : 0.012339, loss_ce: 0.004310
2022-01-21 20:11:14,188 iteration 5370 : loss : 0.013688, loss_ce: 0.005350
2022-01-21 20:11:15,533 iteration 5371 : loss : 0.013350, loss_ce: 0.006746
2022-01-21 20:11:16,838 iteration 5372 : loss : 0.016331, loss_ce: 0.005082
 79%|██████████████████████▉      | 316/400 [2:09:32<35:02, 25.03s/it]2022-01-21 20:11:18,216 iteration 5373 : loss : 0.014278, loss_ce: 0.006579
2022-01-21 20:11:19,513 iteration 5374 : loss : 0.017542, loss_ce: 0.007289
2022-01-21 20:11:20,868 iteration 5375 : loss : 0.012368, loss_ce: 0.003816
2022-01-21 20:11:22,177 iteration 5376 : loss : 0.014964, loss_ce: 0.005217
2022-01-21 20:11:23,472 iteration 5377 : loss : 0.012650, loss_ce: 0.003871
2022-01-21 20:11:24,805 iteration 5378 : loss : 0.017395, loss_ce: 0.005288
2022-01-21 20:11:26,068 iteration 5379 : loss : 0.009741, loss_ce: 0.003438
2022-01-21 20:11:27,400 iteration 5380 : loss : 0.023085, loss_ce: 0.010118
2022-01-21 20:11:28,700 iteration 5381 : loss : 0.014615, loss_ce: 0.006016
2022-01-21 20:11:30,053 iteration 5382 : loss : 0.011884, loss_ce: 0.003380
2022-01-21 20:11:31,468 iteration 5383 : loss : 0.019316, loss_ce: 0.009427
2022-01-21 20:11:32,954 iteration 5384 : loss : 0.018937, loss_ce: 0.006599
2022-01-21 20:11:34,267 iteration 5385 : loss : 0.014168, loss_ce: 0.005563
2022-01-21 20:11:35,520 iteration 5386 : loss : 0.012711, loss_ce: 0.004225
2022-01-21 20:11:36,824 iteration 5387 : loss : 0.018405, loss_ce: 0.007880
2022-01-21 20:11:38,201 iteration 5388 : loss : 0.013504, loss_ce: 0.004448
2022-01-21 20:11:39,645 iteration 5389 : loss : 0.034033, loss_ce: 0.009491
 79%|██████████████████████▉      | 317/400 [2:09:55<33:42, 24.36s/it]2022-01-21 20:11:40,998 iteration 5390 : loss : 0.016781, loss_ce: 0.004772
2022-01-21 20:11:42,377 iteration 5391 : loss : 0.015931, loss_ce: 0.005349
2022-01-21 20:11:43,766 iteration 5392 : loss : 0.016919, loss_ce: 0.008525
2022-01-21 20:11:45,104 iteration 5393 : loss : 0.021925, loss_ce: 0.010379
2022-01-21 20:11:46,408 iteration 5394 : loss : 0.017228, loss_ce: 0.007440
2022-01-21 20:11:47,764 iteration 5395 : loss : 0.015873, loss_ce: 0.004663
2022-01-21 20:11:49,048 iteration 5396 : loss : 0.015317, loss_ce: 0.007590
2022-01-21 20:11:50,439 iteration 5397 : loss : 0.021149, loss_ce: 0.006774
2022-01-21 20:11:51,789 iteration 5398 : loss : 0.015995, loss_ce: 0.006173
2022-01-21 20:11:53,054 iteration 5399 : loss : 0.020445, loss_ce: 0.005736
2022-01-21 20:11:54,470 iteration 5400 : loss : 0.029895, loss_ce: 0.008432
2022-01-21 20:11:55,840 iteration 5401 : loss : 0.016120, loss_ce: 0.007134
2022-01-21 20:11:57,182 iteration 5402 : loss : 0.021301, loss_ce: 0.007069
2022-01-21 20:11:58,484 iteration 5403 : loss : 0.019017, loss_ce: 0.007966
2022-01-21 20:11:59,771 iteration 5404 : loss : 0.013919, loss_ce: 0.003677
2022-01-21 20:12:01,072 iteration 5405 : loss : 0.016944, loss_ce: 0.006838
2022-01-21 20:12:02,449 iteration 5406 : loss : 0.018165, loss_ce: 0.006583
 80%|███████████████████████      | 318/400 [2:10:18<32:39, 23.89s/it]2022-01-21 20:12:03,857 iteration 5407 : loss : 0.017345, loss_ce: 0.006331
2022-01-21 20:12:05,189 iteration 5408 : loss : 0.029579, loss_ce: 0.009296
2022-01-21 20:12:06,597 iteration 5409 : loss : 0.021677, loss_ce: 0.009615
2022-01-21 20:12:07,895 iteration 5410 : loss : 0.014576, loss_ce: 0.006240
2022-01-21 20:12:09,225 iteration 5411 : loss : 0.018456, loss_ce: 0.007873
2022-01-21 20:12:10,568 iteration 5412 : loss : 0.020264, loss_ce: 0.009813
2022-01-21 20:12:11,878 iteration 5413 : loss : 0.015531, loss_ce: 0.007880
2022-01-21 20:12:13,221 iteration 5414 : loss : 0.016191, loss_ce: 0.006461
2022-01-21 20:12:14,635 iteration 5415 : loss : 0.023471, loss_ce: 0.009572
2022-01-21 20:12:15,909 iteration 5416 : loss : 0.009760, loss_ce: 0.003277
2022-01-21 20:12:17,274 iteration 5417 : loss : 0.013629, loss_ce: 0.004751
2022-01-21 20:12:18,591 iteration 5418 : loss : 0.019443, loss_ce: 0.007633
2022-01-21 20:12:19,953 iteration 5419 : loss : 0.023443, loss_ce: 0.005202
2022-01-21 20:12:21,349 iteration 5420 : loss : 0.018350, loss_ce: 0.007901
2022-01-21 20:12:22,703 iteration 5421 : loss : 0.021591, loss_ce: 0.009526
2022-01-21 20:12:23,919 iteration 5422 : loss : 0.010156, loss_ce: 0.004290
2022-01-21 20:12:25,283 iteration 5423 : loss : 0.027620, loss_ce: 0.006281
 80%|███████████████████████▏     | 319/400 [2:10:40<31:49, 23.58s/it]2022-01-21 20:12:26,720 iteration 5424 : loss : 0.021227, loss_ce: 0.007219
2022-01-21 20:12:28,023 iteration 5425 : loss : 0.013964, loss_ce: 0.004656
2022-01-21 20:12:29,346 iteration 5426 : loss : 0.019326, loss_ce: 0.005986
2022-01-21 20:12:30,588 iteration 5427 : loss : 0.018120, loss_ce: 0.006440
2022-01-21 20:12:31,887 iteration 5428 : loss : 0.016135, loss_ce: 0.006299
2022-01-21 20:12:33,233 iteration 5429 : loss : 0.011869, loss_ce: 0.004121
2022-01-21 20:12:34,570 iteration 5430 : loss : 0.021333, loss_ce: 0.013151
2022-01-21 20:12:35,838 iteration 5431 : loss : 0.014750, loss_ce: 0.005389
2022-01-21 20:12:37,232 iteration 5432 : loss : 0.020665, loss_ce: 0.010744
2022-01-21 20:12:38,618 iteration 5433 : loss : 0.018263, loss_ce: 0.007079
2022-01-21 20:12:39,898 iteration 5434 : loss : 0.019903, loss_ce: 0.008953
2022-01-21 20:12:41,300 iteration 5435 : loss : 0.017283, loss_ce: 0.006679
2022-01-21 20:12:42,659 iteration 5436 : loss : 0.012931, loss_ce: 0.004552
2022-01-21 20:12:44,036 iteration 5437 : loss : 0.026218, loss_ce: 0.007358
2022-01-21 20:12:45,412 iteration 5438 : loss : 0.014944, loss_ce: 0.006681
2022-01-21 20:12:46,730 iteration 5439 : loss : 0.029219, loss_ce: 0.013962
2022-01-21 20:12:46,730 Training Data Eval:
2022-01-21 20:12:53,256   Average segmentation loss on training set: 0.0109
2022-01-21 20:12:53,256 Validation Data Eval:
2022-01-21 20:12:55,490   Average segmentation loss on validation set: 0.0706
2022-01-21 20:12:56,764 iteration 5440 : loss : 0.015670, loss_ce: 0.004595
 80%|███████████████████████▏     | 320/400 [2:11:12<34:35, 25.95s/it]2022-01-21 20:12:58,106 iteration 5441 : loss : 0.012571, loss_ce: 0.004190
2022-01-21 20:12:59,380 iteration 5442 : loss : 0.014096, loss_ce: 0.004623
2022-01-21 20:13:00,693 iteration 5443 : loss : 0.015465, loss_ce: 0.005105
2022-01-21 20:13:01,939 iteration 5444 : loss : 0.014052, loss_ce: 0.004429
2022-01-21 20:13:03,276 iteration 5445 : loss : 0.019302, loss_ce: 0.007954
2022-01-21 20:13:04,558 iteration 5446 : loss : 0.017679, loss_ce: 0.007926
2022-01-21 20:13:05,968 iteration 5447 : loss : 0.045053, loss_ce: 0.013191
2022-01-21 20:13:07,247 iteration 5448 : loss : 0.016619, loss_ce: 0.006949
2022-01-21 20:13:08,586 iteration 5449 : loss : 0.018549, loss_ce: 0.009674
2022-01-21 20:13:09,910 iteration 5450 : loss : 0.018431, loss_ce: 0.007537
2022-01-21 20:13:11,178 iteration 5451 : loss : 0.014212, loss_ce: 0.004939
2022-01-21 20:13:12,512 iteration 5452 : loss : 0.018288, loss_ce: 0.006709
2022-01-21 20:13:13,791 iteration 5453 : loss : 0.017107, loss_ce: 0.006960
2022-01-21 20:13:15,171 iteration 5454 : loss : 0.026409, loss_ce: 0.012780
2022-01-21 20:13:16,523 iteration 5455 : loss : 0.019141, loss_ce: 0.006838
2022-01-21 20:13:17,856 iteration 5456 : loss : 0.011188, loss_ce: 0.002717
2022-01-21 20:13:19,137 iteration 5457 : loss : 0.013119, loss_ce: 0.004034
 80%|███████████████████████▎     | 321/400 [2:11:34<32:45, 24.88s/it]2022-01-21 20:13:20,485 iteration 5458 : loss : 0.019588, loss_ce: 0.006473
2022-01-21 20:13:21,752 iteration 5459 : loss : 0.014817, loss_ce: 0.006520
2022-01-21 20:13:23,076 iteration 5460 : loss : 0.014281, loss_ce: 0.005614
2022-01-21 20:13:24,393 iteration 5461 : loss : 0.017753, loss_ce: 0.007052
2022-01-21 20:13:25,702 iteration 5462 : loss : 0.014601, loss_ce: 0.005500
2022-01-21 20:13:27,040 iteration 5463 : loss : 0.019823, loss_ce: 0.005515
2022-01-21 20:13:28,374 iteration 5464 : loss : 0.016648, loss_ce: 0.006994
2022-01-21 20:13:29,771 iteration 5465 : loss : 0.018274, loss_ce: 0.006984
2022-01-21 20:13:31,159 iteration 5466 : loss : 0.016665, loss_ce: 0.005753
2022-01-21 20:13:32,516 iteration 5467 : loss : 0.021564, loss_ce: 0.010162
2022-01-21 20:13:33,867 iteration 5468 : loss : 0.015370, loss_ce: 0.006553
2022-01-21 20:13:35,128 iteration 5469 : loss : 0.013481, loss_ce: 0.004920
2022-01-21 20:13:36,440 iteration 5470 : loss : 0.009083, loss_ce: 0.003373
2022-01-21 20:13:37,757 iteration 5471 : loss : 0.015377, loss_ce: 0.003720
2022-01-21 20:13:39,107 iteration 5472 : loss : 0.019583, loss_ce: 0.006880
2022-01-21 20:13:40,381 iteration 5473 : loss : 0.012764, loss_ce: 0.004384
2022-01-21 20:13:41,658 iteration 5474 : loss : 0.014118, loss_ce: 0.004681
 80%|███████████████████████▎     | 322/400 [2:11:57<31:25, 24.17s/it]2022-01-21 20:13:43,042 iteration 5475 : loss : 0.018699, loss_ce: 0.004867
2022-01-21 20:13:44,424 iteration 5476 : loss : 0.016322, loss_ce: 0.007291
2022-01-21 20:13:45,750 iteration 5477 : loss : 0.029600, loss_ce: 0.004242
2022-01-21 20:13:46,998 iteration 5478 : loss : 0.015763, loss_ce: 0.004825
2022-01-21 20:13:48,313 iteration 5479 : loss : 0.014188, loss_ce: 0.006249
2022-01-21 20:13:49,625 iteration 5480 : loss : 0.019634, loss_ce: 0.006604
2022-01-21 20:13:50,918 iteration 5481 : loss : 0.016310, loss_ce: 0.005856
2022-01-21 20:13:52,336 iteration 5482 : loss : 0.029070, loss_ce: 0.008107
2022-01-21 20:13:53,580 iteration 5483 : loss : 0.011311, loss_ce: 0.004380
2022-01-21 20:13:54,928 iteration 5484 : loss : 0.020572, loss_ce: 0.007840
2022-01-21 20:13:56,248 iteration 5485 : loss : 0.023504, loss_ce: 0.013610
2022-01-21 20:13:57,566 iteration 5486 : loss : 0.016592, loss_ce: 0.007380
2022-01-21 20:13:58,907 iteration 5487 : loss : 0.014868, loss_ce: 0.005730
2022-01-21 20:14:00,197 iteration 5488 : loss : 0.013791, loss_ce: 0.006091
2022-01-21 20:14:01,476 iteration 5489 : loss : 0.018684, loss_ce: 0.009931
2022-01-21 20:14:02,875 iteration 5490 : loss : 0.024003, loss_ce: 0.008717
2022-01-21 20:14:04,171 iteration 5491 : loss : 0.017146, loss_ce: 0.005809
 81%|███████████████████████▍     | 323/400 [2:12:19<30:22, 23.67s/it]2022-01-21 20:14:05,448 iteration 5492 : loss : 0.016185, loss_ce: 0.006033
2022-01-21 20:14:06,801 iteration 5493 : loss : 0.023448, loss_ce: 0.007472
2022-01-21 20:14:08,081 iteration 5494 : loss : 0.021691, loss_ce: 0.008068
2022-01-21 20:14:09,418 iteration 5495 : loss : 0.013964, loss_ce: 0.004339
2022-01-21 20:14:10,758 iteration 5496 : loss : 0.030593, loss_ce: 0.008076
2022-01-21 20:14:12,101 iteration 5497 : loss : 0.013512, loss_ce: 0.004951
2022-01-21 20:14:13,471 iteration 5498 : loss : 0.025321, loss_ce: 0.010875
2022-01-21 20:14:14,828 iteration 5499 : loss : 0.019655, loss_ce: 0.010428
2022-01-21 20:14:16,091 iteration 5500 : loss : 0.015984, loss_ce: 0.006754
2022-01-21 20:14:17,424 iteration 5501 : loss : 0.019430, loss_ce: 0.007763
2022-01-21 20:14:18,709 iteration 5502 : loss : 0.010625, loss_ce: 0.004404
2022-01-21 20:14:20,032 iteration 5503 : loss : 0.014921, loss_ce: 0.003835
2022-01-21 20:14:21,321 iteration 5504 : loss : 0.024428, loss_ce: 0.009091
2022-01-21 20:14:22,640 iteration 5505 : loss : 0.014733, loss_ce: 0.006078
2022-01-21 20:14:24,001 iteration 5506 : loss : 0.016385, loss_ce: 0.005947
2022-01-21 20:14:25,317 iteration 5507 : loss : 0.018009, loss_ce: 0.008260
2022-01-21 20:14:26,647 iteration 5508 : loss : 0.017850, loss_ce: 0.006935
 81%|███████████████████████▍     | 324/400 [2:12:42<29:31, 23.32s/it]2022-01-21 20:14:28,015 iteration 5509 : loss : 0.021825, loss_ce: 0.005942
2022-01-21 20:14:29,429 iteration 5510 : loss : 0.021801, loss_ce: 0.007688
2022-01-21 20:14:30,738 iteration 5511 : loss : 0.014264, loss_ce: 0.005543
2022-01-21 20:14:32,117 iteration 5512 : loss : 0.019059, loss_ce: 0.007506
2022-01-21 20:14:33,419 iteration 5513 : loss : 0.012810, loss_ce: 0.005351
2022-01-21 20:14:34,677 iteration 5514 : loss : 0.012037, loss_ce: 0.004134
2022-01-21 20:14:36,058 iteration 5515 : loss : 0.025511, loss_ce: 0.005357
2022-01-21 20:14:37,360 iteration 5516 : loss : 0.014867, loss_ce: 0.006197
2022-01-21 20:14:38,691 iteration 5517 : loss : 0.013417, loss_ce: 0.005837
2022-01-21 20:14:40,022 iteration 5518 : loss : 0.016655, loss_ce: 0.005749
2022-01-21 20:14:41,369 iteration 5519 : loss : 0.024983, loss_ce: 0.009453
2022-01-21 20:14:42,699 iteration 5520 : loss : 0.015414, loss_ce: 0.006208
2022-01-21 20:14:44,046 iteration 5521 : loss : 0.026370, loss_ce: 0.011251
2022-01-21 20:14:45,373 iteration 5522 : loss : 0.019803, loss_ce: 0.006985
2022-01-21 20:14:46,667 iteration 5523 : loss : 0.010580, loss_ce: 0.003882
2022-01-21 20:14:47,969 iteration 5524 : loss : 0.019346, loss_ce: 0.007831
2022-01-21 20:14:47,969 Training Data Eval:
2022-01-21 20:14:54,495   Average segmentation loss on training set: 0.0097
2022-01-21 20:14:54,496 Validation Data Eval:
2022-01-21 20:14:56,730   Average segmentation loss on validation set: 0.0693
2022-01-21 20:14:58,046 iteration 5525 : loss : 0.019615, loss_ce: 0.009818
 81%|███████████████████████▌     | 325/400 [2:13:13<32:10, 25.74s/it]2022-01-21 20:14:59,455 iteration 5526 : loss : 0.023099, loss_ce: 0.007289
2022-01-21 20:15:00,789 iteration 5527 : loss : 0.017494, loss_ce: 0.007624
2022-01-21 20:15:02,111 iteration 5528 : loss : 0.022156, loss_ce: 0.007887
2022-01-21 20:15:03,470 iteration 5529 : loss : 0.027896, loss_ce: 0.011013
2022-01-21 20:15:04,741 iteration 5530 : loss : 0.013859, loss_ce: 0.006414
2022-01-21 20:15:06,036 iteration 5531 : loss : 0.020012, loss_ce: 0.009875
2022-01-21 20:15:07,320 iteration 5532 : loss : 0.011573, loss_ce: 0.004709
2022-01-21 20:15:08,698 iteration 5533 : loss : 0.015062, loss_ce: 0.004021
2022-01-21 20:15:10,017 iteration 5534 : loss : 0.016610, loss_ce: 0.005718
2022-01-21 20:15:11,405 iteration 5535 : loss : 0.020708, loss_ce: 0.007852
2022-01-21 20:15:12,828 iteration 5536 : loss : 0.013464, loss_ce: 0.005538
2022-01-21 20:15:14,195 iteration 5537 : loss : 0.039216, loss_ce: 0.008667
2022-01-21 20:15:15,535 iteration 5538 : loss : 0.017784, loss_ce: 0.006836
2022-01-21 20:15:16,959 iteration 5539 : loss : 0.017952, loss_ce: 0.004156
2022-01-21 20:15:18,257 iteration 5540 : loss : 0.020353, loss_ce: 0.010156
2022-01-21 20:15:19,595 iteration 5541 : loss : 0.020029, loss_ce: 0.006139
2022-01-21 20:15:20,903 iteration 5542 : loss : 0.014434, loss_ce: 0.005046
 82%|███████████████████████▋     | 326/400 [2:13:36<30:40, 24.87s/it]2022-01-21 20:15:22,299 iteration 5543 : loss : 0.020791, loss_ce: 0.007465
2022-01-21 20:15:23,636 iteration 5544 : loss : 0.014633, loss_ce: 0.005725
2022-01-21 20:15:24,942 iteration 5545 : loss : 0.020058, loss_ce: 0.007162
2022-01-21 20:15:26,220 iteration 5546 : loss : 0.014644, loss_ce: 0.005178
2022-01-21 20:15:27,546 iteration 5547 : loss : 0.016959, loss_ce: 0.006662
2022-01-21 20:15:28,931 iteration 5548 : loss : 0.022823, loss_ce: 0.007559
2022-01-21 20:15:30,199 iteration 5549 : loss : 0.017489, loss_ce: 0.007291
2022-01-21 20:15:31,501 iteration 5550 : loss : 0.014840, loss_ce: 0.005085
2022-01-21 20:15:32,824 iteration 5551 : loss : 0.016444, loss_ce: 0.006852
2022-01-21 20:15:34,092 iteration 5552 : loss : 0.012907, loss_ce: 0.004939
2022-01-21 20:15:35,433 iteration 5553 : loss : 0.025129, loss_ce: 0.010694
2022-01-21 20:15:36,808 iteration 5554 : loss : 0.012126, loss_ce: 0.004122
2022-01-21 20:15:38,175 iteration 5555 : loss : 0.029793, loss_ce: 0.008839
2022-01-21 20:15:39,432 iteration 5556 : loss : 0.015401, loss_ce: 0.005584
2022-01-21 20:15:40,821 iteration 5557 : loss : 0.021928, loss_ce: 0.006525
2022-01-21 20:15:42,160 iteration 5558 : loss : 0.015685, loss_ce: 0.005022
2022-01-21 20:15:43,400 iteration 5559 : loss : 0.016903, loss_ce: 0.008316
 82%|███████████████████████▋     | 327/400 [2:13:58<29:23, 24.16s/it]2022-01-21 20:15:44,936 iteration 5560 : loss : 0.022960, loss_ce: 0.007717
2022-01-21 20:15:46,253 iteration 5561 : loss : 0.018291, loss_ce: 0.006173
2022-01-21 20:15:47,572 iteration 5562 : loss : 0.017176, loss_ce: 0.005330
2022-01-21 20:15:48,892 iteration 5563 : loss : 0.013818, loss_ce: 0.006002
2022-01-21 20:15:50,311 iteration 5564 : loss : 0.020890, loss_ce: 0.007597
2022-01-21 20:15:51,647 iteration 5565 : loss : 0.013970, loss_ce: 0.005954
2022-01-21 20:15:53,015 iteration 5566 : loss : 0.013420, loss_ce: 0.006607
2022-01-21 20:15:54,441 iteration 5567 : loss : 0.017740, loss_ce: 0.009098
2022-01-21 20:15:55,796 iteration 5568 : loss : 0.020555, loss_ce: 0.007280
2022-01-21 20:15:57,171 iteration 5569 : loss : 0.015676, loss_ce: 0.007421
2022-01-21 20:15:58,521 iteration 5570 : loss : 0.012746, loss_ce: 0.004421
2022-01-21 20:15:59,896 iteration 5571 : loss : 0.015374, loss_ce: 0.006249
2022-01-21 20:16:01,226 iteration 5572 : loss : 0.012491, loss_ce: 0.004784
2022-01-21 20:16:02,547 iteration 5573 : loss : 0.016496, loss_ce: 0.004824
2022-01-21 20:16:03,981 iteration 5574 : loss : 0.015184, loss_ce: 0.004696
2022-01-21 20:16:05,207 iteration 5575 : loss : 0.010575, loss_ce: 0.004574
2022-01-21 20:16:06,411 iteration 5576 : loss : 0.012926, loss_ce: 0.004014
 82%|███████████████████████▊     | 328/400 [2:14:21<28:34, 23.82s/it]2022-01-21 20:16:07,771 iteration 5577 : loss : 0.014003, loss_ce: 0.004897
2022-01-21 20:16:09,062 iteration 5578 : loss : 0.014167, loss_ce: 0.003262
2022-01-21 20:16:10,380 iteration 5579 : loss : 0.011349, loss_ce: 0.003396
2022-01-21 20:16:11,752 iteration 5580 : loss : 0.011339, loss_ce: 0.004065
2022-01-21 20:16:13,063 iteration 5581 : loss : 0.013206, loss_ce: 0.004874
2022-01-21 20:16:14,423 iteration 5582 : loss : 0.016238, loss_ce: 0.004740
2022-01-21 20:16:15,733 iteration 5583 : loss : 0.022255, loss_ce: 0.005661
2022-01-21 20:16:17,151 iteration 5584 : loss : 0.029660, loss_ce: 0.012498
2022-01-21 20:16:18,461 iteration 5585 : loss : 0.020913, loss_ce: 0.008164
2022-01-21 20:16:19,798 iteration 5586 : loss : 0.017144, loss_ce: 0.007462
2022-01-21 20:16:21,128 iteration 5587 : loss : 0.020781, loss_ce: 0.009805
2022-01-21 20:16:22,529 iteration 5588 : loss : 0.018094, loss_ce: 0.005848
2022-01-21 20:16:23,913 iteration 5589 : loss : 0.019246, loss_ce: 0.007321
2022-01-21 20:16:25,255 iteration 5590 : loss : 0.022154, loss_ce: 0.008574
2022-01-21 20:16:26,587 iteration 5591 : loss : 0.014065, loss_ce: 0.005709
2022-01-21 20:16:27,905 iteration 5592 : loss : 0.014774, loss_ce: 0.005105
2022-01-21 20:16:29,217 iteration 5593 : loss : 0.015095, loss_ce: 0.008365
 82%|███████████████████████▊     | 329/400 [2:14:44<27:49, 23.51s/it]2022-01-21 20:16:30,613 iteration 5594 : loss : 0.014943, loss_ce: 0.005421
2022-01-21 20:16:31,918 iteration 5595 : loss : 0.014055, loss_ce: 0.006288
2022-01-21 20:16:33,225 iteration 5596 : loss : 0.013986, loss_ce: 0.004431
2022-01-21 20:16:34,569 iteration 5597 : loss : 0.019718, loss_ce: 0.006610
2022-01-21 20:16:35,968 iteration 5598 : loss : 0.017519, loss_ce: 0.007153
2022-01-21 20:16:37,346 iteration 5599 : loss : 0.016106, loss_ce: 0.006009
2022-01-21 20:16:38,717 iteration 5600 : loss : 0.014455, loss_ce: 0.006147
2022-01-21 20:16:40,090 iteration 5601 : loss : 0.018802, loss_ce: 0.006187
2022-01-21 20:16:41,389 iteration 5602 : loss : 0.016785, loss_ce: 0.004706
2022-01-21 20:16:42,763 iteration 5603 : loss : 0.018659, loss_ce: 0.008095
2022-01-21 20:16:44,062 iteration 5604 : loss : 0.015092, loss_ce: 0.007364
2022-01-21 20:16:45,365 iteration 5605 : loss : 0.014242, loss_ce: 0.004561
2022-01-21 20:16:46,765 iteration 5606 : loss : 0.019661, loss_ce: 0.006278
2022-01-21 20:16:48,095 iteration 5607 : loss : 0.017758, loss_ce: 0.006536
2022-01-21 20:16:49,545 iteration 5608 : loss : 0.017531, loss_ce: 0.008772
2022-01-21 20:16:50,843 iteration 5609 : loss : 0.017233, loss_ce: 0.008753
2022-01-21 20:16:50,844 Training Data Eval:
2022-01-21 20:16:57,369   Average segmentation loss on training set: 0.0099
2022-01-21 20:16:57,369 Validation Data Eval:
2022-01-21 20:16:59,600   Average segmentation loss on validation set: 0.0671
2022-01-21 20:17:00,953 iteration 5610 : loss : 0.018329, loss_ce: 0.008998
 82%|███████████████████████▉     | 330/400 [2:15:16<30:18, 25.98s/it]2022-01-21 20:17:02,367 iteration 5611 : loss : 0.021334, loss_ce: 0.012737
2022-01-21 20:17:03,706 iteration 5612 : loss : 0.017867, loss_ce: 0.006425
2022-01-21 20:17:05,025 iteration 5613 : loss : 0.023860, loss_ce: 0.009878
2022-01-21 20:17:06,344 iteration 5614 : loss : 0.023880, loss_ce: 0.007512
2022-01-21 20:17:07,701 iteration 5615 : loss : 0.017558, loss_ce: 0.006116
2022-01-21 20:17:09,074 iteration 5616 : loss : 0.019511, loss_ce: 0.007314
2022-01-21 20:17:10,416 iteration 5617 : loss : 0.012386, loss_ce: 0.004644
2022-01-21 20:17:11,693 iteration 5618 : loss : 0.014556, loss_ce: 0.006290
2022-01-21 20:17:13,062 iteration 5619 : loss : 0.022706, loss_ce: 0.006961
2022-01-21 20:17:14,447 iteration 5620 : loss : 0.020257, loss_ce: 0.005542
2022-01-21 20:17:15,748 iteration 5621 : loss : 0.016175, loss_ce: 0.006098
2022-01-21 20:17:17,160 iteration 5622 : loss : 0.018073, loss_ce: 0.007611
2022-01-21 20:17:18,453 iteration 5623 : loss : 0.018418, loss_ce: 0.005656
2022-01-21 20:17:19,808 iteration 5624 : loss : 0.019938, loss_ce: 0.008840
2022-01-21 20:17:21,183 iteration 5625 : loss : 0.019689, loss_ce: 0.007956
2022-01-21 20:17:22,518 iteration 5626 : loss : 0.016596, loss_ce: 0.006426
2022-01-21 20:17:23,842 iteration 5627 : loss : 0.019738, loss_ce: 0.006442
 83%|███████████████████████▉     | 331/400 [2:15:39<28:48, 25.05s/it]2022-01-21 20:17:25,111 iteration 5628 : loss : 0.012700, loss_ce: 0.004623
2022-01-21 20:17:26,465 iteration 5629 : loss : 0.020586, loss_ce: 0.009930
2022-01-21 20:17:27,793 iteration 5630 : loss : 0.016544, loss_ce: 0.006467
2022-01-21 20:17:29,226 iteration 5631 : loss : 0.024860, loss_ce: 0.012402
2022-01-21 20:17:30,483 iteration 5632 : loss : 0.016521, loss_ce: 0.007129
2022-01-21 20:17:31,863 iteration 5633 : loss : 0.021897, loss_ce: 0.009392
2022-01-21 20:17:33,148 iteration 5634 : loss : 0.022554, loss_ce: 0.006340
2022-01-21 20:17:34,502 iteration 5635 : loss : 0.014853, loss_ce: 0.003745
2022-01-21 20:17:35,774 iteration 5636 : loss : 0.011260, loss_ce: 0.004635
2022-01-21 20:17:37,123 iteration 5637 : loss : 0.031411, loss_ce: 0.014868
2022-01-21 20:17:38,345 iteration 5638 : loss : 0.014689, loss_ce: 0.004231
2022-01-21 20:17:39,615 iteration 5639 : loss : 0.019643, loss_ce: 0.005304
2022-01-21 20:17:40,923 iteration 5640 : loss : 0.014961, loss_ce: 0.007119
2022-01-21 20:17:42,288 iteration 5641 : loss : 0.014583, loss_ce: 0.007939
2022-01-21 20:17:43,597 iteration 5642 : loss : 0.021776, loss_ce: 0.004137
2022-01-21 20:17:44,972 iteration 5643 : loss : 0.016269, loss_ce: 0.004991
2022-01-21 20:17:46,327 iteration 5644 : loss : 0.016360, loss_ce: 0.006517
 83%|████████████████████████     | 332/400 [2:16:01<27:31, 24.28s/it]2022-01-21 20:17:47,797 iteration 5645 : loss : 0.032109, loss_ce: 0.013131
2022-01-21 20:17:49,096 iteration 5646 : loss : 0.018265, loss_ce: 0.006429
2022-01-21 20:17:50,428 iteration 5647 : loss : 0.020357, loss_ce: 0.009558
2022-01-21 20:17:51,805 iteration 5648 : loss : 0.020787, loss_ce: 0.006347
2022-01-21 20:17:53,179 iteration 5649 : loss : 0.019277, loss_ce: 0.008757
2022-01-21 20:17:54,522 iteration 5650 : loss : 0.015848, loss_ce: 0.006291
2022-01-21 20:17:55,847 iteration 5651 : loss : 0.023894, loss_ce: 0.011864
2022-01-21 20:17:57,104 iteration 5652 : loss : 0.013978, loss_ce: 0.005102
2022-01-21 20:17:58,416 iteration 5653 : loss : 0.014408, loss_ce: 0.004638
2022-01-21 20:17:59,685 iteration 5654 : loss : 0.012471, loss_ce: 0.003457
2022-01-21 20:18:01,037 iteration 5655 : loss : 0.020336, loss_ce: 0.008943
2022-01-21 20:18:02,360 iteration 5656 : loss : 0.014322, loss_ce: 0.004959
2022-01-21 20:18:03,688 iteration 5657 : loss : 0.018814, loss_ce: 0.008176
2022-01-21 20:18:05,019 iteration 5658 : loss : 0.021258, loss_ce: 0.011569
2022-01-21 20:18:06,325 iteration 5659 : loss : 0.013700, loss_ce: 0.003686
2022-01-21 20:18:07,593 iteration 5660 : loss : 0.015350, loss_ce: 0.006908
2022-01-21 20:18:09,008 iteration 5661 : loss : 0.016963, loss_ce: 0.005084
 83%|████████████████████████▏    | 333/400 [2:16:24<26:34, 23.80s/it]2022-01-21 20:18:10,379 iteration 5662 : loss : 0.016700, loss_ce: 0.004163
2022-01-21 20:18:11,710 iteration 5663 : loss : 0.015895, loss_ce: 0.006181
2022-01-21 20:18:13,061 iteration 5664 : loss : 0.031842, loss_ce: 0.008785
2022-01-21 20:18:14,308 iteration 5665 : loss : 0.015018, loss_ce: 0.005689
2022-01-21 20:18:15,664 iteration 5666 : loss : 0.015870, loss_ce: 0.006764
2022-01-21 20:18:17,040 iteration 5667 : loss : 0.015285, loss_ce: 0.005683
2022-01-21 20:18:18,364 iteration 5668 : loss : 0.012738, loss_ce: 0.005729
2022-01-21 20:18:19,737 iteration 5669 : loss : 0.023319, loss_ce: 0.011646
2022-01-21 20:18:21,086 iteration 5670 : loss : 0.013581, loss_ce: 0.004748
2022-01-21 20:18:22,429 iteration 5671 : loss : 0.013308, loss_ce: 0.004731
2022-01-21 20:18:23,757 iteration 5672 : loss : 0.020599, loss_ce: 0.005423
2022-01-21 20:18:25,050 iteration 5673 : loss : 0.013548, loss_ce: 0.003984
2022-01-21 20:18:26,452 iteration 5674 : loss : 0.017168, loss_ce: 0.008425
2022-01-21 20:18:27,757 iteration 5675 : loss : 0.016594, loss_ce: 0.007530
2022-01-21 20:18:29,151 iteration 5676 : loss : 0.016858, loss_ce: 0.006440
2022-01-21 20:18:30,523 iteration 5677 : loss : 0.013276, loss_ce: 0.006679
2022-01-21 20:18:31,870 iteration 5678 : loss : 0.018386, loss_ce: 0.005882
 84%|████████████████████████▏    | 334/400 [2:16:47<25:52, 23.52s/it]2022-01-21 20:18:33,253 iteration 5679 : loss : 0.017153, loss_ce: 0.008132
2022-01-21 20:18:34,482 iteration 5680 : loss : 0.011703, loss_ce: 0.002966
2022-01-21 20:18:35,858 iteration 5681 : loss : 0.029018, loss_ce: 0.010110
2022-01-21 20:18:37,246 iteration 5682 : loss : 0.019778, loss_ce: 0.008493
2022-01-21 20:18:38,545 iteration 5683 : loss : 0.012751, loss_ce: 0.004148
2022-01-21 20:18:39,830 iteration 5684 : loss : 0.012302, loss_ce: 0.006219
2022-01-21 20:18:41,181 iteration 5685 : loss : 0.018342, loss_ce: 0.008379
2022-01-21 20:18:42,489 iteration 5686 : loss : 0.014930, loss_ce: 0.005376
2022-01-21 20:18:43,813 iteration 5687 : loss : 0.014881, loss_ce: 0.006159
2022-01-21 20:18:45,234 iteration 5688 : loss : 0.021825, loss_ce: 0.007875
2022-01-21 20:18:46,569 iteration 5689 : loss : 0.022350, loss_ce: 0.006149
2022-01-21 20:18:47,914 iteration 5690 : loss : 0.016919, loss_ce: 0.007200
2022-01-21 20:18:49,279 iteration 5691 : loss : 0.017829, loss_ce: 0.007727
2022-01-21 20:18:50,636 iteration 5692 : loss : 0.018746, loss_ce: 0.008418
2022-01-21 20:18:51,974 iteration 5693 : loss : 0.020379, loss_ce: 0.005346
2022-01-21 20:18:53,288 iteration 5694 : loss : 0.019326, loss_ce: 0.008392
2022-01-21 20:18:53,288 Training Data Eval:
2022-01-21 20:18:59,808   Average segmentation loss on training set: 0.0094
2022-01-21 20:18:59,809 Validation Data Eval:
2022-01-21 20:19:02,042   Average segmentation loss on validation set: 0.0618
2022-01-21 20:19:03,321 iteration 5695 : loss : 0.011844, loss_ce: 0.004012
 84%|████████████████████████▎    | 335/400 [2:17:18<28:03, 25.90s/it]2022-01-21 20:19:04,640 iteration 5696 : loss : 0.010871, loss_ce: 0.005344
2022-01-21 20:19:05,911 iteration 5697 : loss : 0.012879, loss_ce: 0.005626
2022-01-21 20:19:07,281 iteration 5698 : loss : 0.021282, loss_ce: 0.008153
2022-01-21 20:19:08,532 iteration 5699 : loss : 0.013249, loss_ce: 0.005612
2022-01-21 20:19:09,829 iteration 5700 : loss : 0.014053, loss_ce: 0.005035
2022-01-21 20:19:11,096 iteration 5701 : loss : 0.014560, loss_ce: 0.006221
2022-01-21 20:19:12,520 iteration 5702 : loss : 0.018562, loss_ce: 0.007706
2022-01-21 20:19:13,879 iteration 5703 : loss : 0.020076, loss_ce: 0.008524
2022-01-21 20:19:15,224 iteration 5704 : loss : 0.017005, loss_ce: 0.006268
2022-01-21 20:19:16,579 iteration 5705 : loss : 0.021621, loss_ce: 0.007939
2022-01-21 20:19:17,817 iteration 5706 : loss : 0.012434, loss_ce: 0.004693
2022-01-21 20:19:19,124 iteration 5707 : loss : 0.014547, loss_ce: 0.004690
2022-01-21 20:19:20,400 iteration 5708 : loss : 0.014055, loss_ce: 0.004964
2022-01-21 20:19:21,732 iteration 5709 : loss : 0.024380, loss_ce: 0.006764
2022-01-21 20:19:23,051 iteration 5710 : loss : 0.021927, loss_ce: 0.007113
2022-01-21 20:19:24,308 iteration 5711 : loss : 0.015159, loss_ce: 0.004734
2022-01-21 20:19:25,647 iteration 5712 : loss : 0.020349, loss_ce: 0.008124
 84%|████████████████████████▎    | 336/400 [2:17:41<26:29, 24.83s/it]2022-01-21 20:19:27,055 iteration 5713 : loss : 0.018626, loss_ce: 0.006707
2022-01-21 20:19:28,430 iteration 5714 : loss : 0.026177, loss_ce: 0.012172
2022-01-21 20:19:29,817 iteration 5715 : loss : 0.015539, loss_ce: 0.005984
2022-01-21 20:19:31,128 iteration 5716 : loss : 0.015294, loss_ce: 0.006441
2022-01-21 20:19:32,546 iteration 5717 : loss : 0.016933, loss_ce: 0.007334
2022-01-21 20:19:33,824 iteration 5718 : loss : 0.011679, loss_ce: 0.003789
2022-01-21 20:19:35,102 iteration 5719 : loss : 0.013059, loss_ce: 0.005478
2022-01-21 20:19:36,475 iteration 5720 : loss : 0.018042, loss_ce: 0.007228
2022-01-21 20:19:37,816 iteration 5721 : loss : 0.019368, loss_ce: 0.010727
2022-01-21 20:19:39,139 iteration 5722 : loss : 0.015089, loss_ce: 0.006110
2022-01-21 20:19:40,480 iteration 5723 : loss : 0.017041, loss_ce: 0.005872
2022-01-21 20:19:41,851 iteration 5724 : loss : 0.020220, loss_ce: 0.007422
2022-01-21 20:19:43,184 iteration 5725 : loss : 0.015513, loss_ce: 0.005874
2022-01-21 20:19:44,464 iteration 5726 : loss : 0.014765, loss_ce: 0.003848
2022-01-21 20:19:45,808 iteration 5727 : loss : 0.016067, loss_ce: 0.004872
2022-01-21 20:19:47,114 iteration 5728 : loss : 0.019386, loss_ce: 0.006058
2022-01-21 20:19:48,511 iteration 5729 : loss : 0.014925, loss_ce: 0.005947
 84%|████████████████████████▍    | 337/400 [2:18:04<25:27, 24.24s/it]2022-01-21 20:19:49,831 iteration 5730 : loss : 0.012845, loss_ce: 0.005783
2022-01-21 20:19:51,205 iteration 5731 : loss : 0.017176, loss_ce: 0.007730
2022-01-21 20:19:52,489 iteration 5732 : loss : 0.011227, loss_ce: 0.004335
2022-01-21 20:19:53,875 iteration 5733 : loss : 0.030387, loss_ce: 0.008267
2022-01-21 20:19:55,252 iteration 5734 : loss : 0.015204, loss_ce: 0.005866
2022-01-21 20:19:56,553 iteration 5735 : loss : 0.014010, loss_ce: 0.004337
2022-01-21 20:19:57,850 iteration 5736 : loss : 0.021412, loss_ce: 0.008181
2022-01-21 20:19:59,250 iteration 5737 : loss : 0.019006, loss_ce: 0.006417
2022-01-21 20:20:00,544 iteration 5738 : loss : 0.012064, loss_ce: 0.004179
2022-01-21 20:20:01,837 iteration 5739 : loss : 0.011756, loss_ce: 0.004347
2022-01-21 20:20:03,160 iteration 5740 : loss : 0.026057, loss_ce: 0.012406
2022-01-21 20:20:04,487 iteration 5741 : loss : 0.017511, loss_ce: 0.007956
2022-01-21 20:20:05,830 iteration 5742 : loss : 0.013886, loss_ce: 0.002731
2022-01-21 20:20:07,187 iteration 5743 : loss : 0.011186, loss_ce: 0.004589
2022-01-21 20:20:08,577 iteration 5744 : loss : 0.027565, loss_ce: 0.012131
2022-01-21 20:20:09,965 iteration 5745 : loss : 0.017940, loss_ce: 0.007069
2022-01-21 20:20:11,260 iteration 5746 : loss : 0.013536, loss_ce: 0.003357
 84%|████████████████████████▌    | 338/400 [2:18:26<24:35, 23.79s/it]2022-01-21 20:20:12,633 iteration 5747 : loss : 0.016609, loss_ce: 0.005541
2022-01-21 20:20:13,985 iteration 5748 : loss : 0.022984, loss_ce: 0.008307
2022-01-21 20:20:15,320 iteration 5749 : loss : 0.021116, loss_ce: 0.008145
2022-01-21 20:20:16,649 iteration 5750 : loss : 0.016391, loss_ce: 0.005550
2022-01-21 20:20:17,918 iteration 5751 : loss : 0.017748, loss_ce: 0.006431
2022-01-21 20:20:19,224 iteration 5752 : loss : 0.014953, loss_ce: 0.004517
2022-01-21 20:20:20,593 iteration 5753 : loss : 0.012788, loss_ce: 0.004698
2022-01-21 20:20:21,978 iteration 5754 : loss : 0.013927, loss_ce: 0.004377
2022-01-21 20:20:23,308 iteration 5755 : loss : 0.027507, loss_ce: 0.008510
2022-01-21 20:20:24,608 iteration 5756 : loss : 0.014696, loss_ce: 0.004983
2022-01-21 20:20:25,830 iteration 5757 : loss : 0.010856, loss_ce: 0.004452
2022-01-21 20:20:27,209 iteration 5758 : loss : 0.018942, loss_ce: 0.007326
2022-01-21 20:20:28,583 iteration 5759 : loss : 0.014782, loss_ce: 0.006390
2022-01-21 20:20:29,999 iteration 5760 : loss : 0.015453, loss_ce: 0.008073
2022-01-21 20:20:31,429 iteration 5761 : loss : 0.019868, loss_ce: 0.007273
2022-01-21 20:20:32,709 iteration 5762 : loss : 0.015881, loss_ce: 0.008460
2022-01-21 20:20:34,076 iteration 5763 : loss : 0.011403, loss_ce: 0.004642
 85%|████████████████████████▌    | 339/400 [2:18:49<23:53, 23.50s/it]2022-01-21 20:20:35,449 iteration 5764 : loss : 0.013049, loss_ce: 0.004403
2022-01-21 20:20:36,843 iteration 5765 : loss : 0.039746, loss_ce: 0.007016
2022-01-21 20:20:38,202 iteration 5766 : loss : 0.019273, loss_ce: 0.009886
2022-01-21 20:20:39,534 iteration 5767 : loss : 0.015936, loss_ce: 0.009186
2022-01-21 20:20:40,969 iteration 5768 : loss : 0.016505, loss_ce: 0.005565
2022-01-21 20:20:42,354 iteration 5769 : loss : 0.016951, loss_ce: 0.005063
2022-01-21 20:20:43,650 iteration 5770 : loss : 0.013565, loss_ce: 0.004731
2022-01-21 20:20:45,005 iteration 5771 : loss : 0.019615, loss_ce: 0.008232
2022-01-21 20:20:46,330 iteration 5772 : loss : 0.013812, loss_ce: 0.004852
2022-01-21 20:20:47,592 iteration 5773 : loss : 0.010778, loss_ce: 0.004014
2022-01-21 20:20:48,835 iteration 5774 : loss : 0.016355, loss_ce: 0.004723
2022-01-21 20:20:50,181 iteration 5775 : loss : 0.014644, loss_ce: 0.005859
2022-01-21 20:20:51,588 iteration 5776 : loss : 0.017639, loss_ce: 0.008103
2022-01-21 20:20:52,835 iteration 5777 : loss : 0.014744, loss_ce: 0.006138
2022-01-21 20:20:54,136 iteration 5778 : loss : 0.016822, loss_ce: 0.005114
2022-01-21 20:20:55,445 iteration 5779 : loss : 0.010451, loss_ce: 0.003562
2022-01-21 20:20:55,445 Training Data Eval:
2022-01-21 20:21:01,975   Average segmentation loss on training set: 0.0086
2022-01-21 20:21:01,975 Validation Data Eval:
2022-01-21 20:21:04,208   Average segmentation loss on validation set: 0.0620
2022-01-21 20:21:05,526 iteration 5780 : loss : 0.016140, loss_ce: 0.005507
 85%|████████████████████████▋    | 340/400 [2:19:21<25:53, 25.89s/it]2022-01-21 20:21:06,862 iteration 5781 : loss : 0.022444, loss_ce: 0.005765
2022-01-21 20:21:08,251 iteration 5782 : loss : 0.017941, loss_ce: 0.006989
2022-01-21 20:21:09,572 iteration 5783 : loss : 0.018261, loss_ce: 0.006455
2022-01-21 20:21:10,922 iteration 5784 : loss : 0.013702, loss_ce: 0.007113
2022-01-21 20:21:12,208 iteration 5785 : loss : 0.010988, loss_ce: 0.003792
2022-01-21 20:21:13,504 iteration 5786 : loss : 0.013104, loss_ce: 0.006114
2022-01-21 20:21:14,798 iteration 5787 : loss : 0.012899, loss_ce: 0.004756
2022-01-21 20:21:16,255 iteration 5788 : loss : 0.013110, loss_ce: 0.005403
2022-01-21 20:21:17,601 iteration 5789 : loss : 0.016221, loss_ce: 0.007828
2022-01-21 20:21:18,935 iteration 5790 : loss : 0.013509, loss_ce: 0.004646
2022-01-21 20:21:20,219 iteration 5791 : loss : 0.012198, loss_ce: 0.004275
2022-01-21 20:21:21,575 iteration 5792 : loss : 0.019870, loss_ce: 0.007064
2022-01-21 20:21:23,019 iteration 5793 : loss : 0.020087, loss_ce: 0.007581
2022-01-21 20:21:24,365 iteration 5794 : loss : 0.013737, loss_ce: 0.005257
2022-01-21 20:21:25,689 iteration 5795 : loss : 0.015340, loss_ce: 0.005121
2022-01-21 20:21:26,975 iteration 5796 : loss : 0.011397, loss_ce: 0.003196
2022-01-21 20:21:28,330 iteration 5797 : loss : 0.023702, loss_ce: 0.009421
 85%|████████████████████████▋    | 341/400 [2:19:43<24:32, 24.96s/it]2022-01-21 20:21:29,735 iteration 5798 : loss : 0.015668, loss_ce: 0.006364
2022-01-21 20:21:31,088 iteration 5799 : loss : 0.014592, loss_ce: 0.005419
2022-01-21 20:21:32,408 iteration 5800 : loss : 0.014694, loss_ce: 0.006258
2022-01-21 20:21:33,727 iteration 5801 : loss : 0.016587, loss_ce: 0.005855
2022-01-21 20:21:34,993 iteration 5802 : loss : 0.011985, loss_ce: 0.005424
2022-01-21 20:21:36,291 iteration 5803 : loss : 0.013130, loss_ce: 0.006213
2022-01-21 20:21:37,615 iteration 5804 : loss : 0.013872, loss_ce: 0.005369
2022-01-21 20:21:39,030 iteration 5805 : loss : 0.015524, loss_ce: 0.005321
2022-01-21 20:21:40,344 iteration 5806 : loss : 0.017037, loss_ce: 0.005327
2022-01-21 20:21:41,754 iteration 5807 : loss : 0.028312, loss_ce: 0.010712
2022-01-21 20:21:43,109 iteration 5808 : loss : 0.020038, loss_ce: 0.008858
2022-01-21 20:21:44,381 iteration 5809 : loss : 0.013189, loss_ce: 0.003502
2022-01-21 20:21:45,673 iteration 5810 : loss : 0.016115, loss_ce: 0.005560
2022-01-21 20:21:46,932 iteration 5811 : loss : 0.010207, loss_ce: 0.003092
2022-01-21 20:21:48,259 iteration 5812 : loss : 0.014159, loss_ce: 0.004837
2022-01-21 20:21:49,521 iteration 5813 : loss : 0.016145, loss_ce: 0.008086
2022-01-21 20:21:50,864 iteration 5814 : loss : 0.016536, loss_ce: 0.007813
 86%|████████████████████████▊    | 342/400 [2:20:06<23:25, 24.23s/it]2022-01-21 20:21:52,164 iteration 5815 : loss : 0.010602, loss_ce: 0.003273
2022-01-21 20:21:53,469 iteration 5816 : loss : 0.012258, loss_ce: 0.005676
2022-01-21 20:21:54,763 iteration 5817 : loss : 0.012668, loss_ce: 0.004565
2022-01-21 20:21:55,995 iteration 5818 : loss : 0.013065, loss_ce: 0.005350
2022-01-21 20:21:57,372 iteration 5819 : loss : 0.014261, loss_ce: 0.004752
2022-01-21 20:21:58,773 iteration 5820 : loss : 0.016935, loss_ce: 0.008170
2022-01-21 20:22:00,031 iteration 5821 : loss : 0.012863, loss_ce: 0.004169
2022-01-21 20:22:01,316 iteration 5822 : loss : 0.009438, loss_ce: 0.004255
2022-01-21 20:22:02,741 iteration 5823 : loss : 0.015671, loss_ce: 0.006407
2022-01-21 20:22:04,068 iteration 5824 : loss : 0.014752, loss_ce: 0.004009
2022-01-21 20:22:05,445 iteration 5825 : loss : 0.016371, loss_ce: 0.006092
2022-01-21 20:22:06,814 iteration 5826 : loss : 0.016601, loss_ce: 0.004139
2022-01-21 20:22:08,144 iteration 5827 : loss : 0.016543, loss_ce: 0.005218
2022-01-21 20:22:09,571 iteration 5828 : loss : 0.035076, loss_ce: 0.018934
2022-01-21 20:22:10,893 iteration 5829 : loss : 0.012320, loss_ce: 0.004821
2022-01-21 20:22:12,187 iteration 5830 : loss : 0.019907, loss_ce: 0.007839
2022-01-21 20:22:13,494 iteration 5831 : loss : 0.014669, loss_ce: 0.005270
 86%|████████████████████████▊    | 343/400 [2:20:29<22:33, 23.75s/it]2022-01-21 20:22:14,861 iteration 5832 : loss : 0.011859, loss_ce: 0.003440
2022-01-21 20:22:16,224 iteration 5833 : loss : 0.016011, loss_ce: 0.007401
2022-01-21 20:22:17,494 iteration 5834 : loss : 0.011558, loss_ce: 0.003999
2022-01-21 20:22:18,769 iteration 5835 : loss : 0.024778, loss_ce: 0.007721
2022-01-21 20:22:20,141 iteration 5836 : loss : 0.016696, loss_ce: 0.008273
2022-01-21 20:22:21,467 iteration 5837 : loss : 0.013905, loss_ce: 0.003066
2022-01-21 20:22:22,702 iteration 5838 : loss : 0.010080, loss_ce: 0.002982
2022-01-21 20:22:24,016 iteration 5839 : loss : 0.012250, loss_ce: 0.004292
2022-01-21 20:22:25,379 iteration 5840 : loss : 0.016345, loss_ce: 0.005927
2022-01-21 20:22:26,676 iteration 5841 : loss : 0.016083, loss_ce: 0.007111
2022-01-21 20:22:27,973 iteration 5842 : loss : 0.008314, loss_ce: 0.003144
2022-01-21 20:22:29,266 iteration 5843 : loss : 0.020198, loss_ce: 0.007869
2022-01-21 20:22:30,718 iteration 5844 : loss : 0.039313, loss_ce: 0.011101
2022-01-21 20:22:32,041 iteration 5845 : loss : 0.017232, loss_ce: 0.007368
2022-01-21 20:22:33,382 iteration 5846 : loss : 0.022966, loss_ce: 0.010168
2022-01-21 20:22:34,731 iteration 5847 : loss : 0.016812, loss_ce: 0.006898
2022-01-21 20:22:36,060 iteration 5848 : loss : 0.013938, loss_ce: 0.004960
 86%|████████████████████████▉    | 344/400 [2:20:51<21:50, 23.40s/it]2022-01-21 20:22:37,430 iteration 5849 : loss : 0.015507, loss_ce: 0.006111
2022-01-21 20:22:38,696 iteration 5850 : loss : 0.011497, loss_ce: 0.004598
2022-01-21 20:22:40,023 iteration 5851 : loss : 0.012780, loss_ce: 0.004850
2022-01-21 20:22:41,324 iteration 5852 : loss : 0.016545, loss_ce: 0.006771
2022-01-21 20:22:42,568 iteration 5853 : loss : 0.011260, loss_ce: 0.003631
2022-01-21 20:22:43,861 iteration 5854 : loss : 0.018521, loss_ce: 0.006040
2022-01-21 20:22:45,248 iteration 5855 : loss : 0.017317, loss_ce: 0.007222
2022-01-21 20:22:46,579 iteration 5856 : loss : 0.013169, loss_ce: 0.006029
2022-01-21 20:22:47,922 iteration 5857 : loss : 0.013465, loss_ce: 0.004671
2022-01-21 20:22:49,175 iteration 5858 : loss : 0.012909, loss_ce: 0.004895
2022-01-21 20:22:50,554 iteration 5859 : loss : 0.016730, loss_ce: 0.006758
2022-01-21 20:22:51,923 iteration 5860 : loss : 0.017648, loss_ce: 0.006545
2022-01-21 20:22:53,225 iteration 5861 : loss : 0.014221, loss_ce: 0.003924
2022-01-21 20:22:54,575 iteration 5862 : loss : 0.013540, loss_ce: 0.006515
2022-01-21 20:22:55,810 iteration 5863 : loss : 0.008474, loss_ce: 0.002783
2022-01-21 20:22:57,135 iteration 5864 : loss : 0.018018, loss_ce: 0.005654
2022-01-21 20:22:57,135 Training Data Eval:
2022-01-21 20:23:03,657   Average segmentation loss on training set: 0.0081
2022-01-21 20:23:03,658 Validation Data Eval:
2022-01-21 20:23:05,888   Average segmentation loss on validation set: 0.0678
2022-01-21 20:23:07,150 iteration 5865 : loss : 0.014893, loss_ce: 0.004286
 86%|█████████████████████████    | 345/400 [2:21:22<23:33, 25.70s/it]2022-01-21 20:23:08,593 iteration 5866 : loss : 0.012805, loss_ce: 0.005463
2022-01-21 20:23:09,972 iteration 5867 : loss : 0.015013, loss_ce: 0.004399
2022-01-21 20:23:11,338 iteration 5868 : loss : 0.017469, loss_ce: 0.006495
2022-01-21 20:23:12,586 iteration 5869 : loss : 0.013767, loss_ce: 0.005854
2022-01-21 20:23:13,992 iteration 5870 : loss : 0.020403, loss_ce: 0.005061
2022-01-21 20:23:15,350 iteration 5871 : loss : 0.011614, loss_ce: 0.003870
2022-01-21 20:23:16,717 iteration 5872 : loss : 0.024064, loss_ce: 0.008971
2022-01-21 20:23:18,168 iteration 5873 : loss : 0.023137, loss_ce: 0.008500
2022-01-21 20:23:19,461 iteration 5874 : loss : 0.012455, loss_ce: 0.004410
2022-01-21 20:23:20,767 iteration 5875 : loss : 0.013710, loss_ce: 0.006927
2022-01-21 20:23:22,099 iteration 5876 : loss : 0.017167, loss_ce: 0.006448
2022-01-21 20:23:23,430 iteration 5877 : loss : 0.015247, loss_ce: 0.006246
2022-01-21 20:23:24,785 iteration 5878 : loss : 0.015905, loss_ce: 0.006299
2022-01-21 20:23:26,074 iteration 5879 : loss : 0.015023, loss_ce: 0.006349
2022-01-21 20:23:27,499 iteration 5880 : loss : 0.016461, loss_ce: 0.004159
2022-01-21 20:23:28,766 iteration 5881 : loss : 0.011132, loss_ce: 0.003893
2022-01-21 20:23:30,075 iteration 5882 : loss : 0.014204, loss_ce: 0.006497
 86%|█████████████████████████    | 346/400 [2:21:45<22:23, 24.87s/it]2022-01-21 20:23:31,418 iteration 5883 : loss : 0.012097, loss_ce: 0.004314
2022-01-21 20:23:32,715 iteration 5884 : loss : 0.012377, loss_ce: 0.004891
2022-01-21 20:23:34,173 iteration 5885 : loss : 0.032959, loss_ce: 0.012925
2022-01-21 20:23:35,445 iteration 5886 : loss : 0.016367, loss_ce: 0.005512
2022-01-21 20:23:36,742 iteration 5887 : loss : 0.010644, loss_ce: 0.004390
2022-01-21 20:23:38,155 iteration 5888 : loss : 0.022862, loss_ce: 0.007732
2022-01-21 20:23:39,563 iteration 5889 : loss : 0.016263, loss_ce: 0.005678
2022-01-21 20:23:40,910 iteration 5890 : loss : 0.011275, loss_ce: 0.003752
2022-01-21 20:23:42,298 iteration 5891 : loss : 0.018462, loss_ce: 0.006410
2022-01-21 20:23:43,728 iteration 5892 : loss : 0.020534, loss_ce: 0.008094
2022-01-21 20:23:45,027 iteration 5893 : loss : 0.011747, loss_ce: 0.003817
2022-01-21 20:23:46,441 iteration 5894 : loss : 0.042300, loss_ce: 0.014767
2022-01-21 20:23:47,804 iteration 5895 : loss : 0.023282, loss_ce: 0.007090
2022-01-21 20:23:49,121 iteration 5896 : loss : 0.016943, loss_ce: 0.009010
2022-01-21 20:23:50,520 iteration 5897 : loss : 0.025687, loss_ce: 0.011383
2022-01-21 20:23:51,897 iteration 5898 : loss : 0.012291, loss_ce: 0.004350
2022-01-21 20:23:53,207 iteration 5899 : loss : 0.012029, loss_ce: 0.004241
 87%|█████████████████████████▏   | 347/400 [2:22:08<21:30, 24.35s/it]2022-01-21 20:23:54,597 iteration 5900 : loss : 0.013974, loss_ce: 0.005213
2022-01-21 20:23:56,006 iteration 5901 : loss : 0.015484, loss_ce: 0.005263
2022-01-21 20:23:57,339 iteration 5902 : loss : 0.018558, loss_ce: 0.007364
2022-01-21 20:23:58,740 iteration 5903 : loss : 0.014716, loss_ce: 0.008093
2022-01-21 20:24:00,062 iteration 5904 : loss : 0.019277, loss_ce: 0.007636
2022-01-21 20:24:01,445 iteration 5905 : loss : 0.030590, loss_ce: 0.006459
2022-01-21 20:24:02,728 iteration 5906 : loss : 0.013674, loss_ce: 0.005587
2022-01-21 20:24:04,089 iteration 5907 : loss : 0.008711, loss_ce: 0.002971
2022-01-21 20:24:05,431 iteration 5908 : loss : 0.012188, loss_ce: 0.004495
2022-01-21 20:24:06,675 iteration 5909 : loss : 0.016153, loss_ce: 0.003991
2022-01-21 20:24:08,011 iteration 5910 : loss : 0.018783, loss_ce: 0.006925
2022-01-21 20:24:09,390 iteration 5911 : loss : 0.016815, loss_ce: 0.007044
2022-01-21 20:24:10,663 iteration 5912 : loss : 0.014534, loss_ce: 0.005012
2022-01-21 20:24:11,968 iteration 5913 : loss : 0.023899, loss_ce: 0.011602
2022-01-21 20:24:13,308 iteration 5914 : loss : 0.018971, loss_ce: 0.006253
2022-01-21 20:24:14,558 iteration 5915 : loss : 0.016001, loss_ce: 0.005706
2022-01-21 20:24:15,934 iteration 5916 : loss : 0.022335, loss_ce: 0.008340
 87%|█████████████████████████▏   | 348/400 [2:22:31<20:40, 23.86s/it]2022-01-21 20:24:17,276 iteration 5917 : loss : 0.012929, loss_ce: 0.005136
2022-01-21 20:24:18,542 iteration 5918 : loss : 0.013851, loss_ce: 0.005287
2022-01-21 20:24:19,902 iteration 5919 : loss : 0.017359, loss_ce: 0.007630
2022-01-21 20:24:21,284 iteration 5920 : loss : 0.017065, loss_ce: 0.008807
2022-01-21 20:24:22,794 iteration 5921 : loss : 0.019540, loss_ce: 0.005733
2022-01-21 20:24:24,107 iteration 5922 : loss : 0.013912, loss_ce: 0.003765
2022-01-21 20:24:25,457 iteration 5923 : loss : 0.020779, loss_ce: 0.006904
2022-01-21 20:24:26,895 iteration 5924 : loss : 0.026233, loss_ce: 0.005645
2022-01-21 20:24:28,243 iteration 5925 : loss : 0.016420, loss_ce: 0.005613
2022-01-21 20:24:29,574 iteration 5926 : loss : 0.026843, loss_ce: 0.010226
2022-01-21 20:24:30,926 iteration 5927 : loss : 0.011705, loss_ce: 0.004441
2022-01-21 20:24:32,196 iteration 5928 : loss : 0.017078, loss_ce: 0.004345
2022-01-21 20:24:33,464 iteration 5929 : loss : 0.017030, loss_ce: 0.009073
2022-01-21 20:24:34,738 iteration 5930 : loss : 0.018472, loss_ce: 0.008876
2022-01-21 20:24:36,078 iteration 5931 : loss : 0.025530, loss_ce: 0.006661
2022-01-21 20:24:37,456 iteration 5932 : loss : 0.019453, loss_ce: 0.006095
2022-01-21 20:24:38,775 iteration 5933 : loss : 0.012783, loss_ce: 0.004817
 87%|█████████████████████████▎   | 349/400 [2:22:54<20:01, 23.55s/it]2022-01-21 20:24:40,097 iteration 5934 : loss : 0.013065, loss_ce: 0.004375
2022-01-21 20:24:41,558 iteration 5935 : loss : 0.015673, loss_ce: 0.005007
2022-01-21 20:24:42,894 iteration 5936 : loss : 0.011449, loss_ce: 0.004789
2022-01-21 20:24:44,197 iteration 5937 : loss : 0.012565, loss_ce: 0.004281
2022-01-21 20:24:45,447 iteration 5938 : loss : 0.010852, loss_ce: 0.003843
2022-01-21 20:24:46,810 iteration 5939 : loss : 0.017997, loss_ce: 0.007382
2022-01-21 20:24:48,084 iteration 5940 : loss : 0.015049, loss_ce: 0.006118
2022-01-21 20:24:49,373 iteration 5941 : loss : 0.015843, loss_ce: 0.006573
2022-01-21 20:24:50,670 iteration 5942 : loss : 0.012866, loss_ce: 0.005866
2022-01-21 20:24:52,007 iteration 5943 : loss : 0.014534, loss_ce: 0.004098
2022-01-21 20:24:53,383 iteration 5944 : loss : 0.013047, loss_ce: 0.006362
2022-01-21 20:24:54,681 iteration 5945 : loss : 0.014560, loss_ce: 0.003702
2022-01-21 20:24:56,105 iteration 5946 : loss : 0.016190, loss_ce: 0.005837
2022-01-21 20:24:57,471 iteration 5947 : loss : 0.015852, loss_ce: 0.006208
2022-01-21 20:24:58,779 iteration 5948 : loss : 0.021527, loss_ce: 0.007935
2022-01-21 20:25:00,176 iteration 5949 : loss : 0.010980, loss_ce: 0.003437
2022-01-21 20:25:00,176 Training Data Eval:
2022-01-21 20:25:06,692   Average segmentation loss on training set: 0.0086
2022-01-21 20:25:06,693 Validation Data Eval:
2022-01-21 20:25:08,927   Average segmentation loss on validation set: 0.0652
2022-01-21 20:25:10,267 iteration 5950 : loss : 0.012629, loss_ce: 0.004082
 88%|█████████████████████████▍   | 350/400 [2:23:25<21:36, 25.94s/it]2022-01-21 20:25:11,590 iteration 5951 : loss : 0.011342, loss_ce: 0.004066
2022-01-21 20:25:12,919 iteration 5952 : loss : 0.013739, loss_ce: 0.004853
2022-01-21 20:25:14,251 iteration 5953 : loss : 0.017141, loss_ce: 0.006657
2022-01-21 20:25:15,541 iteration 5954 : loss : 0.014897, loss_ce: 0.005302
2022-01-21 20:25:16,862 iteration 5955 : loss : 0.015024, loss_ce: 0.005104
2022-01-21 20:25:18,216 iteration 5956 : loss : 0.022225, loss_ce: 0.012651
2022-01-21 20:25:19,557 iteration 5957 : loss : 0.011798, loss_ce: 0.004548
2022-01-21 20:25:20,842 iteration 5958 : loss : 0.013461, loss_ce: 0.005341
2022-01-21 20:25:22,160 iteration 5959 : loss : 0.016024, loss_ce: 0.007426
2022-01-21 20:25:23,438 iteration 5960 : loss : 0.011080, loss_ce: 0.003282
2022-01-21 20:25:24,711 iteration 5961 : loss : 0.014702, loss_ce: 0.003436
2022-01-21 20:25:26,027 iteration 5962 : loss : 0.045886, loss_ce: 0.009591
2022-01-21 20:25:27,387 iteration 5963 : loss : 0.014676, loss_ce: 0.006296
2022-01-21 20:25:28,686 iteration 5964 : loss : 0.011509, loss_ce: 0.004710
2022-01-21 20:25:29,947 iteration 5965 : loss : 0.019896, loss_ce: 0.012167
2022-01-21 20:25:31,321 iteration 5966 : loss : 0.015326, loss_ce: 0.003920
2022-01-21 20:25:32,666 iteration 5967 : loss : 0.012518, loss_ce: 0.004983
 88%|█████████████████████████▍   | 351/400 [2:23:48<20:18, 24.87s/it]2022-01-21 20:25:34,108 iteration 5968 : loss : 0.026879, loss_ce: 0.009171
2022-01-21 20:25:35,413 iteration 5969 : loss : 0.016587, loss_ce: 0.006876
2022-01-21 20:25:36,778 iteration 5970 : loss : 0.020400, loss_ce: 0.008342
2022-01-21 20:25:38,040 iteration 5971 : loss : 0.014733, loss_ce: 0.004712
2022-01-21 20:25:39,275 iteration 5972 : loss : 0.010858, loss_ce: 0.003388
2022-01-21 20:25:40,604 iteration 5973 : loss : 0.020859, loss_ce: 0.010352
2022-01-21 20:25:42,026 iteration 5974 : loss : 0.033798, loss_ce: 0.018980
2022-01-21 20:25:43,302 iteration 5975 : loss : 0.016528, loss_ce: 0.005923
2022-01-21 20:25:44,602 iteration 5976 : loss : 0.014013, loss_ce: 0.003877
2022-01-21 20:25:45,873 iteration 5977 : loss : 0.016756, loss_ce: 0.003942
2022-01-21 20:25:47,140 iteration 5978 : loss : 0.016426, loss_ce: 0.007431
2022-01-21 20:25:48,455 iteration 5979 : loss : 0.011358, loss_ce: 0.005180
2022-01-21 20:25:49,821 iteration 5980 : loss : 0.012939, loss_ce: 0.004103
2022-01-21 20:25:51,108 iteration 5981 : loss : 0.018106, loss_ce: 0.007909
2022-01-21 20:25:52,431 iteration 5982 : loss : 0.014797, loss_ce: 0.005995
2022-01-21 20:25:53,816 iteration 5983 : loss : 0.014254, loss_ce: 0.004215
2022-01-21 20:25:55,110 iteration 5984 : loss : 0.017587, loss_ce: 0.005970
 88%|█████████████████████████▌   | 352/400 [2:24:10<19:19, 24.15s/it]2022-01-21 20:25:56,479 iteration 5985 : loss : 0.012287, loss_ce: 0.003676
2022-01-21 20:25:57,716 iteration 5986 : loss : 0.021800, loss_ce: 0.006564
2022-01-21 20:25:59,066 iteration 5987 : loss : 0.015897, loss_ce: 0.006551
2022-01-21 20:26:00,442 iteration 5988 : loss : 0.019718, loss_ce: 0.008321
2022-01-21 20:26:01,783 iteration 5989 : loss : 0.014380, loss_ce: 0.005634
2022-01-21 20:26:03,090 iteration 5990 : loss : 0.012877, loss_ce: 0.004601
2022-01-21 20:26:04,438 iteration 5991 : loss : 0.017605, loss_ce: 0.005441
2022-01-21 20:26:05,782 iteration 5992 : loss : 0.018157, loss_ce: 0.006026
2022-01-21 20:26:07,099 iteration 5993 : loss : 0.012535, loss_ce: 0.005067
2022-01-21 20:26:08,471 iteration 5994 : loss : 0.022981, loss_ce: 0.010517
2022-01-21 20:26:09,788 iteration 5995 : loss : 0.021029, loss_ce: 0.006714
2022-01-21 20:26:11,066 iteration 5996 : loss : 0.012608, loss_ce: 0.003510
2022-01-21 20:26:12,410 iteration 5997 : loss : 0.017884, loss_ce: 0.006465
2022-01-21 20:26:13,811 iteration 5998 : loss : 0.013464, loss_ce: 0.004538
2022-01-21 20:26:15,242 iteration 5999 : loss : 0.026606, loss_ce: 0.010796
2022-01-21 20:26:16,589 iteration 6000 : loss : 0.014096, loss_ce: 0.005904
2022-01-21 20:26:17,838 iteration 6001 : loss : 0.014045, loss_ce: 0.006445
 88%|█████████████████████████▌   | 353/400 [2:24:33<18:34, 23.72s/it]2022-01-21 20:26:19,220 iteration 6002 : loss : 0.016994, loss_ce: 0.007263
2022-01-21 20:26:20,511 iteration 6003 : loss : 0.015750, loss_ce: 0.005685
2022-01-21 20:26:21,883 iteration 6004 : loss : 0.017413, loss_ce: 0.008042
2022-01-21 20:26:23,243 iteration 6005 : loss : 0.018020, loss_ce: 0.006320
2022-01-21 20:26:24,675 iteration 6006 : loss : 0.015073, loss_ce: 0.006250
2022-01-21 20:26:26,023 iteration 6007 : loss : 0.013017, loss_ce: 0.005229
2022-01-21 20:26:27,360 iteration 6008 : loss : 0.017219, loss_ce: 0.006220
2022-01-21 20:26:28,607 iteration 6009 : loss : 0.010746, loss_ce: 0.005118
2022-01-21 20:26:29,874 iteration 6010 : loss : 0.011561, loss_ce: 0.004706
2022-01-21 20:26:31,232 iteration 6011 : loss : 0.019655, loss_ce: 0.007305
2022-01-21 20:26:32,624 iteration 6012 : loss : 0.023987, loss_ce: 0.005357
2022-01-21 20:26:33,991 iteration 6013 : loss : 0.019514, loss_ce: 0.006096
2022-01-21 20:26:35,353 iteration 6014 : loss : 0.016923, loss_ce: 0.004587
2022-01-21 20:26:36,649 iteration 6015 : loss : 0.018314, loss_ce: 0.007071
2022-01-21 20:26:37,976 iteration 6016 : loss : 0.014207, loss_ce: 0.005288
2022-01-21 20:26:39,300 iteration 6017 : loss : 0.016283, loss_ce: 0.007129
2022-01-21 20:26:40,647 iteration 6018 : loss : 0.015784, loss_ce: 0.005414
 88%|█████████████████████████▋   | 354/400 [2:24:56<17:58, 23.45s/it]2022-01-21 20:26:42,026 iteration 6019 : loss : 0.020299, loss_ce: 0.010766
2022-01-21 20:26:43,338 iteration 6020 : loss : 0.012118, loss_ce: 0.006199
2022-01-21 20:26:44,681 iteration 6021 : loss : 0.015823, loss_ce: 0.004709
2022-01-21 20:26:45,956 iteration 6022 : loss : 0.014521, loss_ce: 0.005758
2022-01-21 20:26:47,323 iteration 6023 : loss : 0.013548, loss_ce: 0.005131
2022-01-21 20:26:48,628 iteration 6024 : loss : 0.024165, loss_ce: 0.007973
2022-01-21 20:26:49,922 iteration 6025 : loss : 0.015469, loss_ce: 0.007322
2022-01-21 20:26:51,267 iteration 6026 : loss : 0.016994, loss_ce: 0.005843
2022-01-21 20:26:52,607 iteration 6027 : loss : 0.016699, loss_ce: 0.005791
2022-01-21 20:26:53,974 iteration 6028 : loss : 0.015645, loss_ce: 0.007068
2022-01-21 20:26:55,283 iteration 6029 : loss : 0.017739, loss_ce: 0.004359
2022-01-21 20:26:56,544 iteration 6030 : loss : 0.015005, loss_ce: 0.006973
2022-01-21 20:26:57,887 iteration 6031 : loss : 0.013239, loss_ce: 0.006175
2022-01-21 20:26:59,164 iteration 6032 : loss : 0.012604, loss_ce: 0.003666
2022-01-21 20:27:00,541 iteration 6033 : loss : 0.017447, loss_ce: 0.006622
2022-01-21 20:27:01,873 iteration 6034 : loss : 0.013726, loss_ce: 0.005519
2022-01-21 20:27:01,873 Training Data Eval:
2022-01-21 20:27:08,396   Average segmentation loss on training set: 0.0079
2022-01-21 20:27:08,396 Validation Data Eval:
2022-01-21 20:27:10,626   Average segmentation loss on validation set: 0.0629
2022-01-21 20:27:11,836 iteration 6035 : loss : 0.010630, loss_ce: 0.004040
 89%|█████████████████████████▋   | 355/400 [2:25:27<19:19, 25.77s/it]2022-01-21 20:27:13,292 iteration 6036 : loss : 0.015874, loss_ce: 0.003846
2022-01-21 20:27:14,662 iteration 6037 : loss : 0.020896, loss_ce: 0.006065
2022-01-21 20:27:15,973 iteration 6038 : loss : 0.013481, loss_ce: 0.004555
2022-01-21 20:27:17,268 iteration 6039 : loss : 0.012884, loss_ce: 0.004158
2022-01-21 20:27:18,598 iteration 6040 : loss : 0.016218, loss_ce: 0.006014
2022-01-21 20:27:19,884 iteration 6041 : loss : 0.010116, loss_ce: 0.003632
2022-01-21 20:27:21,227 iteration 6042 : loss : 0.010710, loss_ce: 0.004473
2022-01-21 20:27:22,502 iteration 6043 : loss : 0.012884, loss_ce: 0.006364
2022-01-21 20:27:23,759 iteration 6044 : loss : 0.011472, loss_ce: 0.004786
2022-01-21 20:27:25,154 iteration 6045 : loss : 0.025629, loss_ce: 0.010067
2022-01-21 20:27:26,417 iteration 6046 : loss : 0.013149, loss_ce: 0.005937
2022-01-21 20:27:27,681 iteration 6047 : loss : 0.010715, loss_ce: 0.004591
2022-01-21 20:27:29,074 iteration 6048 : loss : 0.026145, loss_ce: 0.006463
2022-01-21 20:27:30,328 iteration 6049 : loss : 0.012116, loss_ce: 0.004178
2022-01-21 20:27:31,580 iteration 6050 : loss : 0.034893, loss_ce: 0.007991
2022-01-21 20:27:32,833 iteration 6051 : loss : 0.009824, loss_ce: 0.004181
2022-01-21 20:27:34,179 iteration 6052 : loss : 0.012230, loss_ce: 0.004261
 89%|█████████████████████████▊   | 356/400 [2:25:49<18:08, 24.74s/it]2022-01-21 20:27:35,513 iteration 6053 : loss : 0.015250, loss_ce: 0.005134
2022-01-21 20:27:36,799 iteration 6054 : loss : 0.012750, loss_ce: 0.004259
2022-01-21 20:27:38,144 iteration 6055 : loss : 0.014213, loss_ce: 0.006059
2022-01-21 20:27:39,451 iteration 6056 : loss : 0.015696, loss_ce: 0.005511
2022-01-21 20:27:40,689 iteration 6057 : loss : 0.014963, loss_ce: 0.005693
2022-01-21 20:27:41,954 iteration 6058 : loss : 0.010657, loss_ce: 0.005692
2022-01-21 20:27:43,326 iteration 6059 : loss : 0.037980, loss_ce: 0.009403
2022-01-21 20:27:44,652 iteration 6060 : loss : 0.012964, loss_ce: 0.003933
2022-01-21 20:27:45,919 iteration 6061 : loss : 0.016565, loss_ce: 0.007511
2022-01-21 20:27:47,352 iteration 6062 : loss : 0.018051, loss_ce: 0.006042
2022-01-21 20:27:48,625 iteration 6063 : loss : 0.015976, loss_ce: 0.006610
2022-01-21 20:27:49,902 iteration 6064 : loss : 0.011766, loss_ce: 0.003961
2022-01-21 20:27:51,239 iteration 6065 : loss : 0.021100, loss_ce: 0.007868
2022-01-21 20:27:52,503 iteration 6066 : loss : 0.013606, loss_ce: 0.005430
2022-01-21 20:27:53,849 iteration 6067 : loss : 0.023136, loss_ce: 0.007503
2022-01-21 20:27:55,192 iteration 6068 : loss : 0.018087, loss_ce: 0.003084
2022-01-21 20:27:56,600 iteration 6069 : loss : 0.016300, loss_ce: 0.006848
 89%|█████████████████████████▉   | 357/400 [2:26:12<17:13, 24.05s/it]2022-01-21 20:27:57,984 iteration 6070 : loss : 0.015860, loss_ce: 0.006268
2022-01-21 20:27:59,317 iteration 6071 : loss : 0.013763, loss_ce: 0.005413
2022-01-21 20:28:00,633 iteration 6072 : loss : 0.015162, loss_ce: 0.005474
2022-01-21 20:28:01,967 iteration 6073 : loss : 0.017163, loss_ce: 0.004333
2022-01-21 20:28:03,199 iteration 6074 : loss : 0.021523, loss_ce: 0.009030
2022-01-21 20:28:04,559 iteration 6075 : loss : 0.014585, loss_ce: 0.005907
2022-01-21 20:28:05,887 iteration 6076 : loss : 0.013942, loss_ce: 0.005633
2022-01-21 20:28:07,099 iteration 6077 : loss : 0.010319, loss_ce: 0.003591
2022-01-21 20:28:08,403 iteration 6078 : loss : 0.014471, loss_ce: 0.007785
2022-01-21 20:28:09,790 iteration 6079 : loss : 0.015443, loss_ce: 0.006686
2022-01-21 20:28:11,044 iteration 6080 : loss : 0.011431, loss_ce: 0.004114
2022-01-21 20:28:12,444 iteration 6081 : loss : 0.025485, loss_ce: 0.008895
2022-01-21 20:28:13,758 iteration 6082 : loss : 0.015714, loss_ce: 0.003866
2022-01-21 20:28:15,126 iteration 6083 : loss : 0.019245, loss_ce: 0.007369
2022-01-21 20:28:16,404 iteration 6084 : loss : 0.013247, loss_ce: 0.003547
2022-01-21 20:28:17,679 iteration 6085 : loss : 0.013707, loss_ce: 0.005974
2022-01-21 20:28:19,161 iteration 6086 : loss : 0.019785, loss_ce: 0.005688
 90%|█████████████████████████▉   | 358/400 [2:26:34<16:31, 23.60s/it]2022-01-21 20:28:20,467 iteration 6087 : loss : 0.013294, loss_ce: 0.005154
2022-01-21 20:28:21,800 iteration 6088 : loss : 0.014100, loss_ce: 0.006171
2022-01-21 20:28:23,105 iteration 6089 : loss : 0.019009, loss_ce: 0.009720
2022-01-21 20:28:24,414 iteration 6090 : loss : 0.012418, loss_ce: 0.004009
2022-01-21 20:28:25,730 iteration 6091 : loss : 0.015256, loss_ce: 0.007338
2022-01-21 20:28:27,057 iteration 6092 : loss : 0.012883, loss_ce: 0.005954
2022-01-21 20:28:28,323 iteration 6093 : loss : 0.015476, loss_ce: 0.005312
2022-01-21 20:28:29,587 iteration 6094 : loss : 0.017052, loss_ce: 0.005617
2022-01-21 20:28:30,927 iteration 6095 : loss : 0.014022, loss_ce: 0.005406
2022-01-21 20:28:32,271 iteration 6096 : loss : 0.016611, loss_ce: 0.004887
2022-01-21 20:28:33,519 iteration 6097 : loss : 0.011717, loss_ce: 0.005536
2022-01-21 20:28:34,844 iteration 6098 : loss : 0.018147, loss_ce: 0.006986
2022-01-21 20:28:36,202 iteration 6099 : loss : 0.016614, loss_ce: 0.003897
2022-01-21 20:28:37,605 iteration 6100 : loss : 0.019755, loss_ce: 0.006417
2022-01-21 20:28:38,973 iteration 6101 : loss : 0.013035, loss_ce: 0.004748
2022-01-21 20:28:40,260 iteration 6102 : loss : 0.014404, loss_ce: 0.004335
2022-01-21 20:28:41,474 iteration 6103 : loss : 0.008675, loss_ce: 0.003157
 90%|██████████████████████████   | 359/400 [2:26:57<15:51, 23.21s/it]2022-01-21 20:28:42,874 iteration 6104 : loss : 0.015438, loss_ce: 0.004407
2022-01-21 20:28:44,148 iteration 6105 : loss : 0.015310, loss_ce: 0.005518
2022-01-21 20:28:45,381 iteration 6106 : loss : 0.010804, loss_ce: 0.003675
2022-01-21 20:28:46,647 iteration 6107 : loss : 0.014318, loss_ce: 0.004929
2022-01-21 20:28:48,009 iteration 6108 : loss : 0.013319, loss_ce: 0.003888
2022-01-21 20:28:49,303 iteration 6109 : loss : 0.025952, loss_ce: 0.008794
2022-01-21 20:28:50,640 iteration 6110 : loss : 0.014721, loss_ce: 0.007250
2022-01-21 20:28:52,014 iteration 6111 : loss : 0.023121, loss_ce: 0.010312
2022-01-21 20:28:53,368 iteration 6112 : loss : 0.013569, loss_ce: 0.004441
2022-01-21 20:28:54,751 iteration 6113 : loss : 0.021278, loss_ce: 0.007587
2022-01-21 20:28:56,053 iteration 6114 : loss : 0.016513, loss_ce: 0.007332
2022-01-21 20:28:57,452 iteration 6115 : loss : 0.023554, loss_ce: 0.008404
2022-01-21 20:28:58,805 iteration 6116 : loss : 0.015392, loss_ce: 0.007557
2022-01-21 20:29:00,095 iteration 6117 : loss : 0.019215, loss_ce: 0.007611
2022-01-21 20:29:01,453 iteration 6118 : loss : 0.015017, loss_ce: 0.006493
2022-01-21 20:29:02,758 iteration 6119 : loss : 0.015432, loss_ce: 0.004740
2022-01-21 20:29:02,759 Training Data Eval:
2022-01-21 20:29:09,264   Average segmentation loss on training set: 0.0089
2022-01-21 20:29:09,265 Validation Data Eval:
2022-01-21 20:29:11,496   Average segmentation loss on validation set: 0.0662
2022-01-21 20:29:12,797 iteration 6120 : loss : 0.014558, loss_ce: 0.006881
 90%|██████████████████████████   | 360/400 [2:27:28<17:05, 25.65s/it]2022-01-21 20:29:14,175 iteration 6121 : loss : 0.018096, loss_ce: 0.007835
2022-01-21 20:29:15,542 iteration 6122 : loss : 0.023871, loss_ce: 0.008411
2022-01-21 20:29:16,944 iteration 6123 : loss : 0.014097, loss_ce: 0.006068
2022-01-21 20:29:18,279 iteration 6124 : loss : 0.014114, loss_ce: 0.004474
2022-01-21 20:29:19,704 iteration 6125 : loss : 0.021964, loss_ce: 0.007507
2022-01-21 20:29:21,020 iteration 6126 : loss : 0.019455, loss_ce: 0.004231
2022-01-21 20:29:22,323 iteration 6127 : loss : 0.013978, loss_ce: 0.005050
2022-01-21 20:29:23,723 iteration 6128 : loss : 0.013901, loss_ce: 0.004711
2022-01-21 20:29:25,053 iteration 6129 : loss : 0.012280, loss_ce: 0.006314
2022-01-21 20:29:26,467 iteration 6130 : loss : 0.016779, loss_ce: 0.007561
2022-01-21 20:29:27,812 iteration 6131 : loss : 0.012685, loss_ce: 0.006650
2022-01-21 20:29:29,153 iteration 6132 : loss : 0.018436, loss_ce: 0.004204
2022-01-21 20:29:30,436 iteration 6133 : loss : 0.010839, loss_ce: 0.005305
2022-01-21 20:29:31,684 iteration 6134 : loss : 0.009171, loss_ce: 0.003760
2022-01-21 20:29:32,939 iteration 6135 : loss : 0.009769, loss_ce: 0.003702
2022-01-21 20:29:34,278 iteration 6136 : loss : 0.013384, loss_ce: 0.004740
2022-01-21 20:29:35,578 iteration 6137 : loss : 0.016436, loss_ce: 0.005499
 90%|██████████████████████████▏  | 361/400 [2:27:51<16:06, 24.79s/it]2022-01-21 20:29:36,892 iteration 6138 : loss : 0.011127, loss_ce: 0.003824
2022-01-21 20:29:38,247 iteration 6139 : loss : 0.015609, loss_ce: 0.006903
2022-01-21 20:29:39,561 iteration 6140 : loss : 0.010454, loss_ce: 0.003804
2022-01-21 20:29:40,912 iteration 6141 : loss : 0.013464, loss_ce: 0.005709
2022-01-21 20:29:42,392 iteration 6142 : loss : 0.015168, loss_ce: 0.005622
2022-01-21 20:29:43,655 iteration 6143 : loss : 0.013294, loss_ce: 0.006260
2022-01-21 20:29:44,994 iteration 6144 : loss : 0.011700, loss_ce: 0.005064
2022-01-21 20:29:46,334 iteration 6145 : loss : 0.022101, loss_ce: 0.006986
2022-01-21 20:29:47,655 iteration 6146 : loss : 0.013807, loss_ce: 0.006212
2022-01-21 20:29:48,972 iteration 6147 : loss : 0.012926, loss_ce: 0.003142
2022-01-21 20:29:50,247 iteration 6148 : loss : 0.012236, loss_ce: 0.004386
2022-01-21 20:29:51,521 iteration 6149 : loss : 0.030518, loss_ce: 0.016615
2022-01-21 20:29:52,814 iteration 6150 : loss : 0.017010, loss_ce: 0.005465
2022-01-21 20:29:54,126 iteration 6151 : loss : 0.015554, loss_ce: 0.003505
2022-01-21 20:29:55,400 iteration 6152 : loss : 0.015954, loss_ce: 0.006031
2022-01-21 20:29:56,777 iteration 6153 : loss : 0.022431, loss_ce: 0.009877
2022-01-21 20:29:58,195 iteration 6154 : loss : 0.017515, loss_ce: 0.006918
 90%|██████████████████████████▏  | 362/400 [2:28:13<15:17, 24.13s/it]2022-01-21 20:29:59,532 iteration 6155 : loss : 0.013073, loss_ce: 0.005530
2022-01-21 20:30:00,845 iteration 6156 : loss : 0.009777, loss_ce: 0.004048
2022-01-21 20:30:02,213 iteration 6157 : loss : 0.016059, loss_ce: 0.004976
2022-01-21 20:30:03,514 iteration 6158 : loss : 0.014149, loss_ce: 0.004449
2022-01-21 20:30:04,750 iteration 6159 : loss : 0.010678, loss_ce: 0.004152
2022-01-21 20:30:06,260 iteration 6160 : loss : 0.027549, loss_ce: 0.016166
2022-01-21 20:30:07,508 iteration 6161 : loss : 0.016180, loss_ce: 0.005313
2022-01-21 20:30:08,858 iteration 6162 : loss : 0.010815, loss_ce: 0.004076
2022-01-21 20:30:10,172 iteration 6163 : loss : 0.021473, loss_ce: 0.007690
2022-01-21 20:30:11,455 iteration 6164 : loss : 0.013929, loss_ce: 0.003902
2022-01-21 20:30:12,790 iteration 6165 : loss : 0.011318, loss_ce: 0.004177
2022-01-21 20:30:14,145 iteration 6166 : loss : 0.017030, loss_ce: 0.006623
2022-01-21 20:30:15,388 iteration 6167 : loss : 0.009988, loss_ce: 0.003183
2022-01-21 20:30:16,810 iteration 6168 : loss : 0.026270, loss_ce: 0.007966
2022-01-21 20:30:18,122 iteration 6169 : loss : 0.012599, loss_ce: 0.005026
2022-01-21 20:30:19,474 iteration 6170 : loss : 0.014940, loss_ce: 0.006059
2022-01-21 20:30:20,792 iteration 6171 : loss : 0.016464, loss_ce: 0.004530
 91%|██████████████████████████▎  | 363/400 [2:28:36<14:35, 23.67s/it]2022-01-21 20:30:22,145 iteration 6172 : loss : 0.018990, loss_ce: 0.006342
2022-01-21 20:30:23,371 iteration 6173 : loss : 0.010585, loss_ce: 0.003738
2022-01-21 20:30:24,672 iteration 6174 : loss : 0.012610, loss_ce: 0.005877
2022-01-21 20:30:25,925 iteration 6175 : loss : 0.010001, loss_ce: 0.002832
2022-01-21 20:30:27,263 iteration 6176 : loss : 0.014066, loss_ce: 0.007489
2022-01-21 20:30:28,681 iteration 6177 : loss : 0.013686, loss_ce: 0.006641
2022-01-21 20:30:30,061 iteration 6178 : loss : 0.016490, loss_ce: 0.005621
2022-01-21 20:30:31,418 iteration 6179 : loss : 0.014549, loss_ce: 0.004502
2022-01-21 20:30:32,773 iteration 6180 : loss : 0.022795, loss_ce: 0.003622
2022-01-21 20:30:34,072 iteration 6181 : loss : 0.014071, loss_ce: 0.005419
2022-01-21 20:30:35,411 iteration 6182 : loss : 0.013704, loss_ce: 0.005118
2022-01-21 20:30:36,690 iteration 6183 : loss : 0.016674, loss_ce: 0.005881
2022-01-21 20:30:37,964 iteration 6184 : loss : 0.011508, loss_ce: 0.004491
2022-01-21 20:30:39,329 iteration 6185 : loss : 0.020824, loss_ce: 0.005957
2022-01-21 20:30:40,589 iteration 6186 : loss : 0.012250, loss_ce: 0.004473
2022-01-21 20:30:41,862 iteration 6187 : loss : 0.013449, loss_ce: 0.003847
2022-01-21 20:30:43,132 iteration 6188 : loss : 0.013554, loss_ce: 0.004989
 91%|██████████████████████████▍  | 364/400 [2:28:58<13:57, 23.27s/it]2022-01-21 20:30:44,571 iteration 6189 : loss : 0.017003, loss_ce: 0.006713
2022-01-21 20:30:45,907 iteration 6190 : loss : 0.012064, loss_ce: 0.004442
2022-01-21 20:30:47,302 iteration 6191 : loss : 0.009895, loss_ce: 0.003030
2022-01-21 20:30:48,662 iteration 6192 : loss : 0.017329, loss_ce: 0.006363
2022-01-21 20:30:49,947 iteration 6193 : loss : 0.010846, loss_ce: 0.003364
2022-01-21 20:30:51,318 iteration 6194 : loss : 0.016605, loss_ce: 0.006119
2022-01-21 20:30:52,707 iteration 6195 : loss : 0.014958, loss_ce: 0.004988
2022-01-21 20:30:53,994 iteration 6196 : loss : 0.015230, loss_ce: 0.005901
2022-01-21 20:30:55,403 iteration 6197 : loss : 0.024219, loss_ce: 0.008531
2022-01-21 20:30:56,821 iteration 6198 : loss : 0.022873, loss_ce: 0.009698
2022-01-21 20:30:58,113 iteration 6199 : loss : 0.012260, loss_ce: 0.004718
2022-01-21 20:30:59,471 iteration 6200 : loss : 0.018640, loss_ce: 0.008569
2022-01-21 20:31:00,799 iteration 6201 : loss : 0.012250, loss_ce: 0.004668
2022-01-21 20:31:02,112 iteration 6202 : loss : 0.011545, loss_ce: 0.003631
2022-01-21 20:31:03,413 iteration 6203 : loss : 0.017456, loss_ce: 0.005597
2022-01-21 20:31:04,782 iteration 6204 : loss : 0.014384, loss_ce: 0.006707
2022-01-21 20:31:04,783 Training Data Eval:
2022-01-21 20:31:11,295   Average segmentation loss on training set: 0.0077
2022-01-21 20:31:11,295 Validation Data Eval:
2022-01-21 20:31:13,523   Average segmentation loss on validation set: 0.0631
2022-01-21 20:31:14,943 iteration 6205 : loss : 0.020581, loss_ce: 0.008979
 91%|██████████████████████████▍  | 365/400 [2:29:30<15:04, 25.83s/it]2022-01-21 20:31:16,327 iteration 6206 : loss : 0.011541, loss_ce: 0.004780
2022-01-21 20:31:17,660 iteration 6207 : loss : 0.015128, loss_ce: 0.008025
2022-01-21 20:31:19,007 iteration 6208 : loss : 0.019338, loss_ce: 0.006389
2022-01-21 20:31:20,355 iteration 6209 : loss : 0.016225, loss_ce: 0.005338
2022-01-21 20:31:21,659 iteration 6210 : loss : 0.020982, loss_ce: 0.007012
2022-01-21 20:31:22,922 iteration 6211 : loss : 0.011514, loss_ce: 0.004089
2022-01-21 20:31:24,221 iteration 6212 : loss : 0.014909, loss_ce: 0.005676
2022-01-21 20:31:25,544 iteration 6213 : loss : 0.013780, loss_ce: 0.005290
2022-01-21 20:31:26,848 iteration 6214 : loss : 0.009267, loss_ce: 0.003514
2022-01-21 20:31:28,225 iteration 6215 : loss : 0.017714, loss_ce: 0.005870
2022-01-21 20:31:29,539 iteration 6216 : loss : 0.010313, loss_ce: 0.004252
2022-01-21 20:31:30,791 iteration 6217 : loss : 0.018066, loss_ce: 0.007570
2022-01-21 20:31:32,123 iteration 6218 : loss : 0.015978, loss_ce: 0.006141
2022-01-21 20:31:33,434 iteration 6219 : loss : 0.012030, loss_ce: 0.004109
2022-01-21 20:31:34,721 iteration 6220 : loss : 0.011791, loss_ce: 0.002669
2022-01-21 20:31:36,062 iteration 6221 : loss : 0.011480, loss_ce: 0.003372
2022-01-21 20:31:37,338 iteration 6222 : loss : 0.010785, loss_ce: 0.005020
 92%|██████████████████████████▌  | 366/400 [2:29:52<14:03, 24.80s/it]2022-01-21 20:31:38,731 iteration 6223 : loss : 0.019169, loss_ce: 0.010000
2022-01-21 20:31:40,042 iteration 6224 : loss : 0.016858, loss_ce: 0.007092
2022-01-21 20:31:41,371 iteration 6225 : loss : 0.026571, loss_ce: 0.008593
2022-01-21 20:31:42,655 iteration 6226 : loss : 0.010772, loss_ce: 0.003623
2022-01-21 20:31:43,918 iteration 6227 : loss : 0.013149, loss_ce: 0.005563
2022-01-21 20:31:45,244 iteration 6228 : loss : 0.016400, loss_ce: 0.005391
2022-01-21 20:31:46,577 iteration 6229 : loss : 0.016006, loss_ce: 0.007989
2022-01-21 20:31:47,933 iteration 6230 : loss : 0.017741, loss_ce: 0.005219
2022-01-21 20:31:49,304 iteration 6231 : loss : 0.017926, loss_ce: 0.006881
2022-01-21 20:31:50,647 iteration 6232 : loss : 0.012221, loss_ce: 0.004786
2022-01-21 20:31:51,965 iteration 6233 : loss : 0.013288, loss_ce: 0.005932
2022-01-21 20:31:53,261 iteration 6234 : loss : 0.012128, loss_ce: 0.002583
2022-01-21 20:31:54,536 iteration 6235 : loss : 0.012867, loss_ce: 0.006471
2022-01-21 20:31:55,862 iteration 6236 : loss : 0.011133, loss_ce: 0.005293
2022-01-21 20:31:57,209 iteration 6237 : loss : 0.016333, loss_ce: 0.007282
2022-01-21 20:31:58,602 iteration 6238 : loss : 0.016883, loss_ce: 0.005211
2022-01-21 20:31:59,941 iteration 6239 : loss : 0.020062, loss_ce: 0.005591
 92%|██████████████████████████▌  | 367/400 [2:30:15<13:16, 24.14s/it]2022-01-21 20:32:01,293 iteration 6240 : loss : 0.009899, loss_ce: 0.003206
2022-01-21 20:32:02,574 iteration 6241 : loss : 0.010759, loss_ce: 0.004950
2022-01-21 20:32:03,969 iteration 6242 : loss : 0.020294, loss_ce: 0.007429
2022-01-21 20:32:05,283 iteration 6243 : loss : 0.015269, loss_ce: 0.006631
2022-01-21 20:32:06,687 iteration 6244 : loss : 0.014716, loss_ce: 0.007046
2022-01-21 20:32:08,004 iteration 6245 : loss : 0.013610, loss_ce: 0.004856
2022-01-21 20:32:09,306 iteration 6246 : loss : 0.012233, loss_ce: 0.005167
2022-01-21 20:32:10,648 iteration 6247 : loss : 0.014937, loss_ce: 0.003736
2022-01-21 20:32:11,959 iteration 6248 : loss : 0.013489, loss_ce: 0.004843
2022-01-21 20:32:13,268 iteration 6249 : loss : 0.013905, loss_ce: 0.004380
2022-01-21 20:32:14,620 iteration 6250 : loss : 0.014763, loss_ce: 0.005444
2022-01-21 20:32:16,034 iteration 6251 : loss : 0.016654, loss_ce: 0.006722
2022-01-21 20:32:17,317 iteration 6252 : loss : 0.013256, loss_ce: 0.005668
2022-01-21 20:32:18,683 iteration 6253 : loss : 0.011623, loss_ce: 0.003924
2022-01-21 20:32:19,981 iteration 6254 : loss : 0.011865, loss_ce: 0.005377
2022-01-21 20:32:21,317 iteration 6255 : loss : 0.014906, loss_ce: 0.005563
2022-01-21 20:32:22,719 iteration 6256 : loss : 0.018314, loss_ce: 0.008002
 92%|██████████████████████████▋  | 368/400 [2:30:38<12:39, 23.73s/it]2022-01-21 20:32:24,130 iteration 6257 : loss : 0.019355, loss_ce: 0.005559
2022-01-21 20:32:25,505 iteration 6258 : loss : 0.016724, loss_ce: 0.006224
2022-01-21 20:32:26,903 iteration 6259 : loss : 0.014637, loss_ce: 0.006044
2022-01-21 20:32:28,214 iteration 6260 : loss : 0.013957, loss_ce: 0.005813
2022-01-21 20:32:29,524 iteration 6261 : loss : 0.014899, loss_ce: 0.005998
2022-01-21 20:32:30,869 iteration 6262 : loss : 0.018976, loss_ce: 0.005064
2022-01-21 20:32:32,213 iteration 6263 : loss : 0.018996, loss_ce: 0.003531
2022-01-21 20:32:33,562 iteration 6264 : loss : 0.016207, loss_ce: 0.005929
2022-01-21 20:32:34,907 iteration 6265 : loss : 0.014993, loss_ce: 0.006054
2022-01-21 20:32:36,213 iteration 6266 : loss : 0.015426, loss_ce: 0.007785
2022-01-21 20:32:37,505 iteration 6267 : loss : 0.012455, loss_ce: 0.005844
2022-01-21 20:32:38,830 iteration 6268 : loss : 0.012217, loss_ce: 0.004696
2022-01-21 20:32:40,025 iteration 6269 : loss : 0.009710, loss_ce: 0.003282
2022-01-21 20:32:41,330 iteration 6270 : loss : 0.011051, loss_ce: 0.004670
2022-01-21 20:32:42,638 iteration 6271 : loss : 0.012652, loss_ce: 0.003443
2022-01-21 20:32:44,004 iteration 6272 : loss : 0.021216, loss_ce: 0.008359
2022-01-21 20:32:45,357 iteration 6273 : loss : 0.014812, loss_ce: 0.005630
 92%|██████████████████████████▊  | 369/400 [2:31:00<12:05, 23.41s/it]2022-01-21 20:32:46,851 iteration 6274 : loss : 0.018802, loss_ce: 0.006499
2022-01-21 20:32:48,206 iteration 6275 : loss : 0.012364, loss_ce: 0.005781
2022-01-21 20:32:49,548 iteration 6276 : loss : 0.012459, loss_ce: 0.004493
2022-01-21 20:32:50,839 iteration 6277 : loss : 0.011783, loss_ce: 0.003510
2022-01-21 20:32:52,174 iteration 6278 : loss : 0.018678, loss_ce: 0.006625
2022-01-21 20:32:53,490 iteration 6279 : loss : 0.024556, loss_ce: 0.009912
2022-01-21 20:32:54,783 iteration 6280 : loss : 0.016275, loss_ce: 0.005875
2022-01-21 20:32:56,222 iteration 6281 : loss : 0.027178, loss_ce: 0.006447
2022-01-21 20:32:57,536 iteration 6282 : loss : 0.011047, loss_ce: 0.004227
2022-01-21 20:32:58,824 iteration 6283 : loss : 0.011090, loss_ce: 0.004927
2022-01-21 20:33:00,151 iteration 6284 : loss : 0.023584, loss_ce: 0.009384
2022-01-21 20:33:01,521 iteration 6285 : loss : 0.014373, loss_ce: 0.005129
2022-01-21 20:33:02,823 iteration 6286 : loss : 0.018379, loss_ce: 0.008145
2022-01-21 20:33:04,121 iteration 6287 : loss : 0.020479, loss_ce: 0.006234
2022-01-21 20:33:05,360 iteration 6288 : loss : 0.010050, loss_ce: 0.003267
2022-01-21 20:33:06,698 iteration 6289 : loss : 0.012966, loss_ce: 0.005711
2022-01-21 20:33:06,698 Training Data Eval:
2022-01-21 20:33:13,221   Average segmentation loss on training set: 0.0077
2022-01-21 20:33:13,221 Validation Data Eval:
2022-01-21 20:33:15,456   Average segmentation loss on validation set: 0.0618
2022-01-21 20:33:16,818 iteration 6290 : loss : 0.016501, loss_ce: 0.007096
 92%|██████████████████████████▊  | 370/400 [2:31:32<12:54, 25.82s/it]2022-01-21 20:33:18,184 iteration 6291 : loss : 0.010379, loss_ce: 0.004218
2022-01-21 20:33:19,510 iteration 6292 : loss : 0.014555, loss_ce: 0.004637
2022-01-21 20:33:20,871 iteration 6293 : loss : 0.015525, loss_ce: 0.006887
2022-01-21 20:33:22,234 iteration 6294 : loss : 0.018252, loss_ce: 0.004829
2022-01-21 20:33:23,555 iteration 6295 : loss : 0.011907, loss_ce: 0.005009
2022-01-21 20:33:24,953 iteration 6296 : loss : 0.016672, loss_ce: 0.005726
2022-01-21 20:33:26,291 iteration 6297 : loss : 0.017562, loss_ce: 0.005725
2022-01-21 20:33:27,663 iteration 6298 : loss : 0.018830, loss_ce: 0.007126
2022-01-21 20:33:28,985 iteration 6299 : loss : 0.011231, loss_ce: 0.003671
2022-01-21 20:33:30,283 iteration 6300 : loss : 0.011866, loss_ce: 0.003840
2022-01-21 20:33:31,578 iteration 6301 : loss : 0.011992, loss_ce: 0.006671
2022-01-21 20:33:32,919 iteration 6302 : loss : 0.015631, loss_ce: 0.005928
2022-01-21 20:33:34,159 iteration 6303 : loss : 0.010880, loss_ce: 0.002493
2022-01-21 20:33:35,412 iteration 6304 : loss : 0.014277, loss_ce: 0.003641
2022-01-21 20:33:36,751 iteration 6305 : loss : 0.016487, loss_ce: 0.008837
2022-01-21 20:33:38,055 iteration 6306 : loss : 0.018132, loss_ce: 0.004040
2022-01-21 20:33:39,369 iteration 6307 : loss : 0.011627, loss_ce: 0.005233
 93%|██████████████████████████▉  | 371/400 [2:31:54<12:00, 24.84s/it]2022-01-21 20:33:40,687 iteration 6308 : loss : 0.013931, loss_ce: 0.003261
2022-01-21 20:33:42,025 iteration 6309 : loss : 0.014479, loss_ce: 0.005268
2022-01-21 20:33:43,336 iteration 6310 : loss : 0.014048, loss_ce: 0.006213
2022-01-21 20:33:44,673 iteration 6311 : loss : 0.012193, loss_ce: 0.005320
2022-01-21 20:33:46,019 iteration 6312 : loss : 0.018795, loss_ce: 0.006428
2022-01-21 20:33:47,418 iteration 6313 : loss : 0.014271, loss_ce: 0.006018
2022-01-21 20:33:48,734 iteration 6314 : loss : 0.022072, loss_ce: 0.009227
2022-01-21 20:33:50,021 iteration 6315 : loss : 0.012163, loss_ce: 0.004395
2022-01-21 20:33:51,339 iteration 6316 : loss : 0.013158, loss_ce: 0.004891
2022-01-21 20:33:52,646 iteration 6317 : loss : 0.011531, loss_ce: 0.002916
2022-01-21 20:33:54,035 iteration 6318 : loss : 0.025910, loss_ce: 0.009513
2022-01-21 20:33:55,381 iteration 6319 : loss : 0.011663, loss_ce: 0.004361
2022-01-21 20:33:56,693 iteration 6320 : loss : 0.014605, loss_ce: 0.004892
2022-01-21 20:33:58,062 iteration 6321 : loss : 0.015090, loss_ce: 0.006936
2022-01-21 20:33:59,448 iteration 6322 : loss : 0.015855, loss_ce: 0.008042
2022-01-21 20:34:00,915 iteration 6323 : loss : 0.023749, loss_ce: 0.008539
2022-01-21 20:34:02,319 iteration 6324 : loss : 0.020750, loss_ce: 0.010773
 93%|██████████████████████████▉  | 372/400 [2:32:17<11:19, 24.27s/it]2022-01-21 20:34:03,721 iteration 6325 : loss : 0.014054, loss_ce: 0.003565
2022-01-21 20:34:05,019 iteration 6326 : loss : 0.012362, loss_ce: 0.005118
2022-01-21 20:34:06,341 iteration 6327 : loss : 0.016718, loss_ce: 0.005678
2022-01-21 20:34:07,718 iteration 6328 : loss : 0.011891, loss_ce: 0.005564
2022-01-21 20:34:08,979 iteration 6329 : loss : 0.011948, loss_ce: 0.005401
2022-01-21 20:34:10,292 iteration 6330 : loss : 0.019937, loss_ce: 0.008321
2022-01-21 20:34:11,674 iteration 6331 : loss : 0.014798, loss_ce: 0.006452
2022-01-21 20:34:13,036 iteration 6332 : loss : 0.012910, loss_ce: 0.003629
2022-01-21 20:34:14,365 iteration 6333 : loss : 0.010169, loss_ce: 0.004554
2022-01-21 20:34:15,697 iteration 6334 : loss : 0.016431, loss_ce: 0.003898
2022-01-21 20:34:17,107 iteration 6335 : loss : 0.029795, loss_ce: 0.012507
2022-01-21 20:34:18,409 iteration 6336 : loss : 0.014950, loss_ce: 0.008024
2022-01-21 20:34:19,756 iteration 6337 : loss : 0.016138, loss_ce: 0.005611
2022-01-21 20:34:21,088 iteration 6338 : loss : 0.020382, loss_ce: 0.006354
2022-01-21 20:34:22,412 iteration 6339 : loss : 0.015642, loss_ce: 0.005805
2022-01-21 20:34:23,740 iteration 6340 : loss : 0.017379, loss_ce: 0.007653
2022-01-21 20:34:24,991 iteration 6341 : loss : 0.009809, loss_ce: 0.003344
 93%|███████████████████████████  | 373/400 [2:32:40<10:42, 23.79s/it]2022-01-21 20:34:26,405 iteration 6342 : loss : 0.018732, loss_ce: 0.006205
2022-01-21 20:34:27,715 iteration 6343 : loss : 0.011769, loss_ce: 0.004899
2022-01-21 20:34:29,020 iteration 6344 : loss : 0.016957, loss_ce: 0.004896
2022-01-21 20:34:30,313 iteration 6345 : loss : 0.024739, loss_ce: 0.003223
2022-01-21 20:34:31,653 iteration 6346 : loss : 0.019943, loss_ce: 0.005548
2022-01-21 20:34:32,986 iteration 6347 : loss : 0.015530, loss_ce: 0.005398
2022-01-21 20:34:34,218 iteration 6348 : loss : 0.009272, loss_ce: 0.003786
2022-01-21 20:34:35,552 iteration 6349 : loss : 0.017713, loss_ce: 0.008230
2022-01-21 20:34:36,988 iteration 6350 : loss : 0.019872, loss_ce: 0.006903
2022-01-21 20:34:38,372 iteration 6351 : loss : 0.018902, loss_ce: 0.007651
2022-01-21 20:34:39,701 iteration 6352 : loss : 0.022924, loss_ce: 0.006149
2022-01-21 20:34:41,036 iteration 6353 : loss : 0.014805, loss_ce: 0.005455
2022-01-21 20:34:42,364 iteration 6354 : loss : 0.013200, loss_ce: 0.005584
2022-01-21 20:34:43,665 iteration 6355 : loss : 0.018973, loss_ce: 0.006544
2022-01-21 20:34:45,051 iteration 6356 : loss : 0.019173, loss_ce: 0.004164
2022-01-21 20:34:46,350 iteration 6357 : loss : 0.016082, loss_ce: 0.005404
2022-01-21 20:34:47,783 iteration 6358 : loss : 0.018867, loss_ce: 0.008297
 94%|███████████████████████████  | 374/400 [2:33:03<10:10, 23.49s/it]2022-01-21 20:34:49,207 iteration 6359 : loss : 0.036159, loss_ce: 0.007978
2022-01-21 20:34:50,484 iteration 6360 : loss : 0.015450, loss_ce: 0.006888
2022-01-21 20:34:51,838 iteration 6361 : loss : 0.015929, loss_ce: 0.005353
2022-01-21 20:34:53,197 iteration 6362 : loss : 0.016756, loss_ce: 0.007538
2022-01-21 20:34:54,579 iteration 6363 : loss : 0.017797, loss_ce: 0.007161
2022-01-21 20:34:55,869 iteration 6364 : loss : 0.011225, loss_ce: 0.002931
2022-01-21 20:34:57,210 iteration 6365 : loss : 0.017731, loss_ce: 0.009542
2022-01-21 20:34:58,625 iteration 6366 : loss : 0.015076, loss_ce: 0.006072
2022-01-21 20:35:00,072 iteration 6367 : loss : 0.017458, loss_ce: 0.006524
2022-01-21 20:35:01,450 iteration 6368 : loss : 0.017748, loss_ce: 0.007242
2022-01-21 20:35:02,787 iteration 6369 : loss : 0.011493, loss_ce: 0.004244
2022-01-21 20:35:04,127 iteration 6370 : loss : 0.013453, loss_ce: 0.004691
2022-01-21 20:35:05,559 iteration 6371 : loss : 0.024296, loss_ce: 0.009617
2022-01-21 20:35:06,853 iteration 6372 : loss : 0.008717, loss_ce: 0.003472
2022-01-21 20:35:08,140 iteration 6373 : loss : 0.010365, loss_ce: 0.003858
2022-01-21 20:35:09,473 iteration 6374 : loss : 0.024178, loss_ce: 0.009349
2022-01-21 20:35:09,473 Training Data Eval:
2022-01-21 20:35:15,991   Average segmentation loss on training set: 0.0076
2022-01-21 20:35:15,992 Validation Data Eval:
2022-01-21 20:35:18,222   Average segmentation loss on validation set: 0.0634
2022-01-21 20:35:19,558 iteration 6375 : loss : 0.020608, loss_ce: 0.006841
 94%|███████████████████████████▏ | 375/400 [2:33:35<10:49, 25.98s/it]2022-01-21 20:35:20,962 iteration 6376 : loss : 0.016345, loss_ce: 0.004629
2022-01-21 20:35:22,307 iteration 6377 : loss : 0.015329, loss_ce: 0.005647
2022-01-21 20:35:23,540 iteration 6378 : loss : 0.013057, loss_ce: 0.006156
2022-01-21 20:35:24,856 iteration 6379 : loss : 0.015165, loss_ce: 0.003514
2022-01-21 20:35:26,149 iteration 6380 : loss : 0.014859, loss_ce: 0.005639
2022-01-21 20:35:27,432 iteration 6381 : loss : 0.009257, loss_ce: 0.002879
2022-01-21 20:35:28,660 iteration 6382 : loss : 0.011481, loss_ce: 0.003867
2022-01-21 20:35:30,021 iteration 6383 : loss : 0.019124, loss_ce: 0.006630
2022-01-21 20:35:31,312 iteration 6384 : loss : 0.012688, loss_ce: 0.005139
2022-01-21 20:35:32,661 iteration 6385 : loss : 0.024962, loss_ce: 0.008422
2022-01-21 20:35:34,033 iteration 6386 : loss : 0.017398, loss_ce: 0.005158
2022-01-21 20:35:35,452 iteration 6387 : loss : 0.014225, loss_ce: 0.006239
2022-01-21 20:35:36,814 iteration 6388 : loss : 0.014843, loss_ce: 0.006288
2022-01-21 20:35:38,031 iteration 6389 : loss : 0.011011, loss_ce: 0.003791
2022-01-21 20:35:39,351 iteration 6390 : loss : 0.011772, loss_ce: 0.005263
2022-01-21 20:35:40,631 iteration 6391 : loss : 0.011154, loss_ce: 0.006002
2022-01-21 20:35:42,024 iteration 6392 : loss : 0.018464, loss_ce: 0.005163
 94%|███████████████████████████▎ | 376/400 [2:33:57<09:58, 24.93s/it]2022-01-21 20:35:43,387 iteration 6393 : loss : 0.012920, loss_ce: 0.004619
2022-01-21 20:35:44,765 iteration 6394 : loss : 0.011771, loss_ce: 0.004466
2022-01-21 20:35:46,076 iteration 6395 : loss : 0.017200, loss_ce: 0.004684
2022-01-21 20:35:47,398 iteration 6396 : loss : 0.013197, loss_ce: 0.004601
2022-01-21 20:35:48,740 iteration 6397 : loss : 0.013731, loss_ce: 0.004796
2022-01-21 20:35:50,091 iteration 6398 : loss : 0.016735, loss_ce: 0.007454
2022-01-21 20:35:51,413 iteration 6399 : loss : 0.014745, loss_ce: 0.004480
2022-01-21 20:35:52,718 iteration 6400 : loss : 0.009942, loss_ce: 0.004009
2022-01-21 20:35:54,078 iteration 6401 : loss : 0.029547, loss_ce: 0.010256
2022-01-21 20:35:55,389 iteration 6402 : loss : 0.014850, loss_ce: 0.007592
2022-01-21 20:35:56,794 iteration 6403 : loss : 0.018548, loss_ce: 0.007779
2022-01-21 20:35:58,102 iteration 6404 : loss : 0.011461, loss_ce: 0.004657
2022-01-21 20:35:59,399 iteration 6405 : loss : 0.023731, loss_ce: 0.007389
2022-01-21 20:36:00,872 iteration 6406 : loss : 0.031113, loss_ce: 0.008049
2022-01-21 20:36:02,236 iteration 6407 : loss : 0.038095, loss_ce: 0.009713
2022-01-21 20:36:03,460 iteration 6408 : loss : 0.010166, loss_ce: 0.003502
2022-01-21 20:36:04,769 iteration 6409 : loss : 0.011247, loss_ce: 0.004701
 94%|███████████████████████████▎ | 377/400 [2:34:20<09:18, 24.27s/it]2022-01-21 20:36:06,095 iteration 6410 : loss : 0.012497, loss_ce: 0.004128
2022-01-21 20:36:07,443 iteration 6411 : loss : 0.017888, loss_ce: 0.007012
2022-01-21 20:36:08,795 iteration 6412 : loss : 0.015673, loss_ce: 0.006068
2022-01-21 20:36:10,107 iteration 6413 : loss : 0.013475, loss_ce: 0.005769
2022-01-21 20:36:11,401 iteration 6414 : loss : 0.017445, loss_ce: 0.009347
2022-01-21 20:36:12,673 iteration 6415 : loss : 0.010933, loss_ce: 0.003606
2022-01-21 20:36:14,007 iteration 6416 : loss : 0.013448, loss_ce: 0.006040
2022-01-21 20:36:15,303 iteration 6417 : loss : 0.013756, loss_ce: 0.005140
2022-01-21 20:36:16,597 iteration 6418 : loss : 0.010096, loss_ce: 0.004314
2022-01-21 20:36:18,006 iteration 6419 : loss : 0.020111, loss_ce: 0.008372
2022-01-21 20:36:19,408 iteration 6420 : loss : 0.021886, loss_ce: 0.005892
2022-01-21 20:36:20,770 iteration 6421 : loss : 0.015928, loss_ce: 0.005927
2022-01-21 20:36:22,103 iteration 6422 : loss : 0.017212, loss_ce: 0.005185
2022-01-21 20:36:23,457 iteration 6423 : loss : 0.016987, loss_ce: 0.007106
2022-01-21 20:36:24,877 iteration 6424 : loss : 0.018708, loss_ce: 0.009168
2022-01-21 20:36:26,195 iteration 6425 : loss : 0.015013, loss_ce: 0.004629
2022-01-21 20:36:27,591 iteration 6426 : loss : 0.019497, loss_ce: 0.006171
 94%|███████████████████████████▍ | 378/400 [2:34:43<08:44, 23.83s/it]2022-01-21 20:36:28,990 iteration 6427 : loss : 0.012147, loss_ce: 0.003584
2022-01-21 20:36:30,326 iteration 6428 : loss : 0.020862, loss_ce: 0.007368
2022-01-21 20:36:31,662 iteration 6429 : loss : 0.014308, loss_ce: 0.005244
2022-01-21 20:36:33,037 iteration 6430 : loss : 0.017623, loss_ce: 0.007462
2022-01-21 20:36:34,305 iteration 6431 : loss : 0.012315, loss_ce: 0.004463
2022-01-21 20:36:35,643 iteration 6432 : loss : 0.012074, loss_ce: 0.004741
2022-01-21 20:36:36,966 iteration 6433 : loss : 0.011275, loss_ce: 0.003496
2022-01-21 20:36:38,258 iteration 6434 : loss : 0.015205, loss_ce: 0.006103
2022-01-21 20:36:39,573 iteration 6435 : loss : 0.016780, loss_ce: 0.005962
2022-01-21 20:36:40,878 iteration 6436 : loss : 0.012189, loss_ce: 0.005202
2022-01-21 20:36:42,206 iteration 6437 : loss : 0.012460, loss_ce: 0.004063
2022-01-21 20:36:43,569 iteration 6438 : loss : 0.018490, loss_ce: 0.006247
2022-01-21 20:36:44,851 iteration 6439 : loss : 0.011013, loss_ce: 0.004752
2022-01-21 20:36:46,216 iteration 6440 : loss : 0.015330, loss_ce: 0.006701
2022-01-21 20:36:47,482 iteration 6441 : loss : 0.011024, loss_ce: 0.005042
2022-01-21 20:36:48,819 iteration 6442 : loss : 0.013302, loss_ce: 0.003852
2022-01-21 20:36:50,072 iteration 6443 : loss : 0.009966, loss_ce: 0.003227
 95%|███████████████████████████▍ | 379/400 [2:35:05<08:12, 23.43s/it]2022-01-21 20:36:51,453 iteration 6444 : loss : 0.014837, loss_ce: 0.006704
2022-01-21 20:36:52,778 iteration 6445 : loss : 0.013548, loss_ce: 0.005488
2022-01-21 20:36:54,117 iteration 6446 : loss : 0.013636, loss_ce: 0.005655
2022-01-21 20:36:55,475 iteration 6447 : loss : 0.022766, loss_ce: 0.003767
2022-01-21 20:36:56,839 iteration 6448 : loss : 0.016058, loss_ce: 0.006332
2022-01-21 20:36:58,145 iteration 6449 : loss : 0.009198, loss_ce: 0.002600
2022-01-21 20:36:59,423 iteration 6450 : loss : 0.012730, loss_ce: 0.005480
2022-01-21 20:37:00,755 iteration 6451 : loss : 0.013287, loss_ce: 0.005062
2022-01-21 20:37:02,151 iteration 6452 : loss : 0.014818, loss_ce: 0.005328
2022-01-21 20:37:03,456 iteration 6453 : loss : 0.018689, loss_ce: 0.006455
2022-01-21 20:37:04,720 iteration 6454 : loss : 0.014971, loss_ce: 0.005645
2022-01-21 20:37:06,084 iteration 6455 : loss : 0.012235, loss_ce: 0.005826
2022-01-21 20:37:07,404 iteration 6456 : loss : 0.017348, loss_ce: 0.005581
2022-01-21 20:37:08,750 iteration 6457 : loss : 0.016150, loss_ce: 0.005731
2022-01-21 20:37:10,027 iteration 6458 : loss : 0.014140, loss_ce: 0.005196
2022-01-21 20:37:11,333 iteration 6459 : loss : 0.008537, loss_ce: 0.002110
2022-01-21 20:37:11,333 Training Data Eval:
2022-01-21 20:37:17,858   Average segmentation loss on training set: 0.0075
2022-01-21 20:37:17,859 Validation Data Eval:
2022-01-21 20:37:20,080   Average segmentation loss on validation set: 0.0678
2022-01-21 20:37:21,448 iteration 6460 : loss : 0.014435, loss_ce: 0.006515
 95%|███████████████████████████▌ | 380/400 [2:35:37<08:36, 25.81s/it]2022-01-21 20:37:22,870 iteration 6461 : loss : 0.022344, loss_ce: 0.011948
2022-01-21 20:37:24,169 iteration 6462 : loss : 0.009837, loss_ce: 0.004083
2022-01-21 20:37:25,547 iteration 6463 : loss : 0.016420, loss_ce: 0.007014
2022-01-21 20:37:26,875 iteration 6464 : loss : 0.021734, loss_ce: 0.007338
2022-01-21 20:37:28,248 iteration 6465 : loss : 0.017166, loss_ce: 0.006397
2022-01-21 20:37:29,526 iteration 6466 : loss : 0.011756, loss_ce: 0.003627
2022-01-21 20:37:30,830 iteration 6467 : loss : 0.011464, loss_ce: 0.004339
2022-01-21 20:37:32,216 iteration 6468 : loss : 0.015690, loss_ce: 0.005653
2022-01-21 20:37:33,529 iteration 6469 : loss : 0.012792, loss_ce: 0.005565
2022-01-21 20:37:34,820 iteration 6470 : loss : 0.012711, loss_ce: 0.003625
2022-01-21 20:37:36,148 iteration 6471 : loss : 0.012893, loss_ce: 0.004401
2022-01-21 20:37:37,483 iteration 6472 : loss : 0.018998, loss_ce: 0.007386
2022-01-21 20:37:38,778 iteration 6473 : loss : 0.012170, loss_ce: 0.004052
2022-01-21 20:37:40,169 iteration 6474 : loss : 0.010686, loss_ce: 0.004908
2022-01-21 20:37:41,516 iteration 6475 : loss : 0.017220, loss_ce: 0.009343
2022-01-21 20:37:42,734 iteration 6476 : loss : 0.011956, loss_ce: 0.004233
2022-01-21 20:37:44,150 iteration 6477 : loss : 0.021196, loss_ce: 0.007542
 95%|███████████████████████████▌ | 381/400 [2:35:59<07:52, 24.88s/it]2022-01-21 20:37:45,574 iteration 6478 : loss : 0.018134, loss_ce: 0.005419
2022-01-21 20:37:46,884 iteration 6479 : loss : 0.028369, loss_ce: 0.010159
2022-01-21 20:37:48,197 iteration 6480 : loss : 0.012896, loss_ce: 0.005859
2022-01-21 20:37:49,552 iteration 6481 : loss : 0.014705, loss_ce: 0.006847
2022-01-21 20:37:50,812 iteration 6482 : loss : 0.009738, loss_ce: 0.003474
2022-01-21 20:37:52,168 iteration 6483 : loss : 0.014257, loss_ce: 0.003093
2022-01-21 20:37:53,458 iteration 6484 : loss : 0.011125, loss_ce: 0.004308
2022-01-21 20:37:54,773 iteration 6485 : loss : 0.018925, loss_ce: 0.007709
2022-01-21 20:37:56,153 iteration 6486 : loss : 0.012090, loss_ce: 0.004234
2022-01-21 20:37:57,583 iteration 6487 : loss : 0.019835, loss_ce: 0.008062
2022-01-21 20:37:58,946 iteration 6488 : loss : 0.014381, loss_ce: 0.005572
2022-01-21 20:38:00,241 iteration 6489 : loss : 0.010284, loss_ce: 0.005029
2022-01-21 20:38:01,588 iteration 6490 : loss : 0.014843, loss_ce: 0.003909
2022-01-21 20:38:02,893 iteration 6491 : loss : 0.011871, loss_ce: 0.004395
2022-01-21 20:38:04,300 iteration 6492 : loss : 0.011612, loss_ce: 0.003910
2022-01-21 20:38:05,650 iteration 6493 : loss : 0.018728, loss_ce: 0.006312
2022-01-21 20:38:06,876 iteration 6494 : loss : 0.008930, loss_ce: 0.003689
 96%|███████████████████████████▋ | 382/400 [2:36:22<07:16, 24.23s/it]2022-01-21 20:38:08,210 iteration 6495 : loss : 0.011974, loss_ce: 0.004556
2022-01-21 20:38:09,540 iteration 6496 : loss : 0.020617, loss_ce: 0.004823
2022-01-21 20:38:10,904 iteration 6497 : loss : 0.009261, loss_ce: 0.003462
2022-01-21 20:38:12,274 iteration 6498 : loss : 0.020370, loss_ce: 0.007097
2022-01-21 20:38:13,637 iteration 6499 : loss : 0.016946, loss_ce: 0.006845
2022-01-21 20:38:14,953 iteration 6500 : loss : 0.012043, loss_ce: 0.004725
2022-01-21 20:38:16,301 iteration 6501 : loss : 0.014083, loss_ce: 0.005357
2022-01-21 20:38:17,684 iteration 6502 : loss : 0.012357, loss_ce: 0.006674
2022-01-21 20:38:18,981 iteration 6503 : loss : 0.009729, loss_ce: 0.002384
2022-01-21 20:38:20,251 iteration 6504 : loss : 0.011847, loss_ce: 0.004357
2022-01-21 20:38:21,452 iteration 6505 : loss : 0.010383, loss_ce: 0.004741
2022-01-21 20:38:22,756 iteration 6506 : loss : 0.015835, loss_ce: 0.005161
2022-01-21 20:38:24,151 iteration 6507 : loss : 0.016223, loss_ce: 0.007655
2022-01-21 20:38:25,510 iteration 6508 : loss : 0.014358, loss_ce: 0.005499
2022-01-21 20:38:26,854 iteration 6509 : loss : 0.017466, loss_ce: 0.006572
2022-01-21 20:38:28,199 iteration 6510 : loss : 0.013160, loss_ce: 0.004300
2022-01-21 20:38:29,449 iteration 6511 : loss : 0.011241, loss_ce: 0.004115
 96%|███████████████████████████▊ | 383/400 [2:36:45<06:43, 23.74s/it]2022-01-21 20:38:30,782 iteration 6512 : loss : 0.012930, loss_ce: 0.004557
2022-01-21 20:38:32,115 iteration 6513 : loss : 0.015178, loss_ce: 0.005416
2022-01-21 20:38:33,544 iteration 6514 : loss : 0.011373, loss_ce: 0.003621
2022-01-21 20:38:34,930 iteration 6515 : loss : 0.020058, loss_ce: 0.008443
2022-01-21 20:38:36,290 iteration 6516 : loss : 0.018000, loss_ce: 0.007966
2022-01-21 20:38:37,605 iteration 6517 : loss : 0.027919, loss_ce: 0.004932
2022-01-21 20:38:38,936 iteration 6518 : loss : 0.011470, loss_ce: 0.003864
2022-01-21 20:38:40,258 iteration 6519 : loss : 0.013236, loss_ce: 0.003951
2022-01-21 20:38:41,634 iteration 6520 : loss : 0.013310, loss_ce: 0.004271
2022-01-21 20:38:42,925 iteration 6521 : loss : 0.019402, loss_ce: 0.008426
2022-01-21 20:38:44,272 iteration 6522 : loss : 0.012423, loss_ce: 0.004792
2022-01-21 20:38:45,528 iteration 6523 : loss : 0.009838, loss_ce: 0.003807
2022-01-21 20:38:46,902 iteration 6524 : loss : 0.015682, loss_ce: 0.006879
2022-01-21 20:38:48,241 iteration 6525 : loss : 0.018025, loss_ce: 0.006777
2022-01-21 20:38:49,577 iteration 6526 : loss : 0.013191, loss_ce: 0.005337
2022-01-21 20:38:50,831 iteration 6527 : loss : 0.011651, loss_ce: 0.005094
2022-01-21 20:38:52,117 iteration 6528 : loss : 0.015294, loss_ce: 0.004532
 96%|███████████████████████████▊ | 384/400 [2:37:07<06:14, 23.42s/it]2022-01-21 20:38:53,534 iteration 6529 : loss : 0.018351, loss_ce: 0.005808
2022-01-21 20:38:54,888 iteration 6530 : loss : 0.013997, loss_ce: 0.004775
2022-01-21 20:38:56,160 iteration 6531 : loss : 0.011990, loss_ce: 0.003445
2022-01-21 20:38:57,511 iteration 6532 : loss : 0.017476, loss_ce: 0.006279
2022-01-21 20:38:58,766 iteration 6533 : loss : 0.008174, loss_ce: 0.003195
2022-01-21 20:39:00,093 iteration 6534 : loss : 0.014987, loss_ce: 0.006750
2022-01-21 20:39:01,438 iteration 6535 : loss : 0.020926, loss_ce: 0.011200
2022-01-21 20:39:02,792 iteration 6536 : loss : 0.013059, loss_ce: 0.004071
2022-01-21 20:39:04,140 iteration 6537 : loss : 0.019836, loss_ce: 0.006025
2022-01-21 20:39:05,494 iteration 6538 : loss : 0.012289, loss_ce: 0.003410
2022-01-21 20:39:06,870 iteration 6539 : loss : 0.015865, loss_ce: 0.007910
2022-01-21 20:39:08,118 iteration 6540 : loss : 0.009566, loss_ce: 0.003947
2022-01-21 20:39:09,409 iteration 6541 : loss : 0.017310, loss_ce: 0.011383
2022-01-21 20:39:10,820 iteration 6542 : loss : 0.011331, loss_ce: 0.003741
2022-01-21 20:39:12,116 iteration 6543 : loss : 0.010373, loss_ce: 0.003286
2022-01-21 20:39:13,474 iteration 6544 : loss : 0.029134, loss_ce: 0.010379
2022-01-21 20:39:13,475 Training Data Eval:
2022-01-21 20:39:20,003   Average segmentation loss on training set: 0.0071
2022-01-21 20:39:20,003 Validation Data Eval:
2022-01-21 20:39:22,245   Average segmentation loss on validation set: 0.0734
2022-01-21 20:39:23,648 iteration 6545 : loss : 0.014628, loss_ce: 0.005726
 96%|███████████████████████████▉ | 385/400 [2:37:39<06:27, 25.85s/it]2022-01-21 20:39:25,151 iteration 6546 : loss : 0.013503, loss_ce: 0.005541
2022-01-21 20:39:26,477 iteration 6547 : loss : 0.019638, loss_ce: 0.007797
2022-01-21 20:39:27,835 iteration 6548 : loss : 0.013171, loss_ce: 0.005161
2022-01-21 20:39:29,131 iteration 6549 : loss : 0.013029, loss_ce: 0.005139
2022-01-21 20:39:30,498 iteration 6550 : loss : 0.014806, loss_ce: 0.004987
2022-01-21 20:39:31,887 iteration 6551 : loss : 0.014696, loss_ce: 0.006997
2022-01-21 20:39:33,317 iteration 6552 : loss : 0.020203, loss_ce: 0.006906
2022-01-21 20:39:34,782 iteration 6553 : loss : 0.018189, loss_ce: 0.005644
2022-01-21 20:39:36,138 iteration 6554 : loss : 0.017603, loss_ce: 0.005639
2022-01-21 20:39:37,477 iteration 6555 : loss : 0.010644, loss_ce: 0.004571
2022-01-21 20:39:38,811 iteration 6556 : loss : 0.014463, loss_ce: 0.003558
2022-01-21 20:39:40,041 iteration 6557 : loss : 0.008536, loss_ce: 0.003544
2022-01-21 20:39:41,359 iteration 6558 : loss : 0.013929, loss_ce: 0.004294
2022-01-21 20:39:42,607 iteration 6559 : loss : 0.011845, loss_ce: 0.004259
2022-01-21 20:39:43,932 iteration 6560 : loss : 0.016274, loss_ce: 0.007887
2022-01-21 20:39:45,294 iteration 6561 : loss : 0.016119, loss_ce: 0.004649
2022-01-21 20:39:46,583 iteration 6562 : loss : 0.011901, loss_ce: 0.004445
 96%|███████████████████████████▉ | 386/400 [2:38:02<05:49, 24.98s/it]2022-01-21 20:39:48,077 iteration 6563 : loss : 0.019356, loss_ce: 0.008576
2022-01-21 20:39:49,389 iteration 6564 : loss : 0.016178, loss_ce: 0.007141
2022-01-21 20:39:50,666 iteration 6565 : loss : 0.014300, loss_ce: 0.003316
2022-01-21 20:39:51,934 iteration 6566 : loss : 0.010106, loss_ce: 0.004089
2022-01-21 20:39:53,177 iteration 6567 : loss : 0.011650, loss_ce: 0.004448
2022-01-21 20:39:54,476 iteration 6568 : loss : 0.019593, loss_ce: 0.008219
2022-01-21 20:39:55,802 iteration 6569 : loss : 0.010197, loss_ce: 0.003768
2022-01-21 20:39:57,076 iteration 6570 : loss : 0.010567, loss_ce: 0.005355
2022-01-21 20:39:58,380 iteration 6571 : loss : 0.013500, loss_ce: 0.004179
2022-01-21 20:39:59,624 iteration 6572 : loss : 0.012441, loss_ce: 0.005275
2022-01-21 20:40:01,010 iteration 6573 : loss : 0.012900, loss_ce: 0.004255
2022-01-21 20:40:02,410 iteration 6574 : loss : 0.011372, loss_ce: 0.004693
2022-01-21 20:40:03,816 iteration 6575 : loss : 0.024188, loss_ce: 0.005504
2022-01-21 20:40:05,110 iteration 6576 : loss : 0.013363, loss_ce: 0.005388
2022-01-21 20:40:06,453 iteration 6577 : loss : 0.018928, loss_ce: 0.003463
2022-01-21 20:40:07,731 iteration 6578 : loss : 0.013889, loss_ce: 0.005976
2022-01-21 20:40:09,065 iteration 6579 : loss : 0.018557, loss_ce: 0.006567
 97%|████████████████████████████ | 387/400 [2:38:24<05:14, 24.23s/it]2022-01-21 20:40:10,443 iteration 6580 : loss : 0.017159, loss_ce: 0.005083
2022-01-21 20:40:11,746 iteration 6581 : loss : 0.011917, loss_ce: 0.003785
2022-01-21 20:40:13,139 iteration 6582 : loss : 0.015767, loss_ce: 0.005162
2022-01-21 20:40:14,471 iteration 6583 : loss : 0.014577, loss_ce: 0.004799
2022-01-21 20:40:15,821 iteration 6584 : loss : 0.013215, loss_ce: 0.005324
2022-01-21 20:40:17,204 iteration 6585 : loss : 0.019886, loss_ce: 0.008262
2022-01-21 20:40:18,565 iteration 6586 : loss : 0.020709, loss_ce: 0.007331
2022-01-21 20:40:19,879 iteration 6587 : loss : 0.014265, loss_ce: 0.005951
2022-01-21 20:40:21,223 iteration 6588 : loss : 0.015141, loss_ce: 0.006423
2022-01-21 20:40:22,494 iteration 6589 : loss : 0.022229, loss_ce: 0.007201
2022-01-21 20:40:23,884 iteration 6590 : loss : 0.014723, loss_ce: 0.006935
2022-01-21 20:40:25,274 iteration 6591 : loss : 0.026161, loss_ce: 0.012481
2022-01-21 20:40:26,573 iteration 6592 : loss : 0.010966, loss_ce: 0.004256
2022-01-21 20:40:27,983 iteration 6593 : loss : 0.018436, loss_ce: 0.003376
2022-01-21 20:40:29,305 iteration 6594 : loss : 0.013057, loss_ce: 0.006622
2022-01-21 20:40:30,613 iteration 6595 : loss : 0.021770, loss_ce: 0.006483
2022-01-21 20:40:31,998 iteration 6596 : loss : 0.018968, loss_ce: 0.007775
 97%|████████████████████████████▏| 388/400 [2:38:47<04:46, 23.84s/it]2022-01-21 20:40:33,364 iteration 6597 : loss : 0.016281, loss_ce: 0.006493
2022-01-21 20:40:34,638 iteration 6598 : loss : 0.017184, loss_ce: 0.003505
2022-01-21 20:40:35,985 iteration 6599 : loss : 0.013734, loss_ce: 0.005793
2022-01-21 20:40:37,199 iteration 6600 : loss : 0.009042, loss_ce: 0.003741
2022-01-21 20:40:38,511 iteration 6601 : loss : 0.012092, loss_ce: 0.004065
2022-01-21 20:40:39,793 iteration 6602 : loss : 0.015014, loss_ce: 0.005473
2022-01-21 20:40:41,112 iteration 6603 : loss : 0.014255, loss_ce: 0.005333
2022-01-21 20:40:42,355 iteration 6604 : loss : 0.009187, loss_ce: 0.003835
2022-01-21 20:40:43,683 iteration 6605 : loss : 0.013946, loss_ce: 0.004823
2022-01-21 20:40:45,041 iteration 6606 : loss : 0.012492, loss_ce: 0.004975
2022-01-21 20:40:46,391 iteration 6607 : loss : 0.020494, loss_ce: 0.009162
2022-01-21 20:40:47,744 iteration 6608 : loss : 0.010784, loss_ce: 0.004623
2022-01-21 20:40:49,024 iteration 6609 : loss : 0.011991, loss_ce: 0.004286
2022-01-21 20:40:50,321 iteration 6610 : loss : 0.015191, loss_ce: 0.006464
2022-01-21 20:40:51,620 iteration 6611 : loss : 0.013390, loss_ce: 0.003422
2022-01-21 20:40:52,985 iteration 6612 : loss : 0.015661, loss_ce: 0.006771
2022-01-21 20:40:54,199 iteration 6613 : loss : 0.009440, loss_ce: 0.003635
 97%|████████████████████████████▏| 389/400 [2:39:09<04:16, 23.35s/it]2022-01-21 20:40:55,564 iteration 6614 : loss : 0.013193, loss_ce: 0.005042
2022-01-21 20:40:56,905 iteration 6615 : loss : 0.013546, loss_ce: 0.005598
2022-01-21 20:40:58,217 iteration 6616 : loss : 0.013319, loss_ce: 0.003940
2022-01-21 20:40:59,676 iteration 6617 : loss : 0.016816, loss_ce: 0.006281
2022-01-21 20:41:01,024 iteration 6618 : loss : 0.014719, loss_ce: 0.004645
2022-01-21 20:41:02,454 iteration 6619 : loss : 0.016402, loss_ce: 0.006406
2022-01-21 20:41:03,831 iteration 6620 : loss : 0.020080, loss_ce: 0.009099
2022-01-21 20:41:05,146 iteration 6621 : loss : 0.014616, loss_ce: 0.004257
2022-01-21 20:41:06,458 iteration 6622 : loss : 0.015245, loss_ce: 0.006857
2022-01-21 20:41:07,776 iteration 6623 : loss : 0.018860, loss_ce: 0.006847
2022-01-21 20:41:09,144 iteration 6624 : loss : 0.023321, loss_ce: 0.009495
2022-01-21 20:41:10,535 iteration 6625 : loss : 0.014856, loss_ce: 0.006196
2022-01-21 20:41:11,855 iteration 6626 : loss : 0.018810, loss_ce: 0.004742
2022-01-21 20:41:13,099 iteration 6627 : loss : 0.012306, loss_ce: 0.004070
2022-01-21 20:41:14,411 iteration 6628 : loss : 0.012534, loss_ce: 0.005830
2022-01-21 20:41:15,722 iteration 6629 : loss : 0.011250, loss_ce: 0.005103
2022-01-21 20:41:15,722 Training Data Eval:
2022-01-21 20:41:22,242   Average segmentation loss on training set: 0.0071
2022-01-21 20:41:22,243 Validation Data Eval:
2022-01-21 20:41:24,476   Average segmentation loss on validation set: 0.0639
2022-01-21 20:41:25,843 iteration 6630 : loss : 0.014549, loss_ce: 0.004340
 98%|████████████████████████████▎| 390/400 [2:39:41<04:18, 25.84s/it]2022-01-21 20:41:27,286 iteration 6631 : loss : 0.013913, loss_ce: 0.004669
2022-01-21 20:41:28,627 iteration 6632 : loss : 0.013370, loss_ce: 0.005337
2022-01-21 20:41:29,963 iteration 6633 : loss : 0.015044, loss_ce: 0.003757
2022-01-21 20:41:31,167 iteration 6634 : loss : 0.009614, loss_ce: 0.002922
2022-01-21 20:41:32,442 iteration 6635 : loss : 0.014378, loss_ce: 0.003679
2022-01-21 20:41:33,822 iteration 6636 : loss : 0.016937, loss_ce: 0.006567
2022-01-21 20:41:35,176 iteration 6637 : loss : 0.012664, loss_ce: 0.005227
2022-01-21 20:41:36,551 iteration 6638 : loss : 0.015803, loss_ce: 0.005303
2022-01-21 20:41:37,954 iteration 6639 : loss : 0.019406, loss_ce: 0.006176
2022-01-21 20:41:39,279 iteration 6640 : loss : 0.016959, loss_ce: 0.004865
2022-01-21 20:41:40,571 iteration 6641 : loss : 0.013690, loss_ce: 0.007429
2022-01-21 20:41:41,969 iteration 6642 : loss : 0.013359, loss_ce: 0.005735
2022-01-21 20:41:43,321 iteration 6643 : loss : 0.014355, loss_ce: 0.005964
2022-01-21 20:41:44,650 iteration 6644 : loss : 0.014485, loss_ce: 0.004670
2022-01-21 20:41:45,920 iteration 6645 : loss : 0.010382, loss_ce: 0.004683
2022-01-21 20:41:47,221 iteration 6646 : loss : 0.011116, loss_ce: 0.004608
2022-01-21 20:41:48,449 iteration 6647 : loss : 0.009938, loss_ce: 0.003309
 98%|████████████████████████████▎| 391/400 [2:40:04<03:43, 24.87s/it]2022-01-21 20:41:49,772 iteration 6648 : loss : 0.014958, loss_ce: 0.005044
2022-01-21 20:41:51,156 iteration 6649 : loss : 0.015686, loss_ce: 0.006170
2022-01-21 20:41:52,415 iteration 6650 : loss : 0.014317, loss_ce: 0.005016
2022-01-21 20:41:53,697 iteration 6651 : loss : 0.010288, loss_ce: 0.003355
2022-01-21 20:41:55,102 iteration 6652 : loss : 0.014812, loss_ce: 0.005048
2022-01-21 20:41:56,484 iteration 6653 : loss : 0.014749, loss_ce: 0.005984
2022-01-21 20:41:57,775 iteration 6654 : loss : 0.012583, loss_ce: 0.005173
2022-01-21 20:41:59,122 iteration 6655 : loss : 0.012029, loss_ce: 0.004799
2022-01-21 20:42:00,481 iteration 6656 : loss : 0.011841, loss_ce: 0.004942
2022-01-21 20:42:01,903 iteration 6657 : loss : 0.016826, loss_ce: 0.006443
2022-01-21 20:42:03,257 iteration 6658 : loss : 0.021561, loss_ce: 0.008362
2022-01-21 20:42:04,631 iteration 6659 : loss : 0.021054, loss_ce: 0.007978
2022-01-21 20:42:05,921 iteration 6660 : loss : 0.010542, loss_ce: 0.003430
2022-01-21 20:42:07,170 iteration 6661 : loss : 0.009442, loss_ce: 0.003388
2022-01-21 20:42:08,512 iteration 6662 : loss : 0.010848, loss_ce: 0.003641
2022-01-21 20:42:09,898 iteration 6663 : loss : 0.018273, loss_ce: 0.006200
2022-01-21 20:42:11,215 iteration 6664 : loss : 0.011661, loss_ce: 0.003864
 98%|████████████████████████████▍| 392/400 [2:40:26<03:13, 24.24s/it]2022-01-21 20:42:12,600 iteration 6665 : loss : 0.018399, loss_ce: 0.006578
2022-01-21 20:42:13,953 iteration 6666 : loss : 0.017706, loss_ce: 0.006500
2022-01-21 20:42:15,246 iteration 6667 : loss : 0.011758, loss_ce: 0.004094
2022-01-21 20:42:16,472 iteration 6668 : loss : 0.008475, loss_ce: 0.003489
2022-01-21 20:42:17,812 iteration 6669 : loss : 0.012827, loss_ce: 0.004358
2022-01-21 20:42:19,076 iteration 6670 : loss : 0.013447, loss_ce: 0.004791
2022-01-21 20:42:20,474 iteration 6671 : loss : 0.020470, loss_ce: 0.010439
2022-01-21 20:42:21,795 iteration 6672 : loss : 0.012947, loss_ce: 0.005920
2022-01-21 20:42:23,199 iteration 6673 : loss : 0.013109, loss_ce: 0.005542
2022-01-21 20:42:24,585 iteration 6674 : loss : 0.018779, loss_ce: 0.008100
2022-01-21 20:42:25,883 iteration 6675 : loss : 0.013010, loss_ce: 0.004318
2022-01-21 20:42:27,134 iteration 6676 : loss : 0.009335, loss_ce: 0.003577
2022-01-21 20:42:28,481 iteration 6677 : loss : 0.011785, loss_ce: 0.002637
2022-01-21 20:42:29,896 iteration 6678 : loss : 0.018498, loss_ce: 0.010089
2022-01-21 20:42:31,251 iteration 6679 : loss : 0.013642, loss_ce: 0.004533
2022-01-21 20:42:32,562 iteration 6680 : loss : 0.020758, loss_ce: 0.008465
2022-01-21 20:42:33,840 iteration 6681 : loss : 0.012293, loss_ce: 0.004345
 98%|████████████████████████████▍| 393/400 [2:40:49<02:46, 23.75s/it]2022-01-21 20:42:35,204 iteration 6682 : loss : 0.012765, loss_ce: 0.003840
2022-01-21 20:42:36,575 iteration 6683 : loss : 0.014781, loss_ce: 0.005177
2022-01-21 20:42:37,928 iteration 6684 : loss : 0.037309, loss_ce: 0.004438
2022-01-21 20:42:39,239 iteration 6685 : loss : 0.013129, loss_ce: 0.004804
2022-01-21 20:42:40,584 iteration 6686 : loss : 0.011488, loss_ce: 0.003735
2022-01-21 20:42:41,924 iteration 6687 : loss : 0.016244, loss_ce: 0.006408
2022-01-21 20:42:43,266 iteration 6688 : loss : 0.014252, loss_ce: 0.004440
2022-01-21 20:42:44,563 iteration 6689 : loss : 0.014443, loss_ce: 0.005626
2022-01-21 20:42:45,950 iteration 6690 : loss : 0.015036, loss_ce: 0.005521
2022-01-21 20:42:47,221 iteration 6691 : loss : 0.014950, loss_ce: 0.006298
2022-01-21 20:42:48,490 iteration 6692 : loss : 0.012390, loss_ce: 0.007399
2022-01-21 20:42:49,832 iteration 6693 : loss : 0.013339, loss_ce: 0.004682
2022-01-21 20:42:51,089 iteration 6694 : loss : 0.008788, loss_ce: 0.003760
2022-01-21 20:42:52,384 iteration 6695 : loss : 0.011567, loss_ce: 0.003087
2022-01-21 20:42:53,701 iteration 6696 : loss : 0.012644, loss_ce: 0.006838
2022-01-21 20:42:55,025 iteration 6697 : loss : 0.014444, loss_ce: 0.004748
2022-01-21 20:42:56,272 iteration 6698 : loss : 0.021422, loss_ce: 0.008858
 98%|████████████████████████████▌| 394/400 [2:41:11<02:20, 23.36s/it]2022-01-21 20:42:57,651 iteration 6699 : loss : 0.016032, loss_ce: 0.004401
2022-01-21 20:42:59,028 iteration 6700 : loss : 0.016521, loss_ce: 0.007283
2022-01-21 20:43:00,438 iteration 6701 : loss : 0.031356, loss_ce: 0.007969
2022-01-21 20:43:01,733 iteration 6702 : loss : 0.013275, loss_ce: 0.003973
2022-01-21 20:43:03,164 iteration 6703 : loss : 0.017511, loss_ce: 0.005389
2022-01-21 20:43:04,501 iteration 6704 : loss : 0.011235, loss_ce: 0.005655
2022-01-21 20:43:05,772 iteration 6705 : loss : 0.011582, loss_ce: 0.003792
2022-01-21 20:43:07,069 iteration 6706 : loss : 0.013578, loss_ce: 0.004734
2022-01-21 20:43:08,388 iteration 6707 : loss : 0.011679, loss_ce: 0.004046
2022-01-21 20:43:09,629 iteration 6708 : loss : 0.009081, loss_ce: 0.002648
2022-01-21 20:43:10,900 iteration 6709 : loss : 0.012857, loss_ce: 0.003478
2022-01-21 20:43:12,229 iteration 6710 : loss : 0.018048, loss_ce: 0.007542
2022-01-21 20:43:13,546 iteration 6711 : loss : 0.012412, loss_ce: 0.005043
2022-01-21 20:43:14,904 iteration 6712 : loss : 0.012753, loss_ce: 0.004827
2022-01-21 20:43:16,198 iteration 6713 : loss : 0.012639, loss_ce: 0.003915
2022-01-21 20:43:17,510 iteration 6714 : loss : 0.012210, loss_ce: 0.005176
2022-01-21 20:43:17,510 Training Data Eval:
2022-01-21 20:43:24,020   Average segmentation loss on training set: 0.0072
2022-01-21 20:43:24,020 Validation Data Eval:
2022-01-21 20:43:26,255   Average segmentation loss on validation set: 0.0671
2022-01-21 20:43:27,537 iteration 6715 : loss : 0.007661, loss_ce: 0.002308
 99%|████████████████████████████▋| 395/400 [2:41:43<02:08, 25.73s/it]2022-01-21 20:43:28,819 iteration 6716 : loss : 0.010843, loss_ce: 0.003565
2022-01-21 20:43:30,171 iteration 6717 : loss : 0.016826, loss_ce: 0.004669
2022-01-21 20:43:31,558 iteration 6718 : loss : 0.021597, loss_ce: 0.010324
2022-01-21 20:43:32,933 iteration 6719 : loss : 0.020026, loss_ce: 0.006874
2022-01-21 20:43:34,285 iteration 6720 : loss : 0.021632, loss_ce: 0.004565
2022-01-21 20:43:35,645 iteration 6721 : loss : 0.014772, loss_ce: 0.006580
2022-01-21 20:43:36,954 iteration 6722 : loss : 0.010595, loss_ce: 0.004415
2022-01-21 20:43:38,290 iteration 6723 : loss : 0.015921, loss_ce: 0.006465
2022-01-21 20:43:39,564 iteration 6724 : loss : 0.011999, loss_ce: 0.004775
2022-01-21 20:43:40,881 iteration 6725 : loss : 0.008733, loss_ce: 0.002874
2022-01-21 20:43:42,124 iteration 6726 : loss : 0.009774, loss_ce: 0.003403
2022-01-21 20:43:43,544 iteration 6727 : loss : 0.025301, loss_ce: 0.009340
2022-01-21 20:43:44,829 iteration 6728 : loss : 0.013636, loss_ce: 0.005251
2022-01-21 20:43:46,199 iteration 6729 : loss : 0.017239, loss_ce: 0.006112
2022-01-21 20:43:47,627 iteration 6730 : loss : 0.016029, loss_ce: 0.006759
2022-01-21 20:43:49,000 iteration 6731 : loss : 0.016565, loss_ce: 0.005904
2022-01-21 20:43:50,323 iteration 6732 : loss : 0.008758, loss_ce: 0.003569
 99%|████████████████████████████▋| 396/400 [2:42:05<01:39, 24.85s/it]2022-01-21 20:43:51,634 iteration 6733 : loss : 0.008594, loss_ce: 0.003601
2022-01-21 20:43:52,942 iteration 6734 : loss : 0.013523, loss_ce: 0.003516
2022-01-21 20:43:54,296 iteration 6735 : loss : 0.019752, loss_ce: 0.006622
2022-01-21 20:43:55,604 iteration 6736 : loss : 0.011023, loss_ce: 0.005037
2022-01-21 20:43:56,871 iteration 6737 : loss : 0.011812, loss_ce: 0.006003
2022-01-21 20:43:58,121 iteration 6738 : loss : 0.012684, loss_ce: 0.003940
2022-01-21 20:43:59,443 iteration 6739 : loss : 0.015731, loss_ce: 0.006935
2022-01-21 20:44:00,800 iteration 6740 : loss : 0.018597, loss_ce: 0.006351
2022-01-21 20:44:02,138 iteration 6741 : loss : 0.014840, loss_ce: 0.005938
2022-01-21 20:44:03,436 iteration 6742 : loss : 0.011648, loss_ce: 0.005469
2022-01-21 20:44:04,699 iteration 6743 : loss : 0.010389, loss_ce: 0.002382
2022-01-21 20:44:06,064 iteration 6744 : loss : 0.020442, loss_ce: 0.008412
2022-01-21 20:44:07,382 iteration 6745 : loss : 0.011427, loss_ce: 0.005208
2022-01-21 20:44:08,637 iteration 6746 : loss : 0.008300, loss_ce: 0.002480
2022-01-21 20:44:09,918 iteration 6747 : loss : 0.008502, loss_ce: 0.002625
2022-01-21 20:44:11,264 iteration 6748 : loss : 0.009906, loss_ce: 0.004319
2022-01-21 20:44:12,570 iteration 6749 : loss : 0.010707, loss_ce: 0.002861
 99%|████████████████████████████▊| 397/400 [2:42:28<01:12, 24.07s/it]2022-01-21 20:44:13,926 iteration 6750 : loss : 0.011313, loss_ce: 0.005405
2022-01-21 20:44:15,311 iteration 6751 : loss : 0.010266, loss_ce: 0.004012
2022-01-21 20:44:16,563 iteration 6752 : loss : 0.009181, loss_ce: 0.003137
2022-01-21 20:44:17,885 iteration 6753 : loss : 0.012857, loss_ce: 0.005744
2022-01-21 20:44:19,239 iteration 6754 : loss : 0.010431, loss_ce: 0.003545
2022-01-21 20:44:20,526 iteration 6755 : loss : 0.012275, loss_ce: 0.003450
2022-01-21 20:44:21,812 iteration 6756 : loss : 0.013149, loss_ce: 0.005750
2022-01-21 20:44:23,205 iteration 6757 : loss : 0.011531, loss_ce: 0.003686
2022-01-21 20:44:24,493 iteration 6758 : loss : 0.012018, loss_ce: 0.005449
2022-01-21 20:44:25,823 iteration 6759 : loss : 0.012651, loss_ce: 0.005484
2022-01-21 20:44:27,215 iteration 6760 : loss : 0.019738, loss_ce: 0.003313
2022-01-21 20:44:28,535 iteration 6761 : loss : 0.011902, loss_ce: 0.004399
2022-01-21 20:44:29,838 iteration 6762 : loss : 0.012283, loss_ce: 0.004032
2022-01-21 20:44:31,212 iteration 6763 : loss : 0.015079, loss_ce: 0.006575
2022-01-21 20:44:32,500 iteration 6764 : loss : 0.016805, loss_ce: 0.007169
2022-01-21 20:44:33,875 iteration 6765 : loss : 0.015848, loss_ce: 0.006457
2022-01-21 20:44:35,166 iteration 6766 : loss : 0.009674, loss_ce: 0.004272
100%|████████████████████████████▊| 398/400 [2:42:50<00:47, 23.62s/it]2022-01-21 20:44:36,520 iteration 6767 : loss : 0.012957, loss_ce: 0.004565
2022-01-21 20:44:37,931 iteration 6768 : loss : 0.019978, loss_ce: 0.007595
2022-01-21 20:44:39,274 iteration 6769 : loss : 0.014136, loss_ce: 0.006206
2022-01-21 20:44:40,576 iteration 6770 : loss : 0.013167, loss_ce: 0.006431
2022-01-21 20:44:41,995 iteration 6771 : loss : 0.017442, loss_ce: 0.003672
2022-01-21 20:44:43,289 iteration 6772 : loss : 0.010727, loss_ce: 0.003741
2022-01-21 20:44:44,485 iteration 6773 : loss : 0.009596, loss_ce: 0.002937
2022-01-21 20:44:45,833 iteration 6774 : loss : 0.019678, loss_ce: 0.005948
2022-01-21 20:44:47,188 iteration 6775 : loss : 0.021433, loss_ce: 0.009616
2022-01-21 20:44:48,497 iteration 6776 : loss : 0.015893, loss_ce: 0.004856
2022-01-21 20:44:49,894 iteration 6777 : loss : 0.020266, loss_ce: 0.011359
2022-01-21 20:44:51,205 iteration 6778 : loss : 0.009457, loss_ce: 0.003360
2022-01-21 20:44:52,609 iteration 6779 : loss : 0.016109, loss_ce: 0.005761
2022-01-21 20:44:53,951 iteration 6780 : loss : 0.012573, loss_ce: 0.006117
2022-01-21 20:44:55,322 iteration 6781 : loss : 0.019762, loss_ce: 0.008489
2022-01-21 20:44:56,697 iteration 6782 : loss : 0.011386, loss_ce: 0.004489
2022-01-21 20:44:57,997 iteration 6783 : loss : 0.015832, loss_ce: 0.005842
100%|████████████████████████████▉| 399/400 [2:43:13<00:23, 23.39s/it]2022-01-21 20:44:59,440 iteration 6784 : loss : 0.018339, loss_ce: 0.006720
2022-01-21 20:45:00,797 iteration 6785 : loss : 0.017008, loss_ce: 0.005983
2022-01-21 20:45:02,077 iteration 6786 : loss : 0.009972, loss_ce: 0.003916
2022-01-21 20:45:03,366 iteration 6787 : loss : 0.010360, loss_ce: 0.003464
2022-01-21 20:45:04,716 iteration 6788 : loss : 0.014352, loss_ce: 0.005528
2022-01-21 20:45:06,047 iteration 6789 : loss : 0.014015, loss_ce: 0.004141
2022-01-21 20:45:07,345 iteration 6790 : loss : 0.013971, loss_ce: 0.005830
2022-01-21 20:45:08,690 iteration 6791 : loss : 0.011395, loss_ce: 0.004538
2022-01-21 20:45:09,963 iteration 6792 : loss : 0.013645, loss_ce: 0.006482
2022-01-21 20:45:11,353 iteration 6793 : loss : 0.021046, loss_ce: 0.006565
2022-01-21 20:45:12,683 iteration 6794 : loss : 0.020814, loss_ce: 0.006962
2022-01-21 20:45:14,046 iteration 6795 : loss : 0.012648, loss_ce: 0.004673
2022-01-21 20:45:15,430 iteration 6796 : loss : 0.022384, loss_ce: 0.012460
2022-01-21 20:45:16,673 iteration 6797 : loss : 0.009412, loss_ce: 0.003136
2022-01-21 20:45:18,034 iteration 6798 : loss : 0.012922, loss_ce: 0.004130
2022-01-21 20:45:19,447 iteration 6799 : loss : 0.017065, loss_ce: 0.009407
2022-01-21 20:45:19,447 Training Data Eval:
2022-01-21 20:45:25,959   Average segmentation loss on training set: 0.0069
2022-01-21 20:45:25,959 Validation Data Eval:
2022-01-21 20:45:28,187   Average segmentation loss on validation set: 0.0638
2022-01-21 20:45:29,458 iteration 6800 : loss : 0.009904, loss_ce: 0.002538
100%|█████████████████████████████| 400/400 [2:43:45<00:00, 25.81s/it]100%|█████████████████████████████| 400/400 [2:43:45<00:00, 24.56s/it]
