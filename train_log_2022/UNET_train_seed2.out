2022-01-20 20:53:35,073 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:53:35,074 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:53:35,074 ============================================================
2022-01-20 20:53:35,074 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:53:35,074 ============================================================
2022-01-20 20:53:35,074 Loading data...
2022-01-20 20:53:35,074 Reading NCI - RUNMC images...
2022-01-20 20:53:35,074 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-20 20:53:35,075 Already preprocessed this configuration. Loading now!
2022-01-20 20:53:35,119 Training Images: (256, 256, 286)
2022-01-20 20:53:35,119 Training Labels: (256, 256, 286)
2022-01-20 20:53:35,119 Validation Images: (256, 256, 98)
2022-01-20 20:53:35,119 Validation Labels: (256, 256, 98)
2022-01-20 20:53:35,119 ============================================================
2022-01-20 20:53:35,174 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-20 20:53:37,594 iteration 1 : loss : 0.999336, loss_ce: 1.240370
2022-01-20 20:53:38,196 iteration 2 : loss : 0.968046, loss_ce: 1.202533
2022-01-20 20:53:38,859 iteration 3 : loss : 0.927837, loss_ce: 1.136674
2022-01-20 20:53:39,454 iteration 4 : loss : 0.915072, loss_ce: 1.096151
2022-01-20 20:53:39,977 iteration 5 : loss : 0.886803, loss_ce: 1.033960
2022-01-20 20:53:40,548 iteration 6 : loss : 0.843604, loss_ce: 0.966221
2022-01-20 20:53:41,155 iteration 7 : loss : 0.838019, loss_ce: 0.965068
2022-01-20 20:53:41,817 iteration 8 : loss : 0.809473, loss_ce: 0.910309
2022-01-20 20:53:42,350 iteration 9 : loss : 0.792153, loss_ce: 0.865361
2022-01-20 20:53:42,888 iteration 10 : loss : 0.750709, loss_ce: 0.813241
2022-01-20 20:53:43,411 iteration 11 : loss : 0.739647, loss_ce: 0.782065
2022-01-20 20:53:43,985 iteration 12 : loss : 0.714701, loss_ce: 0.756846
2022-01-20 20:53:44,609 iteration 13 : loss : 0.701376, loss_ce: 0.758388
2022-01-20 20:53:45,132 iteration 14 : loss : 0.691750, loss_ce: 0.726645
2022-01-20 20:53:45,747 iteration 15 : loss : 0.683590, loss_ce: 0.705533
2022-01-20 20:53:46,311 iteration 16 : loss : 0.668624, loss_ce: 0.682136
2022-01-20 20:53:46,865 iteration 17 : loss : 0.645510, loss_ce: 0.673358
  0%|                               | 1/400 [00:11<1:18:07, 11.75s/it]2022-01-20 20:53:47,470 iteration 18 : loss : 0.645810, loss_ce: 0.647074
2022-01-20 20:53:48,057 iteration 19 : loss : 0.631709, loss_ce: 0.636154
2022-01-20 20:53:48,626 iteration 20 : loss : 0.616936, loss_ce: 0.620174
2022-01-20 20:53:49,268 iteration 21 : loss : 0.608617, loss_ce: 0.607350
2022-01-20 20:53:49,828 iteration 22 : loss : 0.604661, loss_ce: 0.601758
2022-01-20 20:53:50,420 iteration 23 : loss : 0.580588, loss_ce: 0.573000
2022-01-20 20:53:50,942 iteration 24 : loss : 0.582580, loss_ce: 0.580671
2022-01-20 20:53:51,428 iteration 25 : loss : 0.596003, loss_ce: 0.583339
2022-01-20 20:53:51,948 iteration 26 : loss : 0.591259, loss_ce: 0.563285
2022-01-20 20:53:52,522 iteration 27 : loss : 0.545931, loss_ce: 0.531374
2022-01-20 20:53:53,077 iteration 28 : loss : 0.561335, loss_ce: 0.534419
2022-01-20 20:53:53,767 iteration 29 : loss : 0.558939, loss_ce: 0.534525
2022-01-20 20:53:54,376 iteration 30 : loss : 0.550016, loss_ce: 0.515976
2022-01-20 20:53:54,900 iteration 31 : loss : 0.520536, loss_ce: 0.493851
2022-01-20 20:53:55,446 iteration 32 : loss : 0.531921, loss_ce: 0.496451
2022-01-20 20:53:56,084 iteration 33 : loss : 0.509127, loss_ce: 0.481161
2022-01-20 20:53:56,627 iteration 34 : loss : 0.528039, loss_ce: 0.481309
  0%|▏                              | 2/400 [00:21<1:10:06, 10.57s/it]2022-01-20 20:53:57,281 iteration 35 : loss : 0.488280, loss_ce: 0.464877
2022-01-20 20:53:57,860 iteration 36 : loss : 0.493410, loss_ce: 0.457164
2022-01-20 20:53:58,473 iteration 37 : loss : 0.475576, loss_ce: 0.445374
2022-01-20 20:53:59,149 iteration 38 : loss : 0.478191, loss_ce: 0.433390
2022-01-20 20:53:59,737 iteration 39 : loss : 0.549126, loss_ce: 0.481397
2022-01-20 20:54:00,357 iteration 40 : loss : 0.454730, loss_ce: 0.424263
2022-01-20 20:54:00,886 iteration 41 : loss : 0.480616, loss_ce: 0.424984
2022-01-20 20:54:01,586 iteration 42 : loss : 0.481390, loss_ce: 0.438011
2022-01-20 20:54:02,111 iteration 43 : loss : 0.505546, loss_ce: 0.432197
2022-01-20 20:54:02,713 iteration 44 : loss : 0.464081, loss_ce: 0.401533
2022-01-20 20:54:03,330 iteration 45 : loss : 0.534453, loss_ce: 0.456820
2022-01-20 20:54:03,825 iteration 46 : loss : 0.469275, loss_ce: 0.396875
2022-01-20 20:54:04,386 iteration 47 : loss : 0.489743, loss_ce: 0.389387
2022-01-20 20:54:04,986 iteration 48 : loss : 0.433122, loss_ce: 0.371371
2022-01-20 20:54:05,568 iteration 49 : loss : 0.458890, loss_ce: 0.371179
2022-01-20 20:54:06,190 iteration 50 : loss : 0.447156, loss_ce: 0.363846
2022-01-20 20:54:06,785 iteration 51 : loss : 0.422732, loss_ce: 0.357282
  1%|▏                              | 3/400 [00:31<1:08:41, 10.38s/it]2022-01-20 20:54:07,328 iteration 52 : loss : 0.428154, loss_ce: 0.359182
2022-01-20 20:54:07,823 iteration 53 : loss : 0.418499, loss_ce: 0.355256
2022-01-20 20:54:08,424 iteration 54 : loss : 0.390826, loss_ce: 0.332395
2022-01-20 20:54:09,014 iteration 55 : loss : 0.479800, loss_ce: 0.385077
2022-01-20 20:54:09,627 iteration 56 : loss : 0.421847, loss_ce: 0.339989
2022-01-20 20:54:10,231 iteration 57 : loss : 0.436511, loss_ce: 0.345414
2022-01-20 20:54:10,821 iteration 58 : loss : 0.401796, loss_ce: 0.320598
2022-01-20 20:54:11,385 iteration 59 : loss : 0.407774, loss_ce: 0.315220
2022-01-20 20:54:12,025 iteration 60 : loss : 0.412449, loss_ce: 0.305229
2022-01-20 20:54:12,671 iteration 61 : loss : 0.369428, loss_ce: 0.296237
2022-01-20 20:54:13,253 iteration 62 : loss : 0.385010, loss_ce: 0.293029
2022-01-20 20:54:13,767 iteration 63 : loss : 0.356104, loss_ce: 0.288805
2022-01-20 20:54:14,331 iteration 64 : loss : 0.410435, loss_ce: 0.333307
2022-01-20 20:54:14,892 iteration 65 : loss : 0.393095, loss_ce: 0.295602
2022-01-20 20:54:15,513 iteration 66 : loss : 0.380470, loss_ce: 0.295609
2022-01-20 20:54:16,043 iteration 67 : loss : 0.388117, loss_ce: 0.296539
2022-01-20 20:54:16,609 iteration 68 : loss : 0.425065, loss_ce: 0.307173
  1%|▎                              | 4/400 [00:41<1:07:04, 10.16s/it]2022-01-20 20:54:17,225 iteration 69 : loss : 0.400898, loss_ce: 0.280563
2022-01-20 20:54:17,826 iteration 70 : loss : 0.423044, loss_ce: 0.311768
2022-01-20 20:54:18,362 iteration 71 : loss : 0.360930, loss_ce: 0.261968
2022-01-20 20:54:18,986 iteration 72 : loss : 0.362135, loss_ce: 0.256075
2022-01-20 20:54:19,557 iteration 73 : loss : 0.346863, loss_ce: 0.260606
2022-01-20 20:54:20,208 iteration 74 : loss : 0.349661, loss_ce: 0.252400
2022-01-20 20:54:20,798 iteration 75 : loss : 0.370584, loss_ce: 0.273479
2022-01-20 20:54:21,430 iteration 76 : loss : 0.337146, loss_ce: 0.240658
2022-01-20 20:54:22,087 iteration 77 : loss : 0.344613, loss_ce: 0.238594
2022-01-20 20:54:22,719 iteration 78 : loss : 0.308219, loss_ce: 0.232965
2022-01-20 20:54:23,255 iteration 79 : loss : 0.311268, loss_ce: 0.216761
2022-01-20 20:54:23,884 iteration 80 : loss : 0.386977, loss_ce: 0.243539
2022-01-20 20:54:24,454 iteration 81 : loss : 0.322228, loss_ce: 0.216479
2022-01-20 20:54:25,031 iteration 82 : loss : 0.362063, loss_ce: 0.249279
2022-01-20 20:54:25,667 iteration 83 : loss : 0.310456, loss_ce: 0.208622
2022-01-20 20:54:26,222 iteration 84 : loss : 0.332982, loss_ce: 0.230348
2022-01-20 20:54:26,222 Training Data Eval:
2022-01-20 20:54:28,871   Average segmentation loss on training set: 0.3054
2022-01-20 20:54:28,871 Validation Data Eval:
2022-01-20 20:54:29,979   Average segmentation loss on validation set: 0.3058
2022-01-20 20:54:30,527 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 20:54:31,151 iteration 85 : loss : 0.296743, loss_ce: 0.209058
  1%|▍                              | 5/400 [00:56<1:17:17, 11.74s/it]2022-01-20 20:54:31,744 iteration 86 : loss : 0.358182, loss_ce: 0.223745
2022-01-20 20:54:32,236 iteration 87 : loss : 0.330561, loss_ce: 0.219758
2022-01-20 20:54:32,773 iteration 88 : loss : 0.295125, loss_ce: 0.191133
2022-01-20 20:54:33,397 iteration 89 : loss : 0.297831, loss_ce: 0.205230
2022-01-20 20:54:33,932 iteration 90 : loss : 0.279112, loss_ce: 0.191606
2022-01-20 20:54:34,521 iteration 91 : loss : 0.330038, loss_ce: 0.214188
2022-01-20 20:54:35,079 iteration 92 : loss : 0.285182, loss_ce: 0.186796
2022-01-20 20:54:35,716 iteration 93 : loss : 0.305441, loss_ce: 0.200359
2022-01-20 20:54:36,351 iteration 94 : loss : 0.274969, loss_ce: 0.193285
2022-01-20 20:54:36,909 iteration 95 : loss : 0.306076, loss_ce: 0.189792
2022-01-20 20:54:37,433 iteration 96 : loss : 0.293320, loss_ce: 0.183093
2022-01-20 20:54:37,956 iteration 97 : loss : 0.256648, loss_ce: 0.172801
2022-01-20 20:54:38,517 iteration 98 : loss : 0.323925, loss_ce: 0.193387
2022-01-20 20:54:39,202 iteration 99 : loss : 0.278917, loss_ce: 0.184845
2022-01-20 20:54:39,900 iteration 100 : loss : 0.293901, loss_ce: 0.184767
2022-01-20 20:54:40,450 iteration 101 : loss : 0.348240, loss_ce: 0.207417
2022-01-20 20:54:41,023 iteration 102 : loss : 0.287655, loss_ce: 0.171726
  2%|▍                              | 6/400 [01:05<1:12:56, 11.11s/it]2022-01-20 20:54:41,658 iteration 103 : loss : 0.291696, loss_ce: 0.173235
2022-01-20 20:54:42,289 iteration 104 : loss : 0.311288, loss_ce: 0.178505
2022-01-20 20:54:42,887 iteration 105 : loss : 0.264255, loss_ce: 0.167129
2022-01-20 20:54:43,490 iteration 106 : loss : 0.278718, loss_ce: 0.164626
2022-01-20 20:54:44,147 iteration 107 : loss : 0.247159, loss_ce: 0.160218
2022-01-20 20:54:44,717 iteration 108 : loss : 0.274568, loss_ce: 0.178180
2022-01-20 20:54:45,309 iteration 109 : loss : 0.255633, loss_ce: 0.156193
2022-01-20 20:54:45,930 iteration 110 : loss : 0.276702, loss_ce: 0.175752
2022-01-20 20:54:46,680 iteration 111 : loss : 0.268936, loss_ce: 0.159269
2022-01-20 20:54:47,238 iteration 112 : loss : 0.324657, loss_ce: 0.187707
2022-01-20 20:54:47,921 iteration 113 : loss : 0.250595, loss_ce: 0.146900
2022-01-20 20:54:48,518 iteration 114 : loss : 0.250304, loss_ce: 0.142403
2022-01-20 20:54:49,038 iteration 115 : loss : 0.227604, loss_ce: 0.137134
2022-01-20 20:54:49,625 iteration 116 : loss : 0.276900, loss_ce: 0.164303
2022-01-20 20:54:50,180 iteration 117 : loss : 0.227212, loss_ce: 0.136861
2022-01-20 20:54:50,817 iteration 118 : loss : 0.264864, loss_ce: 0.142727
2022-01-20 20:54:51,371 iteration 119 : loss : 0.305268, loss_ce: 0.172403
  2%|▌                              | 7/400 [01:16<1:11:07, 10.86s/it]2022-01-20 20:54:52,050 iteration 120 : loss : 0.285979, loss_ce: 0.168894
2022-01-20 20:54:52,671 iteration 121 : loss : 0.312939, loss_ce: 0.171412
2022-01-20 20:54:53,165 iteration 122 : loss : 0.236734, loss_ce: 0.137614
2022-01-20 20:54:53,754 iteration 123 : loss : 0.264612, loss_ce: 0.154784
2022-01-20 20:54:54,316 iteration 124 : loss : 0.256202, loss_ce: 0.144015
2022-01-20 20:54:54,882 iteration 125 : loss : 0.250176, loss_ce: 0.136287
2022-01-20 20:54:55,442 iteration 126 : loss : 0.217978, loss_ce: 0.127666
2022-01-20 20:54:56,024 iteration 127 : loss : 0.252140, loss_ce: 0.145275
2022-01-20 20:54:56,578 iteration 128 : loss : 0.255875, loss_ce: 0.137602
2022-01-20 20:54:57,218 iteration 129 : loss : 0.305454, loss_ce: 0.163795
2022-01-20 20:54:57,705 iteration 130 : loss : 0.232684, loss_ce: 0.134901
2022-01-20 20:54:58,264 iteration 131 : loss : 0.237303, loss_ce: 0.144521
2022-01-20 20:54:58,850 iteration 132 : loss : 0.257761, loss_ce: 0.141106
2022-01-20 20:54:59,436 iteration 133 : loss : 0.304633, loss_ce: 0.184765
2022-01-20 20:55:00,001 iteration 134 : loss : 0.221561, loss_ce: 0.123569
2022-01-20 20:55:00,556 iteration 135 : loss : 0.238280, loss_ce: 0.124023
2022-01-20 20:55:01,205 iteration 136 : loss : 0.243252, loss_ce: 0.140887
  2%|▌                              | 8/400 [01:26<1:08:48, 10.53s/it]2022-01-20 20:55:01,898 iteration 137 : loss : 0.275427, loss_ce: 0.144527
2022-01-20 20:55:02,429 iteration 138 : loss : 0.195478, loss_ce: 0.117011
2022-01-20 20:55:03,092 iteration 139 : loss : 0.254746, loss_ce: 0.117343
2022-01-20 20:55:03,665 iteration 140 : loss : 0.336312, loss_ce: 0.184259
2022-01-20 20:55:04,200 iteration 141 : loss : 0.270643, loss_ce: 0.141606
2022-01-20 20:55:04,767 iteration 142 : loss : 0.233712, loss_ce: 0.123791
2022-01-20 20:55:05,357 iteration 143 : loss : 0.287721, loss_ce: 0.147688
2022-01-20 20:55:05,921 iteration 144 : loss : 0.238379, loss_ce: 0.115263
2022-01-20 20:55:06,513 iteration 145 : loss : 0.247658, loss_ce: 0.149519
2022-01-20 20:55:07,135 iteration 146 : loss : 0.176277, loss_ce: 0.105798
2022-01-20 20:55:07,729 iteration 147 : loss : 0.278057, loss_ce: 0.153678
2022-01-20 20:55:08,407 iteration 148 : loss : 0.219438, loss_ce: 0.124854
2022-01-20 20:55:09,069 iteration 149 : loss : 0.242486, loss_ce: 0.133290
2022-01-20 20:55:09,725 iteration 150 : loss : 0.201894, loss_ce: 0.118176
2022-01-20 20:55:10,272 iteration 151 : loss : 0.200482, loss_ce: 0.134493
2022-01-20 20:55:10,769 iteration 152 : loss : 0.166807, loss_ce: 0.113043
2022-01-20 20:55:11,334 iteration 153 : loss : 0.211593, loss_ce: 0.120340
  2%|▋                              | 9/400 [01:36<1:07:48, 10.40s/it]2022-01-20 20:55:11,997 iteration 154 : loss : 0.231547, loss_ce: 0.131483
2022-01-20 20:55:12,574 iteration 155 : loss : 0.179812, loss_ce: 0.112773
2022-01-20 20:55:13,116 iteration 156 : loss : 0.195866, loss_ce: 0.113421
2022-01-20 20:55:13,666 iteration 157 : loss : 0.209183, loss_ce: 0.123128
2022-01-20 20:55:14,307 iteration 158 : loss : 0.216897, loss_ce: 0.119033
2022-01-20 20:55:14,943 iteration 159 : loss : 0.202670, loss_ce: 0.115499
2022-01-20 20:55:15,503 iteration 160 : loss : 0.194479, loss_ce: 0.108296
2022-01-20 20:55:16,171 iteration 161 : loss : 0.170046, loss_ce: 0.107233
2022-01-20 20:55:16,764 iteration 162 : loss : 0.210029, loss_ce: 0.106291
2022-01-20 20:55:17,357 iteration 163 : loss : 0.229527, loss_ce: 0.127349
2022-01-20 20:55:17,935 iteration 164 : loss : 0.225151, loss_ce: 0.115000
2022-01-20 20:55:18,458 iteration 165 : loss : 0.188613, loss_ce: 0.101036
2022-01-20 20:55:19,074 iteration 166 : loss : 0.265110, loss_ce: 0.165293
2022-01-20 20:55:19,764 iteration 167 : loss : 0.236188, loss_ce: 0.135450
2022-01-20 20:55:20,341 iteration 168 : loss : 0.247216, loss_ce: 0.112058
2022-01-20 20:55:20,947 iteration 169 : loss : 0.251194, loss_ce: 0.123318
2022-01-20 20:55:20,947 Training Data Eval:
2022-01-20 20:55:23,620   Average segmentation loss on training set: 0.2014
2022-01-20 20:55:23,621 Validation Data Eval:
2022-01-20 20:55:24,498   Average segmentation loss on validation set: 0.2222
2022-01-20 20:55:25,075 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 20:55:25,780 iteration 170 : loss : 0.229273, loss_ce: 0.120400
  2%|▊                             | 10/400 [01:50<1:15:44, 11.65s/it]2022-01-20 20:55:26,504 iteration 171 : loss : 0.172970, loss_ce: 0.100255
2022-01-20 20:55:27,065 iteration 172 : loss : 0.199117, loss_ce: 0.116745
2022-01-20 20:55:27,741 iteration 173 : loss : 0.222374, loss_ce: 0.116276
2022-01-20 20:55:28,268 iteration 174 : loss : 0.230155, loss_ce: 0.133794
2022-01-20 20:55:28,848 iteration 175 : loss : 0.225682, loss_ce: 0.114857
2022-01-20 20:55:29,434 iteration 176 : loss : 0.162372, loss_ce: 0.099441
2022-01-20 20:55:30,071 iteration 177 : loss : 0.148609, loss_ce: 0.090137
2022-01-20 20:55:30,670 iteration 178 : loss : 0.171333, loss_ce: 0.088848
2022-01-20 20:55:32,724 iteration 179 : loss : 0.187485, loss_ce: 0.091765
2022-01-20 20:55:33,432 iteration 180 : loss : 0.206481, loss_ce: 0.115483
2022-01-20 20:55:34,075 iteration 181 : loss : 0.186507, loss_ce: 0.102308
2022-01-20 20:55:34,672 iteration 182 : loss : 0.176698, loss_ce: 0.100393
2022-01-20 20:55:35,298 iteration 183 : loss : 0.188346, loss_ce: 0.092624
2022-01-20 20:55:36,049 iteration 184 : loss : 0.221322, loss_ce: 0.101103
2022-01-20 20:55:36,786 iteration 185 : loss : 0.188829, loss_ce: 0.109603
2022-01-20 20:55:37,368 iteration 186 : loss : 0.181972, loss_ce: 0.092098
2022-01-20 20:55:37,981 iteration 187 : loss : 0.154162, loss_ce: 0.090521
  3%|▊                             | 11/400 [02:02<1:16:37, 11.82s/it]2022-01-20 20:55:38,581 iteration 188 : loss : 0.164693, loss_ce: 0.090981
2022-01-20 20:55:39,270 iteration 189 : loss : 0.176130, loss_ce: 0.098987
2022-01-20 20:55:39,900 iteration 190 : loss : 0.213807, loss_ce: 0.121866
2022-01-20 20:55:40,517 iteration 191 : loss : 0.136133, loss_ce: 0.075432
2022-01-20 20:55:41,116 iteration 192 : loss : 0.177835, loss_ce: 0.087503
2022-01-20 20:55:41,642 iteration 193 : loss : 0.232441, loss_ce: 0.117601
2022-01-20 20:55:42,270 iteration 194 : loss : 0.152686, loss_ce: 0.089235
2022-01-20 20:55:42,914 iteration 195 : loss : 0.141964, loss_ce: 0.076224
2022-01-20 20:55:43,491 iteration 196 : loss : 0.146477, loss_ce: 0.088447
2022-01-20 20:55:44,128 iteration 197 : loss : 0.178509, loss_ce: 0.088066
2022-01-20 20:55:44,742 iteration 198 : loss : 0.166905, loss_ce: 0.080884
2022-01-20 20:55:45,247 iteration 199 : loss : 0.208230, loss_ce: 0.093226
2022-01-20 20:55:45,827 iteration 200 : loss : 0.188235, loss_ce: 0.103818
2022-01-20 20:55:46,543 iteration 201 : loss : 0.202198, loss_ce: 0.099659
2022-01-20 20:55:47,116 iteration 202 : loss : 0.180726, loss_ce: 0.092452
2022-01-20 20:55:47,665 iteration 203 : loss : 0.226228, loss_ce: 0.127157
2022-01-20 20:55:48,180 iteration 204 : loss : 0.143203, loss_ce: 0.085942
  3%|▉                             | 12/400 [02:13<1:13:15, 11.33s/it]2022-01-20 20:55:48,760 iteration 205 : loss : 0.206685, loss_ce: 0.109885
2022-01-20 20:55:49,379 iteration 206 : loss : 0.249876, loss_ce: 0.135225
2022-01-20 20:55:50,085 iteration 207 : loss : 0.191892, loss_ce: 0.106194
2022-01-20 20:55:50,786 iteration 208 : loss : 0.158162, loss_ce: 0.078293
2022-01-20 20:55:51,343 iteration 209 : loss : 0.157186, loss_ce: 0.082082
2022-01-20 20:55:51,876 iteration 210 : loss : 0.149290, loss_ce: 0.074005
2022-01-20 20:55:52,474 iteration 211 : loss : 0.176737, loss_ce: 0.086611
2022-01-20 20:55:52,986 iteration 212 : loss : 0.203493, loss_ce: 0.094790
2022-01-20 20:55:53,629 iteration 213 : loss : 0.204227, loss_ce: 0.100622
2022-01-20 20:55:54,239 iteration 214 : loss : 0.219467, loss_ce: 0.088751
2022-01-20 20:55:54,767 iteration 215 : loss : 0.164434, loss_ce: 0.078962
2022-01-20 20:55:55,422 iteration 216 : loss : 0.214989, loss_ce: 0.101975
2022-01-20 20:55:55,986 iteration 217 : loss : 0.137450, loss_ce: 0.074633
2022-01-20 20:55:56,552 iteration 218 : loss : 0.146343, loss_ce: 0.075478
2022-01-20 20:55:57,124 iteration 219 : loss : 0.136102, loss_ce: 0.068837
2022-01-20 20:55:57,656 iteration 220 : loss : 0.178617, loss_ce: 0.101322
2022-01-20 20:55:58,226 iteration 221 : loss : 0.136486, loss_ce: 0.081050
  3%|▉                             | 13/400 [02:23<1:10:34, 10.94s/it]2022-01-20 20:55:58,978 iteration 222 : loss : 0.182146, loss_ce: 0.086340
2022-01-20 20:55:59,621 iteration 223 : loss : 0.131788, loss_ce: 0.067193
2022-01-20 20:56:00,123 iteration 224 : loss : 0.128229, loss_ce: 0.076107
2022-01-20 20:56:00,756 iteration 225 : loss : 0.149213, loss_ce: 0.073917
2022-01-20 20:56:01,393 iteration 226 : loss : 0.215564, loss_ce: 0.101135
2022-01-20 20:56:02,025 iteration 227 : loss : 0.155566, loss_ce: 0.077210
2022-01-20 20:56:02,636 iteration 228 : loss : 0.164058, loss_ce: 0.081721
2022-01-20 20:56:03,247 iteration 229 : loss : 0.144342, loss_ce: 0.073785
2022-01-20 20:56:03,834 iteration 230 : loss : 0.188286, loss_ce: 0.088835
2022-01-20 20:56:04,394 iteration 231 : loss : 0.214720, loss_ce: 0.090779
2022-01-20 20:56:05,070 iteration 232 : loss : 0.134813, loss_ce: 0.084713
2022-01-20 20:56:05,734 iteration 233 : loss : 0.139782, loss_ce: 0.081457
2022-01-20 20:56:06,376 iteration 234 : loss : 0.189768, loss_ce: 0.081652
2022-01-20 20:56:06,973 iteration 235 : loss : 0.131047, loss_ce: 0.068548
2022-01-20 20:56:07,553 iteration 236 : loss : 0.174061, loss_ce: 0.095722
2022-01-20 20:56:08,121 iteration 237 : loss : 0.112005, loss_ce: 0.061644
2022-01-20 20:56:08,611 iteration 238 : loss : 0.156150, loss_ce: 0.085704
  4%|█                             | 14/400 [02:33<1:09:17, 10.77s/it]2022-01-20 20:56:09,201 iteration 239 : loss : 0.133397, loss_ce: 0.065531
2022-01-20 20:56:09,857 iteration 240 : loss : 0.168402, loss_ce: 0.091518
2022-01-20 20:56:10,412 iteration 241 : loss : 0.171053, loss_ce: 0.077096
2022-01-20 20:56:11,065 iteration 242 : loss : 0.132966, loss_ce: 0.072754
2022-01-20 20:56:11,739 iteration 243 : loss : 0.167893, loss_ce: 0.090816
2022-01-20 20:56:12,395 iteration 244 : loss : 0.155503, loss_ce: 0.079856
2022-01-20 20:56:12,918 iteration 245 : loss : 0.141630, loss_ce: 0.063868
2022-01-20 20:56:13,530 iteration 246 : loss : 0.169549, loss_ce: 0.076861
2022-01-20 20:56:14,072 iteration 247 : loss : 0.113561, loss_ce: 0.061419
2022-01-20 20:56:14,574 iteration 248 : loss : 0.113187, loss_ce: 0.056759
2022-01-20 20:56:15,263 iteration 249 : loss : 0.132686, loss_ce: 0.058089
2022-01-20 20:56:15,920 iteration 250 : loss : 0.156778, loss_ce: 0.082031
2022-01-20 20:56:16,509 iteration 251 : loss : 0.094944, loss_ce: 0.057654
2022-01-20 20:56:17,108 iteration 252 : loss : 0.161933, loss_ce: 0.100866
2022-01-20 20:56:17,654 iteration 253 : loss : 0.193808, loss_ce: 0.082082
2022-01-20 20:56:18,193 iteration 254 : loss : 0.139805, loss_ce: 0.067912
2022-01-20 20:56:18,194 Training Data Eval:
2022-01-20 20:56:20,883   Average segmentation loss on training set: 0.1437
2022-01-20 20:56:20,884 Validation Data Eval:
2022-01-20 20:56:22,004   Average segmentation loss on validation set: 0.2428
2022-01-20 20:56:22,595 iteration 255 : loss : 0.178202, loss_ce: 0.087042
  4%|█▏                            | 15/400 [02:47<1:15:19, 11.74s/it]2022-01-20 20:56:23,244 iteration 256 : loss : 0.149218, loss_ce: 0.068374
2022-01-20 20:56:23,832 iteration 257 : loss : 0.143794, loss_ce: 0.091498
2022-01-20 20:56:24,562 iteration 258 : loss : 0.149071, loss_ce: 0.067765
2022-01-20 20:56:25,107 iteration 259 : loss : 0.178065, loss_ce: 0.083716
2022-01-20 20:56:25,732 iteration 260 : loss : 0.153467, loss_ce: 0.079544
2022-01-20 20:56:26,371 iteration 261 : loss : 0.146599, loss_ce: 0.070486
2022-01-20 20:56:26,994 iteration 262 : loss : 0.145069, loss_ce: 0.093621
2022-01-20 20:56:27,552 iteration 263 : loss : 0.178906, loss_ce: 0.103917
2022-01-20 20:56:28,102 iteration 264 : loss : 0.149991, loss_ce: 0.069349
2022-01-20 20:56:28,743 iteration 265 : loss : 0.145361, loss_ce: 0.082701
2022-01-20 20:56:29,369 iteration 266 : loss : 0.177279, loss_ce: 0.074016
2022-01-20 20:56:29,960 iteration 267 : loss : 0.145734, loss_ce: 0.073436
2022-01-20 20:56:30,568 iteration 268 : loss : 0.109227, loss_ce: 0.064579
2022-01-20 20:56:31,166 iteration 269 : loss : 0.125943, loss_ce: 0.064196
2022-01-20 20:56:31,690 iteration 270 : loss : 0.144647, loss_ce: 0.068009
2022-01-20 20:56:32,319 iteration 271 : loss : 0.182525, loss_ce: 0.075904
2022-01-20 20:56:33,002 iteration 272 : loss : 0.163324, loss_ce: 0.076753
  4%|█▏                            | 16/400 [02:57<1:12:34, 11.34s/it]2022-01-20 20:56:33,642 iteration 273 : loss : 0.123352, loss_ce: 0.059898
2022-01-20 20:56:34,271 iteration 274 : loss : 0.154270, loss_ce: 0.068628
2022-01-20 20:56:34,883 iteration 275 : loss : 0.153911, loss_ce: 0.078958
2022-01-20 20:56:35,432 iteration 276 : loss : 0.141492, loss_ce: 0.070112
2022-01-20 20:56:36,111 iteration 277 : loss : 0.153064, loss_ce: 0.066562
2022-01-20 20:56:36,637 iteration 278 : loss : 0.276968, loss_ce: 0.124437
2022-01-20 20:56:37,230 iteration 279 : loss : 0.145139, loss_ce: 0.071848
2022-01-20 20:56:37,733 iteration 280 : loss : 0.112931, loss_ce: 0.066803
2022-01-20 20:56:38,338 iteration 281 : loss : 0.137983, loss_ce: 0.068459
2022-01-20 20:56:38,969 iteration 282 : loss : 0.147712, loss_ce: 0.075530
2022-01-20 20:56:39,583 iteration 283 : loss : 0.140673, loss_ce: 0.078503
2022-01-20 20:56:40,131 iteration 284 : loss : 0.104482, loss_ce: 0.055177
2022-01-20 20:56:40,743 iteration 285 : loss : 0.115045, loss_ce: 0.055027
2022-01-20 20:56:41,365 iteration 286 : loss : 0.112978, loss_ce: 0.055239
2022-01-20 20:56:41,910 iteration 287 : loss : 0.142187, loss_ce: 0.066033
2022-01-20 20:56:42,486 iteration 288 : loss : 0.088313, loss_ce: 0.053248
2022-01-20 20:56:43,071 iteration 289 : loss : 0.137098, loss_ce: 0.076350
  4%|█▎                            | 17/400 [03:07<1:09:57, 10.96s/it]2022-01-20 20:56:43,718 iteration 290 : loss : 0.103843, loss_ce: 0.055786
2022-01-20 20:56:44,315 iteration 291 : loss : 0.110500, loss_ce: 0.053850
2022-01-20 20:56:44,907 iteration 292 : loss : 0.102485, loss_ce: 0.053137
2022-01-20 20:56:45,648 iteration 293 : loss : 0.152007, loss_ce: 0.077952
2022-01-20 20:56:46,207 iteration 294 : loss : 0.108493, loss_ce: 0.056469
2022-01-20 20:56:46,765 iteration 295 : loss : 0.193331, loss_ce: 0.077666
2022-01-20 20:56:47,333 iteration 296 : loss : 0.127871, loss_ce: 0.064569
2022-01-20 20:56:47,982 iteration 297 : loss : 0.139914, loss_ce: 0.075630
2022-01-20 20:56:48,533 iteration 298 : loss : 0.133254, loss_ce: 0.059282
2022-01-20 20:56:49,149 iteration 299 : loss : 0.160068, loss_ce: 0.072496
2022-01-20 20:56:49,705 iteration 300 : loss : 0.105245, loss_ce: 0.056022
2022-01-20 20:56:50,291 iteration 301 : loss : 0.157154, loss_ce: 0.069401
2022-01-20 20:56:50,978 iteration 302 : loss : 0.194314, loss_ce: 0.113743
2022-01-20 20:56:51,604 iteration 303 : loss : 0.143815, loss_ce: 0.075418
2022-01-20 20:56:52,178 iteration 304 : loss : 0.112310, loss_ce: 0.055828
2022-01-20 20:56:52,768 iteration 305 : loss : 0.096018, loss_ce: 0.047972
2022-01-20 20:56:53,352 iteration 306 : loss : 0.143747, loss_ce: 0.063415
  4%|█▎                            | 18/400 [03:18<1:08:26, 10.75s/it]2022-01-20 20:56:53,954 iteration 307 : loss : 0.136360, loss_ce: 0.069428
2022-01-20 20:56:54,587 iteration 308 : loss : 0.175691, loss_ce: 0.068874
2022-01-20 20:56:55,180 iteration 309 : loss : 0.144597, loss_ce: 0.074764
2022-01-20 20:56:55,751 iteration 310 : loss : 0.130065, loss_ce: 0.059933
2022-01-20 20:56:56,315 iteration 311 : loss : 0.139517, loss_ce: 0.063556
2022-01-20 20:56:56,917 iteration 312 : loss : 0.193449, loss_ce: 0.067195
2022-01-20 20:56:57,556 iteration 313 : loss : 0.121919, loss_ce: 0.055768
2022-01-20 20:56:58,056 iteration 314 : loss : 0.136286, loss_ce: 0.063196
2022-01-20 20:56:58,620 iteration 315 : loss : 0.137587, loss_ce: 0.077214
2022-01-20 20:56:59,280 iteration 316 : loss : 0.127182, loss_ce: 0.061880
2022-01-20 20:56:59,956 iteration 317 : loss : 0.145280, loss_ce: 0.079017
2022-01-20 20:57:00,541 iteration 318 : loss : 0.153287, loss_ce: 0.085932
2022-01-20 20:57:01,148 iteration 319 : loss : 0.118353, loss_ce: 0.058081
2022-01-20 20:57:01,761 iteration 320 : loss : 0.115783, loss_ce: 0.053655
2022-01-20 20:57:02,326 iteration 321 : loss : 0.133860, loss_ce: 0.058804
2022-01-20 20:57:02,867 iteration 322 : loss : 0.084108, loss_ce: 0.045117
2022-01-20 20:57:03,436 iteration 323 : loss : 0.105796, loss_ce: 0.056653
  5%|█▍                            | 19/400 [03:28<1:07:00, 10.55s/it]2022-01-20 20:57:04,071 iteration 324 : loss : 0.106696, loss_ce: 0.051870
2022-01-20 20:57:04,626 iteration 325 : loss : 0.133992, loss_ce: 0.054030
2022-01-20 20:57:05,177 iteration 326 : loss : 0.173385, loss_ce: 0.090187
2022-01-20 20:57:05,711 iteration 327 : loss : 0.136012, loss_ce: 0.064800
2022-01-20 20:57:06,318 iteration 328 : loss : 0.083643, loss_ce: 0.040552
2022-01-20 20:57:06,973 iteration 329 : loss : 0.124149, loss_ce: 0.056332
2022-01-20 20:57:07,540 iteration 330 : loss : 0.116100, loss_ce: 0.062597
2022-01-20 20:57:08,128 iteration 331 : loss : 0.148174, loss_ce: 0.063803
2022-01-20 20:57:08,633 iteration 332 : loss : 0.101707, loss_ce: 0.055923
2022-01-20 20:57:09,272 iteration 333 : loss : 0.183974, loss_ce: 0.103102
2022-01-20 20:57:09,867 iteration 334 : loss : 0.095498, loss_ce: 0.048051
2022-01-20 20:57:10,526 iteration 335 : loss : 0.147537, loss_ce: 0.093091
2022-01-20 20:57:11,109 iteration 336 : loss : 0.127173, loss_ce: 0.074601
2022-01-20 20:57:11,676 iteration 337 : loss : 0.151882, loss_ce: 0.068311
2022-01-20 20:57:12,263 iteration 338 : loss : 0.100494, loss_ce: 0.052619
2022-01-20 20:57:12,822 iteration 339 : loss : 0.117526, loss_ce: 0.063923
2022-01-20 20:57:12,823 Training Data Eval:
2022-01-20 20:57:15,600   Average segmentation loss on training set: 0.0959
2022-01-20 20:57:15,600 Validation Data Eval:
2022-01-20 20:57:16,506   Average segmentation loss on validation set: 0.1326
2022-01-20 20:57:17,074 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 20:57:17,710 iteration 340 : loss : 0.155353, loss_ce: 0.084292
  5%|█▌                            | 20/400 [03:42<1:13:54, 11.67s/it]2022-01-20 20:57:18,320 iteration 341 : loss : 0.082447, loss_ce: 0.046047
2022-01-20 20:57:18,960 iteration 342 : loss : 0.118844, loss_ce: 0.059297
2022-01-20 20:57:19,587 iteration 343 : loss : 0.135737, loss_ce: 0.066441
2022-01-20 20:57:20,152 iteration 344 : loss : 0.131677, loss_ce: 0.063755
2022-01-20 20:57:20,716 iteration 345 : loss : 0.101902, loss_ce: 0.051011
2022-01-20 20:57:21,350 iteration 346 : loss : 0.081055, loss_ce: 0.043498
2022-01-20 20:57:21,990 iteration 347 : loss : 0.136206, loss_ce: 0.059616
2022-01-20 20:57:22,562 iteration 348 : loss : 0.089748, loss_ce: 0.043849
2022-01-20 20:57:23,148 iteration 349 : loss : 0.109817, loss_ce: 0.051625
2022-01-20 20:57:23,770 iteration 350 : loss : 0.102418, loss_ce: 0.052572
2022-01-20 20:57:24,348 iteration 351 : loss : 0.113948, loss_ce: 0.053273
2022-01-20 20:57:25,039 iteration 352 : loss : 0.114201, loss_ce: 0.066514
2022-01-20 20:57:25,726 iteration 353 : loss : 0.128490, loss_ce: 0.065792
2022-01-20 20:57:26,301 iteration 354 : loss : 0.092188, loss_ce: 0.043381
2022-01-20 20:57:26,933 iteration 355 : loss : 0.090028, loss_ce: 0.042004
2022-01-20 20:57:27,537 iteration 356 : loss : 0.093055, loss_ce: 0.044255
2022-01-20 20:57:28,160 iteration 357 : loss : 0.121020, loss_ce: 0.048696
  5%|█▌                            | 21/400 [03:53<1:11:24, 11.30s/it]2022-01-20 20:57:28,902 iteration 358 : loss : 0.164961, loss_ce: 0.094883
2022-01-20 20:57:29,576 iteration 359 : loss : 0.093646, loss_ce: 0.045781
2022-01-20 20:57:30,145 iteration 360 : loss : 0.107770, loss_ce: 0.046734
2022-01-20 20:57:30,771 iteration 361 : loss : 0.173861, loss_ce: 0.072967
2022-01-20 20:57:31,395 iteration 362 : loss : 0.116493, loss_ce: 0.068794
2022-01-20 20:57:31,925 iteration 363 : loss : 0.108180, loss_ce: 0.052772
2022-01-20 20:57:32,535 iteration 364 : loss : 0.247520, loss_ce: 0.105636
2022-01-20 20:57:33,094 iteration 365 : loss : 0.111031, loss_ce: 0.056595
2022-01-20 20:57:33,675 iteration 366 : loss : 0.121254, loss_ce: 0.048202
2022-01-20 20:57:34,285 iteration 367 : loss : 0.116030, loss_ce: 0.054054
2022-01-20 20:57:34,867 iteration 368 : loss : 0.167548, loss_ce: 0.079218
2022-01-20 20:57:35,428 iteration 369 : loss : 0.112450, loss_ce: 0.051549
2022-01-20 20:57:36,018 iteration 370 : loss : 0.164717, loss_ce: 0.079702
2022-01-20 20:57:36,605 iteration 371 : loss : 0.140648, loss_ce: 0.053388
2022-01-20 20:57:37,148 iteration 372 : loss : 0.094505, loss_ce: 0.044600
2022-01-20 20:57:37,728 iteration 373 : loss : 0.080323, loss_ce: 0.040130
2022-01-20 20:57:38,356 iteration 374 : loss : 0.118983, loss_ce: 0.061324
  6%|█▋                            | 22/400 [04:03<1:09:06, 10.97s/it]2022-01-20 20:57:38,990 iteration 375 : loss : 0.095116, loss_ce: 0.048910
2022-01-20 20:57:39,567 iteration 376 : loss : 0.161113, loss_ce: 0.053913
2022-01-20 20:57:40,169 iteration 377 : loss : 0.163362, loss_ce: 0.073923
2022-01-20 20:57:40,841 iteration 378 : loss : 0.122121, loss_ce: 0.050984
2022-01-20 20:57:41,456 iteration 379 : loss : 0.090498, loss_ce: 0.046061
2022-01-20 20:57:42,018 iteration 380 : loss : 0.115641, loss_ce: 0.060203
2022-01-20 20:57:42,630 iteration 381 : loss : 0.150645, loss_ce: 0.070939
2022-01-20 20:57:43,162 iteration 382 : loss : 0.107975, loss_ce: 0.058171
2022-01-20 20:57:43,778 iteration 383 : loss : 0.169918, loss_ce: 0.054183
2022-01-20 20:57:44,378 iteration 384 : loss : 0.103758, loss_ce: 0.048926
2022-01-20 20:57:44,952 iteration 385 : loss : 0.104513, loss_ce: 0.053662
2022-01-20 20:57:45,555 iteration 386 : loss : 0.115328, loss_ce: 0.050063
2022-01-20 20:57:46,102 iteration 387 : loss : 0.081377, loss_ce: 0.038753
2022-01-20 20:57:46,725 iteration 388 : loss : 0.119095, loss_ce: 0.056785
2022-01-20 20:57:47,304 iteration 389 : loss : 0.109892, loss_ce: 0.047609
2022-01-20 20:57:47,901 iteration 390 : loss : 0.168141, loss_ce: 0.087310
2022-01-20 20:57:48,516 iteration 391 : loss : 0.078251, loss_ce: 0.036874
  6%|█▋                            | 23/400 [04:13<1:07:24, 10.73s/it]2022-01-20 20:57:49,205 iteration 392 : loss : 0.115958, loss_ce: 0.059956
2022-01-20 20:57:49,747 iteration 393 : loss : 0.102687, loss_ce: 0.054736
2022-01-20 20:57:50,346 iteration 394 : loss : 0.119534, loss_ce: 0.052521
2022-01-20 20:57:50,890 iteration 395 : loss : 0.086045, loss_ce: 0.038859
2022-01-20 20:57:51,476 iteration 396 : loss : 0.102375, loss_ce: 0.044062
2022-01-20 20:57:52,151 iteration 397 : loss : 0.113617, loss_ce: 0.061150
2022-01-20 20:57:52,736 iteration 398 : loss : 0.110438, loss_ce: 0.046123
2022-01-20 20:57:53,334 iteration 399 : loss : 0.108753, loss_ce: 0.046294
2022-01-20 20:57:53,898 iteration 400 : loss : 0.080320, loss_ce: 0.037037
2022-01-20 20:57:54,501 iteration 401 : loss : 0.097748, loss_ce: 0.057481
2022-01-20 20:57:55,186 iteration 402 : loss : 0.090426, loss_ce: 0.046259
2022-01-20 20:57:55,821 iteration 403 : loss : 0.104039, loss_ce: 0.047415
2022-01-20 20:57:56,389 iteration 404 : loss : 0.085344, loss_ce: 0.039686
2022-01-20 20:57:56,966 iteration 405 : loss : 0.132125, loss_ce: 0.070205
2022-01-20 20:57:57,595 iteration 406 : loss : 0.099002, loss_ce: 0.045199
2022-01-20 20:57:58,225 iteration 407 : loss : 0.098368, loss_ce: 0.044372
2022-01-20 20:57:58,734 iteration 408 : loss : 0.092405, loss_ce: 0.045279
  6%|█▊                            | 24/400 [04:23<1:06:16, 10.58s/it]2022-01-20 20:57:59,448 iteration 409 : loss : 0.112412, loss_ce: 0.040172
2022-01-20 20:58:00,081 iteration 410 : loss : 0.092388, loss_ce: 0.042317
2022-01-20 20:58:00,712 iteration 411 : loss : 0.170264, loss_ce: 0.059893
2022-01-20 20:58:01,283 iteration 412 : loss : 0.090578, loss_ce: 0.044643
2022-01-20 20:58:01,868 iteration 413 : loss : 0.096800, loss_ce: 0.039231
2022-01-20 20:58:02,411 iteration 414 : loss : 0.081807, loss_ce: 0.038750
2022-01-20 20:58:03,066 iteration 415 : loss : 0.104060, loss_ce: 0.052390
2022-01-20 20:58:03,627 iteration 416 : loss : 0.103007, loss_ce: 0.056600
2022-01-20 20:58:04,248 iteration 417 : loss : 0.121985, loss_ce: 0.052422
2022-01-20 20:58:04,770 iteration 418 : loss : 0.090052, loss_ce: 0.053860
2022-01-20 20:58:05,356 iteration 419 : loss : 0.124290, loss_ce: 0.044907
2022-01-20 20:58:05,956 iteration 420 : loss : 0.062378, loss_ce: 0.034149
2022-01-20 20:58:06,629 iteration 421 : loss : 0.111686, loss_ce: 0.062007
2022-01-20 20:58:07,205 iteration 422 : loss : 0.097135, loss_ce: 0.043606
2022-01-20 20:58:07,803 iteration 423 : loss : 0.086987, loss_ce: 0.043575
2022-01-20 20:58:08,437 iteration 424 : loss : 0.081364, loss_ce: 0.037344
2022-01-20 20:58:08,437 Training Data Eval:
2022-01-20 20:58:11,168   Average segmentation loss on training set: 0.1087
2022-01-20 20:58:11,168 Validation Data Eval:
2022-01-20 20:58:12,084   Average segmentation loss on validation set: 0.2497
2022-01-20 20:58:12,750 iteration 425 : loss : 0.101488, loss_ce: 0.045211
  6%|█▉                            | 25/400 [04:37<1:12:32, 11.61s/it]2022-01-20 20:58:13,457 iteration 426 : loss : 0.084836, loss_ce: 0.040182
2022-01-20 20:58:14,074 iteration 427 : loss : 0.124669, loss_ce: 0.052277
2022-01-20 20:58:14,726 iteration 428 : loss : 0.089955, loss_ce: 0.042214
2022-01-20 20:58:15,297 iteration 429 : loss : 0.074071, loss_ce: 0.035794
2022-01-20 20:58:15,913 iteration 430 : loss : 0.121136, loss_ce: 0.049601
2022-01-20 20:58:16,454 iteration 431 : loss : 0.094278, loss_ce: 0.043140
2022-01-20 20:58:17,028 iteration 432 : loss : 0.072840, loss_ce: 0.033968
2022-01-20 20:58:17,642 iteration 433 : loss : 0.115070, loss_ce: 0.041933
2022-01-20 20:58:18,224 iteration 434 : loss : 0.069563, loss_ce: 0.032352
2022-01-20 20:58:18,813 iteration 435 : loss : 0.120811, loss_ce: 0.063529
2022-01-20 20:58:19,455 iteration 436 : loss : 0.108867, loss_ce: 0.050412
2022-01-20 20:58:20,052 iteration 437 : loss : 0.099719, loss_ce: 0.043318
2022-01-20 20:58:20,647 iteration 438 : loss : 0.125386, loss_ce: 0.068040
2022-01-20 20:58:21,236 iteration 439 : loss : 0.092426, loss_ce: 0.049705
2022-01-20 20:58:21,784 iteration 440 : loss : 0.072044, loss_ce: 0.036783
2022-01-20 20:58:22,361 iteration 441 : loss : 0.086474, loss_ce: 0.045350
2022-01-20 20:58:22,922 iteration 442 : loss : 0.156124, loss_ce: 0.056902
  6%|█▉                            | 26/400 [04:47<1:09:39, 11.18s/it]2022-01-20 20:58:23,563 iteration 443 : loss : 0.089599, loss_ce: 0.050896
2022-01-20 20:58:24,146 iteration 444 : loss : 0.122888, loss_ce: 0.049631
2022-01-20 20:58:24,922 iteration 445 : loss : 0.121012, loss_ce: 0.065158
2022-01-20 20:58:25,459 iteration 446 : loss : 0.126975, loss_ce: 0.051643
2022-01-20 20:58:26,136 iteration 447 : loss : 0.114918, loss_ce: 0.053292
2022-01-20 20:58:26,776 iteration 448 : loss : 0.069485, loss_ce: 0.036890
2022-01-20 20:58:27,362 iteration 449 : loss : 0.089739, loss_ce: 0.046077
2022-01-20 20:58:27,880 iteration 450 : loss : 0.079929, loss_ce: 0.040453
2022-01-20 20:58:28,459 iteration 451 : loss : 0.103775, loss_ce: 0.045032
2022-01-20 20:58:29,066 iteration 452 : loss : 0.078529, loss_ce: 0.044196
2022-01-20 20:58:29,663 iteration 453 : loss : 0.079390, loss_ce: 0.036718
2022-01-20 20:58:30,295 iteration 454 : loss : 0.154725, loss_ce: 0.059586
2022-01-20 20:58:30,964 iteration 455 : loss : 0.088997, loss_ce: 0.035082
2022-01-20 20:58:31,528 iteration 456 : loss : 0.106536, loss_ce: 0.039598
2022-01-20 20:58:32,098 iteration 457 : loss : 0.104270, loss_ce: 0.043604
2022-01-20 20:58:32,692 iteration 458 : loss : 0.089019, loss_ce: 0.042607
2022-01-20 20:58:33,302 iteration 459 : loss : 0.080724, loss_ce: 0.036320
  7%|██                            | 27/400 [04:58<1:08:00, 10.94s/it]2022-01-20 20:58:33,863 iteration 460 : loss : 0.088447, loss_ce: 0.034042
2022-01-20 20:58:34,474 iteration 461 : loss : 0.093101, loss_ce: 0.047738
2022-01-20 20:58:35,070 iteration 462 : loss : 0.094997, loss_ce: 0.030374
2022-01-20 20:58:35,576 iteration 463 : loss : 0.079694, loss_ce: 0.042565
2022-01-20 20:58:36,234 iteration 464 : loss : 0.071418, loss_ce: 0.032977
2022-01-20 20:58:36,812 iteration 465 : loss : 0.085927, loss_ce: 0.046398
2022-01-20 20:58:37,446 iteration 466 : loss : 0.105791, loss_ce: 0.053659
2022-01-20 20:58:38,005 iteration 467 : loss : 0.095455, loss_ce: 0.037489
2022-01-20 20:58:38,591 iteration 468 : loss : 0.074316, loss_ce: 0.031574
2022-01-20 20:58:39,145 iteration 469 : loss : 0.103618, loss_ce: 0.041290
2022-01-20 20:58:39,811 iteration 470 : loss : 0.113643, loss_ce: 0.063579
2022-01-20 20:58:40,366 iteration 471 : loss : 0.087293, loss_ce: 0.039328
2022-01-20 20:58:41,012 iteration 472 : loss : 0.121479, loss_ce: 0.055890
2022-01-20 20:58:41,648 iteration 473 : loss : 0.075487, loss_ce: 0.035414
2022-01-20 20:58:42,303 iteration 474 : loss : 0.088580, loss_ce: 0.041477
2022-01-20 20:58:42,904 iteration 475 : loss : 0.115315, loss_ce: 0.044854
2022-01-20 20:58:43,531 iteration 476 : loss : 0.087787, loss_ce: 0.045349
  7%|██                            | 28/400 [05:08<1:06:29, 10.72s/it]2022-01-20 20:58:44,155 iteration 477 : loss : 0.082190, loss_ce: 0.045236
2022-01-20 20:58:44,791 iteration 478 : loss : 0.085038, loss_ce: 0.036650
2022-01-20 20:58:45,330 iteration 479 : loss : 0.087986, loss_ce: 0.039681
2022-01-20 20:58:45,838 iteration 480 : loss : 0.082342, loss_ce: 0.042269
2022-01-20 20:58:46,415 iteration 481 : loss : 0.097672, loss_ce: 0.047883
2022-01-20 20:58:47,058 iteration 482 : loss : 0.090110, loss_ce: 0.040720
2022-01-20 20:58:47,662 iteration 483 : loss : 0.081972, loss_ce: 0.033947
2022-01-20 20:58:48,246 iteration 484 : loss : 0.069637, loss_ce: 0.034087
2022-01-20 20:58:48,771 iteration 485 : loss : 0.059097, loss_ce: 0.028731
2022-01-20 20:58:49,411 iteration 486 : loss : 0.192327, loss_ce: 0.060557
2022-01-20 20:58:50,033 iteration 487 : loss : 0.121957, loss_ce: 0.066929
2022-01-20 20:58:50,720 iteration 488 : loss : 0.121659, loss_ce: 0.052793
2022-01-20 20:58:51,341 iteration 489 : loss : 0.056236, loss_ce: 0.028620
2022-01-20 20:58:51,891 iteration 490 : loss : 0.074947, loss_ce: 0.033951
2022-01-20 20:58:52,537 iteration 491 : loss : 0.108988, loss_ce: 0.049785
2022-01-20 20:58:53,083 iteration 492 : loss : 0.140514, loss_ce: 0.068466
2022-01-20 20:58:53,657 iteration 493 : loss : 0.117737, loss_ce: 0.056400
  7%|██▏                           | 29/400 [05:18<1:05:11, 10.54s/it]2022-01-20 20:58:54,259 iteration 494 : loss : 0.094417, loss_ce: 0.041465
2022-01-20 20:58:54,851 iteration 495 : loss : 0.075383, loss_ce: 0.036525
2022-01-20 20:58:55,365 iteration 496 : loss : 0.093889, loss_ce: 0.045207
2022-01-20 20:58:55,998 iteration 497 : loss : 0.078515, loss_ce: 0.032450
2022-01-20 20:58:56,576 iteration 498 : loss : 0.104380, loss_ce: 0.043123
2022-01-20 20:58:57,236 iteration 499 : loss : 0.095160, loss_ce: 0.049147
2022-01-20 20:58:57,746 iteration 500 : loss : 0.072369, loss_ce: 0.032173
2022-01-20 20:58:58,352 iteration 501 : loss : 0.099704, loss_ce: 0.033982
2022-01-20 20:58:58,915 iteration 502 : loss : 0.097142, loss_ce: 0.038347
2022-01-20 20:58:59,514 iteration 503 : loss : 0.124883, loss_ce: 0.060295
2022-01-20 20:59:00,199 iteration 504 : loss : 0.064246, loss_ce: 0.028617
2022-01-20 20:59:00,879 iteration 505 : loss : 0.067636, loss_ce: 0.031741
2022-01-20 20:59:01,499 iteration 506 : loss : 0.128309, loss_ce: 0.066062
2022-01-20 20:59:02,086 iteration 507 : loss : 0.078292, loss_ce: 0.031307
2022-01-20 20:59:02,716 iteration 508 : loss : 0.101936, loss_ce: 0.036976
2022-01-20 20:59:03,365 iteration 509 : loss : 0.095748, loss_ce: 0.050983
2022-01-20 20:59:03,366 Training Data Eval:
2022-01-20 20:59:06,105   Average segmentation loss on training set: 0.1184
2022-01-20 20:59:06,106 Validation Data Eval:
2022-01-20 20:59:07,015   Average segmentation loss on validation set: 0.1752
2022-01-20 20:59:07,602 iteration 510 : loss : 0.070412, loss_ce: 0.033124
  8%|██▎                           | 30/400 [05:32<1:11:19, 11.57s/it]2022-01-20 20:59:08,216 iteration 511 : loss : 0.070559, loss_ce: 0.029018
2022-01-20 20:59:08,803 iteration 512 : loss : 0.097118, loss_ce: 0.044265
2022-01-20 20:59:09,405 iteration 513 : loss : 0.079738, loss_ce: 0.035181
2022-01-20 20:59:10,032 iteration 514 : loss : 0.092888, loss_ce: 0.043397
2022-01-20 20:59:10,556 iteration 515 : loss : 0.075733, loss_ce: 0.038983
2022-01-20 20:59:11,050 iteration 516 : loss : 0.062726, loss_ce: 0.025369
2022-01-20 20:59:11,717 iteration 517 : loss : 0.088278, loss_ce: 0.046224
2022-01-20 20:59:12,404 iteration 518 : loss : 0.155473, loss_ce: 0.064712
2022-01-20 20:59:13,084 iteration 519 : loss : 0.094010, loss_ce: 0.052015
2022-01-20 20:59:13,698 iteration 520 : loss : 0.071375, loss_ce: 0.035228
2022-01-20 20:59:14,235 iteration 521 : loss : 0.059681, loss_ce: 0.027679
2022-01-20 20:59:14,873 iteration 522 : loss : 0.095511, loss_ce: 0.038864
2022-01-20 20:59:15,453 iteration 523 : loss : 0.090168, loss_ce: 0.033570
2022-01-20 20:59:16,018 iteration 524 : loss : 0.077567, loss_ce: 0.040669
2022-01-20 20:59:16,591 iteration 525 : loss : 0.061674, loss_ce: 0.030250
2022-01-20 20:59:17,218 iteration 526 : loss : 0.071661, loss_ce: 0.030881
2022-01-20 20:59:17,837 iteration 527 : loss : 0.101204, loss_ce: 0.038139
  8%|██▎                           | 31/400 [05:42<1:08:40, 11.17s/it]2022-01-20 20:59:18,450 iteration 528 : loss : 0.058028, loss_ce: 0.026775
2022-01-20 20:59:19,150 iteration 529 : loss : 0.111620, loss_ce: 0.043339
2022-01-20 20:59:19,719 iteration 530 : loss : 0.054845, loss_ce: 0.024556
2022-01-20 20:59:20,266 iteration 531 : loss : 0.061912, loss_ce: 0.028681
2022-01-20 20:59:20,876 iteration 532 : loss : 0.079412, loss_ce: 0.038471
2022-01-20 20:59:21,473 iteration 533 : loss : 0.073767, loss_ce: 0.035723
2022-01-20 20:59:22,056 iteration 534 : loss : 0.075345, loss_ce: 0.034506
2022-01-20 20:59:22,689 iteration 535 : loss : 0.080485, loss_ce: 0.033702
2022-01-20 20:59:23,296 iteration 536 : loss : 0.081304, loss_ce: 0.043269
2022-01-20 20:59:23,879 iteration 537 : loss : 0.060290, loss_ce: 0.029520
2022-01-20 20:59:24,488 iteration 538 : loss : 0.096049, loss_ce: 0.049021
2022-01-20 20:59:25,012 iteration 539 : loss : 0.065762, loss_ce: 0.030376
2022-01-20 20:59:25,731 iteration 540 : loss : 0.110357, loss_ce: 0.061174
2022-01-20 20:59:26,430 iteration 541 : loss : 0.100158, loss_ce: 0.052712
2022-01-20 20:59:26,971 iteration 542 : loss : 0.144023, loss_ce: 0.072568
2022-01-20 20:59:27,566 iteration 543 : loss : 0.068309, loss_ce: 0.035167
2022-01-20 20:59:28,140 iteration 544 : loss : 0.175053, loss_ce: 0.066879
  8%|██▍                           | 32/400 [05:53<1:06:54, 10.91s/it]2022-01-20 20:59:28,840 iteration 545 : loss : 0.091730, loss_ce: 0.041717
2022-01-20 20:59:29,503 iteration 546 : loss : 0.073536, loss_ce: 0.035595
2022-01-20 20:59:30,150 iteration 547 : loss : 0.073730, loss_ce: 0.034114
2022-01-20 20:59:30,687 iteration 548 : loss : 0.132104, loss_ce: 0.058745
2022-01-20 20:59:31,231 iteration 549 : loss : 0.111269, loss_ce: 0.043393
2022-01-20 20:59:31,785 iteration 550 : loss : 0.079201, loss_ce: 0.032676
2022-01-20 20:59:32,331 iteration 551 : loss : 0.078623, loss_ce: 0.029230
2022-01-20 20:59:32,968 iteration 552 : loss : 0.121324, loss_ce: 0.053162
2022-01-20 20:59:33,583 iteration 553 : loss : 0.080056, loss_ce: 0.038869
2022-01-20 20:59:34,188 iteration 554 : loss : 0.116746, loss_ce: 0.041677
2022-01-20 20:59:34,818 iteration 555 : loss : 0.073293, loss_ce: 0.025282
2022-01-20 20:59:35,481 iteration 556 : loss : 0.079656, loss_ce: 0.041021
2022-01-20 20:59:36,039 iteration 557 : loss : 0.092538, loss_ce: 0.047723
2022-01-20 20:59:36,574 iteration 558 : loss : 0.082402, loss_ce: 0.031238
2022-01-20 20:59:37,147 iteration 559 : loss : 0.105021, loss_ce: 0.043803
2022-01-20 20:59:37,806 iteration 560 : loss : 0.091383, loss_ce: 0.040143
2022-01-20 20:59:38,452 iteration 561 : loss : 0.075881, loss_ce: 0.036158
  8%|██▍                           | 33/400 [06:03<1:05:37, 10.73s/it]2022-01-20 20:59:39,136 iteration 562 : loss : 0.080280, loss_ce: 0.031023
2022-01-20 20:59:39,680 iteration 563 : loss : 0.058717, loss_ce: 0.031714
2022-01-20 20:59:40,224 iteration 564 : loss : 0.075489, loss_ce: 0.038134
2022-01-20 20:59:40,846 iteration 565 : loss : 0.058872, loss_ce: 0.029130
2022-01-20 20:59:41,450 iteration 566 : loss : 0.134568, loss_ce: 0.050308
2022-01-20 20:59:42,071 iteration 567 : loss : 0.111042, loss_ce: 0.046185
2022-01-20 20:59:42,687 iteration 568 : loss : 0.121424, loss_ce: 0.035664
2022-01-20 20:59:43,362 iteration 569 : loss : 0.159093, loss_ce: 0.058945
2022-01-20 20:59:43,973 iteration 570 : loss : 0.086313, loss_ce: 0.041055
2022-01-20 20:59:44,612 iteration 571 : loss : 0.068995, loss_ce: 0.036704
2022-01-20 20:59:45,272 iteration 572 : loss : 0.097169, loss_ce: 0.048237
2022-01-20 20:59:45,835 iteration 573 : loss : 0.079406, loss_ce: 0.036731
2022-01-20 20:59:46,514 iteration 574 : loss : 0.081910, loss_ce: 0.032487
2022-01-20 20:59:47,106 iteration 575 : loss : 0.099883, loss_ce: 0.033946
2022-01-20 20:59:47,649 iteration 576 : loss : 0.091420, loss_ce: 0.044142
2022-01-20 20:59:48,375 iteration 577 : loss : 0.115882, loss_ce: 0.056801
2022-01-20 20:59:49,019 iteration 578 : loss : 0.081151, loss_ce: 0.037618
  8%|██▌                           | 34/400 [06:13<1:05:08, 10.68s/it]2022-01-20 20:59:49,596 iteration 579 : loss : 0.074744, loss_ce: 0.036601
2022-01-20 20:59:50,243 iteration 580 : loss : 0.089943, loss_ce: 0.035117
2022-01-20 20:59:50,996 iteration 581 : loss : 0.063770, loss_ce: 0.031744
2022-01-20 20:59:51,543 iteration 582 : loss : 0.056441, loss_ce: 0.026387
2022-01-20 20:59:52,161 iteration 583 : loss : 0.079036, loss_ce: 0.040523
2022-01-20 20:59:52,809 iteration 584 : loss : 0.069824, loss_ce: 0.032947
2022-01-20 20:59:53,383 iteration 585 : loss : 0.063340, loss_ce: 0.026518
2022-01-20 20:59:54,023 iteration 586 : loss : 0.083305, loss_ce: 0.033709
2022-01-20 20:59:54,643 iteration 587 : loss : 0.077641, loss_ce: 0.040059
2022-01-20 20:59:55,197 iteration 588 : loss : 0.098989, loss_ce: 0.041346
2022-01-20 20:59:55,854 iteration 589 : loss : 0.124583, loss_ce: 0.063983
2022-01-20 20:59:56,433 iteration 590 : loss : 0.083496, loss_ce: 0.034428
2022-01-20 20:59:57,011 iteration 591 : loss : 0.086703, loss_ce: 0.034509
2022-01-20 20:59:57,638 iteration 592 : loss : 0.062708, loss_ce: 0.034902
2022-01-20 20:59:58,176 iteration 593 : loss : 0.087367, loss_ce: 0.036882
2022-01-20 20:59:58,819 iteration 594 : loss : 0.080983, loss_ce: 0.033850
2022-01-20 20:59:58,819 Training Data Eval:
2022-01-20 21:00:01,517   Average segmentation loss on training set: 0.0657
2022-01-20 21:00:01,518 Validation Data Eval:
2022-01-20 21:00:02,396   Average segmentation loss on validation set: 0.1187
2022-01-20 21:00:02,960 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:00:03,572 iteration 595 : loss : 0.100192, loss_ce: 0.041541
  9%|██▋                           | 35/400 [06:28<1:12:02, 11.84s/it]2022-01-20 21:00:04,295 iteration 596 : loss : 0.110201, loss_ce: 0.048986
2022-01-20 21:00:04,896 iteration 597 : loss : 0.059075, loss_ce: 0.027167
2022-01-20 21:00:05,493 iteration 598 : loss : 0.078106, loss_ce: 0.027887
2022-01-20 21:00:06,122 iteration 599 : loss : 0.075259, loss_ce: 0.030398
2022-01-20 21:00:06,761 iteration 600 : loss : 0.079289, loss_ce: 0.029452
2022-01-20 21:00:07,392 iteration 601 : loss : 0.071009, loss_ce: 0.029786
2022-01-20 21:00:07,904 iteration 602 : loss : 0.073489, loss_ce: 0.034402
2022-01-20 21:00:08,490 iteration 603 : loss : 0.061763, loss_ce: 0.027265
2022-01-20 21:00:09,038 iteration 604 : loss : 0.102775, loss_ce: 0.038881
2022-01-20 21:00:09,733 iteration 605 : loss : 0.087551, loss_ce: 0.041224
2022-01-20 21:00:10,287 iteration 606 : loss : 0.052877, loss_ce: 0.024799
2022-01-20 21:00:10,839 iteration 607 : loss : 0.068358, loss_ce: 0.029140
2022-01-20 21:00:11,390 iteration 608 : loss : 0.046766, loss_ce: 0.026652
2022-01-20 21:00:11,940 iteration 609 : loss : 0.078553, loss_ce: 0.030779
2022-01-20 21:00:12,627 iteration 610 : loss : 0.091310, loss_ce: 0.044171
2022-01-20 21:00:13,211 iteration 611 : loss : 0.072987, loss_ce: 0.037345
2022-01-20 21:00:13,741 iteration 612 : loss : 0.057856, loss_ce: 0.027752
  9%|██▋                           | 36/400 [06:38<1:08:47, 11.34s/it]2022-01-20 21:00:14,380 iteration 613 : loss : 0.075135, loss_ce: 0.031453
2022-01-20 21:00:15,049 iteration 614 : loss : 0.068258, loss_ce: 0.032170
2022-01-20 21:00:15,658 iteration 615 : loss : 0.054332, loss_ce: 0.027267
2022-01-20 21:00:16,235 iteration 616 : loss : 0.109305, loss_ce: 0.042542
2022-01-20 21:00:16,874 iteration 617 : loss : 0.119124, loss_ce: 0.048189
2022-01-20 21:00:17,542 iteration 618 : loss : 0.054779, loss_ce: 0.028020
2022-01-20 21:00:18,165 iteration 619 : loss : 0.057456, loss_ce: 0.027306
2022-01-20 21:00:18,811 iteration 620 : loss : 0.050598, loss_ce: 0.024892
2022-01-20 21:00:19,322 iteration 621 : loss : 0.061661, loss_ce: 0.026122
2022-01-20 21:00:19,980 iteration 622 : loss : 0.084988, loss_ce: 0.036570
2022-01-20 21:00:20,644 iteration 623 : loss : 0.093869, loss_ce: 0.047429
2022-01-20 21:00:21,171 iteration 624 : loss : 0.085097, loss_ce: 0.038591
2022-01-20 21:00:21,893 iteration 625 : loss : 0.081540, loss_ce: 0.033541
2022-01-20 21:00:22,485 iteration 626 : loss : 0.060738, loss_ce: 0.028969
2022-01-20 21:00:23,021 iteration 627 : loss : 0.104524, loss_ce: 0.035980
2022-01-20 21:00:23,531 iteration 628 : loss : 0.093380, loss_ce: 0.038019
2022-01-20 21:00:24,147 iteration 629 : loss : 0.094339, loss_ce: 0.043864
  9%|██▊                           | 37/400 [06:49<1:06:54, 11.06s/it]2022-01-20 21:00:24,684 iteration 630 : loss : 0.069514, loss_ce: 0.033911
2022-01-20 21:00:25,269 iteration 631 : loss : 0.091893, loss_ce: 0.037997
2022-01-20 21:00:25,794 iteration 632 : loss : 0.066986, loss_ce: 0.027483
2022-01-20 21:00:26,414 iteration 633 : loss : 0.073482, loss_ce: 0.038694
2022-01-20 21:00:27,021 iteration 634 : loss : 0.061540, loss_ce: 0.032363
2022-01-20 21:00:27,643 iteration 635 : loss : 0.082442, loss_ce: 0.037643
2022-01-20 21:00:28,212 iteration 636 : loss : 0.123273, loss_ce: 0.043153
2022-01-20 21:00:28,771 iteration 637 : loss : 0.062451, loss_ce: 0.030087
2022-01-20 21:00:29,330 iteration 638 : loss : 0.056656, loss_ce: 0.029112
2022-01-20 21:00:29,970 iteration 639 : loss : 0.062974, loss_ce: 0.032693
2022-01-20 21:00:30,617 iteration 640 : loss : 0.071515, loss_ce: 0.027436
2022-01-20 21:00:31,167 iteration 641 : loss : 0.061361, loss_ce: 0.027667
2022-01-20 21:00:31,775 iteration 642 : loss : 0.072767, loss_ce: 0.030279
2022-01-20 21:00:32,354 iteration 643 : loss : 0.071222, loss_ce: 0.026971
2022-01-20 21:00:32,950 iteration 644 : loss : 0.092685, loss_ce: 0.030959
2022-01-20 21:00:33,512 iteration 645 : loss : 0.087936, loss_ce: 0.036289
2022-01-20 21:00:34,138 iteration 646 : loss : 0.061758, loss_ce: 0.027096
 10%|██▊                           | 38/400 [06:59<1:04:48, 10.74s/it]2022-01-20 21:00:34,745 iteration 647 : loss : 0.080382, loss_ce: 0.034526
2022-01-20 21:00:35,395 iteration 648 : loss : 0.113076, loss_ce: 0.049474
2022-01-20 21:00:36,014 iteration 649 : loss : 0.082128, loss_ce: 0.035926
2022-01-20 21:00:36,538 iteration 650 : loss : 0.071171, loss_ce: 0.038865
2022-01-20 21:00:37,134 iteration 651 : loss : 0.090526, loss_ce: 0.033852
2022-01-20 21:00:37,672 iteration 652 : loss : 0.091718, loss_ce: 0.033432
2022-01-20 21:00:38,284 iteration 653 : loss : 0.145566, loss_ce: 0.045559
2022-01-20 21:00:38,949 iteration 654 : loss : 0.101960, loss_ce: 0.038410
2022-01-20 21:00:39,581 iteration 655 : loss : 0.058561, loss_ce: 0.025201
2022-01-20 21:00:40,112 iteration 656 : loss : 0.067860, loss_ce: 0.033039
2022-01-20 21:00:40,704 iteration 657 : loss : 0.066821, loss_ce: 0.030502
2022-01-20 21:00:41,344 iteration 658 : loss : 0.137848, loss_ce: 0.044442
2022-01-20 21:00:41,992 iteration 659 : loss : 0.087051, loss_ce: 0.037592
2022-01-20 21:00:42,601 iteration 660 : loss : 0.081683, loss_ce: 0.035117
2022-01-20 21:00:43,199 iteration 661 : loss : 0.070604, loss_ce: 0.034504
2022-01-20 21:00:43,754 iteration 662 : loss : 0.068622, loss_ce: 0.035138
2022-01-20 21:00:44,352 iteration 663 : loss : 0.070146, loss_ce: 0.029037
 10%|██▉                           | 39/400 [07:09<1:03:40, 10.58s/it]2022-01-20 21:00:44,953 iteration 664 : loss : 0.065471, loss_ce: 0.034644
2022-01-20 21:00:45,540 iteration 665 : loss : 0.063305, loss_ce: 0.030265
2022-01-20 21:00:46,151 iteration 666 : loss : 0.097708, loss_ce: 0.040368
2022-01-20 21:00:46,700 iteration 667 : loss : 0.044131, loss_ce: 0.022227
2022-01-20 21:00:47,346 iteration 668 : loss : 0.064026, loss_ce: 0.029657
2022-01-20 21:00:47,899 iteration 669 : loss : 0.078717, loss_ce: 0.040660
2022-01-20 21:00:48,459 iteration 670 : loss : 0.064576, loss_ce: 0.032201
2022-01-20 21:00:49,095 iteration 671 : loss : 0.061309, loss_ce: 0.023243
2022-01-20 21:00:49,737 iteration 672 : loss : 0.051286, loss_ce: 0.023132
2022-01-20 21:00:50,282 iteration 673 : loss : 0.068253, loss_ce: 0.035183
2022-01-20 21:00:50,903 iteration 674 : loss : 0.084547, loss_ce: 0.041532
2022-01-20 21:00:51,542 iteration 675 : loss : 0.067620, loss_ce: 0.031120
2022-01-20 21:00:52,117 iteration 676 : loss : 0.084566, loss_ce: 0.030023
2022-01-20 21:00:52,729 iteration 677 : loss : 0.087296, loss_ce: 0.047745
2022-01-20 21:00:53,323 iteration 678 : loss : 0.086597, loss_ce: 0.033586
2022-01-20 21:00:53,871 iteration 679 : loss : 0.101197, loss_ce: 0.056110
2022-01-20 21:00:53,871 Training Data Eval:
2022-01-20 21:00:56,591   Average segmentation loss on training set: 0.0773
2022-01-20 21:00:56,591 Validation Data Eval:
2022-01-20 21:00:57,509   Average segmentation loss on validation set: 0.2166
2022-01-20 21:00:58,144 iteration 680 : loss : 0.134144, loss_ce: 0.040399
 10%|███                           | 40/400 [07:23<1:09:15, 11.54s/it]2022-01-20 21:00:58,861 iteration 681 : loss : 0.074769, loss_ce: 0.037102
2022-01-20 21:00:59,436 iteration 682 : loss : 0.057891, loss_ce: 0.022764
2022-01-20 21:01:00,066 iteration 683 : loss : 0.062755, loss_ce: 0.033942
2022-01-20 21:01:00,700 iteration 684 : loss : 0.068981, loss_ce: 0.029835
2022-01-20 21:01:01,363 iteration 685 : loss : 0.062284, loss_ce: 0.031750
2022-01-20 21:01:01,871 iteration 686 : loss : 0.074871, loss_ce: 0.025968
2022-01-20 21:01:02,425 iteration 687 : loss : 0.053360, loss_ce: 0.022128
2022-01-20 21:01:03,079 iteration 688 : loss : 0.078583, loss_ce: 0.036745
2022-01-20 21:01:03,682 iteration 689 : loss : 0.080928, loss_ce: 0.044368
2022-01-20 21:01:04,223 iteration 690 : loss : 0.105623, loss_ce: 0.056277
2022-01-20 21:01:04,896 iteration 691 : loss : 0.068760, loss_ce: 0.029153
2022-01-20 21:01:05,548 iteration 692 : loss : 0.108934, loss_ce: 0.043060
2022-01-20 21:01:06,186 iteration 693 : loss : 0.083314, loss_ce: 0.034181
2022-01-20 21:01:06,786 iteration 694 : loss : 0.065981, loss_ce: 0.028438
2022-01-20 21:01:07,377 iteration 695 : loss : 0.094867, loss_ce: 0.034184
2022-01-20 21:01:07,958 iteration 696 : loss : 0.067389, loss_ce: 0.028300
2022-01-20 21:01:08,560 iteration 697 : loss : 0.107536, loss_ce: 0.043535
 10%|███                           | 41/400 [07:33<1:07:03, 11.21s/it]2022-01-20 21:01:09,175 iteration 698 : loss : 0.070003, loss_ce: 0.030767
2022-01-20 21:01:09,772 iteration 699 : loss : 0.065179, loss_ce: 0.024895
2022-01-20 21:01:10,376 iteration 700 : loss : 0.066606, loss_ce: 0.027812
2022-01-20 21:01:10,963 iteration 701 : loss : 0.073840, loss_ce: 0.030293
2022-01-20 21:01:11,600 iteration 702 : loss : 0.063787, loss_ce: 0.023795
2022-01-20 21:01:12,191 iteration 703 : loss : 0.082583, loss_ce: 0.037155
2022-01-20 21:01:12,776 iteration 704 : loss : 0.064787, loss_ce: 0.022134
2022-01-20 21:01:13,329 iteration 705 : loss : 0.085359, loss_ce: 0.044666
2022-01-20 21:01:13,971 iteration 706 : loss : 0.078819, loss_ce: 0.037442
2022-01-20 21:01:14,593 iteration 707 : loss : 0.072214, loss_ce: 0.032836
2022-01-20 21:01:15,206 iteration 708 : loss : 0.105783, loss_ce: 0.044118
2022-01-20 21:01:15,830 iteration 709 : loss : 0.050007, loss_ce: 0.025596
2022-01-20 21:01:16,433 iteration 710 : loss : 0.061877, loss_ce: 0.024066
2022-01-20 21:01:17,071 iteration 711 : loss : 0.125858, loss_ce: 0.045844
2022-01-20 21:01:17,725 iteration 712 : loss : 0.066197, loss_ce: 0.033913
2022-01-20 21:01:18,285 iteration 713 : loss : 0.073573, loss_ce: 0.035835
2022-01-20 21:01:18,874 iteration 714 : loss : 0.064867, loss_ce: 0.035991
 10%|███▏                          | 42/400 [07:43<1:05:16, 10.94s/it]2022-01-20 21:01:19,504 iteration 715 : loss : 0.051818, loss_ce: 0.025317
2022-01-20 21:01:20,089 iteration 716 : loss : 0.114179, loss_ce: 0.041957
2022-01-20 21:01:20,666 iteration 717 : loss : 0.051550, loss_ce: 0.021746
2022-01-20 21:01:21,163 iteration 718 : loss : 0.052495, loss_ce: 0.021333
2022-01-20 21:01:21,751 iteration 719 : loss : 0.066898, loss_ce: 0.036543
2022-01-20 21:01:22,260 iteration 720 : loss : 0.054240, loss_ce: 0.025200
2022-01-20 21:01:22,974 iteration 721 : loss : 0.108508, loss_ce: 0.040767
2022-01-20 21:01:23,567 iteration 722 : loss : 0.046633, loss_ce: 0.022899
2022-01-20 21:01:24,171 iteration 723 : loss : 0.065246, loss_ce: 0.026960
2022-01-20 21:01:24,833 iteration 724 : loss : 0.075217, loss_ce: 0.037581
2022-01-20 21:01:25,381 iteration 725 : loss : 0.054330, loss_ce: 0.025165
2022-01-20 21:01:25,984 iteration 726 : loss : 0.082094, loss_ce: 0.043892
2022-01-20 21:01:26,542 iteration 727 : loss : 0.042803, loss_ce: 0.019719
2022-01-20 21:01:27,113 iteration 728 : loss : 0.072460, loss_ce: 0.026953
2022-01-20 21:01:27,684 iteration 729 : loss : 0.084865, loss_ce: 0.045255
2022-01-20 21:01:28,295 iteration 730 : loss : 0.067370, loss_ce: 0.027745
2022-01-20 21:01:28,858 iteration 731 : loss : 0.079534, loss_ce: 0.033181
 11%|███▏                          | 43/400 [07:53<1:03:23, 10.65s/it]2022-01-20 21:01:29,540 iteration 732 : loss : 0.050384, loss_ce: 0.022636
2022-01-20 21:01:30,161 iteration 733 : loss : 0.054499, loss_ce: 0.025580
2022-01-20 21:01:30,775 iteration 734 : loss : 0.096919, loss_ce: 0.041553
2022-01-20 21:01:31,398 iteration 735 : loss : 0.075286, loss_ce: 0.028834
2022-01-20 21:01:32,014 iteration 736 : loss : 0.051017, loss_ce: 0.022777
2022-01-20 21:01:32,547 iteration 737 : loss : 0.050054, loss_ce: 0.023129
2022-01-20 21:01:33,199 iteration 738 : loss : 0.070411, loss_ce: 0.031880
2022-01-20 21:01:33,814 iteration 739 : loss : 0.083824, loss_ce: 0.041196
2022-01-20 21:01:34,405 iteration 740 : loss : 0.052744, loss_ce: 0.020031
2022-01-20 21:01:35,025 iteration 741 : loss : 0.056776, loss_ce: 0.025420
2022-01-20 21:01:35,647 iteration 742 : loss : 0.051958, loss_ce: 0.020477
2022-01-20 21:01:36,229 iteration 743 : loss : 0.055904, loss_ce: 0.021548
2022-01-20 21:01:36,838 iteration 744 : loss : 0.055844, loss_ce: 0.026023
2022-01-20 21:01:37,430 iteration 745 : loss : 0.063519, loss_ce: 0.027659
2022-01-20 21:01:38,002 iteration 746 : loss : 0.117077, loss_ce: 0.041860
2022-01-20 21:01:38,586 iteration 747 : loss : 0.062928, loss_ce: 0.028784
2022-01-20 21:01:39,206 iteration 748 : loss : 0.056980, loss_ce: 0.023550
 11%|███▎                          | 44/400 [08:04<1:02:38, 10.56s/it]2022-01-20 21:01:39,813 iteration 749 : loss : 0.066390, loss_ce: 0.025554
2022-01-20 21:01:40,380 iteration 750 : loss : 0.051832, loss_ce: 0.018329
2022-01-20 21:01:41,008 iteration 751 : loss : 0.075687, loss_ce: 0.031046
2022-01-20 21:01:41,570 iteration 752 : loss : 0.058243, loss_ce: 0.028170
2022-01-20 21:01:42,192 iteration 753 : loss : 0.061602, loss_ce: 0.027909
2022-01-20 21:01:42,779 iteration 754 : loss : 0.052981, loss_ce: 0.021457
2022-01-20 21:01:43,382 iteration 755 : loss : 0.048313, loss_ce: 0.021095
2022-01-20 21:01:43,890 iteration 756 : loss : 0.054314, loss_ce: 0.025344
2022-01-20 21:01:44,424 iteration 757 : loss : 0.055678, loss_ce: 0.025854
2022-01-20 21:01:45,029 iteration 758 : loss : 0.086487, loss_ce: 0.038145
2022-01-20 21:01:45,672 iteration 759 : loss : 0.086642, loss_ce: 0.030709
2022-01-20 21:01:46,284 iteration 760 : loss : 0.070595, loss_ce: 0.028338
2022-01-20 21:01:46,921 iteration 761 : loss : 0.068275, loss_ce: 0.025755
2022-01-20 21:01:47,435 iteration 762 : loss : 0.060216, loss_ce: 0.030665
2022-01-20 21:01:48,018 iteration 763 : loss : 0.050477, loss_ce: 0.025516
2022-01-20 21:01:48,529 iteration 764 : loss : 0.057084, loss_ce: 0.022872
2022-01-20 21:01:48,529 Training Data Eval:
2022-01-20 21:01:51,216   Average segmentation loss on training set: 0.0515
2022-01-20 21:01:51,216 Validation Data Eval:
2022-01-20 21:01:52,095   Average segmentation loss on validation set: 0.1112
2022-01-20 21:01:52,667 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:01:53,173 iteration 765 : loss : 0.064434, loss_ce: 0.030125
 11%|███▍                          | 45/400 [08:18<1:08:31, 11.58s/it]2022-01-20 21:01:53,885 iteration 766 : loss : 0.067718, loss_ce: 0.026505
2022-01-20 21:01:54,633 iteration 767 : loss : 0.085376, loss_ce: 0.038472
2022-01-20 21:01:55,268 iteration 768 : loss : 0.078850, loss_ce: 0.031884
2022-01-20 21:01:55,910 iteration 769 : loss : 0.065352, loss_ce: 0.032039
2022-01-20 21:01:56,589 iteration 770 : loss : 0.067536, loss_ce: 0.035670
2022-01-20 21:01:57,217 iteration 771 : loss : 0.048232, loss_ce: 0.026338
2022-01-20 21:01:57,756 iteration 772 : loss : 0.054422, loss_ce: 0.026022
2022-01-20 21:01:58,338 iteration 773 : loss : 0.072199, loss_ce: 0.025639
2022-01-20 21:01:58,999 iteration 774 : loss : 0.068780, loss_ce: 0.029875
2022-01-20 21:01:59,527 iteration 775 : loss : 0.056268, loss_ce: 0.023224
2022-01-20 21:02:00,091 iteration 776 : loss : 0.097939, loss_ce: 0.036042
2022-01-20 21:02:00,787 iteration 777 : loss : 0.052242, loss_ce: 0.025985
2022-01-20 21:02:01,390 iteration 778 : loss : 0.060484, loss_ce: 0.021545
2022-01-20 21:02:01,976 iteration 779 : loss : 0.087636, loss_ce: 0.036251
2022-01-20 21:02:02,667 iteration 780 : loss : 0.098776, loss_ce: 0.046674
2022-01-20 21:02:03,304 iteration 781 : loss : 0.044023, loss_ce: 0.018731
2022-01-20 21:02:03,876 iteration 782 : loss : 0.079393, loss_ce: 0.036581
 12%|███▍                          | 46/400 [08:28<1:06:46, 11.32s/it]2022-01-20 21:02:04,503 iteration 783 : loss : 0.061374, loss_ce: 0.028954
2022-01-20 21:02:05,044 iteration 784 : loss : 0.045848, loss_ce: 0.018116
2022-01-20 21:02:05,700 iteration 785 : loss : 0.084407, loss_ce: 0.033480
2022-01-20 21:02:06,282 iteration 786 : loss : 0.069223, loss_ce: 0.025747
2022-01-20 21:02:06,924 iteration 787 : loss : 0.068902, loss_ce: 0.028788
2022-01-20 21:02:07,474 iteration 788 : loss : 0.083782, loss_ce: 0.039179
2022-01-20 21:02:08,108 iteration 789 : loss : 0.082187, loss_ce: 0.033452
2022-01-20 21:02:08,758 iteration 790 : loss : 0.053480, loss_ce: 0.026098
2022-01-20 21:02:09,289 iteration 791 : loss : 0.051729, loss_ce: 0.026911
2022-01-20 21:02:09,943 iteration 792 : loss : 0.071153, loss_ce: 0.030357
2022-01-20 21:02:10,572 iteration 793 : loss : 0.079025, loss_ce: 0.034233
2022-01-20 21:02:11,213 iteration 794 : loss : 0.047332, loss_ce: 0.020380
2022-01-20 21:02:11,837 iteration 795 : loss : 0.067413, loss_ce: 0.028582
2022-01-20 21:02:12,520 iteration 796 : loss : 0.063020, loss_ce: 0.028114
2022-01-20 21:02:13,110 iteration 797 : loss : 0.040656, loss_ce: 0.021085
2022-01-20 21:02:13,696 iteration 798 : loss : 0.067505, loss_ce: 0.032857
2022-01-20 21:02:14,402 iteration 799 : loss : 0.143590, loss_ce: 0.056336
 12%|███▌                          | 47/400 [08:39<1:05:11, 11.08s/it]2022-01-20 21:02:15,066 iteration 800 : loss : 0.069240, loss_ce: 0.033760
2022-01-20 21:02:15,643 iteration 801 : loss : 0.087432, loss_ce: 0.026482
2022-01-20 21:02:16,274 iteration 802 : loss : 0.088705, loss_ce: 0.042086
2022-01-20 21:02:16,802 iteration 803 : loss : 0.047518, loss_ce: 0.019708
2022-01-20 21:02:17,490 iteration 804 : loss : 0.081283, loss_ce: 0.024074
2022-01-20 21:02:18,069 iteration 805 : loss : 0.063278, loss_ce: 0.029065
2022-01-20 21:02:18,590 iteration 806 : loss : 0.062779, loss_ce: 0.025533
2022-01-20 21:02:19,180 iteration 807 : loss : 0.053737, loss_ce: 0.030829
2022-01-20 21:02:19,771 iteration 808 : loss : 0.068179, loss_ce: 0.023215
2022-01-20 21:02:20,427 iteration 809 : loss : 0.066832, loss_ce: 0.029575
2022-01-20 21:02:20,982 iteration 810 : loss : 0.048345, loss_ce: 0.018067
2022-01-20 21:02:21,610 iteration 811 : loss : 0.107762, loss_ce: 0.044472
2022-01-20 21:02:22,153 iteration 812 : loss : 0.078251, loss_ce: 0.041486
2022-01-20 21:02:22,810 iteration 813 : loss : 0.054933, loss_ce: 0.025366
2022-01-20 21:02:23,506 iteration 814 : loss : 0.146547, loss_ce: 0.035175
2022-01-20 21:02:23,973 iteration 815 : loss : 0.051002, loss_ce: 0.025634
2022-01-20 21:02:24,632 iteration 816 : loss : 0.083535, loss_ce: 0.034688
 12%|███▌                          | 48/400 [08:49<1:03:30, 10.83s/it]2022-01-20 21:02:25,228 iteration 817 : loss : 0.056955, loss_ce: 0.024249
2022-01-20 21:02:25,800 iteration 818 : loss : 0.071757, loss_ce: 0.033248
2022-01-20 21:02:26,524 iteration 819 : loss : 0.099067, loss_ce: 0.047629
2022-01-20 21:02:27,186 iteration 820 : loss : 0.093156, loss_ce: 0.040230
2022-01-20 21:02:27,829 iteration 821 : loss : 0.086277, loss_ce: 0.037793
2022-01-20 21:02:28,432 iteration 822 : loss : 0.071193, loss_ce: 0.031466
2022-01-20 21:02:29,058 iteration 823 : loss : 0.061467, loss_ce: 0.027837
2022-01-20 21:02:29,593 iteration 824 : loss : 0.057615, loss_ce: 0.019925
2022-01-20 21:02:30,177 iteration 825 : loss : 0.117710, loss_ce: 0.035889
2022-01-20 21:02:30,708 iteration 826 : loss : 0.055357, loss_ce: 0.023999
2022-01-20 21:02:31,298 iteration 827 : loss : 0.094218, loss_ce: 0.034270
2022-01-20 21:02:31,817 iteration 828 : loss : 0.058567, loss_ce: 0.024589
2022-01-20 21:02:32,486 iteration 829 : loss : 0.068635, loss_ce: 0.033313
2022-01-20 21:02:33,063 iteration 830 : loss : 0.076324, loss_ce: 0.036053
2022-01-20 21:02:33,697 iteration 831 : loss : 0.094771, loss_ce: 0.046184
2022-01-20 21:02:34,311 iteration 832 : loss : 0.071468, loss_ce: 0.024777
2022-01-20 21:02:34,917 iteration 833 : loss : 0.063425, loss_ce: 0.030359
 12%|███▋                          | 49/400 [08:59<1:02:22, 10.66s/it]2022-01-20 21:02:35,472 iteration 834 : loss : 0.064251, loss_ce: 0.024379
2022-01-20 21:02:35,977 iteration 835 : loss : 0.040245, loss_ce: 0.015657
2022-01-20 21:02:36,627 iteration 836 : loss : 0.087507, loss_ce: 0.033396
2022-01-20 21:02:37,190 iteration 837 : loss : 0.040864, loss_ce: 0.017605
2022-01-20 21:02:37,819 iteration 838 : loss : 0.108305, loss_ce: 0.063662
2022-01-20 21:02:38,335 iteration 839 : loss : 0.052371, loss_ce: 0.021596
2022-01-20 21:02:38,856 iteration 840 : loss : 0.049614, loss_ce: 0.025494
2022-01-20 21:02:39,395 iteration 841 : loss : 0.064516, loss_ce: 0.026017
2022-01-20 21:02:40,065 iteration 842 : loss : 0.095270, loss_ce: 0.035591
2022-01-20 21:02:40,616 iteration 843 : loss : 0.069662, loss_ce: 0.025241
2022-01-20 21:02:41,257 iteration 844 : loss : 0.062872, loss_ce: 0.024565
2022-01-20 21:02:41,836 iteration 845 : loss : 0.061487, loss_ce: 0.032668
2022-01-20 21:02:42,416 iteration 846 : loss : 0.047427, loss_ce: 0.023940
2022-01-20 21:02:43,082 iteration 847 : loss : 0.065990, loss_ce: 0.024203
2022-01-20 21:02:43,665 iteration 848 : loss : 0.042598, loss_ce: 0.018643
2022-01-20 21:02:44,231 iteration 849 : loss : 0.057998, loss_ce: 0.024635
2022-01-20 21:02:44,231 Training Data Eval:
2022-01-20 21:02:46,919   Average segmentation loss on training set: 0.0576
2022-01-20 21:02:46,919 Validation Data Eval:
2022-01-20 21:02:47,797   Average segmentation loss on validation set: 0.1432
2022-01-20 21:02:48,330 iteration 850 : loss : 0.089855, loss_ce: 0.042911
 12%|███▊                          | 50/400 [09:13<1:07:00, 11.49s/it]2022-01-20 21:02:48,960 iteration 851 : loss : 0.065060, loss_ce: 0.026867
2022-01-20 21:02:49,539 iteration 852 : loss : 0.060093, loss_ce: 0.022763
2022-01-20 21:02:50,136 iteration 853 : loss : 0.062579, loss_ce: 0.025002
2022-01-20 21:02:50,744 iteration 854 : loss : 0.061765, loss_ce: 0.029327
2022-01-20 21:02:51,302 iteration 855 : loss : 0.049696, loss_ce: 0.023179
2022-01-20 21:02:51,926 iteration 856 : loss : 0.088796, loss_ce: 0.045305
2022-01-20 21:02:52,493 iteration 857 : loss : 0.080430, loss_ce: 0.042884
2022-01-20 21:02:53,163 iteration 858 : loss : 0.040788, loss_ce: 0.019399
2022-01-20 21:02:53,628 iteration 859 : loss : 0.045301, loss_ce: 0.016697
2022-01-20 21:02:54,202 iteration 860 : loss : 0.048126, loss_ce: 0.019660
2022-01-20 21:02:54,791 iteration 861 : loss : 0.067992, loss_ce: 0.022855
2022-01-20 21:02:55,402 iteration 862 : loss : 0.056626, loss_ce: 0.029316
2022-01-20 21:02:55,994 iteration 863 : loss : 0.080329, loss_ce: 0.037411
2022-01-20 21:02:56,568 iteration 864 : loss : 0.061675, loss_ce: 0.028222
2022-01-20 21:02:57,164 iteration 865 : loss : 0.045808, loss_ce: 0.019859
2022-01-20 21:02:57,717 iteration 866 : loss : 0.058462, loss_ce: 0.028978
2022-01-20 21:02:58,341 iteration 867 : loss : 0.046611, loss_ce: 0.019324
 13%|███▊                          | 51/400 [09:23<1:04:14, 11.05s/it]2022-01-20 21:02:58,960 iteration 868 : loss : 0.058664, loss_ce: 0.025063
2022-01-20 21:02:59,587 iteration 869 : loss : 0.052429, loss_ce: 0.024695
2022-01-20 21:03:00,090 iteration 870 : loss : 0.054758, loss_ce: 0.026246
2022-01-20 21:03:00,657 iteration 871 : loss : 0.055575, loss_ce: 0.027161
2022-01-20 21:03:01,227 iteration 872 : loss : 0.060870, loss_ce: 0.027374
2022-01-20 21:03:01,850 iteration 873 : loss : 0.063207, loss_ce: 0.031192
2022-01-20 21:03:02,454 iteration 874 : loss : 0.055308, loss_ce: 0.025137
2022-01-20 21:03:03,056 iteration 875 : loss : 0.064676, loss_ce: 0.025997
2022-01-20 21:03:03,653 iteration 876 : loss : 0.052152, loss_ce: 0.021419
2022-01-20 21:03:04,314 iteration 877 : loss : 0.054445, loss_ce: 0.024063
2022-01-20 21:03:04,871 iteration 878 : loss : 0.132218, loss_ce: 0.036178
2022-01-20 21:03:05,449 iteration 879 : loss : 0.099077, loss_ce: 0.032874
2022-01-20 21:03:05,996 iteration 880 : loss : 0.053570, loss_ce: 0.025402
2022-01-20 21:03:06,652 iteration 881 : loss : 0.058016, loss_ce: 0.020450
2022-01-20 21:03:07,270 iteration 882 : loss : 0.062589, loss_ce: 0.026307
2022-01-20 21:03:07,830 iteration 883 : loss : 0.062087, loss_ce: 0.023094
2022-01-20 21:03:08,464 iteration 884 : loss : 0.065393, loss_ce: 0.027229
 13%|███▉                          | 52/400 [09:33<1:02:27, 10.77s/it]2022-01-20 21:03:09,117 iteration 885 : loss : 0.068214, loss_ce: 0.039701
2022-01-20 21:03:09,718 iteration 886 : loss : 0.080940, loss_ce: 0.040538
2022-01-20 21:03:10,313 iteration 887 : loss : 0.066972, loss_ce: 0.024523
2022-01-20 21:03:10,925 iteration 888 : loss : 0.065418, loss_ce: 0.030927
2022-01-20 21:03:11,524 iteration 889 : loss : 0.104348, loss_ce: 0.032394
2022-01-20 21:03:12,090 iteration 890 : loss : 0.048522, loss_ce: 0.021561
2022-01-20 21:03:12,687 iteration 891 : loss : 0.055680, loss_ce: 0.039654
2022-01-20 21:03:13,287 iteration 892 : loss : 0.046750, loss_ce: 0.020529
2022-01-20 21:03:13,875 iteration 893 : loss : 0.045359, loss_ce: 0.021376
2022-01-20 21:03:14,451 iteration 894 : loss : 0.048730, loss_ce: 0.017406
2022-01-20 21:03:15,026 iteration 895 : loss : 0.066906, loss_ce: 0.023478
2022-01-20 21:03:15,577 iteration 896 : loss : 0.074068, loss_ce: 0.040032
2022-01-20 21:03:16,306 iteration 897 : loss : 0.061413, loss_ce: 0.027415
2022-01-20 21:03:16,880 iteration 898 : loss : 0.074820, loss_ce: 0.027906
2022-01-20 21:03:17,522 iteration 899 : loss : 0.068013, loss_ce: 0.025509
2022-01-20 21:03:18,146 iteration 900 : loss : 0.088148, loss_ce: 0.031503
2022-01-20 21:03:18,707 iteration 901 : loss : 0.065865, loss_ce: 0.030264
 13%|███▉                          | 53/400 [09:43<1:01:22, 10.61s/it]2022-01-20 21:03:19,409 iteration 902 : loss : 0.054627, loss_ce: 0.026927
2022-01-20 21:03:20,030 iteration 903 : loss : 0.104290, loss_ce: 0.031096
2022-01-20 21:03:20,611 iteration 904 : loss : 0.104824, loss_ce: 0.054149
2022-01-20 21:03:21,182 iteration 905 : loss : 0.056643, loss_ce: 0.027300
2022-01-20 21:03:21,858 iteration 906 : loss : 0.092360, loss_ce: 0.039658
2022-01-20 21:03:22,409 iteration 907 : loss : 0.063066, loss_ce: 0.026309
2022-01-20 21:03:22,968 iteration 908 : loss : 0.064023, loss_ce: 0.030820
2022-01-20 21:03:23,586 iteration 909 : loss : 0.055994, loss_ce: 0.024759
2022-01-20 21:03:24,263 iteration 910 : loss : 0.067483, loss_ce: 0.030746
2022-01-20 21:03:24,850 iteration 911 : loss : 0.064771, loss_ce: 0.026638
2022-01-20 21:03:25,478 iteration 912 : loss : 0.077259, loss_ce: 0.037338
2022-01-20 21:03:26,073 iteration 913 : loss : 0.069957, loss_ce: 0.026024
2022-01-20 21:03:26,604 iteration 914 : loss : 0.061624, loss_ce: 0.027614
2022-01-20 21:03:27,214 iteration 915 : loss : 0.080560, loss_ce: 0.031872
2022-01-20 21:03:27,882 iteration 916 : loss : 0.090318, loss_ce: 0.029508
2022-01-20 21:03:28,504 iteration 917 : loss : 0.056182, loss_ce: 0.023568
2022-01-20 21:03:29,182 iteration 918 : loss : 0.097833, loss_ce: 0.032684
 14%|████                          | 54/400 [09:54<1:00:57, 10.57s/it]2022-01-20 21:03:29,800 iteration 919 : loss : 0.061104, loss_ce: 0.021564
2022-01-20 21:03:30,467 iteration 920 : loss : 0.069516, loss_ce: 0.033261
2022-01-20 21:03:31,009 iteration 921 : loss : 0.052332, loss_ce: 0.021238
2022-01-20 21:03:31,631 iteration 922 : loss : 0.057924, loss_ce: 0.022336
2022-01-20 21:03:32,159 iteration 923 : loss : 0.045496, loss_ce: 0.017225
2022-01-20 21:03:32,771 iteration 924 : loss : 0.091070, loss_ce: 0.033203
2022-01-20 21:03:33,393 iteration 925 : loss : 0.081278, loss_ce: 0.022913
2022-01-20 21:03:34,001 iteration 926 : loss : 0.059037, loss_ce: 0.022452
2022-01-20 21:03:34,524 iteration 927 : loss : 0.117837, loss_ce: 0.034902
2022-01-20 21:03:35,181 iteration 928 : loss : 0.053118, loss_ce: 0.026617
2022-01-20 21:03:35,762 iteration 929 : loss : 0.061309, loss_ce: 0.026731
2022-01-20 21:03:36,300 iteration 930 : loss : 0.043918, loss_ce: 0.018758
2022-01-20 21:03:36,859 iteration 931 : loss : 0.089119, loss_ce: 0.051292
2022-01-20 21:03:37,457 iteration 932 : loss : 0.055010, loss_ce: 0.028420
2022-01-20 21:03:38,086 iteration 933 : loss : 0.060794, loss_ce: 0.030119
2022-01-20 21:03:38,641 iteration 934 : loss : 0.061472, loss_ce: 0.022275
2022-01-20 21:03:38,641 Training Data Eval:
2022-01-20 21:03:41,327   Average segmentation loss on training set: 0.0527
2022-01-20 21:03:41,328 Validation Data Eval:
2022-01-20 21:03:42,215   Average segmentation loss on validation set: 0.0999
2022-01-20 21:03:42,924 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:03:43,544 iteration 935 : loss : 0.051932, loss_ce: 0.023504
 14%|████▏                         | 55/400 [10:08<1:07:18, 11.71s/it]2022-01-20 21:03:44,194 iteration 936 : loss : 0.057288, loss_ce: 0.026976
2022-01-20 21:03:44,772 iteration 937 : loss : 0.100167, loss_ce: 0.042952
2022-01-20 21:03:45,383 iteration 938 : loss : 0.046507, loss_ce: 0.022817
2022-01-20 21:03:46,079 iteration 939 : loss : 0.099851, loss_ce: 0.027934
2022-01-20 21:03:46,612 iteration 940 : loss : 0.060769, loss_ce: 0.023596
2022-01-20 21:03:47,171 iteration 941 : loss : 0.059953, loss_ce: 0.022534
2022-01-20 21:03:47,753 iteration 942 : loss : 0.068485, loss_ce: 0.030793
2022-01-20 21:03:48,367 iteration 943 : loss : 0.080216, loss_ce: 0.026674
2022-01-20 21:03:48,962 iteration 944 : loss : 0.097595, loss_ce: 0.035372
2022-01-20 21:03:49,582 iteration 945 : loss : 0.065379, loss_ce: 0.028975
2022-01-20 21:03:50,174 iteration 946 : loss : 0.054397, loss_ce: 0.021836
2022-01-20 21:03:50,775 iteration 947 : loss : 0.048403, loss_ce: 0.016265
2022-01-20 21:03:51,441 iteration 948 : loss : 0.107574, loss_ce: 0.048760
2022-01-20 21:03:52,114 iteration 949 : loss : 0.104866, loss_ce: 0.045388
2022-01-20 21:03:52,796 iteration 950 : loss : 0.063591, loss_ce: 0.026482
2022-01-20 21:03:53,385 iteration 951 : loss : 0.046176, loss_ce: 0.018749
2022-01-20 21:03:54,023 iteration 952 : loss : 0.081085, loss_ce: 0.028382
 14%|████▏                         | 56/400 [10:18<1:05:01, 11.34s/it]2022-01-20 21:03:54,636 iteration 953 : loss : 0.065509, loss_ce: 0.024035
2022-01-20 21:03:55,210 iteration 954 : loss : 0.061703, loss_ce: 0.023161
2022-01-20 21:03:55,838 iteration 955 : loss : 0.058886, loss_ce: 0.022487
2022-01-20 21:03:56,465 iteration 956 : loss : 0.043759, loss_ce: 0.017130
2022-01-20 21:03:57,071 iteration 957 : loss : 0.066937, loss_ce: 0.025335
2022-01-20 21:03:57,700 iteration 958 : loss : 0.069500, loss_ce: 0.027327
2022-01-20 21:03:58,356 iteration 959 : loss : 0.091372, loss_ce: 0.038859
2022-01-20 21:03:58,991 iteration 960 : loss : 0.064008, loss_ce: 0.026769
2022-01-20 21:03:59,604 iteration 961 : loss : 0.069017, loss_ce: 0.028461
2022-01-20 21:04:00,242 iteration 962 : loss : 0.081343, loss_ce: 0.023651
2022-01-20 21:04:00,786 iteration 963 : loss : 0.066764, loss_ce: 0.028603
2022-01-20 21:04:01,410 iteration 964 : loss : 0.067727, loss_ce: 0.019607
2022-01-20 21:04:01,976 iteration 965 : loss : 0.044303, loss_ce: 0.017039
2022-01-20 21:04:02,657 iteration 966 : loss : 0.085806, loss_ce: 0.029022
2022-01-20 21:04:03,274 iteration 967 : loss : 0.056079, loss_ce: 0.026950
2022-01-20 21:04:03,795 iteration 968 : loss : 0.057625, loss_ce: 0.024217
2022-01-20 21:04:04,397 iteration 969 : loss : 0.063157, loss_ce: 0.032979
 14%|████▎                         | 57/400 [10:29<1:03:09, 11.05s/it]2022-01-20 21:04:04,987 iteration 970 : loss : 0.071320, loss_ce: 0.034575
2022-01-20 21:04:05,605 iteration 971 : loss : 0.052571, loss_ce: 0.025043
2022-01-20 21:04:06,190 iteration 972 : loss : 0.059415, loss_ce: 0.024084
2022-01-20 21:04:06,802 iteration 973 : loss : 0.048977, loss_ce: 0.023058
2022-01-20 21:04:07,393 iteration 974 : loss : 0.075204, loss_ce: 0.029911
2022-01-20 21:04:07,945 iteration 975 : loss : 0.062146, loss_ce: 0.024178
2022-01-20 21:04:08,597 iteration 976 : loss : 0.065566, loss_ce: 0.031137
2022-01-20 21:04:09,184 iteration 977 : loss : 0.049453, loss_ce: 0.021777
2022-01-20 21:04:09,807 iteration 978 : loss : 0.049390, loss_ce: 0.019909
2022-01-20 21:04:10,377 iteration 979 : loss : 0.049194, loss_ce: 0.021695
2022-01-20 21:04:10,946 iteration 980 : loss : 0.055657, loss_ce: 0.021275
2022-01-20 21:04:11,504 iteration 981 : loss : 0.027961, loss_ce: 0.011922
2022-01-20 21:04:12,128 iteration 982 : loss : 0.074629, loss_ce: 0.032633
2022-01-20 21:04:12,790 iteration 983 : loss : 0.062396, loss_ce: 0.029152
2022-01-20 21:04:13,453 iteration 984 : loss : 0.058183, loss_ce: 0.026962
2022-01-20 21:04:14,088 iteration 985 : loss : 0.068665, loss_ce: 0.032030
2022-01-20 21:04:14,650 iteration 986 : loss : 0.049390, loss_ce: 0.015775
 14%|████▎                         | 58/400 [10:39<1:01:37, 10.81s/it]2022-01-20 21:04:15,203 iteration 987 : loss : 0.049718, loss_ce: 0.017984
2022-01-20 21:04:15,787 iteration 988 : loss : 0.049790, loss_ce: 0.020116
2022-01-20 21:04:16,368 iteration 989 : loss : 0.042742, loss_ce: 0.018081
2022-01-20 21:04:16,948 iteration 990 : loss : 0.053030, loss_ce: 0.019705
2022-01-20 21:04:17,538 iteration 991 : loss : 0.059619, loss_ce: 0.022013
2022-01-20 21:04:18,097 iteration 992 : loss : 0.040543, loss_ce: 0.017673
2022-01-20 21:04:18,616 iteration 993 : loss : 0.050551, loss_ce: 0.018571
2022-01-20 21:04:19,084 iteration 994 : loss : 0.051222, loss_ce: 0.020056
2022-01-20 21:04:19,741 iteration 995 : loss : 0.049728, loss_ce: 0.024625
2022-01-20 21:04:20,354 iteration 996 : loss : 0.045682, loss_ce: 0.022414
2022-01-20 21:04:20,990 iteration 997 : loss : 0.075012, loss_ce: 0.032966
2022-01-20 21:04:21,613 iteration 998 : loss : 0.047545, loss_ce: 0.017501
2022-01-20 21:04:22,164 iteration 999 : loss : 0.048683, loss_ce: 0.023021
2022-01-20 21:04:22,808 iteration 1000 : loss : 0.048748, loss_ce: 0.026814
2022-01-20 21:04:23,375 iteration 1001 : loss : 0.050143, loss_ce: 0.019617
2022-01-20 21:04:24,026 iteration 1002 : loss : 0.057582, loss_ce: 0.025335
2022-01-20 21:04:24,558 iteration 1003 : loss : 0.104015, loss_ce: 0.031998
 15%|████▋                           | 59/400 [10:49<59:53, 10.54s/it]2022-01-20 21:04:25,186 iteration 1004 : loss : 0.057979, loss_ce: 0.023155
2022-01-20 21:04:25,782 iteration 1005 : loss : 0.075277, loss_ce: 0.039370
2022-01-20 21:04:26,473 iteration 1006 : loss : 0.059450, loss_ce: 0.025109
2022-01-20 21:04:27,128 iteration 1007 : loss : 0.061552, loss_ce: 0.026558
2022-01-20 21:04:27,781 iteration 1008 : loss : 0.055024, loss_ce: 0.028800
2022-01-20 21:04:28,352 iteration 1009 : loss : 0.041079, loss_ce: 0.016401
2022-01-20 21:04:28,876 iteration 1010 : loss : 0.042358, loss_ce: 0.013996
2022-01-20 21:04:29,447 iteration 1011 : loss : 0.079328, loss_ce: 0.039326
2022-01-20 21:04:30,087 iteration 1012 : loss : 0.061741, loss_ce: 0.027456
2022-01-20 21:04:30,673 iteration 1013 : loss : 0.042234, loss_ce: 0.016283
2022-01-20 21:04:31,248 iteration 1014 : loss : 0.036519, loss_ce: 0.014526
2022-01-20 21:04:31,961 iteration 1015 : loss : 0.085953, loss_ce: 0.034107
2022-01-20 21:04:32,547 iteration 1016 : loss : 0.049125, loss_ce: 0.019664
2022-01-20 21:04:33,110 iteration 1017 : loss : 0.080130, loss_ce: 0.031314
2022-01-20 21:04:33,764 iteration 1018 : loss : 0.059494, loss_ce: 0.021075
2022-01-20 21:04:34,395 iteration 1019 : loss : 0.053030, loss_ce: 0.022740
2022-01-20 21:04:34,395 Training Data Eval:
2022-01-20 21:04:37,087   Average segmentation loss on training set: 0.0506
2022-01-20 21:04:37,087 Validation Data Eval:
2022-01-20 21:04:37,971   Average segmentation loss on validation set: 0.1871
2022-01-20 21:04:38,636 iteration 1020 : loss : 0.060298, loss_ce: 0.028699
 15%|████▌                         | 60/400 [11:03<1:05:44, 11.60s/it]2022-01-20 21:04:39,253 iteration 1021 : loss : 0.053929, loss_ce: 0.019885
2022-01-20 21:04:39,931 iteration 1022 : loss : 0.059949, loss_ce: 0.030211
2022-01-20 21:04:40,482 iteration 1023 : loss : 0.055869, loss_ce: 0.022963
2022-01-20 21:04:41,044 iteration 1024 : loss : 0.041517, loss_ce: 0.016405
2022-01-20 21:04:41,687 iteration 1025 : loss : 0.042996, loss_ce: 0.019256
2022-01-20 21:04:42,306 iteration 1026 : loss : 0.083629, loss_ce: 0.019552
2022-01-20 21:04:42,889 iteration 1027 : loss : 0.044964, loss_ce: 0.015347
2022-01-20 21:04:43,574 iteration 1028 : loss : 0.066671, loss_ce: 0.023237
2022-01-20 21:04:44,226 iteration 1029 : loss : 0.073735, loss_ce: 0.024412
2022-01-20 21:04:44,835 iteration 1030 : loss : 0.077476, loss_ce: 0.034556
2022-01-20 21:04:45,533 iteration 1031 : loss : 0.068300, loss_ce: 0.033740
2022-01-20 21:04:46,153 iteration 1032 : loss : 0.061118, loss_ce: 0.026454
2022-01-20 21:04:46,731 iteration 1033 : loss : 0.064617, loss_ce: 0.030435
2022-01-20 21:04:47,278 iteration 1034 : loss : 0.039591, loss_ce: 0.017602
2022-01-20 21:04:47,914 iteration 1035 : loss : 0.055389, loss_ce: 0.024864
2022-01-20 21:04:48,573 iteration 1036 : loss : 0.060159, loss_ce: 0.026763
2022-01-20 21:04:49,094 iteration 1037 : loss : 0.042950, loss_ce: 0.019798
 15%|████▌                         | 61/400 [11:13<1:03:36, 11.26s/it]2022-01-20 21:04:49,692 iteration 1038 : loss : 0.050053, loss_ce: 0.023646
2022-01-20 21:04:50,260 iteration 1039 : loss : 0.042758, loss_ce: 0.017839
2022-01-20 21:04:50,834 iteration 1040 : loss : 0.076870, loss_ce: 0.025464
2022-01-20 21:04:51,432 iteration 1041 : loss : 0.057759, loss_ce: 0.027846
2022-01-20 21:04:52,009 iteration 1042 : loss : 0.046401, loss_ce: 0.025414
2022-01-20 21:04:52,595 iteration 1043 : loss : 0.043618, loss_ce: 0.018436
2022-01-20 21:04:53,251 iteration 1044 : loss : 0.058887, loss_ce: 0.027786
2022-01-20 21:04:53,866 iteration 1045 : loss : 0.055811, loss_ce: 0.023737
2022-01-20 21:04:54,429 iteration 1046 : loss : 0.046465, loss_ce: 0.023281
2022-01-20 21:04:54,910 iteration 1047 : loss : 0.046324, loss_ce: 0.018591
2022-01-20 21:04:55,509 iteration 1048 : loss : 0.041799, loss_ce: 0.019523
2022-01-20 21:04:56,149 iteration 1049 : loss : 0.047196, loss_ce: 0.018493
2022-01-20 21:04:56,733 iteration 1050 : loss : 0.086424, loss_ce: 0.020979
2022-01-20 21:04:57,296 iteration 1051 : loss : 0.048707, loss_ce: 0.024071
2022-01-20 21:04:57,936 iteration 1052 : loss : 0.054832, loss_ce: 0.019591
2022-01-20 21:04:58,560 iteration 1053 : loss : 0.066421, loss_ce: 0.017841
2022-01-20 21:04:59,160 iteration 1054 : loss : 0.049563, loss_ce: 0.019808
 16%|████▋                         | 62/400 [11:24<1:01:24, 10.90s/it]2022-01-20 21:04:59,792 iteration 1055 : loss : 0.047772, loss_ce: 0.015678
2022-01-20 21:05:00,308 iteration 1056 : loss : 0.047582, loss_ce: 0.023001
2022-01-20 21:05:00,931 iteration 1057 : loss : 0.078055, loss_ce: 0.028039
2022-01-20 21:05:01,533 iteration 1058 : loss : 0.084636, loss_ce: 0.029544
2022-01-20 21:05:02,146 iteration 1059 : loss : 0.062235, loss_ce: 0.023970
2022-01-20 21:05:02,676 iteration 1060 : loss : 0.044423, loss_ce: 0.015416
2022-01-20 21:05:03,375 iteration 1061 : loss : 0.074271, loss_ce: 0.039638
2022-01-20 21:05:04,001 iteration 1062 : loss : 0.076904, loss_ce: 0.025766
2022-01-20 21:05:04,739 iteration 1063 : loss : 0.048204, loss_ce: 0.022557
2022-01-20 21:05:05,364 iteration 1064 : loss : 0.069420, loss_ce: 0.023569
2022-01-20 21:05:06,048 iteration 1065 : loss : 0.053169, loss_ce: 0.026084
2022-01-20 21:05:06,614 iteration 1066 : loss : 0.047744, loss_ce: 0.020788
2022-01-20 21:05:07,178 iteration 1067 : loss : 0.052755, loss_ce: 0.023636
2022-01-20 21:05:07,810 iteration 1068 : loss : 0.052258, loss_ce: 0.022844
2022-01-20 21:05:08,427 iteration 1069 : loss : 0.045186, loss_ce: 0.021379
2022-01-20 21:05:09,133 iteration 1070 : loss : 0.120605, loss_ce: 0.036144
2022-01-20 21:05:09,737 iteration 1071 : loss : 0.054328, loss_ce: 0.025044
 16%|████▋                         | 63/400 [11:34<1:00:41, 10.80s/it]2022-01-20 21:05:10,466 iteration 1072 : loss : 0.059463, loss_ce: 0.019010
2022-01-20 21:05:11,085 iteration 1073 : loss : 0.072968, loss_ce: 0.035882
2022-01-20 21:05:11,713 iteration 1074 : loss : 0.066784, loss_ce: 0.023639
2022-01-20 21:05:12,336 iteration 1075 : loss : 0.068165, loss_ce: 0.020775
2022-01-20 21:05:12,901 iteration 1076 : loss : 0.042399, loss_ce: 0.018232
2022-01-20 21:05:13,581 iteration 1077 : loss : 0.074098, loss_ce: 0.024755
2022-01-20 21:05:14,157 iteration 1078 : loss : 0.059088, loss_ce: 0.030481
2022-01-20 21:05:14,824 iteration 1079 : loss : 0.066070, loss_ce: 0.031860
2022-01-20 21:05:15,351 iteration 1080 : loss : 0.038296, loss_ce: 0.014365
2022-01-20 21:05:15,935 iteration 1081 : loss : 0.044010, loss_ce: 0.022407
2022-01-20 21:05:16,569 iteration 1082 : loss : 0.074864, loss_ce: 0.037641
2022-01-20 21:05:17,135 iteration 1083 : loss : 0.044247, loss_ce: 0.017691
2022-01-20 21:05:17,717 iteration 1084 : loss : 0.053030, loss_ce: 0.018022
2022-01-20 21:05:18,326 iteration 1085 : loss : 0.053246, loss_ce: 0.023985
2022-01-20 21:05:18,912 iteration 1086 : loss : 0.056466, loss_ce: 0.026227
2022-01-20 21:05:19,583 iteration 1087 : loss : 0.043839, loss_ce: 0.018401
2022-01-20 21:05:20,188 iteration 1088 : loss : 0.044916, loss_ce: 0.018833
 16%|█████                           | 64/400 [11:45<59:53, 10.70s/it]2022-01-20 21:05:20,790 iteration 1089 : loss : 0.091189, loss_ce: 0.031861
2022-01-20 21:05:21,357 iteration 1090 : loss : 0.059373, loss_ce: 0.020052
2022-01-20 21:05:22,004 iteration 1091 : loss : 0.047976, loss_ce: 0.022656
2022-01-20 21:05:22,610 iteration 1092 : loss : 0.054310, loss_ce: 0.022896
2022-01-20 21:05:23,211 iteration 1093 : loss : 0.034394, loss_ce: 0.015453
2022-01-20 21:05:23,830 iteration 1094 : loss : 0.048110, loss_ce: 0.021648
2022-01-20 21:05:24,457 iteration 1095 : loss : 0.096577, loss_ce: 0.033946
2022-01-20 21:05:25,055 iteration 1096 : loss : 0.039632, loss_ce: 0.018115
2022-01-20 21:05:25,606 iteration 1097 : loss : 0.076947, loss_ce: 0.031421
2022-01-20 21:05:26,173 iteration 1098 : loss : 0.048103, loss_ce: 0.023178
2022-01-20 21:05:26,793 iteration 1099 : loss : 0.042785, loss_ce: 0.017058
2022-01-20 21:05:27,375 iteration 1100 : loss : 0.046703, loss_ce: 0.021110
2022-01-20 21:05:27,952 iteration 1101 : loss : 0.045434, loss_ce: 0.018262
2022-01-20 21:05:28,631 iteration 1102 : loss : 0.072487, loss_ce: 0.022685
2022-01-20 21:05:29,222 iteration 1103 : loss : 0.081523, loss_ce: 0.030890
2022-01-20 21:05:29,768 iteration 1104 : loss : 0.065370, loss_ce: 0.029493
2022-01-20 21:05:29,768 Training Data Eval:
2022-01-20 21:05:32,454   Average segmentation loss on training set: 0.0377
2022-01-20 21:05:32,454 Validation Data Eval:
2022-01-20 21:05:33,327   Average segmentation loss on validation set: 0.1210
2022-01-20 21:05:33,923 iteration 1105 : loss : 0.040639, loss_ce: 0.020881
 16%|████▉                         | 65/400 [11:58<1:04:48, 11.61s/it]2022-01-20 21:05:34,557 iteration 1106 : loss : 0.053664, loss_ce: 0.020993
2022-01-20 21:05:35,205 iteration 1107 : loss : 0.061453, loss_ce: 0.026876
2022-01-20 21:05:35,754 iteration 1108 : loss : 0.053370, loss_ce: 0.020076
2022-01-20 21:05:36,287 iteration 1109 : loss : 0.071313, loss_ce: 0.030788
2022-01-20 21:05:36,867 iteration 1110 : loss : 0.056609, loss_ce: 0.025844
2022-01-20 21:05:37,470 iteration 1111 : loss : 0.050939, loss_ce: 0.023679
2022-01-20 21:05:38,083 iteration 1112 : loss : 0.051571, loss_ce: 0.023395
2022-01-20 21:05:38,656 iteration 1113 : loss : 0.056304, loss_ce: 0.021738
2022-01-20 21:05:39,199 iteration 1114 : loss : 0.059234, loss_ce: 0.023620
2022-01-20 21:05:39,704 iteration 1115 : loss : 0.046426, loss_ce: 0.016305
2022-01-20 21:05:40,366 iteration 1116 : loss : 0.063468, loss_ce: 0.027064
2022-01-20 21:05:41,037 iteration 1117 : loss : 0.058143, loss_ce: 0.025338
2022-01-20 21:05:41,594 iteration 1118 : loss : 0.033874, loss_ce: 0.014472
2022-01-20 21:05:42,148 iteration 1119 : loss : 0.036041, loss_ce: 0.014209
2022-01-20 21:05:42,686 iteration 1120 : loss : 0.057534, loss_ce: 0.020337
2022-01-20 21:05:43,234 iteration 1121 : loss : 0.045070, loss_ce: 0.014484
2022-01-20 21:05:43,770 iteration 1122 : loss : 0.048556, loss_ce: 0.021471
 16%|████▉                         | 66/400 [12:08<1:01:41, 11.08s/it]2022-01-20 21:05:44,405 iteration 1123 : loss : 0.065935, loss_ce: 0.028243
2022-01-20 21:05:44,959 iteration 1124 : loss : 0.041291, loss_ce: 0.020156
2022-01-20 21:05:45,599 iteration 1125 : loss : 0.061050, loss_ce: 0.026980
2022-01-20 21:05:46,306 iteration 1126 : loss : 0.073295, loss_ce: 0.032431
2022-01-20 21:05:46,930 iteration 1127 : loss : 0.067698, loss_ce: 0.026399
2022-01-20 21:05:47,552 iteration 1128 : loss : 0.065028, loss_ce: 0.019697
2022-01-20 21:05:48,144 iteration 1129 : loss : 0.038475, loss_ce: 0.015546
2022-01-20 21:05:48,795 iteration 1130 : loss : 0.051506, loss_ce: 0.027027
2022-01-20 21:05:49,466 iteration 1131 : loss : 0.129984, loss_ce: 0.045768
2022-01-20 21:05:50,088 iteration 1132 : loss : 0.081123, loss_ce: 0.028923
2022-01-20 21:05:50,706 iteration 1133 : loss : 0.057303, loss_ce: 0.025472
2022-01-20 21:05:51,322 iteration 1134 : loss : 0.062018, loss_ce: 0.025698
2022-01-20 21:05:51,882 iteration 1135 : loss : 0.043525, loss_ce: 0.015530
2022-01-20 21:05:52,483 iteration 1136 : loss : 0.043304, loss_ce: 0.019122
2022-01-20 21:05:53,055 iteration 1137 : loss : 0.053761, loss_ce: 0.020258
2022-01-20 21:05:53,726 iteration 1138 : loss : 0.060834, loss_ce: 0.031310
2022-01-20 21:05:54,387 iteration 1139 : loss : 0.049048, loss_ce: 0.022448
 17%|█████                         | 67/400 [12:19<1:00:43, 10.94s/it]2022-01-20 21:05:55,016 iteration 1140 : loss : 0.052381, loss_ce: 0.023140
2022-01-20 21:05:55,618 iteration 1141 : loss : 0.043283, loss_ce: 0.018861
2022-01-20 21:05:56,170 iteration 1142 : loss : 0.043848, loss_ce: 0.017916
2022-01-20 21:05:56,784 iteration 1143 : loss : 0.078558, loss_ce: 0.026727
2022-01-20 21:05:57,433 iteration 1144 : loss : 0.071263, loss_ce: 0.030083
2022-01-20 21:05:58,025 iteration 1145 : loss : 0.042208, loss_ce: 0.016695
2022-01-20 21:05:58,651 iteration 1146 : loss : 0.041544, loss_ce: 0.019048
2022-01-20 21:05:59,185 iteration 1147 : loss : 0.033188, loss_ce: 0.012942
2022-01-20 21:05:59,772 iteration 1148 : loss : 0.042790, loss_ce: 0.016019
2022-01-20 21:06:00,408 iteration 1149 : loss : 0.057412, loss_ce: 0.029295
2022-01-20 21:06:01,004 iteration 1150 : loss : 0.045001, loss_ce: 0.020479
2022-01-20 21:06:01,603 iteration 1151 : loss : 0.055679, loss_ce: 0.017879
2022-01-20 21:06:02,228 iteration 1152 : loss : 0.150036, loss_ce: 0.028625
2022-01-20 21:06:02,838 iteration 1153 : loss : 0.044325, loss_ce: 0.016906
2022-01-20 21:06:03,378 iteration 1154 : loss : 0.038712, loss_ce: 0.018671
2022-01-20 21:06:04,067 iteration 1155 : loss : 0.050309, loss_ce: 0.018849
2022-01-20 21:06:04,706 iteration 1156 : loss : 0.075390, loss_ce: 0.023562
 17%|█████▍                          | 68/400 [12:29<59:29, 10.75s/it]2022-01-20 21:06:05,302 iteration 1157 : loss : 0.038543, loss_ce: 0.017949
2022-01-20 21:06:06,027 iteration 1158 : loss : 0.069018, loss_ce: 0.025362
2022-01-20 21:06:06,695 iteration 1159 : loss : 0.070660, loss_ce: 0.027842
2022-01-20 21:06:07,220 iteration 1160 : loss : 0.045245, loss_ce: 0.022788
2022-01-20 21:06:07,820 iteration 1161 : loss : 0.052714, loss_ce: 0.017722
2022-01-20 21:06:08,413 iteration 1162 : loss : 0.052487, loss_ce: 0.012592
2022-01-20 21:06:09,108 iteration 1163 : loss : 0.098651, loss_ce: 0.036671
2022-01-20 21:06:09,736 iteration 1164 : loss : 0.045688, loss_ce: 0.018926
2022-01-20 21:06:10,283 iteration 1165 : loss : 0.053530, loss_ce: 0.026364
2022-01-20 21:06:10,870 iteration 1166 : loss : 0.046033, loss_ce: 0.020554
2022-01-20 21:06:11,490 iteration 1167 : loss : 0.055560, loss_ce: 0.024236
2022-01-20 21:06:12,014 iteration 1168 : loss : 0.048497, loss_ce: 0.019440
2022-01-20 21:06:12,611 iteration 1169 : loss : 0.059357, loss_ce: 0.020695
2022-01-20 21:06:13,218 iteration 1170 : loss : 0.056075, loss_ce: 0.021733
2022-01-20 21:06:13,746 iteration 1171 : loss : 0.042956, loss_ce: 0.016050
2022-01-20 21:06:14,335 iteration 1172 : loss : 0.057587, loss_ce: 0.026073
2022-01-20 21:06:14,951 iteration 1173 : loss : 0.071798, loss_ce: 0.049599
 17%|█████▌                          | 69/400 [12:39<58:30, 10.60s/it]2022-01-20 21:06:15,629 iteration 1174 : loss : 0.054450, loss_ce: 0.018089
2022-01-20 21:06:16,213 iteration 1175 : loss : 0.043245, loss_ce: 0.018208
2022-01-20 21:06:16,866 iteration 1176 : loss : 0.064898, loss_ce: 0.031979
2022-01-20 21:06:17,568 iteration 1177 : loss : 0.063107, loss_ce: 0.030320
2022-01-20 21:06:18,196 iteration 1178 : loss : 0.058344, loss_ce: 0.029546
2022-01-20 21:06:18,722 iteration 1179 : loss : 0.048195, loss_ce: 0.022537
2022-01-20 21:06:19,367 iteration 1180 : loss : 0.060095, loss_ce: 0.021384
2022-01-20 21:06:19,890 iteration 1181 : loss : 0.042367, loss_ce: 0.019584
2022-01-20 21:06:20,575 iteration 1182 : loss : 0.051131, loss_ce: 0.019606
2022-01-20 21:06:21,166 iteration 1183 : loss : 0.048041, loss_ce: 0.021000
2022-01-20 21:06:21,695 iteration 1184 : loss : 0.042444, loss_ce: 0.018242
2022-01-20 21:06:22,306 iteration 1185 : loss : 0.073459, loss_ce: 0.029624
2022-01-20 21:06:22,860 iteration 1186 : loss : 0.058825, loss_ce: 0.024681
2022-01-20 21:06:23,470 iteration 1187 : loss : 0.050513, loss_ce: 0.020863
2022-01-20 21:06:24,009 iteration 1188 : loss : 0.042933, loss_ce: 0.015912
2022-01-20 21:06:24,596 iteration 1189 : loss : 0.057841, loss_ce: 0.021393
2022-01-20 21:06:24,596 Training Data Eval:
2022-01-20 21:06:27,279   Average segmentation loss on training set: 0.0480
2022-01-20 21:06:27,280 Validation Data Eval:
2022-01-20 21:06:28,153   Average segmentation loss on validation set: 0.0906
2022-01-20 21:06:28,710 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:06:29,322 iteration 1190 : loss : 0.058896, loss_ce: 0.021943
 18%|█████▎                        | 70/400 [12:54<1:04:31, 11.73s/it]2022-01-20 21:06:29,927 iteration 1191 : loss : 0.064037, loss_ce: 0.025538
2022-01-20 21:06:30,476 iteration 1192 : loss : 0.045009, loss_ce: 0.020532
2022-01-20 21:06:31,066 iteration 1193 : loss : 0.049323, loss_ce: 0.015688
2022-01-20 21:06:31,629 iteration 1194 : loss : 0.080345, loss_ce: 0.028223
2022-01-20 21:06:32,269 iteration 1195 : loss : 0.061699, loss_ce: 0.019235
2022-01-20 21:06:32,795 iteration 1196 : loss : 0.048202, loss_ce: 0.016134
2022-01-20 21:06:33,426 iteration 1197 : loss : 0.055255, loss_ce: 0.029063
2022-01-20 21:06:34,024 iteration 1198 : loss : 0.049559, loss_ce: 0.027547
2022-01-20 21:06:34,635 iteration 1199 : loss : 0.058524, loss_ce: 0.021576
2022-01-20 21:06:35,268 iteration 1200 : loss : 0.060668, loss_ce: 0.021329
2022-01-20 21:06:35,850 iteration 1201 : loss : 0.035268, loss_ce: 0.016084
2022-01-20 21:06:36,478 iteration 1202 : loss : 0.038919, loss_ce: 0.017060
2022-01-20 21:06:37,060 iteration 1203 : loss : 0.041999, loss_ce: 0.015591
2022-01-20 21:06:37,643 iteration 1204 : loss : 0.045621, loss_ce: 0.020533
2022-01-20 21:06:38,271 iteration 1205 : loss : 0.098522, loss_ce: 0.057624
2022-01-20 21:06:38,919 iteration 1206 : loss : 0.134212, loss_ce: 0.039264
2022-01-20 21:06:39,475 iteration 1207 : loss : 0.055005, loss_ce: 0.018939
 18%|█████▎                        | 71/400 [13:04<1:01:44, 11.26s/it]2022-01-20 21:06:40,054 iteration 1208 : loss : 0.041674, loss_ce: 0.020138
2022-01-20 21:06:40,646 iteration 1209 : loss : 0.046499, loss_ce: 0.018613
2022-01-20 21:06:41,169 iteration 1210 : loss : 0.053668, loss_ce: 0.020454
2022-01-20 21:06:41,804 iteration 1211 : loss : 0.071043, loss_ce: 0.025055
2022-01-20 21:06:42,360 iteration 1212 : loss : 0.038298, loss_ce: 0.016511
2022-01-20 21:06:42,966 iteration 1213 : loss : 0.070354, loss_ce: 0.019390
2022-01-20 21:06:43,592 iteration 1214 : loss : 0.045365, loss_ce: 0.021868
2022-01-20 21:06:44,188 iteration 1215 : loss : 0.054630, loss_ce: 0.024671
2022-01-20 21:06:44,765 iteration 1216 : loss : 0.043098, loss_ce: 0.019332
2022-01-20 21:06:45,399 iteration 1217 : loss : 0.063194, loss_ce: 0.029022
2022-01-20 21:06:45,895 iteration 1218 : loss : 0.038800, loss_ce: 0.017860
2022-01-20 21:06:46,516 iteration 1219 : loss : 0.040112, loss_ce: 0.018668
2022-01-20 21:06:47,086 iteration 1220 : loss : 0.041295, loss_ce: 0.016887
2022-01-20 21:06:47,786 iteration 1221 : loss : 0.059094, loss_ce: 0.024930
2022-01-20 21:06:48,419 iteration 1222 : loss : 0.055466, loss_ce: 0.020432
2022-01-20 21:06:48,993 iteration 1223 : loss : 0.034232, loss_ce: 0.015400
2022-01-20 21:06:49,619 iteration 1224 : loss : 0.041306, loss_ce: 0.019615
 18%|█████▊                          | 72/400 [13:14<59:42, 10.92s/it]2022-01-20 21:06:50,286 iteration 1225 : loss : 0.052321, loss_ce: 0.019914
2022-01-20 21:06:50,894 iteration 1226 : loss : 0.050876, loss_ce: 0.019948
2022-01-20 21:06:51,455 iteration 1227 : loss : 0.039923, loss_ce: 0.014618
2022-01-20 21:06:52,161 iteration 1228 : loss : 0.102962, loss_ce: 0.034046
2022-01-20 21:06:52,834 iteration 1229 : loss : 0.051128, loss_ce: 0.022477
2022-01-20 21:06:53,482 iteration 1230 : loss : 0.036126, loss_ce: 0.015566
2022-01-20 21:06:54,073 iteration 1231 : loss : 0.062895, loss_ce: 0.022248
2022-01-20 21:06:54,726 iteration 1232 : loss : 0.035259, loss_ce: 0.015203
2022-01-20 21:06:55,441 iteration 1233 : loss : 0.052344, loss_ce: 0.024064
2022-01-20 21:06:56,057 iteration 1234 : loss : 0.070133, loss_ce: 0.030031
2022-01-20 21:06:56,636 iteration 1235 : loss : 0.051142, loss_ce: 0.026262
2022-01-20 21:06:57,194 iteration 1236 : loss : 0.033367, loss_ce: 0.013451
2022-01-20 21:06:57,712 iteration 1237 : loss : 0.040597, loss_ce: 0.013643
2022-01-20 21:06:58,297 iteration 1238 : loss : 0.051280, loss_ce: 0.022641
2022-01-20 21:06:58,938 iteration 1239 : loss : 0.061377, loss_ce: 0.021092
2022-01-20 21:06:59,459 iteration 1240 : loss : 0.041734, loss_ce: 0.015448
2022-01-20 21:07:00,139 iteration 1241 : loss : 0.038849, loss_ce: 0.016132
 18%|█████▊                          | 73/400 [13:25<58:53, 10.81s/it]2022-01-20 21:07:00,702 iteration 1242 : loss : 0.036793, loss_ce: 0.016877
2022-01-20 21:07:01,225 iteration 1243 : loss : 0.032998, loss_ce: 0.016040
2022-01-20 21:07:01,763 iteration 1244 : loss : 0.046724, loss_ce: 0.017710
2022-01-20 21:07:02,335 iteration 1245 : loss : 0.052623, loss_ce: 0.022712
2022-01-20 21:07:02,933 iteration 1246 : loss : 0.055829, loss_ce: 0.022706
2022-01-20 21:07:03,556 iteration 1247 : loss : 0.049605, loss_ce: 0.018504
2022-01-20 21:07:04,106 iteration 1248 : loss : 0.028697, loss_ce: 0.012084
2022-01-20 21:07:04,718 iteration 1249 : loss : 0.038694, loss_ce: 0.013587
2022-01-20 21:07:05,280 iteration 1250 : loss : 0.049674, loss_ce: 0.018463
2022-01-20 21:07:05,900 iteration 1251 : loss : 0.039640, loss_ce: 0.015961
2022-01-20 21:07:06,517 iteration 1252 : loss : 0.083204, loss_ce: 0.020988
2022-01-20 21:07:07,132 iteration 1253 : loss : 0.056524, loss_ce: 0.024277
2022-01-20 21:07:07,710 iteration 1254 : loss : 0.056299, loss_ce: 0.024989
2022-01-20 21:07:08,351 iteration 1255 : loss : 0.035797, loss_ce: 0.014651
2022-01-20 21:07:09,013 iteration 1256 : loss : 0.057748, loss_ce: 0.020150
2022-01-20 21:07:09,612 iteration 1257 : loss : 0.039164, loss_ce: 0.018518
2022-01-20 21:07:10,290 iteration 1258 : loss : 0.039180, loss_ce: 0.019059
 18%|█████▉                          | 74/400 [13:35<57:37, 10.61s/it]2022-01-20 21:07:10,926 iteration 1259 : loss : 0.040122, loss_ce: 0.013978
2022-01-20 21:07:11,568 iteration 1260 : loss : 0.049732, loss_ce: 0.017009
2022-01-20 21:07:12,186 iteration 1261 : loss : 0.044969, loss_ce: 0.018510
2022-01-20 21:07:12,739 iteration 1262 : loss : 0.032285, loss_ce: 0.015578
2022-01-20 21:07:13,390 iteration 1263 : loss : 0.034266, loss_ce: 0.012785
2022-01-20 21:07:13,926 iteration 1264 : loss : 0.033917, loss_ce: 0.016909
2022-01-20 21:07:14,478 iteration 1265 : loss : 0.034213, loss_ce: 0.014349
2022-01-20 21:07:14,998 iteration 1266 : loss : 0.042908, loss_ce: 0.019991
2022-01-20 21:07:15,671 iteration 1267 : loss : 0.053596, loss_ce: 0.021182
2022-01-20 21:07:16,253 iteration 1268 : loss : 0.102363, loss_ce: 0.026541
2022-01-20 21:07:16,882 iteration 1269 : loss : 0.067308, loss_ce: 0.025463
2022-01-20 21:07:17,425 iteration 1270 : loss : 0.045304, loss_ce: 0.017607
2022-01-20 21:07:18,010 iteration 1271 : loss : 0.049454, loss_ce: 0.021399
2022-01-20 21:07:18,586 iteration 1272 : loss : 0.053796, loss_ce: 0.023902
2022-01-20 21:07:19,220 iteration 1273 : loss : 0.048895, loss_ce: 0.023047
2022-01-20 21:07:19,834 iteration 1274 : loss : 0.056271, loss_ce: 0.020590
2022-01-20 21:07:19,834 Training Data Eval:
2022-01-20 21:07:22,524   Average segmentation loss on training set: 0.0337
2022-01-20 21:07:22,524 Validation Data Eval:
2022-01-20 21:07:23,407   Average segmentation loss on validation set: 0.1565
2022-01-20 21:07:24,018 iteration 1275 : loss : 0.051620, loss_ce: 0.018902
 19%|█████▋                        | 75/400 [13:48<1:02:32, 11.54s/it]2022-01-20 21:07:24,745 iteration 1276 : loss : 0.069855, loss_ce: 0.020599
2022-01-20 21:07:25,293 iteration 1277 : loss : 0.035924, loss_ce: 0.014021
2022-01-20 21:07:25,915 iteration 1278 : loss : 0.049665, loss_ce: 0.021767
2022-01-20 21:07:26,409 iteration 1279 : loss : 0.042775, loss_ce: 0.023198
2022-01-20 21:07:26,911 iteration 1280 : loss : 0.043599, loss_ce: 0.021308
2022-01-20 21:07:27,560 iteration 1281 : loss : 0.052136, loss_ce: 0.025001
2022-01-20 21:07:28,106 iteration 1282 : loss : 0.055593, loss_ce: 0.029809
2022-01-20 21:07:28,667 iteration 1283 : loss : 0.045538, loss_ce: 0.020175
2022-01-20 21:07:29,253 iteration 1284 : loss : 0.042527, loss_ce: 0.019186
2022-01-20 21:07:29,985 iteration 1285 : loss : 0.077302, loss_ce: 0.024714
2022-01-20 21:07:30,625 iteration 1286 : loss : 0.046164, loss_ce: 0.017045
2022-01-20 21:07:31,203 iteration 1287 : loss : 0.050700, loss_ce: 0.018938
2022-01-20 21:07:31,816 iteration 1288 : loss : 0.062700, loss_ce: 0.024158
2022-01-20 21:07:32,488 iteration 1289 : loss : 0.059103, loss_ce: 0.024427
2022-01-20 21:07:33,048 iteration 1290 : loss : 0.049183, loss_ce: 0.015683
2022-01-20 21:07:33,646 iteration 1291 : loss : 0.034503, loss_ce: 0.012997
2022-01-20 21:07:34,184 iteration 1292 : loss : 0.033555, loss_ce: 0.015101
 19%|█████▋                        | 76/400 [13:59<1:00:05, 11.13s/it]2022-01-20 21:07:34,813 iteration 1293 : loss : 0.048608, loss_ce: 0.023821
2022-01-20 21:07:35,363 iteration 1294 : loss : 0.049849, loss_ce: 0.018660
2022-01-20 21:07:35,939 iteration 1295 : loss : 0.037751, loss_ce: 0.015918
2022-01-20 21:07:36,530 iteration 1296 : loss : 0.037747, loss_ce: 0.015258
2022-01-20 21:07:37,110 iteration 1297 : loss : 0.047366, loss_ce: 0.019054
2022-01-20 21:07:37,714 iteration 1298 : loss : 0.035393, loss_ce: 0.015796
2022-01-20 21:07:38,260 iteration 1299 : loss : 0.044987, loss_ce: 0.016243
2022-01-20 21:07:38,908 iteration 1300 : loss : 0.057316, loss_ce: 0.015557
2022-01-20 21:07:39,519 iteration 1301 : loss : 0.044699, loss_ce: 0.022947
2022-01-20 21:07:40,177 iteration 1302 : loss : 0.051681, loss_ce: 0.018367
2022-01-20 21:07:40,737 iteration 1303 : loss : 0.044953, loss_ce: 0.019707
2022-01-20 21:07:41,372 iteration 1304 : loss : 0.091062, loss_ce: 0.033094
2022-01-20 21:07:41,972 iteration 1305 : loss : 0.046106, loss_ce: 0.021481
2022-01-20 21:07:42,621 iteration 1306 : loss : 0.051579, loss_ce: 0.019698
2022-01-20 21:07:43,282 iteration 1307 : loss : 0.057725, loss_ce: 0.024659
2022-01-20 21:07:43,888 iteration 1308 : loss : 0.055859, loss_ce: 0.033720
2022-01-20 21:07:44,484 iteration 1309 : loss : 0.044711, loss_ce: 0.015814
 19%|██████▏                         | 77/400 [14:09<58:34, 10.88s/it]2022-01-20 21:07:45,129 iteration 1310 : loss : 0.049252, loss_ce: 0.022587
2022-01-20 21:07:45,795 iteration 1311 : loss : 0.044689, loss_ce: 0.018887
2022-01-20 21:07:46,381 iteration 1312 : loss : 0.057202, loss_ce: 0.027592
2022-01-20 21:07:46,910 iteration 1313 : loss : 0.039297, loss_ce: 0.017853
2022-01-20 21:07:47,516 iteration 1314 : loss : 0.038421, loss_ce: 0.017571
2022-01-20 21:07:48,134 iteration 1315 : loss : 0.050863, loss_ce: 0.020606
2022-01-20 21:07:48,709 iteration 1316 : loss : 0.044444, loss_ce: 0.019406
2022-01-20 21:07:49,347 iteration 1317 : loss : 0.038444, loss_ce: 0.019348
2022-01-20 21:07:49,991 iteration 1318 : loss : 0.048148, loss_ce: 0.020612
2022-01-20 21:07:50,568 iteration 1319 : loss : 0.048052, loss_ce: 0.018111
2022-01-20 21:07:51,162 iteration 1320 : loss : 0.041925, loss_ce: 0.016004
2022-01-20 21:07:51,763 iteration 1321 : loss : 0.067763, loss_ce: 0.026072
2022-01-20 21:07:52,469 iteration 1322 : loss : 0.050691, loss_ce: 0.022820
2022-01-20 21:07:53,113 iteration 1323 : loss : 0.045000, loss_ce: 0.018758
2022-01-20 21:07:53,752 iteration 1324 : loss : 0.059680, loss_ce: 0.021584
2022-01-20 21:07:54,406 iteration 1325 : loss : 0.053624, loss_ce: 0.023261
2022-01-20 21:07:54,948 iteration 1326 : loss : 0.059868, loss_ce: 0.021547
 20%|██████▏                         | 78/400 [14:19<57:43, 10.76s/it]2022-01-20 21:07:55,613 iteration 1327 : loss : 0.050097, loss_ce: 0.027467
2022-01-20 21:07:56,313 iteration 1328 : loss : 0.065241, loss_ce: 0.024454
2022-01-20 21:07:56,845 iteration 1329 : loss : 0.041765, loss_ce: 0.021261
2022-01-20 21:07:57,435 iteration 1330 : loss : 0.060017, loss_ce: 0.028585
2022-01-20 21:07:58,025 iteration 1331 : loss : 0.040834, loss_ce: 0.014696
2022-01-20 21:07:58,603 iteration 1332 : loss : 0.038202, loss_ce: 0.016125
2022-01-20 21:07:59,220 iteration 1333 : loss : 0.062179, loss_ce: 0.015638
2022-01-20 21:07:59,800 iteration 1334 : loss : 0.032720, loss_ce: 0.013826
2022-01-20 21:08:00,502 iteration 1335 : loss : 0.041211, loss_ce: 0.014804
2022-01-20 21:08:01,132 iteration 1336 : loss : 0.038920, loss_ce: 0.017094
2022-01-20 21:08:01,798 iteration 1337 : loss : 0.057919, loss_ce: 0.023592
2022-01-20 21:08:02,462 iteration 1338 : loss : 0.065304, loss_ce: 0.027381
2022-01-20 21:08:03,101 iteration 1339 : loss : 0.046850, loss_ce: 0.020957
2022-01-20 21:08:03,659 iteration 1340 : loss : 0.046439, loss_ce: 0.015110
2022-01-20 21:08:04,250 iteration 1341 : loss : 0.052007, loss_ce: 0.024221
2022-01-20 21:08:04,846 iteration 1342 : loss : 0.062491, loss_ce: 0.024206
2022-01-20 21:08:05,425 iteration 1343 : loss : 0.042319, loss_ce: 0.016003
 20%|██████▎                         | 79/400 [14:30<57:05, 10.67s/it]2022-01-20 21:08:06,040 iteration 1344 : loss : 0.035594, loss_ce: 0.013714
2022-01-20 21:08:06,598 iteration 1345 : loss : 0.044168, loss_ce: 0.020916
2022-01-20 21:08:07,144 iteration 1346 : loss : 0.043016, loss_ce: 0.014754
2022-01-20 21:08:07,806 iteration 1347 : loss : 0.119464, loss_ce: 0.028707
2022-01-20 21:08:08,474 iteration 1348 : loss : 0.042637, loss_ce: 0.018165
2022-01-20 21:08:09,096 iteration 1349 : loss : 0.069387, loss_ce: 0.032845
2022-01-20 21:08:09,737 iteration 1350 : loss : 0.062159, loss_ce: 0.023486
2022-01-20 21:08:10,288 iteration 1351 : loss : 0.049461, loss_ce: 0.016478
2022-01-20 21:08:10,965 iteration 1352 : loss : 0.053384, loss_ce: 0.020654
2022-01-20 21:08:11,495 iteration 1353 : loss : 0.052510, loss_ce: 0.024167
2022-01-20 21:08:12,120 iteration 1354 : loss : 0.042384, loss_ce: 0.018550
2022-01-20 21:08:12,665 iteration 1355 : loss : 0.066904, loss_ce: 0.021588
2022-01-20 21:08:13,308 iteration 1356 : loss : 0.056283, loss_ce: 0.020404
2022-01-20 21:08:13,859 iteration 1357 : loss : 0.053060, loss_ce: 0.030898
2022-01-20 21:08:14,458 iteration 1358 : loss : 0.054022, loss_ce: 0.017049
2022-01-20 21:08:14,998 iteration 1359 : loss : 0.047186, loss_ce: 0.025070
2022-01-20 21:08:14,998 Training Data Eval:
2022-01-20 21:08:17,686   Average segmentation loss on training set: 0.0439
2022-01-20 21:08:17,686 Validation Data Eval:
2022-01-20 21:08:18,560   Average segmentation loss on validation set: 0.1264
2022-01-20 21:08:19,130 iteration 1360 : loss : 0.049621, loss_ce: 0.018630
 20%|██████                        | 80/400 [14:44<1:01:46, 11.58s/it]2022-01-20 21:08:19,804 iteration 1361 : loss : 0.069862, loss_ce: 0.023162
2022-01-20 21:08:20,419 iteration 1362 : loss : 0.039535, loss_ce: 0.018244
2022-01-20 21:08:21,051 iteration 1363 : loss : 0.043567, loss_ce: 0.015512
2022-01-20 21:08:21,712 iteration 1364 : loss : 0.057914, loss_ce: 0.018567
2022-01-20 21:08:22,415 iteration 1365 : loss : 0.061797, loss_ce: 0.025707
2022-01-20 21:08:23,027 iteration 1366 : loss : 0.049037, loss_ce: 0.022959
2022-01-20 21:08:23,590 iteration 1367 : loss : 0.033851, loss_ce: 0.015258
2022-01-20 21:08:24,202 iteration 1368 : loss : 0.041208, loss_ce: 0.018284
2022-01-20 21:08:24,784 iteration 1369 : loss : 0.059419, loss_ce: 0.018770
2022-01-20 21:08:25,387 iteration 1370 : loss : 0.058708, loss_ce: 0.020414
2022-01-20 21:08:25,920 iteration 1371 : loss : 0.044053, loss_ce: 0.018179
2022-01-20 21:08:26,532 iteration 1372 : loss : 0.072469, loss_ce: 0.022690
2022-01-20 21:08:27,222 iteration 1373 : loss : 0.047767, loss_ce: 0.027262
2022-01-20 21:08:27,805 iteration 1374 : loss : 0.054097, loss_ce: 0.019718
2022-01-20 21:08:28,454 iteration 1375 : loss : 0.044325, loss_ce: 0.019011
2022-01-20 21:08:28,975 iteration 1376 : loss : 0.037006, loss_ce: 0.015282
2022-01-20 21:08:29,614 iteration 1377 : loss : 0.065977, loss_ce: 0.024417
 20%|██████▍                         | 81/400 [14:54<59:49, 11.25s/it]2022-01-20 21:08:30,323 iteration 1378 : loss : 0.057353, loss_ce: 0.031550
2022-01-20 21:08:30,984 iteration 1379 : loss : 0.065140, loss_ce: 0.021134
2022-01-20 21:08:31,585 iteration 1380 : loss : 0.053704, loss_ce: 0.025667
2022-01-20 21:08:32,198 iteration 1381 : loss : 0.041128, loss_ce: 0.016618
2022-01-20 21:08:32,782 iteration 1382 : loss : 0.046365, loss_ce: 0.018020
2022-01-20 21:08:33,376 iteration 1383 : loss : 0.073104, loss_ce: 0.019480
2022-01-20 21:08:34,062 iteration 1384 : loss : 0.063735, loss_ce: 0.027552
2022-01-20 21:08:34,589 iteration 1385 : loss : 0.037096, loss_ce: 0.015649
2022-01-20 21:08:35,274 iteration 1386 : loss : 0.068075, loss_ce: 0.031063
2022-01-20 21:08:35,838 iteration 1387 : loss : 0.071003, loss_ce: 0.024534
2022-01-20 21:08:36,483 iteration 1388 : loss : 0.057097, loss_ce: 0.017508
2022-01-20 21:08:37,114 iteration 1389 : loss : 0.061738, loss_ce: 0.029890
2022-01-20 21:08:37,655 iteration 1390 : loss : 0.038002, loss_ce: 0.018135
2022-01-20 21:08:38,281 iteration 1391 : loss : 0.073352, loss_ce: 0.024170
2022-01-20 21:08:38,876 iteration 1392 : loss : 0.050491, loss_ce: 0.026064
2022-01-20 21:08:39,490 iteration 1393 : loss : 0.092532, loss_ce: 0.028634
2022-01-20 21:08:40,094 iteration 1394 : loss : 0.077348, loss_ce: 0.022635
 20%|██████▌                         | 82/400 [15:04<58:24, 11.02s/it]2022-01-20 21:08:40,789 iteration 1395 : loss : 0.041815, loss_ce: 0.020469
2022-01-20 21:08:41,326 iteration 1396 : loss : 0.046538, loss_ce: 0.020594
2022-01-20 21:08:41,983 iteration 1397 : loss : 0.055103, loss_ce: 0.021579
2022-01-20 21:08:42,508 iteration 1398 : loss : 0.033310, loss_ce: 0.013549
2022-01-20 21:08:43,135 iteration 1399 : loss : 0.035994, loss_ce: 0.015191
2022-01-20 21:08:43,796 iteration 1400 : loss : 0.062552, loss_ce: 0.023918
2022-01-20 21:08:44,365 iteration 1401 : loss : 0.037126, loss_ce: 0.014610
2022-01-20 21:08:45,028 iteration 1402 : loss : 0.060421, loss_ce: 0.023671
2022-01-20 21:08:45,638 iteration 1403 : loss : 0.055889, loss_ce: 0.017942
2022-01-20 21:08:46,314 iteration 1404 : loss : 0.048622, loss_ce: 0.022435
2022-01-20 21:08:46,765 iteration 1405 : loss : 0.041347, loss_ce: 0.015502
2022-01-20 21:08:47,389 iteration 1406 : loss : 0.048571, loss_ce: 0.017458
2022-01-20 21:08:47,964 iteration 1407 : loss : 0.054020, loss_ce: 0.022604
2022-01-20 21:08:48,514 iteration 1408 : loss : 0.045542, loss_ce: 0.021301
2022-01-20 21:08:49,192 iteration 1409 : loss : 0.083637, loss_ce: 0.025306
2022-01-20 21:08:49,745 iteration 1410 : loss : 0.069188, loss_ce: 0.035480
2022-01-20 21:08:50,264 iteration 1411 : loss : 0.035539, loss_ce: 0.014348
 21%|██████▋                         | 83/400 [15:15<56:52, 10.76s/it]2022-01-20 21:08:50,924 iteration 1412 : loss : 0.042544, loss_ce: 0.020523
2022-01-20 21:08:51,452 iteration 1413 : loss : 0.039237, loss_ce: 0.014363
2022-01-20 21:08:52,075 iteration 1414 : loss : 0.039678, loss_ce: 0.016451
2022-01-20 21:08:52,617 iteration 1415 : loss : 0.056122, loss_ce: 0.020731
2022-01-20 21:08:53,211 iteration 1416 : loss : 0.034625, loss_ce: 0.013776
2022-01-20 21:08:53,829 iteration 1417 : loss : 0.056836, loss_ce: 0.025492
2022-01-20 21:08:54,440 iteration 1418 : loss : 0.045132, loss_ce: 0.015850
2022-01-20 21:08:54,963 iteration 1419 : loss : 0.043683, loss_ce: 0.016799
2022-01-20 21:08:55,540 iteration 1420 : loss : 0.040224, loss_ce: 0.011838
2022-01-20 21:08:56,118 iteration 1421 : loss : 0.061746, loss_ce: 0.037268
2022-01-20 21:08:56,723 iteration 1422 : loss : 0.066909, loss_ce: 0.029637
2022-01-20 21:08:57,275 iteration 1423 : loss : 0.044563, loss_ce: 0.015341
2022-01-20 21:08:57,783 iteration 1424 : loss : 0.030362, loss_ce: 0.013184
2022-01-20 21:08:58,392 iteration 1425 : loss : 0.051463, loss_ce: 0.017463
2022-01-20 21:08:59,016 iteration 1426 : loss : 0.049101, loss_ce: 0.027755
2022-01-20 21:08:59,612 iteration 1427 : loss : 0.091236, loss_ce: 0.020440
2022-01-20 21:09:00,311 iteration 1428 : loss : 0.057059, loss_ce: 0.022496
 21%|██████▋                         | 84/400 [15:25<55:34, 10.55s/it]2022-01-20 21:09:00,984 iteration 1429 : loss : 0.047927, loss_ce: 0.025301
2022-01-20 21:09:01,570 iteration 1430 : loss : 0.040241, loss_ce: 0.015962
2022-01-20 21:09:02,118 iteration 1431 : loss : 0.094506, loss_ce: 0.031402
2022-01-20 21:09:02,722 iteration 1432 : loss : 0.051456, loss_ce: 0.022308
2022-01-20 21:09:03,249 iteration 1433 : loss : 0.039646, loss_ce: 0.018414
2022-01-20 21:09:03,934 iteration 1434 : loss : 0.044697, loss_ce: 0.018409
2022-01-20 21:09:04,576 iteration 1435 : loss : 0.042508, loss_ce: 0.015375
2022-01-20 21:09:05,237 iteration 1436 : loss : 0.052839, loss_ce: 0.025117
2022-01-20 21:09:05,843 iteration 1437 : loss : 0.045281, loss_ce: 0.020645
2022-01-20 21:09:06,428 iteration 1438 : loss : 0.043964, loss_ce: 0.018026
2022-01-20 21:09:07,043 iteration 1439 : loss : 0.071454, loss_ce: 0.024144
2022-01-20 21:09:07,583 iteration 1440 : loss : 0.044531, loss_ce: 0.015608
2022-01-20 21:09:08,200 iteration 1441 : loss : 0.039763, loss_ce: 0.017220
2022-01-20 21:09:08,793 iteration 1442 : loss : 0.059737, loss_ce: 0.019933
2022-01-20 21:09:09,451 iteration 1443 : loss : 0.050362, loss_ce: 0.018032
2022-01-20 21:09:10,044 iteration 1444 : loss : 0.063673, loss_ce: 0.015483
2022-01-20 21:09:10,044 Training Data Eval:
2022-01-20 21:09:12,737   Average segmentation loss on training set: 0.0341
2022-01-20 21:09:12,737 Validation Data Eval:
2022-01-20 21:09:13,613   Average segmentation loss on validation set: 0.1293
2022-01-20 21:09:14,255 iteration 1445 : loss : 0.049520, loss_ce: 0.025151
 21%|██████▍                       | 85/400 [15:39<1:00:44, 11.57s/it]2022-01-20 21:09:14,822 iteration 1446 : loss : 0.046686, loss_ce: 0.017676
2022-01-20 21:09:15,334 iteration 1447 : loss : 0.035028, loss_ce: 0.016742
2022-01-20 21:09:15,973 iteration 1448 : loss : 0.075752, loss_ce: 0.021334
2022-01-20 21:09:16,612 iteration 1449 : loss : 0.068288, loss_ce: 0.023311
2022-01-20 21:09:17,195 iteration 1450 : loss : 0.047241, loss_ce: 0.017707
2022-01-20 21:09:17,814 iteration 1451 : loss : 0.042173, loss_ce: 0.014047
2022-01-20 21:09:18,398 iteration 1452 : loss : 0.066248, loss_ce: 0.039838
2022-01-20 21:09:19,018 iteration 1453 : loss : 0.050247, loss_ce: 0.021730
2022-01-20 21:09:19,620 iteration 1454 : loss : 0.060466, loss_ce: 0.019016
2022-01-20 21:09:20,238 iteration 1455 : loss : 0.037753, loss_ce: 0.013217
2022-01-20 21:09:20,792 iteration 1456 : loss : 0.042563, loss_ce: 0.013303
2022-01-20 21:09:21,441 iteration 1457 : loss : 0.049512, loss_ce: 0.021939
2022-01-20 21:09:22,059 iteration 1458 : loss : 0.040294, loss_ce: 0.016895
2022-01-20 21:09:22,628 iteration 1459 : loss : 0.045453, loss_ce: 0.014980
2022-01-20 21:09:23,206 iteration 1460 : loss : 0.045557, loss_ce: 0.016647
2022-01-20 21:09:23,749 iteration 1461 : loss : 0.044871, loss_ce: 0.017468
2022-01-20 21:09:24,416 iteration 1462 : loss : 0.047353, loss_ce: 0.022078
 22%|██████▉                         | 86/400 [15:49<58:20, 11.15s/it]2022-01-20 21:09:25,171 iteration 1463 : loss : 0.091298, loss_ce: 0.032344
2022-01-20 21:09:25,725 iteration 1464 : loss : 0.040430, loss_ce: 0.020726
2022-01-20 21:09:26,442 iteration 1465 : loss : 0.049062, loss_ce: 0.016903
2022-01-20 21:09:27,049 iteration 1466 : loss : 0.043550, loss_ce: 0.015812
2022-01-20 21:09:27,616 iteration 1467 : loss : 0.069623, loss_ce: 0.026191
2022-01-20 21:09:28,227 iteration 1468 : loss : 0.043425, loss_ce: 0.021197
2022-01-20 21:09:28,822 iteration 1469 : loss : 0.049702, loss_ce: 0.022993
2022-01-20 21:09:29,363 iteration 1470 : loss : 0.069528, loss_ce: 0.014977
2022-01-20 21:09:29,952 iteration 1471 : loss : 0.037759, loss_ce: 0.017261
2022-01-20 21:09:30,574 iteration 1472 : loss : 0.046654, loss_ce: 0.018926
2022-01-20 21:09:31,127 iteration 1473 : loss : 0.037259, loss_ce: 0.017529
2022-01-20 21:09:31,757 iteration 1474 : loss : 0.053028, loss_ce: 0.015788
2022-01-20 21:09:32,323 iteration 1475 : loss : 0.035558, loss_ce: 0.015900
2022-01-20 21:09:32,890 iteration 1476 : loss : 0.039814, loss_ce: 0.016766
2022-01-20 21:09:33,560 iteration 1477 : loss : 0.048154, loss_ce: 0.021487
2022-01-20 21:09:34,118 iteration 1478 : loss : 0.060291, loss_ce: 0.017595
2022-01-20 21:09:34,713 iteration 1479 : loss : 0.064952, loss_ce: 0.022346
 22%|██████▉                         | 87/400 [15:59<56:49, 10.89s/it]2022-01-20 21:09:35,233 iteration 1480 : loss : 0.028749, loss_ce: 0.010962
2022-01-20 21:09:35,923 iteration 1481 : loss : 0.049209, loss_ce: 0.023513
2022-01-20 21:09:36,517 iteration 1482 : loss : 0.044854, loss_ce: 0.018891
2022-01-20 21:09:37,175 iteration 1483 : loss : 0.038449, loss_ce: 0.014781
2022-01-20 21:09:37,800 iteration 1484 : loss : 0.038441, loss_ce: 0.012004
2022-01-20 21:09:38,442 iteration 1485 : loss : 0.039393, loss_ce: 0.020655
2022-01-20 21:09:39,028 iteration 1486 : loss : 0.034185, loss_ce: 0.013412
2022-01-20 21:09:39,704 iteration 1487 : loss : 0.032489, loss_ce: 0.012614
2022-01-20 21:09:40,240 iteration 1488 : loss : 0.046893, loss_ce: 0.020537
2022-01-20 21:09:40,808 iteration 1489 : loss : 0.044730, loss_ce: 0.020587
2022-01-20 21:09:41,433 iteration 1490 : loss : 0.050601, loss_ce: 0.020501
2022-01-20 21:09:41,939 iteration 1491 : loss : 0.047713, loss_ce: 0.014680
2022-01-20 21:09:42,476 iteration 1492 : loss : 0.058386, loss_ce: 0.030716
2022-01-20 21:09:43,106 iteration 1493 : loss : 0.039016, loss_ce: 0.017875
2022-01-20 21:09:43,689 iteration 1494 : loss : 0.048965, loss_ce: 0.016763
2022-01-20 21:09:44,221 iteration 1495 : loss : 0.036769, loss_ce: 0.010341
2022-01-20 21:09:44,859 iteration 1496 : loss : 0.035982, loss_ce: 0.017397
 22%|███████                         | 88/400 [16:09<55:28, 10.67s/it]2022-01-20 21:09:45,425 iteration 1497 : loss : 0.031720, loss_ce: 0.013419
2022-01-20 21:09:46,053 iteration 1498 : loss : 0.050747, loss_ce: 0.021967
2022-01-20 21:09:46,579 iteration 1499 : loss : 0.042759, loss_ce: 0.016456
2022-01-20 21:09:47,174 iteration 1500 : loss : 0.042678, loss_ce: 0.019980
2022-01-20 21:09:47,743 iteration 1501 : loss : 0.045359, loss_ce: 0.020989
2022-01-20 21:09:48,409 iteration 1502 : loss : 0.062383, loss_ce: 0.016520
2022-01-20 21:09:49,124 iteration 1503 : loss : 0.073641, loss_ce: 0.021845
2022-01-20 21:09:49,701 iteration 1504 : loss : 0.038851, loss_ce: 0.016196
2022-01-20 21:09:50,325 iteration 1505 : loss : 0.044670, loss_ce: 0.020705
2022-01-20 21:09:50,945 iteration 1506 : loss : 0.038305, loss_ce: 0.016365
2022-01-20 21:09:51,569 iteration 1507 : loss : 0.062711, loss_ce: 0.020857
2022-01-20 21:09:52,186 iteration 1508 : loss : 0.037565, loss_ce: 0.018537
2022-01-20 21:09:52,782 iteration 1509 : loss : 0.047312, loss_ce: 0.018782
2022-01-20 21:09:53,456 iteration 1510 : loss : 0.061491, loss_ce: 0.021476
2022-01-20 21:09:54,119 iteration 1511 : loss : 0.054961, loss_ce: 0.029442
2022-01-20 21:09:54,725 iteration 1512 : loss : 0.049128, loss_ce: 0.014769
2022-01-20 21:09:55,330 iteration 1513 : loss : 0.040970, loss_ce: 0.016174
 22%|███████                         | 89/400 [16:20<54:59, 10.61s/it]2022-01-20 21:09:56,011 iteration 1514 : loss : 0.045351, loss_ce: 0.021293
2022-01-20 21:09:56,556 iteration 1515 : loss : 0.035321, loss_ce: 0.015070
2022-01-20 21:09:57,155 iteration 1516 : loss : 0.046253, loss_ce: 0.020909
2022-01-20 21:09:57,676 iteration 1517 : loss : 0.031972, loss_ce: 0.012942
2022-01-20 21:09:58,307 iteration 1518 : loss : 0.038174, loss_ce: 0.014802
2022-01-20 21:09:58,977 iteration 1519 : loss : 0.045205, loss_ce: 0.018505
2022-01-20 21:09:59,632 iteration 1520 : loss : 0.041803, loss_ce: 0.015940
2022-01-20 21:10:00,243 iteration 1521 : loss : 0.081130, loss_ce: 0.027784
2022-01-20 21:10:00,803 iteration 1522 : loss : 0.042712, loss_ce: 0.018678
2022-01-20 21:10:01,370 iteration 1523 : loss : 0.042808, loss_ce: 0.014724
2022-01-20 21:10:01,976 iteration 1524 : loss : 0.038730, loss_ce: 0.016346
2022-01-20 21:10:02,502 iteration 1525 : loss : 0.043652, loss_ce: 0.017511
2022-01-20 21:10:03,126 iteration 1526 : loss : 0.047311, loss_ce: 0.020800
2022-01-20 21:10:03,767 iteration 1527 : loss : 0.059799, loss_ce: 0.026948
2022-01-20 21:10:04,324 iteration 1528 : loss : 0.035120, loss_ce: 0.016011
2022-01-20 21:10:04,878 iteration 1529 : loss : 0.042893, loss_ce: 0.018124
2022-01-20 21:10:04,878 Training Data Eval:
2022-01-20 21:10:07,564   Average segmentation loss on training set: 0.0300
2022-01-20 21:10:07,564 Validation Data Eval:
2022-01-20 21:10:08,450   Average segmentation loss on validation set: 0.0968
2022-01-20 21:10:09,073 iteration 1530 : loss : 0.041300, loss_ce: 0.018378
 22%|███████▏                        | 90/400 [16:33<59:40, 11.55s/it]2022-01-20 21:10:09,727 iteration 1531 : loss : 0.040055, loss_ce: 0.017265
2022-01-20 21:10:10,365 iteration 1532 : loss : 0.041044, loss_ce: 0.015270
2022-01-20 21:10:10,903 iteration 1533 : loss : 0.032828, loss_ce: 0.012551
2022-01-20 21:10:11,473 iteration 1534 : loss : 0.046484, loss_ce: 0.021680
2022-01-20 21:10:12,119 iteration 1535 : loss : 0.034714, loss_ce: 0.013624
2022-01-20 21:10:12,762 iteration 1536 : loss : 0.045306, loss_ce: 0.021159
2022-01-20 21:10:13,347 iteration 1537 : loss : 0.049939, loss_ce: 0.019250
2022-01-20 21:10:13,981 iteration 1538 : loss : 0.030340, loss_ce: 0.013217
2022-01-20 21:10:14,581 iteration 1539 : loss : 0.036104, loss_ce: 0.015418
2022-01-20 21:10:15,175 iteration 1540 : loss : 0.040657, loss_ce: 0.018321
2022-01-20 21:10:15,738 iteration 1541 : loss : 0.027853, loss_ce: 0.012498
2022-01-20 21:10:16,282 iteration 1542 : loss : 0.030238, loss_ce: 0.012371
2022-01-20 21:10:16,848 iteration 1543 : loss : 0.060150, loss_ce: 0.019194
2022-01-20 21:10:17,370 iteration 1544 : loss : 0.028000, loss_ce: 0.010943
2022-01-20 21:10:18,065 iteration 1545 : loss : 0.040691, loss_ce: 0.015132
2022-01-20 21:10:18,604 iteration 1546 : loss : 0.061959, loss_ce: 0.017405
2022-01-20 21:10:19,275 iteration 1547 : loss : 0.058086, loss_ce: 0.023582
 23%|███████▎                        | 91/400 [16:44<57:23, 11.14s/it]2022-01-20 21:10:19,929 iteration 1548 : loss : 0.043952, loss_ce: 0.018865
2022-01-20 21:10:20,434 iteration 1549 : loss : 0.033738, loss_ce: 0.014223
2022-01-20 21:10:20,990 iteration 1550 : loss : 0.038616, loss_ce: 0.016098
2022-01-20 21:10:21,475 iteration 1551 : loss : 0.031761, loss_ce: 0.011666
2022-01-20 21:10:22,079 iteration 1552 : loss : 0.038307, loss_ce: 0.015266
2022-01-20 21:10:22,716 iteration 1553 : loss : 0.059332, loss_ce: 0.022017
2022-01-20 21:10:23,330 iteration 1554 : loss : 0.031745, loss_ce: 0.013114
2022-01-20 21:10:23,902 iteration 1555 : loss : 0.037031, loss_ce: 0.017126
2022-01-20 21:10:24,520 iteration 1556 : loss : 0.036947, loss_ce: 0.011578
2022-01-20 21:10:25,081 iteration 1557 : loss : 0.041379, loss_ce: 0.015539
2022-01-20 21:10:25,670 iteration 1558 : loss : 0.036677, loss_ce: 0.018778
2022-01-20 21:10:26,271 iteration 1559 : loss : 0.047908, loss_ce: 0.019045
2022-01-20 21:10:26,816 iteration 1560 : loss : 0.027564, loss_ce: 0.013812
2022-01-20 21:10:27,444 iteration 1561 : loss : 0.039984, loss_ce: 0.017347
2022-01-20 21:10:27,997 iteration 1562 : loss : 0.050182, loss_ce: 0.012559
2022-01-20 21:10:28,641 iteration 1563 : loss : 0.033707, loss_ce: 0.016346
2022-01-20 21:10:29,281 iteration 1564 : loss : 0.033985, loss_ce: 0.014606
 23%|███████▎                        | 92/400 [16:54<55:26, 10.80s/it]2022-01-20 21:10:29,895 iteration 1565 : loss : 0.040091, loss_ce: 0.018893
2022-01-20 21:10:30,485 iteration 1566 : loss : 0.037388, loss_ce: 0.015243
2022-01-20 21:10:31,114 iteration 1567 : loss : 0.040950, loss_ce: 0.013715
2022-01-20 21:10:31,673 iteration 1568 : loss : 0.087728, loss_ce: 0.033641
2022-01-20 21:10:32,284 iteration 1569 : loss : 0.034996, loss_ce: 0.016256
2022-01-20 21:10:32,877 iteration 1570 : loss : 0.028767, loss_ce: 0.013108
2022-01-20 21:10:33,431 iteration 1571 : loss : 0.052949, loss_ce: 0.014601
2022-01-20 21:10:34,079 iteration 1572 : loss : 0.061630, loss_ce: 0.020386
2022-01-20 21:10:34,687 iteration 1573 : loss : 0.046975, loss_ce: 0.022209
2022-01-20 21:10:35,229 iteration 1574 : loss : 0.027645, loss_ce: 0.012904
2022-01-20 21:10:35,723 iteration 1575 : loss : 0.047104, loss_ce: 0.018027
2022-01-20 21:10:36,301 iteration 1576 : loss : 0.043926, loss_ce: 0.022087
2022-01-20 21:10:36,877 iteration 1577 : loss : 0.031233, loss_ce: 0.012870
2022-01-20 21:10:37,460 iteration 1578 : loss : 0.052331, loss_ce: 0.019042
2022-01-20 21:10:38,081 iteration 1579 : loss : 0.029867, loss_ce: 0.011243
2022-01-20 21:10:38,627 iteration 1580 : loss : 0.049827, loss_ce: 0.020190
2022-01-20 21:10:39,204 iteration 1581 : loss : 0.036816, loss_ce: 0.012626
 23%|███████▍                        | 93/400 [17:04<53:55, 10.54s/it]2022-01-20 21:10:39,898 iteration 1582 : loss : 0.039498, loss_ce: 0.013455
2022-01-20 21:10:40,476 iteration 1583 : loss : 0.052528, loss_ce: 0.017018
2022-01-20 21:10:41,094 iteration 1584 : loss : 0.035342, loss_ce: 0.020155
2022-01-20 21:10:41,683 iteration 1585 : loss : 0.034718, loss_ce: 0.011611
2022-01-20 21:10:42,262 iteration 1586 : loss : 0.044587, loss_ce: 0.019313
2022-01-20 21:10:42,750 iteration 1587 : loss : 0.028959, loss_ce: 0.012510
2022-01-20 21:10:43,367 iteration 1588 : loss : 0.042428, loss_ce: 0.020948
2022-01-20 21:10:43,957 iteration 1589 : loss : 0.055298, loss_ce: 0.028674
2022-01-20 21:10:44,675 iteration 1590 : loss : 0.034346, loss_ce: 0.015398
2022-01-20 21:10:45,227 iteration 1591 : loss : 0.033815, loss_ce: 0.013591
2022-01-20 21:10:45,810 iteration 1592 : loss : 0.057248, loss_ce: 0.026136
2022-01-20 21:10:46,499 iteration 1593 : loss : 0.047380, loss_ce: 0.022546
2022-01-20 21:10:47,180 iteration 1594 : loss : 0.053652, loss_ce: 0.023617
2022-01-20 21:10:47,771 iteration 1595 : loss : 0.029353, loss_ce: 0.009977
2022-01-20 21:10:48,377 iteration 1596 : loss : 0.047728, loss_ce: 0.021919
2022-01-20 21:10:48,972 iteration 1597 : loss : 0.053329, loss_ce: 0.026020
2022-01-20 21:10:49,592 iteration 1598 : loss : 0.037647, loss_ce: 0.014294
 24%|███████▌                        | 94/400 [17:14<53:31, 10.49s/it]2022-01-20 21:10:50,205 iteration 1599 : loss : 0.034721, loss_ce: 0.014270
2022-01-20 21:10:50,800 iteration 1600 : loss : 0.028227, loss_ce: 0.010664
2022-01-20 21:10:51,455 iteration 1601 : loss : 0.040628, loss_ce: 0.018075
2022-01-20 21:10:52,177 iteration 1602 : loss : 0.042210, loss_ce: 0.016724
2022-01-20 21:10:52,768 iteration 1603 : loss : 0.030281, loss_ce: 0.012293
2022-01-20 21:10:53,322 iteration 1604 : loss : 0.041781, loss_ce: 0.017567
2022-01-20 21:10:53,952 iteration 1605 : loss : 0.047574, loss_ce: 0.017520
2022-01-20 21:10:54,526 iteration 1606 : loss : 0.045797, loss_ce: 0.023785
2022-01-20 21:10:55,086 iteration 1607 : loss : 0.033201, loss_ce: 0.014897
2022-01-20 21:10:55,746 iteration 1608 : loss : 0.036736, loss_ce: 0.013856
2022-01-20 21:10:56,333 iteration 1609 : loss : 0.048864, loss_ce: 0.025246
2022-01-20 21:10:56,945 iteration 1610 : loss : 0.033532, loss_ce: 0.013859
2022-01-20 21:10:57,640 iteration 1611 : loss : 0.051713, loss_ce: 0.017654
2022-01-20 21:10:58,236 iteration 1612 : loss : 0.031884, loss_ce: 0.014712
2022-01-20 21:10:58,696 iteration 1613 : loss : 0.042987, loss_ce: 0.018247
2022-01-20 21:10:59,317 iteration 1614 : loss : 0.055418, loss_ce: 0.017316
2022-01-20 21:10:59,317 Training Data Eval:
2022-01-20 21:11:02,004   Average segmentation loss on training set: 0.0313
2022-01-20 21:11:02,004 Validation Data Eval:
2022-01-20 21:11:02,883   Average segmentation loss on validation set: 0.0839
2022-01-20 21:11:03,451 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:11:04,061 iteration 1615 : loss : 0.031470, loss_ce: 0.013659
 24%|███████▌                        | 95/400 [17:28<59:24, 11.69s/it]2022-01-20 21:11:04,735 iteration 1616 : loss : 0.048705, loss_ce: 0.019983
2022-01-20 21:11:05,353 iteration 1617 : loss : 0.048577, loss_ce: 0.017633
2022-01-20 21:11:05,874 iteration 1618 : loss : 0.028017, loss_ce: 0.013731
2022-01-20 21:11:06,400 iteration 1619 : loss : 0.028659, loss_ce: 0.010503
2022-01-20 21:11:06,899 iteration 1620 : loss : 0.044809, loss_ce: 0.014963
2022-01-20 21:11:07,502 iteration 1621 : loss : 0.041721, loss_ce: 0.023685
2022-01-20 21:11:08,222 iteration 1622 : loss : 0.055549, loss_ce: 0.018204
2022-01-20 21:11:08,821 iteration 1623 : loss : 0.044450, loss_ce: 0.018764
2022-01-20 21:11:09,379 iteration 1624 : loss : 0.031386, loss_ce: 0.012603
2022-01-20 21:11:09,949 iteration 1625 : loss : 0.031908, loss_ce: 0.012577
2022-01-20 21:11:10,510 iteration 1626 : loss : 0.029522, loss_ce: 0.013020
2022-01-20 21:11:11,093 iteration 1627 : loss : 0.041235, loss_ce: 0.015805
2022-01-20 21:11:11,758 iteration 1628 : loss : 0.037009, loss_ce: 0.015839
2022-01-20 21:11:12,343 iteration 1629 : loss : 0.031146, loss_ce: 0.012792
2022-01-20 21:11:12,878 iteration 1630 : loss : 0.039330, loss_ce: 0.015055
2022-01-20 21:11:13,595 iteration 1631 : loss : 0.039663, loss_ce: 0.019234
2022-01-20 21:11:14,275 iteration 1632 : loss : 0.038509, loss_ce: 0.015426
 24%|███████▋                        | 96/400 [17:39<56:57, 11.24s/it]2022-01-20 21:11:14,976 iteration 1633 : loss : 0.029152, loss_ce: 0.010892
2022-01-20 21:11:15,608 iteration 1634 : loss : 0.063557, loss_ce: 0.020676
2022-01-20 21:11:16,208 iteration 1635 : loss : 0.030096, loss_ce: 0.014107
2022-01-20 21:11:16,885 iteration 1636 : loss : 0.037708, loss_ce: 0.017886
2022-01-20 21:11:17,497 iteration 1637 : loss : 0.041627, loss_ce: 0.014704
2022-01-20 21:11:18,073 iteration 1638 : loss : 0.042144, loss_ce: 0.019422
2022-01-20 21:11:18,773 iteration 1639 : loss : 0.066347, loss_ce: 0.015906
2022-01-20 21:11:19,406 iteration 1640 : loss : 0.061028, loss_ce: 0.018355
2022-01-20 21:11:19,937 iteration 1641 : loss : 0.029380, loss_ce: 0.013646
2022-01-20 21:11:20,517 iteration 1642 : loss : 0.028510, loss_ce: 0.010141
2022-01-20 21:11:21,149 iteration 1643 : loss : 0.034478, loss_ce: 0.010881
2022-01-20 21:11:21,712 iteration 1644 : loss : 0.034008, loss_ce: 0.012537
2022-01-20 21:11:22,289 iteration 1645 : loss : 0.034363, loss_ce: 0.012695
2022-01-20 21:11:22,865 iteration 1646 : loss : 0.047433, loss_ce: 0.016602
2022-01-20 21:11:23,428 iteration 1647 : loss : 0.056421, loss_ce: 0.019820
2022-01-20 21:11:24,027 iteration 1648 : loss : 0.049299, loss_ce: 0.024855
2022-01-20 21:11:24,570 iteration 1649 : loss : 0.039216, loss_ce: 0.018654
 24%|███████▊                        | 97/400 [17:49<55:20, 10.96s/it]2022-01-20 21:11:25,237 iteration 1650 : loss : 0.032326, loss_ce: 0.015881
2022-01-20 21:11:25,955 iteration 1651 : loss : 0.052469, loss_ce: 0.018549
2022-01-20 21:11:26,495 iteration 1652 : loss : 0.045943, loss_ce: 0.015206
2022-01-20 21:11:27,034 iteration 1653 : loss : 0.030507, loss_ce: 0.011145
2022-01-20 21:11:27,667 iteration 1654 : loss : 0.063292, loss_ce: 0.022737
2022-01-20 21:11:28,324 iteration 1655 : loss : 0.050855, loss_ce: 0.018888
2022-01-20 21:11:28,909 iteration 1656 : loss : 0.026698, loss_ce: 0.010564
2022-01-20 21:11:29,620 iteration 1657 : loss : 0.049314, loss_ce: 0.019572
2022-01-20 21:11:30,268 iteration 1658 : loss : 0.056832, loss_ce: 0.031135
2022-01-20 21:11:30,817 iteration 1659 : loss : 0.025435, loss_ce: 0.009337
2022-01-20 21:11:31,524 iteration 1660 : loss : 0.036440, loss_ce: 0.014840
2022-01-20 21:11:32,210 iteration 1661 : loss : 0.031594, loss_ce: 0.010691
2022-01-20 21:11:32,811 iteration 1662 : loss : 0.042707, loss_ce: 0.016836
2022-01-20 21:11:33,291 iteration 1663 : loss : 0.026965, loss_ce: 0.014177
2022-01-20 21:11:33,964 iteration 1664 : loss : 0.048270, loss_ce: 0.019531
2022-01-20 21:11:34,599 iteration 1665 : loss : 0.035567, loss_ce: 0.013778
2022-01-20 21:11:35,263 iteration 1666 : loss : 0.049310, loss_ce: 0.020838
 24%|███████▊                        | 98/400 [18:00<54:46, 10.88s/it]2022-01-20 21:11:35,938 iteration 1667 : loss : 0.066892, loss_ce: 0.023161
2022-01-20 21:11:36,543 iteration 1668 : loss : 0.055966, loss_ce: 0.022362
2022-01-20 21:11:37,098 iteration 1669 : loss : 0.033448, loss_ce: 0.013526
2022-01-20 21:11:37,709 iteration 1670 : loss : 0.048051, loss_ce: 0.024540
2022-01-20 21:11:38,296 iteration 1671 : loss : 0.035944, loss_ce: 0.013773
2022-01-20 21:11:38,950 iteration 1672 : loss : 0.031047, loss_ce: 0.012344
2022-01-20 21:11:39,578 iteration 1673 : loss : 0.039699, loss_ce: 0.016761
2022-01-20 21:11:40,246 iteration 1674 : loss : 0.036273, loss_ce: 0.017841
2022-01-20 21:11:40,813 iteration 1675 : loss : 0.039400, loss_ce: 0.011138
2022-01-20 21:11:41,396 iteration 1676 : loss : 0.057576, loss_ce: 0.020163
2022-01-20 21:11:42,065 iteration 1677 : loss : 0.054898, loss_ce: 0.023770
2022-01-20 21:11:42,549 iteration 1678 : loss : 0.039956, loss_ce: 0.017334
2022-01-20 21:11:43,116 iteration 1679 : loss : 0.038079, loss_ce: 0.011165
2022-01-20 21:11:43,754 iteration 1680 : loss : 0.038652, loss_ce: 0.017962
2022-01-20 21:11:44,391 iteration 1681 : loss : 0.043667, loss_ce: 0.026046
2022-01-20 21:11:45,028 iteration 1682 : loss : 0.046608, loss_ce: 0.017010
2022-01-20 21:11:45,573 iteration 1683 : loss : 0.029172, loss_ce: 0.010242
 25%|███████▉                        | 99/400 [18:10<53:43, 10.71s/it]2022-01-20 21:11:46,244 iteration 1684 : loss : 0.065044, loss_ce: 0.021441
2022-01-20 21:11:46,848 iteration 1685 : loss : 0.039609, loss_ce: 0.013083
2022-01-20 21:11:47,435 iteration 1686 : loss : 0.036782, loss_ce: 0.014320
2022-01-20 21:11:47,964 iteration 1687 : loss : 0.038021, loss_ce: 0.017335
2022-01-20 21:11:48,678 iteration 1688 : loss : 0.033382, loss_ce: 0.014449
2022-01-20 21:11:49,291 iteration 1689 : loss : 0.038333, loss_ce: 0.017047
2022-01-20 21:11:49,934 iteration 1690 : loss : 0.041352, loss_ce: 0.021935
2022-01-20 21:11:50,458 iteration 1691 : loss : 0.081453, loss_ce: 0.022244
2022-01-20 21:11:51,097 iteration 1692 : loss : 0.072515, loss_ce: 0.023716
2022-01-20 21:11:51,571 iteration 1693 : loss : 0.031731, loss_ce: 0.013125
2022-01-20 21:11:52,193 iteration 1694 : loss : 0.029113, loss_ce: 0.011943
2022-01-20 21:11:52,858 iteration 1695 : loss : 0.043543, loss_ce: 0.016326
2022-01-20 21:11:53,525 iteration 1696 : loss : 0.049531, loss_ce: 0.016235
2022-01-20 21:11:54,113 iteration 1697 : loss : 0.037501, loss_ce: 0.014822
2022-01-20 21:11:54,755 iteration 1698 : loss : 0.065951, loss_ce: 0.025265
2022-01-20 21:11:55,356 iteration 1699 : loss : 0.040429, loss_ce: 0.021838
2022-01-20 21:11:55,356 Training Data Eval:
2022-01-20 21:11:58,043   Average segmentation loss on training set: 0.0298
2022-01-20 21:11:58,044 Validation Data Eval:
2022-01-20 21:11:58,920   Average segmentation loss on validation set: 0.0787
2022-01-20 21:11:59,504 Found new lowest validation loss at iteration 1699! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:12:00,072 iteration 1700 : loss : 0.033735, loss_ce: 0.012073
 25%|███████▊                       | 100/400 [18:24<59:13, 11.85s/it]2022-01-20 21:12:00,714 iteration 1701 : loss : 0.032606, loss_ce: 0.013454
2022-01-20 21:12:01,283 iteration 1702 : loss : 0.050954, loss_ce: 0.020445
2022-01-20 21:12:01,961 iteration 1703 : loss : 0.049781, loss_ce: 0.021125
2022-01-20 21:12:02,612 iteration 1704 : loss : 0.047418, loss_ce: 0.021598
2022-01-20 21:12:03,197 iteration 1705 : loss : 0.034560, loss_ce: 0.012082
2022-01-20 21:12:03,838 iteration 1706 : loss : 0.047779, loss_ce: 0.012516
2022-01-20 21:12:04,415 iteration 1707 : loss : 0.052385, loss_ce: 0.022182
2022-01-20 21:12:04,998 iteration 1708 : loss : 0.036807, loss_ce: 0.015532
2022-01-20 21:12:05,748 iteration 1709 : loss : 0.034790, loss_ce: 0.013302
2022-01-20 21:12:06,307 iteration 1710 : loss : 0.038498, loss_ce: 0.018571
2022-01-20 21:12:06,924 iteration 1711 : loss : 0.043470, loss_ce: 0.015436
2022-01-20 21:12:07,542 iteration 1712 : loss : 0.049499, loss_ce: 0.015712
2022-01-20 21:12:08,150 iteration 1713 : loss : 0.048139, loss_ce: 0.016578
2022-01-20 21:12:08,725 iteration 1714 : loss : 0.031480, loss_ce: 0.013975
2022-01-20 21:12:09,382 iteration 1715 : loss : 0.044066, loss_ce: 0.021575
2022-01-20 21:12:09,965 iteration 1716 : loss : 0.047850, loss_ce: 0.016658
2022-01-20 21:12:10,578 iteration 1717 : loss : 0.036728, loss_ce: 0.016486
 25%|███████▊                       | 101/400 [18:35<57:01, 11.44s/it]2022-01-20 21:12:11,255 iteration 1718 : loss : 0.035333, loss_ce: 0.013687
2022-01-20 21:12:11,928 iteration 1719 : loss : 0.034488, loss_ce: 0.010718
2022-01-20 21:12:12,567 iteration 1720 : loss : 0.045620, loss_ce: 0.016593
2022-01-20 21:12:13,179 iteration 1721 : loss : 0.047022, loss_ce: 0.022791
2022-01-20 21:12:13,737 iteration 1722 : loss : 0.031539, loss_ce: 0.012415
2022-01-20 21:12:14,305 iteration 1723 : loss : 0.033760, loss_ce: 0.013207
2022-01-20 21:12:14,831 iteration 1724 : loss : 0.031639, loss_ce: 0.015087
2022-01-20 21:12:15,374 iteration 1725 : loss : 0.033780, loss_ce: 0.014801
2022-01-20 21:12:16,081 iteration 1726 : loss : 0.036070, loss_ce: 0.013683
2022-01-20 21:12:16,734 iteration 1727 : loss : 0.049391, loss_ce: 0.016462
2022-01-20 21:12:17,443 iteration 1728 : loss : 0.056094, loss_ce: 0.023184
2022-01-20 21:12:18,013 iteration 1729 : loss : 0.037590, loss_ce: 0.014823
2022-01-20 21:12:18,628 iteration 1730 : loss : 0.030726, loss_ce: 0.011471
2022-01-20 21:12:19,183 iteration 1731 : loss : 0.033936, loss_ce: 0.016196
2022-01-20 21:12:19,791 iteration 1732 : loss : 0.042567, loss_ce: 0.018664
2022-01-20 21:12:20,392 iteration 1733 : loss : 0.045216, loss_ce: 0.014819
2022-01-20 21:12:20,966 iteration 1734 : loss : 0.044556, loss_ce: 0.013267
 26%|███████▉                       | 102/400 [18:45<55:15, 11.12s/it]2022-01-20 21:12:21,670 iteration 1735 : loss : 0.041941, loss_ce: 0.015277
2022-01-20 21:12:22,270 iteration 1736 : loss : 0.038036, loss_ce: 0.015063
2022-01-20 21:12:22,888 iteration 1737 : loss : 0.042389, loss_ce: 0.017883
2022-01-20 21:12:23,480 iteration 1738 : loss : 0.033199, loss_ce: 0.012851
2022-01-20 21:12:24,068 iteration 1739 : loss : 0.039190, loss_ce: 0.020430
2022-01-20 21:12:24,652 iteration 1740 : loss : 0.045692, loss_ce: 0.012743
2022-01-20 21:12:25,336 iteration 1741 : loss : 0.044056, loss_ce: 0.015245
2022-01-20 21:12:25,950 iteration 1742 : loss : 0.042423, loss_ce: 0.016893
2022-01-20 21:12:26,551 iteration 1743 : loss : 0.042058, loss_ce: 0.025336
2022-01-20 21:12:27,100 iteration 1744 : loss : 0.037482, loss_ce: 0.012709
2022-01-20 21:12:27,762 iteration 1745 : loss : 0.047544, loss_ce: 0.018195
2022-01-20 21:12:28,333 iteration 1746 : loss : 0.034141, loss_ce: 0.012790
2022-01-20 21:12:28,911 iteration 1747 : loss : 0.038506, loss_ce: 0.013622
2022-01-20 21:12:29,457 iteration 1748 : loss : 0.028181, loss_ce: 0.013251
2022-01-20 21:12:30,077 iteration 1749 : loss : 0.034128, loss_ce: 0.012300
2022-01-20 21:12:30,634 iteration 1750 : loss : 0.038366, loss_ce: 0.018029
2022-01-20 21:12:31,195 iteration 1751 : loss : 0.039123, loss_ce: 0.014261
 26%|███████▉                       | 103/400 [18:56<53:44, 10.86s/it]2022-01-20 21:12:31,836 iteration 1752 : loss : 0.054121, loss_ce: 0.023057
2022-01-20 21:12:32,517 iteration 1753 : loss : 0.039048, loss_ce: 0.017928
2022-01-20 21:12:33,142 iteration 1754 : loss : 0.037149, loss_ce: 0.018000
2022-01-20 21:12:33,757 iteration 1755 : loss : 0.049019, loss_ce: 0.016290
2022-01-20 21:12:34,404 iteration 1756 : loss : 0.037597, loss_ce: 0.015435
2022-01-20 21:12:35,007 iteration 1757 : loss : 0.103565, loss_ce: 0.020965
2022-01-20 21:12:35,620 iteration 1758 : loss : 0.045075, loss_ce: 0.018704
2022-01-20 21:12:36,201 iteration 1759 : loss : 0.029814, loss_ce: 0.009851
2022-01-20 21:12:36,851 iteration 1760 : loss : 0.063384, loss_ce: 0.025445
2022-01-20 21:12:37,397 iteration 1761 : loss : 0.025960, loss_ce: 0.011766
2022-01-20 21:12:38,065 iteration 1762 : loss : 0.073265, loss_ce: 0.027927
2022-01-20 21:12:38,628 iteration 1763 : loss : 0.051976, loss_ce: 0.017566
2022-01-20 21:12:39,262 iteration 1764 : loss : 0.103717, loss_ce: 0.035614
2022-01-20 21:12:39,901 iteration 1765 : loss : 0.053509, loss_ce: 0.015138
2022-01-20 21:12:40,451 iteration 1766 : loss : 0.038144, loss_ce: 0.016600
2022-01-20 21:12:41,039 iteration 1767 : loss : 0.049339, loss_ce: 0.022361
2022-01-20 21:12:41,702 iteration 1768 : loss : 0.039751, loss_ce: 0.014847
 26%|████████                       | 104/400 [19:06<53:02, 10.75s/it]2022-01-20 21:12:42,331 iteration 1769 : loss : 0.047209, loss_ce: 0.014216
2022-01-20 21:12:43,112 iteration 1770 : loss : 0.065923, loss_ce: 0.027526
2022-01-20 21:12:43,710 iteration 1771 : loss : 0.050755, loss_ce: 0.022165
2022-01-20 21:12:44,259 iteration 1772 : loss : 0.034753, loss_ce: 0.011117
2022-01-20 21:12:44,779 iteration 1773 : loss : 0.036789, loss_ce: 0.013045
2022-01-20 21:12:45,376 iteration 1774 : loss : 0.037517, loss_ce: 0.016485
2022-01-20 21:12:46,026 iteration 1775 : loss : 0.043334, loss_ce: 0.020316
2022-01-20 21:12:46,613 iteration 1776 : loss : 0.072706, loss_ce: 0.019940
2022-01-20 21:12:47,180 iteration 1777 : loss : 0.047378, loss_ce: 0.020820
2022-01-20 21:12:47,759 iteration 1778 : loss : 0.042623, loss_ce: 0.017524
2022-01-20 21:12:48,360 iteration 1779 : loss : 0.037212, loss_ce: 0.014705
2022-01-20 21:12:48,932 iteration 1780 : loss : 0.037171, loss_ce: 0.013688
2022-01-20 21:12:49,511 iteration 1781 : loss : 0.047391, loss_ce: 0.022356
2022-01-20 21:12:50,130 iteration 1782 : loss : 0.046490, loss_ce: 0.018274
2022-01-20 21:12:50,684 iteration 1783 : loss : 0.039311, loss_ce: 0.020219
2022-01-20 21:12:51,372 iteration 1784 : loss : 0.050489, loss_ce: 0.019141
2022-01-20 21:12:51,373 Training Data Eval:
2022-01-20 21:12:54,059   Average segmentation loss on training set: 0.0377
2022-01-20 21:12:54,059 Validation Data Eval:
2022-01-20 21:12:54,940   Average segmentation loss on validation set: 0.1073
2022-01-20 21:12:55,542 iteration 1785 : loss : 0.035866, loss_ce: 0.015224
 26%|████████▏                      | 105/400 [19:20<57:25, 11.68s/it]2022-01-20 21:12:56,306 iteration 1786 : loss : 0.041500, loss_ce: 0.019748
2022-01-20 21:12:57,006 iteration 1787 : loss : 0.041981, loss_ce: 0.017764
2022-01-20 21:12:57,643 iteration 1788 : loss : 0.048755, loss_ce: 0.020421
2022-01-20 21:12:58,256 iteration 1789 : loss : 0.038336, loss_ce: 0.013524
2022-01-20 21:12:58,850 iteration 1790 : loss : 0.035436, loss_ce: 0.016055
2022-01-20 21:12:59,387 iteration 1791 : loss : 0.031619, loss_ce: 0.014243
2022-01-20 21:13:00,017 iteration 1792 : loss : 0.045625, loss_ce: 0.014421
2022-01-20 21:13:00,660 iteration 1793 : loss : 0.032571, loss_ce: 0.015240
2022-01-20 21:13:01,224 iteration 1794 : loss : 0.038841, loss_ce: 0.018455
2022-01-20 21:13:01,834 iteration 1795 : loss : 0.043392, loss_ce: 0.017732
2022-01-20 21:13:02,433 iteration 1796 : loss : 0.035187, loss_ce: 0.012404
2022-01-20 21:13:03,129 iteration 1797 : loss : 0.027820, loss_ce: 0.010928
2022-01-20 21:13:03,735 iteration 1798 : loss : 0.040483, loss_ce: 0.013469
2022-01-20 21:13:04,372 iteration 1799 : loss : 0.041746, loss_ce: 0.017535
2022-01-20 21:13:04,999 iteration 1800 : loss : 0.081212, loss_ce: 0.046802
2022-01-20 21:13:05,637 iteration 1801 : loss : 0.048692, loss_ce: 0.020976
2022-01-20 21:13:06,154 iteration 1802 : loss : 0.064046, loss_ce: 0.017261
 26%|████████▏                      | 106/400 [19:31<55:39, 11.36s/it]2022-01-20 21:13:06,831 iteration 1803 : loss : 0.038323, loss_ce: 0.013220
2022-01-20 21:13:07,411 iteration 1804 : loss : 0.038331, loss_ce: 0.008974
2022-01-20 21:13:07,952 iteration 1805 : loss : 0.030527, loss_ce: 0.013597
2022-01-20 21:13:08,512 iteration 1806 : loss : 0.041839, loss_ce: 0.014052
2022-01-20 21:13:09,116 iteration 1807 : loss : 0.044917, loss_ce: 0.015944
2022-01-20 21:13:09,725 iteration 1808 : loss : 0.037644, loss_ce: 0.015468
2022-01-20 21:13:10,302 iteration 1809 : loss : 0.042075, loss_ce: 0.019310
2022-01-20 21:13:10,908 iteration 1810 : loss : 0.039159, loss_ce: 0.017453
2022-01-20 21:13:11,535 iteration 1811 : loss : 0.056852, loss_ce: 0.023272
2022-01-20 21:13:12,201 iteration 1812 : loss : 0.043200, loss_ce: 0.019757
2022-01-20 21:13:12,838 iteration 1813 : loss : 0.077969, loss_ce: 0.023190
2022-01-20 21:13:13,530 iteration 1814 : loss : 0.047925, loss_ce: 0.021507
2022-01-20 21:13:14,160 iteration 1815 : loss : 0.034253, loss_ce: 0.017254
2022-01-20 21:13:14,835 iteration 1816 : loss : 0.056396, loss_ce: 0.019699
2022-01-20 21:13:15,450 iteration 1817 : loss : 0.052176, loss_ce: 0.018283
2022-01-20 21:13:16,153 iteration 1818 : loss : 0.035478, loss_ce: 0.017937
2022-01-20 21:13:16,734 iteration 1819 : loss : 0.039680, loss_ce: 0.015215
 27%|████████▎                      | 107/400 [19:41<54:18, 11.12s/it]2022-01-20 21:13:17,426 iteration 1820 : loss : 0.066514, loss_ce: 0.022074
2022-01-20 21:13:17,993 iteration 1821 : loss : 0.051710, loss_ce: 0.016499
2022-01-20 21:13:18,562 iteration 1822 : loss : 0.031602, loss_ce: 0.014702
2022-01-20 21:13:19,204 iteration 1823 : loss : 0.044433, loss_ce: 0.018012
2022-01-20 21:13:19,797 iteration 1824 : loss : 0.035907, loss_ce: 0.011646
2022-01-20 21:13:20,414 iteration 1825 : loss : 0.056865, loss_ce: 0.019139
2022-01-20 21:13:20,937 iteration 1826 : loss : 0.034573, loss_ce: 0.014810
2022-01-20 21:13:21,492 iteration 1827 : loss : 0.041863, loss_ce: 0.012061
2022-01-20 21:13:22,131 iteration 1828 : loss : 0.038140, loss_ce: 0.017658
2022-01-20 21:13:22,766 iteration 1829 : loss : 0.055557, loss_ce: 0.017056
2022-01-20 21:13:23,363 iteration 1830 : loss : 0.026911, loss_ce: 0.011220
2022-01-20 21:13:23,942 iteration 1831 : loss : 0.035849, loss_ce: 0.015843
2022-01-20 21:13:24,521 iteration 1832 : loss : 0.037199, loss_ce: 0.012990
2022-01-20 21:13:25,088 iteration 1833 : loss : 0.033634, loss_ce: 0.019337
2022-01-20 21:13:25,761 iteration 1834 : loss : 0.041139, loss_ce: 0.015821
2022-01-20 21:13:26,282 iteration 1835 : loss : 0.033773, loss_ce: 0.012488
2022-01-20 21:13:26,843 iteration 1836 : loss : 0.040916, loss_ce: 0.018993
 27%|████████▎                      | 108/400 [19:51<52:40, 10.82s/it]2022-01-20 21:13:27,421 iteration 1837 : loss : 0.059326, loss_ce: 0.012247
2022-01-20 21:13:28,088 iteration 1838 : loss : 0.041763, loss_ce: 0.021264
2022-01-20 21:13:28,620 iteration 1839 : loss : 0.033256, loss_ce: 0.013943
2022-01-20 21:13:29,221 iteration 1840 : loss : 0.044361, loss_ce: 0.013418
2022-01-20 21:13:29,820 iteration 1841 : loss : 0.038134, loss_ce: 0.013429
2022-01-20 21:13:30,497 iteration 1842 : loss : 0.032947, loss_ce: 0.013728
2022-01-20 21:13:31,079 iteration 1843 : loss : 0.054209, loss_ce: 0.029902
2022-01-20 21:13:31,683 iteration 1844 : loss : 0.039682, loss_ce: 0.017365
2022-01-20 21:13:32,280 iteration 1845 : loss : 0.035528, loss_ce: 0.013794
2022-01-20 21:13:32,893 iteration 1846 : loss : 0.042011, loss_ce: 0.014399
2022-01-20 21:13:33,401 iteration 1847 : loss : 0.030068, loss_ce: 0.011911
2022-01-20 21:13:34,005 iteration 1848 : loss : 0.032179, loss_ce: 0.012518
2022-01-20 21:13:34,602 iteration 1849 : loss : 0.041144, loss_ce: 0.014900
2022-01-20 21:13:35,208 iteration 1850 : loss : 0.064704, loss_ce: 0.023577
2022-01-20 21:13:35,842 iteration 1851 : loss : 0.035937, loss_ce: 0.015634
2022-01-20 21:13:36,348 iteration 1852 : loss : 0.039742, loss_ce: 0.019474
2022-01-20 21:13:36,973 iteration 1853 : loss : 0.032459, loss_ce: 0.014711
 27%|████████▍                      | 109/400 [20:01<51:28, 10.61s/it]2022-01-20 21:13:37,635 iteration 1854 : loss : 0.033951, loss_ce: 0.012030
2022-01-20 21:13:38,287 iteration 1855 : loss : 0.038213, loss_ce: 0.014211
2022-01-20 21:13:38,791 iteration 1856 : loss : 0.035279, loss_ce: 0.016628
2022-01-20 21:13:39,299 iteration 1857 : loss : 0.028241, loss_ce: 0.012799
2022-01-20 21:13:39,840 iteration 1858 : loss : 0.025476, loss_ce: 0.012013
2022-01-20 21:13:40,452 iteration 1859 : loss : 0.035985, loss_ce: 0.014771
2022-01-20 21:13:41,094 iteration 1860 : loss : 0.052722, loss_ce: 0.019506
2022-01-20 21:13:41,707 iteration 1861 : loss : 0.034666, loss_ce: 0.015909
2022-01-20 21:13:42,338 iteration 1862 : loss : 0.029360, loss_ce: 0.014350
2022-01-20 21:13:42,977 iteration 1863 : loss : 0.044615, loss_ce: 0.015102
2022-01-20 21:13:43,603 iteration 1864 : loss : 0.032484, loss_ce: 0.012688
2022-01-20 21:13:44,212 iteration 1865 : loss : 0.051838, loss_ce: 0.015580
2022-01-20 21:13:44,822 iteration 1866 : loss : 0.029360, loss_ce: 0.011246
2022-01-20 21:13:45,319 iteration 1867 : loss : 0.028228, loss_ce: 0.008856
2022-01-20 21:13:45,879 iteration 1868 : loss : 0.031114, loss_ce: 0.011142
2022-01-20 21:13:46,435 iteration 1869 : loss : 0.033158, loss_ce: 0.016572
2022-01-20 21:13:46,435 Training Data Eval:
2022-01-20 21:13:49,130   Average segmentation loss on training set: 0.0304
2022-01-20 21:13:49,130 Validation Data Eval:
2022-01-20 21:13:50,011   Average segmentation loss on validation set: 0.1344
2022-01-20 21:13:50,619 iteration 1870 : loss : 0.049775, loss_ce: 0.025035
 28%|████████▌                      | 110/400 [20:15<55:42, 11.52s/it]2022-01-20 21:13:51,309 iteration 1871 : loss : 0.033477, loss_ce: 0.010154
2022-01-20 21:13:51,942 iteration 1872 : loss : 0.032908, loss_ce: 0.011949
2022-01-20 21:13:52,592 iteration 1873 : loss : 0.039640, loss_ce: 0.012187
2022-01-20 21:13:53,219 iteration 1874 : loss : 0.032390, loss_ce: 0.011435
2022-01-20 21:13:53,746 iteration 1875 : loss : 0.026515, loss_ce: 0.011483
2022-01-20 21:13:54,256 iteration 1876 : loss : 0.030538, loss_ce: 0.014277
2022-01-20 21:13:54,895 iteration 1877 : loss : 0.023997, loss_ce: 0.008005
2022-01-20 21:13:55,524 iteration 1878 : loss : 0.043158, loss_ce: 0.021607
2022-01-20 21:13:56,132 iteration 1879 : loss : 0.034665, loss_ce: 0.012007
2022-01-20 21:13:56,768 iteration 1880 : loss : 0.049373, loss_ce: 0.022493
2022-01-20 21:13:57,368 iteration 1881 : loss : 0.050730, loss_ce: 0.022757
2022-01-20 21:13:58,041 iteration 1882 : loss : 0.057125, loss_ce: 0.019561
2022-01-20 21:13:58,661 iteration 1883 : loss : 0.024860, loss_ce: 0.009048
2022-01-20 21:13:59,221 iteration 1884 : loss : 0.031394, loss_ce: 0.013010
2022-01-20 21:13:59,743 iteration 1885 : loss : 0.023673, loss_ce: 0.009897
2022-01-20 21:14:00,358 iteration 1886 : loss : 0.049232, loss_ce: 0.020408
2022-01-20 21:14:00,976 iteration 1887 : loss : 0.049219, loss_ce: 0.022050
 28%|████████▌                      | 111/400 [20:25<53:48, 11.17s/it]2022-01-20 21:14:01,736 iteration 1888 : loss : 0.073341, loss_ce: 0.025677
2022-01-20 21:14:02,287 iteration 1889 : loss : 0.040825, loss_ce: 0.013797
2022-01-20 21:14:02,818 iteration 1890 : loss : 0.032148, loss_ce: 0.013928
2022-01-20 21:14:03,362 iteration 1891 : loss : 0.031966, loss_ce: 0.011653
2022-01-20 21:14:03,945 iteration 1892 : loss : 0.032269, loss_ce: 0.014734
2022-01-20 21:14:04,560 iteration 1893 : loss : 0.037152, loss_ce: 0.011582
2022-01-20 21:14:05,148 iteration 1894 : loss : 0.051305, loss_ce: 0.026657
2022-01-20 21:14:05,676 iteration 1895 : loss : 0.028377, loss_ce: 0.011540
2022-01-20 21:14:06,335 iteration 1896 : loss : 0.043636, loss_ce: 0.017199
2022-01-20 21:14:06,957 iteration 1897 : loss : 0.046941, loss_ce: 0.018496
2022-01-20 21:14:07,637 iteration 1898 : loss : 0.032014, loss_ce: 0.013959
2022-01-20 21:14:08,234 iteration 1899 : loss : 0.031820, loss_ce: 0.010786
2022-01-20 21:14:08,785 iteration 1900 : loss : 0.039649, loss_ce: 0.016499
2022-01-20 21:14:09,318 iteration 1901 : loss : 0.028421, loss_ce: 0.010576
2022-01-20 21:14:09,914 iteration 1902 : loss : 0.033385, loss_ce: 0.013024
2022-01-20 21:14:10,556 iteration 1903 : loss : 0.040411, loss_ce: 0.015679
2022-01-20 21:14:11,217 iteration 1904 : loss : 0.034795, loss_ce: 0.014321
 28%|████████▋                      | 112/400 [20:36<52:17, 10.89s/it]2022-01-20 21:14:11,796 iteration 1905 : loss : 0.029336, loss_ce: 0.012737
2022-01-20 21:14:12,432 iteration 1906 : loss : 0.030435, loss_ce: 0.010441
2022-01-20 21:14:13,086 iteration 1907 : loss : 0.030615, loss_ce: 0.013809
2022-01-20 21:14:13,842 iteration 1908 : loss : 0.032648, loss_ce: 0.014213
2022-01-20 21:14:14,367 iteration 1909 : loss : 0.028296, loss_ce: 0.012203
2022-01-20 21:14:14,948 iteration 1910 : loss : 0.033190, loss_ce: 0.013399
2022-01-20 21:14:15,584 iteration 1911 : loss : 0.029742, loss_ce: 0.014549
2022-01-20 21:14:16,295 iteration 1912 : loss : 0.040782, loss_ce: 0.015777
2022-01-20 21:14:16,935 iteration 1913 : loss : 0.050540, loss_ce: 0.026222
2022-01-20 21:14:17,638 iteration 1914 : loss : 0.038973, loss_ce: 0.016211
2022-01-20 21:14:18,253 iteration 1915 : loss : 0.029191, loss_ce: 0.010251
2022-01-20 21:14:18,833 iteration 1916 : loss : 0.050752, loss_ce: 0.018708
2022-01-20 21:14:19,416 iteration 1917 : loss : 0.030389, loss_ce: 0.012798
2022-01-20 21:14:20,065 iteration 1918 : loss : 0.039933, loss_ce: 0.019648
2022-01-20 21:14:20,628 iteration 1919 : loss : 0.035548, loss_ce: 0.011201
2022-01-20 21:14:21,148 iteration 1920 : loss : 0.030147, loss_ce: 0.013537
2022-01-20 21:14:21,817 iteration 1921 : loss : 0.045395, loss_ce: 0.017798
 28%|████████▊                      | 113/400 [20:46<51:41, 10.81s/it]2022-01-20 21:14:22,521 iteration 1922 : loss : 0.047856, loss_ce: 0.017843
2022-01-20 21:14:23,079 iteration 1923 : loss : 0.024203, loss_ce: 0.010002
2022-01-20 21:14:23,741 iteration 1924 : loss : 0.047456, loss_ce: 0.014830
2022-01-20 21:14:24,284 iteration 1925 : loss : 0.054104, loss_ce: 0.016542
2022-01-20 21:14:24,941 iteration 1926 : loss : 0.049366, loss_ce: 0.019818
2022-01-20 21:14:25,611 iteration 1927 : loss : 0.028940, loss_ce: 0.014040
2022-01-20 21:14:26,168 iteration 1928 : loss : 0.037587, loss_ce: 0.011818
2022-01-20 21:14:26,905 iteration 1929 : loss : 0.058183, loss_ce: 0.029655
2022-01-20 21:14:27,508 iteration 1930 : loss : 0.042165, loss_ce: 0.018333
2022-01-20 21:14:28,169 iteration 1931 : loss : 0.043102, loss_ce: 0.015764
2022-01-20 21:14:28,798 iteration 1932 : loss : 0.061229, loss_ce: 0.018536
2022-01-20 21:14:29,429 iteration 1933 : loss : 0.039965, loss_ce: 0.015010
2022-01-20 21:14:30,020 iteration 1934 : loss : 0.042531, loss_ce: 0.013359
2022-01-20 21:14:30,627 iteration 1935 : loss : 0.034038, loss_ce: 0.013943
2022-01-20 21:14:31,209 iteration 1936 : loss : 0.030869, loss_ce: 0.012758
2022-01-20 21:14:31,753 iteration 1937 : loss : 0.037705, loss_ce: 0.015093
2022-01-20 21:14:32,376 iteration 1938 : loss : 0.035390, loss_ce: 0.015386
 28%|████████▊                      | 114/400 [20:57<51:09, 10.73s/it]2022-01-20 21:14:33,049 iteration 1939 : loss : 0.044711, loss_ce: 0.019401
2022-01-20 21:14:33,598 iteration 1940 : loss : 0.030787, loss_ce: 0.014486
2022-01-20 21:14:34,205 iteration 1941 : loss : 0.035821, loss_ce: 0.014455
2022-01-20 21:14:34,831 iteration 1942 : loss : 0.039057, loss_ce: 0.014591
2022-01-20 21:14:35,430 iteration 1943 : loss : 0.038131, loss_ce: 0.013348
2022-01-20 21:14:36,044 iteration 1944 : loss : 0.033016, loss_ce: 0.011916
2022-01-20 21:14:36,663 iteration 1945 : loss : 0.048974, loss_ce: 0.018503
2022-01-20 21:14:37,232 iteration 1946 : loss : 0.035905, loss_ce: 0.010338
2022-01-20 21:14:37,815 iteration 1947 : loss : 0.029883, loss_ce: 0.008769
2022-01-20 21:14:38,434 iteration 1948 : loss : 0.042416, loss_ce: 0.018786
2022-01-20 21:14:38,989 iteration 1949 : loss : 0.033408, loss_ce: 0.013416
2022-01-20 21:14:39,627 iteration 1950 : loss : 0.046668, loss_ce: 0.016675
2022-01-20 21:14:40,253 iteration 1951 : loss : 0.028708, loss_ce: 0.011671
2022-01-20 21:14:40,860 iteration 1952 : loss : 0.035831, loss_ce: 0.015202
2022-01-20 21:14:41,384 iteration 1953 : loss : 0.041249, loss_ce: 0.023773
2022-01-20 21:14:42,004 iteration 1954 : loss : 0.029617, loss_ce: 0.012193
2022-01-20 21:14:42,004 Training Data Eval:
2022-01-20 21:14:44,694   Average segmentation loss on training set: 0.0257
2022-01-20 21:14:44,695 Validation Data Eval:
2022-01-20 21:14:45,573   Average segmentation loss on validation set: 0.0794
2022-01-20 21:14:46,203 iteration 1955 : loss : 0.031724, loss_ce: 0.012994
 29%|████████▉                      | 115/400 [21:11<55:23, 11.66s/it]2022-01-20 21:14:46,844 iteration 1956 : loss : 0.041883, loss_ce: 0.016935
2022-01-20 21:14:47,487 iteration 1957 : loss : 0.042742, loss_ce: 0.022401
2022-01-20 21:14:48,076 iteration 1958 : loss : 0.044355, loss_ce: 0.014638
2022-01-20 21:14:48,651 iteration 1959 : loss : 0.036614, loss_ce: 0.011420
2022-01-20 21:14:49,160 iteration 1960 : loss : 0.032657, loss_ce: 0.013343
2022-01-20 21:14:49,642 iteration 1961 : loss : 0.031120, loss_ce: 0.013514
2022-01-20 21:14:50,283 iteration 1962 : loss : 0.029561, loss_ce: 0.013363
2022-01-20 21:14:50,824 iteration 1963 : loss : 0.029177, loss_ce: 0.010622
2022-01-20 21:14:51,451 iteration 1964 : loss : 0.048645, loss_ce: 0.013750
2022-01-20 21:14:51,959 iteration 1965 : loss : 0.026871, loss_ce: 0.012685
2022-01-20 21:14:52,544 iteration 1966 : loss : 0.028830, loss_ce: 0.011294
2022-01-20 21:14:53,242 iteration 1967 : loss : 0.040116, loss_ce: 0.015492
2022-01-20 21:14:54,007 iteration 1968 : loss : 0.066613, loss_ce: 0.034050
2022-01-20 21:14:54,661 iteration 1969 : loss : 0.042965, loss_ce: 0.016296
2022-01-20 21:14:55,193 iteration 1970 : loss : 0.029496, loss_ce: 0.012293
2022-01-20 21:14:55,797 iteration 1971 : loss : 0.029517, loss_ce: 0.010888
2022-01-20 21:14:56,400 iteration 1972 : loss : 0.039682, loss_ce: 0.012320
 29%|████████▉                      | 116/400 [21:21<53:07, 11.22s/it]2022-01-20 21:14:56,985 iteration 1973 : loss : 0.030724, loss_ce: 0.013752
2022-01-20 21:14:57,536 iteration 1974 : loss : 0.033300, loss_ce: 0.013198
2022-01-20 21:14:58,154 iteration 1975 : loss : 0.037939, loss_ce: 0.013993
2022-01-20 21:14:58,718 iteration 1976 : loss : 0.045488, loss_ce: 0.024491
2022-01-20 21:14:59,376 iteration 1977 : loss : 0.031809, loss_ce: 0.011960
2022-01-20 21:15:00,050 iteration 1978 : loss : 0.035464, loss_ce: 0.011954
2022-01-20 21:15:00,591 iteration 1979 : loss : 0.028386, loss_ce: 0.012047
2022-01-20 21:15:01,137 iteration 1980 : loss : 0.031704, loss_ce: 0.011626
2022-01-20 21:15:01,705 iteration 1981 : loss : 0.031874, loss_ce: 0.014967
2022-01-20 21:15:02,349 iteration 1982 : loss : 0.034208, loss_ce: 0.013045
2022-01-20 21:15:02,880 iteration 1983 : loss : 0.040189, loss_ce: 0.013489
2022-01-20 21:15:03,530 iteration 1984 : loss : 0.047654, loss_ce: 0.018745
2022-01-20 21:15:04,129 iteration 1985 : loss : 0.047608, loss_ce: 0.018937
2022-01-20 21:15:04,779 iteration 1986 : loss : 0.037097, loss_ce: 0.011741
2022-01-20 21:15:05,347 iteration 1987 : loss : 0.029698, loss_ce: 0.011100
2022-01-20 21:15:05,864 iteration 1988 : loss : 0.029685, loss_ce: 0.013365
2022-01-20 21:15:06,450 iteration 1989 : loss : 0.048000, loss_ce: 0.013943
 29%|█████████                      | 117/400 [21:31<51:16, 10.87s/it]2022-01-20 21:15:07,094 iteration 1990 : loss : 0.041891, loss_ce: 0.010973
2022-01-20 21:15:07,618 iteration 1991 : loss : 0.029070, loss_ce: 0.014302
2022-01-20 21:15:08,246 iteration 1992 : loss : 0.032559, loss_ce: 0.011579
2022-01-20 21:15:08,871 iteration 1993 : loss : 0.034764, loss_ce: 0.012590
2022-01-20 21:15:09,536 iteration 1994 : loss : 0.043576, loss_ce: 0.017505
2022-01-20 21:15:10,113 iteration 1995 : loss : 0.032939, loss_ce: 0.013468
2022-01-20 21:15:10,750 iteration 1996 : loss : 0.033675, loss_ce: 0.013629
2022-01-20 21:15:11,300 iteration 1997 : loss : 0.029085, loss_ce: 0.012270
2022-01-20 21:15:11,910 iteration 1998 : loss : 0.033733, loss_ce: 0.014548
2022-01-20 21:15:12,536 iteration 1999 : loss : 0.035260, loss_ce: 0.013481
2022-01-20 21:15:13,135 iteration 2000 : loss : 0.034841, loss_ce: 0.016007
2022-01-20 21:15:13,687 iteration 2001 : loss : 0.046598, loss_ce: 0.018990
2022-01-20 21:15:14,352 iteration 2002 : loss : 0.030901, loss_ce: 0.012555
2022-01-20 21:15:14,894 iteration 2003 : loss : 0.045241, loss_ce: 0.015685
2022-01-20 21:15:15,513 iteration 2004 : loss : 0.032252, loss_ce: 0.016003
2022-01-20 21:15:16,066 iteration 2005 : loss : 0.033728, loss_ce: 0.015540
2022-01-20 21:15:16,648 iteration 2006 : loss : 0.039823, loss_ce: 0.014080
 30%|█████████▏                     | 118/400 [21:41<50:07, 10.67s/it]2022-01-20 21:15:17,356 iteration 2007 : loss : 0.053517, loss_ce: 0.017718
2022-01-20 21:15:17,979 iteration 2008 : loss : 0.034040, loss_ce: 0.016200
2022-01-20 21:15:18,533 iteration 2009 : loss : 0.032141, loss_ce: 0.014753
2022-01-20 21:15:19,134 iteration 2010 : loss : 0.032724, loss_ce: 0.013868
2022-01-20 21:15:19,668 iteration 2011 : loss : 0.045623, loss_ce: 0.016179
2022-01-20 21:15:20,185 iteration 2012 : loss : 0.024403, loss_ce: 0.009333
2022-01-20 21:15:20,736 iteration 2013 : loss : 0.038172, loss_ce: 0.020097
2022-01-20 21:15:21,344 iteration 2014 : loss : 0.024223, loss_ce: 0.010829
2022-01-20 21:15:21,973 iteration 2015 : loss : 0.036767, loss_ce: 0.011360
2022-01-20 21:15:22,629 iteration 2016 : loss : 0.036907, loss_ce: 0.015996
2022-01-20 21:15:23,246 iteration 2017 : loss : 0.036682, loss_ce: 0.014017
2022-01-20 21:15:23,766 iteration 2018 : loss : 0.036812, loss_ce: 0.012606
2022-01-20 21:15:24,368 iteration 2019 : loss : 0.034928, loss_ce: 0.014883
2022-01-20 21:15:24,958 iteration 2020 : loss : 0.035708, loss_ce: 0.013524
2022-01-20 21:15:25,541 iteration 2021 : loss : 0.026819, loss_ce: 0.010825
2022-01-20 21:15:26,137 iteration 2022 : loss : 0.032398, loss_ce: 0.011613
2022-01-20 21:15:26,744 iteration 2023 : loss : 0.031278, loss_ce: 0.011857
 30%|█████████▏                     | 119/400 [21:51<49:09, 10.50s/it]2022-01-20 21:15:27,408 iteration 2024 : loss : 0.045632, loss_ce: 0.020746
2022-01-20 21:15:28,170 iteration 2025 : loss : 0.082568, loss_ce: 0.032471
2022-01-20 21:15:28,741 iteration 2026 : loss : 0.032900, loss_ce: 0.011217
2022-01-20 21:15:29,377 iteration 2027 : loss : 0.026135, loss_ce: 0.008381
2022-01-20 21:15:29,871 iteration 2028 : loss : 0.029211, loss_ce: 0.012806
2022-01-20 21:15:30,397 iteration 2029 : loss : 0.037085, loss_ce: 0.010804
2022-01-20 21:15:31,010 iteration 2030 : loss : 0.032311, loss_ce: 0.011694
2022-01-20 21:15:31,632 iteration 2031 : loss : 0.036138, loss_ce: 0.014049
2022-01-20 21:15:32,240 iteration 2032 : loss : 0.035792, loss_ce: 0.016549
2022-01-20 21:15:32,733 iteration 2033 : loss : 0.025246, loss_ce: 0.010677
2022-01-20 21:15:33,285 iteration 2034 : loss : 0.025889, loss_ce: 0.008337
2022-01-20 21:15:33,909 iteration 2035 : loss : 0.044600, loss_ce: 0.016014
2022-01-20 21:15:34,474 iteration 2036 : loss : 0.038842, loss_ce: 0.017621
2022-01-20 21:15:35,016 iteration 2037 : loss : 0.029924, loss_ce: 0.012158
2022-01-20 21:15:35,707 iteration 2038 : loss : 0.061640, loss_ce: 0.018941
2022-01-20 21:15:36,342 iteration 2039 : loss : 0.038610, loss_ce: 0.013504
2022-01-20 21:15:36,343 Training Data Eval:
2022-01-20 21:15:39,033   Average segmentation loss on training set: 0.0246
2022-01-20 21:15:39,034 Validation Data Eval:
2022-01-20 21:15:39,906   Average segmentation loss on validation set: 0.0832
2022-01-20 21:15:40,559 iteration 2040 : loss : 0.037142, loss_ce: 0.016958
 30%|█████████▎                     | 120/400 [22:05<53:37, 11.49s/it]2022-01-20 21:15:41,163 iteration 2041 : loss : 0.028800, loss_ce: 0.013748
2022-01-20 21:15:41,782 iteration 2042 : loss : 0.038517, loss_ce: 0.015039
2022-01-20 21:15:42,387 iteration 2043 : loss : 0.035670, loss_ce: 0.011496
2022-01-20 21:15:42,959 iteration 2044 : loss : 0.031372, loss_ce: 0.015855
2022-01-20 21:15:43,648 iteration 2045 : loss : 0.043282, loss_ce: 0.017291
2022-01-20 21:15:44,255 iteration 2046 : loss : 0.039343, loss_ce: 0.010615
2022-01-20 21:15:44,818 iteration 2047 : loss : 0.029304, loss_ce: 0.011352
2022-01-20 21:15:45,346 iteration 2048 : loss : 0.031587, loss_ce: 0.012221
2022-01-20 21:15:45,990 iteration 2049 : loss : 0.051116, loss_ce: 0.024514
2022-01-20 21:15:46,626 iteration 2050 : loss : 0.027067, loss_ce: 0.008038
2022-01-20 21:15:47,192 iteration 2051 : loss : 0.033201, loss_ce: 0.016696
2022-01-20 21:15:47,843 iteration 2052 : loss : 0.030727, loss_ce: 0.011724
2022-01-20 21:15:48,454 iteration 2053 : loss : 0.037516, loss_ce: 0.015885
2022-01-20 21:15:49,047 iteration 2054 : loss : 0.034982, loss_ce: 0.012941
2022-01-20 21:15:49,670 iteration 2055 : loss : 0.044312, loss_ce: 0.016262
2022-01-20 21:15:50,239 iteration 2056 : loss : 0.027855, loss_ce: 0.010462
2022-01-20 21:15:50,804 iteration 2057 : loss : 0.025734, loss_ce: 0.010974
 30%|█████████▍                     | 121/400 [22:15<51:41, 11.12s/it]2022-01-20 21:15:51,435 iteration 2058 : loss : 0.032601, loss_ce: 0.016866
2022-01-20 21:15:52,080 iteration 2059 : loss : 0.041880, loss_ce: 0.015627
2022-01-20 21:15:52,757 iteration 2060 : loss : 0.033373, loss_ce: 0.011714
2022-01-20 21:15:53,356 iteration 2061 : loss : 0.027627, loss_ce: 0.012895
2022-01-20 21:15:53,903 iteration 2062 : loss : 0.048075, loss_ce: 0.019078
2022-01-20 21:15:54,667 iteration 2063 : loss : 0.046814, loss_ce: 0.020343
2022-01-20 21:15:55,282 iteration 2064 : loss : 0.032234, loss_ce: 0.012330
2022-01-20 21:15:55,962 iteration 2065 : loss : 0.039805, loss_ce: 0.013887
2022-01-20 21:15:56,556 iteration 2066 : loss : 0.032935, loss_ce: 0.013283
2022-01-20 21:15:57,196 iteration 2067 : loss : 0.040023, loss_ce: 0.014558
2022-01-20 21:15:57,746 iteration 2068 : loss : 0.031089, loss_ce: 0.012809
2022-01-20 21:15:58,352 iteration 2069 : loss : 0.041918, loss_ce: 0.020309
2022-01-20 21:15:59,001 iteration 2070 : loss : 0.035147, loss_ce: 0.016843
2022-01-20 21:15:59,554 iteration 2071 : loss : 0.023143, loss_ce: 0.009166
2022-01-20 21:16:00,106 iteration 2072 : loss : 0.030194, loss_ce: 0.013678
2022-01-20 21:16:00,749 iteration 2073 : loss : 0.031268, loss_ce: 0.013364
2022-01-20 21:16:01,277 iteration 2074 : loss : 0.029089, loss_ce: 0.008582
 30%|█████████▍                     | 122/400 [22:26<50:36, 10.92s/it]2022-01-20 21:16:01,909 iteration 2075 : loss : 0.027418, loss_ce: 0.013790
2022-01-20 21:16:02,543 iteration 2076 : loss : 0.033666, loss_ce: 0.014109
2022-01-20 21:16:03,172 iteration 2077 : loss : 0.034198, loss_ce: 0.017300
2022-01-20 21:16:03,826 iteration 2078 : loss : 0.037928, loss_ce: 0.013182
2022-01-20 21:16:04,461 iteration 2079 : loss : 0.037167, loss_ce: 0.014146
2022-01-20 21:16:05,023 iteration 2080 : loss : 0.036299, loss_ce: 0.011338
2022-01-20 21:16:05,556 iteration 2081 : loss : 0.032428, loss_ce: 0.011893
2022-01-20 21:16:06,152 iteration 2082 : loss : 0.037171, loss_ce: 0.010915
2022-01-20 21:16:06,723 iteration 2083 : loss : 0.026966, loss_ce: 0.009818
2022-01-20 21:16:07,252 iteration 2084 : loss : 0.032348, loss_ce: 0.015235
2022-01-20 21:16:07,865 iteration 2085 : loss : 0.080261, loss_ce: 0.017785
2022-01-20 21:16:08,562 iteration 2086 : loss : 0.031170, loss_ce: 0.010623
2022-01-20 21:16:09,084 iteration 2087 : loss : 0.029960, loss_ce: 0.011245
2022-01-20 21:16:09,660 iteration 2088 : loss : 0.029518, loss_ce: 0.011380
2022-01-20 21:16:10,277 iteration 2089 : loss : 0.026794, loss_ce: 0.010954
2022-01-20 21:16:10,884 iteration 2090 : loss : 0.036630, loss_ce: 0.015812
2022-01-20 21:16:11,577 iteration 2091 : loss : 0.039212, loss_ce: 0.016820
 31%|█████████▌                     | 123/400 [22:36<49:34, 10.74s/it]2022-01-20 21:16:12,202 iteration 2092 : loss : 0.048691, loss_ce: 0.015222
2022-01-20 21:16:12,736 iteration 2093 : loss : 0.022505, loss_ce: 0.009056
2022-01-20 21:16:13,371 iteration 2094 : loss : 0.029615, loss_ce: 0.010593
2022-01-20 21:16:14,152 iteration 2095 : loss : 0.052157, loss_ce: 0.018076
2022-01-20 21:16:14,740 iteration 2096 : loss : 0.031047, loss_ce: 0.012494
2022-01-20 21:16:15,321 iteration 2097 : loss : 0.050293, loss_ce: 0.013819
2022-01-20 21:16:15,851 iteration 2098 : loss : 0.028329, loss_ce: 0.010712
2022-01-20 21:16:16,425 iteration 2099 : loss : 0.025579, loss_ce: 0.010659
2022-01-20 21:16:17,063 iteration 2100 : loss : 0.038853, loss_ce: 0.014268
2022-01-20 21:16:17,567 iteration 2101 : loss : 0.040114, loss_ce: 0.014394
2022-01-20 21:16:18,203 iteration 2102 : loss : 0.034022, loss_ce: 0.015163
2022-01-20 21:16:18,754 iteration 2103 : loss : 0.026480, loss_ce: 0.013460
2022-01-20 21:16:19,265 iteration 2104 : loss : 0.027173, loss_ce: 0.009710
2022-01-20 21:16:19,864 iteration 2105 : loss : 0.035595, loss_ce: 0.014869
2022-01-20 21:16:20,469 iteration 2106 : loss : 0.036561, loss_ce: 0.013698
2022-01-20 21:16:21,014 iteration 2107 : loss : 0.031460, loss_ce: 0.011411
2022-01-20 21:16:21,540 iteration 2108 : loss : 0.038910, loss_ce: 0.015850
 31%|█████████▌                     | 124/400 [22:46<48:19, 10.51s/it]2022-01-20 21:16:22,180 iteration 2109 : loss : 0.055890, loss_ce: 0.017503
2022-01-20 21:16:22,798 iteration 2110 : loss : 0.042728, loss_ce: 0.020352
2022-01-20 21:16:23,456 iteration 2111 : loss : 0.038673, loss_ce: 0.013056
2022-01-20 21:16:24,168 iteration 2112 : loss : 0.042558, loss_ce: 0.018280
2022-01-20 21:16:24,822 iteration 2113 : loss : 0.036240, loss_ce: 0.014534
2022-01-20 21:16:25,462 iteration 2114 : loss : 0.037825, loss_ce: 0.014562
2022-01-20 21:16:26,022 iteration 2115 : loss : 0.032038, loss_ce: 0.009873
2022-01-20 21:16:26,579 iteration 2116 : loss : 0.030045, loss_ce: 0.009781
2022-01-20 21:16:27,281 iteration 2117 : loss : 0.054143, loss_ce: 0.015106
2022-01-20 21:16:27,896 iteration 2118 : loss : 0.033454, loss_ce: 0.013796
2022-01-20 21:16:28,615 iteration 2119 : loss : 0.034109, loss_ce: 0.013609
2022-01-20 21:16:29,325 iteration 2120 : loss : 0.042203, loss_ce: 0.023071
2022-01-20 21:16:29,996 iteration 2121 : loss : 0.039274, loss_ce: 0.019544
2022-01-20 21:16:30,654 iteration 2122 : loss : 0.044609, loss_ce: 0.025760
2022-01-20 21:16:31,192 iteration 2123 : loss : 0.038514, loss_ce: 0.012159
2022-01-20 21:16:31,859 iteration 2124 : loss : 0.040211, loss_ce: 0.016955
2022-01-20 21:16:31,859 Training Data Eval:
2022-01-20 21:16:34,557   Average segmentation loss on training set: 0.0228
2022-01-20 21:16:34,557 Validation Data Eval:
2022-01-20 21:16:35,439   Average segmentation loss on validation set: 0.0812
2022-01-20 21:16:36,007 iteration 2125 : loss : 0.025883, loss_ce: 0.012795
 31%|█████████▋                     | 125/400 [23:00<53:36, 11.70s/it]2022-01-20 21:16:36,690 iteration 2126 : loss : 0.062267, loss_ce: 0.018521
2022-01-20 21:16:37,223 iteration 2127 : loss : 0.024580, loss_ce: 0.010219
2022-01-20 21:16:37,750 iteration 2128 : loss : 0.024158, loss_ce: 0.010549
2022-01-20 21:16:38,419 iteration 2129 : loss : 0.033437, loss_ce: 0.013596
2022-01-20 21:16:39,005 iteration 2130 : loss : 0.032908, loss_ce: 0.013038
2022-01-20 21:16:39,549 iteration 2131 : loss : 0.031890, loss_ce: 0.014959
2022-01-20 21:16:40,181 iteration 2132 : loss : 0.040224, loss_ce: 0.010807
2022-01-20 21:16:40,776 iteration 2133 : loss : 0.026702, loss_ce: 0.010832
2022-01-20 21:16:41,455 iteration 2134 : loss : 0.045458, loss_ce: 0.017136
2022-01-20 21:16:41,986 iteration 2135 : loss : 0.031254, loss_ce: 0.009481
2022-01-20 21:16:42,644 iteration 2136 : loss : 0.039069, loss_ce: 0.015872
2022-01-20 21:16:43,230 iteration 2137 : loss : 0.030888, loss_ce: 0.012289
2022-01-20 21:16:43,909 iteration 2138 : loss : 0.038141, loss_ce: 0.011627
2022-01-20 21:16:44,491 iteration 2139 : loss : 0.036000, loss_ce: 0.018511
2022-01-20 21:16:45,139 iteration 2140 : loss : 0.042938, loss_ce: 0.025610
2022-01-20 21:16:45,759 iteration 2141 : loss : 0.034146, loss_ce: 0.011390
2022-01-20 21:16:46,388 iteration 2142 : loss : 0.041461, loss_ce: 0.013576
 32%|█████████▊                     | 126/400 [23:11<51:36, 11.30s/it]2022-01-20 21:16:47,037 iteration 2143 : loss : 0.041777, loss_ce: 0.020340
2022-01-20 21:16:47,653 iteration 2144 : loss : 0.032487, loss_ce: 0.013737
2022-01-20 21:16:48,251 iteration 2145 : loss : 0.035340, loss_ce: 0.013449
2022-01-20 21:16:48,813 iteration 2146 : loss : 0.042686, loss_ce: 0.016651
2022-01-20 21:16:49,355 iteration 2147 : loss : 0.024771, loss_ce: 0.009954
2022-01-20 21:16:49,941 iteration 2148 : loss : 0.027134, loss_ce: 0.010715
2022-01-20 21:16:50,605 iteration 2149 : loss : 0.071139, loss_ce: 0.028216
2022-01-20 21:16:51,171 iteration 2150 : loss : 0.026060, loss_ce: 0.011119
2022-01-20 21:16:51,761 iteration 2151 : loss : 0.032569, loss_ce: 0.011987
2022-01-20 21:16:52,299 iteration 2152 : loss : 0.030805, loss_ce: 0.015015
2022-01-20 21:16:52,882 iteration 2153 : loss : 0.038379, loss_ce: 0.013873
2022-01-20 21:16:53,467 iteration 2154 : loss : 0.027929, loss_ce: 0.010284
2022-01-20 21:16:54,087 iteration 2155 : loss : 0.035957, loss_ce: 0.018877
2022-01-20 21:16:54,621 iteration 2156 : loss : 0.027395, loss_ce: 0.011224
2022-01-20 21:16:55,310 iteration 2157 : loss : 0.043957, loss_ce: 0.018326
2022-01-20 21:16:55,969 iteration 2158 : loss : 0.037034, loss_ce: 0.012014
2022-01-20 21:16:56,598 iteration 2159 : loss : 0.033503, loss_ce: 0.012957
 32%|█████████▊                     | 127/400 [23:21<49:54, 10.97s/it]2022-01-20 21:16:57,247 iteration 2160 : loss : 0.036565, loss_ce: 0.013117
2022-01-20 21:16:57,930 iteration 2161 : loss : 0.059914, loss_ce: 0.029127
2022-01-20 21:16:58,596 iteration 2162 : loss : 0.036437, loss_ce: 0.014968
2022-01-20 21:16:59,140 iteration 2163 : loss : 0.034843, loss_ce: 0.013524
2022-01-20 21:16:59,792 iteration 2164 : loss : 0.034470, loss_ce: 0.012017
2022-01-20 21:17:00,433 iteration 2165 : loss : 0.032058, loss_ce: 0.015755
2022-01-20 21:17:01,061 iteration 2166 : loss : 0.033178, loss_ce: 0.009099
2022-01-20 21:17:01,719 iteration 2167 : loss : 0.030561, loss_ce: 0.013060
2022-01-20 21:17:02,326 iteration 2168 : loss : 0.027170, loss_ce: 0.010706
2022-01-20 21:17:02,932 iteration 2169 : loss : 0.029981, loss_ce: 0.011816
2022-01-20 21:17:03,490 iteration 2170 : loss : 0.042636, loss_ce: 0.019056
2022-01-20 21:17:04,137 iteration 2171 : loss : 0.065189, loss_ce: 0.023497
2022-01-20 21:17:04,847 iteration 2172 : loss : 0.050230, loss_ce: 0.019255
2022-01-20 21:17:05,401 iteration 2173 : loss : 0.033163, loss_ce: 0.011192
2022-01-20 21:17:05,912 iteration 2174 : loss : 0.027122, loss_ce: 0.013186
2022-01-20 21:17:06,453 iteration 2175 : loss : 0.029234, loss_ce: 0.010754
2022-01-20 21:17:07,157 iteration 2176 : loss : 0.036196, loss_ce: 0.013615
 32%|█████████▉                     | 128/400 [23:32<49:11, 10.85s/it]2022-01-20 21:17:07,828 iteration 2177 : loss : 0.034070, loss_ce: 0.011668
2022-01-20 21:17:08,486 iteration 2178 : loss : 0.032278, loss_ce: 0.013079
2022-01-20 21:17:09,064 iteration 2179 : loss : 0.029376, loss_ce: 0.013559
2022-01-20 21:17:09,645 iteration 2180 : loss : 0.028521, loss_ce: 0.010812
2022-01-20 21:17:10,279 iteration 2181 : loss : 0.041947, loss_ce: 0.021658
2022-01-20 21:17:10,862 iteration 2182 : loss : 0.048066, loss_ce: 0.013021
2022-01-20 21:17:11,392 iteration 2183 : loss : 0.028409, loss_ce: 0.012917
2022-01-20 21:17:12,053 iteration 2184 : loss : 0.051863, loss_ce: 0.014475
2022-01-20 21:17:12,603 iteration 2185 : loss : 0.025360, loss_ce: 0.009166
2022-01-20 21:17:13,177 iteration 2186 : loss : 0.035717, loss_ce: 0.013304
2022-01-20 21:17:13,770 iteration 2187 : loss : 0.023268, loss_ce: 0.009049
2022-01-20 21:17:14,330 iteration 2188 : loss : 0.041900, loss_ce: 0.011396
2022-01-20 21:17:14,986 iteration 2189 : loss : 0.045401, loss_ce: 0.016789
2022-01-20 21:17:15,575 iteration 2190 : loss : 0.030803, loss_ce: 0.011798
2022-01-20 21:17:16,192 iteration 2191 : loss : 0.059698, loss_ce: 0.019428
2022-01-20 21:17:16,746 iteration 2192 : loss : 0.032653, loss_ce: 0.010981
2022-01-20 21:17:17,346 iteration 2193 : loss : 0.057326, loss_ce: 0.027847
 32%|█████████▉                     | 129/400 [23:42<48:06, 10.65s/it]2022-01-20 21:17:18,036 iteration 2194 : loss : 0.039477, loss_ce: 0.021731
2022-01-20 21:17:18,611 iteration 2195 : loss : 0.034470, loss_ce: 0.012953
2022-01-20 21:17:19,200 iteration 2196 : loss : 0.031253, loss_ce: 0.012621
2022-01-20 21:17:19,832 iteration 2197 : loss : 0.031017, loss_ce: 0.016805
2022-01-20 21:17:20,460 iteration 2198 : loss : 0.030682, loss_ce: 0.013169
2022-01-20 21:17:21,066 iteration 2199 : loss : 0.038216, loss_ce: 0.016372
2022-01-20 21:17:21,631 iteration 2200 : loss : 0.035456, loss_ce: 0.012140
2022-01-20 21:17:22,182 iteration 2201 : loss : 0.022752, loss_ce: 0.009398
2022-01-20 21:17:22,824 iteration 2202 : loss : 0.068967, loss_ce: 0.017344
2022-01-20 21:17:23,474 iteration 2203 : loss : 0.033358, loss_ce: 0.017095
2022-01-20 21:17:24,034 iteration 2204 : loss : 0.027487, loss_ce: 0.012603
2022-01-20 21:17:24,547 iteration 2205 : loss : 0.025163, loss_ce: 0.010593
2022-01-20 21:17:25,062 iteration 2206 : loss : 0.041269, loss_ce: 0.011880
2022-01-20 21:17:25,615 iteration 2207 : loss : 0.042240, loss_ce: 0.017338
2022-01-20 21:17:26,227 iteration 2208 : loss : 0.049453, loss_ce: 0.013741
2022-01-20 21:17:26,798 iteration 2209 : loss : 0.038328, loss_ce: 0.013519
2022-01-20 21:17:26,799 Training Data Eval:
2022-01-20 21:17:29,487   Average segmentation loss on training set: 0.0274
2022-01-20 21:17:29,487 Validation Data Eval:
2022-01-20 21:17:30,361   Average segmentation loss on validation set: 0.1074
2022-01-20 21:17:30,961 iteration 2210 : loss : 0.038188, loss_ce: 0.013476
 32%|██████████                     | 130/400 [23:55<51:55, 11.54s/it]2022-01-20 21:17:31,627 iteration 2211 : loss : 0.049153, loss_ce: 0.017157
2022-01-20 21:17:32,249 iteration 2212 : loss : 0.041117, loss_ce: 0.018473
2022-01-20 21:17:32,874 iteration 2213 : loss : 0.037087, loss_ce: 0.013936
2022-01-20 21:17:33,497 iteration 2214 : loss : 0.039772, loss_ce: 0.014369
2022-01-20 21:17:34,143 iteration 2215 : loss : 0.044983, loss_ce: 0.019066
2022-01-20 21:17:34,669 iteration 2216 : loss : 0.035785, loss_ce: 0.011138
2022-01-20 21:17:35,322 iteration 2217 : loss : 0.045469, loss_ce: 0.018897
2022-01-20 21:17:35,873 iteration 2218 : loss : 0.029287, loss_ce: 0.010937
2022-01-20 21:17:36,524 iteration 2219 : loss : 0.027417, loss_ce: 0.010478
2022-01-20 21:17:37,026 iteration 2220 : loss : 0.036649, loss_ce: 0.012695
2022-01-20 21:17:37,578 iteration 2221 : loss : 0.030932, loss_ce: 0.011005
2022-01-20 21:17:38,218 iteration 2222 : loss : 0.033260, loss_ce: 0.014061
2022-01-20 21:17:38,830 iteration 2223 : loss : 0.040899, loss_ce: 0.013410
2022-01-20 21:17:39,499 iteration 2224 : loss : 0.032429, loss_ce: 0.014757
2022-01-20 21:17:40,040 iteration 2225 : loss : 0.023033, loss_ce: 0.008938
2022-01-20 21:17:40,715 iteration 2226 : loss : 0.044317, loss_ce: 0.022334
2022-01-20 21:17:41,291 iteration 2227 : loss : 0.027144, loss_ce: 0.011394
 33%|██████████▏                    | 131/400 [24:06<50:06, 11.18s/it]2022-01-20 21:17:41,993 iteration 2228 : loss : 0.027608, loss_ce: 0.012425
2022-01-20 21:17:42,595 iteration 2229 : loss : 0.037279, loss_ce: 0.016028
2022-01-20 21:17:43,244 iteration 2230 : loss : 0.036022, loss_ce: 0.012997
2022-01-20 21:17:43,744 iteration 2231 : loss : 0.018687, loss_ce: 0.007484
2022-01-20 21:17:44,294 iteration 2232 : loss : 0.033658, loss_ce: 0.013058
2022-01-20 21:17:44,857 iteration 2233 : loss : 0.030669, loss_ce: 0.010095
2022-01-20 21:17:45,432 iteration 2234 : loss : 0.039701, loss_ce: 0.013787
2022-01-20 21:17:46,001 iteration 2235 : loss : 0.036949, loss_ce: 0.008293
2022-01-20 21:17:46,730 iteration 2236 : loss : 0.046671, loss_ce: 0.019704
2022-01-20 21:17:47,329 iteration 2237 : loss : 0.025646, loss_ce: 0.011334
2022-01-20 21:17:47,938 iteration 2238 : loss : 0.039569, loss_ce: 0.023161
2022-01-20 21:17:48,541 iteration 2239 : loss : 0.034070, loss_ce: 0.013364
2022-01-20 21:17:49,190 iteration 2240 : loss : 0.032607, loss_ce: 0.012963
2022-01-20 21:17:49,859 iteration 2241 : loss : 0.030734, loss_ce: 0.009738
2022-01-20 21:17:50,514 iteration 2242 : loss : 0.042589, loss_ce: 0.015736
2022-01-20 21:17:51,217 iteration 2243 : loss : 0.031848, loss_ce: 0.009075
2022-01-20 21:17:51,813 iteration 2244 : loss : 0.045201, loss_ce: 0.019141
 33%|██████████▏                    | 132/400 [24:16<49:02, 10.98s/it]2022-01-20 21:17:52,547 iteration 2245 : loss : 0.049461, loss_ce: 0.018608
2022-01-20 21:17:53,115 iteration 2246 : loss : 0.029561, loss_ce: 0.012903
2022-01-20 21:17:53,810 iteration 2247 : loss : 0.059562, loss_ce: 0.017684
2022-01-20 21:17:54,448 iteration 2248 : loss : 0.033669, loss_ce: 0.012597
2022-01-20 21:17:55,066 iteration 2249 : loss : 0.037680, loss_ce: 0.012101
2022-01-20 21:17:55,658 iteration 2250 : loss : 0.050754, loss_ce: 0.018931
2022-01-20 21:17:56,184 iteration 2251 : loss : 0.028804, loss_ce: 0.009965
2022-01-20 21:17:56,886 iteration 2252 : loss : 0.051360, loss_ce: 0.019947
2022-01-20 21:17:57,567 iteration 2253 : loss : 0.036435, loss_ce: 0.016444
2022-01-20 21:17:58,168 iteration 2254 : loss : 0.038045, loss_ce: 0.016534
2022-01-20 21:17:58,738 iteration 2255 : loss : 0.045884, loss_ce: 0.016835
2022-01-20 21:17:59,360 iteration 2256 : loss : 0.026756, loss_ce: 0.011717
2022-01-20 21:17:59,947 iteration 2257 : loss : 0.035372, loss_ce: 0.014480
2022-01-20 21:18:00,480 iteration 2258 : loss : 0.028114, loss_ce: 0.012576
2022-01-20 21:18:01,155 iteration 2259 : loss : 0.024915, loss_ce: 0.009830
2022-01-20 21:18:01,730 iteration 2260 : loss : 0.032656, loss_ce: 0.012238
2022-01-20 21:18:02,357 iteration 2261 : loss : 0.028773, loss_ce: 0.011812
 33%|██████████▎                    | 133/400 [24:27<48:16, 10.85s/it]2022-01-20 21:18:03,033 iteration 2262 : loss : 0.034239, loss_ce: 0.014167
2022-01-20 21:18:03,650 iteration 2263 : loss : 0.030440, loss_ce: 0.012900
2022-01-20 21:18:04,303 iteration 2264 : loss : 0.048233, loss_ce: 0.019973
2022-01-20 21:18:04,905 iteration 2265 : loss : 0.024919, loss_ce: 0.009067
2022-01-20 21:18:05,496 iteration 2266 : loss : 0.035998, loss_ce: 0.010618
2022-01-20 21:18:06,019 iteration 2267 : loss : 0.022290, loss_ce: 0.009228
2022-01-20 21:18:06,591 iteration 2268 : loss : 0.027762, loss_ce: 0.012969
2022-01-20 21:18:07,141 iteration 2269 : loss : 0.030030, loss_ce: 0.014410
2022-01-20 21:18:07,672 iteration 2270 : loss : 0.023274, loss_ce: 0.008338
2022-01-20 21:18:08,252 iteration 2271 : loss : 0.062583, loss_ce: 0.025471
2022-01-20 21:18:08,902 iteration 2272 : loss : 0.033381, loss_ce: 0.015046
2022-01-20 21:18:09,548 iteration 2273 : loss : 0.031395, loss_ce: 0.011767
2022-01-20 21:18:10,146 iteration 2274 : loss : 0.035834, loss_ce: 0.015726
2022-01-20 21:18:10,730 iteration 2275 : loss : 0.048901, loss_ce: 0.016972
2022-01-20 21:18:11,274 iteration 2276 : loss : 0.038923, loss_ce: 0.016456
2022-01-20 21:18:11,860 iteration 2277 : loss : 0.023544, loss_ce: 0.006808
2022-01-20 21:18:12,484 iteration 2278 : loss : 0.031358, loss_ce: 0.011844
 34%|██████████▍                    | 134/400 [24:37<47:08, 10.63s/it]2022-01-20 21:18:13,059 iteration 2279 : loss : 0.031168, loss_ce: 0.011824
2022-01-20 21:18:13,589 iteration 2280 : loss : 0.030411, loss_ce: 0.013852
2022-01-20 21:18:14,177 iteration 2281 : loss : 0.039707, loss_ce: 0.013562
2022-01-20 21:18:14,700 iteration 2282 : loss : 0.039837, loss_ce: 0.015113
2022-01-20 21:18:15,298 iteration 2283 : loss : 0.056727, loss_ce: 0.020213
2022-01-20 21:18:15,814 iteration 2284 : loss : 0.034543, loss_ce: 0.015223
2022-01-20 21:18:16,438 iteration 2285 : loss : 0.033471, loss_ce: 0.013942
2022-01-20 21:18:17,006 iteration 2286 : loss : 0.035785, loss_ce: 0.015095
2022-01-20 21:18:17,587 iteration 2287 : loss : 0.033118, loss_ce: 0.009626
2022-01-20 21:18:18,179 iteration 2288 : loss : 0.062438, loss_ce: 0.016580
2022-01-20 21:18:18,795 iteration 2289 : loss : 0.037152, loss_ce: 0.013381
2022-01-20 21:18:19,403 iteration 2290 : loss : 0.048652, loss_ce: 0.019903
2022-01-20 21:18:20,109 iteration 2291 : loss : 0.043674, loss_ce: 0.017590
2022-01-20 21:18:20,747 iteration 2292 : loss : 0.036804, loss_ce: 0.014466
2022-01-20 21:18:21,359 iteration 2293 : loss : 0.041617, loss_ce: 0.015470
2022-01-20 21:18:21,941 iteration 2294 : loss : 0.043534, loss_ce: 0.020166
2022-01-20 21:18:21,942 Training Data Eval:
2022-01-20 21:18:24,631   Average segmentation loss on training set: 0.0273
2022-01-20 21:18:24,632 Validation Data Eval:
2022-01-20 21:18:25,513   Average segmentation loss on validation set: 0.0796
2022-01-20 21:18:26,100 iteration 2295 : loss : 0.035398, loss_ce: 0.011583
 34%|██████████▍                    | 135/400 [24:50<50:54, 11.53s/it]2022-01-20 21:18:26,674 iteration 2296 : loss : 0.029825, loss_ce: 0.013148
2022-01-20 21:18:27,315 iteration 2297 : loss : 0.028968, loss_ce: 0.009969
2022-01-20 21:18:27,914 iteration 2298 : loss : 0.034020, loss_ce: 0.010655
2022-01-20 21:18:28,548 iteration 2299 : loss : 0.036409, loss_ce: 0.011231
2022-01-20 21:18:29,117 iteration 2300 : loss : 0.023925, loss_ce: 0.009883
2022-01-20 21:18:29,722 iteration 2301 : loss : 0.040190, loss_ce: 0.014139
2022-01-20 21:18:30,369 iteration 2302 : loss : 0.028436, loss_ce: 0.010924
2022-01-20 21:18:31,007 iteration 2303 : loss : 0.038351, loss_ce: 0.013758
2022-01-20 21:18:31,643 iteration 2304 : loss : 0.028408, loss_ce: 0.010873
2022-01-20 21:18:32,234 iteration 2305 : loss : 0.031809, loss_ce: 0.013760
2022-01-20 21:18:32,806 iteration 2306 : loss : 0.036760, loss_ce: 0.015934
2022-01-20 21:18:33,481 iteration 2307 : loss : 0.033397, loss_ce: 0.013893
2022-01-20 21:18:34,044 iteration 2308 : loss : 0.030249, loss_ce: 0.012375
2022-01-20 21:18:34,702 iteration 2309 : loss : 0.031689, loss_ce: 0.013123
2022-01-20 21:18:35,336 iteration 2310 : loss : 0.034213, loss_ce: 0.014192
2022-01-20 21:18:35,894 iteration 2311 : loss : 0.047947, loss_ce: 0.015290
2022-01-20 21:18:36,424 iteration 2312 : loss : 0.027285, loss_ce: 0.009298
 34%|██████████▌                    | 136/400 [25:01<49:08, 11.17s/it]2022-01-20 21:18:37,050 iteration 2313 : loss : 0.049705, loss_ce: 0.019587
2022-01-20 21:18:37,663 iteration 2314 : loss : 0.032495, loss_ce: 0.011376
2022-01-20 21:18:38,356 iteration 2315 : loss : 0.034251, loss_ce: 0.009012
2022-01-20 21:18:38,883 iteration 2316 : loss : 0.028170, loss_ce: 0.010490
2022-01-20 21:18:39,551 iteration 2317 : loss : 0.035624, loss_ce: 0.010269
2022-01-20 21:18:40,174 iteration 2318 : loss : 0.034374, loss_ce: 0.015992
2022-01-20 21:18:40,794 iteration 2319 : loss : 0.033110, loss_ce: 0.013911
2022-01-20 21:18:41,453 iteration 2320 : loss : 0.039511, loss_ce: 0.020849
2022-01-20 21:18:42,007 iteration 2321 : loss : 0.039531, loss_ce: 0.015449
2022-01-20 21:18:42,604 iteration 2322 : loss : 0.047836, loss_ce: 0.026035
2022-01-20 21:18:43,187 iteration 2323 : loss : 0.040434, loss_ce: 0.017020
2022-01-20 21:18:43,809 iteration 2324 : loss : 0.032141, loss_ce: 0.010769
2022-01-20 21:18:44,379 iteration 2325 : loss : 0.028910, loss_ce: 0.011450
2022-01-20 21:18:44,987 iteration 2326 : loss : 0.048401, loss_ce: 0.020217
2022-01-20 21:18:45,567 iteration 2327 : loss : 0.032053, loss_ce: 0.012845
2022-01-20 21:18:46,199 iteration 2328 : loss : 0.036621, loss_ce: 0.020117
2022-01-20 21:18:46,764 iteration 2329 : loss : 0.022883, loss_ce: 0.009701
 34%|██████████▌                    | 137/400 [25:11<47:51, 10.92s/it]2022-01-20 21:18:47,380 iteration 2330 : loss : 0.034961, loss_ce: 0.013843
2022-01-20 21:18:47,977 iteration 2331 : loss : 0.047193, loss_ce: 0.020994
2022-01-20 21:18:48,632 iteration 2332 : loss : 0.045667, loss_ce: 0.019699
2022-01-20 21:18:49,303 iteration 2333 : loss : 0.028313, loss_ce: 0.013349
2022-01-20 21:18:49,888 iteration 2334 : loss : 0.025106, loss_ce: 0.011276
2022-01-20 21:18:50,479 iteration 2335 : loss : 0.041038, loss_ce: 0.012382
2022-01-20 21:18:51,135 iteration 2336 : loss : 0.041572, loss_ce: 0.011125
2022-01-20 21:18:51,781 iteration 2337 : loss : 0.031683, loss_ce: 0.014059
2022-01-20 21:18:52,367 iteration 2338 : loss : 0.029216, loss_ce: 0.011161
2022-01-20 21:18:52,984 iteration 2339 : loss : 0.034434, loss_ce: 0.012931
2022-01-20 21:18:53,644 iteration 2340 : loss : 0.035028, loss_ce: 0.014981
2022-01-20 21:18:54,169 iteration 2341 : loss : 0.022313, loss_ce: 0.006339
2022-01-20 21:18:54,765 iteration 2342 : loss : 0.026696, loss_ce: 0.012144
2022-01-20 21:18:55,427 iteration 2343 : loss : 0.056706, loss_ce: 0.022331
2022-01-20 21:18:56,057 iteration 2344 : loss : 0.042343, loss_ce: 0.018560
2022-01-20 21:18:56,718 iteration 2345 : loss : 0.050659, loss_ce: 0.019620
2022-01-20 21:18:57,336 iteration 2346 : loss : 0.043877, loss_ce: 0.022366
 34%|██████████▋                    | 138/400 [25:22<47:13, 10.81s/it]2022-01-20 21:18:57,988 iteration 2347 : loss : 0.037382, loss_ce: 0.012986
2022-01-20 21:18:58,576 iteration 2348 : loss : 0.036969, loss_ce: 0.012501
2022-01-20 21:18:59,242 iteration 2349 : loss : 0.029255, loss_ce: 0.012137
2022-01-20 21:18:59,828 iteration 2350 : loss : 0.035421, loss_ce: 0.012604
2022-01-20 21:19:00,445 iteration 2351 : loss : 0.134519, loss_ce: 0.023707
2022-01-20 21:19:01,064 iteration 2352 : loss : 0.033064, loss_ce: 0.012043
2022-01-20 21:19:01,726 iteration 2353 : loss : 0.039279, loss_ce: 0.017223
2022-01-20 21:19:02,397 iteration 2354 : loss : 0.047481, loss_ce: 0.020790
2022-01-20 21:19:02,926 iteration 2355 : loss : 0.032810, loss_ce: 0.012595
2022-01-20 21:19:03,524 iteration 2356 : loss : 0.040764, loss_ce: 0.016540
2022-01-20 21:19:04,117 iteration 2357 : loss : 0.041905, loss_ce: 0.013467
2022-01-20 21:19:04,747 iteration 2358 : loss : 0.038514, loss_ce: 0.016419
2022-01-20 21:19:05,469 iteration 2359 : loss : 0.038954, loss_ce: 0.015637
2022-01-20 21:19:06,044 iteration 2360 : loss : 0.032709, loss_ce: 0.014105
2022-01-20 21:19:06,681 iteration 2361 : loss : 0.042129, loss_ce: 0.013885
2022-01-20 21:19:07,397 iteration 2362 : loss : 0.035230, loss_ce: 0.018021
2022-01-20 21:19:07,946 iteration 2363 : loss : 0.036375, loss_ce: 0.017798
 35%|██████████▊                    | 139/400 [25:32<46:46, 10.75s/it]2022-01-20 21:19:08,510 iteration 2364 : loss : 0.072739, loss_ce: 0.013703
2022-01-20 21:19:09,065 iteration 2365 : loss : 0.042656, loss_ce: 0.012369
2022-01-20 21:19:09,683 iteration 2366 : loss : 0.059559, loss_ce: 0.026133
2022-01-20 21:19:10,262 iteration 2367 : loss : 0.073581, loss_ce: 0.039353
2022-01-20 21:19:10,827 iteration 2368 : loss : 0.037410, loss_ce: 0.012334
2022-01-20 21:19:11,441 iteration 2369 : loss : 0.044263, loss_ce: 0.016799
2022-01-20 21:19:11,955 iteration 2370 : loss : 0.047993, loss_ce: 0.016482
2022-01-20 21:19:12,606 iteration 2371 : loss : 0.036019, loss_ce: 0.013041
2022-01-20 21:19:13,201 iteration 2372 : loss : 0.055411, loss_ce: 0.022401
2022-01-20 21:19:13,756 iteration 2373 : loss : 0.033814, loss_ce: 0.013450
2022-01-20 21:19:14,328 iteration 2374 : loss : 0.031486, loss_ce: 0.012467
2022-01-20 21:19:14,955 iteration 2375 : loss : 0.048592, loss_ce: 0.017835
2022-01-20 21:19:15,599 iteration 2376 : loss : 0.032935, loss_ce: 0.012768
2022-01-20 21:19:16,180 iteration 2377 : loss : 0.034937, loss_ce: 0.013506
2022-01-20 21:19:16,767 iteration 2378 : loss : 0.030229, loss_ce: 0.011651
2022-01-20 21:19:17,370 iteration 2379 : loss : 0.050270, loss_ce: 0.029726
2022-01-20 21:19:17,371 Training Data Eval:
2022-01-20 21:19:20,051   Average segmentation loss on training set: 0.0477
2022-01-20 21:19:20,052 Validation Data Eval:
2022-01-20 21:19:20,930   Average segmentation loss on validation set: 0.0911
2022-01-20 21:19:21,475 iteration 2380 : loss : 0.028580, loss_ce: 0.013369
 35%|██████████▊                    | 140/400 [25:46<50:12, 11.59s/it]2022-01-20 21:19:22,223 iteration 2381 : loss : 0.065894, loss_ce: 0.021371
2022-01-20 21:19:22,853 iteration 2382 : loss : 0.044819, loss_ce: 0.017776
2022-01-20 21:19:23,476 iteration 2383 : loss : 0.048690, loss_ce: 0.018130
2022-01-20 21:19:24,023 iteration 2384 : loss : 0.028914, loss_ce: 0.010357
2022-01-20 21:19:24,620 iteration 2385 : loss : 0.038189, loss_ce: 0.013795
2022-01-20 21:19:25,256 iteration 2386 : loss : 0.045023, loss_ce: 0.013087
2022-01-20 21:19:25,905 iteration 2387 : loss : 0.029503, loss_ce: 0.011392
2022-01-20 21:19:26,514 iteration 2388 : loss : 0.031851, loss_ce: 0.015083
2022-01-20 21:19:27,118 iteration 2389 : loss : 0.035116, loss_ce: 0.012606
2022-01-20 21:19:27,675 iteration 2390 : loss : 0.030010, loss_ce: 0.012082
2022-01-20 21:19:28,197 iteration 2391 : loss : 0.034708, loss_ce: 0.012291
2022-01-20 21:19:28,923 iteration 2392 : loss : 0.033807, loss_ce: 0.007380
2022-01-20 21:19:29,584 iteration 2393 : loss : 0.030039, loss_ce: 0.011808
2022-01-20 21:19:30,191 iteration 2394 : loss : 0.036675, loss_ce: 0.015130
2022-01-20 21:19:30,849 iteration 2395 : loss : 0.038959, loss_ce: 0.019151
2022-01-20 21:19:31,398 iteration 2396 : loss : 0.032737, loss_ce: 0.013137
2022-01-20 21:19:32,055 iteration 2397 : loss : 0.031647, loss_ce: 0.015485
 35%|██████████▉                    | 141/400 [25:56<48:42, 11.29s/it]2022-01-20 21:19:32,673 iteration 2398 : loss : 0.029535, loss_ce: 0.015856
2022-01-20 21:19:33,357 iteration 2399 : loss : 0.059936, loss_ce: 0.030252
2022-01-20 21:19:33,940 iteration 2400 : loss : 0.030754, loss_ce: 0.011651
2022-01-20 21:19:34,668 iteration 2401 : loss : 0.048872, loss_ce: 0.019285
2022-01-20 21:19:35,262 iteration 2402 : loss : 0.036796, loss_ce: 0.015538
2022-01-20 21:19:35,838 iteration 2403 : loss : 0.031975, loss_ce: 0.012188
2022-01-20 21:19:36,398 iteration 2404 : loss : 0.024281, loss_ce: 0.008660
2022-01-20 21:19:37,044 iteration 2405 : loss : 0.043180, loss_ce: 0.014301
2022-01-20 21:19:37,583 iteration 2406 : loss : 0.038239, loss_ce: 0.016982
2022-01-20 21:19:38,166 iteration 2407 : loss : 0.030787, loss_ce: 0.011406
2022-01-20 21:19:38,918 iteration 2408 : loss : 0.037169, loss_ce: 0.012299
2022-01-20 21:19:39,483 iteration 2409 : loss : 0.031915, loss_ce: 0.012351
2022-01-20 21:19:40,052 iteration 2410 : loss : 0.048454, loss_ce: 0.016342
2022-01-20 21:19:40,612 iteration 2411 : loss : 0.027505, loss_ce: 0.010698
2022-01-20 21:19:41,175 iteration 2412 : loss : 0.027429, loss_ce: 0.010003
2022-01-20 21:19:41,716 iteration 2413 : loss : 0.037618, loss_ce: 0.016083
2022-01-20 21:19:42,254 iteration 2414 : loss : 0.028092, loss_ce: 0.011618
 36%|███████████                    | 142/400 [26:07<47:07, 10.96s/it]2022-01-20 21:19:42,938 iteration 2415 : loss : 0.026997, loss_ce: 0.008641
2022-01-20 21:19:43,506 iteration 2416 : loss : 0.026904, loss_ce: 0.013303
2022-01-20 21:19:44,100 iteration 2417 : loss : 0.025112, loss_ce: 0.013210
2022-01-20 21:19:44,642 iteration 2418 : loss : 0.044499, loss_ce: 0.013456
2022-01-20 21:19:45,243 iteration 2419 : loss : 0.054125, loss_ce: 0.021067
2022-01-20 21:19:45,916 iteration 2420 : loss : 0.027960, loss_ce: 0.012383
2022-01-20 21:19:46,512 iteration 2421 : loss : 0.029007, loss_ce: 0.012549
2022-01-20 21:19:47,101 iteration 2422 : loss : 0.044532, loss_ce: 0.019880
2022-01-20 21:19:47,618 iteration 2423 : loss : 0.025847, loss_ce: 0.011659
2022-01-20 21:19:48,209 iteration 2424 : loss : 0.028097, loss_ce: 0.011593
2022-01-20 21:19:48,828 iteration 2425 : loss : 0.028652, loss_ce: 0.008291
2022-01-20 21:19:49,415 iteration 2426 : loss : 0.041152, loss_ce: 0.014196
2022-01-20 21:19:49,956 iteration 2427 : loss : 0.038082, loss_ce: 0.015125
2022-01-20 21:19:50,535 iteration 2428 : loss : 0.034308, loss_ce: 0.011846
2022-01-20 21:19:51,090 iteration 2429 : loss : 0.033325, loss_ce: 0.010273
2022-01-20 21:19:51,675 iteration 2430 : loss : 0.031837, loss_ce: 0.012811
2022-01-20 21:19:52,285 iteration 2431 : loss : 0.027613, loss_ce: 0.008971
 36%|███████████                    | 143/400 [26:17<45:44, 10.68s/it]2022-01-20 21:19:52,854 iteration 2432 : loss : 0.027613, loss_ce: 0.009504
2022-01-20 21:19:53,417 iteration 2433 : loss : 0.031999, loss_ce: 0.014909
2022-01-20 21:19:54,033 iteration 2434 : loss : 0.031819, loss_ce: 0.013282
2022-01-20 21:19:54,620 iteration 2435 : loss : 0.025864, loss_ce: 0.011988
2022-01-20 21:19:55,284 iteration 2436 : loss : 0.034931, loss_ce: 0.012443
2022-01-20 21:19:55,880 iteration 2437 : loss : 0.028114, loss_ce: 0.011977
2022-01-20 21:19:56,410 iteration 2438 : loss : 0.022063, loss_ce: 0.008873
2022-01-20 21:19:56,991 iteration 2439 : loss : 0.026837, loss_ce: 0.009902
2022-01-20 21:19:57,581 iteration 2440 : loss : 0.033676, loss_ce: 0.013165
2022-01-20 21:19:58,280 iteration 2441 : loss : 0.068727, loss_ce: 0.022240
2022-01-20 21:19:58,909 iteration 2442 : loss : 0.025843, loss_ce: 0.009697
2022-01-20 21:19:59,549 iteration 2443 : loss : 0.028326, loss_ce: 0.010983
2022-01-20 21:20:00,181 iteration 2444 : loss : 0.034589, loss_ce: 0.013656
2022-01-20 21:20:00,875 iteration 2445 : loss : 0.028677, loss_ce: 0.011429
2022-01-20 21:20:01,443 iteration 2446 : loss : 0.028502, loss_ce: 0.012742
2022-01-20 21:20:02,101 iteration 2447 : loss : 0.062849, loss_ce: 0.024149
2022-01-20 21:20:02,647 iteration 2448 : loss : 0.035032, loss_ce: 0.018417
 36%|███████████▏                   | 144/400 [26:27<45:09, 10.59s/it]2022-01-20 21:20:03,284 iteration 2449 : loss : 0.022439, loss_ce: 0.006642
2022-01-20 21:20:03,820 iteration 2450 : loss : 0.034949, loss_ce: 0.013844
2022-01-20 21:20:04,360 iteration 2451 : loss : 0.026121, loss_ce: 0.009184
2022-01-20 21:20:04,933 iteration 2452 : loss : 0.031251, loss_ce: 0.014108
2022-01-20 21:20:05,512 iteration 2453 : loss : 0.038164, loss_ce: 0.019173
2022-01-20 21:20:06,080 iteration 2454 : loss : 0.032341, loss_ce: 0.012378
2022-01-20 21:20:06,757 iteration 2455 : loss : 0.053743, loss_ce: 0.019022
2022-01-20 21:20:07,369 iteration 2456 : loss : 0.026677, loss_ce: 0.012467
2022-01-20 21:20:07,925 iteration 2457 : loss : 0.035987, loss_ce: 0.017297
2022-01-20 21:20:08,553 iteration 2458 : loss : 0.039372, loss_ce: 0.011576
2022-01-20 21:20:09,135 iteration 2459 : loss : 0.023084, loss_ce: 0.008304
2022-01-20 21:20:09,777 iteration 2460 : loss : 0.042421, loss_ce: 0.011259
2022-01-20 21:20:10,401 iteration 2461 : loss : 0.044689, loss_ce: 0.011886
2022-01-20 21:20:11,093 iteration 2462 : loss : 0.036163, loss_ce: 0.017813
2022-01-20 21:20:11,661 iteration 2463 : loss : 0.032712, loss_ce: 0.012921
2022-01-20 21:20:12,261 iteration 2464 : loss : 0.034134, loss_ce: 0.019075
2022-01-20 21:20:12,262 Training Data Eval:
2022-01-20 21:20:14,948   Average segmentation loss on training set: 0.0221
2022-01-20 21:20:14,948 Validation Data Eval:
2022-01-20 21:20:15,824   Average segmentation loss on validation set: 0.0973
2022-01-20 21:20:16,425 iteration 2465 : loss : 0.030324, loss_ce: 0.013647
 36%|███████████▏                   | 145/400 [26:41<49:02, 11.54s/it]2022-01-20 21:20:17,095 iteration 2466 : loss : 0.063714, loss_ce: 0.024330
2022-01-20 21:20:17,669 iteration 2467 : loss : 0.024671, loss_ce: 0.008195
2022-01-20 21:20:18,346 iteration 2468 : loss : 0.036353, loss_ce: 0.013595
2022-01-20 21:20:18,895 iteration 2469 : loss : 0.027102, loss_ce: 0.012607
2022-01-20 21:20:19,526 iteration 2470 : loss : 0.037707, loss_ce: 0.014902
2022-01-20 21:20:20,151 iteration 2471 : loss : 0.027647, loss_ce: 0.013871
2022-01-20 21:20:20,771 iteration 2472 : loss : 0.035682, loss_ce: 0.015010
2022-01-20 21:20:21,359 iteration 2473 : loss : 0.030288, loss_ce: 0.010586
2022-01-20 21:20:21,856 iteration 2474 : loss : 0.027089, loss_ce: 0.011412
2022-01-20 21:20:22,486 iteration 2475 : loss : 0.044173, loss_ce: 0.025595
2022-01-20 21:20:23,104 iteration 2476 : loss : 0.027048, loss_ce: 0.008712
2022-01-20 21:20:23,710 iteration 2477 : loss : 0.029131, loss_ce: 0.010509
2022-01-20 21:20:24,292 iteration 2478 : loss : 0.031648, loss_ce: 0.009917
2022-01-20 21:20:24,940 iteration 2479 : loss : 0.029911, loss_ce: 0.009409
2022-01-20 21:20:25,528 iteration 2480 : loss : 0.048889, loss_ce: 0.017363
2022-01-20 21:20:26,088 iteration 2481 : loss : 0.028400, loss_ce: 0.011854
2022-01-20 21:20:26,790 iteration 2482 : loss : 0.066878, loss_ce: 0.025861
 36%|███████████▎                   | 146/400 [26:51<47:22, 11.19s/it]2022-01-20 21:20:27,418 iteration 2483 : loss : 0.039948, loss_ce: 0.017438
2022-01-20 21:20:28,047 iteration 2484 : loss : 0.048324, loss_ce: 0.011746
2022-01-20 21:20:28,664 iteration 2485 : loss : 0.035479, loss_ce: 0.012267
2022-01-20 21:20:29,272 iteration 2486 : loss : 0.037733, loss_ce: 0.015331
2022-01-20 21:20:29,817 iteration 2487 : loss : 0.028152, loss_ce: 0.011932
2022-01-20 21:20:30,476 iteration 2488 : loss : 0.036133, loss_ce: 0.015930
2022-01-20 21:20:31,110 iteration 2489 : loss : 0.040824, loss_ce: 0.017248
2022-01-20 21:20:31,782 iteration 2490 : loss : 0.035632, loss_ce: 0.015347
2022-01-20 21:20:32,398 iteration 2491 : loss : 0.028674, loss_ce: 0.008872
2022-01-20 21:20:33,020 iteration 2492 : loss : 0.052980, loss_ce: 0.018530
2022-01-20 21:20:33,574 iteration 2493 : loss : 0.034883, loss_ce: 0.011935
2022-01-20 21:20:34,175 iteration 2494 : loss : 0.046787, loss_ce: 0.019402
2022-01-20 21:20:34,860 iteration 2495 : loss : 0.025353, loss_ce: 0.010744
2022-01-20 21:20:35,348 iteration 2496 : loss : 0.021123, loss_ce: 0.008548
2022-01-20 21:20:35,896 iteration 2497 : loss : 0.032039, loss_ce: 0.011278
2022-01-20 21:20:36,619 iteration 2498 : loss : 0.021833, loss_ce: 0.007947
2022-01-20 21:20:37,219 iteration 2499 : loss : 0.031627, loss_ce: 0.015245
 37%|███████████▍                   | 147/400 [27:02<46:13, 10.96s/it]2022-01-20 21:20:37,883 iteration 2500 : loss : 0.030051, loss_ce: 0.011132
2022-01-20 21:20:38,517 iteration 2501 : loss : 0.026855, loss_ce: 0.011416
2022-01-20 21:20:39,142 iteration 2502 : loss : 0.026783, loss_ce: 0.012243
2022-01-20 21:20:39,719 iteration 2503 : loss : 0.028674, loss_ce: 0.012148
2022-01-20 21:20:40,345 iteration 2504 : loss : 0.029928, loss_ce: 0.011411
2022-01-20 21:20:40,959 iteration 2505 : loss : 0.026901, loss_ce: 0.008141
2022-01-20 21:20:41,577 iteration 2506 : loss : 0.031553, loss_ce: 0.014771
2022-01-20 21:20:42,131 iteration 2507 : loss : 0.028765, loss_ce: 0.010452
2022-01-20 21:20:42,642 iteration 2508 : loss : 0.026099, loss_ce: 0.011403
2022-01-20 21:20:43,205 iteration 2509 : loss : 0.024283, loss_ce: 0.011711
2022-01-20 21:20:43,734 iteration 2510 : loss : 0.044876, loss_ce: 0.013513
2022-01-20 21:20:44,311 iteration 2511 : loss : 0.029762, loss_ce: 0.014179
2022-01-20 21:20:44,887 iteration 2512 : loss : 0.028838, loss_ce: 0.012662
2022-01-20 21:20:45,476 iteration 2513 : loss : 0.040389, loss_ce: 0.015736
2022-01-20 21:20:46,081 iteration 2514 : loss : 0.026598, loss_ce: 0.010330
2022-01-20 21:20:46,648 iteration 2515 : loss : 0.037831, loss_ce: 0.012620
2022-01-20 21:20:47,193 iteration 2516 : loss : 0.038104, loss_ce: 0.016796
 37%|███████████▍                   | 148/400 [27:12<44:47, 10.67s/it]2022-01-20 21:20:47,802 iteration 2517 : loss : 0.035416, loss_ce: 0.017870
2022-01-20 21:20:48,491 iteration 2518 : loss : 0.035326, loss_ce: 0.015846
2022-01-20 21:20:49,080 iteration 2519 : loss : 0.029082, loss_ce: 0.013229
2022-01-20 21:20:49,650 iteration 2520 : loss : 0.023376, loss_ce: 0.007468
2022-01-20 21:20:50,276 iteration 2521 : loss : 0.029669, loss_ce: 0.014364
2022-01-20 21:20:50,811 iteration 2522 : loss : 0.021537, loss_ce: 0.008367
2022-01-20 21:20:51,288 iteration 2523 : loss : 0.034469, loss_ce: 0.009267
2022-01-20 21:20:51,913 iteration 2524 : loss : 0.034106, loss_ce: 0.016014
2022-01-20 21:20:52,467 iteration 2525 : loss : 0.028710, loss_ce: 0.012231
2022-01-20 21:20:53,017 iteration 2526 : loss : 0.026827, loss_ce: 0.009771
2022-01-20 21:20:53,658 iteration 2527 : loss : 0.026551, loss_ce: 0.009675
2022-01-20 21:20:54,221 iteration 2528 : loss : 0.027257, loss_ce: 0.011050
2022-01-20 21:20:54,834 iteration 2529 : loss : 0.030212, loss_ce: 0.012699
2022-01-20 21:20:55,426 iteration 2530 : loss : 0.023300, loss_ce: 0.006854
2022-01-20 21:20:56,003 iteration 2531 : loss : 0.031547, loss_ce: 0.011746
2022-01-20 21:20:56,623 iteration 2532 : loss : 0.035433, loss_ce: 0.011545
2022-01-20 21:20:57,220 iteration 2533 : loss : 0.028745, loss_ce: 0.016631
 37%|███████████▌                   | 149/400 [27:22<43:49, 10.47s/it]2022-01-20 21:20:57,797 iteration 2534 : loss : 0.020944, loss_ce: 0.009136
2022-01-20 21:20:58,412 iteration 2535 : loss : 0.023284, loss_ce: 0.007073
2022-01-20 21:20:59,045 iteration 2536 : loss : 0.033890, loss_ce: 0.016597
2022-01-20 21:20:59,691 iteration 2537 : loss : 0.048781, loss_ce: 0.018131
2022-01-20 21:21:00,347 iteration 2538 : loss : 0.041067, loss_ce: 0.014691
2022-01-20 21:21:00,882 iteration 2539 : loss : 0.024651, loss_ce: 0.010357
2022-01-20 21:21:01,464 iteration 2540 : loss : 0.029163, loss_ce: 0.010514
2022-01-20 21:21:02,178 iteration 2541 : loss : 0.039474, loss_ce: 0.012061
2022-01-20 21:21:02,710 iteration 2542 : loss : 0.025509, loss_ce: 0.009851
2022-01-20 21:21:03,302 iteration 2543 : loss : 0.024247, loss_ce: 0.009288
2022-01-20 21:21:03,959 iteration 2544 : loss : 0.046540, loss_ce: 0.016517
2022-01-20 21:21:04,598 iteration 2545 : loss : 0.033353, loss_ce: 0.017680
2022-01-20 21:21:05,138 iteration 2546 : loss : 0.023771, loss_ce: 0.008925
2022-01-20 21:21:05,739 iteration 2547 : loss : 0.044275, loss_ce: 0.010096
2022-01-20 21:21:06,325 iteration 2548 : loss : 0.028085, loss_ce: 0.011057
2022-01-20 21:21:06,974 iteration 2549 : loss : 0.049864, loss_ce: 0.016223
2022-01-20 21:21:06,975 Training Data Eval:
2022-01-20 21:21:09,673   Average segmentation loss on training set: 0.0227
2022-01-20 21:21:09,674 Validation Data Eval:
2022-01-20 21:21:10,553   Average segmentation loss on validation set: 0.0936
2022-01-20 21:21:11,128 iteration 2550 : loss : 0.058388, loss_ce: 0.034741
 38%|███████████▋                   | 150/400 [27:35<47:55, 11.50s/it]2022-01-20 21:21:11,732 iteration 2551 : loss : 0.025018, loss_ce: 0.009144
2022-01-20 21:21:12,321 iteration 2552 : loss : 0.027073, loss_ce: 0.010602
2022-01-20 21:21:12,982 iteration 2553 : loss : 0.040140, loss_ce: 0.014781
2022-01-20 21:21:13,620 iteration 2554 : loss : 0.056335, loss_ce: 0.024217
2022-01-20 21:21:14,192 iteration 2555 : loss : 0.027089, loss_ce: 0.007975
2022-01-20 21:21:14,711 iteration 2556 : loss : 0.034380, loss_ce: 0.014059
2022-01-20 21:21:15,347 iteration 2557 : loss : 0.028289, loss_ce: 0.013134
2022-01-20 21:21:15,982 iteration 2558 : loss : 0.024128, loss_ce: 0.009922
2022-01-20 21:21:16,631 iteration 2559 : loss : 0.056348, loss_ce: 0.016165
2022-01-20 21:21:17,274 iteration 2560 : loss : 0.026253, loss_ce: 0.011062
2022-01-20 21:21:17,857 iteration 2561 : loss : 0.027480, loss_ce: 0.011220
2022-01-20 21:21:18,405 iteration 2562 : loss : 0.027131, loss_ce: 0.014335
2022-01-20 21:21:18,984 iteration 2563 : loss : 0.027981, loss_ce: 0.008859
2022-01-20 21:21:19,578 iteration 2564 : loss : 0.033763, loss_ce: 0.014874
2022-01-20 21:21:20,168 iteration 2565 : loss : 0.035789, loss_ce: 0.008915
2022-01-20 21:21:20,734 iteration 2566 : loss : 0.024238, loss_ce: 0.011448
2022-01-20 21:21:21,416 iteration 2567 : loss : 0.031963, loss_ce: 0.013194
 38%|███████████▋                   | 151/400 [27:46<46:14, 11.14s/it]2022-01-20 21:21:22,048 iteration 2568 : loss : 0.024265, loss_ce: 0.011220
2022-01-20 21:21:22,645 iteration 2569 : loss : 0.026384, loss_ce: 0.010240
2022-01-20 21:21:23,203 iteration 2570 : loss : 0.039813, loss_ce: 0.011825
2022-01-20 21:21:23,796 iteration 2571 : loss : 0.039668, loss_ce: 0.016216
2022-01-20 21:21:24,320 iteration 2572 : loss : 0.026192, loss_ce: 0.008133
2022-01-20 21:21:24,869 iteration 2573 : loss : 0.038851, loss_ce: 0.019939
2022-01-20 21:21:25,451 iteration 2574 : loss : 0.032214, loss_ce: 0.012371
2022-01-20 21:21:26,078 iteration 2575 : loss : 0.043906, loss_ce: 0.016803
2022-01-20 21:21:26,785 iteration 2576 : loss : 0.027499, loss_ce: 0.011773
2022-01-20 21:21:27,360 iteration 2577 : loss : 0.032953, loss_ce: 0.011657
2022-01-20 21:21:27,979 iteration 2578 : loss : 0.031960, loss_ce: 0.015884
2022-01-20 21:21:28,545 iteration 2579 : loss : 0.037345, loss_ce: 0.012105
2022-01-20 21:21:29,167 iteration 2580 : loss : 0.029531, loss_ce: 0.009754
2022-01-20 21:21:29,871 iteration 2581 : loss : 0.037810, loss_ce: 0.014077
2022-01-20 21:21:30,364 iteration 2582 : loss : 0.027215, loss_ce: 0.011223
2022-01-20 21:21:30,988 iteration 2583 : loss : 0.021909, loss_ce: 0.007837
2022-01-20 21:21:31,552 iteration 2584 : loss : 0.030771, loss_ce: 0.011050
 38%|███████████▊                   | 152/400 [27:56<44:47, 10.84s/it]2022-01-20 21:21:32,231 iteration 2585 : loss : 0.033068, loss_ce: 0.016176
2022-01-20 21:21:32,826 iteration 2586 : loss : 0.051672, loss_ce: 0.022086
2022-01-20 21:21:33,362 iteration 2587 : loss : 0.025605, loss_ce: 0.008682
2022-01-20 21:21:33,935 iteration 2588 : loss : 0.031674, loss_ce: 0.014191
2022-01-20 21:21:34,454 iteration 2589 : loss : 0.025109, loss_ce: 0.009262
2022-01-20 21:21:35,079 iteration 2590 : loss : 0.040647, loss_ce: 0.013908
2022-01-20 21:21:35,660 iteration 2591 : loss : 0.034009, loss_ce: 0.015536
2022-01-20 21:21:36,229 iteration 2592 : loss : 0.023676, loss_ce: 0.008725
2022-01-20 21:21:36,782 iteration 2593 : loss : 0.030440, loss_ce: 0.011292
2022-01-20 21:21:37,401 iteration 2594 : loss : 0.027323, loss_ce: 0.009388
2022-01-20 21:21:38,089 iteration 2595 : loss : 0.044954, loss_ce: 0.015846
2022-01-20 21:21:38,617 iteration 2596 : loss : 0.025741, loss_ce: 0.009484
2022-01-20 21:21:39,212 iteration 2597 : loss : 0.038892, loss_ce: 0.011477
2022-01-20 21:21:39,771 iteration 2598 : loss : 0.027190, loss_ce: 0.011511
2022-01-20 21:21:40,403 iteration 2599 : loss : 0.023994, loss_ce: 0.011000
2022-01-20 21:21:40,999 iteration 2600 : loss : 0.035500, loss_ce: 0.011780
2022-01-20 21:21:41,614 iteration 2601 : loss : 0.027040, loss_ce: 0.010205
 38%|███████████▊                   | 153/400 [28:06<43:39, 10.61s/it]2022-01-20 21:21:42,276 iteration 2602 : loss : 0.027695, loss_ce: 0.009454
2022-01-20 21:21:42,962 iteration 2603 : loss : 0.037428, loss_ce: 0.013018
2022-01-20 21:21:43,558 iteration 2604 : loss : 0.032032, loss_ce: 0.014065
2022-01-20 21:21:44,032 iteration 2605 : loss : 0.024577, loss_ce: 0.007694
2022-01-20 21:21:44,759 iteration 2606 : loss : 0.045329, loss_ce: 0.014612
2022-01-20 21:21:45,404 iteration 2607 : loss : 0.025871, loss_ce: 0.009289
2022-01-20 21:21:46,008 iteration 2608 : loss : 0.023450, loss_ce: 0.010898
2022-01-20 21:21:46,698 iteration 2609 : loss : 0.049436, loss_ce: 0.017291
2022-01-20 21:21:47,349 iteration 2610 : loss : 0.033777, loss_ce: 0.012244
2022-01-20 21:21:47,977 iteration 2611 : loss : 0.044310, loss_ce: 0.019366
2022-01-20 21:21:48,635 iteration 2612 : loss : 0.040109, loss_ce: 0.019086
2022-01-20 21:21:49,189 iteration 2613 : loss : 0.030088, loss_ce: 0.012732
2022-01-20 21:21:49,858 iteration 2614 : loss : 0.034735, loss_ce: 0.011788
2022-01-20 21:21:50,427 iteration 2615 : loss : 0.048996, loss_ce: 0.020450
2022-01-20 21:21:51,056 iteration 2616 : loss : 0.027067, loss_ce: 0.013211
2022-01-20 21:21:51,639 iteration 2617 : loss : 0.026650, loss_ce: 0.008592
2022-01-20 21:21:52,187 iteration 2618 : loss : 0.024130, loss_ce: 0.009913
 38%|███████████▉                   | 154/400 [28:17<43:26, 10.60s/it]2022-01-20 21:21:52,791 iteration 2619 : loss : 0.027202, loss_ce: 0.008704
2022-01-20 21:21:53,353 iteration 2620 : loss : 0.038407, loss_ce: 0.018891
2022-01-20 21:21:54,003 iteration 2621 : loss : 0.041886, loss_ce: 0.016184
2022-01-20 21:21:54,588 iteration 2622 : loss : 0.043461, loss_ce: 0.009433
2022-01-20 21:21:55,209 iteration 2623 : loss : 0.035164, loss_ce: 0.015267
2022-01-20 21:21:55,761 iteration 2624 : loss : 0.022734, loss_ce: 0.007113
2022-01-20 21:21:56,377 iteration 2625 : loss : 0.045663, loss_ce: 0.009655
2022-01-20 21:21:56,987 iteration 2626 : loss : 0.034646, loss_ce: 0.014395
2022-01-20 21:21:57,730 iteration 2627 : loss : 0.031119, loss_ce: 0.011783
2022-01-20 21:21:58,269 iteration 2628 : loss : 0.029923, loss_ce: 0.012611
2022-01-20 21:21:58,926 iteration 2629 : loss : 0.027242, loss_ce: 0.012287
2022-01-20 21:21:59,549 iteration 2630 : loss : 0.040349, loss_ce: 0.016241
2022-01-20 21:22:00,153 iteration 2631 : loss : 0.031180, loss_ce: 0.012852
2022-01-20 21:22:00,747 iteration 2632 : loss : 0.022630, loss_ce: 0.008135
2022-01-20 21:22:01,382 iteration 2633 : loss : 0.026393, loss_ce: 0.013641
2022-01-20 21:22:02,005 iteration 2634 : loss : 0.031950, loss_ce: 0.010249
2022-01-20 21:22:02,006 Training Data Eval:
2022-01-20 21:22:04,702   Average segmentation loss on training set: 0.0197
2022-01-20 21:22:04,702 Validation Data Eval:
2022-01-20 21:22:05,584   Average segmentation loss on validation set: 0.0819
2022-01-20 21:22:06,183 iteration 2635 : loss : 0.025671, loss_ce: 0.010226
 39%|████████████                   | 155/400 [28:31<47:25, 11.62s/it]2022-01-20 21:22:06,827 iteration 2636 : loss : 0.031378, loss_ce: 0.014099
2022-01-20 21:22:07,506 iteration 2637 : loss : 0.040446, loss_ce: 0.017263
2022-01-20 21:22:08,084 iteration 2638 : loss : 0.028632, loss_ce: 0.009539
2022-01-20 21:22:08,631 iteration 2639 : loss : 0.052493, loss_ce: 0.027135
2022-01-20 21:22:09,197 iteration 2640 : loss : 0.030116, loss_ce: 0.009910
2022-01-20 21:22:09,775 iteration 2641 : loss : 0.033687, loss_ce: 0.015487
2022-01-20 21:22:10,321 iteration 2642 : loss : 0.029598, loss_ce: 0.009739
2022-01-20 21:22:11,015 iteration 2643 : loss : 0.029550, loss_ce: 0.011628
2022-01-20 21:22:11,586 iteration 2644 : loss : 0.023681, loss_ce: 0.008836
2022-01-20 21:22:12,130 iteration 2645 : loss : 0.023207, loss_ce: 0.007997
2022-01-20 21:22:12,882 iteration 2646 : loss : 0.036713, loss_ce: 0.011864
2022-01-20 21:22:13,535 iteration 2647 : loss : 0.046143, loss_ce: 0.021519
2022-01-20 21:22:14,117 iteration 2648 : loss : 0.027928, loss_ce: 0.010794
2022-01-20 21:22:14,728 iteration 2649 : loss : 0.029086, loss_ce: 0.011159
2022-01-20 21:22:15,375 iteration 2650 : loss : 0.027360, loss_ce: 0.008625
2022-01-20 21:22:15,988 iteration 2651 : loss : 0.038354, loss_ce: 0.016941
2022-01-20 21:22:16,525 iteration 2652 : loss : 0.020877, loss_ce: 0.008912
 39%|████████████                   | 156/400 [28:41<45:41, 11.23s/it]2022-01-20 21:22:17,216 iteration 2653 : loss : 0.026895, loss_ce: 0.012172
2022-01-20 21:22:17,830 iteration 2654 : loss : 0.027155, loss_ce: 0.008992
2022-01-20 21:22:18,517 iteration 2655 : loss : 0.037630, loss_ce: 0.021901
2022-01-20 21:22:19,099 iteration 2656 : loss : 0.028322, loss_ce: 0.009200
2022-01-20 21:22:19,691 iteration 2657 : loss : 0.022381, loss_ce: 0.009069
2022-01-20 21:22:20,170 iteration 2658 : loss : 0.025934, loss_ce: 0.013910
2022-01-20 21:22:20,701 iteration 2659 : loss : 0.040154, loss_ce: 0.010245
2022-01-20 21:22:21,331 iteration 2660 : loss : 0.038724, loss_ce: 0.011996
2022-01-20 21:22:21,890 iteration 2661 : loss : 0.026923, loss_ce: 0.012577
2022-01-20 21:22:22,477 iteration 2662 : loss : 0.036974, loss_ce: 0.017510
2022-01-20 21:22:23,043 iteration 2663 : loss : 0.036006, loss_ce: 0.010485
2022-01-20 21:22:23,724 iteration 2664 : loss : 0.036729, loss_ce: 0.017278
2022-01-20 21:22:24,324 iteration 2665 : loss : 0.028754, loss_ce: 0.011527
2022-01-20 21:22:24,879 iteration 2666 : loss : 0.018174, loss_ce: 0.006858
2022-01-20 21:22:25,527 iteration 2667 : loss : 0.030493, loss_ce: 0.010673
2022-01-20 21:22:26,088 iteration 2668 : loss : 0.022679, loss_ce: 0.007702
2022-01-20 21:22:26,648 iteration 2669 : loss : 0.027432, loss_ce: 0.011289
 39%|████████████▏                  | 157/400 [28:51<44:08, 10.90s/it]2022-01-20 21:22:27,318 iteration 2670 : loss : 0.029449, loss_ce: 0.013434
2022-01-20 21:22:28,028 iteration 2671 : loss : 0.047371, loss_ce: 0.015785
2022-01-20 21:22:28,667 iteration 2672 : loss : 0.034612, loss_ce: 0.015433
2022-01-20 21:22:29,216 iteration 2673 : loss : 0.023795, loss_ce: 0.011470
2022-01-20 21:22:29,847 iteration 2674 : loss : 0.030118, loss_ce: 0.013081
2022-01-20 21:22:30,332 iteration 2675 : loss : 0.020549, loss_ce: 0.008775
2022-01-20 21:22:31,038 iteration 2676 : loss : 0.058320, loss_ce: 0.016136
2022-01-20 21:22:31,662 iteration 2677 : loss : 0.033891, loss_ce: 0.013710
2022-01-20 21:22:32,249 iteration 2678 : loss : 0.029862, loss_ce: 0.013161
2022-01-20 21:22:32,852 iteration 2679 : loss : 0.033746, loss_ce: 0.011770
2022-01-20 21:22:33,436 iteration 2680 : loss : 0.027856, loss_ce: 0.010841
2022-01-20 21:22:34,040 iteration 2681 : loss : 0.032057, loss_ce: 0.013358
2022-01-20 21:22:34,647 iteration 2682 : loss : 0.024554, loss_ce: 0.009554
2022-01-20 21:22:35,231 iteration 2683 : loss : 0.043759, loss_ce: 0.013029
2022-01-20 21:22:35,776 iteration 2684 : loss : 0.028913, loss_ce: 0.016266
2022-01-20 21:22:36,385 iteration 2685 : loss : 0.022707, loss_ce: 0.009720
2022-01-20 21:22:36,929 iteration 2686 : loss : 0.032332, loss_ce: 0.015616
 40%|████████████▏                  | 158/400 [29:01<43:12, 10.71s/it]2022-01-20 21:22:37,476 iteration 2687 : loss : 0.032195, loss_ce: 0.010506
2022-01-20 21:22:38,066 iteration 2688 : loss : 0.034539, loss_ce: 0.011375
2022-01-20 21:22:38,629 iteration 2689 : loss : 0.034488, loss_ce: 0.012149
2022-01-20 21:22:39,321 iteration 2690 : loss : 0.031290, loss_ce: 0.014462
2022-01-20 21:22:39,850 iteration 2691 : loss : 0.020707, loss_ce: 0.008374
2022-01-20 21:22:40,396 iteration 2692 : loss : 0.029799, loss_ce: 0.011904
2022-01-20 21:22:40,991 iteration 2693 : loss : 0.030706, loss_ce: 0.010862
2022-01-20 21:22:41,659 iteration 2694 : loss : 0.036436, loss_ce: 0.013312
2022-01-20 21:22:42,233 iteration 2695 : loss : 0.027531, loss_ce: 0.011950
2022-01-20 21:22:42,850 iteration 2696 : loss : 0.037630, loss_ce: 0.018101
2022-01-20 21:22:43,380 iteration 2697 : loss : 0.023174, loss_ce: 0.010360
2022-01-20 21:22:43,840 iteration 2698 : loss : 0.023539, loss_ce: 0.010806
2022-01-20 21:22:44,435 iteration 2699 : loss : 0.030992, loss_ce: 0.011462
2022-01-20 21:22:45,078 iteration 2700 : loss : 0.028806, loss_ce: 0.013971
2022-01-20 21:22:45,669 iteration 2701 : loss : 0.029623, loss_ce: 0.011030
2022-01-20 21:22:46,295 iteration 2702 : loss : 0.051665, loss_ce: 0.009327
2022-01-20 21:22:46,881 iteration 2703 : loss : 0.027366, loss_ce: 0.010464
 40%|████████████▎                  | 159/400 [29:11<42:07, 10.49s/it]2022-01-20 21:22:47,620 iteration 2704 : loss : 0.037575, loss_ce: 0.016727
2022-01-20 21:22:48,169 iteration 2705 : loss : 0.030724, loss_ce: 0.008942
2022-01-20 21:22:48,716 iteration 2706 : loss : 0.032876, loss_ce: 0.018056
2022-01-20 21:22:49,382 iteration 2707 : loss : 0.029305, loss_ce: 0.009164
2022-01-20 21:22:49,900 iteration 2708 : loss : 0.020127, loss_ce: 0.008165
2022-01-20 21:22:50,496 iteration 2709 : loss : 0.030717, loss_ce: 0.008971
2022-01-20 21:22:51,041 iteration 2710 : loss : 0.027002, loss_ce: 0.010947
2022-01-20 21:22:51,731 iteration 2711 : loss : 0.036644, loss_ce: 0.011866
2022-01-20 21:22:52,265 iteration 2712 : loss : 0.021582, loss_ce: 0.008730
2022-01-20 21:22:52,959 iteration 2713 : loss : 0.057265, loss_ce: 0.019066
2022-01-20 21:22:53,494 iteration 2714 : loss : 0.024087, loss_ce: 0.008168
2022-01-20 21:22:54,102 iteration 2715 : loss : 0.032919, loss_ce: 0.016803
2022-01-20 21:22:54,661 iteration 2716 : loss : 0.030390, loss_ce: 0.011450
2022-01-20 21:22:55,191 iteration 2717 : loss : 0.022881, loss_ce: 0.010801
2022-01-20 21:22:55,730 iteration 2718 : loss : 0.024256, loss_ce: 0.009054
2022-01-20 21:22:56,384 iteration 2719 : loss : 0.063411, loss_ce: 0.019886
2022-01-20 21:22:56,384 Training Data Eval:
2022-01-20 21:22:59,073   Average segmentation loss on training set: 0.0211
2022-01-20 21:22:59,074 Validation Data Eval:
2022-01-20 21:22:59,945   Average segmentation loss on validation set: 0.0891
2022-01-20 21:23:00,468 iteration 2720 : loss : 0.023647, loss_ce: 0.010254
 40%|████████████▍                  | 160/400 [29:25<45:40, 11.42s/it]2022-01-20 21:23:01,115 iteration 2721 : loss : 0.030458, loss_ce: 0.011124
2022-01-20 21:23:01,730 iteration 2722 : loss : 0.025448, loss_ce: 0.011095
2022-01-20 21:23:02,356 iteration 2723 : loss : 0.029437, loss_ce: 0.010388
2022-01-20 21:23:02,888 iteration 2724 : loss : 0.032777, loss_ce: 0.011982
2022-01-20 21:23:03,385 iteration 2725 : loss : 0.023091, loss_ce: 0.008911
2022-01-20 21:23:03,939 iteration 2726 : loss : 0.028711, loss_ce: 0.010220
2022-01-20 21:23:04,456 iteration 2727 : loss : 0.023475, loss_ce: 0.007818
2022-01-20 21:23:05,163 iteration 2728 : loss : 0.038468, loss_ce: 0.019808
2022-01-20 21:23:05,766 iteration 2729 : loss : 0.034513, loss_ce: 0.012522
2022-01-20 21:23:06,408 iteration 2730 : loss : 0.026726, loss_ce: 0.011228
2022-01-20 21:23:07,039 iteration 2731 : loss : 0.026270, loss_ce: 0.011699
2022-01-20 21:23:07,733 iteration 2732 : loss : 0.034594, loss_ce: 0.013759
2022-01-20 21:23:08,366 iteration 2733 : loss : 0.047081, loss_ce: 0.016065
2022-01-20 21:23:08,987 iteration 2734 : loss : 0.022788, loss_ce: 0.006506
2022-01-20 21:23:09,496 iteration 2735 : loss : 0.029241, loss_ce: 0.012651
2022-01-20 21:23:10,141 iteration 2736 : loss : 0.027909, loss_ce: 0.014124
2022-01-20 21:23:10,718 iteration 2737 : loss : 0.024290, loss_ce: 0.008570
 40%|████████████▍                  | 161/400 [29:35<44:04, 11.06s/it]2022-01-20 21:23:11,338 iteration 2738 : loss : 0.025803, loss_ce: 0.011126
2022-01-20 21:23:11,904 iteration 2739 : loss : 0.032949, loss_ce: 0.015641
2022-01-20 21:23:12,510 iteration 2740 : loss : 0.026456, loss_ce: 0.010717
2022-01-20 21:23:13,126 iteration 2741 : loss : 0.024887, loss_ce: 0.008054
2022-01-20 21:23:13,654 iteration 2742 : loss : 0.023202, loss_ce: 0.008637
2022-01-20 21:23:14,245 iteration 2743 : loss : 0.032951, loss_ce: 0.016172
2022-01-20 21:23:14,865 iteration 2744 : loss : 0.027367, loss_ce: 0.010513
2022-01-20 21:23:15,464 iteration 2745 : loss : 0.028126, loss_ce: 0.010551
2022-01-20 21:23:16,005 iteration 2746 : loss : 0.040955, loss_ce: 0.011861
2022-01-20 21:23:16,610 iteration 2747 : loss : 0.028008, loss_ce: 0.008302
2022-01-20 21:23:17,248 iteration 2748 : loss : 0.031888, loss_ce: 0.011612
2022-01-20 21:23:17,774 iteration 2749 : loss : 0.040816, loss_ce: 0.016403
2022-01-20 21:23:18,392 iteration 2750 : loss : 0.022686, loss_ce: 0.006832
2022-01-20 21:23:18,947 iteration 2751 : loss : 0.021805, loss_ce: 0.008868
2022-01-20 21:23:19,455 iteration 2752 : loss : 0.031543, loss_ce: 0.007092
2022-01-20 21:23:20,126 iteration 2753 : loss : 0.041263, loss_ce: 0.018727
2022-01-20 21:23:20,758 iteration 2754 : loss : 0.024128, loss_ce: 0.010379
 40%|████████████▌                  | 162/400 [29:45<42:40, 10.76s/it]2022-01-20 21:23:21,391 iteration 2755 : loss : 0.019158, loss_ce: 0.007258
2022-01-20 21:23:21,995 iteration 2756 : loss : 0.039611, loss_ce: 0.021479
2022-01-20 21:23:22,591 iteration 2757 : loss : 0.035315, loss_ce: 0.016108
2022-01-20 21:23:23,254 iteration 2758 : loss : 0.033391, loss_ce: 0.011581
2022-01-20 21:23:23,855 iteration 2759 : loss : 0.031315, loss_ce: 0.009593
2022-01-20 21:23:24,446 iteration 2760 : loss : 0.029247, loss_ce: 0.010782
2022-01-20 21:23:24,955 iteration 2761 : loss : 0.030979, loss_ce: 0.011407
2022-01-20 21:23:25,482 iteration 2762 : loss : 0.020968, loss_ce: 0.008472
2022-01-20 21:23:26,122 iteration 2763 : loss : 0.035795, loss_ce: 0.010693
2022-01-20 21:23:26,712 iteration 2764 : loss : 0.025493, loss_ce: 0.010200
2022-01-20 21:23:27,313 iteration 2765 : loss : 0.025545, loss_ce: 0.010666
2022-01-20 21:23:27,878 iteration 2766 : loss : 0.025079, loss_ce: 0.009981
2022-01-20 21:23:28,502 iteration 2767 : loss : 0.028832, loss_ce: 0.011034
2022-01-20 21:23:29,061 iteration 2768 : loss : 0.021903, loss_ce: 0.006401
2022-01-20 21:23:29,654 iteration 2769 : loss : 0.023700, loss_ce: 0.009683
2022-01-20 21:23:30,250 iteration 2770 : loss : 0.028198, loss_ce: 0.013236
2022-01-20 21:23:30,819 iteration 2771 : loss : 0.024065, loss_ce: 0.007767
 41%|████████████▋                  | 163/400 [29:55<41:40, 10.55s/it]2022-01-20 21:23:31,505 iteration 2772 : loss : 0.027303, loss_ce: 0.014372
2022-01-20 21:23:32,042 iteration 2773 : loss : 0.023107, loss_ce: 0.009759
2022-01-20 21:23:32,563 iteration 2774 : loss : 0.028933, loss_ce: 0.008220
2022-01-20 21:23:33,121 iteration 2775 : loss : 0.025939, loss_ce: 0.009911
2022-01-20 21:23:33,672 iteration 2776 : loss : 0.020576, loss_ce: 0.007498
2022-01-20 21:23:34,260 iteration 2777 : loss : 0.018446, loss_ce: 0.006624
2022-01-20 21:23:34,932 iteration 2778 : loss : 0.038054, loss_ce: 0.016618
2022-01-20 21:23:35,638 iteration 2779 : loss : 0.023618, loss_ce: 0.008952
2022-01-20 21:23:36,186 iteration 2780 : loss : 0.018026, loss_ce: 0.006290
2022-01-20 21:23:36,826 iteration 2781 : loss : 0.036679, loss_ce: 0.012271
2022-01-20 21:23:37,408 iteration 2782 : loss : 0.024279, loss_ce: 0.008471
2022-01-20 21:23:37,958 iteration 2783 : loss : 0.027567, loss_ce: 0.012164
2022-01-20 21:23:38,657 iteration 2784 : loss : 0.029908, loss_ce: 0.009723
2022-01-20 21:23:39,314 iteration 2785 : loss : 0.035402, loss_ce: 0.010619
2022-01-20 21:23:39,939 iteration 2786 : loss : 0.031461, loss_ce: 0.015535
2022-01-20 21:23:40,581 iteration 2787 : loss : 0.026871, loss_ce: 0.012585
2022-01-20 21:23:41,133 iteration 2788 : loss : 0.026304, loss_ce: 0.013725
 41%|████████████▋                  | 164/400 [30:06<41:12, 10.48s/it]2022-01-20 21:23:41,731 iteration 2789 : loss : 0.030936, loss_ce: 0.012175
2022-01-20 21:23:42,351 iteration 2790 : loss : 0.030883, loss_ce: 0.009769
2022-01-20 21:23:42,910 iteration 2791 : loss : 0.027317, loss_ce: 0.011842
2022-01-20 21:23:43,560 iteration 2792 : loss : 0.036636, loss_ce: 0.013788
2022-01-20 21:23:44,103 iteration 2793 : loss : 0.027933, loss_ce: 0.011191
2022-01-20 21:23:44,725 iteration 2794 : loss : 0.028708, loss_ce: 0.010386
2022-01-20 21:23:45,266 iteration 2795 : loss : 0.021455, loss_ce: 0.007557
2022-01-20 21:23:45,882 iteration 2796 : loss : 0.026669, loss_ce: 0.009789
2022-01-20 21:23:46,500 iteration 2797 : loss : 0.032718, loss_ce: 0.014829
2022-01-20 21:23:47,151 iteration 2798 : loss : 0.030732, loss_ce: 0.015605
2022-01-20 21:23:47,704 iteration 2799 : loss : 0.022079, loss_ce: 0.010001
2022-01-20 21:23:48,241 iteration 2800 : loss : 0.034798, loss_ce: 0.013207
2022-01-20 21:23:48,763 iteration 2801 : loss : 0.018531, loss_ce: 0.006005
2022-01-20 21:23:49,403 iteration 2802 : loss : 0.027970, loss_ce: 0.008449
2022-01-20 21:23:49,978 iteration 2803 : loss : 0.025259, loss_ce: 0.010563
2022-01-20 21:23:50,537 iteration 2804 : loss : 0.019652, loss_ce: 0.007048
2022-01-20 21:23:50,537 Training Data Eval:
2022-01-20 21:23:53,216   Average segmentation loss on training set: 0.0184
2022-01-20 21:23:53,216 Validation Data Eval:
2022-01-20 21:23:54,098   Average segmentation loss on validation set: 0.1028
2022-01-20 21:23:54,661 iteration 2805 : loss : 0.022315, loss_ce: 0.008989
 41%|████████████▊                  | 165/400 [30:19<44:37, 11.39s/it]2022-01-20 21:23:55,422 iteration 2806 : loss : 0.033872, loss_ce: 0.013849
2022-01-20 21:23:55,945 iteration 2807 : loss : 0.026958, loss_ce: 0.010438
2022-01-20 21:23:56,486 iteration 2808 : loss : 0.021296, loss_ce: 0.008623
2022-01-20 21:23:57,100 iteration 2809 : loss : 0.019316, loss_ce: 0.006839
2022-01-20 21:23:57,672 iteration 2810 : loss : 0.034753, loss_ce: 0.018602
2022-01-20 21:23:58,342 iteration 2811 : loss : 0.036003, loss_ce: 0.010646
2022-01-20 21:23:59,033 iteration 2812 : loss : 0.023658, loss_ce: 0.009797
2022-01-20 21:23:59,541 iteration 2813 : loss : 0.025570, loss_ce: 0.009126
2022-01-20 21:24:00,156 iteration 2814 : loss : 0.027948, loss_ce: 0.014439
2022-01-20 21:24:00,792 iteration 2815 : loss : 0.031496, loss_ce: 0.012160
2022-01-20 21:24:01,370 iteration 2816 : loss : 0.019676, loss_ce: 0.006877
2022-01-20 21:24:01,950 iteration 2817 : loss : 0.031418, loss_ce: 0.012036
2022-01-20 21:24:02,647 iteration 2818 : loss : 0.034373, loss_ce: 0.010421
2022-01-20 21:24:03,309 iteration 2819 : loss : 0.024983, loss_ce: 0.010957
2022-01-20 21:24:03,889 iteration 2820 : loss : 0.025736, loss_ce: 0.009041
2022-01-20 21:24:04,498 iteration 2821 : loss : 0.021865, loss_ce: 0.008808
2022-01-20 21:24:05,143 iteration 2822 : loss : 0.051937, loss_ce: 0.014144
 42%|████████████▊                  | 166/400 [30:30<43:21, 11.12s/it]2022-01-20 21:24:05,818 iteration 2823 : loss : 0.026049, loss_ce: 0.009187
2022-01-20 21:24:06,454 iteration 2824 : loss : 0.044058, loss_ce: 0.013085
2022-01-20 21:24:07,071 iteration 2825 : loss : 0.031273, loss_ce: 0.010601
2022-01-20 21:24:07,618 iteration 2826 : loss : 0.026591, loss_ce: 0.012457
2022-01-20 21:24:08,249 iteration 2827 : loss : 0.031629, loss_ce: 0.016928
2022-01-20 21:24:08,816 iteration 2828 : loss : 0.046035, loss_ce: 0.021924
2022-01-20 21:24:09,381 iteration 2829 : loss : 0.031831, loss_ce: 0.009864
2022-01-20 21:24:09,992 iteration 2830 : loss : 0.025269, loss_ce: 0.010769
2022-01-20 21:24:10,570 iteration 2831 : loss : 0.038913, loss_ce: 0.011112
2022-01-20 21:24:11,107 iteration 2832 : loss : 0.028094, loss_ce: 0.011809
2022-01-20 21:24:11,783 iteration 2833 : loss : 0.023745, loss_ce: 0.009936
2022-01-20 21:24:12,398 iteration 2834 : loss : 0.027974, loss_ce: 0.010972
2022-01-20 21:24:13,020 iteration 2835 : loss : 0.030835, loss_ce: 0.012327
2022-01-20 21:24:13,648 iteration 2836 : loss : 0.036067, loss_ce: 0.014423
2022-01-20 21:24:14,299 iteration 2837 : loss : 0.018254, loss_ce: 0.006537
2022-01-20 21:24:14,937 iteration 2838 : loss : 0.034016, loss_ce: 0.012595
2022-01-20 21:24:15,467 iteration 2839 : loss : 0.025329, loss_ce: 0.010909
 42%|████████████▉                  | 167/400 [30:40<42:14, 10.88s/it]2022-01-20 21:24:16,091 iteration 2840 : loss : 0.034339, loss_ce: 0.011270
2022-01-20 21:24:16,645 iteration 2841 : loss : 0.022456, loss_ce: 0.010140
2022-01-20 21:24:17,158 iteration 2842 : loss : 0.019951, loss_ce: 0.007185
2022-01-20 21:24:17,738 iteration 2843 : loss : 0.034092, loss_ce: 0.012926
2022-01-20 21:24:18,379 iteration 2844 : loss : 0.031603, loss_ce: 0.013045
2022-01-20 21:24:19,041 iteration 2845 : loss : 0.022983, loss_ce: 0.007564
2022-01-20 21:24:19,628 iteration 2846 : loss : 0.026777, loss_ce: 0.009594
2022-01-20 21:24:20,244 iteration 2847 : loss : 0.033090, loss_ce: 0.012925
2022-01-20 21:24:20,945 iteration 2848 : loss : 0.028883, loss_ce: 0.013320
2022-01-20 21:24:21,526 iteration 2849 : loss : 0.028721, loss_ce: 0.010444
2022-01-20 21:24:22,086 iteration 2850 : loss : 0.025436, loss_ce: 0.007782
2022-01-20 21:24:22,690 iteration 2851 : loss : 0.028229, loss_ce: 0.012129
2022-01-20 21:24:23,298 iteration 2852 : loss : 0.044268, loss_ce: 0.018856
2022-01-20 21:24:23,861 iteration 2853 : loss : 0.024214, loss_ce: 0.010038
2022-01-20 21:24:24,500 iteration 2854 : loss : 0.028145, loss_ce: 0.012609
2022-01-20 21:24:25,097 iteration 2855 : loss : 0.029334, loss_ce: 0.012608
2022-01-20 21:24:25,754 iteration 2856 : loss : 0.030490, loss_ce: 0.012252
 42%|█████████████                  | 168/400 [30:50<41:22, 10.70s/it]2022-01-20 21:24:26,449 iteration 2857 : loss : 0.039478, loss_ce: 0.010063
2022-01-20 21:24:27,071 iteration 2858 : loss : 0.040910, loss_ce: 0.013161
2022-01-20 21:24:27,612 iteration 2859 : loss : 0.026190, loss_ce: 0.009046
2022-01-20 21:24:28,260 iteration 2860 : loss : 0.030515, loss_ce: 0.011895
2022-01-20 21:24:28,813 iteration 2861 : loss : 0.023531, loss_ce: 0.008293
2022-01-20 21:24:29,433 iteration 2862 : loss : 0.026985, loss_ce: 0.009568
2022-01-20 21:24:30,089 iteration 2863 : loss : 0.041986, loss_ce: 0.014900
2022-01-20 21:24:30,691 iteration 2864 : loss : 0.031570, loss_ce: 0.013269
2022-01-20 21:24:31,211 iteration 2865 : loss : 0.023511, loss_ce: 0.008841
2022-01-20 21:24:31,784 iteration 2866 : loss : 0.027359, loss_ce: 0.008400
2022-01-20 21:24:32,437 iteration 2867 : loss : 0.031136, loss_ce: 0.013205
2022-01-20 21:24:33,070 iteration 2868 : loss : 0.032443, loss_ce: 0.015118
2022-01-20 21:24:33,625 iteration 2869 : loss : 0.026690, loss_ce: 0.011760
2022-01-20 21:24:34,237 iteration 2870 : loss : 0.043048, loss_ce: 0.020515
2022-01-20 21:24:34,747 iteration 2871 : loss : 0.020621, loss_ce: 0.009354
2022-01-20 21:24:35,336 iteration 2872 : loss : 0.034859, loss_ce: 0.011775
2022-01-20 21:24:35,972 iteration 2873 : loss : 0.032705, loss_ce: 0.019286
 42%|█████████████                  | 169/400 [31:00<40:39, 10.56s/it]2022-01-20 21:24:36,579 iteration 2874 : loss : 0.036592, loss_ce: 0.011550
2022-01-20 21:24:37,083 iteration 2875 : loss : 0.023168, loss_ce: 0.009112
2022-01-20 21:24:37,639 iteration 2876 : loss : 0.025373, loss_ce: 0.010216
2022-01-20 21:24:38,242 iteration 2877 : loss : 0.034020, loss_ce: 0.012856
2022-01-20 21:24:38,863 iteration 2878 : loss : 0.034932, loss_ce: 0.015318
2022-01-20 21:24:39,400 iteration 2879 : loss : 0.023165, loss_ce: 0.011285
2022-01-20 21:24:40,068 iteration 2880 : loss : 0.041941, loss_ce: 0.017886
2022-01-20 21:24:40,650 iteration 2881 : loss : 0.030233, loss_ce: 0.012179
2022-01-20 21:24:41,340 iteration 2882 : loss : 0.044294, loss_ce: 0.013986
2022-01-20 21:24:42,020 iteration 2883 : loss : 0.032678, loss_ce: 0.013254
2022-01-20 21:24:42,700 iteration 2884 : loss : 0.034589, loss_ce: 0.010157
2022-01-20 21:24:43,310 iteration 2885 : loss : 0.031358, loss_ce: 0.014884
2022-01-20 21:24:43,863 iteration 2886 : loss : 0.026759, loss_ce: 0.007700
2022-01-20 21:24:44,448 iteration 2887 : loss : 0.024174, loss_ce: 0.008381
2022-01-20 21:24:45,130 iteration 2888 : loss : 0.025325, loss_ce: 0.009200
2022-01-20 21:24:45,740 iteration 2889 : loss : 0.031514, loss_ce: 0.012882
2022-01-20 21:24:45,741 Training Data Eval:
2022-01-20 21:24:48,429   Average segmentation loss on training set: 0.0191
2022-01-20 21:24:48,429 Validation Data Eval:
2022-01-20 21:24:49,302   Average segmentation loss on validation set: 0.1213
2022-01-20 21:24:49,937 iteration 2890 : loss : 0.028186, loss_ce: 0.010891
 42%|█████████████▏                 | 170/400 [31:14<44:23, 11.58s/it]2022-01-20 21:24:50,633 iteration 2891 : loss : 0.029680, loss_ce: 0.013763
2022-01-20 21:24:51,168 iteration 2892 : loss : 0.021114, loss_ce: 0.010360
2022-01-20 21:24:51,731 iteration 2893 : loss : 0.025977, loss_ce: 0.008259
2022-01-20 21:24:52,351 iteration 2894 : loss : 0.019927, loss_ce: 0.007902
2022-01-20 21:24:52,920 iteration 2895 : loss : 0.028179, loss_ce: 0.008906
2022-01-20 21:24:53,462 iteration 2896 : loss : 0.026214, loss_ce: 0.010717
2022-01-20 21:24:54,046 iteration 2897 : loss : 0.030603, loss_ce: 0.012182
2022-01-20 21:24:54,648 iteration 2898 : loss : 0.034898, loss_ce: 0.020338
2022-01-20 21:24:55,291 iteration 2899 : loss : 0.033387, loss_ce: 0.011628
2022-01-20 21:24:55,833 iteration 2900 : loss : 0.025259, loss_ce: 0.010072
2022-01-20 21:24:56,526 iteration 2901 : loss : 0.026408, loss_ce: 0.010780
2022-01-20 21:24:57,021 iteration 2902 : loss : 0.022241, loss_ce: 0.007561
2022-01-20 21:24:57,640 iteration 2903 : loss : 0.027776, loss_ce: 0.012614
2022-01-20 21:24:58,293 iteration 2904 : loss : 0.033890, loss_ce: 0.010385
2022-01-20 21:24:58,882 iteration 2905 : loss : 0.025728, loss_ce: 0.010073
2022-01-20 21:24:59,530 iteration 2906 : loss : 0.038917, loss_ce: 0.015138
2022-01-20 21:25:00,083 iteration 2907 : loss : 0.023192, loss_ce: 0.009325
 43%|█████████████▎                 | 171/400 [31:24<42:33, 11.15s/it]2022-01-20 21:25:00,719 iteration 2908 : loss : 0.023627, loss_ce: 0.009127
2022-01-20 21:25:01,244 iteration 2909 : loss : 0.038000, loss_ce: 0.008489
2022-01-20 21:25:01,882 iteration 2910 : loss : 0.035443, loss_ce: 0.011402
2022-01-20 21:25:02,489 iteration 2911 : loss : 0.036817, loss_ce: 0.014012
2022-01-20 21:25:03,082 iteration 2912 : loss : 0.020809, loss_ce: 0.007403
2022-01-20 21:25:03,731 iteration 2913 : loss : 0.029838, loss_ce: 0.011017
2022-01-20 21:25:04,345 iteration 2914 : loss : 0.026759, loss_ce: 0.011420
2022-01-20 21:25:05,001 iteration 2915 : loss : 0.023380, loss_ce: 0.008455
2022-01-20 21:25:05,546 iteration 2916 : loss : 0.021838, loss_ce: 0.011074
2022-01-20 21:25:06,204 iteration 2917 : loss : 0.039654, loss_ce: 0.015886
2022-01-20 21:25:06,831 iteration 2918 : loss : 0.026457, loss_ce: 0.008647
2022-01-20 21:25:07,471 iteration 2919 : loss : 0.032021, loss_ce: 0.015272
2022-01-20 21:25:08,101 iteration 2920 : loss : 0.035804, loss_ce: 0.009354
2022-01-20 21:25:08,778 iteration 2921 : loss : 0.024905, loss_ce: 0.007653
2022-01-20 21:25:09,368 iteration 2922 : loss : 0.027192, loss_ce: 0.010169
2022-01-20 21:25:10,013 iteration 2923 : loss : 0.027661, loss_ce: 0.010371
2022-01-20 21:25:10,603 iteration 2924 : loss : 0.024208, loss_ce: 0.008394
 43%|█████████████▎                 | 172/400 [31:35<41:39, 10.96s/it]2022-01-20 21:25:11,352 iteration 2925 : loss : 0.053258, loss_ce: 0.024541
2022-01-20 21:25:11,932 iteration 2926 : loss : 0.024097, loss_ce: 0.008418
2022-01-20 21:25:12,609 iteration 2927 : loss : 0.030885, loss_ce: 0.013330
2022-01-20 21:25:13,342 iteration 2928 : loss : 0.045888, loss_ce: 0.013385
2022-01-20 21:25:13,922 iteration 2929 : loss : 0.029145, loss_ce: 0.010869
2022-01-20 21:25:14,498 iteration 2930 : loss : 0.036791, loss_ce: 0.016263
2022-01-20 21:25:15,021 iteration 2931 : loss : 0.028528, loss_ce: 0.010861
2022-01-20 21:25:15,688 iteration 2932 : loss : 0.023825, loss_ce: 0.008687
2022-01-20 21:25:16,265 iteration 2933 : loss : 0.031556, loss_ce: 0.011706
2022-01-20 21:25:16,910 iteration 2934 : loss : 0.036211, loss_ce: 0.016997
2022-01-20 21:25:17,521 iteration 2935 : loss : 0.038778, loss_ce: 0.013974
2022-01-20 21:25:18,190 iteration 2936 : loss : 0.022814, loss_ce: 0.010932
2022-01-20 21:25:18,774 iteration 2937 : loss : 0.022973, loss_ce: 0.010196
2022-01-20 21:25:19,369 iteration 2938 : loss : 0.029013, loss_ce: 0.011155
2022-01-20 21:25:19,947 iteration 2939 : loss : 0.025803, loss_ce: 0.010815
2022-01-20 21:25:20,575 iteration 2940 : loss : 0.027044, loss_ce: 0.008402
2022-01-20 21:25:21,164 iteration 2941 : loss : 0.026326, loss_ce: 0.009295
 43%|█████████████▍                 | 173/400 [31:46<41:00, 10.84s/it]2022-01-20 21:25:21,819 iteration 2942 : loss : 0.028501, loss_ce: 0.011350
2022-01-20 21:25:22,331 iteration 2943 : loss : 0.020187, loss_ce: 0.007972
2022-01-20 21:25:22,869 iteration 2944 : loss : 0.034089, loss_ce: 0.013949
2022-01-20 21:25:23,520 iteration 2945 : loss : 0.042360, loss_ce: 0.020032
2022-01-20 21:25:24,081 iteration 2946 : loss : 0.027948, loss_ce: 0.011557
2022-01-20 21:25:24,630 iteration 2947 : loss : 0.016463, loss_ce: 0.005769
2022-01-20 21:25:25,230 iteration 2948 : loss : 0.025969, loss_ce: 0.009884
2022-01-20 21:25:25,863 iteration 2949 : loss : 0.033116, loss_ce: 0.013650
2022-01-20 21:25:26,456 iteration 2950 : loss : 0.023596, loss_ce: 0.010544
2022-01-20 21:25:27,001 iteration 2951 : loss : 0.027126, loss_ce: 0.009786
2022-01-20 21:25:27,600 iteration 2952 : loss : 0.031667, loss_ce: 0.009664
2022-01-20 21:25:28,192 iteration 2953 : loss : 0.027896, loss_ce: 0.010708
2022-01-20 21:25:28,814 iteration 2954 : loss : 0.038647, loss_ce: 0.012183
2022-01-20 21:25:29,363 iteration 2955 : loss : 0.024035, loss_ce: 0.010695
2022-01-20 21:25:29,945 iteration 2956 : loss : 0.021757, loss_ce: 0.010439
2022-01-20 21:25:30,535 iteration 2957 : loss : 0.041017, loss_ce: 0.009513
2022-01-20 21:25:31,126 iteration 2958 : loss : 0.037424, loss_ce: 0.013095
 44%|█████████████▍                 | 174/400 [31:55<39:50, 10.58s/it]2022-01-20 21:25:31,845 iteration 2959 : loss : 0.023761, loss_ce: 0.010260
2022-01-20 21:25:32,469 iteration 2960 : loss : 0.020414, loss_ce: 0.007355
2022-01-20 21:25:33,116 iteration 2961 : loss : 0.027628, loss_ce: 0.014519
2022-01-20 21:25:33,667 iteration 2962 : loss : 0.023566, loss_ce: 0.007633
2022-01-20 21:25:34,249 iteration 2963 : loss : 0.030272, loss_ce: 0.011332
2022-01-20 21:25:34,898 iteration 2964 : loss : 0.035318, loss_ce: 0.014112
2022-01-20 21:25:35,502 iteration 2965 : loss : 0.022876, loss_ce: 0.010093
2022-01-20 21:25:36,084 iteration 2966 : loss : 0.029569, loss_ce: 0.010667
2022-01-20 21:25:36,759 iteration 2967 : loss : 0.035996, loss_ce: 0.013555
2022-01-20 21:25:37,363 iteration 2968 : loss : 0.041476, loss_ce: 0.016550
2022-01-20 21:25:37,913 iteration 2969 : loss : 0.023018, loss_ce: 0.006964
2022-01-20 21:25:38,490 iteration 2970 : loss : 0.024168, loss_ce: 0.009257
2022-01-20 21:25:39,104 iteration 2971 : loss : 0.039612, loss_ce: 0.014870
2022-01-20 21:25:39,731 iteration 2972 : loss : 0.023071, loss_ce: 0.008023
2022-01-20 21:25:40,321 iteration 2973 : loss : 0.026038, loss_ce: 0.012066
2022-01-20 21:25:41,033 iteration 2974 : loss : 0.032896, loss_ce: 0.012752
2022-01-20 21:25:41,033 Training Data Eval:
2022-01-20 21:25:43,728   Average segmentation loss on training set: 0.0186
2022-01-20 21:25:43,729 Validation Data Eval:
2022-01-20 21:25:44,609   Average segmentation loss on validation set: 0.0876
2022-01-20 21:25:45,172 iteration 2975 : loss : 0.031096, loss_ce: 0.011080
 44%|█████████████▌                 | 175/400 [32:10<43:34, 11.62s/it]2022-01-20 21:25:45,839 iteration 2976 : loss : 0.027051, loss_ce: 0.011240
2022-01-20 21:25:46,559 iteration 2977 : loss : 0.028959, loss_ce: 0.011898
2022-01-20 21:25:47,163 iteration 2978 : loss : 0.023875, loss_ce: 0.009792
2022-01-20 21:25:47,835 iteration 2979 : loss : 0.036459, loss_ce: 0.008914
2022-01-20 21:25:48,591 iteration 2980 : loss : 0.031195, loss_ce: 0.012757
2022-01-20 21:25:49,193 iteration 2981 : loss : 0.021971, loss_ce: 0.010084
2022-01-20 21:25:49,788 iteration 2982 : loss : 0.023289, loss_ce: 0.009722
2022-01-20 21:25:50,420 iteration 2983 : loss : 0.024101, loss_ce: 0.006649
2022-01-20 21:25:51,042 iteration 2984 : loss : 0.027465, loss_ce: 0.012143
2022-01-20 21:25:51,646 iteration 2985 : loss : 0.021714, loss_ce: 0.009193
2022-01-20 21:25:52,232 iteration 2986 : loss : 0.029007, loss_ce: 0.010780
2022-01-20 21:25:52,807 iteration 2987 : loss : 0.026499, loss_ce: 0.008896
2022-01-20 21:25:53,435 iteration 2988 : loss : 0.042698, loss_ce: 0.018288
2022-01-20 21:25:54,003 iteration 2989 : loss : 0.020483, loss_ce: 0.007762
2022-01-20 21:25:54,614 iteration 2990 : loss : 0.030574, loss_ce: 0.012973
2022-01-20 21:25:55,177 iteration 2991 : loss : 0.025521, loss_ce: 0.008223
2022-01-20 21:25:55,797 iteration 2992 : loss : 0.026484, loss_ce: 0.012053
 44%|█████████████▋                 | 176/400 [32:20<42:15, 11.32s/it]2022-01-20 21:25:56,462 iteration 2993 : loss : 0.035793, loss_ce: 0.012492
2022-01-20 21:25:57,048 iteration 2994 : loss : 0.021537, loss_ce: 0.008120
2022-01-20 21:25:57,683 iteration 2995 : loss : 0.039188, loss_ce: 0.017239
2022-01-20 21:25:58,237 iteration 2996 : loss : 0.026759, loss_ce: 0.010753
2022-01-20 21:25:58,828 iteration 2997 : loss : 0.020568, loss_ce: 0.006525
2022-01-20 21:25:59,453 iteration 2998 : loss : 0.019888, loss_ce: 0.009635
2022-01-20 21:26:00,046 iteration 2999 : loss : 0.033834, loss_ce: 0.010988
2022-01-20 21:26:00,630 iteration 3000 : loss : 0.027611, loss_ce: 0.010540
2022-01-20 21:26:01,306 iteration 3001 : loss : 0.026690, loss_ce: 0.012088
2022-01-20 21:26:01,953 iteration 3002 : loss : 0.031810, loss_ce: 0.011354
2022-01-20 21:26:02,485 iteration 3003 : loss : 0.026983, loss_ce: 0.011192
2022-01-20 21:26:03,078 iteration 3004 : loss : 0.023195, loss_ce: 0.011137
2022-01-20 21:26:03,653 iteration 3005 : loss : 0.023143, loss_ce: 0.009474
2022-01-20 21:26:04,230 iteration 3006 : loss : 0.030248, loss_ce: 0.013039
2022-01-20 21:26:04,839 iteration 3007 : loss : 0.024676, loss_ce: 0.007671
2022-01-20 21:26:05,385 iteration 3008 : loss : 0.022658, loss_ce: 0.008485
2022-01-20 21:26:05,936 iteration 3009 : loss : 0.027101, loss_ce: 0.006753
 44%|█████████████▋                 | 177/400 [32:30<40:45, 10.97s/it]2022-01-20 21:26:06,664 iteration 3010 : loss : 0.029233, loss_ce: 0.010645
2022-01-20 21:26:07,250 iteration 3011 : loss : 0.043640, loss_ce: 0.013701
2022-01-20 21:26:07,810 iteration 3012 : loss : 0.025098, loss_ce: 0.008541
2022-01-20 21:26:08,491 iteration 3013 : loss : 0.027827, loss_ce: 0.009054
2022-01-20 21:26:09,126 iteration 3014 : loss : 0.039941, loss_ce: 0.017064
2022-01-20 21:26:09,753 iteration 3015 : loss : 0.029776, loss_ce: 0.009875
2022-01-20 21:26:10,281 iteration 3016 : loss : 0.021837, loss_ce: 0.006869
2022-01-20 21:26:10,938 iteration 3017 : loss : 0.028612, loss_ce: 0.014759
2022-01-20 21:26:11,626 iteration 3018 : loss : 0.025610, loss_ce: 0.013336
2022-01-20 21:26:12,383 iteration 3019 : loss : 0.031977, loss_ce: 0.011933
2022-01-20 21:26:12,969 iteration 3020 : loss : 0.022988, loss_ce: 0.008053
2022-01-20 21:26:13,561 iteration 3021 : loss : 0.021478, loss_ce: 0.008533
2022-01-20 21:26:14,084 iteration 3022 : loss : 0.019335, loss_ce: 0.009250
2022-01-20 21:26:14,641 iteration 3023 : loss : 0.026758, loss_ce: 0.010730
2022-01-20 21:26:15,240 iteration 3024 : loss : 0.030704, loss_ce: 0.013420
2022-01-20 21:26:15,840 iteration 3025 : loss : 0.025788, loss_ce: 0.010203
2022-01-20 21:26:16,395 iteration 3026 : loss : 0.032296, loss_ce: 0.009348
 44%|█████████████▊                 | 178/400 [32:41<40:00, 10.81s/it]2022-01-20 21:26:17,032 iteration 3027 : loss : 0.033397, loss_ce: 0.015133
2022-01-20 21:26:17,737 iteration 3028 : loss : 0.021754, loss_ce: 0.008554
2022-01-20 21:26:18,308 iteration 3029 : loss : 0.019622, loss_ce: 0.005763
2022-01-20 21:26:18,971 iteration 3030 : loss : 0.021803, loss_ce: 0.006438
2022-01-20 21:26:19,639 iteration 3031 : loss : 0.036187, loss_ce: 0.010588
2022-01-20 21:26:20,307 iteration 3032 : loss : 0.029832, loss_ce: 0.011280
2022-01-20 21:26:20,931 iteration 3033 : loss : 0.030143, loss_ce: 0.010918
2022-01-20 21:26:21,504 iteration 3034 : loss : 0.020877, loss_ce: 0.005993
2022-01-20 21:26:22,047 iteration 3035 : loss : 0.024313, loss_ce: 0.009908
2022-01-20 21:26:22,687 iteration 3036 : loss : 0.028996, loss_ce: 0.013183
2022-01-20 21:26:23,236 iteration 3037 : loss : 0.025379, loss_ce: 0.010645
2022-01-20 21:26:23,762 iteration 3038 : loss : 0.023201, loss_ce: 0.010504
2022-01-20 21:26:24,307 iteration 3039 : loss : 0.021435, loss_ce: 0.007690
2022-01-20 21:26:24,968 iteration 3040 : loss : 0.035737, loss_ce: 0.010832
2022-01-20 21:26:25,460 iteration 3041 : loss : 0.023312, loss_ce: 0.009128
2022-01-20 21:26:26,006 iteration 3042 : loss : 0.025551, loss_ce: 0.011491
2022-01-20 21:26:26,548 iteration 3043 : loss : 0.021254, loss_ce: 0.008596
 45%|█████████████▊                 | 179/400 [32:51<39:06, 10.62s/it]2022-01-20 21:26:27,210 iteration 3044 : loss : 0.024208, loss_ce: 0.010484
2022-01-20 21:26:27,728 iteration 3045 : loss : 0.024339, loss_ce: 0.009217
2022-01-20 21:26:28,410 iteration 3046 : loss : 0.029768, loss_ce: 0.013733
2022-01-20 21:26:29,097 iteration 3047 : loss : 0.029439, loss_ce: 0.009418
2022-01-20 21:26:29,726 iteration 3048 : loss : 0.024754, loss_ce: 0.008460
2022-01-20 21:26:30,352 iteration 3049 : loss : 0.022873, loss_ce: 0.007431
2022-01-20 21:26:30,994 iteration 3050 : loss : 0.034044, loss_ce: 0.008692
2022-01-20 21:26:31,670 iteration 3051 : loss : 0.023707, loss_ce: 0.008732
2022-01-20 21:26:32,302 iteration 3052 : loss : 0.027525, loss_ce: 0.012339
2022-01-20 21:26:32,825 iteration 3053 : loss : 0.019824, loss_ce: 0.007083
2022-01-20 21:26:33,382 iteration 3054 : loss : 0.028635, loss_ce: 0.011860
2022-01-20 21:26:33,907 iteration 3055 : loss : 0.033628, loss_ce: 0.014024
2022-01-20 21:26:34,425 iteration 3056 : loss : 0.020439, loss_ce: 0.006627
2022-01-20 21:26:35,144 iteration 3057 : loss : 0.038127, loss_ce: 0.013405
2022-01-20 21:26:35,706 iteration 3058 : loss : 0.023800, loss_ce: 0.007788
2022-01-20 21:26:36,272 iteration 3059 : loss : 0.024398, loss_ce: 0.013619
2022-01-20 21:26:36,272 Training Data Eval:
2022-01-20 21:26:38,964   Average segmentation loss on training set: 0.0184
2022-01-20 21:26:38,964 Validation Data Eval:
2022-01-20 21:26:39,845   Average segmentation loss on validation set: 0.0860
2022-01-20 21:26:40,475 iteration 3060 : loss : 0.029140, loss_ce: 0.011963
 45%|█████████████▉                 | 180/400 [33:05<42:33, 11.61s/it]2022-01-20 21:26:41,121 iteration 3061 : loss : 0.029623, loss_ce: 0.010044
2022-01-20 21:26:41,748 iteration 3062 : loss : 0.026675, loss_ce: 0.011945
2022-01-20 21:26:42,323 iteration 3063 : loss : 0.019197, loss_ce: 0.008118
2022-01-20 21:26:42,918 iteration 3064 : loss : 0.042453, loss_ce: 0.022726
2022-01-20 21:26:43,551 iteration 3065 : loss : 0.025881, loss_ce: 0.007652
2022-01-20 21:26:44,109 iteration 3066 : loss : 0.024656, loss_ce: 0.007571
2022-01-20 21:26:44,767 iteration 3067 : loss : 0.026292, loss_ce: 0.010393
2022-01-20 21:26:45,452 iteration 3068 : loss : 0.026068, loss_ce: 0.010483
2022-01-20 21:26:45,998 iteration 3069 : loss : 0.016773, loss_ce: 0.006151
2022-01-20 21:26:46,600 iteration 3070 : loss : 0.028202, loss_ce: 0.010361
2022-01-20 21:26:47,339 iteration 3071 : loss : 0.033660, loss_ce: 0.010793
2022-01-20 21:26:47,926 iteration 3072 : loss : 0.021287, loss_ce: 0.008051
2022-01-20 21:26:48,503 iteration 3073 : loss : 0.034628, loss_ce: 0.011482
2022-01-20 21:26:49,088 iteration 3074 : loss : 0.027879, loss_ce: 0.011191
2022-01-20 21:26:49,706 iteration 3075 : loss : 0.037954, loss_ce: 0.011862
2022-01-20 21:26:50,254 iteration 3076 : loss : 0.018444, loss_ce: 0.006985
2022-01-20 21:26:50,941 iteration 3077 : loss : 0.039118, loss_ce: 0.015912
 45%|██████████████                 | 181/400 [33:15<41:07, 11.26s/it]2022-01-20 21:26:51,637 iteration 3078 : loss : 0.050791, loss_ce: 0.010257
2022-01-20 21:26:52,219 iteration 3079 : loss : 0.021825, loss_ce: 0.006571
2022-01-20 21:26:52,807 iteration 3080 : loss : 0.022538, loss_ce: 0.006831
2022-01-20 21:26:53,417 iteration 3081 : loss : 0.034172, loss_ce: 0.012392
2022-01-20 21:26:54,024 iteration 3082 : loss : 0.034948, loss_ce: 0.011628
2022-01-20 21:26:54,624 iteration 3083 : loss : 0.042539, loss_ce: 0.012944
2022-01-20 21:26:55,250 iteration 3084 : loss : 0.033269, loss_ce: 0.013019
2022-01-20 21:26:55,780 iteration 3085 : loss : 0.025879, loss_ce: 0.010809
2022-01-20 21:26:56,353 iteration 3086 : loss : 0.029125, loss_ce: 0.015184
2022-01-20 21:26:56,988 iteration 3087 : loss : 0.031321, loss_ce: 0.013922
2022-01-20 21:26:57,580 iteration 3088 : loss : 0.032754, loss_ce: 0.015781
2022-01-20 21:26:58,253 iteration 3089 : loss : 0.045088, loss_ce: 0.014891
2022-01-20 21:26:58,790 iteration 3090 : loss : 0.027822, loss_ce: 0.011585
2022-01-20 21:26:59,425 iteration 3091 : loss : 0.027696, loss_ce: 0.010850
2022-01-20 21:26:59,982 iteration 3092 : loss : 0.031416, loss_ce: 0.012634
2022-01-20 21:27:00,533 iteration 3093 : loss : 0.021789, loss_ce: 0.008814
2022-01-20 21:27:01,121 iteration 3094 : loss : 0.046325, loss_ce: 0.011783
 46%|██████████████                 | 182/400 [33:25<39:44, 10.94s/it]2022-01-20 21:27:01,797 iteration 3095 : loss : 0.023390, loss_ce: 0.009359
2022-01-20 21:27:02,408 iteration 3096 : loss : 0.025553, loss_ce: 0.008928
2022-01-20 21:27:03,034 iteration 3097 : loss : 0.034875, loss_ce: 0.015259
2022-01-20 21:27:03,673 iteration 3098 : loss : 0.049409, loss_ce: 0.013260
2022-01-20 21:27:04,313 iteration 3099 : loss : 0.033671, loss_ce: 0.016548
2022-01-20 21:27:04,921 iteration 3100 : loss : 0.024937, loss_ce: 0.008956
2022-01-20 21:27:05,485 iteration 3101 : loss : 0.021154, loss_ce: 0.008781
2022-01-20 21:27:05,997 iteration 3102 : loss : 0.023787, loss_ce: 0.009115
2022-01-20 21:27:06,627 iteration 3103 : loss : 0.033185, loss_ce: 0.015092
2022-01-20 21:27:07,213 iteration 3104 : loss : 0.032763, loss_ce: 0.009918
2022-01-20 21:27:07,849 iteration 3105 : loss : 0.019994, loss_ce: 0.007948
2022-01-20 21:27:08,455 iteration 3106 : loss : 0.029729, loss_ce: 0.012142
2022-01-20 21:27:09,112 iteration 3107 : loss : 0.024421, loss_ce: 0.010465
2022-01-20 21:27:09,739 iteration 3108 : loss : 0.032299, loss_ce: 0.011413
2022-01-20 21:27:10,272 iteration 3109 : loss : 0.026285, loss_ce: 0.012038
2022-01-20 21:27:10,848 iteration 3110 : loss : 0.033388, loss_ce: 0.012850
2022-01-20 21:27:11,457 iteration 3111 : loss : 0.033234, loss_ce: 0.009078
 46%|██████████████▏                | 183/400 [33:36<38:55, 10.76s/it]2022-01-20 21:27:12,058 iteration 3112 : loss : 0.027356, loss_ce: 0.010663
2022-01-20 21:27:12,684 iteration 3113 : loss : 0.031851, loss_ce: 0.011642
2022-01-20 21:27:13,245 iteration 3114 : loss : 0.027117, loss_ce: 0.012129
2022-01-20 21:27:13,869 iteration 3115 : loss : 0.026881, loss_ce: 0.007983
2022-01-20 21:27:14,397 iteration 3116 : loss : 0.029877, loss_ce: 0.011528
2022-01-20 21:27:15,063 iteration 3117 : loss : 0.031023, loss_ce: 0.008094
2022-01-20 21:27:15,673 iteration 3118 : loss : 0.022717, loss_ce: 0.009663
2022-01-20 21:27:16,280 iteration 3119 : loss : 0.027096, loss_ce: 0.011413
2022-01-20 21:27:16,817 iteration 3120 : loss : 0.032526, loss_ce: 0.008957
2022-01-20 21:27:17,439 iteration 3121 : loss : 0.029228, loss_ce: 0.009258
2022-01-20 21:27:18,022 iteration 3122 : loss : 0.036398, loss_ce: 0.016523
2022-01-20 21:27:18,730 iteration 3123 : loss : 0.039595, loss_ce: 0.015974
2022-01-20 21:27:19,290 iteration 3124 : loss : 0.029976, loss_ce: 0.009538
2022-01-20 21:27:19,845 iteration 3125 : loss : 0.017335, loss_ce: 0.007349
2022-01-20 21:27:20,403 iteration 3126 : loss : 0.023319, loss_ce: 0.008961
2022-01-20 21:27:20,972 iteration 3127 : loss : 0.027028, loss_ce: 0.012541
2022-01-20 21:27:21,553 iteration 3128 : loss : 0.035825, loss_ce: 0.008758
 46%|██████████████▎                | 184/400 [33:46<38:01, 10.56s/it]2022-01-20 21:27:22,159 iteration 3129 : loss : 0.039052, loss_ce: 0.014688
2022-01-20 21:27:22,720 iteration 3130 : loss : 0.023435, loss_ce: 0.008439
2022-01-20 21:27:23,367 iteration 3131 : loss : 0.032074, loss_ce: 0.014608
2022-01-20 21:27:23,990 iteration 3132 : loss : 0.028249, loss_ce: 0.009398
2022-01-20 21:27:24,547 iteration 3133 : loss : 0.020651, loss_ce: 0.008788
2022-01-20 21:27:25,184 iteration 3134 : loss : 0.028221, loss_ce: 0.012620
2022-01-20 21:27:25,829 iteration 3135 : loss : 0.031221, loss_ce: 0.007804
2022-01-20 21:27:26,379 iteration 3136 : loss : 0.020752, loss_ce: 0.009187
2022-01-20 21:27:26,931 iteration 3137 : loss : 0.019158, loss_ce: 0.008181
2022-01-20 21:27:27,505 iteration 3138 : loss : 0.023327, loss_ce: 0.009363
2022-01-20 21:27:28,227 iteration 3139 : loss : 0.039845, loss_ce: 0.010994
2022-01-20 21:27:28,854 iteration 3140 : loss : 0.024471, loss_ce: 0.008594
2022-01-20 21:27:29,430 iteration 3141 : loss : 0.026461, loss_ce: 0.011157
2022-01-20 21:27:29,959 iteration 3142 : loss : 0.022690, loss_ce: 0.008238
2022-01-20 21:27:30,569 iteration 3143 : loss : 0.035564, loss_ce: 0.009807
2022-01-20 21:27:31,218 iteration 3144 : loss : 0.029885, loss_ce: 0.007423
2022-01-20 21:27:31,219 Training Data Eval:
2022-01-20 21:27:33,897   Average segmentation loss on training set: 0.0183
2022-01-20 21:27:33,898 Validation Data Eval:
2022-01-20 21:27:34,773   Average segmentation loss on validation set: 0.1211
2022-01-20 21:27:35,307 iteration 3145 : loss : 0.024245, loss_ce: 0.010873
 46%|██████████████▎                | 185/400 [34:00<41:16, 11.52s/it]2022-01-20 21:27:36,035 iteration 3146 : loss : 0.028099, loss_ce: 0.010397
2022-01-20 21:27:36,701 iteration 3147 : loss : 0.031230, loss_ce: 0.014636
2022-01-20 21:27:37,241 iteration 3148 : loss : 0.021558, loss_ce: 0.007810
2022-01-20 21:27:37,845 iteration 3149 : loss : 0.036110, loss_ce: 0.010432
2022-01-20 21:27:38,449 iteration 3150 : loss : 0.030896, loss_ce: 0.009922
2022-01-20 21:27:38,961 iteration 3151 : loss : 0.022268, loss_ce: 0.009514
2022-01-20 21:27:39,596 iteration 3152 : loss : 0.022730, loss_ce: 0.010952
2022-01-20 21:27:40,168 iteration 3153 : loss : 0.023975, loss_ce: 0.010973
2022-01-20 21:27:40,773 iteration 3154 : loss : 0.028953, loss_ce: 0.007899
2022-01-20 21:27:41,377 iteration 3155 : loss : 0.019684, loss_ce: 0.006375
2022-01-20 21:27:41,999 iteration 3156 : loss : 0.029202, loss_ce: 0.010521
2022-01-20 21:27:42,523 iteration 3157 : loss : 0.032160, loss_ce: 0.008405
2022-01-20 21:27:43,192 iteration 3158 : loss : 0.024200, loss_ce: 0.009146
2022-01-20 21:27:43,786 iteration 3159 : loss : 0.030337, loss_ce: 0.012097
2022-01-20 21:27:44,370 iteration 3160 : loss : 0.025213, loss_ce: 0.012490
2022-01-20 21:27:45,049 iteration 3161 : loss : 0.027605, loss_ce: 0.009108
2022-01-20 21:27:45,749 iteration 3162 : loss : 0.025539, loss_ce: 0.012029
 46%|██████████████▍                | 186/400 [34:10<39:55, 11.20s/it]2022-01-20 21:27:46,345 iteration 3163 : loss : 0.022776, loss_ce: 0.007315
2022-01-20 21:27:46,896 iteration 3164 : loss : 0.024293, loss_ce: 0.008170
2022-01-20 21:27:47,470 iteration 3165 : loss : 0.016858, loss_ce: 0.007119
2022-01-20 21:27:48,070 iteration 3166 : loss : 0.026989, loss_ce: 0.013390
2022-01-20 21:27:48,685 iteration 3167 : loss : 0.051505, loss_ce: 0.016102
2022-01-20 21:27:49,228 iteration 3168 : loss : 0.019564, loss_ce: 0.009422
2022-01-20 21:27:49,825 iteration 3169 : loss : 0.019534, loss_ce: 0.007412
2022-01-20 21:27:50,443 iteration 3170 : loss : 0.021892, loss_ce: 0.009046
2022-01-20 21:27:51,094 iteration 3171 : loss : 0.033524, loss_ce: 0.010183
2022-01-20 21:27:51,728 iteration 3172 : loss : 0.026123, loss_ce: 0.010934
2022-01-20 21:27:52,358 iteration 3173 : loss : 0.021035, loss_ce: 0.007592
2022-01-20 21:27:53,010 iteration 3174 : loss : 0.031622, loss_ce: 0.011425
2022-01-20 21:27:53,604 iteration 3175 : loss : 0.026288, loss_ce: 0.009654
2022-01-20 21:27:54,219 iteration 3176 : loss : 0.023656, loss_ce: 0.011375
2022-01-20 21:27:54,775 iteration 3177 : loss : 0.024505, loss_ce: 0.010972
2022-01-20 21:27:55,382 iteration 3178 : loss : 0.032910, loss_ce: 0.009792
2022-01-20 21:27:56,018 iteration 3179 : loss : 0.036867, loss_ce: 0.009862
 47%|██████████████▍                | 187/400 [34:20<38:45, 10.92s/it]2022-01-20 21:27:56,729 iteration 3180 : loss : 0.023321, loss_ce: 0.009806
2022-01-20 21:27:57,346 iteration 3181 : loss : 0.031299, loss_ce: 0.013799
2022-01-20 21:27:57,999 iteration 3182 : loss : 0.029619, loss_ce: 0.011352
2022-01-20 21:27:58,660 iteration 3183 : loss : 0.034953, loss_ce: 0.015068
2022-01-20 21:27:59,180 iteration 3184 : loss : 0.020157, loss_ce: 0.008911
2022-01-20 21:27:59,719 iteration 3185 : loss : 0.027850, loss_ce: 0.011459
2022-01-20 21:28:00,275 iteration 3186 : loss : 0.027125, loss_ce: 0.014585
2022-01-20 21:28:00,816 iteration 3187 : loss : 0.019530, loss_ce: 0.006652
2022-01-20 21:28:01,409 iteration 3188 : loss : 0.026701, loss_ce: 0.008248
2022-01-20 21:28:01,945 iteration 3189 : loss : 0.019483, loss_ce: 0.009328
2022-01-20 21:28:02,581 iteration 3190 : loss : 0.035087, loss_ce: 0.011785
2022-01-20 21:28:03,202 iteration 3191 : loss : 0.028433, loss_ce: 0.010236
2022-01-20 21:28:03,786 iteration 3192 : loss : 0.020573, loss_ce: 0.008274
2022-01-20 21:28:04,333 iteration 3193 : loss : 0.025676, loss_ce: 0.010211
2022-01-20 21:28:04,856 iteration 3194 : loss : 0.024497, loss_ce: 0.007969
2022-01-20 21:28:05,437 iteration 3195 : loss : 0.026229, loss_ce: 0.007020
2022-01-20 21:28:06,080 iteration 3196 : loss : 0.020042, loss_ce: 0.005572
 47%|██████████████▌                | 188/400 [34:30<37:40, 10.66s/it]2022-01-20 21:28:06,705 iteration 3197 : loss : 0.020087, loss_ce: 0.006549
2022-01-20 21:28:07,257 iteration 3198 : loss : 0.027362, loss_ce: 0.008792
2022-01-20 21:28:07,788 iteration 3199 : loss : 0.023164, loss_ce: 0.009060
2022-01-20 21:28:08,340 iteration 3200 : loss : 0.021892, loss_ce: 0.008639
2022-01-20 21:28:08,959 iteration 3201 : loss : 0.027125, loss_ce: 0.009932
2022-01-20 21:28:09,573 iteration 3202 : loss : 0.024050, loss_ce: 0.009532
2022-01-20 21:28:10,097 iteration 3203 : loss : 0.041548, loss_ce: 0.010898
2022-01-20 21:28:10,712 iteration 3204 : loss : 0.032748, loss_ce: 0.017005
2022-01-20 21:28:11,335 iteration 3205 : loss : 0.021670, loss_ce: 0.007452
2022-01-20 21:28:11,889 iteration 3206 : loss : 0.023952, loss_ce: 0.009293
2022-01-20 21:28:12,425 iteration 3207 : loss : 0.021907, loss_ce: 0.006668
2022-01-20 21:28:12,976 iteration 3208 : loss : 0.027331, loss_ce: 0.009914
2022-01-20 21:28:13,600 iteration 3209 : loss : 0.020269, loss_ce: 0.008299
2022-01-20 21:28:14,197 iteration 3210 : loss : 0.033143, loss_ce: 0.010662
2022-01-20 21:28:14,836 iteration 3211 : loss : 0.027217, loss_ce: 0.012337
2022-01-20 21:28:15,465 iteration 3212 : loss : 0.024603, loss_ce: 0.009615
2022-01-20 21:28:16,045 iteration 3213 : loss : 0.030898, loss_ce: 0.017849
 47%|██████████████▋                | 189/400 [34:40<36:45, 10.45s/it]2022-01-20 21:28:16,665 iteration 3214 : loss : 0.038748, loss_ce: 0.013488
2022-01-20 21:28:17,225 iteration 3215 : loss : 0.019011, loss_ce: 0.008015
2022-01-20 21:28:17,806 iteration 3216 : loss : 0.023758, loss_ce: 0.010251
2022-01-20 21:28:18,438 iteration 3217 : loss : 0.035280, loss_ce: 0.009254
2022-01-20 21:28:18,990 iteration 3218 : loss : 0.022647, loss_ce: 0.009130
2022-01-20 21:28:19,542 iteration 3219 : loss : 0.022252, loss_ce: 0.007038
2022-01-20 21:28:20,146 iteration 3220 : loss : 0.031426, loss_ce: 0.015153
2022-01-20 21:28:20,759 iteration 3221 : loss : 0.029364, loss_ce: 0.009441
2022-01-20 21:28:21,300 iteration 3222 : loss : 0.024200, loss_ce: 0.008494
2022-01-20 21:28:21,904 iteration 3223 : loss : 0.042054, loss_ce: 0.009493
2022-01-20 21:28:22,486 iteration 3224 : loss : 0.021218, loss_ce: 0.008050
2022-01-20 21:28:23,012 iteration 3225 : loss : 0.033097, loss_ce: 0.010910
2022-01-20 21:28:23,598 iteration 3226 : loss : 0.032587, loss_ce: 0.013227
2022-01-20 21:28:24,204 iteration 3227 : loss : 0.040635, loss_ce: 0.012553
2022-01-20 21:28:24,793 iteration 3228 : loss : 0.027392, loss_ce: 0.010800
2022-01-20 21:28:25,408 iteration 3229 : loss : 0.029361, loss_ce: 0.011192
2022-01-20 21:28:25,408 Training Data Eval:
2022-01-20 21:28:28,097   Average segmentation loss on training set: 0.0215
2022-01-20 21:28:28,098 Validation Data Eval:
2022-01-20 21:28:28,984   Average segmentation loss on validation set: 0.0830
2022-01-20 21:28:29,564 iteration 3230 : loss : 0.028326, loss_ce: 0.017051
 48%|██████████████▋                | 190/400 [34:54<39:48, 11.37s/it]2022-01-20 21:28:30,114 iteration 3231 : loss : 0.029732, loss_ce: 0.010735
2022-01-20 21:28:30,729 iteration 3232 : loss : 0.023372, loss_ce: 0.009287
2022-01-20 21:28:31,345 iteration 3233 : loss : 0.038429, loss_ce: 0.009348
2022-01-20 21:28:31,918 iteration 3234 : loss : 0.022799, loss_ce: 0.008397
2022-01-20 21:28:32,529 iteration 3235 : loss : 0.024744, loss_ce: 0.009168
2022-01-20 21:28:33,022 iteration 3236 : loss : 0.022497, loss_ce: 0.011066
2022-01-20 21:28:33,591 iteration 3237 : loss : 0.022352, loss_ce: 0.008321
2022-01-20 21:28:34,185 iteration 3238 : loss : 0.029041, loss_ce: 0.011807
2022-01-20 21:28:34,699 iteration 3239 : loss : 0.031213, loss_ce: 0.014250
2022-01-20 21:28:35,340 iteration 3240 : loss : 0.028507, loss_ce: 0.010144
2022-01-20 21:28:36,032 iteration 3241 : loss : 0.036655, loss_ce: 0.010337
2022-01-20 21:28:36,648 iteration 3242 : loss : 0.026712, loss_ce: 0.010024
2022-01-20 21:28:37,286 iteration 3243 : loss : 0.022750, loss_ce: 0.010074
2022-01-20 21:28:37,832 iteration 3244 : loss : 0.026060, loss_ce: 0.008036
2022-01-20 21:28:38,438 iteration 3245 : loss : 0.034968, loss_ce: 0.011826
2022-01-20 21:28:39,063 iteration 3246 : loss : 0.030669, loss_ce: 0.009634
2022-01-20 21:28:39,761 iteration 3247 : loss : 0.040165, loss_ce: 0.014651
 48%|██████████████▊                | 191/400 [35:04<38:23, 11.02s/it]2022-01-20 21:28:40,448 iteration 3248 : loss : 0.044211, loss_ce: 0.012170
2022-01-20 21:28:41,089 iteration 3249 : loss : 0.024997, loss_ce: 0.008763
2022-01-20 21:28:41,688 iteration 3250 : loss : 0.036439, loss_ce: 0.013440
2022-01-20 21:28:42,293 iteration 3251 : loss : 0.028756, loss_ce: 0.010702
2022-01-20 21:28:42,788 iteration 3252 : loss : 0.020853, loss_ce: 0.010218
2022-01-20 21:28:43,359 iteration 3253 : loss : 0.033103, loss_ce: 0.012691
2022-01-20 21:28:43,993 iteration 3254 : loss : 0.030483, loss_ce: 0.013663
2022-01-20 21:28:44,593 iteration 3255 : loss : 0.027581, loss_ce: 0.011473
2022-01-20 21:28:45,223 iteration 3256 : loss : 0.031320, loss_ce: 0.011304
2022-01-20 21:28:45,831 iteration 3257 : loss : 0.031613, loss_ce: 0.016788
2022-01-20 21:28:46,372 iteration 3258 : loss : 0.022326, loss_ce: 0.006030
2022-01-20 21:28:46,972 iteration 3259 : loss : 0.030942, loss_ce: 0.011078
2022-01-20 21:28:47,588 iteration 3260 : loss : 0.022792, loss_ce: 0.008807
2022-01-20 21:28:48,171 iteration 3261 : loss : 0.021881, loss_ce: 0.009032
2022-01-20 21:28:48,849 iteration 3262 : loss : 0.034177, loss_ce: 0.014231
2022-01-20 21:28:49,420 iteration 3263 : loss : 0.028904, loss_ce: 0.013100
2022-01-20 21:28:50,089 iteration 3264 : loss : 0.042399, loss_ce: 0.014328
 48%|██████████████▉                | 192/400 [35:14<37:28, 10.81s/it]2022-01-20 21:28:50,703 iteration 3265 : loss : 0.026378, loss_ce: 0.010617
2022-01-20 21:28:51,333 iteration 3266 : loss : 0.026747, loss_ce: 0.008683
2022-01-20 21:28:51,944 iteration 3267 : loss : 0.028774, loss_ce: 0.008150
2022-01-20 21:28:52,557 iteration 3268 : loss : 0.025732, loss_ce: 0.009150
2022-01-20 21:28:53,109 iteration 3269 : loss : 0.022177, loss_ce: 0.011439
2022-01-20 21:28:53,709 iteration 3270 : loss : 0.026614, loss_ce: 0.009801
2022-01-20 21:28:54,216 iteration 3271 : loss : 0.029935, loss_ce: 0.009290
2022-01-20 21:28:54,874 iteration 3272 : loss : 0.032556, loss_ce: 0.013098
2022-01-20 21:28:55,456 iteration 3273 : loss : 0.027054, loss_ce: 0.012774
2022-01-20 21:28:55,977 iteration 3274 : loss : 0.024060, loss_ce: 0.008248
2022-01-20 21:28:56,540 iteration 3275 : loss : 0.028113, loss_ce: 0.010088
2022-01-20 21:28:57,104 iteration 3276 : loss : 0.030225, loss_ce: 0.008315
2022-01-20 21:28:57,627 iteration 3277 : loss : 0.022044, loss_ce: 0.008394
2022-01-20 21:28:58,200 iteration 3278 : loss : 0.031128, loss_ce: 0.013981
2022-01-20 21:28:58,690 iteration 3279 : loss : 0.025252, loss_ce: 0.013911
2022-01-20 21:28:59,349 iteration 3280 : loss : 0.032136, loss_ce: 0.012800
2022-01-20 21:28:59,938 iteration 3281 : loss : 0.019040, loss_ce: 0.006029
 48%|██████████████▉                | 193/400 [35:24<36:17, 10.52s/it]2022-01-20 21:29:00,609 iteration 3282 : loss : 0.038196, loss_ce: 0.007896
2022-01-20 21:29:01,236 iteration 3283 : loss : 0.031029, loss_ce: 0.010197
2022-01-20 21:29:01,841 iteration 3284 : loss : 0.028341, loss_ce: 0.010218
2022-01-20 21:29:02,462 iteration 3285 : loss : 0.043629, loss_ce: 0.014357
2022-01-20 21:29:03,048 iteration 3286 : loss : 0.022806, loss_ce: 0.006956
2022-01-20 21:29:03,719 iteration 3287 : loss : 0.032147, loss_ce: 0.013968
2022-01-20 21:29:04,254 iteration 3288 : loss : 0.030202, loss_ce: 0.011547
2022-01-20 21:29:04,945 iteration 3289 : loss : 0.029635, loss_ce: 0.013994
2022-01-20 21:29:05,601 iteration 3290 : loss : 0.029477, loss_ce: 0.010369
2022-01-20 21:29:06,267 iteration 3291 : loss : 0.028470, loss_ce: 0.013959
2022-01-20 21:29:06,856 iteration 3292 : loss : 0.034385, loss_ce: 0.012279
2022-01-20 21:29:07,438 iteration 3293 : loss : 0.061061, loss_ce: 0.014325
2022-01-20 21:29:08,129 iteration 3294 : loss : 0.028567, loss_ce: 0.013080
2022-01-20 21:29:08,771 iteration 3295 : loss : 0.024920, loss_ce: 0.010128
2022-01-20 21:29:09,312 iteration 3296 : loss : 0.027250, loss_ce: 0.009579
2022-01-20 21:29:09,876 iteration 3297 : loss : 0.024004, loss_ce: 0.009361
2022-01-20 21:29:10,561 iteration 3298 : loss : 0.026245, loss_ce: 0.012119
 48%|███████████████                | 194/400 [35:35<36:14, 10.55s/it]2022-01-20 21:29:11,123 iteration 3299 : loss : 0.021403, loss_ce: 0.005786
2022-01-20 21:29:11,757 iteration 3300 : loss : 0.031526, loss_ce: 0.010757
2022-01-20 21:29:12,359 iteration 3301 : loss : 0.021006, loss_ce: 0.009733
2022-01-20 21:29:12,926 iteration 3302 : loss : 0.024960, loss_ce: 0.007873
2022-01-20 21:29:13,581 iteration 3303 : loss : 0.031467, loss_ce: 0.013431
2022-01-20 21:29:14,213 iteration 3304 : loss : 0.023862, loss_ce: 0.009727
2022-01-20 21:29:14,792 iteration 3305 : loss : 0.021502, loss_ce: 0.008041
2022-01-20 21:29:15,376 iteration 3306 : loss : 0.025956, loss_ce: 0.006775
2022-01-20 21:29:16,088 iteration 3307 : loss : 0.046107, loss_ce: 0.021713
2022-01-20 21:29:16,746 iteration 3308 : loss : 0.026438, loss_ce: 0.011509
2022-01-20 21:29:17,392 iteration 3309 : loss : 0.025373, loss_ce: 0.011922
2022-01-20 21:29:17,940 iteration 3310 : loss : 0.023000, loss_ce: 0.011905
2022-01-20 21:29:18,612 iteration 3311 : loss : 0.043798, loss_ce: 0.014078
2022-01-20 21:29:19,210 iteration 3312 : loss : 0.050296, loss_ce: 0.013104
2022-01-20 21:29:19,882 iteration 3313 : loss : 0.029604, loss_ce: 0.012316
2022-01-20 21:29:20,482 iteration 3314 : loss : 0.024219, loss_ce: 0.007871
2022-01-20 21:29:20,483 Training Data Eval:
2022-01-20 21:29:23,173   Average segmentation loss on training set: 0.0184
2022-01-20 21:29:23,173 Validation Data Eval:
2022-01-20 21:29:24,048   Average segmentation loss on validation set: 0.0785
2022-01-20 21:29:24,649 Found new lowest validation loss at iteration 3314! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:29:25,190 iteration 3315 : loss : 0.021757, loss_ce: 0.008314
 49%|███████████████                | 195/400 [35:50<40:14, 11.78s/it]2022-01-20 21:29:25,779 iteration 3316 : loss : 0.020804, loss_ce: 0.008628
2022-01-20 21:29:26,379 iteration 3317 : loss : 0.027427, loss_ce: 0.012439
2022-01-20 21:29:26,955 iteration 3318 : loss : 0.038475, loss_ce: 0.016005
2022-01-20 21:29:27,495 iteration 3319 : loss : 0.030474, loss_ce: 0.010504
2022-01-20 21:29:28,177 iteration 3320 : loss : 0.043609, loss_ce: 0.015630
2022-01-20 21:29:28,746 iteration 3321 : loss : 0.026271, loss_ce: 0.010690
2022-01-20 21:29:29,400 iteration 3322 : loss : 0.028356, loss_ce: 0.009285
2022-01-20 21:29:29,947 iteration 3323 : loss : 0.022754, loss_ce: 0.007689
2022-01-20 21:29:30,539 iteration 3324 : loss : 0.024199, loss_ce: 0.010966
2022-01-20 21:29:31,175 iteration 3325 : loss : 0.030685, loss_ce: 0.011646
2022-01-20 21:29:31,733 iteration 3326 : loss : 0.024571, loss_ce: 0.009316
2022-01-20 21:29:32,320 iteration 3327 : loss : 0.021708, loss_ce: 0.006867
2022-01-20 21:29:32,979 iteration 3328 : loss : 0.024485, loss_ce: 0.008423
2022-01-20 21:29:33,572 iteration 3329 : loss : 0.028386, loss_ce: 0.010523
2022-01-20 21:29:34,133 iteration 3330 : loss : 0.025150, loss_ce: 0.014579
2022-01-20 21:29:34,649 iteration 3331 : loss : 0.023108, loss_ce: 0.010389
2022-01-20 21:29:35,267 iteration 3332 : loss : 0.018835, loss_ce: 0.005579
 49%|███████████████▏               | 196/400 [36:00<38:18, 11.27s/it]2022-01-20 21:29:35,938 iteration 3333 : loss : 0.033836, loss_ce: 0.012845
2022-01-20 21:29:36,561 iteration 3334 : loss : 0.029040, loss_ce: 0.013006
2022-01-20 21:29:37,245 iteration 3335 : loss : 0.034748, loss_ce: 0.015431
2022-01-20 21:29:37,849 iteration 3336 : loss : 0.044813, loss_ce: 0.015273
2022-01-20 21:29:38,495 iteration 3337 : loss : 0.026926, loss_ce: 0.011896
2022-01-20 21:29:39,203 iteration 3338 : loss : 0.028560, loss_ce: 0.013588
2022-01-20 21:29:39,746 iteration 3339 : loss : 0.026748, loss_ce: 0.010888
2022-01-20 21:29:40,274 iteration 3340 : loss : 0.044261, loss_ce: 0.010789
2022-01-20 21:29:40,869 iteration 3341 : loss : 0.038361, loss_ce: 0.012616
2022-01-20 21:29:41,442 iteration 3342 : loss : 0.024807, loss_ce: 0.010569
2022-01-20 21:29:42,069 iteration 3343 : loss : 0.022812, loss_ce: 0.009901
2022-01-20 21:29:42,666 iteration 3344 : loss : 0.027481, loss_ce: 0.009203
2022-01-20 21:29:43,275 iteration 3345 : loss : 0.027958, loss_ce: 0.012520
2022-01-20 21:29:43,834 iteration 3346 : loss : 0.034980, loss_ce: 0.015001
2022-01-20 21:29:44,387 iteration 3347 : loss : 0.020961, loss_ce: 0.008440
2022-01-20 21:29:44,902 iteration 3348 : loss : 0.026844, loss_ce: 0.011335
2022-01-20 21:29:45,556 iteration 3349 : loss : 0.037578, loss_ce: 0.011368
 49%|███████████████▎               | 197/400 [36:10<37:07, 10.97s/it]2022-01-20 21:29:46,196 iteration 3350 : loss : 0.037792, loss_ce: 0.011778
2022-01-20 21:29:46,841 iteration 3351 : loss : 0.032248, loss_ce: 0.011629
2022-01-20 21:29:47,473 iteration 3352 : loss : 0.036103, loss_ce: 0.015330
2022-01-20 21:29:48,158 iteration 3353 : loss : 0.029877, loss_ce: 0.009337
2022-01-20 21:29:48,730 iteration 3354 : loss : 0.028380, loss_ce: 0.011493
2022-01-20 21:29:49,402 iteration 3355 : loss : 0.041198, loss_ce: 0.018419
2022-01-20 21:29:50,060 iteration 3356 : loss : 0.041996, loss_ce: 0.016406
2022-01-20 21:29:50,652 iteration 3357 : loss : 0.033773, loss_ce: 0.008995
2022-01-20 21:29:51,304 iteration 3358 : loss : 0.021361, loss_ce: 0.009103
2022-01-20 21:29:51,834 iteration 3359 : loss : 0.027332, loss_ce: 0.010018
2022-01-20 21:29:52,400 iteration 3360 : loss : 0.027593, loss_ce: 0.010032
2022-01-20 21:29:52,990 iteration 3361 : loss : 0.026062, loss_ce: 0.009528
2022-01-20 21:29:53,571 iteration 3362 : loss : 0.027206, loss_ce: 0.009674
2022-01-20 21:29:54,235 iteration 3363 : loss : 0.032696, loss_ce: 0.009607
2022-01-20 21:29:54,768 iteration 3364 : loss : 0.026235, loss_ce: 0.012022
2022-01-20 21:29:55,393 iteration 3365 : loss : 0.032692, loss_ce: 0.014469
2022-01-20 21:29:55,907 iteration 3366 : loss : 0.022121, loss_ce: 0.009873
 50%|███████████████▎               | 198/400 [36:20<36:18, 10.79s/it]2022-01-20 21:29:56,548 iteration 3367 : loss : 0.028129, loss_ce: 0.011031
2022-01-20 21:29:57,122 iteration 3368 : loss : 0.022790, loss_ce: 0.010988
2022-01-20 21:29:57,649 iteration 3369 : loss : 0.028703, loss_ce: 0.008825
2022-01-20 21:29:58,301 iteration 3370 : loss : 0.031585, loss_ce: 0.014122
2022-01-20 21:29:59,022 iteration 3371 : loss : 0.030655, loss_ce: 0.010029
2022-01-20 21:29:59,582 iteration 3372 : loss : 0.020297, loss_ce: 0.009113
2022-01-20 21:30:00,195 iteration 3373 : loss : 0.032671, loss_ce: 0.011725
2022-01-20 21:30:00,738 iteration 3374 : loss : 0.023562, loss_ce: 0.007940
2022-01-20 21:30:01,293 iteration 3375 : loss : 0.032370, loss_ce: 0.012299
2022-01-20 21:30:01,885 iteration 3376 : loss : 0.041730, loss_ce: 0.010385
2022-01-20 21:30:02,381 iteration 3377 : loss : 0.018413, loss_ce: 0.007160
2022-01-20 21:30:03,005 iteration 3378 : loss : 0.039596, loss_ce: 0.009249
2022-01-20 21:30:03,713 iteration 3379 : loss : 0.041658, loss_ce: 0.018063
2022-01-20 21:30:04,358 iteration 3380 : loss : 0.033304, loss_ce: 0.012400
2022-01-20 21:30:04,995 iteration 3381 : loss : 0.035415, loss_ce: 0.014687
2022-01-20 21:30:05,614 iteration 3382 : loss : 0.030420, loss_ce: 0.012509
2022-01-20 21:30:06,185 iteration 3383 : loss : 0.021832, loss_ce: 0.008039
 50%|███████████████▍               | 199/400 [36:31<35:37, 10.63s/it]2022-01-20 21:30:06,901 iteration 3384 : loss : 0.031749, loss_ce: 0.010132
2022-01-20 21:30:07,544 iteration 3385 : loss : 0.034170, loss_ce: 0.012233
2022-01-20 21:30:08,104 iteration 3386 : loss : 0.021460, loss_ce: 0.007348
2022-01-20 21:30:08,766 iteration 3387 : loss : 0.027321, loss_ce: 0.010984
2022-01-20 21:30:09,386 iteration 3388 : loss : 0.027465, loss_ce: 0.010795
2022-01-20 21:30:09,952 iteration 3389 : loss : 0.020044, loss_ce: 0.007744
2022-01-20 21:30:10,432 iteration 3390 : loss : 0.017891, loss_ce: 0.007053
2022-01-20 21:30:11,061 iteration 3391 : loss : 0.024623, loss_ce: 0.008965
2022-01-20 21:30:11,683 iteration 3392 : loss : 0.034959, loss_ce: 0.011652
2022-01-20 21:30:12,291 iteration 3393 : loss : 0.024977, loss_ce: 0.010247
2022-01-20 21:30:12,917 iteration 3394 : loss : 0.018932, loss_ce: 0.007182
2022-01-20 21:30:13,445 iteration 3395 : loss : 0.018882, loss_ce: 0.007435
2022-01-20 21:30:14,099 iteration 3396 : loss : 0.023048, loss_ce: 0.007921
2022-01-20 21:30:14,724 iteration 3397 : loss : 0.025914, loss_ce: 0.010236
2022-01-20 21:30:15,351 iteration 3398 : loss : 0.024900, loss_ce: 0.011049
2022-01-20 21:30:15,932 iteration 3399 : loss : 0.031570, loss_ce: 0.011639
2022-01-20 21:30:15,932 Training Data Eval:
2022-01-20 21:30:18,622   Average segmentation loss on training set: 0.0180
2022-01-20 21:30:18,623 Validation Data Eval:
2022-01-20 21:30:19,498   Average segmentation loss on validation set: 0.1096
2022-01-20 21:30:20,014 iteration 3400 : loss : 0.022049, loss_ce: 0.007308
 50%|███████████████▌               | 200/400 [36:44<38:38, 11.59s/it]2022-01-20 21:30:20,661 iteration 3401 : loss : 0.027659, loss_ce: 0.014037
2022-01-20 21:30:21,186 iteration 3402 : loss : 0.020967, loss_ce: 0.008058
2022-01-20 21:30:21,858 iteration 3403 : loss : 0.026688, loss_ce: 0.009881
2022-01-20 21:30:22,506 iteration 3404 : loss : 0.024788, loss_ce: 0.008539
2022-01-20 21:30:23,044 iteration 3405 : loss : 0.029612, loss_ce: 0.010422
2022-01-20 21:30:23,703 iteration 3406 : loss : 0.024651, loss_ce: 0.009796
2022-01-20 21:30:24,281 iteration 3407 : loss : 0.026145, loss_ce: 0.010293
2022-01-20 21:30:24,801 iteration 3408 : loss : 0.024166, loss_ce: 0.008690
2022-01-20 21:30:25,398 iteration 3409 : loss : 0.020335, loss_ce: 0.006889
2022-01-20 21:30:26,031 iteration 3410 : loss : 0.024807, loss_ce: 0.009725
2022-01-20 21:30:26,684 iteration 3411 : loss : 0.029179, loss_ce: 0.012419
2022-01-20 21:30:27,315 iteration 3412 : loss : 0.022961, loss_ce: 0.009458
2022-01-20 21:30:27,927 iteration 3413 : loss : 0.030479, loss_ce: 0.006999
2022-01-20 21:30:28,601 iteration 3414 : loss : 0.025662, loss_ce: 0.010977
2022-01-20 21:30:29,224 iteration 3415 : loss : 0.022273, loss_ce: 0.010878
2022-01-20 21:30:29,900 iteration 3416 : loss : 0.027616, loss_ce: 0.009750
2022-01-20 21:30:30,561 iteration 3417 : loss : 0.024243, loss_ce: 0.007970
 50%|███████████████▌               | 201/400 [36:55<37:24, 11.28s/it]2022-01-20 21:30:31,140 iteration 3418 : loss : 0.017197, loss_ce: 0.005899
2022-01-20 21:30:31,638 iteration 3419 : loss : 0.025454, loss_ce: 0.011226
2022-01-20 21:30:32,186 iteration 3420 : loss : 0.021511, loss_ce: 0.007576
2022-01-20 21:30:32,726 iteration 3421 : loss : 0.019567, loss_ce: 0.007518
2022-01-20 21:30:33,254 iteration 3422 : loss : 0.021573, loss_ce: 0.007365
2022-01-20 21:30:33,871 iteration 3423 : loss : 0.026823, loss_ce: 0.013766
2022-01-20 21:30:34,475 iteration 3424 : loss : 0.036861, loss_ce: 0.015371
2022-01-20 21:30:35,100 iteration 3425 : loss : 0.021193, loss_ce: 0.007791
2022-01-20 21:30:35,600 iteration 3426 : loss : 0.024952, loss_ce: 0.009802
2022-01-20 21:30:36,194 iteration 3427 : loss : 0.026612, loss_ce: 0.007546
2022-01-20 21:30:36,813 iteration 3428 : loss : 0.031079, loss_ce: 0.014343
2022-01-20 21:30:37,369 iteration 3429 : loss : 0.023111, loss_ce: 0.007386
2022-01-20 21:30:37,996 iteration 3430 : loss : 0.021499, loss_ce: 0.008418
2022-01-20 21:30:38,607 iteration 3431 : loss : 0.022345, loss_ce: 0.007703
2022-01-20 21:30:39,275 iteration 3432 : loss : 0.032702, loss_ce: 0.012631
2022-01-20 21:30:39,928 iteration 3433 : loss : 0.030795, loss_ce: 0.009536
2022-01-20 21:30:40,530 iteration 3434 : loss : 0.026489, loss_ce: 0.007078
 50%|███████████████▋               | 202/400 [37:05<35:55, 10.88s/it]2022-01-20 21:30:41,156 iteration 3435 : loss : 0.031016, loss_ce: 0.010512
2022-01-20 21:30:41,818 iteration 3436 : loss : 0.030985, loss_ce: 0.011918
2022-01-20 21:30:42,493 iteration 3437 : loss : 0.021356, loss_ce: 0.007822
2022-01-20 21:30:43,169 iteration 3438 : loss : 0.026171, loss_ce: 0.011132
2022-01-20 21:30:43,720 iteration 3439 : loss : 0.022083, loss_ce: 0.007997
2022-01-20 21:30:44,347 iteration 3440 : loss : 0.023039, loss_ce: 0.008329
2022-01-20 21:30:44,921 iteration 3441 : loss : 0.024946, loss_ce: 0.007822
2022-01-20 21:30:45,533 iteration 3442 : loss : 0.020675, loss_ce: 0.008451
2022-01-20 21:30:46,228 iteration 3443 : loss : 0.024861, loss_ce: 0.010282
2022-01-20 21:30:46,806 iteration 3444 : loss : 0.030315, loss_ce: 0.010538
2022-01-20 21:30:47,435 iteration 3445 : loss : 0.027125, loss_ce: 0.010759
2022-01-20 21:30:48,086 iteration 3446 : loss : 0.025457, loss_ce: 0.012175
2022-01-20 21:30:48,736 iteration 3447 : loss : 0.028484, loss_ce: 0.008542
2022-01-20 21:30:49,275 iteration 3448 : loss : 0.025384, loss_ce: 0.009507
2022-01-20 21:30:49,837 iteration 3449 : loss : 0.020570, loss_ce: 0.008164
2022-01-20 21:30:50,409 iteration 3450 : loss : 0.020775, loss_ce: 0.007147
2022-01-20 21:30:50,979 iteration 3451 : loss : 0.018530, loss_ce: 0.009802
 51%|███████████████▋               | 203/400 [37:15<35:19, 10.76s/it]2022-01-20 21:30:51,529 iteration 3452 : loss : 0.015670, loss_ce: 0.006750
2022-01-20 21:30:52,164 iteration 3453 : loss : 0.026162, loss_ce: 0.008889
2022-01-20 21:30:52,906 iteration 3454 : loss : 0.034993, loss_ce: 0.014376
2022-01-20 21:30:53,487 iteration 3455 : loss : 0.023356, loss_ce: 0.009528
2022-01-20 21:30:54,101 iteration 3456 : loss : 0.037507, loss_ce: 0.009331
2022-01-20 21:30:54,647 iteration 3457 : loss : 0.019834, loss_ce: 0.008507
2022-01-20 21:30:55,177 iteration 3458 : loss : 0.043337, loss_ce: 0.011254
2022-01-20 21:30:55,826 iteration 3459 : loss : 0.021932, loss_ce: 0.009921
2022-01-20 21:30:56,367 iteration 3460 : loss : 0.020156, loss_ce: 0.007479
2022-01-20 21:30:56,909 iteration 3461 : loss : 0.018414, loss_ce: 0.006172
2022-01-20 21:30:57,389 iteration 3462 : loss : 0.017885, loss_ce: 0.008392
2022-01-20 21:30:58,009 iteration 3463 : loss : 0.022129, loss_ce: 0.008710
2022-01-20 21:30:58,613 iteration 3464 : loss : 0.029405, loss_ce: 0.009717
2022-01-20 21:30:59,166 iteration 3465 : loss : 0.022222, loss_ce: 0.008074
2022-01-20 21:30:59,836 iteration 3466 : loss : 0.032068, loss_ce: 0.014958
2022-01-20 21:31:00,354 iteration 3467 : loss : 0.021493, loss_ce: 0.007427
2022-01-20 21:31:00,928 iteration 3468 : loss : 0.021771, loss_ce: 0.007199
 51%|███████████████▊               | 204/400 [37:25<34:20, 10.51s/it]2022-01-20 21:31:01,535 iteration 3469 : loss : 0.024093, loss_ce: 0.010355
2022-01-20 21:31:02,120 iteration 3470 : loss : 0.031716, loss_ce: 0.012100
2022-01-20 21:31:02,786 iteration 3471 : loss : 0.022077, loss_ce: 0.008050
2022-01-20 21:31:03,471 iteration 3472 : loss : 0.043418, loss_ce: 0.015982
2022-01-20 21:31:04,026 iteration 3473 : loss : 0.021510, loss_ce: 0.009795
2022-01-20 21:31:04,683 iteration 3474 : loss : 0.024715, loss_ce: 0.009199
2022-01-20 21:31:05,290 iteration 3475 : loss : 0.020934, loss_ce: 0.008830
2022-01-20 21:31:05,854 iteration 3476 : loss : 0.026406, loss_ce: 0.007232
2022-01-20 21:31:06,433 iteration 3477 : loss : 0.020938, loss_ce: 0.007001
2022-01-20 21:31:07,032 iteration 3478 : loss : 0.022479, loss_ce: 0.011501
2022-01-20 21:31:07,613 iteration 3479 : loss : 0.021370, loss_ce: 0.009266
2022-01-20 21:31:08,154 iteration 3480 : loss : 0.023194, loss_ce: 0.011029
2022-01-20 21:31:08,709 iteration 3481 : loss : 0.027332, loss_ce: 0.008368
2022-01-20 21:31:09,287 iteration 3482 : loss : 0.024714, loss_ce: 0.009902
2022-01-20 21:31:09,947 iteration 3483 : loss : 0.023348, loss_ce: 0.010298
2022-01-20 21:31:10,569 iteration 3484 : loss : 0.024748, loss_ce: 0.008446
2022-01-20 21:31:10,569 Training Data Eval:
2022-01-20 21:31:13,258   Average segmentation loss on training set: 0.0160
2022-01-20 21:31:13,258 Validation Data Eval:
2022-01-20 21:31:14,134   Average segmentation loss on validation set: 0.0886
2022-01-20 21:31:14,717 iteration 3485 : loss : 0.020564, loss_ce: 0.007891
 51%|███████████████▉               | 205/400 [37:39<37:21, 11.50s/it]2022-01-20 21:31:15,380 iteration 3486 : loss : 0.026015, loss_ce: 0.007548
2022-01-20 21:31:15,974 iteration 3487 : loss : 0.021146, loss_ce: 0.009689
2022-01-20 21:31:16,564 iteration 3488 : loss : 0.021991, loss_ce: 0.007591
2022-01-20 21:31:17,042 iteration 3489 : loss : 0.022036, loss_ce: 0.009921
2022-01-20 21:31:17,665 iteration 3490 : loss : 0.030584, loss_ce: 0.012496
2022-01-20 21:31:18,362 iteration 3491 : loss : 0.027409, loss_ce: 0.013657
2022-01-20 21:31:18,972 iteration 3492 : loss : 0.020303, loss_ce: 0.006653
2022-01-20 21:31:19,542 iteration 3493 : loss : 0.022372, loss_ce: 0.008814
2022-01-20 21:31:20,145 iteration 3494 : loss : 0.024240, loss_ce: 0.010190
2022-01-20 21:31:20,773 iteration 3495 : loss : 0.018336, loss_ce: 0.005757
2022-01-20 21:31:21,483 iteration 3496 : loss : 0.026704, loss_ce: 0.009480
2022-01-20 21:31:22,083 iteration 3497 : loss : 0.021773, loss_ce: 0.009431
2022-01-20 21:31:22,729 iteration 3498 : loss : 0.018574, loss_ce: 0.007712
2022-01-20 21:31:23,306 iteration 3499 : loss : 0.024501, loss_ce: 0.011863
2022-01-20 21:31:23,910 iteration 3500 : loss : 0.023741, loss_ce: 0.010616
2022-01-20 21:31:24,606 iteration 3501 : loss : 0.023631, loss_ce: 0.011151
2022-01-20 21:31:25,204 iteration 3502 : loss : 0.021484, loss_ce: 0.012017
 52%|███████████████▉               | 206/400 [37:50<36:11, 11.19s/it]2022-01-20 21:31:25,877 iteration 3503 : loss : 0.029760, loss_ce: 0.008602
2022-01-20 21:31:26,476 iteration 3504 : loss : 0.019579, loss_ce: 0.007186
2022-01-20 21:31:27,081 iteration 3505 : loss : 0.017811, loss_ce: 0.007713
2022-01-20 21:31:27,730 iteration 3506 : loss : 0.021251, loss_ce: 0.006404
2022-01-20 21:31:28,273 iteration 3507 : loss : 0.018323, loss_ce: 0.007095
2022-01-20 21:31:28,859 iteration 3508 : loss : 0.023770, loss_ce: 0.005655
2022-01-20 21:31:29,498 iteration 3509 : loss : 0.026209, loss_ce: 0.009105
2022-01-20 21:31:30,088 iteration 3510 : loss : 0.022598, loss_ce: 0.008975
2022-01-20 21:31:30,880 iteration 3511 : loss : 0.033904, loss_ce: 0.012984
2022-01-20 21:31:31,423 iteration 3512 : loss : 0.017938, loss_ce: 0.006671
2022-01-20 21:31:31,933 iteration 3513 : loss : 0.019392, loss_ce: 0.008258
2022-01-20 21:31:32,519 iteration 3514 : loss : 0.020154, loss_ce: 0.008712
2022-01-20 21:31:33,103 iteration 3515 : loss : 0.028003, loss_ce: 0.013255
2022-01-20 21:31:33,677 iteration 3516 : loss : 0.018238, loss_ce: 0.008301
2022-01-20 21:31:34,265 iteration 3517 : loss : 0.024010, loss_ce: 0.011856
2022-01-20 21:31:34,945 iteration 3518 : loss : 0.044821, loss_ce: 0.017080
2022-01-20 21:31:35,596 iteration 3519 : loss : 0.020891, loss_ce: 0.008251
 52%|████████████████               | 207/400 [38:00<35:13, 10.95s/it]2022-01-20 21:31:36,172 iteration 3520 : loss : 0.027551, loss_ce: 0.009308
2022-01-20 21:31:36,749 iteration 3521 : loss : 0.021354, loss_ce: 0.005326
2022-01-20 21:31:37,286 iteration 3522 : loss : 0.022352, loss_ce: 0.006477
2022-01-20 21:31:37,907 iteration 3523 : loss : 0.026815, loss_ce: 0.015150
2022-01-20 21:31:38,576 iteration 3524 : loss : 0.021913, loss_ce: 0.008478
2022-01-20 21:31:39,142 iteration 3525 : loss : 0.029571, loss_ce: 0.008350
2022-01-20 21:31:39,759 iteration 3526 : loss : 0.034991, loss_ce: 0.024002
2022-01-20 21:31:40,441 iteration 3527 : loss : 0.028572, loss_ce: 0.011991
2022-01-20 21:31:41,016 iteration 3528 : loss : 0.050046, loss_ce: 0.008438
2022-01-20 21:31:41,603 iteration 3529 : loss : 0.020463, loss_ce: 0.006810
2022-01-20 21:31:42,191 iteration 3530 : loss : 0.025921, loss_ce: 0.009580
2022-01-20 21:31:42,783 iteration 3531 : loss : 0.026004, loss_ce: 0.009007
2022-01-20 21:31:43,401 iteration 3532 : loss : 0.022395, loss_ce: 0.009493
2022-01-20 21:31:44,043 iteration 3533 : loss : 0.051097, loss_ce: 0.024414
2022-01-20 21:31:44,581 iteration 3534 : loss : 0.026490, loss_ce: 0.009469
2022-01-20 21:31:45,195 iteration 3535 : loss : 0.026563, loss_ce: 0.010268
2022-01-20 21:31:45,768 iteration 3536 : loss : 0.032207, loss_ce: 0.013695
 52%|████████████████               | 208/400 [38:10<34:17, 10.72s/it]2022-01-20 21:31:46,490 iteration 3537 : loss : 0.034681, loss_ce: 0.017223
2022-01-20 21:31:47,051 iteration 3538 : loss : 0.027688, loss_ce: 0.009700
2022-01-20 21:31:47,615 iteration 3539 : loss : 0.028773, loss_ce: 0.009364
2022-01-20 21:31:48,239 iteration 3540 : loss : 0.021121, loss_ce: 0.009098
2022-01-20 21:31:48,885 iteration 3541 : loss : 0.021573, loss_ce: 0.008269
2022-01-20 21:31:49,512 iteration 3542 : loss : 0.025786, loss_ce: 0.009343
2022-01-20 21:31:50,187 iteration 3543 : loss : 0.029260, loss_ce: 0.012927
2022-01-20 21:31:50,841 iteration 3544 : loss : 0.048766, loss_ce: 0.009219
2022-01-20 21:31:51,502 iteration 3545 : loss : 0.029357, loss_ce: 0.008816
2022-01-20 21:31:52,151 iteration 3546 : loss : 0.026955, loss_ce: 0.009173
2022-01-20 21:31:52,823 iteration 3547 : loss : 0.044298, loss_ce: 0.014667
2022-01-20 21:31:53,382 iteration 3548 : loss : 0.016992, loss_ce: 0.005229
2022-01-20 21:31:54,080 iteration 3549 : loss : 0.037652, loss_ce: 0.017438
2022-01-20 21:31:54,664 iteration 3550 : loss : 0.019695, loss_ce: 0.006712
2022-01-20 21:31:55,229 iteration 3551 : loss : 0.031355, loss_ce: 0.011900
2022-01-20 21:31:55,778 iteration 3552 : loss : 0.025234, loss_ce: 0.011841
2022-01-20 21:31:56,339 iteration 3553 : loss : 0.023273, loss_ce: 0.008970
 52%|████████████████▏              | 209/400 [38:21<33:59, 10.68s/it]2022-01-20 21:31:56,969 iteration 3554 : loss : 0.025668, loss_ce: 0.010528
2022-01-20 21:31:57,551 iteration 3555 : loss : 0.025175, loss_ce: 0.011805
2022-01-20 21:31:58,210 iteration 3556 : loss : 0.030366, loss_ce: 0.014634
2022-01-20 21:31:58,890 iteration 3557 : loss : 0.039618, loss_ce: 0.017387
2022-01-20 21:31:59,478 iteration 3558 : loss : 0.026172, loss_ce: 0.008784
2022-01-20 21:32:00,087 iteration 3559 : loss : 0.027160, loss_ce: 0.007101
2022-01-20 21:32:00,673 iteration 3560 : loss : 0.025594, loss_ce: 0.009879
2022-01-20 21:32:01,184 iteration 3561 : loss : 0.017174, loss_ce: 0.008252
2022-01-20 21:32:01,792 iteration 3562 : loss : 0.029685, loss_ce: 0.011647
2022-01-20 21:32:02,392 iteration 3563 : loss : 0.029252, loss_ce: 0.010979
2022-01-20 21:32:03,038 iteration 3564 : loss : 0.028775, loss_ce: 0.009382
2022-01-20 21:32:03,589 iteration 3565 : loss : 0.022552, loss_ce: 0.006188
2022-01-20 21:32:04,138 iteration 3566 : loss : 0.028062, loss_ce: 0.011329
2022-01-20 21:32:04,816 iteration 3567 : loss : 0.026973, loss_ce: 0.013708
2022-01-20 21:32:05,412 iteration 3568 : loss : 0.039056, loss_ce: 0.016992
2022-01-20 21:32:05,962 iteration 3569 : loss : 0.024088, loss_ce: 0.009836
2022-01-20 21:32:05,963 Training Data Eval:
2022-01-20 21:32:08,650   Average segmentation loss on training set: 0.0180
2022-01-20 21:32:08,651 Validation Data Eval:
2022-01-20 21:32:09,528   Average segmentation loss on validation set: 0.1341
2022-01-20 21:32:10,165 iteration 3570 : loss : 0.028429, loss_ce: 0.009477
 52%|████████████████▎              | 210/400 [38:35<36:48, 11.62s/it]2022-01-20 21:32:10,838 iteration 3571 : loss : 0.024350, loss_ce: 0.011126
2022-01-20 21:32:11,379 iteration 3572 : loss : 0.024643, loss_ce: 0.010137
2022-01-20 21:32:11,993 iteration 3573 : loss : 0.025199, loss_ce: 0.010206
2022-01-20 21:32:12,584 iteration 3574 : loss : 0.029156, loss_ce: 0.009710
2022-01-20 21:32:13,125 iteration 3575 : loss : 0.023166, loss_ce: 0.008267
2022-01-20 21:32:13,761 iteration 3576 : loss : 0.022326, loss_ce: 0.006206
2022-01-20 21:32:14,374 iteration 3577 : loss : 0.023501, loss_ce: 0.008979
2022-01-20 21:32:14,875 iteration 3578 : loss : 0.023793, loss_ce: 0.008699
2022-01-20 21:32:15,444 iteration 3579 : loss : 0.030139, loss_ce: 0.011156
2022-01-20 21:32:15,986 iteration 3580 : loss : 0.025687, loss_ce: 0.010650
2022-01-20 21:32:16,519 iteration 3581 : loss : 0.026164, loss_ce: 0.013902
2022-01-20 21:32:17,096 iteration 3582 : loss : 0.021094, loss_ce: 0.008465
2022-01-20 21:32:17,723 iteration 3583 : loss : 0.024448, loss_ce: 0.008090
2022-01-20 21:32:18,332 iteration 3584 : loss : 0.023029, loss_ce: 0.007808
2022-01-20 21:32:18,880 iteration 3585 : loss : 0.023530, loss_ce: 0.008762
2022-01-20 21:32:19,545 iteration 3586 : loss : 0.028982, loss_ce: 0.012737
2022-01-20 21:32:20,130 iteration 3587 : loss : 0.018141, loss_ce: 0.007937
 53%|████████████████▎              | 211/400 [38:45<35:02, 11.12s/it]2022-01-20 21:32:20,840 iteration 3588 : loss : 0.026345, loss_ce: 0.011837
2022-01-20 21:32:21,373 iteration 3589 : loss : 0.021566, loss_ce: 0.007949
2022-01-20 21:32:21,935 iteration 3590 : loss : 0.019935, loss_ce: 0.007199
2022-01-20 21:32:22,529 iteration 3591 : loss : 0.019675, loss_ce: 0.006841
2022-01-20 21:32:23,304 iteration 3592 : loss : 0.028978, loss_ce: 0.012883
2022-01-20 21:32:23,880 iteration 3593 : loss : 0.043756, loss_ce: 0.016744
2022-01-20 21:32:24,475 iteration 3594 : loss : 0.025342, loss_ce: 0.008898
2022-01-20 21:32:25,102 iteration 3595 : loss : 0.027833, loss_ce: 0.010164
2022-01-20 21:32:25,705 iteration 3596 : loss : 0.022718, loss_ce: 0.008343
2022-01-20 21:32:26,351 iteration 3597 : loss : 0.031329, loss_ce: 0.010628
2022-01-20 21:32:26,891 iteration 3598 : loss : 0.017883, loss_ce: 0.007544
2022-01-20 21:32:27,521 iteration 3599 : loss : 0.025308, loss_ce: 0.008453
2022-01-20 21:32:28,002 iteration 3600 : loss : 0.020090, loss_ce: 0.007710
2022-01-20 21:32:28,591 iteration 3601 : loss : 0.022195, loss_ce: 0.008252
2022-01-20 21:32:29,123 iteration 3602 : loss : 0.020878, loss_ce: 0.006931
2022-01-20 21:32:29,739 iteration 3603 : loss : 0.018292, loss_ce: 0.008674
2022-01-20 21:32:30,263 iteration 3604 : loss : 0.018884, loss_ce: 0.008116
 53%|████████████████▍              | 212/400 [38:55<33:55, 10.83s/it]2022-01-20 21:32:30,909 iteration 3605 : loss : 0.026675, loss_ce: 0.009256
2022-01-20 21:32:31,478 iteration 3606 : loss : 0.023100, loss_ce: 0.010984
2022-01-20 21:32:32,101 iteration 3607 : loss : 0.024052, loss_ce: 0.008837
2022-01-20 21:32:32,669 iteration 3608 : loss : 0.020541, loss_ce: 0.007945
2022-01-20 21:32:33,227 iteration 3609 : loss : 0.019439, loss_ce: 0.008980
2022-01-20 21:32:33,816 iteration 3610 : loss : 0.019576, loss_ce: 0.007893
2022-01-20 21:32:34,341 iteration 3611 : loss : 0.026312, loss_ce: 0.007588
2022-01-20 21:32:34,872 iteration 3612 : loss : 0.017953, loss_ce: 0.005807
2022-01-20 21:32:35,566 iteration 3613 : loss : 0.028391, loss_ce: 0.012232
2022-01-20 21:32:36,112 iteration 3614 : loss : 0.017764, loss_ce: 0.006756
2022-01-20 21:32:36,607 iteration 3615 : loss : 0.019676, loss_ce: 0.007096
2022-01-20 21:32:37,204 iteration 3616 : loss : 0.042653, loss_ce: 0.019499
2022-01-20 21:32:37,827 iteration 3617 : loss : 0.023316, loss_ce: 0.009298
2022-01-20 21:32:38,435 iteration 3618 : loss : 0.017406, loss_ce: 0.007005
2022-01-20 21:32:39,029 iteration 3619 : loss : 0.023525, loss_ce: 0.007263
2022-01-20 21:32:39,577 iteration 3620 : loss : 0.027706, loss_ce: 0.009664
2022-01-20 21:32:40,180 iteration 3621 : loss : 0.040871, loss_ce: 0.016989
 53%|████████████████▌              | 213/400 [39:05<32:53, 10.55s/it]2022-01-20 21:32:40,819 iteration 3622 : loss : 0.023238, loss_ce: 0.010940
2022-01-20 21:32:41,468 iteration 3623 : loss : 0.016943, loss_ce: 0.004384
2022-01-20 21:32:42,068 iteration 3624 : loss : 0.016769, loss_ce: 0.006899
2022-01-20 21:32:42,645 iteration 3625 : loss : 0.022004, loss_ce: 0.008609
2022-01-20 21:32:43,188 iteration 3626 : loss : 0.019517, loss_ce: 0.009568
2022-01-20 21:32:43,718 iteration 3627 : loss : 0.019085, loss_ce: 0.006998
2022-01-20 21:32:44,372 iteration 3628 : loss : 0.043624, loss_ce: 0.012292
2022-01-20 21:32:45,127 iteration 3629 : loss : 0.024166, loss_ce: 0.009929
2022-01-20 21:32:45,634 iteration 3630 : loss : 0.024398, loss_ce: 0.008812
2022-01-20 21:32:46,233 iteration 3631 : loss : 0.031185, loss_ce: 0.009528
2022-01-20 21:32:46,952 iteration 3632 : loss : 0.031187, loss_ce: 0.011125
2022-01-20 21:32:47,545 iteration 3633 : loss : 0.021175, loss_ce: 0.008168
2022-01-20 21:32:48,118 iteration 3634 : loss : 0.022998, loss_ce: 0.009704
2022-01-20 21:32:48,807 iteration 3635 : loss : 0.035810, loss_ce: 0.018144
2022-01-20 21:32:49,475 iteration 3636 : loss : 0.025986, loss_ce: 0.007217
2022-01-20 21:32:50,077 iteration 3637 : loss : 0.031933, loss_ce: 0.011235
2022-01-20 21:32:50,671 iteration 3638 : loss : 0.018334, loss_ce: 0.007911
 54%|████████████████▌              | 214/400 [39:15<32:39, 10.53s/it]2022-01-20 21:32:51,258 iteration 3639 : loss : 0.019390, loss_ce: 0.007741
2022-01-20 21:32:51,793 iteration 3640 : loss : 0.021169, loss_ce: 0.008361
2022-01-20 21:32:52,317 iteration 3641 : loss : 0.018579, loss_ce: 0.006042
2022-01-20 21:32:52,906 iteration 3642 : loss : 0.034448, loss_ce: 0.010295
2022-01-20 21:32:53,434 iteration 3643 : loss : 0.018759, loss_ce: 0.008308
2022-01-20 21:32:53,980 iteration 3644 : loss : 0.016121, loss_ce: 0.006012
2022-01-20 21:32:54,566 iteration 3645 : loss : 0.027964, loss_ce: 0.008586
2022-01-20 21:32:55,155 iteration 3646 : loss : 0.025479, loss_ce: 0.010741
2022-01-20 21:32:55,754 iteration 3647 : loss : 0.024749, loss_ce: 0.006561
2022-01-20 21:32:56,378 iteration 3648 : loss : 0.030380, loss_ce: 0.013774
2022-01-20 21:32:56,958 iteration 3649 : loss : 0.020459, loss_ce: 0.005570
2022-01-20 21:32:57,563 iteration 3650 : loss : 0.022063, loss_ce: 0.010980
2022-01-20 21:32:58,186 iteration 3651 : loss : 0.022637, loss_ce: 0.008007
2022-01-20 21:32:58,908 iteration 3652 : loss : 0.049329, loss_ce: 0.012032
2022-01-20 21:32:59,460 iteration 3653 : loss : 0.022579, loss_ce: 0.012023
2022-01-20 21:32:59,985 iteration 3654 : loss : 0.018346, loss_ce: 0.009083
2022-01-20 21:32:59,985 Training Data Eval:
2022-01-20 21:33:02,675   Average segmentation loss on training set: 0.0179
2022-01-20 21:33:02,675 Validation Data Eval:
2022-01-20 21:33:03,561   Average segmentation loss on validation set: 0.0822
2022-01-20 21:33:04,162 iteration 3655 : loss : 0.023569, loss_ce: 0.009309
 54%|████████████████▋              | 215/400 [39:29<35:13, 11.42s/it]2022-01-20 21:33:04,836 iteration 3656 : loss : 0.028317, loss_ce: 0.010086
2022-01-20 21:33:05,382 iteration 3657 : loss : 0.023212, loss_ce: 0.011168
2022-01-20 21:33:06,021 iteration 3658 : loss : 0.023156, loss_ce: 0.010232
2022-01-20 21:33:06,717 iteration 3659 : loss : 0.032938, loss_ce: 0.012679
2022-01-20 21:33:07,315 iteration 3660 : loss : 0.029923, loss_ce: 0.007277
2022-01-20 21:33:07,852 iteration 3661 : loss : 0.018505, loss_ce: 0.007649
2022-01-20 21:33:08,450 iteration 3662 : loss : 0.021965, loss_ce: 0.007499
2022-01-20 21:33:09,027 iteration 3663 : loss : 0.024604, loss_ce: 0.007329
2022-01-20 21:33:09,656 iteration 3664 : loss : 0.018960, loss_ce: 0.006573
2022-01-20 21:33:10,251 iteration 3665 : loss : 0.028569, loss_ce: 0.015126
2022-01-20 21:33:10,830 iteration 3666 : loss : 0.025481, loss_ce: 0.010067
2022-01-20 21:33:11,395 iteration 3667 : loss : 0.031854, loss_ce: 0.014698
2022-01-20 21:33:11,893 iteration 3668 : loss : 0.020132, loss_ce: 0.004277
2022-01-20 21:33:12,536 iteration 3669 : loss : 0.029905, loss_ce: 0.016838
2022-01-20 21:33:13,071 iteration 3670 : loss : 0.018131, loss_ce: 0.006450
2022-01-20 21:33:13,644 iteration 3671 : loss : 0.017888, loss_ce: 0.008664
2022-01-20 21:33:14,375 iteration 3672 : loss : 0.065064, loss_ce: 0.015860
 54%|████████████████▋              | 216/400 [39:39<33:55, 11.06s/it]2022-01-20 21:33:15,033 iteration 3673 : loss : 0.021332, loss_ce: 0.009318
2022-01-20 21:33:15,679 iteration 3674 : loss : 0.031179, loss_ce: 0.009529
2022-01-20 21:33:16,360 iteration 3675 : loss : 0.034355, loss_ce: 0.011505
2022-01-20 21:33:16,881 iteration 3676 : loss : 0.017454, loss_ce: 0.007162
2022-01-20 21:33:17,483 iteration 3677 : loss : 0.027392, loss_ce: 0.009006
2022-01-20 21:33:18,146 iteration 3678 : loss : 0.040908, loss_ce: 0.012411
2022-01-20 21:33:18,728 iteration 3679 : loss : 0.022819, loss_ce: 0.008684
2022-01-20 21:33:19,325 iteration 3680 : loss : 0.030525, loss_ce: 0.014351
2022-01-20 21:33:19,911 iteration 3681 : loss : 0.026158, loss_ce: 0.012621
2022-01-20 21:33:20,420 iteration 3682 : loss : 0.030340, loss_ce: 0.013597
2022-01-20 21:33:20,917 iteration 3683 : loss : 0.018579, loss_ce: 0.006303
2022-01-20 21:33:21,555 iteration 3684 : loss : 0.016638, loss_ce: 0.006503
2022-01-20 21:33:22,109 iteration 3685 : loss : 0.021220, loss_ce: 0.007940
2022-01-20 21:33:22,713 iteration 3686 : loss : 0.024923, loss_ce: 0.009908
2022-01-20 21:33:23,270 iteration 3687 : loss : 0.017758, loss_ce: 0.006307
2022-01-20 21:33:23,858 iteration 3688 : loss : 0.022565, loss_ce: 0.011558
2022-01-20 21:33:24,466 iteration 3689 : loss : 0.033416, loss_ce: 0.010009
 54%|████████████████▊              | 217/400 [39:49<32:50, 10.77s/it]2022-01-20 21:33:25,107 iteration 3690 : loss : 0.027620, loss_ce: 0.007753
2022-01-20 21:33:25,734 iteration 3691 : loss : 0.032378, loss_ce: 0.007608
2022-01-20 21:33:26,345 iteration 3692 : loss : 0.025774, loss_ce: 0.012937
2022-01-20 21:33:26,882 iteration 3693 : loss : 0.020067, loss_ce: 0.008117
2022-01-20 21:33:27,473 iteration 3694 : loss : 0.032257, loss_ce: 0.012922
2022-01-20 21:33:28,075 iteration 3695 : loss : 0.025398, loss_ce: 0.013691
2022-01-20 21:33:28,654 iteration 3696 : loss : 0.029435, loss_ce: 0.008326
2022-01-20 21:33:29,270 iteration 3697 : loss : 0.027763, loss_ce: 0.009495
2022-01-20 21:33:29,947 iteration 3698 : loss : 0.026152, loss_ce: 0.011760
2022-01-20 21:33:30,486 iteration 3699 : loss : 0.019053, loss_ce: 0.007793
2022-01-20 21:33:31,080 iteration 3700 : loss : 0.028705, loss_ce: 0.009305
2022-01-20 21:33:31,577 iteration 3701 : loss : 0.020361, loss_ce: 0.008649
2022-01-20 21:33:32,180 iteration 3702 : loss : 0.018288, loss_ce: 0.006318
2022-01-20 21:33:32,783 iteration 3703 : loss : 0.021446, loss_ce: 0.009709
2022-01-20 21:33:33,283 iteration 3704 : loss : 0.021988, loss_ce: 0.007935
2022-01-20 21:33:33,939 iteration 3705 : loss : 0.026164, loss_ce: 0.009597
2022-01-20 21:33:34,442 iteration 3706 : loss : 0.016646, loss_ce: 0.005159
 55%|████████████████▉              | 218/400 [39:59<31:56, 10.53s/it]2022-01-20 21:33:35,097 iteration 3707 : loss : 0.023457, loss_ce: 0.010486
2022-01-20 21:33:35,606 iteration 3708 : loss : 0.022483, loss_ce: 0.007358
2022-01-20 21:33:36,297 iteration 3709 : loss : 0.034961, loss_ce: 0.012713
2022-01-20 21:33:36,888 iteration 3710 : loss : 0.028421, loss_ce: 0.009781
2022-01-20 21:33:37,440 iteration 3711 : loss : 0.018367, loss_ce: 0.006448
2022-01-20 21:33:37,969 iteration 3712 : loss : 0.018407, loss_ce: 0.008564
2022-01-20 21:33:38,647 iteration 3713 : loss : 0.025614, loss_ce: 0.008796
2022-01-20 21:33:39,245 iteration 3714 : loss : 0.026048, loss_ce: 0.010495
2022-01-20 21:33:39,813 iteration 3715 : loss : 0.020862, loss_ce: 0.009282
2022-01-20 21:33:40,401 iteration 3716 : loss : 0.025468, loss_ce: 0.012557
2022-01-20 21:33:41,038 iteration 3717 : loss : 0.019018, loss_ce: 0.007884
2022-01-20 21:33:41,610 iteration 3718 : loss : 0.018868, loss_ce: 0.007378
2022-01-20 21:33:42,209 iteration 3719 : loss : 0.023213, loss_ce: 0.008979
2022-01-20 21:33:42,895 iteration 3720 : loss : 0.025092, loss_ce: 0.007185
2022-01-20 21:33:43,479 iteration 3721 : loss : 0.018166, loss_ce: 0.006731
2022-01-20 21:33:44,048 iteration 3722 : loss : 0.048979, loss_ce: 0.023911
2022-01-20 21:33:44,693 iteration 3723 : loss : 0.025282, loss_ce: 0.007626
 55%|████████████████▉              | 219/400 [40:09<31:31, 10.45s/it]2022-01-20 21:33:45,384 iteration 3724 : loss : 0.025048, loss_ce: 0.009768
2022-01-20 21:33:45,977 iteration 3725 : loss : 0.026113, loss_ce: 0.012361
2022-01-20 21:33:46,698 iteration 3726 : loss : 0.019545, loss_ce: 0.006763
2022-01-20 21:33:47,247 iteration 3727 : loss : 0.018781, loss_ce: 0.005982
2022-01-20 21:33:47,827 iteration 3728 : loss : 0.021169, loss_ce: 0.011368
2022-01-20 21:33:48,474 iteration 3729 : loss : 0.027059, loss_ce: 0.009929
2022-01-20 21:33:49,035 iteration 3730 : loss : 0.026242, loss_ce: 0.008449
2022-01-20 21:33:49,565 iteration 3731 : loss : 0.023184, loss_ce: 0.007905
2022-01-20 21:33:50,156 iteration 3732 : loss : 0.026351, loss_ce: 0.009976
2022-01-20 21:33:50,724 iteration 3733 : loss : 0.024958, loss_ce: 0.007071
2022-01-20 21:33:51,325 iteration 3734 : loss : 0.024011, loss_ce: 0.009552
2022-01-20 21:33:51,955 iteration 3735 : loss : 0.035891, loss_ce: 0.016470
2022-01-20 21:33:52,594 iteration 3736 : loss : 0.020559, loss_ce: 0.006372
2022-01-20 21:33:53,197 iteration 3737 : loss : 0.021790, loss_ce: 0.008060
2022-01-20 21:33:53,787 iteration 3738 : loss : 0.021943, loss_ce: 0.008779
2022-01-20 21:33:54,383 iteration 3739 : loss : 0.026499, loss_ce: 0.010481
2022-01-20 21:33:54,383 Training Data Eval:
2022-01-20 21:33:57,062   Average segmentation loss on training set: 0.0157
2022-01-20 21:33:57,063 Validation Data Eval:
2022-01-20 21:33:57,945   Average segmentation loss on validation set: 0.0930
2022-01-20 21:33:58,577 iteration 3740 : loss : 0.019629, loss_ce: 0.006709
 55%|█████████████████              | 220/400 [40:23<34:26, 11.48s/it]2022-01-20 21:33:59,223 iteration 3741 : loss : 0.028214, loss_ce: 0.011476
2022-01-20 21:33:59,777 iteration 3742 : loss : 0.023830, loss_ce: 0.010686
2022-01-20 21:34:00,349 iteration 3743 : loss : 0.023183, loss_ce: 0.007594
2022-01-20 21:34:00,955 iteration 3744 : loss : 0.027146, loss_ce: 0.011071
2022-01-20 21:34:01,504 iteration 3745 : loss : 0.021035, loss_ce: 0.007871
2022-01-20 21:34:02,144 iteration 3746 : loss : 0.017462, loss_ce: 0.006656
2022-01-20 21:34:02,780 iteration 3747 : loss : 0.035274, loss_ce: 0.005898
2022-01-20 21:34:03,381 iteration 3748 : loss : 0.025779, loss_ce: 0.012612
2022-01-20 21:34:03,966 iteration 3749 : loss : 0.028757, loss_ce: 0.011132
2022-01-20 21:34:04,577 iteration 3750 : loss : 0.023898, loss_ce: 0.009317
2022-01-20 21:34:05,193 iteration 3751 : loss : 0.037366, loss_ce: 0.010305
2022-01-20 21:34:05,787 iteration 3752 : loss : 0.022165, loss_ce: 0.008558
2022-01-20 21:34:06,326 iteration 3753 : loss : 0.031043, loss_ce: 0.008545
2022-01-20 21:34:06,851 iteration 3754 : loss : 0.016587, loss_ce: 0.005258
2022-01-20 21:34:07,410 iteration 3755 : loss : 0.020522, loss_ce: 0.009069
2022-01-20 21:34:08,000 iteration 3756 : loss : 0.026852, loss_ce: 0.009341
2022-01-20 21:34:08,591 iteration 3757 : loss : 0.026480, loss_ce: 0.008461
 55%|█████████████████▏             | 221/400 [40:33<32:56, 11.04s/it]2022-01-20 21:34:09,247 iteration 3758 : loss : 0.026184, loss_ce: 0.009731
2022-01-20 21:34:09,836 iteration 3759 : loss : 0.023382, loss_ce: 0.008233
2022-01-20 21:34:10,337 iteration 3760 : loss : 0.020972, loss_ce: 0.007155
2022-01-20 21:34:10,980 iteration 3761 : loss : 0.027606, loss_ce: 0.010878
2022-01-20 21:34:11,573 iteration 3762 : loss : 0.027810, loss_ce: 0.008507
2022-01-20 21:34:12,224 iteration 3763 : loss : 0.026969, loss_ce: 0.010839
2022-01-20 21:34:12,858 iteration 3764 : loss : 0.030420, loss_ce: 0.012294
2022-01-20 21:34:13,453 iteration 3765 : loss : 0.019010, loss_ce: 0.007839
2022-01-20 21:34:14,040 iteration 3766 : loss : 0.034493, loss_ce: 0.013539
2022-01-20 21:34:14,706 iteration 3767 : loss : 0.027054, loss_ce: 0.008993
2022-01-20 21:34:15,313 iteration 3768 : loss : 0.025208, loss_ce: 0.011110
2022-01-20 21:34:15,875 iteration 3769 : loss : 0.017410, loss_ce: 0.006908
2022-01-20 21:34:16,408 iteration 3770 : loss : 0.018281, loss_ce: 0.005989
2022-01-20 21:34:16,965 iteration 3771 : loss : 0.019061, loss_ce: 0.006576
2022-01-20 21:34:17,551 iteration 3772 : loss : 0.020820, loss_ce: 0.006835
2022-01-20 21:34:18,082 iteration 3773 : loss : 0.020463, loss_ce: 0.008025
2022-01-20 21:34:18,627 iteration 3774 : loss : 0.020705, loss_ce: 0.008486
 56%|█████████████████▏             | 222/400 [40:43<31:51, 10.74s/it]2022-01-20 21:34:19,234 iteration 3775 : loss : 0.020912, loss_ce: 0.005490
2022-01-20 21:34:19,868 iteration 3776 : loss : 0.026898, loss_ce: 0.012192
2022-01-20 21:34:20,589 iteration 3777 : loss : 0.034325, loss_ce: 0.012291
2022-01-20 21:34:21,158 iteration 3778 : loss : 0.017230, loss_ce: 0.008179
2022-01-20 21:34:21,789 iteration 3779 : loss : 0.018684, loss_ce: 0.007038
2022-01-20 21:34:22,368 iteration 3780 : loss : 0.023436, loss_ce: 0.010962
2022-01-20 21:34:22,958 iteration 3781 : loss : 0.023731, loss_ce: 0.008859
2022-01-20 21:34:23,573 iteration 3782 : loss : 0.028092, loss_ce: 0.009650
2022-01-20 21:34:24,208 iteration 3783 : loss : 0.017899, loss_ce: 0.004734
2022-01-20 21:34:24,851 iteration 3784 : loss : 0.021524, loss_ce: 0.010332
2022-01-20 21:34:25,405 iteration 3785 : loss : 0.018681, loss_ce: 0.006856
2022-01-20 21:34:26,002 iteration 3786 : loss : 0.016386, loss_ce: 0.005500
2022-01-20 21:34:26,654 iteration 3787 : loss : 0.031371, loss_ce: 0.012615
2022-01-20 21:34:27,314 iteration 3788 : loss : 0.025126, loss_ce: 0.008498
2022-01-20 21:34:27,872 iteration 3789 : loss : 0.021172, loss_ce: 0.005802
2022-01-20 21:34:28,486 iteration 3790 : loss : 0.026597, loss_ce: 0.010828
2022-01-20 21:34:28,988 iteration 3791 : loss : 0.019364, loss_ce: 0.007309
 56%|█████████████████▎             | 223/400 [40:53<31:20, 10.62s/it]2022-01-20 21:34:29,619 iteration 3792 : loss : 0.019263, loss_ce: 0.007995
2022-01-20 21:34:30,216 iteration 3793 : loss : 0.020196, loss_ce: 0.007934
2022-01-20 21:34:30,760 iteration 3794 : loss : 0.020193, loss_ce: 0.008372
2022-01-20 21:34:31,474 iteration 3795 : loss : 0.027317, loss_ce: 0.011614
2022-01-20 21:34:32,108 iteration 3796 : loss : 0.036330, loss_ce: 0.010810
2022-01-20 21:34:32,679 iteration 3797 : loss : 0.021093, loss_ce: 0.006739
2022-01-20 21:34:33,369 iteration 3798 : loss : 0.020202, loss_ce: 0.007356
2022-01-20 21:34:33,925 iteration 3799 : loss : 0.023167, loss_ce: 0.012622
2022-01-20 21:34:34,566 iteration 3800 : loss : 0.022526, loss_ce: 0.007207
2022-01-20 21:34:35,108 iteration 3801 : loss : 0.016288, loss_ce: 0.005926
2022-01-20 21:34:35,701 iteration 3802 : loss : 0.019209, loss_ce: 0.005230
2022-01-20 21:34:36,282 iteration 3803 : loss : 0.017425, loss_ce: 0.006060
2022-01-20 21:34:36,773 iteration 3804 : loss : 0.022572, loss_ce: 0.008113
2022-01-20 21:34:37,391 iteration 3805 : loss : 0.017925, loss_ce: 0.007153
2022-01-20 21:34:37,950 iteration 3806 : loss : 0.020840, loss_ce: 0.005841
2022-01-20 21:34:38,528 iteration 3807 : loss : 0.023243, loss_ce: 0.009740
2022-01-20 21:34:39,134 iteration 3808 : loss : 0.021528, loss_ce: 0.007594
 56%|█████████████████▎             | 224/400 [41:04<30:44, 10.48s/it]2022-01-20 21:34:39,769 iteration 3809 : loss : 0.022925, loss_ce: 0.008936
2022-01-20 21:34:40,350 iteration 3810 : loss : 0.019617, loss_ce: 0.007348
2022-01-20 21:34:41,046 iteration 3811 : loss : 0.024096, loss_ce: 0.007466
2022-01-20 21:34:41,609 iteration 3812 : loss : 0.021260, loss_ce: 0.007302
2022-01-20 21:34:42,212 iteration 3813 : loss : 0.037913, loss_ce: 0.011050
2022-01-20 21:34:42,723 iteration 3814 : loss : 0.017012, loss_ce: 0.005908
2022-01-20 21:34:43,373 iteration 3815 : loss : 0.028735, loss_ce: 0.009818
2022-01-20 21:34:44,079 iteration 3816 : loss : 0.028249, loss_ce: 0.008560
2022-01-20 21:34:44,691 iteration 3817 : loss : 0.021509, loss_ce: 0.010002
2022-01-20 21:34:45,403 iteration 3818 : loss : 0.023861, loss_ce: 0.009854
2022-01-20 21:34:45,947 iteration 3819 : loss : 0.033092, loss_ce: 0.016165
2022-01-20 21:34:46,579 iteration 3820 : loss : 0.030702, loss_ce: 0.012585
2022-01-20 21:34:47,170 iteration 3821 : loss : 0.020779, loss_ce: 0.008902
2022-01-20 21:34:47,664 iteration 3822 : loss : 0.016965, loss_ce: 0.007025
2022-01-20 21:34:48,208 iteration 3823 : loss : 0.019827, loss_ce: 0.007069
2022-01-20 21:34:48,775 iteration 3824 : loss : 0.028017, loss_ce: 0.011723
2022-01-20 21:34:48,776 Training Data Eval:
2022-01-20 21:34:51,457   Average segmentation loss on training set: 0.0157
2022-01-20 21:34:51,458 Validation Data Eval:
2022-01-20 21:34:52,345   Average segmentation loss on validation set: 0.0819
2022-01-20 21:34:52,887 iteration 3825 : loss : 0.023939, loss_ce: 0.008984
 56%|█████████████████▍             | 225/400 [41:17<33:26, 11.46s/it]2022-01-20 21:34:53,426 iteration 3826 : loss : 0.023222, loss_ce: 0.009223
2022-01-20 21:34:54,020 iteration 3827 : loss : 0.031671, loss_ce: 0.013108
2022-01-20 21:34:54,636 iteration 3828 : loss : 0.027372, loss_ce: 0.011546
2022-01-20 21:34:55,216 iteration 3829 : loss : 0.029789, loss_ce: 0.014084
2022-01-20 21:34:55,808 iteration 3830 : loss : 0.024215, loss_ce: 0.010437
2022-01-20 21:34:56,469 iteration 3831 : loss : 0.033972, loss_ce: 0.008411
2022-01-20 21:34:56,978 iteration 3832 : loss : 0.016982, loss_ce: 0.005926
2022-01-20 21:34:57,590 iteration 3833 : loss : 0.020639, loss_ce: 0.006996
2022-01-20 21:34:58,156 iteration 3834 : loss : 0.015961, loss_ce: 0.007491
2022-01-20 21:34:58,803 iteration 3835 : loss : 0.023521, loss_ce: 0.011968
2022-01-20 21:34:59,465 iteration 3836 : loss : 0.025905, loss_ce: 0.009003
2022-01-20 21:34:59,990 iteration 3837 : loss : 0.018395, loss_ce: 0.007323
2022-01-20 21:35:00,531 iteration 3838 : loss : 0.022142, loss_ce: 0.007667
2022-01-20 21:35:01,078 iteration 3839 : loss : 0.026573, loss_ce: 0.010485
2022-01-20 21:35:01,570 iteration 3840 : loss : 0.022693, loss_ce: 0.006592
2022-01-20 21:35:02,120 iteration 3841 : loss : 0.017095, loss_ce: 0.005887
2022-01-20 21:35:02,677 iteration 3842 : loss : 0.025590, loss_ce: 0.005853
 56%|█████████████████▌             | 226/400 [41:27<31:46, 10.96s/it]2022-01-20 21:35:03,339 iteration 3843 : loss : 0.018607, loss_ce: 0.007651
2022-01-20 21:35:03,934 iteration 3844 : loss : 0.023472, loss_ce: 0.010237
2022-01-20 21:35:04,489 iteration 3845 : loss : 0.033072, loss_ce: 0.011021
2022-01-20 21:35:05,060 iteration 3846 : loss : 0.016666, loss_ce: 0.004477
2022-01-20 21:35:05,688 iteration 3847 : loss : 0.024736, loss_ce: 0.011936
2022-01-20 21:35:06,253 iteration 3848 : loss : 0.019850, loss_ce: 0.007895
2022-01-20 21:35:06,776 iteration 3849 : loss : 0.016554, loss_ce: 0.006154
2022-01-20 21:35:07,403 iteration 3850 : loss : 0.043556, loss_ce: 0.014757
2022-01-20 21:35:08,045 iteration 3851 : loss : 0.028215, loss_ce: 0.015354
2022-01-20 21:35:08,611 iteration 3852 : loss : 0.029447, loss_ce: 0.011076
2022-01-20 21:35:09,158 iteration 3853 : loss : 0.018449, loss_ce: 0.010062
2022-01-20 21:35:09,786 iteration 3854 : loss : 0.020387, loss_ce: 0.008267
2022-01-20 21:35:10,379 iteration 3855 : loss : 0.023605, loss_ce: 0.009712
2022-01-20 21:35:10,981 iteration 3856 : loss : 0.024084, loss_ce: 0.008447
2022-01-20 21:35:11,543 iteration 3857 : loss : 0.018719, loss_ce: 0.007603
2022-01-20 21:35:12,171 iteration 3858 : loss : 0.018389, loss_ce: 0.006412
2022-01-20 21:35:12,790 iteration 3859 : loss : 0.022880, loss_ce: 0.005102
 57%|█████████████████▌             | 227/400 [41:37<30:52, 10.71s/it]2022-01-20 21:35:13,442 iteration 3860 : loss : 0.020065, loss_ce: 0.008889
2022-01-20 21:35:14,115 iteration 3861 : loss : 0.030365, loss_ce: 0.013799
2022-01-20 21:35:14,648 iteration 3862 : loss : 0.021143, loss_ce: 0.009970
2022-01-20 21:35:15,287 iteration 3863 : loss : 0.022874, loss_ce: 0.011194
2022-01-20 21:35:15,935 iteration 3864 : loss : 0.022299, loss_ce: 0.007800
2022-01-20 21:35:16,670 iteration 3865 : loss : 0.025745, loss_ce: 0.012199
2022-01-20 21:35:17,396 iteration 3866 : loss : 0.027425, loss_ce: 0.011093
2022-01-20 21:35:17,980 iteration 3867 : loss : 0.017218, loss_ce: 0.006620
2022-01-20 21:35:18,624 iteration 3868 : loss : 0.023047, loss_ce: 0.009483
2022-01-20 21:35:19,262 iteration 3869 : loss : 0.026185, loss_ce: 0.009997
2022-01-20 21:35:19,929 iteration 3870 : loss : 0.020049, loss_ce: 0.006181
2022-01-20 21:35:20,538 iteration 3871 : loss : 0.038621, loss_ce: 0.010638
2022-01-20 21:35:21,114 iteration 3872 : loss : 0.024245, loss_ce: 0.010631
2022-01-20 21:35:21,694 iteration 3873 : loss : 0.025948, loss_ce: 0.009683
2022-01-20 21:35:22,339 iteration 3874 : loss : 0.017014, loss_ce: 0.006321
2022-01-20 21:35:22,973 iteration 3875 : loss : 0.019670, loss_ce: 0.006856
2022-01-20 21:35:23,553 iteration 3876 : loss : 0.030650, loss_ce: 0.006319
 57%|█████████████████▋             | 228/400 [41:48<30:44, 10.72s/it]2022-01-20 21:35:24,157 iteration 3877 : loss : 0.018144, loss_ce: 0.006684
2022-01-20 21:35:24,808 iteration 3878 : loss : 0.024138, loss_ce: 0.012263
2022-01-20 21:35:25,424 iteration 3879 : loss : 0.021364, loss_ce: 0.008435
2022-01-20 21:35:26,010 iteration 3880 : loss : 0.018014, loss_ce: 0.007610
2022-01-20 21:35:26,561 iteration 3881 : loss : 0.022229, loss_ce: 0.011645
2022-01-20 21:35:27,228 iteration 3882 : loss : 0.031175, loss_ce: 0.010483
2022-01-20 21:35:27,862 iteration 3883 : loss : 0.026514, loss_ce: 0.012603
2022-01-20 21:35:28,417 iteration 3884 : loss : 0.046716, loss_ce: 0.006933
2022-01-20 21:35:28,961 iteration 3885 : loss : 0.018512, loss_ce: 0.006179
2022-01-20 21:35:29,508 iteration 3886 : loss : 0.023352, loss_ce: 0.008031
2022-01-20 21:35:30,155 iteration 3887 : loss : 0.038771, loss_ce: 0.014148
2022-01-20 21:35:30,758 iteration 3888 : loss : 0.025389, loss_ce: 0.008672
2022-01-20 21:35:31,361 iteration 3889 : loss : 0.029227, loss_ce: 0.012657
2022-01-20 21:35:31,863 iteration 3890 : loss : 0.032450, loss_ce: 0.010270
2022-01-20 21:35:32,465 iteration 3891 : loss : 0.015538, loss_ce: 0.005944
2022-01-20 21:35:33,068 iteration 3892 : loss : 0.020700, loss_ce: 0.005556
2022-01-20 21:35:33,763 iteration 3893 : loss : 0.025172, loss_ce: 0.013613
 57%|█████████████████▋             | 229/400 [41:58<30:07, 10.57s/it]2022-01-20 21:35:34,338 iteration 3894 : loss : 0.026601, loss_ce: 0.010236
2022-01-20 21:35:34,985 iteration 3895 : loss : 0.034375, loss_ce: 0.012480
2022-01-20 21:35:35,560 iteration 3896 : loss : 0.033638, loss_ce: 0.008627
2022-01-20 21:35:36,195 iteration 3897 : loss : 0.034756, loss_ce: 0.018831
2022-01-20 21:35:36,760 iteration 3898 : loss : 0.026997, loss_ce: 0.010858
2022-01-20 21:35:37,395 iteration 3899 : loss : 0.022149, loss_ce: 0.009173
2022-01-20 21:35:38,071 iteration 3900 : loss : 0.030640, loss_ce: 0.010748
2022-01-20 21:35:38,618 iteration 3901 : loss : 0.020189, loss_ce: 0.006383
2022-01-20 21:35:39,183 iteration 3902 : loss : 0.018561, loss_ce: 0.007260
2022-01-20 21:35:39,779 iteration 3903 : loss : 0.022774, loss_ce: 0.008204
2022-01-20 21:35:40,452 iteration 3904 : loss : 0.023879, loss_ce: 0.007887
2022-01-20 21:35:41,055 iteration 3905 : loss : 0.030471, loss_ce: 0.012179
2022-01-20 21:35:41,614 iteration 3906 : loss : 0.023931, loss_ce: 0.010561
2022-01-20 21:35:42,225 iteration 3907 : loss : 0.041299, loss_ce: 0.011224
2022-01-20 21:35:42,892 iteration 3908 : loss : 0.029510, loss_ce: 0.010063
2022-01-20 21:35:43,520 iteration 3909 : loss : 0.019857, loss_ce: 0.007759
2022-01-20 21:35:43,521 Training Data Eval:
2022-01-20 21:35:46,207   Average segmentation loss on training set: 0.0167
2022-01-20 21:35:46,208 Validation Data Eval:
2022-01-20 21:35:47,089   Average segmentation loss on validation set: 0.1005
2022-01-20 21:35:47,607 iteration 3910 : loss : 0.018318, loss_ce: 0.006023
 57%|█████████████████▊             | 230/400 [42:12<32:43, 11.55s/it]2022-01-20 21:35:48,186 iteration 3911 : loss : 0.019163, loss_ce: 0.006677
2022-01-20 21:35:48,838 iteration 3912 : loss : 0.021544, loss_ce: 0.008435
2022-01-20 21:35:49,354 iteration 3913 : loss : 0.019730, loss_ce: 0.006246
2022-01-20 21:35:49,858 iteration 3914 : loss : 0.023621, loss_ce: 0.008347
2022-01-20 21:35:50,359 iteration 3915 : loss : 0.020632, loss_ce: 0.007033
2022-01-20 21:35:50,994 iteration 3916 : loss : 0.029763, loss_ce: 0.011246
2022-01-20 21:35:51,642 iteration 3917 : loss : 0.046401, loss_ce: 0.014215
2022-01-20 21:35:52,289 iteration 3918 : loss : 0.029011, loss_ce: 0.012684
2022-01-20 21:35:52,888 iteration 3919 : loss : 0.024116, loss_ce: 0.009242
2022-01-20 21:35:53,501 iteration 3920 : loss : 0.028396, loss_ce: 0.012156
2022-01-20 21:35:54,113 iteration 3921 : loss : 0.042721, loss_ce: 0.013093
2022-01-20 21:35:54,673 iteration 3922 : loss : 0.013911, loss_ce: 0.005777
2022-01-20 21:35:55,265 iteration 3923 : loss : 0.020958, loss_ce: 0.009759
2022-01-20 21:35:55,861 iteration 3924 : loss : 0.023495, loss_ce: 0.009926
2022-01-20 21:35:56,598 iteration 3925 : loss : 0.024901, loss_ce: 0.010672
2022-01-20 21:35:57,201 iteration 3926 : loss : 0.020715, loss_ce: 0.006987
2022-01-20 21:35:57,816 iteration 3927 : loss : 0.032541, loss_ce: 0.014281
 58%|█████████████████▉             | 231/400 [42:22<31:24, 11.15s/it]2022-01-20 21:35:58,472 iteration 3928 : loss : 0.021807, loss_ce: 0.009113
2022-01-20 21:35:59,160 iteration 3929 : loss : 0.024687, loss_ce: 0.009635
2022-01-20 21:35:59,913 iteration 3930 : loss : 0.031330, loss_ce: 0.010438
2022-01-20 21:36:00,540 iteration 3931 : loss : 0.021481, loss_ce: 0.009963
2022-01-20 21:36:01,193 iteration 3932 : loss : 0.029450, loss_ce: 0.007998
2022-01-20 21:36:01,764 iteration 3933 : loss : 0.026005, loss_ce: 0.008008
2022-01-20 21:36:02,367 iteration 3934 : loss : 0.023678, loss_ce: 0.008442
2022-01-20 21:36:03,024 iteration 3935 : loss : 0.025473, loss_ce: 0.008567
2022-01-20 21:36:03,608 iteration 3936 : loss : 0.021775, loss_ce: 0.009775
2022-01-20 21:36:04,201 iteration 3937 : loss : 0.016276, loss_ce: 0.004958
2022-01-20 21:36:04,762 iteration 3938 : loss : 0.025317, loss_ce: 0.014033
2022-01-20 21:36:05,445 iteration 3939 : loss : 0.029034, loss_ce: 0.011352
2022-01-20 21:36:06,018 iteration 3940 : loss : 0.024659, loss_ce: 0.007079
2022-01-20 21:36:06,616 iteration 3941 : loss : 0.018775, loss_ce: 0.008306
2022-01-20 21:36:07,200 iteration 3942 : loss : 0.027764, loss_ce: 0.011991
2022-01-20 21:36:07,845 iteration 3943 : loss : 0.026155, loss_ce: 0.011845
2022-01-20 21:36:08,462 iteration 3944 : loss : 0.017897, loss_ce: 0.005697
 58%|█████████████████▉             | 232/400 [42:33<30:47, 11.00s/it]2022-01-20 21:36:09,088 iteration 3945 : loss : 0.016640, loss_ce: 0.007826
2022-01-20 21:36:09,598 iteration 3946 : loss : 0.016660, loss_ce: 0.006644
2022-01-20 21:36:10,184 iteration 3947 : loss : 0.021249, loss_ce: 0.008299
2022-01-20 21:36:10,757 iteration 3948 : loss : 0.022639, loss_ce: 0.009777
2022-01-20 21:36:11,359 iteration 3949 : loss : 0.022857, loss_ce: 0.010442
2022-01-20 21:36:11,945 iteration 3950 : loss : 0.020220, loss_ce: 0.007445
2022-01-20 21:36:12,572 iteration 3951 : loss : 0.029870, loss_ce: 0.012157
2022-01-20 21:36:13,154 iteration 3952 : loss : 0.018434, loss_ce: 0.008394
2022-01-20 21:36:13,742 iteration 3953 : loss : 0.020408, loss_ce: 0.006024
2022-01-20 21:36:14,374 iteration 3954 : loss : 0.026414, loss_ce: 0.011262
2022-01-20 21:36:14,992 iteration 3955 : loss : 0.023218, loss_ce: 0.008689
2022-01-20 21:36:15,563 iteration 3956 : loss : 0.021123, loss_ce: 0.008773
2022-01-20 21:36:16,140 iteration 3957 : loss : 0.023274, loss_ce: 0.010510
2022-01-20 21:36:16,819 iteration 3958 : loss : 0.027563, loss_ce: 0.012936
2022-01-20 21:36:17,385 iteration 3959 : loss : 0.020132, loss_ce: 0.006338
2022-01-20 21:36:17,984 iteration 3960 : loss : 0.026018, loss_ce: 0.006304
2022-01-20 21:36:18,620 iteration 3961 : loss : 0.018413, loss_ce: 0.006626
 58%|██████████████████             | 233/400 [42:43<29:54, 10.75s/it]2022-01-20 21:36:19,401 iteration 3962 : loss : 0.028751, loss_ce: 0.011676
2022-01-20 21:36:19,942 iteration 3963 : loss : 0.020606, loss_ce: 0.007748
2022-01-20 21:36:20,583 iteration 3964 : loss : 0.030692, loss_ce: 0.015083
2022-01-20 21:36:21,282 iteration 3965 : loss : 0.028217, loss_ce: 0.009215
2022-01-20 21:36:21,860 iteration 3966 : loss : 0.017378, loss_ce: 0.005822
2022-01-20 21:36:22,423 iteration 3967 : loss : 0.017536, loss_ce: 0.004582
2022-01-20 21:36:23,101 iteration 3968 : loss : 0.021254, loss_ce: 0.007544
2022-01-20 21:36:23,762 iteration 3969 : loss : 0.019535, loss_ce: 0.008207
2022-01-20 21:36:24,452 iteration 3970 : loss : 0.022016, loss_ce: 0.010637
2022-01-20 21:36:25,017 iteration 3971 : loss : 0.019174, loss_ce: 0.006214
2022-01-20 21:36:25,580 iteration 3972 : loss : 0.023673, loss_ce: 0.008419
2022-01-20 21:36:26,198 iteration 3973 : loss : 0.028913, loss_ce: 0.010770
2022-01-20 21:36:26,877 iteration 3974 : loss : 0.023775, loss_ce: 0.010503
2022-01-20 21:36:27,553 iteration 3975 : loss : 0.023364, loss_ce: 0.007726
2022-01-20 21:36:28,254 iteration 3976 : loss : 0.028386, loss_ce: 0.013583
2022-01-20 21:36:28,856 iteration 3977 : loss : 0.022512, loss_ce: 0.008538
2022-01-20 21:36:29,441 iteration 3978 : loss : 0.022235, loss_ce: 0.010354
 58%|██████████████████▏            | 234/400 [42:54<29:47, 10.77s/it]2022-01-20 21:36:30,089 iteration 3979 : loss : 0.031426, loss_ce: 0.011603
2022-01-20 21:36:30,713 iteration 3980 : loss : 0.022102, loss_ce: 0.011136
2022-01-20 21:36:31,276 iteration 3981 : loss : 0.023211, loss_ce: 0.008778
2022-01-20 21:36:32,015 iteration 3982 : loss : 0.022396, loss_ce: 0.007464
2022-01-20 21:36:32,618 iteration 3983 : loss : 0.022130, loss_ce: 0.006451
2022-01-20 21:36:33,266 iteration 3984 : loss : 0.024436, loss_ce: 0.009331
2022-01-20 21:36:33,874 iteration 3985 : loss : 0.020170, loss_ce: 0.006655
2022-01-20 21:36:34,433 iteration 3986 : loss : 0.019028, loss_ce: 0.007901
2022-01-20 21:36:35,002 iteration 3987 : loss : 0.016828, loss_ce: 0.007368
2022-01-20 21:36:35,656 iteration 3988 : loss : 0.029678, loss_ce: 0.013827
2022-01-20 21:36:36,275 iteration 3989 : loss : 0.029420, loss_ce: 0.010772
2022-01-20 21:36:36,866 iteration 3990 : loss : 0.019444, loss_ce: 0.007420
2022-01-20 21:36:37,462 iteration 3991 : loss : 0.026461, loss_ce: 0.008956
2022-01-20 21:36:38,189 iteration 3992 : loss : 0.036597, loss_ce: 0.009343
2022-01-20 21:36:38,785 iteration 3993 : loss : 0.020961, loss_ce: 0.010438
2022-01-20 21:36:39,377 iteration 3994 : loss : 0.019120, loss_ce: 0.008020
2022-01-20 21:36:39,377 Training Data Eval:
2022-01-20 21:36:42,071   Average segmentation loss on training set: 0.0140
2022-01-20 21:36:42,071 Validation Data Eval:
2022-01-20 21:36:42,947   Average segmentation loss on validation set: 0.1163
2022-01-20 21:36:43,521 iteration 3995 : loss : 0.021103, loss_ce: 0.005630
 59%|██████████████████▏            | 235/400 [43:08<32:20, 11.76s/it]2022-01-20 21:36:44,232 iteration 3996 : loss : 0.020459, loss_ce: 0.010224
2022-01-20 21:36:44,866 iteration 3997 : loss : 0.022730, loss_ce: 0.007884
2022-01-20 21:36:45,457 iteration 3998 : loss : 0.022971, loss_ce: 0.008224
2022-01-20 21:36:46,109 iteration 3999 : loss : 0.026022, loss_ce: 0.008372
2022-01-20 21:36:46,718 iteration 4000 : loss : 0.020248, loss_ce: 0.008103
2022-01-20 21:36:47,427 iteration 4001 : loss : 0.030047, loss_ce: 0.008978
2022-01-20 21:36:48,025 iteration 4002 : loss : 0.018954, loss_ce: 0.008994
2022-01-20 21:36:48,623 iteration 4003 : loss : 0.024235, loss_ce: 0.009760
2022-01-20 21:36:49,210 iteration 4004 : loss : 0.022420, loss_ce: 0.008109
2022-01-20 21:36:49,817 iteration 4005 : loss : 0.024017, loss_ce: 0.012260
2022-01-20 21:36:50,520 iteration 4006 : loss : 0.024840, loss_ce: 0.009492
2022-01-20 21:36:51,100 iteration 4007 : loss : 0.018703, loss_ce: 0.007141
2022-01-20 21:36:51,714 iteration 4008 : loss : 0.026093, loss_ce: 0.009775
2022-01-20 21:36:52,311 iteration 4009 : loss : 0.018240, loss_ce: 0.007126
2022-01-20 21:36:52,841 iteration 4010 : loss : 0.013524, loss_ce: 0.005101
2022-01-20 21:36:53,486 iteration 4011 : loss : 0.025219, loss_ce: 0.007378
2022-01-20 21:36:54,130 iteration 4012 : loss : 0.020623, loss_ce: 0.009874
 59%|██████████████████▎            | 236/400 [43:18<31:12, 11.42s/it]2022-01-20 21:36:54,761 iteration 4013 : loss : 0.021054, loss_ce: 0.005544
2022-01-20 21:36:55,410 iteration 4014 : loss : 0.023128, loss_ce: 0.007519
2022-01-20 21:36:55,980 iteration 4015 : loss : 0.020605, loss_ce: 0.010518
2022-01-20 21:36:56,610 iteration 4016 : loss : 0.021665, loss_ce: 0.007141
2022-01-20 21:36:57,167 iteration 4017 : loss : 0.019930, loss_ce: 0.007605
2022-01-20 21:36:57,839 iteration 4018 : loss : 0.026934, loss_ce: 0.009936
2022-01-20 21:36:58,511 iteration 4019 : loss : 0.022870, loss_ce: 0.010731
2022-01-20 21:36:59,096 iteration 4020 : loss : 0.018390, loss_ce: 0.006471
2022-01-20 21:36:59,702 iteration 4021 : loss : 0.019280, loss_ce: 0.007071
2022-01-20 21:37:00,302 iteration 4022 : loss : 0.029053, loss_ce: 0.009364
2022-01-20 21:37:00,921 iteration 4023 : loss : 0.018448, loss_ce: 0.008027
2022-01-20 21:37:01,543 iteration 4024 : loss : 0.032714, loss_ce: 0.010506
2022-01-20 21:37:02,124 iteration 4025 : loss : 0.020632, loss_ce: 0.008217
2022-01-20 21:37:02,698 iteration 4026 : loss : 0.017730, loss_ce: 0.007479
2022-01-20 21:37:03,273 iteration 4027 : loss : 0.019109, loss_ce: 0.007319
2022-01-20 21:37:03,861 iteration 4028 : loss : 0.021427, loss_ce: 0.005977
2022-01-20 21:37:04,477 iteration 4029 : loss : 0.019908, loss_ce: 0.008326
 59%|██████████████████▎            | 237/400 [43:29<30:08, 11.09s/it]2022-01-20 21:37:05,137 iteration 4030 : loss : 0.027957, loss_ce: 0.010868
2022-01-20 21:37:05,728 iteration 4031 : loss : 0.023602, loss_ce: 0.009640
2022-01-20 21:37:06,379 iteration 4032 : loss : 0.021510, loss_ce: 0.009912
2022-01-20 21:37:07,076 iteration 4033 : loss : 0.037813, loss_ce: 0.009868
2022-01-20 21:37:07,649 iteration 4034 : loss : 0.025664, loss_ce: 0.008923
2022-01-20 21:37:08,316 iteration 4035 : loss : 0.023722, loss_ce: 0.008130
2022-01-20 21:37:08,907 iteration 4036 : loss : 0.015676, loss_ce: 0.005437
2022-01-20 21:37:09,561 iteration 4037 : loss : 0.025132, loss_ce: 0.007292
2022-01-20 21:37:10,173 iteration 4038 : loss : 0.027789, loss_ce: 0.018273
2022-01-20 21:37:10,674 iteration 4039 : loss : 0.018217, loss_ce: 0.008459
2022-01-20 21:37:11,260 iteration 4040 : loss : 0.031241, loss_ce: 0.008245
2022-01-20 21:37:11,969 iteration 4041 : loss : 0.046676, loss_ce: 0.031282
2022-01-20 21:37:12,498 iteration 4042 : loss : 0.021160, loss_ce: 0.009879
2022-01-20 21:37:13,112 iteration 4043 : loss : 0.021089, loss_ce: 0.007245
2022-01-20 21:37:13,721 iteration 4044 : loss : 0.021584, loss_ce: 0.009130
2022-01-20 21:37:14,295 iteration 4045 : loss : 0.017746, loss_ce: 0.007270
2022-01-20 21:37:14,943 iteration 4046 : loss : 0.021347, loss_ce: 0.007343
 60%|██████████████████▍            | 238/400 [43:39<29:26, 10.91s/it]2022-01-20 21:37:15,531 iteration 4047 : loss : 0.017290, loss_ce: 0.007503
2022-01-20 21:37:16,120 iteration 4048 : loss : 0.017521, loss_ce: 0.005074
2022-01-20 21:37:16,802 iteration 4049 : loss : 0.023942, loss_ce: 0.008540
2022-01-20 21:37:17,408 iteration 4050 : loss : 0.030429, loss_ce: 0.009257
2022-01-20 21:37:18,023 iteration 4051 : loss : 0.015043, loss_ce: 0.005190
2022-01-20 21:37:18,620 iteration 4052 : loss : 0.017520, loss_ce: 0.005643
2022-01-20 21:37:19,205 iteration 4053 : loss : 0.021361, loss_ce: 0.010668
2022-01-20 21:37:19,769 iteration 4054 : loss : 0.020569, loss_ce: 0.008750
2022-01-20 21:37:20,479 iteration 4055 : loss : 0.026791, loss_ce: 0.008840
2022-01-20 21:37:21,128 iteration 4056 : loss : 0.025228, loss_ce: 0.009623
2022-01-20 21:37:21,801 iteration 4057 : loss : 0.026738, loss_ce: 0.011928
2022-01-20 21:37:22,324 iteration 4058 : loss : 0.022417, loss_ce: 0.012648
2022-01-20 21:37:22,983 iteration 4059 : loss : 0.019954, loss_ce: 0.008504
2022-01-20 21:37:23,613 iteration 4060 : loss : 0.021409, loss_ce: 0.007909
2022-01-20 21:37:24,202 iteration 4061 : loss : 0.032430, loss_ce: 0.009730
2022-01-20 21:37:24,776 iteration 4062 : loss : 0.025017, loss_ce: 0.011125
2022-01-20 21:37:25,490 iteration 4063 : loss : 0.035057, loss_ce: 0.011302
 60%|██████████████████▌            | 239/400 [43:50<28:58, 10.80s/it]2022-01-20 21:37:26,130 iteration 4064 : loss : 0.022307, loss_ce: 0.009262
2022-01-20 21:37:26,721 iteration 4065 : loss : 0.021246, loss_ce: 0.008211
2022-01-20 21:37:27,236 iteration 4066 : loss : 0.016643, loss_ce: 0.005285
2022-01-20 21:37:27,785 iteration 4067 : loss : 0.024330, loss_ce: 0.005914
2022-01-20 21:37:28,401 iteration 4068 : loss : 0.016197, loss_ce: 0.005986
2022-01-20 21:37:29,051 iteration 4069 : loss : 0.022482, loss_ce: 0.007956
2022-01-20 21:37:29,685 iteration 4070 : loss : 0.023577, loss_ce: 0.012087
2022-01-20 21:37:30,230 iteration 4071 : loss : 0.022185, loss_ce: 0.009651
2022-01-20 21:37:30,826 iteration 4072 : loss : 0.019883, loss_ce: 0.008418
2022-01-20 21:37:31,443 iteration 4073 : loss : 0.024540, loss_ce: 0.012007
2022-01-20 21:37:31,997 iteration 4074 : loss : 0.021670, loss_ce: 0.008526
2022-01-20 21:37:32,649 iteration 4075 : loss : 0.021768, loss_ce: 0.008574
2022-01-20 21:37:33,267 iteration 4076 : loss : 0.020894, loss_ce: 0.007387
2022-01-20 21:37:33,899 iteration 4077 : loss : 0.019058, loss_ce: 0.008274
2022-01-20 21:37:34,574 iteration 4078 : loss : 0.031416, loss_ce: 0.008745
2022-01-20 21:37:35,191 iteration 4079 : loss : 0.021329, loss_ce: 0.007932
2022-01-20 21:37:35,191 Training Data Eval:
2022-01-20 21:37:37,871   Average segmentation loss on training set: 0.0138
2022-01-20 21:37:37,871 Validation Data Eval:
2022-01-20 21:37:38,758   Average segmentation loss on validation set: 0.0903
2022-01-20 21:37:39,368 iteration 4080 : loss : 0.024950, loss_ce: 0.008132
 60%|██████████████████▌            | 240/400 [44:04<31:15, 11.72s/it]2022-01-20 21:37:40,006 iteration 4081 : loss : 0.021294, loss_ce: 0.011007
2022-01-20 21:37:40,694 iteration 4082 : loss : 0.022815, loss_ce: 0.009153
2022-01-20 21:37:41,229 iteration 4083 : loss : 0.020305, loss_ce: 0.008255
2022-01-20 21:37:41,795 iteration 4084 : loss : 0.020822, loss_ce: 0.006692
2022-01-20 21:37:42,390 iteration 4085 : loss : 0.024285, loss_ce: 0.005669
2022-01-20 21:37:42,958 iteration 4086 : loss : 0.021188, loss_ce: 0.006913
2022-01-20 21:37:43,551 iteration 4087 : loss : 0.021617, loss_ce: 0.006349
2022-01-20 21:37:44,164 iteration 4088 : loss : 0.026645, loss_ce: 0.011630
2022-01-20 21:37:44,787 iteration 4089 : loss : 0.026345, loss_ce: 0.008820
2022-01-20 21:37:45,390 iteration 4090 : loss : 0.030507, loss_ce: 0.015656
2022-01-20 21:37:46,041 iteration 4091 : loss : 0.035350, loss_ce: 0.010904
2022-01-20 21:37:46,591 iteration 4092 : loss : 0.027608, loss_ce: 0.007539
2022-01-20 21:37:47,166 iteration 4093 : loss : 0.017685, loss_ce: 0.007516
2022-01-20 21:37:47,842 iteration 4094 : loss : 0.028353, loss_ce: 0.010920
2022-01-20 21:37:48,456 iteration 4095 : loss : 0.021078, loss_ce: 0.007077
2022-01-20 21:37:49,106 iteration 4096 : loss : 0.030525, loss_ce: 0.014852
2022-01-20 21:37:49,764 iteration 4097 : loss : 0.021684, loss_ce: 0.008944
 60%|██████████████████▋            | 241/400 [44:14<30:00, 11.32s/it]2022-01-20 21:37:50,425 iteration 4098 : loss : 0.023907, loss_ce: 0.010981
2022-01-20 21:37:51,036 iteration 4099 : loss : 0.020944, loss_ce: 0.007151
2022-01-20 21:37:51,599 iteration 4100 : loss : 0.023755, loss_ce: 0.010164
2022-01-20 21:37:52,223 iteration 4101 : loss : 0.020729, loss_ce: 0.009234
2022-01-20 21:37:52,908 iteration 4102 : loss : 0.034494, loss_ce: 0.012723
2022-01-20 21:37:53,430 iteration 4103 : loss : 0.017855, loss_ce: 0.007040
2022-01-20 21:37:54,053 iteration 4104 : loss : 0.028560, loss_ce: 0.010927
2022-01-20 21:37:54,702 iteration 4105 : loss : 0.034001, loss_ce: 0.013890
2022-01-20 21:37:55,396 iteration 4106 : loss : 0.031691, loss_ce: 0.012039
2022-01-20 21:37:56,034 iteration 4107 : loss : 0.024452, loss_ce: 0.009273
2022-01-20 21:37:56,685 iteration 4108 : loss : 0.027774, loss_ce: 0.012419
2022-01-20 21:37:57,320 iteration 4109 : loss : 0.021425, loss_ce: 0.006403
2022-01-20 21:37:57,984 iteration 4110 : loss : 0.017245, loss_ce: 0.005805
2022-01-20 21:37:58,605 iteration 4111 : loss : 0.024321, loss_ce: 0.007778
2022-01-20 21:37:59,104 iteration 4112 : loss : 0.016825, loss_ce: 0.007159
2022-01-20 21:37:59,767 iteration 4113 : loss : 0.028733, loss_ce: 0.008412
2022-01-20 21:38:00,373 iteration 4114 : loss : 0.022041, loss_ce: 0.009090
 60%|██████████████████▊            | 242/400 [44:25<29:15, 11.11s/it]2022-01-20 21:38:01,011 iteration 4115 : loss : 0.021250, loss_ce: 0.006204
2022-01-20 21:38:01,575 iteration 4116 : loss : 0.022245, loss_ce: 0.009435
2022-01-20 21:38:02,122 iteration 4117 : loss : 0.017247, loss_ce: 0.008732
2022-01-20 21:38:02,705 iteration 4118 : loss : 0.022549, loss_ce: 0.007002
2022-01-20 21:38:03,205 iteration 4119 : loss : 0.017073, loss_ce: 0.006524
2022-01-20 21:38:03,925 iteration 4120 : loss : 0.025884, loss_ce: 0.008607
2022-01-20 21:38:04,528 iteration 4121 : loss : 0.021730, loss_ce: 0.008299
2022-01-20 21:38:05,164 iteration 4122 : loss : 0.020807, loss_ce: 0.007208
2022-01-20 21:38:05,803 iteration 4123 : loss : 0.019509, loss_ce: 0.008151
2022-01-20 21:38:06,328 iteration 4124 : loss : 0.018076, loss_ce: 0.006700
2022-01-20 21:38:06,957 iteration 4125 : loss : 0.038987, loss_ce: 0.013616
2022-01-20 21:38:07,688 iteration 4126 : loss : 0.025117, loss_ce: 0.009362
2022-01-20 21:38:08,362 iteration 4127 : loss : 0.025882, loss_ce: 0.012272
2022-01-20 21:38:08,940 iteration 4128 : loss : 0.018482, loss_ce: 0.008181
2022-01-20 21:38:09,669 iteration 4129 : loss : 0.028319, loss_ce: 0.008693
2022-01-20 21:38:10,335 iteration 4130 : loss : 0.022306, loss_ce: 0.007379
2022-01-20 21:38:10,940 iteration 4131 : loss : 0.017412, loss_ce: 0.007091
 61%|██████████████████▊            | 243/400 [44:35<28:38, 10.95s/it]2022-01-20 21:38:11,636 iteration 4132 : loss : 0.029605, loss_ce: 0.010876
2022-01-20 21:38:12,186 iteration 4133 : loss : 0.024232, loss_ce: 0.011784
2022-01-20 21:38:12,852 iteration 4134 : loss : 0.016562, loss_ce: 0.006902
2022-01-20 21:38:13,468 iteration 4135 : loss : 0.029000, loss_ce: 0.010456
2022-01-20 21:38:14,063 iteration 4136 : loss : 0.022038, loss_ce: 0.007144
2022-01-20 21:38:14,691 iteration 4137 : loss : 0.020134, loss_ce: 0.010153
2022-01-20 21:38:15,327 iteration 4138 : loss : 0.023875, loss_ce: 0.012914
2022-01-20 21:38:15,962 iteration 4139 : loss : 0.049072, loss_ce: 0.014460
2022-01-20 21:38:16,626 iteration 4140 : loss : 0.027325, loss_ce: 0.009303
2022-01-20 21:38:17,235 iteration 4141 : loss : 0.020258, loss_ce: 0.005192
2022-01-20 21:38:17,814 iteration 4142 : loss : 0.018296, loss_ce: 0.008030
2022-01-20 21:38:18,381 iteration 4143 : loss : 0.020359, loss_ce: 0.007043
2022-01-20 21:38:19,004 iteration 4144 : loss : 0.025769, loss_ce: 0.008561
2022-01-20 21:38:19,590 iteration 4145 : loss : 0.029802, loss_ce: 0.011045
2022-01-20 21:38:20,085 iteration 4146 : loss : 0.017870, loss_ce: 0.004678
2022-01-20 21:38:20,658 iteration 4147 : loss : 0.021207, loss_ce: 0.007556
2022-01-20 21:38:21,250 iteration 4148 : loss : 0.034395, loss_ce: 0.012472
 61%|██████████████████▉            | 244/400 [44:46<27:58, 10.76s/it]2022-01-20 21:38:21,897 iteration 4149 : loss : 0.025766, loss_ce: 0.010078
2022-01-20 21:38:22,474 iteration 4150 : loss : 0.022343, loss_ce: 0.007745
2022-01-20 21:38:23,059 iteration 4151 : loss : 0.023561, loss_ce: 0.010465
2022-01-20 21:38:23,731 iteration 4152 : loss : 0.024426, loss_ce: 0.010335
2022-01-20 21:38:24,368 iteration 4153 : loss : 0.028241, loss_ce: 0.012126
2022-01-20 21:38:24,905 iteration 4154 : loss : 0.016109, loss_ce: 0.006424
2022-01-20 21:38:25,464 iteration 4155 : loss : 0.019292, loss_ce: 0.009105
2022-01-20 21:38:26,065 iteration 4156 : loss : 0.028415, loss_ce: 0.009454
2022-01-20 21:38:26,682 iteration 4157 : loss : 0.018580, loss_ce: 0.006907
2022-01-20 21:38:27,267 iteration 4158 : loss : 0.017423, loss_ce: 0.006793
2022-01-20 21:38:27,928 iteration 4159 : loss : 0.021900, loss_ce: 0.012067
2022-01-20 21:38:28,552 iteration 4160 : loss : 0.028021, loss_ce: 0.010322
2022-01-20 21:38:29,124 iteration 4161 : loss : 0.019667, loss_ce: 0.005680
2022-01-20 21:38:29,753 iteration 4162 : loss : 0.020101, loss_ce: 0.007199
2022-01-20 21:38:30,371 iteration 4163 : loss : 0.025513, loss_ce: 0.008821
2022-01-20 21:38:30,953 iteration 4164 : loss : 0.019620, loss_ce: 0.005592
2022-01-20 21:38:30,953 Training Data Eval:
2022-01-20 21:38:33,631   Average segmentation loss on training set: 0.0150
2022-01-20 21:38:33,632 Validation Data Eval:
2022-01-20 21:38:34,512   Average segmentation loss on validation set: 0.0778
2022-01-20 21:38:35,091 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:38:35,712 iteration 4165 : loss : 0.028836, loss_ce: 0.011244
 61%|██████████████████▉            | 245/400 [45:00<30:39, 11.87s/it]2022-01-20 21:38:36,328 iteration 4166 : loss : 0.033465, loss_ce: 0.007839
2022-01-20 21:38:36,891 iteration 4167 : loss : 0.015497, loss_ce: 0.006653
2022-01-20 21:38:37,407 iteration 4168 : loss : 0.022414, loss_ce: 0.006540
2022-01-20 21:38:37,959 iteration 4169 : loss : 0.017235, loss_ce: 0.007611
2022-01-20 21:38:38,643 iteration 4170 : loss : 0.026737, loss_ce: 0.009845
2022-01-20 21:38:39,350 iteration 4171 : loss : 0.020902, loss_ce: 0.007909
2022-01-20 21:38:39,893 iteration 4172 : loss : 0.019725, loss_ce: 0.004810
2022-01-20 21:38:40,498 iteration 4173 : loss : 0.024827, loss_ce: 0.008287
2022-01-20 21:38:41,101 iteration 4174 : loss : 0.025691, loss_ce: 0.011261
2022-01-20 21:38:41,744 iteration 4175 : loss : 0.017428, loss_ce: 0.006185
2022-01-20 21:38:42,361 iteration 4176 : loss : 0.021521, loss_ce: 0.009410
2022-01-20 21:38:42,986 iteration 4177 : loss : 0.021726, loss_ce: 0.007267
2022-01-20 21:38:43,579 iteration 4178 : loss : 0.016936, loss_ce: 0.007597
2022-01-20 21:38:44,260 iteration 4179 : loss : 0.028598, loss_ce: 0.010513
2022-01-20 21:38:44,864 iteration 4180 : loss : 0.035490, loss_ce: 0.011558
2022-01-20 21:38:45,364 iteration 4181 : loss : 0.028541, loss_ce: 0.008889
2022-01-20 21:38:45,991 iteration 4182 : loss : 0.018636, loss_ce: 0.007959
 62%|███████████████████            | 246/400 [45:10<29:14, 11.39s/it]2022-01-20 21:38:46,637 iteration 4183 : loss : 0.024258, loss_ce: 0.010402
2022-01-20 21:38:47,248 iteration 4184 : loss : 0.025616, loss_ce: 0.009958
2022-01-20 21:38:47,842 iteration 4185 : loss : 0.019790, loss_ce: 0.007159
2022-01-20 21:38:48,411 iteration 4186 : loss : 0.017017, loss_ce: 0.006802
2022-01-20 21:38:49,080 iteration 4187 : loss : 0.020382, loss_ce: 0.007147
2022-01-20 21:38:49,731 iteration 4188 : loss : 0.021960, loss_ce: 0.010676
2022-01-20 21:38:50,357 iteration 4189 : loss : 0.018796, loss_ce: 0.005343
2022-01-20 21:38:51,026 iteration 4190 : loss : 0.027474, loss_ce: 0.009513
2022-01-20 21:38:51,604 iteration 4191 : loss : 0.023079, loss_ce: 0.007458
2022-01-20 21:38:52,210 iteration 4192 : loss : 0.016637, loss_ce: 0.004940
2022-01-20 21:38:52,822 iteration 4193 : loss : 0.022282, loss_ce: 0.006635
2022-01-20 21:38:53,454 iteration 4194 : loss : 0.021545, loss_ce: 0.008221
2022-01-20 21:38:54,210 iteration 4195 : loss : 0.032059, loss_ce: 0.011034
2022-01-20 21:38:54,778 iteration 4196 : loss : 0.018549, loss_ce: 0.010318
2022-01-20 21:38:55,439 iteration 4197 : loss : 0.017920, loss_ce: 0.005693
2022-01-20 21:38:56,050 iteration 4198 : loss : 0.022020, loss_ce: 0.007929
2022-01-20 21:38:56,578 iteration 4199 : loss : 0.023825, loss_ce: 0.008323
 62%|███████████████████▏           | 247/400 [45:21<28:26, 11.15s/it]2022-01-20 21:38:57,183 iteration 4200 : loss : 0.023035, loss_ce: 0.006654
2022-01-20 21:38:57,810 iteration 4201 : loss : 0.018392, loss_ce: 0.007840
2022-01-20 21:38:58,337 iteration 4202 : loss : 0.015774, loss_ce: 0.007072
2022-01-20 21:38:58,891 iteration 4203 : loss : 0.017873, loss_ce: 0.007406
2022-01-20 21:38:59,480 iteration 4204 : loss : 0.018492, loss_ce: 0.006187
2022-01-20 21:39:00,046 iteration 4205 : loss : 0.018883, loss_ce: 0.006393
2022-01-20 21:39:00,559 iteration 4206 : loss : 0.022838, loss_ce: 0.006230
2022-01-20 21:39:01,115 iteration 4207 : loss : 0.016570, loss_ce: 0.007029
2022-01-20 21:39:01,683 iteration 4208 : loss : 0.018986, loss_ce: 0.006586
2022-01-20 21:39:02,368 iteration 4209 : loss : 0.037790, loss_ce: 0.009637
2022-01-20 21:39:03,031 iteration 4210 : loss : 0.023367, loss_ce: 0.009748
2022-01-20 21:39:03,491 iteration 4211 : loss : 0.014264, loss_ce: 0.005636
2022-01-20 21:39:04,076 iteration 4212 : loss : 0.020635, loss_ce: 0.009208
2022-01-20 21:39:04,661 iteration 4213 : loss : 0.021713, loss_ce: 0.009468
2022-01-20 21:39:05,304 iteration 4214 : loss : 0.026658, loss_ce: 0.009670
2022-01-20 21:39:05,875 iteration 4215 : loss : 0.019992, loss_ce: 0.006653
2022-01-20 21:39:06,564 iteration 4216 : loss : 0.031537, loss_ce: 0.009304
 62%|███████████████████▏           | 248/400 [45:31<27:21, 10.80s/it]2022-01-20 21:39:07,296 iteration 4217 : loss : 0.020495, loss_ce: 0.008623
2022-01-20 21:39:07,821 iteration 4218 : loss : 0.016858, loss_ce: 0.008670
2022-01-20 21:39:08,367 iteration 4219 : loss : 0.022622, loss_ce: 0.008761
2022-01-20 21:39:09,090 iteration 4220 : loss : 0.027178, loss_ce: 0.009823
2022-01-20 21:39:09,720 iteration 4221 : loss : 0.027343, loss_ce: 0.007715
2022-01-20 21:39:10,357 iteration 4222 : loss : 0.022499, loss_ce: 0.009755
2022-01-20 21:39:10,967 iteration 4223 : loss : 0.020000, loss_ce: 0.007101
2022-01-20 21:39:11,559 iteration 4224 : loss : 0.020490, loss_ce: 0.006160
2022-01-20 21:39:12,129 iteration 4225 : loss : 0.021357, loss_ce: 0.006827
2022-01-20 21:39:12,709 iteration 4226 : loss : 0.014162, loss_ce: 0.004056
2022-01-20 21:39:13,409 iteration 4227 : loss : 0.024632, loss_ce: 0.007936
2022-01-20 21:39:13,999 iteration 4228 : loss : 0.020625, loss_ce: 0.007753
2022-01-20 21:39:14,638 iteration 4229 : loss : 0.030317, loss_ce: 0.011142
2022-01-20 21:39:15,243 iteration 4230 : loss : 0.020418, loss_ce: 0.009729
2022-01-20 21:39:15,812 iteration 4231 : loss : 0.031919, loss_ce: 0.009284
2022-01-20 21:39:16,388 iteration 4232 : loss : 0.023282, loss_ce: 0.009010
2022-01-20 21:39:16,990 iteration 4233 : loss : 0.023798, loss_ce: 0.010935
 62%|███████████████████▎           | 249/400 [45:41<26:53, 10.69s/it]2022-01-20 21:39:17,700 iteration 4234 : loss : 0.033871, loss_ce: 0.014608
2022-01-20 21:39:18,296 iteration 4235 : loss : 0.018480, loss_ce: 0.005092
2022-01-20 21:39:18,833 iteration 4236 : loss : 0.017591, loss_ce: 0.006772
2022-01-20 21:39:19,383 iteration 4237 : loss : 0.022969, loss_ce: 0.009896
2022-01-20 21:39:19,963 iteration 4238 : loss : 0.018680, loss_ce: 0.005977
2022-01-20 21:39:20,602 iteration 4239 : loss : 0.025015, loss_ce: 0.009778
2022-01-20 21:39:21,218 iteration 4240 : loss : 0.025934, loss_ce: 0.008336
2022-01-20 21:39:21,811 iteration 4241 : loss : 0.023451, loss_ce: 0.009736
2022-01-20 21:39:22,292 iteration 4242 : loss : 0.015818, loss_ce: 0.006354
2022-01-20 21:39:22,905 iteration 4243 : loss : 0.032010, loss_ce: 0.012102
2022-01-20 21:39:23,445 iteration 4244 : loss : 0.019717, loss_ce: 0.006199
2022-01-20 21:39:24,024 iteration 4245 : loss : 0.020604, loss_ce: 0.007387
2022-01-20 21:39:24,588 iteration 4246 : loss : 0.021456, loss_ce: 0.007291
2022-01-20 21:39:25,171 iteration 4247 : loss : 0.021090, loss_ce: 0.005726
2022-01-20 21:39:25,683 iteration 4248 : loss : 0.022160, loss_ce: 0.008263
2022-01-20 21:39:26,336 iteration 4249 : loss : 0.024131, loss_ce: 0.011118
2022-01-20 21:39:26,337 Training Data Eval:
2022-01-20 21:39:29,022   Average segmentation loss on training set: 0.0149
2022-01-20 21:39:29,022 Validation Data Eval:
2022-01-20 21:39:29,898   Average segmentation loss on validation set: 0.1206
2022-01-20 21:39:30,500 iteration 4250 : loss : 0.020394, loss_ce: 0.007581
 62%|███████████████████▍           | 250/400 [45:55<28:50, 11.54s/it]2022-01-20 21:39:31,159 iteration 4251 : loss : 0.017165, loss_ce: 0.005366
2022-01-20 21:39:31,764 iteration 4252 : loss : 0.018927, loss_ce: 0.005082
2022-01-20 21:39:32,397 iteration 4253 : loss : 0.016779, loss_ce: 0.008235
2022-01-20 21:39:33,023 iteration 4254 : loss : 0.022002, loss_ce: 0.008817
2022-01-20 21:39:33,650 iteration 4255 : loss : 0.024423, loss_ce: 0.007681
2022-01-20 21:39:34,217 iteration 4256 : loss : 0.031436, loss_ce: 0.010425
2022-01-20 21:39:34,815 iteration 4257 : loss : 0.024614, loss_ce: 0.012226
2022-01-20 21:39:35,482 iteration 4258 : loss : 0.028851, loss_ce: 0.015459
2022-01-20 21:39:35,983 iteration 4259 : loss : 0.016125, loss_ce: 0.005796
2022-01-20 21:39:36,597 iteration 4260 : loss : 0.020859, loss_ce: 0.007401
2022-01-20 21:39:37,126 iteration 4261 : loss : 0.015393, loss_ce: 0.005222
2022-01-20 21:39:37,695 iteration 4262 : loss : 0.017670, loss_ce: 0.007490
2022-01-20 21:39:38,327 iteration 4263 : loss : 0.024484, loss_ce: 0.010893
2022-01-20 21:39:38,904 iteration 4264 : loss : 0.022853, loss_ce: 0.010078
2022-01-20 21:39:39,381 iteration 4265 : loss : 0.016247, loss_ce: 0.006980
2022-01-20 21:39:40,002 iteration 4266 : loss : 0.024198, loss_ce: 0.006549
2022-01-20 21:39:40,629 iteration 4267 : loss : 0.032919, loss_ce: 0.010777
 63%|███████████████████▍           | 251/400 [46:05<27:35, 11.11s/it]2022-01-20 21:39:41,195 iteration 4268 : loss : 0.015824, loss_ce: 0.005819
2022-01-20 21:39:41,722 iteration 4269 : loss : 0.014606, loss_ce: 0.003854
2022-01-20 21:39:42,288 iteration 4270 : loss : 0.022690, loss_ce: 0.006991
2022-01-20 21:39:42,856 iteration 4271 : loss : 0.023313, loss_ce: 0.008179
2022-01-20 21:39:43,432 iteration 4272 : loss : 0.019161, loss_ce: 0.007812
2022-01-20 21:39:43,993 iteration 4273 : loss : 0.017097, loss_ce: 0.007187
2022-01-20 21:39:44,587 iteration 4274 : loss : 0.018173, loss_ce: 0.008573
2022-01-20 21:39:45,163 iteration 4275 : loss : 0.018036, loss_ce: 0.007299
2022-01-20 21:39:45,729 iteration 4276 : loss : 0.019266, loss_ce: 0.007209
2022-01-20 21:39:46,326 iteration 4277 : loss : 0.020273, loss_ce: 0.009003
2022-01-20 21:39:46,903 iteration 4278 : loss : 0.014627, loss_ce: 0.003628
2022-01-20 21:39:47,448 iteration 4279 : loss : 0.016772, loss_ce: 0.007393
2022-01-20 21:39:48,054 iteration 4280 : loss : 0.033120, loss_ce: 0.011109
2022-01-20 21:39:48,662 iteration 4281 : loss : 0.020450, loss_ce: 0.007823
2022-01-20 21:39:49,297 iteration 4282 : loss : 0.025820, loss_ce: 0.009256
2022-01-20 21:39:49,976 iteration 4283 : loss : 0.017910, loss_ce: 0.007894
2022-01-20 21:39:50,653 iteration 4284 : loss : 0.040673, loss_ce: 0.017309
 63%|███████████████████▌           | 252/400 [46:15<26:36, 10.79s/it]2022-01-20 21:39:51,234 iteration 4285 : loss : 0.015744, loss_ce: 0.007447
2022-01-20 21:39:51,784 iteration 4286 : loss : 0.018276, loss_ce: 0.006710
2022-01-20 21:39:52,389 iteration 4287 : loss : 0.028316, loss_ce: 0.012726
2022-01-20 21:39:52,930 iteration 4288 : loss : 0.017522, loss_ce: 0.005338
2022-01-20 21:39:53,478 iteration 4289 : loss : 0.015085, loss_ce: 0.006263
2022-01-20 21:39:54,062 iteration 4290 : loss : 0.023861, loss_ce: 0.009024
2022-01-20 21:39:54,714 iteration 4291 : loss : 0.018696, loss_ce: 0.008404
2022-01-20 21:39:55,338 iteration 4292 : loss : 0.024139, loss_ce: 0.014033
2022-01-20 21:39:55,834 iteration 4293 : loss : 0.019559, loss_ce: 0.007438
2022-01-20 21:39:56,397 iteration 4294 : loss : 0.021025, loss_ce: 0.009101
2022-01-20 21:39:57,133 iteration 4295 : loss : 0.022513, loss_ce: 0.008045
2022-01-20 21:39:57,707 iteration 4296 : loss : 0.018464, loss_ce: 0.006912
2022-01-20 21:39:58,271 iteration 4297 : loss : 0.016761, loss_ce: 0.005522
2022-01-20 21:39:58,931 iteration 4298 : loss : 0.019424, loss_ce: 0.006541
2022-01-20 21:39:59,560 iteration 4299 : loss : 0.019141, loss_ce: 0.005361
2022-01-20 21:40:00,255 iteration 4300 : loss : 0.022123, loss_ce: 0.006928
2022-01-20 21:40:00,857 iteration 4301 : loss : 0.035099, loss_ce: 0.014909
 63%|███████████████████▌           | 253/400 [46:25<25:59, 10.61s/it]2022-01-20 21:40:01,563 iteration 4302 : loss : 0.019753, loss_ce: 0.008358
2022-01-20 21:40:02,089 iteration 4303 : loss : 0.018483, loss_ce: 0.009784
2022-01-20 21:40:02,677 iteration 4304 : loss : 0.019802, loss_ce: 0.008562
2022-01-20 21:40:03,282 iteration 4305 : loss : 0.018833, loss_ce: 0.005293
2022-01-20 21:40:03,869 iteration 4306 : loss : 0.015249, loss_ce: 0.004863
2022-01-20 21:40:04,531 iteration 4307 : loss : 0.021223, loss_ce: 0.006713
2022-01-20 21:40:05,108 iteration 4308 : loss : 0.018360, loss_ce: 0.007095
2022-01-20 21:40:05,748 iteration 4309 : loss : 0.032258, loss_ce: 0.010263
2022-01-20 21:40:06,287 iteration 4310 : loss : 0.016530, loss_ce: 0.005620
2022-01-20 21:40:06,975 iteration 4311 : loss : 0.029620, loss_ce: 0.010839
2022-01-20 21:40:07,555 iteration 4312 : loss : 0.024165, loss_ce: 0.011242
2022-01-20 21:40:08,212 iteration 4313 : loss : 0.020897, loss_ce: 0.010334
2022-01-20 21:40:08,829 iteration 4314 : loss : 0.029412, loss_ce: 0.006783
2022-01-20 21:40:09,397 iteration 4315 : loss : 0.018606, loss_ce: 0.006718
2022-01-20 21:40:09,965 iteration 4316 : loss : 0.027036, loss_ce: 0.010900
2022-01-20 21:40:10,563 iteration 4317 : loss : 0.020108, loss_ce: 0.008171
2022-01-20 21:40:11,252 iteration 4318 : loss : 0.018264, loss_ce: 0.007038
 64%|███████████████████▋           | 254/400 [46:36<25:39, 10.55s/it]2022-01-20 21:40:11,866 iteration 4319 : loss : 0.019597, loss_ce: 0.007012
2022-01-20 21:40:12,363 iteration 4320 : loss : 0.019438, loss_ce: 0.007821
2022-01-20 21:40:13,100 iteration 4321 : loss : 0.024911, loss_ce: 0.012311
2022-01-20 21:40:13,689 iteration 4322 : loss : 0.024559, loss_ce: 0.008824
2022-01-20 21:40:14,285 iteration 4323 : loss : 0.024973, loss_ce: 0.008588
2022-01-20 21:40:14,857 iteration 4324 : loss : 0.015981, loss_ce: 0.007229
2022-01-20 21:40:15,425 iteration 4325 : loss : 0.022102, loss_ce: 0.007176
2022-01-20 21:40:16,065 iteration 4326 : loss : 0.027559, loss_ce: 0.008039
2022-01-20 21:40:16,740 iteration 4327 : loss : 0.018651, loss_ce: 0.007969
2022-01-20 21:40:17,373 iteration 4328 : loss : 0.020123, loss_ce: 0.009042
2022-01-20 21:40:17,945 iteration 4329 : loss : 0.018449, loss_ce: 0.006712
2022-01-20 21:40:18,478 iteration 4330 : loss : 0.018432, loss_ce: 0.008014
2022-01-20 21:40:19,044 iteration 4331 : loss : 0.019695, loss_ce: 0.009013
2022-01-20 21:40:19,579 iteration 4332 : loss : 0.018616, loss_ce: 0.006676
2022-01-20 21:40:20,071 iteration 4333 : loss : 0.013882, loss_ce: 0.005612
2022-01-20 21:40:20,684 iteration 4334 : loss : 0.017554, loss_ce: 0.005614
2022-01-20 21:40:20,684 Training Data Eval:
2022-01-20 21:40:23,361   Average segmentation loss on training set: 0.0128
2022-01-20 21:40:23,362 Validation Data Eval:
2022-01-20 21:40:24,250   Average segmentation loss on validation set: 0.0887
2022-01-20 21:40:24,877 iteration 4335 : loss : 0.043153, loss_ce: 0.009470
 64%|███████████████████▊           | 255/400 [46:49<27:42, 11.47s/it]2022-01-20 21:40:25,436 iteration 4336 : loss : 0.016911, loss_ce: 0.006846
2022-01-20 21:40:26,060 iteration 4337 : loss : 0.018356, loss_ce: 0.007394
2022-01-20 21:40:26,686 iteration 4338 : loss : 0.025768, loss_ce: 0.008805
2022-01-20 21:40:27,206 iteration 4339 : loss : 0.023884, loss_ce: 0.005678
2022-01-20 21:40:27,820 iteration 4340 : loss : 0.028817, loss_ce: 0.006565
2022-01-20 21:40:28,408 iteration 4341 : loss : 0.020905, loss_ce: 0.008666
2022-01-20 21:40:28,984 iteration 4342 : loss : 0.016342, loss_ce: 0.005802
2022-01-20 21:40:29,648 iteration 4343 : loss : 0.028410, loss_ce: 0.009354
2022-01-20 21:40:30,199 iteration 4344 : loss : 0.019394, loss_ce: 0.007012
2022-01-20 21:40:30,749 iteration 4345 : loss : 0.015346, loss_ce: 0.006820
2022-01-20 21:40:31,230 iteration 4346 : loss : 0.014003, loss_ce: 0.004676
2022-01-20 21:40:31,881 iteration 4347 : loss : 0.023620, loss_ce: 0.007580
2022-01-20 21:40:32,524 iteration 4348 : loss : 0.021019, loss_ce: 0.010348
2022-01-20 21:40:33,060 iteration 4349 : loss : 0.021617, loss_ce: 0.008972
2022-01-20 21:40:33,589 iteration 4350 : loss : 0.018552, loss_ce: 0.006092
2022-01-20 21:40:34,248 iteration 4351 : loss : 0.023264, loss_ce: 0.009259
2022-01-20 21:40:34,882 iteration 4352 : loss : 0.027479, loss_ce: 0.010820
 64%|███████████████████▊           | 256/400 [46:59<26:28, 11.03s/it]2022-01-20 21:40:35,489 iteration 4353 : loss : 0.015663, loss_ce: 0.005753
2022-01-20 21:40:36,154 iteration 4354 : loss : 0.020793, loss_ce: 0.005412
2022-01-20 21:40:36,773 iteration 4355 : loss : 0.021237, loss_ce: 0.006976
2022-01-20 21:40:37,324 iteration 4356 : loss : 0.023466, loss_ce: 0.008925
2022-01-20 21:40:37,987 iteration 4357 : loss : 0.020649, loss_ce: 0.007286
2022-01-20 21:40:38,545 iteration 4358 : loss : 0.022286, loss_ce: 0.009539
2022-01-20 21:40:39,165 iteration 4359 : loss : 0.020886, loss_ce: 0.006123
2022-01-20 21:40:39,692 iteration 4360 : loss : 0.022336, loss_ce: 0.008211
2022-01-20 21:40:40,334 iteration 4361 : loss : 0.026389, loss_ce: 0.009701
2022-01-20 21:40:40,869 iteration 4362 : loss : 0.016788, loss_ce: 0.005646
2022-01-20 21:40:41,495 iteration 4363 : loss : 0.020698, loss_ce: 0.008363
2022-01-20 21:40:42,090 iteration 4364 : loss : 0.020874, loss_ce: 0.009487
2022-01-20 21:40:42,730 iteration 4365 : loss : 0.022201, loss_ce: 0.007235
2022-01-20 21:40:43,291 iteration 4366 : loss : 0.019930, loss_ce: 0.007795
2022-01-20 21:40:43,813 iteration 4367 : loss : 0.020613, loss_ce: 0.009119
2022-01-20 21:40:44,368 iteration 4368 : loss : 0.012922, loss_ce: 0.004814
2022-01-20 21:40:45,004 iteration 4369 : loss : 0.021299, loss_ce: 0.008193
 64%|███████████████████▉           | 257/400 [47:09<25:38, 10.76s/it]2022-01-20 21:40:45,595 iteration 4370 : loss : 0.018986, loss_ce: 0.006827
2022-01-20 21:40:46,358 iteration 4371 : loss : 0.025975, loss_ce: 0.008909
2022-01-20 21:40:46,994 iteration 4372 : loss : 0.041138, loss_ce: 0.012969
2022-01-20 21:40:47,637 iteration 4373 : loss : 0.032035, loss_ce: 0.010694
2022-01-20 21:40:48,210 iteration 4374 : loss : 0.017006, loss_ce: 0.006749
2022-01-20 21:40:48,817 iteration 4375 : loss : 0.017554, loss_ce: 0.007333
2022-01-20 21:40:49,443 iteration 4376 : loss : 0.022741, loss_ce: 0.008364
2022-01-20 21:40:50,005 iteration 4377 : loss : 0.017834, loss_ce: 0.005951
2022-01-20 21:40:50,650 iteration 4378 : loss : 0.027049, loss_ce: 0.013562
2022-01-20 21:40:51,222 iteration 4379 : loss : 0.024267, loss_ce: 0.009598
2022-01-20 21:40:51,821 iteration 4380 : loss : 0.017195, loss_ce: 0.006125
2022-01-20 21:40:52,444 iteration 4381 : loss : 0.021200, loss_ce: 0.005934
2022-01-20 21:40:53,138 iteration 4382 : loss : 0.035507, loss_ce: 0.013252
2022-01-20 21:40:53,735 iteration 4383 : loss : 0.022386, loss_ce: 0.007855
2022-01-20 21:40:54,379 iteration 4384 : loss : 0.019336, loss_ce: 0.006741
2022-01-20 21:40:55,039 iteration 4385 : loss : 0.021810, loss_ce: 0.010702
2022-01-20 21:40:55,613 iteration 4386 : loss : 0.020229, loss_ce: 0.005583
 64%|███████████████████▉           | 258/400 [47:20<25:21, 10.71s/it]2022-01-20 21:40:56,313 iteration 4387 : loss : 0.031129, loss_ce: 0.007605
2022-01-20 21:40:56,927 iteration 4388 : loss : 0.020312, loss_ce: 0.009901
2022-01-20 21:40:57,539 iteration 4389 : loss : 0.017685, loss_ce: 0.007427
2022-01-20 21:40:58,172 iteration 4390 : loss : 0.020336, loss_ce: 0.008670
2022-01-20 21:40:58,843 iteration 4391 : loss : 0.031444, loss_ce: 0.013174
2022-01-20 21:40:59,468 iteration 4392 : loss : 0.020045, loss_ce: 0.008459
2022-01-20 21:41:00,161 iteration 4393 : loss : 0.020927, loss_ce: 0.008665
2022-01-20 21:41:00,689 iteration 4394 : loss : 0.015145, loss_ce: 0.006084
2022-01-20 21:41:01,296 iteration 4395 : loss : 0.018240, loss_ce: 0.008311
2022-01-20 21:41:01,911 iteration 4396 : loss : 0.022056, loss_ce: 0.007972
2022-01-20 21:41:02,448 iteration 4397 : loss : 0.017131, loss_ce: 0.005200
2022-01-20 21:41:03,041 iteration 4398 : loss : 0.015955, loss_ce: 0.006479
2022-01-20 21:41:03,645 iteration 4399 : loss : 0.019576, loss_ce: 0.006367
2022-01-20 21:41:04,183 iteration 4400 : loss : 0.017592, loss_ce: 0.005262
2022-01-20 21:41:04,810 iteration 4401 : loss : 0.025632, loss_ce: 0.013044
2022-01-20 21:41:05,325 iteration 4402 : loss : 0.015675, loss_ce: 0.005307
2022-01-20 21:41:05,938 iteration 4403 : loss : 0.020775, loss_ce: 0.006399
 65%|████████████████████           | 259/400 [47:30<24:54, 10.60s/it]2022-01-20 21:41:06,649 iteration 4404 : loss : 0.020060, loss_ce: 0.008789
2022-01-20 21:41:07,252 iteration 4405 : loss : 0.031749, loss_ce: 0.010742
2022-01-20 21:41:07,886 iteration 4406 : loss : 0.018998, loss_ce: 0.008442
2022-01-20 21:41:08,504 iteration 4407 : loss : 0.028625, loss_ce: 0.006386
2022-01-20 21:41:09,068 iteration 4408 : loss : 0.017403, loss_ce: 0.008818
2022-01-20 21:41:09,613 iteration 4409 : loss : 0.025715, loss_ce: 0.009839
2022-01-20 21:41:10,305 iteration 4410 : loss : 0.024489, loss_ce: 0.008489
2022-01-20 21:41:10,922 iteration 4411 : loss : 0.028937, loss_ce: 0.010139
2022-01-20 21:41:11,530 iteration 4412 : loss : 0.021336, loss_ce: 0.007041
2022-01-20 21:41:12,150 iteration 4413 : loss : 0.017511, loss_ce: 0.007145
2022-01-20 21:41:12,719 iteration 4414 : loss : 0.027788, loss_ce: 0.008737
2022-01-20 21:41:13,260 iteration 4415 : loss : 0.015352, loss_ce: 0.006697
2022-01-20 21:41:13,882 iteration 4416 : loss : 0.021495, loss_ce: 0.007910
2022-01-20 21:41:14,499 iteration 4417 : loss : 0.025319, loss_ce: 0.013992
2022-01-20 21:41:15,106 iteration 4418 : loss : 0.018456, loss_ce: 0.007529
2022-01-20 21:41:15,684 iteration 4419 : loss : 0.014559, loss_ce: 0.004742
2022-01-20 21:41:15,685 Training Data Eval:
2022-01-20 21:41:18,365   Average segmentation loss on training set: 0.0140
2022-01-20 21:41:18,365 Validation Data Eval:
2022-01-20 21:41:19,246   Average segmentation loss on validation set: 0.0657
2022-01-20 21:41:19,909 Found new lowest validation loss at iteration 4419! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed2.pth
2022-01-20 21:41:20,480 iteration 4420 : loss : 0.015462, loss_ce: 0.004451
 65%|████████████████████▏          | 260/400 [47:45<27:29, 11.78s/it]2022-01-20 21:41:21,121 iteration 4421 : loss : 0.021553, loss_ce: 0.006392
2022-01-20 21:41:21,702 iteration 4422 : loss : 0.019424, loss_ce: 0.006502
2022-01-20 21:41:22,274 iteration 4423 : loss : 0.015903, loss_ce: 0.005452
2022-01-20 21:41:22,913 iteration 4424 : loss : 0.021004, loss_ce: 0.008549
2022-01-20 21:41:23,500 iteration 4425 : loss : 0.022086, loss_ce: 0.008843
2022-01-20 21:41:24,074 iteration 4426 : loss : 0.017276, loss_ce: 0.005214
2022-01-20 21:41:24,676 iteration 4427 : loss : 0.016526, loss_ce: 0.006558
2022-01-20 21:41:25,294 iteration 4428 : loss : 0.023985, loss_ce: 0.011103
2022-01-20 21:41:25,791 iteration 4429 : loss : 0.019282, loss_ce: 0.007641
2022-01-20 21:41:26,393 iteration 4430 : loss : 0.025216, loss_ce: 0.011463
2022-01-20 21:41:27,029 iteration 4431 : loss : 0.028625, loss_ce: 0.010265
2022-01-20 21:41:27,691 iteration 4432 : loss : 0.020751, loss_ce: 0.008920
2022-01-20 21:41:28,316 iteration 4433 : loss : 0.030793, loss_ce: 0.007682
2022-01-20 21:41:28,950 iteration 4434 : loss : 0.022512, loss_ce: 0.009715
2022-01-20 21:41:29,498 iteration 4435 : loss : 0.016722, loss_ce: 0.005475
2022-01-20 21:41:30,073 iteration 4436 : loss : 0.019472, loss_ce: 0.009658
2022-01-20 21:41:30,653 iteration 4437 : loss : 0.018908, loss_ce: 0.007527
 65%|████████████████████▏          | 261/400 [47:55<26:10, 11.30s/it]2022-01-20 21:41:31,390 iteration 4438 : loss : 0.022422, loss_ce: 0.008414
2022-01-20 21:41:31,912 iteration 4439 : loss : 0.015483, loss_ce: 0.006787
2022-01-20 21:41:32,579 iteration 4440 : loss : 0.018904, loss_ce: 0.008617
2022-01-20 21:41:33,184 iteration 4441 : loss : 0.016727, loss_ce: 0.006822
2022-01-20 21:41:33,881 iteration 4442 : loss : 0.023169, loss_ce: 0.010632
2022-01-20 21:41:34,569 iteration 4443 : loss : 0.023612, loss_ce: 0.009071
2022-01-20 21:41:35,201 iteration 4444 : loss : 0.019359, loss_ce: 0.006722
2022-01-20 21:41:35,780 iteration 4445 : loss : 0.019706, loss_ce: 0.006478
2022-01-20 21:41:36,442 iteration 4446 : loss : 0.034668, loss_ce: 0.009007
2022-01-20 21:41:37,142 iteration 4447 : loss : 0.024871, loss_ce: 0.008334
2022-01-20 21:41:37,731 iteration 4448 : loss : 0.018807, loss_ce: 0.006797
2022-01-20 21:41:38,437 iteration 4449 : loss : 0.021788, loss_ce: 0.009621
2022-01-20 21:41:39,033 iteration 4450 : loss : 0.020417, loss_ce: 0.010740
2022-01-20 21:41:39,673 iteration 4451 : loss : 0.016547, loss_ce: 0.006392
2022-01-20 21:41:40,236 iteration 4452 : loss : 0.022421, loss_ce: 0.006947
2022-01-20 21:41:40,782 iteration 4453 : loss : 0.014106, loss_ce: 0.005485
2022-01-20 21:41:41,354 iteration 4454 : loss : 0.017115, loss_ce: 0.006432
 66%|████████████████████▎          | 262/400 [48:06<25:34, 11.12s/it]2022-01-20 21:41:41,963 iteration 4455 : loss : 0.024536, loss_ce: 0.008542
2022-01-20 21:41:42,484 iteration 4456 : loss : 0.021430, loss_ce: 0.007423
2022-01-20 21:41:43,071 iteration 4457 : loss : 0.019340, loss_ce: 0.008850
2022-01-20 21:41:43,633 iteration 4458 : loss : 0.016999, loss_ce: 0.006666
2022-01-20 21:41:44,264 iteration 4459 : loss : 0.023860, loss_ce: 0.007368
2022-01-20 21:41:44,816 iteration 4460 : loss : 0.015315, loss_ce: 0.006203
2022-01-20 21:41:45,385 iteration 4461 : loss : 0.018538, loss_ce: 0.008737
2022-01-20 21:41:46,057 iteration 4462 : loss : 0.027697, loss_ce: 0.008908
2022-01-20 21:41:46,588 iteration 4463 : loss : 0.015866, loss_ce: 0.006019
2022-01-20 21:41:47,150 iteration 4464 : loss : 0.015515, loss_ce: 0.007225
2022-01-20 21:41:47,844 iteration 4465 : loss : 0.097151, loss_ce: 0.019833
2022-01-20 21:41:48,362 iteration 4466 : loss : 0.015225, loss_ce: 0.005566
2022-01-20 21:41:48,968 iteration 4467 : loss : 0.030561, loss_ce: 0.013932
2022-01-20 21:41:49,552 iteration 4468 : loss : 0.021482, loss_ce: 0.007453
2022-01-20 21:41:50,136 iteration 4469 : loss : 0.025431, loss_ce: 0.006017
2022-01-20 21:41:50,716 iteration 4470 : loss : 0.022107, loss_ce: 0.010040
2022-01-20 21:41:51,360 iteration 4471 : loss : 0.036681, loss_ce: 0.009652
 66%|████████████████████▍          | 263/400 [48:16<24:37, 10.78s/it]2022-01-20 21:41:51,957 iteration 4472 : loss : 0.020995, loss_ce: 0.009900
2022-01-20 21:41:52,600 iteration 4473 : loss : 0.021072, loss_ce: 0.008356
2022-01-20 21:41:53,304 iteration 4474 : loss : 0.023088, loss_ce: 0.009088
2022-01-20 21:41:53,935 iteration 4475 : loss : 0.018403, loss_ce: 0.007536
2022-01-20 21:41:54,514 iteration 4476 : loss : 0.022873, loss_ce: 0.007804
2022-01-20 21:41:55,088 iteration 4477 : loss : 0.015790, loss_ce: 0.006834
2022-01-20 21:41:55,783 iteration 4478 : loss : 0.024708, loss_ce: 0.012391
2022-01-20 21:41:56,372 iteration 4479 : loss : 0.022661, loss_ce: 0.011363
2022-01-20 21:41:56,899 iteration 4480 : loss : 0.016930, loss_ce: 0.006861
2022-01-20 21:41:57,546 iteration 4481 : loss : 0.022413, loss_ce: 0.005490
2022-01-20 21:41:58,138 iteration 4482 : loss : 0.017934, loss_ce: 0.006150
2022-01-20 21:41:58,683 iteration 4483 : loss : 0.020257, loss_ce: 0.005769
2022-01-20 21:41:59,350 iteration 4484 : loss : 0.023392, loss_ce: 0.007427
2022-01-20 21:42:00,004 iteration 4485 : loss : 0.023507, loss_ce: 0.010399
2022-01-20 21:42:00,662 iteration 4486 : loss : 0.021918, loss_ce: 0.008076
2022-01-20 21:42:01,215 iteration 4487 : loss : 0.017055, loss_ce: 0.004968
2022-01-20 21:42:01,785 iteration 4488 : loss : 0.023775, loss_ce: 0.008410
 66%|████████████████████▍          | 264/400 [48:26<24:12, 10.68s/it]2022-01-20 21:42:02,468 iteration 4489 : loss : 0.019440, loss_ce: 0.008606
2022-01-20 21:42:03,020 iteration 4490 : loss : 0.019345, loss_ce: 0.011773
2022-01-20 21:42:03,658 iteration 4491 : loss : 0.021225, loss_ce: 0.007694
2022-01-20 21:42:04,343 iteration 4492 : loss : 0.014058, loss_ce: 0.005726
2022-01-20 21:42:04,922 iteration 4493 : loss : 0.020974, loss_ce: 0.007594
2022-01-20 21:42:05,508 iteration 4494 : loss : 0.023084, loss_ce: 0.007672
2022-01-20 21:42:06,113 iteration 4495 : loss : 0.023162, loss_ce: 0.007803
2022-01-20 21:42:06,673 iteration 4496 : loss : 0.016475, loss_ce: 0.007684
2022-01-20 21:42:07,329 iteration 4497 : loss : 0.020470, loss_ce: 0.009172
2022-01-20 21:42:07,919 iteration 4498 : loss : 0.023878, loss_ce: 0.006869
2022-01-20 21:42:08,539 iteration 4499 : loss : 0.021649, loss_ce: 0.008188
2022-01-20 21:42:09,068 iteration 4500 : loss : 0.015555, loss_ce: 0.005664
2022-01-20 21:42:09,618 iteration 4501 : loss : 0.015702, loss_ce: 0.004929
2022-01-20 21:42:10,177 iteration 4502 : loss : 0.023217, loss_ce: 0.007801
2022-01-20 21:42:10,853 iteration 4503 : loss : 0.023716, loss_ce: 0.010064
2022-01-20 21:42:11,444 iteration 4504 : loss : 0.018014, loss_ce: 0.006604
2022-01-20 21:42:11,445 Training Data Eval:
2022-01-20 21:42:14,121   Average segmentation loss on training set: 0.0133
2022-01-20 21:42:14,121 Validation Data Eval:
2022-01-20 21:42:15,005   Average segmentation loss on validation set: 0.0946
2022-01-20 21:42:15,624 iteration 4505 : loss : 0.016923, loss_ce: 0.006352
 66%|████████████████████▌          | 265/400 [48:40<26:09, 11.63s/it]2022-01-20 21:42:16,222 iteration 4506 : loss : 0.027651, loss_ce: 0.011658
2022-01-20 21:42:16,824 iteration 4507 : loss : 0.016127, loss_ce: 0.007255
2022-01-20 21:42:17,389 iteration 4508 : loss : 0.021225, loss_ce: 0.007190
2022-01-20 21:42:17,944 iteration 4509 : loss : 0.035785, loss_ce: 0.007520
2022-01-20 21:42:18,617 iteration 4510 : loss : 0.036540, loss_ce: 0.011610
2022-01-20 21:42:19,206 iteration 4511 : loss : 0.019996, loss_ce: 0.005537
2022-01-20 21:42:19,877 iteration 4512 : loss : 0.019640, loss_ce: 0.009272
2022-01-20 21:42:20,578 iteration 4513 : loss : 0.025853, loss_ce: 0.009588
2022-01-20 21:42:21,088 iteration 4514 : loss : 0.021578, loss_ce: 0.006603
2022-01-20 21:42:21,669 iteration 4515 : loss : 0.022901, loss_ce: 0.007371
2022-01-20 21:42:22,201 iteration 4516 : loss : 0.014577, loss_ce: 0.005850
2022-01-20 21:42:22,740 iteration 4517 : loss : 0.017688, loss_ce: 0.006644
2022-01-20 21:42:23,346 iteration 4518 : loss : 0.031651, loss_ce: 0.011405
2022-01-20 21:42:23,851 iteration 4519 : loss : 0.017756, loss_ce: 0.006501
2022-01-20 21:42:24,480 iteration 4520 : loss : 0.033980, loss_ce: 0.013114
2022-01-20 21:42:25,039 iteration 4521 : loss : 0.016870, loss_ce: 0.006788
2022-01-20 21:42:25,643 iteration 4522 : loss : 0.023428, loss_ce: 0.008378
 66%|████████████████████▌          | 266/400 [48:50<24:53, 11.15s/it]2022-01-20 21:42:26,368 iteration 4523 : loss : 0.017817, loss_ce: 0.006706
2022-01-20 21:42:26,930 iteration 4524 : loss : 0.016863, loss_ce: 0.006306
2022-01-20 21:42:27,444 iteration 4525 : loss : 0.014720, loss_ce: 0.006616
2022-01-20 21:42:28,004 iteration 4526 : loss : 0.017280, loss_ce: 0.005058
2022-01-20 21:42:28,561 iteration 4527 : loss : 0.014967, loss_ce: 0.006028
2022-01-20 21:42:29,151 iteration 4528 : loss : 0.018427, loss_ce: 0.008088
2022-01-20 21:42:29,671 iteration 4529 : loss : 0.019734, loss_ce: 0.006444
2022-01-20 21:42:30,262 iteration 4530 : loss : 0.026828, loss_ce: 0.011196
2022-01-20 21:42:30,954 iteration 4531 : loss : 0.026836, loss_ce: 0.010939
2022-01-20 21:42:31,468 iteration 4532 : loss : 0.016572, loss_ce: 0.005836
2022-01-20 21:42:32,212 iteration 4533 : loss : 0.038585, loss_ce: 0.012869
2022-01-20 21:42:32,772 iteration 4534 : loss : 0.015195, loss_ce: 0.006878
2022-01-20 21:42:33,408 iteration 4535 : loss : 0.023849, loss_ce: 0.010274
2022-01-20 21:42:34,023 iteration 4536 : loss : 0.019837, loss_ce: 0.005415
2022-01-20 21:42:34,591 iteration 4537 : loss : 0.025815, loss_ce: 0.007242
2022-01-20 21:42:35,173 iteration 4538 : loss : 0.016806, loss_ce: 0.007177
2022-01-20 21:42:35,668 iteration 4539 : loss : 0.015038, loss_ce: 0.005273
 67%|████████████████████▋          | 267/400 [49:00<23:57, 10.81s/it]2022-01-20 21:42:36,245 iteration 4540 : loss : 0.017279, loss_ce: 0.007785
2022-01-20 21:42:36,832 iteration 4541 : loss : 0.023459, loss_ce: 0.008778
2022-01-20 21:42:37,421 iteration 4542 : loss : 0.024835, loss_ce: 0.007418
2022-01-20 21:42:38,170 iteration 4543 : loss : 0.025791, loss_ce: 0.009599
2022-01-20 21:42:38,713 iteration 4544 : loss : 0.018495, loss_ce: 0.007234
2022-01-20 21:42:39,249 iteration 4545 : loss : 0.013858, loss_ce: 0.005147
2022-01-20 21:42:39,820 iteration 4546 : loss : 0.021826, loss_ce: 0.008397
2022-01-20 21:42:40,421 iteration 4547 : loss : 0.018789, loss_ce: 0.006643
2022-01-20 21:42:40,985 iteration 4548 : loss : 0.029416, loss_ce: 0.013919
2022-01-20 21:42:41,503 iteration 4549 : loss : 0.025313, loss_ce: 0.007328
2022-01-20 21:42:42,185 iteration 4550 : loss : 0.028302, loss_ce: 0.008706
2022-01-20 21:42:42,865 iteration 4551 : loss : 0.033469, loss_ce: 0.010958
2022-01-20 21:42:43,466 iteration 4552 : loss : 0.030168, loss_ce: 0.010764
2022-01-20 21:42:44,040 iteration 4553 : loss : 0.014864, loss_ce: 0.005068
2022-01-20 21:42:44,678 iteration 4554 : loss : 0.022478, loss_ce: 0.006599
2022-01-20 21:42:45,223 iteration 4555 : loss : 0.030161, loss_ce: 0.010425
2022-01-20 21:42:45,807 iteration 4556 : loss : 0.018202, loss_ce: 0.007201
 67%|████████████████████▊          | 268/400 [49:10<23:20, 10.61s/it]2022-01-20 21:42:46,427 iteration 4557 : loss : 0.017961, loss_ce: 0.009085
2022-01-20 21:42:47,031 iteration 4558 : loss : 0.031582, loss_ce: 0.012072
2022-01-20 21:42:47,662 iteration 4559 : loss : 0.022822, loss_ce: 0.007120
2022-01-20 21:42:48,256 iteration 4560 : loss : 0.020101, loss_ce: 0.006536
2022-01-20 21:42:48,885 iteration 4561 : loss : 0.026751, loss_ce: 0.007017
2022-01-20 21:42:49,442 iteration 4562 : loss : 0.019915, loss_ce: 0.006223
2022-01-20 21:42:50,063 iteration 4563 : loss : 0.021597, loss_ce: 0.008854
2022-01-20 21:42:50,704 iteration 4564 : loss : 0.025853, loss_ce: 0.009694
2022-01-20 21:42:51,383 iteration 4565 : loss : 0.025949, loss_ce: 0.008990
2022-01-20 21:42:52,030 iteration 4566 : loss : 0.036857, loss_ce: 0.015503
2022-01-20 21:42:52,617 iteration 4567 : loss : 0.020572, loss_ce: 0.008045
2022-01-20 21:42:53,208 iteration 4568 : loss : 0.020185, loss_ce: 0.006468
2022-01-20 21:42:53,897 iteration 4569 : loss : 0.049061, loss_ce: 0.010511
2022-01-20 21:42:54,602 iteration 4570 : loss : 0.033707, loss_ce: 0.017645
2022-01-20 21:42:55,195 iteration 4571 : loss : 0.021022, loss_ce: 0.008239
2022-01-20 21:42:55,733 iteration 4572 : loss : 0.016900, loss_ce: 0.006440
2022-01-20 21:42:56,363 iteration 4573 : loss : 0.026991, loss_ce: 0.010847
 67%|████████████████████▊          | 269/400 [49:21<23:07, 10.59s/it]2022-01-20 21:42:56,925 iteration 4574 : loss : 0.016701, loss_ce: 0.006941
2022-01-20 21:42:57,569 iteration 4575 : loss : 0.021260, loss_ce: 0.005969
2022-01-20 21:42:58,292 iteration 4576 : loss : 0.019962, loss_ce: 0.007048
2022-01-20 21:42:58,917 iteration 4577 : loss : 0.019703, loss_ce: 0.006515
2022-01-20 21:42:59,433 iteration 4578 : loss : 0.019648, loss_ce: 0.008715
2022-01-20 21:43:00,083 iteration 4579 : loss : 0.020231, loss_ce: 0.007556
2022-01-20 21:43:00,683 iteration 4580 : loss : 0.016488, loss_ce: 0.006462
2022-01-20 21:43:01,284 iteration 4581 : loss : 0.021281, loss_ce: 0.007367
2022-01-20 21:43:01,866 iteration 4582 : loss : 0.021831, loss_ce: 0.008564
2022-01-20 21:43:02,555 iteration 4583 : loss : 0.026228, loss_ce: 0.005906
2022-01-20 21:43:03,147 iteration 4584 : loss : 0.027294, loss_ce: 0.008392
2022-01-20 21:43:03,693 iteration 4585 : loss : 0.016377, loss_ce: 0.005420
2022-01-20 21:43:04,270 iteration 4586 : loss : 0.014999, loss_ce: 0.006530
2022-01-20 21:43:04,857 iteration 4587 : loss : 0.016481, loss_ce: 0.006258
2022-01-20 21:43:05,521 iteration 4588 : loss : 0.035033, loss_ce: 0.019551
2022-01-20 21:43:06,119 iteration 4589 : loss : 0.020453, loss_ce: 0.008502
2022-01-20 21:43:06,119 Training Data Eval:
2022-01-20 21:43:08,801   Average segmentation loss on training set: 0.0137
2022-01-20 21:43:08,801 Validation Data Eval:
2022-01-20 21:43:09,678   Average segmentation loss on validation set: 0.1000
2022-01-20 21:43:10,314 iteration 4590 : loss : 0.021872, loss_ce: 0.011347
 68%|████████████████████▉          | 270/400 [49:35<25:08, 11.60s/it]2022-01-20 21:43:11,108 iteration 4591 : loss : 0.021326, loss_ce: 0.006819
2022-01-20 21:43:11,712 iteration 4592 : loss : 0.020378, loss_ce: 0.009320
2022-01-20 21:43:12,316 iteration 4593 : loss : 0.020434, loss_ce: 0.007308
2022-01-20 21:43:12,937 iteration 4594 : loss : 0.023052, loss_ce: 0.009918
2022-01-20 21:43:13,543 iteration 4595 : loss : 0.018452, loss_ce: 0.006854
2022-01-20 21:43:14,250 iteration 4596 : loss : 0.021839, loss_ce: 0.009438
2022-01-20 21:43:14,796 iteration 4597 : loss : 0.020554, loss_ce: 0.005993
2022-01-20 21:43:15,306 iteration 4598 : loss : 0.020621, loss_ce: 0.006098
2022-01-20 21:43:15,868 iteration 4599 : loss : 0.018367, loss_ce: 0.008090
2022-01-20 21:43:16,471 iteration 4600 : loss : 0.018897, loss_ce: 0.006960
2022-01-20 21:43:17,096 iteration 4601 : loss : 0.017820, loss_ce: 0.009031
2022-01-20 21:43:17,780 iteration 4602 : loss : 0.020752, loss_ce: 0.007810
2022-01-20 21:43:18,463 iteration 4603 : loss : 0.020219, loss_ce: 0.007539
2022-01-20 21:43:19,017 iteration 4604 : loss : 0.016279, loss_ce: 0.005704
2022-01-20 21:43:19,609 iteration 4605 : loss : 0.018674, loss_ce: 0.005297
2022-01-20 21:43:20,184 iteration 4606 : loss : 0.022415, loss_ce: 0.008528
2022-01-20 21:43:20,765 iteration 4607 : loss : 0.019541, loss_ce: 0.007595
 68%|█████████████████████          | 271/400 [49:45<24:11, 11.25s/it]2022-01-20 21:43:21,440 iteration 4608 : loss : 0.015143, loss_ce: 0.005581
2022-01-20 21:43:22,071 iteration 4609 : loss : 0.015691, loss_ce: 0.004754
2022-01-20 21:43:22,694 iteration 4610 : loss : 0.019610, loss_ce: 0.004703
2022-01-20 21:43:23,348 iteration 4611 : loss : 0.022214, loss_ce: 0.009318
2022-01-20 21:43:23,962 iteration 4612 : loss : 0.033211, loss_ce: 0.013644
2022-01-20 21:43:24,575 iteration 4613 : loss : 0.017746, loss_ce: 0.005861
2022-01-20 21:43:25,183 iteration 4614 : loss : 0.016786, loss_ce: 0.005102
2022-01-20 21:43:25,906 iteration 4615 : loss : 0.025370, loss_ce: 0.010528
2022-01-20 21:43:26,455 iteration 4616 : loss : 0.019499, loss_ce: 0.009222
2022-01-20 21:43:27,083 iteration 4617 : loss : 0.023723, loss_ce: 0.008066
2022-01-20 21:43:27,655 iteration 4618 : loss : 0.019432, loss_ce: 0.010311
2022-01-20 21:43:28,275 iteration 4619 : loss : 0.020703, loss_ce: 0.007857
2022-01-20 21:43:28,850 iteration 4620 : loss : 0.027273, loss_ce: 0.012520
2022-01-20 21:43:29,423 iteration 4621 : loss : 0.015091, loss_ce: 0.005279
2022-01-20 21:43:30,040 iteration 4622 : loss : 0.020113, loss_ce: 0.007717
2022-01-20 21:43:30,645 iteration 4623 : loss : 0.025362, loss_ce: 0.013811
2022-01-20 21:43:31,207 iteration 4624 : loss : 0.016309, loss_ce: 0.005136
 68%|█████████████████████          | 272/400 [49:56<23:29, 11.01s/it]2022-01-20 21:43:31,915 iteration 4625 : loss : 0.022825, loss_ce: 0.007539
2022-01-20 21:43:32,555 iteration 4626 : loss : 0.028106, loss_ce: 0.009430
2022-01-20 21:43:33,141 iteration 4627 : loss : 0.015688, loss_ce: 0.006814
2022-01-20 21:43:33,741 iteration 4628 : loss : 0.037506, loss_ce: 0.015852
2022-01-20 21:43:34,281 iteration 4629 : loss : 0.028331, loss_ce: 0.005346
2022-01-20 21:43:34,887 iteration 4630 : loss : 0.017467, loss_ce: 0.008835
2022-01-20 21:43:35,453 iteration 4631 : loss : 0.021961, loss_ce: 0.008456
2022-01-20 21:43:36,059 iteration 4632 : loss : 0.020155, loss_ce: 0.006441
2022-01-20 21:43:36,677 iteration 4633 : loss : 0.018960, loss_ce: 0.006253
2022-01-20 21:43:37,347 iteration 4634 : loss : 0.018831, loss_ce: 0.007517
2022-01-20 21:43:37,828 iteration 4635 : loss : 0.015088, loss_ce: 0.004882
2022-01-20 21:43:38,350 iteration 4636 : loss : 0.012809, loss_ce: 0.004799
2022-01-20 21:43:38,940 iteration 4637 : loss : 0.025529, loss_ce: 0.008434
2022-01-20 21:43:39,538 iteration 4638 : loss : 0.017266, loss_ce: 0.008293
2022-01-20 21:43:40,174 iteration 4639 : loss : 0.016858, loss_ce: 0.004999
2022-01-20 21:43:40,820 iteration 4640 : loss : 0.023113, loss_ce: 0.010372
2022-01-20 21:43:41,428 iteration 4641 : loss : 0.029251, loss_ce: 0.013267
 68%|█████████████████████▏         | 273/400 [50:06<22:48, 10.77s/it]2022-01-20 21:43:42,072 iteration 4642 : loss : 0.028899, loss_ce: 0.011362
2022-01-20 21:43:42,678 iteration 4643 : loss : 0.034236, loss_ce: 0.013520
2022-01-20 21:43:43,287 iteration 4644 : loss : 0.024789, loss_ce: 0.011963
2022-01-20 21:43:43,847 iteration 4645 : loss : 0.025427, loss_ce: 0.008344
2022-01-20 21:43:44,434 iteration 4646 : loss : 0.018244, loss_ce: 0.007047
2022-01-20 21:43:45,032 iteration 4647 : loss : 0.017272, loss_ce: 0.006927
2022-01-20 21:43:45,588 iteration 4648 : loss : 0.015540, loss_ce: 0.006827
2022-01-20 21:43:46,319 iteration 4649 : loss : 0.016430, loss_ce: 0.005754
2022-01-20 21:43:46,802 iteration 4650 : loss : 0.017426, loss_ce: 0.007017
2022-01-20 21:43:47,414 iteration 4651 : loss : 0.022474, loss_ce: 0.007863
2022-01-20 21:43:48,005 iteration 4652 : loss : 0.017524, loss_ce: 0.006395
2022-01-20 21:43:48,526 iteration 4653 : loss : 0.015784, loss_ce: 0.006379
2022-01-20 21:43:49,056 iteration 4654 : loss : 0.016926, loss_ce: 0.004926
2022-01-20 21:43:49,702 iteration 4655 : loss : 0.028518, loss_ce: 0.009230
2022-01-20 21:43:50,286 iteration 4656 : loss : 0.019355, loss_ce: 0.006104
2022-01-20 21:43:50,878 iteration 4657 : loss : 0.017660, loss_ce: 0.006952
2022-01-20 21:43:51,454 iteration 4658 : loss : 0.013739, loss_ce: 0.004953
 68%|█████████████████████▏         | 274/400 [50:16<22:09, 10.55s/it]2022-01-20 21:43:52,101 iteration 4659 : loss : 0.021488, loss_ce: 0.007792
2022-01-20 21:43:52,658 iteration 4660 : loss : 0.014941, loss_ce: 0.005847
2022-01-20 21:43:53,317 iteration 4661 : loss : 0.017530, loss_ce: 0.007251
2022-01-20 21:43:53,816 iteration 4662 : loss : 0.012864, loss_ce: 0.005799
2022-01-20 21:43:54,501 iteration 4663 : loss : 0.020595, loss_ce: 0.007517
2022-01-20 21:43:55,096 iteration 4664 : loss : 0.017771, loss_ce: 0.006190
2022-01-20 21:43:55,683 iteration 4665 : loss : 0.022875, loss_ce: 0.009543
2022-01-20 21:43:56,340 iteration 4666 : loss : 0.023702, loss_ce: 0.008788
2022-01-20 21:43:57,002 iteration 4667 : loss : 0.023166, loss_ce: 0.008670
2022-01-20 21:43:57,584 iteration 4668 : loss : 0.015183, loss_ce: 0.006184
2022-01-20 21:43:58,234 iteration 4669 : loss : 0.020541, loss_ce: 0.007573
2022-01-20 21:43:58,847 iteration 4670 : loss : 0.029764, loss_ce: 0.008557
2022-01-20 21:43:59,410 iteration 4671 : loss : 0.016279, loss_ce: 0.005710
2022-01-20 21:43:59,967 iteration 4672 : loss : 0.013159, loss_ce: 0.004760
2022-01-20 21:44:00,471 iteration 4673 : loss : 0.015042, loss_ce: 0.004855
2022-01-20 21:44:01,088 iteration 4674 : loss : 0.015776, loss_ce: 0.003457
2022-01-20 21:44:01,088 Training Data Eval:
2022-01-20 21:44:03,776   Average segmentation loss on training set: 0.0129
2022-01-20 21:44:03,776 Validation Data Eval:
2022-01-20 21:44:04,654   Average segmentation loss on validation set: 0.1142
2022-01-20 21:44:05,166 iteration 4675 : loss : 0.014361, loss_ce: 0.005354
 69%|█████████████████████▎         | 275/400 [50:30<23:57, 11.50s/it]2022-01-20 21:44:05,802 iteration 4676 : loss : 0.015686, loss_ce: 0.006777
2022-01-20 21:44:06,346 iteration 4677 : loss : 0.014686, loss_ce: 0.006233
2022-01-20 21:44:06,979 iteration 4678 : loss : 0.020520, loss_ce: 0.007010
2022-01-20 21:44:07,662 iteration 4679 : loss : 0.020244, loss_ce: 0.007453
2022-01-20 21:44:08,184 iteration 4680 : loss : 0.016335, loss_ce: 0.006078
2022-01-20 21:44:08,776 iteration 4681 : loss : 0.016795, loss_ce: 0.007329
2022-01-20 21:44:09,352 iteration 4682 : loss : 0.017014, loss_ce: 0.006177
2022-01-20 21:44:09,915 iteration 4683 : loss : 0.017494, loss_ce: 0.005551
2022-01-20 21:44:10,508 iteration 4684 : loss : 0.019293, loss_ce: 0.006340
2022-01-20 21:44:11,147 iteration 4685 : loss : 0.016187, loss_ce: 0.007094
2022-01-20 21:44:11,689 iteration 4686 : loss : 0.020494, loss_ce: 0.007122
2022-01-20 21:44:12,282 iteration 4687 : loss : 0.024042, loss_ce: 0.006990
2022-01-20 21:44:12,782 iteration 4688 : loss : 0.012242, loss_ce: 0.005343
2022-01-20 21:44:13,404 iteration 4689 : loss : 0.025354, loss_ce: 0.009246
2022-01-20 21:44:13,914 iteration 4690 : loss : 0.015484, loss_ce: 0.005235
2022-01-20 21:44:14,513 iteration 4691 : loss : 0.035795, loss_ce: 0.008116
2022-01-20 21:44:15,227 iteration 4692 : loss : 0.017095, loss_ce: 0.005960
 69%|█████████████████████▍         | 276/400 [50:40<22:52, 11.07s/it]2022-01-20 21:44:15,856 iteration 4693 : loss : 0.018386, loss_ce: 0.007162
2022-01-20 21:44:16,445 iteration 4694 : loss : 0.027682, loss_ce: 0.007766
2022-01-20 21:44:17,069 iteration 4695 : loss : 0.025008, loss_ce: 0.009626
2022-01-20 21:44:17,691 iteration 4696 : loss : 0.017444, loss_ce: 0.007305
2022-01-20 21:44:18,242 iteration 4697 : loss : 0.019749, loss_ce: 0.008339
2022-01-20 21:44:18,804 iteration 4698 : loss : 0.018239, loss_ce: 0.007132
2022-01-20 21:44:19,385 iteration 4699 : loss : 0.016930, loss_ce: 0.005105
2022-01-20 21:44:19,969 iteration 4700 : loss : 0.018820, loss_ce: 0.007357
2022-01-20 21:44:20,536 iteration 4701 : loss : 0.015640, loss_ce: 0.003948
2022-01-20 21:44:21,174 iteration 4702 : loss : 0.024359, loss_ce: 0.008055
2022-01-20 21:44:21,780 iteration 4703 : loss : 0.025322, loss_ce: 0.011112
2022-01-20 21:44:22,397 iteration 4704 : loss : 0.017812, loss_ce: 0.003993
2022-01-20 21:44:23,012 iteration 4705 : loss : 0.037782, loss_ce: 0.013520
2022-01-20 21:44:23,530 iteration 4706 : loss : 0.023422, loss_ce: 0.008258
2022-01-20 21:44:24,099 iteration 4707 : loss : 0.020091, loss_ce: 0.006000
2022-01-20 21:44:24,684 iteration 4708 : loss : 0.026951, loss_ce: 0.010684
2022-01-20 21:44:25,252 iteration 4709 : loss : 0.024836, loss_ce: 0.011044
 69%|█████████████████████▍         | 277/400 [50:50<22:02, 10.75s/it]2022-01-20 21:44:25,850 iteration 4710 : loss : 0.018770, loss_ce: 0.006360
2022-01-20 21:44:26,382 iteration 4711 : loss : 0.019404, loss_ce: 0.006045
2022-01-20 21:44:26,890 iteration 4712 : loss : 0.017101, loss_ce: 0.005835
2022-01-20 21:44:27,481 iteration 4713 : loss : 0.017563, loss_ce: 0.005082
2022-01-20 21:44:28,005 iteration 4714 : loss : 0.017814, loss_ce: 0.005724
2022-01-20 21:44:28,617 iteration 4715 : loss : 0.019342, loss_ce: 0.009561
2022-01-20 21:44:29,255 iteration 4716 : loss : 0.021478, loss_ce: 0.007984
2022-01-20 21:44:29,833 iteration 4717 : loss : 0.016127, loss_ce: 0.005725
2022-01-20 21:44:30,442 iteration 4718 : loss : 0.015999, loss_ce: 0.005747
2022-01-20 21:44:31,013 iteration 4719 : loss : 0.015125, loss_ce: 0.005236
2022-01-20 21:44:31,597 iteration 4720 : loss : 0.018129, loss_ce: 0.008517
2022-01-20 21:44:32,165 iteration 4721 : loss : 0.021021, loss_ce: 0.006398
2022-01-20 21:44:32,817 iteration 4722 : loss : 0.022773, loss_ce: 0.009779
2022-01-20 21:44:33,493 iteration 4723 : loss : 0.020640, loss_ce: 0.006624
2022-01-20 21:44:34,181 iteration 4724 : loss : 0.021485, loss_ce: 0.011280
2022-01-20 21:44:34,733 iteration 4725 : loss : 0.028549, loss_ce: 0.009245
2022-01-20 21:44:35,358 iteration 4726 : loss : 0.038705, loss_ce: 0.012125
 70%|█████████████████████▌         | 278/400 [51:00<21:28, 10.56s/it]2022-01-20 21:44:36,007 iteration 4727 : loss : 0.022916, loss_ce: 0.006985
2022-01-20 21:44:36,620 iteration 4728 : loss : 0.017104, loss_ce: 0.005888
2022-01-20 21:44:37,179 iteration 4729 : loss : 0.018271, loss_ce: 0.005347
2022-01-20 21:44:37,780 iteration 4730 : loss : 0.021533, loss_ce: 0.008845
2022-01-20 21:44:38,375 iteration 4731 : loss : 0.021345, loss_ce: 0.006108
2022-01-20 21:44:38,976 iteration 4732 : loss : 0.019014, loss_ce: 0.006771
2022-01-20 21:44:39,512 iteration 4733 : loss : 0.016057, loss_ce: 0.005474
2022-01-20 21:44:40,041 iteration 4734 : loss : 0.014585, loss_ce: 0.005202
2022-01-20 21:44:40,707 iteration 4735 : loss : 0.032272, loss_ce: 0.016749
2022-01-20 21:44:41,329 iteration 4736 : loss : 0.020714, loss_ce: 0.008074
2022-01-20 21:44:42,021 iteration 4737 : loss : 0.031266, loss_ce: 0.008790
2022-01-20 21:44:42,690 iteration 4738 : loss : 0.050021, loss_ce: 0.007490
2022-01-20 21:44:43,275 iteration 4739 : loss : 0.018836, loss_ce: 0.007193
2022-01-20 21:44:43,802 iteration 4740 : loss : 0.015120, loss_ce: 0.006369
2022-01-20 21:44:44,377 iteration 4741 : loss : 0.025406, loss_ce: 0.015090
2022-01-20 21:44:44,879 iteration 4742 : loss : 0.017978, loss_ce: 0.006277
2022-01-20 21:44:45,470 iteration 4743 : loss : 0.023036, loss_ce: 0.010110
 70%|█████████████████████▌         | 279/400 [51:10<21:01, 10.43s/it]2022-01-20 21:44:46,116 iteration 4744 : loss : 0.027283, loss_ce: 0.010909
2022-01-20 21:44:46,718 iteration 4745 : loss : 0.021297, loss_ce: 0.009336
2022-01-20 21:44:47,303 iteration 4746 : loss : 0.023562, loss_ce: 0.009892
2022-01-20 21:44:47,938 iteration 4747 : loss : 0.019512, loss_ce: 0.007844
2022-01-20 21:44:48,629 iteration 4748 : loss : 0.020585, loss_ce: 0.008058
2022-01-20 21:44:49,279 iteration 4749 : loss : 0.018030, loss_ce: 0.005046
2022-01-20 21:44:49,861 iteration 4750 : loss : 0.018517, loss_ce: 0.007130
2022-01-20 21:44:50,390 iteration 4751 : loss : 0.018141, loss_ce: 0.006622
2022-01-20 21:44:50,980 iteration 4752 : loss : 0.021486, loss_ce: 0.005308
2022-01-20 21:44:51,600 iteration 4753 : loss : 0.021583, loss_ce: 0.011014
2022-01-20 21:44:52,208 iteration 4754 : loss : 0.020600, loss_ce: 0.006085
2022-01-20 21:44:52,832 iteration 4755 : loss : 0.028182, loss_ce: 0.011215
2022-01-20 21:44:53,434 iteration 4756 : loss : 0.017066, loss_ce: 0.007050
2022-01-20 21:44:54,043 iteration 4757 : loss : 0.023910, loss_ce: 0.010844
2022-01-20 21:44:54,747 iteration 4758 : loss : 0.022492, loss_ce: 0.006573
2022-01-20 21:44:55,287 iteration 4759 : loss : 0.013560, loss_ce: 0.005355
2022-01-20 21:44:55,287 Training Data Eval:
2022-01-20 21:44:57,976   Average segmentation loss on training set: 0.0130
2022-01-20 21:44:57,976 Validation Data Eval:
2022-01-20 21:44:58,858   Average segmentation loss on validation set: 0.1050
2022-01-20 21:44:59,455 iteration 4760 : loss : 0.023311, loss_ce: 0.007717
 70%|█████████████████████▋         | 280/400 [51:24<22:59, 11.49s/it]2022-01-20 21:45:00,114 iteration 4761 : loss : 0.017679, loss_ce: 0.007783
2022-01-20 21:45:00,761 iteration 4762 : loss : 0.020633, loss_ce: 0.006770
2022-01-20 21:45:01,377 iteration 4763 : loss : 0.022716, loss_ce: 0.007500
2022-01-20 21:45:02,048 iteration 4764 : loss : 0.016671, loss_ce: 0.005333
2022-01-20 21:45:02,692 iteration 4765 : loss : 0.016923, loss_ce: 0.006476
2022-01-20 21:45:03,405 iteration 4766 : loss : 0.023760, loss_ce: 0.006523
2022-01-20 21:45:04,125 iteration 4767 : loss : 0.020283, loss_ce: 0.010174
2022-01-20 21:45:04,752 iteration 4768 : loss : 0.020905, loss_ce: 0.007993
2022-01-20 21:45:05,285 iteration 4769 : loss : 0.015573, loss_ce: 0.005436
2022-01-20 21:45:05,923 iteration 4770 : loss : 0.019408, loss_ce: 0.008483
2022-01-20 21:45:06,506 iteration 4771 : loss : 0.033933, loss_ce: 0.010306
2022-01-20 21:45:07,062 iteration 4772 : loss : 0.017230, loss_ce: 0.006248
2022-01-20 21:45:07,586 iteration 4773 : loss : 0.014880, loss_ce: 0.006236
2022-01-20 21:45:08,223 iteration 4774 : loss : 0.025359, loss_ce: 0.008790
2022-01-20 21:45:08,756 iteration 4775 : loss : 0.014383, loss_ce: 0.005540
2022-01-20 21:45:09,345 iteration 4776 : loss : 0.023083, loss_ce: 0.009476
2022-01-20 21:45:09,917 iteration 4777 : loss : 0.016641, loss_ce: 0.005478
 70%|█████████████████████▊         | 281/400 [51:34<22:10, 11.18s/it]2022-01-20 21:45:10,565 iteration 4778 : loss : 0.017386, loss_ce: 0.007851
2022-01-20 21:45:11,120 iteration 4779 : loss : 0.014700, loss_ce: 0.006098
2022-01-20 21:45:11,672 iteration 4780 : loss : 0.020398, loss_ce: 0.008165
2022-01-20 21:45:12,293 iteration 4781 : loss : 0.024681, loss_ce: 0.008277
2022-01-20 21:45:12,928 iteration 4782 : loss : 0.021922, loss_ce: 0.008087
2022-01-20 21:45:13,507 iteration 4783 : loss : 0.017283, loss_ce: 0.007513
2022-01-20 21:45:14,175 iteration 4784 : loss : 0.024109, loss_ce: 0.008164
2022-01-20 21:45:14,770 iteration 4785 : loss : 0.015434, loss_ce: 0.005306
2022-01-20 21:45:15,350 iteration 4786 : loss : 0.016108, loss_ce: 0.005845
2022-01-20 21:45:15,938 iteration 4787 : loss : 0.029178, loss_ce: 0.008317
2022-01-20 21:45:16,560 iteration 4788 : loss : 0.019223, loss_ce: 0.004945
2022-01-20 21:45:17,054 iteration 4789 : loss : 0.014895, loss_ce: 0.005669
2022-01-20 21:45:17,541 iteration 4790 : loss : 0.013040, loss_ce: 0.004825
2022-01-20 21:45:18,148 iteration 4791 : loss : 0.022986, loss_ce: 0.010434
2022-01-20 21:45:18,756 iteration 4792 : loss : 0.026497, loss_ce: 0.010403
2022-01-20 21:45:19,422 iteration 4793 : loss : 0.023728, loss_ce: 0.007439
2022-01-20 21:45:19,999 iteration 4794 : loss : 0.016018, loss_ce: 0.004391
 70%|█████████████████████▊         | 282/400 [51:44<21:20, 10.85s/it]2022-01-20 21:45:20,671 iteration 4795 : loss : 0.021658, loss_ce: 0.007454
2022-01-20 21:45:21,298 iteration 4796 : loss : 0.017944, loss_ce: 0.005452
2022-01-20 21:45:21,906 iteration 4797 : loss : 0.015999, loss_ce: 0.006472
2022-01-20 21:45:22,531 iteration 4798 : loss : 0.017811, loss_ce: 0.006046
2022-01-20 21:45:23,100 iteration 4799 : loss : 0.016753, loss_ce: 0.004134
2022-01-20 21:45:23,720 iteration 4800 : loss : 0.020554, loss_ce: 0.007976
2022-01-20 21:45:24,289 iteration 4801 : loss : 0.017650, loss_ce: 0.007292
2022-01-20 21:45:24,926 iteration 4802 : loss : 0.021401, loss_ce: 0.008102
2022-01-20 21:45:25,512 iteration 4803 : loss : 0.014778, loss_ce: 0.006291
2022-01-20 21:45:26,129 iteration 4804 : loss : 0.014829, loss_ce: 0.005461
2022-01-20 21:45:26,805 iteration 4805 : loss : 0.023090, loss_ce: 0.008703
2022-01-20 21:45:27,435 iteration 4806 : loss : 0.020047, loss_ce: 0.004647
2022-01-20 21:45:27,976 iteration 4807 : loss : 0.016993, loss_ce: 0.004867
2022-01-20 21:45:28,620 iteration 4808 : loss : 0.017887, loss_ce: 0.006348
2022-01-20 21:45:29,168 iteration 4809 : loss : 0.015933, loss_ce: 0.008004
2022-01-20 21:45:29,759 iteration 4810 : loss : 0.022071, loss_ce: 0.008347
2022-01-20 21:45:30,399 iteration 4811 : loss : 0.021197, loss_ce: 0.008236
 71%|█████████████████████▉         | 283/400 [51:55<20:54, 10.72s/it]2022-01-20 21:45:31,034 iteration 4812 : loss : 0.016430, loss_ce: 0.004758
2022-01-20 21:45:31,592 iteration 4813 : loss : 0.017639, loss_ce: 0.006483
2022-01-20 21:45:32,321 iteration 4814 : loss : 0.035899, loss_ce: 0.013472
2022-01-20 21:45:32,903 iteration 4815 : loss : 0.014979, loss_ce: 0.005244
2022-01-20 21:45:33,448 iteration 4816 : loss : 0.016955, loss_ce: 0.006167
2022-01-20 21:45:33,982 iteration 4817 : loss : 0.013662, loss_ce: 0.005243
2022-01-20 21:45:34,548 iteration 4818 : loss : 0.015999, loss_ce: 0.005800
2022-01-20 21:45:35,206 iteration 4819 : loss : 0.020614, loss_ce: 0.006851
2022-01-20 21:45:35,763 iteration 4820 : loss : 0.017012, loss_ce: 0.007583
2022-01-20 21:45:36,361 iteration 4821 : loss : 0.016332, loss_ce: 0.005434
2022-01-20 21:45:37,010 iteration 4822 : loss : 0.017912, loss_ce: 0.006406
2022-01-20 21:45:37,613 iteration 4823 : loss : 0.022338, loss_ce: 0.005520
2022-01-20 21:45:38,174 iteration 4824 : loss : 0.019814, loss_ce: 0.005504
2022-01-20 21:45:38,821 iteration 4825 : loss : 0.017684, loss_ce: 0.007325
2022-01-20 21:45:39,594 iteration 4826 : loss : 0.031747, loss_ce: 0.017329
2022-01-20 21:45:40,158 iteration 4827 : loss : 0.017344, loss_ce: 0.008946
2022-01-20 21:45:40,706 iteration 4828 : loss : 0.015382, loss_ce: 0.005552
 71%|██████████████████████         | 284/400 [52:05<20:28, 10.59s/it]2022-01-20 21:45:41,322 iteration 4829 : loss : 0.017833, loss_ce: 0.010709
2022-01-20 21:45:41,975 iteration 4830 : loss : 0.020332, loss_ce: 0.009133
2022-01-20 21:45:42,610 iteration 4831 : loss : 0.027511, loss_ce: 0.017729
2022-01-20 21:45:43,249 iteration 4832 : loss : 0.020906, loss_ce: 0.007602
2022-01-20 21:45:43,839 iteration 4833 : loss : 0.019299, loss_ce: 0.009288
2022-01-20 21:45:44,518 iteration 4834 : loss : 0.018014, loss_ce: 0.006085
2022-01-20 21:45:45,101 iteration 4835 : loss : 0.020327, loss_ce: 0.008171
2022-01-20 21:45:45,667 iteration 4836 : loss : 0.017690, loss_ce: 0.005363
2022-01-20 21:45:46,285 iteration 4837 : loss : 0.017313, loss_ce: 0.004866
2022-01-20 21:45:46,906 iteration 4838 : loss : 0.017031, loss_ce: 0.007058
2022-01-20 21:45:47,399 iteration 4839 : loss : 0.018097, loss_ce: 0.006992
2022-01-20 21:45:47,967 iteration 4840 : loss : 0.020677, loss_ce: 0.006494
2022-01-20 21:45:48,597 iteration 4841 : loss : 0.019711, loss_ce: 0.007730
2022-01-20 21:45:49,209 iteration 4842 : loss : 0.022491, loss_ce: 0.008476
2022-01-20 21:45:49,790 iteration 4843 : loss : 0.017811, loss_ce: 0.006367
2022-01-20 21:45:50,443 iteration 4844 : loss : 0.018698, loss_ce: 0.005378
2022-01-20 21:45:50,443 Training Data Eval:
2022-01-20 21:45:53,141   Average segmentation loss on training set: 0.0121
2022-01-20 21:45:53,141 Validation Data Eval:
2022-01-20 21:45:54,023   Average segmentation loss on validation set: 0.0783
2022-01-20 21:45:54,571 iteration 4845 : loss : 0.016799, loss_ce: 0.006152
 71%|██████████████████████         | 285/400 [52:19<22:11, 11.58s/it]2022-01-20 21:45:55,213 iteration 4846 : loss : 0.019536, loss_ce: 0.008381
2022-01-20 21:45:55,751 iteration 4847 : loss : 0.013423, loss_ce: 0.004418
2022-01-20 21:45:56,438 iteration 4848 : loss : 0.019395, loss_ce: 0.007792
2022-01-20 21:45:57,010 iteration 4849 : loss : 0.015052, loss_ce: 0.005270
2022-01-20 21:45:57,528 iteration 4850 : loss : 0.014291, loss_ce: 0.006330
2022-01-20 21:45:58,219 iteration 4851 : loss : 0.022876, loss_ce: 0.006419
2022-01-20 21:45:58,798 iteration 4852 : loss : 0.016673, loss_ce: 0.007757
2022-01-20 21:45:59,422 iteration 4853 : loss : 0.022102, loss_ce: 0.005880
2022-01-20 21:46:00,166 iteration 4854 : loss : 0.026806, loss_ce: 0.009903
2022-01-20 21:46:00,791 iteration 4855 : loss : 0.019658, loss_ce: 0.007751
2022-01-20 21:46:01,320 iteration 4856 : loss : 0.016539, loss_ce: 0.005174
2022-01-20 21:46:01,968 iteration 4857 : loss : 0.017200, loss_ce: 0.008758
2022-01-20 21:46:02,592 iteration 4858 : loss : 0.019184, loss_ce: 0.007158
2022-01-20 21:46:03,190 iteration 4859 : loss : 0.014736, loss_ce: 0.006253
2022-01-20 21:46:03,819 iteration 4860 : loss : 0.031509, loss_ce: 0.011028
2022-01-20 21:46:04,415 iteration 4861 : loss : 0.017735, loss_ce: 0.007014
2022-01-20 21:46:04,959 iteration 4862 : loss : 0.014890, loss_ce: 0.006116
 72%|██████████████████████▏        | 286/400 [52:29<21:18, 11.22s/it]2022-01-20 21:46:05,551 iteration 4863 : loss : 0.016690, loss_ce: 0.005580
2022-01-20 21:46:06,206 iteration 4864 : loss : 0.021847, loss_ce: 0.007458
2022-01-20 21:46:06,898 iteration 4865 : loss : 0.023893, loss_ce: 0.007100
2022-01-20 21:46:07,473 iteration 4866 : loss : 0.015426, loss_ce: 0.005743
2022-01-20 21:46:08,074 iteration 4867 : loss : 0.017335, loss_ce: 0.006770
2022-01-20 21:46:08,631 iteration 4868 : loss : 0.018294, loss_ce: 0.008408
2022-01-20 21:46:09,192 iteration 4869 : loss : 0.017466, loss_ce: 0.006688
2022-01-20 21:46:09,876 iteration 4870 : loss : 0.026899, loss_ce: 0.010051
2022-01-20 21:46:10,504 iteration 4871 : loss : 0.015286, loss_ce: 0.005863
2022-01-20 21:46:11,044 iteration 4872 : loss : 0.029050, loss_ce: 0.011436
2022-01-20 21:46:11,562 iteration 4873 : loss : 0.016426, loss_ce: 0.005667
2022-01-20 21:46:12,061 iteration 4874 : loss : 0.013191, loss_ce: 0.005739
2022-01-20 21:46:12,646 iteration 4875 : loss : 0.016284, loss_ce: 0.006027
2022-01-20 21:46:13,178 iteration 4876 : loss : 0.017946, loss_ce: 0.006186
2022-01-20 21:46:13,878 iteration 4877 : loss : 0.020313, loss_ce: 0.008476
2022-01-20 21:46:14,475 iteration 4878 : loss : 0.016381, loss_ce: 0.005996
2022-01-20 21:46:15,065 iteration 4879 : loss : 0.018193, loss_ce: 0.006836
 72%|██████████████████████▏        | 287/400 [52:39<20:29, 10.88s/it]2022-01-20 21:46:15,780 iteration 4880 : loss : 0.024804, loss_ce: 0.013350
2022-01-20 21:46:16,354 iteration 4881 : loss : 0.029523, loss_ce: 0.010378
2022-01-20 21:46:16,940 iteration 4882 : loss : 0.019158, loss_ce: 0.005700
2022-01-20 21:46:17,537 iteration 4883 : loss : 0.019789, loss_ce: 0.005791
2022-01-20 21:46:18,139 iteration 4884 : loss : 0.013673, loss_ce: 0.007776
2022-01-20 21:46:18,864 iteration 4885 : loss : 0.021265, loss_ce: 0.006667
2022-01-20 21:46:19,519 iteration 4886 : loss : 0.020859, loss_ce: 0.007636
2022-01-20 21:46:20,195 iteration 4887 : loss : 0.024327, loss_ce: 0.009558
2022-01-20 21:46:20,780 iteration 4888 : loss : 0.021250, loss_ce: 0.005571
2022-01-20 21:46:21,365 iteration 4889 : loss : 0.016393, loss_ce: 0.005754
2022-01-20 21:46:22,029 iteration 4890 : loss : 0.019628, loss_ce: 0.006542
2022-01-20 21:46:22,693 iteration 4891 : loss : 0.022052, loss_ce: 0.011315
2022-01-20 21:46:23,225 iteration 4892 : loss : 0.018298, loss_ce: 0.007574
2022-01-20 21:46:23,785 iteration 4893 : loss : 0.014521, loss_ce: 0.006727
2022-01-20 21:46:24,369 iteration 4894 : loss : 0.019154, loss_ce: 0.004532
2022-01-20 21:46:24,920 iteration 4895 : loss : 0.018156, loss_ce: 0.006626
2022-01-20 21:46:25,527 iteration 4896 : loss : 0.021261, loss_ce: 0.007486
 72%|██████████████████████▎        | 288/400 [52:50<20:04, 10.76s/it]2022-01-20 21:46:26,152 iteration 4897 : loss : 0.020225, loss_ce: 0.006511
2022-01-20 21:46:26,782 iteration 4898 : loss : 0.022547, loss_ce: 0.007561
2022-01-20 21:46:27,243 iteration 4899 : loss : 0.016549, loss_ce: 0.006980
2022-01-20 21:46:27,933 iteration 4900 : loss : 0.018787, loss_ce: 0.006390
2022-01-20 21:46:28,510 iteration 4901 : loss : 0.014062, loss_ce: 0.003605
2022-01-20 21:46:29,167 iteration 4902 : loss : 0.026139, loss_ce: 0.009985
2022-01-20 21:46:29,855 iteration 4903 : loss : 0.032863, loss_ce: 0.015692
2022-01-20 21:46:30,520 iteration 4904 : loss : 0.022512, loss_ce: 0.010978
2022-01-20 21:46:31,142 iteration 4905 : loss : 0.021634, loss_ce: 0.007149
2022-01-20 21:46:31,764 iteration 4906 : loss : 0.022355, loss_ce: 0.009046
2022-01-20 21:46:32,267 iteration 4907 : loss : 0.013662, loss_ce: 0.005523
2022-01-20 21:46:32,814 iteration 4908 : loss : 0.018660, loss_ce: 0.007229
2022-01-20 21:46:33,407 iteration 4909 : loss : 0.017114, loss_ce: 0.006339
2022-01-20 21:46:34,000 iteration 4910 : loss : 0.017133, loss_ce: 0.006664
2022-01-20 21:46:34,556 iteration 4911 : loss : 0.018860, loss_ce: 0.006417
2022-01-20 21:46:35,189 iteration 4912 : loss : 0.024677, loss_ce: 0.008162
2022-01-20 21:46:35,779 iteration 4913 : loss : 0.019102, loss_ce: 0.006764
 72%|██████████████████████▍        | 289/400 [53:00<19:37, 10.61s/it]2022-01-20 21:46:36,356 iteration 4914 : loss : 0.016344, loss_ce: 0.006248
2022-01-20 21:46:36,957 iteration 4915 : loss : 0.014931, loss_ce: 0.006683
2022-01-20 21:46:37,610 iteration 4916 : loss : 0.028444, loss_ce: 0.008683
2022-01-20 21:46:38,203 iteration 4917 : loss : 0.017099, loss_ce: 0.005183
2022-01-20 21:46:38,814 iteration 4918 : loss : 0.016079, loss_ce: 0.006917
2022-01-20 21:46:39,401 iteration 4919 : loss : 0.015410, loss_ce: 0.006752
2022-01-20 21:46:40,071 iteration 4920 : loss : 0.023630, loss_ce: 0.008675
2022-01-20 21:46:40,608 iteration 4921 : loss : 0.016866, loss_ce: 0.005847
2022-01-20 21:46:41,246 iteration 4922 : loss : 0.015756, loss_ce: 0.005184
2022-01-20 21:46:41,856 iteration 4923 : loss : 0.019947, loss_ce: 0.006851
2022-01-20 21:46:42,478 iteration 4924 : loss : 0.018417, loss_ce: 0.008092
2022-01-20 21:46:43,051 iteration 4925 : loss : 0.023886, loss_ce: 0.009256
2022-01-20 21:46:43,545 iteration 4926 : loss : 0.014351, loss_ce: 0.006705
2022-01-20 21:46:44,133 iteration 4927 : loss : 0.013540, loss_ce: 0.004698
2022-01-20 21:46:44,752 iteration 4928 : loss : 0.016009, loss_ce: 0.006936
2022-01-20 21:46:45,296 iteration 4929 : loss : 0.024315, loss_ce: 0.005453
2022-01-20 21:46:45,296 Training Data Eval:
2022-01-20 21:46:47,986   Average segmentation loss on training set: 0.0121
2022-01-20 21:46:47,987 Validation Data Eval:
2022-01-20 21:46:48,866   Average segmentation loss on validation set: 0.0884
2022-01-20 21:46:49,462 iteration 4930 : loss : 0.015802, loss_ce: 0.005073
 72%|██████████████████████▍        | 290/400 [53:14<21:08, 11.53s/it]2022-01-20 21:46:50,133 iteration 4931 : loss : 0.021451, loss_ce: 0.010556
2022-01-20 21:46:50,762 iteration 4932 : loss : 0.020439, loss_ce: 0.005945
2022-01-20 21:46:51,297 iteration 4933 : loss : 0.019171, loss_ce: 0.007900
2022-01-20 21:46:51,896 iteration 4934 : loss : 0.016172, loss_ce: 0.005309
2022-01-20 21:46:52,470 iteration 4935 : loss : 0.012859, loss_ce: 0.003363
2022-01-20 21:46:53,090 iteration 4936 : loss : 0.014254, loss_ce: 0.004578
2022-01-20 21:46:53,653 iteration 4937 : loss : 0.022744, loss_ce: 0.009616
2022-01-20 21:46:54,198 iteration 4938 : loss : 0.015805, loss_ce: 0.006246
2022-01-20 21:46:54,903 iteration 4939 : loss : 0.023973, loss_ce: 0.009150
2022-01-20 21:46:55,458 iteration 4940 : loss : 0.015913, loss_ce: 0.006091
2022-01-20 21:46:56,056 iteration 4941 : loss : 0.018907, loss_ce: 0.008143
2022-01-20 21:46:56,820 iteration 4942 : loss : 0.018315, loss_ce: 0.007200
2022-01-20 21:46:57,393 iteration 4943 : loss : 0.015882, loss_ce: 0.006515
2022-01-20 21:46:57,953 iteration 4944 : loss : 0.015373, loss_ce: 0.007431
2022-01-20 21:46:58,541 iteration 4945 : loss : 0.012293, loss_ce: 0.004137
2022-01-20 21:46:59,065 iteration 4946 : loss : 0.017925, loss_ce: 0.006289
2022-01-20 21:46:59,724 iteration 4947 : loss : 0.019652, loss_ce: 0.007651
 73%|██████████████████████▌        | 291/400 [53:24<20:15, 11.15s/it]2022-01-20 21:47:00,390 iteration 4948 : loss : 0.023326, loss_ce: 0.009697
2022-01-20 21:47:01,100 iteration 4949 : loss : 0.022246, loss_ce: 0.008983
2022-01-20 21:47:01,653 iteration 4950 : loss : 0.017599, loss_ce: 0.008915
2022-01-20 21:47:02,249 iteration 4951 : loss : 0.022149, loss_ce: 0.008177
2022-01-20 21:47:02,844 iteration 4952 : loss : 0.015951, loss_ce: 0.005384
2022-01-20 21:47:03,518 iteration 4953 : loss : 0.019775, loss_ce: 0.005487
2022-01-20 21:47:04,026 iteration 4954 : loss : 0.017131, loss_ce: 0.005133
2022-01-20 21:47:04,579 iteration 4955 : loss : 0.016293, loss_ce: 0.007460
2022-01-20 21:47:05,219 iteration 4956 : loss : 0.017460, loss_ce: 0.005312
2022-01-20 21:47:05,830 iteration 4957 : loss : 0.014673, loss_ce: 0.006066
2022-01-20 21:47:06,591 iteration 4958 : loss : 0.023169, loss_ce: 0.009745
2022-01-20 21:47:07,276 iteration 4959 : loss : 0.019268, loss_ce: 0.007587
2022-01-20 21:47:08,005 iteration 4960 : loss : 0.018461, loss_ce: 0.007497
2022-01-20 21:47:08,592 iteration 4961 : loss : 0.018396, loss_ce: 0.004087
2022-01-20 21:47:09,207 iteration 4962 : loss : 0.016752, loss_ce: 0.007535
2022-01-20 21:47:09,858 iteration 4963 : loss : 0.014411, loss_ce: 0.004845
2022-01-20 21:47:10,509 iteration 4964 : loss : 0.014697, loss_ce: 0.004767
 73%|██████████████████████▋        | 292/400 [53:35<19:52, 11.04s/it]2022-01-20 21:47:11,127 iteration 4965 : loss : 0.022411, loss_ce: 0.007231
2022-01-20 21:47:11,733 iteration 4966 : loss : 0.015734, loss_ce: 0.005466
2022-01-20 21:47:12,338 iteration 4967 : loss : 0.017993, loss_ce: 0.005008
2022-01-20 21:47:12,920 iteration 4968 : loss : 0.026436, loss_ce: 0.007526
2022-01-20 21:47:13,536 iteration 4969 : loss : 0.025885, loss_ce: 0.009309
2022-01-20 21:47:14,172 iteration 4970 : loss : 0.017095, loss_ce: 0.008522
2022-01-20 21:47:14,750 iteration 4971 : loss : 0.020765, loss_ce: 0.008294
2022-01-20 21:47:15,294 iteration 4972 : loss : 0.018457, loss_ce: 0.005528
2022-01-20 21:47:15,864 iteration 4973 : loss : 0.015292, loss_ce: 0.004854
2022-01-20 21:47:16,477 iteration 4974 : loss : 0.017139, loss_ce: 0.008801
2022-01-20 21:47:17,159 iteration 4975 : loss : 0.014623, loss_ce: 0.005328
2022-01-20 21:47:17,722 iteration 4976 : loss : 0.023321, loss_ce: 0.007238
2022-01-20 21:47:18,306 iteration 4977 : loss : 0.015108, loss_ce: 0.006667
2022-01-20 21:47:18,913 iteration 4978 : loss : 0.015172, loss_ce: 0.006380
2022-01-20 21:47:19,470 iteration 4979 : loss : 0.016262, loss_ce: 0.005712
2022-01-20 21:47:19,992 iteration 4980 : loss : 0.012328, loss_ce: 0.004116
2022-01-20 21:47:20,573 iteration 4981 : loss : 0.020761, loss_ce: 0.006938
 73%|██████████████████████▋        | 293/400 [53:45<19:10, 10.75s/it]2022-01-20 21:47:21,236 iteration 4982 : loss : 0.022871, loss_ce: 0.005108
2022-01-20 21:47:21,760 iteration 4983 : loss : 0.013007, loss_ce: 0.004071
2022-01-20 21:47:22,368 iteration 4984 : loss : 0.015116, loss_ce: 0.004626
2022-01-20 21:47:22,886 iteration 4985 : loss : 0.012876, loss_ce: 0.004422
2022-01-20 21:47:23,430 iteration 4986 : loss : 0.019944, loss_ce: 0.006123
2022-01-20 21:47:24,032 iteration 4987 : loss : 0.016965, loss_ce: 0.007770
2022-01-20 21:47:24,645 iteration 4988 : loss : 0.018553, loss_ce: 0.009519
2022-01-20 21:47:25,221 iteration 4989 : loss : 0.020478, loss_ce: 0.008271
2022-01-20 21:47:25,850 iteration 4990 : loss : 0.016556, loss_ce: 0.007379
2022-01-20 21:47:26,426 iteration 4991 : loss : 0.017910, loss_ce: 0.005738
2022-01-20 21:47:27,039 iteration 4992 : loss : 0.018701, loss_ce: 0.005728
2022-01-20 21:47:27,640 iteration 4993 : loss : 0.017911, loss_ce: 0.007799
2022-01-20 21:47:28,376 iteration 4994 : loss : 0.020956, loss_ce: 0.008447
2022-01-20 21:47:29,036 iteration 4995 : loss : 0.021395, loss_ce: 0.010127
2022-01-20 21:47:29,594 iteration 4996 : loss : 0.016713, loss_ce: 0.004681
2022-01-20 21:47:30,214 iteration 4997 : loss : 0.020058, loss_ce: 0.007442
2022-01-20 21:47:30,829 iteration 4998 : loss : 0.018590, loss_ce: 0.006528
 74%|██████████████████████▊        | 294/400 [53:55<18:43, 10.60s/it]2022-01-20 21:47:31,472 iteration 4999 : loss : 0.015348, loss_ce: 0.005948
2022-01-20 21:47:32,004 iteration 5000 : loss : 0.015541, loss_ce: 0.004840
2022-01-20 21:47:32,640 iteration 5001 : loss : 0.017911, loss_ce: 0.004880
2022-01-20 21:47:33,320 iteration 5002 : loss : 0.015924, loss_ce: 0.004761
2022-01-20 21:47:34,023 iteration 5003 : loss : 0.020163, loss_ce: 0.008891
2022-01-20 21:47:34,614 iteration 5004 : loss : 0.014249, loss_ce: 0.006150
2022-01-20 21:47:35,233 iteration 5005 : loss : 0.017554, loss_ce: 0.006449
2022-01-20 21:47:35,774 iteration 5006 : loss : 0.014866, loss_ce: 0.005967
2022-01-20 21:47:36,396 iteration 5007 : loss : 0.018280, loss_ce: 0.004633
2022-01-20 21:47:36,938 iteration 5008 : loss : 0.013391, loss_ce: 0.004604
2022-01-20 21:47:37,479 iteration 5009 : loss : 0.018145, loss_ce: 0.009978
2022-01-20 21:47:38,107 iteration 5010 : loss : 0.026137, loss_ce: 0.010166
2022-01-20 21:47:38,651 iteration 5011 : loss : 0.014188, loss_ce: 0.005790
2022-01-20 21:47:39,225 iteration 5012 : loss : 0.021903, loss_ce: 0.006303
2022-01-20 21:47:39,910 iteration 5013 : loss : 0.015032, loss_ce: 0.006016
2022-01-20 21:47:40,439 iteration 5014 : loss : 0.017531, loss_ce: 0.006445
2022-01-20 21:47:40,439 Training Data Eval:
2022-01-20 21:47:43,128   Average segmentation loss on training set: 0.0112
2022-01-20 21:47:43,129 Validation Data Eval:
2022-01-20 21:47:44,007   Average segmentation loss on validation set: 0.0928
2022-01-20 21:47:44,578 iteration 5015 : loss : 0.019270, loss_ce: 0.005855
 74%|██████████████████████▊        | 295/400 [54:09<20:12, 11.54s/it]2022-01-20 21:47:45,234 iteration 5016 : loss : 0.017026, loss_ce: 0.006917
2022-01-20 21:47:45,733 iteration 5017 : loss : 0.012529, loss_ce: 0.004627
2022-01-20 21:47:46,425 iteration 5018 : loss : 0.022484, loss_ce: 0.010091
2022-01-20 21:47:46,948 iteration 5019 : loss : 0.015412, loss_ce: 0.005470
2022-01-20 21:47:47,598 iteration 5020 : loss : 0.020360, loss_ce: 0.006596
2022-01-20 21:47:48,196 iteration 5021 : loss : 0.021480, loss_ce: 0.007743
2022-01-20 21:47:48,787 iteration 5022 : loss : 0.016682, loss_ce: 0.004689
2022-01-20 21:47:49,374 iteration 5023 : loss : 0.017029, loss_ce: 0.007745
2022-01-20 21:47:50,037 iteration 5024 : loss : 0.022847, loss_ce: 0.008490
2022-01-20 21:47:50,649 iteration 5025 : loss : 0.018289, loss_ce: 0.006215
2022-01-20 21:47:51,313 iteration 5026 : loss : 0.028975, loss_ce: 0.008548
2022-01-20 21:47:51,868 iteration 5027 : loss : 0.016326, loss_ce: 0.005771
2022-01-20 21:47:52,390 iteration 5028 : loss : 0.014319, loss_ce: 0.005882
2022-01-20 21:47:53,038 iteration 5029 : loss : 0.018878, loss_ce: 0.007988
2022-01-20 21:47:53,607 iteration 5030 : loss : 0.013190, loss_ce: 0.005318
2022-01-20 21:47:54,247 iteration 5031 : loss : 0.024567, loss_ce: 0.007345
2022-01-20 21:47:54,771 iteration 5032 : loss : 0.013984, loss_ce: 0.005083
 74%|██████████████████████▉        | 296/400 [54:19<19:18, 11.14s/it]2022-01-20 21:47:55,345 iteration 5033 : loss : 0.020760, loss_ce: 0.007097
2022-01-20 21:47:55,892 iteration 5034 : loss : 0.017281, loss_ce: 0.005312
2022-01-20 21:47:56,482 iteration 5035 : loss : 0.018599, loss_ce: 0.006572
2022-01-20 21:47:57,025 iteration 5036 : loss : 0.020231, loss_ce: 0.007891
2022-01-20 21:47:57,600 iteration 5037 : loss : 0.015968, loss_ce: 0.004955
2022-01-20 21:47:58,154 iteration 5038 : loss : 0.017078, loss_ce: 0.005381
2022-01-20 21:47:58,757 iteration 5039 : loss : 0.026642, loss_ce: 0.011056
2022-01-20 21:47:59,388 iteration 5040 : loss : 0.021229, loss_ce: 0.009115
2022-01-20 21:47:59,968 iteration 5041 : loss : 0.020354, loss_ce: 0.008861
2022-01-20 21:48:00,655 iteration 5042 : loss : 0.023573, loss_ce: 0.008908
2022-01-20 21:48:01,151 iteration 5043 : loss : 0.017292, loss_ce: 0.005953
2022-01-20 21:48:01,788 iteration 5044 : loss : 0.020901, loss_ce: 0.008460
2022-01-20 21:48:02,402 iteration 5045 : loss : 0.018083, loss_ce: 0.008284
2022-01-20 21:48:03,001 iteration 5046 : loss : 0.018858, loss_ce: 0.004925
2022-01-20 21:48:03,530 iteration 5047 : loss : 0.015246, loss_ce: 0.005027
2022-01-20 21:48:04,051 iteration 5048 : loss : 0.013957, loss_ce: 0.006811
2022-01-20 21:48:04,560 iteration 5049 : loss : 0.013276, loss_ce: 0.005901
 74%|███████████████████████        | 297/400 [54:29<18:25, 10.73s/it]2022-01-20 21:48:05,212 iteration 5050 : loss : 0.014518, loss_ce: 0.004546
2022-01-20 21:48:05,866 iteration 5051 : loss : 0.022635, loss_ce: 0.007483
2022-01-20 21:48:06,555 iteration 5052 : loss : 0.022679, loss_ce: 0.008504
2022-01-20 21:48:07,236 iteration 5053 : loss : 0.024593, loss_ce: 0.007509
2022-01-20 21:48:07,814 iteration 5054 : loss : 0.020108, loss_ce: 0.004804
2022-01-20 21:48:08,433 iteration 5055 : loss : 0.022084, loss_ce: 0.008093
2022-01-20 21:48:09,057 iteration 5056 : loss : 0.017952, loss_ce: 0.006906
2022-01-20 21:48:09,751 iteration 5057 : loss : 0.031052, loss_ce: 0.015677
2022-01-20 21:48:10,436 iteration 5058 : loss : 0.023375, loss_ce: 0.010625
2022-01-20 21:48:11,031 iteration 5059 : loss : 0.016413, loss_ce: 0.006746
2022-01-20 21:48:11,677 iteration 5060 : loss : 0.020775, loss_ce: 0.008563
2022-01-20 21:48:12,342 iteration 5061 : loss : 0.024106, loss_ce: 0.008474
2022-01-20 21:48:13,039 iteration 5062 : loss : 0.026610, loss_ce: 0.008781
2022-01-20 21:48:13,722 iteration 5063 : loss : 0.022763, loss_ce: 0.009633
2022-01-20 21:48:14,307 iteration 5064 : loss : 0.018803, loss_ce: 0.006390
2022-01-20 21:48:14,963 iteration 5065 : loss : 0.019116, loss_ce: 0.009016
2022-01-20 21:48:15,507 iteration 5066 : loss : 0.015056, loss_ce: 0.005555
 74%|███████████████████████        | 298/400 [54:40<18:21, 10.80s/it]2022-01-20 21:48:16,027 iteration 5067 : loss : 0.017453, loss_ce: 0.005891
2022-01-20 21:48:16,667 iteration 5068 : loss : 0.031245, loss_ce: 0.006861
2022-01-20 21:48:17,284 iteration 5069 : loss : 0.016281, loss_ce: 0.007934
2022-01-20 21:48:17,822 iteration 5070 : loss : 0.020766, loss_ce: 0.007629
2022-01-20 21:48:18,455 iteration 5071 : loss : 0.020906, loss_ce: 0.011151
2022-01-20 21:48:18,975 iteration 5072 : loss : 0.014786, loss_ce: 0.005391
2022-01-20 21:48:19,641 iteration 5073 : loss : 0.023940, loss_ce: 0.010280
2022-01-20 21:48:20,212 iteration 5074 : loss : 0.014173, loss_ce: 0.005709
2022-01-20 21:48:20,781 iteration 5075 : loss : 0.020996, loss_ce: 0.008564
2022-01-20 21:48:21,393 iteration 5076 : loss : 0.029976, loss_ce: 0.006767
2022-01-20 21:48:21,996 iteration 5077 : loss : 0.020375, loss_ce: 0.006522
2022-01-20 21:48:22,544 iteration 5078 : loss : 0.017813, loss_ce: 0.008307
2022-01-20 21:48:23,077 iteration 5079 : loss : 0.015177, loss_ce: 0.006278
2022-01-20 21:48:23,635 iteration 5080 : loss : 0.015135, loss_ce: 0.005994
2022-01-20 21:48:24,269 iteration 5081 : loss : 0.021578, loss_ce: 0.006460
2022-01-20 21:48:24,848 iteration 5082 : loss : 0.015320, loss_ce: 0.006010
2022-01-20 21:48:25,459 iteration 5083 : loss : 0.021689, loss_ce: 0.004987
 75%|███████████████████████▏       | 299/400 [54:50<17:45, 10.54s/it]2022-01-20 21:48:26,134 iteration 5084 : loss : 0.016120, loss_ce: 0.008161
2022-01-20 21:48:26,825 iteration 5085 : loss : 0.021246, loss_ce: 0.008012
2022-01-20 21:48:27,470 iteration 5086 : loss : 0.015066, loss_ce: 0.005056
2022-01-20 21:48:28,007 iteration 5087 : loss : 0.017351, loss_ce: 0.007313
2022-01-20 21:48:28,550 iteration 5088 : loss : 0.017972, loss_ce: 0.007634
2022-01-20 21:48:29,170 iteration 5089 : loss : 0.019779, loss_ce: 0.006194
2022-01-20 21:48:29,774 iteration 5090 : loss : 0.019161, loss_ce: 0.004075
2022-01-20 21:48:30,445 iteration 5091 : loss : 0.019859, loss_ce: 0.006257
2022-01-20 21:48:31,067 iteration 5092 : loss : 0.024606, loss_ce: 0.008293
2022-01-20 21:48:31,612 iteration 5093 : loss : 0.017103, loss_ce: 0.005588
2022-01-20 21:48:32,245 iteration 5094 : loss : 0.025347, loss_ce: 0.009857
2022-01-20 21:48:32,785 iteration 5095 : loss : 0.015667, loss_ce: 0.006265
2022-01-20 21:48:33,365 iteration 5096 : loss : 0.022855, loss_ce: 0.009486
2022-01-20 21:48:33,884 iteration 5097 : loss : 0.016659, loss_ce: 0.007555
2022-01-20 21:48:34,553 iteration 5098 : loss : 0.020571, loss_ce: 0.007345
2022-01-20 21:48:35,179 iteration 5099 : loss : 0.021314, loss_ce: 0.006627
2022-01-20 21:48:35,179 Training Data Eval:
2022-01-20 21:48:37,862   Average segmentation loss on training set: 0.0114
2022-01-20 21:48:37,862 Validation Data Eval:
2022-01-20 21:48:38,742   Average segmentation loss on validation set: 0.0996
2022-01-20 21:48:39,407 iteration 5100 : loss : 0.023928, loss_ce: 0.006095
 75%|███████████████████████▎       | 300/400 [55:04<19:16, 11.57s/it]2022-01-20 21:48:40,142 iteration 5101 : loss : 0.024292, loss_ce: 0.010440
2022-01-20 21:48:40,728 iteration 5102 : loss : 0.019561, loss_ce: 0.007301
2022-01-20 21:48:41,330 iteration 5103 : loss : 0.016296, loss_ce: 0.008088
2022-01-20 21:48:41,997 iteration 5104 : loss : 0.018295, loss_ce: 0.005085
2022-01-20 21:48:42,571 iteration 5105 : loss : 0.017774, loss_ce: 0.007338
2022-01-20 21:48:43,146 iteration 5106 : loss : 0.016251, loss_ce: 0.006070
2022-01-20 21:48:43,809 iteration 5107 : loss : 0.027517, loss_ce: 0.008461
2022-01-20 21:48:44,428 iteration 5108 : loss : 0.017313, loss_ce: 0.008151
2022-01-20 21:48:45,028 iteration 5109 : loss : 0.022699, loss_ce: 0.009001
2022-01-20 21:48:45,574 iteration 5110 : loss : 0.012796, loss_ce: 0.003863
2022-01-20 21:48:46,190 iteration 5111 : loss : 0.019303, loss_ce: 0.007020
2022-01-20 21:48:46,882 iteration 5112 : loss : 0.027659, loss_ce: 0.009662
2022-01-20 21:48:47,500 iteration 5113 : loss : 0.019523, loss_ce: 0.006569
2022-01-20 21:48:48,170 iteration 5114 : loss : 0.027372, loss_ce: 0.010329
2022-01-20 21:48:48,764 iteration 5115 : loss : 0.019789, loss_ce: 0.006581
2022-01-20 21:48:49,339 iteration 5116 : loss : 0.018177, loss_ce: 0.007333
2022-01-20 21:48:49,967 iteration 5117 : loss : 0.019955, loss_ce: 0.009042
 75%|███████████████████████▎       | 301/400 [55:14<18:35, 11.27s/it]2022-01-20 21:48:50,642 iteration 5118 : loss : 0.022566, loss_ce: 0.006469
2022-01-20 21:48:51,226 iteration 5119 : loss : 0.016943, loss_ce: 0.007748
2022-01-20 21:48:51,764 iteration 5120 : loss : 0.012118, loss_ce: 0.005060
2022-01-20 21:48:52,423 iteration 5121 : loss : 0.018121, loss_ce: 0.004735
2022-01-20 21:48:53,123 iteration 5122 : loss : 0.017730, loss_ce: 0.007379
2022-01-20 21:48:53,814 iteration 5123 : loss : 0.026804, loss_ce: 0.007951
2022-01-20 21:48:54,363 iteration 5124 : loss : 0.013446, loss_ce: 0.006142
2022-01-20 21:48:54,911 iteration 5125 : loss : 0.020493, loss_ce: 0.007427
2022-01-20 21:48:55,516 iteration 5126 : loss : 0.017924, loss_ce: 0.006579
2022-01-20 21:48:56,100 iteration 5127 : loss : 0.020025, loss_ce: 0.007972
2022-01-20 21:48:56,653 iteration 5128 : loss : 0.016960, loss_ce: 0.005108
2022-01-20 21:48:57,258 iteration 5129 : loss : 0.020118, loss_ce: 0.008266
2022-01-20 21:48:57,844 iteration 5130 : loss : 0.016290, loss_ce: 0.006849
2022-01-20 21:48:58,457 iteration 5131 : loss : 0.014285, loss_ce: 0.005569
2022-01-20 21:48:59,054 iteration 5132 : loss : 0.016645, loss_ce: 0.006298
2022-01-20 21:48:59,723 iteration 5133 : loss : 0.028679, loss_ce: 0.010466
2022-01-20 21:49:00,318 iteration 5134 : loss : 0.021320, loss_ce: 0.005746
 76%|███████████████████████▍       | 302/400 [55:25<17:56, 10.99s/it]2022-01-20 21:49:00,946 iteration 5135 : loss : 0.020089, loss_ce: 0.011040
2022-01-20 21:49:01,543 iteration 5136 : loss : 0.011552, loss_ce: 0.003591
2022-01-20 21:49:02,088 iteration 5137 : loss : 0.014700, loss_ce: 0.005393
2022-01-20 21:49:02,715 iteration 5138 : loss : 0.013169, loss_ce: 0.005672
2022-01-20 21:49:03,407 iteration 5139 : loss : 0.023478, loss_ce: 0.010420
2022-01-20 21:49:04,070 iteration 5140 : loss : 0.031312, loss_ce: 0.011765
2022-01-20 21:49:04,616 iteration 5141 : loss : 0.031955, loss_ce: 0.012971
2022-01-20 21:49:05,229 iteration 5142 : loss : 0.024741, loss_ce: 0.007284
2022-01-20 21:49:05,817 iteration 5143 : loss : 0.014983, loss_ce: 0.007529
2022-01-20 21:49:06,503 iteration 5144 : loss : 0.015809, loss_ce: 0.006338
2022-01-20 21:49:07,241 iteration 5145 : loss : 0.018998, loss_ce: 0.006660
2022-01-20 21:49:07,880 iteration 5146 : loss : 0.020330, loss_ce: 0.006350
2022-01-20 21:49:08,418 iteration 5147 : loss : 0.018910, loss_ce: 0.004667
2022-01-20 21:49:09,009 iteration 5148 : loss : 0.017748, loss_ce: 0.005989
2022-01-20 21:49:09,587 iteration 5149 : loss : 0.020876, loss_ce: 0.007021
2022-01-20 21:49:10,170 iteration 5150 : loss : 0.017726, loss_ce: 0.008827
2022-01-20 21:49:10,819 iteration 5151 : loss : 0.015377, loss_ce: 0.006627
 76%|███████████████████████▍       | 303/400 [55:35<17:31, 10.85s/it]2022-01-20 21:49:11,451 iteration 5152 : loss : 0.020179, loss_ce: 0.009262
2022-01-20 21:49:12,066 iteration 5153 : loss : 0.020721, loss_ce: 0.007916
2022-01-20 21:49:12,594 iteration 5154 : loss : 0.016214, loss_ce: 0.005367
2022-01-20 21:49:13,139 iteration 5155 : loss : 0.017057, loss_ce: 0.006846
2022-01-20 21:49:13,719 iteration 5156 : loss : 0.026454, loss_ce: 0.008853
2022-01-20 21:49:14,256 iteration 5157 : loss : 0.011720, loss_ce: 0.004446
2022-01-20 21:49:14,809 iteration 5158 : loss : 0.017998, loss_ce: 0.006259
2022-01-20 21:49:15,423 iteration 5159 : loss : 0.019017, loss_ce: 0.007431
2022-01-20 21:49:16,027 iteration 5160 : loss : 0.017648, loss_ce: 0.007918
2022-01-20 21:49:16,653 iteration 5161 : loss : 0.018237, loss_ce: 0.006833
2022-01-20 21:49:17,326 iteration 5162 : loss : 0.013735, loss_ce: 0.003757
2022-01-20 21:49:17,951 iteration 5163 : loss : 0.016821, loss_ce: 0.008564
2022-01-20 21:49:18,499 iteration 5164 : loss : 0.016499, loss_ce: 0.005879
2022-01-20 21:49:19,184 iteration 5165 : loss : 0.023774, loss_ce: 0.008223
2022-01-20 21:49:19,807 iteration 5166 : loss : 0.016207, loss_ce: 0.005726
2022-01-20 21:49:20,452 iteration 5167 : loss : 0.020161, loss_ce: 0.005487
2022-01-20 21:49:20,958 iteration 5168 : loss : 0.016702, loss_ce: 0.007592
 76%|███████████████████████▌       | 304/400 [55:45<17:00, 10.63s/it]2022-01-20 21:49:21,644 iteration 5169 : loss : 0.020218, loss_ce: 0.006216
2022-01-20 21:49:22,218 iteration 5170 : loss : 0.015306, loss_ce: 0.007380
2022-01-20 21:49:22,813 iteration 5171 : loss : 0.019756, loss_ce: 0.006656
2022-01-20 21:49:23,424 iteration 5172 : loss : 0.024724, loss_ce: 0.011256
2022-01-20 21:49:24,105 iteration 5173 : loss : 0.029648, loss_ce: 0.012372
2022-01-20 21:49:24,709 iteration 5174 : loss : 0.012687, loss_ce: 0.003350
2022-01-20 21:49:25,343 iteration 5175 : loss : 0.017932, loss_ce: 0.007314
2022-01-20 21:49:26,024 iteration 5176 : loss : 0.016767, loss_ce: 0.005704
2022-01-20 21:49:26,633 iteration 5177 : loss : 0.021875, loss_ce: 0.008066
2022-01-20 21:49:27,249 iteration 5178 : loss : 0.013846, loss_ce: 0.006190
2022-01-20 21:49:27,820 iteration 5179 : loss : 0.016405, loss_ce: 0.008136
2022-01-20 21:49:28,343 iteration 5180 : loss : 0.015660, loss_ce: 0.006553
2022-01-20 21:49:28,898 iteration 5181 : loss : 0.016027, loss_ce: 0.004863
2022-01-20 21:49:29,472 iteration 5182 : loss : 0.016980, loss_ce: 0.006860
2022-01-20 21:49:30,045 iteration 5183 : loss : 0.014802, loss_ce: 0.005343
2022-01-20 21:49:30,593 iteration 5184 : loss : 0.020296, loss_ce: 0.010638
2022-01-20 21:49:30,593 Training Data Eval:
2022-01-20 21:49:33,273   Average segmentation loss on training set: 0.0107
2022-01-20 21:49:33,273 Validation Data Eval:
2022-01-20 21:49:34,154   Average segmentation loss on validation set: 0.0797
2022-01-20 21:49:34,724 iteration 5185 : loss : 0.013755, loss_ce: 0.005655
 76%|███████████████████████▋       | 305/400 [55:59<18:19, 11.57s/it]2022-01-20 21:49:35,400 iteration 5186 : loss : 0.020432, loss_ce: 0.006490
2022-01-20 21:49:35,943 iteration 5187 : loss : 0.015648, loss_ce: 0.006519
2022-01-20 21:49:36,540 iteration 5188 : loss : 0.016516, loss_ce: 0.005510
2022-01-20 21:49:37,157 iteration 5189 : loss : 0.024266, loss_ce: 0.007356
2022-01-20 21:49:37,857 iteration 5190 : loss : 0.021786, loss_ce: 0.007213
2022-01-20 21:49:38,429 iteration 5191 : loss : 0.018206, loss_ce: 0.006547
2022-01-20 21:49:39,022 iteration 5192 : loss : 0.017702, loss_ce: 0.007930
2022-01-20 21:49:39,665 iteration 5193 : loss : 0.015285, loss_ce: 0.007053
2022-01-20 21:49:40,294 iteration 5194 : loss : 0.022080, loss_ce: 0.006403
2022-01-20 21:49:40,882 iteration 5195 : loss : 0.015836, loss_ce: 0.004750
2022-01-20 21:49:41,589 iteration 5196 : loss : 0.022895, loss_ce: 0.008063
2022-01-20 21:49:42,180 iteration 5197 : loss : 0.015587, loss_ce: 0.004894
2022-01-20 21:49:42,733 iteration 5198 : loss : 0.021702, loss_ce: 0.014224
2022-01-20 21:49:43,436 iteration 5199 : loss : 0.019906, loss_ce: 0.007685
2022-01-20 21:49:43,955 iteration 5200 : loss : 0.015906, loss_ce: 0.006744
2022-01-20 21:49:44,483 iteration 5201 : loss : 0.014909, loss_ce: 0.006193
2022-01-20 21:49:45,064 iteration 5202 : loss : 0.018195, loss_ce: 0.007102
 76%|███████████████████████▋       | 306/400 [56:09<17:33, 11.20s/it]2022-01-20 21:49:45,690 iteration 5203 : loss : 0.020770, loss_ce: 0.008182
2022-01-20 21:49:46,348 iteration 5204 : loss : 0.016197, loss_ce: 0.006643
2022-01-20 21:49:46,990 iteration 5205 : loss : 0.035689, loss_ce: 0.010098
2022-01-20 21:49:47,727 iteration 5206 : loss : 0.022618, loss_ce: 0.008169
2022-01-20 21:49:48,385 iteration 5207 : loss : 0.031991, loss_ce: 0.007303
2022-01-20 21:49:48,996 iteration 5208 : loss : 0.013385, loss_ce: 0.005691
2022-01-20 21:49:49,651 iteration 5209 : loss : 0.025130, loss_ce: 0.010503
2022-01-20 21:49:50,304 iteration 5210 : loss : 0.021687, loss_ce: 0.010151
2022-01-20 21:49:50,898 iteration 5211 : loss : 0.022558, loss_ce: 0.006878
2022-01-20 21:49:51,548 iteration 5212 : loss : 0.027731, loss_ce: 0.007966
2022-01-20 21:49:52,133 iteration 5213 : loss : 0.016889, loss_ce: 0.006429
2022-01-20 21:49:52,724 iteration 5214 : loss : 0.017075, loss_ce: 0.007715
2022-01-20 21:49:53,239 iteration 5215 : loss : 0.013221, loss_ce: 0.004741
2022-01-20 21:49:53,805 iteration 5216 : loss : 0.016368, loss_ce: 0.005280
2022-01-20 21:49:54,474 iteration 5217 : loss : 0.038011, loss_ce: 0.021655
2022-01-20 21:49:55,021 iteration 5218 : loss : 0.012645, loss_ce: 0.004336
2022-01-20 21:49:55,632 iteration 5219 : loss : 0.018067, loss_ce: 0.006739
 77%|███████████████████████▊       | 307/400 [56:20<17:04, 11.01s/it]2022-01-20 21:49:56,190 iteration 5220 : loss : 0.014943, loss_ce: 0.006470
2022-01-20 21:49:56,716 iteration 5221 : loss : 0.016272, loss_ce: 0.004476
2022-01-20 21:49:57,346 iteration 5222 : loss : 0.021859, loss_ce: 0.006697
2022-01-20 21:49:57,928 iteration 5223 : loss : 0.017307, loss_ce: 0.006846
2022-01-20 21:49:58,596 iteration 5224 : loss : 0.032486, loss_ce: 0.010619
2022-01-20 21:49:59,166 iteration 5225 : loss : 0.017287, loss_ce: 0.007594
2022-01-20 21:49:59,774 iteration 5226 : loss : 0.013956, loss_ce: 0.005813
2022-01-20 21:50:00,391 iteration 5227 : loss : 0.020806, loss_ce: 0.007587
2022-01-20 21:50:00,914 iteration 5228 : loss : 0.012422, loss_ce: 0.003784
2022-01-20 21:50:01,551 iteration 5229 : loss : 0.023269, loss_ce: 0.008187
2022-01-20 21:50:02,095 iteration 5230 : loss : 0.013325, loss_ce: 0.004894
2022-01-20 21:50:02,706 iteration 5231 : loss : 0.023826, loss_ce: 0.008487
2022-01-20 21:50:03,393 iteration 5232 : loss : 0.038009, loss_ce: 0.011088
2022-01-20 21:50:03,873 iteration 5233 : loss : 0.015138, loss_ce: 0.006300
2022-01-20 21:50:04,465 iteration 5234 : loss : 0.023335, loss_ce: 0.008509
2022-01-20 21:50:05,090 iteration 5235 : loss : 0.021166, loss_ce: 0.009584
2022-01-20 21:50:05,767 iteration 5236 : loss : 0.019928, loss_ce: 0.008370
 77%|███████████████████████▊       | 308/400 [56:30<16:28, 10.75s/it]2022-01-20 21:50:06,324 iteration 5237 : loss : 0.013471, loss_ce: 0.006277
2022-01-20 21:50:06,904 iteration 5238 : loss : 0.020800, loss_ce: 0.008772
2022-01-20 21:50:07,482 iteration 5239 : loss : 0.019830, loss_ce: 0.006803
2022-01-20 21:50:08,139 iteration 5240 : loss : 0.042993, loss_ce: 0.008198
2022-01-20 21:50:08,759 iteration 5241 : loss : 0.020615, loss_ce: 0.007462
2022-01-20 21:50:09,472 iteration 5242 : loss : 0.023663, loss_ce: 0.011074
2022-01-20 21:50:10,115 iteration 5243 : loss : 0.023645, loss_ce: 0.011210
2022-01-20 21:50:10,698 iteration 5244 : loss : 0.016775, loss_ce: 0.005811
2022-01-20 21:50:11,365 iteration 5245 : loss : 0.021514, loss_ce: 0.006841
2022-01-20 21:50:11,997 iteration 5246 : loss : 0.024380, loss_ce: 0.008284
2022-01-20 21:50:12,584 iteration 5247 : loss : 0.021416, loss_ce: 0.009026
2022-01-20 21:50:13,254 iteration 5248 : loss : 0.022981, loss_ce: 0.010535
2022-01-20 21:50:13,829 iteration 5249 : loss : 0.017535, loss_ce: 0.006105
2022-01-20 21:50:14,432 iteration 5250 : loss : 0.017237, loss_ce: 0.005932
2022-01-20 21:50:15,086 iteration 5251 : loss : 0.020282, loss_ce: 0.007837
2022-01-20 21:50:15,667 iteration 5252 : loss : 0.016517, loss_ce: 0.007783
2022-01-20 21:50:16,244 iteration 5253 : loss : 0.014139, loss_ce: 0.005246
 77%|███████████████████████▉       | 309/400 [56:41<16:10, 10.67s/it]2022-01-20 21:50:16,866 iteration 5254 : loss : 0.017040, loss_ce: 0.007948
2022-01-20 21:50:17,514 iteration 5255 : loss : 0.021250, loss_ce: 0.005081
2022-01-20 21:50:18,128 iteration 5256 : loss : 0.022086, loss_ce: 0.009127
2022-01-20 21:50:18,754 iteration 5257 : loss : 0.020437, loss_ce: 0.006849
2022-01-20 21:50:19,276 iteration 5258 : loss : 0.014424, loss_ce: 0.006103
2022-01-20 21:50:19,844 iteration 5259 : loss : 0.023380, loss_ce: 0.007413
2022-01-20 21:50:20,529 iteration 5260 : loss : 0.023635, loss_ce: 0.008418
2022-01-20 21:50:21,116 iteration 5261 : loss : 0.017254, loss_ce: 0.007259
2022-01-20 21:50:21,684 iteration 5262 : loss : 0.020820, loss_ce: 0.008791
2022-01-20 21:50:22,320 iteration 5263 : loss : 0.037395, loss_ce: 0.017247
2022-01-20 21:50:22,957 iteration 5264 : loss : 0.022432, loss_ce: 0.009139
2022-01-20 21:50:23,609 iteration 5265 : loss : 0.019591, loss_ce: 0.008191
2022-01-20 21:50:24,186 iteration 5266 : loss : 0.018876, loss_ce: 0.006923
2022-01-20 21:50:24,875 iteration 5267 : loss : 0.018198, loss_ce: 0.008034
2022-01-20 21:50:25,346 iteration 5268 : loss : 0.012884, loss_ce: 0.003365
2022-01-20 21:50:25,836 iteration 5269 : loss : 0.017197, loss_ce: 0.006475
2022-01-20 21:50:25,836 Training Data Eval:
2022-01-20 21:50:28,527   Average segmentation loss on training set: 0.0108
2022-01-20 21:50:28,527 Validation Data Eval:
2022-01-20 21:50:29,405   Average segmentation loss on validation set: 0.0785
2022-01-20 21:50:29,978 iteration 5270 : loss : 0.029427, loss_ce: 0.004569
 78%|████████████████████████       | 310/400 [56:54<17:22, 11.59s/it]2022-01-20 21:50:30,728 iteration 5271 : loss : 0.020843, loss_ce: 0.007304
2022-01-20 21:50:31,408 iteration 5272 : loss : 0.020534, loss_ce: 0.007685
2022-01-20 21:50:32,017 iteration 5273 : loss : 0.020968, loss_ce: 0.011759
2022-01-20 21:50:32,628 iteration 5274 : loss : 0.018426, loss_ce: 0.007326
2022-01-20 21:50:33,198 iteration 5275 : loss : 0.014974, loss_ce: 0.005861
2022-01-20 21:50:33,763 iteration 5276 : loss : 0.019558, loss_ce: 0.007431
2022-01-20 21:50:34,470 iteration 5277 : loss : 0.023424, loss_ce: 0.009495
2022-01-20 21:50:35,063 iteration 5278 : loss : 0.021155, loss_ce: 0.005304
2022-01-20 21:50:35,704 iteration 5279 : loss : 0.019411, loss_ce: 0.006369
2022-01-20 21:50:36,241 iteration 5280 : loss : 0.020411, loss_ce: 0.007837
2022-01-20 21:50:36,806 iteration 5281 : loss : 0.013821, loss_ce: 0.006086
2022-01-20 21:50:37,365 iteration 5282 : loss : 0.015326, loss_ce: 0.006169
2022-01-20 21:50:37,916 iteration 5283 : loss : 0.018219, loss_ce: 0.006984
2022-01-20 21:50:38,525 iteration 5284 : loss : 0.015826, loss_ce: 0.005909
2022-01-20 21:50:39,104 iteration 5285 : loss : 0.018691, loss_ce: 0.006347
2022-01-20 21:50:39,651 iteration 5286 : loss : 0.022515, loss_ce: 0.011013
2022-01-20 21:50:40,270 iteration 5287 : loss : 0.018805, loss_ce: 0.007468
 78%|████████████████████████       | 311/400 [57:05<16:36, 11.20s/it]2022-01-20 21:50:40,924 iteration 5288 : loss : 0.017501, loss_ce: 0.008795
2022-01-20 21:50:41,475 iteration 5289 : loss : 0.019724, loss_ce: 0.007205
2022-01-20 21:50:42,202 iteration 5290 : loss : 0.018971, loss_ce: 0.005699
2022-01-20 21:50:42,805 iteration 5291 : loss : 0.018601, loss_ce: 0.009075
2022-01-20 21:50:43,425 iteration 5292 : loss : 0.016792, loss_ce: 0.004339
2022-01-20 21:50:43,966 iteration 5293 : loss : 0.017253, loss_ce: 0.006033
2022-01-20 21:50:44,602 iteration 5294 : loss : 0.032429, loss_ce: 0.008764
2022-01-20 21:50:45,208 iteration 5295 : loss : 0.020898, loss_ce: 0.007098
2022-01-20 21:50:45,735 iteration 5296 : loss : 0.021687, loss_ce: 0.005336
2022-01-20 21:50:46,308 iteration 5297 : loss : 0.020627, loss_ce: 0.006670
2022-01-20 21:50:46,861 iteration 5298 : loss : 0.012721, loss_ce: 0.005699
2022-01-20 21:50:47,425 iteration 5299 : loss : 0.036355, loss_ce: 0.007635
2022-01-20 21:50:47,974 iteration 5300 : loss : 0.015952, loss_ce: 0.005899
2022-01-20 21:50:48,542 iteration 5301 : loss : 0.022144, loss_ce: 0.005129
2022-01-20 21:50:49,200 iteration 5302 : loss : 0.018875, loss_ce: 0.007730
2022-01-20 21:50:49,825 iteration 5303 : loss : 0.016598, loss_ce: 0.007641
2022-01-20 21:50:50,406 iteration 5304 : loss : 0.021231, loss_ce: 0.011096
 78%|████████████████████████▏      | 312/400 [57:15<15:57, 10.88s/it]2022-01-20 21:50:50,970 iteration 5305 : loss : 0.011771, loss_ce: 0.004148
2022-01-20 21:50:51,605 iteration 5306 : loss : 0.019133, loss_ce: 0.008266
2022-01-20 21:50:52,217 iteration 5307 : loss : 0.018257, loss_ce: 0.007329
2022-01-20 21:50:52,786 iteration 5308 : loss : 0.014347, loss_ce: 0.004890
2022-01-20 21:50:53,396 iteration 5309 : loss : 0.017294, loss_ce: 0.008445
2022-01-20 21:50:54,111 iteration 5310 : loss : 0.014129, loss_ce: 0.004483
2022-01-20 21:50:54,702 iteration 5311 : loss : 0.021799, loss_ce: 0.006704
2022-01-20 21:50:55,369 iteration 5312 : loss : 0.028037, loss_ce: 0.011498
2022-01-20 21:50:55,941 iteration 5313 : loss : 0.018242, loss_ce: 0.009078
2022-01-20 21:50:56,532 iteration 5314 : loss : 0.018990, loss_ce: 0.006992
2022-01-20 21:50:57,098 iteration 5315 : loss : 0.017389, loss_ce: 0.006001
2022-01-20 21:50:57,689 iteration 5316 : loss : 0.015122, loss_ce: 0.004223
2022-01-20 21:50:58,260 iteration 5317 : loss : 0.016250, loss_ce: 0.004776
2022-01-20 21:50:58,906 iteration 5318 : loss : 0.017107, loss_ce: 0.006423
2022-01-20 21:50:59,487 iteration 5319 : loss : 0.023847, loss_ce: 0.008234
2022-01-20 21:51:00,033 iteration 5320 : loss : 0.015261, loss_ce: 0.005229
2022-01-20 21:51:00,589 iteration 5321 : loss : 0.018538, loss_ce: 0.007784
 78%|████████████████████████▎      | 313/400 [57:25<15:28, 10.67s/it]2022-01-20 21:51:01,160 iteration 5322 : loss : 0.014307, loss_ce: 0.005142
2022-01-20 21:51:01,782 iteration 5323 : loss : 0.019778, loss_ce: 0.005302
2022-01-20 21:51:02,350 iteration 5324 : loss : 0.017645, loss_ce: 0.005955
2022-01-20 21:51:03,003 iteration 5325 : loss : 0.018177, loss_ce: 0.007404
2022-01-20 21:51:03,640 iteration 5326 : loss : 0.025797, loss_ce: 0.009323
2022-01-20 21:51:04,240 iteration 5327 : loss : 0.026233, loss_ce: 0.011184
2022-01-20 21:51:04,869 iteration 5328 : loss : 0.011850, loss_ce: 0.004314
2022-01-20 21:51:05,502 iteration 5329 : loss : 0.017016, loss_ce: 0.008277
2022-01-20 21:51:06,158 iteration 5330 : loss : 0.016528, loss_ce: 0.005533
2022-01-20 21:51:06,699 iteration 5331 : loss : 0.016578, loss_ce: 0.006026
2022-01-20 21:51:07,258 iteration 5332 : loss : 0.018527, loss_ce: 0.007908
2022-01-20 21:51:07,836 iteration 5333 : loss : 0.021546, loss_ce: 0.007446
2022-01-20 21:51:08,397 iteration 5334 : loss : 0.015457, loss_ce: 0.004698
2022-01-20 21:51:09,082 iteration 5335 : loss : 0.020950, loss_ce: 0.007647
2022-01-20 21:51:09,687 iteration 5336 : loss : 0.018069, loss_ce: 0.005857
2022-01-20 21:51:10,277 iteration 5337 : loss : 0.023956, loss_ce: 0.007898
2022-01-20 21:51:10,776 iteration 5338 : loss : 0.014942, loss_ce: 0.005394
 78%|████████████████████████▎      | 314/400 [57:35<15:05, 10.53s/it]2022-01-20 21:51:11,398 iteration 5339 : loss : 0.017578, loss_ce: 0.005597
2022-01-20 21:51:11,997 iteration 5340 : loss : 0.013759, loss_ce: 0.007932
2022-01-20 21:51:12,616 iteration 5341 : loss : 0.017268, loss_ce: 0.007111
2022-01-20 21:51:13,254 iteration 5342 : loss : 0.019438, loss_ce: 0.005403
2022-01-20 21:51:13,819 iteration 5343 : loss : 0.020694, loss_ce: 0.006858
2022-01-20 21:51:14,384 iteration 5344 : loss : 0.017120, loss_ce: 0.007216
2022-01-20 21:51:14,922 iteration 5345 : loss : 0.015742, loss_ce: 0.004648
2022-01-20 21:51:15,496 iteration 5346 : loss : 0.023596, loss_ce: 0.011671
2022-01-20 21:51:16,177 iteration 5347 : loss : 0.017628, loss_ce: 0.007076
2022-01-20 21:51:16,797 iteration 5348 : loss : 0.018421, loss_ce: 0.007612
2022-01-20 21:51:17,388 iteration 5349 : loss : 0.015747, loss_ce: 0.007192
2022-01-20 21:51:17,918 iteration 5350 : loss : 0.014098, loss_ce: 0.005214
2022-01-20 21:51:18,560 iteration 5351 : loss : 0.017836, loss_ce: 0.004129
2022-01-20 21:51:19,159 iteration 5352 : loss : 0.012575, loss_ce: 0.004773
2022-01-20 21:51:19,804 iteration 5353 : loss : 0.021556, loss_ce: 0.009906
2022-01-20 21:51:20,355 iteration 5354 : loss : 0.013313, loss_ce: 0.005050
2022-01-20 21:51:20,355 Training Data Eval:
2022-01-20 21:51:23,042   Average segmentation loss on training set: 0.0103
2022-01-20 21:51:23,043 Validation Data Eval:
2022-01-20 21:51:23,915   Average segmentation loss on validation set: 0.0790
2022-01-20 21:51:24,443 iteration 5355 : loss : 0.012348, loss_ce: 0.004648
 79%|████████████████████████▍      | 315/400 [57:49<16:14, 11.47s/it]2022-01-20 21:51:25,133 iteration 5356 : loss : 0.022470, loss_ce: 0.009055
2022-01-20 21:51:25,641 iteration 5357 : loss : 0.011545, loss_ce: 0.003362
2022-01-20 21:51:26,234 iteration 5358 : loss : 0.012638, loss_ce: 0.003167
2022-01-20 21:51:26,798 iteration 5359 : loss : 0.015919, loss_ce: 0.008390
2022-01-20 21:51:27,382 iteration 5360 : loss : 0.016166, loss_ce: 0.005614
2022-01-20 21:51:28,039 iteration 5361 : loss : 0.018320, loss_ce: 0.005803
2022-01-20 21:51:28,679 iteration 5362 : loss : 0.017471, loss_ce: 0.010415
2022-01-20 21:51:29,274 iteration 5363 : loss : 0.015823, loss_ce: 0.006617
2022-01-20 21:51:29,771 iteration 5364 : loss : 0.015936, loss_ce: 0.002613
2022-01-20 21:51:30,412 iteration 5365 : loss : 0.013713, loss_ce: 0.004667
2022-01-20 21:51:30,942 iteration 5366 : loss : 0.018294, loss_ce: 0.006201
2022-01-20 21:51:31,563 iteration 5367 : loss : 0.015856, loss_ce: 0.003898
2022-01-20 21:51:32,258 iteration 5368 : loss : 0.017665, loss_ce: 0.006620
2022-01-20 21:51:32,877 iteration 5369 : loss : 0.019059, loss_ce: 0.008322
2022-01-20 21:51:33,495 iteration 5370 : loss : 0.021072, loss_ce: 0.006850
2022-01-20 21:51:34,174 iteration 5371 : loss : 0.017510, loss_ce: 0.005275
2022-01-20 21:51:34,756 iteration 5372 : loss : 0.022315, loss_ce: 0.009265
 79%|████████████████████████▍      | 316/400 [57:59<15:34, 11.12s/it]2022-01-20 21:51:35,315 iteration 5373 : loss : 0.013860, loss_ce: 0.005976
2022-01-20 21:51:35,925 iteration 5374 : loss : 0.020635, loss_ce: 0.005917
2022-01-20 21:51:36,473 iteration 5375 : loss : 0.015550, loss_ce: 0.005366
2022-01-20 21:51:37,001 iteration 5376 : loss : 0.013565, loss_ce: 0.004361
2022-01-20 21:51:37,483 iteration 5377 : loss : 0.017161, loss_ce: 0.002665
2022-01-20 21:51:37,966 iteration 5378 : loss : 0.012344, loss_ce: 0.004515
2022-01-20 21:51:38,574 iteration 5379 : loss : 0.020225, loss_ce: 0.006134
2022-01-20 21:51:39,128 iteration 5380 : loss : 0.014814, loss_ce: 0.006467
2022-01-20 21:51:39,716 iteration 5381 : loss : 0.020582, loss_ce: 0.008123
2022-01-20 21:51:40,341 iteration 5382 : loss : 0.020364, loss_ce: 0.005782
2022-01-20 21:51:40,984 iteration 5383 : loss : 0.020522, loss_ce: 0.008575
2022-01-20 21:51:41,563 iteration 5384 : loss : 0.017494, loss_ce: 0.007781
2022-01-20 21:51:42,146 iteration 5385 : loss : 0.019689, loss_ce: 0.008152
2022-01-20 21:51:42,780 iteration 5386 : loss : 0.015988, loss_ce: 0.005988
2022-01-20 21:51:43,380 iteration 5387 : loss : 0.018966, loss_ce: 0.008698
2022-01-20 21:51:43,888 iteration 5388 : loss : 0.013466, loss_ce: 0.005177
2022-01-20 21:51:44,454 iteration 5389 : loss : 0.015942, loss_ce: 0.005108
 79%|████████████████████████▌      | 317/400 [58:09<14:47, 10.69s/it]2022-01-20 21:51:45,161 iteration 5390 : loss : 0.021450, loss_ce: 0.005879
2022-01-20 21:51:45,657 iteration 5391 : loss : 0.014413, loss_ce: 0.004910
2022-01-20 21:51:46,273 iteration 5392 : loss : 0.015425, loss_ce: 0.006455
2022-01-20 21:51:46,900 iteration 5393 : loss : 0.018660, loss_ce: 0.005987
2022-01-20 21:51:47,481 iteration 5394 : loss : 0.014346, loss_ce: 0.005711
2022-01-20 21:51:48,010 iteration 5395 : loss : 0.015350, loss_ce: 0.006738
2022-01-20 21:51:48,650 iteration 5396 : loss : 0.021733, loss_ce: 0.005903
2022-01-20 21:51:49,249 iteration 5397 : loss : 0.023123, loss_ce: 0.008367
2022-01-20 21:51:49,740 iteration 5398 : loss : 0.011076, loss_ce: 0.005324
2022-01-20 21:51:50,308 iteration 5399 : loss : 0.011509, loss_ce: 0.005162
2022-01-20 21:51:50,985 iteration 5400 : loss : 0.018737, loss_ce: 0.005533
2022-01-20 21:51:51,630 iteration 5401 : loss : 0.016059, loss_ce: 0.004833
2022-01-20 21:51:52,219 iteration 5402 : loss : 0.017351, loss_ce: 0.007474
2022-01-20 21:51:52,862 iteration 5403 : loss : 0.019491, loss_ce: 0.005588
2022-01-20 21:51:53,424 iteration 5404 : loss : 0.014685, loss_ce: 0.007024
2022-01-20 21:51:53,956 iteration 5405 : loss : 0.011844, loss_ce: 0.003801
2022-01-20 21:51:54,451 iteration 5406 : loss : 0.018277, loss_ce: 0.004187
 80%|████████████████████████▋      | 318/400 [58:19<14:19, 10.49s/it]2022-01-20 21:51:55,153 iteration 5407 : loss : 0.016090, loss_ce: 0.004527
2022-01-20 21:51:55,721 iteration 5408 : loss : 0.014044, loss_ce: 0.004120
2022-01-20 21:51:56,258 iteration 5409 : loss : 0.013528, loss_ce: 0.005903
2022-01-20 21:51:56,807 iteration 5410 : loss : 0.014561, loss_ce: 0.005204
2022-01-20 21:51:57,425 iteration 5411 : loss : 0.015960, loss_ce: 0.005511
2022-01-20 21:51:58,056 iteration 5412 : loss : 0.018707, loss_ce: 0.008697
2022-01-20 21:51:58,594 iteration 5413 : loss : 0.016384, loss_ce: 0.006219
2022-01-20 21:51:59,237 iteration 5414 : loss : 0.018492, loss_ce: 0.006143
2022-01-20 21:51:59,822 iteration 5415 : loss : 0.019531, loss_ce: 0.006353
2022-01-20 21:52:00,469 iteration 5416 : loss : 0.015064, loss_ce: 0.006221
2022-01-20 21:52:01,036 iteration 5417 : loss : 0.017274, loss_ce: 0.006590
2022-01-20 21:52:01,625 iteration 5418 : loss : 0.013440, loss_ce: 0.004400
2022-01-20 21:52:02,195 iteration 5419 : loss : 0.015190, loss_ce: 0.007232
2022-01-20 21:52:02,804 iteration 5420 : loss : 0.015849, loss_ce: 0.006918
2022-01-20 21:52:03,437 iteration 5421 : loss : 0.022090, loss_ce: 0.006778
2022-01-20 21:52:04,040 iteration 5422 : loss : 0.018044, loss_ce: 0.006241
2022-01-20 21:52:04,682 iteration 5423 : loss : 0.022627, loss_ce: 0.007533
 80%|████████████████████████▋      | 319/400 [58:29<14:02, 10.41s/it]2022-01-20 21:52:05,345 iteration 5424 : loss : 0.017007, loss_ce: 0.005982
2022-01-20 21:52:05,958 iteration 5425 : loss : 0.019490, loss_ce: 0.007867
2022-01-20 21:52:06,578 iteration 5426 : loss : 0.017456, loss_ce: 0.005603
2022-01-20 21:52:07,288 iteration 5427 : loss : 0.029033, loss_ce: 0.009713
2022-01-20 21:52:07,951 iteration 5428 : loss : 0.058520, loss_ce: 0.032996
2022-01-20 21:52:08,503 iteration 5429 : loss : 0.012603, loss_ce: 0.004825
2022-01-20 21:52:09,011 iteration 5430 : loss : 0.013342, loss_ce: 0.005489
2022-01-20 21:52:09,670 iteration 5431 : loss : 0.027149, loss_ce: 0.009370
2022-01-20 21:52:10,235 iteration 5432 : loss : 0.015995, loss_ce: 0.005610
2022-01-20 21:52:10,949 iteration 5433 : loss : 0.021961, loss_ce: 0.007572
2022-01-20 21:52:11,629 iteration 5434 : loss : 0.028354, loss_ce: 0.009372
2022-01-20 21:52:12,258 iteration 5435 : loss : 0.016673, loss_ce: 0.007037
2022-01-20 21:52:12,912 iteration 5436 : loss : 0.019000, loss_ce: 0.008774
2022-01-20 21:52:13,472 iteration 5437 : loss : 0.017303, loss_ce: 0.004284
2022-01-20 21:52:14,071 iteration 5438 : loss : 0.021739, loss_ce: 0.009747
2022-01-20 21:52:14,706 iteration 5439 : loss : 0.025621, loss_ce: 0.008254
2022-01-20 21:52:14,707 Training Data Eval:
2022-01-20 21:52:17,392   Average segmentation loss on training set: 0.0100
2022-01-20 21:52:17,393 Validation Data Eval:
2022-01-20 21:52:18,278   Average segmentation loss on validation set: 0.0823
2022-01-20 21:52:18,875 iteration 5440 : loss : 0.015344, loss_ce: 0.005772
 80%|████████████████████████▊      | 320/400 [58:43<15:23, 11.55s/it]2022-01-20 21:52:19,446 iteration 5441 : loss : 0.014624, loss_ce: 0.006351
2022-01-20 21:52:20,161 iteration 5442 : loss : 0.024462, loss_ce: 0.010401
2022-01-20 21:52:20,792 iteration 5443 : loss : 0.026560, loss_ce: 0.011290
2022-01-20 21:52:21,373 iteration 5444 : loss : 0.016545, loss_ce: 0.007806
2022-01-20 21:52:21,945 iteration 5445 : loss : 0.023491, loss_ce: 0.009251
2022-01-20 21:52:22,543 iteration 5446 : loss : 0.015893, loss_ce: 0.006132
2022-01-20 21:52:23,068 iteration 5447 : loss : 0.015090, loss_ce: 0.002956
2022-01-20 21:52:23,678 iteration 5448 : loss : 0.016524, loss_ce: 0.005548
2022-01-20 21:52:24,249 iteration 5449 : loss : 0.013667, loss_ce: 0.004093
2022-01-20 21:52:24,800 iteration 5450 : loss : 0.023364, loss_ce: 0.007154
2022-01-20 21:52:25,407 iteration 5451 : loss : 0.013107, loss_ce: 0.003830
2022-01-20 21:52:26,014 iteration 5452 : loss : 0.014176, loss_ce: 0.005720
2022-01-20 21:52:26,662 iteration 5453 : loss : 0.016444, loss_ce: 0.005872
2022-01-20 21:52:27,284 iteration 5454 : loss : 0.018475, loss_ce: 0.008775
2022-01-20 21:52:27,892 iteration 5455 : loss : 0.017494, loss_ce: 0.009659
2022-01-20 21:52:28,523 iteration 5456 : loss : 0.017470, loss_ce: 0.005069
2022-01-20 21:52:29,140 iteration 5457 : loss : 0.014585, loss_ce: 0.005937
 80%|████████████████████████▉      | 321/400 [58:54<14:41, 11.16s/it]2022-01-20 21:52:29,857 iteration 5458 : loss : 0.020992, loss_ce: 0.005961
2022-01-20 21:52:30,406 iteration 5459 : loss : 0.016539, loss_ce: 0.005820
2022-01-20 21:52:30,998 iteration 5460 : loss : 0.019462, loss_ce: 0.008021
2022-01-20 21:52:31,622 iteration 5461 : loss : 0.017643, loss_ce: 0.006306
2022-01-20 21:52:32,261 iteration 5462 : loss : 0.015944, loss_ce: 0.006328
2022-01-20 21:52:32,828 iteration 5463 : loss : 0.011908, loss_ce: 0.003931
2022-01-20 21:52:33,561 iteration 5464 : loss : 0.019793, loss_ce: 0.007465
2022-01-20 21:52:34,128 iteration 5465 : loss : 0.019318, loss_ce: 0.007007
2022-01-20 21:52:34,693 iteration 5466 : loss : 0.015108, loss_ce: 0.005915
2022-01-20 21:52:35,363 iteration 5467 : loss : 0.016937, loss_ce: 0.005898
2022-01-20 21:52:36,024 iteration 5468 : loss : 0.017482, loss_ce: 0.008628
2022-01-20 21:52:36,690 iteration 5469 : loss : 0.020695, loss_ce: 0.009318
2022-01-20 21:52:37,270 iteration 5470 : loss : 0.014325, loss_ce: 0.006461
2022-01-20 21:52:37,835 iteration 5471 : loss : 0.013554, loss_ce: 0.006545
2022-01-20 21:52:38,491 iteration 5472 : loss : 0.018597, loss_ce: 0.008116
2022-01-20 21:52:39,060 iteration 5473 : loss : 0.014972, loss_ce: 0.004222
2022-01-20 21:52:39,709 iteration 5474 : loss : 0.015532, loss_ce: 0.005003
 80%|████████████████████████▉      | 322/400 [59:04<14:16, 10.98s/it]2022-01-20 21:52:40,316 iteration 5475 : loss : 0.022461, loss_ce: 0.007839
2022-01-20 21:52:40,896 iteration 5476 : loss : 0.013177, loss_ce: 0.005538
2022-01-20 21:52:41,539 iteration 5477 : loss : 0.012378, loss_ce: 0.004585
2022-01-20 21:52:42,200 iteration 5478 : loss : 0.022007, loss_ce: 0.009597
2022-01-20 21:52:42,768 iteration 5479 : loss : 0.019540, loss_ce: 0.005163
2022-01-20 21:52:43,369 iteration 5480 : loss : 0.015662, loss_ce: 0.003910
2022-01-20 21:52:43,980 iteration 5481 : loss : 0.018207, loss_ce: 0.007337
2022-01-20 21:52:44,579 iteration 5482 : loss : 0.015969, loss_ce: 0.005714
2022-01-20 21:52:45,119 iteration 5483 : loss : 0.018796, loss_ce: 0.006977
2022-01-20 21:52:45,775 iteration 5484 : loss : 0.020416, loss_ce: 0.008571
2022-01-20 21:52:46,307 iteration 5485 : loss : 0.015081, loss_ce: 0.007264
2022-01-20 21:52:47,020 iteration 5486 : loss : 0.020068, loss_ce: 0.005120
2022-01-20 21:52:47,563 iteration 5487 : loss : 0.016857, loss_ce: 0.009873
2022-01-20 21:52:48,191 iteration 5488 : loss : 0.020576, loss_ce: 0.005624
2022-01-20 21:52:48,734 iteration 5489 : loss : 0.020242, loss_ce: 0.004882
2022-01-20 21:52:49,369 iteration 5490 : loss : 0.015157, loss_ce: 0.005578
2022-01-20 21:52:49,929 iteration 5491 : loss : 0.015729, loss_ce: 0.005356
 81%|█████████████████████████      | 323/400 [59:14<13:48, 10.75s/it]2022-01-20 21:52:50,605 iteration 5492 : loss : 0.017585, loss_ce: 0.009031
2022-01-20 21:52:51,144 iteration 5493 : loss : 0.013656, loss_ce: 0.004556
2022-01-20 21:52:51,708 iteration 5494 : loss : 0.014867, loss_ce: 0.006673
2022-01-20 21:52:52,372 iteration 5495 : loss : 0.023669, loss_ce: 0.005160
2022-01-20 21:52:52,914 iteration 5496 : loss : 0.014968, loss_ce: 0.004847
2022-01-20 21:52:53,515 iteration 5497 : loss : 0.016160, loss_ce: 0.007758
2022-01-20 21:52:54,153 iteration 5498 : loss : 0.014280, loss_ce: 0.005971
2022-01-20 21:52:54,749 iteration 5499 : loss : 0.013572, loss_ce: 0.004340
2022-01-20 21:52:55,344 iteration 5500 : loss : 0.014418, loss_ce: 0.004593
2022-01-20 21:52:55,908 iteration 5501 : loss : 0.012488, loss_ce: 0.004380
2022-01-20 21:52:56,467 iteration 5502 : loss : 0.014373, loss_ce: 0.006495
2022-01-20 21:52:57,191 iteration 5503 : loss : 0.028517, loss_ce: 0.009981
2022-01-20 21:52:57,805 iteration 5504 : loss : 0.021281, loss_ce: 0.007855
2022-01-20 21:52:58,332 iteration 5505 : loss : 0.012801, loss_ce: 0.004674
2022-01-20 21:52:58,885 iteration 5506 : loss : 0.015748, loss_ce: 0.005722
2022-01-20 21:52:59,565 iteration 5507 : loss : 0.022405, loss_ce: 0.007373
2022-01-20 21:53:00,203 iteration 5508 : loss : 0.023690, loss_ce: 0.010823
 81%|█████████████████████████      | 324/400 [59:25<13:26, 10.61s/it]2022-01-20 21:53:00,878 iteration 5509 : loss : 0.015791, loss_ce: 0.007159
2022-01-20 21:53:01,450 iteration 5510 : loss : 0.014340, loss_ce: 0.005361
2022-01-20 21:53:02,066 iteration 5511 : loss : 0.022300, loss_ce: 0.007582
2022-01-20 21:53:02,652 iteration 5512 : loss : 0.016353, loss_ce: 0.007669
2022-01-20 21:53:03,242 iteration 5513 : loss : 0.013657, loss_ce: 0.006841
2022-01-20 21:53:03,902 iteration 5514 : loss : 0.026306, loss_ce: 0.012576
2022-01-20 21:53:04,498 iteration 5515 : loss : 0.015284, loss_ce: 0.006007
2022-01-20 21:53:05,092 iteration 5516 : loss : 0.013920, loss_ce: 0.006288
2022-01-20 21:53:05,764 iteration 5517 : loss : 0.020527, loss_ce: 0.007004
2022-01-20 21:53:06,286 iteration 5518 : loss : 0.013286, loss_ce: 0.004422
2022-01-20 21:53:06,963 iteration 5519 : loss : 0.024708, loss_ce: 0.006662
2022-01-20 21:53:07,552 iteration 5520 : loss : 0.014162, loss_ce: 0.003267
2022-01-20 21:53:08,231 iteration 5521 : loss : 0.021819, loss_ce: 0.009366
2022-01-20 21:53:08,823 iteration 5522 : loss : 0.015278, loss_ce: 0.005012
2022-01-20 21:53:09,466 iteration 5523 : loss : 0.023274, loss_ce: 0.011403
2022-01-20 21:53:10,133 iteration 5524 : loss : 0.017722, loss_ce: 0.007205
2022-01-20 21:53:10,133 Training Data Eval:
2022-01-20 21:53:12,822   Average segmentation loss on training set: 0.0106
2022-01-20 21:53:12,823 Validation Data Eval:
2022-01-20 21:53:13,702   Average segmentation loss on validation set: 0.0870
2022-01-20 21:53:14,390 iteration 5525 : loss : 0.017074, loss_ce: 0.007352
 81%|█████████████████████████▏     | 325/400 [59:39<14:36, 11.68s/it]2022-01-20 21:53:15,023 iteration 5526 : loss : 0.026247, loss_ce: 0.007884
2022-01-20 21:53:15,553 iteration 5527 : loss : 0.015264, loss_ce: 0.006429
2022-01-20 21:53:16,227 iteration 5528 : loss : 0.023962, loss_ce: 0.008036
2022-01-20 21:53:16,797 iteration 5529 : loss : 0.013943, loss_ce: 0.005150
2022-01-20 21:53:17,347 iteration 5530 : loss : 0.017318, loss_ce: 0.007098
2022-01-20 21:53:17,850 iteration 5531 : loss : 0.011824, loss_ce: 0.003632
2022-01-20 21:53:18,381 iteration 5532 : loss : 0.015646, loss_ce: 0.005903
2022-01-20 21:53:19,006 iteration 5533 : loss : 0.014830, loss_ce: 0.007110
2022-01-20 21:53:19,527 iteration 5534 : loss : 0.011135, loss_ce: 0.003899
2022-01-20 21:53:20,094 iteration 5535 : loss : 0.016335, loss_ce: 0.007122
2022-01-20 21:53:20,740 iteration 5536 : loss : 0.019900, loss_ce: 0.006329
2022-01-20 21:53:21,383 iteration 5537 : loss : 0.017665, loss_ce: 0.007807
2022-01-20 21:53:22,076 iteration 5538 : loss : 0.020568, loss_ce: 0.005655
2022-01-20 21:53:22,690 iteration 5539 : loss : 0.014300, loss_ce: 0.005526
2022-01-20 21:53:23,220 iteration 5540 : loss : 0.015268, loss_ce: 0.006664
2022-01-20 21:53:23,930 iteration 5541 : loss : 0.022303, loss_ce: 0.010255
2022-01-20 21:53:24,541 iteration 5542 : loss : 0.021510, loss_ce: 0.009672
 82%|█████████████████████████▎     | 326/400 [59:49<13:50, 11.22s/it]2022-01-20 21:53:25,241 iteration 5543 : loss : 0.017758, loss_ce: 0.008015
2022-01-20 21:53:25,800 iteration 5544 : loss : 0.014343, loss_ce: 0.005077
2022-01-20 21:53:26,436 iteration 5545 : loss : 0.015340, loss_ce: 0.006930
2022-01-20 21:53:27,130 iteration 5546 : loss : 0.035578, loss_ce: 0.008672
2022-01-20 21:53:27,775 iteration 5547 : loss : 0.017516, loss_ce: 0.007951
2022-01-20 21:53:28,349 iteration 5548 : loss : 0.018499, loss_ce: 0.004542
2022-01-20 21:53:28,922 iteration 5549 : loss : 0.013449, loss_ce: 0.003712
2022-01-20 21:53:29,541 iteration 5550 : loss : 0.014565, loss_ce: 0.005405
2022-01-20 21:53:30,110 iteration 5551 : loss : 0.029138, loss_ce: 0.014237
2022-01-20 21:53:30,591 iteration 5552 : loss : 0.012999, loss_ce: 0.004179
2022-01-20 21:53:31,196 iteration 5553 : loss : 0.018096, loss_ce: 0.007002
2022-01-20 21:53:31,778 iteration 5554 : loss : 0.017285, loss_ce: 0.007487
2022-01-20 21:53:32,289 iteration 5555 : loss : 0.015881, loss_ce: 0.006872
2022-01-20 21:53:32,935 iteration 5556 : loss : 0.018344, loss_ce: 0.006362
2022-01-20 21:53:33,556 iteration 5557 : loss : 0.012449, loss_ce: 0.005098
2022-01-20 21:53:34,153 iteration 5558 : loss : 0.017471, loss_ce: 0.006323
2022-01-20 21:53:34,740 iteration 5559 : loss : 0.018842, loss_ce: 0.006860
 82%|█████████████████████████▎     | 327/400 [59:59<13:16, 10.92s/it]2022-01-20 21:53:35,390 iteration 5560 : loss : 0.018020, loss_ce: 0.006594
2022-01-20 21:53:35,954 iteration 5561 : loss : 0.021566, loss_ce: 0.007867
2022-01-20 21:53:36,538 iteration 5562 : loss : 0.016264, loss_ce: 0.007142
2022-01-20 21:53:37,116 iteration 5563 : loss : 0.016944, loss_ce: 0.007180
2022-01-20 21:53:37,754 iteration 5564 : loss : 0.018359, loss_ce: 0.009052
2022-01-20 21:53:38,402 iteration 5565 : loss : 0.018212, loss_ce: 0.007907
2022-01-20 21:53:39,013 iteration 5566 : loss : 0.014836, loss_ce: 0.005786
2022-01-20 21:53:39,655 iteration 5567 : loss : 0.016646, loss_ce: 0.008177
2022-01-20 21:53:40,238 iteration 5568 : loss : 0.017850, loss_ce: 0.006570
2022-01-20 21:53:40,849 iteration 5569 : loss : 0.020203, loss_ce: 0.006567
2022-01-20 21:53:41,395 iteration 5570 : loss : 0.011872, loss_ce: 0.003392
2022-01-20 21:53:41,883 iteration 5571 : loss : 0.011881, loss_ce: 0.004418
2022-01-20 21:53:42,428 iteration 5572 : loss : 0.017472, loss_ce: 0.005906
2022-01-20 21:53:42,946 iteration 5573 : loss : 0.010108, loss_ce: 0.003101
2022-01-20 21:53:43,530 iteration 5574 : loss : 0.012417, loss_ce: 0.003851
2022-01-20 21:53:44,225 iteration 5575 : loss : 0.022254, loss_ce: 0.007101
2022-01-20 21:53:44,854 iteration 5576 : loss : 0.019112, loss_ce: 0.007068
 82%|███████████████████████▊     | 328/400 [1:00:09<12:48, 10.67s/it]2022-01-20 21:53:45,514 iteration 5577 : loss : 0.019113, loss_ce: 0.007956
2022-01-20 21:53:46,150 iteration 5578 : loss : 0.020161, loss_ce: 0.007121
2022-01-20 21:53:46,820 iteration 5579 : loss : 0.018850, loss_ce: 0.008693
2022-01-20 21:53:47,402 iteration 5580 : loss : 0.020397, loss_ce: 0.007831
2022-01-20 21:53:47,950 iteration 5581 : loss : 0.012791, loss_ce: 0.005010
2022-01-20 21:53:48,550 iteration 5582 : loss : 0.013599, loss_ce: 0.003973
2022-01-20 21:53:49,129 iteration 5583 : loss : 0.010905, loss_ce: 0.004140
2022-01-20 21:53:49,772 iteration 5584 : loss : 0.017975, loss_ce: 0.007297
2022-01-20 21:53:50,345 iteration 5585 : loss : 0.016064, loss_ce: 0.005129
2022-01-20 21:53:51,003 iteration 5586 : loss : 0.018909, loss_ce: 0.006723
2022-01-20 21:53:51,543 iteration 5587 : loss : 0.022086, loss_ce: 0.007052
2022-01-20 21:53:52,117 iteration 5588 : loss : 0.017765, loss_ce: 0.006741
2022-01-20 21:53:52,647 iteration 5589 : loss : 0.012043, loss_ce: 0.003442
2022-01-20 21:53:53,205 iteration 5590 : loss : 0.012997, loss_ce: 0.003211
2022-01-20 21:53:53,771 iteration 5591 : loss : 0.015076, loss_ce: 0.006026
2022-01-20 21:53:54,433 iteration 5592 : loss : 0.019633, loss_ce: 0.006225
2022-01-20 21:53:55,059 iteration 5593 : loss : 0.018021, loss_ce: 0.007272
 82%|███████████████████████▊     | 329/400 [1:00:19<12:28, 10.54s/it]2022-01-20 21:53:55,649 iteration 5594 : loss : 0.018109, loss_ce: 0.005367
2022-01-20 21:53:56,282 iteration 5595 : loss : 0.019333, loss_ce: 0.008729
2022-01-20 21:53:56,851 iteration 5596 : loss : 0.015432, loss_ce: 0.005734
2022-01-20 21:53:57,502 iteration 5597 : loss : 0.013417, loss_ce: 0.004781
2022-01-20 21:53:58,037 iteration 5598 : loss : 0.013207, loss_ce: 0.005600
2022-01-20 21:53:58,628 iteration 5599 : loss : 0.023116, loss_ce: 0.008697
2022-01-20 21:53:59,209 iteration 5600 : loss : 0.014193, loss_ce: 0.005514
2022-01-20 21:53:59,778 iteration 5601 : loss : 0.013328, loss_ce: 0.005371
2022-01-20 21:54:00,396 iteration 5602 : loss : 0.015130, loss_ce: 0.006221
2022-01-20 21:54:00,940 iteration 5603 : loss : 0.012097, loss_ce: 0.004715
2022-01-20 21:54:01,551 iteration 5604 : loss : 0.016761, loss_ce: 0.003620
2022-01-20 21:54:02,185 iteration 5605 : loss : 0.018352, loss_ce: 0.007416
2022-01-20 21:54:02,798 iteration 5606 : loss : 0.017597, loss_ce: 0.005602
2022-01-20 21:54:03,393 iteration 5607 : loss : 0.017688, loss_ce: 0.006519
2022-01-20 21:54:03,984 iteration 5608 : loss : 0.013890, loss_ce: 0.004464
2022-01-20 21:54:04,615 iteration 5609 : loss : 0.013951, loss_ce: 0.005740
2022-01-20 21:54:04,616 Training Data Eval:
2022-01-20 21:54:07,316   Average segmentation loss on training set: 0.0096
2022-01-20 21:54:07,316 Validation Data Eval:
2022-01-20 21:54:08,195   Average segmentation loss on validation set: 0.0858
2022-01-20 21:54:08,745 iteration 5610 : loss : 0.013996, loss_ce: 0.004937
 82%|███████████████████████▉     | 330/400 [1:00:33<13:23, 11.48s/it]2022-01-20 21:54:09,367 iteration 5611 : loss : 0.018958, loss_ce: 0.006509
2022-01-20 21:54:09,975 iteration 5612 : loss : 0.021994, loss_ce: 0.004395
2022-01-20 21:54:10,571 iteration 5613 : loss : 0.014976, loss_ce: 0.005378
2022-01-20 21:54:11,160 iteration 5614 : loss : 0.016637, loss_ce: 0.006484
2022-01-20 21:54:11,668 iteration 5615 : loss : 0.010691, loss_ce: 0.004425
2022-01-20 21:54:12,290 iteration 5616 : loss : 0.014880, loss_ce: 0.006668
2022-01-20 21:54:12,939 iteration 5617 : loss : 0.015329, loss_ce: 0.005492
2022-01-20 21:54:13,556 iteration 5618 : loss : 0.018717, loss_ce: 0.008010
2022-01-20 21:54:14,119 iteration 5619 : loss : 0.017479, loss_ce: 0.005234
2022-01-20 21:54:14,775 iteration 5620 : loss : 0.015857, loss_ce: 0.006343
2022-01-20 21:54:15,298 iteration 5621 : loss : 0.014711, loss_ce: 0.005165
2022-01-20 21:54:15,900 iteration 5622 : loss : 0.015972, loss_ce: 0.007114
2022-01-20 21:54:16,582 iteration 5623 : loss : 0.024011, loss_ce: 0.009700
2022-01-20 21:54:17,123 iteration 5624 : loss : 0.015471, loss_ce: 0.004306
2022-01-20 21:54:17,658 iteration 5625 : loss : 0.014435, loss_ce: 0.005996
2022-01-20 21:54:18,225 iteration 5626 : loss : 0.018307, loss_ce: 0.004948
2022-01-20 21:54:18,849 iteration 5627 : loss : 0.016825, loss_ce: 0.006623
 83%|███████████████████████▉     | 331/400 [1:00:43<12:43, 11.07s/it]2022-01-20 21:54:19,592 iteration 5628 : loss : 0.019000, loss_ce: 0.009525
2022-01-20 21:54:20,145 iteration 5629 : loss : 0.013521, loss_ce: 0.005459
2022-01-20 21:54:20,774 iteration 5630 : loss : 0.019135, loss_ce: 0.007628
2022-01-20 21:54:21,360 iteration 5631 : loss : 0.017732, loss_ce: 0.006183
2022-01-20 21:54:21,992 iteration 5632 : loss : 0.016818, loss_ce: 0.007324
2022-01-20 21:54:22,655 iteration 5633 : loss : 0.026073, loss_ce: 0.009001
2022-01-20 21:54:23,266 iteration 5634 : loss : 0.011102, loss_ce: 0.004487
2022-01-20 21:54:23,844 iteration 5635 : loss : 0.013305, loss_ce: 0.004935
2022-01-20 21:54:24,450 iteration 5636 : loss : 0.016598, loss_ce: 0.004769
2022-01-20 21:54:25,033 iteration 5637 : loss : 0.016185, loss_ce: 0.005152
2022-01-20 21:54:25,632 iteration 5638 : loss : 0.017614, loss_ce: 0.007458
2022-01-20 21:54:26,246 iteration 5639 : loss : 0.015040, loss_ce: 0.004942
2022-01-20 21:54:26,861 iteration 5640 : loss : 0.015245, loss_ce: 0.006251
2022-01-20 21:54:27,388 iteration 5641 : loss : 0.015126, loss_ce: 0.004500
2022-01-20 21:54:27,938 iteration 5642 : loss : 0.016573, loss_ce: 0.006632
2022-01-20 21:54:28,521 iteration 5643 : loss : 0.015073, loss_ce: 0.004944
2022-01-20 21:54:29,091 iteration 5644 : loss : 0.014142, loss_ce: 0.005629
 83%|████████████████████████     | 332/400 [1:00:53<12:15, 10.82s/it]2022-01-20 21:54:29,705 iteration 5645 : loss : 0.016698, loss_ce: 0.005455
2022-01-20 21:54:30,300 iteration 5646 : loss : 0.011113, loss_ce: 0.003735
2022-01-20 21:54:30,941 iteration 5647 : loss : 0.016354, loss_ce: 0.004984
2022-01-20 21:54:31,556 iteration 5648 : loss : 0.015017, loss_ce: 0.004207
2022-01-20 21:54:32,149 iteration 5649 : loss : 0.014595, loss_ce: 0.005657
2022-01-20 21:54:32,795 iteration 5650 : loss : 0.018009, loss_ce: 0.005250
2022-01-20 21:54:33,386 iteration 5651 : loss : 0.012968, loss_ce: 0.006173
2022-01-20 21:54:33,954 iteration 5652 : loss : 0.015534, loss_ce: 0.006350
2022-01-20 21:54:34,529 iteration 5653 : loss : 0.024026, loss_ce: 0.009818
2022-01-20 21:54:35,194 iteration 5654 : loss : 0.013259, loss_ce: 0.005101
2022-01-20 21:54:35,773 iteration 5655 : loss : 0.015662, loss_ce: 0.005986
2022-01-20 21:54:36,390 iteration 5656 : loss : 0.018284, loss_ce: 0.007442
2022-01-20 21:54:36,963 iteration 5657 : loss : 0.017194, loss_ce: 0.008823
2022-01-20 21:54:37,614 iteration 5658 : loss : 0.019367, loss_ce: 0.005454
2022-01-20 21:54:38,297 iteration 5659 : loss : 0.013504, loss_ce: 0.006512
2022-01-20 21:54:38,802 iteration 5660 : loss : 0.011887, loss_ce: 0.004426
2022-01-20 21:54:39,431 iteration 5661 : loss : 0.017654, loss_ce: 0.006802
 83%|████████████████████████▏    | 333/400 [1:01:04<11:55, 10.67s/it]2022-01-20 21:54:40,023 iteration 5662 : loss : 0.014804, loss_ce: 0.006242
2022-01-20 21:54:40,663 iteration 5663 : loss : 0.015117, loss_ce: 0.006615
2022-01-20 21:54:41,317 iteration 5664 : loss : 0.017323, loss_ce: 0.006011
2022-01-20 21:54:41,894 iteration 5665 : loss : 0.013882, loss_ce: 0.003019
2022-01-20 21:54:42,567 iteration 5666 : loss : 0.015232, loss_ce: 0.005543
2022-01-20 21:54:43,192 iteration 5667 : loss : 0.013496, loss_ce: 0.004097
2022-01-20 21:54:43,813 iteration 5668 : loss : 0.017147, loss_ce: 0.005336
2022-01-20 21:54:44,494 iteration 5669 : loss : 0.018517, loss_ce: 0.009548
2022-01-20 21:54:45,111 iteration 5670 : loss : 0.017822, loss_ce: 0.005645
2022-01-20 21:54:45,781 iteration 5671 : loss : 0.020095, loss_ce: 0.005047
2022-01-20 21:54:46,294 iteration 5672 : loss : 0.015027, loss_ce: 0.004114
2022-01-20 21:54:46,878 iteration 5673 : loss : 0.016866, loss_ce: 0.008080
2022-01-20 21:54:47,418 iteration 5674 : loss : 0.016558, loss_ce: 0.005664
2022-01-20 21:54:48,136 iteration 5675 : loss : 0.022965, loss_ce: 0.007984
2022-01-20 21:54:48,730 iteration 5676 : loss : 0.018850, loss_ce: 0.010045
2022-01-20 21:54:49,296 iteration 5677 : loss : 0.014520, loss_ce: 0.005378
2022-01-20 21:54:49,884 iteration 5678 : loss : 0.020151, loss_ce: 0.009050
 84%|████████████████████████▏    | 334/400 [1:01:14<11:40, 10.61s/it]2022-01-20 21:54:50,552 iteration 5679 : loss : 0.019205, loss_ce: 0.006396
2022-01-20 21:54:51,146 iteration 5680 : loss : 0.013792, loss_ce: 0.006159
2022-01-20 21:54:51,781 iteration 5681 : loss : 0.015446, loss_ce: 0.004352
2022-01-20 21:54:52,302 iteration 5682 : loss : 0.011874, loss_ce: 0.003958
2022-01-20 21:54:52,811 iteration 5683 : loss : 0.010897, loss_ce: 0.004639
2022-01-20 21:54:53,458 iteration 5684 : loss : 0.015767, loss_ce: 0.008037
2022-01-20 21:54:54,071 iteration 5685 : loss : 0.018600, loss_ce: 0.006255
2022-01-20 21:54:54,666 iteration 5686 : loss : 0.012412, loss_ce: 0.004490
2022-01-20 21:54:55,293 iteration 5687 : loss : 0.012255, loss_ce: 0.003896
2022-01-20 21:54:55,953 iteration 5688 : loss : 0.020766, loss_ce: 0.008327
2022-01-20 21:54:56,523 iteration 5689 : loss : 0.013947, loss_ce: 0.006035
2022-01-20 21:54:57,056 iteration 5690 : loss : 0.013352, loss_ce: 0.004483
2022-01-20 21:54:57,675 iteration 5691 : loss : 0.012535, loss_ce: 0.005122
2022-01-20 21:54:58,264 iteration 5692 : loss : 0.011209, loss_ce: 0.003594
2022-01-20 21:54:58,735 iteration 5693 : loss : 0.012461, loss_ce: 0.005166
2022-01-20 21:54:59,348 iteration 5694 : loss : 0.016241, loss_ce: 0.006906
2022-01-20 21:54:59,349 Training Data Eval:
2022-01-20 21:55:02,037   Average segmentation loss on training set: 0.0092
2022-01-20 21:55:02,038 Validation Data Eval:
2022-01-20 21:55:02,909   Average segmentation loss on validation set: 0.0842
2022-01-20 21:55:03,487 iteration 5695 : loss : 0.015991, loss_ce: 0.006452
 84%|████████████████████████▎    | 335/400 [1:01:28<12:27, 11.51s/it]2022-01-20 21:55:04,134 iteration 5696 : loss : 0.017154, loss_ce: 0.005381
2022-01-20 21:55:04,682 iteration 5697 : loss : 0.012678, loss_ce: 0.003652
2022-01-20 21:55:05,332 iteration 5698 : loss : 0.024379, loss_ce: 0.009135
2022-01-20 21:55:05,995 iteration 5699 : loss : 0.021421, loss_ce: 0.005817
2022-01-20 21:55:06,502 iteration 5700 : loss : 0.012804, loss_ce: 0.005561
2022-01-20 21:55:07,196 iteration 5701 : loss : 0.021586, loss_ce: 0.004246
2022-01-20 21:55:07,821 iteration 5702 : loss : 0.016718, loss_ce: 0.006281
2022-01-20 21:55:08,494 iteration 5703 : loss : 0.018980, loss_ce: 0.008851
2022-01-20 21:55:09,057 iteration 5704 : loss : 0.014234, loss_ce: 0.006432
2022-01-20 21:55:09,619 iteration 5705 : loss : 0.015810, loss_ce: 0.007020
2022-01-20 21:55:10,166 iteration 5706 : loss : 0.014021, loss_ce: 0.005167
2022-01-20 21:55:10,792 iteration 5707 : loss : 0.025577, loss_ce: 0.007007
2022-01-20 21:55:11,387 iteration 5708 : loss : 0.016017, loss_ce: 0.008214
2022-01-20 21:55:11,934 iteration 5709 : loss : 0.014433, loss_ce: 0.005851
2022-01-20 21:55:12,510 iteration 5710 : loss : 0.018790, loss_ce: 0.010244
2022-01-20 21:55:13,115 iteration 5711 : loss : 0.011524, loss_ce: 0.005566
2022-01-20 21:55:13,718 iteration 5712 : loss : 0.016730, loss_ce: 0.007699
 84%|████████████████████████▎    | 336/400 [1:01:38<11:52, 11.13s/it]2022-01-20 21:55:14,378 iteration 5713 : loss : 0.012992, loss_ce: 0.006274
2022-01-20 21:55:15,009 iteration 5714 : loss : 0.015173, loss_ce: 0.004689
2022-01-20 21:55:15,554 iteration 5715 : loss : 0.013163, loss_ce: 0.005046
2022-01-20 21:55:16,190 iteration 5716 : loss : 0.016453, loss_ce: 0.005799
2022-01-20 21:55:16,716 iteration 5717 : loss : 0.013138, loss_ce: 0.005655
2022-01-20 21:55:17,260 iteration 5718 : loss : 0.017007, loss_ce: 0.008214
2022-01-20 21:55:17,890 iteration 5719 : loss : 0.017847, loss_ce: 0.004543
2022-01-20 21:55:18,546 iteration 5720 : loss : 0.024128, loss_ce: 0.010076
2022-01-20 21:55:19,086 iteration 5721 : loss : 0.014902, loss_ce: 0.004375
2022-01-20 21:55:19,717 iteration 5722 : loss : 0.016717, loss_ce: 0.006108
2022-01-20 21:55:20,376 iteration 5723 : loss : 0.022011, loss_ce: 0.008670
2022-01-20 21:55:20,991 iteration 5724 : loss : 0.014466, loss_ce: 0.005978
2022-01-20 21:55:21,562 iteration 5725 : loss : 0.015350, loss_ce: 0.006035
2022-01-20 21:55:22,189 iteration 5726 : loss : 0.012311, loss_ce: 0.005074
2022-01-20 21:55:22,801 iteration 5727 : loss : 0.018370, loss_ce: 0.008637
2022-01-20 21:55:23,357 iteration 5728 : loss : 0.015392, loss_ce: 0.005479
2022-01-20 21:55:23,876 iteration 5729 : loss : 0.019572, loss_ce: 0.005618
 84%|████████████████████████▍    | 337/400 [1:01:48<11:22, 10.83s/it]2022-01-20 21:55:24,605 iteration 5730 : loss : 0.019048, loss_ce: 0.007091
2022-01-20 21:55:25,272 iteration 5731 : loss : 0.020379, loss_ce: 0.007439
2022-01-20 21:55:25,912 iteration 5732 : loss : 0.021869, loss_ce: 0.005261
2022-01-20 21:55:26,512 iteration 5733 : loss : 0.016742, loss_ce: 0.006365
2022-01-20 21:55:27,081 iteration 5734 : loss : 0.010779, loss_ce: 0.003841
2022-01-20 21:55:27,779 iteration 5735 : loss : 0.025279, loss_ce: 0.008238
2022-01-20 21:55:28,449 iteration 5736 : loss : 0.017792, loss_ce: 0.007709
2022-01-20 21:55:29,051 iteration 5737 : loss : 0.015459, loss_ce: 0.005468
2022-01-20 21:55:29,621 iteration 5738 : loss : 0.012775, loss_ce: 0.005612
2022-01-20 21:55:30,241 iteration 5739 : loss : 0.014285, loss_ce: 0.004112
2022-01-20 21:55:30,895 iteration 5740 : loss : 0.019025, loss_ce: 0.007812
2022-01-20 21:55:31,501 iteration 5741 : loss : 0.012568, loss_ce: 0.005159
2022-01-20 21:55:32,067 iteration 5742 : loss : 0.019879, loss_ce: 0.004189
2022-01-20 21:55:32,672 iteration 5743 : loss : 0.020943, loss_ce: 0.006802
2022-01-20 21:55:33,230 iteration 5744 : loss : 0.014307, loss_ce: 0.005959
2022-01-20 21:55:33,839 iteration 5745 : loss : 0.012956, loss_ce: 0.004156
2022-01-20 21:55:34,400 iteration 5746 : loss : 0.017476, loss_ce: 0.008453
 84%|████████████████████████▌    | 338/400 [1:01:59<11:06, 10.74s/it]2022-01-20 21:55:35,075 iteration 5747 : loss : 0.019285, loss_ce: 0.006604
2022-01-20 21:55:35,643 iteration 5748 : loss : 0.020442, loss_ce: 0.007719
2022-01-20 21:55:36,290 iteration 5749 : loss : 0.020217, loss_ce: 0.009107
2022-01-20 21:55:36,906 iteration 5750 : loss : 0.016124, loss_ce: 0.004228
2022-01-20 21:55:37,573 iteration 5751 : loss : 0.019973, loss_ce: 0.008296
2022-01-20 21:55:38,191 iteration 5752 : loss : 0.020443, loss_ce: 0.008508
2022-01-20 21:55:38,838 iteration 5753 : loss : 0.017951, loss_ce: 0.008249
2022-01-20 21:55:39,432 iteration 5754 : loss : 0.014591, loss_ce: 0.004988
2022-01-20 21:55:40,010 iteration 5755 : loss : 0.017208, loss_ce: 0.005436
2022-01-20 21:55:40,573 iteration 5756 : loss : 0.016035, loss_ce: 0.008157
2022-01-20 21:55:41,182 iteration 5757 : loss : 0.019680, loss_ce: 0.006401
2022-01-20 21:55:41,712 iteration 5758 : loss : 0.009236, loss_ce: 0.002778
2022-01-20 21:55:42,365 iteration 5759 : loss : 0.017664, loss_ce: 0.004587
2022-01-20 21:55:42,950 iteration 5760 : loss : 0.014985, loss_ce: 0.005560
2022-01-20 21:55:43,573 iteration 5761 : loss : 0.012899, loss_ce: 0.004394
2022-01-20 21:55:44,236 iteration 5762 : loss : 0.017802, loss_ce: 0.007758
2022-01-20 21:55:44,861 iteration 5763 : loss : 0.016042, loss_ce: 0.006141
 85%|████████████████████████▌    | 339/400 [1:02:09<10:50, 10.66s/it]2022-01-20 21:55:45,563 iteration 5764 : loss : 0.016270, loss_ce: 0.007992
2022-01-20 21:55:46,175 iteration 5765 : loss : 0.028629, loss_ce: 0.009267
2022-01-20 21:55:46,740 iteration 5766 : loss : 0.014900, loss_ce: 0.005379
2022-01-20 21:55:47,380 iteration 5767 : loss : 0.021059, loss_ce: 0.009984
2022-01-20 21:55:48,023 iteration 5768 : loss : 0.023570, loss_ce: 0.008219
2022-01-20 21:55:48,650 iteration 5769 : loss : 0.014471, loss_ce: 0.004317
2022-01-20 21:55:49,284 iteration 5770 : loss : 0.018979, loss_ce: 0.007337
2022-01-20 21:55:49,807 iteration 5771 : loss : 0.012218, loss_ce: 0.005282
2022-01-20 21:55:50,422 iteration 5772 : loss : 0.013792, loss_ce: 0.004588
2022-01-20 21:55:50,952 iteration 5773 : loss : 0.012941, loss_ce: 0.004561
2022-01-20 21:55:51,501 iteration 5774 : loss : 0.012477, loss_ce: 0.004845
2022-01-20 21:55:52,114 iteration 5775 : loss : 0.019384, loss_ce: 0.008506
2022-01-20 21:55:52,604 iteration 5776 : loss : 0.015123, loss_ce: 0.006017
2022-01-20 21:55:53,169 iteration 5777 : loss : 0.014634, loss_ce: 0.005619
2022-01-20 21:55:53,788 iteration 5778 : loss : 0.014085, loss_ce: 0.005125
2022-01-20 21:55:54,394 iteration 5779 : loss : 0.011078, loss_ce: 0.004787
2022-01-20 21:55:54,394 Training Data Eval:
2022-01-20 21:55:57,082   Average segmentation loss on training set: 0.0091
2022-01-20 21:55:57,083 Validation Data Eval:
2022-01-20 21:55:57,963   Average segmentation loss on validation set: 0.1046
2022-01-20 21:55:58,539 iteration 5780 : loss : 0.013905, loss_ce: 0.005371
 85%|████████████████████████▋    | 340/400 [1:02:23<11:33, 11.56s/it]2022-01-20 21:55:59,176 iteration 5781 : loss : 0.022711, loss_ce: 0.008670
2022-01-20 21:55:59,682 iteration 5782 : loss : 0.010272, loss_ce: 0.003751
2022-01-20 21:56:00,290 iteration 5783 : loss : 0.016254, loss_ce: 0.004993
2022-01-20 21:56:00,912 iteration 5784 : loss : 0.014927, loss_ce: 0.004593
2022-01-20 21:56:01,518 iteration 5785 : loss : 0.015043, loss_ce: 0.007299
2022-01-20 21:56:02,173 iteration 5786 : loss : 0.013538, loss_ce: 0.005440
2022-01-20 21:56:02,765 iteration 5787 : loss : 0.018238, loss_ce: 0.005953
2022-01-20 21:56:03,371 iteration 5788 : loss : 0.013476, loss_ce: 0.005138
2022-01-20 21:56:03,970 iteration 5789 : loss : 0.022107, loss_ce: 0.006906
2022-01-20 21:56:04,597 iteration 5790 : loss : 0.020757, loss_ce: 0.009335
2022-01-20 21:56:05,235 iteration 5791 : loss : 0.013145, loss_ce: 0.004650
2022-01-20 21:56:05,905 iteration 5792 : loss : 0.015824, loss_ce: 0.004631
2022-01-20 21:56:06,462 iteration 5793 : loss : 0.014611, loss_ce: 0.006030
2022-01-20 21:56:07,014 iteration 5794 : loss : 0.019065, loss_ce: 0.006512
2022-01-20 21:56:07,586 iteration 5795 : loss : 0.017572, loss_ce: 0.009953
2022-01-20 21:56:08,160 iteration 5796 : loss : 0.013057, loss_ce: 0.004947
2022-01-20 21:56:08,722 iteration 5797 : loss : 0.012794, loss_ce: 0.004301
 85%|████████████████████████▋    | 341/400 [1:02:33<10:57, 11.15s/it]2022-01-20 21:56:09,307 iteration 5798 : loss : 0.015165, loss_ce: 0.004732
2022-01-20 21:56:09,864 iteration 5799 : loss : 0.014720, loss_ce: 0.005571
2022-01-20 21:56:10,352 iteration 5800 : loss : 0.009800, loss_ce: 0.003854
2022-01-20 21:56:10,947 iteration 5801 : loss : 0.015130, loss_ce: 0.006862
2022-01-20 21:56:11,487 iteration 5802 : loss : 0.011985, loss_ce: 0.004955
2022-01-20 21:56:12,117 iteration 5803 : loss : 0.015687, loss_ce: 0.005301
2022-01-20 21:56:12,664 iteration 5804 : loss : 0.016898, loss_ce: 0.006163
2022-01-20 21:56:13,201 iteration 5805 : loss : 0.012592, loss_ce: 0.004206
2022-01-20 21:56:13,724 iteration 5806 : loss : 0.011913, loss_ce: 0.005378
2022-01-20 21:56:14,332 iteration 5807 : loss : 0.017378, loss_ce: 0.006360
2022-01-20 21:56:14,967 iteration 5808 : loss : 0.040024, loss_ce: 0.014050
2022-01-20 21:56:15,603 iteration 5809 : loss : 0.018803, loss_ce: 0.007366
2022-01-20 21:56:16,280 iteration 5810 : loss : 0.022509, loss_ce: 0.006620
2022-01-20 21:56:16,919 iteration 5811 : loss : 0.016078, loss_ce: 0.006365
2022-01-20 21:56:17,487 iteration 5812 : loss : 0.016228, loss_ce: 0.006858
2022-01-20 21:56:18,036 iteration 5813 : loss : 0.018779, loss_ce: 0.008478
2022-01-20 21:56:18,599 iteration 5814 : loss : 0.024252, loss_ce: 0.008198
 86%|████████████████████████▊    | 342/400 [1:02:43<10:24, 10.77s/it]2022-01-20 21:56:19,286 iteration 5815 : loss : 0.016967, loss_ce: 0.006130
2022-01-20 21:56:19,865 iteration 5816 : loss : 0.014731, loss_ce: 0.005793
2022-01-20 21:56:20,531 iteration 5817 : loss : 0.026845, loss_ce: 0.013164
2022-01-20 21:56:21,162 iteration 5818 : loss : 0.018217, loss_ce: 0.007085
2022-01-20 21:56:21,738 iteration 5819 : loss : 0.011480, loss_ce: 0.003257
2022-01-20 21:56:22,301 iteration 5820 : loss : 0.015548, loss_ce: 0.005689
2022-01-20 21:56:22,919 iteration 5821 : loss : 0.019024, loss_ce: 0.010312
2022-01-20 21:56:23,598 iteration 5822 : loss : 0.020194, loss_ce: 0.006561
2022-01-20 21:56:24,142 iteration 5823 : loss : 0.013279, loss_ce: 0.006193
2022-01-20 21:56:24,817 iteration 5824 : loss : 0.022453, loss_ce: 0.005351
2022-01-20 21:56:25,423 iteration 5825 : loss : 0.012620, loss_ce: 0.004738
2022-01-20 21:56:26,027 iteration 5826 : loss : 0.017700, loss_ce: 0.007673
2022-01-20 21:56:26,564 iteration 5827 : loss : 0.013701, loss_ce: 0.005597
2022-01-20 21:56:27,236 iteration 5828 : loss : 0.022649, loss_ce: 0.004561
2022-01-20 21:56:27,829 iteration 5829 : loss : 0.017140, loss_ce: 0.006705
2022-01-20 21:56:28,376 iteration 5830 : loss : 0.015594, loss_ce: 0.005214
2022-01-20 21:56:29,042 iteration 5831 : loss : 0.021549, loss_ce: 0.008689
 86%|████████████████████████▊    | 343/400 [1:02:53<10:08, 10.67s/it]2022-01-20 21:56:29,718 iteration 5832 : loss : 0.032597, loss_ce: 0.016094
2022-01-20 21:56:30,377 iteration 5833 : loss : 0.024709, loss_ce: 0.011377
2022-01-20 21:56:30,968 iteration 5834 : loss : 0.020126, loss_ce: 0.011006
2022-01-20 21:56:31,558 iteration 5835 : loss : 0.018833, loss_ce: 0.007943
2022-01-20 21:56:32,138 iteration 5836 : loss : 0.063259, loss_ce: 0.030522
2022-01-20 21:56:32,804 iteration 5837 : loss : 0.019042, loss_ce: 0.006874
2022-01-20 21:56:33,402 iteration 5838 : loss : 0.015969, loss_ce: 0.004554
2022-01-20 21:56:34,001 iteration 5839 : loss : 0.017779, loss_ce: 0.006795
2022-01-20 21:56:34,587 iteration 5840 : loss : 0.012055, loss_ce: 0.004258
2022-01-20 21:56:35,227 iteration 5841 : loss : 0.019721, loss_ce: 0.008002
2022-01-20 21:56:35,767 iteration 5842 : loss : 0.016432, loss_ce: 0.005656
2022-01-20 21:56:36,314 iteration 5843 : loss : 0.013526, loss_ce: 0.004972
2022-01-20 21:56:36,917 iteration 5844 : loss : 0.019342, loss_ce: 0.007745
2022-01-20 21:56:37,457 iteration 5845 : loss : 0.013524, loss_ce: 0.005363
2022-01-20 21:56:37,994 iteration 5846 : loss : 0.011654, loss_ce: 0.005232
2022-01-20 21:56:38,545 iteration 5847 : loss : 0.012822, loss_ce: 0.004782
2022-01-20 21:56:39,107 iteration 5848 : loss : 0.014383, loss_ce: 0.005220
 86%|████████████████████████▉    | 344/400 [1:03:03<09:47, 10.49s/it]2022-01-20 21:56:39,747 iteration 5849 : loss : 0.015494, loss_ce: 0.005171
2022-01-20 21:56:40,412 iteration 5850 : loss : 0.015071, loss_ce: 0.006708
2022-01-20 21:56:41,051 iteration 5851 : loss : 0.012447, loss_ce: 0.003188
2022-01-20 21:56:41,668 iteration 5852 : loss : 0.016467, loss_ce: 0.007261
2022-01-20 21:56:42,221 iteration 5853 : loss : 0.016914, loss_ce: 0.005679
2022-01-20 21:56:42,863 iteration 5854 : loss : 0.018810, loss_ce: 0.008657
2022-01-20 21:56:43,452 iteration 5855 : loss : 0.013711, loss_ce: 0.006302
2022-01-20 21:56:44,045 iteration 5856 : loss : 0.017128, loss_ce: 0.006792
2022-01-20 21:56:44,669 iteration 5857 : loss : 0.016428, loss_ce: 0.006047
2022-01-20 21:56:45,305 iteration 5858 : loss : 0.013316, loss_ce: 0.003956
2022-01-20 21:56:45,997 iteration 5859 : loss : 0.023170, loss_ce: 0.007535
2022-01-20 21:56:46,614 iteration 5860 : loss : 0.013505, loss_ce: 0.004846
2022-01-20 21:56:47,186 iteration 5861 : loss : 0.016263, loss_ce: 0.006735
2022-01-20 21:56:47,790 iteration 5862 : loss : 0.017738, loss_ce: 0.007199
2022-01-20 21:56:48,391 iteration 5863 : loss : 0.022958, loss_ce: 0.006822
2022-01-20 21:56:49,073 iteration 5864 : loss : 0.017017, loss_ce: 0.007381
2022-01-20 21:56:49,074 Training Data Eval:
2022-01-20 21:56:51,766   Average segmentation loss on training set: 0.0095
2022-01-20 21:56:51,766 Validation Data Eval:
2022-01-20 21:56:52,644   Average segmentation loss on validation set: 0.0865
2022-01-20 21:56:53,336 iteration 5865 : loss : 0.023124, loss_ce: 0.007106
 86%|█████████████████████████    | 345/400 [1:03:18<10:38, 11.61s/it]2022-01-20 21:56:53,926 iteration 5866 : loss : 0.014646, loss_ce: 0.003938
2022-01-20 21:56:54,490 iteration 5867 : loss : 0.012609, loss_ce: 0.005139
2022-01-20 21:56:55,094 iteration 5868 : loss : 0.013997, loss_ce: 0.005201
2022-01-20 21:56:55,657 iteration 5869 : loss : 0.014740, loss_ce: 0.004498
2022-01-20 21:56:56,351 iteration 5870 : loss : 0.024044, loss_ce: 0.010831
2022-01-20 21:56:56,933 iteration 5871 : loss : 0.012949, loss_ce: 0.004970
2022-01-20 21:56:57,493 iteration 5872 : loss : 0.017782, loss_ce: 0.006061
2022-01-20 21:56:58,103 iteration 5873 : loss : 0.019002, loss_ce: 0.011622
2022-01-20 21:56:58,721 iteration 5874 : loss : 0.015564, loss_ce: 0.005656
2022-01-20 21:56:59,338 iteration 5875 : loss : 0.011377, loss_ce: 0.005294
2022-01-20 21:57:00,033 iteration 5876 : loss : 0.018790, loss_ce: 0.007204
2022-01-20 21:57:00,691 iteration 5877 : loss : 0.019692, loss_ce: 0.008942
2022-01-20 21:57:01,237 iteration 5878 : loss : 0.018463, loss_ce: 0.005993
2022-01-20 21:57:01,830 iteration 5879 : loss : 0.018196, loss_ce: 0.006348
2022-01-20 21:57:02,452 iteration 5880 : loss : 0.015844, loss_ce: 0.004239
2022-01-20 21:57:03,005 iteration 5881 : loss : 0.013229, loss_ce: 0.005389
2022-01-20 21:57:03,534 iteration 5882 : loss : 0.015091, loss_ce: 0.004874
 86%|█████████████████████████    | 346/400 [1:03:28<10:03, 11.18s/it]2022-01-20 21:57:04,126 iteration 5883 : loss : 0.012864, loss_ce: 0.003796
2022-01-20 21:57:04,627 iteration 5884 : loss : 0.011613, loss_ce: 0.004318
2022-01-20 21:57:05,273 iteration 5885 : loss : 0.015537, loss_ce: 0.004486
2022-01-20 21:57:05,850 iteration 5886 : loss : 0.017485, loss_ce: 0.005239
2022-01-20 21:57:06,485 iteration 5887 : loss : 0.014684, loss_ce: 0.005268
2022-01-20 21:57:07,076 iteration 5888 : loss : 0.010546, loss_ce: 0.004248
2022-01-20 21:57:07,740 iteration 5889 : loss : 0.012953, loss_ce: 0.004340
2022-01-20 21:57:08,327 iteration 5890 : loss : 0.013500, loss_ce: 0.005618
2022-01-20 21:57:08,928 iteration 5891 : loss : 0.019106, loss_ce: 0.005423
2022-01-20 21:57:09,555 iteration 5892 : loss : 0.016415, loss_ce: 0.004606
2022-01-20 21:57:10,129 iteration 5893 : loss : 0.014493, loss_ce: 0.007273
2022-01-20 21:57:10,661 iteration 5894 : loss : 0.014762, loss_ce: 0.006632
2022-01-20 21:57:11,191 iteration 5895 : loss : 0.011273, loss_ce: 0.004330
2022-01-20 21:57:11,732 iteration 5896 : loss : 0.016750, loss_ce: 0.006182
2022-01-20 21:57:12,322 iteration 5897 : loss : 0.013926, loss_ce: 0.006090
2022-01-20 21:57:12,875 iteration 5898 : loss : 0.016962, loss_ce: 0.005637
2022-01-20 21:57:13,513 iteration 5899 : loss : 0.016339, loss_ce: 0.006606
 87%|█████████████████████████▏   | 347/400 [1:03:38<09:33, 10.82s/it]2022-01-20 21:57:14,075 iteration 5900 : loss : 0.014495, loss_ce: 0.004870
2022-01-20 21:57:14,778 iteration 5901 : loss : 0.017439, loss_ce: 0.006345
2022-01-20 21:57:15,468 iteration 5902 : loss : 0.020103, loss_ce: 0.009570
2022-01-20 21:57:16,056 iteration 5903 : loss : 0.015124, loss_ce: 0.004815
2022-01-20 21:57:16,671 iteration 5904 : loss : 0.012723, loss_ce: 0.005247
2022-01-20 21:57:17,203 iteration 5905 : loss : 0.011849, loss_ce: 0.004366
2022-01-20 21:57:17,777 iteration 5906 : loss : 0.017274, loss_ce: 0.006477
2022-01-20 21:57:18,381 iteration 5907 : loss : 0.020699, loss_ce: 0.010953
2022-01-20 21:57:18,963 iteration 5908 : loss : 0.016119, loss_ce: 0.005872
2022-01-20 21:57:19,505 iteration 5909 : loss : 0.010626, loss_ce: 0.004270
2022-01-20 21:57:20,070 iteration 5910 : loss : 0.015419, loss_ce: 0.006423
2022-01-20 21:57:20,651 iteration 5911 : loss : 0.011498, loss_ce: 0.004361
2022-01-20 21:57:21,367 iteration 5912 : loss : 0.038595, loss_ce: 0.005887
2022-01-20 21:57:21,893 iteration 5913 : loss : 0.017254, loss_ce: 0.006233
2022-01-20 21:57:22,565 iteration 5914 : loss : 0.017327, loss_ce: 0.006283
2022-01-20 21:57:23,205 iteration 5915 : loss : 0.015720, loss_ce: 0.007706
2022-01-20 21:57:23,805 iteration 5916 : loss : 0.015791, loss_ce: 0.005969
 87%|█████████████████████████▏   | 348/400 [1:03:48<09:14, 10.66s/it]2022-01-20 21:57:24,428 iteration 5917 : loss : 0.018563, loss_ce: 0.004084
2022-01-20 21:57:25,115 iteration 5918 : loss : 0.021494, loss_ce: 0.009863
2022-01-20 21:57:25,670 iteration 5919 : loss : 0.014319, loss_ce: 0.008222
2022-01-20 21:57:26,373 iteration 5920 : loss : 0.017451, loss_ce: 0.007076
2022-01-20 21:57:26,956 iteration 5921 : loss : 0.015725, loss_ce: 0.004392
2022-01-20 21:57:27,586 iteration 5922 : loss : 0.018145, loss_ce: 0.009061
2022-01-20 21:57:28,160 iteration 5923 : loss : 0.016657, loss_ce: 0.004492
2022-01-20 21:57:28,704 iteration 5924 : loss : 0.012625, loss_ce: 0.005046
2022-01-20 21:57:29,272 iteration 5925 : loss : 0.015134, loss_ce: 0.004633
2022-01-20 21:57:29,852 iteration 5926 : loss : 0.011920, loss_ce: 0.004135
2022-01-20 21:57:30,520 iteration 5927 : loss : 0.020540, loss_ce: 0.007140
2022-01-20 21:57:31,028 iteration 5928 : loss : 0.013020, loss_ce: 0.005528
2022-01-20 21:57:31,571 iteration 5929 : loss : 0.016617, loss_ce: 0.004682
2022-01-20 21:57:32,168 iteration 5930 : loss : 0.015516, loss_ce: 0.005410
2022-01-20 21:57:32,765 iteration 5931 : loss : 0.017267, loss_ce: 0.007437
2022-01-20 21:57:33,335 iteration 5932 : loss : 0.016337, loss_ce: 0.006162
2022-01-20 21:57:33,881 iteration 5933 : loss : 0.011193, loss_ce: 0.004471
 87%|█████████████████████████▎   | 349/400 [1:03:58<08:54, 10.49s/it]2022-01-20 21:57:34,448 iteration 5934 : loss : 0.012347, loss_ce: 0.004333
2022-01-20 21:57:34,977 iteration 5935 : loss : 0.013902, loss_ce: 0.006836
2022-01-20 21:57:35,496 iteration 5936 : loss : 0.025294, loss_ce: 0.010455
2022-01-20 21:57:36,111 iteration 5937 : loss : 0.015901, loss_ce: 0.006588
2022-01-20 21:57:36,728 iteration 5938 : loss : 0.015053, loss_ce: 0.006734
2022-01-20 21:57:37,377 iteration 5939 : loss : 0.026921, loss_ce: 0.007915
2022-01-20 21:57:37,933 iteration 5940 : loss : 0.011950, loss_ce: 0.004148
2022-01-20 21:57:38,562 iteration 5941 : loss : 0.015677, loss_ce: 0.005637
2022-01-20 21:57:39,157 iteration 5942 : loss : 0.011463, loss_ce: 0.004620
2022-01-20 21:57:39,792 iteration 5943 : loss : 0.015012, loss_ce: 0.005346
2022-01-20 21:57:40,294 iteration 5944 : loss : 0.014819, loss_ce: 0.006314
2022-01-20 21:57:40,998 iteration 5945 : loss : 0.024585, loss_ce: 0.008548
2022-01-20 21:57:41,608 iteration 5946 : loss : 0.013676, loss_ce: 0.005487
2022-01-20 21:57:42,317 iteration 5947 : loss : 0.022829, loss_ce: 0.007124
2022-01-20 21:57:42,979 iteration 5948 : loss : 0.021814, loss_ce: 0.007263
2022-01-20 21:57:43,564 iteration 5949 : loss : 0.019508, loss_ce: 0.004806
2022-01-20 21:57:43,564 Training Data Eval:
2022-01-20 21:57:46,251   Average segmentation loss on training set: 0.0094
2022-01-20 21:57:46,251 Validation Data Eval:
2022-01-20 21:57:47,135   Average segmentation loss on validation set: 0.0919
2022-01-20 21:57:47,663 iteration 5950 : loss : 0.011020, loss_ce: 0.003690
 88%|█████████████████████████▍   | 350/400 [1:04:12<09:33, 11.48s/it]2022-01-20 21:57:48,224 iteration 5951 : loss : 0.016649, loss_ce: 0.005106
2022-01-20 21:57:48,821 iteration 5952 : loss : 0.017952, loss_ce: 0.008973
2022-01-20 21:57:49,513 iteration 5953 : loss : 0.019525, loss_ce: 0.009480
2022-01-20 21:57:50,077 iteration 5954 : loss : 0.020419, loss_ce: 0.005879
2022-01-20 21:57:50,784 iteration 5955 : loss : 0.022368, loss_ce: 0.009363
2022-01-20 21:57:51,352 iteration 5956 : loss : 0.023993, loss_ce: 0.005979
2022-01-20 21:57:51,986 iteration 5957 : loss : 0.018706, loss_ce: 0.008702
2022-01-20 21:57:52,630 iteration 5958 : loss : 0.019131, loss_ce: 0.008508
2022-01-20 21:57:53,261 iteration 5959 : loss : 0.016511, loss_ce: 0.003946
2022-01-20 21:57:53,828 iteration 5960 : loss : 0.015335, loss_ce: 0.004387
2022-01-20 21:57:54,465 iteration 5961 : loss : 0.020525, loss_ce: 0.011155
2022-01-20 21:57:55,093 iteration 5962 : loss : 0.017533, loss_ce: 0.007088
2022-01-20 21:57:55,656 iteration 5963 : loss : 0.013005, loss_ce: 0.005058
2022-01-20 21:57:56,314 iteration 5964 : loss : 0.022181, loss_ce: 0.010035
2022-01-20 21:57:56,939 iteration 5965 : loss : 0.015462, loss_ce: 0.008134
2022-01-20 21:57:57,514 iteration 5966 : loss : 0.011098, loss_ce: 0.003886
2022-01-20 21:57:58,194 iteration 5967 : loss : 0.015293, loss_ce: 0.005802
 88%|█████████████████████████▍   | 351/400 [1:04:23<09:08, 11.19s/it]2022-01-20 21:57:58,813 iteration 5968 : loss : 0.016940, loss_ce: 0.006682
2022-01-20 21:57:59,390 iteration 5969 : loss : 0.017890, loss_ce: 0.008741
2022-01-20 21:58:00,006 iteration 5970 : loss : 0.016831, loss_ce: 0.007397
2022-01-20 21:58:00,556 iteration 5971 : loss : 0.011462, loss_ce: 0.004782
2022-01-20 21:58:01,090 iteration 5972 : loss : 0.013441, loss_ce: 0.003803
2022-01-20 21:58:01,637 iteration 5973 : loss : 0.015639, loss_ce: 0.006798
2022-01-20 21:58:02,226 iteration 5974 : loss : 0.020038, loss_ce: 0.005491
2022-01-20 21:58:02,826 iteration 5975 : loss : 0.015850, loss_ce: 0.009334
2022-01-20 21:58:03,448 iteration 5976 : loss : 0.017077, loss_ce: 0.005810
2022-01-20 21:58:03,992 iteration 5977 : loss : 0.012483, loss_ce: 0.004126
2022-01-20 21:58:04,563 iteration 5978 : loss : 0.014578, loss_ce: 0.005095
2022-01-20 21:58:05,149 iteration 5979 : loss : 0.014767, loss_ce: 0.003996
2022-01-20 21:58:05,803 iteration 5980 : loss : 0.017198, loss_ce: 0.004102
2022-01-20 21:58:06,469 iteration 5981 : loss : 0.024385, loss_ce: 0.010072
2022-01-20 21:58:07,072 iteration 5982 : loss : 0.020701, loss_ce: 0.009912
2022-01-20 21:58:07,676 iteration 5983 : loss : 0.025064, loss_ce: 0.005661
2022-01-20 21:58:08,336 iteration 5984 : loss : 0.016292, loss_ce: 0.005602
 88%|█████████████████████████▌   | 352/400 [1:04:33<08:42, 10.88s/it]2022-01-20 21:58:09,017 iteration 5985 : loss : 0.020734, loss_ce: 0.007483
2022-01-20 21:58:09,517 iteration 5986 : loss : 0.010947, loss_ce: 0.005244
2022-01-20 21:58:10,160 iteration 5987 : loss : 0.028659, loss_ce: 0.008891
2022-01-20 21:58:10,685 iteration 5988 : loss : 0.013027, loss_ce: 0.005385
2022-01-20 21:58:11,288 iteration 5989 : loss : 0.015382, loss_ce: 0.005834
2022-01-20 21:58:11,861 iteration 5990 : loss : 0.016135, loss_ce: 0.005378
2022-01-20 21:58:12,521 iteration 5991 : loss : 0.018002, loss_ce: 0.004988
2022-01-20 21:58:13,168 iteration 5992 : loss : 0.022883, loss_ce: 0.005699
2022-01-20 21:58:13,744 iteration 5993 : loss : 0.018226, loss_ce: 0.007379
2022-01-20 21:58:14,255 iteration 5994 : loss : 0.011939, loss_ce: 0.005393
2022-01-20 21:58:14,929 iteration 5995 : loss : 0.015806, loss_ce: 0.005065
2022-01-20 21:58:15,556 iteration 5996 : loss : 0.011785, loss_ce: 0.006043
2022-01-20 21:58:16,107 iteration 5997 : loss : 0.014731, loss_ce: 0.004357
2022-01-20 21:58:16,817 iteration 5998 : loss : 0.021855, loss_ce: 0.007905
2022-01-20 21:58:17,388 iteration 5999 : loss : 0.017369, loss_ce: 0.006064
2022-01-20 21:58:18,099 iteration 6000 : loss : 0.021190, loss_ce: 0.008496
2022-01-20 21:58:18,638 iteration 6001 : loss : 0.010973, loss_ce: 0.004059
 88%|█████████████████████████▌   | 353/400 [1:04:43<08:23, 10.70s/it]2022-01-20 21:58:19,213 iteration 6002 : loss : 0.016428, loss_ce: 0.005874
2022-01-20 21:58:19,833 iteration 6003 : loss : 0.013864, loss_ce: 0.006197
2022-01-20 21:58:20,407 iteration 6004 : loss : 0.013996, loss_ce: 0.005349
2022-01-20 21:58:20,972 iteration 6005 : loss : 0.015767, loss_ce: 0.005909
2022-01-20 21:58:21,622 iteration 6006 : loss : 0.015477, loss_ce: 0.004721
2022-01-20 21:58:22,175 iteration 6007 : loss : 0.013698, loss_ce: 0.005078
2022-01-20 21:58:22,752 iteration 6008 : loss : 0.015302, loss_ce: 0.005565
2022-01-20 21:58:23,381 iteration 6009 : loss : 0.014723, loss_ce: 0.004492
2022-01-20 21:58:23,921 iteration 6010 : loss : 0.015036, loss_ce: 0.003718
2022-01-20 21:58:24,545 iteration 6011 : loss : 0.020028, loss_ce: 0.007248
2022-01-20 21:58:25,197 iteration 6012 : loss : 0.018991, loss_ce: 0.007701
2022-01-20 21:58:25,772 iteration 6013 : loss : 0.014885, loss_ce: 0.005004
2022-01-20 21:58:26,317 iteration 6014 : loss : 0.013822, loss_ce: 0.005143
2022-01-20 21:58:26,826 iteration 6015 : loss : 0.011586, loss_ce: 0.005672
2022-01-20 21:58:27,394 iteration 6016 : loss : 0.011201, loss_ce: 0.003205
2022-01-20 21:58:27,997 iteration 6017 : loss : 0.015890, loss_ce: 0.006466
2022-01-20 21:58:28,508 iteration 6018 : loss : 0.015212, loss_ce: 0.005884
 88%|█████████████████████████▋   | 354/400 [1:04:53<08:00, 10.45s/it]2022-01-20 21:58:29,191 iteration 6019 : loss : 0.014672, loss_ce: 0.005608
2022-01-20 21:58:29,798 iteration 6020 : loss : 0.015526, loss_ce: 0.005344
2022-01-20 21:58:30,342 iteration 6021 : loss : 0.010882, loss_ce: 0.003957
2022-01-20 21:58:30,962 iteration 6022 : loss : 0.014182, loss_ce: 0.005325
2022-01-20 21:58:31,591 iteration 6023 : loss : 0.017313, loss_ce: 0.007073
2022-01-20 21:58:32,185 iteration 6024 : loss : 0.011779, loss_ce: 0.004631
2022-01-20 21:58:32,719 iteration 6025 : loss : 0.017692, loss_ce: 0.004146
2022-01-20 21:58:33,279 iteration 6026 : loss : 0.015680, loss_ce: 0.005763
2022-01-20 21:58:33,913 iteration 6027 : loss : 0.011200, loss_ce: 0.004715
2022-01-20 21:58:34,459 iteration 6028 : loss : 0.013191, loss_ce: 0.005778
2022-01-20 21:58:35,055 iteration 6029 : loss : 0.017649, loss_ce: 0.007586
2022-01-20 21:58:35,704 iteration 6030 : loss : 0.020237, loss_ce: 0.007965
2022-01-20 21:58:36,339 iteration 6031 : loss : 0.021924, loss_ce: 0.006527
2022-01-20 21:58:36,940 iteration 6032 : loss : 0.024252, loss_ce: 0.007287
2022-01-20 21:58:37,525 iteration 6033 : loss : 0.019493, loss_ce: 0.006693
2022-01-20 21:58:38,071 iteration 6034 : loss : 0.010589, loss_ce: 0.004065
2022-01-20 21:58:38,072 Training Data Eval:
2022-01-20 21:58:40,759   Average segmentation loss on training set: 0.0088
2022-01-20 21:58:40,759 Validation Data Eval:
2022-01-20 21:58:41,642   Average segmentation loss on validation set: 0.0867
2022-01-20 21:58:42,176 iteration 6035 : loss : 0.022268, loss_ce: 0.008375
 89%|█████████████████████████▋   | 355/400 [1:05:07<08:33, 11.42s/it]2022-01-20 21:58:42,815 iteration 6036 : loss : 0.012377, loss_ce: 0.005693
2022-01-20 21:58:43,346 iteration 6037 : loss : 0.010364, loss_ce: 0.004103
2022-01-20 21:58:43,896 iteration 6038 : loss : 0.012657, loss_ce: 0.004667
2022-01-20 21:58:44,387 iteration 6039 : loss : 0.011552, loss_ce: 0.003925
2022-01-20 21:58:44,941 iteration 6040 : loss : 0.022842, loss_ce: 0.005910
2022-01-20 21:58:45,578 iteration 6041 : loss : 0.017291, loss_ce: 0.006983
2022-01-20 21:58:46,115 iteration 6042 : loss : 0.016916, loss_ce: 0.004137
2022-01-20 21:58:46,618 iteration 6043 : loss : 0.012994, loss_ce: 0.004234
2022-01-20 21:58:47,227 iteration 6044 : loss : 0.014742, loss_ce: 0.004341
2022-01-20 21:58:47,777 iteration 6045 : loss : 0.012968, loss_ce: 0.005462
2022-01-20 21:58:48,358 iteration 6046 : loss : 0.018205, loss_ce: 0.007936
2022-01-20 21:58:48,915 iteration 6047 : loss : 0.011585, loss_ce: 0.004351
2022-01-20 21:58:49,534 iteration 6048 : loss : 0.020219, loss_ce: 0.008636
2022-01-20 21:58:50,112 iteration 6049 : loss : 0.012925, loss_ce: 0.006231
2022-01-20 21:58:50,700 iteration 6050 : loss : 0.013178, loss_ce: 0.004594
2022-01-20 21:58:51,411 iteration 6051 : loss : 0.013859, loss_ce: 0.004556
2022-01-20 21:58:51,988 iteration 6052 : loss : 0.014417, loss_ce: 0.006168
 89%|█████████████████████████▊   | 356/400 [1:05:16<08:01, 10.94s/it]2022-01-20 21:58:52,580 iteration 6053 : loss : 0.020561, loss_ce: 0.006380
2022-01-20 21:58:53,104 iteration 6054 : loss : 0.013913, loss_ce: 0.006966
2022-01-20 21:58:53,738 iteration 6055 : loss : 0.014667, loss_ce: 0.004791
2022-01-20 21:58:54,308 iteration 6056 : loss : 0.012588, loss_ce: 0.005353
2022-01-20 21:58:54,850 iteration 6057 : loss : 0.012776, loss_ce: 0.003742
2022-01-20 21:58:55,452 iteration 6058 : loss : 0.016764, loss_ce: 0.005261
2022-01-20 21:58:56,092 iteration 6059 : loss : 0.017017, loss_ce: 0.008688
2022-01-20 21:58:56,824 iteration 6060 : loss : 0.059767, loss_ce: 0.023796
2022-01-20 21:58:57,417 iteration 6061 : loss : 0.015424, loss_ce: 0.006033
2022-01-20 21:58:58,086 iteration 6062 : loss : 0.020851, loss_ce: 0.006937
2022-01-20 21:58:58,635 iteration 6063 : loss : 0.020035, loss_ce: 0.006821
2022-01-20 21:58:59,290 iteration 6064 : loss : 0.015654, loss_ce: 0.006895
2022-01-20 21:58:59,825 iteration 6065 : loss : 0.010516, loss_ce: 0.004213
2022-01-20 21:59:00,369 iteration 6066 : loss : 0.009843, loss_ce: 0.002999
2022-01-20 21:59:00,949 iteration 6067 : loss : 0.014081, loss_ce: 0.006431
2022-01-20 21:59:01,498 iteration 6068 : loss : 0.011438, loss_ce: 0.003250
2022-01-20 21:59:02,067 iteration 6069 : loss : 0.025884, loss_ce: 0.012636
 89%|█████████████████████████▉   | 357/400 [1:05:26<07:39, 10.68s/it]2022-01-20 21:59:02,698 iteration 6070 : loss : 0.010259, loss_ce: 0.005167
2022-01-20 21:59:03,234 iteration 6071 : loss : 0.013306, loss_ce: 0.004406
2022-01-20 21:59:03,789 iteration 6072 : loss : 0.013462, loss_ce: 0.006602
2022-01-20 21:59:04,377 iteration 6073 : loss : 0.015211, loss_ce: 0.005593
2022-01-20 21:59:04,992 iteration 6074 : loss : 0.013685, loss_ce: 0.005284
2022-01-20 21:59:05,494 iteration 6075 : loss : 0.011367, loss_ce: 0.004858
2022-01-20 21:59:06,067 iteration 6076 : loss : 0.016648, loss_ce: 0.004268
2022-01-20 21:59:06,673 iteration 6077 : loss : 0.021381, loss_ce: 0.008524
2022-01-20 21:59:07,330 iteration 6078 : loss : 0.015960, loss_ce: 0.005413
2022-01-20 21:59:08,041 iteration 6079 : loss : 0.017229, loss_ce: 0.006705
2022-01-20 21:59:08,646 iteration 6080 : loss : 0.017544, loss_ce: 0.006378
2022-01-20 21:59:09,277 iteration 6081 : loss : 0.017970, loss_ce: 0.006869
2022-01-20 21:59:09,789 iteration 6082 : loss : 0.016171, loss_ce: 0.004925
2022-01-20 21:59:10,332 iteration 6083 : loss : 0.016411, loss_ce: 0.004453
2022-01-20 21:59:10,921 iteration 6084 : loss : 0.020001, loss_ce: 0.004839
2022-01-20 21:59:11,494 iteration 6085 : loss : 0.022447, loss_ce: 0.006764
2022-01-20 21:59:12,056 iteration 6086 : loss : 0.012210, loss_ce: 0.003844
 90%|█████████████████████████▉   | 358/400 [1:05:36<07:19, 10.47s/it]2022-01-20 21:59:12,626 iteration 6087 : loss : 0.016687, loss_ce: 0.005026
2022-01-20 21:59:13,255 iteration 6088 : loss : 0.013176, loss_ce: 0.005002
2022-01-20 21:59:13,832 iteration 6089 : loss : 0.019360, loss_ce: 0.005625
2022-01-20 21:59:14,314 iteration 6090 : loss : 0.012695, loss_ce: 0.005501
2022-01-20 21:59:14,914 iteration 6091 : loss : 0.011496, loss_ce: 0.003847
2022-01-20 21:59:15,519 iteration 6092 : loss : 0.014253, loss_ce: 0.004143
2022-01-20 21:59:16,101 iteration 6093 : loss : 0.014974, loss_ce: 0.006211
2022-01-20 21:59:16,645 iteration 6094 : loss : 0.014239, loss_ce: 0.005119
2022-01-20 21:59:17,200 iteration 6095 : loss : 0.014130, loss_ce: 0.004154
2022-01-20 21:59:17,811 iteration 6096 : loss : 0.014833, loss_ce: 0.004604
2022-01-20 21:59:18,431 iteration 6097 : loss : 0.011677, loss_ce: 0.004286
2022-01-20 21:59:19,121 iteration 6098 : loss : 0.021798, loss_ce: 0.008774
2022-01-20 21:59:19,768 iteration 6099 : loss : 0.015082, loss_ce: 0.006374
2022-01-20 21:59:20,389 iteration 6100 : loss : 0.016034, loss_ce: 0.008288
2022-01-20 21:59:20,999 iteration 6101 : loss : 0.016230, loss_ce: 0.006210
2022-01-20 21:59:21,633 iteration 6102 : loss : 0.020071, loss_ce: 0.010304
2022-01-20 21:59:22,277 iteration 6103 : loss : 0.020661, loss_ce: 0.007011
 90%|██████████████████████████   | 359/400 [1:05:47<07:06, 10.40s/it]2022-01-20 21:59:22,975 iteration 6104 : loss : 0.022364, loss_ce: 0.009673
2022-01-20 21:59:23,630 iteration 6105 : loss : 0.017482, loss_ce: 0.008209
2022-01-20 21:59:24,249 iteration 6106 : loss : 0.015944, loss_ce: 0.007260
2022-01-20 21:59:24,845 iteration 6107 : loss : 0.015823, loss_ce: 0.005788
2022-01-20 21:59:25,420 iteration 6108 : loss : 0.014785, loss_ce: 0.005751
2022-01-20 21:59:26,003 iteration 6109 : loss : 0.017752, loss_ce: 0.004627
2022-01-20 21:59:26,562 iteration 6110 : loss : 0.016700, loss_ce: 0.007941
2022-01-20 21:59:27,136 iteration 6111 : loss : 0.014642, loss_ce: 0.005803
2022-01-20 21:59:27,714 iteration 6112 : loss : 0.017141, loss_ce: 0.005243
2022-01-20 21:59:28,299 iteration 6113 : loss : 0.014332, loss_ce: 0.006171
2022-01-20 21:59:28,927 iteration 6114 : loss : 0.016064, loss_ce: 0.004843
2022-01-20 21:59:29,507 iteration 6115 : loss : 0.014277, loss_ce: 0.005258
2022-01-20 21:59:30,118 iteration 6116 : loss : 0.024193, loss_ce: 0.006893
2022-01-20 21:59:30,671 iteration 6117 : loss : 0.012949, loss_ce: 0.005418
2022-01-20 21:59:31,205 iteration 6118 : loss : 0.010982, loss_ce: 0.003531
2022-01-20 21:59:31,890 iteration 6119 : loss : 0.018899, loss_ce: 0.009972
2022-01-20 21:59:31,891 Training Data Eval:
2022-01-20 21:59:34,572   Average segmentation loss on training set: 0.0088
2022-01-20 21:59:34,573 Validation Data Eval:
2022-01-20 21:59:35,448   Average segmentation loss on validation set: 0.0842
2022-01-20 21:59:36,028 iteration 6120 : loss : 0.021651, loss_ce: 0.006439
 90%|██████████████████████████   | 360/400 [1:06:00<07:36, 11.40s/it]2022-01-20 21:59:36,648 iteration 6121 : loss : 0.017486, loss_ce: 0.004950
2022-01-20 21:59:37,232 iteration 6122 : loss : 0.016529, loss_ce: 0.007173
2022-01-20 21:59:37,820 iteration 6123 : loss : 0.020352, loss_ce: 0.009020
2022-01-20 21:59:38,364 iteration 6124 : loss : 0.010533, loss_ce: 0.003523
2022-01-20 21:59:38,950 iteration 6125 : loss : 0.024904, loss_ce: 0.009867
2022-01-20 21:59:39,495 iteration 6126 : loss : 0.013905, loss_ce: 0.007273
2022-01-20 21:59:40,118 iteration 6127 : loss : 0.012446, loss_ce: 0.004188
2022-01-20 21:59:40,685 iteration 6128 : loss : 0.015061, loss_ce: 0.005199
2022-01-20 21:59:41,366 iteration 6129 : loss : 0.012709, loss_ce: 0.005009
2022-01-20 21:59:41,926 iteration 6130 : loss : 0.019764, loss_ce: 0.004812
2022-01-20 21:59:42,604 iteration 6131 : loss : 0.014076, loss_ce: 0.006599
2022-01-20 21:59:43,176 iteration 6132 : loss : 0.013667, loss_ce: 0.006584
2022-01-20 21:59:43,794 iteration 6133 : loss : 0.020871, loss_ce: 0.005805
2022-01-20 21:59:44,398 iteration 6134 : loss : 0.018361, loss_ce: 0.007330
2022-01-20 21:59:45,097 iteration 6135 : loss : 0.022583, loss_ce: 0.008014
2022-01-20 21:59:45,698 iteration 6136 : loss : 0.013854, loss_ce: 0.003622
2022-01-20 21:59:46,254 iteration 6137 : loss : 0.015107, loss_ce: 0.006001
 90%|██████████████████████████▏  | 361/400 [1:06:11<07:10, 11.05s/it]2022-01-20 21:59:46,851 iteration 6138 : loss : 0.016136, loss_ce: 0.005723
2022-01-20 21:59:47,430 iteration 6139 : loss : 0.013246, loss_ce: 0.005150
2022-01-20 21:59:47,990 iteration 6140 : loss : 0.018301, loss_ce: 0.009290
2022-01-20 21:59:48,500 iteration 6141 : loss : 0.011568, loss_ce: 0.004574
2022-01-20 21:59:48,994 iteration 6142 : loss : 0.010584, loss_ce: 0.004422
2022-01-20 21:59:49,635 iteration 6143 : loss : 0.013188, loss_ce: 0.003504
2022-01-20 21:59:50,213 iteration 6144 : loss : 0.015660, loss_ce: 0.006539
2022-01-20 21:59:50,778 iteration 6145 : loss : 0.013564, loss_ce: 0.005956
2022-01-20 21:59:51,321 iteration 6146 : loss : 0.014431, loss_ce: 0.004092
2022-01-20 21:59:51,890 iteration 6147 : loss : 0.013592, loss_ce: 0.005961
2022-01-20 21:59:52,515 iteration 6148 : loss : 0.022811, loss_ce: 0.010002
2022-01-20 21:59:53,132 iteration 6149 : loss : 0.019584, loss_ce: 0.007153
2022-01-20 21:59:53,794 iteration 6150 : loss : 0.016937, loss_ce: 0.005675
2022-01-20 21:59:54,457 iteration 6151 : loss : 0.017106, loss_ce: 0.004115
2022-01-20 21:59:54,999 iteration 6152 : loss : 0.014204, loss_ce: 0.005991
2022-01-20 21:59:55,607 iteration 6153 : loss : 0.013772, loss_ce: 0.004140
2022-01-20 21:59:56,227 iteration 6154 : loss : 0.016632, loss_ce: 0.006856
 90%|██████████████████████████▏  | 362/400 [1:06:21<06:47, 10.73s/it]2022-01-20 21:59:56,906 iteration 6155 : loss : 0.021937, loss_ce: 0.007965
2022-01-20 21:59:57,535 iteration 6156 : loss : 0.026641, loss_ce: 0.010681
2022-01-20 21:59:58,144 iteration 6157 : loss : 0.015602, loss_ce: 0.005754
2022-01-20 21:59:58,826 iteration 6158 : loss : 0.015284, loss_ce: 0.003734
2022-01-20 21:59:59,388 iteration 6159 : loss : 0.012347, loss_ce: 0.004182
2022-01-20 21:59:59,957 iteration 6160 : loss : 0.012858, loss_ce: 0.005209
2022-01-20 22:00:00,582 iteration 6161 : loss : 0.023409, loss_ce: 0.009237
2022-01-20 22:00:01,243 iteration 6162 : loss : 0.026519, loss_ce: 0.006785
2022-01-20 22:00:01,843 iteration 6163 : loss : 0.015668, loss_ce: 0.006242
2022-01-20 22:00:02,362 iteration 6164 : loss : 0.015588, loss_ce: 0.004610
2022-01-20 22:00:03,010 iteration 6165 : loss : 0.021832, loss_ce: 0.008435
2022-01-20 22:00:03,572 iteration 6166 : loss : 0.011301, loss_ce: 0.004255
2022-01-20 22:00:04,228 iteration 6167 : loss : 0.019206, loss_ce: 0.009720
2022-01-20 22:00:04,848 iteration 6168 : loss : 0.015775, loss_ce: 0.006056
2022-01-20 22:00:05,437 iteration 6169 : loss : 0.018279, loss_ce: 0.005003
2022-01-20 22:00:05,982 iteration 6170 : loss : 0.013106, loss_ce: 0.006182
2022-01-20 22:00:06,548 iteration 6171 : loss : 0.015240, loss_ce: 0.007162
 91%|██████████████████████████▎  | 363/400 [1:06:31<06:32, 10.61s/it]2022-01-20 22:00:07,163 iteration 6172 : loss : 0.015121, loss_ce: 0.005183
2022-01-20 22:00:07,834 iteration 6173 : loss : 0.027940, loss_ce: 0.007716
2022-01-20 22:00:08,448 iteration 6174 : loss : 0.016771, loss_ce: 0.007440
2022-01-20 22:00:09,150 iteration 6175 : loss : 0.017450, loss_ce: 0.005965
2022-01-20 22:00:09,773 iteration 6176 : loss : 0.016119, loss_ce: 0.006295
2022-01-20 22:00:10,357 iteration 6177 : loss : 0.013686, loss_ce: 0.006109
2022-01-20 22:00:10,956 iteration 6178 : loss : 0.016529, loss_ce: 0.006428
2022-01-20 22:00:11,507 iteration 6179 : loss : 0.016472, loss_ce: 0.005415
2022-01-20 22:00:12,144 iteration 6180 : loss : 0.015967, loss_ce: 0.006876
2022-01-20 22:00:12,695 iteration 6181 : loss : 0.011114, loss_ce: 0.003486
2022-01-20 22:00:13,257 iteration 6182 : loss : 0.012393, loss_ce: 0.003753
2022-01-20 22:00:13,905 iteration 6183 : loss : 0.017789, loss_ce: 0.007202
2022-01-20 22:00:14,522 iteration 6184 : loss : 0.019467, loss_ce: 0.009909
2022-01-20 22:00:15,188 iteration 6185 : loss : 0.023105, loss_ce: 0.005767
2022-01-20 22:00:15,774 iteration 6186 : loss : 0.013401, loss_ce: 0.005030
2022-01-20 22:00:16,391 iteration 6187 : loss : 0.015032, loss_ce: 0.007053
2022-01-20 22:00:17,079 iteration 6188 : loss : 0.017130, loss_ce: 0.007657
 91%|██████████████████████████▍  | 364/400 [1:06:41<06:21, 10.58s/it]2022-01-20 22:00:17,790 iteration 6189 : loss : 0.017897, loss_ce: 0.004713
2022-01-20 22:00:18,454 iteration 6190 : loss : 0.016051, loss_ce: 0.004313
2022-01-20 22:00:19,030 iteration 6191 : loss : 0.016406, loss_ce: 0.007800
2022-01-20 22:00:19,566 iteration 6192 : loss : 0.010571, loss_ce: 0.003977
2022-01-20 22:00:20,149 iteration 6193 : loss : 0.015888, loss_ce: 0.005089
2022-01-20 22:00:20,681 iteration 6194 : loss : 0.013963, loss_ce: 0.005396
2022-01-20 22:00:21,356 iteration 6195 : loss : 0.013793, loss_ce: 0.004619
2022-01-20 22:00:21,933 iteration 6196 : loss : 0.015282, loss_ce: 0.005188
2022-01-20 22:00:22,467 iteration 6197 : loss : 0.013379, loss_ce: 0.006658
2022-01-20 22:00:23,180 iteration 6198 : loss : 0.021242, loss_ce: 0.007281
2022-01-20 22:00:23,765 iteration 6199 : loss : 0.015117, loss_ce: 0.006327
2022-01-20 22:00:24,332 iteration 6200 : loss : 0.013489, loss_ce: 0.005983
2022-01-20 22:00:24,932 iteration 6201 : loss : 0.016707, loss_ce: 0.007125
2022-01-20 22:00:25,461 iteration 6202 : loss : 0.012684, loss_ce: 0.004549
2022-01-20 22:00:26,201 iteration 6203 : loss : 0.022260, loss_ce: 0.010234
2022-01-20 22:00:26,736 iteration 6204 : loss : 0.013848, loss_ce: 0.005793
2022-01-20 22:00:26,736 Training Data Eval:
2022-01-20 22:00:29,423   Average segmentation loss on training set: 0.0086
2022-01-20 22:00:29,424 Validation Data Eval:
2022-01-20 22:00:30,302   Average segmentation loss on validation set: 0.0734
2022-01-20 22:00:30,943 iteration 6205 : loss : 0.016318, loss_ce: 0.005322
 91%|██████████████████████████▍  | 365/400 [1:06:55<06:44, 11.57s/it]2022-01-20 22:00:31,601 iteration 6206 : loss : 0.016673, loss_ce: 0.007346
2022-01-20 22:00:32,217 iteration 6207 : loss : 0.017479, loss_ce: 0.005832
2022-01-20 22:00:32,863 iteration 6208 : loss : 0.021336, loss_ce: 0.007983
2022-01-20 22:00:33,470 iteration 6209 : loss : 0.017322, loss_ce: 0.006568
2022-01-20 22:00:34,081 iteration 6210 : loss : 0.012912, loss_ce: 0.005242
2022-01-20 22:00:34,656 iteration 6211 : loss : 0.014124, loss_ce: 0.006719
2022-01-20 22:00:35,210 iteration 6212 : loss : 0.015229, loss_ce: 0.005892
2022-01-20 22:00:35,710 iteration 6213 : loss : 0.011692, loss_ce: 0.004027
2022-01-20 22:00:36,371 iteration 6214 : loss : 0.015357, loss_ce: 0.005647
2022-01-20 22:00:36,956 iteration 6215 : loss : 0.016304, loss_ce: 0.004796
2022-01-20 22:00:37,557 iteration 6216 : loss : 0.015351, loss_ce: 0.004935
2022-01-20 22:00:38,189 iteration 6217 : loss : 0.015340, loss_ce: 0.006223
2022-01-20 22:00:38,735 iteration 6218 : loss : 0.012337, loss_ce: 0.004726
2022-01-20 22:00:39,351 iteration 6219 : loss : 0.019189, loss_ce: 0.006916
2022-01-20 22:00:39,865 iteration 6220 : loss : 0.012636, loss_ce: 0.003334
2022-01-20 22:00:40,540 iteration 6221 : loss : 0.013836, loss_ce: 0.004572
2022-01-20 22:00:41,143 iteration 6222 : loss : 0.015547, loss_ce: 0.006773
 92%|██████████████████████████▌  | 366/400 [1:07:06<06:19, 11.16s/it]2022-01-20 22:00:41,802 iteration 6223 : loss : 0.021191, loss_ce: 0.010886
2022-01-20 22:00:42,436 iteration 6224 : loss : 0.015309, loss_ce: 0.006662
2022-01-20 22:00:43,051 iteration 6225 : loss : 0.012623, loss_ce: 0.006164
2022-01-20 22:00:43,636 iteration 6226 : loss : 0.015194, loss_ce: 0.005388
2022-01-20 22:00:44,307 iteration 6227 : loss : 0.014299, loss_ce: 0.004528
2022-01-20 22:00:44,887 iteration 6228 : loss : 0.017476, loss_ce: 0.006227
2022-01-20 22:00:45,511 iteration 6229 : loss : 0.014039, loss_ce: 0.004359
2022-01-20 22:00:46,155 iteration 6230 : loss : 0.028889, loss_ce: 0.007431
2022-01-20 22:00:46,696 iteration 6231 : loss : 0.013789, loss_ce: 0.006115
2022-01-20 22:00:47,269 iteration 6232 : loss : 0.016037, loss_ce: 0.006243
2022-01-20 22:00:47,945 iteration 6233 : loss : 0.022789, loss_ce: 0.007890
2022-01-20 22:00:48,532 iteration 6234 : loss : 0.019122, loss_ce: 0.007693
2022-01-20 22:00:49,126 iteration 6235 : loss : 0.017020, loss_ce: 0.005532
2022-01-20 22:00:49,777 iteration 6236 : loss : 0.019106, loss_ce: 0.007857
2022-01-20 22:00:50,402 iteration 6237 : loss : 0.016410, loss_ce: 0.005036
2022-01-20 22:00:51,061 iteration 6238 : loss : 0.014787, loss_ce: 0.005610
2022-01-20 22:00:51,739 iteration 6239 : loss : 0.016409, loss_ce: 0.006383
 92%|██████████████████████████▌  | 367/400 [1:07:16<06:02, 10.99s/it]2022-01-20 22:00:52,338 iteration 6240 : loss : 0.013863, loss_ce: 0.004828
2022-01-20 22:00:52,887 iteration 6241 : loss : 0.012817, loss_ce: 0.005300
2022-01-20 22:00:53,512 iteration 6242 : loss : 0.016354, loss_ce: 0.006948
2022-01-20 22:00:54,103 iteration 6243 : loss : 0.014979, loss_ce: 0.005626
2022-01-20 22:00:54,703 iteration 6244 : loss : 0.015084, loss_ce: 0.005616
2022-01-20 22:00:55,317 iteration 6245 : loss : 0.012148, loss_ce: 0.004939
2022-01-20 22:00:55,888 iteration 6246 : loss : 0.013073, loss_ce: 0.005556
2022-01-20 22:00:56,440 iteration 6247 : loss : 0.012874, loss_ce: 0.004307
2022-01-20 22:00:57,064 iteration 6248 : loss : 0.029492, loss_ce: 0.007548
2022-01-20 22:00:57,700 iteration 6249 : loss : 0.017834, loss_ce: 0.006516
2022-01-20 22:00:58,198 iteration 6250 : loss : 0.013063, loss_ce: 0.003045
2022-01-20 22:00:58,837 iteration 6251 : loss : 0.024348, loss_ce: 0.012735
2022-01-20 22:00:59,357 iteration 6252 : loss : 0.012091, loss_ce: 0.004100
2022-01-20 22:01:00,041 iteration 6253 : loss : 0.021122, loss_ce: 0.008384
2022-01-20 22:01:00,550 iteration 6254 : loss : 0.009218, loss_ce: 0.003972
2022-01-20 22:01:01,293 iteration 6255 : loss : 0.022592, loss_ce: 0.008234
2022-01-20 22:01:01,857 iteration 6256 : loss : 0.015032, loss_ce: 0.005918
 92%|██████████████████████████▋  | 368/400 [1:07:26<05:43, 10.73s/it]2022-01-20 22:01:02,538 iteration 6257 : loss : 0.017515, loss_ce: 0.006724
2022-01-20 22:01:03,111 iteration 6258 : loss : 0.012590, loss_ce: 0.006291
2022-01-20 22:01:03,726 iteration 6259 : loss : 0.014688, loss_ce: 0.006863
2022-01-20 22:01:04,317 iteration 6260 : loss : 0.021253, loss_ce: 0.005707
2022-01-20 22:01:04,868 iteration 6261 : loss : 0.013647, loss_ce: 0.005463
2022-01-20 22:01:05,486 iteration 6262 : loss : 0.021309, loss_ce: 0.009224
2022-01-20 22:01:06,122 iteration 6263 : loss : 0.017792, loss_ce: 0.004810
2022-01-20 22:01:06,698 iteration 6264 : loss : 0.013062, loss_ce: 0.006118
2022-01-20 22:01:07,247 iteration 6265 : loss : 0.013490, loss_ce: 0.005782
2022-01-20 22:01:07,840 iteration 6266 : loss : 0.011539, loss_ce: 0.004765
2022-01-20 22:01:08,433 iteration 6267 : loss : 0.016835, loss_ce: 0.006371
2022-01-20 22:01:09,021 iteration 6268 : loss : 0.016549, loss_ce: 0.006305
2022-01-20 22:01:09,589 iteration 6269 : loss : 0.017525, loss_ce: 0.005354
2022-01-20 22:01:10,208 iteration 6270 : loss : 0.021588, loss_ce: 0.007981
2022-01-20 22:01:10,801 iteration 6271 : loss : 0.017732, loss_ce: 0.003981
2022-01-20 22:01:11,377 iteration 6272 : loss : 0.014124, loss_ce: 0.004189
2022-01-20 22:01:11,890 iteration 6273 : loss : 0.010411, loss_ce: 0.004176
 92%|██████████████████████████▊  | 369/400 [1:07:36<05:26, 10.52s/it]2022-01-20 22:01:12,500 iteration 6274 : loss : 0.015396, loss_ce: 0.004677
2022-01-20 22:01:13,092 iteration 6275 : loss : 0.015753, loss_ce: 0.006716
2022-01-20 22:01:13,662 iteration 6276 : loss : 0.024525, loss_ce: 0.009363
2022-01-20 22:01:14,298 iteration 6277 : loss : 0.023605, loss_ce: 0.006025
2022-01-20 22:01:14,955 iteration 6278 : loss : 0.028913, loss_ce: 0.009801
2022-01-20 22:01:15,662 iteration 6279 : loss : 0.029982, loss_ce: 0.009088
2022-01-20 22:01:16,268 iteration 6280 : loss : 0.013027, loss_ce: 0.005840
2022-01-20 22:01:16,847 iteration 6281 : loss : 0.013711, loss_ce: 0.004697
2022-01-20 22:01:17,405 iteration 6282 : loss : 0.012198, loss_ce: 0.005165
2022-01-20 22:01:18,048 iteration 6283 : loss : 0.022116, loss_ce: 0.005687
2022-01-20 22:01:18,717 iteration 6284 : loss : 0.017281, loss_ce: 0.010074
2022-01-20 22:01:19,312 iteration 6285 : loss : 0.017593, loss_ce: 0.005832
2022-01-20 22:01:19,910 iteration 6286 : loss : 0.014009, loss_ce: 0.006699
2022-01-20 22:01:20,553 iteration 6287 : loss : 0.014759, loss_ce: 0.005375
2022-01-20 22:01:21,220 iteration 6288 : loss : 0.022702, loss_ce: 0.008012
2022-01-20 22:01:21,798 iteration 6289 : loss : 0.014731, loss_ce: 0.004919
2022-01-20 22:01:21,798 Training Data Eval:
2022-01-20 22:01:24,481   Average segmentation loss on training set: 0.0088
2022-01-20 22:01:24,482 Validation Data Eval:
2022-01-20 22:01:25,368   Average segmentation loss on validation set: 0.0847
2022-01-20 22:01:25,917 iteration 6290 : loss : 0.013335, loss_ce: 0.004495
 92%|██████████████████████████▊  | 370/400 [1:07:50<05:47, 11.57s/it]2022-01-20 22:01:26,543 iteration 6291 : loss : 0.014571, loss_ce: 0.003157
2022-01-20 22:01:27,225 iteration 6292 : loss : 0.017222, loss_ce: 0.006927
2022-01-20 22:01:27,798 iteration 6293 : loss : 0.012398, loss_ce: 0.005103
2022-01-20 22:01:28,411 iteration 6294 : loss : 0.017864, loss_ce: 0.007909
2022-01-20 22:01:29,029 iteration 6295 : loss : 0.016095, loss_ce: 0.006138
2022-01-20 22:01:29,603 iteration 6296 : loss : 0.012272, loss_ce: 0.004479
2022-01-20 22:01:30,193 iteration 6297 : loss : 0.022290, loss_ce: 0.006968
2022-01-20 22:01:30,762 iteration 6298 : loss : 0.013060, loss_ce: 0.004444
2022-01-20 22:01:31,406 iteration 6299 : loss : 0.016013, loss_ce: 0.005812
2022-01-20 22:01:32,005 iteration 6300 : loss : 0.016654, loss_ce: 0.005971
2022-01-20 22:01:32,610 iteration 6301 : loss : 0.014062, loss_ce: 0.005020
2022-01-20 22:01:33,160 iteration 6302 : loss : 0.015387, loss_ce: 0.005969
2022-01-20 22:01:33,767 iteration 6303 : loss : 0.017271, loss_ce: 0.007413
2022-01-20 22:01:34,329 iteration 6304 : loss : 0.012601, loss_ce: 0.004724
2022-01-20 22:01:34,847 iteration 6305 : loss : 0.011381, loss_ce: 0.004935
2022-01-20 22:01:35,376 iteration 6306 : loss : 0.013109, loss_ce: 0.004909
2022-01-20 22:01:36,046 iteration 6307 : loss : 0.018538, loss_ce: 0.007892
 93%|██████████████████████████▉  | 371/400 [1:08:00<05:23, 11.14s/it]2022-01-20 22:01:36,654 iteration 6308 : loss : 0.013550, loss_ce: 0.005058
2022-01-20 22:01:37,280 iteration 6309 : loss : 0.015990, loss_ce: 0.007040
2022-01-20 22:01:37,894 iteration 6310 : loss : 0.015604, loss_ce: 0.006650
2022-01-20 22:01:38,457 iteration 6311 : loss : 0.019119, loss_ce: 0.005314
2022-01-20 22:01:39,088 iteration 6312 : loss : 0.015134, loss_ce: 0.006701
2022-01-20 22:01:39,663 iteration 6313 : loss : 0.011399, loss_ce: 0.002502
2022-01-20 22:01:40,294 iteration 6314 : loss : 0.018315, loss_ce: 0.007875
2022-01-20 22:01:40,944 iteration 6315 : loss : 0.021964, loss_ce: 0.008203
2022-01-20 22:01:41,527 iteration 6316 : loss : 0.014511, loss_ce: 0.006719
2022-01-20 22:01:42,146 iteration 6317 : loss : 0.013490, loss_ce: 0.005532
2022-01-20 22:01:42,817 iteration 6318 : loss : 0.016679, loss_ce: 0.007385
2022-01-20 22:01:43,514 iteration 6319 : loss : 0.016236, loss_ce: 0.005181
2022-01-20 22:01:44,210 iteration 6320 : loss : 0.014700, loss_ce: 0.005958
2022-01-20 22:01:44,860 iteration 6321 : loss : 0.020925, loss_ce: 0.008234
2022-01-20 22:01:45,530 iteration 6322 : loss : 0.014951, loss_ce: 0.005724
2022-01-20 22:01:46,001 iteration 6323 : loss : 0.011045, loss_ce: 0.005020
2022-01-20 22:01:46,603 iteration 6324 : loss : 0.017451, loss_ce: 0.006113
 93%|██████████████████████████▉  | 372/400 [1:08:11<05:07, 10.97s/it]2022-01-20 22:01:47,180 iteration 6325 : loss : 0.018400, loss_ce: 0.005847
2022-01-20 22:01:47,706 iteration 6326 : loss : 0.010615, loss_ce: 0.004408
2022-01-20 22:01:48,216 iteration 6327 : loss : 0.011155, loss_ce: 0.004144
2022-01-20 22:01:48,869 iteration 6328 : loss : 0.016167, loss_ce: 0.006881
2022-01-20 22:01:49,563 iteration 6329 : loss : 0.015014, loss_ce: 0.005173
2022-01-20 22:01:50,177 iteration 6330 : loss : 0.013341, loss_ce: 0.005034
2022-01-20 22:01:50,827 iteration 6331 : loss : 0.015418, loss_ce: 0.007545
2022-01-20 22:01:51,400 iteration 6332 : loss : 0.019835, loss_ce: 0.007078
2022-01-20 22:01:51,981 iteration 6333 : loss : 0.012987, loss_ce: 0.005356
2022-01-20 22:01:52,596 iteration 6334 : loss : 0.011300, loss_ce: 0.004344
2022-01-20 22:01:53,334 iteration 6335 : loss : 0.023707, loss_ce: 0.011731
2022-01-20 22:01:53,962 iteration 6336 : loss : 0.014888, loss_ce: 0.005019
2022-01-20 22:01:54,482 iteration 6337 : loss : 0.014723, loss_ce: 0.005566
2022-01-20 22:01:55,144 iteration 6338 : loss : 0.015094, loss_ce: 0.004420
2022-01-20 22:01:55,710 iteration 6339 : loss : 0.012633, loss_ce: 0.004730
2022-01-20 22:01:56,310 iteration 6340 : loss : 0.014690, loss_ce: 0.006908
2022-01-20 22:01:56,933 iteration 6341 : loss : 0.014682, loss_ce: 0.003815
 93%|███████████████████████████  | 373/400 [1:08:21<04:50, 10.77s/it]2022-01-20 22:01:57,687 iteration 6342 : loss : 0.017132, loss_ce: 0.007266
2022-01-20 22:01:58,282 iteration 6343 : loss : 0.015111, loss_ce: 0.004830
2022-01-20 22:01:58,891 iteration 6344 : loss : 0.014448, loss_ce: 0.006545
2022-01-20 22:01:59,499 iteration 6345 : loss : 0.016644, loss_ce: 0.008092
2022-01-20 22:02:00,052 iteration 6346 : loss : 0.013774, loss_ce: 0.003685
2022-01-20 22:02:00,641 iteration 6347 : loss : 0.023400, loss_ce: 0.009452
2022-01-20 22:02:01,336 iteration 6348 : loss : 0.019204, loss_ce: 0.005894
2022-01-20 22:02:01,886 iteration 6349 : loss : 0.012282, loss_ce: 0.005130
2022-01-20 22:02:02,460 iteration 6350 : loss : 0.012561, loss_ce: 0.003602
2022-01-20 22:02:03,032 iteration 6351 : loss : 0.011378, loss_ce: 0.004084
2022-01-20 22:02:03,686 iteration 6352 : loss : 0.013503, loss_ce: 0.005378
2022-01-20 22:02:04,339 iteration 6353 : loss : 0.014222, loss_ce: 0.006236
2022-01-20 22:02:05,044 iteration 6354 : loss : 0.013841, loss_ce: 0.005607
2022-01-20 22:02:05,608 iteration 6355 : loss : 0.012024, loss_ce: 0.005645
2022-01-20 22:02:06,232 iteration 6356 : loss : 0.016234, loss_ce: 0.006779
2022-01-20 22:02:06,805 iteration 6357 : loss : 0.019436, loss_ce: 0.007219
2022-01-20 22:02:07,470 iteration 6358 : loss : 0.016056, loss_ce: 0.005509
 94%|███████████████████████████  | 374/400 [1:08:32<04:38, 10.70s/it]2022-01-20 22:02:08,113 iteration 6359 : loss : 0.016158, loss_ce: 0.005225
2022-01-20 22:02:08,667 iteration 6360 : loss : 0.015693, loss_ce: 0.004504
2022-01-20 22:02:09,273 iteration 6361 : loss : 0.014273, loss_ce: 0.003435
2022-01-20 22:02:09,897 iteration 6362 : loss : 0.013299, loss_ce: 0.006209
2022-01-20 22:02:10,570 iteration 6363 : loss : 0.018943, loss_ce: 0.008312
2022-01-20 22:02:11,114 iteration 6364 : loss : 0.010011, loss_ce: 0.003894
2022-01-20 22:02:11,645 iteration 6365 : loss : 0.013251, loss_ce: 0.005035
2022-01-20 22:02:12,285 iteration 6366 : loss : 0.017335, loss_ce: 0.006613
2022-01-20 22:02:12,870 iteration 6367 : loss : 0.013195, loss_ce: 0.005731
2022-01-20 22:02:13,430 iteration 6368 : loss : 0.017601, loss_ce: 0.005720
2022-01-20 22:02:14,043 iteration 6369 : loss : 0.011873, loss_ce: 0.005045
2022-01-20 22:02:14,674 iteration 6370 : loss : 0.019575, loss_ce: 0.005042
2022-01-20 22:02:15,308 iteration 6371 : loss : 0.018221, loss_ce: 0.007077
2022-01-20 22:02:15,911 iteration 6372 : loss : 0.014368, loss_ce: 0.006585
2022-01-20 22:02:16,383 iteration 6373 : loss : 0.009148, loss_ce: 0.002386
2022-01-20 22:02:16,932 iteration 6374 : loss : 0.011388, loss_ce: 0.004522
2022-01-20 22:02:16,932 Training Data Eval:
2022-01-20 22:02:19,618   Average segmentation loss on training set: 0.0081
2022-01-20 22:02:19,618 Validation Data Eval:
2022-01-20 22:02:20,494   Average segmentation loss on validation set: 0.0736
2022-01-20 22:02:21,068 iteration 6375 : loss : 0.015642, loss_ce: 0.005133
 94%|███████████████████████████▏ | 375/400 [1:08:45<04:49, 11.57s/it]2022-01-20 22:02:21,905 iteration 6376 : loss : 0.019426, loss_ce: 0.007176
2022-01-20 22:02:22,512 iteration 6377 : loss : 0.019591, loss_ce: 0.008734
2022-01-20 22:02:23,084 iteration 6378 : loss : 0.016063, loss_ce: 0.005449
2022-01-20 22:02:23,714 iteration 6379 : loss : 0.015429, loss_ce: 0.004337
2022-01-20 22:02:24,232 iteration 6380 : loss : 0.010936, loss_ce: 0.004964
2022-01-20 22:02:24,749 iteration 6381 : loss : 0.013703, loss_ce: 0.004360
2022-01-20 22:02:25,356 iteration 6382 : loss : 0.018769, loss_ce: 0.008152
2022-01-20 22:02:25,984 iteration 6383 : loss : 0.013553, loss_ce: 0.005187
2022-01-20 22:02:26,558 iteration 6384 : loss : 0.012156, loss_ce: 0.004603
2022-01-20 22:02:27,230 iteration 6385 : loss : 0.023327, loss_ce: 0.009533
2022-01-20 22:02:27,822 iteration 6386 : loss : 0.015780, loss_ce: 0.006191
2022-01-20 22:02:28,534 iteration 6387 : loss : 0.024493, loss_ce: 0.011605
2022-01-20 22:02:29,102 iteration 6388 : loss : 0.010507, loss_ce: 0.003704
2022-01-20 22:02:29,597 iteration 6389 : loss : 0.012132, loss_ce: 0.003919
2022-01-20 22:02:30,176 iteration 6390 : loss : 0.015744, loss_ce: 0.005623
2022-01-20 22:02:30,878 iteration 6391 : loss : 0.019639, loss_ce: 0.005860
2022-01-20 22:02:31,414 iteration 6392 : loss : 0.009326, loss_ce: 0.003908
 94%|███████████████████████████▎ | 376/400 [1:08:56<04:28, 11.20s/it]2022-01-20 22:02:32,059 iteration 6393 : loss : 0.010866, loss_ce: 0.003440
2022-01-20 22:02:32,676 iteration 6394 : loss : 0.016387, loss_ce: 0.005607
2022-01-20 22:02:33,234 iteration 6395 : loss : 0.012927, loss_ce: 0.006763
2022-01-20 22:02:33,918 iteration 6396 : loss : 0.017011, loss_ce: 0.006802
2022-01-20 22:02:34,476 iteration 6397 : loss : 0.015160, loss_ce: 0.005831
2022-01-20 22:02:35,006 iteration 6398 : loss : 0.012701, loss_ce: 0.003978
2022-01-20 22:02:35,604 iteration 6399 : loss : 0.012246, loss_ce: 0.003685
2022-01-20 22:02:36,199 iteration 6400 : loss : 0.013172, loss_ce: 0.006489
2022-01-20 22:02:36,722 iteration 6401 : loss : 0.012148, loss_ce: 0.004711
2022-01-20 22:02:37,313 iteration 6402 : loss : 0.014582, loss_ce: 0.005379
2022-01-20 22:02:38,027 iteration 6403 : loss : 0.018897, loss_ce: 0.009352
2022-01-20 22:02:38,606 iteration 6404 : loss : 0.014167, loss_ce: 0.004384
2022-01-20 22:02:39,187 iteration 6405 : loss : 0.016903, loss_ce: 0.006322
2022-01-20 22:02:39,942 iteration 6406 : loss : 0.020603, loss_ce: 0.008672
2022-01-20 22:02:40,477 iteration 6407 : loss : 0.013000, loss_ce: 0.004022
2022-01-20 22:02:41,069 iteration 6408 : loss : 0.013534, loss_ce: 0.003162
2022-01-20 22:02:41,630 iteration 6409 : loss : 0.016590, loss_ce: 0.006464
 94%|███████████████████████████▎ | 377/400 [1:09:06<04:10, 10.91s/it]2022-01-20 22:02:42,403 iteration 6410 : loss : 0.020267, loss_ce: 0.007962
2022-01-20 22:02:43,096 iteration 6411 : loss : 0.016044, loss_ce: 0.006019
2022-01-20 22:02:43,713 iteration 6412 : loss : 0.014353, loss_ce: 0.006487
2022-01-20 22:02:44,346 iteration 6413 : loss : 0.009387, loss_ce: 0.003089
2022-01-20 22:02:44,982 iteration 6414 : loss : 0.020675, loss_ce: 0.007762
2022-01-20 22:02:45,559 iteration 6415 : loss : 0.016571, loss_ce: 0.005213
2022-01-20 22:02:46,147 iteration 6416 : loss : 0.017432, loss_ce: 0.005649
2022-01-20 22:02:46,787 iteration 6417 : loss : 0.016610, loss_ce: 0.008839
2022-01-20 22:02:47,420 iteration 6418 : loss : 0.012777, loss_ce: 0.005196
2022-01-20 22:02:48,013 iteration 6419 : loss : 0.015191, loss_ce: 0.004966
2022-01-20 22:02:48,654 iteration 6420 : loss : 0.013396, loss_ce: 0.004967
2022-01-20 22:02:49,266 iteration 6421 : loss : 0.015399, loss_ce: 0.006243
2022-01-20 22:02:49,793 iteration 6422 : loss : 0.011566, loss_ce: 0.004877
2022-01-20 22:02:50,435 iteration 6423 : loss : 0.018764, loss_ce: 0.006099
2022-01-20 22:02:51,085 iteration 6424 : loss : 0.014662, loss_ce: 0.006520
2022-01-20 22:02:51,609 iteration 6425 : loss : 0.014298, loss_ce: 0.004986
2022-01-20 22:02:52,242 iteration 6426 : loss : 0.015898, loss_ce: 0.007201
 94%|███████████████████████████▍ | 378/400 [1:09:17<03:58, 10.82s/it]2022-01-20 22:02:52,897 iteration 6427 : loss : 0.014202, loss_ce: 0.005871
2022-01-20 22:02:53,414 iteration 6428 : loss : 0.011219, loss_ce: 0.005377
2022-01-20 22:02:54,042 iteration 6429 : loss : 0.016014, loss_ce: 0.005450
2022-01-20 22:02:54,575 iteration 6430 : loss : 0.012393, loss_ce: 0.003800
2022-01-20 22:02:55,174 iteration 6431 : loss : 0.016144, loss_ce: 0.005440
2022-01-20 22:02:55,781 iteration 6432 : loss : 0.014706, loss_ce: 0.005475
2022-01-20 22:02:56,447 iteration 6433 : loss : 0.014451, loss_ce: 0.005148
2022-01-20 22:02:56,954 iteration 6434 : loss : 0.009873, loss_ce: 0.003557
2022-01-20 22:02:57,549 iteration 6435 : loss : 0.012876, loss_ce: 0.005851
2022-01-20 22:02:58,129 iteration 6436 : loss : 0.012930, loss_ce: 0.005249
2022-01-20 22:02:58,754 iteration 6437 : loss : 0.021541, loss_ce: 0.005783
2022-01-20 22:02:59,391 iteration 6438 : loss : 0.017028, loss_ce: 0.006990
2022-01-20 22:03:00,029 iteration 6439 : loss : 0.014028, loss_ce: 0.005683
2022-01-20 22:03:00,708 iteration 6440 : loss : 0.019251, loss_ce: 0.007260
2022-01-20 22:03:01,333 iteration 6441 : loss : 0.013299, loss_ce: 0.003913
2022-01-20 22:03:01,931 iteration 6442 : loss : 0.015123, loss_ce: 0.005849
2022-01-20 22:03:02,565 iteration 6443 : loss : 0.014736, loss_ce: 0.005453
 95%|███████████████████████████▍ | 379/400 [1:09:27<03:44, 10.67s/it]2022-01-20 22:03:03,259 iteration 6444 : loss : 0.014723, loss_ce: 0.006436
2022-01-20 22:03:03,937 iteration 6445 : loss : 0.013864, loss_ce: 0.005018
2022-01-20 22:03:04,553 iteration 6446 : loss : 0.013411, loss_ce: 0.003592
2022-01-20 22:03:05,148 iteration 6447 : loss : 0.017391, loss_ce: 0.009345
2022-01-20 22:03:05,746 iteration 6448 : loss : 0.012611, loss_ce: 0.005420
2022-01-20 22:03:06,396 iteration 6449 : loss : 0.013111, loss_ce: 0.004226
2022-01-20 22:03:06,948 iteration 6450 : loss : 0.013039, loss_ce: 0.005793
2022-01-20 22:03:07,478 iteration 6451 : loss : 0.014518, loss_ce: 0.005208
2022-01-20 22:03:08,103 iteration 6452 : loss : 0.013640, loss_ce: 0.006740
2022-01-20 22:03:08,708 iteration 6453 : loss : 0.014041, loss_ce: 0.006046
2022-01-20 22:03:09,293 iteration 6454 : loss : 0.021509, loss_ce: 0.006628
2022-01-20 22:03:09,876 iteration 6455 : loss : 0.011984, loss_ce: 0.003578
2022-01-20 22:03:10,585 iteration 6456 : loss : 0.015990, loss_ce: 0.006729
2022-01-20 22:03:11,199 iteration 6457 : loss : 0.013338, loss_ce: 0.004296
2022-01-20 22:03:11,768 iteration 6458 : loss : 0.013490, loss_ce: 0.004891
2022-01-20 22:03:12,310 iteration 6459 : loss : 0.011128, loss_ce: 0.004003
2022-01-20 22:03:12,310 Training Data Eval:
2022-01-20 22:03:15,001   Average segmentation loss on training set: 0.0079
2022-01-20 22:03:15,002 Validation Data Eval:
2022-01-20 22:03:15,876   Average segmentation loss on validation set: 0.0858
2022-01-20 22:03:16,511 iteration 6460 : loss : 0.016845, loss_ce: 0.004643
 95%|███████████████████████████▌ | 380/400 [1:09:41<03:53, 11.65s/it]2022-01-20 22:03:17,171 iteration 6461 : loss : 0.017853, loss_ce: 0.005983
2022-01-20 22:03:17,785 iteration 6462 : loss : 0.014916, loss_ce: 0.005339
2022-01-20 22:03:18,335 iteration 6463 : loss : 0.009620, loss_ce: 0.002776
2022-01-20 22:03:18,877 iteration 6464 : loss : 0.012223, loss_ce: 0.004288
2022-01-20 22:03:19,453 iteration 6465 : loss : 0.023222, loss_ce: 0.006773
2022-01-20 22:03:20,073 iteration 6466 : loss : 0.014948, loss_ce: 0.005551
2022-01-20 22:03:20,724 iteration 6467 : loss : 0.012818, loss_ce: 0.005449
2022-01-20 22:03:21,399 iteration 6468 : loss : 0.018561, loss_ce: 0.009065
2022-01-20 22:03:21,999 iteration 6469 : loss : 0.015821, loss_ce: 0.008742
2022-01-20 22:03:22,578 iteration 6470 : loss : 0.018445, loss_ce: 0.005219
2022-01-20 22:03:23,159 iteration 6471 : loss : 0.016330, loss_ce: 0.005722
2022-01-20 22:03:23,738 iteration 6472 : loss : 0.014685, loss_ce: 0.004340
2022-01-20 22:03:24,269 iteration 6473 : loss : 0.013864, loss_ce: 0.006545
2022-01-20 22:03:24,920 iteration 6474 : loss : 0.015571, loss_ce: 0.008683
2022-01-20 22:03:25,444 iteration 6475 : loss : 0.009450, loss_ce: 0.003127
2022-01-20 22:03:26,008 iteration 6476 : loss : 0.010471, loss_ce: 0.003846
2022-01-20 22:03:26,535 iteration 6477 : loss : 0.017898, loss_ce: 0.006433
 95%|███████████████████████████▌ | 381/400 [1:09:51<03:32, 11.16s/it]2022-01-20 22:03:27,213 iteration 6478 : loss : 0.021134, loss_ce: 0.008842
2022-01-20 22:03:27,978 iteration 6479 : loss : 0.016214, loss_ce: 0.007792
2022-01-20 22:03:28,611 iteration 6480 : loss : 0.021415, loss_ce: 0.005131
2022-01-20 22:03:29,238 iteration 6481 : loss : 0.015410, loss_ce: 0.006550
2022-01-20 22:03:29,865 iteration 6482 : loss : 0.015037, loss_ce: 0.005535
2022-01-20 22:03:30,443 iteration 6483 : loss : 0.017937, loss_ce: 0.006803
2022-01-20 22:03:31,032 iteration 6484 : loss : 0.014249, loss_ce: 0.004039
2022-01-20 22:03:31,661 iteration 6485 : loss : 0.021099, loss_ce: 0.008852
2022-01-20 22:03:32,344 iteration 6486 : loss : 0.017007, loss_ce: 0.005025
2022-01-20 22:03:32,974 iteration 6487 : loss : 0.013679, loss_ce: 0.004386
2022-01-20 22:03:33,480 iteration 6488 : loss : 0.011377, loss_ce: 0.004745
2022-01-20 22:03:34,136 iteration 6489 : loss : 0.018924, loss_ce: 0.005970
2022-01-20 22:03:34,643 iteration 6490 : loss : 0.011259, loss_ce: 0.004297
2022-01-20 22:03:35,272 iteration 6491 : loss : 0.016735, loss_ce: 0.005020
2022-01-20 22:03:35,841 iteration 6492 : loss : 0.010456, loss_ce: 0.003754
2022-01-20 22:03:36,472 iteration 6493 : loss : 0.018062, loss_ce: 0.005437
2022-01-20 22:03:37,063 iteration 6494 : loss : 0.014158, loss_ce: 0.005240
 96%|███████████████████████████▋ | 382/400 [1:10:01<03:17, 10.97s/it]2022-01-20 22:03:37,748 iteration 6495 : loss : 0.011324, loss_ce: 0.003189
2022-01-20 22:03:38,336 iteration 6496 : loss : 0.014244, loss_ce: 0.005355
2022-01-20 22:03:38,976 iteration 6497 : loss : 0.010273, loss_ce: 0.003698
2022-01-20 22:03:39,601 iteration 6498 : loss : 0.022381, loss_ce: 0.011071
2022-01-20 22:03:40,322 iteration 6499 : loss : 0.019033, loss_ce: 0.006689
2022-01-20 22:03:40,974 iteration 6500 : loss : 0.016712, loss_ce: 0.006669
2022-01-20 22:03:41,650 iteration 6501 : loss : 0.012460, loss_ce: 0.003527
2022-01-20 22:03:42,303 iteration 6502 : loss : 0.019359, loss_ce: 0.007935
2022-01-20 22:03:43,001 iteration 6503 : loss : 0.025810, loss_ce: 0.009239
2022-01-20 22:03:43,550 iteration 6504 : loss : 0.011575, loss_ce: 0.005554
2022-01-20 22:03:44,127 iteration 6505 : loss : 0.013416, loss_ce: 0.003664
2022-01-20 22:03:44,718 iteration 6506 : loss : 0.013528, loss_ce: 0.004185
2022-01-20 22:03:45,310 iteration 6507 : loss : 0.014203, loss_ce: 0.005633
2022-01-20 22:03:45,915 iteration 6508 : loss : 0.011153, loss_ce: 0.004060
2022-01-20 22:03:46,506 iteration 6509 : loss : 0.018355, loss_ce: 0.009080
2022-01-20 22:03:47,069 iteration 6510 : loss : 0.014022, loss_ce: 0.004843
2022-01-20 22:03:47,666 iteration 6511 : loss : 0.015965, loss_ce: 0.007411
 96%|███████████████████████████▊ | 383/400 [1:10:12<03:04, 10.86s/it]2022-01-20 22:03:48,300 iteration 6512 : loss : 0.014373, loss_ce: 0.006218
2022-01-20 22:03:48,837 iteration 6513 : loss : 0.013807, loss_ce: 0.005021
2022-01-20 22:03:49,417 iteration 6514 : loss : 0.012506, loss_ce: 0.003152
2022-01-20 22:03:50,007 iteration 6515 : loss : 0.013733, loss_ce: 0.004166
2022-01-20 22:03:50,598 iteration 6516 : loss : 0.016550, loss_ce: 0.005242
2022-01-20 22:03:51,265 iteration 6517 : loss : 0.019137, loss_ce: 0.008903
2022-01-20 22:03:51,804 iteration 6518 : loss : 0.014816, loss_ce: 0.006186
2022-01-20 22:03:52,476 iteration 6519 : loss : 0.017995, loss_ce: 0.005675
2022-01-20 22:03:53,008 iteration 6520 : loss : 0.012528, loss_ce: 0.005814
2022-01-20 22:03:53,650 iteration 6521 : loss : 0.011567, loss_ce: 0.004916
2022-01-20 22:03:54,245 iteration 6522 : loss : 0.014452, loss_ce: 0.006800
2022-01-20 22:03:54,787 iteration 6523 : loss : 0.020192, loss_ce: 0.007422
2022-01-20 22:03:55,392 iteration 6524 : loss : 0.018602, loss_ce: 0.007224
2022-01-20 22:03:55,971 iteration 6525 : loss : 0.012004, loss_ce: 0.003808
2022-01-20 22:03:56,594 iteration 6526 : loss : 0.011743, loss_ce: 0.004130
2022-01-20 22:03:57,253 iteration 6527 : loss : 0.016501, loss_ce: 0.004807
2022-01-20 22:03:57,875 iteration 6528 : loss : 0.013413, loss_ce: 0.005461
 96%|███████████████████████████▊ | 384/400 [1:10:22<02:50, 10.66s/it]2022-01-20 22:03:58,471 iteration 6529 : loss : 0.012584, loss_ce: 0.004683
2022-01-20 22:03:58,987 iteration 6530 : loss : 0.009427, loss_ce: 0.004048
2022-01-20 22:03:59,586 iteration 6531 : loss : 0.010900, loss_ce: 0.002740
2022-01-20 22:04:00,237 iteration 6532 : loss : 0.011907, loss_ce: 0.003725
2022-01-20 22:04:00,799 iteration 6533 : loss : 0.017334, loss_ce: 0.007542
2022-01-20 22:04:01,434 iteration 6534 : loss : 0.019617, loss_ce: 0.005470
2022-01-20 22:04:02,044 iteration 6535 : loss : 0.022114, loss_ce: 0.008478
2022-01-20 22:04:02,688 iteration 6536 : loss : 0.022269, loss_ce: 0.008021
2022-01-20 22:04:03,404 iteration 6537 : loss : 0.033682, loss_ce: 0.013426
2022-01-20 22:04:03,959 iteration 6538 : loss : 0.014630, loss_ce: 0.005187
2022-01-20 22:04:04,688 iteration 6539 : loss : 0.024185, loss_ce: 0.008200
2022-01-20 22:04:05,243 iteration 6540 : loss : 0.016392, loss_ce: 0.007245
2022-01-20 22:04:05,764 iteration 6541 : loss : 0.012617, loss_ce: 0.005232
2022-01-20 22:04:06,348 iteration 6542 : loss : 0.017717, loss_ce: 0.007078
2022-01-20 22:04:07,026 iteration 6543 : loss : 0.013934, loss_ce: 0.004624
2022-01-20 22:04:07,621 iteration 6544 : loss : 0.030581, loss_ce: 0.011123
2022-01-20 22:04:07,622 Training Data Eval:
2022-01-20 22:04:10,309   Average segmentation loss on training set: 0.0081
2022-01-20 22:04:10,309 Validation Data Eval:
2022-01-20 22:04:11,186   Average segmentation loss on validation set: 0.0843
2022-01-20 22:04:11,775 iteration 6545 : loss : 0.012958, loss_ce: 0.003760
 96%|███████████████████████████▉ | 385/400 [1:10:36<02:54, 11.64s/it]2022-01-20 22:04:12,477 iteration 6546 : loss : 0.019697, loss_ce: 0.007613
2022-01-20 22:04:13,016 iteration 6547 : loss : 0.012012, loss_ce: 0.002548
2022-01-20 22:04:13,624 iteration 6548 : loss : 0.022725, loss_ce: 0.006020
2022-01-20 22:04:14,308 iteration 6549 : loss : 0.016613, loss_ce: 0.005233
2022-01-20 22:04:14,900 iteration 6550 : loss : 0.017342, loss_ce: 0.009244
2022-01-20 22:04:15,559 iteration 6551 : loss : 0.032589, loss_ce: 0.014044
2022-01-20 22:04:16,268 iteration 6552 : loss : 0.015134, loss_ce: 0.005518
2022-01-20 22:04:16,868 iteration 6553 : loss : 0.014692, loss_ce: 0.005178
2022-01-20 22:04:17,610 iteration 6554 : loss : 0.028334, loss_ce: 0.008428
2022-01-20 22:04:18,182 iteration 6555 : loss : 0.011968, loss_ce: 0.004657
2022-01-20 22:04:18,812 iteration 6556 : loss : 0.016967, loss_ce: 0.006043
2022-01-20 22:04:19,343 iteration 6557 : loss : 0.013222, loss_ce: 0.005301
2022-01-20 22:04:19,994 iteration 6558 : loss : 0.015339, loss_ce: 0.006370
2022-01-20 22:04:20,525 iteration 6559 : loss : 0.010873, loss_ce: 0.003877
2022-01-20 22:04:21,076 iteration 6560 : loss : 0.011244, loss_ce: 0.005076
2022-01-20 22:04:21,689 iteration 6561 : loss : 0.012490, loss_ce: 0.004797
2022-01-20 22:04:22,287 iteration 6562 : loss : 0.019867, loss_ce: 0.008590
 96%|███████████████████████████▉ | 386/400 [1:10:47<02:38, 11.30s/it]2022-01-20 22:04:22,947 iteration 6563 : loss : 0.016029, loss_ce: 0.006509
2022-01-20 22:04:23,613 iteration 6564 : loss : 0.021589, loss_ce: 0.006961
2022-01-20 22:04:24,169 iteration 6565 : loss : 0.016118, loss_ce: 0.004666
2022-01-20 22:04:24,839 iteration 6566 : loss : 0.022652, loss_ce: 0.008725
2022-01-20 22:04:25,447 iteration 6567 : loss : 0.018683, loss_ce: 0.007822
2022-01-20 22:04:26,041 iteration 6568 : loss : 0.011824, loss_ce: 0.004143
2022-01-20 22:04:26,614 iteration 6569 : loss : 0.017443, loss_ce: 0.004919
2022-01-20 22:04:27,316 iteration 6570 : loss : 0.018684, loss_ce: 0.007421
2022-01-20 22:04:27,844 iteration 6571 : loss : 0.011968, loss_ce: 0.004875
2022-01-20 22:04:28,413 iteration 6572 : loss : 0.016879, loss_ce: 0.005604
2022-01-20 22:04:28,965 iteration 6573 : loss : 0.011533, loss_ce: 0.003719
2022-01-20 22:04:29,569 iteration 6574 : loss : 0.015392, loss_ce: 0.005782
2022-01-20 22:04:30,069 iteration 6575 : loss : 0.009462, loss_ce: 0.003965
2022-01-20 22:04:30,671 iteration 6576 : loss : 0.016938, loss_ce: 0.006897
2022-01-20 22:04:31,300 iteration 6577 : loss : 0.019888, loss_ce: 0.007869
2022-01-20 22:04:31,924 iteration 6578 : loss : 0.013468, loss_ce: 0.005724
2022-01-20 22:04:32,516 iteration 6579 : loss : 0.012225, loss_ce: 0.003070
 97%|████████████████████████████ | 387/400 [1:10:57<02:22, 10.98s/it]2022-01-20 22:04:33,203 iteration 6580 : loss : 0.014366, loss_ce: 0.005183
2022-01-20 22:04:33,852 iteration 6581 : loss : 0.019614, loss_ce: 0.005602
2022-01-20 22:04:34,514 iteration 6582 : loss : 0.023271, loss_ce: 0.015974
2022-01-20 22:04:35,130 iteration 6583 : loss : 0.014691, loss_ce: 0.005986
2022-01-20 22:04:35,756 iteration 6584 : loss : 0.019360, loss_ce: 0.007030
2022-01-20 22:04:36,316 iteration 6585 : loss : 0.015618, loss_ce: 0.005136
2022-01-20 22:04:36,938 iteration 6586 : loss : 0.013883, loss_ce: 0.005430
2022-01-20 22:04:37,480 iteration 6587 : loss : 0.012287, loss_ce: 0.005226
2022-01-20 22:04:38,134 iteration 6588 : loss : 0.017878, loss_ce: 0.006929
2022-01-20 22:04:38,725 iteration 6589 : loss : 0.014226, loss_ce: 0.004598
2022-01-20 22:04:39,298 iteration 6590 : loss : 0.013736, loss_ce: 0.005336
2022-01-20 22:04:39,851 iteration 6591 : loss : 0.013309, loss_ce: 0.005846
2022-01-20 22:04:40,448 iteration 6592 : loss : 0.012945, loss_ce: 0.004649
2022-01-20 22:04:41,097 iteration 6593 : loss : 0.014978, loss_ce: 0.006451
2022-01-20 22:04:41,671 iteration 6594 : loss : 0.011973, loss_ce: 0.004116
2022-01-20 22:04:42,207 iteration 6595 : loss : 0.014142, loss_ce: 0.004333
2022-01-20 22:04:42,766 iteration 6596 : loss : 0.009237, loss_ce: 0.003590
 97%|████████████████████████████▏| 388/400 [1:11:07<02:09, 10.76s/it]2022-01-20 22:04:43,474 iteration 6597 : loss : 0.014380, loss_ce: 0.007448
2022-01-20 22:04:44,148 iteration 6598 : loss : 0.021266, loss_ce: 0.005987
2022-01-20 22:04:44,699 iteration 6599 : loss : 0.013930, loss_ce: 0.005335
2022-01-20 22:04:45,342 iteration 6600 : loss : 0.021103, loss_ce: 0.006789
2022-01-20 22:04:45,884 iteration 6601 : loss : 0.011432, loss_ce: 0.004820
2022-01-20 22:04:46,376 iteration 6602 : loss : 0.009875, loss_ce: 0.003328
2022-01-20 22:04:46,993 iteration 6603 : loss : 0.022720, loss_ce: 0.007455
2022-01-20 22:04:47,666 iteration 6604 : loss : 0.016132, loss_ce: 0.006087
2022-01-20 22:04:48,289 iteration 6605 : loss : 0.014415, loss_ce: 0.005995
2022-01-20 22:04:48,901 iteration 6606 : loss : 0.013813, loss_ce: 0.006889
2022-01-20 22:04:49,461 iteration 6607 : loss : 0.014689, loss_ce: 0.004634
2022-01-20 22:04:50,086 iteration 6608 : loss : 0.015946, loss_ce: 0.006031
2022-01-20 22:04:50,747 iteration 6609 : loss : 0.016707, loss_ce: 0.006607
2022-01-20 22:04:51,326 iteration 6610 : loss : 0.017889, loss_ce: 0.004757
2022-01-20 22:04:51,826 iteration 6611 : loss : 0.011483, loss_ce: 0.004917
2022-01-20 22:04:52,432 iteration 6612 : loss : 0.016388, loss_ce: 0.006160
2022-01-20 22:04:53,079 iteration 6613 : loss : 0.018977, loss_ce: 0.006017
 97%|████████████████████████████▏| 389/400 [1:11:17<01:56, 10.63s/it]2022-01-20 22:04:53,619 iteration 6614 : loss : 0.009835, loss_ce: 0.003840
2022-01-20 22:04:54,240 iteration 6615 : loss : 0.017127, loss_ce: 0.006451
2022-01-20 22:04:54,870 iteration 6616 : loss : 0.014212, loss_ce: 0.006009
2022-01-20 22:04:55,436 iteration 6617 : loss : 0.011014, loss_ce: 0.002437
2022-01-20 22:04:56,043 iteration 6618 : loss : 0.017914, loss_ce: 0.006056
2022-01-20 22:04:56,682 iteration 6619 : loss : 0.016478, loss_ce: 0.006006
2022-01-20 22:04:57,289 iteration 6620 : loss : 0.015818, loss_ce: 0.005230
2022-01-20 22:04:57,813 iteration 6621 : loss : 0.014159, loss_ce: 0.005978
2022-01-20 22:04:58,295 iteration 6622 : loss : 0.010664, loss_ce: 0.003573
2022-01-20 22:04:58,891 iteration 6623 : loss : 0.019392, loss_ce: 0.010307
2022-01-20 22:04:59,373 iteration 6624 : loss : 0.011216, loss_ce: 0.004048
2022-01-20 22:04:59,860 iteration 6625 : loss : 0.009661, loss_ce: 0.003959
2022-01-20 22:05:00,443 iteration 6626 : loss : 0.017439, loss_ce: 0.006649
2022-01-20 22:05:00,973 iteration 6627 : loss : 0.009086, loss_ce: 0.003095
2022-01-20 22:05:01,593 iteration 6628 : loss : 0.015756, loss_ce: 0.005851
2022-01-20 22:05:02,144 iteration 6629 : loss : 0.011482, loss_ce: 0.004862
2022-01-20 22:05:02,144 Training Data Eval:
2022-01-20 22:05:04,832   Average segmentation loss on training set: 0.0078
2022-01-20 22:05:04,833 Validation Data Eval:
2022-01-20 22:05:05,713   Average segmentation loss on validation set: 0.0808
2022-01-20 22:05:06,308 iteration 6630 : loss : 0.014089, loss_ce: 0.005482
 98%|████████████████████████████▎| 390/400 [1:11:31<01:54, 11.40s/it]2022-01-20 22:05:06,843 iteration 6631 : loss : 0.011198, loss_ce: 0.004271
2022-01-20 22:05:07,454 iteration 6632 : loss : 0.014791, loss_ce: 0.003406
2022-01-20 22:05:08,028 iteration 6633 : loss : 0.010410, loss_ce: 0.004064
2022-01-20 22:05:08,577 iteration 6634 : loss : 0.013095, loss_ce: 0.005118
2022-01-20 22:05:09,222 iteration 6635 : loss : 0.011341, loss_ce: 0.004510
2022-01-20 22:05:09,786 iteration 6636 : loss : 0.010544, loss_ce: 0.005207
2022-01-20 22:05:10,414 iteration 6637 : loss : 0.020578, loss_ce: 0.006962
2022-01-20 22:05:11,034 iteration 6638 : loss : 0.010153, loss_ce: 0.003039
2022-01-20 22:05:11,654 iteration 6639 : loss : 0.015179, loss_ce: 0.005346
2022-01-20 22:05:12,289 iteration 6640 : loss : 0.015645, loss_ce: 0.006308
2022-01-20 22:05:12,882 iteration 6641 : loss : 0.014005, loss_ce: 0.005897
2022-01-20 22:05:13,484 iteration 6642 : loss : 0.012927, loss_ce: 0.004023
2022-01-20 22:05:14,164 iteration 6643 : loss : 0.014882, loss_ce: 0.007525
2022-01-20 22:05:14,858 iteration 6644 : loss : 0.016446, loss_ce: 0.007555
2022-01-20 22:05:15,453 iteration 6645 : loss : 0.017290, loss_ce: 0.007512
2022-01-20 22:05:16,052 iteration 6646 : loss : 0.015435, loss_ce: 0.007375
2022-01-20 22:05:16,661 iteration 6647 : loss : 0.019269, loss_ce: 0.003712
 98%|████████████████████████████▎| 391/400 [1:11:41<01:39, 11.09s/it]2022-01-20 22:05:17,337 iteration 6648 : loss : 0.018480, loss_ce: 0.007039
2022-01-20 22:05:17,985 iteration 6649 : loss : 0.018632, loss_ce: 0.004719
2022-01-20 22:05:18,533 iteration 6650 : loss : 0.013448, loss_ce: 0.005023
2022-01-20 22:05:19,105 iteration 6651 : loss : 0.013032, loss_ce: 0.005543
2022-01-20 22:05:19,726 iteration 6652 : loss : 0.014435, loss_ce: 0.005560
2022-01-20 22:05:20,382 iteration 6653 : loss : 0.015610, loss_ce: 0.005460
2022-01-20 22:05:21,110 iteration 6654 : loss : 0.017033, loss_ce: 0.005508
2022-01-20 22:05:21,700 iteration 6655 : loss : 0.013304, loss_ce: 0.005195
2022-01-20 22:05:22,390 iteration 6656 : loss : 0.019978, loss_ce: 0.008157
2022-01-20 22:05:23,016 iteration 6657 : loss : 0.021997, loss_ce: 0.006853
2022-01-20 22:05:23,679 iteration 6658 : loss : 0.017438, loss_ce: 0.006456
2022-01-20 22:05:24,297 iteration 6659 : loss : 0.018474, loss_ce: 0.005512
2022-01-20 22:05:24,888 iteration 6660 : loss : 0.011770, loss_ce: 0.004743
2022-01-20 22:05:25,448 iteration 6661 : loss : 0.012675, loss_ce: 0.004811
2022-01-20 22:05:26,088 iteration 6662 : loss : 0.014564, loss_ce: 0.005185
2022-01-20 22:05:26,660 iteration 6663 : loss : 0.012122, loss_ce: 0.004890
2022-01-20 22:05:27,295 iteration 6664 : loss : 0.010345, loss_ce: 0.004605
 98%|████████████████████████████▍| 392/400 [1:11:52<01:27, 10.96s/it]2022-01-20 22:05:27,958 iteration 6665 : loss : 0.022892, loss_ce: 0.007887
2022-01-20 22:05:28,608 iteration 6666 : loss : 0.011813, loss_ce: 0.003865
2022-01-20 22:05:29,204 iteration 6667 : loss : 0.016588, loss_ce: 0.006103
2022-01-20 22:05:29,939 iteration 6668 : loss : 0.020276, loss_ce: 0.009596
2022-01-20 22:05:30,486 iteration 6669 : loss : 0.015244, loss_ce: 0.005624
2022-01-20 22:05:31,036 iteration 6670 : loss : 0.009345, loss_ce: 0.003703
2022-01-20 22:05:31,603 iteration 6671 : loss : 0.013037, loss_ce: 0.005392
2022-01-20 22:05:32,116 iteration 6672 : loss : 0.015661, loss_ce: 0.003841
2022-01-20 22:05:32,742 iteration 6673 : loss : 0.016501, loss_ce: 0.006101
2022-01-20 22:05:33,330 iteration 6674 : loss : 0.012458, loss_ce: 0.005460
2022-01-20 22:05:33,969 iteration 6675 : loss : 0.014300, loss_ce: 0.004917
2022-01-20 22:05:34,509 iteration 6676 : loss : 0.012145, loss_ce: 0.003728
2022-01-20 22:05:35,084 iteration 6677 : loss : 0.015648, loss_ce: 0.003871
2022-01-20 22:05:35,561 iteration 6678 : loss : 0.009778, loss_ce: 0.004103
2022-01-20 22:05:36,274 iteration 6679 : loss : 0.014515, loss_ce: 0.006383
2022-01-20 22:05:36,875 iteration 6680 : loss : 0.017367, loss_ce: 0.006589
2022-01-20 22:05:37,527 iteration 6681 : loss : 0.012096, loss_ce: 0.004892
 98%|████████████████████████████▍| 393/400 [1:12:02<01:15, 10.74s/it]2022-01-20 22:05:38,186 iteration 6682 : loss : 0.012130, loss_ce: 0.005886
2022-01-20 22:05:38,889 iteration 6683 : loss : 0.015610, loss_ce: 0.005246
2022-01-20 22:05:39,442 iteration 6684 : loss : 0.011629, loss_ce: 0.003609
2022-01-20 22:05:40,103 iteration 6685 : loss : 0.018248, loss_ce: 0.007474
2022-01-20 22:05:40,650 iteration 6686 : loss : 0.014712, loss_ce: 0.008017
2022-01-20 22:05:41,246 iteration 6687 : loss : 0.015632, loss_ce: 0.003582
2022-01-20 22:05:41,896 iteration 6688 : loss : 0.017947, loss_ce: 0.007729
2022-01-20 22:05:42,472 iteration 6689 : loss : 0.010130, loss_ce: 0.003441
2022-01-20 22:05:43,045 iteration 6690 : loss : 0.013231, loss_ce: 0.005253
2022-01-20 22:05:43,711 iteration 6691 : loss : 0.021190, loss_ce: 0.007606
2022-01-20 22:05:44,342 iteration 6692 : loss : 0.026258, loss_ce: 0.008050
2022-01-20 22:05:45,007 iteration 6693 : loss : 0.018823, loss_ce: 0.006130
2022-01-20 22:05:45,646 iteration 6694 : loss : 0.013905, loss_ce: 0.006039
2022-01-20 22:05:46,307 iteration 6695 : loss : 0.012835, loss_ce: 0.005262
2022-01-20 22:05:46,855 iteration 6696 : loss : 0.011734, loss_ce: 0.005268
2022-01-20 22:05:47,505 iteration 6697 : loss : 0.015485, loss_ce: 0.005092
2022-01-20 22:05:48,106 iteration 6698 : loss : 0.011946, loss_ce: 0.004066
 98%|████████████████████████████▌| 394/400 [1:12:12<01:04, 10.69s/it]2022-01-20 22:05:48,713 iteration 6699 : loss : 0.012841, loss_ce: 0.006787
2022-01-20 22:05:49,377 iteration 6700 : loss : 0.016822, loss_ce: 0.007202
2022-01-20 22:05:49,964 iteration 6701 : loss : 0.012900, loss_ce: 0.006019
2022-01-20 22:05:50,530 iteration 6702 : loss : 0.020398, loss_ce: 0.006675
2022-01-20 22:05:51,115 iteration 6703 : loss : 0.011234, loss_ce: 0.003501
2022-01-20 22:05:51,759 iteration 6704 : loss : 0.016543, loss_ce: 0.005811
2022-01-20 22:05:52,325 iteration 6705 : loss : 0.015567, loss_ce: 0.005301
2022-01-20 22:05:52,879 iteration 6706 : loss : 0.010312, loss_ce: 0.004788
2022-01-20 22:05:53,434 iteration 6707 : loss : 0.013978, loss_ce: 0.004501
2022-01-20 22:05:53,954 iteration 6708 : loss : 0.012190, loss_ce: 0.004256
2022-01-20 22:05:54,502 iteration 6709 : loss : 0.012794, loss_ce: 0.004723
2022-01-20 22:05:55,056 iteration 6710 : loss : 0.015441, loss_ce: 0.006435
2022-01-20 22:05:55,604 iteration 6711 : loss : 0.015192, loss_ce: 0.002972
2022-01-20 22:05:56,224 iteration 6712 : loss : 0.015926, loss_ce: 0.006405
2022-01-20 22:05:56,899 iteration 6713 : loss : 0.014589, loss_ce: 0.005646
2022-01-20 22:05:57,525 iteration 6714 : loss : 0.013525, loss_ce: 0.006098
2022-01-20 22:05:57,525 Training Data Eval:
2022-01-20 22:06:00,216   Average segmentation loss on training set: 0.0075
2022-01-20 22:06:00,217 Validation Data Eval:
2022-01-20 22:06:01,098   Average segmentation loss on validation set: 0.0853
2022-01-20 22:06:01,731 iteration 6715 : loss : 0.015864, loss_ce: 0.004909
 99%|████████████████████████████▋| 395/400 [1:12:26<00:57, 11.57s/it]2022-01-20 22:06:02,382 iteration 6716 : loss : 0.007703, loss_ce: 0.002798
2022-01-20 22:06:02,977 iteration 6717 : loss : 0.015193, loss_ce: 0.005756
2022-01-20 22:06:03,513 iteration 6718 : loss : 0.011251, loss_ce: 0.004121
2022-01-20 22:06:04,085 iteration 6719 : loss : 0.011809, loss_ce: 0.003789
2022-01-20 22:06:04,670 iteration 6720 : loss : 0.013381, loss_ce: 0.005135
2022-01-20 22:06:05,301 iteration 6721 : loss : 0.016331, loss_ce: 0.005703
2022-01-20 22:06:05,939 iteration 6722 : loss : 0.017051, loss_ce: 0.004669
2022-01-20 22:06:06,524 iteration 6723 : loss : 0.015480, loss_ce: 0.005468
2022-01-20 22:06:07,085 iteration 6724 : loss : 0.027678, loss_ce: 0.009999
2022-01-20 22:06:07,721 iteration 6725 : loss : 0.013520, loss_ce: 0.005584
2022-01-20 22:06:08,334 iteration 6726 : loss : 0.019152, loss_ce: 0.005631
2022-01-20 22:06:08,967 iteration 6727 : loss : 0.018168, loss_ce: 0.007399
2022-01-20 22:06:09,605 iteration 6728 : loss : 0.013084, loss_ce: 0.005810
2022-01-20 22:06:10,151 iteration 6729 : loss : 0.011410, loss_ce: 0.003624
2022-01-20 22:06:10,715 iteration 6730 : loss : 0.013551, loss_ce: 0.005262
2022-01-20 22:06:11,276 iteration 6731 : loss : 0.011585, loss_ce: 0.005140
2022-01-20 22:06:11,866 iteration 6732 : loss : 0.013060, loss_ce: 0.006399
 99%|████████████████████████████▋| 396/400 [1:12:36<00:44, 11.14s/it]2022-01-20 22:06:12,548 iteration 6733 : loss : 0.016338, loss_ce: 0.007538
2022-01-20 22:06:13,097 iteration 6734 : loss : 0.007930, loss_ce: 0.002447
2022-01-20 22:06:13,701 iteration 6735 : loss : 0.014515, loss_ce: 0.006902
2022-01-20 22:06:14,293 iteration 6736 : loss : 0.013966, loss_ce: 0.004350
2022-01-20 22:06:14,849 iteration 6737 : loss : 0.010704, loss_ce: 0.004691
2022-01-20 22:06:15,432 iteration 6738 : loss : 0.011554, loss_ce: 0.003939
2022-01-20 22:06:16,060 iteration 6739 : loss : 0.016453, loss_ce: 0.006872
2022-01-20 22:06:16,731 iteration 6740 : loss : 0.015037, loss_ce: 0.005659
2022-01-20 22:06:17,269 iteration 6741 : loss : 0.009716, loss_ce: 0.003866
2022-01-20 22:06:17,910 iteration 6742 : loss : 0.013555, loss_ce: 0.005574
2022-01-20 22:06:18,536 iteration 6743 : loss : 0.016700, loss_ce: 0.005489
2022-01-20 22:06:19,211 iteration 6744 : loss : 0.011996, loss_ce: 0.005035
2022-01-20 22:06:19,782 iteration 6745 : loss : 0.019750, loss_ce: 0.005538
2022-01-20 22:06:20,358 iteration 6746 : loss : 0.018344, loss_ce: 0.008792
2022-01-20 22:06:20,952 iteration 6747 : loss : 0.018912, loss_ce: 0.006805
2022-01-20 22:06:21,565 iteration 6748 : loss : 0.016134, loss_ce: 0.005944
2022-01-20 22:06:22,198 iteration 6749 : loss : 0.017218, loss_ce: 0.006097
 99%|████████████████████████████▊| 397/400 [1:12:47<00:32, 10.90s/it]2022-01-20 22:06:22,820 iteration 6750 : loss : 0.011632, loss_ce: 0.004160
2022-01-20 22:06:23,471 iteration 6751 : loss : 0.015511, loss_ce: 0.006920
2022-01-20 22:06:24,115 iteration 6752 : loss : 0.017597, loss_ce: 0.009035
2022-01-20 22:06:24,731 iteration 6753 : loss : 0.017908, loss_ce: 0.006778
2022-01-20 22:06:25,385 iteration 6754 : loss : 0.017786, loss_ce: 0.005257
2022-01-20 22:06:25,986 iteration 6755 : loss : 0.008380, loss_ce: 0.002445
2022-01-20 22:06:26,593 iteration 6756 : loss : 0.011712, loss_ce: 0.004171
2022-01-20 22:06:27,202 iteration 6757 : loss : 0.020137, loss_ce: 0.007743
2022-01-20 22:06:27,749 iteration 6758 : loss : 0.008795, loss_ce: 0.003598
2022-01-20 22:06:28,380 iteration 6759 : loss : 0.013909, loss_ce: 0.005412
2022-01-20 22:06:28,962 iteration 6760 : loss : 0.013667, loss_ce: 0.005520
2022-01-20 22:06:29,602 iteration 6761 : loss : 0.013524, loss_ce: 0.005490
2022-01-20 22:06:30,095 iteration 6762 : loss : 0.009443, loss_ce: 0.003429
2022-01-20 22:06:30,692 iteration 6763 : loss : 0.014274, loss_ce: 0.003597
2022-01-20 22:06:31,263 iteration 6764 : loss : 0.015756, loss_ce: 0.005378
2022-01-20 22:06:31,815 iteration 6765 : loss : 0.014315, loss_ce: 0.004591
2022-01-20 22:06:32,390 iteration 6766 : loss : 0.014349, loss_ce: 0.005270
100%|████████████████████████████▊| 398/400 [1:12:57<00:21, 10.69s/it]2022-01-20 22:06:33,150 iteration 6767 : loss : 0.013239, loss_ce: 0.004001
2022-01-20 22:06:33,688 iteration 6768 : loss : 0.012790, loss_ce: 0.006337
2022-01-20 22:06:34,283 iteration 6769 : loss : 0.014143, loss_ce: 0.004465
2022-01-20 22:06:34,814 iteration 6770 : loss : 0.009998, loss_ce: 0.004001
2022-01-20 22:06:35,394 iteration 6771 : loss : 0.013113, loss_ce: 0.004123
2022-01-20 22:06:36,057 iteration 6772 : loss : 0.029146, loss_ce: 0.009028
2022-01-20 22:06:36,675 iteration 6773 : loss : 0.011461, loss_ce: 0.004793
2022-01-20 22:06:37,270 iteration 6774 : loss : 0.014933, loss_ce: 0.007076
2022-01-20 22:06:37,854 iteration 6775 : loss : 0.014467, loss_ce: 0.006009
2022-01-20 22:06:38,499 iteration 6776 : loss : 0.024304, loss_ce: 0.009664
2022-01-20 22:06:39,097 iteration 6777 : loss : 0.014655, loss_ce: 0.005433
2022-01-20 22:06:39,649 iteration 6778 : loss : 0.009761, loss_ce: 0.002882
2022-01-20 22:06:40,220 iteration 6779 : loss : 0.013219, loss_ce: 0.004135
2022-01-20 22:06:40,735 iteration 6780 : loss : 0.010009, loss_ce: 0.003447
2022-01-20 22:06:41,282 iteration 6781 : loss : 0.012174, loss_ce: 0.005448
2022-01-20 22:06:41,877 iteration 6782 : loss : 0.010399, loss_ce: 0.004207
2022-01-20 22:06:42,467 iteration 6783 : loss : 0.010938, loss_ce: 0.004716
100%|████████████████████████████▉| 399/400 [1:13:07<00:10, 10.50s/it]2022-01-20 22:06:43,200 iteration 6784 : loss : 0.021594, loss_ce: 0.008039
2022-01-20 22:06:43,729 iteration 6785 : loss : 0.014255, loss_ce: 0.006376
2022-01-20 22:06:44,224 iteration 6786 : loss : 0.012528, loss_ce: 0.006360
2022-01-20 22:06:44,837 iteration 6787 : loss : 0.016549, loss_ce: 0.006773
2022-01-20 22:06:45,362 iteration 6788 : loss : 0.021556, loss_ce: 0.005532
2022-01-20 22:06:45,978 iteration 6789 : loss : 0.010438, loss_ce: 0.004270
2022-01-20 22:06:46,606 iteration 6790 : loss : 0.014407, loss_ce: 0.004775
2022-01-20 22:06:47,260 iteration 6791 : loss : 0.021922, loss_ce: 0.008699
2022-01-20 22:06:47,899 iteration 6792 : loss : 0.013400, loss_ce: 0.004807
2022-01-20 22:06:48,499 iteration 6793 : loss : 0.016502, loss_ce: 0.005475
2022-01-20 22:06:49,115 iteration 6794 : loss : 0.015222, loss_ce: 0.006203
2022-01-20 22:06:49,698 iteration 6795 : loss : 0.012120, loss_ce: 0.004376
2022-01-20 22:06:50,291 iteration 6796 : loss : 0.014414, loss_ce: 0.005267
2022-01-20 22:06:50,847 iteration 6797 : loss : 0.015689, loss_ce: 0.005637
2022-01-20 22:06:51,359 iteration 6798 : loss : 0.013824, loss_ce: 0.004794
2022-01-20 22:06:51,945 iteration 6799 : loss : 0.024203, loss_ce: 0.011464
2022-01-20 22:06:51,945 Training Data Eval:
2022-01-20 22:06:54,638   Average segmentation loss on training set: 0.0076
2022-01-20 22:06:54,638 Validation Data Eval:
2022-01-20 22:06:55,516   Average segmentation loss on validation set: 0.0802
2022-01-20 22:06:56,088 iteration 6800 : loss : 0.013053, loss_ce: 0.005974
100%|█████████████████████████████| 400/400 [1:13:20<00:00, 11.44s/it]100%|█████████████████████████████| 400/400 [1:13:20<00:00, 11.00s/it]
