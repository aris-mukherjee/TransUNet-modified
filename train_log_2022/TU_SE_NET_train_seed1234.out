2022-01-17 11:25:50,110 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-17 11:25:50,111 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-17 11:25:50,111 ============================================================
2022-01-17 11:25:50,111 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-17 11:25:50,111 ============================================================
2022-01-17 11:25:50,111 Loading data...
2022-01-17 11:25:50,111 Reading NCI - RUNMC images...
2022-01-17 11:25:50,111 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-17 11:25:50,111 Already preprocessed this configuration. Loading now!
2022-01-17 11:25:50,133 Training Images: (256, 256, 286)
2022-01-17 11:25:50,133 Training Labels: (256, 256, 286)
2022-01-17 11:25:50,133 Validation Images: (256, 256, 98)
2022-01-17 11:25:50,133 Validation Labels: (256, 256, 98)
2022-01-17 11:25:50,133 ============================================================
2022-01-17 11:25:50,179 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-17 11:25:52,691 iteration 1 : loss : 0.950305, loss_ce: 1.155400
2022-01-17 11:25:53,522 iteration 2 : loss : 0.895802, loss_ce: 1.063559
2022-01-17 11:25:54,478 iteration 3 : loss : 0.836299, loss_ce: 0.968330
2022-01-17 11:25:55,328 iteration 4 : loss : 0.793839, loss_ce: 0.888724
2022-01-17 11:25:56,188 iteration 5 : loss : 0.737328, loss_ce: 0.804260
2022-01-17 11:25:57,061 iteration 6 : loss : 0.703588, loss_ce: 0.733614
2022-01-17 11:25:57,993 iteration 7 : loss : 0.650881, loss_ce: 0.666950
2022-01-17 11:25:58,868 iteration 8 : loss : 0.635341, loss_ce: 0.606408
2022-01-17 11:25:59,770 iteration 9 : loss : 0.573420, loss_ce: 0.573916
2022-01-17 11:26:00,696 iteration 10 : loss : 0.571054, loss_ce: 0.510273
2022-01-17 11:26:01,683 iteration 11 : loss : 0.531111, loss_ce: 0.479431
2022-01-17 11:26:02,551 iteration 12 : loss : 0.505796, loss_ce: 0.430568
2022-01-17 11:26:03,400 iteration 13 : loss : 0.491106, loss_ce: 0.394971
2022-01-17 11:26:04,218 iteration 14 : loss : 0.464053, loss_ce: 0.363462
2022-01-17 11:26:05,117 iteration 15 : loss : 0.440444, loss_ce: 0.331004
2022-01-17 11:26:05,988 iteration 16 : loss : 0.451861, loss_ce: 0.322346
2022-01-17 11:26:06,857 iteration 17 : loss : 0.406273, loss_ce: 0.301158
  0%|                               | 1/400 [00:16<1:51:18, 16.74s/it]2022-01-17 11:26:07,823 iteration 18 : loss : 0.423133, loss_ce: 0.266973
2022-01-17 11:26:08,620 iteration 19 : loss : 0.374176, loss_ce: 0.246344
2022-01-17 11:26:09,562 iteration 20 : loss : 0.364638, loss_ce: 0.227978
2022-01-17 11:26:10,409 iteration 21 : loss : 0.372184, loss_ce: 0.204232
2022-01-17 11:26:11,274 iteration 22 : loss : 0.366561, loss_ce: 0.220792
2022-01-17 11:26:12,227 iteration 23 : loss : 0.347080, loss_ce: 0.187223
2022-01-17 11:26:13,098 iteration 24 : loss : 0.337760, loss_ce: 0.188886
2022-01-17 11:26:14,033 iteration 25 : loss : 0.373717, loss_ce: 0.231172
2022-01-17 11:26:14,880 iteration 26 : loss : 0.327674, loss_ce: 0.177669
2022-01-17 11:26:15,675 iteration 27 : loss : 0.318859, loss_ce: 0.175877
2022-01-17 11:26:16,481 iteration 28 : loss : 0.317307, loss_ce: 0.164688
2022-01-17 11:26:17,397 iteration 29 : loss : 0.326763, loss_ce: 0.160508
2022-01-17 11:26:18,304 iteration 30 : loss : 0.316369, loss_ce: 0.157548
2022-01-17 11:26:19,106 iteration 31 : loss : 0.311827, loss_ce: 0.152430
2022-01-17 11:26:20,039 iteration 32 : loss : 0.324043, loss_ce: 0.172847
2022-01-17 11:26:20,952 iteration 33 : loss : 0.322878, loss_ce: 0.170755
2022-01-17 11:26:21,866 iteration 34 : loss : 0.319444, loss_ce: 0.177385
  0%|▏                              | 2/400 [00:31<1:44:14, 15.71s/it]2022-01-17 11:26:22,819 iteration 35 : loss : 0.303211, loss_ce: 0.141669
2022-01-17 11:26:23,750 iteration 36 : loss : 0.298587, loss_ce: 0.146385
2022-01-17 11:26:24,694 iteration 37 : loss : 0.298068, loss_ce: 0.123902
2022-01-17 11:26:25,536 iteration 38 : loss : 0.304935, loss_ce: 0.140967
2022-01-17 11:26:26,391 iteration 39 : loss : 0.279819, loss_ce: 0.127327
2022-01-17 11:26:27,331 iteration 40 : loss : 0.296863, loss_ce: 0.146323
2022-01-17 11:26:28,256 iteration 41 : loss : 0.317019, loss_ce: 0.150459
2022-01-17 11:26:29,162 iteration 42 : loss : 0.290278, loss_ce: 0.135420
2022-01-17 11:26:29,968 iteration 43 : loss : 0.272402, loss_ce: 0.115364
2022-01-17 11:26:30,927 iteration 44 : loss : 0.280624, loss_ce: 0.121820
2022-01-17 11:26:31,809 iteration 45 : loss : 0.270572, loss_ce: 0.113707
2022-01-17 11:26:32,703 iteration 46 : loss : 0.273973, loss_ce: 0.108550
2022-01-17 11:26:33,631 iteration 47 : loss : 0.249722, loss_ce: 0.093709
2022-01-17 11:26:34,543 iteration 48 : loss : 0.257684, loss_ce: 0.101628
2022-01-17 11:26:35,495 iteration 49 : loss : 0.301503, loss_ce: 0.126656
2022-01-17 11:26:36,333 iteration 50 : loss : 0.322091, loss_ce: 0.132314
2022-01-17 11:26:37,154 iteration 51 : loss : 0.287783, loss_ce: 0.124323
  1%|▏                              | 3/400 [00:47<1:42:40, 15.52s/it]2022-01-17 11:26:38,137 iteration 52 : loss : 0.302995, loss_ce: 0.139154
2022-01-17 11:26:39,057 iteration 53 : loss : 0.280427, loss_ce: 0.121649
2022-01-17 11:26:39,945 iteration 54 : loss : 0.263632, loss_ce: 0.105808
2022-01-17 11:26:40,847 iteration 55 : loss : 0.296584, loss_ce: 0.137741
2022-01-17 11:26:41,720 iteration 56 : loss : 0.286153, loss_ce: 0.121210
2022-01-17 11:26:42,628 iteration 57 : loss : 0.262348, loss_ce: 0.107510
2022-01-17 11:26:43,541 iteration 58 : loss : 0.280154, loss_ce: 0.109176
2022-01-17 11:26:44,413 iteration 59 : loss : 0.251549, loss_ce: 0.105452
2022-01-17 11:26:45,320 iteration 60 : loss : 0.287462, loss_ce: 0.112376
2022-01-17 11:26:46,218 iteration 61 : loss : 0.294312, loss_ce: 0.128151
2022-01-17 11:26:47,102 iteration 62 : loss : 0.320436, loss_ce: 0.105928
2022-01-17 11:26:47,904 iteration 63 : loss : 0.304849, loss_ce: 0.133768
2022-01-17 11:26:48,771 iteration 64 : loss : 0.320128, loss_ce: 0.128133
2022-01-17 11:26:49,584 iteration 65 : loss : 0.267863, loss_ce: 0.093159
2022-01-17 11:26:50,444 iteration 66 : loss : 0.264044, loss_ce: 0.106384
2022-01-17 11:26:51,391 iteration 67 : loss : 0.265605, loss_ce: 0.086461
2022-01-17 11:26:52,269 iteration 68 : loss : 0.272509, loss_ce: 0.112038
  1%|▎                              | 4/400 [01:02<1:41:21, 15.36s/it]2022-01-17 11:26:53,218 iteration 69 : loss : 0.263993, loss_ce: 0.102431
2022-01-17 11:26:54,190 iteration 70 : loss : 0.247947, loss_ce: 0.094827
2022-01-17 11:26:55,038 iteration 71 : loss : 0.253538, loss_ce: 0.093028
2022-01-17 11:26:55,934 iteration 72 : loss : 0.243015, loss_ce: 0.092229
2022-01-17 11:26:56,771 iteration 73 : loss : 0.282405, loss_ce: 0.126718
2022-01-17 11:26:57,577 iteration 74 : loss : 0.248727, loss_ce: 0.095619
2022-01-17 11:26:58,420 iteration 75 : loss : 0.253049, loss_ce: 0.103179
2022-01-17 11:26:59,251 iteration 76 : loss : 0.269495, loss_ce: 0.105375
2022-01-17 11:26:59,997 iteration 77 : loss : 0.253530, loss_ce: 0.105399
2022-01-17 11:27:00,852 iteration 78 : loss : 0.285022, loss_ce: 0.117628
2022-01-17 11:27:01,686 iteration 79 : loss : 0.281447, loss_ce: 0.098391
2022-01-17 11:27:02,501 iteration 80 : loss : 0.250530, loss_ce: 0.099619
2022-01-17 11:27:03,310 iteration 81 : loss : 0.250042, loss_ce: 0.095217
2022-01-17 11:27:04,152 iteration 82 : loss : 0.248512, loss_ce: 0.084306
2022-01-17 11:27:05,006 iteration 83 : loss : 0.250180, loss_ce: 0.086282
2022-01-17 11:27:05,972 iteration 84 : loss : 0.269101, loss_ce: 0.123766
2022-01-17 11:27:05,972 Training Data Eval:
2022-01-17 11:27:10,411   Average segmentation loss on training set: 0.2302
2022-01-17 11:27:10,412 Validation Data Eval:
2022-01-17 11:27:11,912   Average segmentation loss on validation set: 0.2496
2022-01-17 11:27:15,545 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 11:27:16,398 iteration 85 : loss : 0.259304, loss_ce: 0.098400
  1%|▍                              | 5/400 [01:26<2:01:55, 18.52s/it]2022-01-17 11:27:17,333 iteration 86 : loss : 0.254927, loss_ce: 0.084590
2022-01-17 11:27:18,362 iteration 87 : loss : 0.225198, loss_ce: 0.093664
2022-01-17 11:27:19,191 iteration 88 : loss : 0.233661, loss_ce: 0.101865
2022-01-17 11:27:20,105 iteration 89 : loss : 0.250016, loss_ce: 0.094123
2022-01-17 11:27:21,010 iteration 90 : loss : 0.225357, loss_ce: 0.087259
2022-01-17 11:27:21,986 iteration 91 : loss : 0.229988, loss_ce: 0.110178
2022-01-17 11:27:22,802 iteration 92 : loss : 0.223919, loss_ce: 0.092610
2022-01-17 11:27:23,669 iteration 93 : loss : 0.263317, loss_ce: 0.094347
2022-01-17 11:27:24,547 iteration 94 : loss : 0.249216, loss_ce: 0.100856
2022-01-17 11:27:25,568 iteration 95 : loss : 0.234880, loss_ce: 0.106196
2022-01-17 11:27:26,423 iteration 96 : loss : 0.210960, loss_ce: 0.092345
2022-01-17 11:27:27,288 iteration 97 : loss : 0.252661, loss_ce: 0.101710
2022-01-17 11:27:28,186 iteration 98 : loss : 0.225770, loss_ce: 0.099149
2022-01-17 11:27:29,186 iteration 99 : loss : 0.209668, loss_ce: 0.092423
2022-01-17 11:27:30,129 iteration 100 : loss : 0.219714, loss_ce: 0.090207
2022-01-17 11:27:31,053 iteration 101 : loss : 0.144559, loss_ce: 0.057188
2022-01-17 11:27:31,908 iteration 102 : loss : 0.211057, loss_ce: 0.089070
  2%|▍                              | 6/400 [01:41<1:54:54, 17.50s/it]2022-01-17 11:27:32,986 iteration 103 : loss : 0.181507, loss_ce: 0.084296
2022-01-17 11:27:34,010 iteration 104 : loss : 0.215299, loss_ce: 0.092356
2022-01-17 11:27:35,076 iteration 105 : loss : 0.252018, loss_ce: 0.103319
2022-01-17 11:27:35,967 iteration 106 : loss : 0.290106, loss_ce: 0.126374
2022-01-17 11:27:37,068 iteration 107 : loss : 0.213531, loss_ce: 0.102928
2022-01-17 11:27:37,934 iteration 108 : loss : 0.265052, loss_ce: 0.112781
2022-01-17 11:27:38,844 iteration 109 : loss : 0.181268, loss_ce: 0.085913
2022-01-17 11:27:39,703 iteration 110 : loss : 0.190943, loss_ce: 0.082667
2022-01-17 11:27:40,669 iteration 111 : loss : 0.213614, loss_ce: 0.107448
2022-01-17 11:27:41,536 iteration 112 : loss : 0.198283, loss_ce: 0.081029
2022-01-17 11:27:42,474 iteration 113 : loss : 0.228466, loss_ce: 0.124637
2022-01-17 11:27:43,374 iteration 114 : loss : 0.247721, loss_ce: 0.081340
2022-01-17 11:27:44,289 iteration 115 : loss : 0.189073, loss_ce: 0.081760
2022-01-17 11:27:45,273 iteration 116 : loss : 0.248556, loss_ce: 0.109336
2022-01-17 11:27:46,243 iteration 117 : loss : 0.215104, loss_ce: 0.097189
2022-01-17 11:27:47,168 iteration 118 : loss : 0.238072, loss_ce: 0.108076
2022-01-17 11:27:48,117 iteration 119 : loss : 0.185655, loss_ce: 0.074673
  2%|▌                              | 7/400 [01:57<1:51:51, 17.08s/it]2022-01-17 11:27:49,044 iteration 120 : loss : 0.278831, loss_ce: 0.139491
2022-01-17 11:27:49,908 iteration 121 : loss : 0.176281, loss_ce: 0.074646
2022-01-17 11:27:50,891 iteration 122 : loss : 0.177282, loss_ce: 0.067671
2022-01-17 11:27:51,836 iteration 123 : loss : 0.200187, loss_ce: 0.083752
2022-01-17 11:27:52,756 iteration 124 : loss : 0.207346, loss_ce: 0.083351
2022-01-17 11:27:53,634 iteration 125 : loss : 0.202080, loss_ce: 0.106868
2022-01-17 11:27:54,581 iteration 126 : loss : 0.226919, loss_ce: 0.090058
2022-01-17 11:27:55,458 iteration 127 : loss : 0.183819, loss_ce: 0.089089
2022-01-17 11:27:56,360 iteration 128 : loss : 0.181399, loss_ce: 0.080147
2022-01-17 11:27:57,345 iteration 129 : loss : 0.205491, loss_ce: 0.080612
2022-01-17 11:27:58,259 iteration 130 : loss : 0.206039, loss_ce: 0.081606
2022-01-17 11:27:59,274 iteration 131 : loss : 0.224494, loss_ce: 0.105004
2022-01-17 11:28:00,310 iteration 132 : loss : 0.161786, loss_ce: 0.048676
2022-01-17 11:28:01,200 iteration 133 : loss : 0.198044, loss_ce: 0.073167
2022-01-17 11:28:02,191 iteration 134 : loss : 0.206089, loss_ce: 0.080694
2022-01-17 11:28:03,189 iteration 135 : loss : 0.223260, loss_ce: 0.101037
2022-01-17 11:28:04,099 iteration 136 : loss : 0.145845, loss_ce: 0.076991
  2%|▌                              | 8/400 [02:13<1:49:16, 16.73s/it]2022-01-17 11:28:05,122 iteration 137 : loss : 0.217806, loss_ce: 0.084875
2022-01-17 11:28:06,002 iteration 138 : loss : 0.206904, loss_ce: 0.119514
2022-01-17 11:28:06,959 iteration 139 : loss : 0.197786, loss_ce: 0.083795
2022-01-17 11:28:07,896 iteration 140 : loss : 0.183056, loss_ce: 0.074224
2022-01-17 11:28:08,881 iteration 141 : loss : 0.196153, loss_ce: 0.101993
2022-01-17 11:28:09,878 iteration 142 : loss : 0.198612, loss_ce: 0.077637
2022-01-17 11:28:10,902 iteration 143 : loss : 0.206013, loss_ce: 0.097504
2022-01-17 11:28:11,892 iteration 144 : loss : 0.197242, loss_ce: 0.078874
2022-01-17 11:28:12,821 iteration 145 : loss : 0.201987, loss_ce: 0.084855
2022-01-17 11:28:13,795 iteration 146 : loss : 0.166953, loss_ce: 0.076057
2022-01-17 11:28:14,787 iteration 147 : loss : 0.186403, loss_ce: 0.076682
2022-01-17 11:28:15,644 iteration 148 : loss : 0.168108, loss_ce: 0.075169
2022-01-17 11:28:16,574 iteration 149 : loss : 0.232996, loss_ce: 0.105937
2022-01-17 11:28:17,474 iteration 150 : loss : 0.223320, loss_ce: 0.079391
2022-01-17 11:28:18,380 iteration 151 : loss : 0.180714, loss_ce: 0.080557
2022-01-17 11:28:19,295 iteration 152 : loss : 0.216941, loss_ce: 0.077958
2022-01-17 11:28:20,258 iteration 153 : loss : 0.237304, loss_ce: 0.110626
  2%|▋                              | 9/400 [02:30<1:47:51, 16.55s/it]2022-01-17 11:28:21,177 iteration 154 : loss : 0.225908, loss_ce: 0.097299
2022-01-17 11:28:22,128 iteration 155 : loss : 0.182130, loss_ce: 0.077068
2022-01-17 11:28:23,138 iteration 156 : loss : 0.160087, loss_ce: 0.063568
2022-01-17 11:28:24,082 iteration 157 : loss : 0.196580, loss_ce: 0.075711
2022-01-17 11:28:25,141 iteration 158 : loss : 0.232013, loss_ce: 0.096223
2022-01-17 11:28:25,943 iteration 159 : loss : 0.179807, loss_ce: 0.079286
2022-01-17 11:28:26,955 iteration 160 : loss : 0.168828, loss_ce: 0.061474
2022-01-17 11:28:27,957 iteration 161 : loss : 0.218959, loss_ce: 0.090839
2022-01-17 11:28:28,964 iteration 162 : loss : 0.208682, loss_ce: 0.092565
2022-01-17 11:28:29,904 iteration 163 : loss : 0.195187, loss_ce: 0.076842
2022-01-17 11:28:30,867 iteration 164 : loss : 0.197090, loss_ce: 0.068816
2022-01-17 11:28:31,796 iteration 165 : loss : 0.200710, loss_ce: 0.087111
2022-01-17 11:28:32,716 iteration 166 : loss : 0.212856, loss_ce: 0.085035
2022-01-17 11:28:33,660 iteration 167 : loss : 0.172023, loss_ce: 0.069406
2022-01-17 11:28:34,642 iteration 168 : loss : 0.198521, loss_ce: 0.101434
2022-01-17 11:28:35,591 iteration 169 : loss : 0.163032, loss_ce: 0.083036
2022-01-17 11:28:35,591 Training Data Eval:
2022-01-17 11:28:40,048   Average segmentation loss on training set: 0.2403
2022-01-17 11:28:40,049 Validation Data Eval:
2022-01-17 11:28:41,549   Average segmentation loss on validation set: 0.2299
2022-01-17 11:28:45,205 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 11:28:46,160 iteration 170 : loss : 0.184156, loss_ce: 0.079396
  2%|▊                             | 10/400 [02:56<2:06:19, 19.43s/it]2022-01-17 11:28:47,116 iteration 171 : loss : 0.213492, loss_ce: 0.089292
2022-01-17 11:28:48,041 iteration 172 : loss : 0.201504, loss_ce: 0.095172
2022-01-17 11:28:48,988 iteration 173 : loss : 0.185959, loss_ce: 0.086608
2022-01-17 11:28:49,834 iteration 174 : loss : 0.193641, loss_ce: 0.092080
2022-01-17 11:28:50,668 iteration 175 : loss : 0.226351, loss_ce: 0.098895
2022-01-17 11:28:51,584 iteration 176 : loss : 0.170618, loss_ce: 0.084343
2022-01-17 11:28:52,469 iteration 177 : loss : 0.157347, loss_ce: 0.062856
2022-01-17 11:28:53,354 iteration 178 : loss : 0.170989, loss_ce: 0.078325
2022-01-17 11:28:54,239 iteration 179 : loss : 0.218279, loss_ce: 0.082795
2022-01-17 11:28:55,105 iteration 180 : loss : 0.156245, loss_ce: 0.060209
2022-01-17 11:28:56,055 iteration 181 : loss : 0.216481, loss_ce: 0.087007
2022-01-17 11:28:56,961 iteration 182 : loss : 0.126065, loss_ce: 0.048361
2022-01-17 11:28:57,855 iteration 183 : loss : 0.158702, loss_ce: 0.057370
2022-01-17 11:28:58,712 iteration 184 : loss : 0.183891, loss_ce: 0.061253
2022-01-17 11:28:59,696 iteration 185 : loss : 0.197074, loss_ce: 0.067545
2022-01-17 11:29:00,686 iteration 186 : loss : 0.223228, loss_ce: 0.092399
2022-01-17 11:29:01,717 iteration 187 : loss : 0.157192, loss_ce: 0.064286
  3%|▊                             | 11/400 [03:11<1:58:18, 18.25s/it]2022-01-17 11:29:02,750 iteration 188 : loss : 0.241672, loss_ce: 0.100029
2022-01-17 11:29:03,732 iteration 189 : loss : 0.151784, loss_ce: 0.065865
2022-01-17 11:29:04,711 iteration 190 : loss : 0.188048, loss_ce: 0.069134
2022-01-17 11:29:05,634 iteration 191 : loss : 0.159748, loss_ce: 0.065383
2022-01-17 11:29:06,504 iteration 192 : loss : 0.167010, loss_ce: 0.078806
2022-01-17 11:29:07,507 iteration 193 : loss : 0.169842, loss_ce: 0.069227
2022-01-17 11:29:08,436 iteration 194 : loss : 0.236767, loss_ce: 0.085887
2022-01-17 11:29:09,340 iteration 195 : loss : 0.167534, loss_ce: 0.074342
2022-01-17 11:29:10,197 iteration 196 : loss : 0.158980, loss_ce: 0.062728
2022-01-17 11:29:11,155 iteration 197 : loss : 0.191703, loss_ce: 0.077376
2022-01-17 11:29:12,140 iteration 198 : loss : 0.157507, loss_ce: 0.070306
2022-01-17 11:29:13,049 iteration 199 : loss : 0.197687, loss_ce: 0.075612
2022-01-17 11:29:13,975 iteration 200 : loss : 0.198131, loss_ce: 0.078192
2022-01-17 11:29:14,938 iteration 201 : loss : 0.125566, loss_ce: 0.046490
2022-01-17 11:29:15,920 iteration 202 : loss : 0.213668, loss_ce: 0.086752
2022-01-17 11:29:16,817 iteration 203 : loss : 0.151595, loss_ce: 0.058703
2022-01-17 11:29:17,856 iteration 204 : loss : 0.197213, loss_ce: 0.077821
  3%|▉                             | 12/400 [03:27<1:53:51, 17.61s/it]2022-01-17 11:29:18,807 iteration 205 : loss : 0.140611, loss_ce: 0.059968
2022-01-17 11:29:19,742 iteration 206 : loss : 0.168972, loss_ce: 0.060034
2022-01-17 11:29:20,708 iteration 207 : loss : 0.131817, loss_ce: 0.050098
2022-01-17 11:29:21,626 iteration 208 : loss : 0.206866, loss_ce: 0.067289
2022-01-17 11:29:22,653 iteration 209 : loss : 0.218097, loss_ce: 0.103027
2022-01-17 11:29:23,501 iteration 210 : loss : 0.141000, loss_ce: 0.052842
2022-01-17 11:29:24,485 iteration 211 : loss : 0.160605, loss_ce: 0.071400
2022-01-17 11:29:25,443 iteration 212 : loss : 0.181535, loss_ce: 0.070764
2022-01-17 11:29:26,496 iteration 213 : loss : 0.138128, loss_ce: 0.065386
2022-01-17 11:29:27,440 iteration 214 : loss : 0.172843, loss_ce: 0.062139
2022-01-17 11:29:28,380 iteration 215 : loss : 0.193397, loss_ce: 0.083189
2022-01-17 11:29:29,493 iteration 216 : loss : 0.150102, loss_ce: 0.062176
2022-01-17 11:29:30,527 iteration 217 : loss : 0.131157, loss_ce: 0.050809
2022-01-17 11:29:31,471 iteration 218 : loss : 0.176049, loss_ce: 0.083938
2022-01-17 11:29:32,302 iteration 219 : loss : 0.145113, loss_ce: 0.065767
2022-01-17 11:29:33,265 iteration 220 : loss : 0.158503, loss_ce: 0.067376
2022-01-17 11:29:34,218 iteration 221 : loss : 0.186479, loss_ce: 0.073580
  3%|▉                             | 13/400 [03:44<1:51:07, 17.23s/it]2022-01-17 11:29:35,223 iteration 222 : loss : 0.174536, loss_ce: 0.080954
2022-01-17 11:29:36,213 iteration 223 : loss : 0.155262, loss_ce: 0.062976
2022-01-17 11:29:37,150 iteration 224 : loss : 0.187523, loss_ce: 0.105108
2022-01-17 11:29:38,185 iteration 225 : loss : 0.277412, loss_ce: 0.084702
2022-01-17 11:29:39,118 iteration 226 : loss : 0.172752, loss_ce: 0.069829
2022-01-17 11:29:40,105 iteration 227 : loss : 0.212944, loss_ce: 0.097682
2022-01-17 11:29:41,038 iteration 228 : loss : 0.199442, loss_ce: 0.088057
2022-01-17 11:29:41,931 iteration 229 : loss : 0.164893, loss_ce: 0.055560
2022-01-17 11:29:42,891 iteration 230 : loss : 0.148117, loss_ce: 0.054599
2022-01-17 11:29:43,893 iteration 231 : loss : 0.211631, loss_ce: 0.074826
2022-01-17 11:29:44,889 iteration 232 : loss : 0.159201, loss_ce: 0.063994
2022-01-17 11:29:45,796 iteration 233 : loss : 0.192107, loss_ce: 0.077554
2022-01-17 11:29:46,813 iteration 234 : loss : 0.148630, loss_ce: 0.063322
2022-01-17 11:29:47,733 iteration 235 : loss : 0.141042, loss_ce: 0.063846
2022-01-17 11:29:48,701 iteration 236 : loss : 0.133664, loss_ce: 0.055411
2022-01-17 11:29:49,625 iteration 237 : loss : 0.125700, loss_ce: 0.054780
2022-01-17 11:29:50,575 iteration 238 : loss : 0.112713, loss_ce: 0.052713
  4%|█                             | 14/400 [04:00<1:49:09, 16.97s/it]2022-01-17 11:29:51,508 iteration 239 : loss : 0.165465, loss_ce: 0.055775
2022-01-17 11:29:52,497 iteration 240 : loss : 0.150893, loss_ce: 0.067551
2022-01-17 11:29:53,489 iteration 241 : loss : 0.172635, loss_ce: 0.066567
2022-01-17 11:29:54,456 iteration 242 : loss : 0.157549, loss_ce: 0.086757
2022-01-17 11:29:55,549 iteration 243 : loss : 0.138777, loss_ce: 0.061739
2022-01-17 11:29:56,452 iteration 244 : loss : 0.202389, loss_ce: 0.052897
2022-01-17 11:29:57,422 iteration 245 : loss : 0.160134, loss_ce: 0.080878
2022-01-17 11:29:58,424 iteration 246 : loss : 0.140481, loss_ce: 0.060178
2022-01-17 11:29:59,364 iteration 247 : loss : 0.177870, loss_ce: 0.062223
2022-01-17 11:30:00,292 iteration 248 : loss : 0.129162, loss_ce: 0.041779
2022-01-17 11:30:01,202 iteration 249 : loss : 0.160990, loss_ce: 0.076531
2022-01-17 11:30:02,129 iteration 250 : loss : 0.170712, loss_ce: 0.067880
2022-01-17 11:30:03,004 iteration 251 : loss : 0.163697, loss_ce: 0.054958
2022-01-17 11:30:03,943 iteration 252 : loss : 0.105717, loss_ce: 0.046657
2022-01-17 11:30:04,918 iteration 253 : loss : 0.167020, loss_ce: 0.069566
2022-01-17 11:30:05,953 iteration 254 : loss : 0.235399, loss_ce: 0.075893
2022-01-17 11:30:05,953 Training Data Eval:
2022-01-17 11:30:10,404   Average segmentation loss on training set: 0.1371
2022-01-17 11:30:10,404 Validation Data Eval:
2022-01-17 11:30:11,907   Average segmentation loss on validation set: 0.1842
2022-01-17 11:30:15,568 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 11:30:16,419 iteration 255 : loss : 0.130836, loss_ce: 0.051335
  4%|█▏                            | 15/400 [04:26<2:06:03, 19.64s/it]2022-01-17 11:30:17,371 iteration 256 : loss : 0.150512, loss_ce: 0.061161
2022-01-17 11:30:18,315 iteration 257 : loss : 0.136748, loss_ce: 0.050913
2022-01-17 11:30:19,307 iteration 258 : loss : 0.174541, loss_ce: 0.065839
2022-01-17 11:30:20,107 iteration 259 : loss : 0.107304, loss_ce: 0.047338
2022-01-17 11:30:21,057 iteration 260 : loss : 0.135716, loss_ce: 0.063496
2022-01-17 11:30:21,972 iteration 261 : loss : 0.206362, loss_ce: 0.068832
2022-01-17 11:30:22,974 iteration 262 : loss : 0.126129, loss_ce: 0.053684
2022-01-17 11:30:23,860 iteration 263 : loss : 0.115297, loss_ce: 0.056723
2022-01-17 11:30:24,806 iteration 264 : loss : 0.179668, loss_ce: 0.086799
2022-01-17 11:30:25,694 iteration 265 : loss : 0.127440, loss_ce: 0.053534
2022-01-17 11:30:26,677 iteration 266 : loss : 0.127140, loss_ce: 0.067540
2022-01-17 11:30:27,628 iteration 267 : loss : 0.158249, loss_ce: 0.049077
2022-01-17 11:30:28,592 iteration 268 : loss : 0.165620, loss_ce: 0.074114
2022-01-17 11:30:29,770 iteration 269 : loss : 0.129841, loss_ce: 0.044043
2022-01-17 11:30:30,837 iteration 270 : loss : 0.158214, loss_ce: 0.064719
2022-01-17 11:30:31,665 iteration 271 : loss : 0.144713, loss_ce: 0.042132
2022-01-17 11:30:32,628 iteration 272 : loss : 0.118670, loss_ce: 0.055697
  4%|█▏                            | 16/400 [04:42<1:59:06, 18.61s/it]2022-01-17 11:30:33,576 iteration 273 : loss : 0.118125, loss_ce: 0.047018
2022-01-17 11:30:34,463 iteration 274 : loss : 0.103097, loss_ce: 0.041044
2022-01-17 11:30:35,361 iteration 275 : loss : 0.108665, loss_ce: 0.044915
2022-01-17 11:30:36,324 iteration 276 : loss : 0.115863, loss_ce: 0.054966
2022-01-17 11:30:37,313 iteration 277 : loss : 0.118748, loss_ce: 0.044278
2022-01-17 11:30:38,132 iteration 278 : loss : 0.152074, loss_ce: 0.045426
2022-01-17 11:30:39,028 iteration 279 : loss : 0.167516, loss_ce: 0.061423
2022-01-17 11:30:39,917 iteration 280 : loss : 0.142800, loss_ce: 0.057514
2022-01-17 11:30:40,866 iteration 281 : loss : 0.133077, loss_ce: 0.060072
2022-01-17 11:30:41,797 iteration 282 : loss : 0.115937, loss_ce: 0.046142
2022-01-17 11:30:42,703 iteration 283 : loss : 0.134901, loss_ce: 0.067332
2022-01-17 11:30:43,715 iteration 284 : loss : 0.157568, loss_ce: 0.064791
2022-01-17 11:30:44,601 iteration 285 : loss : 0.147381, loss_ce: 0.051161
2022-01-17 11:30:45,504 iteration 286 : loss : 0.113643, loss_ce: 0.048583
2022-01-17 11:30:46,535 iteration 287 : loss : 0.121340, loss_ce: 0.050210
2022-01-17 11:30:47,545 iteration 288 : loss : 0.158554, loss_ce: 0.059469
2022-01-17 11:30:48,471 iteration 289 : loss : 0.141523, loss_ce: 0.057945
  4%|█▎                            | 17/400 [04:58<1:53:28, 17.78s/it]2022-01-17 11:30:49,471 iteration 290 : loss : 0.116551, loss_ce: 0.044800
2022-01-17 11:30:50,378 iteration 291 : loss : 0.127841, loss_ce: 0.050261
2022-01-17 11:30:51,294 iteration 292 : loss : 0.105548, loss_ce: 0.045879
2022-01-17 11:30:52,218 iteration 293 : loss : 0.102835, loss_ce: 0.041747
2022-01-17 11:30:53,169 iteration 294 : loss : 0.131723, loss_ce: 0.057416
2022-01-17 11:30:54,222 iteration 295 : loss : 0.131527, loss_ce: 0.045475
2022-01-17 11:30:55,142 iteration 296 : loss : 0.100427, loss_ce: 0.035028
2022-01-17 11:30:56,095 iteration 297 : loss : 0.109977, loss_ce: 0.036972
2022-01-17 11:30:57,007 iteration 298 : loss : 0.099326, loss_ce: 0.033288
2022-01-17 11:30:57,981 iteration 299 : loss : 0.112968, loss_ce: 0.046673
2022-01-17 11:30:58,924 iteration 300 : loss : 0.137066, loss_ce: 0.052266
2022-01-17 11:30:59,886 iteration 301 : loss : 0.165948, loss_ce: 0.082206
2022-01-17 11:31:00,904 iteration 302 : loss : 0.120182, loss_ce: 0.047464
2022-01-17 11:31:01,899 iteration 303 : loss : 0.165840, loss_ce: 0.065843
2022-01-17 11:31:02,868 iteration 304 : loss : 0.143976, loss_ce: 0.053688
2022-01-17 11:31:03,869 iteration 305 : loss : 0.106302, loss_ce: 0.044955
2022-01-17 11:31:04,859 iteration 306 : loss : 0.106817, loss_ce: 0.048874
  4%|█▎                            | 18/400 [05:14<1:50:31, 17.36s/it]2022-01-17 11:31:05,860 iteration 307 : loss : 0.133764, loss_ce: 0.048229
2022-01-17 11:31:06,761 iteration 308 : loss : 0.092998, loss_ce: 0.043231
2022-01-17 11:31:07,728 iteration 309 : loss : 0.167481, loss_ce: 0.063969
2022-01-17 11:31:08,719 iteration 310 : loss : 0.143981, loss_ce: 0.065592
2022-01-17 11:31:09,626 iteration 311 : loss : 0.147887, loss_ce: 0.051903
2022-01-17 11:31:10,568 iteration 312 : loss : 0.108231, loss_ce: 0.050007
2022-01-17 11:31:11,530 iteration 313 : loss : 0.161309, loss_ce: 0.080992
2022-01-17 11:31:12,409 iteration 314 : loss : 0.095594, loss_ce: 0.038404
2022-01-17 11:31:13,341 iteration 315 : loss : 0.139441, loss_ce: 0.050241
2022-01-17 11:31:14,304 iteration 316 : loss : 0.126926, loss_ce: 0.046170
2022-01-17 11:31:15,257 iteration 317 : loss : 0.127220, loss_ce: 0.044788
2022-01-17 11:31:16,225 iteration 318 : loss : 0.113541, loss_ce: 0.051604
2022-01-17 11:31:17,115 iteration 319 : loss : 0.133531, loss_ce: 0.050865
2022-01-17 11:31:18,147 iteration 320 : loss : 0.111118, loss_ce: 0.039667
2022-01-17 11:31:19,136 iteration 321 : loss : 0.160703, loss_ce: 0.051243
2022-01-17 11:31:20,085 iteration 322 : loss : 0.196075, loss_ce: 0.088425
2022-01-17 11:31:21,092 iteration 323 : loss : 0.128548, loss_ce: 0.043801
  5%|█▍                            | 19/400 [05:30<1:48:05, 17.02s/it]2022-01-17 11:31:22,065 iteration 324 : loss : 0.124973, loss_ce: 0.045710
2022-01-17 11:31:23,015 iteration 325 : loss : 0.147181, loss_ce: 0.051502
2022-01-17 11:31:24,006 iteration 326 : loss : 0.096886, loss_ce: 0.044390
2022-01-17 11:31:25,075 iteration 327 : loss : 0.106178, loss_ce: 0.043116
2022-01-17 11:31:26,019 iteration 328 : loss : 0.116156, loss_ce: 0.045998
2022-01-17 11:31:27,005 iteration 329 : loss : 0.142434, loss_ce: 0.072636
2022-01-17 11:31:28,003 iteration 330 : loss : 0.110858, loss_ce: 0.038811
2022-01-17 11:31:28,904 iteration 331 : loss : 0.104941, loss_ce: 0.048686
2022-01-17 11:31:29,841 iteration 332 : loss : 0.109641, loss_ce: 0.039278
2022-01-17 11:31:30,815 iteration 333 : loss : 0.099273, loss_ce: 0.043701
2022-01-17 11:31:31,766 iteration 334 : loss : 0.112635, loss_ce: 0.045777
2022-01-17 11:31:32,679 iteration 335 : loss : 0.156256, loss_ce: 0.046976
2022-01-17 11:31:33,679 iteration 336 : loss : 0.106532, loss_ce: 0.039143
2022-01-17 11:31:34,631 iteration 337 : loss : 0.115067, loss_ce: 0.036450
2022-01-17 11:31:35,540 iteration 338 : loss : 0.123130, loss_ce: 0.059055
2022-01-17 11:31:36,459 iteration 339 : loss : 0.120406, loss_ce: 0.042037
2022-01-17 11:31:36,459 Training Data Eval:
2022-01-17 11:31:40,921   Average segmentation loss on training set: 0.0898
2022-01-17 11:31:40,921 Validation Data Eval:
2022-01-17 11:31:42,428   Average segmentation loss on validation set: 0.1559
2022-01-17 11:31:46,095 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 11:31:47,046 iteration 340 : loss : 0.122339, loss_ce: 0.049614
  5%|█▌                            | 20/400 [05:56<2:04:46, 19.70s/it]2022-01-17 11:31:48,029 iteration 341 : loss : 0.085094, loss_ce: 0.040236
2022-01-17 11:31:48,948 iteration 342 : loss : 0.113549, loss_ce: 0.037120
2022-01-17 11:31:49,829 iteration 343 : loss : 0.129789, loss_ce: 0.049123
2022-01-17 11:31:50,755 iteration 344 : loss : 0.152021, loss_ce: 0.056346
2022-01-17 11:31:51,640 iteration 345 : loss : 0.090665, loss_ce: 0.033105
2022-01-17 11:31:52,593 iteration 346 : loss : 0.138513, loss_ce: 0.057803
2022-01-17 11:31:53,424 iteration 347 : loss : 0.117886, loss_ce: 0.056599
2022-01-17 11:31:54,348 iteration 348 : loss : 0.134563, loss_ce: 0.043917
2022-01-17 11:31:55,408 iteration 349 : loss : 0.109436, loss_ce: 0.051294
2022-01-17 11:31:56,333 iteration 350 : loss : 0.091647, loss_ce: 0.037882
2022-01-17 11:31:57,334 iteration 351 : loss : 0.095994, loss_ce: 0.041461
2022-01-17 11:31:58,313 iteration 352 : loss : 0.120381, loss_ce: 0.050672
2022-01-17 11:31:59,209 iteration 353 : loss : 0.106253, loss_ce: 0.039744
2022-01-17 11:32:00,173 iteration 354 : loss : 0.127666, loss_ce: 0.045443
2022-01-17 11:32:01,184 iteration 355 : loss : 0.129116, loss_ce: 0.049277
2022-01-17 11:32:02,278 iteration 356 : loss : 0.120977, loss_ce: 0.046362
2022-01-17 11:32:03,164 iteration 357 : loss : 0.096438, loss_ce: 0.037167
  5%|█▌                            | 21/400 [06:13<1:57:39, 18.63s/it]2022-01-17 11:32:04,195 iteration 358 : loss : 0.104759, loss_ce: 0.043529
2022-01-17 11:32:05,225 iteration 359 : loss : 0.118590, loss_ce: 0.044088
2022-01-17 11:32:06,118 iteration 360 : loss : 0.077296, loss_ce: 0.026607
2022-01-17 11:32:07,111 iteration 361 : loss : 0.145221, loss_ce: 0.042584
2022-01-17 11:32:08,153 iteration 362 : loss : 0.107753, loss_ce: 0.030450
2022-01-17 11:32:09,185 iteration 363 : loss : 0.122701, loss_ce: 0.034934
2022-01-17 11:32:10,155 iteration 364 : loss : 0.100725, loss_ce: 0.036142
2022-01-17 11:32:11,007 iteration 365 : loss : 0.140101, loss_ce: 0.061802
2022-01-17 11:32:12,004 iteration 366 : loss : 0.137489, loss_ce: 0.062264
2022-01-17 11:32:12,891 iteration 367 : loss : 0.127490, loss_ce: 0.048787
2022-01-17 11:32:13,890 iteration 368 : loss : 0.109756, loss_ce: 0.038125
2022-01-17 11:32:14,931 iteration 369 : loss : 0.164129, loss_ce: 0.049591
2022-01-17 11:32:15,944 iteration 370 : loss : 0.107393, loss_ce: 0.053177
2022-01-17 11:32:16,916 iteration 371 : loss : 0.149894, loss_ce: 0.042703
2022-01-17 11:32:17,901 iteration 372 : loss : 0.142327, loss_ce: 0.071397
2022-01-17 11:32:18,801 iteration 373 : loss : 0.134080, loss_ce: 0.042039
2022-01-17 11:32:19,738 iteration 374 : loss : 0.129286, loss_ce: 0.052639
  6%|█▋                            | 22/400 [06:29<1:53:28, 18.01s/it]2022-01-17 11:32:20,797 iteration 375 : loss : 0.167918, loss_ce: 0.074553
2022-01-17 11:32:21,706 iteration 376 : loss : 0.080718, loss_ce: 0.030028
2022-01-17 11:32:22,645 iteration 377 : loss : 0.087609, loss_ce: 0.028551
2022-01-17 11:32:23,675 iteration 378 : loss : 0.117050, loss_ce: 0.045753
2022-01-17 11:32:24,544 iteration 379 : loss : 0.101099, loss_ce: 0.042924
2022-01-17 11:32:25,532 iteration 380 : loss : 0.094361, loss_ce: 0.032965
2022-01-17 11:32:26,490 iteration 381 : loss : 0.084306, loss_ce: 0.028782
2022-01-17 11:32:27,360 iteration 382 : loss : 0.123794, loss_ce: 0.061208
2022-01-17 11:32:28,315 iteration 383 : loss : 0.150773, loss_ce: 0.066053
2022-01-17 11:32:29,294 iteration 384 : loss : 0.100576, loss_ce: 0.042164
2022-01-17 11:32:30,246 iteration 385 : loss : 0.097728, loss_ce: 0.041200
2022-01-17 11:32:31,203 iteration 386 : loss : 0.113336, loss_ce: 0.041695
2022-01-17 11:32:32,188 iteration 387 : loss : 0.146248, loss_ce: 0.051121
2022-01-17 11:32:33,183 iteration 388 : loss : 0.094463, loss_ce: 0.039876
2022-01-17 11:32:34,162 iteration 389 : loss : 0.187617, loss_ce: 0.091838
2022-01-17 11:32:35,095 iteration 390 : loss : 0.083773, loss_ce: 0.033610
2022-01-17 11:32:36,035 iteration 391 : loss : 0.124665, loss_ce: 0.064065
  6%|█▋                            | 23/400 [06:45<1:49:55, 17.49s/it]2022-01-17 11:32:37,062 iteration 392 : loss : 0.087765, loss_ce: 0.040133
2022-01-17 11:32:37,980 iteration 393 : loss : 0.097911, loss_ce: 0.035050
2022-01-17 11:32:38,995 iteration 394 : loss : 0.118397, loss_ce: 0.053639
2022-01-17 11:32:39,979 iteration 395 : loss : 0.143118, loss_ce: 0.066706
2022-01-17 11:32:40,905 iteration 396 : loss : 0.125492, loss_ce: 0.042385
2022-01-17 11:32:41,864 iteration 397 : loss : 0.107098, loss_ce: 0.044336
2022-01-17 11:32:42,844 iteration 398 : loss : 0.066514, loss_ce: 0.027675
2022-01-17 11:32:43,692 iteration 399 : loss : 0.106466, loss_ce: 0.045490
2022-01-17 11:32:44,657 iteration 400 : loss : 0.072968, loss_ce: 0.031708
2022-01-17 11:32:45,674 iteration 401 : loss : 0.128022, loss_ce: 0.060934
2022-01-17 11:32:46,597 iteration 402 : loss : 0.076254, loss_ce: 0.034025
2022-01-17 11:32:47,522 iteration 403 : loss : 0.079708, loss_ce: 0.029766
2022-01-17 11:32:48,502 iteration 404 : loss : 0.092596, loss_ce: 0.043271
2022-01-17 11:32:49,522 iteration 405 : loss : 0.117238, loss_ce: 0.043579
2022-01-17 11:32:50,448 iteration 406 : loss : 0.091003, loss_ce: 0.030705
2022-01-17 11:32:51,333 iteration 407 : loss : 0.092362, loss_ce: 0.031175
2022-01-17 11:32:52,272 iteration 408 : loss : 0.126332, loss_ce: 0.046610
  6%|█▊                            | 24/400 [07:02<1:47:17, 17.12s/it]2022-01-17 11:32:53,309 iteration 409 : loss : 0.107697, loss_ce: 0.047052
2022-01-17 11:32:54,291 iteration 410 : loss : 0.108289, loss_ce: 0.043267
2022-01-17 11:32:55,241 iteration 411 : loss : 0.139274, loss_ce: 0.036867
2022-01-17 11:32:56,096 iteration 412 : loss : 0.095530, loss_ce: 0.044894
2022-01-17 11:32:57,044 iteration 413 : loss : 0.096517, loss_ce: 0.032856
2022-01-17 11:32:57,940 iteration 414 : loss : 0.129443, loss_ce: 0.054183
2022-01-17 11:32:58,780 iteration 415 : loss : 0.073293, loss_ce: 0.028495
2022-01-17 11:32:59,714 iteration 416 : loss : 0.106793, loss_ce: 0.048776
2022-01-17 11:33:00,620 iteration 417 : loss : 0.143377, loss_ce: 0.061131
2022-01-17 11:33:01,634 iteration 418 : loss : 0.117883, loss_ce: 0.050630
2022-01-17 11:33:02,555 iteration 419 : loss : 0.095685, loss_ce: 0.053643
2022-01-17 11:33:03,519 iteration 420 : loss : 0.094551, loss_ce: 0.037299
2022-01-17 11:33:04,417 iteration 421 : loss : 0.127535, loss_ce: 0.048193
2022-01-17 11:33:05,313 iteration 422 : loss : 0.144324, loss_ce: 0.057476
2022-01-17 11:33:06,218 iteration 423 : loss : 0.102875, loss_ce: 0.035079
2022-01-17 11:33:07,183 iteration 424 : loss : 0.132527, loss_ce: 0.067027
2022-01-17 11:33:07,183 Training Data Eval:
2022-01-17 11:33:11,644   Average segmentation loss on training set: 0.0834
2022-01-17 11:33:11,645 Validation Data Eval:
2022-01-17 11:33:13,150   Average segmentation loss on validation set: 0.1536
2022-01-17 11:33:16,907 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 11:33:17,773 iteration 425 : loss : 0.072909, loss_ce: 0.030919
  6%|█▉                            | 25/400 [07:27<2:02:42, 19.63s/it]2022-01-17 11:33:18,647 iteration 426 : loss : 0.082259, loss_ce: 0.028758
2022-01-17 11:33:19,567 iteration 427 : loss : 0.067294, loss_ce: 0.026186
2022-01-17 11:33:20,452 iteration 428 : loss : 0.077405, loss_ce: 0.029669
2022-01-17 11:33:21,280 iteration 429 : loss : 0.139750, loss_ce: 0.077763
2022-01-17 11:33:22,097 iteration 430 : loss : 0.128345, loss_ce: 0.044504
2022-01-17 11:33:22,941 iteration 431 : loss : 0.182844, loss_ce: 0.068596
2022-01-17 11:33:23,862 iteration 432 : loss : 0.071842, loss_ce: 0.030474
2022-01-17 11:33:24,832 iteration 433 : loss : 0.075943, loss_ce: 0.030992
2022-01-17 11:33:25,763 iteration 434 : loss : 0.078459, loss_ce: 0.032012
2022-01-17 11:33:26,635 iteration 435 : loss : 0.074369, loss_ce: 0.029768
2022-01-17 11:33:27,559 iteration 436 : loss : 0.107106, loss_ce: 0.048871
2022-01-17 11:33:28,496 iteration 437 : loss : 0.135600, loss_ce: 0.066034
2022-01-17 11:33:29,376 iteration 438 : loss : 0.138789, loss_ce: 0.049991
2022-01-17 11:33:30,334 iteration 439 : loss : 0.160909, loss_ce: 0.050300
2022-01-17 11:33:31,259 iteration 440 : loss : 0.112932, loss_ce: 0.046717
2022-01-17 11:33:32,255 iteration 441 : loss : 0.113038, loss_ce: 0.045309
2022-01-17 11:33:33,229 iteration 442 : loss : 0.095305, loss_ce: 0.042575
  6%|█▉                            | 26/400 [07:43<1:54:34, 18.38s/it]2022-01-17 11:33:34,192 iteration 443 : loss : 0.098705, loss_ce: 0.045895
2022-01-17 11:33:35,084 iteration 444 : loss : 0.101521, loss_ce: 0.039879
2022-01-17 11:33:36,015 iteration 445 : loss : 0.108471, loss_ce: 0.035138
2022-01-17 11:33:37,091 iteration 446 : loss : 0.145673, loss_ce: 0.052232
2022-01-17 11:33:38,100 iteration 447 : loss : 0.095475, loss_ce: 0.050552
2022-01-17 11:33:39,087 iteration 448 : loss : 0.204170, loss_ce: 0.059717
2022-01-17 11:33:40,034 iteration 449 : loss : 0.085338, loss_ce: 0.037471
2022-01-17 11:33:40,965 iteration 450 : loss : 0.093176, loss_ce: 0.030866
2022-01-17 11:33:41,995 iteration 451 : loss : 0.054063, loss_ce: 0.024190
2022-01-17 11:33:42,973 iteration 452 : loss : 0.066473, loss_ce: 0.026419
2022-01-17 11:33:43,944 iteration 453 : loss : 0.087975, loss_ce: 0.034963
2022-01-17 11:33:44,921 iteration 454 : loss : 0.108759, loss_ce: 0.033729
2022-01-17 11:33:45,937 iteration 455 : loss : 0.077690, loss_ce: 0.030642
2022-01-17 11:33:46,903 iteration 456 : loss : 0.085854, loss_ce: 0.030735
2022-01-17 11:33:47,850 iteration 457 : loss : 0.111286, loss_ce: 0.044924
2022-01-17 11:33:48,876 iteration 458 : loss : 0.123121, loss_ce: 0.056275
2022-01-17 11:33:49,755 iteration 459 : loss : 0.067747, loss_ce: 0.026091
  7%|██                            | 27/400 [07:59<1:50:47, 17.82s/it]2022-01-17 11:33:50,764 iteration 460 : loss : 0.096143, loss_ce: 0.041366
2022-01-17 11:33:51,737 iteration 461 : loss : 0.073718, loss_ce: 0.032997
2022-01-17 11:33:52,680 iteration 462 : loss : 0.091133, loss_ce: 0.041507
2022-01-17 11:33:53,706 iteration 463 : loss : 0.093685, loss_ce: 0.039616
2022-01-17 11:33:54,672 iteration 464 : loss : 0.080825, loss_ce: 0.033845
2022-01-17 11:33:55,579 iteration 465 : loss : 0.097696, loss_ce: 0.031216
2022-01-17 11:33:56,525 iteration 466 : loss : 0.098815, loss_ce: 0.033560
2022-01-17 11:33:57,458 iteration 467 : loss : 0.091503, loss_ce: 0.032719
2022-01-17 11:33:58,518 iteration 468 : loss : 0.090770, loss_ce: 0.038385
2022-01-17 11:33:59,445 iteration 469 : loss : 0.069392, loss_ce: 0.023092
2022-01-17 11:34:00,386 iteration 470 : loss : 0.103738, loss_ce: 0.037878
2022-01-17 11:34:01,327 iteration 471 : loss : 0.090156, loss_ce: 0.030569
2022-01-17 11:34:02,333 iteration 472 : loss : 0.114181, loss_ce: 0.042761
2022-01-17 11:34:03,432 iteration 473 : loss : 0.080154, loss_ce: 0.031858
2022-01-17 11:34:04,481 iteration 474 : loss : 0.146665, loss_ce: 0.058392
2022-01-17 11:34:05,400 iteration 475 : loss : 0.071607, loss_ce: 0.027554
2022-01-17 11:34:06,406 iteration 476 : loss : 0.126411, loss_ce: 0.058471
  7%|██                            | 28/400 [08:16<1:48:19, 17.47s/it]2022-01-17 11:34:07,390 iteration 477 : loss : 0.109130, loss_ce: 0.035670
2022-01-17 11:34:08,383 iteration 478 : loss : 0.069672, loss_ce: 0.024416
2022-01-17 11:34:09,321 iteration 479 : loss : 0.116042, loss_ce: 0.045250
2022-01-17 11:34:10,295 iteration 480 : loss : 0.076938, loss_ce: 0.037342
2022-01-17 11:34:11,165 iteration 481 : loss : 0.091550, loss_ce: 0.039860
2022-01-17 11:34:12,139 iteration 482 : loss : 0.107225, loss_ce: 0.029284
2022-01-17 11:34:13,114 iteration 483 : loss : 0.098931, loss_ce: 0.034884
2022-01-17 11:34:14,106 iteration 484 : loss : 0.119039, loss_ce: 0.048128
2022-01-17 11:34:15,035 iteration 485 : loss : 0.087901, loss_ce: 0.041360
2022-01-17 11:34:15,962 iteration 486 : loss : 0.100042, loss_ce: 0.035007
2022-01-17 11:34:16,969 iteration 487 : loss : 0.086562, loss_ce: 0.037529
2022-01-17 11:34:17,862 iteration 488 : loss : 0.092435, loss_ce: 0.035929
2022-01-17 11:34:18,823 iteration 489 : loss : 0.092325, loss_ce: 0.037421
2022-01-17 11:34:19,667 iteration 490 : loss : 0.066622, loss_ce: 0.023763
2022-01-17 11:34:20,630 iteration 491 : loss : 0.084860, loss_ce: 0.039725
2022-01-17 11:34:21,565 iteration 492 : loss : 0.063825, loss_ce: 0.030984
2022-01-17 11:34:22,552 iteration 493 : loss : 0.086295, loss_ce: 0.038678
  7%|██▏                           | 29/400 [08:32<1:45:34, 17.07s/it]2022-01-17 11:34:23,545 iteration 494 : loss : 0.072476, loss_ce: 0.031313
2022-01-17 11:34:24,540 iteration 495 : loss : 0.105819, loss_ce: 0.037446
2022-01-17 11:34:25,488 iteration 496 : loss : 0.093559, loss_ce: 0.047589
2022-01-17 11:34:26,476 iteration 497 : loss : 0.116659, loss_ce: 0.050922
2022-01-17 11:34:27,503 iteration 498 : loss : 0.088113, loss_ce: 0.037730
2022-01-17 11:34:28,386 iteration 499 : loss : 0.087647, loss_ce: 0.039980
2022-01-17 11:34:29,290 iteration 500 : loss : 0.077974, loss_ce: 0.025946
2022-01-17 11:34:30,196 iteration 501 : loss : 0.093981, loss_ce: 0.043131
2022-01-17 11:34:31,217 iteration 502 : loss : 0.079377, loss_ce: 0.031457
2022-01-17 11:34:32,126 iteration 503 : loss : 0.114077, loss_ce: 0.035348
2022-01-17 11:34:33,103 iteration 504 : loss : 0.093101, loss_ce: 0.032023
2022-01-17 11:34:34,014 iteration 505 : loss : 0.054330, loss_ce: 0.021280
2022-01-17 11:34:35,062 iteration 506 : loss : 0.113143, loss_ce: 0.042670
2022-01-17 11:34:36,022 iteration 507 : loss : 0.110430, loss_ce: 0.035515
2022-01-17 11:34:36,982 iteration 508 : loss : 0.132123, loss_ce: 0.057795
2022-01-17 11:34:37,992 iteration 509 : loss : 0.096998, loss_ce: 0.032753
2022-01-17 11:34:37,992 Training Data Eval:
2022-01-17 11:34:42,451   Average segmentation loss on training set: 0.0729
2022-01-17 11:34:42,451 Validation Data Eval:
2022-01-17 11:34:43,960   Average segmentation loss on validation set: 0.1183
2022-01-17 11:34:47,659 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 11:34:48,607 iteration 510 : loss : 0.076602, loss_ce: 0.029484
  8%|██▎                           | 30/400 [08:58<2:01:53, 19.77s/it]2022-01-17 11:34:49,555 iteration 511 : loss : 0.122972, loss_ce: 0.059923
2022-01-17 11:34:50,389 iteration 512 : loss : 0.107358, loss_ce: 0.040451
2022-01-17 11:34:51,246 iteration 513 : loss : 0.057752, loss_ce: 0.020965
2022-01-17 11:34:52,127 iteration 514 : loss : 0.074065, loss_ce: 0.030154
2022-01-17 11:34:52,986 iteration 515 : loss : 0.127040, loss_ce: 0.060692
2022-01-17 11:34:53,896 iteration 516 : loss : 0.088902, loss_ce: 0.034923
2022-01-17 11:34:54,849 iteration 517 : loss : 0.082030, loss_ce: 0.040990
2022-01-17 11:34:55,690 iteration 518 : loss : 0.100995, loss_ce: 0.033922
2022-01-17 11:34:56,617 iteration 519 : loss : 0.088856, loss_ce: 0.042779
2022-01-17 11:34:57,504 iteration 520 : loss : 0.085239, loss_ce: 0.046213
2022-01-17 11:34:58,457 iteration 521 : loss : 0.088192, loss_ce: 0.032619
2022-01-17 11:34:59,461 iteration 522 : loss : 0.089962, loss_ce: 0.032105
2022-01-17 11:35:00,493 iteration 523 : loss : 0.110953, loss_ce: 0.051170
2022-01-17 11:35:01,551 iteration 524 : loss : 0.080893, loss_ce: 0.032701
2022-01-17 11:35:02,512 iteration 525 : loss : 0.137359, loss_ce: 0.073094
2022-01-17 11:35:03,458 iteration 526 : loss : 0.078876, loss_ce: 0.034016
2022-01-17 11:35:04,411 iteration 527 : loss : 0.077095, loss_ce: 0.031192
  8%|██▎                           | 31/400 [09:14<1:54:15, 18.58s/it]2022-01-17 11:35:05,379 iteration 528 : loss : 0.073049, loss_ce: 0.033779
2022-01-17 11:35:06,344 iteration 529 : loss : 0.095879, loss_ce: 0.034488
2022-01-17 11:35:07,259 iteration 530 : loss : 0.087179, loss_ce: 0.029818
2022-01-17 11:35:08,156 iteration 531 : loss : 0.085165, loss_ce: 0.026564
2022-01-17 11:35:09,072 iteration 532 : loss : 0.124158, loss_ce: 0.057011
2022-01-17 11:35:10,132 iteration 533 : loss : 0.072201, loss_ce: 0.032132
2022-01-17 11:35:11,024 iteration 534 : loss : 0.081899, loss_ce: 0.032512
2022-01-17 11:35:12,023 iteration 535 : loss : 0.081555, loss_ce: 0.028010
2022-01-17 11:35:13,056 iteration 536 : loss : 0.094681, loss_ce: 0.044435
2022-01-17 11:35:14,106 iteration 537 : loss : 0.099361, loss_ce: 0.034513
2022-01-17 11:35:15,073 iteration 538 : loss : 0.074176, loss_ce: 0.033336
2022-01-17 11:35:16,005 iteration 539 : loss : 0.070158, loss_ce: 0.030734
2022-01-17 11:35:16,979 iteration 540 : loss : 0.094913, loss_ce: 0.032613
2022-01-17 11:35:17,914 iteration 541 : loss : 0.067316, loss_ce: 0.029717
2022-01-17 11:35:18,868 iteration 542 : loss : 0.063833, loss_ce: 0.028419
2022-01-17 11:35:19,765 iteration 543 : loss : 0.049409, loss_ce: 0.020320
2022-01-17 11:35:20,699 iteration 544 : loss : 0.057739, loss_ce: 0.020378
  8%|██▍                           | 32/400 [09:30<1:49:44, 17.89s/it]2022-01-17 11:35:21,710 iteration 545 : loss : 0.062364, loss_ce: 0.031252
2022-01-17 11:35:22,657 iteration 546 : loss : 0.079669, loss_ce: 0.030370
2022-01-17 11:35:23,611 iteration 547 : loss : 0.087550, loss_ce: 0.038318
2022-01-17 11:35:24,546 iteration 548 : loss : 0.134907, loss_ce: 0.046679
2022-01-17 11:35:25,518 iteration 549 : loss : 0.063957, loss_ce: 0.027515
2022-01-17 11:35:26,431 iteration 550 : loss : 0.068283, loss_ce: 0.023276
2022-01-17 11:35:27,373 iteration 551 : loss : 0.067810, loss_ce: 0.027196
2022-01-17 11:35:28,293 iteration 552 : loss : 0.060024, loss_ce: 0.022313
2022-01-17 11:35:29,276 iteration 553 : loss : 0.088682, loss_ce: 0.040295
2022-01-17 11:35:30,162 iteration 554 : loss : 0.066963, loss_ce: 0.029483
2022-01-17 11:35:31,105 iteration 555 : loss : 0.078040, loss_ce: 0.023575
2022-01-17 11:35:32,095 iteration 556 : loss : 0.076894, loss_ce: 0.037144
2022-01-17 11:35:32,963 iteration 557 : loss : 0.068270, loss_ce: 0.023761
2022-01-17 11:35:33,950 iteration 558 : loss : 0.087112, loss_ce: 0.027793
2022-01-17 11:35:34,897 iteration 559 : loss : 0.073580, loss_ce: 0.027950
2022-01-17 11:35:35,865 iteration 560 : loss : 0.110441, loss_ce: 0.031469
2022-01-17 11:35:36,854 iteration 561 : loss : 0.099091, loss_ce: 0.050661
  8%|██▍                           | 33/400 [09:46<1:46:15, 17.37s/it]2022-01-17 11:35:37,955 iteration 562 : loss : 0.101028, loss_ce: 0.046524
2022-01-17 11:35:38,801 iteration 563 : loss : 0.067436, loss_ce: 0.027863
2022-01-17 11:35:39,770 iteration 564 : loss : 0.064556, loss_ce: 0.035848
2022-01-17 11:35:40,738 iteration 565 : loss : 0.068008, loss_ce: 0.026345
2022-01-17 11:35:41,742 iteration 566 : loss : 0.072770, loss_ce: 0.030351
2022-01-17 11:35:42,666 iteration 567 : loss : 0.067991, loss_ce: 0.021542
2022-01-17 11:35:43,582 iteration 568 : loss : 0.168246, loss_ce: 0.064249
2022-01-17 11:35:44,537 iteration 569 : loss : 0.070574, loss_ce: 0.026024
2022-01-17 11:35:45,532 iteration 570 : loss : 0.072288, loss_ce: 0.037068
2022-01-17 11:35:46,464 iteration 571 : loss : 0.114461, loss_ce: 0.042503
2022-01-17 11:35:47,438 iteration 572 : loss : 0.079610, loss_ce: 0.027550
2022-01-17 11:35:48,360 iteration 573 : loss : 0.068682, loss_ce: 0.025380
2022-01-17 11:35:49,312 iteration 574 : loss : 0.063007, loss_ce: 0.023347
2022-01-17 11:35:50,326 iteration 575 : loss : 0.076645, loss_ce: 0.025560
2022-01-17 11:35:51,322 iteration 576 : loss : 0.094401, loss_ce: 0.035790
2022-01-17 11:35:52,275 iteration 577 : loss : 0.057079, loss_ce: 0.026824
2022-01-17 11:35:53,184 iteration 578 : loss : 0.067510, loss_ce: 0.028556
  8%|██▌                           | 34/400 [10:03<1:44:03, 17.06s/it]2022-01-17 11:35:54,351 iteration 579 : loss : 0.086446, loss_ce: 0.041772
2022-01-17 11:35:55,312 iteration 580 : loss : 0.093185, loss_ce: 0.038625
2022-01-17 11:35:56,304 iteration 581 : loss : 0.105378, loss_ce: 0.032483
2022-01-17 11:35:57,237 iteration 582 : loss : 0.091844, loss_ce: 0.034660
2022-01-17 11:35:58,187 iteration 583 : loss : 0.132514, loss_ce: 0.036641
2022-01-17 11:35:59,098 iteration 584 : loss : 0.053137, loss_ce: 0.021622
2022-01-17 11:36:00,110 iteration 585 : loss : 0.064699, loss_ce: 0.027342
2022-01-17 11:36:01,022 iteration 586 : loss : 0.099395, loss_ce: 0.037187
2022-01-17 11:36:01,930 iteration 587 : loss : 0.055473, loss_ce: 0.026161
2022-01-17 11:36:02,908 iteration 588 : loss : 0.078581, loss_ce: 0.030305
2022-01-17 11:36:03,846 iteration 589 : loss : 0.070581, loss_ce: 0.028594
2022-01-17 11:36:04,801 iteration 590 : loss : 0.076247, loss_ce: 0.027527
2022-01-17 11:36:05,761 iteration 591 : loss : 0.086539, loss_ce: 0.035836
2022-01-17 11:36:06,716 iteration 592 : loss : 0.063933, loss_ce: 0.025729
2022-01-17 11:36:07,706 iteration 593 : loss : 0.059806, loss_ce: 0.022417
2022-01-17 11:36:08,677 iteration 594 : loss : 0.090157, loss_ce: 0.038151
2022-01-17 11:36:08,677 Training Data Eval:
2022-01-17 11:36:13,122   Average segmentation loss on training set: 0.0659
2022-01-17 11:36:13,123 Validation Data Eval:
2022-01-17 11:36:14,626   Average segmentation loss on validation set: 0.0976
2022-01-17 11:36:18,285 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 11:36:19,272 iteration 595 : loss : 0.089861, loss_ce: 0.046335
  9%|██▋                           | 35/400 [10:29<2:00:15, 19.77s/it]2022-01-17 11:36:20,213 iteration 596 : loss : 0.062581, loss_ce: 0.024099
2022-01-17 11:36:21,065 iteration 597 : loss : 0.099401, loss_ce: 0.029756
2022-01-17 11:36:21,902 iteration 598 : loss : 0.048688, loss_ce: 0.017484
2022-01-17 11:36:22,768 iteration 599 : loss : 0.081046, loss_ce: 0.035303
2022-01-17 11:36:23,631 iteration 600 : loss : 0.078528, loss_ce: 0.036951
2022-01-17 11:36:24,529 iteration 601 : loss : 0.063453, loss_ce: 0.024158
2022-01-17 11:36:25,437 iteration 602 : loss : 0.058706, loss_ce: 0.024622
2022-01-17 11:36:26,266 iteration 603 : loss : 0.068571, loss_ce: 0.025180
2022-01-17 11:36:27,145 iteration 604 : loss : 0.060071, loss_ce: 0.023888
2022-01-17 11:36:28,029 iteration 605 : loss : 0.064441, loss_ce: 0.022912
2022-01-17 11:36:29,120 iteration 606 : loss : 0.074506, loss_ce: 0.033069
2022-01-17 11:36:30,056 iteration 607 : loss : 0.066847, loss_ce: 0.029067
2022-01-17 11:36:31,004 iteration 608 : loss : 0.078021, loss_ce: 0.039938
2022-01-17 11:36:31,873 iteration 609 : loss : 0.061821, loss_ce: 0.024236
2022-01-17 11:36:32,873 iteration 610 : loss : 0.060098, loss_ce: 0.026463
2022-01-17 11:36:33,930 iteration 611 : loss : 0.070370, loss_ce: 0.032533
2022-01-17 11:36:34,909 iteration 612 : loss : 0.073653, loss_ce: 0.023230
  9%|██▋                           | 36/400 [10:44<1:52:24, 18.53s/it]2022-01-17 11:36:35,942 iteration 613 : loss : 0.057512, loss_ce: 0.024057
2022-01-17 11:36:36,860 iteration 614 : loss : 0.080323, loss_ce: 0.028955
2022-01-17 11:36:37,764 iteration 615 : loss : 0.101894, loss_ce: 0.047268
2022-01-17 11:36:38,798 iteration 616 : loss : 0.068686, loss_ce: 0.029990
2022-01-17 11:36:39,714 iteration 617 : loss : 0.072763, loss_ce: 0.031432
2022-01-17 11:36:40,677 iteration 618 : loss : 0.101967, loss_ce: 0.027598
2022-01-17 11:36:41,640 iteration 619 : loss : 0.128821, loss_ce: 0.047098
2022-01-17 11:36:42,696 iteration 620 : loss : 0.200592, loss_ce: 0.053717
2022-01-17 11:36:43,656 iteration 621 : loss : 0.085095, loss_ce: 0.026016
2022-01-17 11:36:44,733 iteration 622 : loss : 0.098652, loss_ce: 0.035720
2022-01-17 11:36:45,781 iteration 623 : loss : 0.113827, loss_ce: 0.054350
2022-01-17 11:36:46,716 iteration 624 : loss : 0.090752, loss_ce: 0.031679
2022-01-17 11:36:47,614 iteration 625 : loss : 0.068498, loss_ce: 0.028344
2022-01-17 11:36:48,611 iteration 626 : loss : 0.086949, loss_ce: 0.040510
2022-01-17 11:36:49,610 iteration 627 : loss : 0.123900, loss_ce: 0.041247
2022-01-17 11:36:50,655 iteration 628 : loss : 0.064430, loss_ce: 0.026347
2022-01-17 11:36:51,578 iteration 629 : loss : 0.068274, loss_ce: 0.027891
  9%|██▊                           | 37/400 [11:01<1:48:43, 17.97s/it]2022-01-17 11:36:52,596 iteration 630 : loss : 0.071328, loss_ce: 0.032797
2022-01-17 11:36:53,514 iteration 631 : loss : 0.041613, loss_ce: 0.018289
2022-01-17 11:36:54,434 iteration 632 : loss : 0.103297, loss_ce: 0.045741
2022-01-17 11:36:55,460 iteration 633 : loss : 0.065074, loss_ce: 0.025289
2022-01-17 11:36:56,421 iteration 634 : loss : 0.087386, loss_ce: 0.027141
2022-01-17 11:36:57,479 iteration 635 : loss : 0.093931, loss_ce: 0.039725
2022-01-17 11:36:58,456 iteration 636 : loss : 0.108049, loss_ce: 0.038552
2022-01-17 11:36:59,334 iteration 637 : loss : 0.078020, loss_ce: 0.034053
2022-01-17 11:37:00,378 iteration 638 : loss : 0.116954, loss_ce: 0.034611
2022-01-17 11:37:01,298 iteration 639 : loss : 0.066320, loss_ce: 0.028667
2022-01-17 11:37:02,190 iteration 640 : loss : 0.134832, loss_ce: 0.037341
2022-01-17 11:37:03,083 iteration 641 : loss : 0.078157, loss_ce: 0.033553
2022-01-17 11:37:03,989 iteration 642 : loss : 0.083251, loss_ce: 0.026427
2022-01-17 11:37:04,927 iteration 643 : loss : 0.078970, loss_ce: 0.031220
2022-01-17 11:37:05,874 iteration 644 : loss : 0.098777, loss_ce: 0.039997
2022-01-17 11:37:06,783 iteration 645 : loss : 0.076836, loss_ce: 0.020066
2022-01-17 11:37:07,802 iteration 646 : loss : 0.070818, loss_ce: 0.028932
 10%|██▊                           | 38/400 [11:17<1:45:15, 17.45s/it]2022-01-17 11:37:08,773 iteration 647 : loss : 0.091518, loss_ce: 0.035448
2022-01-17 11:37:09,720 iteration 648 : loss : 0.060255, loss_ce: 0.025189
2022-01-17 11:37:10,698 iteration 649 : loss : 0.076817, loss_ce: 0.032476
2022-01-17 11:37:11,720 iteration 650 : loss : 0.092952, loss_ce: 0.039317
2022-01-17 11:37:12,656 iteration 651 : loss : 0.068605, loss_ce: 0.026748
2022-01-17 11:37:13,500 iteration 652 : loss : 0.062170, loss_ce: 0.022639
2022-01-17 11:37:14,528 iteration 653 : loss : 0.092594, loss_ce: 0.033767
2022-01-17 11:37:15,432 iteration 654 : loss : 0.084429, loss_ce: 0.031578
2022-01-17 11:37:16,386 iteration 655 : loss : 0.087182, loss_ce: 0.031938
2022-01-17 11:37:17,352 iteration 656 : loss : 0.062094, loss_ce: 0.024395
2022-01-17 11:37:18,388 iteration 657 : loss : 0.053537, loss_ce: 0.018791
2022-01-17 11:37:19,368 iteration 658 : loss : 0.074757, loss_ce: 0.026710
2022-01-17 11:37:20,354 iteration 659 : loss : 0.105409, loss_ce: 0.043174
2022-01-17 11:37:21,274 iteration 660 : loss : 0.054247, loss_ce: 0.025644
2022-01-17 11:37:22,259 iteration 661 : loss : 0.074117, loss_ce: 0.032623
2022-01-17 11:37:23,315 iteration 662 : loss : 0.087698, loss_ce: 0.028241
2022-01-17 11:37:24,275 iteration 663 : loss : 0.083105, loss_ce: 0.033956
 10%|██▉                           | 39/400 [11:34<1:43:11, 17.15s/it]2022-01-17 11:37:25,300 iteration 664 : loss : 0.062106, loss_ce: 0.026020
2022-01-17 11:37:26,177 iteration 665 : loss : 0.055143, loss_ce: 0.028351
2022-01-17 11:37:27,119 iteration 666 : loss : 0.040550, loss_ce: 0.012991
2022-01-17 11:37:28,105 iteration 667 : loss : 0.055536, loss_ce: 0.023984
2022-01-17 11:37:29,058 iteration 668 : loss : 0.084348, loss_ce: 0.032535
2022-01-17 11:37:29,980 iteration 669 : loss : 0.075907, loss_ce: 0.028961
2022-01-17 11:37:31,058 iteration 670 : loss : 0.079782, loss_ce: 0.032062
2022-01-17 11:37:31,984 iteration 671 : loss : 0.078527, loss_ce: 0.026199
2022-01-17 11:37:33,004 iteration 672 : loss : 0.070629, loss_ce: 0.023568
2022-01-17 11:37:33,991 iteration 673 : loss : 0.066213, loss_ce: 0.029610
2022-01-17 11:37:34,966 iteration 674 : loss : 0.059938, loss_ce: 0.032648
2022-01-17 11:37:35,978 iteration 675 : loss : 0.120946, loss_ce: 0.051342
2022-01-17 11:37:36,928 iteration 676 : loss : 0.073984, loss_ce: 0.030906
2022-01-17 11:37:37,888 iteration 677 : loss : 0.054255, loss_ce: 0.024122
2022-01-17 11:37:38,873 iteration 678 : loss : 0.080877, loss_ce: 0.029180
2022-01-17 11:37:39,843 iteration 679 : loss : 0.083273, loss_ce: 0.037274
2022-01-17 11:37:39,843 Training Data Eval:
2022-01-17 11:37:44,307   Average segmentation loss on training set: 0.0650
2022-01-17 11:37:44,307 Validation Data Eval:
2022-01-17 11:37:45,812   Average segmentation loss on validation set: 0.1741
2022-01-17 11:37:46,772 iteration 680 : loss : 0.062927, loss_ce: 0.023044
 10%|███                           | 40/400 [11:56<1:52:32, 18.76s/it]2022-01-17 11:37:47,799 iteration 681 : loss : 0.060167, loss_ce: 0.022859
2022-01-17 11:37:48,675 iteration 682 : loss : 0.117027, loss_ce: 0.033513
2022-01-17 11:37:49,630 iteration 683 : loss : 0.070548, loss_ce: 0.030930
2022-01-17 11:37:50,542 iteration 684 : loss : 0.077052, loss_ce: 0.030667
2022-01-17 11:37:51,558 iteration 685 : loss : 0.062917, loss_ce: 0.026526
2022-01-17 11:37:52,517 iteration 686 : loss : 0.092814, loss_ce: 0.037948
2022-01-17 11:37:53,472 iteration 687 : loss : 0.068946, loss_ce: 0.029058
2022-01-17 11:37:54,401 iteration 688 : loss : 0.061467, loss_ce: 0.020239
2022-01-17 11:37:55,381 iteration 689 : loss : 0.065774, loss_ce: 0.031508
2022-01-17 11:37:56,327 iteration 690 : loss : 0.064585, loss_ce: 0.020907
2022-01-17 11:37:57,291 iteration 691 : loss : 0.063373, loss_ce: 0.027345
2022-01-17 11:37:58,308 iteration 692 : loss : 0.063165, loss_ce: 0.022563
2022-01-17 11:37:59,205 iteration 693 : loss : 0.066650, loss_ce: 0.029999
2022-01-17 11:38:00,174 iteration 694 : loss : 0.087201, loss_ce: 0.036321
2022-01-17 11:38:01,089 iteration 695 : loss : 0.070981, loss_ce: 0.028602
2022-01-17 11:38:02,104 iteration 696 : loss : 0.063374, loss_ce: 0.028353
2022-01-17 11:38:03,051 iteration 697 : loss : 0.068440, loss_ce: 0.026875
 10%|███                           | 41/400 [12:12<1:47:47, 18.02s/it]2022-01-17 11:38:04,009 iteration 698 : loss : 0.075430, loss_ce: 0.023875
2022-01-17 11:38:05,010 iteration 699 : loss : 0.097145, loss_ce: 0.048396
2022-01-17 11:38:05,947 iteration 700 : loss : 0.072261, loss_ce: 0.033915
2022-01-17 11:38:06,876 iteration 701 : loss : 0.077323, loss_ce: 0.038268
2022-01-17 11:38:07,869 iteration 702 : loss : 0.086312, loss_ce: 0.030304
2022-01-17 11:38:08,912 iteration 703 : loss : 0.039896, loss_ce: 0.017877
2022-01-17 11:38:09,794 iteration 704 : loss : 0.057590, loss_ce: 0.022650
2022-01-17 11:38:10,747 iteration 705 : loss : 0.076065, loss_ce: 0.029207
2022-01-17 11:38:11,709 iteration 706 : loss : 0.087785, loss_ce: 0.035001
2022-01-17 11:38:12,591 iteration 707 : loss : 0.045528, loss_ce: 0.020577
2022-01-17 11:38:13,536 iteration 708 : loss : 0.044594, loss_ce: 0.015979
2022-01-17 11:38:14,484 iteration 709 : loss : 0.112582, loss_ce: 0.056987
2022-01-17 11:38:15,474 iteration 710 : loss : 0.060332, loss_ce: 0.021137
2022-01-17 11:38:16,447 iteration 711 : loss : 0.064640, loss_ce: 0.028577
2022-01-17 11:38:17,487 iteration 712 : loss : 0.066644, loss_ce: 0.025597
2022-01-17 11:38:18,421 iteration 713 : loss : 0.055769, loss_ce: 0.022339
2022-01-17 11:38:19,441 iteration 714 : loss : 0.089690, loss_ce: 0.031174
 10%|███▏                          | 42/400 [12:29<1:44:35, 17.53s/it]2022-01-17 11:38:20,484 iteration 715 : loss : 0.056899, loss_ce: 0.021545
2022-01-17 11:38:21,480 iteration 716 : loss : 0.043137, loss_ce: 0.018721
2022-01-17 11:38:22,428 iteration 717 : loss : 0.069418, loss_ce: 0.026292
2022-01-17 11:38:23,401 iteration 718 : loss : 0.070441, loss_ce: 0.032411
2022-01-17 11:38:24,418 iteration 719 : loss : 0.076539, loss_ce: 0.026177
2022-01-17 11:38:25,366 iteration 720 : loss : 0.089749, loss_ce: 0.032513
2022-01-17 11:38:26,308 iteration 721 : loss : 0.070304, loss_ce: 0.021982
2022-01-17 11:38:27,244 iteration 722 : loss : 0.076735, loss_ce: 0.024646
2022-01-17 11:38:28,240 iteration 723 : loss : 0.091608, loss_ce: 0.047688
2022-01-17 11:38:29,169 iteration 724 : loss : 0.088098, loss_ce: 0.034680
2022-01-17 11:38:30,186 iteration 725 : loss : 0.076921, loss_ce: 0.025443
2022-01-17 11:38:31,129 iteration 726 : loss : 0.060850, loss_ce: 0.024755
2022-01-17 11:38:32,006 iteration 727 : loss : 0.052396, loss_ce: 0.020193
2022-01-17 11:38:32,992 iteration 728 : loss : 0.076670, loss_ce: 0.028037
2022-01-17 11:38:33,993 iteration 729 : loss : 0.071942, loss_ce: 0.029080
2022-01-17 11:38:34,964 iteration 730 : loss : 0.060549, loss_ce: 0.023813
2022-01-17 11:38:35,830 iteration 731 : loss : 0.051815, loss_ce: 0.020899
 11%|███▏                          | 43/400 [12:45<1:42:15, 17.19s/it]2022-01-17 11:38:36,764 iteration 732 : loss : 0.057004, loss_ce: 0.026385
2022-01-17 11:38:37,636 iteration 733 : loss : 0.064393, loss_ce: 0.031081
2022-01-17 11:38:38,633 iteration 734 : loss : 0.056800, loss_ce: 0.021541
2022-01-17 11:38:39,574 iteration 735 : loss : 0.080947, loss_ce: 0.029360
2022-01-17 11:38:40,491 iteration 736 : loss : 0.053057, loss_ce: 0.019790
2022-01-17 11:38:41,570 iteration 737 : loss : 0.068437, loss_ce: 0.030147
2022-01-17 11:38:42,436 iteration 738 : loss : 0.050545, loss_ce: 0.021404
2022-01-17 11:38:43,419 iteration 739 : loss : 0.063028, loss_ce: 0.024445
2022-01-17 11:38:44,346 iteration 740 : loss : 0.047189, loss_ce: 0.018522
2022-01-17 11:38:45,256 iteration 741 : loss : 0.052972, loss_ce: 0.020728
2022-01-17 11:38:46,125 iteration 742 : loss : 0.058869, loss_ce: 0.027941
2022-01-17 11:38:47,079 iteration 743 : loss : 0.055902, loss_ce: 0.021076
2022-01-17 11:38:48,058 iteration 744 : loss : 0.050968, loss_ce: 0.019972
2022-01-17 11:38:48,968 iteration 745 : loss : 0.107129, loss_ce: 0.024069
2022-01-17 11:38:49,888 iteration 746 : loss : 0.063318, loss_ce: 0.023751
2022-01-17 11:38:50,800 iteration 747 : loss : 0.061243, loss_ce: 0.023194
2022-01-17 11:38:51,697 iteration 748 : loss : 0.067952, loss_ce: 0.030080
 11%|███▎                          | 44/400 [13:01<1:39:37, 16.79s/it]2022-01-17 11:38:52,627 iteration 749 : loss : 0.125925, loss_ce: 0.020427
2022-01-17 11:38:53,555 iteration 750 : loss : 0.063816, loss_ce: 0.024157
2022-01-17 11:38:54,521 iteration 751 : loss : 0.054301, loss_ce: 0.016265
2022-01-17 11:38:55,449 iteration 752 : loss : 0.116992, loss_ce: 0.053816
2022-01-17 11:38:56,343 iteration 753 : loss : 0.090216, loss_ce: 0.036261
2022-01-17 11:38:57,243 iteration 754 : loss : 0.088107, loss_ce: 0.031431
2022-01-17 11:38:58,095 iteration 755 : loss : 0.071382, loss_ce: 0.035289
2022-01-17 11:38:58,960 iteration 756 : loss : 0.055711, loss_ce: 0.018372
2022-01-17 11:38:59,895 iteration 757 : loss : 0.094625, loss_ce: 0.048143
2022-01-17 11:39:00,937 iteration 758 : loss : 0.065469, loss_ce: 0.030504
2022-01-17 11:39:02,028 iteration 759 : loss : 0.100768, loss_ce: 0.034293
2022-01-17 11:39:02,961 iteration 760 : loss : 0.074263, loss_ce: 0.036801
2022-01-17 11:39:03,943 iteration 761 : loss : 0.060806, loss_ce: 0.027996
2022-01-17 11:39:04,939 iteration 762 : loss : 0.089168, loss_ce: 0.035677
2022-01-17 11:39:05,938 iteration 763 : loss : 0.055734, loss_ce: 0.020502
2022-01-17 11:39:06,853 iteration 764 : loss : 0.060738, loss_ce: 0.025881
2022-01-17 11:39:06,854 Training Data Eval:
2022-01-17 11:39:11,307   Average segmentation loss on training set: 0.0535
2022-01-17 11:39:11,307 Validation Data Eval:
2022-01-17 11:39:12,808   Average segmentation loss on validation set: 0.1180
2022-01-17 11:39:13,933 iteration 765 : loss : 0.084740, loss_ce: 0.031003
 11%|███▍                          | 45/400 [13:23<1:49:00, 18.42s/it]2022-01-17 11:39:14,982 iteration 766 : loss : 0.089366, loss_ce: 0.028966
2022-01-17 11:39:15,969 iteration 767 : loss : 0.073047, loss_ce: 0.028146
2022-01-17 11:39:16,943 iteration 768 : loss : 0.055662, loss_ce: 0.019414
2022-01-17 11:39:17,939 iteration 769 : loss : 0.074305, loss_ce: 0.029900
2022-01-17 11:39:18,810 iteration 770 : loss : 0.055530, loss_ce: 0.021072
2022-01-17 11:39:19,773 iteration 771 : loss : 0.085893, loss_ce: 0.026265
2022-01-17 11:39:20,740 iteration 772 : loss : 0.051050, loss_ce: 0.017227
2022-01-17 11:39:21,722 iteration 773 : loss : 0.062002, loss_ce: 0.014014
2022-01-17 11:39:22,791 iteration 774 : loss : 0.070900, loss_ce: 0.030300
2022-01-17 11:39:23,711 iteration 775 : loss : 0.083968, loss_ce: 0.041327
2022-01-17 11:39:24,615 iteration 776 : loss : 0.063207, loss_ce: 0.020107
2022-01-17 11:39:25,748 iteration 777 : loss : 0.094353, loss_ce: 0.048803
2022-01-17 11:39:26,625 iteration 778 : loss : 0.120077, loss_ce: 0.039716
2022-01-17 11:39:27,639 iteration 779 : loss : 0.080504, loss_ce: 0.034075
2022-01-17 11:39:28,650 iteration 780 : loss : 0.077622, loss_ce: 0.028516
2022-01-17 11:39:29,554 iteration 781 : loss : 0.062199, loss_ce: 0.034902
2022-01-17 11:39:30,419 iteration 782 : loss : 0.051952, loss_ce: 0.025190
 12%|███▍                          | 46/400 [13:40<1:45:16, 17.84s/it]2022-01-17 11:39:31,396 iteration 783 : loss : 0.077109, loss_ce: 0.036875
2022-01-17 11:39:32,308 iteration 784 : loss : 0.082055, loss_ce: 0.029128
2022-01-17 11:39:33,267 iteration 785 : loss : 0.082851, loss_ce: 0.036072
2022-01-17 11:39:34,195 iteration 786 : loss : 0.085305, loss_ce: 0.031827
2022-01-17 11:39:35,135 iteration 787 : loss : 0.071583, loss_ce: 0.025880
2022-01-17 11:39:36,146 iteration 788 : loss : 0.079214, loss_ce: 0.038553
2022-01-17 11:39:37,009 iteration 789 : loss : 0.077155, loss_ce: 0.024425
2022-01-17 11:39:38,013 iteration 790 : loss : 0.078802, loss_ce: 0.024037
2022-01-17 11:39:38,960 iteration 791 : loss : 0.062152, loss_ce: 0.025682
2022-01-17 11:39:39,853 iteration 792 : loss : 0.045912, loss_ce: 0.019538
2022-01-17 11:39:40,874 iteration 793 : loss : 0.059496, loss_ce: 0.029157
2022-01-17 11:39:41,732 iteration 794 : loss : 0.053650, loss_ce: 0.021857
2022-01-17 11:39:42,618 iteration 795 : loss : 0.058025, loss_ce: 0.022553
2022-01-17 11:39:43,505 iteration 796 : loss : 0.071119, loss_ce: 0.029966
2022-01-17 11:39:44,495 iteration 797 : loss : 0.065423, loss_ce: 0.023093
2022-01-17 11:39:45,424 iteration 798 : loss : 0.063651, loss_ce: 0.021055
2022-01-17 11:39:46,296 iteration 799 : loss : 0.048910, loss_ce: 0.023881
 12%|███▌                          | 47/400 [13:56<1:41:30, 17.25s/it]2022-01-17 11:39:47,394 iteration 800 : loss : 0.054531, loss_ce: 0.019248
2022-01-17 11:39:48,354 iteration 801 : loss : 0.052935, loss_ce: 0.020169
2022-01-17 11:39:49,298 iteration 802 : loss : 0.060843, loss_ce: 0.021862
2022-01-17 11:39:50,259 iteration 803 : loss : 0.058535, loss_ce: 0.029971
2022-01-17 11:39:51,288 iteration 804 : loss : 0.115490, loss_ce: 0.055880
2022-01-17 11:39:52,377 iteration 805 : loss : 0.052288, loss_ce: 0.017330
2022-01-17 11:39:53,286 iteration 806 : loss : 0.058203, loss_ce: 0.024899
2022-01-17 11:39:54,164 iteration 807 : loss : 0.059516, loss_ce: 0.023253
2022-01-17 11:39:55,137 iteration 808 : loss : 0.073985, loss_ce: 0.036178
2022-01-17 11:39:56,081 iteration 809 : loss : 0.064805, loss_ce: 0.022616
2022-01-17 11:39:56,991 iteration 810 : loss : 0.107964, loss_ce: 0.037377
2022-01-17 11:39:57,870 iteration 811 : loss : 0.076972, loss_ce: 0.036988
2022-01-17 11:39:58,785 iteration 812 : loss : 0.070796, loss_ce: 0.029891
2022-01-17 11:39:59,727 iteration 813 : loss : 0.101362, loss_ce: 0.030618
2022-01-17 11:40:00,791 iteration 814 : loss : 0.097684, loss_ce: 0.033661
2022-01-17 11:40:01,803 iteration 815 : loss : 0.080677, loss_ce: 0.029450
2022-01-17 11:40:02,766 iteration 816 : loss : 0.047004, loss_ce: 0.017941
 12%|███▌                          | 48/400 [14:12<1:39:50, 17.02s/it]2022-01-17 11:40:03,745 iteration 817 : loss : 0.065684, loss_ce: 0.027586
2022-01-17 11:40:04,634 iteration 818 : loss : 0.049653, loss_ce: 0.020656
2022-01-17 11:40:05,586 iteration 819 : loss : 0.050944, loss_ce: 0.017003
2022-01-17 11:40:06,459 iteration 820 : loss : 0.046053, loss_ce: 0.017179
2022-01-17 11:40:07,471 iteration 821 : loss : 0.064293, loss_ce: 0.021312
2022-01-17 11:40:08,462 iteration 822 : loss : 0.088953, loss_ce: 0.034897
2022-01-17 11:40:09,355 iteration 823 : loss : 0.041212, loss_ce: 0.015064
2022-01-17 11:40:10,243 iteration 824 : loss : 0.048689, loss_ce: 0.019674
2022-01-17 11:40:11,179 iteration 825 : loss : 0.059416, loss_ce: 0.022037
2022-01-17 11:40:12,105 iteration 826 : loss : 0.070403, loss_ce: 0.018175
2022-01-17 11:40:13,040 iteration 827 : loss : 0.075040, loss_ce: 0.022896
2022-01-17 11:40:13,978 iteration 828 : loss : 0.063020, loss_ce: 0.022877
2022-01-17 11:40:14,940 iteration 829 : loss : 0.086429, loss_ce: 0.032833
2022-01-17 11:40:15,944 iteration 830 : loss : 0.055814, loss_ce: 0.018956
2022-01-17 11:40:16,885 iteration 831 : loss : 0.068356, loss_ce: 0.030494
2022-01-17 11:40:17,802 iteration 832 : loss : 0.046293, loss_ce: 0.016908
2022-01-17 11:40:18,802 iteration 833 : loss : 0.064248, loss_ce: 0.030572
 12%|███▋                          | 49/400 [14:28<1:37:49, 16.72s/it]2022-01-17 11:40:19,788 iteration 834 : loss : 0.060460, loss_ce: 0.023833
2022-01-17 11:40:20,639 iteration 835 : loss : 0.054922, loss_ce: 0.016066
2022-01-17 11:40:21,597 iteration 836 : loss : 0.056793, loss_ce: 0.024953
2022-01-17 11:40:22,487 iteration 837 : loss : 0.052241, loss_ce: 0.023522
2022-01-17 11:40:23,355 iteration 838 : loss : 0.056751, loss_ce: 0.021530
2022-01-17 11:40:24,323 iteration 839 : loss : 0.063654, loss_ce: 0.027071
2022-01-17 11:40:25,258 iteration 840 : loss : 0.063129, loss_ce: 0.021588
2022-01-17 11:40:26,252 iteration 841 : loss : 0.046268, loss_ce: 0.019273
2022-01-17 11:40:27,183 iteration 842 : loss : 0.050701, loss_ce: 0.020950
2022-01-17 11:40:28,229 iteration 843 : loss : 0.065682, loss_ce: 0.024177
2022-01-17 11:40:29,150 iteration 844 : loss : 0.052875, loss_ce: 0.017034
2022-01-17 11:40:30,114 iteration 845 : loss : 0.078750, loss_ce: 0.024752
2022-01-17 11:40:31,179 iteration 846 : loss : 0.053409, loss_ce: 0.025610
2022-01-17 11:40:32,133 iteration 847 : loss : 0.055305, loss_ce: 0.023610
2022-01-17 11:40:32,975 iteration 848 : loss : 0.048414, loss_ce: 0.019802
2022-01-17 11:40:33,941 iteration 849 : loss : 0.067309, loss_ce: 0.021901
2022-01-17 11:40:33,941 Training Data Eval:
2022-01-17 11:40:38,403   Average segmentation loss on training set: 0.0418
2022-01-17 11:40:38,403 Validation Data Eval:
2022-01-17 11:40:39,902   Average segmentation loss on validation set: 0.1281
2022-01-17 11:40:40,889 iteration 850 : loss : 0.060144, loss_ce: 0.021038
 12%|███▊                          | 50/400 [14:50<1:46:56, 18.33s/it]2022-01-17 11:40:41,899 iteration 851 : loss : 0.043268, loss_ce: 0.016691
2022-01-17 11:40:42,820 iteration 852 : loss : 0.035531, loss_ce: 0.014155
2022-01-17 11:40:43,843 iteration 853 : loss : 0.069465, loss_ce: 0.030624
2022-01-17 11:40:44,823 iteration 854 : loss : 0.041490, loss_ce: 0.012732
2022-01-17 11:40:45,796 iteration 855 : loss : 0.064355, loss_ce: 0.025647
2022-01-17 11:40:46,785 iteration 856 : loss : 0.047390, loss_ce: 0.017261
2022-01-17 11:40:47,701 iteration 857 : loss : 0.055673, loss_ce: 0.024928
2022-01-17 11:40:48,551 iteration 858 : loss : 0.045949, loss_ce: 0.020817
2022-01-17 11:40:49,483 iteration 859 : loss : 0.062824, loss_ce: 0.028905
2022-01-17 11:40:50,370 iteration 860 : loss : 0.059328, loss_ce: 0.016243
2022-01-17 11:40:51,381 iteration 861 : loss : 0.051183, loss_ce: 0.022831
2022-01-17 11:40:52,252 iteration 862 : loss : 0.059827, loss_ce: 0.017850
2022-01-17 11:40:53,276 iteration 863 : loss : 0.065155, loss_ce: 0.026222
2022-01-17 11:40:54,260 iteration 864 : loss : 0.062632, loss_ce: 0.028586
2022-01-17 11:40:55,117 iteration 865 : loss : 0.041173, loss_ce: 0.016181
2022-01-17 11:40:56,122 iteration 866 : loss : 0.072061, loss_ce: 0.034449
2022-01-17 11:40:57,000 iteration 867 : loss : 0.037539, loss_ce: 0.014356
 13%|███▊                          | 51/400 [15:06<1:42:45, 17.67s/it]2022-01-17 11:40:58,023 iteration 868 : loss : 0.073446, loss_ce: 0.025772
2022-01-17 11:40:58,961 iteration 869 : loss : 0.054713, loss_ce: 0.020781
2022-01-17 11:40:59,805 iteration 870 : loss : 0.042895, loss_ce: 0.015269
2022-01-17 11:41:00,697 iteration 871 : loss : 0.047017, loss_ce: 0.018957
2022-01-17 11:41:01,609 iteration 872 : loss : 0.056480, loss_ce: 0.030345
2022-01-17 11:41:02,635 iteration 873 : loss : 0.048705, loss_ce: 0.017176
2022-01-17 11:41:03,491 iteration 874 : loss : 0.037784, loss_ce: 0.016429
2022-01-17 11:41:04,585 iteration 875 : loss : 0.066746, loss_ce: 0.025350
2022-01-17 11:41:05,519 iteration 876 : loss : 0.041170, loss_ce: 0.019218
2022-01-17 11:41:06,356 iteration 877 : loss : 0.048792, loss_ce: 0.019791
2022-01-17 11:41:07,347 iteration 878 : loss : 0.060276, loss_ce: 0.025236
2022-01-17 11:41:08,262 iteration 879 : loss : 0.048431, loss_ce: 0.018568
2022-01-17 11:41:09,230 iteration 880 : loss : 0.043224, loss_ce: 0.015130
2022-01-17 11:41:10,140 iteration 881 : loss : 0.072644, loss_ce: 0.030325
2022-01-17 11:41:11,132 iteration 882 : loss : 0.059570, loss_ce: 0.025417
2022-01-17 11:41:12,069 iteration 883 : loss : 0.053465, loss_ce: 0.028476
2022-01-17 11:41:13,109 iteration 884 : loss : 0.052088, loss_ce: 0.026441
 13%|███▉                          | 52/400 [15:22<1:39:45, 17.20s/it]2022-01-17 11:41:14,131 iteration 885 : loss : 0.058633, loss_ce: 0.023557
2022-01-17 11:41:15,123 iteration 886 : loss : 0.058859, loss_ce: 0.022287
2022-01-17 11:41:16,121 iteration 887 : loss : 0.081965, loss_ce: 0.035631
2022-01-17 11:41:17,077 iteration 888 : loss : 0.051977, loss_ce: 0.020531
2022-01-17 11:41:18,093 iteration 889 : loss : 0.081781, loss_ce: 0.026160
2022-01-17 11:41:19,150 iteration 890 : loss : 0.074595, loss_ce: 0.025732
2022-01-17 11:41:20,099 iteration 891 : loss : 0.039749, loss_ce: 0.013735
2022-01-17 11:41:21,040 iteration 892 : loss : 0.050218, loss_ce: 0.025216
2022-01-17 11:41:21,963 iteration 893 : loss : 0.047883, loss_ce: 0.015623
2022-01-17 11:41:23,016 iteration 894 : loss : 0.093387, loss_ce: 0.034699
2022-01-17 11:41:23,922 iteration 895 : loss : 0.072880, loss_ce: 0.024870
2022-01-17 11:41:24,924 iteration 896 : loss : 0.075951, loss_ce: 0.026732
2022-01-17 11:41:25,949 iteration 897 : loss : 0.092081, loss_ce: 0.044687
2022-01-17 11:41:26,869 iteration 898 : loss : 0.066200, loss_ce: 0.029713
2022-01-17 11:41:27,797 iteration 899 : loss : 0.059713, loss_ce: 0.025427
2022-01-17 11:41:28,689 iteration 900 : loss : 0.050795, loss_ce: 0.021314
2022-01-17 11:41:29,604 iteration 901 : loss : 0.066626, loss_ce: 0.021194
 13%|███▉                          | 53/400 [15:39<1:38:14, 16.99s/it]2022-01-17 11:41:30,621 iteration 902 : loss : 0.069423, loss_ce: 0.028320
2022-01-17 11:41:31,667 iteration 903 : loss : 0.049811, loss_ce: 0.016377
2022-01-17 11:41:32,649 iteration 904 : loss : 0.077640, loss_ce: 0.028537
2022-01-17 11:41:33,604 iteration 905 : loss : 0.081651, loss_ce: 0.040029
2022-01-17 11:41:34,539 iteration 906 : loss : 0.043217, loss_ce: 0.018869
2022-01-17 11:41:35,548 iteration 907 : loss : 0.068623, loss_ce: 0.020909
2022-01-17 11:41:36,395 iteration 908 : loss : 0.051345, loss_ce: 0.018705
2022-01-17 11:41:37,373 iteration 909 : loss : 0.060783, loss_ce: 0.028302
2022-01-17 11:41:38,250 iteration 910 : loss : 0.086603, loss_ce: 0.034315
2022-01-17 11:41:39,190 iteration 911 : loss : 0.056717, loss_ce: 0.024138
2022-01-17 11:41:40,120 iteration 912 : loss : 0.046531, loss_ce: 0.015886
2022-01-17 11:41:41,043 iteration 913 : loss : 0.066528, loss_ce: 0.022609
2022-01-17 11:41:41,977 iteration 914 : loss : 0.061844, loss_ce: 0.028023
2022-01-17 11:41:42,882 iteration 915 : loss : 0.109606, loss_ce: 0.029925
2022-01-17 11:41:43,796 iteration 916 : loss : 0.043280, loss_ce: 0.015536
2022-01-17 11:41:44,771 iteration 917 : loss : 0.060224, loss_ce: 0.023159
2022-01-17 11:41:45,757 iteration 918 : loss : 0.059238, loss_ce: 0.022205
 14%|████                          | 54/400 [15:55<1:36:30, 16.74s/it]2022-01-17 11:41:46,784 iteration 919 : loss : 0.059266, loss_ce: 0.023683
2022-01-17 11:41:47,741 iteration 920 : loss : 0.065316, loss_ce: 0.025863
2022-01-17 11:41:48,723 iteration 921 : loss : 0.053674, loss_ce: 0.021135
2022-01-17 11:41:49,730 iteration 922 : loss : 0.068822, loss_ce: 0.029702
2022-01-17 11:41:50,652 iteration 923 : loss : 0.044828, loss_ce: 0.018991
2022-01-17 11:41:51,655 iteration 924 : loss : 0.085366, loss_ce: 0.022228
2022-01-17 11:41:52,563 iteration 925 : loss : 0.036879, loss_ce: 0.014716
2022-01-17 11:41:53,562 iteration 926 : loss : 0.047109, loss_ce: 0.020103
2022-01-17 11:41:54,433 iteration 927 : loss : 0.055872, loss_ce: 0.017798
2022-01-17 11:41:55,371 iteration 928 : loss : 0.047090, loss_ce: 0.019608
2022-01-17 11:41:56,378 iteration 929 : loss : 0.056928, loss_ce: 0.020835
2022-01-17 11:41:57,344 iteration 930 : loss : 0.043756, loss_ce: 0.018418
2022-01-17 11:41:58,317 iteration 931 : loss : 0.090888, loss_ce: 0.022259
2022-01-17 11:41:59,275 iteration 932 : loss : 0.051243, loss_ce: 0.018739
2022-01-17 11:42:00,194 iteration 933 : loss : 0.080423, loss_ce: 0.029841
2022-01-17 11:42:01,144 iteration 934 : loss : 0.046484, loss_ce: 0.019818
2022-01-17 11:42:01,144 Training Data Eval:
2022-01-17 11:42:05,600   Average segmentation loss on training set: 0.0389
2022-01-17 11:42:05,601 Validation Data Eval:
2022-01-17 11:42:07,101   Average segmentation loss on validation set: 0.1003
2022-01-17 11:42:08,153 iteration 935 : loss : 0.073860, loss_ce: 0.028558
 14%|████▏                         | 55/400 [16:18<1:45:59, 18.43s/it]2022-01-17 11:42:09,117 iteration 936 : loss : 0.048548, loss_ce: 0.014363
2022-01-17 11:42:10,084 iteration 937 : loss : 0.048426, loss_ce: 0.017332
2022-01-17 11:42:11,078 iteration 938 : loss : 0.047115, loss_ce: 0.017592
2022-01-17 11:42:11,982 iteration 939 : loss : 0.050608, loss_ce: 0.016423
2022-01-17 11:42:12,946 iteration 940 : loss : 0.070985, loss_ce: 0.025026
2022-01-17 11:42:14,003 iteration 941 : loss : 0.074651, loss_ce: 0.023947
2022-01-17 11:42:14,897 iteration 942 : loss : 0.043054, loss_ce: 0.014854
2022-01-17 11:42:15,822 iteration 943 : loss : 0.051652, loss_ce: 0.022814
2022-01-17 11:42:16,726 iteration 944 : loss : 0.051088, loss_ce: 0.020556
2022-01-17 11:42:17,645 iteration 945 : loss : 0.060841, loss_ce: 0.023222
2022-01-17 11:42:18,558 iteration 946 : loss : 0.044373, loss_ce: 0.018731
2022-01-17 11:42:19,463 iteration 947 : loss : 0.054306, loss_ce: 0.017608
2022-01-17 11:42:20,361 iteration 948 : loss : 0.067718, loss_ce: 0.022448
2022-01-17 11:42:21,291 iteration 949 : loss : 0.044092, loss_ce: 0.016733
2022-01-17 11:42:22,218 iteration 950 : loss : 0.070569, loss_ce: 0.033515
2022-01-17 11:42:23,203 iteration 951 : loss : 0.041599, loss_ce: 0.017958
2022-01-17 11:42:24,098 iteration 952 : loss : 0.045897, loss_ce: 0.018928
 14%|████▏                         | 56/400 [16:33<1:41:24, 17.69s/it]2022-01-17 11:42:25,115 iteration 953 : loss : 0.067930, loss_ce: 0.021676
2022-01-17 11:42:26,116 iteration 954 : loss : 0.057792, loss_ce: 0.023307
2022-01-17 11:42:26,987 iteration 955 : loss : 0.038350, loss_ce: 0.015294
2022-01-17 11:42:27,973 iteration 956 : loss : 0.060373, loss_ce: 0.023462
2022-01-17 11:42:28,930 iteration 957 : loss : 0.039593, loss_ce: 0.012783
2022-01-17 11:42:29,900 iteration 958 : loss : 0.059492, loss_ce: 0.019457
2022-01-17 11:42:30,941 iteration 959 : loss : 0.054818, loss_ce: 0.026458
2022-01-17 11:42:32,040 iteration 960 : loss : 0.067210, loss_ce: 0.029910
2022-01-17 11:42:32,937 iteration 961 : loss : 0.053688, loss_ce: 0.016048
2022-01-17 11:42:33,809 iteration 962 : loss : 0.054040, loss_ce: 0.016038
2022-01-17 11:42:34,836 iteration 963 : loss : 0.050742, loss_ce: 0.019007
2022-01-17 11:42:35,820 iteration 964 : loss : 0.058287, loss_ce: 0.029690
2022-01-17 11:42:36,741 iteration 965 : loss : 0.072830, loss_ce: 0.034926
2022-01-17 11:42:37,690 iteration 966 : loss : 0.048545, loss_ce: 0.019069
2022-01-17 11:42:38,664 iteration 967 : loss : 0.042209, loss_ce: 0.016859
2022-01-17 11:42:39,565 iteration 968 : loss : 0.092844, loss_ce: 0.029860
2022-01-17 11:42:40,539 iteration 969 : loss : 0.050688, loss_ce: 0.019707
 14%|████▎                         | 57/400 [16:50<1:38:58, 17.31s/it]2022-01-17 11:42:41,512 iteration 970 : loss : 0.047803, loss_ce: 0.024659
2022-01-17 11:42:42,493 iteration 971 : loss : 0.058459, loss_ce: 0.017336
2022-01-17 11:42:43,378 iteration 972 : loss : 0.045619, loss_ce: 0.020794
2022-01-17 11:42:44,347 iteration 973 : loss : 0.055175, loss_ce: 0.014955
2022-01-17 11:42:45,236 iteration 974 : loss : 0.053759, loss_ce: 0.023462
2022-01-17 11:42:46,241 iteration 975 : loss : 0.068048, loss_ce: 0.024277
2022-01-17 11:42:47,169 iteration 976 : loss : 0.038920, loss_ce: 0.016610
2022-01-17 11:42:48,107 iteration 977 : loss : 0.037424, loss_ce: 0.012137
2022-01-17 11:42:49,081 iteration 978 : loss : 0.041520, loss_ce: 0.014567
2022-01-17 11:42:50,006 iteration 979 : loss : 0.063987, loss_ce: 0.033032
2022-01-17 11:42:50,928 iteration 980 : loss : 0.039810, loss_ce: 0.013546
2022-01-17 11:42:51,974 iteration 981 : loss : 0.052562, loss_ce: 0.022873
2022-01-17 11:42:52,889 iteration 982 : loss : 0.045210, loss_ce: 0.021308
2022-01-17 11:42:53,888 iteration 983 : loss : 0.078620, loss_ce: 0.024488
2022-01-17 11:42:54,751 iteration 984 : loss : 0.050266, loss_ce: 0.025614
2022-01-17 11:42:55,694 iteration 985 : loss : 0.049145, loss_ce: 0.014497
2022-01-17 11:42:56,700 iteration 986 : loss : 0.052786, loss_ce: 0.020029
 14%|████▎                         | 58/400 [17:06<1:36:43, 16.97s/it]2022-01-17 11:42:57,762 iteration 987 : loss : 0.044277, loss_ce: 0.018685
2022-01-17 11:42:58,739 iteration 988 : loss : 0.055855, loss_ce: 0.025436
2022-01-17 11:42:59,700 iteration 989 : loss : 0.047566, loss_ce: 0.017378
2022-01-17 11:43:00,641 iteration 990 : loss : 0.047808, loss_ce: 0.021798
2022-01-17 11:43:01,582 iteration 991 : loss : 0.043612, loss_ce: 0.019188
2022-01-17 11:43:02,621 iteration 992 : loss : 0.053365, loss_ce: 0.022245
2022-01-17 11:43:03,604 iteration 993 : loss : 0.038417, loss_ce: 0.013678
2022-01-17 11:43:04,670 iteration 994 : loss : 0.059218, loss_ce: 0.025152
2022-01-17 11:43:05,630 iteration 995 : loss : 0.086317, loss_ce: 0.026740
2022-01-17 11:43:06,635 iteration 996 : loss : 0.043542, loss_ce: 0.019425
2022-01-17 11:43:07,635 iteration 997 : loss : 0.056595, loss_ce: 0.020019
2022-01-17 11:43:08,520 iteration 998 : loss : 0.069883, loss_ce: 0.021218
2022-01-17 11:43:09,508 iteration 999 : loss : 0.049177, loss_ce: 0.019300
2022-01-17 11:43:10,403 iteration 1000 : loss : 0.051565, loss_ce: 0.015129
2022-01-17 11:43:11,312 iteration 1001 : loss : 0.061493, loss_ce: 0.014004
2022-01-17 11:43:12,359 iteration 1002 : loss : 0.048449, loss_ce: 0.018115
2022-01-17 11:43:13,388 iteration 1003 : loss : 0.070350, loss_ce: 0.030238
 15%|████▍                         | 59/400 [17:23<1:35:57, 16.88s/it]2022-01-17 11:43:14,380 iteration 1004 : loss : 0.123593, loss_ce: 0.048595
2022-01-17 11:43:15,317 iteration 1005 : loss : 0.056187, loss_ce: 0.021630
2022-01-17 11:43:16,365 iteration 1006 : loss : 0.060559, loss_ce: 0.024870
2022-01-17 11:43:17,278 iteration 1007 : loss : 0.042930, loss_ce: 0.021542
2022-01-17 11:43:18,180 iteration 1008 : loss : 0.089297, loss_ce: 0.026736
2022-01-17 11:43:19,087 iteration 1009 : loss : 0.056676, loss_ce: 0.018417
2022-01-17 11:43:19,997 iteration 1010 : loss : 0.055061, loss_ce: 0.021652
2022-01-17 11:43:21,007 iteration 1011 : loss : 0.063006, loss_ce: 0.027010
2022-01-17 11:43:21,940 iteration 1012 : loss : 0.035107, loss_ce: 0.013165
2022-01-17 11:43:22,829 iteration 1013 : loss : 0.037938, loss_ce: 0.014328
2022-01-17 11:43:23,788 iteration 1014 : loss : 0.069417, loss_ce: 0.024231
2022-01-17 11:43:24,665 iteration 1015 : loss : 0.074090, loss_ce: 0.029237
2022-01-17 11:43:25,624 iteration 1016 : loss : 0.062496, loss_ce: 0.026472
2022-01-17 11:43:26,474 iteration 1017 : loss : 0.040052, loss_ce: 0.014182
2022-01-17 11:43:27,321 iteration 1018 : loss : 0.060253, loss_ce: 0.023104
2022-01-17 11:43:28,247 iteration 1019 : loss : 0.070042, loss_ce: 0.028038
2022-01-17 11:43:28,247 Training Data Eval:
2022-01-17 11:43:32,706   Average segmentation loss on training set: 0.1195
2022-01-17 11:43:32,706 Validation Data Eval:
2022-01-17 11:43:34,204   Average segmentation loss on validation set: 0.1349
2022-01-17 11:43:35,095 iteration 1020 : loss : 0.051223, loss_ce: 0.017424
 15%|████▌                         | 60/400 [17:44<1:43:52, 18.33s/it]2022-01-17 11:43:36,167 iteration 1021 : loss : 0.086770, loss_ce: 0.020813
2022-01-17 11:43:37,095 iteration 1022 : loss : 0.053200, loss_ce: 0.023812
2022-01-17 11:43:38,046 iteration 1023 : loss : 0.106771, loss_ce: 0.036092
2022-01-17 11:43:39,065 iteration 1024 : loss : 0.045515, loss_ce: 0.017739
2022-01-17 11:43:40,072 iteration 1025 : loss : 0.037717, loss_ce: 0.018156
2022-01-17 11:43:40,928 iteration 1026 : loss : 0.051415, loss_ce: 0.019136
2022-01-17 11:43:41,931 iteration 1027 : loss : 0.064056, loss_ce: 0.018679
2022-01-17 11:43:42,923 iteration 1028 : loss : 0.084553, loss_ce: 0.038865
2022-01-17 11:43:43,863 iteration 1029 : loss : 0.050034, loss_ce: 0.020728
2022-01-17 11:43:44,813 iteration 1030 : loss : 0.039973, loss_ce: 0.015073
2022-01-17 11:43:45,826 iteration 1031 : loss : 0.074804, loss_ce: 0.031936
2022-01-17 11:43:46,804 iteration 1032 : loss : 0.056521, loss_ce: 0.029083
2022-01-17 11:43:47,722 iteration 1033 : loss : 0.055377, loss_ce: 0.019327
2022-01-17 11:43:48,744 iteration 1034 : loss : 0.083429, loss_ce: 0.031104
2022-01-17 11:43:49,717 iteration 1035 : loss : 0.051413, loss_ce: 0.021038
2022-01-17 11:43:50,693 iteration 1036 : loss : 0.045916, loss_ce: 0.020228
2022-01-17 11:43:51,604 iteration 1037 : loss : 0.059482, loss_ce: 0.020930
 15%|████▌                         | 61/400 [18:01<1:40:27, 17.78s/it]2022-01-17 11:43:52,604 iteration 1038 : loss : 0.043840, loss_ce: 0.017723
2022-01-17 11:43:53,550 iteration 1039 : loss : 0.050561, loss_ce: 0.024705
2022-01-17 11:43:54,532 iteration 1040 : loss : 0.082087, loss_ce: 0.040904
2022-01-17 11:43:55,491 iteration 1041 : loss : 0.054309, loss_ce: 0.023686
2022-01-17 11:43:56,460 iteration 1042 : loss : 0.046963, loss_ce: 0.019865
2022-01-17 11:43:57,409 iteration 1043 : loss : 0.077026, loss_ce: 0.024042
2022-01-17 11:43:58,386 iteration 1044 : loss : 0.049749, loss_ce: 0.020346
2022-01-17 11:43:59,242 iteration 1045 : loss : 0.044079, loss_ce: 0.020655
2022-01-17 11:44:00,136 iteration 1046 : loss : 0.055894, loss_ce: 0.017087
2022-01-17 11:44:01,135 iteration 1047 : loss : 0.072914, loss_ce: 0.025768
2022-01-17 11:44:02,086 iteration 1048 : loss : 0.058766, loss_ce: 0.021991
2022-01-17 11:44:03,047 iteration 1049 : loss : 0.054964, loss_ce: 0.016192
2022-01-17 11:44:04,061 iteration 1050 : loss : 0.075360, loss_ce: 0.019497
2022-01-17 11:44:05,008 iteration 1051 : loss : 0.054069, loss_ce: 0.021796
2022-01-17 11:44:05,958 iteration 1052 : loss : 0.054449, loss_ce: 0.018988
2022-01-17 11:44:06,827 iteration 1053 : loss : 0.052151, loss_ce: 0.017110
2022-01-17 11:44:07,849 iteration 1054 : loss : 0.046500, loss_ce: 0.021624
 16%|████▋                         | 62/400 [18:17<1:37:35, 17.32s/it]2022-01-17 11:44:08,835 iteration 1055 : loss : 0.032584, loss_ce: 0.011450
2022-01-17 11:44:09,751 iteration 1056 : loss : 0.055438, loss_ce: 0.029930
2022-01-17 11:44:10,672 iteration 1057 : loss : 0.081249, loss_ce: 0.037896
2022-01-17 11:44:11,618 iteration 1058 : loss : 0.048704, loss_ce: 0.023274
2022-01-17 11:44:12,477 iteration 1059 : loss : 0.050865, loss_ce: 0.017934
2022-01-17 11:44:13,415 iteration 1060 : loss : 0.039809, loss_ce: 0.015606
2022-01-17 11:44:14,390 iteration 1061 : loss : 0.061722, loss_ce: 0.022195
2022-01-17 11:44:15,359 iteration 1062 : loss : 0.059189, loss_ce: 0.023507
2022-01-17 11:44:16,385 iteration 1063 : loss : 0.082259, loss_ce: 0.025573
2022-01-17 11:44:17,331 iteration 1064 : loss : 0.052128, loss_ce: 0.016323
2022-01-17 11:44:18,217 iteration 1065 : loss : 0.050015, loss_ce: 0.019590
2022-01-17 11:44:19,211 iteration 1066 : loss : 0.041003, loss_ce: 0.015318
2022-01-17 11:44:20,142 iteration 1067 : loss : 0.111880, loss_ce: 0.027033
2022-01-17 11:44:21,143 iteration 1068 : loss : 0.063201, loss_ce: 0.030242
2022-01-17 11:44:22,120 iteration 1069 : loss : 0.065651, loss_ce: 0.027093
2022-01-17 11:44:23,066 iteration 1070 : loss : 0.047375, loss_ce: 0.019007
2022-01-17 11:44:24,001 iteration 1071 : loss : 0.040572, loss_ce: 0.017919
 16%|████▋                         | 63/400 [18:33<1:35:19, 16.97s/it]2022-01-17 11:44:25,097 iteration 1072 : loss : 0.041802, loss_ce: 0.015389
2022-01-17 11:44:26,018 iteration 1073 : loss : 0.072225, loss_ce: 0.017896
2022-01-17 11:44:26,940 iteration 1074 : loss : 0.051392, loss_ce: 0.018575
2022-01-17 11:44:27,912 iteration 1075 : loss : 0.063103, loss_ce: 0.020753
2022-01-17 11:44:28,797 iteration 1076 : loss : 0.046388, loss_ce: 0.015289
2022-01-17 11:44:29,726 iteration 1077 : loss : 0.051200, loss_ce: 0.015445
2022-01-17 11:44:30,743 iteration 1078 : loss : 0.056205, loss_ce: 0.032013
2022-01-17 11:44:31,651 iteration 1079 : loss : 0.051256, loss_ce: 0.018915
2022-01-17 11:44:32,546 iteration 1080 : loss : 0.039006, loss_ce: 0.016249
2022-01-17 11:44:33,527 iteration 1081 : loss : 0.060784, loss_ce: 0.019678
2022-01-17 11:44:34,500 iteration 1082 : loss : 0.051830, loss_ce: 0.026497
2022-01-17 11:44:35,494 iteration 1083 : loss : 0.052422, loss_ce: 0.020943
2022-01-17 11:44:36,415 iteration 1084 : loss : 0.049293, loss_ce: 0.022089
2022-01-17 11:44:37,450 iteration 1085 : loss : 0.043501, loss_ce: 0.013842
2022-01-17 11:44:38,377 iteration 1086 : loss : 0.060416, loss_ce: 0.023917
2022-01-17 11:44:39,321 iteration 1087 : loss : 0.044370, loss_ce: 0.018340
2022-01-17 11:44:40,325 iteration 1088 : loss : 0.045206, loss_ce: 0.019208
 16%|████▊                         | 64/400 [18:50<1:33:57, 16.78s/it]2022-01-17 11:44:41,282 iteration 1089 : loss : 0.063273, loss_ce: 0.024854
2022-01-17 11:44:42,259 iteration 1090 : loss : 0.042159, loss_ce: 0.021598
2022-01-17 11:44:43,197 iteration 1091 : loss : 0.053047, loss_ce: 0.025208
2022-01-17 11:44:44,142 iteration 1092 : loss : 0.039986, loss_ce: 0.016161
2022-01-17 11:44:45,105 iteration 1093 : loss : 0.069022, loss_ce: 0.023662
2022-01-17 11:44:46,119 iteration 1094 : loss : 0.053962, loss_ce: 0.021434
2022-01-17 11:44:47,019 iteration 1095 : loss : 0.035482, loss_ce: 0.014718
2022-01-17 11:44:48,080 iteration 1096 : loss : 0.048639, loss_ce: 0.017778
2022-01-17 11:44:49,055 iteration 1097 : loss : 0.049426, loss_ce: 0.019554
2022-01-17 11:44:49,966 iteration 1098 : loss : 0.035496, loss_ce: 0.015185
2022-01-17 11:44:50,946 iteration 1099 : loss : 0.043312, loss_ce: 0.014768
2022-01-17 11:44:51,979 iteration 1100 : loss : 0.042318, loss_ce: 0.013275
2022-01-17 11:44:52,915 iteration 1101 : loss : 0.040868, loss_ce: 0.014394
2022-01-17 11:44:53,935 iteration 1102 : loss : 0.071025, loss_ce: 0.020017
2022-01-17 11:44:54,852 iteration 1103 : loss : 0.054803, loss_ce: 0.018148
2022-01-17 11:44:55,776 iteration 1104 : loss : 0.061696, loss_ce: 0.026669
2022-01-17 11:44:55,776 Training Data Eval:
2022-01-17 11:45:00,239   Average segmentation loss on training set: 0.0386
2022-01-17 11:45:00,240 Validation Data Eval:
2022-01-17 11:45:01,750   Average segmentation loss on validation set: 0.1076
2022-01-17 11:45:02,812 iteration 1105 : loss : 0.040574, loss_ce: 0.013460
 16%|████▉                         | 65/400 [19:12<1:43:13, 18.49s/it]2022-01-17 11:45:03,729 iteration 1106 : loss : 0.049376, loss_ce: 0.016337
2022-01-17 11:45:04,660 iteration 1107 : loss : 0.050620, loss_ce: 0.024976
2022-01-17 11:45:05,620 iteration 1108 : loss : 0.051936, loss_ce: 0.012770
2022-01-17 11:45:06,508 iteration 1109 : loss : 0.037023, loss_ce: 0.014786
2022-01-17 11:45:07,464 iteration 1110 : loss : 0.044859, loss_ce: 0.020080
2022-01-17 11:45:08,386 iteration 1111 : loss : 0.037743, loss_ce: 0.015682
2022-01-17 11:45:09,315 iteration 1112 : loss : 0.038937, loss_ce: 0.015975
2022-01-17 11:45:10,229 iteration 1113 : loss : 0.043540, loss_ce: 0.014110
2022-01-17 11:45:11,242 iteration 1114 : loss : 0.059120, loss_ce: 0.031887
2022-01-17 11:45:12,330 iteration 1115 : loss : 0.050539, loss_ce: 0.025462
2022-01-17 11:45:13,336 iteration 1116 : loss : 0.055059, loss_ce: 0.018280
2022-01-17 11:45:14,414 iteration 1117 : loss : 0.046030, loss_ce: 0.015299
2022-01-17 11:45:15,410 iteration 1118 : loss : 0.048781, loss_ce: 0.016330
2022-01-17 11:45:16,322 iteration 1119 : loss : 0.040528, loss_ce: 0.017177
2022-01-17 11:45:17,227 iteration 1120 : loss : 0.041811, loss_ce: 0.013444
2022-01-17 11:45:18,194 iteration 1121 : loss : 0.072225, loss_ce: 0.020386
2022-01-17 11:45:19,143 iteration 1122 : loss : 0.052146, loss_ce: 0.025542
 16%|████▉                         | 66/400 [19:29<1:39:19, 17.84s/it]2022-01-17 11:45:20,087 iteration 1123 : loss : 0.052775, loss_ce: 0.018880
2022-01-17 11:45:21,072 iteration 1124 : loss : 0.046096, loss_ce: 0.019467
2022-01-17 11:45:22,014 iteration 1125 : loss : 0.038466, loss_ce: 0.010397
2022-01-17 11:45:22,936 iteration 1126 : loss : 0.058349, loss_ce: 0.023724
2022-01-17 11:45:23,854 iteration 1127 : loss : 0.057296, loss_ce: 0.020283
2022-01-17 11:45:24,865 iteration 1128 : loss : 0.057463, loss_ce: 0.022395
2022-01-17 11:45:25,876 iteration 1129 : loss : 0.051879, loss_ce: 0.017023
2022-01-17 11:45:26,795 iteration 1130 : loss : 0.047219, loss_ce: 0.021876
2022-01-17 11:45:27,727 iteration 1131 : loss : 0.040294, loss_ce: 0.014752
2022-01-17 11:45:28,713 iteration 1132 : loss : 0.041065, loss_ce: 0.014459
2022-01-17 11:45:29,598 iteration 1133 : loss : 0.030185, loss_ce: 0.013845
2022-01-17 11:45:30,543 iteration 1134 : loss : 0.057765, loss_ce: 0.017617
2022-01-17 11:45:31,454 iteration 1135 : loss : 0.051528, loss_ce: 0.021908
2022-01-17 11:45:32,389 iteration 1136 : loss : 0.031134, loss_ce: 0.010706
2022-01-17 11:45:33,310 iteration 1137 : loss : 0.053054, loss_ce: 0.021619
2022-01-17 11:45:34,300 iteration 1138 : loss : 0.045514, loss_ce: 0.020552
2022-01-17 11:45:35,259 iteration 1139 : loss : 0.080398, loss_ce: 0.026362
 17%|█████                         | 67/400 [19:45<1:36:09, 17.32s/it]2022-01-17 11:45:36,252 iteration 1140 : loss : 0.058346, loss_ce: 0.022968
2022-01-17 11:45:37,158 iteration 1141 : loss : 0.048173, loss_ce: 0.016607
2022-01-17 11:45:38,176 iteration 1142 : loss : 0.048863, loss_ce: 0.020199
2022-01-17 11:45:39,124 iteration 1143 : loss : 0.058544, loss_ce: 0.020053
2022-01-17 11:45:40,114 iteration 1144 : loss : 0.070513, loss_ce: 0.037827
2022-01-17 11:45:41,007 iteration 1145 : loss : 0.048634, loss_ce: 0.019625
2022-01-17 11:45:41,969 iteration 1146 : loss : 0.054354, loss_ce: 0.027124
2022-01-17 11:45:42,829 iteration 1147 : loss : 0.049872, loss_ce: 0.018309
2022-01-17 11:45:43,825 iteration 1148 : loss : 0.057130, loss_ce: 0.020285
2022-01-17 11:45:44,719 iteration 1149 : loss : 0.042997, loss_ce: 0.018904
2022-01-17 11:45:45,662 iteration 1150 : loss : 0.048695, loss_ce: 0.018068
2022-01-17 11:45:46,645 iteration 1151 : loss : 0.051879, loss_ce: 0.018102
2022-01-17 11:45:47,722 iteration 1152 : loss : 0.063876, loss_ce: 0.025741
2022-01-17 11:45:48,577 iteration 1153 : loss : 0.053554, loss_ce: 0.019137
2022-01-17 11:45:49,565 iteration 1154 : loss : 0.049589, loss_ce: 0.015979
2022-01-17 11:45:50,473 iteration 1155 : loss : 0.053389, loss_ce: 0.021533
2022-01-17 11:45:51,472 iteration 1156 : loss : 0.065933, loss_ce: 0.038322
 17%|█████                         | 68/400 [20:01<1:34:00, 16.99s/it]2022-01-17 11:45:52,441 iteration 1157 : loss : 0.084922, loss_ce: 0.020183
2022-01-17 11:45:53,413 iteration 1158 : loss : 0.038282, loss_ce: 0.013627
2022-01-17 11:45:54,444 iteration 1159 : loss : 0.047391, loss_ce: 0.015515
2022-01-17 11:45:55,517 iteration 1160 : loss : 0.091181, loss_ce: 0.040735
2022-01-17 11:45:56,519 iteration 1161 : loss : 0.050883, loss_ce: 0.024701
2022-01-17 11:45:57,492 iteration 1162 : loss : 0.042989, loss_ce: 0.015566
2022-01-17 11:45:58,406 iteration 1163 : loss : 0.062499, loss_ce: 0.024858
2022-01-17 11:45:59,335 iteration 1164 : loss : 0.050439, loss_ce: 0.019023
2022-01-17 11:46:00,272 iteration 1165 : loss : 0.045270, loss_ce: 0.019177
2022-01-17 11:46:01,298 iteration 1166 : loss : 0.042206, loss_ce: 0.015083
2022-01-17 11:46:02,209 iteration 1167 : loss : 0.042612, loss_ce: 0.021102
2022-01-17 11:46:03,140 iteration 1168 : loss : 0.043048, loss_ce: 0.018319
2022-01-17 11:46:04,057 iteration 1169 : loss : 0.037953, loss_ce: 0.014912
2022-01-17 11:46:04,977 iteration 1170 : loss : 0.068155, loss_ce: 0.026912
2022-01-17 11:46:05,944 iteration 1171 : loss : 0.041348, loss_ce: 0.012954
2022-01-17 11:46:06,905 iteration 1172 : loss : 0.044781, loss_ce: 0.019759
2022-01-17 11:46:07,889 iteration 1173 : loss : 0.051196, loss_ce: 0.017780
 17%|█████▏                        | 69/400 [20:17<1:32:46, 16.82s/it]2022-01-17 11:46:08,856 iteration 1174 : loss : 0.050752, loss_ce: 0.014161
2022-01-17 11:46:09,805 iteration 1175 : loss : 0.042258, loss_ce: 0.018217
2022-01-17 11:46:10,740 iteration 1176 : loss : 0.038146, loss_ce: 0.015190
2022-01-17 11:46:11,652 iteration 1177 : loss : 0.052747, loss_ce: 0.020327
2022-01-17 11:46:12,638 iteration 1178 : loss : 0.037956, loss_ce: 0.010663
2022-01-17 11:46:13,677 iteration 1179 : loss : 0.051085, loss_ce: 0.022182
2022-01-17 11:46:14,591 iteration 1180 : loss : 0.035002, loss_ce: 0.015357
2022-01-17 11:46:15,533 iteration 1181 : loss : 0.044128, loss_ce: 0.015973
2022-01-17 11:46:16,497 iteration 1182 : loss : 0.035357, loss_ce: 0.013508
2022-01-17 11:46:17,397 iteration 1183 : loss : 0.045522, loss_ce: 0.017419
2022-01-17 11:46:18,308 iteration 1184 : loss : 0.032087, loss_ce: 0.014302
2022-01-17 11:46:19,299 iteration 1185 : loss : 0.050960, loss_ce: 0.020667
2022-01-17 11:46:20,209 iteration 1186 : loss : 0.041132, loss_ce: 0.018054
2022-01-17 11:46:21,217 iteration 1187 : loss : 0.052182, loss_ce: 0.021605
2022-01-17 11:46:22,112 iteration 1188 : loss : 0.048571, loss_ce: 0.017546
2022-01-17 11:46:23,135 iteration 1189 : loss : 0.047812, loss_ce: 0.019961
2022-01-17 11:46:23,135 Training Data Eval:
2022-01-17 11:46:27,599   Average segmentation loss on training set: 0.0322
2022-01-17 11:46:27,600 Validation Data Eval:
2022-01-17 11:46:29,108   Average segmentation loss on validation set: 0.0722
2022-01-17 11:46:32,768 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 11:46:33,666 iteration 1190 : loss : 0.047141, loss_ce: 0.019589
 18%|█████▎                        | 70/400 [20:43<1:47:17, 19.51s/it]2022-01-17 11:46:34,665 iteration 1191 : loss : 0.045084, loss_ce: 0.017908
2022-01-17 11:46:35,498 iteration 1192 : loss : 0.034574, loss_ce: 0.015456
2022-01-17 11:46:36,459 iteration 1193 : loss : 0.051488, loss_ce: 0.016321
2022-01-17 11:46:37,319 iteration 1194 : loss : 0.035848, loss_ce: 0.011885
2022-01-17 11:46:38,145 iteration 1195 : loss : 0.035535, loss_ce: 0.015031
2022-01-17 11:46:38,972 iteration 1196 : loss : 0.039066, loss_ce: 0.015830
2022-01-17 11:46:39,756 iteration 1197 : loss : 0.035066, loss_ce: 0.012919
2022-01-17 11:46:40,693 iteration 1198 : loss : 0.039711, loss_ce: 0.017633
2022-01-17 11:46:41,603 iteration 1199 : loss : 0.045927, loss_ce: 0.015362
2022-01-17 11:46:42,508 iteration 1200 : loss : 0.050736, loss_ce: 0.014695
2022-01-17 11:46:43,396 iteration 1201 : loss : 0.036428, loss_ce: 0.016134
2022-01-17 11:46:44,369 iteration 1202 : loss : 0.042829, loss_ce: 0.014282
2022-01-17 11:46:45,334 iteration 1203 : loss : 0.056106, loss_ce: 0.019236
2022-01-17 11:46:46,285 iteration 1204 : loss : 0.045872, loss_ce: 0.015307
2022-01-17 11:46:47,253 iteration 1205 : loss : 0.064036, loss_ce: 0.024064
2022-01-17 11:46:48,220 iteration 1206 : loss : 0.033780, loss_ce: 0.012315
2022-01-17 11:46:49,223 iteration 1207 : loss : 0.033219, loss_ce: 0.009652
 18%|█████▎                        | 71/400 [20:59<1:40:28, 18.32s/it]2022-01-17 11:46:50,247 iteration 1208 : loss : 0.044004, loss_ce: 0.020967
2022-01-17 11:46:51,196 iteration 1209 : loss : 0.045122, loss_ce: 0.017588
2022-01-17 11:46:52,138 iteration 1210 : loss : 0.045056, loss_ce: 0.016102
2022-01-17 11:46:53,028 iteration 1211 : loss : 0.030470, loss_ce: 0.011544
2022-01-17 11:46:53,903 iteration 1212 : loss : 0.048736, loss_ce: 0.014224
2022-01-17 11:46:54,973 iteration 1213 : loss : 0.062368, loss_ce: 0.025580
2022-01-17 11:46:55,920 iteration 1214 : loss : 0.035310, loss_ce: 0.012777
2022-01-17 11:46:56,884 iteration 1215 : loss : 0.057014, loss_ce: 0.020026
2022-01-17 11:46:57,964 iteration 1216 : loss : 0.045635, loss_ce: 0.015374
2022-01-17 11:46:58,923 iteration 1217 : loss : 0.038394, loss_ce: 0.013269
2022-01-17 11:46:59,825 iteration 1218 : loss : 0.043364, loss_ce: 0.014156
2022-01-17 11:47:00,696 iteration 1219 : loss : 0.034242, loss_ce: 0.010869
2022-01-17 11:47:01,635 iteration 1220 : loss : 0.043906, loss_ce: 0.015610
2022-01-17 11:47:02,543 iteration 1221 : loss : 0.046253, loss_ce: 0.019208
2022-01-17 11:47:03,554 iteration 1222 : loss : 0.056233, loss_ce: 0.019658
2022-01-17 11:47:04,479 iteration 1223 : loss : 0.037905, loss_ce: 0.015683
2022-01-17 11:47:05,472 iteration 1224 : loss : 0.056173, loss_ce: 0.023243
 18%|█████▍                        | 72/400 [21:15<1:36:45, 17.70s/it]2022-01-17 11:47:06,432 iteration 1225 : loss : 0.035766, loss_ce: 0.014434
2022-01-17 11:47:07,418 iteration 1226 : loss : 0.055445, loss_ce: 0.023772
2022-01-17 11:47:08,308 iteration 1227 : loss : 0.042738, loss_ce: 0.015171
2022-01-17 11:47:09,241 iteration 1228 : loss : 0.037314, loss_ce: 0.013722
2022-01-17 11:47:10,113 iteration 1229 : loss : 0.038548, loss_ce: 0.010099
2022-01-17 11:47:11,014 iteration 1230 : loss : 0.041515, loss_ce: 0.016061
2022-01-17 11:47:11,994 iteration 1231 : loss : 0.051329, loss_ce: 0.028634
2022-01-17 11:47:12,893 iteration 1232 : loss : 0.038863, loss_ce: 0.014810
2022-01-17 11:47:13,805 iteration 1233 : loss : 0.032684, loss_ce: 0.012946
2022-01-17 11:47:14,785 iteration 1234 : loss : 0.054282, loss_ce: 0.024263
2022-01-17 11:47:15,763 iteration 1235 : loss : 0.073697, loss_ce: 0.023575
2022-01-17 11:47:16,668 iteration 1236 : loss : 0.045157, loss_ce: 0.016094
2022-01-17 11:47:17,517 iteration 1237 : loss : 0.045432, loss_ce: 0.016305
2022-01-17 11:47:18,509 iteration 1238 : loss : 0.040519, loss_ce: 0.011564
2022-01-17 11:47:19,396 iteration 1239 : loss : 0.028109, loss_ce: 0.010519
2022-01-17 11:47:20,291 iteration 1240 : loss : 0.039077, loss_ce: 0.015530
2022-01-17 11:47:21,190 iteration 1241 : loss : 0.051151, loss_ce: 0.027597
 18%|█████▍                        | 73/400 [21:31<1:33:13, 17.10s/it]2022-01-17 11:47:22,195 iteration 1242 : loss : 0.054615, loss_ce: 0.033311
2022-01-17 11:47:23,100 iteration 1243 : loss : 0.046549, loss_ce: 0.015190
2022-01-17 11:47:24,009 iteration 1244 : loss : 0.045523, loss_ce: 0.017479
2022-01-17 11:47:24,971 iteration 1245 : loss : 0.061392, loss_ce: 0.021850
2022-01-17 11:47:25,925 iteration 1246 : loss : 0.047472, loss_ce: 0.016775
2022-01-17 11:47:26,837 iteration 1247 : loss : 0.034581, loss_ce: 0.015957
2022-01-17 11:47:27,808 iteration 1248 : loss : 0.053469, loss_ce: 0.020272
2022-01-17 11:47:28,712 iteration 1249 : loss : 0.035011, loss_ce: 0.011841
2022-01-17 11:47:29,759 iteration 1250 : loss : 0.039577, loss_ce: 0.014967
2022-01-17 11:47:30,838 iteration 1251 : loss : 0.056957, loss_ce: 0.029154
2022-01-17 11:47:31,805 iteration 1252 : loss : 0.042099, loss_ce: 0.018351
2022-01-17 11:47:32,666 iteration 1253 : loss : 0.032228, loss_ce: 0.010602
2022-01-17 11:47:33,615 iteration 1254 : loss : 0.034928, loss_ce: 0.017639
2022-01-17 11:47:34,580 iteration 1255 : loss : 0.033569, loss_ce: 0.013004
2022-01-17 11:47:35,507 iteration 1256 : loss : 0.047030, loss_ce: 0.019038
2022-01-17 11:47:36,452 iteration 1257 : loss : 0.050714, loss_ce: 0.013427
2022-01-17 11:47:37,417 iteration 1258 : loss : 0.034414, loss_ce: 0.015857
 18%|█████▌                        | 74/400 [21:47<1:31:30, 16.84s/it]2022-01-17 11:47:38,359 iteration 1259 : loss : 0.034281, loss_ce: 0.015644
2022-01-17 11:47:39,358 iteration 1260 : loss : 0.041916, loss_ce: 0.016964
2022-01-17 11:47:40,276 iteration 1261 : loss : 0.030283, loss_ce: 0.008246
2022-01-17 11:47:41,304 iteration 1262 : loss : 0.043555, loss_ce: 0.016564
2022-01-17 11:47:42,349 iteration 1263 : loss : 0.078180, loss_ce: 0.024100
2022-01-17 11:47:43,262 iteration 1264 : loss : 0.033556, loss_ce: 0.014110
2022-01-17 11:47:44,254 iteration 1265 : loss : 0.051588, loss_ce: 0.029051
2022-01-17 11:47:45,247 iteration 1266 : loss : 0.052997, loss_ce: 0.020730
2022-01-17 11:47:46,220 iteration 1267 : loss : 0.047213, loss_ce: 0.018207
2022-01-17 11:47:47,136 iteration 1268 : loss : 0.054781, loss_ce: 0.019829
2022-01-17 11:47:48,161 iteration 1269 : loss : 0.077773, loss_ce: 0.021810
2022-01-17 11:47:49,154 iteration 1270 : loss : 0.044631, loss_ce: 0.019214
2022-01-17 11:47:50,101 iteration 1271 : loss : 0.052461, loss_ce: 0.024677
2022-01-17 11:47:50,961 iteration 1272 : loss : 0.051411, loss_ce: 0.015988
2022-01-17 11:47:51,880 iteration 1273 : loss : 0.057668, loss_ce: 0.017618
2022-01-17 11:47:52,826 iteration 1274 : loss : 0.044198, loss_ce: 0.015114
2022-01-17 11:47:52,827 Training Data Eval:
2022-01-17 11:47:57,289   Average segmentation loss on training set: 0.0493
2022-01-17 11:47:57,289 Validation Data Eval:
2022-01-17 11:47:58,796   Average segmentation loss on validation set: 0.1921
2022-01-17 11:47:59,730 iteration 1275 : loss : 0.050706, loss_ce: 0.016951
 19%|█████▋                        | 75/400 [22:09<1:40:06, 18.48s/it]2022-01-17 11:48:00,624 iteration 1276 : loss : 0.040771, loss_ce: 0.015942
2022-01-17 11:48:01,684 iteration 1277 : loss : 0.049552, loss_ce: 0.019856
2022-01-17 11:48:02,592 iteration 1278 : loss : 0.029444, loss_ce: 0.010087
2022-01-17 11:48:03,632 iteration 1279 : loss : 0.044908, loss_ce: 0.014040
2022-01-17 11:48:04,596 iteration 1280 : loss : 0.050798, loss_ce: 0.022337
2022-01-17 11:48:05,553 iteration 1281 : loss : 0.066258, loss_ce: 0.029512
2022-01-17 11:48:06,443 iteration 1282 : loss : 0.026067, loss_ce: 0.011668
2022-01-17 11:48:07,442 iteration 1283 : loss : 0.054792, loss_ce: 0.018694
2022-01-17 11:48:08,344 iteration 1284 : loss : 0.047996, loss_ce: 0.019651
2022-01-17 11:48:09,363 iteration 1285 : loss : 0.043432, loss_ce: 0.015572
2022-01-17 11:48:10,405 iteration 1286 : loss : 0.090804, loss_ce: 0.024779
2022-01-17 11:48:11,323 iteration 1287 : loss : 0.035271, loss_ce: 0.018200
2022-01-17 11:48:12,225 iteration 1288 : loss : 0.040417, loss_ce: 0.016869
2022-01-17 11:48:13,170 iteration 1289 : loss : 0.042280, loss_ce: 0.016387
2022-01-17 11:48:14,157 iteration 1290 : loss : 0.056387, loss_ce: 0.017525
2022-01-17 11:48:15,160 iteration 1291 : loss : 0.069958, loss_ce: 0.032995
2022-01-17 11:48:16,181 iteration 1292 : loss : 0.046379, loss_ce: 0.015016
 19%|█████▋                        | 76/400 [22:26<1:36:31, 17.87s/it]2022-01-17 11:48:17,210 iteration 1293 : loss : 0.046144, loss_ce: 0.019217
2022-01-17 11:48:18,199 iteration 1294 : loss : 0.055756, loss_ce: 0.018321
2022-01-17 11:48:19,233 iteration 1295 : loss : 0.055108, loss_ce: 0.013941
2022-01-17 11:48:20,209 iteration 1296 : loss : 0.059776, loss_ce: 0.018672
2022-01-17 11:48:21,110 iteration 1297 : loss : 0.044535, loss_ce: 0.021769
2022-01-17 11:48:21,990 iteration 1298 : loss : 0.037682, loss_ce: 0.013963
2022-01-17 11:48:22,949 iteration 1299 : loss : 0.052775, loss_ce: 0.025474
2022-01-17 11:48:23,895 iteration 1300 : loss : 0.048561, loss_ce: 0.013186
2022-01-17 11:48:24,871 iteration 1301 : loss : 0.028076, loss_ce: 0.010273
2022-01-17 11:48:25,787 iteration 1302 : loss : 0.041830, loss_ce: 0.017624
2022-01-17 11:48:26,712 iteration 1303 : loss : 0.044018, loss_ce: 0.016881
2022-01-17 11:48:27,674 iteration 1304 : loss : 0.038688, loss_ce: 0.014932
2022-01-17 11:48:28,622 iteration 1305 : loss : 0.051919, loss_ce: 0.021766
2022-01-17 11:48:29,609 iteration 1306 : loss : 0.066612, loss_ce: 0.021301
2022-01-17 11:48:30,594 iteration 1307 : loss : 0.044998, loss_ce: 0.022324
2022-01-17 11:48:31,559 iteration 1308 : loss : 0.057822, loss_ce: 0.014352
2022-01-17 11:48:32,446 iteration 1309 : loss : 0.045228, loss_ce: 0.017001
 19%|█████▊                        | 77/400 [22:42<1:33:37, 17.39s/it]2022-01-17 11:48:33,509 iteration 1310 : loss : 0.062050, loss_ce: 0.019300
2022-01-17 11:48:34,432 iteration 1311 : loss : 0.051164, loss_ce: 0.021499
2022-01-17 11:48:35,345 iteration 1312 : loss : 0.033912, loss_ce: 0.012906
2022-01-17 11:48:36,264 iteration 1313 : loss : 0.070291, loss_ce: 0.022161
2022-01-17 11:48:37,218 iteration 1314 : loss : 0.044195, loss_ce: 0.019783
2022-01-17 11:48:38,192 iteration 1315 : loss : 0.048435, loss_ce: 0.017147
2022-01-17 11:48:39,260 iteration 1316 : loss : 0.071542, loss_ce: 0.031458
2022-01-17 11:48:40,194 iteration 1317 : loss : 0.045893, loss_ce: 0.025499
2022-01-17 11:48:41,218 iteration 1318 : loss : 0.115656, loss_ce: 0.026979
2022-01-17 11:48:42,190 iteration 1319 : loss : 0.052131, loss_ce: 0.021465
2022-01-17 11:48:43,103 iteration 1320 : loss : 0.039360, loss_ce: 0.014937
2022-01-17 11:48:44,062 iteration 1321 : loss : 0.063336, loss_ce: 0.017692
2022-01-17 11:48:44,948 iteration 1322 : loss : 0.063593, loss_ce: 0.030125
2022-01-17 11:48:45,887 iteration 1323 : loss : 0.059487, loss_ce: 0.020979
2022-01-17 11:48:46,864 iteration 1324 : loss : 0.039829, loss_ce: 0.016451
2022-01-17 11:48:47,881 iteration 1325 : loss : 0.066674, loss_ce: 0.025715
2022-01-17 11:48:48,737 iteration 1326 : loss : 0.053092, loss_ce: 0.019104
 20%|█████▊                        | 78/400 [22:58<1:31:33, 17.06s/it]2022-01-17 11:48:49,693 iteration 1327 : loss : 0.061973, loss_ce: 0.019961
2022-01-17 11:48:50,669 iteration 1328 : loss : 0.046812, loss_ce: 0.023959
2022-01-17 11:48:51,612 iteration 1329 : loss : 0.042125, loss_ce: 0.017566
2022-01-17 11:48:52,533 iteration 1330 : loss : 0.087306, loss_ce: 0.022882
2022-01-17 11:48:53,414 iteration 1331 : loss : 0.048341, loss_ce: 0.026572
2022-01-17 11:48:54,316 iteration 1332 : loss : 0.045476, loss_ce: 0.014738
2022-01-17 11:48:55,248 iteration 1333 : loss : 0.045490, loss_ce: 0.013903
2022-01-17 11:48:56,196 iteration 1334 : loss : 0.051852, loss_ce: 0.021519
2022-01-17 11:48:57,116 iteration 1335 : loss : 0.042594, loss_ce: 0.014604
2022-01-17 11:48:58,039 iteration 1336 : loss : 0.029683, loss_ce: 0.010729
2022-01-17 11:48:59,046 iteration 1337 : loss : 0.059121, loss_ce: 0.023731
2022-01-17 11:49:00,025 iteration 1338 : loss : 0.062314, loss_ce: 0.017360
2022-01-17 11:49:00,997 iteration 1339 : loss : 0.053139, loss_ce: 0.025948
2022-01-17 11:49:01,973 iteration 1340 : loss : 0.036993, loss_ce: 0.015616
2022-01-17 11:49:02,928 iteration 1341 : loss : 0.043676, loss_ce: 0.015335
2022-01-17 11:49:03,862 iteration 1342 : loss : 0.067576, loss_ce: 0.024529
2022-01-17 11:49:04,752 iteration 1343 : loss : 0.048254, loss_ce: 0.020348
 20%|█████▉                        | 79/400 [23:14<1:29:35, 16.75s/it]2022-01-17 11:49:05,744 iteration 1344 : loss : 0.051296, loss_ce: 0.020563
2022-01-17 11:49:06,771 iteration 1345 : loss : 0.059798, loss_ce: 0.021085
2022-01-17 11:49:07,702 iteration 1346 : loss : 0.053270, loss_ce: 0.023787
2022-01-17 11:49:08,723 iteration 1347 : loss : 0.046461, loss_ce: 0.021194
2022-01-17 11:49:09,783 iteration 1348 : loss : 0.083285, loss_ce: 0.029701
2022-01-17 11:49:10,726 iteration 1349 : loss : 0.044838, loss_ce: 0.016628
2022-01-17 11:49:11,665 iteration 1350 : loss : 0.052977, loss_ce: 0.020791
2022-01-17 11:49:12,602 iteration 1351 : loss : 0.037476, loss_ce: 0.018112
2022-01-17 11:49:13,602 iteration 1352 : loss : 0.033125, loss_ce: 0.015027
2022-01-17 11:49:14,573 iteration 1353 : loss : 0.061994, loss_ce: 0.021197
2022-01-17 11:49:15,567 iteration 1354 : loss : 0.053390, loss_ce: 0.016892
2022-01-17 11:49:16,626 iteration 1355 : loss : 0.147599, loss_ce: 0.048394
2022-01-17 11:49:17,603 iteration 1356 : loss : 0.048093, loss_ce: 0.019070
2022-01-17 11:49:18,592 iteration 1357 : loss : 0.049346, loss_ce: 0.021863
2022-01-17 11:49:19,593 iteration 1358 : loss : 0.068803, loss_ce: 0.025607
2022-01-17 11:49:20,531 iteration 1359 : loss : 0.052636, loss_ce: 0.021104
2022-01-17 11:49:20,532 Training Data Eval:
2022-01-17 11:49:24,989   Average segmentation loss on training set: 0.0344
2022-01-17 11:49:24,990 Validation Data Eval:
2022-01-17 11:49:26,491   Average segmentation loss on validation set: 0.1236
2022-01-17 11:49:27,503 iteration 1360 : loss : 0.044354, loss_ce: 0.012012
 20%|██████                        | 80/400 [23:37<1:38:55, 18.55s/it]2022-01-17 11:49:28,598 iteration 1361 : loss : 0.048362, loss_ce: 0.020873
2022-01-17 11:49:29,555 iteration 1362 : loss : 0.033851, loss_ce: 0.010284
2022-01-17 11:49:30,674 iteration 1363 : loss : 0.066010, loss_ce: 0.025422
2022-01-17 11:49:31,495 iteration 1364 : loss : 0.040314, loss_ce: 0.011324
2022-01-17 11:49:32,519 iteration 1365 : loss : 0.039977, loss_ce: 0.017106
2022-01-17 11:49:33,487 iteration 1366 : loss : 0.052807, loss_ce: 0.020462
2022-01-17 11:49:34,426 iteration 1367 : loss : 0.038774, loss_ce: 0.014427
2022-01-17 11:49:35,396 iteration 1368 : loss : 0.036806, loss_ce: 0.017558
2022-01-17 11:49:36,321 iteration 1369 : loss : 0.045754, loss_ce: 0.015676
2022-01-17 11:49:37,320 iteration 1370 : loss : 0.050140, loss_ce: 0.023559
2022-01-17 11:49:38,250 iteration 1371 : loss : 0.036298, loss_ce: 0.012801
2022-01-17 11:49:39,171 iteration 1372 : loss : 0.041002, loss_ce: 0.015433
2022-01-17 11:49:40,079 iteration 1373 : loss : 0.049441, loss_ce: 0.017551
2022-01-17 11:49:41,043 iteration 1374 : loss : 0.037450, loss_ce: 0.013405
2022-01-17 11:49:42,018 iteration 1375 : loss : 0.046670, loss_ce: 0.020385
2022-01-17 11:49:42,980 iteration 1376 : loss : 0.048369, loss_ce: 0.013750
2022-01-17 11:49:43,917 iteration 1377 : loss : 0.024888, loss_ce: 0.008689
 20%|██████                        | 81/400 [23:53<1:35:13, 17.91s/it]2022-01-17 11:49:44,837 iteration 1378 : loss : 0.046382, loss_ce: 0.017880
2022-01-17 11:49:45,839 iteration 1379 : loss : 0.030988, loss_ce: 0.011324
2022-01-17 11:49:46,803 iteration 1380 : loss : 0.038230, loss_ce: 0.014258
2022-01-17 11:49:47,842 iteration 1381 : loss : 0.041311, loss_ce: 0.016274
2022-01-17 11:49:48,709 iteration 1382 : loss : 0.037297, loss_ce: 0.013774
2022-01-17 11:49:49,732 iteration 1383 : loss : 0.035777, loss_ce: 0.013127
2022-01-17 11:49:50,694 iteration 1384 : loss : 0.042586, loss_ce: 0.014924
2022-01-17 11:49:51,583 iteration 1385 : loss : 0.090175, loss_ce: 0.025825
2022-01-17 11:49:52,501 iteration 1386 : loss : 0.033365, loss_ce: 0.011722
2022-01-17 11:49:53,439 iteration 1387 : loss : 0.060119, loss_ce: 0.024089
2022-01-17 11:49:54,394 iteration 1388 : loss : 0.039815, loss_ce: 0.013246
2022-01-17 11:49:55,340 iteration 1389 : loss : 0.044600, loss_ce: 0.017460
2022-01-17 11:49:56,344 iteration 1390 : loss : 0.034969, loss_ce: 0.014532
2022-01-17 11:49:57,370 iteration 1391 : loss : 0.034764, loss_ce: 0.012539
2022-01-17 11:49:58,375 iteration 1392 : loss : 0.031413, loss_ce: 0.014625
2022-01-17 11:49:59,304 iteration 1393 : loss : 0.042299, loss_ce: 0.015956
2022-01-17 11:50:00,320 iteration 1394 : loss : 0.036336, loss_ce: 0.016635
 20%|██████▏                       | 82/400 [24:10<1:32:30, 17.46s/it]2022-01-17 11:50:01,287 iteration 1395 : loss : 0.047727, loss_ce: 0.018074
2022-01-17 11:50:02,207 iteration 1396 : loss : 0.054306, loss_ce: 0.027086
2022-01-17 11:50:03,209 iteration 1397 : loss : 0.064014, loss_ce: 0.021430
2022-01-17 11:50:04,221 iteration 1398 : loss : 0.059181, loss_ce: 0.024355
2022-01-17 11:50:05,074 iteration 1399 : loss : 0.038438, loss_ce: 0.014944
2022-01-17 11:50:05,927 iteration 1400 : loss : 0.037963, loss_ce: 0.013012
2022-01-17 11:50:06,933 iteration 1401 : loss : 0.037771, loss_ce: 0.012272
2022-01-17 11:50:07,895 iteration 1402 : loss : 0.049456, loss_ce: 0.017915
2022-01-17 11:50:08,785 iteration 1403 : loss : 0.046327, loss_ce: 0.015270
2022-01-17 11:50:09,678 iteration 1404 : loss : 0.030175, loss_ce: 0.013184
2022-01-17 11:50:10,627 iteration 1405 : loss : 0.040907, loss_ce: 0.014317
2022-01-17 11:50:11,584 iteration 1406 : loss : 0.053916, loss_ce: 0.021418
2022-01-17 11:50:12,584 iteration 1407 : loss : 0.030010, loss_ce: 0.010883
2022-01-17 11:50:13,537 iteration 1408 : loss : 0.038978, loss_ce: 0.012891
2022-01-17 11:50:14,500 iteration 1409 : loss : 0.070023, loss_ce: 0.022309
2022-01-17 11:50:15,529 iteration 1410 : loss : 0.037924, loss_ce: 0.013847
2022-01-17 11:50:16,444 iteration 1411 : loss : 0.043621, loss_ce: 0.012861
 21%|██████▏                       | 83/400 [24:26<1:30:06, 17.06s/it]2022-01-17 11:50:17,402 iteration 1412 : loss : 0.061776, loss_ce: 0.026192
2022-01-17 11:50:18,416 iteration 1413 : loss : 0.050868, loss_ce: 0.014055
2022-01-17 11:50:19,342 iteration 1414 : loss : 0.034268, loss_ce: 0.011430
2022-01-17 11:50:20,336 iteration 1415 : loss : 0.043790, loss_ce: 0.011417
2022-01-17 11:50:21,269 iteration 1416 : loss : 0.043138, loss_ce: 0.016551
2022-01-17 11:50:22,180 iteration 1417 : loss : 0.060113, loss_ce: 0.016332
2022-01-17 11:50:23,093 iteration 1418 : loss : 0.048165, loss_ce: 0.020853
2022-01-17 11:50:23,984 iteration 1419 : loss : 0.039893, loss_ce: 0.014855
2022-01-17 11:50:24,983 iteration 1420 : loss : 0.048760, loss_ce: 0.016525
2022-01-17 11:50:26,018 iteration 1421 : loss : 0.049946, loss_ce: 0.020554
2022-01-17 11:50:26,995 iteration 1422 : loss : 0.040363, loss_ce: 0.012298
2022-01-17 11:50:27,870 iteration 1423 : loss : 0.044986, loss_ce: 0.018432
2022-01-17 11:50:28,852 iteration 1424 : loss : 0.036255, loss_ce: 0.015624
2022-01-17 11:50:29,832 iteration 1425 : loss : 0.039524, loss_ce: 0.014713
2022-01-17 11:50:30,741 iteration 1426 : loss : 0.049807, loss_ce: 0.022463
2022-01-17 11:50:31,686 iteration 1427 : loss : 0.063612, loss_ce: 0.022732
2022-01-17 11:50:32,535 iteration 1428 : loss : 0.051490, loss_ce: 0.019844
 21%|██████▎                       | 84/400 [24:42<1:28:18, 16.77s/it]2022-01-17 11:50:33,601 iteration 1429 : loss : 0.044493, loss_ce: 0.020034
2022-01-17 11:50:34,502 iteration 1430 : loss : 0.083423, loss_ce: 0.018629
2022-01-17 11:50:35,444 iteration 1431 : loss : 0.048580, loss_ce: 0.021993
2022-01-17 11:50:36,418 iteration 1432 : loss : 0.053863, loss_ce: 0.024124
2022-01-17 11:50:37,421 iteration 1433 : loss : 0.047144, loss_ce: 0.015210
2022-01-17 11:50:38,341 iteration 1434 : loss : 0.048377, loss_ce: 0.019050
2022-01-17 11:50:39,317 iteration 1435 : loss : 0.042752, loss_ce: 0.017849
2022-01-17 11:50:40,302 iteration 1436 : loss : 0.063563, loss_ce: 0.023721
2022-01-17 11:50:41,297 iteration 1437 : loss : 0.078978, loss_ce: 0.020171
2022-01-17 11:50:42,245 iteration 1438 : loss : 0.039341, loss_ce: 0.018756
2022-01-17 11:50:43,243 iteration 1439 : loss : 0.041687, loss_ce: 0.015753
2022-01-17 11:50:44,231 iteration 1440 : loss : 0.046672, loss_ce: 0.020072
2022-01-17 11:50:45,161 iteration 1441 : loss : 0.033527, loss_ce: 0.014001
2022-01-17 11:50:46,114 iteration 1442 : loss : 0.043788, loss_ce: 0.017191
2022-01-17 11:50:47,089 iteration 1443 : loss : 0.046669, loss_ce: 0.017559
2022-01-17 11:50:48,039 iteration 1444 : loss : 0.086368, loss_ce: 0.021315
2022-01-17 11:50:48,039 Training Data Eval:
2022-01-17 11:50:52,482   Average segmentation loss on training set: 0.0331
2022-01-17 11:50:52,482 Validation Data Eval:
2022-01-17 11:50:53,976   Average segmentation loss on validation set: 0.0730
2022-01-17 11:50:54,927 iteration 1445 : loss : 0.035604, loss_ce: 0.010648
 21%|██████▍                       | 85/400 [25:04<1:36:52, 18.45s/it]2022-01-17 11:50:56,020 iteration 1446 : loss : 0.042748, loss_ce: 0.014344
2022-01-17 11:50:56,959 iteration 1447 : loss : 0.058694, loss_ce: 0.021269
2022-01-17 11:50:57,851 iteration 1448 : loss : 0.056410, loss_ce: 0.033964
2022-01-17 11:50:58,827 iteration 1449 : loss : 0.035566, loss_ce: 0.012163
2022-01-17 11:50:59,887 iteration 1450 : loss : 0.054974, loss_ce: 0.026409
2022-01-17 11:51:00,959 iteration 1451 : loss : 0.065301, loss_ce: 0.028312
2022-01-17 11:51:01,876 iteration 1452 : loss : 0.031349, loss_ce: 0.010268
2022-01-17 11:51:02,805 iteration 1453 : loss : 0.047603, loss_ce: 0.023756
2022-01-17 11:51:03,776 iteration 1454 : loss : 0.065400, loss_ce: 0.022364
2022-01-17 11:51:04,689 iteration 1455 : loss : 0.033988, loss_ce: 0.014626
2022-01-17 11:51:05,720 iteration 1456 : loss : 0.081896, loss_ce: 0.024201
2022-01-17 11:51:06,664 iteration 1457 : loss : 0.053175, loss_ce: 0.026458
2022-01-17 11:51:07,600 iteration 1458 : loss : 0.038459, loss_ce: 0.013110
2022-01-17 11:51:08,505 iteration 1459 : loss : 0.046100, loss_ce: 0.013052
2022-01-17 11:51:09,533 iteration 1460 : loss : 0.068178, loss_ce: 0.028143
2022-01-17 11:51:10,482 iteration 1461 : loss : 0.055403, loss_ce: 0.024551
2022-01-17 11:51:11,488 iteration 1462 : loss : 0.045427, loss_ce: 0.017492
 22%|██████▍                       | 86/400 [25:21<1:33:36, 17.89s/it]2022-01-17 11:51:12,471 iteration 1463 : loss : 0.049048, loss_ce: 0.021809
2022-01-17 11:51:13,388 iteration 1464 : loss : 0.034293, loss_ce: 0.012767
2022-01-17 11:51:14,367 iteration 1465 : loss : 0.045350, loss_ce: 0.012674
2022-01-17 11:51:15,354 iteration 1466 : loss : 0.036116, loss_ce: 0.014358
2022-01-17 11:51:16,311 iteration 1467 : loss : 0.041786, loss_ce: 0.017415
2022-01-17 11:51:17,233 iteration 1468 : loss : 0.035561, loss_ce: 0.015407
2022-01-17 11:51:18,173 iteration 1469 : loss : 0.052831, loss_ce: 0.020051
2022-01-17 11:51:19,149 iteration 1470 : loss : 0.054218, loss_ce: 0.020269
2022-01-17 11:51:20,114 iteration 1471 : loss : 0.054726, loss_ce: 0.030073
2022-01-17 11:51:20,955 iteration 1472 : loss : 0.033781, loss_ce: 0.012188
2022-01-17 11:51:22,001 iteration 1473 : loss : 0.043206, loss_ce: 0.018630
2022-01-17 11:51:23,006 iteration 1474 : loss : 0.043674, loss_ce: 0.015355
2022-01-17 11:51:23,959 iteration 1475 : loss : 0.033806, loss_ce: 0.014281
2022-01-17 11:51:25,009 iteration 1476 : loss : 0.055189, loss_ce: 0.017331
2022-01-17 11:51:26,017 iteration 1477 : loss : 0.042618, loss_ce: 0.014090
2022-01-17 11:51:27,051 iteration 1478 : loss : 0.042765, loss_ce: 0.017456
2022-01-17 11:51:27,953 iteration 1479 : loss : 0.037491, loss_ce: 0.012652
 22%|██████▌                       | 87/400 [25:37<1:31:05, 17.46s/it]2022-01-17 11:51:28,947 iteration 1480 : loss : 0.056802, loss_ce: 0.019594
2022-01-17 11:51:29,868 iteration 1481 : loss : 0.034396, loss_ce: 0.013325
2022-01-17 11:51:30,804 iteration 1482 : loss : 0.031886, loss_ce: 0.012237
2022-01-17 11:51:31,834 iteration 1483 : loss : 0.059861, loss_ce: 0.023891
2022-01-17 11:51:32,920 iteration 1484 : loss : 0.042624, loss_ce: 0.014654
2022-01-17 11:51:33,930 iteration 1485 : loss : 0.037286, loss_ce: 0.016130
2022-01-17 11:51:34,847 iteration 1486 : loss : 0.034775, loss_ce: 0.013702
2022-01-17 11:51:35,786 iteration 1487 : loss : 0.042698, loss_ce: 0.021825
2022-01-17 11:51:36,743 iteration 1488 : loss : 0.037224, loss_ce: 0.014536
2022-01-17 11:51:37,707 iteration 1489 : loss : 0.033852, loss_ce: 0.012213
2022-01-17 11:51:38,699 iteration 1490 : loss : 0.051439, loss_ce: 0.017579
2022-01-17 11:51:39,726 iteration 1491 : loss : 0.053338, loss_ce: 0.022355
2022-01-17 11:51:40,640 iteration 1492 : loss : 0.040368, loss_ce: 0.016098
2022-01-17 11:51:41,634 iteration 1493 : loss : 0.049236, loss_ce: 0.017064
2022-01-17 11:51:42,559 iteration 1494 : loss : 0.030731, loss_ce: 0.012679
2022-01-17 11:51:43,493 iteration 1495 : loss : 0.041983, loss_ce: 0.015348
2022-01-17 11:51:44,455 iteration 1496 : loss : 0.040939, loss_ce: 0.011561
 22%|██████▌                       | 88/400 [25:54<1:29:17, 17.17s/it]2022-01-17 11:51:45,403 iteration 1497 : loss : 0.045143, loss_ce: 0.018190
2022-01-17 11:51:46,326 iteration 1498 : loss : 0.035165, loss_ce: 0.010366
2022-01-17 11:51:47,324 iteration 1499 : loss : 0.051251, loss_ce: 0.023370
2022-01-17 11:51:48,207 iteration 1500 : loss : 0.049720, loss_ce: 0.015487
2022-01-17 11:51:49,138 iteration 1501 : loss : 0.031039, loss_ce: 0.010932
2022-01-17 11:51:50,116 iteration 1502 : loss : 0.039515, loss_ce: 0.013370
2022-01-17 11:51:51,041 iteration 1503 : loss : 0.022579, loss_ce: 0.009414
2022-01-17 11:51:51,970 iteration 1504 : loss : 0.037718, loss_ce: 0.012243
2022-01-17 11:51:52,854 iteration 1505 : loss : 0.033124, loss_ce: 0.011778
2022-01-17 11:51:53,793 iteration 1506 : loss : 0.040543, loss_ce: 0.015834
2022-01-17 11:51:54,734 iteration 1507 : loss : 0.063594, loss_ce: 0.019320
2022-01-17 11:51:55,648 iteration 1508 : loss : 0.032294, loss_ce: 0.013180
2022-01-17 11:51:56,588 iteration 1509 : loss : 0.048224, loss_ce: 0.017195
2022-01-17 11:51:57,495 iteration 1510 : loss : 0.025743, loss_ce: 0.009637
2022-01-17 11:51:58,463 iteration 1511 : loss : 0.033864, loss_ce: 0.015080
2022-01-17 11:51:59,373 iteration 1512 : loss : 0.031780, loss_ce: 0.012754
2022-01-17 11:52:00,338 iteration 1513 : loss : 0.043989, loss_ce: 0.022530
 22%|██████▋                       | 89/400 [26:10<1:26:59, 16.78s/it]2022-01-17 11:52:01,305 iteration 1514 : loss : 0.040865, loss_ce: 0.012723
2022-01-17 11:52:02,258 iteration 1515 : loss : 0.055794, loss_ce: 0.025726
2022-01-17 11:52:03,235 iteration 1516 : loss : 0.040101, loss_ce: 0.014601
2022-01-17 11:52:04,172 iteration 1517 : loss : 0.031424, loss_ce: 0.012898
2022-01-17 11:52:05,151 iteration 1518 : loss : 0.029441, loss_ce: 0.008932
2022-01-17 11:52:06,076 iteration 1519 : loss : 0.033035, loss_ce: 0.011165
2022-01-17 11:52:06,993 iteration 1520 : loss : 0.034330, loss_ce: 0.012183
2022-01-17 11:52:07,922 iteration 1521 : loss : 0.052739, loss_ce: 0.017077
2022-01-17 11:52:08,979 iteration 1522 : loss : 0.042313, loss_ce: 0.013113
2022-01-17 11:52:09,871 iteration 1523 : loss : 0.031668, loss_ce: 0.013641
2022-01-17 11:52:10,847 iteration 1524 : loss : 0.049846, loss_ce: 0.017562
2022-01-17 11:52:11,766 iteration 1525 : loss : 0.027232, loss_ce: 0.010912
2022-01-17 11:52:12,779 iteration 1526 : loss : 0.037187, loss_ce: 0.014476
2022-01-17 11:52:13,792 iteration 1527 : loss : 0.055966, loss_ce: 0.025529
2022-01-17 11:52:14,781 iteration 1528 : loss : 0.040689, loss_ce: 0.017219
2022-01-17 11:52:15,696 iteration 1529 : loss : 0.042430, loss_ce: 0.016970
2022-01-17 11:52:15,697 Training Data Eval:
2022-01-17 11:52:20,164   Average segmentation loss on training set: 0.0302
2022-01-17 11:52:20,165 Validation Data Eval:
2022-01-17 11:52:21,668   Average segmentation loss on validation set: 0.0794
2022-01-17 11:52:22,606 iteration 1530 : loss : 0.045727, loss_ce: 0.021029
 22%|██████▊                       | 90/400 [26:32<1:35:13, 18.43s/it]2022-01-17 11:52:23,726 iteration 1531 : loss : 0.053361, loss_ce: 0.020543
2022-01-17 11:52:24,720 iteration 1532 : loss : 0.048295, loss_ce: 0.017898
2022-01-17 11:52:25,623 iteration 1533 : loss : 0.027938, loss_ce: 0.012566
2022-01-17 11:52:26,631 iteration 1534 : loss : 0.046411, loss_ce: 0.016280
2022-01-17 11:52:27,565 iteration 1535 : loss : 0.037764, loss_ce: 0.014308
2022-01-17 11:52:28,482 iteration 1536 : loss : 0.068145, loss_ce: 0.034312
2022-01-17 11:52:29,397 iteration 1537 : loss : 0.047088, loss_ce: 0.013830
2022-01-17 11:52:30,289 iteration 1538 : loss : 0.052193, loss_ce: 0.010608
2022-01-17 11:52:31,226 iteration 1539 : loss : 0.039544, loss_ce: 0.013407
2022-01-17 11:52:32,175 iteration 1540 : loss : 0.052165, loss_ce: 0.023466
2022-01-17 11:52:33,036 iteration 1541 : loss : 0.027732, loss_ce: 0.007692
2022-01-17 11:52:33,990 iteration 1542 : loss : 0.057843, loss_ce: 0.026009
2022-01-17 11:52:34,917 iteration 1543 : loss : 0.033717, loss_ce: 0.009835
2022-01-17 11:52:35,798 iteration 1544 : loss : 0.037187, loss_ce: 0.012745
2022-01-17 11:52:36,732 iteration 1545 : loss : 0.039506, loss_ce: 0.015609
2022-01-17 11:52:37,660 iteration 1546 : loss : 0.037266, loss_ce: 0.016584
2022-01-17 11:52:38,576 iteration 1547 : loss : 0.072415, loss_ce: 0.031358
 23%|██████▊                       | 91/400 [26:48<1:31:07, 17.69s/it]2022-01-17 11:52:39,556 iteration 1548 : loss : 0.046929, loss_ce: 0.016835
2022-01-17 11:52:40,443 iteration 1549 : loss : 0.034491, loss_ce: 0.014945
2022-01-17 11:52:41,487 iteration 1550 : loss : 0.051554, loss_ce: 0.021101
2022-01-17 11:52:42,431 iteration 1551 : loss : 0.041254, loss_ce: 0.016769
2022-01-17 11:52:43,388 iteration 1552 : loss : 0.035943, loss_ce: 0.014569
2022-01-17 11:52:44,250 iteration 1553 : loss : 0.028583, loss_ce: 0.014686
2022-01-17 11:52:45,151 iteration 1554 : loss : 0.053884, loss_ce: 0.020475
2022-01-17 11:52:46,156 iteration 1555 : loss : 0.045954, loss_ce: 0.014834
2022-01-17 11:52:47,231 iteration 1556 : loss : 0.059946, loss_ce: 0.023238
2022-01-17 11:52:48,246 iteration 1557 : loss : 0.071067, loss_ce: 0.013964
2022-01-17 11:52:49,189 iteration 1558 : loss : 0.052605, loss_ce: 0.012966
2022-01-17 11:52:50,231 iteration 1559 : loss : 0.045138, loss_ce: 0.019489
2022-01-17 11:52:51,148 iteration 1560 : loss : 0.043270, loss_ce: 0.012668
2022-01-17 11:52:52,070 iteration 1561 : loss : 0.049286, loss_ce: 0.014819
2022-01-17 11:52:53,022 iteration 1562 : loss : 0.046065, loss_ce: 0.020782
2022-01-17 11:52:53,949 iteration 1563 : loss : 0.040048, loss_ce: 0.020229
2022-01-17 11:52:54,900 iteration 1564 : loss : 0.043214, loss_ce: 0.013414
 23%|██████▉                       | 92/400 [27:04<1:28:42, 17.28s/it]2022-01-17 11:52:55,912 iteration 1565 : loss : 0.033944, loss_ce: 0.013702
2022-01-17 11:52:56,833 iteration 1566 : loss : 0.045674, loss_ce: 0.020445
2022-01-17 11:52:57,812 iteration 1567 : loss : 0.061207, loss_ce: 0.019888
2022-01-17 11:52:58,865 iteration 1568 : loss : 0.034653, loss_ce: 0.014522
2022-01-17 11:52:59,783 iteration 1569 : loss : 0.037859, loss_ce: 0.015029
2022-01-17 11:53:00,736 iteration 1570 : loss : 0.032751, loss_ce: 0.013382
2022-01-17 11:53:01,659 iteration 1571 : loss : 0.035152, loss_ce: 0.015300
2022-01-17 11:53:02,608 iteration 1572 : loss : 0.037809, loss_ce: 0.016943
2022-01-17 11:53:03,608 iteration 1573 : loss : 0.052979, loss_ce: 0.014047
2022-01-17 11:53:04,561 iteration 1574 : loss : 0.040020, loss_ce: 0.018099
2022-01-17 11:53:05,539 iteration 1575 : loss : 0.049266, loss_ce: 0.023570
2022-01-17 11:53:06,473 iteration 1576 : loss : 0.039904, loss_ce: 0.013091
2022-01-17 11:53:07,377 iteration 1577 : loss : 0.036551, loss_ce: 0.011134
2022-01-17 11:53:08,228 iteration 1578 : loss : 0.033871, loss_ce: 0.013717
2022-01-17 11:53:09,167 iteration 1579 : loss : 0.029051, loss_ce: 0.010383
2022-01-17 11:53:10,132 iteration 1580 : loss : 0.035163, loss_ce: 0.011251
2022-01-17 11:53:11,096 iteration 1581 : loss : 0.029518, loss_ce: 0.012360
 23%|██████▉                       | 93/400 [27:20<1:26:45, 16.96s/it]2022-01-17 11:53:12,121 iteration 1582 : loss : 0.040671, loss_ce: 0.018575
2022-01-17 11:53:13,073 iteration 1583 : loss : 0.041166, loss_ce: 0.010863
2022-01-17 11:53:13,972 iteration 1584 : loss : 0.036010, loss_ce: 0.012274
2022-01-17 11:53:14,906 iteration 1585 : loss : 0.028127, loss_ce: 0.013410
2022-01-17 11:53:15,770 iteration 1586 : loss : 0.026271, loss_ce: 0.012118
2022-01-17 11:53:16,692 iteration 1587 : loss : 0.037609, loss_ce: 0.013387
2022-01-17 11:53:17,620 iteration 1588 : loss : 0.030749, loss_ce: 0.009255
2022-01-17 11:53:18,563 iteration 1589 : loss : 0.036993, loss_ce: 0.016398
2022-01-17 11:53:19,594 iteration 1590 : loss : 0.044128, loss_ce: 0.016405
2022-01-17 11:53:20,516 iteration 1591 : loss : 0.032466, loss_ce: 0.014404
2022-01-17 11:53:21,378 iteration 1592 : loss : 0.028540, loss_ce: 0.011293
2022-01-17 11:53:22,337 iteration 1593 : loss : 0.068460, loss_ce: 0.023848
2022-01-17 11:53:23,272 iteration 1594 : loss : 0.037844, loss_ce: 0.012618
2022-01-17 11:53:24,165 iteration 1595 : loss : 0.033356, loss_ce: 0.017379
2022-01-17 11:53:25,028 iteration 1596 : loss : 0.040320, loss_ce: 0.014045
2022-01-17 11:53:25,994 iteration 1597 : loss : 0.055842, loss_ce: 0.014316
2022-01-17 11:53:26,969 iteration 1598 : loss : 0.043384, loss_ce: 0.015904
 24%|███████                       | 94/400 [27:36<1:24:49, 16.63s/it]2022-01-17 11:53:27,992 iteration 1599 : loss : 0.045828, loss_ce: 0.021078
2022-01-17 11:53:28,909 iteration 1600 : loss : 0.034160, loss_ce: 0.017853
2022-01-17 11:53:29,881 iteration 1601 : loss : 0.046927, loss_ce: 0.018040
2022-01-17 11:53:30,830 iteration 1602 : loss : 0.040692, loss_ce: 0.013177
2022-01-17 11:53:31,750 iteration 1603 : loss : 0.032332, loss_ce: 0.011376
2022-01-17 11:53:32,663 iteration 1604 : loss : 0.035473, loss_ce: 0.008704
2022-01-17 11:53:33,586 iteration 1605 : loss : 0.057303, loss_ce: 0.017565
2022-01-17 11:53:34,539 iteration 1606 : loss : 0.027230, loss_ce: 0.010874
2022-01-17 11:53:35,480 iteration 1607 : loss : 0.039371, loss_ce: 0.013952
2022-01-17 11:53:36,512 iteration 1608 : loss : 0.043624, loss_ce: 0.018005
2022-01-17 11:53:37,444 iteration 1609 : loss : 0.036008, loss_ce: 0.014153
2022-01-17 11:53:38,481 iteration 1610 : loss : 0.040889, loss_ce: 0.016257
2022-01-17 11:53:39,510 iteration 1611 : loss : 0.040961, loss_ce: 0.020713
2022-01-17 11:53:40,548 iteration 1612 : loss : 0.036658, loss_ce: 0.013053
2022-01-17 11:53:41,494 iteration 1613 : loss : 0.049335, loss_ce: 0.019363
2022-01-17 11:53:42,494 iteration 1614 : loss : 0.048838, loss_ce: 0.019661
2022-01-17 11:53:42,495 Training Data Eval:
2022-01-17 11:53:46,950   Average segmentation loss on training set: 0.0346
2022-01-17 11:53:46,950 Validation Data Eval:
2022-01-17 11:53:48,457   Average segmentation loss on validation set: 0.0879
2022-01-17 11:53:49,455 iteration 1615 : loss : 0.063778, loss_ce: 0.016595
 24%|███████▏                      | 95/400 [27:59<1:33:28, 18.39s/it]2022-01-17 11:53:50,449 iteration 1616 : loss : 0.044783, loss_ce: 0.016293
2022-01-17 11:53:51,391 iteration 1617 : loss : 0.056105, loss_ce: 0.021860
2022-01-17 11:53:52,289 iteration 1618 : loss : 0.035607, loss_ce: 0.012121
2022-01-17 11:53:53,232 iteration 1619 : loss : 0.033339, loss_ce: 0.018800
2022-01-17 11:53:54,304 iteration 1620 : loss : 0.032905, loss_ce: 0.009692
2022-01-17 11:53:55,371 iteration 1621 : loss : 0.031224, loss_ce: 0.011554
2022-01-17 11:53:56,311 iteration 1622 : loss : 0.045680, loss_ce: 0.018635
2022-01-17 11:53:57,205 iteration 1623 : loss : 0.030611, loss_ce: 0.009628
2022-01-17 11:53:58,171 iteration 1624 : loss : 0.046696, loss_ce: 0.019709
2022-01-17 11:53:59,050 iteration 1625 : loss : 0.029294, loss_ce: 0.009520
2022-01-17 11:53:59,976 iteration 1626 : loss : 0.033002, loss_ce: 0.013015
2022-01-17 11:54:01,048 iteration 1627 : loss : 0.062731, loss_ce: 0.024188
2022-01-17 11:54:02,090 iteration 1628 : loss : 0.037808, loss_ce: 0.015016
2022-01-17 11:54:03,003 iteration 1629 : loss : 0.035451, loss_ce: 0.012197
2022-01-17 11:54:03,892 iteration 1630 : loss : 0.024166, loss_ce: 0.009775
2022-01-17 11:54:04,791 iteration 1631 : loss : 0.033641, loss_ce: 0.011595
2022-01-17 11:54:05,709 iteration 1632 : loss : 0.029085, loss_ce: 0.011884
 24%|███████▏                      | 96/400 [28:15<1:29:54, 17.75s/it]2022-01-17 11:54:06,699 iteration 1633 : loss : 0.041044, loss_ce: 0.013163
2022-01-17 11:54:07,669 iteration 1634 : loss : 0.052996, loss_ce: 0.020683
2022-01-17 11:54:08,585 iteration 1635 : loss : 0.039649, loss_ce: 0.012314
2022-01-17 11:54:09,451 iteration 1636 : loss : 0.032214, loss_ce: 0.014991
2022-01-17 11:54:10,421 iteration 1637 : loss : 0.039944, loss_ce: 0.015026
2022-01-17 11:54:11,362 iteration 1638 : loss : 0.046289, loss_ce: 0.021233
2022-01-17 11:54:12,367 iteration 1639 : loss : 0.050299, loss_ce: 0.027057
2022-01-17 11:54:13,282 iteration 1640 : loss : 0.037089, loss_ce: 0.012415
2022-01-17 11:54:14,312 iteration 1641 : loss : 0.047327, loss_ce: 0.018092
2022-01-17 11:54:15,208 iteration 1642 : loss : 0.033987, loss_ce: 0.013058
2022-01-17 11:54:16,090 iteration 1643 : loss : 0.037584, loss_ce: 0.012909
2022-01-17 11:54:17,097 iteration 1644 : loss : 0.040872, loss_ce: 0.016201
2022-01-17 11:54:18,138 iteration 1645 : loss : 0.028738, loss_ce: 0.012509
2022-01-17 11:54:19,044 iteration 1646 : loss : 0.063702, loss_ce: 0.023208
2022-01-17 11:54:19,963 iteration 1647 : loss : 0.054173, loss_ce: 0.020864
2022-01-17 11:54:20,818 iteration 1648 : loss : 0.029709, loss_ce: 0.011556
2022-01-17 11:54:21,699 iteration 1649 : loss : 0.036742, loss_ce: 0.012810
 24%|███████▎                      | 97/400 [28:31<1:26:57, 17.22s/it]2022-01-17 11:54:22,800 iteration 1650 : loss : 0.066836, loss_ce: 0.029278
2022-01-17 11:54:23,718 iteration 1651 : loss : 0.041537, loss_ce: 0.010266
2022-01-17 11:54:24,667 iteration 1652 : loss : 0.056534, loss_ce: 0.019628
2022-01-17 11:54:25,575 iteration 1653 : loss : 0.033040, loss_ce: 0.010479
2022-01-17 11:54:26,493 iteration 1654 : loss : 0.035691, loss_ce: 0.011950
2022-01-17 11:54:27,380 iteration 1655 : loss : 0.036333, loss_ce: 0.012950
2022-01-17 11:54:28,366 iteration 1656 : loss : 0.045388, loss_ce: 0.017235
2022-01-17 11:54:29,299 iteration 1657 : loss : 0.029154, loss_ce: 0.013374
2022-01-17 11:54:30,295 iteration 1658 : loss : 0.044683, loss_ce: 0.023890
2022-01-17 11:54:31,327 iteration 1659 : loss : 0.043852, loss_ce: 0.022113
2022-01-17 11:54:32,276 iteration 1660 : loss : 0.040204, loss_ce: 0.016372
2022-01-17 11:54:33,161 iteration 1661 : loss : 0.043755, loss_ce: 0.013867
2022-01-17 11:54:34,147 iteration 1662 : loss : 0.055087, loss_ce: 0.017109
2022-01-17 11:54:35,155 iteration 1663 : loss : 0.033924, loss_ce: 0.014069
2022-01-17 11:54:36,099 iteration 1664 : loss : 0.057617, loss_ce: 0.021817
2022-01-17 11:54:37,031 iteration 1665 : loss : 0.037229, loss_ce: 0.015732
2022-01-17 11:54:37,999 iteration 1666 : loss : 0.036656, loss_ce: 0.009738
 24%|███████▎                      | 98/400 [28:47<1:25:16, 16.94s/it]2022-01-17 11:54:38,939 iteration 1667 : loss : 0.043232, loss_ce: 0.019358
2022-01-17 11:54:39,971 iteration 1668 : loss : 0.045934, loss_ce: 0.014668
2022-01-17 11:54:40,962 iteration 1669 : loss : 0.042912, loss_ce: 0.014401
2022-01-17 11:54:41,834 iteration 1670 : loss : 0.025968, loss_ce: 0.008752
2022-01-17 11:54:42,726 iteration 1671 : loss : 0.026499, loss_ce: 0.011343
2022-01-17 11:54:43,732 iteration 1672 : loss : 0.036894, loss_ce: 0.015037
2022-01-17 11:54:44,716 iteration 1673 : loss : 0.036566, loss_ce: 0.010580
2022-01-17 11:54:45,753 iteration 1674 : loss : 0.055992, loss_ce: 0.020818
2022-01-17 11:54:46,674 iteration 1675 : loss : 0.044253, loss_ce: 0.011882
2022-01-17 11:54:47,679 iteration 1676 : loss : 0.036470, loss_ce: 0.016442
2022-01-17 11:54:48,641 iteration 1677 : loss : 0.058515, loss_ce: 0.017830
2022-01-17 11:54:49,618 iteration 1678 : loss : 0.032340, loss_ce: 0.013779
2022-01-17 11:54:50,535 iteration 1679 : loss : 0.063207, loss_ce: 0.028128
2022-01-17 11:54:51,496 iteration 1680 : loss : 0.040888, loss_ce: 0.019827
2022-01-17 11:54:52,420 iteration 1681 : loss : 0.036836, loss_ce: 0.012952
2022-01-17 11:54:53,367 iteration 1682 : loss : 0.041053, loss_ce: 0.018045
2022-01-17 11:54:54,278 iteration 1683 : loss : 0.029397, loss_ce: 0.013166
 25%|███████▍                      | 99/400 [29:04<1:24:00, 16.75s/it]2022-01-17 11:54:55,301 iteration 1684 : loss : 0.043135, loss_ce: 0.016495
2022-01-17 11:54:56,213 iteration 1685 : loss : 0.040930, loss_ce: 0.019728
2022-01-17 11:54:57,093 iteration 1686 : loss : 0.037041, loss_ce: 0.013314
2022-01-17 11:54:58,015 iteration 1687 : loss : 0.030040, loss_ce: 0.013308
2022-01-17 11:54:58,977 iteration 1688 : loss : 0.046771, loss_ce: 0.021559
2022-01-17 11:54:59,888 iteration 1689 : loss : 0.044717, loss_ce: 0.017606
2022-01-17 11:55:00,869 iteration 1690 : loss : 0.064258, loss_ce: 0.028054
2022-01-17 11:55:01,804 iteration 1691 : loss : 0.036060, loss_ce: 0.013165
2022-01-17 11:55:02,807 iteration 1692 : loss : 0.057282, loss_ce: 0.023452
2022-01-17 11:55:03,818 iteration 1693 : loss : 0.038506, loss_ce: 0.017575
2022-01-17 11:55:04,795 iteration 1694 : loss : 0.037171, loss_ce: 0.010870
2022-01-17 11:55:05,663 iteration 1695 : loss : 0.027905, loss_ce: 0.008533
2022-01-17 11:55:06,598 iteration 1696 : loss : 0.054431, loss_ce: 0.020538
2022-01-17 11:55:07,593 iteration 1697 : loss : 0.037780, loss_ce: 0.010944
2022-01-17 11:55:08,527 iteration 1698 : loss : 0.028419, loss_ce: 0.009134
2022-01-17 11:55:09,367 iteration 1699 : loss : 0.034954, loss_ce: 0.014943
2022-01-17 11:55:09,368 Training Data Eval:
2022-01-17 11:55:13,831   Average segmentation loss on training set: 0.0332
2022-01-17 11:55:13,831 Validation Data Eval:
2022-01-17 11:55:15,339   Average segmentation loss on validation set: 0.0971
2022-01-17 11:55:16,301 iteration 1700 : loss : 0.046064, loss_ce: 0.012122
 25%|███████▎                     | 100/400 [29:26<1:31:38, 18.33s/it]2022-01-17 11:55:17,327 iteration 1701 : loss : 0.040718, loss_ce: 0.017084
2022-01-17 11:55:18,291 iteration 1702 : loss : 0.032569, loss_ce: 0.013513
2022-01-17 11:55:19,187 iteration 1703 : loss : 0.040962, loss_ce: 0.016544
2022-01-17 11:55:20,217 iteration 1704 : loss : 0.042557, loss_ce: 0.017982
2022-01-17 11:55:21,171 iteration 1705 : loss : 0.033014, loss_ce: 0.015456
2022-01-17 11:55:22,142 iteration 1706 : loss : 0.033245, loss_ce: 0.014415
2022-01-17 11:55:23,086 iteration 1707 : loss : 0.035948, loss_ce: 0.012180
2022-01-17 11:55:24,069 iteration 1708 : loss : 0.039899, loss_ce: 0.013079
2022-01-17 11:55:24,954 iteration 1709 : loss : 0.029837, loss_ce: 0.011688
2022-01-17 11:55:25,816 iteration 1710 : loss : 0.034403, loss_ce: 0.014055
2022-01-17 11:55:26,773 iteration 1711 : loss : 0.036991, loss_ce: 0.014170
2022-01-17 11:55:27,669 iteration 1712 : loss : 0.030494, loss_ce: 0.009441
2022-01-17 11:55:28,556 iteration 1713 : loss : 0.028731, loss_ce: 0.009594
2022-01-17 11:55:29,589 iteration 1714 : loss : 0.051481, loss_ce: 0.013756
2022-01-17 11:55:30,564 iteration 1715 : loss : 0.053958, loss_ce: 0.013777
2022-01-17 11:55:31,591 iteration 1716 : loss : 0.057354, loss_ce: 0.022693
2022-01-17 11:55:32,529 iteration 1717 : loss : 0.042000, loss_ce: 0.013126
 25%|███████▎                     | 101/400 [29:42<1:28:12, 17.70s/it]2022-01-17 11:55:33,471 iteration 1718 : loss : 0.035266, loss_ce: 0.011504
2022-01-17 11:55:34,431 iteration 1719 : loss : 0.055138, loss_ce: 0.023764
2022-01-17 11:55:35,276 iteration 1720 : loss : 0.032681, loss_ce: 0.009960
2022-01-17 11:55:36,213 iteration 1721 : loss : 0.032601, loss_ce: 0.014164
2022-01-17 11:55:37,215 iteration 1722 : loss : 0.034703, loss_ce: 0.013092
2022-01-17 11:55:38,161 iteration 1723 : loss : 0.045637, loss_ce: 0.020758
2022-01-17 11:55:39,152 iteration 1724 : loss : 0.038632, loss_ce: 0.013163
2022-01-17 11:55:40,224 iteration 1725 : loss : 0.056357, loss_ce: 0.017709
2022-01-17 11:55:41,242 iteration 1726 : loss : 0.054134, loss_ce: 0.013365
2022-01-17 11:55:42,193 iteration 1727 : loss : 0.030533, loss_ce: 0.014689
2022-01-17 11:55:43,114 iteration 1728 : loss : 0.031643, loss_ce: 0.010107
2022-01-17 11:55:44,045 iteration 1729 : loss : 0.030046, loss_ce: 0.012132
2022-01-17 11:55:45,007 iteration 1730 : loss : 0.033938, loss_ce: 0.011951
2022-01-17 11:55:46,023 iteration 1731 : loss : 0.045327, loss_ce: 0.016991
2022-01-17 11:55:46,977 iteration 1732 : loss : 0.025177, loss_ce: 0.012027
2022-01-17 11:55:48,010 iteration 1733 : loss : 0.036463, loss_ce: 0.016428
2022-01-17 11:55:48,912 iteration 1734 : loss : 0.033598, loss_ce: 0.012574
 26%|███████▍                     | 102/400 [29:58<1:25:56, 17.30s/it]2022-01-17 11:55:49,850 iteration 1735 : loss : 0.042636, loss_ce: 0.021243
2022-01-17 11:55:50,783 iteration 1736 : loss : 0.030482, loss_ce: 0.011854
2022-01-17 11:55:51,726 iteration 1737 : loss : 0.027460, loss_ce: 0.010688
2022-01-17 11:55:52,639 iteration 1738 : loss : 0.034672, loss_ce: 0.011521
2022-01-17 11:55:53,679 iteration 1739 : loss : 0.033886, loss_ce: 0.016580
2022-01-17 11:55:54,656 iteration 1740 : loss : 0.048634, loss_ce: 0.017600
2022-01-17 11:55:55,580 iteration 1741 : loss : 0.031098, loss_ce: 0.011048
2022-01-17 11:55:56,621 iteration 1742 : loss : 0.033798, loss_ce: 0.014114
2022-01-17 11:55:57,545 iteration 1743 : loss : 0.041468, loss_ce: 0.012008
2022-01-17 11:55:58,511 iteration 1744 : loss : 0.033930, loss_ce: 0.011594
2022-01-17 11:55:59,606 iteration 1745 : loss : 0.048781, loss_ce: 0.025476
2022-01-17 11:56:00,533 iteration 1746 : loss : 0.028700, loss_ce: 0.011371
2022-01-17 11:56:01,453 iteration 1747 : loss : 0.029026, loss_ce: 0.011405
2022-01-17 11:56:02,402 iteration 1748 : loss : 0.026960, loss_ce: 0.009387
2022-01-17 11:56:03,353 iteration 1749 : loss : 0.028315, loss_ce: 0.009415
2022-01-17 11:56:04,248 iteration 1750 : loss : 0.026718, loss_ce: 0.010672
2022-01-17 11:56:05,304 iteration 1751 : loss : 0.048049, loss_ce: 0.015248
 26%|███████▍                     | 103/400 [30:15<1:24:17, 17.03s/it]2022-01-17 11:56:06,257 iteration 1752 : loss : 0.026016, loss_ce: 0.009701
2022-01-17 11:56:07,160 iteration 1753 : loss : 0.031031, loss_ce: 0.013536
2022-01-17 11:56:08,084 iteration 1754 : loss : 0.031390, loss_ce: 0.012361
2022-01-17 11:56:09,029 iteration 1755 : loss : 0.030710, loss_ce: 0.011883
2022-01-17 11:56:09,995 iteration 1756 : loss : 0.031975, loss_ce: 0.013264
2022-01-17 11:56:11,016 iteration 1757 : loss : 0.038302, loss_ce: 0.018899
2022-01-17 11:56:12,008 iteration 1758 : loss : 0.044411, loss_ce: 0.017966
2022-01-17 11:56:12,879 iteration 1759 : loss : 0.038855, loss_ce: 0.010846
2022-01-17 11:56:13,806 iteration 1760 : loss : 0.037031, loss_ce: 0.014892
2022-01-17 11:56:14,710 iteration 1761 : loss : 0.022399, loss_ce: 0.008373
2022-01-17 11:56:15,653 iteration 1762 : loss : 0.037380, loss_ce: 0.013531
2022-01-17 11:56:16,516 iteration 1763 : loss : 0.035245, loss_ce: 0.013852
2022-01-17 11:56:17,565 iteration 1764 : loss : 0.030951, loss_ce: 0.007814
2022-01-17 11:56:18,514 iteration 1765 : loss : 0.037433, loss_ce: 0.011518
2022-01-17 11:56:19,523 iteration 1766 : loss : 0.028499, loss_ce: 0.010956
2022-01-17 11:56:20,496 iteration 1767 : loss : 0.038532, loss_ce: 0.015958
2022-01-17 11:56:21,434 iteration 1768 : loss : 0.034181, loss_ce: 0.012709
 26%|███████▌                     | 104/400 [30:31<1:22:41, 16.76s/it]2022-01-17 11:56:22,457 iteration 1769 : loss : 0.027905, loss_ce: 0.010562
2022-01-17 11:56:23,393 iteration 1770 : loss : 0.039722, loss_ce: 0.013127
2022-01-17 11:56:24,296 iteration 1771 : loss : 0.024449, loss_ce: 0.007896
2022-01-17 11:56:25,300 iteration 1772 : loss : 0.050371, loss_ce: 0.026463
2022-01-17 11:56:26,264 iteration 1773 : loss : 0.040903, loss_ce: 0.017864
2022-01-17 11:56:27,173 iteration 1774 : loss : 0.040010, loss_ce: 0.013949
2022-01-17 11:56:28,097 iteration 1775 : loss : 0.032481, loss_ce: 0.010821
2022-01-17 11:56:29,011 iteration 1776 : loss : 0.032645, loss_ce: 0.010314
2022-01-17 11:56:29,905 iteration 1777 : loss : 0.032510, loss_ce: 0.012630
2022-01-17 11:56:30,898 iteration 1778 : loss : 0.033077, loss_ce: 0.015282
2022-01-17 11:56:31,841 iteration 1779 : loss : 0.039875, loss_ce: 0.017168
2022-01-17 11:56:32,808 iteration 1780 : loss : 0.058865, loss_ce: 0.018715
2022-01-17 11:56:33,777 iteration 1781 : loss : 0.042712, loss_ce: 0.014693
2022-01-17 11:56:34,645 iteration 1782 : loss : 0.046753, loss_ce: 0.011226
2022-01-17 11:56:35,551 iteration 1783 : loss : 0.032252, loss_ce: 0.015687
2022-01-17 11:56:36,526 iteration 1784 : loss : 0.032445, loss_ce: 0.016111
2022-01-17 11:56:36,526 Training Data Eval:
2022-01-17 11:56:40,991   Average segmentation loss on training set: 0.0262
2022-01-17 11:56:40,991 Validation Data Eval:
2022-01-17 11:56:42,490   Average segmentation loss on validation set: 0.0882
2022-01-17 11:56:43,440 iteration 1785 : loss : 0.036369, loss_ce: 0.016442
 26%|███████▌                     | 105/400 [30:53<1:30:08, 18.33s/it]2022-01-17 11:56:44,477 iteration 1786 : loss : 0.042329, loss_ce: 0.013457
2022-01-17 11:56:45,378 iteration 1787 : loss : 0.031831, loss_ce: 0.008665
2022-01-17 11:56:46,343 iteration 1788 : loss : 0.034986, loss_ce: 0.012781
2022-01-17 11:56:47,313 iteration 1789 : loss : 0.034056, loss_ce: 0.016521
2022-01-17 11:56:48,406 iteration 1790 : loss : 0.036127, loss_ce: 0.012674
2022-01-17 11:56:49,376 iteration 1791 : loss : 0.035612, loss_ce: 0.015020
2022-01-17 11:56:50,341 iteration 1792 : loss : 0.039416, loss_ce: 0.014746
2022-01-17 11:56:51,324 iteration 1793 : loss : 0.075813, loss_ce: 0.034197
2022-01-17 11:56:52,266 iteration 1794 : loss : 0.040229, loss_ce: 0.020870
2022-01-17 11:56:53,118 iteration 1795 : loss : 0.027657, loss_ce: 0.010628
2022-01-17 11:56:54,144 iteration 1796 : loss : 0.038611, loss_ce: 0.017031
2022-01-17 11:56:55,044 iteration 1797 : loss : 0.042386, loss_ce: 0.018177
2022-01-17 11:56:56,000 iteration 1798 : loss : 0.034121, loss_ce: 0.013275
2022-01-17 11:56:57,010 iteration 1799 : loss : 0.038431, loss_ce: 0.014758
2022-01-17 11:56:57,899 iteration 1800 : loss : 0.035703, loss_ce: 0.011035
2022-01-17 11:56:58,848 iteration 1801 : loss : 0.034418, loss_ce: 0.012352
2022-01-17 11:56:59,849 iteration 1802 : loss : 0.037331, loss_ce: 0.012849
 26%|███████▋                     | 106/400 [31:09<1:26:59, 17.75s/it]2022-01-17 11:57:00,888 iteration 1803 : loss : 0.047544, loss_ce: 0.013571
2022-01-17 11:57:01,764 iteration 1804 : loss : 0.033778, loss_ce: 0.010988
2022-01-17 11:57:02,839 iteration 1805 : loss : 0.045453, loss_ce: 0.014514
2022-01-17 11:57:03,866 iteration 1806 : loss : 0.043053, loss_ce: 0.019477
2022-01-17 11:57:04,796 iteration 1807 : loss : 0.034033, loss_ce: 0.013422
2022-01-17 11:57:05,785 iteration 1808 : loss : 0.022476, loss_ce: 0.009082
2022-01-17 11:57:06,710 iteration 1809 : loss : 0.031712, loss_ce: 0.012929
2022-01-17 11:57:07,684 iteration 1810 : loss : 0.029206, loss_ce: 0.013890
2022-01-17 11:57:08,607 iteration 1811 : loss : 0.042881, loss_ce: 0.016207
2022-01-17 11:57:09,524 iteration 1812 : loss : 0.035454, loss_ce: 0.011631
2022-01-17 11:57:10,476 iteration 1813 : loss : 0.034573, loss_ce: 0.016264
2022-01-17 11:57:11,405 iteration 1814 : loss : 0.027146, loss_ce: 0.010244
2022-01-17 11:57:12,432 iteration 1815 : loss : 0.041568, loss_ce: 0.013138
2022-01-17 11:57:13,390 iteration 1816 : loss : 0.035784, loss_ce: 0.014217
2022-01-17 11:57:14,414 iteration 1817 : loss : 0.030820, loss_ce: 0.011772
2022-01-17 11:57:15,301 iteration 1818 : loss : 0.024774, loss_ce: 0.008140
2022-01-17 11:57:16,302 iteration 1819 : loss : 0.037320, loss_ce: 0.012813
 27%|███████▊                     | 107/400 [31:26<1:24:48, 17.37s/it]2022-01-17 11:57:17,181 iteration 1820 : loss : 0.029291, loss_ce: 0.012661
2022-01-17 11:57:18,244 iteration 1821 : loss : 0.044896, loss_ce: 0.014291
2022-01-17 11:57:19,236 iteration 1822 : loss : 0.044412, loss_ce: 0.020626
2022-01-17 11:57:20,252 iteration 1823 : loss : 0.036214, loss_ce: 0.012864
2022-01-17 11:57:21,211 iteration 1824 : loss : 0.048565, loss_ce: 0.013327
2022-01-17 11:57:22,103 iteration 1825 : loss : 0.031635, loss_ce: 0.012831
2022-01-17 11:57:23,111 iteration 1826 : loss : 0.050142, loss_ce: 0.020037
2022-01-17 11:57:24,001 iteration 1827 : loss : 0.025485, loss_ce: 0.008083
2022-01-17 11:57:24,955 iteration 1828 : loss : 0.044164, loss_ce: 0.016916
2022-01-17 11:57:25,873 iteration 1829 : loss : 0.039019, loss_ce: 0.018587
2022-01-17 11:57:26,915 iteration 1830 : loss : 0.054222, loss_ce: 0.017436
2022-01-17 11:57:27,889 iteration 1831 : loss : 0.030196, loss_ce: 0.012116
2022-01-17 11:57:28,818 iteration 1832 : loss : 0.031426, loss_ce: 0.013223
2022-01-17 11:57:29,709 iteration 1833 : loss : 0.038327, loss_ce: 0.015890
2022-01-17 11:57:30,654 iteration 1834 : loss : 0.039599, loss_ce: 0.013615
2022-01-17 11:57:31,613 iteration 1835 : loss : 0.032153, loss_ce: 0.013188
2022-01-17 11:57:32,534 iteration 1836 : loss : 0.040719, loss_ce: 0.013123
 27%|███████▊                     | 108/400 [31:42<1:22:51, 17.03s/it]2022-01-17 11:57:33,568 iteration 1837 : loss : 0.037646, loss_ce: 0.013324
2022-01-17 11:57:34,435 iteration 1838 : loss : 0.031564, loss_ce: 0.013326
2022-01-17 11:57:35,337 iteration 1839 : loss : 0.039515, loss_ce: 0.015222
2022-01-17 11:57:36,306 iteration 1840 : loss : 0.034670, loss_ce: 0.013152
2022-01-17 11:57:37,192 iteration 1841 : loss : 0.038456, loss_ce: 0.014874
2022-01-17 11:57:38,120 iteration 1842 : loss : 0.033448, loss_ce: 0.010092
2022-01-17 11:57:39,082 iteration 1843 : loss : 0.029090, loss_ce: 0.014966
2022-01-17 11:57:40,008 iteration 1844 : loss : 0.031844, loss_ce: 0.009795
2022-01-17 11:57:40,931 iteration 1845 : loss : 0.027809, loss_ce: 0.007774
2022-01-17 11:57:41,957 iteration 1846 : loss : 0.044078, loss_ce: 0.019057
2022-01-17 11:57:42,868 iteration 1847 : loss : 0.027994, loss_ce: 0.009399
2022-01-17 11:57:43,803 iteration 1848 : loss : 0.041584, loss_ce: 0.017371
2022-01-17 11:57:44,724 iteration 1849 : loss : 0.040950, loss_ce: 0.020913
2022-01-17 11:57:45,803 iteration 1850 : loss : 0.041288, loss_ce: 0.016624
2022-01-17 11:57:46,751 iteration 1851 : loss : 0.054133, loss_ce: 0.014969
2022-01-17 11:57:47,717 iteration 1852 : loss : 0.039508, loss_ce: 0.018793
2022-01-17 11:57:48,620 iteration 1853 : loss : 0.030205, loss_ce: 0.012677
 27%|███████▉                     | 109/400 [31:58<1:21:12, 16.74s/it]2022-01-17 11:57:49,572 iteration 1854 : loss : 0.035428, loss_ce: 0.012144
2022-01-17 11:57:50,562 iteration 1855 : loss : 0.037841, loss_ce: 0.014406
2022-01-17 11:57:51,556 iteration 1856 : loss : 0.042475, loss_ce: 0.012998
2022-01-17 11:57:52,559 iteration 1857 : loss : 0.039236, loss_ce: 0.013351
2022-01-17 11:57:53,513 iteration 1858 : loss : 0.031326, loss_ce: 0.012947
2022-01-17 11:57:54,476 iteration 1859 : loss : 0.037457, loss_ce: 0.015804
2022-01-17 11:57:55,381 iteration 1860 : loss : 0.028116, loss_ce: 0.009985
2022-01-17 11:57:56,394 iteration 1861 : loss : 0.034807, loss_ce: 0.011771
2022-01-17 11:57:57,294 iteration 1862 : loss : 0.028311, loss_ce: 0.013423
2022-01-17 11:57:58,243 iteration 1863 : loss : 0.045811, loss_ce: 0.019330
2022-01-17 11:57:59,226 iteration 1864 : loss : 0.039615, loss_ce: 0.010885
2022-01-17 11:58:00,082 iteration 1865 : loss : 0.031516, loss_ce: 0.013541
2022-01-17 11:58:01,209 iteration 1866 : loss : 0.026317, loss_ce: 0.011493
2022-01-17 11:58:02,151 iteration 1867 : loss : 0.030421, loss_ce: 0.013125
2022-01-17 11:58:03,051 iteration 1868 : loss : 0.041321, loss_ce: 0.016087
2022-01-17 11:58:03,951 iteration 1869 : loss : 0.048894, loss_ce: 0.012949
2022-01-17 11:58:03,951 Training Data Eval:
2022-01-17 11:58:08,416   Average segmentation loss on training set: 0.0250
2022-01-17 11:58:08,417 Validation Data Eval:
2022-01-17 11:58:09,927   Average segmentation loss on validation set: 0.1202
2022-01-17 11:58:10,923 iteration 1870 : loss : 0.034070, loss_ce: 0.012402
 28%|███████▉                     | 110/400 [32:20<1:28:59, 18.41s/it]2022-01-17 11:58:11,970 iteration 1871 : loss : 0.031602, loss_ce: 0.012384
2022-01-17 11:58:13,033 iteration 1872 : loss : 0.054451, loss_ce: 0.017779
2022-01-17 11:58:13,940 iteration 1873 : loss : 0.035946, loss_ce: 0.014815
2022-01-17 11:58:14,965 iteration 1874 : loss : 0.055051, loss_ce: 0.028568
2022-01-17 11:58:15,826 iteration 1875 : loss : 0.034686, loss_ce: 0.010836
2022-01-17 11:58:16,864 iteration 1876 : loss : 0.046356, loss_ce: 0.015742
2022-01-17 11:58:17,868 iteration 1877 : loss : 0.059397, loss_ce: 0.027160
2022-01-17 11:58:18,796 iteration 1878 : loss : 0.030508, loss_ce: 0.011825
2022-01-17 11:58:19,714 iteration 1879 : loss : 0.028675, loss_ce: 0.011745
2022-01-17 11:58:20,622 iteration 1880 : loss : 0.039979, loss_ce: 0.020545
2022-01-17 11:58:21,577 iteration 1881 : loss : 0.039970, loss_ce: 0.012921
2022-01-17 11:58:22,480 iteration 1882 : loss : 0.036348, loss_ce: 0.012763
2022-01-17 11:58:23,343 iteration 1883 : loss : 0.036195, loss_ce: 0.011437
2022-01-17 11:58:24,323 iteration 1884 : loss : 0.040406, loss_ce: 0.016498
2022-01-17 11:58:25,176 iteration 1885 : loss : 0.026613, loss_ce: 0.010372
2022-01-17 11:58:26,210 iteration 1886 : loss : 0.038642, loss_ce: 0.016835
2022-01-17 11:58:27,233 iteration 1887 : loss : 0.036323, loss_ce: 0.015465
 28%|████████                     | 111/400 [32:37<1:25:38, 17.78s/it]2022-01-17 11:58:28,194 iteration 1888 : loss : 0.032936, loss_ce: 0.013092
2022-01-17 11:58:29,194 iteration 1889 : loss : 0.037792, loss_ce: 0.015483
2022-01-17 11:58:30,176 iteration 1890 : loss : 0.039508, loss_ce: 0.011608
2022-01-17 11:58:31,172 iteration 1891 : loss : 0.034825, loss_ce: 0.014257
2022-01-17 11:58:32,130 iteration 1892 : loss : 0.034365, loss_ce: 0.014697
2022-01-17 11:58:33,095 iteration 1893 : loss : 0.034224, loss_ce: 0.016821
2022-01-17 11:58:34,032 iteration 1894 : loss : 0.034853, loss_ce: 0.014635
2022-01-17 11:58:34,958 iteration 1895 : loss : 0.040588, loss_ce: 0.011779
2022-01-17 11:58:36,028 iteration 1896 : loss : 0.056577, loss_ce: 0.031828
2022-01-17 11:58:36,947 iteration 1897 : loss : 0.039551, loss_ce: 0.010769
2022-01-17 11:58:37,949 iteration 1898 : loss : 0.035189, loss_ce: 0.012276
2022-01-17 11:58:38,884 iteration 1899 : loss : 0.037280, loss_ce: 0.017251
2022-01-17 11:58:39,744 iteration 1900 : loss : 0.026019, loss_ce: 0.010140
2022-01-17 11:58:40,686 iteration 1901 : loss : 0.030743, loss_ce: 0.010918
2022-01-17 11:58:41,665 iteration 1902 : loss : 0.031162, loss_ce: 0.012605
2022-01-17 11:58:42,677 iteration 1903 : loss : 0.047287, loss_ce: 0.012656
2022-01-17 11:58:43,737 iteration 1904 : loss : 0.047162, loss_ce: 0.014785
 28%|████████                     | 112/400 [32:53<1:23:30, 17.40s/it]2022-01-17 11:58:44,669 iteration 1905 : loss : 0.028339, loss_ce: 0.011605
2022-01-17 11:58:45,674 iteration 1906 : loss : 0.033986, loss_ce: 0.010931
2022-01-17 11:58:46,729 iteration 1907 : loss : 0.035512, loss_ce: 0.012877
2022-01-17 11:58:47,699 iteration 1908 : loss : 0.034712, loss_ce: 0.013453
2022-01-17 11:58:48,699 iteration 1909 : loss : 0.033970, loss_ce: 0.017922
2022-01-17 11:58:49,689 iteration 1910 : loss : 0.064682, loss_ce: 0.033449
2022-01-17 11:58:50,755 iteration 1911 : loss : 0.029579, loss_ce: 0.011283
2022-01-17 11:58:51,734 iteration 1912 : loss : 0.036084, loss_ce: 0.009689
2022-01-17 11:58:52,668 iteration 1913 : loss : 0.031240, loss_ce: 0.010566
2022-01-17 11:58:53,566 iteration 1914 : loss : 0.031078, loss_ce: 0.013695
2022-01-17 11:58:54,520 iteration 1915 : loss : 0.042607, loss_ce: 0.013418
2022-01-17 11:58:55,473 iteration 1916 : loss : 0.036933, loss_ce: 0.014616
2022-01-17 11:58:56,460 iteration 1917 : loss : 0.039390, loss_ce: 0.014729
2022-01-17 11:58:57,376 iteration 1918 : loss : 0.036441, loss_ce: 0.015434
2022-01-17 11:58:58,319 iteration 1919 : loss : 0.030190, loss_ce: 0.013084
2022-01-17 11:58:59,268 iteration 1920 : loss : 0.027347, loss_ce: 0.009995
2022-01-17 11:59:00,265 iteration 1921 : loss : 0.035893, loss_ce: 0.012369
 28%|████████▏                    | 113/400 [33:10<1:21:57, 17.14s/it]2022-01-17 11:59:01,207 iteration 1922 : loss : 0.033719, loss_ce: 0.012580
2022-01-17 11:59:02,083 iteration 1923 : loss : 0.021714, loss_ce: 0.008964
2022-01-17 11:59:03,061 iteration 1924 : loss : 0.038240, loss_ce: 0.019604
2022-01-17 11:59:03,964 iteration 1925 : loss : 0.032845, loss_ce: 0.013187
2022-01-17 11:59:04,884 iteration 1926 : loss : 0.026373, loss_ce: 0.011396
2022-01-17 11:59:05,884 iteration 1927 : loss : 0.048723, loss_ce: 0.019315
2022-01-17 11:59:06,888 iteration 1928 : loss : 0.025785, loss_ce: 0.010397
2022-01-17 11:59:07,805 iteration 1929 : loss : 0.029414, loss_ce: 0.013052
2022-01-17 11:59:08,744 iteration 1930 : loss : 0.046066, loss_ce: 0.013118
2022-01-17 11:59:09,662 iteration 1931 : loss : 0.029006, loss_ce: 0.007433
2022-01-17 11:59:10,610 iteration 1932 : loss : 0.033808, loss_ce: 0.009856
2022-01-17 11:59:11,568 iteration 1933 : loss : 0.039857, loss_ce: 0.014144
2022-01-17 11:59:12,401 iteration 1934 : loss : 0.026325, loss_ce: 0.012360
2022-01-17 11:59:13,322 iteration 1935 : loss : 0.044249, loss_ce: 0.021347
2022-01-17 11:59:14,316 iteration 1936 : loss : 0.031183, loss_ce: 0.012186
2022-01-17 11:59:15,296 iteration 1937 : loss : 0.029179, loss_ce: 0.011723
2022-01-17 11:59:16,282 iteration 1938 : loss : 0.031877, loss_ce: 0.008863
 28%|████████▎                    | 114/400 [33:26<1:20:05, 16.80s/it]2022-01-17 11:59:17,203 iteration 1939 : loss : 0.023137, loss_ce: 0.010463
2022-01-17 11:59:18,117 iteration 1940 : loss : 0.023176, loss_ce: 0.008844
2022-01-17 11:59:19,117 iteration 1941 : loss : 0.035640, loss_ce: 0.016126
2022-01-17 11:59:20,059 iteration 1942 : loss : 0.043474, loss_ce: 0.012642
2022-01-17 11:59:20,929 iteration 1943 : loss : 0.036356, loss_ce: 0.012628
2022-01-17 11:59:21,852 iteration 1944 : loss : 0.035561, loss_ce: 0.013216
2022-01-17 11:59:22,788 iteration 1945 : loss : 0.032513, loss_ce: 0.016026
2022-01-17 11:59:23,726 iteration 1946 : loss : 0.033484, loss_ce: 0.012559
2022-01-17 11:59:24,649 iteration 1947 : loss : 0.035155, loss_ce: 0.012632
2022-01-17 11:59:25,571 iteration 1948 : loss : 0.025229, loss_ce: 0.010432
2022-01-17 11:59:26,442 iteration 1949 : loss : 0.028698, loss_ce: 0.013973
2022-01-17 11:59:27,425 iteration 1950 : loss : 0.030117, loss_ce: 0.010400
2022-01-17 11:59:28,474 iteration 1951 : loss : 0.040329, loss_ce: 0.013345
2022-01-17 11:59:29,360 iteration 1952 : loss : 0.030338, loss_ce: 0.007698
2022-01-17 11:59:30,322 iteration 1953 : loss : 0.043302, loss_ce: 0.021123
2022-01-17 11:59:31,343 iteration 1954 : loss : 0.041280, loss_ce: 0.016012
2022-01-17 11:59:31,343 Training Data Eval:
2022-01-17 11:59:35,801   Average segmentation loss on training set: 0.0228
2022-01-17 11:59:35,801 Validation Data Eval:
2022-01-17 11:59:37,303   Average segmentation loss on validation set: 0.0880
2022-01-17 11:59:38,225 iteration 1955 : loss : 0.028947, loss_ce: 0.010673
 29%|████████▎                    | 115/400 [33:48<1:27:08, 18.34s/it]2022-01-17 11:59:39,254 iteration 1956 : loss : 0.035605, loss_ce: 0.012598
2022-01-17 11:59:40,143 iteration 1957 : loss : 0.028776, loss_ce: 0.012133
2022-01-17 11:59:41,068 iteration 1958 : loss : 0.022841, loss_ce: 0.010432
2022-01-17 11:59:42,101 iteration 1959 : loss : 0.060378, loss_ce: 0.016460
2022-01-17 11:59:43,027 iteration 1960 : loss : 0.035872, loss_ce: 0.010999
2022-01-17 11:59:43,974 iteration 1961 : loss : 0.046756, loss_ce: 0.018859
2022-01-17 11:59:44,906 iteration 1962 : loss : 0.025580, loss_ce: 0.010340
2022-01-17 11:59:45,869 iteration 1963 : loss : 0.029557, loss_ce: 0.012588
2022-01-17 11:59:46,796 iteration 1964 : loss : 0.033574, loss_ce: 0.009140
2022-01-17 11:59:47,701 iteration 1965 : loss : 0.028447, loss_ce: 0.013545
2022-01-17 11:59:48,604 iteration 1966 : loss : 0.033017, loss_ce: 0.014782
2022-01-17 11:59:49,495 iteration 1967 : loss : 0.037406, loss_ce: 0.012052
2022-01-17 11:59:50,369 iteration 1968 : loss : 0.028502, loss_ce: 0.015383
2022-01-17 11:59:51,345 iteration 1969 : loss : 0.029242, loss_ce: 0.011190
2022-01-17 11:59:52,438 iteration 1970 : loss : 0.030015, loss_ce: 0.010336
2022-01-17 11:59:53,287 iteration 1971 : loss : 0.029319, loss_ce: 0.009371
2022-01-17 11:59:54,340 iteration 1972 : loss : 0.050765, loss_ce: 0.018053
 29%|████████▍                    | 116/400 [34:04<1:23:39, 17.68s/it]2022-01-17 11:59:55,231 iteration 1973 : loss : 0.031974, loss_ce: 0.012854
2022-01-17 11:59:56,103 iteration 1974 : loss : 0.028667, loss_ce: 0.011085
2022-01-17 11:59:57,127 iteration 1975 : loss : 0.045335, loss_ce: 0.017665
2022-01-17 11:59:57,987 iteration 1976 : loss : 0.030088, loss_ce: 0.012036
2022-01-17 11:59:59,016 iteration 1977 : loss : 0.049473, loss_ce: 0.023349
2022-01-17 11:59:59,916 iteration 1978 : loss : 0.030751, loss_ce: 0.013748
2022-01-17 12:00:00,834 iteration 1979 : loss : 0.034317, loss_ce: 0.016765
2022-01-17 12:00:01,815 iteration 1980 : loss : 0.035482, loss_ce: 0.011789
2022-01-17 12:00:02,710 iteration 1981 : loss : 0.029278, loss_ce: 0.011213
2022-01-17 12:00:03,713 iteration 1982 : loss : 0.041215, loss_ce: 0.018186
2022-01-17 12:00:04,748 iteration 1983 : loss : 0.037150, loss_ce: 0.014666
2022-01-17 12:00:05,657 iteration 1984 : loss : 0.027380, loss_ce: 0.008476
2022-01-17 12:00:06,571 iteration 1985 : loss : 0.027260, loss_ce: 0.009648
2022-01-17 12:00:07,477 iteration 1986 : loss : 0.023467, loss_ce: 0.006700
2022-01-17 12:00:08,380 iteration 1987 : loss : 0.023522, loss_ce: 0.008457
2022-01-17 12:00:09,412 iteration 1988 : loss : 0.027419, loss_ce: 0.011070
2022-01-17 12:00:10,352 iteration 1989 : loss : 0.029937, loss_ce: 0.013609
 29%|████████▍                    | 117/400 [34:20<1:21:00, 17.17s/it]2022-01-17 12:00:11,331 iteration 1990 : loss : 0.034726, loss_ce: 0.012573
2022-01-17 12:00:12,184 iteration 1991 : loss : 0.024553, loss_ce: 0.011022
2022-01-17 12:00:13,169 iteration 1992 : loss : 0.035942, loss_ce: 0.014999
2022-01-17 12:00:14,109 iteration 1993 : loss : 0.055234, loss_ce: 0.013410
2022-01-17 12:00:15,091 iteration 1994 : loss : 0.026883, loss_ce: 0.011028
2022-01-17 12:00:16,035 iteration 1995 : loss : 0.047824, loss_ce: 0.014777
2022-01-17 12:00:16,990 iteration 1996 : loss : 0.027471, loss_ce: 0.011878
2022-01-17 12:00:17,936 iteration 1997 : loss : 0.028886, loss_ce: 0.012882
2022-01-17 12:00:18,916 iteration 1998 : loss : 0.049149, loss_ce: 0.021223
2022-01-17 12:00:19,890 iteration 1999 : loss : 0.044849, loss_ce: 0.016562
2022-01-17 12:00:20,961 iteration 2000 : loss : 0.053876, loss_ce: 0.014571
2022-01-17 12:00:21,903 iteration 2001 : loss : 0.029515, loss_ce: 0.011112
2022-01-17 12:00:22,769 iteration 2002 : loss : 0.028903, loss_ce: 0.011530
2022-01-17 12:00:23,588 iteration 2003 : loss : 0.021488, loss_ce: 0.010284
2022-01-17 12:00:24,490 iteration 2004 : loss : 0.037975, loss_ce: 0.011241
2022-01-17 12:00:25,480 iteration 2005 : loss : 0.025405, loss_ce: 0.009530
2022-01-17 12:00:26,459 iteration 2006 : loss : 0.029952, loss_ce: 0.009116
 30%|████████▌                    | 118/400 [34:36<1:19:12, 16.85s/it]2022-01-17 12:00:27,512 iteration 2007 : loss : 0.032855, loss_ce: 0.012775
2022-01-17 12:00:28,582 iteration 2008 : loss : 0.054062, loss_ce: 0.020801
2022-01-17 12:00:29,524 iteration 2009 : loss : 0.037002, loss_ce: 0.015367
2022-01-17 12:00:30,456 iteration 2010 : loss : 0.036502, loss_ce: 0.016147
2022-01-17 12:00:31,487 iteration 2011 : loss : 0.046323, loss_ce: 0.016245
2022-01-17 12:00:32,430 iteration 2012 : loss : 0.027269, loss_ce: 0.013722
2022-01-17 12:00:33,290 iteration 2013 : loss : 0.025534, loss_ce: 0.011032
2022-01-17 12:00:34,216 iteration 2014 : loss : 0.032503, loss_ce: 0.009587
2022-01-17 12:00:35,204 iteration 2015 : loss : 0.036564, loss_ce: 0.014136
2022-01-17 12:00:36,137 iteration 2016 : loss : 0.044824, loss_ce: 0.016008
2022-01-17 12:00:37,137 iteration 2017 : loss : 0.027609, loss_ce: 0.008973
2022-01-17 12:00:38,196 iteration 2018 : loss : 0.043529, loss_ce: 0.019882
2022-01-17 12:00:39,121 iteration 2019 : loss : 0.053390, loss_ce: 0.014204
2022-01-17 12:00:40,029 iteration 2020 : loss : 0.022424, loss_ce: 0.007219
2022-01-17 12:00:41,006 iteration 2021 : loss : 0.031069, loss_ce: 0.009653
2022-01-17 12:00:41,974 iteration 2022 : loss : 0.030046, loss_ce: 0.013667
2022-01-17 12:00:42,982 iteration 2023 : loss : 0.044777, loss_ce: 0.017941
 30%|████████▋                    | 119/400 [34:52<1:18:28, 16.75s/it]2022-01-17 12:00:43,913 iteration 2024 : loss : 0.023541, loss_ce: 0.006285
2022-01-17 12:00:44,881 iteration 2025 : loss : 0.028205, loss_ce: 0.013925
2022-01-17 12:00:45,885 iteration 2026 : loss : 0.029507, loss_ce: 0.010992
2022-01-17 12:00:46,811 iteration 2027 : loss : 0.023732, loss_ce: 0.006770
2022-01-17 12:00:47,707 iteration 2028 : loss : 0.020143, loss_ce: 0.009427
2022-01-17 12:00:48,636 iteration 2029 : loss : 0.032667, loss_ce: 0.011933
2022-01-17 12:00:49,546 iteration 2030 : loss : 0.046280, loss_ce: 0.021299
2022-01-17 12:00:50,488 iteration 2031 : loss : 0.034357, loss_ce: 0.013399
2022-01-17 12:00:51,525 iteration 2032 : loss : 0.045561, loss_ce: 0.024622
2022-01-17 12:00:52,587 iteration 2033 : loss : 0.046288, loss_ce: 0.021818
2022-01-17 12:00:53,494 iteration 2034 : loss : 0.029717, loss_ce: 0.011982
2022-01-17 12:00:54,448 iteration 2035 : loss : 0.027904, loss_ce: 0.009483
2022-01-17 12:00:55,448 iteration 2036 : loss : 0.026241, loss_ce: 0.011221
2022-01-17 12:00:56,390 iteration 2037 : loss : 0.038067, loss_ce: 0.008865
2022-01-17 12:00:57,385 iteration 2038 : loss : 0.045348, loss_ce: 0.015330
2022-01-17 12:00:58,423 iteration 2039 : loss : 0.035507, loss_ce: 0.014948
2022-01-17 12:00:58,423 Training Data Eval:
2022-01-17 12:01:02,881   Average segmentation loss on training set: 0.0223
2022-01-17 12:01:02,881 Validation Data Eval:
2022-01-17 12:01:04,382   Average segmentation loss on validation set: 0.1133
2022-01-17 12:01:05,415 iteration 2040 : loss : 0.049729, loss_ce: 0.018130
 30%|████████▋                    | 120/400 [35:15<1:26:09, 18.46s/it]2022-01-17 12:01:06,458 iteration 2041 : loss : 0.041848, loss_ce: 0.008808
2022-01-17 12:01:07,384 iteration 2042 : loss : 0.031047, loss_ce: 0.013123
2022-01-17 12:01:08,306 iteration 2043 : loss : 0.028138, loss_ce: 0.008488
2022-01-17 12:01:09,252 iteration 2044 : loss : 0.033251, loss_ce: 0.014250
2022-01-17 12:01:10,167 iteration 2045 : loss : 0.020898, loss_ce: 0.006952
2022-01-17 12:01:11,130 iteration 2046 : loss : 0.037493, loss_ce: 0.016061
2022-01-17 12:01:12,050 iteration 2047 : loss : 0.027505, loss_ce: 0.011578
2022-01-17 12:01:13,017 iteration 2048 : loss : 0.032771, loss_ce: 0.011949
2022-01-17 12:01:13,942 iteration 2049 : loss : 0.057630, loss_ce: 0.015329
2022-01-17 12:01:14,912 iteration 2050 : loss : 0.040396, loss_ce: 0.017205
2022-01-17 12:01:15,877 iteration 2051 : loss : 0.028990, loss_ce: 0.012661
2022-01-17 12:01:16,765 iteration 2052 : loss : 0.026278, loss_ce: 0.009620
2022-01-17 12:01:17,728 iteration 2053 : loss : 0.036331, loss_ce: 0.010068
2022-01-17 12:01:18,649 iteration 2054 : loss : 0.036073, loss_ce: 0.014643
2022-01-17 12:01:19,580 iteration 2055 : loss : 0.047257, loss_ce: 0.013743
2022-01-17 12:01:20,570 iteration 2056 : loss : 0.025436, loss_ce: 0.011606
2022-01-17 12:01:21,465 iteration 2057 : loss : 0.030198, loss_ce: 0.011979
 30%|████████▊                    | 121/400 [35:31<1:22:27, 17.73s/it]2022-01-17 12:01:22,459 iteration 2058 : loss : 0.032756, loss_ce: 0.015802
2022-01-17 12:01:23,462 iteration 2059 : loss : 0.044036, loss_ce: 0.015069
2022-01-17 12:01:24,315 iteration 2060 : loss : 0.026088, loss_ce: 0.009439
2022-01-17 12:01:25,296 iteration 2061 : loss : 0.037957, loss_ce: 0.014823
2022-01-17 12:01:26,228 iteration 2062 : loss : 0.030636, loss_ce: 0.012003
2022-01-17 12:01:27,167 iteration 2063 : loss : 0.051941, loss_ce: 0.012211
2022-01-17 12:01:28,061 iteration 2064 : loss : 0.021784, loss_ce: 0.007733
2022-01-17 12:01:28,992 iteration 2065 : loss : 0.042676, loss_ce: 0.011722
2022-01-17 12:01:29,943 iteration 2066 : loss : 0.036686, loss_ce: 0.011924
2022-01-17 12:01:30,921 iteration 2067 : loss : 0.027994, loss_ce: 0.009909
2022-01-17 12:01:31,931 iteration 2068 : loss : 0.024717, loss_ce: 0.010219
2022-01-17 12:01:32,845 iteration 2069 : loss : 0.033039, loss_ce: 0.008703
2022-01-17 12:01:33,834 iteration 2070 : loss : 0.036503, loss_ce: 0.015605
2022-01-17 12:01:34,841 iteration 2071 : loss : 0.047265, loss_ce: 0.016720
2022-01-17 12:01:35,786 iteration 2072 : loss : 0.032620, loss_ce: 0.011648
2022-01-17 12:01:36,778 iteration 2073 : loss : 0.045069, loss_ce: 0.012085
2022-01-17 12:01:37,753 iteration 2074 : loss : 0.030969, loss_ce: 0.016413
 30%|████████▊                    | 122/400 [35:47<1:20:10, 17.30s/it]2022-01-17 12:01:38,702 iteration 2075 : loss : 0.028627, loss_ce: 0.009082
2022-01-17 12:01:39,650 iteration 2076 : loss : 0.027967, loss_ce: 0.007490
2022-01-17 12:01:40,622 iteration 2077 : loss : 0.033389, loss_ce: 0.014754
2022-01-17 12:01:41,699 iteration 2078 : loss : 0.040907, loss_ce: 0.010830
2022-01-17 12:01:42,624 iteration 2079 : loss : 0.037498, loss_ce: 0.011894
2022-01-17 12:01:43,631 iteration 2080 : loss : 0.042255, loss_ce: 0.017369
2022-01-17 12:01:44,483 iteration 2081 : loss : 0.037038, loss_ce: 0.013216
2022-01-17 12:01:45,324 iteration 2082 : loss : 0.024029, loss_ce: 0.008270
2022-01-17 12:01:46,261 iteration 2083 : loss : 0.037314, loss_ce: 0.019729
2022-01-17 12:01:47,195 iteration 2084 : loss : 0.037599, loss_ce: 0.018582
2022-01-17 12:01:48,095 iteration 2085 : loss : 0.033098, loss_ce: 0.009617
2022-01-17 12:01:49,040 iteration 2086 : loss : 0.040690, loss_ce: 0.017325
2022-01-17 12:01:49,949 iteration 2087 : loss : 0.037729, loss_ce: 0.016697
2022-01-17 12:01:50,973 iteration 2088 : loss : 0.025729, loss_ce: 0.010434
2022-01-17 12:01:51,967 iteration 2089 : loss : 0.028298, loss_ce: 0.012435
2022-01-17 12:01:52,843 iteration 2090 : loss : 0.031813, loss_ce: 0.013861
2022-01-17 12:01:53,827 iteration 2091 : loss : 0.038685, loss_ce: 0.018401
 31%|████████▉                    | 123/400 [36:03<1:18:10, 16.93s/it]2022-01-17 12:01:54,739 iteration 2092 : loss : 0.027277, loss_ce: 0.011553
2022-01-17 12:01:55,656 iteration 2093 : loss : 0.031077, loss_ce: 0.011843
2022-01-17 12:01:56,605 iteration 2094 : loss : 0.033037, loss_ce: 0.008348
2022-01-17 12:01:57,496 iteration 2095 : loss : 0.023485, loss_ce: 0.009812
2022-01-17 12:01:58,534 iteration 2096 : loss : 0.039032, loss_ce: 0.018097
2022-01-17 12:01:59,509 iteration 2097 : loss : 0.043113, loss_ce: 0.012806
2022-01-17 12:02:00,463 iteration 2098 : loss : 0.040659, loss_ce: 0.014027
2022-01-17 12:02:01,430 iteration 2099 : loss : 0.025943, loss_ce: 0.007935
2022-01-17 12:02:02,419 iteration 2100 : loss : 0.042834, loss_ce: 0.022721
2022-01-17 12:02:03,388 iteration 2101 : loss : 0.033130, loss_ce: 0.011626
2022-01-17 12:02:04,393 iteration 2102 : loss : 0.033627, loss_ce: 0.014341
2022-01-17 12:02:05,263 iteration 2103 : loss : 0.032529, loss_ce: 0.013802
2022-01-17 12:02:06,155 iteration 2104 : loss : 0.041257, loss_ce: 0.013104
2022-01-17 12:02:07,201 iteration 2105 : loss : 0.055435, loss_ce: 0.017371
2022-01-17 12:02:08,109 iteration 2106 : loss : 0.023881, loss_ce: 0.010594
2022-01-17 12:02:09,140 iteration 2107 : loss : 0.025806, loss_ce: 0.009934
2022-01-17 12:02:10,111 iteration 2108 : loss : 0.036091, loss_ce: 0.012660
 31%|████████▉                    | 124/400 [36:19<1:16:59, 16.74s/it]2022-01-17 12:02:11,096 iteration 2109 : loss : 0.047412, loss_ce: 0.018517
2022-01-17 12:02:12,086 iteration 2110 : loss : 0.042848, loss_ce: 0.013617
2022-01-17 12:02:13,125 iteration 2111 : loss : 0.041886, loss_ce: 0.009214
2022-01-17 12:02:14,084 iteration 2112 : loss : 0.052922, loss_ce: 0.018610
2022-01-17 12:02:14,996 iteration 2113 : loss : 0.035422, loss_ce: 0.017665
2022-01-17 12:02:15,979 iteration 2114 : loss : 0.031219, loss_ce: 0.014148
2022-01-17 12:02:16,955 iteration 2115 : loss : 0.033142, loss_ce: 0.010072
2022-01-17 12:02:17,930 iteration 2116 : loss : 0.039553, loss_ce: 0.012901
2022-01-17 12:02:18,895 iteration 2117 : loss : 0.031852, loss_ce: 0.012381
2022-01-17 12:02:19,886 iteration 2118 : loss : 0.037512, loss_ce: 0.010627
2022-01-17 12:02:20,879 iteration 2119 : loss : 0.034080, loss_ce: 0.012817
2022-01-17 12:02:21,839 iteration 2120 : loss : 0.035567, loss_ce: 0.010404
2022-01-17 12:02:22,688 iteration 2121 : loss : 0.033025, loss_ce: 0.010688
2022-01-17 12:02:23,624 iteration 2122 : loss : 0.029070, loss_ce: 0.009707
2022-01-17 12:02:24,636 iteration 2123 : loss : 0.047424, loss_ce: 0.020302
2022-01-17 12:02:25,670 iteration 2124 : loss : 0.045621, loss_ce: 0.018605
2022-01-17 12:02:25,670 Training Data Eval:
2022-01-17 12:02:30,136   Average segmentation loss on training set: 0.0286
2022-01-17 12:02:30,137 Validation Data Eval:
2022-01-17 12:02:31,639   Average segmentation loss on validation set: 0.1390
2022-01-17 12:02:32,618 iteration 2125 : loss : 0.034728, loss_ce: 0.018145
 31%|█████████                    | 125/400 [36:42<1:24:39, 18.47s/it]2022-01-17 12:02:33,673 iteration 2126 : loss : 0.025735, loss_ce: 0.010658
2022-01-17 12:02:34,662 iteration 2127 : loss : 0.032016, loss_ce: 0.014144
2022-01-17 12:02:35,639 iteration 2128 : loss : 0.030883, loss_ce: 0.009544
2022-01-17 12:02:36,560 iteration 2129 : loss : 0.029939, loss_ce: 0.011238
2022-01-17 12:02:37,551 iteration 2130 : loss : 0.054661, loss_ce: 0.018488
2022-01-17 12:02:38,484 iteration 2131 : loss : 0.031178, loss_ce: 0.009681
2022-01-17 12:02:39,436 iteration 2132 : loss : 0.022304, loss_ce: 0.008490
2022-01-17 12:02:40,462 iteration 2133 : loss : 0.049138, loss_ce: 0.015895
2022-01-17 12:02:41,344 iteration 2134 : loss : 0.027767, loss_ce: 0.012209
2022-01-17 12:02:42,305 iteration 2135 : loss : 0.045239, loss_ce: 0.017112
2022-01-17 12:02:43,254 iteration 2136 : loss : 0.034019, loss_ce: 0.015191
2022-01-17 12:02:44,209 iteration 2137 : loss : 0.033058, loss_ce: 0.013855
2022-01-17 12:02:45,121 iteration 2138 : loss : 0.034445, loss_ce: 0.015190
2022-01-17 12:02:46,111 iteration 2139 : loss : 0.039538, loss_ce: 0.019319
2022-01-17 12:02:47,052 iteration 2140 : loss : 0.033335, loss_ce: 0.014661
2022-01-17 12:02:48,064 iteration 2141 : loss : 0.053417, loss_ce: 0.012559
2022-01-17 12:02:48,972 iteration 2142 : loss : 0.029098, loss_ce: 0.009675
 32%|█████████▏                   | 126/400 [36:58<1:21:26, 17.83s/it]2022-01-17 12:02:49,888 iteration 2143 : loss : 0.031301, loss_ce: 0.011782
2022-01-17 12:02:50,868 iteration 2144 : loss : 0.035657, loss_ce: 0.011923
2022-01-17 12:02:51,859 iteration 2145 : loss : 0.036764, loss_ce: 0.012060
2022-01-17 12:02:52,758 iteration 2146 : loss : 0.021425, loss_ce: 0.008643
2022-01-17 12:02:53,728 iteration 2147 : loss : 0.032892, loss_ce: 0.010340
2022-01-17 12:02:54,652 iteration 2148 : loss : 0.034733, loss_ce: 0.012640
2022-01-17 12:02:55,612 iteration 2149 : loss : 0.028241, loss_ce: 0.010109
2022-01-17 12:02:56,539 iteration 2150 : loss : 0.024542, loss_ce: 0.009149
2022-01-17 12:02:57,557 iteration 2151 : loss : 0.047952, loss_ce: 0.021892
2022-01-17 12:02:58,462 iteration 2152 : loss : 0.024942, loss_ce: 0.008943
2022-01-17 12:02:59,354 iteration 2153 : loss : 0.025660, loss_ce: 0.010166
2022-01-17 12:03:00,444 iteration 2154 : loss : 0.045521, loss_ce: 0.013617
2022-01-17 12:03:01,392 iteration 2155 : loss : 0.033467, loss_ce: 0.012368
2022-01-17 12:03:02,282 iteration 2156 : loss : 0.038804, loss_ce: 0.016735
2022-01-17 12:03:03,374 iteration 2157 : loss : 0.042270, loss_ce: 0.015539
2022-01-17 12:03:04,413 iteration 2158 : loss : 0.036939, loss_ce: 0.015894
2022-01-17 12:03:05,380 iteration 2159 : loss : 0.042428, loss_ce: 0.013176
 32%|█████████▏                   | 127/400 [37:15<1:19:11, 17.40s/it]2022-01-17 12:03:06,315 iteration 2160 : loss : 0.029695, loss_ce: 0.012508
2022-01-17 12:03:07,200 iteration 2161 : loss : 0.025263, loss_ce: 0.007921
2022-01-17 12:03:08,127 iteration 2162 : loss : 0.033700, loss_ce: 0.013817
2022-01-17 12:03:09,049 iteration 2163 : loss : 0.028696, loss_ce: 0.010066
2022-01-17 12:03:10,031 iteration 2164 : loss : 0.028160, loss_ce: 0.013335
2022-01-17 12:03:10,998 iteration 2165 : loss : 0.042233, loss_ce: 0.013961
2022-01-17 12:03:11,902 iteration 2166 : loss : 0.042105, loss_ce: 0.020628
2022-01-17 12:03:12,774 iteration 2167 : loss : 0.028871, loss_ce: 0.010912
2022-01-17 12:03:13,689 iteration 2168 : loss : 0.025069, loss_ce: 0.009865
2022-01-17 12:03:14,666 iteration 2169 : loss : 0.051735, loss_ce: 0.017942
2022-01-17 12:03:15,502 iteration 2170 : loss : 0.023899, loss_ce: 0.007257
2022-01-17 12:03:16,428 iteration 2171 : loss : 0.029090, loss_ce: 0.012074
2022-01-17 12:03:17,344 iteration 2172 : loss : 0.040680, loss_ce: 0.014228
2022-01-17 12:03:18,251 iteration 2173 : loss : 0.032071, loss_ce: 0.007664
2022-01-17 12:03:19,199 iteration 2174 : loss : 0.037535, loss_ce: 0.014282
2022-01-17 12:03:20,239 iteration 2175 : loss : 0.027339, loss_ce: 0.011159
2022-01-17 12:03:21,075 iteration 2176 : loss : 0.024713, loss_ce: 0.010880
 32%|█████████▎                   | 128/400 [37:30<1:16:35, 16.89s/it]2022-01-17 12:03:21,994 iteration 2177 : loss : 0.027440, loss_ce: 0.013739
2022-01-17 12:03:22,942 iteration 2178 : loss : 0.026170, loss_ce: 0.008835
2022-01-17 12:03:23,969 iteration 2179 : loss : 0.030470, loss_ce: 0.010681
2022-01-17 12:03:24,957 iteration 2180 : loss : 0.030712, loss_ce: 0.010491
2022-01-17 12:03:25,836 iteration 2181 : loss : 0.022286, loss_ce: 0.008009
2022-01-17 12:03:26,781 iteration 2182 : loss : 0.046748, loss_ce: 0.016511
2022-01-17 12:03:27,753 iteration 2183 : loss : 0.042226, loss_ce: 0.010895
2022-01-17 12:03:28,646 iteration 2184 : loss : 0.036233, loss_ce: 0.014783
2022-01-17 12:03:29,543 iteration 2185 : loss : 0.026104, loss_ce: 0.008909
2022-01-17 12:03:30,572 iteration 2186 : loss : 0.027856, loss_ce: 0.010542
2022-01-17 12:03:31,612 iteration 2187 : loss : 0.033960, loss_ce: 0.010277
2022-01-17 12:03:32,709 iteration 2188 : loss : 0.059583, loss_ce: 0.031035
2022-01-17 12:03:33,790 iteration 2189 : loss : 0.044214, loss_ce: 0.014728
2022-01-17 12:03:34,739 iteration 2190 : loss : 0.031135, loss_ce: 0.012357
2022-01-17 12:03:35,712 iteration 2191 : loss : 0.026172, loss_ce: 0.009307
2022-01-17 12:03:36,619 iteration 2192 : loss : 0.042150, loss_ce: 0.012929
2022-01-17 12:03:37,591 iteration 2193 : loss : 0.030803, loss_ce: 0.010833
 32%|█████████▎                   | 129/400 [37:47<1:15:47, 16.78s/it]2022-01-17 12:03:38,624 iteration 2194 : loss : 0.031615, loss_ce: 0.011873
2022-01-17 12:03:39,605 iteration 2195 : loss : 0.029319, loss_ce: 0.013427
2022-01-17 12:03:40,614 iteration 2196 : loss : 0.036739, loss_ce: 0.017610
2022-01-17 12:03:41,655 iteration 2197 : loss : 0.024209, loss_ce: 0.008763
2022-01-17 12:03:42,601 iteration 2198 : loss : 0.048037, loss_ce: 0.012524
2022-01-17 12:03:43,559 iteration 2199 : loss : 0.031748, loss_ce: 0.015005
2022-01-17 12:03:44,597 iteration 2200 : loss : 0.035987, loss_ce: 0.007821
2022-01-17 12:03:45,490 iteration 2201 : loss : 0.028953, loss_ce: 0.010786
2022-01-17 12:03:46,547 iteration 2202 : loss : 0.042888, loss_ce: 0.020235
2022-01-17 12:03:47,522 iteration 2203 : loss : 0.039317, loss_ce: 0.010310
2022-01-17 12:03:48,396 iteration 2204 : loss : 0.028623, loss_ce: 0.008686
2022-01-17 12:03:49,369 iteration 2205 : loss : 0.031091, loss_ce: 0.013901
2022-01-17 12:03:50,417 iteration 2206 : loss : 0.042554, loss_ce: 0.018144
2022-01-17 12:03:51,402 iteration 2207 : loss : 0.042232, loss_ce: 0.015622
2022-01-17 12:03:52,417 iteration 2208 : loss : 0.032651, loss_ce: 0.009434
2022-01-17 12:03:53,373 iteration 2209 : loss : 0.034642, loss_ce: 0.013632
2022-01-17 12:03:53,374 Training Data Eval:
2022-01-17 12:03:57,835   Average segmentation loss on training set: 0.0261
2022-01-17 12:03:57,836 Validation Data Eval:
2022-01-17 12:03:59,348   Average segmentation loss on validation set: 0.0768
2022-01-17 12:04:00,336 iteration 2210 : loss : 0.039148, loss_ce: 0.020323
 32%|█████████▍                   | 130/400 [38:10<1:23:33, 18.57s/it]2022-01-17 12:04:01,339 iteration 2211 : loss : 0.034460, loss_ce: 0.009270
2022-01-17 12:04:02,248 iteration 2212 : loss : 0.031883, loss_ce: 0.013983
2022-01-17 12:04:03,214 iteration 2213 : loss : 0.045260, loss_ce: 0.009975
2022-01-17 12:04:04,089 iteration 2214 : loss : 0.029011, loss_ce: 0.009296
2022-01-17 12:04:04,962 iteration 2215 : loss : 0.024491, loss_ce: 0.009677
2022-01-17 12:04:05,879 iteration 2216 : loss : 0.046974, loss_ce: 0.021758
2022-01-17 12:04:06,776 iteration 2217 : loss : 0.034643, loss_ce: 0.015897
2022-01-17 12:04:07,701 iteration 2218 : loss : 0.027101, loss_ce: 0.009347
2022-01-17 12:04:08,684 iteration 2219 : loss : 0.037963, loss_ce: 0.016759
2022-01-17 12:04:09,724 iteration 2220 : loss : 0.031296, loss_ce: 0.013891
2022-01-17 12:04:10,749 iteration 2221 : loss : 0.033857, loss_ce: 0.011866
2022-01-17 12:04:11,614 iteration 2222 : loss : 0.030084, loss_ce: 0.012343
2022-01-17 12:04:12,510 iteration 2223 : loss : 0.040347, loss_ce: 0.013607
2022-01-17 12:04:13,526 iteration 2224 : loss : 0.037673, loss_ce: 0.016280
2022-01-17 12:04:14,492 iteration 2225 : loss : 0.041675, loss_ce: 0.014055
2022-01-17 12:04:15,515 iteration 2226 : loss : 0.037540, loss_ce: 0.016499
2022-01-17 12:04:16,508 iteration 2227 : loss : 0.038701, loss_ce: 0.011958
 33%|█████████▍                   | 131/400 [38:26<1:20:01, 17.85s/it]2022-01-17 12:04:17,570 iteration 2228 : loss : 0.040103, loss_ce: 0.016545
2022-01-17 12:04:18,530 iteration 2229 : loss : 0.055434, loss_ce: 0.018382
2022-01-17 12:04:19,625 iteration 2230 : loss : 0.042095, loss_ce: 0.017313
2022-01-17 12:04:20,556 iteration 2231 : loss : 0.038821, loss_ce: 0.021374
2022-01-17 12:04:21,482 iteration 2232 : loss : 0.028454, loss_ce: 0.014209
2022-01-17 12:04:22,626 iteration 2233 : loss : 0.045745, loss_ce: 0.012691
2022-01-17 12:04:23,610 iteration 2234 : loss : 0.028677, loss_ce: 0.007458
2022-01-17 12:04:24,559 iteration 2235 : loss : 0.030437, loss_ce: 0.011629
2022-01-17 12:04:25,489 iteration 2236 : loss : 0.027239, loss_ce: 0.011159
2022-01-17 12:04:26,461 iteration 2237 : loss : 0.037433, loss_ce: 0.016501
2022-01-17 12:04:27,361 iteration 2238 : loss : 0.034617, loss_ce: 0.009392
2022-01-17 12:04:28,296 iteration 2239 : loss : 0.034660, loss_ce: 0.007044
2022-01-17 12:04:29,167 iteration 2240 : loss : 0.031945, loss_ce: 0.008647
2022-01-17 12:04:30,113 iteration 2241 : loss : 0.023861, loss_ce: 0.007758
2022-01-17 12:04:31,136 iteration 2242 : loss : 0.033751, loss_ce: 0.011621
2022-01-17 12:04:32,132 iteration 2243 : loss : 0.042134, loss_ce: 0.022029
2022-01-17 12:04:33,062 iteration 2244 : loss : 0.024812, loss_ce: 0.008375
 33%|█████████▌                   | 132/400 [38:42<1:17:59, 17.46s/it]2022-01-17 12:04:34,043 iteration 2245 : loss : 0.023298, loss_ce: 0.007506
2022-01-17 12:04:34,903 iteration 2246 : loss : 0.027764, loss_ce: 0.007516
2022-01-17 12:04:35,867 iteration 2247 : loss : 0.033581, loss_ce: 0.014853
2022-01-17 12:04:36,891 iteration 2248 : loss : 0.035586, loss_ce: 0.015687
2022-01-17 12:04:37,839 iteration 2249 : loss : 0.023902, loss_ce: 0.010111
2022-01-17 12:04:38,791 iteration 2250 : loss : 0.030598, loss_ce: 0.009960
2022-01-17 12:04:39,770 iteration 2251 : loss : 0.037647, loss_ce: 0.014988
2022-01-17 12:04:40,717 iteration 2252 : loss : 0.042462, loss_ce: 0.014959
2022-01-17 12:04:41,767 iteration 2253 : loss : 0.037431, loss_ce: 0.014166
2022-01-17 12:04:42,764 iteration 2254 : loss : 0.029431, loss_ce: 0.011397
2022-01-17 12:04:43,706 iteration 2255 : loss : 0.022246, loss_ce: 0.007655
2022-01-17 12:04:44,635 iteration 2256 : loss : 0.024812, loss_ce: 0.009412
2022-01-17 12:04:45,534 iteration 2257 : loss : 0.029891, loss_ce: 0.008936
2022-01-17 12:04:46,433 iteration 2258 : loss : 0.038343, loss_ce: 0.013639
2022-01-17 12:04:47,449 iteration 2259 : loss : 0.030637, loss_ce: 0.011299
2022-01-17 12:04:48,338 iteration 2260 : loss : 0.032259, loss_ce: 0.012180
2022-01-17 12:04:49,312 iteration 2261 : loss : 0.046676, loss_ce: 0.019294
 33%|█████████▋                   | 133/400 [38:59<1:16:05, 17.10s/it]2022-01-17 12:04:50,257 iteration 2262 : loss : 0.024313, loss_ce: 0.011443
2022-01-17 12:04:51,284 iteration 2263 : loss : 0.035644, loss_ce: 0.011986
2022-01-17 12:04:52,336 iteration 2264 : loss : 0.034490, loss_ce: 0.009708
2022-01-17 12:04:53,316 iteration 2265 : loss : 0.025145, loss_ce: 0.009737
2022-01-17 12:04:54,232 iteration 2266 : loss : 0.023065, loss_ce: 0.009503
2022-01-17 12:04:55,162 iteration 2267 : loss : 0.021231, loss_ce: 0.007472
2022-01-17 12:04:56,120 iteration 2268 : loss : 0.028117, loss_ce: 0.009973
2022-01-17 12:04:57,033 iteration 2269 : loss : 0.027804, loss_ce: 0.014517
2022-01-17 12:04:57,984 iteration 2270 : loss : 0.028507, loss_ce: 0.008506
2022-01-17 12:04:58,908 iteration 2271 : loss : 0.043748, loss_ce: 0.017176
2022-01-17 12:04:59,847 iteration 2272 : loss : 0.032066, loss_ce: 0.015867
2022-01-17 12:05:00,885 iteration 2273 : loss : 0.023881, loss_ce: 0.007577
2022-01-17 12:05:01,859 iteration 2274 : loss : 0.029164, loss_ce: 0.008803
2022-01-17 12:05:02,870 iteration 2275 : loss : 0.039906, loss_ce: 0.014196
2022-01-17 12:05:03,766 iteration 2276 : loss : 0.024641, loss_ce: 0.010250
2022-01-17 12:05:04,728 iteration 2277 : loss : 0.031194, loss_ce: 0.009489
2022-01-17 12:05:05,632 iteration 2278 : loss : 0.024539, loss_ce: 0.009447
 34%|█████████▋                   | 134/400 [39:15<1:14:45, 16.86s/it]2022-01-17 12:05:06,557 iteration 2279 : loss : 0.043843, loss_ce: 0.015448
2022-01-17 12:05:07,516 iteration 2280 : loss : 0.035792, loss_ce: 0.016543
2022-01-17 12:05:08,462 iteration 2281 : loss : 0.036679, loss_ce: 0.007789
2022-01-17 12:05:09,440 iteration 2282 : loss : 0.033230, loss_ce: 0.012664
2022-01-17 12:05:10,470 iteration 2283 : loss : 0.034915, loss_ce: 0.015532
2022-01-17 12:05:11,397 iteration 2284 : loss : 0.034660, loss_ce: 0.015313
2022-01-17 12:05:12,329 iteration 2285 : loss : 0.031847, loss_ce: 0.013506
2022-01-17 12:05:13,258 iteration 2286 : loss : 0.028630, loss_ce: 0.009864
2022-01-17 12:05:14,197 iteration 2287 : loss : 0.024902, loss_ce: 0.009166
2022-01-17 12:05:15,186 iteration 2288 : loss : 0.030240, loss_ce: 0.010438
2022-01-17 12:05:16,093 iteration 2289 : loss : 0.025574, loss_ce: 0.005876
2022-01-17 12:05:17,112 iteration 2290 : loss : 0.042609, loss_ce: 0.023127
2022-01-17 12:05:18,059 iteration 2291 : loss : 0.026469, loss_ce: 0.008888
2022-01-17 12:05:18,986 iteration 2292 : loss : 0.029553, loss_ce: 0.012755
2022-01-17 12:05:19,854 iteration 2293 : loss : 0.032712, loss_ce: 0.017207
2022-01-17 12:05:20,844 iteration 2294 : loss : 0.037144, loss_ce: 0.011856
2022-01-17 12:05:20,844 Training Data Eval:
2022-01-17 12:05:25,318   Average segmentation loss on training set: 0.0223
2022-01-17 12:05:25,319 Validation Data Eval:
2022-01-17 12:05:26,823   Average segmentation loss on validation set: 0.1011
2022-01-17 12:05:27,856 iteration 2295 : loss : 0.033446, loss_ce: 0.011660
 34%|█████████▊                   | 135/400 [39:37<1:21:35, 18.47s/it]2022-01-17 12:05:28,766 iteration 2296 : loss : 0.026932, loss_ce: 0.011356
2022-01-17 12:05:29,707 iteration 2297 : loss : 0.024927, loss_ce: 0.010628
2022-01-17 12:05:30,646 iteration 2298 : loss : 0.022948, loss_ce: 0.009626
2022-01-17 12:05:31,680 iteration 2299 : loss : 0.046584, loss_ce: 0.022475
2022-01-17 12:05:32,602 iteration 2300 : loss : 0.025351, loss_ce: 0.012676
2022-01-17 12:05:33,629 iteration 2301 : loss : 0.024426, loss_ce: 0.007500
2022-01-17 12:05:34,622 iteration 2302 : loss : 0.045190, loss_ce: 0.013986
2022-01-17 12:05:35,594 iteration 2303 : loss : 0.026561, loss_ce: 0.008288
2022-01-17 12:05:36,629 iteration 2304 : loss : 0.036073, loss_ce: 0.010857
2022-01-17 12:05:37,618 iteration 2305 : loss : 0.025914, loss_ce: 0.008389
2022-01-17 12:05:38,675 iteration 2306 : loss : 0.031457, loss_ce: 0.014399
2022-01-17 12:05:39,600 iteration 2307 : loss : 0.036199, loss_ce: 0.009755
2022-01-17 12:05:40,496 iteration 2308 : loss : 0.028634, loss_ce: 0.009128
2022-01-17 12:05:41,421 iteration 2309 : loss : 0.029261, loss_ce: 0.013631
2022-01-17 12:05:42,444 iteration 2310 : loss : 0.024522, loss_ce: 0.009407
2022-01-17 12:05:43,311 iteration 2311 : loss : 0.044109, loss_ce: 0.011916
2022-01-17 12:05:44,273 iteration 2312 : loss : 0.035284, loss_ce: 0.011210
 34%|█████████▊                   | 136/400 [39:54<1:18:32, 17.85s/it]2022-01-17 12:05:45,303 iteration 2313 : loss : 0.035345, loss_ce: 0.011455
2022-01-17 12:05:46,148 iteration 2314 : loss : 0.020601, loss_ce: 0.006450
2022-01-17 12:05:47,052 iteration 2315 : loss : 0.023045, loss_ce: 0.007763
2022-01-17 12:05:48,090 iteration 2316 : loss : 0.031914, loss_ce: 0.014301
2022-01-17 12:05:48,978 iteration 2317 : loss : 0.031960, loss_ce: 0.009752
2022-01-17 12:05:49,904 iteration 2318 : loss : 0.029018, loss_ce: 0.013687
2022-01-17 12:05:50,855 iteration 2319 : loss : 0.028699, loss_ce: 0.009835
2022-01-17 12:05:51,885 iteration 2320 : loss : 0.044061, loss_ce: 0.017491
2022-01-17 12:05:52,824 iteration 2321 : loss : 0.044481, loss_ce: 0.022986
2022-01-17 12:05:53,779 iteration 2322 : loss : 0.031194, loss_ce: 0.013163
2022-01-17 12:05:54,639 iteration 2323 : loss : 0.020616, loss_ce: 0.007297
2022-01-17 12:05:55,572 iteration 2324 : loss : 0.022203, loss_ce: 0.009076
2022-01-17 12:05:56,400 iteration 2325 : loss : 0.021698, loss_ce: 0.009445
2022-01-17 12:05:57,330 iteration 2326 : loss : 0.063557, loss_ce: 0.010689
2022-01-17 12:05:58,239 iteration 2327 : loss : 0.030548, loss_ce: 0.011083
2022-01-17 12:05:59,187 iteration 2328 : loss : 0.036717, loss_ce: 0.015168
2022-01-17 12:06:00,082 iteration 2329 : loss : 0.027154, loss_ce: 0.010234
 34%|█████████▉                   | 137/400 [40:09<1:15:35, 17.24s/it]2022-01-17 12:06:01,089 iteration 2330 : loss : 0.033917, loss_ce: 0.014061
2022-01-17 12:06:01,992 iteration 2331 : loss : 0.023459, loss_ce: 0.009125
2022-01-17 12:06:03,028 iteration 2332 : loss : 0.028661, loss_ce: 0.012271
2022-01-17 12:06:03,976 iteration 2333 : loss : 0.041819, loss_ce: 0.017543
2022-01-17 12:06:05,063 iteration 2334 : loss : 0.025718, loss_ce: 0.011202
2022-01-17 12:06:06,128 iteration 2335 : loss : 0.034934, loss_ce: 0.016067
2022-01-17 12:06:07,154 iteration 2336 : loss : 0.037293, loss_ce: 0.015249
2022-01-17 12:06:08,112 iteration 2337 : loss : 0.033822, loss_ce: 0.010845
2022-01-17 12:06:09,098 iteration 2338 : loss : 0.030756, loss_ce: 0.011634
2022-01-17 12:06:10,069 iteration 2339 : loss : 0.036180, loss_ce: 0.012345
2022-01-17 12:06:10,949 iteration 2340 : loss : 0.025273, loss_ce: 0.009906
2022-01-17 12:06:11,918 iteration 2341 : loss : 0.031446, loss_ce: 0.011176
2022-01-17 12:06:12,899 iteration 2342 : loss : 0.026704, loss_ce: 0.009851
2022-01-17 12:06:13,985 iteration 2343 : loss : 0.026884, loss_ce: 0.010231
2022-01-17 12:06:14,891 iteration 2344 : loss : 0.036600, loss_ce: 0.011531
2022-01-17 12:06:15,815 iteration 2345 : loss : 0.039499, loss_ce: 0.019431
2022-01-17 12:06:16,755 iteration 2346 : loss : 0.034932, loss_ce: 0.014283
 34%|██████████                   | 138/400 [40:26<1:14:32, 17.07s/it]2022-01-17 12:06:17,845 iteration 2347 : loss : 0.037660, loss_ce: 0.016306
2022-01-17 12:06:18,808 iteration 2348 : loss : 0.030361, loss_ce: 0.011330
2022-01-17 12:06:19,724 iteration 2349 : loss : 0.026017, loss_ce: 0.008093
2022-01-17 12:06:20,646 iteration 2350 : loss : 0.042471, loss_ce: 0.012543
2022-01-17 12:06:21,667 iteration 2351 : loss : 0.050233, loss_ce: 0.024235
2022-01-17 12:06:22,568 iteration 2352 : loss : 0.020513, loss_ce: 0.010130
2022-01-17 12:06:23,477 iteration 2353 : loss : 0.024489, loss_ce: 0.009942
2022-01-17 12:06:24,381 iteration 2354 : loss : 0.020369, loss_ce: 0.009492
2022-01-17 12:06:25,296 iteration 2355 : loss : 0.043409, loss_ce: 0.016628
2022-01-17 12:06:26,309 iteration 2356 : loss : 0.038008, loss_ce: 0.013628
2022-01-17 12:06:27,267 iteration 2357 : loss : 0.037247, loss_ce: 0.010442
2022-01-17 12:06:28,225 iteration 2358 : loss : 0.032053, loss_ce: 0.013332
2022-01-17 12:06:29,142 iteration 2359 : loss : 0.029451, loss_ce: 0.010110
2022-01-17 12:06:30,038 iteration 2360 : loss : 0.029658, loss_ce: 0.007820
2022-01-17 12:06:30,983 iteration 2361 : loss : 0.026760, loss_ce: 0.009134
2022-01-17 12:06:32,068 iteration 2362 : loss : 0.049110, loss_ce: 0.020123
2022-01-17 12:06:33,028 iteration 2363 : loss : 0.022909, loss_ce: 0.009955
 35%|██████████                   | 139/400 [40:42<1:13:13, 16.83s/it]2022-01-17 12:06:34,100 iteration 2364 : loss : 0.036385, loss_ce: 0.016183
2022-01-17 12:06:35,143 iteration 2365 : loss : 0.027893, loss_ce: 0.010708
2022-01-17 12:06:36,138 iteration 2366 : loss : 0.035991, loss_ce: 0.013491
2022-01-17 12:06:37,027 iteration 2367 : loss : 0.036324, loss_ce: 0.007805
2022-01-17 12:06:37,929 iteration 2368 : loss : 0.023586, loss_ce: 0.009031
2022-01-17 12:06:38,894 iteration 2369 : loss : 0.034536, loss_ce: 0.009630
2022-01-17 12:06:39,838 iteration 2370 : loss : 0.036751, loss_ce: 0.015122
2022-01-17 12:06:40,831 iteration 2371 : loss : 0.026966, loss_ce: 0.011459
2022-01-17 12:06:41,738 iteration 2372 : loss : 0.025440, loss_ce: 0.008628
2022-01-17 12:06:42,672 iteration 2373 : loss : 0.046894, loss_ce: 0.016669
2022-01-17 12:06:43,569 iteration 2374 : loss : 0.025755, loss_ce: 0.010156
2022-01-17 12:06:44,486 iteration 2375 : loss : 0.025484, loss_ce: 0.008764
2022-01-17 12:06:45,455 iteration 2376 : loss : 0.029132, loss_ce: 0.015847
2022-01-17 12:06:46,426 iteration 2377 : loss : 0.029818, loss_ce: 0.014687
2022-01-17 12:06:47,393 iteration 2378 : loss : 0.023609, loss_ce: 0.008747
2022-01-17 12:06:48,379 iteration 2379 : loss : 0.040884, loss_ce: 0.018854
2022-01-17 12:06:48,379 Training Data Eval:
2022-01-17 12:06:52,846   Average segmentation loss on training set: 0.0218
2022-01-17 12:06:52,847 Validation Data Eval:
2022-01-17 12:06:54,357   Average segmentation loss on validation set: 0.0881
2022-01-17 12:06:55,269 iteration 2380 : loss : 0.025378, loss_ce: 0.010575
 35%|██████████▏                  | 140/400 [41:05<1:19:57, 18.45s/it]2022-01-17 12:06:56,206 iteration 2381 : loss : 0.026696, loss_ce: 0.008033
2022-01-17 12:06:57,199 iteration 2382 : loss : 0.026899, loss_ce: 0.008656
2022-01-17 12:06:58,110 iteration 2383 : loss : 0.020021, loss_ce: 0.006169
2022-01-17 12:06:59,115 iteration 2384 : loss : 0.039959, loss_ce: 0.015242
2022-01-17 12:07:00,137 iteration 2385 : loss : 0.029510, loss_ce: 0.010740
2022-01-17 12:07:01,079 iteration 2386 : loss : 0.023726, loss_ce: 0.007026
2022-01-17 12:07:01,999 iteration 2387 : loss : 0.031340, loss_ce: 0.010247
2022-01-17 12:07:02,955 iteration 2388 : loss : 0.035368, loss_ce: 0.015371
2022-01-17 12:07:03,839 iteration 2389 : loss : 0.015338, loss_ce: 0.004907
2022-01-17 12:07:04,810 iteration 2390 : loss : 0.026529, loss_ce: 0.013116
2022-01-17 12:07:05,741 iteration 2391 : loss : 0.027345, loss_ce: 0.015107
2022-01-17 12:07:06,719 iteration 2392 : loss : 0.025919, loss_ce: 0.008149
2022-01-17 12:07:07,705 iteration 2393 : loss : 0.037632, loss_ce: 0.013087
2022-01-17 12:07:08,563 iteration 2394 : loss : 0.026819, loss_ce: 0.008849
2022-01-17 12:07:09,574 iteration 2395 : loss : 0.034501, loss_ce: 0.016654
2022-01-17 12:07:10,484 iteration 2396 : loss : 0.022237, loss_ce: 0.010005
2022-01-17 12:07:11,466 iteration 2397 : loss : 0.028008, loss_ce: 0.011036
 35%|██████████▏                  | 141/400 [41:21<1:16:44, 17.78s/it]2022-01-17 12:07:12,450 iteration 2398 : loss : 0.037557, loss_ce: 0.011995
2022-01-17 12:07:13,368 iteration 2399 : loss : 0.024844, loss_ce: 0.007374
2022-01-17 12:07:14,379 iteration 2400 : loss : 0.034139, loss_ce: 0.014625
2022-01-17 12:07:15,333 iteration 2401 : loss : 0.027826, loss_ce: 0.007934
2022-01-17 12:07:16,342 iteration 2402 : loss : 0.033253, loss_ce: 0.016102
2022-01-17 12:07:17,266 iteration 2403 : loss : 0.031436, loss_ce: 0.011852
2022-01-17 12:07:18,163 iteration 2404 : loss : 0.027301, loss_ce: 0.011618
2022-01-17 12:07:19,031 iteration 2405 : loss : 0.029890, loss_ce: 0.010170
2022-01-17 12:07:20,118 iteration 2406 : loss : 0.028835, loss_ce: 0.009638
2022-01-17 12:07:20,997 iteration 2407 : loss : 0.029899, loss_ce: 0.016398
2022-01-17 12:07:21,882 iteration 2408 : loss : 0.019797, loss_ce: 0.008245
2022-01-17 12:07:22,886 iteration 2409 : loss : 0.028140, loss_ce: 0.010298
2022-01-17 12:07:23,901 iteration 2410 : loss : 0.036627, loss_ce: 0.015259
2022-01-17 12:07:24,891 iteration 2411 : loss : 0.029004, loss_ce: 0.008721
2022-01-17 12:07:25,792 iteration 2412 : loss : 0.019641, loss_ce: 0.007612
2022-01-17 12:07:26,814 iteration 2413 : loss : 0.036328, loss_ce: 0.016240
2022-01-17 12:07:27,770 iteration 2414 : loss : 0.024240, loss_ce: 0.009545
 36%|██████████▎                  | 142/400 [41:37<1:14:32, 17.33s/it]2022-01-17 12:07:28,776 iteration 2415 : loss : 0.027684, loss_ce: 0.009851
2022-01-17 12:07:29,697 iteration 2416 : loss : 0.023984, loss_ce: 0.008566
2022-01-17 12:07:30,641 iteration 2417 : loss : 0.024130, loss_ce: 0.007693
2022-01-17 12:07:31,682 iteration 2418 : loss : 0.027291, loss_ce: 0.009208
2022-01-17 12:07:32,644 iteration 2419 : loss : 0.030279, loss_ce: 0.014388
2022-01-17 12:07:33,702 iteration 2420 : loss : 0.032378, loss_ce: 0.016103
2022-01-17 12:07:34,729 iteration 2421 : loss : 0.044619, loss_ce: 0.013581
2022-01-17 12:07:35,732 iteration 2422 : loss : 0.032048, loss_ce: 0.011782
2022-01-17 12:07:36,666 iteration 2423 : loss : 0.027155, loss_ce: 0.008630
2022-01-17 12:07:37,584 iteration 2424 : loss : 0.019745, loss_ce: 0.008144
2022-01-17 12:07:38,627 iteration 2425 : loss : 0.029526, loss_ce: 0.008993
2022-01-17 12:07:39,544 iteration 2426 : loss : 0.028877, loss_ce: 0.009103
2022-01-17 12:07:40,389 iteration 2427 : loss : 0.024085, loss_ce: 0.010985
2022-01-17 12:07:41,291 iteration 2428 : loss : 0.033450, loss_ce: 0.009211
2022-01-17 12:07:42,203 iteration 2429 : loss : 0.028931, loss_ce: 0.010183
2022-01-17 12:07:43,117 iteration 2430 : loss : 0.018789, loss_ce: 0.007520
2022-01-17 12:07:44,070 iteration 2431 : loss : 0.027078, loss_ce: 0.013634
 36%|██████████▎                  | 143/400 [41:53<1:12:54, 17.02s/it]2022-01-17 12:07:45,019 iteration 2432 : loss : 0.024408, loss_ce: 0.007419
2022-01-17 12:07:45,954 iteration 2433 : loss : 0.025225, loss_ce: 0.009171
2022-01-17 12:07:46,905 iteration 2434 : loss : 0.027590, loss_ce: 0.009508
2022-01-17 12:07:47,951 iteration 2435 : loss : 0.040335, loss_ce: 0.019686
2022-01-17 12:07:48,817 iteration 2436 : loss : 0.024059, loss_ce: 0.010093
2022-01-17 12:07:49,811 iteration 2437 : loss : 0.020204, loss_ce: 0.006364
2022-01-17 12:07:50,818 iteration 2438 : loss : 0.031423, loss_ce: 0.009932
2022-01-17 12:07:51,806 iteration 2439 : loss : 0.023153, loss_ce: 0.008298
2022-01-17 12:07:52,807 iteration 2440 : loss : 0.037966, loss_ce: 0.014774
2022-01-17 12:07:53,748 iteration 2441 : loss : 0.025868, loss_ce: 0.008401
2022-01-17 12:07:54,678 iteration 2442 : loss : 0.030793, loss_ce: 0.012626
2022-01-17 12:07:55,559 iteration 2443 : loss : 0.022795, loss_ce: 0.008510
2022-01-17 12:07:56,507 iteration 2444 : loss : 0.025802, loss_ce: 0.009298
2022-01-17 12:07:57,476 iteration 2445 : loss : 0.029003, loss_ce: 0.011878
2022-01-17 12:07:58,523 iteration 2446 : loss : 0.023762, loss_ce: 0.010262
2022-01-17 12:07:59,409 iteration 2447 : loss : 0.024670, loss_ce: 0.007858
2022-01-17 12:08:00,412 iteration 2448 : loss : 0.032625, loss_ce: 0.011065
 36%|██████████▍                  | 144/400 [42:10<1:11:45, 16.82s/it]2022-01-17 12:08:01,327 iteration 2449 : loss : 0.043979, loss_ce: 0.015641
2022-01-17 12:08:02,204 iteration 2450 : loss : 0.020411, loss_ce: 0.010421
2022-01-17 12:08:03,132 iteration 2451 : loss : 0.023588, loss_ce: 0.006948
2022-01-17 12:08:04,035 iteration 2452 : loss : 0.031486, loss_ce: 0.012247
2022-01-17 12:08:04,993 iteration 2453 : loss : 0.028931, loss_ce: 0.009851
2022-01-17 12:08:05,919 iteration 2454 : loss : 0.030641, loss_ce: 0.010330
2022-01-17 12:08:06,817 iteration 2455 : loss : 0.028443, loss_ce: 0.013664
2022-01-17 12:08:07,697 iteration 2456 : loss : 0.024541, loss_ce: 0.009351
2022-01-17 12:08:08,623 iteration 2457 : loss : 0.029741, loss_ce: 0.011100
2022-01-17 12:08:09,516 iteration 2458 : loss : 0.025952, loss_ce: 0.009640
2022-01-17 12:08:10,365 iteration 2459 : loss : 0.020738, loss_ce: 0.008057
2022-01-17 12:08:11,279 iteration 2460 : loss : 0.039004, loss_ce: 0.009616
2022-01-17 12:08:12,294 iteration 2461 : loss : 0.037073, loss_ce: 0.013157
2022-01-17 12:08:13,273 iteration 2462 : loss : 0.026351, loss_ce: 0.008857
2022-01-17 12:08:14,199 iteration 2463 : loss : 0.027954, loss_ce: 0.012790
2022-01-17 12:08:15,168 iteration 2464 : loss : 0.024398, loss_ce: 0.009194
2022-01-17 12:08:15,168 Training Data Eval:
2022-01-17 12:08:19,639   Average segmentation loss on training set: 0.0232
2022-01-17 12:08:19,640 Validation Data Eval:
2022-01-17 12:08:21,146   Average segmentation loss on validation set: 0.1097
2022-01-17 12:08:22,074 iteration 2465 : loss : 0.027151, loss_ce: 0.010026
 36%|██████████▌                  | 145/400 [42:31<1:17:39, 18.27s/it]2022-01-17 12:08:23,131 iteration 2466 : loss : 0.047339, loss_ce: 0.016069
2022-01-17 12:08:24,161 iteration 2467 : loss : 0.026975, loss_ce: 0.011109
2022-01-17 12:08:25,088 iteration 2468 : loss : 0.032268, loss_ce: 0.015679
2022-01-17 12:08:25,985 iteration 2469 : loss : 0.019759, loss_ce: 0.008312
2022-01-17 12:08:26,918 iteration 2470 : loss : 0.023429, loss_ce: 0.007532
2022-01-17 12:08:27,951 iteration 2471 : loss : 0.035910, loss_ce: 0.012685
2022-01-17 12:08:28,855 iteration 2472 : loss : 0.047305, loss_ce: 0.019481
2022-01-17 12:08:29,859 iteration 2473 : loss : 0.028937, loss_ce: 0.011364
2022-01-17 12:08:30,776 iteration 2474 : loss : 0.025641, loss_ce: 0.008654
2022-01-17 12:08:31,723 iteration 2475 : loss : 0.038075, loss_ce: 0.016174
2022-01-17 12:08:32,619 iteration 2476 : loss : 0.028125, loss_ce: 0.013751
2022-01-17 12:08:33,659 iteration 2477 : loss : 0.046761, loss_ce: 0.017795
2022-01-17 12:08:34,641 iteration 2478 : loss : 0.029901, loss_ce: 0.009134
2022-01-17 12:08:35,503 iteration 2479 : loss : 0.029102, loss_ce: 0.008535
2022-01-17 12:08:36,456 iteration 2480 : loss : 0.032957, loss_ce: 0.011187
2022-01-17 12:08:37,469 iteration 2481 : loss : 0.032003, loss_ce: 0.011874
2022-01-17 12:08:38,386 iteration 2482 : loss : 0.026238, loss_ce: 0.012031
 36%|██████████▌                  | 146/400 [42:48<1:14:51, 17.68s/it]2022-01-17 12:08:39,465 iteration 2483 : loss : 0.039777, loss_ce: 0.016929
2022-01-17 12:08:40,438 iteration 2484 : loss : 0.041796, loss_ce: 0.008345
2022-01-17 12:08:41,345 iteration 2485 : loss : 0.025893, loss_ce: 0.011341
2022-01-17 12:08:42,278 iteration 2486 : loss : 0.026315, loss_ce: 0.011274
2022-01-17 12:08:43,203 iteration 2487 : loss : 0.029662, loss_ce: 0.009462
2022-01-17 12:08:44,212 iteration 2488 : loss : 0.036315, loss_ce: 0.015318
2022-01-17 12:08:45,148 iteration 2489 : loss : 0.032374, loss_ce: 0.012724
2022-01-17 12:08:46,145 iteration 2490 : loss : 0.041182, loss_ce: 0.017367
2022-01-17 12:08:47,174 iteration 2491 : loss : 0.027183, loss_ce: 0.011344
2022-01-17 12:08:48,019 iteration 2492 : loss : 0.022800, loss_ce: 0.008411
2022-01-17 12:08:48,981 iteration 2493 : loss : 0.028640, loss_ce: 0.011542
2022-01-17 12:08:49,908 iteration 2494 : loss : 0.030845, loss_ce: 0.007824
2022-01-17 12:08:50,832 iteration 2495 : loss : 0.028112, loss_ce: 0.011618
2022-01-17 12:08:51,966 iteration 2496 : loss : 0.039448, loss_ce: 0.010687
2022-01-17 12:08:52,951 iteration 2497 : loss : 0.035015, loss_ce: 0.011283
2022-01-17 12:08:53,947 iteration 2498 : loss : 0.027805, loss_ce: 0.010683
2022-01-17 12:08:54,821 iteration 2499 : loss : 0.026087, loss_ce: 0.006769
 37%|██████████▋                  | 147/400 [43:04<1:12:59, 17.31s/it]2022-01-17 12:08:55,786 iteration 2500 : loss : 0.032548, loss_ce: 0.012056
2022-01-17 12:08:56,714 iteration 2501 : loss : 0.026159, loss_ce: 0.008270
2022-01-17 12:08:57,739 iteration 2502 : loss : 0.037022, loss_ce: 0.013229
2022-01-17 12:08:58,625 iteration 2503 : loss : 0.024500, loss_ce: 0.009376
2022-01-17 12:08:59,537 iteration 2504 : loss : 0.028154, loss_ce: 0.010805
2022-01-17 12:09:00,529 iteration 2505 : loss : 0.036927, loss_ce: 0.017153
2022-01-17 12:09:01,510 iteration 2506 : loss : 0.036189, loss_ce: 0.010381
2022-01-17 12:09:02,400 iteration 2507 : loss : 0.027250, loss_ce: 0.012545
2022-01-17 12:09:03,320 iteration 2508 : loss : 0.040929, loss_ce: 0.013345
2022-01-17 12:09:04,251 iteration 2509 : loss : 0.025458, loss_ce: 0.008558
2022-01-17 12:09:05,164 iteration 2510 : loss : 0.026634, loss_ce: 0.011683
2022-01-17 12:09:06,125 iteration 2511 : loss : 0.034377, loss_ce: 0.014668
2022-01-17 12:09:07,099 iteration 2512 : loss : 0.030323, loss_ce: 0.011269
2022-01-17 12:09:08,111 iteration 2513 : loss : 0.028074, loss_ce: 0.008881
2022-01-17 12:09:09,070 iteration 2514 : loss : 0.030151, loss_ce: 0.008163
2022-01-17 12:09:10,011 iteration 2515 : loss : 0.021091, loss_ce: 0.010177
2022-01-17 12:09:10,941 iteration 2516 : loss : 0.026266, loss_ce: 0.011175
 37%|██████████▋                  | 148/400 [43:20<1:11:12, 16.95s/it]2022-01-17 12:09:11,895 iteration 2517 : loss : 0.026260, loss_ce: 0.010300
2022-01-17 12:09:12,839 iteration 2518 : loss : 0.032138, loss_ce: 0.008303
2022-01-17 12:09:13,811 iteration 2519 : loss : 0.027423, loss_ce: 0.008087
2022-01-17 12:09:14,750 iteration 2520 : loss : 0.030331, loss_ce: 0.011351
2022-01-17 12:09:15,677 iteration 2521 : loss : 0.029049, loss_ce: 0.009608
2022-01-17 12:09:16,631 iteration 2522 : loss : 0.035736, loss_ce: 0.017221
2022-01-17 12:09:17,628 iteration 2523 : loss : 0.030191, loss_ce: 0.008250
2022-01-17 12:09:18,556 iteration 2524 : loss : 0.029155, loss_ce: 0.011211
2022-01-17 12:09:19,513 iteration 2525 : loss : 0.022764, loss_ce: 0.008987
2022-01-17 12:09:20,488 iteration 2526 : loss : 0.048390, loss_ce: 0.015798
2022-01-17 12:09:21,449 iteration 2527 : loss : 0.021456, loss_ce: 0.007846
2022-01-17 12:09:22,429 iteration 2528 : loss : 0.028669, loss_ce: 0.009249
2022-01-17 12:09:23,388 iteration 2529 : loss : 0.037543, loss_ce: 0.013839
2022-01-17 12:09:24,352 iteration 2530 : loss : 0.026392, loss_ce: 0.012148
2022-01-17 12:09:25,387 iteration 2531 : loss : 0.027419, loss_ce: 0.010389
2022-01-17 12:09:26,326 iteration 2532 : loss : 0.062638, loss_ce: 0.025125
2022-01-17 12:09:27,283 iteration 2533 : loss : 0.031615, loss_ce: 0.008571
 37%|██████████▊                  | 149/400 [43:37<1:10:08, 16.77s/it]2022-01-17 12:09:28,190 iteration 2534 : loss : 0.023741, loss_ce: 0.009088
2022-01-17 12:09:29,216 iteration 2535 : loss : 0.041859, loss_ce: 0.013639
2022-01-17 12:09:30,125 iteration 2536 : loss : 0.025542, loss_ce: 0.011605
2022-01-17 12:09:31,046 iteration 2537 : loss : 0.026440, loss_ce: 0.009935
2022-01-17 12:09:31,889 iteration 2538 : loss : 0.019234, loss_ce: 0.007806
2022-01-17 12:09:32,863 iteration 2539 : loss : 0.025838, loss_ce: 0.009185
2022-01-17 12:09:33,764 iteration 2540 : loss : 0.021241, loss_ce: 0.006326
2022-01-17 12:09:34,687 iteration 2541 : loss : 0.025625, loss_ce: 0.009736
2022-01-17 12:09:35,565 iteration 2542 : loss : 0.019348, loss_ce: 0.006883
2022-01-17 12:09:36,448 iteration 2543 : loss : 0.022966, loss_ce: 0.007703
2022-01-17 12:09:37,396 iteration 2544 : loss : 0.035881, loss_ce: 0.014006
2022-01-17 12:09:38,459 iteration 2545 : loss : 0.025869, loss_ce: 0.009928
2022-01-17 12:09:39,533 iteration 2546 : loss : 0.042906, loss_ce: 0.019575
2022-01-17 12:09:40,412 iteration 2547 : loss : 0.018690, loss_ce: 0.009030
2022-01-17 12:09:41,383 iteration 2548 : loss : 0.027248, loss_ce: 0.013567
2022-01-17 12:09:42,343 iteration 2549 : loss : 0.035372, loss_ce: 0.011464
2022-01-17 12:09:42,343 Training Data Eval:
2022-01-17 12:09:46,798   Average segmentation loss on training set: 0.0193
2022-01-17 12:09:46,799 Validation Data Eval:
2022-01-17 12:09:48,301   Average segmentation loss on validation set: 0.0855
2022-01-17 12:09:49,215 iteration 2550 : loss : 0.028114, loss_ce: 0.008955
 38%|██████████▉                  | 150/400 [43:59<1:16:20, 18.32s/it]2022-01-17 12:09:50,181 iteration 2551 : loss : 0.021550, loss_ce: 0.010383
2022-01-17 12:09:51,189 iteration 2552 : loss : 0.021450, loss_ce: 0.008261
2022-01-17 12:09:52,066 iteration 2553 : loss : 0.017974, loss_ce: 0.006098
2022-01-17 12:09:53,022 iteration 2554 : loss : 0.027365, loss_ce: 0.009925
2022-01-17 12:09:53,955 iteration 2555 : loss : 0.038569, loss_ce: 0.012699
2022-01-17 12:09:54,960 iteration 2556 : loss : 0.027282, loss_ce: 0.011399
2022-01-17 12:09:55,897 iteration 2557 : loss : 0.025697, loss_ce: 0.012425
2022-01-17 12:09:56,859 iteration 2558 : loss : 0.037931, loss_ce: 0.022440
2022-01-17 12:09:57,905 iteration 2559 : loss : 0.027637, loss_ce: 0.010530
2022-01-17 12:09:58,852 iteration 2560 : loss : 0.022998, loss_ce: 0.010937
2022-01-17 12:09:59,889 iteration 2561 : loss : 0.046312, loss_ce: 0.016601
2022-01-17 12:10:00,852 iteration 2562 : loss : 0.026594, loss_ce: 0.010044
2022-01-17 12:10:01,834 iteration 2563 : loss : 0.031435, loss_ce: 0.013408
2022-01-17 12:10:02,738 iteration 2564 : loss : 0.026830, loss_ce: 0.010497
2022-01-17 12:10:03,648 iteration 2565 : loss : 0.025600, loss_ce: 0.009306
2022-01-17 12:10:04,577 iteration 2566 : loss : 0.027660, loss_ce: 0.010825
2022-01-17 12:10:05,535 iteration 2567 : loss : 0.028836, loss_ce: 0.007423
 38%|██████████▉                  | 151/400 [44:15<1:13:31, 17.72s/it]2022-01-17 12:10:06,550 iteration 2568 : loss : 0.032026, loss_ce: 0.014383
2022-01-17 12:10:07,480 iteration 2569 : loss : 0.023578, loss_ce: 0.012347
2022-01-17 12:10:08,407 iteration 2570 : loss : 0.028749, loss_ce: 0.009722
2022-01-17 12:10:09,347 iteration 2571 : loss : 0.018339, loss_ce: 0.007095
2022-01-17 12:10:10,233 iteration 2572 : loss : 0.032734, loss_ce: 0.008902
2022-01-17 12:10:11,127 iteration 2573 : loss : 0.024491, loss_ce: 0.010336
2022-01-17 12:10:12,052 iteration 2574 : loss : 0.032422, loss_ce: 0.010701
2022-01-17 12:10:13,117 iteration 2575 : loss : 0.034680, loss_ce: 0.015426
2022-01-17 12:10:14,087 iteration 2576 : loss : 0.022756, loss_ce: 0.008046
2022-01-17 12:10:15,048 iteration 2577 : loss : 0.039920, loss_ce: 0.014708
2022-01-17 12:10:16,009 iteration 2578 : loss : 0.041392, loss_ce: 0.012363
2022-01-17 12:10:16,890 iteration 2579 : loss : 0.031670, loss_ce: 0.008752
2022-01-17 12:10:17,891 iteration 2580 : loss : 0.029473, loss_ce: 0.007682
2022-01-17 12:10:18,878 iteration 2581 : loss : 0.027466, loss_ce: 0.010574
2022-01-17 12:10:19,902 iteration 2582 : loss : 0.025705, loss_ce: 0.009024
2022-01-17 12:10:20,833 iteration 2583 : loss : 0.019442, loss_ce: 0.007345
2022-01-17 12:10:21,688 iteration 2584 : loss : 0.021266, loss_ce: 0.008509
 38%|███████████                  | 152/400 [44:31<1:11:18, 17.25s/it]2022-01-17 12:10:22,675 iteration 2585 : loss : 0.018710, loss_ce: 0.005589
2022-01-17 12:10:23,635 iteration 2586 : loss : 0.027492, loss_ce: 0.011868
2022-01-17 12:10:24,520 iteration 2587 : loss : 0.025084, loss_ce: 0.009276
2022-01-17 12:10:25,444 iteration 2588 : loss : 0.025008, loss_ce: 0.011213
2022-01-17 12:10:26,430 iteration 2589 : loss : 0.027184, loss_ce: 0.008576
2022-01-17 12:10:27,427 iteration 2590 : loss : 0.029658, loss_ce: 0.013453
2022-01-17 12:10:28,340 iteration 2591 : loss : 0.020107, loss_ce: 0.006535
2022-01-17 12:10:29,254 iteration 2592 : loss : 0.027962, loss_ce: 0.009255
2022-01-17 12:10:30,176 iteration 2593 : loss : 0.021065, loss_ce: 0.009011
2022-01-17 12:10:31,259 iteration 2594 : loss : 0.042670, loss_ce: 0.017343
2022-01-17 12:10:32,244 iteration 2595 : loss : 0.025780, loss_ce: 0.009165
2022-01-17 12:10:33,148 iteration 2596 : loss : 0.021459, loss_ce: 0.009229
2022-01-17 12:10:34,038 iteration 2597 : loss : 0.026197, loss_ce: 0.009460
2022-01-17 12:10:34,962 iteration 2598 : loss : 0.025788, loss_ce: 0.010142
2022-01-17 12:10:35,896 iteration 2599 : loss : 0.023949, loss_ce: 0.004740
2022-01-17 12:10:36,833 iteration 2600 : loss : 0.029578, loss_ce: 0.010208
2022-01-17 12:10:37,724 iteration 2601 : loss : 0.023112, loss_ce: 0.009164
 38%|███████████                  | 153/400 [44:47<1:09:30, 16.89s/it]2022-01-17 12:10:38,738 iteration 2602 : loss : 0.023217, loss_ce: 0.009231
2022-01-17 12:10:39,612 iteration 2603 : loss : 0.020395, loss_ce: 0.007449
2022-01-17 12:10:40,537 iteration 2604 : loss : 0.016595, loss_ce: 0.005491
2022-01-17 12:10:41,610 iteration 2605 : loss : 0.023045, loss_ce: 0.006748
2022-01-17 12:10:42,547 iteration 2606 : loss : 0.023968, loss_ce: 0.009792
2022-01-17 12:10:43,498 iteration 2607 : loss : 0.034533, loss_ce: 0.011591
2022-01-17 12:10:44,389 iteration 2608 : loss : 0.023745, loss_ce: 0.010190
2022-01-17 12:10:45,294 iteration 2609 : loss : 0.027954, loss_ce: 0.008080
2022-01-17 12:10:46,364 iteration 2610 : loss : 0.033653, loss_ce: 0.014127
2022-01-17 12:10:47,277 iteration 2611 : loss : 0.025951, loss_ce: 0.008897
2022-01-17 12:10:48,123 iteration 2612 : loss : 0.025723, loss_ce: 0.011714
2022-01-17 12:10:49,038 iteration 2613 : loss : 0.033374, loss_ce: 0.010545
2022-01-17 12:10:50,039 iteration 2614 : loss : 0.068921, loss_ce: 0.028854
2022-01-17 12:10:50,949 iteration 2615 : loss : 0.026653, loss_ce: 0.010846
2022-01-17 12:10:51,862 iteration 2616 : loss : 0.023168, loss_ce: 0.008313
2022-01-17 12:10:52,890 iteration 2617 : loss : 0.024740, loss_ce: 0.006141
2022-01-17 12:10:53,854 iteration 2618 : loss : 0.045092, loss_ce: 0.020472
 38%|███████████▏                 | 154/400 [45:03<1:08:17, 16.66s/it]2022-01-17 12:10:54,900 iteration 2619 : loss : 0.028786, loss_ce: 0.007293
2022-01-17 12:10:55,813 iteration 2620 : loss : 0.031551, loss_ce: 0.010815
2022-01-17 12:10:56,777 iteration 2621 : loss : 0.023261, loss_ce: 0.007236
2022-01-17 12:10:57,745 iteration 2622 : loss : 0.030258, loss_ce: 0.014310
2022-01-17 12:10:58,727 iteration 2623 : loss : 0.032973, loss_ce: 0.014047
2022-01-17 12:10:59,636 iteration 2624 : loss : 0.025400, loss_ce: 0.007919
2022-01-17 12:11:00,561 iteration 2625 : loss : 0.022124, loss_ce: 0.008852
2022-01-17 12:11:01,577 iteration 2626 : loss : 0.033575, loss_ce: 0.015608
2022-01-17 12:11:02,554 iteration 2627 : loss : 0.037320, loss_ce: 0.008209
2022-01-17 12:11:03,459 iteration 2628 : loss : 0.022027, loss_ce: 0.007752
2022-01-17 12:11:04,474 iteration 2629 : loss : 0.026149, loss_ce: 0.008266
2022-01-17 12:11:05,363 iteration 2630 : loss : 0.019563, loss_ce: 0.005955
2022-01-17 12:11:06,329 iteration 2631 : loss : 0.028213, loss_ce: 0.012168
2022-01-17 12:11:07,312 iteration 2632 : loss : 0.026498, loss_ce: 0.010733
2022-01-17 12:11:08,225 iteration 2633 : loss : 0.024697, loss_ce: 0.010800
2022-01-17 12:11:09,195 iteration 2634 : loss : 0.022317, loss_ce: 0.007442
2022-01-17 12:11:09,196 Training Data Eval:
2022-01-17 12:11:13,667   Average segmentation loss on training set: 0.0181
2022-01-17 12:11:13,668 Validation Data Eval:
2022-01-17 12:11:15,177   Average segmentation loss on validation set: 0.0805
2022-01-17 12:11:16,201 iteration 2635 : loss : 0.033726, loss_ce: 0.012333
 39%|███████████▏                 | 155/400 [45:26<1:14:59, 18.36s/it]2022-01-17 12:11:17,154 iteration 2636 : loss : 0.021909, loss_ce: 0.006424
2022-01-17 12:11:18,238 iteration 2637 : loss : 0.049770, loss_ce: 0.015606
2022-01-17 12:11:19,199 iteration 2638 : loss : 0.024825, loss_ce: 0.009067
2022-01-17 12:11:20,029 iteration 2639 : loss : 0.018498, loss_ce: 0.006550
2022-01-17 12:11:20,923 iteration 2640 : loss : 0.024829, loss_ce: 0.009997
2022-01-17 12:11:21,960 iteration 2641 : loss : 0.035879, loss_ce: 0.014201
2022-01-17 12:11:22,964 iteration 2642 : loss : 0.031311, loss_ce: 0.010361
2022-01-17 12:11:23,956 iteration 2643 : loss : 0.028606, loss_ce: 0.009799
2022-01-17 12:11:24,869 iteration 2644 : loss : 0.030989, loss_ce: 0.008041
2022-01-17 12:11:25,779 iteration 2645 : loss : 0.024054, loss_ce: 0.011379
2022-01-17 12:11:26,699 iteration 2646 : loss : 0.031796, loss_ce: 0.008865
2022-01-17 12:11:27,693 iteration 2647 : loss : 0.027485, loss_ce: 0.012703
2022-01-17 12:11:28,554 iteration 2648 : loss : 0.017236, loss_ce: 0.007911
2022-01-17 12:11:29,534 iteration 2649 : loss : 0.023563, loss_ce: 0.010494
2022-01-17 12:11:30,517 iteration 2650 : loss : 0.023224, loss_ce: 0.010157
2022-01-17 12:11:31,436 iteration 2651 : loss : 0.028242, loss_ce: 0.011158
2022-01-17 12:11:32,384 iteration 2652 : loss : 0.024723, loss_ce: 0.010224
 39%|███████████▎                 | 156/400 [45:42<1:12:01, 17.71s/it]2022-01-17 12:11:33,472 iteration 2653 : loss : 0.030716, loss_ce: 0.010903
2022-01-17 12:11:34,412 iteration 2654 : loss : 0.022407, loss_ce: 0.008536
2022-01-17 12:11:35,297 iteration 2655 : loss : 0.018615, loss_ce: 0.006365
2022-01-17 12:11:36,167 iteration 2656 : loss : 0.020314, loss_ce: 0.009655
2022-01-17 12:11:37,057 iteration 2657 : loss : 0.024777, loss_ce: 0.009822
2022-01-17 12:11:37,965 iteration 2658 : loss : 0.021511, loss_ce: 0.008863
2022-01-17 12:11:39,031 iteration 2659 : loss : 0.031857, loss_ce: 0.016192
2022-01-17 12:11:39,969 iteration 2660 : loss : 0.027652, loss_ce: 0.009255
2022-01-17 12:11:40,828 iteration 2661 : loss : 0.022868, loss_ce: 0.008193
2022-01-17 12:11:41,818 iteration 2662 : loss : 0.027869, loss_ce: 0.011989
2022-01-17 12:11:42,711 iteration 2663 : loss : 0.025229, loss_ce: 0.010668
2022-01-17 12:11:43,715 iteration 2664 : loss : 0.022791, loss_ce: 0.007503
2022-01-17 12:11:44,639 iteration 2665 : loss : 0.022768, loss_ce: 0.008548
2022-01-17 12:11:45,592 iteration 2666 : loss : 0.035486, loss_ce: 0.010640
2022-01-17 12:11:46,575 iteration 2667 : loss : 0.022229, loss_ce: 0.007985
2022-01-17 12:11:47,542 iteration 2668 : loss : 0.027533, loss_ce: 0.009178
2022-01-17 12:11:48,532 iteration 2669 : loss : 0.022332, loss_ce: 0.008437
 39%|███████████▍                 | 157/400 [45:58<1:09:50, 17.24s/it]2022-01-17 12:11:49,540 iteration 2670 : loss : 0.046576, loss_ce: 0.012428
2022-01-17 12:11:50,503 iteration 2671 : loss : 0.035121, loss_ce: 0.011431
2022-01-17 12:11:51,474 iteration 2672 : loss : 0.021005, loss_ce: 0.007731
2022-01-17 12:11:52,476 iteration 2673 : loss : 0.040417, loss_ce: 0.014088
2022-01-17 12:11:53,386 iteration 2674 : loss : 0.031124, loss_ce: 0.016595
2022-01-17 12:11:54,391 iteration 2675 : loss : 0.030745, loss_ce: 0.012848
2022-01-17 12:11:55,353 iteration 2676 : loss : 0.028658, loss_ce: 0.007705
2022-01-17 12:11:56,236 iteration 2677 : loss : 0.020013, loss_ce: 0.008497
2022-01-17 12:11:57,104 iteration 2678 : loss : 0.022880, loss_ce: 0.007540
2022-01-17 12:11:58,079 iteration 2679 : loss : 0.024140, loss_ce: 0.010317
2022-01-17 12:11:59,089 iteration 2680 : loss : 0.031887, loss_ce: 0.012157
2022-01-17 12:12:00,020 iteration 2681 : loss : 0.021809, loss_ce: 0.009920
2022-01-17 12:12:00,904 iteration 2682 : loss : 0.021102, loss_ce: 0.008015
2022-01-17 12:12:01,865 iteration 2683 : loss : 0.023675, loss_ce: 0.011563
2022-01-17 12:12:02,812 iteration 2684 : loss : 0.022972, loss_ce: 0.005978
2022-01-17 12:12:03,763 iteration 2685 : loss : 0.027005, loss_ce: 0.012391
2022-01-17 12:12:04,698 iteration 2686 : loss : 0.021807, loss_ce: 0.007788
 40%|███████████▍                 | 158/400 [46:14<1:08:14, 16.92s/it]2022-01-17 12:12:05,654 iteration 2687 : loss : 0.017047, loss_ce: 0.007142
2022-01-17 12:12:06,575 iteration 2688 : loss : 0.033461, loss_ce: 0.012580
2022-01-17 12:12:07,408 iteration 2689 : loss : 0.019832, loss_ce: 0.006939
2022-01-17 12:12:08,333 iteration 2690 : loss : 0.028877, loss_ce: 0.012318
2022-01-17 12:12:09,292 iteration 2691 : loss : 0.019077, loss_ce: 0.006033
2022-01-17 12:12:10,228 iteration 2692 : loss : 0.023489, loss_ce: 0.007520
2022-01-17 12:12:11,132 iteration 2693 : loss : 0.026584, loss_ce: 0.009013
2022-01-17 12:12:11,983 iteration 2694 : loss : 0.025729, loss_ce: 0.008472
2022-01-17 12:12:12,971 iteration 2695 : loss : 0.036420, loss_ce: 0.013811
2022-01-17 12:12:14,019 iteration 2696 : loss : 0.049391, loss_ce: 0.015346
2022-01-17 12:12:15,017 iteration 2697 : loss : 0.036555, loss_ce: 0.018007
2022-01-17 12:12:15,891 iteration 2698 : loss : 0.018016, loss_ce: 0.006993
2022-01-17 12:12:16,787 iteration 2699 : loss : 0.021491, loss_ce: 0.007244
2022-01-17 12:12:17,691 iteration 2700 : loss : 0.032583, loss_ce: 0.010329
2022-01-17 12:12:18,638 iteration 2701 : loss : 0.031730, loss_ce: 0.014048
2022-01-17 12:12:19,623 iteration 2702 : loss : 0.042648, loss_ce: 0.007814
2022-01-17 12:12:20,613 iteration 2703 : loss : 0.031959, loss_ce: 0.010588
 40%|███████████▌                 | 159/400 [46:30<1:06:44, 16.62s/it]2022-01-17 12:12:21,550 iteration 2704 : loss : 0.022461, loss_ce: 0.006456
2022-01-17 12:12:22,442 iteration 2705 : loss : 0.026576, loss_ce: 0.007380
2022-01-17 12:12:23,419 iteration 2706 : loss : 0.035954, loss_ce: 0.015830
2022-01-17 12:12:24,359 iteration 2707 : loss : 0.022019, loss_ce: 0.007767
2022-01-17 12:12:25,286 iteration 2708 : loss : 0.037039, loss_ce: 0.011089
2022-01-17 12:12:26,297 iteration 2709 : loss : 0.037713, loss_ce: 0.010651
2022-01-17 12:12:27,283 iteration 2710 : loss : 0.033412, loss_ce: 0.014912
2022-01-17 12:12:28,198 iteration 2711 : loss : 0.023545, loss_ce: 0.007867
2022-01-17 12:12:29,131 iteration 2712 : loss : 0.028203, loss_ce: 0.010231
2022-01-17 12:12:30,087 iteration 2713 : loss : 0.022604, loss_ce: 0.008136
2022-01-17 12:12:31,041 iteration 2714 : loss : 0.026821, loss_ce: 0.011681
2022-01-17 12:12:31,972 iteration 2715 : loss : 0.031406, loss_ce: 0.019824
2022-01-17 12:12:32,905 iteration 2716 : loss : 0.033532, loss_ce: 0.008597
2022-01-17 12:12:33,787 iteration 2717 : loss : 0.025096, loss_ce: 0.009198
2022-01-17 12:12:34,763 iteration 2718 : loss : 0.025532, loss_ce: 0.009265
2022-01-17 12:12:35,675 iteration 2719 : loss : 0.022359, loss_ce: 0.009976
2022-01-17 12:12:35,676 Training Data Eval:
2022-01-17 12:12:40,142   Average segmentation loss on training set: 0.0197
2022-01-17 12:12:40,142 Validation Data Eval:
2022-01-17 12:12:41,649   Average segmentation loss on validation set: 0.0718
2022-01-17 12:12:45,308 Found new lowest validation loss at iteration 2719! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 12:12:46,185 iteration 2720 : loss : 0.029647, loss_ce: 0.012444
 40%|███████████▌                 | 160/400 [46:56<1:17:12, 19.30s/it]2022-01-17 12:12:47,122 iteration 2721 : loss : 0.023997, loss_ce: 0.008371
2022-01-17 12:12:48,039 iteration 2722 : loss : 0.021424, loss_ce: 0.008954
2022-01-17 12:12:49,011 iteration 2723 : loss : 0.028256, loss_ce: 0.012186
2022-01-17 12:12:49,839 iteration 2724 : loss : 0.028414, loss_ce: 0.008667
2022-01-17 12:12:50,700 iteration 2725 : loss : 0.032924, loss_ce: 0.009595
2022-01-17 12:12:51,667 iteration 2726 : loss : 0.043116, loss_ce: 0.013923
2022-01-17 12:12:52,551 iteration 2727 : loss : 0.027449, loss_ce: 0.009466
2022-01-17 12:12:53,487 iteration 2728 : loss : 0.025062, loss_ce: 0.010225
2022-01-17 12:12:54,437 iteration 2729 : loss : 0.034519, loss_ce: 0.014928
2022-01-17 12:12:55,450 iteration 2730 : loss : 0.034990, loss_ce: 0.012793
2022-01-17 12:12:56,385 iteration 2731 : loss : 0.025697, loss_ce: 0.009365
2022-01-17 12:12:57,242 iteration 2732 : loss : 0.022886, loss_ce: 0.008804
2022-01-17 12:12:58,188 iteration 2733 : loss : 0.024435, loss_ce: 0.010648
2022-01-17 12:12:59,156 iteration 2734 : loss : 0.039318, loss_ce: 0.012001
2022-01-17 12:13:00,121 iteration 2735 : loss : 0.026564, loss_ce: 0.012718
2022-01-17 12:13:01,057 iteration 2736 : loss : 0.029298, loss_ce: 0.008994
2022-01-17 12:13:02,003 iteration 2737 : loss : 0.033547, loss_ce: 0.008176
 40%|███████████▋                 | 161/400 [47:11<1:12:43, 18.26s/it]2022-01-17 12:13:03,051 iteration 2738 : loss : 0.033002, loss_ce: 0.014935
2022-01-17 12:13:03,950 iteration 2739 : loss : 0.021615, loss_ce: 0.006330
2022-01-17 12:13:04,996 iteration 2740 : loss : 0.032945, loss_ce: 0.014592
2022-01-17 12:13:05,948 iteration 2741 : loss : 0.036425, loss_ce: 0.015868
2022-01-17 12:13:06,919 iteration 2742 : loss : 0.033420, loss_ce: 0.013534
2022-01-17 12:13:07,810 iteration 2743 : loss : 0.029576, loss_ce: 0.010221
2022-01-17 12:13:08,758 iteration 2744 : loss : 0.020823, loss_ce: 0.006859
2022-01-17 12:13:09,660 iteration 2745 : loss : 0.019625, loss_ce: 0.005689
2022-01-17 12:13:10,712 iteration 2746 : loss : 0.069199, loss_ce: 0.016931
2022-01-17 12:13:11,629 iteration 2747 : loss : 0.030660, loss_ce: 0.013668
2022-01-17 12:13:12,623 iteration 2748 : loss : 0.029740, loss_ce: 0.007652
2022-01-17 12:13:13,643 iteration 2749 : loss : 0.031950, loss_ce: 0.011020
2022-01-17 12:13:14,567 iteration 2750 : loss : 0.038254, loss_ce: 0.015291
2022-01-17 12:13:15,509 iteration 2751 : loss : 0.032868, loss_ce: 0.010296
2022-01-17 12:13:16,553 iteration 2752 : loss : 0.034991, loss_ce: 0.018061
2022-01-17 12:13:17,602 iteration 2753 : loss : 0.039296, loss_ce: 0.018685
2022-01-17 12:13:18,566 iteration 2754 : loss : 0.023788, loss_ce: 0.012586
 40%|███████████▋                 | 162/400 [47:28<1:10:23, 17.75s/it]2022-01-17 12:13:19,412 iteration 2755 : loss : 0.024952, loss_ce: 0.008027
2022-01-17 12:13:20,365 iteration 2756 : loss : 0.034046, loss_ce: 0.013935
2022-01-17 12:13:21,305 iteration 2757 : loss : 0.025751, loss_ce: 0.010724
2022-01-17 12:13:22,246 iteration 2758 : loss : 0.029934, loss_ce: 0.013826
2022-01-17 12:13:23,185 iteration 2759 : loss : 0.033998, loss_ce: 0.014237
2022-01-17 12:13:24,126 iteration 2760 : loss : 0.027694, loss_ce: 0.011789
2022-01-17 12:13:25,111 iteration 2761 : loss : 0.029865, loss_ce: 0.010064
2022-01-17 12:13:26,046 iteration 2762 : loss : 0.024115, loss_ce: 0.010746
2022-01-17 12:13:27,022 iteration 2763 : loss : 0.040553, loss_ce: 0.011640
2022-01-17 12:13:27,905 iteration 2764 : loss : 0.020323, loss_ce: 0.007025
2022-01-17 12:13:28,955 iteration 2765 : loss : 0.023471, loss_ce: 0.007534
2022-01-17 12:13:29,819 iteration 2766 : loss : 0.022148, loss_ce: 0.007417
2022-01-17 12:13:30,780 iteration 2767 : loss : 0.028218, loss_ce: 0.011197
2022-01-17 12:13:31,702 iteration 2768 : loss : 0.035312, loss_ce: 0.012022
2022-01-17 12:13:32,576 iteration 2769 : loss : 0.019754, loss_ce: 0.008564
2022-01-17 12:13:33,486 iteration 2770 : loss : 0.021200, loss_ce: 0.009929
2022-01-17 12:13:34,424 iteration 2771 : loss : 0.022382, loss_ce: 0.009345
 41%|███████████▊                 | 163/400 [47:44<1:07:52, 17.18s/it]2022-01-17 12:13:35,338 iteration 2772 : loss : 0.027962, loss_ce: 0.009116
2022-01-17 12:13:36,293 iteration 2773 : loss : 0.027049, loss_ce: 0.011105
2022-01-17 12:13:37,249 iteration 2774 : loss : 0.026158, loss_ce: 0.006131
2022-01-17 12:13:38,212 iteration 2775 : loss : 0.037369, loss_ce: 0.014496
2022-01-17 12:13:39,140 iteration 2776 : loss : 0.021708, loss_ce: 0.008017
2022-01-17 12:13:40,149 iteration 2777 : loss : 0.022765, loss_ce: 0.007501
2022-01-17 12:13:41,051 iteration 2778 : loss : 0.023096, loss_ce: 0.006874
2022-01-17 12:13:41,958 iteration 2779 : loss : 0.026429, loss_ce: 0.009842
2022-01-17 12:13:42,888 iteration 2780 : loss : 0.033357, loss_ce: 0.015362
2022-01-17 12:13:43,949 iteration 2781 : loss : 0.025131, loss_ce: 0.009687
2022-01-17 12:13:44,965 iteration 2782 : loss : 0.019612, loss_ce: 0.008989
2022-01-17 12:13:45,885 iteration 2783 : loss : 0.029619, loss_ce: 0.008640
2022-01-17 12:13:46,715 iteration 2784 : loss : 0.021273, loss_ce: 0.005457
2022-01-17 12:13:47,605 iteration 2785 : loss : 0.020703, loss_ce: 0.008700
2022-01-17 12:13:48,481 iteration 2786 : loss : 0.024396, loss_ce: 0.009461
2022-01-17 12:13:49,376 iteration 2787 : loss : 0.020706, loss_ce: 0.008088
2022-01-17 12:13:50,459 iteration 2788 : loss : 0.033992, loss_ce: 0.014140
 41%|███████████▉                 | 164/400 [48:00<1:06:13, 16.84s/it]2022-01-17 12:13:51,462 iteration 2789 : loss : 0.021525, loss_ce: 0.007045
2022-01-17 12:13:52,492 iteration 2790 : loss : 0.034767, loss_ce: 0.014107
2022-01-17 12:13:53,373 iteration 2791 : loss : 0.019815, loss_ce: 0.005338
2022-01-17 12:13:54,306 iteration 2792 : loss : 0.024981, loss_ce: 0.011261
2022-01-17 12:13:55,251 iteration 2793 : loss : 0.024244, loss_ce: 0.007706
2022-01-17 12:13:56,259 iteration 2794 : loss : 0.034076, loss_ce: 0.018137
2022-01-17 12:13:57,200 iteration 2795 : loss : 0.028140, loss_ce: 0.011160
2022-01-17 12:13:58,116 iteration 2796 : loss : 0.025457, loss_ce: 0.008448
2022-01-17 12:13:59,108 iteration 2797 : loss : 0.030713, loss_ce: 0.014194
2022-01-17 12:14:00,064 iteration 2798 : loss : 0.032081, loss_ce: 0.008838
2022-01-17 12:14:01,096 iteration 2799 : loss : 0.038206, loss_ce: 0.013801
2022-01-17 12:14:02,048 iteration 2800 : loss : 0.027946, loss_ce: 0.013600
2022-01-17 12:14:02,900 iteration 2801 : loss : 0.019970, loss_ce: 0.005872
2022-01-17 12:14:03,799 iteration 2802 : loss : 0.018116, loss_ce: 0.005975
2022-01-17 12:14:04,757 iteration 2803 : loss : 0.028070, loss_ce: 0.010739
2022-01-17 12:14:05,608 iteration 2804 : loss : 0.027377, loss_ce: 0.011394
2022-01-17 12:14:05,608 Training Data Eval:
2022-01-17 12:14:10,071   Average segmentation loss on training set: 0.0170
2022-01-17 12:14:10,072 Validation Data Eval:
2022-01-17 12:14:11,567   Average segmentation loss on validation set: 0.0780
2022-01-17 12:14:12,609 iteration 2805 : loss : 0.023617, loss_ce: 0.009299
 41%|███████████▉                 | 165/400 [48:22<1:12:11, 18.43s/it]2022-01-17 12:14:13,674 iteration 2806 : loss : 0.024017, loss_ce: 0.009548
2022-01-17 12:14:14,704 iteration 2807 : loss : 0.031307, loss_ce: 0.008280
2022-01-17 12:14:15,700 iteration 2808 : loss : 0.026616, loss_ce: 0.008229
2022-01-17 12:14:16,662 iteration 2809 : loss : 0.025303, loss_ce: 0.009208
2022-01-17 12:14:17,534 iteration 2810 : loss : 0.028726, loss_ce: 0.010012
2022-01-17 12:14:18,530 iteration 2811 : loss : 0.023913, loss_ce: 0.011071
2022-01-17 12:14:19,408 iteration 2812 : loss : 0.016892, loss_ce: 0.006542
2022-01-17 12:14:20,427 iteration 2813 : loss : 0.044050, loss_ce: 0.021887
2022-01-17 12:14:21,392 iteration 2814 : loss : 0.023456, loss_ce: 0.007846
2022-01-17 12:14:22,337 iteration 2815 : loss : 0.021896, loss_ce: 0.009961
2022-01-17 12:14:23,281 iteration 2816 : loss : 0.024614, loss_ce: 0.008082
2022-01-17 12:14:24,311 iteration 2817 : loss : 0.037476, loss_ce: 0.006385
2022-01-17 12:14:25,311 iteration 2818 : loss : 0.039658, loss_ce: 0.017871
2022-01-17 12:14:26,227 iteration 2819 : loss : 0.025597, loss_ce: 0.010623
2022-01-17 12:14:27,274 iteration 2820 : loss : 0.044321, loss_ce: 0.012258
2022-01-17 12:14:28,286 iteration 2821 : loss : 0.035585, loss_ce: 0.012360
2022-01-17 12:14:29,271 iteration 2822 : loss : 0.028486, loss_ce: 0.009633
 42%|████████████                 | 166/400 [48:39<1:09:48, 17.90s/it]2022-01-17 12:14:30,366 iteration 2823 : loss : 0.026045, loss_ce: 0.010513
2022-01-17 12:14:31,280 iteration 2824 : loss : 0.027914, loss_ce: 0.012982
2022-01-17 12:14:32,235 iteration 2825 : loss : 0.032395, loss_ce: 0.012648
2022-01-17 12:14:33,286 iteration 2826 : loss : 0.040470, loss_ce: 0.016587
2022-01-17 12:14:34,358 iteration 2827 : loss : 0.040518, loss_ce: 0.012647
2022-01-17 12:14:35,329 iteration 2828 : loss : 0.033090, loss_ce: 0.011338
2022-01-17 12:14:36,266 iteration 2829 : loss : 0.030788, loss_ce: 0.015803
2022-01-17 12:14:37,198 iteration 2830 : loss : 0.038916, loss_ce: 0.012134
2022-01-17 12:14:38,048 iteration 2831 : loss : 0.036075, loss_ce: 0.014616
2022-01-17 12:14:39,130 iteration 2832 : loss : 0.033726, loss_ce: 0.015755
2022-01-17 12:14:40,069 iteration 2833 : loss : 0.030716, loss_ce: 0.010137
2022-01-17 12:14:41,084 iteration 2834 : loss : 0.039316, loss_ce: 0.012765
2022-01-17 12:14:42,062 iteration 2835 : loss : 0.032708, loss_ce: 0.009295
2022-01-17 12:14:43,008 iteration 2836 : loss : 0.028256, loss_ce: 0.009634
2022-01-17 12:14:44,026 iteration 2837 : loss : 0.028138, loss_ce: 0.010947
2022-01-17 12:14:44,912 iteration 2838 : loss : 0.020463, loss_ce: 0.007955
2022-01-17 12:14:45,895 iteration 2839 : loss : 0.024013, loss_ce: 0.007869
 42%|████████████                 | 167/400 [48:55<1:08:01, 17.52s/it]2022-01-17 12:14:46,950 iteration 2840 : loss : 0.028828, loss_ce: 0.010244
2022-01-17 12:14:47,891 iteration 2841 : loss : 0.024907, loss_ce: 0.006927
2022-01-17 12:14:48,830 iteration 2842 : loss : 0.022645, loss_ce: 0.008556
2022-01-17 12:14:49,825 iteration 2843 : loss : 0.055770, loss_ce: 0.014013
2022-01-17 12:14:50,791 iteration 2844 : loss : 0.029945, loss_ce: 0.012737
2022-01-17 12:14:51,742 iteration 2845 : loss : 0.020877, loss_ce: 0.007362
2022-01-17 12:14:52,697 iteration 2846 : loss : 0.019687, loss_ce: 0.006962
2022-01-17 12:14:53,518 iteration 2847 : loss : 0.018149, loss_ce: 0.008954
2022-01-17 12:14:54,483 iteration 2848 : loss : 0.035290, loss_ce: 0.012581
2022-01-17 12:14:55,497 iteration 2849 : loss : 0.027151, loss_ce: 0.009049
2022-01-17 12:14:56,493 iteration 2850 : loss : 0.029269, loss_ce: 0.010111
2022-01-17 12:14:57,501 iteration 2851 : loss : 0.024143, loss_ce: 0.008592
2022-01-17 12:14:58,462 iteration 2852 : loss : 0.056744, loss_ce: 0.013345
2022-01-17 12:14:59,468 iteration 2853 : loss : 0.018301, loss_ce: 0.006006
2022-01-17 12:15:00,439 iteration 2854 : loss : 0.029992, loss_ce: 0.012856
2022-01-17 12:15:01,343 iteration 2855 : loss : 0.030643, loss_ce: 0.014165
2022-01-17 12:15:02,328 iteration 2856 : loss : 0.041483, loss_ce: 0.021000
 42%|████████████▏                | 168/400 [49:12<1:06:28, 17.19s/it]2022-01-17 12:15:03,231 iteration 2857 : loss : 0.025620, loss_ce: 0.008673
2022-01-17 12:15:04,192 iteration 2858 : loss : 0.031030, loss_ce: 0.014398
2022-01-17 12:15:05,110 iteration 2859 : loss : 0.020778, loss_ce: 0.009103
2022-01-17 12:15:06,103 iteration 2860 : loss : 0.033455, loss_ce: 0.011729
2022-01-17 12:15:06,966 iteration 2861 : loss : 0.027898, loss_ce: 0.012580
2022-01-17 12:15:07,997 iteration 2862 : loss : 0.051051, loss_ce: 0.016536
2022-01-17 12:15:08,902 iteration 2863 : loss : 0.033673, loss_ce: 0.009836
2022-01-17 12:15:09,881 iteration 2864 : loss : 0.024948, loss_ce: 0.009871
2022-01-17 12:15:10,871 iteration 2865 : loss : 0.029759, loss_ce: 0.010423
2022-01-17 12:15:11,803 iteration 2866 : loss : 0.030738, loss_ce: 0.012243
2022-01-17 12:15:12,869 iteration 2867 : loss : 0.038386, loss_ce: 0.016681
2022-01-17 12:15:13,770 iteration 2868 : loss : 0.024871, loss_ce: 0.007955
2022-01-17 12:15:14,808 iteration 2869 : loss : 0.031787, loss_ce: 0.015115
2022-01-17 12:15:15,790 iteration 2870 : loss : 0.025055, loss_ce: 0.007259
2022-01-17 12:15:16,708 iteration 2871 : loss : 0.021043, loss_ce: 0.008348
2022-01-17 12:15:17,582 iteration 2872 : loss : 0.029670, loss_ce: 0.011283
2022-01-17 12:15:18,588 iteration 2873 : loss : 0.024483, loss_ce: 0.007503
 42%|████████████▎                | 169/400 [49:28<1:05:07, 16.91s/it]2022-01-17 12:15:19,621 iteration 2874 : loss : 0.031521, loss_ce: 0.009591
2022-01-17 12:15:20,592 iteration 2875 : loss : 0.027412, loss_ce: 0.010015
2022-01-17 12:15:21,550 iteration 2876 : loss : 0.029223, loss_ce: 0.011420
2022-01-17 12:15:22,559 iteration 2877 : loss : 0.035928, loss_ce: 0.009577
2022-01-17 12:15:23,511 iteration 2878 : loss : 0.039028, loss_ce: 0.015952
2022-01-17 12:15:24,514 iteration 2879 : loss : 0.022942, loss_ce: 0.007986
2022-01-17 12:15:25,527 iteration 2880 : loss : 0.033080, loss_ce: 0.010798
2022-01-17 12:15:26,476 iteration 2881 : loss : 0.022357, loss_ce: 0.009201
2022-01-17 12:15:27,483 iteration 2882 : loss : 0.021814, loss_ce: 0.009975
2022-01-17 12:15:28,391 iteration 2883 : loss : 0.034496, loss_ce: 0.015474
2022-01-17 12:15:29,312 iteration 2884 : loss : 0.026141, loss_ce: 0.011322
2022-01-17 12:15:30,277 iteration 2885 : loss : 0.025915, loss_ce: 0.009996
2022-01-17 12:15:31,139 iteration 2886 : loss : 0.033081, loss_ce: 0.010209
2022-01-17 12:15:32,172 iteration 2887 : loss : 0.035413, loss_ce: 0.018128
2022-01-17 12:15:33,144 iteration 2888 : loss : 0.045678, loss_ce: 0.009916
2022-01-17 12:15:34,211 iteration 2889 : loss : 0.022976, loss_ce: 0.007285
2022-01-17 12:15:34,211 Training Data Eval:
2022-01-17 12:15:38,669   Average segmentation loss on training set: 0.0173
2022-01-17 12:15:38,670 Validation Data Eval:
2022-01-17 12:15:40,168   Average segmentation loss on validation set: 0.1050
2022-01-17 12:15:41,181 iteration 2890 : loss : 0.025216, loss_ce: 0.008280
 42%|████████████▎                | 170/400 [49:51<1:11:21, 18.61s/it]2022-01-17 12:15:42,213 iteration 2891 : loss : 0.022676, loss_ce: 0.009457
2022-01-17 12:15:43,253 iteration 2892 : loss : 0.024269, loss_ce: 0.005148
2022-01-17 12:15:44,166 iteration 2893 : loss : 0.024192, loss_ce: 0.007285
2022-01-17 12:15:45,203 iteration 2894 : loss : 0.032275, loss_ce: 0.009444
2022-01-17 12:15:46,218 iteration 2895 : loss : 0.026576, loss_ce: 0.011156
2022-01-17 12:15:47,126 iteration 2896 : loss : 0.019354, loss_ce: 0.006118
2022-01-17 12:15:48,081 iteration 2897 : loss : 0.044011, loss_ce: 0.016207
2022-01-17 12:15:48,970 iteration 2898 : loss : 0.022030, loss_ce: 0.010002
2022-01-17 12:15:49,958 iteration 2899 : loss : 0.032951, loss_ce: 0.010331
2022-01-17 12:15:50,911 iteration 2900 : loss : 0.021480, loss_ce: 0.006211
2022-01-17 12:15:51,879 iteration 2901 : loss : 0.032682, loss_ce: 0.009539
2022-01-17 12:15:52,763 iteration 2902 : loss : 0.025878, loss_ce: 0.008760
2022-01-17 12:15:53,682 iteration 2903 : loss : 0.026033, loss_ce: 0.013127
2022-01-17 12:15:54,591 iteration 2904 : loss : 0.029290, loss_ce: 0.011605
2022-01-17 12:15:55,466 iteration 2905 : loss : 0.026442, loss_ce: 0.011457
2022-01-17 12:15:56,460 iteration 2906 : loss : 0.030047, loss_ce: 0.016280
2022-01-17 12:15:57,374 iteration 2907 : loss : 0.027434, loss_ce: 0.010090
 43%|████████████▍                | 171/400 [50:07<1:08:16, 17.89s/it]2022-01-17 12:15:58,402 iteration 2908 : loss : 0.040424, loss_ce: 0.018499
2022-01-17 12:15:59,415 iteration 2909 : loss : 0.036194, loss_ce: 0.018047
2022-01-17 12:16:00,380 iteration 2910 : loss : 0.024135, loss_ce: 0.009632
2022-01-17 12:16:01,388 iteration 2911 : loss : 0.024500, loss_ce: 0.007638
2022-01-17 12:16:02,311 iteration 2912 : loss : 0.025165, loss_ce: 0.008251
2022-01-17 12:16:03,327 iteration 2913 : loss : 0.026727, loss_ce: 0.011749
2022-01-17 12:16:04,255 iteration 2914 : loss : 0.033769, loss_ce: 0.011590
2022-01-17 12:16:05,184 iteration 2915 : loss : 0.020682, loss_ce: 0.008211
2022-01-17 12:16:06,148 iteration 2916 : loss : 0.019827, loss_ce: 0.007691
2022-01-17 12:16:07,030 iteration 2917 : loss : 0.022621, loss_ce: 0.009836
2022-01-17 12:16:07,941 iteration 2918 : loss : 0.020562, loss_ce: 0.004843
2022-01-17 12:16:08,892 iteration 2919 : loss : 0.026541, loss_ce: 0.008623
2022-01-17 12:16:09,872 iteration 2920 : loss : 0.024581, loss_ce: 0.009465
2022-01-17 12:16:10,813 iteration 2921 : loss : 0.024367, loss_ce: 0.010376
2022-01-17 12:16:11,689 iteration 2922 : loss : 0.028499, loss_ce: 0.010065
2022-01-17 12:16:12,612 iteration 2923 : loss : 0.025271, loss_ce: 0.007365
2022-01-17 12:16:13,562 iteration 2924 : loss : 0.046962, loss_ce: 0.019027
 43%|████████████▍                | 172/400 [50:23<1:06:02, 17.38s/it]2022-01-17 12:16:14,448 iteration 2925 : loss : 0.018307, loss_ce: 0.008737
2022-01-17 12:16:15,484 iteration 2926 : loss : 0.035030, loss_ce: 0.013980
2022-01-17 12:16:16,429 iteration 2927 : loss : 0.027785, loss_ce: 0.010444
2022-01-17 12:16:17,259 iteration 2928 : loss : 0.022626, loss_ce: 0.007094
2022-01-17 12:16:18,179 iteration 2929 : loss : 0.024791, loss_ce: 0.009843
2022-01-17 12:16:19,210 iteration 2930 : loss : 0.051584, loss_ce: 0.022756
2022-01-17 12:16:20,131 iteration 2931 : loss : 0.026620, loss_ce: 0.009504
2022-01-17 12:16:21,030 iteration 2932 : loss : 0.024344, loss_ce: 0.008574
2022-01-17 12:16:22,053 iteration 2933 : loss : 0.030512, loss_ce: 0.010257
2022-01-17 12:16:22,989 iteration 2934 : loss : 0.023928, loss_ce: 0.007194
2022-01-17 12:16:23,944 iteration 2935 : loss : 0.028694, loss_ce: 0.009577
2022-01-17 12:16:24,882 iteration 2936 : loss : 0.018850, loss_ce: 0.005173
2022-01-17 12:16:25,855 iteration 2937 : loss : 0.024449, loss_ce: 0.010268
2022-01-17 12:16:26,855 iteration 2938 : loss : 0.035347, loss_ce: 0.009818
2022-01-17 12:16:27,860 iteration 2939 : loss : 0.025071, loss_ce: 0.008899
2022-01-17 12:16:28,923 iteration 2940 : loss : 0.028037, loss_ce: 0.013887
2022-01-17 12:16:29,815 iteration 2941 : loss : 0.020172, loss_ce: 0.006236
 43%|████████████▌                | 173/400 [50:39<1:04:28, 17.04s/it]2022-01-17 12:16:30,743 iteration 2942 : loss : 0.020656, loss_ce: 0.006555
2022-01-17 12:16:31,723 iteration 2943 : loss : 0.033289, loss_ce: 0.009608
2022-01-17 12:16:32,633 iteration 2944 : loss : 0.021568, loss_ce: 0.010974
2022-01-17 12:16:33,600 iteration 2945 : loss : 0.021244, loss_ce: 0.005660
2022-01-17 12:16:34,448 iteration 2946 : loss : 0.019316, loss_ce: 0.007296
2022-01-17 12:16:35,366 iteration 2947 : loss : 0.025506, loss_ce: 0.009549
2022-01-17 12:16:36,276 iteration 2948 : loss : 0.021457, loss_ce: 0.005563
2022-01-17 12:16:37,296 iteration 2949 : loss : 0.027297, loss_ce: 0.009703
2022-01-17 12:16:38,271 iteration 2950 : loss : 0.027438, loss_ce: 0.010997
2022-01-17 12:16:39,267 iteration 2951 : loss : 0.031267, loss_ce: 0.013418
2022-01-17 12:16:40,249 iteration 2952 : loss : 0.020567, loss_ce: 0.006400
2022-01-17 12:16:41,262 iteration 2953 : loss : 0.023702, loss_ce: 0.010184
2022-01-17 12:16:42,309 iteration 2954 : loss : 0.035247, loss_ce: 0.009347
2022-01-17 12:16:43,211 iteration 2955 : loss : 0.022764, loss_ce: 0.009121
2022-01-17 12:16:44,135 iteration 2956 : loss : 0.021092, loss_ce: 0.007268
2022-01-17 12:16:45,030 iteration 2957 : loss : 0.024748, loss_ce: 0.009427
2022-01-17 12:16:45,989 iteration 2958 : loss : 0.025163, loss_ce: 0.012100
 44%|████████████▌                | 174/400 [50:55<1:03:12, 16.78s/it]2022-01-17 12:16:46,955 iteration 2959 : loss : 0.021659, loss_ce: 0.007101
2022-01-17 12:16:47,886 iteration 2960 : loss : 0.025608, loss_ce: 0.010811
2022-01-17 12:16:48,850 iteration 2961 : loss : 0.026780, loss_ce: 0.009652
2022-01-17 12:16:49,958 iteration 2962 : loss : 0.019677, loss_ce: 0.006504
2022-01-17 12:16:50,920 iteration 2963 : loss : 0.033063, loss_ce: 0.011611
2022-01-17 12:16:51,766 iteration 2964 : loss : 0.018781, loss_ce: 0.005600
2022-01-17 12:16:52,722 iteration 2965 : loss : 0.023461, loss_ce: 0.014235
2022-01-17 12:16:53,717 iteration 2966 : loss : 0.024419, loss_ce: 0.007948
2022-01-17 12:16:54,653 iteration 2967 : loss : 0.032338, loss_ce: 0.012946
2022-01-17 12:16:55,601 iteration 2968 : loss : 0.024175, loss_ce: 0.009805
2022-01-17 12:16:56,527 iteration 2969 : loss : 0.030428, loss_ce: 0.012410
2022-01-17 12:16:57,488 iteration 2970 : loss : 0.035190, loss_ce: 0.014330
2022-01-17 12:16:58,415 iteration 2971 : loss : 0.022592, loss_ce: 0.007864
2022-01-17 12:16:59,359 iteration 2972 : loss : 0.027433, loss_ce: 0.012016
2022-01-17 12:17:00,255 iteration 2973 : loss : 0.021466, loss_ce: 0.005460
2022-01-17 12:17:01,260 iteration 2974 : loss : 0.030572, loss_ce: 0.009299
2022-01-17 12:17:01,260 Training Data Eval:
2022-01-17 12:17:05,723   Average segmentation loss on training set: 0.0170
2022-01-17 12:17:05,723 Validation Data Eval:
2022-01-17 12:17:07,232   Average segmentation loss on validation set: 0.0724
2022-01-17 12:17:08,158 iteration 2975 : loss : 0.018617, loss_ce: 0.006872
 44%|████████████▋                | 175/400 [51:18<1:08:59, 18.40s/it]2022-01-17 12:17:09,061 iteration 2976 : loss : 0.019393, loss_ce: 0.007505
2022-01-17 12:17:10,049 iteration 2977 : loss : 0.025460, loss_ce: 0.011513
2022-01-17 12:17:11,014 iteration 2978 : loss : 0.023681, loss_ce: 0.008501
2022-01-17 12:17:12,022 iteration 2979 : loss : 0.032697, loss_ce: 0.009035
2022-01-17 12:17:13,012 iteration 2980 : loss : 0.028920, loss_ce: 0.007888
2022-01-17 12:17:14,067 iteration 2981 : loss : 0.033332, loss_ce: 0.014910
2022-01-17 12:17:15,009 iteration 2982 : loss : 0.015608, loss_ce: 0.006073
2022-01-17 12:17:15,970 iteration 2983 : loss : 0.023916, loss_ce: 0.008146
2022-01-17 12:17:16,940 iteration 2984 : loss : 0.034725, loss_ce: 0.012228
2022-01-17 12:17:17,926 iteration 2985 : loss : 0.024712, loss_ce: 0.008273
2022-01-17 12:17:18,814 iteration 2986 : loss : 0.022834, loss_ce: 0.010118
2022-01-17 12:17:19,774 iteration 2987 : loss : 0.025412, loss_ce: 0.007858
2022-01-17 12:17:20,777 iteration 2988 : loss : 0.023258, loss_ce: 0.009076
2022-01-17 12:17:21,774 iteration 2989 : loss : 0.025014, loss_ce: 0.009467
2022-01-17 12:17:22,667 iteration 2990 : loss : 0.019985, loss_ce: 0.008202
2022-01-17 12:17:23,617 iteration 2991 : loss : 0.020971, loss_ce: 0.007852
2022-01-17 12:17:24,643 iteration 2992 : loss : 0.022406, loss_ce: 0.009344
 44%|████████████▊                | 176/400 [51:34<1:06:32, 17.82s/it]2022-01-17 12:17:25,580 iteration 2993 : loss : 0.020988, loss_ce: 0.010149
2022-01-17 12:17:26,549 iteration 2994 : loss : 0.030599, loss_ce: 0.005699
2022-01-17 12:17:27,477 iteration 2995 : loss : 0.018638, loss_ce: 0.006114
2022-01-17 12:17:28,422 iteration 2996 : loss : 0.020834, loss_ce: 0.010135
2022-01-17 12:17:29,363 iteration 2997 : loss : 0.031922, loss_ce: 0.009485
2022-01-17 12:17:30,322 iteration 2998 : loss : 0.023327, loss_ce: 0.008414
2022-01-17 12:17:31,338 iteration 2999 : loss : 0.051107, loss_ce: 0.007699
2022-01-17 12:17:32,375 iteration 3000 : loss : 0.029109, loss_ce: 0.011301
2022-01-17 12:17:33,400 iteration 3001 : loss : 0.034179, loss_ce: 0.007686
2022-01-17 12:17:34,287 iteration 3002 : loss : 0.019757, loss_ce: 0.007577
2022-01-17 12:17:35,203 iteration 3003 : loss : 0.024163, loss_ce: 0.008737
2022-01-17 12:17:36,126 iteration 3004 : loss : 0.023826, loss_ce: 0.009614
2022-01-17 12:17:37,075 iteration 3005 : loss : 0.025922, loss_ce: 0.010210
2022-01-17 12:17:38,070 iteration 3006 : loss : 0.028478, loss_ce: 0.012102
2022-01-17 12:17:39,054 iteration 3007 : loss : 0.026728, loss_ce: 0.010464
2022-01-17 12:17:40,041 iteration 3008 : loss : 0.030859, loss_ce: 0.010850
2022-01-17 12:17:40,913 iteration 3009 : loss : 0.029163, loss_ce: 0.012165
 44%|████████████▊                | 177/400 [51:50<1:04:30, 17.36s/it]2022-01-17 12:17:42,019 iteration 3010 : loss : 0.029239, loss_ce: 0.010751
2022-01-17 12:17:43,004 iteration 3011 : loss : 0.024231, loss_ce: 0.010899
2022-01-17 12:17:43,898 iteration 3012 : loss : 0.021128, loss_ce: 0.009009
2022-01-17 12:17:44,782 iteration 3013 : loss : 0.028440, loss_ce: 0.008077
2022-01-17 12:17:45,740 iteration 3014 : loss : 0.031726, loss_ce: 0.013997
2022-01-17 12:17:46,685 iteration 3015 : loss : 0.039913, loss_ce: 0.009883
2022-01-17 12:17:47,629 iteration 3016 : loss : 0.033402, loss_ce: 0.012856
2022-01-17 12:17:48,548 iteration 3017 : loss : 0.022407, loss_ce: 0.010992
2022-01-17 12:17:49,467 iteration 3018 : loss : 0.020153, loss_ce: 0.007950
2022-01-17 12:17:50,344 iteration 3019 : loss : 0.020852, loss_ce: 0.007080
2022-01-17 12:17:51,320 iteration 3020 : loss : 0.036669, loss_ce: 0.012622
2022-01-17 12:17:52,281 iteration 3021 : loss : 0.017952, loss_ce: 0.006515
2022-01-17 12:17:53,210 iteration 3022 : loss : 0.018663, loss_ce: 0.006149
2022-01-17 12:17:54,162 iteration 3023 : loss : 0.030394, loss_ce: 0.010634
2022-01-17 12:17:55,195 iteration 3024 : loss : 0.028274, loss_ce: 0.011869
2022-01-17 12:17:56,195 iteration 3025 : loss : 0.026781, loss_ce: 0.011341
2022-01-17 12:17:57,082 iteration 3026 : loss : 0.021012, loss_ce: 0.009038
 44%|████████████▉                | 178/400 [52:06<1:02:54, 17.00s/it]2022-01-17 12:17:58,126 iteration 3027 : loss : 0.042968, loss_ce: 0.016536
2022-01-17 12:17:59,035 iteration 3028 : loss : 0.028992, loss_ce: 0.010330
2022-01-17 12:18:00,000 iteration 3029 : loss : 0.021562, loss_ce: 0.008526
2022-01-17 12:18:00,917 iteration 3030 : loss : 0.019585, loss_ce: 0.008539
2022-01-17 12:18:01,870 iteration 3031 : loss : 0.026776, loss_ce: 0.011433
2022-01-17 12:18:02,783 iteration 3032 : loss : 0.030369, loss_ce: 0.012179
2022-01-17 12:18:03,765 iteration 3033 : loss : 0.035078, loss_ce: 0.010171
2022-01-17 12:18:04,768 iteration 3034 : loss : 0.053292, loss_ce: 0.024445
2022-01-17 12:18:05,739 iteration 3035 : loss : 0.021259, loss_ce: 0.008534
2022-01-17 12:18:06,668 iteration 3036 : loss : 0.028494, loss_ce: 0.014700
2022-01-17 12:18:07,622 iteration 3037 : loss : 0.030188, loss_ce: 0.012540
2022-01-17 12:18:08,614 iteration 3038 : loss : 0.039169, loss_ce: 0.017371
2022-01-17 12:18:09,500 iteration 3039 : loss : 0.026203, loss_ce: 0.007236
2022-01-17 12:18:10,466 iteration 3040 : loss : 0.037285, loss_ce: 0.011360
2022-01-17 12:18:11,467 iteration 3041 : loss : 0.021974, loss_ce: 0.008140
2022-01-17 12:18:12,418 iteration 3042 : loss : 0.028015, loss_ce: 0.012875
2022-01-17 12:18:13,552 iteration 3043 : loss : 0.036451, loss_ce: 0.011012
 45%|████████████▉                | 179/400 [52:23<1:02:02, 16.84s/it]2022-01-17 12:18:14,552 iteration 3044 : loss : 0.031471, loss_ce: 0.012150
2022-01-17 12:18:15,438 iteration 3045 : loss : 0.024088, loss_ce: 0.009112
2022-01-17 12:18:16,354 iteration 3046 : loss : 0.020941, loss_ce: 0.006732
2022-01-17 12:18:17,410 iteration 3047 : loss : 0.033650, loss_ce: 0.018283
2022-01-17 12:18:18,316 iteration 3048 : loss : 0.028106, loss_ce: 0.009670
2022-01-17 12:18:19,273 iteration 3049 : loss : 0.027987, loss_ce: 0.012641
2022-01-17 12:18:20,262 iteration 3050 : loss : 0.028201, loss_ce: 0.011735
2022-01-17 12:18:21,226 iteration 3051 : loss : 0.040033, loss_ce: 0.011576
2022-01-17 12:18:22,169 iteration 3052 : loss : 0.028368, loss_ce: 0.010233
2022-01-17 12:18:23,210 iteration 3053 : loss : 0.027807, loss_ce: 0.013151
2022-01-17 12:18:24,103 iteration 3054 : loss : 0.023759, loss_ce: 0.006774
2022-01-17 12:18:25,066 iteration 3055 : loss : 0.038766, loss_ce: 0.014924
2022-01-17 12:18:25,981 iteration 3056 : loss : 0.020440, loss_ce: 0.008075
2022-01-17 12:18:26,867 iteration 3057 : loss : 0.024203, loss_ce: 0.008734
2022-01-17 12:18:27,840 iteration 3058 : loss : 0.020971, loss_ce: 0.007981
2022-01-17 12:18:28,835 iteration 3059 : loss : 0.020995, loss_ce: 0.005902
2022-01-17 12:18:28,873 Training Data Eval:
2022-01-17 12:18:33,341   Average segmentation loss on training set: 0.0181
2022-01-17 12:18:33,341 Validation Data Eval:
2022-01-17 12:18:34,856   Average segmentation loss on validation set: 0.1128
2022-01-17 12:18:35,767 iteration 3060 : loss : 0.025968, loss_ce: 0.012700
 45%|█████████████                | 180/400 [52:45<1:07:39, 18.45s/it]2022-01-17 12:18:36,677 iteration 3061 : loss : 0.025262, loss_ce: 0.008794
2022-01-17 12:18:37,626 iteration 3062 : loss : 0.029654, loss_ce: 0.011501
2022-01-17 12:18:38,609 iteration 3063 : loss : 0.029421, loss_ce: 0.010196
2022-01-17 12:18:39,599 iteration 3064 : loss : 0.022542, loss_ce: 0.009207
2022-01-17 12:18:40,441 iteration 3065 : loss : 0.018815, loss_ce: 0.005958
2022-01-17 12:18:41,354 iteration 3066 : loss : 0.020667, loss_ce: 0.009248
2022-01-17 12:18:42,331 iteration 3067 : loss : 0.030958, loss_ce: 0.013301
2022-01-17 12:18:43,290 iteration 3068 : loss : 0.036339, loss_ce: 0.010913
2022-01-17 12:18:44,246 iteration 3069 : loss : 0.024875, loss_ce: 0.006552
2022-01-17 12:18:45,208 iteration 3070 : loss : 0.022564, loss_ce: 0.009516
2022-01-17 12:18:46,104 iteration 3071 : loss : 0.022029, loss_ce: 0.008533
2022-01-17 12:18:46,994 iteration 3072 : loss : 0.023164, loss_ce: 0.008370
2022-01-17 12:18:47,925 iteration 3073 : loss : 0.020196, loss_ce: 0.007329
2022-01-17 12:18:48,948 iteration 3074 : loss : 0.025026, loss_ce: 0.009451
2022-01-17 12:18:49,934 iteration 3075 : loss : 0.025362, loss_ce: 0.008715
2022-01-17 12:18:50,958 iteration 3076 : loss : 0.026210, loss_ce: 0.009702
2022-01-17 12:18:51,861 iteration 3077 : loss : 0.030349, loss_ce: 0.010574
 45%|█████████████                | 181/400 [53:01<1:04:45, 17.74s/it]2022-01-17 12:18:52,794 iteration 3078 : loss : 0.023517, loss_ce: 0.008722
2022-01-17 12:18:53,861 iteration 3079 : loss : 0.020857, loss_ce: 0.007508
2022-01-17 12:18:54,736 iteration 3080 : loss : 0.021826, loss_ce: 0.005800
2022-01-17 12:18:55,716 iteration 3081 : loss : 0.024518, loss_ce: 0.008248
2022-01-17 12:18:56,652 iteration 3082 : loss : 0.024107, loss_ce: 0.005888
2022-01-17 12:18:57,655 iteration 3083 : loss : 0.026690, loss_ce: 0.009747
2022-01-17 12:18:58,481 iteration 3084 : loss : 0.020945, loss_ce: 0.008602
2022-01-17 12:18:59,448 iteration 3085 : loss : 0.023056, loss_ce: 0.009145
2022-01-17 12:19:00,499 iteration 3086 : loss : 0.028284, loss_ce: 0.016000
2022-01-17 12:19:01,421 iteration 3087 : loss : 0.026220, loss_ce: 0.010622
2022-01-17 12:19:02,383 iteration 3088 : loss : 0.018940, loss_ce: 0.005872
2022-01-17 12:19:03,428 iteration 3089 : loss : 0.039406, loss_ce: 0.014464
2022-01-17 12:19:04,290 iteration 3090 : loss : 0.026150, loss_ce: 0.012393
2022-01-17 12:19:05,236 iteration 3091 : loss : 0.029826, loss_ce: 0.015162
2022-01-17 12:19:06,337 iteration 3092 : loss : 0.028490, loss_ce: 0.009971
2022-01-17 12:19:07,242 iteration 3093 : loss : 0.022413, loss_ce: 0.009591
2022-01-17 12:19:08,202 iteration 3094 : loss : 0.022910, loss_ce: 0.010004
 46%|█████████████▏               | 182/400 [53:18<1:02:57, 17.33s/it]2022-01-17 12:19:09,186 iteration 3095 : loss : 0.023133, loss_ce: 0.009019
2022-01-17 12:19:10,147 iteration 3096 : loss : 0.024006, loss_ce: 0.011059
2022-01-17 12:19:11,073 iteration 3097 : loss : 0.020054, loss_ce: 0.007125
2022-01-17 12:19:11,971 iteration 3098 : loss : 0.024337, loss_ce: 0.011814
2022-01-17 12:19:12,922 iteration 3099 : loss : 0.020953, loss_ce: 0.006794
2022-01-17 12:19:13,818 iteration 3100 : loss : 0.025899, loss_ce: 0.008120
2022-01-17 12:19:14,820 iteration 3101 : loss : 0.020273, loss_ce: 0.007358
2022-01-17 12:19:15,772 iteration 3102 : loss : 0.028154, loss_ce: 0.009842
2022-01-17 12:19:16,742 iteration 3103 : loss : 0.036736, loss_ce: 0.016163
2022-01-17 12:19:17,648 iteration 3104 : loss : 0.022726, loss_ce: 0.010103
2022-01-17 12:19:18,530 iteration 3105 : loss : 0.018534, loss_ce: 0.007827
2022-01-17 12:19:19,464 iteration 3106 : loss : 0.021293, loss_ce: 0.009173
2022-01-17 12:19:20,386 iteration 3107 : loss : 0.015786, loss_ce: 0.004044
2022-01-17 12:19:21,350 iteration 3108 : loss : 0.027205, loss_ce: 0.008227
2022-01-17 12:19:22,333 iteration 3109 : loss : 0.023478, loss_ce: 0.007997
2022-01-17 12:19:23,318 iteration 3110 : loss : 0.031314, loss_ce: 0.013544
2022-01-17 12:19:24,277 iteration 3111 : loss : 0.022716, loss_ce: 0.008681
 46%|█████████████▎               | 183/400 [53:34<1:01:17, 16.95s/it]2022-01-17 12:19:25,279 iteration 3112 : loss : 0.024054, loss_ce: 0.008831
2022-01-17 12:19:26,181 iteration 3113 : loss : 0.025858, loss_ce: 0.009135
2022-01-17 12:19:27,170 iteration 3114 : loss : 0.027370, loss_ce: 0.009733
2022-01-17 12:19:28,125 iteration 3115 : loss : 0.023072, loss_ce: 0.010571
2022-01-17 12:19:29,061 iteration 3116 : loss : 0.019766, loss_ce: 0.008630
2022-01-17 12:19:30,076 iteration 3117 : loss : 0.019158, loss_ce: 0.006919
2022-01-17 12:19:30,999 iteration 3118 : loss : 0.025321, loss_ce: 0.011173
2022-01-17 12:19:32,051 iteration 3119 : loss : 0.028250, loss_ce: 0.008370
2022-01-17 12:19:32,943 iteration 3120 : loss : 0.020836, loss_ce: 0.007495
2022-01-17 12:19:33,952 iteration 3121 : loss : 0.022339, loss_ce: 0.010176
2022-01-17 12:19:34,870 iteration 3122 : loss : 0.025436, loss_ce: 0.006790
2022-01-17 12:19:35,878 iteration 3123 : loss : 0.022430, loss_ce: 0.008755
2022-01-17 12:19:36,745 iteration 3124 : loss : 0.018432, loss_ce: 0.006150
2022-01-17 12:19:37,686 iteration 3125 : loss : 0.021367, loss_ce: 0.006080
2022-01-17 12:19:38,699 iteration 3126 : loss : 0.026178, loss_ce: 0.011178
2022-01-17 12:19:39,718 iteration 3127 : loss : 0.031332, loss_ce: 0.009627
2022-01-17 12:19:40,724 iteration 3128 : loss : 0.026579, loss_ce: 0.008880
 46%|█████████████▎               | 184/400 [53:50<1:00:28, 16.80s/it]2022-01-17 12:19:41,668 iteration 3129 : loss : 0.021222, loss_ce: 0.007928
2022-01-17 12:19:42,705 iteration 3130 : loss : 0.027279, loss_ce: 0.011499
2022-01-17 12:19:43,631 iteration 3131 : loss : 0.021314, loss_ce: 0.006648
2022-01-17 12:19:44,572 iteration 3132 : loss : 0.021285, loss_ce: 0.006708
2022-01-17 12:19:45,521 iteration 3133 : loss : 0.031500, loss_ce: 0.010728
2022-01-17 12:19:46,434 iteration 3134 : loss : 0.021117, loss_ce: 0.010196
2022-01-17 12:19:47,385 iteration 3135 : loss : 0.021416, loss_ce: 0.010052
2022-01-17 12:19:48,316 iteration 3136 : loss : 0.026206, loss_ce: 0.010931
2022-01-17 12:19:49,386 iteration 3137 : loss : 0.027320, loss_ce: 0.010759
2022-01-17 12:19:50,411 iteration 3138 : loss : 0.032316, loss_ce: 0.012236
2022-01-17 12:19:51,296 iteration 3139 : loss : 0.017111, loss_ce: 0.005470
2022-01-17 12:19:52,196 iteration 3140 : loss : 0.024013, loss_ce: 0.009706
2022-01-17 12:19:53,168 iteration 3141 : loss : 0.027596, loss_ce: 0.012460
2022-01-17 12:19:54,099 iteration 3142 : loss : 0.025448, loss_ce: 0.008468
2022-01-17 12:19:55,101 iteration 3143 : loss : 0.030261, loss_ce: 0.009913
2022-01-17 12:19:56,038 iteration 3144 : loss : 0.028504, loss_ce: 0.010403
2022-01-17 12:19:56,038 Training Data Eval:
2022-01-17 12:20:00,506   Average segmentation loss on training set: 0.0150
2022-01-17 12:20:00,506 Validation Data Eval:
2022-01-17 12:20:02,011   Average segmentation loss on validation set: 0.0751
2022-01-17 12:20:02,916 iteration 3145 : loss : 0.019286, loss_ce: 0.007484
 46%|█████████████▍               | 185/400 [54:12<1:05:59, 18.42s/it]2022-01-17 12:20:04,056 iteration 3146 : loss : 0.026650, loss_ce: 0.008018
2022-01-17 12:20:05,050 iteration 3147 : loss : 0.027202, loss_ce: 0.011368
2022-01-17 12:20:05,934 iteration 3148 : loss : 0.015535, loss_ce: 0.005530
2022-01-17 12:20:06,931 iteration 3149 : loss : 0.024219, loss_ce: 0.007506
2022-01-17 12:20:07,918 iteration 3150 : loss : 0.021354, loss_ce: 0.006586
2022-01-17 12:20:08,907 iteration 3151 : loss : 0.031481, loss_ce: 0.012190
2022-01-17 12:20:09,891 iteration 3152 : loss : 0.026901, loss_ce: 0.008837
2022-01-17 12:20:10,863 iteration 3153 : loss : 0.024301, loss_ce: 0.012264
2022-01-17 12:20:11,902 iteration 3154 : loss : 0.025019, loss_ce: 0.008315
2022-01-17 12:20:12,903 iteration 3155 : loss : 0.023349, loss_ce: 0.007504
2022-01-17 12:20:13,798 iteration 3156 : loss : 0.025719, loss_ce: 0.009682
2022-01-17 12:20:14,769 iteration 3157 : loss : 0.024393, loss_ce: 0.011410
2022-01-17 12:20:15,678 iteration 3158 : loss : 0.045530, loss_ce: 0.008184
2022-01-17 12:20:16,656 iteration 3159 : loss : 0.025857, loss_ce: 0.012139
2022-01-17 12:20:17,643 iteration 3160 : loss : 0.020350, loss_ce: 0.007438
2022-01-17 12:20:18,685 iteration 3161 : loss : 0.023995, loss_ce: 0.007973
2022-01-17 12:20:19,652 iteration 3162 : loss : 0.031378, loss_ce: 0.008769
 46%|█████████████▍               | 186/400 [54:29<1:03:53, 17.91s/it]2022-01-17 12:20:20,596 iteration 3163 : loss : 0.043304, loss_ce: 0.011529
2022-01-17 12:20:21,657 iteration 3164 : loss : 0.033284, loss_ce: 0.014384
2022-01-17 12:20:22,654 iteration 3165 : loss : 0.021641, loss_ce: 0.008331
2022-01-17 12:20:23,564 iteration 3166 : loss : 0.028224, loss_ce: 0.011190
2022-01-17 12:20:24,566 iteration 3167 : loss : 0.026329, loss_ce: 0.008710
2022-01-17 12:20:25,510 iteration 3168 : loss : 0.027245, loss_ce: 0.010766
2022-01-17 12:20:26,480 iteration 3169 : loss : 0.039016, loss_ce: 0.017553
2022-01-17 12:20:27,437 iteration 3170 : loss : 0.026366, loss_ce: 0.011585
2022-01-17 12:20:28,267 iteration 3171 : loss : 0.027461, loss_ce: 0.006979
2022-01-17 12:20:29,176 iteration 3172 : loss : 0.031293, loss_ce: 0.010948
2022-01-17 12:20:30,133 iteration 3173 : loss : 0.034899, loss_ce: 0.012235
2022-01-17 12:20:31,057 iteration 3174 : loss : 0.027243, loss_ce: 0.011526
2022-01-17 12:20:31,949 iteration 3175 : loss : 0.027278, loss_ce: 0.008240
2022-01-17 12:20:32,990 iteration 3176 : loss : 0.049293, loss_ce: 0.012659
2022-01-17 12:20:33,944 iteration 3177 : loss : 0.033120, loss_ce: 0.011698
2022-01-17 12:20:34,987 iteration 3178 : loss : 0.022025, loss_ce: 0.006465
2022-01-17 12:20:35,935 iteration 3179 : loss : 0.027462, loss_ce: 0.012653
 47%|█████████████▌               | 187/400 [54:45<1:01:51, 17.42s/it]2022-01-17 12:20:36,930 iteration 3180 : loss : 0.045927, loss_ce: 0.016070
2022-01-17 12:20:37,848 iteration 3181 : loss : 0.022254, loss_ce: 0.009414
2022-01-17 12:20:38,742 iteration 3182 : loss : 0.026286, loss_ce: 0.011809
2022-01-17 12:20:39,762 iteration 3183 : loss : 0.052619, loss_ce: 0.017144
2022-01-17 12:20:40,721 iteration 3184 : loss : 0.023964, loss_ce: 0.008438
2022-01-17 12:20:41,684 iteration 3185 : loss : 0.027922, loss_ce: 0.007782
2022-01-17 12:20:42,679 iteration 3186 : loss : 0.025751, loss_ce: 0.010947
2022-01-17 12:20:43,675 iteration 3187 : loss : 0.020787, loss_ce: 0.007546
2022-01-17 12:20:44,686 iteration 3188 : loss : 0.029173, loss_ce: 0.012003
2022-01-17 12:20:45,638 iteration 3189 : loss : 0.025710, loss_ce: 0.008676
2022-01-17 12:20:46,697 iteration 3190 : loss : 0.030099, loss_ce: 0.009317
2022-01-17 12:20:47,702 iteration 3191 : loss : 0.027635, loss_ce: 0.011578
2022-01-17 12:20:48,585 iteration 3192 : loss : 0.026265, loss_ce: 0.005271
2022-01-17 12:20:49,538 iteration 3193 : loss : 0.039417, loss_ce: 0.014816
2022-01-17 12:20:50,622 iteration 3194 : loss : 0.030552, loss_ce: 0.012210
2022-01-17 12:20:51,587 iteration 3195 : loss : 0.027295, loss_ce: 0.012714
2022-01-17 12:20:52,539 iteration 3196 : loss : 0.020317, loss_ce: 0.008842
 47%|█████████████▋               | 188/400 [55:02<1:00:41, 17.18s/it]2022-01-17 12:20:53,513 iteration 3197 : loss : 0.020365, loss_ce: 0.008069
2022-01-17 12:20:54,507 iteration 3198 : loss : 0.026232, loss_ce: 0.012322
2022-01-17 12:20:55,495 iteration 3199 : loss : 0.031180, loss_ce: 0.008245
2022-01-17 12:20:56,496 iteration 3200 : loss : 0.036387, loss_ce: 0.011845
2022-01-17 12:20:57,492 iteration 3201 : loss : 0.037621, loss_ce: 0.016405
2022-01-17 12:20:58,488 iteration 3202 : loss : 0.033896, loss_ce: 0.009771
2022-01-17 12:20:59,357 iteration 3203 : loss : 0.021166, loss_ce: 0.009744
2022-01-17 12:21:00,222 iteration 3204 : loss : 0.019541, loss_ce: 0.007931
2022-01-17 12:21:01,094 iteration 3205 : loss : 0.031691, loss_ce: 0.009476
2022-01-17 12:21:01,924 iteration 3206 : loss : 0.017998, loss_ce: 0.005146
2022-01-17 12:21:02,911 iteration 3207 : loss : 0.032092, loss_ce: 0.012443
2022-01-17 12:21:03,860 iteration 3208 : loss : 0.023105, loss_ce: 0.008941
2022-01-17 12:21:04,786 iteration 3209 : loss : 0.035532, loss_ce: 0.009975
2022-01-17 12:21:05,766 iteration 3210 : loss : 0.019795, loss_ce: 0.008964
2022-01-17 12:21:06,654 iteration 3211 : loss : 0.018951, loss_ce: 0.005584
2022-01-17 12:21:07,687 iteration 3212 : loss : 0.042831, loss_ce: 0.018307
2022-01-17 12:21:08,731 iteration 3213 : loss : 0.028099, loss_ce: 0.009047
 47%|██████████████▋                | 189/400 [55:18<59:21, 16.88s/it]2022-01-17 12:21:09,666 iteration 3214 : loss : 0.017778, loss_ce: 0.007249
2022-01-17 12:21:10,620 iteration 3215 : loss : 0.022232, loss_ce: 0.009511
2022-01-17 12:21:11,570 iteration 3216 : loss : 0.035980, loss_ce: 0.012176
2022-01-17 12:21:12,559 iteration 3217 : loss : 0.029491, loss_ce: 0.013610
2022-01-17 12:21:13,523 iteration 3218 : loss : 0.031891, loss_ce: 0.009602
2022-01-17 12:21:14,473 iteration 3219 : loss : 0.025195, loss_ce: 0.009307
2022-01-17 12:21:15,379 iteration 3220 : loss : 0.019985, loss_ce: 0.008212
2022-01-17 12:21:16,429 iteration 3221 : loss : 0.028265, loss_ce: 0.010878
2022-01-17 12:21:17,351 iteration 3222 : loss : 0.016779, loss_ce: 0.004259
2022-01-17 12:21:18,331 iteration 3223 : loss : 0.020890, loss_ce: 0.007511
2022-01-17 12:21:19,380 iteration 3224 : loss : 0.031343, loss_ce: 0.009203
2022-01-17 12:21:20,333 iteration 3225 : loss : 0.040849, loss_ce: 0.017011
2022-01-17 12:21:21,289 iteration 3226 : loss : 0.023600, loss_ce: 0.009140
2022-01-17 12:21:22,256 iteration 3227 : loss : 0.028274, loss_ce: 0.011599
2022-01-17 12:21:23,173 iteration 3228 : loss : 0.024472, loss_ce: 0.007395
2022-01-17 12:21:24,061 iteration 3229 : loss : 0.022836, loss_ce: 0.006361
2022-01-17 12:21:24,061 Training Data Eval:
2022-01-17 12:21:28,522   Average segmentation loss on training set: 0.0164
2022-01-17 12:21:28,523 Validation Data Eval:
2022-01-17 12:21:30,023   Average segmentation loss on validation set: 0.0733
2022-01-17 12:21:30,901 iteration 3230 : loss : 0.022003, loss_ce: 0.008038
 48%|█████████████▊               | 190/400 [55:40<1:04:38, 18.47s/it]2022-01-17 12:21:31,844 iteration 3231 : loss : 0.027355, loss_ce: 0.006215
2022-01-17 12:21:32,775 iteration 3232 : loss : 0.021416, loss_ce: 0.006965
2022-01-17 12:21:33,736 iteration 3233 : loss : 0.027324, loss_ce: 0.012138
2022-01-17 12:21:34,717 iteration 3234 : loss : 0.016644, loss_ce: 0.006146
2022-01-17 12:21:35,696 iteration 3235 : loss : 0.038727, loss_ce: 0.012897
2022-01-17 12:21:36,589 iteration 3236 : loss : 0.019431, loss_ce: 0.009701
2022-01-17 12:21:37,639 iteration 3237 : loss : 0.024630, loss_ce: 0.010739
2022-01-17 12:21:38,597 iteration 3238 : loss : 0.019509, loss_ce: 0.009177
2022-01-17 12:21:39,554 iteration 3239 : loss : 0.022693, loss_ce: 0.008526
2022-01-17 12:21:40,457 iteration 3240 : loss : 0.025749, loss_ce: 0.006078
2022-01-17 12:21:41,335 iteration 3241 : loss : 0.024735, loss_ce: 0.006043
2022-01-17 12:21:42,293 iteration 3242 : loss : 0.034249, loss_ce: 0.012871
2022-01-17 12:21:43,176 iteration 3243 : loss : 0.029294, loss_ce: 0.009407
2022-01-17 12:21:44,138 iteration 3244 : loss : 0.028172, loss_ce: 0.011434
2022-01-17 12:21:45,052 iteration 3245 : loss : 0.017991, loss_ce: 0.007540
2022-01-17 12:21:46,071 iteration 3246 : loss : 0.052737, loss_ce: 0.028557
2022-01-17 12:21:46,981 iteration 3247 : loss : 0.023099, loss_ce: 0.008974
 48%|█████████████▊               | 191/400 [55:56<1:01:50, 17.75s/it]2022-01-17 12:21:47,926 iteration 3248 : loss : 0.017330, loss_ce: 0.006375
2022-01-17 12:21:48,830 iteration 3249 : loss : 0.019006, loss_ce: 0.007623
2022-01-17 12:21:49,761 iteration 3250 : loss : 0.026859, loss_ce: 0.008576
2022-01-17 12:21:50,691 iteration 3251 : loss : 0.018632, loss_ce: 0.007899
2022-01-17 12:21:51,652 iteration 3252 : loss : 0.032620, loss_ce: 0.009714
2022-01-17 12:21:52,588 iteration 3253 : loss : 0.019651, loss_ce: 0.008405
2022-01-17 12:21:53,513 iteration 3254 : loss : 0.021911, loss_ce: 0.008260
2022-01-17 12:21:54,371 iteration 3255 : loss : 0.025311, loss_ce: 0.009803
2022-01-17 12:21:55,298 iteration 3256 : loss : 0.018176, loss_ce: 0.006065
2022-01-17 12:21:56,195 iteration 3257 : loss : 0.018382, loss_ce: 0.007408
2022-01-17 12:21:57,151 iteration 3258 : loss : 0.022454, loss_ce: 0.009146
2022-01-17 12:21:58,039 iteration 3259 : loss : 0.023539, loss_ce: 0.008804
2022-01-17 12:21:58,997 iteration 3260 : loss : 0.020014, loss_ce: 0.007091
2022-01-17 12:21:59,916 iteration 3261 : loss : 0.027069, loss_ce: 0.005903
2022-01-17 12:22:00,909 iteration 3262 : loss : 0.030859, loss_ce: 0.011252
2022-01-17 12:22:01,974 iteration 3263 : loss : 0.041634, loss_ce: 0.010351
2022-01-17 12:22:02,931 iteration 3264 : loss : 0.025286, loss_ce: 0.009995
 48%|██████████████▉                | 192/400 [56:12<59:40, 17.21s/it]2022-01-17 12:22:03,866 iteration 3265 : loss : 0.018249, loss_ce: 0.007253
2022-01-17 12:22:04,864 iteration 3266 : loss : 0.024828, loss_ce: 0.010078
2022-01-17 12:22:05,825 iteration 3267 : loss : 0.019161, loss_ce: 0.007170
2022-01-17 12:22:06,729 iteration 3268 : loss : 0.019084, loss_ce: 0.006766
2022-01-17 12:22:07,736 iteration 3269 : loss : 0.027452, loss_ce: 0.011982
2022-01-17 12:22:08,770 iteration 3270 : loss : 0.035130, loss_ce: 0.011323
2022-01-17 12:22:09,771 iteration 3271 : loss : 0.022942, loss_ce: 0.007613
2022-01-17 12:22:10,774 iteration 3272 : loss : 0.023318, loss_ce: 0.009703
2022-01-17 12:22:11,655 iteration 3273 : loss : 0.018750, loss_ce: 0.005375
2022-01-17 12:22:12,583 iteration 3274 : loss : 0.021246, loss_ce: 0.010471
2022-01-17 12:22:13,594 iteration 3275 : loss : 0.029594, loss_ce: 0.007136
2022-01-17 12:22:14,517 iteration 3276 : loss : 0.022434, loss_ce: 0.008939
2022-01-17 12:22:15,497 iteration 3277 : loss : 0.021812, loss_ce: 0.011025
2022-01-17 12:22:16,458 iteration 3278 : loss : 0.023699, loss_ce: 0.008315
2022-01-17 12:22:17,372 iteration 3279 : loss : 0.018724, loss_ce: 0.006982
2022-01-17 12:22:18,308 iteration 3280 : loss : 0.021440, loss_ce: 0.007265
2022-01-17 12:22:19,201 iteration 3281 : loss : 0.017139, loss_ce: 0.005000
 48%|██████████████▉                | 193/400 [56:29<58:24, 16.93s/it]2022-01-17 12:22:20,218 iteration 3282 : loss : 0.026447, loss_ce: 0.011226
2022-01-17 12:22:21,170 iteration 3283 : loss : 0.017947, loss_ce: 0.005944
2022-01-17 12:22:22,123 iteration 3284 : loss : 0.028140, loss_ce: 0.012794
2022-01-17 12:22:23,056 iteration 3285 : loss : 0.023706, loss_ce: 0.007764
2022-01-17 12:22:23,993 iteration 3286 : loss : 0.014507, loss_ce: 0.005185
2022-01-17 12:22:24,959 iteration 3287 : loss : 0.020644, loss_ce: 0.008203
2022-01-17 12:22:25,853 iteration 3288 : loss : 0.021318, loss_ce: 0.011401
2022-01-17 12:22:26,760 iteration 3289 : loss : 0.022447, loss_ce: 0.006076
2022-01-17 12:22:27,761 iteration 3290 : loss : 0.029246, loss_ce: 0.010534
2022-01-17 12:22:28,774 iteration 3291 : loss : 0.023108, loss_ce: 0.007858
2022-01-17 12:22:29,746 iteration 3292 : loss : 0.029713, loss_ce: 0.007371
2022-01-17 12:22:30,693 iteration 3293 : loss : 0.019043, loss_ce: 0.008213
2022-01-17 12:22:31,612 iteration 3294 : loss : 0.022466, loss_ce: 0.010345
2022-01-17 12:22:32,653 iteration 3295 : loss : 0.042040, loss_ce: 0.015290
2022-01-17 12:22:33,626 iteration 3296 : loss : 0.036566, loss_ce: 0.011866
2022-01-17 12:22:34,503 iteration 3297 : loss : 0.015780, loss_ce: 0.006091
2022-01-17 12:22:35,492 iteration 3298 : loss : 0.024431, loss_ce: 0.010600
 48%|███████████████                | 194/400 [56:45<57:27, 16.74s/it]2022-01-17 12:22:36,407 iteration 3299 : loss : 0.017263, loss_ce: 0.007072
2022-01-17 12:22:37,321 iteration 3300 : loss : 0.029618, loss_ce: 0.009174
2022-01-17 12:22:38,329 iteration 3301 : loss : 0.021685, loss_ce: 0.010424
2022-01-17 12:22:39,274 iteration 3302 : loss : 0.021225, loss_ce: 0.007899
2022-01-17 12:22:40,203 iteration 3303 : loss : 0.022728, loss_ce: 0.008789
2022-01-17 12:22:41,158 iteration 3304 : loss : 0.020315, loss_ce: 0.006840
2022-01-17 12:22:42,129 iteration 3305 : loss : 0.023301, loss_ce: 0.007131
2022-01-17 12:22:43,128 iteration 3306 : loss : 0.029785, loss_ce: 0.011312
2022-01-17 12:22:44,047 iteration 3307 : loss : 0.019830, loss_ce: 0.007657
2022-01-17 12:22:45,010 iteration 3308 : loss : 0.026534, loss_ce: 0.011435
2022-01-17 12:22:45,954 iteration 3309 : loss : 0.026088, loss_ce: 0.005237
2022-01-17 12:22:46,980 iteration 3310 : loss : 0.042156, loss_ce: 0.015707
2022-01-17 12:22:48,023 iteration 3311 : loss : 0.020038, loss_ce: 0.007149
2022-01-17 12:22:48,914 iteration 3312 : loss : 0.022403, loss_ce: 0.007001
2022-01-17 12:22:49,817 iteration 3313 : loss : 0.018887, loss_ce: 0.006623
2022-01-17 12:22:50,835 iteration 3314 : loss : 0.024017, loss_ce: 0.007652
2022-01-17 12:22:50,836 Training Data Eval:
2022-01-17 12:22:55,298   Average segmentation loss on training set: 0.0193
2022-01-17 12:22:55,298 Validation Data Eval:
2022-01-17 12:22:56,812   Average segmentation loss on validation set: 0.0941
2022-01-17 12:22:57,709 iteration 3315 : loss : 0.019276, loss_ce: 0.008584
 49%|██████████████▏              | 195/400 [57:07<1:02:48, 18.38s/it]2022-01-17 12:22:58,648 iteration 3316 : loss : 0.016990, loss_ce: 0.006364
2022-01-17 12:22:59,567 iteration 3317 : loss : 0.027649, loss_ce: 0.010898
2022-01-17 12:23:00,616 iteration 3318 : loss : 0.021000, loss_ce: 0.008189
2022-01-17 12:23:01,538 iteration 3319 : loss : 0.019581, loss_ce: 0.007318
2022-01-17 12:23:02,470 iteration 3320 : loss : 0.018161, loss_ce: 0.006631
2022-01-17 12:23:03,431 iteration 3321 : loss : 0.017156, loss_ce: 0.004970
2022-01-17 12:23:04,388 iteration 3322 : loss : 0.026117, loss_ce: 0.012749
2022-01-17 12:23:05,286 iteration 3323 : loss : 0.019221, loss_ce: 0.005740
2022-01-17 12:23:06,317 iteration 3324 : loss : 0.026908, loss_ce: 0.010495
2022-01-17 12:23:07,219 iteration 3325 : loss : 0.022682, loss_ce: 0.006886
2022-01-17 12:23:08,205 iteration 3326 : loss : 0.025599, loss_ce: 0.009147
2022-01-17 12:23:09,260 iteration 3327 : loss : 0.029741, loss_ce: 0.009593
2022-01-17 12:23:10,211 iteration 3328 : loss : 0.023986, loss_ce: 0.009155
2022-01-17 12:23:11,121 iteration 3329 : loss : 0.019775, loss_ce: 0.008536
2022-01-17 12:23:12,064 iteration 3330 : loss : 0.025841, loss_ce: 0.008537
2022-01-17 12:23:13,025 iteration 3331 : loss : 0.020157, loss_ce: 0.007541
2022-01-17 12:23:13,886 iteration 3332 : loss : 0.016610, loss_ce: 0.007122
 49%|██████████████▏              | 196/400 [57:23<1:00:15, 17.72s/it]2022-01-17 12:23:14,845 iteration 3333 : loss : 0.019928, loss_ce: 0.007632
2022-01-17 12:23:15,809 iteration 3334 : loss : 0.017424, loss_ce: 0.008298
2022-01-17 12:23:16,674 iteration 3335 : loss : 0.015364, loss_ce: 0.006345
2022-01-17 12:23:17,622 iteration 3336 : loss : 0.042254, loss_ce: 0.017411
2022-01-17 12:23:18,615 iteration 3337 : loss : 0.026318, loss_ce: 0.010704
2022-01-17 12:23:19,659 iteration 3338 : loss : 0.028238, loss_ce: 0.014592
2022-01-17 12:23:20,594 iteration 3339 : loss : 0.036016, loss_ce: 0.010551
2022-01-17 12:23:21,505 iteration 3340 : loss : 0.017102, loss_ce: 0.006408
2022-01-17 12:23:22,440 iteration 3341 : loss : 0.021943, loss_ce: 0.008451
2022-01-17 12:23:23,437 iteration 3342 : loss : 0.027243, loss_ce: 0.012330
2022-01-17 12:23:24,414 iteration 3343 : loss : 0.021036, loss_ce: 0.007152
2022-01-17 12:23:25,379 iteration 3344 : loss : 0.021402, loss_ce: 0.007248
2022-01-17 12:23:26,302 iteration 3345 : loss : 0.017723, loss_ce: 0.005782
2022-01-17 12:23:27,257 iteration 3346 : loss : 0.027510, loss_ce: 0.012503
2022-01-17 12:23:28,238 iteration 3347 : loss : 0.034505, loss_ce: 0.008865
2022-01-17 12:23:29,277 iteration 3348 : loss : 0.034431, loss_ce: 0.009946
2022-01-17 12:23:30,239 iteration 3349 : loss : 0.022715, loss_ce: 0.008842
 49%|███████████████▎               | 197/400 [57:40<58:33, 17.31s/it]2022-01-17 12:23:31,174 iteration 3350 : loss : 0.016130, loss_ce: 0.005901
2022-01-17 12:23:32,066 iteration 3351 : loss : 0.019828, loss_ce: 0.007620
2022-01-17 12:23:32,994 iteration 3352 : loss : 0.016856, loss_ce: 0.006159
2022-01-17 12:23:33,969 iteration 3353 : loss : 0.022052, loss_ce: 0.008638
2022-01-17 12:23:34,939 iteration 3354 : loss : 0.019468, loss_ce: 0.005901
2022-01-17 12:23:35,968 iteration 3355 : loss : 0.023132, loss_ce: 0.011498
2022-01-17 12:23:36,964 iteration 3356 : loss : 0.020137, loss_ce: 0.005522
2022-01-17 12:23:37,964 iteration 3357 : loss : 0.018577, loss_ce: 0.005594
2022-01-17 12:23:38,983 iteration 3358 : loss : 0.028433, loss_ce: 0.011483
2022-01-17 12:23:39,968 iteration 3359 : loss : 0.030895, loss_ce: 0.012181
2022-01-17 12:23:41,018 iteration 3360 : loss : 0.022862, loss_ce: 0.009786
2022-01-17 12:23:41,912 iteration 3361 : loss : 0.023760, loss_ce: 0.007419
2022-01-17 12:23:42,827 iteration 3362 : loss : 0.022078, loss_ce: 0.009719
2022-01-17 12:23:43,729 iteration 3363 : loss : 0.017415, loss_ce: 0.007836
2022-01-17 12:23:44,706 iteration 3364 : loss : 0.024090, loss_ce: 0.008798
2022-01-17 12:23:45,609 iteration 3365 : loss : 0.017636, loss_ce: 0.009026
2022-01-17 12:23:46,552 iteration 3366 : loss : 0.024409, loss_ce: 0.008731
 50%|███████████████▎               | 198/400 [57:56<57:16, 17.01s/it]2022-01-17 12:23:47,543 iteration 3367 : loss : 0.024335, loss_ce: 0.008627
2022-01-17 12:23:48,476 iteration 3368 : loss : 0.022019, loss_ce: 0.009390
2022-01-17 12:23:49,445 iteration 3369 : loss : 0.025000, loss_ce: 0.008605
2022-01-17 12:23:50,417 iteration 3370 : loss : 0.021184, loss_ce: 0.009018
2022-01-17 12:23:51,278 iteration 3371 : loss : 0.013179, loss_ce: 0.004853
2022-01-17 12:23:52,215 iteration 3372 : loss : 0.025999, loss_ce: 0.013185
2022-01-17 12:23:53,149 iteration 3373 : loss : 0.022911, loss_ce: 0.013722
2022-01-17 12:23:54,040 iteration 3374 : loss : 0.019855, loss_ce: 0.009012
2022-01-17 12:23:54,938 iteration 3375 : loss : 0.018762, loss_ce: 0.008951
2022-01-17 12:23:55,854 iteration 3376 : loss : 0.021612, loss_ce: 0.008378
2022-01-17 12:23:56,844 iteration 3377 : loss : 0.025644, loss_ce: 0.007393
2022-01-17 12:23:57,781 iteration 3378 : loss : 0.021404, loss_ce: 0.007748
2022-01-17 12:23:58,640 iteration 3379 : loss : 0.015765, loss_ce: 0.006959
2022-01-17 12:23:59,649 iteration 3380 : loss : 0.023780, loss_ce: 0.008183
2022-01-17 12:24:00,529 iteration 3381 : loss : 0.029750, loss_ce: 0.004729
2022-01-17 12:24:01,480 iteration 3382 : loss : 0.024866, loss_ce: 0.008443
2022-01-17 12:24:02,411 iteration 3383 : loss : 0.019841, loss_ce: 0.006521
 50%|███████████████▍               | 199/400 [58:12<55:49, 16.67s/it]2022-01-17 12:24:03,343 iteration 3384 : loss : 0.020996, loss_ce: 0.007110
2022-01-17 12:24:04,341 iteration 3385 : loss : 0.029309, loss_ce: 0.015433
2022-01-17 12:24:05,349 iteration 3386 : loss : 0.023255, loss_ce: 0.009555
2022-01-17 12:24:06,337 iteration 3387 : loss : 0.023672, loss_ce: 0.010010
2022-01-17 12:24:07,224 iteration 3388 : loss : 0.023899, loss_ce: 0.008909
2022-01-17 12:24:08,199 iteration 3389 : loss : 0.026649, loss_ce: 0.010653
2022-01-17 12:24:09,075 iteration 3390 : loss : 0.023815, loss_ce: 0.009616
2022-01-17 12:24:10,124 iteration 3391 : loss : 0.046788, loss_ce: 0.020321
2022-01-17 12:24:11,110 iteration 3392 : loss : 0.028337, loss_ce: 0.010781
2022-01-17 12:24:12,085 iteration 3393 : loss : 0.024878, loss_ce: 0.008712
2022-01-17 12:24:12,934 iteration 3394 : loss : 0.023367, loss_ce: 0.008095
2022-01-17 12:24:13,994 iteration 3395 : loss : 0.033390, loss_ce: 0.011746
2022-01-17 12:24:14,956 iteration 3396 : loss : 0.044524, loss_ce: 0.018187
2022-01-17 12:24:15,875 iteration 3397 : loss : 0.021111, loss_ce: 0.008143
2022-01-17 12:24:16,861 iteration 3398 : loss : 0.021060, loss_ce: 0.007407
2022-01-17 12:24:17,820 iteration 3399 : loss : 0.018513, loss_ce: 0.007794
2022-01-17 12:24:17,821 Training Data Eval:
2022-01-17 12:24:22,277   Average segmentation loss on training set: 0.0162
2022-01-17 12:24:22,278 Validation Data Eval:
2022-01-17 12:24:23,779   Average segmentation loss on validation set: 0.1196
2022-01-17 12:24:24,734 iteration 3400 : loss : 0.025923, loss_ce: 0.006848
 50%|██████████████▌              | 200/400 [58:34<1:01:12, 18.36s/it]2022-01-17 12:24:25,867 iteration 3401 : loss : 0.027890, loss_ce: 0.013414
2022-01-17 12:24:26,884 iteration 3402 : loss : 0.022913, loss_ce: 0.007881
2022-01-17 12:24:27,810 iteration 3403 : loss : 0.021704, loss_ce: 0.009923
2022-01-17 12:24:28,737 iteration 3404 : loss : 0.020132, loss_ce: 0.007416
2022-01-17 12:24:29,669 iteration 3405 : loss : 0.021987, loss_ce: 0.008509
2022-01-17 12:24:30,673 iteration 3406 : loss : 0.033263, loss_ce: 0.010637
2022-01-17 12:24:31,631 iteration 3407 : loss : 0.033787, loss_ce: 0.013744
2022-01-17 12:24:32,606 iteration 3408 : loss : 0.020574, loss_ce: 0.007293
2022-01-17 12:24:33,597 iteration 3409 : loss : 0.024665, loss_ce: 0.010804
2022-01-17 12:24:34,568 iteration 3410 : loss : 0.032535, loss_ce: 0.010714
2022-01-17 12:24:35,576 iteration 3411 : loss : 0.023010, loss_ce: 0.009646
2022-01-17 12:24:36,469 iteration 3412 : loss : 0.025258, loss_ce: 0.008648
2022-01-17 12:24:37,344 iteration 3413 : loss : 0.016220, loss_ce: 0.006848
2022-01-17 12:24:38,322 iteration 3414 : loss : 0.026513, loss_ce: 0.006672
2022-01-17 12:24:39,324 iteration 3415 : loss : 0.023727, loss_ce: 0.008717
2022-01-17 12:24:40,321 iteration 3416 : loss : 0.031143, loss_ce: 0.011989
2022-01-17 12:24:41,355 iteration 3417 : loss : 0.026192, loss_ce: 0.010282
 50%|███████████████▌               | 201/400 [58:51<59:10, 17.84s/it]2022-01-17 12:24:42,343 iteration 3418 : loss : 0.019975, loss_ce: 0.008722
2022-01-17 12:24:43,319 iteration 3419 : loss : 0.019442, loss_ce: 0.006646
2022-01-17 12:24:44,362 iteration 3420 : loss : 0.029233, loss_ce: 0.009236
2022-01-17 12:24:45,321 iteration 3421 : loss : 0.021051, loss_ce: 0.007072
2022-01-17 12:24:46,205 iteration 3422 : loss : 0.017394, loss_ce: 0.005572
2022-01-17 12:24:47,155 iteration 3423 : loss : 0.016994, loss_ce: 0.007261
2022-01-17 12:24:48,118 iteration 3424 : loss : 0.019913, loss_ce: 0.008782
2022-01-17 12:24:49,021 iteration 3425 : loss : 0.021218, loss_ce: 0.010017
2022-01-17 12:24:49,985 iteration 3426 : loss : 0.024455, loss_ce: 0.007678
2022-01-17 12:24:50,960 iteration 3427 : loss : 0.021703, loss_ce: 0.007296
2022-01-17 12:24:51,936 iteration 3428 : loss : 0.026885, loss_ce: 0.011319
2022-01-17 12:24:52,935 iteration 3429 : loss : 0.022627, loss_ce: 0.008406
2022-01-17 12:24:53,940 iteration 3430 : loss : 0.029468, loss_ce: 0.012508
2022-01-17 12:24:54,808 iteration 3431 : loss : 0.017817, loss_ce: 0.007133
2022-01-17 12:24:55,721 iteration 3432 : loss : 0.018008, loss_ce: 0.005668
2022-01-17 12:24:56,633 iteration 3433 : loss : 0.021720, loss_ce: 0.008108
2022-01-17 12:24:57,638 iteration 3434 : loss : 0.031163, loss_ce: 0.010456
 50%|███████████████▋               | 202/400 [59:07<57:20, 17.37s/it]2022-01-17 12:24:58,547 iteration 3435 : loss : 0.022745, loss_ce: 0.006768
2022-01-17 12:24:59,468 iteration 3436 : loss : 0.017713, loss_ce: 0.006256
2022-01-17 12:25:00,522 iteration 3437 : loss : 0.023460, loss_ce: 0.010430
2022-01-17 12:25:01,547 iteration 3438 : loss : 0.018615, loss_ce: 0.008318
2022-01-17 12:25:02,546 iteration 3439 : loss : 0.017665, loss_ce: 0.005884
2022-01-17 12:25:03,467 iteration 3440 : loss : 0.015479, loss_ce: 0.005702
2022-01-17 12:25:04,410 iteration 3441 : loss : 0.045402, loss_ce: 0.016288
2022-01-17 12:25:05,481 iteration 3442 : loss : 0.028546, loss_ce: 0.010680
2022-01-17 12:25:06,478 iteration 3443 : loss : 0.018683, loss_ce: 0.005290
2022-01-17 12:25:07,478 iteration 3444 : loss : 0.021455, loss_ce: 0.007473
2022-01-17 12:25:08,442 iteration 3445 : loss : 0.019805, loss_ce: 0.004768
2022-01-17 12:25:09,389 iteration 3446 : loss : 0.020469, loss_ce: 0.008754
2022-01-17 12:25:10,329 iteration 3447 : loss : 0.021314, loss_ce: 0.007261
2022-01-17 12:25:11,340 iteration 3448 : loss : 0.034286, loss_ce: 0.008552
2022-01-17 12:25:12,319 iteration 3449 : loss : 0.027412, loss_ce: 0.010341
2022-01-17 12:25:13,272 iteration 3450 : loss : 0.033226, loss_ce: 0.013082
2022-01-17 12:25:14,306 iteration 3451 : loss : 0.036253, loss_ce: 0.013319
 51%|███████████████▋               | 203/400 [59:24<56:20, 17.16s/it]2022-01-17 12:25:15,285 iteration 3452 : loss : 0.023260, loss_ce: 0.009865
2022-01-17 12:25:16,211 iteration 3453 : loss : 0.017884, loss_ce: 0.006257
2022-01-17 12:25:17,123 iteration 3454 : loss : 0.017610, loss_ce: 0.005909
2022-01-17 12:25:18,154 iteration 3455 : loss : 0.026120, loss_ce: 0.011446
2022-01-17 12:25:19,059 iteration 3456 : loss : 0.020219, loss_ce: 0.006395
2022-01-17 12:25:20,103 iteration 3457 : loss : 0.027030, loss_ce: 0.010756
2022-01-17 12:25:21,091 iteration 3458 : loss : 0.029903, loss_ce: 0.012376
2022-01-17 12:25:22,027 iteration 3459 : loss : 0.020841, loss_ce: 0.008189
2022-01-17 12:25:22,957 iteration 3460 : loss : 0.020481, loss_ce: 0.008973
2022-01-17 12:25:23,886 iteration 3461 : loss : 0.018645, loss_ce: 0.006358
2022-01-17 12:25:24,807 iteration 3462 : loss : 0.019822, loss_ce: 0.008395
2022-01-17 12:25:25,794 iteration 3463 : loss : 0.029790, loss_ce: 0.010588
2022-01-17 12:25:26,684 iteration 3464 : loss : 0.016062, loss_ce: 0.005405
2022-01-17 12:25:27,684 iteration 3465 : loss : 0.029273, loss_ce: 0.008952
2022-01-17 12:25:28,657 iteration 3466 : loss : 0.017615, loss_ce: 0.005402
2022-01-17 12:25:29,687 iteration 3467 : loss : 0.022246, loss_ce: 0.010288
2022-01-17 12:25:30,624 iteration 3468 : loss : 0.025361, loss_ce: 0.010549
 51%|███████████████▊               | 204/400 [59:40<55:13, 16.91s/it]2022-01-17 12:25:31,576 iteration 3469 : loss : 0.018068, loss_ce: 0.004505
2022-01-17 12:25:32,583 iteration 3470 : loss : 0.025582, loss_ce: 0.007925
2022-01-17 12:25:33,456 iteration 3471 : loss : 0.016996, loss_ce: 0.005794
2022-01-17 12:25:34,434 iteration 3472 : loss : 0.031198, loss_ce: 0.015007
2022-01-17 12:25:35,509 iteration 3473 : loss : 0.044851, loss_ce: 0.019940
2022-01-17 12:25:36,456 iteration 3474 : loss : 0.029515, loss_ce: 0.007569
2022-01-17 12:25:37,481 iteration 3475 : loss : 0.073068, loss_ce: 0.015988
2022-01-17 12:25:38,395 iteration 3476 : loss : 0.022954, loss_ce: 0.006209
2022-01-17 12:25:39,384 iteration 3477 : loss : 0.023166, loss_ce: 0.006249
2022-01-17 12:25:40,340 iteration 3478 : loss : 0.022384, loss_ce: 0.008249
2022-01-17 12:25:41,256 iteration 3479 : loss : 0.031083, loss_ce: 0.011536
2022-01-17 12:25:42,122 iteration 3480 : loss : 0.027734, loss_ce: 0.009794
2022-01-17 12:25:43,064 iteration 3481 : loss : 0.030879, loss_ce: 0.010192
2022-01-17 12:25:44,012 iteration 3482 : loss : 0.022312, loss_ce: 0.008809
2022-01-17 12:25:45,025 iteration 3483 : loss : 0.031326, loss_ce: 0.012109
2022-01-17 12:25:45,884 iteration 3484 : loss : 0.025705, loss_ce: 0.009765
2022-01-17 12:25:45,885 Training Data Eval:
2022-01-17 12:25:50,349   Average segmentation loss on training set: 0.0189
2022-01-17 12:25:50,350 Validation Data Eval:
2022-01-17 12:25:51,861   Average segmentation loss on validation set: 0.0945
2022-01-17 12:25:52,914 iteration 3485 : loss : 0.037090, loss_ce: 0.017255
 51%|█████████████▊             | 205/400 [1:00:02<1:00:12, 18.52s/it]2022-01-17 12:25:53,907 iteration 3486 : loss : 0.031000, loss_ce: 0.012508
2022-01-17 12:25:54,803 iteration 3487 : loss : 0.021131, loss_ce: 0.008888
2022-01-17 12:25:55,733 iteration 3488 : loss : 0.027969, loss_ce: 0.009708
2022-01-17 12:25:56,673 iteration 3489 : loss : 0.028776, loss_ce: 0.009480
2022-01-17 12:25:57,647 iteration 3490 : loss : 0.032848, loss_ce: 0.013848
2022-01-17 12:25:58,657 iteration 3491 : loss : 0.028556, loss_ce: 0.010615
2022-01-17 12:25:59,546 iteration 3492 : loss : 0.022283, loss_ce: 0.007998
2022-01-17 12:26:00,605 iteration 3493 : loss : 0.021641, loss_ce: 0.007721
2022-01-17 12:26:01,580 iteration 3494 : loss : 0.029959, loss_ce: 0.007642
2022-01-17 12:26:02,518 iteration 3495 : loss : 0.021444, loss_ce: 0.006886
2022-01-17 12:26:03,508 iteration 3496 : loss : 0.021770, loss_ce: 0.008253
2022-01-17 12:26:04,491 iteration 3497 : loss : 0.025780, loss_ce: 0.010181
2022-01-17 12:26:05,562 iteration 3498 : loss : 0.024090, loss_ce: 0.008782
2022-01-17 12:26:06,473 iteration 3499 : loss : 0.023282, loss_ce: 0.007835
2022-01-17 12:26:07,332 iteration 3500 : loss : 0.021006, loss_ce: 0.006550
2022-01-17 12:26:08,238 iteration 3501 : loss : 0.021994, loss_ce: 0.006718
2022-01-17 12:26:09,213 iteration 3502 : loss : 0.027377, loss_ce: 0.009840
 52%|██████████████▉              | 206/400 [1:00:19<57:43, 17.86s/it]2022-01-17 12:26:10,223 iteration 3503 : loss : 0.024193, loss_ce: 0.008573
2022-01-17 12:26:11,150 iteration 3504 : loss : 0.020139, loss_ce: 0.005650
2022-01-17 12:26:11,998 iteration 3505 : loss : 0.017270, loss_ce: 0.007481
2022-01-17 12:26:12,972 iteration 3506 : loss : 0.021657, loss_ce: 0.006726
2022-01-17 12:26:13,902 iteration 3507 : loss : 0.022907, loss_ce: 0.006351
2022-01-17 12:26:14,971 iteration 3508 : loss : 0.032890, loss_ce: 0.013609
2022-01-17 12:26:15,938 iteration 3509 : loss : 0.023139, loss_ce: 0.007756
2022-01-17 12:26:16,833 iteration 3510 : loss : 0.021096, loss_ce: 0.007899
2022-01-17 12:26:17,723 iteration 3511 : loss : 0.018489, loss_ce: 0.007914
2022-01-17 12:26:18,746 iteration 3512 : loss : 0.028579, loss_ce: 0.008111
2022-01-17 12:26:19,704 iteration 3513 : loss : 0.018291, loss_ce: 0.005148
2022-01-17 12:26:20,783 iteration 3514 : loss : 0.030471, loss_ce: 0.014303
2022-01-17 12:26:21,705 iteration 3515 : loss : 0.023324, loss_ce: 0.007252
2022-01-17 12:26:22,627 iteration 3516 : loss : 0.017779, loss_ce: 0.006202
2022-01-17 12:26:23,557 iteration 3517 : loss : 0.024525, loss_ce: 0.009764
2022-01-17 12:26:24,494 iteration 3518 : loss : 0.022532, loss_ce: 0.011100
2022-01-17 12:26:25,467 iteration 3519 : loss : 0.020496, loss_ce: 0.007748
 52%|███████████████              | 207/400 [1:00:35<55:53, 17.37s/it]2022-01-17 12:26:26,477 iteration 3520 : loss : 0.024051, loss_ce: 0.008478
2022-01-17 12:26:27,396 iteration 3521 : loss : 0.025744, loss_ce: 0.011704
2022-01-17 12:26:28,278 iteration 3522 : loss : 0.015819, loss_ce: 0.006966
2022-01-17 12:26:29,208 iteration 3523 : loss : 0.016753, loss_ce: 0.005702
2022-01-17 12:26:30,199 iteration 3524 : loss : 0.022505, loss_ce: 0.008155
2022-01-17 12:26:31,251 iteration 3525 : loss : 0.025419, loss_ce: 0.010825
2022-01-17 12:26:32,220 iteration 3526 : loss : 0.030588, loss_ce: 0.010588
2022-01-17 12:26:33,218 iteration 3527 : loss : 0.031511, loss_ce: 0.009390
2022-01-17 12:26:34,304 iteration 3528 : loss : 0.041941, loss_ce: 0.018533
2022-01-17 12:26:35,289 iteration 3529 : loss : 0.023333, loss_ce: 0.005978
2022-01-17 12:26:36,272 iteration 3530 : loss : 0.019906, loss_ce: 0.007443
2022-01-17 12:26:37,171 iteration 3531 : loss : 0.021647, loss_ce: 0.006058
2022-01-17 12:26:38,203 iteration 3532 : loss : 0.025921, loss_ce: 0.011038
2022-01-17 12:26:39,144 iteration 3533 : loss : 0.032382, loss_ce: 0.008236
2022-01-17 12:26:40,124 iteration 3534 : loss : 0.026839, loss_ce: 0.010772
2022-01-17 12:26:41,150 iteration 3535 : loss : 0.022454, loss_ce: 0.008295
2022-01-17 12:26:42,132 iteration 3536 : loss : 0.024257, loss_ce: 0.010006
 52%|███████████████              | 208/400 [1:00:51<54:54, 17.16s/it]2022-01-17 12:26:43,031 iteration 3537 : loss : 0.017299, loss_ce: 0.006949
2022-01-17 12:26:43,897 iteration 3538 : loss : 0.016813, loss_ce: 0.006446
2022-01-17 12:26:44,787 iteration 3539 : loss : 0.014591, loss_ce: 0.006527
2022-01-17 12:26:45,624 iteration 3540 : loss : 0.015836, loss_ce: 0.004219
2022-01-17 12:26:46,654 iteration 3541 : loss : 0.026931, loss_ce: 0.009712
2022-01-17 12:26:47,606 iteration 3542 : loss : 0.020406, loss_ce: 0.008271
2022-01-17 12:26:48,679 iteration 3543 : loss : 0.040051, loss_ce: 0.013117
2022-01-17 12:26:49,550 iteration 3544 : loss : 0.016687, loss_ce: 0.007100
2022-01-17 12:26:50,493 iteration 3545 : loss : 0.017804, loss_ce: 0.007754
2022-01-17 12:26:51,373 iteration 3546 : loss : 0.018783, loss_ce: 0.006761
2022-01-17 12:26:52,326 iteration 3547 : loss : 0.017394, loss_ce: 0.007064
2022-01-17 12:26:53,220 iteration 3548 : loss : 0.020083, loss_ce: 0.006216
2022-01-17 12:26:54,177 iteration 3549 : loss : 0.026669, loss_ce: 0.009515
2022-01-17 12:26:55,173 iteration 3550 : loss : 0.018839, loss_ce: 0.008028
2022-01-17 12:26:56,196 iteration 3551 : loss : 0.022313, loss_ce: 0.006685
2022-01-17 12:26:57,216 iteration 3552 : loss : 0.030932, loss_ce: 0.010462
2022-01-17 12:26:58,233 iteration 3553 : loss : 0.026696, loss_ce: 0.011639
 52%|███████████████▏             | 209/400 [1:01:08<53:37, 16.84s/it]2022-01-17 12:26:59,238 iteration 3554 : loss : 0.017765, loss_ce: 0.007722
2022-01-17 12:27:00,159 iteration 3555 : loss : 0.017581, loss_ce: 0.005839
2022-01-17 12:27:01,081 iteration 3556 : loss : 0.019900, loss_ce: 0.008595
2022-01-17 12:27:02,127 iteration 3557 : loss : 0.037053, loss_ce: 0.009801
2022-01-17 12:27:03,024 iteration 3558 : loss : 0.034074, loss_ce: 0.008799
2022-01-17 12:27:03,959 iteration 3559 : loss : 0.020382, loss_ce: 0.005674
2022-01-17 12:27:04,798 iteration 3560 : loss : 0.017020, loss_ce: 0.008068
2022-01-17 12:27:05,834 iteration 3561 : loss : 0.020744, loss_ce: 0.007595
2022-01-17 12:27:06,753 iteration 3562 : loss : 0.019152, loss_ce: 0.006729
2022-01-17 12:27:07,735 iteration 3563 : loss : 0.021603, loss_ce: 0.006937
2022-01-17 12:27:08,694 iteration 3564 : loss : 0.022374, loss_ce: 0.007716
2022-01-17 12:27:09,769 iteration 3565 : loss : 0.026013, loss_ce: 0.008106
2022-01-17 12:27:10,742 iteration 3566 : loss : 0.023434, loss_ce: 0.007614
2022-01-17 12:27:11,783 iteration 3567 : loss : 0.026278, loss_ce: 0.012081
2022-01-17 12:27:12,788 iteration 3568 : loss : 0.021737, loss_ce: 0.007562
2022-01-17 12:27:13,793 iteration 3569 : loss : 0.030520, loss_ce: 0.007651
2022-01-17 12:27:13,794 Training Data Eval:
2022-01-17 12:27:18,250   Average segmentation loss on training set: 0.0155
2022-01-17 12:27:18,250 Validation Data Eval:
2022-01-17 12:27:19,758   Average segmentation loss on validation set: 0.0906
2022-01-17 12:27:20,738 iteration 3570 : loss : 0.024643, loss_ce: 0.009258
 52%|███████████████▏             | 210/400 [1:01:30<58:42, 18.54s/it]2022-01-17 12:27:21,725 iteration 3571 : loss : 0.017643, loss_ce: 0.006983
2022-01-17 12:27:22,671 iteration 3572 : loss : 0.021419, loss_ce: 0.005452
2022-01-17 12:27:23,620 iteration 3573 : loss : 0.027257, loss_ce: 0.010704
2022-01-17 12:27:24,539 iteration 3574 : loss : 0.019274, loss_ce: 0.007767
2022-01-17 12:27:25,470 iteration 3575 : loss : 0.026227, loss_ce: 0.015019
2022-01-17 12:27:26,440 iteration 3576 : loss : 0.030718, loss_ce: 0.010682
2022-01-17 12:27:27,442 iteration 3577 : loss : 0.018438, loss_ce: 0.008143
2022-01-17 12:27:28,441 iteration 3578 : loss : 0.019285, loss_ce: 0.006775
2022-01-17 12:27:29,365 iteration 3579 : loss : 0.022440, loss_ce: 0.007773
2022-01-17 12:27:30,351 iteration 3580 : loss : 0.021993, loss_ce: 0.007276
2022-01-17 12:27:31,264 iteration 3581 : loss : 0.027198, loss_ce: 0.006483
2022-01-17 12:27:32,208 iteration 3582 : loss : 0.017582, loss_ce: 0.006364
2022-01-17 12:27:33,201 iteration 3583 : loss : 0.020368, loss_ce: 0.008258
2022-01-17 12:27:34,113 iteration 3584 : loss : 0.022168, loss_ce: 0.008032
2022-01-17 12:27:35,051 iteration 3585 : loss : 0.014711, loss_ce: 0.005058
2022-01-17 12:27:35,940 iteration 3586 : loss : 0.020265, loss_ce: 0.007262
2022-01-17 12:27:36,882 iteration 3587 : loss : 0.023678, loss_ce: 0.009280
 53%|███████████████▎             | 211/400 [1:01:46<56:08, 17.82s/it]2022-01-17 12:27:37,785 iteration 3588 : loss : 0.019143, loss_ce: 0.006140
2022-01-17 12:27:38,777 iteration 3589 : loss : 0.032078, loss_ce: 0.010710
2022-01-17 12:27:39,731 iteration 3590 : loss : 0.024760, loss_ce: 0.010179
2022-01-17 12:27:40,661 iteration 3591 : loss : 0.014754, loss_ce: 0.004534
2022-01-17 12:27:41,673 iteration 3592 : loss : 0.018662, loss_ce: 0.007468
2022-01-17 12:27:42,646 iteration 3593 : loss : 0.020005, loss_ce: 0.006576
2022-01-17 12:27:43,620 iteration 3594 : loss : 0.017254, loss_ce: 0.005202
2022-01-17 12:27:44,714 iteration 3595 : loss : 0.041847, loss_ce: 0.008945
2022-01-17 12:27:45,582 iteration 3596 : loss : 0.024425, loss_ce: 0.010442
2022-01-17 12:27:46,617 iteration 3597 : loss : 0.023933, loss_ce: 0.008404
2022-01-17 12:27:47,569 iteration 3598 : loss : 0.020589, loss_ce: 0.009876
2022-01-17 12:27:48,540 iteration 3599 : loss : 0.030602, loss_ce: 0.012518
2022-01-17 12:27:49,472 iteration 3600 : loss : 0.017124, loss_ce: 0.007660
2022-01-17 12:27:50,425 iteration 3601 : loss : 0.022660, loss_ce: 0.010344
2022-01-17 12:27:51,347 iteration 3602 : loss : 0.025779, loss_ce: 0.011434
2022-01-17 12:27:52,251 iteration 3603 : loss : 0.016878, loss_ce: 0.006434
2022-01-17 12:27:53,145 iteration 3604 : loss : 0.013797, loss_ce: 0.005048
 53%|███████████████▎             | 212/400 [1:02:03<54:23, 17.36s/it]2022-01-17 12:27:54,118 iteration 3605 : loss : 0.018226, loss_ce: 0.007063
2022-01-17 12:27:55,068 iteration 3606 : loss : 0.025841, loss_ce: 0.008820
2022-01-17 12:27:55,950 iteration 3607 : loss : 0.017473, loss_ce: 0.005964
2022-01-17 12:27:56,834 iteration 3608 : loss : 0.019781, loss_ce: 0.008442
2022-01-17 12:27:57,810 iteration 3609 : loss : 0.020752, loss_ce: 0.006064
2022-01-17 12:27:58,720 iteration 3610 : loss : 0.020638, loss_ce: 0.009455
2022-01-17 12:27:59,699 iteration 3611 : loss : 0.024413, loss_ce: 0.009652
2022-01-17 12:28:00,706 iteration 3612 : loss : 0.018837, loss_ce: 0.005315
2022-01-17 12:28:01,663 iteration 3613 : loss : 0.024419, loss_ce: 0.007698
2022-01-17 12:28:02,653 iteration 3614 : loss : 0.013950, loss_ce: 0.003854
2022-01-17 12:28:03,570 iteration 3615 : loss : 0.024052, loss_ce: 0.008318
2022-01-17 12:28:04,594 iteration 3616 : loss : 0.023707, loss_ce: 0.009401
2022-01-17 12:28:05,520 iteration 3617 : loss : 0.021170, loss_ce: 0.008210
2022-01-17 12:28:06,462 iteration 3618 : loss : 0.021387, loss_ce: 0.009996
2022-01-17 12:28:07,398 iteration 3619 : loss : 0.018420, loss_ce: 0.007465
2022-01-17 12:28:08,380 iteration 3620 : loss : 0.023833, loss_ce: 0.008940
2022-01-17 12:28:09,318 iteration 3621 : loss : 0.022272, loss_ce: 0.009267
 53%|███████████████▍             | 213/400 [1:02:19<52:59, 17.00s/it]2022-01-17 12:28:10,372 iteration 3622 : loss : 0.026978, loss_ce: 0.009912
2022-01-17 12:28:11,323 iteration 3623 : loss : 0.017949, loss_ce: 0.007058
2022-01-17 12:28:12,350 iteration 3624 : loss : 0.018129, loss_ce: 0.005416
2022-01-17 12:28:13,362 iteration 3625 : loss : 0.022991, loss_ce: 0.009149
2022-01-17 12:28:14,297 iteration 3626 : loss : 0.019541, loss_ce: 0.007000
2022-01-17 12:28:15,279 iteration 3627 : loss : 0.021978, loss_ce: 0.010786
2022-01-17 12:28:16,246 iteration 3628 : loss : 0.020466, loss_ce: 0.006412
2022-01-17 12:28:17,268 iteration 3629 : loss : 0.020427, loss_ce: 0.008039
2022-01-17 12:28:18,210 iteration 3630 : loss : 0.018064, loss_ce: 0.006880
2022-01-17 12:28:19,083 iteration 3631 : loss : 0.016825, loss_ce: 0.006883
2022-01-17 12:28:19,965 iteration 3632 : loss : 0.017209, loss_ce: 0.007401
2022-01-17 12:28:20,981 iteration 3633 : loss : 0.039950, loss_ce: 0.014134
2022-01-17 12:28:21,927 iteration 3634 : loss : 0.021660, loss_ce: 0.007678
2022-01-17 12:28:22,834 iteration 3635 : loss : 0.020699, loss_ce: 0.006715
2022-01-17 12:28:23,741 iteration 3636 : loss : 0.026092, loss_ce: 0.009960
2022-01-17 12:28:24,752 iteration 3637 : loss : 0.035700, loss_ce: 0.010561
2022-01-17 12:28:25,642 iteration 3638 : loss : 0.019288, loss_ce: 0.006213
 54%|███████████████▌             | 214/400 [1:02:35<52:04, 16.80s/it]2022-01-17 12:28:26,606 iteration 3639 : loss : 0.022731, loss_ce: 0.011120
2022-01-17 12:28:27,603 iteration 3640 : loss : 0.022668, loss_ce: 0.008375
2022-01-17 12:28:28,557 iteration 3641 : loss : 0.023144, loss_ce: 0.006880
2022-01-17 12:28:29,551 iteration 3642 : loss : 0.023697, loss_ce: 0.009415
2022-01-17 12:28:30,494 iteration 3643 : loss : 0.028957, loss_ce: 0.013649
2022-01-17 12:28:31,431 iteration 3644 : loss : 0.019183, loss_ce: 0.008594
2022-01-17 12:28:32,340 iteration 3645 : loss : 0.017806, loss_ce: 0.006922
2022-01-17 12:28:33,301 iteration 3646 : loss : 0.024795, loss_ce: 0.009195
2022-01-17 12:28:34,296 iteration 3647 : loss : 0.024904, loss_ce: 0.009580
2022-01-17 12:28:35,359 iteration 3648 : loss : 0.027128, loss_ce: 0.011302
2022-01-17 12:28:36,323 iteration 3649 : loss : 0.028931, loss_ce: 0.009842
2022-01-17 12:28:37,274 iteration 3650 : loss : 0.021626, loss_ce: 0.006809
2022-01-17 12:28:38,247 iteration 3651 : loss : 0.020167, loss_ce: 0.007636
2022-01-17 12:28:39,167 iteration 3652 : loss : 0.017866, loss_ce: 0.007591
2022-01-17 12:28:40,180 iteration 3653 : loss : 0.033590, loss_ce: 0.007705
2022-01-17 12:28:41,136 iteration 3654 : loss : 0.019614, loss_ce: 0.005019
2022-01-17 12:28:41,136 Training Data Eval:
2022-01-17 12:28:45,596   Average segmentation loss on training set: 0.0142
2022-01-17 12:28:45,596 Validation Data Eval:
2022-01-17 12:28:47,101   Average segmentation loss on validation set: 0.0869
2022-01-17 12:28:47,953 iteration 3655 : loss : 0.023609, loss_ce: 0.009491
 54%|███████████████▌             | 215/400 [1:02:57<56:53, 18.45s/it]2022-01-17 12:28:49,007 iteration 3656 : loss : 0.036825, loss_ce: 0.006370
2022-01-17 12:28:49,927 iteration 3657 : loss : 0.020806, loss_ce: 0.009626
2022-01-17 12:28:50,879 iteration 3658 : loss : 0.023452, loss_ce: 0.008962
2022-01-17 12:28:51,871 iteration 3659 : loss : 0.017811, loss_ce: 0.005905
2022-01-17 12:28:52,932 iteration 3660 : loss : 0.023997, loss_ce: 0.007748
2022-01-17 12:28:53,998 iteration 3661 : loss : 0.019782, loss_ce: 0.008383
2022-01-17 12:28:54,868 iteration 3662 : loss : 0.021078, loss_ce: 0.007750
2022-01-17 12:28:55,785 iteration 3663 : loss : 0.019210, loss_ce: 0.006110
2022-01-17 12:28:56,718 iteration 3664 : loss : 0.023007, loss_ce: 0.006718
2022-01-17 12:28:57,662 iteration 3665 : loss : 0.023224, loss_ce: 0.009160
2022-01-17 12:28:58,729 iteration 3666 : loss : 0.029158, loss_ce: 0.012478
2022-01-17 12:28:59,718 iteration 3667 : loss : 0.025627, loss_ce: 0.010044
2022-01-17 12:29:00,718 iteration 3668 : loss : 0.023449, loss_ce: 0.008251
2022-01-17 12:29:01,682 iteration 3669 : loss : 0.023184, loss_ce: 0.011177
2022-01-17 12:29:02,599 iteration 3670 : loss : 0.023286, loss_ce: 0.006464
2022-01-17 12:29:03,595 iteration 3671 : loss : 0.023314, loss_ce: 0.008221
2022-01-17 12:29:04,497 iteration 3672 : loss : 0.018788, loss_ce: 0.007651
 54%|███████████████▋             | 216/400 [1:03:14<54:49, 17.88s/it]2022-01-17 12:29:05,475 iteration 3673 : loss : 0.021840, loss_ce: 0.010266
2022-01-17 12:29:06,437 iteration 3674 : loss : 0.028689, loss_ce: 0.011616
2022-01-17 12:29:07,376 iteration 3675 : loss : 0.020109, loss_ce: 0.011193
2022-01-17 12:29:08,313 iteration 3676 : loss : 0.017697, loss_ce: 0.005221
2022-01-17 12:29:09,251 iteration 3677 : loss : 0.016584, loss_ce: 0.008188
2022-01-17 12:29:10,281 iteration 3678 : loss : 0.025367, loss_ce: 0.008677
2022-01-17 12:29:11,207 iteration 3679 : loss : 0.019278, loss_ce: 0.007096
2022-01-17 12:29:12,127 iteration 3680 : loss : 0.023320, loss_ce: 0.006283
2022-01-17 12:29:13,123 iteration 3681 : loss : 0.018985, loss_ce: 0.005946
2022-01-17 12:29:14,047 iteration 3682 : loss : 0.019819, loss_ce: 0.007836
2022-01-17 12:29:15,051 iteration 3683 : loss : 0.048147, loss_ce: 0.004301
2022-01-17 12:29:15,975 iteration 3684 : loss : 0.012278, loss_ce: 0.003895
2022-01-17 12:29:16,906 iteration 3685 : loss : 0.029619, loss_ce: 0.013787
2022-01-17 12:29:17,881 iteration 3686 : loss : 0.023073, loss_ce: 0.009154
2022-01-17 12:29:18,829 iteration 3687 : loss : 0.022802, loss_ce: 0.007486
2022-01-17 12:29:19,765 iteration 3688 : loss : 0.028409, loss_ce: 0.013882
2022-01-17 12:29:20,647 iteration 3689 : loss : 0.019490, loss_ce: 0.006499
 54%|███████████████▋             | 217/400 [1:03:30<52:57, 17.36s/it]2022-01-17 12:29:21,591 iteration 3690 : loss : 0.016523, loss_ce: 0.003909
2022-01-17 12:29:22,626 iteration 3691 : loss : 0.032209, loss_ce: 0.005983
2022-01-17 12:29:23,588 iteration 3692 : loss : 0.017781, loss_ce: 0.007515
2022-01-17 12:29:24,612 iteration 3693 : loss : 0.046701, loss_ce: 0.017206
2022-01-17 12:29:25,564 iteration 3694 : loss : 0.023188, loss_ce: 0.010096
2022-01-17 12:29:26,466 iteration 3695 : loss : 0.019729, loss_ce: 0.007979
2022-01-17 12:29:27,463 iteration 3696 : loss : 0.027134, loss_ce: 0.013394
2022-01-17 12:29:28,398 iteration 3697 : loss : 0.029699, loss_ce: 0.007726
2022-01-17 12:29:29,354 iteration 3698 : loss : 0.021910, loss_ce: 0.008591
2022-01-17 12:29:30,375 iteration 3699 : loss : 0.029002, loss_ce: 0.012414
2022-01-17 12:29:31,323 iteration 3700 : loss : 0.021080, loss_ce: 0.009275
2022-01-17 12:29:32,243 iteration 3701 : loss : 0.018226, loss_ce: 0.006449
2022-01-17 12:29:33,161 iteration 3702 : loss : 0.027112, loss_ce: 0.010810
2022-01-17 12:29:34,221 iteration 3703 : loss : 0.030113, loss_ce: 0.012710
2022-01-17 12:29:35,125 iteration 3704 : loss : 0.038177, loss_ce: 0.010458
2022-01-17 12:29:36,026 iteration 3705 : loss : 0.020812, loss_ce: 0.007060
2022-01-17 12:29:36,922 iteration 3706 : loss : 0.016567, loss_ce: 0.004502
 55%|███████████████▊             | 218/400 [1:03:46<51:39, 17.03s/it]2022-01-17 12:29:37,898 iteration 3707 : loss : 0.024820, loss_ce: 0.008337
2022-01-17 12:29:38,857 iteration 3708 : loss : 0.028259, loss_ce: 0.010803
2022-01-17 12:29:39,813 iteration 3709 : loss : 0.022718, loss_ce: 0.007152
2022-01-17 12:29:40,820 iteration 3710 : loss : 0.024934, loss_ce: 0.008646
2022-01-17 12:29:41,747 iteration 3711 : loss : 0.016709, loss_ce: 0.006178
2022-01-17 12:29:42,722 iteration 3712 : loss : 0.048640, loss_ce: 0.017211
2022-01-17 12:29:43,623 iteration 3713 : loss : 0.019824, loss_ce: 0.007152
2022-01-17 12:29:44,543 iteration 3714 : loss : 0.028630, loss_ce: 0.009783
2022-01-17 12:29:45,509 iteration 3715 : loss : 0.035135, loss_ce: 0.012692
2022-01-17 12:29:46,424 iteration 3716 : loss : 0.024227, loss_ce: 0.009790
2022-01-17 12:29:47,393 iteration 3717 : loss : 0.032525, loss_ce: 0.013013
2022-01-17 12:29:48,412 iteration 3718 : loss : 0.037312, loss_ce: 0.017330
2022-01-17 12:29:49,310 iteration 3719 : loss : 0.017587, loss_ce: 0.004736
2022-01-17 12:29:50,285 iteration 3720 : loss : 0.020452, loss_ce: 0.010090
2022-01-17 12:29:51,245 iteration 3721 : loss : 0.021203, loss_ce: 0.008000
2022-01-17 12:29:52,179 iteration 3722 : loss : 0.017859, loss_ce: 0.006695
2022-01-17 12:29:53,090 iteration 3723 : loss : 0.036478, loss_ce: 0.011736
 55%|███████████████▉             | 219/400 [1:04:02<50:36, 16.77s/it]2022-01-17 12:29:54,005 iteration 3724 : loss : 0.017826, loss_ce: 0.007874
2022-01-17 12:29:54,911 iteration 3725 : loss : 0.025945, loss_ce: 0.010608
2022-01-17 12:29:55,923 iteration 3726 : loss : 0.027492, loss_ce: 0.014668
2022-01-17 12:29:56,879 iteration 3727 : loss : 0.031332, loss_ce: 0.012841
2022-01-17 12:29:57,850 iteration 3728 : loss : 0.019840, loss_ce: 0.005111
2022-01-17 12:29:58,758 iteration 3729 : loss : 0.015077, loss_ce: 0.004020
2022-01-17 12:29:59,695 iteration 3730 : loss : 0.022419, loss_ce: 0.009425
2022-01-17 12:30:00,622 iteration 3731 : loss : 0.027724, loss_ce: 0.008782
2022-01-17 12:30:01,598 iteration 3732 : loss : 0.022358, loss_ce: 0.007201
2022-01-17 12:30:02,495 iteration 3733 : loss : 0.020272, loss_ce: 0.007057
2022-01-17 12:30:03,455 iteration 3734 : loss : 0.029989, loss_ce: 0.011220
2022-01-17 12:30:04,404 iteration 3735 : loss : 0.019794, loss_ce: 0.005673
2022-01-17 12:30:05,407 iteration 3736 : loss : 0.026298, loss_ce: 0.011753
2022-01-17 12:30:06,311 iteration 3737 : loss : 0.021586, loss_ce: 0.006758
2022-01-17 12:30:07,253 iteration 3738 : loss : 0.016889, loss_ce: 0.005477
2022-01-17 12:30:08,152 iteration 3739 : loss : 0.020988, loss_ce: 0.007677
2022-01-17 12:30:08,152 Training Data Eval:
2022-01-17 12:30:12,619   Average segmentation loss on training set: 0.0141
2022-01-17 12:30:12,619 Validation Data Eval:
2022-01-17 12:30:14,131   Average segmentation loss on validation set: 0.0801
2022-01-17 12:30:15,236 iteration 3740 : loss : 0.030877, loss_ce: 0.014194
 55%|███████████████▉             | 220/400 [1:04:25<55:09, 18.38s/it]2022-01-17 12:30:16,354 iteration 3741 : loss : 0.035146, loss_ce: 0.009827
2022-01-17 12:30:17,295 iteration 3742 : loss : 0.022048, loss_ce: 0.010564
2022-01-17 12:30:18,240 iteration 3743 : loss : 0.034409, loss_ce: 0.011429
2022-01-17 12:30:19,243 iteration 3744 : loss : 0.027577, loss_ce: 0.010809
2022-01-17 12:30:20,262 iteration 3745 : loss : 0.026256, loss_ce: 0.007598
2022-01-17 12:30:21,283 iteration 3746 : loss : 0.021959, loss_ce: 0.008632
2022-01-17 12:30:22,220 iteration 3747 : loss : 0.025395, loss_ce: 0.007726
2022-01-17 12:30:23,148 iteration 3748 : loss : 0.018167, loss_ce: 0.008600
2022-01-17 12:30:24,146 iteration 3749 : loss : 0.024962, loss_ce: 0.007772
2022-01-17 12:30:25,177 iteration 3750 : loss : 0.029762, loss_ce: 0.013715
2022-01-17 12:30:26,156 iteration 3751 : loss : 0.028820, loss_ce: 0.008283
2022-01-17 12:30:27,088 iteration 3752 : loss : 0.033353, loss_ce: 0.009083
2022-01-17 12:30:27,990 iteration 3753 : loss : 0.023136, loss_ce: 0.007102
2022-01-17 12:30:28,951 iteration 3754 : loss : 0.026726, loss_ce: 0.008762
2022-01-17 12:30:29,961 iteration 3755 : loss : 0.021064, loss_ce: 0.009056
2022-01-17 12:30:30,843 iteration 3756 : loss : 0.021354, loss_ce: 0.009768
2022-01-17 12:30:31,746 iteration 3757 : loss : 0.020177, loss_ce: 0.007879
 55%|████████████████             | 221/400 [1:04:41<53:10, 17.82s/it]2022-01-17 12:30:32,812 iteration 3758 : loss : 0.024466, loss_ce: 0.007944
2022-01-17 12:30:33,714 iteration 3759 : loss : 0.021129, loss_ce: 0.006993
2022-01-17 12:30:34,646 iteration 3760 : loss : 0.020011, loss_ce: 0.008100
2022-01-17 12:30:35,641 iteration 3761 : loss : 0.024331, loss_ce: 0.009097
2022-01-17 12:30:36,655 iteration 3762 : loss : 0.026252, loss_ce: 0.015486
2022-01-17 12:30:37,705 iteration 3763 : loss : 0.024500, loss_ce: 0.007226
2022-01-17 12:30:38,645 iteration 3764 : loss : 0.032925, loss_ce: 0.011983
2022-01-17 12:30:39,546 iteration 3765 : loss : 0.020184, loss_ce: 0.008589
2022-01-17 12:30:40,550 iteration 3766 : loss : 0.030359, loss_ce: 0.008973
2022-01-17 12:30:41,504 iteration 3767 : loss : 0.018401, loss_ce: 0.007144
2022-01-17 12:30:42,415 iteration 3768 : loss : 0.022756, loss_ce: 0.007116
2022-01-17 12:30:43,334 iteration 3769 : loss : 0.019012, loss_ce: 0.008550
2022-01-17 12:30:44,317 iteration 3770 : loss : 0.026447, loss_ce: 0.005774
2022-01-17 12:30:45,391 iteration 3771 : loss : 0.039628, loss_ce: 0.013847
2022-01-17 12:30:46,401 iteration 3772 : loss : 0.024574, loss_ce: 0.006462
2022-01-17 12:30:47,377 iteration 3773 : loss : 0.015368, loss_ce: 0.005418
2022-01-17 12:30:48,391 iteration 3774 : loss : 0.034519, loss_ce: 0.016424
 56%|████████████████             | 222/400 [1:04:58<51:49, 17.47s/it]2022-01-17 12:30:49,351 iteration 3775 : loss : 0.022492, loss_ce: 0.008812
2022-01-17 12:30:50,213 iteration 3776 : loss : 0.024972, loss_ce: 0.010210
2022-01-17 12:30:51,137 iteration 3777 : loss : 0.020032, loss_ce: 0.005535
2022-01-17 12:30:52,046 iteration 3778 : loss : 0.018652, loss_ce: 0.007693
2022-01-17 12:30:52,957 iteration 3779 : loss : 0.023143, loss_ce: 0.010448
2022-01-17 12:30:53,928 iteration 3780 : loss : 0.024652, loss_ce: 0.008002
2022-01-17 12:30:54,892 iteration 3781 : loss : 0.029257, loss_ce: 0.012550
2022-01-17 12:30:55,870 iteration 3782 : loss : 0.058816, loss_ce: 0.012782
2022-01-17 12:30:56,846 iteration 3783 : loss : 0.017711, loss_ce: 0.007863
2022-01-17 12:30:57,833 iteration 3784 : loss : 0.018448, loss_ce: 0.008408
2022-01-17 12:30:58,760 iteration 3785 : loss : 0.026463, loss_ce: 0.010580
2022-01-17 12:30:59,682 iteration 3786 : loss : 0.017873, loss_ce: 0.006969
2022-01-17 12:31:00,594 iteration 3787 : loss : 0.020933, loss_ce: 0.006861
2022-01-17 12:31:01,616 iteration 3788 : loss : 0.029816, loss_ce: 0.007053
2022-01-17 12:31:02,569 iteration 3789 : loss : 0.017958, loss_ce: 0.004568
2022-01-17 12:31:03,563 iteration 3790 : loss : 0.024353, loss_ce: 0.009071
2022-01-17 12:31:04,539 iteration 3791 : loss : 0.021789, loss_ce: 0.009010
 56%|████████████████▏            | 223/400 [1:05:14<50:22, 17.07s/it]2022-01-17 12:31:05,484 iteration 3792 : loss : 0.017771, loss_ce: 0.006391
2022-01-17 12:31:06,485 iteration 3793 : loss : 0.020294, loss_ce: 0.006066
2022-01-17 12:31:07,465 iteration 3794 : loss : 0.025777, loss_ce: 0.010674
2022-01-17 12:31:08,417 iteration 3795 : loss : 0.017120, loss_ce: 0.005443
2022-01-17 12:31:09,273 iteration 3796 : loss : 0.016946, loss_ce: 0.005783
2022-01-17 12:31:10,202 iteration 3797 : loss : 0.022781, loss_ce: 0.008853
2022-01-17 12:31:11,081 iteration 3798 : loss : 0.017084, loss_ce: 0.006383
2022-01-17 12:31:12,012 iteration 3799 : loss : 0.028528, loss_ce: 0.010013
2022-01-17 12:31:12,946 iteration 3800 : loss : 0.020499, loss_ce: 0.005298
2022-01-17 12:31:13,872 iteration 3801 : loss : 0.030065, loss_ce: 0.009087
2022-01-17 12:31:14,789 iteration 3802 : loss : 0.019737, loss_ce: 0.009149
2022-01-17 12:31:15,734 iteration 3803 : loss : 0.015249, loss_ce: 0.004788
2022-01-17 12:31:16,677 iteration 3804 : loss : 0.021919, loss_ce: 0.008617
2022-01-17 12:31:17,595 iteration 3805 : loss : 0.019333, loss_ce: 0.007261
2022-01-17 12:31:18,512 iteration 3806 : loss : 0.020440, loss_ce: 0.009726
2022-01-17 12:31:19,496 iteration 3807 : loss : 0.024905, loss_ce: 0.008524
2022-01-17 12:31:20,451 iteration 3808 : loss : 0.022489, loss_ce: 0.008899
 56%|████████████████▏            | 224/400 [1:05:30<49:03, 16.72s/it]2022-01-17 12:31:21,376 iteration 3809 : loss : 0.015412, loss_ce: 0.004825
2022-01-17 12:31:22,294 iteration 3810 : loss : 0.020484, loss_ce: 0.007856
2022-01-17 12:31:23,236 iteration 3811 : loss : 0.020773, loss_ce: 0.006102
2022-01-17 12:31:24,200 iteration 3812 : loss : 0.024893, loss_ce: 0.013624
2022-01-17 12:31:25,134 iteration 3813 : loss : 0.018002, loss_ce: 0.008135
2022-01-17 12:31:26,115 iteration 3814 : loss : 0.024482, loss_ce: 0.008213
2022-01-17 12:31:27,063 iteration 3815 : loss : 0.025472, loss_ce: 0.009405
2022-01-17 12:31:28,022 iteration 3816 : loss : 0.018334, loss_ce: 0.006607
2022-01-17 12:31:28,915 iteration 3817 : loss : 0.015626, loss_ce: 0.005771
2022-01-17 12:31:29,888 iteration 3818 : loss : 0.018227, loss_ce: 0.008123
2022-01-17 12:31:30,877 iteration 3819 : loss : 0.024344, loss_ce: 0.009684
2022-01-17 12:31:31,851 iteration 3820 : loss : 0.024514, loss_ce: 0.009102
2022-01-17 12:31:32,834 iteration 3821 : loss : 0.024038, loss_ce: 0.008511
2022-01-17 12:31:33,747 iteration 3822 : loss : 0.027825, loss_ce: 0.009264
2022-01-17 12:31:34,787 iteration 3823 : loss : 0.023333, loss_ce: 0.006087
2022-01-17 12:31:35,756 iteration 3824 : loss : 0.021722, loss_ce: 0.006940
2022-01-17 12:31:35,756 Training Data Eval:
2022-01-17 12:31:40,229   Average segmentation loss on training set: 0.0141
2022-01-17 12:31:40,230 Validation Data Eval:
2022-01-17 12:31:41,746   Average segmentation loss on validation set: 0.1070
2022-01-17 12:31:42,777 iteration 3825 : loss : 0.023337, loss_ce: 0.008321
 56%|████████████████▎            | 225/400 [1:05:52<53:40, 18.40s/it]2022-01-17 12:31:43,789 iteration 3826 : loss : 0.020948, loss_ce: 0.009348
2022-01-17 12:31:44,699 iteration 3827 : loss : 0.020360, loss_ce: 0.006505
2022-01-17 12:31:45,666 iteration 3828 : loss : 0.019648, loss_ce: 0.006789
2022-01-17 12:31:46,628 iteration 3829 : loss : 0.017613, loss_ce: 0.005092
2022-01-17 12:31:47,547 iteration 3830 : loss : 0.014486, loss_ce: 0.005569
2022-01-17 12:31:48,448 iteration 3831 : loss : 0.015291, loss_ce: 0.005420
2022-01-17 12:31:49,347 iteration 3832 : loss : 0.023486, loss_ce: 0.005290
2022-01-17 12:31:50,295 iteration 3833 : loss : 0.013359, loss_ce: 0.005972
2022-01-17 12:31:51,283 iteration 3834 : loss : 0.030977, loss_ce: 0.014228
2022-01-17 12:31:52,251 iteration 3835 : loss : 0.019538, loss_ce: 0.006420
2022-01-17 12:31:53,202 iteration 3836 : loss : 0.017870, loss_ce: 0.007011
2022-01-17 12:31:54,184 iteration 3837 : loss : 0.018758, loss_ce: 0.006297
2022-01-17 12:31:55,228 iteration 3838 : loss : 0.026453, loss_ce: 0.010617
2022-01-17 12:31:56,169 iteration 3839 : loss : 0.020303, loss_ce: 0.009103
2022-01-17 12:31:57,120 iteration 3840 : loss : 0.042961, loss_ce: 0.008629
2022-01-17 12:31:58,033 iteration 3841 : loss : 0.017551, loss_ce: 0.006138
2022-01-17 12:31:59,008 iteration 3842 : loss : 0.026213, loss_ce: 0.012605
 56%|████████████████▍            | 226/400 [1:06:08<51:28, 17.75s/it]2022-01-17 12:31:59,962 iteration 3843 : loss : 0.017354, loss_ce: 0.006500
2022-01-17 12:32:00,960 iteration 3844 : loss : 0.027590, loss_ce: 0.007305
2022-01-17 12:32:01,948 iteration 3845 : loss : 0.017430, loss_ce: 0.008005
2022-01-17 12:32:02,855 iteration 3846 : loss : 0.016411, loss_ce: 0.005859
2022-01-17 12:32:03,857 iteration 3847 : loss : 0.020824, loss_ce: 0.008152
2022-01-17 12:32:04,854 iteration 3848 : loss : 0.017437, loss_ce: 0.008182
2022-01-17 12:32:05,914 iteration 3849 : loss : 0.022592, loss_ce: 0.009462
2022-01-17 12:32:06,948 iteration 3850 : loss : 0.032669, loss_ce: 0.007859
2022-01-17 12:32:07,903 iteration 3851 : loss : 0.016456, loss_ce: 0.007422
2022-01-17 12:32:08,877 iteration 3852 : loss : 0.027346, loss_ce: 0.008707
2022-01-17 12:32:09,778 iteration 3853 : loss : 0.022926, loss_ce: 0.006552
2022-01-17 12:32:10,765 iteration 3854 : loss : 0.022259, loss_ce: 0.006434
2022-01-17 12:32:11,858 iteration 3855 : loss : 0.029698, loss_ce: 0.009287
2022-01-17 12:32:12,677 iteration 3856 : loss : 0.016946, loss_ce: 0.007451
2022-01-17 12:32:13,611 iteration 3857 : loss : 0.018574, loss_ce: 0.007947
2022-01-17 12:32:14,470 iteration 3858 : loss : 0.018160, loss_ce: 0.007106
2022-01-17 12:32:15,409 iteration 3859 : loss : 0.019428, loss_ce: 0.009051
 57%|████████████████▍            | 227/400 [1:06:25<50:01, 17.35s/it]2022-01-17 12:32:16,396 iteration 3860 : loss : 0.018668, loss_ce: 0.006940
2022-01-17 12:32:17,413 iteration 3861 : loss : 0.027595, loss_ce: 0.011256
2022-01-17 12:32:18,396 iteration 3862 : loss : 0.025189, loss_ce: 0.008271
2022-01-17 12:32:19,370 iteration 3863 : loss : 0.019598, loss_ce: 0.006348
2022-01-17 12:32:20,366 iteration 3864 : loss : 0.021329, loss_ce: 0.006986
2022-01-17 12:32:21,313 iteration 3865 : loss : 0.019004, loss_ce: 0.006486
2022-01-17 12:32:22,383 iteration 3866 : loss : 0.026452, loss_ce: 0.008228
2022-01-17 12:32:23,315 iteration 3867 : loss : 0.031209, loss_ce: 0.010561
2022-01-17 12:32:24,316 iteration 3868 : loss : 0.023293, loss_ce: 0.006655
2022-01-17 12:32:25,299 iteration 3869 : loss : 0.018540, loss_ce: 0.008859
2022-01-17 12:32:26,304 iteration 3870 : loss : 0.019152, loss_ce: 0.008070
2022-01-17 12:32:27,290 iteration 3871 : loss : 0.029668, loss_ce: 0.009654
2022-01-17 12:32:28,199 iteration 3872 : loss : 0.017373, loss_ce: 0.006559
2022-01-17 12:32:29,113 iteration 3873 : loss : 0.020479, loss_ce: 0.010823
2022-01-17 12:32:30,089 iteration 3874 : loss : 0.034813, loss_ce: 0.012399
2022-01-17 12:32:31,065 iteration 3875 : loss : 0.025342, loss_ce: 0.009768
2022-01-17 12:32:32,046 iteration 3876 : loss : 0.020909, loss_ce: 0.006039
 57%|████████████████▌            | 228/400 [1:06:41<49:07, 17.14s/it]2022-01-17 12:32:33,007 iteration 3877 : loss : 0.021180, loss_ce: 0.007863
2022-01-17 12:32:33,988 iteration 3878 : loss : 0.024653, loss_ce: 0.008976
2022-01-17 12:32:34,907 iteration 3879 : loss : 0.018709, loss_ce: 0.006589
2022-01-17 12:32:35,892 iteration 3880 : loss : 0.032161, loss_ce: 0.013503
2022-01-17 12:32:36,808 iteration 3881 : loss : 0.017938, loss_ce: 0.007486
2022-01-17 12:32:37,849 iteration 3882 : loss : 0.042108, loss_ce: 0.008919
2022-01-17 12:32:38,856 iteration 3883 : loss : 0.024893, loss_ce: 0.007098
2022-01-17 12:32:39,835 iteration 3884 : loss : 0.017735, loss_ce: 0.006628
2022-01-17 12:32:40,840 iteration 3885 : loss : 0.077002, loss_ce: 0.015673
2022-01-17 12:32:41,842 iteration 3886 : loss : 0.027907, loss_ce: 0.010972
2022-01-17 12:32:42,737 iteration 3887 : loss : 0.019444, loss_ce: 0.007423
2022-01-17 12:32:43,730 iteration 3888 : loss : 0.022501, loss_ce: 0.012371
2022-01-17 12:32:44,701 iteration 3889 : loss : 0.018467, loss_ce: 0.006355
2022-01-17 12:32:45,776 iteration 3890 : loss : 0.025872, loss_ce: 0.006484
2022-01-17 12:32:46,706 iteration 3891 : loss : 0.027153, loss_ce: 0.010064
2022-01-17 12:32:47,666 iteration 3892 : loss : 0.019724, loss_ce: 0.007400
2022-01-17 12:32:48,665 iteration 3893 : loss : 0.028450, loss_ce: 0.009461
 57%|████████████████▌            | 229/400 [1:06:58<48:23, 16.98s/it]2022-01-17 12:32:49,647 iteration 3894 : loss : 0.023186, loss_ce: 0.006504
2022-01-17 12:32:50,558 iteration 3895 : loss : 0.020604, loss_ce: 0.007505
2022-01-17 12:32:51,510 iteration 3896 : loss : 0.026587, loss_ce: 0.010503
2022-01-17 12:32:52,504 iteration 3897 : loss : 0.024340, loss_ce: 0.009985
2022-01-17 12:32:53,492 iteration 3898 : loss : 0.025765, loss_ce: 0.007502
2022-01-17 12:32:54,373 iteration 3899 : loss : 0.019582, loss_ce: 0.007175
2022-01-17 12:32:55,292 iteration 3900 : loss : 0.024484, loss_ce: 0.008318
2022-01-17 12:32:56,197 iteration 3901 : loss : 0.019878, loss_ce: 0.008259
2022-01-17 12:32:57,107 iteration 3902 : loss : 0.021891, loss_ce: 0.007386
2022-01-17 12:32:57,984 iteration 3903 : loss : 0.024295, loss_ce: 0.006873
2022-01-17 12:32:58,919 iteration 3904 : loss : 0.020015, loss_ce: 0.005833
2022-01-17 12:32:59,859 iteration 3905 : loss : 0.026248, loss_ce: 0.008868
2022-01-17 12:33:00,726 iteration 3906 : loss : 0.014201, loss_ce: 0.005671
2022-01-17 12:33:01,577 iteration 3907 : loss : 0.015022, loss_ce: 0.005088
2022-01-17 12:33:02,453 iteration 3908 : loss : 0.025584, loss_ce: 0.008783
2022-01-17 12:33:03,393 iteration 3909 : loss : 0.022948, loss_ce: 0.011112
2022-01-17 12:33:03,393 Training Data Eval:
2022-01-17 12:33:07,869   Average segmentation loss on training set: 0.0145
2022-01-17 12:33:07,870 Validation Data Eval:
2022-01-17 12:33:09,375   Average segmentation loss on validation set: 0.1046
2022-01-17 12:33:10,392 iteration 3910 : loss : 0.020583, loss_ce: 0.006527
 57%|████████████████▋            | 230/400 [1:07:20<52:08, 18.41s/it]2022-01-17 12:33:11,335 iteration 3911 : loss : 0.015668, loss_ce: 0.006501
2022-01-17 12:33:12,313 iteration 3912 : loss : 0.024234, loss_ce: 0.009249
2022-01-17 12:33:13,261 iteration 3913 : loss : 0.029478, loss_ce: 0.011605
2022-01-17 12:33:14,199 iteration 3914 : loss : 0.017781, loss_ce: 0.008300
2022-01-17 12:33:15,134 iteration 3915 : loss : 0.024818, loss_ce: 0.010401
2022-01-17 12:33:16,038 iteration 3916 : loss : 0.016984, loss_ce: 0.006069
2022-01-17 12:33:17,017 iteration 3917 : loss : 0.030891, loss_ce: 0.010432
2022-01-17 12:33:17,992 iteration 3918 : loss : 0.031748, loss_ce: 0.009522
2022-01-17 12:33:19,070 iteration 3919 : loss : 0.025876, loss_ce: 0.007415
2022-01-17 12:33:19,978 iteration 3920 : loss : 0.018460, loss_ce: 0.007302
2022-01-17 12:33:20,920 iteration 3921 : loss : 0.022163, loss_ce: 0.009623
2022-01-17 12:33:21,908 iteration 3922 : loss : 0.021191, loss_ce: 0.007408
2022-01-17 12:33:22,839 iteration 3923 : loss : 0.017031, loss_ce: 0.008022
2022-01-17 12:33:23,739 iteration 3924 : loss : 0.023251, loss_ce: 0.006144
2022-01-17 12:33:24,764 iteration 3925 : loss : 0.037187, loss_ce: 0.013516
2022-01-17 12:33:25,768 iteration 3926 : loss : 0.022547, loss_ce: 0.006884
2022-01-17 12:33:26,715 iteration 3927 : loss : 0.025027, loss_ce: 0.008296
 58%|████████████████▋            | 231/400 [1:07:36<50:04, 17.78s/it]2022-01-17 12:33:27,761 iteration 3928 : loss : 0.029105, loss_ce: 0.013696
2022-01-17 12:33:28,715 iteration 3929 : loss : 0.017892, loss_ce: 0.008278
2022-01-17 12:33:29,725 iteration 3930 : loss : 0.024764, loss_ce: 0.009694
2022-01-17 12:33:30,718 iteration 3931 : loss : 0.020599, loss_ce: 0.008099
2022-01-17 12:33:31,704 iteration 3932 : loss : 0.032116, loss_ce: 0.009624
2022-01-17 12:33:32,733 iteration 3933 : loss : 0.027363, loss_ce: 0.011598
2022-01-17 12:33:33,715 iteration 3934 : loss : 0.019600, loss_ce: 0.008195
2022-01-17 12:33:34,592 iteration 3935 : loss : 0.017376, loss_ce: 0.006922
2022-01-17 12:33:35,681 iteration 3936 : loss : 0.023642, loss_ce: 0.008848
2022-01-17 12:33:36,587 iteration 3937 : loss : 0.024528, loss_ce: 0.010553
2022-01-17 12:33:37,590 iteration 3938 : loss : 0.057681, loss_ce: 0.010734
2022-01-17 12:33:38,466 iteration 3939 : loss : 0.024559, loss_ce: 0.007303
2022-01-17 12:33:39,390 iteration 3940 : loss : 0.022565, loss_ce: 0.007864
2022-01-17 12:33:40,333 iteration 3941 : loss : 0.023381, loss_ce: 0.009889
2022-01-17 12:33:41,330 iteration 3942 : loss : 0.042345, loss_ce: 0.018497
2022-01-17 12:33:42,239 iteration 3943 : loss : 0.016421, loss_ce: 0.003657
2022-01-17 12:33:43,255 iteration 3944 : loss : 0.038221, loss_ce: 0.014887
 58%|████████████████▊            | 232/400 [1:07:53<48:44, 17.41s/it]2022-01-17 12:33:44,262 iteration 3945 : loss : 0.026264, loss_ce: 0.011501
2022-01-17 12:33:45,114 iteration 3946 : loss : 0.017600, loss_ce: 0.008383
2022-01-17 12:33:46,054 iteration 3947 : loss : 0.021404, loss_ce: 0.006093
2022-01-17 12:33:47,141 iteration 3948 : loss : 0.025565, loss_ce: 0.009100
2022-01-17 12:33:48,136 iteration 3949 : loss : 0.025503, loss_ce: 0.009093
2022-01-17 12:33:49,155 iteration 3950 : loss : 0.023388, loss_ce: 0.006097
2022-01-17 12:33:50,043 iteration 3951 : loss : 0.020517, loss_ce: 0.008617
2022-01-17 12:33:51,039 iteration 3952 : loss : 0.025592, loss_ce: 0.009389
2022-01-17 12:33:52,051 iteration 3953 : loss : 0.029799, loss_ce: 0.009703
2022-01-17 12:33:52,990 iteration 3954 : loss : 0.030725, loss_ce: 0.011439
2022-01-17 12:33:53,929 iteration 3955 : loss : 0.014951, loss_ce: 0.005029
2022-01-17 12:33:55,008 iteration 3956 : loss : 0.031630, loss_ce: 0.013662
2022-01-17 12:33:55,910 iteration 3957 : loss : 0.024040, loss_ce: 0.009297
2022-01-17 12:33:56,832 iteration 3958 : loss : 0.020258, loss_ce: 0.007073
2022-01-17 12:33:57,866 iteration 3959 : loss : 0.027161, loss_ce: 0.007653
2022-01-17 12:33:58,788 iteration 3960 : loss : 0.019808, loss_ce: 0.009012
2022-01-17 12:33:59,733 iteration 3961 : loss : 0.021194, loss_ce: 0.008221
 58%|████████████████▉            | 233/400 [1:08:09<47:40, 17.13s/it]2022-01-17 12:34:00,752 iteration 3962 : loss : 0.021266, loss_ce: 0.007537
2022-01-17 12:34:01,699 iteration 3963 : loss : 0.027357, loss_ce: 0.011436
2022-01-17 12:34:02,737 iteration 3964 : loss : 0.034070, loss_ce: 0.017419
2022-01-17 12:34:03,632 iteration 3965 : loss : 0.019424, loss_ce: 0.005501
2022-01-17 12:34:04,629 iteration 3966 : loss : 0.030377, loss_ce: 0.010330
2022-01-17 12:34:05,587 iteration 3967 : loss : 0.020272, loss_ce: 0.007428
2022-01-17 12:34:06,437 iteration 3968 : loss : 0.021152, loss_ce: 0.007992
2022-01-17 12:34:07,401 iteration 3969 : loss : 0.018003, loss_ce: 0.004983
2022-01-17 12:34:08,342 iteration 3970 : loss : 0.027921, loss_ce: 0.009312
2022-01-17 12:34:09,188 iteration 3971 : loss : 0.016547, loss_ce: 0.006390
2022-01-17 12:34:10,173 iteration 3972 : loss : 0.018897, loss_ce: 0.004559
2022-01-17 12:34:11,074 iteration 3973 : loss : 0.025023, loss_ce: 0.012035
2022-01-17 12:34:11,935 iteration 3974 : loss : 0.017069, loss_ce: 0.005117
2022-01-17 12:34:12,897 iteration 3975 : loss : 0.017043, loss_ce: 0.006428
2022-01-17 12:34:13,908 iteration 3976 : loss : 0.025130, loss_ce: 0.010360
2022-01-17 12:34:14,915 iteration 3977 : loss : 0.028434, loss_ce: 0.010873
2022-01-17 12:34:15,946 iteration 3978 : loss : 0.030456, loss_ce: 0.011019
 58%|████████████████▉            | 234/400 [1:08:25<46:37, 16.85s/it]2022-01-17 12:34:16,933 iteration 3979 : loss : 0.023250, loss_ce: 0.008800
2022-01-17 12:34:17,917 iteration 3980 : loss : 0.030194, loss_ce: 0.009659
2022-01-17 12:34:18,836 iteration 3981 : loss : 0.025219, loss_ce: 0.012552
2022-01-17 12:34:19,671 iteration 3982 : loss : 0.013979, loss_ce: 0.004752
2022-01-17 12:34:20,539 iteration 3983 : loss : 0.016719, loss_ce: 0.007903
2022-01-17 12:34:21,448 iteration 3984 : loss : 0.016043, loss_ce: 0.006200
2022-01-17 12:34:22,415 iteration 3985 : loss : 0.030750, loss_ce: 0.018027
2022-01-17 12:34:23,460 iteration 3986 : loss : 0.023918, loss_ce: 0.010163
2022-01-17 12:34:24,445 iteration 3987 : loss : 0.022993, loss_ce: 0.008597
2022-01-17 12:34:25,398 iteration 3988 : loss : 0.018935, loss_ce: 0.008179
2022-01-17 12:34:26,323 iteration 3989 : loss : 0.017457, loss_ce: 0.003319
2022-01-17 12:34:27,250 iteration 3990 : loss : 0.018143, loss_ce: 0.005614
2022-01-17 12:34:28,257 iteration 3991 : loss : 0.024885, loss_ce: 0.006695
2022-01-17 12:34:29,214 iteration 3992 : loss : 0.030254, loss_ce: 0.009243
2022-01-17 12:34:30,208 iteration 3993 : loss : 0.030603, loss_ce: 0.009618
2022-01-17 12:34:31,125 iteration 3994 : loss : 0.015753, loss_ce: 0.007113
2022-01-17 12:34:31,126 Training Data Eval:
2022-01-17 12:34:35,586   Average segmentation loss on training set: 0.0141
2022-01-17 12:34:35,587 Validation Data Eval:
2022-01-17 12:34:37,094   Average segmentation loss on validation set: 0.0906
2022-01-17 12:34:37,986 iteration 3995 : loss : 0.018625, loss_ce: 0.007103
 59%|█████████████████            | 235/400 [1:08:47<50:37, 18.41s/it]2022-01-17 12:34:39,042 iteration 3996 : loss : 0.015879, loss_ce: 0.004811
2022-01-17 12:34:39,936 iteration 3997 : loss : 0.023964, loss_ce: 0.006617
2022-01-17 12:34:40,905 iteration 3998 : loss : 0.020469, loss_ce: 0.009672
2022-01-17 12:34:41,840 iteration 3999 : loss : 0.018314, loss_ce: 0.004614
2022-01-17 12:34:42,843 iteration 4000 : loss : 0.019521, loss_ce: 0.009481
2022-01-17 12:34:43,726 iteration 4001 : loss : 0.021044, loss_ce: 0.007580
2022-01-17 12:34:44,677 iteration 4002 : loss : 0.020855, loss_ce: 0.009435
2022-01-17 12:34:45,640 iteration 4003 : loss : 0.021203, loss_ce: 0.010345
2022-01-17 12:34:46,629 iteration 4004 : loss : 0.025184, loss_ce: 0.006080
2022-01-17 12:34:47,588 iteration 4005 : loss : 0.023055, loss_ce: 0.011128
2022-01-17 12:34:48,484 iteration 4006 : loss : 0.016047, loss_ce: 0.006279
2022-01-17 12:34:49,489 iteration 4007 : loss : 0.025260, loss_ce: 0.007503
2022-01-17 12:34:50,402 iteration 4008 : loss : 0.017220, loss_ce: 0.005457
2022-01-17 12:34:51,349 iteration 4009 : loss : 0.024511, loss_ce: 0.009415
2022-01-17 12:34:52,369 iteration 4010 : loss : 0.023145, loss_ce: 0.010206
2022-01-17 12:34:53,262 iteration 4011 : loss : 0.020465, loss_ce: 0.005961
2022-01-17 12:34:54,289 iteration 4012 : loss : 0.017535, loss_ce: 0.007382
 59%|█████████████████            | 236/400 [1:09:04<48:35, 17.78s/it]2022-01-17 12:34:55,354 iteration 4013 : loss : 0.025122, loss_ce: 0.007105
2022-01-17 12:34:56,238 iteration 4014 : loss : 0.020671, loss_ce: 0.006073
2022-01-17 12:34:57,234 iteration 4015 : loss : 0.026793, loss_ce: 0.010557
2022-01-17 12:34:58,214 iteration 4016 : loss : 0.016095, loss_ce: 0.005371
2022-01-17 12:34:59,214 iteration 4017 : loss : 0.023106, loss_ce: 0.007030
2022-01-17 12:35:00,117 iteration 4018 : loss : 0.018549, loss_ce: 0.005967
2022-01-17 12:35:01,054 iteration 4019 : loss : 0.018562, loss_ce: 0.008857
2022-01-17 12:35:01,952 iteration 4020 : loss : 0.016875, loss_ce: 0.009212
2022-01-17 12:35:02,872 iteration 4021 : loss : 0.018346, loss_ce: 0.008082
2022-01-17 12:35:03,852 iteration 4022 : loss : 0.020494, loss_ce: 0.010455
2022-01-17 12:35:04,803 iteration 4023 : loss : 0.015678, loss_ce: 0.005327
2022-01-17 12:35:05,687 iteration 4024 : loss : 0.019149, loss_ce: 0.006562
2022-01-17 12:35:06,593 iteration 4025 : loss : 0.016963, loss_ce: 0.006011
2022-01-17 12:35:07,569 iteration 4026 : loss : 0.020252, loss_ce: 0.008043
2022-01-17 12:35:08,548 iteration 4027 : loss : 0.024327, loss_ce: 0.007612
2022-01-17 12:35:09,561 iteration 4028 : loss : 0.021287, loss_ce: 0.006926
2022-01-17 12:35:10,459 iteration 4029 : loss : 0.015723, loss_ce: 0.005645
 59%|█████████████████▏           | 237/400 [1:09:20<46:59, 17.30s/it]2022-01-17 12:35:11,509 iteration 4030 : loss : 0.022249, loss_ce: 0.008417
2022-01-17 12:35:12,470 iteration 4031 : loss : 0.028288, loss_ce: 0.008767
2022-01-17 12:35:13,403 iteration 4032 : loss : 0.030456, loss_ce: 0.014298
2022-01-17 12:35:14,339 iteration 4033 : loss : 0.023811, loss_ce: 0.008103
2022-01-17 12:35:15,218 iteration 4034 : loss : 0.026169, loss_ce: 0.007586
2022-01-17 12:35:16,146 iteration 4035 : loss : 0.014959, loss_ce: 0.004512
2022-01-17 12:35:17,132 iteration 4036 : loss : 0.024785, loss_ce: 0.008320
2022-01-17 12:35:18,035 iteration 4037 : loss : 0.015570, loss_ce: 0.007260
2022-01-17 12:35:19,053 iteration 4038 : loss : 0.026207, loss_ce: 0.008976
2022-01-17 12:35:20,097 iteration 4039 : loss : 0.023181, loss_ce: 0.009007
2022-01-17 12:35:21,123 iteration 4040 : loss : 0.028059, loss_ce: 0.010228
2022-01-17 12:35:22,128 iteration 4041 : loss : 0.020209, loss_ce: 0.006234
2022-01-17 12:35:23,035 iteration 4042 : loss : 0.020835, loss_ce: 0.007202
2022-01-17 12:35:23,985 iteration 4043 : loss : 0.174879, loss_ce: 0.004365
2022-01-17 12:35:24,889 iteration 4044 : loss : 0.019864, loss_ce: 0.007978
2022-01-17 12:35:25,812 iteration 4045 : loss : 0.018446, loss_ce: 0.008366
2022-01-17 12:35:26,801 iteration 4046 : loss : 0.021563, loss_ce: 0.009607
 60%|█████████████████▎           | 238/400 [1:09:36<45:55, 17.01s/it]2022-01-17 12:35:27,871 iteration 4047 : loss : 0.018825, loss_ce: 0.008582
2022-01-17 12:35:28,864 iteration 4048 : loss : 0.020649, loss_ce: 0.008625
2022-01-17 12:35:29,775 iteration 4049 : loss : 0.015736, loss_ce: 0.005804
2022-01-17 12:35:30,753 iteration 4050 : loss : 0.021256, loss_ce: 0.007463
2022-01-17 12:35:31,811 iteration 4051 : loss : 0.046554, loss_ce: 0.006981
2022-01-17 12:35:32,689 iteration 4052 : loss : 0.019003, loss_ce: 0.006382
2022-01-17 12:35:33,549 iteration 4053 : loss : 0.019540, loss_ce: 0.005986
2022-01-17 12:35:34,452 iteration 4054 : loss : 0.028437, loss_ce: 0.007031
2022-01-17 12:35:35,390 iteration 4055 : loss : 0.022174, loss_ce: 0.009328
2022-01-17 12:35:36,357 iteration 4056 : loss : 0.020552, loss_ce: 0.008810
2022-01-17 12:35:37,254 iteration 4057 : loss : 0.019443, loss_ce: 0.004385
2022-01-17 12:35:38,189 iteration 4058 : loss : 0.014409, loss_ce: 0.004657
2022-01-17 12:35:39,245 iteration 4059 : loss : 0.030661, loss_ce: 0.013333
2022-01-17 12:35:40,204 iteration 4060 : loss : 0.026393, loss_ce: 0.010059
2022-01-17 12:35:41,150 iteration 4061 : loss : 0.021738, loss_ce: 0.008614
2022-01-17 12:35:42,133 iteration 4062 : loss : 0.021472, loss_ce: 0.007813
2022-01-17 12:35:43,108 iteration 4063 : loss : 0.030339, loss_ce: 0.009215
 60%|█████████████████▎           | 239/400 [1:09:52<45:04, 16.80s/it]2022-01-17 12:35:44,068 iteration 4064 : loss : 0.021526, loss_ce: 0.004523
2022-01-17 12:35:44,979 iteration 4065 : loss : 0.018437, loss_ce: 0.005572
2022-01-17 12:35:45,992 iteration 4066 : loss : 0.031786, loss_ce: 0.010100
2022-01-17 12:35:46,906 iteration 4067 : loss : 0.017716, loss_ce: 0.007573
2022-01-17 12:35:47,859 iteration 4068 : loss : 0.022239, loss_ce: 0.007837
2022-01-17 12:35:48,840 iteration 4069 : loss : 0.021295, loss_ce: 0.009925
2022-01-17 12:35:49,808 iteration 4070 : loss : 0.025493, loss_ce: 0.009204
2022-01-17 12:35:50,813 iteration 4071 : loss : 0.025342, loss_ce: 0.010336
2022-01-17 12:35:51,749 iteration 4072 : loss : 0.017211, loss_ce: 0.005084
2022-01-17 12:35:52,663 iteration 4073 : loss : 0.014781, loss_ce: 0.004926
2022-01-17 12:35:53,615 iteration 4074 : loss : 0.018332, loss_ce: 0.008253
2022-01-17 12:35:54,617 iteration 4075 : loss : 0.023155, loss_ce: 0.009721
2022-01-17 12:35:55,519 iteration 4076 : loss : 0.025816, loss_ce: 0.009948
2022-01-17 12:35:56,457 iteration 4077 : loss : 0.018025, loss_ce: 0.006697
2022-01-17 12:35:57,466 iteration 4078 : loss : 0.039327, loss_ce: 0.014350
2022-01-17 12:35:58,450 iteration 4079 : loss : 0.019476, loss_ce: 0.008336
2022-01-17 12:35:58,451 Training Data Eval:
2022-01-17 12:36:02,897   Average segmentation loss on training set: 0.0133
2022-01-17 12:36:02,897 Validation Data Eval:
2022-01-17 12:36:04,399   Average segmentation loss on validation set: 0.0897
2022-01-17 12:36:05,400 iteration 4080 : loss : 0.020246, loss_ce: 0.009173
 60%|█████████████████▍           | 240/400 [1:10:15<49:11, 18.45s/it]2022-01-17 12:36:06,420 iteration 4081 : loss : 0.024954, loss_ce: 0.010449
2022-01-17 12:36:07,374 iteration 4082 : loss : 0.016225, loss_ce: 0.005863
2022-01-17 12:36:08,272 iteration 4083 : loss : 0.019215, loss_ce: 0.008471
2022-01-17 12:36:09,216 iteration 4084 : loss : 0.024271, loss_ce: 0.007575
2022-01-17 12:36:10,119 iteration 4085 : loss : 0.017635, loss_ce: 0.004899
2022-01-17 12:36:11,187 iteration 4086 : loss : 0.028720, loss_ce: 0.010072
2022-01-17 12:36:12,150 iteration 4087 : loss : 0.019900, loss_ce: 0.005436
2022-01-17 12:36:13,027 iteration 4088 : loss : 0.015559, loss_ce: 0.006862
2022-01-17 12:36:13,972 iteration 4089 : loss : 0.027142, loss_ce: 0.009530
2022-01-17 12:36:14,827 iteration 4090 : loss : 0.020266, loss_ce: 0.006372
2022-01-17 12:36:15,771 iteration 4091 : loss : 0.029172, loss_ce: 0.011680
2022-01-17 12:36:16,736 iteration 4092 : loss : 0.017562, loss_ce: 0.005563
2022-01-17 12:36:17,706 iteration 4093 : loss : 0.026122, loss_ce: 0.009258
2022-01-17 12:36:18,625 iteration 4094 : loss : 0.018922, loss_ce: 0.006868
2022-01-17 12:36:19,594 iteration 4095 : loss : 0.025790, loss_ce: 0.009989
2022-01-17 12:36:20,514 iteration 4096 : loss : 0.016491, loss_ce: 0.008488
2022-01-17 12:36:21,450 iteration 4097 : loss : 0.021788, loss_ce: 0.007082
 60%|█████████████████▍           | 241/400 [1:10:31<46:58, 17.73s/it]2022-01-17 12:36:22,418 iteration 4098 : loss : 0.016856, loss_ce: 0.006552
2022-01-17 12:36:23,334 iteration 4099 : loss : 0.028304, loss_ce: 0.008081
2022-01-17 12:36:24,291 iteration 4100 : loss : 0.017547, loss_ce: 0.005529
2022-01-17 12:36:25,287 iteration 4101 : loss : 0.021072, loss_ce: 0.006664
2022-01-17 12:36:26,269 iteration 4102 : loss : 0.028616, loss_ce: 0.011832
2022-01-17 12:36:27,228 iteration 4103 : loss : 0.026744, loss_ce: 0.011355
2022-01-17 12:36:28,175 iteration 4104 : loss : 0.023644, loss_ce: 0.009899
2022-01-17 12:36:29,134 iteration 4105 : loss : 0.024967, loss_ce: 0.010907
2022-01-17 12:36:30,063 iteration 4106 : loss : 0.020257, loss_ce: 0.008562
2022-01-17 12:36:30,995 iteration 4107 : loss : 0.020887, loss_ce: 0.006967
2022-01-17 12:36:31,940 iteration 4108 : loss : 0.022094, loss_ce: 0.008637
2022-01-17 12:36:32,832 iteration 4109 : loss : 0.014454, loss_ce: 0.004717
2022-01-17 12:36:33,814 iteration 4110 : loss : 0.027346, loss_ce: 0.010357
2022-01-17 12:36:34,916 iteration 4111 : loss : 0.026098, loss_ce: 0.012888
2022-01-17 12:36:35,819 iteration 4112 : loss : 0.018023, loss_ce: 0.006239
2022-01-17 12:36:36,802 iteration 4113 : loss : 0.028447, loss_ce: 0.008047
2022-01-17 12:36:37,738 iteration 4114 : loss : 0.017077, loss_ce: 0.007105
 60%|█████████████████▌           | 242/400 [1:10:47<45:32, 17.29s/it]2022-01-17 12:36:38,679 iteration 4115 : loss : 0.019446, loss_ce: 0.009933
2022-01-17 12:36:39,693 iteration 4116 : loss : 0.018851, loss_ce: 0.005632
2022-01-17 12:36:40,585 iteration 4117 : loss : 0.016334, loss_ce: 0.006578
2022-01-17 12:36:41,603 iteration 4118 : loss : 0.027515, loss_ce: 0.011512
2022-01-17 12:36:42,678 iteration 4119 : loss : 0.028211, loss_ce: 0.008617
2022-01-17 12:36:43,647 iteration 4120 : loss : 0.022730, loss_ce: 0.006046
2022-01-17 12:36:44,548 iteration 4121 : loss : 0.017999, loss_ce: 0.006324
2022-01-17 12:36:45,481 iteration 4122 : loss : 0.027868, loss_ce: 0.008477
2022-01-17 12:36:46,367 iteration 4123 : loss : 0.011885, loss_ce: 0.004905
2022-01-17 12:36:47,351 iteration 4124 : loss : 0.019850, loss_ce: 0.008888
2022-01-17 12:36:48,318 iteration 4125 : loss : 0.025309, loss_ce: 0.011271
2022-01-17 12:36:49,281 iteration 4126 : loss : 0.020394, loss_ce: 0.008018
2022-01-17 12:36:50,178 iteration 4127 : loss : 0.014228, loss_ce: 0.006537
2022-01-17 12:36:51,230 iteration 4128 : loss : 0.058034, loss_ce: 0.013344
2022-01-17 12:36:52,107 iteration 4129 : loss : 0.026052, loss_ce: 0.006522
2022-01-17 12:36:52,971 iteration 4130 : loss : 0.017032, loss_ce: 0.005174
2022-01-17 12:36:53,893 iteration 4131 : loss : 0.019247, loss_ce: 0.008871
 61%|█████████████████▌           | 243/400 [1:11:03<44:21, 16.95s/it]2022-01-17 12:36:54,936 iteration 4132 : loss : 0.021299, loss_ce: 0.006538
2022-01-17 12:36:55,906 iteration 4133 : loss : 0.022894, loss_ce: 0.006536
2022-01-17 12:36:56,898 iteration 4134 : loss : 0.023142, loss_ce: 0.009014
2022-01-17 12:36:57,773 iteration 4135 : loss : 0.025601, loss_ce: 0.010726
2022-01-17 12:36:58,719 iteration 4136 : loss : 0.017663, loss_ce: 0.007860
2022-01-17 12:36:59,595 iteration 4137 : loss : 0.019146, loss_ce: 0.006900
2022-01-17 12:37:00,571 iteration 4138 : loss : 0.020145, loss_ce: 0.009225
2022-01-17 12:37:01,547 iteration 4139 : loss : 0.017435, loss_ce: 0.007170
2022-01-17 12:37:02,508 iteration 4140 : loss : 0.018749, loss_ce: 0.007994
2022-01-17 12:37:03,470 iteration 4141 : loss : 0.020543, loss_ce: 0.007162
2022-01-17 12:37:04,482 iteration 4142 : loss : 0.026857, loss_ce: 0.009599
2022-01-17 12:37:05,330 iteration 4143 : loss : 0.021829, loss_ce: 0.006610
2022-01-17 12:37:06,205 iteration 4144 : loss : 0.014801, loss_ce: 0.003196
2022-01-17 12:37:07,206 iteration 4145 : loss : 0.031312, loss_ce: 0.010674
2022-01-17 12:37:08,126 iteration 4146 : loss : 0.014840, loss_ce: 0.006264
2022-01-17 12:37:09,093 iteration 4147 : loss : 0.019747, loss_ce: 0.007177
2022-01-17 12:37:10,010 iteration 4148 : loss : 0.019888, loss_ce: 0.009306
 61%|█████████████████▋           | 244/400 [1:11:19<43:25, 16.70s/it]2022-01-17 12:37:11,006 iteration 4149 : loss : 0.016497, loss_ce: 0.005986
2022-01-17 12:37:11,967 iteration 4150 : loss : 0.022010, loss_ce: 0.006532
2022-01-17 12:37:12,961 iteration 4151 : loss : 0.024034, loss_ce: 0.008940
2022-01-17 12:37:13,912 iteration 4152 : loss : 0.019125, loss_ce: 0.007888
2022-01-17 12:37:14,781 iteration 4153 : loss : 0.014301, loss_ce: 0.005372
2022-01-17 12:37:15,741 iteration 4154 : loss : 0.019630, loss_ce: 0.007624
2022-01-17 12:37:16,673 iteration 4155 : loss : 0.019319, loss_ce: 0.005989
2022-01-17 12:37:17,555 iteration 4156 : loss : 0.015495, loss_ce: 0.005389
2022-01-17 12:37:18,557 iteration 4157 : loss : 0.018932, loss_ce: 0.008749
2022-01-17 12:37:19,459 iteration 4158 : loss : 0.018591, loss_ce: 0.006996
2022-01-17 12:37:20,380 iteration 4159 : loss : 0.019410, loss_ce: 0.008370
2022-01-17 12:37:21,440 iteration 4160 : loss : 0.029770, loss_ce: 0.009040
2022-01-17 12:37:22,474 iteration 4161 : loss : 0.022122, loss_ce: 0.007138
2022-01-17 12:37:23,501 iteration 4162 : loss : 0.029970, loss_ce: 0.010519
2022-01-17 12:37:24,503 iteration 4163 : loss : 0.034812, loss_ce: 0.016394
2022-01-17 12:37:25,456 iteration 4164 : loss : 0.020206, loss_ce: 0.007596
2022-01-17 12:37:25,456 Training Data Eval:
2022-01-17 12:37:29,913   Average segmentation loss on training set: 0.0148
2022-01-17 12:37:29,914 Validation Data Eval:
2022-01-17 12:37:31,419   Average segmentation loss on validation set: 0.1071
2022-01-17 12:37:32,398 iteration 4165 : loss : 0.032365, loss_ce: 0.009694
 61%|█████████████████▊           | 245/400 [1:11:42<47:33, 18.41s/it]2022-01-17 12:37:33,379 iteration 4166 : loss : 0.018427, loss_ce: 0.007122
2022-01-17 12:37:34,253 iteration 4167 : loss : 0.021230, loss_ce: 0.005236
2022-01-17 12:37:35,155 iteration 4168 : loss : 0.013790, loss_ce: 0.005612
2022-01-17 12:37:36,054 iteration 4169 : loss : 0.015187, loss_ce: 0.006863
2022-01-17 12:37:37,109 iteration 4170 : loss : 0.023680, loss_ce: 0.010495
2022-01-17 12:37:37,978 iteration 4171 : loss : 0.020481, loss_ce: 0.005996
2022-01-17 12:37:38,906 iteration 4172 : loss : 0.019011, loss_ce: 0.008393
2022-01-17 12:37:39,882 iteration 4173 : loss : 0.022163, loss_ce: 0.006354
2022-01-17 12:37:40,804 iteration 4174 : loss : 0.016812, loss_ce: 0.004794
2022-01-17 12:37:41,770 iteration 4175 : loss : 0.019130, loss_ce: 0.008303
2022-01-17 12:37:42,698 iteration 4176 : loss : 0.019799, loss_ce: 0.008091
2022-01-17 12:37:43,690 iteration 4177 : loss : 0.016783, loss_ce: 0.004377
2022-01-17 12:37:44,588 iteration 4178 : loss : 0.022508, loss_ce: 0.008112
2022-01-17 12:37:45,511 iteration 4179 : loss : 0.021326, loss_ce: 0.009468
2022-01-17 12:37:46,427 iteration 4180 : loss : 0.020342, loss_ce: 0.005742
2022-01-17 12:37:47,360 iteration 4181 : loss : 0.017462, loss_ce: 0.006948
2022-01-17 12:37:48,302 iteration 4182 : loss : 0.016695, loss_ce: 0.004399
 62%|█████████████████▊           | 246/400 [1:11:58<45:19, 17.66s/it]2022-01-17 12:37:49,306 iteration 4183 : loss : 0.017442, loss_ce: 0.005377
2022-01-17 12:37:50,297 iteration 4184 : loss : 0.019640, loss_ce: 0.008438
2022-01-17 12:37:51,243 iteration 4185 : loss : 0.021938, loss_ce: 0.008618
2022-01-17 12:37:52,167 iteration 4186 : loss : 0.016645, loss_ce: 0.004413
2022-01-17 12:37:53,155 iteration 4187 : loss : 0.029836, loss_ce: 0.009371
2022-01-17 12:37:54,059 iteration 4188 : loss : 0.025158, loss_ce: 0.007366
2022-01-17 12:37:55,112 iteration 4189 : loss : 0.022826, loss_ce: 0.008326
2022-01-17 12:37:56,107 iteration 4190 : loss : 0.029892, loss_ce: 0.013290
2022-01-17 12:37:57,121 iteration 4191 : loss : 0.024282, loss_ce: 0.009633
2022-01-17 12:37:57,967 iteration 4192 : loss : 0.020967, loss_ce: 0.006308
2022-01-17 12:37:58,939 iteration 4193 : loss : 0.019358, loss_ce: 0.009442
2022-01-17 12:37:59,940 iteration 4194 : loss : 0.019764, loss_ce: 0.006924
2022-01-17 12:38:00,869 iteration 4195 : loss : 0.022943, loss_ce: 0.006593
2022-01-17 12:38:01,847 iteration 4196 : loss : 0.017390, loss_ce: 0.007325
2022-01-17 12:38:02,775 iteration 4197 : loss : 0.021527, loss_ce: 0.006846
2022-01-17 12:38:03,703 iteration 4198 : loss : 0.015518, loss_ce: 0.005776
2022-01-17 12:38:04,575 iteration 4199 : loss : 0.015910, loss_ce: 0.006078
 62%|█████████████████▉           | 247/400 [1:12:14<43:58, 17.24s/it]2022-01-17 12:38:05,557 iteration 4200 : loss : 0.023385, loss_ce: 0.009290
2022-01-17 12:38:06,533 iteration 4201 : loss : 0.016559, loss_ce: 0.006887
2022-01-17 12:38:07,513 iteration 4202 : loss : 0.017070, loss_ce: 0.006891
2022-01-17 12:38:08,567 iteration 4203 : loss : 0.029057, loss_ce: 0.014548
2022-01-17 12:38:09,495 iteration 4204 : loss : 0.017079, loss_ce: 0.006356
2022-01-17 12:38:10,433 iteration 4205 : loss : 0.017328, loss_ce: 0.006748
2022-01-17 12:38:11,512 iteration 4206 : loss : 0.026018, loss_ce: 0.008951
2022-01-17 12:38:12,577 iteration 4207 : loss : 0.025748, loss_ce: 0.009827
2022-01-17 12:38:13,427 iteration 4208 : loss : 0.014165, loss_ce: 0.004910
2022-01-17 12:38:14,340 iteration 4209 : loss : 0.017998, loss_ce: 0.008174
2022-01-17 12:38:15,263 iteration 4210 : loss : 0.018567, loss_ce: 0.008101
2022-01-17 12:38:16,220 iteration 4211 : loss : 0.020522, loss_ce: 0.008671
2022-01-17 12:38:17,218 iteration 4212 : loss : 0.020003, loss_ce: 0.007125
2022-01-17 12:38:18,134 iteration 4213 : loss : 0.016277, loss_ce: 0.004482
2022-01-17 12:38:19,124 iteration 4214 : loss : 0.026902, loss_ce: 0.008758
2022-01-17 12:38:20,066 iteration 4215 : loss : 0.016192, loss_ce: 0.005163
2022-01-17 12:38:20,998 iteration 4216 : loss : 0.016820, loss_ce: 0.005324
 62%|█████████████████▉           | 248/400 [1:12:30<43:03, 17.00s/it]2022-01-17 12:38:22,022 iteration 4217 : loss : 0.021254, loss_ce: 0.006756
2022-01-17 12:38:22,935 iteration 4218 : loss : 0.019305, loss_ce: 0.006342
2022-01-17 12:38:23,832 iteration 4219 : loss : 0.017911, loss_ce: 0.007385
2022-01-17 12:38:24,681 iteration 4220 : loss : 0.020075, loss_ce: 0.004663
2022-01-17 12:38:25,725 iteration 4221 : loss : 0.018654, loss_ce: 0.009452
2022-01-17 12:38:26,763 iteration 4222 : loss : 0.029865, loss_ce: 0.011618
2022-01-17 12:38:27,679 iteration 4223 : loss : 0.018664, loss_ce: 0.006438
2022-01-17 12:38:28,681 iteration 4224 : loss : 0.023451, loss_ce: 0.005552
2022-01-17 12:38:29,652 iteration 4225 : loss : 0.027347, loss_ce: 0.007962
2022-01-17 12:38:30,651 iteration 4226 : loss : 0.018879, loss_ce: 0.008649
2022-01-17 12:38:31,627 iteration 4227 : loss : 0.017202, loss_ce: 0.007141
2022-01-17 12:38:32,523 iteration 4228 : loss : 0.023562, loss_ce: 0.012495
2022-01-17 12:38:33,457 iteration 4229 : loss : 0.021637, loss_ce: 0.007832
2022-01-17 12:38:34,385 iteration 4230 : loss : 0.023192, loss_ce: 0.011594
2022-01-17 12:38:35,387 iteration 4231 : loss : 0.018052, loss_ce: 0.007414
2022-01-17 12:38:36,387 iteration 4232 : loss : 0.021911, loss_ce: 0.006636
2022-01-17 12:38:37,332 iteration 4233 : loss : 0.017998, loss_ce: 0.008721
 62%|██████████████████           | 249/400 [1:12:47<42:16, 16.80s/it]2022-01-17 12:38:38,235 iteration 4234 : loss : 0.020381, loss_ce: 0.004275
2022-01-17 12:38:39,116 iteration 4235 : loss : 0.012880, loss_ce: 0.004572
2022-01-17 12:38:40,091 iteration 4236 : loss : 0.021778, loss_ce: 0.009179
2022-01-17 12:38:40,988 iteration 4237 : loss : 0.019471, loss_ce: 0.007113
2022-01-17 12:38:41,930 iteration 4238 : loss : 0.029069, loss_ce: 0.014068
2022-01-17 12:38:43,019 iteration 4239 : loss : 0.039960, loss_ce: 0.020364
2022-01-17 12:38:43,978 iteration 4240 : loss : 0.014625, loss_ce: 0.003937
2022-01-17 12:38:44,831 iteration 4241 : loss : 0.018474, loss_ce: 0.008296
2022-01-17 12:38:45,789 iteration 4242 : loss : 0.019540, loss_ce: 0.005010
2022-01-17 12:38:46,710 iteration 4243 : loss : 0.018371, loss_ce: 0.007281
2022-01-17 12:38:47,578 iteration 4244 : loss : 0.015133, loss_ce: 0.007147
2022-01-17 12:38:48,569 iteration 4245 : loss : 0.020103, loss_ce: 0.008003
2022-01-17 12:38:49,593 iteration 4246 : loss : 0.020565, loss_ce: 0.004828
2022-01-17 12:38:50,570 iteration 4247 : loss : 0.020343, loss_ce: 0.007846
2022-01-17 12:38:51,453 iteration 4248 : loss : 0.020436, loss_ce: 0.008045
2022-01-17 12:38:52,460 iteration 4249 : loss : 0.021520, loss_ce: 0.006238
2022-01-17 12:38:52,460 Training Data Eval:
2022-01-17 12:38:56,919   Average segmentation loss on training set: 0.0133
2022-01-17 12:38:56,919 Validation Data Eval:
2022-01-17 12:38:58,420   Average segmentation loss on validation set: 0.1042
2022-01-17 12:38:59,359 iteration 4250 : loss : 0.023349, loss_ce: 0.007749
 62%|██████████████████▏          | 250/400 [1:13:09<45:54, 18.36s/it]2022-01-17 12:39:00,410 iteration 4251 : loss : 0.026475, loss_ce: 0.006401
2022-01-17 12:39:01,409 iteration 4252 : loss : 0.022215, loss_ce: 0.010634
2022-01-17 12:39:02,368 iteration 4253 : loss : 0.022537, loss_ce: 0.006879
2022-01-17 12:39:03,359 iteration 4254 : loss : 0.014241, loss_ce: 0.004983
2022-01-17 12:39:04,359 iteration 4255 : loss : 0.021858, loss_ce: 0.007000
2022-01-17 12:39:05,212 iteration 4256 : loss : 0.019860, loss_ce: 0.008022
2022-01-17 12:39:06,156 iteration 4257 : loss : 0.023132, loss_ce: 0.008503
2022-01-17 12:39:07,034 iteration 4258 : loss : 0.028034, loss_ce: 0.008391
2022-01-17 12:39:08,003 iteration 4259 : loss : 0.026145, loss_ce: 0.010842
2022-01-17 12:39:08,977 iteration 4260 : loss : 0.026623, loss_ce: 0.008386
2022-01-17 12:39:09,960 iteration 4261 : loss : 0.020991, loss_ce: 0.008326
2022-01-17 12:39:10,865 iteration 4262 : loss : 0.016855, loss_ce: 0.007247
2022-01-17 12:39:11,844 iteration 4263 : loss : 0.020117, loss_ce: 0.008321
2022-01-17 12:39:12,853 iteration 4264 : loss : 0.023488, loss_ce: 0.009593
2022-01-17 12:39:13,792 iteration 4265 : loss : 0.027634, loss_ce: 0.008458
2022-01-17 12:39:14,765 iteration 4266 : loss : 0.025590, loss_ce: 0.008557
2022-01-17 12:39:15,756 iteration 4267 : loss : 0.021069, loss_ce: 0.007299
 63%|██████████████████▏          | 251/400 [1:13:25<44:08, 17.78s/it]2022-01-17 12:39:16,756 iteration 4268 : loss : 0.014596, loss_ce: 0.003242
2022-01-17 12:39:17,692 iteration 4269 : loss : 0.020332, loss_ce: 0.005934
2022-01-17 12:39:18,600 iteration 4270 : loss : 0.017691, loss_ce: 0.008611
2022-01-17 12:39:19,472 iteration 4271 : loss : 0.015172, loss_ce: 0.005560
2022-01-17 12:39:20,410 iteration 4272 : loss : 0.024137, loss_ce: 0.011208
2022-01-17 12:39:21,288 iteration 4273 : loss : 0.013856, loss_ce: 0.005767
2022-01-17 12:39:22,326 iteration 4274 : loss : 0.018149, loss_ce: 0.007587
2022-01-17 12:39:23,254 iteration 4275 : loss : 0.029017, loss_ce: 0.010773
2022-01-17 12:39:24,251 iteration 4276 : loss : 0.026657, loss_ce: 0.006707
2022-01-17 12:39:25,247 iteration 4277 : loss : 0.030937, loss_ce: 0.010055
2022-01-17 12:39:26,231 iteration 4278 : loss : 0.027804, loss_ce: 0.008016
2022-01-17 12:39:27,155 iteration 4279 : loss : 0.022049, loss_ce: 0.010632
2022-01-17 12:39:28,109 iteration 4280 : loss : 0.020534, loss_ce: 0.006328
2022-01-17 12:39:29,061 iteration 4281 : loss : 0.026606, loss_ce: 0.009392
2022-01-17 12:39:29,939 iteration 4282 : loss : 0.017046, loss_ce: 0.006773
2022-01-17 12:39:30,878 iteration 4283 : loss : 0.018698, loss_ce: 0.005579
2022-01-17 12:39:31,793 iteration 4284 : loss : 0.015982, loss_ce: 0.006887
 63%|██████████████████▎          | 252/400 [1:13:41<42:33, 17.25s/it]2022-01-17 12:39:32,718 iteration 4285 : loss : 0.016481, loss_ce: 0.004606
2022-01-17 12:39:33,709 iteration 4286 : loss : 0.021932, loss_ce: 0.008060
2022-01-17 12:39:34,608 iteration 4287 : loss : 0.019155, loss_ce: 0.007981
2022-01-17 12:39:35,512 iteration 4288 : loss : 0.019548, loss_ce: 0.009015
2022-01-17 12:39:36,465 iteration 4289 : loss : 0.028733, loss_ce: 0.010339
2022-01-17 12:39:37,403 iteration 4290 : loss : 0.019825, loss_ce: 0.004663
2022-01-17 12:39:38,378 iteration 4291 : loss : 0.019510, loss_ce: 0.006845
2022-01-17 12:39:39,346 iteration 4292 : loss : 0.016330, loss_ce: 0.007432
2022-01-17 12:39:40,290 iteration 4293 : loss : 0.019167, loss_ce: 0.006031
2022-01-17 12:39:41,199 iteration 4294 : loss : 0.016283, loss_ce: 0.004445
2022-01-17 12:39:42,246 iteration 4295 : loss : 0.019468, loss_ce: 0.006584
2022-01-17 12:39:43,196 iteration 4296 : loss : 0.020305, loss_ce: 0.007523
2022-01-17 12:39:44,166 iteration 4297 : loss : 0.024286, loss_ce: 0.009214
2022-01-17 12:39:45,075 iteration 4298 : loss : 0.016107, loss_ce: 0.007543
2022-01-17 12:39:46,075 iteration 4299 : loss : 0.024634, loss_ce: 0.012968
2022-01-17 12:39:47,105 iteration 4300 : loss : 0.024703, loss_ce: 0.009265
2022-01-17 12:39:48,121 iteration 4301 : loss : 0.019153, loss_ce: 0.009266
 63%|██████████████████▎          | 253/400 [1:13:57<41:35, 16.98s/it]2022-01-17 12:39:49,142 iteration 4302 : loss : 0.021805, loss_ce: 0.009243
2022-01-17 12:39:50,149 iteration 4303 : loss : 0.032036, loss_ce: 0.006121
2022-01-17 12:39:51,059 iteration 4304 : loss : 0.015241, loss_ce: 0.005698
2022-01-17 12:39:51,978 iteration 4305 : loss : 0.021464, loss_ce: 0.008224
2022-01-17 12:39:52,909 iteration 4306 : loss : 0.015802, loss_ce: 0.005126
2022-01-17 12:39:53,797 iteration 4307 : loss : 0.017730, loss_ce: 0.007796
2022-01-17 12:39:54,782 iteration 4308 : loss : 0.019004, loss_ce: 0.006367
2022-01-17 12:39:55,800 iteration 4309 : loss : 0.030097, loss_ce: 0.010486
2022-01-17 12:39:56,751 iteration 4310 : loss : 0.018327, loss_ce: 0.007680
2022-01-17 12:39:57,656 iteration 4311 : loss : 0.017469, loss_ce: 0.006692
2022-01-17 12:39:58,550 iteration 4312 : loss : 0.017261, loss_ce: 0.006512
2022-01-17 12:39:59,458 iteration 4313 : loss : 0.017400, loss_ce: 0.008953
2022-01-17 12:40:00,376 iteration 4314 : loss : 0.017881, loss_ce: 0.005641
2022-01-17 12:40:01,361 iteration 4315 : loss : 0.022116, loss_ce: 0.007733
2022-01-17 12:40:02,270 iteration 4316 : loss : 0.028967, loss_ce: 0.008339
2022-01-17 12:40:03,274 iteration 4317 : loss : 0.021537, loss_ce: 0.008344
2022-01-17 12:40:04,162 iteration 4318 : loss : 0.019435, loss_ce: 0.007561
 64%|██████████████████▍          | 254/400 [1:14:14<40:37, 16.69s/it]2022-01-17 12:40:05,193 iteration 4319 : loss : 0.019358, loss_ce: 0.006504
2022-01-17 12:40:06,175 iteration 4320 : loss : 0.022975, loss_ce: 0.009629
2022-01-17 12:40:07,017 iteration 4321 : loss : 0.017119, loss_ce: 0.005135
2022-01-17 12:40:07,965 iteration 4322 : loss : 0.019844, loss_ce: 0.005736
2022-01-17 12:40:08,855 iteration 4323 : loss : 0.016370, loss_ce: 0.007676
2022-01-17 12:40:09,915 iteration 4324 : loss : 0.026252, loss_ce: 0.011178
2022-01-17 12:40:10,858 iteration 4325 : loss : 0.017671, loss_ce: 0.006851
2022-01-17 12:40:11,777 iteration 4326 : loss : 0.022593, loss_ce: 0.009583
2022-01-17 12:40:12,753 iteration 4327 : loss : 0.022127, loss_ce: 0.007689
2022-01-17 12:40:13,656 iteration 4328 : loss : 0.036661, loss_ce: 0.014667
2022-01-17 12:40:14,660 iteration 4329 : loss : 0.030773, loss_ce: 0.008633
2022-01-17 12:40:15,642 iteration 4330 : loss : 0.019048, loss_ce: 0.008324
2022-01-17 12:40:16,678 iteration 4331 : loss : 0.026820, loss_ce: 0.006542
2022-01-17 12:40:17,665 iteration 4332 : loss : 0.024515, loss_ce: 0.008423
2022-01-17 12:40:18,680 iteration 4333 : loss : 0.029217, loss_ce: 0.012772
2022-01-17 12:40:19,622 iteration 4334 : loss : 0.021665, loss_ce: 0.009787
2022-01-17 12:40:19,623 Training Data Eval:
2022-01-17 12:40:24,070   Average segmentation loss on training set: 0.0131
2022-01-17 12:40:24,070 Validation Data Eval:
2022-01-17 12:40:25,571   Average segmentation loss on validation set: 0.0809
2022-01-17 12:40:26,564 iteration 4335 : loss : 0.022952, loss_ce: 0.005640
 64%|██████████████████▍          | 255/400 [1:14:36<44:28, 18.41s/it]2022-01-17 12:40:27,441 iteration 4336 : loss : 0.013301, loss_ce: 0.006443
2022-01-17 12:40:28,472 iteration 4337 : loss : 0.027839, loss_ce: 0.012592
2022-01-17 12:40:29,422 iteration 4338 : loss : 0.023045, loss_ce: 0.008666
2022-01-17 12:40:30,325 iteration 4339 : loss : 0.013056, loss_ce: 0.004537
2022-01-17 12:40:31,314 iteration 4340 : loss : 0.017772, loss_ce: 0.007651
2022-01-17 12:40:32,207 iteration 4341 : loss : 0.014982, loss_ce: 0.004865
2022-01-17 12:40:33,204 iteration 4342 : loss : 0.023819, loss_ce: 0.006674
2022-01-17 12:40:34,193 iteration 4343 : loss : 0.028148, loss_ce: 0.009030
2022-01-17 12:40:35,177 iteration 4344 : loss : 0.020250, loss_ce: 0.009836
2022-01-17 12:40:36,218 iteration 4345 : loss : 0.021068, loss_ce: 0.008525
2022-01-17 12:40:37,094 iteration 4346 : loss : 0.014750, loss_ce: 0.003885
2022-01-17 12:40:38,048 iteration 4347 : loss : 0.015211, loss_ce: 0.006801
2022-01-17 12:40:38,945 iteration 4348 : loss : 0.018404, loss_ce: 0.008854
2022-01-17 12:40:39,797 iteration 4349 : loss : 0.014739, loss_ce: 0.003577
2022-01-17 12:40:40,650 iteration 4350 : loss : 0.018305, loss_ce: 0.007161
2022-01-17 12:40:41,610 iteration 4351 : loss : 0.027971, loss_ce: 0.008353
2022-01-17 12:40:42,561 iteration 4352 : loss : 0.019311, loss_ce: 0.008071
 64%|██████████████████▌          | 256/400 [1:14:52<42:26, 17.68s/it]2022-01-17 12:40:43,504 iteration 4353 : loss : 0.018094, loss_ce: 0.006389
2022-01-17 12:40:44,532 iteration 4354 : loss : 0.019615, loss_ce: 0.009148
2022-01-17 12:40:45,524 iteration 4355 : loss : 0.017376, loss_ce: 0.007664
2022-01-17 12:40:46,561 iteration 4356 : loss : 0.016298, loss_ce: 0.004881
2022-01-17 12:40:47,552 iteration 4357 : loss : 0.016311, loss_ce: 0.007291
2022-01-17 12:40:48,559 iteration 4358 : loss : 0.025281, loss_ce: 0.009324
2022-01-17 12:40:49,530 iteration 4359 : loss : 0.022039, loss_ce: 0.008246
2022-01-17 12:40:50,468 iteration 4360 : loss : 0.025679, loss_ce: 0.011204
2022-01-17 12:40:51,473 iteration 4361 : loss : 0.023195, loss_ce: 0.008987
2022-01-17 12:40:52,420 iteration 4362 : loss : 0.019660, loss_ce: 0.008293
2022-01-17 12:40:53,366 iteration 4363 : loss : 0.015068, loss_ce: 0.006564
2022-01-17 12:40:54,339 iteration 4364 : loss : 0.018020, loss_ce: 0.007141
2022-01-17 12:40:55,381 iteration 4365 : loss : 0.025112, loss_ce: 0.011623
2022-01-17 12:40:56,302 iteration 4366 : loss : 0.013107, loss_ce: 0.003621
2022-01-17 12:40:57,143 iteration 4367 : loss : 0.015157, loss_ce: 0.005919
2022-01-17 12:40:58,022 iteration 4368 : loss : 0.017214, loss_ce: 0.005324
2022-01-17 12:40:58,984 iteration 4369 : loss : 0.016508, loss_ce: 0.006080
 64%|██████████████████▋          | 257/400 [1:15:08<41:14, 17.31s/it]2022-01-17 12:40:59,977 iteration 4370 : loss : 0.017289, loss_ce: 0.005625
2022-01-17 12:41:00,950 iteration 4371 : loss : 0.020357, loss_ce: 0.010174
2022-01-17 12:41:01,928 iteration 4372 : loss : 0.019803, loss_ce: 0.006737
2022-01-17 12:41:02,899 iteration 4373 : loss : 0.023895, loss_ce: 0.012160
2022-01-17 12:41:03,884 iteration 4374 : loss : 0.018747, loss_ce: 0.006946
2022-01-17 12:41:04,866 iteration 4375 : loss : 0.021789, loss_ce: 0.009692
2022-01-17 12:41:05,782 iteration 4376 : loss : 0.017099, loss_ce: 0.005907
2022-01-17 12:41:06,703 iteration 4377 : loss : 0.017898, loss_ce: 0.004756
2022-01-17 12:41:07,579 iteration 4378 : loss : 0.016066, loss_ce: 0.005534
2022-01-17 12:41:08,471 iteration 4379 : loss : 0.016866, loss_ce: 0.005419
2022-01-17 12:41:09,335 iteration 4380 : loss : 0.016103, loss_ce: 0.005451
2022-01-17 12:41:10,305 iteration 4381 : loss : 0.027779, loss_ce: 0.009134
2022-01-17 12:41:11,256 iteration 4382 : loss : 0.039118, loss_ce: 0.006455
2022-01-17 12:41:12,176 iteration 4383 : loss : 0.020380, loss_ce: 0.005406
2022-01-17 12:41:13,183 iteration 4384 : loss : 0.020118, loss_ce: 0.007711
2022-01-17 12:41:14,190 iteration 4385 : loss : 0.022285, loss_ce: 0.007170
2022-01-17 12:41:15,103 iteration 4386 : loss : 0.015053, loss_ce: 0.006554
 64%|██████████████████▋          | 258/400 [1:15:24<40:07, 16.95s/it]2022-01-17 12:41:16,023 iteration 4387 : loss : 0.017950, loss_ce: 0.005456
2022-01-17 12:41:16,978 iteration 4388 : loss : 0.019602, loss_ce: 0.008083
2022-01-17 12:41:17,927 iteration 4389 : loss : 0.020099, loss_ce: 0.007012
2022-01-17 12:41:18,808 iteration 4390 : loss : 0.016000, loss_ce: 0.005471
2022-01-17 12:41:19,770 iteration 4391 : loss : 0.020033, loss_ce: 0.006306
2022-01-17 12:41:20,707 iteration 4392 : loss : 0.017776, loss_ce: 0.005211
2022-01-17 12:41:21,726 iteration 4393 : loss : 0.021922, loss_ce: 0.008354
2022-01-17 12:41:22,712 iteration 4394 : loss : 0.022031, loss_ce: 0.008679
2022-01-17 12:41:23,761 iteration 4395 : loss : 0.026431, loss_ce: 0.009461
2022-01-17 12:41:24,672 iteration 4396 : loss : 0.017401, loss_ce: 0.005445
2022-01-17 12:41:25,728 iteration 4397 : loss : 0.020877, loss_ce: 0.009863
2022-01-17 12:41:26,619 iteration 4398 : loss : 0.020680, loss_ce: 0.008264
2022-01-17 12:41:27,615 iteration 4399 : loss : 0.017480, loss_ce: 0.006272
2022-01-17 12:41:28,580 iteration 4400 : loss : 0.037773, loss_ce: 0.012780
2022-01-17 12:41:29,674 iteration 4401 : loss : 0.027074, loss_ce: 0.010254
2022-01-17 12:41:30,641 iteration 4402 : loss : 0.023772, loss_ce: 0.006667
2022-01-17 12:41:31,612 iteration 4403 : loss : 0.019842, loss_ce: 0.007672
 65%|██████████████████▊          | 259/400 [1:15:41<39:31, 16.82s/it]2022-01-17 12:41:32,570 iteration 4404 : loss : 0.017892, loss_ce: 0.007637
2022-01-17 12:41:33,563 iteration 4405 : loss : 0.020010, loss_ce: 0.008532
2022-01-17 12:41:34,537 iteration 4406 : loss : 0.016238, loss_ce: 0.006601
2022-01-17 12:41:35,553 iteration 4407 : loss : 0.026456, loss_ce: 0.009550
2022-01-17 12:41:36,470 iteration 4408 : loss : 0.018810, loss_ce: 0.007189
2022-01-17 12:41:37,443 iteration 4409 : loss : 0.016656, loss_ce: 0.006052
2022-01-17 12:41:38,543 iteration 4410 : loss : 0.027039, loss_ce: 0.010013
2022-01-17 12:41:39,542 iteration 4411 : loss : 0.021681, loss_ce: 0.008872
2022-01-17 12:41:40,482 iteration 4412 : loss : 0.023369, loss_ce: 0.008050
2022-01-17 12:41:41,447 iteration 4413 : loss : 0.014572, loss_ce: 0.004532
2022-01-17 12:41:42,320 iteration 4414 : loss : 0.015493, loss_ce: 0.004880
2022-01-17 12:41:43,302 iteration 4415 : loss : 0.018032, loss_ce: 0.006438
2022-01-17 12:41:44,309 iteration 4416 : loss : 0.024604, loss_ce: 0.008451
2022-01-17 12:41:45,256 iteration 4417 : loss : 0.014132, loss_ce: 0.004195
2022-01-17 12:41:46,227 iteration 4418 : loss : 0.024340, loss_ce: 0.010579
2022-01-17 12:41:47,229 iteration 4419 : loss : 0.016044, loss_ce: 0.005487
2022-01-17 12:41:47,229 Training Data Eval:
2022-01-17 12:41:51,686   Average segmentation loss on training set: 0.0125
2022-01-17 12:41:51,733 Validation Data Eval:
2022-01-17 12:41:53,235   Average segmentation loss on validation set: 0.0868
2022-01-17 12:41:54,132 iteration 4420 : loss : 0.013057, loss_ce: 0.005664
 65%|██████████████████▊          | 260/400 [1:16:03<43:14, 18.53s/it]2022-01-17 12:41:55,095 iteration 4421 : loss : 0.016382, loss_ce: 0.005651
2022-01-17 12:41:56,069 iteration 4422 : loss : 0.021326, loss_ce: 0.008342
2022-01-17 12:41:57,092 iteration 4423 : loss : 0.021701, loss_ce: 0.008944
2022-01-17 12:41:57,991 iteration 4424 : loss : 0.018341, loss_ce: 0.005667
2022-01-17 12:41:58,880 iteration 4425 : loss : 0.014920, loss_ce: 0.005162
2022-01-17 12:41:59,891 iteration 4426 : loss : 0.012913, loss_ce: 0.004962
2022-01-17 12:42:00,784 iteration 4427 : loss : 0.016433, loss_ce: 0.006819
2022-01-17 12:42:01,633 iteration 4428 : loss : 0.014847, loss_ce: 0.006813
2022-01-17 12:42:02,506 iteration 4429 : loss : 0.016927, loss_ce: 0.005547
2022-01-17 12:42:03,384 iteration 4430 : loss : 0.013003, loss_ce: 0.005144
2022-01-17 12:42:04,346 iteration 4431 : loss : 0.019060, loss_ce: 0.008110
2022-01-17 12:42:05,343 iteration 4432 : loss : 0.019966, loss_ce: 0.008179
2022-01-17 12:42:06,268 iteration 4433 : loss : 0.022983, loss_ce: 0.005004
2022-01-17 12:42:07,150 iteration 4434 : loss : 0.015282, loss_ce: 0.006156
2022-01-17 12:42:08,096 iteration 4435 : loss : 0.024816, loss_ce: 0.004813
2022-01-17 12:42:09,037 iteration 4436 : loss : 0.015885, loss_ce: 0.006327
2022-01-17 12:42:10,051 iteration 4437 : loss : 0.016479, loss_ce: 0.005323
 65%|██████████████████▉          | 261/400 [1:16:19<41:06, 17.75s/it]2022-01-17 12:42:11,103 iteration 4438 : loss : 0.041042, loss_ce: 0.010230
2022-01-17 12:42:12,077 iteration 4439 : loss : 0.018224, loss_ce: 0.007033
2022-01-17 12:42:13,037 iteration 4440 : loss : 0.016615, loss_ce: 0.005999
2022-01-17 12:42:14,100 iteration 4441 : loss : 0.018628, loss_ce: 0.005677
2022-01-17 12:42:15,113 iteration 4442 : loss : 0.022406, loss_ce: 0.009982
2022-01-17 12:42:16,087 iteration 4443 : loss : 0.025341, loss_ce: 0.009035
2022-01-17 12:42:16,954 iteration 4444 : loss : 0.018924, loss_ce: 0.006010
2022-01-17 12:42:17,883 iteration 4445 : loss : 0.023407, loss_ce: 0.009560
2022-01-17 12:42:18,866 iteration 4446 : loss : 0.021454, loss_ce: 0.009211
2022-01-17 12:42:19,795 iteration 4447 : loss : 0.017627, loss_ce: 0.005557
2022-01-17 12:42:20,769 iteration 4448 : loss : 0.021412, loss_ce: 0.007256
2022-01-17 12:42:21,728 iteration 4449 : loss : 0.022851, loss_ce: 0.008831
2022-01-17 12:42:22,746 iteration 4450 : loss : 0.027402, loss_ce: 0.007589
2022-01-17 12:42:23,665 iteration 4451 : loss : 0.022404, loss_ce: 0.008966
2022-01-17 12:42:24,626 iteration 4452 : loss : 0.019293, loss_ce: 0.008989
2022-01-17 12:42:25,543 iteration 4453 : loss : 0.022212, loss_ce: 0.007588
2022-01-17 12:42:26,459 iteration 4454 : loss : 0.022591, loss_ce: 0.008596
 66%|██████████████████▉          | 262/400 [1:16:36<39:53, 17.34s/it]2022-01-17 12:42:27,470 iteration 4455 : loss : 0.017433, loss_ce: 0.004516
2022-01-17 12:42:28,334 iteration 4456 : loss : 0.017928, loss_ce: 0.006832
2022-01-17 12:42:29,310 iteration 4457 : loss : 0.024605, loss_ce: 0.009838
2022-01-17 12:42:30,367 iteration 4458 : loss : 0.032916, loss_ce: 0.012107
2022-01-17 12:42:31,484 iteration 4459 : loss : 0.021348, loss_ce: 0.009282
2022-01-17 12:42:32,380 iteration 4460 : loss : 0.017472, loss_ce: 0.005508
2022-01-17 12:42:33,324 iteration 4461 : loss : 0.018573, loss_ce: 0.005707
2022-01-17 12:42:34,307 iteration 4462 : loss : 0.020382, loss_ce: 0.009377
2022-01-17 12:42:35,236 iteration 4463 : loss : 0.027756, loss_ce: 0.010631
2022-01-17 12:42:36,162 iteration 4464 : loss : 0.018700, loss_ce: 0.005922
2022-01-17 12:42:37,036 iteration 4465 : loss : 0.017970, loss_ce: 0.003809
2022-01-17 12:42:37,937 iteration 4466 : loss : 0.012244, loss_ce: 0.003265
2022-01-17 12:42:38,891 iteration 4467 : loss : 0.031250, loss_ce: 0.012158
2022-01-17 12:42:39,884 iteration 4468 : loss : 0.018917, loss_ce: 0.007538
2022-01-17 12:42:40,914 iteration 4469 : loss : 0.023740, loss_ce: 0.010855
2022-01-17 12:42:41,916 iteration 4470 : loss : 0.017394, loss_ce: 0.006962
2022-01-17 12:42:42,945 iteration 4471 : loss : 0.020551, loss_ce: 0.006409
 66%|███████████████████          | 263/400 [1:16:52<39:00, 17.08s/it]2022-01-17 12:42:43,886 iteration 4472 : loss : 0.014245, loss_ce: 0.005946
2022-01-17 12:42:44,778 iteration 4473 : loss : 0.016951, loss_ce: 0.007016
2022-01-17 12:42:45,727 iteration 4474 : loss : 0.016751, loss_ce: 0.007892
2022-01-17 12:42:46,667 iteration 4475 : loss : 0.016599, loss_ce: 0.005007
2022-01-17 12:42:47,569 iteration 4476 : loss : 0.015751, loss_ce: 0.004408
2022-01-17 12:42:48,493 iteration 4477 : loss : 0.018644, loss_ce: 0.008074
2022-01-17 12:42:49,554 iteration 4478 : loss : 0.017824, loss_ce: 0.008574
2022-01-17 12:42:50,506 iteration 4479 : loss : 0.020803, loss_ce: 0.005403
2022-01-17 12:42:51,476 iteration 4480 : loss : 0.017725, loss_ce: 0.006041
2022-01-17 12:42:52,384 iteration 4481 : loss : 0.017808, loss_ce: 0.006513
2022-01-17 12:42:53,277 iteration 4482 : loss : 0.015184, loss_ce: 0.004355
2022-01-17 12:42:54,194 iteration 4483 : loss : 0.026863, loss_ce: 0.008716
2022-01-17 12:42:55,145 iteration 4484 : loss : 0.014058, loss_ce: 0.004374
2022-01-17 12:42:56,023 iteration 4485 : loss : 0.020599, loss_ce: 0.007823
2022-01-17 12:42:57,032 iteration 4486 : loss : 0.014127, loss_ce: 0.004890
2022-01-17 12:42:58,015 iteration 4487 : loss : 0.021134, loss_ce: 0.008591
2022-01-17 12:42:58,915 iteration 4488 : loss : 0.018552, loss_ce: 0.006951
 66%|███████████████████▏         | 264/400 [1:17:08<37:58, 16.75s/it]2022-01-17 12:42:59,938 iteration 4489 : loss : 0.017717, loss_ce: 0.007151
2022-01-17 12:43:00,876 iteration 4490 : loss : 0.016305, loss_ce: 0.006665
2022-01-17 12:43:01,929 iteration 4491 : loss : 0.021359, loss_ce: 0.007813
2022-01-17 12:43:02,850 iteration 4492 : loss : 0.023804, loss_ce: 0.005824
2022-01-17 12:43:03,888 iteration 4493 : loss : 0.020072, loss_ce: 0.012501
2022-01-17 12:43:04,796 iteration 4494 : loss : 0.024151, loss_ce: 0.007975
2022-01-17 12:43:05,760 iteration 4495 : loss : 0.024746, loss_ce: 0.005012
2022-01-17 12:43:06,733 iteration 4496 : loss : 0.021130, loss_ce: 0.005627
2022-01-17 12:43:07,579 iteration 4497 : loss : 0.017428, loss_ce: 0.007704
2022-01-17 12:43:08,524 iteration 4498 : loss : 0.016369, loss_ce: 0.004963
2022-01-17 12:43:09,444 iteration 4499 : loss : 0.014094, loss_ce: 0.005545
2022-01-17 12:43:10,392 iteration 4500 : loss : 0.022938, loss_ce: 0.006870
2022-01-17 12:43:11,312 iteration 4501 : loss : 0.016284, loss_ce: 0.006727
2022-01-17 12:43:12,244 iteration 4502 : loss : 0.018218, loss_ce: 0.005970
2022-01-17 12:43:13,279 iteration 4503 : loss : 0.015660, loss_ce: 0.005341
2022-01-17 12:43:14,127 iteration 4504 : loss : 0.015624, loss_ce: 0.005801
2022-01-17 12:43:14,127 Training Data Eval:
2022-01-17 12:43:18,584   Average segmentation loss on training set: 0.0116
2022-01-17 12:43:18,585 Validation Data Eval:
2022-01-17 12:43:20,093   Average segmentation loss on validation set: 0.1040
2022-01-17 12:43:21,051 iteration 4505 : loss : 0.015671, loss_ce: 0.005302
 66%|███████████████████▏         | 265/400 [1:17:30<41:19, 18.37s/it]2022-01-17 12:43:22,065 iteration 4506 : loss : 0.015859, loss_ce: 0.005520
2022-01-17 12:43:23,082 iteration 4507 : loss : 0.025673, loss_ce: 0.009297
2022-01-17 12:43:24,025 iteration 4508 : loss : 0.031672, loss_ce: 0.010080
2022-01-17 12:43:24,902 iteration 4509 : loss : 0.017681, loss_ce: 0.005774
2022-01-17 12:43:25,857 iteration 4510 : loss : 0.013119, loss_ce: 0.004272
2022-01-17 12:43:26,909 iteration 4511 : loss : 0.023860, loss_ce: 0.009749
2022-01-17 12:43:27,768 iteration 4512 : loss : 0.017197, loss_ce: 0.005557
2022-01-17 12:43:28,694 iteration 4513 : loss : 0.015483, loss_ce: 0.005291
2022-01-17 12:43:29,612 iteration 4514 : loss : 0.021249, loss_ce: 0.008721
2022-01-17 12:43:30,551 iteration 4515 : loss : 0.014382, loss_ce: 0.005535
2022-01-17 12:43:31,511 iteration 4516 : loss : 0.018415, loss_ce: 0.007528
2022-01-17 12:43:32,499 iteration 4517 : loss : 0.032168, loss_ce: 0.013270
2022-01-17 12:43:33,419 iteration 4518 : loss : 0.022057, loss_ce: 0.009622
2022-01-17 12:43:34,297 iteration 4519 : loss : 0.027701, loss_ce: 0.008655
2022-01-17 12:43:35,253 iteration 4520 : loss : 0.018514, loss_ce: 0.006423
2022-01-17 12:43:36,225 iteration 4521 : loss : 0.016017, loss_ce: 0.007088
2022-01-17 12:43:37,238 iteration 4522 : loss : 0.030212, loss_ce: 0.008475
 66%|███████████████████▎         | 266/400 [1:17:47<39:33, 17.71s/it]2022-01-17 12:43:38,304 iteration 4523 : loss : 0.022765, loss_ce: 0.010670
2022-01-17 12:43:39,267 iteration 4524 : loss : 0.025816, loss_ce: 0.008848
2022-01-17 12:43:40,242 iteration 4525 : loss : 0.025761, loss_ce: 0.011503
2022-01-17 12:43:41,184 iteration 4526 : loss : 0.026356, loss_ce: 0.010173
2022-01-17 12:43:42,051 iteration 4527 : loss : 0.014865, loss_ce: 0.005656
2022-01-17 12:43:42,961 iteration 4528 : loss : 0.019510, loss_ce: 0.006641
2022-01-17 12:43:43,928 iteration 4529 : loss : 0.014289, loss_ce: 0.005921
2022-01-17 12:43:44,838 iteration 4530 : loss : 0.023936, loss_ce: 0.005096
2022-01-17 12:43:45,792 iteration 4531 : loss : 0.018171, loss_ce: 0.006322
2022-01-17 12:43:46,768 iteration 4532 : loss : 0.014127, loss_ce: 0.004485
2022-01-17 12:43:47,690 iteration 4533 : loss : 0.016099, loss_ce: 0.007235
2022-01-17 12:43:48,618 iteration 4534 : loss : 0.026291, loss_ce: 0.006866
2022-01-17 12:43:49,601 iteration 4535 : loss : 0.019822, loss_ce: 0.006817
2022-01-17 12:43:50,575 iteration 4536 : loss : 0.018837, loss_ce: 0.007111
2022-01-17 12:43:51,525 iteration 4537 : loss : 0.022356, loss_ce: 0.010150
2022-01-17 12:43:52,463 iteration 4538 : loss : 0.019904, loss_ce: 0.006943
2022-01-17 12:43:53,405 iteration 4539 : loss : 0.015868, loss_ce: 0.005590
 67%|███████████████████▎         | 267/400 [1:18:03<38:14, 17.25s/it]2022-01-17 12:43:54,359 iteration 4540 : loss : 0.012868, loss_ce: 0.004517
2022-01-17 12:43:55,333 iteration 4541 : loss : 0.018734, loss_ce: 0.007380
2022-01-17 12:43:56,229 iteration 4542 : loss : 0.020856, loss_ce: 0.006921
2022-01-17 12:43:57,146 iteration 4543 : loss : 0.015982, loss_ce: 0.005184
2022-01-17 12:43:58,050 iteration 4544 : loss : 0.017127, loss_ce: 0.005714
2022-01-17 12:43:59,071 iteration 4545 : loss : 0.017786, loss_ce: 0.006652
2022-01-17 12:44:00,141 iteration 4546 : loss : 0.022774, loss_ce: 0.009568
2022-01-17 12:44:01,190 iteration 4547 : loss : 0.022938, loss_ce: 0.008773
2022-01-17 12:44:02,069 iteration 4548 : loss : 0.017002, loss_ce: 0.006483
2022-01-17 12:44:02,965 iteration 4549 : loss : 0.014591, loss_ce: 0.004010
2022-01-17 12:44:03,929 iteration 4550 : loss : 0.028960, loss_ce: 0.014025
2022-01-17 12:44:04,909 iteration 4551 : loss : 0.021435, loss_ce: 0.009537
2022-01-17 12:44:05,950 iteration 4552 : loss : 0.024556, loss_ce: 0.006495
2022-01-17 12:44:06,917 iteration 4553 : loss : 0.018093, loss_ce: 0.007397
2022-01-17 12:44:07,812 iteration 4554 : loss : 0.016126, loss_ce: 0.006800
2022-01-17 12:44:08,743 iteration 4555 : loss : 0.014157, loss_ce: 0.005617
2022-01-17 12:44:09,671 iteration 4556 : loss : 0.021828, loss_ce: 0.006623
 67%|███████████████████▍         | 268/400 [1:18:19<37:17, 16.95s/it]2022-01-17 12:44:10,622 iteration 4557 : loss : 0.018581, loss_ce: 0.007986
2022-01-17 12:44:11,600 iteration 4558 : loss : 0.017628, loss_ce: 0.006871
2022-01-17 12:44:12,611 iteration 4559 : loss : 0.017412, loss_ce: 0.006433
2022-01-17 12:44:13,580 iteration 4560 : loss : 0.016247, loss_ce: 0.009001
2022-01-17 12:44:14,474 iteration 4561 : loss : 0.014385, loss_ce: 0.004893
2022-01-17 12:44:15,426 iteration 4562 : loss : 0.020213, loss_ce: 0.008368
2022-01-17 12:44:16,357 iteration 4563 : loss : 0.017591, loss_ce: 0.005613
2022-01-17 12:44:17,279 iteration 4564 : loss : 0.025286, loss_ce: 0.010521
2022-01-17 12:44:18,223 iteration 4565 : loss : 0.017691, loss_ce: 0.006595
2022-01-17 12:44:19,190 iteration 4566 : loss : 0.015982, loss_ce: 0.005746
2022-01-17 12:44:20,129 iteration 4567 : loss : 0.016417, loss_ce: 0.006381
2022-01-17 12:44:20,990 iteration 4568 : loss : 0.013506, loss_ce: 0.004168
2022-01-17 12:44:21,880 iteration 4569 : loss : 0.020212, loss_ce: 0.007075
2022-01-17 12:44:22,783 iteration 4570 : loss : 0.014938, loss_ce: 0.005075
2022-01-17 12:44:23,775 iteration 4571 : loss : 0.020439, loss_ce: 0.009598
2022-01-17 12:44:24,762 iteration 4572 : loss : 0.023800, loss_ce: 0.008154
2022-01-17 12:44:25,761 iteration 4573 : loss : 0.027815, loss_ce: 0.009198
 67%|███████████████████▌         | 269/400 [1:18:35<36:26, 16.69s/it]2022-01-17 12:44:26,676 iteration 4574 : loss : 0.012022, loss_ce: 0.003670
2022-01-17 12:44:27,648 iteration 4575 : loss : 0.031941, loss_ce: 0.007444
2022-01-17 12:44:28,523 iteration 4576 : loss : 0.017558, loss_ce: 0.007801
2022-01-17 12:44:29,415 iteration 4577 : loss : 0.017688, loss_ce: 0.008414
2022-01-17 12:44:30,355 iteration 4578 : loss : 0.015669, loss_ce: 0.006059
2022-01-17 12:44:31,254 iteration 4579 : loss : 0.015478, loss_ce: 0.006193
2022-01-17 12:44:32,177 iteration 4580 : loss : 0.015832, loss_ce: 0.005809
2022-01-17 12:44:33,122 iteration 4581 : loss : 0.018586, loss_ce: 0.007133
2022-01-17 12:44:34,060 iteration 4582 : loss : 0.020911, loss_ce: 0.007425
2022-01-17 12:44:35,000 iteration 4583 : loss : 0.017048, loss_ce: 0.006407
2022-01-17 12:44:35,926 iteration 4584 : loss : 0.015731, loss_ce: 0.005289
2022-01-17 12:44:36,894 iteration 4585 : loss : 0.018327, loss_ce: 0.006017
2022-01-17 12:44:37,784 iteration 4586 : loss : 0.015178, loss_ce: 0.006185
2022-01-17 12:44:38,699 iteration 4587 : loss : 0.013647, loss_ce: 0.003895
2022-01-17 12:44:39,619 iteration 4588 : loss : 0.019939, loss_ce: 0.008076
2022-01-17 12:44:40,585 iteration 4589 : loss : 0.017791, loss_ce: 0.006209
2022-01-17 12:44:40,585 Training Data Eval:
2022-01-17 12:44:45,034   Average segmentation loss on training set: 0.0125
2022-01-17 12:44:45,035 Validation Data Eval:
2022-01-17 12:44:46,536   Average segmentation loss on validation set: 0.0720
2022-01-17 12:44:47,447 iteration 4590 : loss : 0.019319, loss_ce: 0.008171
 68%|███████████████████▌         | 270/400 [1:18:57<39:25, 18.19s/it]2022-01-17 12:44:48,416 iteration 4591 : loss : 0.026949, loss_ce: 0.006903
2022-01-17 12:44:49,393 iteration 4592 : loss : 0.018749, loss_ce: 0.006687
2022-01-17 12:44:50,348 iteration 4593 : loss : 0.018682, loss_ce: 0.008164
2022-01-17 12:44:51,342 iteration 4594 : loss : 0.039882, loss_ce: 0.010643
2022-01-17 12:44:52,266 iteration 4595 : loss : 0.015948, loss_ce: 0.005203
2022-01-17 12:44:53,173 iteration 4596 : loss : 0.015742, loss_ce: 0.004802
2022-01-17 12:44:54,120 iteration 4597 : loss : 0.016375, loss_ce: 0.007010
2022-01-17 12:44:55,113 iteration 4598 : loss : 0.021022, loss_ce: 0.006338
2022-01-17 12:44:56,083 iteration 4599 : loss : 0.015464, loss_ce: 0.007747
2022-01-17 12:44:57,005 iteration 4600 : loss : 0.017421, loss_ce: 0.007053
2022-01-17 12:44:57,962 iteration 4601 : loss : 0.015292, loss_ce: 0.006596
2022-01-17 12:44:58,990 iteration 4602 : loss : 0.024983, loss_ce: 0.006326
2022-01-17 12:44:59,940 iteration 4603 : loss : 0.021706, loss_ce: 0.007177
2022-01-17 12:45:00,909 iteration 4604 : loss : 0.019318, loss_ce: 0.007638
2022-01-17 12:45:01,889 iteration 4605 : loss : 0.035661, loss_ce: 0.006530
2022-01-17 12:45:02,864 iteration 4606 : loss : 0.019678, loss_ce: 0.007088
2022-01-17 12:45:03,839 iteration 4607 : loss : 0.019055, loss_ce: 0.009525
 68%|███████████████████▋         | 271/400 [1:19:13<37:57, 17.65s/it]2022-01-17 12:45:04,762 iteration 4608 : loss : 0.013442, loss_ce: 0.005092
2022-01-17 12:45:05,698 iteration 4609 : loss : 0.025415, loss_ce: 0.011099
2022-01-17 12:45:06,575 iteration 4610 : loss : 0.021193, loss_ce: 0.006548
2022-01-17 12:45:07,455 iteration 4611 : loss : 0.017254, loss_ce: 0.006408
2022-01-17 12:45:08,314 iteration 4612 : loss : 0.018186, loss_ce: 0.005647
2022-01-17 12:45:09,247 iteration 4613 : loss : 0.016962, loss_ce: 0.005922
2022-01-17 12:45:10,180 iteration 4614 : loss : 0.017247, loss_ce: 0.008640
2022-01-17 12:45:11,148 iteration 4615 : loss : 0.016530, loss_ce: 0.005836
2022-01-17 12:45:12,186 iteration 4616 : loss : 0.028754, loss_ce: 0.012051
2022-01-17 12:45:13,130 iteration 4617 : loss : 0.022285, loss_ce: 0.008490
2022-01-17 12:45:14,015 iteration 4618 : loss : 0.015474, loss_ce: 0.004316
2022-01-17 12:45:14,913 iteration 4619 : loss : 0.014102, loss_ce: 0.006152
2022-01-17 12:45:15,893 iteration 4620 : loss : 0.023237, loss_ce: 0.008334
2022-01-17 12:45:16,816 iteration 4621 : loss : 0.023673, loss_ce: 0.012825
2022-01-17 12:45:17,753 iteration 4622 : loss : 0.021164, loss_ce: 0.007018
2022-01-17 12:45:18,677 iteration 4623 : loss : 0.016952, loss_ce: 0.004956
2022-01-17 12:45:19,618 iteration 4624 : loss : 0.015804, loss_ce: 0.006746
 68%|███████████████████▋         | 272/400 [1:19:29<36:27, 17.09s/it]2022-01-17 12:45:20,628 iteration 4625 : loss : 0.017715, loss_ce: 0.006345
2022-01-17 12:45:21,609 iteration 4626 : loss : 0.016729, loss_ce: 0.007491
2022-01-17 12:45:22,625 iteration 4627 : loss : 0.026242, loss_ce: 0.010439
2022-01-17 12:45:23,522 iteration 4628 : loss : 0.015507, loss_ce: 0.005322
2022-01-17 12:45:24,380 iteration 4629 : loss : 0.016155, loss_ce: 0.005255
2022-01-17 12:45:25,298 iteration 4630 : loss : 0.015021, loss_ce: 0.005223
2022-01-17 12:45:26,237 iteration 4631 : loss : 0.020080, loss_ce: 0.006767
2022-01-17 12:45:27,173 iteration 4632 : loss : 0.016066, loss_ce: 0.005221
2022-01-17 12:45:28,087 iteration 4633 : loss : 0.014417, loss_ce: 0.004518
2022-01-17 12:45:28,982 iteration 4634 : loss : 0.013171, loss_ce: 0.005700
2022-01-17 12:45:29,834 iteration 4635 : loss : 0.013425, loss_ce: 0.005054
2022-01-17 12:45:30,839 iteration 4636 : loss : 0.024951, loss_ce: 0.011971
2022-01-17 12:45:31,745 iteration 4637 : loss : 0.019512, loss_ce: 0.006067
2022-01-17 12:45:32,782 iteration 4638 : loss : 0.040854, loss_ce: 0.020463
2022-01-17 12:45:33,754 iteration 4639 : loss : 0.020712, loss_ce: 0.007939
2022-01-17 12:45:34,794 iteration 4640 : loss : 0.017164, loss_ce: 0.006538
2022-01-17 12:45:35,764 iteration 4641 : loss : 0.017217, loss_ce: 0.006611
 68%|███████████████████▊         | 273/400 [1:19:45<35:34, 16.81s/it]2022-01-17 12:45:36,723 iteration 4642 : loss : 0.023516, loss_ce: 0.004840
2022-01-17 12:45:37,643 iteration 4643 : loss : 0.020495, loss_ce: 0.006982
2022-01-17 12:45:38,616 iteration 4644 : loss : 0.018373, loss_ce: 0.005742
2022-01-17 12:45:39,599 iteration 4645 : loss : 0.018053, loss_ce: 0.008439
2022-01-17 12:45:40,549 iteration 4646 : loss : 0.027164, loss_ce: 0.007368
2022-01-17 12:45:41,407 iteration 4647 : loss : 0.014287, loss_ce: 0.004527
2022-01-17 12:45:42,316 iteration 4648 : loss : 0.017557, loss_ce: 0.006132
2022-01-17 12:45:43,263 iteration 4649 : loss : 0.018584, loss_ce: 0.007725
2022-01-17 12:45:44,251 iteration 4650 : loss : 0.021982, loss_ce: 0.008800
2022-01-17 12:45:45,136 iteration 4651 : loss : 0.015704, loss_ce: 0.007386
2022-01-17 12:45:46,137 iteration 4652 : loss : 0.020426, loss_ce: 0.008215
2022-01-17 12:45:47,044 iteration 4653 : loss : 0.018326, loss_ce: 0.006772
2022-01-17 12:45:47,950 iteration 4654 : loss : 0.019845, loss_ce: 0.005781
2022-01-17 12:45:48,941 iteration 4655 : loss : 0.021310, loss_ce: 0.008231
2022-01-17 12:45:49,949 iteration 4656 : loss : 0.018912, loss_ce: 0.008399
2022-01-17 12:45:50,915 iteration 4657 : loss : 0.019157, loss_ce: 0.009203
2022-01-17 12:45:51,871 iteration 4658 : loss : 0.023354, loss_ce: 0.009789
 68%|███████████████████▊         | 274/400 [1:20:01<34:51, 16.60s/it]2022-01-17 12:45:52,861 iteration 4659 : loss : 0.028434, loss_ce: 0.011814
2022-01-17 12:45:53,833 iteration 4660 : loss : 0.024947, loss_ce: 0.012654
2022-01-17 12:45:54,777 iteration 4661 : loss : 0.023723, loss_ce: 0.008663
2022-01-17 12:45:55,654 iteration 4662 : loss : 0.013605, loss_ce: 0.004935
2022-01-17 12:45:56,601 iteration 4663 : loss : 0.019586, loss_ce: 0.007840
2022-01-17 12:45:57,507 iteration 4664 : loss : 0.013418, loss_ce: 0.004712
2022-01-17 12:45:58,423 iteration 4665 : loss : 0.016832, loss_ce: 0.005985
2022-01-17 12:45:59,259 iteration 4666 : loss : 0.013705, loss_ce: 0.004652
2022-01-17 12:46:00,155 iteration 4667 : loss : 0.013243, loss_ce: 0.004723
2022-01-17 12:46:01,203 iteration 4668 : loss : 0.022237, loss_ce: 0.010044
2022-01-17 12:46:02,090 iteration 4669 : loss : 0.014942, loss_ce: 0.006423
2022-01-17 12:46:02,989 iteration 4670 : loss : 0.018510, loss_ce: 0.007109
2022-01-17 12:46:03,874 iteration 4671 : loss : 0.016757, loss_ce: 0.004429
2022-01-17 12:46:04,892 iteration 4672 : loss : 0.027802, loss_ce: 0.013215
2022-01-17 12:46:05,873 iteration 4673 : loss : 0.014208, loss_ce: 0.005895
2022-01-17 12:46:06,738 iteration 4674 : loss : 0.013218, loss_ce: 0.003559
2022-01-17 12:46:06,738 Training Data Eval:
2022-01-17 12:46:11,165   Average segmentation loss on training set: 0.0113
2022-01-17 12:46:11,166 Validation Data Eval:
2022-01-17 12:46:12,665   Average segmentation loss on validation set: 0.0810
2022-01-17 12:46:13,643 iteration 4675 : loss : 0.018620, loss_ce: 0.007441
 69%|███████████████████▉         | 275/400 [1:20:23<37:48, 18.15s/it]2022-01-17 12:46:14,700 iteration 4676 : loss : 0.023022, loss_ce: 0.007261
2022-01-17 12:46:15,604 iteration 4677 : loss : 0.022256, loss_ce: 0.007363
2022-01-17 12:46:16,550 iteration 4678 : loss : 0.017338, loss_ce: 0.005438
2022-01-17 12:46:17,541 iteration 4679 : loss : 0.044449, loss_ce: 0.011904
2022-01-17 12:46:18,462 iteration 4680 : loss : 0.013116, loss_ce: 0.004828
2022-01-17 12:46:19,369 iteration 4681 : loss : 0.032406, loss_ce: 0.007705
2022-01-17 12:46:20,263 iteration 4682 : loss : 0.018525, loss_ce: 0.006403
2022-01-17 12:46:21,100 iteration 4683 : loss : 0.018646, loss_ce: 0.005041
2022-01-17 12:46:22,086 iteration 4684 : loss : 0.020437, loss_ce: 0.008373
2022-01-17 12:46:23,043 iteration 4685 : loss : 0.025890, loss_ce: 0.008653
2022-01-17 12:46:24,001 iteration 4686 : loss : 0.026230, loss_ce: 0.008446
2022-01-17 12:46:24,909 iteration 4687 : loss : 0.016909, loss_ce: 0.007187
2022-01-17 12:46:25,770 iteration 4688 : loss : 0.013346, loss_ce: 0.005929
2022-01-17 12:46:26,633 iteration 4689 : loss : 0.012372, loss_ce: 0.005456
2022-01-17 12:46:27,519 iteration 4690 : loss : 0.016795, loss_ce: 0.006250
2022-01-17 12:46:28,490 iteration 4691 : loss : 0.037130, loss_ce: 0.019009
2022-01-17 12:46:29,404 iteration 4692 : loss : 0.016697, loss_ce: 0.004620
 69%|████████████████████         | 276/400 [1:20:39<36:01, 17.43s/it]2022-01-17 12:46:30,439 iteration 4693 : loss : 0.019543, loss_ce: 0.006383
2022-01-17 12:46:31,387 iteration 4694 : loss : 0.025704, loss_ce: 0.010105
2022-01-17 12:46:32,185 iteration 4695 : loss : 0.012526, loss_ce: 0.003954
2022-01-17 12:46:33,186 iteration 4696 : loss : 0.023064, loss_ce: 0.009058
2022-01-17 12:46:34,082 iteration 4697 : loss : 0.022251, loss_ce: 0.007820
2022-01-17 12:46:35,010 iteration 4698 : loss : 0.020514, loss_ce: 0.009115
2022-01-17 12:46:35,992 iteration 4699 : loss : 0.014226, loss_ce: 0.006277
2022-01-17 12:46:36,875 iteration 4700 : loss : 0.020587, loss_ce: 0.009328
2022-01-17 12:46:37,890 iteration 4701 : loss : 0.022506, loss_ce: 0.008279
2022-01-17 12:46:38,783 iteration 4702 : loss : 0.016568, loss_ce: 0.006203
2022-01-17 12:46:39,663 iteration 4703 : loss : 0.023431, loss_ce: 0.006223
2022-01-17 12:46:40,584 iteration 4704 : loss : 0.024206, loss_ce: 0.007817
2022-01-17 12:46:41,395 iteration 4705 : loss : 0.013474, loss_ce: 0.005634
2022-01-17 12:46:42,321 iteration 4706 : loss : 0.016193, loss_ce: 0.005099
2022-01-17 12:46:43,296 iteration 4707 : loss : 0.020474, loss_ce: 0.008985
2022-01-17 12:46:44,269 iteration 4708 : loss : 0.016944, loss_ce: 0.005102
2022-01-17 12:46:45,224 iteration 4709 : loss : 0.025893, loss_ce: 0.009187
 69%|████████████████████         | 277/400 [1:20:55<34:44, 16.95s/it]2022-01-17 12:46:46,213 iteration 4710 : loss : 0.023748, loss_ce: 0.006224
2022-01-17 12:46:47,266 iteration 4711 : loss : 0.019126, loss_ce: 0.006769
2022-01-17 12:46:48,159 iteration 4712 : loss : 0.017717, loss_ce: 0.007627
2022-01-17 12:46:49,065 iteration 4713 : loss : 0.016068, loss_ce: 0.006115
2022-01-17 12:46:49,992 iteration 4714 : loss : 0.017111, loss_ce: 0.006064
2022-01-17 12:46:50,969 iteration 4715 : loss : 0.030268, loss_ce: 0.010146
2022-01-17 12:46:51,902 iteration 4716 : loss : 0.015792, loss_ce: 0.005785
2022-01-17 12:46:52,809 iteration 4717 : loss : 0.025199, loss_ce: 0.008198
2022-01-17 12:46:53,667 iteration 4718 : loss : 0.015008, loss_ce: 0.005381
2022-01-17 12:46:54,532 iteration 4719 : loss : 0.018047, loss_ce: 0.007976
2022-01-17 12:46:55,427 iteration 4720 : loss : 0.016368, loss_ce: 0.006351
2022-01-17 12:46:56,339 iteration 4721 : loss : 0.023554, loss_ce: 0.008082
2022-01-17 12:46:57,319 iteration 4722 : loss : 0.025861, loss_ce: 0.007859
2022-01-17 12:46:58,240 iteration 4723 : loss : 0.015027, loss_ce: 0.005584
2022-01-17 12:46:59,097 iteration 4724 : loss : 0.017475, loss_ce: 0.006934
2022-01-17 12:46:59,960 iteration 4725 : loss : 0.016897, loss_ce: 0.006741
2022-01-17 12:47:00,882 iteration 4726 : loss : 0.020673, loss_ce: 0.008110
 70%|████████████████████▏        | 278/400 [1:21:10<33:40, 16.56s/it]2022-01-17 12:47:01,906 iteration 4727 : loss : 0.019989, loss_ce: 0.007596
2022-01-17 12:47:02,773 iteration 4728 : loss : 0.014913, loss_ce: 0.005616
2022-01-17 12:47:03,654 iteration 4729 : loss : 0.014480, loss_ce: 0.005057
2022-01-17 12:47:04,535 iteration 4730 : loss : 0.011509, loss_ce: 0.003496
2022-01-17 12:47:05,507 iteration 4731 : loss : 0.020544, loss_ce: 0.007580
2022-01-17 12:47:06,437 iteration 4732 : loss : 0.016438, loss_ce: 0.005276
2022-01-17 12:47:07,366 iteration 4733 : loss : 0.016162, loss_ce: 0.006174
2022-01-17 12:47:08,262 iteration 4734 : loss : 0.017760, loss_ce: 0.006678
2022-01-17 12:47:09,272 iteration 4735 : loss : 0.017609, loss_ce: 0.005641
2022-01-17 12:47:10,131 iteration 4736 : loss : 0.019272, loss_ce: 0.007706
2022-01-17 12:47:11,122 iteration 4737 : loss : 0.018703, loss_ce: 0.007265
2022-01-17 12:47:12,043 iteration 4738 : loss : 0.014340, loss_ce: 0.005093
2022-01-17 12:47:12,963 iteration 4739 : loss : 0.016707, loss_ce: 0.006104
2022-01-17 12:47:13,932 iteration 4740 : loss : 0.018571, loss_ce: 0.008009
2022-01-17 12:47:14,834 iteration 4741 : loss : 0.015979, loss_ce: 0.005151
2022-01-17 12:47:15,742 iteration 4742 : loss : 0.017401, loss_ce: 0.007789
2022-01-17 12:47:16,730 iteration 4743 : loss : 0.018593, loss_ce: 0.005229
 70%|████████████████████▏        | 279/400 [1:21:26<32:58, 16.35s/it]2022-01-17 12:47:17,740 iteration 4744 : loss : 0.017130, loss_ce: 0.005719
2022-01-17 12:47:18,658 iteration 4745 : loss : 0.028339, loss_ce: 0.007427
2022-01-17 12:47:19,533 iteration 4746 : loss : 0.015145, loss_ce: 0.007662
2022-01-17 12:47:20,430 iteration 4747 : loss : 0.019114, loss_ce: 0.006373
2022-01-17 12:47:21,364 iteration 4748 : loss : 0.017700, loss_ce: 0.005637
2022-01-17 12:47:22,300 iteration 4749 : loss : 0.029118, loss_ce: 0.009105
2022-01-17 12:47:23,271 iteration 4750 : loss : 0.017679, loss_ce: 0.006970
2022-01-17 12:47:24,169 iteration 4751 : loss : 0.021034, loss_ce: 0.008065
2022-01-17 12:47:25,116 iteration 4752 : loss : 0.017363, loss_ce: 0.005876
2022-01-17 12:47:26,078 iteration 4753 : loss : 0.017012, loss_ce: 0.005466
2022-01-17 12:47:27,022 iteration 4754 : loss : 0.015784, loss_ce: 0.004869
2022-01-17 12:47:28,043 iteration 4755 : loss : 0.017541, loss_ce: 0.004722
2022-01-17 12:47:28,931 iteration 4756 : loss : 0.016047, loss_ce: 0.007494
2022-01-17 12:47:29,837 iteration 4757 : loss : 0.022879, loss_ce: 0.008907
2022-01-17 12:47:30,721 iteration 4758 : loss : 0.016498, loss_ce: 0.004762
2022-01-17 12:47:31,640 iteration 4759 : loss : 0.012366, loss_ce: 0.004245
2022-01-17 12:47:31,640 Training Data Eval:
2022-01-17 12:47:36,056   Average segmentation loss on training set: 0.0115
2022-01-17 12:47:36,056 Validation Data Eval:
2022-01-17 12:47:37,544   Average segmentation loss on validation set: 0.0814
2022-01-17 12:47:38,444 iteration 4760 : loss : 0.017366, loss_ce: 0.007118
 70%|████████████████████▎        | 280/400 [1:21:48<35:54, 17.96s/it]2022-01-17 12:47:39,397 iteration 4761 : loss : 0.016660, loss_ce: 0.005553
2022-01-17 12:47:40,354 iteration 4762 : loss : 0.018984, loss_ce: 0.006814
2022-01-17 12:47:41,229 iteration 4763 : loss : 0.013470, loss_ce: 0.005295
2022-01-17 12:47:42,192 iteration 4764 : loss : 0.016429, loss_ce: 0.005705
2022-01-17 12:47:43,094 iteration 4765 : loss : 0.024868, loss_ce: 0.011837
2022-01-17 12:47:44,068 iteration 4766 : loss : 0.018510, loss_ce: 0.007003
2022-01-17 12:47:45,003 iteration 4767 : loss : 0.017302, loss_ce: 0.007662
2022-01-17 12:47:45,871 iteration 4768 : loss : 0.016100, loss_ce: 0.005755
2022-01-17 12:47:46,822 iteration 4769 : loss : 0.023601, loss_ce: 0.007969
2022-01-17 12:47:47,776 iteration 4770 : loss : 0.019480, loss_ce: 0.007907
2022-01-17 12:47:48,630 iteration 4771 : loss : 0.014306, loss_ce: 0.004592
2022-01-17 12:47:49,592 iteration 4772 : loss : 0.018049, loss_ce: 0.007005
2022-01-17 12:47:50,548 iteration 4773 : loss : 0.019325, loss_ce: 0.006828
2022-01-17 12:47:51,494 iteration 4774 : loss : 0.017559, loss_ce: 0.006477
2022-01-17 12:47:52,385 iteration 4775 : loss : 0.019228, loss_ce: 0.005554
2022-01-17 12:47:53,294 iteration 4776 : loss : 0.013782, loss_ce: 0.007275
2022-01-17 12:47:54,339 iteration 4777 : loss : 0.020578, loss_ce: 0.009743
 70%|████████████████████▎        | 281/400 [1:22:04<34:23, 17.34s/it]2022-01-17 12:47:55,236 iteration 4778 : loss : 0.010978, loss_ce: 0.002917
2022-01-17 12:47:56,170 iteration 4779 : loss : 0.021550, loss_ce: 0.007674
2022-01-17 12:47:57,019 iteration 4780 : loss : 0.011894, loss_ce: 0.003955
2022-01-17 12:47:57,916 iteration 4781 : loss : 0.023405, loss_ce: 0.006975
2022-01-17 12:47:58,885 iteration 4782 : loss : 0.026292, loss_ce: 0.012100
2022-01-17 12:47:59,804 iteration 4783 : loss : 0.012249, loss_ce: 0.005144
2022-01-17 12:48:00,671 iteration 4784 : loss : 0.016674, loss_ce: 0.007911
2022-01-17 12:48:01,667 iteration 4785 : loss : 0.017184, loss_ce: 0.005719
2022-01-17 12:48:02,616 iteration 4786 : loss : 0.020210, loss_ce: 0.007859
2022-01-17 12:48:03,564 iteration 4787 : loss : 0.019352, loss_ce: 0.006323
2022-01-17 12:48:04,512 iteration 4788 : loss : 0.016275, loss_ce: 0.005525
2022-01-17 12:48:05,367 iteration 4789 : loss : 0.015605, loss_ce: 0.007594
2022-01-17 12:48:06,369 iteration 4790 : loss : 0.023080, loss_ce: 0.007663
2022-01-17 12:48:07,266 iteration 4791 : loss : 0.017323, loss_ce: 0.007780
2022-01-17 12:48:08,235 iteration 4792 : loss : 0.020236, loss_ce: 0.005181
2022-01-17 12:48:09,116 iteration 4793 : loss : 0.013513, loss_ce: 0.004536
2022-01-17 12:48:09,953 iteration 4794 : loss : 0.015132, loss_ce: 0.004253
 70%|████████████████████▍        | 282/400 [1:22:19<33:04, 16.82s/it]2022-01-17 12:48:10,930 iteration 4795 : loss : 0.020484, loss_ce: 0.005524
2022-01-17 12:48:11,858 iteration 4796 : loss : 0.013554, loss_ce: 0.004354
2022-01-17 12:48:12,791 iteration 4797 : loss : 0.023574, loss_ce: 0.010019
2022-01-17 12:48:13,767 iteration 4798 : loss : 0.024686, loss_ce: 0.008790
2022-01-17 12:48:14,685 iteration 4799 : loss : 0.012101, loss_ce: 0.003480
2022-01-17 12:48:15,613 iteration 4800 : loss : 0.019972, loss_ce: 0.006146
2022-01-17 12:48:16,613 iteration 4801 : loss : 0.017966, loss_ce: 0.007720
2022-01-17 12:48:17,466 iteration 4802 : loss : 0.013643, loss_ce: 0.005191
2022-01-17 12:48:18,368 iteration 4803 : loss : 0.017949, loss_ce: 0.008546
2022-01-17 12:48:19,353 iteration 4804 : loss : 0.034568, loss_ce: 0.008639
2022-01-17 12:48:20,314 iteration 4805 : loss : 0.025058, loss_ce: 0.010379
2022-01-17 12:48:21,283 iteration 4806 : loss : 0.018195, loss_ce: 0.007118
2022-01-17 12:48:22,127 iteration 4807 : loss : 0.018599, loss_ce: 0.007702
2022-01-17 12:48:22,969 iteration 4808 : loss : 0.016417, loss_ce: 0.006855
2022-01-17 12:48:23,894 iteration 4809 : loss : 0.020723, loss_ce: 0.009902
2022-01-17 12:48:24,809 iteration 4810 : loss : 0.027112, loss_ce: 0.006781
2022-01-17 12:48:25,741 iteration 4811 : loss : 0.015490, loss_ce: 0.006028
 71%|████████████████████▌        | 283/400 [1:22:35<32:11, 16.51s/it]2022-01-17 12:48:26,652 iteration 4812 : loss : 0.021374, loss_ce: 0.007897
2022-01-17 12:48:27,590 iteration 4813 : loss : 0.016081, loss_ce: 0.004475
2022-01-17 12:48:28,554 iteration 4814 : loss : 0.020134, loss_ce: 0.005078
2022-01-17 12:48:29,412 iteration 4815 : loss : 0.013422, loss_ce: 0.005845
2022-01-17 12:48:30,427 iteration 4816 : loss : 0.020960, loss_ce: 0.009139
2022-01-17 12:48:31,327 iteration 4817 : loss : 0.025016, loss_ce: 0.008901
2022-01-17 12:48:32,220 iteration 4818 : loss : 0.015021, loss_ce: 0.005513
2022-01-17 12:48:33,060 iteration 4819 : loss : 0.018422, loss_ce: 0.006945
2022-01-17 12:48:33,960 iteration 4820 : loss : 0.017891, loss_ce: 0.007074
2022-01-17 12:48:34,963 iteration 4821 : loss : 0.018570, loss_ce: 0.008518
2022-01-17 12:48:35,955 iteration 4822 : loss : 0.016980, loss_ce: 0.005667
2022-01-17 12:48:36,871 iteration 4823 : loss : 0.015278, loss_ce: 0.006368
2022-01-17 12:48:37,815 iteration 4824 : loss : 0.017536, loss_ce: 0.006800
2022-01-17 12:48:38,709 iteration 4825 : loss : 0.018390, loss_ce: 0.006553
2022-01-17 12:48:39,595 iteration 4826 : loss : 0.026843, loss_ce: 0.006892
2022-01-17 12:48:40,491 iteration 4827 : loss : 0.018821, loss_ce: 0.007627
2022-01-17 12:48:41,375 iteration 4828 : loss : 0.014374, loss_ce: 0.005348
 71%|████████████████████▌        | 284/400 [1:22:51<31:24, 16.25s/it]2022-01-17 12:48:42,286 iteration 4829 : loss : 0.017845, loss_ce: 0.005747
2022-01-17 12:48:43,244 iteration 4830 : loss : 0.015450, loss_ce: 0.007120
2022-01-17 12:48:44,183 iteration 4831 : loss : 0.013906, loss_ce: 0.005493
2022-01-17 12:48:45,101 iteration 4832 : loss : 0.017968, loss_ce: 0.005723
2022-01-17 12:48:46,060 iteration 4833 : loss : 0.025449, loss_ce: 0.008114
2022-01-17 12:48:46,921 iteration 4834 : loss : 0.016689, loss_ce: 0.005473
2022-01-17 12:48:47,943 iteration 4835 : loss : 0.015195, loss_ce: 0.006231
2022-01-17 12:48:48,858 iteration 4836 : loss : 0.026171, loss_ce: 0.008566
2022-01-17 12:48:49,813 iteration 4837 : loss : 0.019571, loss_ce: 0.005281
2022-01-17 12:48:50,707 iteration 4838 : loss : 0.013374, loss_ce: 0.003913
2022-01-17 12:48:51,646 iteration 4839 : loss : 0.030774, loss_ce: 0.012670
2022-01-17 12:48:52,563 iteration 4840 : loss : 0.016544, loss_ce: 0.007676
2022-01-17 12:48:53,416 iteration 4841 : loss : 0.012547, loss_ce: 0.003796
2022-01-17 12:48:54,342 iteration 4842 : loss : 0.013966, loss_ce: 0.004710
2022-01-17 12:48:55,349 iteration 4843 : loss : 0.014824, loss_ce: 0.004644
2022-01-17 12:48:56,267 iteration 4844 : loss : 0.019087, loss_ce: 0.006610
2022-01-17 12:48:56,267 Training Data Eval:
2022-01-17 12:49:00,672   Average segmentation loss on training set: 0.0110
2022-01-17 12:49:00,672 Validation Data Eval:
2022-01-17 12:49:02,172   Average segmentation loss on validation set: 0.0766
2022-01-17 12:49:03,138 iteration 4845 : loss : 0.017363, loss_ce: 0.007781
 71%|████████████████████▋        | 285/400 [1:23:13<34:18, 17.90s/it]2022-01-17 12:49:04,071 iteration 4846 : loss : 0.015922, loss_ce: 0.005775
2022-01-17 12:49:04,961 iteration 4847 : loss : 0.016335, loss_ce: 0.005753
2022-01-17 12:49:05,929 iteration 4848 : loss : 0.020806, loss_ce: 0.009549
2022-01-17 12:49:06,879 iteration 4849 : loss : 0.013686, loss_ce: 0.003001
2022-01-17 12:49:07,776 iteration 4850 : loss : 0.015875, loss_ce: 0.004363
2022-01-17 12:49:08,799 iteration 4851 : loss : 0.015173, loss_ce: 0.006234
2022-01-17 12:49:09,696 iteration 4852 : loss : 0.016588, loss_ce: 0.006143
2022-01-17 12:49:10,613 iteration 4853 : loss : 0.014567, loss_ce: 0.006211
2022-01-17 12:49:11,533 iteration 4854 : loss : 0.015270, loss_ce: 0.006063
2022-01-17 12:49:12,427 iteration 4855 : loss : 0.017641, loss_ce: 0.004581
2022-01-17 12:49:13,436 iteration 4856 : loss : 0.022156, loss_ce: 0.008269
2022-01-17 12:49:14,329 iteration 4857 : loss : 0.012591, loss_ce: 0.004504
2022-01-17 12:49:15,320 iteration 4858 : loss : 0.016355, loss_ce: 0.005957
2022-01-17 12:49:16,177 iteration 4859 : loss : 0.010976, loss_ce: 0.004397
2022-01-17 12:49:17,133 iteration 4860 : loss : 0.020349, loss_ce: 0.008940
2022-01-17 12:49:18,026 iteration 4861 : loss : 0.015298, loss_ce: 0.005014
2022-01-17 12:49:18,986 iteration 4862 : loss : 0.016950, loss_ce: 0.008446
 72%|████████████████████▋        | 286/400 [1:23:28<32:50, 17.28s/it]2022-01-17 12:49:20,026 iteration 4863 : loss : 0.020185, loss_ce: 0.005198
2022-01-17 12:49:20,939 iteration 4864 : loss : 0.014498, loss_ce: 0.005125
2022-01-17 12:49:21,834 iteration 4865 : loss : 0.014061, loss_ce: 0.006845
2022-01-17 12:49:22,812 iteration 4866 : loss : 0.021319, loss_ce: 0.006767
2022-01-17 12:49:23,736 iteration 4867 : loss : 0.017667, loss_ce: 0.006283
2022-01-17 12:49:24,558 iteration 4868 : loss : 0.014401, loss_ce: 0.006045
2022-01-17 12:49:25,563 iteration 4869 : loss : 0.018008, loss_ce: 0.007943
2022-01-17 12:49:26,472 iteration 4870 : loss : 0.010734, loss_ce: 0.003820
2022-01-17 12:49:27,479 iteration 4871 : loss : 0.024808, loss_ce: 0.009734
2022-01-17 12:49:28,336 iteration 4872 : loss : 0.012971, loss_ce: 0.003668
2022-01-17 12:49:29,351 iteration 4873 : loss : 0.014213, loss_ce: 0.005161
2022-01-17 12:49:30,299 iteration 4874 : loss : 0.019657, loss_ce: 0.006384
2022-01-17 12:49:31,202 iteration 4875 : loss : 0.018535, loss_ce: 0.007248
2022-01-17 12:49:32,035 iteration 4876 : loss : 0.016116, loss_ce: 0.004820
2022-01-17 12:49:33,001 iteration 4877 : loss : 0.018939, loss_ce: 0.008874
2022-01-17 12:49:33,996 iteration 4878 : loss : 0.024034, loss_ce: 0.007539
2022-01-17 12:49:34,911 iteration 4879 : loss : 0.016892, loss_ce: 0.005497
 72%|████████████████████▊        | 287/400 [1:23:44<31:47, 16.88s/it]2022-01-17 12:49:35,846 iteration 4880 : loss : 0.016755, loss_ce: 0.006565
2022-01-17 12:49:36,705 iteration 4881 : loss : 0.015055, loss_ce: 0.005925
2022-01-17 12:49:37,540 iteration 4882 : loss : 0.013721, loss_ce: 0.005706
2022-01-17 12:49:38,484 iteration 4883 : loss : 0.017208, loss_ce: 0.007168
2022-01-17 12:49:39,441 iteration 4884 : loss : 0.018770, loss_ce: 0.004763
2022-01-17 12:49:40,261 iteration 4885 : loss : 0.011406, loss_ce: 0.004332
2022-01-17 12:49:41,177 iteration 4886 : loss : 0.022286, loss_ce: 0.005887
2022-01-17 12:49:42,038 iteration 4887 : loss : 0.012485, loss_ce: 0.003532
2022-01-17 12:49:42,981 iteration 4888 : loss : 0.022487, loss_ce: 0.005210
2022-01-17 12:49:43,905 iteration 4889 : loss : 0.020709, loss_ce: 0.009905
2022-01-17 12:49:44,780 iteration 4890 : loss : 0.015873, loss_ce: 0.007942
2022-01-17 12:49:45,592 iteration 4891 : loss : 0.013169, loss_ce: 0.004248
2022-01-17 12:49:46,547 iteration 4892 : loss : 0.015691, loss_ce: 0.005363
2022-01-17 12:49:47,470 iteration 4893 : loss : 0.023990, loss_ce: 0.008417
2022-01-17 12:49:48,377 iteration 4894 : loss : 0.016363, loss_ce: 0.007502
2022-01-17 12:49:49,273 iteration 4895 : loss : 0.019314, loss_ce: 0.003573
2022-01-17 12:49:50,151 iteration 4896 : loss : 0.020860, loss_ce: 0.006313
 72%|████████████████████▉        | 288/400 [1:24:00<30:35, 16.39s/it]2022-01-17 12:49:51,079 iteration 4897 : loss : 0.016014, loss_ce: 0.005997
2022-01-17 12:49:52,055 iteration 4898 : loss : 0.023099, loss_ce: 0.011727
2022-01-17 12:49:52,972 iteration 4899 : loss : 0.014447, loss_ce: 0.004081
2022-01-17 12:49:53,882 iteration 4900 : loss : 0.021877, loss_ce: 0.008174
2022-01-17 12:49:54,765 iteration 4901 : loss : 0.028428, loss_ce: 0.008322
2022-01-17 12:49:55,648 iteration 4902 : loss : 0.016696, loss_ce: 0.006673
2022-01-17 12:49:56,576 iteration 4903 : loss : 0.017120, loss_ce: 0.007885
2022-01-17 12:49:57,391 iteration 4904 : loss : 0.018536, loss_ce: 0.004500
2022-01-17 12:49:58,264 iteration 4905 : loss : 0.016674, loss_ce: 0.004732
2022-01-17 12:49:59,210 iteration 4906 : loss : 0.016122, loss_ce: 0.005225
2022-01-17 12:50:00,089 iteration 4907 : loss : 0.021972, loss_ce: 0.007397
2022-01-17 12:50:01,072 iteration 4908 : loss : 0.018833, loss_ce: 0.007302
2022-01-17 12:50:02,015 iteration 4909 : loss : 0.017068, loss_ce: 0.004602
2022-01-17 12:50:02,885 iteration 4910 : loss : 0.018385, loss_ce: 0.007666
2022-01-17 12:50:03,774 iteration 4911 : loss : 0.012822, loss_ce: 0.004579
2022-01-17 12:50:04,694 iteration 4912 : loss : 0.017394, loss_ce: 0.007486
2022-01-17 12:50:05,602 iteration 4913 : loss : 0.017329, loss_ce: 0.006007
 72%|████████████████████▉        | 289/400 [1:24:15<29:47, 16.11s/it]2022-01-17 12:50:06,599 iteration 4914 : loss : 0.018690, loss_ce: 0.006910
2022-01-17 12:50:07,473 iteration 4915 : loss : 0.024291, loss_ce: 0.009818
2022-01-17 12:50:08,359 iteration 4916 : loss : 0.017321, loss_ce: 0.005851
2022-01-17 12:50:09,273 iteration 4917 : loss : 0.013382, loss_ce: 0.003834
2022-01-17 12:50:10,213 iteration 4918 : loss : 0.015546, loss_ce: 0.005233
2022-01-17 12:50:11,276 iteration 4919 : loss : 0.024873, loss_ce: 0.010853
2022-01-17 12:50:12,175 iteration 4920 : loss : 0.015954, loss_ce: 0.006500
2022-01-17 12:50:13,051 iteration 4921 : loss : 0.014125, loss_ce: 0.006418
2022-01-17 12:50:13,905 iteration 4922 : loss : 0.014591, loss_ce: 0.003586
2022-01-17 12:50:14,863 iteration 4923 : loss : 0.017779, loss_ce: 0.006840
2022-01-17 12:50:15,846 iteration 4924 : loss : 0.019122, loss_ce: 0.010527
2022-01-17 12:50:16,780 iteration 4925 : loss : 0.021497, loss_ce: 0.006780
2022-01-17 12:50:17,741 iteration 4926 : loss : 0.018174, loss_ce: 0.009908
2022-01-17 12:50:18,635 iteration 4927 : loss : 0.014812, loss_ce: 0.004622
2022-01-17 12:50:19,598 iteration 4928 : loss : 0.022282, loss_ce: 0.007997
2022-01-17 12:50:20,586 iteration 4929 : loss : 0.020945, loss_ce: 0.008292
2022-01-17 12:50:20,586 Training Data Eval:
2022-01-17 12:50:24,961   Average segmentation loss on training set: 0.0103
2022-01-17 12:50:24,961 Validation Data Eval:
2022-01-17 12:50:26,461   Average segmentation loss on validation set: 0.0802
2022-01-17 12:50:27,398 iteration 4930 : loss : 0.015981, loss_ce: 0.004796
 72%|█████████████████████        | 290/400 [1:24:37<32:39, 17.81s/it]2022-01-17 12:50:28,354 iteration 4931 : loss : 0.015355, loss_ce: 0.006542
2022-01-17 12:50:29,298 iteration 4932 : loss : 0.016767, loss_ce: 0.007634
2022-01-17 12:50:30,159 iteration 4933 : loss : 0.013909, loss_ce: 0.006717
2022-01-17 12:50:31,134 iteration 4934 : loss : 0.017519, loss_ce: 0.005612
2022-01-17 12:50:32,047 iteration 4935 : loss : 0.015119, loss_ce: 0.004893
2022-01-17 12:50:32,988 iteration 4936 : loss : 0.020320, loss_ce: 0.007240
2022-01-17 12:50:33,914 iteration 4937 : loss : 0.012418, loss_ce: 0.004825
2022-01-17 12:50:34,879 iteration 4938 : loss : 0.029135, loss_ce: 0.009874
2022-01-17 12:50:35,838 iteration 4939 : loss : 0.025254, loss_ce: 0.008417
2022-01-17 12:50:36,730 iteration 4940 : loss : 0.018199, loss_ce: 0.007046
2022-01-17 12:50:37,658 iteration 4941 : loss : 0.022832, loss_ce: 0.012023
2022-01-17 12:50:38,587 iteration 4942 : loss : 0.016451, loss_ce: 0.005151
2022-01-17 12:50:39,597 iteration 4943 : loss : 0.031124, loss_ce: 0.006356
2022-01-17 12:50:40,520 iteration 4944 : loss : 0.014764, loss_ce: 0.005031
2022-01-17 12:50:41,474 iteration 4945 : loss : 0.018847, loss_ce: 0.007630
2022-01-17 12:50:42,450 iteration 4946 : loss : 0.016357, loss_ce: 0.004173
2022-01-17 12:50:43,351 iteration 4947 : loss : 0.031495, loss_ce: 0.009687
 73%|█████████████████████        | 291/400 [1:24:53<31:20, 17.25s/it]2022-01-17 12:50:44,330 iteration 4948 : loss : 0.025424, loss_ce: 0.008495
2022-01-17 12:50:45,219 iteration 4949 : loss : 0.035551, loss_ce: 0.015205
2022-01-17 12:50:46,172 iteration 4950 : loss : 0.017281, loss_ce: 0.007041
2022-01-17 12:50:47,119 iteration 4951 : loss : 0.016322, loss_ce: 0.004853
2022-01-17 12:50:48,048 iteration 4952 : loss : 0.014689, loss_ce: 0.007611
2022-01-17 12:50:49,001 iteration 4953 : loss : 0.015899, loss_ce: 0.006656
2022-01-17 12:50:49,895 iteration 4954 : loss : 0.013630, loss_ce: 0.004016
2022-01-17 12:50:50,758 iteration 4955 : loss : 0.018648, loss_ce: 0.004880
2022-01-17 12:50:51,673 iteration 4956 : loss : 0.015869, loss_ce: 0.004426
2022-01-17 12:50:52,519 iteration 4957 : loss : 0.015067, loss_ce: 0.005866
2022-01-17 12:50:53,463 iteration 4958 : loss : 0.018420, loss_ce: 0.008682
2022-01-17 12:50:54,396 iteration 4959 : loss : 0.016864, loss_ce: 0.005763
2022-01-17 12:50:55,315 iteration 4960 : loss : 0.013568, loss_ce: 0.004606
2022-01-17 12:50:56,238 iteration 4961 : loss : 0.014775, loss_ce: 0.005501
2022-01-17 12:50:57,110 iteration 4962 : loss : 0.027400, loss_ce: 0.005485
2022-01-17 12:50:58,016 iteration 4963 : loss : 0.014405, loss_ce: 0.005266
2022-01-17 12:50:58,987 iteration 4964 : loss : 0.018233, loss_ce: 0.006256
 73%|█████████████████████▏       | 292/400 [1:25:08<30:11, 16.77s/it]2022-01-17 12:51:00,015 iteration 4965 : loss : 0.024883, loss_ce: 0.010918
2022-01-17 12:51:00,977 iteration 4966 : loss : 0.028309, loss_ce: 0.011945
2022-01-17 12:51:01,897 iteration 4967 : loss : 0.020495, loss_ce: 0.008613
2022-01-17 12:51:02,832 iteration 4968 : loss : 0.016480, loss_ce: 0.007959
2022-01-17 12:51:03,839 iteration 4969 : loss : 0.037140, loss_ce: 0.013752
2022-01-17 12:51:04,699 iteration 4970 : loss : 0.016386, loss_ce: 0.007450
2022-01-17 12:51:05,578 iteration 4971 : loss : 0.016456, loss_ce: 0.008202
2022-01-17 12:51:06,516 iteration 4972 : loss : 0.018815, loss_ce: 0.008048
2022-01-17 12:51:07,432 iteration 4973 : loss : 0.016597, loss_ce: 0.005731
2022-01-17 12:51:08,463 iteration 4974 : loss : 0.022293, loss_ce: 0.007172
2022-01-17 12:51:09,370 iteration 4975 : loss : 0.012779, loss_ce: 0.003302
2022-01-17 12:51:10,234 iteration 4976 : loss : 0.016981, loss_ce: 0.006038
2022-01-17 12:51:11,179 iteration 4977 : loss : 0.021767, loss_ce: 0.003926
2022-01-17 12:51:12,087 iteration 4978 : loss : 0.011208, loss_ce: 0.003199
2022-01-17 12:51:13,000 iteration 4979 : loss : 0.018930, loss_ce: 0.007033
2022-01-17 12:51:13,931 iteration 4980 : loss : 0.015675, loss_ce: 0.004254
2022-01-17 12:51:14,841 iteration 4981 : loss : 0.018717, loss_ce: 0.006514
 73%|█████████████████████▏       | 293/400 [1:25:24<29:24, 16.49s/it]2022-01-17 12:51:15,777 iteration 4982 : loss : 0.015284, loss_ce: 0.006752
2022-01-17 12:51:16,661 iteration 4983 : loss : 0.017302, loss_ce: 0.007167
2022-01-17 12:51:17,665 iteration 4984 : loss : 0.014185, loss_ce: 0.004323
2022-01-17 12:51:18,519 iteration 4985 : loss : 0.012476, loss_ce: 0.003219
2022-01-17 12:51:19,517 iteration 4986 : loss : 0.022815, loss_ce: 0.010894
2022-01-17 12:51:20,390 iteration 4987 : loss : 0.018281, loss_ce: 0.005433
2022-01-17 12:51:21,324 iteration 4988 : loss : 0.016933, loss_ce: 0.004793
2022-01-17 12:51:22,291 iteration 4989 : loss : 0.017619, loss_ce: 0.006467
2022-01-17 12:51:23,281 iteration 4990 : loss : 0.018326, loss_ce: 0.007858
2022-01-17 12:51:24,211 iteration 4991 : loss : 0.021320, loss_ce: 0.005712
2022-01-17 12:51:25,047 iteration 4992 : loss : 0.013870, loss_ce: 0.006507
2022-01-17 12:51:25,957 iteration 4993 : loss : 0.017560, loss_ce: 0.006002
2022-01-17 12:51:26,833 iteration 4994 : loss : 0.019350, loss_ce: 0.006203
2022-01-17 12:51:27,721 iteration 4995 : loss : 0.016649, loss_ce: 0.007542
2022-01-17 12:51:28,692 iteration 4996 : loss : 0.020346, loss_ce: 0.005470
2022-01-17 12:51:29,541 iteration 4997 : loss : 0.016107, loss_ce: 0.004891
2022-01-17 12:51:30,410 iteration 4998 : loss : 0.015150, loss_ce: 0.005345
 74%|█████████████████████▎       | 294/400 [1:25:40<28:39, 16.22s/it]2022-01-17 12:51:31,354 iteration 4999 : loss : 0.016909, loss_ce: 0.006293
2022-01-17 12:51:32,259 iteration 5000 : loss : 0.015338, loss_ce: 0.006070
2022-01-17 12:51:33,166 iteration 5001 : loss : 0.017073, loss_ce: 0.007216
2022-01-17 12:51:34,055 iteration 5002 : loss : 0.009890, loss_ce: 0.003371
2022-01-17 12:51:34,998 iteration 5003 : loss : 0.036559, loss_ce: 0.005885
2022-01-17 12:51:35,908 iteration 5004 : loss : 0.016401, loss_ce: 0.006109
2022-01-17 12:51:36,824 iteration 5005 : loss : 0.017382, loss_ce: 0.006946
2022-01-17 12:51:37,794 iteration 5006 : loss : 0.014693, loss_ce: 0.005393
2022-01-17 12:51:38,735 iteration 5007 : loss : 0.017673, loss_ce: 0.007381
2022-01-17 12:51:39,686 iteration 5008 : loss : 0.019244, loss_ce: 0.008703
2022-01-17 12:51:40,636 iteration 5009 : loss : 0.019134, loss_ce: 0.004987
2022-01-17 12:51:41,571 iteration 5010 : loss : 0.021739, loss_ce: 0.007551
2022-01-17 12:51:42,465 iteration 5011 : loss : 0.013635, loss_ce: 0.005864
2022-01-17 12:51:43,392 iteration 5012 : loss : 0.016315, loss_ce: 0.006287
2022-01-17 12:51:44,254 iteration 5013 : loss : 0.018839, loss_ce: 0.006322
2022-01-17 12:51:45,163 iteration 5014 : loss : 0.018552, loss_ce: 0.006487
2022-01-17 12:51:45,163 Training Data Eval:
2022-01-17 12:51:49,577   Average segmentation loss on training set: 0.0101
2022-01-17 12:51:49,577 Validation Data Eval:
2022-01-17 12:51:51,076   Average segmentation loss on validation set: 0.0932
2022-01-17 12:51:51,994 iteration 5015 : loss : 0.015364, loss_ce: 0.004592
 74%|█████████████████████▍       | 295/400 [1:26:01<31:11, 17.82s/it]2022-01-17 12:51:52,944 iteration 5016 : loss : 0.015594, loss_ce: 0.006865
2022-01-17 12:51:53,841 iteration 5017 : loss : 0.018384, loss_ce: 0.005857
2022-01-17 12:51:54,755 iteration 5018 : loss : 0.019023, loss_ce: 0.007913
2022-01-17 12:51:55,691 iteration 5019 : loss : 0.017681, loss_ce: 0.005850
2022-01-17 12:51:56,629 iteration 5020 : loss : 0.017112, loss_ce: 0.005074
2022-01-17 12:51:57,587 iteration 5021 : loss : 0.015193, loss_ce: 0.007198
2022-01-17 12:51:58,446 iteration 5022 : loss : 0.013116, loss_ce: 0.003893
2022-01-17 12:51:59,360 iteration 5023 : loss : 0.022132, loss_ce: 0.005517
2022-01-17 12:52:00,367 iteration 5024 : loss : 0.021128, loss_ce: 0.004210
2022-01-17 12:52:01,346 iteration 5025 : loss : 0.020682, loss_ce: 0.004581
2022-01-17 12:52:02,272 iteration 5026 : loss : 0.021981, loss_ce: 0.007636
2022-01-17 12:52:03,151 iteration 5027 : loss : 0.014864, loss_ce: 0.006081
2022-01-17 12:52:04,046 iteration 5028 : loss : 0.016964, loss_ce: 0.006148
2022-01-17 12:52:05,040 iteration 5029 : loss : 0.022087, loss_ce: 0.005597
2022-01-17 12:52:05,955 iteration 5030 : loss : 0.015103, loss_ce: 0.007402
2022-01-17 12:52:06,932 iteration 5031 : loss : 0.020751, loss_ce: 0.010321
2022-01-17 12:52:07,853 iteration 5032 : loss : 0.016033, loss_ce: 0.007417
 74%|█████████████████████▍       | 296/400 [1:26:17<29:52, 17.24s/it]2022-01-17 12:52:08,916 iteration 5033 : loss : 0.022860, loss_ce: 0.007327
2022-01-17 12:52:09,817 iteration 5034 : loss : 0.021026, loss_ce: 0.006123
2022-01-17 12:52:10,701 iteration 5035 : loss : 0.016466, loss_ce: 0.006848
2022-01-17 12:52:11,595 iteration 5036 : loss : 0.016481, loss_ce: 0.006096
2022-01-17 12:52:12,521 iteration 5037 : loss : 0.020221, loss_ce: 0.007303
2022-01-17 12:52:13,407 iteration 5038 : loss : 0.023084, loss_ce: 0.004597
2022-01-17 12:52:14,403 iteration 5039 : loss : 0.016011, loss_ce: 0.007352
2022-01-17 12:52:15,334 iteration 5040 : loss : 0.016863, loss_ce: 0.005787
2022-01-17 12:52:16,320 iteration 5041 : loss : 0.020591, loss_ce: 0.006724
2022-01-17 12:52:17,199 iteration 5042 : loss : 0.015891, loss_ce: 0.006061
2022-01-17 12:52:18,117 iteration 5043 : loss : 0.014579, loss_ce: 0.006531
2022-01-17 12:52:19,045 iteration 5044 : loss : 0.021571, loss_ce: 0.010560
2022-01-17 12:52:20,007 iteration 5045 : loss : 0.020196, loss_ce: 0.008822
2022-01-17 12:52:20,942 iteration 5046 : loss : 0.034398, loss_ce: 0.009320
2022-01-17 12:52:21,844 iteration 5047 : loss : 0.028086, loss_ce: 0.007189
2022-01-17 12:52:22,738 iteration 5048 : loss : 0.015443, loss_ce: 0.006104
2022-01-17 12:52:23,629 iteration 5049 : loss : 0.015434, loss_ce: 0.006539
 74%|█████████████████████▌       | 297/400 [1:26:33<28:50, 16.80s/it]2022-01-17 12:52:24,600 iteration 5050 : loss : 0.019574, loss_ce: 0.005925
2022-01-17 12:52:25,501 iteration 5051 : loss : 0.022166, loss_ce: 0.008438
2022-01-17 12:52:26,415 iteration 5052 : loss : 0.017566, loss_ce: 0.008059
2022-01-17 12:52:27,315 iteration 5053 : loss : 0.015754, loss_ce: 0.006450
2022-01-17 12:52:28,242 iteration 5054 : loss : 0.015686, loss_ce: 0.005082
2022-01-17 12:52:29,146 iteration 5055 : loss : 0.017287, loss_ce: 0.005565
2022-01-17 12:52:30,032 iteration 5056 : loss : 0.020623, loss_ce: 0.004564
2022-01-17 12:52:30,991 iteration 5057 : loss : 0.017437, loss_ce: 0.008353
2022-01-17 12:52:31,965 iteration 5058 : loss : 0.028544, loss_ce: 0.011034
2022-01-17 12:52:32,770 iteration 5059 : loss : 0.016950, loss_ce: 0.003930
2022-01-17 12:52:33,675 iteration 5060 : loss : 0.020009, loss_ce: 0.005477
2022-01-17 12:52:34,618 iteration 5061 : loss : 0.014985, loss_ce: 0.006205
2022-01-17 12:52:35,552 iteration 5062 : loss : 0.035928, loss_ce: 0.010794
2022-01-17 12:52:36,527 iteration 5063 : loss : 0.017675, loss_ce: 0.006986
2022-01-17 12:52:37,408 iteration 5064 : loss : 0.016102, loss_ce: 0.006505
2022-01-17 12:52:38,296 iteration 5065 : loss : 0.019137, loss_ce: 0.007068
2022-01-17 12:52:39,219 iteration 5066 : loss : 0.015295, loss_ce: 0.008302
 74%|█████████████████████▌       | 298/400 [1:26:49<27:56, 16.44s/it]2022-01-17 12:52:40,263 iteration 5067 : loss : 0.023169, loss_ce: 0.009988
2022-01-17 12:52:41,196 iteration 5068 : loss : 0.020932, loss_ce: 0.008716
2022-01-17 12:52:42,117 iteration 5069 : loss : 0.020308, loss_ce: 0.005936
2022-01-17 12:52:43,013 iteration 5070 : loss : 0.017484, loss_ce: 0.004655
2022-01-17 12:52:43,977 iteration 5071 : loss : 0.020536, loss_ce: 0.007448
2022-01-17 12:52:44,784 iteration 5072 : loss : 0.014592, loss_ce: 0.004958
2022-01-17 12:52:45,698 iteration 5073 : loss : 0.018569, loss_ce: 0.009105
2022-01-17 12:52:46,661 iteration 5074 : loss : 0.021715, loss_ce: 0.007249
2022-01-17 12:52:47,587 iteration 5075 : loss : 0.014257, loss_ce: 0.005622
2022-01-17 12:52:48,559 iteration 5076 : loss : 0.015575, loss_ce: 0.006600
2022-01-17 12:52:49,456 iteration 5077 : loss : 0.016862, loss_ce: 0.005684
2022-01-17 12:52:50,393 iteration 5078 : loss : 0.013110, loss_ce: 0.003468
2022-01-17 12:52:51,293 iteration 5079 : loss : 0.017205, loss_ce: 0.006472
2022-01-17 12:52:52,221 iteration 5080 : loss : 0.016530, loss_ce: 0.005623
2022-01-17 12:52:53,168 iteration 5081 : loss : 0.017386, loss_ce: 0.007295
2022-01-17 12:52:54,142 iteration 5082 : loss : 0.024112, loss_ce: 0.011006
2022-01-17 12:52:55,080 iteration 5083 : loss : 0.014802, loss_ce: 0.004331
 75%|█████████████████████▋       | 299/400 [1:27:04<27:22, 16.26s/it]2022-01-17 12:52:56,011 iteration 5084 : loss : 0.014521, loss_ce: 0.004696
2022-01-17 12:52:56,923 iteration 5085 : loss : 0.017171, loss_ce: 0.006192
2022-01-17 12:52:57,806 iteration 5086 : loss : 0.014071, loss_ce: 0.004546
2022-01-17 12:52:58,770 iteration 5087 : loss : 0.018931, loss_ce: 0.006146
2022-01-17 12:52:59,701 iteration 5088 : loss : 0.016297, loss_ce: 0.005744
2022-01-17 12:53:00,576 iteration 5089 : loss : 0.016007, loss_ce: 0.005201
2022-01-17 12:53:01,473 iteration 5090 : loss : 0.013165, loss_ce: 0.004389
2022-01-17 12:53:02,491 iteration 5091 : loss : 0.021283, loss_ce: 0.007685
2022-01-17 12:53:03,403 iteration 5092 : loss : 0.012177, loss_ce: 0.005803
2022-01-17 12:53:04,290 iteration 5093 : loss : 0.017395, loss_ce: 0.007542
2022-01-17 12:53:05,155 iteration 5094 : loss : 0.012221, loss_ce: 0.004349
2022-01-17 12:53:06,112 iteration 5095 : loss : 0.022554, loss_ce: 0.007257
2022-01-17 12:53:06,980 iteration 5096 : loss : 0.012105, loss_ce: 0.004246
2022-01-17 12:53:07,859 iteration 5097 : loss : 0.015446, loss_ce: 0.006279
2022-01-17 12:53:08,796 iteration 5098 : loss : 0.025878, loss_ce: 0.009736
2022-01-17 12:53:09,708 iteration 5099 : loss : 0.014600, loss_ce: 0.004949
2022-01-17 12:53:09,709 Training Data Eval:
2022-01-17 12:53:14,115   Average segmentation loss on training set: 0.0100
2022-01-17 12:53:14,115 Validation Data Eval:
2022-01-17 12:53:15,608   Average segmentation loss on validation set: 0.0890
2022-01-17 12:53:16,527 iteration 5100 : loss : 0.012956, loss_ce: 0.006055
 75%|█████████████████████▊       | 300/400 [1:27:26<29:41, 17.82s/it]2022-01-17 12:53:17,513 iteration 5101 : loss : 0.012883, loss_ce: 0.005116
2022-01-17 12:53:18,406 iteration 5102 : loss : 0.012328, loss_ce: 0.004516
2022-01-17 12:53:19,321 iteration 5103 : loss : 0.019264, loss_ce: 0.007724
2022-01-17 12:53:20,311 iteration 5104 : loss : 0.017767, loss_ce: 0.007362
2022-01-17 12:53:21,180 iteration 5105 : loss : 0.015311, loss_ce: 0.005178
2022-01-17 12:53:22,167 iteration 5106 : loss : 0.014134, loss_ce: 0.004781
2022-01-17 12:53:23,038 iteration 5107 : loss : 0.014694, loss_ce: 0.005304
2022-01-17 12:53:23,982 iteration 5108 : loss : 0.017251, loss_ce: 0.006194
2022-01-17 12:53:24,903 iteration 5109 : loss : 0.019684, loss_ce: 0.006404
2022-01-17 12:53:25,806 iteration 5110 : loss : 0.017925, loss_ce: 0.008328
2022-01-17 12:53:26,747 iteration 5111 : loss : 0.015244, loss_ce: 0.004918
2022-01-17 12:53:27,614 iteration 5112 : loss : 0.016661, loss_ce: 0.004310
2022-01-17 12:53:28,585 iteration 5113 : loss : 0.040862, loss_ce: 0.006157
2022-01-17 12:53:29,480 iteration 5114 : loss : 0.017140, loss_ce: 0.008100
2022-01-17 12:53:30,356 iteration 5115 : loss : 0.018362, loss_ce: 0.005430
2022-01-17 12:53:31,241 iteration 5116 : loss : 0.013611, loss_ce: 0.005357
2022-01-17 12:53:32,217 iteration 5117 : loss : 0.018558, loss_ce: 0.008052
 75%|█████████████████████▊       | 301/400 [1:27:42<28:20, 17.18s/it]2022-01-17 12:53:33,186 iteration 5118 : loss : 0.014231, loss_ce: 0.005121
2022-01-17 12:53:34,110 iteration 5119 : loss : 0.017632, loss_ce: 0.006482
2022-01-17 12:53:34,994 iteration 5120 : loss : 0.016416, loss_ce: 0.004274
2022-01-17 12:53:35,912 iteration 5121 : loss : 0.018841, loss_ce: 0.008024
2022-01-17 12:53:36,793 iteration 5122 : loss : 0.017251, loss_ce: 0.006617
2022-01-17 12:53:37,711 iteration 5123 : loss : 0.026858, loss_ce: 0.007753
2022-01-17 12:53:38,654 iteration 5124 : loss : 0.014759, loss_ce: 0.006177
2022-01-17 12:53:39,493 iteration 5125 : loss : 0.017471, loss_ce: 0.008367
2022-01-17 12:53:40,371 iteration 5126 : loss : 0.019462, loss_ce: 0.006231
2022-01-17 12:53:41,334 iteration 5127 : loss : 0.023172, loss_ce: 0.008469
2022-01-17 12:53:42,233 iteration 5128 : loss : 0.012315, loss_ce: 0.004478
2022-01-17 12:53:43,170 iteration 5129 : loss : 0.021161, loss_ce: 0.006876
2022-01-17 12:53:44,090 iteration 5130 : loss : 0.017176, loss_ce: 0.005082
2022-01-17 12:53:44,936 iteration 5131 : loss : 0.011411, loss_ce: 0.004106
2022-01-17 12:53:45,845 iteration 5132 : loss : 0.014342, loss_ce: 0.005778
2022-01-17 12:53:46,730 iteration 5133 : loss : 0.024790, loss_ce: 0.007823
2022-01-17 12:53:47,600 iteration 5134 : loss : 0.018099, loss_ce: 0.007367
 76%|█████████████████████▉       | 302/400 [1:27:57<27:10, 16.64s/it]2022-01-17 12:53:48,693 iteration 5135 : loss : 0.021621, loss_ce: 0.007420
2022-01-17 12:53:49,607 iteration 5136 : loss : 0.021970, loss_ce: 0.006608
2022-01-17 12:53:50,568 iteration 5137 : loss : 0.026079, loss_ce: 0.007950
2022-01-17 12:53:51,445 iteration 5138 : loss : 0.019703, loss_ce: 0.007587
2022-01-17 12:53:52,352 iteration 5139 : loss : 0.015515, loss_ce: 0.006407
2022-01-17 12:53:53,340 iteration 5140 : loss : 0.017335, loss_ce: 0.007432
2022-01-17 12:53:54,215 iteration 5141 : loss : 0.018524, loss_ce: 0.006911
2022-01-17 12:53:55,144 iteration 5142 : loss : 0.017102, loss_ce: 0.005678
2022-01-17 12:53:55,993 iteration 5143 : loss : 0.014597, loss_ce: 0.005643
2022-01-17 12:53:56,944 iteration 5144 : loss : 0.038152, loss_ce: 0.019259
2022-01-17 12:53:57,790 iteration 5145 : loss : 0.012601, loss_ce: 0.003882
2022-01-17 12:53:58,775 iteration 5146 : loss : 0.023776, loss_ce: 0.009785
2022-01-17 12:53:59,751 iteration 5147 : loss : 0.019060, loss_ce: 0.006447
2022-01-17 12:54:00,642 iteration 5148 : loss : 0.017223, loss_ce: 0.006813
2022-01-17 12:54:01,535 iteration 5149 : loss : 0.023313, loss_ce: 0.005633
2022-01-17 12:54:02,429 iteration 5150 : loss : 0.016855, loss_ce: 0.005881
2022-01-17 12:54:03,348 iteration 5151 : loss : 0.046465, loss_ce: 0.008451
 76%|█████████████████████▉       | 303/400 [1:28:13<26:28, 16.37s/it]2022-01-17 12:54:04,254 iteration 5152 : loss : 0.019258, loss_ce: 0.003643
2022-01-17 12:54:05,092 iteration 5153 : loss : 0.014229, loss_ce: 0.005327
2022-01-17 12:54:06,074 iteration 5154 : loss : 0.024357, loss_ce: 0.008552
2022-01-17 12:54:06,938 iteration 5155 : loss : 0.013977, loss_ce: 0.004516
2022-01-17 12:54:07,842 iteration 5156 : loss : 0.023977, loss_ce: 0.009088
2022-01-17 12:54:08,705 iteration 5157 : loss : 0.014242, loss_ce: 0.004296
2022-01-17 12:54:09,609 iteration 5158 : loss : 0.018095, loss_ce: 0.006208
2022-01-17 12:54:10,572 iteration 5159 : loss : 0.023347, loss_ce: 0.007216
2022-01-17 12:54:11,418 iteration 5160 : loss : 0.014264, loss_ce: 0.004997
2022-01-17 12:54:12,313 iteration 5161 : loss : 0.015442, loss_ce: 0.005933
2022-01-17 12:54:13,173 iteration 5162 : loss : 0.017311, loss_ce: 0.007304
2022-01-17 12:54:14,100 iteration 5163 : loss : 0.017457, loss_ce: 0.006191
2022-01-17 12:54:15,033 iteration 5164 : loss : 0.018178, loss_ce: 0.008230
2022-01-17 12:54:15,885 iteration 5165 : loss : 0.019643, loss_ce: 0.006292
2022-01-17 12:54:16,796 iteration 5166 : loss : 0.017308, loss_ce: 0.006978
2022-01-17 12:54:17,715 iteration 5167 : loss : 0.025226, loss_ce: 0.007846
2022-01-17 12:54:18,679 iteration 5168 : loss : 0.025809, loss_ce: 0.010094
 76%|██████████████████████       | 304/400 [1:28:28<25:41, 16.06s/it]2022-01-17 12:54:19,731 iteration 5169 : loss : 0.026782, loss_ce: 0.010970
2022-01-17 12:54:20,587 iteration 5170 : loss : 0.016144, loss_ce: 0.004883
2022-01-17 12:54:21,553 iteration 5171 : loss : 0.015825, loss_ce: 0.007147
2022-01-17 12:54:22,397 iteration 5172 : loss : 0.014970, loss_ce: 0.004125
2022-01-17 12:54:23,192 iteration 5173 : loss : 0.013227, loss_ce: 0.005578
2022-01-17 12:54:24,175 iteration 5174 : loss : 0.018941, loss_ce: 0.006675
2022-01-17 12:54:25,060 iteration 5175 : loss : 0.016457, loss_ce: 0.007667
2022-01-17 12:54:26,098 iteration 5176 : loss : 0.025667, loss_ce: 0.011441
2022-01-17 12:54:26,976 iteration 5177 : loss : 0.016724, loss_ce: 0.006913
2022-01-17 12:54:27,881 iteration 5178 : loss : 0.013132, loss_ce: 0.004138
2022-01-17 12:54:28,841 iteration 5179 : loss : 0.019379, loss_ce: 0.005671
2022-01-17 12:54:29,755 iteration 5180 : loss : 0.017764, loss_ce: 0.006275
2022-01-17 12:54:30,625 iteration 5181 : loss : 0.018588, loss_ce: 0.004698
2022-01-17 12:54:31,534 iteration 5182 : loss : 0.015982, loss_ce: 0.006032
2022-01-17 12:54:32,423 iteration 5183 : loss : 0.022533, loss_ce: 0.009295
2022-01-17 12:54:33,299 iteration 5184 : loss : 0.017099, loss_ce: 0.006149
2022-01-17 12:54:33,299 Training Data Eval:
2022-01-17 12:54:37,699   Average segmentation loss on training set: 0.0106
2022-01-17 12:54:37,700 Validation Data Eval:
2022-01-17 12:54:39,194   Average segmentation loss on validation set: 0.0877
2022-01-17 12:54:40,104 iteration 5185 : loss : 0.018927, loss_ce: 0.007215
 76%|██████████████████████       | 305/400 [1:28:49<27:58, 17.67s/it]2022-01-17 12:54:41,080 iteration 5186 : loss : 0.015046, loss_ce: 0.006383
2022-01-17 12:54:41,946 iteration 5187 : loss : 0.018722, loss_ce: 0.007724
2022-01-17 12:54:42,817 iteration 5188 : loss : 0.015034, loss_ce: 0.006125
2022-01-17 12:54:43,696 iteration 5189 : loss : 0.015543, loss_ce: 0.006398
2022-01-17 12:54:44,562 iteration 5190 : loss : 0.015924, loss_ce: 0.006671
2022-01-17 12:54:45,527 iteration 5191 : loss : 0.018653, loss_ce: 0.005908
2022-01-17 12:54:46,470 iteration 5192 : loss : 0.022784, loss_ce: 0.008450
2022-01-17 12:54:47,339 iteration 5193 : loss : 0.011020, loss_ce: 0.003713
2022-01-17 12:54:48,282 iteration 5194 : loss : 0.020453, loss_ce: 0.008294
2022-01-17 12:54:49,171 iteration 5195 : loss : 0.015228, loss_ce: 0.004996
2022-01-17 12:54:49,986 iteration 5196 : loss : 0.015676, loss_ce: 0.003770
2022-01-17 12:54:50,837 iteration 5197 : loss : 0.015088, loss_ce: 0.005041
2022-01-17 12:54:51,707 iteration 5198 : loss : 0.019414, loss_ce: 0.008426
2022-01-17 12:54:52,644 iteration 5199 : loss : 0.012649, loss_ce: 0.004183
2022-01-17 12:54:53,555 iteration 5200 : loss : 0.018888, loss_ce: 0.006061
2022-01-17 12:54:54,490 iteration 5201 : loss : 0.015195, loss_ce: 0.005108
2022-01-17 12:54:55,482 iteration 5202 : loss : 0.017101, loss_ce: 0.007805
 76%|██████████████████████▏      | 306/400 [1:29:05<26:36, 16.98s/it]2022-01-17 12:54:56,396 iteration 5203 : loss : 0.012272, loss_ce: 0.004150
2022-01-17 12:54:57,276 iteration 5204 : loss : 0.017479, loss_ce: 0.007055
2022-01-17 12:54:58,291 iteration 5205 : loss : 0.027036, loss_ce: 0.010507
2022-01-17 12:54:59,189 iteration 5206 : loss : 0.019660, loss_ce: 0.006310
2022-01-17 12:55:00,095 iteration 5207 : loss : 0.015825, loss_ce: 0.006367
2022-01-17 12:55:01,076 iteration 5208 : loss : 0.015580, loss_ce: 0.006266
2022-01-17 12:55:01,936 iteration 5209 : loss : 0.014672, loss_ce: 0.005952
2022-01-17 12:55:02,891 iteration 5210 : loss : 0.021663, loss_ce: 0.008536
2022-01-17 12:55:03,815 iteration 5211 : loss : 0.014059, loss_ce: 0.005520
2022-01-17 12:55:04,731 iteration 5212 : loss : 0.019834, loss_ce: 0.006952
2022-01-17 12:55:05,547 iteration 5213 : loss : 0.014029, loss_ce: 0.005120
2022-01-17 12:55:06,551 iteration 5214 : loss : 0.031965, loss_ce: 0.014429
2022-01-17 12:55:07,495 iteration 5215 : loss : 0.017525, loss_ce: 0.006029
2022-01-17 12:55:08,464 iteration 5216 : loss : 0.013232, loss_ce: 0.004178
2022-01-17 12:55:09,460 iteration 5217 : loss : 0.020096, loss_ce: 0.007557
2022-01-17 12:55:10,337 iteration 5218 : loss : 0.018182, loss_ce: 0.003276
2022-01-17 12:55:11,339 iteration 5219 : loss : 0.014793, loss_ce: 0.004695
 77%|██████████████████████▎      | 307/400 [1:29:21<25:47, 16.65s/it]2022-01-17 12:55:12,271 iteration 5220 : loss : 0.022099, loss_ce: 0.006258
2022-01-17 12:55:13,172 iteration 5221 : loss : 0.015623, loss_ce: 0.005303
2022-01-17 12:55:14,031 iteration 5222 : loss : 0.012829, loss_ce: 0.004744
2022-01-17 12:55:14,993 iteration 5223 : loss : 0.017544, loss_ce: 0.006518
2022-01-17 12:55:15,898 iteration 5224 : loss : 0.017950, loss_ce: 0.005788
2022-01-17 12:55:16,869 iteration 5225 : loss : 0.015874, loss_ce: 0.005483
2022-01-17 12:55:17,766 iteration 5226 : loss : 0.016380, loss_ce: 0.006650
2022-01-17 12:55:18,752 iteration 5227 : loss : 0.020145, loss_ce: 0.007889
2022-01-17 12:55:19,623 iteration 5228 : loss : 0.016380, loss_ce: 0.004459
2022-01-17 12:55:20,640 iteration 5229 : loss : 0.019866, loss_ce: 0.007966
2022-01-17 12:55:21,444 iteration 5230 : loss : 0.012960, loss_ce: 0.005398
2022-01-17 12:55:22,370 iteration 5231 : loss : 0.022977, loss_ce: 0.012286
2022-01-17 12:55:23,282 iteration 5232 : loss : 0.020535, loss_ce: 0.005729
2022-01-17 12:55:24,225 iteration 5233 : loss : 0.017276, loss_ce: 0.007009
2022-01-17 12:55:25,101 iteration 5234 : loss : 0.013296, loss_ce: 0.005672
2022-01-17 12:55:26,022 iteration 5235 : loss : 0.016739, loss_ce: 0.005192
2022-01-17 12:55:26,978 iteration 5236 : loss : 0.020489, loss_ce: 0.007472
 77%|██████████████████████▎      | 308/400 [1:29:36<25:03, 16.34s/it]2022-01-17 12:55:27,821 iteration 5237 : loss : 0.012380, loss_ce: 0.005160
2022-01-17 12:55:28,776 iteration 5238 : loss : 0.015384, loss_ce: 0.005973
2022-01-17 12:55:29,715 iteration 5239 : loss : 0.018809, loss_ce: 0.005766
2022-01-17 12:55:30,675 iteration 5240 : loss : 0.171668, loss_ce: 0.003098
2022-01-17 12:55:31,561 iteration 5241 : loss : 0.013379, loss_ce: 0.004986
2022-01-17 12:55:32,472 iteration 5242 : loss : 0.020076, loss_ce: 0.008554
2022-01-17 12:55:33,464 iteration 5243 : loss : 0.025050, loss_ce: 0.006767
2022-01-17 12:55:34,410 iteration 5244 : loss : 0.014185, loss_ce: 0.005572
2022-01-17 12:55:35,330 iteration 5245 : loss : 0.014881, loss_ce: 0.005140
2022-01-17 12:55:36,264 iteration 5246 : loss : 0.031068, loss_ce: 0.008415
2022-01-17 12:55:37,098 iteration 5247 : loss : 0.012084, loss_ce: 0.004603
2022-01-17 12:55:38,037 iteration 5248 : loss : 0.018062, loss_ce: 0.006142
2022-01-17 12:55:39,022 iteration 5249 : loss : 0.019051, loss_ce: 0.006557
2022-01-17 12:55:39,963 iteration 5250 : loss : 0.018987, loss_ce: 0.008814
2022-01-17 12:55:40,804 iteration 5251 : loss : 0.014461, loss_ce: 0.004591
2022-01-17 12:55:41,720 iteration 5252 : loss : 0.014017, loss_ce: 0.005541
2022-01-17 12:55:42,666 iteration 5253 : loss : 0.035062, loss_ce: 0.007511
 77%|██████████████████████▍      | 309/400 [1:29:52<24:29, 16.15s/it]2022-01-17 12:55:43,614 iteration 5254 : loss : 0.010706, loss_ce: 0.003501
2022-01-17 12:55:44,525 iteration 5255 : loss : 0.016595, loss_ce: 0.008463
2022-01-17 12:55:45,379 iteration 5256 : loss : 0.011752, loss_ce: 0.004878
2022-01-17 12:55:46,308 iteration 5257 : loss : 0.018511, loss_ce: 0.007029
2022-01-17 12:55:47,263 iteration 5258 : loss : 0.015790, loss_ce: 0.004141
2022-01-17 12:55:48,138 iteration 5259 : loss : 0.020807, loss_ce: 0.004908
2022-01-17 12:55:49,067 iteration 5260 : loss : 0.015736, loss_ce: 0.005339
2022-01-17 12:55:50,007 iteration 5261 : loss : 0.021259, loss_ce: 0.010609
2022-01-17 12:55:50,923 iteration 5262 : loss : 0.012468, loss_ce: 0.004828
2022-01-17 12:55:51,850 iteration 5263 : loss : 0.014183, loss_ce: 0.005111
2022-01-17 12:55:52,718 iteration 5264 : loss : 0.013107, loss_ce: 0.005174
2022-01-17 12:55:53,672 iteration 5265 : loss : 0.021814, loss_ce: 0.007287
2022-01-17 12:55:54,668 iteration 5266 : loss : 0.019331, loss_ce: 0.005765
2022-01-17 12:55:55,582 iteration 5267 : loss : 0.021048, loss_ce: 0.005459
2022-01-17 12:55:56,511 iteration 5268 : loss : 0.017429, loss_ce: 0.004681
2022-01-17 12:55:57,528 iteration 5269 : loss : 0.025393, loss_ce: 0.007244
2022-01-17 12:55:57,528 Training Data Eval:
2022-01-17 12:56:01,920   Average segmentation loss on training set: 0.0099
2022-01-17 12:56:01,921 Validation Data Eval:
2022-01-17 12:56:03,412   Average segmentation loss on validation set: 0.0813
2022-01-17 12:56:04,338 iteration 5270 : loss : 0.013951, loss_ce: 0.006171
 78%|██████████████████████▍      | 310/400 [1:30:14<26:42, 17.80s/it]2022-01-17 12:56:05,270 iteration 5271 : loss : 0.018432, loss_ce: 0.006243
2022-01-17 12:56:06,210 iteration 5272 : loss : 0.017143, loss_ce: 0.007520
2022-01-17 12:56:07,097 iteration 5273 : loss : 0.013946, loss_ce: 0.004416
2022-01-17 12:56:07,991 iteration 5274 : loss : 0.017184, loss_ce: 0.006723
2022-01-17 12:56:08,835 iteration 5275 : loss : 0.013482, loss_ce: 0.005665
2022-01-17 12:56:09,774 iteration 5276 : loss : 0.015851, loss_ce: 0.005966
2022-01-17 12:56:10,700 iteration 5277 : loss : 0.017691, loss_ce: 0.005879
2022-01-17 12:56:11,542 iteration 5278 : loss : 0.013971, loss_ce: 0.005705
2022-01-17 12:56:12,462 iteration 5279 : loss : 0.027209, loss_ce: 0.012291
2022-01-17 12:56:13,504 iteration 5280 : loss : 0.022909, loss_ce: 0.009139
2022-01-17 12:56:14,405 iteration 5281 : loss : 0.014808, loss_ce: 0.004834
2022-01-17 12:56:15,256 iteration 5282 : loss : 0.011706, loss_ce: 0.003451
2022-01-17 12:56:16,177 iteration 5283 : loss : 0.030523, loss_ce: 0.009201
2022-01-17 12:56:17,106 iteration 5284 : loss : 0.018586, loss_ce: 0.004974
2022-01-17 12:56:18,010 iteration 5285 : loss : 0.015272, loss_ce: 0.006288
2022-01-17 12:56:18,848 iteration 5286 : loss : 0.012485, loss_ce: 0.005140
2022-01-17 12:56:19,752 iteration 5287 : loss : 0.016276, loss_ce: 0.003347
 78%|██████████████████████▌      | 311/400 [1:30:29<25:20, 17.09s/it]2022-01-17 12:56:20,741 iteration 5288 : loss : 0.016970, loss_ce: 0.006522
2022-01-17 12:56:21,683 iteration 5289 : loss : 0.025535, loss_ce: 0.011094
2022-01-17 12:56:22,583 iteration 5290 : loss : 0.017179, loss_ce: 0.004818
2022-01-17 12:56:23,467 iteration 5291 : loss : 0.020300, loss_ce: 0.007102
2022-01-17 12:56:24,418 iteration 5292 : loss : 0.018373, loss_ce: 0.007232
2022-01-17 12:56:25,347 iteration 5293 : loss : 0.020070, loss_ce: 0.008298
2022-01-17 12:56:26,305 iteration 5294 : loss : 0.016320, loss_ce: 0.005888
2022-01-17 12:56:27,310 iteration 5295 : loss : 0.017432, loss_ce: 0.005835
2022-01-17 12:56:28,262 iteration 5296 : loss : 0.025446, loss_ce: 0.006559
2022-01-17 12:56:29,212 iteration 5297 : loss : 0.013603, loss_ce: 0.004074
2022-01-17 12:56:30,162 iteration 5298 : loss : 0.021754, loss_ce: 0.007537
2022-01-17 12:56:31,105 iteration 5299 : loss : 0.019213, loss_ce: 0.006288
2022-01-17 12:56:32,061 iteration 5300 : loss : 0.023602, loss_ce: 0.007512
2022-01-17 12:56:32,909 iteration 5301 : loss : 0.014989, loss_ce: 0.005442
2022-01-17 12:56:33,766 iteration 5302 : loss : 0.014967, loss_ce: 0.007914
2022-01-17 12:56:34,635 iteration 5303 : loss : 0.014533, loss_ce: 0.005363
2022-01-17 12:56:35,484 iteration 5304 : loss : 0.016130, loss_ce: 0.005452
 78%|██████████████████████▌      | 312/400 [1:30:45<24:28, 16.68s/it]2022-01-17 12:56:36,457 iteration 5305 : loss : 0.021001, loss_ce: 0.006592
2022-01-17 12:56:37,467 iteration 5306 : loss : 0.017945, loss_ce: 0.007710
2022-01-17 12:56:38,487 iteration 5307 : loss : 0.016700, loss_ce: 0.005938
2022-01-17 12:56:39,470 iteration 5308 : loss : 0.020434, loss_ce: 0.006782
2022-01-17 12:56:40,440 iteration 5309 : loss : 0.025543, loss_ce: 0.007548
2022-01-17 12:56:41,324 iteration 5310 : loss : 0.015818, loss_ce: 0.007628
2022-01-17 12:56:42,194 iteration 5311 : loss : 0.020156, loss_ce: 0.004698
2022-01-17 12:56:43,162 iteration 5312 : loss : 0.016728, loss_ce: 0.007568
2022-01-17 12:56:44,172 iteration 5313 : loss : 0.025209, loss_ce: 0.010284
2022-01-17 12:56:45,094 iteration 5314 : loss : 0.016068, loss_ce: 0.005272
2022-01-17 12:56:46,061 iteration 5315 : loss : 0.028672, loss_ce: 0.007751
2022-01-17 12:56:47,018 iteration 5316 : loss : 0.029836, loss_ce: 0.014079
2022-01-17 12:56:47,930 iteration 5317 : loss : 0.016940, loss_ce: 0.007247
2022-01-17 12:56:48,818 iteration 5318 : loss : 0.020889, loss_ce: 0.010191
2022-01-17 12:56:49,788 iteration 5319 : loss : 0.016991, loss_ce: 0.006373
2022-01-17 12:56:50,739 iteration 5320 : loss : 0.023867, loss_ce: 0.010318
2022-01-17 12:56:51,706 iteration 5321 : loss : 0.026438, loss_ce: 0.011010
 78%|██████████████████████▋      | 313/400 [1:31:01<23:59, 16.54s/it]2022-01-17 12:56:52,585 iteration 5322 : loss : 0.013386, loss_ce: 0.005396
2022-01-17 12:56:53,515 iteration 5323 : loss : 0.020677, loss_ce: 0.008338
2022-01-17 12:56:54,368 iteration 5324 : loss : 0.016711, loss_ce: 0.005177
2022-01-17 12:56:55,257 iteration 5325 : loss : 0.015904, loss_ce: 0.004062
2022-01-17 12:56:56,216 iteration 5326 : loss : 0.022286, loss_ce: 0.008081
2022-01-17 12:56:57,112 iteration 5327 : loss : 0.014767, loss_ce: 0.005390
2022-01-17 12:56:58,028 iteration 5328 : loss : 0.015798, loss_ce: 0.007985
2022-01-17 12:56:58,997 iteration 5329 : loss : 0.019386, loss_ce: 0.006646
2022-01-17 12:56:59,938 iteration 5330 : loss : 0.019484, loss_ce: 0.007408
2022-01-17 12:57:00,848 iteration 5331 : loss : 0.016610, loss_ce: 0.005295
2022-01-17 12:57:01,770 iteration 5332 : loss : 0.016205, loss_ce: 0.005649
2022-01-17 12:57:02,731 iteration 5333 : loss : 0.015980, loss_ce: 0.007339
2022-01-17 12:57:03,667 iteration 5334 : loss : 0.023874, loss_ce: 0.008965
2022-01-17 12:57:04,624 iteration 5335 : loss : 0.019024, loss_ce: 0.005337
2022-01-17 12:57:05,554 iteration 5336 : loss : 0.018498, loss_ce: 0.007094
2022-01-17 12:57:06,435 iteration 5337 : loss : 0.015029, loss_ce: 0.005715
2022-01-17 12:57:07,315 iteration 5338 : loss : 0.025546, loss_ce: 0.011237
 78%|██████████████████████▊      | 314/400 [1:31:17<23:18, 16.26s/it]2022-01-17 12:57:08,418 iteration 5339 : loss : 0.022563, loss_ce: 0.008850
2022-01-17 12:57:09,373 iteration 5340 : loss : 0.019216, loss_ce: 0.009849
2022-01-17 12:57:10,307 iteration 5341 : loss : 0.015078, loss_ce: 0.003073
2022-01-17 12:57:11,222 iteration 5342 : loss : 0.013939, loss_ce: 0.007206
2022-01-17 12:57:12,106 iteration 5343 : loss : 0.012796, loss_ce: 0.004030
2022-01-17 12:57:13,034 iteration 5344 : loss : 0.018058, loss_ce: 0.007162
2022-01-17 12:57:13,945 iteration 5345 : loss : 0.015059, loss_ce: 0.005153
2022-01-17 12:57:14,901 iteration 5346 : loss : 0.020844, loss_ce: 0.006799
2022-01-17 12:57:15,867 iteration 5347 : loss : 0.014352, loss_ce: 0.004220
2022-01-17 12:57:16,842 iteration 5348 : loss : 0.021284, loss_ce: 0.005437
2022-01-17 12:57:17,773 iteration 5349 : loss : 0.024144, loss_ce: 0.010031
2022-01-17 12:57:18,626 iteration 5350 : loss : 0.011888, loss_ce: 0.004374
2022-01-17 12:57:19,491 iteration 5351 : loss : 0.019778, loss_ce: 0.007338
2022-01-17 12:57:20,453 iteration 5352 : loss : 0.019643, loss_ce: 0.008023
2022-01-17 12:57:21,409 iteration 5353 : loss : 0.013557, loss_ce: 0.004865
2022-01-17 12:57:22,295 iteration 5354 : loss : 0.014928, loss_ce: 0.007254
2022-01-17 12:57:22,295 Training Data Eval:
2022-01-17 12:57:26,701   Average segmentation loss on training set: 0.0104
2022-01-17 12:57:26,701 Validation Data Eval:
2022-01-17 12:57:28,198   Average segmentation loss on validation set: 0.0784
2022-01-17 12:57:29,073 iteration 5355 : loss : 0.020179, loss_ce: 0.006629
 79%|██████████████████████▊      | 315/400 [1:31:38<25:22, 17.91s/it]2022-01-17 12:57:30,048 iteration 5356 : loss : 0.016150, loss_ce: 0.006679
2022-01-17 12:57:30,905 iteration 5357 : loss : 0.019294, loss_ce: 0.003761
2022-01-17 12:57:31,952 iteration 5358 : loss : 0.023338, loss_ce: 0.009243
2022-01-17 12:57:32,802 iteration 5359 : loss : 0.011357, loss_ce: 0.004097
2022-01-17 12:57:33,742 iteration 5360 : loss : 0.032001, loss_ce: 0.015881
2022-01-17 12:57:34,686 iteration 5361 : loss : 0.019610, loss_ce: 0.008335
2022-01-17 12:57:35,639 iteration 5362 : loss : 0.016907, loss_ce: 0.004794
2022-01-17 12:57:36,568 iteration 5363 : loss : 0.015699, loss_ce: 0.006250
2022-01-17 12:57:37,494 iteration 5364 : loss : 0.024865, loss_ce: 0.004849
2022-01-17 12:57:38,401 iteration 5365 : loss : 0.019995, loss_ce: 0.008044
2022-01-17 12:57:39,340 iteration 5366 : loss : 0.019212, loss_ce: 0.008080
2022-01-17 12:57:40,304 iteration 5367 : loss : 0.013362, loss_ce: 0.005636
2022-01-17 12:57:41,210 iteration 5368 : loss : 0.012805, loss_ce: 0.005680
2022-01-17 12:57:42,142 iteration 5369 : loss : 0.012972, loss_ce: 0.004892
2022-01-17 12:57:43,046 iteration 5370 : loss : 0.011561, loss_ce: 0.004464
2022-01-17 12:57:43,967 iteration 5371 : loss : 0.023627, loss_ce: 0.011170
2022-01-17 12:57:44,860 iteration 5372 : loss : 0.015560, loss_ce: 0.004922
 79%|██████████████████████▉      | 316/400 [1:31:54<24:11, 17.27s/it]2022-01-17 12:57:45,821 iteration 5373 : loss : 0.014607, loss_ce: 0.006746
2022-01-17 12:57:46,706 iteration 5374 : loss : 0.020229, loss_ce: 0.008460
2022-01-17 12:57:47,646 iteration 5375 : loss : 0.010533, loss_ce: 0.003163
2022-01-17 12:57:48,541 iteration 5376 : loss : 0.016328, loss_ce: 0.005455
2022-01-17 12:57:49,426 iteration 5377 : loss : 0.012873, loss_ce: 0.004021
2022-01-17 12:57:50,349 iteration 5378 : loss : 0.014596, loss_ce: 0.005137
2022-01-17 12:57:51,209 iteration 5379 : loss : 0.010809, loss_ce: 0.004165
2022-01-17 12:57:52,134 iteration 5380 : loss : 0.020059, loss_ce: 0.007779
2022-01-17 12:57:53,036 iteration 5381 : loss : 0.013930, loss_ce: 0.005750
2022-01-17 12:57:53,982 iteration 5382 : loss : 0.012998, loss_ce: 0.003736
2022-01-17 12:57:54,988 iteration 5383 : loss : 0.022691, loss_ce: 0.009980
2022-01-17 12:57:56,053 iteration 5384 : loss : 0.019117, loss_ce: 0.006827
2022-01-17 12:57:56,937 iteration 5385 : loss : 0.017067, loss_ce: 0.006376
2022-01-17 12:57:57,775 iteration 5386 : loss : 0.013966, loss_ce: 0.004733
2022-01-17 12:57:58,669 iteration 5387 : loss : 0.019993, loss_ce: 0.008753
2022-01-17 12:57:59,632 iteration 5388 : loss : 0.011835, loss_ce: 0.003646
2022-01-17 12:58:00,654 iteration 5389 : loss : 0.020366, loss_ce: 0.006836
 79%|██████████████████████▉      | 317/400 [1:32:10<23:16, 16.83s/it]2022-01-17 12:58:01,584 iteration 5390 : loss : 0.017418, loss_ce: 0.005023
2022-01-17 12:58:02,545 iteration 5391 : loss : 0.018607, loss_ce: 0.007046
2022-01-17 12:58:03,511 iteration 5392 : loss : 0.015262, loss_ce: 0.006916
2022-01-17 12:58:04,429 iteration 5393 : loss : 0.019763, loss_ce: 0.007011
2022-01-17 12:58:05,320 iteration 5394 : loss : 0.015041, loss_ce: 0.006487
2022-01-17 12:58:06,265 iteration 5395 : loss : 0.013231, loss_ce: 0.003923
2022-01-17 12:58:07,142 iteration 5396 : loss : 0.021721, loss_ce: 0.012218
2022-01-17 12:58:08,116 iteration 5397 : loss : 0.017570, loss_ce: 0.005219
2022-01-17 12:58:09,046 iteration 5398 : loss : 0.015850, loss_ce: 0.004887
2022-01-17 12:58:09,900 iteration 5399 : loss : 0.018121, loss_ce: 0.005344
2022-01-17 12:58:10,894 iteration 5400 : loss : 0.018696, loss_ce: 0.005126
2022-01-17 12:58:11,830 iteration 5401 : loss : 0.015730, loss_ce: 0.006847
2022-01-17 12:58:12,752 iteration 5402 : loss : 0.017036, loss_ce: 0.005084
2022-01-17 12:58:13,642 iteration 5403 : loss : 0.018809, loss_ce: 0.007261
2022-01-17 12:58:14,515 iteration 5404 : loss : 0.014115, loss_ce: 0.004063
2022-01-17 12:58:15,406 iteration 5405 : loss : 0.011892, loss_ce: 0.004891
2022-01-17 12:58:16,366 iteration 5406 : loss : 0.016202, loss_ce: 0.004218
 80%|███████████████████████      | 318/400 [1:32:26<22:32, 16.49s/it]2022-01-17 12:58:17,359 iteration 5407 : loss : 0.016295, loss_ce: 0.006027
2022-01-17 12:58:18,274 iteration 5408 : loss : 0.019966, loss_ce: 0.005586
2022-01-17 12:58:19,262 iteration 5409 : loss : 0.016199, loss_ce: 0.006789
2022-01-17 12:58:20,146 iteration 5410 : loss : 0.015234, loss_ce: 0.006531
2022-01-17 12:58:21,053 iteration 5411 : loss : 0.016676, loss_ce: 0.006365
2022-01-17 12:58:21,978 iteration 5412 : loss : 0.017099, loss_ce: 0.007364
2022-01-17 12:58:22,868 iteration 5413 : loss : 0.015840, loss_ce: 0.007254
2022-01-17 12:58:23,803 iteration 5414 : loss : 0.016917, loss_ce: 0.006391
2022-01-17 12:58:24,810 iteration 5415 : loss : 0.024002, loss_ce: 0.010284
2022-01-17 12:58:25,676 iteration 5416 : loss : 0.011264, loss_ce: 0.003593
2022-01-17 12:58:26,629 iteration 5417 : loss : 0.013782, loss_ce: 0.004083
2022-01-17 12:58:27,535 iteration 5418 : loss : 0.021027, loss_ce: 0.008486
2022-01-17 12:58:28,486 iteration 5419 : loss : 0.017427, loss_ce: 0.004082
2022-01-17 12:58:29,468 iteration 5420 : loss : 0.017252, loss_ce: 0.005921
2022-01-17 12:58:30,414 iteration 5421 : loss : 0.017857, loss_ce: 0.008468
2022-01-17 12:58:31,231 iteration 5422 : loss : 0.010606, loss_ce: 0.004196
2022-01-17 12:58:32,187 iteration 5423 : loss : 0.039385, loss_ce: 0.014923
 80%|███████████████████████▏     | 319/400 [1:32:42<21:59, 16.29s/it]2022-01-17 12:58:33,209 iteration 5424 : loss : 0.020706, loss_ce: 0.007276
2022-01-17 12:58:34,089 iteration 5425 : loss : 0.012516, loss_ce: 0.003713
2022-01-17 12:58:34,999 iteration 5426 : loss : 0.013806, loss_ce: 0.003286
2022-01-17 12:58:35,837 iteration 5427 : loss : 0.016681, loss_ce: 0.006119
2022-01-17 12:58:36,731 iteration 5428 : loss : 0.017430, loss_ce: 0.006113
2022-01-17 12:58:37,667 iteration 5429 : loss : 0.012245, loss_ce: 0.004070
2022-01-17 12:58:38,600 iteration 5430 : loss : 0.015676, loss_ce: 0.006221
2022-01-17 12:58:39,461 iteration 5431 : loss : 0.014948, loss_ce: 0.005125
2022-01-17 12:58:40,449 iteration 5432 : loss : 0.017771, loss_ce: 0.008101
2022-01-17 12:58:41,424 iteration 5433 : loss : 0.019413, loss_ce: 0.007688
2022-01-17 12:58:42,296 iteration 5434 : loss : 0.015383, loss_ce: 0.006394
2022-01-17 12:58:43,284 iteration 5435 : loss : 0.022815, loss_ce: 0.009057
2022-01-17 12:58:44,222 iteration 5436 : loss : 0.013171, loss_ce: 0.004770
2022-01-17 12:58:45,175 iteration 5437 : loss : 0.039150, loss_ce: 0.006028
2022-01-17 12:58:46,136 iteration 5438 : loss : 0.014315, loss_ce: 0.005873
2022-01-17 12:58:47,030 iteration 5439 : loss : 0.016818, loss_ce: 0.006807
2022-01-17 12:58:47,030 Training Data Eval:
2022-01-17 12:58:51,439   Average segmentation loss on training set: 0.0098
2022-01-17 12:58:51,439 Validation Data Eval:
2022-01-17 12:58:52,926   Average segmentation loss on validation set: 0.0786
2022-01-17 12:58:53,806 iteration 5440 : loss : 0.016492, loss_ce: 0.004957
 80%|███████████████████████▏     | 320/400 [1:33:03<23:51, 17.89s/it]2022-01-17 12:58:54,754 iteration 5441 : loss : 0.014116, loss_ce: 0.005460
2022-01-17 12:58:55,632 iteration 5442 : loss : 0.015819, loss_ce: 0.005497
2022-01-17 12:58:56,549 iteration 5443 : loss : 0.014658, loss_ce: 0.004868
2022-01-17 12:58:57,397 iteration 5444 : loss : 0.013815, loss_ce: 0.004351
2022-01-17 12:58:58,324 iteration 5445 : loss : 0.021640, loss_ce: 0.009671
2022-01-17 12:58:59,195 iteration 5446 : loss : 0.015326, loss_ce: 0.006999
2022-01-17 12:59:00,185 iteration 5447 : loss : 0.019621, loss_ce: 0.006662
2022-01-17 12:59:01,049 iteration 5448 : loss : 0.014463, loss_ce: 0.005304
2022-01-17 12:59:01,977 iteration 5449 : loss : 0.026245, loss_ce: 0.014035
2022-01-17 12:59:02,895 iteration 5450 : loss : 0.019026, loss_ce: 0.007674
2022-01-17 12:59:03,762 iteration 5451 : loss : 0.014951, loss_ce: 0.004883
2022-01-17 12:59:04,689 iteration 5452 : loss : 0.024116, loss_ce: 0.009649
2022-01-17 12:59:05,560 iteration 5453 : loss : 0.014351, loss_ce: 0.005916
2022-01-17 12:59:06,522 iteration 5454 : loss : 0.020684, loss_ce: 0.011190
2022-01-17 12:59:07,448 iteration 5455 : loss : 0.017561, loss_ce: 0.007065
2022-01-17 12:59:08,353 iteration 5456 : loss : 0.012061, loss_ce: 0.002549
2022-01-17 12:59:09,222 iteration 5457 : loss : 0.013618, loss_ce: 0.003954
 80%|███████████████████████▎     | 321/400 [1:33:19<22:34, 17.15s/it]2022-01-17 12:59:10,162 iteration 5458 : loss : 0.018650, loss_ce: 0.005806
2022-01-17 12:59:11,024 iteration 5459 : loss : 0.013859, loss_ce: 0.006002
2022-01-17 12:59:11,947 iteration 5460 : loss : 0.013214, loss_ce: 0.004669
2022-01-17 12:59:12,856 iteration 5461 : loss : 0.017155, loss_ce: 0.006059
2022-01-17 12:59:13,755 iteration 5462 : loss : 0.014308, loss_ce: 0.005019
2022-01-17 12:59:14,684 iteration 5463 : loss : 0.017698, loss_ce: 0.004835
2022-01-17 12:59:15,602 iteration 5464 : loss : 0.016112, loss_ce: 0.006931
2022-01-17 12:59:16,576 iteration 5465 : loss : 0.020653, loss_ce: 0.006977
2022-01-17 12:59:17,540 iteration 5466 : loss : 0.017941, loss_ce: 0.006169
2022-01-17 12:59:18,477 iteration 5467 : loss : 0.018915, loss_ce: 0.008591
2022-01-17 12:59:19,410 iteration 5468 : loss : 0.013354, loss_ce: 0.005692
2022-01-17 12:59:20,259 iteration 5469 : loss : 0.018021, loss_ce: 0.005714
2022-01-17 12:59:21,161 iteration 5470 : loss : 0.009249, loss_ce: 0.003102
2022-01-17 12:59:22,067 iteration 5471 : loss : 0.015792, loss_ce: 0.003539
2022-01-17 12:59:23,012 iteration 5472 : loss : 0.024312, loss_ce: 0.008965
2022-01-17 12:59:23,881 iteration 5473 : loss : 0.012058, loss_ce: 0.004096
2022-01-17 12:59:24,759 iteration 5474 : loss : 0.013991, loss_ce: 0.004450
 80%|███████████████████████▎     | 322/400 [1:33:34<21:39, 16.66s/it]2022-01-17 12:59:25,741 iteration 5475 : loss : 0.021444, loss_ce: 0.005235
2022-01-17 12:59:26,717 iteration 5476 : loss : 0.018439, loss_ce: 0.009496
2022-01-17 12:59:27,638 iteration 5477 : loss : 0.025803, loss_ce: 0.003392
2022-01-17 12:59:28,489 iteration 5478 : loss : 0.014081, loss_ce: 0.004597
2022-01-17 12:59:29,401 iteration 5479 : loss : 0.013336, loss_ce: 0.005647
2022-01-17 12:59:30,315 iteration 5480 : loss : 0.014248, loss_ce: 0.004028
2022-01-17 12:59:31,218 iteration 5481 : loss : 0.014549, loss_ce: 0.004664
2022-01-17 12:59:32,224 iteration 5482 : loss : 0.024193, loss_ce: 0.006010
2022-01-17 12:59:33,065 iteration 5483 : loss : 0.010959, loss_ce: 0.004169
2022-01-17 12:59:33,993 iteration 5484 : loss : 0.020114, loss_ce: 0.006969
2022-01-17 12:59:34,905 iteration 5485 : loss : 0.012174, loss_ce: 0.004913
2022-01-17 12:59:35,812 iteration 5486 : loss : 0.021055, loss_ce: 0.009506
2022-01-17 12:59:36,744 iteration 5487 : loss : 0.013860, loss_ce: 0.005219
2022-01-17 12:59:37,620 iteration 5488 : loss : 0.012728, loss_ce: 0.005800
2022-01-17 12:59:38,489 iteration 5489 : loss : 0.012419, loss_ce: 0.006514
2022-01-17 12:59:39,467 iteration 5490 : loss : 0.021150, loss_ce: 0.008107
2022-01-17 12:59:40,352 iteration 5491 : loss : 0.011168, loss_ce: 0.003211
 81%|███████████████████████▍     | 323/400 [1:33:50<20:58, 16.34s/it]2022-01-17 12:59:41,227 iteration 5492 : loss : 0.017559, loss_ce: 0.006188
2022-01-17 12:59:42,161 iteration 5493 : loss : 0.018492, loss_ce: 0.005488
2022-01-17 12:59:43,028 iteration 5494 : loss : 0.014858, loss_ce: 0.004510
2022-01-17 12:59:43,944 iteration 5495 : loss : 0.011213, loss_ce: 0.003217
2022-01-17 12:59:44,869 iteration 5496 : loss : 0.014448, loss_ce: 0.004030
2022-01-17 12:59:45,798 iteration 5497 : loss : 0.013564, loss_ce: 0.004997
2022-01-17 12:59:46,762 iteration 5498 : loss : 0.018740, loss_ce: 0.006138
2022-01-17 12:59:47,704 iteration 5499 : loss : 0.019256, loss_ce: 0.010638
2022-01-17 12:59:48,551 iteration 5500 : loss : 0.014306, loss_ce: 0.006038
2022-01-17 12:59:49,468 iteration 5501 : loss : 0.019331, loss_ce: 0.009527
2022-01-17 12:59:50,337 iteration 5502 : loss : 0.010119, loss_ce: 0.004015
2022-01-17 12:59:51,247 iteration 5503 : loss : 0.015346, loss_ce: 0.004036
2022-01-17 12:59:52,127 iteration 5504 : loss : 0.012971, loss_ce: 0.004985
2022-01-17 12:59:53,038 iteration 5505 : loss : 0.018683, loss_ce: 0.008321
2022-01-17 12:59:53,988 iteration 5506 : loss : 0.012085, loss_ce: 0.004365
2022-01-17 12:59:54,900 iteration 5507 : loss : 0.016987, loss_ce: 0.007410
2022-01-17 12:59:55,829 iteration 5508 : loss : 0.024582, loss_ce: 0.007498
 81%|███████████████████████▍     | 324/400 [1:34:05<20:22, 16.09s/it]2022-01-17 12:59:56,800 iteration 5509 : loss : 0.017664, loss_ce: 0.004894
2022-01-17 12:59:57,802 iteration 5510 : loss : 0.017046, loss_ce: 0.006270
2022-01-17 12:59:58,696 iteration 5511 : loss : 0.013472, loss_ce: 0.005095
2022-01-17 12:59:59,656 iteration 5512 : loss : 0.018407, loss_ce: 0.006793
2022-01-17 13:00:00,544 iteration 5513 : loss : 0.013875, loss_ce: 0.005491
2022-01-17 13:00:01,390 iteration 5514 : loss : 0.010137, loss_ce: 0.003237
2022-01-17 13:00:02,361 iteration 5515 : loss : 0.034361, loss_ce: 0.008471
2022-01-17 13:00:03,255 iteration 5516 : loss : 0.015723, loss_ce: 0.005851
2022-01-17 13:00:04,181 iteration 5517 : loss : 0.013945, loss_ce: 0.005962
2022-01-17 13:00:05,096 iteration 5518 : loss : 0.024701, loss_ce: 0.007962
2022-01-17 13:00:06,029 iteration 5519 : loss : 0.020295, loss_ce: 0.009671
2022-01-17 13:00:06,943 iteration 5520 : loss : 0.016258, loss_ce: 0.007245
2022-01-17 13:00:07,878 iteration 5521 : loss : 0.019747, loss_ce: 0.010277
2022-01-17 13:00:08,790 iteration 5522 : loss : 0.015969, loss_ce: 0.004387
2022-01-17 13:00:09,669 iteration 5523 : loss : 0.009575, loss_ce: 0.003256
2022-01-17 13:00:10,557 iteration 5524 : loss : 0.015882, loss_ce: 0.006553
2022-01-17 13:00:10,557 Training Data Eval:
2022-01-17 13:00:14,955   Average segmentation loss on training set: 0.0095
2022-01-17 13:00:14,955 Validation Data Eval:
2022-01-17 13:00:16,442   Average segmentation loss on validation set: 0.0775
2022-01-17 13:00:17,362 iteration 5525 : loss : 0.016620, loss_ce: 0.007706
 81%|███████████████████████▌     | 325/400 [1:34:27<22:08, 17.72s/it]2022-01-17 13:00:18,369 iteration 5526 : loss : 0.017972, loss_ce: 0.006335
2022-01-17 13:00:19,292 iteration 5527 : loss : 0.020048, loss_ce: 0.009944
2022-01-17 13:00:20,200 iteration 5528 : loss : 0.021016, loss_ce: 0.006457
2022-01-17 13:00:21,144 iteration 5529 : loss : 0.022711, loss_ce: 0.009788
2022-01-17 13:00:22,007 iteration 5530 : loss : 0.014149, loss_ce: 0.006277
2022-01-17 13:00:22,890 iteration 5531 : loss : 0.014781, loss_ce: 0.006010
2022-01-17 13:00:23,763 iteration 5532 : loss : 0.010289, loss_ce: 0.004032
2022-01-17 13:00:24,734 iteration 5533 : loss : 0.015521, loss_ce: 0.004025
2022-01-17 13:00:25,652 iteration 5534 : loss : 0.014188, loss_ce: 0.005022
2022-01-17 13:00:26,627 iteration 5535 : loss : 0.016759, loss_ce: 0.006327
2022-01-17 13:00:27,632 iteration 5536 : loss : 0.012878, loss_ce: 0.005206
2022-01-17 13:00:28,580 iteration 5537 : loss : 0.017639, loss_ce: 0.005196
2022-01-17 13:00:29,504 iteration 5538 : loss : 0.016977, loss_ce: 0.006612
2022-01-17 13:00:30,509 iteration 5539 : loss : 0.017848, loss_ce: 0.003932
2022-01-17 13:00:31,395 iteration 5540 : loss : 0.013530, loss_ce: 0.006161
2022-01-17 13:00:32,313 iteration 5541 : loss : 0.022564, loss_ce: 0.007778
2022-01-17 13:00:33,209 iteration 5542 : loss : 0.013979, loss_ce: 0.005199
 82%|███████████████████████▋     | 326/400 [1:34:43<21:09, 17.16s/it]2022-01-17 13:00:34,197 iteration 5543 : loss : 0.017604, loss_ce: 0.006046
2022-01-17 13:00:35,126 iteration 5544 : loss : 0.018599, loss_ce: 0.007820
2022-01-17 13:00:36,019 iteration 5545 : loss : 0.017703, loss_ce: 0.006597
2022-01-17 13:00:36,892 iteration 5546 : loss : 0.012158, loss_ce: 0.004151
2022-01-17 13:00:37,817 iteration 5547 : loss : 0.015847, loss_ce: 0.005615
2022-01-17 13:00:38,794 iteration 5548 : loss : 0.023164, loss_ce: 0.007431
2022-01-17 13:00:39,662 iteration 5549 : loss : 0.016017, loss_ce: 0.006662
2022-01-17 13:00:40,562 iteration 5550 : loss : 0.014093, loss_ce: 0.004941
2022-01-17 13:00:41,485 iteration 5551 : loss : 0.012598, loss_ce: 0.005161
2022-01-17 13:00:42,353 iteration 5552 : loss : 0.011661, loss_ce: 0.004580
2022-01-17 13:00:43,289 iteration 5553 : loss : 0.023280, loss_ce: 0.009451
2022-01-17 13:00:44,253 iteration 5554 : loss : 0.019146, loss_ce: 0.005944
2022-01-17 13:00:45,208 iteration 5555 : loss : 0.018631, loss_ce: 0.005501
2022-01-17 13:00:46,052 iteration 5556 : loss : 0.016157, loss_ce: 0.006220
2022-01-17 13:00:47,025 iteration 5557 : loss : 0.030454, loss_ce: 0.009176
2022-01-17 13:00:47,953 iteration 5558 : loss : 0.014483, loss_ce: 0.004602
2022-01-17 13:00:48,787 iteration 5559 : loss : 0.013434, loss_ce: 0.004900
 82%|███████████████████████▋     | 327/400 [1:34:58<20:17, 16.68s/it]2022-01-17 13:00:49,910 iteration 5560 : loss : 0.022483, loss_ce: 0.008535
2022-01-17 13:00:50,807 iteration 5561 : loss : 0.017839, loss_ce: 0.005507
2022-01-17 13:00:51,709 iteration 5562 : loss : 0.018686, loss_ce: 0.005691
2022-01-17 13:00:52,609 iteration 5563 : loss : 0.011948, loss_ce: 0.004702
2022-01-17 13:00:53,604 iteration 5564 : loss : 0.018124, loss_ce: 0.006493
2022-01-17 13:00:54,521 iteration 5565 : loss : 0.013634, loss_ce: 0.005395
2022-01-17 13:00:55,474 iteration 5566 : loss : 0.015804, loss_ce: 0.007807
2022-01-17 13:00:56,476 iteration 5567 : loss : 0.015763, loss_ce: 0.007241
2022-01-17 13:00:57,393 iteration 5568 : loss : 0.019739, loss_ce: 0.007093
2022-01-17 13:00:58,347 iteration 5569 : loss : 0.015363, loss_ce: 0.006350
2022-01-17 13:00:59,273 iteration 5570 : loss : 0.014559, loss_ce: 0.004703
2022-01-17 13:01:00,225 iteration 5571 : loss : 0.016196, loss_ce: 0.006657
2022-01-17 13:01:01,136 iteration 5572 : loss : 0.014433, loss_ce: 0.005432
2022-01-17 13:01:02,027 iteration 5573 : loss : 0.015888, loss_ce: 0.004693
2022-01-17 13:01:03,028 iteration 5574 : loss : 0.023979, loss_ce: 0.009241
2022-01-17 13:01:03,844 iteration 5575 : loss : 0.011304, loss_ce: 0.004887
2022-01-17 13:01:04,657 iteration 5576 : loss : 0.011557, loss_ce: 0.003463
 82%|███████████████████████▊     | 328/400 [1:35:14<19:43, 16.44s/it]2022-01-17 13:01:05,629 iteration 5577 : loss : 0.012610, loss_ce: 0.004065
2022-01-17 13:01:06,525 iteration 5578 : loss : 0.017660, loss_ce: 0.003879
2022-01-17 13:01:07,440 iteration 5579 : loss : 0.013752, loss_ce: 0.003805
2022-01-17 13:01:08,401 iteration 5580 : loss : 0.012530, loss_ce: 0.004360
2022-01-17 13:01:09,296 iteration 5581 : loss : 0.015114, loss_ce: 0.005752
2022-01-17 13:01:10,243 iteration 5582 : loss : 0.014249, loss_ce: 0.003867
2022-01-17 13:01:11,140 iteration 5583 : loss : 0.024255, loss_ce: 0.006449
2022-01-17 13:01:12,132 iteration 5584 : loss : 0.022848, loss_ce: 0.009952
2022-01-17 13:01:13,018 iteration 5585 : loss : 0.014287, loss_ce: 0.005182
2022-01-17 13:01:13,924 iteration 5586 : loss : 0.025558, loss_ce: 0.011238
2022-01-17 13:01:14,839 iteration 5587 : loss : 0.014618, loss_ce: 0.006766
2022-01-17 13:01:15,822 iteration 5588 : loss : 0.016389, loss_ce: 0.007535
2022-01-17 13:01:16,777 iteration 5589 : loss : 0.020221, loss_ce: 0.008079
2022-01-17 13:01:17,697 iteration 5590 : loss : 0.023573, loss_ce: 0.009159
2022-01-17 13:01:18,612 iteration 5591 : loss : 0.015058, loss_ce: 0.006125
2022-01-17 13:01:19,515 iteration 5592 : loss : 0.017924, loss_ce: 0.007129
2022-01-17 13:01:20,413 iteration 5593 : loss : 0.014451, loss_ce: 0.008295
 82%|███████████████████████▊     | 329/400 [1:35:30<19:12, 16.23s/it]2022-01-17 13:01:21,405 iteration 5594 : loss : 0.015853, loss_ce: 0.005075
2022-01-17 13:01:22,302 iteration 5595 : loss : 0.014545, loss_ce: 0.006010
2022-01-17 13:01:23,199 iteration 5596 : loss : 0.010576, loss_ce: 0.002862
2022-01-17 13:01:24,136 iteration 5597 : loss : 0.014242, loss_ce: 0.004456
2022-01-17 13:01:25,128 iteration 5598 : loss : 0.023069, loss_ce: 0.009159
2022-01-17 13:01:26,093 iteration 5599 : loss : 0.016471, loss_ce: 0.005366
2022-01-17 13:01:27,047 iteration 5600 : loss : 0.015178, loss_ce: 0.005944
2022-01-17 13:01:28,001 iteration 5601 : loss : 0.012974, loss_ce: 0.003631
2022-01-17 13:01:28,881 iteration 5602 : loss : 0.017295, loss_ce: 0.004353
2022-01-17 13:01:29,839 iteration 5603 : loss : 0.025787, loss_ce: 0.010738
2022-01-17 13:01:30,727 iteration 5604 : loss : 0.015473, loss_ce: 0.006706
2022-01-17 13:01:31,619 iteration 5605 : loss : 0.016742, loss_ce: 0.005544
2022-01-17 13:01:32,601 iteration 5606 : loss : 0.022552, loss_ce: 0.006894
2022-01-17 13:01:33,526 iteration 5607 : loss : 0.019904, loss_ce: 0.007484
2022-01-17 13:01:34,561 iteration 5608 : loss : 0.028268, loss_ce: 0.012926
2022-01-17 13:01:35,446 iteration 5609 : loss : 0.015601, loss_ce: 0.007535
2022-01-17 13:01:35,446 Training Data Eval:
2022-01-17 13:01:39,833   Average segmentation loss on training set: 0.0091
2022-01-17 13:01:39,833 Validation Data Eval:
2022-01-17 13:01:41,323   Average segmentation loss on validation set: 0.0816
2022-01-17 13:01:42,277 iteration 5610 : loss : 0.016714, loss_ce: 0.005707
 82%|███████████████████████▉     | 330/400 [1:35:52<20:54, 17.92s/it]2022-01-17 13:01:43,284 iteration 5611 : loss : 0.014604, loss_ce: 0.006070
2022-01-17 13:01:44,209 iteration 5612 : loss : 0.015680, loss_ce: 0.004542
2022-01-17 13:01:45,119 iteration 5613 : loss : 0.017604, loss_ce: 0.007309
2022-01-17 13:01:46,025 iteration 5614 : loss : 0.016231, loss_ce: 0.005679
2022-01-17 13:01:46,968 iteration 5615 : loss : 0.015682, loss_ce: 0.005001
2022-01-17 13:01:47,927 iteration 5616 : loss : 0.018104, loss_ce: 0.006283
2022-01-17 13:01:48,853 iteration 5617 : loss : 0.011714, loss_ce: 0.003883
2022-01-17 13:01:49,725 iteration 5618 : loss : 0.017869, loss_ce: 0.008611
2022-01-17 13:01:50,689 iteration 5619 : loss : 0.022582, loss_ce: 0.008766
2022-01-17 13:01:51,654 iteration 5620 : loss : 0.014935, loss_ce: 0.004223
2022-01-17 13:01:52,548 iteration 5621 : loss : 0.016961, loss_ce: 0.006485
2022-01-17 13:01:53,548 iteration 5622 : loss : 0.018671, loss_ce: 0.007299
2022-01-17 13:01:54,434 iteration 5623 : loss : 0.017507, loss_ce: 0.004916
2022-01-17 13:01:55,378 iteration 5624 : loss : 0.014479, loss_ce: 0.005927
2022-01-17 13:01:56,327 iteration 5625 : loss : 0.019823, loss_ce: 0.008277
2022-01-17 13:01:57,245 iteration 5626 : loss : 0.015109, loss_ce: 0.005696
2022-01-17 13:01:58,150 iteration 5627 : loss : 0.022725, loss_ce: 0.007139
 83%|███████████████████████▉     | 331/400 [1:36:08<19:54, 17.31s/it]2022-01-17 13:01:59,012 iteration 5628 : loss : 0.012963, loss_ce: 0.004717
2022-01-17 13:01:59,948 iteration 5629 : loss : 0.017502, loss_ce: 0.006957
2022-01-17 13:02:00,866 iteration 5630 : loss : 0.013068, loss_ce: 0.004662
2022-01-17 13:02:01,880 iteration 5631 : loss : 0.019170, loss_ce: 0.008413
2022-01-17 13:02:02,723 iteration 5632 : loss : 0.014326, loss_ce: 0.006071
2022-01-17 13:02:03,680 iteration 5633 : loss : 0.020417, loss_ce: 0.007462
2022-01-17 13:02:04,549 iteration 5634 : loss : 0.015456, loss_ce: 0.004908
2022-01-17 13:02:05,487 iteration 5635 : loss : 0.016284, loss_ce: 0.004035
2022-01-17 13:02:06,354 iteration 5636 : loss : 0.014119, loss_ce: 0.005645
2022-01-17 13:02:07,298 iteration 5637 : loss : 0.016525, loss_ce: 0.006509
2022-01-17 13:02:08,127 iteration 5638 : loss : 0.011356, loss_ce: 0.003319
2022-01-17 13:02:08,998 iteration 5639 : loss : 0.017002, loss_ce: 0.004712
2022-01-17 13:02:09,909 iteration 5640 : loss : 0.014066, loss_ce: 0.006847
2022-01-17 13:02:10,866 iteration 5641 : loss : 0.012979, loss_ce: 0.006589
2022-01-17 13:02:11,766 iteration 5642 : loss : 0.011674, loss_ce: 0.002189
2022-01-17 13:02:12,723 iteration 5643 : loss : 0.011757, loss_ce: 0.003184
2022-01-17 13:02:13,661 iteration 5644 : loss : 0.013177, loss_ce: 0.004831
 83%|████████████████████████     | 332/400 [1:36:23<19:00, 16.77s/it]2022-01-17 13:02:14,722 iteration 5645 : loss : 0.019733, loss_ce: 0.008035
2022-01-17 13:02:15,600 iteration 5646 : loss : 0.019282, loss_ce: 0.007115
2022-01-17 13:02:16,507 iteration 5647 : loss : 0.015481, loss_ce: 0.007171
2022-01-17 13:02:17,455 iteration 5648 : loss : 0.016945, loss_ce: 0.005608
2022-01-17 13:02:18,399 iteration 5649 : loss : 0.015548, loss_ce: 0.006809
2022-01-17 13:02:19,319 iteration 5650 : loss : 0.013564, loss_ce: 0.005206
2022-01-17 13:02:20,218 iteration 5651 : loss : 0.016849, loss_ce: 0.007762
2022-01-17 13:02:21,065 iteration 5652 : loss : 0.011680, loss_ce: 0.004405
2022-01-17 13:02:21,976 iteration 5653 : loss : 0.011403, loss_ce: 0.003963
2022-01-17 13:02:22,854 iteration 5654 : loss : 0.012410, loss_ce: 0.003158
2022-01-17 13:02:23,800 iteration 5655 : loss : 0.017911, loss_ce: 0.007871
2022-01-17 13:02:24,725 iteration 5656 : loss : 0.015706, loss_ce: 0.005074
2022-01-17 13:02:25,648 iteration 5657 : loss : 0.013503, loss_ce: 0.005003
2022-01-17 13:02:26,570 iteration 5658 : loss : 0.018174, loss_ce: 0.008168
2022-01-17 13:02:27,466 iteration 5659 : loss : 0.012953, loss_ce: 0.003732
2022-01-17 13:02:28,332 iteration 5660 : loss : 0.026301, loss_ce: 0.009483
2022-01-17 13:02:29,335 iteration 5661 : loss : 0.015980, loss_ce: 0.005168
 83%|████████████████████████▏    | 333/400 [1:36:39<18:21, 16.44s/it]2022-01-17 13:02:30,295 iteration 5662 : loss : 0.020030, loss_ce: 0.004479
2022-01-17 13:02:31,204 iteration 5663 : loss : 0.014214, loss_ce: 0.005574
2022-01-17 13:02:32,131 iteration 5664 : loss : 0.020769, loss_ce: 0.007556
2022-01-17 13:02:32,958 iteration 5665 : loss : 0.012329, loss_ce: 0.004321
2022-01-17 13:02:33,892 iteration 5666 : loss : 0.014891, loss_ce: 0.005112
2022-01-17 13:02:34,844 iteration 5667 : loss : 0.015451, loss_ce: 0.006126
2022-01-17 13:02:35,754 iteration 5668 : loss : 0.012913, loss_ce: 0.005795
2022-01-17 13:02:36,710 iteration 5669 : loss : 0.015267, loss_ce: 0.007263
2022-01-17 13:02:37,649 iteration 5670 : loss : 0.012902, loss_ce: 0.004359
2022-01-17 13:02:38,581 iteration 5671 : loss : 0.014574, loss_ce: 0.005595
2022-01-17 13:02:39,500 iteration 5672 : loss : 0.021433, loss_ce: 0.006416
2022-01-17 13:02:40,387 iteration 5673 : loss : 0.013569, loss_ce: 0.004167
2022-01-17 13:02:41,376 iteration 5674 : loss : 0.014278, loss_ce: 0.006316
2022-01-17 13:02:42,272 iteration 5675 : loss : 0.013166, loss_ce: 0.005644
2022-01-17 13:02:43,244 iteration 5676 : loss : 0.015571, loss_ce: 0.005606
2022-01-17 13:02:44,195 iteration 5677 : loss : 0.018012, loss_ce: 0.009993
2022-01-17 13:02:45,128 iteration 5678 : loss : 0.017556, loss_ce: 0.005598
 84%|████████████████████████▏    | 334/400 [1:36:54<17:52, 16.24s/it]2022-01-17 13:02:46,097 iteration 5679 : loss : 0.018239, loss_ce: 0.008092
2022-01-17 13:02:46,915 iteration 5680 : loss : 0.011753, loss_ce: 0.002736
2022-01-17 13:02:47,874 iteration 5681 : loss : 0.019322, loss_ce: 0.006704
2022-01-17 13:02:48,841 iteration 5682 : loss : 0.024368, loss_ce: 0.011972
2022-01-17 13:02:49,734 iteration 5683 : loss : 0.011128, loss_ce: 0.003647
2022-01-17 13:02:50,619 iteration 5684 : loss : 0.011907, loss_ce: 0.006089
2022-01-17 13:02:51,558 iteration 5685 : loss : 0.015280, loss_ce: 0.006619
2022-01-17 13:02:52,459 iteration 5686 : loss : 0.015407, loss_ce: 0.005747
2022-01-17 13:02:53,380 iteration 5687 : loss : 0.012368, loss_ce: 0.004802
2022-01-17 13:02:54,382 iteration 5688 : loss : 0.016926, loss_ce: 0.005634
2022-01-17 13:02:55,300 iteration 5689 : loss : 0.021592, loss_ce: 0.005223
2022-01-17 13:02:56,226 iteration 5690 : loss : 0.015907, loss_ce: 0.007084
2022-01-17 13:02:57,168 iteration 5691 : loss : 0.017203, loss_ce: 0.007193
2022-01-17 13:02:58,102 iteration 5692 : loss : 0.019018, loss_ce: 0.007657
2022-01-17 13:02:59,020 iteration 5693 : loss : 0.016206, loss_ce: 0.005281
2022-01-17 13:02:59,920 iteration 5694 : loss : 0.019735, loss_ce: 0.008581
2022-01-17 13:02:59,920 Training Data Eval:
2022-01-17 13:03:04,304   Average segmentation loss on training set: 0.0095
2022-01-17 13:03:04,304 Validation Data Eval:
2022-01-17 13:03:05,794   Average segmentation loss on validation set: 0.0739
2022-01-17 13:03:06,676 iteration 5695 : loss : 0.015541, loss_ce: 0.005217
 84%|████████████████████████▎    | 335/400 [1:37:16<19:19, 17.83s/it]2022-01-17 13:03:07,595 iteration 5696 : loss : 0.010205, loss_ce: 0.005035
2022-01-17 13:03:08,467 iteration 5697 : loss : 0.013436, loss_ce: 0.005854
2022-01-17 13:03:09,434 iteration 5698 : loss : 0.026256, loss_ce: 0.011107
2022-01-17 13:03:10,279 iteration 5699 : loss : 0.012387, loss_ce: 0.005185
2022-01-17 13:03:11,177 iteration 5700 : loss : 0.013539, loss_ce: 0.005020
2022-01-17 13:03:12,049 iteration 5701 : loss : 0.013651, loss_ce: 0.006126
2022-01-17 13:03:13,063 iteration 5702 : loss : 0.015435, loss_ce: 0.006270
2022-01-17 13:03:14,014 iteration 5703 : loss : 0.014720, loss_ce: 0.006704
2022-01-17 13:03:14,943 iteration 5704 : loss : 0.013695, loss_ce: 0.004812
2022-01-17 13:03:15,878 iteration 5705 : loss : 0.014868, loss_ce: 0.005242
2022-01-17 13:03:16,706 iteration 5706 : loss : 0.012108, loss_ce: 0.004494
2022-01-17 13:03:17,593 iteration 5707 : loss : 0.014803, loss_ce: 0.005521
2022-01-17 13:03:18,455 iteration 5708 : loss : 0.013440, loss_ce: 0.004844
2022-01-17 13:03:19,377 iteration 5709 : loss : 0.014215, loss_ce: 0.004333
2022-01-17 13:03:20,286 iteration 5710 : loss : 0.015298, loss_ce: 0.004169
2022-01-17 13:03:21,147 iteration 5711 : loss : 0.017099, loss_ce: 0.006438
2022-01-17 13:03:22,086 iteration 5712 : loss : 0.018532, loss_ce: 0.009340
 84%|████████████████████████▎    | 336/400 [1:37:31<18:15, 17.11s/it]2022-01-17 13:03:23,089 iteration 5713 : loss : 0.017193, loss_ce: 0.005621
2022-01-17 13:03:24,047 iteration 5714 : loss : 0.015685, loss_ce: 0.005828
2022-01-17 13:03:25,013 iteration 5715 : loss : 0.014891, loss_ce: 0.005608
2022-01-17 13:03:25,909 iteration 5716 : loss : 0.013272, loss_ce: 0.005151
2022-01-17 13:03:26,900 iteration 5717 : loss : 0.021457, loss_ce: 0.009836
2022-01-17 13:03:27,759 iteration 5718 : loss : 0.013948, loss_ce: 0.004443
2022-01-17 13:03:28,617 iteration 5719 : loss : 0.012492, loss_ce: 0.005482
2022-01-17 13:03:29,571 iteration 5720 : loss : 0.017948, loss_ce: 0.006744
2022-01-17 13:03:30,491 iteration 5721 : loss : 0.018609, loss_ce: 0.009401
2022-01-17 13:03:31,400 iteration 5722 : loss : 0.014333, loss_ce: 0.006052
2022-01-17 13:03:32,324 iteration 5723 : loss : 0.016009, loss_ce: 0.005449
2022-01-17 13:03:33,285 iteration 5724 : loss : 0.012622, loss_ce: 0.004252
2022-01-17 13:03:34,206 iteration 5725 : loss : 0.013159, loss_ce: 0.004695
2022-01-17 13:03:35,083 iteration 5726 : loss : 0.017876, loss_ce: 0.004116
2022-01-17 13:03:36,016 iteration 5727 : loss : 0.014957, loss_ce: 0.004936
2022-01-17 13:03:36,910 iteration 5728 : loss : 0.020781, loss_ce: 0.006611
2022-01-17 13:03:37,887 iteration 5729 : loss : 0.012533, loss_ce: 0.004507
 84%|████████████████████████▍    | 337/400 [1:37:47<17:33, 16.72s/it]2022-01-17 13:03:38,789 iteration 5730 : loss : 0.013843, loss_ce: 0.006443
2022-01-17 13:03:39,737 iteration 5731 : loss : 0.015410, loss_ce: 0.006952
2022-01-17 13:03:40,603 iteration 5732 : loss : 0.011191, loss_ce: 0.004310
2022-01-17 13:03:41,568 iteration 5733 : loss : 0.019050, loss_ce: 0.005687
2022-01-17 13:03:42,517 iteration 5734 : loss : 0.015910, loss_ce: 0.007330
2022-01-17 13:03:43,391 iteration 5735 : loss : 0.013244, loss_ce: 0.003915
2022-01-17 13:03:44,273 iteration 5736 : loss : 0.019286, loss_ce: 0.007302
2022-01-17 13:03:45,257 iteration 5737 : loss : 0.024379, loss_ce: 0.007671
2022-01-17 13:03:46,136 iteration 5738 : loss : 0.012054, loss_ce: 0.003923
2022-01-17 13:03:47,010 iteration 5739 : loss : 0.012809, loss_ce: 0.004472
2022-01-17 13:03:47,910 iteration 5740 : loss : 0.017704, loss_ce: 0.006467
2022-01-17 13:03:48,825 iteration 5741 : loss : 0.014409, loss_ce: 0.006655
2022-01-17 13:03:49,753 iteration 5742 : loss : 0.016859, loss_ce: 0.003127
2022-01-17 13:03:50,698 iteration 5743 : loss : 0.015561, loss_ce: 0.006631
2022-01-17 13:03:51,669 iteration 5744 : loss : 0.017817, loss_ce: 0.007818
2022-01-17 13:03:52,643 iteration 5745 : loss : 0.018875, loss_ce: 0.009517
2022-01-17 13:03:53,526 iteration 5746 : loss : 0.012851, loss_ce: 0.003160
 84%|████████████████████████▌    | 338/400 [1:38:03<16:56, 16.39s/it]2022-01-17 13:03:54,492 iteration 5747 : loss : 0.014968, loss_ce: 0.005515
2022-01-17 13:03:55,433 iteration 5748 : loss : 0.017438, loss_ce: 0.006861
2022-01-17 13:03:56,357 iteration 5749 : loss : 0.020630, loss_ce: 0.007517
2022-01-17 13:03:57,277 iteration 5750 : loss : 0.013652, loss_ce: 0.004818
2022-01-17 13:03:58,146 iteration 5751 : loss : 0.015982, loss_ce: 0.006424
2022-01-17 13:03:59,058 iteration 5752 : loss : 0.016999, loss_ce: 0.004994
2022-01-17 13:04:00,027 iteration 5753 : loss : 0.012703, loss_ce: 0.005068
2022-01-17 13:04:01,001 iteration 5754 : loss : 0.010856, loss_ce: 0.003213
2022-01-17 13:04:01,923 iteration 5755 : loss : 0.010369, loss_ce: 0.003329
2022-01-17 13:04:02,808 iteration 5756 : loss : 0.014060, loss_ce: 0.004943
2022-01-17 13:04:03,621 iteration 5757 : loss : 0.010382, loss_ce: 0.004105
2022-01-17 13:04:04,587 iteration 5758 : loss : 0.019254, loss_ce: 0.006996
2022-01-17 13:04:05,544 iteration 5759 : loss : 0.014085, loss_ce: 0.005976
2022-01-17 13:04:06,537 iteration 5760 : loss : 0.019987, loss_ce: 0.008312
2022-01-17 13:04:07,544 iteration 5761 : loss : 0.018280, loss_ce: 0.007083
2022-01-17 13:04:08,414 iteration 5762 : loss : 0.012170, loss_ce: 0.005345
2022-01-17 13:04:09,374 iteration 5763 : loss : 0.013470, loss_ce: 0.005588
 85%|████████████████████████▌    | 339/400 [1:38:19<16:29, 16.23s/it]2022-01-17 13:04:10,348 iteration 5764 : loss : 0.014247, loss_ce: 0.005037
2022-01-17 13:04:11,326 iteration 5765 : loss : 0.032052, loss_ce: 0.006322
2022-01-17 13:04:12,261 iteration 5766 : loss : 0.017045, loss_ce: 0.008634
2022-01-17 13:04:13,173 iteration 5767 : loss : 0.011829, loss_ce: 0.005756
2022-01-17 13:04:14,183 iteration 5768 : loss : 0.015370, loss_ce: 0.005700
2022-01-17 13:04:15,139 iteration 5769 : loss : 0.020546, loss_ce: 0.005624
2022-01-17 13:04:16,013 iteration 5770 : loss : 0.014519, loss_ce: 0.004923
2022-01-17 13:04:16,948 iteration 5771 : loss : 0.018929, loss_ce: 0.007527
2022-01-17 13:04:17,861 iteration 5772 : loss : 0.012484, loss_ce: 0.004029
2022-01-17 13:04:18,712 iteration 5773 : loss : 0.011314, loss_ce: 0.003500
2022-01-17 13:04:19,555 iteration 5774 : loss : 0.012542, loss_ce: 0.003305
2022-01-17 13:04:20,488 iteration 5775 : loss : 0.012750, loss_ce: 0.005126
2022-01-17 13:04:21,476 iteration 5776 : loss : 0.016740, loss_ce: 0.007666
2022-01-17 13:04:22,317 iteration 5777 : loss : 0.013537, loss_ce: 0.005541
2022-01-17 13:04:23,215 iteration 5778 : loss : 0.023138, loss_ce: 0.006779
2022-01-17 13:04:24,123 iteration 5779 : loss : 0.013111, loss_ce: 0.004071
2022-01-17 13:04:24,123 Training Data Eval:
2022-01-17 13:04:28,519   Average segmentation loss on training set: 0.0087
2022-01-17 13:04:28,550 Validation Data Eval:
2022-01-17 13:04:30,041   Average segmentation loss on validation set: 0.0759
2022-01-17 13:04:30,958 iteration 5780 : loss : 0.015654, loss_ce: 0.005144
 85%|████████████████████████▋    | 340/400 [1:38:40<17:50, 17.84s/it]2022-01-17 13:04:31,895 iteration 5781 : loss : 0.019572, loss_ce: 0.005468
2022-01-17 13:04:32,877 iteration 5782 : loss : 0.017968, loss_ce: 0.007485
2022-01-17 13:04:33,791 iteration 5783 : loss : 0.015804, loss_ce: 0.006169
2022-01-17 13:04:34,729 iteration 5784 : loss : 0.014497, loss_ce: 0.007333
2022-01-17 13:04:35,608 iteration 5785 : loss : 0.010498, loss_ce: 0.003517
2022-01-17 13:04:36,494 iteration 5786 : loss : 0.012056, loss_ce: 0.005120
2022-01-17 13:04:37,376 iteration 5787 : loss : 0.012187, loss_ce: 0.004578
2022-01-17 13:04:38,409 iteration 5788 : loss : 0.013274, loss_ce: 0.004895
2022-01-17 13:04:39,336 iteration 5789 : loss : 0.013684, loss_ce: 0.005282
2022-01-17 13:04:40,252 iteration 5790 : loss : 0.016689, loss_ce: 0.006179
2022-01-17 13:04:41,125 iteration 5791 : loss : 0.012482, loss_ce: 0.004424
2022-01-17 13:04:42,072 iteration 5792 : loss : 0.017128, loss_ce: 0.006239
2022-01-17 13:04:43,092 iteration 5793 : loss : 0.018237, loss_ce: 0.006006
2022-01-17 13:04:44,011 iteration 5794 : loss : 0.013415, loss_ce: 0.005531
2022-01-17 13:04:44,911 iteration 5795 : loss : 0.013456, loss_ce: 0.004403
2022-01-17 13:04:45,776 iteration 5796 : loss : 0.010643, loss_ce: 0.002860
2022-01-17 13:04:46,708 iteration 5797 : loss : 0.016638, loss_ce: 0.006182
 85%|████████████████████████▋    | 341/400 [1:38:56<16:55, 17.21s/it]2022-01-17 13:04:47,699 iteration 5798 : loss : 0.018831, loss_ce: 0.007714
2022-01-17 13:04:48,620 iteration 5799 : loss : 0.017249, loss_ce: 0.007102
2022-01-17 13:04:49,518 iteration 5800 : loss : 0.011776, loss_ce: 0.004842
2022-01-17 13:04:50,423 iteration 5801 : loss : 0.016418, loss_ce: 0.005354
2022-01-17 13:04:51,276 iteration 5802 : loss : 0.017874, loss_ce: 0.006146
2022-01-17 13:04:52,162 iteration 5803 : loss : 0.016376, loss_ce: 0.007372
2022-01-17 13:04:53,080 iteration 5804 : loss : 0.013794, loss_ce: 0.004663
2022-01-17 13:04:54,084 iteration 5805 : loss : 0.015828, loss_ce: 0.005307
2022-01-17 13:04:54,982 iteration 5806 : loss : 0.016576, loss_ce: 0.005135
2022-01-17 13:04:55,963 iteration 5807 : loss : 0.024309, loss_ce: 0.008497
2022-01-17 13:04:56,893 iteration 5808 : loss : 0.023512, loss_ce: 0.009726
2022-01-17 13:04:57,745 iteration 5809 : loss : 0.009214, loss_ce: 0.002283
2022-01-17 13:04:58,623 iteration 5810 : loss : 0.014598, loss_ce: 0.005187
2022-01-17 13:04:59,477 iteration 5811 : loss : 0.010454, loss_ce: 0.002846
2022-01-17 13:05:00,399 iteration 5812 : loss : 0.013662, loss_ce: 0.004568
2022-01-17 13:05:01,263 iteration 5813 : loss : 0.016238, loss_ce: 0.007551
2022-01-17 13:05:02,207 iteration 5814 : loss : 0.014945, loss_ce: 0.006322
 86%|████████████████████████▊    | 342/400 [1:39:12<16:08, 16.70s/it]2022-01-17 13:05:03,118 iteration 5815 : loss : 0.013844, loss_ce: 0.005238
2022-01-17 13:05:04,027 iteration 5816 : loss : 0.011190, loss_ce: 0.005089
2022-01-17 13:05:04,912 iteration 5817 : loss : 0.011519, loss_ce: 0.004010
2022-01-17 13:05:05,739 iteration 5818 : loss : 0.013550, loss_ce: 0.005158
2022-01-17 13:05:06,708 iteration 5819 : loss : 0.021821, loss_ce: 0.007152
2022-01-17 13:05:07,699 iteration 5820 : loss : 0.016040, loss_ce: 0.006526
2022-01-17 13:05:08,548 iteration 5821 : loss : 0.011779, loss_ce: 0.003621
2022-01-17 13:05:09,425 iteration 5822 : loss : 0.010217, loss_ce: 0.004345
2022-01-17 13:05:10,435 iteration 5823 : loss : 0.013968, loss_ce: 0.005663
2022-01-17 13:05:11,345 iteration 5824 : loss : 0.013921, loss_ce: 0.004317
2022-01-17 13:05:12,293 iteration 5825 : loss : 0.018161, loss_ce: 0.007397
2022-01-17 13:05:13,240 iteration 5826 : loss : 0.017107, loss_ce: 0.004190
2022-01-17 13:05:14,143 iteration 5827 : loss : 0.015759, loss_ce: 0.005056
2022-01-17 13:05:15,138 iteration 5828 : loss : 0.023372, loss_ce: 0.008288
2022-01-17 13:05:16,042 iteration 5829 : loss : 0.012631, loss_ce: 0.005075
2022-01-17 13:05:16,922 iteration 5830 : loss : 0.019294, loss_ce: 0.008250
2022-01-17 13:05:17,814 iteration 5831 : loss : 0.014309, loss_ce: 0.005403
 86%|████████████████████████▊    | 343/400 [1:39:27<15:32, 16.37s/it]2022-01-17 13:05:18,780 iteration 5832 : loss : 0.011505, loss_ce: 0.003221
2022-01-17 13:05:19,737 iteration 5833 : loss : 0.013592, loss_ce: 0.005482
2022-01-17 13:05:20,607 iteration 5834 : loss : 0.012437, loss_ce: 0.004313
2022-01-17 13:05:21,482 iteration 5835 : loss : 0.016624, loss_ce: 0.004815
2022-01-17 13:05:22,450 iteration 5836 : loss : 0.016662, loss_ce: 0.007699
2022-01-17 13:05:23,372 iteration 5837 : loss : 0.012852, loss_ce: 0.002727
2022-01-17 13:05:24,204 iteration 5838 : loss : 0.008992, loss_ce: 0.002550
2022-01-17 13:05:25,118 iteration 5839 : loss : 0.012862, loss_ce: 0.004197
2022-01-17 13:05:26,077 iteration 5840 : loss : 0.016372, loss_ce: 0.005793
2022-01-17 13:05:26,973 iteration 5841 : loss : 0.015206, loss_ce: 0.006066
2022-01-17 13:05:27,861 iteration 5842 : loss : 0.008626, loss_ce: 0.003163
2022-01-17 13:05:28,740 iteration 5843 : loss : 0.013443, loss_ce: 0.005594
2022-01-17 13:05:29,771 iteration 5844 : loss : 0.019266, loss_ce: 0.005207
2022-01-17 13:05:30,672 iteration 5845 : loss : 0.021783, loss_ce: 0.009315
2022-01-17 13:05:31,588 iteration 5846 : loss : 0.019978, loss_ce: 0.008101
2022-01-17 13:05:32,518 iteration 5847 : loss : 0.015775, loss_ce: 0.006100
2022-01-17 13:05:33,429 iteration 5848 : loss : 0.014416, loss_ce: 0.004841
 86%|████████████████████████▉    | 344/400 [1:39:43<15:04, 16.14s/it]2022-01-17 13:05:34,389 iteration 5849 : loss : 0.015234, loss_ce: 0.006286
2022-01-17 13:05:35,241 iteration 5850 : loss : 0.011030, loss_ce: 0.004592
2022-01-17 13:05:36,150 iteration 5851 : loss : 0.016274, loss_ce: 0.007038
2022-01-17 13:05:37,035 iteration 5852 : loss : 0.014307, loss_ce: 0.005177
2022-01-17 13:05:37,878 iteration 5853 : loss : 0.010408, loss_ce: 0.003317
2022-01-17 13:05:38,775 iteration 5854 : loss : 0.016723, loss_ce: 0.005551
2022-01-17 13:05:39,760 iteration 5855 : loss : 0.017700, loss_ce: 0.008219
2022-01-17 13:05:40,680 iteration 5856 : loss : 0.012808, loss_ce: 0.005350
2022-01-17 13:05:41,604 iteration 5857 : loss : 0.014880, loss_ce: 0.005214
2022-01-17 13:05:42,447 iteration 5858 : loss : 0.012292, loss_ce: 0.004784
2022-01-17 13:05:43,401 iteration 5859 : loss : 0.016860, loss_ce: 0.005687
2022-01-17 13:05:44,352 iteration 5860 : loss : 0.012319, loss_ce: 0.003202
2022-01-17 13:05:45,240 iteration 5861 : loss : 0.016589, loss_ce: 0.004665
2022-01-17 13:05:46,175 iteration 5862 : loss : 0.016113, loss_ce: 0.008481
2022-01-17 13:05:47,007 iteration 5863 : loss : 0.008674, loss_ce: 0.002773
2022-01-17 13:05:47,931 iteration 5864 : loss : 0.018881, loss_ce: 0.006397
2022-01-17 13:05:47,931 Training Data Eval:
2022-01-17 13:05:52,337   Average segmentation loss on training set: 0.0082
2022-01-17 13:05:52,337 Validation Data Eval:
2022-01-17 13:05:53,827   Average segmentation loss on validation set: 0.0808
2022-01-17 13:05:54,695 iteration 5865 : loss : 0.017247, loss_ce: 0.005155
 86%|█████████████████████████    | 345/400 [1:40:04<16:12, 17.68s/it]2022-01-17 13:05:55,728 iteration 5866 : loss : 0.013147, loss_ce: 0.005519
2022-01-17 13:05:56,690 iteration 5867 : loss : 0.013227, loss_ce: 0.004046
2022-01-17 13:05:57,636 iteration 5868 : loss : 0.014935, loss_ce: 0.005323
2022-01-17 13:05:58,471 iteration 5869 : loss : 0.020989, loss_ce: 0.008049
2022-01-17 13:05:59,455 iteration 5870 : loss : 0.020887, loss_ce: 0.005730
2022-01-17 13:06:00,390 iteration 5871 : loss : 0.012411, loss_ce: 0.004209
2022-01-17 13:06:01,332 iteration 5872 : loss : 0.018515, loss_ce: 0.006142
2022-01-17 13:06:02,351 iteration 5873 : loss : 0.026022, loss_ce: 0.009224
2022-01-17 13:06:03,214 iteration 5874 : loss : 0.012800, loss_ce: 0.004220
2022-01-17 13:06:04,095 iteration 5875 : loss : 0.012607, loss_ce: 0.006074
2022-01-17 13:06:05,014 iteration 5876 : loss : 0.016069, loss_ce: 0.005675
2022-01-17 13:06:05,934 iteration 5877 : loss : 0.014776, loss_ce: 0.005219
2022-01-17 13:06:06,878 iteration 5878 : loss : 0.013925, loss_ce: 0.006137
2022-01-17 13:06:07,759 iteration 5879 : loss : 0.012734, loss_ce: 0.005619
2022-01-17 13:06:08,779 iteration 5880 : loss : 0.016393, loss_ce: 0.004007
2022-01-17 13:06:09,649 iteration 5881 : loss : 0.010652, loss_ce: 0.003779
2022-01-17 13:06:10,557 iteration 5882 : loss : 0.012383, loss_ce: 0.005365
 86%|█████████████████████████    | 346/400 [1:40:20<15:25, 17.14s/it]2022-01-17 13:06:11,493 iteration 5883 : loss : 0.011082, loss_ce: 0.003573
2022-01-17 13:06:12,381 iteration 5884 : loss : 0.014007, loss_ce: 0.006354
2022-01-17 13:06:13,411 iteration 5885 : loss : 0.020276, loss_ce: 0.006955
2022-01-17 13:06:14,273 iteration 5886 : loss : 0.015278, loss_ce: 0.005589
2022-01-17 13:06:15,165 iteration 5887 : loss : 0.011787, loss_ce: 0.004895
2022-01-17 13:06:16,159 iteration 5888 : loss : 0.013948, loss_ce: 0.004179
2022-01-17 13:06:17,148 iteration 5889 : loss : 0.016971, loss_ce: 0.006449
2022-01-17 13:06:18,075 iteration 5890 : loss : 0.011271, loss_ce: 0.003633
2022-01-17 13:06:19,043 iteration 5891 : loss : 0.022523, loss_ce: 0.007782
2022-01-17 13:06:20,049 iteration 5892 : loss : 0.016959, loss_ce: 0.006979
2022-01-17 13:06:20,929 iteration 5893 : loss : 0.011334, loss_ce: 0.003558
2022-01-17 13:06:21,917 iteration 5894 : loss : 0.014019, loss_ce: 0.005457
2022-01-17 13:06:22,859 iteration 5895 : loss : 0.021310, loss_ce: 0.007777
2022-01-17 13:06:23,757 iteration 5896 : loss : 0.012682, loss_ce: 0.005373
2022-01-17 13:06:24,731 iteration 5897 : loss : 0.025589, loss_ce: 0.009144
2022-01-17 13:06:25,684 iteration 5898 : loss : 0.010704, loss_ce: 0.003532
2022-01-17 13:06:26,571 iteration 5899 : loss : 0.018069, loss_ce: 0.006766
 87%|█████████████████████████▏   | 347/400 [1:40:36<14:50, 16.80s/it]2022-01-17 13:06:27,541 iteration 5900 : loss : 0.013186, loss_ce: 0.004369
2022-01-17 13:06:28,520 iteration 5901 : loss : 0.017286, loss_ce: 0.005738
2022-01-17 13:06:29,432 iteration 5902 : loss : 0.015795, loss_ce: 0.005760
2022-01-17 13:06:30,408 iteration 5903 : loss : 0.013779, loss_ce: 0.006920
2022-01-17 13:06:31,306 iteration 5904 : loss : 0.017483, loss_ce: 0.006150
2022-01-17 13:06:32,269 iteration 5905 : loss : 0.020511, loss_ce: 0.006163
2022-01-17 13:06:33,137 iteration 5906 : loss : 0.015558, loss_ce: 0.005825
2022-01-17 13:06:34,085 iteration 5907 : loss : 0.009305, loss_ce: 0.003179
2022-01-17 13:06:35,007 iteration 5908 : loss : 0.015434, loss_ce: 0.006562
2022-01-17 13:06:35,836 iteration 5909 : loss : 0.014644, loss_ce: 0.003593
2022-01-17 13:06:36,764 iteration 5910 : loss : 0.017380, loss_ce: 0.006298
2022-01-17 13:06:37,726 iteration 5911 : loss : 0.023895, loss_ce: 0.009017
2022-01-17 13:06:38,591 iteration 5912 : loss : 0.014430, loss_ce: 0.004677
2022-01-17 13:06:39,488 iteration 5913 : loss : 0.013791, loss_ce: 0.006134
2022-01-17 13:06:40,417 iteration 5914 : loss : 0.015483, loss_ce: 0.005629
2022-01-17 13:06:41,259 iteration 5915 : loss : 0.014572, loss_ce: 0.005284
2022-01-17 13:06:42,217 iteration 5916 : loss : 0.028507, loss_ce: 0.009522
 87%|█████████████████████████▏   | 348/400 [1:40:52<14:15, 16.45s/it]2022-01-17 13:06:43,151 iteration 5917 : loss : 0.013015, loss_ce: 0.005517
2022-01-17 13:06:44,014 iteration 5918 : loss : 0.013795, loss_ce: 0.005230
2022-01-17 13:06:44,972 iteration 5919 : loss : 0.016990, loss_ce: 0.008111
2022-01-17 13:06:45,941 iteration 5920 : loss : 0.015317, loss_ce: 0.007337
2022-01-17 13:06:46,993 iteration 5921 : loss : 0.020730, loss_ce: 0.005882
2022-01-17 13:06:47,886 iteration 5922 : loss : 0.012854, loss_ce: 0.003301
2022-01-17 13:06:48,816 iteration 5923 : loss : 0.017705, loss_ce: 0.005588
2022-01-17 13:06:49,828 iteration 5924 : loss : 0.021398, loss_ce: 0.004450
2022-01-17 13:06:50,752 iteration 5925 : loss : 0.017127, loss_ce: 0.005556
2022-01-17 13:06:51,664 iteration 5926 : loss : 0.013811, loss_ce: 0.005439
2022-01-17 13:06:52,601 iteration 5927 : loss : 0.013408, loss_ce: 0.005339
2022-01-17 13:06:53,463 iteration 5928 : loss : 0.013041, loss_ce: 0.003294
2022-01-17 13:06:54,334 iteration 5929 : loss : 0.011043, loss_ce: 0.004917
2022-01-17 13:06:55,214 iteration 5930 : loss : 0.014437, loss_ce: 0.006275
2022-01-17 13:06:56,148 iteration 5931 : loss : 0.025797, loss_ce: 0.007999
2022-01-17 13:06:57,115 iteration 5932 : loss : 0.015402, loss_ce: 0.005110
2022-01-17 13:06:58,024 iteration 5933 : loss : 0.016830, loss_ce: 0.006424
 87%|█████████████████████████▎   | 349/400 [1:41:07<13:49, 16.26s/it]2022-01-17 13:06:58,946 iteration 5934 : loss : 0.012274, loss_ce: 0.004189
2022-01-17 13:06:59,981 iteration 5935 : loss : 0.016922, loss_ce: 0.005830
2022-01-17 13:07:00,892 iteration 5936 : loss : 0.011780, loss_ce: 0.004545
2022-01-17 13:07:01,771 iteration 5937 : loss : 0.026047, loss_ce: 0.007642
2022-01-17 13:07:02,607 iteration 5938 : loss : 0.011480, loss_ce: 0.004163
2022-01-17 13:07:03,548 iteration 5939 : loss : 0.013447, loss_ce: 0.005335
2022-01-17 13:07:04,408 iteration 5940 : loss : 0.011961, loss_ce: 0.004590
2022-01-17 13:07:05,284 iteration 5941 : loss : 0.016971, loss_ce: 0.007268
2022-01-17 13:07:06,170 iteration 5942 : loss : 0.010791, loss_ce: 0.004226
2022-01-17 13:07:07,096 iteration 5943 : loss : 0.014979, loss_ce: 0.004092
2022-01-17 13:07:08,019 iteration 5944 : loss : 0.014991, loss_ce: 0.006923
2022-01-17 13:07:08,904 iteration 5945 : loss : 0.013220, loss_ce: 0.002812
2022-01-17 13:07:09,905 iteration 5946 : loss : 0.015309, loss_ce: 0.005905
2022-01-17 13:07:10,851 iteration 5947 : loss : 0.016027, loss_ce: 0.005991
2022-01-17 13:07:11,747 iteration 5948 : loss : 0.012922, loss_ce: 0.005221
2022-01-17 13:07:12,731 iteration 5949 : loss : 0.014992, loss_ce: 0.005180
2022-01-17 13:07:12,731 Training Data Eval:
2022-01-17 13:07:17,123   Average segmentation loss on training set: 0.0085
2022-01-17 13:07:17,123 Validation Data Eval:
2022-01-17 13:07:18,620   Average segmentation loss on validation set: 0.0874
2022-01-17 13:07:19,564 iteration 5950 : loss : 0.012423, loss_ce: 0.004041
 88%|█████████████████████████▍   | 350/400 [1:41:29<14:52, 17.85s/it]2022-01-17 13:07:20,490 iteration 5951 : loss : 0.013692, loss_ce: 0.004982
2022-01-17 13:07:21,417 iteration 5952 : loss : 0.013708, loss_ce: 0.004471
2022-01-17 13:07:22,340 iteration 5953 : loss : 0.019450, loss_ce: 0.008568
2022-01-17 13:07:23,234 iteration 5954 : loss : 0.015850, loss_ce: 0.005084
2022-01-17 13:07:24,152 iteration 5955 : loss : 0.014671, loss_ce: 0.004522
2022-01-17 13:07:25,091 iteration 5956 : loss : 0.019713, loss_ce: 0.009864
2022-01-17 13:07:26,015 iteration 5957 : loss : 0.011466, loss_ce: 0.004328
2022-01-17 13:07:26,892 iteration 5958 : loss : 0.012022, loss_ce: 0.004324
2022-01-17 13:07:27,806 iteration 5959 : loss : 0.013012, loss_ce: 0.005273
2022-01-17 13:07:28,683 iteration 5960 : loss : 0.012868, loss_ce: 0.003849
2022-01-17 13:07:29,562 iteration 5961 : loss : 0.020879, loss_ce: 0.004325
2022-01-17 13:07:30,477 iteration 5962 : loss : 0.021700, loss_ce: 0.004164
2022-01-17 13:07:31,424 iteration 5963 : loss : 0.016228, loss_ce: 0.006445
2022-01-17 13:07:32,315 iteration 5964 : loss : 0.009898, loss_ce: 0.004321
2022-01-17 13:07:33,178 iteration 5965 : loss : 0.011517, loss_ce: 0.005150
2022-01-17 13:07:34,147 iteration 5966 : loss : 0.015237, loss_ce: 0.004226
2022-01-17 13:07:35,079 iteration 5967 : loss : 0.014687, loss_ce: 0.006252
 88%|█████████████████████████▍   | 351/400 [1:41:44<14:00, 17.14s/it]2022-01-17 13:07:36,107 iteration 5968 : loss : 0.026583, loss_ce: 0.008966
2022-01-17 13:07:36,997 iteration 5969 : loss : 0.015824, loss_ce: 0.007013
2022-01-17 13:07:37,939 iteration 5970 : loss : 0.016499, loss_ce: 0.006301
2022-01-17 13:07:38,784 iteration 5971 : loss : 0.011590, loss_ce: 0.003502
2022-01-17 13:07:39,610 iteration 5972 : loss : 0.010866, loss_ce: 0.003351
2022-01-17 13:07:40,530 iteration 5973 : loss : 0.015067, loss_ce: 0.007140
2022-01-17 13:07:41,542 iteration 5974 : loss : 0.026878, loss_ce: 0.010094
2022-01-17 13:07:42,413 iteration 5975 : loss : 0.016148, loss_ce: 0.005639
2022-01-17 13:07:43,307 iteration 5976 : loss : 0.015975, loss_ce: 0.004359
2022-01-17 13:07:44,181 iteration 5977 : loss : 0.012932, loss_ce: 0.003368
2022-01-17 13:07:45,050 iteration 5978 : loss : 0.013427, loss_ce: 0.006092
2022-01-17 13:07:45,967 iteration 5979 : loss : 0.010608, loss_ce: 0.004889
2022-01-17 13:07:46,924 iteration 5980 : loss : 0.012595, loss_ce: 0.004608
2022-01-17 13:07:47,799 iteration 5981 : loss : 0.014385, loss_ce: 0.006378
2022-01-17 13:07:48,714 iteration 5982 : loss : 0.016228, loss_ce: 0.006275
2022-01-17 13:07:49,688 iteration 5983 : loss : 0.014048, loss_ce: 0.003922
2022-01-17 13:07:50,574 iteration 5984 : loss : 0.014374, loss_ce: 0.005105
 88%|█████████████████████████▌   | 352/400 [1:42:00<13:19, 16.65s/it]2022-01-17 13:07:51,533 iteration 5985 : loss : 0.010934, loss_ce: 0.002947
2022-01-17 13:07:52,365 iteration 5986 : loss : 0.022185, loss_ce: 0.006384
2022-01-17 13:07:53,299 iteration 5987 : loss : 0.015075, loss_ce: 0.006264
2022-01-17 13:07:54,291 iteration 5988 : loss : 0.018128, loss_ce: 0.006569
2022-01-17 13:07:55,218 iteration 5989 : loss : 0.013809, loss_ce: 0.005253
2022-01-17 13:07:56,107 iteration 5990 : loss : 0.015763, loss_ce: 0.005577
2022-01-17 13:07:57,036 iteration 5991 : loss : 0.015624, loss_ce: 0.005046
2022-01-17 13:07:57,960 iteration 5992 : loss : 0.016621, loss_ce: 0.006915
2022-01-17 13:07:58,861 iteration 5993 : loss : 0.011544, loss_ce: 0.004799
2022-01-17 13:07:59,811 iteration 5994 : loss : 0.015564, loss_ce: 0.006750
2022-01-17 13:08:00,703 iteration 5995 : loss : 0.013518, loss_ce: 0.005538
2022-01-17 13:08:01,568 iteration 5996 : loss : 0.010813, loss_ce: 0.003014
2022-01-17 13:08:02,492 iteration 5997 : loss : 0.026381, loss_ce: 0.010497
2022-01-17 13:08:03,470 iteration 5998 : loss : 0.014509, loss_ce: 0.005383
2022-01-17 13:08:04,476 iteration 5999 : loss : 0.017753, loss_ce: 0.006442
2022-01-17 13:08:05,403 iteration 6000 : loss : 0.014268, loss_ce: 0.005859
2022-01-17 13:08:06,242 iteration 6001 : loss : 0.013557, loss_ce: 0.006438
 88%|█████████████████████████▌   | 353/400 [1:42:16<12:48, 16.35s/it]2022-01-17 13:08:07,213 iteration 6002 : loss : 0.013983, loss_ce: 0.005256
2022-01-17 13:08:08,094 iteration 6003 : loss : 0.012056, loss_ce: 0.004354
2022-01-17 13:08:09,052 iteration 6004 : loss : 0.016361, loss_ce: 0.006658
2022-01-17 13:08:10,001 iteration 6005 : loss : 0.020180, loss_ce: 0.006301
2022-01-17 13:08:11,020 iteration 6006 : loss : 0.014261, loss_ce: 0.005868
2022-01-17 13:08:11,953 iteration 6007 : loss : 0.011819, loss_ce: 0.005198
2022-01-17 13:08:12,874 iteration 6008 : loss : 0.016377, loss_ce: 0.005529
2022-01-17 13:08:13,714 iteration 6009 : loss : 0.012781, loss_ce: 0.005913
2022-01-17 13:08:14,575 iteration 6010 : loss : 0.011580, loss_ce: 0.004731
2022-01-17 13:08:15,530 iteration 6011 : loss : 0.015810, loss_ce: 0.005570
2022-01-17 13:08:16,509 iteration 6012 : loss : 0.014084, loss_ce: 0.002839
2022-01-17 13:08:17,461 iteration 6013 : loss : 0.016656, loss_ce: 0.005201
2022-01-17 13:08:18,398 iteration 6014 : loss : 0.014659, loss_ce: 0.003918
2022-01-17 13:08:19,275 iteration 6015 : loss : 0.027486, loss_ce: 0.010608
2022-01-17 13:08:20,186 iteration 6016 : loss : 0.013131, loss_ce: 0.004835
2022-01-17 13:08:21,093 iteration 6017 : loss : 0.012075, loss_ce: 0.005523
2022-01-17 13:08:22,030 iteration 6018 : loss : 0.020310, loss_ce: 0.006046
 88%|█████████████████████████▋   | 354/400 [1:42:31<12:24, 16.18s/it]2022-01-17 13:08:23,000 iteration 6019 : loss : 0.014815, loss_ce: 0.007052
2022-01-17 13:08:23,897 iteration 6020 : loss : 0.010481, loss_ce: 0.004612
2022-01-17 13:08:24,824 iteration 6021 : loss : 0.014530, loss_ce: 0.003548
2022-01-17 13:08:25,685 iteration 6022 : loss : 0.014762, loss_ce: 0.007118
2022-01-17 13:08:26,636 iteration 6023 : loss : 0.013507, loss_ce: 0.005077
2022-01-17 13:08:27,535 iteration 6024 : loss : 0.014397, loss_ce: 0.004538
2022-01-17 13:08:28,429 iteration 6025 : loss : 0.015499, loss_ce: 0.006473
2022-01-17 13:08:29,372 iteration 6026 : loss : 0.021842, loss_ce: 0.008031
2022-01-17 13:08:30,310 iteration 6027 : loss : 0.013666, loss_ce: 0.004813
2022-01-17 13:08:31,269 iteration 6028 : loss : 0.017139, loss_ce: 0.008532
2022-01-17 13:08:32,173 iteration 6029 : loss : 0.016314, loss_ce: 0.004336
2022-01-17 13:08:33,024 iteration 6030 : loss : 0.011253, loss_ce: 0.005071
2022-01-17 13:08:33,961 iteration 6031 : loss : 0.014212, loss_ce: 0.006813
2022-01-17 13:08:34,831 iteration 6032 : loss : 0.014845, loss_ce: 0.004219
2022-01-17 13:08:35,793 iteration 6033 : loss : 0.015350, loss_ce: 0.005020
2022-01-17 13:08:36,711 iteration 6034 : loss : 0.012953, loss_ce: 0.005273
2022-01-17 13:08:36,711 Training Data Eval:
2022-01-17 13:08:41,102   Average segmentation loss on training set: 0.0082
2022-01-17 13:08:41,103 Validation Data Eval:
2022-01-17 13:08:42,594   Average segmentation loss on validation set: 0.0718
2022-01-17 13:08:43,415 iteration 6035 : loss : 0.009722, loss_ce: 0.003774
 89%|█████████████████████████▋   | 355/400 [1:42:53<13:18, 17.75s/it]2022-01-17 13:08:44,465 iteration 6036 : loss : 0.018994, loss_ce: 0.005588
2022-01-17 13:08:45,421 iteration 6037 : loss : 0.014435, loss_ce: 0.004486
2022-01-17 13:08:46,323 iteration 6038 : loss : 0.013683, loss_ce: 0.005162
2022-01-17 13:08:47,208 iteration 6039 : loss : 0.014037, loss_ce: 0.004566
2022-01-17 13:08:48,132 iteration 6040 : loss : 0.017885, loss_ce: 0.006679
2022-01-17 13:08:49,012 iteration 6041 : loss : 0.011875, loss_ce: 0.003967
2022-01-17 13:08:49,950 iteration 6042 : loss : 0.012647, loss_ce: 0.005779
2022-01-17 13:08:50,822 iteration 6043 : loss : 0.011640, loss_ce: 0.005346
2022-01-17 13:08:51,681 iteration 6044 : loss : 0.010447, loss_ce: 0.004482
2022-01-17 13:08:52,659 iteration 6045 : loss : 0.014254, loss_ce: 0.005775
2022-01-17 13:08:53,517 iteration 6046 : loss : 0.016419, loss_ce: 0.006908
2022-01-17 13:08:54,386 iteration 6047 : loss : 0.010649, loss_ce: 0.004486
2022-01-17 13:08:55,371 iteration 6048 : loss : 0.016956, loss_ce: 0.005003
2022-01-17 13:08:56,226 iteration 6049 : loss : 0.013685, loss_ce: 0.004453
2022-01-17 13:08:57,077 iteration 6050 : loss : 0.014459, loss_ce: 0.003708
2022-01-17 13:08:57,930 iteration 6051 : loss : 0.010199, loss_ce: 0.004321
2022-01-17 13:08:58,872 iteration 6052 : loss : 0.014728, loss_ce: 0.005354
 89%|█████████████████████████▊   | 356/400 [1:43:08<12:30, 17.06s/it]2022-01-17 13:08:59,804 iteration 6053 : loss : 0.013158, loss_ce: 0.003726
2022-01-17 13:09:00,681 iteration 6054 : loss : 0.014791, loss_ce: 0.005149
2022-01-17 13:09:01,615 iteration 6055 : loss : 0.015820, loss_ce: 0.006515
2022-01-17 13:09:02,504 iteration 6056 : loss : 0.012310, loss_ce: 0.004119
2022-01-17 13:09:03,330 iteration 6057 : loss : 0.014294, loss_ce: 0.005715
2022-01-17 13:09:04,190 iteration 6058 : loss : 0.010853, loss_ce: 0.005545
2022-01-17 13:09:05,156 iteration 6059 : loss : 0.014104, loss_ce: 0.003606
2022-01-17 13:09:06,080 iteration 6060 : loss : 0.011331, loss_ce: 0.003484
2022-01-17 13:09:06,946 iteration 6061 : loss : 0.013262, loss_ce: 0.006753
2022-01-17 13:09:07,974 iteration 6062 : loss : 0.024094, loss_ce: 0.008804
2022-01-17 13:09:08,838 iteration 6063 : loss : 0.012998, loss_ce: 0.005753
2022-01-17 13:09:09,719 iteration 6064 : loss : 0.011155, loss_ce: 0.003585
2022-01-17 13:09:10,657 iteration 6065 : loss : 0.023370, loss_ce: 0.008940
2022-01-17 13:09:11,510 iteration 6066 : loss : 0.011664, loss_ce: 0.004582
2022-01-17 13:09:12,450 iteration 6067 : loss : 0.020999, loss_ce: 0.006928
2022-01-17 13:09:13,362 iteration 6068 : loss : 0.012203, loss_ce: 0.002012
2022-01-17 13:09:14,353 iteration 6069 : loss : 0.016086, loss_ce: 0.007565
 89%|█████████████████████████▉   | 357/400 [1:43:24<11:53, 16.59s/it]2022-01-17 13:09:15,323 iteration 6070 : loss : 0.014694, loss_ce: 0.006574
2022-01-17 13:09:16,237 iteration 6071 : loss : 0.012850, loss_ce: 0.005213
2022-01-17 13:09:17,138 iteration 6072 : loss : 0.014214, loss_ce: 0.005025
2022-01-17 13:09:18,052 iteration 6073 : loss : 0.027073, loss_ce: 0.008730
2022-01-17 13:09:18,878 iteration 6074 : loss : 0.013007, loss_ce: 0.005692
2022-01-17 13:09:19,823 iteration 6075 : loss : 0.015251, loss_ce: 0.006172
2022-01-17 13:09:20,736 iteration 6076 : loss : 0.012480, loss_ce: 0.005313
2022-01-17 13:09:21,544 iteration 6077 : loss : 0.010206, loss_ce: 0.003562
2022-01-17 13:09:22,447 iteration 6078 : loss : 0.014532, loss_ce: 0.007492
2022-01-17 13:09:23,422 iteration 6079 : loss : 0.014830, loss_ce: 0.006408
2022-01-17 13:09:24,271 iteration 6080 : loss : 0.011352, loss_ce: 0.003957
2022-01-17 13:09:25,258 iteration 6081 : loss : 0.016591, loss_ce: 0.006787
2022-01-17 13:09:26,170 iteration 6082 : loss : 0.012969, loss_ce: 0.003086
2022-01-17 13:09:27,121 iteration 6083 : loss : 0.012876, loss_ce: 0.003592
2022-01-17 13:09:27,992 iteration 6084 : loss : 0.015340, loss_ce: 0.004103
2022-01-17 13:09:28,859 iteration 6085 : loss : 0.014356, loss_ce: 0.005241
2022-01-17 13:09:29,909 iteration 6086 : loss : 0.020713, loss_ce: 0.005139
 90%|█████████████████████████▉   | 358/400 [1:43:39<11:23, 16.28s/it]2022-01-17 13:09:30,794 iteration 6087 : loss : 0.011924, loss_ce: 0.004815
2022-01-17 13:09:31,701 iteration 6088 : loss : 0.014020, loss_ce: 0.005797
2022-01-17 13:09:32,583 iteration 6089 : loss : 0.017101, loss_ce: 0.008127
2022-01-17 13:09:33,475 iteration 6090 : loss : 0.013029, loss_ce: 0.003483
2022-01-17 13:09:34,377 iteration 6091 : loss : 0.014237, loss_ce: 0.007226
2022-01-17 13:09:35,284 iteration 6092 : loss : 0.009730, loss_ce: 0.003675
2022-01-17 13:09:36,113 iteration 6093 : loss : 0.013004, loss_ce: 0.004079
2022-01-17 13:09:36,968 iteration 6094 : loss : 0.012657, loss_ce: 0.003914
2022-01-17 13:09:37,900 iteration 6095 : loss : 0.013848, loss_ce: 0.005697
2022-01-17 13:09:38,843 iteration 6096 : loss : 0.013776, loss_ce: 0.003891
2022-01-17 13:09:39,697 iteration 6097 : loss : 0.011446, loss_ce: 0.005162
2022-01-17 13:09:40,626 iteration 6098 : loss : 0.020027, loss_ce: 0.007419
2022-01-17 13:09:41,584 iteration 6099 : loss : 0.017145, loss_ce: 0.003866
2022-01-17 13:09:42,572 iteration 6100 : loss : 0.016933, loss_ce: 0.005556
2022-01-17 13:09:43,527 iteration 6101 : loss : 0.013800, loss_ce: 0.004751
2022-01-17 13:09:44,396 iteration 6102 : loss : 0.014934, loss_ce: 0.005343
2022-01-17 13:09:45,196 iteration 6103 : loss : 0.008366, loss_ce: 0.002982
 90%|██████████████████████████   | 359/400 [1:43:55<10:55, 15.98s/it]2022-01-17 13:09:46,181 iteration 6104 : loss : 0.021387, loss_ce: 0.006933
2022-01-17 13:09:47,033 iteration 6105 : loss : 0.013908, loss_ce: 0.004432
2022-01-17 13:09:47,859 iteration 6106 : loss : 0.018013, loss_ce: 0.007112
2022-01-17 13:09:48,720 iteration 6107 : loss : 0.011711, loss_ce: 0.003738
2022-01-17 13:09:49,677 iteration 6108 : loss : 0.013309, loss_ce: 0.004091
2022-01-17 13:09:50,569 iteration 6109 : loss : 0.012067, loss_ce: 0.004056
2022-01-17 13:09:51,500 iteration 6110 : loss : 0.013541, loss_ce: 0.006101
2022-01-17 13:09:52,464 iteration 6111 : loss : 0.016126, loss_ce: 0.006289
2022-01-17 13:09:53,402 iteration 6112 : loss : 0.012187, loss_ce: 0.004478
2022-01-17 13:09:54,365 iteration 6113 : loss : 0.016290, loss_ce: 0.005154
2022-01-17 13:09:55,253 iteration 6114 : loss : 0.012661, loss_ce: 0.005191
2022-01-17 13:09:56,229 iteration 6115 : loss : 0.018652, loss_ce: 0.006395
2022-01-17 13:09:57,158 iteration 6116 : loss : 0.014733, loss_ce: 0.006499
2022-01-17 13:09:58,034 iteration 6117 : loss : 0.016964, loss_ce: 0.006794
2022-01-17 13:09:58,982 iteration 6118 : loss : 0.014776, loss_ce: 0.006381
2022-01-17 13:09:59,885 iteration 6119 : loss : 0.017043, loss_ce: 0.004870
2022-01-17 13:09:59,885 Training Data Eval:
2022-01-17 13:10:04,280   Average segmentation loss on training set: 0.0082
2022-01-17 13:10:04,280 Validation Data Eval:
2022-01-17 13:10:05,772   Average segmentation loss on validation set: 0.0850
2022-01-17 13:10:06,680 iteration 6120 : loss : 0.014199, loss_ce: 0.005221
 90%|██████████████████████████   | 360/400 [1:44:16<11:45, 17.63s/it]2022-01-17 13:10:07,665 iteration 6121 : loss : 0.015954, loss_ce: 0.007426
2022-01-17 13:10:08,619 iteration 6122 : loss : 0.029152, loss_ce: 0.011059
2022-01-17 13:10:09,606 iteration 6123 : loss : 0.018453, loss_ce: 0.006952
2022-01-17 13:10:10,525 iteration 6124 : loss : 0.013592, loss_ce: 0.004020
2022-01-17 13:10:11,521 iteration 6125 : loss : 0.018512, loss_ce: 0.006378
2022-01-17 13:10:12,413 iteration 6126 : loss : 0.021056, loss_ce: 0.003870
2022-01-17 13:10:13,291 iteration 6127 : loss : 0.013396, loss_ce: 0.004842
2022-01-17 13:10:14,262 iteration 6128 : loss : 0.014875, loss_ce: 0.004602
2022-01-17 13:10:15,175 iteration 6129 : loss : 0.012527, loss_ce: 0.005242
2022-01-17 13:10:16,173 iteration 6130 : loss : 0.019896, loss_ce: 0.005334
2022-01-17 13:10:17,109 iteration 6131 : loss : 0.015288, loss_ce: 0.008304
2022-01-17 13:10:18,035 iteration 6132 : loss : 0.025523, loss_ce: 0.004649
2022-01-17 13:10:18,916 iteration 6133 : loss : 0.010361, loss_ce: 0.004995
2022-01-17 13:10:19,762 iteration 6134 : loss : 0.009417, loss_ce: 0.003998
2022-01-17 13:10:20,618 iteration 6135 : loss : 0.010009, loss_ce: 0.003664
2022-01-17 13:10:21,548 iteration 6136 : loss : 0.012264, loss_ce: 0.003628
2022-01-17 13:10:22,442 iteration 6137 : loss : 0.012091, loss_ce: 0.004421
 90%|██████████████████████████▏  | 361/400 [1:44:32<11:05, 17.07s/it]2022-01-17 13:10:23,359 iteration 6138 : loss : 0.010980, loss_ce: 0.003594
2022-01-17 13:10:24,312 iteration 6139 : loss : 0.013388, loss_ce: 0.005325
2022-01-17 13:10:25,221 iteration 6140 : loss : 0.011783, loss_ce: 0.004022
2022-01-17 13:10:26,170 iteration 6141 : loss : 0.012537, loss_ce: 0.004651
2022-01-17 13:10:27,224 iteration 6142 : loss : 0.018914, loss_ce: 0.006900
2022-01-17 13:10:28,072 iteration 6143 : loss : 0.012879, loss_ce: 0.006103
2022-01-17 13:10:28,998 iteration 6144 : loss : 0.012413, loss_ce: 0.005748
2022-01-17 13:10:29,928 iteration 6145 : loss : 0.014303, loss_ce: 0.005484
2022-01-17 13:10:30,836 iteration 6146 : loss : 0.013383, loss_ce: 0.006111
2022-01-17 13:10:31,744 iteration 6147 : loss : 0.012936, loss_ce: 0.003149
2022-01-17 13:10:32,611 iteration 6148 : loss : 0.011009, loss_ce: 0.003639
2022-01-17 13:10:33,478 iteration 6149 : loss : 0.016632, loss_ce: 0.005727
2022-01-17 13:10:34,361 iteration 6150 : loss : 0.017408, loss_ce: 0.005339
2022-01-17 13:10:35,261 iteration 6151 : loss : 0.013688, loss_ce: 0.003064
2022-01-17 13:10:36,130 iteration 6152 : loss : 0.014954, loss_ce: 0.005783
2022-01-17 13:10:37,098 iteration 6153 : loss : 0.015269, loss_ce: 0.006532
2022-01-17 13:10:38,093 iteration 6154 : loss : 0.021313, loss_ce: 0.010183
 90%|██████████████████████████▏  | 362/400 [1:44:47<10:32, 16.64s/it]2022-01-17 13:10:39,018 iteration 6155 : loss : 0.014339, loss_ce: 0.005998
2022-01-17 13:10:39,915 iteration 6156 : loss : 0.011070, loss_ce: 0.004577
2022-01-17 13:10:40,862 iteration 6157 : loss : 0.015912, loss_ce: 0.005958
2022-01-17 13:10:41,743 iteration 6158 : loss : 0.013302, loss_ce: 0.004619
2022-01-17 13:10:42,571 iteration 6159 : loss : 0.009256, loss_ce: 0.003538
2022-01-17 13:10:43,656 iteration 6160 : loss : 0.045112, loss_ce: 0.020191
2022-01-17 13:10:44,493 iteration 6161 : loss : 0.017011, loss_ce: 0.004699
2022-01-17 13:10:45,419 iteration 6162 : loss : 0.011008, loss_ce: 0.003831
2022-01-17 13:10:46,315 iteration 6163 : loss : 0.013407, loss_ce: 0.004667
2022-01-17 13:10:47,185 iteration 6164 : loss : 0.012210, loss_ce: 0.003257
2022-01-17 13:10:48,109 iteration 6165 : loss : 0.011312, loss_ce: 0.004015
2022-01-17 13:10:49,054 iteration 6166 : loss : 0.014347, loss_ce: 0.005814
2022-01-17 13:10:49,891 iteration 6167 : loss : 0.011754, loss_ce: 0.003698
2022-01-17 13:10:50,896 iteration 6168 : loss : 0.025505, loss_ce: 0.006873
2022-01-17 13:10:51,798 iteration 6169 : loss : 0.013223, loss_ce: 0.005709
2022-01-17 13:10:52,744 iteration 6170 : loss : 0.012323, loss_ce: 0.004808
2022-01-17 13:10:53,654 iteration 6171 : loss : 0.026372, loss_ce: 0.008419
 91%|██████████████████████████▎  | 363/400 [1:45:03<10:03, 16.32s/it]2022-01-17 13:10:54,603 iteration 6172 : loss : 0.014013, loss_ce: 0.005191
2022-01-17 13:10:55,420 iteration 6173 : loss : 0.010363, loss_ce: 0.003515
2022-01-17 13:10:56,307 iteration 6174 : loss : 0.015443, loss_ce: 0.006818
2022-01-17 13:10:57,161 iteration 6175 : loss : 0.010946, loss_ce: 0.003210
2022-01-17 13:10:58,097 iteration 6176 : loss : 0.014484, loss_ce: 0.007220
2022-01-17 13:10:59,106 iteration 6177 : loss : 0.015445, loss_ce: 0.007075
2022-01-17 13:11:00,063 iteration 6178 : loss : 0.014439, loss_ce: 0.004586
2022-01-17 13:11:00,998 iteration 6179 : loss : 0.015876, loss_ce: 0.005086
2022-01-17 13:11:01,927 iteration 6180 : loss : 0.021564, loss_ce: 0.003408
2022-01-17 13:11:02,807 iteration 6181 : loss : 0.013337, loss_ce: 0.005156
2022-01-17 13:11:03,727 iteration 6182 : loss : 0.011808, loss_ce: 0.004500
2022-01-17 13:11:04,596 iteration 6183 : loss : 0.022920, loss_ce: 0.009176
2022-01-17 13:11:05,464 iteration 6184 : loss : 0.011430, loss_ce: 0.004200
2022-01-17 13:11:06,413 iteration 6185 : loss : 0.019202, loss_ce: 0.005055
2022-01-17 13:11:07,267 iteration 6186 : loss : 0.012152, loss_ce: 0.004739
2022-01-17 13:11:08,143 iteration 6187 : loss : 0.012987, loss_ce: 0.004035
2022-01-17 13:11:09,013 iteration 6188 : loss : 0.012564, loss_ce: 0.004764
 91%|██████████████████████████▍  | 364/400 [1:45:18<09:37, 16.03s/it]2022-01-17 13:11:10,047 iteration 6189 : loss : 0.019928, loss_ce: 0.008727
2022-01-17 13:11:10,972 iteration 6190 : loss : 0.011301, loss_ce: 0.004131
2022-01-17 13:11:11,949 iteration 6191 : loss : 0.015470, loss_ce: 0.004619
2022-01-17 13:11:12,900 iteration 6192 : loss : 0.020135, loss_ce: 0.007468
2022-01-17 13:11:13,780 iteration 6193 : loss : 0.010435, loss_ce: 0.003159
2022-01-17 13:11:14,740 iteration 6194 : loss : 0.012576, loss_ce: 0.004971
2022-01-17 13:11:15,724 iteration 6195 : loss : 0.018313, loss_ce: 0.006352
2022-01-17 13:11:16,599 iteration 6196 : loss : 0.024817, loss_ce: 0.006523
2022-01-17 13:11:17,599 iteration 6197 : loss : 0.024516, loss_ce: 0.008925
2022-01-17 13:11:18,592 iteration 6198 : loss : 0.016248, loss_ce: 0.006068
2022-01-17 13:11:19,463 iteration 6199 : loss : 0.011455, loss_ce: 0.004433
2022-01-17 13:11:20,402 iteration 6200 : loss : 0.019965, loss_ce: 0.008761
2022-01-17 13:11:21,311 iteration 6201 : loss : 0.014856, loss_ce: 0.005865
2022-01-17 13:11:22,202 iteration 6202 : loss : 0.011819, loss_ce: 0.003723
2022-01-17 13:11:23,089 iteration 6203 : loss : 0.018931, loss_ce: 0.005624
2022-01-17 13:11:24,034 iteration 6204 : loss : 0.012377, loss_ce: 0.005651
2022-01-17 13:11:24,034 Training Data Eval:
2022-01-17 13:11:28,403   Average segmentation loss on training set: 0.0085
2022-01-17 13:11:28,403 Validation Data Eval:
2022-01-17 13:11:29,895   Average segmentation loss on validation set: 0.0717
2022-01-17 13:11:33,553 Found new lowest validation loss at iteration 6204! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 13:11:34,540 iteration 6205 : loss : 0.017744, loss_ce: 0.009055
 91%|██████████████████████████▍  | 365/400 [1:45:44<11:00, 18.88s/it]2022-01-17 13:11:35,463 iteration 6206 : loss : 0.012779, loss_ce: 0.005468
2022-01-17 13:11:36,326 iteration 6207 : loss : 0.013027, loss_ce: 0.006614
2022-01-17 13:11:37,206 iteration 6208 : loss : 0.015348, loss_ce: 0.005445
2022-01-17 13:11:38,088 iteration 6209 : loss : 0.019420, loss_ce: 0.007618
2022-01-17 13:11:38,927 iteration 6210 : loss : 0.019338, loss_ce: 0.006466
2022-01-17 13:11:39,727 iteration 6211 : loss : 0.013367, loss_ce: 0.004857
2022-01-17 13:11:40,562 iteration 6212 : loss : 0.012797, loss_ce: 0.004851
2022-01-17 13:11:41,419 iteration 6213 : loss : 0.013837, loss_ce: 0.005023
2022-01-17 13:11:42,262 iteration 6214 : loss : 0.011086, loss_ce: 0.004473
2022-01-17 13:11:43,175 iteration 6215 : loss : 0.021108, loss_ce: 0.008253
2022-01-17 13:11:44,034 iteration 6216 : loss : 0.014040, loss_ce: 0.005875
2022-01-17 13:11:44,853 iteration 6217 : loss : 0.014721, loss_ce: 0.005350
2022-01-17 13:11:45,766 iteration 6218 : loss : 0.013829, loss_ce: 0.005241
2022-01-17 13:11:46,676 iteration 6219 : loss : 0.013316, loss_ce: 0.004327
2022-01-17 13:11:47,566 iteration 6220 : loss : 0.011795, loss_ce: 0.002642
2022-01-17 13:11:48,513 iteration 6221 : loss : 0.015247, loss_ce: 0.004324
2022-01-17 13:11:49,396 iteration 6222 : loss : 0.010825, loss_ce: 0.004833
 92%|██████████████████████████▌  | 366/400 [1:45:59<10:00, 17.67s/it]2022-01-17 13:11:50,397 iteration 6223 : loss : 0.016557, loss_ce: 0.006548
2022-01-17 13:11:51,310 iteration 6224 : loss : 0.013220, loss_ce: 0.004960
2022-01-17 13:11:52,243 iteration 6225 : loss : 0.032113, loss_ce: 0.012269
2022-01-17 13:11:53,125 iteration 6226 : loss : 0.010846, loss_ce: 0.003423
2022-01-17 13:11:53,983 iteration 6227 : loss : 0.012624, loss_ce: 0.005202
2022-01-17 13:11:55,045 iteration 6228 : loss : 0.019711, loss_ce: 0.006341
2022-01-17 13:11:55,960 iteration 6229 : loss : 0.014762, loss_ce: 0.007444
2022-01-17 13:11:56,897 iteration 6230 : loss : 0.015441, loss_ce: 0.004193
2022-01-17 13:11:57,845 iteration 6231 : loss : 0.016764, loss_ce: 0.006676
2022-01-17 13:11:58,771 iteration 6232 : loss : 0.013569, loss_ce: 0.005398
2022-01-17 13:11:59,675 iteration 6233 : loss : 0.016363, loss_ce: 0.008076
2022-01-17 13:12:00,564 iteration 6234 : loss : 0.019010, loss_ce: 0.003821
2022-01-17 13:12:01,434 iteration 6235 : loss : 0.015760, loss_ce: 0.008773
2022-01-17 13:12:02,348 iteration 6236 : loss : 0.011403, loss_ce: 0.005010
2022-01-17 13:12:03,279 iteration 6237 : loss : 0.016641, loss_ce: 0.007270
2022-01-17 13:12:04,254 iteration 6238 : loss : 0.018230, loss_ce: 0.004961
2022-01-17 13:12:05,167 iteration 6239 : loss : 0.011029, loss_ce: 0.003125
 92%|██████████████████████████▌  | 367/400 [1:46:15<09:24, 17.10s/it]2022-01-17 13:12:06,103 iteration 6240 : loss : 0.022553, loss_ce: 0.007078
2022-01-17 13:12:06,967 iteration 6241 : loss : 0.011418, loss_ce: 0.005272
2022-01-17 13:12:07,941 iteration 6242 : loss : 0.016953, loss_ce: 0.005015
2022-01-17 13:12:08,840 iteration 6243 : loss : 0.011940, loss_ce: 0.004881
2022-01-17 13:12:09,827 iteration 6244 : loss : 0.018671, loss_ce: 0.007430
2022-01-17 13:12:10,730 iteration 6245 : loss : 0.013731, loss_ce: 0.004773
2022-01-17 13:12:11,616 iteration 6246 : loss : 0.014603, loss_ce: 0.005487
2022-01-17 13:12:12,537 iteration 6247 : loss : 0.014374, loss_ce: 0.003448
2022-01-17 13:12:13,435 iteration 6248 : loss : 0.011758, loss_ce: 0.004277
2022-01-17 13:12:14,336 iteration 6249 : loss : 0.015533, loss_ce: 0.004565
2022-01-17 13:12:15,280 iteration 6250 : loss : 0.014231, loss_ce: 0.005473
2022-01-17 13:12:16,284 iteration 6251 : loss : 0.026864, loss_ce: 0.012376
2022-01-17 13:12:17,160 iteration 6252 : loss : 0.012772, loss_ce: 0.005458
2022-01-17 13:12:18,117 iteration 6253 : loss : 0.014248, loss_ce: 0.004840
2022-01-17 13:12:19,010 iteration 6254 : loss : 0.013542, loss_ce: 0.005606
2022-01-17 13:12:19,936 iteration 6255 : loss : 0.014209, loss_ce: 0.005398
2022-01-17 13:12:20,918 iteration 6256 : loss : 0.013747, loss_ce: 0.005635
 92%|██████████████████████████▋  | 368/400 [1:46:30<08:54, 16.70s/it]2022-01-17 13:12:21,914 iteration 6257 : loss : 0.022183, loss_ce: 0.006935
2022-01-17 13:12:22,852 iteration 6258 : loss : 0.016281, loss_ce: 0.005651
2022-01-17 13:12:23,812 iteration 6259 : loss : 0.016680, loss_ce: 0.006532
2022-01-17 13:12:24,698 iteration 6260 : loss : 0.018006, loss_ce: 0.007439
2022-01-17 13:12:25,607 iteration 6261 : loss : 0.015571, loss_ce: 0.005301
2022-01-17 13:12:26,533 iteration 6262 : loss : 0.018604, loss_ce: 0.004451
2022-01-17 13:12:27,461 iteration 6263 : loss : 0.017687, loss_ce: 0.003859
2022-01-17 13:12:28,391 iteration 6264 : loss : 0.011766, loss_ce: 0.004447
2022-01-17 13:12:29,320 iteration 6265 : loss : 0.014241, loss_ce: 0.005171
2022-01-17 13:12:30,211 iteration 6266 : loss : 0.017404, loss_ce: 0.008855
2022-01-17 13:12:31,094 iteration 6267 : loss : 0.013340, loss_ce: 0.005799
2022-01-17 13:12:32,004 iteration 6268 : loss : 0.012551, loss_ce: 0.004740
2022-01-17 13:12:32,799 iteration 6269 : loss : 0.009653, loss_ce: 0.003162
2022-01-17 13:12:33,699 iteration 6270 : loss : 0.012404, loss_ce: 0.005180
2022-01-17 13:12:34,604 iteration 6271 : loss : 0.013825, loss_ce: 0.003881
2022-01-17 13:12:35,557 iteration 6272 : loss : 0.018873, loss_ce: 0.006436
2022-01-17 13:12:36,498 iteration 6273 : loss : 0.012658, loss_ce: 0.004594
 92%|██████████████████████████▊  | 369/400 [1:46:46<08:27, 16.36s/it]2022-01-17 13:12:37,574 iteration 6274 : loss : 0.024623, loss_ce: 0.009035
2022-01-17 13:12:38,510 iteration 6275 : loss : 0.017922, loss_ce: 0.008795
2022-01-17 13:12:39,438 iteration 6276 : loss : 0.017692, loss_ce: 0.009210
2022-01-17 13:12:40,321 iteration 6277 : loss : 0.011303, loss_ce: 0.002935
2022-01-17 13:12:41,245 iteration 6278 : loss : 0.013626, loss_ce: 0.004661
2022-01-17 13:12:42,153 iteration 6279 : loss : 0.017812, loss_ce: 0.007290
2022-01-17 13:12:43,040 iteration 6280 : loss : 0.017192, loss_ce: 0.006032
2022-01-17 13:12:44,060 iteration 6281 : loss : 0.020316, loss_ce: 0.003793
2022-01-17 13:12:44,955 iteration 6282 : loss : 0.012596, loss_ce: 0.005364
2022-01-17 13:12:45,831 iteration 6283 : loss : 0.010291, loss_ce: 0.004435
2022-01-17 13:12:46,746 iteration 6284 : loss : 0.016949, loss_ce: 0.006838
2022-01-17 13:12:47,703 iteration 6285 : loss : 0.012335, loss_ce: 0.003842
2022-01-17 13:12:48,590 iteration 6286 : loss : 0.012443, loss_ce: 0.004222
2022-01-17 13:12:49,480 iteration 6287 : loss : 0.014398, loss_ce: 0.004131
2022-01-17 13:12:50,313 iteration 6288 : loss : 0.009377, loss_ce: 0.002951
2022-01-17 13:12:51,242 iteration 6289 : loss : 0.012723, loss_ce: 0.005609
2022-01-17 13:12:51,242 Training Data Eval:
2022-01-17 13:12:55,661   Average segmentation loss on training set: 0.0079
2022-01-17 13:12:55,661 Validation Data Eval:
2022-01-17 13:12:57,158   Average segmentation loss on validation set: 0.0697
2022-01-17 13:13:00,856 Found new lowest validation loss at iteration 6289! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed1234.pth
2022-01-17 13:13:01,807 iteration 6290 : loss : 0.015113, loss_ce: 0.006301
 92%|██████████████████████████▊  | 370/400 [1:47:11<09:31, 19.04s/it]2022-01-17 13:13:02,707 iteration 6291 : loss : 0.011682, loss_ce: 0.005071
2022-01-17 13:13:03,567 iteration 6292 : loss : 0.018849, loss_ce: 0.006986
2022-01-17 13:13:04,456 iteration 6293 : loss : 0.013658, loss_ce: 0.006006
2022-01-17 13:13:05,353 iteration 6294 : loss : 0.019828, loss_ce: 0.005646
2022-01-17 13:13:06,211 iteration 6295 : loss : 0.011294, loss_ce: 0.004276
2022-01-17 13:13:07,146 iteration 6296 : loss : 0.014868, loss_ce: 0.005151
2022-01-17 13:13:08,022 iteration 6297 : loss : 0.015356, loss_ce: 0.005618
2022-01-17 13:13:08,932 iteration 6298 : loss : 0.019173, loss_ce: 0.007033
2022-01-17 13:13:09,787 iteration 6299 : loss : 0.012627, loss_ce: 0.004054
2022-01-17 13:13:10,620 iteration 6300 : loss : 0.010885, loss_ce: 0.003587
2022-01-17 13:13:11,449 iteration 6301 : loss : 0.018044, loss_ce: 0.014139
2022-01-17 13:13:12,340 iteration 6302 : loss : 0.012788, loss_ce: 0.004324
2022-01-17 13:13:13,156 iteration 6303 : loss : 0.010889, loss_ce: 0.002470
2022-01-17 13:13:14,004 iteration 6304 : loss : 0.012394, loss_ce: 0.003296
2022-01-17 13:13:14,950 iteration 6305 : loss : 0.016576, loss_ce: 0.006746
2022-01-17 13:13:15,859 iteration 6306 : loss : 0.016846, loss_ce: 0.004197
2022-01-17 13:13:16,777 iteration 6307 : loss : 0.011906, loss_ce: 0.005192
 93%|██████████████████████████▉  | 371/400 [1:47:26<08:36, 17.82s/it]2022-01-17 13:13:17,706 iteration 6308 : loss : 0.014200, loss_ce: 0.003018
2022-01-17 13:13:18,644 iteration 6309 : loss : 0.015633, loss_ce: 0.006206
2022-01-17 13:13:19,557 iteration 6310 : loss : 0.015099, loss_ce: 0.006760
2022-01-17 13:13:20,495 iteration 6311 : loss : 0.010870, loss_ce: 0.004544
2022-01-17 13:13:21,449 iteration 6312 : loss : 0.017683, loss_ce: 0.005510
2022-01-17 13:13:22,438 iteration 6313 : loss : 0.016820, loss_ce: 0.006579
2022-01-17 13:13:23,346 iteration 6314 : loss : 0.009414, loss_ce: 0.002831
2022-01-17 13:13:24,224 iteration 6315 : loss : 0.013603, loss_ce: 0.004901
2022-01-17 13:13:25,138 iteration 6316 : loss : 0.013483, loss_ce: 0.004668
2022-01-17 13:13:26,044 iteration 6317 : loss : 0.011779, loss_ce: 0.003317
2022-01-17 13:13:27,021 iteration 6318 : loss : 0.019097, loss_ce: 0.007036
2022-01-17 13:13:27,952 iteration 6319 : loss : 0.011372, loss_ce: 0.004292
2022-01-17 13:13:28,853 iteration 6320 : loss : 0.021296, loss_ce: 0.005387
2022-01-17 13:13:29,803 iteration 6321 : loss : 0.017032, loss_ce: 0.008482
2022-01-17 13:13:30,768 iteration 6322 : loss : 0.013530, loss_ce: 0.005821
2022-01-17 13:13:31,815 iteration 6323 : loss : 0.019956, loss_ce: 0.006597
2022-01-17 13:13:32,789 iteration 6324 : loss : 0.020356, loss_ce: 0.010734
 93%|██████████████████████████▉  | 372/400 [1:47:42<08:03, 17.28s/it]2022-01-17 13:13:33,761 iteration 6325 : loss : 0.014470, loss_ce: 0.003772
2022-01-17 13:13:34,630 iteration 6326 : loss : 0.014942, loss_ce: 0.005820
2022-01-17 13:13:35,531 iteration 6327 : loss : 0.014567, loss_ce: 0.004499
2022-01-17 13:13:36,487 iteration 6328 : loss : 0.010703, loss_ce: 0.004804
2022-01-17 13:13:37,330 iteration 6329 : loss : 0.011955, loss_ce: 0.005832
2022-01-17 13:13:38,229 iteration 6330 : loss : 0.013471, loss_ce: 0.005280
2022-01-17 13:13:39,195 iteration 6331 : loss : 0.012953, loss_ce: 0.004947
2022-01-17 13:13:40,147 iteration 6332 : loss : 0.012954, loss_ce: 0.003423
2022-01-17 13:13:41,070 iteration 6333 : loss : 0.012377, loss_ce: 0.005662
2022-01-17 13:13:41,995 iteration 6334 : loss : 0.018301, loss_ce: 0.004370
2022-01-17 13:13:42,996 iteration 6335 : loss : 0.011594, loss_ce: 0.004175
2022-01-17 13:13:43,889 iteration 6336 : loss : 0.015916, loss_ce: 0.006022
2022-01-17 13:13:44,825 iteration 6337 : loss : 0.012960, loss_ce: 0.003860
2022-01-17 13:13:45,741 iteration 6338 : loss : 0.015085, loss_ce: 0.004570
2022-01-17 13:13:46,650 iteration 6339 : loss : 0.012825, loss_ce: 0.003947
2022-01-17 13:13:47,556 iteration 6340 : loss : 0.016520, loss_ce: 0.007193
2022-01-17 13:13:48,400 iteration 6341 : loss : 0.010547, loss_ce: 0.003363
 93%|███████████████████████████  | 373/400 [1:47:58<07:33, 16.78s/it]2022-01-17 13:13:49,398 iteration 6342 : loss : 0.020716, loss_ce: 0.006002
2022-01-17 13:13:50,305 iteration 6343 : loss : 0.016259, loss_ce: 0.005543
2022-01-17 13:13:51,205 iteration 6344 : loss : 0.014955, loss_ce: 0.004215
2022-01-17 13:13:52,088 iteration 6345 : loss : 0.018677, loss_ce: 0.002655
2022-01-17 13:13:53,014 iteration 6346 : loss : 0.016928, loss_ce: 0.005343
2022-01-17 13:13:53,934 iteration 6347 : loss : 0.013734, loss_ce: 0.004841
2022-01-17 13:13:54,759 iteration 6348 : loss : 0.009701, loss_ce: 0.004077
2022-01-17 13:13:55,680 iteration 6349 : loss : 0.017519, loss_ce: 0.007387
2022-01-17 13:13:56,698 iteration 6350 : loss : 0.018447, loss_ce: 0.006045
2022-01-17 13:13:57,659 iteration 6351 : loss : 0.014252, loss_ce: 0.005929
2022-01-17 13:13:58,571 iteration 6352 : loss : 0.016257, loss_ce: 0.004542
2022-01-17 13:13:59,491 iteration 6353 : loss : 0.013201, loss_ce: 0.005037
2022-01-17 13:14:00,407 iteration 6354 : loss : 0.013516, loss_ce: 0.005759
2022-01-17 13:14:01,297 iteration 6355 : loss : 0.016467, loss_ce: 0.005347
2022-01-17 13:14:02,273 iteration 6356 : loss : 0.014620, loss_ce: 0.003505
2022-01-17 13:14:03,166 iteration 6357 : loss : 0.015753, loss_ce: 0.005684
2022-01-17 13:14:04,180 iteration 6358 : loss : 0.018001, loss_ce: 0.008075
 94%|███████████████████████████  | 374/400 [1:48:14<07:08, 16.48s/it]2022-01-17 13:14:05,183 iteration 6359 : loss : 0.021414, loss_ce: 0.007378
2022-01-17 13:14:06,043 iteration 6360 : loss : 0.015810, loss_ce: 0.007129
2022-01-17 13:14:06,983 iteration 6361 : loss : 0.014615, loss_ce: 0.005008
2022-01-17 13:14:07,934 iteration 6362 : loss : 0.015965, loss_ce: 0.006843
2022-01-17 13:14:08,908 iteration 6363 : loss : 0.015517, loss_ce: 0.005921
2022-01-17 13:14:09,794 iteration 6364 : loss : 0.023109, loss_ce: 0.004126
2022-01-17 13:14:10,718 iteration 6365 : loss : 0.012364, loss_ce: 0.006435
2022-01-17 13:14:11,714 iteration 6366 : loss : 0.016366, loss_ce: 0.005622
2022-01-17 13:14:12,724 iteration 6367 : loss : 0.027027, loss_ce: 0.012574
2022-01-17 13:14:13,668 iteration 6368 : loss : 0.016878, loss_ce: 0.006400
2022-01-17 13:14:14,572 iteration 6369 : loss : 0.010493, loss_ce: 0.004035
2022-01-17 13:14:15,492 iteration 6370 : loss : 0.012092, loss_ce: 0.003843
2022-01-17 13:14:16,499 iteration 6371 : loss : 0.014885, loss_ce: 0.004895
2022-01-17 13:14:17,380 iteration 6372 : loss : 0.008919, loss_ce: 0.003440
2022-01-17 13:14:18,257 iteration 6373 : loss : 0.013943, loss_ce: 0.004890
2022-01-17 13:14:19,184 iteration 6374 : loss : 0.028382, loss_ce: 0.013870
2022-01-17 13:14:19,184 Training Data Eval:
2022-01-17 13:14:23,585   Average segmentation loss on training set: 0.0076
2022-01-17 13:14:23,586 Validation Data Eval:
2022-01-17 13:14:25,072   Average segmentation loss on validation set: 0.0821
2022-01-17 13:14:26,011 iteration 6375 : loss : 0.017971, loss_ce: 0.005717
 94%|███████████████████████████▏ | 375/400 [1:48:35<07:32, 18.08s/it]2022-01-17 13:14:27,014 iteration 6376 : loss : 0.024345, loss_ce: 0.006530
2022-01-17 13:14:27,947 iteration 6377 : loss : 0.014649, loss_ce: 0.005896
2022-01-17 13:14:28,774 iteration 6378 : loss : 0.011930, loss_ce: 0.005582
2022-01-17 13:14:29,681 iteration 6379 : loss : 0.015184, loss_ce: 0.003856
2022-01-17 13:14:30,567 iteration 6380 : loss : 0.014477, loss_ce: 0.005352
2022-01-17 13:14:31,446 iteration 6381 : loss : 0.009038, loss_ce: 0.002622
2022-01-17 13:14:32,281 iteration 6382 : loss : 0.011624, loss_ce: 0.003899
2022-01-17 13:14:33,241 iteration 6383 : loss : 0.018478, loss_ce: 0.006361
2022-01-17 13:14:34,127 iteration 6384 : loss : 0.012913, loss_ce: 0.005113
2022-01-17 13:14:35,079 iteration 6385 : loss : 0.014823, loss_ce: 0.004987
2022-01-17 13:14:36,050 iteration 6386 : loss : 0.015628, loss_ce: 0.004844
2022-01-17 13:14:37,060 iteration 6387 : loss : 0.017564, loss_ce: 0.007429
2022-01-17 13:14:38,005 iteration 6388 : loss : 0.013889, loss_ce: 0.005424
2022-01-17 13:14:38,812 iteration 6389 : loss : 0.011099, loss_ce: 0.003767
2022-01-17 13:14:39,723 iteration 6390 : loss : 0.015666, loss_ce: 0.007299
2022-01-17 13:14:40,597 iteration 6391 : loss : 0.011601, loss_ce: 0.005806
2022-01-17 13:14:41,571 iteration 6392 : loss : 0.020528, loss_ce: 0.006015
 94%|███████████████████████████▎ | 376/400 [1:48:51<06:55, 17.33s/it]2022-01-17 13:14:42,518 iteration 6393 : loss : 0.014160, loss_ce: 0.005109
2022-01-17 13:14:43,470 iteration 6394 : loss : 0.016077, loss_ce: 0.005677
2022-01-17 13:14:44,370 iteration 6395 : loss : 0.012297, loss_ce: 0.003604
2022-01-17 13:14:45,283 iteration 6396 : loss : 0.013102, loss_ce: 0.004046
2022-01-17 13:14:46,217 iteration 6397 : loss : 0.011700, loss_ce: 0.004625
2022-01-17 13:14:47,154 iteration 6398 : loss : 0.014960, loss_ce: 0.006176
2022-01-17 13:14:48,067 iteration 6399 : loss : 0.014196, loss_ce: 0.004444
2022-01-17 13:14:48,965 iteration 6400 : loss : 0.012938, loss_ce: 0.004899
2022-01-17 13:14:49,908 iteration 6401 : loss : 0.012689, loss_ce: 0.004915
2022-01-17 13:14:50,811 iteration 6402 : loss : 0.014345, loss_ce: 0.007355
2022-01-17 13:14:51,801 iteration 6403 : loss : 0.020059, loss_ce: 0.007701
2022-01-17 13:14:52,696 iteration 6404 : loss : 0.012268, loss_ce: 0.005234
2022-01-17 13:14:53,584 iteration 6405 : loss : 0.018508, loss_ce: 0.005017
2022-01-17 13:14:54,641 iteration 6406 : loss : 0.028723, loss_ce: 0.008634
2022-01-17 13:14:55,579 iteration 6407 : loss : 0.015982, loss_ce: 0.004075
2022-01-17 13:14:56,399 iteration 6408 : loss : 0.010069, loss_ce: 0.003330
2022-01-17 13:14:57,298 iteration 6409 : loss : 0.014780, loss_ce: 0.007141
 94%|███████████████████████████▎ | 377/400 [1:49:07<06:27, 16.85s/it]2022-01-17 13:14:58,218 iteration 6410 : loss : 0.010447, loss_ce: 0.002989
2022-01-17 13:14:59,216 iteration 6411 : loss : 0.015726, loss_ce: 0.006114
2022-01-17 13:15:00,145 iteration 6412 : loss : 0.012798, loss_ce: 0.004500
2022-01-17 13:15:01,036 iteration 6413 : loss : 0.011837, loss_ce: 0.004948
2022-01-17 13:15:01,906 iteration 6414 : loss : 0.012596, loss_ce: 0.005427
2022-01-17 13:15:02,762 iteration 6415 : loss : 0.021548, loss_ce: 0.005503
2022-01-17 13:15:03,679 iteration 6416 : loss : 0.009174, loss_ce: 0.003357
2022-01-17 13:15:04,536 iteration 6417 : loss : 0.014441, loss_ce: 0.004877
2022-01-17 13:15:05,429 iteration 6418 : loss : 0.011349, loss_ce: 0.004450
2022-01-17 13:15:06,437 iteration 6419 : loss : 0.015888, loss_ce: 0.006090
2022-01-17 13:15:07,421 iteration 6420 : loss : 0.016272, loss_ce: 0.003617
2022-01-17 13:15:08,370 iteration 6421 : loss : 0.012050, loss_ce: 0.004381
2022-01-17 13:15:09,290 iteration 6422 : loss : 0.015624, loss_ce: 0.004601
2022-01-17 13:15:10,236 iteration 6423 : loss : 0.011947, loss_ce: 0.004460
2022-01-17 13:15:11,236 iteration 6424 : loss : 0.022282, loss_ce: 0.010832
2022-01-17 13:15:12,131 iteration 6425 : loss : 0.011987, loss_ce: 0.003431
2022-01-17 13:15:13,111 iteration 6426 : loss : 0.017259, loss_ce: 0.005881
 94%|███████████████████████████▍ | 378/400 [1:49:22<06:03, 16.54s/it]2022-01-17 13:15:14,099 iteration 6427 : loss : 0.019491, loss_ce: 0.005717
2022-01-17 13:15:15,006 iteration 6428 : loss : 0.018872, loss_ce: 0.005625
2022-01-17 13:15:15,918 iteration 6429 : loss : 0.013721, loss_ce: 0.004286
2022-01-17 13:15:16,865 iteration 6430 : loss : 0.013787, loss_ce: 0.005699
2022-01-17 13:15:17,715 iteration 6431 : loss : 0.013006, loss_ce: 0.004912
2022-01-17 13:15:18,637 iteration 6432 : loss : 0.011902, loss_ce: 0.004747
2022-01-17 13:15:19,540 iteration 6433 : loss : 0.011562, loss_ce: 0.003750
2022-01-17 13:15:20,422 iteration 6434 : loss : 0.014238, loss_ce: 0.005609
2022-01-17 13:15:21,331 iteration 6435 : loss : 0.012443, loss_ce: 0.004452
2022-01-17 13:15:22,235 iteration 6436 : loss : 0.012747, loss_ce: 0.005255
2022-01-17 13:15:23,167 iteration 6437 : loss : 0.012618, loss_ce: 0.004079
2022-01-17 13:15:24,125 iteration 6438 : loss : 0.019533, loss_ce: 0.006624
2022-01-17 13:15:25,010 iteration 6439 : loss : 0.011855, loss_ce: 0.005489
2022-01-17 13:15:25,967 iteration 6440 : loss : 0.015860, loss_ce: 0.006854
2022-01-17 13:15:26,827 iteration 6441 : loss : 0.010485, loss_ce: 0.004801
2022-01-17 13:15:27,749 iteration 6442 : loss : 0.012077, loss_ce: 0.003563
2022-01-17 13:15:28,592 iteration 6443 : loss : 0.009460, loss_ce: 0.002998
 95%|███████████████████████████▍ | 379/400 [1:49:38<05:40, 16.22s/it]2022-01-17 13:15:29,559 iteration 6444 : loss : 0.013707, loss_ce: 0.006027
2022-01-17 13:15:30,466 iteration 6445 : loss : 0.015566, loss_ce: 0.006005
2022-01-17 13:15:31,390 iteration 6446 : loss : 0.014398, loss_ce: 0.005955
2022-01-17 13:15:32,328 iteration 6447 : loss : 0.014909, loss_ce: 0.002508
2022-01-17 13:15:33,269 iteration 6448 : loss : 0.014419, loss_ce: 0.005295
2022-01-17 13:15:34,161 iteration 6449 : loss : 0.011445, loss_ce: 0.002533
2022-01-17 13:15:35,034 iteration 6450 : loss : 0.014733, loss_ce: 0.006304
2022-01-17 13:15:35,950 iteration 6451 : loss : 0.012598, loss_ce: 0.004428
2022-01-17 13:15:36,932 iteration 6452 : loss : 0.017581, loss_ce: 0.006010
2022-01-17 13:15:37,829 iteration 6453 : loss : 0.013852, loss_ce: 0.005095
2022-01-17 13:15:38,685 iteration 6454 : loss : 0.012999, loss_ce: 0.004768
2022-01-17 13:15:39,633 iteration 6455 : loss : 0.012184, loss_ce: 0.005410
2022-01-17 13:15:40,545 iteration 6456 : loss : 0.014653, loss_ce: 0.005458
2022-01-17 13:15:41,475 iteration 6457 : loss : 0.019085, loss_ce: 0.005937
2022-01-17 13:15:42,342 iteration 6458 : loss : 0.012419, loss_ce: 0.004547
2022-01-17 13:15:43,241 iteration 6459 : loss : 0.008106, loss_ce: 0.002015
2022-01-17 13:15:43,241 Training Data Eval:
2022-01-17 13:15:47,652   Average segmentation loss on training set: 0.0073
2022-01-17 13:15:47,652 Validation Data Eval:
2022-01-17 13:15:49,132   Average segmentation loss on validation set: 0.0879
2022-01-17 13:15:50,096 iteration 6460 : loss : 0.016755, loss_ce: 0.008252
 95%|███████████████████████████▌ | 380/400 [1:49:59<05:56, 17.81s/it]2022-01-17 13:15:51,119 iteration 6461 : loss : 0.019851, loss_ce: 0.008861
2022-01-17 13:15:52,017 iteration 6462 : loss : 0.010020, loss_ce: 0.004387
2022-01-17 13:15:52,982 iteration 6463 : loss : 0.016303, loss_ce: 0.006965
2022-01-17 13:15:53,900 iteration 6464 : loss : 0.014338, loss_ce: 0.003804
2022-01-17 13:15:54,855 iteration 6465 : loss : 0.014420, loss_ce: 0.005166
2022-01-17 13:15:55,726 iteration 6466 : loss : 0.012071, loss_ce: 0.003629
2022-01-17 13:15:56,621 iteration 6467 : loss : 0.010857, loss_ce: 0.003820
2022-01-17 13:15:57,597 iteration 6468 : loss : 0.019220, loss_ce: 0.006681
2022-01-17 13:15:58,499 iteration 6469 : loss : 0.013657, loss_ce: 0.006098
2022-01-17 13:15:59,382 iteration 6470 : loss : 0.012910, loss_ce: 0.003818
2022-01-17 13:16:00,295 iteration 6471 : loss : 0.012107, loss_ce: 0.004047
2022-01-17 13:16:01,223 iteration 6472 : loss : 0.018465, loss_ce: 0.005581
2022-01-17 13:16:02,110 iteration 6473 : loss : 0.012945, loss_ce: 0.004221
2022-01-17 13:16:03,087 iteration 6474 : loss : 0.011862, loss_ce: 0.005718
2022-01-17 13:16:04,023 iteration 6475 : loss : 0.016964, loss_ce: 0.007911
2022-01-17 13:16:04,837 iteration 6476 : loss : 0.010884, loss_ce: 0.003946
2022-01-17 13:16:05,850 iteration 6477 : loss : 0.015127, loss_ce: 0.005649
 95%|███████████████████████████▌ | 381/400 [1:50:15<05:26, 17.19s/it]2022-01-17 13:16:06,859 iteration 6478 : loss : 0.018660, loss_ce: 0.006800
2022-01-17 13:16:07,747 iteration 6479 : loss : 0.014446, loss_ce: 0.004959
2022-01-17 13:16:08,643 iteration 6480 : loss : 0.012371, loss_ce: 0.005902
2022-01-17 13:16:09,580 iteration 6481 : loss : 0.015052, loss_ce: 0.006589
2022-01-17 13:16:10,424 iteration 6482 : loss : 0.012382, loss_ce: 0.004871
2022-01-17 13:16:11,357 iteration 6483 : loss : 0.014377, loss_ce: 0.003153
2022-01-17 13:16:12,229 iteration 6484 : loss : 0.011774, loss_ce: 0.004798
2022-01-17 13:16:13,135 iteration 6485 : loss : 0.018471, loss_ce: 0.008432
2022-01-17 13:16:14,097 iteration 6486 : loss : 0.013343, loss_ce: 0.004536
2022-01-17 13:16:15,106 iteration 6487 : loss : 0.017181, loss_ce: 0.006662
2022-01-17 13:16:16,047 iteration 6488 : loss : 0.019351, loss_ce: 0.006724
2022-01-17 13:16:16,923 iteration 6489 : loss : 0.009361, loss_ce: 0.004531
2022-01-17 13:16:17,857 iteration 6490 : loss : 0.015271, loss_ce: 0.004310
2022-01-17 13:16:18,745 iteration 6491 : loss : 0.011909, loss_ce: 0.003835
2022-01-17 13:16:19,728 iteration 6492 : loss : 0.013075, loss_ce: 0.004694
2022-01-17 13:16:20,660 iteration 6493 : loss : 0.029583, loss_ce: 0.010854
2022-01-17 13:16:21,478 iteration 6494 : loss : 0.008056, loss_ce: 0.003155
 96%|███████████████████████████▋ | 382/400 [1:50:31<05:00, 16.72s/it]2022-01-17 13:16:22,410 iteration 6495 : loss : 0.014220, loss_ce: 0.005992
2022-01-17 13:16:23,326 iteration 6496 : loss : 0.016562, loss_ce: 0.003837
2022-01-17 13:16:24,275 iteration 6497 : loss : 0.010952, loss_ce: 0.004125
2022-01-17 13:16:25,220 iteration 6498 : loss : 0.014929, loss_ce: 0.005013
2022-01-17 13:16:26,161 iteration 6499 : loss : 0.015488, loss_ce: 0.006662
2022-01-17 13:16:27,059 iteration 6500 : loss : 0.011922, loss_ce: 0.004240
2022-01-17 13:16:27,992 iteration 6501 : loss : 0.017114, loss_ce: 0.006555
2022-01-17 13:16:28,951 iteration 6502 : loss : 0.015324, loss_ce: 0.009659
2022-01-17 13:16:29,830 iteration 6503 : loss : 0.009180, loss_ce: 0.002279
2022-01-17 13:16:30,688 iteration 6504 : loss : 0.011354, loss_ce: 0.004079
2022-01-17 13:16:31,487 iteration 6505 : loss : 0.010427, loss_ce: 0.004767
2022-01-17 13:16:32,389 iteration 6506 : loss : 0.014503, loss_ce: 0.004087
2022-01-17 13:16:33,374 iteration 6507 : loss : 0.016119, loss_ce: 0.007607
2022-01-17 13:16:34,321 iteration 6508 : loss : 0.013132, loss_ce: 0.004800
2022-01-17 13:16:35,259 iteration 6509 : loss : 0.013814, loss_ce: 0.005689
2022-01-17 13:16:36,191 iteration 6510 : loss : 0.011981, loss_ce: 0.004057
2022-01-17 13:16:37,038 iteration 6511 : loss : 0.011231, loss_ce: 0.004015
 96%|███████████████████████████▊ | 383/400 [1:50:46<04:38, 16.37s/it]2022-01-17 13:16:37,968 iteration 6512 : loss : 0.014529, loss_ce: 0.004160
2022-01-17 13:16:38,888 iteration 6513 : loss : 0.016749, loss_ce: 0.005569
2022-01-17 13:16:39,893 iteration 6514 : loss : 0.010840, loss_ce: 0.003189
2022-01-17 13:16:40,857 iteration 6515 : loss : 0.025616, loss_ce: 0.008535
2022-01-17 13:16:41,797 iteration 6516 : loss : 0.017976, loss_ce: 0.007921
2022-01-17 13:16:42,695 iteration 6517 : loss : 0.017566, loss_ce: 0.003675
2022-01-17 13:16:43,604 iteration 6518 : loss : 0.010960, loss_ce: 0.003756
2022-01-17 13:16:44,503 iteration 6519 : loss : 0.014206, loss_ce: 0.004100
2022-01-17 13:16:45,456 iteration 6520 : loss : 0.012721, loss_ce: 0.004199
2022-01-17 13:16:46,333 iteration 6521 : loss : 0.015489, loss_ce: 0.006597
2022-01-17 13:16:47,261 iteration 6522 : loss : 0.011839, loss_ce: 0.004247
2022-01-17 13:16:48,109 iteration 6523 : loss : 0.009157, loss_ce: 0.003608
2022-01-17 13:16:49,065 iteration 6524 : loss : 0.018057, loss_ce: 0.007701
2022-01-17 13:16:49,995 iteration 6525 : loss : 0.013614, loss_ce: 0.004992
2022-01-17 13:16:50,916 iteration 6526 : loss : 0.018299, loss_ce: 0.007290
2022-01-17 13:16:51,766 iteration 6527 : loss : 0.011641, loss_ce: 0.004982
2022-01-17 13:16:52,650 iteration 6528 : loss : 0.011751, loss_ce: 0.003410
 96%|███████████████████████████▊ | 384/400 [1:51:02<04:18, 16.15s/it]2022-01-17 13:16:53,660 iteration 6529 : loss : 0.019175, loss_ce: 0.006430
2022-01-17 13:16:54,596 iteration 6530 : loss : 0.011356, loss_ce: 0.003643
2022-01-17 13:16:55,445 iteration 6531 : loss : 0.011193, loss_ce: 0.002980
2022-01-17 13:16:56,378 iteration 6532 : loss : 0.016593, loss_ce: 0.006652
2022-01-17 13:16:57,223 iteration 6533 : loss : 0.008266, loss_ce: 0.003189
2022-01-17 13:16:58,149 iteration 6534 : loss : 0.019327, loss_ce: 0.008530
2022-01-17 13:16:59,080 iteration 6535 : loss : 0.015301, loss_ce: 0.006130
2022-01-17 13:17:00,023 iteration 6536 : loss : 0.011919, loss_ce: 0.003661
2022-01-17 13:17:00,954 iteration 6537 : loss : 0.013545, loss_ce: 0.004205
2022-01-17 13:17:01,899 iteration 6538 : loss : 0.013411, loss_ce: 0.003865
2022-01-17 13:17:02,865 iteration 6539 : loss : 0.015523, loss_ce: 0.007522
2022-01-17 13:17:03,707 iteration 6540 : loss : 0.009980, loss_ce: 0.004135
2022-01-17 13:17:04,595 iteration 6541 : loss : 0.020368, loss_ce: 0.011817
2022-01-17 13:17:05,597 iteration 6542 : loss : 0.011956, loss_ce: 0.003902
2022-01-17 13:17:06,481 iteration 6543 : loss : 0.011898, loss_ce: 0.003592
2022-01-17 13:17:07,430 iteration 6544 : loss : 0.013488, loss_ce: 0.004708
2022-01-17 13:17:07,431 Training Data Eval:
2022-01-17 13:17:11,810   Average segmentation loss on training set: 0.0073
2022-01-17 13:17:11,811 Validation Data Eval:
2022-01-17 13:17:13,312   Average segmentation loss on validation set: 0.0865
2022-01-17 13:17:14,306 iteration 6545 : loss : 0.013838, loss_ce: 0.004755
 96%|███████████████████████████▉ | 385/400 [1:51:24<04:26, 17.80s/it]2022-01-17 13:17:15,397 iteration 6546 : loss : 0.020071, loss_ce: 0.009211
2022-01-17 13:17:16,300 iteration 6547 : loss : 0.013897, loss_ce: 0.005418
2022-01-17 13:17:17,240 iteration 6548 : loss : 0.011009, loss_ce: 0.004078
2022-01-17 13:17:18,117 iteration 6549 : loss : 0.013362, loss_ce: 0.004792
2022-01-17 13:17:19,067 iteration 6550 : loss : 0.025747, loss_ce: 0.007932
2022-01-17 13:17:20,041 iteration 6551 : loss : 0.016991, loss_ce: 0.006659
2022-01-17 13:17:21,050 iteration 6552 : loss : 0.018676, loss_ce: 0.006738
2022-01-17 13:17:22,075 iteration 6553 : loss : 0.022660, loss_ce: 0.006730
2022-01-17 13:17:22,999 iteration 6554 : loss : 0.016777, loss_ce: 0.005646
2022-01-17 13:17:23,909 iteration 6555 : loss : 0.010869, loss_ce: 0.004800
2022-01-17 13:17:24,817 iteration 6556 : loss : 0.015311, loss_ce: 0.003797
2022-01-17 13:17:25,638 iteration 6557 : loss : 0.008830, loss_ce: 0.003380
2022-01-17 13:17:26,549 iteration 6558 : loss : 0.013711, loss_ce: 0.004169
2022-01-17 13:17:27,396 iteration 6559 : loss : 0.010538, loss_ce: 0.003585
2022-01-17 13:17:28,318 iteration 6560 : loss : 0.012565, loss_ce: 0.005748
2022-01-17 13:17:29,276 iteration 6561 : loss : 0.014071, loss_ce: 0.004285
2022-01-17 13:17:30,161 iteration 6562 : loss : 0.013286, loss_ce: 0.004954
 96%|███████████████████████████▉ | 386/400 [1:51:40<04:01, 17.22s/it]2022-01-17 13:17:31,248 iteration 6563 : loss : 0.018025, loss_ce: 0.007396
2022-01-17 13:17:32,136 iteration 6564 : loss : 0.014734, loss_ce: 0.006226
2022-01-17 13:17:32,990 iteration 6565 : loss : 0.016111, loss_ce: 0.003830
2022-01-17 13:17:33,837 iteration 6566 : loss : 0.011335, loss_ce: 0.004383
2022-01-17 13:17:34,672 iteration 6567 : loss : 0.011307, loss_ce: 0.004375
2022-01-17 13:17:35,568 iteration 6568 : loss : 0.011517, loss_ce: 0.004835
2022-01-17 13:17:36,489 iteration 6569 : loss : 0.010411, loss_ce: 0.003722
2022-01-17 13:17:37,367 iteration 6570 : loss : 0.009782, loss_ce: 0.004395
2022-01-17 13:17:38,267 iteration 6571 : loss : 0.013080, loss_ce: 0.003541
2022-01-17 13:17:39,111 iteration 6572 : loss : 0.009791, loss_ce: 0.004093
2022-01-17 13:17:40,087 iteration 6573 : loss : 0.015135, loss_ce: 0.004737
2022-01-17 13:17:41,068 iteration 6574 : loss : 0.010497, loss_ce: 0.004106
2022-01-17 13:17:42,059 iteration 6575 : loss : 0.027670, loss_ce: 0.007372
2022-01-17 13:17:42,996 iteration 6576 : loss : 0.013204, loss_ce: 0.005742
2022-01-17 13:17:43,918 iteration 6577 : loss : 0.016822, loss_ce: 0.003391
2022-01-17 13:17:44,777 iteration 6578 : loss : 0.014172, loss_ce: 0.005226
2022-01-17 13:17:45,691 iteration 6579 : loss : 0.013336, loss_ce: 0.004469
 97%|████████████████████████████ | 387/400 [1:51:55<03:37, 16.71s/it]2022-01-17 13:17:46,650 iteration 6580 : loss : 0.013424, loss_ce: 0.003760
2022-01-17 13:17:47,529 iteration 6581 : loss : 0.012983, loss_ce: 0.004088
2022-01-17 13:17:48,490 iteration 6582 : loss : 0.013137, loss_ce: 0.004313
2022-01-17 13:17:49,401 iteration 6583 : loss : 0.015540, loss_ce: 0.005626
2022-01-17 13:17:50,327 iteration 6584 : loss : 0.016018, loss_ce: 0.006949
2022-01-17 13:17:51,287 iteration 6585 : loss : 0.017532, loss_ce: 0.005522
2022-01-17 13:17:52,221 iteration 6586 : loss : 0.018644, loss_ce: 0.005180
2022-01-17 13:17:53,124 iteration 6587 : loss : 0.010189, loss_ce: 0.004177
2022-01-17 13:17:54,052 iteration 6588 : loss : 0.014589, loss_ce: 0.005592
2022-01-17 13:17:54,911 iteration 6589 : loss : 0.011700, loss_ce: 0.004239
2022-01-17 13:17:55,887 iteration 6590 : loss : 0.012714, loss_ce: 0.005700
2022-01-17 13:17:56,853 iteration 6591 : loss : 0.018630, loss_ce: 0.007159
2022-01-17 13:17:57,737 iteration 6592 : loss : 0.011085, loss_ce: 0.004149
2022-01-17 13:17:58,716 iteration 6593 : loss : 0.026627, loss_ce: 0.004994
2022-01-17 13:17:59,621 iteration 6594 : loss : 0.012029, loss_ce: 0.005866
2022-01-17 13:18:00,510 iteration 6595 : loss : 0.010989, loss_ce: 0.003737
2022-01-17 13:18:01,481 iteration 6596 : loss : 0.014182, loss_ce: 0.004503
 97%|████████████████████████████▏| 388/400 [1:52:11<03:17, 16.44s/it]2022-01-17 13:18:02,442 iteration 6597 : loss : 0.013497, loss_ce: 0.005607
2022-01-17 13:18:03,310 iteration 6598 : loss : 0.025252, loss_ce: 0.005065
2022-01-17 13:18:04,241 iteration 6599 : loss : 0.012896, loss_ce: 0.004982
2022-01-17 13:18:05,053 iteration 6600 : loss : 0.008058, loss_ce: 0.003293
2022-01-17 13:18:05,964 iteration 6601 : loss : 0.012995, loss_ce: 0.004506
2022-01-17 13:18:06,846 iteration 6602 : loss : 0.012068, loss_ce: 0.004107
2022-01-17 13:18:07,765 iteration 6603 : loss : 0.014546, loss_ce: 0.004528
2022-01-17 13:18:08,613 iteration 6604 : loss : 0.007973, loss_ce: 0.003215
2022-01-17 13:18:09,534 iteration 6605 : loss : 0.011808, loss_ce: 0.003681
2022-01-17 13:18:10,476 iteration 6606 : loss : 0.012968, loss_ce: 0.005610
2022-01-17 13:18:11,416 iteration 6607 : loss : 0.016327, loss_ce: 0.007362
2022-01-17 13:18:12,352 iteration 6608 : loss : 0.012517, loss_ce: 0.005172
2022-01-17 13:18:13,218 iteration 6609 : loss : 0.010809, loss_ce: 0.003845
2022-01-17 13:18:14,100 iteration 6610 : loss : 0.011812, loss_ce: 0.004557
2022-01-17 13:18:14,985 iteration 6611 : loss : 0.009841, loss_ce: 0.002198
2022-01-17 13:18:15,935 iteration 6612 : loss : 0.015490, loss_ce: 0.005544
2022-01-17 13:18:16,742 iteration 6613 : loss : 0.010045, loss_ce: 0.003659
 97%|████████████████████████████▏| 389/400 [1:52:26<02:56, 16.08s/it]2022-01-17 13:18:17,706 iteration 6614 : loss : 0.016413, loss_ce: 0.007687
2022-01-17 13:18:18,630 iteration 6615 : loss : 0.012807, loss_ce: 0.005216
2022-01-17 13:18:19,529 iteration 6616 : loss : 0.012675, loss_ce: 0.003517
2022-01-17 13:18:20,559 iteration 6617 : loss : 0.017250, loss_ce: 0.006373
2022-01-17 13:18:21,485 iteration 6618 : loss : 0.012691, loss_ce: 0.003183
2022-01-17 13:18:22,475 iteration 6619 : loss : 0.018142, loss_ce: 0.006605
2022-01-17 13:18:23,428 iteration 6620 : loss : 0.021168, loss_ce: 0.008458
2022-01-17 13:18:24,320 iteration 6621 : loss : 0.013821, loss_ce: 0.003925
2022-01-17 13:18:25,216 iteration 6622 : loss : 0.014318, loss_ce: 0.006962
2022-01-17 13:18:26,113 iteration 6623 : loss : 0.013708, loss_ce: 0.004946
2022-01-17 13:18:27,061 iteration 6624 : loss : 0.033061, loss_ce: 0.014618
2022-01-17 13:18:28,024 iteration 6625 : loss : 0.012774, loss_ce: 0.004976
2022-01-17 13:18:28,927 iteration 6626 : loss : 0.013101, loss_ce: 0.003139
2022-01-17 13:18:29,761 iteration 6627 : loss : 0.013481, loss_ce: 0.003883
2022-01-17 13:18:30,668 iteration 6628 : loss : 0.011924, loss_ce: 0.005209
2022-01-17 13:18:31,577 iteration 6629 : loss : 0.012080, loss_ce: 0.005371
2022-01-17 13:18:31,578 Training Data Eval:
2022-01-17 13:18:35,984   Average segmentation loss on training set: 0.0073
2022-01-17 13:18:35,984 Validation Data Eval:
2022-01-17 13:18:37,470   Average segmentation loss on validation set: 0.0837
2022-01-17 13:18:38,427 iteration 6630 : loss : 0.014082, loss_ce: 0.003800
 98%|████████████████████████████▎| 390/400 [1:52:48<02:57, 17.76s/it]2022-01-17 13:18:39,461 iteration 6631 : loss : 0.015299, loss_ce: 0.005577
2022-01-17 13:18:40,388 iteration 6632 : loss : 0.016052, loss_ce: 0.006829
2022-01-17 13:18:41,305 iteration 6633 : loss : 0.023593, loss_ce: 0.005731
2022-01-17 13:18:42,103 iteration 6634 : loss : 0.009681, loss_ce: 0.002937
2022-01-17 13:18:42,975 iteration 6635 : loss : 0.014737, loss_ce: 0.003922
2022-01-17 13:18:43,943 iteration 6636 : loss : 0.017995, loss_ce: 0.006955
2022-01-17 13:18:44,885 iteration 6637 : loss : 0.010133, loss_ce: 0.004551
2022-01-17 13:18:45,841 iteration 6638 : loss : 0.014810, loss_ce: 0.004823
2022-01-17 13:18:46,819 iteration 6639 : loss : 0.018850, loss_ce: 0.006295
2022-01-17 13:18:47,719 iteration 6640 : loss : 0.017472, loss_ce: 0.004882
2022-01-17 13:18:48,596 iteration 6641 : loss : 0.011681, loss_ce: 0.006116
2022-01-17 13:18:49,578 iteration 6642 : loss : 0.012719, loss_ce: 0.004932
2022-01-17 13:18:50,504 iteration 6643 : loss : 0.019673, loss_ce: 0.008483
2022-01-17 13:18:51,413 iteration 6644 : loss : 0.014290, loss_ce: 0.004993
2022-01-17 13:18:52,263 iteration 6645 : loss : 0.009438, loss_ce: 0.004461
2022-01-17 13:18:53,144 iteration 6646 : loss : 0.011950, loss_ce: 0.004817
2022-01-17 13:18:53,967 iteration 6647 : loss : 0.010185, loss_ce: 0.003149
 98%|████████████████████████████▎| 391/400 [1:53:03<02:33, 17.09s/it]2022-01-17 13:18:54,894 iteration 6648 : loss : 0.012265, loss_ce: 0.003862
2022-01-17 13:18:55,871 iteration 6649 : loss : 0.017467, loss_ce: 0.008640
2022-01-17 13:18:56,734 iteration 6650 : loss : 0.015143, loss_ce: 0.005202
2022-01-17 13:18:57,615 iteration 6651 : loss : 0.009878, loss_ce: 0.003148
2022-01-17 13:18:58,604 iteration 6652 : loss : 0.015999, loss_ce: 0.006051
2022-01-17 13:18:59,569 iteration 6653 : loss : 0.015007, loss_ce: 0.006048
2022-01-17 13:19:00,446 iteration 6654 : loss : 0.010658, loss_ce: 0.003786
2022-01-17 13:19:01,371 iteration 6655 : loss : 0.011958, loss_ce: 0.004510
2022-01-17 13:19:02,311 iteration 6656 : loss : 0.012836, loss_ce: 0.005337
2022-01-17 13:19:03,322 iteration 6657 : loss : 0.015175, loss_ce: 0.005574
2022-01-17 13:19:04,260 iteration 6658 : loss : 0.018805, loss_ce: 0.006915
2022-01-17 13:19:05,212 iteration 6659 : loss : 0.018404, loss_ce: 0.006573
2022-01-17 13:19:06,083 iteration 6660 : loss : 0.014807, loss_ce: 0.004417
2022-01-17 13:19:06,917 iteration 6661 : loss : 0.009745, loss_ce: 0.003382
2022-01-17 13:19:07,841 iteration 6662 : loss : 0.010602, loss_ce: 0.003812
2022-01-17 13:19:08,805 iteration 6663 : loss : 0.015479, loss_ce: 0.005828
2022-01-17 13:19:09,707 iteration 6664 : loss : 0.014277, loss_ce: 0.004698
 98%|████████████████████████████▍| 392/400 [1:53:19<02:13, 16.69s/it]2022-01-17 13:19:10,683 iteration 6665 : loss : 0.016785, loss_ce: 0.005838
2022-01-17 13:19:11,610 iteration 6666 : loss : 0.012267, loss_ce: 0.004374
2022-01-17 13:19:12,492 iteration 6667 : loss : 0.014234, loss_ce: 0.004978
2022-01-17 13:19:13,314 iteration 6668 : loss : 0.008931, loss_ce: 0.003543
2022-01-17 13:19:14,242 iteration 6669 : loss : 0.013408, loss_ce: 0.004281
2022-01-17 13:19:15,107 iteration 6670 : loss : 0.011545, loss_ce: 0.003947
2022-01-17 13:19:16,099 iteration 6671 : loss : 0.013097, loss_ce: 0.005335
2022-01-17 13:19:17,013 iteration 6672 : loss : 0.013366, loss_ce: 0.006371
2022-01-17 13:19:17,997 iteration 6673 : loss : 0.013579, loss_ce: 0.005587
2022-01-17 13:19:18,963 iteration 6674 : loss : 0.016674, loss_ce: 0.006749
2022-01-17 13:19:19,842 iteration 6675 : loss : 0.015393, loss_ce: 0.004827
2022-01-17 13:19:20,680 iteration 6676 : loss : 0.010141, loss_ce: 0.004112
2022-01-17 13:19:21,602 iteration 6677 : loss : 0.011045, loss_ce: 0.002548
2022-01-17 13:19:22,602 iteration 6678 : loss : 0.013787, loss_ce: 0.007143
2022-01-17 13:19:23,545 iteration 6679 : loss : 0.016123, loss_ce: 0.005672
2022-01-17 13:19:24,448 iteration 6680 : loss : 0.030161, loss_ce: 0.011558
2022-01-17 13:19:25,377 iteration 6681 : loss : 0.011285, loss_ce: 0.003642
 98%|████████████████████████████▍| 393/400 [1:53:35<01:54, 16.38s/it]2022-01-17 13:19:26,328 iteration 6682 : loss : 0.011935, loss_ce: 0.003436
2022-01-17 13:19:27,275 iteration 6683 : loss : 0.018083, loss_ce: 0.005843
2022-01-17 13:19:28,202 iteration 6684 : loss : 0.030072, loss_ce: 0.005071
2022-01-17 13:19:29,094 iteration 6685 : loss : 0.010765, loss_ce: 0.003876
2022-01-17 13:19:30,011 iteration 6686 : loss : 0.012640, loss_ce: 0.003805
2022-01-17 13:19:30,928 iteration 6687 : loss : 0.014781, loss_ce: 0.006256
2022-01-17 13:19:31,840 iteration 6688 : loss : 0.012161, loss_ce: 0.003917
2022-01-17 13:19:32,718 iteration 6689 : loss : 0.011345, loss_ce: 0.004485
2022-01-17 13:19:33,685 iteration 6690 : loss : 0.012153, loss_ce: 0.004187
2022-01-17 13:19:34,543 iteration 6691 : loss : 0.011608, loss_ce: 0.004485
2022-01-17 13:19:35,408 iteration 6692 : loss : 0.009445, loss_ce: 0.004517
2022-01-17 13:19:36,343 iteration 6693 : loss : 0.010181, loss_ce: 0.003732
2022-01-17 13:19:37,198 iteration 6694 : loss : 0.008973, loss_ce: 0.003627
2022-01-17 13:19:38,092 iteration 6695 : loss : 0.011860, loss_ce: 0.003548
2022-01-17 13:19:39,004 iteration 6696 : loss : 0.012880, loss_ce: 0.006483
2022-01-17 13:19:39,926 iteration 6697 : loss : 0.014488, loss_ce: 0.005121
2022-01-17 13:19:40,771 iteration 6698 : loss : 0.012634, loss_ce: 0.003900
 98%|████████████████████████████▌| 394/400 [1:53:50<01:36, 16.09s/it]2022-01-17 13:19:41,743 iteration 6699 : loss : 0.014691, loss_ce: 0.004137
2022-01-17 13:19:42,705 iteration 6700 : loss : 0.017648, loss_ce: 0.007805
2022-01-17 13:19:43,694 iteration 6701 : loss : 0.026664, loss_ce: 0.007785
2022-01-17 13:19:44,576 iteration 6702 : loss : 0.013360, loss_ce: 0.004378
2022-01-17 13:19:45,574 iteration 6703 : loss : 0.015115, loss_ce: 0.004443
2022-01-17 13:19:46,495 iteration 6704 : loss : 0.012613, loss_ce: 0.006310
2022-01-17 13:19:47,351 iteration 6705 : loss : 0.010624, loss_ce: 0.003199
2022-01-17 13:19:48,230 iteration 6706 : loss : 0.013350, loss_ce: 0.004556
2022-01-17 13:19:49,140 iteration 6707 : loss : 0.012777, loss_ce: 0.004478
2022-01-17 13:19:49,982 iteration 6708 : loss : 0.011791, loss_ce: 0.003062
2022-01-17 13:19:50,856 iteration 6709 : loss : 0.012283, loss_ce: 0.003266
2022-01-17 13:19:51,783 iteration 6710 : loss : 0.013222, loss_ce: 0.004678
2022-01-17 13:19:52,698 iteration 6711 : loss : 0.011488, loss_ce: 0.004891
2022-01-17 13:19:53,654 iteration 6712 : loss : 0.012339, loss_ce: 0.004781
2022-01-17 13:19:54,545 iteration 6713 : loss : 0.012664, loss_ce: 0.004045
2022-01-17 13:19:55,446 iteration 6714 : loss : 0.013110, loss_ce: 0.005163
2022-01-17 13:19:55,446 Training Data Eval:
2022-01-17 13:19:59,817   Average segmentation loss on training set: 0.0074
2022-01-17 13:19:59,818 Validation Data Eval:
2022-01-17 13:20:01,313   Average segmentation loss on validation set: 0.0799
2022-01-17 13:20:02,202 iteration 6715 : loss : 0.008337, loss_ce: 0.002351
 99%|████████████████████████████▋| 395/400 [1:54:12<01:28, 17.69s/it]2022-01-17 13:20:03,098 iteration 6716 : loss : 0.010339, loss_ce: 0.003489
2022-01-17 13:20:04,040 iteration 6717 : loss : 0.015628, loss_ce: 0.004377
2022-01-17 13:20:05,013 iteration 6718 : loss : 0.021420, loss_ce: 0.009368
2022-01-17 13:20:05,966 iteration 6719 : loss : 0.019994, loss_ce: 0.006746
2022-01-17 13:20:06,898 iteration 6720 : loss : 0.025063, loss_ce: 0.005497
2022-01-17 13:20:07,840 iteration 6721 : loss : 0.014910, loss_ce: 0.006419
2022-01-17 13:20:08,735 iteration 6722 : loss : 0.015245, loss_ce: 0.006136
2022-01-17 13:20:09,660 iteration 6723 : loss : 0.016161, loss_ce: 0.006124
2022-01-17 13:20:10,527 iteration 6724 : loss : 0.012995, loss_ce: 0.004833
2022-01-17 13:20:11,436 iteration 6725 : loss : 0.009396, loss_ce: 0.003071
2022-01-17 13:20:12,281 iteration 6726 : loss : 0.009144, loss_ce: 0.003008
2022-01-17 13:20:13,296 iteration 6727 : loss : 0.020932, loss_ce: 0.006730
2022-01-17 13:20:14,175 iteration 6728 : loss : 0.016299, loss_ce: 0.006788
2022-01-17 13:20:15,129 iteration 6729 : loss : 0.020270, loss_ce: 0.006192
2022-01-17 13:20:16,125 iteration 6730 : loss : 0.015165, loss_ce: 0.005932
2022-01-17 13:20:17,068 iteration 6731 : loss : 0.015277, loss_ce: 0.005200
2022-01-17 13:20:17,961 iteration 6732 : loss : 0.009925, loss_ce: 0.004302
 99%|████████████████████████████▋| 396/400 [1:54:27<01:08, 17.11s/it]2022-01-17 13:20:18,862 iteration 6733 : loss : 0.008488, loss_ce: 0.003481
2022-01-17 13:20:19,755 iteration 6734 : loss : 0.013071, loss_ce: 0.003283
2022-01-17 13:20:20,694 iteration 6735 : loss : 0.016592, loss_ce: 0.004875
2022-01-17 13:20:21,591 iteration 6736 : loss : 0.011929, loss_ce: 0.005297
2022-01-17 13:20:22,449 iteration 6737 : loss : 0.014448, loss_ce: 0.006956
2022-01-17 13:20:23,298 iteration 6738 : loss : 0.010676, loss_ce: 0.003206
2022-01-17 13:20:24,219 iteration 6739 : loss : 0.012048, loss_ce: 0.005367
2022-01-17 13:20:25,170 iteration 6740 : loss : 0.017473, loss_ce: 0.006966
2022-01-17 13:20:26,102 iteration 6741 : loss : 0.014363, loss_ce: 0.005889
2022-01-17 13:20:26,998 iteration 6742 : loss : 0.011917, loss_ce: 0.005517
2022-01-17 13:20:27,860 iteration 6743 : loss : 0.011400, loss_ce: 0.002513
2022-01-17 13:20:28,809 iteration 6744 : loss : 0.018591, loss_ce: 0.007515
2022-01-17 13:20:29,711 iteration 6745 : loss : 0.011506, loss_ce: 0.005084
2022-01-17 13:20:30,554 iteration 6746 : loss : 0.008398, loss_ce: 0.002291
2022-01-17 13:20:31,425 iteration 6747 : loss : 0.008599, loss_ce: 0.002812
2022-01-17 13:20:32,362 iteration 6748 : loss : 0.012053, loss_ce: 0.005092
2022-01-17 13:20:33,269 iteration 6749 : loss : 0.010671, loss_ce: 0.002832
 99%|████████████████████████████▊| 397/400 [1:54:43<00:49, 16.57s/it]2022-01-17 13:20:34,225 iteration 6750 : loss : 0.009861, loss_ce: 0.004401
2022-01-17 13:20:35,196 iteration 6751 : loss : 0.009690, loss_ce: 0.003577
2022-01-17 13:20:36,036 iteration 6752 : loss : 0.012694, loss_ce: 0.003984
2022-01-17 13:20:36,942 iteration 6753 : loss : 0.012042, loss_ce: 0.005326
2022-01-17 13:20:37,881 iteration 6754 : loss : 0.012118, loss_ce: 0.004081
2022-01-17 13:20:38,761 iteration 6755 : loss : 0.010471, loss_ce: 0.003020
2022-01-17 13:20:39,641 iteration 6756 : loss : 0.014293, loss_ce: 0.006277
2022-01-17 13:20:40,621 iteration 6757 : loss : 0.011723, loss_ce: 0.003630
2022-01-17 13:20:41,502 iteration 6758 : loss : 0.017398, loss_ce: 0.007520
2022-01-17 13:20:42,427 iteration 6759 : loss : 0.010587, loss_ce: 0.004587
2022-01-17 13:20:43,401 iteration 6760 : loss : 0.024064, loss_ce: 0.004455
2022-01-17 13:20:44,307 iteration 6761 : loss : 0.015011, loss_ce: 0.005417
2022-01-17 13:20:45,200 iteration 6762 : loss : 0.015863, loss_ce: 0.006009
2022-01-17 13:20:46,159 iteration 6763 : loss : 0.019228, loss_ce: 0.008099
2022-01-17 13:20:47,034 iteration 6764 : loss : 0.013859, loss_ce: 0.005302
2022-01-17 13:20:47,998 iteration 6765 : loss : 0.012793, loss_ce: 0.004588
2022-01-17 13:20:48,875 iteration 6766 : loss : 0.009641, loss_ce: 0.004578
100%|████████████████████████████▊| 398/400 [1:54:58<00:32, 16.28s/it]2022-01-17 13:20:49,826 iteration 6767 : loss : 0.013607, loss_ce: 0.004782
2022-01-17 13:20:50,813 iteration 6768 : loss : 0.014076, loss_ce: 0.004883
2022-01-17 13:20:51,735 iteration 6769 : loss : 0.013393, loss_ce: 0.005573
2022-01-17 13:20:52,623 iteration 6770 : loss : 0.013984, loss_ce: 0.006521
2022-01-17 13:20:53,619 iteration 6771 : loss : 0.021093, loss_ce: 0.004714
2022-01-17 13:20:54,491 iteration 6772 : loss : 0.011322, loss_ce: 0.004166
2022-01-17 13:20:55,277 iteration 6773 : loss : 0.010035, loss_ce: 0.002998
2022-01-17 13:20:56,208 iteration 6774 : loss : 0.022051, loss_ce: 0.007002
2022-01-17 13:20:57,151 iteration 6775 : loss : 0.013876, loss_ce: 0.004069
2022-01-17 13:20:58,053 iteration 6776 : loss : 0.015345, loss_ce: 0.005291
2022-01-17 13:20:59,040 iteration 6777 : loss : 0.015550, loss_ce: 0.008015
2022-01-17 13:20:59,938 iteration 6778 : loss : 0.009514, loss_ce: 0.003075
2022-01-17 13:21:00,921 iteration 6779 : loss : 0.015127, loss_ce: 0.005606
2022-01-17 13:21:01,844 iteration 6780 : loss : 0.011685, loss_ce: 0.005294
2022-01-17 13:21:02,795 iteration 6781 : loss : 0.012659, loss_ce: 0.005234
2022-01-17 13:21:03,747 iteration 6782 : loss : 0.012140, loss_ce: 0.004597
2022-01-17 13:21:04,630 iteration 6783 : loss : 0.013737, loss_ce: 0.004922
100%|████████████████████████████▉| 399/400 [1:55:14<00:16, 16.12s/it]2022-01-17 13:21:05,654 iteration 6784 : loss : 0.014842, loss_ce: 0.004863
2022-01-17 13:21:06,588 iteration 6785 : loss : 0.017705, loss_ce: 0.006147
2022-01-17 13:21:07,447 iteration 6786 : loss : 0.010042, loss_ce: 0.003944
2022-01-17 13:21:08,321 iteration 6787 : loss : 0.010797, loss_ce: 0.003777
2022-01-17 13:21:09,248 iteration 6788 : loss : 0.012847, loss_ce: 0.006510
2022-01-17 13:21:10,164 iteration 6789 : loss : 0.013167, loss_ce: 0.003850
2022-01-17 13:21:11,056 iteration 6790 : loss : 0.011946, loss_ce: 0.005147
2022-01-17 13:21:11,988 iteration 6791 : loss : 0.012320, loss_ce: 0.004553
2022-01-17 13:21:12,853 iteration 6792 : loss : 0.013084, loss_ce: 0.005994
2022-01-17 13:21:13,836 iteration 6793 : loss : 0.018602, loss_ce: 0.006152
2022-01-17 13:21:14,754 iteration 6794 : loss : 0.021230, loss_ce: 0.007315
2022-01-17 13:21:15,704 iteration 6795 : loss : 0.013464, loss_ce: 0.004426
2022-01-17 13:21:16,675 iteration 6796 : loss : 0.012888, loss_ce: 0.006334
2022-01-17 13:21:17,515 iteration 6797 : loss : 0.012002, loss_ce: 0.003682
2022-01-17 13:21:18,463 iteration 6798 : loss : 0.014238, loss_ce: 0.004615
2022-01-17 13:21:19,463 iteration 6799 : loss : 0.015753, loss_ce: 0.007007
2022-01-17 13:21:19,463 Training Data Eval:
2022-01-17 13:21:23,862   Average segmentation loss on training set: 0.0071
2022-01-17 13:21:23,862 Validation Data Eval:
2022-01-17 13:21:25,350   Average segmentation loss on validation set: 0.0774
2022-01-17 13:21:26,228 iteration 6800 : loss : 0.009895, loss_ce: 0.002410
100%|█████████████████████████████| 400/400 [1:55:36<00:00, 17.77s/it]100%|█████████████████████████████| 400/400 [1:55:36<00:00, 17.34s/it]
