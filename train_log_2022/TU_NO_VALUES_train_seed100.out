2022-01-09 11:24:20,796 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-09 11:24:20,797 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-09 11:24:20,797 ============================================================
2022-01-09 11:24:20,797 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-09 11:24:20,797 ============================================================
2022-01-09 11:24:20,797 Loading data...
2022-01-09 11:24:20,797 Reading NCI - RUNMC images...
2022-01-09 11:24:20,797 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-09 11:24:20,799 Already preprocessed this configuration. Loading now!
2022-01-09 11:24:20,817 Training Images: (256, 256, 286)
2022-01-09 11:24:20,817 Training Labels: (256, 256, 286)
2022-01-09 11:24:20,817 Validation Images: (256, 256, 98)
2022-01-09 11:24:20,817 Validation Labels: (256, 256, 98)
2022-01-09 11:24:20,817 ============================================================
2022-01-09 11:24:20,845 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-09 11:24:23,455 iteration 1 : loss : 0.767216, loss_ce: 0.862417
2022-01-09 11:24:24,842 iteration 2 : loss : 0.726907, loss_ce: 0.777426
2022-01-09 11:24:26,204 iteration 3 : loss : 0.684242, loss_ce: 0.688064
2022-01-09 11:24:27,615 iteration 4 : loss : 0.631409, loss_ce: 0.640934
2022-01-09 11:24:28,960 iteration 5 : loss : 0.605140, loss_ce: 0.564661
2022-01-09 11:24:30,415 iteration 6 : loss : 0.562328, loss_ce: 0.513226
2022-01-09 11:24:31,837 iteration 7 : loss : 0.548059, loss_ce: 0.474642
2022-01-09 11:24:33,268 iteration 8 : loss : 0.512022, loss_ce: 0.423386
2022-01-09 11:24:34,589 iteration 9 : loss : 0.473756, loss_ce: 0.400419
2022-01-09 11:24:36,025 iteration 10 : loss : 0.465380, loss_ce: 0.367269
2022-01-09 11:24:37,465 iteration 11 : loss : 0.441495, loss_ce: 0.326426
2022-01-09 11:24:38,940 iteration 12 : loss : 0.425358, loss_ce: 0.309941
2022-01-09 11:24:40,323 iteration 13 : loss : 0.400759, loss_ce: 0.272504
2022-01-09 11:24:41,809 iteration 14 : loss : 0.396017, loss_ce: 0.262669
2022-01-09 11:24:43,223 iteration 15 : loss : 0.368836, loss_ce: 0.231898
2022-01-09 11:24:44,617 iteration 16 : loss : 0.372216, loss_ce: 0.231088
2022-01-09 11:24:45,983 iteration 17 : loss : 0.363322, loss_ce: 0.191989
  0%|                               | 1/400 [00:25<2:47:34, 25.20s/it]2022-01-09 11:24:47,482 iteration 18 : loss : 0.344310, loss_ce: 0.195387
2022-01-09 11:24:48,915 iteration 19 : loss : 0.343150, loss_ce: 0.172416
2022-01-09 11:24:50,440 iteration 20 : loss : 0.316709, loss_ce: 0.176624
2022-01-09 11:24:51,836 iteration 21 : loss : 0.345063, loss_ce: 0.170329
2022-01-09 11:24:53,186 iteration 22 : loss : 0.312941, loss_ce: 0.153149
2022-01-09 11:24:54,675 iteration 23 : loss : 0.327974, loss_ce: 0.153219
2022-01-09 11:24:56,159 iteration 24 : loss : 0.291819, loss_ce: 0.146753
2022-01-09 11:24:57,675 iteration 25 : loss : 0.326252, loss_ce: 0.183894
2022-01-09 11:24:59,237 iteration 26 : loss : 0.305268, loss_ce: 0.159533
2022-01-09 11:25:00,608 iteration 27 : loss : 0.317444, loss_ce: 0.153957
2022-01-09 11:25:01,953 iteration 28 : loss : 0.266756, loss_ce: 0.119825
2022-01-09 11:25:03,392 iteration 29 : loss : 0.326131, loss_ce: 0.156068
2022-01-09 11:25:04,767 iteration 30 : loss : 0.273309, loss_ce: 0.126102
2022-01-09 11:25:06,133 iteration 31 : loss : 0.268335, loss_ce: 0.106963
2022-01-09 11:25:07,526 iteration 32 : loss : 0.292647, loss_ce: 0.156022
2022-01-09 11:25:08,976 iteration 33 : loss : 0.300202, loss_ce: 0.142856
2022-01-09 11:25:10,496 iteration 34 : loss : 0.232952, loss_ce: 0.100621
  0%|▏                              | 2/400 [00:49<2:44:24, 24.79s/it]2022-01-09 11:25:11,994 iteration 35 : loss : 0.243869, loss_ce: 0.112606
2022-01-09 11:25:13,422 iteration 36 : loss : 0.272930, loss_ce: 0.094541
2022-01-09 11:25:14,882 iteration 37 : loss : 0.252716, loss_ce: 0.097918
2022-01-09 11:25:16,311 iteration 38 : loss : 0.268445, loss_ce: 0.108882
2022-01-09 11:25:17,643 iteration 39 : loss : 0.285199, loss_ce: 0.125271
2022-01-09 11:25:19,047 iteration 40 : loss : 0.314035, loss_ce: 0.148195
2022-01-09 11:25:20,375 iteration 41 : loss : 0.199902, loss_ce: 0.091513
2022-01-09 11:25:21,826 iteration 42 : loss : 0.269151, loss_ce: 0.132189
2022-01-09 11:25:23,244 iteration 43 : loss : 0.245735, loss_ce: 0.108524
2022-01-09 11:25:24,583 iteration 44 : loss : 0.248513, loss_ce: 0.129567
2022-01-09 11:25:26,081 iteration 45 : loss : 0.269856, loss_ce: 0.109147
2022-01-09 11:25:27,508 iteration 46 : loss : 0.237137, loss_ce: 0.102987
2022-01-09 11:25:28,942 iteration 47 : loss : 0.240658, loss_ce: 0.088935
2022-01-09 11:25:30,362 iteration 48 : loss : 0.237119, loss_ce: 0.103957
2022-01-09 11:25:31,839 iteration 49 : loss : 0.292716, loss_ce: 0.130147
2022-01-09 11:25:33,302 iteration 50 : loss : 0.226996, loss_ce: 0.091690
2022-01-09 11:25:34,800 iteration 51 : loss : 0.223438, loss_ce: 0.093339
  1%|▏                              | 3/400 [01:14<2:42:33, 24.57s/it]2022-01-09 11:25:36,253 iteration 52 : loss : 0.279365, loss_ce: 0.106258
2022-01-09 11:25:37,705 iteration 53 : loss : 0.232209, loss_ce: 0.106408
2022-01-09 11:25:39,305 iteration 54 : loss : 0.232217, loss_ce: 0.092399
2022-01-09 11:25:40,890 iteration 55 : loss : 0.290666, loss_ce: 0.110156
2022-01-09 11:25:42,480 iteration 56 : loss : 0.257336, loss_ce: 0.125281
2022-01-09 11:25:44,011 iteration 57 : loss : 0.261179, loss_ce: 0.125129
2022-01-09 11:25:45,516 iteration 58 : loss : 0.264336, loss_ce: 0.127535
2022-01-09 11:25:47,022 iteration 59 : loss : 0.220798, loss_ce: 0.097075
2022-01-09 11:25:48,551 iteration 60 : loss : 0.204110, loss_ce: 0.094221
2022-01-09 11:25:50,100 iteration 61 : loss : 0.254604, loss_ce: 0.113167
2022-01-09 11:25:51,720 iteration 62 : loss : 0.297622, loss_ce: 0.114791
2022-01-09 11:25:53,241 iteration 63 : loss : 0.268154, loss_ce: 0.118690
2022-01-09 11:25:54,812 iteration 64 : loss : 0.312986, loss_ce: 0.124808
2022-01-09 11:25:56,381 iteration 65 : loss : 0.222715, loss_ce: 0.081395
2022-01-09 11:25:58,002 iteration 66 : loss : 0.271306, loss_ce: 0.112693
2022-01-09 11:25:59,548 iteration 67 : loss : 0.241628, loss_ce: 0.109904
2022-01-09 11:26:01,036 iteration 68 : loss : 0.232403, loss_ce: 0.108371
  1%|▎                              | 4/400 [01:40<2:46:28, 25.22s/it]2022-01-09 11:26:02,668 iteration 69 : loss : 0.282678, loss_ce: 0.130152
2022-01-09 11:26:04,206 iteration 70 : loss : 0.268130, loss_ce: 0.111820
2022-01-09 11:26:05,765 iteration 71 : loss : 0.263637, loss_ce: 0.135057
2022-01-09 11:26:07,335 iteration 72 : loss : 0.248664, loss_ce: 0.110825
2022-01-09 11:26:08,920 iteration 73 : loss : 0.237353, loss_ce: 0.093606
2022-01-09 11:26:10,500 iteration 74 : loss : 0.202887, loss_ce: 0.081064
2022-01-09 11:26:12,031 iteration 75 : loss : 0.208252, loss_ce: 0.101972
2022-01-09 11:26:13,514 iteration 76 : loss : 0.224306, loss_ce: 0.104254
2022-01-09 11:26:15,073 iteration 77 : loss : 0.249657, loss_ce: 0.110432
2022-01-09 11:26:16,637 iteration 78 : loss : 0.220855, loss_ce: 0.081228
2022-01-09 11:26:18,213 iteration 79 : loss : 0.267981, loss_ce: 0.108095
2022-01-09 11:26:19,677 iteration 80 : loss : 0.224171, loss_ce: 0.091006
2022-01-09 11:26:21,311 iteration 81 : loss : 0.268940, loss_ce: 0.122488
2022-01-09 11:26:22,863 iteration 82 : loss : 0.274378, loss_ce: 0.090828
2022-01-09 11:26:24,363 iteration 83 : loss : 0.297348, loss_ce: 0.089673
2022-01-09 11:26:26,016 iteration 84 : loss : 0.305291, loss_ce: 0.130802
2022-01-09 11:26:26,016 Training Data Eval:
2022-01-09 11:26:33,874   Average segmentation loss on training set: 0.2830
2022-01-09 11:26:33,874 Validation Data Eval:
2022-01-09 11:26:36,745   Average segmentation loss on validation set: 0.2453
2022-01-09 11:26:42,565 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 11:26:43,972 iteration 85 : loss : 0.290715, loss_ce: 0.136318
  1%|▍                              | 5/400 [02:23<3:28:07, 31.61s/it]2022-01-09 11:26:45,477 iteration 86 : loss : 0.232740, loss_ce: 0.103872
2022-01-09 11:26:46,886 iteration 87 : loss : 0.234329, loss_ce: 0.094354
2022-01-09 11:26:48,281 iteration 88 : loss : 0.214021, loss_ce: 0.106619
2022-01-09 11:26:49,835 iteration 89 : loss : 0.273587, loss_ce: 0.106963
2022-01-09 11:26:51,383 iteration 90 : loss : 0.215085, loss_ce: 0.097522
2022-01-09 11:26:52,993 iteration 91 : loss : 0.224843, loss_ce: 0.110541
2022-01-09 11:26:54,614 iteration 92 : loss : 0.208075, loss_ce: 0.080446
2022-01-09 11:26:56,123 iteration 93 : loss : 0.210485, loss_ce: 0.072722
2022-01-09 11:26:57,724 iteration 94 : loss : 0.205859, loss_ce: 0.091691
2022-01-09 11:26:59,273 iteration 95 : loss : 0.251286, loss_ce: 0.121658
2022-01-09 11:27:00,893 iteration 96 : loss : 0.198213, loss_ce: 0.075431
2022-01-09 11:27:02,454 iteration 97 : loss : 0.250495, loss_ce: 0.096522
2022-01-09 11:27:04,059 iteration 98 : loss : 0.265744, loss_ce: 0.103021
2022-01-09 11:27:05,611 iteration 99 : loss : 0.275686, loss_ce: 0.111676
2022-01-09 11:27:07,210 iteration 100 : loss : 0.232049, loss_ce: 0.106208
2022-01-09 11:27:08,752 iteration 101 : loss : 0.215268, loss_ce: 0.095660
2022-01-09 11:27:10,274 iteration 102 : loss : 0.224626, loss_ce: 0.110545
  2%|▍                              | 6/400 [02:49<3:15:43, 29.81s/it]2022-01-09 11:27:11,902 iteration 103 : loss : 0.254485, loss_ce: 0.097857
2022-01-09 11:27:13,516 iteration 104 : loss : 0.227171, loss_ce: 0.096805
2022-01-09 11:27:15,121 iteration 105 : loss : 0.169757, loss_ce: 0.065881
2022-01-09 11:27:16,809 iteration 106 : loss : 0.221739, loss_ce: 0.081854
2022-01-09 11:27:18,413 iteration 107 : loss : 0.251329, loss_ce: 0.084062
2022-01-09 11:27:19,960 iteration 108 : loss : 0.230243, loss_ce: 0.072126
2022-01-09 11:27:21,449 iteration 109 : loss : 0.268969, loss_ce: 0.105013
2022-01-09 11:27:22,975 iteration 110 : loss : 0.223040, loss_ce: 0.091380
2022-01-09 11:27:24,608 iteration 111 : loss : 0.204767, loss_ce: 0.085448
2022-01-09 11:27:26,154 iteration 112 : loss : 0.217516, loss_ce: 0.082654
2022-01-09 11:27:27,657 iteration 113 : loss : 0.202874, loss_ce: 0.076848
2022-01-09 11:27:29,242 iteration 114 : loss : 0.232359, loss_ce: 0.081722
2022-01-09 11:27:30,783 iteration 115 : loss : 0.193839, loss_ce: 0.094611
2022-01-09 11:27:32,374 iteration 116 : loss : 0.235546, loss_ce: 0.117867
2022-01-09 11:27:33,902 iteration 117 : loss : 0.234939, loss_ce: 0.101318
2022-01-09 11:27:35,436 iteration 118 : loss : 0.268571, loss_ce: 0.136163
2022-01-09 11:27:37,002 iteration 119 : loss : 0.204771, loss_ce: 0.083805
  2%|▌                              | 7/400 [03:16<3:08:38, 28.80s/it]2022-01-09 11:27:38,666 iteration 120 : loss : 0.211164, loss_ce: 0.096564
2022-01-09 11:27:40,267 iteration 121 : loss : 0.291265, loss_ce: 0.125316
2022-01-09 11:27:41,760 iteration 122 : loss : 0.220651, loss_ce: 0.102490
2022-01-09 11:27:43,367 iteration 123 : loss : 0.214181, loss_ce: 0.095308
2022-01-09 11:27:44,976 iteration 124 : loss : 0.275324, loss_ce: 0.109441
2022-01-09 11:27:46,526 iteration 125 : loss : 0.215907, loss_ce: 0.105457
2022-01-09 11:27:48,129 iteration 126 : loss : 0.296652, loss_ce: 0.122395
2022-01-09 11:27:49,739 iteration 127 : loss : 0.195571, loss_ce: 0.089496
2022-01-09 11:27:51,372 iteration 128 : loss : 0.156615, loss_ce: 0.074605
2022-01-09 11:27:52,913 iteration 129 : loss : 0.215698, loss_ce: 0.083722
2022-01-09 11:27:54,538 iteration 130 : loss : 0.220238, loss_ce: 0.106514
2022-01-09 11:27:56,126 iteration 131 : loss : 0.220319, loss_ce: 0.104669
2022-01-09 11:27:57,660 iteration 132 : loss : 0.227324, loss_ce: 0.086086
2022-01-09 11:27:59,277 iteration 133 : loss : 0.220847, loss_ce: 0.074852
2022-01-09 11:28:00,855 iteration 134 : loss : 0.233470, loss_ce: 0.091764
2022-01-09 11:28:02,450 iteration 135 : loss : 0.204144, loss_ce: 0.091062
2022-01-09 11:28:03,994 iteration 136 : loss : 0.246260, loss_ce: 0.115244
  2%|▌                              | 8/400 [03:43<3:04:23, 28.22s/it]2022-01-09 11:28:05,532 iteration 137 : loss : 0.161554, loss_ce: 0.051066
2022-01-09 11:28:07,052 iteration 138 : loss : 0.249273, loss_ce: 0.130986
2022-01-09 11:28:08,676 iteration 139 : loss : 0.209688, loss_ce: 0.077049
2022-01-09 11:28:10,325 iteration 140 : loss : 0.273043, loss_ce: 0.104566
2022-01-09 11:28:11,909 iteration 141 : loss : 0.252077, loss_ce: 0.091456
2022-01-09 11:28:13,424 iteration 142 : loss : 0.194401, loss_ce: 0.073321
2022-01-09 11:28:14,941 iteration 143 : loss : 0.205375, loss_ce: 0.086401
2022-01-09 11:28:16,536 iteration 144 : loss : 0.252798, loss_ce: 0.096614
2022-01-09 11:28:18,274 iteration 145 : loss : 0.213049, loss_ce: 0.101232
2022-01-09 11:28:19,817 iteration 146 : loss : 0.238639, loss_ce: 0.086033
2022-01-09 11:28:21,362 iteration 147 : loss : 0.239119, loss_ce: 0.101759
2022-01-09 11:28:22,939 iteration 148 : loss : 0.211926, loss_ce: 0.105294
2022-01-09 11:28:24,522 iteration 149 : loss : 0.215787, loss_ce: 0.089180
2022-01-09 11:28:26,069 iteration 150 : loss : 0.286849, loss_ce: 0.138189
2022-01-09 11:28:27,639 iteration 151 : loss : 0.189951, loss_ce: 0.085752
2022-01-09 11:28:29,266 iteration 152 : loss : 0.223893, loss_ce: 0.096367
2022-01-09 11:28:30,886 iteration 153 : loss : 0.195760, loss_ce: 0.091439
  2%|▋                              | 9/400 [04:10<3:01:12, 27.81s/it]2022-01-09 11:28:32,501 iteration 154 : loss : 0.178957, loss_ce: 0.072351
2022-01-09 11:28:34,101 iteration 155 : loss : 0.255964, loss_ce: 0.106408
2022-01-09 11:28:35,688 iteration 156 : loss : 0.185338, loss_ce: 0.078935
2022-01-09 11:28:37,279 iteration 157 : loss : 0.246962, loss_ce: 0.088335
2022-01-09 11:28:38,864 iteration 158 : loss : 0.253486, loss_ce: 0.120798
2022-01-09 11:28:40,436 iteration 159 : loss : 0.215416, loss_ce: 0.093075
2022-01-09 11:28:41,998 iteration 160 : loss : 0.270492, loss_ce: 0.089684
2022-01-09 11:28:43,599 iteration 161 : loss : 0.214364, loss_ce: 0.092755
2022-01-09 11:28:45,268 iteration 162 : loss : 0.192693, loss_ce: 0.089886
2022-01-09 11:28:46,750 iteration 163 : loss : 0.172327, loss_ce: 0.073028
2022-01-09 11:28:48,368 iteration 164 : loss : 0.176433, loss_ce: 0.073230
2022-01-09 11:28:49,918 iteration 165 : loss : 0.193251, loss_ce: 0.073878
2022-01-09 11:28:51,545 iteration 166 : loss : 0.211395, loss_ce: 0.085974
2022-01-09 11:28:53,175 iteration 167 : loss : 0.227916, loss_ce: 0.109847
2022-01-09 11:28:54,791 iteration 168 : loss : 0.226015, loss_ce: 0.101114
2022-01-09 11:28:56,371 iteration 169 : loss : 0.230969, loss_ce: 0.108031
2022-01-09 11:28:56,371 Training Data Eval:
2022-01-09 11:29:04,251   Average segmentation loss on training set: 0.4659
2022-01-09 11:29:04,251 Validation Data Eval:
2022-01-09 11:29:06,974   Average segmentation loss on validation set: 0.4604
2022-01-09 11:29:08,494 iteration 170 : loss : 0.218113, loss_ce: 0.097973
  2%|▊                             | 10/400 [04:47<3:20:25, 30.83s/it]2022-01-09 11:29:10,123 iteration 171 : loss : 0.279049, loss_ce: 0.140189
2022-01-09 11:29:11,575 iteration 172 : loss : 0.296790, loss_ce: 0.117704
2022-01-09 11:29:13,068 iteration 173 : loss : 0.181407, loss_ce: 0.078101
2022-01-09 11:29:14,694 iteration 174 : loss : 0.243210, loss_ce: 0.104087
2022-01-09 11:29:16,239 iteration 175 : loss : 0.244855, loss_ce: 0.106501
2022-01-09 11:29:17,888 iteration 176 : loss : 0.197377, loss_ce: 0.079037
2022-01-09 11:29:19,449 iteration 177 : loss : 0.293570, loss_ce: 0.104972
2022-01-09 11:29:21,058 iteration 178 : loss : 0.217824, loss_ce: 0.074571
2022-01-09 11:29:22,659 iteration 179 : loss : 0.217086, loss_ce: 0.086293
2022-01-09 11:29:24,268 iteration 180 : loss : 0.203403, loss_ce: 0.066083
2022-01-09 11:29:25,878 iteration 181 : loss : 0.168076, loss_ce: 0.059009
2022-01-09 11:29:27,471 iteration 182 : loss : 0.171449, loss_ce: 0.064292
2022-01-09 11:29:29,079 iteration 183 : loss : 0.178782, loss_ce: 0.071689
2022-01-09 11:29:30,656 iteration 184 : loss : 0.189107, loss_ce: 0.078595
2022-01-09 11:29:32,181 iteration 185 : loss : 0.224864, loss_ce: 0.111426
2022-01-09 11:29:33,710 iteration 186 : loss : 0.175831, loss_ce: 0.078803
2022-01-09 11:29:35,216 iteration 187 : loss : 0.250577, loss_ce: 0.121740
  3%|▊                             | 11/400 [05:14<3:11:44, 29.57s/it]2022-01-09 11:29:36,836 iteration 188 : loss : 0.337908, loss_ce: 0.139348
2022-01-09 11:29:38,449 iteration 189 : loss : 0.209647, loss_ce: 0.089679
2022-01-09 11:29:40,087 iteration 190 : loss : 0.215711, loss_ce: 0.071923
2022-01-09 11:29:41,661 iteration 191 : loss : 0.223040, loss_ce: 0.098057
2022-01-09 11:29:43,138 iteration 192 : loss : 0.145928, loss_ce: 0.063995
2022-01-09 11:29:44,658 iteration 193 : loss : 0.262202, loss_ce: 0.107985
2022-01-09 11:29:46,163 iteration 194 : loss : 0.270564, loss_ce: 0.116379
2022-01-09 11:29:47,820 iteration 195 : loss : 0.166610, loss_ce: 0.068888
2022-01-09 11:29:49,428 iteration 196 : loss : 0.192251, loss_ce: 0.065815
2022-01-09 11:29:51,007 iteration 197 : loss : 0.189866, loss_ce: 0.075305
2022-01-09 11:29:52,615 iteration 198 : loss : 0.209710, loss_ce: 0.094596
2022-01-09 11:29:54,214 iteration 199 : loss : 0.171253, loss_ce: 0.079641
2022-01-09 11:29:55,770 iteration 200 : loss : 0.234470, loss_ce: 0.085229
2022-01-09 11:29:57,332 iteration 201 : loss : 0.220436, loss_ce: 0.091165
2022-01-09 11:29:58,789 iteration 202 : loss : 0.221861, loss_ce: 0.075834
2022-01-09 11:30:00,414 iteration 203 : loss : 0.155374, loss_ce: 0.063045
2022-01-09 11:30:01,970 iteration 204 : loss : 0.195880, loss_ce: 0.097843
  3%|▉                             | 12/400 [05:41<3:05:43, 28.72s/it]2022-01-09 11:30:03,667 iteration 205 : loss : 0.198733, loss_ce: 0.078517
2022-01-09 11:30:05,256 iteration 206 : loss : 0.333613, loss_ce: 0.143892
2022-01-09 11:30:06,915 iteration 207 : loss : 0.266327, loss_ce: 0.099438
2022-01-09 11:30:08,558 iteration 208 : loss : 0.248120, loss_ce: 0.116567
2022-01-09 11:30:10,162 iteration 209 : loss : 0.186081, loss_ce: 0.076182
2022-01-09 11:30:11,725 iteration 210 : loss : 0.225139, loss_ce: 0.105333
2022-01-09 11:30:13,309 iteration 211 : loss : 0.190129, loss_ce: 0.087738
2022-01-09 11:30:14,940 iteration 212 : loss : 0.194815, loss_ce: 0.082552
2022-01-09 11:30:16,565 iteration 213 : loss : 0.211558, loss_ce: 0.095192
2022-01-09 11:30:18,133 iteration 214 : loss : 0.231523, loss_ce: 0.096054
2022-01-09 11:30:19,746 iteration 215 : loss : 0.220942, loss_ce: 0.088360
2022-01-09 11:30:21,590 iteration 216 : loss : 0.162645, loss_ce: 0.067740
2022-01-09 11:30:23,557 iteration 217 : loss : 0.221494, loss_ce: 0.089581
2022-01-09 11:30:25,490 iteration 218 : loss : 0.220961, loss_ce: 0.095290
2022-01-09 11:30:27,441 iteration 219 : loss : 0.233020, loss_ce: 0.104720
2022-01-09 11:30:29,498 iteration 220 : loss : 0.182956, loss_ce: 0.071611
2022-01-09 11:30:31,592 iteration 221 : loss : 0.198331, loss_ce: 0.082809
  3%|▉                             | 13/400 [06:10<3:06:59, 28.99s/it]2022-01-09 11:30:33,702 iteration 222 : loss : 0.158009, loss_ce: 0.066239
2022-01-09 11:30:35,700 iteration 223 : loss : 0.298760, loss_ce: 0.146099
2022-01-09 11:30:37,707 iteration 224 : loss : 0.181910, loss_ce: 0.068190
2022-01-09 11:30:39,876 iteration 225 : loss : 0.177532, loss_ce: 0.081711
2022-01-09 11:30:41,913 iteration 226 : loss : 0.228507, loss_ce: 0.098326
2022-01-09 11:30:43,988 iteration 227 : loss : 0.192262, loss_ce: 0.077929
2022-01-09 11:30:46,086 iteration 228 : loss : 0.194907, loss_ce: 0.070969
2022-01-09 11:30:48,156 iteration 229 : loss : 0.220358, loss_ce: 0.089057
2022-01-09 11:30:50,189 iteration 230 : loss : 0.150909, loss_ce: 0.066074
2022-01-09 11:30:52,234 iteration 231 : loss : 0.198279, loss_ce: 0.084845
2022-01-09 11:30:54,320 iteration 232 : loss : 0.183148, loss_ce: 0.079939
2022-01-09 11:30:56,381 iteration 233 : loss : 0.173744, loss_ce: 0.074063
2022-01-09 11:30:58,559 iteration 234 : loss : 0.238763, loss_ce: 0.089426
2022-01-09 11:31:00,681 iteration 235 : loss : 0.182930, loss_ce: 0.074331
2022-01-09 11:31:02,818 iteration 236 : loss : 0.332083, loss_ce: 0.143374
2022-01-09 11:31:04,868 iteration 237 : loss : 0.275779, loss_ce: 0.131236
2022-01-09 11:31:07,052 iteration 238 : loss : 0.241582, loss_ce: 0.085502
  4%|█                             | 14/400 [06:46<3:19:06, 30.95s/it]2022-01-09 11:31:09,295 iteration 239 : loss : 0.231412, loss_ce: 0.087704
2022-01-09 11:31:11,651 iteration 240 : loss : 0.224483, loss_ce: 0.081358
2022-01-09 11:31:13,895 iteration 241 : loss : 0.204486, loss_ce: 0.090629
2022-01-09 11:31:16,125 iteration 242 : loss : 0.137828, loss_ce: 0.055316
2022-01-09 11:31:18,370 iteration 243 : loss : 0.196478, loss_ce: 0.082013
2022-01-09 11:31:20,583 iteration 244 : loss : 0.194023, loss_ce: 0.075902
2022-01-09 11:31:22,717 iteration 245 : loss : 0.184875, loss_ce: 0.056151
2022-01-09 11:31:24,842 iteration 246 : loss : 0.230510, loss_ce: 0.080216
2022-01-09 11:31:26,992 iteration 247 : loss : 0.205242, loss_ce: 0.088324
2022-01-09 11:31:29,290 iteration 248 : loss : 0.177316, loss_ce: 0.077048
2022-01-09 11:31:31,505 iteration 249 : loss : 0.145272, loss_ce: 0.059663
2022-01-09 11:31:33,788 iteration 250 : loss : 0.202671, loss_ce: 0.071108
2022-01-09 11:31:36,020 iteration 251 : loss : 0.144986, loss_ce: 0.066347
2022-01-09 11:31:38,459 iteration 252 : loss : 0.269739, loss_ce: 0.151828
2022-01-09 11:31:40,824 iteration 253 : loss : 0.162389, loss_ce: 0.061060
2022-01-09 11:31:43,146 iteration 254 : loss : 0.143330, loss_ce: 0.069372
2022-01-09 11:31:43,146 Training Data Eval:
2022-01-09 11:31:55,675   Average segmentation loss on training set: 0.2718
2022-01-09 11:31:55,675 Validation Data Eval:
2022-01-09 11:31:59,980   Average segmentation loss on validation set: 0.3407
2022-01-09 11:32:02,373 iteration 255 : loss : 0.211288, loss_ce: 0.101189
  4%|█▏                            | 15/400 [07:41<4:05:43, 38.29s/it]2022-01-09 11:32:04,800 iteration 256 : loss : 0.169579, loss_ce: 0.068630
2022-01-09 11:32:07,158 iteration 257 : loss : 0.171304, loss_ce: 0.073246
2022-01-09 11:32:09,598 iteration 258 : loss : 0.192425, loss_ce: 0.084646
2022-01-09 11:32:11,913 iteration 259 : loss : 0.185722, loss_ce: 0.080703
2022-01-09 11:32:14,150 iteration 260 : loss : 0.155546, loss_ce: 0.081064
2022-01-09 11:32:16,464 iteration 261 : loss : 0.205809, loss_ce: 0.089552
2022-01-09 11:32:18,862 iteration 262 : loss : 0.280410, loss_ce: 0.133050
2022-01-09 11:32:21,182 iteration 263 : loss : 0.136819, loss_ce: 0.058126
2022-01-09 11:32:23,623 iteration 264 : loss : 0.247389, loss_ce: 0.092770
2022-01-09 11:32:26,032 iteration 265 : loss : 0.218778, loss_ce: 0.123790
2022-01-09 11:32:28,294 iteration 266 : loss : 0.194746, loss_ce: 0.082582
2022-01-09 11:32:30,635 iteration 267 : loss : 0.173363, loss_ce: 0.064257
2022-01-09 11:32:33,015 iteration 268 : loss : 0.208883, loss_ce: 0.081452
2022-01-09 11:32:35,318 iteration 269 : loss : 0.279669, loss_ce: 0.126295
2022-01-09 11:32:37,698 iteration 270 : loss : 0.223892, loss_ce: 0.080902
2022-01-09 11:32:40,016 iteration 271 : loss : 0.227590, loss_ce: 0.104994
2022-01-09 11:32:42,248 iteration 272 : loss : 0.163150, loss_ce: 0.064499
  4%|█▏                            | 16/400 [08:21<4:08:08, 38.77s/it]2022-01-09 11:32:44,638 iteration 273 : loss : 0.183074, loss_ce: 0.066758
2022-01-09 11:32:46,974 iteration 274 : loss : 0.262546, loss_ce: 0.115149
2022-01-09 11:32:49,329 iteration 275 : loss : 0.252642, loss_ce: 0.069102
2022-01-09 11:32:51,702 iteration 276 : loss : 0.145362, loss_ce: 0.057578
2022-01-09 11:32:54,133 iteration 277 : loss : 0.131364, loss_ce: 0.050555
2022-01-09 11:32:56,523 iteration 278 : loss : 0.214705, loss_ce: 0.097643
2022-01-09 11:32:58,866 iteration 279 : loss : 0.236045, loss_ce: 0.097298
2022-01-09 11:33:01,172 iteration 280 : loss : 0.201792, loss_ce: 0.097894
2022-01-09 11:33:03,573 iteration 281 : loss : 0.160840, loss_ce: 0.076196
2022-01-09 11:33:05,943 iteration 282 : loss : 0.126016, loss_ce: 0.046731
2022-01-09 11:33:08,344 iteration 283 : loss : 0.176780, loss_ce: 0.067243
2022-01-09 11:33:10,760 iteration 284 : loss : 0.164069, loss_ce: 0.088350
2022-01-09 11:33:13,284 iteration 285 : loss : 0.172707, loss_ce: 0.057485
2022-01-09 11:33:15,619 iteration 286 : loss : 0.154409, loss_ce: 0.062242
2022-01-09 11:33:17,982 iteration 287 : loss : 0.155173, loss_ce: 0.068719
2022-01-09 11:33:20,390 iteration 288 : loss : 0.146249, loss_ce: 0.055348
2022-01-09 11:33:22,871 iteration 289 : loss : 0.181578, loss_ce: 0.071181
  4%|█▎                            | 17/400 [09:02<4:11:01, 39.33s/it]2022-01-09 11:33:25,339 iteration 290 : loss : 0.208078, loss_ce: 0.080737
2022-01-09 11:33:27,648 iteration 291 : loss : 0.170512, loss_ce: 0.067013
2022-01-09 11:33:29,906 iteration 292 : loss : 0.185686, loss_ce: 0.084439
2022-01-09 11:33:32,251 iteration 293 : loss : 0.164488, loss_ce: 0.068106
2022-01-09 11:33:34,532 iteration 294 : loss : 0.142100, loss_ce: 0.065426
2022-01-09 11:33:36,960 iteration 295 : loss : 0.130491, loss_ce: 0.061306
2022-01-09 11:33:39,372 iteration 296 : loss : 0.189983, loss_ce: 0.080252
2022-01-09 11:33:41,661 iteration 297 : loss : 0.145655, loss_ce: 0.074181
2022-01-09 11:33:43,966 iteration 298 : loss : 0.157506, loss_ce: 0.074761
2022-01-09 11:33:46,245 iteration 299 : loss : 0.168704, loss_ce: 0.070131
2022-01-09 11:33:48,549 iteration 300 : loss : 0.144210, loss_ce: 0.060935
2022-01-09 11:33:50,882 iteration 301 : loss : 0.179556, loss_ce: 0.068267
2022-01-09 11:33:53,329 iteration 302 : loss : 0.175744, loss_ce: 0.069810
2022-01-09 11:33:55,762 iteration 303 : loss : 0.166102, loss_ce: 0.057812
2022-01-09 11:33:58,319 iteration 304 : loss : 0.178609, loss_ce: 0.075480
2022-01-09 11:34:00,961 iteration 305 : loss : 0.151257, loss_ce: 0.062688
2022-01-09 11:34:03,209 iteration 306 : loss : 0.141301, loss_ce: 0.057679
  4%|█▎                            | 18/400 [09:42<4:12:19, 39.63s/it]2022-01-09 11:34:05,443 iteration 307 : loss : 0.233819, loss_ce: 0.084730
2022-01-09 11:34:07,662 iteration 308 : loss : 0.149559, loss_ce: 0.062224
2022-01-09 11:34:09,919 iteration 309 : loss : 0.182434, loss_ce: 0.083706
2022-01-09 11:34:12,297 iteration 310 : loss : 0.200007, loss_ce: 0.080582
2022-01-09 11:34:14,695 iteration 311 : loss : 0.129324, loss_ce: 0.054602
2022-01-09 11:34:17,132 iteration 312 : loss : 0.135989, loss_ce: 0.055463
2022-01-09 11:34:19,541 iteration 313 : loss : 0.167109, loss_ce: 0.071526
2022-01-09 11:34:21,980 iteration 314 : loss : 0.159538, loss_ce: 0.076428
2022-01-09 11:34:24,393 iteration 315 : loss : 0.177586, loss_ce: 0.075597
2022-01-09 11:34:26,816 iteration 316 : loss : 0.175946, loss_ce: 0.069478
2022-01-09 11:34:29,218 iteration 317 : loss : 0.211065, loss_ce: 0.077375
2022-01-09 11:34:31,561 iteration 318 : loss : 0.178936, loss_ce: 0.076121
2022-01-09 11:34:33,929 iteration 319 : loss : 0.143202, loss_ce: 0.060413
2022-01-09 11:34:36,211 iteration 320 : loss : 0.184950, loss_ce: 0.069302
2022-01-09 11:34:38,544 iteration 321 : loss : 0.148476, loss_ce: 0.079349
2022-01-09 11:34:41,103 iteration 322 : loss : 0.162756, loss_ce: 0.074894
2022-01-09 11:34:43,540 iteration 323 : loss : 0.161483, loss_ce: 0.070684
  5%|█▍                            | 19/400 [10:22<4:13:00, 39.84s/it]2022-01-09 11:34:45,879 iteration 324 : loss : 0.193956, loss_ce: 0.080739
2022-01-09 11:34:48,471 iteration 325 : loss : 0.152085, loss_ce: 0.060382
2022-01-09 11:34:50,884 iteration 326 : loss : 0.155317, loss_ce: 0.061195
2022-01-09 11:34:53,314 iteration 327 : loss : 0.203528, loss_ce: 0.085004
2022-01-09 11:34:55,632 iteration 328 : loss : 0.180724, loss_ce: 0.074719
2022-01-09 11:34:57,952 iteration 329 : loss : 0.160510, loss_ce: 0.061709
2022-01-09 11:35:00,232 iteration 330 : loss : 0.152654, loss_ce: 0.063718
2022-01-09 11:35:02,670 iteration 331 : loss : 0.126449, loss_ce: 0.042957
2022-01-09 11:35:05,078 iteration 332 : loss : 0.122014, loss_ce: 0.050280
2022-01-09 11:35:07,391 iteration 333 : loss : 0.213209, loss_ce: 0.088963
2022-01-09 11:35:09,783 iteration 334 : loss : 0.163528, loss_ce: 0.085613
2022-01-09 11:35:12,170 iteration 335 : loss : 0.219349, loss_ce: 0.082350
2022-01-09 11:35:14,603 iteration 336 : loss : 0.156639, loss_ce: 0.064917
2022-01-09 11:35:16,896 iteration 337 : loss : 0.132170, loss_ce: 0.054181
2022-01-09 11:35:19,250 iteration 338 : loss : 0.157160, loss_ce: 0.070277
2022-01-09 11:35:21,675 iteration 339 : loss : 0.143574, loss_ce: 0.052086
2022-01-09 11:35:21,675 Training Data Eval:
2022-01-09 11:35:34,432   Average segmentation loss on training set: 0.3269
2022-01-09 11:35:34,433 Validation Data Eval:
2022-01-09 11:35:38,829   Average segmentation loss on validation set: 0.3576
2022-01-09 11:35:41,262 iteration 340 : loss : 0.156440, loss_ce: 0.056935
  5%|█▌                            | 20/400 [11:20<4:46:19, 45.21s/it]2022-01-09 11:35:43,745 iteration 341 : loss : 0.216211, loss_ce: 0.098156
2022-01-09 11:35:46,197 iteration 342 : loss : 0.166119, loss_ce: 0.077273
2022-01-09 11:35:48,639 iteration 343 : loss : 0.209893, loss_ce: 0.111818
2022-01-09 11:35:50,951 iteration 344 : loss : 0.207863, loss_ce: 0.077090
2022-01-09 11:35:53,341 iteration 345 : loss : 0.218159, loss_ce: 0.092928
2022-01-09 11:35:55,793 iteration 346 : loss : 0.166892, loss_ce: 0.065240
2022-01-09 11:35:58,158 iteration 347 : loss : 0.148034, loss_ce: 0.065662
2022-01-09 11:36:00,658 iteration 348 : loss : 0.135004, loss_ce: 0.057796
2022-01-09 11:36:03,007 iteration 349 : loss : 0.178554, loss_ce: 0.081949
2022-01-09 11:36:05,280 iteration 350 : loss : 0.141188, loss_ce: 0.051035
2022-01-09 11:36:07,731 iteration 351 : loss : 0.144191, loss_ce: 0.051298
2022-01-09 11:36:10,179 iteration 352 : loss : 0.160694, loss_ce: 0.057452
2022-01-09 11:36:12,679 iteration 353 : loss : 0.126115, loss_ce: 0.040869
2022-01-09 11:36:15,026 iteration 354 : loss : 0.183438, loss_ce: 0.084231
2022-01-09 11:36:17,337 iteration 355 : loss : 0.192420, loss_ce: 0.072502
2022-01-09 11:36:19,583 iteration 356 : loss : 0.154003, loss_ce: 0.071257
2022-01-09 11:36:21,953 iteration 357 : loss : 0.165523, loss_ce: 0.070020
  5%|█▌                            | 21/400 [12:01<4:37:00, 43.85s/it]2022-01-09 11:36:24,430 iteration 358 : loss : 0.177260, loss_ce: 0.066950
2022-01-09 11:36:26,807 iteration 359 : loss : 0.114844, loss_ce: 0.062175
2022-01-09 11:36:29,129 iteration 360 : loss : 0.209997, loss_ce: 0.065830
2022-01-09 11:36:31,553 iteration 361 : loss : 0.197604, loss_ce: 0.072272
2022-01-09 11:36:33,867 iteration 362 : loss : 0.146832, loss_ce: 0.056588
2022-01-09 11:36:36,332 iteration 363 : loss : 0.172864, loss_ce: 0.082663
2022-01-09 11:36:38,665 iteration 364 : loss : 0.201023, loss_ce: 0.108191
2022-01-09 11:36:41,021 iteration 365 : loss : 0.142245, loss_ce: 0.055397
2022-01-09 11:36:43,296 iteration 366 : loss : 0.144523, loss_ce: 0.065598
2022-01-09 11:36:45,697 iteration 367 : loss : 0.176221, loss_ce: 0.079016
2022-01-09 11:36:47,946 iteration 368 : loss : 0.146125, loss_ce: 0.043154
2022-01-09 11:36:50,408 iteration 369 : loss : 0.134034, loss_ce: 0.061750
2022-01-09 11:36:52,755 iteration 370 : loss : 0.123460, loss_ce: 0.039741
2022-01-09 11:36:55,188 iteration 371 : loss : 0.140736, loss_ce: 0.072076
2022-01-09 11:36:57,608 iteration 372 : loss : 0.169181, loss_ce: 0.068454
2022-01-09 11:36:59,940 iteration 373 : loss : 0.154921, loss_ce: 0.054825
2022-01-09 11:37:02,309 iteration 374 : loss : 0.137019, loss_ce: 0.057469
  6%|█▋                            | 22/400 [12:41<4:29:39, 42.80s/it]2022-01-09 11:37:04,718 iteration 375 : loss : 0.129911, loss_ce: 0.049183
2022-01-09 11:37:07,029 iteration 376 : loss : 0.144862, loss_ce: 0.059820
2022-01-09 11:37:09,403 iteration 377 : loss : 0.180987, loss_ce: 0.065174
2022-01-09 11:37:11,793 iteration 378 : loss : 0.173072, loss_ce: 0.077715
2022-01-09 11:37:14,141 iteration 379 : loss : 0.172737, loss_ce: 0.064902
2022-01-09 11:37:16,509 iteration 380 : loss : 0.140420, loss_ce: 0.068476
2022-01-09 11:37:18,784 iteration 381 : loss : 0.092284, loss_ce: 0.035838
2022-01-09 11:37:21,257 iteration 382 : loss : 0.137796, loss_ce: 0.066283
2022-01-09 11:37:23,630 iteration 383 : loss : 0.139234, loss_ce: 0.059178
2022-01-09 11:37:25,964 iteration 384 : loss : 0.120869, loss_ce: 0.050088
2022-01-09 11:37:28,358 iteration 385 : loss : 0.127888, loss_ce: 0.052102
2022-01-09 11:37:30,763 iteration 386 : loss : 0.170418, loss_ce: 0.067978
2022-01-09 11:37:33,151 iteration 387 : loss : 0.155303, loss_ce: 0.061263
2022-01-09 11:37:35,503 iteration 388 : loss : 0.116450, loss_ce: 0.049207
2022-01-09 11:37:37,804 iteration 389 : loss : 0.161756, loss_ce: 0.053725
2022-01-09 11:37:40,145 iteration 390 : loss : 0.152769, loss_ce: 0.078446
2022-01-09 11:37:42,477 iteration 391 : loss : 0.166165, loss_ce: 0.060862
  6%|█▋                            | 23/400 [13:21<4:23:58, 42.01s/it]2022-01-09 11:37:44,913 iteration 392 : loss : 0.125286, loss_ce: 0.055068
2022-01-09 11:37:47,236 iteration 393 : loss : 0.138670, loss_ce: 0.068033
2022-01-09 11:37:49,556 iteration 394 : loss : 0.170594, loss_ce: 0.072296
2022-01-09 11:37:51,817 iteration 395 : loss : 0.183170, loss_ce: 0.085279
2022-01-09 11:37:54,065 iteration 396 : loss : 0.141845, loss_ce: 0.062764
2022-01-09 11:37:56,337 iteration 397 : loss : 0.101171, loss_ce: 0.046517
2022-01-09 11:37:58,666 iteration 398 : loss : 0.128210, loss_ce: 0.063570
2022-01-09 11:38:00,968 iteration 399 : loss : 0.090043, loss_ce: 0.036462
2022-01-09 11:38:03,398 iteration 400 : loss : 0.124677, loss_ce: 0.059306
2022-01-09 11:38:05,598 iteration 401 : loss : 0.150420, loss_ce: 0.053672
2022-01-09 11:38:07,932 iteration 402 : loss : 0.156183, loss_ce: 0.064158
2022-01-09 11:38:10,389 iteration 403 : loss : 0.139851, loss_ce: 0.059430
2022-01-09 11:38:12,803 iteration 404 : loss : 0.100303, loss_ce: 0.032286
2022-01-09 11:38:15,183 iteration 405 : loss : 0.136273, loss_ce: 0.049525
2022-01-09 11:38:17,515 iteration 406 : loss : 0.161280, loss_ce: 0.065338
2022-01-09 11:38:19,749 iteration 407 : loss : 0.125016, loss_ce: 0.051446
2022-01-09 11:38:21,950 iteration 408 : loss : 0.087176, loss_ce: 0.030545
  6%|█▊                            | 24/400 [14:01<4:18:29, 41.25s/it]2022-01-09 11:38:24,413 iteration 409 : loss : 0.109366, loss_ce: 0.049285
2022-01-09 11:38:26,770 iteration 410 : loss : 0.119582, loss_ce: 0.045912
2022-01-09 11:38:29,114 iteration 411 : loss : 0.109518, loss_ce: 0.039667
2022-01-09 11:38:31,449 iteration 412 : loss : 0.117810, loss_ce: 0.046810
2022-01-09 11:38:33,736 iteration 413 : loss : 0.109362, loss_ce: 0.044147
2022-01-09 11:38:36,039 iteration 414 : loss : 0.109207, loss_ce: 0.047404
2022-01-09 11:38:38,405 iteration 415 : loss : 0.173685, loss_ce: 0.095481
2022-01-09 11:38:40,661 iteration 416 : loss : 0.150496, loss_ce: 0.053594
2022-01-09 11:38:43,085 iteration 417 : loss : 0.183231, loss_ce: 0.070874
2022-01-09 11:38:45,451 iteration 418 : loss : 0.101762, loss_ce: 0.033408
2022-01-09 11:38:47,832 iteration 419 : loss : 0.187579, loss_ce: 0.081092
2022-01-09 11:38:50,292 iteration 420 : loss : 0.101771, loss_ce: 0.038938
2022-01-09 11:38:52,630 iteration 421 : loss : 0.127469, loss_ce: 0.035124
2022-01-09 11:38:55,019 iteration 422 : loss : 0.139401, loss_ce: 0.053892
2022-01-09 11:38:57,356 iteration 423 : loss : 0.125802, loss_ce: 0.047059
2022-01-09 11:38:59,630 iteration 424 : loss : 0.153725, loss_ce: 0.077376
2022-01-09 11:38:59,630 Training Data Eval:
2022-01-09 11:39:12,491   Average segmentation loss on training set: 0.1292
2022-01-09 11:39:12,491 Validation Data Eval:
2022-01-09 11:39:16,875   Average segmentation loss on validation set: 0.2097
2022-01-09 11:39:22,611 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 11:39:24,301 iteration 425 : loss : 0.172932, loss_ce: 0.082546
  6%|█▉                            | 25/400 [15:03<4:57:21, 47.58s/it]2022-01-09 11:39:26,000 iteration 426 : loss : 0.131280, loss_ce: 0.054493
2022-01-09 11:39:27,639 iteration 427 : loss : 0.108806, loss_ce: 0.047897
2022-01-09 11:39:29,568 iteration 428 : loss : 0.105680, loss_ce: 0.047419
2022-01-09 11:39:31,548 iteration 429 : loss : 0.087207, loss_ce: 0.032550
2022-01-09 11:39:33,622 iteration 430 : loss : 0.124776, loss_ce: 0.059133
2022-01-09 11:39:35,751 iteration 431 : loss : 0.094066, loss_ce: 0.046784
2022-01-09 11:39:37,869 iteration 432 : loss : 0.106355, loss_ce: 0.042716
2022-01-09 11:39:39,975 iteration 433 : loss : 0.125876, loss_ce: 0.051373
2022-01-09 11:39:42,251 iteration 434 : loss : 0.101852, loss_ce: 0.037818
2022-01-09 11:39:44,567 iteration 435 : loss : 0.111175, loss_ce: 0.041493
2022-01-09 11:39:46,849 iteration 436 : loss : 0.187760, loss_ce: 0.060954
2022-01-09 11:39:49,043 iteration 437 : loss : 0.102418, loss_ce: 0.044660
2022-01-09 11:39:51,271 iteration 438 : loss : 0.133549, loss_ce: 0.053796
2022-01-09 11:39:53,544 iteration 439 : loss : 0.123267, loss_ce: 0.057889
2022-01-09 11:39:55,975 iteration 440 : loss : 0.147479, loss_ce: 0.067126
2022-01-09 11:39:58,274 iteration 441 : loss : 0.116144, loss_ce: 0.055815
2022-01-09 11:40:00,481 iteration 442 : loss : 0.091306, loss_ce: 0.034105
  6%|█▉                            | 26/400 [15:39<4:35:17, 44.16s/it]2022-01-09 11:40:02,820 iteration 443 : loss : 0.104830, loss_ce: 0.042054
2022-01-09 11:40:05,075 iteration 444 : loss : 0.087439, loss_ce: 0.031058
2022-01-09 11:40:07,338 iteration 445 : loss : 0.132589, loss_ce: 0.058017
2022-01-09 11:40:09,749 iteration 446 : loss : 0.103870, loss_ce: 0.034937
2022-01-09 11:40:12,187 iteration 447 : loss : 0.092323, loss_ce: 0.034192
2022-01-09 11:40:14,460 iteration 448 : loss : 0.134929, loss_ce: 0.048371
2022-01-09 11:40:16,759 iteration 449 : loss : 0.086438, loss_ce: 0.028469
2022-01-09 11:40:18,979 iteration 450 : loss : 0.161342, loss_ce: 0.094588
2022-01-09 11:40:21,228 iteration 451 : loss : 0.143704, loss_ce: 0.063204
2022-01-09 11:40:23,475 iteration 452 : loss : 0.115371, loss_ce: 0.041285
2022-01-09 11:40:25,691 iteration 453 : loss : 0.070048, loss_ce: 0.029884
2022-01-09 11:40:28,028 iteration 454 : loss : 0.110339, loss_ce: 0.048231
2022-01-09 11:40:30,316 iteration 455 : loss : 0.127706, loss_ce: 0.055821
2022-01-09 11:40:32,544 iteration 456 : loss : 0.081920, loss_ce: 0.031873
2022-01-09 11:40:34,885 iteration 457 : loss : 0.103055, loss_ce: 0.050780
2022-01-09 11:40:37,209 iteration 458 : loss : 0.101853, loss_ce: 0.054181
2022-01-09 11:40:39,490 iteration 459 : loss : 0.141922, loss_ce: 0.065259
  7%|██                            | 27/400 [16:18<4:24:53, 42.61s/it]2022-01-09 11:40:41,764 iteration 460 : loss : 0.100761, loss_ce: 0.047258
2022-01-09 11:40:44,036 iteration 461 : loss : 0.084406, loss_ce: 0.040113
2022-01-09 11:40:46,477 iteration 462 : loss : 0.132237, loss_ce: 0.052885
2022-01-09 11:40:48,878 iteration 463 : loss : 0.160803, loss_ce: 0.059565
2022-01-09 11:40:51,390 iteration 464 : loss : 0.168036, loss_ce: 0.059346
2022-01-09 11:40:53,796 iteration 465 : loss : 0.121003, loss_ce: 0.051437
2022-01-09 11:40:56,046 iteration 466 : loss : 0.104083, loss_ce: 0.041118
2022-01-09 11:40:58,392 iteration 467 : loss : 0.121908, loss_ce: 0.049478
2022-01-09 11:41:00,668 iteration 468 : loss : 0.082549, loss_ce: 0.032617
2022-01-09 11:41:03,046 iteration 469 : loss : 0.110152, loss_ce: 0.047005
2022-01-09 11:41:05,342 iteration 470 : loss : 0.073659, loss_ce: 0.027750
2022-01-09 11:41:07,656 iteration 471 : loss : 0.211680, loss_ce: 0.120927
2022-01-09 11:41:10,006 iteration 472 : loss : 0.094206, loss_ce: 0.040680
2022-01-09 11:41:12,366 iteration 473 : loss : 0.113001, loss_ce: 0.055868
2022-01-09 11:41:14,627 iteration 474 : loss : 0.195832, loss_ce: 0.073253
2022-01-09 11:41:16,913 iteration 475 : loss : 0.150790, loss_ce: 0.052489
2022-01-09 11:41:19,380 iteration 476 : loss : 0.085377, loss_ce: 0.033131
  7%|██                            | 28/400 [16:58<4:19:07, 41.79s/it]2022-01-09 11:41:21,731 iteration 477 : loss : 0.103351, loss_ce: 0.043101
2022-01-09 11:41:23,962 iteration 478 : loss : 0.091969, loss_ce: 0.043456
2022-01-09 11:41:26,300 iteration 479 : loss : 0.116846, loss_ce: 0.042707
2022-01-09 11:41:28,546 iteration 480 : loss : 0.126190, loss_ce: 0.033983
2022-01-09 11:41:30,803 iteration 481 : loss : 0.104574, loss_ce: 0.031853
2022-01-09 11:41:33,234 iteration 482 : loss : 0.106912, loss_ce: 0.043842
2022-01-09 11:41:35,490 iteration 483 : loss : 0.145371, loss_ce: 0.073591
2022-01-09 11:41:37,808 iteration 484 : loss : 0.127051, loss_ce: 0.045832
2022-01-09 11:41:40,096 iteration 485 : loss : 0.160680, loss_ce: 0.066322
2022-01-09 11:41:42,507 iteration 486 : loss : 0.114407, loss_ce: 0.049168
2022-01-09 11:41:44,776 iteration 487 : loss : 0.132586, loss_ce: 0.048226
2022-01-09 11:41:47,076 iteration 488 : loss : 0.122120, loss_ce: 0.058070
2022-01-09 11:41:49,488 iteration 489 : loss : 0.105171, loss_ce: 0.048238
2022-01-09 11:41:51,926 iteration 490 : loss : 0.136264, loss_ce: 0.075810
2022-01-09 11:41:54,391 iteration 491 : loss : 0.139194, loss_ce: 0.048795
2022-01-09 11:41:56,743 iteration 492 : loss : 0.111601, loss_ce: 0.065402
2022-01-09 11:41:59,187 iteration 493 : loss : 0.099151, loss_ce: 0.048561
  7%|██▏                           | 29/400 [17:38<4:14:45, 41.20s/it]2022-01-09 11:42:01,611 iteration 494 : loss : 0.155780, loss_ce: 0.062383
2022-01-09 11:42:03,900 iteration 495 : loss : 0.120562, loss_ce: 0.043054
2022-01-09 11:42:06,209 iteration 496 : loss : 0.098149, loss_ce: 0.031502
2022-01-09 11:42:08,512 iteration 497 : loss : 0.126139, loss_ce: 0.055306
2022-01-09 11:42:10,844 iteration 498 : loss : 0.152636, loss_ce: 0.079197
2022-01-09 11:42:13,136 iteration 499 : loss : 0.108044, loss_ce: 0.036831
2022-01-09 11:42:15,451 iteration 500 : loss : 0.133769, loss_ce: 0.052135
2022-01-09 11:42:17,706 iteration 501 : loss : 0.118305, loss_ce: 0.044413
2022-01-09 11:42:20,046 iteration 502 : loss : 0.112939, loss_ce: 0.053108
2022-01-09 11:42:22,542 iteration 503 : loss : 0.099816, loss_ce: 0.029298
2022-01-09 11:42:24,969 iteration 504 : loss : 0.115651, loss_ce: 0.045821
2022-01-09 11:42:27,237 iteration 505 : loss : 0.092227, loss_ce: 0.042937
2022-01-09 11:42:29,623 iteration 506 : loss : 0.132713, loss_ce: 0.055298
2022-01-09 11:42:31,943 iteration 507 : loss : 0.109418, loss_ce: 0.042628
2022-01-09 11:42:34,189 iteration 508 : loss : 0.091032, loss_ce: 0.039234
2022-01-09 11:42:36,569 iteration 509 : loss : 0.107622, loss_ce: 0.050005
2022-01-09 11:42:36,569 Training Data Eval:
2022-01-09 11:42:49,202   Average segmentation loss on training set: 0.1010
2022-01-09 11:42:49,202 Validation Data Eval:
2022-01-09 11:42:53,726   Average segmentation loss on validation set: 0.1063
2022-01-09 11:42:59,681 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 11:43:01,192 iteration 510 : loss : 0.106157, loss_ce: 0.040870
  8%|██▎                           | 30/400 [18:40<4:52:32, 47.44s/it]2022-01-09 11:43:02,692 iteration 511 : loss : 0.099467, loss_ce: 0.046501
2022-01-09 11:43:04,481 iteration 512 : loss : 0.121481, loss_ce: 0.052974
2022-01-09 11:43:06,188 iteration 513 : loss : 0.131374, loss_ce: 0.072204
2022-01-09 11:43:08,102 iteration 514 : loss : 0.140596, loss_ce: 0.058266
2022-01-09 11:43:10,091 iteration 515 : loss : 0.093739, loss_ce: 0.042017
2022-01-09 11:43:12,099 iteration 516 : loss : 0.074990, loss_ce: 0.038269
2022-01-09 11:43:14,390 iteration 517 : loss : 0.098979, loss_ce: 0.041909
2022-01-09 11:43:16,600 iteration 518 : loss : 0.122132, loss_ce: 0.063740
2022-01-09 11:43:18,846 iteration 519 : loss : 0.109643, loss_ce: 0.043318
2022-01-09 11:43:21,144 iteration 520 : loss : 0.120720, loss_ce: 0.057399
2022-01-09 11:43:23,622 iteration 521 : loss : 0.208395, loss_ce: 0.064135
2022-01-09 11:43:25,936 iteration 522 : loss : 0.089502, loss_ce: 0.029739
2022-01-09 11:43:28,257 iteration 523 : loss : 0.099137, loss_ce: 0.040245
2022-01-09 11:43:30,548 iteration 524 : loss : 0.104665, loss_ce: 0.042881
2022-01-09 11:43:32,909 iteration 525 : loss : 0.100687, loss_ce: 0.041690
2022-01-09 11:43:35,231 iteration 526 : loss : 0.106564, loss_ce: 0.041739
2022-01-09 11:43:37,519 iteration 527 : loss : 0.114175, loss_ce: 0.046285
  8%|██▎                           | 31/400 [19:16<4:31:17, 44.11s/it]2022-01-09 11:43:39,904 iteration 528 : loss : 0.077410, loss_ce: 0.031948
2022-01-09 11:43:42,207 iteration 529 : loss : 0.105682, loss_ce: 0.052732
2022-01-09 11:43:44,446 iteration 530 : loss : 0.091507, loss_ce: 0.035055
2022-01-09 11:43:46,813 iteration 531 : loss : 0.198094, loss_ce: 0.079949
2022-01-09 11:43:49,093 iteration 532 : loss : 0.142566, loss_ce: 0.044508
2022-01-09 11:43:51,466 iteration 533 : loss : 0.079553, loss_ce: 0.037662
2022-01-09 11:43:53,778 iteration 534 : loss : 0.144284, loss_ce: 0.071362
2022-01-09 11:43:56,009 iteration 535 : loss : 0.113025, loss_ce: 0.046324
2022-01-09 11:43:58,160 iteration 536 : loss : 0.121224, loss_ce: 0.067250
2022-01-09 11:44:00,543 iteration 537 : loss : 0.118274, loss_ce: 0.052018
2022-01-09 11:44:02,877 iteration 538 : loss : 0.079263, loss_ce: 0.032099
2022-01-09 11:44:05,268 iteration 539 : loss : 0.131809, loss_ce: 0.053034
2022-01-09 11:44:07,598 iteration 540 : loss : 0.113570, loss_ce: 0.049204
2022-01-09 11:44:09,958 iteration 541 : loss : 0.118959, loss_ce: 0.059898
2022-01-09 11:44:12,278 iteration 542 : loss : 0.131391, loss_ce: 0.048745
2022-01-09 11:44:14,651 iteration 543 : loss : 0.121416, loss_ce: 0.039460
2022-01-09 11:44:17,025 iteration 544 : loss : 0.107539, loss_ce: 0.036424
  8%|██▍                           | 32/400 [19:56<4:22:05, 42.73s/it]2022-01-09 11:44:19,458 iteration 545 : loss : 0.122609, loss_ce: 0.055388
2022-01-09 11:44:21,945 iteration 546 : loss : 0.089339, loss_ce: 0.034771
2022-01-09 11:44:24,361 iteration 547 : loss : 0.129328, loss_ce: 0.054233
2022-01-09 11:44:26,855 iteration 548 : loss : 0.134970, loss_ce: 0.051312
2022-01-09 11:44:29,253 iteration 549 : loss : 0.133298, loss_ce: 0.054735
2022-01-09 11:44:31,612 iteration 550 : loss : 0.136012, loss_ce: 0.075055
2022-01-09 11:44:33,837 iteration 551 : loss : 0.104015, loss_ce: 0.038148
2022-01-09 11:44:36,112 iteration 552 : loss : 0.101866, loss_ce: 0.051783
2022-01-09 11:44:38,427 iteration 553 : loss : 0.103848, loss_ce: 0.053118
2022-01-09 11:44:40,691 iteration 554 : loss : 0.090011, loss_ce: 0.037358
2022-01-09 11:44:43,087 iteration 555 : loss : 0.090299, loss_ce: 0.043339
2022-01-09 11:44:45,596 iteration 556 : loss : 0.116542, loss_ce: 0.047515
2022-01-09 11:44:47,977 iteration 557 : loss : 0.112600, loss_ce: 0.055733
2022-01-09 11:44:50,355 iteration 558 : loss : 0.121233, loss_ce: 0.047413
2022-01-09 11:44:52,760 iteration 559 : loss : 0.133796, loss_ce: 0.060854
2022-01-09 11:44:55,090 iteration 560 : loss : 0.129981, loss_ce: 0.053134
2022-01-09 11:44:57,330 iteration 561 : loss : 0.129103, loss_ce: 0.040388
  8%|██▍                           | 33/400 [20:36<4:16:54, 42.00s/it]2022-01-09 11:44:59,711 iteration 562 : loss : 0.155089, loss_ce: 0.059372
2022-01-09 11:45:02,128 iteration 563 : loss : 0.124949, loss_ce: 0.059413
2022-01-09 11:45:04,574 iteration 564 : loss : 0.084740, loss_ce: 0.042896
2022-01-09 11:45:06,914 iteration 565 : loss : 0.152864, loss_ce: 0.070136
2022-01-09 11:45:09,186 iteration 566 : loss : 0.075287, loss_ce: 0.028388
2022-01-09 11:45:11,574 iteration 567 : loss : 0.114833, loss_ce: 0.036607
2022-01-09 11:45:13,893 iteration 568 : loss : 0.101440, loss_ce: 0.040447
2022-01-09 11:45:16,195 iteration 569 : loss : 0.083256, loss_ce: 0.031553
2022-01-09 11:45:18,593 iteration 570 : loss : 0.112489, loss_ce: 0.051195
2022-01-09 11:45:21,037 iteration 571 : loss : 0.096089, loss_ce: 0.037966
2022-01-09 11:45:23,463 iteration 572 : loss : 0.107460, loss_ce: 0.043712
2022-01-09 11:45:25,851 iteration 573 : loss : 0.103673, loss_ce: 0.038051
2022-01-09 11:45:28,311 iteration 574 : loss : 0.116659, loss_ce: 0.055320
2022-01-09 11:45:30,747 iteration 575 : loss : 0.117293, loss_ce: 0.046718
2022-01-09 11:45:33,124 iteration 576 : loss : 0.087919, loss_ce: 0.046685
2022-01-09 11:45:35,454 iteration 577 : loss : 0.173467, loss_ce: 0.060385
2022-01-09 11:45:38,005 iteration 578 : loss : 0.113191, loss_ce: 0.041754
  8%|██▌                           | 34/400 [21:17<4:13:46, 41.60s/it]2022-01-09 11:45:40,434 iteration 579 : loss : 0.092753, loss_ce: 0.030491
2022-01-09 11:45:42,780 iteration 580 : loss : 0.080541, loss_ce: 0.035666
2022-01-09 11:45:45,084 iteration 581 : loss : 0.099831, loss_ce: 0.043753
2022-01-09 11:45:47,376 iteration 582 : loss : 0.083963, loss_ce: 0.032138
2022-01-09 11:45:49,649 iteration 583 : loss : 0.142115, loss_ce: 0.074150
2022-01-09 11:45:51,828 iteration 584 : loss : 0.078322, loss_ce: 0.033635
2022-01-09 11:45:54,085 iteration 585 : loss : 0.078929, loss_ce: 0.028957
2022-01-09 11:45:56,473 iteration 586 : loss : 0.091499, loss_ce: 0.044721
2022-01-09 11:45:58,809 iteration 587 : loss : 0.093868, loss_ce: 0.034768
2022-01-09 11:46:01,153 iteration 588 : loss : 0.113104, loss_ce: 0.044293
2022-01-09 11:46:03,472 iteration 589 : loss : 0.082198, loss_ce: 0.035896
2022-01-09 11:46:05,987 iteration 590 : loss : 0.120009, loss_ce: 0.078050
2022-01-09 11:46:08,397 iteration 591 : loss : 0.070809, loss_ce: 0.028452
2022-01-09 11:46:10,768 iteration 592 : loss : 0.105759, loss_ce: 0.041296
2022-01-09 11:46:13,202 iteration 593 : loss : 0.097697, loss_ce: 0.040990
2022-01-09 11:46:15,662 iteration 594 : loss : 0.092682, loss_ce: 0.046231
2022-01-09 11:46:15,662 Training Data Eval:
2022-01-09 11:46:28,554   Average segmentation loss on training set: 0.0658
2022-01-09 11:46:28,555 Validation Data Eval:
2022-01-09 11:46:33,093   Average segmentation loss on validation set: 0.0958
2022-01-09 11:46:38,880 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 11:46:40,524 iteration 595 : loss : 0.107807, loss_ce: 0.041416
  9%|██▋                           | 35/400 [22:19<4:51:15, 47.88s/it]2022-01-09 11:46:42,111 iteration 596 : loss : 0.065872, loss_ce: 0.030951
2022-01-09 11:46:43,748 iteration 597 : loss : 0.131868, loss_ce: 0.061353
2022-01-09 11:46:45,524 iteration 598 : loss : 0.084976, loss_ce: 0.034860
2022-01-09 11:46:47,483 iteration 599 : loss : 0.066219, loss_ce: 0.027081
2022-01-09 11:46:49,483 iteration 600 : loss : 0.076140, loss_ce: 0.037987
2022-01-09 11:46:51,607 iteration 601 : loss : 0.083056, loss_ce: 0.033967
2022-01-09 11:46:53,865 iteration 602 : loss : 0.069637, loss_ce: 0.031138
2022-01-09 11:46:55,984 iteration 603 : loss : 0.095609, loss_ce: 0.037310
2022-01-09 11:46:58,170 iteration 604 : loss : 0.087187, loss_ce: 0.035968
2022-01-09 11:47:00,484 iteration 605 : loss : 0.078291, loss_ce: 0.035871
2022-01-09 11:47:02,865 iteration 606 : loss : 0.129144, loss_ce: 0.051101
2022-01-09 11:47:05,231 iteration 607 : loss : 0.080637, loss_ce: 0.030126
2022-01-09 11:47:07,644 iteration 608 : loss : 0.082059, loss_ce: 0.028285
2022-01-09 11:47:09,966 iteration 609 : loss : 0.066473, loss_ce: 0.027352
2022-01-09 11:47:12,297 iteration 610 : loss : 0.095157, loss_ce: 0.039263
2022-01-09 11:47:14,587 iteration 611 : loss : 0.110923, loss_ce: 0.044082
2022-01-09 11:47:16,867 iteration 612 : loss : 0.087264, loss_ce: 0.041383
  9%|██▋                           | 36/400 [22:56<4:29:27, 44.42s/it]2022-01-09 11:47:19,294 iteration 613 : loss : 0.090810, loss_ce: 0.042548
2022-01-09 11:47:21,694 iteration 614 : loss : 0.106530, loss_ce: 0.050913
2022-01-09 11:47:24,026 iteration 615 : loss : 0.106359, loss_ce: 0.044417
2022-01-09 11:47:26,400 iteration 616 : loss : 0.107669, loss_ce: 0.063586
2022-01-09 11:47:28,785 iteration 617 : loss : 0.113403, loss_ce: 0.050928
2022-01-09 11:47:31,089 iteration 618 : loss : 0.117895, loss_ce: 0.046731
2022-01-09 11:47:33,419 iteration 619 : loss : 0.112525, loss_ce: 0.038461
2022-01-09 11:47:35,771 iteration 620 : loss : 0.155182, loss_ce: 0.066552
2022-01-09 11:47:38,054 iteration 621 : loss : 0.116173, loss_ce: 0.046832
2022-01-09 11:47:40,458 iteration 622 : loss : 0.081347, loss_ce: 0.036967
2022-01-09 11:47:42,907 iteration 623 : loss : 0.092706, loss_ce: 0.031754
2022-01-09 11:47:45,261 iteration 624 : loss : 0.103878, loss_ce: 0.033750
2022-01-09 11:47:47,594 iteration 625 : loss : 0.126463, loss_ce: 0.053289
2022-01-09 11:47:50,020 iteration 626 : loss : 0.081487, loss_ce: 0.030872
2022-01-09 11:47:52,409 iteration 627 : loss : 0.072088, loss_ce: 0.023176
2022-01-09 11:47:54,771 iteration 628 : loss : 0.121243, loss_ce: 0.066617
2022-01-09 11:47:57,137 iteration 629 : loss : 0.077509, loss_ce: 0.030432
  9%|██▊                           | 37/400 [23:36<4:21:11, 43.17s/it]2022-01-09 11:47:59,557 iteration 630 : loss : 0.060857, loss_ce: 0.025002
2022-01-09 11:48:02,089 iteration 631 : loss : 0.098030, loss_ce: 0.051910
2022-01-09 11:48:04,494 iteration 632 : loss : 0.104134, loss_ce: 0.043040
2022-01-09 11:48:06,830 iteration 633 : loss : 0.084675, loss_ce: 0.032815
2022-01-09 11:48:09,226 iteration 634 : loss : 0.069631, loss_ce: 0.033971
2022-01-09 11:48:11,641 iteration 635 : loss : 0.154025, loss_ce: 0.058271
2022-01-09 11:48:14,030 iteration 636 : loss : 0.125077, loss_ce: 0.070684
2022-01-09 11:48:16,345 iteration 637 : loss : 0.077873, loss_ce: 0.029422
2022-01-09 11:48:18,703 iteration 638 : loss : 0.125513, loss_ce: 0.064108
2022-01-09 11:48:21,071 iteration 639 : loss : 0.117142, loss_ce: 0.052710
2022-01-09 11:48:23,377 iteration 640 : loss : 0.098996, loss_ce: 0.039069
2022-01-09 11:48:25,776 iteration 641 : loss : 0.064238, loss_ce: 0.025461
2022-01-09 11:48:28,149 iteration 642 : loss : 0.113362, loss_ce: 0.046081
2022-01-09 11:48:30,484 iteration 643 : loss : 0.095816, loss_ce: 0.044974
2022-01-09 11:48:32,871 iteration 644 : loss : 0.065212, loss_ce: 0.027653
2022-01-09 11:48:35,418 iteration 645 : loss : 0.157547, loss_ce: 0.069026
2022-01-09 11:48:37,807 iteration 646 : loss : 0.080998, loss_ce: 0.038772
 10%|██▊                           | 38/400 [24:17<4:15:56, 42.42s/it]2022-01-09 11:48:40,157 iteration 647 : loss : 0.126219, loss_ce: 0.043097
2022-01-09 11:48:42,509 iteration 648 : loss : 0.102397, loss_ce: 0.059985
2022-01-09 11:48:44,892 iteration 649 : loss : 0.091364, loss_ce: 0.041595
2022-01-09 11:48:47,325 iteration 650 : loss : 0.152116, loss_ce: 0.051846
2022-01-09 11:48:49,783 iteration 651 : loss : 0.132259, loss_ce: 0.062378
2022-01-09 11:48:52,119 iteration 652 : loss : 0.082633, loss_ce: 0.038275
2022-01-09 11:48:54,439 iteration 653 : loss : 0.074325, loss_ce: 0.037726
2022-01-09 11:48:56,737 iteration 654 : loss : 0.080257, loss_ce: 0.031419
2022-01-09 11:48:59,144 iteration 655 : loss : 0.105146, loss_ce: 0.042854
2022-01-09 11:49:01,576 iteration 656 : loss : 0.092551, loss_ce: 0.038418
2022-01-09 11:49:03,866 iteration 657 : loss : 0.113145, loss_ce: 0.044220
2022-01-09 11:49:06,115 iteration 658 : loss : 0.086941, loss_ce: 0.031130
2022-01-09 11:49:08,462 iteration 659 : loss : 0.129844, loss_ce: 0.040876
2022-01-09 11:49:10,790 iteration 660 : loss : 0.086171, loss_ce: 0.035436
2022-01-09 11:49:13,114 iteration 661 : loss : 0.091123, loss_ce: 0.045063
2022-01-09 11:49:15,532 iteration 662 : loss : 0.088160, loss_ce: 0.038240
2022-01-09 11:49:17,841 iteration 663 : loss : 0.142144, loss_ce: 0.066217
 10%|██▉                           | 39/400 [24:57<4:10:54, 41.70s/it]2022-01-09 11:49:20,199 iteration 664 : loss : 0.131488, loss_ce: 0.076115
2022-01-09 11:49:22,545 iteration 665 : loss : 0.099457, loss_ce: 0.033812
2022-01-09 11:49:24,950 iteration 666 : loss : 0.092190, loss_ce: 0.032097
2022-01-09 11:49:27,323 iteration 667 : loss : 0.099957, loss_ce: 0.046968
2022-01-09 11:49:29,663 iteration 668 : loss : 0.053389, loss_ce: 0.021329
2022-01-09 11:49:32,037 iteration 669 : loss : 0.113026, loss_ce: 0.051936
2022-01-09 11:49:34,393 iteration 670 : loss : 0.119836, loss_ce: 0.046077
2022-01-09 11:49:36,693 iteration 671 : loss : 0.086668, loss_ce: 0.036857
2022-01-09 11:49:38,972 iteration 672 : loss : 0.078304, loss_ce: 0.032612
2022-01-09 11:49:41,267 iteration 673 : loss : 0.121898, loss_ce: 0.045452
2022-01-09 11:49:43,735 iteration 674 : loss : 0.099065, loss_ce: 0.056621
2022-01-09 11:49:46,097 iteration 675 : loss : 0.103662, loss_ce: 0.034036
2022-01-09 11:49:48,418 iteration 676 : loss : 0.096319, loss_ce: 0.040831
2022-01-09 11:49:50,841 iteration 677 : loss : 0.065833, loss_ce: 0.031478
2022-01-09 11:49:53,158 iteration 678 : loss : 0.103562, loss_ce: 0.032540
2022-01-09 11:49:55,419 iteration 679 : loss : 0.090624, loss_ce: 0.038978
2022-01-09 11:49:55,419 Training Data Eval:
2022-01-09 11:50:07,993   Average segmentation loss on training set: 0.1192
2022-01-09 11:50:07,993 Validation Data Eval:
2022-01-09 11:50:12,436   Average segmentation loss on validation set: 0.1502
2022-01-09 11:50:14,817 iteration 680 : loss : 0.083627, loss_ce: 0.040672
 10%|███                           | 40/400 [25:54<4:37:42, 46.29s/it]2022-01-09 11:50:17,336 iteration 681 : loss : 0.096267, loss_ce: 0.033256
2022-01-09 11:50:19,736 iteration 682 : loss : 0.087210, loss_ce: 0.031759
2022-01-09 11:50:22,122 iteration 683 : loss : 0.091933, loss_ce: 0.030345
2022-01-09 11:50:24,549 iteration 684 : loss : 0.076113, loss_ce: 0.032780
2022-01-09 11:50:26,986 iteration 685 : loss : 0.102710, loss_ce: 0.049879
2022-01-09 11:50:29,287 iteration 686 : loss : 0.090072, loss_ce: 0.042156
2022-01-09 11:50:31,591 iteration 687 : loss : 0.075459, loss_ce: 0.032886
2022-01-09 11:50:33,959 iteration 688 : loss : 0.086498, loss_ce: 0.033562
2022-01-09 11:50:36,268 iteration 689 : loss : 0.097960, loss_ce: 0.053981
2022-01-09 11:50:38,611 iteration 690 : loss : 0.099145, loss_ce: 0.040757
2022-01-09 11:50:41,017 iteration 691 : loss : 0.103386, loss_ce: 0.036213
2022-01-09 11:50:43,276 iteration 692 : loss : 0.066533, loss_ce: 0.029352
2022-01-09 11:50:45,629 iteration 693 : loss : 0.074915, loss_ce: 0.030605
2022-01-09 11:50:47,989 iteration 694 : loss : 0.108131, loss_ce: 0.035197
2022-01-09 11:50:50,370 iteration 695 : loss : 0.097873, loss_ce: 0.038990
2022-01-09 11:50:52,698 iteration 696 : loss : 0.163622, loss_ce: 0.044259
2022-01-09 11:50:55,030 iteration 697 : loss : 0.058809, loss_ce: 0.026496
 10%|███                           | 41/400 [26:34<4:26:02, 44.46s/it]2022-01-09 11:50:57,532 iteration 698 : loss : 0.070942, loss_ce: 0.034942
2022-01-09 11:50:59,943 iteration 699 : loss : 0.059041, loss_ce: 0.025482
2022-01-09 11:51:02,337 iteration 700 : loss : 0.072473, loss_ce: 0.029156
2022-01-09 11:51:04,691 iteration 701 : loss : 0.112562, loss_ce: 0.040365
2022-01-09 11:51:07,032 iteration 702 : loss : 0.073022, loss_ce: 0.034414
2022-01-09 11:51:09,334 iteration 703 : loss : 0.119598, loss_ce: 0.037795
2022-01-09 11:51:11,718 iteration 704 : loss : 0.120968, loss_ce: 0.040629
2022-01-09 11:51:14,146 iteration 705 : loss : 0.076891, loss_ce: 0.037933
2022-01-09 11:51:16,562 iteration 706 : loss : 0.134974, loss_ce: 0.036104
2022-01-09 11:51:18,863 iteration 707 : loss : 0.092145, loss_ce: 0.040497
2022-01-09 11:51:21,430 iteration 708 : loss : 0.082918, loss_ce: 0.028182
2022-01-09 11:51:23,852 iteration 709 : loss : 0.099859, loss_ce: 0.035109
2022-01-09 11:51:26,234 iteration 710 : loss : 0.081167, loss_ce: 0.038907
2022-01-09 11:51:28,632 iteration 711 : loss : 0.085059, loss_ce: 0.038017
2022-01-09 11:51:30,931 iteration 712 : loss : 0.139140, loss_ce: 0.046380
2022-01-09 11:51:33,264 iteration 713 : loss : 0.073539, loss_ce: 0.031405
2022-01-09 11:51:35,639 iteration 714 : loss : 0.071831, loss_ce: 0.028020
 10%|███▏                          | 42/400 [27:14<4:18:23, 43.31s/it]2022-01-09 11:51:38,117 iteration 715 : loss : 0.129473, loss_ce: 0.067345
2022-01-09 11:51:40,522 iteration 716 : loss : 0.079846, loss_ce: 0.033809
2022-01-09 11:51:42,930 iteration 717 : loss : 0.115647, loss_ce: 0.044485
2022-01-09 11:51:45,310 iteration 718 : loss : 0.111187, loss_ce: 0.053546
2022-01-09 11:51:47,747 iteration 719 : loss : 0.076425, loss_ce: 0.030162
2022-01-09 11:51:50,132 iteration 720 : loss : 0.100995, loss_ce: 0.033566
2022-01-09 11:51:52,528 iteration 721 : loss : 0.089506, loss_ce: 0.033906
2022-01-09 11:51:54,927 iteration 722 : loss : 0.070811, loss_ce: 0.031824
2022-01-09 11:51:57,305 iteration 723 : loss : 0.071017, loss_ce: 0.029947
2022-01-09 11:51:59,758 iteration 724 : loss : 0.087834, loss_ce: 0.041376
2022-01-09 11:52:02,005 iteration 725 : loss : 0.052755, loss_ce: 0.020906
2022-01-09 11:52:04,238 iteration 726 : loss : 0.114105, loss_ce: 0.033495
2022-01-09 11:52:06,460 iteration 727 : loss : 0.137347, loss_ce: 0.042573
2022-01-09 11:52:08,846 iteration 728 : loss : 0.103904, loss_ce: 0.050278
2022-01-09 11:52:11,007 iteration 729 : loss : 0.057189, loss_ce: 0.022657
2022-01-09 11:52:13,271 iteration 730 : loss : 0.100026, loss_ce: 0.047994
2022-01-09 11:52:15,510 iteration 731 : loss : 0.083418, loss_ce: 0.029921
 11%|███▏                          | 43/400 [27:54<4:11:32, 42.28s/it]2022-01-09 11:52:17,906 iteration 732 : loss : 0.072059, loss_ce: 0.030532
2022-01-09 11:52:20,182 iteration 733 : loss : 0.143115, loss_ce: 0.061704
2022-01-09 11:52:22,394 iteration 734 : loss : 0.094722, loss_ce: 0.033499
2022-01-09 11:52:24,811 iteration 735 : loss : 0.065340, loss_ce: 0.026515
2022-01-09 11:52:27,180 iteration 736 : loss : 0.084636, loss_ce: 0.032484
2022-01-09 11:52:29,509 iteration 737 : loss : 0.066700, loss_ce: 0.023074
2022-01-09 11:52:31,777 iteration 738 : loss : 0.061530, loss_ce: 0.027847
2022-01-09 11:52:33,992 iteration 739 : loss : 0.103957, loss_ce: 0.042236
2022-01-09 11:52:36,212 iteration 740 : loss : 0.112958, loss_ce: 0.053557
2022-01-09 11:52:38,451 iteration 741 : loss : 0.082322, loss_ce: 0.036103
2022-01-09 11:52:40,683 iteration 742 : loss : 0.107925, loss_ce: 0.035623
2022-01-09 11:52:42,926 iteration 743 : loss : 0.084810, loss_ce: 0.032860
2022-01-09 11:52:45,235 iteration 744 : loss : 0.096745, loss_ce: 0.041780
2022-01-09 11:52:47,586 iteration 745 : loss : 0.064957, loss_ce: 0.030977
2022-01-09 11:52:49,940 iteration 746 : loss : 0.162887, loss_ce: 0.088060
2022-01-09 11:52:52,317 iteration 747 : loss : 0.118532, loss_ce: 0.035338
2022-01-09 11:52:54,525 iteration 748 : loss : 0.065841, loss_ce: 0.027356
 11%|███▎                          | 44/400 [28:33<4:05:03, 41.30s/it]2022-01-09 11:52:56,857 iteration 749 : loss : 0.079312, loss_ce: 0.034167
2022-01-09 11:52:59,160 iteration 750 : loss : 0.080092, loss_ce: 0.032808
2022-01-09 11:53:01,307 iteration 751 : loss : 0.061741, loss_ce: 0.026601
2022-01-09 11:53:03,491 iteration 752 : loss : 0.090536, loss_ce: 0.036008
2022-01-09 11:53:05,687 iteration 753 : loss : 0.097169, loss_ce: 0.040642
2022-01-09 11:53:07,764 iteration 754 : loss : 0.110334, loss_ce: 0.042663
2022-01-09 11:53:09,890 iteration 755 : loss : 0.055232, loss_ce: 0.021465
2022-01-09 11:53:12,086 iteration 756 : loss : 0.090204, loss_ce: 0.037473
2022-01-09 11:53:14,325 iteration 757 : loss : 0.102873, loss_ce: 0.042716
2022-01-09 11:53:16,673 iteration 758 : loss : 0.071130, loss_ce: 0.028177
2022-01-09 11:53:18,903 iteration 759 : loss : 0.065739, loss_ce: 0.025204
2022-01-09 11:53:21,266 iteration 760 : loss : 0.100328, loss_ce: 0.034341
2022-01-09 11:53:23,562 iteration 761 : loss : 0.072457, loss_ce: 0.024934
2022-01-09 11:53:25,799 iteration 762 : loss : 0.088741, loss_ce: 0.045445
2022-01-09 11:53:28,047 iteration 763 : loss : 0.072254, loss_ce: 0.030192
2022-01-09 11:53:30,281 iteration 764 : loss : 0.071315, loss_ce: 0.028441
2022-01-09 11:53:30,281 Training Data Eval:
2022-01-09 11:53:43,008   Average segmentation loss on training set: 0.0575
2022-01-09 11:53:43,008 Validation Data Eval:
2022-01-09 11:53:47,404   Average segmentation loss on validation set: 0.1002
2022-01-09 11:53:49,844 iteration 765 : loss : 0.066268, loss_ce: 0.027572
 11%|███▍                          | 45/400 [29:29<4:29:14, 45.51s/it]2022-01-09 11:53:52,262 iteration 766 : loss : 0.099734, loss_ce: 0.036761
2022-01-09 11:53:54,739 iteration 767 : loss : 0.083335, loss_ce: 0.029928
2022-01-09 11:53:57,069 iteration 768 : loss : 0.091546, loss_ce: 0.031164
2022-01-09 11:53:59,450 iteration 769 : loss : 0.194723, loss_ce: 0.046431
2022-01-09 11:54:01,744 iteration 770 : loss : 0.065431, loss_ce: 0.027763
2022-01-09 11:54:04,079 iteration 771 : loss : 0.091054, loss_ce: 0.033926
2022-01-09 11:54:06,403 iteration 772 : loss : 0.083392, loss_ce: 0.037935
2022-01-09 11:54:08,719 iteration 773 : loss : 0.073872, loss_ce: 0.025681
2022-01-09 11:54:11,023 iteration 774 : loss : 0.065334, loss_ce: 0.030747
2022-01-09 11:54:13,395 iteration 775 : loss : 0.080899, loss_ce: 0.032041
2022-01-09 11:54:15,731 iteration 776 : loss : 0.081803, loss_ce: 0.035474
2022-01-09 11:54:18,124 iteration 777 : loss : 0.072104, loss_ce: 0.029771
2022-01-09 11:54:20,432 iteration 778 : loss : 0.046291, loss_ce: 0.018185
2022-01-09 11:54:22,710 iteration 779 : loss : 0.083683, loss_ce: 0.042182
2022-01-09 11:54:24,951 iteration 780 : loss : 0.085359, loss_ce: 0.034302
2022-01-09 11:54:27,203 iteration 781 : loss : 0.068148, loss_ce: 0.031107
2022-01-09 11:54:29,391 iteration 782 : loss : 0.110678, loss_ce: 0.052134
 12%|███▍                          | 46/400 [30:08<4:17:55, 43.72s/it]2022-01-09 11:54:31,632 iteration 783 : loss : 0.064226, loss_ce: 0.031804
2022-01-09 11:54:33,781 iteration 784 : loss : 0.092693, loss_ce: 0.033576
2022-01-09 11:54:35,998 iteration 785 : loss : 0.078383, loss_ce: 0.033284
2022-01-09 11:54:38,166 iteration 786 : loss : 0.081879, loss_ce: 0.029245
2022-01-09 11:54:40,428 iteration 787 : loss : 0.084483, loss_ce: 0.034037
2022-01-09 11:54:42,686 iteration 788 : loss : 0.065106, loss_ce: 0.021010
2022-01-09 11:54:44,961 iteration 789 : loss : 0.114250, loss_ce: 0.059212
2022-01-09 11:54:47,244 iteration 790 : loss : 0.068777, loss_ce: 0.024857
2022-01-09 11:54:49,484 iteration 791 : loss : 0.086615, loss_ce: 0.031497
2022-01-09 11:54:51,769 iteration 792 : loss : 0.086396, loss_ce: 0.039518
2022-01-09 11:54:53,988 iteration 793 : loss : 0.111362, loss_ce: 0.048553
2022-01-09 11:54:56,299 iteration 794 : loss : 0.069868, loss_ce: 0.029901
2022-01-09 11:54:58,619 iteration 795 : loss : 0.076974, loss_ce: 0.034621
2022-01-09 11:55:00,918 iteration 796 : loss : 0.095373, loss_ce: 0.041952
2022-01-09 11:55:03,129 iteration 797 : loss : 0.067461, loss_ce: 0.032096
2022-01-09 11:55:05,356 iteration 798 : loss : 0.125448, loss_ce: 0.038447
2022-01-09 11:55:07,645 iteration 799 : loss : 0.051478, loss_ce: 0.020253
 12%|███▌                          | 47/400 [30:46<4:07:33, 42.08s/it]2022-01-09 11:55:10,007 iteration 800 : loss : 0.081014, loss_ce: 0.021955
2022-01-09 11:55:12,207 iteration 801 : loss : 0.090957, loss_ce: 0.033465
2022-01-09 11:55:14,448 iteration 802 : loss : 0.102529, loss_ce: 0.054848
2022-01-09 11:55:16,736 iteration 803 : loss : 0.117252, loss_ce: 0.070953
2022-01-09 11:55:18,980 iteration 804 : loss : 0.075459, loss_ce: 0.032657
2022-01-09 11:55:21,168 iteration 805 : loss : 0.129470, loss_ce: 0.029885
2022-01-09 11:55:23,388 iteration 806 : loss : 0.076118, loss_ce: 0.028427
2022-01-09 11:55:25,689 iteration 807 : loss : 0.104162, loss_ce: 0.038685
2022-01-09 11:55:27,908 iteration 808 : loss : 0.077057, loss_ce: 0.025176
2022-01-09 11:55:30,092 iteration 809 : loss : 0.132767, loss_ce: 0.037390
2022-01-09 11:55:32,351 iteration 810 : loss : 0.099650, loss_ce: 0.032824
2022-01-09 11:55:34,507 iteration 811 : loss : 0.056349, loss_ce: 0.023091
2022-01-09 11:55:36,796 iteration 812 : loss : 0.136885, loss_ce: 0.047583
2022-01-09 11:55:39,023 iteration 813 : loss : 0.063281, loss_ce: 0.026619
2022-01-09 11:55:41,301 iteration 814 : loss : 0.072519, loss_ce: 0.033528
2022-01-09 11:55:43,537 iteration 815 : loss : 0.071974, loss_ce: 0.028337
2022-01-09 11:55:45,709 iteration 816 : loss : 0.072256, loss_ce: 0.026212
 12%|███▌                          | 48/400 [31:24<3:59:48, 40.88s/it]2022-01-09 11:55:48,084 iteration 817 : loss : 0.077645, loss_ce: 0.029552
2022-01-09 11:55:50,370 iteration 818 : loss : 0.102384, loss_ce: 0.038742
2022-01-09 11:55:52,554 iteration 819 : loss : 0.064153, loss_ce: 0.026378
2022-01-09 11:55:54,853 iteration 820 : loss : 0.092688, loss_ce: 0.036221
2022-01-09 11:55:56,994 iteration 821 : loss : 0.103649, loss_ce: 0.039857
2022-01-09 11:55:59,284 iteration 822 : loss : 0.063939, loss_ce: 0.026299
2022-01-09 11:56:01,496 iteration 823 : loss : 0.093181, loss_ce: 0.035074
2022-01-09 11:56:03,681 iteration 824 : loss : 0.097625, loss_ce: 0.037850
2022-01-09 11:56:05,980 iteration 825 : loss : 0.102008, loss_ce: 0.032059
2022-01-09 11:56:08,343 iteration 826 : loss : 0.086847, loss_ce: 0.038543
2022-01-09 11:56:10,647 iteration 827 : loss : 0.111096, loss_ce: 0.031695
2022-01-09 11:56:12,983 iteration 828 : loss : 0.071074, loss_ce: 0.030289
2022-01-09 11:56:15,236 iteration 829 : loss : 0.106242, loss_ce: 0.030564
2022-01-09 11:56:17,517 iteration 830 : loss : 0.080847, loss_ce: 0.026850
2022-01-09 11:56:19,739 iteration 831 : loss : 0.120182, loss_ce: 0.047310
2022-01-09 11:56:21,902 iteration 832 : loss : 0.057793, loss_ce: 0.022953
2022-01-09 11:56:24,009 iteration 833 : loss : 0.072097, loss_ce: 0.034739
 12%|███▋                          | 49/400 [32:03<3:54:35, 40.10s/it]2022-01-09 11:56:26,209 iteration 834 : loss : 0.092901, loss_ce: 0.032476
2022-01-09 11:56:28,450 iteration 835 : loss : 0.101891, loss_ce: 0.043733
2022-01-09 11:56:30,733 iteration 836 : loss : 0.068471, loss_ce: 0.031379
2022-01-09 11:56:32,902 iteration 837 : loss : 0.065475, loss_ce: 0.029614
2022-01-09 11:56:35,120 iteration 838 : loss : 0.115204, loss_ce: 0.059281
2022-01-09 11:56:37,476 iteration 839 : loss : 0.075712, loss_ce: 0.025765
2022-01-09 11:56:39,846 iteration 840 : loss : 0.143859, loss_ce: 0.064374
2022-01-09 11:56:42,171 iteration 841 : loss : 0.076146, loss_ce: 0.043653
2022-01-09 11:56:44,595 iteration 842 : loss : 0.115051, loss_ce: 0.044714
2022-01-09 11:56:46,835 iteration 843 : loss : 0.072872, loss_ce: 0.028479
2022-01-09 11:56:49,115 iteration 844 : loss : 0.099971, loss_ce: 0.038076
2022-01-09 11:56:51,376 iteration 845 : loss : 0.065161, loss_ce: 0.025998
2022-01-09 11:56:53,675 iteration 846 : loss : 0.099021, loss_ce: 0.036728
2022-01-09 11:56:55,986 iteration 847 : loss : 0.080764, loss_ce: 0.033373
2022-01-09 11:56:58,244 iteration 848 : loss : 0.066755, loss_ce: 0.023138
2022-01-09 11:57:00,580 iteration 849 : loss : 0.067617, loss_ce: 0.030417
2022-01-09 11:57:00,580 Training Data Eval:
2022-01-09 11:57:13,737   Average segmentation loss on training set: 0.1906
2022-01-09 11:57:13,738 Validation Data Eval:
2022-01-09 11:57:18,126   Average segmentation loss on validation set: 0.1628
2022-01-09 11:57:20,569 iteration 850 : loss : 0.076785, loss_ce: 0.023779
 12%|███▊                          | 50/400 [32:59<4:22:42, 45.03s/it]2022-01-09 11:57:23,028 iteration 851 : loss : 0.074519, loss_ce: 0.035189
2022-01-09 11:57:25,415 iteration 852 : loss : 0.070812, loss_ce: 0.023425
2022-01-09 11:57:27,752 iteration 853 : loss : 0.089929, loss_ce: 0.035009
2022-01-09 11:57:30,091 iteration 854 : loss : 0.076515, loss_ce: 0.033033
2022-01-09 11:57:32,424 iteration 855 : loss : 0.062995, loss_ce: 0.026608
2022-01-09 11:57:34,764 iteration 856 : loss : 0.064651, loss_ce: 0.024309
2022-01-09 11:57:37,151 iteration 857 : loss : 0.107362, loss_ce: 0.046116
2022-01-09 11:57:39,507 iteration 858 : loss : 0.098378, loss_ce: 0.037580
2022-01-09 11:57:41,948 iteration 859 : loss : 0.074717, loss_ce: 0.027280
2022-01-09 11:57:44,261 iteration 860 : loss : 0.101736, loss_ce: 0.038688
2022-01-09 11:57:46,546 iteration 861 : loss : 0.084573, loss_ce: 0.032653
2022-01-09 11:57:48,900 iteration 862 : loss : 0.071430, loss_ce: 0.022058
2022-01-09 11:57:51,175 iteration 863 : loss : 0.099187, loss_ce: 0.045166
2022-01-09 11:57:53,630 iteration 864 : loss : 0.062330, loss_ce: 0.026569
2022-01-09 11:57:55,993 iteration 865 : loss : 0.058779, loss_ce: 0.028186
2022-01-09 11:57:58,328 iteration 866 : loss : 0.055657, loss_ce: 0.021659
2022-01-09 11:58:00,628 iteration 867 : loss : 0.062739, loss_ce: 0.026869
 13%|███▊                          | 51/400 [33:39<4:13:16, 43.54s/it]2022-01-09 11:58:02,964 iteration 868 : loss : 0.048182, loss_ce: 0.017511
2022-01-09 11:58:05,270 iteration 869 : loss : 0.069048, loss_ce: 0.030421
2022-01-09 11:58:07,715 iteration 870 : loss : 0.118296, loss_ce: 0.034021
2022-01-09 11:58:10,132 iteration 871 : loss : 0.099632, loss_ce: 0.031645
2022-01-09 11:58:12,491 iteration 872 : loss : 0.056444, loss_ce: 0.024925
2022-01-09 11:58:14,905 iteration 873 : loss : 0.045611, loss_ce: 0.016888
2022-01-09 11:58:17,315 iteration 874 : loss : 0.083200, loss_ce: 0.038851
2022-01-09 11:58:19,680 iteration 875 : loss : 0.101353, loss_ce: 0.050461
2022-01-09 11:58:22,034 iteration 876 : loss : 0.076532, loss_ce: 0.033727
2022-01-09 11:58:24,351 iteration 877 : loss : 0.050191, loss_ce: 0.016679
2022-01-09 11:58:26,649 iteration 878 : loss : 0.057328, loss_ce: 0.024164
2022-01-09 11:58:28,946 iteration 879 : loss : 0.077369, loss_ce: 0.030236
2022-01-09 11:58:31,338 iteration 880 : loss : 0.064313, loss_ce: 0.028555
2022-01-09 11:58:33,761 iteration 881 : loss : 0.081465, loss_ce: 0.034309
2022-01-09 11:58:36,091 iteration 882 : loss : 0.075904, loss_ce: 0.035726
2022-01-09 11:58:38,459 iteration 883 : loss : 0.107293, loss_ce: 0.034449
2022-01-09 11:58:40,919 iteration 884 : loss : 0.067937, loss_ce: 0.023577
 13%|███▉                          | 52/400 [34:20<4:06:52, 42.57s/it]2022-01-09 11:58:43,418 iteration 885 : loss : 0.080888, loss_ce: 0.035957
2022-01-09 11:58:45,722 iteration 886 : loss : 0.084800, loss_ce: 0.029574
2022-01-09 11:58:48,016 iteration 887 : loss : 0.086118, loss_ce: 0.039643
2022-01-09 11:58:50,376 iteration 888 : loss : 0.067977, loss_ce: 0.028124
2022-01-09 11:58:52,703 iteration 889 : loss : 0.089068, loss_ce: 0.029212
2022-01-09 11:58:55,107 iteration 890 : loss : 0.074161, loss_ce: 0.035140
2022-01-09 11:58:57,538 iteration 891 : loss : 0.089528, loss_ce: 0.043856
2022-01-09 11:58:59,935 iteration 892 : loss : 0.080853, loss_ce: 0.027536
2022-01-09 11:59:02,332 iteration 893 : loss : 0.096380, loss_ce: 0.042841
2022-01-09 11:59:04,689 iteration 894 : loss : 0.082483, loss_ce: 0.035040
2022-01-09 11:59:06,993 iteration 895 : loss : 0.076703, loss_ce: 0.027461
2022-01-09 11:59:09,350 iteration 896 : loss : 0.112724, loss_ce: 0.036583
2022-01-09 11:59:11,819 iteration 897 : loss : 0.067225, loss_ce: 0.028326
2022-01-09 11:59:14,310 iteration 898 : loss : 0.088927, loss_ce: 0.039446
2022-01-09 11:59:16,650 iteration 899 : loss : 0.085062, loss_ce: 0.033909
2022-01-09 11:59:18,941 iteration 900 : loss : 0.094594, loss_ce: 0.036113
2022-01-09 11:59:21,194 iteration 901 : loss : 0.080155, loss_ce: 0.047237
 13%|███▉                          | 53/400 [35:00<4:02:12, 41.88s/it]2022-01-09 11:59:23,663 iteration 902 : loss : 0.070343, loss_ce: 0.028761
2022-01-09 11:59:26,084 iteration 903 : loss : 0.068485, loss_ce: 0.021626
2022-01-09 11:59:28,405 iteration 904 : loss : 0.095420, loss_ce: 0.045815
2022-01-09 11:59:30,774 iteration 905 : loss : 0.119471, loss_ce: 0.031426
2022-01-09 11:59:33,114 iteration 906 : loss : 0.067930, loss_ce: 0.024989
2022-01-09 11:59:35,572 iteration 907 : loss : 0.050262, loss_ce: 0.025532
2022-01-09 11:59:37,944 iteration 908 : loss : 0.061141, loss_ce: 0.032071
2022-01-09 11:59:40,331 iteration 909 : loss : 0.092288, loss_ce: 0.041916
2022-01-09 11:59:42,863 iteration 910 : loss : 0.112128, loss_ce: 0.048545
2022-01-09 11:59:45,307 iteration 911 : loss : 0.094544, loss_ce: 0.034979
2022-01-09 11:59:47,823 iteration 912 : loss : 0.093156, loss_ce: 0.035150
2022-01-09 11:59:50,266 iteration 913 : loss : 0.076384, loss_ce: 0.028683
2022-01-09 11:59:52,587 iteration 914 : loss : 0.057877, loss_ce: 0.027959
2022-01-09 11:59:54,878 iteration 915 : loss : 0.074840, loss_ce: 0.034169
2022-01-09 11:59:57,083 iteration 916 : loss : 0.081166, loss_ce: 0.034118
2022-01-09 11:59:59,354 iteration 917 : loss : 0.088603, loss_ce: 0.032997
2022-01-09 12:00:01,679 iteration 918 : loss : 0.069482, loss_ce: 0.025019
 14%|████                          | 54/400 [35:40<3:59:06, 41.46s/it]2022-01-09 12:00:04,122 iteration 919 : loss : 0.066278, loss_ce: 0.027476
2022-01-09 12:00:06,473 iteration 920 : loss : 0.140150, loss_ce: 0.103385
2022-01-09 12:00:08,933 iteration 921 : loss : 0.076063, loss_ce: 0.033540
2022-01-09 12:00:11,225 iteration 922 : loss : 0.066278, loss_ce: 0.028492
2022-01-09 12:00:13,642 iteration 923 : loss : 0.082452, loss_ce: 0.034047
2022-01-09 12:00:16,057 iteration 924 : loss : 0.060609, loss_ce: 0.019915
2022-01-09 12:00:18,379 iteration 925 : loss : 0.058444, loss_ce: 0.020216
2022-01-09 12:00:20,697 iteration 926 : loss : 0.090139, loss_ce: 0.032374
2022-01-09 12:00:23,050 iteration 927 : loss : 0.081649, loss_ce: 0.038132
2022-01-09 12:00:25,387 iteration 928 : loss : 0.076468, loss_ce: 0.024769
2022-01-09 12:00:27,901 iteration 929 : loss : 0.085472, loss_ce: 0.037726
2022-01-09 12:00:30,256 iteration 930 : loss : 0.071432, loss_ce: 0.044315
2022-01-09 12:00:32,613 iteration 931 : loss : 0.081044, loss_ce: 0.029667
2022-01-09 12:00:35,009 iteration 932 : loss : 0.104668, loss_ce: 0.035222
2022-01-09 12:00:37,527 iteration 933 : loss : 0.138155, loss_ce: 0.045703
2022-01-09 12:00:39,911 iteration 934 : loss : 0.070028, loss_ce: 0.027133
2022-01-09 12:00:39,911 Training Data Eval:
2022-01-09 12:00:52,981   Average segmentation loss on training set: 0.0597
2022-01-09 12:00:52,981 Validation Data Eval:
2022-01-09 12:00:57,381   Average segmentation loss on validation set: 0.1360
2022-01-09 12:00:59,771 iteration 935 : loss : 0.106227, loss_ce: 0.035738
 14%|████▏                         | 55/400 [36:38<4:27:05, 46.45s/it]2022-01-09 12:01:02,369 iteration 936 : loss : 0.109237, loss_ce: 0.029896
2022-01-09 12:01:04,768 iteration 937 : loss : 0.078114, loss_ce: 0.032420
2022-01-09 12:01:07,150 iteration 938 : loss : 0.066134, loss_ce: 0.034619
2022-01-09 12:01:09,544 iteration 939 : loss : 0.065253, loss_ce: 0.030123
2022-01-09 12:01:11,941 iteration 940 : loss : 0.085406, loss_ce: 0.035630
2022-01-09 12:01:14,310 iteration 941 : loss : 0.097994, loss_ce: 0.033076
2022-01-09 12:01:16,682 iteration 942 : loss : 0.076491, loss_ce: 0.025381
2022-01-09 12:01:18,996 iteration 943 : loss : 0.106064, loss_ce: 0.037450
2022-01-09 12:01:21,463 iteration 944 : loss : 0.059331, loss_ce: 0.024003
2022-01-09 12:01:23,847 iteration 945 : loss : 0.096183, loss_ce: 0.051867
2022-01-09 12:01:26,240 iteration 946 : loss : 0.056450, loss_ce: 0.021099
2022-01-09 12:01:28,669 iteration 947 : loss : 0.059310, loss_ce: 0.027255
2022-01-09 12:01:31,128 iteration 948 : loss : 0.072880, loss_ce: 0.029559
2022-01-09 12:01:33,534 iteration 949 : loss : 0.064078, loss_ce: 0.025344
2022-01-09 12:01:36,038 iteration 950 : loss : 0.103276, loss_ce: 0.030910
2022-01-09 12:01:38,514 iteration 951 : loss : 0.078519, loss_ce: 0.037857
2022-01-09 12:01:40,816 iteration 952 : loss : 0.088837, loss_ce: 0.027350
 14%|████▏                         | 56/400 [37:20<4:17:01, 44.83s/it]2022-01-09 12:01:43,182 iteration 953 : loss : 0.067702, loss_ce: 0.023440
2022-01-09 12:01:45,594 iteration 954 : loss : 0.053303, loss_ce: 0.019306
2022-01-09 12:01:47,897 iteration 955 : loss : 0.038502, loss_ce: 0.015873
2022-01-09 12:01:50,241 iteration 956 : loss : 0.062595, loss_ce: 0.028324
2022-01-09 12:01:52,712 iteration 957 : loss : 0.094873, loss_ce: 0.032664
2022-01-09 12:01:55,108 iteration 958 : loss : 0.076543, loss_ce: 0.023290
2022-01-09 12:01:57,437 iteration 959 : loss : 0.079631, loss_ce: 0.036518
2022-01-09 12:01:59,719 iteration 960 : loss : 0.059245, loss_ce: 0.022088
2022-01-09 12:02:02,085 iteration 961 : loss : 0.081510, loss_ce: 0.028263
2022-01-09 12:02:04,446 iteration 962 : loss : 0.057242, loss_ce: 0.022072
2022-01-09 12:02:06,857 iteration 963 : loss : 0.072892, loss_ce: 0.026569
2022-01-09 12:02:09,268 iteration 964 : loss : 0.089988, loss_ce: 0.038078
2022-01-09 12:02:11,643 iteration 965 : loss : 0.051772, loss_ce: 0.020427
2022-01-09 12:02:14,032 iteration 966 : loss : 0.090822, loss_ce: 0.041690
2022-01-09 12:02:16,389 iteration 967 : loss : 0.133079, loss_ce: 0.059693
2022-01-09 12:02:18,776 iteration 968 : loss : 0.067003, loss_ce: 0.030570
2022-01-09 12:02:21,219 iteration 969 : loss : 0.071235, loss_ce: 0.027825
 14%|████▎                         | 57/400 [38:00<4:08:39, 43.50s/it]2022-01-09 12:02:23,608 iteration 970 : loss : 0.059306, loss_ce: 0.025623
2022-01-09 12:02:26,041 iteration 971 : loss : 0.100281, loss_ce: 0.042324
2022-01-09 12:02:28,351 iteration 972 : loss : 0.054468, loss_ce: 0.020895
2022-01-09 12:02:30,768 iteration 973 : loss : 0.071095, loss_ce: 0.029978
2022-01-09 12:02:33,143 iteration 974 : loss : 0.077962, loss_ce: 0.032691
2022-01-09 12:02:35,453 iteration 975 : loss : 0.077888, loss_ce: 0.026063
2022-01-09 12:02:37,809 iteration 976 : loss : 0.095956, loss_ce: 0.031662
2022-01-09 12:02:40,200 iteration 977 : loss : 0.075079, loss_ce: 0.027753
2022-01-09 12:02:42,551 iteration 978 : loss : 0.096182, loss_ce: 0.046223
2022-01-09 12:02:45,186 iteration 979 : loss : 0.047261, loss_ce: 0.022292
2022-01-09 12:02:47,555 iteration 980 : loss : 0.083189, loss_ce: 0.027951
2022-01-09 12:02:49,963 iteration 981 : loss : 0.062724, loss_ce: 0.023031
2022-01-09 12:02:52,229 iteration 982 : loss : 0.086637, loss_ce: 0.045299
2022-01-09 12:02:54,605 iteration 983 : loss : 0.078393, loss_ce: 0.034811
2022-01-09 12:02:57,107 iteration 984 : loss : 0.063445, loss_ce: 0.030704
2022-01-09 12:02:59,489 iteration 985 : loss : 0.087724, loss_ce: 0.027521
2022-01-09 12:03:01,875 iteration 986 : loss : 0.087471, loss_ce: 0.026605
 14%|████▎                         | 58/400 [38:41<4:03:05, 42.65s/it]2022-01-09 12:03:04,328 iteration 987 : loss : 0.056809, loss_ce: 0.027889
2022-01-09 12:03:06,801 iteration 988 : loss : 0.082489, loss_ce: 0.034835
2022-01-09 12:03:09,115 iteration 989 : loss : 0.063821, loss_ce: 0.022510
2022-01-09 12:03:11,521 iteration 990 : loss : 0.060847, loss_ce: 0.031891
2022-01-09 12:03:13,961 iteration 991 : loss : 0.096068, loss_ce: 0.043926
2022-01-09 12:03:16,337 iteration 992 : loss : 0.076880, loss_ce: 0.031038
2022-01-09 12:03:18,809 iteration 993 : loss : 0.056483, loss_ce: 0.022994
2022-01-09 12:03:21,116 iteration 994 : loss : 0.089275, loss_ce: 0.028805
2022-01-09 12:03:23,353 iteration 995 : loss : 0.077474, loss_ce: 0.031679
2022-01-09 12:03:25,561 iteration 996 : loss : 0.062711, loss_ce: 0.025747
2022-01-09 12:03:27,909 iteration 997 : loss : 0.066382, loss_ce: 0.029275
2022-01-09 12:03:30,254 iteration 998 : loss : 0.088711, loss_ce: 0.031323
2022-01-09 12:03:32,606 iteration 999 : loss : 0.085813, loss_ce: 0.036688
2022-01-09 12:03:34,834 iteration 1000 : loss : 0.065037, loss_ce: 0.029851
2022-01-09 12:03:37,166 iteration 1001 : loss : 0.077472, loss_ce: 0.029891
2022-01-09 12:03:39,516 iteration 1002 : loss : 0.064136, loss_ce: 0.020178
2022-01-09 12:03:41,958 iteration 1003 : loss : 0.087856, loss_ce: 0.034476
 15%|████▍                         | 59/400 [39:21<3:58:01, 41.88s/it]2022-01-09 12:03:44,382 iteration 1004 : loss : 0.071572, loss_ce: 0.031763
2022-01-09 12:03:46,786 iteration 1005 : loss : 0.117255, loss_ce: 0.038732
2022-01-09 12:03:49,031 iteration 1006 : loss : 0.074419, loss_ce: 0.034465
2022-01-09 12:03:51,292 iteration 1007 : loss : 0.077396, loss_ce: 0.032725
2022-01-09 12:03:53,612 iteration 1008 : loss : 0.112493, loss_ce: 0.037609
2022-01-09 12:03:55,946 iteration 1009 : loss : 0.077790, loss_ce: 0.028450
2022-01-09 12:03:58,227 iteration 1010 : loss : 0.081207, loss_ce: 0.033729
2022-01-09 12:04:00,501 iteration 1011 : loss : 0.061447, loss_ce: 0.023094
2022-01-09 12:04:02,961 iteration 1012 : loss : 0.112172, loss_ce: 0.036996
2022-01-09 12:04:05,294 iteration 1013 : loss : 0.098599, loss_ce: 0.034826
2022-01-09 12:04:07,727 iteration 1014 : loss : 0.062072, loss_ce: 0.024489
2022-01-09 12:04:10,066 iteration 1015 : loss : 0.082380, loss_ce: 0.036498
2022-01-09 12:04:12,287 iteration 1016 : loss : 0.079740, loss_ce: 0.039356
2022-01-09 12:04:14,668 iteration 1017 : loss : 0.071193, loss_ce: 0.023372
2022-01-09 12:04:17,155 iteration 1018 : loss : 0.057935, loss_ce: 0.023667
2022-01-09 12:04:19,585 iteration 1019 : loss : 0.095074, loss_ce: 0.042031
2022-01-09 12:04:19,585 Training Data Eval:
2022-01-09 12:04:32,158   Average segmentation loss on training set: 0.0639
2022-01-09 12:04:32,158 Validation Data Eval:
2022-01-09 12:04:36,708   Average segmentation loss on validation set: 0.1476
2022-01-09 12:04:39,145 iteration 1020 : loss : 0.069755, loss_ce: 0.024459
 15%|████▌                         | 60/400 [40:18<4:23:21, 46.47s/it]2022-01-09 12:04:41,589 iteration 1021 : loss : 0.096455, loss_ce: 0.039498
2022-01-09 12:04:43,875 iteration 1022 : loss : 0.074229, loss_ce: 0.028468
2022-01-09 12:04:46,185 iteration 1023 : loss : 0.115021, loss_ce: 0.037921
2022-01-09 12:04:48,523 iteration 1024 : loss : 0.041997, loss_ce: 0.020521
2022-01-09 12:04:50,785 iteration 1025 : loss : 0.105125, loss_ce: 0.047540
2022-01-09 12:04:53,120 iteration 1026 : loss : 0.081138, loss_ce: 0.029442
2022-01-09 12:04:55,458 iteration 1027 : loss : 0.079016, loss_ce: 0.043586
2022-01-09 12:04:57,740 iteration 1028 : loss : 0.073177, loss_ce: 0.022526
2022-01-09 12:05:00,135 iteration 1029 : loss : 0.090922, loss_ce: 0.023107
2022-01-09 12:05:02,659 iteration 1030 : loss : 0.107516, loss_ce: 0.045599
2022-01-09 12:05:05,123 iteration 1031 : loss : 0.067824, loss_ce: 0.030183
2022-01-09 12:05:07,497 iteration 1032 : loss : 0.049365, loss_ce: 0.018198
2022-01-09 12:05:09,909 iteration 1033 : loss : 0.062662, loss_ce: 0.024018
2022-01-09 12:05:12,252 iteration 1034 : loss : 0.051216, loss_ce: 0.024210
2022-01-09 12:05:14,602 iteration 1035 : loss : 0.099904, loss_ce: 0.039548
2022-01-09 12:05:16,965 iteration 1036 : loss : 0.090701, loss_ce: 0.042850
2022-01-09 12:05:19,261 iteration 1037 : loss : 0.050270, loss_ce: 0.022594
 15%|████▌                         | 61/400 [40:58<4:11:47, 44.57s/it]2022-01-09 12:05:21,687 iteration 1038 : loss : 0.077031, loss_ce: 0.033469
2022-01-09 12:05:24,083 iteration 1039 : loss : 0.059489, loss_ce: 0.022127
2022-01-09 12:05:26,443 iteration 1040 : loss : 0.066856, loss_ce: 0.022135
2022-01-09 12:05:28,908 iteration 1041 : loss : 0.073341, loss_ce: 0.026551
2022-01-09 12:05:31,274 iteration 1042 : loss : 0.075576, loss_ce: 0.026127
2022-01-09 12:05:33,504 iteration 1043 : loss : 0.049997, loss_ce: 0.017801
2022-01-09 12:05:35,801 iteration 1044 : loss : 0.049545, loss_ce: 0.020354
2022-01-09 12:05:38,038 iteration 1045 : loss : 0.064223, loss_ce: 0.036692
2022-01-09 12:05:40,279 iteration 1046 : loss : 0.078086, loss_ce: 0.027907
2022-01-09 12:05:42,609 iteration 1047 : loss : 0.085881, loss_ce: 0.037781
2022-01-09 12:05:44,865 iteration 1048 : loss : 0.091788, loss_ce: 0.040080
2022-01-09 12:05:47,106 iteration 1049 : loss : 0.069723, loss_ce: 0.028408
2022-01-09 12:05:49,412 iteration 1050 : loss : 0.068322, loss_ce: 0.027644
2022-01-09 12:05:51,669 iteration 1051 : loss : 0.066328, loss_ce: 0.024353
2022-01-09 12:05:53,849 iteration 1052 : loss : 0.090930, loss_ce: 0.048642
2022-01-09 12:05:56,079 iteration 1053 : loss : 0.060537, loss_ce: 0.024784
2022-01-09 12:05:58,297 iteration 1054 : loss : 0.062466, loss_ce: 0.024108
 16%|████▋                         | 62/400 [41:37<4:01:41, 42.90s/it]2022-01-09 12:06:00,601 iteration 1055 : loss : 0.055834, loss_ce: 0.021022
2022-01-09 12:06:02,823 iteration 1056 : loss : 0.083345, loss_ce: 0.037026
2022-01-09 12:06:05,068 iteration 1057 : loss : 0.094249, loss_ce: 0.022289
2022-01-09 12:06:07,276 iteration 1058 : loss : 0.054893, loss_ce: 0.023252
2022-01-09 12:06:09,701 iteration 1059 : loss : 0.058170, loss_ce: 0.025442
2022-01-09 12:06:11,999 iteration 1060 : loss : 0.063231, loss_ce: 0.029972
2022-01-09 12:06:14,393 iteration 1061 : loss : 0.078989, loss_ce: 0.029753
2022-01-09 12:06:16,674 iteration 1062 : loss : 0.058681, loss_ce: 0.022181
2022-01-09 12:06:19,011 iteration 1063 : loss : 0.054329, loss_ce: 0.020082
2022-01-09 12:06:21,205 iteration 1064 : loss : 0.054662, loss_ce: 0.026524
2022-01-09 12:06:23,430 iteration 1065 : loss : 0.077640, loss_ce: 0.024487
2022-01-09 12:06:25,660 iteration 1066 : loss : 0.059246, loss_ce: 0.030148
2022-01-09 12:06:27,994 iteration 1067 : loss : 0.080432, loss_ce: 0.034452
2022-01-09 12:06:30,316 iteration 1068 : loss : 0.111359, loss_ce: 0.044518
2022-01-09 12:06:32,562 iteration 1069 : loss : 0.085827, loss_ce: 0.034068
2022-01-09 12:06:34,877 iteration 1070 : loss : 0.063718, loss_ce: 0.022266
2022-01-09 12:06:37,086 iteration 1071 : loss : 0.067019, loss_ce: 0.027653
 16%|████▋                         | 63/400 [42:16<3:54:02, 41.67s/it]2022-01-09 12:06:39,330 iteration 1072 : loss : 0.063068, loss_ce: 0.024610
2022-01-09 12:06:41,634 iteration 1073 : loss : 0.078993, loss_ce: 0.028044
2022-01-09 12:06:43,844 iteration 1074 : loss : 0.051592, loss_ce: 0.026098
2022-01-09 12:06:46,098 iteration 1075 : loss : 0.048680, loss_ce: 0.016993
2022-01-09 12:06:48,361 iteration 1076 : loss : 0.076710, loss_ce: 0.030807
2022-01-09 12:06:50,768 iteration 1077 : loss : 0.138768, loss_ce: 0.041669
2022-01-09 12:06:53,010 iteration 1078 : loss : 0.094883, loss_ce: 0.035148
2022-01-09 12:06:55,318 iteration 1079 : loss : 0.081907, loss_ce: 0.035157
2022-01-09 12:06:57,714 iteration 1080 : loss : 0.071293, loss_ce: 0.029593
2022-01-09 12:07:00,141 iteration 1081 : loss : 0.086907, loss_ce: 0.034014
2022-01-09 12:07:02,459 iteration 1082 : loss : 0.100599, loss_ce: 0.042187
2022-01-09 12:07:04,731 iteration 1083 : loss : 0.085907, loss_ce: 0.029604
2022-01-09 12:07:06,990 iteration 1084 : loss : 0.132478, loss_ce: 0.039463
2022-01-09 12:07:09,245 iteration 1085 : loss : 0.051720, loss_ce: 0.018865
2022-01-09 12:07:11,527 iteration 1086 : loss : 0.070060, loss_ce: 0.025543
2022-01-09 12:07:13,814 iteration 1087 : loss : 0.049448, loss_ce: 0.020166
2022-01-09 12:07:16,122 iteration 1088 : loss : 0.076861, loss_ce: 0.035114
 16%|████▊                         | 64/400 [42:55<3:48:56, 40.88s/it]2022-01-09 12:07:18,436 iteration 1089 : loss : 0.076166, loss_ce: 0.033558
2022-01-09 12:07:21,017 iteration 1090 : loss : 0.065318, loss_ce: 0.021893
2022-01-09 12:07:23,446 iteration 1091 : loss : 0.085046, loss_ce: 0.048740
2022-01-09 12:07:25,764 iteration 1092 : loss : 0.066448, loss_ce: 0.020158
2022-01-09 12:07:28,047 iteration 1093 : loss : 0.091634, loss_ce: 0.029646
2022-01-09 12:07:30,366 iteration 1094 : loss : 0.160261, loss_ce: 0.043035
2022-01-09 12:07:32,532 iteration 1095 : loss : 0.067243, loss_ce: 0.025086
2022-01-09 12:07:34,776 iteration 1096 : loss : 0.071899, loss_ce: 0.033137
2022-01-09 12:07:37,052 iteration 1097 : loss : 0.055624, loss_ce: 0.022170
2022-01-09 12:07:39,501 iteration 1098 : loss : 0.062162, loss_ce: 0.029752
2022-01-09 12:07:41,860 iteration 1099 : loss : 0.060732, loss_ce: 0.021610
2022-01-09 12:07:44,277 iteration 1100 : loss : 0.082280, loss_ce: 0.037346
2022-01-09 12:07:46,611 iteration 1101 : loss : 0.060715, loss_ce: 0.026887
2022-01-09 12:07:48,795 iteration 1102 : loss : 0.097488, loss_ce: 0.047311
2022-01-09 12:07:51,010 iteration 1103 : loss : 0.057488, loss_ce: 0.025155
2022-01-09 12:07:53,305 iteration 1104 : loss : 0.080580, loss_ce: 0.035543
2022-01-09 12:07:53,305 Training Data Eval:
2022-01-09 12:08:05,643   Average segmentation loss on training set: 0.0490
2022-01-09 12:08:05,644 Validation Data Eval:
2022-01-09 12:08:10,037   Average segmentation loss on validation set: 0.0788
2022-01-09 12:08:15,989 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 12:08:17,591 iteration 1105 : loss : 0.061318, loss_ce: 0.026793
 16%|████▉                         | 65/400 [43:56<4:22:44, 47.06s/it]2022-01-09 12:08:19,282 iteration 1106 : loss : 0.061631, loss_ce: 0.022134
2022-01-09 12:08:20,904 iteration 1107 : loss : 0.065105, loss_ce: 0.024443
2022-01-09 12:08:22,611 iteration 1108 : loss : 0.067573, loss_ce: 0.021614
2022-01-09 12:08:24,520 iteration 1109 : loss : 0.074493, loss_ce: 0.026568
2022-01-09 12:08:26,459 iteration 1110 : loss : 0.049749, loss_ce: 0.019035
2022-01-09 12:08:28,516 iteration 1111 : loss : 0.118968, loss_ce: 0.038630
2022-01-09 12:08:30,520 iteration 1112 : loss : 0.073379, loss_ce: 0.032956
2022-01-09 12:08:32,622 iteration 1113 : loss : 0.069311, loss_ce: 0.022740
2022-01-09 12:08:34,756 iteration 1114 : loss : 0.063298, loss_ce: 0.023339
2022-01-09 12:08:36,916 iteration 1115 : loss : 0.038576, loss_ce: 0.016260
2022-01-09 12:08:38,948 iteration 1116 : loss : 0.080650, loss_ce: 0.040271
2022-01-09 12:08:41,041 iteration 1117 : loss : 0.057280, loss_ce: 0.023323
2022-01-09 12:08:43,292 iteration 1118 : loss : 0.068408, loss_ce: 0.030282
2022-01-09 12:08:45,478 iteration 1119 : loss : 0.054494, loss_ce: 0.024529
2022-01-09 12:08:47,607 iteration 1120 : loss : 0.055889, loss_ce: 0.017146
2022-01-09 12:08:49,683 iteration 1121 : loss : 0.061419, loss_ce: 0.029549
2022-01-09 12:08:51,842 iteration 1122 : loss : 0.067493, loss_ce: 0.021487
 16%|████▉                         | 66/400 [44:31<4:00:34, 43.22s/it]2022-01-09 12:08:54,223 iteration 1123 : loss : 0.048586, loss_ce: 0.017972
2022-01-09 12:08:56,401 iteration 1124 : loss : 0.044811, loss_ce: 0.020935
2022-01-09 12:08:58,517 iteration 1125 : loss : 0.080855, loss_ce: 0.027501
2022-01-09 12:09:00,771 iteration 1126 : loss : 0.062937, loss_ce: 0.021606
2022-01-09 12:09:03,137 iteration 1127 : loss : 0.061629, loss_ce: 0.026138
2022-01-09 12:09:05,530 iteration 1128 : loss : 0.067552, loss_ce: 0.027428
2022-01-09 12:09:07,839 iteration 1129 : loss : 0.083750, loss_ce: 0.035247
2022-01-09 12:09:10,014 iteration 1130 : loss : 0.065601, loss_ce: 0.027776
2022-01-09 12:09:12,365 iteration 1131 : loss : 0.087116, loss_ce: 0.039899
2022-01-09 12:09:14,698 iteration 1132 : loss : 0.061736, loss_ce: 0.023371
2022-01-09 12:09:17,007 iteration 1133 : loss : 0.088828, loss_ce: 0.041429
2022-01-09 12:09:19,274 iteration 1134 : loss : 0.073395, loss_ce: 0.022662
2022-01-09 12:09:21,505 iteration 1135 : loss : 0.073253, loss_ce: 0.027607
2022-01-09 12:09:23,744 iteration 1136 : loss : 0.046315, loss_ce: 0.021327
2022-01-09 12:09:26,006 iteration 1137 : loss : 0.088411, loss_ce: 0.051068
2022-01-09 12:09:28,364 iteration 1138 : loss : 0.102463, loss_ce: 0.039598
2022-01-09 12:09:30,675 iteration 1139 : loss : 0.071059, loss_ce: 0.031506
 17%|█████                         | 67/400 [45:09<3:52:32, 41.90s/it]2022-01-09 12:09:33,109 iteration 1140 : loss : 0.050508, loss_ce: 0.020010
2022-01-09 12:09:35,501 iteration 1141 : loss : 0.072577, loss_ce: 0.033836
2022-01-09 12:09:37,985 iteration 1142 : loss : 0.070503, loss_ce: 0.030928
2022-01-09 12:09:40,383 iteration 1143 : loss : 0.072728, loss_ce: 0.031428
2022-01-09 12:09:42,815 iteration 1144 : loss : 0.073465, loss_ce: 0.026140
2022-01-09 12:09:45,197 iteration 1145 : loss : 0.076488, loss_ce: 0.027774
2022-01-09 12:09:47,541 iteration 1146 : loss : 0.053414, loss_ce: 0.024709
2022-01-09 12:09:49,913 iteration 1147 : loss : 0.056346, loss_ce: 0.021250
2022-01-09 12:09:52,247 iteration 1148 : loss : 0.064060, loss_ce: 0.025664
2022-01-09 12:09:54,637 iteration 1149 : loss : 0.044597, loss_ce: 0.022683
2022-01-09 12:09:56,964 iteration 1150 : loss : 0.056315, loss_ce: 0.020967
2022-01-09 12:09:59,272 iteration 1151 : loss : 0.047201, loss_ce: 0.021942
2022-01-09 12:10:01,578 iteration 1152 : loss : 0.071316, loss_ce: 0.027855
2022-01-09 12:10:03,962 iteration 1153 : loss : 0.072921, loss_ce: 0.023250
2022-01-09 12:10:06,349 iteration 1154 : loss : 0.058268, loss_ce: 0.021305
2022-01-09 12:10:08,953 iteration 1155 : loss : 0.068706, loss_ce: 0.027790
2022-01-09 12:10:11,473 iteration 1156 : loss : 0.075802, loss_ce: 0.026492
 17%|█████                         | 68/400 [45:50<3:50:00, 41.57s/it]2022-01-09 12:10:13,871 iteration 1157 : loss : 0.075149, loss_ce: 0.033265
2022-01-09 12:10:16,189 iteration 1158 : loss : 0.051910, loss_ce: 0.018703
2022-01-09 12:10:18,446 iteration 1159 : loss : 0.063052, loss_ce: 0.024023
2022-01-09 12:10:20,737 iteration 1160 : loss : 0.065743, loss_ce: 0.029610
2022-01-09 12:10:23,079 iteration 1161 : loss : 0.053830, loss_ce: 0.020695
2022-01-09 12:10:25,436 iteration 1162 : loss : 0.072492, loss_ce: 0.030480
2022-01-09 12:10:27,861 iteration 1163 : loss : 0.052068, loss_ce: 0.025074
2022-01-09 12:10:30,280 iteration 1164 : loss : 0.072584, loss_ce: 0.031727
2022-01-09 12:10:32,532 iteration 1165 : loss : 0.048629, loss_ce: 0.024289
2022-01-09 12:10:34,913 iteration 1166 : loss : 0.076273, loss_ce: 0.025794
2022-01-09 12:10:37,279 iteration 1167 : loss : 0.072213, loss_ce: 0.037070
2022-01-09 12:10:39,616 iteration 1168 : loss : 0.113146, loss_ce: 0.034665
2022-01-09 12:10:41,792 iteration 1169 : loss : 0.079366, loss_ce: 0.024762
2022-01-09 12:10:44,071 iteration 1170 : loss : 0.083260, loss_ce: 0.030134
2022-01-09 12:10:46,387 iteration 1171 : loss : 0.100280, loss_ce: 0.026713
2022-01-09 12:10:48,621 iteration 1172 : loss : 0.057694, loss_ce: 0.021966
2022-01-09 12:10:50,962 iteration 1173 : loss : 0.040263, loss_ce: 0.014726
 17%|█████▏                        | 69/400 [46:30<3:45:53, 40.95s/it]2022-01-09 12:10:53,409 iteration 1174 : loss : 0.078296, loss_ce: 0.026192
2022-01-09 12:10:55,773 iteration 1175 : loss : 0.076999, loss_ce: 0.032294
2022-01-09 12:10:58,064 iteration 1176 : loss : 0.068755, loss_ce: 0.025907
2022-01-09 12:11:00,370 iteration 1177 : loss : 0.071169, loss_ce: 0.029006
2022-01-09 12:11:02,710 iteration 1178 : loss : 0.074017, loss_ce: 0.027072
2022-01-09 12:11:05,274 iteration 1179 : loss : 0.052932, loss_ce: 0.021923
2022-01-09 12:11:07,691 iteration 1180 : loss : 0.062149, loss_ce: 0.025732
2022-01-09 12:11:09,984 iteration 1181 : loss : 0.084076, loss_ce: 0.029825
2022-01-09 12:11:12,361 iteration 1182 : loss : 0.063319, loss_ce: 0.027273
2022-01-09 12:11:14,771 iteration 1183 : loss : 0.047418, loss_ce: 0.020063
2022-01-09 12:11:17,147 iteration 1184 : loss : 0.076193, loss_ce: 0.032966
2022-01-09 12:11:19,396 iteration 1185 : loss : 0.072189, loss_ce: 0.040218
2022-01-09 12:11:21,731 iteration 1186 : loss : 0.056206, loss_ce: 0.019797
2022-01-09 12:11:24,041 iteration 1187 : loss : 0.042178, loss_ce: 0.019217
2022-01-09 12:11:26,434 iteration 1188 : loss : 0.083256, loss_ce: 0.030592
2022-01-09 12:11:28,849 iteration 1189 : loss : 0.106972, loss_ce: 0.024137
2022-01-09 12:11:28,850 Training Data Eval:
2022-01-09 12:11:41,761   Average segmentation loss on training set: 0.0512
2022-01-09 12:11:41,761 Validation Data Eval:
2022-01-09 12:11:46,300   Average segmentation loss on validation set: 0.1079
2022-01-09 12:11:48,690 iteration 1190 : loss : 0.061445, loss_ce: 0.020109
 18%|█████▎                        | 70/400 [47:27<4:12:53, 45.98s/it]2022-01-09 12:11:51,102 iteration 1191 : loss : 0.057410, loss_ce: 0.023152
2022-01-09 12:11:53,351 iteration 1192 : loss : 0.094826, loss_ce: 0.050196
2022-01-09 12:11:55,753 iteration 1193 : loss : 0.065433, loss_ce: 0.025791
2022-01-09 12:11:58,147 iteration 1194 : loss : 0.058095, loss_ce: 0.020595
2022-01-09 12:12:00,524 iteration 1195 : loss : 0.069150, loss_ce: 0.026530
2022-01-09 12:12:02,952 iteration 1196 : loss : 0.056627, loss_ce: 0.024479
2022-01-09 12:12:05,359 iteration 1197 : loss : 0.069788, loss_ce: 0.023109
2022-01-09 12:12:07,857 iteration 1198 : loss : 0.045148, loss_ce: 0.018013
2022-01-09 12:12:10,265 iteration 1199 : loss : 0.069188, loss_ce: 0.033978
2022-01-09 12:12:12,578 iteration 1200 : loss : 0.046103, loss_ce: 0.018671
2022-01-09 12:12:14,885 iteration 1201 : loss : 0.082202, loss_ce: 0.028584
2022-01-09 12:12:17,239 iteration 1202 : loss : 0.051061, loss_ce: 0.020719
2022-01-09 12:12:19,820 iteration 1203 : loss : 0.074584, loss_ce: 0.035244
2022-01-09 12:12:22,174 iteration 1204 : loss : 0.070118, loss_ce: 0.018005
2022-01-09 12:12:24,563 iteration 1205 : loss : 0.057542, loss_ce: 0.027205
2022-01-09 12:12:26,879 iteration 1206 : loss : 0.066872, loss_ce: 0.025281
2022-01-09 12:12:29,327 iteration 1207 : loss : 0.054504, loss_ce: 0.023430
 18%|█████▎                        | 71/400 [48:08<4:03:19, 44.38s/it]2022-01-09 12:12:31,706 iteration 1208 : loss : 0.077412, loss_ce: 0.031049
2022-01-09 12:12:34,031 iteration 1209 : loss : 0.089386, loss_ce: 0.027895
2022-01-09 12:12:36,355 iteration 1210 : loss : 0.064328, loss_ce: 0.024004
2022-01-09 12:12:38,777 iteration 1211 : loss : 0.054109, loss_ce: 0.024306
2022-01-09 12:12:41,189 iteration 1212 : loss : 0.047448, loss_ce: 0.019709
2022-01-09 12:12:43,644 iteration 1213 : loss : 0.043223, loss_ce: 0.015282
2022-01-09 12:12:46,110 iteration 1214 : loss : 0.077196, loss_ce: 0.033839
2022-01-09 12:12:48,450 iteration 1215 : loss : 0.047336, loss_ce: 0.018576
2022-01-09 12:12:50,791 iteration 1216 : loss : 0.063008, loss_ce: 0.026019
2022-01-09 12:12:53,177 iteration 1217 : loss : 0.079859, loss_ce: 0.028793
2022-01-09 12:12:55,392 iteration 1218 : loss : 0.075889, loss_ce: 0.037521
2022-01-09 12:12:57,880 iteration 1219 : loss : 0.078087, loss_ce: 0.040024
2022-01-09 12:13:00,199 iteration 1220 : loss : 0.057910, loss_ce: 0.022495
2022-01-09 12:13:02,636 iteration 1221 : loss : 0.058900, loss_ce: 0.020724
2022-01-09 12:13:04,992 iteration 1222 : loss : 0.094864, loss_ce: 0.035727
2022-01-09 12:13:07,323 iteration 1223 : loss : 0.066101, loss_ce: 0.025147
2022-01-09 12:13:09,686 iteration 1224 : loss : 0.121365, loss_ce: 0.053208
 18%|█████▍                        | 72/400 [48:48<3:56:00, 43.17s/it]2022-01-09 12:13:12,117 iteration 1225 : loss : 0.054286, loss_ce: 0.019704
2022-01-09 12:13:14,493 iteration 1226 : loss : 0.070418, loss_ce: 0.020944
2022-01-09 12:13:16,829 iteration 1227 : loss : 0.069486, loss_ce: 0.025605
2022-01-09 12:13:19,220 iteration 1228 : loss : 0.123887, loss_ce: 0.051968
2022-01-09 12:13:21,701 iteration 1229 : loss : 0.056349, loss_ce: 0.026610
2022-01-09 12:13:24,141 iteration 1230 : loss : 0.076751, loss_ce: 0.036215
2022-01-09 12:13:26,578 iteration 1231 : loss : 0.066278, loss_ce: 0.025880
2022-01-09 12:13:28,903 iteration 1232 : loss : 0.089240, loss_ce: 0.037690
2022-01-09 12:13:31,308 iteration 1233 : loss : 0.072885, loss_ce: 0.025130
2022-01-09 12:13:33,723 iteration 1234 : loss : 0.107486, loss_ce: 0.046102
2022-01-09 12:13:36,205 iteration 1235 : loss : 0.130986, loss_ce: 0.048860
2022-01-09 12:13:38,619 iteration 1236 : loss : 0.116833, loss_ce: 0.060360
2022-01-09 12:13:40,969 iteration 1237 : loss : 0.120175, loss_ce: 0.038993
2022-01-09 12:13:43,217 iteration 1238 : loss : 0.100844, loss_ce: 0.041630
2022-01-09 12:13:45,502 iteration 1239 : loss : 0.067309, loss_ce: 0.029966
2022-01-09 12:13:47,930 iteration 1240 : loss : 0.115431, loss_ce: 0.049172
2022-01-09 12:13:50,258 iteration 1241 : loss : 0.106011, loss_ce: 0.048494
 18%|█████▍                        | 73/400 [49:29<3:51:02, 42.39s/it]2022-01-09 12:13:52,767 iteration 1242 : loss : 0.098837, loss_ce: 0.049883
2022-01-09 12:13:55,167 iteration 1243 : loss : 0.070969, loss_ce: 0.026089
2022-01-09 12:13:57,573 iteration 1244 : loss : 0.088626, loss_ce: 0.035822
2022-01-09 12:13:59,913 iteration 1245 : loss : 0.064434, loss_ce: 0.027112
2022-01-09 12:14:02,195 iteration 1246 : loss : 0.070733, loss_ce: 0.029258
2022-01-09 12:14:04,728 iteration 1247 : loss : 0.093699, loss_ce: 0.035659
2022-01-09 12:14:07,088 iteration 1248 : loss : 0.058229, loss_ce: 0.022154
2022-01-09 12:14:09,554 iteration 1249 : loss : 0.079965, loss_ce: 0.039181
2022-01-09 12:14:11,946 iteration 1250 : loss : 0.100224, loss_ce: 0.025268
2022-01-09 12:14:14,360 iteration 1251 : loss : 0.069811, loss_ce: 0.031550
2022-01-09 12:14:16,683 iteration 1252 : loss : 0.093124, loss_ce: 0.031593
2022-01-09 12:14:19,263 iteration 1253 : loss : 0.075015, loss_ce: 0.027619
2022-01-09 12:14:21,649 iteration 1254 : loss : 0.058270, loss_ce: 0.020959
2022-01-09 12:14:24,054 iteration 1255 : loss : 0.067587, loss_ce: 0.029562
2022-01-09 12:14:26,372 iteration 1256 : loss : 0.044191, loss_ce: 0.016725
2022-01-09 12:14:28,630 iteration 1257 : loss : 0.043558, loss_ce: 0.016587
2022-01-09 12:14:30,837 iteration 1258 : loss : 0.054510, loss_ce: 0.025330
 18%|█████▌                        | 74/400 [50:10<3:47:22, 41.85s/it]2022-01-09 12:14:33,093 iteration 1259 : loss : 0.054992, loss_ce: 0.020317
2022-01-09 12:14:35,506 iteration 1260 : loss : 0.065259, loss_ce: 0.028774
2022-01-09 12:14:37,912 iteration 1261 : loss : 0.064626, loss_ce: 0.023442
2022-01-09 12:14:40,244 iteration 1262 : loss : 0.047154, loss_ce: 0.016747
2022-01-09 12:14:42,661 iteration 1263 : loss : 0.047959, loss_ce: 0.018513
2022-01-09 12:14:45,065 iteration 1264 : loss : 0.061501, loss_ce: 0.025221
2022-01-09 12:14:47,492 iteration 1265 : loss : 0.071037, loss_ce: 0.025054
2022-01-09 12:14:49,844 iteration 1266 : loss : 0.050527, loss_ce: 0.022678
2022-01-09 12:14:52,272 iteration 1267 : loss : 0.091553, loss_ce: 0.041986
2022-01-09 12:14:54,733 iteration 1268 : loss : 0.054594, loss_ce: 0.020158
2022-01-09 12:14:57,142 iteration 1269 : loss : 0.059747, loss_ce: 0.029337
2022-01-09 12:14:59,527 iteration 1270 : loss : 0.044981, loss_ce: 0.018484
2022-01-09 12:15:01,900 iteration 1271 : loss : 0.095014, loss_ce: 0.045921
2022-01-09 12:15:04,159 iteration 1272 : loss : 0.048331, loss_ce: 0.015869
2022-01-09 12:15:06,539 iteration 1273 : loss : 0.057486, loss_ce: 0.018436
2022-01-09 12:15:08,954 iteration 1274 : loss : 0.075438, loss_ce: 0.030799
2022-01-09 12:15:08,955 Training Data Eval:
2022-01-09 12:15:21,681   Average segmentation loss on training set: 0.0486
2022-01-09 12:15:21,681 Validation Data Eval:
2022-01-09 12:15:26,218   Average segmentation loss on validation set: 0.1130
2022-01-09 12:15:28,625 iteration 1275 : loss : 0.054746, loss_ce: 0.022226
 19%|█████▋                        | 75/400 [51:07<4:12:35, 46.63s/it]2022-01-09 12:15:31,073 iteration 1276 : loss : 0.054976, loss_ce: 0.023464
2022-01-09 12:15:33,476 iteration 1277 : loss : 0.075023, loss_ce: 0.028616
2022-01-09 12:15:35,742 iteration 1278 : loss : 0.111236, loss_ce: 0.051601
2022-01-09 12:15:38,011 iteration 1279 : loss : 0.065295, loss_ce: 0.024846
2022-01-09 12:15:40,380 iteration 1280 : loss : 0.079542, loss_ce: 0.037200
2022-01-09 12:15:42,690 iteration 1281 : loss : 0.050116, loss_ce: 0.019755
2022-01-09 12:15:45,037 iteration 1282 : loss : 0.049404, loss_ce: 0.022056
2022-01-09 12:15:47,378 iteration 1283 : loss : 0.098407, loss_ce: 0.031547
2022-01-09 12:15:49,949 iteration 1284 : loss : 0.049021, loss_ce: 0.016597
2022-01-09 12:15:52,308 iteration 1285 : loss : 0.037692, loss_ce: 0.013295
2022-01-09 12:15:54,710 iteration 1286 : loss : 0.070053, loss_ce: 0.024519
2022-01-09 12:15:57,019 iteration 1287 : loss : 0.057391, loss_ce: 0.024343
2022-01-09 12:15:59,283 iteration 1288 : loss : 0.058909, loss_ce: 0.021821
2022-01-09 12:16:01,696 iteration 1289 : loss : 0.081055, loss_ce: 0.036737
2022-01-09 12:16:04,078 iteration 1290 : loss : 0.090806, loss_ce: 0.032218
2022-01-09 12:16:06,418 iteration 1291 : loss : 0.066616, loss_ce: 0.022650
2022-01-09 12:16:08,724 iteration 1292 : loss : 0.088456, loss_ce: 0.052059
 19%|█████▋                        | 76/400 [51:47<4:01:13, 44.67s/it]2022-01-09 12:16:11,224 iteration 1293 : loss : 0.065889, loss_ce: 0.031606
2022-01-09 12:16:13,473 iteration 1294 : loss : 0.045243, loss_ce: 0.019487
2022-01-09 12:16:15,843 iteration 1295 : loss : 0.060868, loss_ce: 0.021945
2022-01-09 12:16:18,282 iteration 1296 : loss : 0.085514, loss_ce: 0.024802
2022-01-09 12:16:20,631 iteration 1297 : loss : 0.042751, loss_ce: 0.017695
2022-01-09 12:16:23,074 iteration 1298 : loss : 0.059365, loss_ce: 0.022732
2022-01-09 12:16:25,389 iteration 1299 : loss : 0.056392, loss_ce: 0.022793
2022-01-09 12:16:27,772 iteration 1300 : loss : 0.094500, loss_ce: 0.044295
2022-01-09 12:16:30,156 iteration 1301 : loss : 0.071394, loss_ce: 0.021985
2022-01-09 12:16:32,478 iteration 1302 : loss : 0.071005, loss_ce: 0.026108
2022-01-09 12:16:34,868 iteration 1303 : loss : 0.071721, loss_ce: 0.023052
2022-01-09 12:16:37,189 iteration 1304 : loss : 0.051546, loss_ce: 0.022707
2022-01-09 12:16:39,568 iteration 1305 : loss : 0.071778, loss_ce: 0.025456
2022-01-09 12:16:41,875 iteration 1306 : loss : 0.050633, loss_ce: 0.019772
2022-01-09 12:16:44,361 iteration 1307 : loss : 0.058422, loss_ce: 0.021963
2022-01-09 12:16:46,751 iteration 1308 : loss : 0.067238, loss_ce: 0.031584
2022-01-09 12:16:49,066 iteration 1309 : loss : 0.054260, loss_ce: 0.020661
 19%|█████▊                        | 77/400 [52:28<3:53:29, 43.37s/it]2022-01-09 12:16:51,371 iteration 1310 : loss : 0.052663, loss_ce: 0.018093
2022-01-09 12:16:53,760 iteration 1311 : loss : 0.076701, loss_ce: 0.026381
2022-01-09 12:16:56,177 iteration 1312 : loss : 0.068841, loss_ce: 0.024226
2022-01-09 12:16:58,594 iteration 1313 : loss : 0.054575, loss_ce: 0.022368
2022-01-09 12:17:01,041 iteration 1314 : loss : 0.072480, loss_ce: 0.033198
2022-01-09 12:17:03,389 iteration 1315 : loss : 0.061324, loss_ce: 0.032265
2022-01-09 12:17:05,583 iteration 1316 : loss : 0.054027, loss_ce: 0.023878
2022-01-09 12:17:07,699 iteration 1317 : loss : 0.067698, loss_ce: 0.021820
2022-01-09 12:17:09,804 iteration 1318 : loss : 0.054768, loss_ce: 0.021875
2022-01-09 12:17:12,100 iteration 1319 : loss : 0.058177, loss_ce: 0.021270
2022-01-09 12:17:14,383 iteration 1320 : loss : 0.054285, loss_ce: 0.020033
2022-01-09 12:17:16,685 iteration 1321 : loss : 0.057538, loss_ce: 0.026746
2022-01-09 12:17:18,922 iteration 1322 : loss : 0.054744, loss_ce: 0.020333
2022-01-09 12:17:21,287 iteration 1323 : loss : 0.069183, loss_ce: 0.021414
2022-01-09 12:17:23,710 iteration 1324 : loss : 0.054727, loss_ce: 0.022359
2022-01-09 12:17:25,988 iteration 1325 : loss : 0.048909, loss_ce: 0.019401
2022-01-09 12:17:28,273 iteration 1326 : loss : 0.057566, loss_ce: 0.021554
 20%|█████▊                        | 78/400 [53:07<3:46:03, 42.12s/it]2022-01-09 12:17:30,674 iteration 1327 : loss : 0.040169, loss_ce: 0.014278
2022-01-09 12:17:33,032 iteration 1328 : loss : 0.055553, loss_ce: 0.019058
2022-01-09 12:17:35,339 iteration 1329 : loss : 0.073807, loss_ce: 0.031310
2022-01-09 12:17:37,719 iteration 1330 : loss : 0.054461, loss_ce: 0.018425
2022-01-09 12:17:39,992 iteration 1331 : loss : 0.056936, loss_ce: 0.023716
2022-01-09 12:17:42,277 iteration 1332 : loss : 0.042058, loss_ce: 0.016049
2022-01-09 12:17:44,592 iteration 1333 : loss : 0.049037, loss_ce: 0.020011
2022-01-09 12:17:46,916 iteration 1334 : loss : 0.044104, loss_ce: 0.019664
2022-01-09 12:17:49,344 iteration 1335 : loss : 0.041743, loss_ce: 0.016888
2022-01-09 12:17:51,771 iteration 1336 : loss : 0.043606, loss_ce: 0.019858
2022-01-09 12:17:54,202 iteration 1337 : loss : 0.076705, loss_ce: 0.030843
2022-01-09 12:17:56,526 iteration 1338 : loss : 0.033800, loss_ce: 0.016205
2022-01-09 12:17:58,828 iteration 1339 : loss : 0.073651, loss_ce: 0.027781
2022-01-09 12:18:01,132 iteration 1340 : loss : 0.044013, loss_ce: 0.018707
2022-01-09 12:18:03,485 iteration 1341 : loss : 0.068561, loss_ce: 0.028811
2022-01-09 12:18:05,910 iteration 1342 : loss : 0.056533, loss_ce: 0.018293
2022-01-09 12:18:08,138 iteration 1343 : loss : 0.052072, loss_ce: 0.019120
 20%|█████▉                        | 79/400 [53:47<3:41:43, 41.44s/it]2022-01-09 12:18:10,543 iteration 1344 : loss : 0.048883, loss_ce: 0.016232
2022-01-09 12:18:12,853 iteration 1345 : loss : 0.046332, loss_ce: 0.012100
2022-01-09 12:18:15,200 iteration 1346 : loss : 0.043531, loss_ce: 0.014511
2022-01-09 12:18:17,599 iteration 1347 : loss : 0.069546, loss_ce: 0.026926
2022-01-09 12:18:19,870 iteration 1348 : loss : 0.066857, loss_ce: 0.029333
2022-01-09 12:18:22,181 iteration 1349 : loss : 0.077036, loss_ce: 0.030130
2022-01-09 12:18:24,515 iteration 1350 : loss : 0.080243, loss_ce: 0.025346
2022-01-09 12:18:26,870 iteration 1351 : loss : 0.092235, loss_ce: 0.041110
2022-01-09 12:18:29,127 iteration 1352 : loss : 0.056238, loss_ce: 0.025903
2022-01-09 12:18:31,482 iteration 1353 : loss : 0.059049, loss_ce: 0.037666
2022-01-09 12:18:33,849 iteration 1354 : loss : 0.080540, loss_ce: 0.041986
2022-01-09 12:18:36,158 iteration 1355 : loss : 0.052506, loss_ce: 0.016711
2022-01-09 12:18:38,525 iteration 1356 : loss : 0.056074, loss_ce: 0.019515
2022-01-09 12:18:40,775 iteration 1357 : loss : 0.048593, loss_ce: 0.025053
2022-01-09 12:18:43,170 iteration 1358 : loss : 0.070859, loss_ce: 0.036273
2022-01-09 12:18:45,586 iteration 1359 : loss : 0.083945, loss_ce: 0.048475
2022-01-09 12:18:45,586 Training Data Eval:
2022-01-09 12:18:58,143   Average segmentation loss on training set: 0.0407
2022-01-09 12:18:58,143 Validation Data Eval:
2022-01-09 12:19:02,536   Average segmentation loss on validation set: 0.0922
2022-01-09 12:19:04,969 iteration 1360 : loss : 0.059075, loss_ce: 0.025510
 20%|██████                        | 80/400 [54:44<4:05:39, 46.06s/it]2022-01-09 12:19:07,435 iteration 1361 : loss : 0.068153, loss_ce: 0.022509
2022-01-09 12:19:09,719 iteration 1362 : loss : 0.082166, loss_ce: 0.022917
2022-01-09 12:19:11,994 iteration 1363 : loss : 0.055516, loss_ce: 0.024031
2022-01-09 12:19:14,172 iteration 1364 : loss : 0.076194, loss_ce: 0.034387
2022-01-09 12:19:16,486 iteration 1365 : loss : 0.055786, loss_ce: 0.015829
2022-01-09 12:19:18,914 iteration 1366 : loss : 0.087446, loss_ce: 0.031205
2022-01-09 12:19:21,236 iteration 1367 : loss : 0.064886, loss_ce: 0.039802
2022-01-09 12:19:23,686 iteration 1368 : loss : 0.061131, loss_ce: 0.024679
2022-01-09 12:19:26,113 iteration 1369 : loss : 0.044233, loss_ce: 0.017268
2022-01-09 12:19:28,460 iteration 1370 : loss : 0.067487, loss_ce: 0.029975
2022-01-09 12:19:30,840 iteration 1371 : loss : 0.063095, loss_ce: 0.024788
2022-01-09 12:19:33,366 iteration 1372 : loss : 0.072670, loss_ce: 0.026231
2022-01-09 12:19:35,726 iteration 1373 : loss : 0.062311, loss_ce: 0.027472
2022-01-09 12:19:38,043 iteration 1374 : loss : 0.061484, loss_ce: 0.020770
2022-01-09 12:19:40,316 iteration 1375 : loss : 0.056009, loss_ce: 0.023887
2022-01-09 12:19:42,586 iteration 1376 : loss : 0.040245, loss_ce: 0.012582
2022-01-09 12:19:45,035 iteration 1377 : loss : 0.054651, loss_ce: 0.033565
 20%|██████                        | 81/400 [55:24<3:55:20, 44.26s/it]2022-01-09 12:19:47,488 iteration 1378 : loss : 0.065297, loss_ce: 0.034553
2022-01-09 12:19:49,806 iteration 1379 : loss : 0.065911, loss_ce: 0.025393
2022-01-09 12:19:52,072 iteration 1380 : loss : 0.086549, loss_ce: 0.029682
2022-01-09 12:19:54,404 iteration 1381 : loss : 0.045770, loss_ce: 0.016530
2022-01-09 12:19:56,686 iteration 1382 : loss : 0.067476, loss_ce: 0.026179
2022-01-09 12:19:58,888 iteration 1383 : loss : 0.062222, loss_ce: 0.019566
2022-01-09 12:20:01,192 iteration 1384 : loss : 0.048352, loss_ce: 0.020757
2022-01-09 12:20:03,605 iteration 1385 : loss : 0.054761, loss_ce: 0.025440
2022-01-09 12:20:05,987 iteration 1386 : loss : 0.059448, loss_ce: 0.022262
2022-01-09 12:20:08,492 iteration 1387 : loss : 0.077497, loss_ce: 0.029292
2022-01-09 12:20:10,832 iteration 1388 : loss : 0.050261, loss_ce: 0.018164
2022-01-09 12:20:13,110 iteration 1389 : loss : 0.049140, loss_ce: 0.021407
2022-01-09 12:20:15,492 iteration 1390 : loss : 0.056973, loss_ce: 0.023414
2022-01-09 12:20:17,819 iteration 1391 : loss : 0.055539, loss_ce: 0.018983
2022-01-09 12:20:20,101 iteration 1392 : loss : 0.059480, loss_ce: 0.018447
2022-01-09 12:20:22,370 iteration 1393 : loss : 0.046860, loss_ce: 0.016264
2022-01-09 12:20:24,679 iteration 1394 : loss : 0.044315, loss_ce: 0.022196
 20%|██████▏                       | 82/400 [56:03<3:47:15, 42.88s/it]2022-01-09 12:20:27,044 iteration 1395 : loss : 0.046406, loss_ce: 0.017572
2022-01-09 12:20:29,264 iteration 1396 : loss : 0.045321, loss_ce: 0.017584
2022-01-09 12:20:31,586 iteration 1397 : loss : 0.052602, loss_ce: 0.018555
2022-01-09 12:20:33,932 iteration 1398 : loss : 0.046240, loss_ce: 0.019984
2022-01-09 12:20:36,269 iteration 1399 : loss : 0.072292, loss_ce: 0.033863
2022-01-09 12:20:38,608 iteration 1400 : loss : 0.075980, loss_ce: 0.049128
2022-01-09 12:20:41,009 iteration 1401 : loss : 0.058496, loss_ce: 0.021678
2022-01-09 12:20:43,326 iteration 1402 : loss : 0.045247, loss_ce: 0.018607
2022-01-09 12:20:45,737 iteration 1403 : loss : 0.049290, loss_ce: 0.019198
2022-01-09 12:20:48,052 iteration 1404 : loss : 0.056593, loss_ce: 0.020235
2022-01-09 12:20:50,371 iteration 1405 : loss : 0.052752, loss_ce: 0.025028
2022-01-09 12:20:52,750 iteration 1406 : loss : 0.055803, loss_ce: 0.018117
2022-01-09 12:20:55,091 iteration 1407 : loss : 0.043195, loss_ce: 0.022039
2022-01-09 12:20:57,446 iteration 1408 : loss : 0.052744, loss_ce: 0.017395
2022-01-09 12:20:59,846 iteration 1409 : loss : 0.105041, loss_ce: 0.029651
2022-01-09 12:21:02,225 iteration 1410 : loss : 0.071988, loss_ce: 0.023858
2022-01-09 12:21:04,544 iteration 1411 : loss : 0.041261, loss_ce: 0.017653
 21%|██████▏                       | 83/400 [56:43<3:41:44, 41.97s/it]2022-01-09 12:21:06,862 iteration 1412 : loss : 0.063587, loss_ce: 0.018946
2022-01-09 12:21:09,275 iteration 1413 : loss : 0.063816, loss_ce: 0.023218
2022-01-09 12:21:11,661 iteration 1414 : loss : 0.045474, loss_ce: 0.021745
2022-01-09 12:21:13,951 iteration 1415 : loss : 0.045740, loss_ce: 0.015745
2022-01-09 12:21:16,217 iteration 1416 : loss : 0.051084, loss_ce: 0.014954
2022-01-09 12:21:18,490 iteration 1417 : loss : 0.060423, loss_ce: 0.024224
2022-01-09 12:21:20,702 iteration 1418 : loss : 0.038472, loss_ce: 0.013201
2022-01-09 12:21:23,086 iteration 1419 : loss : 0.059668, loss_ce: 0.019879
2022-01-09 12:21:25,370 iteration 1420 : loss : 0.059323, loss_ce: 0.018876
2022-01-09 12:21:27,619 iteration 1421 : loss : 0.054203, loss_ce: 0.022663
2022-01-09 12:21:29,956 iteration 1422 : loss : 0.043477, loss_ce: 0.015481
2022-01-09 12:21:32,291 iteration 1423 : loss : 0.071279, loss_ce: 0.027240
2022-01-09 12:21:34,689 iteration 1424 : loss : 0.065878, loss_ce: 0.022578
2022-01-09 12:21:37,098 iteration 1425 : loss : 0.054822, loss_ce: 0.023058
2022-01-09 12:21:39,364 iteration 1426 : loss : 0.044293, loss_ce: 0.017924
2022-01-09 12:21:41,686 iteration 1427 : loss : 0.057168, loss_ce: 0.023783
2022-01-09 12:21:43,995 iteration 1428 : loss : 0.053442, loss_ce: 0.021917
 21%|██████▎                       | 84/400 [57:23<3:37:04, 41.22s/it]2022-01-09 12:21:46,443 iteration 1429 : loss : 0.070417, loss_ce: 0.027260
2022-01-09 12:21:48,761 iteration 1430 : loss : 0.078826, loss_ce: 0.023901
2022-01-09 12:21:51,100 iteration 1431 : loss : 0.045608, loss_ce: 0.023700
2022-01-09 12:21:53,419 iteration 1432 : loss : 0.054045, loss_ce: 0.025004
2022-01-09 12:21:55,820 iteration 1433 : loss : 0.054372, loss_ce: 0.021117
2022-01-09 12:21:58,115 iteration 1434 : loss : 0.062235, loss_ce: 0.027003
2022-01-09 12:22:00,312 iteration 1435 : loss : 0.051074, loss_ce: 0.015735
2022-01-09 12:22:02,636 iteration 1436 : loss : 0.043439, loss_ce: 0.020022
2022-01-09 12:22:04,781 iteration 1437 : loss : 0.106768, loss_ce: 0.025479
2022-01-09 12:22:06,925 iteration 1438 : loss : 0.044407, loss_ce: 0.020341
2022-01-09 12:22:09,174 iteration 1439 : loss : 0.037630, loss_ce: 0.011637
2022-01-09 12:22:11,487 iteration 1440 : loss : 0.058698, loss_ce: 0.028577
2022-01-09 12:22:13,780 iteration 1441 : loss : 0.036429, loss_ce: 0.015240
2022-01-09 12:22:16,114 iteration 1442 : loss : 0.056190, loss_ce: 0.025293
2022-01-09 12:22:18,493 iteration 1443 : loss : 0.061604, loss_ce: 0.023345
2022-01-09 12:22:20,869 iteration 1444 : loss : 0.037895, loss_ce: 0.017790
2022-01-09 12:22:20,869 Training Data Eval:
2022-01-09 12:22:33,222   Average segmentation loss on training set: 0.0747
2022-01-09 12:22:33,223 Validation Data Eval:
2022-01-09 12:22:37,756   Average segmentation loss on validation set: 0.0798
2022-01-09 12:22:40,214 iteration 1445 : loss : 0.053248, loss_ce: 0.018751
 21%|██████▍                       | 85/400 [58:19<4:00:00, 45.72s/it]2022-01-09 12:22:42,674 iteration 1446 : loss : 0.061155, loss_ce: 0.023144
2022-01-09 12:22:44,998 iteration 1447 : loss : 0.087914, loss_ce: 0.031153
2022-01-09 12:22:47,301 iteration 1448 : loss : 0.065816, loss_ce: 0.032923
2022-01-09 12:22:49,603 iteration 1449 : loss : 0.049314, loss_ce: 0.019040
2022-01-09 12:22:51,838 iteration 1450 : loss : 0.066457, loss_ce: 0.026811
2022-01-09 12:22:54,095 iteration 1451 : loss : 0.046912, loss_ce: 0.014783
2022-01-09 12:22:56,436 iteration 1452 : loss : 0.098288, loss_ce: 0.024239
2022-01-09 12:22:58,795 iteration 1453 : loss : 0.059930, loss_ce: 0.018646
2022-01-09 12:23:01,015 iteration 1454 : loss : 0.046205, loss_ce: 0.020783
2022-01-09 12:23:03,275 iteration 1455 : loss : 0.050159, loss_ce: 0.023403
2022-01-09 12:23:05,627 iteration 1456 : loss : 0.058976, loss_ce: 0.020727
2022-01-09 12:23:07,940 iteration 1457 : loss : 0.054335, loss_ce: 0.026908
2022-01-09 12:23:10,232 iteration 1458 : loss : 0.049404, loss_ce: 0.018770
2022-01-09 12:23:12,435 iteration 1459 : loss : 0.042232, loss_ce: 0.018294
2022-01-09 12:23:14,729 iteration 1460 : loss : 0.078655, loss_ce: 0.042836
2022-01-09 12:23:17,004 iteration 1461 : loss : 0.043533, loss_ce: 0.015217
2022-01-09 12:23:19,266 iteration 1462 : loss : 0.055242, loss_ce: 0.023213
 22%|██████▍                       | 86/400 [58:58<3:48:46, 43.72s/it]2022-01-09 12:23:21,586 iteration 1463 : loss : 0.052915, loss_ce: 0.022842
2022-01-09 12:23:24,026 iteration 1464 : loss : 0.050241, loss_ce: 0.015937
2022-01-09 12:23:26,479 iteration 1465 : loss : 0.101904, loss_ce: 0.051931
2022-01-09 12:23:28,834 iteration 1466 : loss : 0.047087, loss_ce: 0.016276
2022-01-09 12:23:31,116 iteration 1467 : loss : 0.065346, loss_ce: 0.023248
2022-01-09 12:23:33,355 iteration 1468 : loss : 0.064394, loss_ce: 0.024033
2022-01-09 12:23:35,555 iteration 1469 : loss : 0.046348, loss_ce: 0.021557
2022-01-09 12:23:37,839 iteration 1470 : loss : 0.043509, loss_ce: 0.015915
2022-01-09 12:23:40,086 iteration 1471 : loss : 0.051114, loss_ce: 0.017966
2022-01-09 12:23:42,420 iteration 1472 : loss : 0.051629, loss_ce: 0.017699
2022-01-09 12:23:44,732 iteration 1473 : loss : 0.049420, loss_ce: 0.024565
2022-01-09 12:23:46,934 iteration 1474 : loss : 0.060976, loss_ce: 0.023939
2022-01-09 12:23:49,273 iteration 1475 : loss : 0.052658, loss_ce: 0.017089
2022-01-09 12:23:51,586 iteration 1476 : loss : 0.074937, loss_ce: 0.041073
2022-01-09 12:23:53,842 iteration 1477 : loss : 0.064789, loss_ce: 0.020366
2022-01-09 12:23:56,128 iteration 1478 : loss : 0.061106, loss_ce: 0.020901
2022-01-09 12:23:58,512 iteration 1479 : loss : 0.064407, loss_ce: 0.024050
 22%|██████▌                       | 87/400 [59:37<3:41:03, 42.38s/it]2022-01-09 12:24:00,914 iteration 1480 : loss : 0.056591, loss_ce: 0.029057
2022-01-09 12:24:03,269 iteration 1481 : loss : 0.051972, loss_ce: 0.023628
2022-01-09 12:24:05,542 iteration 1482 : loss : 0.046788, loss_ce: 0.019261
2022-01-09 12:24:07,768 iteration 1483 : loss : 0.041228, loss_ce: 0.016523
2022-01-09 12:24:10,102 iteration 1484 : loss : 0.049183, loss_ce: 0.020576
2022-01-09 12:24:12,420 iteration 1485 : loss : 0.054380, loss_ce: 0.018674
2022-01-09 12:24:14,960 iteration 1486 : loss : 0.057251, loss_ce: 0.019768
2022-01-09 12:24:17,416 iteration 1487 : loss : 0.077704, loss_ce: 0.034167
2022-01-09 12:24:19,692 iteration 1488 : loss : 0.042309, loss_ce: 0.017361
2022-01-09 12:24:21,939 iteration 1489 : loss : 0.047248, loss_ce: 0.019406
2022-01-09 12:24:24,086 iteration 1490 : loss : 0.047520, loss_ce: 0.021042
2022-01-09 12:24:26,297 iteration 1491 : loss : 0.047244, loss_ce: 0.016567
2022-01-09 12:24:28,712 iteration 1492 : loss : 0.051555, loss_ce: 0.020867
2022-01-09 12:24:31,133 iteration 1493 : loss : 0.060323, loss_ce: 0.025495
2022-01-09 12:24:33,515 iteration 1494 : loss : 0.063979, loss_ce: 0.020303
2022-01-09 12:24:35,866 iteration 1495 : loss : 0.071083, loss_ce: 0.025188
2022-01-09 12:24:38,180 iteration 1496 : loss : 0.066061, loss_ce: 0.026376
 22%|██████▏                     | 88/400 [1:00:17<3:36:08, 41.56s/it]2022-01-09 12:24:40,590 iteration 1497 : loss : 0.039123, loss_ce: 0.016650
2022-01-09 12:24:42,843 iteration 1498 : loss : 0.035317, loss_ce: 0.014420
2022-01-09 12:24:45,167 iteration 1499 : loss : 0.063651, loss_ce: 0.026559
2022-01-09 12:24:47,597 iteration 1500 : loss : 0.087672, loss_ce: 0.031951
2022-01-09 12:24:49,818 iteration 1501 : loss : 0.042810, loss_ce: 0.012513
2022-01-09 12:24:52,125 iteration 1502 : loss : 0.064491, loss_ce: 0.025637
2022-01-09 12:24:54,441 iteration 1503 : loss : 0.056991, loss_ce: 0.024408
2022-01-09 12:24:56,734 iteration 1504 : loss : 0.067693, loss_ce: 0.027717
2022-01-09 12:24:59,070 iteration 1505 : loss : 0.056466, loss_ce: 0.021731
2022-01-09 12:25:01,553 iteration 1506 : loss : 0.047095, loss_ce: 0.018321
2022-01-09 12:25:03,951 iteration 1507 : loss : 0.043371, loss_ce: 0.020430
2022-01-09 12:25:06,340 iteration 1508 : loss : 0.109111, loss_ce: 0.023459
2022-01-09 12:25:08,686 iteration 1509 : loss : 0.042325, loss_ce: 0.018393
2022-01-09 12:25:11,041 iteration 1510 : loss : 0.058668, loss_ce: 0.021508
2022-01-09 12:25:13,521 iteration 1511 : loss : 0.075560, loss_ce: 0.039688
2022-01-09 12:25:15,859 iteration 1512 : loss : 0.061053, loss_ce: 0.019053
2022-01-09 12:25:18,290 iteration 1513 : loss : 0.049516, loss_ce: 0.017630
 22%|██████▏                     | 89/400 [1:00:57<3:33:10, 41.13s/it]2022-01-09 12:25:20,673 iteration 1514 : loss : 0.060363, loss_ce: 0.023554
2022-01-09 12:25:22,920 iteration 1515 : loss : 0.052309, loss_ce: 0.025200
2022-01-09 12:25:25,247 iteration 1516 : loss : 0.056718, loss_ce: 0.028144
2022-01-09 12:25:27,646 iteration 1517 : loss : 0.044623, loss_ce: 0.019702
2022-01-09 12:25:29,958 iteration 1518 : loss : 0.045551, loss_ce: 0.019426
2022-01-09 12:25:32,313 iteration 1519 : loss : 0.039754, loss_ce: 0.015817
2022-01-09 12:25:34,858 iteration 1520 : loss : 0.054668, loss_ce: 0.025926
2022-01-09 12:25:37,138 iteration 1521 : loss : 0.047515, loss_ce: 0.016962
2022-01-09 12:25:39,622 iteration 1522 : loss : 0.048243, loss_ce: 0.015653
2022-01-09 12:25:42,018 iteration 1523 : loss : 0.053527, loss_ce: 0.021020
2022-01-09 12:25:44,324 iteration 1524 : loss : 0.040377, loss_ce: 0.013941
2022-01-09 12:25:46,686 iteration 1525 : loss : 0.046466, loss_ce: 0.021326
2022-01-09 12:25:49,018 iteration 1526 : loss : 0.074071, loss_ce: 0.025240
2022-01-09 12:25:51,448 iteration 1527 : loss : 0.044201, loss_ce: 0.017582
2022-01-09 12:25:53,846 iteration 1528 : loss : 0.050496, loss_ce: 0.018452
2022-01-09 12:25:56,197 iteration 1529 : loss : 0.070842, loss_ce: 0.022324
2022-01-09 12:25:56,197 Training Data Eval:
2022-01-09 12:26:08,992   Average segmentation loss on training set: 0.0584
2022-01-09 12:26:08,993 Validation Data Eval:
2022-01-09 12:26:13,436   Average segmentation loss on validation set: 0.1694
2022-01-09 12:26:15,791 iteration 1530 : loss : 0.048421, loss_ce: 0.021757
 22%|██████▎                     | 90/400 [1:01:55<3:57:53, 46.04s/it]2022-01-09 12:26:18,264 iteration 1531 : loss : 0.071772, loss_ce: 0.031572
2022-01-09 12:26:20,599 iteration 1532 : loss : 0.088451, loss_ce: 0.035930
2022-01-09 12:26:22,887 iteration 1533 : loss : 0.056795, loss_ce: 0.021499
2022-01-09 12:26:25,462 iteration 1534 : loss : 0.039753, loss_ce: 0.019115
2022-01-09 12:26:27,840 iteration 1535 : loss : 0.059397, loss_ce: 0.024594
2022-01-09 12:26:30,203 iteration 1536 : loss : 0.053978, loss_ce: 0.015878
2022-01-09 12:26:32,445 iteration 1537 : loss : 0.061234, loss_ce: 0.032584
2022-01-09 12:26:34,738 iteration 1538 : loss : 0.104078, loss_ce: 0.029295
2022-01-09 12:26:37,062 iteration 1539 : loss : 0.049102, loss_ce: 0.022199
2022-01-09 12:26:39,381 iteration 1540 : loss : 0.066454, loss_ce: 0.031177
2022-01-09 12:26:41,742 iteration 1541 : loss : 0.051626, loss_ce: 0.022226
2022-01-09 12:26:44,148 iteration 1542 : loss : 0.077496, loss_ce: 0.034161
2022-01-09 12:26:46,504 iteration 1543 : loss : 0.083848, loss_ce: 0.021649
2022-01-09 12:26:48,824 iteration 1544 : loss : 0.053863, loss_ce: 0.022883
2022-01-09 12:26:51,145 iteration 1545 : loss : 0.067596, loss_ce: 0.027349
2022-01-09 12:26:53,485 iteration 1546 : loss : 0.064830, loss_ce: 0.021572
2022-01-09 12:26:55,854 iteration 1547 : loss : 0.050571, loss_ce: 0.021272
 23%|██████▎                     | 91/400 [1:02:35<3:47:52, 44.25s/it]2022-01-09 12:26:58,283 iteration 1548 : loss : 0.062515, loss_ce: 0.019917
2022-01-09 12:27:00,637 iteration 1549 : loss : 0.053121, loss_ce: 0.016597
2022-01-09 12:27:03,012 iteration 1550 : loss : 0.046470, loss_ce: 0.013378
2022-01-09 12:27:05,345 iteration 1551 : loss : 0.071877, loss_ce: 0.028041
2022-01-09 12:27:07,666 iteration 1552 : loss : 0.056115, loss_ce: 0.017192
2022-01-09 12:27:10,280 iteration 1553 : loss : 0.061656, loss_ce: 0.025469
2022-01-09 12:27:12,606 iteration 1554 : loss : 0.085592, loss_ce: 0.051282
2022-01-09 12:27:14,954 iteration 1555 : loss : 0.053126, loss_ce: 0.017351
2022-01-09 12:27:17,428 iteration 1556 : loss : 0.086840, loss_ce: 0.038815
2022-01-09 12:27:19,715 iteration 1557 : loss : 0.052530, loss_ce: 0.016563
2022-01-09 12:27:21,922 iteration 1558 : loss : 0.049571, loss_ce: 0.019496
2022-01-09 12:27:24,260 iteration 1559 : loss : 0.063555, loss_ce: 0.023222
2022-01-09 12:27:26,519 iteration 1560 : loss : 0.051262, loss_ce: 0.030383
2022-01-09 12:27:28,806 iteration 1561 : loss : 0.044007, loss_ce: 0.018313
2022-01-09 12:27:31,145 iteration 1562 : loss : 0.066566, loss_ce: 0.034921
2022-01-09 12:27:33,513 iteration 1563 : loss : 0.077440, loss_ce: 0.029366
2022-01-09 12:27:35,861 iteration 1564 : loss : 0.062889, loss_ce: 0.022869
 23%|██████▍                     | 92/400 [1:03:15<3:40:36, 42.98s/it]2022-01-09 12:27:38,225 iteration 1565 : loss : 0.049524, loss_ce: 0.023874
2022-01-09 12:27:40,602 iteration 1566 : loss : 0.053591, loss_ce: 0.017889
2022-01-09 12:27:42,993 iteration 1567 : loss : 0.058972, loss_ce: 0.025499
2022-01-09 12:27:45,444 iteration 1568 : loss : 0.054781, loss_ce: 0.018098
2022-01-09 12:27:47,874 iteration 1569 : loss : 0.054308, loss_ce: 0.025299
2022-01-09 12:27:50,270 iteration 1570 : loss : 0.045299, loss_ce: 0.016559
2022-01-09 12:27:52,623 iteration 1571 : loss : 0.048930, loss_ce: 0.018061
2022-01-09 12:27:54,962 iteration 1572 : loss : 0.083355, loss_ce: 0.027113
2022-01-09 12:27:57,129 iteration 1573 : loss : 0.044084, loss_ce: 0.021012
2022-01-09 12:27:59,389 iteration 1574 : loss : 0.046069, loss_ce: 0.019592
2022-01-09 12:28:01,725 iteration 1575 : loss : 0.068165, loss_ce: 0.028065
2022-01-09 12:28:04,138 iteration 1576 : loss : 0.040073, loss_ce: 0.015398
2022-01-09 12:28:06,618 iteration 1577 : loss : 0.044610, loss_ce: 0.016927
2022-01-09 12:28:09,052 iteration 1578 : loss : 0.039484, loss_ce: 0.014255
2022-01-09 12:28:11,486 iteration 1579 : loss : 0.070719, loss_ce: 0.026855
2022-01-09 12:28:13,821 iteration 1580 : loss : 0.082384, loss_ce: 0.026872
2022-01-09 12:28:16,240 iteration 1581 : loss : 0.050106, loss_ce: 0.020550
 23%|██████▌                     | 93/400 [1:03:55<3:35:54, 42.20s/it]2022-01-09 12:28:18,593 iteration 1582 : loss : 0.049455, loss_ce: 0.017817
2022-01-09 12:28:20,960 iteration 1583 : loss : 0.059775, loss_ce: 0.022400
2022-01-09 12:28:23,234 iteration 1584 : loss : 0.057366, loss_ce: 0.020143
2022-01-09 12:28:25,541 iteration 1585 : loss : 0.091737, loss_ce: 0.021255
2022-01-09 12:28:27,917 iteration 1586 : loss : 0.076052, loss_ce: 0.021721
2022-01-09 12:28:30,287 iteration 1587 : loss : 0.065945, loss_ce: 0.019228
2022-01-09 12:28:32,699 iteration 1588 : loss : 0.060338, loss_ce: 0.029152
2022-01-09 12:28:35,054 iteration 1589 : loss : 0.063244, loss_ce: 0.017452
2022-01-09 12:28:37,458 iteration 1590 : loss : 0.067670, loss_ce: 0.030994
2022-01-09 12:28:39,839 iteration 1591 : loss : 0.095777, loss_ce: 0.051195
2022-01-09 12:28:42,189 iteration 1592 : loss : 0.076980, loss_ce: 0.030510
2022-01-09 12:28:44,660 iteration 1593 : loss : 0.090900, loss_ce: 0.028079
2022-01-09 12:28:47,071 iteration 1594 : loss : 0.046241, loss_ce: 0.023347
2022-01-09 12:28:49,558 iteration 1595 : loss : 0.056555, loss_ce: 0.022638
2022-01-09 12:28:51,945 iteration 1596 : loss : 0.047472, loss_ce: 0.018813
2022-01-09 12:28:54,251 iteration 1597 : loss : 0.065620, loss_ce: 0.020302
2022-01-09 12:28:56,583 iteration 1598 : loss : 0.045984, loss_ce: 0.019583
 24%|██████▌                     | 94/400 [1:04:35<3:32:21, 41.64s/it]2022-01-09 12:28:59,016 iteration 1599 : loss : 0.039834, loss_ce: 0.016271
2022-01-09 12:29:01,299 iteration 1600 : loss : 0.065397, loss_ce: 0.026003
2022-01-09 12:29:03,631 iteration 1601 : loss : 0.071333, loss_ce: 0.026216
2022-01-09 12:29:05,956 iteration 1602 : loss : 0.070664, loss_ce: 0.038177
2022-01-09 12:29:08,443 iteration 1603 : loss : 0.080764, loss_ce: 0.031082
2022-01-09 12:29:10,811 iteration 1604 : loss : 0.090138, loss_ce: 0.044463
2022-01-09 12:29:13,240 iteration 1605 : loss : 0.054915, loss_ce: 0.020210
2022-01-09 12:29:15,723 iteration 1606 : loss : 0.064473, loss_ce: 0.019416
2022-01-09 12:29:18,113 iteration 1607 : loss : 0.065066, loss_ce: 0.030079
2022-01-09 12:29:20,488 iteration 1608 : loss : 0.044574, loss_ce: 0.015755
2022-01-09 12:29:22,874 iteration 1609 : loss : 0.039429, loss_ce: 0.014855
2022-01-09 12:29:25,184 iteration 1610 : loss : 0.054653, loss_ce: 0.023799
2022-01-09 12:29:27,725 iteration 1611 : loss : 0.051934, loss_ce: 0.018843
2022-01-09 12:29:30,147 iteration 1612 : loss : 0.042232, loss_ce: 0.020479
2022-01-09 12:29:32,517 iteration 1613 : loss : 0.056555, loss_ce: 0.024643
2022-01-09 12:29:34,854 iteration 1614 : loss : 0.048054, loss_ce: 0.015170
2022-01-09 12:29:34,855 Training Data Eval:
2022-01-09 12:29:47,169   Average segmentation loss on training set: 0.0617
2022-01-09 12:29:47,169 Validation Data Eval:
2022-01-09 12:29:51,680   Average segmentation loss on validation set: 0.0840
2022-01-09 12:29:54,142 iteration 1615 : loss : 0.056688, loss_ce: 0.024688
 24%|██████▋                     | 95/400 [1:05:33<3:55:57, 46.42s/it]2022-01-09 12:29:56,525 iteration 1616 : loss : 0.050607, loss_ce: 0.016643
2022-01-09 12:29:58,767 iteration 1617 : loss : 0.033996, loss_ce: 0.014961
2022-01-09 12:30:01,119 iteration 1618 : loss : 0.028052, loss_ce: 0.011017
2022-01-09 12:30:03,548 iteration 1619 : loss : 0.033316, loss_ce: 0.016172
2022-01-09 12:30:05,833 iteration 1620 : loss : 0.043501, loss_ce: 0.018390
2022-01-09 12:30:08,170 iteration 1621 : loss : 0.045339, loss_ce: 0.016974
2022-01-09 12:30:10,494 iteration 1622 : loss : 0.051780, loss_ce: 0.019252
2022-01-09 12:30:12,724 iteration 1623 : loss : 0.036868, loss_ce: 0.017196
2022-01-09 12:30:15,058 iteration 1624 : loss : 0.053568, loss_ce: 0.021840
2022-01-09 12:30:17,436 iteration 1625 : loss : 0.041612, loss_ce: 0.021847
2022-01-09 12:30:19,921 iteration 1626 : loss : 0.045057, loss_ce: 0.018699
2022-01-09 12:30:22,253 iteration 1627 : loss : 0.046685, loss_ce: 0.017067
2022-01-09 12:30:24,695 iteration 1628 : loss : 0.050389, loss_ce: 0.016342
2022-01-09 12:30:27,092 iteration 1629 : loss : 0.055938, loss_ce: 0.025430
2022-01-09 12:30:29,361 iteration 1630 : loss : 0.051173, loss_ce: 0.018339
2022-01-09 12:30:31,630 iteration 1631 : loss : 0.041152, loss_ce: 0.017465
2022-01-09 12:30:33,859 iteration 1632 : loss : 0.040006, loss_ce: 0.015776
 24%|██████▋                     | 96/400 [1:06:13<3:44:58, 44.40s/it]2022-01-09 12:30:36,232 iteration 1633 : loss : 0.058695, loss_ce: 0.017832
2022-01-09 12:30:38,530 iteration 1634 : loss : 0.035631, loss_ce: 0.015033
2022-01-09 12:30:40,810 iteration 1635 : loss : 0.040886, loss_ce: 0.017372
2022-01-09 12:30:42,963 iteration 1636 : loss : 0.037258, loss_ce: 0.013482
2022-01-09 12:30:45,268 iteration 1637 : loss : 0.046913, loss_ce: 0.016642
2022-01-09 12:30:47,636 iteration 1638 : loss : 0.063587, loss_ce: 0.021500
2022-01-09 12:30:50,091 iteration 1639 : loss : 0.065923, loss_ce: 0.029003
2022-01-09 12:30:52,509 iteration 1640 : loss : 0.050482, loss_ce: 0.021819
2022-01-09 12:30:54,890 iteration 1641 : loss : 0.050787, loss_ce: 0.019846
2022-01-09 12:30:57,341 iteration 1642 : loss : 0.075134, loss_ce: 0.026636
2022-01-09 12:30:59,648 iteration 1643 : loss : 0.036469, loss_ce: 0.015412
2022-01-09 12:31:01,929 iteration 1644 : loss : 0.055957, loss_ce: 0.024227
2022-01-09 12:31:04,133 iteration 1645 : loss : 0.042918, loss_ce: 0.014051
2022-01-09 12:31:06,484 iteration 1646 : loss : 0.044792, loss_ce: 0.019152
2022-01-09 12:31:08,948 iteration 1647 : loss : 0.056066, loss_ce: 0.032625
2022-01-09 12:31:11,359 iteration 1648 : loss : 0.046552, loss_ce: 0.020558
2022-01-09 12:31:13,803 iteration 1649 : loss : 0.104775, loss_ce: 0.026963
 24%|██████▊                     | 97/400 [1:06:52<3:37:28, 43.06s/it]2022-01-09 12:31:16,122 iteration 1650 : loss : 0.038208, loss_ce: 0.012529
2022-01-09 12:31:18,460 iteration 1651 : loss : 0.075767, loss_ce: 0.034677
2022-01-09 12:31:20,791 iteration 1652 : loss : 0.095006, loss_ce: 0.030080
2022-01-09 12:31:23,152 iteration 1653 : loss : 0.060608, loss_ce: 0.028813
2022-01-09 12:31:25,483 iteration 1654 : loss : 0.044655, loss_ce: 0.015227
2022-01-09 12:31:27,748 iteration 1655 : loss : 0.060796, loss_ce: 0.018344
2022-01-09 12:31:30,108 iteration 1656 : loss : 0.032464, loss_ce: 0.014397
2022-01-09 12:31:32,567 iteration 1657 : loss : 0.046347, loss_ce: 0.019745
2022-01-09 12:31:34,876 iteration 1658 : loss : 0.039139, loss_ce: 0.015012
2022-01-09 12:31:37,221 iteration 1659 : loss : 0.050346, loss_ce: 0.020835
2022-01-09 12:31:39,639 iteration 1660 : loss : 0.051717, loss_ce: 0.022950
2022-01-09 12:31:41,953 iteration 1661 : loss : 0.061758, loss_ce: 0.021534
2022-01-09 12:31:44,306 iteration 1662 : loss : 0.045218, loss_ce: 0.016493
2022-01-09 12:31:46,750 iteration 1663 : loss : 0.057030, loss_ce: 0.020385
2022-01-09 12:31:49,111 iteration 1664 : loss : 0.048802, loss_ce: 0.017145
2022-01-09 12:31:51,352 iteration 1665 : loss : 0.024663, loss_ce: 0.011225
2022-01-09 12:31:53,616 iteration 1666 : loss : 0.033524, loss_ce: 0.012676
 24%|██████▊                     | 98/400 [1:07:32<3:31:50, 42.09s/it]2022-01-09 12:31:55,934 iteration 1667 : loss : 0.045009, loss_ce: 0.025132
2022-01-09 12:31:58,344 iteration 1668 : loss : 0.063073, loss_ce: 0.026533
2022-01-09 12:32:00,755 iteration 1669 : loss : 0.041168, loss_ce: 0.016385
2022-01-09 12:32:03,135 iteration 1670 : loss : 0.044652, loss_ce: 0.018403
2022-01-09 12:32:05,470 iteration 1671 : loss : 0.047170, loss_ce: 0.018356
2022-01-09 12:32:07,703 iteration 1672 : loss : 0.049260, loss_ce: 0.017863
2022-01-09 12:32:09,901 iteration 1673 : loss : 0.033341, loss_ce: 0.013691
2022-01-09 12:32:12,191 iteration 1674 : loss : 0.050147, loss_ce: 0.022171
2022-01-09 12:32:14,383 iteration 1675 : loss : 0.044574, loss_ce: 0.016983
2022-01-09 12:32:16,583 iteration 1676 : loss : 0.045204, loss_ce: 0.020424
2022-01-09 12:32:18,876 iteration 1677 : loss : 0.041449, loss_ce: 0.016661
2022-01-09 12:32:21,222 iteration 1678 : loss : 0.077619, loss_ce: 0.023273
2022-01-09 12:32:23,687 iteration 1679 : loss : 0.034231, loss_ce: 0.008416
2022-01-09 12:32:26,127 iteration 1680 : loss : 0.062227, loss_ce: 0.031675
2022-01-09 12:32:28,475 iteration 1681 : loss : 0.085174, loss_ce: 0.026424
2022-01-09 12:32:30,769 iteration 1682 : loss : 0.052359, loss_ce: 0.025353
2022-01-09 12:32:33,195 iteration 1683 : loss : 0.073941, loss_ce: 0.034986
 25%|██████▉                     | 99/400 [1:08:12<3:27:21, 41.34s/it]2022-01-09 12:32:35,621 iteration 1684 : loss : 0.041242, loss_ce: 0.015987
2022-01-09 12:32:37,949 iteration 1685 : loss : 0.064296, loss_ce: 0.025427
2022-01-09 12:32:40,408 iteration 1686 : loss : 0.045275, loss_ce: 0.015798
2022-01-09 12:32:42,757 iteration 1687 : loss : 0.040992, loss_ce: 0.013206
2022-01-09 12:32:45,201 iteration 1688 : loss : 0.046772, loss_ce: 0.017371
2022-01-09 12:32:47,619 iteration 1689 : loss : 0.073936, loss_ce: 0.031847
2022-01-09 12:32:49,944 iteration 1690 : loss : 0.057674, loss_ce: 0.018592
2022-01-09 12:32:52,230 iteration 1691 : loss : 0.061051, loss_ce: 0.022440
2022-01-09 12:32:54,550 iteration 1692 : loss : 0.042049, loss_ce: 0.019586
2022-01-09 12:32:56,941 iteration 1693 : loss : 0.052277, loss_ce: 0.022252
2022-01-09 12:32:59,334 iteration 1694 : loss : 0.044307, loss_ce: 0.015685
2022-01-09 12:33:01,667 iteration 1695 : loss : 0.059572, loss_ce: 0.017921
2022-01-09 12:33:04,059 iteration 1696 : loss : 0.061908, loss_ce: 0.030606
2022-01-09 12:33:06,437 iteration 1697 : loss : 0.041992, loss_ce: 0.019470
2022-01-09 12:33:08,815 iteration 1698 : loss : 0.032188, loss_ce: 0.012438
2022-01-09 12:33:11,182 iteration 1699 : loss : 0.039346, loss_ce: 0.018173
2022-01-09 12:33:11,183 Training Data Eval:
2022-01-09 12:33:23,869   Average segmentation loss on training set: 0.0339
2022-01-09 12:33:23,870 Validation Data Eval:
2022-01-09 12:33:28,259   Average segmentation loss on validation set: 0.0750
2022-01-09 12:33:35,098 Found new lowest validation loss at iteration 1699! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 12:33:36,704 iteration 1700 : loss : 0.034201, loss_ce: 0.012497
 25%|██████▊                    | 100/400 [1:09:15<3:59:56, 47.99s/it]2022-01-09 12:33:38,313 iteration 1701 : loss : 0.031897, loss_ce: 0.013536
2022-01-09 12:33:39,943 iteration 1702 : loss : 0.058302, loss_ce: 0.022034
2022-01-09 12:33:41,764 iteration 1703 : loss : 0.063412, loss_ce: 0.029499
2022-01-09 12:33:43,610 iteration 1704 : loss : 0.033765, loss_ce: 0.016323
2022-01-09 12:33:45,611 iteration 1705 : loss : 0.054556, loss_ce: 0.022264
2022-01-09 12:33:47,712 iteration 1706 : loss : 0.065897, loss_ce: 0.027059
2022-01-09 12:33:49,850 iteration 1707 : loss : 0.047476, loss_ce: 0.020492
2022-01-09 12:33:52,009 iteration 1708 : loss : 0.077384, loss_ce: 0.025295
2022-01-09 12:33:54,184 iteration 1709 : loss : 0.049532, loss_ce: 0.021273
2022-01-09 12:33:56,458 iteration 1710 : loss : 0.048142, loss_ce: 0.016954
2022-01-09 12:33:58,740 iteration 1711 : loss : 0.043421, loss_ce: 0.015420
2022-01-09 12:34:00,947 iteration 1712 : loss : 0.034232, loss_ce: 0.015751
2022-01-09 12:34:03,324 iteration 1713 : loss : 0.054500, loss_ce: 0.017113
2022-01-09 12:34:05,661 iteration 1714 : loss : 0.057133, loss_ce: 0.016208
2022-01-09 12:34:07,989 iteration 1715 : loss : 0.042587, loss_ce: 0.019520
2022-01-09 12:34:10,138 iteration 1716 : loss : 0.049388, loss_ce: 0.015897
2022-01-09 12:34:12,362 iteration 1717 : loss : 0.062388, loss_ce: 0.017791
 25%|██████▊                    | 101/400 [1:09:51<3:40:41, 44.29s/it]2022-01-09 12:34:14,651 iteration 1718 : loss : 0.055070, loss_ce: 0.026117
2022-01-09 12:34:16,865 iteration 1719 : loss : 0.056575, loss_ce: 0.012865
2022-01-09 12:34:19,190 iteration 1720 : loss : 0.055036, loss_ce: 0.019228
2022-01-09 12:34:21,578 iteration 1721 : loss : 0.035569, loss_ce: 0.012128
2022-01-09 12:34:23,957 iteration 1722 : loss : 0.043031, loss_ce: 0.013064
2022-01-09 12:34:26,210 iteration 1723 : loss : 0.064313, loss_ce: 0.022819
2022-01-09 12:34:28,494 iteration 1724 : loss : 0.039950, loss_ce: 0.015640
2022-01-09 12:34:30,805 iteration 1725 : loss : 0.053534, loss_ce: 0.016867
2022-01-09 12:34:33,158 iteration 1726 : loss : 0.035153, loss_ce: 0.015602
2022-01-09 12:34:35,551 iteration 1727 : loss : 0.062052, loss_ce: 0.028009
2022-01-09 12:34:37,818 iteration 1728 : loss : 0.039326, loss_ce: 0.013114
2022-01-09 12:34:40,225 iteration 1729 : loss : 0.048679, loss_ce: 0.019574
2022-01-09 12:34:42,582 iteration 1730 : loss : 0.036814, loss_ce: 0.018276
2022-01-09 12:34:44,850 iteration 1731 : loss : 0.063117, loss_ce: 0.032929
2022-01-09 12:34:47,126 iteration 1732 : loss : 0.049442, loss_ce: 0.020204
2022-01-09 12:34:49,347 iteration 1733 : loss : 0.042473, loss_ce: 0.017385
2022-01-09 12:34:51,630 iteration 1734 : loss : 0.040189, loss_ce: 0.016829
 26%|██████▉                    | 102/400 [1:10:30<3:32:28, 42.78s/it]2022-01-09 12:34:54,124 iteration 1735 : loss : 0.052883, loss_ce: 0.020958
2022-01-09 12:34:56,405 iteration 1736 : loss : 0.046684, loss_ce: 0.018501
2022-01-09 12:34:58,745 iteration 1737 : loss : 0.053564, loss_ce: 0.020991
2022-01-09 12:35:00,989 iteration 1738 : loss : 0.039503, loss_ce: 0.018267
2022-01-09 12:35:03,235 iteration 1739 : loss : 0.033100, loss_ce: 0.012722
2022-01-09 12:35:05,560 iteration 1740 : loss : 0.036463, loss_ce: 0.015143
2022-01-09 12:35:07,871 iteration 1741 : loss : 0.030404, loss_ce: 0.010109
2022-01-09 12:35:10,270 iteration 1742 : loss : 0.043287, loss_ce: 0.016345
2022-01-09 12:35:12,588 iteration 1743 : loss : 0.051595, loss_ce: 0.017349
2022-01-09 12:35:14,983 iteration 1744 : loss : 0.091216, loss_ce: 0.039656
2022-01-09 12:35:17,371 iteration 1745 : loss : 0.067545, loss_ce: 0.026727
2022-01-09 12:35:19,732 iteration 1746 : loss : 0.064156, loss_ce: 0.032355
2022-01-09 12:35:22,035 iteration 1747 : loss : 0.046460, loss_ce: 0.020534
2022-01-09 12:35:24,357 iteration 1748 : loss : 0.037141, loss_ce: 0.013882
2022-01-09 12:35:26,535 iteration 1749 : loss : 0.033282, loss_ce: 0.010729
2022-01-09 12:35:28,830 iteration 1750 : loss : 0.116741, loss_ce: 0.027184
2022-01-09 12:35:31,281 iteration 1751 : loss : 0.046466, loss_ce: 0.016412
 26%|██████▉                    | 103/400 [1:11:10<3:27:07, 41.84s/it]2022-01-09 12:35:33,650 iteration 1752 : loss : 0.087570, loss_ce: 0.023009
2022-01-09 12:35:35,778 iteration 1753 : loss : 0.050019, loss_ce: 0.017530
2022-01-09 12:35:38,022 iteration 1754 : loss : 0.048080, loss_ce: 0.016183
2022-01-09 12:35:40,218 iteration 1755 : loss : 0.032354, loss_ce: 0.013590
2022-01-09 12:35:42,452 iteration 1756 : loss : 0.049946, loss_ce: 0.019890
2022-01-09 12:35:44,742 iteration 1757 : loss : 0.032984, loss_ce: 0.013455
2022-01-09 12:35:47,070 iteration 1758 : loss : 0.044532, loss_ce: 0.021664
2022-01-09 12:35:49,334 iteration 1759 : loss : 0.038368, loss_ce: 0.011690
2022-01-09 12:35:51,640 iteration 1760 : loss : 0.045818, loss_ce: 0.014698
2022-01-09 12:35:53,960 iteration 1761 : loss : 0.081876, loss_ce: 0.022090
2022-01-09 12:35:56,175 iteration 1762 : loss : 0.039190, loss_ce: 0.015316
2022-01-09 12:35:58,430 iteration 1763 : loss : 0.044301, loss_ce: 0.016847
2022-01-09 12:36:00,714 iteration 1764 : loss : 0.032579, loss_ce: 0.009798
2022-01-09 12:36:03,036 iteration 1765 : loss : 0.040872, loss_ce: 0.021562
2022-01-09 12:36:05,409 iteration 1766 : loss : 0.058291, loss_ce: 0.030040
2022-01-09 12:36:07,696 iteration 1767 : loss : 0.034407, loss_ce: 0.014831
2022-01-09 12:36:10,012 iteration 1768 : loss : 0.049857, loss_ce: 0.018515
 26%|███████                    | 104/400 [1:11:49<3:21:49, 40.91s/it]2022-01-09 12:36:12,331 iteration 1769 : loss : 0.045319, loss_ce: 0.018327
2022-01-09 12:36:14,601 iteration 1770 : loss : 0.042725, loss_ce: 0.018654
2022-01-09 12:36:16,773 iteration 1771 : loss : 0.058784, loss_ce: 0.022882
2022-01-09 12:36:19,034 iteration 1772 : loss : 0.041094, loss_ce: 0.021522
2022-01-09 12:36:21,422 iteration 1773 : loss : 0.060845, loss_ce: 0.018090
2022-01-09 12:36:23,743 iteration 1774 : loss : 0.032825, loss_ce: 0.011024
2022-01-09 12:36:26,175 iteration 1775 : loss : 0.051155, loss_ce: 0.020433
2022-01-09 12:36:28,562 iteration 1776 : loss : 0.031664, loss_ce: 0.015936
2022-01-09 12:36:30,859 iteration 1777 : loss : 0.038621, loss_ce: 0.016821
2022-01-09 12:36:33,098 iteration 1778 : loss : 0.042208, loss_ce: 0.015854
2022-01-09 12:36:35,446 iteration 1779 : loss : 0.040959, loss_ce: 0.012499
2022-01-09 12:36:37,733 iteration 1780 : loss : 0.053098, loss_ce: 0.025268
2022-01-09 12:36:40,058 iteration 1781 : loss : 0.036032, loss_ce: 0.013984
2022-01-09 12:36:42,388 iteration 1782 : loss : 0.053102, loss_ce: 0.020442
2022-01-09 12:36:44,705 iteration 1783 : loss : 0.040894, loss_ce: 0.015290
2022-01-09 12:36:46,964 iteration 1784 : loss : 0.046608, loss_ce: 0.017880
2022-01-09 12:36:46,965 Training Data Eval:
2022-01-09 12:36:59,672   Average segmentation loss on training set: 0.0323
2022-01-09 12:36:59,673 Validation Data Eval:
2022-01-09 12:37:04,210   Average segmentation loss on validation set: 0.0607
2022-01-09 12:37:10,110 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 12:37:11,749 iteration 1785 : loss : 0.061135, loss_ce: 0.024710
 26%|███████                    | 105/400 [1:12:50<3:51:51, 47.16s/it]2022-01-09 12:37:13,384 iteration 1786 : loss : 0.041534, loss_ce: 0.021095
2022-01-09 12:37:14,942 iteration 1787 : loss : 0.044815, loss_ce: 0.017037
2022-01-09 12:37:16,720 iteration 1788 : loss : 0.055528, loss_ce: 0.032404
2022-01-09 12:37:18,591 iteration 1789 : loss : 0.053647, loss_ce: 0.019029
2022-01-09 12:37:20,530 iteration 1790 : loss : 0.033111, loss_ce: 0.014605
2022-01-09 12:37:22,519 iteration 1791 : loss : 0.058053, loss_ce: 0.022894
2022-01-09 12:37:24,527 iteration 1792 : loss : 0.047466, loss_ce: 0.017147
2022-01-09 12:37:26,682 iteration 1793 : loss : 0.069659, loss_ce: 0.024525
2022-01-09 12:37:28,806 iteration 1794 : loss : 0.034619, loss_ce: 0.013882
2022-01-09 12:37:30,917 iteration 1795 : loss : 0.038993, loss_ce: 0.014282
2022-01-09 12:37:33,061 iteration 1796 : loss : 0.052810, loss_ce: 0.025594
2022-01-09 12:37:35,341 iteration 1797 : loss : 0.052437, loss_ce: 0.015673
2022-01-09 12:37:37,614 iteration 1798 : loss : 0.038809, loss_ce: 0.013963
2022-01-09 12:37:39,811 iteration 1799 : loss : 0.052528, loss_ce: 0.021029
2022-01-09 12:37:42,084 iteration 1800 : loss : 0.037622, loss_ce: 0.012683
2022-01-09 12:37:44,304 iteration 1801 : loss : 0.032842, loss_ce: 0.011404
2022-01-09 12:37:46,671 iteration 1802 : loss : 0.046950, loss_ce: 0.018400
 26%|███████▏                   | 106/400 [1:13:25<3:33:04, 43.49s/it]2022-01-09 12:37:49,165 iteration 1803 : loss : 0.046610, loss_ce: 0.016705
2022-01-09 12:37:51,566 iteration 1804 : loss : 0.046275, loss_ce: 0.012942
2022-01-09 12:37:53,900 iteration 1805 : loss : 0.035083, loss_ce: 0.010441
2022-01-09 12:37:56,258 iteration 1806 : loss : 0.041527, loss_ce: 0.019484
2022-01-09 12:37:58,648 iteration 1807 : loss : 0.054325, loss_ce: 0.019834
2022-01-09 12:38:01,018 iteration 1808 : loss : 0.030830, loss_ce: 0.013485
2022-01-09 12:38:03,341 iteration 1809 : loss : 0.033090, loss_ce: 0.013053
2022-01-09 12:38:05,633 iteration 1810 : loss : 0.029842, loss_ce: 0.011284
2022-01-09 12:38:08,060 iteration 1811 : loss : 0.038696, loss_ce: 0.017371
2022-01-09 12:38:10,462 iteration 1812 : loss : 0.050001, loss_ce: 0.018348
2022-01-09 12:38:12,904 iteration 1813 : loss : 0.040916, loss_ce: 0.013587
2022-01-09 12:38:15,408 iteration 1814 : loss : 0.040719, loss_ce: 0.018433
2022-01-09 12:38:17,781 iteration 1815 : loss : 0.043164, loss_ce: 0.014655
2022-01-09 12:38:20,135 iteration 1816 : loss : 0.038919, loss_ce: 0.016008
2022-01-09 12:38:22,582 iteration 1817 : loss : 0.055379, loss_ce: 0.023864
2022-01-09 12:38:24,993 iteration 1818 : loss : 0.073702, loss_ce: 0.035905
2022-01-09 12:38:27,415 iteration 1819 : loss : 0.055859, loss_ce: 0.023759
 27%|███████▏                   | 107/400 [1:14:06<3:28:20, 42.67s/it]2022-01-09 12:38:29,836 iteration 1820 : loss : 0.051935, loss_ce: 0.027774
2022-01-09 12:38:32,163 iteration 1821 : loss : 0.031327, loss_ce: 0.014295
2022-01-09 12:38:34,554 iteration 1822 : loss : 0.031167, loss_ce: 0.011010
2022-01-09 12:38:36,896 iteration 1823 : loss : 0.034794, loss_ce: 0.011412
2022-01-09 12:38:39,165 iteration 1824 : loss : 0.031655, loss_ce: 0.013072
2022-01-09 12:38:41,553 iteration 1825 : loss : 0.080333, loss_ce: 0.031999
2022-01-09 12:38:43,881 iteration 1826 : loss : 0.038966, loss_ce: 0.018684
2022-01-09 12:38:46,320 iteration 1827 : loss : 0.151623, loss_ce: 0.042795
2022-01-09 12:38:48,689 iteration 1828 : loss : 0.040144, loss_ce: 0.015662
2022-01-09 12:38:51,110 iteration 1829 : loss : 0.048549, loss_ce: 0.016589
2022-01-09 12:38:53,469 iteration 1830 : loss : 0.043364, loss_ce: 0.019093
2022-01-09 12:38:55,876 iteration 1831 : loss : 0.069860, loss_ce: 0.039551
2022-01-09 12:38:58,419 iteration 1832 : loss : 0.042104, loss_ce: 0.013003
2022-01-09 12:39:00,801 iteration 1833 : loss : 0.039629, loss_ce: 0.017855
2022-01-09 12:39:03,206 iteration 1834 : loss : 0.045408, loss_ce: 0.016530
2022-01-09 12:39:05,481 iteration 1835 : loss : 0.055571, loss_ce: 0.028518
2022-01-09 12:39:07,739 iteration 1836 : loss : 0.053215, loss_ce: 0.019738
 27%|███████▎                   | 108/400 [1:14:46<3:24:13, 41.96s/it]2022-01-09 12:39:10,133 iteration 1837 : loss : 0.031099, loss_ce: 0.012158
2022-01-09 12:39:12,428 iteration 1838 : loss : 0.056516, loss_ce: 0.025969
2022-01-09 12:39:14,767 iteration 1839 : loss : 0.054966, loss_ce: 0.020362
2022-01-09 12:39:16,990 iteration 1840 : loss : 0.065521, loss_ce: 0.036397
2022-01-09 12:39:19,279 iteration 1841 : loss : 0.047079, loss_ce: 0.023157
2022-01-09 12:39:21,560 iteration 1842 : loss : 0.061752, loss_ce: 0.018651
2022-01-09 12:39:23,813 iteration 1843 : loss : 0.037513, loss_ce: 0.016433
2022-01-09 12:39:26,199 iteration 1844 : loss : 0.040731, loss_ce: 0.015393
2022-01-09 12:39:28,477 iteration 1845 : loss : 0.035585, loss_ce: 0.014762
2022-01-09 12:39:30,823 iteration 1846 : loss : 0.043373, loss_ce: 0.016854
2022-01-09 12:39:33,089 iteration 1847 : loss : 0.074246, loss_ce: 0.028795
2022-01-09 12:39:35,450 iteration 1848 : loss : 0.049315, loss_ce: 0.021930
2022-01-09 12:39:37,783 iteration 1849 : loss : 0.034203, loss_ce: 0.015993
2022-01-09 12:39:40,196 iteration 1850 : loss : 0.065245, loss_ce: 0.019923
2022-01-09 12:39:42,610 iteration 1851 : loss : 0.066311, loss_ce: 0.029494
2022-01-09 12:39:44,983 iteration 1852 : loss : 0.050792, loss_ce: 0.020927
2022-01-09 12:39:47,333 iteration 1853 : loss : 0.052594, loss_ce: 0.010892
 27%|███████▎                   | 109/400 [1:15:26<3:20:04, 41.25s/it]2022-01-09 12:39:49,672 iteration 1854 : loss : 0.046159, loss_ce: 0.017710
2022-01-09 12:39:52,077 iteration 1855 : loss : 0.054246, loss_ce: 0.022652
2022-01-09 12:39:54,497 iteration 1856 : loss : 0.035835, loss_ce: 0.010539
2022-01-09 12:39:56,877 iteration 1857 : loss : 0.064640, loss_ce: 0.023905
2022-01-09 12:39:59,202 iteration 1858 : loss : 0.050299, loss_ce: 0.024687
2022-01-09 12:40:01,500 iteration 1859 : loss : 0.040787, loss_ce: 0.017982
2022-01-09 12:40:03,954 iteration 1860 : loss : 0.069082, loss_ce: 0.031803
2022-01-09 12:40:06,360 iteration 1861 : loss : 0.060483, loss_ce: 0.024613
2022-01-09 12:40:08,948 iteration 1862 : loss : 0.038766, loss_ce: 0.018241
2022-01-09 12:40:11,377 iteration 1863 : loss : 0.050051, loss_ce: 0.018788
2022-01-09 12:40:13,685 iteration 1864 : loss : 0.056198, loss_ce: 0.023784
2022-01-09 12:40:15,976 iteration 1865 : loss : 0.057527, loss_ce: 0.030405
2022-01-09 12:40:18,271 iteration 1866 : loss : 0.049278, loss_ce: 0.025211
2022-01-09 12:40:20,599 iteration 1867 : loss : 0.107570, loss_ce: 0.042081
2022-01-09 12:40:22,942 iteration 1868 : loss : 0.042361, loss_ce: 0.019693
2022-01-09 12:40:25,330 iteration 1869 : loss : 0.053667, loss_ce: 0.017715
2022-01-09 12:40:25,331 Training Data Eval:
2022-01-09 12:40:38,108   Average segmentation loss on training set: 0.0307
2022-01-09 12:40:38,108 Validation Data Eval:
2022-01-09 12:40:42,534   Average segmentation loss on validation set: 0.0904
2022-01-09 12:40:44,891 iteration 1870 : loss : 0.049838, loss_ce: 0.015756
 28%|███████▍                   | 110/400 [1:16:24<3:43:01, 46.14s/it]2022-01-09 12:40:47,342 iteration 1871 : loss : 0.039521, loss_ce: 0.018149
2022-01-09 12:40:49,688 iteration 1872 : loss : 0.035826, loss_ce: 0.013258
2022-01-09 12:40:52,244 iteration 1873 : loss : 0.064923, loss_ce: 0.027481
2022-01-09 12:40:54,677 iteration 1874 : loss : 0.063214, loss_ce: 0.028016
2022-01-09 12:40:57,045 iteration 1875 : loss : 0.041572, loss_ce: 0.021489
2022-01-09 12:40:59,383 iteration 1876 : loss : 0.053301, loss_ce: 0.016222
2022-01-09 12:41:01,770 iteration 1877 : loss : 0.049570, loss_ce: 0.015865
2022-01-09 12:41:04,028 iteration 1878 : loss : 0.047267, loss_ce: 0.015368
2022-01-09 12:41:06,268 iteration 1879 : loss : 0.039684, loss_ce: 0.018315
2022-01-09 12:41:08,537 iteration 1880 : loss : 0.041060, loss_ce: 0.014518
2022-01-09 12:41:10,900 iteration 1881 : loss : 0.027818, loss_ce: 0.009131
2022-01-09 12:41:13,319 iteration 1882 : loss : 0.047040, loss_ce: 0.013922
2022-01-09 12:41:15,651 iteration 1883 : loss : 0.031971, loss_ce: 0.012518
2022-01-09 12:41:18,097 iteration 1884 : loss : 0.032996, loss_ce: 0.012551
2022-01-09 12:41:20,404 iteration 1885 : loss : 0.029583, loss_ce: 0.010852
2022-01-09 12:41:22,778 iteration 1886 : loss : 0.046576, loss_ce: 0.022684
2022-01-09 12:41:25,037 iteration 1887 : loss : 0.046137, loss_ce: 0.017533
 28%|███████▍                   | 111/400 [1:17:04<3:33:35, 44.34s/it]2022-01-09 12:41:27,383 iteration 1888 : loss : 0.058233, loss_ce: 0.020671
2022-01-09 12:41:29,762 iteration 1889 : loss : 0.041223, loss_ce: 0.017067
2022-01-09 12:41:31,955 iteration 1890 : loss : 0.029266, loss_ce: 0.010829
2022-01-09 12:41:34,309 iteration 1891 : loss : 0.042560, loss_ce: 0.021815
2022-01-09 12:41:36,648 iteration 1892 : loss : 0.052366, loss_ce: 0.017907
2022-01-09 12:41:39,007 iteration 1893 : loss : 0.074716, loss_ce: 0.027657
2022-01-09 12:41:41,378 iteration 1894 : loss : 0.048186, loss_ce: 0.020517
2022-01-09 12:41:43,803 iteration 1895 : loss : 0.050128, loss_ce: 0.016628
2022-01-09 12:41:46,231 iteration 1896 : loss : 0.038085, loss_ce: 0.017839
2022-01-09 12:41:48,670 iteration 1897 : loss : 0.068034, loss_ce: 0.026135
2022-01-09 12:41:51,140 iteration 1898 : loss : 0.044908, loss_ce: 0.016764
2022-01-09 12:41:53,533 iteration 1899 : loss : 0.034461, loss_ce: 0.013390
2022-01-09 12:41:55,992 iteration 1900 : loss : 0.049323, loss_ce: 0.022193
2022-01-09 12:41:58,385 iteration 1901 : loss : 0.049813, loss_ce: 0.018261
2022-01-09 12:42:00,747 iteration 1902 : loss : 0.052468, loss_ce: 0.018953
2022-01-09 12:42:03,164 iteration 1903 : loss : 0.042923, loss_ce: 0.019403
2022-01-09 12:42:05,527 iteration 1904 : loss : 0.062848, loss_ce: 0.020122
 28%|███████▌                   | 112/400 [1:17:44<3:27:18, 43.19s/it]2022-01-09 12:42:07,927 iteration 1905 : loss : 0.058056, loss_ce: 0.024991
2022-01-09 12:42:10,323 iteration 1906 : loss : 0.042895, loss_ce: 0.013301
2022-01-09 12:42:12,664 iteration 1907 : loss : 0.037930, loss_ce: 0.015852
2022-01-09 12:42:15,138 iteration 1908 : loss : 0.042648, loss_ce: 0.014847
2022-01-09 12:42:17,448 iteration 1909 : loss : 0.052963, loss_ce: 0.018986
2022-01-09 12:42:19,804 iteration 1910 : loss : 0.077788, loss_ce: 0.015722
2022-01-09 12:42:22,173 iteration 1911 : loss : 0.036981, loss_ce: 0.013241
2022-01-09 12:42:24,505 iteration 1912 : loss : 0.038148, loss_ce: 0.013361
2022-01-09 12:42:26,959 iteration 1913 : loss : 0.044583, loss_ce: 0.019857
2022-01-09 12:42:29,351 iteration 1914 : loss : 0.035236, loss_ce: 0.016331
2022-01-09 12:42:31,801 iteration 1915 : loss : 0.058230, loss_ce: 0.028638
2022-01-09 12:42:34,194 iteration 1916 : loss : 0.048702, loss_ce: 0.019455
2022-01-09 12:42:36,552 iteration 1917 : loss : 0.040507, loss_ce: 0.018134
2022-01-09 12:42:38,948 iteration 1918 : loss : 0.038463, loss_ce: 0.012266
2022-01-09 12:42:41,309 iteration 1919 : loss : 0.052685, loss_ce: 0.018444
2022-01-09 12:42:43,721 iteration 1920 : loss : 0.052197, loss_ce: 0.020956
2022-01-09 12:42:46,187 iteration 1921 : loss : 0.052326, loss_ce: 0.025701
 28%|███████▋                   | 113/400 [1:18:25<3:22:57, 42.43s/it]2022-01-09 12:42:48,604 iteration 1922 : loss : 0.047188, loss_ce: 0.021515
2022-01-09 12:42:50,968 iteration 1923 : loss : 0.037106, loss_ce: 0.018534
2022-01-09 12:42:53,601 iteration 1924 : loss : 0.037303, loss_ce: 0.017017
2022-01-09 12:42:56,041 iteration 1925 : loss : 0.050018, loss_ce: 0.020330
2022-01-09 12:42:58,412 iteration 1926 : loss : 0.027792, loss_ce: 0.011762
2022-01-09 12:43:00,864 iteration 1927 : loss : 0.040382, loss_ce: 0.017031
2022-01-09 12:43:03,334 iteration 1928 : loss : 0.054800, loss_ce: 0.026855
2022-01-09 12:43:05,654 iteration 1929 : loss : 0.045417, loss_ce: 0.016933
2022-01-09 12:43:07,986 iteration 1930 : loss : 0.043191, loss_ce: 0.018115
2022-01-09 12:43:10,363 iteration 1931 : loss : 0.085038, loss_ce: 0.021028
2022-01-09 12:43:12,676 iteration 1932 : loss : 0.043224, loss_ce: 0.015139
2022-01-09 12:43:15,015 iteration 1933 : loss : 0.054476, loss_ce: 0.026871
2022-01-09 12:43:17,229 iteration 1934 : loss : 0.030020, loss_ce: 0.012156
2022-01-09 12:43:19,534 iteration 1935 : loss : 0.057383, loss_ce: 0.018282
2022-01-09 12:43:21,961 iteration 1936 : loss : 0.039798, loss_ce: 0.017972
2022-01-09 12:43:24,195 iteration 1937 : loss : 0.048623, loss_ce: 0.013616
2022-01-09 12:43:26,429 iteration 1938 : loss : 0.046645, loss_ce: 0.017590
 28%|███████▋                   | 114/400 [1:19:05<3:19:06, 41.77s/it]2022-01-09 12:43:28,789 iteration 1939 : loss : 0.035939, loss_ce: 0.014620
2022-01-09 12:43:31,240 iteration 1940 : loss : 0.054835, loss_ce: 0.027395
2022-01-09 12:43:33,652 iteration 1941 : loss : 0.043502, loss_ce: 0.018177
2022-01-09 12:43:36,042 iteration 1942 : loss : 0.048115, loss_ce: 0.017507
2022-01-09 12:43:38,394 iteration 1943 : loss : 0.046969, loss_ce: 0.020542
2022-01-09 12:43:40,792 iteration 1944 : loss : 0.037691, loss_ce: 0.014767
2022-01-09 12:43:43,100 iteration 1945 : loss : 0.046657, loss_ce: 0.017313
2022-01-09 12:43:45,424 iteration 1946 : loss : 0.035375, loss_ce: 0.012483
2022-01-09 12:43:47,842 iteration 1947 : loss : 0.053407, loss_ce: 0.024963
2022-01-09 12:43:50,168 iteration 1948 : loss : 0.059945, loss_ce: 0.017526
2022-01-09 12:43:52,565 iteration 1949 : loss : 0.041478, loss_ce: 0.015582
2022-01-09 12:43:55,094 iteration 1950 : loss : 0.030628, loss_ce: 0.012959
2022-01-09 12:43:57,533 iteration 1951 : loss : 0.066802, loss_ce: 0.022713
2022-01-09 12:43:59,931 iteration 1952 : loss : 0.045787, loss_ce: 0.013836
2022-01-09 12:44:02,360 iteration 1953 : loss : 0.057099, loss_ce: 0.026887
2022-01-09 12:44:04,643 iteration 1954 : loss : 0.031683, loss_ce: 0.015518
2022-01-09 12:44:04,643 Training Data Eval:
2022-01-09 12:44:17,440   Average segmentation loss on training set: 0.0266
2022-01-09 12:44:17,441 Validation Data Eval:
2022-01-09 12:44:21,960   Average segmentation loss on validation set: 0.0857
2022-01-09 12:44:24,365 iteration 1955 : loss : 0.044671, loss_ce: 0.014184
 29%|███████▊                   | 115/400 [1:20:03<3:41:27, 46.62s/it]2022-01-09 12:44:26,738 iteration 1956 : loss : 0.049331, loss_ce: 0.012659
2022-01-09 12:44:29,174 iteration 1957 : loss : 0.048093, loss_ce: 0.019981
2022-01-09 12:44:31,628 iteration 1958 : loss : 0.033257, loss_ce: 0.013331
2022-01-09 12:44:34,037 iteration 1959 : loss : 0.038907, loss_ce: 0.013374
2022-01-09 12:44:36,399 iteration 1960 : loss : 0.041006, loss_ce: 0.017672
2022-01-09 12:44:38,770 iteration 1961 : loss : 0.040533, loss_ce: 0.015469
2022-01-09 12:44:41,092 iteration 1962 : loss : 0.054996, loss_ce: 0.030866
2022-01-09 12:44:43,412 iteration 1963 : loss : 0.040245, loss_ce: 0.015144
2022-01-09 12:44:45,797 iteration 1964 : loss : 0.032713, loss_ce: 0.013657
2022-01-09 12:44:48,150 iteration 1965 : loss : 0.038218, loss_ce: 0.016813
2022-01-09 12:44:50,604 iteration 1966 : loss : 0.064672, loss_ce: 0.031289
2022-01-09 12:44:52,993 iteration 1967 : loss : 0.046331, loss_ce: 0.016693
2022-01-09 12:44:55,406 iteration 1968 : loss : 0.045840, loss_ce: 0.023135
2022-01-09 12:44:57,759 iteration 1969 : loss : 0.050724, loss_ce: 0.020413
2022-01-09 12:45:00,219 iteration 1970 : loss : 0.050298, loss_ce: 0.015481
2022-01-09 12:45:02,670 iteration 1971 : loss : 0.045281, loss_ce: 0.020554
2022-01-09 12:45:05,074 iteration 1972 : loss : 0.067522, loss_ce: 0.022366
 29%|███████▊                   | 116/400 [1:20:44<3:32:16, 44.85s/it]2022-01-09 12:45:07,570 iteration 1973 : loss : 0.032020, loss_ce: 0.012955
2022-01-09 12:45:09,972 iteration 1974 : loss : 0.041793, loss_ce: 0.016481
2022-01-09 12:45:12,268 iteration 1975 : loss : 0.036442, loss_ce: 0.011991
2022-01-09 12:45:14,573 iteration 1976 : loss : 0.052508, loss_ce: 0.021791
2022-01-09 12:45:16,934 iteration 1977 : loss : 0.048305, loss_ce: 0.014619
2022-01-09 12:45:19,187 iteration 1978 : loss : 0.031302, loss_ce: 0.012885
2022-01-09 12:45:21,558 iteration 1979 : loss : 0.043770, loss_ce: 0.020751
2022-01-09 12:45:23,992 iteration 1980 : loss : 0.042626, loss_ce: 0.017503
2022-01-09 12:45:26,342 iteration 1981 : loss : 0.044616, loss_ce: 0.018098
2022-01-09 12:45:28,734 iteration 1982 : loss : 0.047900, loss_ce: 0.019001
2022-01-09 12:45:31,177 iteration 1983 : loss : 0.050123, loss_ce: 0.028095
2022-01-09 12:45:33,466 iteration 1984 : loss : 0.039471, loss_ce: 0.010560
2022-01-09 12:45:36,074 iteration 1985 : loss : 0.025801, loss_ce: 0.009391
2022-01-09 12:45:38,480 iteration 1986 : loss : 0.048555, loss_ce: 0.023891
2022-01-09 12:45:40,855 iteration 1987 : loss : 0.031619, loss_ce: 0.012333
2022-01-09 12:45:43,148 iteration 1988 : loss : 0.043082, loss_ce: 0.012171
2022-01-09 12:45:45,390 iteration 1989 : loss : 0.054400, loss_ce: 0.027863
 29%|███████▉                   | 117/400 [1:21:24<3:25:07, 43.49s/it]2022-01-09 12:45:47,578 iteration 1990 : loss : 0.024975, loss_ce: 0.010765
2022-01-09 12:45:49,797 iteration 1991 : loss : 0.025616, loss_ce: 0.009562
2022-01-09 12:45:52,119 iteration 1992 : loss : 0.038745, loss_ce: 0.013342
2022-01-09 12:45:54,496 iteration 1993 : loss : 0.044416, loss_ce: 0.022018
2022-01-09 12:45:56,808 iteration 1994 : loss : 0.032265, loss_ce: 0.013748
2022-01-09 12:45:59,200 iteration 1995 : loss : 0.065248, loss_ce: 0.018643
2022-01-09 12:46:01,668 iteration 1996 : loss : 0.037681, loss_ce: 0.010398
2022-01-09 12:46:04,157 iteration 1997 : loss : 0.036720, loss_ce: 0.012124
2022-01-09 12:46:06,589 iteration 1998 : loss : 0.046688, loss_ce: 0.018548
2022-01-09 12:46:08,954 iteration 1999 : loss : 0.041100, loss_ce: 0.017482
2022-01-09 12:46:11,340 iteration 2000 : loss : 0.040157, loss_ce: 0.010686
2022-01-09 12:46:13,611 iteration 2001 : loss : 0.040538, loss_ce: 0.017205
2022-01-09 12:46:15,951 iteration 2002 : loss : 0.047885, loss_ce: 0.025587
2022-01-09 12:46:18,232 iteration 2003 : loss : 0.043923, loss_ce: 0.021162
2022-01-09 12:46:20,627 iteration 2004 : loss : 0.054085, loss_ce: 0.016934
2022-01-09 12:46:22,972 iteration 2005 : loss : 0.043480, loss_ce: 0.017228
2022-01-09 12:46:25,280 iteration 2006 : loss : 0.044559, loss_ce: 0.015714
 30%|███████▉                   | 118/400 [1:22:04<3:19:19, 42.41s/it]2022-01-09 12:46:27,621 iteration 2007 : loss : 0.036519, loss_ce: 0.016371
2022-01-09 12:46:29,887 iteration 2008 : loss : 0.047027, loss_ce: 0.018526
2022-01-09 12:46:32,179 iteration 2009 : loss : 0.074745, loss_ce: 0.025155
2022-01-09 12:46:34,464 iteration 2010 : loss : 0.048053, loss_ce: 0.019699
2022-01-09 12:46:36,753 iteration 2011 : loss : 0.042043, loss_ce: 0.018429
2022-01-09 12:46:39,081 iteration 2012 : loss : 0.061862, loss_ce: 0.021300
2022-01-09 12:46:41,480 iteration 2013 : loss : 0.041501, loss_ce: 0.015679
2022-01-09 12:46:43,816 iteration 2014 : loss : 0.036409, loss_ce: 0.012657
2022-01-09 12:46:46,154 iteration 2015 : loss : 0.036156, loss_ce: 0.014073
2022-01-09 12:46:48,573 iteration 2016 : loss : 0.044769, loss_ce: 0.013664
2022-01-09 12:46:50,867 iteration 2017 : loss : 0.032447, loss_ce: 0.015013
2022-01-09 12:46:53,223 iteration 2018 : loss : 0.060574, loss_ce: 0.024165
2022-01-09 12:46:55,704 iteration 2019 : loss : 0.031642, loss_ce: 0.013940
2022-01-09 12:46:58,100 iteration 2020 : loss : 0.059090, loss_ce: 0.026969
2022-01-09 12:47:00,441 iteration 2021 : loss : 0.040749, loss_ce: 0.018092
2022-01-09 12:47:02,847 iteration 2022 : loss : 0.047276, loss_ce: 0.022531
2022-01-09 12:47:05,100 iteration 2023 : loss : 0.050651, loss_ce: 0.014893
 30%|████████                   | 119/400 [1:22:44<3:14:58, 41.63s/it]2022-01-09 12:47:07,395 iteration 2024 : loss : 0.041462, loss_ce: 0.017948
2022-01-09 12:47:09,587 iteration 2025 : loss : 0.027529, loss_ce: 0.009377
2022-01-09 12:47:11,789 iteration 2026 : loss : 0.058797, loss_ce: 0.028387
2022-01-09 12:47:14,044 iteration 2027 : loss : 0.043599, loss_ce: 0.016830
2022-01-09 12:47:16,282 iteration 2028 : loss : 0.051417, loss_ce: 0.020775
2022-01-09 12:47:18,478 iteration 2029 : loss : 0.034212, loss_ce: 0.016521
2022-01-09 12:47:20,795 iteration 2030 : loss : 0.047566, loss_ce: 0.016816
2022-01-09 12:47:23,125 iteration 2031 : loss : 0.031387, loss_ce: 0.011384
2022-01-09 12:47:25,381 iteration 2032 : loss : 0.035496, loss_ce: 0.012937
2022-01-09 12:47:27,601 iteration 2033 : loss : 0.049560, loss_ce: 0.017525
2022-01-09 12:47:29,860 iteration 2034 : loss : 0.028098, loss_ce: 0.009609
2022-01-09 12:47:32,362 iteration 2035 : loss : 0.033251, loss_ce: 0.014283
2022-01-09 12:47:34,817 iteration 2036 : loss : 0.037537, loss_ce: 0.015515
2022-01-09 12:47:37,163 iteration 2037 : loss : 0.044952, loss_ce: 0.015058
2022-01-09 12:47:39,445 iteration 2038 : loss : 0.035407, loss_ce: 0.013521
2022-01-09 12:47:41,849 iteration 2039 : loss : 0.049942, loss_ce: 0.022031
2022-01-09 12:47:41,849 Training Data Eval:
2022-01-09 12:47:54,629   Average segmentation loss on training set: 0.0274
2022-01-09 12:47:54,629 Validation Data Eval:
2022-01-09 12:47:59,065   Average segmentation loss on validation set: 0.0848
2022-01-09 12:48:01,456 iteration 2040 : loss : 0.032468, loss_ce: 0.011077
 30%|████████                   | 120/400 [1:23:40<3:34:53, 46.05s/it]2022-01-09 12:48:03,876 iteration 2041 : loss : 0.037537, loss_ce: 0.016733
2022-01-09 12:48:06,167 iteration 2042 : loss : 0.032322, loss_ce: 0.013012
2022-01-09 12:48:08,522 iteration 2043 : loss : 0.035591, loss_ce: 0.015803
2022-01-09 12:48:10,928 iteration 2044 : loss : 0.050756, loss_ce: 0.023971
2022-01-09 12:48:13,370 iteration 2045 : loss : 0.044203, loss_ce: 0.017739
2022-01-09 12:48:15,788 iteration 2046 : loss : 0.043946, loss_ce: 0.018032
2022-01-09 12:48:18,171 iteration 2047 : loss : 0.029236, loss_ce: 0.010549
2022-01-09 12:48:20,482 iteration 2048 : loss : 0.031296, loss_ce: 0.010253
2022-01-09 12:48:22,848 iteration 2049 : loss : 0.038429, loss_ce: 0.015346
2022-01-09 12:48:25,305 iteration 2050 : loss : 0.041910, loss_ce: 0.012037
2022-01-09 12:48:27,716 iteration 2051 : loss : 0.049502, loss_ce: 0.017747
2022-01-09 12:48:30,020 iteration 2052 : loss : 0.029126, loss_ce: 0.014244
2022-01-09 12:48:32,278 iteration 2053 : loss : 0.040273, loss_ce: 0.014478
2022-01-09 12:48:34,600 iteration 2054 : loss : 0.035689, loss_ce: 0.012289
2022-01-09 12:48:36,918 iteration 2055 : loss : 0.045102, loss_ce: 0.020218
2022-01-09 12:48:39,286 iteration 2056 : loss : 0.040489, loss_ce: 0.017105
2022-01-09 12:48:41,637 iteration 2057 : loss : 0.034066, loss_ce: 0.014112
 30%|████████▏                  | 121/400 [1:24:20<3:25:57, 44.29s/it]2022-01-09 12:48:44,169 iteration 2058 : loss : 0.041730, loss_ce: 0.020505
2022-01-09 12:48:46,595 iteration 2059 : loss : 0.041919, loss_ce: 0.015077
2022-01-09 12:48:49,048 iteration 2060 : loss : 0.034536, loss_ce: 0.012586
2022-01-09 12:48:51,371 iteration 2061 : loss : 0.027095, loss_ce: 0.012773
2022-01-09 12:48:53,702 iteration 2062 : loss : 0.031574, loss_ce: 0.010373
2022-01-09 12:48:56,005 iteration 2063 : loss : 0.028840, loss_ce: 0.012439
2022-01-09 12:48:58,344 iteration 2064 : loss : 0.026298, loss_ce: 0.011970
2022-01-09 12:49:00,668 iteration 2065 : loss : 0.039661, loss_ce: 0.013349
2022-01-09 12:49:02,979 iteration 2066 : loss : 0.041778, loss_ce: 0.014531
2022-01-09 12:49:05,201 iteration 2067 : loss : 0.042523, loss_ce: 0.017730
2022-01-09 12:49:07,494 iteration 2068 : loss : 0.039534, loss_ce: 0.020631
2022-01-09 12:49:09,783 iteration 2069 : loss : 0.048618, loss_ce: 0.014585
2022-01-09 12:49:12,030 iteration 2070 : loss : 0.027289, loss_ce: 0.009886
2022-01-09 12:49:14,335 iteration 2071 : loss : 0.044500, loss_ce: 0.020800
2022-01-09 12:49:16,669 iteration 2072 : loss : 0.029299, loss_ce: 0.013242
2022-01-09 12:49:18,948 iteration 2073 : loss : 0.037277, loss_ce: 0.012192
2022-01-09 12:49:21,266 iteration 2074 : loss : 0.041705, loss_ce: 0.012998
 30%|████████▏                  | 122/400 [1:25:00<3:18:43, 42.89s/it]2022-01-09 12:49:23,649 iteration 2075 : loss : 0.035824, loss_ce: 0.013267
2022-01-09 12:49:26,037 iteration 2076 : loss : 0.049167, loss_ce: 0.017171
2022-01-09 12:49:28,543 iteration 2077 : loss : 0.039271, loss_ce: 0.015118
2022-01-09 12:49:30,921 iteration 2078 : loss : 0.030939, loss_ce: 0.012916
2022-01-09 12:49:33,238 iteration 2079 : loss : 0.032233, loss_ce: 0.011106
2022-01-09 12:49:35,602 iteration 2080 : loss : 0.037723, loss_ce: 0.012108
2022-01-09 12:49:37,933 iteration 2081 : loss : 0.049157, loss_ce: 0.023005
2022-01-09 12:49:40,196 iteration 2082 : loss : 0.044580, loss_ce: 0.017729
2022-01-09 12:49:42,448 iteration 2083 : loss : 0.031600, loss_ce: 0.011624
2022-01-09 12:49:44,700 iteration 2084 : loss : 0.042509, loss_ce: 0.015729
2022-01-09 12:49:46,991 iteration 2085 : loss : 0.035667, loss_ce: 0.017951
2022-01-09 12:49:49,405 iteration 2086 : loss : 0.032198, loss_ce: 0.013990
2022-01-09 12:49:51,739 iteration 2087 : loss : 0.053687, loss_ce: 0.015243
2022-01-09 12:49:54,168 iteration 2088 : loss : 0.065208, loss_ce: 0.032808
2022-01-09 12:49:56,453 iteration 2089 : loss : 0.034382, loss_ce: 0.013049
2022-01-09 12:49:58,844 iteration 2090 : loss : 0.034753, loss_ce: 0.012844
2022-01-09 12:50:01,141 iteration 2091 : loss : 0.033785, loss_ce: 0.014841
 31%|████████▎                  | 123/400 [1:25:40<3:13:49, 41.98s/it]2022-01-09 12:50:03,399 iteration 2092 : loss : 0.034247, loss_ce: 0.013887
2022-01-09 12:50:05,747 iteration 2093 : loss : 0.043611, loss_ce: 0.021249
2022-01-09 12:50:08,026 iteration 2094 : loss : 0.033569, loss_ce: 0.015117
2022-01-09 12:50:10,365 iteration 2095 : loss : 0.041004, loss_ce: 0.017190
2022-01-09 12:50:12,638 iteration 2096 : loss : 0.051719, loss_ce: 0.017860
2022-01-09 12:50:14,846 iteration 2097 : loss : 0.036299, loss_ce: 0.016815
2022-01-09 12:50:17,184 iteration 2098 : loss : 0.045565, loss_ce: 0.016796
2022-01-09 12:50:19,493 iteration 2099 : loss : 0.049687, loss_ce: 0.019757
2022-01-09 12:50:21,803 iteration 2100 : loss : 0.046772, loss_ce: 0.018192
2022-01-09 12:50:24,042 iteration 2101 : loss : 0.063972, loss_ce: 0.017558
2022-01-09 12:50:26,315 iteration 2102 : loss : 0.044933, loss_ce: 0.019003
2022-01-09 12:50:28,763 iteration 2103 : loss : 0.042165, loss_ce: 0.016516
2022-01-09 12:50:31,098 iteration 2104 : loss : 0.029603, loss_ce: 0.011444
2022-01-09 12:50:33,388 iteration 2105 : loss : 0.046177, loss_ce: 0.017923
2022-01-09 12:50:35,792 iteration 2106 : loss : 0.057439, loss_ce: 0.020543
2022-01-09 12:50:38,103 iteration 2107 : loss : 0.051527, loss_ce: 0.018421
2022-01-09 12:50:40,392 iteration 2108 : loss : 0.033430, loss_ce: 0.012782
 31%|████████▎                  | 124/400 [1:26:19<3:09:21, 41.16s/it]2022-01-09 12:50:42,793 iteration 2109 : loss : 0.050526, loss_ce: 0.018708
2022-01-09 12:50:45,053 iteration 2110 : loss : 0.034308, loss_ce: 0.010944
2022-01-09 12:50:47,348 iteration 2111 : loss : 0.050910, loss_ce: 0.016510
2022-01-09 12:50:49,639 iteration 2112 : loss : 0.040602, loss_ce: 0.018101
2022-01-09 12:50:51,768 iteration 2113 : loss : 0.033473, loss_ce: 0.014578
2022-01-09 12:50:53,988 iteration 2114 : loss : 0.041292, loss_ce: 0.014672
2022-01-09 12:50:56,249 iteration 2115 : loss : 0.045548, loss_ce: 0.013898
2022-01-09 12:50:58,850 iteration 2116 : loss : 0.050174, loss_ce: 0.023118
2022-01-09 12:51:01,310 iteration 2117 : loss : 0.060387, loss_ce: 0.023697
2022-01-09 12:51:03,659 iteration 2118 : loss : 0.040130, loss_ce: 0.018497
2022-01-09 12:51:05,952 iteration 2119 : loss : 0.037991, loss_ce: 0.016485
2022-01-09 12:51:08,186 iteration 2120 : loss : 0.050387, loss_ce: 0.019923
2022-01-09 12:51:10,586 iteration 2121 : loss : 0.047172, loss_ce: 0.019903
2022-01-09 12:51:12,921 iteration 2122 : loss : 0.052145, loss_ce: 0.022047
2022-01-09 12:51:15,274 iteration 2123 : loss : 0.064975, loss_ce: 0.041835
2022-01-09 12:51:17,724 iteration 2124 : loss : 0.040392, loss_ce: 0.014302
2022-01-09 12:51:17,724 Training Data Eval:
2022-01-09 12:51:30,594   Average segmentation loss on training set: 0.0270
2022-01-09 12:51:30,595 Validation Data Eval:
2022-01-09 12:51:35,027   Average segmentation loss on validation set: 0.0799
2022-01-09 12:51:37,431 iteration 2125 : loss : 0.029295, loss_ce: 0.009143
 31%|████████▍                  | 125/400 [1:27:16<3:30:30, 45.93s/it]2022-01-09 12:51:39,862 iteration 2126 : loss : 0.030673, loss_ce: 0.010962
2022-01-09 12:51:42,327 iteration 2127 : loss : 0.036654, loss_ce: 0.014108
2022-01-09 12:51:44,704 iteration 2128 : loss : 0.032535, loss_ce: 0.014996
2022-01-09 12:51:47,103 iteration 2129 : loss : 0.036564, loss_ce: 0.012295
2022-01-09 12:51:49,402 iteration 2130 : loss : 0.045355, loss_ce: 0.016254
2022-01-09 12:51:51,879 iteration 2131 : loss : 0.083148, loss_ce: 0.034556
2022-01-09 12:51:54,260 iteration 2132 : loss : 0.047317, loss_ce: 0.017579
2022-01-09 12:51:56,616 iteration 2133 : loss : 0.048939, loss_ce: 0.019553
2022-01-09 12:51:59,067 iteration 2134 : loss : 0.083213, loss_ce: 0.026179
2022-01-09 12:52:01,518 iteration 2135 : loss : 0.061351, loss_ce: 0.023214
2022-01-09 12:52:03,924 iteration 2136 : loss : 0.052438, loss_ce: 0.018342
2022-01-09 12:52:06,331 iteration 2137 : loss : 0.061813, loss_ce: 0.019067
2022-01-09 12:52:08,647 iteration 2138 : loss : 0.065257, loss_ce: 0.019051
2022-01-09 12:52:10,955 iteration 2139 : loss : 0.038235, loss_ce: 0.019510
2022-01-09 12:52:13,280 iteration 2140 : loss : 0.039260, loss_ce: 0.013564
2022-01-09 12:52:15,645 iteration 2141 : loss : 0.039557, loss_ce: 0.016226
2022-01-09 12:52:18,034 iteration 2142 : loss : 0.078439, loss_ce: 0.050075
 32%|████████▌                  | 126/400 [1:27:57<3:22:26, 44.33s/it]2022-01-09 12:52:20,445 iteration 2143 : loss : 0.037581, loss_ce: 0.011334
2022-01-09 12:52:22,832 iteration 2144 : loss : 0.042844, loss_ce: 0.013803
2022-01-09 12:52:25,170 iteration 2145 : loss : 0.025525, loss_ce: 0.013594
2022-01-09 12:52:27,674 iteration 2146 : loss : 0.053298, loss_ce: 0.023376
2022-01-09 12:52:30,044 iteration 2147 : loss : 0.038941, loss_ce: 0.017821
2022-01-09 12:52:32,405 iteration 2148 : loss : 0.046773, loss_ce: 0.017848
2022-01-09 12:52:34,765 iteration 2149 : loss : 0.078905, loss_ce: 0.028809
2022-01-09 12:52:37,220 iteration 2150 : loss : 0.076119, loss_ce: 0.037393
2022-01-09 12:52:39,663 iteration 2151 : loss : 0.044988, loss_ce: 0.017512
2022-01-09 12:52:42,025 iteration 2152 : loss : 0.032208, loss_ce: 0.013902
2022-01-09 12:52:44,387 iteration 2153 : loss : 0.038258, loss_ce: 0.011543
2022-01-09 12:52:46,740 iteration 2154 : loss : 0.033091, loss_ce: 0.015866
2022-01-09 12:52:49,086 iteration 2155 : loss : 0.037324, loss_ce: 0.014034
2022-01-09 12:52:51,516 iteration 2156 : loss : 0.047766, loss_ce: 0.018642
2022-01-09 12:52:53,919 iteration 2157 : loss : 0.058760, loss_ce: 0.034321
2022-01-09 12:52:56,251 iteration 2158 : loss : 0.039890, loss_ce: 0.016020
2022-01-09 12:52:58,654 iteration 2159 : loss : 0.057550, loss_ce: 0.019990
 32%|████████▌                  | 127/400 [1:28:37<3:16:38, 43.22s/it]2022-01-09 12:53:00,941 iteration 2160 : loss : 0.029690, loss_ce: 0.009724
2022-01-09 12:53:03,240 iteration 2161 : loss : 0.036485, loss_ce: 0.015265
2022-01-09 12:53:05,555 iteration 2162 : loss : 0.040931, loss_ce: 0.017385
2022-01-09 12:53:07,814 iteration 2163 : loss : 0.047089, loss_ce: 0.016703
2022-01-09 12:53:10,206 iteration 2164 : loss : 0.038566, loss_ce: 0.017829
2022-01-09 12:53:12,600 iteration 2165 : loss : 0.029574, loss_ce: 0.010910
2022-01-09 12:53:15,043 iteration 2166 : loss : 0.043122, loss_ce: 0.021535
2022-01-09 12:53:17,403 iteration 2167 : loss : 0.040720, loss_ce: 0.021893
2022-01-09 12:53:19,664 iteration 2168 : loss : 0.041592, loss_ce: 0.016542
2022-01-09 12:53:21,866 iteration 2169 : loss : 0.032288, loss_ce: 0.012303
2022-01-09 12:53:24,024 iteration 2170 : loss : 0.045506, loss_ce: 0.016911
2022-01-09 12:53:26,364 iteration 2171 : loss : 0.025727, loss_ce: 0.009039
2022-01-09 12:53:28,583 iteration 2172 : loss : 0.032271, loss_ce: 0.015211
2022-01-09 12:53:31,055 iteration 2173 : loss : 0.039348, loss_ce: 0.013378
2022-01-09 12:53:33,480 iteration 2174 : loss : 0.047050, loss_ce: 0.019680
2022-01-09 12:53:35,782 iteration 2175 : loss : 0.039455, loss_ce: 0.012085
2022-01-09 12:53:38,066 iteration 2176 : loss : 0.049448, loss_ce: 0.026226
 32%|████████▋                  | 128/400 [1:29:17<3:10:44, 42.08s/it]2022-01-09 12:53:40,501 iteration 2177 : loss : 0.048565, loss_ce: 0.014831
2022-01-09 12:53:42,796 iteration 2178 : loss : 0.028512, loss_ce: 0.012145
2022-01-09 12:53:45,100 iteration 2179 : loss : 0.034703, loss_ce: 0.014983
2022-01-09 12:53:47,588 iteration 2180 : loss : 0.033455, loss_ce: 0.010605
2022-01-09 12:53:49,994 iteration 2181 : loss : 0.044123, loss_ce: 0.015672
2022-01-09 12:53:52,332 iteration 2182 : loss : 0.030387, loss_ce: 0.012104
2022-01-09 12:53:54,677 iteration 2183 : loss : 0.045944, loss_ce: 0.019021
2022-01-09 12:53:57,070 iteration 2184 : loss : 0.040668, loss_ce: 0.019530
2022-01-09 12:53:59,396 iteration 2185 : loss : 0.032912, loss_ce: 0.012775
2022-01-09 12:54:01,853 iteration 2186 : loss : 0.062771, loss_ce: 0.031237
2022-01-09 12:54:04,098 iteration 2187 : loss : 0.037046, loss_ce: 0.018888
2022-01-09 12:54:06,423 iteration 2188 : loss : 0.040129, loss_ce: 0.015290
2022-01-09 12:54:08,651 iteration 2189 : loss : 0.038060, loss_ce: 0.014440
2022-01-09 12:54:11,045 iteration 2190 : loss : 0.037882, loss_ce: 0.014024
2022-01-09 12:54:13,356 iteration 2191 : loss : 0.031438, loss_ce: 0.013609
2022-01-09 12:54:15,696 iteration 2192 : loss : 0.040788, loss_ce: 0.014787
2022-01-09 12:54:18,143 iteration 2193 : loss : 0.058603, loss_ce: 0.025207
 32%|████████▋                  | 129/400 [1:29:57<3:07:21, 41.48s/it]2022-01-09 12:54:20,515 iteration 2194 : loss : 0.044640, loss_ce: 0.018016
2022-01-09 12:54:22,782 iteration 2195 : loss : 0.030651, loss_ce: 0.011633
2022-01-09 12:54:25,085 iteration 2196 : loss : 0.035820, loss_ce: 0.015532
2022-01-09 12:54:27,507 iteration 2197 : loss : 0.078907, loss_ce: 0.027530
2022-01-09 12:54:29,893 iteration 2198 : loss : 0.032274, loss_ce: 0.016615
2022-01-09 12:54:32,346 iteration 2199 : loss : 0.038778, loss_ce: 0.017537
2022-01-09 12:54:34,655 iteration 2200 : loss : 0.027798, loss_ce: 0.010520
2022-01-09 12:54:36,997 iteration 2201 : loss : 0.049322, loss_ce: 0.015083
2022-01-09 12:54:39,290 iteration 2202 : loss : 0.078286, loss_ce: 0.027013
2022-01-09 12:54:41,545 iteration 2203 : loss : 0.034514, loss_ce: 0.012064
2022-01-09 12:54:43,872 iteration 2204 : loss : 0.037095, loss_ce: 0.013542
2022-01-09 12:54:46,239 iteration 2205 : loss : 0.034966, loss_ce: 0.014697
2022-01-09 12:54:48,585 iteration 2206 : loss : 0.034781, loss_ce: 0.017620
2022-01-09 12:54:50,971 iteration 2207 : loss : 0.080385, loss_ce: 0.039804
2022-01-09 12:54:53,306 iteration 2208 : loss : 0.041284, loss_ce: 0.015608
2022-01-09 12:54:55,752 iteration 2209 : loss : 0.040893, loss_ce: 0.013756
2022-01-09 12:54:55,752 Training Data Eval:
2022-01-09 12:55:08,474   Average segmentation loss on training set: 0.0281
2022-01-09 12:55:08,475 Validation Data Eval:
2022-01-09 12:55:13,010   Average segmentation loss on validation set: 0.1034
2022-01-09 12:55:15,438 iteration 2210 : loss : 0.053803, loss_ce: 0.021379
 32%|████████▊                  | 130/400 [1:30:54<3:27:59, 46.22s/it]2022-01-09 12:55:17,828 iteration 2211 : loss : 0.031106, loss_ce: 0.014345
2022-01-09 12:55:20,128 iteration 2212 : loss : 0.034989, loss_ce: 0.012018
2022-01-09 12:55:22,453 iteration 2213 : loss : 0.029028, loss_ce: 0.010547
2022-01-09 12:55:24,803 iteration 2214 : loss : 0.039043, loss_ce: 0.017678
2022-01-09 12:55:27,085 iteration 2215 : loss : 0.031330, loss_ce: 0.011908
2022-01-09 12:55:29,462 iteration 2216 : loss : 0.048627, loss_ce: 0.020442
2022-01-09 12:55:31,765 iteration 2217 : loss : 0.039968, loss_ce: 0.018222
2022-01-09 12:55:34,165 iteration 2218 : loss : 0.065027, loss_ce: 0.027920
2022-01-09 12:55:36,484 iteration 2219 : loss : 0.039571, loss_ce: 0.017221
2022-01-09 12:55:38,751 iteration 2220 : loss : 0.030343, loss_ce: 0.014725
2022-01-09 12:55:41,081 iteration 2221 : loss : 0.043506, loss_ce: 0.017306
2022-01-09 12:55:43,344 iteration 2222 : loss : 0.060681, loss_ce: 0.021457
2022-01-09 12:55:45,773 iteration 2223 : loss : 0.055743, loss_ce: 0.020544
2022-01-09 12:55:48,088 iteration 2224 : loss : 0.058220, loss_ce: 0.016373
2022-01-09 12:55:50,372 iteration 2225 : loss : 0.032301, loss_ce: 0.012429
2022-01-09 12:55:52,770 iteration 2226 : loss : 0.053950, loss_ce: 0.019636
2022-01-09 12:55:55,168 iteration 2227 : loss : 0.041534, loss_ce: 0.012256
 33%|████████▊                  | 131/400 [1:31:34<3:18:29, 44.27s/it]2022-01-09 12:55:57,529 iteration 2228 : loss : 0.091969, loss_ce: 0.037194
2022-01-09 12:55:59,861 iteration 2229 : loss : 0.066803, loss_ce: 0.027944
2022-01-09 12:56:02,182 iteration 2230 : loss : 0.043944, loss_ce: 0.018386
2022-01-09 12:56:04,426 iteration 2231 : loss : 0.033035, loss_ce: 0.015507
2022-01-09 12:56:06,690 iteration 2232 : loss : 0.033181, loss_ce: 0.011726
2022-01-09 12:56:09,040 iteration 2233 : loss : 0.039296, loss_ce: 0.012160
2022-01-09 12:56:11,442 iteration 2234 : loss : 0.045556, loss_ce: 0.016342
2022-01-09 12:56:13,774 iteration 2235 : loss : 0.043407, loss_ce: 0.021889
2022-01-09 12:56:16,113 iteration 2236 : loss : 0.032107, loss_ce: 0.012837
2022-01-09 12:56:18,463 iteration 2237 : loss : 0.045803, loss_ce: 0.021502
2022-01-09 12:56:20,821 iteration 2238 : loss : 0.056961, loss_ce: 0.019916
2022-01-09 12:56:23,300 iteration 2239 : loss : 0.039213, loss_ce: 0.015140
2022-01-09 12:56:25,638 iteration 2240 : loss : 0.032310, loss_ce: 0.012702
2022-01-09 12:56:28,028 iteration 2241 : loss : 0.039411, loss_ce: 0.015993
2022-01-09 12:56:30,349 iteration 2242 : loss : 0.037940, loss_ce: 0.017205
2022-01-09 12:56:32,711 iteration 2243 : loss : 0.042064, loss_ce: 0.016651
2022-01-09 12:56:35,106 iteration 2244 : loss : 0.024289, loss_ce: 0.010286
 33%|████████▉                  | 132/400 [1:32:14<3:11:57, 42.97s/it]2022-01-09 12:56:37,469 iteration 2245 : loss : 0.029890, loss_ce: 0.012662
2022-01-09 12:56:39,860 iteration 2246 : loss : 0.046489, loss_ce: 0.016582
2022-01-09 12:56:42,209 iteration 2247 : loss : 0.055260, loss_ce: 0.020070
2022-01-09 12:56:44,493 iteration 2248 : loss : 0.024946, loss_ce: 0.010473
2022-01-09 12:56:46,935 iteration 2249 : loss : 0.036300, loss_ce: 0.013369
2022-01-09 12:56:49,445 iteration 2250 : loss : 0.057565, loss_ce: 0.019931
2022-01-09 12:56:51,753 iteration 2251 : loss : 0.034750, loss_ce: 0.014898
2022-01-09 12:56:54,156 iteration 2252 : loss : 0.031807, loss_ce: 0.010968
2022-01-09 12:56:56,414 iteration 2253 : loss : 0.050363, loss_ce: 0.015458
2022-01-09 12:56:58,887 iteration 2254 : loss : 0.045483, loss_ce: 0.020611
2022-01-09 12:57:01,280 iteration 2255 : loss : 0.042532, loss_ce: 0.019870
2022-01-09 12:57:03,637 iteration 2256 : loss : 0.052159, loss_ce: 0.023188
2022-01-09 12:57:05,916 iteration 2257 : loss : 0.034187, loss_ce: 0.012531
2022-01-09 12:57:08,164 iteration 2258 : loss : 0.043489, loss_ce: 0.017411
2022-01-09 12:57:10,462 iteration 2259 : loss : 0.043926, loss_ce: 0.013972
2022-01-09 12:57:12,746 iteration 2260 : loss : 0.040706, loss_ce: 0.013462
2022-01-09 12:57:15,001 iteration 2261 : loss : 0.051734, loss_ce: 0.013826
 33%|████████▉                  | 133/400 [1:32:54<3:07:07, 42.05s/it]2022-01-09 12:57:17,451 iteration 2262 : loss : 0.041839, loss_ce: 0.016635
2022-01-09 12:57:19,724 iteration 2263 : loss : 0.033508, loss_ce: 0.012595
2022-01-09 12:57:21,993 iteration 2264 : loss : 0.056956, loss_ce: 0.017324
2022-01-09 12:57:24,310 iteration 2265 : loss : 0.035315, loss_ce: 0.015899
2022-01-09 12:57:26,558 iteration 2266 : loss : 0.032717, loss_ce: 0.011242
2022-01-09 12:57:28,768 iteration 2267 : loss : 0.040296, loss_ce: 0.015580
2022-01-09 12:57:30,973 iteration 2268 : loss : 0.034091, loss_ce: 0.013831
2022-01-09 12:57:33,304 iteration 2269 : loss : 0.047933, loss_ce: 0.021059
2022-01-09 12:57:35,604 iteration 2270 : loss : 0.035376, loss_ce: 0.013476
2022-01-09 12:57:37,952 iteration 2271 : loss : 0.049530, loss_ce: 0.029533
2022-01-09 12:57:40,318 iteration 2272 : loss : 0.039053, loss_ce: 0.009313
2022-01-09 12:57:42,728 iteration 2273 : loss : 0.039548, loss_ce: 0.011915
2022-01-09 12:57:44,968 iteration 2274 : loss : 0.039902, loss_ce: 0.014007
2022-01-09 12:57:47,288 iteration 2275 : loss : 0.033615, loss_ce: 0.014830
2022-01-09 12:57:49,589 iteration 2276 : loss : 0.059006, loss_ce: 0.020016
2022-01-09 12:57:51,779 iteration 2277 : loss : 0.042568, loss_ce: 0.017068
2022-01-09 12:57:54,032 iteration 2278 : loss : 0.040681, loss_ce: 0.017079
 34%|█████████                  | 134/400 [1:33:33<3:02:25, 41.15s/it]2022-01-09 12:57:56,533 iteration 2279 : loss : 0.039972, loss_ce: 0.019603
2022-01-09 12:57:58,867 iteration 2280 : loss : 0.036195, loss_ce: 0.016662
2022-01-09 12:58:01,180 iteration 2281 : loss : 0.030357, loss_ce: 0.011359
2022-01-09 12:58:03,614 iteration 2282 : loss : 0.052703, loss_ce: 0.017265
2022-01-09 12:58:05,990 iteration 2283 : loss : 0.033423, loss_ce: 0.012525
2022-01-09 12:58:08,448 iteration 2284 : loss : 0.053915, loss_ce: 0.020728
2022-01-09 12:58:10,788 iteration 2285 : loss : 0.032725, loss_ce: 0.011789
2022-01-09 12:58:13,104 iteration 2286 : loss : 0.028729, loss_ce: 0.009666
2022-01-09 12:58:15,424 iteration 2287 : loss : 0.052931, loss_ce: 0.015265
2022-01-09 12:58:17,733 iteration 2288 : loss : 0.033101, loss_ce: 0.013125
2022-01-09 12:58:20,158 iteration 2289 : loss : 0.039143, loss_ce: 0.012652
2022-01-09 12:58:22,540 iteration 2290 : loss : 0.037559, loss_ce: 0.016479
2022-01-09 12:58:24,858 iteration 2291 : loss : 0.034832, loss_ce: 0.013152
2022-01-09 12:58:27,214 iteration 2292 : loss : 0.038491, loss_ce: 0.013219
2022-01-09 12:58:29,517 iteration 2293 : loss : 0.078845, loss_ce: 0.040696
2022-01-09 12:58:31,841 iteration 2294 : loss : 0.042792, loss_ce: 0.018456
2022-01-09 12:58:31,841 Training Data Eval:
2022-01-09 12:58:44,678   Average segmentation loss on training set: 0.0243
2022-01-09 12:58:44,679 Validation Data Eval:
2022-01-09 12:58:49,205   Average segmentation loss on validation set: 0.0655
2022-01-09 12:58:51,578 iteration 2295 : loss : 0.032980, loss_ce: 0.011689
 34%|█████████                  | 135/400 [1:34:30<3:23:27, 46.07s/it]2022-01-09 12:58:53,944 iteration 2296 : loss : 0.032902, loss_ce: 0.013310
2022-01-09 12:58:56,280 iteration 2297 : loss : 0.033186, loss_ce: 0.010749
2022-01-09 12:58:58,692 iteration 2298 : loss : 0.058305, loss_ce: 0.020731
2022-01-09 12:59:01,028 iteration 2299 : loss : 0.040071, loss_ce: 0.011596
2022-01-09 12:59:03,458 iteration 2300 : loss : 0.045337, loss_ce: 0.015196
2022-01-09 12:59:05,742 iteration 2301 : loss : 0.044306, loss_ce: 0.022301
2022-01-09 12:59:08,020 iteration 2302 : loss : 0.038211, loss_ce: 0.018638
2022-01-09 12:59:10,518 iteration 2303 : loss : 0.044178, loss_ce: 0.012802
2022-01-09 12:59:12,846 iteration 2304 : loss : 0.049691, loss_ce: 0.019882
2022-01-09 12:59:15,256 iteration 2305 : loss : 0.042271, loss_ce: 0.014210
2022-01-09 12:59:17,496 iteration 2306 : loss : 0.035627, loss_ce: 0.012885
2022-01-09 12:59:19,674 iteration 2307 : loss : 0.029929, loss_ce: 0.010269
2022-01-09 12:59:21,851 iteration 2308 : loss : 0.044852, loss_ce: 0.020665
2022-01-09 12:59:24,067 iteration 2309 : loss : 0.036310, loss_ce: 0.015426
2022-01-09 12:59:26,385 iteration 2310 : loss : 0.048688, loss_ce: 0.022254
2022-01-09 12:59:28,784 iteration 2311 : loss : 0.050659, loss_ce: 0.020476
2022-01-09 12:59:31,236 iteration 2312 : loss : 0.033019, loss_ce: 0.014519
 34%|█████████▏                 | 136/400 [1:35:10<3:14:13, 44.14s/it]2022-01-09 12:59:33,669 iteration 2313 : loss : 0.035300, loss_ce: 0.016367
2022-01-09 12:59:35,950 iteration 2314 : loss : 0.044693, loss_ce: 0.019164
2022-01-09 12:59:38,244 iteration 2315 : loss : 0.034401, loss_ce: 0.012678
2022-01-09 12:59:40,524 iteration 2316 : loss : 0.033379, loss_ce: 0.016599
2022-01-09 12:59:42,694 iteration 2317 : loss : 0.050059, loss_ce: 0.022853
2022-01-09 12:59:45,001 iteration 2318 : loss : 0.029765, loss_ce: 0.012478
2022-01-09 12:59:47,272 iteration 2319 : loss : 0.049541, loss_ce: 0.015645
2022-01-09 12:59:49,481 iteration 2320 : loss : 0.043209, loss_ce: 0.021361
2022-01-09 12:59:51,836 iteration 2321 : loss : 0.053505, loss_ce: 0.016867
2022-01-09 12:59:54,229 iteration 2322 : loss : 0.027709, loss_ce: 0.011496
2022-01-09 12:59:56,645 iteration 2323 : loss : 0.053848, loss_ce: 0.014604
2022-01-09 12:59:58,964 iteration 2324 : loss : 0.033540, loss_ce: 0.010479
2022-01-09 13:00:01,249 iteration 2325 : loss : 0.042748, loss_ce: 0.022322
2022-01-09 13:00:03,634 iteration 2326 : loss : 0.044289, loss_ce: 0.023507
2022-01-09 13:00:05,908 iteration 2327 : loss : 0.030697, loss_ce: 0.011353
2022-01-09 13:00:08,246 iteration 2328 : loss : 0.047838, loss_ce: 0.017253
2022-01-09 13:00:10,490 iteration 2329 : loss : 0.038760, loss_ce: 0.013539
 34%|█████████▏                 | 137/400 [1:35:49<3:07:04, 42.68s/it]2022-01-09 13:00:12,865 iteration 2330 : loss : 0.029780, loss_ce: 0.012428
2022-01-09 13:00:15,162 iteration 2331 : loss : 0.049780, loss_ce: 0.013252
2022-01-09 13:00:17,605 iteration 2332 : loss : 0.040149, loss_ce: 0.018218
2022-01-09 13:00:19,924 iteration 2333 : loss : 0.030365, loss_ce: 0.016382
2022-01-09 13:00:22,295 iteration 2334 : loss : 0.033647, loss_ce: 0.008234
2022-01-09 13:00:24,706 iteration 2335 : loss : 0.046250, loss_ce: 0.022367
2022-01-09 13:00:27,007 iteration 2336 : loss : 0.040341, loss_ce: 0.017965
2022-01-09 13:00:29,347 iteration 2337 : loss : 0.044261, loss_ce: 0.016232
2022-01-09 13:00:31,680 iteration 2338 : loss : 0.040884, loss_ce: 0.012431
2022-01-09 13:00:34,035 iteration 2339 : loss : 0.078661, loss_ce: 0.027105
2022-01-09 13:00:36,414 iteration 2340 : loss : 0.036742, loss_ce: 0.014567
2022-01-09 13:00:38,799 iteration 2341 : loss : 0.033344, loss_ce: 0.013027
2022-01-09 13:00:41,163 iteration 2342 : loss : 0.022783, loss_ce: 0.007586
2022-01-09 13:00:43,483 iteration 2343 : loss : 0.031900, loss_ce: 0.011595
2022-01-09 13:00:45,743 iteration 2344 : loss : 0.032468, loss_ce: 0.013339
2022-01-09 13:00:48,079 iteration 2345 : loss : 0.031923, loss_ce: 0.012619
2022-01-09 13:00:50,380 iteration 2346 : loss : 0.036495, loss_ce: 0.013002
 34%|█████████▎                 | 138/400 [1:36:29<3:02:40, 41.84s/it]2022-01-09 13:00:52,853 iteration 2347 : loss : 0.039760, loss_ce: 0.014108
2022-01-09 13:00:55,269 iteration 2348 : loss : 0.031377, loss_ce: 0.010963
2022-01-09 13:00:57,703 iteration 2349 : loss : 0.042261, loss_ce: 0.020582
2022-01-09 13:01:00,000 iteration 2350 : loss : 0.030807, loss_ce: 0.015227
2022-01-09 13:01:02,314 iteration 2351 : loss : 0.050140, loss_ce: 0.017210
2022-01-09 13:01:04,631 iteration 2352 : loss : 0.034177, loss_ce: 0.015030
2022-01-09 13:01:06,901 iteration 2353 : loss : 0.027170, loss_ce: 0.012076
2022-01-09 13:01:09,293 iteration 2354 : loss : 0.033844, loss_ce: 0.010758
2022-01-09 13:01:11,651 iteration 2355 : loss : 0.034014, loss_ce: 0.015914
2022-01-09 13:01:14,086 iteration 2356 : loss : 0.045122, loss_ce: 0.015557
2022-01-09 13:01:16,446 iteration 2357 : loss : 0.046045, loss_ce: 0.020423
2022-01-09 13:01:18,771 iteration 2358 : loss : 0.067070, loss_ce: 0.023409
2022-01-09 13:01:21,144 iteration 2359 : loss : 0.069419, loss_ce: 0.017973
2022-01-09 13:01:23,426 iteration 2360 : loss : 0.084323, loss_ce: 0.015923
2022-01-09 13:01:25,935 iteration 2361 : loss : 0.029828, loss_ce: 0.010996
2022-01-09 13:01:28,314 iteration 2362 : loss : 0.037842, loss_ce: 0.015923
2022-01-09 13:01:30,605 iteration 2363 : loss : 0.031450, loss_ce: 0.011366
 35%|█████████▍                 | 139/400 [1:37:09<2:59:53, 41.35s/it]2022-01-09 13:01:32,857 iteration 2364 : loss : 0.077138, loss_ce: 0.039887
2022-01-09 13:01:35,123 iteration 2365 : loss : 0.035928, loss_ce: 0.012760
2022-01-09 13:01:37,545 iteration 2366 : loss : 0.033132, loss_ce: 0.014411
2022-01-09 13:01:39,897 iteration 2367 : loss : 0.059080, loss_ce: 0.018475
2022-01-09 13:01:42,271 iteration 2368 : loss : 0.032568, loss_ce: 0.008989
2022-01-09 13:01:44,502 iteration 2369 : loss : 0.051126, loss_ce: 0.016062
2022-01-09 13:01:46,805 iteration 2370 : loss : 0.040322, loss_ce: 0.013195
2022-01-09 13:01:49,110 iteration 2371 : loss : 0.043403, loss_ce: 0.018229
2022-01-09 13:01:51,295 iteration 2372 : loss : 0.028565, loss_ce: 0.013987
2022-01-09 13:01:53,526 iteration 2373 : loss : 0.031176, loss_ce: 0.011580
2022-01-09 13:01:55,904 iteration 2374 : loss : 0.033808, loss_ce: 0.013229
2022-01-09 13:01:58,192 iteration 2375 : loss : 0.040295, loss_ce: 0.014305
2022-01-09 13:02:00,512 iteration 2376 : loss : 0.062333, loss_ce: 0.033944
2022-01-09 13:02:02,774 iteration 2377 : loss : 0.044845, loss_ce: 0.011983
2022-01-09 13:02:05,188 iteration 2378 : loss : 0.049491, loss_ce: 0.025868
2022-01-09 13:02:07,479 iteration 2379 : loss : 0.054346, loss_ce: 0.016075
2022-01-09 13:02:07,479 Training Data Eval:
2022-01-09 13:02:19,981   Average segmentation loss on training set: 0.0603
2022-01-09 13:02:19,982 Validation Data Eval:
2022-01-09 13:02:24,479   Average segmentation loss on validation set: 0.0844
2022-01-09 13:02:26,930 iteration 2380 : loss : 0.033307, loss_ce: 0.011736
 35%|█████████▍                 | 140/400 [1:38:06<3:18:38, 45.84s/it]2022-01-09 13:02:29,206 iteration 2381 : loss : 0.038121, loss_ce: 0.012657
2022-01-09 13:02:31,562 iteration 2382 : loss : 0.042765, loss_ce: 0.018856
2022-01-09 13:02:33,855 iteration 2383 : loss : 0.053507, loss_ce: 0.025195
2022-01-09 13:02:36,111 iteration 2384 : loss : 0.036746, loss_ce: 0.012033
2022-01-09 13:02:38,473 iteration 2385 : loss : 0.043206, loss_ce: 0.021114
2022-01-09 13:02:40,955 iteration 2386 : loss : 0.051533, loss_ce: 0.019594
2022-01-09 13:02:43,277 iteration 2387 : loss : 0.042042, loss_ce: 0.015483
2022-01-09 13:02:45,649 iteration 2388 : loss : 0.054366, loss_ce: 0.020261
2022-01-09 13:02:47,912 iteration 2389 : loss : 0.040479, loss_ce: 0.017101
2022-01-09 13:02:50,265 iteration 2390 : loss : 0.023650, loss_ce: 0.009929
2022-01-09 13:02:52,578 iteration 2391 : loss : 0.033727, loss_ce: 0.012406
2022-01-09 13:02:54,897 iteration 2392 : loss : 0.035810, loss_ce: 0.014407
2022-01-09 13:02:57,185 iteration 2393 : loss : 0.045533, loss_ce: 0.022998
2022-01-09 13:02:59,475 iteration 2394 : loss : 0.098658, loss_ce: 0.028159
2022-01-09 13:03:01,960 iteration 2395 : loss : 0.038050, loss_ce: 0.013891
2022-01-09 13:03:04,335 iteration 2396 : loss : 0.030563, loss_ce: 0.012919
2022-01-09 13:03:06,604 iteration 2397 : loss : 0.034282, loss_ce: 0.011248
 35%|█████████▌                 | 141/400 [1:38:45<3:09:54, 43.99s/it]2022-01-09 13:03:08,959 iteration 2398 : loss : 0.064777, loss_ce: 0.036100
2022-01-09 13:03:11,154 iteration 2399 : loss : 0.036557, loss_ce: 0.013906
2022-01-09 13:03:13,438 iteration 2400 : loss : 0.032018, loss_ce: 0.008383
2022-01-09 13:03:15,690 iteration 2401 : loss : 0.044287, loss_ce: 0.017309
2022-01-09 13:03:17,934 iteration 2402 : loss : 0.036768, loss_ce: 0.015624
2022-01-09 13:03:20,273 iteration 2403 : loss : 0.027475, loss_ce: 0.009822
2022-01-09 13:03:22,529 iteration 2404 : loss : 0.039073, loss_ce: 0.019967
2022-01-09 13:03:24,780 iteration 2405 : loss : 0.053618, loss_ce: 0.025656
2022-01-09 13:03:27,055 iteration 2406 : loss : 0.051627, loss_ce: 0.024090
2022-01-09 13:03:29,317 iteration 2407 : loss : 0.031260, loss_ce: 0.012014
2022-01-09 13:03:31,647 iteration 2408 : loss : 0.033310, loss_ce: 0.013476
2022-01-09 13:03:33,951 iteration 2409 : loss : 0.042601, loss_ce: 0.015232
2022-01-09 13:03:36,368 iteration 2410 : loss : 0.057732, loss_ce: 0.017677
2022-01-09 13:03:38,612 iteration 2411 : loss : 0.032712, loss_ce: 0.009981
2022-01-09 13:03:40,974 iteration 2412 : loss : 0.059551, loss_ce: 0.023314
2022-01-09 13:03:43,367 iteration 2413 : loss : 0.041837, loss_ce: 0.020766
2022-01-09 13:03:45,695 iteration 2414 : loss : 0.047092, loss_ce: 0.020611
 36%|█████████▌                 | 142/400 [1:39:24<3:02:51, 42.52s/it]2022-01-09 13:03:48,050 iteration 2415 : loss : 0.035310, loss_ce: 0.013447
2022-01-09 13:03:50,434 iteration 2416 : loss : 0.043554, loss_ce: 0.023392
2022-01-09 13:03:52,758 iteration 2417 : loss : 0.031113, loss_ce: 0.009558
2022-01-09 13:03:55,103 iteration 2418 : loss : 0.038940, loss_ce: 0.011950
2022-01-09 13:03:57,470 iteration 2419 : loss : 0.036851, loss_ce: 0.017090
2022-01-09 13:03:59,764 iteration 2420 : loss : 0.030160, loss_ce: 0.011766
2022-01-09 13:04:02,144 iteration 2421 : loss : 0.031126, loss_ce: 0.008858
2022-01-09 13:04:04,438 iteration 2422 : loss : 0.038688, loss_ce: 0.012759
2022-01-09 13:04:06,696 iteration 2423 : loss : 0.038035, loss_ce: 0.017171
2022-01-09 13:04:08,912 iteration 2424 : loss : 0.042585, loss_ce: 0.013321
2022-01-09 13:04:11,281 iteration 2425 : loss : 0.039716, loss_ce: 0.021677
2022-01-09 13:04:13,578 iteration 2426 : loss : 0.037875, loss_ce: 0.015188
2022-01-09 13:04:16,018 iteration 2427 : loss : 0.049372, loss_ce: 0.014056
2022-01-09 13:04:18,471 iteration 2428 : loss : 0.038553, loss_ce: 0.016134
2022-01-09 13:04:20,880 iteration 2429 : loss : 0.054599, loss_ce: 0.023766
2022-01-09 13:04:23,261 iteration 2430 : loss : 0.032675, loss_ce: 0.014015
2022-01-09 13:04:25,583 iteration 2431 : loss : 0.028412, loss_ce: 0.013494
 36%|█████████▋                 | 143/400 [1:40:04<2:58:46, 41.74s/it]2022-01-09 13:04:28,027 iteration 2432 : loss : 0.027490, loss_ce: 0.011920
2022-01-09 13:04:30,352 iteration 2433 : loss : 0.056051, loss_ce: 0.025267
2022-01-09 13:04:32,713 iteration 2434 : loss : 0.025730, loss_ce: 0.007277
2022-01-09 13:04:35,128 iteration 2435 : loss : 0.041581, loss_ce: 0.021577
2022-01-09 13:04:37,426 iteration 2436 : loss : 0.034778, loss_ce: 0.013872
2022-01-09 13:04:39,765 iteration 2437 : loss : 0.024332, loss_ce: 0.009827
2022-01-09 13:04:42,261 iteration 2438 : loss : 0.038345, loss_ce: 0.017325
2022-01-09 13:04:44,666 iteration 2439 : loss : 0.039315, loss_ce: 0.017566
2022-01-09 13:04:47,074 iteration 2440 : loss : 0.036179, loss_ce: 0.012511
2022-01-09 13:04:49,429 iteration 2441 : loss : 0.044223, loss_ce: 0.012519
2022-01-09 13:04:51,740 iteration 2442 : loss : 0.040688, loss_ce: 0.014343
2022-01-09 13:04:54,058 iteration 2443 : loss : 0.035307, loss_ce: 0.015021
2022-01-09 13:04:56,521 iteration 2444 : loss : 0.026091, loss_ce: 0.010505
2022-01-09 13:04:58,853 iteration 2445 : loss : 0.047357, loss_ce: 0.011105
2022-01-09 13:05:01,288 iteration 2446 : loss : 0.039159, loss_ce: 0.013019
2022-01-09 13:05:03,646 iteration 2447 : loss : 0.041975, loss_ce: 0.018916
2022-01-09 13:05:05,962 iteration 2448 : loss : 0.029539, loss_ce: 0.010268
 36%|█████████▋                 | 144/400 [1:40:45<2:56:20, 41.33s/it]2022-01-09 13:05:08,256 iteration 2449 : loss : 0.035646, loss_ce: 0.016273
2022-01-09 13:05:10,593 iteration 2450 : loss : 0.046359, loss_ce: 0.015643
2022-01-09 13:05:13,001 iteration 2451 : loss : 0.044306, loss_ce: 0.017559
2022-01-09 13:05:15,231 iteration 2452 : loss : 0.024852, loss_ce: 0.011524
2022-01-09 13:05:17,485 iteration 2453 : loss : 0.040542, loss_ce: 0.010156
2022-01-09 13:05:19,785 iteration 2454 : loss : 0.040388, loss_ce: 0.021321
2022-01-09 13:05:22,166 iteration 2455 : loss : 0.040454, loss_ce: 0.020227
2022-01-09 13:05:24,548 iteration 2456 : loss : 0.077919, loss_ce: 0.031215
2022-01-09 13:05:26,800 iteration 2457 : loss : 0.040273, loss_ce: 0.013536
2022-01-09 13:05:29,166 iteration 2458 : loss : 0.039252, loss_ce: 0.012437
2022-01-09 13:05:31,515 iteration 2459 : loss : 0.046206, loss_ce: 0.014074
2022-01-09 13:05:33,864 iteration 2460 : loss : 0.041403, loss_ce: 0.014731
2022-01-09 13:05:36,242 iteration 2461 : loss : 0.057508, loss_ce: 0.019060
2022-01-09 13:05:38,514 iteration 2462 : loss : 0.030508, loss_ce: 0.014456
2022-01-09 13:05:40,799 iteration 2463 : loss : 0.028523, loss_ce: 0.009834
2022-01-09 13:05:43,067 iteration 2464 : loss : 0.058963, loss_ce: 0.024595
2022-01-09 13:05:43,068 Training Data Eval:
2022-01-09 13:05:55,631   Average segmentation loss on training set: 0.0249
2022-01-09 13:05:55,631 Validation Data Eval:
2022-01-09 13:06:00,011   Average segmentation loss on validation set: 0.0786
2022-01-09 13:06:02,396 iteration 2465 : loss : 0.035776, loss_ce: 0.012789
 36%|█████████▊                 | 145/400 [1:41:41<3:14:54, 45.86s/it]2022-01-09 13:06:04,811 iteration 2466 : loss : 0.036918, loss_ce: 0.015147
2022-01-09 13:06:07,180 iteration 2467 : loss : 0.040820, loss_ce: 0.022569
2022-01-09 13:06:09,490 iteration 2468 : loss : 0.032426, loss_ce: 0.014029
2022-01-09 13:06:11,807 iteration 2469 : loss : 0.019967, loss_ce: 0.009905
2022-01-09 13:06:14,231 iteration 2470 : loss : 0.034649, loss_ce: 0.012989
2022-01-09 13:06:16,685 iteration 2471 : loss : 0.047231, loss_ce: 0.019086
2022-01-09 13:06:19,173 iteration 2472 : loss : 0.053530, loss_ce: 0.021451
2022-01-09 13:06:21,491 iteration 2473 : loss : 0.037011, loss_ce: 0.013896
2022-01-09 13:06:23,868 iteration 2474 : loss : 0.036080, loss_ce: 0.011317
2022-01-09 13:06:26,151 iteration 2475 : loss : 0.023362, loss_ce: 0.010232
2022-01-09 13:06:28,590 iteration 2476 : loss : 0.055266, loss_ce: 0.017964
2022-01-09 13:06:30,939 iteration 2477 : loss : 0.040381, loss_ce: 0.017299
2022-01-09 13:06:33,303 iteration 2478 : loss : 0.033739, loss_ce: 0.010185
2022-01-09 13:06:35,740 iteration 2479 : loss : 0.039351, loss_ce: 0.010560
2022-01-09 13:06:38,161 iteration 2480 : loss : 0.057088, loss_ce: 0.024847
2022-01-09 13:06:40,504 iteration 2481 : loss : 0.030063, loss_ce: 0.011173
2022-01-09 13:06:42,901 iteration 2482 : loss : 0.033100, loss_ce: 0.013054
 36%|█████████▊                 | 146/400 [1:42:22<3:07:20, 44.26s/it]2022-01-09 13:06:45,310 iteration 2483 : loss : 0.032176, loss_ce: 0.013381
2022-01-09 13:06:47,728 iteration 2484 : loss : 0.041708, loss_ce: 0.013562
2022-01-09 13:06:50,173 iteration 2485 : loss : 0.058232, loss_ce: 0.021868
2022-01-09 13:06:52,482 iteration 2486 : loss : 0.029905, loss_ce: 0.012636
2022-01-09 13:06:54,786 iteration 2487 : loss : 0.032512, loss_ce: 0.010562
2022-01-09 13:06:57,191 iteration 2488 : loss : 0.040639, loss_ce: 0.013770
2022-01-09 13:06:59,649 iteration 2489 : loss : 0.037124, loss_ce: 0.014923
2022-01-09 13:07:01,980 iteration 2490 : loss : 0.032825, loss_ce: 0.014545
2022-01-09 13:07:04,375 iteration 2491 : loss : 0.038410, loss_ce: 0.015512
2022-01-09 13:07:06,760 iteration 2492 : loss : 0.047131, loss_ce: 0.018801
2022-01-09 13:07:09,119 iteration 2493 : loss : 0.033503, loss_ce: 0.011443
2022-01-09 13:07:11,438 iteration 2494 : loss : 0.030648, loss_ce: 0.013734
2022-01-09 13:07:13,806 iteration 2495 : loss : 0.048117, loss_ce: 0.014980
2022-01-09 13:07:16,258 iteration 2496 : loss : 0.065845, loss_ce: 0.019454
2022-01-09 13:07:18,661 iteration 2497 : loss : 0.042994, loss_ce: 0.019185
2022-01-09 13:07:20,966 iteration 2498 : loss : 0.050511, loss_ce: 0.024795
2022-01-09 13:07:23,407 iteration 2499 : loss : 0.043858, loss_ce: 0.019823
 37%|█████████▉                 | 147/400 [1:43:02<3:01:49, 43.12s/it]2022-01-09 13:07:25,791 iteration 2500 : loss : 0.058279, loss_ce: 0.025488
2022-01-09 13:07:28,071 iteration 2501 : loss : 0.030113, loss_ce: 0.010681
2022-01-09 13:07:30,443 iteration 2502 : loss : 0.043086, loss_ce: 0.016215
2022-01-09 13:07:32,842 iteration 2503 : loss : 0.035484, loss_ce: 0.016828
2022-01-09 13:07:35,225 iteration 2504 : loss : 0.045734, loss_ce: 0.014564
2022-01-09 13:07:37,525 iteration 2505 : loss : 0.033891, loss_ce: 0.014891
2022-01-09 13:07:39,877 iteration 2506 : loss : 0.052817, loss_ce: 0.015121
2022-01-09 13:07:42,231 iteration 2507 : loss : 0.031640, loss_ce: 0.013024
2022-01-09 13:07:44,559 iteration 2508 : loss : 0.030601, loss_ce: 0.016557
2022-01-09 13:07:46,873 iteration 2509 : loss : 0.043833, loss_ce: 0.017758
2022-01-09 13:07:49,131 iteration 2510 : loss : 0.043498, loss_ce: 0.015181
2022-01-09 13:07:51,543 iteration 2511 : loss : 0.035476, loss_ce: 0.018200
2022-01-09 13:07:53,980 iteration 2512 : loss : 0.038760, loss_ce: 0.014415
2022-01-09 13:07:56,550 iteration 2513 : loss : 0.033282, loss_ce: 0.012874
2022-01-09 13:07:58,979 iteration 2514 : loss : 0.038292, loss_ce: 0.012591
2022-01-09 13:08:01,377 iteration 2515 : loss : 0.036797, loss_ce: 0.017987
2022-01-09 13:08:03,897 iteration 2516 : loss : 0.051796, loss_ce: 0.020322
 37%|█████████▉                 | 148/400 [1:43:43<2:57:48, 42.34s/it]2022-01-09 13:08:06,254 iteration 2517 : loss : 0.043139, loss_ce: 0.014660
2022-01-09 13:08:08,567 iteration 2518 : loss : 0.048985, loss_ce: 0.015155
2022-01-09 13:08:10,851 iteration 2519 : loss : 0.029347, loss_ce: 0.010324
2022-01-09 13:08:13,290 iteration 2520 : loss : 0.059293, loss_ce: 0.030335
2022-01-09 13:08:15,717 iteration 2521 : loss : 0.046332, loss_ce: 0.020870
2022-01-09 13:08:18,131 iteration 2522 : loss : 0.047576, loss_ce: 0.017751
2022-01-09 13:08:20,681 iteration 2523 : loss : 0.046242, loss_ce: 0.014499
2022-01-09 13:08:23,140 iteration 2524 : loss : 0.028177, loss_ce: 0.011268
2022-01-09 13:08:25,474 iteration 2525 : loss : 0.037021, loss_ce: 0.012096
2022-01-09 13:08:27,801 iteration 2526 : loss : 0.038347, loss_ce: 0.013101
2022-01-09 13:08:30,334 iteration 2527 : loss : 0.049572, loss_ce: 0.021678
2022-01-09 13:08:32,717 iteration 2528 : loss : 0.041419, loss_ce: 0.018196
2022-01-09 13:08:35,059 iteration 2529 : loss : 0.034047, loss_ce: 0.014890
2022-01-09 13:08:37,353 iteration 2530 : loss : 0.045007, loss_ce: 0.016812
2022-01-09 13:08:39,733 iteration 2531 : loss : 0.053617, loss_ce: 0.018119
2022-01-09 13:08:42,183 iteration 2532 : loss : 0.039216, loss_ce: 0.017877
2022-01-09 13:08:44,516 iteration 2533 : loss : 0.040180, loss_ce: 0.010817
 37%|██████████                 | 149/400 [1:44:23<2:54:56, 41.82s/it]2022-01-09 13:08:46,954 iteration 2534 : loss : 0.032362, loss_ce: 0.012734
2022-01-09 13:08:49,308 iteration 2535 : loss : 0.037911, loss_ce: 0.016348
2022-01-09 13:08:51,671 iteration 2536 : loss : 0.023118, loss_ce: 0.010420
2022-01-09 13:08:54,122 iteration 2537 : loss : 0.041613, loss_ce: 0.019825
2022-01-09 13:08:56,452 iteration 2538 : loss : 0.036883, loss_ce: 0.013350
2022-01-09 13:08:58,788 iteration 2539 : loss : 0.033871, loss_ce: 0.013638
2022-01-09 13:09:01,161 iteration 2540 : loss : 0.044343, loss_ce: 0.017842
2022-01-09 13:09:03,760 iteration 2541 : loss : 0.066762, loss_ce: 0.027189
2022-01-09 13:09:06,140 iteration 2542 : loss : 0.044073, loss_ce: 0.013327
2022-01-09 13:09:08,584 iteration 2543 : loss : 0.036232, loss_ce: 0.011178
2022-01-09 13:09:11,109 iteration 2544 : loss : 0.050669, loss_ce: 0.018608
2022-01-09 13:09:13,545 iteration 2545 : loss : 0.033010, loss_ce: 0.014548
2022-01-09 13:09:16,104 iteration 2546 : loss : 0.063001, loss_ce: 0.022904
2022-01-09 13:09:18,462 iteration 2547 : loss : 0.055406, loss_ce: 0.017371
2022-01-09 13:09:20,808 iteration 2548 : loss : 0.036295, loss_ce: 0.014540
2022-01-09 13:09:23,052 iteration 2549 : loss : 0.038586, loss_ce: 0.015098
2022-01-09 13:09:23,052 Training Data Eval:
2022-01-09 13:09:35,858   Average segmentation loss on training set: 0.0255
2022-01-09 13:09:35,859 Validation Data Eval:
2022-01-09 13:09:40,389   Average segmentation loss on validation set: 0.0891
2022-01-09 13:09:42,813 iteration 2550 : loss : 0.044942, loss_ce: 0.011370
 38%|██████████▏                | 150/400 [1:45:22<3:14:50, 46.76s/it]2022-01-09 13:09:45,223 iteration 2551 : loss : 0.034100, loss_ce: 0.012057
2022-01-09 13:09:47,538 iteration 2552 : loss : 0.024513, loss_ce: 0.009705
2022-01-09 13:09:49,863 iteration 2553 : loss : 0.036787, loss_ce: 0.012859
2022-01-09 13:09:52,190 iteration 2554 : loss : 0.038620, loss_ce: 0.016449
2022-01-09 13:09:54,429 iteration 2555 : loss : 0.034551, loss_ce: 0.014129
2022-01-09 13:09:56,781 iteration 2556 : loss : 0.035136, loss_ce: 0.014258
2022-01-09 13:09:59,160 iteration 2557 : loss : 0.033438, loss_ce: 0.014011
2022-01-09 13:10:01,559 iteration 2558 : loss : 0.031712, loss_ce: 0.010924
2022-01-09 13:10:03,879 iteration 2559 : loss : 0.044927, loss_ce: 0.021144
2022-01-09 13:10:06,267 iteration 2560 : loss : 0.037467, loss_ce: 0.012732
2022-01-09 13:10:08,492 iteration 2561 : loss : 0.052642, loss_ce: 0.017884
2022-01-09 13:10:10,804 iteration 2562 : loss : 0.051219, loss_ce: 0.021280
2022-01-09 13:10:13,148 iteration 2563 : loss : 0.029703, loss_ce: 0.011820
2022-01-09 13:10:15,490 iteration 2564 : loss : 0.027262, loss_ce: 0.012019
2022-01-09 13:10:17,903 iteration 2565 : loss : 0.024528, loss_ce: 0.009786
2022-01-09 13:10:20,241 iteration 2566 : loss : 0.030201, loss_ce: 0.011547
2022-01-09 13:10:22,597 iteration 2567 : loss : 0.059705, loss_ce: 0.018672
 38%|██████████▏                | 151/400 [1:46:01<3:05:23, 44.67s/it]2022-01-09 13:10:24,916 iteration 2568 : loss : 0.035010, loss_ce: 0.014215
2022-01-09 13:10:27,182 iteration 2569 : loss : 0.025763, loss_ce: 0.011373
2022-01-09 13:10:29,607 iteration 2570 : loss : 0.047888, loss_ce: 0.016975
2022-01-09 13:10:31,901 iteration 2571 : loss : 0.038102, loss_ce: 0.011265
2022-01-09 13:10:34,180 iteration 2572 : loss : 0.050463, loss_ce: 0.016159
2022-01-09 13:10:36,535 iteration 2573 : loss : 0.037664, loss_ce: 0.014909
2022-01-09 13:10:38,824 iteration 2574 : loss : 0.039922, loss_ce: 0.019924
2022-01-09 13:10:41,040 iteration 2575 : loss : 0.029785, loss_ce: 0.009694
2022-01-09 13:10:43,266 iteration 2576 : loss : 0.030848, loss_ce: 0.008988
2022-01-09 13:10:45,682 iteration 2577 : loss : 0.054103, loss_ce: 0.029874
2022-01-09 13:10:48,002 iteration 2578 : loss : 0.039207, loss_ce: 0.012714
2022-01-09 13:10:50,357 iteration 2579 : loss : 0.048282, loss_ce: 0.016244
2022-01-09 13:10:52,633 iteration 2580 : loss : 0.036160, loss_ce: 0.012067
2022-01-09 13:10:54,954 iteration 2581 : loss : 0.037211, loss_ce: 0.015475
2022-01-09 13:10:57,298 iteration 2582 : loss : 0.029034, loss_ce: 0.013842
2022-01-09 13:10:59,593 iteration 2583 : loss : 0.027963, loss_ce: 0.012979
2022-01-09 13:11:01,979 iteration 2584 : loss : 0.037234, loss_ce: 0.013589
 38%|██████████▎                | 152/400 [1:46:41<2:58:04, 43.08s/it]2022-01-09 13:11:04,379 iteration 2585 : loss : 0.037214, loss_ce: 0.013827
2022-01-09 13:11:06,897 iteration 2586 : loss : 0.048044, loss_ce: 0.015035
2022-01-09 13:11:09,231 iteration 2587 : loss : 0.036223, loss_ce: 0.012527
2022-01-09 13:11:11,552 iteration 2588 : loss : 0.061794, loss_ce: 0.023660
2022-01-09 13:11:13,828 iteration 2589 : loss : 0.045391, loss_ce: 0.012142
2022-01-09 13:11:16,146 iteration 2590 : loss : 0.038847, loss_ce: 0.012066
2022-01-09 13:11:18,460 iteration 2591 : loss : 0.031465, loss_ce: 0.012070
2022-01-09 13:11:20,819 iteration 2592 : loss : 0.041682, loss_ce: 0.024312
2022-01-09 13:11:23,143 iteration 2593 : loss : 0.037140, loss_ce: 0.019019
2022-01-09 13:11:25,518 iteration 2594 : loss : 0.075827, loss_ce: 0.040972
2022-01-09 13:11:27,824 iteration 2595 : loss : 0.038913, loss_ce: 0.010964
2022-01-09 13:11:30,348 iteration 2596 : loss : 0.064751, loss_ce: 0.019336
2022-01-09 13:11:32,752 iteration 2597 : loss : 0.039284, loss_ce: 0.014196
2022-01-09 13:11:35,114 iteration 2598 : loss : 0.038474, loss_ce: 0.016086
2022-01-09 13:11:37,506 iteration 2599 : loss : 0.032208, loss_ce: 0.013377
2022-01-09 13:11:39,818 iteration 2600 : loss : 0.037975, loss_ce: 0.015652
2022-01-09 13:11:42,138 iteration 2601 : loss : 0.039814, loss_ce: 0.015409
 38%|██████████▎                | 153/400 [1:47:21<2:53:45, 42.21s/it]2022-01-09 13:11:44,494 iteration 2602 : loss : 0.037753, loss_ce: 0.014383
2022-01-09 13:11:46,854 iteration 2603 : loss : 0.088809, loss_ce: 0.022386
2022-01-09 13:11:49,117 iteration 2604 : loss : 0.040600, loss_ce: 0.017652
2022-01-09 13:11:51,416 iteration 2605 : loss : 0.056007, loss_ce: 0.021651
2022-01-09 13:11:53,792 iteration 2606 : loss : 0.033494, loss_ce: 0.012447
2022-01-09 13:11:56,127 iteration 2607 : loss : 0.041978, loss_ce: 0.018967
2022-01-09 13:11:58,487 iteration 2608 : loss : 0.051965, loss_ce: 0.016495
2022-01-09 13:12:00,864 iteration 2609 : loss : 0.037127, loss_ce: 0.014481
2022-01-09 13:12:03,169 iteration 2610 : loss : 0.041246, loss_ce: 0.013690
2022-01-09 13:12:05,439 iteration 2611 : loss : 0.047073, loss_ce: 0.019935
2022-01-09 13:12:07,657 iteration 2612 : loss : 0.029852, loss_ce: 0.011741
2022-01-09 13:12:09,991 iteration 2613 : loss : 0.046072, loss_ce: 0.016484
2022-01-09 13:12:12,346 iteration 2614 : loss : 0.034911, loss_ce: 0.017034
2022-01-09 13:12:14,730 iteration 2615 : loss : 0.040560, loss_ce: 0.017546
2022-01-09 13:12:17,139 iteration 2616 : loss : 0.041076, loss_ce: 0.017455
2022-01-09 13:12:19,468 iteration 2617 : loss : 0.046566, loss_ce: 0.019026
2022-01-09 13:12:21,911 iteration 2618 : loss : 0.042744, loss_ce: 0.014188
 38%|██████████▍                | 154/400 [1:48:01<2:50:04, 41.48s/it]2022-01-09 13:12:24,434 iteration 2619 : loss : 0.038952, loss_ce: 0.016668
2022-01-09 13:12:26,767 iteration 2620 : loss : 0.044290, loss_ce: 0.015508
2022-01-09 13:12:28,920 iteration 2621 : loss : 0.035757, loss_ce: 0.015598
2022-01-09 13:12:31,167 iteration 2622 : loss : 0.055991, loss_ce: 0.018796
2022-01-09 13:12:33,401 iteration 2623 : loss : 0.028545, loss_ce: 0.011342
2022-01-09 13:12:35,746 iteration 2624 : loss : 0.070126, loss_ce: 0.027883
2022-01-09 13:12:38,072 iteration 2625 : loss : 0.036930, loss_ce: 0.016060
2022-01-09 13:12:40,413 iteration 2626 : loss : 0.039598, loss_ce: 0.016499
2022-01-09 13:12:42,695 iteration 2627 : loss : 0.035114, loss_ce: 0.019444
2022-01-09 13:12:45,026 iteration 2628 : loss : 0.028600, loss_ce: 0.011115
2022-01-09 13:12:47,287 iteration 2629 : loss : 0.048425, loss_ce: 0.015044
2022-01-09 13:12:49,647 iteration 2630 : loss : 0.095136, loss_ce: 0.022848
2022-01-09 13:12:51,869 iteration 2631 : loss : 0.046458, loss_ce: 0.021253
2022-01-09 13:12:54,107 iteration 2632 : loss : 0.034893, loss_ce: 0.010715
2022-01-09 13:12:56,502 iteration 2633 : loss : 0.022287, loss_ce: 0.007558
2022-01-09 13:12:58,825 iteration 2634 : loss : 0.065661, loss_ce: 0.022675
2022-01-09 13:12:58,826 Training Data Eval:
2022-01-09 13:13:11,538   Average segmentation loss on training set: 0.1097
2022-01-09 13:13:11,538 Validation Data Eval:
2022-01-09 13:13:15,957   Average segmentation loss on validation set: 0.2899
2022-01-09 13:13:18,325 iteration 2635 : loss : 0.048179, loss_ce: 0.019988
 39%|██████████▍                | 155/400 [1:48:57<3:07:39, 45.96s/it]2022-01-09 13:13:20,716 iteration 2636 : loss : 0.040715, loss_ce: 0.014025
2022-01-09 13:13:23,110 iteration 2637 : loss : 0.053885, loss_ce: 0.030107
2022-01-09 13:13:25,711 iteration 2638 : loss : 0.073682, loss_ce: 0.032525
2022-01-09 13:13:28,083 iteration 2639 : loss : 0.041292, loss_ce: 0.018344
2022-01-09 13:13:30,451 iteration 2640 : loss : 0.042399, loss_ce: 0.015482
2022-01-09 13:13:32,792 iteration 2641 : loss : 0.034001, loss_ce: 0.013197
2022-01-09 13:13:35,202 iteration 2642 : loss : 0.051559, loss_ce: 0.018034
2022-01-09 13:13:37,527 iteration 2643 : loss : 0.050714, loss_ce: 0.026237
2022-01-09 13:13:39,890 iteration 2644 : loss : 0.045106, loss_ce: 0.026467
2022-01-09 13:13:42,164 iteration 2645 : loss : 0.032995, loss_ce: 0.014461
2022-01-09 13:13:44,432 iteration 2646 : loss : 0.044055, loss_ce: 0.015072
2022-01-09 13:13:46,834 iteration 2647 : loss : 0.043281, loss_ce: 0.020850
2022-01-09 13:13:49,083 iteration 2648 : loss : 0.041910, loss_ce: 0.015248
2022-01-09 13:13:51,446 iteration 2649 : loss : 0.040134, loss_ce: 0.012275
2022-01-09 13:13:53,899 iteration 2650 : loss : 0.046717, loss_ce: 0.018681
2022-01-09 13:13:56,176 iteration 2651 : loss : 0.033276, loss_ce: 0.013581
2022-01-09 13:13:58,471 iteration 2652 : loss : 0.039415, loss_ce: 0.017049
 39%|██████████▌                | 156/400 [1:49:37<2:59:48, 44.21s/it]2022-01-09 13:14:00,811 iteration 2653 : loss : 0.043345, loss_ce: 0.016563
2022-01-09 13:14:03,056 iteration 2654 : loss : 0.030724, loss_ce: 0.014665
2022-01-09 13:14:05,334 iteration 2655 : loss : 0.040466, loss_ce: 0.016845
2022-01-09 13:14:07,660 iteration 2656 : loss : 0.031267, loss_ce: 0.015952
2022-01-09 13:14:10,014 iteration 2657 : loss : 0.033370, loss_ce: 0.014228
2022-01-09 13:14:12,360 iteration 2658 : loss : 0.065508, loss_ce: 0.023480
2022-01-09 13:14:14,666 iteration 2659 : loss : 0.038169, loss_ce: 0.013794
2022-01-09 13:14:17,012 iteration 2660 : loss : 0.035472, loss_ce: 0.015066
2022-01-09 13:14:19,303 iteration 2661 : loss : 0.039148, loss_ce: 0.014373
2022-01-09 13:14:21,681 iteration 2662 : loss : 0.031646, loss_ce: 0.010482
2022-01-09 13:14:24,009 iteration 2663 : loss : 0.056261, loss_ce: 0.021235
2022-01-09 13:14:26,234 iteration 2664 : loss : 0.041521, loss_ce: 0.014971
2022-01-09 13:14:28,504 iteration 2665 : loss : 0.023747, loss_ce: 0.010164
2022-01-09 13:14:31,101 iteration 2666 : loss : 0.068749, loss_ce: 0.028959
2022-01-09 13:14:33,477 iteration 2667 : loss : 0.033647, loss_ce: 0.013834
2022-01-09 13:14:35,888 iteration 2668 : loss : 0.049608, loss_ce: 0.023064
2022-01-09 13:14:38,182 iteration 2669 : loss : 0.045832, loss_ce: 0.014898
 39%|██████████▌                | 157/400 [1:50:17<2:53:36, 42.87s/it]2022-01-09 13:14:40,517 iteration 2670 : loss : 0.029017, loss_ce: 0.010965
2022-01-09 13:14:42,736 iteration 2671 : loss : 0.036624, loss_ce: 0.013858
2022-01-09 13:14:44,929 iteration 2672 : loss : 0.049267, loss_ce: 0.016850
2022-01-09 13:14:47,253 iteration 2673 : loss : 0.037767, loss_ce: 0.011124
2022-01-09 13:14:49,652 iteration 2674 : loss : 0.039872, loss_ce: 0.014149
2022-01-09 13:14:52,088 iteration 2675 : loss : 0.033016, loss_ce: 0.011092
2022-01-09 13:14:54,414 iteration 2676 : loss : 0.034842, loss_ce: 0.012054
2022-01-09 13:14:56,658 iteration 2677 : loss : 0.027856, loss_ce: 0.011584
2022-01-09 13:14:58,809 iteration 2678 : loss : 0.030828, loss_ce: 0.013740
2022-01-09 13:15:01,064 iteration 2679 : loss : 0.036668, loss_ce: 0.014432
2022-01-09 13:15:03,360 iteration 2680 : loss : 0.033921, loss_ce: 0.011710
2022-01-09 13:15:05,615 iteration 2681 : loss : 0.034558, loss_ce: 0.012551
2022-01-09 13:15:07,958 iteration 2682 : loss : 0.030041, loss_ce: 0.011449
2022-01-09 13:15:10,280 iteration 2683 : loss : 0.040885, loss_ce: 0.017961
2022-01-09 13:15:12,681 iteration 2684 : loss : 0.047901, loss_ce: 0.021588
2022-01-09 13:15:15,013 iteration 2685 : loss : 0.031861, loss_ce: 0.014003
2022-01-09 13:15:17,379 iteration 2686 : loss : 0.055734, loss_ce: 0.013606
 40%|██████████▋                | 158/400 [1:50:56<2:48:26, 41.76s/it]2022-01-09 13:15:19,689 iteration 2687 : loss : 0.039365, loss_ce: 0.016135
2022-01-09 13:15:21,931 iteration 2688 : loss : 0.039330, loss_ce: 0.014885
2022-01-09 13:15:24,260 iteration 2689 : loss : 0.057871, loss_ce: 0.019029
2022-01-09 13:15:26,595 iteration 2690 : loss : 0.075767, loss_ce: 0.019432
2022-01-09 13:15:28,801 iteration 2691 : loss : 0.040872, loss_ce: 0.015848
2022-01-09 13:15:31,059 iteration 2692 : loss : 0.051781, loss_ce: 0.025516
2022-01-09 13:15:33,346 iteration 2693 : loss : 0.028423, loss_ce: 0.011977
2022-01-09 13:15:35,665 iteration 2694 : loss : 0.045217, loss_ce: 0.021628
2022-01-09 13:15:38,035 iteration 2695 : loss : 0.048023, loss_ce: 0.024466
2022-01-09 13:15:40,371 iteration 2696 : loss : 0.032558, loss_ce: 0.014496
2022-01-09 13:15:42,705 iteration 2697 : loss : 0.044922, loss_ce: 0.021961
2022-01-09 13:15:45,116 iteration 2698 : loss : 0.037650, loss_ce: 0.010785
2022-01-09 13:15:47,509 iteration 2699 : loss : 0.039217, loss_ce: 0.018103
2022-01-09 13:15:49,804 iteration 2700 : loss : 0.039686, loss_ce: 0.013424
2022-01-09 13:15:52,176 iteration 2701 : loss : 0.062994, loss_ce: 0.023797
2022-01-09 13:15:54,404 iteration 2702 : loss : 0.046442, loss_ce: 0.025151
2022-01-09 13:15:56,709 iteration 2703 : loss : 0.039674, loss_ce: 0.015688
 40%|██████████▋                | 159/400 [1:51:35<2:44:49, 41.04s/it]2022-01-09 13:15:59,070 iteration 2704 : loss : 0.071926, loss_ce: 0.025470
2022-01-09 13:16:01,202 iteration 2705 : loss : 0.038088, loss_ce: 0.015908
2022-01-09 13:16:03,438 iteration 2706 : loss : 0.068291, loss_ce: 0.026612
2022-01-09 13:16:05,616 iteration 2707 : loss : 0.044480, loss_ce: 0.024004
2022-01-09 13:16:07,852 iteration 2708 : loss : 0.040788, loss_ce: 0.015162
2022-01-09 13:16:10,095 iteration 2709 : loss : 0.032283, loss_ce: 0.013827
2022-01-09 13:16:12,375 iteration 2710 : loss : 0.030636, loss_ce: 0.013451
2022-01-09 13:16:14,973 iteration 2711 : loss : 0.028939, loss_ce: 0.011109
2022-01-09 13:16:17,371 iteration 2712 : loss : 0.034320, loss_ce: 0.009972
2022-01-09 13:16:19,575 iteration 2713 : loss : 0.029324, loss_ce: 0.014708
2022-01-09 13:16:21,797 iteration 2714 : loss : 0.050046, loss_ce: 0.018461
2022-01-09 13:16:23,991 iteration 2715 : loss : 0.050605, loss_ce: 0.016336
2022-01-09 13:16:26,240 iteration 2716 : loss : 0.035509, loss_ce: 0.012311
2022-01-09 13:16:28,484 iteration 2717 : loss : 0.040727, loss_ce: 0.017090
2022-01-09 13:16:30,754 iteration 2718 : loss : 0.058229, loss_ce: 0.017973
2022-01-09 13:16:33,078 iteration 2719 : loss : 0.037562, loss_ce: 0.012935
2022-01-09 13:16:33,079 Training Data Eval:
2022-01-09 13:16:45,492   Average segmentation loss on training set: 0.0270
2022-01-09 13:16:45,493 Validation Data Eval:
2022-01-09 13:16:49,867   Average segmentation loss on validation set: 0.0878
2022-01-09 13:16:52,192 iteration 2720 : loss : 0.033244, loss_ce: 0.011454
 40%|██████████▊                | 160/400 [1:52:31<3:01:28, 45.37s/it]2022-01-09 13:16:54,585 iteration 2721 : loss : 0.039443, loss_ce: 0.017199
2022-01-09 13:16:56,943 iteration 2722 : loss : 0.041333, loss_ce: 0.016461
2022-01-09 13:16:59,365 iteration 2723 : loss : 0.040422, loss_ce: 0.016337
2022-01-09 13:17:01,690 iteration 2724 : loss : 0.054670, loss_ce: 0.015451
2022-01-09 13:17:03,934 iteration 2725 : loss : 0.041188, loss_ce: 0.014656
2022-01-09 13:17:06,333 iteration 2726 : loss : 0.064202, loss_ce: 0.020408
2022-01-09 13:17:08,581 iteration 2727 : loss : 0.053381, loss_ce: 0.023943
2022-01-09 13:17:10,809 iteration 2728 : loss : 0.037497, loss_ce: 0.014845
2022-01-09 13:17:13,085 iteration 2729 : loss : 0.043303, loss_ce: 0.019542
2022-01-09 13:17:15,326 iteration 2730 : loss : 0.031782, loss_ce: 0.011476
2022-01-09 13:17:17,641 iteration 2731 : loss : 0.034236, loss_ce: 0.014263
2022-01-09 13:17:19,976 iteration 2732 : loss : 0.049380, loss_ce: 0.020897
2022-01-09 13:17:22,316 iteration 2733 : loss : 0.032186, loss_ce: 0.011074
2022-01-09 13:17:24,618 iteration 2734 : loss : 0.053524, loss_ce: 0.017743
2022-01-09 13:17:26,983 iteration 2735 : loss : 0.036721, loss_ce: 0.010408
2022-01-09 13:17:29,325 iteration 2736 : loss : 0.027088, loss_ce: 0.012833
2022-01-09 13:17:31,659 iteration 2737 : loss : 0.040368, loss_ce: 0.014084
 40%|██████████▊                | 161/400 [1:53:10<2:53:39, 43.60s/it]2022-01-09 13:17:33,909 iteration 2738 : loss : 0.019674, loss_ce: 0.008222
2022-01-09 13:17:36,174 iteration 2739 : loss : 0.035324, loss_ce: 0.016185
2022-01-09 13:17:38,520 iteration 2740 : loss : 0.048699, loss_ce: 0.021103
2022-01-09 13:17:40,709 iteration 2741 : loss : 0.026820, loss_ce: 0.010148
2022-01-09 13:17:42,916 iteration 2742 : loss : 0.035925, loss_ce: 0.011524
2022-01-09 13:17:45,279 iteration 2743 : loss : 0.038550, loss_ce: 0.011831
2022-01-09 13:17:47,633 iteration 2744 : loss : 0.075206, loss_ce: 0.025584
2022-01-09 13:17:49,812 iteration 2745 : loss : 0.036740, loss_ce: 0.012013
2022-01-09 13:17:52,033 iteration 2746 : loss : 0.032136, loss_ce: 0.012036
2022-01-09 13:17:54,448 iteration 2747 : loss : 0.060307, loss_ce: 0.033084
2022-01-09 13:17:56,654 iteration 2748 : loss : 0.028754, loss_ce: 0.011394
2022-01-09 13:17:58,922 iteration 2749 : loss : 0.028802, loss_ce: 0.013338
2022-01-09 13:18:01,242 iteration 2750 : loss : 0.045542, loss_ce: 0.015462
2022-01-09 13:18:03,620 iteration 2751 : loss : 0.040183, loss_ce: 0.014803
2022-01-09 13:18:06,050 iteration 2752 : loss : 0.034922, loss_ce: 0.015642
2022-01-09 13:18:08,455 iteration 2753 : loss : 0.039039, loss_ce: 0.018583
2022-01-09 13:18:10,850 iteration 2754 : loss : 0.045923, loss_ce: 0.014795
 40%|██████████▉                | 162/400 [1:53:50<2:47:41, 42.28s/it]2022-01-09 13:18:13,217 iteration 2755 : loss : 0.026886, loss_ce: 0.009539
2022-01-09 13:18:15,502 iteration 2756 : loss : 0.031355, loss_ce: 0.013700
2022-01-09 13:18:17,776 iteration 2757 : loss : 0.029009, loss_ce: 0.012431
2022-01-09 13:18:20,111 iteration 2758 : loss : 0.031226, loss_ce: 0.013555
2022-01-09 13:18:22,365 iteration 2759 : loss : 0.031397, loss_ce: 0.012822
2022-01-09 13:18:24,715 iteration 2760 : loss : 0.054489, loss_ce: 0.012862
2022-01-09 13:18:27,066 iteration 2761 : loss : 0.030133, loss_ce: 0.011340
2022-01-09 13:18:29,364 iteration 2762 : loss : 0.034887, loss_ce: 0.014218
2022-01-09 13:18:31,690 iteration 2763 : loss : 0.030626, loss_ce: 0.012874
2022-01-09 13:18:33,963 iteration 2764 : loss : 0.025205, loss_ce: 0.010760
2022-01-09 13:18:36,373 iteration 2765 : loss : 0.044345, loss_ce: 0.021497
2022-01-09 13:18:38,788 iteration 2766 : loss : 0.031310, loss_ce: 0.011372
2022-01-09 13:18:41,106 iteration 2767 : loss : 0.026790, loss_ce: 0.008115
2022-01-09 13:18:43,586 iteration 2768 : loss : 0.032938, loss_ce: 0.012989
2022-01-09 13:18:45,903 iteration 2769 : loss : 0.026689, loss_ce: 0.009314
2022-01-09 13:18:48,244 iteration 2770 : loss : 0.027247, loss_ce: 0.013335
2022-01-09 13:18:50,610 iteration 2771 : loss : 0.032460, loss_ce: 0.017771
 41%|███████████                | 163/400 [1:54:29<2:44:00, 41.52s/it]2022-01-09 13:18:53,017 iteration 2772 : loss : 0.035790, loss_ce: 0.012468
2022-01-09 13:18:55,261 iteration 2773 : loss : 0.031469, loss_ce: 0.011126
2022-01-09 13:18:57,580 iteration 2774 : loss : 0.025490, loss_ce: 0.011244
2022-01-09 13:18:59,967 iteration 2775 : loss : 0.045148, loss_ce: 0.020962
2022-01-09 13:19:02,354 iteration 2776 : loss : 0.040592, loss_ce: 0.021486
2022-01-09 13:19:04,832 iteration 2777 : loss : 0.048711, loss_ce: 0.019166
2022-01-09 13:19:07,209 iteration 2778 : loss : 0.025536, loss_ce: 0.010962
2022-01-09 13:19:09,628 iteration 2779 : loss : 0.034754, loss_ce: 0.015167
2022-01-09 13:19:12,026 iteration 2780 : loss : 0.038060, loss_ce: 0.014513
2022-01-09 13:19:14,292 iteration 2781 : loss : 0.027318, loss_ce: 0.010949
2022-01-09 13:19:16,683 iteration 2782 : loss : 0.028957, loss_ce: 0.011418
2022-01-09 13:19:19,114 iteration 2783 : loss : 0.040547, loss_ce: 0.014839
2022-01-09 13:19:21,616 iteration 2784 : loss : 0.036727, loss_ce: 0.017809
2022-01-09 13:19:23,945 iteration 2785 : loss : 0.025527, loss_ce: 0.009855
2022-01-09 13:19:26,344 iteration 2786 : loss : 0.073188, loss_ce: 0.023622
2022-01-09 13:19:28,743 iteration 2787 : loss : 0.054221, loss_ce: 0.016853
2022-01-09 13:19:31,119 iteration 2788 : loss : 0.036719, loss_ce: 0.011920
 41%|███████████                | 164/400 [1:55:10<2:42:06, 41.21s/it]2022-01-09 13:19:33,553 iteration 2789 : loss : 0.031270, loss_ce: 0.015096
2022-01-09 13:19:36,118 iteration 2790 : loss : 0.030859, loss_ce: 0.008671
2022-01-09 13:19:38,551 iteration 2791 : loss : 0.038970, loss_ce: 0.013121
2022-01-09 13:19:41,003 iteration 2792 : loss : 0.040198, loss_ce: 0.010974
2022-01-09 13:19:43,428 iteration 2793 : loss : 0.055990, loss_ce: 0.024484
2022-01-09 13:19:45,878 iteration 2794 : loss : 0.039599, loss_ce: 0.018959
2022-01-09 13:19:48,344 iteration 2795 : loss : 0.033326, loss_ce: 0.012903
2022-01-09 13:19:51,030 iteration 2796 : loss : 0.043256, loss_ce: 0.016779
2022-01-09 13:19:53,443 iteration 2797 : loss : 0.029220, loss_ce: 0.011531
2022-01-09 13:19:55,797 iteration 2798 : loss : 0.049046, loss_ce: 0.017158
2022-01-09 13:19:58,077 iteration 2799 : loss : 0.045305, loss_ce: 0.016161
2022-01-09 13:20:00,296 iteration 2800 : loss : 0.024238, loss_ce: 0.010954
2022-01-09 13:20:02,549 iteration 2801 : loss : 0.029523, loss_ce: 0.012939
2022-01-09 13:20:04,796 iteration 2802 : loss : 0.026385, loss_ce: 0.009940
2022-01-09 13:20:07,240 iteration 2803 : loss : 0.036384, loss_ce: 0.013348
2022-01-09 13:20:09,598 iteration 2804 : loss : 0.052069, loss_ce: 0.021857
2022-01-09 13:20:09,599 Training Data Eval:
2022-01-09 13:20:22,379   Average segmentation loss on training set: 0.0263
2022-01-09 13:20:22,380 Validation Data Eval:
2022-01-09 13:20:26,949   Average segmentation loss on validation set: 0.0664
2022-01-09 13:20:29,332 iteration 2805 : loss : 0.035381, loss_ce: 0.012624
 41%|███████████▏               | 165/400 [1:56:08<3:01:24, 46.32s/it]2022-01-09 13:20:31,793 iteration 2806 : loss : 0.059169, loss_ce: 0.019206
2022-01-09 13:20:34,290 iteration 2807 : loss : 0.046658, loss_ce: 0.020231
2022-01-09 13:20:36,582 iteration 2808 : loss : 0.031276, loss_ce: 0.016354
2022-01-09 13:20:38,917 iteration 2809 : loss : 0.055634, loss_ce: 0.027586
2022-01-09 13:20:41,261 iteration 2810 : loss : 0.033500, loss_ce: 0.012771
2022-01-09 13:20:43,612 iteration 2811 : loss : 0.027211, loss_ce: 0.010796
2022-01-09 13:20:46,022 iteration 2812 : loss : 0.039838, loss_ce: 0.015548
2022-01-09 13:20:48,445 iteration 2813 : loss : 0.037600, loss_ce: 0.012448
2022-01-09 13:20:50,802 iteration 2814 : loss : 0.038723, loss_ce: 0.015116
2022-01-09 13:20:53,106 iteration 2815 : loss : 0.028830, loss_ce: 0.013418
2022-01-09 13:20:55,522 iteration 2816 : loss : 0.030201, loss_ce: 0.013045
2022-01-09 13:20:57,871 iteration 2817 : loss : 0.025617, loss_ce: 0.008319
2022-01-09 13:21:00,248 iteration 2818 : loss : 0.052408, loss_ce: 0.012912
2022-01-09 13:21:02,750 iteration 2819 : loss : 0.034717, loss_ce: 0.016225
2022-01-09 13:21:05,258 iteration 2820 : loss : 0.040690, loss_ce: 0.016418
2022-01-09 13:21:07,617 iteration 2821 : loss : 0.033470, loss_ce: 0.014111
2022-01-09 13:21:09,904 iteration 2822 : loss : 0.025164, loss_ce: 0.008497
 42%|███████████▏               | 166/400 [1:56:49<2:53:53, 44.59s/it]2022-01-09 13:21:12,452 iteration 2823 : loss : 0.036054, loss_ce: 0.013394
2022-01-09 13:21:14,822 iteration 2824 : loss : 0.026524, loss_ce: 0.010504
2022-01-09 13:21:17,230 iteration 2825 : loss : 0.031618, loss_ce: 0.012640
2022-01-09 13:21:19,551 iteration 2826 : loss : 0.026182, loss_ce: 0.010944
2022-01-09 13:21:21,967 iteration 2827 : loss : 0.037658, loss_ce: 0.017561
2022-01-09 13:21:24,281 iteration 2828 : loss : 0.032697, loss_ce: 0.014823
2022-01-09 13:21:26,710 iteration 2829 : loss : 0.040253, loss_ce: 0.015395
2022-01-09 13:21:28,951 iteration 2830 : loss : 0.026235, loss_ce: 0.011654
2022-01-09 13:21:31,537 iteration 2831 : loss : 0.036169, loss_ce: 0.016795
2022-01-09 13:21:34,002 iteration 2832 : loss : 0.039761, loss_ce: 0.013775
2022-01-09 13:21:36,427 iteration 2833 : loss : 0.043948, loss_ce: 0.018417
2022-01-09 13:21:38,799 iteration 2834 : loss : 0.068740, loss_ce: 0.026481
2022-01-09 13:21:41,193 iteration 2835 : loss : 0.078104, loss_ce: 0.026183
2022-01-09 13:21:43,530 iteration 2836 : loss : 0.034170, loss_ce: 0.014506
2022-01-09 13:21:45,812 iteration 2837 : loss : 0.037854, loss_ce: 0.011240
2022-01-09 13:21:48,105 iteration 2838 : loss : 0.027825, loss_ce: 0.008687
2022-01-09 13:21:50,533 iteration 2839 : loss : 0.034849, loss_ce: 0.013141
 42%|███████████▎               | 167/400 [1:57:29<2:48:33, 43.40s/it]2022-01-09 13:21:52,966 iteration 2840 : loss : 0.058081, loss_ce: 0.034878
2022-01-09 13:21:55,383 iteration 2841 : loss : 0.048059, loss_ce: 0.017647
2022-01-09 13:21:57,873 iteration 2842 : loss : 0.043145, loss_ce: 0.014131
2022-01-09 13:22:00,253 iteration 2843 : loss : 0.033969, loss_ce: 0.013335
2022-01-09 13:22:02,581 iteration 2844 : loss : 0.023332, loss_ce: 0.009160
2022-01-09 13:22:04,934 iteration 2845 : loss : 0.056327, loss_ce: 0.026041
2022-01-09 13:22:07,355 iteration 2846 : loss : 0.051910, loss_ce: 0.015812
2022-01-09 13:22:09,753 iteration 2847 : loss : 0.054110, loss_ce: 0.020871
2022-01-09 13:22:12,118 iteration 2848 : loss : 0.050126, loss_ce: 0.018505
2022-01-09 13:22:14,491 iteration 2849 : loss : 0.033045, loss_ce: 0.013596
2022-01-09 13:22:16,995 iteration 2850 : loss : 0.034796, loss_ce: 0.019039
2022-01-09 13:22:19,476 iteration 2851 : loss : 0.030625, loss_ce: 0.013979
2022-01-09 13:22:21,751 iteration 2852 : loss : 0.039225, loss_ce: 0.013246
2022-01-09 13:22:24,132 iteration 2853 : loss : 0.054519, loss_ce: 0.016026
2022-01-09 13:22:26,473 iteration 2854 : loss : 0.034905, loss_ce: 0.011615
2022-01-09 13:22:28,986 iteration 2855 : loss : 0.039668, loss_ce: 0.017414
2022-01-09 13:22:31,309 iteration 2856 : loss : 0.023099, loss_ce: 0.011290
 42%|███████████▎               | 168/400 [1:58:10<2:44:47, 42.62s/it]2022-01-09 13:22:33,746 iteration 2857 : loss : 0.059282, loss_ce: 0.028936
2022-01-09 13:22:36,223 iteration 2858 : loss : 0.049784, loss_ce: 0.016747
2022-01-09 13:22:38,621 iteration 2859 : loss : 0.042542, loss_ce: 0.015919
2022-01-09 13:22:40,956 iteration 2860 : loss : 0.043730, loss_ce: 0.018012
2022-01-09 13:22:43,321 iteration 2861 : loss : 0.051207, loss_ce: 0.014238
2022-01-09 13:22:45,796 iteration 2862 : loss : 0.059694, loss_ce: 0.013424
2022-01-09 13:22:48,147 iteration 2863 : loss : 0.031050, loss_ce: 0.012487
2022-01-09 13:22:50,523 iteration 2864 : loss : 0.032945, loss_ce: 0.011342
2022-01-09 13:22:52,916 iteration 2865 : loss : 0.026805, loss_ce: 0.010427
2022-01-09 13:22:55,324 iteration 2866 : loss : 0.024554, loss_ce: 0.008125
2022-01-09 13:22:57,775 iteration 2867 : loss : 0.047481, loss_ce: 0.017820
2022-01-09 13:23:00,173 iteration 2868 : loss : 0.047307, loss_ce: 0.019200
2022-01-09 13:23:02,571 iteration 2869 : loss : 0.037171, loss_ce: 0.014553
2022-01-09 13:23:04,939 iteration 2870 : loss : 0.038876, loss_ce: 0.013351
2022-01-09 13:23:07,205 iteration 2871 : loss : 0.053049, loss_ce: 0.030113
2022-01-09 13:23:09,722 iteration 2872 : loss : 0.028268, loss_ce: 0.012946
2022-01-09 13:23:12,130 iteration 2873 : loss : 0.030617, loss_ce: 0.013243
 42%|███████████▍               | 169/400 [1:58:51<2:42:00, 42.08s/it]2022-01-09 13:23:14,548 iteration 2874 : loss : 0.035547, loss_ce: 0.013033
2022-01-09 13:23:16,951 iteration 2875 : loss : 0.035276, loss_ce: 0.013988
2022-01-09 13:23:19,246 iteration 2876 : loss : 0.069579, loss_ce: 0.035039
2022-01-09 13:23:21,522 iteration 2877 : loss : 0.031689, loss_ce: 0.011253
2022-01-09 13:23:23,854 iteration 2878 : loss : 0.037424, loss_ce: 0.012595
2022-01-09 13:23:26,227 iteration 2879 : loss : 0.039039, loss_ce: 0.021261
2022-01-09 13:23:28,641 iteration 2880 : loss : 0.028871, loss_ce: 0.015068
2022-01-09 13:23:30,983 iteration 2881 : loss : 0.030150, loss_ce: 0.014656
2022-01-09 13:23:33,328 iteration 2882 : loss : 0.055302, loss_ce: 0.019161
2022-01-09 13:23:35,698 iteration 2883 : loss : 0.040786, loss_ce: 0.013447
2022-01-09 13:23:38,094 iteration 2884 : loss : 0.060130, loss_ce: 0.027951
2022-01-09 13:23:40,403 iteration 2885 : loss : 0.032105, loss_ce: 0.010779
2022-01-09 13:23:42,674 iteration 2886 : loss : 0.033955, loss_ce: 0.011213
2022-01-09 13:23:44,972 iteration 2887 : loss : 0.042235, loss_ce: 0.015361
2022-01-09 13:23:47,320 iteration 2888 : loss : 0.039160, loss_ce: 0.019686
2022-01-09 13:23:49,639 iteration 2889 : loss : 0.032372, loss_ce: 0.013677
2022-01-09 13:23:49,639 Training Data Eval:
2022-01-09 13:24:02,284   Average segmentation loss on training set: 0.0265
2022-01-09 13:24:02,284 Validation Data Eval:
2022-01-09 13:24:06,672   Average segmentation loss on validation set: 0.1600
2022-01-09 13:24:09,026 iteration 2890 : loss : 0.046889, loss_ce: 0.026146
 42%|███████████▍               | 170/400 [1:59:48<2:58:19, 46.52s/it]2022-01-09 13:24:11,422 iteration 2891 : loss : 0.032498, loss_ce: 0.017024
2022-01-09 13:24:13,797 iteration 2892 : loss : 0.031966, loss_ce: 0.013383
2022-01-09 13:24:16,136 iteration 2893 : loss : 0.025457, loss_ce: 0.010039
2022-01-09 13:24:18,485 iteration 2894 : loss : 0.024620, loss_ce: 0.010025
2022-01-09 13:24:20,884 iteration 2895 : loss : 0.032137, loss_ce: 0.011066
2022-01-09 13:24:23,274 iteration 2896 : loss : 0.042013, loss_ce: 0.014732
2022-01-09 13:24:25,728 iteration 2897 : loss : 0.089129, loss_ce: 0.029151
2022-01-09 13:24:28,034 iteration 2898 : loss : 0.049423, loss_ce: 0.017464
2022-01-09 13:24:30,307 iteration 2899 : loss : 0.038173, loss_ce: 0.017615
2022-01-09 13:24:32,694 iteration 2900 : loss : 0.057981, loss_ce: 0.024069
2022-01-09 13:24:34,977 iteration 2901 : loss : 0.033702, loss_ce: 0.013223
2022-01-09 13:24:37,304 iteration 2902 : loss : 0.047625, loss_ce: 0.024057
2022-01-09 13:24:39,634 iteration 2903 : loss : 0.040059, loss_ce: 0.011415
2022-01-09 13:24:42,005 iteration 2904 : loss : 0.034545, loss_ce: 0.014844
2022-01-09 13:24:44,349 iteration 2905 : loss : 0.036772, loss_ce: 0.016991
2022-01-09 13:24:46,664 iteration 2906 : loss : 0.036713, loss_ce: 0.014644
2022-01-09 13:24:49,048 iteration 2907 : loss : 0.033046, loss_ce: 0.012543
 43%|███████████▌               | 171/400 [2:00:28<2:50:05, 44.57s/it]2022-01-09 13:24:51,460 iteration 2908 : loss : 0.027760, loss_ce: 0.010874
2022-01-09 13:24:53,778 iteration 2909 : loss : 0.048965, loss_ce: 0.019327
2022-01-09 13:24:56,186 iteration 2910 : loss : 0.026135, loss_ce: 0.010322
2022-01-09 13:24:58,547 iteration 2911 : loss : 0.035119, loss_ce: 0.014424
2022-01-09 13:25:00,763 iteration 2912 : loss : 0.024231, loss_ce: 0.009619
2022-01-09 13:25:02,990 iteration 2913 : loss : 0.027834, loss_ce: 0.009793
2022-01-09 13:25:05,215 iteration 2914 : loss : 0.036282, loss_ce: 0.015539
2022-01-09 13:25:07,497 iteration 2915 : loss : 0.048027, loss_ce: 0.029016
2022-01-09 13:25:09,849 iteration 2916 : loss : 0.038388, loss_ce: 0.015100
2022-01-09 13:25:12,145 iteration 2917 : loss : 0.037699, loss_ce: 0.014901
2022-01-09 13:25:14,413 iteration 2918 : loss : 0.027342, loss_ce: 0.013135
2022-01-09 13:25:16,713 iteration 2919 : loss : 0.046985, loss_ce: 0.012914
2022-01-09 13:25:18,950 iteration 2920 : loss : 0.028831, loss_ce: 0.011611
2022-01-09 13:25:21,169 iteration 2921 : loss : 0.027883, loss_ce: 0.012921
2022-01-09 13:25:23,363 iteration 2922 : loss : 0.042002, loss_ce: 0.016434
2022-01-09 13:25:25,650 iteration 2923 : loss : 0.053728, loss_ce: 0.020683
2022-01-09 13:25:27,829 iteration 2924 : loss : 0.032087, loss_ce: 0.013769
 43%|███████████▌               | 172/400 [2:01:07<2:42:46, 42.83s/it]2022-01-09 13:25:30,043 iteration 2925 : loss : 0.038611, loss_ce: 0.017878
2022-01-09 13:25:32,230 iteration 2926 : loss : 0.028249, loss_ce: 0.010906
2022-01-09 13:25:34,533 iteration 2927 : loss : 0.025413, loss_ce: 0.009108
2022-01-09 13:25:36,820 iteration 2928 : loss : 0.029333, loss_ce: 0.010655
2022-01-09 13:25:39,085 iteration 2929 : loss : 0.030410, loss_ce: 0.008571
2022-01-09 13:25:41,373 iteration 2930 : loss : 0.026249, loss_ce: 0.011548
2022-01-09 13:25:43,654 iteration 2931 : loss : 0.063932, loss_ce: 0.012137
2022-01-09 13:25:45,957 iteration 2932 : loss : 0.048864, loss_ce: 0.021734
2022-01-09 13:25:48,181 iteration 2933 : loss : 0.044622, loss_ce: 0.017098
2022-01-09 13:25:50,450 iteration 2934 : loss : 0.028279, loss_ce: 0.013566
2022-01-09 13:25:52,629 iteration 2935 : loss : 0.035213, loss_ce: 0.011623
2022-01-09 13:25:54,898 iteration 2936 : loss : 0.034764, loss_ce: 0.016782
2022-01-09 13:25:57,264 iteration 2937 : loss : 0.032048, loss_ce: 0.014562
2022-01-09 13:25:59,598 iteration 2938 : loss : 0.047373, loss_ce: 0.017627
2022-01-09 13:26:01,815 iteration 2939 : loss : 0.036978, loss_ce: 0.010368
2022-01-09 13:26:04,178 iteration 2940 : loss : 0.036793, loss_ce: 0.015444
2022-01-09 13:26:06,460 iteration 2941 : loss : 0.037918, loss_ce: 0.015614
 43%|███████████▋               | 173/400 [2:01:45<2:37:16, 41.57s/it]2022-01-09 13:26:08,933 iteration 2942 : loss : 0.065611, loss_ce: 0.033072
2022-01-09 13:26:11,327 iteration 2943 : loss : 0.031162, loss_ce: 0.013916
2022-01-09 13:26:13,636 iteration 2944 : loss : 0.056262, loss_ce: 0.021912
2022-01-09 13:26:15,892 iteration 2945 : loss : 0.037973, loss_ce: 0.017374
2022-01-09 13:26:18,181 iteration 2946 : loss : 0.031654, loss_ce: 0.015443
2022-01-09 13:26:20,442 iteration 2947 : loss : 0.033928, loss_ce: 0.013089
2022-01-09 13:26:22,834 iteration 2948 : loss : 0.026590, loss_ce: 0.010254
2022-01-09 13:26:25,173 iteration 2949 : loss : 0.038419, loss_ce: 0.014212
2022-01-09 13:26:27,475 iteration 2950 : loss : 0.024971, loss_ce: 0.010262
2022-01-09 13:26:29,850 iteration 2951 : loss : 0.029815, loss_ce: 0.009844
2022-01-09 13:26:32,116 iteration 2952 : loss : 0.089718, loss_ce: 0.019912
2022-01-09 13:26:34,525 iteration 2953 : loss : 0.045214, loss_ce: 0.020209
2022-01-09 13:26:36,826 iteration 2954 : loss : 0.035512, loss_ce: 0.014356
2022-01-09 13:26:39,130 iteration 2955 : loss : 0.034541, loss_ce: 0.008664
2022-01-09 13:26:41,377 iteration 2956 : loss : 0.044177, loss_ce: 0.025172
2022-01-09 13:26:43,655 iteration 2957 : loss : 0.035376, loss_ce: 0.013703
2022-01-09 13:26:45,947 iteration 2958 : loss : 0.052481, loss_ce: 0.022689
 44%|███████████▋               | 174/400 [2:02:25<2:34:14, 40.95s/it]2022-01-09 13:26:48,407 iteration 2959 : loss : 0.034413, loss_ce: 0.017396
2022-01-09 13:26:50,759 iteration 2960 : loss : 0.043946, loss_ce: 0.021909
2022-01-09 13:26:53,192 iteration 2961 : loss : 0.049313, loss_ce: 0.023588
2022-01-09 13:26:55,611 iteration 2962 : loss : 0.030529, loss_ce: 0.012436
2022-01-09 13:26:57,922 iteration 2963 : loss : 0.037006, loss_ce: 0.014810
2022-01-09 13:27:00,220 iteration 2964 : loss : 0.038239, loss_ce: 0.014466
2022-01-09 13:27:02,562 iteration 2965 : loss : 0.054262, loss_ce: 0.018532
2022-01-09 13:27:04,892 iteration 2966 : loss : 0.032385, loss_ce: 0.012437
2022-01-09 13:27:07,285 iteration 2967 : loss : 0.032218, loss_ce: 0.015290
2022-01-09 13:27:09,784 iteration 2968 : loss : 0.062056, loss_ce: 0.017612
2022-01-09 13:27:12,169 iteration 2969 : loss : 0.026701, loss_ce: 0.010848
2022-01-09 13:27:14,393 iteration 2970 : loss : 0.033606, loss_ce: 0.011289
2022-01-09 13:27:16,540 iteration 2971 : loss : 0.033728, loss_ce: 0.015045
2022-01-09 13:27:18,740 iteration 2972 : loss : 0.053035, loss_ce: 0.020568
2022-01-09 13:27:20,811 iteration 2973 : loss : 0.039121, loss_ce: 0.017436
2022-01-09 13:27:23,027 iteration 2974 : loss : 0.024355, loss_ce: 0.008515
2022-01-09 13:27:23,027 Training Data Eval:
2022-01-09 13:27:35,183   Average segmentation loss on training set: 0.0233
2022-01-09 13:27:35,183 Validation Data Eval:
2022-01-09 13:27:39,436   Average segmentation loss on validation set: 0.0687
2022-01-09 13:27:41,843 iteration 2975 : loss : 0.036712, loss_ce: 0.011141
 44%|███████████▊               | 175/400 [2:03:21<2:50:22, 45.43s/it]2022-01-09 13:27:44,224 iteration 2976 : loss : 0.042837, loss_ce: 0.019982
2022-01-09 13:27:46,397 iteration 2977 : loss : 0.033121, loss_ce: 0.013403
2022-01-09 13:27:48,688 iteration 2978 : loss : 0.031753, loss_ce: 0.012623
2022-01-09 13:27:51,054 iteration 2979 : loss : 0.041394, loss_ce: 0.017163
2022-01-09 13:27:53,411 iteration 2980 : loss : 0.027124, loss_ce: 0.011570
2022-01-09 13:27:55,684 iteration 2981 : loss : 0.045663, loss_ce: 0.014321
2022-01-09 13:27:57,953 iteration 2982 : loss : 0.033062, loss_ce: 0.015056
2022-01-09 13:28:00,176 iteration 2983 : loss : 0.049701, loss_ce: 0.021591
2022-01-09 13:28:02,512 iteration 2984 : loss : 0.028504, loss_ce: 0.011641
2022-01-09 13:28:04,808 iteration 2985 : loss : 0.038300, loss_ce: 0.011821
2022-01-09 13:28:07,159 iteration 2986 : loss : 0.042119, loss_ce: 0.015379
2022-01-09 13:28:09,385 iteration 2987 : loss : 0.037202, loss_ce: 0.018813
2022-01-09 13:28:11,691 iteration 2988 : loss : 0.023991, loss_ce: 0.008200
2022-01-09 13:28:14,159 iteration 2989 : loss : 0.028970, loss_ce: 0.007795
2022-01-09 13:28:16,564 iteration 2990 : loss : 0.043253, loss_ce: 0.015551
2022-01-09 13:28:18,934 iteration 2991 : loss : 0.030695, loss_ce: 0.010716
2022-01-09 13:28:21,262 iteration 2992 : loss : 0.028839, loss_ce: 0.011441
 44%|███████████▉               | 176/400 [2:04:00<2:42:53, 43.63s/it]2022-01-09 13:28:23,559 iteration 2993 : loss : 0.038050, loss_ce: 0.008860
2022-01-09 13:28:25,892 iteration 2994 : loss : 0.033346, loss_ce: 0.014615
2022-01-09 13:28:28,237 iteration 2995 : loss : 0.037046, loss_ce: 0.017481
2022-01-09 13:28:30,470 iteration 2996 : loss : 0.024203, loss_ce: 0.009050
2022-01-09 13:28:32,758 iteration 2997 : loss : 0.029508, loss_ce: 0.010624
2022-01-09 13:28:35,028 iteration 2998 : loss : 0.024674, loss_ce: 0.008026
2022-01-09 13:28:37,299 iteration 2999 : loss : 0.034352, loss_ce: 0.011668
2022-01-09 13:28:39,507 iteration 3000 : loss : 0.036215, loss_ce: 0.011989
2022-01-09 13:28:41,687 iteration 3001 : loss : 0.022086, loss_ce: 0.008698
2022-01-09 13:28:43,787 iteration 3002 : loss : 0.029197, loss_ce: 0.012070
2022-01-09 13:28:46,005 iteration 3003 : loss : 0.031439, loss_ce: 0.011667
2022-01-09 13:28:48,119 iteration 3004 : loss : 0.026769, loss_ce: 0.011262
2022-01-09 13:28:50,335 iteration 3005 : loss : 0.042397, loss_ce: 0.013395
2022-01-09 13:28:52,582 iteration 3006 : loss : 0.028206, loss_ce: 0.010089
2022-01-09 13:28:54,772 iteration 3007 : loss : 0.022602, loss_ce: 0.008934
2022-01-09 13:28:57,052 iteration 3008 : loss : 0.042095, loss_ce: 0.018838
2022-01-09 13:28:59,301 iteration 3009 : loss : 0.027851, loss_ce: 0.014762
 44%|███████████▉               | 177/400 [2:04:38<2:35:55, 41.95s/it]2022-01-09 13:29:01,580 iteration 3010 : loss : 0.024004, loss_ce: 0.009158
2022-01-09 13:29:03,822 iteration 3011 : loss : 0.032215, loss_ce: 0.011150
2022-01-09 13:29:06,051 iteration 3012 : loss : 0.024634, loss_ce: 0.008263
2022-01-09 13:29:08,356 iteration 3013 : loss : 0.025462, loss_ce: 0.013199
2022-01-09 13:29:10,771 iteration 3014 : loss : 0.032858, loss_ce: 0.012902
2022-01-09 13:29:13,167 iteration 3015 : loss : 0.030478, loss_ce: 0.013498
2022-01-09 13:29:15,447 iteration 3016 : loss : 0.033743, loss_ce: 0.013768
2022-01-09 13:29:17,659 iteration 3017 : loss : 0.037328, loss_ce: 0.010084
2022-01-09 13:29:19,854 iteration 3018 : loss : 0.020891, loss_ce: 0.005736
2022-01-09 13:29:22,052 iteration 3019 : loss : 0.030580, loss_ce: 0.012664
2022-01-09 13:29:24,217 iteration 3020 : loss : 0.024777, loss_ce: 0.012594
2022-01-09 13:29:26,392 iteration 3021 : loss : 0.025025, loss_ce: 0.008628
2022-01-09 13:29:28,652 iteration 3022 : loss : 0.033483, loss_ce: 0.010371
2022-01-09 13:29:30,884 iteration 3023 : loss : 0.025420, loss_ce: 0.012652
2022-01-09 13:29:33,140 iteration 3024 : loss : 0.034297, loss_ce: 0.012566
2022-01-09 13:29:35,373 iteration 3025 : loss : 0.025943, loss_ce: 0.010934
2022-01-09 13:29:37,724 iteration 3026 : loss : 0.029920, loss_ce: 0.013993
 44%|████████████               | 178/400 [2:05:16<2:31:18, 40.90s/it]2022-01-09 13:29:40,174 iteration 3027 : loss : 0.027057, loss_ce: 0.012968
2022-01-09 13:29:42,578 iteration 3028 : loss : 0.027852, loss_ce: 0.012314
2022-01-09 13:29:44,956 iteration 3029 : loss : 0.047678, loss_ce: 0.022392
2022-01-09 13:29:47,392 iteration 3030 : loss : 0.033032, loss_ce: 0.011008
2022-01-09 13:29:49,599 iteration 3031 : loss : 0.022432, loss_ce: 0.008694
2022-01-09 13:29:51,960 iteration 3032 : loss : 0.033694, loss_ce: 0.013173
2022-01-09 13:29:54,353 iteration 3033 : loss : 0.031194, loss_ce: 0.014663
2022-01-09 13:29:56,675 iteration 3034 : loss : 0.029781, loss_ce: 0.011064
2022-01-09 13:29:59,043 iteration 3035 : loss : 0.037509, loss_ce: 0.012455
2022-01-09 13:30:01,307 iteration 3036 : loss : 0.022040, loss_ce: 0.009095
2022-01-09 13:30:03,656 iteration 3037 : loss : 0.030876, loss_ce: 0.010485
2022-01-09 13:30:05,839 iteration 3038 : loss : 0.021949, loss_ce: 0.005065
2022-01-09 13:30:08,282 iteration 3039 : loss : 0.065833, loss_ce: 0.022126
2022-01-09 13:30:10,582 iteration 3040 : loss : 0.024674, loss_ce: 0.011117
2022-01-09 13:30:12,924 iteration 3041 : loss : 0.036109, loss_ce: 0.014098
2022-01-09 13:30:15,278 iteration 3042 : loss : 0.028130, loss_ce: 0.011895
2022-01-09 13:30:17,733 iteration 3043 : loss : 0.023834, loss_ce: 0.009015
 45%|████████████               | 179/400 [2:05:56<2:29:38, 40.63s/it]2022-01-09 13:30:20,113 iteration 3044 : loss : 0.042219, loss_ce: 0.018451
2022-01-09 13:30:22,436 iteration 3045 : loss : 0.022922, loss_ce: 0.010087
2022-01-09 13:30:24,769 iteration 3046 : loss : 0.031226, loss_ce: 0.012476
2022-01-09 13:30:27,183 iteration 3047 : loss : 0.026971, loss_ce: 0.011686
2022-01-09 13:30:29,478 iteration 3048 : loss : 0.049884, loss_ce: 0.024320
2022-01-09 13:30:31,771 iteration 3049 : loss : 0.028604, loss_ce: 0.012378
2022-01-09 13:30:34,209 iteration 3050 : loss : 0.028878, loss_ce: 0.012912
2022-01-09 13:30:36,536 iteration 3051 : loss : 0.054338, loss_ce: 0.012807
2022-01-09 13:30:38,849 iteration 3052 : loss : 0.046343, loss_ce: 0.017858
2022-01-09 13:30:41,069 iteration 3053 : loss : 0.031394, loss_ce: 0.014999
2022-01-09 13:30:43,426 iteration 3054 : loss : 0.048525, loss_ce: 0.017728
2022-01-09 13:30:45,834 iteration 3055 : loss : 0.033809, loss_ce: 0.015820
2022-01-09 13:30:48,182 iteration 3056 : loss : 0.035887, loss_ce: 0.011294
2022-01-09 13:30:50,489 iteration 3057 : loss : 0.021976, loss_ce: 0.007573
2022-01-09 13:30:52,911 iteration 3058 : loss : 0.060808, loss_ce: 0.018975
2022-01-09 13:30:55,302 iteration 3059 : loss : 0.063685, loss_ce: 0.026312
2022-01-09 13:30:55,302 Training Data Eval:
2022-01-09 13:31:08,018   Average segmentation loss on training set: 0.0226
2022-01-09 13:31:08,019 Validation Data Eval:
2022-01-09 13:31:12,572   Average segmentation loss on validation set: 0.0691
2022-01-09 13:31:14,945 iteration 3060 : loss : 0.043103, loss_ce: 0.015967
 45%|████████████▏              | 180/400 [2:06:54<2:47:13, 45.61s/it]2022-01-09 13:31:17,333 iteration 3061 : loss : 0.036957, loss_ce: 0.013511
2022-01-09 13:31:19,752 iteration 3062 : loss : 0.045868, loss_ce: 0.014378
2022-01-09 13:31:22,036 iteration 3063 : loss : 0.034131, loss_ce: 0.011026
2022-01-09 13:31:24,458 iteration 3064 : loss : 0.032095, loss_ce: 0.015983
2022-01-09 13:31:26,847 iteration 3065 : loss : 0.045638, loss_ce: 0.011839
2022-01-09 13:31:29,216 iteration 3066 : loss : 0.027770, loss_ce: 0.007634
2022-01-09 13:31:31,636 iteration 3067 : loss : 0.030204, loss_ce: 0.013819
2022-01-09 13:31:34,098 iteration 3068 : loss : 0.024030, loss_ce: 0.008323
2022-01-09 13:31:36,516 iteration 3069 : loss : 0.048517, loss_ce: 0.012762
2022-01-09 13:31:38,834 iteration 3070 : loss : 0.029065, loss_ce: 0.010739
2022-01-09 13:31:41,205 iteration 3071 : loss : 0.034500, loss_ce: 0.016504
2022-01-09 13:31:43,523 iteration 3072 : loss : 0.025582, loss_ce: 0.010390
2022-01-09 13:31:45,703 iteration 3073 : loss : 0.056995, loss_ce: 0.022646
2022-01-09 13:31:48,044 iteration 3074 : loss : 0.045441, loss_ce: 0.021868
2022-01-09 13:31:50,454 iteration 3075 : loss : 0.029899, loss_ce: 0.010307
2022-01-09 13:31:52,710 iteration 3076 : loss : 0.036005, loss_ce: 0.017072
2022-01-09 13:31:55,113 iteration 3077 : loss : 0.041453, loss_ce: 0.019661
 45%|████████████▏              | 181/400 [2:07:34<2:40:30, 43.97s/it]2022-01-09 13:31:57,585 iteration 3078 : loss : 0.018769, loss_ce: 0.007947
2022-01-09 13:32:00,024 iteration 3079 : loss : 0.046959, loss_ce: 0.014707
2022-01-09 13:32:02,334 iteration 3080 : loss : 0.027887, loss_ce: 0.010814
2022-01-09 13:32:04,539 iteration 3081 : loss : 0.049388, loss_ce: 0.016309
2022-01-09 13:32:06,784 iteration 3082 : loss : 0.029121, loss_ce: 0.010688
2022-01-09 13:32:09,085 iteration 3083 : loss : 0.043281, loss_ce: 0.020302
2022-01-09 13:32:11,436 iteration 3084 : loss : 0.024892, loss_ce: 0.009712
2022-01-09 13:32:13,829 iteration 3085 : loss : 0.068567, loss_ce: 0.013821
2022-01-09 13:32:16,133 iteration 3086 : loss : 0.022089, loss_ce: 0.008825
2022-01-09 13:32:18,506 iteration 3087 : loss : 0.026811, loss_ce: 0.007853
2022-01-09 13:32:20,831 iteration 3088 : loss : 0.027294, loss_ce: 0.010974
2022-01-09 13:32:23,345 iteration 3089 : loss : 0.031414, loss_ce: 0.012500
2022-01-09 13:32:25,778 iteration 3090 : loss : 0.026465, loss_ce: 0.009944
2022-01-09 13:32:28,109 iteration 3091 : loss : 0.045432, loss_ce: 0.017405
2022-01-09 13:32:30,383 iteration 3092 : loss : 0.027250, loss_ce: 0.012853
2022-01-09 13:32:32,707 iteration 3093 : loss : 0.029058, loss_ce: 0.009809
2022-01-09 13:32:35,044 iteration 3094 : loss : 0.033564, loss_ce: 0.016059
 46%|████████████▎              | 182/400 [2:08:14<2:35:20, 42.76s/it]2022-01-09 13:32:37,434 iteration 3095 : loss : 0.026573, loss_ce: 0.009649
2022-01-09 13:32:39,680 iteration 3096 : loss : 0.023717, loss_ce: 0.009718
2022-01-09 13:32:41,987 iteration 3097 : loss : 0.033462, loss_ce: 0.013586
2022-01-09 13:32:44,294 iteration 3098 : loss : 0.032744, loss_ce: 0.011014
2022-01-09 13:32:46,707 iteration 3099 : loss : 0.057255, loss_ce: 0.020487
2022-01-09 13:32:49,033 iteration 3100 : loss : 0.029589, loss_ce: 0.010681
2022-01-09 13:32:51,334 iteration 3101 : loss : 0.028492, loss_ce: 0.012382
2022-01-09 13:32:53,722 iteration 3102 : loss : 0.026393, loss_ce: 0.010345
2022-01-09 13:32:56,004 iteration 3103 : loss : 0.029434, loss_ce: 0.008223
2022-01-09 13:32:58,344 iteration 3104 : loss : 0.021540, loss_ce: 0.007213
2022-01-09 13:33:00,733 iteration 3105 : loss : 0.028424, loss_ce: 0.009133
2022-01-09 13:33:03,215 iteration 3106 : loss : 0.035499, loss_ce: 0.016407
2022-01-09 13:33:05,511 iteration 3107 : loss : 0.046073, loss_ce: 0.022216
2022-01-09 13:33:07,722 iteration 3108 : loss : 0.028697, loss_ce: 0.011118
2022-01-09 13:33:10,170 iteration 3109 : loss : 0.034505, loss_ce: 0.018989
2022-01-09 13:33:12,576 iteration 3110 : loss : 0.040222, loss_ce: 0.017718
2022-01-09 13:33:14,836 iteration 3111 : loss : 0.031753, loss_ce: 0.009437
 46%|████████████▎              | 183/400 [2:08:54<2:31:25, 41.87s/it]2022-01-09 13:33:17,103 iteration 3112 : loss : 0.023557, loss_ce: 0.008801
2022-01-09 13:33:19,403 iteration 3113 : loss : 0.027235, loss_ce: 0.011174
2022-01-09 13:33:21,822 iteration 3114 : loss : 0.057140, loss_ce: 0.015920
2022-01-09 13:33:24,191 iteration 3115 : loss : 0.027884, loss_ce: 0.012989
2022-01-09 13:33:26,602 iteration 3116 : loss : 0.037873, loss_ce: 0.018544
2022-01-09 13:33:29,153 iteration 3117 : loss : 0.023545, loss_ce: 0.010152
2022-01-09 13:33:31,628 iteration 3118 : loss : 0.043106, loss_ce: 0.017371
2022-01-09 13:33:34,015 iteration 3119 : loss : 0.038302, loss_ce: 0.013339
2022-01-09 13:33:36,419 iteration 3120 : loss : 0.023999, loss_ce: 0.007732
2022-01-09 13:33:38,886 iteration 3121 : loss : 0.032831, loss_ce: 0.009226
2022-01-09 13:33:41,351 iteration 3122 : loss : 0.031989, loss_ce: 0.008650
2022-01-09 13:33:43,714 iteration 3123 : loss : 0.024756, loss_ce: 0.010155
2022-01-09 13:33:46,038 iteration 3124 : loss : 0.041068, loss_ce: 0.016082
2022-01-09 13:33:48,443 iteration 3125 : loss : 0.050028, loss_ce: 0.022034
2022-01-09 13:33:50,792 iteration 3126 : loss : 0.028868, loss_ce: 0.013081
2022-01-09 13:33:53,237 iteration 3127 : loss : 0.028240, loss_ce: 0.010550
2022-01-09 13:33:55,538 iteration 3128 : loss : 0.028647, loss_ce: 0.009613
 46%|████████████▍              | 184/400 [2:09:34<2:29:27, 41.52s/it]2022-01-09 13:33:57,952 iteration 3129 : loss : 0.029197, loss_ce: 0.011759
2022-01-09 13:34:00,331 iteration 3130 : loss : 0.033841, loss_ce: 0.011848
2022-01-09 13:34:02,662 iteration 3131 : loss : 0.029759, loss_ce: 0.010967
2022-01-09 13:34:04,970 iteration 3132 : loss : 0.028563, loss_ce: 0.011973
2022-01-09 13:34:07,354 iteration 3133 : loss : 0.031678, loss_ce: 0.010782
2022-01-09 13:34:09,773 iteration 3134 : loss : 0.032235, loss_ce: 0.010907
2022-01-09 13:34:12,145 iteration 3135 : loss : 0.027883, loss_ce: 0.009222
2022-01-09 13:34:14,545 iteration 3136 : loss : 0.059695, loss_ce: 0.017392
2022-01-09 13:34:16,989 iteration 3137 : loss : 0.027437, loss_ce: 0.012160
2022-01-09 13:34:19,445 iteration 3138 : loss : 0.030516, loss_ce: 0.014918
2022-01-09 13:34:21,868 iteration 3139 : loss : 0.044924, loss_ce: 0.014775
2022-01-09 13:34:24,288 iteration 3140 : loss : 0.039733, loss_ce: 0.016923
2022-01-09 13:34:26,652 iteration 3141 : loss : 0.027758, loss_ce: 0.009742
2022-01-09 13:34:28,998 iteration 3142 : loss : 0.028941, loss_ce: 0.010292
2022-01-09 13:34:31,361 iteration 3143 : loss : 0.027945, loss_ce: 0.011592
2022-01-09 13:34:33,718 iteration 3144 : loss : 0.030232, loss_ce: 0.012848
2022-01-09 13:34:33,718 Training Data Eval:
2022-01-09 13:34:46,680   Average segmentation loss on training set: 0.0195
2022-01-09 13:34:46,681 Validation Data Eval:
2022-01-09 13:34:51,091   Average segmentation loss on validation set: 0.0822
2022-01-09 13:34:53,398 iteration 3145 : loss : 0.026626, loss_ce: 0.008931
 46%|████████████▍              | 185/400 [2:10:32<2:46:20, 46.42s/it]2022-01-09 13:34:55,744 iteration 3146 : loss : 0.025572, loss_ce: 0.009445
2022-01-09 13:34:58,057 iteration 3147 : loss : 0.026843, loss_ce: 0.011971
2022-01-09 13:35:00,406 iteration 3148 : loss : 0.029917, loss_ce: 0.009846
2022-01-09 13:35:02,789 iteration 3149 : loss : 0.021472, loss_ce: 0.008106
2022-01-09 13:35:05,121 iteration 3150 : loss : 0.032719, loss_ce: 0.014951
2022-01-09 13:35:07,456 iteration 3151 : loss : 0.034057, loss_ce: 0.007947
2022-01-09 13:35:09,825 iteration 3152 : loss : 0.023595, loss_ce: 0.009013
2022-01-09 13:35:12,216 iteration 3153 : loss : 0.041718, loss_ce: 0.015301
2022-01-09 13:35:14,535 iteration 3154 : loss : 0.032997, loss_ce: 0.016079
2022-01-09 13:35:16,890 iteration 3155 : loss : 0.026713, loss_ce: 0.010982
2022-01-09 13:35:19,243 iteration 3156 : loss : 0.051369, loss_ce: 0.019574
2022-01-09 13:35:21,621 iteration 3157 : loss : 0.025482, loss_ce: 0.009946
2022-01-09 13:35:24,156 iteration 3158 : loss : 0.039719, loss_ce: 0.014519
2022-01-09 13:35:26,561 iteration 3159 : loss : 0.027993, loss_ce: 0.010927
2022-01-09 13:35:28,885 iteration 3160 : loss : 0.024507, loss_ce: 0.009513
2022-01-09 13:35:31,182 iteration 3161 : loss : 0.030258, loss_ce: 0.010470
2022-01-09 13:35:33,796 iteration 3162 : loss : 0.028434, loss_ce: 0.012186
 46%|████████████▌              | 186/400 [2:11:13<2:39:07, 44.62s/it]2022-01-09 13:35:36,271 iteration 3163 : loss : 0.033270, loss_ce: 0.013788
2022-01-09 13:35:38,660 iteration 3164 : loss : 0.023839, loss_ce: 0.009180
2022-01-09 13:35:41,028 iteration 3165 : loss : 0.032513, loss_ce: 0.013809
2022-01-09 13:35:43,463 iteration 3166 : loss : 0.022980, loss_ce: 0.007346
2022-01-09 13:35:45,853 iteration 3167 : loss : 0.019880, loss_ce: 0.008427
2022-01-09 13:35:48,358 iteration 3168 : loss : 0.032521, loss_ce: 0.016465
2022-01-09 13:35:50,763 iteration 3169 : loss : 0.036013, loss_ce: 0.016721
2022-01-09 13:35:53,079 iteration 3170 : loss : 0.023455, loss_ce: 0.010413
2022-01-09 13:35:55,310 iteration 3171 : loss : 0.020562, loss_ce: 0.009440
2022-01-09 13:35:57,588 iteration 3172 : loss : 0.024019, loss_ce: 0.009175
2022-01-09 13:35:59,848 iteration 3173 : loss : 0.026073, loss_ce: 0.009345
2022-01-09 13:36:02,172 iteration 3174 : loss : 0.032152, loss_ce: 0.014253
2022-01-09 13:36:04,582 iteration 3175 : loss : 0.042600, loss_ce: 0.012186
2022-01-09 13:36:06,935 iteration 3176 : loss : 0.027873, loss_ce: 0.009486
2022-01-09 13:36:09,384 iteration 3177 : loss : 0.051454, loss_ce: 0.019774
2022-01-09 13:36:11,748 iteration 3178 : loss : 0.025158, loss_ce: 0.008911
2022-01-09 13:36:14,112 iteration 3179 : loss : 0.035226, loss_ce: 0.010652
 47%|████████████▌              | 187/400 [2:11:53<2:33:47, 43.32s/it]2022-01-09 13:36:16,513 iteration 3180 : loss : 0.042214, loss_ce: 0.021414
2022-01-09 13:36:18,710 iteration 3181 : loss : 0.025402, loss_ce: 0.009817
2022-01-09 13:36:20,981 iteration 3182 : loss : 0.026252, loss_ce: 0.009703
2022-01-09 13:36:23,293 iteration 3183 : loss : 0.025459, loss_ce: 0.007352
2022-01-09 13:36:25,658 iteration 3184 : loss : 0.045055, loss_ce: 0.016262
2022-01-09 13:36:28,040 iteration 3185 : loss : 0.031299, loss_ce: 0.011671
2022-01-09 13:36:30,344 iteration 3186 : loss : 0.024149, loss_ce: 0.011896
2022-01-09 13:36:32,808 iteration 3187 : loss : 0.021797, loss_ce: 0.007673
2022-01-09 13:36:35,223 iteration 3188 : loss : 0.024573, loss_ce: 0.010653
2022-01-09 13:36:37,621 iteration 3189 : loss : 0.039361, loss_ce: 0.015340
2022-01-09 13:36:39,987 iteration 3190 : loss : 0.027723, loss_ce: 0.010624
2022-01-09 13:36:42,386 iteration 3191 : loss : 0.025355, loss_ce: 0.006841
2022-01-09 13:36:44,635 iteration 3192 : loss : 0.030704, loss_ce: 0.010023
2022-01-09 13:36:47,056 iteration 3193 : loss : 0.031545, loss_ce: 0.013917
2022-01-09 13:36:49,531 iteration 3194 : loss : 0.026763, loss_ce: 0.007663
2022-01-09 13:36:52,025 iteration 3195 : loss : 0.023257, loss_ce: 0.011112
2022-01-09 13:36:54,436 iteration 3196 : loss : 0.030530, loss_ce: 0.012399
 47%|████████████▋              | 188/400 [2:12:33<2:29:53, 42.42s/it]2022-01-09 13:36:56,784 iteration 3197 : loss : 0.026128, loss_ce: 0.010621
2022-01-09 13:36:59,103 iteration 3198 : loss : 0.024078, loss_ce: 0.009075
2022-01-09 13:37:01,405 iteration 3199 : loss : 0.033916, loss_ce: 0.016538
2022-01-09 13:37:03,879 iteration 3200 : loss : 0.029451, loss_ce: 0.014048
2022-01-09 13:37:06,323 iteration 3201 : loss : 0.035163, loss_ce: 0.009557
2022-01-09 13:37:08,698 iteration 3202 : loss : 0.037055, loss_ce: 0.012433
2022-01-09 13:37:11,101 iteration 3203 : loss : 0.030778, loss_ce: 0.013175
2022-01-09 13:37:13,433 iteration 3204 : loss : 0.025386, loss_ce: 0.007521
2022-01-09 13:37:15,772 iteration 3205 : loss : 0.049660, loss_ce: 0.017291
2022-01-09 13:37:18,162 iteration 3206 : loss : 0.024043, loss_ce: 0.009868
2022-01-09 13:37:20,562 iteration 3207 : loss : 0.045127, loss_ce: 0.021799
2022-01-09 13:37:22,849 iteration 3208 : loss : 0.028228, loss_ce: 0.007962
2022-01-09 13:37:25,106 iteration 3209 : loss : 0.029128, loss_ce: 0.015171
2022-01-09 13:37:27,399 iteration 3210 : loss : 0.029766, loss_ce: 0.013693
2022-01-09 13:37:29,756 iteration 3211 : loss : 0.027097, loss_ce: 0.008369
2022-01-09 13:37:32,139 iteration 3212 : loss : 0.023826, loss_ce: 0.009794
2022-01-09 13:37:34,673 iteration 3213 : loss : 0.033161, loss_ce: 0.009997
 47%|████████████▊              | 189/400 [2:13:13<2:26:52, 41.77s/it]2022-01-09 13:37:37,094 iteration 3214 : loss : 0.024813, loss_ce: 0.010460
2022-01-09 13:37:39,477 iteration 3215 : loss : 0.039224, loss_ce: 0.015724
2022-01-09 13:37:41,834 iteration 3216 : loss : 0.034184, loss_ce: 0.013008
2022-01-09 13:37:44,186 iteration 3217 : loss : 0.065161, loss_ce: 0.017906
2022-01-09 13:37:46,478 iteration 3218 : loss : 0.034496, loss_ce: 0.012179
2022-01-09 13:37:48,847 iteration 3219 : loss : 0.024568, loss_ce: 0.009150
2022-01-09 13:37:51,265 iteration 3220 : loss : 0.036555, loss_ce: 0.014739
2022-01-09 13:37:53,644 iteration 3221 : loss : 0.034178, loss_ce: 0.015489
2022-01-09 13:37:56,025 iteration 3222 : loss : 0.036265, loss_ce: 0.019179
2022-01-09 13:37:58,347 iteration 3223 : loss : 0.032622, loss_ce: 0.009038
2022-01-09 13:38:00,648 iteration 3224 : loss : 0.026370, loss_ce: 0.008688
2022-01-09 13:38:02,888 iteration 3225 : loss : 0.042267, loss_ce: 0.015378
2022-01-09 13:38:05,195 iteration 3226 : loss : 0.045733, loss_ce: 0.016221
2022-01-09 13:38:07,478 iteration 3227 : loss : 0.031496, loss_ce: 0.013267
2022-01-09 13:38:09,696 iteration 3228 : loss : 0.023131, loss_ce: 0.010447
2022-01-09 13:38:11,996 iteration 3229 : loss : 0.023385, loss_ce: 0.009906
2022-01-09 13:38:11,996 Training Data Eval:
2022-01-09 13:38:24,649   Average segmentation loss on training set: 0.0193
2022-01-09 13:38:24,649 Validation Data Eval:
2022-01-09 13:38:29,016   Average segmentation loss on validation set: 0.0802
2022-01-09 13:38:31,486 iteration 3230 : loss : 0.042372, loss_ce: 0.016686
 48%|████████████▊              | 190/400 [2:14:10<2:41:58, 46.28s/it]2022-01-09 13:38:33,876 iteration 3231 : loss : 0.029668, loss_ce: 0.010848
2022-01-09 13:38:36,211 iteration 3232 : loss : 0.034076, loss_ce: 0.015886
2022-01-09 13:38:38,444 iteration 3233 : loss : 0.027881, loss_ce: 0.009783
2022-01-09 13:38:40,610 iteration 3234 : loss : 0.031439, loss_ce: 0.010783
2022-01-09 13:38:42,818 iteration 3235 : loss : 0.024692, loss_ce: 0.006936
2022-01-09 13:38:45,051 iteration 3236 : loss : 0.025069, loss_ce: 0.011272
2022-01-09 13:38:47,386 iteration 3237 : loss : 0.029494, loss_ce: 0.014527
2022-01-09 13:38:49,778 iteration 3238 : loss : 0.026239, loss_ce: 0.007759
2022-01-09 13:38:52,248 iteration 3239 : loss : 0.024693, loss_ce: 0.009560
2022-01-09 13:38:54,674 iteration 3240 : loss : 0.030127, loss_ce: 0.009853
2022-01-09 13:38:57,097 iteration 3241 : loss : 0.046056, loss_ce: 0.019013
2022-01-09 13:38:59,476 iteration 3242 : loss : 0.029094, loss_ce: 0.013192
2022-01-09 13:39:01,736 iteration 3243 : loss : 0.026615, loss_ce: 0.013067
2022-01-09 13:39:04,105 iteration 3244 : loss : 0.048289, loss_ce: 0.011476
2022-01-09 13:39:06,417 iteration 3245 : loss : 0.025305, loss_ce: 0.011593
2022-01-09 13:39:08,722 iteration 3246 : loss : 0.032221, loss_ce: 0.014179
2022-01-09 13:39:10,999 iteration 3247 : loss : 0.032903, loss_ce: 0.011337
 48%|████████████▉              | 191/400 [2:14:50<2:34:08, 44.25s/it]2022-01-09 13:39:13,484 iteration 3248 : loss : 0.041939, loss_ce: 0.019660
2022-01-09 13:39:15,874 iteration 3249 : loss : 0.018952, loss_ce: 0.005943
2022-01-09 13:39:18,278 iteration 3250 : loss : 0.034933, loss_ce: 0.013378
2022-01-09 13:39:20,696 iteration 3251 : loss : 0.025043, loss_ce: 0.006385
2022-01-09 13:39:23,024 iteration 3252 : loss : 0.043974, loss_ce: 0.018885
2022-01-09 13:39:25,361 iteration 3253 : loss : 0.031476, loss_ce: 0.014377
2022-01-09 13:39:27,656 iteration 3254 : loss : 0.030769, loss_ce: 0.009094
2022-01-09 13:39:29,957 iteration 3255 : loss : 0.023588, loss_ce: 0.009034
2022-01-09 13:39:32,192 iteration 3256 : loss : 0.022032, loss_ce: 0.012438
2022-01-09 13:39:34,454 iteration 3257 : loss : 0.046589, loss_ce: 0.016150
2022-01-09 13:39:36,782 iteration 3258 : loss : 0.031842, loss_ce: 0.014200
2022-01-09 13:39:39,076 iteration 3259 : loss : 0.028673, loss_ce: 0.011143
2022-01-09 13:39:41,420 iteration 3260 : loss : 0.025937, loss_ce: 0.010511
2022-01-09 13:39:43,815 iteration 3261 : loss : 0.046203, loss_ce: 0.015595
2022-01-09 13:39:46,179 iteration 3262 : loss : 0.038032, loss_ce: 0.018212
2022-01-09 13:39:48,500 iteration 3263 : loss : 0.051451, loss_ce: 0.011900
2022-01-09 13:39:50,739 iteration 3264 : loss : 0.037874, loss_ce: 0.013723
 48%|████████████▉              | 192/400 [2:15:29<2:28:43, 42.90s/it]2022-01-09 13:39:53,049 iteration 3265 : loss : 0.022139, loss_ce: 0.008197
2022-01-09 13:39:55,466 iteration 3266 : loss : 0.022378, loss_ce: 0.009271
2022-01-09 13:39:57,761 iteration 3267 : loss : 0.025212, loss_ce: 0.011034
2022-01-09 13:40:00,211 iteration 3268 : loss : 0.030528, loss_ce: 0.012239
2022-01-09 13:40:02,452 iteration 3269 : loss : 0.032758, loss_ce: 0.015268
2022-01-09 13:40:04,644 iteration 3270 : loss : 0.027630, loss_ce: 0.010160
2022-01-09 13:40:06,870 iteration 3271 : loss : 0.030479, loss_ce: 0.010027
2022-01-09 13:40:09,012 iteration 3272 : loss : 0.023922, loss_ce: 0.008809
2022-01-09 13:40:11,154 iteration 3273 : loss : 0.047842, loss_ce: 0.017996
2022-01-09 13:40:13,394 iteration 3274 : loss : 0.028799, loss_ce: 0.009783
2022-01-09 13:40:15,633 iteration 3275 : loss : 0.021849, loss_ce: 0.009352
2022-01-09 13:40:17,933 iteration 3276 : loss : 0.028282, loss_ce: 0.009022
2022-01-09 13:40:20,240 iteration 3277 : loss : 0.030959, loss_ce: 0.013906
2022-01-09 13:40:22,479 iteration 3278 : loss : 0.028987, loss_ce: 0.011275
2022-01-09 13:40:24,697 iteration 3279 : loss : 0.038044, loss_ce: 0.014648
2022-01-09 13:40:26,871 iteration 3280 : loss : 0.034455, loss_ce: 0.015904
2022-01-09 13:40:29,080 iteration 3281 : loss : 0.023023, loss_ce: 0.006722
 48%|█████████████              | 193/400 [2:16:08<2:23:16, 41.53s/it]2022-01-09 13:40:31,331 iteration 3282 : loss : 0.022424, loss_ce: 0.009959
2022-01-09 13:40:33,803 iteration 3283 : loss : 0.040704, loss_ce: 0.014572
2022-01-09 13:40:36,113 iteration 3284 : loss : 0.022666, loss_ce: 0.010475
2022-01-09 13:40:38,325 iteration 3285 : loss : 0.019776, loss_ce: 0.007036
2022-01-09 13:40:40,792 iteration 3286 : loss : 0.048390, loss_ce: 0.011558
2022-01-09 13:40:43,202 iteration 3287 : loss : 0.030676, loss_ce: 0.013834
2022-01-09 13:40:45,498 iteration 3288 : loss : 0.028819, loss_ce: 0.009402
2022-01-09 13:40:47,772 iteration 3289 : loss : 0.040048, loss_ce: 0.012828
2022-01-09 13:40:50,009 iteration 3290 : loss : 0.021948, loss_ce: 0.006365
2022-01-09 13:40:52,339 iteration 3291 : loss : 0.026603, loss_ce: 0.008759
2022-01-09 13:40:54,689 iteration 3292 : loss : 0.031590, loss_ce: 0.013126
2022-01-09 13:40:56,997 iteration 3293 : loss : 0.024279, loss_ce: 0.009846
2022-01-09 13:40:59,288 iteration 3294 : loss : 0.022257, loss_ce: 0.008531
2022-01-09 13:41:01,566 iteration 3295 : loss : 0.021504, loss_ce: 0.009604
2022-01-09 13:41:03,836 iteration 3296 : loss : 0.031258, loss_ce: 0.011247
2022-01-09 13:41:06,205 iteration 3297 : loss : 0.040197, loss_ce: 0.017868
2022-01-09 13:41:08,576 iteration 3298 : loss : 0.024709, loss_ce: 0.010451
 48%|█████████████              | 194/400 [2:16:47<2:20:29, 40.92s/it]2022-01-09 13:41:10,948 iteration 3299 : loss : 0.022309, loss_ce: 0.009831
2022-01-09 13:41:13,256 iteration 3300 : loss : 0.027045, loss_ce: 0.009775
2022-01-09 13:41:15,558 iteration 3301 : loss : 0.027586, loss_ce: 0.009986
2022-01-09 13:41:17,867 iteration 3302 : loss : 0.027933, loss_ce: 0.008777
2022-01-09 13:41:20,200 iteration 3303 : loss : 0.034304, loss_ce: 0.011415
2022-01-09 13:41:22,440 iteration 3304 : loss : 0.035128, loss_ce: 0.017979
2022-01-09 13:41:24,722 iteration 3305 : loss : 0.043233, loss_ce: 0.016346
2022-01-09 13:41:26,905 iteration 3306 : loss : 0.023238, loss_ce: 0.008820
2022-01-09 13:41:29,184 iteration 3307 : loss : 0.031504, loss_ce: 0.011672
2022-01-09 13:41:31,411 iteration 3308 : loss : 0.035651, loss_ce: 0.012871
2022-01-09 13:41:33,640 iteration 3309 : loss : 0.019822, loss_ce: 0.008535
2022-01-09 13:41:35,900 iteration 3310 : loss : 0.036039, loss_ce: 0.011273
2022-01-09 13:41:38,093 iteration 3311 : loss : 0.039408, loss_ce: 0.013318
2022-01-09 13:41:40,256 iteration 3312 : loss : 0.021322, loss_ce: 0.010158
2022-01-09 13:41:42,560 iteration 3313 : loss : 0.040540, loss_ce: 0.014552
2022-01-09 13:41:44,753 iteration 3314 : loss : 0.026410, loss_ce: 0.011609
2022-01-09 13:41:44,753 Training Data Eval:
2022-01-09 13:41:57,539   Average segmentation loss on training set: 0.0216
2022-01-09 13:41:57,539 Validation Data Eval:
2022-01-09 13:42:02,048   Average segmentation loss on validation set: 0.1237
2022-01-09 13:42:04,408 iteration 3315 : loss : 0.030299, loss_ce: 0.012289
 49%|█████████████▏             | 195/400 [2:17:43<2:35:06, 45.40s/it]2022-01-09 13:42:06,779 iteration 3316 : loss : 0.025798, loss_ce: 0.006366
2022-01-09 13:42:09,092 iteration 3317 : loss : 0.042842, loss_ce: 0.016865
2022-01-09 13:42:11,436 iteration 3318 : loss : 0.034322, loss_ce: 0.015790
2022-01-09 13:42:13,684 iteration 3319 : loss : 0.022155, loss_ce: 0.009573
2022-01-09 13:42:16,067 iteration 3320 : loss : 0.031642, loss_ce: 0.010609
2022-01-09 13:42:18,369 iteration 3321 : loss : 0.022103, loss_ce: 0.011077
2022-01-09 13:42:20,691 iteration 3322 : loss : 0.027089, loss_ce: 0.009301
2022-01-09 13:42:23,078 iteration 3323 : loss : 0.035912, loss_ce: 0.016898
2022-01-09 13:42:25,453 iteration 3324 : loss : 0.029706, loss_ce: 0.010169
2022-01-09 13:42:27,863 iteration 3325 : loss : 0.029922, loss_ce: 0.010952
2022-01-09 13:42:30,249 iteration 3326 : loss : 0.034944, loss_ce: 0.015235
2022-01-09 13:42:32,690 iteration 3327 : loss : 0.043444, loss_ce: 0.013892
2022-01-09 13:42:34,996 iteration 3328 : loss : 0.022872, loss_ce: 0.011722
2022-01-09 13:42:37,208 iteration 3329 : loss : 0.024354, loss_ce: 0.008904
2022-01-09 13:42:39,446 iteration 3330 : loss : 0.032132, loss_ce: 0.016676
2022-01-09 13:42:41,653 iteration 3331 : loss : 0.020633, loss_ce: 0.007972
2022-01-09 13:42:43,812 iteration 3332 : loss : 0.026560, loss_ce: 0.009197
 49%|█████████████▏             | 196/400 [2:18:23<2:28:14, 43.60s/it]2022-01-09 13:42:46,145 iteration 3333 : loss : 0.024982, loss_ce: 0.010572
2022-01-09 13:42:48,405 iteration 3334 : loss : 0.028249, loss_ce: 0.012288
2022-01-09 13:42:50,724 iteration 3335 : loss : 0.038504, loss_ce: 0.015747
2022-01-09 13:42:52,991 iteration 3336 : loss : 0.020068, loss_ce: 0.007413
2022-01-09 13:42:55,271 iteration 3337 : loss : 0.024514, loss_ce: 0.009166
2022-01-09 13:42:57,634 iteration 3338 : loss : 0.027739, loss_ce: 0.009835
2022-01-09 13:42:59,923 iteration 3339 : loss : 0.040276, loss_ce: 0.013564
2022-01-09 13:43:02,123 iteration 3340 : loss : 0.046928, loss_ce: 0.017468
2022-01-09 13:43:04,373 iteration 3341 : loss : 0.022571, loss_ce: 0.009015
2022-01-09 13:43:06,577 iteration 3342 : loss : 0.050019, loss_ce: 0.030854
2022-01-09 13:43:08,777 iteration 3343 : loss : 0.026521, loss_ce: 0.011199
2022-01-09 13:43:11,037 iteration 3344 : loss : 0.048911, loss_ce: 0.017985
2022-01-09 13:43:13,335 iteration 3345 : loss : 0.026479, loss_ce: 0.012857
2022-01-09 13:43:15,593 iteration 3346 : loss : 0.034519, loss_ce: 0.011819
2022-01-09 13:43:17,871 iteration 3347 : loss : 0.022271, loss_ce: 0.007889
2022-01-09 13:43:20,239 iteration 3348 : loss : 0.029393, loss_ce: 0.014281
2022-01-09 13:43:22,524 iteration 3349 : loss : 0.029882, loss_ce: 0.008772
 49%|█████████████▎             | 197/400 [2:19:01<2:22:33, 42.13s/it]2022-01-09 13:43:24,779 iteration 3350 : loss : 0.029177, loss_ce: 0.014112
2022-01-09 13:43:26,983 iteration 3351 : loss : 0.024467, loss_ce: 0.009113
2022-01-09 13:43:29,174 iteration 3352 : loss : 0.033849, loss_ce: 0.011551
2022-01-09 13:43:31,504 iteration 3353 : loss : 0.023206, loss_ce: 0.006332
2022-01-09 13:43:33,784 iteration 3354 : loss : 0.020058, loss_ce: 0.006044
2022-01-09 13:43:36,162 iteration 3355 : loss : 0.029671, loss_ce: 0.011531
2022-01-09 13:43:38,450 iteration 3356 : loss : 0.044375, loss_ce: 0.020289
2022-01-09 13:43:40,687 iteration 3357 : loss : 0.018381, loss_ce: 0.007752
2022-01-09 13:43:42,938 iteration 3358 : loss : 0.024978, loss_ce: 0.008896
2022-01-09 13:43:45,143 iteration 3359 : loss : 0.025290, loss_ce: 0.011465
2022-01-09 13:43:47,475 iteration 3360 : loss : 0.021814, loss_ce: 0.007822
2022-01-09 13:43:49,784 iteration 3361 : loss : 0.030234, loss_ce: 0.012586
2022-01-09 13:43:52,082 iteration 3362 : loss : 0.030289, loss_ce: 0.010733
2022-01-09 13:43:54,318 iteration 3363 : loss : 0.027981, loss_ce: 0.008680
2022-01-09 13:43:56,701 iteration 3364 : loss : 0.027207, loss_ce: 0.011124
2022-01-09 13:43:58,931 iteration 3365 : loss : 0.021396, loss_ce: 0.008634
2022-01-09 13:44:01,114 iteration 3366 : loss : 0.023891, loss_ce: 0.009606
 50%|█████████████▎             | 198/400 [2:19:40<2:18:15, 41.07s/it]2022-01-09 13:44:03,490 iteration 3367 : loss : 0.031937, loss_ce: 0.012614
2022-01-09 13:44:05,776 iteration 3368 : loss : 0.022549, loss_ce: 0.010717
2022-01-09 13:44:08,037 iteration 3369 : loss : 0.025980, loss_ce: 0.012282
2022-01-09 13:44:10,280 iteration 3370 : loss : 0.031361, loss_ce: 0.007711
2022-01-09 13:44:12,601 iteration 3371 : loss : 0.021222, loss_ce: 0.008210
2022-01-09 13:44:14,895 iteration 3372 : loss : 0.040589, loss_ce: 0.012613
2022-01-09 13:44:17,133 iteration 3373 : loss : 0.026760, loss_ce: 0.011515
2022-01-09 13:44:19,539 iteration 3374 : loss : 0.024778, loss_ce: 0.010240
2022-01-09 13:44:21,900 iteration 3375 : loss : 0.042657, loss_ce: 0.015276
2022-01-09 13:44:24,190 iteration 3376 : loss : 0.021738, loss_ce: 0.007903
2022-01-09 13:44:26,615 iteration 3377 : loss : 0.022044, loss_ce: 0.008847
2022-01-09 13:44:28,951 iteration 3378 : loss : 0.024716, loss_ce: 0.007416
2022-01-09 13:44:31,314 iteration 3379 : loss : 0.022861, loss_ce: 0.008742
2022-01-09 13:44:33,552 iteration 3380 : loss : 0.022579, loss_ce: 0.007504
2022-01-09 13:44:35,813 iteration 3381 : loss : 0.030550, loss_ce: 0.017978
2022-01-09 13:44:38,177 iteration 3382 : loss : 0.027628, loss_ce: 0.009856
2022-01-09 13:44:40,513 iteration 3383 : loss : 0.029179, loss_ce: 0.013595
 50%|█████████████▍             | 199/400 [2:20:19<2:15:53, 40.57s/it]2022-01-09 13:44:42,901 iteration 3384 : loss : 0.024334, loss_ce: 0.009648
2022-01-09 13:44:45,248 iteration 3385 : loss : 0.027134, loss_ce: 0.010810
2022-01-09 13:44:47,614 iteration 3386 : loss : 0.021896, loss_ce: 0.007659
2022-01-09 13:44:49,932 iteration 3387 : loss : 0.029959, loss_ce: 0.009644
2022-01-09 13:44:52,270 iteration 3388 : loss : 0.031943, loss_ce: 0.012771
2022-01-09 13:44:54,552 iteration 3389 : loss : 0.024170, loss_ce: 0.008005
2022-01-09 13:44:56,882 iteration 3390 : loss : 0.035735, loss_ce: 0.014143
2022-01-09 13:44:59,341 iteration 3391 : loss : 0.025990, loss_ce: 0.012675
2022-01-09 13:45:01,698 iteration 3392 : loss : 0.032168, loss_ce: 0.012524
2022-01-09 13:45:04,051 iteration 3393 : loss : 0.025225, loss_ce: 0.009985
2022-01-09 13:45:06,412 iteration 3394 : loss : 0.032227, loss_ce: 0.011382
2022-01-09 13:45:08,886 iteration 3395 : loss : 0.025545, loss_ce: 0.011804
2022-01-09 13:45:11,349 iteration 3396 : loss : 0.032387, loss_ce: 0.011063
2022-01-09 13:45:13,723 iteration 3397 : loss : 0.024678, loss_ce: 0.010431
2022-01-09 13:45:16,202 iteration 3398 : loss : 0.034272, loss_ce: 0.011581
2022-01-09 13:45:18,588 iteration 3399 : loss : 0.024913, loss_ce: 0.012448
2022-01-09 13:45:18,588 Training Data Eval:
2022-01-09 13:45:31,195   Average segmentation loss on training set: 0.0185
2022-01-09 13:45:31,196 Validation Data Eval:
2022-01-09 13:45:35,714   Average segmentation loss on validation set: 0.0684
2022-01-09 13:45:38,149 iteration 3400 : loss : 0.033751, loss_ce: 0.010311
 50%|█████████████▌             | 200/400 [2:21:17<2:32:16, 45.68s/it]2022-01-09 13:45:40,601 iteration 3401 : loss : 0.034846, loss_ce: 0.012092
2022-01-09 13:45:43,092 iteration 3402 : loss : 0.025949, loss_ce: 0.009647
2022-01-09 13:45:45,559 iteration 3403 : loss : 0.032053, loss_ce: 0.011083
2022-01-09 13:45:47,850 iteration 3404 : loss : 0.025826, loss_ce: 0.008724
2022-01-09 13:45:50,132 iteration 3405 : loss : 0.022898, loss_ce: 0.006290
2022-01-09 13:45:52,437 iteration 3406 : loss : 0.028755, loss_ce: 0.012962
2022-01-09 13:45:54,768 iteration 3407 : loss : 0.020063, loss_ce: 0.006932
2022-01-09 13:45:57,099 iteration 3408 : loss : 0.019209, loss_ce: 0.007151
2022-01-09 13:45:59,360 iteration 3409 : loss : 0.024261, loss_ce: 0.004607
2022-01-09 13:46:01,723 iteration 3410 : loss : 0.023484, loss_ce: 0.008940
2022-01-09 13:46:04,164 iteration 3411 : loss : 0.039904, loss_ce: 0.011605
2022-01-09 13:46:06,595 iteration 3412 : loss : 0.034350, loss_ce: 0.017307
2022-01-09 13:46:08,987 iteration 3413 : loss : 0.024315, loss_ce: 0.012601
2022-01-09 13:46:11,355 iteration 3414 : loss : 0.055132, loss_ce: 0.021701
2022-01-09 13:46:13,709 iteration 3415 : loss : 0.024924, loss_ce: 0.010337
2022-01-09 13:46:16,101 iteration 3416 : loss : 0.025516, loss_ce: 0.011035
2022-01-09 13:46:18,459 iteration 3417 : loss : 0.019498, loss_ce: 0.008099
 50%|█████████████▌             | 201/400 [2:21:57<2:26:10, 44.07s/it]2022-01-09 13:46:20,965 iteration 3418 : loss : 0.040634, loss_ce: 0.010985
2022-01-09 13:46:23,443 iteration 3419 : loss : 0.033124, loss_ce: 0.016647
2022-01-09 13:46:25,801 iteration 3420 : loss : 0.020800, loss_ce: 0.010781
2022-01-09 13:46:28,144 iteration 3421 : loss : 0.048862, loss_ce: 0.013040
2022-01-09 13:46:30,463 iteration 3422 : loss : 0.026900, loss_ce: 0.009709
2022-01-09 13:46:32,892 iteration 3423 : loss : 0.032808, loss_ce: 0.015362
2022-01-09 13:46:35,278 iteration 3424 : loss : 0.020863, loss_ce: 0.006924
2022-01-09 13:46:37,701 iteration 3425 : loss : 0.026102, loss_ce: 0.012690
2022-01-09 13:46:40,087 iteration 3426 : loss : 0.020819, loss_ce: 0.006421
2022-01-09 13:46:42,579 iteration 3427 : loss : 0.039130, loss_ce: 0.013593
2022-01-09 13:46:44,966 iteration 3428 : loss : 0.022562, loss_ce: 0.009508
2022-01-09 13:46:47,332 iteration 3429 : loss : 0.028146, loss_ce: 0.014071
2022-01-09 13:46:49,732 iteration 3430 : loss : 0.022932, loss_ce: 0.008134
2022-01-09 13:46:52,162 iteration 3431 : loss : 0.031999, loss_ce: 0.011728
2022-01-09 13:46:54,526 iteration 3432 : loss : 0.027008, loss_ce: 0.008109
2022-01-09 13:46:57,012 iteration 3433 : loss : 0.022195, loss_ce: 0.006360
2022-01-09 13:46:59,427 iteration 3434 : loss : 0.035213, loss_ce: 0.010349
 50%|█████████████▋             | 202/400 [2:22:38<2:22:22, 43.14s/it]2022-01-09 13:47:01,785 iteration 3435 : loss : 0.020628, loss_ce: 0.010167
2022-01-09 13:47:04,173 iteration 3436 : loss : 0.028772, loss_ce: 0.011022
2022-01-09 13:47:06,503 iteration 3437 : loss : 0.030785, loss_ce: 0.009844
2022-01-09 13:47:08,896 iteration 3438 : loss : 0.030516, loss_ce: 0.013252
2022-01-09 13:47:11,300 iteration 3439 : loss : 0.033167, loss_ce: 0.013849
2022-01-09 13:47:13,656 iteration 3440 : loss : 0.041574, loss_ce: 0.013708
2022-01-09 13:47:15,840 iteration 3441 : loss : 0.026155, loss_ce: 0.014172
2022-01-09 13:47:18,176 iteration 3442 : loss : 0.022448, loss_ce: 0.007631
2022-01-09 13:47:20,576 iteration 3443 : loss : 0.021811, loss_ce: 0.008485
2022-01-09 13:47:22,972 iteration 3444 : loss : 0.027014, loss_ce: 0.008919
2022-01-09 13:47:25,480 iteration 3445 : loss : 0.020083, loss_ce: 0.007196
2022-01-09 13:47:27,887 iteration 3446 : loss : 0.029039, loss_ce: 0.008668
2022-01-09 13:47:30,261 iteration 3447 : loss : 0.026818, loss_ce: 0.013803
2022-01-09 13:47:32,570 iteration 3448 : loss : 0.020415, loss_ce: 0.007019
2022-01-09 13:47:34,978 iteration 3449 : loss : 0.038032, loss_ce: 0.012013
2022-01-09 13:47:37,402 iteration 3450 : loss : 0.026874, loss_ce: 0.008394
2022-01-09 13:47:39,793 iteration 3451 : loss : 0.019067, loss_ce: 0.007753
 51%|█████████████▋             | 203/400 [2:23:18<2:18:55, 42.31s/it]2022-01-09 13:47:42,233 iteration 3452 : loss : 0.018309, loss_ce: 0.007046
2022-01-09 13:47:44,669 iteration 3453 : loss : 0.039999, loss_ce: 0.014690
2022-01-09 13:47:47,081 iteration 3454 : loss : 0.038968, loss_ce: 0.011168
2022-01-09 13:47:49,446 iteration 3455 : loss : 0.026331, loss_ce: 0.011452
2022-01-09 13:47:51,791 iteration 3456 : loss : 0.024011, loss_ce: 0.008779
2022-01-09 13:47:54,366 iteration 3457 : loss : 0.037398, loss_ce: 0.016898
2022-01-09 13:47:56,819 iteration 3458 : loss : 0.026068, loss_ce: 0.012859
2022-01-09 13:47:59,250 iteration 3459 : loss : 0.029665, loss_ce: 0.013296
2022-01-09 13:48:01,668 iteration 3460 : loss : 0.026689, loss_ce: 0.009375
2022-01-09 13:48:04,016 iteration 3461 : loss : 0.027024, loss_ce: 0.010955
2022-01-09 13:48:06,326 iteration 3462 : loss : 0.023712, loss_ce: 0.009166
2022-01-09 13:48:08,733 iteration 3463 : loss : 0.018577, loss_ce: 0.006365
2022-01-09 13:48:11,126 iteration 3464 : loss : 0.047759, loss_ce: 0.020219
2022-01-09 13:48:13,455 iteration 3465 : loss : 0.028409, loss_ce: 0.010577
2022-01-09 13:48:16,080 iteration 3466 : loss : 0.018989, loss_ce: 0.007727
2022-01-09 13:48:18,542 iteration 3467 : loss : 0.035796, loss_ce: 0.014741
2022-01-09 13:48:20,965 iteration 3468 : loss : 0.033830, loss_ce: 0.012131
 51%|█████████████▊             | 204/400 [2:24:00<2:17:05, 41.97s/it]2022-01-09 13:48:23,354 iteration 3469 : loss : 0.023380, loss_ce: 0.009099
2022-01-09 13:48:25,871 iteration 3470 : loss : 0.038670, loss_ce: 0.015570
2022-01-09 13:48:28,333 iteration 3471 : loss : 0.026639, loss_ce: 0.009441
2022-01-09 13:48:30,965 iteration 3472 : loss : 0.034643, loss_ce: 0.014477
2022-01-09 13:48:33,409 iteration 3473 : loss : 0.025816, loss_ce: 0.012348
2022-01-09 13:48:35,715 iteration 3474 : loss : 0.044323, loss_ce: 0.015835
2022-01-09 13:48:38,183 iteration 3475 : loss : 0.047983, loss_ce: 0.019156
2022-01-09 13:48:40,562 iteration 3476 : loss : 0.026795, loss_ce: 0.009229
2022-01-09 13:48:42,984 iteration 3477 : loss : 0.049809, loss_ce: 0.017792
2022-01-09 13:48:45,554 iteration 3478 : loss : 0.031341, loss_ce: 0.011616
2022-01-09 13:48:47,924 iteration 3479 : loss : 0.028327, loss_ce: 0.012453
2022-01-09 13:48:50,307 iteration 3480 : loss : 0.022296, loss_ce: 0.009299
2022-01-09 13:48:52,688 iteration 3481 : loss : 0.029112, loss_ce: 0.015399
2022-01-09 13:48:55,179 iteration 3482 : loss : 0.024202, loss_ce: 0.008126
2022-01-09 13:48:57,611 iteration 3483 : loss : 0.022570, loss_ce: 0.008378
2022-01-09 13:48:59,956 iteration 3484 : loss : 0.033907, loss_ce: 0.009967
2022-01-09 13:48:59,957 Training Data Eval:
2022-01-09 13:49:12,857   Average segmentation loss on training set: 0.0181
2022-01-09 13:49:12,857 Validation Data Eval:
2022-01-09 13:49:17,378   Average segmentation loss on validation set: 0.0860
2022-01-09 13:49:19,749 iteration 3485 : loss : 0.024299, loss_ce: 0.009198
 51%|█████████████▊             | 205/400 [2:24:58<2:32:47, 47.01s/it]2022-01-09 13:49:22,228 iteration 3486 : loss : 0.024172, loss_ce: 0.007711
2022-01-09 13:49:24,663 iteration 3487 : loss : 0.033656, loss_ce: 0.014372
2022-01-09 13:49:27,130 iteration 3488 : loss : 0.025425, loss_ce: 0.014990
2022-01-09 13:49:29,470 iteration 3489 : loss : 0.031154, loss_ce: 0.010400
2022-01-09 13:49:31,916 iteration 3490 : loss : 0.031511, loss_ce: 0.013248
2022-01-09 13:49:34,328 iteration 3491 : loss : 0.026741, loss_ce: 0.011159
2022-01-09 13:49:36,665 iteration 3492 : loss : 0.021208, loss_ce: 0.005997
2022-01-09 13:49:39,124 iteration 3493 : loss : 0.034561, loss_ce: 0.008758
2022-01-09 13:49:41,536 iteration 3494 : loss : 0.024642, loss_ce: 0.012826
2022-01-09 13:49:43,862 iteration 3495 : loss : 0.019253, loss_ce: 0.008380
2022-01-09 13:49:46,260 iteration 3496 : loss : 0.040977, loss_ce: 0.011767
2022-01-09 13:49:48,698 iteration 3497 : loss : 0.035453, loss_ce: 0.015404
2022-01-09 13:49:51,283 iteration 3498 : loss : 0.030284, loss_ce: 0.011810
2022-01-09 13:49:53,723 iteration 3499 : loss : 0.043178, loss_ce: 0.011104
2022-01-09 13:49:56,043 iteration 3500 : loss : 0.028172, loss_ce: 0.008142
2022-01-09 13:49:58,354 iteration 3501 : loss : 0.028861, loss_ce: 0.010885
2022-01-09 13:50:00,584 iteration 3502 : loss : 0.039684, loss_ce: 0.016287
 52%|█████████████▉             | 206/400 [2:25:39<2:26:01, 45.16s/it]2022-01-09 13:50:02,899 iteration 3503 : loss : 0.020644, loss_ce: 0.009769
2022-01-09 13:50:05,255 iteration 3504 : loss : 0.023126, loss_ce: 0.007855
2022-01-09 13:50:07,767 iteration 3505 : loss : 0.026042, loss_ce: 0.013319
2022-01-09 13:50:10,228 iteration 3506 : loss : 0.035861, loss_ce: 0.013066
2022-01-09 13:50:12,550 iteration 3507 : loss : 0.023587, loss_ce: 0.009967
2022-01-09 13:50:14,819 iteration 3508 : loss : 0.019891, loss_ce: 0.006284
2022-01-09 13:50:17,176 iteration 3509 : loss : 0.029972, loss_ce: 0.014937
2022-01-09 13:50:19,644 iteration 3510 : loss : 0.023207, loss_ce: 0.010119
2022-01-09 13:50:21,973 iteration 3511 : loss : 0.024436, loss_ce: 0.010736
2022-01-09 13:50:24,509 iteration 3512 : loss : 0.029646, loss_ce: 0.010694
2022-01-09 13:50:26,892 iteration 3513 : loss : 0.022781, loss_ce: 0.007513
2022-01-09 13:50:29,188 iteration 3514 : loss : 0.015767, loss_ce: 0.006771
2022-01-09 13:50:31,495 iteration 3515 : loss : 0.017726, loss_ce: 0.005906
2022-01-09 13:50:34,044 iteration 3516 : loss : 0.035713, loss_ce: 0.013627
2022-01-09 13:50:36,458 iteration 3517 : loss : 0.023321, loss_ce: 0.009201
2022-01-09 13:50:38,773 iteration 3518 : loss : 0.017543, loss_ce: 0.008394
2022-01-09 13:50:41,190 iteration 3519 : loss : 0.028390, loss_ce: 0.010056
 52%|█████████████▉             | 207/400 [2:26:20<2:20:52, 43.80s/it]2022-01-09 13:50:43,610 iteration 3520 : loss : 0.027193, loss_ce: 0.009495
2022-01-09 13:50:46,186 iteration 3521 : loss : 0.038186, loss_ce: 0.014495
2022-01-09 13:50:48,590 iteration 3522 : loss : 0.038137, loss_ce: 0.018834
2022-01-09 13:50:50,982 iteration 3523 : loss : 0.028242, loss_ce: 0.011155
2022-01-09 13:50:53,229 iteration 3524 : loss : 0.026748, loss_ce: 0.006937
2022-01-09 13:50:55,643 iteration 3525 : loss : 0.035057, loss_ce: 0.014713
2022-01-09 13:50:58,253 iteration 3526 : loss : 0.029621, loss_ce: 0.015433
2022-01-09 13:51:00,663 iteration 3527 : loss : 0.020026, loss_ce: 0.006681
2022-01-09 13:51:02,969 iteration 3528 : loss : 0.026155, loss_ce: 0.011857
2022-01-09 13:51:05,355 iteration 3529 : loss : 0.035040, loss_ce: 0.014717
2022-01-09 13:51:07,894 iteration 3530 : loss : 0.028410, loss_ce: 0.009695
2022-01-09 13:51:10,295 iteration 3531 : loss : 0.024769, loss_ce: 0.010843
2022-01-09 13:51:12,568 iteration 3532 : loss : 0.023016, loss_ce: 0.008837
2022-01-09 13:51:14,877 iteration 3533 : loss : 0.024754, loss_ce: 0.009999
2022-01-09 13:51:17,393 iteration 3534 : loss : 0.026631, loss_ce: 0.013901
2022-01-09 13:51:19,790 iteration 3535 : loss : 0.023991, loss_ce: 0.007537
2022-01-09 13:51:22,140 iteration 3536 : loss : 0.023223, loss_ce: 0.007124
 52%|██████████████             | 208/400 [2:27:01<2:17:24, 42.94s/it]2022-01-09 13:51:24,505 iteration 3537 : loss : 0.038296, loss_ce: 0.016848
2022-01-09 13:51:26,877 iteration 3538 : loss : 0.036280, loss_ce: 0.011074
2022-01-09 13:51:29,355 iteration 3539 : loss : 0.025758, loss_ce: 0.012099
2022-01-09 13:51:31,837 iteration 3540 : loss : 0.021480, loss_ce: 0.004660
2022-01-09 13:51:34,274 iteration 3541 : loss : 0.025959, loss_ce: 0.009860
2022-01-09 13:51:36,659 iteration 3542 : loss : 0.025096, loss_ce: 0.006013
2022-01-09 13:51:39,022 iteration 3543 : loss : 0.023142, loss_ce: 0.010557
2022-01-09 13:51:41,632 iteration 3544 : loss : 0.028829, loss_ce: 0.010106
2022-01-09 13:51:44,011 iteration 3545 : loss : 0.025276, loss_ce: 0.009297
2022-01-09 13:51:46,456 iteration 3546 : loss : 0.025178, loss_ce: 0.011543
2022-01-09 13:51:48,880 iteration 3547 : loss : 0.026733, loss_ce: 0.010704
2022-01-09 13:51:51,292 iteration 3548 : loss : 0.035514, loss_ce: 0.010509
2022-01-09 13:51:53,642 iteration 3549 : loss : 0.031800, loss_ce: 0.013776
2022-01-09 13:51:55,971 iteration 3550 : loss : 0.023477, loss_ce: 0.008162
2022-01-09 13:51:58,441 iteration 3551 : loss : 0.048308, loss_ce: 0.014506
2022-01-09 13:52:00,892 iteration 3552 : loss : 0.039230, loss_ce: 0.016228
2022-01-09 13:52:03,416 iteration 3553 : loss : 0.026250, loss_ce: 0.008533
 52%|██████████████             | 209/400 [2:27:42<2:15:05, 42.44s/it]2022-01-09 13:52:05,871 iteration 3554 : loss : 0.023987, loss_ce: 0.009550
2022-01-09 13:52:08,431 iteration 3555 : loss : 0.029187, loss_ce: 0.012376
2022-01-09 13:52:10,818 iteration 3556 : loss : 0.034232, loss_ce: 0.010877
2022-01-09 13:52:13,202 iteration 3557 : loss : 0.024299, loss_ce: 0.010712
2022-01-09 13:52:15,591 iteration 3558 : loss : 0.030545, loss_ce: 0.010293
2022-01-09 13:52:18,024 iteration 3559 : loss : 0.028792, loss_ce: 0.011095
2022-01-09 13:52:20,361 iteration 3560 : loss : 0.039709, loss_ce: 0.013574
2022-01-09 13:52:22,767 iteration 3561 : loss : 0.026089, loss_ce: 0.010965
2022-01-09 13:52:25,317 iteration 3562 : loss : 0.022950, loss_ce: 0.008484
2022-01-09 13:52:27,694 iteration 3563 : loss : 0.021252, loss_ce: 0.007945
2022-01-09 13:52:30,057 iteration 3564 : loss : 0.035723, loss_ce: 0.011803
2022-01-09 13:52:32,299 iteration 3565 : loss : 0.022996, loss_ce: 0.009473
2022-01-09 13:52:34,563 iteration 3566 : loss : 0.016708, loss_ce: 0.006499
2022-01-09 13:52:36,863 iteration 3567 : loss : 0.023782, loss_ce: 0.007596
2022-01-09 13:52:39,435 iteration 3568 : loss : 0.027112, loss_ce: 0.009627
2022-01-09 13:52:41,801 iteration 3569 : loss : 0.047793, loss_ce: 0.029471
2022-01-09 13:52:41,801 Training Data Eval:
2022-01-09 13:52:54,511   Average segmentation loss on training set: 0.0169
2022-01-09 13:52:54,511 Validation Data Eval:
2022-01-09 13:52:59,034   Average segmentation loss on validation set: 0.0682
2022-01-09 13:53:01,408 iteration 3570 : loss : 0.018571, loss_ce: 0.006121
 52%|██████████████▏            | 210/400 [2:28:40<2:29:10, 47.11s/it]2022-01-09 13:53:03,850 iteration 3571 : loss : 0.025627, loss_ce: 0.010942
2022-01-09 13:53:06,260 iteration 3572 : loss : 0.031744, loss_ce: 0.012071
2022-01-09 13:53:08,660 iteration 3573 : loss : 0.027457, loss_ce: 0.010979
2022-01-09 13:53:10,962 iteration 3574 : loss : 0.017765, loss_ce: 0.008279
2022-01-09 13:53:13,240 iteration 3575 : loss : 0.027126, loss_ce: 0.010337
2022-01-09 13:53:15,575 iteration 3576 : loss : 0.026627, loss_ce: 0.009478
2022-01-09 13:53:17,946 iteration 3577 : loss : 0.022996, loss_ce: 0.009564
2022-01-09 13:53:20,260 iteration 3578 : loss : 0.027399, loss_ce: 0.011379
2022-01-09 13:53:22,643 iteration 3579 : loss : 0.022316, loss_ce: 0.008409
2022-01-09 13:53:25,019 iteration 3580 : loss : 0.030028, loss_ce: 0.014100
2022-01-09 13:53:27,395 iteration 3581 : loss : 0.023018, loss_ce: 0.009129
2022-01-09 13:53:29,826 iteration 3582 : loss : 0.025201, loss_ce: 0.009774
2022-01-09 13:53:32,193 iteration 3583 : loss : 0.062536, loss_ce: 0.021061
2022-01-09 13:53:34,528 iteration 3584 : loss : 0.023789, loss_ce: 0.008853
2022-01-09 13:53:36,869 iteration 3585 : loss : 0.016262, loss_ce: 0.006198
2022-01-09 13:53:39,141 iteration 3586 : loss : 0.017761, loss_ce: 0.005358
2022-01-09 13:53:41,500 iteration 3587 : loss : 0.018871, loss_ce: 0.008489
 53%|██████████████▏            | 211/400 [2:29:20<2:21:45, 45.00s/it]2022-01-09 13:53:43,978 iteration 3588 : loss : 0.019759, loss_ce: 0.007484
2022-01-09 13:53:46,352 iteration 3589 : loss : 0.028727, loss_ce: 0.010105
2022-01-09 13:53:48,648 iteration 3590 : loss : 0.037787, loss_ce: 0.009931
2022-01-09 13:53:50,891 iteration 3591 : loss : 0.023524, loss_ce: 0.007548
2022-01-09 13:53:53,254 iteration 3592 : loss : 0.018685, loss_ce: 0.007609
2022-01-09 13:53:55,614 iteration 3593 : loss : 0.024725, loss_ce: 0.013405
2022-01-09 13:53:58,026 iteration 3594 : loss : 0.026435, loss_ce: 0.008144
2022-01-09 13:54:00,344 iteration 3595 : loss : 0.037411, loss_ce: 0.016445
2022-01-09 13:54:02,591 iteration 3596 : loss : 0.020892, loss_ce: 0.009116
2022-01-09 13:54:04,850 iteration 3597 : loss : 0.022407, loss_ce: 0.009341
2022-01-09 13:54:07,166 iteration 3598 : loss : 0.022304, loss_ce: 0.009909
2022-01-09 13:54:09,402 iteration 3599 : loss : 0.029949, loss_ce: 0.009892
2022-01-09 13:54:11,526 iteration 3600 : loss : 0.021523, loss_ce: 0.011592
2022-01-09 13:54:13,725 iteration 3601 : loss : 0.023030, loss_ce: 0.008947
2022-01-09 13:54:15,936 iteration 3602 : loss : 0.029330, loss_ce: 0.012363
2022-01-09 13:54:18,136 iteration 3603 : loss : 0.027031, loss_ce: 0.014269
2022-01-09 13:54:20,468 iteration 3604 : loss : 0.034525, loss_ce: 0.008721
 53%|██████████████▎            | 212/400 [2:29:59<2:15:20, 43.19s/it]2022-01-09 13:54:22,874 iteration 3605 : loss : 0.030893, loss_ce: 0.012326
2022-01-09 13:54:25,028 iteration 3606 : loss : 0.029677, loss_ce: 0.008434
2022-01-09 13:54:27,177 iteration 3607 : loss : 0.012750, loss_ce: 0.004130
2022-01-09 13:54:29,425 iteration 3608 : loss : 0.032397, loss_ce: 0.011054
2022-01-09 13:54:31,756 iteration 3609 : loss : 0.058808, loss_ce: 0.026031
2022-01-09 13:54:34,005 iteration 3610 : loss : 0.014883, loss_ce: 0.006124
2022-01-09 13:54:36,367 iteration 3611 : loss : 0.029157, loss_ce: 0.013146
2022-01-09 13:54:38,686 iteration 3612 : loss : 0.023645, loss_ce: 0.010967
2022-01-09 13:54:41,057 iteration 3613 : loss : 0.020245, loss_ce: 0.008030
2022-01-09 13:54:43,358 iteration 3614 : loss : 0.023245, loss_ce: 0.009111
2022-01-09 13:54:45,670 iteration 3615 : loss : 0.038698, loss_ce: 0.011321
2022-01-09 13:54:47,985 iteration 3616 : loss : 0.024461, loss_ce: 0.011686
2022-01-09 13:54:50,344 iteration 3617 : loss : 0.024393, loss_ce: 0.011186
2022-01-09 13:54:52,737 iteration 3618 : loss : 0.027714, loss_ce: 0.009435
2022-01-09 13:54:55,091 iteration 3619 : loss : 0.021903, loss_ce: 0.007661
2022-01-09 13:54:57,431 iteration 3620 : loss : 0.037684, loss_ce: 0.010483
2022-01-09 13:54:59,703 iteration 3621 : loss : 0.018681, loss_ce: 0.008523
 53%|██████████████▍            | 213/400 [2:30:38<2:10:54, 42.00s/it]2022-01-09 13:55:02,109 iteration 3622 : loss : 0.030278, loss_ce: 0.010229
2022-01-09 13:55:04,402 iteration 3623 : loss : 0.053201, loss_ce: 0.017753
2022-01-09 13:55:06,789 iteration 3624 : loss : 0.028324, loss_ce: 0.011154
2022-01-09 13:55:09,052 iteration 3625 : loss : 0.025017, loss_ce: 0.009642
2022-01-09 13:55:11,401 iteration 3626 : loss : 0.027274, loss_ce: 0.007889
2022-01-09 13:55:13,804 iteration 3627 : loss : 0.037216, loss_ce: 0.014221
2022-01-09 13:55:16,121 iteration 3628 : loss : 0.037462, loss_ce: 0.012235
2022-01-09 13:55:18,406 iteration 3629 : loss : 0.050717, loss_ce: 0.022902
2022-01-09 13:55:20,682 iteration 3630 : loss : 0.031879, loss_ce: 0.014515
2022-01-09 13:55:23,177 iteration 3631 : loss : 0.028630, loss_ce: 0.009953
2022-01-09 13:55:25,590 iteration 3632 : loss : 0.030944, loss_ce: 0.014893
2022-01-09 13:55:27,938 iteration 3633 : loss : 0.032894, loss_ce: 0.010410
2022-01-09 13:55:30,311 iteration 3634 : loss : 0.026771, loss_ce: 0.008696
2022-01-09 13:55:32,758 iteration 3635 : loss : 0.030859, loss_ce: 0.014208
2022-01-09 13:55:34,969 iteration 3636 : loss : 0.020417, loss_ce: 0.009445
2022-01-09 13:55:37,209 iteration 3637 : loss : 0.024503, loss_ce: 0.009131
2022-01-09 13:55:39,458 iteration 3638 : loss : 0.022665, loss_ce: 0.007300
 54%|██████████████▍            | 214/400 [2:31:18<2:08:07, 41.33s/it]2022-01-09 13:55:41,933 iteration 3639 : loss : 0.040773, loss_ce: 0.012905
2022-01-09 13:55:44,384 iteration 3640 : loss : 0.046627, loss_ce: 0.016230
2022-01-09 13:55:46,759 iteration 3641 : loss : 0.026435, loss_ce: 0.010532
2022-01-09 13:55:49,017 iteration 3642 : loss : 0.035332, loss_ce: 0.014942
2022-01-09 13:55:51,415 iteration 3643 : loss : 0.040821, loss_ce: 0.016281
2022-01-09 13:55:53,792 iteration 3644 : loss : 0.023995, loss_ce: 0.009446
2022-01-09 13:55:56,208 iteration 3645 : loss : 0.050699, loss_ce: 0.018899
2022-01-09 13:55:58,529 iteration 3646 : loss : 0.038467, loss_ce: 0.016849
2022-01-09 13:56:00,856 iteration 3647 : loss : 0.019536, loss_ce: 0.007487
2022-01-09 13:56:03,217 iteration 3648 : loss : 0.028162, loss_ce: 0.011095
2022-01-09 13:56:05,406 iteration 3649 : loss : 0.023570, loss_ce: 0.009018
2022-01-09 13:56:07,762 iteration 3650 : loss : 0.022505, loss_ce: 0.009198
2022-01-09 13:56:10,131 iteration 3651 : loss : 0.026823, loss_ce: 0.009862
2022-01-09 13:56:12,438 iteration 3652 : loss : 0.031295, loss_ce: 0.012509
2022-01-09 13:56:14,824 iteration 3653 : loss : 0.033081, loss_ce: 0.013301
2022-01-09 13:56:17,092 iteration 3654 : loss : 0.022921, loss_ce: 0.009087
2022-01-09 13:56:17,092 Training Data Eval:
2022-01-09 13:56:29,648   Average segmentation loss on training set: 0.0166
2022-01-09 13:56:29,648 Validation Data Eval:
2022-01-09 13:56:34,200   Average segmentation loss on validation set: 0.0833
2022-01-09 13:56:36,708 iteration 3655 : loss : 0.046782, loss_ce: 0.015231
 54%|██████████████▌            | 215/400 [2:32:15<2:22:08, 46.10s/it]2022-01-09 13:56:39,126 iteration 3656 : loss : 0.023031, loss_ce: 0.007650
2022-01-09 13:56:41,499 iteration 3657 : loss : 0.023402, loss_ce: 0.010003
2022-01-09 13:56:43,906 iteration 3658 : loss : 0.031603, loss_ce: 0.013028
2022-01-09 13:56:46,219 iteration 3659 : loss : 0.060292, loss_ce: 0.024170
2022-01-09 13:56:48,624 iteration 3660 : loss : 0.026636, loss_ce: 0.011079
2022-01-09 13:56:50,881 iteration 3661 : loss : 0.028010, loss_ce: 0.011391
2022-01-09 13:56:53,156 iteration 3662 : loss : 0.030856, loss_ce: 0.014699
2022-01-09 13:56:55,512 iteration 3663 : loss : 0.031730, loss_ce: 0.016345
2022-01-09 13:56:57,822 iteration 3664 : loss : 0.030678, loss_ce: 0.010002
2022-01-09 13:57:00,139 iteration 3665 : loss : 0.030924, loss_ce: 0.009989
2022-01-09 13:57:02,403 iteration 3666 : loss : 0.024984, loss_ce: 0.010798
2022-01-09 13:57:04,668 iteration 3667 : loss : 0.024492, loss_ce: 0.009376
2022-01-09 13:57:06,903 iteration 3668 : loss : 0.027738, loss_ce: 0.009714
2022-01-09 13:57:09,212 iteration 3669 : loss : 0.032075, loss_ce: 0.010921
2022-01-09 13:57:11,433 iteration 3670 : loss : 0.024459, loss_ce: 0.011138
2022-01-09 13:57:13,912 iteration 3671 : loss : 0.032602, loss_ce: 0.009085
2022-01-09 13:57:16,263 iteration 3672 : loss : 0.031941, loss_ce: 0.008746
 54%|██████████████▌            | 216/400 [2:32:55<2:15:22, 44.14s/it]2022-01-09 13:57:18,586 iteration 3673 : loss : 0.022913, loss_ce: 0.010540
2022-01-09 13:57:20,899 iteration 3674 : loss : 0.021805, loss_ce: 0.009841
2022-01-09 13:57:23,181 iteration 3675 : loss : 0.024985, loss_ce: 0.011139
2022-01-09 13:57:25,372 iteration 3676 : loss : 0.025697, loss_ce: 0.007091
2022-01-09 13:57:27,625 iteration 3677 : loss : 0.032134, loss_ce: 0.015776
2022-01-09 13:57:29,951 iteration 3678 : loss : 0.036358, loss_ce: 0.011115
2022-01-09 13:57:32,134 iteration 3679 : loss : 0.020181, loss_ce: 0.007239
2022-01-09 13:57:34,426 iteration 3680 : loss : 0.020823, loss_ce: 0.008009
2022-01-09 13:57:36,798 iteration 3681 : loss : 0.039901, loss_ce: 0.011544
2022-01-09 13:57:39,124 iteration 3682 : loss : 0.019969, loss_ce: 0.006480
2022-01-09 13:57:41,517 iteration 3683 : loss : 0.024975, loss_ce: 0.011844
2022-01-09 13:57:43,823 iteration 3684 : loss : 0.018710, loss_ce: 0.006293
2022-01-09 13:57:46,132 iteration 3685 : loss : 0.033929, loss_ce: 0.012691
2022-01-09 13:57:48,465 iteration 3686 : loss : 0.032585, loss_ce: 0.014545
2022-01-09 13:57:50,911 iteration 3687 : loss : 0.031780, loss_ce: 0.012677
2022-01-09 13:57:53,346 iteration 3688 : loss : 0.030175, loss_ce: 0.012404
2022-01-09 13:57:55,723 iteration 3689 : loss : 0.034068, loss_ce: 0.009309
 54%|██████████████▋            | 217/400 [2:33:34<2:10:20, 42.74s/it]2022-01-09 13:57:58,234 iteration 3690 : loss : 0.029210, loss_ce: 0.012936
2022-01-09 13:58:00,481 iteration 3691 : loss : 0.051576, loss_ce: 0.017472
2022-01-09 13:58:02,777 iteration 3692 : loss : 0.023466, loss_ce: 0.006905
2022-01-09 13:58:05,064 iteration 3693 : loss : 0.017439, loss_ce: 0.004779
2022-01-09 13:58:07,376 iteration 3694 : loss : 0.023650, loss_ce: 0.007783
2022-01-09 13:58:09,646 iteration 3695 : loss : 0.022548, loss_ce: 0.007900
2022-01-09 13:58:11,898 iteration 3696 : loss : 0.020285, loss_ce: 0.007565
2022-01-09 13:58:14,186 iteration 3697 : loss : 0.034757, loss_ce: 0.010885
2022-01-09 13:58:16,527 iteration 3698 : loss : 0.038010, loss_ce: 0.012249
2022-01-09 13:58:18,828 iteration 3699 : loss : 0.022403, loss_ce: 0.010681
2022-01-09 13:58:21,158 iteration 3700 : loss : 0.021263, loss_ce: 0.006652
2022-01-09 13:58:23,388 iteration 3701 : loss : 0.022245, loss_ce: 0.010958
2022-01-09 13:58:25,710 iteration 3702 : loss : 0.044914, loss_ce: 0.017389
2022-01-09 13:58:28,005 iteration 3703 : loss : 0.021541, loss_ce: 0.008038
2022-01-09 13:58:30,375 iteration 3704 : loss : 0.027877, loss_ce: 0.009662
2022-01-09 13:58:32,760 iteration 3705 : loss : 0.040322, loss_ce: 0.019084
2022-01-09 13:58:35,111 iteration 3706 : loss : 0.025706, loss_ce: 0.008422
 55%|██████████████▋            | 218/400 [2:34:14<2:06:35, 41.73s/it]2022-01-09 13:58:37,518 iteration 3707 : loss : 0.119756, loss_ce: 0.015854
2022-01-09 13:58:39,884 iteration 3708 : loss : 0.065928, loss_ce: 0.025268
2022-01-09 13:58:42,092 iteration 3709 : loss : 0.042432, loss_ce: 0.016264
2022-01-09 13:58:44,311 iteration 3710 : loss : 0.022863, loss_ce: 0.008643
2022-01-09 13:58:46,705 iteration 3711 : loss : 0.031151, loss_ce: 0.012810
2022-01-09 13:58:48,984 iteration 3712 : loss : 0.027388, loss_ce: 0.009521
2022-01-09 13:58:51,293 iteration 3713 : loss : 0.020461, loss_ce: 0.008240
2022-01-09 13:58:53,693 iteration 3714 : loss : 0.034218, loss_ce: 0.014247
2022-01-09 13:58:55,997 iteration 3715 : loss : 0.028822, loss_ce: 0.010853
2022-01-09 13:58:58,268 iteration 3716 : loss : 0.043562, loss_ce: 0.019611
2022-01-09 13:59:00,696 iteration 3717 : loss : 0.028589, loss_ce: 0.013522
2022-01-09 13:59:03,136 iteration 3718 : loss : 0.036659, loss_ce: 0.013346
2022-01-09 13:59:05,610 iteration 3719 : loss : 0.045680, loss_ce: 0.014806
2022-01-09 13:59:08,001 iteration 3720 : loss : 0.035939, loss_ce: 0.015324
2022-01-09 13:59:10,345 iteration 3721 : loss : 0.036437, loss_ce: 0.015300
2022-01-09 13:59:12,668 iteration 3722 : loss : 0.035151, loss_ce: 0.010973
2022-01-09 13:59:14,935 iteration 3723 : loss : 0.028233, loss_ce: 0.012822
 55%|██████████████▊            | 219/400 [2:34:54<2:04:09, 41.16s/it]2022-01-09 13:59:17,268 iteration 3724 : loss : 0.031100, loss_ce: 0.018631
2022-01-09 13:59:19,617 iteration 3725 : loss : 0.031042, loss_ce: 0.013433
2022-01-09 13:59:21,953 iteration 3726 : loss : 0.025105, loss_ce: 0.010588
2022-01-09 13:59:24,336 iteration 3727 : loss : 0.026848, loss_ce: 0.010635
2022-01-09 13:59:26,660 iteration 3728 : loss : 0.027048, loss_ce: 0.012937
2022-01-09 13:59:29,070 iteration 3729 : loss : 0.032744, loss_ce: 0.011065
2022-01-09 13:59:31,451 iteration 3730 : loss : 0.027053, loss_ce: 0.011131
2022-01-09 13:59:33,877 iteration 3731 : loss : 0.047056, loss_ce: 0.018667
2022-01-09 13:59:36,166 iteration 3732 : loss : 0.028546, loss_ce: 0.013682
2022-01-09 13:59:38,446 iteration 3733 : loss : 0.018885, loss_ce: 0.005381
2022-01-09 13:59:40,886 iteration 3734 : loss : 0.033824, loss_ce: 0.012234
2022-01-09 13:59:43,323 iteration 3735 : loss : 0.023189, loss_ce: 0.008495
2022-01-09 13:59:45,635 iteration 3736 : loss : 0.040799, loss_ce: 0.016353
2022-01-09 13:59:47,954 iteration 3737 : loss : 0.043763, loss_ce: 0.022531
2022-01-09 13:59:50,274 iteration 3738 : loss : 0.035203, loss_ce: 0.010768
2022-01-09 13:59:52,603 iteration 3739 : loss : 0.027785, loss_ce: 0.008748
2022-01-09 13:59:52,603 Training Data Eval:
2022-01-09 14:00:05,444   Average segmentation loss on training set: 0.0187
2022-01-09 14:00:05,445 Validation Data Eval:
2022-01-09 14:00:10,102   Average segmentation loss on validation set: 0.0807
2022-01-09 14:00:12,464 iteration 3740 : loss : 0.028825, loss_ce: 0.008395
 55%|██████████████▊            | 220/400 [2:35:51<2:18:12, 46.07s/it]2022-01-09 14:00:14,867 iteration 3741 : loss : 0.026559, loss_ce: 0.012763
2022-01-09 14:00:17,154 iteration 3742 : loss : 0.023871, loss_ce: 0.008755
2022-01-09 14:00:19,468 iteration 3743 : loss : 0.022802, loss_ce: 0.006835
2022-01-09 14:00:21,816 iteration 3744 : loss : 0.019436, loss_ce: 0.006928
2022-01-09 14:00:24,235 iteration 3745 : loss : 0.034037, loss_ce: 0.022025
2022-01-09 14:00:26,723 iteration 3746 : loss : 0.026670, loss_ce: 0.007730
2022-01-09 14:00:29,138 iteration 3747 : loss : 0.038967, loss_ce: 0.019091
2022-01-09 14:00:31,564 iteration 3748 : loss : 0.043515, loss_ce: 0.015858
2022-01-09 14:00:33,907 iteration 3749 : loss : 0.025128, loss_ce: 0.007743
2022-01-09 14:00:36,231 iteration 3750 : loss : 0.035962, loss_ce: 0.013519
2022-01-09 14:00:38,465 iteration 3751 : loss : 0.030250, loss_ce: 0.014003
2022-01-09 14:00:40,678 iteration 3752 : loss : 0.025560, loss_ce: 0.010063
2022-01-09 14:00:43,074 iteration 3753 : loss : 0.036353, loss_ce: 0.013170
2022-01-09 14:00:45,578 iteration 3754 : loss : 0.023272, loss_ce: 0.011531
2022-01-09 14:00:47,996 iteration 3755 : loss : 0.023452, loss_ce: 0.009780
2022-01-09 14:00:50,541 iteration 3756 : loss : 0.024438, loss_ce: 0.008730
2022-01-09 14:00:52,949 iteration 3757 : loss : 0.028745, loss_ce: 0.010370
 55%|██████████████▉            | 221/400 [2:36:32<2:12:27, 44.40s/it]2022-01-09 14:00:55,384 iteration 3758 : loss : 0.032214, loss_ce: 0.011979
2022-01-09 14:00:57,723 iteration 3759 : loss : 0.029805, loss_ce: 0.012096
2022-01-09 14:01:00,139 iteration 3760 : loss : 0.043001, loss_ce: 0.017419
2022-01-09 14:01:02,495 iteration 3761 : loss : 0.025465, loss_ce: 0.011306
2022-01-09 14:01:04,881 iteration 3762 : loss : 0.033229, loss_ce: 0.013647
2022-01-09 14:01:07,241 iteration 3763 : loss : 0.030153, loss_ce: 0.013808
2022-01-09 14:01:09,547 iteration 3764 : loss : 0.033637, loss_ce: 0.008667
2022-01-09 14:01:11,805 iteration 3765 : loss : 0.026317, loss_ce: 0.010114
2022-01-09 14:01:14,122 iteration 3766 : loss : 0.031417, loss_ce: 0.010330
2022-01-09 14:01:16,496 iteration 3767 : loss : 0.025531, loss_ce: 0.008999
2022-01-09 14:01:18,938 iteration 3768 : loss : 0.025341, loss_ce: 0.009386
2022-01-09 14:01:21,494 iteration 3769 : loss : 0.034626, loss_ce: 0.012185
2022-01-09 14:01:23,924 iteration 3770 : loss : 0.033152, loss_ce: 0.012277
2022-01-09 14:01:26,353 iteration 3771 : loss : 0.028441, loss_ce: 0.011157
2022-01-09 14:01:28,770 iteration 3772 : loss : 0.036267, loss_ce: 0.009218
2022-01-09 14:01:31,127 iteration 3773 : loss : 0.025087, loss_ce: 0.008277
2022-01-09 14:01:33,602 iteration 3774 : loss : 0.033816, loss_ce: 0.015548
 56%|██████████████▉            | 222/400 [2:37:12<2:08:22, 43.27s/it]2022-01-09 14:01:36,080 iteration 3775 : loss : 0.032554, loss_ce: 0.014167
2022-01-09 14:01:38,421 iteration 3776 : loss : 0.017983, loss_ce: 0.006824
2022-01-09 14:01:40,710 iteration 3777 : loss : 0.029822, loss_ce: 0.009569
2022-01-09 14:01:43,144 iteration 3778 : loss : 0.038078, loss_ce: 0.016156
2022-01-09 14:01:45,545 iteration 3779 : loss : 0.024153, loss_ce: 0.008837
2022-01-09 14:01:47,980 iteration 3780 : loss : 0.030378, loss_ce: 0.014358
2022-01-09 14:01:50,398 iteration 3781 : loss : 0.027393, loss_ce: 0.008475
2022-01-09 14:01:52,794 iteration 3782 : loss : 0.032068, loss_ce: 0.012166
2022-01-09 14:01:55,283 iteration 3783 : loss : 0.024567, loss_ce: 0.011379
2022-01-09 14:01:57,721 iteration 3784 : loss : 0.033190, loss_ce: 0.010408
2022-01-09 14:02:00,134 iteration 3785 : loss : 0.039089, loss_ce: 0.013459
2022-01-09 14:02:02,506 iteration 3786 : loss : 0.029891, loss_ce: 0.010993
2022-01-09 14:02:04,800 iteration 3787 : loss : 0.030438, loss_ce: 0.011441
2022-01-09 14:02:07,152 iteration 3788 : loss : 0.034636, loss_ce: 0.011668
2022-01-09 14:02:09,472 iteration 3789 : loss : 0.036567, loss_ce: 0.015343
2022-01-09 14:02:11,854 iteration 3790 : loss : 0.037103, loss_ce: 0.013254
2022-01-09 14:02:14,280 iteration 3791 : loss : 0.022149, loss_ce: 0.008634
 56%|███████████████            | 223/400 [2:37:53<2:05:21, 42.49s/it]2022-01-09 14:02:16,776 iteration 3792 : loss : 0.025574, loss_ce: 0.009737
2022-01-09 14:02:19,114 iteration 3793 : loss : 0.020277, loss_ce: 0.005031
2022-01-09 14:02:21,464 iteration 3794 : loss : 0.024066, loss_ce: 0.010158
2022-01-09 14:02:23,843 iteration 3795 : loss : 0.025165, loss_ce: 0.007620
2022-01-09 14:02:26,249 iteration 3796 : loss : 0.025553, loss_ce: 0.008100
2022-01-09 14:02:28,669 iteration 3797 : loss : 0.023026, loss_ce: 0.007466
2022-01-09 14:02:31,123 iteration 3798 : loss : 0.022334, loss_ce: 0.008738
2022-01-09 14:02:33,578 iteration 3799 : loss : 0.041398, loss_ce: 0.020100
2022-01-09 14:02:36,021 iteration 3800 : loss : 0.041715, loss_ce: 0.020840
2022-01-09 14:02:38,446 iteration 3801 : loss : 0.032114, loss_ce: 0.008469
2022-01-09 14:02:41,038 iteration 3802 : loss : 0.028834, loss_ce: 0.011894
2022-01-09 14:02:43,409 iteration 3803 : loss : 0.024538, loss_ce: 0.009551
2022-01-09 14:02:45,803 iteration 3804 : loss : 0.023580, loss_ce: 0.008381
2022-01-09 14:02:48,184 iteration 3805 : loss : 0.030758, loss_ce: 0.011299
2022-01-09 14:02:50,547 iteration 3806 : loss : 0.025456, loss_ce: 0.011716
2022-01-09 14:02:53,013 iteration 3807 : loss : 0.029866, loss_ce: 0.009482
2022-01-09 14:02:55,432 iteration 3808 : loss : 0.034399, loss_ce: 0.014810
 56%|███████████████            | 224/400 [2:38:34<2:03:28, 42.09s/it]2022-01-09 14:02:57,881 iteration 3809 : loss : 0.023361, loss_ce: 0.010752
2022-01-09 14:03:00,203 iteration 3810 : loss : 0.024981, loss_ce: 0.008127
2022-01-09 14:03:02,466 iteration 3811 : loss : 0.023002, loss_ce: 0.008325
2022-01-09 14:03:04,982 iteration 3812 : loss : 0.019819, loss_ce: 0.006427
2022-01-09 14:03:07,343 iteration 3813 : loss : 0.035904, loss_ce: 0.015685
2022-01-09 14:03:09,802 iteration 3814 : loss : 0.026859, loss_ce: 0.012333
2022-01-09 14:03:12,471 iteration 3815 : loss : 0.030425, loss_ce: 0.011433
2022-01-09 14:03:14,839 iteration 3816 : loss : 0.018199, loss_ce: 0.006660
2022-01-09 14:03:17,111 iteration 3817 : loss : 0.022075, loss_ce: 0.007135
2022-01-09 14:03:19,523 iteration 3818 : loss : 0.026245, loss_ce: 0.007859
2022-01-09 14:03:21,929 iteration 3819 : loss : 0.052911, loss_ce: 0.023101
2022-01-09 14:03:24,294 iteration 3820 : loss : 0.016861, loss_ce: 0.007434
2022-01-09 14:03:26,725 iteration 3821 : loss : 0.027189, loss_ce: 0.012245
2022-01-09 14:03:29,046 iteration 3822 : loss : 0.025175, loss_ce: 0.006627
2022-01-09 14:03:31,548 iteration 3823 : loss : 0.029890, loss_ce: 0.010216
2022-01-09 14:03:33,948 iteration 3824 : loss : 0.029603, loss_ce: 0.012840
2022-01-09 14:03:33,948 Training Data Eval:
2022-01-09 14:03:46,726   Average segmentation loss on training set: 0.0168
2022-01-09 14:03:46,727 Validation Data Eval:
2022-01-09 14:03:51,275   Average segmentation loss on validation set: 0.0749
2022-01-09 14:03:53,641 iteration 3825 : loss : 0.023101, loss_ce: 0.008205
 56%|███████████████▏           | 225/400 [2:39:32<2:16:51, 46.92s/it]2022-01-09 14:03:56,127 iteration 3826 : loss : 0.026668, loss_ce: 0.011266
2022-01-09 14:03:58,649 iteration 3827 : loss : 0.032260, loss_ce: 0.012975
2022-01-09 14:04:01,060 iteration 3828 : loss : 0.019997, loss_ce: 0.010498
2022-01-09 14:04:03,462 iteration 3829 : loss : 0.019280, loss_ce: 0.007348
2022-01-09 14:04:05,913 iteration 3830 : loss : 0.035092, loss_ce: 0.009728
2022-01-09 14:04:08,428 iteration 3831 : loss : 0.032943, loss_ce: 0.012645
2022-01-09 14:04:10,830 iteration 3832 : loss : 0.024054, loss_ce: 0.011389
2022-01-09 14:04:13,342 iteration 3833 : loss : 0.035148, loss_ce: 0.011547
2022-01-09 14:04:15,731 iteration 3834 : loss : 0.026599, loss_ce: 0.008902
2022-01-09 14:04:18,127 iteration 3835 : loss : 0.037154, loss_ce: 0.009587
2022-01-09 14:04:20,410 iteration 3836 : loss : 0.019432, loss_ce: 0.008411
2022-01-09 14:04:22,921 iteration 3837 : loss : 0.023218, loss_ce: 0.009993
2022-01-09 14:04:25,370 iteration 3838 : loss : 0.028484, loss_ce: 0.012105
2022-01-09 14:04:27,695 iteration 3839 : loss : 0.028007, loss_ce: 0.008557
2022-01-09 14:04:30,114 iteration 3840 : loss : 0.030699, loss_ce: 0.013745
2022-01-09 14:04:32,483 iteration 3841 : loss : 0.022426, loss_ce: 0.008713
2022-01-09 14:04:34,891 iteration 3842 : loss : 0.068047, loss_ce: 0.013513
 56%|███████████████▎           | 226/400 [2:40:14<2:11:08, 45.22s/it]2022-01-09 14:04:37,314 iteration 3843 : loss : 0.027733, loss_ce: 0.010081
2022-01-09 14:04:39,737 iteration 3844 : loss : 0.024498, loss_ce: 0.008407
2022-01-09 14:04:42,197 iteration 3845 : loss : 0.033015, loss_ce: 0.010394
2022-01-09 14:04:44,582 iteration 3846 : loss : 0.045674, loss_ce: 0.017567
2022-01-09 14:04:47,050 iteration 3847 : loss : 0.033917, loss_ce: 0.011493
2022-01-09 14:04:49,335 iteration 3848 : loss : 0.037986, loss_ce: 0.013246
2022-01-09 14:04:51,631 iteration 3849 : loss : 0.021891, loss_ce: 0.008600
2022-01-09 14:04:54,018 iteration 3850 : loss : 0.039215, loss_ce: 0.011639
2022-01-09 14:04:56,475 iteration 3851 : loss : 0.045046, loss_ce: 0.011467
2022-01-09 14:04:58,958 iteration 3852 : loss : 0.033898, loss_ce: 0.012470
2022-01-09 14:05:01,390 iteration 3853 : loss : 0.023327, loss_ce: 0.008577
2022-01-09 14:05:03,913 iteration 3854 : loss : 0.020010, loss_ce: 0.008076
2022-01-09 14:05:06,362 iteration 3855 : loss : 0.034128, loss_ce: 0.008871
2022-01-09 14:05:08,837 iteration 3856 : loss : 0.031714, loss_ce: 0.015767
2022-01-09 14:05:11,156 iteration 3857 : loss : 0.039970, loss_ce: 0.012845
2022-01-09 14:05:13,683 iteration 3858 : loss : 0.028784, loss_ce: 0.012290
2022-01-09 14:05:16,010 iteration 3859 : loss : 0.026433, loss_ce: 0.011779
 57%|███████████████▎           | 227/400 [2:40:55<2:06:50, 43.99s/it]2022-01-09 14:05:18,477 iteration 3860 : loss : 0.023220, loss_ce: 0.010688
2022-01-09 14:05:20,895 iteration 3861 : loss : 0.033792, loss_ce: 0.013546
2022-01-09 14:05:23,354 iteration 3862 : loss : 0.032693, loss_ce: 0.009380
2022-01-09 14:05:25,796 iteration 3863 : loss : 0.028634, loss_ce: 0.012875
2022-01-09 14:05:28,162 iteration 3864 : loss : 0.026561, loss_ce: 0.009670
2022-01-09 14:05:30,548 iteration 3865 : loss : 0.029840, loss_ce: 0.012676
2022-01-09 14:05:32,884 iteration 3866 : loss : 0.023727, loss_ce: 0.010918
2022-01-09 14:05:35,253 iteration 3867 : loss : 0.033845, loss_ce: 0.012898
2022-01-09 14:05:37,661 iteration 3868 : loss : 0.024497, loss_ce: 0.009701
2022-01-09 14:05:40,112 iteration 3869 : loss : 0.028792, loss_ce: 0.007405
2022-01-09 14:05:42,534 iteration 3870 : loss : 0.027387, loss_ce: 0.009107
2022-01-09 14:05:44,945 iteration 3871 : loss : 0.033949, loss_ce: 0.013770
2022-01-09 14:05:47,335 iteration 3872 : loss : 0.036647, loss_ce: 0.011424
2022-01-09 14:05:49,720 iteration 3873 : loss : 0.026009, loss_ce: 0.007684
2022-01-09 14:05:52,142 iteration 3874 : loss : 0.029034, loss_ce: 0.009944
2022-01-09 14:05:54,460 iteration 3875 : loss : 0.028779, loss_ce: 0.009696
2022-01-09 14:05:56,891 iteration 3876 : loss : 0.036169, loss_ce: 0.011648
 57%|███████████████▍           | 228/400 [2:41:36<2:03:26, 43.06s/it]2022-01-09 14:05:59,288 iteration 3877 : loss : 0.020808, loss_ce: 0.008217
2022-01-09 14:06:01,869 iteration 3878 : loss : 0.023660, loss_ce: 0.008367
2022-01-09 14:06:04,307 iteration 3879 : loss : 0.021416, loss_ce: 0.011251
2022-01-09 14:06:06,676 iteration 3880 : loss : 0.020159, loss_ce: 0.007124
2022-01-09 14:06:09,095 iteration 3881 : loss : 0.029958, loss_ce: 0.009201
2022-01-09 14:06:11,516 iteration 3882 : loss : 0.023314, loss_ce: 0.010537
2022-01-09 14:06:14,141 iteration 3883 : loss : 0.026629, loss_ce: 0.009635
2022-01-09 14:06:16,559 iteration 3884 : loss : 0.021610, loss_ce: 0.007786
2022-01-09 14:06:18,891 iteration 3885 : loss : 0.021750, loss_ce: 0.006931
2022-01-09 14:06:21,381 iteration 3886 : loss : 0.026499, loss_ce: 0.010633
2022-01-09 14:06:23,786 iteration 3887 : loss : 0.025352, loss_ce: 0.009556
2022-01-09 14:06:26,234 iteration 3888 : loss : 0.026339, loss_ce: 0.012934
2022-01-09 14:06:28,614 iteration 3889 : loss : 0.034722, loss_ce: 0.008330
2022-01-09 14:06:31,134 iteration 3890 : loss : 0.022968, loss_ce: 0.007052
2022-01-09 14:06:33,630 iteration 3891 : loss : 0.031345, loss_ce: 0.016173
2022-01-09 14:06:36,043 iteration 3892 : loss : 0.026687, loss_ce: 0.009590
2022-01-09 14:06:38,389 iteration 3893 : loss : 0.041301, loss_ce: 0.010684
 57%|███████████████▍           | 229/400 [2:42:17<2:01:22, 42.59s/it]2022-01-09 14:06:40,933 iteration 3894 : loss : 0.036574, loss_ce: 0.012732
2022-01-09 14:06:43,346 iteration 3895 : loss : 0.026061, loss_ce: 0.011832
2022-01-09 14:06:45,705 iteration 3896 : loss : 0.020835, loss_ce: 0.008749
2022-01-09 14:06:48,128 iteration 3897 : loss : 0.031403, loss_ce: 0.009377
2022-01-09 14:06:50,533 iteration 3898 : loss : 0.034770, loss_ce: 0.008841
2022-01-09 14:06:52,956 iteration 3899 : loss : 0.027292, loss_ce: 0.008921
2022-01-09 14:06:55,349 iteration 3900 : loss : 0.020868, loss_ce: 0.009106
2022-01-09 14:06:57,694 iteration 3901 : loss : 0.020957, loss_ce: 0.010489
2022-01-09 14:07:00,061 iteration 3902 : loss : 0.019431, loss_ce: 0.006137
2022-01-09 14:07:02,375 iteration 3903 : loss : 0.019044, loss_ce: 0.006052
2022-01-09 14:07:04,753 iteration 3904 : loss : 0.024689, loss_ce: 0.010276
2022-01-09 14:07:07,090 iteration 3905 : loss : 0.031645, loss_ce: 0.017103
2022-01-09 14:07:09,369 iteration 3906 : loss : 0.034041, loss_ce: 0.010191
2022-01-09 14:07:11,705 iteration 3907 : loss : 0.026862, loss_ce: 0.008208
2022-01-09 14:07:14,074 iteration 3908 : loss : 0.024310, loss_ce: 0.008217
2022-01-09 14:07:16,450 iteration 3909 : loss : 0.025424, loss_ce: 0.009984
2022-01-09 14:07:16,450 Training Data Eval:
2022-01-09 14:07:29,311   Average segmentation loss on training set: 0.0175
2022-01-09 14:07:29,311 Validation Data Eval:
2022-01-09 14:07:33,837   Average segmentation loss on validation set: 0.0684
2022-01-09 14:07:36,290 iteration 3910 : loss : 0.029007, loss_ce: 0.012686
 57%|███████████████▌           | 230/400 [2:43:15<2:13:40, 47.18s/it]2022-01-09 14:07:38,652 iteration 3911 : loss : 0.024294, loss_ce: 0.010421
2022-01-09 14:07:40,963 iteration 3912 : loss : 0.032709, loss_ce: 0.011113
2022-01-09 14:07:43,342 iteration 3913 : loss : 0.030597, loss_ce: 0.013193
2022-01-09 14:07:45,653 iteration 3914 : loss : 0.016579, loss_ce: 0.007062
2022-01-09 14:07:48,047 iteration 3915 : loss : 0.034484, loss_ce: 0.010854
2022-01-09 14:07:50,427 iteration 3916 : loss : 0.022557, loss_ce: 0.007721
2022-01-09 14:07:52,743 iteration 3917 : loss : 0.024286, loss_ce: 0.007795
2022-01-09 14:07:55,022 iteration 3918 : loss : 0.021337, loss_ce: 0.006835
2022-01-09 14:07:57,392 iteration 3919 : loss : 0.025455, loss_ce: 0.008704
2022-01-09 14:07:59,851 iteration 3920 : loss : 0.072731, loss_ce: 0.009607
2022-01-09 14:08:02,252 iteration 3921 : loss : 0.022095, loss_ce: 0.006972
2022-01-09 14:08:04,652 iteration 3922 : loss : 0.046151, loss_ce: 0.012821
2022-01-09 14:08:07,117 iteration 3923 : loss : 0.053508, loss_ce: 0.025491
2022-01-09 14:08:09,494 iteration 3924 : loss : 0.031483, loss_ce: 0.013004
2022-01-09 14:08:11,787 iteration 3925 : loss : 0.050681, loss_ce: 0.029228
2022-01-09 14:08:14,223 iteration 3926 : loss : 0.029224, loss_ce: 0.013118
2022-01-09 14:08:16,558 iteration 3927 : loss : 0.028634, loss_ce: 0.013307
 58%|███████████████▌           | 231/400 [2:43:55<2:07:03, 45.11s/it]2022-01-09 14:08:18,867 iteration 3928 : loss : 0.022912, loss_ce: 0.009009
2022-01-09 14:08:21,070 iteration 3929 : loss : 0.027701, loss_ce: 0.016229
2022-01-09 14:08:23,347 iteration 3930 : loss : 0.030713, loss_ce: 0.008869
2022-01-09 14:08:25,527 iteration 3931 : loss : 0.029246, loss_ce: 0.007554
2022-01-09 14:08:27,817 iteration 3932 : loss : 0.022482, loss_ce: 0.008617
2022-01-09 14:08:30,082 iteration 3933 : loss : 0.039552, loss_ce: 0.020253
2022-01-09 14:08:32,474 iteration 3934 : loss : 0.028251, loss_ce: 0.010070
2022-01-09 14:08:34,868 iteration 3935 : loss : 0.035002, loss_ce: 0.012088
2022-01-09 14:08:37,188 iteration 3936 : loss : 0.020949, loss_ce: 0.006938
2022-01-09 14:08:39,487 iteration 3937 : loss : 0.031333, loss_ce: 0.009173
2022-01-09 14:08:41,853 iteration 3938 : loss : 0.023100, loss_ce: 0.006476
2022-01-09 14:08:44,209 iteration 3939 : loss : 0.027281, loss_ce: 0.007582
2022-01-09 14:08:46,612 iteration 3940 : loss : 0.023821, loss_ce: 0.011688
2022-01-09 14:08:48,944 iteration 3941 : loss : 0.020274, loss_ce: 0.006153
2022-01-09 14:08:51,192 iteration 3942 : loss : 0.020028, loss_ce: 0.010452
2022-01-09 14:08:53,412 iteration 3943 : loss : 0.029855, loss_ce: 0.011539
2022-01-09 14:08:55,737 iteration 3944 : loss : 0.029598, loss_ce: 0.008933
 58%|███████████████▋           | 232/400 [2:44:34<2:01:19, 43.33s/it]2022-01-09 14:08:58,163 iteration 3945 : loss : 0.024114, loss_ce: 0.008076
2022-01-09 14:09:00,513 iteration 3946 : loss : 0.020349, loss_ce: 0.008289
2022-01-09 14:09:02,877 iteration 3947 : loss : 0.026874, loss_ce: 0.010685
2022-01-09 14:09:05,279 iteration 3948 : loss : 0.026838, loss_ce: 0.012638
2022-01-09 14:09:07,622 iteration 3949 : loss : 0.034152, loss_ce: 0.010731
2022-01-09 14:09:09,844 iteration 3950 : loss : 0.020173, loss_ce: 0.009386
2022-01-09 14:09:12,088 iteration 3951 : loss : 0.016959, loss_ce: 0.003811
2022-01-09 14:09:14,584 iteration 3952 : loss : 0.030072, loss_ce: 0.015260
2022-01-09 14:09:16,957 iteration 3953 : loss : 0.018221, loss_ce: 0.007859
2022-01-09 14:09:19,243 iteration 3954 : loss : 0.025998, loss_ce: 0.010353
2022-01-09 14:09:21,641 iteration 3955 : loss : 0.027860, loss_ce: 0.011682
2022-01-09 14:09:24,055 iteration 3956 : loss : 0.030213, loss_ce: 0.014278
2022-01-09 14:09:26,485 iteration 3957 : loss : 0.043715, loss_ce: 0.011777
2022-01-09 14:09:28,912 iteration 3958 : loss : 0.027990, loss_ce: 0.012753
2022-01-09 14:09:31,158 iteration 3959 : loss : 0.021727, loss_ce: 0.006033
2022-01-09 14:09:33,502 iteration 3960 : loss : 0.032411, loss_ce: 0.011067
2022-01-09 14:09:35,818 iteration 3961 : loss : 0.032943, loss_ce: 0.008942
 58%|███████████████▋           | 233/400 [2:45:15<1:57:53, 42.36s/it]2022-01-09 14:09:38,203 iteration 3962 : loss : 0.028920, loss_ce: 0.011541
2022-01-09 14:09:40,515 iteration 3963 : loss : 0.048567, loss_ce: 0.023559
2022-01-09 14:09:42,794 iteration 3964 : loss : 0.017504, loss_ce: 0.005691
2022-01-09 14:09:45,092 iteration 3965 : loss : 0.019244, loss_ce: 0.008643
2022-01-09 14:09:47,412 iteration 3966 : loss : 0.041607, loss_ce: 0.020012
2022-01-09 14:09:49,746 iteration 3967 : loss : 0.041987, loss_ce: 0.010552
2022-01-09 14:09:52,042 iteration 3968 : loss : 0.022352, loss_ce: 0.008492
2022-01-09 14:09:54,359 iteration 3969 : loss : 0.022273, loss_ce: 0.007447
2022-01-09 14:09:56,734 iteration 3970 : loss : 0.033701, loss_ce: 0.009126
2022-01-09 14:09:59,130 iteration 3971 : loss : 0.031694, loss_ce: 0.010970
2022-01-09 14:10:01,471 iteration 3972 : loss : 0.026833, loss_ce: 0.010845
2022-01-09 14:10:03,791 iteration 3973 : loss : 0.025196, loss_ce: 0.011904
2022-01-09 14:10:06,198 iteration 3974 : loss : 0.021510, loss_ce: 0.010807
2022-01-09 14:10:08,602 iteration 3975 : loss : 0.027201, loss_ce: 0.008047
2022-01-09 14:10:10,955 iteration 3976 : loss : 0.023037, loss_ce: 0.007879
2022-01-09 14:10:13,309 iteration 3977 : loss : 0.028431, loss_ce: 0.012782
2022-01-09 14:10:15,728 iteration 3978 : loss : 0.029887, loss_ce: 0.015919
 58%|███████████████▊           | 234/400 [2:45:54<1:55:09, 41.62s/it]2022-01-09 14:10:18,176 iteration 3979 : loss : 0.038606, loss_ce: 0.019790
2022-01-09 14:10:20,418 iteration 3980 : loss : 0.024784, loss_ce: 0.009845
2022-01-09 14:10:22,782 iteration 3981 : loss : 0.032384, loss_ce: 0.010109
2022-01-09 14:10:25,140 iteration 3982 : loss : 0.022674, loss_ce: 0.011258
2022-01-09 14:10:27,532 iteration 3983 : loss : 0.029396, loss_ce: 0.007719
2022-01-09 14:10:29,934 iteration 3984 : loss : 0.034485, loss_ce: 0.015663
2022-01-09 14:10:32,304 iteration 3985 : loss : 0.027351, loss_ce: 0.009838
2022-01-09 14:10:34,616 iteration 3986 : loss : 0.029847, loss_ce: 0.011272
2022-01-09 14:10:36,896 iteration 3987 : loss : 0.028092, loss_ce: 0.014268
2022-01-09 14:10:39,227 iteration 3988 : loss : 0.022945, loss_ce: 0.007922
2022-01-09 14:10:41,625 iteration 3989 : loss : 0.030788, loss_ce: 0.011752
2022-01-09 14:10:43,969 iteration 3990 : loss : 0.027743, loss_ce: 0.011095
2022-01-09 14:10:46,250 iteration 3991 : loss : 0.023072, loss_ce: 0.010575
2022-01-09 14:10:48,541 iteration 3992 : loss : 0.023769, loss_ce: 0.010115
2022-01-09 14:10:50,828 iteration 3993 : loss : 0.025378, loss_ce: 0.010175
2022-01-09 14:10:53,114 iteration 3994 : loss : 0.021779, loss_ce: 0.007206
2022-01-09 14:10:53,115 Training Data Eval:
2022-01-09 14:11:05,713   Average segmentation loss on training set: 0.0145
2022-01-09 14:11:05,713 Validation Data Eval:
2022-01-09 14:11:10,242   Average segmentation loss on validation set: 0.0692
2022-01-09 14:11:12,715 iteration 3995 : loss : 0.025032, loss_ce: 0.008829
 59%|███████████████▊           | 235/400 [2:46:51<2:07:07, 46.23s/it]2022-01-09 14:11:15,157 iteration 3996 : loss : 0.023262, loss_ce: 0.010838
2022-01-09 14:11:17,475 iteration 3997 : loss : 0.022226, loss_ce: 0.010873
2022-01-09 14:11:19,737 iteration 3998 : loss : 0.020777, loss_ce: 0.005748
2022-01-09 14:11:22,043 iteration 3999 : loss : 0.033854, loss_ce: 0.009073
2022-01-09 14:11:24,343 iteration 4000 : loss : 0.018814, loss_ce: 0.007435
2022-01-09 14:11:26,753 iteration 4001 : loss : 0.019914, loss_ce: 0.010439
2022-01-09 14:11:29,002 iteration 4002 : loss : 0.023004, loss_ce: 0.008052
2022-01-09 14:11:31,292 iteration 4003 : loss : 0.031155, loss_ce: 0.009779
2022-01-09 14:11:33,549 iteration 4004 : loss : 0.034384, loss_ce: 0.014754
2022-01-09 14:11:35,917 iteration 4005 : loss : 0.026275, loss_ce: 0.009949
2022-01-09 14:11:38,278 iteration 4006 : loss : 0.025586, loss_ce: 0.009487
2022-01-09 14:11:40,606 iteration 4007 : loss : 0.030634, loss_ce: 0.009871
2022-01-09 14:11:42,899 iteration 4008 : loss : 0.032060, loss_ce: 0.016878
2022-01-09 14:11:45,241 iteration 4009 : loss : 0.017801, loss_ce: 0.006446
2022-01-09 14:11:47,625 iteration 4010 : loss : 0.026163, loss_ce: 0.009677
2022-01-09 14:11:50,040 iteration 4011 : loss : 0.025416, loss_ce: 0.009249
2022-01-09 14:11:52,459 iteration 4012 : loss : 0.023899, loss_ce: 0.009078
 59%|███████████████▉           | 236/400 [2:47:31<2:01:02, 44.28s/it]2022-01-09 14:11:54,798 iteration 4013 : loss : 0.015257, loss_ce: 0.007415
2022-01-09 14:11:57,181 iteration 4014 : loss : 0.020266, loss_ce: 0.007940
2022-01-09 14:11:59,418 iteration 4015 : loss : 0.025968, loss_ce: 0.013684
2022-01-09 14:12:01,804 iteration 4016 : loss : 0.017307, loss_ce: 0.006588
2022-01-09 14:12:04,063 iteration 4017 : loss : 0.037940, loss_ce: 0.010308
2022-01-09 14:12:06,213 iteration 4018 : loss : 0.022791, loss_ce: 0.008724
2022-01-09 14:12:08,472 iteration 4019 : loss : 0.031176, loss_ce: 0.010471
2022-01-09 14:12:10,742 iteration 4020 : loss : 0.024539, loss_ce: 0.009885
2022-01-09 14:12:13,149 iteration 4021 : loss : 0.029475, loss_ce: 0.008853
2022-01-09 14:12:15,577 iteration 4022 : loss : 0.037444, loss_ce: 0.011303
2022-01-09 14:12:17,892 iteration 4023 : loss : 0.020239, loss_ce: 0.009005
2022-01-09 14:12:20,267 iteration 4024 : loss : 0.030135, loss_ce: 0.010662
2022-01-09 14:12:22,536 iteration 4025 : loss : 0.025000, loss_ce: 0.008355
2022-01-09 14:12:24,833 iteration 4026 : loss : 0.030628, loss_ce: 0.010235
2022-01-09 14:12:27,020 iteration 4027 : loss : 0.020697, loss_ce: 0.006971
2022-01-09 14:12:29,308 iteration 4028 : loss : 0.027917, loss_ce: 0.013052
2022-01-09 14:12:31,552 iteration 4029 : loss : 0.028579, loss_ce: 0.011454
 59%|███████████████▉           | 237/400 [2:48:10<1:56:04, 42.73s/it]2022-01-09 14:12:33,765 iteration 4030 : loss : 0.023492, loss_ce: 0.008392
2022-01-09 14:12:36,007 iteration 4031 : loss : 0.026268, loss_ce: 0.011679
2022-01-09 14:12:38,264 iteration 4032 : loss : 0.017372, loss_ce: 0.005343
2022-01-09 14:12:40,561 iteration 4033 : loss : 0.021680, loss_ce: 0.008241
2022-01-09 14:12:42,933 iteration 4034 : loss : 0.023254, loss_ce: 0.010145
2022-01-09 14:12:45,211 iteration 4035 : loss : 0.025433, loss_ce: 0.007904
2022-01-09 14:12:47,445 iteration 4036 : loss : 0.022551, loss_ce: 0.009342
2022-01-09 14:12:49,645 iteration 4037 : loss : 0.021481, loss_ce: 0.011615
2022-01-09 14:12:51,951 iteration 4038 : loss : 0.020832, loss_ce: 0.008475
2022-01-09 14:12:54,305 iteration 4039 : loss : 0.031129, loss_ce: 0.010719
2022-01-09 14:12:56,665 iteration 4040 : loss : 0.022988, loss_ce: 0.008080
2022-01-09 14:12:59,080 iteration 4041 : loss : 0.022445, loss_ce: 0.009392
2022-01-09 14:13:01,446 iteration 4042 : loss : 0.025975, loss_ce: 0.009701
2022-01-09 14:13:03,741 iteration 4043 : loss : 0.022266, loss_ce: 0.008401
2022-01-09 14:13:06,021 iteration 4044 : loss : 0.026119, loss_ce: 0.010391
2022-01-09 14:13:08,373 iteration 4045 : loss : 0.026315, loss_ce: 0.007371
2022-01-09 14:13:10,804 iteration 4046 : loss : 0.028227, loss_ce: 0.009665
 60%|████████████████           | 238/400 [2:48:49<1:52:32, 41.68s/it]2022-01-09 14:13:13,243 iteration 4047 : loss : 0.019715, loss_ce: 0.008382
2022-01-09 14:13:15,643 iteration 4048 : loss : 0.025437, loss_ce: 0.008085
2022-01-09 14:13:18,005 iteration 4049 : loss : 0.020518, loss_ce: 0.006046
2022-01-09 14:13:20,292 iteration 4050 : loss : 0.024681, loss_ce: 0.007851
2022-01-09 14:13:22,664 iteration 4051 : loss : 0.018252, loss_ce: 0.007403
2022-01-09 14:13:25,018 iteration 4052 : loss : 0.017672, loss_ce: 0.006884
2022-01-09 14:13:27,404 iteration 4053 : loss : 0.030967, loss_ce: 0.007743
2022-01-09 14:13:29,750 iteration 4054 : loss : 0.019234, loss_ce: 0.007744
2022-01-09 14:13:32,097 iteration 4055 : loss : 0.022980, loss_ce: 0.011052
2022-01-09 14:13:34,469 iteration 4056 : loss : 0.023147, loss_ce: 0.010227
2022-01-09 14:13:36,815 iteration 4057 : loss : 0.021074, loss_ce: 0.006546
2022-01-09 14:13:39,145 iteration 4058 : loss : 0.027888, loss_ce: 0.012203
2022-01-09 14:13:41,582 iteration 4059 : loss : 0.027489, loss_ce: 0.009294
2022-01-09 14:13:43,953 iteration 4060 : loss : 0.017603, loss_ce: 0.007196
2022-01-09 14:13:46,384 iteration 4061 : loss : 0.019941, loss_ce: 0.008833
2022-01-09 14:13:48,760 iteration 4062 : loss : 0.017897, loss_ce: 0.008067
2022-01-09 14:13:51,172 iteration 4063 : loss : 0.024514, loss_ce: 0.008825
 60%|████████████████▏          | 239/400 [2:49:30<1:50:47, 41.29s/it]2022-01-09 14:13:53,508 iteration 4064 : loss : 0.017930, loss_ce: 0.006659
2022-01-09 14:13:55,811 iteration 4065 : loss : 0.022281, loss_ce: 0.005761
2022-01-09 14:13:58,188 iteration 4066 : loss : 0.022446, loss_ce: 0.007418
2022-01-09 14:14:00,616 iteration 4067 : loss : 0.023707, loss_ce: 0.008884
2022-01-09 14:14:03,006 iteration 4068 : loss : 0.025969, loss_ce: 0.010098
2022-01-09 14:14:05,362 iteration 4069 : loss : 0.039135, loss_ce: 0.021644
2022-01-09 14:14:07,709 iteration 4070 : loss : 0.020335, loss_ce: 0.006391
2022-01-09 14:14:10,082 iteration 4071 : loss : 0.024233, loss_ce: 0.010210
2022-01-09 14:14:12,490 iteration 4072 : loss : 0.017915, loss_ce: 0.006714
2022-01-09 14:14:14,863 iteration 4073 : loss : 0.024212, loss_ce: 0.010993
2022-01-09 14:14:17,244 iteration 4074 : loss : 0.021301, loss_ce: 0.008762
2022-01-09 14:14:19,742 iteration 4075 : loss : 0.026108, loss_ce: 0.008870
2022-01-09 14:14:22,134 iteration 4076 : loss : 0.016572, loss_ce: 0.006998
2022-01-09 14:14:24,537 iteration 4077 : loss : 0.021805, loss_ce: 0.009563
2022-01-09 14:14:26,933 iteration 4078 : loss : 0.022278, loss_ce: 0.008117
2022-01-09 14:14:29,199 iteration 4079 : loss : 0.020140, loss_ce: 0.007394
2022-01-09 14:14:29,199 Training Data Eval:
2022-01-09 14:14:42,275   Average segmentation loss on training set: 0.0142
2022-01-09 14:14:42,276 Validation Data Eval:
2022-01-09 14:14:46,791   Average segmentation loss on validation set: 0.0597
2022-01-09 14:14:52,597 Found new lowest validation loss at iteration 4079! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 14:14:54,268 iteration 4080 : loss : 0.029192, loss_ce: 0.011461
 60%|████████████████▏          | 240/400 [2:50:33<2:07:33, 47.83s/it]2022-01-09 14:14:55,850 iteration 4081 : loss : 0.018729, loss_ce: 0.007780
2022-01-09 14:14:57,538 iteration 4082 : loss : 0.021072, loss_ce: 0.008403
2022-01-09 14:14:59,367 iteration 4083 : loss : 0.021932, loss_ce: 0.011573
2022-01-09 14:15:01,355 iteration 4084 : loss : 0.024448, loss_ce: 0.008087
2022-01-09 14:15:03,438 iteration 4085 : loss : 0.031453, loss_ce: 0.009664
2022-01-09 14:15:05,579 iteration 4086 : loss : 0.025088, loss_ce: 0.010983
2022-01-09 14:15:07,729 iteration 4087 : loss : 0.025483, loss_ce: 0.006753
2022-01-09 14:15:09,895 iteration 4088 : loss : 0.028513, loss_ce: 0.014395
2022-01-09 14:15:12,173 iteration 4089 : loss : 0.021792, loss_ce: 0.008268
2022-01-09 14:15:14,489 iteration 4090 : loss : 0.017880, loss_ce: 0.007342
2022-01-09 14:15:16,748 iteration 4091 : loss : 0.029186, loss_ce: 0.010167
2022-01-09 14:15:19,113 iteration 4092 : loss : 0.026647, loss_ce: 0.013207
2022-01-09 14:15:21,445 iteration 4093 : loss : 0.017939, loss_ce: 0.007451
2022-01-09 14:15:23,978 iteration 4094 : loss : 0.016242, loss_ce: 0.005289
2022-01-09 14:15:26,410 iteration 4095 : loss : 0.019517, loss_ce: 0.007549
2022-01-09 14:15:28,778 iteration 4096 : loss : 0.021170, loss_ce: 0.008649
2022-01-09 14:15:31,202 iteration 4097 : loss : 0.018125, loss_ce: 0.008990
 60%|████████████████▎          | 241/400 [2:51:10<1:58:05, 44.56s/it]2022-01-09 14:15:33,612 iteration 4098 : loss : 0.028532, loss_ce: 0.010402
2022-01-09 14:15:35,873 iteration 4099 : loss : 0.030664, loss_ce: 0.006621
2022-01-09 14:15:38,102 iteration 4100 : loss : 0.021050, loss_ce: 0.008721
2022-01-09 14:15:40,433 iteration 4101 : loss : 0.018670, loss_ce: 0.007494
2022-01-09 14:15:42,778 iteration 4102 : loss : 0.023855, loss_ce: 0.010197
2022-01-09 14:15:45,263 iteration 4103 : loss : 0.016164, loss_ce: 0.006694
2022-01-09 14:15:47,577 iteration 4104 : loss : 0.021532, loss_ce: 0.011071
2022-01-09 14:15:49,927 iteration 4105 : loss : 0.033425, loss_ce: 0.013280
2022-01-09 14:15:52,258 iteration 4106 : loss : 0.029163, loss_ce: 0.004946
2022-01-09 14:15:54,804 iteration 4107 : loss : 0.028020, loss_ce: 0.013845
2022-01-09 14:15:57,223 iteration 4108 : loss : 0.022262, loss_ce: 0.007859
2022-01-09 14:15:59,576 iteration 4109 : loss : 0.019021, loss_ce: 0.004373
2022-01-09 14:16:01,952 iteration 4110 : loss : 0.022283, loss_ce: 0.009678
2022-01-09 14:16:04,400 iteration 4111 : loss : 0.020337, loss_ce: 0.007788
2022-01-09 14:16:06,783 iteration 4112 : loss : 0.035978, loss_ce: 0.013546
2022-01-09 14:16:09,350 iteration 4113 : loss : 0.022467, loss_ce: 0.008517
2022-01-09 14:16:11,794 iteration 4114 : loss : 0.023095, loss_ce: 0.008288
 60%|████████████████▎          | 242/400 [2:51:50<1:54:12, 43.37s/it]2022-01-09 14:16:14,137 iteration 4115 : loss : 0.020855, loss_ce: 0.005058
2022-01-09 14:16:16,448 iteration 4116 : loss : 0.019955, loss_ce: 0.007904
2022-01-09 14:16:18,949 iteration 4117 : loss : 0.026843, loss_ce: 0.006789
2022-01-09 14:16:21,387 iteration 4118 : loss : 0.025810, loss_ce: 0.011283
2022-01-09 14:16:23,828 iteration 4119 : loss : 0.020010, loss_ce: 0.008760
2022-01-09 14:16:26,217 iteration 4120 : loss : 0.052277, loss_ce: 0.007999
2022-01-09 14:16:28,562 iteration 4121 : loss : 0.024660, loss_ce: 0.011847
2022-01-09 14:16:30,939 iteration 4122 : loss : 0.020196, loss_ce: 0.006789
2022-01-09 14:16:33,382 iteration 4123 : loss : 0.035278, loss_ce: 0.012494
2022-01-09 14:16:35,705 iteration 4124 : loss : 0.025264, loss_ce: 0.009799
2022-01-09 14:16:38,178 iteration 4125 : loss : 0.028464, loss_ce: 0.007116
2022-01-09 14:16:40,762 iteration 4126 : loss : 0.022016, loss_ce: 0.010503
2022-01-09 14:16:43,242 iteration 4127 : loss : 0.037098, loss_ce: 0.015382
2022-01-09 14:16:45,581 iteration 4128 : loss : 0.029463, loss_ce: 0.014091
2022-01-09 14:16:48,023 iteration 4129 : loss : 0.024486, loss_ce: 0.009506
2022-01-09 14:16:50,500 iteration 4130 : loss : 0.018230, loss_ce: 0.009753
2022-01-09 14:16:52,860 iteration 4131 : loss : 0.015591, loss_ce: 0.004367
 61%|████████████████▍          | 243/400 [2:52:32<1:51:40, 42.68s/it]2022-01-09 14:16:55,318 iteration 4132 : loss : 0.022017, loss_ce: 0.008143
2022-01-09 14:16:57,745 iteration 4133 : loss : 0.029466, loss_ce: 0.013901
2022-01-09 14:17:00,128 iteration 4134 : loss : 0.025162, loss_ce: 0.010038
2022-01-09 14:17:02,552 iteration 4135 : loss : 0.021442, loss_ce: 0.008467
2022-01-09 14:17:04,895 iteration 4136 : loss : 0.033469, loss_ce: 0.018997
2022-01-09 14:17:07,239 iteration 4137 : loss : 0.021921, loss_ce: 0.011351
2022-01-09 14:17:09,644 iteration 4138 : loss : 0.021659, loss_ce: 0.009884
2022-01-09 14:17:12,039 iteration 4139 : loss : 0.026619, loss_ce: 0.007237
2022-01-09 14:17:14,392 iteration 4140 : loss : 0.028671, loss_ce: 0.009675
2022-01-09 14:17:16,791 iteration 4141 : loss : 0.023753, loss_ce: 0.005661
2022-01-09 14:17:19,195 iteration 4142 : loss : 0.047780, loss_ce: 0.018272
2022-01-09 14:17:21,614 iteration 4143 : loss : 0.026160, loss_ce: 0.006432
2022-01-09 14:17:23,983 iteration 4144 : loss : 0.023319, loss_ce: 0.009044
2022-01-09 14:17:26,433 iteration 4145 : loss : 0.021307, loss_ce: 0.005539
2022-01-09 14:17:28,807 iteration 4146 : loss : 0.049382, loss_ce: 0.019840
2022-01-09 14:17:31,235 iteration 4147 : loss : 0.023188, loss_ce: 0.008711
2022-01-09 14:17:33,671 iteration 4148 : loss : 0.016921, loss_ce: 0.006421
 61%|████████████████▍          | 244/400 [2:53:12<1:49:30, 42.12s/it]2022-01-09 14:17:36,203 iteration 4149 : loss : 0.050919, loss_ce: 0.017716
2022-01-09 14:17:38,604 iteration 4150 : loss : 0.022523, loss_ce: 0.005891
2022-01-09 14:17:41,040 iteration 4151 : loss : 0.024750, loss_ce: 0.013303
2022-01-09 14:17:43,360 iteration 4152 : loss : 0.016524, loss_ce: 0.006018
2022-01-09 14:17:45,756 iteration 4153 : loss : 0.038747, loss_ce: 0.010896
2022-01-09 14:17:48,108 iteration 4154 : loss : 0.036013, loss_ce: 0.013931
2022-01-09 14:17:50,452 iteration 4155 : loss : 0.028906, loss_ce: 0.009938
2022-01-09 14:17:52,806 iteration 4156 : loss : 0.015158, loss_ce: 0.006066
2022-01-09 14:17:55,206 iteration 4157 : loss : 0.022496, loss_ce: 0.007927
2022-01-09 14:17:57,663 iteration 4158 : loss : 0.026677, loss_ce: 0.011031
2022-01-09 14:18:00,099 iteration 4159 : loss : 0.024392, loss_ce: 0.011143
2022-01-09 14:18:02,478 iteration 4160 : loss : 0.026040, loss_ce: 0.011083
2022-01-09 14:18:04,931 iteration 4161 : loss : 0.018821, loss_ce: 0.007998
2022-01-09 14:18:07,279 iteration 4162 : loss : 0.027128, loss_ce: 0.010740
2022-01-09 14:18:09,719 iteration 4163 : loss : 0.028272, loss_ce: 0.008431
2022-01-09 14:18:12,266 iteration 4164 : loss : 0.027752, loss_ce: 0.012719
2022-01-09 14:18:12,266 Training Data Eval:
2022-01-09 14:18:25,210   Average segmentation loss on training set: 0.0153
2022-01-09 14:18:25,210 Validation Data Eval:
2022-01-09 14:18:29,868   Average segmentation loss on validation set: 0.0629
2022-01-09 14:18:32,278 iteration 4165 : loss : 0.028511, loss_ce: 0.011765
 61%|████████████████▌          | 245/400 [2:54:11<2:01:35, 47.07s/it]2022-01-09 14:18:34,644 iteration 4166 : loss : 0.018954, loss_ce: 0.008432
2022-01-09 14:18:37,220 iteration 4167 : loss : 0.024972, loss_ce: 0.006871
2022-01-09 14:18:39,698 iteration 4168 : loss : 0.023656, loss_ce: 0.009853
2022-01-09 14:18:42,086 iteration 4169 : loss : 0.027298, loss_ce: 0.011167
2022-01-09 14:18:44,468 iteration 4170 : loss : 0.028608, loss_ce: 0.011730
2022-01-09 14:18:46,803 iteration 4171 : loss : 0.024664, loss_ce: 0.010324
2022-01-09 14:18:49,129 iteration 4172 : loss : 0.026366, loss_ce: 0.010092
2022-01-09 14:18:51,598 iteration 4173 : loss : 0.019366, loss_ce: 0.006069
2022-01-09 14:18:54,005 iteration 4174 : loss : 0.034588, loss_ce: 0.013563
2022-01-09 14:18:56,433 iteration 4175 : loss : 0.019222, loss_ce: 0.005157
2022-01-09 14:18:58,996 iteration 4176 : loss : 0.031531, loss_ce: 0.010808
2022-01-09 14:19:01,500 iteration 4177 : loss : 0.018900, loss_ce: 0.008289
2022-01-09 14:19:03,930 iteration 4178 : loss : 0.017203, loss_ce: 0.007291
2022-01-09 14:19:06,336 iteration 4179 : loss : 0.028117, loss_ce: 0.008952
2022-01-09 14:19:08,705 iteration 4180 : loss : 0.027001, loss_ce: 0.008200
2022-01-09 14:19:11,092 iteration 4181 : loss : 0.022695, loss_ce: 0.009289
2022-01-09 14:19:13,492 iteration 4182 : loss : 0.036497, loss_ce: 0.015796
 62%|████████████████▌          | 246/400 [2:54:52<1:56:17, 45.31s/it]2022-01-09 14:19:15,918 iteration 4183 : loss : 0.031277, loss_ce: 0.008314
2022-01-09 14:19:18,350 iteration 4184 : loss : 0.020821, loss_ce: 0.007407
2022-01-09 14:19:20,837 iteration 4185 : loss : 0.035963, loss_ce: 0.011544
2022-01-09 14:19:23,271 iteration 4186 : loss : 0.022436, loss_ce: 0.007787
2022-01-09 14:19:25,632 iteration 4187 : loss : 0.019405, loss_ce: 0.007659
2022-01-09 14:19:27,952 iteration 4188 : loss : 0.019215, loss_ce: 0.007166
2022-01-09 14:19:30,324 iteration 4189 : loss : 0.022542, loss_ce: 0.007889
2022-01-09 14:19:32,782 iteration 4190 : loss : 0.035137, loss_ce: 0.017941
2022-01-09 14:19:35,121 iteration 4191 : loss : 0.020347, loss_ce: 0.005721
2022-01-09 14:19:37,396 iteration 4192 : loss : 0.017554, loss_ce: 0.009021
2022-01-09 14:19:39,638 iteration 4193 : loss : 0.017697, loss_ce: 0.005708
2022-01-09 14:19:41,970 iteration 4194 : loss : 0.020870, loss_ce: 0.007035
2022-01-09 14:19:44,496 iteration 4195 : loss : 0.017530, loss_ce: 0.007096
2022-01-09 14:19:46,854 iteration 4196 : loss : 0.017493, loss_ce: 0.006719
2022-01-09 14:19:49,176 iteration 4197 : loss : 0.020903, loss_ce: 0.008128
2022-01-09 14:19:51,500 iteration 4198 : loss : 0.021332, loss_ce: 0.005655
2022-01-09 14:19:53,938 iteration 4199 : loss : 0.018367, loss_ce: 0.007902
 62%|████████████████▋          | 247/400 [2:55:33<1:51:49, 43.85s/it]2022-01-09 14:19:56,338 iteration 4200 : loss : 0.021150, loss_ce: 0.006943
2022-01-09 14:19:58,680 iteration 4201 : loss : 0.029225, loss_ce: 0.015018
2022-01-09 14:20:01,087 iteration 4202 : loss : 0.020014, loss_ce: 0.009235
2022-01-09 14:20:03,532 iteration 4203 : loss : 0.032949, loss_ce: 0.013540
2022-01-09 14:20:05,862 iteration 4204 : loss : 0.019179, loss_ce: 0.007632
2022-01-09 14:20:08,120 iteration 4205 : loss : 0.015442, loss_ce: 0.005549
2022-01-09 14:20:10,520 iteration 4206 : loss : 0.018897, loss_ce: 0.006194
2022-01-09 14:20:12,855 iteration 4207 : loss : 0.015675, loss_ce: 0.007764
2022-01-09 14:20:15,336 iteration 4208 : loss : 0.025551, loss_ce: 0.008430
2022-01-09 14:20:17,771 iteration 4209 : loss : 0.021228, loss_ce: 0.006628
2022-01-09 14:20:20,172 iteration 4210 : loss : 0.017690, loss_ce: 0.006231
2022-01-09 14:20:22,591 iteration 4211 : loss : 0.016600, loss_ce: 0.006546
2022-01-09 14:20:24,935 iteration 4212 : loss : 0.015993, loss_ce: 0.006587
2022-01-09 14:20:27,363 iteration 4213 : loss : 0.022528, loss_ce: 0.008413
2022-01-09 14:20:29,756 iteration 4214 : loss : 0.046952, loss_ce: 0.021759
2022-01-09 14:20:32,041 iteration 4215 : loss : 0.033218, loss_ce: 0.008006
2022-01-09 14:20:34,319 iteration 4216 : loss : 0.024630, loss_ce: 0.008670
 62%|████████████████▋          | 248/400 [2:56:13<1:48:27, 42.81s/it]2022-01-09 14:20:36,652 iteration 4217 : loss : 0.045010, loss_ce: 0.011918
2022-01-09 14:20:39,005 iteration 4218 : loss : 0.042460, loss_ce: 0.024404
2022-01-09 14:20:41,466 iteration 4219 : loss : 0.019983, loss_ce: 0.007646
2022-01-09 14:20:43,876 iteration 4220 : loss : 0.025657, loss_ce: 0.008272
2022-01-09 14:20:46,245 iteration 4221 : loss : 0.025264, loss_ce: 0.007917
2022-01-09 14:20:48,639 iteration 4222 : loss : 0.018551, loss_ce: 0.007864
2022-01-09 14:20:51,099 iteration 4223 : loss : 0.052747, loss_ce: 0.011155
2022-01-09 14:20:53,396 iteration 4224 : loss : 0.027512, loss_ce: 0.009007
2022-01-09 14:20:55,785 iteration 4225 : loss : 0.026177, loss_ce: 0.012765
2022-01-09 14:20:58,245 iteration 4226 : loss : 0.025569, loss_ce: 0.009934
2022-01-09 14:21:00,568 iteration 4227 : loss : 0.030704, loss_ce: 0.009235
2022-01-09 14:21:02,969 iteration 4228 : loss : 0.031352, loss_ce: 0.015144
2022-01-09 14:21:05,260 iteration 4229 : loss : 0.021998, loss_ce: 0.008480
2022-01-09 14:21:07,606 iteration 4230 : loss : 0.024063, loss_ce: 0.008108
2022-01-09 14:21:09,966 iteration 4231 : loss : 0.024175, loss_ce: 0.008911
2022-01-09 14:21:12,353 iteration 4232 : loss : 0.032669, loss_ce: 0.016170
2022-01-09 14:21:14,603 iteration 4233 : loss : 0.020421, loss_ce: 0.007863
 62%|████████████████▊          | 249/400 [2:56:53<1:45:50, 42.05s/it]2022-01-09 14:21:17,064 iteration 4234 : loss : 0.024631, loss_ce: 0.010056
2022-01-09 14:21:19,356 iteration 4235 : loss : 0.018047, loss_ce: 0.006808
2022-01-09 14:21:21,707 iteration 4236 : loss : 0.027969, loss_ce: 0.014213
2022-01-09 14:21:24,074 iteration 4237 : loss : 0.021337, loss_ce: 0.010068
2022-01-09 14:21:26,495 iteration 4238 : loss : 0.052497, loss_ce: 0.014840
2022-01-09 14:21:28,801 iteration 4239 : loss : 0.022462, loss_ce: 0.006890
2022-01-09 14:21:31,188 iteration 4240 : loss : 0.023270, loss_ce: 0.007395
2022-01-09 14:21:33,550 iteration 4241 : loss : 0.032857, loss_ce: 0.013890
2022-01-09 14:21:35,852 iteration 4242 : loss : 0.033339, loss_ce: 0.009092
2022-01-09 14:21:38,139 iteration 4243 : loss : 0.024724, loss_ce: 0.008048
2022-01-09 14:21:40,468 iteration 4244 : loss : 0.023983, loss_ce: 0.009195
2022-01-09 14:21:42,738 iteration 4245 : loss : 0.041664, loss_ce: 0.007861
2022-01-09 14:21:45,029 iteration 4246 : loss : 0.034730, loss_ce: 0.017678
2022-01-09 14:21:47,418 iteration 4247 : loss : 0.021685, loss_ce: 0.005025
2022-01-09 14:21:49,829 iteration 4248 : loss : 0.025845, loss_ce: 0.009431
2022-01-09 14:21:52,242 iteration 4249 : loss : 0.051840, loss_ce: 0.026412
2022-01-09 14:21:52,242 Training Data Eval:
2022-01-09 14:22:04,984   Average segmentation loss on training set: 0.0160
2022-01-09 14:22:04,984 Validation Data Eval:
2022-01-09 14:22:09,612   Average segmentation loss on validation set: 0.0687
2022-01-09 14:22:12,051 iteration 4250 : loss : 0.024477, loss_ce: 0.009112
 62%|████████████████▉          | 250/400 [2:57:51<1:56:40, 46.67s/it]2022-01-09 14:22:14,479 iteration 4251 : loss : 0.023647, loss_ce: 0.010328
2022-01-09 14:22:16,802 iteration 4252 : loss : 0.022865, loss_ce: 0.009475
2022-01-09 14:22:19,049 iteration 4253 : loss : 0.034337, loss_ce: 0.014914
2022-01-09 14:22:21,379 iteration 4254 : loss : 0.028383, loss_ce: 0.013463
2022-01-09 14:22:23,546 iteration 4255 : loss : 0.015835, loss_ce: 0.006249
2022-01-09 14:22:25,808 iteration 4256 : loss : 0.029500, loss_ce: 0.008962
2022-01-09 14:22:28,165 iteration 4257 : loss : 0.027085, loss_ce: 0.010999
2022-01-09 14:22:30,433 iteration 4258 : loss : 0.020700, loss_ce: 0.007904
2022-01-09 14:22:32,785 iteration 4259 : loss : 0.029206, loss_ce: 0.010988
2022-01-09 14:22:35,129 iteration 4260 : loss : 0.019101, loss_ce: 0.005889
2022-01-09 14:22:37,463 iteration 4261 : loss : 0.019769, loss_ce: 0.008372
2022-01-09 14:22:39,927 iteration 4262 : loss : 0.025406, loss_ce: 0.010660
2022-01-09 14:22:42,261 iteration 4263 : loss : 0.017140, loss_ce: 0.006419
2022-01-09 14:22:44,617 iteration 4264 : loss : 0.030126, loss_ce: 0.009138
2022-01-09 14:22:46,977 iteration 4265 : loss : 0.031754, loss_ce: 0.012737
2022-01-09 14:22:49,353 iteration 4266 : loss : 0.022111, loss_ce: 0.007951
2022-01-09 14:22:51,766 iteration 4267 : loss : 0.017000, loss_ce: 0.007957
 63%|████████████████▉          | 251/400 [2:58:30<1:50:42, 44.58s/it]2022-01-09 14:22:54,177 iteration 4268 : loss : 0.025558, loss_ce: 0.011009
2022-01-09 14:22:56,461 iteration 4269 : loss : 0.018342, loss_ce: 0.006198
2022-01-09 14:22:58,710 iteration 4270 : loss : 0.043562, loss_ce: 0.008431
2022-01-09 14:23:00,928 iteration 4271 : loss : 0.017992, loss_ce: 0.008347
2022-01-09 14:23:03,249 iteration 4272 : loss : 0.038173, loss_ce: 0.016713
2022-01-09 14:23:05,521 iteration 4273 : loss : 0.029056, loss_ce: 0.013957
2022-01-09 14:23:07,827 iteration 4274 : loss : 0.040373, loss_ce: 0.026345
2022-01-09 14:23:10,069 iteration 4275 : loss : 0.019881, loss_ce: 0.007828
2022-01-09 14:23:12,424 iteration 4276 : loss : 0.022477, loss_ce: 0.007656
2022-01-09 14:23:14,916 iteration 4277 : loss : 0.013767, loss_ce: 0.005607
2022-01-09 14:23:17,296 iteration 4278 : loss : 0.032402, loss_ce: 0.009119
2022-01-09 14:23:19,664 iteration 4279 : loss : 0.016842, loss_ce: 0.005348
2022-01-09 14:23:22,068 iteration 4280 : loss : 0.039041, loss_ce: 0.008910
2022-01-09 14:23:24,549 iteration 4281 : loss : 0.026086, loss_ce: 0.012503
2022-01-09 14:23:26,893 iteration 4282 : loss : 0.022316, loss_ce: 0.008919
2022-01-09 14:23:29,092 iteration 4283 : loss : 0.021786, loss_ce: 0.008431
2022-01-09 14:23:31,311 iteration 4284 : loss : 0.032970, loss_ce: 0.017072
 63%|█████████████████          | 252/400 [2:59:10<1:46:14, 43.07s/it]2022-01-09 14:23:33,570 iteration 4285 : loss : 0.026541, loss_ce: 0.011218
2022-01-09 14:23:35,826 iteration 4286 : loss : 0.025574, loss_ce: 0.006735
2022-01-09 14:23:38,165 iteration 4287 : loss : 0.044994, loss_ce: 0.021595
2022-01-09 14:23:40,409 iteration 4288 : loss : 0.022616, loss_ce: 0.006539
2022-01-09 14:23:42,697 iteration 4289 : loss : 0.031903, loss_ce: 0.012640
2022-01-09 14:23:45,044 iteration 4290 : loss : 0.037107, loss_ce: 0.012798
2022-01-09 14:23:47,510 iteration 4291 : loss : 0.024904, loss_ce: 0.007967
2022-01-09 14:23:49,951 iteration 4292 : loss : 0.029214, loss_ce: 0.010698
2022-01-09 14:23:52,308 iteration 4293 : loss : 0.026718, loss_ce: 0.011275
2022-01-09 14:23:54,602 iteration 4294 : loss : 0.031835, loss_ce: 0.014593
2022-01-09 14:23:56,978 iteration 4295 : loss : 0.024086, loss_ce: 0.011124
2022-01-09 14:23:59,278 iteration 4296 : loss : 0.019696, loss_ce: 0.007856
2022-01-09 14:24:01,662 iteration 4297 : loss : 0.026598, loss_ce: 0.010623
2022-01-09 14:24:04,035 iteration 4298 : loss : 0.023833, loss_ce: 0.007871
2022-01-09 14:24:06,444 iteration 4299 : loss : 0.035509, loss_ce: 0.015045
2022-01-09 14:24:08,736 iteration 4300 : loss : 0.029391, loss_ce: 0.008514
2022-01-09 14:24:10,945 iteration 4301 : loss : 0.020283, loss_ce: 0.008051
 63%|█████████████████          | 253/400 [2:59:50<1:42:59, 42.04s/it]2022-01-09 14:24:13,256 iteration 4302 : loss : 0.017412, loss_ce: 0.007251
2022-01-09 14:24:15,616 iteration 4303 : loss : 0.023070, loss_ce: 0.007417
2022-01-09 14:24:17,892 iteration 4304 : loss : 0.025709, loss_ce: 0.010835
2022-01-09 14:24:20,216 iteration 4305 : loss : 0.026584, loss_ce: 0.007300
2022-01-09 14:24:22,563 iteration 4306 : loss : 0.032354, loss_ce: 0.010433
2022-01-09 14:24:24,950 iteration 4307 : loss : 0.021497, loss_ce: 0.007585
2022-01-09 14:24:27,346 iteration 4308 : loss : 0.030899, loss_ce: 0.011240
2022-01-09 14:24:29,686 iteration 4309 : loss : 0.023699, loss_ce: 0.006467
2022-01-09 14:24:32,087 iteration 4310 : loss : 0.027713, loss_ce: 0.014819
2022-01-09 14:24:34,509 iteration 4311 : loss : 0.024849, loss_ce: 0.012323
2022-01-09 14:24:37,193 iteration 4312 : loss : 0.035086, loss_ce: 0.012849
2022-01-09 14:24:39,606 iteration 4313 : loss : 0.025355, loss_ce: 0.009705
2022-01-09 14:24:41,932 iteration 4314 : loss : 0.017647, loss_ce: 0.005773
2022-01-09 14:24:44,205 iteration 4315 : loss : 0.021134, loss_ce: 0.007694
2022-01-09 14:24:46,593 iteration 4316 : loss : 0.022285, loss_ce: 0.008151
2022-01-09 14:24:48,869 iteration 4317 : loss : 0.030977, loss_ce: 0.011483
2022-01-09 14:24:51,189 iteration 4318 : loss : 0.017868, loss_ce: 0.008310
 64%|█████████████████▏         | 254/400 [3:00:30<1:40:59, 41.50s/it]2022-01-09 14:24:53,647 iteration 4319 : loss : 0.034531, loss_ce: 0.013298
2022-01-09 14:24:56,105 iteration 4320 : loss : 0.030352, loss_ce: 0.012844
2022-01-09 14:24:58,538 iteration 4321 : loss : 0.020657, loss_ce: 0.008684
2022-01-09 14:25:00,894 iteration 4322 : loss : 0.023821, loss_ce: 0.007198
2022-01-09 14:25:03,165 iteration 4323 : loss : 0.016560, loss_ce: 0.005031
2022-01-09 14:25:05,524 iteration 4324 : loss : 0.026298, loss_ce: 0.010170
2022-01-09 14:25:08,011 iteration 4325 : loss : 0.024233, loss_ce: 0.006397
2022-01-09 14:25:10,342 iteration 4326 : loss : 0.045459, loss_ce: 0.027187
2022-01-09 14:25:12,648 iteration 4327 : loss : 0.025971, loss_ce: 0.010555
2022-01-09 14:25:14,963 iteration 4328 : loss : 0.036006, loss_ce: 0.014702
2022-01-09 14:25:17,372 iteration 4329 : loss : 0.029676, loss_ce: 0.012300
2022-01-09 14:25:19,743 iteration 4330 : loss : 0.016315, loss_ce: 0.005774
2022-01-09 14:25:22,207 iteration 4331 : loss : 0.030599, loss_ce: 0.010199
2022-01-09 14:25:24,505 iteration 4332 : loss : 0.034490, loss_ce: 0.015846
2022-01-09 14:25:26,761 iteration 4333 : loss : 0.027392, loss_ce: 0.007619
2022-01-09 14:25:29,161 iteration 4334 : loss : 0.019320, loss_ce: 0.008164
2022-01-09 14:25:29,161 Training Data Eval:
2022-01-09 14:25:41,896   Average segmentation loss on training set: 0.0161
2022-01-09 14:25:41,897 Validation Data Eval:
2022-01-09 14:25:46,442   Average segmentation loss on validation set: 0.0587
2022-01-09 14:25:52,462 Found new lowest validation loss at iteration 4334! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed100.pth
2022-01-09 14:25:54,119 iteration 4335 : loss : 0.021143, loss_ce: 0.011423
 64%|█████████████████▏         | 255/400 [3:01:33<1:55:49, 47.93s/it]2022-01-09 14:25:55,723 iteration 4336 : loss : 0.022086, loss_ce: 0.009267
2022-01-09 14:25:57,382 iteration 4337 : loss : 0.026949, loss_ce: 0.009709
2022-01-09 14:25:59,220 iteration 4338 : loss : 0.041400, loss_ce: 0.014879
2022-01-09 14:26:01,104 iteration 4339 : loss : 0.025626, loss_ce: 0.008163
2022-01-09 14:26:03,148 iteration 4340 : loss : 0.019692, loss_ce: 0.008281
2022-01-09 14:26:05,305 iteration 4341 : loss : 0.028893, loss_ce: 0.012557
2022-01-09 14:26:07,506 iteration 4342 : loss : 0.044575, loss_ce: 0.013251
2022-01-09 14:26:09,764 iteration 4343 : loss : 0.019014, loss_ce: 0.005490
2022-01-09 14:26:11,986 iteration 4344 : loss : 0.021211, loss_ce: 0.007112
2022-01-09 14:26:14,318 iteration 4345 : loss : 0.027796, loss_ce: 0.008584
2022-01-09 14:26:16,577 iteration 4346 : loss : 0.020780, loss_ce: 0.010014
2022-01-09 14:26:18,903 iteration 4347 : loss : 0.034022, loss_ce: 0.010395
2022-01-09 14:26:21,161 iteration 4348 : loss : 0.023629, loss_ce: 0.013270
2022-01-09 14:26:23,374 iteration 4349 : loss : 0.033355, loss_ce: 0.012660
2022-01-09 14:26:25,675 iteration 4350 : loss : 0.020363, loss_ce: 0.007949
2022-01-09 14:26:28,185 iteration 4351 : loss : 0.016243, loss_ce: 0.007647
2022-01-09 14:26:30,563 iteration 4352 : loss : 0.015220, loss_ce: 0.006144
 64%|█████████████████▎         | 256/400 [3:02:09<1:46:46, 44.49s/it]2022-01-09 14:26:32,967 iteration 4353 : loss : 0.025424, loss_ce: 0.009714
2022-01-09 14:26:35,344 iteration 4354 : loss : 0.023820, loss_ce: 0.007019
2022-01-09 14:26:37,668 iteration 4355 : loss : 0.021267, loss_ce: 0.006833
2022-01-09 14:26:40,128 iteration 4356 : loss : 0.023409, loss_ce: 0.011718
2022-01-09 14:26:42,543 iteration 4357 : loss : 0.022739, loss_ce: 0.008355
2022-01-09 14:26:44,888 iteration 4358 : loss : 0.016442, loss_ce: 0.006756
2022-01-09 14:26:47,326 iteration 4359 : loss : 0.015816, loss_ce: 0.005267
2022-01-09 14:26:49,717 iteration 4360 : loss : 0.022546, loss_ce: 0.008149
2022-01-09 14:26:52,142 iteration 4361 : loss : 0.026041, loss_ce: 0.011837
2022-01-09 14:26:54,562 iteration 4362 : loss : 0.019280, loss_ce: 0.006829
2022-01-09 14:26:56,897 iteration 4363 : loss : 0.024568, loss_ce: 0.011468
2022-01-09 14:26:59,508 iteration 4364 : loss : 0.032718, loss_ce: 0.012502
2022-01-09 14:27:01,879 iteration 4365 : loss : 0.026216, loss_ce: 0.010391
2022-01-09 14:27:04,176 iteration 4366 : loss : 0.015717, loss_ce: 0.006818
2022-01-09 14:27:06,532 iteration 4367 : loss : 0.023497, loss_ce: 0.007747
2022-01-09 14:27:08,991 iteration 4368 : loss : 0.029170, loss_ce: 0.010513
2022-01-09 14:27:11,406 iteration 4369 : loss : 0.028730, loss_ce: 0.007175
 64%|█████████████████▎         | 257/400 [3:02:50<1:43:25, 43.39s/it]2022-01-09 14:27:13,839 iteration 4370 : loss : 0.034629, loss_ce: 0.007924
2022-01-09 14:27:16,287 iteration 4371 : loss : 0.022850, loss_ce: 0.011031
2022-01-09 14:27:18,628 iteration 4372 : loss : 0.018245, loss_ce: 0.008563
2022-01-09 14:27:21,043 iteration 4373 : loss : 0.018310, loss_ce: 0.006473
2022-01-09 14:27:23,433 iteration 4374 : loss : 0.016629, loss_ce: 0.007359
2022-01-09 14:27:25,889 iteration 4375 : loss : 0.019964, loss_ce: 0.008339
2022-01-09 14:27:28,313 iteration 4376 : loss : 0.022483, loss_ce: 0.007481
2022-01-09 14:27:30,780 iteration 4377 : loss : 0.038419, loss_ce: 0.015176
2022-01-09 14:27:33,359 iteration 4378 : loss : 0.020680, loss_ce: 0.008373
2022-01-09 14:27:35,824 iteration 4379 : loss : 0.031985, loss_ce: 0.015101
2022-01-09 14:27:38,217 iteration 4380 : loss : 0.016078, loss_ce: 0.006899
2022-01-09 14:27:40,781 iteration 4381 : loss : 0.031578, loss_ce: 0.012504
2022-01-09 14:27:43,187 iteration 4382 : loss : 0.030600, loss_ce: 0.013312
2022-01-09 14:27:45,555 iteration 4383 : loss : 0.029639, loss_ce: 0.007729
2022-01-09 14:27:47,940 iteration 4384 : loss : 0.024573, loss_ce: 0.008799
2022-01-09 14:27:50,291 iteration 4385 : loss : 0.018329, loss_ce: 0.008473
2022-01-09 14:27:52,870 iteration 4386 : loss : 0.032647, loss_ce: 0.018043
 64%|█████████████████▍         | 258/400 [3:03:32<1:41:19, 42.82s/it]2022-01-09 14:27:55,334 iteration 4387 : loss : 0.017276, loss_ce: 0.006619
2022-01-09 14:27:57,741 iteration 4388 : loss : 0.018885, loss_ce: 0.007843
2022-01-09 14:28:00,100 iteration 4389 : loss : 0.015648, loss_ce: 0.007104
2022-01-09 14:28:02,445 iteration 4390 : loss : 0.020471, loss_ce: 0.007382
2022-01-09 14:28:04,898 iteration 4391 : loss : 0.018956, loss_ce: 0.008120
2022-01-09 14:28:07,501 iteration 4392 : loss : 0.023225, loss_ce: 0.011380
2022-01-09 14:28:09,835 iteration 4393 : loss : 0.019747, loss_ce: 0.006815
2022-01-09 14:28:12,251 iteration 4394 : loss : 0.024403, loss_ce: 0.009885
2022-01-09 14:28:14,676 iteration 4395 : loss : 0.019612, loss_ce: 0.007113
2022-01-09 14:28:17,205 iteration 4396 : loss : 0.024738, loss_ce: 0.009338
2022-01-09 14:28:19,658 iteration 4397 : loss : 0.025431, loss_ce: 0.009124
2022-01-09 14:28:22,098 iteration 4398 : loss : 0.028873, loss_ce: 0.009074
2022-01-09 14:28:24,575 iteration 4399 : loss : 0.019233, loss_ce: 0.006385
2022-01-09 14:28:27,011 iteration 4400 : loss : 0.018519, loss_ce: 0.007727
2022-01-09 14:28:29,391 iteration 4401 : loss : 0.019738, loss_ce: 0.009262
2022-01-09 14:28:31,900 iteration 4402 : loss : 0.016348, loss_ce: 0.005166
2022-01-09 14:28:34,265 iteration 4403 : loss : 0.021617, loss_ce: 0.006236
 65%|█████████████████▍         | 259/400 [3:04:13<1:39:37, 42.39s/it]2022-01-09 14:28:36,570 iteration 4404 : loss : 0.014185, loss_ce: 0.006588
2022-01-09 14:28:39,004 iteration 4405 : loss : 0.017054, loss_ce: 0.004711
2022-01-09 14:28:41,392 iteration 4406 : loss : 0.028870, loss_ce: 0.009871
2022-01-09 14:28:43,857 iteration 4407 : loss : 0.019352, loss_ce: 0.007478
2022-01-09 14:28:46,205 iteration 4408 : loss : 0.022137, loss_ce: 0.005421
2022-01-09 14:28:48,594 iteration 4409 : loss : 0.016203, loss_ce: 0.005805
2022-01-09 14:28:50,969 iteration 4410 : loss : 0.036916, loss_ce: 0.011773
2022-01-09 14:28:53,436 iteration 4411 : loss : 0.023837, loss_ce: 0.012035
2022-01-09 14:28:55,820 iteration 4412 : loss : 0.020093, loss_ce: 0.008764
2022-01-09 14:28:58,263 iteration 4413 : loss : 0.020399, loss_ce: 0.006019
2022-01-09 14:29:00,624 iteration 4414 : loss : 0.016044, loss_ce: 0.006335
2022-01-09 14:29:03,068 iteration 4415 : loss : 0.023950, loss_ce: 0.010168
2022-01-09 14:29:05,468 iteration 4416 : loss : 0.018497, loss_ce: 0.005342
2022-01-09 14:29:07,853 iteration 4417 : loss : 0.038013, loss_ce: 0.014628
2022-01-09 14:29:10,366 iteration 4418 : loss : 0.025587, loss_ce: 0.011748
2022-01-09 14:29:12,760 iteration 4419 : loss : 0.023050, loss_ce: 0.007688
2022-01-09 14:29:12,760 Training Data Eval:
2022-01-09 14:29:26,011   Average segmentation loss on training set: 0.0133
2022-01-09 14:29:26,012 Validation Data Eval:
2022-01-09 14:29:30,517   Average segmentation loss on validation set: 0.0640
2022-01-09 14:29:32,865 iteration 4420 : loss : 0.016745, loss_ce: 0.006946
 65%|█████████████████▌         | 260/400 [3:05:12<1:50:15, 47.25s/it]2022-01-09 14:29:35,269 iteration 4421 : loss : 0.022683, loss_ce: 0.008848
2022-01-09 14:29:37,577 iteration 4422 : loss : 0.038248, loss_ce: 0.017032
2022-01-09 14:29:40,014 iteration 4423 : loss : 0.023565, loss_ce: 0.010439
2022-01-09 14:29:42,360 iteration 4424 : loss : 0.028169, loss_ce: 0.011477
2022-01-09 14:29:44,693 iteration 4425 : loss : 0.016615, loss_ce: 0.006124
2022-01-09 14:29:47,107 iteration 4426 : loss : 0.026278, loss_ce: 0.011157
2022-01-09 14:29:49,482 iteration 4427 : loss : 0.035497, loss_ce: 0.009444
2022-01-09 14:29:51,900 iteration 4428 : loss : 0.024815, loss_ce: 0.008487
2022-01-09 14:29:54,265 iteration 4429 : loss : 0.027214, loss_ce: 0.009640
2022-01-09 14:29:56,611 iteration 4430 : loss : 0.031682, loss_ce: 0.011312
2022-01-09 14:29:58,975 iteration 4431 : loss : 0.021681, loss_ce: 0.008372
2022-01-09 14:30:01,430 iteration 4432 : loss : 0.015755, loss_ce: 0.006514
2022-01-09 14:30:03,856 iteration 4433 : loss : 0.020669, loss_ce: 0.008281
2022-01-09 14:30:06,245 iteration 4434 : loss : 0.017540, loss_ce: 0.006686
2022-01-09 14:30:08,618 iteration 4435 : loss : 0.039165, loss_ce: 0.013545
2022-01-09 14:30:11,099 iteration 4436 : loss : 0.033761, loss_ce: 0.015487
2022-01-09 14:30:13,513 iteration 4437 : loss : 0.023222, loss_ce: 0.008990
 65%|█████████████████▌         | 261/400 [3:05:52<1:44:52, 45.27s/it]2022-01-09 14:30:16,017 iteration 4438 : loss : 0.025256, loss_ce: 0.007933
2022-01-09 14:30:18,317 iteration 4439 : loss : 0.026107, loss_ce: 0.008642
2022-01-09 14:30:20,638 iteration 4440 : loss : 0.030183, loss_ce: 0.011102
2022-01-09 14:30:23,057 iteration 4441 : loss : 0.022283, loss_ce: 0.009216
2022-01-09 14:30:25,467 iteration 4442 : loss : 0.018394, loss_ce: 0.008458
2022-01-09 14:30:27,848 iteration 4443 : loss : 0.026582, loss_ce: 0.010841
2022-01-09 14:30:30,235 iteration 4444 : loss : 0.022063, loss_ce: 0.007660
2022-01-09 14:30:32,801 iteration 4445 : loss : 0.022427, loss_ce: 0.008932
2022-01-09 14:30:35,238 iteration 4446 : loss : 0.021239, loss_ce: 0.008300
2022-01-09 14:30:37,640 iteration 4447 : loss : 0.024009, loss_ce: 0.010132
2022-01-09 14:30:40,069 iteration 4448 : loss : 0.026680, loss_ce: 0.007154
2022-01-09 14:30:42,468 iteration 4449 : loss : 0.019060, loss_ce: 0.008649
2022-01-09 14:30:44,896 iteration 4450 : loss : 0.020605, loss_ce: 0.006858
2022-01-09 14:30:47,197 iteration 4451 : loss : 0.017233, loss_ce: 0.005650
2022-01-09 14:30:49,613 iteration 4452 : loss : 0.023437, loss_ce: 0.010238
2022-01-09 14:30:52,079 iteration 4453 : loss : 0.028457, loss_ce: 0.012012
2022-01-09 14:30:54,489 iteration 4454 : loss : 0.024621, loss_ce: 0.011179
 66%|█████████████████▋         | 262/400 [3:06:33<1:41:09, 43.98s/it]2022-01-09 14:30:56,998 iteration 4455 : loss : 0.019874, loss_ce: 0.007680
2022-01-09 14:30:59,452 iteration 4456 : loss : 0.025129, loss_ce: 0.011606
2022-01-09 14:31:02,022 iteration 4457 : loss : 0.015811, loss_ce: 0.007547
2022-01-09 14:31:04,485 iteration 4458 : loss : 0.028366, loss_ce: 0.012810
2022-01-09 14:31:06,835 iteration 4459 : loss : 0.018119, loss_ce: 0.007428
2022-01-09 14:31:09,213 iteration 4460 : loss : 0.020278, loss_ce: 0.008167
2022-01-09 14:31:11,610 iteration 4461 : loss : 0.018156, loss_ce: 0.008323
2022-01-09 14:31:14,129 iteration 4462 : loss : 0.018450, loss_ce: 0.007271
2022-01-09 14:31:16,522 iteration 4463 : loss : 0.019416, loss_ce: 0.007594
2022-01-09 14:31:18,876 iteration 4464 : loss : 0.021299, loss_ce: 0.007509
2022-01-09 14:31:21,271 iteration 4465 : loss : 0.028121, loss_ce: 0.014274
2022-01-09 14:31:23,644 iteration 4466 : loss : 0.036821, loss_ce: 0.011621
2022-01-09 14:31:26,019 iteration 4467 : loss : 0.016802, loss_ce: 0.006075
2022-01-09 14:31:28,488 iteration 4468 : loss : 0.018771, loss_ce: 0.005896
2022-01-09 14:31:30,909 iteration 4469 : loss : 0.025190, loss_ce: 0.007138
2022-01-09 14:31:33,349 iteration 4470 : loss : 0.030731, loss_ce: 0.008877
2022-01-09 14:31:35,762 iteration 4471 : loss : 0.021120, loss_ce: 0.007548
 66%|█████████████████▊         | 263/400 [3:07:14<1:38:34, 43.17s/it]2022-01-09 14:31:38,176 iteration 4472 : loss : 0.021767, loss_ce: 0.008682
2022-01-09 14:31:40,566 iteration 4473 : loss : 0.020847, loss_ce: 0.009037
2022-01-09 14:31:42,962 iteration 4474 : loss : 0.019753, loss_ce: 0.006356
2022-01-09 14:31:45,479 iteration 4475 : loss : 0.017072, loss_ce: 0.007740
2022-01-09 14:31:47,834 iteration 4476 : loss : 0.016064, loss_ce: 0.005608
2022-01-09 14:31:50,212 iteration 4477 : loss : 0.029163, loss_ce: 0.014699
2022-01-09 14:31:52,624 iteration 4478 : loss : 0.022987, loss_ce: 0.007771
2022-01-09 14:31:55,142 iteration 4479 : loss : 0.051806, loss_ce: 0.008291
2022-01-09 14:31:57,543 iteration 4480 : loss : 0.016984, loss_ce: 0.006872
2022-01-09 14:31:59,894 iteration 4481 : loss : 0.013754, loss_ce: 0.005691
2022-01-09 14:32:02,279 iteration 4482 : loss : 0.023197, loss_ce: 0.007972
2022-01-09 14:32:04,626 iteration 4483 : loss : 0.023558, loss_ce: 0.009386
2022-01-09 14:32:06,990 iteration 4484 : loss : 0.020969, loss_ce: 0.007182
2022-01-09 14:32:09,329 iteration 4485 : loss : 0.018480, loss_ce: 0.005570
2022-01-09 14:32:11,731 iteration 4486 : loss : 0.031596, loss_ce: 0.013014
2022-01-09 14:32:14,074 iteration 4487 : loss : 0.024826, loss_ce: 0.010453
2022-01-09 14:32:16,602 iteration 4488 : loss : 0.021625, loss_ce: 0.009312
 66%|█████████████████▊         | 264/400 [3:07:55<1:36:16, 42.47s/it]2022-01-09 14:32:19,074 iteration 4489 : loss : 0.033011, loss_ce: 0.012373
2022-01-09 14:32:21,430 iteration 4490 : loss : 0.016325, loss_ce: 0.005810
2022-01-09 14:32:23,881 iteration 4491 : loss : 0.026215, loss_ce: 0.009524
2022-01-09 14:32:26,436 iteration 4492 : loss : 0.024626, loss_ce: 0.008327
2022-01-09 14:32:28,876 iteration 4493 : loss : 0.040718, loss_ce: 0.013989
2022-01-09 14:32:31,160 iteration 4494 : loss : 0.017145, loss_ce: 0.006629
2022-01-09 14:32:33,560 iteration 4495 : loss : 0.021743, loss_ce: 0.009915
2022-01-09 14:32:35,937 iteration 4496 : loss : 0.023705, loss_ce: 0.006797
2022-01-09 14:32:38,237 iteration 4497 : loss : 0.018335, loss_ce: 0.005176
2022-01-09 14:32:40,690 iteration 4498 : loss : 0.028845, loss_ce: 0.011886
2022-01-09 14:32:43,271 iteration 4499 : loss : 0.038877, loss_ce: 0.017205
2022-01-09 14:32:45,674 iteration 4500 : loss : 0.021452, loss_ce: 0.009545
2022-01-09 14:32:48,180 iteration 4501 : loss : 0.022040, loss_ce: 0.008065
2022-01-09 14:32:50,566 iteration 4502 : loss : 0.016772, loss_ce: 0.006254
2022-01-09 14:32:53,060 iteration 4503 : loss : 0.020796, loss_ce: 0.008305
2022-01-09 14:32:55,526 iteration 4504 : loss : 0.024010, loss_ce: 0.008516
2022-01-09 14:32:55,526 Training Data Eval:
2022-01-09 14:33:08,780   Average segmentation loss on training set: 0.0124
2022-01-09 14:33:08,780 Validation Data Eval:
2022-01-09 14:33:13,305   Average segmentation loss on validation set: 0.0665
2022-01-09 14:33:15,678 iteration 4505 : loss : 0.013894, loss_ce: 0.005521
 66%|█████████████████▉         | 265/400 [3:08:54<1:46:46, 47.45s/it]2022-01-09 14:33:18,148 iteration 4506 : loss : 0.025631, loss_ce: 0.008361
2022-01-09 14:33:20,450 iteration 4507 : loss : 0.018045, loss_ce: 0.005786
2022-01-09 14:33:22,794 iteration 4508 : loss : 0.035698, loss_ce: 0.012663
2022-01-09 14:33:25,172 iteration 4509 : loss : 0.028368, loss_ce: 0.007601
2022-01-09 14:33:27,555 iteration 4510 : loss : 0.017313, loss_ce: 0.006307
2022-01-09 14:33:29,976 iteration 4511 : loss : 0.026972, loss_ce: 0.009902
2022-01-09 14:33:32,421 iteration 4512 : loss : 0.016173, loss_ce: 0.007209
2022-01-09 14:33:34,810 iteration 4513 : loss : 0.028062, loss_ce: 0.014525
2022-01-09 14:33:37,079 iteration 4514 : loss : 0.018628, loss_ce: 0.006990
2022-01-09 14:33:39,343 iteration 4515 : loss : 0.029980, loss_ce: 0.010976
2022-01-09 14:33:41,727 iteration 4516 : loss : 0.025491, loss_ce: 0.011150
2022-01-09 14:33:44,044 iteration 4517 : loss : 0.017304, loss_ce: 0.006513
2022-01-09 14:33:46,415 iteration 4518 : loss : 0.041926, loss_ce: 0.015473
2022-01-09 14:33:48,853 iteration 4519 : loss : 0.021096, loss_ce: 0.009580
2022-01-09 14:33:51,216 iteration 4520 : loss : 0.018832, loss_ce: 0.006218
2022-01-09 14:33:53,607 iteration 4521 : loss : 0.024791, loss_ce: 0.007930
2022-01-09 14:33:55,961 iteration 4522 : loss : 0.019113, loss_ce: 0.009506
 66%|█████████████████▉         | 266/400 [3:09:35<1:41:10, 45.30s/it]2022-01-09 14:33:58,451 iteration 4523 : loss : 0.019471, loss_ce: 0.007260
2022-01-09 14:34:00,755 iteration 4524 : loss : 0.014865, loss_ce: 0.005688
2022-01-09 14:34:03,100 iteration 4525 : loss : 0.044301, loss_ce: 0.014691
2022-01-09 14:34:05,368 iteration 4526 : loss : 0.016872, loss_ce: 0.006990
2022-01-09 14:34:07,678 iteration 4527 : loss : 0.019682, loss_ce: 0.008478
2022-01-09 14:34:10,016 iteration 4528 : loss : 0.025562, loss_ce: 0.010282
2022-01-09 14:34:12,298 iteration 4529 : loss : 0.022366, loss_ce: 0.010175
2022-01-09 14:34:14,693 iteration 4530 : loss : 0.025361, loss_ce: 0.010637
2022-01-09 14:34:17,017 iteration 4531 : loss : 0.024117, loss_ce: 0.010453
2022-01-09 14:34:19,403 iteration 4532 : loss : 0.025407, loss_ce: 0.012107
2022-01-09 14:34:21,820 iteration 4533 : loss : 0.036874, loss_ce: 0.015327
2022-01-09 14:34:24,287 iteration 4534 : loss : 0.028589, loss_ce: 0.010100
2022-01-09 14:34:26,596 iteration 4535 : loss : 0.021313, loss_ce: 0.007293
2022-01-09 14:34:29,034 iteration 4536 : loss : 0.024875, loss_ce: 0.014805
2022-01-09 14:34:31,645 iteration 4537 : loss : 0.028909, loss_ce: 0.009963
2022-01-09 14:34:34,007 iteration 4538 : loss : 0.018812, loss_ce: 0.007156
2022-01-09 14:34:36,449 iteration 4539 : loss : 0.026268, loss_ce: 0.010618
 67%|██████████████████         | 267/400 [3:10:15<1:37:12, 43.85s/it]2022-01-09 14:34:38,920 iteration 4540 : loss : 0.025758, loss_ce: 0.008112
2022-01-09 14:34:41,266 iteration 4541 : loss : 0.018876, loss_ce: 0.006875
2022-01-09 14:34:43,611 iteration 4542 : loss : 0.024163, loss_ce: 0.006320
2022-01-09 14:34:45,872 iteration 4543 : loss : 0.016342, loss_ce: 0.006532
2022-01-09 14:34:48,276 iteration 4544 : loss : 0.024424, loss_ce: 0.010286
2022-01-09 14:34:50,712 iteration 4545 : loss : 0.036152, loss_ce: 0.015456
2022-01-09 14:34:53,059 iteration 4546 : loss : 0.028486, loss_ce: 0.010748
2022-01-09 14:34:55,466 iteration 4547 : loss : 0.021647, loss_ce: 0.009547
2022-01-09 14:34:57,835 iteration 4548 : loss : 0.025468, loss_ce: 0.009618
2022-01-09 14:35:00,215 iteration 4549 : loss : 0.025309, loss_ce: 0.008831
2022-01-09 14:35:02,573 iteration 4550 : loss : 0.049624, loss_ce: 0.012182
2022-01-09 14:35:04,873 iteration 4551 : loss : 0.036953, loss_ce: 0.007509
2022-01-09 14:35:07,071 iteration 4552 : loss : 0.016225, loss_ce: 0.006189
2022-01-09 14:35:09,396 iteration 4553 : loss : 0.031170, loss_ce: 0.011812
2022-01-09 14:35:11,784 iteration 4554 : loss : 0.018175, loss_ce: 0.006832
2022-01-09 14:35:14,169 iteration 4555 : loss : 0.032934, loss_ce: 0.013137
2022-01-09 14:35:16,459 iteration 4556 : loss : 0.020190, loss_ce: 0.009308
 67%|██████████████████         | 268/400 [3:10:55<1:33:56, 42.70s/it]2022-01-09 14:35:18,841 iteration 4557 : loss : 0.021720, loss_ce: 0.010193
2022-01-09 14:35:21,324 iteration 4558 : loss : 0.034275, loss_ce: 0.016613
2022-01-09 14:35:23,785 iteration 4559 : loss : 0.034894, loss_ce: 0.013449
2022-01-09 14:35:26,170 iteration 4560 : loss : 0.019756, loss_ce: 0.005246
2022-01-09 14:35:28,506 iteration 4561 : loss : 0.023134, loss_ce: 0.006559
2022-01-09 14:35:30,840 iteration 4562 : loss : 0.025086, loss_ce: 0.009156
2022-01-09 14:35:33,085 iteration 4563 : loss : 0.017836, loss_ce: 0.005585
2022-01-09 14:35:35,323 iteration 4564 : loss : 0.034840, loss_ce: 0.010797
2022-01-09 14:35:37,540 iteration 4565 : loss : 0.020843, loss_ce: 0.008212
2022-01-09 14:35:39,762 iteration 4566 : loss : 0.020932, loss_ce: 0.009301
2022-01-09 14:35:42,022 iteration 4567 : loss : 0.025220, loss_ce: 0.010312
2022-01-09 14:35:44,302 iteration 4568 : loss : 0.027048, loss_ce: 0.009043
2022-01-09 14:35:46,636 iteration 4569 : loss : 0.022209, loss_ce: 0.009129
2022-01-09 14:35:48,926 iteration 4570 : loss : 0.018726, loss_ce: 0.007704
2022-01-09 14:35:51,264 iteration 4571 : loss : 0.017975, loss_ce: 0.008773
2022-01-09 14:35:53,696 iteration 4572 : loss : 0.016540, loss_ce: 0.005117
2022-01-09 14:35:56,067 iteration 4573 : loss : 0.021561, loss_ce: 0.009363
 67%|██████████████████▏        | 269/400 [3:11:35<1:31:12, 41.78s/it]2022-01-09 14:35:58,487 iteration 4574 : loss : 0.017423, loss_ce: 0.005738
2022-01-09 14:36:00,852 iteration 4575 : loss : 0.017893, loss_ce: 0.006761
2022-01-09 14:36:03,416 iteration 4576 : loss : 0.026573, loss_ce: 0.017948
2022-01-09 14:36:05,839 iteration 4577 : loss : 0.020612, loss_ce: 0.007895
2022-01-09 14:36:08,148 iteration 4578 : loss : 0.020661, loss_ce: 0.008741
2022-01-09 14:36:10,526 iteration 4579 : loss : 0.021053, loss_ce: 0.009712
2022-01-09 14:36:12,916 iteration 4580 : loss : 0.019397, loss_ce: 0.008325
2022-01-09 14:36:15,349 iteration 4581 : loss : 0.023863, loss_ce: 0.007692
2022-01-09 14:36:17,724 iteration 4582 : loss : 0.026025, loss_ce: 0.011906
2022-01-09 14:36:20,035 iteration 4583 : loss : 0.018407, loss_ce: 0.007455
2022-01-09 14:36:22,416 iteration 4584 : loss : 0.038477, loss_ce: 0.014036
2022-01-09 14:36:24,814 iteration 4585 : loss : 0.026922, loss_ce: 0.007301
2022-01-09 14:36:27,264 iteration 4586 : loss : 0.017847, loss_ce: 0.007122
2022-01-09 14:36:29,721 iteration 4587 : loss : 0.034062, loss_ce: 0.013558
2022-01-09 14:36:32,102 iteration 4588 : loss : 0.026119, loss_ce: 0.008249
2022-01-09 14:36:34,491 iteration 4589 : loss : 0.020351, loss_ce: 0.008525
2022-01-09 14:36:34,491 Training Data Eval:
2022-01-09 14:36:47,376   Average segmentation loss on training set: 0.0143
2022-01-09 14:36:47,376 Validation Data Eval:
2022-01-09 14:36:51,896   Average segmentation loss on validation set: 0.0729
2022-01-09 14:36:54,387 iteration 4590 : loss : 0.026448, loss_ce: 0.008432
 68%|██████████████████▏        | 270/400 [3:12:33<1:41:15, 46.74s/it]2022-01-09 14:36:56,789 iteration 4591 : loss : 0.016167, loss_ce: 0.004723
2022-01-09 14:36:59,159 iteration 4592 : loss : 0.022617, loss_ce: 0.008525
2022-01-09 14:37:01,421 iteration 4593 : loss : 0.018547, loss_ce: 0.005369
2022-01-09 14:37:03,766 iteration 4594 : loss : 0.020488, loss_ce: 0.009188
2022-01-09 14:37:06,113 iteration 4595 : loss : 0.025199, loss_ce: 0.005286
2022-01-09 14:37:08,438 iteration 4596 : loss : 0.029267, loss_ce: 0.010361
2022-01-09 14:37:10,639 iteration 4597 : loss : 0.015891, loss_ce: 0.006382
2022-01-09 14:37:12,855 iteration 4598 : loss : 0.020686, loss_ce: 0.009928
2022-01-09 14:37:15,224 iteration 4599 : loss : 0.021719, loss_ce: 0.006059
2022-01-09 14:37:17,624 iteration 4600 : loss : 0.022295, loss_ce: 0.011646
2022-01-09 14:37:20,059 iteration 4601 : loss : 0.021306, loss_ce: 0.011520
2022-01-09 14:37:22,312 iteration 4602 : loss : 0.016938, loss_ce: 0.006288
2022-01-09 14:37:24,656 iteration 4603 : loss : 0.016261, loss_ce: 0.007473
2022-01-09 14:37:27,047 iteration 4604 : loss : 0.022455, loss_ce: 0.007621
2022-01-09 14:37:29,393 iteration 4605 : loss : 0.025250, loss_ce: 0.006819
2022-01-09 14:37:31,738 iteration 4606 : loss : 0.028861, loss_ce: 0.010019
2022-01-09 14:37:34,078 iteration 4607 : loss : 0.016091, loss_ce: 0.008456
 68%|██████████████████▎        | 271/400 [3:13:13<1:35:56, 44.63s/it]2022-01-09 14:37:36,511 iteration 4608 : loss : 0.016568, loss_ce: 0.005315
2022-01-09 14:37:38,873 iteration 4609 : loss : 0.027031, loss_ce: 0.013073
2022-01-09 14:37:41,203 iteration 4610 : loss : 0.024503, loss_ce: 0.006941
2022-01-09 14:37:43,550 iteration 4611 : loss : 0.025267, loss_ce: 0.010415
2022-01-09 14:37:45,849 iteration 4612 : loss : 0.015819, loss_ce: 0.005838
2022-01-09 14:37:48,279 iteration 4613 : loss : 0.020622, loss_ce: 0.008476
2022-01-09 14:37:50,647 iteration 4614 : loss : 0.018879, loss_ce: 0.007798
2022-01-09 14:37:53,048 iteration 4615 : loss : 0.030622, loss_ce: 0.012340
2022-01-09 14:37:55,450 iteration 4616 : loss : 0.022383, loss_ce: 0.008990
2022-01-09 14:37:57,710 iteration 4617 : loss : 0.020336, loss_ce: 0.009183
2022-01-09 14:38:00,033 iteration 4618 : loss : 0.029559, loss_ce: 0.009378
2022-01-09 14:38:02,352 iteration 4619 : loss : 0.025479, loss_ce: 0.008635
2022-01-09 14:38:04,953 iteration 4620 : loss : 0.026022, loss_ce: 0.009097
2022-01-09 14:38:07,389 iteration 4621 : loss : 0.025264, loss_ce: 0.009362
2022-01-09 14:38:09,733 iteration 4622 : loss : 0.025055, loss_ce: 0.009889
2022-01-09 14:38:12,046 iteration 4623 : loss : 0.023736, loss_ce: 0.008792
2022-01-09 14:38:14,303 iteration 4624 : loss : 0.021996, loss_ce: 0.009117
 68%|██████████████████▎        | 272/400 [3:13:53<1:32:22, 43.30s/it]2022-01-09 14:38:16,638 iteration 4625 : loss : 0.018135, loss_ce: 0.007998
2022-01-09 14:38:18,940 iteration 4626 : loss : 0.017143, loss_ce: 0.005481
2022-01-09 14:38:21,282 iteration 4627 : loss : 0.016362, loss_ce: 0.005319
2022-01-09 14:38:23,606 iteration 4628 : loss : 0.024285, loss_ce: 0.009379
2022-01-09 14:38:25,897 iteration 4629 : loss : 0.019358, loss_ce: 0.008670
2022-01-09 14:38:28,443 iteration 4630 : loss : 0.019656, loss_ce: 0.007481
2022-01-09 14:38:30,896 iteration 4631 : loss : 0.025535, loss_ce: 0.010836
2022-01-09 14:38:33,209 iteration 4632 : loss : 0.014386, loss_ce: 0.004674
2022-01-09 14:38:35,553 iteration 4633 : loss : 0.021327, loss_ce: 0.008376
2022-01-09 14:38:37,764 iteration 4634 : loss : 0.026380, loss_ce: 0.013871
2022-01-09 14:38:40,078 iteration 4635 : loss : 0.022698, loss_ce: 0.006892
2022-01-09 14:38:42,319 iteration 4636 : loss : 0.023821, loss_ce: 0.008163
2022-01-09 14:38:44,568 iteration 4637 : loss : 0.015210, loss_ce: 0.005676
2022-01-09 14:38:46,862 iteration 4638 : loss : 0.027303, loss_ce: 0.013065
2022-01-09 14:38:49,193 iteration 4639 : loss : 0.027994, loss_ce: 0.010354
2022-01-09 14:38:51,513 iteration 4640 : loss : 0.023701, loss_ce: 0.009459
2022-01-09 14:38:53,757 iteration 4641 : loss : 0.014504, loss_ce: 0.006168
 68%|██████████████████▍        | 273/400 [3:14:32<1:29:12, 42.15s/it]2022-01-09 14:38:56,213 iteration 4642 : loss : 0.028048, loss_ce: 0.008978
2022-01-09 14:38:58,602 iteration 4643 : loss : 0.028893, loss_ce: 0.012120
2022-01-09 14:39:01,001 iteration 4644 : loss : 0.026271, loss_ce: 0.011227
2022-01-09 14:39:03,409 iteration 4645 : loss : 0.027069, loss_ce: 0.011487
2022-01-09 14:39:05,675 iteration 4646 : loss : 0.019732, loss_ce: 0.009117
2022-01-09 14:39:07,929 iteration 4647 : loss : 0.017854, loss_ce: 0.007009
2022-01-09 14:39:10,136 iteration 4648 : loss : 0.016169, loss_ce: 0.006388
2022-01-09 14:39:12,543 iteration 4649 : loss : 0.024951, loss_ce: 0.010611
2022-01-09 14:39:15,053 iteration 4650 : loss : 0.034645, loss_ce: 0.011472
2022-01-09 14:39:17,439 iteration 4651 : loss : 0.018431, loss_ce: 0.007000
2022-01-09 14:39:19,890 iteration 4652 : loss : 0.024817, loss_ce: 0.012293
2022-01-09 14:39:22,296 iteration 4653 : loss : 0.017619, loss_ce: 0.006371
2022-01-09 14:39:24,643 iteration 4654 : loss : 0.019554, loss_ce: 0.009862
2022-01-09 14:39:26,946 iteration 4655 : loss : 0.018909, loss_ce: 0.005917
2022-01-09 14:39:29,267 iteration 4656 : loss : 0.036906, loss_ce: 0.010143
2022-01-09 14:39:31,563 iteration 4657 : loss : 0.052234, loss_ce: 0.006717
2022-01-09 14:39:33,896 iteration 4658 : loss : 0.025382, loss_ce: 0.006041
 68%|██████████████████▍        | 274/400 [3:15:13<1:27:15, 41.55s/it]2022-01-09 14:39:36,360 iteration 4659 : loss : 0.020692, loss_ce: 0.007454
2022-01-09 14:39:38,770 iteration 4660 : loss : 0.020898, loss_ce: 0.005273
2022-01-09 14:39:41,121 iteration 4661 : loss : 0.029263, loss_ce: 0.014215
2022-01-09 14:39:43,576 iteration 4662 : loss : 0.033394, loss_ce: 0.016261
2022-01-09 14:39:46,108 iteration 4663 : loss : 0.023127, loss_ce: 0.006381
2022-01-09 14:39:48,594 iteration 4664 : loss : 0.030857, loss_ce: 0.008808
2022-01-09 14:39:51,079 iteration 4665 : loss : 0.036144, loss_ce: 0.013559
2022-01-09 14:39:53,315 iteration 4666 : loss : 0.018527, loss_ce: 0.007284
2022-01-09 14:39:55,560 iteration 4667 : loss : 0.024347, loss_ce: 0.010352
2022-01-09 14:39:57,876 iteration 4668 : loss : 0.026602, loss_ce: 0.005753
2022-01-09 14:40:00,237 iteration 4669 : loss : 0.026343, loss_ce: 0.011855
2022-01-09 14:40:02,688 iteration 4670 : loss : 0.024000, loss_ce: 0.010745
2022-01-09 14:40:05,000 iteration 4671 : loss : 0.031404, loss_ce: 0.010545
2022-01-09 14:40:07,454 iteration 4672 : loss : 0.033062, loss_ce: 0.013407
2022-01-09 14:40:09,873 iteration 4673 : loss : 0.020992, loss_ce: 0.006860
2022-01-09 14:40:12,364 iteration 4674 : loss : 0.032506, loss_ce: 0.019167
2022-01-09 14:40:12,364 Training Data Eval:
2022-01-09 14:40:25,423   Average segmentation loss on training set: 0.0143
2022-01-09 14:40:25,424 Validation Data Eval:
2022-01-09 14:40:29,949   Average segmentation loss on validation set: 0.0646
2022-01-09 14:40:32,360 iteration 4675 : loss : 0.022624, loss_ce: 0.008624
 69%|██████████████████▌        | 275/400 [3:16:11<1:37:07, 46.62s/it]2022-01-09 14:40:34,890 iteration 4676 : loss : 0.025014, loss_ce: 0.008276
2022-01-09 14:40:37,282 iteration 4677 : loss : 0.020408, loss_ce: 0.008627
2022-01-09 14:40:39,805 iteration 4678 : loss : 0.033374, loss_ce: 0.010851
2022-01-09 14:40:42,183 iteration 4679 : loss : 0.020799, loss_ce: 0.010577
2022-01-09 14:40:44,517 iteration 4680 : loss : 0.019426, loss_ce: 0.006737
2022-01-09 14:40:46,962 iteration 4681 : loss : 0.040378, loss_ce: 0.014160
2022-01-09 14:40:49,314 iteration 4682 : loss : 0.033582, loss_ce: 0.008336
2022-01-09 14:40:51,725 iteration 4683 : loss : 0.025832, loss_ce: 0.010448
2022-01-09 14:40:54,138 iteration 4684 : loss : 0.023784, loss_ce: 0.010685
2022-01-09 14:40:56,567 iteration 4685 : loss : 0.023108, loss_ce: 0.010212
2022-01-09 14:40:58,945 iteration 4686 : loss : 0.019503, loss_ce: 0.006106
2022-01-09 14:41:01,377 iteration 4687 : loss : 0.017313, loss_ce: 0.007200
2022-01-09 14:41:03,821 iteration 4688 : loss : 0.026176, loss_ce: 0.009143
2022-01-09 14:41:06,404 iteration 4689 : loss : 0.030871, loss_ce: 0.012663
2022-01-09 14:41:08,804 iteration 4690 : loss : 0.024462, loss_ce: 0.006875
2022-01-09 14:41:11,153 iteration 4691 : loss : 0.016433, loss_ce: 0.006248
2022-01-09 14:41:13,601 iteration 4692 : loss : 0.018525, loss_ce: 0.007500
 69%|██████████████████▋        | 276/400 [3:16:52<1:33:01, 45.01s/it]2022-01-09 14:41:16,063 iteration 4693 : loss : 0.020395, loss_ce: 0.008357
2022-01-09 14:41:18,475 iteration 4694 : loss : 0.016850, loss_ce: 0.005178
2022-01-09 14:41:20,988 iteration 4695 : loss : 0.037029, loss_ce: 0.016031
2022-01-09 14:41:23,449 iteration 4696 : loss : 0.023640, loss_ce: 0.011107
2022-01-09 14:41:25,898 iteration 4697 : loss : 0.027935, loss_ce: 0.011758
2022-01-09 14:41:28,270 iteration 4698 : loss : 0.018600, loss_ce: 0.007148
2022-01-09 14:41:30,798 iteration 4699 : loss : 0.019325, loss_ce: 0.007101
2022-01-09 14:41:33,186 iteration 4700 : loss : 0.032836, loss_ce: 0.010454
2022-01-09 14:41:35,486 iteration 4701 : loss : 0.022322, loss_ce: 0.009844
2022-01-09 14:41:37,938 iteration 4702 : loss : 0.017127, loss_ce: 0.006454
2022-01-09 14:41:40,382 iteration 4703 : loss : 0.021556, loss_ce: 0.008050
2022-01-09 14:41:42,761 iteration 4704 : loss : 0.029774, loss_ce: 0.008812
2022-01-09 14:41:45,125 iteration 4705 : loss : 0.015631, loss_ce: 0.005996
2022-01-09 14:41:47,538 iteration 4706 : loss : 0.018076, loss_ce: 0.008206
2022-01-09 14:41:50,065 iteration 4707 : loss : 0.023055, loss_ce: 0.009684
2022-01-09 14:41:52,513 iteration 4708 : loss : 0.022975, loss_ce: 0.005227
2022-01-09 14:41:54,897 iteration 4709 : loss : 0.021447, loss_ce: 0.008496
 69%|██████████████████▋        | 277/400 [3:17:34<1:29:58, 43.89s/it]2022-01-09 14:41:57,427 iteration 4710 : loss : 0.028483, loss_ce: 0.010266
2022-01-09 14:41:59,808 iteration 4711 : loss : 0.029014, loss_ce: 0.015434
2022-01-09 14:42:02,210 iteration 4712 : loss : 0.020488, loss_ce: 0.009615
2022-01-09 14:42:04,585 iteration 4713 : loss : 0.016060, loss_ce: 0.005509
2022-01-09 14:42:06,921 iteration 4714 : loss : 0.015169, loss_ce: 0.006336
2022-01-09 14:42:09,305 iteration 4715 : loss : 0.029744, loss_ce: 0.011333
2022-01-09 14:42:11,740 iteration 4716 : loss : 0.017783, loss_ce: 0.007033
2022-01-09 14:42:14,229 iteration 4717 : loss : 0.022834, loss_ce: 0.007265
2022-01-09 14:42:16,624 iteration 4718 : loss : 0.015327, loss_ce: 0.005265
2022-01-09 14:42:18,967 iteration 4719 : loss : 0.014462, loss_ce: 0.005100
2022-01-09 14:42:21,392 iteration 4720 : loss : 0.023022, loss_ce: 0.008830
2022-01-09 14:42:23,793 iteration 4721 : loss : 0.015651, loss_ce: 0.005263
2022-01-09 14:42:26,164 iteration 4722 : loss : 0.016913, loss_ce: 0.006995
2022-01-09 14:42:28,496 iteration 4723 : loss : 0.024906, loss_ce: 0.006929
2022-01-09 14:42:30,819 iteration 4724 : loss : 0.018158, loss_ce: 0.009319
2022-01-09 14:42:33,280 iteration 4725 : loss : 0.022316, loss_ce: 0.008710
2022-01-09 14:42:35,647 iteration 4726 : loss : 0.019480, loss_ce: 0.006550
 70%|██████████████████▊        | 278/400 [3:18:14<1:27:20, 42.95s/it]2022-01-09 14:42:38,081 iteration 4727 : loss : 0.037118, loss_ce: 0.013380
2022-01-09 14:42:40,614 iteration 4728 : loss : 0.028716, loss_ce: 0.011923
2022-01-09 14:42:43,026 iteration 4729 : loss : 0.014574, loss_ce: 0.004455
2022-01-09 14:42:45,379 iteration 4730 : loss : 0.037090, loss_ce: 0.013661
2022-01-09 14:42:47,956 iteration 4731 : loss : 0.030373, loss_ce: 0.007791
2022-01-09 14:42:50,300 iteration 4732 : loss : 0.018999, loss_ce: 0.007659
2022-01-09 14:42:52,727 iteration 4733 : loss : 0.026783, loss_ce: 0.012669
2022-01-09 14:42:55,042 iteration 4734 : loss : 0.019806, loss_ce: 0.008159
2022-01-09 14:42:57,441 iteration 4735 : loss : 0.016821, loss_ce: 0.006745
2022-01-09 14:42:59,865 iteration 4736 : loss : 0.029753, loss_ce: 0.013086
2022-01-09 14:43:02,222 iteration 4737 : loss : 0.025494, loss_ce: 0.010275
2022-01-09 14:43:04,714 iteration 4738 : loss : 0.032789, loss_ce: 0.010318
2022-01-09 14:43:07,135 iteration 4739 : loss : 0.013623, loss_ce: 0.004812
2022-01-09 14:43:09,543 iteration 4740 : loss : 0.019128, loss_ce: 0.005607
2022-01-09 14:43:11,989 iteration 4741 : loss : 0.018135, loss_ce: 0.008078
2022-01-09 14:43:14,470 iteration 4742 : loss : 0.026011, loss_ce: 0.011440
2022-01-09 14:43:17,012 iteration 4743 : loss : 0.037518, loss_ce: 0.017311
 70%|██████████████████▊        | 279/400 [3:18:56<1:25:39, 42.47s/it]2022-01-09 14:43:19,561 iteration 4744 : loss : 0.032166, loss_ce: 0.012797
2022-01-09 14:43:21,965 iteration 4745 : loss : 0.024801, loss_ce: 0.012040
2022-01-09 14:43:24,406 iteration 4746 : loss : 0.028777, loss_ce: 0.009174
2022-01-09 14:43:26,719 iteration 4747 : loss : 0.019825, loss_ce: 0.011110
2022-01-09 14:43:29,274 iteration 4748 : loss : 0.026033, loss_ce: 0.011008
2022-01-09 14:43:31,631 iteration 4749 : loss : 0.024856, loss_ce: 0.010482
2022-01-09 14:43:34,201 iteration 4750 : loss : 0.024097, loss_ce: 0.008018
2022-01-09 14:43:36,766 iteration 4751 : loss : 0.027576, loss_ce: 0.012764
2022-01-09 14:43:39,137 iteration 4752 : loss : 0.027226, loss_ce: 0.009048
2022-01-09 14:43:41,424 iteration 4753 : loss : 0.015837, loss_ce: 0.005276
2022-01-09 14:43:43,892 iteration 4754 : loss : 0.025515, loss_ce: 0.012207
2022-01-09 14:43:46,427 iteration 4755 : loss : 0.022076, loss_ce: 0.006007
2022-01-09 14:43:48,845 iteration 4756 : loss : 0.022570, loss_ce: 0.006714
2022-01-09 14:43:51,266 iteration 4757 : loss : 0.023411, loss_ce: 0.011712
2022-01-09 14:43:53,781 iteration 4758 : loss : 0.037892, loss_ce: 0.015054
2022-01-09 14:43:56,240 iteration 4759 : loss : 0.025860, loss_ce: 0.014811
2022-01-09 14:43:56,240 Training Data Eval:
2022-01-09 14:44:09,391   Average segmentation loss on training set: 0.0149
2022-01-09 14:44:09,391 Validation Data Eval:
2022-01-09 14:44:13,955   Average segmentation loss on validation set: 0.0925
2022-01-09 14:44:16,455 iteration 4760 : loss : 0.027630, loss_ce: 0.009183
 70%|██████████████████▉        | 280/400 [3:19:55<1:35:07, 47.56s/it]2022-01-09 14:44:18,869 iteration 4761 : loss : 0.016321, loss_ce: 0.005455
2022-01-09 14:44:21,328 iteration 4762 : loss : 0.034047, loss_ce: 0.010040
2022-01-09 14:44:23,695 iteration 4763 : loss : 0.023078, loss_ce: 0.010540
2022-01-09 14:44:26,014 iteration 4764 : loss : 0.020162, loss_ce: 0.007719
2022-01-09 14:44:28,369 iteration 4765 : loss : 0.022574, loss_ce: 0.009046
2022-01-09 14:44:30,702 iteration 4766 : loss : 0.019452, loss_ce: 0.006630
2022-01-09 14:44:33,265 iteration 4767 : loss : 0.023436, loss_ce: 0.008398
2022-01-09 14:44:35,734 iteration 4768 : loss : 0.031224, loss_ce: 0.014555
2022-01-09 14:44:38,211 iteration 4769 : loss : 0.026143, loss_ce: 0.007262
2022-01-09 14:44:40,633 iteration 4770 : loss : 0.019811, loss_ce: 0.010591
2022-01-09 14:44:42,978 iteration 4771 : loss : 0.018238, loss_ce: 0.008065
2022-01-09 14:44:45,381 iteration 4772 : loss : 0.015477, loss_ce: 0.004754
2022-01-09 14:44:47,723 iteration 4773 : loss : 0.018953, loss_ce: 0.007376
2022-01-09 14:44:50,236 iteration 4774 : loss : 0.016757, loss_ce: 0.006501
2022-01-09 14:44:52,684 iteration 4775 : loss : 0.031139, loss_ce: 0.012685
2022-01-09 14:44:55,121 iteration 4776 : loss : 0.020608, loss_ce: 0.008403
2022-01-09 14:44:57,483 iteration 4777 : loss : 0.017693, loss_ce: 0.006031
 70%|██████████████████▉        | 281/400 [3:20:36<1:30:26, 45.60s/it]2022-01-09 14:44:59,978 iteration 4778 : loss : 0.024949, loss_ce: 0.009880
2022-01-09 14:45:02,355 iteration 4779 : loss : 0.018480, loss_ce: 0.007409
2022-01-09 14:45:04,703 iteration 4780 : loss : 0.029784, loss_ce: 0.007319
2022-01-09 14:45:07,122 iteration 4781 : loss : 0.016785, loss_ce: 0.007447
2022-01-09 14:45:09,552 iteration 4782 : loss : 0.038345, loss_ce: 0.013020
2022-01-09 14:45:12,069 iteration 4783 : loss : 0.020481, loss_ce: 0.005849
2022-01-09 14:45:14,504 iteration 4784 : loss : 0.022113, loss_ce: 0.009503
2022-01-09 14:45:16,959 iteration 4785 : loss : 0.034531, loss_ce: 0.016658
2022-01-09 14:45:19,367 iteration 4786 : loss : 0.018868, loss_ce: 0.007691
2022-01-09 14:45:21,753 iteration 4787 : loss : 0.024481, loss_ce: 0.005870
2022-01-09 14:45:24,139 iteration 4788 : loss : 0.016433, loss_ce: 0.005919
2022-01-09 14:45:26,509 iteration 4789 : loss : 0.019900, loss_ce: 0.007607
2022-01-09 14:45:28,948 iteration 4790 : loss : 0.016732, loss_ce: 0.007326
2022-01-09 14:45:31,360 iteration 4791 : loss : 0.014175, loss_ce: 0.005196
2022-01-09 14:45:33,723 iteration 4792 : loss : 0.026490, loss_ce: 0.011559
2022-01-09 14:45:36,203 iteration 4793 : loss : 0.018241, loss_ce: 0.008528
2022-01-09 14:45:38,600 iteration 4794 : loss : 0.034662, loss_ce: 0.006576
 70%|███████████████████        | 282/400 [3:21:17<1:27:02, 44.26s/it]2022-01-09 14:45:41,150 iteration 4795 : loss : 0.017705, loss_ce: 0.006143
2022-01-09 14:45:43,500 iteration 4796 : loss : 0.020300, loss_ce: 0.007897
2022-01-09 14:45:45,825 iteration 4797 : loss : 0.018386, loss_ce: 0.006810
2022-01-09 14:45:48,195 iteration 4798 : loss : 0.031113, loss_ce: 0.013113
2022-01-09 14:45:50,611 iteration 4799 : loss : 0.025139, loss_ce: 0.006049
2022-01-09 14:45:52,999 iteration 4800 : loss : 0.046817, loss_ce: 0.020405
2022-01-09 14:45:55,385 iteration 4801 : loss : 0.018479, loss_ce: 0.007891
2022-01-09 14:45:57,708 iteration 4802 : loss : 0.014849, loss_ce: 0.004806
2022-01-09 14:46:00,163 iteration 4803 : loss : 0.020968, loss_ce: 0.009343
2022-01-09 14:46:02,575 iteration 4804 : loss : 0.023823, loss_ce: 0.008159
2022-01-09 14:46:05,009 iteration 4805 : loss : 0.023290, loss_ce: 0.008114
2022-01-09 14:46:07,340 iteration 4806 : loss : 0.018812, loss_ce: 0.005620
2022-01-09 14:46:09,736 iteration 4807 : loss : 0.025612, loss_ce: 0.009689
2022-01-09 14:46:12,309 iteration 4808 : loss : 0.030164, loss_ce: 0.010814
2022-01-09 14:46:14,642 iteration 4809 : loss : 0.014863, loss_ce: 0.006291
2022-01-09 14:46:17,064 iteration 4810 : loss : 0.017959, loss_ce: 0.006713
2022-01-09 14:46:19,389 iteration 4811 : loss : 0.023143, loss_ce: 0.008553
 71%|███████████████████        | 283/400 [3:21:58<1:24:16, 43.22s/it]2022-01-09 14:46:21,789 iteration 4812 : loss : 0.036288, loss_ce: 0.016822
2022-01-09 14:46:24,141 iteration 4813 : loss : 0.035124, loss_ce: 0.012618
2022-01-09 14:46:26,472 iteration 4814 : loss : 0.016358, loss_ce: 0.007689
2022-01-09 14:46:29,067 iteration 4815 : loss : 0.018065, loss_ce: 0.006603
2022-01-09 14:46:31,405 iteration 4816 : loss : 0.019598, loss_ce: 0.006845
2022-01-09 14:46:33,857 iteration 4817 : loss : 0.017047, loss_ce: 0.006044
2022-01-09 14:46:36,331 iteration 4818 : loss : 0.029109, loss_ce: 0.013561
2022-01-09 14:46:38,785 iteration 4819 : loss : 0.031212, loss_ce: 0.010728
2022-01-09 14:46:41,249 iteration 4820 : loss : 0.022042, loss_ce: 0.009586
2022-01-09 14:46:43,612 iteration 4821 : loss : 0.019351, loss_ce: 0.007499
2022-01-09 14:46:46,014 iteration 4822 : loss : 0.030472, loss_ce: 0.009425
2022-01-09 14:46:48,393 iteration 4823 : loss : 0.020394, loss_ce: 0.008460
2022-01-09 14:46:50,819 iteration 4824 : loss : 0.016323, loss_ce: 0.005773
2022-01-09 14:46:53,327 iteration 4825 : loss : 0.013987, loss_ce: 0.004403
2022-01-09 14:46:55,705 iteration 4826 : loss : 0.029216, loss_ce: 0.008962
2022-01-09 14:46:58,142 iteration 4827 : loss : 0.023534, loss_ce: 0.008194
2022-01-09 14:47:00,557 iteration 4828 : loss : 0.039200, loss_ce: 0.016989
 71%|███████████████████▏       | 284/400 [3:22:39<1:22:22, 42.60s/it]2022-01-09 14:47:03,014 iteration 4829 : loss : 0.038342, loss_ce: 0.011680
2022-01-09 14:47:05,299 iteration 4830 : loss : 0.020443, loss_ce: 0.006722
2022-01-09 14:47:07,642 iteration 4831 : loss : 0.034079, loss_ce: 0.011718
2022-01-09 14:47:09,930 iteration 4832 : loss : 0.026858, loss_ce: 0.010949
2022-01-09 14:47:12,329 iteration 4833 : loss : 0.024433, loss_ce: 0.006985
2022-01-09 14:47:14,667 iteration 4834 : loss : 0.043149, loss_ce: 0.017398
2022-01-09 14:47:16,879 iteration 4835 : loss : 0.022507, loss_ce: 0.008487
2022-01-09 14:47:19,186 iteration 4836 : loss : 0.022649, loss_ce: 0.008544
2022-01-09 14:47:21,454 iteration 4837 : loss : 0.036691, loss_ce: 0.008007
2022-01-09 14:47:23,862 iteration 4838 : loss : 0.021182, loss_ce: 0.009141
2022-01-09 14:47:26,273 iteration 4839 : loss : 0.021299, loss_ce: 0.009968
2022-01-09 14:47:28,812 iteration 4840 : loss : 0.030321, loss_ce: 0.011219
2022-01-09 14:47:31,268 iteration 4841 : loss : 0.025958, loss_ce: 0.009516
2022-01-09 14:47:33,708 iteration 4842 : loss : 0.022600, loss_ce: 0.008844
2022-01-09 14:47:36,093 iteration 4843 : loss : 0.027796, loss_ce: 0.011867
2022-01-09 14:47:38,367 iteration 4844 : loss : 0.019705, loss_ce: 0.009159
2022-01-09 14:47:38,367 Training Data Eval:
2022-01-09 14:47:51,175   Average segmentation loss on training set: 0.0128
2022-01-09 14:47:51,175 Validation Data Eval:
2022-01-09 14:47:55,682   Average segmentation loss on validation set: 0.0732
2022-01-09 14:47:58,100 iteration 4845 : loss : 0.020716, loss_ce: 0.006636
 71%|███████████████████▏       | 285/400 [3:23:37<1:30:14, 47.09s/it]2022-01-09 14:48:00,550 iteration 4846 : loss : 0.020032, loss_ce: 0.006970
2022-01-09 14:48:02,863 iteration 4847 : loss : 0.020486, loss_ce: 0.006271
2022-01-09 14:48:05,215 iteration 4848 : loss : 0.022539, loss_ce: 0.009122
2022-01-09 14:48:07,453 iteration 4849 : loss : 0.018499, loss_ce: 0.008074
2022-01-09 14:48:09,816 iteration 4850 : loss : 0.051977, loss_ce: 0.011660
2022-01-09 14:48:12,102 iteration 4851 : loss : 0.019232, loss_ce: 0.008742
2022-01-09 14:48:14,583 iteration 4852 : loss : 0.023989, loss_ce: 0.010071
2022-01-09 14:48:16,966 iteration 4853 : loss : 0.020731, loss_ce: 0.007634
2022-01-09 14:48:19,265 iteration 4854 : loss : 0.024589, loss_ce: 0.008670
2022-01-09 14:48:21,586 iteration 4855 : loss : 0.023906, loss_ce: 0.008399
2022-01-09 14:48:24,043 iteration 4856 : loss : 0.027659, loss_ce: 0.009946
2022-01-09 14:48:26,488 iteration 4857 : loss : 0.026506, loss_ce: 0.013555
2022-01-09 14:48:28,868 iteration 4858 : loss : 0.023121, loss_ce: 0.010087
2022-01-09 14:48:31,230 iteration 4859 : loss : 0.015542, loss_ce: 0.006162
2022-01-09 14:48:33,610 iteration 4860 : loss : 0.019193, loss_ce: 0.005019
2022-01-09 14:48:35,905 iteration 4861 : loss : 0.022433, loss_ce: 0.007272
2022-01-09 14:48:38,274 iteration 4862 : loss : 0.022413, loss_ce: 0.006962
 72%|███████████████████▎       | 286/400 [3:24:17<1:25:31, 45.01s/it]2022-01-09 14:48:40,655 iteration 4863 : loss : 0.024472, loss_ce: 0.007416
2022-01-09 14:48:43,115 iteration 4864 : loss : 0.026037, loss_ce: 0.009317
2022-01-09 14:48:45,537 iteration 4865 : loss : 0.021206, loss_ce: 0.008033
2022-01-09 14:48:47,876 iteration 4866 : loss : 0.024153, loss_ce: 0.010376
2022-01-09 14:48:50,210 iteration 4867 : loss : 0.041924, loss_ce: 0.016660
2022-01-09 14:48:52,599 iteration 4868 : loss : 0.019098, loss_ce: 0.009172
2022-01-09 14:48:54,977 iteration 4869 : loss : 0.018033, loss_ce: 0.005943
2022-01-09 14:48:57,253 iteration 4870 : loss : 0.016129, loss_ce: 0.005966
2022-01-09 14:48:59,547 iteration 4871 : loss : 0.020638, loss_ce: 0.006490
2022-01-09 14:49:01,827 iteration 4872 : loss : 0.018644, loss_ce: 0.008458
2022-01-09 14:49:04,109 iteration 4873 : loss : 0.018733, loss_ce: 0.006355
2022-01-09 14:49:06,471 iteration 4874 : loss : 0.017753, loss_ce: 0.006209
2022-01-09 14:49:08,972 iteration 4875 : loss : 0.020927, loss_ce: 0.005623
2022-01-09 14:49:11,293 iteration 4876 : loss : 0.016976, loss_ce: 0.007438
2022-01-09 14:49:13,600 iteration 4877 : loss : 0.015030, loss_ce: 0.005376
2022-01-09 14:49:15,883 iteration 4878 : loss : 0.036133, loss_ce: 0.012786
2022-01-09 14:49:18,167 iteration 4879 : loss : 0.020219, loss_ce: 0.006617
 72%|███████████████████▎       | 287/400 [3:24:57<1:21:52, 43.48s/it]2022-01-09 14:49:20,422 iteration 4880 : loss : 0.018187, loss_ce: 0.006169
2022-01-09 14:49:22,582 iteration 4881 : loss : 0.014331, loss_ce: 0.004728
2022-01-09 14:49:24,848 iteration 4882 : loss : 0.016327, loss_ce: 0.004221
2022-01-09 14:49:27,153 iteration 4883 : loss : 0.020461, loss_ce: 0.008857
2022-01-09 14:49:29,399 iteration 4884 : loss : 0.030368, loss_ce: 0.013953
2022-01-09 14:49:31,726 iteration 4885 : loss : 0.018850, loss_ce: 0.005740
2022-01-09 14:49:34,021 iteration 4886 : loss : 0.017804, loss_ce: 0.006586
2022-01-09 14:49:36,249 iteration 4887 : loss : 0.023296, loss_ce: 0.010974
2022-01-09 14:49:38,514 iteration 4888 : loss : 0.016071, loss_ce: 0.004149
2022-01-09 14:49:40,795 iteration 4889 : loss : 0.021347, loss_ce: 0.008936
2022-01-09 14:49:43,106 iteration 4890 : loss : 0.020770, loss_ce: 0.007718
2022-01-09 14:49:45,442 iteration 4891 : loss : 0.022384, loss_ce: 0.011074
2022-01-09 14:49:47,748 iteration 4892 : loss : 0.017469, loss_ce: 0.007885
2022-01-09 14:49:50,204 iteration 4893 : loss : 0.022815, loss_ce: 0.008577
2022-01-09 14:49:52,510 iteration 4894 : loss : 0.021183, loss_ce: 0.008080
2022-01-09 14:49:54,839 iteration 4895 : loss : 0.017752, loss_ce: 0.008088
2022-01-09 14:49:57,105 iteration 4896 : loss : 0.020854, loss_ce: 0.008181
 72%|███████████████████▍       | 288/400 [3:25:36<1:18:36, 42.12s/it]2022-01-09 14:49:59,339 iteration 4897 : loss : 0.013694, loss_ce: 0.006492
2022-01-09 14:50:01,528 iteration 4898 : loss : 0.014666, loss_ce: 0.005388
2022-01-09 14:50:03,784 iteration 4899 : loss : 0.024372, loss_ce: 0.015513
2022-01-09 14:50:06,172 iteration 4900 : loss : 0.047554, loss_ce: 0.018988
2022-01-09 14:50:08,440 iteration 4901 : loss : 0.023216, loss_ce: 0.007234
2022-01-09 14:50:10,727 iteration 4902 : loss : 0.018514, loss_ce: 0.004279
2022-01-09 14:50:13,036 iteration 4903 : loss : 0.022160, loss_ce: 0.009205
2022-01-09 14:50:15,368 iteration 4904 : loss : 0.021520, loss_ce: 0.010187
2022-01-09 14:50:17,646 iteration 4905 : loss : 0.017744, loss_ce: 0.007924
2022-01-09 14:50:19,956 iteration 4906 : loss : 0.016566, loss_ce: 0.006109
2022-01-09 14:50:22,245 iteration 4907 : loss : 0.027717, loss_ce: 0.009851
2022-01-09 14:50:24,448 iteration 4908 : loss : 0.026519, loss_ce: 0.006873
2022-01-09 14:50:26,774 iteration 4909 : loss : 0.028155, loss_ce: 0.009108
2022-01-09 14:50:29,099 iteration 4910 : loss : 0.021065, loss_ce: 0.004944
2022-01-09 14:50:31,545 iteration 4911 : loss : 0.019501, loss_ce: 0.007623
2022-01-09 14:50:33,907 iteration 4912 : loss : 0.031246, loss_ce: 0.009992
2022-01-09 14:50:36,287 iteration 4913 : loss : 0.018706, loss_ce: 0.006200
 72%|███████████████████▌       | 289/400 [3:26:15<1:16:16, 41.23s/it]2022-01-09 14:50:38,647 iteration 4914 : loss : 0.017415, loss_ce: 0.005243
2022-01-09 14:50:41,070 iteration 4915 : loss : 0.024433, loss_ce: 0.009309
2022-01-09 14:50:43,497 iteration 4916 : loss : 0.023285, loss_ce: 0.007055
2022-01-09 14:50:45,866 iteration 4917 : loss : 0.024648, loss_ce: 0.010773
2022-01-09 14:50:48,159 iteration 4918 : loss : 0.018285, loss_ce: 0.008304
2022-01-09 14:50:50,395 iteration 4919 : loss : 0.016786, loss_ce: 0.006490
2022-01-09 14:50:52,651 iteration 4920 : loss : 0.020714, loss_ce: 0.009047
2022-01-09 14:50:55,001 iteration 4921 : loss : 0.020444, loss_ce: 0.005009
2022-01-09 14:50:57,395 iteration 4922 : loss : 0.031081, loss_ce: 0.005378
2022-01-09 14:50:59,767 iteration 4923 : loss : 0.024935, loss_ce: 0.009435
2022-01-09 14:51:02,192 iteration 4924 : loss : 0.022600, loss_ce: 0.009227
2022-01-09 14:51:04,642 iteration 4925 : loss : 0.027340, loss_ce: 0.011068
2022-01-09 14:51:06,901 iteration 4926 : loss : 0.020755, loss_ce: 0.009570
2022-01-09 14:51:09,232 iteration 4927 : loss : 0.017943, loss_ce: 0.007439
2022-01-09 14:51:11,550 iteration 4928 : loss : 0.026235, loss_ce: 0.013027
2022-01-09 14:51:13,912 iteration 4929 : loss : 0.038820, loss_ce: 0.013478
2022-01-09 14:51:13,912 Training Data Eval:
2022-01-09 14:51:26,868   Average segmentation loss on training set: 0.0145
2022-01-09 14:51:26,868 Validation Data Eval:
2022-01-09 14:51:31,385   Average segmentation loss on validation set: 0.0682
2022-01-09 14:51:33,763 iteration 4930 : loss : 0.016086, loss_ce: 0.006122
 72%|███████████████████▌       | 290/400 [3:27:12<1:24:32, 46.11s/it]2022-01-09 14:51:36,149 iteration 4931 : loss : 0.020224, loss_ce: 0.008940
2022-01-09 14:51:38,376 iteration 4932 : loss : 0.018035, loss_ce: 0.007007
2022-01-09 14:51:40,643 iteration 4933 : loss : 0.024836, loss_ce: 0.008202
2022-01-09 14:51:43,027 iteration 4934 : loss : 0.021645, loss_ce: 0.009828
2022-01-09 14:51:45,393 iteration 4935 : loss : 0.022975, loss_ce: 0.007542
2022-01-09 14:51:47,805 iteration 4936 : loss : 0.020892, loss_ce: 0.007911
2022-01-09 14:51:50,202 iteration 4937 : loss : 0.025059, loss_ce: 0.007970
2022-01-09 14:51:52,572 iteration 4938 : loss : 0.028418, loss_ce: 0.010529
2022-01-09 14:51:54,963 iteration 4939 : loss : 0.018762, loss_ce: 0.006976
2022-01-09 14:51:57,225 iteration 4940 : loss : 0.020295, loss_ce: 0.005819
2022-01-09 14:51:59,637 iteration 4941 : loss : 0.017966, loss_ce: 0.006549
2022-01-09 14:52:02,047 iteration 4942 : loss : 0.019992, loss_ce: 0.007212
2022-01-09 14:52:04,344 iteration 4943 : loss : 0.013845, loss_ce: 0.004300
2022-01-09 14:52:06,654 iteration 4944 : loss : 0.033059, loss_ce: 0.013995
2022-01-09 14:52:09,023 iteration 4945 : loss : 0.020056, loss_ce: 0.005908
2022-01-09 14:52:11,301 iteration 4946 : loss : 0.028716, loss_ce: 0.013273
2022-01-09 14:52:13,646 iteration 4947 : loss : 0.020165, loss_ce: 0.007406
 73%|███████████████████▋       | 291/400 [3:27:52<1:20:22, 44.24s/it]2022-01-09 14:52:16,001 iteration 4948 : loss : 0.028342, loss_ce: 0.010310
2022-01-09 14:52:18,358 iteration 4949 : loss : 0.020636, loss_ce: 0.008451
2022-01-09 14:52:20,759 iteration 4950 : loss : 0.031009, loss_ce: 0.013789
2022-01-09 14:52:23,115 iteration 4951 : loss : 0.023850, loss_ce: 0.008707
2022-01-09 14:52:25,467 iteration 4952 : loss : 0.020450, loss_ce: 0.007807
2022-01-09 14:52:27,882 iteration 4953 : loss : 0.020458, loss_ce: 0.009777
2022-01-09 14:52:30,282 iteration 4954 : loss : 0.021868, loss_ce: 0.008589
2022-01-09 14:52:32,668 iteration 4955 : loss : 0.015667, loss_ce: 0.006069
2022-01-09 14:52:35,023 iteration 4956 : loss : 0.028993, loss_ce: 0.010177
2022-01-09 14:52:37,419 iteration 4957 : loss : 0.015462, loss_ce: 0.007022
2022-01-09 14:52:39,796 iteration 4958 : loss : 0.021931, loss_ce: 0.010453
2022-01-09 14:52:42,136 iteration 4959 : loss : 0.015629, loss_ce: 0.005147
2022-01-09 14:52:44,565 iteration 4960 : loss : 0.027824, loss_ce: 0.010771
2022-01-09 14:52:46,922 iteration 4961 : loss : 0.025018, loss_ce: 0.011064
2022-01-09 14:52:49,297 iteration 4962 : loss : 0.019911, loss_ce: 0.008671
2022-01-09 14:52:51,617 iteration 4963 : loss : 0.016937, loss_ce: 0.006745
2022-01-09 14:52:54,075 iteration 4964 : loss : 0.023635, loss_ce: 0.009956
 73%|███████████████████▋       | 292/400 [3:28:33<1:17:34, 43.09s/it]2022-01-09 14:52:56,567 iteration 4965 : loss : 0.032862, loss_ce: 0.012580
2022-01-09 14:52:58,982 iteration 4966 : loss : 0.024809, loss_ce: 0.007343
2022-01-09 14:53:01,275 iteration 4967 : loss : 0.013790, loss_ce: 0.005657
2022-01-09 14:53:03,651 iteration 4968 : loss : 0.016915, loss_ce: 0.007182
2022-01-09 14:53:05,985 iteration 4969 : loss : 0.020360, loss_ce: 0.004621
2022-01-09 14:53:08,322 iteration 4970 : loss : 0.015402, loss_ce: 0.005897
2022-01-09 14:53:10,796 iteration 4971 : loss : 0.019975, loss_ce: 0.007771
2022-01-09 14:53:13,234 iteration 4972 : loss : 0.022857, loss_ce: 0.007757
2022-01-09 14:53:15,621 iteration 4973 : loss : 0.018426, loss_ce: 0.006897
2022-01-09 14:53:17,963 iteration 4974 : loss : 0.019286, loss_ce: 0.007060
2022-01-09 14:53:20,356 iteration 4975 : loss : 0.023584, loss_ce: 0.007819
2022-01-09 14:53:22,781 iteration 4976 : loss : 0.023695, loss_ce: 0.009214
2022-01-09 14:53:25,247 iteration 4977 : loss : 0.023802, loss_ce: 0.012436
2022-01-09 14:53:27,696 iteration 4978 : loss : 0.038577, loss_ce: 0.010783
2022-01-09 14:53:30,090 iteration 4979 : loss : 0.031317, loss_ce: 0.015320
2022-01-09 14:53:32,440 iteration 4980 : loss : 0.013664, loss_ce: 0.005186
2022-01-09 14:53:34,884 iteration 4981 : loss : 0.025518, loss_ce: 0.008374
 73%|███████████████████▊       | 293/400 [3:29:14<1:15:37, 42.41s/it]2022-01-09 14:53:37,482 iteration 4982 : loss : 0.020141, loss_ce: 0.008196
2022-01-09 14:53:39,859 iteration 4983 : loss : 0.016106, loss_ce: 0.006426
2022-01-09 14:53:42,287 iteration 4984 : loss : 0.024252, loss_ce: 0.009612
2022-01-09 14:53:44,645 iteration 4985 : loss : 0.019978, loss_ce: 0.006281
2022-01-09 14:53:47,063 iteration 4986 : loss : 0.037001, loss_ce: 0.017372
2022-01-09 14:53:49,395 iteration 4987 : loss : 0.016689, loss_ce: 0.007756
2022-01-09 14:53:51,720 iteration 4988 : loss : 0.021138, loss_ce: 0.010972
2022-01-09 14:53:54,237 iteration 4989 : loss : 0.019678, loss_ce: 0.007207
2022-01-09 14:53:56,699 iteration 4990 : loss : 0.022299, loss_ce: 0.007598
2022-01-09 14:53:59,147 iteration 4991 : loss : 0.016164, loss_ce: 0.004284
2022-01-09 14:54:01,602 iteration 4992 : loss : 0.026071, loss_ce: 0.016343
2022-01-09 14:54:04,069 iteration 4993 : loss : 0.021916, loss_ce: 0.010046
2022-01-09 14:54:06,499 iteration 4994 : loss : 0.027273, loss_ce: 0.006212
2022-01-09 14:54:08,879 iteration 4995 : loss : 0.023672, loss_ce: 0.008866
2022-01-09 14:54:11,259 iteration 4996 : loss : 0.022167, loss_ce: 0.007949
2022-01-09 14:54:13,878 iteration 4997 : loss : 0.023132, loss_ce: 0.009104
2022-01-09 14:54:16,245 iteration 4998 : loss : 0.016170, loss_ce: 0.005938
 74%|███████████████████▊       | 294/400 [3:29:55<1:14:22, 42.10s/it]2022-01-09 14:54:18,685 iteration 4999 : loss : 0.019241, loss_ce: 0.007958
2022-01-09 14:54:21,000 iteration 5000 : loss : 0.014942, loss_ce: 0.005262
2022-01-09 14:54:23,410 iteration 5001 : loss : 0.026837, loss_ce: 0.008228
2022-01-09 14:54:25,809 iteration 5002 : loss : 0.018447, loss_ce: 0.006438
2022-01-09 14:54:28,233 iteration 5003 : loss : 0.027134, loss_ce: 0.007042
2022-01-09 14:54:30,843 iteration 5004 : loss : 0.029264, loss_ce: 0.008975
2022-01-09 14:54:33,219 iteration 5005 : loss : 0.019694, loss_ce: 0.006789
2022-01-09 14:54:35,652 iteration 5006 : loss : 0.015676, loss_ce: 0.004362
2022-01-09 14:54:38,105 iteration 5007 : loss : 0.015651, loss_ce: 0.005912
2022-01-09 14:54:40,483 iteration 5008 : loss : 0.021178, loss_ce: 0.006814
2022-01-09 14:54:42,881 iteration 5009 : loss : 0.024050, loss_ce: 0.007022
2022-01-09 14:54:45,323 iteration 5010 : loss : 0.035690, loss_ce: 0.013239
2022-01-09 14:54:47,725 iteration 5011 : loss : 0.023162, loss_ce: 0.013112
2022-01-09 14:54:50,165 iteration 5012 : loss : 0.025991, loss_ce: 0.011430
2022-01-09 14:54:52,701 iteration 5013 : loss : 0.025751, loss_ce: 0.009362
2022-01-09 14:54:55,074 iteration 5014 : loss : 0.015848, loss_ce: 0.005368
2022-01-09 14:54:55,074 Training Data Eval:
2022-01-09 14:55:08,099   Average segmentation loss on training set: 0.0128
2022-01-09 14:55:08,099 Validation Data Eval:
2022-01-09 14:55:12,613   Average segmentation loss on validation set: 0.0734
2022-01-09 14:55:14,999 iteration 5015 : loss : 0.023248, loss_ce: 0.005309
 74%|███████████████████▉       | 295/400 [3:30:54<1:22:24, 47.09s/it]2022-01-09 14:55:17,565 iteration 5016 : loss : 0.022248, loss_ce: 0.008884
2022-01-09 14:55:19,975 iteration 5017 : loss : 0.016031, loss_ce: 0.004774
2022-01-09 14:55:22,465 iteration 5018 : loss : 0.023745, loss_ce: 0.008405
2022-01-09 14:55:24,753 iteration 5019 : loss : 0.024849, loss_ce: 0.005993
2022-01-09 14:55:27,209 iteration 5020 : loss : 0.023265, loss_ce: 0.011212
2022-01-09 14:55:29,654 iteration 5021 : loss : 0.016794, loss_ce: 0.005754
2022-01-09 14:55:32,120 iteration 5022 : loss : 0.034950, loss_ce: 0.016325
2022-01-09 14:55:34,524 iteration 5023 : loss : 0.023959, loss_ce: 0.010224
2022-01-09 14:55:36,838 iteration 5024 : loss : 0.014372, loss_ce: 0.005228
2022-01-09 14:55:39,471 iteration 5025 : loss : 0.017090, loss_ce: 0.006329
2022-01-09 14:55:41,952 iteration 5026 : loss : 0.031674, loss_ce: 0.015109
2022-01-09 14:55:44,416 iteration 5027 : loss : 0.016261, loss_ce: 0.005699
2022-01-09 14:55:46,841 iteration 5028 : loss : 0.021132, loss_ce: 0.008348
2022-01-09 14:55:49,176 iteration 5029 : loss : 0.016381, loss_ce: 0.006826
2022-01-09 14:55:51,608 iteration 5030 : loss : 0.032764, loss_ce: 0.014108
2022-01-09 14:55:54,079 iteration 5031 : loss : 0.021701, loss_ce: 0.009016
2022-01-09 14:55:56,528 iteration 5032 : loss : 0.020296, loss_ce: 0.007434
 74%|███████████████████▉       | 296/400 [3:31:35<1:18:44, 45.43s/it]2022-01-09 14:55:58,976 iteration 5033 : loss : 0.021948, loss_ce: 0.012068
2022-01-09 14:56:01,312 iteration 5034 : loss : 0.024947, loss_ce: 0.007015
2022-01-09 14:56:03,690 iteration 5035 : loss : 0.023985, loss_ce: 0.008553
2022-01-09 14:56:06,032 iteration 5036 : loss : 0.013751, loss_ce: 0.004906
2022-01-09 14:56:08,379 iteration 5037 : loss : 0.015482, loss_ce: 0.005710
2022-01-09 14:56:11,045 iteration 5038 : loss : 0.024804, loss_ce: 0.011063
2022-01-09 14:56:13,405 iteration 5039 : loss : 0.015545, loss_ce: 0.004975
2022-01-09 14:56:15,724 iteration 5040 : loss : 0.020568, loss_ce: 0.009484
2022-01-09 14:56:17,992 iteration 5041 : loss : 0.017408, loss_ce: 0.006228
2022-01-09 14:56:20,363 iteration 5042 : loss : 0.015765, loss_ce: 0.006245
2022-01-09 14:56:22,741 iteration 5043 : loss : 0.016948, loss_ce: 0.005988
2022-01-09 14:56:25,132 iteration 5044 : loss : 0.015297, loss_ce: 0.005417
2022-01-09 14:56:27,568 iteration 5045 : loss : 0.014280, loss_ce: 0.004473
2022-01-09 14:56:30,130 iteration 5046 : loss : 0.046631, loss_ce: 0.015309
2022-01-09 14:56:32,504 iteration 5047 : loss : 0.016500, loss_ce: 0.006686
2022-01-09 14:56:34,827 iteration 5048 : loss : 0.015674, loss_ce: 0.006019
2022-01-09 14:56:37,346 iteration 5049 : loss : 0.025465, loss_ce: 0.010013
 74%|████████████████████       | 297/400 [3:32:16<1:15:36, 44.04s/it]2022-01-09 14:56:39,773 iteration 5050 : loss : 0.022070, loss_ce: 0.006161
2022-01-09 14:56:42,194 iteration 5051 : loss : 0.016877, loss_ce: 0.007132
2022-01-09 14:56:44,602 iteration 5052 : loss : 0.019408, loss_ce: 0.009784
2022-01-09 14:56:47,066 iteration 5053 : loss : 0.017745, loss_ce: 0.006550
2022-01-09 14:56:49,517 iteration 5054 : loss : 0.017822, loss_ce: 0.008385
2022-01-09 14:56:51,938 iteration 5055 : loss : 0.015738, loss_ce: 0.005576
2022-01-09 14:56:54,362 iteration 5056 : loss : 0.020602, loss_ce: 0.006375
2022-01-09 14:56:56,728 iteration 5057 : loss : 0.019509, loss_ce: 0.009483
2022-01-09 14:56:59,092 iteration 5058 : loss : 0.020058, loss_ce: 0.007791
2022-01-09 14:57:01,630 iteration 5059 : loss : 0.017137, loss_ce: 0.007953
2022-01-09 14:57:04,056 iteration 5060 : loss : 0.035389, loss_ce: 0.008137
2022-01-09 14:57:06,625 iteration 5061 : loss : 0.023428, loss_ce: 0.011706
2022-01-09 14:57:09,057 iteration 5062 : loss : 0.019782, loss_ce: 0.006759
2022-01-09 14:57:11,474 iteration 5063 : loss : 0.014427, loss_ce: 0.005544
2022-01-09 14:57:13,856 iteration 5064 : loss : 0.032968, loss_ce: 0.008551
2022-01-09 14:57:16,263 iteration 5065 : loss : 0.036306, loss_ce: 0.011676
2022-01-09 14:57:18,535 iteration 5066 : loss : 0.016439, loss_ce: 0.007030
 74%|████████████████████       | 298/400 [3:32:57<1:13:24, 43.18s/it]2022-01-09 14:57:21,158 iteration 5067 : loss : 0.017746, loss_ce: 0.006061
2022-01-09 14:57:23,720 iteration 5068 : loss : 0.014437, loss_ce: 0.005123
2022-01-09 14:57:26,093 iteration 5069 : loss : 0.019969, loss_ce: 0.006892
2022-01-09 14:57:28,470 iteration 5070 : loss : 0.019400, loss_ce: 0.010310
2022-01-09 14:57:31,091 iteration 5071 : loss : 0.026159, loss_ce: 0.010884
2022-01-09 14:57:33,489 iteration 5072 : loss : 0.020655, loss_ce: 0.006309
2022-01-09 14:57:35,917 iteration 5073 : loss : 0.028592, loss_ce: 0.007350
2022-01-09 14:57:38,250 iteration 5074 : loss : 0.022141, loss_ce: 0.008576
2022-01-09 14:57:40,547 iteration 5075 : loss : 0.017759, loss_ce: 0.008118
2022-01-09 14:57:42,849 iteration 5076 : loss : 0.017180, loss_ce: 0.006764
2022-01-09 14:57:45,282 iteration 5077 : loss : 0.040306, loss_ce: 0.016486
2022-01-09 14:57:47,699 iteration 5078 : loss : 0.022643, loss_ce: 0.007211
2022-01-09 14:57:50,060 iteration 5079 : loss : 0.012720, loss_ce: 0.004480
2022-01-09 14:57:52,457 iteration 5080 : loss : 0.020700, loss_ce: 0.008187
2022-01-09 14:57:54,925 iteration 5081 : loss : 0.019714, loss_ce: 0.008436
2022-01-09 14:57:57,335 iteration 5082 : loss : 0.019965, loss_ce: 0.006267
2022-01-09 14:57:59,740 iteration 5083 : loss : 0.022932, loss_ce: 0.008863
 75%|████████████████████▏      | 299/400 [3:33:38<1:11:42, 42.59s/it]2022-01-09 14:58:02,216 iteration 5084 : loss : 0.017375, loss_ce: 0.007947
2022-01-09 14:58:04,710 iteration 5085 : loss : 0.027778, loss_ce: 0.012173
2022-01-09 14:58:07,079 iteration 5086 : loss : 0.015464, loss_ce: 0.004740
2022-01-09 14:58:09,468 iteration 5087 : loss : 0.025320, loss_ce: 0.007575
2022-01-09 14:58:11,849 iteration 5088 : loss : 0.014936, loss_ce: 0.007335
2022-01-09 14:58:14,269 iteration 5089 : loss : 0.022521, loss_ce: 0.008824
2022-01-09 14:58:16,726 iteration 5090 : loss : 0.027820, loss_ce: 0.012687
2022-01-09 14:58:19,133 iteration 5091 : loss : 0.028634, loss_ce: 0.012704
2022-01-09 14:58:21,498 iteration 5092 : loss : 0.021782, loss_ce: 0.005212
2022-01-09 14:58:23,931 iteration 5093 : loss : 0.018355, loss_ce: 0.006324
2022-01-09 14:58:26,395 iteration 5094 : loss : 0.015694, loss_ce: 0.005020
2022-01-09 14:58:28,893 iteration 5095 : loss : 0.017541, loss_ce: 0.008535
2022-01-09 14:58:31,346 iteration 5096 : loss : 0.023190, loss_ce: 0.006617
2022-01-09 14:58:33,826 iteration 5097 : loss : 0.034715, loss_ce: 0.014300
2022-01-09 14:58:36,204 iteration 5098 : loss : 0.017916, loss_ce: 0.007550
2022-01-09 14:58:38,652 iteration 5099 : loss : 0.024952, loss_ce: 0.010414
2022-01-09 14:58:38,652 Training Data Eval:
2022-01-09 14:58:51,802   Average segmentation loss on training set: 0.0113
2022-01-09 14:58:51,802 Validation Data Eval:
2022-01-09 14:58:56,308   Average segmentation loss on validation set: 0.0613
2022-01-09 14:58:58,683 iteration 5100 : loss : 0.023332, loss_ce: 0.006490
 75%|████████████████████▎      | 300/400 [3:34:37<1:19:09, 47.50s/it]2022-01-09 14:59:01,120 iteration 5101 : loss : 0.030066, loss_ce: 0.007543
2022-01-09 14:59:03,535 iteration 5102 : loss : 0.026372, loss_ce: 0.012813
2022-01-09 14:59:05,869 iteration 5103 : loss : 0.018828, loss_ce: 0.007018
2022-01-09 14:59:08,218 iteration 5104 : loss : 0.020283, loss_ce: 0.006241
2022-01-09 14:59:10,656 iteration 5105 : loss : 0.015509, loss_ce: 0.005229
2022-01-09 14:59:13,064 iteration 5106 : loss : 0.034512, loss_ce: 0.013878
2022-01-09 14:59:15,451 iteration 5107 : loss : 0.039743, loss_ce: 0.014806
2022-01-09 14:59:17,809 iteration 5108 : loss : 0.022590, loss_ce: 0.009302
2022-01-09 14:59:20,217 iteration 5109 : loss : 0.017885, loss_ce: 0.007303
2022-01-09 14:59:22,534 iteration 5110 : loss : 0.016869, loss_ce: 0.006199
2022-01-09 14:59:25,097 iteration 5111 : loss : 0.032286, loss_ce: 0.009621
2022-01-09 14:59:27,495 iteration 5112 : loss : 0.015518, loss_ce: 0.006784
2022-01-09 14:59:30,112 iteration 5113 : loss : 0.026946, loss_ce: 0.011646
2022-01-09 14:59:32,472 iteration 5114 : loss : 0.014805, loss_ce: 0.005877
2022-01-09 14:59:34,816 iteration 5115 : loss : 0.015197, loss_ce: 0.007040
2022-01-09 14:59:37,232 iteration 5116 : loss : 0.028724, loss_ce: 0.010381
2022-01-09 14:59:39,609 iteration 5117 : loss : 0.019452, loss_ce: 0.006813
 75%|████████████████████▎      | 301/400 [3:35:18<1:15:06, 45.52s/it]2022-01-09 14:59:41,984 iteration 5118 : loss : 0.018809, loss_ce: 0.007875
2022-01-09 14:59:44,331 iteration 5119 : loss : 0.027116, loss_ce: 0.010002
2022-01-09 14:59:46,760 iteration 5120 : loss : 0.016453, loss_ce: 0.004511
2022-01-09 14:59:49,101 iteration 5121 : loss : 0.018074, loss_ce: 0.007137
2022-01-09 14:59:51,634 iteration 5122 : loss : 0.019579, loss_ce: 0.005764
2022-01-09 14:59:54,039 iteration 5123 : loss : 0.018800, loss_ce: 0.010199
2022-01-09 14:59:56,376 iteration 5124 : loss : 0.022423, loss_ce: 0.005574
2022-01-09 14:59:58,833 iteration 5125 : loss : 0.017885, loss_ce: 0.006514
2022-01-09 15:00:01,213 iteration 5126 : loss : 0.018963, loss_ce: 0.007769
2022-01-09 15:00:03,624 iteration 5127 : loss : 0.054646, loss_ce: 0.021559
2022-01-09 15:00:06,206 iteration 5128 : loss : 0.032779, loss_ce: 0.012544
2022-01-09 15:00:08,645 iteration 5129 : loss : 0.026947, loss_ce: 0.009588
2022-01-09 15:00:10,931 iteration 5130 : loss : 0.015006, loss_ce: 0.005807
2022-01-09 15:00:13,328 iteration 5131 : loss : 0.017156, loss_ce: 0.004542
2022-01-09 15:00:15,746 iteration 5132 : loss : 0.021290, loss_ce: 0.009161
2022-01-09 15:00:18,111 iteration 5133 : loss : 0.021640, loss_ce: 0.008473
2022-01-09 15:00:20,428 iteration 5134 : loss : 0.014216, loss_ce: 0.004823
 76%|████████████████████▍      | 302/400 [3:35:59<1:12:03, 44.11s/it]2022-01-09 15:00:22,807 iteration 5135 : loss : 0.014985, loss_ce: 0.004934
2022-01-09 15:00:25,175 iteration 5136 : loss : 0.017357, loss_ce: 0.006151
2022-01-09 15:00:27,510 iteration 5137 : loss : 0.031638, loss_ce: 0.009774
2022-01-09 15:00:29,850 iteration 5138 : loss : 0.027546, loss_ce: 0.012658
2022-01-09 15:00:32,028 iteration 5139 : loss : 0.011588, loss_ce: 0.003465
2022-01-09 15:00:34,306 iteration 5140 : loss : 0.019965, loss_ce: 0.009140
2022-01-09 15:00:36,524 iteration 5141 : loss : 0.018241, loss_ce: 0.009057
2022-01-09 15:00:38,951 iteration 5142 : loss : 0.027430, loss_ce: 0.008663
2022-01-09 15:00:41,182 iteration 5143 : loss : 0.013589, loss_ce: 0.005031
2022-01-09 15:00:43,505 iteration 5144 : loss : 0.016104, loss_ce: 0.007495
2022-01-09 15:00:46,077 iteration 5145 : loss : 0.023913, loss_ce: 0.008197
2022-01-09 15:00:48,580 iteration 5146 : loss : 0.026070, loss_ce: 0.006324
2022-01-09 15:00:50,941 iteration 5147 : loss : 0.015867, loss_ce: 0.007861
2022-01-09 15:00:53,368 iteration 5148 : loss : 0.019468, loss_ce: 0.007287
2022-01-09 15:00:55,793 iteration 5149 : loss : 0.016855, loss_ce: 0.005791
2022-01-09 15:00:58,178 iteration 5150 : loss : 0.019795, loss_ce: 0.008595
2022-01-09 15:01:00,489 iteration 5151 : loss : 0.013649, loss_ce: 0.004475
 76%|████████████████████▍      | 303/400 [3:36:39<1:09:21, 42.90s/it]2022-01-09 15:01:02,904 iteration 5152 : loss : 0.022794, loss_ce: 0.005672
2022-01-09 15:01:05,236 iteration 5153 : loss : 0.012051, loss_ce: 0.005423
2022-01-09 15:01:07,660 iteration 5154 : loss : 0.027680, loss_ce: 0.010440
2022-01-09 15:01:10,011 iteration 5155 : loss : 0.010810, loss_ce: 0.003776
2022-01-09 15:01:12,526 iteration 5156 : loss : 0.018514, loss_ce: 0.006741
2022-01-09 15:01:14,955 iteration 5157 : loss : 0.021838, loss_ce: 0.008777
2022-01-09 15:01:17,323 iteration 5158 : loss : 0.016654, loss_ce: 0.005408
2022-01-09 15:01:19,709 iteration 5159 : loss : 0.024991, loss_ce: 0.007653
2022-01-09 15:01:22,031 iteration 5160 : loss : 0.019049, loss_ce: 0.007958
2022-01-09 15:01:24,357 iteration 5161 : loss : 0.018169, loss_ce: 0.006889
2022-01-09 15:01:26,696 iteration 5162 : loss : 0.013943, loss_ce: 0.003986
2022-01-09 15:01:29,017 iteration 5163 : loss : 0.037179, loss_ce: 0.011462
2022-01-09 15:01:31,274 iteration 5164 : loss : 0.016428, loss_ce: 0.008563
2022-01-09 15:01:33,570 iteration 5165 : loss : 0.015149, loss_ce: 0.004516
2022-01-09 15:01:35,952 iteration 5166 : loss : 0.016610, loss_ce: 0.007228
2022-01-09 15:01:38,240 iteration 5167 : loss : 0.016209, loss_ce: 0.007252
2022-01-09 15:01:40,571 iteration 5168 : loss : 0.031290, loss_ce: 0.011621
 76%|████████████████████▌      | 304/400 [3:37:19<1:07:16, 42.05s/it]2022-01-09 15:01:42,893 iteration 5169 : loss : 0.021883, loss_ce: 0.009347
2022-01-09 15:01:45,158 iteration 5170 : loss : 0.014753, loss_ce: 0.006448
2022-01-09 15:01:47,431 iteration 5171 : loss : 0.023129, loss_ce: 0.006006
2022-01-09 15:01:49,737 iteration 5172 : loss : 0.017054, loss_ce: 0.005524
2022-01-09 15:01:52,079 iteration 5173 : loss : 0.018811, loss_ce: 0.008519
2022-01-09 15:01:54,458 iteration 5174 : loss : 0.023850, loss_ce: 0.008920
2022-01-09 15:01:56,913 iteration 5175 : loss : 0.029376, loss_ce: 0.009665
2022-01-09 15:01:59,255 iteration 5176 : loss : 0.021983, loss_ce: 0.007836
2022-01-09 15:02:01,721 iteration 5177 : loss : 0.031731, loss_ce: 0.014559
2022-01-09 15:02:04,299 iteration 5178 : loss : 0.019656, loss_ce: 0.003448
2022-01-09 15:02:06,743 iteration 5179 : loss : 0.022906, loss_ce: 0.008888
2022-01-09 15:02:09,160 iteration 5180 : loss : 0.016832, loss_ce: 0.006520
2022-01-09 15:02:11,540 iteration 5181 : loss : 0.021622, loss_ce: 0.007942
2022-01-09 15:02:13,840 iteration 5182 : loss : 0.026238, loss_ce: 0.008158
2022-01-09 15:02:16,065 iteration 5183 : loss : 0.022893, loss_ce: 0.006677
2022-01-09 15:02:18,317 iteration 5184 : loss : 0.020405, loss_ce: 0.009440
2022-01-09 15:02:18,318 Training Data Eval:
2022-01-09 15:02:30,963   Average segmentation loss on training set: 0.0112
2022-01-09 15:02:30,963 Validation Data Eval:
2022-01-09 15:02:35,475   Average segmentation loss on validation set: 0.0624
2022-01-09 15:02:37,945 iteration 5185 : loss : 0.018158, loss_ce: 0.008812
 76%|████████████████████▌      | 305/400 [3:38:17<1:13:51, 46.65s/it]2022-01-09 15:02:40,384 iteration 5186 : loss : 0.015687, loss_ce: 0.006341
2022-01-09 15:02:42,781 iteration 5187 : loss : 0.018490, loss_ce: 0.007544
2022-01-09 15:02:45,094 iteration 5188 : loss : 0.019394, loss_ce: 0.005425
2022-01-09 15:02:47,558 iteration 5189 : loss : 0.017901, loss_ce: 0.007079
2022-01-09 15:02:49,905 iteration 5190 : loss : 0.017135, loss_ce: 0.007809
2022-01-09 15:02:52,429 iteration 5191 : loss : 0.019518, loss_ce: 0.007861
2022-01-09 15:02:54,848 iteration 5192 : loss : 0.027596, loss_ce: 0.008481
2022-01-09 15:02:57,200 iteration 5193 : loss : 0.022116, loss_ce: 0.010915
2022-01-09 15:02:59,486 iteration 5194 : loss : 0.016690, loss_ce: 0.006489
2022-01-09 15:03:01,724 iteration 5195 : loss : 0.022773, loss_ce: 0.007706
2022-01-09 15:03:04,078 iteration 5196 : loss : 0.030996, loss_ce: 0.010312
2022-01-09 15:03:06,279 iteration 5197 : loss : 0.018765, loss_ce: 0.005560
2022-01-09 15:03:08,578 iteration 5198 : loss : 0.027527, loss_ce: 0.009983
2022-01-09 15:03:10,919 iteration 5199 : loss : 0.021262, loss_ce: 0.009843
2022-01-09 15:03:13,204 iteration 5200 : loss : 0.017183, loss_ce: 0.005554
2022-01-09 15:03:15,446 iteration 5201 : loss : 0.024833, loss_ce: 0.005393
2022-01-09 15:03:17,821 iteration 5202 : loss : 0.022485, loss_ce: 0.008721
 76%|████████████████████▋      | 306/400 [3:38:57<1:09:54, 44.62s/it]2022-01-09 15:03:20,123 iteration 5203 : loss : 0.014334, loss_ce: 0.003887
2022-01-09 15:03:22,440 iteration 5204 : loss : 0.018582, loss_ce: 0.006787
2022-01-09 15:03:24,714 iteration 5205 : loss : 0.019825, loss_ce: 0.006849
2022-01-09 15:03:27,003 iteration 5206 : loss : 0.016999, loss_ce: 0.006917
2022-01-09 15:03:29,391 iteration 5207 : loss : 0.016275, loss_ce: 0.006444
2022-01-09 15:03:31,833 iteration 5208 : loss : 0.039097, loss_ce: 0.016362
2022-01-09 15:03:34,142 iteration 5209 : loss : 0.021931, loss_ce: 0.007869
2022-01-09 15:03:36,417 iteration 5210 : loss : 0.016688, loss_ce: 0.005263
2022-01-09 15:03:38,619 iteration 5211 : loss : 0.013866, loss_ce: 0.004051
2022-01-09 15:03:40,929 iteration 5212 : loss : 0.016096, loss_ce: 0.004967
2022-01-09 15:03:43,258 iteration 5213 : loss : 0.033685, loss_ce: 0.009390
2022-01-09 15:03:45,605 iteration 5214 : loss : 0.024915, loss_ce: 0.015980
2022-01-09 15:03:47,954 iteration 5215 : loss : 0.021164, loss_ce: 0.007531
2022-01-09 15:03:50,314 iteration 5216 : loss : 0.016515, loss_ce: 0.006246
2022-01-09 15:03:52,631 iteration 5217 : loss : 0.016517, loss_ce: 0.006139
2022-01-09 15:03:55,143 iteration 5218 : loss : 0.028318, loss_ce: 0.010398
2022-01-09 15:03:57,536 iteration 5219 : loss : 0.025575, loss_ce: 0.010967
 77%|████████████████████▋      | 307/400 [3:39:36<1:06:52, 43.15s/it]2022-01-09 15:04:00,040 iteration 5220 : loss : 0.024765, loss_ce: 0.009755
2022-01-09 15:04:02,350 iteration 5221 : loss : 0.014975, loss_ce: 0.006620
2022-01-09 15:04:04,563 iteration 5222 : loss : 0.018327, loss_ce: 0.004615
2022-01-09 15:04:06,880 iteration 5223 : loss : 0.020116, loss_ce: 0.008024
2022-01-09 15:04:09,212 iteration 5224 : loss : 0.026613, loss_ce: 0.010772
2022-01-09 15:04:11,518 iteration 5225 : loss : 0.017606, loss_ce: 0.004974
2022-01-09 15:04:13,932 iteration 5226 : loss : 0.036506, loss_ce: 0.016283
2022-01-09 15:04:16,216 iteration 5227 : loss : 0.018426, loss_ce: 0.006397
2022-01-09 15:04:18,471 iteration 5228 : loss : 0.013851, loss_ce: 0.005546
2022-01-09 15:04:20,717 iteration 5229 : loss : 0.019878, loss_ce: 0.008097
2022-01-09 15:04:23,070 iteration 5230 : loss : 0.021380, loss_ce: 0.011207
2022-01-09 15:04:25,348 iteration 5231 : loss : 0.032425, loss_ce: 0.007805
2022-01-09 15:04:27,598 iteration 5232 : loss : 0.017921, loss_ce: 0.007627
2022-01-09 15:04:29,925 iteration 5233 : loss : 0.028023, loss_ce: 0.014331
2022-01-09 15:04:32,212 iteration 5234 : loss : 0.013003, loss_ce: 0.004605
2022-01-09 15:04:34,673 iteration 5235 : loss : 0.025867, loss_ce: 0.010158
2022-01-09 15:04:37,002 iteration 5236 : loss : 0.024128, loss_ce: 0.009230
 77%|████████████████████▊      | 308/400 [3:40:16<1:04:27, 42.04s/it]2022-01-09 15:04:39,425 iteration 5237 : loss : 0.020097, loss_ce: 0.006666
2022-01-09 15:04:41,763 iteration 5238 : loss : 0.019861, loss_ce: 0.009056
2022-01-09 15:04:44,053 iteration 5239 : loss : 0.017876, loss_ce: 0.005379
2022-01-09 15:04:46,395 iteration 5240 : loss : 0.019234, loss_ce: 0.006630
2022-01-09 15:04:48,673 iteration 5241 : loss : 0.020526, loss_ce: 0.008086
2022-01-09 15:04:51,004 iteration 5242 : loss : 0.025987, loss_ce: 0.011459
2022-01-09 15:04:53,353 iteration 5243 : loss : 0.021483, loss_ce: 0.008355
2022-01-09 15:04:55,625 iteration 5244 : loss : 0.035151, loss_ce: 0.012202
2022-01-09 15:04:57,813 iteration 5245 : loss : 0.018874, loss_ce: 0.006676
2022-01-09 15:05:00,058 iteration 5246 : loss : 0.011992, loss_ce: 0.005491
2022-01-09 15:05:02,399 iteration 5247 : loss : 0.020691, loss_ce: 0.007612
2022-01-09 15:05:04,767 iteration 5248 : loss : 0.017631, loss_ce: 0.006203
2022-01-09 15:05:07,041 iteration 5249 : loss : 0.022336, loss_ce: 0.008651
2022-01-09 15:05:09,382 iteration 5250 : loss : 0.024241, loss_ce: 0.009783
2022-01-09 15:05:11,777 iteration 5251 : loss : 0.018895, loss_ce: 0.006586
2022-01-09 15:05:14,143 iteration 5252 : loss : 0.018560, loss_ce: 0.006149
2022-01-09 15:05:16,516 iteration 5253 : loss : 0.013832, loss_ce: 0.005675
 77%|████████████████████▊      | 309/400 [3:40:55<1:02:36, 41.28s/it]2022-01-09 15:05:18,877 iteration 5254 : loss : 0.016553, loss_ce: 0.005767
2022-01-09 15:05:21,362 iteration 5255 : loss : 0.020392, loss_ce: 0.005926
2022-01-09 15:05:23,789 iteration 5256 : loss : 0.016126, loss_ce: 0.006741
2022-01-09 15:05:26,207 iteration 5257 : loss : 0.023276, loss_ce: 0.006756
2022-01-09 15:05:28,475 iteration 5258 : loss : 0.018975, loss_ce: 0.007727
2022-01-09 15:05:30,845 iteration 5259 : loss : 0.024946, loss_ce: 0.007202
2022-01-09 15:05:33,123 iteration 5260 : loss : 0.015278, loss_ce: 0.006302
2022-01-09 15:05:35,488 iteration 5261 : loss : 0.017116, loss_ce: 0.007625
2022-01-09 15:05:37,755 iteration 5262 : loss : 0.012425, loss_ce: 0.005557
2022-01-09 15:05:40,058 iteration 5263 : loss : 0.021540, loss_ce: 0.007158
2022-01-09 15:05:42,368 iteration 5264 : loss : 0.019632, loss_ce: 0.006831
2022-01-09 15:05:44,665 iteration 5265 : loss : 0.016543, loss_ce: 0.005592
2022-01-09 15:05:47,074 iteration 5266 : loss : 0.021380, loss_ce: 0.008738
2022-01-09 15:05:49,392 iteration 5267 : loss : 0.020801, loss_ce: 0.007904
2022-01-09 15:05:51,827 iteration 5268 : loss : 0.018919, loss_ce: 0.007068
2022-01-09 15:05:54,277 iteration 5269 : loss : 0.026647, loss_ce: 0.012245
2022-01-09 15:05:54,277 Training Data Eval:
2022-01-09 15:06:07,222   Average segmentation loss on training set: 0.0110
2022-01-09 15:06:07,222 Validation Data Eval:
2022-01-09 15:06:11,732   Average segmentation loss on validation set: 0.0722
2022-01-09 15:06:14,147 iteration 5270 : loss : 0.031501, loss_ce: 0.015193
 78%|████████████████████▉      | 310/400 [3:41:53<1:09:16, 46.18s/it]2022-01-09 15:06:16,579 iteration 5271 : loss : 0.023142, loss_ce: 0.009833
2022-01-09 15:06:19,000 iteration 5272 : loss : 0.022993, loss_ce: 0.009198
2022-01-09 15:06:21,364 iteration 5273 : loss : 0.016511, loss_ce: 0.006958
2022-01-09 15:06:23,658 iteration 5274 : loss : 0.014693, loss_ce: 0.005027
2022-01-09 15:06:26,018 iteration 5275 : loss : 0.021835, loss_ce: 0.005823
2022-01-09 15:06:28,408 iteration 5276 : loss : 0.020437, loss_ce: 0.006604
2022-01-09 15:06:30,673 iteration 5277 : loss : 0.023051, loss_ce: 0.006841
2022-01-09 15:06:33,039 iteration 5278 : loss : 0.023425, loss_ce: 0.010716
2022-01-09 15:06:35,229 iteration 5279 : loss : 0.019628, loss_ce: 0.005393
2022-01-09 15:06:37,509 iteration 5280 : loss : 0.037819, loss_ce: 0.018797
2022-01-09 15:06:39,814 iteration 5281 : loss : 0.019383, loss_ce: 0.009486
2022-01-09 15:06:42,181 iteration 5282 : loss : 0.018586, loss_ce: 0.006190
2022-01-09 15:06:44,470 iteration 5283 : loss : 0.021054, loss_ce: 0.006362
2022-01-09 15:06:46,759 iteration 5284 : loss : 0.016975, loss_ce: 0.007491
2022-01-09 15:06:49,079 iteration 5285 : loss : 0.021379, loss_ce: 0.010035
2022-01-09 15:06:51,417 iteration 5286 : loss : 0.016159, loss_ce: 0.006124
2022-01-09 15:06:53,746 iteration 5287 : loss : 0.026004, loss_ce: 0.010984
 78%|████████████████████▉      | 311/400 [3:42:32<1:05:34, 44.21s/it]2022-01-09 15:06:56,020 iteration 5288 : loss : 0.019741, loss_ce: 0.006777
2022-01-09 15:06:58,344 iteration 5289 : loss : 0.015989, loss_ce: 0.005722
2022-01-09 15:07:00,737 iteration 5290 : loss : 0.026800, loss_ce: 0.010716
2022-01-09 15:07:03,127 iteration 5291 : loss : 0.016977, loss_ce: 0.006985
2022-01-09 15:07:05,454 iteration 5292 : loss : 0.015562, loss_ce: 0.005946
2022-01-09 15:07:07,745 iteration 5293 : loss : 0.024262, loss_ce: 0.007783
2022-01-09 15:07:10,118 iteration 5294 : loss : 0.019835, loss_ce: 0.008962
2022-01-09 15:07:12,599 iteration 5295 : loss : 0.012869, loss_ce: 0.004773
2022-01-09 15:07:14,978 iteration 5296 : loss : 0.023134, loss_ce: 0.007863
2022-01-09 15:07:17,348 iteration 5297 : loss : 0.025240, loss_ce: 0.008650
2022-01-09 15:07:19,591 iteration 5298 : loss : 0.015022, loss_ce: 0.006413
2022-01-09 15:07:21,960 iteration 5299 : loss : 0.019399, loss_ce: 0.008447
2022-01-09 15:07:24,262 iteration 5300 : loss : 0.020710, loss_ce: 0.007206
2022-01-09 15:07:26,601 iteration 5301 : loss : 0.031027, loss_ce: 0.011276
2022-01-09 15:07:28,898 iteration 5302 : loss : 0.068329, loss_ce: 0.035105
2022-01-09 15:07:31,351 iteration 5303 : loss : 0.015586, loss_ce: 0.005533
2022-01-09 15:07:33,805 iteration 5304 : loss : 0.022499, loss_ce: 0.008496
 78%|█████████████████████      | 312/400 [3:43:13<1:03:01, 42.97s/it]2022-01-09 15:07:36,244 iteration 5305 : loss : 0.022591, loss_ce: 0.007451
2022-01-09 15:07:38,682 iteration 5306 : loss : 0.022290, loss_ce: 0.008062
2022-01-09 15:07:41,018 iteration 5307 : loss : 0.015181, loss_ce: 0.005707
2022-01-09 15:07:43,361 iteration 5308 : loss : 0.017227, loss_ce: 0.006964
2022-01-09 15:07:45,871 iteration 5309 : loss : 0.018164, loss_ce: 0.006877
2022-01-09 15:07:48,278 iteration 5310 : loss : 0.016242, loss_ce: 0.007020
2022-01-09 15:07:50,628 iteration 5311 : loss : 0.017112, loss_ce: 0.006517
2022-01-09 15:07:52,998 iteration 5312 : loss : 0.017978, loss_ce: 0.005787
2022-01-09 15:07:55,355 iteration 5313 : loss : 0.024784, loss_ce: 0.007324
2022-01-09 15:07:57,719 iteration 5314 : loss : 0.017172, loss_ce: 0.006779
2022-01-09 15:08:00,128 iteration 5315 : loss : 0.020320, loss_ce: 0.008358
2022-01-09 15:08:02,519 iteration 5316 : loss : 0.013117, loss_ce: 0.005955
2022-01-09 15:08:04,937 iteration 5317 : loss : 0.019910, loss_ce: 0.006947
2022-01-09 15:08:07,343 iteration 5318 : loss : 0.022688, loss_ce: 0.006494
2022-01-09 15:08:09,676 iteration 5319 : loss : 0.022454, loss_ce: 0.008554
2022-01-09 15:08:12,021 iteration 5320 : loss : 0.031274, loss_ce: 0.014695
2022-01-09 15:08:14,485 iteration 5321 : loss : 0.021418, loss_ce: 0.004186
 78%|█████████████████████▏     | 313/400 [3:43:53<1:01:18, 42.28s/it]2022-01-09 15:08:16,963 iteration 5322 : loss : 0.017802, loss_ce: 0.007892
2022-01-09 15:08:19,338 iteration 5323 : loss : 0.032931, loss_ce: 0.011616
2022-01-09 15:08:21,767 iteration 5324 : loss : 0.021778, loss_ce: 0.008406
2022-01-09 15:08:24,199 iteration 5325 : loss : 0.022136, loss_ce: 0.007882
2022-01-09 15:08:26,865 iteration 5326 : loss : 0.043825, loss_ce: 0.014965
2022-01-09 15:08:29,269 iteration 5327 : loss : 0.030461, loss_ce: 0.011985
2022-01-09 15:08:31,573 iteration 5328 : loss : 0.022603, loss_ce: 0.008170
2022-01-09 15:08:33,986 iteration 5329 : loss : 0.015353, loss_ce: 0.005700
2022-01-09 15:08:36,397 iteration 5330 : loss : 0.032102, loss_ce: 0.012890
2022-01-09 15:08:38,748 iteration 5331 : loss : 0.017351, loss_ce: 0.006902
2022-01-09 15:08:41,257 iteration 5332 : loss : 0.034351, loss_ce: 0.015444
2022-01-09 15:08:43,575 iteration 5333 : loss : 0.021092, loss_ce: 0.007850
2022-01-09 15:08:45,961 iteration 5334 : loss : 0.018915, loss_ce: 0.004928
2022-01-09 15:08:48,375 iteration 5335 : loss : 0.017402, loss_ce: 0.004666
2022-01-09 15:08:50,878 iteration 5336 : loss : 0.025179, loss_ce: 0.008218
2022-01-09 15:08:53,252 iteration 5337 : loss : 0.017843, loss_ce: 0.007230
2022-01-09 15:08:55,610 iteration 5338 : loss : 0.022075, loss_ce: 0.007808
 78%|█████████████████████▏     | 314/400 [3:44:34<1:00:06, 41.93s/it]2022-01-09 15:08:58,057 iteration 5339 : loss : 0.025462, loss_ce: 0.008799
2022-01-09 15:09:00,437 iteration 5340 : loss : 0.014474, loss_ce: 0.005426
2022-01-09 15:09:03,019 iteration 5341 : loss : 0.026129, loss_ce: 0.007108
2022-01-09 15:09:05,438 iteration 5342 : loss : 0.024643, loss_ce: 0.008144
2022-01-09 15:09:07,848 iteration 5343 : loss : 0.036077, loss_ce: 0.015049
2022-01-09 15:09:10,291 iteration 5344 : loss : 0.014274, loss_ce: 0.005758
2022-01-09 15:09:12,677 iteration 5345 : loss : 0.016520, loss_ce: 0.007188
2022-01-09 15:09:15,030 iteration 5346 : loss : 0.021389, loss_ce: 0.008094
2022-01-09 15:09:17,456 iteration 5347 : loss : 0.017551, loss_ce: 0.007890
2022-01-09 15:09:19,941 iteration 5348 : loss : 0.019528, loss_ce: 0.007019
2022-01-09 15:09:22,322 iteration 5349 : loss : 0.034347, loss_ce: 0.012587
2022-01-09 15:09:24,854 iteration 5350 : loss : 0.018331, loss_ce: 0.005788
2022-01-09 15:09:27,202 iteration 5351 : loss : 0.012031, loss_ce: 0.004321
2022-01-09 15:09:29,598 iteration 5352 : loss : 0.024508, loss_ce: 0.010523
2022-01-09 15:09:31,994 iteration 5353 : loss : 0.022533, loss_ce: 0.008957
2022-01-09 15:09:34,399 iteration 5354 : loss : 0.014888, loss_ce: 0.005940
2022-01-09 15:09:34,399 Training Data Eval:
2022-01-09 15:09:47,489   Average segmentation loss on training set: 0.0112
2022-01-09 15:09:47,489 Validation Data Eval:
2022-01-09 15:09:51,996   Average segmentation loss on validation set: 0.0715
2022-01-09 15:09:54,447 iteration 5355 : loss : 0.019448, loss_ce: 0.008627
 79%|█████████████████████▎     | 315/400 [3:45:33<1:06:35, 47.00s/it]2022-01-09 15:09:56,921 iteration 5356 : loss : 0.026558, loss_ce: 0.011972
2022-01-09 15:09:59,294 iteration 5357 : loss : 0.011217, loss_ce: 0.004023
2022-01-09 15:10:01,801 iteration 5358 : loss : 0.017357, loss_ce: 0.007098
2022-01-09 15:10:04,162 iteration 5359 : loss : 0.019141, loss_ce: 0.007927
2022-01-09 15:10:06,574 iteration 5360 : loss : 0.023652, loss_ce: 0.010529
2022-01-09 15:10:09,007 iteration 5361 : loss : 0.016384, loss_ce: 0.007348
2022-01-09 15:10:11,397 iteration 5362 : loss : 0.015376, loss_ce: 0.005509
2022-01-09 15:10:13,846 iteration 5363 : loss : 0.023017, loss_ce: 0.008884
2022-01-09 15:10:16,194 iteration 5364 : loss : 0.018798, loss_ce: 0.005001
2022-01-09 15:10:18,548 iteration 5365 : loss : 0.021742, loss_ce: 0.006664
2022-01-09 15:10:20,996 iteration 5366 : loss : 0.020221, loss_ce: 0.006800
2022-01-09 15:10:23,312 iteration 5367 : loss : 0.015142, loss_ce: 0.005507
2022-01-09 15:10:25,804 iteration 5368 : loss : 0.031242, loss_ce: 0.011936
2022-01-09 15:10:28,148 iteration 5369 : loss : 0.011141, loss_ce: 0.004349
2022-01-09 15:10:30,463 iteration 5370 : loss : 0.017442, loss_ce: 0.007825
2022-01-09 15:10:32,812 iteration 5371 : loss : 0.017952, loss_ce: 0.006059
2022-01-09 15:10:35,092 iteration 5372 : loss : 0.013784, loss_ce: 0.005231
 79%|█████████████████████▎     | 316/400 [3:46:14<1:03:08, 45.10s/it]2022-01-09 15:10:37,462 iteration 5373 : loss : 0.017303, loss_ce: 0.006703
2022-01-09 15:10:39,723 iteration 5374 : loss : 0.023534, loss_ce: 0.005606
2022-01-09 15:10:42,099 iteration 5375 : loss : 0.016203, loss_ce: 0.006095
2022-01-09 15:10:44,513 iteration 5376 : loss : 0.018510, loss_ce: 0.006738
2022-01-09 15:10:47,120 iteration 5377 : loss : 0.038669, loss_ce: 0.008601
2022-01-09 15:10:49,541 iteration 5378 : loss : 0.018526, loss_ce: 0.005760
2022-01-09 15:10:51,917 iteration 5379 : loss : 0.017707, loss_ce: 0.006666
2022-01-09 15:10:54,285 iteration 5380 : loss : 0.014500, loss_ce: 0.006168
2022-01-09 15:10:56,721 iteration 5381 : loss : 0.017754, loss_ce: 0.007465
2022-01-09 15:10:59,092 iteration 5382 : loss : 0.020667, loss_ce: 0.007505
2022-01-09 15:11:01,532 iteration 5383 : loss : 0.022083, loss_ce: 0.010703
2022-01-09 15:11:03,913 iteration 5384 : loss : 0.013035, loss_ce: 0.006329
2022-01-09 15:11:06,265 iteration 5385 : loss : 0.031229, loss_ce: 0.013720
2022-01-09 15:11:08,597 iteration 5386 : loss : 0.018394, loss_ce: 0.006997
2022-01-09 15:11:10,986 iteration 5387 : loss : 0.018928, loss_ce: 0.006910
2022-01-09 15:11:13,352 iteration 5388 : loss : 0.015101, loss_ce: 0.004683
2022-01-09 15:11:15,796 iteration 5389 : loss : 0.019675, loss_ce: 0.007918
 79%|█████████████████████▍     | 317/400 [3:46:55<1:00:33, 43.78s/it]2022-01-09 15:11:18,171 iteration 5390 : loss : 0.014860, loss_ce: 0.004751
2022-01-09 15:11:20,668 iteration 5391 : loss : 0.020328, loss_ce: 0.006484
2022-01-09 15:11:23,025 iteration 5392 : loss : 0.025931, loss_ce: 0.007769
2022-01-09 15:11:25,389 iteration 5393 : loss : 0.017168, loss_ce: 0.006058
2022-01-09 15:11:27,745 iteration 5394 : loss : 0.015820, loss_ce: 0.005072
2022-01-09 15:11:30,077 iteration 5395 : loss : 0.020827, loss_ce: 0.006243
2022-01-09 15:11:32,411 iteration 5396 : loss : 0.016476, loss_ce: 0.005910
2022-01-09 15:11:34,777 iteration 5397 : loss : 0.021292, loss_ce: 0.008847
2022-01-09 15:11:37,191 iteration 5398 : loss : 0.023691, loss_ce: 0.007474
2022-01-09 15:11:39,600 iteration 5399 : loss : 0.025427, loss_ce: 0.010120
2022-01-09 15:11:42,094 iteration 5400 : loss : 0.017985, loss_ce: 0.007136
2022-01-09 15:11:44,496 iteration 5401 : loss : 0.020917, loss_ce: 0.012379
2022-01-09 15:11:46,908 iteration 5402 : loss : 0.018124, loss_ce: 0.008779
2022-01-09 15:11:49,296 iteration 5403 : loss : 0.025466, loss_ce: 0.009628
2022-01-09 15:11:51,699 iteration 5404 : loss : 0.013213, loss_ce: 0.005466
2022-01-09 15:11:54,184 iteration 5405 : loss : 0.020846, loss_ce: 0.007494
2022-01-09 15:11:56,590 iteration 5406 : loss : 0.015558, loss_ce: 0.007227
 80%|███████████████████████      | 318/400 [3:47:35<58:36, 42.88s/it]2022-01-09 15:11:59,080 iteration 5407 : loss : 0.019168, loss_ce: 0.008011
2022-01-09 15:12:01,528 iteration 5408 : loss : 0.016926, loss_ce: 0.006612
2022-01-09 15:12:03,858 iteration 5409 : loss : 0.012997, loss_ce: 0.004451
2022-01-09 15:12:06,261 iteration 5410 : loss : 0.019359, loss_ce: 0.006943
2022-01-09 15:12:08,687 iteration 5411 : loss : 0.014112, loss_ce: 0.005446
2022-01-09 15:12:11,133 iteration 5412 : loss : 0.017863, loss_ce: 0.006749
2022-01-09 15:12:13,544 iteration 5413 : loss : 0.020704, loss_ce: 0.009238
2022-01-09 15:12:16,002 iteration 5414 : loss : 0.014127, loss_ce: 0.005409
2022-01-09 15:12:18,471 iteration 5415 : loss : 0.018142, loss_ce: 0.005854
2022-01-09 15:12:20,847 iteration 5416 : loss : 0.025883, loss_ce: 0.009064
2022-01-09 15:12:23,440 iteration 5417 : loss : 0.015548, loss_ce: 0.004526
2022-01-09 15:12:25,890 iteration 5418 : loss : 0.019050, loss_ce: 0.008326
2022-01-09 15:12:28,250 iteration 5419 : loss : 0.017679, loss_ce: 0.007112
2022-01-09 15:12:30,595 iteration 5420 : loss : 0.016978, loss_ce: 0.007222
2022-01-09 15:12:33,158 iteration 5421 : loss : 0.036447, loss_ce: 0.012390
2022-01-09 15:12:35,596 iteration 5422 : loss : 0.022318, loss_ce: 0.005032
2022-01-09 15:12:38,191 iteration 5423 : loss : 0.017364, loss_ce: 0.007003
 80%|███████████████████████▏     | 319/400 [3:48:17<57:22, 42.50s/it]2022-01-09 15:12:40,623 iteration 5424 : loss : 0.020969, loss_ce: 0.006633
2022-01-09 15:12:42,932 iteration 5425 : loss : 0.021597, loss_ce: 0.005274
2022-01-09 15:12:45,353 iteration 5426 : loss : 0.033008, loss_ce: 0.013916
2022-01-09 15:12:47,651 iteration 5427 : loss : 0.017178, loss_ce: 0.004961
2022-01-09 15:12:50,012 iteration 5428 : loss : 0.012782, loss_ce: 0.004770
2022-01-09 15:12:52,521 iteration 5429 : loss : 0.021049, loss_ce: 0.008253
2022-01-09 15:12:54,993 iteration 5430 : loss : 0.022043, loss_ce: 0.007693
2022-01-09 15:12:57,341 iteration 5431 : loss : 0.023599, loss_ce: 0.010329
2022-01-09 15:12:59,684 iteration 5432 : loss : 0.022079, loss_ce: 0.009629
2022-01-09 15:13:02,144 iteration 5433 : loss : 0.016633, loss_ce: 0.006654
2022-01-09 15:13:04,530 iteration 5434 : loss : 0.017655, loss_ce: 0.007037
2022-01-09 15:13:06,961 iteration 5435 : loss : 0.031415, loss_ce: 0.015440
2022-01-09 15:13:09,284 iteration 5436 : loss : 0.015930, loss_ce: 0.006571
2022-01-09 15:13:11,574 iteration 5437 : loss : 0.012928, loss_ce: 0.004965
2022-01-09 15:13:14,036 iteration 5438 : loss : 0.026411, loss_ce: 0.009258
2022-01-09 15:13:16,515 iteration 5439 : loss : 0.013005, loss_ce: 0.005134
2022-01-09 15:13:16,515 Training Data Eval:
2022-01-09 15:13:29,553   Average segmentation loss on training set: 0.0115
2022-01-09 15:13:29,553 Validation Data Eval:
2022-01-09 15:13:34,060   Average segmentation loss on validation set: 0.0971
2022-01-09 15:13:36,506 iteration 5440 : loss : 0.029144, loss_ce: 0.008524
 80%|█████████████████████▌     | 320/400 [3:49:15<1:02:59, 47.24s/it]2022-01-09 15:13:38,831 iteration 5441 : loss : 0.015314, loss_ce: 0.004881
2022-01-09 15:13:41,280 iteration 5442 : loss : 0.022658, loss_ce: 0.007819
2022-01-09 15:13:43,760 iteration 5443 : loss : 0.013326, loss_ce: 0.004305
2022-01-09 15:13:46,184 iteration 5444 : loss : 0.019797, loss_ce: 0.006691
2022-01-09 15:13:48,629 iteration 5445 : loss : 0.024313, loss_ce: 0.009494
2022-01-09 15:13:51,144 iteration 5446 : loss : 0.020109, loss_ce: 0.006713
2022-01-09 15:13:53,536 iteration 5447 : loss : 0.024706, loss_ce: 0.013024
2022-01-09 15:13:55,930 iteration 5448 : loss : 0.022025, loss_ce: 0.007968
2022-01-09 15:13:58,466 iteration 5449 : loss : 0.022835, loss_ce: 0.007840
2022-01-09 15:14:00,893 iteration 5450 : loss : 0.017593, loss_ce: 0.007809
2022-01-09 15:14:03,234 iteration 5451 : loss : 0.020047, loss_ce: 0.008099
2022-01-09 15:14:05,649 iteration 5452 : loss : 0.016423, loss_ce: 0.006611
2022-01-09 15:14:08,033 iteration 5453 : loss : 0.018820, loss_ce: 0.007240
2022-01-09 15:14:10,370 iteration 5454 : loss : 0.011796, loss_ce: 0.005383
2022-01-09 15:14:12,849 iteration 5455 : loss : 0.031555, loss_ce: 0.012369
2022-01-09 15:14:15,454 iteration 5456 : loss : 0.023754, loss_ce: 0.011732
2022-01-09 15:14:17,861 iteration 5457 : loss : 0.018402, loss_ce: 0.006932
 80%|███████████████████████▎     | 321/400 [3:49:57<59:52, 45.48s/it]2022-01-09 15:14:20,265 iteration 5458 : loss : 0.016855, loss_ce: 0.006127
2022-01-09 15:14:22,636 iteration 5459 : loss : 0.014552, loss_ce: 0.005437
2022-01-09 15:14:25,036 iteration 5460 : loss : 0.020402, loss_ce: 0.008509
2022-01-09 15:14:27,475 iteration 5461 : loss : 0.018823, loss_ce: 0.007353
2022-01-09 15:14:29,826 iteration 5462 : loss : 0.017830, loss_ce: 0.004606
2022-01-09 15:14:32,171 iteration 5463 : loss : 0.025087, loss_ce: 0.008355
2022-01-09 15:14:34,476 iteration 5464 : loss : 0.023052, loss_ce: 0.010143
2022-01-09 15:14:36,871 iteration 5465 : loss : 0.023323, loss_ce: 0.008119
2022-01-09 15:14:39,317 iteration 5466 : loss : 0.021552, loss_ce: 0.008452
2022-01-09 15:14:41,641 iteration 5467 : loss : 0.014684, loss_ce: 0.007686
2022-01-09 15:14:44,031 iteration 5468 : loss : 0.024357, loss_ce: 0.010753
2022-01-09 15:14:46,383 iteration 5469 : loss : 0.013795, loss_ce: 0.004486
2022-01-09 15:14:48,794 iteration 5470 : loss : 0.020579, loss_ce: 0.008677
2022-01-09 15:14:51,205 iteration 5471 : loss : 0.017206, loss_ce: 0.006007
2022-01-09 15:14:53,587 iteration 5472 : loss : 0.026850, loss_ce: 0.007943
2022-01-09 15:14:56,136 iteration 5473 : loss : 0.024552, loss_ce: 0.007290
2022-01-09 15:14:58,589 iteration 5474 : loss : 0.018970, loss_ce: 0.008732
 80%|███████████████████████▎     | 322/400 [3:50:37<57:16, 44.05s/it]2022-01-09 15:15:00,977 iteration 5475 : loss : 0.013127, loss_ce: 0.003424
2022-01-09 15:15:03,323 iteration 5476 : loss : 0.025749, loss_ce: 0.007792
2022-01-09 15:15:05,588 iteration 5477 : loss : 0.015266, loss_ce: 0.006709
2022-01-09 15:15:07,912 iteration 5478 : loss : 0.016058, loss_ce: 0.006822
2022-01-09 15:15:10,264 iteration 5479 : loss : 0.018118, loss_ce: 0.007643
2022-01-09 15:15:12,722 iteration 5480 : loss : 0.021735, loss_ce: 0.008383
2022-01-09 15:15:15,096 iteration 5481 : loss : 0.016132, loss_ce: 0.005294
2022-01-09 15:15:17,423 iteration 5482 : loss : 0.014917, loss_ce: 0.005379
2022-01-09 15:15:19,706 iteration 5483 : loss : 0.017626, loss_ce: 0.007009
2022-01-09 15:15:22,011 iteration 5484 : loss : 0.026777, loss_ce: 0.014750
2022-01-09 15:15:24,320 iteration 5485 : loss : 0.013648, loss_ce: 0.004798
2022-01-09 15:15:26,768 iteration 5486 : loss : 0.021096, loss_ce: 0.008131
2022-01-09 15:15:29,205 iteration 5487 : loss : 0.023290, loss_ce: 0.009639
2022-01-09 15:15:31,539 iteration 5488 : loss : 0.016683, loss_ce: 0.006395
2022-01-09 15:15:33,796 iteration 5489 : loss : 0.014709, loss_ce: 0.005999
2022-01-09 15:15:36,060 iteration 5490 : loss : 0.030769, loss_ce: 0.010795
2022-01-09 15:15:38,502 iteration 5491 : loss : 0.020565, loss_ce: 0.006960
 81%|███████████████████████▍     | 323/400 [3:51:17<54:55, 42.80s/it]2022-01-09 15:15:40,926 iteration 5492 : loss : 0.017049, loss_ce: 0.007100
2022-01-09 15:15:43,309 iteration 5493 : loss : 0.016517, loss_ce: 0.007446
2022-01-09 15:15:45,631 iteration 5494 : loss : 0.014339, loss_ce: 0.004118
2022-01-09 15:15:48,079 iteration 5495 : loss : 0.038453, loss_ce: 0.012242
2022-01-09 15:15:50,446 iteration 5496 : loss : 0.011513, loss_ce: 0.003782
2022-01-09 15:15:52,820 iteration 5497 : loss : 0.014766, loss_ce: 0.004607
2022-01-09 15:15:55,213 iteration 5498 : loss : 0.021237, loss_ce: 0.012268
2022-01-09 15:15:57,552 iteration 5499 : loss : 0.020895, loss_ce: 0.008302
2022-01-09 15:15:59,915 iteration 5500 : loss : 0.018434, loss_ce: 0.007052
2022-01-09 15:16:02,300 iteration 5501 : loss : 0.033685, loss_ce: 0.015924
2022-01-09 15:16:04,686 iteration 5502 : loss : 0.025526, loss_ce: 0.010744
2022-01-09 15:16:07,225 iteration 5503 : loss : 0.020092, loss_ce: 0.005934
2022-01-09 15:16:09,657 iteration 5504 : loss : 0.018064, loss_ce: 0.009513
2022-01-09 15:16:12,032 iteration 5505 : loss : 0.021434, loss_ce: 0.008934
2022-01-09 15:16:14,368 iteration 5506 : loss : 0.017137, loss_ce: 0.006730
2022-01-09 15:16:16,763 iteration 5507 : loss : 0.022097, loss_ce: 0.005844
2022-01-09 15:16:19,349 iteration 5508 : loss : 0.020288, loss_ce: 0.008192
 81%|███████████████████████▍     | 324/400 [3:51:58<53:28, 42.22s/it]2022-01-09 15:16:21,753 iteration 5509 : loss : 0.023638, loss_ce: 0.007158
2022-01-09 15:16:24,134 iteration 5510 : loss : 0.023192, loss_ce: 0.008454
2022-01-09 15:16:26,428 iteration 5511 : loss : 0.022129, loss_ce: 0.011944
2022-01-09 15:16:28,707 iteration 5512 : loss : 0.022851, loss_ce: 0.004284
2022-01-09 15:16:30,931 iteration 5513 : loss : 0.017451, loss_ce: 0.004135
2022-01-09 15:16:33,269 iteration 5514 : loss : 0.026543, loss_ce: 0.009102
2022-01-09 15:16:35,698 iteration 5515 : loss : 0.021975, loss_ce: 0.006737
2022-01-09 15:16:38,013 iteration 5516 : loss : 0.015629, loss_ce: 0.006123
2022-01-09 15:16:40,454 iteration 5517 : loss : 0.033742, loss_ce: 0.012406
2022-01-09 15:16:42,816 iteration 5518 : loss : 0.020338, loss_ce: 0.007772
2022-01-09 15:16:45,127 iteration 5519 : loss : 0.018120, loss_ce: 0.005487
2022-01-09 15:16:47,527 iteration 5520 : loss : 0.029269, loss_ce: 0.010498
2022-01-09 15:16:50,022 iteration 5521 : loss : 0.022226, loss_ce: 0.007742
2022-01-09 15:16:52,284 iteration 5522 : loss : 0.014688, loss_ce: 0.006581
2022-01-09 15:16:54,703 iteration 5523 : loss : 0.018949, loss_ce: 0.006998
2022-01-09 15:16:57,067 iteration 5524 : loss : 0.033383, loss_ce: 0.017047
2022-01-09 15:16:57,068 Training Data Eval:
2022-01-09 15:17:09,758   Average segmentation loss on training set: 0.0107
2022-01-09 15:17:09,759 Validation Data Eval:
2022-01-09 15:17:14,122   Average segmentation loss on validation set: 0.0780
2022-01-09 15:17:16,517 iteration 5525 : loss : 0.021993, loss_ce: 0.009902
 81%|███████████████████████▌     | 325/400 [3:52:55<58:22, 46.70s/it]2022-01-09 15:17:18,984 iteration 5526 : loss : 0.020856, loss_ce: 0.008030
2022-01-09 15:17:21,237 iteration 5527 : loss : 0.016086, loss_ce: 0.005175
2022-01-09 15:17:23,565 iteration 5528 : loss : 0.016203, loss_ce: 0.005603
2022-01-09 15:17:25,889 iteration 5529 : loss : 0.015005, loss_ce: 0.005430
2022-01-09 15:17:28,282 iteration 5530 : loss : 0.013982, loss_ce: 0.003431
2022-01-09 15:17:30,667 iteration 5531 : loss : 0.014326, loss_ce: 0.005207
2022-01-09 15:17:32,991 iteration 5532 : loss : 0.015406, loss_ce: 0.004916
2022-01-09 15:17:35,368 iteration 5533 : loss : 0.018201, loss_ce: 0.007938
2022-01-09 15:17:37,914 iteration 5534 : loss : 0.022511, loss_ce: 0.008923
2022-01-09 15:17:40,308 iteration 5535 : loss : 0.018990, loss_ce: 0.008571
2022-01-09 15:17:42,634 iteration 5536 : loss : 0.017355, loss_ce: 0.005078
2022-01-09 15:17:44,886 iteration 5537 : loss : 0.016933, loss_ce: 0.005281
2022-01-09 15:17:47,155 iteration 5538 : loss : 0.021315, loss_ce: 0.012123
2022-01-09 15:17:49,388 iteration 5539 : loss : 0.015952, loss_ce: 0.006085
2022-01-09 15:17:51,693 iteration 5540 : loss : 0.012031, loss_ce: 0.004050
2022-01-09 15:17:53,907 iteration 5541 : loss : 0.024815, loss_ce: 0.011028
2022-01-09 15:17:56,157 iteration 5542 : loss : 0.016823, loss_ce: 0.007693
 82%|███████████████████████▋     | 326/400 [3:53:35<54:59, 44.58s/it]2022-01-09 15:17:58,564 iteration 5543 : loss : 0.026239, loss_ce: 0.011094
2022-01-09 15:18:00,965 iteration 5544 : loss : 0.019995, loss_ce: 0.006348
2022-01-09 15:18:03,364 iteration 5545 : loss : 0.023864, loss_ce: 0.009985
2022-01-09 15:18:05,705 iteration 5546 : loss : 0.011967, loss_ce: 0.005627
2022-01-09 15:18:08,064 iteration 5547 : loss : 0.015389, loss_ce: 0.005844
2022-01-09 15:18:10,330 iteration 5548 : loss : 0.019670, loss_ce: 0.006984
2022-01-09 15:18:12,712 iteration 5549 : loss : 0.017684, loss_ce: 0.006599
2022-01-09 15:18:15,103 iteration 5550 : loss : 0.020407, loss_ce: 0.007933
2022-01-09 15:18:17,469 iteration 5551 : loss : 0.016089, loss_ce: 0.004047
2022-01-09 15:18:19,948 iteration 5552 : loss : 0.030524, loss_ce: 0.008813
2022-01-09 15:18:22,386 iteration 5553 : loss : 0.018311, loss_ce: 0.006862
2022-01-09 15:18:24,808 iteration 5554 : loss : 0.031298, loss_ce: 0.009276
2022-01-09 15:18:27,138 iteration 5555 : loss : 0.019289, loss_ce: 0.007581
2022-01-09 15:18:29,473 iteration 5556 : loss : 0.017614, loss_ce: 0.007533
2022-01-09 15:18:31,735 iteration 5557 : loss : 0.021876, loss_ce: 0.007003
2022-01-09 15:18:33,975 iteration 5558 : loss : 0.025576, loss_ce: 0.007922
2022-01-09 15:18:36,210 iteration 5559 : loss : 0.015545, loss_ce: 0.005407
 82%|███████████████████████▋     | 327/400 [3:54:15<52:35, 43.23s/it]2022-01-09 15:18:38,538 iteration 5560 : loss : 0.018926, loss_ce: 0.007221
2022-01-09 15:18:40,826 iteration 5561 : loss : 0.027736, loss_ce: 0.006156
2022-01-09 15:18:43,087 iteration 5562 : loss : 0.017405, loss_ce: 0.005154
2022-01-09 15:18:45,389 iteration 5563 : loss : 0.019545, loss_ce: 0.006691
2022-01-09 15:18:47,573 iteration 5564 : loss : 0.020941, loss_ce: 0.006947
2022-01-09 15:18:49,886 iteration 5565 : loss : 0.024185, loss_ce: 0.007227
2022-01-09 15:18:52,131 iteration 5566 : loss : 0.014002, loss_ce: 0.004612
2022-01-09 15:18:54,519 iteration 5567 : loss : 0.021393, loss_ce: 0.011505
2022-01-09 15:18:56,823 iteration 5568 : loss : 0.020058, loss_ce: 0.008871
2022-01-09 15:18:59,176 iteration 5569 : loss : 0.022039, loss_ce: 0.009667
2022-01-09 15:19:01,525 iteration 5570 : loss : 0.016378, loss_ce: 0.007860
2022-01-09 15:19:03,808 iteration 5571 : loss : 0.018565, loss_ce: 0.005109
2022-01-09 15:19:06,015 iteration 5572 : loss : 0.012910, loss_ce: 0.004586
2022-01-09 15:19:08,385 iteration 5573 : loss : 0.022674, loss_ce: 0.008487
2022-01-09 15:19:10,631 iteration 5574 : loss : 0.017309, loss_ce: 0.006976
2022-01-09 15:19:12,833 iteration 5575 : loss : 0.018277, loss_ce: 0.007336
2022-01-09 15:19:15,068 iteration 5576 : loss : 0.019589, loss_ce: 0.005498
 82%|███████████████████████▊     | 328/400 [3:54:54<50:17, 41.91s/it]2022-01-09 15:19:17,496 iteration 5577 : loss : 0.034243, loss_ce: 0.011774
2022-01-09 15:19:19,880 iteration 5578 : loss : 0.023141, loss_ce: 0.007991
2022-01-09 15:19:22,351 iteration 5579 : loss : 0.030268, loss_ce: 0.007099
2022-01-09 15:19:24,699 iteration 5580 : loss : 0.017820, loss_ce: 0.006196
2022-01-09 15:19:27,016 iteration 5581 : loss : 0.019249, loss_ce: 0.009804
2022-01-09 15:19:29,324 iteration 5582 : loss : 0.015635, loss_ce: 0.006031
2022-01-09 15:19:31,654 iteration 5583 : loss : 0.011532, loss_ce: 0.003519
2022-01-09 15:19:33,975 iteration 5584 : loss : 0.016961, loss_ce: 0.006239
2022-01-09 15:19:36,280 iteration 5585 : loss : 0.014451, loss_ce: 0.004752
2022-01-09 15:19:38,670 iteration 5586 : loss : 0.015657, loss_ce: 0.007096
2022-01-09 15:19:41,114 iteration 5587 : loss : 0.020897, loss_ce: 0.008090
2022-01-09 15:19:43,444 iteration 5588 : loss : 0.029452, loss_ce: 0.010152
2022-01-09 15:19:45,781 iteration 5589 : loss : 0.020458, loss_ce: 0.006292
2022-01-09 15:19:48,096 iteration 5590 : loss : 0.015215, loss_ce: 0.006547
2022-01-09 15:19:50,409 iteration 5591 : loss : 0.023676, loss_ce: 0.008647
2022-01-09 15:19:52,667 iteration 5592 : loss : 0.018421, loss_ce: 0.007283
2022-01-09 15:19:54,928 iteration 5593 : loss : 0.015783, loss_ce: 0.008208
 82%|███████████████████████▊     | 329/400 [3:55:34<48:52, 41.30s/it]2022-01-09 15:19:57,317 iteration 5594 : loss : 0.013361, loss_ce: 0.003994
2022-01-09 15:19:59,583 iteration 5595 : loss : 0.013612, loss_ce: 0.005341
2022-01-09 15:20:01,951 iteration 5596 : loss : 0.023268, loss_ce: 0.005992
2022-01-09 15:20:04,307 iteration 5597 : loss : 0.016872, loss_ce: 0.007115
2022-01-09 15:20:06,674 iteration 5598 : loss : 0.024143, loss_ce: 0.011414
2022-01-09 15:20:08,983 iteration 5599 : loss : 0.021294, loss_ce: 0.007282
2022-01-09 15:20:11,243 iteration 5600 : loss : 0.015215, loss_ce: 0.005623
2022-01-09 15:20:13,593 iteration 5601 : loss : 0.024152, loss_ce: 0.009941
2022-01-09 15:20:15,865 iteration 5602 : loss : 0.016481, loss_ce: 0.005274
2022-01-09 15:20:18,248 iteration 5603 : loss : 0.023606, loss_ce: 0.012406
2022-01-09 15:20:20,586 iteration 5604 : loss : 0.022611, loss_ce: 0.007126
2022-01-09 15:20:22,999 iteration 5605 : loss : 0.021980, loss_ce: 0.011069
2022-01-09 15:20:25,403 iteration 5606 : loss : 0.030854, loss_ce: 0.009142
2022-01-09 15:20:27,700 iteration 5607 : loss : 0.016528, loss_ce: 0.006797
2022-01-09 15:20:30,059 iteration 5608 : loss : 0.018727, loss_ce: 0.008399
2022-01-09 15:20:32,396 iteration 5609 : loss : 0.015377, loss_ce: 0.005479
2022-01-09 15:20:32,396 Training Data Eval:
2022-01-09 15:20:45,264   Average segmentation loss on training set: 0.0105
2022-01-09 15:20:45,265 Validation Data Eval:
2022-01-09 15:20:49,786   Average segmentation loss on validation set: 0.0652
2022-01-09 15:20:52,152 iteration 5610 : loss : 0.017172, loss_ce: 0.006763
 82%|███████████████████████▉     | 330/400 [3:56:31<53:45, 46.08s/it]2022-01-09 15:20:54,531 iteration 5611 : loss : 0.012623, loss_ce: 0.005347
2022-01-09 15:20:56,950 iteration 5612 : loss : 0.028576, loss_ce: 0.008873
2022-01-09 15:20:59,332 iteration 5613 : loss : 0.013184, loss_ce: 0.002804
2022-01-09 15:21:01,717 iteration 5614 : loss : 0.016317, loss_ce: 0.006220
2022-01-09 15:21:04,044 iteration 5615 : loss : 0.025215, loss_ce: 0.011976
2022-01-09 15:21:06,331 iteration 5616 : loss : 0.015507, loss_ce: 0.004358
2022-01-09 15:21:08,731 iteration 5617 : loss : 0.025031, loss_ce: 0.008684
2022-01-09 15:21:11,116 iteration 5618 : loss : 0.023681, loss_ce: 0.008350
2022-01-09 15:21:13,388 iteration 5619 : loss : 0.014270, loss_ce: 0.006709
2022-01-09 15:21:15,628 iteration 5620 : loss : 0.016078, loss_ce: 0.006336
2022-01-09 15:21:17,919 iteration 5621 : loss : 0.017050, loss_ce: 0.006535
2022-01-09 15:21:20,237 iteration 5622 : loss : 0.013622, loss_ce: 0.005788
2022-01-09 15:21:22,674 iteration 5623 : loss : 0.017342, loss_ce: 0.006623
2022-01-09 15:21:25,066 iteration 5624 : loss : 0.013219, loss_ce: 0.004752
2022-01-09 15:21:27,399 iteration 5625 : loss : 0.019185, loss_ce: 0.008454
2022-01-09 15:21:29,797 iteration 5626 : loss : 0.019913, loss_ce: 0.006912
2022-01-09 15:21:32,242 iteration 5627 : loss : 0.013824, loss_ce: 0.005850
 83%|███████████████████████▉     | 331/400 [3:57:11<50:55, 44.28s/it]2022-01-09 15:21:34,709 iteration 5628 : loss : 0.015519, loss_ce: 0.006444
2022-01-09 15:21:37,061 iteration 5629 : loss : 0.015837, loss_ce: 0.005976
2022-01-09 15:21:39,367 iteration 5630 : loss : 0.014068, loss_ce: 0.005131
2022-01-09 15:21:41,691 iteration 5631 : loss : 0.015452, loss_ce: 0.007470
2022-01-09 15:21:44,225 iteration 5632 : loss : 0.019240, loss_ce: 0.007091
2022-01-09 15:21:46,584 iteration 5633 : loss : 0.022505, loss_ce: 0.005688
2022-01-09 15:21:49,015 iteration 5634 : loss : 0.026255, loss_ce: 0.007311
2022-01-09 15:21:51,339 iteration 5635 : loss : 0.016526, loss_ce: 0.006055
2022-01-09 15:21:53,699 iteration 5636 : loss : 0.018635, loss_ce: 0.005268
2022-01-09 15:21:56,155 iteration 5637 : loss : 0.018453, loss_ce: 0.008100
2022-01-09 15:21:58,528 iteration 5638 : loss : 0.016981, loss_ce: 0.007568
2022-01-09 15:22:01,003 iteration 5639 : loss : 0.019706, loss_ce: 0.005874
2022-01-09 15:22:03,382 iteration 5640 : loss : 0.029409, loss_ce: 0.013151
2022-01-09 15:22:05,695 iteration 5641 : loss : 0.021355, loss_ce: 0.009474
2022-01-09 15:22:08,139 iteration 5642 : loss : 0.016335, loss_ce: 0.007069
2022-01-09 15:22:10,509 iteration 5643 : loss : 0.014887, loss_ce: 0.007120
2022-01-09 15:22:12,875 iteration 5644 : loss : 0.016964, loss_ce: 0.007826
 83%|████████████████████████     | 332/400 [3:57:52<48:56, 43.19s/it]2022-01-09 15:22:15,318 iteration 5645 : loss : 0.015079, loss_ce: 0.004187
2022-01-09 15:22:17,702 iteration 5646 : loss : 0.017796, loss_ce: 0.005004
2022-01-09 15:22:20,047 iteration 5647 : loss : 0.011299, loss_ce: 0.003847
2022-01-09 15:22:22,415 iteration 5648 : loss : 0.018075, loss_ce: 0.009273
2022-01-09 15:22:24,823 iteration 5649 : loss : 0.015485, loss_ce: 0.004965
2022-01-09 15:22:27,254 iteration 5650 : loss : 0.020433, loss_ce: 0.007021
2022-01-09 15:22:29,653 iteration 5651 : loss : 0.014634, loss_ce: 0.006166
2022-01-09 15:22:32,170 iteration 5652 : loss : 0.015423, loss_ce: 0.004643
2022-01-09 15:22:34,538 iteration 5653 : loss : 0.015106, loss_ce: 0.004159
2022-01-09 15:22:36,879 iteration 5654 : loss : 0.017340, loss_ce: 0.006580
2022-01-09 15:22:39,312 iteration 5655 : loss : 0.014201, loss_ce: 0.006533
2022-01-09 15:22:41,765 iteration 5656 : loss : 0.021570, loss_ce: 0.007442
2022-01-09 15:22:44,121 iteration 5657 : loss : 0.025789, loss_ce: 0.008795
2022-01-09 15:22:46,581 iteration 5658 : loss : 0.030609, loss_ce: 0.013336
2022-01-09 15:22:48,886 iteration 5659 : loss : 0.021676, loss_ce: 0.010083
2022-01-09 15:22:51,486 iteration 5660 : loss : 0.026373, loss_ce: 0.007939
2022-01-09 15:22:53,942 iteration 5661 : loss : 0.020891, loss_ce: 0.010056
 83%|████████████████████████▏    | 333/400 [3:58:33<47:30, 42.55s/it]2022-01-09 15:22:56,367 iteration 5662 : loss : 0.027346, loss_ce: 0.010682
2022-01-09 15:22:58,739 iteration 5663 : loss : 0.015855, loss_ce: 0.004638
2022-01-09 15:23:01,113 iteration 5664 : loss : 0.015566, loss_ce: 0.007112
2022-01-09 15:23:03,500 iteration 5665 : loss : 0.013283, loss_ce: 0.005136
2022-01-09 15:23:06,117 iteration 5666 : loss : 0.028854, loss_ce: 0.006408
2022-01-09 15:23:08,529 iteration 5667 : loss : 0.015438, loss_ce: 0.005970
2022-01-09 15:23:10,881 iteration 5668 : loss : 0.019067, loss_ce: 0.007177
2022-01-09 15:23:13,121 iteration 5669 : loss : 0.019642, loss_ce: 0.007028
2022-01-09 15:23:15,521 iteration 5670 : loss : 0.026890, loss_ce: 0.008288
2022-01-09 15:23:18,009 iteration 5671 : loss : 0.016167, loss_ce: 0.006051
2022-01-09 15:23:20,470 iteration 5672 : loss : 0.030338, loss_ce: 0.014778
2022-01-09 15:23:22,801 iteration 5673 : loss : 0.018899, loss_ce: 0.006930
2022-01-09 15:23:25,361 iteration 5674 : loss : 0.014978, loss_ce: 0.004569
2022-01-09 15:23:27,760 iteration 5675 : loss : 0.012428, loss_ce: 0.005653
2022-01-09 15:23:30,371 iteration 5676 : loss : 0.022758, loss_ce: 0.009836
2022-01-09 15:23:32,767 iteration 5677 : loss : 0.019106, loss_ce: 0.004692
2022-01-09 15:23:35,208 iteration 5678 : loss : 0.018048, loss_ce: 0.007204
 84%|████████████████████████▏    | 334/400 [3:59:14<46:22, 42.16s/it]2022-01-09 15:23:37,674 iteration 5679 : loss : 0.015141, loss_ce: 0.005587
2022-01-09 15:23:40,153 iteration 5680 : loss : 0.014129, loss_ce: 0.006090
2022-01-09 15:23:42,544 iteration 5681 : loss : 0.031528, loss_ce: 0.014977
2022-01-09 15:23:44,967 iteration 5682 : loss : 0.016242, loss_ce: 0.006106
2022-01-09 15:23:47,407 iteration 5683 : loss : 0.029058, loss_ce: 0.012249
2022-01-09 15:23:49,851 iteration 5684 : loss : 0.032024, loss_ce: 0.012152
2022-01-09 15:23:52,271 iteration 5685 : loss : 0.016533, loss_ce: 0.004534
2022-01-09 15:23:54,716 iteration 5686 : loss : 0.018025, loss_ce: 0.007404
2022-01-09 15:23:57,056 iteration 5687 : loss : 0.013916, loss_ce: 0.004602
2022-01-09 15:23:59,350 iteration 5688 : loss : 0.018439, loss_ce: 0.006428
2022-01-09 15:24:01,674 iteration 5689 : loss : 0.016514, loss_ce: 0.007330
2022-01-09 15:24:04,070 iteration 5690 : loss : 0.018965, loss_ce: 0.009551
2022-01-09 15:24:06,434 iteration 5691 : loss : 0.014222, loss_ce: 0.003845
2022-01-09 15:24:08,765 iteration 5692 : loss : 0.013595, loss_ce: 0.004758
2022-01-09 15:24:11,171 iteration 5693 : loss : 0.023412, loss_ce: 0.011027
2022-01-09 15:24:13,579 iteration 5694 : loss : 0.022002, loss_ce: 0.008651
2022-01-09 15:24:13,579 Training Data Eval:
2022-01-09 15:24:26,504   Average segmentation loss on training set: 0.0100
2022-01-09 15:24:26,504 Validation Data Eval:
2022-01-09 15:24:31,168   Average segmentation loss on validation set: 0.0685
2022-01-09 15:24:33,543 iteration 5695 : loss : 0.030773, loss_ce: 0.010323
 84%|████████████████████████▎    | 335/400 [4:00:12<50:56, 47.02s/it]2022-01-09 15:24:35,974 iteration 5696 : loss : 0.021236, loss_ce: 0.007541
2022-01-09 15:24:38,441 iteration 5697 : loss : 0.026263, loss_ce: 0.009556
2022-01-09 15:24:40,820 iteration 5698 : loss : 0.015704, loss_ce: 0.005907
2022-01-09 15:24:43,200 iteration 5699 : loss : 0.027158, loss_ce: 0.011078
2022-01-09 15:24:45,621 iteration 5700 : loss : 0.016398, loss_ce: 0.005891
2022-01-09 15:24:48,043 iteration 5701 : loss : 0.014303, loss_ce: 0.006933
2022-01-09 15:24:50,494 iteration 5702 : loss : 0.012618, loss_ce: 0.004305
2022-01-09 15:24:52,860 iteration 5703 : loss : 0.014204, loss_ce: 0.006270
2022-01-09 15:24:55,270 iteration 5704 : loss : 0.017618, loss_ce: 0.007545
2022-01-09 15:24:57,723 iteration 5705 : loss : 0.019816, loss_ce: 0.006296
2022-01-09 15:25:00,097 iteration 5706 : loss : 0.016635, loss_ce: 0.003818
2022-01-09 15:25:02,604 iteration 5707 : loss : 0.017864, loss_ce: 0.006325
2022-01-09 15:25:04,968 iteration 5708 : loss : 0.015278, loss_ce: 0.006854
2022-01-09 15:25:07,437 iteration 5709 : loss : 0.020778, loss_ce: 0.010175
2022-01-09 15:25:09,895 iteration 5710 : loss : 0.018774, loss_ce: 0.008061
2022-01-09 15:25:12,274 iteration 5711 : loss : 0.027639, loss_ce: 0.015937
2022-01-09 15:25:14,639 iteration 5712 : loss : 0.015949, loss_ce: 0.006866
 84%|████████████████████████▎    | 336/400 [4:00:53<48:15, 45.24s/it]2022-01-09 15:25:17,192 iteration 5713 : loss : 0.019337, loss_ce: 0.005858
2022-01-09 15:25:19,569 iteration 5714 : loss : 0.014811, loss_ce: 0.005710
2022-01-09 15:25:21,907 iteration 5715 : loss : 0.011641, loss_ce: 0.004556
2022-01-09 15:25:24,295 iteration 5716 : loss : 0.017075, loss_ce: 0.007584
2022-01-09 15:25:26,791 iteration 5717 : loss : 0.017913, loss_ce: 0.006241
2022-01-09 15:25:29,178 iteration 5718 : loss : 0.022297, loss_ce: 0.007426
2022-01-09 15:25:31,583 iteration 5719 : loss : 0.014112, loss_ce: 0.005666
2022-01-09 15:25:34,004 iteration 5720 : loss : 0.016555, loss_ce: 0.007148
2022-01-09 15:25:36,352 iteration 5721 : loss : 0.012739, loss_ce: 0.003498
2022-01-09 15:25:38,785 iteration 5722 : loss : 0.013996, loss_ce: 0.004764
2022-01-09 15:25:41,218 iteration 5723 : loss : 0.016514, loss_ce: 0.006014
2022-01-09 15:25:43,531 iteration 5724 : loss : 0.013622, loss_ce: 0.005567
2022-01-09 15:25:45,923 iteration 5725 : loss : 0.017061, loss_ce: 0.007872
2022-01-09 15:25:48,209 iteration 5726 : loss : 0.015375, loss_ce: 0.006627
2022-01-09 15:25:50,753 iteration 5727 : loss : 0.018895, loss_ce: 0.006996
2022-01-09 15:25:53,133 iteration 5728 : loss : 0.014639, loss_ce: 0.007022
2022-01-09 15:25:55,498 iteration 5729 : loss : 0.015094, loss_ce: 0.005436
 84%|████████████████████████▍    | 337/400 [4:01:34<46:07, 43.92s/it]2022-01-09 15:25:57,968 iteration 5730 : loss : 0.031522, loss_ce: 0.010402
2022-01-09 15:26:00,389 iteration 5731 : loss : 0.015819, loss_ce: 0.006739
2022-01-09 15:26:02,850 iteration 5732 : loss : 0.016567, loss_ce: 0.004851
2022-01-09 15:26:05,220 iteration 5733 : loss : 0.014649, loss_ce: 0.003906
2022-01-09 15:26:07,646 iteration 5734 : loss : 0.023211, loss_ce: 0.006733
2022-01-09 15:26:10,026 iteration 5735 : loss : 0.016017, loss_ce: 0.007442
2022-01-09 15:26:12,353 iteration 5736 : loss : 0.018697, loss_ce: 0.010398
2022-01-09 15:26:14,849 iteration 5737 : loss : 0.027766, loss_ce: 0.011095
2022-01-09 15:26:17,197 iteration 5738 : loss : 0.011284, loss_ce: 0.004520
2022-01-09 15:26:19,551 iteration 5739 : loss : 0.015819, loss_ce: 0.006782
2022-01-09 15:26:22,115 iteration 5740 : loss : 0.023049, loss_ce: 0.009627
2022-01-09 15:26:24,579 iteration 5741 : loss : 0.017412, loss_ce: 0.009537
2022-01-09 15:26:27,024 iteration 5742 : loss : 0.018858, loss_ce: 0.007858
2022-01-09 15:26:29,426 iteration 5743 : loss : 0.016749, loss_ce: 0.006859
2022-01-09 15:26:31,841 iteration 5744 : loss : 0.018706, loss_ce: 0.007400
2022-01-09 15:26:34,151 iteration 5745 : loss : 0.017938, loss_ce: 0.004528
2022-01-09 15:26:36,628 iteration 5746 : loss : 0.014674, loss_ce: 0.003979
 84%|████████████████████████▌    | 338/400 [4:02:15<44:31, 43.09s/it]2022-01-09 15:26:39,098 iteration 5747 : loss : 0.021378, loss_ce: 0.007736
2022-01-09 15:26:41,565 iteration 5748 : loss : 0.026233, loss_ce: 0.008736
2022-01-09 15:26:44,018 iteration 5749 : loss : 0.019514, loss_ce: 0.008314
2022-01-09 15:26:46,496 iteration 5750 : loss : 0.019420, loss_ce: 0.005497
2022-01-09 15:26:48,845 iteration 5751 : loss : 0.018980, loss_ce: 0.007320
2022-01-09 15:26:51,259 iteration 5752 : loss : 0.017604, loss_ce: 0.005308
2022-01-09 15:26:53,617 iteration 5753 : loss : 0.018622, loss_ce: 0.007259
2022-01-09 15:26:55,955 iteration 5754 : loss : 0.012508, loss_ce: 0.004694
2022-01-09 15:26:58,471 iteration 5755 : loss : 0.015432, loss_ce: 0.006774
2022-01-09 15:27:00,844 iteration 5756 : loss : 0.018142, loss_ce: 0.006072
2022-01-09 15:27:03,156 iteration 5757 : loss : 0.016122, loss_ce: 0.008136
2022-01-09 15:27:05,667 iteration 5758 : loss : 0.023881, loss_ce: 0.004822
2022-01-09 15:27:08,085 iteration 5759 : loss : 0.015468, loss_ce: 0.007107
2022-01-09 15:27:10,502 iteration 5760 : loss : 0.021074, loss_ce: 0.007383
2022-01-09 15:27:12,946 iteration 5761 : loss : 0.011545, loss_ce: 0.004189
2022-01-09 15:27:15,490 iteration 5762 : loss : 0.025836, loss_ce: 0.010149
2022-01-09 15:27:17,894 iteration 5763 : loss : 0.018683, loss_ce: 0.007758
 85%|████████████████████████▌    | 339/400 [4:02:57<43:15, 42.54s/it]2022-01-09 15:27:20,319 iteration 5764 : loss : 0.018132, loss_ce: 0.006617
2022-01-09 15:27:22,779 iteration 5765 : loss : 0.020941, loss_ce: 0.006219
2022-01-09 15:27:25,367 iteration 5766 : loss : 0.018141, loss_ce: 0.007998
2022-01-09 15:27:27,798 iteration 5767 : loss : 0.014414, loss_ce: 0.005597
2022-01-09 15:27:30,212 iteration 5768 : loss : 0.024259, loss_ce: 0.007184
2022-01-09 15:27:32,741 iteration 5769 : loss : 0.013736, loss_ce: 0.005325
2022-01-09 15:27:35,146 iteration 5770 : loss : 0.017453, loss_ce: 0.007108
2022-01-09 15:27:37,480 iteration 5771 : loss : 0.017762, loss_ce: 0.007775
2022-01-09 15:27:39,977 iteration 5772 : loss : 0.018129, loss_ce: 0.006906
2022-01-09 15:27:42,567 iteration 5773 : loss : 0.015249, loss_ce: 0.006032
2022-01-09 15:27:44,975 iteration 5774 : loss : 0.019378, loss_ce: 0.009205
2022-01-09 15:27:47,343 iteration 5775 : loss : 0.028404, loss_ce: 0.010322
2022-01-09 15:27:49,618 iteration 5776 : loss : 0.017071, loss_ce: 0.005461
2022-01-09 15:27:52,022 iteration 5777 : loss : 0.019477, loss_ce: 0.007535
2022-01-09 15:27:54,518 iteration 5778 : loss : 0.030893, loss_ce: 0.008398
2022-01-09 15:27:57,107 iteration 5779 : loss : 0.027363, loss_ce: 0.012099
2022-01-09 15:27:57,108 Training Data Eval:
2022-01-09 15:28:10,093   Average segmentation loss on training set: 0.0097
2022-01-09 15:28:10,094 Validation Data Eval:
2022-01-09 15:28:14,747   Average segmentation loss on validation set: 0.0688
2022-01-09 15:28:17,240 iteration 5780 : loss : 0.026764, loss_ce: 0.014384
 85%|████████████████████████▋    | 340/400 [4:03:56<47:34, 47.58s/it]2022-01-09 15:28:19,789 iteration 5781 : loss : 0.025881, loss_ce: 0.008518
2022-01-09 15:28:22,249 iteration 5782 : loss : 0.011898, loss_ce: 0.005612
2022-01-09 15:28:24,567 iteration 5783 : loss : 0.019002, loss_ce: 0.007846
2022-01-09 15:28:26,928 iteration 5784 : loss : 0.016499, loss_ce: 0.005920
2022-01-09 15:28:29,221 iteration 5785 : loss : 0.014141, loss_ce: 0.006115
2022-01-09 15:28:31,518 iteration 5786 : loss : 0.032195, loss_ce: 0.009136
2022-01-09 15:28:33,777 iteration 5787 : loss : 0.019940, loss_ce: 0.008505
2022-01-09 15:28:36,255 iteration 5788 : loss : 0.013869, loss_ce: 0.005392
2022-01-09 15:28:38,581 iteration 5789 : loss : 0.015254, loss_ce: 0.007186
2022-01-09 15:28:40,962 iteration 5790 : loss : 0.012450, loss_ce: 0.004781
2022-01-09 15:28:43,275 iteration 5791 : loss : 0.013638, loss_ce: 0.005919
2022-01-09 15:28:45,532 iteration 5792 : loss : 0.015485, loss_ce: 0.006174
2022-01-09 15:28:47,937 iteration 5793 : loss : 0.019350, loss_ce: 0.006457
2022-01-09 15:28:50,347 iteration 5794 : loss : 0.020603, loss_ce: 0.010558
2022-01-09 15:28:52,911 iteration 5795 : loss : 0.017230, loss_ce: 0.008190
2022-01-09 15:28:55,323 iteration 5796 : loss : 0.013342, loss_ce: 0.005885
2022-01-09 15:28:57,692 iteration 5797 : loss : 0.024127, loss_ce: 0.009009
 85%|████████████████████████▋    | 341/400 [4:04:36<44:41, 45.44s/it]2022-01-09 15:29:00,136 iteration 5798 : loss : 0.019268, loss_ce: 0.006459
2022-01-09 15:29:02,443 iteration 5799 : loss : 0.017534, loss_ce: 0.005191
2022-01-09 15:29:04,832 iteration 5800 : loss : 0.015738, loss_ce: 0.004370
2022-01-09 15:29:07,116 iteration 5801 : loss : 0.010821, loss_ce: 0.003910
2022-01-09 15:29:09,504 iteration 5802 : loss : 0.015321, loss_ce: 0.007715
2022-01-09 15:29:11,895 iteration 5803 : loss : 0.013200, loss_ce: 0.004502
2022-01-09 15:29:14,354 iteration 5804 : loss : 0.028378, loss_ce: 0.009646
2022-01-09 15:29:16,657 iteration 5805 : loss : 0.019602, loss_ce: 0.009361
2022-01-09 15:29:18,973 iteration 5806 : loss : 0.015746, loss_ce: 0.006104
2022-01-09 15:29:21,367 iteration 5807 : loss : 0.014962, loss_ce: 0.005871
2022-01-09 15:29:23,709 iteration 5808 : loss : 0.016667, loss_ce: 0.007233
2022-01-09 15:29:26,169 iteration 5809 : loss : 0.021766, loss_ce: 0.006774
2022-01-09 15:29:28,551 iteration 5810 : loss : 0.021530, loss_ce: 0.006103
2022-01-09 15:29:30,936 iteration 5811 : loss : 0.013875, loss_ce: 0.006152
2022-01-09 15:29:33,335 iteration 5812 : loss : 0.016523, loss_ce: 0.007122
2022-01-09 15:29:35,849 iteration 5813 : loss : 0.018747, loss_ce: 0.006107
2022-01-09 15:29:38,250 iteration 5814 : loss : 0.019534, loss_ce: 0.007776
 86%|████████████████████████▊    | 342/400 [4:05:17<42:30, 43.98s/it]2022-01-09 15:29:40,822 iteration 5815 : loss : 0.018643, loss_ce: 0.007500
2022-01-09 15:29:43,226 iteration 5816 : loss : 0.015754, loss_ce: 0.004852
2022-01-09 15:29:45,645 iteration 5817 : loss : 0.015692, loss_ce: 0.004448
2022-01-09 15:29:47,998 iteration 5818 : loss : 0.015709, loss_ce: 0.005002
2022-01-09 15:29:50,458 iteration 5819 : loss : 0.016102, loss_ce: 0.006328
2022-01-09 15:29:52,860 iteration 5820 : loss : 0.018600, loss_ce: 0.009151
2022-01-09 15:29:55,212 iteration 5821 : loss : 0.025545, loss_ce: 0.009490
2022-01-09 15:29:57,602 iteration 5822 : loss : 0.015429, loss_ce: 0.004423
2022-01-09 15:30:00,028 iteration 5823 : loss : 0.012668, loss_ce: 0.004535
2022-01-09 15:30:02,401 iteration 5824 : loss : 0.016021, loss_ce: 0.005514
2022-01-09 15:30:04,763 iteration 5825 : loss : 0.017815, loss_ce: 0.007996
2022-01-09 15:30:07,058 iteration 5826 : loss : 0.019003, loss_ce: 0.005428
2022-01-09 15:30:09,302 iteration 5827 : loss : 0.019724, loss_ce: 0.006161
2022-01-09 15:30:11,566 iteration 5828 : loss : 0.010654, loss_ce: 0.004849
2022-01-09 15:30:13,892 iteration 5829 : loss : 0.014648, loss_ce: 0.005775
2022-01-09 15:30:16,219 iteration 5830 : loss : 0.017843, loss_ce: 0.007479
2022-01-09 15:30:18,607 iteration 5831 : loss : 0.017081, loss_ce: 0.007219
 86%|████████████████████████▊    | 343/400 [4:05:57<40:44, 42.89s/it]2022-01-09 15:30:21,099 iteration 5832 : loss : 0.025108, loss_ce: 0.008897
2022-01-09 15:30:23,446 iteration 5833 : loss : 0.011495, loss_ce: 0.003815
2022-01-09 15:30:25,843 iteration 5834 : loss : 0.024501, loss_ce: 0.010940
2022-01-09 15:30:28,276 iteration 5835 : loss : 0.032701, loss_ce: 0.012758
2022-01-09 15:30:30,514 iteration 5836 : loss : 0.017132, loss_ce: 0.008187
2022-01-09 15:30:32,874 iteration 5837 : loss : 0.026021, loss_ce: 0.014992
2022-01-09 15:30:35,199 iteration 5838 : loss : 0.023297, loss_ce: 0.006801
2022-01-09 15:30:37,456 iteration 5839 : loss : 0.019802, loss_ce: 0.006228
2022-01-09 15:30:39,933 iteration 5840 : loss : 0.017542, loss_ce: 0.007450
2022-01-09 15:30:42,214 iteration 5841 : loss : 0.010774, loss_ce: 0.004391
2022-01-09 15:30:44,486 iteration 5842 : loss : 0.022556, loss_ce: 0.009204
2022-01-09 15:30:46,787 iteration 5843 : loss : 0.018797, loss_ce: 0.006070
2022-01-09 15:30:49,120 iteration 5844 : loss : 0.026837, loss_ce: 0.009915
2022-01-09 15:30:51,518 iteration 5845 : loss : 0.018793, loss_ce: 0.006033
2022-01-09 15:30:53,863 iteration 5846 : loss : 0.013240, loss_ce: 0.005712
2022-01-09 15:30:56,142 iteration 5847 : loss : 0.012669, loss_ce: 0.004755
2022-01-09 15:30:58,323 iteration 5848 : loss : 0.013781, loss_ce: 0.004249
 86%|████████████████████████▉    | 344/400 [4:06:37<39:08, 41.94s/it]2022-01-09 15:31:00,575 iteration 5849 : loss : 0.017110, loss_ce: 0.005985
2022-01-09 15:31:02,893 iteration 5850 : loss : 0.018481, loss_ce: 0.005108
2022-01-09 15:31:05,130 iteration 5851 : loss : 0.012718, loss_ce: 0.005477
2022-01-09 15:31:07,384 iteration 5852 : loss : 0.014288, loss_ce: 0.004693
2022-01-09 15:31:09,857 iteration 5853 : loss : 0.034169, loss_ce: 0.007272
2022-01-09 15:31:12,222 iteration 5854 : loss : 0.020853, loss_ce: 0.008374
2022-01-09 15:31:14,485 iteration 5855 : loss : 0.013928, loss_ce: 0.003689
2022-01-09 15:31:16,715 iteration 5856 : loss : 0.014500, loss_ce: 0.006432
2022-01-09 15:31:19,078 iteration 5857 : loss : 0.019378, loss_ce: 0.008846
2022-01-09 15:31:21,576 iteration 5858 : loss : 0.018296, loss_ce: 0.004552
2022-01-09 15:31:23,967 iteration 5859 : loss : 0.016682, loss_ce: 0.008020
2022-01-09 15:31:26,332 iteration 5860 : loss : 0.012963, loss_ce: 0.004846
2022-01-09 15:31:28,747 iteration 5861 : loss : 0.017070, loss_ce: 0.007451
2022-01-09 15:31:31,113 iteration 5862 : loss : 0.012822, loss_ce: 0.004737
2022-01-09 15:31:33,503 iteration 5863 : loss : 0.016896, loss_ce: 0.006386
2022-01-09 15:31:35,863 iteration 5864 : loss : 0.016354, loss_ce: 0.005877
2022-01-09 15:31:35,863 Training Data Eval:
2022-01-09 15:31:48,817   Average segmentation loss on training set: 0.0093
2022-01-09 15:31:48,818 Validation Data Eval:
2022-01-09 15:31:53,186   Average segmentation loss on validation set: 0.0671
2022-01-09 15:31:55,719 iteration 5865 : loss : 0.013926, loss_ce: 0.005024
 86%|█████████████████████████    | 345/400 [4:07:34<42:41, 46.58s/it]2022-01-09 15:31:58,364 iteration 5866 : loss : 0.016211, loss_ce: 0.005810
2022-01-09 15:32:00,779 iteration 5867 : loss : 0.013671, loss_ce: 0.005991
2022-01-09 15:32:03,072 iteration 5868 : loss : 0.010967, loss_ce: 0.004190
2022-01-09 15:32:05,371 iteration 5869 : loss : 0.011160, loss_ce: 0.003983
2022-01-09 15:32:07,577 iteration 5870 : loss : 0.014388, loss_ce: 0.005161
2022-01-09 15:32:09,884 iteration 5871 : loss : 0.014726, loss_ce: 0.006544
2022-01-09 15:32:12,141 iteration 5872 : loss : 0.013117, loss_ce: 0.005930
2022-01-09 15:32:14,322 iteration 5873 : loss : 0.013818, loss_ce: 0.006019
2022-01-09 15:32:16,596 iteration 5874 : loss : 0.031127, loss_ce: 0.008004
2022-01-09 15:32:19,021 iteration 5875 : loss : 0.015730, loss_ce: 0.006766
2022-01-09 15:32:21,376 iteration 5876 : loss : 0.019294, loss_ce: 0.008428
2022-01-09 15:32:23,638 iteration 5877 : loss : 0.025264, loss_ce: 0.008138
2022-01-09 15:32:25,885 iteration 5878 : loss : 0.023154, loss_ce: 0.006304
2022-01-09 15:32:28,134 iteration 5879 : loss : 0.019570, loss_ce: 0.005757
2022-01-09 15:32:30,353 iteration 5880 : loss : 0.017496, loss_ce: 0.006111
2022-01-09 15:32:32,600 iteration 5881 : loss : 0.027529, loss_ce: 0.006808
2022-01-09 15:32:34,876 iteration 5882 : loss : 0.013729, loss_ce: 0.004775
 86%|█████████████████████████    | 346/400 [4:08:14<39:54, 44.35s/it]2022-01-09 15:32:37,348 iteration 5883 : loss : 0.016954, loss_ce: 0.005794
2022-01-09 15:32:39,601 iteration 5884 : loss : 0.016794, loss_ce: 0.007091
2022-01-09 15:32:41,962 iteration 5885 : loss : 0.019632, loss_ce: 0.005479
2022-01-09 15:32:44,257 iteration 5886 : loss : 0.012186, loss_ce: 0.004625
2022-01-09 15:32:46,519 iteration 5887 : loss : 0.023940, loss_ce: 0.006642
2022-01-09 15:32:48,794 iteration 5888 : loss : 0.012574, loss_ce: 0.005378
2022-01-09 15:32:51,171 iteration 5889 : loss : 0.013528, loss_ce: 0.005706
2022-01-09 15:32:53,535 iteration 5890 : loss : 0.019715, loss_ce: 0.008130
2022-01-09 15:32:55,836 iteration 5891 : loss : 0.017210, loss_ce: 0.005385
2022-01-09 15:32:58,161 iteration 5892 : loss : 0.017137, loss_ce: 0.008269
2022-01-09 15:33:00,590 iteration 5893 : loss : 0.016409, loss_ce: 0.004461
2022-01-09 15:33:02,950 iteration 5894 : loss : 0.015123, loss_ce: 0.004461
2022-01-09 15:33:05,345 iteration 5895 : loss : 0.022648, loss_ce: 0.009237
2022-01-09 15:33:07,625 iteration 5896 : loss : 0.013564, loss_ce: 0.004553
2022-01-09 15:33:09,962 iteration 5897 : loss : 0.017770, loss_ce: 0.009136
2022-01-09 15:33:12,273 iteration 5898 : loss : 0.020713, loss_ce: 0.008324
2022-01-09 15:33:14,554 iteration 5899 : loss : 0.014674, loss_ce: 0.004955
 87%|█████████████████████████▏   | 347/400 [4:08:53<37:56, 42.95s/it]2022-01-09 15:33:16,900 iteration 5900 : loss : 0.010642, loss_ce: 0.004218
2022-01-09 15:33:19,224 iteration 5901 : loss : 0.011739, loss_ce: 0.005034
2022-01-09 15:33:21,685 iteration 5902 : loss : 0.012773, loss_ce: 0.004769
2022-01-09 15:33:24,015 iteration 5903 : loss : 0.017814, loss_ce: 0.007010
2022-01-09 15:33:26,350 iteration 5904 : loss : 0.040931, loss_ce: 0.009918
2022-01-09 15:33:28,626 iteration 5905 : loss : 0.020327, loss_ce: 0.008929
2022-01-09 15:33:30,950 iteration 5906 : loss : 0.015079, loss_ce: 0.004159
2022-01-09 15:33:33,209 iteration 5907 : loss : 0.012655, loss_ce: 0.005431
2022-01-09 15:33:35,499 iteration 5908 : loss : 0.024421, loss_ce: 0.007638
2022-01-09 15:33:37,934 iteration 5909 : loss : 0.016397, loss_ce: 0.007444
2022-01-09 15:33:40,332 iteration 5910 : loss : 0.012651, loss_ce: 0.004382
2022-01-09 15:33:42,733 iteration 5911 : loss : 0.015470, loss_ce: 0.003997
2022-01-09 15:33:45,034 iteration 5912 : loss : 0.029103, loss_ce: 0.006493
2022-01-09 15:33:47,272 iteration 5913 : loss : 0.014546, loss_ce: 0.006254
2022-01-09 15:33:49,491 iteration 5914 : loss : 0.020857, loss_ce: 0.011664
2022-01-09 15:33:51,690 iteration 5915 : loss : 0.018799, loss_ce: 0.009262
2022-01-09 15:33:53,884 iteration 5916 : loss : 0.011986, loss_ce: 0.004310
 87%|█████████████████████████▏   | 348/400 [4:09:33<36:16, 41.86s/it]2022-01-09 15:33:56,217 iteration 5917 : loss : 0.013411, loss_ce: 0.005239
2022-01-09 15:33:58,544 iteration 5918 : loss : 0.023111, loss_ce: 0.010317
2022-01-09 15:34:00,944 iteration 5919 : loss : 0.028743, loss_ce: 0.011874
2022-01-09 15:34:03,259 iteration 5920 : loss : 0.017511, loss_ce: 0.006102
2022-01-09 15:34:05,462 iteration 5921 : loss : 0.023329, loss_ce: 0.007810
2022-01-09 15:34:07,734 iteration 5922 : loss : 0.036703, loss_ce: 0.018829
2022-01-09 15:34:10,011 iteration 5923 : loss : 0.018570, loss_ce: 0.007479
2022-01-09 15:34:12,508 iteration 5924 : loss : 0.011892, loss_ce: 0.004051
2022-01-09 15:34:14,928 iteration 5925 : loss : 0.014555, loss_ce: 0.004809
2022-01-09 15:34:17,354 iteration 5926 : loss : 0.016717, loss_ce: 0.005325
2022-01-09 15:34:19,647 iteration 5927 : loss : 0.011095, loss_ce: 0.004463
2022-01-09 15:34:22,003 iteration 5928 : loss : 0.017910, loss_ce: 0.006927
2022-01-09 15:34:24,316 iteration 5929 : loss : 0.017348, loss_ce: 0.006598
2022-01-09 15:34:26,589 iteration 5930 : loss : 0.016980, loss_ce: 0.007001
2022-01-09 15:34:28,819 iteration 5931 : loss : 0.021120, loss_ce: 0.008586
2022-01-09 15:34:31,136 iteration 5932 : loss : 0.016324, loss_ce: 0.005533
2022-01-09 15:34:33,587 iteration 5933 : loss : 0.021926, loss_ce: 0.006461
 87%|█████████████████████████▎   | 349/400 [4:10:12<35:01, 41.21s/it]2022-01-09 15:34:36,028 iteration 5934 : loss : 0.011431, loss_ce: 0.004075
2022-01-09 15:34:38,376 iteration 5935 : loss : 0.016754, loss_ce: 0.005490
2022-01-09 15:34:40,786 iteration 5936 : loss : 0.019472, loss_ce: 0.006602
2022-01-09 15:34:43,237 iteration 5937 : loss : 0.020324, loss_ce: 0.008691
2022-01-09 15:34:45,642 iteration 5938 : loss : 0.023139, loss_ce: 0.007749
2022-01-09 15:34:48,111 iteration 5939 : loss : 0.021645, loss_ce: 0.008393
2022-01-09 15:34:50,547 iteration 5940 : loss : 0.018366, loss_ce: 0.008285
2022-01-09 15:34:53,024 iteration 5941 : loss : 0.012655, loss_ce: 0.006006
2022-01-09 15:34:55,462 iteration 5942 : loss : 0.024970, loss_ce: 0.008552
2022-01-09 15:34:57,765 iteration 5943 : loss : 0.010550, loss_ce: 0.003819
2022-01-09 15:35:00,045 iteration 5944 : loss : 0.018895, loss_ce: 0.006240
2022-01-09 15:35:02,264 iteration 5945 : loss : 0.017168, loss_ce: 0.004966
2022-01-09 15:35:04,425 iteration 5946 : loss : 0.015871, loss_ce: 0.006239
2022-01-09 15:35:06,739 iteration 5947 : loss : 0.015581, loss_ce: 0.006358
2022-01-09 15:35:09,166 iteration 5948 : loss : 0.019477, loss_ce: 0.007663
2022-01-09 15:35:11,573 iteration 5949 : loss : 0.012126, loss_ce: 0.005010
2022-01-09 15:35:11,573 Training Data Eval:
2022-01-09 15:35:24,385   Average segmentation loss on training set: 0.0094
2022-01-09 15:35:24,385 Validation Data Eval:
2022-01-09 15:35:28,913   Average segmentation loss on validation set: 0.0647
2022-01-09 15:35:31,383 iteration 5950 : loss : 0.024038, loss_ce: 0.008634
 88%|█████████████████████████▍   | 350/400 [4:11:10<38:29, 46.19s/it]2022-01-09 15:35:33,776 iteration 5951 : loss : 0.013893, loss_ce: 0.003757
2022-01-09 15:35:36,115 iteration 5952 : loss : 0.013276, loss_ce: 0.006698
2022-01-09 15:35:38,451 iteration 5953 : loss : 0.015276, loss_ce: 0.006857
2022-01-09 15:35:40,898 iteration 5954 : loss : 0.023726, loss_ce: 0.007471
2022-01-09 15:35:43,252 iteration 5955 : loss : 0.017483, loss_ce: 0.005984
2022-01-09 15:35:45,637 iteration 5956 : loss : 0.030462, loss_ce: 0.012864
2022-01-09 15:35:48,029 iteration 5957 : loss : 0.019072, loss_ce: 0.005850
2022-01-09 15:35:50,501 iteration 5958 : loss : 0.014496, loss_ce: 0.006206
2022-01-09 15:35:52,864 iteration 5959 : loss : 0.014317, loss_ce: 0.004952
2022-01-09 15:35:55,224 iteration 5960 : loss : 0.010550, loss_ce: 0.003133
2022-01-09 15:35:57,611 iteration 5961 : loss : 0.014703, loss_ce: 0.005737
2022-01-09 15:36:00,111 iteration 5962 : loss : 0.016432, loss_ce: 0.006998
2022-01-09 15:36:02,441 iteration 5963 : loss : 0.012278, loss_ce: 0.005210
2022-01-09 15:36:04,999 iteration 5964 : loss : 0.033474, loss_ce: 0.012172
2022-01-09 15:36:07,378 iteration 5965 : loss : 0.015484, loss_ce: 0.005790
2022-01-09 15:36:09,778 iteration 5966 : loss : 0.020568, loss_ce: 0.008698
2022-01-09 15:36:12,143 iteration 5967 : loss : 0.022007, loss_ce: 0.007515
 88%|█████████████████████████▍   | 351/400 [4:11:51<36:23, 44.56s/it]2022-01-09 15:36:14,605 iteration 5968 : loss : 0.021468, loss_ce: 0.013839
2022-01-09 15:36:17,053 iteration 5969 : loss : 0.021948, loss_ce: 0.006443
2022-01-09 15:36:19,578 iteration 5970 : loss : 0.016276, loss_ce: 0.005731
2022-01-09 15:36:21,927 iteration 5971 : loss : 0.012097, loss_ce: 0.004840
2022-01-09 15:36:24,334 iteration 5972 : loss : 0.015045, loss_ce: 0.006209
2022-01-09 15:36:26,716 iteration 5973 : loss : 0.014373, loss_ce: 0.006641
2022-01-09 15:36:29,023 iteration 5974 : loss : 0.024881, loss_ce: 0.008303
2022-01-09 15:36:31,390 iteration 5975 : loss : 0.023227, loss_ce: 0.007434
2022-01-09 15:36:33,913 iteration 5976 : loss : 0.024598, loss_ce: 0.005792
2022-01-09 15:36:36,308 iteration 5977 : loss : 0.017388, loss_ce: 0.005994
2022-01-09 15:36:38,660 iteration 5978 : loss : 0.015644, loss_ce: 0.006511
2022-01-09 15:36:41,206 iteration 5979 : loss : 0.014436, loss_ce: 0.006295
2022-01-09 15:36:43,617 iteration 5980 : loss : 0.009617, loss_ce: 0.003141
2022-01-09 15:36:46,018 iteration 5981 : loss : 0.026559, loss_ce: 0.009719
2022-01-09 15:36:48,451 iteration 5982 : loss : 0.029861, loss_ce: 0.012077
2022-01-09 15:36:50,794 iteration 5983 : loss : 0.014291, loss_ce: 0.006819
2022-01-09 15:36:53,117 iteration 5984 : loss : 0.016916, loss_ce: 0.005679
 88%|█████████████████████████▌   | 352/400 [4:12:32<34:47, 43.49s/it]2022-01-09 15:36:55,639 iteration 5985 : loss : 0.030371, loss_ce: 0.012486
2022-01-09 15:36:57,944 iteration 5986 : loss : 0.015710, loss_ce: 0.006330
2022-01-09 15:37:00,276 iteration 5987 : loss : 0.040829, loss_ce: 0.005706
2022-01-09 15:37:02,688 iteration 5988 : loss : 0.017424, loss_ce: 0.008539
2022-01-09 15:37:05,086 iteration 5989 : loss : 0.016275, loss_ce: 0.006502
2022-01-09 15:37:07,460 iteration 5990 : loss : 0.018148, loss_ce: 0.010152
2022-01-09 15:37:09,921 iteration 5991 : loss : 0.011769, loss_ce: 0.004262
2022-01-09 15:37:12,406 iteration 5992 : loss : 0.014112, loss_ce: 0.004501
2022-01-09 15:37:14,818 iteration 5993 : loss : 0.009657, loss_ce: 0.003175
2022-01-09 15:37:17,209 iteration 5994 : loss : 0.023881, loss_ce: 0.008277
2022-01-09 15:37:19,598 iteration 5995 : loss : 0.017170, loss_ce: 0.006280
2022-01-09 15:37:22,000 iteration 5996 : loss : 0.024620, loss_ce: 0.006781
2022-01-09 15:37:24,374 iteration 5997 : loss : 0.017432, loss_ce: 0.007714
2022-01-09 15:37:26,741 iteration 5998 : loss : 0.020022, loss_ce: 0.006955
2022-01-09 15:37:29,154 iteration 5999 : loss : 0.025775, loss_ce: 0.007906
2022-01-09 15:37:31,557 iteration 6000 : loss : 0.020080, loss_ce: 0.009689
2022-01-09 15:37:34,079 iteration 6001 : loss : 0.020884, loss_ce: 0.006665
 88%|█████████████████████████▌   | 353/400 [4:13:13<33:28, 42.72s/it]2022-01-09 15:37:36,509 iteration 6002 : loss : 0.018840, loss_ce: 0.008186
2022-01-09 15:37:38,907 iteration 6003 : loss : 0.021506, loss_ce: 0.008651
2022-01-09 15:37:41,281 iteration 6004 : loss : 0.014891, loss_ce: 0.007211
2022-01-09 15:37:43,687 iteration 6005 : loss : 0.017404, loss_ce: 0.007074
2022-01-09 15:37:46,001 iteration 6006 : loss : 0.016534, loss_ce: 0.008721
2022-01-09 15:37:48,403 iteration 6007 : loss : 0.012228, loss_ce: 0.004606
2022-01-09 15:37:50,807 iteration 6008 : loss : 0.016574, loss_ce: 0.005749
2022-01-09 15:37:53,456 iteration 6009 : loss : 0.028550, loss_ce: 0.012652
2022-01-09 15:37:55,818 iteration 6010 : loss : 0.012381, loss_ce: 0.005167
2022-01-09 15:37:58,207 iteration 6011 : loss : 0.020004, loss_ce: 0.007714
2022-01-09 15:38:00,545 iteration 6012 : loss : 0.034374, loss_ce: 0.011749
2022-01-09 15:38:02,993 iteration 6013 : loss : 0.025074, loss_ce: 0.009095
2022-01-09 15:38:05,555 iteration 6014 : loss : 0.018788, loss_ce: 0.007284
2022-01-09 15:38:07,968 iteration 6015 : loss : 0.017780, loss_ce: 0.006111
2022-01-09 15:38:10,348 iteration 6016 : loss : 0.016051, loss_ce: 0.004624
2022-01-09 15:38:12,767 iteration 6017 : loss : 0.026474, loss_ce: 0.005885
2022-01-09 15:38:15,242 iteration 6018 : loss : 0.019032, loss_ce: 0.006775
 88%|█████████████████████████▋   | 354/400 [4:13:54<32:23, 42.26s/it]2022-01-09 15:38:17,878 iteration 6019 : loss : 0.024054, loss_ce: 0.008741
2022-01-09 15:38:20,310 iteration 6020 : loss : 0.016555, loss_ce: 0.006309
2022-01-09 15:38:22,677 iteration 6021 : loss : 0.013811, loss_ce: 0.005050
2022-01-09 15:38:25,074 iteration 6022 : loss : 0.016705, loss_ce: 0.006881
2022-01-09 15:38:27,438 iteration 6023 : loss : 0.014425, loss_ce: 0.005347
2022-01-09 15:38:29,863 iteration 6024 : loss : 0.032575, loss_ce: 0.013770
2022-01-09 15:38:32,261 iteration 6025 : loss : 0.032366, loss_ce: 0.013033
2022-01-09 15:38:34,685 iteration 6026 : loss : 0.020429, loss_ce: 0.007127
2022-01-09 15:38:37,092 iteration 6027 : loss : 0.016732, loss_ce: 0.006367
2022-01-09 15:38:39,497 iteration 6028 : loss : 0.015579, loss_ce: 0.006419
2022-01-09 15:38:42,098 iteration 6029 : loss : 0.019532, loss_ce: 0.008899
2022-01-09 15:38:44,458 iteration 6030 : loss : 0.014219, loss_ce: 0.004735
2022-01-09 15:38:46,919 iteration 6031 : loss : 0.025706, loss_ce: 0.006708
2022-01-09 15:38:49,421 iteration 6032 : loss : 0.026054, loss_ce: 0.011169
2022-01-09 15:38:51,862 iteration 6033 : loss : 0.020806, loss_ce: 0.009239
2022-01-09 15:38:54,315 iteration 6034 : loss : 0.016729, loss_ce: 0.005395
2022-01-09 15:38:54,316 Training Data Eval:
2022-01-09 15:39:07,158   Average segmentation loss on training set: 0.0094
2022-01-09 15:39:07,158 Validation Data Eval:
2022-01-09 15:39:11,703   Average segmentation loss on validation set: 0.0589
2022-01-09 15:39:14,203 iteration 6035 : loss : 0.015727, loss_ce: 0.003900
 89%|█████████████████████████▋   | 355/400 [4:14:53<35:27, 47.27s/it]2022-01-09 15:39:16,652 iteration 6036 : loss : 0.023645, loss_ce: 0.008160
2022-01-09 15:39:19,126 iteration 6037 : loss : 0.018620, loss_ce: 0.006520
2022-01-09 15:39:21,613 iteration 6038 : loss : 0.020002, loss_ce: 0.008822
2022-01-09 15:39:23,997 iteration 6039 : loss : 0.018278, loss_ce: 0.008974
2022-01-09 15:39:26,405 iteration 6040 : loss : 0.020282, loss_ce: 0.008896
2022-01-09 15:39:28,892 iteration 6041 : loss : 0.029152, loss_ce: 0.010013
2022-01-09 15:39:31,340 iteration 6042 : loss : 0.021492, loss_ce: 0.009227
2022-01-09 15:39:33,715 iteration 6043 : loss : 0.014224, loss_ce: 0.006358
2022-01-09 15:39:36,117 iteration 6044 : loss : 0.014201, loss_ce: 0.004943
2022-01-09 15:39:38,542 iteration 6045 : loss : 0.018245, loss_ce: 0.005220
2022-01-09 15:39:41,114 iteration 6046 : loss : 0.017747, loss_ce: 0.005187
2022-01-09 15:39:43,457 iteration 6047 : loss : 0.018092, loss_ce: 0.004906
2022-01-09 15:39:45,966 iteration 6048 : loss : 0.030086, loss_ce: 0.006159
2022-01-09 15:39:48,532 iteration 6049 : loss : 0.018143, loss_ce: 0.008115
2022-01-09 15:39:50,879 iteration 6050 : loss : 0.013584, loss_ce: 0.005794
2022-01-09 15:39:53,347 iteration 6051 : loss : 0.023170, loss_ce: 0.008374
2022-01-09 15:39:55,635 iteration 6052 : loss : 0.013600, loss_ce: 0.003648
 89%|█████████████████████████▊   | 356/400 [4:15:34<33:22, 45.52s/it]2022-01-09 15:39:57,982 iteration 6053 : loss : 0.014395, loss_ce: 0.007175
2022-01-09 15:40:00,505 iteration 6054 : loss : 0.021630, loss_ce: 0.008684
2022-01-09 15:40:02,930 iteration 6055 : loss : 0.014151, loss_ce: 0.004851
2022-01-09 15:40:05,407 iteration 6056 : loss : 0.014655, loss_ce: 0.005131
2022-01-09 15:40:07,778 iteration 6057 : loss : 0.016764, loss_ce: 0.005382
2022-01-09 15:40:10,168 iteration 6058 : loss : 0.020836, loss_ce: 0.008366
2022-01-09 15:40:12,480 iteration 6059 : loss : 0.012820, loss_ce: 0.005086
2022-01-09 15:40:14,831 iteration 6060 : loss : 0.012863, loss_ce: 0.005773
2022-01-09 15:40:17,191 iteration 6061 : loss : 0.030495, loss_ce: 0.013147
2022-01-09 15:40:19,655 iteration 6062 : loss : 0.015847, loss_ce: 0.008055
2022-01-09 15:40:22,069 iteration 6063 : loss : 0.025599, loss_ce: 0.008766
2022-01-09 15:40:24,458 iteration 6064 : loss : 0.021376, loss_ce: 0.005694
2022-01-09 15:40:26,914 iteration 6065 : loss : 0.018219, loss_ce: 0.009419
2022-01-09 15:40:29,247 iteration 6066 : loss : 0.014434, loss_ce: 0.005953
2022-01-09 15:40:31,578 iteration 6067 : loss : 0.032144, loss_ce: 0.004803
2022-01-09 15:40:34,045 iteration 6068 : loss : 0.026763, loss_ce: 0.009281
2022-01-09 15:40:36,436 iteration 6069 : loss : 0.052479, loss_ce: 0.004674
 89%|█████████████████████████▉   | 357/400 [4:16:15<31:36, 44.11s/it]2022-01-09 15:40:38,885 iteration 6070 : loss : 0.022908, loss_ce: 0.011267
2022-01-09 15:40:41,323 iteration 6071 : loss : 0.018044, loss_ce: 0.005491
2022-01-09 15:40:43,714 iteration 6072 : loss : 0.015996, loss_ce: 0.005386
2022-01-09 15:40:46,161 iteration 6073 : loss : 0.021850, loss_ce: 0.008085
2022-01-09 15:40:48,556 iteration 6074 : loss : 0.017955, loss_ce: 0.005087
2022-01-09 15:40:51,005 iteration 6075 : loss : 0.026439, loss_ce: 0.012819
2022-01-09 15:40:53,539 iteration 6076 : loss : 0.014745, loss_ce: 0.006102
2022-01-09 15:40:55,944 iteration 6077 : loss : 0.020272, loss_ce: 0.009002
2022-01-09 15:40:58,305 iteration 6078 : loss : 0.021990, loss_ce: 0.006635
2022-01-09 15:41:00,727 iteration 6079 : loss : 0.027908, loss_ce: 0.007164
2022-01-09 15:41:03,313 iteration 6080 : loss : 0.016402, loss_ce: 0.005297
2022-01-09 15:41:05,644 iteration 6081 : loss : 0.022854, loss_ce: 0.006154
2022-01-09 15:41:08,077 iteration 6082 : loss : 0.022139, loss_ce: 0.007574
2022-01-09 15:41:10,493 iteration 6083 : loss : 0.044546, loss_ce: 0.017450
2022-01-09 15:41:12,915 iteration 6084 : loss : 0.030489, loss_ce: 0.008398
2022-01-09 15:41:15,242 iteration 6085 : loss : 0.015475, loss_ce: 0.007641
2022-01-09 15:41:17,914 iteration 6086 : loss : 0.052766, loss_ce: 0.018518
 90%|█████████████████████████▉   | 358/400 [4:16:57<30:19, 43.31s/it]2022-01-09 15:41:20,339 iteration 6087 : loss : 0.026505, loss_ce: 0.008184
2022-01-09 15:41:22,685 iteration 6088 : loss : 0.018322, loss_ce: 0.006098
2022-01-09 15:41:25,139 iteration 6089 : loss : 0.017893, loss_ce: 0.007868
2022-01-09 15:41:27,498 iteration 6090 : loss : 0.018951, loss_ce: 0.005673
2022-01-09 15:41:30,014 iteration 6091 : loss : 0.018987, loss_ce: 0.006634
2022-01-09 15:41:32,643 iteration 6092 : loss : 0.023301, loss_ce: 0.009056
2022-01-09 15:41:35,119 iteration 6093 : loss : 0.022402, loss_ce: 0.010447
2022-01-09 15:41:37,515 iteration 6094 : loss : 0.021226, loss_ce: 0.011423
2022-01-09 15:41:39,899 iteration 6095 : loss : 0.017058, loss_ce: 0.004750
2022-01-09 15:41:42,532 iteration 6096 : loss : 0.026339, loss_ce: 0.005898
2022-01-09 15:41:44,891 iteration 6097 : loss : 0.015213, loss_ce: 0.007706
2022-01-09 15:41:47,431 iteration 6098 : loss : 0.014784, loss_ce: 0.007423
2022-01-09 15:41:49,806 iteration 6099 : loss : 0.016269, loss_ce: 0.007099
2022-01-09 15:41:52,176 iteration 6100 : loss : 0.017068, loss_ce: 0.005267
2022-01-09 15:41:54,597 iteration 6101 : loss : 0.033458, loss_ce: 0.017472
2022-01-09 15:41:57,099 iteration 6102 : loss : 0.016172, loss_ce: 0.007162
2022-01-09 15:41:59,492 iteration 6103 : loss : 0.020199, loss_ce: 0.006216
 90%|██████████████████████████   | 359/400 [4:17:38<29:14, 42.79s/it]2022-01-09 15:42:02,121 iteration 6104 : loss : 0.015172, loss_ce: 0.005992
2022-01-09 15:42:04,505 iteration 6105 : loss : 0.019379, loss_ce: 0.005364
2022-01-09 15:42:06,825 iteration 6106 : loss : 0.011317, loss_ce: 0.004660
2022-01-09 15:42:09,095 iteration 6107 : loss : 0.011831, loss_ce: 0.004816
2022-01-09 15:42:11,495 iteration 6108 : loss : 0.021011, loss_ce: 0.007006
2022-01-09 15:42:13,873 iteration 6109 : loss : 0.017523, loss_ce: 0.008086
2022-01-09 15:42:16,152 iteration 6110 : loss : 0.015108, loss_ce: 0.006959
2022-01-09 15:42:18,537 iteration 6111 : loss : 0.023059, loss_ce: 0.007996
2022-01-09 15:42:21,157 iteration 6112 : loss : 0.017643, loss_ce: 0.005763
2022-01-09 15:42:23,560 iteration 6113 : loss : 0.020851, loss_ce: 0.006550
2022-01-09 15:42:25,903 iteration 6114 : loss : 0.019390, loss_ce: 0.007172
2022-01-09 15:42:28,252 iteration 6115 : loss : 0.023382, loss_ce: 0.006342
2022-01-09 15:42:30,468 iteration 6116 : loss : 0.014843, loss_ce: 0.004726
2022-01-09 15:42:32,690 iteration 6117 : loss : 0.018846, loss_ce: 0.007618
2022-01-09 15:42:35,062 iteration 6118 : loss : 0.016926, loss_ce: 0.009494
2022-01-09 15:42:37,459 iteration 6119 : loss : 0.019652, loss_ce: 0.008658
2022-01-09 15:42:37,459 Training Data Eval:
2022-01-09 15:42:50,217   Average segmentation loss on training set: 0.0093
2022-01-09 15:42:50,218 Validation Data Eval:
2022-01-09 15:42:54,587   Average segmentation loss on validation set: 0.0671
2022-01-09 15:42:57,038 iteration 6120 : loss : 0.014299, loss_ce: 0.005437
 90%|██████████████████████████   | 360/400 [4:18:36<31:28, 47.22s/it]2022-01-09 15:42:59,467 iteration 6121 : loss : 0.025129, loss_ce: 0.008298
2022-01-09 15:43:01,852 iteration 6122 : loss : 0.017577, loss_ce: 0.006318
2022-01-09 15:43:04,174 iteration 6123 : loss : 0.014804, loss_ce: 0.005003
2022-01-09 15:43:06,537 iteration 6124 : loss : 0.020543, loss_ce: 0.006682
2022-01-09 15:43:08,828 iteration 6125 : loss : 0.016064, loss_ce: 0.004714
2022-01-09 15:43:11,283 iteration 6126 : loss : 0.027703, loss_ce: 0.011416
2022-01-09 15:43:13,764 iteration 6127 : loss : 0.019369, loss_ce: 0.009971
2022-01-09 15:43:16,177 iteration 6128 : loss : 0.013172, loss_ce: 0.004488
2022-01-09 15:43:18,508 iteration 6129 : loss : 0.014854, loss_ce: 0.005116
2022-01-09 15:43:20,936 iteration 6130 : loss : 0.023755, loss_ce: 0.010007
2022-01-09 15:43:23,232 iteration 6131 : loss : 0.019070, loss_ce: 0.005373
2022-01-09 15:43:25,573 iteration 6132 : loss : 0.017461, loss_ce: 0.005491
2022-01-09 15:43:27,855 iteration 6133 : loss : 0.018256, loss_ce: 0.007890
2022-01-09 15:43:30,230 iteration 6134 : loss : 0.013902, loss_ce: 0.004827
2022-01-09 15:43:32,585 iteration 6135 : loss : 0.015720, loss_ce: 0.007526
2022-01-09 15:43:34,915 iteration 6136 : loss : 0.011638, loss_ce: 0.003151
2022-01-09 15:43:37,217 iteration 6137 : loss : 0.016121, loss_ce: 0.005876
 90%|██████████████████████████▏  | 361/400 [4:19:16<29:19, 45.11s/it]2022-01-09 15:43:39,584 iteration 6138 : loss : 0.015598, loss_ce: 0.004957
2022-01-09 15:43:41,883 iteration 6139 : loss : 0.017657, loss_ce: 0.002867
2022-01-09 15:43:44,370 iteration 6140 : loss : 0.019615, loss_ce: 0.006244
2022-01-09 15:43:46,786 iteration 6141 : loss : 0.015093, loss_ce: 0.006751
2022-01-09 15:43:49,224 iteration 6142 : loss : 0.014076, loss_ce: 0.005789
2022-01-09 15:43:51,543 iteration 6143 : loss : 0.016787, loss_ce: 0.007690
2022-01-09 15:43:53,907 iteration 6144 : loss : 0.023617, loss_ce: 0.010757
2022-01-09 15:43:56,106 iteration 6145 : loss : 0.016282, loss_ce: 0.006225
2022-01-09 15:43:58,360 iteration 6146 : loss : 0.013472, loss_ce: 0.004104
2022-01-09 15:44:00,623 iteration 6147 : loss : 0.014096, loss_ce: 0.005535
2022-01-09 15:44:02,839 iteration 6148 : loss : 0.016050, loss_ce: 0.006416
2022-01-09 15:44:05,025 iteration 6149 : loss : 0.013922, loss_ce: 0.004707
2022-01-09 15:44:07,311 iteration 6150 : loss : 0.017803, loss_ce: 0.006063
2022-01-09 15:44:09,690 iteration 6151 : loss : 0.021905, loss_ce: 0.006061
2022-01-09 15:44:11,924 iteration 6152 : loss : 0.013798, loss_ce: 0.005680
2022-01-09 15:44:14,276 iteration 6153 : loss : 0.014660, loss_ce: 0.006004
2022-01-09 15:44:16,620 iteration 6154 : loss : 0.022662, loss_ce: 0.007633
 90%|██████████████████████████▏  | 362/400 [4:19:55<27:29, 43.39s/it]2022-01-09 15:44:18,996 iteration 6155 : loss : 0.019409, loss_ce: 0.008517
2022-01-09 15:44:21,249 iteration 6156 : loss : 0.011306, loss_ce: 0.004731
2022-01-09 15:44:23,570 iteration 6157 : loss : 0.011603, loss_ce: 0.003623
2022-01-09 15:44:25,850 iteration 6158 : loss : 0.013085, loss_ce: 0.004958
2022-01-09 15:44:28,079 iteration 6159 : loss : 0.016399, loss_ce: 0.005671
2022-01-09 15:44:30,331 iteration 6160 : loss : 0.014167, loss_ce: 0.005552
2022-01-09 15:44:32,599 iteration 6161 : loss : 0.016035, loss_ce: 0.004765
2022-01-09 15:44:34,893 iteration 6162 : loss : 0.021412, loss_ce: 0.004407
2022-01-09 15:44:37,201 iteration 6163 : loss : 0.016010, loss_ce: 0.006442
2022-01-09 15:44:39,538 iteration 6164 : loss : 0.023049, loss_ce: 0.009311
2022-01-09 15:44:41,760 iteration 6165 : loss : 0.019210, loss_ce: 0.006502
2022-01-09 15:44:44,003 iteration 6166 : loss : 0.013199, loss_ce: 0.006028
2022-01-09 15:44:46,267 iteration 6167 : loss : 0.015994, loss_ce: 0.006170
2022-01-09 15:44:48,650 iteration 6168 : loss : 0.019273, loss_ce: 0.007103
2022-01-09 15:44:51,085 iteration 6169 : loss : 0.016143, loss_ce: 0.005194
2022-01-09 15:44:53,433 iteration 6170 : loss : 0.017521, loss_ce: 0.006511
2022-01-09 15:44:55,736 iteration 6171 : loss : 0.013527, loss_ce: 0.005802
 91%|██████████████████████████▎  | 363/400 [4:20:34<25:58, 42.11s/it]2022-01-09 15:44:58,080 iteration 6172 : loss : 0.014337, loss_ce: 0.004874
2022-01-09 15:45:00,410 iteration 6173 : loss : 0.021587, loss_ce: 0.008220
2022-01-09 15:45:02,698 iteration 6174 : loss : 0.013395, loss_ce: 0.004746
2022-01-09 15:45:05,049 iteration 6175 : loss : 0.023342, loss_ce: 0.010470
2022-01-09 15:45:07,410 iteration 6176 : loss : 0.021298, loss_ce: 0.009590
2022-01-09 15:45:09,841 iteration 6177 : loss : 0.021624, loss_ce: 0.008702
2022-01-09 15:45:12,181 iteration 6178 : loss : 0.016730, loss_ce: 0.006783
2022-01-09 15:45:14,513 iteration 6179 : loss : 0.012829, loss_ce: 0.005747
2022-01-09 15:45:16,893 iteration 6180 : loss : 0.013688, loss_ce: 0.004795
2022-01-09 15:45:19,169 iteration 6181 : loss : 0.011176, loss_ce: 0.003650
2022-01-09 15:45:21,510 iteration 6182 : loss : 0.026515, loss_ce: 0.007064
2022-01-09 15:45:23,867 iteration 6183 : loss : 0.016095, loss_ce: 0.006460
2022-01-09 15:45:26,263 iteration 6184 : loss : 0.030472, loss_ce: 0.012521
2022-01-09 15:45:28,584 iteration 6185 : loss : 0.019444, loss_ce: 0.007285
2022-01-09 15:45:30,881 iteration 6186 : loss : 0.015461, loss_ce: 0.005314
2022-01-09 15:45:33,165 iteration 6187 : loss : 0.015820, loss_ce: 0.005599
2022-01-09 15:45:35,342 iteration 6188 : loss : 0.014666, loss_ce: 0.004998
 91%|██████████████████████████▍  | 364/400 [4:21:14<24:48, 41.36s/it]2022-01-09 15:45:37,610 iteration 6189 : loss : 0.011514, loss_ce: 0.003207
2022-01-09 15:45:39,850 iteration 6190 : loss : 0.016205, loss_ce: 0.005457
2022-01-09 15:45:42,318 iteration 6191 : loss : 0.025203, loss_ce: 0.008940
2022-01-09 15:45:44,746 iteration 6192 : loss : 0.012851, loss_ce: 0.004651
2022-01-09 15:45:47,007 iteration 6193 : loss : 0.010374, loss_ce: 0.003862
2022-01-09 15:45:49,328 iteration 6194 : loss : 0.017355, loss_ce: 0.006474
2022-01-09 15:45:51,620 iteration 6195 : loss : 0.019441, loss_ce: 0.007292
2022-01-09 15:45:53,906 iteration 6196 : loss : 0.012478, loss_ce: 0.005218
2022-01-09 15:45:56,130 iteration 6197 : loss : 0.017697, loss_ce: 0.008920
2022-01-09 15:45:58,453 iteration 6198 : loss : 0.013948, loss_ce: 0.004662
2022-01-09 15:46:00,865 iteration 6199 : loss : 0.018645, loss_ce: 0.004803
2022-01-09 15:46:03,157 iteration 6200 : loss : 0.012063, loss_ce: 0.005769
2022-01-09 15:46:05,601 iteration 6201 : loss : 0.023730, loss_ce: 0.007666
2022-01-09 15:46:07,926 iteration 6202 : loss : 0.012029, loss_ce: 0.004833
2022-01-09 15:46:10,230 iteration 6203 : loss : 0.013131, loss_ce: 0.003542
2022-01-09 15:46:12,585 iteration 6204 : loss : 0.014577, loss_ce: 0.006534
2022-01-09 15:46:12,585 Training Data Eval:
2022-01-09 15:46:25,069   Average segmentation loss on training set: 0.0090
2022-01-09 15:46:25,070 Validation Data Eval:
2022-01-09 15:46:29,479   Average segmentation loss on validation set: 0.0710
2022-01-09 15:46:31,832 iteration 6205 : loss : 0.018504, loss_ce: 0.005374
 91%|██████████████████████████▍  | 365/400 [4:22:11<26:46, 45.90s/it]2022-01-09 15:46:34,268 iteration 6206 : loss : 0.017792, loss_ce: 0.008175
2022-01-09 15:46:36,649 iteration 6207 : loss : 0.016928, loss_ce: 0.004893
2022-01-09 15:46:39,056 iteration 6208 : loss : 0.027663, loss_ce: 0.009480
2022-01-09 15:46:41,316 iteration 6209 : loss : 0.021270, loss_ce: 0.005836
2022-01-09 15:46:43,508 iteration 6210 : loss : 0.014414, loss_ce: 0.005213
2022-01-09 15:46:45,783 iteration 6211 : loss : 0.018411, loss_ce: 0.007341
2022-01-09 15:46:48,010 iteration 6212 : loss : 0.014774, loss_ce: 0.005016
2022-01-09 15:46:50,274 iteration 6213 : loss : 0.017736, loss_ce: 0.004568
2022-01-09 15:46:52,571 iteration 6214 : loss : 0.018070, loss_ce: 0.003663
2022-01-09 15:46:54,920 iteration 6215 : loss : 0.018441, loss_ce: 0.009419
2022-01-09 15:46:57,218 iteration 6216 : loss : 0.020845, loss_ce: 0.007004
2022-01-09 15:46:59,506 iteration 6217 : loss : 0.013905, loss_ce: 0.004543
2022-01-09 15:47:01,911 iteration 6218 : loss : 0.013560, loss_ce: 0.006706
2022-01-09 15:47:04,214 iteration 6219 : loss : 0.015908, loss_ce: 0.006165
2022-01-09 15:47:06,487 iteration 6220 : loss : 0.017747, loss_ce: 0.005728
2022-01-09 15:47:08,772 iteration 6221 : loss : 0.017433, loss_ce: 0.007644
2022-01-09 15:47:10,979 iteration 6222 : loss : 0.016748, loss_ce: 0.008236
 92%|██████████████████████████▌  | 366/400 [4:22:50<24:51, 43.87s/it]2022-01-09 15:47:13,327 iteration 6223 : loss : 0.024263, loss_ce: 0.005138
2022-01-09 15:47:15,583 iteration 6224 : loss : 0.013990, loss_ce: 0.004190
2022-01-09 15:47:17,815 iteration 6225 : loss : 0.019477, loss_ce: 0.007880
2022-01-09 15:47:20,102 iteration 6226 : loss : 0.021814, loss_ce: 0.007673
2022-01-09 15:47:22,372 iteration 6227 : loss : 0.014516, loss_ce: 0.003278
2022-01-09 15:47:24,925 iteration 6228 : loss : 0.017191, loss_ce: 0.007543
2022-01-09 15:47:27,272 iteration 6229 : loss : 0.015307, loss_ce: 0.006349
2022-01-09 15:47:29,634 iteration 6230 : loss : 0.017893, loss_ce: 0.007432
2022-01-09 15:47:32,012 iteration 6231 : loss : 0.013605, loss_ce: 0.006178
2022-01-09 15:47:34,310 iteration 6232 : loss : 0.016215, loss_ce: 0.006902
2022-01-09 15:47:36,536 iteration 6233 : loss : 0.015798, loss_ce: 0.006807
2022-01-09 15:47:38,769 iteration 6234 : loss : 0.016928, loss_ce: 0.007141
2022-01-09 15:47:41,110 iteration 6235 : loss : 0.037714, loss_ce: 0.009767
2022-01-09 15:47:43,361 iteration 6236 : loss : 0.011068, loss_ce: 0.004298
2022-01-09 15:47:45,640 iteration 6237 : loss : 0.013034, loss_ce: 0.005443
2022-01-09 15:47:47,916 iteration 6238 : loss : 0.010425, loss_ce: 0.003634
2022-01-09 15:47:50,386 iteration 6239 : loss : 0.011667, loss_ce: 0.004775
 92%|██████████████████████████▌  | 367/400 [4:23:29<23:23, 42.53s/it]2022-01-09 15:47:52,842 iteration 6240 : loss : 0.018525, loss_ce: 0.007873
2022-01-09 15:47:55,178 iteration 6241 : loss : 0.021784, loss_ce: 0.010633
2022-01-09 15:47:57,585 iteration 6242 : loss : 0.015087, loss_ce: 0.005956
2022-01-09 15:48:00,037 iteration 6243 : loss : 0.012980, loss_ce: 0.004637
2022-01-09 15:48:02,364 iteration 6244 : loss : 0.014190, loss_ce: 0.003989
2022-01-09 15:48:04,671 iteration 6245 : loss : 0.015541, loss_ce: 0.006121
2022-01-09 15:48:06,928 iteration 6246 : loss : 0.013791, loss_ce: 0.005570
2022-01-09 15:48:09,227 iteration 6247 : loss : 0.020119, loss_ce: 0.005157
2022-01-09 15:48:11,605 iteration 6248 : loss : 0.016988, loss_ce: 0.007028
2022-01-09 15:48:13,922 iteration 6249 : loss : 0.016298, loss_ce: 0.005608
2022-01-09 15:48:16,272 iteration 6250 : loss : 0.016280, loss_ce: 0.006577
2022-01-09 15:48:18,658 iteration 6251 : loss : 0.014427, loss_ce: 0.004737
2022-01-09 15:48:21,029 iteration 6252 : loss : 0.038832, loss_ce: 0.009281
2022-01-09 15:48:23,322 iteration 6253 : loss : 0.014387, loss_ce: 0.004687
2022-01-09 15:48:25,567 iteration 6254 : loss : 0.013874, loss_ce: 0.005316
2022-01-09 15:48:27,951 iteration 6255 : loss : 0.014415, loss_ce: 0.004955
2022-01-09 15:48:30,323 iteration 6256 : loss : 0.013531, loss_ce: 0.004888
 92%|██████████████████████████▋  | 368/400 [4:24:09<22:16, 41.75s/it]2022-01-09 15:48:32,768 iteration 6257 : loss : 0.014766, loss_ce: 0.004317
2022-01-09 15:48:35,161 iteration 6258 : loss : 0.014090, loss_ce: 0.005048
2022-01-09 15:48:37,586 iteration 6259 : loss : 0.012928, loss_ce: 0.005285
2022-01-09 15:48:40,080 iteration 6260 : loss : 0.049767, loss_ce: 0.012239
2022-01-09 15:48:42,467 iteration 6261 : loss : 0.022667, loss_ce: 0.012685
2022-01-09 15:48:44,853 iteration 6262 : loss : 0.016780, loss_ce: 0.007585
2022-01-09 15:48:47,144 iteration 6263 : loss : 0.014721, loss_ce: 0.005082
2022-01-09 15:48:49,529 iteration 6264 : loss : 0.014742, loss_ce: 0.005969
2022-01-09 15:48:51,960 iteration 6265 : loss : 0.016825, loss_ce: 0.006746
2022-01-09 15:48:54,340 iteration 6266 : loss : 0.014664, loss_ce: 0.004979
2022-01-09 15:48:56,810 iteration 6267 : loss : 0.025193, loss_ce: 0.012106
2022-01-09 15:48:59,251 iteration 6268 : loss : 0.016270, loss_ce: 0.005553
2022-01-09 15:49:01,629 iteration 6269 : loss : 0.017089, loss_ce: 0.007369
2022-01-09 15:49:03,937 iteration 6270 : loss : 0.014459, loss_ce: 0.006309
2022-01-09 15:49:06,263 iteration 6271 : loss : 0.015785, loss_ce: 0.006709
2022-01-09 15:49:08,540 iteration 6272 : loss : 0.019252, loss_ce: 0.005416
2022-01-09 15:49:10,970 iteration 6273 : loss : 0.027567, loss_ce: 0.009916
 92%|██████████████████████████▊  | 369/400 [4:24:50<21:24, 41.42s/it]2022-01-09 15:49:13,525 iteration 6274 : loss : 0.016923, loss_ce: 0.006298
2022-01-09 15:49:15,909 iteration 6275 : loss : 0.022032, loss_ce: 0.006057
2022-01-09 15:49:18,212 iteration 6276 : loss : 0.025248, loss_ce: 0.010273
2022-01-09 15:49:20,627 iteration 6277 : loss : 0.015033, loss_ce: 0.006428
2022-01-09 15:49:23,058 iteration 6278 : loss : 0.025832, loss_ce: 0.009853
2022-01-09 15:49:25,457 iteration 6279 : loss : 0.018535, loss_ce: 0.006388
2022-01-09 15:49:27,773 iteration 6280 : loss : 0.012790, loss_ce: 0.004473
2022-01-09 15:49:30,204 iteration 6281 : loss : 0.024194, loss_ce: 0.007613
2022-01-09 15:49:32,602 iteration 6282 : loss : 0.014560, loss_ce: 0.006677
2022-01-09 15:49:35,034 iteration 6283 : loss : 0.056491, loss_ce: 0.035956
2022-01-09 15:49:37,422 iteration 6284 : loss : 0.012252, loss_ce: 0.003989
2022-01-09 15:49:40,022 iteration 6285 : loss : 0.019729, loss_ce: 0.009912
2022-01-09 15:49:42,486 iteration 6286 : loss : 0.017296, loss_ce: 0.008059
2022-01-09 15:49:44,864 iteration 6287 : loss : 0.013153, loss_ce: 0.004791
2022-01-09 15:49:47,437 iteration 6288 : loss : 0.015613, loss_ce: 0.005803
2022-01-09 15:49:49,852 iteration 6289 : loss : 0.014598, loss_ce: 0.006148
2022-01-09 15:49:49,853 Training Data Eval:
2022-01-09 15:50:02,986   Average segmentation loss on training set: 0.0088
2022-01-09 15:50:02,986 Validation Data Eval:
2022-01-09 15:50:07,489   Average segmentation loss on validation set: 0.0623
2022-01-09 15:50:09,879 iteration 6290 : loss : 0.013927, loss_ce: 0.004961
 92%|██████████████████████████▊  | 370/400 [4:25:49<23:20, 46.67s/it]2022-01-09 15:50:12,290 iteration 6291 : loss : 0.017134, loss_ce: 0.005457
2022-01-09 15:50:14,637 iteration 6292 : loss : 0.015171, loss_ce: 0.004301
2022-01-09 15:50:17,059 iteration 6293 : loss : 0.014874, loss_ce: 0.003690
2022-01-09 15:50:19,667 iteration 6294 : loss : 0.016311, loss_ce: 0.005026
2022-01-09 15:50:22,034 iteration 6295 : loss : 0.019578, loss_ce: 0.006446
2022-01-09 15:50:24,343 iteration 6296 : loss : 0.013248, loss_ce: 0.005199
2022-01-09 15:50:26,810 iteration 6297 : loss : 0.017745, loss_ce: 0.007899
2022-01-09 15:50:29,172 iteration 6298 : loss : 0.017578, loss_ce: 0.008527
2022-01-09 15:50:31,497 iteration 6299 : loss : 0.015055, loss_ce: 0.006066
2022-01-09 15:50:33,909 iteration 6300 : loss : 0.014619, loss_ce: 0.003930
2022-01-09 15:50:36,308 iteration 6301 : loss : 0.014598, loss_ce: 0.006965
2022-01-09 15:50:38,792 iteration 6302 : loss : 0.022869, loss_ce: 0.011208
2022-01-09 15:50:41,131 iteration 6303 : loss : 0.012617, loss_ce: 0.004934
2022-01-09 15:50:43,565 iteration 6304 : loss : 0.017953, loss_ce: 0.007624
2022-01-09 15:50:45,985 iteration 6305 : loss : 0.012954, loss_ce: 0.004330
2022-01-09 15:50:48,519 iteration 6306 : loss : 0.013785, loss_ce: 0.006453
2022-01-09 15:50:50,901 iteration 6307 : loss : 0.012526, loss_ce: 0.004021
 93%|██████████████████████████▉  | 371/400 [4:26:30<21:44, 44.98s/it]2022-01-09 15:50:53,344 iteration 6308 : loss : 0.014780, loss_ce: 0.005957
2022-01-09 15:50:55,690 iteration 6309 : loss : 0.018428, loss_ce: 0.004549
2022-01-09 15:50:58,055 iteration 6310 : loss : 0.017338, loss_ce: 0.006578
2022-01-09 15:51:00,454 iteration 6311 : loss : 0.027580, loss_ce: 0.011968
2022-01-09 15:51:03,007 iteration 6312 : loss : 0.013272, loss_ce: 0.005834
2022-01-09 15:51:05,396 iteration 6313 : loss : 0.018888, loss_ce: 0.005098
2022-01-09 15:51:07,736 iteration 6314 : loss : 0.013831, loss_ce: 0.004933
2022-01-09 15:51:10,057 iteration 6315 : loss : 0.028005, loss_ce: 0.010784
2022-01-09 15:51:12,511 iteration 6316 : loss : 0.012527, loss_ce: 0.003601
2022-01-09 15:51:14,838 iteration 6317 : loss : 0.017885, loss_ce: 0.005873
2022-01-09 15:51:17,211 iteration 6318 : loss : 0.020315, loss_ce: 0.007430
2022-01-09 15:51:19,691 iteration 6319 : loss : 0.022935, loss_ce: 0.009918
2022-01-09 15:51:22,096 iteration 6320 : loss : 0.014101, loss_ce: 0.006087
2022-01-09 15:51:24,453 iteration 6321 : loss : 0.020237, loss_ce: 0.008580
2022-01-09 15:51:27,010 iteration 6322 : loss : 0.021619, loss_ce: 0.008189
2022-01-09 15:51:29,471 iteration 6323 : loss : 0.024970, loss_ce: 0.008108
2022-01-09 15:51:31,797 iteration 6324 : loss : 0.014610, loss_ce: 0.006024
 93%|██████████████████████████▉  | 372/400 [4:27:10<20:25, 43.75s/it]2022-01-09 15:51:34,149 iteration 6325 : loss : 0.014044, loss_ce: 0.006774
2022-01-09 15:51:36,476 iteration 6326 : loss : 0.010097, loss_ce: 0.003958
2022-01-09 15:51:38,888 iteration 6327 : loss : 0.015667, loss_ce: 0.006644
2022-01-09 15:51:41,480 iteration 6328 : loss : 0.012270, loss_ce: 0.003443
2022-01-09 15:51:43,830 iteration 6329 : loss : 0.013503, loss_ce: 0.003737
2022-01-09 15:51:46,231 iteration 6330 : loss : 0.012455, loss_ce: 0.003837
2022-01-09 15:51:48,757 iteration 6331 : loss : 0.023299, loss_ce: 0.008226
2022-01-09 15:51:51,234 iteration 6332 : loss : 0.018456, loss_ce: 0.007668
2022-01-09 15:51:53,634 iteration 6333 : loss : 0.013048, loss_ce: 0.004241
2022-01-09 15:51:56,062 iteration 6334 : loss : 0.015174, loss_ce: 0.007356
2022-01-09 15:51:58,526 iteration 6335 : loss : 0.017169, loss_ce: 0.006532
2022-01-09 15:52:00,867 iteration 6336 : loss : 0.009601, loss_ce: 0.003521
2022-01-09 15:52:03,253 iteration 6337 : loss : 0.014565, loss_ce: 0.005500
2022-01-09 15:52:05,860 iteration 6338 : loss : 0.021191, loss_ce: 0.003946
2022-01-09 15:52:08,281 iteration 6339 : loss : 0.017710, loss_ce: 0.007627
2022-01-09 15:52:10,622 iteration 6340 : loss : 0.011943, loss_ce: 0.005961
2022-01-09 15:52:12,992 iteration 6341 : loss : 0.012855, loss_ce: 0.004230
 93%|███████████████████████████  | 373/400 [4:27:52<19:20, 42.98s/it]2022-01-09 15:52:15,407 iteration 6342 : loss : 0.023449, loss_ce: 0.007888
2022-01-09 15:52:17,795 iteration 6343 : loss : 0.018173, loss_ce: 0.005206
2022-01-09 15:52:20,308 iteration 6344 : loss : 0.026536, loss_ce: 0.011857
2022-01-09 15:52:22,885 iteration 6345 : loss : 0.014100, loss_ce: 0.003857
2022-01-09 15:52:25,253 iteration 6346 : loss : 0.016051, loss_ce: 0.006716
2022-01-09 15:52:27,674 iteration 6347 : loss : 0.021786, loss_ce: 0.011917
2022-01-09 15:52:30,049 iteration 6348 : loss : 0.014417, loss_ce: 0.006120
2022-01-09 15:52:32,417 iteration 6349 : loss : 0.014184, loss_ce: 0.004587
2022-01-09 15:52:34,943 iteration 6350 : loss : 0.013018, loss_ce: 0.004775
2022-01-09 15:52:37,369 iteration 6351 : loss : 0.017573, loss_ce: 0.007648
2022-01-09 15:52:39,769 iteration 6352 : loss : 0.015818, loss_ce: 0.005457
2022-01-09 15:52:42,219 iteration 6353 : loss : 0.030878, loss_ce: 0.009282
2022-01-09 15:52:44,719 iteration 6354 : loss : 0.016384, loss_ce: 0.003774
2022-01-09 15:52:47,168 iteration 6355 : loss : 0.016370, loss_ce: 0.005563
2022-01-09 15:52:49,776 iteration 6356 : loss : 0.019250, loss_ce: 0.006941
2022-01-09 15:52:52,195 iteration 6357 : loss : 0.013102, loss_ce: 0.006511
2022-01-09 15:52:54,673 iteration 6358 : loss : 0.017735, loss_ce: 0.005500
 94%|███████████████████████████  | 374/400 [4:28:33<18:27, 42.59s/it]2022-01-09 15:52:57,229 iteration 6359 : loss : 0.016464, loss_ce: 0.005850
2022-01-09 15:52:59,583 iteration 6360 : loss : 0.009697, loss_ce: 0.003487
2022-01-09 15:53:02,026 iteration 6361 : loss : 0.019105, loss_ce: 0.007057
2022-01-09 15:53:04,470 iteration 6362 : loss : 0.012694, loss_ce: 0.004878
2022-01-09 15:53:06,940 iteration 6363 : loss : 0.036510, loss_ce: 0.010224
2022-01-09 15:53:09,396 iteration 6364 : loss : 0.012502, loss_ce: 0.003161
2022-01-09 15:53:11,833 iteration 6365 : loss : 0.021815, loss_ce: 0.008812
2022-01-09 15:53:14,235 iteration 6366 : loss : 0.012619, loss_ce: 0.004204
2022-01-09 15:53:16,691 iteration 6367 : loss : 0.030806, loss_ce: 0.011767
2022-01-09 15:53:19,101 iteration 6368 : loss : 0.021119, loss_ce: 0.005519
2022-01-09 15:53:21,476 iteration 6369 : loss : 0.021153, loss_ce: 0.004623
2022-01-09 15:53:23,964 iteration 6370 : loss : 0.014935, loss_ce: 0.006658
2022-01-09 15:53:26,325 iteration 6371 : loss : 0.013512, loss_ce: 0.006007
2022-01-09 15:53:28,679 iteration 6372 : loss : 0.018825, loss_ce: 0.006799
2022-01-09 15:53:30,926 iteration 6373 : loss : 0.012706, loss_ce: 0.005825
2022-01-09 15:53:33,173 iteration 6374 : loss : 0.011587, loss_ce: 0.004351
2022-01-09 15:53:33,173 Training Data Eval:
2022-01-09 15:53:45,881   Average segmentation loss on training set: 0.0090
2022-01-09 15:53:45,881 Validation Data Eval:
2022-01-09 15:53:50,423   Average segmentation loss on validation set: 0.0618
2022-01-09 15:53:52,825 iteration 6375 : loss : 0.015624, loss_ce: 0.008703
 94%|███████████████████████████▏ | 375/400 [4:29:32<19:41, 47.26s/it]2022-01-09 15:53:55,230 iteration 6376 : loss : 0.017664, loss_ce: 0.006029
2022-01-09 15:53:57,585 iteration 6377 : loss : 0.017547, loss_ce: 0.004332
2022-01-09 15:53:59,858 iteration 6378 : loss : 0.015090, loss_ce: 0.007079
2022-01-09 15:54:02,277 iteration 6379 : loss : 0.019044, loss_ce: 0.007754
2022-01-09 15:54:04,703 iteration 6380 : loss : 0.017885, loss_ce: 0.005861
2022-01-09 15:54:07,052 iteration 6381 : loss : 0.022352, loss_ce: 0.010585
2022-01-09 15:54:09,364 iteration 6382 : loss : 0.015950, loss_ce: 0.008344
2022-01-09 15:54:11,813 iteration 6383 : loss : 0.016917, loss_ce: 0.005827
2022-01-09 15:54:14,249 iteration 6384 : loss : 0.017318, loss_ce: 0.006681
2022-01-09 15:54:16,532 iteration 6385 : loss : 0.009650, loss_ce: 0.003785
2022-01-09 15:54:18,948 iteration 6386 : loss : 0.017366, loss_ce: 0.005611
2022-01-09 15:54:21,392 iteration 6387 : loss : 0.018592, loss_ce: 0.009380
2022-01-09 15:54:23,890 iteration 6388 : loss : 0.010934, loss_ce: 0.005162
2022-01-09 15:54:26,342 iteration 6389 : loss : 0.017531, loss_ce: 0.007024
2022-01-09 15:54:28,742 iteration 6390 : loss : 0.018889, loss_ce: 0.005539
2022-01-09 15:54:31,171 iteration 6391 : loss : 0.019589, loss_ce: 0.008066
2022-01-09 15:54:33,600 iteration 6392 : loss : 0.017536, loss_ce: 0.003828
 94%|███████████████████████████▎ | 376/400 [4:30:12<18:07, 45.31s/it]2022-01-09 15:54:35,943 iteration 6393 : loss : 0.011416, loss_ce: 0.005428
2022-01-09 15:54:38,194 iteration 6394 : loss : 0.011872, loss_ce: 0.005136
2022-01-09 15:54:40,475 iteration 6395 : loss : 0.010325, loss_ce: 0.003214
2022-01-09 15:54:42,981 iteration 6396 : loss : 0.015819, loss_ce: 0.006254
2022-01-09 15:54:45,436 iteration 6397 : loss : 0.020227, loss_ce: 0.006045
2022-01-09 15:54:47,865 iteration 6398 : loss : 0.017691, loss_ce: 0.007023
2022-01-09 15:54:50,254 iteration 6399 : loss : 0.018216, loss_ce: 0.005556
2022-01-09 15:54:52,601 iteration 6400 : loss : 0.016394, loss_ce: 0.005841
2022-01-09 15:54:54,934 iteration 6401 : loss : 0.010010, loss_ce: 0.003441
2022-01-09 15:54:57,303 iteration 6402 : loss : 0.016939, loss_ce: 0.007266
2022-01-09 15:54:59,562 iteration 6403 : loss : 0.016555, loss_ce: 0.006266
2022-01-09 15:55:01,830 iteration 6404 : loss : 0.011749, loss_ce: 0.005965
2022-01-09 15:55:04,225 iteration 6405 : loss : 0.024873, loss_ce: 0.010593
2022-01-09 15:55:06,502 iteration 6406 : loss : 0.011463, loss_ce: 0.004644
2022-01-09 15:55:08,893 iteration 6407 : loss : 0.021139, loss_ce: 0.009047
2022-01-09 15:55:11,236 iteration 6408 : loss : 0.012625, loss_ce: 0.003918
2022-01-09 15:55:13,514 iteration 6409 : loss : 0.011606, loss_ce: 0.003952
 94%|███████████████████████████▎ | 377/400 [4:30:52<16:45, 43.70s/it]2022-01-09 15:55:15,796 iteration 6410 : loss : 0.015124, loss_ce: 0.006030
2022-01-09 15:55:18,175 iteration 6411 : loss : 0.018434, loss_ce: 0.006767
2022-01-09 15:55:20,605 iteration 6412 : loss : 0.014271, loss_ce: 0.004334
2022-01-09 15:55:22,950 iteration 6413 : loss : 0.018758, loss_ce: 0.007994
2022-01-09 15:55:25,365 iteration 6414 : loss : 0.020661, loss_ce: 0.008065
2022-01-09 15:55:27,741 iteration 6415 : loss : 0.013958, loss_ce: 0.004492
2022-01-09 15:55:29,973 iteration 6416 : loss : 0.017884, loss_ce: 0.006390
2022-01-09 15:55:32,222 iteration 6417 : loss : 0.019641, loss_ce: 0.006066
2022-01-09 15:55:34,512 iteration 6418 : loss : 0.034946, loss_ce: 0.013915
2022-01-09 15:55:36,883 iteration 6419 : loss : 0.016378, loss_ce: 0.006577
2022-01-09 15:55:39,314 iteration 6420 : loss : 0.019266, loss_ce: 0.007338
2022-01-09 15:55:41,732 iteration 6421 : loss : 0.014708, loss_ce: 0.006531
2022-01-09 15:55:44,050 iteration 6422 : loss : 0.013753, loss_ce: 0.005105
2022-01-09 15:55:46,357 iteration 6423 : loss : 0.018984, loss_ce: 0.006543
2022-01-09 15:55:48,638 iteration 6424 : loss : 0.013042, loss_ce: 0.004201
2022-01-09 15:55:51,018 iteration 6425 : loss : 0.021683, loss_ce: 0.007919
2022-01-09 15:55:53,445 iteration 6426 : loss : 0.014302, loss_ce: 0.004640
 94%|███████████████████████████▍ | 378/400 [4:31:32<15:36, 42.57s/it]2022-01-09 15:55:55,880 iteration 6427 : loss : 0.017812, loss_ce: 0.007698
2022-01-09 15:55:58,256 iteration 6428 : loss : 0.018499, loss_ce: 0.006471
2022-01-09 15:56:00,502 iteration 6429 : loss : 0.013594, loss_ce: 0.005712
2022-01-09 15:56:02,816 iteration 6430 : loss : 0.015721, loss_ce: 0.007419
2022-01-09 15:56:05,103 iteration 6431 : loss : 0.020069, loss_ce: 0.005491
2022-01-09 15:56:07,432 iteration 6432 : loss : 0.016056, loss_ce: 0.005803
2022-01-09 15:56:09,731 iteration 6433 : loss : 0.013339, loss_ce: 0.003769
2022-01-09 15:56:12,062 iteration 6434 : loss : 0.028753, loss_ce: 0.011136
2022-01-09 15:56:14,525 iteration 6435 : loss : 0.010178, loss_ce: 0.003404
2022-01-09 15:56:16,876 iteration 6436 : loss : 0.014176, loss_ce: 0.006936
2022-01-09 15:56:19,174 iteration 6437 : loss : 0.014651, loss_ce: 0.005724
2022-01-09 15:56:21,426 iteration 6438 : loss : 0.013417, loss_ce: 0.007222
2022-01-09 15:56:23,818 iteration 6439 : loss : 0.022895, loss_ce: 0.007435
2022-01-09 15:56:26,194 iteration 6440 : loss : 0.012365, loss_ce: 0.004500
2022-01-09 15:56:28,550 iteration 6441 : loss : 0.012108, loss_ce: 0.004970
2022-01-09 15:56:30,915 iteration 6442 : loss : 0.012569, loss_ce: 0.005728
2022-01-09 15:56:33,215 iteration 6443 : loss : 0.015890, loss_ce: 0.005898
 95%|███████████████████████████▍ | 379/400 [4:32:12<14:36, 41.73s/it]2022-01-09 15:56:35,509 iteration 6444 : loss : 0.016555, loss_ce: 0.008556
2022-01-09 15:56:37,706 iteration 6445 : loss : 0.011615, loss_ce: 0.004418
2022-01-09 15:56:39,898 iteration 6446 : loss : 0.016289, loss_ce: 0.006661
2022-01-09 15:56:42,068 iteration 6447 : loss : 0.012479, loss_ce: 0.005079
2022-01-09 15:56:44,250 iteration 6448 : loss : 0.013904, loss_ce: 0.003650
2022-01-09 15:56:46,575 iteration 6449 : loss : 0.017707, loss_ce: 0.006307
2022-01-09 15:56:49,000 iteration 6450 : loss : 0.035669, loss_ce: 0.009036
2022-01-09 15:56:51,326 iteration 6451 : loss : 0.017156, loss_ce: 0.006384
2022-01-09 15:56:53,693 iteration 6452 : loss : 0.018425, loss_ce: 0.004170
2022-01-09 15:56:56,004 iteration 6453 : loss : 0.013385, loss_ce: 0.005948
2022-01-09 15:56:58,372 iteration 6454 : loss : 0.014640, loss_ce: 0.004748
2022-01-09 15:57:00,657 iteration 6455 : loss : 0.013317, loss_ce: 0.005072
2022-01-09 15:57:03,041 iteration 6456 : loss : 0.015218, loss_ce: 0.007424
2022-01-09 15:57:05,422 iteration 6457 : loss : 0.011057, loss_ce: 0.004383
2022-01-09 15:57:07,744 iteration 6458 : loss : 0.025060, loss_ce: 0.020131
2022-01-09 15:57:10,126 iteration 6459 : loss : 0.020873, loss_ce: 0.008035
2022-01-09 15:57:10,126 Training Data Eval:
2022-01-09 15:57:22,860   Average segmentation loss on training set: 0.0086
2022-01-09 15:57:22,860 Validation Data Eval:
2022-01-09 15:57:27,274   Average segmentation loss on validation set: 0.0639
2022-01-09 15:57:29,682 iteration 6460 : loss : 0.016476, loss_ce: 0.005897
 95%|███████████████████████████▌ | 380/400 [4:33:08<15:22, 46.15s/it]2022-01-09 15:57:31,982 iteration 6461 : loss : 0.012450, loss_ce: 0.004606
2022-01-09 15:57:34,239 iteration 6462 : loss : 0.017631, loss_ce: 0.008787
2022-01-09 15:57:36,675 iteration 6463 : loss : 0.015278, loss_ce: 0.008203
2022-01-09 15:57:39,053 iteration 6464 : loss : 0.019887, loss_ce: 0.008575
2022-01-09 15:57:41,374 iteration 6465 : loss : 0.013706, loss_ce: 0.004561
2022-01-09 15:57:43,666 iteration 6466 : loss : 0.019657, loss_ce: 0.008036
2022-01-09 15:57:46,114 iteration 6467 : loss : 0.016129, loss_ce: 0.006335
2022-01-09 15:57:48,463 iteration 6468 : loss : 0.013152, loss_ce: 0.005198
2022-01-09 15:57:50,846 iteration 6469 : loss : 0.021736, loss_ce: 0.005900
2022-01-09 15:57:53,243 iteration 6470 : loss : 0.012022, loss_ce: 0.005242
2022-01-09 15:57:55,587 iteration 6471 : loss : 0.017179, loss_ce: 0.006640
2022-01-09 15:57:57,831 iteration 6472 : loss : 0.014854, loss_ce: 0.005496
2022-01-09 15:58:00,150 iteration 6473 : loss : 0.017708, loss_ce: 0.006629
2022-01-09 15:58:02,431 iteration 6474 : loss : 0.013841, loss_ce: 0.005920
2022-01-09 15:58:04,905 iteration 6475 : loss : 0.017774, loss_ce: 0.005370
2022-01-09 15:58:07,344 iteration 6476 : loss : 0.015501, loss_ce: 0.005605
2022-01-09 15:58:09,723 iteration 6477 : loss : 0.020295, loss_ce: 0.007848
 95%|███████████████████████████▌ | 381/400 [4:33:48<14:02, 44.32s/it]2022-01-09 15:58:12,057 iteration 6478 : loss : 0.012999, loss_ce: 0.005198
2022-01-09 15:58:14,392 iteration 6479 : loss : 0.018533, loss_ce: 0.005903
2022-01-09 15:58:16,657 iteration 6480 : loss : 0.011657, loss_ce: 0.004215
2022-01-09 15:58:19,084 iteration 6481 : loss : 0.029317, loss_ce: 0.011480
2022-01-09 15:58:21,403 iteration 6482 : loss : 0.017769, loss_ce: 0.006357
2022-01-09 15:58:23,827 iteration 6483 : loss : 0.017170, loss_ce: 0.008901
2022-01-09 15:58:26,109 iteration 6484 : loss : 0.013942, loss_ce: 0.004702
2022-01-09 15:58:28,398 iteration 6485 : loss : 0.012478, loss_ce: 0.003798
2022-01-09 15:58:30,627 iteration 6486 : loss : 0.021528, loss_ce: 0.007058
2022-01-09 15:58:32,918 iteration 6487 : loss : 0.015100, loss_ce: 0.006022
2022-01-09 15:58:35,290 iteration 6488 : loss : 0.012501, loss_ce: 0.004375
2022-01-09 15:58:37,628 iteration 6489 : loss : 0.024066, loss_ce: 0.007762
2022-01-09 15:58:39,907 iteration 6490 : loss : 0.016498, loss_ce: 0.005761
2022-01-09 15:58:42,257 iteration 6491 : loss : 0.015121, loss_ce: 0.007287
2022-01-09 15:58:44,615 iteration 6492 : loss : 0.013343, loss_ce: 0.007712
2022-01-09 15:58:46,967 iteration 6493 : loss : 0.015295, loss_ce: 0.005965
2022-01-09 15:58:49,316 iteration 6494 : loss : 0.014007, loss_ce: 0.005858
 96%|███████████████████████████▋ | 382/400 [4:34:28<12:52, 42.90s/it]2022-01-09 15:58:51,615 iteration 6495 : loss : 0.013847, loss_ce: 0.006265
2022-01-09 15:58:54,010 iteration 6496 : loss : 0.016170, loss_ce: 0.005684
2022-01-09 15:58:56,375 iteration 6497 : loss : 0.009876, loss_ce: 0.004817
2022-01-09 15:58:58,620 iteration 6498 : loss : 0.013758, loss_ce: 0.004018
2022-01-09 15:59:00,945 iteration 6499 : loss : 0.026973, loss_ce: 0.005596
2022-01-09 15:59:03,411 iteration 6500 : loss : 0.025048, loss_ce: 0.007861
2022-01-09 15:59:05,796 iteration 6501 : loss : 0.015686, loss_ce: 0.006736
2022-01-09 15:59:08,146 iteration 6502 : loss : 0.012748, loss_ce: 0.004119
2022-01-09 15:59:10,435 iteration 6503 : loss : 0.014187, loss_ce: 0.005235
2022-01-09 15:59:12,750 iteration 6504 : loss : 0.018602, loss_ce: 0.008606
2022-01-09 15:59:14,997 iteration 6505 : loss : 0.011149, loss_ce: 0.004218
2022-01-09 15:59:17,385 iteration 6506 : loss : 0.015656, loss_ce: 0.004328
2022-01-09 15:59:19,688 iteration 6507 : loss : 0.015866, loss_ce: 0.006819
2022-01-09 15:59:21,892 iteration 6508 : loss : 0.014017, loss_ce: 0.005429
2022-01-09 15:59:24,213 iteration 6509 : loss : 0.012259, loss_ce: 0.004206
2022-01-09 15:59:26,475 iteration 6510 : loss : 0.010281, loss_ce: 0.003867
2022-01-09 15:59:28,833 iteration 6511 : loss : 0.015304, loss_ce: 0.005547
 96%|███████████████████████████▊ | 383/400 [4:35:08<11:52, 41.88s/it]2022-01-09 15:59:31,272 iteration 6512 : loss : 0.019284, loss_ce: 0.006532
2022-01-09 15:59:33,646 iteration 6513 : loss : 0.015555, loss_ce: 0.005641
2022-01-09 15:59:36,068 iteration 6514 : loss : 0.019523, loss_ce: 0.005589
2022-01-09 15:59:38,507 iteration 6515 : loss : 0.017206, loss_ce: 0.005800
2022-01-09 15:59:40,886 iteration 6516 : loss : 0.010825, loss_ce: 0.004251
2022-01-09 15:59:43,214 iteration 6517 : loss : 0.015490, loss_ce: 0.007037
2022-01-09 15:59:45,638 iteration 6518 : loss : 0.020958, loss_ce: 0.007313
2022-01-09 15:59:48,070 iteration 6519 : loss : 0.026678, loss_ce: 0.013397
2022-01-09 15:59:50,409 iteration 6520 : loss : 0.026722, loss_ce: 0.017087
2022-01-09 15:59:52,812 iteration 6521 : loss : 0.016898, loss_ce: 0.007670
2022-01-09 15:59:55,153 iteration 6522 : loss : 0.016027, loss_ce: 0.005339
2022-01-09 15:59:57,472 iteration 6523 : loss : 0.016174, loss_ce: 0.007199
2022-01-09 15:59:59,761 iteration 6524 : loss : 0.014641, loss_ce: 0.005285
2022-01-09 16:00:02,151 iteration 6525 : loss : 0.023265, loss_ce: 0.007451
2022-01-09 16:00:04,523 iteration 6526 : loss : 0.015660, loss_ce: 0.005763
2022-01-09 16:00:06,906 iteration 6527 : loss : 0.014302, loss_ce: 0.004846
2022-01-09 16:00:09,273 iteration 6528 : loss : 0.013095, loss_ce: 0.005009
 96%|███████████████████████████▊ | 384/400 [4:35:48<11:03, 41.45s/it]2022-01-09 16:00:11,805 iteration 6529 : loss : 0.022219, loss_ce: 0.009466
2022-01-09 16:00:14,059 iteration 6530 : loss : 0.017425, loss_ce: 0.007678
2022-01-09 16:00:16,430 iteration 6531 : loss : 0.033620, loss_ce: 0.010844
2022-01-09 16:00:18,963 iteration 6532 : loss : 0.026851, loss_ce: 0.010814
2022-01-09 16:00:21,396 iteration 6533 : loss : 0.031586, loss_ce: 0.007051
2022-01-09 16:00:23,926 iteration 6534 : loss : 0.015722, loss_ce: 0.003794
2022-01-09 16:00:26,246 iteration 6535 : loss : 0.025996, loss_ce: 0.003660
2022-01-09 16:00:28,710 iteration 6536 : loss : 0.017153, loss_ce: 0.006523
2022-01-09 16:00:31,149 iteration 6537 : loss : 0.013012, loss_ce: 0.004679
2022-01-09 16:00:33,634 iteration 6538 : loss : 0.019390, loss_ce: 0.008974
2022-01-09 16:00:36,109 iteration 6539 : loss : 0.024404, loss_ce: 0.009811
2022-01-09 16:00:38,521 iteration 6540 : loss : 0.012583, loss_ce: 0.005645
2022-01-09 16:00:40,890 iteration 6541 : loss : 0.012885, loss_ce: 0.005433
2022-01-09 16:00:43,321 iteration 6542 : loss : 0.019469, loss_ce: 0.008461
2022-01-09 16:00:45,884 iteration 6543 : loss : 0.022460, loss_ce: 0.008437
2022-01-09 16:00:48,266 iteration 6544 : loss : 0.010259, loss_ce: 0.003360
2022-01-09 16:00:48,266 Training Data Eval:
2022-01-09 16:01:01,030   Average segmentation loss on training set: 0.0084
2022-01-09 16:01:01,030 Validation Data Eval:
2022-01-09 16:01:05,644   Average segmentation loss on validation set: 0.0624
2022-01-09 16:01:07,939 iteration 6545 : loss : 0.009482, loss_ce: 0.002114
 96%|███████████████████████████▉ | 385/400 [4:36:47<11:39, 46.62s/it]2022-01-09 16:01:10,376 iteration 6546 : loss : 0.021550, loss_ce: 0.007406
2022-01-09 16:01:12,812 iteration 6547 : loss : 0.024313, loss_ce: 0.010257
2022-01-09 16:01:15,026 iteration 6548 : loss : 0.014785, loss_ce: 0.008888
2022-01-09 16:01:17,357 iteration 6549 : loss : 0.008589, loss_ce: 0.002945
2022-01-09 16:01:19,767 iteration 6550 : loss : 0.011717, loss_ce: 0.004446
2022-01-09 16:01:22,175 iteration 6551 : loss : 0.020406, loss_ce: 0.008408
2022-01-09 16:01:24,658 iteration 6552 : loss : 0.012829, loss_ce: 0.005962
2022-01-09 16:01:27,096 iteration 6553 : loss : 0.031623, loss_ce: 0.012730
2022-01-09 16:01:29,704 iteration 6554 : loss : 0.013945, loss_ce: 0.004328
2022-01-09 16:01:32,142 iteration 6555 : loss : 0.018580, loss_ce: 0.006738
2022-01-09 16:01:34,525 iteration 6556 : loss : 0.015821, loss_ce: 0.004724
2022-01-09 16:01:36,846 iteration 6557 : loss : 0.013132, loss_ce: 0.004131
2022-01-09 16:01:39,176 iteration 6558 : loss : 0.019085, loss_ce: 0.005242
2022-01-09 16:01:41,611 iteration 6559 : loss : 0.017293, loss_ce: 0.007176
2022-01-09 16:01:44,036 iteration 6560 : loss : 0.039917, loss_ce: 0.007542
2022-01-09 16:01:46,366 iteration 6561 : loss : 0.014625, loss_ce: 0.006097
2022-01-09 16:01:48,668 iteration 6562 : loss : 0.008572, loss_ce: 0.002812
 96%|███████████████████████████▉ | 386/400 [4:37:27<10:27, 44.86s/it]2022-01-09 16:01:51,085 iteration 6563 : loss : 0.012862, loss_ce: 0.005771
2022-01-09 16:01:53,518 iteration 6564 : loss : 0.020214, loss_ce: 0.005970
2022-01-09 16:01:55,851 iteration 6565 : loss : 0.011320, loss_ce: 0.003078
2022-01-09 16:01:58,199 iteration 6566 : loss : 0.012033, loss_ce: 0.004618
2022-01-09 16:02:00,678 iteration 6567 : loss : 0.015481, loss_ce: 0.006482
2022-01-09 16:02:03,147 iteration 6568 : loss : 0.014134, loss_ce: 0.005667
2022-01-09 16:02:05,586 iteration 6569 : loss : 0.020816, loss_ce: 0.006663
2022-01-09 16:02:08,043 iteration 6570 : loss : 0.013553, loss_ce: 0.003797
2022-01-09 16:02:10,545 iteration 6571 : loss : 0.019277, loss_ce: 0.008701
2022-01-09 16:02:12,967 iteration 6572 : loss : 0.010850, loss_ce: 0.004486
2022-01-09 16:02:15,398 iteration 6573 : loss : 0.027470, loss_ce: 0.008768
2022-01-09 16:02:17,709 iteration 6574 : loss : 0.009623, loss_ce: 0.002881
2022-01-09 16:02:20,051 iteration 6575 : loss : 0.019537, loss_ce: 0.006580
2022-01-09 16:02:22,401 iteration 6576 : loss : 0.014282, loss_ce: 0.006390
2022-01-09 16:02:24,938 iteration 6577 : loss : 0.016233, loss_ce: 0.005474
2022-01-09 16:02:27,375 iteration 6578 : loss : 0.013860, loss_ce: 0.005259
2022-01-09 16:02:29,717 iteration 6579 : loss : 0.016227, loss_ce: 0.007045
 97%|████████████████████████████ | 387/400 [4:38:08<09:28, 43.71s/it]2022-01-09 16:02:32,220 iteration 6580 : loss : 0.019178, loss_ce: 0.008340
2022-01-09 16:02:34,612 iteration 6581 : loss : 0.011832, loss_ce: 0.003337
2022-01-09 16:02:37,068 iteration 6582 : loss : 0.020853, loss_ce: 0.006391
2022-01-09 16:02:39,448 iteration 6583 : loss : 0.030781, loss_ce: 0.008841
2022-01-09 16:02:41,973 iteration 6584 : loss : 0.015061, loss_ce: 0.006011
2022-01-09 16:02:44,301 iteration 6585 : loss : 0.011738, loss_ce: 0.003681
2022-01-09 16:02:46,795 iteration 6586 : loss : 0.018574, loss_ce: 0.003729
2022-01-09 16:02:49,158 iteration 6587 : loss : 0.012283, loss_ce: 0.005611
2022-01-09 16:02:51,598 iteration 6588 : loss : 0.011024, loss_ce: 0.004946
2022-01-09 16:02:53,990 iteration 6589 : loss : 0.013113, loss_ce: 0.005478
2022-01-09 16:02:56,368 iteration 6590 : loss : 0.013219, loss_ce: 0.005538
2022-01-09 16:02:58,875 iteration 6591 : loss : 0.009874, loss_ce: 0.003420
2022-01-09 16:03:01,315 iteration 6592 : loss : 0.015776, loss_ce: 0.008523
2022-01-09 16:03:03,565 iteration 6593 : loss : 0.010619, loss_ce: 0.005537
2022-01-09 16:03:06,103 iteration 6594 : loss : 0.009812, loss_ce: 0.003437
2022-01-09 16:03:08,544 iteration 6595 : loss : 0.021966, loss_ce: 0.007034
2022-01-09 16:03:10,869 iteration 6596 : loss : 0.011876, loss_ce: 0.003466
 97%|████████████████████████████▏| 388/400 [4:38:50<08:35, 42.95s/it]2022-01-09 16:03:13,355 iteration 6597 : loss : 0.013102, loss_ce: 0.006437
2022-01-09 16:03:15,855 iteration 6598 : loss : 0.020669, loss_ce: 0.003083
2022-01-09 16:03:18,286 iteration 6599 : loss : 0.017737, loss_ce: 0.007607
2022-01-09 16:03:20,625 iteration 6600 : loss : 0.012843, loss_ce: 0.005498
2022-01-09 16:03:23,088 iteration 6601 : loss : 0.021885, loss_ce: 0.009518
2022-01-09 16:03:25,441 iteration 6602 : loss : 0.022050, loss_ce: 0.009112
2022-01-09 16:03:27,904 iteration 6603 : loss : 0.013821, loss_ce: 0.006321
2022-01-09 16:03:30,517 iteration 6604 : loss : 0.013499, loss_ce: 0.006436
2022-01-09 16:03:32,873 iteration 6605 : loss : 0.015343, loss_ce: 0.008000
2022-01-09 16:03:35,248 iteration 6606 : loss : 0.020847, loss_ce: 0.007840
2022-01-09 16:03:37,774 iteration 6607 : loss : 0.018992, loss_ce: 0.007476
2022-01-09 16:03:40,127 iteration 6608 : loss : 0.016023, loss_ce: 0.006974
2022-01-09 16:03:42,511 iteration 6609 : loss : 0.019275, loss_ce: 0.008607
2022-01-09 16:03:44,793 iteration 6610 : loss : 0.011913, loss_ce: 0.004422
2022-01-09 16:03:47,104 iteration 6611 : loss : 0.011400, loss_ce: 0.002978
2022-01-09 16:03:49,640 iteration 6612 : loss : 0.012780, loss_ce: 0.003374
2022-01-09 16:03:52,055 iteration 6613 : loss : 0.018052, loss_ce: 0.006644
 97%|████████████████████████████▏| 389/400 [4:39:31<07:46, 42.42s/it]2022-01-09 16:03:54,416 iteration 6614 : loss : 0.008090, loss_ce: 0.002901
2022-01-09 16:03:56,913 iteration 6615 : loss : 0.009832, loss_ce: 0.003789
2022-01-09 16:03:59,357 iteration 6616 : loss : 0.017404, loss_ce: 0.004963
2022-01-09 16:04:01,706 iteration 6617 : loss : 0.017125, loss_ce: 0.006461
2022-01-09 16:04:04,153 iteration 6618 : loss : 0.018339, loss_ce: 0.007640
2022-01-09 16:04:06,688 iteration 6619 : loss : 0.017334, loss_ce: 0.006673
2022-01-09 16:04:09,068 iteration 6620 : loss : 0.015007, loss_ce: 0.004811
2022-01-09 16:04:11,489 iteration 6621 : loss : 0.017501, loss_ce: 0.005605
2022-01-09 16:04:13,842 iteration 6622 : loss : 0.013153, loss_ce: 0.005843
2022-01-09 16:04:16,197 iteration 6623 : loss : 0.015831, loss_ce: 0.005443
2022-01-09 16:04:18,561 iteration 6624 : loss : 0.014385, loss_ce: 0.005628
2022-01-09 16:04:20,953 iteration 6625 : loss : 0.037165, loss_ce: 0.013355
2022-01-09 16:04:23,349 iteration 6626 : loss : 0.017492, loss_ce: 0.007245
2022-01-09 16:04:25,759 iteration 6627 : loss : 0.029252, loss_ce: 0.010855
2022-01-09 16:04:28,120 iteration 6628 : loss : 0.018256, loss_ce: 0.007386
2022-01-09 16:04:30,530 iteration 6629 : loss : 0.018009, loss_ce: 0.004537
2022-01-09 16:04:30,530 Training Data Eval:
2022-01-09 16:04:43,474   Average segmentation loss on training set: 0.0082
2022-01-09 16:04:43,474 Validation Data Eval:
2022-01-09 16:04:47,974   Average segmentation loss on validation set: 0.0714
2022-01-09 16:04:50,378 iteration 6630 : loss : 0.014737, loss_ce: 0.005434
 98%|████████████████████████████▎| 390/400 [4:40:29<07:51, 47.18s/it]2022-01-09 16:04:52,827 iteration 6631 : loss : 0.020144, loss_ce: 0.006592
2022-01-09 16:04:55,164 iteration 6632 : loss : 0.015251, loss_ce: 0.008475
2022-01-09 16:04:57,543 iteration 6633 : loss : 0.017411, loss_ce: 0.004628
2022-01-09 16:04:59,926 iteration 6634 : loss : 0.018230, loss_ce: 0.006886
2022-01-09 16:05:02,318 iteration 6635 : loss : 0.012719, loss_ce: 0.005193
2022-01-09 16:05:04,728 iteration 6636 : loss : 0.010876, loss_ce: 0.005055
2022-01-09 16:05:07,231 iteration 6637 : loss : 0.015207, loss_ce: 0.005318
2022-01-09 16:05:09,692 iteration 6638 : loss : 0.044417, loss_ce: 0.007772
2022-01-09 16:05:12,331 iteration 6639 : loss : 0.020038, loss_ce: 0.007907
2022-01-09 16:05:14,728 iteration 6640 : loss : 0.021028, loss_ce: 0.006472
2022-01-09 16:05:17,079 iteration 6641 : loss : 0.013755, loss_ce: 0.004784
2022-01-09 16:05:19,387 iteration 6642 : loss : 0.018362, loss_ce: 0.008873
2022-01-09 16:05:21,707 iteration 6643 : loss : 0.015164, loss_ce: 0.005579
2022-01-09 16:05:24,235 iteration 6644 : loss : 0.022220, loss_ce: 0.008396
2022-01-09 16:05:26,583 iteration 6645 : loss : 0.012240, loss_ce: 0.005057
2022-01-09 16:05:29,065 iteration 6646 : loss : 0.025663, loss_ce: 0.007939
2022-01-09 16:05:31,430 iteration 6647 : loss : 0.014835, loss_ce: 0.005537
 98%|████████████████████████████▎| 391/400 [4:41:10<06:48, 45.35s/it]2022-01-09 16:05:33,861 iteration 6648 : loss : 0.016327, loss_ce: 0.003405
2022-01-09 16:05:36,272 iteration 6649 : loss : 0.015429, loss_ce: 0.004211
2022-01-09 16:05:38,746 iteration 6650 : loss : 0.022819, loss_ce: 0.007375
2022-01-09 16:05:41,230 iteration 6651 : loss : 0.032246, loss_ce: 0.013313
2022-01-09 16:05:43,629 iteration 6652 : loss : 0.016636, loss_ce: 0.007389
2022-01-09 16:05:45,939 iteration 6653 : loss : 0.010414, loss_ce: 0.004285
2022-01-09 16:05:48,366 iteration 6654 : loss : 0.015989, loss_ce: 0.004869
2022-01-09 16:05:50,836 iteration 6655 : loss : 0.024893, loss_ce: 0.009373
2022-01-09 16:05:53,275 iteration 6656 : loss : 0.017711, loss_ce: 0.007240
2022-01-09 16:05:55,674 iteration 6657 : loss : 0.012120, loss_ce: 0.003344
2022-01-09 16:05:58,232 iteration 6658 : loss : 0.012562, loss_ce: 0.004580
2022-01-09 16:06:00,700 iteration 6659 : loss : 0.017853, loss_ce: 0.007854
2022-01-09 16:06:03,134 iteration 6660 : loss : 0.019026, loss_ce: 0.008151
2022-01-09 16:06:05,604 iteration 6661 : loss : 0.013822, loss_ce: 0.005456
2022-01-09 16:06:08,025 iteration 6662 : loss : 0.017794, loss_ce: 0.004425
2022-01-09 16:06:10,514 iteration 6663 : loss : 0.017266, loss_ce: 0.006577
2022-01-09 16:06:13,128 iteration 6664 : loss : 0.019073, loss_ce: 0.009785
 98%|████████████████████████████▍| 392/400 [4:41:52<05:54, 44.26s/it]2022-01-09 16:06:15,608 iteration 6665 : loss : 0.017158, loss_ce: 0.005031
2022-01-09 16:06:18,099 iteration 6666 : loss : 0.036405, loss_ce: 0.010016
2022-01-09 16:06:20,484 iteration 6667 : loss : 0.016589, loss_ce: 0.003093
2022-01-09 16:06:22,821 iteration 6668 : loss : 0.013306, loss_ce: 0.006442
2022-01-09 16:06:25,333 iteration 6669 : loss : 0.014993, loss_ce: 0.005671
2022-01-09 16:06:27,697 iteration 6670 : loss : 0.014902, loss_ce: 0.006628
2022-01-09 16:06:30,072 iteration 6671 : loss : 0.025399, loss_ce: 0.009218
2022-01-09 16:06:32,452 iteration 6672 : loss : 0.018280, loss_ce: 0.005086
2022-01-09 16:06:34,736 iteration 6673 : loss : 0.018943, loss_ce: 0.004407
2022-01-09 16:06:37,152 iteration 6674 : loss : 0.016007, loss_ce: 0.007560
2022-01-09 16:06:39,602 iteration 6675 : loss : 0.019624, loss_ce: 0.009470
2022-01-09 16:06:41,913 iteration 6676 : loss : 0.014288, loss_ce: 0.005746
2022-01-09 16:06:44,167 iteration 6677 : loss : 0.012805, loss_ce: 0.004366
2022-01-09 16:06:46,501 iteration 6678 : loss : 0.014550, loss_ce: 0.006805
2022-01-09 16:06:48,927 iteration 6679 : loss : 0.020676, loss_ce: 0.009082
2022-01-09 16:06:51,285 iteration 6680 : loss : 0.010107, loss_ce: 0.003631
2022-01-09 16:06:53,585 iteration 6681 : loss : 0.011910, loss_ce: 0.004041
 98%|████████████████████████████▍| 393/400 [4:42:32<05:01, 43.12s/it]2022-01-09 16:06:56,033 iteration 6682 : loss : 0.017473, loss_ce: 0.008147
2022-01-09 16:06:58,336 iteration 6683 : loss : 0.011539, loss_ce: 0.004422
2022-01-09 16:07:00,709 iteration 6684 : loss : 0.012802, loss_ce: 0.005508
2022-01-09 16:07:03,039 iteration 6685 : loss : 0.017234, loss_ce: 0.005979
2022-01-09 16:07:05,483 iteration 6686 : loss : 0.014857, loss_ce: 0.006081
2022-01-09 16:07:07,813 iteration 6687 : loss : 0.017509, loss_ce: 0.006321
2022-01-09 16:07:10,193 iteration 6688 : loss : 0.014673, loss_ce: 0.005316
2022-01-09 16:07:12,601 iteration 6689 : loss : 0.009776, loss_ce: 0.002459
2022-01-09 16:07:14,973 iteration 6690 : loss : 0.008163, loss_ce: 0.002464
2022-01-09 16:07:17,418 iteration 6691 : loss : 0.014743, loss_ce: 0.004923
2022-01-09 16:07:19,724 iteration 6692 : loss : 0.016963, loss_ce: 0.006320
2022-01-09 16:07:22,227 iteration 6693 : loss : 0.016578, loss_ce: 0.005558
2022-01-09 16:07:24,618 iteration 6694 : loss : 0.023479, loss_ce: 0.008108
2022-01-09 16:07:26,950 iteration 6695 : loss : 0.014434, loss_ce: 0.004670
2022-01-09 16:07:29,333 iteration 6696 : loss : 0.011266, loss_ce: 0.004495
2022-01-09 16:07:31,735 iteration 6697 : loss : 0.012444, loss_ce: 0.004376
2022-01-09 16:07:34,153 iteration 6698 : loss : 0.028822, loss_ce: 0.009857
 98%|████████████████████████████▌| 394/400 [4:43:13<04:14, 42.35s/it]2022-01-09 16:07:36,529 iteration 6699 : loss : 0.014156, loss_ce: 0.004884
2022-01-09 16:07:39,106 iteration 6700 : loss : 0.017605, loss_ce: 0.005908
2022-01-09 16:07:41,469 iteration 6701 : loss : 0.011753, loss_ce: 0.004339
2022-01-09 16:07:43,740 iteration 6702 : loss : 0.010173, loss_ce: 0.004829
2022-01-09 16:07:46,035 iteration 6703 : loss : 0.012481, loss_ce: 0.003875
2022-01-09 16:07:48,362 iteration 6704 : loss : 0.021245, loss_ce: 0.011302
2022-01-09 16:07:50,646 iteration 6705 : loss : 0.015227, loss_ce: 0.007319
2022-01-09 16:07:53,050 iteration 6706 : loss : 0.015352, loss_ce: 0.005420
2022-01-09 16:07:55,361 iteration 6707 : loss : 0.010359, loss_ce: 0.003760
2022-01-09 16:07:57,691 iteration 6708 : loss : 0.015614, loss_ce: 0.005735
2022-01-09 16:07:59,987 iteration 6709 : loss : 0.016110, loss_ce: 0.006805
2022-01-09 16:08:02,282 iteration 6710 : loss : 0.025245, loss_ce: 0.005272
2022-01-09 16:08:04,685 iteration 6711 : loss : 0.018747, loss_ce: 0.005744
2022-01-09 16:08:07,122 iteration 6712 : loss : 0.019038, loss_ce: 0.008848
2022-01-09 16:08:09,443 iteration 6713 : loss : 0.013397, loss_ce: 0.004937
2022-01-09 16:08:11,959 iteration 6714 : loss : 0.013184, loss_ce: 0.004259
2022-01-09 16:08:11,959 Training Data Eval:
2022-01-09 16:08:24,636   Average segmentation loss on training set: 0.0084
2022-01-09 16:08:24,636 Validation Data Eval:
2022-01-09 16:08:29,047   Average segmentation loss on validation set: 0.0610
2022-01-09 16:08:31,451 iteration 6715 : loss : 0.013110, loss_ce: 0.005139
 99%|████████████████████████████▋| 395/400 [4:44:10<03:54, 46.83s/it]2022-01-09 16:08:33,865 iteration 6716 : loss : 0.013968, loss_ce: 0.006455
2022-01-09 16:08:36,178 iteration 6717 : loss : 0.012740, loss_ce: 0.005661
2022-01-09 16:08:38,546 iteration 6718 : loss : 0.014315, loss_ce: 0.005319
2022-01-09 16:08:40,913 iteration 6719 : loss : 0.018587, loss_ce: 0.007161
2022-01-09 16:08:43,446 iteration 6720 : loss : 0.011704, loss_ce: 0.003620
2022-01-09 16:08:45,810 iteration 6721 : loss : 0.013050, loss_ce: 0.004828
2022-01-09 16:08:48,223 iteration 6722 : loss : 0.021649, loss_ce: 0.008743
2022-01-09 16:08:50,540 iteration 6723 : loss : 0.011811, loss_ce: 0.003623
2022-01-09 16:08:52,902 iteration 6724 : loss : 0.021427, loss_ce: 0.006447
2022-01-09 16:08:55,330 iteration 6725 : loss : 0.013473, loss_ce: 0.005158
2022-01-09 16:08:57,752 iteration 6726 : loss : 0.016499, loss_ce: 0.007556
2022-01-09 16:09:00,142 iteration 6727 : loss : 0.021083, loss_ce: 0.007216
2022-01-09 16:09:02,394 iteration 6728 : loss : 0.015884, loss_ce: 0.005670
2022-01-09 16:09:04,700 iteration 6729 : loss : 0.018826, loss_ce: 0.005313
2022-01-09 16:09:07,064 iteration 6730 : loss : 0.013870, loss_ce: 0.006780
2022-01-09 16:09:09,431 iteration 6731 : loss : 0.013881, loss_ce: 0.005242
2022-01-09 16:09:11,753 iteration 6732 : loss : 0.014865, loss_ce: 0.005679
 99%|████████████████████████████▋| 396/400 [4:44:50<02:59, 44.88s/it]2022-01-09 16:09:14,055 iteration 6733 : loss : 0.011222, loss_ce: 0.004211
2022-01-09 16:09:16,400 iteration 6734 : loss : 0.016647, loss_ce: 0.005724
2022-01-09 16:09:18,598 iteration 6735 : loss : 0.010391, loss_ce: 0.003991
2022-01-09 16:09:20,887 iteration 6736 : loss : 0.023367, loss_ce: 0.012072
2022-01-09 16:09:23,180 iteration 6737 : loss : 0.019326, loss_ce: 0.006629
2022-01-09 16:09:25,472 iteration 6738 : loss : 0.012370, loss_ce: 0.003700
2022-01-09 16:09:27,843 iteration 6739 : loss : 0.014225, loss_ce: 0.005605
2022-01-09 16:09:30,207 iteration 6740 : loss : 0.011618, loss_ce: 0.005201
2022-01-09 16:09:32,498 iteration 6741 : loss : 0.012942, loss_ce: 0.005319
2022-01-09 16:09:34,869 iteration 6742 : loss : 0.012246, loss_ce: 0.003824
2022-01-09 16:09:37,267 iteration 6743 : loss : 0.014247, loss_ce: 0.006587
2022-01-09 16:09:39,586 iteration 6744 : loss : 0.016960, loss_ce: 0.007102
2022-01-09 16:09:41,882 iteration 6745 : loss : 0.012617, loss_ce: 0.004774
2022-01-09 16:09:44,463 iteration 6746 : loss : 0.014531, loss_ce: 0.005668
2022-01-09 16:09:46,895 iteration 6747 : loss : 0.016623, loss_ce: 0.004465
2022-01-09 16:09:49,232 iteration 6748 : loss : 0.014316, loss_ce: 0.004519
2022-01-09 16:09:51,558 iteration 6749 : loss : 0.013488, loss_ce: 0.005936
 99%|████████████████████████████▊| 397/400 [4:45:30<02:10, 43.35s/it]2022-01-09 16:09:53,935 iteration 6750 : loss : 0.013107, loss_ce: 0.004743
2022-01-09 16:09:56,248 iteration 6751 : loss : 0.017798, loss_ce: 0.005956
2022-01-09 16:09:58,477 iteration 6752 : loss : 0.022092, loss_ce: 0.010605
2022-01-09 16:10:00,717 iteration 6753 : loss : 0.025875, loss_ce: 0.010236
2022-01-09 16:10:03,014 iteration 6754 : loss : 0.016593, loss_ce: 0.006816
2022-01-09 16:10:05,277 iteration 6755 : loss : 0.010660, loss_ce: 0.002411
2022-01-09 16:10:07,512 iteration 6756 : loss : 0.008762, loss_ce: 0.003957
2022-01-09 16:10:09,814 iteration 6757 : loss : 0.011961, loss_ce: 0.005066
2022-01-09 16:10:12,116 iteration 6758 : loss : 0.015290, loss_ce: 0.006866
2022-01-09 16:10:14,446 iteration 6759 : loss : 0.024720, loss_ce: 0.007677
2022-01-09 16:10:16,813 iteration 6760 : loss : 0.012282, loss_ce: 0.004814
2022-01-09 16:10:19,159 iteration 6761 : loss : 0.015504, loss_ce: 0.005707
2022-01-09 16:10:21,501 iteration 6762 : loss : 0.019650, loss_ce: 0.005645
2022-01-09 16:10:23,965 iteration 6763 : loss : 0.013979, loss_ce: 0.007085
2022-01-09 16:10:26,399 iteration 6764 : loss : 0.014566, loss_ce: 0.004959
2022-01-09 16:10:28,764 iteration 6765 : loss : 0.020437, loss_ce: 0.005163
2022-01-09 16:10:31,240 iteration 6766 : loss : 0.011656, loss_ce: 0.005023
100%|████████████████████████████▊| 398/400 [4:46:10<01:24, 42.25s/it]2022-01-09 16:10:33,723 iteration 6767 : loss : 0.020044, loss_ce: 0.008926
2022-01-09 16:10:36,030 iteration 6768 : loss : 0.014899, loss_ce: 0.004658
2022-01-09 16:10:38,304 iteration 6769 : loss : 0.013115, loss_ce: 0.004325
2022-01-09 16:10:40,600 iteration 6770 : loss : 0.020758, loss_ce: 0.006310
2022-01-09 16:10:42,844 iteration 6771 : loss : 0.014853, loss_ce: 0.006501
2022-01-09 16:10:45,259 iteration 6772 : loss : 0.016637, loss_ce: 0.006683
2022-01-09 16:10:47,560 iteration 6773 : loss : 0.011574, loss_ce: 0.004404
2022-01-09 16:10:49,919 iteration 6774 : loss : 0.014110, loss_ce: 0.005126
2022-01-09 16:10:52,251 iteration 6775 : loss : 0.013859, loss_ce: 0.002882
2022-01-09 16:10:54,645 iteration 6776 : loss : 0.015587, loss_ce: 0.005873
2022-01-09 16:10:57,017 iteration 6777 : loss : 0.018058, loss_ce: 0.006939
2022-01-09 16:10:59,373 iteration 6778 : loss : 0.016128, loss_ce: 0.005997
2022-01-09 16:11:01,925 iteration 6779 : loss : 0.013067, loss_ce: 0.006868
2022-01-09 16:11:04,332 iteration 6780 : loss : 0.014370, loss_ce: 0.005315
2022-01-09 16:11:06,633 iteration 6781 : loss : 0.013636, loss_ce: 0.004930
2022-01-09 16:11:08,934 iteration 6782 : loss : 0.019306, loss_ce: 0.008352
2022-01-09 16:11:11,255 iteration 6783 : loss : 0.020352, loss_ce: 0.006859
100%|████████████████████████████▉| 399/400 [4:46:50<00:41, 41.58s/it]2022-01-09 16:11:13,521 iteration 6784 : loss : 0.013358, loss_ce: 0.006365
2022-01-09 16:11:15,733 iteration 6785 : loss : 0.011670, loss_ce: 0.003653
2022-01-09 16:11:18,054 iteration 6786 : loss : 0.014882, loss_ce: 0.005543
2022-01-09 16:11:20,444 iteration 6787 : loss : 0.018632, loss_ce: 0.004640
2022-01-09 16:11:22,850 iteration 6788 : loss : 0.011956, loss_ce: 0.005272
2022-01-09 16:11:25,256 iteration 6789 : loss : 0.020119, loss_ce: 0.005353
2022-01-09 16:11:27,543 iteration 6790 : loss : 0.014574, loss_ce: 0.006061
2022-01-09 16:11:29,890 iteration 6791 : loss : 0.025209, loss_ce: 0.007995
2022-01-09 16:11:32,446 iteration 6792 : loss : 0.015530, loss_ce: 0.006807
2022-01-09 16:11:34,774 iteration 6793 : loss : 0.010519, loss_ce: 0.004129
2022-01-09 16:11:37,137 iteration 6794 : loss : 0.018027, loss_ce: 0.007194
2022-01-09 16:11:39,406 iteration 6795 : loss : 0.012388, loss_ce: 0.005488
2022-01-09 16:11:41,729 iteration 6796 : loss : 0.014624, loss_ce: 0.003858
2022-01-09 16:11:44,068 iteration 6797 : loss : 0.014922, loss_ce: 0.005228
2022-01-09 16:11:46,392 iteration 6798 : loss : 0.021662, loss_ce: 0.007684
2022-01-09 16:11:48,631 iteration 6799 : loss : 0.015330, loss_ce: 0.005303
2022-01-09 16:11:48,631 Training Data Eval:
2022-01-09 16:12:01,315   Average segmentation loss on training set: 0.0080
2022-01-09 16:12:01,315 Validation Data Eval:
2022-01-09 16:12:05,864   Average segmentation loss on validation set: 0.0661
2022-01-09 16:12:08,258 iteration 6800 : loss : 0.016210, loss_ce: 0.007158
100%|█████████████████████████████| 400/400 [4:47:47<00:00, 46.21s/it]100%|█████████████████████████████| 400/400 [4:47:47<00:00, 43.17s/it]
