2022-01-20 20:55:30,560 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:55:30,561 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:55:30,561 ============================================================
2022-01-20 20:55:30,561 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:55:30,561 ============================================================
2022-01-20 20:55:30,561 Loading data...
2022-01-20 20:55:30,561 Reading NCI - RUNMC images...
2022-01-20 20:55:30,561 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-20 20:55:30,562 Already preprocessed this configuration. Loading now!
2022-01-20 20:55:30,581 Training Images: (256, 256, 286)
2022-01-20 20:55:30,581 Training Labels: (256, 256, 286)
2022-01-20 20:55:30,581 Validation Images: (256, 256, 98)
2022-01-20 20:55:30,581 Validation Labels: (256, 256, 98)
2022-01-20 20:55:30,581 ============================================================
2022-01-20 20:55:30,614 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-20 20:55:32,894 iteration 1 : loss : 1.008398, loss_ce: 1.252147
2022-01-20 20:55:33,471 iteration 2 : loss : 0.982593, loss_ce: 1.213147
2022-01-20 20:55:34,140 iteration 3 : loss : 0.947584, loss_ce: 1.149991
2022-01-20 20:55:34,712 iteration 4 : loss : 0.911445, loss_ce: 1.084170
2022-01-20 20:55:35,289 iteration 5 : loss : 0.854967, loss_ce: 0.997766
2022-01-20 20:55:35,882 iteration 6 : loss : 0.821245, loss_ce: 0.932750
2022-01-20 20:55:36,524 iteration 7 : loss : 0.778212, loss_ce: 0.873976
2022-01-20 20:55:37,107 iteration 8 : loss : 0.762820, loss_ce: 0.817624
2022-01-20 20:55:37,713 iteration 9 : loss : 0.717203, loss_ce: 0.797681
2022-01-20 20:55:38,345 iteration 10 : loss : 0.715523, loss_ce: 0.745688
2022-01-20 20:55:39,042 iteration 11 : loss : 0.692978, loss_ce: 0.728496
2022-01-20 20:55:39,615 iteration 12 : loss : 0.677489, loss_ce: 0.697866
2022-01-20 20:55:40,171 iteration 13 : loss : 0.680176, loss_ce: 0.691878
2022-01-20 20:55:40,700 iteration 14 : loss : 0.657761, loss_ce: 0.663718
2022-01-20 20:55:41,302 iteration 15 : loss : 0.644095, loss_ce: 0.642819
2022-01-20 20:55:41,881 iteration 16 : loss : 0.649449, loss_ce: 0.643861
2022-01-20 20:55:42,455 iteration 17 : loss : 0.614136, loss_ce: 0.617182
  0%|                               | 1/400 [00:11<1:19:07, 11.90s/it]2022-01-20 20:55:43,121 iteration 18 : loss : 0.634927, loss_ce: 0.603827
2022-01-20 20:55:43,632 iteration 19 : loss : 0.605159, loss_ce: 0.586200
2022-01-20 20:55:44,282 iteration 20 : loss : 0.598753, loss_ce: 0.578390
2022-01-20 20:55:44,837 iteration 21 : loss : 0.614227, loss_ce: 0.574750
2022-01-20 20:55:45,414 iteration 22 : loss : 0.571717, loss_ce: 0.556034
2022-01-20 20:55:46,068 iteration 23 : loss : 0.587642, loss_ce: 0.544385
2022-01-20 20:55:46,647 iteration 24 : loss : 0.568965, loss_ce: 0.534716
2022-01-20 20:55:47,283 iteration 25 : loss : 0.578783, loss_ce: 0.562068
2022-01-20 20:55:47,842 iteration 26 : loss : 0.553798, loss_ce: 0.514589
2022-01-20 20:55:48,345 iteration 27 : loss : 0.537302, loss_ce: 0.508028
2022-01-20 20:55:48,864 iteration 28 : loss : 0.533005, loss_ce: 0.497632
2022-01-20 20:55:49,483 iteration 29 : loss : 0.529260, loss_ce: 0.484304
2022-01-20 20:55:50,098 iteration 30 : loss : 0.524037, loss_ce: 0.483013
2022-01-20 20:55:50,621 iteration 31 : loss : 0.503501, loss_ce: 0.468061
2022-01-20 20:55:51,259 iteration 32 : loss : 0.493183, loss_ce: 0.466237
2022-01-20 20:55:51,881 iteration 33 : loss : 0.502755, loss_ce: 0.467080
2022-01-20 20:55:52,508 iteration 34 : loss : 0.494274, loss_ce: 0.462953
  0%|▏                              | 2/400 [00:21<1:11:41, 10.81s/it]2022-01-20 20:55:53,163 iteration 35 : loss : 0.485492, loss_ce: 0.434097
2022-01-20 20:55:53,799 iteration 36 : loss : 0.485276, loss_ce: 0.436488
2022-01-20 20:55:54,439 iteration 37 : loss : 0.488634, loss_ce: 0.425922
2022-01-20 20:55:54,993 iteration 38 : loss : 0.468525, loss_ce: 0.417600
2022-01-20 20:55:55,561 iteration 39 : loss : 0.445814, loss_ce: 0.400515
2022-01-20 20:55:56,201 iteration 40 : loss : 0.461340, loss_ce: 0.410150
2022-01-20 20:55:56,831 iteration 41 : loss : 0.489278, loss_ce: 0.425622
2022-01-20 20:55:57,436 iteration 42 : loss : 0.445640, loss_ce: 0.388664
2022-01-20 20:55:57,953 iteration 43 : loss : 0.457881, loss_ce: 0.388545
2022-01-20 20:55:58,608 iteration 44 : loss : 0.426781, loss_ce: 0.368090
2022-01-20 20:55:59,197 iteration 45 : loss : 0.417722, loss_ce: 0.361687
2022-01-20 20:55:59,798 iteration 46 : loss : 0.435602, loss_ce: 0.359277
2022-01-20 20:56:00,429 iteration 47 : loss : 0.405203, loss_ce: 0.339096
2022-01-20 20:56:01,038 iteration 48 : loss : 0.409670, loss_ce: 0.346532
2022-01-20 20:56:01,694 iteration 49 : loss : 0.463175, loss_ce: 0.385385
2022-01-20 20:56:02,245 iteration 50 : loss : 0.456832, loss_ce: 0.369132
2022-01-20 20:56:02,775 iteration 51 : loss : 0.416737, loss_ce: 0.339944
  1%|▏                              | 3/400 [00:32<1:09:52, 10.56s/it]2022-01-20 20:56:03,458 iteration 52 : loss : 0.411139, loss_ce: 0.335579
2022-01-20 20:56:04,079 iteration 53 : loss : 0.400073, loss_ce: 0.322262
2022-01-20 20:56:04,672 iteration 54 : loss : 0.396236, loss_ce: 0.306488
2022-01-20 20:56:05,274 iteration 55 : loss : 0.381050, loss_ce: 0.310617
2022-01-20 20:56:05,859 iteration 56 : loss : 0.403736, loss_ce: 0.316370
2022-01-20 20:56:06,474 iteration 57 : loss : 0.377683, loss_ce: 0.296679
2022-01-20 20:56:07,087 iteration 58 : loss : 0.419571, loss_ce: 0.320901
2022-01-20 20:56:07,662 iteration 59 : loss : 0.358507, loss_ce: 0.288024
2022-01-20 20:56:08,273 iteration 60 : loss : 0.403404, loss_ce: 0.304524
2022-01-20 20:56:08,870 iteration 61 : loss : 0.372962, loss_ce: 0.291948
2022-01-20 20:56:09,458 iteration 62 : loss : 0.427055, loss_ce: 0.295252
2022-01-20 20:56:09,977 iteration 63 : loss : 0.383584, loss_ce: 0.294039
2022-01-20 20:56:10,556 iteration 64 : loss : 0.414300, loss_ce: 0.293190
2022-01-20 20:56:11,088 iteration 65 : loss : 0.378721, loss_ce: 0.261339
2022-01-20 20:56:11,659 iteration 66 : loss : 0.365147, loss_ce: 0.266021
2022-01-20 20:56:12,309 iteration 67 : loss : 0.368540, loss_ce: 0.249581
2022-01-20 20:56:12,902 iteration 68 : loss : 0.361929, loss_ce: 0.269822
  1%|▎                              | 4/400 [00:42<1:08:33, 10.39s/it]2022-01-20 20:56:13,562 iteration 69 : loss : 0.341899, loss_ce: 0.249222
2022-01-20 20:56:14,238 iteration 70 : loss : 0.344497, loss_ce: 0.250010
2022-01-20 20:56:14,792 iteration 71 : loss : 0.336691, loss_ce: 0.240820
2022-01-20 20:56:15,397 iteration 72 : loss : 0.349744, loss_ce: 0.255598
2022-01-20 20:56:15,947 iteration 73 : loss : 0.337168, loss_ce: 0.250224
2022-01-20 20:56:16,476 iteration 74 : loss : 0.335919, loss_ce: 0.242917
2022-01-20 20:56:17,045 iteration 75 : loss : 0.325410, loss_ce: 0.227704
2022-01-20 20:56:17,611 iteration 76 : loss : 0.336260, loss_ce: 0.241965
2022-01-20 20:56:18,101 iteration 77 : loss : 0.321726, loss_ce: 0.231378
2022-01-20 20:56:18,701 iteration 78 : loss : 0.330130, loss_ce: 0.233637
2022-01-20 20:56:19,275 iteration 79 : loss : 0.352272, loss_ce: 0.222818
2022-01-20 20:56:19,833 iteration 80 : loss : 0.306027, loss_ce: 0.218669
2022-01-20 20:56:20,386 iteration 81 : loss : 0.335860, loss_ce: 0.228951
2022-01-20 20:56:20,964 iteration 82 : loss : 0.312748, loss_ce: 0.214820
2022-01-20 20:56:21,537 iteration 83 : loss : 0.329042, loss_ce: 0.214407
2022-01-20 20:56:22,200 iteration 84 : loss : 0.297068, loss_ce: 0.219156
2022-01-20 20:56:22,200 Training Data Eval:
2022-01-20 20:56:25,049   Average segmentation loss on training set: 1.8869
2022-01-20 20:56:25,050 Validation Data Eval:
2022-01-20 20:56:26,003   Average segmentation loss on validation set: 1.9404
2022-01-20 20:56:26,589 iteration 85 : loss : 0.331954, loss_ce: 0.214150
  1%|▍                              | 5/400 [00:56<1:16:12, 11.57s/it]2022-01-20 20:56:27,256 iteration 86 : loss : 0.338110, loss_ce: 0.205620
2022-01-20 20:56:27,995 iteration 87 : loss : 0.308101, loss_ce: 0.198215
2022-01-20 20:56:28,563 iteration 88 : loss : 0.283894, loss_ce: 0.192388
2022-01-20 20:56:29,207 iteration 89 : loss : 0.303869, loss_ce: 0.204167
2022-01-20 20:56:29,843 iteration 90 : loss : 0.296495, loss_ce: 0.197379
2022-01-20 20:56:30,542 iteration 91 : loss : 0.278821, loss_ce: 0.199066
2022-01-20 20:56:31,141 iteration 92 : loss : 0.288907, loss_ce: 0.193813
2022-01-20 20:56:31,747 iteration 93 : loss : 0.310822, loss_ce: 0.197732
2022-01-20 20:56:32,364 iteration 94 : loss : 0.300982, loss_ce: 0.192332
2022-01-20 20:56:33,107 iteration 95 : loss : 0.278584, loss_ce: 0.184906
2022-01-20 20:56:33,698 iteration 96 : loss : 0.269221, loss_ce: 0.176496
2022-01-20 20:56:34,295 iteration 97 : loss : 0.276537, loss_ce: 0.179984
2022-01-20 20:56:34,910 iteration 98 : loss : 0.273255, loss_ce: 0.178469
2022-01-20 20:56:35,602 iteration 99 : loss : 0.283532, loss_ce: 0.178909
2022-01-20 20:56:36,240 iteration 100 : loss : 0.275256, loss_ce: 0.170360
2022-01-20 20:56:36,853 iteration 101 : loss : 0.205405, loss_ce: 0.141890
2022-01-20 20:56:37,397 iteration 102 : loss : 0.274397, loss_ce: 0.172604
  2%|▍                              | 6/400 [01:06<1:14:19, 11.32s/it]2022-01-20 20:56:38,136 iteration 103 : loss : 0.231090, loss_ce: 0.156932
2022-01-20 20:56:38,832 iteration 104 : loss : 0.300501, loss_ce: 0.190667
2022-01-20 20:56:39,578 iteration 105 : loss : 0.310040, loss_ce: 0.193898
2022-01-20 20:56:40,157 iteration 106 : loss : 0.288349, loss_ce: 0.173163
2022-01-20 20:56:40,918 iteration 107 : loss : 0.250539, loss_ce: 0.163299
2022-01-20 20:56:41,470 iteration 108 : loss : 0.287913, loss_ce: 0.175131
2022-01-20 20:56:42,061 iteration 109 : loss : 0.216583, loss_ce: 0.146380
2022-01-20 20:56:42,611 iteration 110 : loss : 0.203910, loss_ce: 0.138387
2022-01-20 20:56:43,261 iteration 111 : loss : 0.281963, loss_ce: 0.187532
2022-01-20 20:56:43,821 iteration 112 : loss : 0.244568, loss_ce: 0.153296
2022-01-20 20:56:44,450 iteration 113 : loss : 0.279297, loss_ce: 0.188298
2022-01-20 20:56:45,042 iteration 114 : loss : 0.279348, loss_ce: 0.150343
2022-01-20 20:56:45,659 iteration 115 : loss : 0.234706, loss_ce: 0.144475
2022-01-20 20:56:46,329 iteration 116 : loss : 0.249929, loss_ce: 0.151894
2022-01-20 20:56:46,991 iteration 117 : loss : 0.251864, loss_ce: 0.152563
2022-01-20 20:56:47,623 iteration 118 : loss : 0.258481, loss_ce: 0.150646
2022-01-20 20:56:48,266 iteration 119 : loss : 0.242961, loss_ce: 0.138175
  2%|▌                              | 7/400 [01:17<1:13:10, 11.17s/it]2022-01-20 20:56:48,895 iteration 120 : loss : 0.295756, loss_ce: 0.176178
2022-01-20 20:56:49,458 iteration 121 : loss : 0.208645, loss_ce: 0.128325
2022-01-20 20:56:50,130 iteration 122 : loss : 0.233868, loss_ce: 0.131776
2022-01-20 20:56:50,776 iteration 123 : loss : 0.213793, loss_ce: 0.121880
2022-01-20 20:56:51,391 iteration 124 : loss : 0.216889, loss_ce: 0.121916
2022-01-20 20:56:51,965 iteration 125 : loss : 0.227372, loss_ce: 0.142311
2022-01-20 20:56:52,600 iteration 126 : loss : 0.253918, loss_ce: 0.134833
2022-01-20 20:56:53,169 iteration 127 : loss : 0.221468, loss_ce: 0.133395
2022-01-20 20:56:53,763 iteration 128 : loss : 0.200853, loss_ce: 0.127844
2022-01-20 20:56:54,433 iteration 129 : loss : 0.230765, loss_ce: 0.128525
2022-01-20 20:56:55,047 iteration 130 : loss : 0.218911, loss_ce: 0.121296
2022-01-20 20:56:55,756 iteration 131 : loss : 0.230174, loss_ce: 0.137428
2022-01-20 20:56:56,488 iteration 132 : loss : 0.231086, loss_ce: 0.114800
2022-01-20 20:56:57,082 iteration 133 : loss : 0.209091, loss_ce: 0.111251
2022-01-20 20:56:57,779 iteration 134 : loss : 0.208521, loss_ce: 0.113289
2022-01-20 20:56:58,480 iteration 135 : loss : 0.228827, loss_ce: 0.128927
2022-01-20 20:56:59,097 iteration 136 : loss : 0.169909, loss_ce: 0.111212
  2%|▌                              | 8/400 [01:28<1:12:15, 11.06s/it]2022-01-20 20:56:59,828 iteration 137 : loss : 0.207463, loss_ce: 0.114969
2022-01-20 20:57:00,423 iteration 138 : loss : 0.190195, loss_ce: 0.128715
2022-01-20 20:57:01,081 iteration 139 : loss : 0.223253, loss_ce: 0.131180
2022-01-20 20:57:01,718 iteration 140 : loss : 0.219106, loss_ce: 0.118849
2022-01-20 20:57:02,400 iteration 141 : loss : 0.231466, loss_ce: 0.138290
2022-01-20 20:57:03,086 iteration 142 : loss : 0.212295, loss_ce: 0.116877
2022-01-20 20:57:03,794 iteration 143 : loss : 0.198410, loss_ce: 0.117941
2022-01-20 20:57:04,468 iteration 144 : loss : 0.220621, loss_ce: 0.123890
2022-01-20 20:57:05,092 iteration 145 : loss : 0.228005, loss_ce: 0.128309
2022-01-20 20:57:05,768 iteration 146 : loss : 0.172437, loss_ce: 0.108685
2022-01-20 20:57:06,446 iteration 147 : loss : 0.222645, loss_ce: 0.117428
2022-01-20 20:57:06,994 iteration 148 : loss : 0.206605, loss_ce: 0.116887
2022-01-20 20:57:07,612 iteration 149 : loss : 0.296335, loss_ce: 0.160772
2022-01-20 20:57:08,208 iteration 150 : loss : 0.246750, loss_ce: 0.117765
2022-01-20 20:57:08,804 iteration 151 : loss : 0.194432, loss_ce: 0.111508
2022-01-20 20:57:09,410 iteration 152 : loss : 0.226307, loss_ce: 0.103100
2022-01-20 20:57:10,062 iteration 153 : loss : 0.266477, loss_ce: 0.145556
  2%|▋                              | 9/400 [01:39<1:11:53, 11.03s/it]2022-01-20 20:57:10,674 iteration 154 : loss : 0.235905, loss_ce: 0.123905
2022-01-20 20:57:11,311 iteration 155 : loss : 0.202782, loss_ce: 0.103723
2022-01-20 20:57:12,024 iteration 156 : loss : 0.196170, loss_ce: 0.112111
2022-01-20 20:57:12,669 iteration 157 : loss : 0.250744, loss_ce: 0.128805
2022-01-20 20:57:13,429 iteration 158 : loss : 0.206001, loss_ce: 0.108766
2022-01-20 20:57:13,948 iteration 159 : loss : 0.176492, loss_ce: 0.095770
2022-01-20 20:57:14,654 iteration 160 : loss : 0.183534, loss_ce: 0.091650
2022-01-20 20:57:15,348 iteration 161 : loss : 0.245702, loss_ce: 0.111792
2022-01-20 20:57:16,053 iteration 162 : loss : 0.214883, loss_ce: 0.116760
2022-01-20 20:57:16,687 iteration 163 : loss : 0.224886, loss_ce: 0.117457
2022-01-20 20:57:17,340 iteration 164 : loss : 0.164093, loss_ce: 0.082760
2022-01-20 20:57:17,959 iteration 165 : loss : 0.201185, loss_ce: 0.103768
2022-01-20 20:57:18,563 iteration 166 : loss : 0.236938, loss_ce: 0.122117
2022-01-20 20:57:19,183 iteration 167 : loss : 0.178011, loss_ce: 0.096712
2022-01-20 20:57:19,844 iteration 168 : loss : 0.193808, loss_ce: 0.113574
2022-01-20 20:57:20,474 iteration 169 : loss : 0.186166, loss_ce: 0.107666
2022-01-20 20:57:20,474 Training Data Eval:
2022-01-20 20:57:23,370   Average segmentation loss on training set: 0.1949
2022-01-20 20:57:23,371 Validation Data Eval:
2022-01-20 20:57:24,322   Average segmentation loss on validation set: 0.2763
2022-01-20 20:57:24,859 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 20:57:25,523 iteration 170 : loss : 0.177893, loss_ce: 0.101480
  2%|▊                             | 10/400 [01:54<1:20:34, 12.40s/it]2022-01-20 20:57:26,213 iteration 171 : loss : 0.210898, loss_ce: 0.123148
2022-01-20 20:57:26,883 iteration 172 : loss : 0.199672, loss_ce: 0.111187
2022-01-20 20:57:27,573 iteration 173 : loss : 0.157048, loss_ce: 0.096550
2022-01-20 20:57:28,169 iteration 174 : loss : 0.182839, loss_ce: 0.101016
2022-01-20 20:57:28,750 iteration 175 : loss : 0.243533, loss_ce: 0.130796
2022-01-20 20:57:29,407 iteration 176 : loss : 0.185109, loss_ce: 0.101662
2022-01-20 20:57:30,028 iteration 177 : loss : 0.209330, loss_ce: 0.103021
2022-01-20 20:57:30,655 iteration 178 : loss : 0.154809, loss_ce: 0.091735
2022-01-20 20:57:31,280 iteration 179 : loss : 0.202986, loss_ce: 0.103405
2022-01-20 20:57:31,886 iteration 180 : loss : 0.141497, loss_ce: 0.070052
2022-01-20 20:57:32,553 iteration 181 : loss : 0.163872, loss_ce: 0.086908
2022-01-20 20:57:33,154 iteration 182 : loss : 0.175785, loss_ce: 0.097202
2022-01-20 20:57:33,733 iteration 183 : loss : 0.179973, loss_ce: 0.087838
2022-01-20 20:57:34,273 iteration 184 : loss : 0.194927, loss_ce: 0.090114
2022-01-20 20:57:34,934 iteration 185 : loss : 0.207814, loss_ce: 0.101723
2022-01-20 20:57:35,592 iteration 186 : loss : 0.195415, loss_ce: 0.101921
2022-01-20 20:57:36,279 iteration 187 : loss : 0.186487, loss_ce: 0.094061
  3%|▊                             | 11/400 [02:05<1:17:06, 11.89s/it]2022-01-20 20:57:36,975 iteration 188 : loss : 0.181465, loss_ce: 0.099280
2022-01-20 20:57:37,623 iteration 189 : loss : 0.192600, loss_ce: 0.096371
2022-01-20 20:57:38,283 iteration 190 : loss : 0.184061, loss_ce: 0.087678
2022-01-20 20:57:38,897 iteration 191 : loss : 0.178205, loss_ce: 0.090487
2022-01-20 20:57:39,463 iteration 192 : loss : 0.171953, loss_ce: 0.095320
2022-01-20 20:57:40,154 iteration 193 : loss : 0.167823, loss_ce: 0.086642
2022-01-20 20:57:40,772 iteration 194 : loss : 0.240583, loss_ce: 0.097958
2022-01-20 20:57:41,366 iteration 195 : loss : 0.185874, loss_ce: 0.094847
2022-01-20 20:57:41,915 iteration 196 : loss : 0.186812, loss_ce: 0.091902
2022-01-20 20:57:42,552 iteration 197 : loss : 0.222996, loss_ce: 0.113095
2022-01-20 20:57:43,220 iteration 198 : loss : 0.169581, loss_ce: 0.088753
2022-01-20 20:57:43,815 iteration 199 : loss : 0.191937, loss_ce: 0.097356
2022-01-20 20:57:44,428 iteration 200 : loss : 0.188199, loss_ce: 0.098001
2022-01-20 20:57:45,074 iteration 201 : loss : 0.151138, loss_ce: 0.086004
2022-01-20 20:57:45,744 iteration 202 : loss : 0.166402, loss_ce: 0.087079
2022-01-20 20:57:46,326 iteration 203 : loss : 0.148385, loss_ce: 0.080480
2022-01-20 20:57:47,041 iteration 204 : loss : 0.214150, loss_ce: 0.106053
  3%|▉                             | 12/400 [02:16<1:14:41, 11.55s/it]2022-01-20 20:57:47,674 iteration 205 : loss : 0.140189, loss_ce: 0.074277
2022-01-20 20:57:48,292 iteration 206 : loss : 0.165624, loss_ce: 0.072238
2022-01-20 20:57:48,932 iteration 207 : loss : 0.179085, loss_ce: 0.081679
2022-01-20 20:57:49,538 iteration 208 : loss : 0.209467, loss_ce: 0.078779
2022-01-20 20:57:50,242 iteration 209 : loss : 0.191603, loss_ce: 0.096959
2022-01-20 20:57:50,780 iteration 210 : loss : 0.176946, loss_ce: 0.076223
2022-01-20 20:57:51,448 iteration 211 : loss : 0.194565, loss_ce: 0.100516
2022-01-20 20:57:52,105 iteration 212 : loss : 0.165665, loss_ce: 0.085411
2022-01-20 20:57:52,858 iteration 213 : loss : 0.128259, loss_ce: 0.076043
2022-01-20 20:57:53,492 iteration 214 : loss : 0.156416, loss_ce: 0.070732
2022-01-20 20:57:54,124 iteration 215 : loss : 0.185112, loss_ce: 0.089247
2022-01-20 20:57:54,913 iteration 216 : loss : 0.153279, loss_ce: 0.074339
2022-01-20 20:57:55,638 iteration 217 : loss : 0.175268, loss_ce: 0.080403
2022-01-20 20:57:56,288 iteration 218 : loss : 0.170988, loss_ce: 0.098347
2022-01-20 20:57:56,824 iteration 219 : loss : 0.139900, loss_ce: 0.078547
2022-01-20 20:57:57,481 iteration 220 : loss : 0.129045, loss_ce: 0.072116
2022-01-20 20:57:58,121 iteration 221 : loss : 0.176671, loss_ce: 0.079429
  3%|▉                             | 13/400 [02:27<1:13:34, 11.41s/it]2022-01-20 20:57:58,821 iteration 222 : loss : 0.159103, loss_ce: 0.092130
2022-01-20 20:57:59,510 iteration 223 : loss : 0.143351, loss_ce: 0.073825
2022-01-20 20:58:00,149 iteration 224 : loss : 0.178251, loss_ce: 0.097845
2022-01-20 20:58:00,884 iteration 225 : loss : 0.281894, loss_ce: 0.100079
2022-01-20 20:58:01,514 iteration 226 : loss : 0.164433, loss_ce: 0.069475
2022-01-20 20:58:02,187 iteration 227 : loss : 0.200824, loss_ce: 0.097649
2022-01-20 20:58:02,818 iteration 228 : loss : 0.156715, loss_ce: 0.074741
2022-01-20 20:58:03,400 iteration 229 : loss : 0.167806, loss_ce: 0.070432
2022-01-20 20:58:04,038 iteration 230 : loss : 0.138027, loss_ce: 0.069525
2022-01-20 20:58:04,718 iteration 231 : loss : 0.183856, loss_ce: 0.081884
2022-01-20 20:58:05,403 iteration 232 : loss : 0.113914, loss_ce: 0.062753
2022-01-20 20:58:05,998 iteration 233 : loss : 0.175934, loss_ce: 0.084312
2022-01-20 20:58:06,709 iteration 234 : loss : 0.174635, loss_ce: 0.089246
2022-01-20 20:58:07,326 iteration 235 : loss : 0.148471, loss_ce: 0.075333
2022-01-20 20:58:07,986 iteration 236 : loss : 0.125910, loss_ce: 0.063809
2022-01-20 20:58:08,600 iteration 237 : loss : 0.122313, loss_ce: 0.063723
2022-01-20 20:58:09,233 iteration 238 : loss : 0.148078, loss_ce: 0.080939
  4%|█                             | 14/400 [02:38<1:12:49, 11.32s/it]2022-01-20 20:58:09,855 iteration 239 : loss : 0.160346, loss_ce: 0.070710
2022-01-20 20:58:10,520 iteration 240 : loss : 0.169268, loss_ce: 0.084801
2022-01-20 20:58:11,192 iteration 241 : loss : 0.162554, loss_ce: 0.077654
2022-01-20 20:58:11,846 iteration 242 : loss : 0.162681, loss_ce: 0.097139
2022-01-20 20:58:12,636 iteration 243 : loss : 0.136007, loss_ce: 0.069857
2022-01-20 20:58:13,225 iteration 244 : loss : 0.202108, loss_ce: 0.069618
2022-01-20 20:58:13,872 iteration 245 : loss : 0.168037, loss_ce: 0.094051
2022-01-20 20:58:14,563 iteration 246 : loss : 0.144849, loss_ce: 0.071040
2022-01-20 20:58:15,188 iteration 247 : loss : 0.153075, loss_ce: 0.073042
2022-01-20 20:58:15,814 iteration 248 : loss : 0.133764, loss_ce: 0.058755
2022-01-20 20:58:16,423 iteration 249 : loss : 0.168689, loss_ce: 0.090585
2022-01-20 20:58:17,055 iteration 250 : loss : 0.169202, loss_ce: 0.078821
2022-01-20 20:58:17,629 iteration 251 : loss : 0.145931, loss_ce: 0.066807
2022-01-20 20:58:18,257 iteration 252 : loss : 0.114198, loss_ce: 0.062690
2022-01-20 20:58:18,917 iteration 253 : loss : 0.167548, loss_ce: 0.085384
2022-01-20 20:58:19,640 iteration 254 : loss : 0.272068, loss_ce: 0.109652
2022-01-20 20:58:19,640 Training Data Eval:
2022-01-20 20:58:22,535   Average segmentation loss on training set: 0.1272
2022-01-20 20:58:22,536 Validation Data Eval:
2022-01-20 20:58:23,490   Average segmentation loss on validation set: 0.1978
2022-01-20 20:58:24,081 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 20:58:24,677 iteration 255 : loss : 0.132072, loss_ce: 0.069943
  4%|█▏                            | 15/400 [02:54<1:20:37, 12.56s/it]2022-01-20 20:58:25,377 iteration 256 : loss : 0.153974, loss_ce: 0.069494
2022-01-20 20:58:26,075 iteration 257 : loss : 0.133761, loss_ce: 0.058560
2022-01-20 20:58:26,823 iteration 258 : loss : 0.172128, loss_ce: 0.074313
2022-01-20 20:58:27,385 iteration 259 : loss : 0.108967, loss_ce: 0.059436
2022-01-20 20:58:28,086 iteration 260 : loss : 0.140509, loss_ce: 0.069751
2022-01-20 20:58:28,740 iteration 261 : loss : 0.215198, loss_ce: 0.080477
2022-01-20 20:58:29,478 iteration 262 : loss : 0.123367, loss_ce: 0.067349
2022-01-20 20:58:30,121 iteration 263 : loss : 0.152565, loss_ce: 0.079161
2022-01-20 20:58:30,796 iteration 264 : loss : 0.145550, loss_ce: 0.078575
2022-01-20 20:58:31,396 iteration 265 : loss : 0.126155, loss_ce: 0.064855
2022-01-20 20:58:32,074 iteration 266 : loss : 0.145563, loss_ce: 0.078831
2022-01-20 20:58:32,712 iteration 267 : loss : 0.120150, loss_ce: 0.049203
2022-01-20 20:58:33,364 iteration 268 : loss : 0.137081, loss_ce: 0.069304
2022-01-20 20:58:34,204 iteration 269 : loss : 0.143482, loss_ce: 0.058715
2022-01-20 20:58:34,954 iteration 270 : loss : 0.153440, loss_ce: 0.077616
2022-01-20 20:58:35,470 iteration 271 : loss : 0.146357, loss_ce: 0.057244
2022-01-20 20:58:36,119 iteration 272 : loss : 0.133437, loss_ce: 0.073385
  4%|█▏                            | 16/400 [03:05<1:18:14, 12.23s/it]2022-01-20 20:58:36,752 iteration 273 : loss : 0.126025, loss_ce: 0.060286
2022-01-20 20:58:37,335 iteration 274 : loss : 0.110857, loss_ce: 0.053764
2022-01-20 20:58:37,924 iteration 275 : loss : 0.104266, loss_ce: 0.054997
2022-01-20 20:58:38,575 iteration 276 : loss : 0.109444, loss_ce: 0.062741
2022-01-20 20:58:39,246 iteration 277 : loss : 0.116992, loss_ce: 0.057523
2022-01-20 20:58:39,756 iteration 278 : loss : 0.157148, loss_ce: 0.064319
2022-01-20 20:58:40,338 iteration 279 : loss : 0.156586, loss_ce: 0.068473
2022-01-20 20:58:40,916 iteration 280 : loss : 0.139461, loss_ce: 0.070227
2022-01-20 20:58:41,554 iteration 281 : loss : 0.115430, loss_ce: 0.058104
2022-01-20 20:58:42,170 iteration 282 : loss : 0.167577, loss_ce: 0.082775
2022-01-20 20:58:42,758 iteration 283 : loss : 0.142269, loss_ce: 0.076425
2022-01-20 20:58:43,455 iteration 284 : loss : 0.166009, loss_ce: 0.071580
2022-01-20 20:58:44,029 iteration 285 : loss : 0.149396, loss_ce: 0.058006
2022-01-20 20:58:44,620 iteration 286 : loss : 0.124371, loss_ce: 0.061768
2022-01-20 20:58:45,335 iteration 287 : loss : 0.151713, loss_ce: 0.076028
2022-01-20 20:58:46,025 iteration 288 : loss : 0.159217, loss_ce: 0.076319
2022-01-20 20:58:46,631 iteration 289 : loss : 0.139208, loss_ce: 0.063444
  4%|█▎                            | 17/400 [03:16<1:14:44, 11.71s/it]2022-01-20 20:58:47,312 iteration 290 : loss : 0.108747, loss_ce: 0.052454
2022-01-20 20:58:47,902 iteration 291 : loss : 0.123141, loss_ce: 0.059275
2022-01-20 20:58:48,500 iteration 292 : loss : 0.109423, loss_ce: 0.057702
2022-01-20 20:58:49,103 iteration 293 : loss : 0.114792, loss_ce: 0.060574
2022-01-20 20:58:49,736 iteration 294 : loss : 0.144558, loss_ce: 0.070127
2022-01-20 20:58:50,462 iteration 295 : loss : 0.130529, loss_ce: 0.054374
2022-01-20 20:58:51,063 iteration 296 : loss : 0.097878, loss_ce: 0.042295
2022-01-20 20:58:51,692 iteration 297 : loss : 0.118745, loss_ce: 0.050659
2022-01-20 20:58:52,289 iteration 298 : loss : 0.122882, loss_ce: 0.057771
2022-01-20 20:58:52,910 iteration 299 : loss : 0.136419, loss_ce: 0.065394
2022-01-20 20:58:53,542 iteration 300 : loss : 0.162297, loss_ce: 0.066387
2022-01-20 20:58:54,185 iteration 301 : loss : 0.167092, loss_ce: 0.095072
2022-01-20 20:58:54,891 iteration 302 : loss : 0.102545, loss_ce: 0.055331
2022-01-20 20:58:55,563 iteration 303 : loss : 0.154900, loss_ce: 0.071574
2022-01-20 20:58:56,216 iteration 304 : loss : 0.148821, loss_ce: 0.071082
2022-01-20 20:58:56,904 iteration 305 : loss : 0.117465, loss_ce: 0.063346
2022-01-20 20:58:57,581 iteration 306 : loss : 0.093052, loss_ce: 0.052047
  4%|█▎                            | 18/400 [03:27<1:13:06, 11.48s/it]2022-01-20 20:58:58,276 iteration 307 : loss : 0.174292, loss_ce: 0.075906
2022-01-20 20:58:58,877 iteration 308 : loss : 0.123860, loss_ce: 0.066615
2022-01-20 20:58:59,539 iteration 309 : loss : 0.192305, loss_ce: 0.086179
2022-01-20 20:59:00,226 iteration 310 : loss : 0.154315, loss_ce: 0.072718
2022-01-20 20:59:00,824 iteration 311 : loss : 0.140952, loss_ce: 0.051848
2022-01-20 20:59:01,460 iteration 312 : loss : 0.154218, loss_ce: 0.080742
2022-01-20 20:59:02,105 iteration 313 : loss : 0.158352, loss_ce: 0.086790
2022-01-20 20:59:02,675 iteration 314 : loss : 0.101769, loss_ce: 0.053606
2022-01-20 20:59:03,298 iteration 315 : loss : 0.150782, loss_ce: 0.059734
2022-01-20 20:59:03,947 iteration 316 : loss : 0.158266, loss_ce: 0.066907
2022-01-20 20:59:04,581 iteration 317 : loss : 0.179960, loss_ce: 0.078676
2022-01-20 20:59:05,233 iteration 318 : loss : 0.116409, loss_ce: 0.061366
2022-01-20 20:59:05,808 iteration 319 : loss : 0.111935, loss_ce: 0.054886
2022-01-20 20:59:06,520 iteration 320 : loss : 0.108157, loss_ce: 0.049082
2022-01-20 20:59:07,191 iteration 321 : loss : 0.149356, loss_ce: 0.056499
2022-01-20 20:59:07,820 iteration 322 : loss : 0.201302, loss_ce: 0.098405
2022-01-20 20:59:08,508 iteration 323 : loss : 0.159130, loss_ce: 0.060742
  5%|█▍                            | 19/400 [03:37<1:11:51, 11.32s/it]2022-01-20 20:59:09,172 iteration 324 : loss : 0.150532, loss_ce: 0.063104
2022-01-20 20:59:09,806 iteration 325 : loss : 0.156257, loss_ce: 0.068511
2022-01-20 20:59:10,472 iteration 326 : loss : 0.114834, loss_ce: 0.058912
2022-01-20 20:59:11,216 iteration 327 : loss : 0.132981, loss_ce: 0.064425
2022-01-20 20:59:11,843 iteration 328 : loss : 0.130074, loss_ce: 0.059017
2022-01-20 20:59:12,517 iteration 329 : loss : 0.135499, loss_ce: 0.074298
2022-01-20 20:59:13,208 iteration 330 : loss : 0.131396, loss_ce: 0.055461
2022-01-20 20:59:13,800 iteration 331 : loss : 0.101530, loss_ce: 0.057332
2022-01-20 20:59:14,415 iteration 332 : loss : 0.122650, loss_ce: 0.056938
2022-01-20 20:59:15,074 iteration 333 : loss : 0.114951, loss_ce: 0.061401
2022-01-20 20:59:15,714 iteration 334 : loss : 0.138982, loss_ce: 0.067043
2022-01-20 20:59:16,323 iteration 335 : loss : 0.156180, loss_ce: 0.057375
2022-01-20 20:59:17,002 iteration 336 : loss : 0.108904, loss_ce: 0.049843
2022-01-20 20:59:17,631 iteration 337 : loss : 0.111741, loss_ce: 0.047879
2022-01-20 20:59:18,221 iteration 338 : loss : 0.156850, loss_ce: 0.081871
2022-01-20 20:59:18,815 iteration 339 : loss : 0.143824, loss_ce: 0.057160
2022-01-20 20:59:18,816 Training Data Eval:
2022-01-20 20:59:21,714   Average segmentation loss on training set: 0.1101
2022-01-20 20:59:21,715 Validation Data Eval:
2022-01-20 20:59:22,670   Average segmentation loss on validation set: 0.1629
2022-01-20 20:59:23,201 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 20:59:23,888 iteration 340 : loss : 0.142098, loss_ce: 0.060657
  5%|█▌                            | 20/400 [03:53<1:19:22, 12.53s/it]2022-01-20 20:59:24,620 iteration 341 : loss : 0.100055, loss_ce: 0.051549
2022-01-20 20:59:25,283 iteration 342 : loss : 0.115324, loss_ce: 0.047350
2022-01-20 20:59:25,916 iteration 343 : loss : 0.099778, loss_ce: 0.051047
2022-01-20 20:59:26,592 iteration 344 : loss : 0.160923, loss_ce: 0.081204
2022-01-20 20:59:27,218 iteration 345 : loss : 0.093614, loss_ce: 0.040818
2022-01-20 20:59:27,911 iteration 346 : loss : 0.142268, loss_ce: 0.065866
2022-01-20 20:59:28,492 iteration 347 : loss : 0.121737, loss_ce: 0.064992
2022-01-20 20:59:29,147 iteration 348 : loss : 0.125382, loss_ce: 0.052855
2022-01-20 20:59:29,910 iteration 349 : loss : 0.122273, loss_ce: 0.061412
2022-01-20 20:59:30,538 iteration 350 : loss : 0.097816, loss_ce: 0.045987
2022-01-20 20:59:31,233 iteration 351 : loss : 0.110510, loss_ce: 0.056177
2022-01-20 20:59:31,907 iteration 352 : loss : 0.128549, loss_ce: 0.056927
2022-01-20 20:59:32,492 iteration 353 : loss : 0.110836, loss_ce: 0.053635
2022-01-20 20:59:33,139 iteration 354 : loss : 0.155014, loss_ce: 0.068742
2022-01-20 20:59:33,830 iteration 355 : loss : 0.122497, loss_ce: 0.056092
2022-01-20 20:59:34,592 iteration 356 : loss : 0.126024, loss_ce: 0.059519
2022-01-20 20:59:35,162 iteration 357 : loss : 0.095742, loss_ce: 0.047545
  5%|█▌                            | 21/400 [04:04<1:16:46, 12.16s/it]2022-01-20 20:59:35,868 iteration 358 : loss : 0.095555, loss_ce: 0.048642
2022-01-20 20:59:36,586 iteration 359 : loss : 0.143359, loss_ce: 0.060248
2022-01-20 20:59:37,173 iteration 360 : loss : 0.086167, loss_ce: 0.037903
2022-01-20 20:59:37,856 iteration 361 : loss : 0.134096, loss_ce: 0.050337
2022-01-20 20:59:38,585 iteration 362 : loss : 0.145783, loss_ce: 0.049794
2022-01-20 20:59:39,307 iteration 363 : loss : 0.124745, loss_ce: 0.050010
2022-01-20 20:59:39,971 iteration 364 : loss : 0.113957, loss_ce: 0.051924
2022-01-20 20:59:40,516 iteration 365 : loss : 0.125113, loss_ce: 0.069875
2022-01-20 20:59:41,189 iteration 366 : loss : 0.113298, loss_ce: 0.054115
2022-01-20 20:59:41,754 iteration 367 : loss : 0.105571, loss_ce: 0.049307
2022-01-20 20:59:42,429 iteration 368 : loss : 0.123602, loss_ce: 0.048519
2022-01-20 20:59:43,144 iteration 369 : loss : 0.129707, loss_ce: 0.049531
2022-01-20 20:59:43,843 iteration 370 : loss : 0.157203, loss_ce: 0.074576
2022-01-20 20:59:44,506 iteration 371 : loss : 0.139481, loss_ce: 0.048006
2022-01-20 20:59:45,180 iteration 372 : loss : 0.177222, loss_ce: 0.088240
2022-01-20 20:59:45,770 iteration 373 : loss : 0.131256, loss_ce: 0.049985
2022-01-20 20:59:46,396 iteration 374 : loss : 0.126540, loss_ce: 0.060370
  6%|█▋                            | 22/400 [04:15<1:14:51, 11.88s/it]2022-01-20 20:59:47,142 iteration 375 : loss : 0.168669, loss_ce: 0.075385
2022-01-20 20:59:47,738 iteration 376 : loss : 0.078908, loss_ce: 0.035414
2022-01-20 20:59:48,367 iteration 377 : loss : 0.110055, loss_ce: 0.042045
2022-01-20 20:59:49,082 iteration 378 : loss : 0.160016, loss_ce: 0.062217
2022-01-20 20:59:49,640 iteration 379 : loss : 0.129128, loss_ce: 0.061251
2022-01-20 20:59:50,318 iteration 380 : loss : 0.081545, loss_ce: 0.035572
2022-01-20 20:59:50,955 iteration 381 : loss : 0.070077, loss_ce: 0.034133
2022-01-20 20:59:51,514 iteration 382 : loss : 0.116274, loss_ce: 0.062383
2022-01-20 20:59:52,152 iteration 383 : loss : 0.161366, loss_ce: 0.068196
2022-01-20 20:59:52,818 iteration 384 : loss : 0.086972, loss_ce: 0.042845
2022-01-20 20:59:53,459 iteration 385 : loss : 0.094395, loss_ce: 0.048101
2022-01-20 20:59:54,108 iteration 386 : loss : 0.114994, loss_ce: 0.048218
2022-01-20 20:59:54,771 iteration 387 : loss : 0.189569, loss_ce: 0.078329
2022-01-20 20:59:55,445 iteration 388 : loss : 0.132691, loss_ce: 0.064284
2022-01-20 20:59:56,109 iteration 389 : loss : 0.156982, loss_ce: 0.066505
2022-01-20 20:59:56,727 iteration 390 : loss : 0.082369, loss_ce: 0.040912
2022-01-20 20:59:57,343 iteration 391 : loss : 0.117309, loss_ce: 0.072597
  6%|█▋                            | 23/400 [04:26<1:12:52, 11.60s/it]2022-01-20 20:59:58,043 iteration 392 : loss : 0.102204, loss_ce: 0.060911
2022-01-20 20:59:58,644 iteration 393 : loss : 0.094956, loss_ce: 0.043459
2022-01-20 20:59:59,336 iteration 394 : loss : 0.095107, loss_ce: 0.043038
2022-01-20 20:59:59,998 iteration 395 : loss : 0.116398, loss_ce: 0.055398
2022-01-20 21:00:00,610 iteration 396 : loss : 0.100407, loss_ce: 0.043354
2022-01-20 21:00:01,248 iteration 397 : loss : 0.103969, loss_ce: 0.053344
2022-01-20 21:00:01,909 iteration 398 : loss : 0.096450, loss_ce: 0.046890
2022-01-20 21:00:02,446 iteration 399 : loss : 0.103568, loss_ce: 0.050159
2022-01-20 21:00:03,093 iteration 400 : loss : 0.101770, loss_ce: 0.045424
2022-01-20 21:00:03,792 iteration 401 : loss : 0.106797, loss_ce: 0.056482
2022-01-20 21:00:04,412 iteration 402 : loss : 0.088570, loss_ce: 0.045242
2022-01-20 21:00:05,024 iteration 403 : loss : 0.074406, loss_ce: 0.035932
2022-01-20 21:00:05,691 iteration 404 : loss : 0.103972, loss_ce: 0.050497
2022-01-20 21:00:06,397 iteration 405 : loss : 0.119527, loss_ce: 0.054030
2022-01-20 21:00:07,009 iteration 406 : loss : 0.115555, loss_ce: 0.050580
2022-01-20 21:00:07,584 iteration 407 : loss : 0.114846, loss_ce: 0.045614
2022-01-20 21:00:08,202 iteration 408 : loss : 0.118995, loss_ce: 0.045451
  6%|█▊                            | 24/400 [04:37<1:11:18, 11.38s/it]2022-01-20 21:00:08,906 iteration 409 : loss : 0.101491, loss_ce: 0.054898
2022-01-20 21:00:09,574 iteration 410 : loss : 0.112753, loss_ce: 0.046990
2022-01-20 21:00:10,209 iteration 411 : loss : 0.186354, loss_ce: 0.057103
2022-01-20 21:00:10,753 iteration 412 : loss : 0.065925, loss_ce: 0.031124
2022-01-20 21:00:11,392 iteration 413 : loss : 0.104332, loss_ce: 0.041369
2022-01-20 21:00:11,972 iteration 414 : loss : 0.118007, loss_ce: 0.060176
2022-01-20 21:00:12,501 iteration 415 : loss : 0.077153, loss_ce: 0.035222
2022-01-20 21:00:13,124 iteration 416 : loss : 0.101844, loss_ce: 0.054556
2022-01-20 21:00:13,715 iteration 417 : loss : 0.120869, loss_ce: 0.054074
2022-01-20 21:00:14,419 iteration 418 : loss : 0.113445, loss_ce: 0.053550
2022-01-20 21:00:15,038 iteration 419 : loss : 0.087099, loss_ce: 0.050951
2022-01-20 21:00:15,689 iteration 420 : loss : 0.096282, loss_ce: 0.046423
2022-01-20 21:00:16,274 iteration 421 : loss : 0.120326, loss_ce: 0.051722
2022-01-20 21:00:16,855 iteration 422 : loss : 0.136053, loss_ce: 0.058055
2022-01-20 21:00:17,446 iteration 423 : loss : 0.113325, loss_ce: 0.046165
2022-01-20 21:00:18,094 iteration 424 : loss : 0.112107, loss_ce: 0.055657
2022-01-20 21:00:18,094 Training Data Eval:
2022-01-20 21:00:20,998   Average segmentation loss on training set: 0.0840
2022-01-20 21:00:20,999 Validation Data Eval:
2022-01-20 21:00:21,953   Average segmentation loss on validation set: 0.1513
2022-01-20 21:00:22,489 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:00:23,098 iteration 425 : loss : 0.085275, loss_ce: 0.043742
  6%|█▉                            | 25/400 [04:52<1:17:42, 12.43s/it]2022-01-20 21:00:23,718 iteration 426 : loss : 0.090671, loss_ce: 0.039542
2022-01-20 21:00:24,387 iteration 427 : loss : 0.076189, loss_ce: 0.034833
2022-01-20 21:00:25,020 iteration 428 : loss : 0.108041, loss_ce: 0.046689
2022-01-20 21:00:25,600 iteration 429 : loss : 0.132270, loss_ce: 0.075029
2022-01-20 21:00:26,168 iteration 430 : loss : 0.108650, loss_ce: 0.046144
2022-01-20 21:00:26,766 iteration 431 : loss : 0.187958, loss_ce: 0.069870
2022-01-20 21:00:27,421 iteration 432 : loss : 0.092274, loss_ce: 0.041835
2022-01-20 21:00:28,117 iteration 433 : loss : 0.091114, loss_ce: 0.041556
2022-01-20 21:00:28,763 iteration 434 : loss : 0.074484, loss_ce: 0.035239
2022-01-20 21:00:29,344 iteration 435 : loss : 0.074773, loss_ce: 0.036536
2022-01-20 21:00:29,956 iteration 436 : loss : 0.085156, loss_ce: 0.043083
2022-01-20 21:00:30,580 iteration 437 : loss : 0.112161, loss_ce: 0.059704
2022-01-20 21:00:31,148 iteration 438 : loss : 0.103424, loss_ce: 0.040623
2022-01-20 21:00:31,791 iteration 439 : loss : 0.126560, loss_ce: 0.045375
2022-01-20 21:00:32,407 iteration 440 : loss : 0.109483, loss_ce: 0.046147
2022-01-20 21:00:33,084 iteration 441 : loss : 0.118823, loss_ce: 0.050492
2022-01-20 21:00:33,737 iteration 442 : loss : 0.091474, loss_ce: 0.046243
  6%|█▉                            | 26/400 [05:03<1:14:09, 11.90s/it]2022-01-20 21:00:34,386 iteration 443 : loss : 0.109388, loss_ce: 0.054123
2022-01-20 21:00:34,960 iteration 444 : loss : 0.095980, loss_ce: 0.040377
2022-01-20 21:00:35,572 iteration 445 : loss : 0.123143, loss_ce: 0.051501
2022-01-20 21:00:36,322 iteration 446 : loss : 0.121944, loss_ce: 0.052622
2022-01-20 21:00:37,020 iteration 447 : loss : 0.089315, loss_ce: 0.050784
2022-01-20 21:00:37,707 iteration 448 : loss : 0.217371, loss_ce: 0.069195
2022-01-20 21:00:38,353 iteration 449 : loss : 0.108379, loss_ce: 0.053041
2022-01-20 21:00:38,973 iteration 450 : loss : 0.092262, loss_ce: 0.036429
2022-01-20 21:00:39,692 iteration 451 : loss : 0.065965, loss_ce: 0.033236
2022-01-20 21:00:40,357 iteration 452 : loss : 0.076446, loss_ce: 0.036610
2022-01-20 21:00:41,014 iteration 453 : loss : 0.111516, loss_ce: 0.049056
2022-01-20 21:00:41,675 iteration 454 : loss : 0.133946, loss_ce: 0.050436
2022-01-20 21:00:42,367 iteration 455 : loss : 0.080224, loss_ce: 0.035194
2022-01-20 21:00:43,016 iteration 456 : loss : 0.088963, loss_ce: 0.037786
2022-01-20 21:00:43,658 iteration 457 : loss : 0.125710, loss_ce: 0.054085
2022-01-20 21:00:44,382 iteration 458 : loss : 0.091912, loss_ce: 0.044514
2022-01-20 21:00:44,963 iteration 459 : loss : 0.065323, loss_ce: 0.029823
  7%|██                            | 27/400 [05:14<1:12:41, 11.69s/it]2022-01-20 21:00:45,664 iteration 460 : loss : 0.102266, loss_ce: 0.051970
2022-01-20 21:00:46,323 iteration 461 : loss : 0.078765, loss_ce: 0.039214
2022-01-20 21:00:46,945 iteration 462 : loss : 0.085834, loss_ce: 0.044678
2022-01-20 21:00:47,643 iteration 463 : loss : 0.105813, loss_ce: 0.053403
2022-01-20 21:00:48,285 iteration 464 : loss : 0.077861, loss_ce: 0.035848
2022-01-20 21:00:48,873 iteration 465 : loss : 0.109881, loss_ce: 0.037885
2022-01-20 21:00:49,493 iteration 466 : loss : 0.085681, loss_ce: 0.036055
2022-01-20 21:00:50,101 iteration 467 : loss : 0.116117, loss_ce: 0.048690
2022-01-20 21:00:50,840 iteration 468 : loss : 0.081095, loss_ce: 0.040831
2022-01-20 21:00:51,463 iteration 469 : loss : 0.074692, loss_ce: 0.030102
2022-01-20 21:00:52,100 iteration 470 : loss : 0.135764, loss_ce: 0.052701
2022-01-20 21:00:52,735 iteration 471 : loss : 0.095386, loss_ce: 0.036625
2022-01-20 21:00:53,429 iteration 472 : loss : 0.106810, loss_ce: 0.046496
2022-01-20 21:00:54,206 iteration 473 : loss : 0.108483, loss_ce: 0.047193
2022-01-20 21:00:54,937 iteration 474 : loss : 0.132471, loss_ce: 0.051387
2022-01-20 21:00:55,557 iteration 475 : loss : 0.080641, loss_ce: 0.036556
2022-01-20 21:00:56,260 iteration 476 : loss : 0.097040, loss_ce: 0.049622
  7%|██                            | 28/400 [05:25<1:11:45, 11.57s/it]2022-01-20 21:00:56,942 iteration 477 : loss : 0.095159, loss_ce: 0.037397
2022-01-20 21:00:57,622 iteration 478 : loss : 0.077631, loss_ce: 0.032824
2022-01-20 21:00:58,256 iteration 479 : loss : 0.108636, loss_ce: 0.046498
2022-01-20 21:00:58,920 iteration 480 : loss : 0.092828, loss_ce: 0.045073
2022-01-20 21:00:59,481 iteration 481 : loss : 0.095857, loss_ce: 0.041194
2022-01-20 21:01:00,142 iteration 482 : loss : 0.120157, loss_ce: 0.039562
2022-01-20 21:01:00,811 iteration 483 : loss : 0.115474, loss_ce: 0.045129
2022-01-20 21:01:01,496 iteration 484 : loss : 0.135900, loss_ce: 0.062580
2022-01-20 21:01:02,115 iteration 485 : loss : 0.081497, loss_ce: 0.039441
2022-01-20 21:01:02,721 iteration 486 : loss : 0.102725, loss_ce: 0.038644
2022-01-20 21:01:03,410 iteration 487 : loss : 0.073747, loss_ce: 0.032432
2022-01-20 21:01:03,988 iteration 488 : loss : 0.092271, loss_ce: 0.038488
2022-01-20 21:01:04,624 iteration 489 : loss : 0.102001, loss_ce: 0.051833
2022-01-20 21:01:05,155 iteration 490 : loss : 0.088588, loss_ce: 0.039964
2022-01-20 21:01:05,796 iteration 491 : loss : 0.097451, loss_ce: 0.050417
2022-01-20 21:01:06,413 iteration 492 : loss : 0.062983, loss_ce: 0.036760
2022-01-20 21:01:07,079 iteration 493 : loss : 0.090909, loss_ce: 0.046448
  7%|██▏                           | 29/400 [05:36<1:10:10, 11.35s/it]2022-01-20 21:01:07,749 iteration 494 : loss : 0.094557, loss_ce: 0.043413
2022-01-20 21:01:08,425 iteration 495 : loss : 0.105213, loss_ce: 0.039040
2022-01-20 21:01:09,053 iteration 496 : loss : 0.106335, loss_ce: 0.054634
2022-01-20 21:01:09,723 iteration 497 : loss : 0.138423, loss_ce: 0.075389
2022-01-20 21:01:10,433 iteration 498 : loss : 0.124058, loss_ce: 0.068199
2022-01-20 21:01:11,008 iteration 499 : loss : 0.070468, loss_ce: 0.035928
2022-01-20 21:01:11,597 iteration 500 : loss : 0.100774, loss_ce: 0.042854
2022-01-20 21:01:12,187 iteration 501 : loss : 0.104789, loss_ce: 0.051444
2022-01-20 21:01:12,887 iteration 502 : loss : 0.080837, loss_ce: 0.040933
2022-01-20 21:01:13,488 iteration 503 : loss : 0.126450, loss_ce: 0.042495
2022-01-20 21:01:14,152 iteration 504 : loss : 0.122595, loss_ce: 0.046584
2022-01-20 21:01:14,743 iteration 505 : loss : 0.079857, loss_ce: 0.036282
2022-01-20 21:01:15,468 iteration 506 : loss : 0.058421, loss_ce: 0.028825
2022-01-20 21:01:16,112 iteration 507 : loss : 0.125502, loss_ce: 0.046917
2022-01-20 21:01:16,754 iteration 508 : loss : 0.103251, loss_ce: 0.047528
2022-01-20 21:01:17,435 iteration 509 : loss : 0.086275, loss_ce: 0.033799
2022-01-20 21:01:17,436 Training Data Eval:
2022-01-20 21:01:20,332   Average segmentation loss on training set: 0.1160
2022-01-20 21:01:20,332 Validation Data Eval:
2022-01-20 21:01:21,287   Average segmentation loss on validation set: 0.1647
2022-01-20 21:01:21,966 iteration 510 : loss : 0.082729, loss_ce: 0.036839
  8%|██▎                           | 30/400 [05:51<1:16:30, 12.41s/it]2022-01-20 21:01:22,655 iteration 511 : loss : 0.092453, loss_ce: 0.043097
2022-01-20 21:01:23,244 iteration 512 : loss : 0.083888, loss_ce: 0.036798
2022-01-20 21:01:23,852 iteration 513 : loss : 0.062344, loss_ce: 0.024968
2022-01-20 21:01:24,478 iteration 514 : loss : 0.084748, loss_ce: 0.038203
2022-01-20 21:01:25,086 iteration 515 : loss : 0.095041, loss_ce: 0.043069
2022-01-20 21:01:25,739 iteration 516 : loss : 0.084189, loss_ce: 0.033968
2022-01-20 21:01:26,433 iteration 517 : loss : 0.088754, loss_ce: 0.044122
2022-01-20 21:01:27,021 iteration 518 : loss : 0.085127, loss_ce: 0.033807
2022-01-20 21:01:27,666 iteration 519 : loss : 0.079542, loss_ce: 0.038871
2022-01-20 21:01:28,251 iteration 520 : loss : 0.069446, loss_ce: 0.032974
2022-01-20 21:01:28,893 iteration 521 : loss : 0.085922, loss_ce: 0.034551
2022-01-20 21:01:29,576 iteration 522 : loss : 0.078012, loss_ce: 0.031128
2022-01-20 21:01:30,291 iteration 523 : loss : 0.099070, loss_ce: 0.046785
2022-01-20 21:01:31,024 iteration 524 : loss : 0.083984, loss_ce: 0.039972
2022-01-20 21:01:31,659 iteration 525 : loss : 0.120853, loss_ce: 0.059466
2022-01-20 21:01:32,284 iteration 526 : loss : 0.102770, loss_ce: 0.048981
2022-01-20 21:01:32,914 iteration 527 : loss : 0.077121, loss_ce: 0.031935
  8%|██▎                           | 31/400 [06:02<1:13:37, 11.97s/it]2022-01-20 21:01:33,559 iteration 528 : loss : 0.087158, loss_ce: 0.047480
2022-01-20 21:01:34,202 iteration 529 : loss : 0.081896, loss_ce: 0.030833
2022-01-20 21:01:34,796 iteration 530 : loss : 0.097864, loss_ce: 0.039738
2022-01-20 21:01:35,375 iteration 531 : loss : 0.088133, loss_ce: 0.031911
2022-01-20 21:01:35,968 iteration 532 : loss : 0.091633, loss_ce: 0.043107
2022-01-20 21:01:36,698 iteration 533 : loss : 0.064823, loss_ce: 0.032248
2022-01-20 21:01:37,279 iteration 534 : loss : 0.062755, loss_ce: 0.033107
2022-01-20 21:01:37,963 iteration 535 : loss : 0.105160, loss_ce: 0.041523
2022-01-20 21:01:38,683 iteration 536 : loss : 0.117398, loss_ce: 0.057316
2022-01-20 21:01:39,416 iteration 537 : loss : 0.096626, loss_ce: 0.038143
2022-01-20 21:01:40,073 iteration 538 : loss : 0.084635, loss_ce: 0.042054
2022-01-20 21:01:40,692 iteration 539 : loss : 0.097010, loss_ce: 0.043516
2022-01-20 21:01:41,345 iteration 540 : loss : 0.121701, loss_ce: 0.043358
2022-01-20 21:01:41,957 iteration 541 : loss : 0.086887, loss_ce: 0.045830
2022-01-20 21:01:42,588 iteration 542 : loss : 0.100772, loss_ce: 0.050379
2022-01-20 21:01:43,169 iteration 543 : loss : 0.051996, loss_ce: 0.024305
2022-01-20 21:01:43,780 iteration 544 : loss : 0.069490, loss_ce: 0.029389
  8%|██▍                           | 32/400 [06:13<1:11:23, 11.64s/it]2022-01-20 21:01:44,483 iteration 545 : loss : 0.064827, loss_ce: 0.035749
2022-01-20 21:01:45,122 iteration 546 : loss : 0.076023, loss_ce: 0.034452
2022-01-20 21:01:45,761 iteration 547 : loss : 0.080603, loss_ce: 0.036836
2022-01-20 21:01:46,386 iteration 548 : loss : 0.130597, loss_ce: 0.050561
2022-01-20 21:01:47,050 iteration 549 : loss : 0.072977, loss_ce: 0.035009
2022-01-20 21:01:47,653 iteration 550 : loss : 0.064970, loss_ce: 0.026429
2022-01-20 21:01:48,278 iteration 551 : loss : 0.077047, loss_ce: 0.035333
2022-01-20 21:01:48,879 iteration 552 : loss : 0.076569, loss_ce: 0.031519
2022-01-20 21:01:49,546 iteration 553 : loss : 0.065354, loss_ce: 0.032503
2022-01-20 21:01:50,123 iteration 554 : loss : 0.072385, loss_ce: 0.036301
2022-01-20 21:01:50,748 iteration 555 : loss : 0.094920, loss_ce: 0.034553
2022-01-20 21:01:51,423 iteration 556 : loss : 0.083739, loss_ce: 0.039625
2022-01-20 21:01:51,978 iteration 557 : loss : 0.066152, loss_ce: 0.029141
2022-01-20 21:01:52,648 iteration 558 : loss : 0.092459, loss_ce: 0.033503
2022-01-20 21:01:53,279 iteration 559 : loss : 0.082576, loss_ce: 0.035190
2022-01-20 21:01:53,934 iteration 560 : loss : 0.081432, loss_ce: 0.024775
2022-01-20 21:01:54,620 iteration 561 : loss : 0.122969, loss_ce: 0.066963
  8%|██▍                           | 33/400 [06:24<1:09:44, 11.40s/it]2022-01-20 21:01:55,413 iteration 562 : loss : 0.122394, loss_ce: 0.061028
2022-01-20 21:01:55,960 iteration 563 : loss : 0.086976, loss_ce: 0.041168
2022-01-20 21:01:56,625 iteration 564 : loss : 0.105051, loss_ce: 0.062654
2022-01-20 21:01:57,288 iteration 565 : loss : 0.067323, loss_ce: 0.033793
2022-01-20 21:01:57,975 iteration 566 : loss : 0.086237, loss_ce: 0.039115
2022-01-20 21:01:58,584 iteration 567 : loss : 0.079753, loss_ce: 0.032365
2022-01-20 21:01:59,183 iteration 568 : loss : 0.150678, loss_ce: 0.064329
2022-01-20 21:01:59,811 iteration 569 : loss : 0.084110, loss_ce: 0.037229
2022-01-20 21:02:00,474 iteration 570 : loss : 0.078051, loss_ce: 0.040181
2022-01-20 21:02:01,089 iteration 571 : loss : 0.108122, loss_ce: 0.044774
2022-01-20 21:02:01,742 iteration 572 : loss : 0.077068, loss_ce: 0.031172
2022-01-20 21:02:02,341 iteration 573 : loss : 0.073840, loss_ce: 0.030391
2022-01-20 21:02:02,975 iteration 574 : loss : 0.073570, loss_ce: 0.027074
2022-01-20 21:02:03,672 iteration 575 : loss : 0.095517, loss_ce: 0.032303
2022-01-20 21:02:04,350 iteration 576 : loss : 0.120600, loss_ce: 0.053395
2022-01-20 21:02:04,987 iteration 577 : loss : 0.055429, loss_ce: 0.030738
2022-01-20 21:02:05,583 iteration 578 : loss : 0.075096, loss_ce: 0.036415
  8%|██▌                           | 34/400 [06:35<1:08:44, 11.27s/it]2022-01-20 21:02:06,434 iteration 579 : loss : 0.079082, loss_ce: 0.041989
2022-01-20 21:02:07,091 iteration 580 : loss : 0.098100, loss_ce: 0.039743
2022-01-20 21:02:07,780 iteration 581 : loss : 0.089867, loss_ce: 0.028764
2022-01-20 21:02:08,404 iteration 582 : loss : 0.097809, loss_ce: 0.042782
2022-01-20 21:02:09,045 iteration 583 : loss : 0.121067, loss_ce: 0.038822
2022-01-20 21:02:09,646 iteration 584 : loss : 0.061810, loss_ce: 0.030710
2022-01-20 21:02:10,330 iteration 585 : loss : 0.068077, loss_ce: 0.032106
2022-01-20 21:02:10,923 iteration 586 : loss : 0.100242, loss_ce: 0.041256
2022-01-20 21:02:11,509 iteration 587 : loss : 0.068185, loss_ce: 0.035210
2022-01-20 21:02:12,165 iteration 588 : loss : 0.073093, loss_ce: 0.031279
2022-01-20 21:02:12,783 iteration 589 : loss : 0.073957, loss_ce: 0.033103
2022-01-20 21:02:13,416 iteration 590 : loss : 0.076552, loss_ce: 0.032658
2022-01-20 21:02:14,055 iteration 591 : loss : 0.093786, loss_ce: 0.042347
2022-01-20 21:02:14,689 iteration 592 : loss : 0.078280, loss_ce: 0.033261
2022-01-20 21:02:15,356 iteration 593 : loss : 0.075232, loss_ce: 0.030209
2022-01-20 21:02:16,003 iteration 594 : loss : 0.075009, loss_ce: 0.034398
2022-01-20 21:02:16,003 Training Data Eval:
2022-01-20 21:02:18,901   Average segmentation loss on training set: 0.0589
2022-01-20 21:02:18,901 Validation Data Eval:
2022-01-20 21:02:19,857   Average segmentation loss on validation set: 0.1158
2022-01-20 21:02:20,397 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:02:21,105 iteration 595 : loss : 0.092573, loss_ce: 0.046849
  9%|██▋                           | 35/400 [06:50<1:16:18, 12.54s/it]2022-01-20 21:02:21,789 iteration 596 : loss : 0.083273, loss_ce: 0.034968
2022-01-20 21:02:22,393 iteration 597 : loss : 0.097401, loss_ce: 0.033193
2022-01-20 21:02:22,986 iteration 598 : loss : 0.057544, loss_ce: 0.023340
2022-01-20 21:02:23,608 iteration 599 : loss : 0.071953, loss_ce: 0.033203
2022-01-20 21:02:24,222 iteration 600 : loss : 0.085598, loss_ce: 0.041530
2022-01-20 21:02:24,865 iteration 601 : loss : 0.074967, loss_ce: 0.032427
2022-01-20 21:02:25,521 iteration 602 : loss : 0.058461, loss_ce: 0.027594
2022-01-20 21:02:26,087 iteration 603 : loss : 0.072938, loss_ce: 0.028845
2022-01-20 21:02:26,669 iteration 604 : loss : 0.060068, loss_ce: 0.023609
2022-01-20 21:02:27,240 iteration 605 : loss : 0.071045, loss_ce: 0.026314
2022-01-20 21:02:28,007 iteration 606 : loss : 0.059721, loss_ce: 0.030133
2022-01-20 21:02:28,631 iteration 607 : loss : 0.072609, loss_ce: 0.033657
2022-01-20 21:02:29,257 iteration 608 : loss : 0.091841, loss_ce: 0.046601
2022-01-20 21:02:29,807 iteration 609 : loss : 0.071648, loss_ce: 0.035416
2022-01-20 21:02:30,477 iteration 610 : loss : 0.062483, loss_ce: 0.029335
2022-01-20 21:02:31,213 iteration 611 : loss : 0.079518, loss_ce: 0.040978
2022-01-20 21:02:31,878 iteration 612 : loss : 0.105114, loss_ce: 0.039680
  9%|██▋                           | 36/400 [07:01<1:12:53, 12.02s/it]2022-01-20 21:02:32,591 iteration 613 : loss : 0.070552, loss_ce: 0.030781
2022-01-20 21:02:33,189 iteration 614 : loss : 0.076852, loss_ce: 0.031396
2022-01-20 21:02:33,782 iteration 615 : loss : 0.106094, loss_ce: 0.051532
2022-01-20 21:02:34,494 iteration 616 : loss : 0.071306, loss_ce: 0.031713
2022-01-20 21:02:35,094 iteration 617 : loss : 0.079977, loss_ce: 0.037172
2022-01-20 21:02:35,734 iteration 618 : loss : 0.132409, loss_ce: 0.036727
2022-01-20 21:02:36,375 iteration 619 : loss : 0.117646, loss_ce: 0.057655
2022-01-20 21:02:37,109 iteration 620 : loss : 0.164406, loss_ce: 0.051062
2022-01-20 21:02:37,761 iteration 621 : loss : 0.060431, loss_ce: 0.024407
2022-01-20 21:02:38,531 iteration 622 : loss : 0.081157, loss_ce: 0.030168
2022-01-20 21:02:39,266 iteration 623 : loss : 0.119058, loss_ce: 0.060342
2022-01-20 21:02:39,898 iteration 624 : loss : 0.086867, loss_ce: 0.031525
2022-01-20 21:02:40,488 iteration 625 : loss : 0.071307, loss_ce: 0.033064
2022-01-20 21:02:41,176 iteration 626 : loss : 0.072366, loss_ce: 0.034400
2022-01-20 21:02:41,881 iteration 627 : loss : 0.092794, loss_ce: 0.037381
2022-01-20 21:02:42,623 iteration 628 : loss : 0.077393, loss_ce: 0.033471
2022-01-20 21:02:43,250 iteration 629 : loss : 0.060143, loss_ce: 0.026244
  9%|██▊                           | 37/400 [07:12<1:11:30, 11.82s/it]2022-01-20 21:02:43,960 iteration 630 : loss : 0.058153, loss_ce: 0.030386
2022-01-20 21:02:44,575 iteration 631 : loss : 0.039671, loss_ce: 0.020566
2022-01-20 21:02:45,189 iteration 632 : loss : 0.099724, loss_ce: 0.039444
2022-01-20 21:02:45,903 iteration 633 : loss : 0.067268, loss_ce: 0.028935
2022-01-20 21:02:46,550 iteration 634 : loss : 0.093677, loss_ce: 0.036374
2022-01-20 21:02:47,294 iteration 635 : loss : 0.079766, loss_ce: 0.035225
2022-01-20 21:02:47,959 iteration 636 : loss : 0.071897, loss_ce: 0.030950
2022-01-20 21:02:48,531 iteration 637 : loss : 0.064647, loss_ce: 0.030085
2022-01-20 21:02:49,248 iteration 638 : loss : 0.111487, loss_ce: 0.039861
2022-01-20 21:02:49,851 iteration 639 : loss : 0.052641, loss_ce: 0.025547
2022-01-20 21:02:50,425 iteration 640 : loss : 0.131023, loss_ce: 0.042331
2022-01-20 21:02:51,002 iteration 641 : loss : 0.074122, loss_ce: 0.033985
2022-01-20 21:02:51,587 iteration 642 : loss : 0.072494, loss_ce: 0.024358
2022-01-20 21:02:52,204 iteration 643 : loss : 0.085245, loss_ce: 0.037685
2022-01-20 21:02:52,830 iteration 644 : loss : 0.085492, loss_ce: 0.037829
2022-01-20 21:02:53,421 iteration 645 : loss : 0.083922, loss_ce: 0.027454
2022-01-20 21:02:54,120 iteration 646 : loss : 0.085360, loss_ce: 0.039484
 10%|██▊                           | 38/400 [07:23<1:09:35, 11.53s/it]2022-01-20 21:02:54,780 iteration 647 : loss : 0.110108, loss_ce: 0.049128
2022-01-20 21:02:55,426 iteration 648 : loss : 0.063536, loss_ce: 0.029729
2022-01-20 21:02:56,096 iteration 649 : loss : 0.085997, loss_ce: 0.040391
2022-01-20 21:02:56,804 iteration 650 : loss : 0.092278, loss_ce: 0.039512
2022-01-20 21:02:57,435 iteration 651 : loss : 0.069434, loss_ce: 0.027729
2022-01-20 21:02:57,966 iteration 652 : loss : 0.059426, loss_ce: 0.025511
2022-01-20 21:02:58,670 iteration 653 : loss : 0.103485, loss_ce: 0.042566
2022-01-20 21:02:59,254 iteration 654 : loss : 0.080449, loss_ce: 0.030098
2022-01-20 21:02:59,886 iteration 655 : loss : 0.095521, loss_ce: 0.036572
2022-01-20 21:03:00,531 iteration 656 : loss : 0.065044, loss_ce: 0.029886
2022-01-20 21:03:01,248 iteration 657 : loss : 0.050172, loss_ce: 0.022592
2022-01-20 21:03:01,923 iteration 658 : loss : 0.066229, loss_ce: 0.026944
2022-01-20 21:03:02,596 iteration 659 : loss : 0.076885, loss_ce: 0.030504
2022-01-20 21:03:03,207 iteration 660 : loss : 0.076994, loss_ce: 0.035090
2022-01-20 21:03:03,870 iteration 661 : loss : 0.091095, loss_ce: 0.040353
2022-01-20 21:03:04,606 iteration 662 : loss : 0.098204, loss_ce: 0.025541
2022-01-20 21:03:05,248 iteration 663 : loss : 0.073146, loss_ce: 0.032192
 10%|██▉                           | 39/400 [07:34<1:08:39, 11.41s/it]2022-01-20 21:03:05,955 iteration 664 : loss : 0.052557, loss_ce: 0.025301
2022-01-20 21:03:06,524 iteration 665 : loss : 0.064505, loss_ce: 0.031317
2022-01-20 21:03:07,150 iteration 666 : loss : 0.057532, loss_ce: 0.019659
2022-01-20 21:03:07,827 iteration 667 : loss : 0.060267, loss_ce: 0.027909
2022-01-20 21:03:08,481 iteration 668 : loss : 0.082762, loss_ce: 0.033292
2022-01-20 21:03:09,102 iteration 669 : loss : 0.059113, loss_ce: 0.022441
2022-01-20 21:03:09,870 iteration 670 : loss : 0.074201, loss_ce: 0.033688
2022-01-20 21:03:10,488 iteration 671 : loss : 0.064822, loss_ce: 0.025078
2022-01-20 21:03:11,195 iteration 672 : loss : 0.064787, loss_ce: 0.025478
2022-01-20 21:03:11,874 iteration 673 : loss : 0.069917, loss_ce: 0.031827
2022-01-20 21:03:12,539 iteration 674 : loss : 0.064608, loss_ce: 0.034203
2022-01-20 21:03:13,240 iteration 675 : loss : 0.102241, loss_ce: 0.051387
2022-01-20 21:03:13,880 iteration 676 : loss : 0.075220, loss_ce: 0.034009
2022-01-20 21:03:14,532 iteration 677 : loss : 0.049011, loss_ce: 0.026009
2022-01-20 21:03:15,205 iteration 678 : loss : 0.088933, loss_ce: 0.036552
2022-01-20 21:03:15,853 iteration 679 : loss : 0.093763, loss_ce: 0.042998
2022-01-20 21:03:15,853 Training Data Eval:
2022-01-20 21:03:18,756   Average segmentation loss on training set: 0.0564
2022-01-20 21:03:18,757 Validation Data Eval:
2022-01-20 21:03:19,712   Average segmentation loss on validation set: 0.1153
2022-01-20 21:03:20,268 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:03:20,902 iteration 680 : loss : 0.067008, loss_ce: 0.026298
 10%|███                           | 40/400 [07:50<1:16:06, 12.69s/it]2022-01-20 21:03:21,602 iteration 681 : loss : 0.060155, loss_ce: 0.024908
2022-01-20 21:03:22,162 iteration 682 : loss : 0.086961, loss_ce: 0.031811
2022-01-20 21:03:22,795 iteration 683 : loss : 0.072013, loss_ce: 0.033357
2022-01-20 21:03:23,389 iteration 684 : loss : 0.070662, loss_ce: 0.028442
2022-01-20 21:03:24,089 iteration 685 : loss : 0.078656, loss_ce: 0.030800
2022-01-20 21:03:24,731 iteration 686 : loss : 0.085267, loss_ce: 0.037700
2022-01-20 21:03:25,369 iteration 687 : loss : 0.065992, loss_ce: 0.032048
2022-01-20 21:03:25,985 iteration 688 : loss : 0.063881, loss_ce: 0.023553
2022-01-20 21:03:26,652 iteration 689 : loss : 0.058484, loss_ce: 0.026982
2022-01-20 21:03:27,283 iteration 690 : loss : 0.063083, loss_ce: 0.024917
2022-01-20 21:03:27,934 iteration 691 : loss : 0.072004, loss_ce: 0.027906
2022-01-20 21:03:28,633 iteration 692 : loss : 0.066393, loss_ce: 0.028106
2022-01-20 21:03:29,215 iteration 693 : loss : 0.068812, loss_ce: 0.033079
2022-01-20 21:03:29,873 iteration 694 : loss : 0.066488, loss_ce: 0.030944
2022-01-20 21:03:30,480 iteration 695 : loss : 0.076794, loss_ce: 0.031855
2022-01-20 21:03:31,181 iteration 696 : loss : 0.068732, loss_ce: 0.027922
2022-01-20 21:03:31,822 iteration 697 : loss : 0.076522, loss_ce: 0.037533
 10%|███                           | 41/400 [08:01<1:12:44, 12.16s/it]2022-01-20 21:03:32,464 iteration 698 : loss : 0.078528, loss_ce: 0.028749
2022-01-20 21:03:33,141 iteration 699 : loss : 0.080777, loss_ce: 0.041278
2022-01-20 21:03:33,753 iteration 700 : loss : 0.092381, loss_ce: 0.046395
2022-01-20 21:03:34,364 iteration 701 : loss : 0.076240, loss_ce: 0.041956
2022-01-20 21:03:35,040 iteration 702 : loss : 0.115586, loss_ce: 0.041483
2022-01-20 21:03:35,772 iteration 703 : loss : 0.059487, loss_ce: 0.028251
2022-01-20 21:03:36,352 iteration 704 : loss : 0.058371, loss_ce: 0.026176
2022-01-20 21:03:36,994 iteration 705 : loss : 0.071542, loss_ce: 0.030698
2022-01-20 21:03:37,642 iteration 706 : loss : 0.070168, loss_ce: 0.028526
2022-01-20 21:03:38,215 iteration 707 : loss : 0.052282, loss_ce: 0.023541
2022-01-20 21:03:38,843 iteration 708 : loss : 0.044579, loss_ce: 0.018919
2022-01-20 21:03:39,475 iteration 709 : loss : 0.084096, loss_ce: 0.035353
2022-01-20 21:03:40,144 iteration 710 : loss : 0.076752, loss_ce: 0.032497
2022-01-20 21:03:40,809 iteration 711 : loss : 0.065350, loss_ce: 0.030806
2022-01-20 21:03:41,535 iteration 712 : loss : 0.072564, loss_ce: 0.028773
2022-01-20 21:03:42,162 iteration 713 : loss : 0.062508, loss_ce: 0.030495
2022-01-20 21:03:42,874 iteration 714 : loss : 0.078105, loss_ce: 0.031877
 10%|███▏                          | 42/400 [08:12<1:10:33, 11.83s/it]2022-01-20 21:03:43,613 iteration 715 : loss : 0.057493, loss_ce: 0.024099
2022-01-20 21:03:44,306 iteration 716 : loss : 0.052548, loss_ce: 0.025219
2022-01-20 21:03:44,946 iteration 717 : loss : 0.056986, loss_ce: 0.023352
2022-01-20 21:03:45,600 iteration 718 : loss : 0.072710, loss_ce: 0.036188
2022-01-20 21:03:46,303 iteration 719 : loss : 0.078988, loss_ce: 0.034069
2022-01-20 21:03:46,943 iteration 720 : loss : 0.063456, loss_ce: 0.024889
2022-01-20 21:03:47,576 iteration 721 : loss : 0.062308, loss_ce: 0.022350
2022-01-20 21:03:48,203 iteration 722 : loss : 0.074593, loss_ce: 0.027317
2022-01-20 21:03:48,889 iteration 723 : loss : 0.086106, loss_ce: 0.046368
2022-01-20 21:03:49,510 iteration 724 : loss : 0.097924, loss_ce: 0.043874
2022-01-20 21:03:50,220 iteration 725 : loss : 0.075452, loss_ce: 0.030444
2022-01-20 21:03:50,858 iteration 726 : loss : 0.081628, loss_ce: 0.034157
2022-01-20 21:03:51,430 iteration 727 : loss : 0.052990, loss_ce: 0.022838
2022-01-20 21:03:52,107 iteration 728 : loss : 0.056158, loss_ce: 0.025402
2022-01-20 21:03:52,801 iteration 729 : loss : 0.062401, loss_ce: 0.028892
2022-01-20 21:03:53,467 iteration 730 : loss : 0.063174, loss_ce: 0.025350
2022-01-20 21:03:54,022 iteration 731 : loss : 0.049915, loss_ce: 0.020285
 11%|███▏                          | 43/400 [08:23<1:09:09, 11.62s/it]2022-01-20 21:03:54,646 iteration 732 : loss : 0.054016, loss_ce: 0.027410
2022-01-20 21:03:55,209 iteration 733 : loss : 0.070132, loss_ce: 0.035790
2022-01-20 21:03:55,890 iteration 734 : loss : 0.086710, loss_ce: 0.035105
2022-01-20 21:03:56,518 iteration 735 : loss : 0.090704, loss_ce: 0.038363
2022-01-20 21:03:57,126 iteration 736 : loss : 0.062845, loss_ce: 0.028447
2022-01-20 21:03:57,886 iteration 737 : loss : 0.066568, loss_ce: 0.028895
2022-01-20 21:03:58,436 iteration 738 : loss : 0.060336, loss_ce: 0.026856
2022-01-20 21:03:59,105 iteration 739 : loss : 0.074255, loss_ce: 0.033306
2022-01-20 21:03:59,722 iteration 740 : loss : 0.058070, loss_ce: 0.024599
2022-01-20 21:04:00,325 iteration 741 : loss : 0.056037, loss_ce: 0.023923
2022-01-20 21:04:00,882 iteration 742 : loss : 0.062992, loss_ce: 0.029911
2022-01-20 21:04:01,526 iteration 743 : loss : 0.054473, loss_ce: 0.024757
2022-01-20 21:04:02,191 iteration 744 : loss : 0.067474, loss_ce: 0.031690
2022-01-20 21:04:02,789 iteration 745 : loss : 0.093928, loss_ce: 0.023802
2022-01-20 21:04:03,398 iteration 746 : loss : 0.072013, loss_ce: 0.027152
2022-01-20 21:04:03,995 iteration 747 : loss : 0.070394, loss_ce: 0.030705
2022-01-20 21:04:04,579 iteration 748 : loss : 0.052813, loss_ce: 0.025761
 11%|███▎                          | 44/400 [08:34<1:07:03, 11.30s/it]2022-01-20 21:04:05,193 iteration 749 : loss : 0.157701, loss_ce: 0.033353
2022-01-20 21:04:05,801 iteration 750 : loss : 0.059110, loss_ce: 0.023042
2022-01-20 21:04:06,447 iteration 751 : loss : 0.066057, loss_ce: 0.021770
2022-01-20 21:04:07,056 iteration 752 : loss : 0.115850, loss_ce: 0.052038
2022-01-20 21:04:07,635 iteration 753 : loss : 0.077984, loss_ce: 0.036647
2022-01-20 21:04:08,221 iteration 754 : loss : 0.085950, loss_ce: 0.035364
2022-01-20 21:04:08,759 iteration 755 : loss : 0.068615, loss_ce: 0.038163
2022-01-20 21:04:09,307 iteration 756 : loss : 0.053981, loss_ce: 0.021175
2022-01-20 21:04:09,926 iteration 757 : loss : 0.095302, loss_ce: 0.048527
2022-01-20 21:04:10,638 iteration 758 : loss : 0.076391, loss_ce: 0.036097
2022-01-20 21:04:11,402 iteration 759 : loss : 0.087531, loss_ce: 0.034392
2022-01-20 21:04:12,021 iteration 760 : loss : 0.094046, loss_ce: 0.061479
2022-01-20 21:04:12,684 iteration 761 : loss : 0.055458, loss_ce: 0.027087
2022-01-20 21:04:13,365 iteration 762 : loss : 0.072799, loss_ce: 0.029622
2022-01-20 21:04:14,053 iteration 763 : loss : 0.068938, loss_ce: 0.030314
2022-01-20 21:04:14,664 iteration 764 : loss : 0.076980, loss_ce: 0.037600
2022-01-20 21:04:14,664 Training Data Eval:
2022-01-20 21:04:17,564   Average segmentation loss on training set: 0.1011
2022-01-20 21:04:17,564 Validation Data Eval:
2022-01-20 21:04:18,513   Average segmentation loss on validation set: 0.1524
2022-01-20 21:04:19,313 iteration 765 : loss : 0.087799, loss_ce: 0.035048
 11%|███▍                          | 45/400 [08:48<1:12:57, 12.33s/it]2022-01-20 21:04:20,040 iteration 766 : loss : 0.072233, loss_ce: 0.026701
2022-01-20 21:04:20,706 iteration 767 : loss : 0.067668, loss_ce: 0.026377
2022-01-20 21:04:21,358 iteration 768 : loss : 0.064947, loss_ce: 0.025537
2022-01-20 21:04:22,029 iteration 769 : loss : 0.071820, loss_ce: 0.031732
2022-01-20 21:04:22,585 iteration 770 : loss : 0.078118, loss_ce: 0.036372
2022-01-20 21:04:23,224 iteration 771 : loss : 0.110854, loss_ce: 0.029289
2022-01-20 21:04:23,874 iteration 772 : loss : 0.055789, loss_ce: 0.021817
2022-01-20 21:04:24,541 iteration 773 : loss : 0.069198, loss_ce: 0.020763
2022-01-20 21:04:25,297 iteration 774 : loss : 0.065923, loss_ce: 0.028126
2022-01-20 21:04:25,916 iteration 775 : loss : 0.074470, loss_ce: 0.035550
2022-01-20 21:04:26,510 iteration 776 : loss : 0.086303, loss_ce: 0.030541
2022-01-20 21:04:27,327 iteration 777 : loss : 0.082033, loss_ce: 0.035648
2022-01-20 21:04:27,895 iteration 778 : loss : 0.108269, loss_ce: 0.033305
2022-01-20 21:04:28,590 iteration 779 : loss : 0.073114, loss_ce: 0.033376
2022-01-20 21:04:29,284 iteration 780 : loss : 0.079695, loss_ce: 0.030898
2022-01-20 21:04:29,878 iteration 781 : loss : 0.069078, loss_ce: 0.041443
2022-01-20 21:04:30,429 iteration 782 : loss : 0.060522, loss_ce: 0.031988
 12%|███▍                          | 46/400 [08:59<1:10:36, 11.97s/it]2022-01-20 21:04:31,083 iteration 783 : loss : 0.071566, loss_ce: 0.032142
2022-01-20 21:04:31,678 iteration 784 : loss : 0.077493, loss_ce: 0.027966
2022-01-20 21:04:32,314 iteration 785 : loss : 0.074252, loss_ce: 0.036349
2022-01-20 21:04:32,921 iteration 786 : loss : 0.062428, loss_ce: 0.023438
2022-01-20 21:04:33,540 iteration 787 : loss : 0.074868, loss_ce: 0.027610
2022-01-20 21:04:34,229 iteration 788 : loss : 0.090469, loss_ce: 0.039915
2022-01-20 21:04:34,776 iteration 789 : loss : 0.089106, loss_ce: 0.034170
2022-01-20 21:04:35,458 iteration 790 : loss : 0.073366, loss_ce: 0.023304
2022-01-20 21:04:36,089 iteration 791 : loss : 0.063736, loss_ce: 0.028015
2022-01-20 21:04:36,663 iteration 792 : loss : 0.065231, loss_ce: 0.031979
2022-01-20 21:04:37,359 iteration 793 : loss : 0.074368, loss_ce: 0.035586
2022-01-20 21:04:37,900 iteration 794 : loss : 0.058036, loss_ce: 0.026520
2022-01-20 21:04:38,476 iteration 795 : loss : 0.065917, loss_ce: 0.027120
2022-01-20 21:04:39,043 iteration 796 : loss : 0.064757, loss_ce: 0.033200
2022-01-20 21:04:39,711 iteration 797 : loss : 0.076769, loss_ce: 0.031545
2022-01-20 21:04:40,316 iteration 798 : loss : 0.058481, loss_ce: 0.024568
2022-01-20 21:04:40,872 iteration 799 : loss : 0.052473, loss_ce: 0.027728
 12%|███▌                          | 47/400 [09:10<1:07:43, 11.51s/it]2022-01-20 21:04:41,649 iteration 800 : loss : 0.055389, loss_ce: 0.022120
2022-01-20 21:04:42,313 iteration 801 : loss : 0.070583, loss_ce: 0.031932
2022-01-20 21:04:42,951 iteration 802 : loss : 0.068258, loss_ce: 0.026064
2022-01-20 21:04:43,610 iteration 803 : loss : 0.064350, loss_ce: 0.033980
2022-01-20 21:04:44,334 iteration 804 : loss : 0.122039, loss_ce: 0.061513
2022-01-20 21:04:45,119 iteration 805 : loss : 0.053048, loss_ce: 0.020463
2022-01-20 21:04:45,730 iteration 806 : loss : 0.070733, loss_ce: 0.037171
2022-01-20 21:04:46,308 iteration 807 : loss : 0.058002, loss_ce: 0.023058
2022-01-20 21:04:46,976 iteration 808 : loss : 0.075072, loss_ce: 0.038027
2022-01-20 21:04:47,617 iteration 809 : loss : 0.071493, loss_ce: 0.025088
2022-01-20 21:04:48,212 iteration 810 : loss : 0.095104, loss_ce: 0.036726
2022-01-20 21:04:48,779 iteration 811 : loss : 0.084524, loss_ce: 0.045190
2022-01-20 21:04:49,374 iteration 812 : loss : 0.073119, loss_ce: 0.034497
2022-01-20 21:04:50,000 iteration 813 : loss : 0.091376, loss_ce: 0.027838
2022-01-20 21:04:50,745 iteration 814 : loss : 0.085268, loss_ce: 0.029713
2022-01-20 21:04:51,455 iteration 815 : loss : 0.092286, loss_ce: 0.037441
2022-01-20 21:04:52,109 iteration 816 : loss : 0.063648, loss_ce: 0.026411
 12%|███▌                          | 48/400 [09:21<1:07:02, 11.43s/it]2022-01-20 21:04:52,773 iteration 817 : loss : 0.058198, loss_ce: 0.028605
2022-01-20 21:04:53,351 iteration 818 : loss : 0.047727, loss_ce: 0.021135
2022-01-20 21:04:53,985 iteration 819 : loss : 0.066324, loss_ce: 0.026158
2022-01-20 21:04:54,543 iteration 820 : loss : 0.058551, loss_ce: 0.024941
2022-01-20 21:04:55,228 iteration 821 : loss : 0.073214, loss_ce: 0.027518
2022-01-20 21:04:55,890 iteration 822 : loss : 0.071811, loss_ce: 0.024545
2022-01-20 21:04:56,467 iteration 823 : loss : 0.049857, loss_ce: 0.018908
2022-01-20 21:04:57,037 iteration 824 : loss : 0.061181, loss_ce: 0.027215
2022-01-20 21:04:57,653 iteration 825 : loss : 0.051729, loss_ce: 0.021145
2022-01-20 21:04:58,259 iteration 826 : loss : 0.071882, loss_ce: 0.019412
2022-01-20 21:04:58,877 iteration 827 : loss : 0.080699, loss_ce: 0.028340
2022-01-20 21:04:59,496 iteration 828 : loss : 0.058292, loss_ce: 0.022846
2022-01-20 21:05:00,139 iteration 829 : loss : 0.075945, loss_ce: 0.029381
2022-01-20 21:05:00,825 iteration 830 : loss : 0.054923, loss_ce: 0.022307
2022-01-20 21:05:01,457 iteration 831 : loss : 0.067843, loss_ce: 0.032667
2022-01-20 21:05:02,068 iteration 832 : loss : 0.041297, loss_ce: 0.016758
2022-01-20 21:05:02,757 iteration 833 : loss : 0.066480, loss_ce: 0.036697
 12%|███▋                          | 49/400 [09:32<1:05:29, 11.19s/it]2022-01-20 21:05:03,433 iteration 834 : loss : 0.058502, loss_ce: 0.025813
2022-01-20 21:05:03,975 iteration 835 : loss : 0.053230, loss_ce: 0.017751
2022-01-20 21:05:04,621 iteration 836 : loss : 0.052496, loss_ce: 0.026316
2022-01-20 21:05:05,199 iteration 837 : loss : 0.047051, loss_ce: 0.027374
2022-01-20 21:05:05,750 iteration 838 : loss : 0.056389, loss_ce: 0.023575
2022-01-20 21:05:06,393 iteration 839 : loss : 0.057518, loss_ce: 0.027929
2022-01-20 21:05:07,003 iteration 840 : loss : 0.067173, loss_ce: 0.024373
2022-01-20 21:05:07,579 iteration 841 : loss : 0.054491, loss_ce: 0.025908
2022-01-20 21:05:08,186 iteration 842 : loss : 0.055213, loss_ce: 0.025680
2022-01-20 21:05:08,904 iteration 843 : loss : 0.072536, loss_ce: 0.029079
2022-01-20 21:05:09,513 iteration 844 : loss : 0.058543, loss_ce: 0.021855
2022-01-20 21:05:10,164 iteration 845 : loss : 0.064865, loss_ce: 0.023011
2022-01-20 21:05:10,913 iteration 846 : loss : 0.063723, loss_ce: 0.028853
2022-01-20 21:05:11,559 iteration 847 : loss : 0.046986, loss_ce: 0.020151
2022-01-20 21:05:12,095 iteration 848 : loss : 0.055227, loss_ce: 0.023775
2022-01-20 21:05:12,731 iteration 849 : loss : 0.058980, loss_ce: 0.023244
2022-01-20 21:05:12,732 Training Data Eval:
2022-01-20 21:05:15,628   Average segmentation loss on training set: 0.0644
2022-01-20 21:05:15,629 Validation Data Eval:
2022-01-20 21:05:16,578   Average segmentation loss on validation set: 0.2018
2022-01-20 21:05:17,248 iteration 850 : loss : 0.074233, loss_ce: 0.030071
 12%|███▊                          | 50/400 [09:46<1:11:04, 12.18s/it]2022-01-20 21:05:17,939 iteration 851 : loss : 0.064154, loss_ce: 0.025172
2022-01-20 21:05:18,562 iteration 852 : loss : 0.041215, loss_ce: 0.017506
2022-01-20 21:05:19,262 iteration 853 : loss : 0.066455, loss_ce: 0.029510
2022-01-20 21:05:19,915 iteration 854 : loss : 0.046902, loss_ce: 0.015585
2022-01-20 21:05:20,563 iteration 855 : loss : 0.072101, loss_ce: 0.030521
2022-01-20 21:05:21,233 iteration 856 : loss : 0.063933, loss_ce: 0.024352
2022-01-20 21:05:21,834 iteration 857 : loss : 0.049579, loss_ce: 0.023511
2022-01-20 21:05:22,369 iteration 858 : loss : 0.055227, loss_ce: 0.027535
2022-01-20 21:05:22,978 iteration 859 : loss : 0.063659, loss_ce: 0.026408
2022-01-20 21:05:23,547 iteration 860 : loss : 0.075260, loss_ce: 0.024195
2022-01-20 21:05:24,235 iteration 861 : loss : 0.059038, loss_ce: 0.028964
2022-01-20 21:05:24,789 iteration 862 : loss : 0.066302, loss_ce: 0.022521
2022-01-20 21:05:25,488 iteration 863 : loss : 0.070209, loss_ce: 0.028169
2022-01-20 21:05:26,159 iteration 864 : loss : 0.067525, loss_ce: 0.031768
2022-01-20 21:05:26,712 iteration 865 : loss : 0.049955, loss_ce: 0.022398
2022-01-20 21:05:27,405 iteration 866 : loss : 0.088587, loss_ce: 0.045638
2022-01-20 21:05:27,971 iteration 867 : loss : 0.036337, loss_ce: 0.015367
 13%|███▊                          | 51/400 [09:57<1:08:18, 11.74s/it]2022-01-20 21:05:28,681 iteration 868 : loss : 0.092125, loss_ce: 0.035481
2022-01-20 21:05:29,313 iteration 869 : loss : 0.067109, loss_ce: 0.024430
2022-01-20 21:05:29,848 iteration 870 : loss : 0.052868, loss_ce: 0.019935
2022-01-20 21:05:30,423 iteration 871 : loss : 0.064193, loss_ce: 0.028690
2022-01-20 21:05:31,019 iteration 872 : loss : 0.064818, loss_ce: 0.036714
2022-01-20 21:05:31,718 iteration 873 : loss : 0.050264, loss_ce: 0.020528
2022-01-20 21:05:32,262 iteration 874 : loss : 0.043927, loss_ce: 0.020557
2022-01-20 21:05:33,032 iteration 875 : loss : 0.116347, loss_ce: 0.049196
2022-01-20 21:05:33,659 iteration 876 : loss : 0.033947, loss_ce: 0.017940
2022-01-20 21:05:34,184 iteration 877 : loss : 0.047038, loss_ce: 0.021455
2022-01-20 21:05:34,848 iteration 878 : loss : 0.058990, loss_ce: 0.026599
2022-01-20 21:05:35,443 iteration 879 : loss : 0.057156, loss_ce: 0.025076
2022-01-20 21:05:36,089 iteration 880 : loss : 0.046208, loss_ce: 0.018623
2022-01-20 21:05:36,680 iteration 881 : loss : 0.066633, loss_ce: 0.026964
2022-01-20 21:05:37,349 iteration 882 : loss : 0.059111, loss_ce: 0.024806
2022-01-20 21:05:37,975 iteration 883 : loss : 0.064851, loss_ce: 0.032286
2022-01-20 21:05:38,703 iteration 884 : loss : 0.075915, loss_ce: 0.034118
 13%|███▉                          | 52/400 [10:08<1:06:21, 11.44s/it]2022-01-20 21:05:39,408 iteration 885 : loss : 0.058765, loss_ce: 0.024480
2022-01-20 21:05:40,070 iteration 886 : loss : 0.054874, loss_ce: 0.022915
2022-01-20 21:05:40,738 iteration 887 : loss : 0.092388, loss_ce: 0.042452
2022-01-20 21:05:41,372 iteration 888 : loss : 0.054969, loss_ce: 0.022662
2022-01-20 21:05:42,069 iteration 889 : loss : 0.087465, loss_ce: 0.030912
2022-01-20 21:05:42,818 iteration 890 : loss : 0.075962, loss_ce: 0.026819
2022-01-20 21:05:43,462 iteration 891 : loss : 0.057706, loss_ce: 0.021330
2022-01-20 21:05:44,094 iteration 892 : loss : 0.052352, loss_ce: 0.027769
2022-01-20 21:05:44,707 iteration 893 : loss : 0.060119, loss_ce: 0.024095
2022-01-20 21:05:45,447 iteration 894 : loss : 0.053009, loss_ce: 0.020849
2022-01-20 21:05:46,050 iteration 895 : loss : 0.064128, loss_ce: 0.021489
2022-01-20 21:05:46,742 iteration 896 : loss : 0.078122, loss_ce: 0.033126
2022-01-20 21:05:47,465 iteration 897 : loss : 0.077938, loss_ce: 0.041625
2022-01-20 21:05:48,086 iteration 898 : loss : 0.067429, loss_ce: 0.034854
2022-01-20 21:05:48,709 iteration 899 : loss : 0.059260, loss_ce: 0.026414
2022-01-20 21:05:49,287 iteration 900 : loss : 0.055159, loss_ce: 0.026338
2022-01-20 21:05:49,886 iteration 901 : loss : 0.075046, loss_ce: 0.026761
 13%|███▉                          | 53/400 [10:19<1:05:42, 11.36s/it]2022-01-20 21:05:50,588 iteration 902 : loss : 0.064051, loss_ce: 0.027472
2022-01-20 21:05:51,331 iteration 903 : loss : 0.072364, loss_ce: 0.030070
2022-01-20 21:05:52,007 iteration 904 : loss : 0.069805, loss_ce: 0.027866
2022-01-20 21:05:52,661 iteration 905 : loss : 0.086693, loss_ce: 0.042093
2022-01-20 21:05:53,289 iteration 906 : loss : 0.044673, loss_ce: 0.021600
2022-01-20 21:05:53,982 iteration 907 : loss : 0.059539, loss_ce: 0.021839
2022-01-20 21:05:54,518 iteration 908 : loss : 0.051120, loss_ce: 0.020743
2022-01-20 21:05:55,175 iteration 909 : loss : 0.074486, loss_ce: 0.035248
2022-01-20 21:05:55,737 iteration 910 : loss : 0.083862, loss_ce: 0.036203
2022-01-20 21:05:56,361 iteration 911 : loss : 0.055265, loss_ce: 0.021396
2022-01-20 21:05:56,975 iteration 912 : loss : 0.056141, loss_ce: 0.022244
2022-01-20 21:05:57,580 iteration 913 : loss : 0.071261, loss_ce: 0.026583
2022-01-20 21:05:58,197 iteration 914 : loss : 0.070641, loss_ce: 0.035072
2022-01-20 21:05:58,789 iteration 915 : loss : 0.074909, loss_ce: 0.027783
2022-01-20 21:05:59,382 iteration 916 : loss : 0.054248, loss_ce: 0.019841
2022-01-20 21:06:00,029 iteration 917 : loss : 0.099573, loss_ce: 0.042808
2022-01-20 21:06:00,695 iteration 918 : loss : 0.085677, loss_ce: 0.036406
 14%|████                          | 54/400 [10:30<1:04:33, 11.19s/it]2022-01-20 21:06:01,406 iteration 919 : loss : 0.051508, loss_ce: 0.022892
2022-01-20 21:06:02,058 iteration 920 : loss : 0.058244, loss_ce: 0.025509
2022-01-20 21:06:02,741 iteration 921 : loss : 0.077685, loss_ce: 0.031969
2022-01-20 21:06:03,445 iteration 922 : loss : 0.057447, loss_ce: 0.029715
2022-01-20 21:06:04,059 iteration 923 : loss : 0.046303, loss_ce: 0.022533
2022-01-20 21:06:04,750 iteration 924 : loss : 0.097434, loss_ce: 0.032796
2022-01-20 21:06:05,350 iteration 925 : loss : 0.050001, loss_ce: 0.019530
2022-01-20 21:06:06,043 iteration 926 : loss : 0.051738, loss_ce: 0.024173
2022-01-20 21:06:06,611 iteration 927 : loss : 0.061330, loss_ce: 0.023036
2022-01-20 21:06:07,234 iteration 928 : loss : 0.057811, loss_ce: 0.027399
2022-01-20 21:06:07,924 iteration 929 : loss : 0.077887, loss_ce: 0.029941
2022-01-20 21:06:08,574 iteration 930 : loss : 0.049137, loss_ce: 0.022275
2022-01-20 21:06:09,229 iteration 931 : loss : 0.081987, loss_ce: 0.022655
2022-01-20 21:06:09,867 iteration 932 : loss : 0.057313, loss_ce: 0.019562
2022-01-20 21:06:10,467 iteration 933 : loss : 0.083855, loss_ce: 0.032691
2022-01-20 21:06:11,097 iteration 934 : loss : 0.051066, loss_ce: 0.024004
2022-01-20 21:06:11,097 Training Data Eval:
2022-01-20 21:06:13,992   Average segmentation loss on training set: 0.0472
2022-01-20 21:06:13,993 Validation Data Eval:
2022-01-20 21:06:14,943   Average segmentation loss on validation set: 0.1238
2022-01-20 21:06:15,679 iteration 935 : loss : 0.121820, loss_ce: 0.034909
 14%|████▏                         | 55/400 [10:45<1:10:54, 12.33s/it]2022-01-20 21:06:16,328 iteration 936 : loss : 0.048576, loss_ce: 0.016928
2022-01-20 21:06:16,984 iteration 937 : loss : 0.051381, loss_ce: 0.018402
2022-01-20 21:06:17,666 iteration 938 : loss : 0.061184, loss_ce: 0.022537
2022-01-20 21:06:18,261 iteration 939 : loss : 0.058286, loss_ce: 0.021579
2022-01-20 21:06:18,910 iteration 940 : loss : 0.069407, loss_ce: 0.029198
2022-01-20 21:06:19,648 iteration 941 : loss : 0.087057, loss_ce: 0.036473
2022-01-20 21:06:20,238 iteration 942 : loss : 0.050085, loss_ce: 0.019666
2022-01-20 21:06:20,849 iteration 943 : loss : 0.061582, loss_ce: 0.029149
2022-01-20 21:06:21,433 iteration 944 : loss : 0.042832, loss_ce: 0.019304
2022-01-20 21:06:22,030 iteration 945 : loss : 0.058373, loss_ce: 0.022692
2022-01-20 21:06:22,624 iteration 946 : loss : 0.046906, loss_ce: 0.022747
2022-01-20 21:06:23,208 iteration 947 : loss : 0.054872, loss_ce: 0.021543
2022-01-20 21:06:23,787 iteration 948 : loss : 0.072857, loss_ce: 0.026743
2022-01-20 21:06:24,397 iteration 949 : loss : 0.056211, loss_ce: 0.022733
2022-01-20 21:06:25,002 iteration 950 : loss : 0.064769, loss_ce: 0.029521
2022-01-20 21:06:25,666 iteration 951 : loss : 0.072637, loss_ce: 0.042135
2022-01-20 21:06:26,243 iteration 952 : loss : 0.064516, loss_ce: 0.031262
 14%|████▏                         | 56/400 [10:55<1:07:39, 11.80s/it]2022-01-20 21:06:26,942 iteration 953 : loss : 0.063950, loss_ce: 0.023846
2022-01-20 21:06:27,622 iteration 954 : loss : 0.058105, loss_ce: 0.023571
2022-01-20 21:06:28,181 iteration 955 : loss : 0.038067, loss_ce: 0.018484
2022-01-20 21:06:28,845 iteration 956 : loss : 0.049553, loss_ce: 0.021074
2022-01-20 21:06:29,493 iteration 957 : loss : 0.064232, loss_ce: 0.024410
2022-01-20 21:06:30,150 iteration 958 : loss : 0.062704, loss_ce: 0.020497
2022-01-20 21:06:30,874 iteration 959 : loss : 0.065749, loss_ce: 0.033781
2022-01-20 21:06:31,667 iteration 960 : loss : 0.072021, loss_ce: 0.037517
2022-01-20 21:06:32,272 iteration 961 : loss : 0.076686, loss_ce: 0.025937
2022-01-20 21:06:32,840 iteration 962 : loss : 0.058034, loss_ce: 0.017798
2022-01-20 21:06:33,552 iteration 963 : loss : 0.051386, loss_ce: 0.020913
2022-01-20 21:06:34,221 iteration 964 : loss : 0.050392, loss_ce: 0.025403
2022-01-20 21:06:34,831 iteration 965 : loss : 0.049903, loss_ce: 0.025244
2022-01-20 21:06:35,462 iteration 966 : loss : 0.052741, loss_ce: 0.022384
2022-01-20 21:06:36,112 iteration 967 : loss : 0.042542, loss_ce: 0.018389
2022-01-20 21:06:36,697 iteration 968 : loss : 0.108199, loss_ce: 0.040832
2022-01-20 21:06:37,348 iteration 969 : loss : 0.048569, loss_ce: 0.021326
 14%|████▎                         | 57/400 [11:06<1:06:16, 11.59s/it]2022-01-20 21:06:37,995 iteration 970 : loss : 0.059815, loss_ce: 0.031924
2022-01-20 21:06:38,658 iteration 971 : loss : 0.065620, loss_ce: 0.021526
2022-01-20 21:06:39,228 iteration 972 : loss : 0.044844, loss_ce: 0.024324
2022-01-20 21:06:39,875 iteration 973 : loss : 0.069889, loss_ce: 0.023845
2022-01-20 21:06:40,448 iteration 974 : loss : 0.052757, loss_ce: 0.021492
2022-01-20 21:06:41,131 iteration 975 : loss : 0.057367, loss_ce: 0.020676
2022-01-20 21:06:41,750 iteration 976 : loss : 0.045547, loss_ce: 0.021858
2022-01-20 21:06:42,378 iteration 977 : loss : 0.043683, loss_ce: 0.016604
2022-01-20 21:06:43,038 iteration 978 : loss : 0.042070, loss_ce: 0.016435
2022-01-20 21:06:43,649 iteration 979 : loss : 0.076109, loss_ce: 0.040405
2022-01-20 21:06:44,263 iteration 980 : loss : 0.040248, loss_ce: 0.015528
2022-01-20 21:06:44,995 iteration 981 : loss : 0.065946, loss_ce: 0.030566
2022-01-20 21:06:45,601 iteration 982 : loss : 0.058764, loss_ce: 0.032466
2022-01-20 21:06:46,280 iteration 983 : loss : 0.089611, loss_ce: 0.030362
2022-01-20 21:06:46,836 iteration 984 : loss : 0.047498, loss_ce: 0.023760
2022-01-20 21:06:47,462 iteration 985 : loss : 0.046578, loss_ce: 0.015547
2022-01-20 21:06:48,142 iteration 986 : loss : 0.077741, loss_ce: 0.032039
 14%|████▎                         | 58/400 [11:17<1:04:43, 11.36s/it]2022-01-20 21:06:48,882 iteration 987 : loss : 0.047702, loss_ce: 0.022798
2022-01-20 21:06:49,550 iteration 988 : loss : 0.065832, loss_ce: 0.031175
2022-01-20 21:06:50,204 iteration 989 : loss : 0.050776, loss_ce: 0.021337
2022-01-20 21:06:50,841 iteration 990 : loss : 0.050278, loss_ce: 0.022644
2022-01-20 21:06:51,471 iteration 991 : loss : 0.039366, loss_ce: 0.017672
2022-01-20 21:06:52,197 iteration 992 : loss : 0.049753, loss_ce: 0.023718
2022-01-20 21:06:52,872 iteration 993 : loss : 0.045819, loss_ce: 0.017834
2022-01-20 21:06:53,626 iteration 994 : loss : 0.059634, loss_ce: 0.025019
2022-01-20 21:06:54,276 iteration 995 : loss : 0.086304, loss_ce: 0.031430
2022-01-20 21:06:54,976 iteration 996 : loss : 0.041806, loss_ce: 0.020956
2022-01-20 21:06:55,673 iteration 997 : loss : 0.061518, loss_ce: 0.024545
2022-01-20 21:06:56,260 iteration 998 : loss : 0.061932, loss_ce: 0.020379
2022-01-20 21:06:56,943 iteration 999 : loss : 0.048332, loss_ce: 0.020357
2022-01-20 21:06:57,539 iteration 1000 : loss : 0.050711, loss_ce: 0.019681
2022-01-20 21:06:58,144 iteration 1001 : loss : 0.073143, loss_ce: 0.018670
2022-01-20 21:06:58,886 iteration 1002 : loss : 0.051834, loss_ce: 0.021378
2022-01-20 21:06:59,609 iteration 1003 : loss : 0.082243, loss_ce: 0.035230
 15%|████▍                         | 59/400 [11:29<1:04:43, 11.39s/it]2022-01-20 21:07:00,292 iteration 1004 : loss : 0.099793, loss_ce: 0.042297
2022-01-20 21:07:00,917 iteration 1005 : loss : 0.050349, loss_ce: 0.019031
2022-01-20 21:07:01,636 iteration 1006 : loss : 0.057540, loss_ce: 0.024092
2022-01-20 21:07:02,238 iteration 1007 : loss : 0.048045, loss_ce: 0.024423
2022-01-20 21:07:02,826 iteration 1008 : loss : 0.122659, loss_ce: 0.054847
2022-01-20 21:07:03,418 iteration 1009 : loss : 0.062039, loss_ce: 0.026507
2022-01-20 21:07:04,013 iteration 1010 : loss : 0.058656, loss_ce: 0.025248
2022-01-20 21:07:04,705 iteration 1011 : loss : 0.057702, loss_ce: 0.026816
2022-01-20 21:07:05,332 iteration 1012 : loss : 0.051879, loss_ce: 0.022620
2022-01-20 21:07:05,910 iteration 1013 : loss : 0.045205, loss_ce: 0.016438
2022-01-20 21:07:06,560 iteration 1014 : loss : 0.088187, loss_ce: 0.039618
2022-01-20 21:07:07,128 iteration 1015 : loss : 0.056371, loss_ce: 0.021495
2022-01-20 21:07:07,779 iteration 1016 : loss : 0.047815, loss_ce: 0.021606
2022-01-20 21:07:08,319 iteration 1017 : loss : 0.038670, loss_ce: 0.015390
2022-01-20 21:07:08,858 iteration 1018 : loss : 0.057586, loss_ce: 0.023583
2022-01-20 21:07:09,476 iteration 1019 : loss : 0.104736, loss_ce: 0.061349
2022-01-20 21:07:09,476 Training Data Eval:
2022-01-20 21:07:12,378   Average segmentation loss on training set: 0.0795
2022-01-20 21:07:12,378 Validation Data Eval:
2022-01-20 21:07:13,328   Average segmentation loss on validation set: 0.2351
2022-01-20 21:07:13,906 iteration 1020 : loss : 0.038250, loss_ce: 0.015342
 15%|████▌                         | 60/400 [11:43<1:09:29, 12.26s/it]2022-01-20 21:07:14,661 iteration 1021 : loss : 0.094345, loss_ce: 0.027931
2022-01-20 21:07:15,279 iteration 1022 : loss : 0.059960, loss_ce: 0.025873
2022-01-20 21:07:15,913 iteration 1023 : loss : 0.119462, loss_ce: 0.034950
2022-01-20 21:07:16,600 iteration 1024 : loss : 0.061124, loss_ce: 0.023736
2022-01-20 21:07:17,276 iteration 1025 : loss : 0.051675, loss_ce: 0.023256
2022-01-20 21:07:17,817 iteration 1026 : loss : 0.038679, loss_ce: 0.015686
2022-01-20 21:07:18,499 iteration 1027 : loss : 0.056513, loss_ce: 0.021280
2022-01-20 21:07:19,173 iteration 1028 : loss : 0.085458, loss_ce: 0.036746
2022-01-20 21:07:19,802 iteration 1029 : loss : 0.061630, loss_ce: 0.026778
2022-01-20 21:07:20,437 iteration 1030 : loss : 0.050808, loss_ce: 0.018939
2022-01-20 21:07:21,129 iteration 1031 : loss : 0.106144, loss_ce: 0.047037
2022-01-20 21:07:21,790 iteration 1032 : loss : 0.055377, loss_ce: 0.026832
2022-01-20 21:07:22,395 iteration 1033 : loss : 0.090574, loss_ce: 0.032976
2022-01-20 21:07:23,096 iteration 1034 : loss : 0.092435, loss_ce: 0.037264
2022-01-20 21:07:23,751 iteration 1035 : loss : 0.058571, loss_ce: 0.029925
2022-01-20 21:07:24,403 iteration 1036 : loss : 0.063406, loss_ce: 0.029076
2022-01-20 21:07:25,002 iteration 1037 : loss : 0.069887, loss_ce: 0.026091
 15%|████▌                         | 61/400 [11:54<1:07:16, 11.91s/it]2022-01-20 21:07:25,691 iteration 1038 : loss : 0.043108, loss_ce: 0.017542
2022-01-20 21:07:26,325 iteration 1039 : loss : 0.085688, loss_ce: 0.043309
2022-01-20 21:07:27,006 iteration 1040 : loss : 0.074021, loss_ce: 0.031220
2022-01-20 21:07:27,667 iteration 1041 : loss : 0.056490, loss_ce: 0.024882
2022-01-20 21:07:28,330 iteration 1042 : loss : 0.047692, loss_ce: 0.020155
2022-01-20 21:07:28,971 iteration 1043 : loss : 0.075304, loss_ce: 0.024635
2022-01-20 21:07:29,637 iteration 1044 : loss : 0.063211, loss_ce: 0.025737
2022-01-20 21:07:30,186 iteration 1045 : loss : 0.050765, loss_ce: 0.024739
2022-01-20 21:07:30,767 iteration 1046 : loss : 0.077851, loss_ce: 0.021885
2022-01-20 21:07:31,446 iteration 1047 : loss : 0.075232, loss_ce: 0.026378
2022-01-20 21:07:32,080 iteration 1048 : loss : 0.065125, loss_ce: 0.025239
2022-01-20 21:07:32,720 iteration 1049 : loss : 0.054361, loss_ce: 0.020170
2022-01-20 21:07:33,408 iteration 1050 : loss : 0.074034, loss_ce: 0.024107
2022-01-20 21:07:34,036 iteration 1051 : loss : 0.056063, loss_ce: 0.023995
2022-01-20 21:07:34,674 iteration 1052 : loss : 0.056204, loss_ce: 0.023901
2022-01-20 21:07:35,233 iteration 1053 : loss : 0.052559, loss_ce: 0.015966
2022-01-20 21:07:35,945 iteration 1054 : loss : 0.060793, loss_ce: 0.028585
 16%|████▋                         | 62/400 [12:05<1:05:28, 11.62s/it]2022-01-20 21:07:36,633 iteration 1055 : loss : 0.043342, loss_ce: 0.015818
2022-01-20 21:07:37,241 iteration 1056 : loss : 0.053789, loss_ce: 0.028399
2022-01-20 21:07:37,853 iteration 1057 : loss : 0.083639, loss_ce: 0.043633
2022-01-20 21:07:38,477 iteration 1058 : loss : 0.059842, loss_ce: 0.025361
2022-01-20 21:07:39,026 iteration 1059 : loss : 0.054551, loss_ce: 0.021041
2022-01-20 21:07:39,648 iteration 1060 : loss : 0.043490, loss_ce: 0.016919
2022-01-20 21:07:40,313 iteration 1061 : loss : 0.042483, loss_ce: 0.015753
2022-01-20 21:07:40,962 iteration 1062 : loss : 0.059519, loss_ce: 0.026918
2022-01-20 21:07:41,662 iteration 1063 : loss : 0.088944, loss_ce: 0.030753
2022-01-20 21:07:42,286 iteration 1064 : loss : 0.065116, loss_ce: 0.022132
2022-01-20 21:07:42,854 iteration 1065 : loss : 0.045449, loss_ce: 0.020047
2022-01-20 21:07:43,521 iteration 1066 : loss : 0.040201, loss_ce: 0.018657
2022-01-20 21:07:44,134 iteration 1067 : loss : 0.107850, loss_ce: 0.025906
2022-01-20 21:07:44,814 iteration 1068 : loss : 0.049164, loss_ce: 0.024960
2022-01-20 21:07:45,474 iteration 1069 : loss : 0.075803, loss_ce: 0.035079
2022-01-20 21:07:46,102 iteration 1070 : loss : 0.042693, loss_ce: 0.018700
2022-01-20 21:07:46,720 iteration 1071 : loss : 0.040771, loss_ce: 0.020150
 16%|████▋                         | 63/400 [12:16<1:03:50, 11.37s/it]2022-01-20 21:07:47,498 iteration 1072 : loss : 0.071921, loss_ce: 0.027353
2022-01-20 21:07:48,120 iteration 1073 : loss : 0.065697, loss_ce: 0.017792
2022-01-20 21:07:48,746 iteration 1074 : loss : 0.045846, loss_ce: 0.018742
2022-01-20 21:07:49,419 iteration 1075 : loss : 0.059638, loss_ce: 0.023529
2022-01-20 21:07:49,998 iteration 1076 : loss : 0.053114, loss_ce: 0.019438
2022-01-20 21:07:50,621 iteration 1077 : loss : 0.041740, loss_ce: 0.015637
2022-01-20 21:07:51,321 iteration 1078 : loss : 0.072602, loss_ce: 0.040613
2022-01-20 21:07:51,915 iteration 1079 : loss : 0.041043, loss_ce: 0.016713
2022-01-20 21:07:52,500 iteration 1080 : loss : 0.037372, loss_ce: 0.017317
2022-01-20 21:07:53,167 iteration 1081 : loss : 0.061834, loss_ce: 0.021337
2022-01-20 21:07:53,828 iteration 1082 : loss : 0.052588, loss_ce: 0.030379
2022-01-20 21:07:54,519 iteration 1083 : loss : 0.061773, loss_ce: 0.024163
2022-01-20 21:07:55,130 iteration 1084 : loss : 0.068014, loss_ce: 0.033870
2022-01-20 21:07:55,844 iteration 1085 : loss : 0.045693, loss_ce: 0.017687
2022-01-20 21:07:56,459 iteration 1086 : loss : 0.055762, loss_ce: 0.023790
2022-01-20 21:07:57,088 iteration 1087 : loss : 0.060421, loss_ce: 0.022295
2022-01-20 21:07:57,775 iteration 1088 : loss : 0.046173, loss_ce: 0.021024
 16%|████▊                         | 64/400 [12:27<1:03:08, 11.27s/it]2022-01-20 21:07:58,419 iteration 1089 : loss : 0.091280, loss_ce: 0.035508
2022-01-20 21:07:59,030 iteration 1090 : loss : 0.040481, loss_ce: 0.019181
2022-01-20 21:07:59,665 iteration 1091 : loss : 0.045136, loss_ce: 0.021807
2022-01-20 21:08:00,300 iteration 1092 : loss : 0.041690, loss_ce: 0.017466
2022-01-20 21:08:00,951 iteration 1093 : loss : 0.071758, loss_ce: 0.023828
2022-01-20 21:08:01,652 iteration 1094 : loss : 0.054138, loss_ce: 0.021632
2022-01-20 21:08:02,239 iteration 1095 : loss : 0.042910, loss_ce: 0.018194
2022-01-20 21:08:02,973 iteration 1096 : loss : 0.051301, loss_ce: 0.020448
2022-01-20 21:08:03,630 iteration 1097 : loss : 0.068432, loss_ce: 0.032062
2022-01-20 21:08:04,229 iteration 1098 : loss : 0.040085, loss_ce: 0.018508
2022-01-20 21:08:04,895 iteration 1099 : loss : 0.047765, loss_ce: 0.018504
2022-01-20 21:08:05,611 iteration 1100 : loss : 0.050823, loss_ce: 0.019715
2022-01-20 21:08:06,246 iteration 1101 : loss : 0.044755, loss_ce: 0.018910
2022-01-20 21:08:06,955 iteration 1102 : loss : 0.068869, loss_ce: 0.020420
2022-01-20 21:08:07,572 iteration 1103 : loss : 0.063014, loss_ce: 0.022896
2022-01-20 21:08:08,182 iteration 1104 : loss : 0.049322, loss_ce: 0.022703
2022-01-20 21:08:08,182 Training Data Eval:
2022-01-20 21:08:11,088   Average segmentation loss on training set: 0.0424
2022-01-20 21:08:11,088 Validation Data Eval:
2022-01-20 21:08:12,044   Average segmentation loss on validation set: 0.0988
2022-01-20 21:08:12,607 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:08:13,299 iteration 1105 : loss : 0.049699, loss_ce: 0.016770
 16%|████▉                         | 65/400 [12:42<1:10:03, 12.55s/it]2022-01-20 21:08:13,911 iteration 1106 : loss : 0.050550, loss_ce: 0.018185
2022-01-20 21:08:14,530 iteration 1107 : loss : 0.053832, loss_ce: 0.026784
2022-01-20 21:08:15,169 iteration 1108 : loss : 0.053938, loss_ce: 0.013816
2022-01-20 21:08:15,741 iteration 1109 : loss : 0.043287, loss_ce: 0.018290
2022-01-20 21:08:16,382 iteration 1110 : loss : 0.055074, loss_ce: 0.028438
2022-01-20 21:08:16,987 iteration 1111 : loss : 0.039015, loss_ce: 0.017598
2022-01-20 21:08:17,601 iteration 1112 : loss : 0.040663, loss_ce: 0.016551
2022-01-20 21:08:18,196 iteration 1113 : loss : 0.053974, loss_ce: 0.018533
2022-01-20 21:08:18,883 iteration 1114 : loss : 0.054259, loss_ce: 0.024985
2022-01-20 21:08:19,644 iteration 1115 : loss : 0.069667, loss_ce: 0.032120
2022-01-20 21:08:20,332 iteration 1116 : loss : 0.059916, loss_ce: 0.019202
2022-01-20 21:08:21,101 iteration 1117 : loss : 0.048261, loss_ce: 0.016786
2022-01-20 21:08:21,793 iteration 1118 : loss : 0.063306, loss_ce: 0.024739
2022-01-20 21:08:22,409 iteration 1119 : loss : 0.045222, loss_ce: 0.021150
2022-01-20 21:08:23,015 iteration 1120 : loss : 0.047872, loss_ce: 0.017364
2022-01-20 21:08:23,672 iteration 1121 : loss : 0.065930, loss_ce: 0.021819
2022-01-20 21:08:24,311 iteration 1122 : loss : 0.067501, loss_ce: 0.035702
 16%|████▉                         | 66/400 [12:53<1:07:17, 12.09s/it]2022-01-20 21:08:24,946 iteration 1123 : loss : 0.062100, loss_ce: 0.019634
2022-01-20 21:08:25,614 iteration 1124 : loss : 0.045374, loss_ce: 0.020654
2022-01-20 21:08:26,242 iteration 1125 : loss : 0.051804, loss_ce: 0.016433
2022-01-20 21:08:26,855 iteration 1126 : loss : 0.051477, loss_ce: 0.021037
2022-01-20 21:08:27,459 iteration 1127 : loss : 0.063234, loss_ce: 0.023382
2022-01-20 21:08:28,143 iteration 1128 : loss : 0.054701, loss_ce: 0.022902
2022-01-20 21:08:28,832 iteration 1129 : loss : 0.053700, loss_ce: 0.017844
2022-01-20 21:08:29,449 iteration 1130 : loss : 0.048742, loss_ce: 0.022655
2022-01-20 21:08:30,064 iteration 1131 : loss : 0.052303, loss_ce: 0.022875
2022-01-20 21:08:30,730 iteration 1132 : loss : 0.044612, loss_ce: 0.020299
2022-01-20 21:08:31,301 iteration 1133 : loss : 0.040723, loss_ce: 0.021363
2022-01-20 21:08:31,927 iteration 1134 : loss : 0.052835, loss_ce: 0.020510
2022-01-20 21:08:32,522 iteration 1135 : loss : 0.036093, loss_ce: 0.016663
2022-01-20 21:08:33,141 iteration 1136 : loss : 0.039594, loss_ce: 0.016275
2022-01-20 21:08:33,743 iteration 1137 : loss : 0.055012, loss_ce: 0.025272
2022-01-20 21:08:34,411 iteration 1138 : loss : 0.059767, loss_ce: 0.026423
2022-01-20 21:08:35,057 iteration 1139 : loss : 0.060344, loss_ce: 0.018348
 17%|█████                         | 67/400 [13:04<1:04:51, 11.68s/it]2022-01-20 21:08:35,734 iteration 1140 : loss : 0.045491, loss_ce: 0.018663
2022-01-20 21:08:36,329 iteration 1141 : loss : 0.035023, loss_ce: 0.014413
2022-01-20 21:08:37,028 iteration 1142 : loss : 0.052293, loss_ce: 0.024230
2022-01-20 21:08:37,663 iteration 1143 : loss : 0.041250, loss_ce: 0.017980
2022-01-20 21:08:38,338 iteration 1144 : loss : 0.051264, loss_ce: 0.028639
2022-01-20 21:08:38,927 iteration 1145 : loss : 0.041368, loss_ce: 0.016915
2022-01-20 21:08:39,577 iteration 1146 : loss : 0.082047, loss_ce: 0.047696
2022-01-20 21:08:40,126 iteration 1147 : loss : 0.046044, loss_ce: 0.019317
2022-01-20 21:08:40,815 iteration 1148 : loss : 0.081595, loss_ce: 0.028347
2022-01-20 21:08:41,398 iteration 1149 : loss : 0.044052, loss_ce: 0.021427
2022-01-20 21:08:42,038 iteration 1150 : loss : 0.044949, loss_ce: 0.019423
2022-01-20 21:08:42,705 iteration 1151 : loss : 0.060766, loss_ce: 0.026227
2022-01-20 21:08:43,458 iteration 1152 : loss : 0.066532, loss_ce: 0.025736
2022-01-20 21:08:44,005 iteration 1153 : loss : 0.048637, loss_ce: 0.018698
2022-01-20 21:08:44,670 iteration 1154 : loss : 0.052569, loss_ce: 0.019478
2022-01-20 21:08:45,261 iteration 1155 : loss : 0.055183, loss_ce: 0.018503
2022-01-20 21:08:45,940 iteration 1156 : loss : 0.065448, loss_ce: 0.032954
 17%|█████                         | 68/400 [13:15<1:03:19, 11.44s/it]2022-01-20 21:08:46,592 iteration 1157 : loss : 0.093811, loss_ce: 0.025582
2022-01-20 21:08:47,244 iteration 1158 : loss : 0.049906, loss_ce: 0.018291
2022-01-20 21:08:47,958 iteration 1159 : loss : 0.045322, loss_ce: 0.017692
2022-01-20 21:08:48,718 iteration 1160 : loss : 0.083241, loss_ce: 0.033264
2022-01-20 21:08:49,415 iteration 1161 : loss : 0.041267, loss_ce: 0.018567
2022-01-20 21:08:50,075 iteration 1162 : loss : 0.053051, loss_ce: 0.020567
2022-01-20 21:08:50,684 iteration 1163 : loss : 0.069610, loss_ce: 0.029292
2022-01-20 21:08:51,306 iteration 1164 : loss : 0.057581, loss_ce: 0.023131
2022-01-20 21:08:51,938 iteration 1165 : loss : 0.051613, loss_ce: 0.021924
2022-01-20 21:08:52,652 iteration 1166 : loss : 0.044339, loss_ce: 0.017858
2022-01-20 21:08:53,257 iteration 1167 : loss : 0.044226, loss_ce: 0.022328
2022-01-20 21:08:53,879 iteration 1168 : loss : 0.047446, loss_ce: 0.022985
2022-01-20 21:08:54,484 iteration 1169 : loss : 0.046052, loss_ce: 0.018895
2022-01-20 21:08:55,085 iteration 1170 : loss : 0.067355, loss_ce: 0.025384
2022-01-20 21:08:55,731 iteration 1171 : loss : 0.044814, loss_ce: 0.015380
2022-01-20 21:08:56,368 iteration 1172 : loss : 0.036966, loss_ce: 0.017414
2022-01-20 21:08:57,029 iteration 1173 : loss : 0.067743, loss_ce: 0.023741
 17%|█████▏                        | 69/400 [13:26<1:02:32, 11.34s/it]2022-01-20 21:08:57,677 iteration 1174 : loss : 0.062206, loss_ce: 0.021143
2022-01-20 21:08:58,317 iteration 1175 : loss : 0.033325, loss_ce: 0.015430
2022-01-20 21:08:58,946 iteration 1176 : loss : 0.055531, loss_ce: 0.024400
2022-01-20 21:08:59,544 iteration 1177 : loss : 0.045082, loss_ce: 0.019381
2022-01-20 21:09:00,219 iteration 1178 : loss : 0.048327, loss_ce: 0.017201
2022-01-20 21:09:00,953 iteration 1179 : loss : 0.059580, loss_ce: 0.024592
2022-01-20 21:09:01,563 iteration 1180 : loss : 0.042748, loss_ce: 0.017937
2022-01-20 21:09:02,194 iteration 1181 : loss : 0.044250, loss_ce: 0.020796
2022-01-20 21:09:02,840 iteration 1182 : loss : 0.048431, loss_ce: 0.018945
2022-01-20 21:09:03,423 iteration 1183 : loss : 0.065172, loss_ce: 0.028710
2022-01-20 21:09:04,021 iteration 1184 : loss : 0.039421, loss_ce: 0.018472
2022-01-20 21:09:04,700 iteration 1185 : loss : 0.047425, loss_ce: 0.017168
2022-01-20 21:09:05,305 iteration 1186 : loss : 0.044307, loss_ce: 0.019287
2022-01-20 21:09:06,005 iteration 1187 : loss : 0.052080, loss_ce: 0.019497
2022-01-20 21:09:06,597 iteration 1188 : loss : 0.047834, loss_ce: 0.019090
2022-01-20 21:09:07,304 iteration 1189 : loss : 0.062614, loss_ce: 0.028275
2022-01-20 21:09:07,305 Training Data Eval:
2022-01-20 21:09:10,214   Average segmentation loss on training set: 0.0385
2022-01-20 21:09:10,214 Validation Data Eval:
2022-01-20 21:09:11,174   Average segmentation loss on validation set: 0.0935
2022-01-20 21:09:11,719 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:09:12,351 iteration 1190 : loss : 0.051364, loss_ce: 0.023714
 18%|█████▎                        | 70/400 [13:41<1:08:56, 12.54s/it]2022-01-20 21:09:13,096 iteration 1191 : loss : 0.053930, loss_ce: 0.022116
2022-01-20 21:09:13,680 iteration 1192 : loss : 0.040212, loss_ce: 0.018920
2022-01-20 21:09:14,394 iteration 1193 : loss : 0.066832, loss_ce: 0.022469
2022-01-20 21:09:15,007 iteration 1194 : loss : 0.045573, loss_ce: 0.013937
2022-01-20 21:09:15,585 iteration 1195 : loss : 0.052321, loss_ce: 0.022083
2022-01-20 21:09:16,164 iteration 1196 : loss : 0.039507, loss_ce: 0.017087
2022-01-20 21:09:16,710 iteration 1197 : loss : 0.041415, loss_ce: 0.016101
2022-01-20 21:09:17,382 iteration 1198 : loss : 0.042024, loss_ce: 0.019498
2022-01-20 21:09:18,014 iteration 1199 : loss : 0.046454, loss_ce: 0.018967
2022-01-20 21:09:18,620 iteration 1200 : loss : 0.073333, loss_ce: 0.026616
2022-01-20 21:09:19,191 iteration 1201 : loss : 0.040355, loss_ce: 0.018901
2022-01-20 21:09:19,838 iteration 1202 : loss : 0.059032, loss_ce: 0.022675
2022-01-20 21:09:20,476 iteration 1203 : loss : 0.066627, loss_ce: 0.023938
2022-01-20 21:09:21,103 iteration 1204 : loss : 0.061542, loss_ce: 0.021487
2022-01-20 21:09:21,739 iteration 1205 : loss : 0.067958, loss_ce: 0.029673
2022-01-20 21:09:22,381 iteration 1206 : loss : 0.039465, loss_ce: 0.015678
2022-01-20 21:09:23,060 iteration 1207 : loss : 0.038150, loss_ce: 0.012528
 18%|█████▎                        | 71/400 [13:52<1:05:43, 11.99s/it]2022-01-20 21:09:23,775 iteration 1208 : loss : 0.052693, loss_ce: 0.026185
2022-01-20 21:09:24,424 iteration 1209 : loss : 0.044679, loss_ce: 0.018929
2022-01-20 21:09:25,067 iteration 1210 : loss : 0.041053, loss_ce: 0.016656
2022-01-20 21:09:25,652 iteration 1211 : loss : 0.033517, loss_ce: 0.013162
2022-01-20 21:09:26,219 iteration 1212 : loss : 0.041987, loss_ce: 0.013916
2022-01-20 21:09:26,968 iteration 1213 : loss : 0.044526, loss_ce: 0.019544
2022-01-20 21:09:27,605 iteration 1214 : loss : 0.039607, loss_ce: 0.016858
2022-01-20 21:09:28,254 iteration 1215 : loss : 0.059141, loss_ce: 0.021161
2022-01-20 21:09:29,007 iteration 1216 : loss : 0.078028, loss_ce: 0.029163
2022-01-20 21:09:29,646 iteration 1217 : loss : 0.032120, loss_ce: 0.011525
2022-01-20 21:09:30,234 iteration 1218 : loss : 0.033585, loss_ce: 0.013022
2022-01-20 21:09:30,792 iteration 1219 : loss : 0.049320, loss_ce: 0.015709
2022-01-20 21:09:31,408 iteration 1220 : loss : 0.040558, loss_ce: 0.016654
2022-01-20 21:09:31,997 iteration 1221 : loss : 0.066476, loss_ce: 0.025025
2022-01-20 21:09:32,683 iteration 1222 : loss : 0.050068, loss_ce: 0.017107
2022-01-20 21:09:33,288 iteration 1223 : loss : 0.058628, loss_ce: 0.034385
2022-01-20 21:09:33,954 iteration 1224 : loss : 0.064262, loss_ce: 0.025021
 18%|█████▍                        | 72/400 [14:03<1:03:43, 11.66s/it]2022-01-20 21:09:34,602 iteration 1225 : loss : 0.049957, loss_ce: 0.020772
2022-01-20 21:09:35,275 iteration 1226 : loss : 0.049004, loss_ce: 0.023340
2022-01-20 21:09:35,857 iteration 1227 : loss : 0.053618, loss_ce: 0.020690
2022-01-20 21:09:36,479 iteration 1228 : loss : 0.036209, loss_ce: 0.013515
2022-01-20 21:09:37,039 iteration 1229 : loss : 0.053792, loss_ce: 0.018177
2022-01-20 21:09:37,624 iteration 1230 : loss : 0.044283, loss_ce: 0.018186
2022-01-20 21:09:38,288 iteration 1231 : loss : 0.051387, loss_ce: 0.022747
2022-01-20 21:09:38,869 iteration 1232 : loss : 0.039160, loss_ce: 0.016002
2022-01-20 21:09:39,464 iteration 1233 : loss : 0.037980, loss_ce: 0.015625
2022-01-20 21:09:40,122 iteration 1234 : loss : 0.053032, loss_ce: 0.021726
2022-01-20 21:09:40,787 iteration 1235 : loss : 0.067283, loss_ce: 0.022570
2022-01-20 21:09:41,380 iteration 1236 : loss : 0.042861, loss_ce: 0.017643
2022-01-20 21:09:41,920 iteration 1237 : loss : 0.046259, loss_ce: 0.017778
2022-01-20 21:09:42,597 iteration 1238 : loss : 0.054045, loss_ce: 0.017922
2022-01-20 21:09:43,172 iteration 1239 : loss : 0.041511, loss_ce: 0.017261
2022-01-20 21:09:43,757 iteration 1240 : loss : 0.039663, loss_ce: 0.016673
2022-01-20 21:09:44,338 iteration 1241 : loss : 0.046184, loss_ce: 0.023727
 18%|█████▍                        | 73/400 [14:13<1:01:27, 11.28s/it]2022-01-20 21:09:45,025 iteration 1242 : loss : 0.060013, loss_ce: 0.031355
2022-01-20 21:09:45,610 iteration 1243 : loss : 0.053164, loss_ce: 0.017971
2022-01-20 21:09:46,204 iteration 1244 : loss : 0.035649, loss_ce: 0.014598
2022-01-20 21:09:46,842 iteration 1245 : loss : 0.068162, loss_ce: 0.024799
2022-01-20 21:09:47,475 iteration 1246 : loss : 0.039883, loss_ce: 0.014168
2022-01-20 21:09:48,064 iteration 1247 : loss : 0.042504, loss_ce: 0.018050
2022-01-20 21:09:48,710 iteration 1248 : loss : 0.067450, loss_ce: 0.025496
2022-01-20 21:09:49,296 iteration 1249 : loss : 0.037897, loss_ce: 0.014399
2022-01-20 21:09:50,015 iteration 1250 : loss : 0.039107, loss_ce: 0.016195
2022-01-20 21:09:50,766 iteration 1251 : loss : 0.055091, loss_ce: 0.024645
2022-01-20 21:09:51,424 iteration 1252 : loss : 0.047193, loss_ce: 0.022851
2022-01-20 21:09:51,975 iteration 1253 : loss : 0.040544, loss_ce: 0.015262
2022-01-20 21:09:52,600 iteration 1254 : loss : 0.049889, loss_ce: 0.031092
2022-01-20 21:09:53,240 iteration 1255 : loss : 0.060328, loss_ce: 0.026772
2022-01-20 21:09:53,848 iteration 1256 : loss : 0.050706, loss_ce: 0.021764
2022-01-20 21:09:54,469 iteration 1257 : loss : 0.055572, loss_ce: 0.016971
2022-01-20 21:09:55,110 iteration 1258 : loss : 0.030405, loss_ce: 0.015392
 18%|█████▌                        | 74/400 [14:24<1:00:26, 11.12s/it]2022-01-20 21:09:55,732 iteration 1259 : loss : 0.039851, loss_ce: 0.019650
2022-01-20 21:09:56,406 iteration 1260 : loss : 0.037642, loss_ce: 0.016409
2022-01-20 21:09:57,014 iteration 1261 : loss : 0.037125, loss_ce: 0.012988
2022-01-20 21:09:57,731 iteration 1262 : loss : 0.054705, loss_ce: 0.024387
2022-01-20 21:09:58,472 iteration 1263 : loss : 0.062135, loss_ce: 0.024545
2022-01-20 21:09:59,087 iteration 1264 : loss : 0.042312, loss_ce: 0.019608
2022-01-20 21:09:59,780 iteration 1265 : loss : 0.053238, loss_ce: 0.027551
2022-01-20 21:10:00,462 iteration 1266 : loss : 0.066330, loss_ce: 0.025864
2022-01-20 21:10:01,116 iteration 1267 : loss : 0.076305, loss_ce: 0.029073
2022-01-20 21:10:01,711 iteration 1268 : loss : 0.063889, loss_ce: 0.021981
2022-01-20 21:10:02,415 iteration 1269 : loss : 0.089233, loss_ce: 0.024914
2022-01-20 21:10:03,087 iteration 1270 : loss : 0.041631, loss_ce: 0.017409
2022-01-20 21:10:03,721 iteration 1271 : loss : 0.044334, loss_ce: 0.020679
2022-01-20 21:10:04,270 iteration 1272 : loss : 0.042889, loss_ce: 0.014916
2022-01-20 21:10:04,882 iteration 1273 : loss : 0.051753, loss_ce: 0.019438
2022-01-20 21:10:05,508 iteration 1274 : loss : 0.047379, loss_ce: 0.014369
2022-01-20 21:10:05,509 Training Data Eval:
2022-01-20 21:10:08,409   Average segmentation loss on training set: 0.0382
2022-01-20 21:10:08,410 Validation Data Eval:
2022-01-20 21:10:09,367   Average segmentation loss on validation set: 0.1060
2022-01-20 21:10:09,979 iteration 1275 : loss : 0.051983, loss_ce: 0.019761
 19%|█████▋                        | 75/400 [14:39<1:06:20, 12.25s/it]2022-01-20 21:10:10,559 iteration 1276 : loss : 0.042247, loss_ce: 0.018487
2022-01-20 21:10:11,289 iteration 1277 : loss : 0.044778, loss_ce: 0.017919
2022-01-20 21:10:11,875 iteration 1278 : loss : 0.043315, loss_ce: 0.016440
2022-01-20 21:10:12,596 iteration 1279 : loss : 0.063269, loss_ce: 0.026248
2022-01-20 21:10:13,250 iteration 1280 : loss : 0.057980, loss_ce: 0.027022
2022-01-20 21:10:13,901 iteration 1281 : loss : 0.074059, loss_ce: 0.030258
2022-01-20 21:10:14,478 iteration 1282 : loss : 0.031015, loss_ce: 0.014629
2022-01-20 21:10:15,169 iteration 1283 : loss : 0.050072, loss_ce: 0.017776
2022-01-20 21:10:15,760 iteration 1284 : loss : 0.050196, loss_ce: 0.021495
2022-01-20 21:10:16,457 iteration 1285 : loss : 0.062608, loss_ce: 0.022693
2022-01-20 21:10:17,175 iteration 1286 : loss : 0.146341, loss_ce: 0.043076
2022-01-20 21:10:17,784 iteration 1287 : loss : 0.040000, loss_ce: 0.021056
2022-01-20 21:10:18,370 iteration 1288 : loss : 0.045204, loss_ce: 0.020739
2022-01-20 21:10:18,998 iteration 1289 : loss : 0.039994, loss_ce: 0.016083
2022-01-20 21:10:19,659 iteration 1290 : loss : 0.065335, loss_ce: 0.032582
2022-01-20 21:10:20,331 iteration 1291 : loss : 0.059516, loss_ce: 0.027753
2022-01-20 21:10:21,032 iteration 1292 : loss : 0.055818, loss_ce: 0.022652
 19%|█████▋                        | 76/400 [14:50<1:04:12, 11.89s/it]2022-01-20 21:10:21,732 iteration 1293 : loss : 0.041172, loss_ce: 0.016176
2022-01-20 21:10:22,394 iteration 1294 : loss : 0.060475, loss_ce: 0.022345
2022-01-20 21:10:23,100 iteration 1295 : loss : 0.063546, loss_ce: 0.017564
2022-01-20 21:10:23,757 iteration 1296 : loss : 0.062251, loss_ce: 0.023942
2022-01-20 21:10:24,353 iteration 1297 : loss : 0.049995, loss_ce: 0.028657
2022-01-20 21:10:24,917 iteration 1298 : loss : 0.039863, loss_ce: 0.016041
2022-01-20 21:10:25,557 iteration 1299 : loss : 0.042623, loss_ce: 0.019666
2022-01-20 21:10:26,185 iteration 1300 : loss : 0.040890, loss_ce: 0.013467
2022-01-20 21:10:26,852 iteration 1301 : loss : 0.034076, loss_ce: 0.012086
2022-01-20 21:10:27,462 iteration 1302 : loss : 0.057217, loss_ce: 0.023943
2022-01-20 21:10:28,078 iteration 1303 : loss : 0.043460, loss_ce: 0.017674
2022-01-20 21:10:28,723 iteration 1304 : loss : 0.047405, loss_ce: 0.018507
2022-01-20 21:10:29,356 iteration 1305 : loss : 0.055097, loss_ce: 0.022732
2022-01-20 21:10:30,031 iteration 1306 : loss : 0.064882, loss_ce: 0.024317
2022-01-20 21:10:30,702 iteration 1307 : loss : 0.060434, loss_ce: 0.037392
2022-01-20 21:10:31,345 iteration 1308 : loss : 0.050105, loss_ce: 0.015459
2022-01-20 21:10:31,915 iteration 1309 : loss : 0.044134, loss_ce: 0.016547
 19%|█████▊                        | 77/400 [15:01<1:02:23, 11.59s/it]2022-01-20 21:10:32,651 iteration 1310 : loss : 0.040353, loss_ce: 0.015061
2022-01-20 21:10:33,257 iteration 1311 : loss : 0.043189, loss_ce: 0.020601
2022-01-20 21:10:33,850 iteration 1312 : loss : 0.028235, loss_ce: 0.011873
2022-01-20 21:10:34,448 iteration 1313 : loss : 0.056078, loss_ce: 0.016166
2022-01-20 21:10:35,079 iteration 1314 : loss : 0.043574, loss_ce: 0.021162
2022-01-20 21:10:35,746 iteration 1315 : loss : 0.064499, loss_ce: 0.027237
2022-01-20 21:10:36,498 iteration 1316 : loss : 0.045163, loss_ce: 0.018134
2022-01-20 21:10:37,120 iteration 1317 : loss : 0.048996, loss_ce: 0.025704
2022-01-20 21:10:37,831 iteration 1318 : loss : 0.085261, loss_ce: 0.019782
2022-01-20 21:10:38,504 iteration 1319 : loss : 0.042367, loss_ce: 0.018808
2022-01-20 21:10:39,122 iteration 1320 : loss : 0.041489, loss_ce: 0.018267
2022-01-20 21:10:39,783 iteration 1321 : loss : 0.067121, loss_ce: 0.019833
2022-01-20 21:10:40,365 iteration 1322 : loss : 0.049395, loss_ce: 0.022609
2022-01-20 21:10:40,989 iteration 1323 : loss : 0.073992, loss_ce: 0.027117
2022-01-20 21:10:41,649 iteration 1324 : loss : 0.034892, loss_ce: 0.015186
2022-01-20 21:10:42,354 iteration 1325 : loss : 0.083104, loss_ce: 0.032328
2022-01-20 21:10:42,894 iteration 1326 : loss : 0.048206, loss_ce: 0.019301
 20%|█████▊                        | 78/400 [15:12<1:01:12, 11.41s/it]2022-01-20 21:10:43,532 iteration 1327 : loss : 0.059163, loss_ce: 0.019623
2022-01-20 21:10:44,186 iteration 1328 : loss : 0.060294, loss_ce: 0.027941
2022-01-20 21:10:44,816 iteration 1329 : loss : 0.039056, loss_ce: 0.017824
2022-01-20 21:10:45,415 iteration 1330 : loss : 0.081647, loss_ce: 0.022923
2022-01-20 21:10:45,981 iteration 1331 : loss : 0.048677, loss_ce: 0.024520
2022-01-20 21:10:46,566 iteration 1332 : loss : 0.037887, loss_ce: 0.012473
2022-01-20 21:10:47,184 iteration 1333 : loss : 0.056473, loss_ce: 0.021097
2022-01-20 21:10:47,820 iteration 1334 : loss : 0.055571, loss_ce: 0.022645
2022-01-20 21:10:48,422 iteration 1335 : loss : 0.035779, loss_ce: 0.014637
2022-01-20 21:10:49,031 iteration 1336 : loss : 0.038991, loss_ce: 0.016385
2022-01-20 21:10:49,723 iteration 1337 : loss : 0.067126, loss_ce: 0.031217
2022-01-20 21:10:50,389 iteration 1338 : loss : 0.050648, loss_ce: 0.016776
2022-01-20 21:10:51,044 iteration 1339 : loss : 0.046896, loss_ce: 0.022607
2022-01-20 21:10:51,698 iteration 1340 : loss : 0.048258, loss_ce: 0.022698
2022-01-20 21:10:52,344 iteration 1341 : loss : 0.063045, loss_ce: 0.024997
2022-01-20 21:10:52,966 iteration 1342 : loss : 0.071416, loss_ce: 0.028552
2022-01-20 21:10:53,539 iteration 1343 : loss : 0.040887, loss_ce: 0.017180
 20%|██████▎                         | 79/400 [15:22<59:47, 11.18s/it]2022-01-20 21:10:54,205 iteration 1344 : loss : 0.069031, loss_ce: 0.026479
2022-01-20 21:10:54,905 iteration 1345 : loss : 0.053280, loss_ce: 0.019760
2022-01-20 21:10:55,516 iteration 1346 : loss : 0.073213, loss_ce: 0.035369
2022-01-20 21:10:56,216 iteration 1347 : loss : 0.038191, loss_ce: 0.018560
2022-01-20 21:10:56,964 iteration 1348 : loss : 0.069993, loss_ce: 0.026307
2022-01-20 21:10:57,613 iteration 1349 : loss : 0.050669, loss_ce: 0.019910
2022-01-20 21:10:58,253 iteration 1350 : loss : 0.046437, loss_ce: 0.023934
2022-01-20 21:10:58,884 iteration 1351 : loss : 0.041765, loss_ce: 0.021901
2022-01-20 21:10:59,571 iteration 1352 : loss : 0.046097, loss_ce: 0.022205
2022-01-20 21:11:00,240 iteration 1353 : loss : 0.047922, loss_ce: 0.017753
2022-01-20 21:11:00,926 iteration 1354 : loss : 0.073650, loss_ce: 0.028726
2022-01-20 21:11:01,672 iteration 1355 : loss : 0.141051, loss_ce: 0.041372
2022-01-20 21:11:02,337 iteration 1356 : loss : 0.047675, loss_ce: 0.020321
2022-01-20 21:11:03,007 iteration 1357 : loss : 0.041346, loss_ce: 0.017574
2022-01-20 21:11:03,703 iteration 1358 : loss : 0.055243, loss_ce: 0.021802
2022-01-20 21:11:04,337 iteration 1359 : loss : 0.053127, loss_ce: 0.022963
2022-01-20 21:11:04,337 Training Data Eval:
2022-01-20 21:11:07,237   Average segmentation loss on training set: 0.0342
2022-01-20 21:11:07,237 Validation Data Eval:
2022-01-20 21:11:08,188   Average segmentation loss on validation set: 0.1055
2022-01-20 21:11:08,886 iteration 1360 : loss : 0.040715, loss_ce: 0.011500
 20%|██████                        | 80/400 [15:38<1:06:16, 12.43s/it]2022-01-20 21:11:09,656 iteration 1361 : loss : 0.068239, loss_ce: 0.030573
2022-01-20 21:11:10,299 iteration 1362 : loss : 0.051645, loss_ce: 0.019272
2022-01-20 21:11:11,105 iteration 1363 : loss : 0.082580, loss_ce: 0.034373
2022-01-20 21:11:11,623 iteration 1364 : loss : 0.063679, loss_ce: 0.017822
2022-01-20 21:11:12,333 iteration 1365 : loss : 0.044673, loss_ce: 0.020559
2022-01-20 21:11:13,000 iteration 1366 : loss : 0.057055, loss_ce: 0.026379
2022-01-20 21:11:13,635 iteration 1367 : loss : 0.044280, loss_ce: 0.017996
2022-01-20 21:11:14,286 iteration 1368 : loss : 0.041481, loss_ce: 0.019006
2022-01-20 21:11:14,900 iteration 1369 : loss : 0.048233, loss_ce: 0.017859
2022-01-20 21:11:15,585 iteration 1370 : loss : 0.056008, loss_ce: 0.028427
2022-01-20 21:11:16,202 iteration 1371 : loss : 0.042718, loss_ce: 0.016794
2022-01-20 21:11:16,808 iteration 1372 : loss : 0.044108, loss_ce: 0.018299
2022-01-20 21:11:17,403 iteration 1373 : loss : 0.050792, loss_ce: 0.019382
2022-01-20 21:11:18,054 iteration 1374 : loss : 0.055626, loss_ce: 0.018861
2022-01-20 21:11:18,721 iteration 1375 : loss : 0.048522, loss_ce: 0.022835
2022-01-20 21:11:19,371 iteration 1376 : loss : 0.053709, loss_ce: 0.019052
2022-01-20 21:11:20,001 iteration 1377 : loss : 0.034062, loss_ce: 0.013579
 20%|██████                        | 81/400 [15:49<1:03:59, 12.04s/it]2022-01-20 21:11:20,608 iteration 1378 : loss : 0.045744, loss_ce: 0.018074
2022-01-20 21:11:21,291 iteration 1379 : loss : 0.035294, loss_ce: 0.014143
2022-01-20 21:11:21,934 iteration 1380 : loss : 0.038966, loss_ce: 0.015932
2022-01-20 21:11:22,651 iteration 1381 : loss : 0.046208, loss_ce: 0.019757
2022-01-20 21:11:23,212 iteration 1382 : loss : 0.043041, loss_ce: 0.016663
2022-01-20 21:11:23,919 iteration 1383 : loss : 0.043030, loss_ce: 0.016702
2022-01-20 21:11:24,569 iteration 1384 : loss : 0.054302, loss_ce: 0.020619
2022-01-20 21:11:25,146 iteration 1385 : loss : 0.052992, loss_ce: 0.019144
2022-01-20 21:11:25,756 iteration 1386 : loss : 0.036224, loss_ce: 0.013422
2022-01-20 21:11:26,370 iteration 1387 : loss : 0.049065, loss_ce: 0.019692
2022-01-20 21:11:27,010 iteration 1388 : loss : 0.042620, loss_ce: 0.013864
2022-01-20 21:11:27,650 iteration 1389 : loss : 0.057179, loss_ce: 0.024172
2022-01-20 21:11:28,338 iteration 1390 : loss : 0.036414, loss_ce: 0.014775
2022-01-20 21:11:29,046 iteration 1391 : loss : 0.042316, loss_ce: 0.017997
2022-01-20 21:11:29,732 iteration 1392 : loss : 0.049644, loss_ce: 0.024186
2022-01-20 21:11:30,348 iteration 1393 : loss : 0.049818, loss_ce: 0.016083
2022-01-20 21:11:31,044 iteration 1394 : loss : 0.036204, loss_ce: 0.016036
 20%|██████▏                       | 82/400 [16:00<1:02:12, 11.74s/it]2022-01-20 21:11:31,702 iteration 1395 : loss : 0.040818, loss_ce: 0.016888
2022-01-20 21:11:32,315 iteration 1396 : loss : 0.046123, loss_ce: 0.020420
2022-01-20 21:11:33,008 iteration 1397 : loss : 0.051438, loss_ce: 0.020530
2022-01-20 21:11:33,708 iteration 1398 : loss : 0.048613, loss_ce: 0.021928
2022-01-20 21:11:34,267 iteration 1399 : loss : 0.037659, loss_ce: 0.017313
2022-01-20 21:11:34,818 iteration 1400 : loss : 0.039647, loss_ce: 0.014074
2022-01-20 21:11:35,510 iteration 1401 : loss : 0.049135, loss_ce: 0.017046
2022-01-20 21:11:36,159 iteration 1402 : loss : 0.064782, loss_ce: 0.027486
2022-01-20 21:11:36,744 iteration 1403 : loss : 0.038358, loss_ce: 0.013234
2022-01-20 21:11:37,320 iteration 1404 : loss : 0.027621, loss_ce: 0.012436
2022-01-20 21:11:37,945 iteration 1405 : loss : 0.045302, loss_ce: 0.014585
2022-01-20 21:11:38,582 iteration 1406 : loss : 0.042693, loss_ce: 0.015448
2022-01-20 21:11:39,258 iteration 1407 : loss : 0.033956, loss_ce: 0.013446
2022-01-20 21:11:39,886 iteration 1408 : loss : 0.036598, loss_ce: 0.013605
2022-01-20 21:11:40,527 iteration 1409 : loss : 0.062865, loss_ce: 0.022012
2022-01-20 21:11:41,230 iteration 1410 : loss : 0.034293, loss_ce: 0.013958
2022-01-20 21:11:41,840 iteration 1411 : loss : 0.040369, loss_ce: 0.013442
 21%|██████▏                       | 83/400 [16:11<1:00:31, 11.45s/it]2022-01-20 21:11:42,483 iteration 1412 : loss : 0.042557, loss_ce: 0.018043
2022-01-20 21:11:43,195 iteration 1413 : loss : 0.056441, loss_ce: 0.019155
2022-01-20 21:11:43,820 iteration 1414 : loss : 0.042017, loss_ce: 0.015563
2022-01-20 21:11:44,505 iteration 1415 : loss : 0.038169, loss_ce: 0.010735
2022-01-20 21:11:45,129 iteration 1416 : loss : 0.037778, loss_ce: 0.015545
2022-01-20 21:11:45,734 iteration 1417 : loss : 0.042155, loss_ce: 0.016918
2022-01-20 21:11:46,338 iteration 1418 : loss : 0.059630, loss_ce: 0.026802
2022-01-20 21:11:46,919 iteration 1419 : loss : 0.040877, loss_ce: 0.016836
2022-01-20 21:11:47,597 iteration 1420 : loss : 0.048083, loss_ce: 0.016598
2022-01-20 21:11:48,309 iteration 1421 : loss : 0.054007, loss_ce: 0.022357
2022-01-20 21:11:48,968 iteration 1422 : loss : 0.042150, loss_ce: 0.014286
2022-01-20 21:11:49,539 iteration 1423 : loss : 0.039380, loss_ce: 0.016219
2022-01-20 21:11:50,198 iteration 1424 : loss : 0.046867, loss_ce: 0.020111
2022-01-20 21:11:50,851 iteration 1425 : loss : 0.029576, loss_ce: 0.012860
2022-01-20 21:11:51,438 iteration 1426 : loss : 0.041445, loss_ce: 0.017354
2022-01-20 21:11:52,067 iteration 1427 : loss : 0.053731, loss_ce: 0.021354
2022-01-20 21:11:52,603 iteration 1428 : loss : 0.038129, loss_ce: 0.014707
 21%|██████▋                         | 84/400 [16:22<59:14, 11.25s/it]2022-01-20 21:11:53,347 iteration 1429 : loss : 0.041792, loss_ce: 0.021134
2022-01-20 21:11:53,935 iteration 1430 : loss : 0.101674, loss_ce: 0.024381
2022-01-20 21:11:54,564 iteration 1431 : loss : 0.044273, loss_ce: 0.020953
2022-01-20 21:11:55,210 iteration 1432 : loss : 0.044681, loss_ce: 0.020783
2022-01-20 21:11:55,898 iteration 1433 : loss : 0.061190, loss_ce: 0.021130
2022-01-20 21:11:56,515 iteration 1434 : loss : 0.050893, loss_ce: 0.023048
2022-01-20 21:11:57,176 iteration 1435 : loss : 0.043069, loss_ce: 0.018764
2022-01-20 21:11:57,847 iteration 1436 : loss : 0.047944, loss_ce: 0.019771
2022-01-20 21:11:58,532 iteration 1437 : loss : 0.068964, loss_ce: 0.022858
2022-01-20 21:11:59,176 iteration 1438 : loss : 0.036391, loss_ce: 0.016312
2022-01-20 21:11:59,859 iteration 1439 : loss : 0.054437, loss_ce: 0.018770
2022-01-20 21:12:00,533 iteration 1440 : loss : 0.037627, loss_ce: 0.016231
2022-01-20 21:12:01,156 iteration 1441 : loss : 0.029340, loss_ce: 0.012874
2022-01-20 21:12:01,804 iteration 1442 : loss : 0.033100, loss_ce: 0.014153
2022-01-20 21:12:02,476 iteration 1443 : loss : 0.052610, loss_ce: 0.019867
2022-01-20 21:12:03,124 iteration 1444 : loss : 0.090058, loss_ce: 0.027782
2022-01-20 21:12:03,124 Training Data Eval:
2022-01-20 21:12:06,021   Average segmentation loss on training set: 0.0343
2022-01-20 21:12:06,021 Validation Data Eval:
2022-01-20 21:12:06,966   Average segmentation loss on validation set: 0.1001
2022-01-20 21:12:07,606 iteration 1445 : loss : 0.049647, loss_ce: 0.017811
 21%|██████▍                       | 85/400 [16:37<1:04:57, 12.37s/it]2022-01-20 21:12:08,369 iteration 1446 : loss : 0.035213, loss_ce: 0.012466
2022-01-20 21:12:08,991 iteration 1447 : loss : 0.044078, loss_ce: 0.016486
2022-01-20 21:12:09,563 iteration 1448 : loss : 0.041198, loss_ce: 0.022207
2022-01-20 21:12:10,228 iteration 1449 : loss : 0.053905, loss_ce: 0.018682
2022-01-20 21:12:10,961 iteration 1450 : loss : 0.040150, loss_ce: 0.018717
2022-01-20 21:12:11,710 iteration 1451 : loss : 0.063715, loss_ce: 0.033627
2022-01-20 21:12:12,315 iteration 1452 : loss : 0.033468, loss_ce: 0.011858
2022-01-20 21:12:12,928 iteration 1453 : loss : 0.035685, loss_ce: 0.018694
2022-01-20 21:12:13,587 iteration 1454 : loss : 0.052564, loss_ce: 0.018404
2022-01-20 21:12:14,192 iteration 1455 : loss : 0.033975, loss_ce: 0.015201
2022-01-20 21:12:14,915 iteration 1456 : loss : 0.090964, loss_ce: 0.030269
2022-01-20 21:12:15,556 iteration 1457 : loss : 0.040065, loss_ce: 0.017818
2022-01-20 21:12:16,183 iteration 1458 : loss : 0.046524, loss_ce: 0.015778
2022-01-20 21:12:16,785 iteration 1459 : loss : 0.037648, loss_ce: 0.011115
2022-01-20 21:12:17,499 iteration 1460 : loss : 0.056986, loss_ce: 0.028009
2022-01-20 21:12:18,146 iteration 1461 : loss : 0.042814, loss_ce: 0.018810
2022-01-20 21:12:18,832 iteration 1462 : loss : 0.043935, loss_ce: 0.020425
 22%|██████▍                       | 86/400 [16:48<1:02:57, 12.03s/it]2022-01-20 21:12:19,499 iteration 1463 : loss : 0.043260, loss_ce: 0.018959
2022-01-20 21:12:20,107 iteration 1464 : loss : 0.042166, loss_ce: 0.018450
2022-01-20 21:12:20,772 iteration 1465 : loss : 0.047845, loss_ce: 0.014809
2022-01-20 21:12:21,444 iteration 1466 : loss : 0.033042, loss_ce: 0.014307
2022-01-20 21:12:22,088 iteration 1467 : loss : 0.045465, loss_ce: 0.020683
2022-01-20 21:12:22,701 iteration 1468 : loss : 0.040001, loss_ce: 0.021585
2022-01-20 21:12:23,336 iteration 1469 : loss : 0.045777, loss_ce: 0.017706
2022-01-20 21:12:24,011 iteration 1470 : loss : 0.044284, loss_ce: 0.016847
2022-01-20 21:12:24,684 iteration 1471 : loss : 0.053601, loss_ce: 0.030531
2022-01-20 21:12:25,224 iteration 1472 : loss : 0.032732, loss_ce: 0.011916
2022-01-20 21:12:25,956 iteration 1473 : loss : 0.037817, loss_ce: 0.014550
2022-01-20 21:12:26,649 iteration 1474 : loss : 0.067185, loss_ce: 0.023850
2022-01-20 21:12:27,285 iteration 1475 : loss : 0.036354, loss_ce: 0.017855
2022-01-20 21:12:28,009 iteration 1476 : loss : 0.071244, loss_ce: 0.024324
2022-01-20 21:12:28,691 iteration 1477 : loss : 0.051786, loss_ce: 0.015774
2022-01-20 21:12:29,408 iteration 1478 : loss : 0.043190, loss_ce: 0.018931
2022-01-20 21:12:30,012 iteration 1479 : loss : 0.041319, loss_ce: 0.014489
 22%|██████▌                       | 87/400 [16:59<1:01:25, 11.78s/it]2022-01-20 21:12:30,704 iteration 1480 : loss : 0.056300, loss_ce: 0.019625
2022-01-20 21:12:31,323 iteration 1481 : loss : 0.041141, loss_ce: 0.015913
2022-01-20 21:12:31,959 iteration 1482 : loss : 0.042187, loss_ce: 0.018215
2022-01-20 21:12:32,682 iteration 1483 : loss : 0.045373, loss_ce: 0.017386
2022-01-20 21:12:33,449 iteration 1484 : loss : 0.046951, loss_ce: 0.016396
2022-01-20 21:12:34,154 iteration 1485 : loss : 0.036707, loss_ce: 0.017258
2022-01-20 21:12:34,775 iteration 1486 : loss : 0.039437, loss_ce: 0.016309
2022-01-20 21:12:35,413 iteration 1487 : loss : 0.034335, loss_ce: 0.016404
2022-01-20 21:12:36,070 iteration 1488 : loss : 0.034520, loss_ce: 0.013663
2022-01-20 21:12:36,736 iteration 1489 : loss : 0.033132, loss_ce: 0.013032
2022-01-20 21:12:37,424 iteration 1490 : loss : 0.049866, loss_ce: 0.019763
2022-01-20 21:12:38,151 iteration 1491 : loss : 0.047617, loss_ce: 0.020341
2022-01-20 21:12:38,758 iteration 1492 : loss : 0.038731, loss_ce: 0.015925
2022-01-20 21:12:39,444 iteration 1493 : loss : 0.042900, loss_ce: 0.016143
2022-01-20 21:12:40,058 iteration 1494 : loss : 0.030883, loss_ce: 0.013171
2022-01-20 21:12:40,675 iteration 1495 : loss : 0.041712, loss_ce: 0.018124
2022-01-20 21:12:41,315 iteration 1496 : loss : 0.045569, loss_ce: 0.014106
 22%|██████▌                       | 88/400 [17:10<1:00:29, 11.63s/it]2022-01-20 21:12:41,945 iteration 1497 : loss : 0.038051, loss_ce: 0.016579
2022-01-20 21:12:42,552 iteration 1498 : loss : 0.039787, loss_ce: 0.012120
2022-01-20 21:12:43,231 iteration 1499 : loss : 0.059705, loss_ce: 0.030081
2022-01-20 21:12:43,804 iteration 1500 : loss : 0.044652, loss_ce: 0.016235
2022-01-20 21:12:44,425 iteration 1501 : loss : 0.043806, loss_ce: 0.014749
2022-01-20 21:12:45,089 iteration 1502 : loss : 0.035398, loss_ce: 0.012917
2022-01-20 21:12:45,708 iteration 1503 : loss : 0.023806, loss_ce: 0.011398
2022-01-20 21:12:46,325 iteration 1504 : loss : 0.038883, loss_ce: 0.012963
2022-01-20 21:12:46,901 iteration 1505 : loss : 0.033254, loss_ce: 0.013288
2022-01-20 21:12:47,525 iteration 1506 : loss : 0.049742, loss_ce: 0.019288
2022-01-20 21:12:48,160 iteration 1507 : loss : 0.065101, loss_ce: 0.019280
2022-01-20 21:12:48,759 iteration 1508 : loss : 0.039901, loss_ce: 0.016089
2022-01-20 21:12:49,385 iteration 1509 : loss : 0.045709, loss_ce: 0.015569
2022-01-20 21:12:49,976 iteration 1510 : loss : 0.024550, loss_ce: 0.009952
2022-01-20 21:12:50,635 iteration 1511 : loss : 0.034333, loss_ce: 0.016164
2022-01-20 21:12:51,234 iteration 1512 : loss : 0.036304, loss_ce: 0.015725
2022-01-20 21:12:51,883 iteration 1513 : loss : 0.043912, loss_ce: 0.020672
 22%|███████                         | 89/400 [17:21<58:38, 11.31s/it]2022-01-20 21:12:52,531 iteration 1514 : loss : 0.046982, loss_ce: 0.016592
2022-01-20 21:12:53,167 iteration 1515 : loss : 0.054441, loss_ce: 0.021290
2022-01-20 21:12:53,820 iteration 1516 : loss : 0.053250, loss_ce: 0.019749
2022-01-20 21:12:54,447 iteration 1517 : loss : 0.044996, loss_ce: 0.022051
2022-01-20 21:12:55,110 iteration 1518 : loss : 0.030170, loss_ce: 0.010437
2022-01-20 21:12:55,720 iteration 1519 : loss : 0.031512, loss_ce: 0.011877
2022-01-20 21:12:56,325 iteration 1520 : loss : 0.037928, loss_ce: 0.012622
2022-01-20 21:12:56,940 iteration 1521 : loss : 0.041563, loss_ce: 0.016881
2022-01-20 21:12:57,691 iteration 1522 : loss : 0.043156, loss_ce: 0.014481
2022-01-20 21:12:58,281 iteration 1523 : loss : 0.045936, loss_ce: 0.020830
2022-01-20 21:12:58,942 iteration 1524 : loss : 0.047511, loss_ce: 0.016714
2022-01-20 21:12:59,550 iteration 1525 : loss : 0.029467, loss_ce: 0.012990
2022-01-20 21:13:00,246 iteration 1526 : loss : 0.031291, loss_ce: 0.012987
2022-01-20 21:13:00,942 iteration 1527 : loss : 0.064488, loss_ce: 0.028974
2022-01-20 21:13:01,615 iteration 1528 : loss : 0.046880, loss_ce: 0.016465
2022-01-20 21:13:02,217 iteration 1529 : loss : 0.045247, loss_ce: 0.016755
2022-01-20 21:13:02,217 Training Data Eval:
2022-01-20 21:13:05,127   Average segmentation loss on training set: 0.0309
2022-01-20 21:13:05,128 Validation Data Eval:
2022-01-20 21:13:06,078   Average segmentation loss on validation set: 0.0893
2022-01-20 21:13:06,628 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:13:07,240 iteration 1530 : loss : 0.040613, loss_ce: 0.016446
 22%|██████▊                       | 90/400 [17:36<1:04:43, 12.53s/it]2022-01-20 21:13:08,043 iteration 1531 : loss : 0.038995, loss_ce: 0.015538
2022-01-20 21:13:08,724 iteration 1532 : loss : 0.046990, loss_ce: 0.015908
2022-01-20 21:13:09,321 iteration 1533 : loss : 0.039226, loss_ce: 0.017121
2022-01-20 21:13:10,007 iteration 1534 : loss : 0.049511, loss_ce: 0.018591
2022-01-20 21:13:10,625 iteration 1535 : loss : 0.036834, loss_ce: 0.013938
2022-01-20 21:13:11,230 iteration 1536 : loss : 0.051546, loss_ce: 0.025361
2022-01-20 21:13:11,824 iteration 1537 : loss : 0.054373, loss_ce: 0.017180
2022-01-20 21:13:12,402 iteration 1538 : loss : 0.121158, loss_ce: 0.021596
2022-01-20 21:13:13,024 iteration 1539 : loss : 0.034552, loss_ce: 0.014045
2022-01-20 21:13:13,656 iteration 1540 : loss : 0.051683, loss_ce: 0.023946
2022-01-20 21:13:14,205 iteration 1541 : loss : 0.033458, loss_ce: 0.011180
2022-01-20 21:13:14,849 iteration 1542 : loss : 0.057118, loss_ce: 0.029670
2022-01-20 21:13:15,463 iteration 1543 : loss : 0.048724, loss_ce: 0.015619
2022-01-20 21:13:16,035 iteration 1544 : loss : 0.046809, loss_ce: 0.017414
2022-01-20 21:13:16,655 iteration 1545 : loss : 0.055843, loss_ce: 0.019515
2022-01-20 21:13:17,272 iteration 1546 : loss : 0.055356, loss_ce: 0.023117
2022-01-20 21:13:17,886 iteration 1547 : loss : 0.061582, loss_ce: 0.021782
 23%|██████▊                       | 91/400 [17:47<1:01:36, 11.96s/it]2022-01-20 21:13:18,561 iteration 1548 : loss : 0.042038, loss_ce: 0.015393
2022-01-20 21:13:19,136 iteration 1549 : loss : 0.036874, loss_ce: 0.015418
2022-01-20 21:13:19,873 iteration 1550 : loss : 0.060790, loss_ce: 0.022999
2022-01-20 21:13:20,504 iteration 1551 : loss : 0.048226, loss_ce: 0.019615
2022-01-20 21:13:21,139 iteration 1552 : loss : 0.042840, loss_ce: 0.019441
2022-01-20 21:13:21,685 iteration 1553 : loss : 0.032420, loss_ce: 0.016849
2022-01-20 21:13:22,271 iteration 1554 : loss : 0.055610, loss_ce: 0.019975
2022-01-20 21:13:22,956 iteration 1555 : loss : 0.042020, loss_ce: 0.016907
2022-01-20 21:13:23,707 iteration 1556 : loss : 0.048200, loss_ce: 0.021039
2022-01-20 21:13:24,406 iteration 1557 : loss : 0.072970, loss_ce: 0.019757
2022-01-20 21:13:25,054 iteration 1558 : loss : 0.048893, loss_ce: 0.013839
2022-01-20 21:13:25,804 iteration 1559 : loss : 0.064262, loss_ce: 0.026468
2022-01-20 21:13:26,423 iteration 1560 : loss : 0.052486, loss_ce: 0.015212
2022-01-20 21:13:27,041 iteration 1561 : loss : 0.056293, loss_ce: 0.021817
2022-01-20 21:13:27,682 iteration 1562 : loss : 0.040648, loss_ce: 0.017948
2022-01-20 21:13:28,301 iteration 1563 : loss : 0.056467, loss_ce: 0.029186
2022-01-20 21:13:28,938 iteration 1564 : loss : 0.042914, loss_ce: 0.016700
 23%|██████▉                       | 92/400 [17:58<1:00:00, 11.69s/it]2022-01-20 21:13:29,633 iteration 1565 : loss : 0.030790, loss_ce: 0.012148
2022-01-20 21:13:30,245 iteration 1566 : loss : 0.060411, loss_ce: 0.027860
2022-01-20 21:13:30,909 iteration 1567 : loss : 0.077878, loss_ce: 0.023159
2022-01-20 21:13:31,658 iteration 1568 : loss : 0.043693, loss_ce: 0.018200
2022-01-20 21:13:32,276 iteration 1569 : loss : 0.043626, loss_ce: 0.019047
2022-01-20 21:13:32,936 iteration 1570 : loss : 0.037493, loss_ce: 0.016289
2022-01-20 21:13:33,555 iteration 1571 : loss : 0.039890, loss_ce: 0.018195
2022-01-20 21:13:34,187 iteration 1572 : loss : 0.042625, loss_ce: 0.019535
2022-01-20 21:13:34,829 iteration 1573 : loss : 0.065063, loss_ce: 0.018889
2022-01-20 21:13:35,470 iteration 1574 : loss : 0.044446, loss_ce: 0.023463
2022-01-20 21:13:36,127 iteration 1575 : loss : 0.049372, loss_ce: 0.019968
2022-01-20 21:13:36,742 iteration 1576 : loss : 0.032979, loss_ce: 0.012323
2022-01-20 21:13:37,329 iteration 1577 : loss : 0.042119, loss_ce: 0.014920
2022-01-20 21:13:37,866 iteration 1578 : loss : 0.045555, loss_ce: 0.021376
2022-01-20 21:13:38,483 iteration 1579 : loss : 0.040297, loss_ce: 0.014869
2022-01-20 21:13:39,131 iteration 1580 : loss : 0.036692, loss_ce: 0.014264
2022-01-20 21:13:39,787 iteration 1581 : loss : 0.037781, loss_ce: 0.018018
 23%|███████▍                        | 93/400 [18:09<58:31, 11.44s/it]2022-01-20 21:13:40,508 iteration 1582 : loss : 0.052835, loss_ce: 0.029845
2022-01-20 21:13:41,155 iteration 1583 : loss : 0.046071, loss_ce: 0.013136
2022-01-20 21:13:41,748 iteration 1584 : loss : 0.032536, loss_ce: 0.011825
2022-01-20 21:13:42,368 iteration 1585 : loss : 0.031441, loss_ce: 0.014968
2022-01-20 21:13:42,923 iteration 1586 : loss : 0.026257, loss_ce: 0.012483
2022-01-20 21:13:43,533 iteration 1587 : loss : 0.045747, loss_ce: 0.017313
2022-01-20 21:13:44,148 iteration 1588 : loss : 0.042794, loss_ce: 0.013686
2022-01-20 21:13:44,784 iteration 1589 : loss : 0.047905, loss_ce: 0.019700
2022-01-20 21:13:45,534 iteration 1590 : loss : 0.042021, loss_ce: 0.016295
2022-01-20 21:13:46,144 iteration 1591 : loss : 0.035040, loss_ce: 0.015910
2022-01-20 21:13:46,691 iteration 1592 : loss : 0.029169, loss_ce: 0.012525
2022-01-20 21:13:47,328 iteration 1593 : loss : 0.038819, loss_ce: 0.013416
2022-01-20 21:13:47,948 iteration 1594 : loss : 0.040858, loss_ce: 0.015317
2022-01-20 21:13:48,529 iteration 1595 : loss : 0.046524, loss_ce: 0.024255
2022-01-20 21:13:49,077 iteration 1596 : loss : 0.039894, loss_ce: 0.014656
2022-01-20 21:13:49,722 iteration 1597 : loss : 0.061399, loss_ce: 0.018929
2022-01-20 21:13:50,383 iteration 1598 : loss : 0.040639, loss_ce: 0.015943
 24%|███████▌                        | 94/400 [18:19<57:02, 11.18s/it]2022-01-20 21:13:51,092 iteration 1599 : loss : 0.040688, loss_ce: 0.019709
2022-01-20 21:13:51,704 iteration 1600 : loss : 0.030614, loss_ce: 0.013469
2022-01-20 21:13:52,366 iteration 1601 : loss : 0.038548, loss_ce: 0.014757
2022-01-20 21:13:53,008 iteration 1602 : loss : 0.080188, loss_ce: 0.027242
2022-01-20 21:13:53,623 iteration 1603 : loss : 0.039892, loss_ce: 0.014166
2022-01-20 21:13:54,232 iteration 1604 : loss : 0.049795, loss_ce: 0.015742
2022-01-20 21:13:54,854 iteration 1605 : loss : 0.046664, loss_ce: 0.018801
2022-01-20 21:13:55,502 iteration 1606 : loss : 0.028211, loss_ce: 0.011560
2022-01-20 21:13:56,134 iteration 1607 : loss : 0.055095, loss_ce: 0.023494
2022-01-20 21:13:56,853 iteration 1608 : loss : 0.063883, loss_ce: 0.026338
2022-01-20 21:13:57,471 iteration 1609 : loss : 0.036782, loss_ce: 0.013766
2022-01-20 21:13:58,196 iteration 1610 : loss : 0.043259, loss_ce: 0.017127
2022-01-20 21:13:58,913 iteration 1611 : loss : 0.041816, loss_ce: 0.021124
2022-01-20 21:13:59,642 iteration 1612 : loss : 0.043386, loss_ce: 0.015753
2022-01-20 21:14:00,292 iteration 1613 : loss : 0.036989, loss_ce: 0.013222
2022-01-20 21:14:00,996 iteration 1614 : loss : 0.045857, loss_ce: 0.020201
2022-01-20 21:14:00,996 Training Data Eval:
2022-01-20 21:14:03,890   Average segmentation loss on training set: 0.0289
2022-01-20 21:14:03,890 Validation Data Eval:
2022-01-20 21:14:04,844   Average segmentation loss on validation set: 0.0809
2022-01-20 21:14:05,417 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:14:06,093 iteration 1615 : loss : 0.051630, loss_ce: 0.018155
 24%|███████▏                      | 95/400 [18:35<1:03:45, 12.54s/it]2022-01-20 21:14:06,770 iteration 1616 : loss : 0.038073, loss_ce: 0.014732
2022-01-20 21:14:07,386 iteration 1617 : loss : 0.056469, loss_ce: 0.026526
2022-01-20 21:14:07,963 iteration 1618 : loss : 0.035451, loss_ce: 0.013222
2022-01-20 21:14:08,587 iteration 1619 : loss : 0.044785, loss_ce: 0.025843
2022-01-20 21:14:09,338 iteration 1620 : loss : 0.039343, loss_ce: 0.012556
2022-01-20 21:14:10,093 iteration 1621 : loss : 0.044569, loss_ce: 0.018147
2022-01-20 21:14:10,728 iteration 1622 : loss : 0.043219, loss_ce: 0.018352
2022-01-20 21:14:11,319 iteration 1623 : loss : 0.035635, loss_ce: 0.012741
2022-01-20 21:14:11,973 iteration 1624 : loss : 0.041890, loss_ce: 0.018185
2022-01-20 21:14:12,542 iteration 1625 : loss : 0.037938, loss_ce: 0.013571
2022-01-20 21:14:13,157 iteration 1626 : loss : 0.031625, loss_ce: 0.013290
2022-01-20 21:14:13,917 iteration 1627 : loss : 0.053996, loss_ce: 0.019573
2022-01-20 21:14:14,644 iteration 1628 : loss : 0.041116, loss_ce: 0.017181
2022-01-20 21:14:15,252 iteration 1629 : loss : 0.038799, loss_ce: 0.014567
2022-01-20 21:14:15,837 iteration 1630 : loss : 0.025992, loss_ce: 0.010878
2022-01-20 21:14:16,430 iteration 1631 : loss : 0.039074, loss_ce: 0.014199
2022-01-20 21:14:17,039 iteration 1632 : loss : 0.031832, loss_ce: 0.013643
 24%|███████▏                      | 96/400 [18:46<1:01:07, 12.06s/it]2022-01-20 21:14:17,720 iteration 1633 : loss : 0.048989, loss_ce: 0.016349
2022-01-20 21:14:18,378 iteration 1634 : loss : 0.059207, loss_ce: 0.023144
2022-01-20 21:14:18,987 iteration 1635 : loss : 0.044759, loss_ce: 0.013787
2022-01-20 21:14:19,547 iteration 1636 : loss : 0.033708, loss_ce: 0.017173
2022-01-20 21:14:20,199 iteration 1637 : loss : 0.034146, loss_ce: 0.012077
2022-01-20 21:14:20,824 iteration 1638 : loss : 0.034058, loss_ce: 0.016140
2022-01-20 21:14:21,509 iteration 1639 : loss : 0.055302, loss_ce: 0.030027
2022-01-20 21:14:22,108 iteration 1640 : loss : 0.051042, loss_ce: 0.018456
2022-01-20 21:14:22,816 iteration 1641 : loss : 0.039849, loss_ce: 0.014410
2022-01-20 21:14:23,401 iteration 1642 : loss : 0.030723, loss_ce: 0.012207
2022-01-20 21:14:23,967 iteration 1643 : loss : 0.042085, loss_ce: 0.013850
2022-01-20 21:14:24,651 iteration 1644 : loss : 0.043916, loss_ce: 0.017163
2022-01-20 21:14:25,374 iteration 1645 : loss : 0.038798, loss_ce: 0.018790
2022-01-20 21:14:25,971 iteration 1646 : loss : 0.043314, loss_ce: 0.015725
2022-01-20 21:14:26,581 iteration 1647 : loss : 0.065938, loss_ce: 0.024138
2022-01-20 21:14:27,128 iteration 1648 : loss : 0.032543, loss_ce: 0.013412
2022-01-20 21:14:27,694 iteration 1649 : loss : 0.032574, loss_ce: 0.012912
 24%|███████▊                        | 97/400 [18:57<58:47, 11.64s/it]2022-01-20 21:14:28,478 iteration 1650 : loss : 0.062190, loss_ce: 0.037500
2022-01-20 21:14:29,092 iteration 1651 : loss : 0.045692, loss_ce: 0.015186
2022-01-20 21:14:29,735 iteration 1652 : loss : 0.046480, loss_ce: 0.016449
2022-01-20 21:14:30,337 iteration 1653 : loss : 0.044709, loss_ce: 0.015572
2022-01-20 21:14:30,951 iteration 1654 : loss : 0.036073, loss_ce: 0.012543
2022-01-20 21:14:31,535 iteration 1655 : loss : 0.042085, loss_ce: 0.015377
2022-01-20 21:14:32,208 iteration 1656 : loss : 0.049776, loss_ce: 0.020627
2022-01-20 21:14:32,825 iteration 1657 : loss : 0.037111, loss_ce: 0.016682
2022-01-20 21:14:33,513 iteration 1658 : loss : 0.084009, loss_ce: 0.056729
2022-01-20 21:14:34,241 iteration 1659 : loss : 0.054014, loss_ce: 0.021689
2022-01-20 21:14:34,891 iteration 1660 : loss : 0.035047, loss_ce: 0.013921
2022-01-20 21:14:35,475 iteration 1661 : loss : 0.036779, loss_ce: 0.012872
2022-01-20 21:14:36,152 iteration 1662 : loss : 0.046096, loss_ce: 0.017530
2022-01-20 21:14:36,853 iteration 1663 : loss : 0.044461, loss_ce: 0.023440
2022-01-20 21:14:37,485 iteration 1664 : loss : 0.053800, loss_ce: 0.017993
2022-01-20 21:14:38,102 iteration 1665 : loss : 0.060872, loss_ce: 0.028915
2022-01-20 21:14:38,747 iteration 1666 : loss : 0.039135, loss_ce: 0.012779
 24%|███████▊                        | 98/400 [19:08<57:41, 11.46s/it]2022-01-20 21:14:39,369 iteration 1667 : loss : 0.043686, loss_ce: 0.019649
2022-01-20 21:14:40,076 iteration 1668 : loss : 0.059827, loss_ce: 0.021468
2022-01-20 21:14:40,750 iteration 1669 : loss : 0.065657, loss_ce: 0.024938
2022-01-20 21:14:41,312 iteration 1670 : loss : 0.026404, loss_ce: 0.009673
2022-01-20 21:14:41,895 iteration 1671 : loss : 0.031315, loss_ce: 0.014477
2022-01-20 21:14:42,590 iteration 1672 : loss : 0.047088, loss_ce: 0.019414
2022-01-20 21:14:43,268 iteration 1673 : loss : 0.046407, loss_ce: 0.014643
2022-01-20 21:14:43,999 iteration 1674 : loss : 0.081288, loss_ce: 0.036292
2022-01-20 21:14:44,612 iteration 1675 : loss : 0.060178, loss_ce: 0.018449
2022-01-20 21:14:45,305 iteration 1676 : loss : 0.043226, loss_ce: 0.017755
2022-01-20 21:14:45,962 iteration 1677 : loss : 0.060538, loss_ce: 0.015191
2022-01-20 21:14:46,640 iteration 1678 : loss : 0.043490, loss_ce: 0.020644
2022-01-20 21:14:47,257 iteration 1679 : loss : 0.052869, loss_ce: 0.022086
2022-01-20 21:14:47,918 iteration 1680 : loss : 0.045643, loss_ce: 0.023159
2022-01-20 21:14:48,543 iteration 1681 : loss : 0.063108, loss_ce: 0.029562
2022-01-20 21:14:49,185 iteration 1682 : loss : 0.057426, loss_ce: 0.022991
2022-01-20 21:14:49,789 iteration 1683 : loss : 0.047199, loss_ce: 0.024209
 25%|███████▉                        | 99/400 [19:19<56:53, 11.34s/it]2022-01-20 21:14:50,491 iteration 1684 : loss : 0.053863, loss_ce: 0.023137
2022-01-20 21:14:51,086 iteration 1685 : loss : 0.048021, loss_ce: 0.022321
2022-01-20 21:14:51,647 iteration 1686 : loss : 0.041684, loss_ce: 0.015037
2022-01-20 21:14:52,246 iteration 1687 : loss : 0.043663, loss_ce: 0.016554
2022-01-20 21:14:52,886 iteration 1688 : loss : 0.050061, loss_ce: 0.024623
2022-01-20 21:14:53,477 iteration 1689 : loss : 0.056596, loss_ce: 0.025970
2022-01-20 21:14:54,140 iteration 1690 : loss : 0.062206, loss_ce: 0.026744
2022-01-20 21:14:54,763 iteration 1691 : loss : 0.035606, loss_ce: 0.014444
2022-01-20 21:14:55,441 iteration 1692 : loss : 0.064982, loss_ce: 0.024664
2022-01-20 21:14:56,137 iteration 1693 : loss : 0.041064, loss_ce: 0.020314
2022-01-20 21:14:56,800 iteration 1694 : loss : 0.042301, loss_ce: 0.020399
2022-01-20 21:14:57,359 iteration 1695 : loss : 0.060758, loss_ce: 0.020643
2022-01-20 21:14:57,976 iteration 1696 : loss : 0.048950, loss_ce: 0.018746
2022-01-20 21:14:58,653 iteration 1697 : loss : 0.062430, loss_ce: 0.017995
2022-01-20 21:14:59,275 iteration 1698 : loss : 0.034429, loss_ce: 0.010674
2022-01-20 21:14:59,803 iteration 1699 : loss : 0.055602, loss_ce: 0.029487
2022-01-20 21:14:59,803 Training Data Eval:
2022-01-20 21:15:02,704   Average segmentation loss on training set: 0.0321
2022-01-20 21:15:02,704 Validation Data Eval:
2022-01-20 21:15:03,659   Average segmentation loss on validation set: 0.0819
2022-01-20 21:15:04,306 iteration 1700 : loss : 0.048196, loss_ce: 0.015668
 25%|███████▎                     | 100/400 [19:33<1:01:27, 12.29s/it]2022-01-20 21:15:05,013 iteration 1701 : loss : 0.041273, loss_ce: 0.016511
2022-01-20 21:15:05,653 iteration 1702 : loss : 0.040676, loss_ce: 0.018897
2022-01-20 21:15:06,230 iteration 1703 : loss : 0.034876, loss_ce: 0.014414
2022-01-20 21:15:06,940 iteration 1704 : loss : 0.044068, loss_ce: 0.017597
2022-01-20 21:15:07,578 iteration 1705 : loss : 0.042300, loss_ce: 0.019731
2022-01-20 21:15:08,235 iteration 1706 : loss : 0.043427, loss_ce: 0.020648
2022-01-20 21:15:08,871 iteration 1707 : loss : 0.053912, loss_ce: 0.020070
2022-01-20 21:15:09,544 iteration 1708 : loss : 0.038471, loss_ce: 0.014389
2022-01-20 21:15:10,118 iteration 1709 : loss : 0.042449, loss_ce: 0.020037
2022-01-20 21:15:10,669 iteration 1710 : loss : 0.039618, loss_ce: 0.014766
2022-01-20 21:15:11,315 iteration 1711 : loss : 0.036428, loss_ce: 0.013646
2022-01-20 21:15:11,902 iteration 1712 : loss : 0.033205, loss_ce: 0.011136
2022-01-20 21:15:12,476 iteration 1713 : loss : 0.039580, loss_ce: 0.014583
2022-01-20 21:15:13,198 iteration 1714 : loss : 0.048081, loss_ce: 0.016592
2022-01-20 21:15:13,870 iteration 1715 : loss : 0.059710, loss_ce: 0.018159
2022-01-20 21:15:14,595 iteration 1716 : loss : 0.062915, loss_ce: 0.025900
2022-01-20 21:15:15,226 iteration 1717 : loss : 0.051620, loss_ce: 0.021256
 25%|███████▊                       | 101/400 [19:44<59:12, 11.88s/it]2022-01-20 21:15:15,864 iteration 1718 : loss : 0.037763, loss_ce: 0.013050
2022-01-20 21:15:16,515 iteration 1719 : loss : 0.036564, loss_ce: 0.015165
2022-01-20 21:15:17,053 iteration 1720 : loss : 0.032264, loss_ce: 0.010702
2022-01-20 21:15:17,674 iteration 1721 : loss : 0.041990, loss_ce: 0.018391
2022-01-20 21:15:18,352 iteration 1722 : loss : 0.032005, loss_ce: 0.011524
2022-01-20 21:15:18,983 iteration 1723 : loss : 0.050009, loss_ce: 0.021452
2022-01-20 21:15:19,657 iteration 1724 : loss : 0.036011, loss_ce: 0.012002
2022-01-20 21:15:20,417 iteration 1725 : loss : 0.066634, loss_ce: 0.020352
2022-01-20 21:15:21,124 iteration 1726 : loss : 0.064215, loss_ce: 0.014401
2022-01-20 21:15:21,768 iteration 1727 : loss : 0.034448, loss_ce: 0.016369
2022-01-20 21:15:22,384 iteration 1728 : loss : 0.051794, loss_ce: 0.016227
2022-01-20 21:15:23,008 iteration 1729 : loss : 0.035073, loss_ce: 0.015180
2022-01-20 21:15:23,656 iteration 1730 : loss : 0.031421, loss_ce: 0.012538
2022-01-20 21:15:24,365 iteration 1731 : loss : 0.048193, loss_ce: 0.017398
2022-01-20 21:15:25,012 iteration 1732 : loss : 0.033056, loss_ce: 0.015623
2022-01-20 21:15:25,729 iteration 1733 : loss : 0.035800, loss_ce: 0.014131
2022-01-20 21:15:26,321 iteration 1734 : loss : 0.031762, loss_ce: 0.012687
 26%|███████▉                       | 102/400 [19:55<57:49, 11.64s/it]2022-01-20 21:15:26,957 iteration 1735 : loss : 0.052867, loss_ce: 0.029356
2022-01-20 21:15:27,578 iteration 1736 : loss : 0.033294, loss_ce: 0.013977
2022-01-20 21:15:28,219 iteration 1737 : loss : 0.034817, loss_ce: 0.013838
2022-01-20 21:15:28,825 iteration 1738 : loss : 0.037535, loss_ce: 0.012818
2022-01-20 21:15:29,559 iteration 1739 : loss : 0.039995, loss_ce: 0.021123
2022-01-20 21:15:30,231 iteration 1740 : loss : 0.046450, loss_ce: 0.018282
2022-01-20 21:15:30,859 iteration 1741 : loss : 0.030958, loss_ce: 0.011952
2022-01-20 21:15:31,607 iteration 1742 : loss : 0.042950, loss_ce: 0.018661
2022-01-20 21:15:32,238 iteration 1743 : loss : 0.038507, loss_ce: 0.012179
2022-01-20 21:15:32,906 iteration 1744 : loss : 0.038313, loss_ce: 0.014107
2022-01-20 21:15:33,682 iteration 1745 : loss : 0.041119, loss_ce: 0.019889
2022-01-20 21:15:34,308 iteration 1746 : loss : 0.029075, loss_ce: 0.011805
2022-01-20 21:15:34,925 iteration 1747 : loss : 0.038746, loss_ce: 0.017811
2022-01-20 21:15:35,572 iteration 1748 : loss : 0.030980, loss_ce: 0.011683
2022-01-20 21:15:36,212 iteration 1749 : loss : 0.041584, loss_ce: 0.015137
2022-01-20 21:15:36,796 iteration 1750 : loss : 0.029604, loss_ce: 0.013701
2022-01-20 21:15:37,529 iteration 1751 : loss : 0.035735, loss_ce: 0.012701
 26%|███████▉                       | 103/400 [20:06<56:58, 11.51s/it]2022-01-20 21:15:38,178 iteration 1752 : loss : 0.045708, loss_ce: 0.016432
2022-01-20 21:15:38,776 iteration 1753 : loss : 0.040767, loss_ce: 0.020768
2022-01-20 21:15:39,390 iteration 1754 : loss : 0.036571, loss_ce: 0.014363
2022-01-20 21:15:40,017 iteration 1755 : loss : 0.037139, loss_ce: 0.013860
2022-01-20 21:15:40,671 iteration 1756 : loss : 0.047231, loss_ce: 0.020894
2022-01-20 21:15:41,375 iteration 1757 : loss : 0.048785, loss_ce: 0.023972
2022-01-20 21:15:42,048 iteration 1758 : loss : 0.061142, loss_ce: 0.024025
2022-01-20 21:15:42,611 iteration 1759 : loss : 0.066212, loss_ce: 0.019875
2022-01-20 21:15:43,229 iteration 1760 : loss : 0.041377, loss_ce: 0.016285
2022-01-20 21:15:43,819 iteration 1761 : loss : 0.033740, loss_ce: 0.012740
2022-01-20 21:15:44,444 iteration 1762 : loss : 0.036958, loss_ce: 0.015285
2022-01-20 21:15:44,996 iteration 1763 : loss : 0.046735, loss_ce: 0.018638
2022-01-20 21:15:45,715 iteration 1764 : loss : 0.031334, loss_ce: 0.009541
2022-01-20 21:15:46,355 iteration 1765 : loss : 0.058669, loss_ce: 0.019075
2022-01-20 21:15:47,043 iteration 1766 : loss : 0.036046, loss_ce: 0.015556
2022-01-20 21:15:47,706 iteration 1767 : loss : 0.072114, loss_ce: 0.036362
2022-01-20 21:15:48,337 iteration 1768 : loss : 0.059675, loss_ce: 0.019874
 26%|████████                       | 104/400 [20:17<55:45, 11.30s/it]2022-01-20 21:15:49,054 iteration 1769 : loss : 0.032472, loss_ce: 0.013823
2022-01-20 21:15:49,683 iteration 1770 : loss : 0.037942, loss_ce: 0.015192
2022-01-20 21:15:50,281 iteration 1771 : loss : 0.034098, loss_ce: 0.011799
2022-01-20 21:15:50,974 iteration 1772 : loss : 0.046447, loss_ce: 0.022392
2022-01-20 21:15:51,634 iteration 1773 : loss : 0.040527, loss_ce: 0.017954
2022-01-20 21:15:52,237 iteration 1774 : loss : 0.053836, loss_ce: 0.018210
2022-01-20 21:15:52,856 iteration 1775 : loss : 0.037660, loss_ce: 0.013865
2022-01-20 21:15:53,461 iteration 1776 : loss : 0.052221, loss_ce: 0.017567
2022-01-20 21:15:54,043 iteration 1777 : loss : 0.033863, loss_ce: 0.013606
2022-01-20 21:15:54,728 iteration 1778 : loss : 0.044800, loss_ce: 0.019995
2022-01-20 21:15:55,373 iteration 1779 : loss : 0.041334, loss_ce: 0.017811
2022-01-20 21:15:56,040 iteration 1780 : loss : 0.070819, loss_ce: 0.021334
2022-01-20 21:15:56,706 iteration 1781 : loss : 0.048711, loss_ce: 0.016378
2022-01-20 21:15:57,276 iteration 1782 : loss : 0.051228, loss_ce: 0.012494
2022-01-20 21:15:57,876 iteration 1783 : loss : 0.044459, loss_ce: 0.019647
2022-01-20 21:15:58,534 iteration 1784 : loss : 0.046222, loss_ce: 0.023276
2022-01-20 21:15:58,535 Training Data Eval:
2022-01-20 21:16:01,432   Average segmentation loss on training set: 0.0329
2022-01-20 21:16:01,433 Validation Data Eval:
2022-01-20 21:16:02,378   Average segmentation loss on validation set: 0.1685
2022-01-20 21:16:03,008 iteration 1785 : loss : 0.047454, loss_ce: 0.020948
 26%|███████▌                     | 105/400 [20:32<1:00:32, 12.31s/it]2022-01-20 21:16:03,729 iteration 1786 : loss : 0.061251, loss_ce: 0.023368
2022-01-20 21:16:04,314 iteration 1787 : loss : 0.067568, loss_ce: 0.018641
2022-01-20 21:16:04,959 iteration 1788 : loss : 0.041915, loss_ce: 0.018827
2022-01-20 21:16:05,617 iteration 1789 : loss : 0.040294, loss_ce: 0.021082
2022-01-20 21:16:06,394 iteration 1790 : loss : 0.035516, loss_ce: 0.013158
2022-01-20 21:16:07,050 iteration 1791 : loss : 0.041526, loss_ce: 0.018528
2022-01-20 21:16:07,715 iteration 1792 : loss : 0.033454, loss_ce: 0.012836
2022-01-20 21:16:08,396 iteration 1793 : loss : 0.092278, loss_ce: 0.034413
2022-01-20 21:16:09,024 iteration 1794 : loss : 0.041898, loss_ce: 0.023285
2022-01-20 21:16:09,565 iteration 1795 : loss : 0.032686, loss_ce: 0.013468
2022-01-20 21:16:10,281 iteration 1796 : loss : 0.034808, loss_ce: 0.016159
2022-01-20 21:16:10,877 iteration 1797 : loss : 0.037196, loss_ce: 0.015391
2022-01-20 21:16:11,528 iteration 1798 : loss : 0.036748, loss_ce: 0.014564
2022-01-20 21:16:12,241 iteration 1799 : loss : 0.038427, loss_ce: 0.015449
2022-01-20 21:16:12,829 iteration 1800 : loss : 0.033897, loss_ce: 0.012079
2022-01-20 21:16:13,471 iteration 1801 : loss : 0.040340, loss_ce: 0.014412
2022-01-20 21:16:14,164 iteration 1802 : loss : 0.048259, loss_ce: 0.017984
 26%|████████▏                      | 106/400 [20:43<58:37, 11.96s/it]2022-01-20 21:16:14,894 iteration 1803 : loss : 0.058236, loss_ce: 0.021650
2022-01-20 21:16:15,467 iteration 1804 : loss : 0.036893, loss_ce: 0.012147
2022-01-20 21:16:16,220 iteration 1805 : loss : 0.042177, loss_ce: 0.015396
2022-01-20 21:16:16,948 iteration 1806 : loss : 0.053781, loss_ce: 0.025173
2022-01-20 21:16:17,588 iteration 1807 : loss : 0.052929, loss_ce: 0.023027
2022-01-20 21:16:18,274 iteration 1808 : loss : 0.031361, loss_ce: 0.014814
2022-01-20 21:16:18,895 iteration 1809 : loss : 0.043383, loss_ce: 0.019502
2022-01-20 21:16:19,559 iteration 1810 : loss : 0.048655, loss_ce: 0.024226
2022-01-20 21:16:20,179 iteration 1811 : loss : 0.046856, loss_ce: 0.016078
2022-01-20 21:16:20,789 iteration 1812 : loss : 0.037100, loss_ce: 0.013037
2022-01-20 21:16:21,426 iteration 1813 : loss : 0.042038, loss_ce: 0.019625
2022-01-20 21:16:22,045 iteration 1814 : loss : 0.030707, loss_ce: 0.011383
2022-01-20 21:16:22,763 iteration 1815 : loss : 0.056442, loss_ce: 0.022151
2022-01-20 21:16:23,424 iteration 1816 : loss : 0.036556, loss_ce: 0.015038
2022-01-20 21:16:24,146 iteration 1817 : loss : 0.038514, loss_ce: 0.015306
2022-01-20 21:16:24,735 iteration 1818 : loss : 0.028743, loss_ce: 0.010457
2022-01-20 21:16:25,437 iteration 1819 : loss : 0.047931, loss_ce: 0.016123
 27%|████████▎                      | 107/400 [20:54<57:25, 11.76s/it]2022-01-20 21:16:26,015 iteration 1820 : loss : 0.031471, loss_ce: 0.012808
2022-01-20 21:16:26,768 iteration 1821 : loss : 0.046077, loss_ce: 0.014577
2022-01-20 21:16:27,457 iteration 1822 : loss : 0.066436, loss_ce: 0.032502
2022-01-20 21:16:28,174 iteration 1823 : loss : 0.057720, loss_ce: 0.027964
2022-01-20 21:16:28,844 iteration 1824 : loss : 0.074003, loss_ce: 0.019710
2022-01-20 21:16:29,444 iteration 1825 : loss : 0.039162, loss_ce: 0.015108
2022-01-20 21:16:30,153 iteration 1826 : loss : 0.032191, loss_ce: 0.011283
2022-01-20 21:16:30,749 iteration 1827 : loss : 0.031133, loss_ce: 0.011379
2022-01-20 21:16:31,397 iteration 1828 : loss : 0.038906, loss_ce: 0.014342
2022-01-20 21:16:32,005 iteration 1829 : loss : 0.045298, loss_ce: 0.020976
2022-01-20 21:16:32,730 iteration 1830 : loss : 0.042403, loss_ce: 0.014501
2022-01-20 21:16:33,386 iteration 1831 : loss : 0.038803, loss_ce: 0.017897
2022-01-20 21:16:34,002 iteration 1832 : loss : 0.045045, loss_ce: 0.020552
2022-01-20 21:16:34,584 iteration 1833 : loss : 0.043697, loss_ce: 0.018399
2022-01-20 21:16:35,213 iteration 1834 : loss : 0.041497, loss_ce: 0.016144
2022-01-20 21:16:35,853 iteration 1835 : loss : 0.036747, loss_ce: 0.015185
2022-01-20 21:16:36,454 iteration 1836 : loss : 0.045512, loss_ce: 0.014985
 27%|████████▎                      | 108/400 [21:05<56:08, 11.54s/it]2022-01-20 21:16:37,173 iteration 1837 : loss : 0.051109, loss_ce: 0.017984
2022-01-20 21:16:37,742 iteration 1838 : loss : 0.036992, loss_ce: 0.015579
2022-01-20 21:16:38,342 iteration 1839 : loss : 0.054083, loss_ce: 0.022538
2022-01-20 21:16:39,002 iteration 1840 : loss : 0.047753, loss_ce: 0.018613
2022-01-20 21:16:39,584 iteration 1841 : loss : 0.038161, loss_ce: 0.016327
2022-01-20 21:16:40,207 iteration 1842 : loss : 0.052094, loss_ce: 0.014171
2022-01-20 21:16:40,871 iteration 1843 : loss : 0.028194, loss_ce: 0.014552
2022-01-20 21:16:41,497 iteration 1844 : loss : 0.031268, loss_ce: 0.010052
2022-01-20 21:16:42,108 iteration 1845 : loss : 0.027402, loss_ce: 0.008954
2022-01-20 21:16:42,818 iteration 1846 : loss : 0.038303, loss_ce: 0.015948
2022-01-20 21:16:43,418 iteration 1847 : loss : 0.054835, loss_ce: 0.017089
2022-01-20 21:16:44,044 iteration 1848 : loss : 0.047995, loss_ce: 0.019843
2022-01-20 21:16:44,647 iteration 1849 : loss : 0.044321, loss_ce: 0.017501
2022-01-20 21:16:45,408 iteration 1850 : loss : 0.050494, loss_ce: 0.020162
2022-01-20 21:16:46,040 iteration 1851 : loss : 0.083055, loss_ce: 0.021116
2022-01-20 21:16:46,690 iteration 1852 : loss : 0.044430, loss_ce: 0.017908
2022-01-20 21:16:47,295 iteration 1853 : loss : 0.036863, loss_ce: 0.016152
 27%|████████▍                      | 109/400 [21:16<54:56, 11.33s/it]2022-01-20 21:16:47,941 iteration 1854 : loss : 0.032839, loss_ce: 0.012437
2022-01-20 21:16:48,626 iteration 1855 : loss : 0.037185, loss_ce: 0.015204
2022-01-20 21:16:49,322 iteration 1856 : loss : 0.042741, loss_ce: 0.013763
2022-01-20 21:16:50,036 iteration 1857 : loss : 0.033553, loss_ce: 0.013865
2022-01-20 21:16:50,696 iteration 1858 : loss : 0.037609, loss_ce: 0.015627
2022-01-20 21:16:51,359 iteration 1859 : loss : 0.044521, loss_ce: 0.018145
2022-01-20 21:16:51,957 iteration 1860 : loss : 0.034786, loss_ce: 0.013204
2022-01-20 21:16:52,648 iteration 1861 : loss : 0.042477, loss_ce: 0.016707
2022-01-20 21:16:53,237 iteration 1862 : loss : 0.035987, loss_ce: 0.016779
2022-01-20 21:16:53,870 iteration 1863 : loss : 0.046425, loss_ce: 0.019792
2022-01-20 21:16:54,540 iteration 1864 : loss : 0.055529, loss_ce: 0.013959
2022-01-20 21:16:55,095 iteration 1865 : loss : 0.035153, loss_ce: 0.016293
2022-01-20 21:16:55,801 iteration 1866 : loss : 0.036726, loss_ce: 0.020571
2022-01-20 21:16:56,443 iteration 1867 : loss : 0.025173, loss_ce: 0.010757
2022-01-20 21:16:57,044 iteration 1868 : loss : 0.038199, loss_ce: 0.015359
2022-01-20 21:16:57,637 iteration 1869 : loss : 0.055898, loss_ce: 0.018502
2022-01-20 21:16:57,637 Training Data Eval:
2022-01-20 21:17:00,534   Average segmentation loss on training set: 0.0255
2022-01-20 21:17:00,534 Validation Data Eval:
2022-01-20 21:17:01,492   Average segmentation loss on validation set: 0.0794
2022-01-20 21:17:02,252 Found new lowest validation loss at iteration 1869! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:17:02,928 iteration 1870 : loss : 0.031704, loss_ce: 0.013029
 28%|███████▉                     | 110/400 [21:32<1:00:59, 12.62s/it]2022-01-20 21:17:03,658 iteration 1871 : loss : 0.038550, loss_ce: 0.015005
2022-01-20 21:17:04,399 iteration 1872 : loss : 0.073245, loss_ce: 0.025549
2022-01-20 21:17:04,988 iteration 1873 : loss : 0.043835, loss_ce: 0.015786
2022-01-20 21:17:05,692 iteration 1874 : loss : 0.051403, loss_ce: 0.023799
2022-01-20 21:17:06,245 iteration 1875 : loss : 0.030949, loss_ce: 0.010711
2022-01-20 21:17:06,956 iteration 1876 : loss : 0.043961, loss_ce: 0.013952
2022-01-20 21:17:07,639 iteration 1877 : loss : 0.058936, loss_ce: 0.022798
2022-01-20 21:17:08,248 iteration 1878 : loss : 0.032872, loss_ce: 0.014428
2022-01-20 21:17:08,850 iteration 1879 : loss : 0.044563, loss_ce: 0.017432
2022-01-20 21:17:09,445 iteration 1880 : loss : 0.039274, loss_ce: 0.019477
2022-01-20 21:17:10,079 iteration 1881 : loss : 0.037240, loss_ce: 0.013374
2022-01-20 21:17:10,664 iteration 1882 : loss : 0.035076, loss_ce: 0.011544
2022-01-20 21:17:11,214 iteration 1883 : loss : 0.042150, loss_ce: 0.014129
2022-01-20 21:17:11,882 iteration 1884 : loss : 0.051688, loss_ce: 0.018343
2022-01-20 21:17:12,426 iteration 1885 : loss : 0.027509, loss_ce: 0.011111
2022-01-20 21:17:13,142 iteration 1886 : loss : 0.038282, loss_ce: 0.017832
2022-01-20 21:17:13,857 iteration 1887 : loss : 0.035894, loss_ce: 0.017425
 28%|████████▌                      | 111/400 [21:43<58:20, 12.11s/it]2022-01-20 21:17:14,519 iteration 1888 : loss : 0.041496, loss_ce: 0.018083
2022-01-20 21:17:15,216 iteration 1889 : loss : 0.037757, loss_ce: 0.015542
2022-01-20 21:17:15,886 iteration 1890 : loss : 0.043486, loss_ce: 0.012703
2022-01-20 21:17:16,568 iteration 1891 : loss : 0.038764, loss_ce: 0.014979
2022-01-20 21:17:17,220 iteration 1892 : loss : 0.029000, loss_ce: 0.012501
2022-01-20 21:17:17,883 iteration 1893 : loss : 0.035681, loss_ce: 0.017901
2022-01-20 21:17:18,517 iteration 1894 : loss : 0.041832, loss_ce: 0.018835
2022-01-20 21:17:19,148 iteration 1895 : loss : 0.042689, loss_ce: 0.014363
2022-01-20 21:17:19,921 iteration 1896 : loss : 0.051890, loss_ce: 0.030221
2022-01-20 21:17:20,552 iteration 1897 : loss : 0.044537, loss_ce: 0.013503
2022-01-20 21:17:21,255 iteration 1898 : loss : 0.036319, loss_ce: 0.012694
2022-01-20 21:17:21,891 iteration 1899 : loss : 0.043041, loss_ce: 0.020726
2022-01-20 21:17:22,449 iteration 1900 : loss : 0.032791, loss_ce: 0.013529
2022-01-20 21:17:23,080 iteration 1901 : loss : 0.033442, loss_ce: 0.011717
2022-01-20 21:17:23,740 iteration 1902 : loss : 0.039113, loss_ce: 0.018766
2022-01-20 21:17:24,425 iteration 1903 : loss : 0.044626, loss_ce: 0.011953
2022-01-20 21:17:25,170 iteration 1904 : loss : 0.052234, loss_ce: 0.021084
 28%|████████▋                      | 112/400 [21:54<56:58, 11.87s/it]2022-01-20 21:17:25,796 iteration 1905 : loss : 0.027348, loss_ce: 0.011644
2022-01-20 21:17:26,494 iteration 1906 : loss : 0.039672, loss_ce: 0.013209
2022-01-20 21:17:27,245 iteration 1907 : loss : 0.034394, loss_ce: 0.013914
2022-01-20 21:17:27,928 iteration 1908 : loss : 0.034225, loss_ce: 0.015573
2022-01-20 21:17:28,636 iteration 1909 : loss : 0.039285, loss_ce: 0.020006
2022-01-20 21:17:29,336 iteration 1910 : loss : 0.043781, loss_ce: 0.021479
2022-01-20 21:17:30,102 iteration 1911 : loss : 0.031061, loss_ce: 0.012079
2022-01-20 21:17:30,790 iteration 1912 : loss : 0.036568, loss_ce: 0.010795
2022-01-20 21:17:31,426 iteration 1913 : loss : 0.034129, loss_ce: 0.013237
2022-01-20 21:17:32,025 iteration 1914 : loss : 0.030010, loss_ce: 0.013403
2022-01-20 21:17:32,671 iteration 1915 : loss : 0.046934, loss_ce: 0.014044
2022-01-20 21:17:33,308 iteration 1916 : loss : 0.035279, loss_ce: 0.013107
2022-01-20 21:17:33,978 iteration 1917 : loss : 0.043376, loss_ce: 0.016589
2022-01-20 21:17:34,578 iteration 1918 : loss : 0.038224, loss_ce: 0.016250
2022-01-20 21:17:35,207 iteration 1919 : loss : 0.030988, loss_ce: 0.012851
2022-01-20 21:17:35,891 iteration 1920 : loss : 0.033072, loss_ce: 0.010750
2022-01-20 21:17:36,578 iteration 1921 : loss : 0.041241, loss_ce: 0.015683
 28%|████████▊                      | 113/400 [22:05<56:06, 11.73s/it]2022-01-20 21:17:37,206 iteration 1922 : loss : 0.033060, loss_ce: 0.012125
2022-01-20 21:17:37,768 iteration 1923 : loss : 0.021612, loss_ce: 0.009077
2022-01-20 21:17:38,425 iteration 1924 : loss : 0.047328, loss_ce: 0.022962
2022-01-20 21:17:39,011 iteration 1925 : loss : 0.039495, loss_ce: 0.016537
2022-01-20 21:17:39,615 iteration 1926 : loss : 0.027046, loss_ce: 0.011510
2022-01-20 21:17:40,290 iteration 1927 : loss : 0.043787, loss_ce: 0.016413
2022-01-20 21:17:40,976 iteration 1928 : loss : 0.024062, loss_ce: 0.009471
2022-01-20 21:17:41,587 iteration 1929 : loss : 0.030375, loss_ce: 0.013517
2022-01-20 21:17:42,219 iteration 1930 : loss : 0.040160, loss_ce: 0.010810
2022-01-20 21:17:42,825 iteration 1931 : loss : 0.046785, loss_ce: 0.012622
2022-01-20 21:17:43,459 iteration 1932 : loss : 0.032202, loss_ce: 0.010377
2022-01-20 21:17:44,095 iteration 1933 : loss : 0.038956, loss_ce: 0.014365
2022-01-20 21:17:44,612 iteration 1934 : loss : 0.023179, loss_ce: 0.010477
2022-01-20 21:17:45,211 iteration 1935 : loss : 0.034741, loss_ce: 0.015982
2022-01-20 21:17:45,884 iteration 1936 : loss : 0.032569, loss_ce: 0.012953
2022-01-20 21:17:46,555 iteration 1937 : loss : 0.029344, loss_ce: 0.012071
2022-01-20 21:17:47,225 iteration 1938 : loss : 0.031465, loss_ce: 0.008489
 28%|████████▊                      | 114/400 [22:16<54:22, 11.41s/it]2022-01-20 21:17:47,843 iteration 1939 : loss : 0.026870, loss_ce: 0.012072
2022-01-20 21:17:48,455 iteration 1940 : loss : 0.027473, loss_ce: 0.010008
2022-01-20 21:17:49,151 iteration 1941 : loss : 0.035592, loss_ce: 0.016809
2022-01-20 21:17:49,791 iteration 1942 : loss : 0.042685, loss_ce: 0.013997
2022-01-20 21:17:50,357 iteration 1943 : loss : 0.023796, loss_ce: 0.008751
2022-01-20 21:17:50,959 iteration 1944 : loss : 0.031669, loss_ce: 0.013734
2022-01-20 21:17:51,573 iteration 1945 : loss : 0.030386, loss_ce: 0.016124
2022-01-20 21:17:52,190 iteration 1946 : loss : 0.031063, loss_ce: 0.012537
2022-01-20 21:17:52,796 iteration 1947 : loss : 0.035842, loss_ce: 0.013915
2022-01-20 21:17:53,397 iteration 1948 : loss : 0.032911, loss_ce: 0.013342
2022-01-20 21:17:53,952 iteration 1949 : loss : 0.029035, loss_ce: 0.015869
2022-01-20 21:17:54,623 iteration 1950 : loss : 0.036124, loss_ce: 0.013012
2022-01-20 21:17:55,358 iteration 1951 : loss : 0.044583, loss_ce: 0.016845
2022-01-20 21:17:55,938 iteration 1952 : loss : 0.027670, loss_ce: 0.007997
2022-01-20 21:17:56,587 iteration 1953 : loss : 0.035946, loss_ce: 0.016719
2022-01-20 21:17:57,288 iteration 1954 : loss : 0.045557, loss_ce: 0.013267
2022-01-20 21:17:57,288 Training Data Eval:
2022-01-20 21:18:00,186   Average segmentation loss on training set: 0.0249
2022-01-20 21:18:00,187 Validation Data Eval:
2022-01-20 21:18:01,137   Average segmentation loss on validation set: 0.0757
2022-01-20 21:18:01,714 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:18:02,329 iteration 1955 : loss : 0.027920, loss_ce: 0.010676
 29%|████████▉                      | 115/400 [22:31<59:27, 12.52s/it]2022-01-20 21:18:03,057 iteration 1956 : loss : 0.038142, loss_ce: 0.014115
2022-01-20 21:18:03,643 iteration 1957 : loss : 0.028681, loss_ce: 0.012049
2022-01-20 21:18:04,259 iteration 1958 : loss : 0.029738, loss_ce: 0.012665
2022-01-20 21:18:04,981 iteration 1959 : loss : 0.054100, loss_ce: 0.013253
2022-01-20 21:18:05,595 iteration 1960 : loss : 0.039763, loss_ce: 0.012785
2022-01-20 21:18:06,234 iteration 1961 : loss : 0.037743, loss_ce: 0.013704
2022-01-20 21:18:06,852 iteration 1962 : loss : 0.032568, loss_ce: 0.012330
2022-01-20 21:18:07,502 iteration 1963 : loss : 0.035821, loss_ce: 0.014747
2022-01-20 21:18:08,117 iteration 1964 : loss : 0.040015, loss_ce: 0.010511
2022-01-20 21:18:08,717 iteration 1965 : loss : 0.032628, loss_ce: 0.015314
2022-01-20 21:18:09,303 iteration 1966 : loss : 0.038044, loss_ce: 0.017400
2022-01-20 21:18:09,878 iteration 1967 : loss : 0.034187, loss_ce: 0.010822
2022-01-20 21:18:10,438 iteration 1968 : loss : 0.037436, loss_ce: 0.018565
2022-01-20 21:18:11,094 iteration 1969 : loss : 0.033802, loss_ce: 0.012284
2022-01-20 21:18:11,866 iteration 1970 : loss : 0.037490, loss_ce: 0.013739
2022-01-20 21:18:12,413 iteration 1971 : loss : 0.037470, loss_ce: 0.010357
2022-01-20 21:18:13,165 iteration 1972 : loss : 0.033665, loss_ce: 0.012978
 29%|████████▉                      | 116/400 [22:42<56:51, 12.01s/it]2022-01-20 21:18:13,755 iteration 1973 : loss : 0.026806, loss_ce: 0.010316
2022-01-20 21:18:14,317 iteration 1974 : loss : 0.038342, loss_ce: 0.015158
2022-01-20 21:18:15,018 iteration 1975 : loss : 0.049507, loss_ce: 0.019638
2022-01-20 21:18:15,570 iteration 1976 : loss : 0.036696, loss_ce: 0.013971
2022-01-20 21:18:16,281 iteration 1977 : loss : 0.066302, loss_ce: 0.022964
2022-01-20 21:18:16,877 iteration 1978 : loss : 0.036207, loss_ce: 0.013633
2022-01-20 21:18:17,489 iteration 1979 : loss : 0.035133, loss_ce: 0.017371
2022-01-20 21:18:18,165 iteration 1980 : loss : 0.034026, loss_ce: 0.011407
2022-01-20 21:18:18,755 iteration 1981 : loss : 0.039019, loss_ce: 0.014128
2022-01-20 21:18:19,453 iteration 1982 : loss : 0.031528, loss_ce: 0.010071
2022-01-20 21:18:20,186 iteration 1983 : loss : 0.032738, loss_ce: 0.013958
2022-01-20 21:18:20,788 iteration 1984 : loss : 0.032815, loss_ce: 0.010507
2022-01-20 21:18:21,405 iteration 1985 : loss : 0.032473, loss_ce: 0.011277
2022-01-20 21:18:21,999 iteration 1986 : loss : 0.033977, loss_ce: 0.011493
2022-01-20 21:18:22,588 iteration 1987 : loss : 0.026306, loss_ce: 0.010061
2022-01-20 21:18:23,303 iteration 1988 : loss : 0.030252, loss_ce: 0.011557
2022-01-20 21:18:23,936 iteration 1989 : loss : 0.028779, loss_ce: 0.013323
 29%|█████████                      | 117/400 [22:53<54:53, 11.64s/it]2022-01-20 21:18:24,603 iteration 1990 : loss : 0.035992, loss_ce: 0.013620
2022-01-20 21:18:25,149 iteration 1991 : loss : 0.031197, loss_ce: 0.013643
2022-01-20 21:18:25,816 iteration 1992 : loss : 0.031033, loss_ce: 0.014492
2022-01-20 21:18:26,432 iteration 1993 : loss : 0.047963, loss_ce: 0.012605
2022-01-20 21:18:27,092 iteration 1994 : loss : 0.032049, loss_ce: 0.013118
2022-01-20 21:18:27,720 iteration 1995 : loss : 0.030853, loss_ce: 0.011261
2022-01-20 21:18:28,363 iteration 1996 : loss : 0.043792, loss_ce: 0.019847
2022-01-20 21:18:29,002 iteration 1997 : loss : 0.034908, loss_ce: 0.015674
2022-01-20 21:18:29,671 iteration 1998 : loss : 0.036296, loss_ce: 0.013850
2022-01-20 21:18:30,338 iteration 1999 : loss : 0.045562, loss_ce: 0.021400
2022-01-20 21:18:31,109 iteration 2000 : loss : 0.052682, loss_ce: 0.014282
2022-01-20 21:18:31,757 iteration 2001 : loss : 0.047955, loss_ce: 0.018269
2022-01-20 21:18:32,319 iteration 2002 : loss : 0.028817, loss_ce: 0.012292
2022-01-20 21:18:32,828 iteration 2003 : loss : 0.025665, loss_ce: 0.011945
2022-01-20 21:18:33,419 iteration 2004 : loss : 0.060288, loss_ce: 0.020606
2022-01-20 21:18:34,096 iteration 2005 : loss : 0.031916, loss_ce: 0.010473
2022-01-20 21:18:34,763 iteration 2006 : loss : 0.047242, loss_ce: 0.015378
 30%|█████████▏                     | 118/400 [23:04<53:33, 11.39s/it]2022-01-20 21:18:35,500 iteration 2007 : loss : 0.035507, loss_ce: 0.012747
2022-01-20 21:18:36,249 iteration 2008 : loss : 0.043534, loss_ce: 0.013989
2022-01-20 21:18:36,886 iteration 2009 : loss : 0.052094, loss_ce: 0.020078
2022-01-20 21:18:37,519 iteration 2010 : loss : 0.077544, loss_ce: 0.025084
2022-01-20 21:18:38,249 iteration 2011 : loss : 0.049503, loss_ce: 0.018411
2022-01-20 21:18:38,901 iteration 2012 : loss : 0.036694, loss_ce: 0.017935
2022-01-20 21:18:39,466 iteration 2013 : loss : 0.031926, loss_ce: 0.014410
2022-01-20 21:18:40,078 iteration 2014 : loss : 0.052027, loss_ce: 0.020345
2022-01-20 21:18:40,759 iteration 2015 : loss : 0.037280, loss_ce: 0.015417
2022-01-20 21:18:41,385 iteration 2016 : loss : 0.079284, loss_ce: 0.032168
2022-01-20 21:18:42,080 iteration 2017 : loss : 0.055872, loss_ce: 0.018793
2022-01-20 21:18:42,825 iteration 2018 : loss : 0.044954, loss_ce: 0.021454
2022-01-20 21:18:43,442 iteration 2019 : loss : 0.047559, loss_ce: 0.017454
2022-01-20 21:18:44,044 iteration 2020 : loss : 0.044690, loss_ce: 0.017215
2022-01-20 21:18:44,703 iteration 2021 : loss : 0.056172, loss_ce: 0.021066
2022-01-20 21:18:45,363 iteration 2022 : loss : 0.041520, loss_ce: 0.017482
2022-01-20 21:18:46,067 iteration 2023 : loss : 0.050328, loss_ce: 0.018270
 30%|█████████▏                     | 119/400 [23:15<53:14, 11.37s/it]2022-01-20 21:18:46,697 iteration 2024 : loss : 0.044097, loss_ce: 0.013697
2022-01-20 21:18:47,360 iteration 2025 : loss : 0.038220, loss_ce: 0.017131
2022-01-20 21:18:48,057 iteration 2026 : loss : 0.047076, loss_ce: 0.020606
2022-01-20 21:18:48,683 iteration 2027 : loss : 0.038347, loss_ce: 0.010347
2022-01-20 21:18:49,269 iteration 2028 : loss : 0.027689, loss_ce: 0.014131
2022-01-20 21:18:49,887 iteration 2029 : loss : 0.036199, loss_ce: 0.013960
2022-01-20 21:18:50,489 iteration 2030 : loss : 0.042305, loss_ce: 0.018501
2022-01-20 21:18:51,131 iteration 2031 : loss : 0.052695, loss_ce: 0.021475
2022-01-20 21:18:51,863 iteration 2032 : loss : 0.047989, loss_ce: 0.018944
2022-01-20 21:18:52,617 iteration 2033 : loss : 0.052919, loss_ce: 0.025687
2022-01-20 21:18:53,218 iteration 2034 : loss : 0.038438, loss_ce: 0.016382
2022-01-20 21:18:53,860 iteration 2035 : loss : 0.035626, loss_ce: 0.012156
2022-01-20 21:18:54,539 iteration 2036 : loss : 0.035647, loss_ce: 0.015383
2022-01-20 21:18:55,172 iteration 2037 : loss : 0.056168, loss_ce: 0.014923
2022-01-20 21:18:55,849 iteration 2038 : loss : 0.040971, loss_ce: 0.018230
2022-01-20 21:18:56,581 iteration 2039 : loss : 0.057479, loss_ce: 0.023319
2022-01-20 21:18:56,581 Training Data Eval:
2022-01-20 21:18:59,478   Average segmentation loss on training set: 0.0292
2022-01-20 21:18:59,478 Validation Data Eval:
2022-01-20 21:19:00,423   Average segmentation loss on validation set: 0.1178
2022-01-20 21:19:01,137 iteration 2040 : loss : 0.058063, loss_ce: 0.023256
 30%|█████████▎                     | 120/400 [23:30<58:14, 12.48s/it]2022-01-20 21:19:01,863 iteration 2041 : loss : 0.066507, loss_ce: 0.018089
2022-01-20 21:19:02,483 iteration 2042 : loss : 0.041128, loss_ce: 0.014463
2022-01-20 21:19:03,096 iteration 2043 : loss : 0.030793, loss_ce: 0.010876
2022-01-20 21:19:03,724 iteration 2044 : loss : 0.046528, loss_ce: 0.017338
2022-01-20 21:19:04,325 iteration 2045 : loss : 0.031797, loss_ce: 0.011166
2022-01-20 21:19:04,967 iteration 2046 : loss : 0.040415, loss_ce: 0.018593
2022-01-20 21:19:05,579 iteration 2047 : loss : 0.040769, loss_ce: 0.016842
2022-01-20 21:19:06,222 iteration 2048 : loss : 0.030990, loss_ce: 0.010651
2022-01-20 21:19:06,834 iteration 2049 : loss : 0.030940, loss_ce: 0.007707
2022-01-20 21:19:07,493 iteration 2050 : loss : 0.050676, loss_ce: 0.022920
2022-01-20 21:19:08,146 iteration 2051 : loss : 0.037663, loss_ce: 0.017180
2022-01-20 21:19:08,723 iteration 2052 : loss : 0.025847, loss_ce: 0.010972
2022-01-20 21:19:09,364 iteration 2053 : loss : 0.052734, loss_ce: 0.016014
2022-01-20 21:19:09,973 iteration 2054 : loss : 0.028638, loss_ce: 0.011472
2022-01-20 21:19:10,593 iteration 2055 : loss : 0.034507, loss_ce: 0.011182
2022-01-20 21:19:11,274 iteration 2056 : loss : 0.038563, loss_ce: 0.017280
2022-01-20 21:19:11,862 iteration 2057 : loss : 0.032963, loss_ce: 0.013651
 30%|█████████▍                     | 121/400 [23:41<55:34, 11.95s/it]2022-01-20 21:19:12,552 iteration 2058 : loss : 0.033060, loss_ce: 0.015555
2022-01-20 21:19:13,253 iteration 2059 : loss : 0.042723, loss_ce: 0.016246
2022-01-20 21:19:13,806 iteration 2060 : loss : 0.036705, loss_ce: 0.013613
2022-01-20 21:19:14,472 iteration 2061 : loss : 0.041578, loss_ce: 0.015013
2022-01-20 21:19:15,086 iteration 2062 : loss : 0.040612, loss_ce: 0.014866
2022-01-20 21:19:15,714 iteration 2063 : loss : 0.071978, loss_ce: 0.014353
2022-01-20 21:19:16,292 iteration 2064 : loss : 0.025444, loss_ce: 0.008764
2022-01-20 21:19:16,904 iteration 2065 : loss : 0.036173, loss_ce: 0.010319
2022-01-20 21:19:17,534 iteration 2066 : loss : 0.038309, loss_ce: 0.013957
2022-01-20 21:19:18,201 iteration 2067 : loss : 0.030031, loss_ce: 0.011085
2022-01-20 21:19:18,896 iteration 2068 : loss : 0.030562, loss_ce: 0.013743
2022-01-20 21:19:19,511 iteration 2069 : loss : 0.030511, loss_ce: 0.008322
2022-01-20 21:19:20,192 iteration 2070 : loss : 0.031828, loss_ce: 0.012867
2022-01-20 21:19:20,888 iteration 2071 : loss : 0.044183, loss_ce: 0.015284
2022-01-20 21:19:21,543 iteration 2072 : loss : 0.041891, loss_ce: 0.015398
2022-01-20 21:19:22,242 iteration 2073 : loss : 0.045229, loss_ce: 0.015343
2022-01-20 21:19:22,922 iteration 2074 : loss : 0.033334, loss_ce: 0.017870
 30%|█████████▍                     | 122/400 [23:52<54:09, 11.69s/it]2022-01-20 21:19:23,576 iteration 2075 : loss : 0.024672, loss_ce: 0.008846
2022-01-20 21:19:24,220 iteration 2076 : loss : 0.044713, loss_ce: 0.013366
2022-01-20 21:19:24,884 iteration 2077 : loss : 0.027827, loss_ce: 0.011783
2022-01-20 21:19:25,643 iteration 2078 : loss : 0.053293, loss_ce: 0.019960
2022-01-20 21:19:26,258 iteration 2079 : loss : 0.042910, loss_ce: 0.014562
2022-01-20 21:19:26,948 iteration 2080 : loss : 0.046380, loss_ce: 0.015552
2022-01-20 21:19:27,496 iteration 2081 : loss : 0.029786, loss_ce: 0.011274
2022-01-20 21:19:28,026 iteration 2082 : loss : 0.021791, loss_ce: 0.007739
2022-01-20 21:19:28,645 iteration 2083 : loss : 0.038981, loss_ce: 0.021420
2022-01-20 21:19:29,260 iteration 2084 : loss : 0.053374, loss_ce: 0.027050
2022-01-20 21:19:29,843 iteration 2085 : loss : 0.038711, loss_ce: 0.010078
2022-01-20 21:19:30,463 iteration 2086 : loss : 0.044605, loss_ce: 0.017013
2022-01-20 21:19:31,055 iteration 2087 : loss : 0.036705, loss_ce: 0.015020
2022-01-20 21:19:31,749 iteration 2088 : loss : 0.030626, loss_ce: 0.013538
2022-01-20 21:19:32,422 iteration 2089 : loss : 0.035004, loss_ce: 0.015763
2022-01-20 21:19:32,988 iteration 2090 : loss : 0.028678, loss_ce: 0.012091
2022-01-20 21:19:33,688 iteration 2091 : loss : 0.030959, loss_ce: 0.013553
 31%|█████████▌                     | 123/400 [24:03<52:40, 11.41s/it]2022-01-20 21:19:34,287 iteration 2092 : loss : 0.026551, loss_ce: 0.012137
2022-01-20 21:19:34,896 iteration 2093 : loss : 0.034133, loss_ce: 0.013633
2022-01-20 21:19:35,527 iteration 2094 : loss : 0.038437, loss_ce: 0.010149
2022-01-20 21:19:36,100 iteration 2095 : loss : 0.026199, loss_ce: 0.011235
2022-01-20 21:19:36,810 iteration 2096 : loss : 0.036318, loss_ce: 0.017407
2022-01-20 21:19:37,461 iteration 2097 : loss : 0.047445, loss_ce: 0.016786
2022-01-20 21:19:38,103 iteration 2098 : loss : 0.039994, loss_ce: 0.015284
2022-01-20 21:19:38,763 iteration 2099 : loss : 0.030150, loss_ce: 0.009244
2022-01-20 21:19:39,443 iteration 2100 : loss : 0.041573, loss_ce: 0.021408
2022-01-20 21:19:40,109 iteration 2101 : loss : 0.034342, loss_ce: 0.011175
2022-01-20 21:19:40,795 iteration 2102 : loss : 0.041873, loss_ce: 0.020606
2022-01-20 21:19:41,351 iteration 2103 : loss : 0.037742, loss_ce: 0.016752
2022-01-20 21:19:41,925 iteration 2104 : loss : 0.050415, loss_ce: 0.019518
2022-01-20 21:19:42,647 iteration 2105 : loss : 0.050444, loss_ce: 0.017315
2022-01-20 21:19:43,247 iteration 2106 : loss : 0.024733, loss_ce: 0.011007
2022-01-20 21:19:43,961 iteration 2107 : loss : 0.025875, loss_ce: 0.009695
2022-01-20 21:19:44,621 iteration 2108 : loss : 0.038311, loss_ce: 0.015387
 31%|█████████▌                     | 124/400 [24:14<51:49, 11.27s/it]2022-01-20 21:19:45,301 iteration 2109 : loss : 0.042256, loss_ce: 0.018307
2022-01-20 21:19:45,986 iteration 2110 : loss : 0.030137, loss_ce: 0.011277
2022-01-20 21:19:46,716 iteration 2111 : loss : 0.043444, loss_ce: 0.012288
2022-01-20 21:19:47,366 iteration 2112 : loss : 0.054323, loss_ce: 0.021091
2022-01-20 21:19:47,968 iteration 2113 : loss : 0.049427, loss_ce: 0.024167
2022-01-20 21:19:48,636 iteration 2114 : loss : 0.035544, loss_ce: 0.016559
2022-01-20 21:19:49,303 iteration 2115 : loss : 0.037906, loss_ce: 0.012340
2022-01-20 21:19:49,968 iteration 2116 : loss : 0.040017, loss_ce: 0.015233
2022-01-20 21:19:50,626 iteration 2117 : loss : 0.036303, loss_ce: 0.013579
2022-01-20 21:19:51,306 iteration 2118 : loss : 0.046097, loss_ce: 0.015932
2022-01-20 21:19:51,988 iteration 2119 : loss : 0.059187, loss_ce: 0.018507
2022-01-20 21:19:52,631 iteration 2120 : loss : 0.043117, loss_ce: 0.015596
2022-01-20 21:19:53,172 iteration 2121 : loss : 0.027151, loss_ce: 0.010867
2022-01-20 21:19:53,787 iteration 2122 : loss : 0.027394, loss_ce: 0.009740
2022-01-20 21:19:54,478 iteration 2123 : loss : 0.038014, loss_ce: 0.016947
2022-01-20 21:19:55,204 iteration 2124 : loss : 0.032519, loss_ce: 0.013440
2022-01-20 21:19:55,204 Training Data Eval:
2022-01-20 21:19:58,110   Average segmentation loss on training set: 0.0260
2022-01-20 21:19:58,110 Validation Data Eval:
2022-01-20 21:19:59,061   Average segmentation loss on validation set: 0.1100
2022-01-20 21:19:59,717 iteration 2125 : loss : 0.040140, loss_ce: 0.021258
 31%|█████████▋                     | 125/400 [24:29<56:54, 12.42s/it]2022-01-20 21:20:00,443 iteration 2126 : loss : 0.053093, loss_ce: 0.024526
2022-01-20 21:20:01,109 iteration 2127 : loss : 0.043497, loss_ce: 0.017884
2022-01-20 21:20:01,767 iteration 2128 : loss : 0.037981, loss_ce: 0.012111
2022-01-20 21:20:02,370 iteration 2129 : loss : 0.031731, loss_ce: 0.011887
2022-01-20 21:20:03,042 iteration 2130 : loss : 0.063428, loss_ce: 0.019654
2022-01-20 21:20:03,660 iteration 2131 : loss : 0.037037, loss_ce: 0.009729
2022-01-20 21:20:04,351 iteration 2132 : loss : 0.026654, loss_ce: 0.009973
2022-01-20 21:20:05,069 iteration 2133 : loss : 0.041863, loss_ce: 0.012997
2022-01-20 21:20:05,640 iteration 2134 : loss : 0.034442, loss_ce: 0.016981
2022-01-20 21:20:06,278 iteration 2135 : loss : 0.045489, loss_ce: 0.018299
2022-01-20 21:20:06,902 iteration 2136 : loss : 0.039343, loss_ce: 0.017325
2022-01-20 21:20:07,538 iteration 2137 : loss : 0.053266, loss_ce: 0.021003
2022-01-20 21:20:08,133 iteration 2138 : loss : 0.029976, loss_ce: 0.011921
2022-01-20 21:20:08,805 iteration 2139 : loss : 0.034329, loss_ce: 0.015286
2022-01-20 21:20:09,439 iteration 2140 : loss : 0.038134, loss_ce: 0.017319
2022-01-20 21:20:10,138 iteration 2141 : loss : 0.034860, loss_ce: 0.011477
2022-01-20 21:20:10,736 iteration 2142 : loss : 0.037594, loss_ce: 0.012410
 32%|█████████▊                     | 126/400 [24:40<54:47, 12.00s/it]2022-01-20 21:20:11,341 iteration 2143 : loss : 0.031326, loss_ce: 0.012702
2022-01-20 21:20:11,997 iteration 2144 : loss : 0.036032, loss_ce: 0.011212
2022-01-20 21:20:12,663 iteration 2145 : loss : 0.048916, loss_ce: 0.015942
2022-01-20 21:20:13,251 iteration 2146 : loss : 0.020491, loss_ce: 0.008792
2022-01-20 21:20:13,905 iteration 2147 : loss : 0.030635, loss_ce: 0.011105
2022-01-20 21:20:14,517 iteration 2148 : loss : 0.031108, loss_ce: 0.012597
2022-01-20 21:20:15,158 iteration 2149 : loss : 0.029835, loss_ce: 0.011805
2022-01-20 21:20:15,765 iteration 2150 : loss : 0.022679, loss_ce: 0.009251
2022-01-20 21:20:16,477 iteration 2151 : loss : 0.037987, loss_ce: 0.016785
2022-01-20 21:20:17,076 iteration 2152 : loss : 0.027342, loss_ce: 0.011370
2022-01-20 21:20:17,663 iteration 2153 : loss : 0.025648, loss_ce: 0.011144
2022-01-20 21:20:18,435 iteration 2154 : loss : 0.050103, loss_ce: 0.018658
2022-01-20 21:20:19,076 iteration 2155 : loss : 0.040139, loss_ce: 0.015109
2022-01-20 21:20:19,661 iteration 2156 : loss : 0.033126, loss_ce: 0.014184
2022-01-20 21:20:20,440 iteration 2157 : loss : 0.074697, loss_ce: 0.022628
2022-01-20 21:20:21,170 iteration 2158 : loss : 0.044970, loss_ce: 0.022094
2022-01-20 21:20:21,840 iteration 2159 : loss : 0.055293, loss_ce: 0.013899
 32%|█████████▊                     | 127/400 [24:51<53:21, 11.73s/it]2022-01-20 21:20:22,483 iteration 2160 : loss : 0.035473, loss_ce: 0.013464
2022-01-20 21:20:23,066 iteration 2161 : loss : 0.028428, loss_ce: 0.008970
2022-01-20 21:20:23,687 iteration 2162 : loss : 0.030407, loss_ce: 0.012274
2022-01-20 21:20:24,297 iteration 2163 : loss : 0.040987, loss_ce: 0.014538
2022-01-20 21:20:24,975 iteration 2164 : loss : 0.029378, loss_ce: 0.014932
2022-01-20 21:20:25,640 iteration 2165 : loss : 0.052215, loss_ce: 0.017841
2022-01-20 21:20:26,228 iteration 2166 : loss : 0.040039, loss_ce: 0.017264
2022-01-20 21:20:26,790 iteration 2167 : loss : 0.028834, loss_ce: 0.010818
2022-01-20 21:20:27,399 iteration 2168 : loss : 0.025372, loss_ce: 0.010888
2022-01-20 21:20:28,061 iteration 2169 : loss : 0.036628, loss_ce: 0.013793
2022-01-20 21:20:28,586 iteration 2170 : loss : 0.027246, loss_ce: 0.010033
2022-01-20 21:20:29,199 iteration 2171 : loss : 0.031654, loss_ce: 0.013966
2022-01-20 21:20:29,801 iteration 2172 : loss : 0.043555, loss_ce: 0.014359
2022-01-20 21:20:30,397 iteration 2173 : loss : 0.047451, loss_ce: 0.013316
2022-01-20 21:20:31,031 iteration 2174 : loss : 0.036894, loss_ce: 0.013939
2022-01-20 21:20:31,755 iteration 2175 : loss : 0.031722, loss_ce: 0.016052
2022-01-20 21:20:32,286 iteration 2176 : loss : 0.027303, loss_ce: 0.012429
 32%|█████████▉                     | 128/400 [25:01<51:25, 11.34s/it]2022-01-20 21:20:32,888 iteration 2177 : loss : 0.047929, loss_ce: 0.023603
2022-01-20 21:20:33,523 iteration 2178 : loss : 0.027557, loss_ce: 0.008656
2022-01-20 21:20:34,239 iteration 2179 : loss : 0.037160, loss_ce: 0.011256
2022-01-20 21:20:34,922 iteration 2180 : loss : 0.036533, loss_ce: 0.012642
2022-01-20 21:20:35,486 iteration 2181 : loss : 0.033138, loss_ce: 0.012457
2022-01-20 21:20:36,113 iteration 2182 : loss : 0.053099, loss_ce: 0.022228
2022-01-20 21:20:36,765 iteration 2183 : loss : 0.051378, loss_ce: 0.018320
2022-01-20 21:20:37,342 iteration 2184 : loss : 0.037551, loss_ce: 0.021197
2022-01-20 21:20:37,926 iteration 2185 : loss : 0.031051, loss_ce: 0.010766
2022-01-20 21:20:38,641 iteration 2186 : loss : 0.037019, loss_ce: 0.013602
2022-01-20 21:20:39,367 iteration 2187 : loss : 0.049645, loss_ce: 0.016905
2022-01-20 21:20:40,152 iteration 2188 : loss : 0.049712, loss_ce: 0.026244
2022-01-20 21:20:40,935 iteration 2189 : loss : 0.048859, loss_ce: 0.018174
2022-01-20 21:20:41,594 iteration 2190 : loss : 0.037769, loss_ce: 0.015888
2022-01-20 21:20:42,262 iteration 2191 : loss : 0.034667, loss_ce: 0.013543
2022-01-20 21:20:42,866 iteration 2192 : loss : 0.041435, loss_ce: 0.013968
2022-01-20 21:20:43,519 iteration 2193 : loss : 0.023744, loss_ce: 0.008772
 32%|█████████▉                     | 129/400 [25:12<51:05, 11.31s/it]2022-01-20 21:20:44,228 iteration 2194 : loss : 0.032797, loss_ce: 0.012801
2022-01-20 21:20:44,896 iteration 2195 : loss : 0.035600, loss_ce: 0.017312
2022-01-20 21:20:45,593 iteration 2196 : loss : 0.034137, loss_ce: 0.016613
2022-01-20 21:20:46,323 iteration 2197 : loss : 0.026864, loss_ce: 0.010212
2022-01-20 21:20:46,964 iteration 2198 : loss : 0.034047, loss_ce: 0.011474
2022-01-20 21:20:47,609 iteration 2199 : loss : 0.033391, loss_ce: 0.015479
2022-01-20 21:20:48,331 iteration 2200 : loss : 0.070984, loss_ce: 0.014304
2022-01-20 21:20:48,916 iteration 2201 : loss : 0.030418, loss_ce: 0.011694
2022-01-20 21:20:49,666 iteration 2202 : loss : 0.048075, loss_ce: 0.020382
2022-01-20 21:20:50,343 iteration 2203 : loss : 0.040272, loss_ce: 0.011766
2022-01-20 21:20:50,921 iteration 2204 : loss : 0.032951, loss_ce: 0.010086
2022-01-20 21:20:51,573 iteration 2205 : loss : 0.040026, loss_ce: 0.018040
2022-01-20 21:20:52,296 iteration 2206 : loss : 0.058342, loss_ce: 0.026777
2022-01-20 21:20:52,977 iteration 2207 : loss : 0.034945, loss_ce: 0.011694
2022-01-20 21:20:53,694 iteration 2208 : loss : 0.048946, loss_ce: 0.014745
2022-01-20 21:20:54,346 iteration 2209 : loss : 0.041652, loss_ce: 0.019615
2022-01-20 21:20:54,347 Training Data Eval:
2022-01-20 21:20:57,240   Average segmentation loss on training set: 0.0263
2022-01-20 21:20:57,241 Validation Data Eval:
2022-01-20 21:20:58,198   Average segmentation loss on validation set: 0.1000
2022-01-20 21:20:58,862 iteration 2210 : loss : 0.042739, loss_ce: 0.021195
 32%|██████████                     | 130/400 [25:28<56:20, 12.52s/it]2022-01-20 21:20:59,545 iteration 2211 : loss : 0.030985, loss_ce: 0.009002
2022-01-20 21:21:00,135 iteration 2212 : loss : 0.042937, loss_ce: 0.018679
2022-01-20 21:21:00,773 iteration 2213 : loss : 0.063080, loss_ce: 0.013167
2022-01-20 21:21:01,334 iteration 2214 : loss : 0.035015, loss_ce: 0.011912
2022-01-20 21:21:01,888 iteration 2215 : loss : 0.028780, loss_ce: 0.011596
2022-01-20 21:21:02,486 iteration 2216 : loss : 0.035270, loss_ce: 0.016767
2022-01-20 21:21:03,062 iteration 2217 : loss : 0.030715, loss_ce: 0.015153
2022-01-20 21:21:03,666 iteration 2218 : loss : 0.033562, loss_ce: 0.012653
2022-01-20 21:21:04,324 iteration 2219 : loss : 0.039950, loss_ce: 0.020374
2022-01-20 21:21:05,035 iteration 2220 : loss : 0.041011, loss_ce: 0.021056
2022-01-20 21:21:05,749 iteration 2221 : loss : 0.045981, loss_ce: 0.015725
2022-01-20 21:21:06,307 iteration 2222 : loss : 0.035171, loss_ce: 0.013419
2022-01-20 21:21:06,893 iteration 2223 : loss : 0.044394, loss_ce: 0.015562
2022-01-20 21:21:07,595 iteration 2224 : loss : 0.041058, loss_ce: 0.016640
2022-01-20 21:21:08,254 iteration 2225 : loss : 0.032322, loss_ce: 0.011270
2022-01-20 21:21:08,959 iteration 2226 : loss : 0.042669, loss_ce: 0.017706
2022-01-20 21:21:09,645 iteration 2227 : loss : 0.058959, loss_ce: 0.018520
 33%|██████████▏                    | 131/400 [25:39<53:47, 12.00s/it]2022-01-20 21:21:10,397 iteration 2228 : loss : 0.039426, loss_ce: 0.019399
2022-01-20 21:21:11,053 iteration 2229 : loss : 0.043255, loss_ce: 0.017048
2022-01-20 21:21:11,845 iteration 2230 : loss : 0.040396, loss_ce: 0.015925
2022-01-20 21:21:12,481 iteration 2231 : loss : 0.040798, loss_ce: 0.021028
2022-01-20 21:21:13,110 iteration 2232 : loss : 0.033771, loss_ce: 0.016037
2022-01-20 21:21:13,940 iteration 2233 : loss : 0.077599, loss_ce: 0.028318
2022-01-20 21:21:14,609 iteration 2234 : loss : 0.051363, loss_ce: 0.016149
2022-01-20 21:21:15,261 iteration 2235 : loss : 0.045647, loss_ce: 0.019659
2022-01-20 21:21:15,891 iteration 2236 : loss : 0.027434, loss_ce: 0.011405
2022-01-20 21:21:16,557 iteration 2237 : loss : 0.038351, loss_ce: 0.017222
2022-01-20 21:21:17,152 iteration 2238 : loss : 0.034780, loss_ce: 0.010481
2022-01-20 21:21:17,771 iteration 2239 : loss : 0.026434, loss_ce: 0.008132
2022-01-20 21:21:18,330 iteration 2240 : loss : 0.061729, loss_ce: 0.018394
2022-01-20 21:21:18,965 iteration 2241 : loss : 0.031591, loss_ce: 0.012795
2022-01-20 21:21:19,674 iteration 2242 : loss : 0.047891, loss_ce: 0.016424
2022-01-20 21:21:20,351 iteration 2243 : loss : 0.052553, loss_ce: 0.024911
2022-01-20 21:21:20,969 iteration 2244 : loss : 0.024599, loss_ce: 0.008110
 33%|██████████▏                    | 132/400 [25:50<52:41, 11.80s/it]2022-01-20 21:21:21,635 iteration 2245 : loss : 0.037454, loss_ce: 0.012160
2022-01-20 21:21:22,179 iteration 2246 : loss : 0.035258, loss_ce: 0.010884
2022-01-20 21:21:22,823 iteration 2247 : loss : 0.040383, loss_ce: 0.020807
2022-01-20 21:21:23,523 iteration 2248 : loss : 0.047151, loss_ce: 0.023330
2022-01-20 21:21:24,158 iteration 2249 : loss : 0.028112, loss_ce: 0.013707
2022-01-20 21:21:24,800 iteration 2250 : loss : 0.027889, loss_ce: 0.009719
2022-01-20 21:21:25,479 iteration 2251 : loss : 0.033386, loss_ce: 0.014737
2022-01-20 21:21:26,127 iteration 2252 : loss : 0.062514, loss_ce: 0.022506
2022-01-20 21:21:26,873 iteration 2253 : loss : 0.051079, loss_ce: 0.020894
2022-01-20 21:21:27,568 iteration 2254 : loss : 0.033261, loss_ce: 0.013531
2022-01-20 21:21:28,207 iteration 2255 : loss : 0.025576, loss_ce: 0.010134
2022-01-20 21:21:28,829 iteration 2256 : loss : 0.027987, loss_ce: 0.011400
2022-01-20 21:21:29,418 iteration 2257 : loss : 0.038372, loss_ce: 0.012038
2022-01-20 21:21:30,001 iteration 2258 : loss : 0.039097, loss_ce: 0.015656
2022-01-20 21:21:30,694 iteration 2259 : loss : 0.036216, loss_ce: 0.014947
2022-01-20 21:21:31,340 iteration 2260 : loss : 0.034163, loss_ce: 0.013630
2022-01-20 21:21:31,993 iteration 2261 : loss : 0.042960, loss_ce: 0.018083
 33%|██████████▎                    | 133/400 [26:01<51:27, 11.57s/it]2022-01-20 21:21:32,615 iteration 2262 : loss : 0.029721, loss_ce: 0.016389
2022-01-20 21:21:33,318 iteration 2263 : loss : 0.051775, loss_ce: 0.018070
2022-01-20 21:21:34,057 iteration 2264 : loss : 0.035132, loss_ce: 0.012192
2022-01-20 21:21:34,721 iteration 2265 : loss : 0.028345, loss_ce: 0.012095
2022-01-20 21:21:35,329 iteration 2266 : loss : 0.028707, loss_ce: 0.012734
2022-01-20 21:21:35,944 iteration 2267 : loss : 0.026754, loss_ce: 0.009367
2022-01-20 21:21:36,578 iteration 2268 : loss : 0.036592, loss_ce: 0.012449
2022-01-20 21:21:37,174 iteration 2269 : loss : 0.033170, loss_ce: 0.017221
2022-01-20 21:21:37,802 iteration 2270 : loss : 0.032860, loss_ce: 0.010458
2022-01-20 21:21:38,404 iteration 2271 : loss : 0.030455, loss_ce: 0.012600
2022-01-20 21:21:39,023 iteration 2272 : loss : 0.042884, loss_ce: 0.021144
2022-01-20 21:21:39,686 iteration 2273 : loss : 0.033794, loss_ce: 0.010549
2022-01-20 21:21:40,351 iteration 2274 : loss : 0.031754, loss_ce: 0.010524
2022-01-20 21:21:41,064 iteration 2275 : loss : 0.040806, loss_ce: 0.014300
2022-01-20 21:21:41,649 iteration 2276 : loss : 0.028368, loss_ce: 0.011286
2022-01-20 21:21:42,301 iteration 2277 : loss : 0.038261, loss_ce: 0.014090
2022-01-20 21:21:42,893 iteration 2278 : loss : 0.026990, loss_ce: 0.009720
 34%|██████████▍                    | 134/400 [26:12<50:22, 11.36s/it]2022-01-20 21:21:43,509 iteration 2279 : loss : 0.041150, loss_ce: 0.016739
2022-01-20 21:21:44,153 iteration 2280 : loss : 0.036298, loss_ce: 0.016099
2022-01-20 21:21:44,793 iteration 2281 : loss : 0.036714, loss_ce: 0.008881
2022-01-20 21:21:45,466 iteration 2282 : loss : 0.026071, loss_ce: 0.009510
2022-01-20 21:21:46,184 iteration 2283 : loss : 0.029944, loss_ce: 0.012769
2022-01-20 21:21:46,803 iteration 2284 : loss : 0.030628, loss_ce: 0.013096
2022-01-20 21:21:47,427 iteration 2285 : loss : 0.026986, loss_ce: 0.009931
2022-01-20 21:21:48,052 iteration 2286 : loss : 0.024242, loss_ce: 0.008808
2022-01-20 21:21:48,679 iteration 2287 : loss : 0.030174, loss_ce: 0.012221
2022-01-20 21:21:49,351 iteration 2288 : loss : 0.029095, loss_ce: 0.010467
2022-01-20 21:21:49,944 iteration 2289 : loss : 0.025600, loss_ce: 0.006531
2022-01-20 21:21:50,635 iteration 2290 : loss : 0.033920, loss_ce: 0.019112
2022-01-20 21:21:51,263 iteration 2291 : loss : 0.027703, loss_ce: 0.010856
2022-01-20 21:21:51,876 iteration 2292 : loss : 0.039485, loss_ce: 0.019686
2022-01-20 21:21:52,429 iteration 2293 : loss : 0.028185, loss_ce: 0.015504
2022-01-20 21:21:53,090 iteration 2294 : loss : 0.045919, loss_ce: 0.018386
2022-01-20 21:21:53,090 Training Data Eval:
2022-01-20 21:21:55,996   Average segmentation loss on training set: 0.0201
2022-01-20 21:21:55,997 Validation Data Eval:
2022-01-20 21:21:56,948   Average segmentation loss on validation set: 0.0775
2022-01-20 21:21:57,670 iteration 2295 : loss : 0.037246, loss_ce: 0.015802
 34%|██████████▍                    | 135/400 [26:27<54:43, 12.39s/it]2022-01-20 21:21:58,270 iteration 2296 : loss : 0.021129, loss_ce: 0.008637
2022-01-20 21:21:58,890 iteration 2297 : loss : 0.023726, loss_ce: 0.009688
2022-01-20 21:21:59,517 iteration 2298 : loss : 0.023484, loss_ce: 0.009387
2022-01-20 21:22:00,231 iteration 2299 : loss : 0.040377, loss_ce: 0.020084
2022-01-20 21:22:00,839 iteration 2300 : loss : 0.027654, loss_ce: 0.011519
2022-01-20 21:22:01,551 iteration 2301 : loss : 0.028576, loss_ce: 0.009467
2022-01-20 21:22:02,228 iteration 2302 : loss : 0.049667, loss_ce: 0.019670
2022-01-20 21:22:02,887 iteration 2303 : loss : 0.029638, loss_ce: 0.012176
2022-01-20 21:22:03,610 iteration 2304 : loss : 0.031880, loss_ce: 0.010621
2022-01-20 21:22:04,288 iteration 2305 : loss : 0.033087, loss_ce: 0.012086
2022-01-20 21:22:05,033 iteration 2306 : loss : 0.039506, loss_ce: 0.017104
2022-01-20 21:22:05,659 iteration 2307 : loss : 0.041222, loss_ce: 0.013479
2022-01-20 21:22:06,255 iteration 2308 : loss : 0.028602, loss_ce: 0.009207
2022-01-20 21:22:06,871 iteration 2309 : loss : 0.027361, loss_ce: 0.012201
2022-01-20 21:22:07,583 iteration 2310 : loss : 0.028291, loss_ce: 0.009168
2022-01-20 21:22:08,148 iteration 2311 : loss : 0.035406, loss_ce: 0.011004
2022-01-20 21:22:08,793 iteration 2312 : loss : 0.034126, loss_ce: 0.013469
 34%|██████████▌                    | 136/400 [26:38<52:49, 12.01s/it]2022-01-20 21:22:09,508 iteration 2313 : loss : 0.029958, loss_ce: 0.011363
2022-01-20 21:22:10,043 iteration 2314 : loss : 0.025183, loss_ce: 0.008156
2022-01-20 21:22:10,627 iteration 2315 : loss : 0.025538, loss_ce: 0.009239
2022-01-20 21:22:11,340 iteration 2316 : loss : 0.032895, loss_ce: 0.012954
2022-01-20 21:22:11,908 iteration 2317 : loss : 0.029688, loss_ce: 0.009206
2022-01-20 21:22:12,514 iteration 2318 : loss : 0.028248, loss_ce: 0.014074
2022-01-20 21:22:13,144 iteration 2319 : loss : 0.032175, loss_ce: 0.014642
2022-01-20 21:22:13,850 iteration 2320 : loss : 0.035461, loss_ce: 0.016333
2022-01-20 21:22:14,478 iteration 2321 : loss : 0.033264, loss_ce: 0.013201
2022-01-20 21:22:15,121 iteration 2322 : loss : 0.032045, loss_ce: 0.013492
2022-01-20 21:22:15,667 iteration 2323 : loss : 0.026444, loss_ce: 0.009964
2022-01-20 21:22:16,280 iteration 2324 : loss : 0.027364, loss_ce: 0.011887
2022-01-20 21:22:16,793 iteration 2325 : loss : 0.024617, loss_ce: 0.010304
2022-01-20 21:22:17,402 iteration 2326 : loss : 0.030299, loss_ce: 0.007156
2022-01-20 21:22:17,991 iteration 2327 : loss : 0.029687, loss_ce: 0.011433
2022-01-20 21:22:18,620 iteration 2328 : loss : 0.040672, loss_ce: 0.018412
2022-01-20 21:22:19,199 iteration 2329 : loss : 0.025659, loss_ce: 0.010351
 34%|██████████▌                    | 137/400 [26:48<50:32, 11.53s/it]2022-01-20 21:22:19,884 iteration 2330 : loss : 0.038095, loss_ce: 0.015171
2022-01-20 21:22:20,468 iteration 2331 : loss : 0.021233, loss_ce: 0.008214
2022-01-20 21:22:21,178 iteration 2332 : loss : 0.026163, loss_ce: 0.009912
2022-01-20 21:22:21,812 iteration 2333 : loss : 0.029295, loss_ce: 0.013114
2022-01-20 21:22:22,581 iteration 2334 : loss : 0.022409, loss_ce: 0.008682
2022-01-20 21:22:23,331 iteration 2335 : loss : 0.044904, loss_ce: 0.020329
2022-01-20 21:22:24,037 iteration 2336 : loss : 0.031686, loss_ce: 0.013936
2022-01-20 21:22:24,677 iteration 2337 : loss : 0.032009, loss_ce: 0.010126
2022-01-20 21:22:25,348 iteration 2338 : loss : 0.038427, loss_ce: 0.015402
2022-01-20 21:22:26,014 iteration 2339 : loss : 0.039966, loss_ce: 0.013086
2022-01-20 21:22:26,596 iteration 2340 : loss : 0.026109, loss_ce: 0.010031
2022-01-20 21:22:27,260 iteration 2341 : loss : 0.025366, loss_ce: 0.009453
2022-01-20 21:22:27,931 iteration 2342 : loss : 0.026361, loss_ce: 0.011182
2022-01-20 21:22:28,710 iteration 2343 : loss : 0.030899, loss_ce: 0.010624
2022-01-20 21:22:29,311 iteration 2344 : loss : 0.046642, loss_ce: 0.016045
2022-01-20 21:22:29,925 iteration 2345 : loss : 0.038208, loss_ce: 0.017875
2022-01-20 21:22:30,547 iteration 2346 : loss : 0.041732, loss_ce: 0.015802
 34%|██████████▋                    | 138/400 [26:59<50:06, 11.48s/it]2022-01-20 21:22:31,313 iteration 2347 : loss : 0.035590, loss_ce: 0.015341
2022-01-20 21:22:31,967 iteration 2348 : loss : 0.025049, loss_ce: 0.009155
2022-01-20 21:22:32,576 iteration 2349 : loss : 0.032193, loss_ce: 0.010957
2022-01-20 21:22:33,198 iteration 2350 : loss : 0.046200, loss_ce: 0.015507
2022-01-20 21:22:33,915 iteration 2351 : loss : 0.034467, loss_ce: 0.015517
2022-01-20 21:22:34,511 iteration 2352 : loss : 0.025756, loss_ce: 0.013234
2022-01-20 21:22:35,116 iteration 2353 : loss : 0.029979, loss_ce: 0.012924
2022-01-20 21:22:35,705 iteration 2354 : loss : 0.020907, loss_ce: 0.010665
2022-01-20 21:22:36,311 iteration 2355 : loss : 0.032305, loss_ce: 0.009999
2022-01-20 21:22:37,002 iteration 2356 : loss : 0.034888, loss_ce: 0.013169
2022-01-20 21:22:37,648 iteration 2357 : loss : 0.032138, loss_ce: 0.011017
2022-01-20 21:22:38,296 iteration 2358 : loss : 0.029607, loss_ce: 0.012044
2022-01-20 21:22:38,904 iteration 2359 : loss : 0.035162, loss_ce: 0.012886
2022-01-20 21:22:39,489 iteration 2360 : loss : 0.031769, loss_ce: 0.009331
2022-01-20 21:22:40,116 iteration 2361 : loss : 0.032358, loss_ce: 0.010966
2022-01-20 21:22:40,869 iteration 2362 : loss : 0.047615, loss_ce: 0.019825
2022-01-20 21:22:41,520 iteration 2363 : loss : 0.028150, loss_ce: 0.011170
 35%|██████████▊                    | 139/400 [27:10<49:15, 11.32s/it]2022-01-20 21:22:42,287 iteration 2364 : loss : 0.040560, loss_ce: 0.012315
2022-01-20 21:22:43,025 iteration 2365 : loss : 0.041926, loss_ce: 0.015048
2022-01-20 21:22:43,710 iteration 2366 : loss : 0.032238, loss_ce: 0.012300
2022-01-20 21:22:44,297 iteration 2367 : loss : 0.024619, loss_ce: 0.006101
2022-01-20 21:22:44,883 iteration 2368 : loss : 0.027109, loss_ce: 0.010454
2022-01-20 21:22:45,526 iteration 2369 : loss : 0.034565, loss_ce: 0.010646
2022-01-20 21:22:46,152 iteration 2370 : loss : 0.035802, loss_ce: 0.013346
2022-01-20 21:22:46,827 iteration 2371 : loss : 0.024938, loss_ce: 0.010579
2022-01-20 21:22:47,427 iteration 2372 : loss : 0.032305, loss_ce: 0.010566
2022-01-20 21:22:48,043 iteration 2373 : loss : 0.036167, loss_ce: 0.013022
2022-01-20 21:22:48,623 iteration 2374 : loss : 0.024521, loss_ce: 0.009763
2022-01-20 21:22:49,223 iteration 2375 : loss : 0.023301, loss_ce: 0.008555
2022-01-20 21:22:49,877 iteration 2376 : loss : 0.032267, loss_ce: 0.015471
2022-01-20 21:22:50,533 iteration 2377 : loss : 0.027323, loss_ce: 0.012467
2022-01-20 21:22:51,183 iteration 2378 : loss : 0.024174, loss_ce: 0.009176
2022-01-20 21:22:51,860 iteration 2379 : loss : 0.036713, loss_ce: 0.015731
2022-01-20 21:22:51,861 Training Data Eval:
2022-01-20 21:22:54,763   Average segmentation loss on training set: 0.0210
2022-01-20 21:22:54,763 Validation Data Eval:
2022-01-20 21:22:55,714   Average segmentation loss on validation set: 0.0743
2022-01-20 21:22:56,309 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:22:56,904 iteration 2380 : loss : 0.023158, loss_ce: 0.010897
 35%|██████████▊                    | 140/400 [27:26<54:20, 12.54s/it]2022-01-20 21:22:57,527 iteration 2381 : loss : 0.029041, loss_ce: 0.009897
2022-01-20 21:22:58,194 iteration 2382 : loss : 0.029028, loss_ce: 0.008975
2022-01-20 21:22:58,786 iteration 2383 : loss : 0.021409, loss_ce: 0.007094
2022-01-20 21:22:59,468 iteration 2384 : loss : 0.033973, loss_ce: 0.012960
2022-01-20 21:23:00,166 iteration 2385 : loss : 0.043084, loss_ce: 0.018044
2022-01-20 21:23:00,790 iteration 2386 : loss : 0.029062, loss_ce: 0.009645
2022-01-20 21:23:01,391 iteration 2387 : loss : 0.039255, loss_ce: 0.012090
2022-01-20 21:23:02,028 iteration 2388 : loss : 0.030030, loss_ce: 0.012725
2022-01-20 21:23:02,596 iteration 2389 : loss : 0.017852, loss_ce: 0.006308
2022-01-20 21:23:03,239 iteration 2390 : loss : 0.027381, loss_ce: 0.013092
2022-01-20 21:23:03,858 iteration 2391 : loss : 0.031146, loss_ce: 0.017343
2022-01-20 21:23:04,526 iteration 2392 : loss : 0.033911, loss_ce: 0.012351
2022-01-20 21:23:05,196 iteration 2393 : loss : 0.062241, loss_ce: 0.020273
2022-01-20 21:23:05,742 iteration 2394 : loss : 0.026097, loss_ce: 0.008854
2022-01-20 21:23:06,440 iteration 2395 : loss : 0.029866, loss_ce: 0.011897
2022-01-20 21:23:07,034 iteration 2396 : loss : 0.024141, loss_ce: 0.010872
2022-01-20 21:23:07,705 iteration 2397 : loss : 0.029288, loss_ce: 0.011296
 35%|██████████▉                    | 141/400 [27:37<51:53, 12.02s/it]2022-01-20 21:23:08,376 iteration 2398 : loss : 0.041331, loss_ce: 0.013695
2022-01-20 21:23:08,982 iteration 2399 : loss : 0.023884, loss_ce: 0.007468
2022-01-20 21:23:09,678 iteration 2400 : loss : 0.031758, loss_ce: 0.013382
2022-01-20 21:23:10,316 iteration 2401 : loss : 0.028501, loss_ce: 0.008996
2022-01-20 21:23:11,000 iteration 2402 : loss : 0.034135, loss_ce: 0.018439
2022-01-20 21:23:11,602 iteration 2403 : loss : 0.032260, loss_ce: 0.015038
2022-01-20 21:23:12,179 iteration 2404 : loss : 0.025771, loss_ce: 0.012116
2022-01-20 21:23:12,730 iteration 2405 : loss : 0.030225, loss_ce: 0.010399
2022-01-20 21:23:13,488 iteration 2406 : loss : 0.041487, loss_ce: 0.012928
2022-01-20 21:23:14,057 iteration 2407 : loss : 0.027799, loss_ce: 0.014058
2022-01-20 21:23:14,628 iteration 2408 : loss : 0.022778, loss_ce: 0.009536
2022-01-20 21:23:15,310 iteration 2409 : loss : 0.038354, loss_ce: 0.015445
2022-01-20 21:23:16,006 iteration 2410 : loss : 0.031662, loss_ce: 0.012439
2022-01-20 21:23:16,680 iteration 2411 : loss : 0.052204, loss_ce: 0.016719
2022-01-20 21:23:17,277 iteration 2412 : loss : 0.020138, loss_ce: 0.008315
2022-01-20 21:23:17,985 iteration 2413 : loss : 0.035318, loss_ce: 0.014917
2022-01-20 21:23:18,629 iteration 2414 : loss : 0.026686, loss_ce: 0.009910
 36%|███████████                    | 142/400 [27:48<50:15, 11.69s/it]2022-01-20 21:23:19,320 iteration 2415 : loss : 0.030602, loss_ce: 0.010455
2022-01-20 21:23:19,937 iteration 2416 : loss : 0.023722, loss_ce: 0.009171
2022-01-20 21:23:20,568 iteration 2417 : loss : 0.027676, loss_ce: 0.009629
2022-01-20 21:23:21,292 iteration 2418 : loss : 0.035076, loss_ce: 0.013887
2022-01-20 21:23:21,951 iteration 2419 : loss : 0.034281, loss_ce: 0.017580
2022-01-20 21:23:22,709 iteration 2420 : loss : 0.046280, loss_ce: 0.020672
2022-01-20 21:23:23,434 iteration 2421 : loss : 0.041910, loss_ce: 0.014284
2022-01-20 21:23:24,129 iteration 2422 : loss : 0.037064, loss_ce: 0.013826
2022-01-20 21:23:24,765 iteration 2423 : loss : 0.034819, loss_ce: 0.011797
2022-01-20 21:23:25,384 iteration 2424 : loss : 0.025636, loss_ce: 0.011256
2022-01-20 21:23:26,141 iteration 2425 : loss : 0.039340, loss_ce: 0.013635
2022-01-20 21:23:26,768 iteration 2426 : loss : 0.030919, loss_ce: 0.010830
2022-01-20 21:23:27,315 iteration 2427 : loss : 0.024152, loss_ce: 0.010898
2022-01-20 21:23:27,910 iteration 2428 : loss : 0.037166, loss_ce: 0.010437
2022-01-20 21:23:28,517 iteration 2429 : loss : 0.034599, loss_ce: 0.012561
2022-01-20 21:23:29,119 iteration 2430 : loss : 0.020262, loss_ce: 0.007890
2022-01-20 21:23:29,756 iteration 2431 : loss : 0.031511, loss_ce: 0.015546
 36%|███████████                    | 143/400 [27:59<49:20, 11.52s/it]2022-01-20 21:23:30,387 iteration 2432 : loss : 0.025297, loss_ce: 0.007567
2022-01-20 21:23:31,007 iteration 2433 : loss : 0.031928, loss_ce: 0.012289
2022-01-20 21:23:31,646 iteration 2434 : loss : 0.027362, loss_ce: 0.009338
2022-01-20 21:23:32,367 iteration 2435 : loss : 0.032607, loss_ce: 0.016730
2022-01-20 21:23:32,918 iteration 2436 : loss : 0.023860, loss_ce: 0.009314
2022-01-20 21:23:33,598 iteration 2437 : loss : 0.026480, loss_ce: 0.009529
2022-01-20 21:23:34,296 iteration 2438 : loss : 0.034269, loss_ce: 0.010761
2022-01-20 21:23:34,981 iteration 2439 : loss : 0.054212, loss_ce: 0.017544
2022-01-20 21:23:35,678 iteration 2440 : loss : 0.034322, loss_ce: 0.013600
2022-01-20 21:23:36,305 iteration 2441 : loss : 0.027932, loss_ce: 0.009318
2022-01-20 21:23:36,921 iteration 2442 : loss : 0.027230, loss_ce: 0.010196
2022-01-20 21:23:37,488 iteration 2443 : loss : 0.026514, loss_ce: 0.010299
2022-01-20 21:23:38,120 iteration 2444 : loss : 0.027080, loss_ce: 0.009941
2022-01-20 21:23:38,770 iteration 2445 : loss : 0.030736, loss_ce: 0.011617
2022-01-20 21:23:39,495 iteration 2446 : loss : 0.028031, loss_ce: 0.011666
2022-01-20 21:23:40,071 iteration 2447 : loss : 0.023194, loss_ce: 0.007693
2022-01-20 21:23:40,751 iteration 2448 : loss : 0.026213, loss_ce: 0.009650
 36%|███████████▏                   | 144/400 [28:10<48:28, 11.36s/it]2022-01-20 21:23:41,358 iteration 2449 : loss : 0.035790, loss_ce: 0.012940
2022-01-20 21:23:41,926 iteration 2450 : loss : 0.022831, loss_ce: 0.011525
2022-01-20 21:23:42,534 iteration 2451 : loss : 0.030054, loss_ce: 0.010090
2022-01-20 21:23:43,120 iteration 2452 : loss : 0.027000, loss_ce: 0.009822
2022-01-20 21:23:43,759 iteration 2453 : loss : 0.037124, loss_ce: 0.012598
2022-01-20 21:23:44,366 iteration 2454 : loss : 0.028676, loss_ce: 0.010049
2022-01-20 21:23:44,948 iteration 2455 : loss : 0.030800, loss_ce: 0.015437
2022-01-20 21:23:45,514 iteration 2456 : loss : 0.023046, loss_ce: 0.008652
2022-01-20 21:23:46,121 iteration 2457 : loss : 0.032911, loss_ce: 0.011483
2022-01-20 21:23:46,699 iteration 2458 : loss : 0.026725, loss_ce: 0.010053
2022-01-20 21:23:47,234 iteration 2459 : loss : 0.022657, loss_ce: 0.008825
2022-01-20 21:23:47,831 iteration 2460 : loss : 0.027440, loss_ce: 0.007120
2022-01-20 21:23:48,527 iteration 2461 : loss : 0.036213, loss_ce: 0.012461
2022-01-20 21:23:49,179 iteration 2462 : loss : 0.039841, loss_ce: 0.014637
2022-01-20 21:23:49,785 iteration 2463 : loss : 0.028480, loss_ce: 0.013049
2022-01-20 21:23:50,439 iteration 2464 : loss : 0.022757, loss_ce: 0.009203
2022-01-20 21:23:50,440 Training Data Eval:
2022-01-20 21:23:53,342   Average segmentation loss on training set: 0.0189
2022-01-20 21:23:53,342 Validation Data Eval:
2022-01-20 21:23:54,295   Average segmentation loss on validation set: 0.0871
2022-01-20 21:23:54,905 iteration 2465 : loss : 0.028528, loss_ce: 0.011266
 36%|███████████▏                   | 145/400 [28:24<51:51, 12.20s/it]2022-01-20 21:23:55,640 iteration 2466 : loss : 0.062031, loss_ce: 0.024288
2022-01-20 21:23:56,346 iteration 2467 : loss : 0.027859, loss_ce: 0.011831
2022-01-20 21:23:56,958 iteration 2468 : loss : 0.031617, loss_ce: 0.011028
2022-01-20 21:23:57,538 iteration 2469 : loss : 0.020736, loss_ce: 0.008712
2022-01-20 21:23:58,159 iteration 2470 : loss : 0.026204, loss_ce: 0.009010
2022-01-20 21:23:58,878 iteration 2471 : loss : 0.033022, loss_ce: 0.011702
2022-01-20 21:23:59,474 iteration 2472 : loss : 0.043286, loss_ce: 0.017650
2022-01-20 21:24:00,168 iteration 2473 : loss : 0.029737, loss_ce: 0.011277
2022-01-20 21:24:00,771 iteration 2474 : loss : 0.025383, loss_ce: 0.009040
2022-01-20 21:24:01,410 iteration 2475 : loss : 0.022712, loss_ce: 0.008391
2022-01-20 21:24:01,998 iteration 2476 : loss : 0.023552, loss_ce: 0.011990
2022-01-20 21:24:02,725 iteration 2477 : loss : 0.040936, loss_ce: 0.017372
2022-01-20 21:24:03,396 iteration 2478 : loss : 0.029471, loss_ce: 0.010442
2022-01-20 21:24:03,952 iteration 2479 : loss : 0.022920, loss_ce: 0.008395
2022-01-20 21:24:04,593 iteration 2480 : loss : 0.043363, loss_ce: 0.016359
2022-01-20 21:24:05,288 iteration 2481 : loss : 0.028466, loss_ce: 0.010718
2022-01-20 21:24:05,897 iteration 2482 : loss : 0.021997, loss_ce: 0.009776
 36%|███████████▎                   | 146/400 [28:35<50:06, 11.84s/it]2022-01-20 21:24:06,657 iteration 2483 : loss : 0.041800, loss_ce: 0.019012
2022-01-20 21:24:07,317 iteration 2484 : loss : 0.038088, loss_ce: 0.009418
2022-01-20 21:24:07,912 iteration 2485 : loss : 0.024229, loss_ce: 0.010593
2022-01-20 21:24:08,535 iteration 2486 : loss : 0.026592, loss_ce: 0.010705
2022-01-20 21:24:09,147 iteration 2487 : loss : 0.025785, loss_ce: 0.008533
2022-01-20 21:24:09,835 iteration 2488 : loss : 0.046026, loss_ce: 0.016321
2022-01-20 21:24:10,454 iteration 2489 : loss : 0.027639, loss_ce: 0.011082
2022-01-20 21:24:11,141 iteration 2490 : loss : 0.050224, loss_ce: 0.021625
2022-01-20 21:24:11,866 iteration 2491 : loss : 0.026636, loss_ce: 0.011367
2022-01-20 21:24:12,411 iteration 2492 : loss : 0.025331, loss_ce: 0.009388
2022-01-20 21:24:13,067 iteration 2493 : loss : 0.044940, loss_ce: 0.017940
2022-01-20 21:24:13,688 iteration 2494 : loss : 0.049941, loss_ce: 0.015255
2022-01-20 21:24:14,302 iteration 2495 : loss : 0.029145, loss_ce: 0.013400
2022-01-20 21:24:15,120 iteration 2496 : loss : 0.064769, loss_ce: 0.019156
2022-01-20 21:24:15,798 iteration 2497 : loss : 0.036178, loss_ce: 0.013401
2022-01-20 21:24:16,486 iteration 2498 : loss : 0.030957, loss_ce: 0.012233
2022-01-20 21:24:17,058 iteration 2499 : loss : 0.023725, loss_ce: 0.006536
 37%|███████████▍                   | 147/400 [28:46<49:03, 11.64s/it]2022-01-20 21:24:17,719 iteration 2500 : loss : 0.031246, loss_ce: 0.010774
2022-01-20 21:24:18,348 iteration 2501 : loss : 0.029261, loss_ce: 0.008711
2022-01-20 21:24:19,061 iteration 2502 : loss : 0.051468, loss_ce: 0.019012
2022-01-20 21:24:19,643 iteration 2503 : loss : 0.026725, loss_ce: 0.010100
2022-01-20 21:24:20,244 iteration 2504 : loss : 0.031387, loss_ce: 0.013711
2022-01-20 21:24:20,922 iteration 2505 : loss : 0.049098, loss_ce: 0.021428
2022-01-20 21:24:21,556 iteration 2506 : loss : 0.046840, loss_ce: 0.014613
2022-01-20 21:24:22,143 iteration 2507 : loss : 0.029397, loss_ce: 0.013274
2022-01-20 21:24:22,751 iteration 2508 : loss : 0.031409, loss_ce: 0.010856
2022-01-20 21:24:23,368 iteration 2509 : loss : 0.037050, loss_ce: 0.012075
2022-01-20 21:24:23,965 iteration 2510 : loss : 0.030560, loss_ce: 0.012302
2022-01-20 21:24:24,609 iteration 2511 : loss : 0.024887, loss_ce: 0.010114
2022-01-20 21:24:25,261 iteration 2512 : loss : 0.033628, loss_ce: 0.012356
2022-01-20 21:24:25,954 iteration 2513 : loss : 0.031214, loss_ce: 0.010036
2022-01-20 21:24:26,597 iteration 2514 : loss : 0.033845, loss_ce: 0.009630
2022-01-20 21:24:27,219 iteration 2515 : loss : 0.022204, loss_ce: 0.010854
2022-01-20 21:24:27,827 iteration 2516 : loss : 0.025226, loss_ce: 0.011152
 37%|███████████▍                   | 148/400 [28:57<47:46, 11.38s/it]2022-01-20 21:24:28,473 iteration 2517 : loss : 0.031293, loss_ce: 0.011910
2022-01-20 21:24:29,106 iteration 2518 : loss : 0.039453, loss_ce: 0.012359
2022-01-20 21:24:29,760 iteration 2519 : loss : 0.031251, loss_ce: 0.011031
2022-01-20 21:24:30,386 iteration 2520 : loss : 0.042525, loss_ce: 0.017079
2022-01-20 21:24:30,999 iteration 2521 : loss : 0.028206, loss_ce: 0.010826
2022-01-20 21:24:31,637 iteration 2522 : loss : 0.029878, loss_ce: 0.013391
2022-01-20 21:24:32,327 iteration 2523 : loss : 0.033058, loss_ce: 0.012191
2022-01-20 21:24:32,944 iteration 2524 : loss : 0.025240, loss_ce: 0.010539
2022-01-20 21:24:33,592 iteration 2525 : loss : 0.033293, loss_ce: 0.012857
2022-01-20 21:24:34,257 iteration 2526 : loss : 0.028511, loss_ce: 0.011785
2022-01-20 21:24:34,898 iteration 2527 : loss : 0.031250, loss_ce: 0.011786
2022-01-20 21:24:35,554 iteration 2528 : loss : 0.026787, loss_ce: 0.009161
2022-01-20 21:24:36,197 iteration 2529 : loss : 0.036540, loss_ce: 0.013032
2022-01-20 21:24:36,841 iteration 2530 : loss : 0.028411, loss_ce: 0.013570
2022-01-20 21:24:37,554 iteration 2531 : loss : 0.027743, loss_ce: 0.011337
2022-01-20 21:24:38,191 iteration 2532 : loss : 0.042100, loss_ce: 0.013897
2022-01-20 21:24:38,846 iteration 2533 : loss : 0.035749, loss_ce: 0.009870
 37%|███████████▌                   | 149/400 [29:08<47:07, 11.27s/it]2022-01-20 21:24:39,452 iteration 2534 : loss : 0.028982, loss_ce: 0.011770
2022-01-20 21:24:40,168 iteration 2535 : loss : 0.048443, loss_ce: 0.017724
2022-01-20 21:24:40,768 iteration 2536 : loss : 0.024683, loss_ce: 0.012091
2022-01-20 21:24:41,379 iteration 2537 : loss : 0.027838, loss_ce: 0.011047
2022-01-20 21:24:41,912 iteration 2538 : loss : 0.022925, loss_ce: 0.009358
2022-01-20 21:24:42,573 iteration 2539 : loss : 0.030031, loss_ce: 0.011809
2022-01-20 21:24:43,160 iteration 2540 : loss : 0.021906, loss_ce: 0.006824
2022-01-20 21:24:43,768 iteration 2541 : loss : 0.030533, loss_ce: 0.013217
2022-01-20 21:24:44,335 iteration 2542 : loss : 0.017092, loss_ce: 0.006239
2022-01-20 21:24:44,907 iteration 2543 : loss : 0.029306, loss_ce: 0.009838
2022-01-20 21:24:45,535 iteration 2544 : loss : 0.043156, loss_ce: 0.012770
2022-01-20 21:24:46,279 iteration 2545 : loss : 0.030277, loss_ce: 0.011431
2022-01-20 21:24:47,042 iteration 2546 : loss : 0.033765, loss_ce: 0.013947
2022-01-20 21:24:47,621 iteration 2547 : loss : 0.021559, loss_ce: 0.010210
2022-01-20 21:24:48,286 iteration 2548 : loss : 0.026337, loss_ce: 0.011434
2022-01-20 21:24:48,933 iteration 2549 : loss : 0.036748, loss_ce: 0.010949
2022-01-20 21:24:48,933 Training Data Eval:
2022-01-20 21:24:51,829   Average segmentation loss on training set: 0.0191
2022-01-20 21:24:51,830 Validation Data Eval:
2022-01-20 21:24:52,777   Average segmentation loss on validation set: 0.0756
2022-01-20 21:24:53,375 iteration 2550 : loss : 0.022190, loss_ce: 0.007070
 38%|███████████▋                   | 150/400 [29:22<51:02, 12.25s/it]2022-01-20 21:24:54,035 iteration 2551 : loss : 0.021959, loss_ce: 0.010320
2022-01-20 21:24:54,734 iteration 2552 : loss : 0.025748, loss_ce: 0.010662
2022-01-20 21:24:55,299 iteration 2553 : loss : 0.021123, loss_ce: 0.007354
2022-01-20 21:24:55,934 iteration 2554 : loss : 0.039577, loss_ce: 0.013955
2022-01-20 21:24:56,556 iteration 2555 : loss : 0.023788, loss_ce: 0.006762
2022-01-20 21:24:57,238 iteration 2556 : loss : 0.024250, loss_ce: 0.009659
2022-01-20 21:24:57,854 iteration 2557 : loss : 0.025581, loss_ce: 0.011429
2022-01-20 21:24:58,493 iteration 2558 : loss : 0.033128, loss_ce: 0.019910
2022-01-20 21:24:59,208 iteration 2559 : loss : 0.028204, loss_ce: 0.010585
2022-01-20 21:24:59,836 iteration 2560 : loss : 0.025165, loss_ce: 0.012908
2022-01-20 21:25:00,553 iteration 2561 : loss : 0.032246, loss_ce: 0.011255
2022-01-20 21:25:01,206 iteration 2562 : loss : 0.030303, loss_ce: 0.011674
2022-01-20 21:25:01,885 iteration 2563 : loss : 0.034035, loss_ce: 0.014361
2022-01-20 21:25:02,477 iteration 2564 : loss : 0.024861, loss_ce: 0.009732
2022-01-20 21:25:03,075 iteration 2565 : loss : 0.027836, loss_ce: 0.009352
2022-01-20 21:25:03,691 iteration 2566 : loss : 0.026975, loss_ce: 0.009533
2022-01-20 21:25:04,340 iteration 2567 : loss : 0.034637, loss_ce: 0.008734
 38%|███████████▋                   | 151/400 [29:33<49:13, 11.86s/it]2022-01-20 21:25:05,046 iteration 2568 : loss : 0.030002, loss_ce: 0.012835
2022-01-20 21:25:05,661 iteration 2569 : loss : 0.025343, loss_ce: 0.011465
2022-01-20 21:25:06,281 iteration 2570 : loss : 0.043213, loss_ce: 0.016553
2022-01-20 21:25:06,906 iteration 2571 : loss : 0.017806, loss_ce: 0.007316
2022-01-20 21:25:07,479 iteration 2572 : loss : 0.026740, loss_ce: 0.007990
2022-01-20 21:25:08,061 iteration 2573 : loss : 0.028069, loss_ce: 0.011052
2022-01-20 21:25:08,672 iteration 2574 : loss : 0.032123, loss_ce: 0.010399
2022-01-20 21:25:09,423 iteration 2575 : loss : 0.041806, loss_ce: 0.015366
2022-01-20 21:25:10,081 iteration 2576 : loss : 0.022501, loss_ce: 0.008081
2022-01-20 21:25:10,727 iteration 2577 : loss : 0.037603, loss_ce: 0.014843
2022-01-20 21:25:11,380 iteration 2578 : loss : 0.032255, loss_ce: 0.009998
2022-01-20 21:25:11,958 iteration 2579 : loss : 0.031322, loss_ce: 0.008552
2022-01-20 21:25:12,658 iteration 2580 : loss : 0.028582, loss_ce: 0.007862
2022-01-20 21:25:13,338 iteration 2581 : loss : 0.035117, loss_ce: 0.014813
2022-01-20 21:25:14,054 iteration 2582 : loss : 0.026499, loss_ce: 0.009078
2022-01-20 21:25:14,678 iteration 2583 : loss : 0.022090, loss_ce: 0.007685
2022-01-20 21:25:15,218 iteration 2584 : loss : 0.024521, loss_ce: 0.009632
 38%|███████████▊                   | 152/400 [29:44<47:49, 11.57s/it]2022-01-20 21:25:15,888 iteration 2585 : loss : 0.024023, loss_ce: 0.007553
2022-01-20 21:25:16,526 iteration 2586 : loss : 0.041444, loss_ce: 0.016315
2022-01-20 21:25:17,095 iteration 2587 : loss : 0.028175, loss_ce: 0.011072
2022-01-20 21:25:17,700 iteration 2588 : loss : 0.034683, loss_ce: 0.017532
2022-01-20 21:25:18,371 iteration 2589 : loss : 0.053578, loss_ce: 0.021347
2022-01-20 21:25:19,047 iteration 2590 : loss : 0.028582, loss_ce: 0.011871
2022-01-20 21:25:19,641 iteration 2591 : loss : 0.023577, loss_ce: 0.008038
2022-01-20 21:25:20,238 iteration 2592 : loss : 0.029842, loss_ce: 0.010168
2022-01-20 21:25:20,843 iteration 2593 : loss : 0.025820, loss_ce: 0.011428
2022-01-20 21:25:21,594 iteration 2594 : loss : 0.040898, loss_ce: 0.016441
2022-01-20 21:25:22,264 iteration 2595 : loss : 0.033960, loss_ce: 0.013078
2022-01-20 21:25:22,865 iteration 2596 : loss : 0.024429, loss_ce: 0.011094
2022-01-20 21:25:23,447 iteration 2597 : loss : 0.033982, loss_ce: 0.013825
2022-01-20 21:25:24,057 iteration 2598 : loss : 0.023322, loss_ce: 0.009755
2022-01-20 21:25:24,679 iteration 2599 : loss : 0.038581, loss_ce: 0.008024
2022-01-20 21:25:25,304 iteration 2600 : loss : 0.024779, loss_ce: 0.008496
2022-01-20 21:25:25,880 iteration 2601 : loss : 0.026638, loss_ce: 0.011098
 38%|███████████▊                   | 153/400 [29:55<46:30, 11.30s/it]2022-01-20 21:25:26,581 iteration 2602 : loss : 0.030146, loss_ce: 0.012598
2022-01-20 21:25:27,139 iteration 2603 : loss : 0.022446, loss_ce: 0.008815
2022-01-20 21:25:27,748 iteration 2604 : loss : 0.024841, loss_ce: 0.009346
2022-01-20 21:25:28,499 iteration 2605 : loss : 0.038569, loss_ce: 0.012488
2022-01-20 21:25:29,125 iteration 2606 : loss : 0.025320, loss_ce: 0.010661
2022-01-20 21:25:29,761 iteration 2607 : loss : 0.030730, loss_ce: 0.009368
2022-01-20 21:25:30,333 iteration 2608 : loss : 0.027207, loss_ce: 0.013323
2022-01-20 21:25:30,919 iteration 2609 : loss : 0.025231, loss_ce: 0.008250
2022-01-20 21:25:31,670 iteration 2610 : loss : 0.033845, loss_ce: 0.015333
2022-01-20 21:25:32,272 iteration 2611 : loss : 0.062992, loss_ce: 0.027622
2022-01-20 21:25:32,804 iteration 2612 : loss : 0.023548, loss_ce: 0.011695
2022-01-20 21:25:33,402 iteration 2613 : loss : 0.033097, loss_ce: 0.011806
2022-01-20 21:25:34,081 iteration 2614 : loss : 0.039498, loss_ce: 0.012923
2022-01-20 21:25:34,677 iteration 2615 : loss : 0.037373, loss_ce: 0.014466
2022-01-20 21:25:35,275 iteration 2616 : loss : 0.029966, loss_ce: 0.010842
2022-01-20 21:25:35,983 iteration 2617 : loss : 0.032021, loss_ce: 0.009044
2022-01-20 21:25:36,641 iteration 2618 : loss : 0.045771, loss_ce: 0.021163
 38%|███████████▉                   | 154/400 [30:06<45:39, 11.13s/it]2022-01-20 21:25:37,380 iteration 2619 : loss : 0.044690, loss_ce: 0.010712
2022-01-20 21:25:37,988 iteration 2620 : loss : 0.026363, loss_ce: 0.010106
2022-01-20 21:25:38,649 iteration 2621 : loss : 0.026252, loss_ce: 0.009511
2022-01-20 21:25:39,306 iteration 2622 : loss : 0.027571, loss_ce: 0.012734
2022-01-20 21:25:39,974 iteration 2623 : loss : 0.048495, loss_ce: 0.019356
2022-01-20 21:25:40,560 iteration 2624 : loss : 0.036947, loss_ce: 0.011223
2022-01-20 21:25:41,169 iteration 2625 : loss : 0.030624, loss_ce: 0.011562
2022-01-20 21:25:41,864 iteration 2626 : loss : 0.041978, loss_ce: 0.015976
2022-01-20 21:25:42,521 iteration 2627 : loss : 0.055450, loss_ce: 0.012587
2022-01-20 21:25:43,110 iteration 2628 : loss : 0.034809, loss_ce: 0.012713
2022-01-20 21:25:43,802 iteration 2629 : loss : 0.036547, loss_ce: 0.012326
2022-01-20 21:25:44,376 iteration 2630 : loss : 0.020357, loss_ce: 0.006405
2022-01-20 21:25:45,023 iteration 2631 : loss : 0.027532, loss_ce: 0.012335
2022-01-20 21:25:45,683 iteration 2632 : loss : 0.032849, loss_ce: 0.012402
2022-01-20 21:25:46,278 iteration 2633 : loss : 0.033713, loss_ce: 0.017688
2022-01-20 21:25:46,920 iteration 2634 : loss : 0.021848, loss_ce: 0.008068
2022-01-20 21:25:46,921 Training Data Eval:
2022-01-20 21:25:49,820   Average segmentation loss on training set: 0.0260
2022-01-20 21:25:49,820 Validation Data Eval:
2022-01-20 21:25:50,775   Average segmentation loss on validation set: 0.1598
2022-01-20 21:25:51,470 iteration 2635 : loss : 0.037991, loss_ce: 0.016755
 39%|████████████                   | 155/400 [30:20<49:59, 12.24s/it]2022-01-20 21:25:52,103 iteration 2636 : loss : 0.024268, loss_ce: 0.007292
2022-01-20 21:25:52,871 iteration 2637 : loss : 0.036014, loss_ce: 0.012044
2022-01-20 21:25:53,517 iteration 2638 : loss : 0.024467, loss_ce: 0.009523
2022-01-20 21:25:54,038 iteration 2639 : loss : 0.019994, loss_ce: 0.007485
2022-01-20 21:25:54,620 iteration 2640 : loss : 0.025963, loss_ce: 0.010360
2022-01-20 21:25:55,336 iteration 2641 : loss : 0.032563, loss_ce: 0.012858
2022-01-20 21:25:56,017 iteration 2642 : loss : 0.035909, loss_ce: 0.010026
2022-01-20 21:25:56,693 iteration 2643 : loss : 0.033542, loss_ce: 0.010699
2022-01-20 21:25:57,290 iteration 2644 : loss : 0.032824, loss_ce: 0.008748
2022-01-20 21:25:57,882 iteration 2645 : loss : 0.025870, loss_ce: 0.013067
2022-01-20 21:25:58,485 iteration 2646 : loss : 0.030504, loss_ce: 0.009556
2022-01-20 21:25:59,159 iteration 2647 : loss : 0.025026, loss_ce: 0.011779
2022-01-20 21:25:59,706 iteration 2648 : loss : 0.017916, loss_ce: 0.008098
2022-01-20 21:26:00,364 iteration 2649 : loss : 0.032875, loss_ce: 0.014310
2022-01-20 21:26:01,022 iteration 2650 : loss : 0.021607, loss_ce: 0.009060
2022-01-20 21:26:01,622 iteration 2651 : loss : 0.034507, loss_ce: 0.011914
2022-01-20 21:26:02,251 iteration 2652 : loss : 0.026169, loss_ce: 0.012734
 39%|████████████                   | 156/400 [30:31<48:00, 11.81s/it]2022-01-20 21:26:03,019 iteration 2653 : loss : 0.039869, loss_ce: 0.017063
2022-01-20 21:26:03,655 iteration 2654 : loss : 0.022689, loss_ce: 0.008952
2022-01-20 21:26:04,231 iteration 2655 : loss : 0.017674, loss_ce: 0.006138
2022-01-20 21:26:04,788 iteration 2656 : loss : 0.021522, loss_ce: 0.009855
2022-01-20 21:26:05,367 iteration 2657 : loss : 0.020006, loss_ce: 0.007164
2022-01-20 21:26:05,963 iteration 2658 : loss : 0.024131, loss_ce: 0.009813
2022-01-20 21:26:06,718 iteration 2659 : loss : 0.033543, loss_ce: 0.013642
2022-01-20 21:26:07,348 iteration 2660 : loss : 0.025999, loss_ce: 0.009104
2022-01-20 21:26:07,896 iteration 2661 : loss : 0.021489, loss_ce: 0.008180
2022-01-20 21:26:08,578 iteration 2662 : loss : 0.027406, loss_ce: 0.011798
2022-01-20 21:26:09,163 iteration 2663 : loss : 0.030980, loss_ce: 0.011685
2022-01-20 21:26:09,852 iteration 2664 : loss : 0.024309, loss_ce: 0.007853
2022-01-20 21:26:10,461 iteration 2665 : loss : 0.026427, loss_ce: 0.009908
2022-01-20 21:26:11,097 iteration 2666 : loss : 0.032251, loss_ce: 0.011250
2022-01-20 21:26:11,765 iteration 2667 : loss : 0.018177, loss_ce: 0.006707
2022-01-20 21:26:12,425 iteration 2668 : loss : 0.035332, loss_ce: 0.012091
2022-01-20 21:26:13,103 iteration 2669 : loss : 0.028920, loss_ce: 0.010175
 39%|████████████▏                  | 157/400 [30:42<46:39, 11.52s/it]2022-01-20 21:26:13,793 iteration 2670 : loss : 0.051411, loss_ce: 0.013800
2022-01-20 21:26:14,438 iteration 2671 : loss : 0.027496, loss_ce: 0.008741
2022-01-20 21:26:15,097 iteration 2672 : loss : 0.021720, loss_ce: 0.008785
2022-01-20 21:26:15,787 iteration 2673 : loss : 0.041092, loss_ce: 0.015305
2022-01-20 21:26:16,389 iteration 2674 : loss : 0.023409, loss_ce: 0.010184
2022-01-20 21:26:17,088 iteration 2675 : loss : 0.030919, loss_ce: 0.011300
2022-01-20 21:26:17,743 iteration 2676 : loss : 0.028454, loss_ce: 0.008019
2022-01-20 21:26:18,320 iteration 2677 : loss : 0.020373, loss_ce: 0.008549
2022-01-20 21:26:18,880 iteration 2678 : loss : 0.023777, loss_ce: 0.007439
2022-01-20 21:26:19,539 iteration 2679 : loss : 0.040611, loss_ce: 0.016992
2022-01-20 21:26:20,234 iteration 2680 : loss : 0.040820, loss_ce: 0.023030
2022-01-20 21:26:20,861 iteration 2681 : loss : 0.031109, loss_ce: 0.012540
2022-01-20 21:26:21,435 iteration 2682 : loss : 0.022565, loss_ce: 0.008935
2022-01-20 21:26:22,081 iteration 2683 : loss : 0.030989, loss_ce: 0.015431
2022-01-20 21:26:22,714 iteration 2684 : loss : 0.050032, loss_ce: 0.013623
2022-01-20 21:26:23,351 iteration 2685 : loss : 0.029494, loss_ce: 0.013481
2022-01-20 21:26:23,970 iteration 2686 : loss : 0.030784, loss_ce: 0.012144
 40%|████████████▏                  | 158/400 [30:53<45:40, 11.32s/it]2022-01-20 21:26:24,614 iteration 2687 : loss : 0.021551, loss_ce: 0.009307
2022-01-20 21:26:25,220 iteration 2688 : loss : 0.029729, loss_ce: 0.011578
2022-01-20 21:26:25,739 iteration 2689 : loss : 0.021834, loss_ce: 0.008097
2022-01-20 21:26:26,344 iteration 2690 : loss : 0.022734, loss_ce: 0.008726
2022-01-20 21:26:26,979 iteration 2691 : loss : 0.022969, loss_ce: 0.008937
2022-01-20 21:26:27,594 iteration 2692 : loss : 0.024459, loss_ce: 0.007940
2022-01-20 21:26:28,184 iteration 2693 : loss : 0.030202, loss_ce: 0.010963
2022-01-20 21:26:28,718 iteration 2694 : loss : 0.028997, loss_ce: 0.010369
2022-01-20 21:26:29,385 iteration 2695 : loss : 0.058450, loss_ce: 0.024058
2022-01-20 21:26:30,109 iteration 2696 : loss : 0.039898, loss_ce: 0.014267
2022-01-20 21:26:30,798 iteration 2697 : loss : 0.028036, loss_ce: 0.014392
2022-01-20 21:26:31,368 iteration 2698 : loss : 0.022969, loss_ce: 0.008651
2022-01-20 21:26:31,956 iteration 2699 : loss : 0.027921, loss_ce: 0.008989
2022-01-20 21:26:32,539 iteration 2700 : loss : 0.032461, loss_ce: 0.010154
2022-01-20 21:26:33,166 iteration 2701 : loss : 0.033083, loss_ce: 0.014920
2022-01-20 21:26:33,825 iteration 2702 : loss : 0.036368, loss_ce: 0.008579
2022-01-20 21:26:34,501 iteration 2703 : loss : 0.039030, loss_ce: 0.013710
 40%|████████████▎                  | 159/400 [31:03<44:31, 11.09s/it]2022-01-20 21:26:35,121 iteration 2704 : loss : 0.021389, loss_ce: 0.006522
2022-01-20 21:26:35,699 iteration 2705 : loss : 0.030097, loss_ce: 0.010668
2022-01-20 21:26:36,362 iteration 2706 : loss : 0.029620, loss_ce: 0.012608
2022-01-20 21:26:36,985 iteration 2707 : loss : 0.022242, loss_ce: 0.007749
2022-01-20 21:26:37,594 iteration 2708 : loss : 0.029574, loss_ce: 0.010046
2022-01-20 21:26:38,292 iteration 2709 : loss : 0.034439, loss_ce: 0.011013
2022-01-20 21:26:38,971 iteration 2710 : loss : 0.033371, loss_ce: 0.013836
2022-01-20 21:26:39,575 iteration 2711 : loss : 0.022449, loss_ce: 0.007385
2022-01-20 21:26:40,190 iteration 2712 : loss : 0.033528, loss_ce: 0.012879
2022-01-20 21:26:40,826 iteration 2713 : loss : 0.026914, loss_ce: 0.010137
2022-01-20 21:26:41,455 iteration 2714 : loss : 0.031532, loss_ce: 0.012172
2022-01-20 21:26:42,068 iteration 2715 : loss : 0.024568, loss_ce: 0.013624
2022-01-20 21:26:42,677 iteration 2716 : loss : 0.044073, loss_ce: 0.013486
2022-01-20 21:26:43,240 iteration 2717 : loss : 0.028979, loss_ce: 0.010451
2022-01-20 21:26:43,893 iteration 2718 : loss : 0.031107, loss_ce: 0.011991
2022-01-20 21:26:44,486 iteration 2719 : loss : 0.023837, loss_ce: 0.010863
2022-01-20 21:26:44,487 Training Data Eval:
2022-01-20 21:26:47,388   Average segmentation loss on training set: 0.0201
2022-01-20 21:26:47,388 Validation Data Eval:
2022-01-20 21:26:48,342   Average segmentation loss on validation set: 0.0846
2022-01-20 21:26:48,949 iteration 2720 : loss : 0.024880, loss_ce: 0.010389
 40%|████████████▍                  | 160/400 [31:18<48:21, 12.09s/it]2022-01-20 21:26:49,626 iteration 2721 : loss : 0.026099, loss_ce: 0.009090
2022-01-20 21:26:50,286 iteration 2722 : loss : 0.023655, loss_ce: 0.011498
2022-01-20 21:26:51,001 iteration 2723 : loss : 0.033034, loss_ce: 0.013786
2022-01-20 21:26:51,576 iteration 2724 : loss : 0.022512, loss_ce: 0.007755
2022-01-20 21:26:52,186 iteration 2725 : loss : 0.040771, loss_ce: 0.013436
2022-01-20 21:26:52,889 iteration 2726 : loss : 0.022337, loss_ce: 0.007613
2022-01-20 21:26:53,519 iteration 2727 : loss : 0.028013, loss_ce: 0.010183
2022-01-20 21:26:54,189 iteration 2728 : loss : 0.030615, loss_ce: 0.010931
2022-01-20 21:26:54,849 iteration 2729 : loss : 0.040985, loss_ce: 0.020272
2022-01-20 21:26:55,543 iteration 2730 : loss : 0.035562, loss_ce: 0.013662
2022-01-20 21:26:56,161 iteration 2731 : loss : 0.033173, loss_ce: 0.011605
2022-01-20 21:26:56,697 iteration 2732 : loss : 0.022333, loss_ce: 0.008938
2022-01-20 21:26:57,312 iteration 2733 : loss : 0.022869, loss_ce: 0.010548
2022-01-20 21:26:57,943 iteration 2734 : loss : 0.040746, loss_ce: 0.012841
2022-01-20 21:26:58,577 iteration 2735 : loss : 0.029297, loss_ce: 0.013951
2022-01-20 21:26:59,182 iteration 2736 : loss : 0.027017, loss_ce: 0.007589
2022-01-20 21:26:59,792 iteration 2737 : loss : 0.030901, loss_ce: 0.007933
 40%|████████████▍                  | 161/400 [31:29<46:40, 11.72s/it]2022-01-20 21:27:00,507 iteration 2738 : loss : 0.031946, loss_ce: 0.015227
2022-01-20 21:27:01,091 iteration 2739 : loss : 0.027103, loss_ce: 0.008572
2022-01-20 21:27:01,812 iteration 2740 : loss : 0.033647, loss_ce: 0.014083
2022-01-20 21:27:02,444 iteration 2741 : loss : 0.032290, loss_ce: 0.014359
2022-01-20 21:27:03,087 iteration 2742 : loss : 0.028817, loss_ce: 0.010982
2022-01-20 21:27:03,663 iteration 2743 : loss : 0.030942, loss_ce: 0.011002
2022-01-20 21:27:04,289 iteration 2744 : loss : 0.023346, loss_ce: 0.008142
2022-01-20 21:27:04,878 iteration 2745 : loss : 0.024334, loss_ce: 0.007583
2022-01-20 21:27:05,612 iteration 2746 : loss : 0.051130, loss_ce: 0.013772
2022-01-20 21:27:06,208 iteration 2747 : loss : 0.031485, loss_ce: 0.015391
2022-01-20 21:27:06,878 iteration 2748 : loss : 0.025309, loss_ce: 0.007218
2022-01-20 21:27:07,577 iteration 2749 : loss : 0.037138, loss_ce: 0.014727
2022-01-20 21:27:08,190 iteration 2750 : loss : 0.042838, loss_ce: 0.019339
2022-01-20 21:27:08,814 iteration 2751 : loss : 0.049527, loss_ce: 0.013928
2022-01-20 21:27:09,538 iteration 2752 : loss : 0.025837, loss_ce: 0.009986
2022-01-20 21:27:10,275 iteration 2753 : loss : 0.031764, loss_ce: 0.014079
2022-01-20 21:27:10,931 iteration 2754 : loss : 0.023508, loss_ce: 0.013062
 40%|████████████▌                  | 162/400 [31:40<45:47, 11.54s/it]2022-01-20 21:27:11,479 iteration 2755 : loss : 0.021286, loss_ce: 0.007035
2022-01-20 21:27:12,127 iteration 2756 : loss : 0.034137, loss_ce: 0.014443
2022-01-20 21:27:12,762 iteration 2757 : loss : 0.029873, loss_ce: 0.011895
2022-01-20 21:27:13,387 iteration 2758 : loss : 0.029372, loss_ce: 0.010732
2022-01-20 21:27:14,015 iteration 2759 : loss : 0.031596, loss_ce: 0.012706
2022-01-20 21:27:14,641 iteration 2760 : loss : 0.028024, loss_ce: 0.013111
2022-01-20 21:27:15,307 iteration 2761 : loss : 0.026583, loss_ce: 0.010526
2022-01-20 21:27:15,925 iteration 2762 : loss : 0.026817, loss_ce: 0.010365
2022-01-20 21:27:16,583 iteration 2763 : loss : 0.045458, loss_ce: 0.012620
2022-01-20 21:27:17,148 iteration 2764 : loss : 0.020873, loss_ce: 0.007368
2022-01-20 21:27:17,880 iteration 2765 : loss : 0.027425, loss_ce: 0.009134
2022-01-20 21:27:18,435 iteration 2766 : loss : 0.024271, loss_ce: 0.008301
2022-01-20 21:27:19,073 iteration 2767 : loss : 0.030165, loss_ce: 0.011515
2022-01-20 21:27:19,672 iteration 2768 : loss : 0.027350, loss_ce: 0.009233
2022-01-20 21:27:20,226 iteration 2769 : loss : 0.022990, loss_ce: 0.010456
2022-01-20 21:27:20,814 iteration 2770 : loss : 0.028980, loss_ce: 0.014030
2022-01-20 21:27:21,439 iteration 2771 : loss : 0.023028, loss_ce: 0.009657
 41%|████████████▋                  | 163/400 [31:50<44:22, 11.23s/it]2022-01-20 21:27:22,037 iteration 2772 : loss : 0.024411, loss_ce: 0.008116
2022-01-20 21:27:22,680 iteration 2773 : loss : 0.023647, loss_ce: 0.009429
2022-01-20 21:27:23,324 iteration 2774 : loss : 0.044671, loss_ce: 0.010747
2022-01-20 21:27:23,976 iteration 2775 : loss : 0.025237, loss_ce: 0.010283
2022-01-20 21:27:24,590 iteration 2776 : loss : 0.025866, loss_ce: 0.010654
2022-01-20 21:27:25,280 iteration 2777 : loss : 0.019919, loss_ce: 0.007003
2022-01-20 21:27:25,872 iteration 2778 : loss : 0.030639, loss_ce: 0.011903
2022-01-20 21:27:26,468 iteration 2779 : loss : 0.023779, loss_ce: 0.009647
2022-01-20 21:27:27,080 iteration 2780 : loss : 0.041841, loss_ce: 0.021242
2022-01-20 21:27:27,818 iteration 2781 : loss : 0.030220, loss_ce: 0.011572
2022-01-20 21:27:28,517 iteration 2782 : loss : 0.025758, loss_ce: 0.010680
2022-01-20 21:27:29,134 iteration 2783 : loss : 0.039408, loss_ce: 0.012057
2022-01-20 21:27:29,656 iteration 2784 : loss : 0.027230, loss_ce: 0.007222
2022-01-20 21:27:30,228 iteration 2785 : loss : 0.022187, loss_ce: 0.010264
2022-01-20 21:27:30,789 iteration 2786 : loss : 0.025440, loss_ce: 0.010573
2022-01-20 21:27:31,374 iteration 2787 : loss : 0.022584, loss_ce: 0.008674
2022-01-20 21:27:32,128 iteration 2788 : loss : 0.030928, loss_ce: 0.012153
 41%|████████████▋                  | 164/400 [32:01<43:32, 11.07s/it]2022-01-20 21:27:32,819 iteration 2789 : loss : 0.021810, loss_ce: 0.006714
2022-01-20 21:27:33,531 iteration 2790 : loss : 0.047732, loss_ce: 0.016292
2022-01-20 21:27:34,102 iteration 2791 : loss : 0.018122, loss_ce: 0.005473
2022-01-20 21:27:34,715 iteration 2792 : loss : 0.024577, loss_ce: 0.009021
2022-01-20 21:27:35,349 iteration 2793 : loss : 0.025355, loss_ce: 0.008314
2022-01-20 21:27:36,038 iteration 2794 : loss : 0.028941, loss_ce: 0.014022
2022-01-20 21:27:36,664 iteration 2795 : loss : 0.026948, loss_ce: 0.009993
2022-01-20 21:27:37,266 iteration 2796 : loss : 0.031540, loss_ce: 0.010351
2022-01-20 21:27:37,943 iteration 2797 : loss : 0.026708, loss_ce: 0.010731
2022-01-20 21:27:38,592 iteration 2798 : loss : 0.026414, loss_ce: 0.007473
2022-01-20 21:27:39,306 iteration 2799 : loss : 0.027236, loss_ce: 0.010937
2022-01-20 21:27:39,951 iteration 2800 : loss : 0.029587, loss_ce: 0.014082
2022-01-20 21:27:40,492 iteration 2801 : loss : 0.030611, loss_ce: 0.008281
2022-01-20 21:27:41,072 iteration 2802 : loss : 0.018066, loss_ce: 0.006266
2022-01-20 21:27:41,715 iteration 2803 : loss : 0.028747, loss_ce: 0.010872
2022-01-20 21:27:42,255 iteration 2804 : loss : 0.028328, loss_ce: 0.010482
2022-01-20 21:27:42,255 Training Data Eval:
2022-01-20 21:27:45,161   Average segmentation loss on training set: 0.0176
2022-01-20 21:27:45,161 Validation Data Eval:
2022-01-20 21:27:46,107   Average segmentation loss on validation set: 0.0731
2022-01-20 21:27:46,721 Found new lowest validation loss at iteration 2804! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:27:47,440 iteration 2805 : loss : 0.033599, loss_ce: 0.013099
 41%|████████████▊                  | 165/400 [32:16<48:20, 12.34s/it]2022-01-20 21:27:48,186 iteration 2806 : loss : 0.025363, loss_ce: 0.010561
2022-01-20 21:27:48,901 iteration 2807 : loss : 0.033877, loss_ce: 0.010377
2022-01-20 21:27:49,575 iteration 2808 : loss : 0.027530, loss_ce: 0.009277
2022-01-20 21:27:50,223 iteration 2809 : loss : 0.025706, loss_ce: 0.009499
2022-01-20 21:27:50,782 iteration 2810 : loss : 0.035541, loss_ce: 0.012010
2022-01-20 21:27:51,452 iteration 2811 : loss : 0.023832, loss_ce: 0.010920
2022-01-20 21:27:52,013 iteration 2812 : loss : 0.014768, loss_ce: 0.006019
2022-01-20 21:27:52,704 iteration 2813 : loss : 0.025509, loss_ce: 0.011314
2022-01-20 21:27:53,343 iteration 2814 : loss : 0.022003, loss_ce: 0.007523
2022-01-20 21:27:53,967 iteration 2815 : loss : 0.027188, loss_ce: 0.011053
2022-01-20 21:27:54,589 iteration 2816 : loss : 0.027486, loss_ce: 0.010247
2022-01-20 21:27:55,302 iteration 2817 : loss : 0.032873, loss_ce: 0.006327
2022-01-20 21:27:56,001 iteration 2818 : loss : 0.032489, loss_ce: 0.013372
2022-01-20 21:27:56,622 iteration 2819 : loss : 0.025569, loss_ce: 0.011581
2022-01-20 21:27:57,366 iteration 2820 : loss : 0.044187, loss_ce: 0.013066
2022-01-20 21:27:58,081 iteration 2821 : loss : 0.049955, loss_ce: 0.017696
2022-01-20 21:27:58,762 iteration 2822 : loss : 0.027193, loss_ce: 0.008730
 42%|████████████▊                  | 166/400 [32:28<46:56, 12.04s/it]2022-01-20 21:27:59,538 iteration 2823 : loss : 0.036865, loss_ce: 0.015908
2022-01-20 21:28:00,140 iteration 2824 : loss : 0.023628, loss_ce: 0.010682
2022-01-20 21:28:00,788 iteration 2825 : loss : 0.029877, loss_ce: 0.013595
2022-01-20 21:28:01,531 iteration 2826 : loss : 0.048104, loss_ce: 0.018456
2022-01-20 21:28:02,292 iteration 2827 : loss : 0.041267, loss_ce: 0.012624
2022-01-20 21:28:02,953 iteration 2828 : loss : 0.026562, loss_ce: 0.009219
2022-01-20 21:28:03,584 iteration 2829 : loss : 0.039886, loss_ce: 0.021386
2022-01-20 21:28:04,202 iteration 2830 : loss : 0.027740, loss_ce: 0.009030
2022-01-20 21:28:04,738 iteration 2831 : loss : 0.023371, loss_ce: 0.009937
2022-01-20 21:28:05,508 iteration 2832 : loss : 0.031560, loss_ce: 0.013471
2022-01-20 21:28:06,131 iteration 2833 : loss : 0.026649, loss_ce: 0.010453
2022-01-20 21:28:06,830 iteration 2834 : loss : 0.032855, loss_ce: 0.011653
2022-01-20 21:28:07,497 iteration 2835 : loss : 0.037698, loss_ce: 0.010891
2022-01-20 21:28:08,127 iteration 2836 : loss : 0.030812, loss_ce: 0.012758
2022-01-20 21:28:08,821 iteration 2837 : loss : 0.032228, loss_ce: 0.012679
2022-01-20 21:28:09,391 iteration 2838 : loss : 0.017731, loss_ce: 0.006894
2022-01-20 21:28:10,058 iteration 2839 : loss : 0.028765, loss_ce: 0.010244
 42%|████████████▉                  | 167/400 [32:39<45:52, 11.81s/it]2022-01-20 21:28:10,803 iteration 2840 : loss : 0.031174, loss_ce: 0.010811
2022-01-20 21:28:11,432 iteration 2841 : loss : 0.026996, loss_ce: 0.008199
2022-01-20 21:28:12,053 iteration 2842 : loss : 0.031246, loss_ce: 0.010563
2022-01-20 21:28:12,733 iteration 2843 : loss : 0.026521, loss_ce: 0.007312
2022-01-20 21:28:13,381 iteration 2844 : loss : 0.026415, loss_ce: 0.011336
2022-01-20 21:28:14,010 iteration 2845 : loss : 0.032356, loss_ce: 0.011460
2022-01-20 21:28:14,652 iteration 2846 : loss : 0.021551, loss_ce: 0.007994
2022-01-20 21:28:15,163 iteration 2847 : loss : 0.015322, loss_ce: 0.007960
2022-01-20 21:28:15,804 iteration 2848 : loss : 0.036754, loss_ce: 0.011810
2022-01-20 21:28:16,489 iteration 2849 : loss : 0.030659, loss_ce: 0.011340
2022-01-20 21:28:17,164 iteration 2850 : loss : 0.026292, loss_ce: 0.009570
2022-01-20 21:28:17,865 iteration 2851 : loss : 0.025333, loss_ce: 0.009486
2022-01-20 21:28:18,526 iteration 2852 : loss : 0.038588, loss_ce: 0.010381
2022-01-20 21:28:19,226 iteration 2853 : loss : 0.032511, loss_ce: 0.011746
2022-01-20 21:28:19,890 iteration 2854 : loss : 0.032655, loss_ce: 0.011946
2022-01-20 21:28:20,490 iteration 2855 : loss : 0.027330, loss_ce: 0.013424
2022-01-20 21:28:21,160 iteration 2856 : loss : 0.031559, loss_ce: 0.015552
 42%|█████████████                  | 168/400 [32:50<44:51, 11.60s/it]2022-01-20 21:28:21,751 iteration 2857 : loss : 0.022986, loss_ce: 0.007582
2022-01-20 21:28:22,394 iteration 2858 : loss : 0.025204, loss_ce: 0.011851
2022-01-20 21:28:23,000 iteration 2859 : loss : 0.019906, loss_ce: 0.008452
2022-01-20 21:28:23,680 iteration 2860 : loss : 0.031835, loss_ce: 0.009584
2022-01-20 21:28:24,235 iteration 2861 : loss : 0.025079, loss_ce: 0.011063
2022-01-20 21:28:24,961 iteration 2862 : loss : 0.062600, loss_ce: 0.017249
2022-01-20 21:28:25,550 iteration 2863 : loss : 0.032988, loss_ce: 0.009821
2022-01-20 21:28:26,216 iteration 2864 : loss : 0.025695, loss_ce: 0.009713
2022-01-20 21:28:26,889 iteration 2865 : loss : 0.033767, loss_ce: 0.014041
2022-01-20 21:28:27,503 iteration 2866 : loss : 0.037568, loss_ce: 0.013366
2022-01-20 21:28:28,243 iteration 2867 : loss : 0.027081, loss_ce: 0.009384
2022-01-20 21:28:28,839 iteration 2868 : loss : 0.027438, loss_ce: 0.009201
2022-01-20 21:28:29,564 iteration 2869 : loss : 0.028540, loss_ce: 0.011458
2022-01-20 21:28:30,237 iteration 2870 : loss : 0.022032, loss_ce: 0.007766
2022-01-20 21:28:30,841 iteration 2871 : loss : 0.021437, loss_ce: 0.008386
2022-01-20 21:28:31,404 iteration 2872 : loss : 0.028852, loss_ce: 0.009753
2022-01-20 21:28:32,090 iteration 2873 : loss : 0.028974, loss_ce: 0.009114
 42%|█████████████                  | 169/400 [33:01<43:53, 11.40s/it]2022-01-20 21:28:32,800 iteration 2874 : loss : 0.026278, loss_ce: 0.007898
2022-01-20 21:28:33,451 iteration 2875 : loss : 0.027502, loss_ce: 0.012857
2022-01-20 21:28:34,099 iteration 2876 : loss : 0.034453, loss_ce: 0.014128
2022-01-20 21:28:34,800 iteration 2877 : loss : 0.035122, loss_ce: 0.008895
2022-01-20 21:28:35,445 iteration 2878 : loss : 0.025418, loss_ce: 0.011467
2022-01-20 21:28:36,137 iteration 2879 : loss : 0.027321, loss_ce: 0.009581
2022-01-20 21:28:36,840 iteration 2880 : loss : 0.045593, loss_ce: 0.012783
2022-01-20 21:28:37,487 iteration 2881 : loss : 0.026689, loss_ce: 0.010960
2022-01-20 21:28:38,180 iteration 2882 : loss : 0.033939, loss_ce: 0.016909
2022-01-20 21:28:38,787 iteration 2883 : loss : 0.036588, loss_ce: 0.018138
2022-01-20 21:28:39,404 iteration 2884 : loss : 0.027985, loss_ce: 0.009961
2022-01-20 21:28:40,058 iteration 2885 : loss : 0.029831, loss_ce: 0.012734
2022-01-20 21:28:40,611 iteration 2886 : loss : 0.034349, loss_ce: 0.011505
2022-01-20 21:28:41,322 iteration 2887 : loss : 0.038482, loss_ce: 0.019655
2022-01-20 21:28:41,969 iteration 2888 : loss : 0.051876, loss_ce: 0.011817
2022-01-20 21:28:42,711 iteration 2889 : loss : 0.027603, loss_ce: 0.008966
2022-01-20 21:28:42,711 Training Data Eval:
2022-01-20 21:28:45,609   Average segmentation loss on training set: 0.0209
2022-01-20 21:28:45,610 Validation Data Eval:
2022-01-20 21:28:46,557   Average segmentation loss on validation set: 0.0994
2022-01-20 21:28:47,244 iteration 2890 : loss : 0.023384, loss_ce: 0.007364
 42%|█████████████▏                 | 170/400 [33:16<48:00, 12.52s/it]2022-01-20 21:28:47,953 iteration 2891 : loss : 0.024448, loss_ce: 0.009836
2022-01-20 21:28:48,675 iteration 2892 : loss : 0.051601, loss_ce: 0.013145
2022-01-20 21:28:49,270 iteration 2893 : loss : 0.021661, loss_ce: 0.007137
2022-01-20 21:28:49,994 iteration 2894 : loss : 0.036895, loss_ce: 0.011423
2022-01-20 21:28:50,706 iteration 2895 : loss : 0.039252, loss_ce: 0.017080
2022-01-20 21:28:51,321 iteration 2896 : loss : 0.020681, loss_ce: 0.007208
2022-01-20 21:28:51,969 iteration 2897 : loss : 0.034829, loss_ce: 0.014929
2022-01-20 21:28:52,556 iteration 2898 : loss : 0.031064, loss_ce: 0.014215
2022-01-20 21:28:53,230 iteration 2899 : loss : 0.033027, loss_ce: 0.012642
2022-01-20 21:28:53,861 iteration 2900 : loss : 0.020349, loss_ce: 0.006923
2022-01-20 21:28:54,506 iteration 2901 : loss : 0.027136, loss_ce: 0.008244
2022-01-20 21:28:55,073 iteration 2902 : loss : 0.027736, loss_ce: 0.009352
2022-01-20 21:28:55,668 iteration 2903 : loss : 0.027217, loss_ce: 0.013547
2022-01-20 21:28:56,255 iteration 2904 : loss : 0.026699, loss_ce: 0.010049
2022-01-20 21:28:56,816 iteration 2905 : loss : 0.028780, loss_ce: 0.014601
2022-01-20 21:28:57,482 iteration 2906 : loss : 0.031530, loss_ce: 0.016037
2022-01-20 21:28:58,081 iteration 2907 : loss : 0.028463, loss_ce: 0.010305
 43%|█████████████▎                 | 171/400 [33:27<45:52, 12.02s/it]2022-01-20 21:28:58,796 iteration 2908 : loss : 0.029448, loss_ce: 0.014073
2022-01-20 21:28:59,499 iteration 2909 : loss : 0.032236, loss_ce: 0.014082
2022-01-20 21:29:00,146 iteration 2910 : loss : 0.029292, loss_ce: 0.009586
2022-01-20 21:29:00,830 iteration 2911 : loss : 0.026567, loss_ce: 0.008528
2022-01-20 21:29:01,438 iteration 2912 : loss : 0.024303, loss_ce: 0.008054
2022-01-20 21:29:02,145 iteration 2913 : loss : 0.031219, loss_ce: 0.015443
2022-01-20 21:29:02,759 iteration 2914 : loss : 0.028340, loss_ce: 0.010205
2022-01-20 21:29:03,377 iteration 2915 : loss : 0.022820, loss_ce: 0.009183
2022-01-20 21:29:04,026 iteration 2916 : loss : 0.022260, loss_ce: 0.008933
2022-01-20 21:29:04,593 iteration 2917 : loss : 0.023850, loss_ce: 0.010316
2022-01-20 21:29:05,188 iteration 2918 : loss : 0.021879, loss_ce: 0.006235
2022-01-20 21:29:05,821 iteration 2919 : loss : 0.026105, loss_ce: 0.008953
2022-01-20 21:29:06,480 iteration 2920 : loss : 0.024353, loss_ce: 0.009061
2022-01-20 21:29:07,100 iteration 2921 : loss : 0.021587, loss_ce: 0.009476
2022-01-20 21:29:07,662 iteration 2922 : loss : 0.027616, loss_ce: 0.009328
2022-01-20 21:29:08,269 iteration 2923 : loss : 0.025834, loss_ce: 0.008439
2022-01-20 21:29:08,906 iteration 2924 : loss : 0.029812, loss_ce: 0.010530
 43%|█████████████▎                 | 172/400 [33:38<44:18, 11.66s/it]2022-01-20 21:29:09,479 iteration 2925 : loss : 0.021059, loss_ce: 0.010327
2022-01-20 21:29:10,189 iteration 2926 : loss : 0.032683, loss_ce: 0.013647
2022-01-20 21:29:10,815 iteration 2927 : loss : 0.028600, loss_ce: 0.011875
2022-01-20 21:29:11,331 iteration 2928 : loss : 0.027721, loss_ce: 0.007848
2022-01-20 21:29:11,932 iteration 2929 : loss : 0.021422, loss_ce: 0.009760
2022-01-20 21:29:12,641 iteration 2930 : loss : 0.030102, loss_ce: 0.013369
2022-01-20 21:29:13,248 iteration 2931 : loss : 0.023201, loss_ce: 0.008722
2022-01-20 21:29:13,827 iteration 2932 : loss : 0.028044, loss_ce: 0.009966
2022-01-20 21:29:14,526 iteration 2933 : loss : 0.035914, loss_ce: 0.011862
2022-01-20 21:29:15,150 iteration 2934 : loss : 0.025279, loss_ce: 0.008704
2022-01-20 21:29:15,789 iteration 2935 : loss : 0.021126, loss_ce: 0.006715
2022-01-20 21:29:16,411 iteration 2936 : loss : 0.025507, loss_ce: 0.008278
2022-01-20 21:29:17,066 iteration 2937 : loss : 0.025542, loss_ce: 0.011493
2022-01-20 21:29:17,741 iteration 2938 : loss : 0.028214, loss_ce: 0.008585
2022-01-20 21:29:18,424 iteration 2939 : loss : 0.024486, loss_ce: 0.007717
2022-01-20 21:29:19,166 iteration 2940 : loss : 0.029625, loss_ce: 0.013631
2022-01-20 21:29:19,758 iteration 2941 : loss : 0.021558, loss_ce: 0.006978
 43%|█████████████▍                 | 173/400 [33:49<43:12, 11.42s/it]2022-01-20 21:29:20,379 iteration 2942 : loss : 0.020877, loss_ce: 0.006391
2022-01-20 21:29:21,046 iteration 2943 : loss : 0.031837, loss_ce: 0.008777
2022-01-20 21:29:21,643 iteration 2944 : loss : 0.022360, loss_ce: 0.010689
2022-01-20 21:29:22,287 iteration 2945 : loss : 0.023396, loss_ce: 0.006671
2022-01-20 21:29:22,820 iteration 2946 : loss : 0.024751, loss_ce: 0.008817
2022-01-20 21:29:23,420 iteration 2947 : loss : 0.025036, loss_ce: 0.010274
2022-01-20 21:29:24,011 iteration 2948 : loss : 0.022859, loss_ce: 0.006605
2022-01-20 21:29:24,714 iteration 2949 : loss : 0.031828, loss_ce: 0.010699
2022-01-20 21:29:25,368 iteration 2950 : loss : 0.021742, loss_ce: 0.008555
2022-01-20 21:29:26,036 iteration 2951 : loss : 0.024360, loss_ce: 0.010583
2022-01-20 21:29:26,698 iteration 2952 : loss : 0.026046, loss_ce: 0.009012
2022-01-20 21:29:27,395 iteration 2953 : loss : 0.032703, loss_ce: 0.013251
2022-01-20 21:29:28,141 iteration 2954 : loss : 0.045224, loss_ce: 0.013246
2022-01-20 21:29:28,749 iteration 2955 : loss : 0.021844, loss_ce: 0.009542
2022-01-20 21:29:29,362 iteration 2956 : loss : 0.019498, loss_ce: 0.007981
2022-01-20 21:29:29,945 iteration 2957 : loss : 0.025489, loss_ce: 0.009357
2022-01-20 21:29:30,594 iteration 2958 : loss : 0.032425, loss_ce: 0.016962
 44%|█████████████▍                 | 174/400 [34:00<42:20, 11.24s/it]2022-01-20 21:29:31,244 iteration 2959 : loss : 0.023270, loss_ce: 0.007659
2022-01-20 21:29:31,859 iteration 2960 : loss : 0.025088, loss_ce: 0.010552
2022-01-20 21:29:32,505 iteration 2961 : loss : 0.027444, loss_ce: 0.009843
2022-01-20 21:29:33,297 iteration 2962 : loss : 0.029947, loss_ce: 0.010613
2022-01-20 21:29:33,959 iteration 2963 : loss : 0.041244, loss_ce: 0.014481
2022-01-20 21:29:34,503 iteration 2964 : loss : 0.030093, loss_ce: 0.009590
2022-01-20 21:29:35,151 iteration 2965 : loss : 0.022566, loss_ce: 0.011346
2022-01-20 21:29:35,832 iteration 2966 : loss : 0.027516, loss_ce: 0.009284
2022-01-20 21:29:36,463 iteration 2967 : loss : 0.025731, loss_ce: 0.009795
2022-01-20 21:29:37,109 iteration 2968 : loss : 0.022239, loss_ce: 0.008833
2022-01-20 21:29:37,752 iteration 2969 : loss : 0.040090, loss_ce: 0.018294
2022-01-20 21:29:38,404 iteration 2970 : loss : 0.029222, loss_ce: 0.011326
2022-01-20 21:29:39,027 iteration 2971 : loss : 0.041262, loss_ce: 0.015312
2022-01-20 21:29:39,652 iteration 2972 : loss : 0.032912, loss_ce: 0.015369
2022-01-20 21:29:40,237 iteration 2973 : loss : 0.022944, loss_ce: 0.006066
2022-01-20 21:29:40,933 iteration 2974 : loss : 0.038847, loss_ce: 0.011588
2022-01-20 21:29:40,933 Training Data Eval:
2022-01-20 21:29:43,820   Average segmentation loss on training set: 0.0175
2022-01-20 21:29:43,821 Validation Data Eval:
2022-01-20 21:29:44,777   Average segmentation loss on validation set: 0.0859
2022-01-20 21:29:45,386 iteration 2975 : loss : 0.020398, loss_ce: 0.007947
 44%|█████████████▌                 | 175/400 [34:14<46:09, 12.31s/it]2022-01-20 21:29:45,969 iteration 2976 : loss : 0.019638, loss_ce: 0.008504
2022-01-20 21:29:46,637 iteration 2977 : loss : 0.037735, loss_ce: 0.017797
2022-01-20 21:29:47,283 iteration 2978 : loss : 0.026675, loss_ce: 0.008230
2022-01-20 21:29:47,969 iteration 2979 : loss : 0.027870, loss_ce: 0.009010
2022-01-20 21:29:48,640 iteration 2980 : loss : 0.034124, loss_ce: 0.009765
2022-01-20 21:29:49,392 iteration 2981 : loss : 0.033865, loss_ce: 0.014992
2022-01-20 21:29:50,038 iteration 2982 : loss : 0.019207, loss_ce: 0.007962
2022-01-20 21:29:50,695 iteration 2983 : loss : 0.029987, loss_ce: 0.010540
2022-01-20 21:29:51,350 iteration 2984 : loss : 0.035408, loss_ce: 0.011023
2022-01-20 21:29:52,025 iteration 2985 : loss : 0.028306, loss_ce: 0.010230
2022-01-20 21:29:52,601 iteration 2986 : loss : 0.024054, loss_ce: 0.010825
2022-01-20 21:29:53,240 iteration 2987 : loss : 0.034976, loss_ce: 0.010780
2022-01-20 21:29:53,921 iteration 2988 : loss : 0.024041, loss_ce: 0.008819
2022-01-20 21:29:54,594 iteration 2989 : loss : 0.027474, loss_ce: 0.010336
2022-01-20 21:29:55,170 iteration 2990 : loss : 0.018863, loss_ce: 0.007796
2022-01-20 21:29:55,798 iteration 2991 : loss : 0.021557, loss_ce: 0.008242
2022-01-20 21:29:56,513 iteration 2992 : loss : 0.022605, loss_ce: 0.008941
 44%|█████████████▋                 | 176/400 [34:25<44:37, 11.95s/it]2022-01-20 21:29:57,135 iteration 2993 : loss : 0.024589, loss_ce: 0.012407
2022-01-20 21:29:57,785 iteration 2994 : loss : 0.050562, loss_ce: 0.012492
2022-01-20 21:29:58,398 iteration 2995 : loss : 0.019876, loss_ce: 0.006406
2022-01-20 21:29:59,033 iteration 2996 : loss : 0.029015, loss_ce: 0.016833
2022-01-20 21:29:59,664 iteration 2997 : loss : 0.033068, loss_ce: 0.008896
2022-01-20 21:30:00,315 iteration 2998 : loss : 0.028067, loss_ce: 0.010643
2022-01-20 21:30:01,007 iteration 2999 : loss : 0.062513, loss_ce: 0.016108
2022-01-20 21:30:01,718 iteration 3000 : loss : 0.032553, loss_ce: 0.013732
2022-01-20 21:30:02,437 iteration 3001 : loss : 0.038034, loss_ce: 0.009407
2022-01-20 21:30:03,029 iteration 3002 : loss : 0.025219, loss_ce: 0.009442
2022-01-20 21:30:03,653 iteration 3003 : loss : 0.029174, loss_ce: 0.009924
2022-01-20 21:30:04,276 iteration 3004 : loss : 0.026598, loss_ce: 0.011351
2022-01-20 21:30:04,924 iteration 3005 : loss : 0.031849, loss_ce: 0.013737
2022-01-20 21:30:05,607 iteration 3006 : loss : 0.030792, loss_ce: 0.011285
2022-01-20 21:30:06,280 iteration 3007 : loss : 0.037815, loss_ce: 0.015677
2022-01-20 21:30:06,962 iteration 3008 : loss : 0.029257, loss_ce: 0.010174
2022-01-20 21:30:07,532 iteration 3009 : loss : 0.029401, loss_ce: 0.012393
 44%|█████████████▋                 | 177/400 [34:36<43:23, 11.67s/it]2022-01-20 21:30:08,331 iteration 3010 : loss : 0.046101, loss_ce: 0.015622
2022-01-20 21:30:09,006 iteration 3011 : loss : 0.024903, loss_ce: 0.010668
2022-01-20 21:30:09,594 iteration 3012 : loss : 0.024404, loss_ce: 0.009566
2022-01-20 21:30:10,162 iteration 3013 : loss : 0.031707, loss_ce: 0.010129
2022-01-20 21:30:10,801 iteration 3014 : loss : 0.026037, loss_ce: 0.009839
2022-01-20 21:30:11,425 iteration 3015 : loss : 0.033956, loss_ce: 0.008416
2022-01-20 21:30:12,043 iteration 3016 : loss : 0.040454, loss_ce: 0.017429
2022-01-20 21:30:12,644 iteration 3017 : loss : 0.024542, loss_ce: 0.012987
2022-01-20 21:30:13,241 iteration 3018 : loss : 0.019770, loss_ce: 0.008504
2022-01-20 21:30:13,804 iteration 3019 : loss : 0.026257, loss_ce: 0.009526
2022-01-20 21:30:14,456 iteration 3020 : loss : 0.033076, loss_ce: 0.011847
2022-01-20 21:30:15,101 iteration 3021 : loss : 0.021407, loss_ce: 0.007846
2022-01-20 21:30:15,710 iteration 3022 : loss : 0.023344, loss_ce: 0.009717
2022-01-20 21:30:16,350 iteration 3023 : loss : 0.032332, loss_ce: 0.011585
2022-01-20 21:30:17,071 iteration 3024 : loss : 0.035580, loss_ce: 0.016342
2022-01-20 21:30:17,767 iteration 3025 : loss : 0.036238, loss_ce: 0.016971
2022-01-20 21:30:18,359 iteration 3026 : loss : 0.024056, loss_ce: 0.008609
 44%|█████████████▊                 | 178/400 [34:47<42:14, 11.42s/it]2022-01-20 21:30:19,092 iteration 3027 : loss : 0.040915, loss_ce: 0.014485
2022-01-20 21:30:19,683 iteration 3028 : loss : 0.021250, loss_ce: 0.008485
2022-01-20 21:30:20,331 iteration 3029 : loss : 0.024397, loss_ce: 0.009444
2022-01-20 21:30:20,936 iteration 3030 : loss : 0.021243, loss_ce: 0.009288
2022-01-20 21:30:21,569 iteration 3031 : loss : 0.030638, loss_ce: 0.011818
2022-01-20 21:30:22,163 iteration 3032 : loss : 0.027269, loss_ce: 0.009019
2022-01-20 21:30:22,827 iteration 3033 : loss : 0.031474, loss_ce: 0.009374
2022-01-20 21:30:23,512 iteration 3034 : loss : 0.031341, loss_ce: 0.010686
2022-01-20 21:30:24,170 iteration 3035 : loss : 0.027626, loss_ce: 0.011392
2022-01-20 21:30:24,789 iteration 3036 : loss : 0.031589, loss_ce: 0.017814
2022-01-20 21:30:25,432 iteration 3037 : loss : 0.023448, loss_ce: 0.008573
2022-01-20 21:30:26,109 iteration 3038 : loss : 0.035478, loss_ce: 0.011413
2022-01-20 21:30:26,688 iteration 3039 : loss : 0.022776, loss_ce: 0.007119
2022-01-20 21:30:27,340 iteration 3040 : loss : 0.035041, loss_ce: 0.011026
2022-01-20 21:30:28,031 iteration 3041 : loss : 0.027367, loss_ce: 0.010732
2022-01-20 21:30:28,672 iteration 3042 : loss : 0.025437, loss_ce: 0.012763
2022-01-20 21:30:29,491 iteration 3043 : loss : 0.034970, loss_ce: 0.011471
 45%|█████████████▊                 | 179/400 [34:58<41:44, 11.33s/it]2022-01-20 21:30:30,183 iteration 3044 : loss : 0.031208, loss_ce: 0.013039
2022-01-20 21:30:30,767 iteration 3045 : loss : 0.020259, loss_ce: 0.007658
2022-01-20 21:30:31,374 iteration 3046 : loss : 0.024307, loss_ce: 0.008340
2022-01-20 21:30:32,124 iteration 3047 : loss : 0.030365, loss_ce: 0.014198
2022-01-20 21:30:32,728 iteration 3048 : loss : 0.027015, loss_ce: 0.008860
2022-01-20 21:30:33,369 iteration 3049 : loss : 0.025042, loss_ce: 0.010215
2022-01-20 21:30:34,045 iteration 3050 : loss : 0.025151, loss_ce: 0.011705
2022-01-20 21:30:34,692 iteration 3051 : loss : 0.028401, loss_ce: 0.007751
2022-01-20 21:30:35,314 iteration 3052 : loss : 0.023207, loss_ce: 0.008216
2022-01-20 21:30:36,037 iteration 3053 : loss : 0.021986, loss_ce: 0.009504
2022-01-20 21:30:36,630 iteration 3054 : loss : 0.023813, loss_ce: 0.006561
2022-01-20 21:30:37,293 iteration 3055 : loss : 0.032481, loss_ce: 0.011658
2022-01-20 21:30:37,907 iteration 3056 : loss : 0.021279, loss_ce: 0.009108
2022-01-20 21:30:38,486 iteration 3057 : loss : 0.022391, loss_ce: 0.008619
2022-01-20 21:30:39,145 iteration 3058 : loss : 0.023616, loss_ce: 0.009699
2022-01-20 21:30:39,820 iteration 3059 : loss : 0.022869, loss_ce: 0.006150
2022-01-20 21:30:39,820 Training Data Eval:
2022-01-20 21:30:42,718   Average segmentation loss on training set: 0.0171
2022-01-20 21:30:42,719 Validation Data Eval:
2022-01-20 21:30:43,678   Average segmentation loss on validation set: 0.0748
2022-01-20 21:30:44,277 iteration 3060 : loss : 0.026307, loss_ce: 0.012731
 45%|█████████████▉                 | 180/400 [35:13<45:21, 12.37s/it]2022-01-20 21:30:44,874 iteration 3061 : loss : 0.025200, loss_ce: 0.009417
2022-01-20 21:30:45,511 iteration 3062 : loss : 0.022750, loss_ce: 0.008846
2022-01-20 21:30:46,187 iteration 3063 : loss : 0.027875, loss_ce: 0.010683
2022-01-20 21:30:46,869 iteration 3064 : loss : 0.019126, loss_ce: 0.007666
2022-01-20 21:30:47,410 iteration 3065 : loss : 0.022288, loss_ce: 0.007825
2022-01-20 21:30:48,012 iteration 3066 : loss : 0.021885, loss_ce: 0.010092
2022-01-20 21:30:48,676 iteration 3067 : loss : 0.027295, loss_ce: 0.012713
2022-01-20 21:30:49,330 iteration 3068 : loss : 0.037314, loss_ce: 0.011518
2022-01-20 21:30:49,971 iteration 3069 : loss : 0.028354, loss_ce: 0.008593
2022-01-20 21:30:50,613 iteration 3070 : loss : 0.019443, loss_ce: 0.007559
2022-01-20 21:30:51,193 iteration 3071 : loss : 0.026305, loss_ce: 0.010804
2022-01-20 21:30:51,766 iteration 3072 : loss : 0.024096, loss_ce: 0.008903
2022-01-20 21:30:52,379 iteration 3073 : loss : 0.022438, loss_ce: 0.008430
2022-01-20 21:30:53,082 iteration 3074 : loss : 0.034709, loss_ce: 0.016613
2022-01-20 21:30:53,746 iteration 3075 : loss : 0.035600, loss_ce: 0.011891
2022-01-20 21:30:54,446 iteration 3076 : loss : 0.027358, loss_ce: 0.009548
2022-01-20 21:30:55,033 iteration 3077 : loss : 0.030487, loss_ce: 0.011190
 45%|██████████████                 | 181/400 [35:24<43:22, 11.88s/it]2022-01-20 21:30:55,654 iteration 3078 : loss : 0.022674, loss_ce: 0.008195
2022-01-20 21:30:56,403 iteration 3079 : loss : 0.020325, loss_ce: 0.007241
2022-01-20 21:30:56,966 iteration 3080 : loss : 0.027356, loss_ce: 0.008158
2022-01-20 21:30:57,625 iteration 3081 : loss : 0.022235, loss_ce: 0.007254
2022-01-20 21:30:58,239 iteration 3082 : loss : 0.029948, loss_ce: 0.007320
2022-01-20 21:30:58,918 iteration 3083 : loss : 0.027198, loss_ce: 0.010953
2022-01-20 21:30:59,433 iteration 3084 : loss : 0.018678, loss_ce: 0.008177
2022-01-20 21:31:00,083 iteration 3085 : loss : 0.029905, loss_ce: 0.012163
2022-01-20 21:31:00,813 iteration 3086 : loss : 0.024388, loss_ce: 0.012926
2022-01-20 21:31:01,428 iteration 3087 : loss : 0.024189, loss_ce: 0.009419
2022-01-20 21:31:02,085 iteration 3088 : loss : 0.022009, loss_ce: 0.006909
2022-01-20 21:31:02,822 iteration 3089 : loss : 0.030139, loss_ce: 0.009220
2022-01-20 21:31:03,379 iteration 3090 : loss : 0.024451, loss_ce: 0.010633
2022-01-20 21:31:04,020 iteration 3091 : loss : 0.027783, loss_ce: 0.013181
2022-01-20 21:31:04,806 iteration 3092 : loss : 0.028151, loss_ce: 0.010960
2022-01-20 21:31:05,410 iteration 3093 : loss : 0.020880, loss_ce: 0.008428
2022-01-20 21:31:06,054 iteration 3094 : loss : 0.025775, loss_ce: 0.010849
 46%|██████████████                 | 182/400 [35:35<42:14, 11.63s/it]2022-01-20 21:31:06,723 iteration 3095 : loss : 0.022987, loss_ce: 0.009385
2022-01-20 21:31:07,371 iteration 3096 : loss : 0.018900, loss_ce: 0.008187
2022-01-20 21:31:07,987 iteration 3097 : loss : 0.019568, loss_ce: 0.006760
2022-01-20 21:31:08,574 iteration 3098 : loss : 0.022040, loss_ce: 0.008656
2022-01-20 21:31:09,208 iteration 3099 : loss : 0.021859, loss_ce: 0.007214
2022-01-20 21:31:09,789 iteration 3100 : loss : 0.024603, loss_ce: 0.007441
2022-01-20 21:31:10,475 iteration 3101 : loss : 0.020664, loss_ce: 0.007545
2022-01-20 21:31:11,108 iteration 3102 : loss : 0.025574, loss_ce: 0.009226
2022-01-20 21:31:11,756 iteration 3103 : loss : 0.028842, loss_ce: 0.011214
2022-01-20 21:31:12,348 iteration 3104 : loss : 0.021337, loss_ce: 0.009078
2022-01-20 21:31:12,914 iteration 3105 : loss : 0.018808, loss_ce: 0.008830
2022-01-20 21:31:13,530 iteration 3106 : loss : 0.023061, loss_ce: 0.010699
2022-01-20 21:31:14,139 iteration 3107 : loss : 0.017427, loss_ce: 0.004359
2022-01-20 21:31:14,793 iteration 3108 : loss : 0.025891, loss_ce: 0.007926
2022-01-20 21:31:15,464 iteration 3109 : loss : 0.030111, loss_ce: 0.011695
2022-01-20 21:31:16,133 iteration 3110 : loss : 0.027090, loss_ce: 0.013711
2022-01-20 21:31:16,782 iteration 3111 : loss : 0.021823, loss_ce: 0.008936
 46%|██████████████▏                | 183/400 [35:46<41:04, 11.36s/it]2022-01-20 21:31:17,471 iteration 3112 : loss : 0.034147, loss_ce: 0.013468
2022-01-20 21:31:18,064 iteration 3113 : loss : 0.022198, loss_ce: 0.009592
2022-01-20 21:31:18,735 iteration 3114 : loss : 0.023368, loss_ce: 0.007922
2022-01-20 21:31:19,373 iteration 3115 : loss : 0.021810, loss_ce: 0.010606
2022-01-20 21:31:19,996 iteration 3116 : loss : 0.019733, loss_ce: 0.009698
2022-01-20 21:31:20,699 iteration 3117 : loss : 0.020303, loss_ce: 0.008006
2022-01-20 21:31:21,318 iteration 3118 : loss : 0.034998, loss_ce: 0.013973
2022-01-20 21:31:22,058 iteration 3119 : loss : 0.029419, loss_ce: 0.009048
2022-01-20 21:31:22,648 iteration 3120 : loss : 0.019684, loss_ce: 0.007502
2022-01-20 21:31:23,354 iteration 3121 : loss : 0.020554, loss_ce: 0.009304
2022-01-20 21:31:23,970 iteration 3122 : loss : 0.026155, loss_ce: 0.006953
2022-01-20 21:31:24,669 iteration 3123 : loss : 0.022411, loss_ce: 0.008692
2022-01-20 21:31:25,230 iteration 3124 : loss : 0.018553, loss_ce: 0.006499
2022-01-20 21:31:25,859 iteration 3125 : loss : 0.035283, loss_ce: 0.010725
2022-01-20 21:31:26,555 iteration 3126 : loss : 0.018897, loss_ce: 0.009183
2022-01-20 21:31:27,262 iteration 3127 : loss : 0.027479, loss_ce: 0.009452
2022-01-20 21:31:27,958 iteration 3128 : loss : 0.029862, loss_ce: 0.009793
 46%|██████████████▎                | 184/400 [35:57<40:41, 11.30s/it]2022-01-20 21:31:28,601 iteration 3129 : loss : 0.022463, loss_ce: 0.008130
2022-01-20 21:31:29,329 iteration 3130 : loss : 0.029960, loss_ce: 0.012546
2022-01-20 21:31:29,952 iteration 3131 : loss : 0.021859, loss_ce: 0.006672
2022-01-20 21:31:30,586 iteration 3132 : loss : 0.025172, loss_ce: 0.006945
2022-01-20 21:31:31,220 iteration 3133 : loss : 0.031115, loss_ce: 0.009565
2022-01-20 21:31:31,821 iteration 3134 : loss : 0.018477, loss_ce: 0.008145
2022-01-20 21:31:32,458 iteration 3135 : loss : 0.027129, loss_ce: 0.012203
2022-01-20 21:31:33,074 iteration 3136 : loss : 0.023076, loss_ce: 0.009758
2022-01-20 21:31:33,828 iteration 3137 : loss : 0.029747, loss_ce: 0.011866
2022-01-20 21:31:34,525 iteration 3138 : loss : 0.034269, loss_ce: 0.013173
2022-01-20 21:31:35,098 iteration 3139 : loss : 0.025961, loss_ce: 0.008216
2022-01-20 21:31:35,679 iteration 3140 : loss : 0.027480, loss_ce: 0.013100
2022-01-20 21:31:36,330 iteration 3141 : loss : 0.026965, loss_ce: 0.012410
2022-01-20 21:31:36,939 iteration 3142 : loss : 0.030160, loss_ce: 0.010006
2022-01-20 21:31:37,612 iteration 3143 : loss : 0.029004, loss_ce: 0.011242
2022-01-20 21:31:38,231 iteration 3144 : loss : 0.023237, loss_ce: 0.008447
2022-01-20 21:31:38,231 Training Data Eval:
2022-01-20 21:31:41,120   Average segmentation loss on training set: 0.0160
2022-01-20 21:31:41,120 Validation Data Eval:
2022-01-20 21:31:42,069   Average segmentation loss on validation set: 0.0807
2022-01-20 21:31:42,659 iteration 3145 : loss : 0.022507, loss_ce: 0.009907
 46%|██████████████▎                | 185/400 [36:12<44:09, 12.32s/it]2022-01-20 21:31:43,482 iteration 3146 : loss : 0.042184, loss_ce: 0.013819
2022-01-20 21:31:44,167 iteration 3147 : loss : 0.022211, loss_ce: 0.009704
2022-01-20 21:31:44,740 iteration 3148 : loss : 0.018861, loss_ce: 0.006748
2022-01-20 21:31:45,414 iteration 3149 : loss : 0.022645, loss_ce: 0.006628
2022-01-20 21:31:46,081 iteration 3150 : loss : 0.022318, loss_ce: 0.007310
2022-01-20 21:31:46,746 iteration 3151 : loss : 0.031150, loss_ce: 0.011895
2022-01-20 21:31:47,403 iteration 3152 : loss : 0.026463, loss_ce: 0.008801
2022-01-20 21:31:48,050 iteration 3153 : loss : 0.026951, loss_ce: 0.012854
2022-01-20 21:31:48,769 iteration 3154 : loss : 0.035824, loss_ce: 0.012348
2022-01-20 21:31:49,453 iteration 3155 : loss : 0.020365, loss_ce: 0.007084
2022-01-20 21:31:50,032 iteration 3156 : loss : 0.023670, loss_ce: 0.007804
2022-01-20 21:31:50,688 iteration 3157 : loss : 0.025806, loss_ce: 0.012572
2022-01-20 21:31:51,279 iteration 3158 : loss : 0.058625, loss_ce: 0.014417
2022-01-20 21:31:51,944 iteration 3159 : loss : 0.029683, loss_ce: 0.014373
2022-01-20 21:31:52,609 iteration 3160 : loss : 0.020335, loss_ce: 0.007992
2022-01-20 21:31:53,326 iteration 3161 : loss : 0.025390, loss_ce: 0.008885
2022-01-20 21:31:53,980 iteration 3162 : loss : 0.028220, loss_ce: 0.009112
 46%|██████████████▍                | 186/400 [36:23<42:52, 12.02s/it]2022-01-20 21:31:54,617 iteration 3163 : loss : 0.032622, loss_ce: 0.010436
2022-01-20 21:31:55,365 iteration 3164 : loss : 0.031116, loss_ce: 0.014522
2022-01-20 21:31:56,050 iteration 3165 : loss : 0.021645, loss_ce: 0.008196
2022-01-20 21:31:56,650 iteration 3166 : loss : 0.035524, loss_ce: 0.014750
2022-01-20 21:31:57,335 iteration 3167 : loss : 0.027369, loss_ce: 0.008943
2022-01-20 21:31:57,971 iteration 3168 : loss : 0.023078, loss_ce: 0.009822
2022-01-20 21:31:58,639 iteration 3169 : loss : 0.021963, loss_ce: 0.008634
2022-01-20 21:31:59,276 iteration 3170 : loss : 0.022038, loss_ce: 0.009193
2022-01-20 21:31:59,798 iteration 3171 : loss : 0.022703, loss_ce: 0.006529
2022-01-20 21:32:00,393 iteration 3172 : loss : 0.020637, loss_ce: 0.007800
2022-01-20 21:32:01,024 iteration 3173 : loss : 0.036174, loss_ce: 0.012557
2022-01-20 21:32:01,630 iteration 3174 : loss : 0.026681, loss_ce: 0.011533
2022-01-20 21:32:02,207 iteration 3175 : loss : 0.028494, loss_ce: 0.008329
2022-01-20 21:32:02,924 iteration 3176 : loss : 0.043566, loss_ce: 0.011320
2022-01-20 21:32:03,567 iteration 3177 : loss : 0.037018, loss_ce: 0.013529
2022-01-20 21:32:04,300 iteration 3178 : loss : 0.026392, loss_ce: 0.007906
2022-01-20 21:32:04,948 iteration 3179 : loss : 0.030963, loss_ce: 0.014512
 47%|██████████████▍                | 187/400 [36:34<41:33, 11.71s/it]2022-01-20 21:32:05,638 iteration 3180 : loss : 0.047384, loss_ce: 0.018791
2022-01-20 21:32:06,247 iteration 3181 : loss : 0.028084, loss_ce: 0.014030
2022-01-20 21:32:06,831 iteration 3182 : loss : 0.023417, loss_ce: 0.011158
2022-01-20 21:32:07,529 iteration 3183 : loss : 0.033854, loss_ce: 0.012508
2022-01-20 21:32:08,175 iteration 3184 : loss : 0.027153, loss_ce: 0.009341
2022-01-20 21:32:08,825 iteration 3185 : loss : 0.024970, loss_ce: 0.008218
2022-01-20 21:32:09,502 iteration 3186 : loss : 0.025086, loss_ce: 0.010868
2022-01-20 21:32:10,197 iteration 3187 : loss : 0.022136, loss_ce: 0.008900
2022-01-20 21:32:10,899 iteration 3188 : loss : 0.031374, loss_ce: 0.012319
2022-01-20 21:32:11,534 iteration 3189 : loss : 0.028796, loss_ce: 0.010388
2022-01-20 21:32:12,273 iteration 3190 : loss : 0.028671, loss_ce: 0.009800
2022-01-20 21:32:12,960 iteration 3191 : loss : 0.034528, loss_ce: 0.011915
2022-01-20 21:32:13,536 iteration 3192 : loss : 0.029306, loss_ce: 0.006319
2022-01-20 21:32:14,169 iteration 3193 : loss : 0.020226, loss_ce: 0.007742
2022-01-20 21:32:14,936 iteration 3194 : loss : 0.029255, loss_ce: 0.011008
2022-01-20 21:32:15,595 iteration 3195 : loss : 0.032157, loss_ce: 0.013338
2022-01-20 21:32:16,235 iteration 3196 : loss : 0.025081, loss_ce: 0.010976
 47%|██████████████▌                | 188/400 [36:45<40:54, 11.58s/it]2022-01-20 21:32:16,898 iteration 3197 : loss : 0.018293, loss_ce: 0.007433
2022-01-20 21:32:17,579 iteration 3198 : loss : 0.018855, loss_ce: 0.007880
2022-01-20 21:32:18,253 iteration 3199 : loss : 0.024203, loss_ce: 0.007864
2022-01-20 21:32:18,951 iteration 3200 : loss : 0.031497, loss_ce: 0.011256
2022-01-20 21:32:19,647 iteration 3201 : loss : 0.030643, loss_ce: 0.011764
2022-01-20 21:32:20,337 iteration 3202 : loss : 0.035282, loss_ce: 0.010152
2022-01-20 21:32:20,910 iteration 3203 : loss : 0.018421, loss_ce: 0.008383
2022-01-20 21:32:21,464 iteration 3204 : loss : 0.020340, loss_ce: 0.008130
2022-01-20 21:32:22,023 iteration 3205 : loss : 0.025620, loss_ce: 0.008018
2022-01-20 21:32:22,542 iteration 3206 : loss : 0.016462, loss_ce: 0.005549
2022-01-20 21:32:23,215 iteration 3207 : loss : 0.028785, loss_ce: 0.011816
2022-01-20 21:32:23,850 iteration 3208 : loss : 0.025237, loss_ce: 0.009725
2022-01-20 21:32:24,466 iteration 3209 : loss : 0.025019, loss_ce: 0.009179
2022-01-20 21:32:25,136 iteration 3210 : loss : 0.021349, loss_ce: 0.009740
2022-01-20 21:32:25,716 iteration 3211 : loss : 0.022167, loss_ce: 0.006818
2022-01-20 21:32:26,434 iteration 3212 : loss : 0.031088, loss_ce: 0.013527
2022-01-20 21:32:27,155 iteration 3213 : loss : 0.029045, loss_ce: 0.010855
 47%|██████████████▋                | 189/400 [36:56<40:01, 11.38s/it]2022-01-20 21:32:27,778 iteration 3214 : loss : 0.019948, loss_ce: 0.008264
2022-01-20 21:32:28,408 iteration 3215 : loss : 0.023640, loss_ce: 0.010093
2022-01-20 21:32:29,042 iteration 3216 : loss : 0.031601, loss_ce: 0.010947
2022-01-20 21:32:29,721 iteration 3217 : loss : 0.044445, loss_ce: 0.021386
2022-01-20 21:32:30,368 iteration 3218 : loss : 0.033252, loss_ce: 0.011080
2022-01-20 21:32:31,005 iteration 3219 : loss : 0.027155, loss_ce: 0.011620
2022-01-20 21:32:31,595 iteration 3220 : loss : 0.015649, loss_ce: 0.006800
2022-01-20 21:32:32,329 iteration 3221 : loss : 0.039924, loss_ce: 0.016933
2022-01-20 21:32:32,935 iteration 3222 : loss : 0.019960, loss_ce: 0.005067
2022-01-20 21:32:33,594 iteration 3223 : loss : 0.018851, loss_ce: 0.006517
2022-01-20 21:32:34,323 iteration 3224 : loss : 0.027831, loss_ce: 0.007912
2022-01-20 21:32:34,970 iteration 3225 : loss : 0.037147, loss_ce: 0.019856
2022-01-20 21:32:35,614 iteration 3226 : loss : 0.026789, loss_ce: 0.010034
2022-01-20 21:32:36,269 iteration 3227 : loss : 0.031532, loss_ce: 0.011865
2022-01-20 21:32:36,876 iteration 3228 : loss : 0.033132, loss_ce: 0.010258
2022-01-20 21:32:37,454 iteration 3229 : loss : 0.022638, loss_ce: 0.006538
2022-01-20 21:32:37,454 Training Data Eval:
2022-01-20 21:32:40,359   Average segmentation loss on training set: 0.0166
2022-01-20 21:32:40,359 Validation Data Eval:
2022-01-20 21:32:41,312   Average segmentation loss on validation set: 0.1303
2022-01-20 21:32:41,873 iteration 3230 : loss : 0.028222, loss_ce: 0.009827
 48%|██████████████▋                | 190/400 [37:11<43:20, 12.38s/it]2022-01-20 21:32:42,506 iteration 3231 : loss : 0.037388, loss_ce: 0.008496
2022-01-20 21:32:43,123 iteration 3232 : loss : 0.020194, loss_ce: 0.006714
2022-01-20 21:32:43,771 iteration 3233 : loss : 0.033445, loss_ce: 0.015379
2022-01-20 21:32:44,443 iteration 3234 : loss : 0.027371, loss_ce: 0.009317
2022-01-20 21:32:45,106 iteration 3235 : loss : 0.038016, loss_ce: 0.012633
2022-01-20 21:32:45,685 iteration 3236 : loss : 0.020479, loss_ce: 0.009621
2022-01-20 21:32:46,420 iteration 3237 : loss : 0.037438, loss_ce: 0.018046
2022-01-20 21:32:47,070 iteration 3238 : loss : 0.024484, loss_ce: 0.011449
2022-01-20 21:32:47,714 iteration 3239 : loss : 0.022816, loss_ce: 0.008700
2022-01-20 21:32:48,296 iteration 3240 : loss : 0.037802, loss_ce: 0.009547
2022-01-20 21:32:48,864 iteration 3241 : loss : 0.038798, loss_ce: 0.008616
2022-01-20 21:32:49,514 iteration 3242 : loss : 0.027571, loss_ce: 0.010666
2022-01-20 21:32:50,086 iteration 3243 : loss : 0.032819, loss_ce: 0.011377
2022-01-20 21:32:50,751 iteration 3244 : loss : 0.027247, loss_ce: 0.011014
2022-01-20 21:32:51,350 iteration 3245 : loss : 0.025628, loss_ce: 0.013688
2022-01-20 21:32:52,046 iteration 3246 : loss : 0.029192, loss_ce: 0.013526
2022-01-20 21:32:52,643 iteration 3247 : loss : 0.024101, loss_ce: 0.010142
 48%|██████████████▊                | 191/400 [37:22<41:26, 11.90s/it]2022-01-20 21:32:53,270 iteration 3248 : loss : 0.017649, loss_ce: 0.006926
2022-01-20 21:32:53,853 iteration 3249 : loss : 0.020547, loss_ce: 0.007535
2022-01-20 21:32:54,466 iteration 3250 : loss : 0.032299, loss_ce: 0.010022
2022-01-20 21:32:55,085 iteration 3251 : loss : 0.027233, loss_ce: 0.009822
2022-01-20 21:32:55,734 iteration 3252 : loss : 0.021137, loss_ce: 0.006963
2022-01-20 21:32:56,358 iteration 3253 : loss : 0.018400, loss_ce: 0.007813
2022-01-20 21:32:56,972 iteration 3254 : loss : 0.028198, loss_ce: 0.009876
2022-01-20 21:32:57,522 iteration 3255 : loss : 0.022659, loss_ce: 0.009422
2022-01-20 21:32:58,141 iteration 3256 : loss : 0.022863, loss_ce: 0.008685
2022-01-20 21:32:58,731 iteration 3257 : loss : 0.020743, loss_ce: 0.008101
2022-01-20 21:32:59,369 iteration 3258 : loss : 0.024810, loss_ce: 0.010214
2022-01-20 21:32:59,945 iteration 3259 : loss : 0.030663, loss_ce: 0.011724
2022-01-20 21:33:00,586 iteration 3260 : loss : 0.019682, loss_ce: 0.007478
2022-01-20 21:33:01,189 iteration 3261 : loss : 0.042698, loss_ce: 0.012261
2022-01-20 21:33:01,858 iteration 3262 : loss : 0.028842, loss_ce: 0.010679
2022-01-20 21:33:02,604 iteration 3263 : loss : 0.026485, loss_ce: 0.007143
2022-01-20 21:33:03,246 iteration 3264 : loss : 0.033674, loss_ce: 0.016652
 48%|██████████████▉                | 192/400 [37:32<39:54, 11.51s/it]2022-01-20 21:33:03,862 iteration 3265 : loss : 0.019909, loss_ce: 0.008179
2022-01-20 21:33:04,539 iteration 3266 : loss : 0.030659, loss_ce: 0.013127
2022-01-20 21:33:05,188 iteration 3267 : loss : 0.021764, loss_ce: 0.008725
2022-01-20 21:33:05,773 iteration 3268 : loss : 0.022639, loss_ce: 0.007744
2022-01-20 21:33:06,457 iteration 3269 : loss : 0.029125, loss_ce: 0.011193
2022-01-20 21:33:07,170 iteration 3270 : loss : 0.025696, loss_ce: 0.007769
2022-01-20 21:33:07,861 iteration 3271 : loss : 0.025317, loss_ce: 0.008955
2022-01-20 21:33:08,556 iteration 3272 : loss : 0.023824, loss_ce: 0.009921
2022-01-20 21:33:09,140 iteration 3273 : loss : 0.026048, loss_ce: 0.007281
2022-01-20 21:33:09,765 iteration 3274 : loss : 0.019597, loss_ce: 0.010228
2022-01-20 21:33:10,463 iteration 3275 : loss : 0.037659, loss_ce: 0.010939
2022-01-20 21:33:11,070 iteration 3276 : loss : 0.028459, loss_ce: 0.012434
2022-01-20 21:33:11,731 iteration 3277 : loss : 0.024211, loss_ce: 0.011893
2022-01-20 21:33:12,374 iteration 3278 : loss : 0.026942, loss_ce: 0.009818
2022-01-20 21:33:12,972 iteration 3279 : loss : 0.022404, loss_ce: 0.008628
2022-01-20 21:33:13,593 iteration 3280 : loss : 0.021387, loss_ce: 0.006617
2022-01-20 21:33:14,172 iteration 3281 : loss : 0.017036, loss_ce: 0.005217
 48%|██████████████▉                | 193/400 [37:43<39:06, 11.33s/it]2022-01-20 21:33:14,873 iteration 3282 : loss : 0.028937, loss_ce: 0.010946
2022-01-20 21:33:15,506 iteration 3283 : loss : 0.016462, loss_ce: 0.005310
2022-01-20 21:33:16,139 iteration 3284 : loss : 0.027075, loss_ce: 0.011364
2022-01-20 21:33:16,752 iteration 3285 : loss : 0.024308, loss_ce: 0.008787
2022-01-20 21:33:17,371 iteration 3286 : loss : 0.017032, loss_ce: 0.006388
2022-01-20 21:33:18,020 iteration 3287 : loss : 0.027836, loss_ce: 0.010295
2022-01-20 21:33:18,598 iteration 3288 : loss : 0.027051, loss_ce: 0.014625
2022-01-20 21:33:19,187 iteration 3289 : loss : 0.025190, loss_ce: 0.007615
2022-01-20 21:33:19,871 iteration 3290 : loss : 0.028796, loss_ce: 0.009989
2022-01-20 21:33:20,567 iteration 3291 : loss : 0.040574, loss_ce: 0.013716
2022-01-20 21:33:21,211 iteration 3292 : loss : 0.025858, loss_ce: 0.007947
2022-01-20 21:33:21,836 iteration 3293 : loss : 0.036877, loss_ce: 0.016668
2022-01-20 21:33:22,432 iteration 3294 : loss : 0.034331, loss_ce: 0.017339
2022-01-20 21:33:23,145 iteration 3295 : loss : 0.041087, loss_ce: 0.017965
2022-01-20 21:33:23,810 iteration 3296 : loss : 0.033796, loss_ce: 0.011724
2022-01-20 21:33:24,381 iteration 3297 : loss : 0.017967, loss_ce: 0.007431
2022-01-20 21:33:25,060 iteration 3298 : loss : 0.031892, loss_ce: 0.014834
 48%|███████████████                | 194/400 [37:54<38:27, 11.20s/it]2022-01-20 21:33:25,666 iteration 3299 : loss : 0.019179, loss_ce: 0.008375
2022-01-20 21:33:26,269 iteration 3300 : loss : 0.032062, loss_ce: 0.010495
2022-01-20 21:33:26,962 iteration 3301 : loss : 0.026030, loss_ce: 0.012418
2022-01-20 21:33:27,594 iteration 3302 : loss : 0.025572, loss_ce: 0.009935
2022-01-20 21:33:28,208 iteration 3303 : loss : 0.020306, loss_ce: 0.008277
2022-01-20 21:33:28,845 iteration 3304 : loss : 0.025429, loss_ce: 0.009040
2022-01-20 21:33:29,508 iteration 3305 : loss : 0.033828, loss_ce: 0.010777
2022-01-20 21:33:30,190 iteration 3306 : loss : 0.030025, loss_ce: 0.011860
2022-01-20 21:33:30,791 iteration 3307 : loss : 0.027984, loss_ce: 0.011763
2022-01-20 21:33:31,427 iteration 3308 : loss : 0.028483, loss_ce: 0.012136
2022-01-20 21:33:32,053 iteration 3309 : loss : 0.031124, loss_ce: 0.006694
2022-01-20 21:33:32,762 iteration 3310 : loss : 0.037415, loss_ce: 0.015279
2022-01-20 21:33:33,494 iteration 3311 : loss : 0.027614, loss_ce: 0.011017
2022-01-20 21:33:34,076 iteration 3312 : loss : 0.020273, loss_ce: 0.006826
2022-01-20 21:33:34,670 iteration 3313 : loss : 0.020010, loss_ce: 0.007142
2022-01-20 21:33:35,362 iteration 3314 : loss : 0.023999, loss_ce: 0.008471
2022-01-20 21:33:35,363 Training Data Eval:
2022-01-20 21:33:38,258   Average segmentation loss on training set: 0.0164
2022-01-20 21:33:38,259 Validation Data Eval:
2022-01-20 21:33:39,223   Average segmentation loss on validation set: 0.0845
2022-01-20 21:33:39,808 iteration 3315 : loss : 0.015753, loss_ce: 0.007613
 49%|███████████████                | 195/400 [38:09<41:54, 12.27s/it]2022-01-20 21:33:40,433 iteration 3316 : loss : 0.016060, loss_ce: 0.006109
2022-01-20 21:33:41,039 iteration 3317 : loss : 0.024520, loss_ce: 0.009047
2022-01-20 21:33:41,770 iteration 3318 : loss : 0.024015, loss_ce: 0.009081
2022-01-20 21:33:42,373 iteration 3319 : loss : 0.022863, loss_ce: 0.007853
2022-01-20 21:33:42,992 iteration 3320 : loss : 0.017597, loss_ce: 0.007098
2022-01-20 21:33:43,635 iteration 3321 : loss : 0.018544, loss_ce: 0.005576
2022-01-20 21:33:44,268 iteration 3322 : loss : 0.030256, loss_ce: 0.014405
2022-01-20 21:33:44,849 iteration 3323 : loss : 0.021696, loss_ce: 0.006930
2022-01-20 21:33:45,563 iteration 3324 : loss : 0.039769, loss_ce: 0.018488
2022-01-20 21:33:46,147 iteration 3325 : loss : 0.022985, loss_ce: 0.007732
2022-01-20 21:33:46,813 iteration 3326 : loss : 0.022306, loss_ce: 0.008055
2022-01-20 21:33:47,543 iteration 3327 : loss : 0.030807, loss_ce: 0.009955
2022-01-20 21:33:48,173 iteration 3328 : loss : 0.028242, loss_ce: 0.009806
2022-01-20 21:33:48,771 iteration 3329 : loss : 0.018257, loss_ce: 0.007836
2022-01-20 21:33:49,386 iteration 3330 : loss : 0.040056, loss_ce: 0.013400
2022-01-20 21:33:50,035 iteration 3331 : loss : 0.027191, loss_ce: 0.009068
2022-01-20 21:33:50,579 iteration 3332 : loss : 0.017661, loss_ce: 0.008345
 49%|███████████████▏               | 196/400 [38:20<40:11, 11.82s/it]2022-01-20 21:33:51,231 iteration 3333 : loss : 0.018811, loss_ce: 0.007412
2022-01-20 21:33:51,884 iteration 3334 : loss : 0.019800, loss_ce: 0.008812
2022-01-20 21:33:52,439 iteration 3335 : loss : 0.017336, loss_ce: 0.007300
2022-01-20 21:33:53,070 iteration 3336 : loss : 0.030625, loss_ce: 0.011584
2022-01-20 21:33:53,753 iteration 3337 : loss : 0.038633, loss_ce: 0.014585
2022-01-20 21:33:54,490 iteration 3338 : loss : 0.025261, loss_ce: 0.013532
2022-01-20 21:33:55,119 iteration 3339 : loss : 0.027223, loss_ce: 0.007654
2022-01-20 21:33:55,723 iteration 3340 : loss : 0.021835, loss_ce: 0.009732
2022-01-20 21:33:56,351 iteration 3341 : loss : 0.019383, loss_ce: 0.007002
2022-01-20 21:33:57,031 iteration 3342 : loss : 0.026599, loss_ce: 0.013209
2022-01-20 21:33:57,692 iteration 3343 : loss : 0.025143, loss_ce: 0.008526
2022-01-20 21:33:58,336 iteration 3344 : loss : 0.023464, loss_ce: 0.007621
2022-01-20 21:33:58,946 iteration 3345 : loss : 0.020206, loss_ce: 0.006875
2022-01-20 21:33:59,582 iteration 3346 : loss : 0.019398, loss_ce: 0.009249
2022-01-20 21:34:00,248 iteration 3347 : loss : 0.025649, loss_ce: 0.007214
2022-01-20 21:34:00,979 iteration 3348 : loss : 0.029016, loss_ce: 0.008766
2022-01-20 21:34:01,640 iteration 3349 : loss : 0.025604, loss_ce: 0.008938
 49%|███████████████▎               | 197/400 [38:31<39:12, 11.59s/it]2022-01-20 21:34:02,274 iteration 3350 : loss : 0.019307, loss_ce: 0.007287
2022-01-20 21:34:02,864 iteration 3351 : loss : 0.020334, loss_ce: 0.007492
2022-01-20 21:34:03,478 iteration 3352 : loss : 0.021900, loss_ce: 0.008545
2022-01-20 21:34:04,134 iteration 3353 : loss : 0.023112, loss_ce: 0.009975
2022-01-20 21:34:04,785 iteration 3354 : loss : 0.028750, loss_ce: 0.010480
2022-01-20 21:34:05,488 iteration 3355 : loss : 0.023343, loss_ce: 0.013333
2022-01-20 21:34:06,162 iteration 3356 : loss : 0.025118, loss_ce: 0.007443
2022-01-20 21:34:06,854 iteration 3357 : loss : 0.023088, loss_ce: 0.008708
2022-01-20 21:34:07,561 iteration 3358 : loss : 0.020052, loss_ce: 0.006874
2022-01-20 21:34:08,227 iteration 3359 : loss : 0.019648, loss_ce: 0.007623
2022-01-20 21:34:08,953 iteration 3360 : loss : 0.025531, loss_ce: 0.010597
2022-01-20 21:34:09,537 iteration 3361 : loss : 0.024059, loss_ce: 0.006180
2022-01-20 21:34:10,132 iteration 3362 : loss : 0.027091, loss_ce: 0.010282
2022-01-20 21:34:10,716 iteration 3363 : loss : 0.020828, loss_ce: 0.009370
2022-01-20 21:34:11,366 iteration 3364 : loss : 0.027276, loss_ce: 0.009548
2022-01-20 21:34:11,950 iteration 3365 : loss : 0.018592, loss_ce: 0.008935
2022-01-20 21:34:12,570 iteration 3366 : loss : 0.023887, loss_ce: 0.008393
 50%|███████████████▎               | 198/400 [38:41<38:21, 11.39s/it]2022-01-20 21:34:13,236 iteration 3367 : loss : 0.024640, loss_ce: 0.008560
2022-01-20 21:34:13,855 iteration 3368 : loss : 0.020932, loss_ce: 0.009032
2022-01-20 21:34:14,511 iteration 3369 : loss : 0.019953, loss_ce: 0.007153
2022-01-20 21:34:15,169 iteration 3370 : loss : 0.022571, loss_ce: 0.009711
2022-01-20 21:34:15,715 iteration 3371 : loss : 0.014836, loss_ce: 0.005807
2022-01-20 21:34:16,328 iteration 3372 : loss : 0.025459, loss_ce: 0.012678
2022-01-20 21:34:16,958 iteration 3373 : loss : 0.022006, loss_ce: 0.010728
2022-01-20 21:34:17,540 iteration 3374 : loss : 0.015872, loss_ce: 0.006718
2022-01-20 21:34:18,129 iteration 3375 : loss : 0.018490, loss_ce: 0.007511
2022-01-20 21:34:18,727 iteration 3376 : loss : 0.018180, loss_ce: 0.007172
2022-01-20 21:34:19,401 iteration 3377 : loss : 0.023675, loss_ce: 0.006892
2022-01-20 21:34:20,023 iteration 3378 : loss : 0.031247, loss_ce: 0.010316
2022-01-20 21:34:20,572 iteration 3379 : loss : 0.017589, loss_ce: 0.007679
2022-01-20 21:34:21,265 iteration 3380 : loss : 0.032366, loss_ce: 0.011787
2022-01-20 21:34:21,833 iteration 3381 : loss : 0.034011, loss_ce: 0.006125
2022-01-20 21:34:22,470 iteration 3382 : loss : 0.028822, loss_ce: 0.010510
2022-01-20 21:34:23,088 iteration 3383 : loss : 0.021636, loss_ce: 0.007981
 50%|███████████████▍               | 199/400 [38:52<37:17, 11.13s/it]2022-01-20 21:34:23,709 iteration 3384 : loss : 0.019391, loss_ce: 0.006564
2022-01-20 21:34:24,386 iteration 3385 : loss : 0.032314, loss_ce: 0.013340
2022-01-20 21:34:25,071 iteration 3386 : loss : 0.020347, loss_ce: 0.009031
2022-01-20 21:34:25,737 iteration 3387 : loss : 0.028650, loss_ce: 0.010577
2022-01-20 21:34:26,306 iteration 3388 : loss : 0.021772, loss_ce: 0.008677
2022-01-20 21:34:26,960 iteration 3389 : loss : 0.027064, loss_ce: 0.012700
2022-01-20 21:34:27,519 iteration 3390 : loss : 0.022619, loss_ce: 0.007010
2022-01-20 21:34:28,245 iteration 3391 : loss : 0.028103, loss_ce: 0.009332
2022-01-20 21:34:28,910 iteration 3392 : loss : 0.027753, loss_ce: 0.010835
2022-01-20 21:34:29,580 iteration 3393 : loss : 0.024540, loss_ce: 0.008844
2022-01-20 21:34:30,129 iteration 3394 : loss : 0.024915, loss_ce: 0.008661
2022-01-20 21:34:30,877 iteration 3395 : loss : 0.033382, loss_ce: 0.011344
2022-01-20 21:34:31,537 iteration 3396 : loss : 0.025960, loss_ce: 0.009892
2022-01-20 21:34:32,153 iteration 3397 : loss : 0.025319, loss_ce: 0.011138
2022-01-20 21:34:32,827 iteration 3398 : loss : 0.027673, loss_ce: 0.009924
2022-01-20 21:34:33,481 iteration 3399 : loss : 0.017945, loss_ce: 0.007111
2022-01-20 21:34:33,481 Training Data Eval:
2022-01-20 21:34:36,370   Average segmentation loss on training set: 0.0175
2022-01-20 21:34:36,371 Validation Data Eval:
2022-01-20 21:34:37,322   Average segmentation loss on validation set: 0.0773
2022-01-20 21:34:37,961 iteration 3400 : loss : 0.027500, loss_ce: 0.007469
 50%|███████████████▌               | 200/400 [39:07<40:50, 12.25s/it]2022-01-20 21:34:38,767 iteration 3401 : loss : 0.023993, loss_ce: 0.010388
2022-01-20 21:34:39,451 iteration 3402 : loss : 0.021486, loss_ce: 0.008546
2022-01-20 21:34:40,056 iteration 3403 : loss : 0.020924, loss_ce: 0.009828
2022-01-20 21:34:40,662 iteration 3404 : loss : 0.017977, loss_ce: 0.006335
2022-01-20 21:34:41,275 iteration 3405 : loss : 0.023867, loss_ce: 0.009028
2022-01-20 21:34:41,952 iteration 3406 : loss : 0.032279, loss_ce: 0.011449
2022-01-20 21:34:42,591 iteration 3407 : loss : 0.030979, loss_ce: 0.012582
2022-01-20 21:34:43,250 iteration 3408 : loss : 0.023548, loss_ce: 0.007558
2022-01-20 21:34:43,923 iteration 3409 : loss : 0.027818, loss_ce: 0.012480
2022-01-20 21:34:44,584 iteration 3410 : loss : 0.022074, loss_ce: 0.007337
2022-01-20 21:34:45,287 iteration 3411 : loss : 0.023865, loss_ce: 0.009760
2022-01-20 21:34:45,871 iteration 3412 : loss : 0.023223, loss_ce: 0.007897
2022-01-20 21:34:46,440 iteration 3413 : loss : 0.018889, loss_ce: 0.007703
2022-01-20 21:34:47,099 iteration 3414 : loss : 0.032911, loss_ce: 0.009554
2022-01-20 21:34:47,786 iteration 3415 : loss : 0.019493, loss_ce: 0.007042
2022-01-20 21:34:48,464 iteration 3416 : loss : 0.018823, loss_ce: 0.005299
2022-01-20 21:34:49,184 iteration 3417 : loss : 0.027458, loss_ce: 0.010358
 50%|███████████████▌               | 201/400 [39:18<39:36, 11.94s/it]2022-01-20 21:34:49,878 iteration 3418 : loss : 0.022946, loss_ce: 0.012491
2022-01-20 21:34:50,551 iteration 3419 : loss : 0.022124, loss_ce: 0.007565
2022-01-20 21:34:51,289 iteration 3420 : loss : 0.028118, loss_ce: 0.009391
2022-01-20 21:34:51,960 iteration 3421 : loss : 0.030847, loss_ce: 0.011943
2022-01-20 21:34:52,543 iteration 3422 : loss : 0.022773, loss_ce: 0.006687
2022-01-20 21:34:53,178 iteration 3423 : loss : 0.017919, loss_ce: 0.007431
2022-01-20 21:34:53,812 iteration 3424 : loss : 0.022047, loss_ce: 0.009248
2022-01-20 21:34:54,393 iteration 3425 : loss : 0.019135, loss_ce: 0.008553
2022-01-20 21:34:55,032 iteration 3426 : loss : 0.023709, loss_ce: 0.007446
2022-01-20 21:34:55,688 iteration 3427 : loss : 0.030650, loss_ce: 0.010901
2022-01-20 21:34:56,350 iteration 3428 : loss : 0.031381, loss_ce: 0.011283
2022-01-20 21:34:57,042 iteration 3429 : loss : 0.022156, loss_ce: 0.008262
2022-01-20 21:34:57,737 iteration 3430 : loss : 0.022992, loss_ce: 0.009581
2022-01-20 21:34:58,299 iteration 3431 : loss : 0.019339, loss_ce: 0.007845
2022-01-20 21:34:58,898 iteration 3432 : loss : 0.022666, loss_ce: 0.007319
2022-01-20 21:34:59,498 iteration 3433 : loss : 0.021383, loss_ce: 0.007800
2022-01-20 21:35:00,181 iteration 3434 : loss : 0.028345, loss_ce: 0.010143
 50%|███████████████▋               | 202/400 [39:29<38:28, 11.66s/it]2022-01-20 21:35:00,774 iteration 3435 : loss : 0.023448, loss_ce: 0.007125
2022-01-20 21:35:01,374 iteration 3436 : loss : 0.015976, loss_ce: 0.006173
2022-01-20 21:35:02,118 iteration 3437 : loss : 0.024726, loss_ce: 0.012117
2022-01-20 21:35:02,835 iteration 3438 : loss : 0.022835, loss_ce: 0.010170
2022-01-20 21:35:03,526 iteration 3439 : loss : 0.021125, loss_ce: 0.008492
2022-01-20 21:35:04,136 iteration 3440 : loss : 0.019768, loss_ce: 0.007437
2022-01-20 21:35:04,767 iteration 3441 : loss : 0.025095, loss_ce: 0.009193
2022-01-20 21:35:05,512 iteration 3442 : loss : 0.030062, loss_ce: 0.010579
2022-01-20 21:35:06,197 iteration 3443 : loss : 0.021835, loss_ce: 0.007565
2022-01-20 21:35:06,890 iteration 3444 : loss : 0.022059, loss_ce: 0.008844
2022-01-20 21:35:07,539 iteration 3445 : loss : 0.019414, loss_ce: 0.005200
2022-01-20 21:35:08,172 iteration 3446 : loss : 0.023220, loss_ce: 0.009109
2022-01-20 21:35:08,794 iteration 3447 : loss : 0.023076, loss_ce: 0.007649
2022-01-20 21:35:09,482 iteration 3448 : loss : 0.023182, loss_ce: 0.006656
2022-01-20 21:35:10,143 iteration 3449 : loss : 0.021511, loss_ce: 0.009211
2022-01-20 21:35:10,781 iteration 3450 : loss : 0.028141, loss_ce: 0.012591
2022-01-20 21:35:11,504 iteration 3451 : loss : 0.018476, loss_ce: 0.006531
 51%|███████████████▋               | 203/400 [39:40<37:56, 11.56s/it]2022-01-20 21:35:12,184 iteration 3452 : loss : 0.019218, loss_ce: 0.006945
2022-01-20 21:35:12,808 iteration 3453 : loss : 0.019351, loss_ce: 0.007731
2022-01-20 21:35:13,414 iteration 3454 : loss : 0.026322, loss_ce: 0.008255
2022-01-20 21:35:14,136 iteration 3455 : loss : 0.026565, loss_ce: 0.012198
2022-01-20 21:35:14,737 iteration 3456 : loss : 0.017818, loss_ce: 0.005784
2022-01-20 21:35:15,480 iteration 3457 : loss : 0.031932, loss_ce: 0.011942
2022-01-20 21:35:16,159 iteration 3458 : loss : 0.020919, loss_ce: 0.008085
2022-01-20 21:35:16,800 iteration 3459 : loss : 0.020113, loss_ce: 0.007929
2022-01-20 21:35:17,438 iteration 3460 : loss : 0.031813, loss_ce: 0.020033
2022-01-20 21:35:18,075 iteration 3461 : loss : 0.021357, loss_ce: 0.007138
2022-01-20 21:35:18,698 iteration 3462 : loss : 0.019565, loss_ce: 0.007949
2022-01-20 21:35:19,376 iteration 3463 : loss : 0.021111, loss_ce: 0.007523
2022-01-20 21:35:19,964 iteration 3464 : loss : 0.017536, loss_ce: 0.006069
2022-01-20 21:35:20,656 iteration 3465 : loss : 0.028888, loss_ce: 0.008739
2022-01-20 21:35:21,310 iteration 3466 : loss : 0.022348, loss_ce: 0.007602
2022-01-20 21:35:21,945 iteration 3467 : loss : 0.021477, loss_ce: 0.010901
2022-01-20 21:35:22,570 iteration 3468 : loss : 0.026611, loss_ce: 0.009814
 51%|███████████████▊               | 204/400 [39:51<37:16, 11.41s/it]2022-01-20 21:35:23,210 iteration 3469 : loss : 0.022341, loss_ce: 0.005257
2022-01-20 21:35:23,892 iteration 3470 : loss : 0.027865, loss_ce: 0.009099
2022-01-20 21:35:24,455 iteration 3471 : loss : 0.018338, loss_ce: 0.006130
2022-01-20 21:35:25,109 iteration 3472 : loss : 0.027450, loss_ce: 0.011944
2022-01-20 21:35:25,860 iteration 3473 : loss : 0.035467, loss_ce: 0.012815
2022-01-20 21:35:26,496 iteration 3474 : loss : 0.026820, loss_ce: 0.008209
2022-01-20 21:35:27,217 iteration 3475 : loss : 0.032887, loss_ce: 0.009694
2022-01-20 21:35:27,825 iteration 3476 : loss : 0.023710, loss_ce: 0.007390
2022-01-20 21:35:28,499 iteration 3477 : loss : 0.029102, loss_ce: 0.011331
2022-01-20 21:35:29,133 iteration 3478 : loss : 0.017625, loss_ce: 0.006655
2022-01-20 21:35:29,730 iteration 3479 : loss : 0.023855, loss_ce: 0.009978
2022-01-20 21:35:30,279 iteration 3480 : loss : 0.021360, loss_ce: 0.008179
2022-01-20 21:35:30,904 iteration 3481 : loss : 0.045803, loss_ce: 0.015492
2022-01-20 21:35:31,534 iteration 3482 : loss : 0.024721, loss_ce: 0.009188
2022-01-20 21:35:32,227 iteration 3483 : loss : 0.023446, loss_ce: 0.010175
2022-01-20 21:35:32,776 iteration 3484 : loss : 0.019796, loss_ce: 0.007375
2022-01-20 21:35:32,776 Training Data Eval:
2022-01-20 21:35:35,667   Average segmentation loss on training set: 0.0168
2022-01-20 21:35:35,667 Validation Data Eval:
2022-01-20 21:35:36,625   Average segmentation loss on validation set: 0.1057
2022-01-20 21:35:37,356 iteration 3485 : loss : 0.028113, loss_ce: 0.012726
 51%|███████████████▉               | 205/400 [40:06<40:22, 12.43s/it]2022-01-20 21:35:38,031 iteration 3486 : loss : 0.025766, loss_ce: 0.010743
2022-01-20 21:35:38,614 iteration 3487 : loss : 0.020506, loss_ce: 0.008216
2022-01-20 21:35:39,229 iteration 3488 : loss : 0.031832, loss_ce: 0.010965
2022-01-20 21:35:39,856 iteration 3489 : loss : 0.034738, loss_ce: 0.011736
2022-01-20 21:35:40,517 iteration 3490 : loss : 0.034591, loss_ce: 0.013531
2022-01-20 21:35:41,213 iteration 3491 : loss : 0.029564, loss_ce: 0.010548
2022-01-20 21:35:41,783 iteration 3492 : loss : 0.024800, loss_ce: 0.008905
2022-01-20 21:35:42,519 iteration 3493 : loss : 0.025551, loss_ce: 0.009920
2022-01-20 21:35:43,182 iteration 3494 : loss : 0.028252, loss_ce: 0.008335
2022-01-20 21:35:43,804 iteration 3495 : loss : 0.034041, loss_ce: 0.011119
2022-01-20 21:35:44,480 iteration 3496 : loss : 0.019741, loss_ce: 0.007887
2022-01-20 21:35:45,143 iteration 3497 : loss : 0.027075, loss_ce: 0.010318
2022-01-20 21:35:45,896 iteration 3498 : loss : 0.022372, loss_ce: 0.008212
2022-01-20 21:35:46,505 iteration 3499 : loss : 0.018328, loss_ce: 0.007125
2022-01-20 21:35:47,055 iteration 3500 : loss : 0.018056, loss_ce: 0.005680
2022-01-20 21:35:47,651 iteration 3501 : loss : 0.024756, loss_ce: 0.009357
2022-01-20 21:35:48,304 iteration 3502 : loss : 0.021471, loss_ce: 0.007873
 52%|███████████████▉               | 206/400 [40:17<38:44, 11.98s/it]2022-01-20 21:35:48,996 iteration 3503 : loss : 0.035429, loss_ce: 0.011266
2022-01-20 21:35:49,603 iteration 3504 : loss : 0.017406, loss_ce: 0.004972
2022-01-20 21:35:50,135 iteration 3505 : loss : 0.018745, loss_ce: 0.008374
2022-01-20 21:35:50,782 iteration 3506 : loss : 0.023860, loss_ce: 0.007380
2022-01-20 21:35:51,400 iteration 3507 : loss : 0.024453, loss_ce: 0.007698
2022-01-20 21:35:52,149 iteration 3508 : loss : 0.026961, loss_ce: 0.011326
2022-01-20 21:35:52,808 iteration 3509 : loss : 0.021806, loss_ce: 0.008410
2022-01-20 21:35:53,397 iteration 3510 : loss : 0.026534, loss_ce: 0.010670
2022-01-20 21:35:53,973 iteration 3511 : loss : 0.017347, loss_ce: 0.007762
2022-01-20 21:35:54,683 iteration 3512 : loss : 0.029373, loss_ce: 0.008405
2022-01-20 21:35:55,329 iteration 3513 : loss : 0.021195, loss_ce: 0.007044
2022-01-20 21:35:56,087 iteration 3514 : loss : 0.032877, loss_ce: 0.015127
2022-01-20 21:35:56,708 iteration 3515 : loss : 0.022381, loss_ce: 0.007235
2022-01-20 21:35:57,317 iteration 3516 : loss : 0.018631, loss_ce: 0.007372
2022-01-20 21:35:57,935 iteration 3517 : loss : 0.023779, loss_ce: 0.008805
2022-01-20 21:35:58,558 iteration 3518 : loss : 0.029529, loss_ce: 0.016755
2022-01-20 21:35:59,218 iteration 3519 : loss : 0.019190, loss_ce: 0.006865
 52%|████████████████               | 207/400 [40:28<37:30, 11.66s/it]2022-01-20 21:35:59,913 iteration 3520 : loss : 0.026047, loss_ce: 0.009750
2022-01-20 21:36:00,521 iteration 3521 : loss : 0.039820, loss_ce: 0.018845
2022-01-20 21:36:01,093 iteration 3522 : loss : 0.019435, loss_ce: 0.008983
2022-01-20 21:36:01,714 iteration 3523 : loss : 0.020500, loss_ce: 0.007839
2022-01-20 21:36:02,388 iteration 3524 : loss : 0.018678, loss_ce: 0.007355
2022-01-20 21:36:03,128 iteration 3525 : loss : 0.033078, loss_ce: 0.013680
2022-01-20 21:36:03,786 iteration 3526 : loss : 0.031216, loss_ce: 0.012665
2022-01-20 21:36:04,463 iteration 3527 : loss : 0.029868, loss_ce: 0.009774
2022-01-20 21:36:05,226 iteration 3528 : loss : 0.026200, loss_ce: 0.011109
2022-01-20 21:36:05,896 iteration 3529 : loss : 0.023292, loss_ce: 0.006533
2022-01-20 21:36:06,571 iteration 3530 : loss : 0.018666, loss_ce: 0.007584
2022-01-20 21:36:07,166 iteration 3531 : loss : 0.024393, loss_ce: 0.007177
2022-01-20 21:36:07,890 iteration 3532 : loss : 0.028113, loss_ce: 0.011703
2022-01-20 21:36:08,516 iteration 3533 : loss : 0.021315, loss_ce: 0.006347
2022-01-20 21:36:09,184 iteration 3534 : loss : 0.026283, loss_ce: 0.010364
2022-01-20 21:36:09,893 iteration 3535 : loss : 0.027506, loss_ce: 0.010906
2022-01-20 21:36:10,569 iteration 3536 : loss : 0.024376, loss_ce: 0.011338
 52%|████████████████               | 208/400 [40:39<37:00, 11.57s/it]2022-01-20 21:36:11,165 iteration 3537 : loss : 0.018744, loss_ce: 0.007453
2022-01-20 21:36:11,726 iteration 3538 : loss : 0.018564, loss_ce: 0.008277
2022-01-20 21:36:12,307 iteration 3539 : loss : 0.015946, loss_ce: 0.007369
2022-01-20 21:36:12,827 iteration 3540 : loss : 0.019339, loss_ce: 0.006108
2022-01-20 21:36:13,529 iteration 3541 : loss : 0.029727, loss_ce: 0.011838
2022-01-20 21:36:14,158 iteration 3542 : loss : 0.023150, loss_ce: 0.009720
2022-01-20 21:36:14,911 iteration 3543 : loss : 0.038568, loss_ce: 0.011301
2022-01-20 21:36:15,475 iteration 3544 : loss : 0.015152, loss_ce: 0.006046
2022-01-20 21:36:16,107 iteration 3545 : loss : 0.019141, loss_ce: 0.007986
2022-01-20 21:36:16,676 iteration 3546 : loss : 0.019655, loss_ce: 0.007707
2022-01-20 21:36:17,311 iteration 3547 : loss : 0.019884, loss_ce: 0.008284
2022-01-20 21:36:17,895 iteration 3548 : loss : 0.025795, loss_ce: 0.007846
2022-01-20 21:36:18,542 iteration 3549 : loss : 0.021255, loss_ce: 0.008308
2022-01-20 21:36:19,222 iteration 3550 : loss : 0.019371, loss_ce: 0.008559
2022-01-20 21:36:19,924 iteration 3551 : loss : 0.027632, loss_ce: 0.010344
2022-01-20 21:36:20,633 iteration 3552 : loss : 0.056201, loss_ce: 0.018305
2022-01-20 21:36:21,348 iteration 3553 : loss : 0.023763, loss_ce: 0.010036
 52%|████████████████▏              | 209/400 [40:50<36:04, 11.33s/it]2022-01-20 21:36:22,039 iteration 3554 : loss : 0.021988, loss_ce: 0.009152
2022-01-20 21:36:22,648 iteration 3555 : loss : 0.020119, loss_ce: 0.006333
2022-01-20 21:36:23,259 iteration 3556 : loss : 0.020435, loss_ce: 0.008817
2022-01-20 21:36:23,982 iteration 3557 : loss : 0.042212, loss_ce: 0.012943
2022-01-20 21:36:24,569 iteration 3558 : loss : 0.042915, loss_ce: 0.015312
2022-01-20 21:36:25,186 iteration 3559 : loss : 0.021133, loss_ce: 0.005499
2022-01-20 21:36:25,709 iteration 3560 : loss : 0.020123, loss_ce: 0.009521
2022-01-20 21:36:26,419 iteration 3561 : loss : 0.024604, loss_ce: 0.009023
2022-01-20 21:36:27,019 iteration 3562 : loss : 0.022128, loss_ce: 0.008062
2022-01-20 21:36:27,685 iteration 3563 : loss : 0.021381, loss_ce: 0.006902
2022-01-20 21:36:28,330 iteration 3564 : loss : 0.026888, loss_ce: 0.009785
2022-01-20 21:36:29,081 iteration 3565 : loss : 0.059845, loss_ce: 0.015323
2022-01-20 21:36:29,729 iteration 3566 : loss : 0.031804, loss_ce: 0.011821
2022-01-20 21:36:30,446 iteration 3567 : loss : 0.027433, loss_ce: 0.012628
2022-01-20 21:36:31,142 iteration 3568 : loss : 0.030547, loss_ce: 0.011363
2022-01-20 21:36:31,842 iteration 3569 : loss : 0.044380, loss_ce: 0.011766
2022-01-20 21:36:31,842 Training Data Eval:
2022-01-20 21:36:34,735   Average segmentation loss on training set: 0.0355
2022-01-20 21:36:34,736 Validation Data Eval:
2022-01-20 21:36:35,693   Average segmentation loss on validation set: 0.1014
2022-01-20 21:36:36,353 iteration 3570 : loss : 0.028612, loss_ce: 0.010932
 52%|████████████████▎              | 210/400 [41:05<39:22, 12.43s/it]2022-01-20 21:36:37,023 iteration 3571 : loss : 0.031276, loss_ce: 0.012824
2022-01-20 21:36:37,664 iteration 3572 : loss : 0.068685, loss_ce: 0.024074
2022-01-20 21:36:38,310 iteration 3573 : loss : 0.033306, loss_ce: 0.013636
2022-01-20 21:36:38,918 iteration 3574 : loss : 0.024445, loss_ce: 0.010383
2022-01-20 21:36:39,532 iteration 3575 : loss : 0.025794, loss_ce: 0.011337
2022-01-20 21:36:40,186 iteration 3576 : loss : 0.045430, loss_ce: 0.016721
2022-01-20 21:36:40,872 iteration 3577 : loss : 0.030290, loss_ce: 0.016244
2022-01-20 21:36:41,559 iteration 3578 : loss : 0.034160, loss_ce: 0.013399
2022-01-20 21:36:42,175 iteration 3579 : loss : 0.027649, loss_ce: 0.011062
2022-01-20 21:36:42,841 iteration 3580 : loss : 0.027111, loss_ce: 0.010133
2022-01-20 21:36:43,443 iteration 3581 : loss : 0.030527, loss_ce: 0.008482
2022-01-20 21:36:44,070 iteration 3582 : loss : 0.029573, loss_ce: 0.012555
2022-01-20 21:36:44,744 iteration 3583 : loss : 0.032745, loss_ce: 0.012755
2022-01-20 21:36:45,348 iteration 3584 : loss : 0.030924, loss_ce: 0.012589
2022-01-20 21:36:45,974 iteration 3585 : loss : 0.021270, loss_ce: 0.007948
2022-01-20 21:36:46,546 iteration 3586 : loss : 0.026936, loss_ce: 0.009637
2022-01-20 21:36:47,168 iteration 3587 : loss : 0.028220, loss_ce: 0.012681
 53%|████████████████▎              | 211/400 [41:16<37:38, 11.95s/it]2022-01-20 21:36:47,754 iteration 3588 : loss : 0.026493, loss_ce: 0.009520
2022-01-20 21:36:48,419 iteration 3589 : loss : 0.035394, loss_ce: 0.011209
2022-01-20 21:36:49,047 iteration 3590 : loss : 0.029896, loss_ce: 0.012531
2022-01-20 21:36:49,666 iteration 3591 : loss : 0.019823, loss_ce: 0.006038
2022-01-20 21:36:50,362 iteration 3592 : loss : 0.024590, loss_ce: 0.009849
2022-01-20 21:36:51,014 iteration 3593 : loss : 0.030703, loss_ce: 0.009197
2022-01-20 21:36:51,671 iteration 3594 : loss : 0.021604, loss_ce: 0.006696
2022-01-20 21:36:52,445 iteration 3595 : loss : 0.040337, loss_ce: 0.007898
2022-01-20 21:36:53,009 iteration 3596 : loss : 0.023007, loss_ce: 0.009225
2022-01-20 21:36:53,723 iteration 3597 : loss : 0.038386, loss_ce: 0.014921
2022-01-20 21:36:54,353 iteration 3598 : loss : 0.028914, loss_ce: 0.013670
2022-01-20 21:36:55,000 iteration 3599 : loss : 0.033070, loss_ce: 0.013684
2022-01-20 21:36:55,616 iteration 3600 : loss : 0.030600, loss_ce: 0.013021
2022-01-20 21:36:56,246 iteration 3601 : loss : 0.025900, loss_ce: 0.011817
2022-01-20 21:36:56,854 iteration 3602 : loss : 0.023009, loss_ce: 0.010618
2022-01-20 21:36:57,441 iteration 3603 : loss : 0.018415, loss_ce: 0.006622
2022-01-20 21:36:58,018 iteration 3604 : loss : 0.021797, loss_ce: 0.008300
 53%|████████████████▍              | 212/400 [41:27<36:24, 11.62s/it]2022-01-20 21:36:58,676 iteration 3605 : loss : 0.023495, loss_ce: 0.009176
2022-01-20 21:36:59,303 iteration 3606 : loss : 0.029928, loss_ce: 0.010333
2022-01-20 21:36:59,870 iteration 3607 : loss : 0.020919, loss_ce: 0.007450
2022-01-20 21:37:00,440 iteration 3608 : loss : 0.025156, loss_ce: 0.011272
2022-01-20 21:37:01,098 iteration 3609 : loss : 0.032386, loss_ce: 0.010737
2022-01-20 21:37:01,693 iteration 3610 : loss : 0.027014, loss_ce: 0.010338
2022-01-20 21:37:02,359 iteration 3611 : loss : 0.032687, loss_ce: 0.017639
2022-01-20 21:37:03,042 iteration 3612 : loss : 0.027250, loss_ce: 0.009092
2022-01-20 21:37:03,679 iteration 3613 : loss : 0.021087, loss_ce: 0.007331
2022-01-20 21:37:04,356 iteration 3614 : loss : 0.029001, loss_ce: 0.009719
2022-01-20 21:37:04,965 iteration 3615 : loss : 0.031291, loss_ce: 0.009920
2022-01-20 21:37:05,668 iteration 3616 : loss : 0.030898, loss_ce: 0.009164
2022-01-20 21:37:06,288 iteration 3617 : loss : 0.029727, loss_ce: 0.011860
2022-01-20 21:37:06,915 iteration 3618 : loss : 0.029660, loss_ce: 0.011777
2022-01-20 21:37:07,534 iteration 3619 : loss : 0.022332, loss_ce: 0.009382
2022-01-20 21:37:08,197 iteration 3620 : loss : 0.080841, loss_ce: 0.048666
2022-01-20 21:37:08,819 iteration 3621 : loss : 0.024411, loss_ce: 0.009161
 53%|████████████████▌              | 213/400 [41:38<35:26, 11.37s/it]2022-01-20 21:37:09,563 iteration 3622 : loss : 0.030597, loss_ce: 0.010486
2022-01-20 21:37:10,209 iteration 3623 : loss : 0.025656, loss_ce: 0.010668
2022-01-20 21:37:10,919 iteration 3624 : loss : 0.023417, loss_ce: 0.007948
2022-01-20 21:37:11,619 iteration 3625 : loss : 0.042002, loss_ce: 0.018732
2022-01-20 21:37:12,248 iteration 3626 : loss : 0.022984, loss_ce: 0.009209
2022-01-20 21:37:12,917 iteration 3627 : loss : 0.025376, loss_ce: 0.012186
2022-01-20 21:37:13,572 iteration 3628 : loss : 0.024698, loss_ce: 0.007014
2022-01-20 21:37:14,287 iteration 3629 : loss : 0.028097, loss_ce: 0.012797
2022-01-20 21:37:14,931 iteration 3630 : loss : 0.023542, loss_ce: 0.009469
2022-01-20 21:37:15,504 iteration 3631 : loss : 0.023735, loss_ce: 0.010160
2022-01-20 21:37:16,078 iteration 3632 : loss : 0.020118, loss_ce: 0.008571
2022-01-20 21:37:16,777 iteration 3633 : loss : 0.035519, loss_ce: 0.014625
2022-01-20 21:37:17,410 iteration 3634 : loss : 0.031387, loss_ce: 0.010625
2022-01-20 21:37:18,001 iteration 3635 : loss : 0.022933, loss_ce: 0.007553
2022-01-20 21:37:18,596 iteration 3636 : loss : 0.026135, loss_ce: 0.011297
2022-01-20 21:37:19,295 iteration 3637 : loss : 0.026142, loss_ce: 0.007906
2022-01-20 21:37:19,872 iteration 3638 : loss : 0.021947, loss_ce: 0.007760
 54%|████████████████▌              | 214/400 [41:49<34:57, 11.28s/it]2022-01-20 21:37:20,525 iteration 3639 : loss : 0.028847, loss_ce: 0.014455
2022-01-20 21:37:21,208 iteration 3640 : loss : 0.022314, loss_ce: 0.008262
2022-01-20 21:37:21,855 iteration 3641 : loss : 0.032871, loss_ce: 0.011425
2022-01-20 21:37:22,533 iteration 3642 : loss : 0.031548, loss_ce: 0.013661
2022-01-20 21:37:23,163 iteration 3643 : loss : 0.024959, loss_ce: 0.010737
2022-01-20 21:37:23,779 iteration 3644 : loss : 0.018814, loss_ce: 0.008807
2022-01-20 21:37:24,374 iteration 3645 : loss : 0.019918, loss_ce: 0.007032
2022-01-20 21:37:25,014 iteration 3646 : loss : 0.023919, loss_ce: 0.008115
2022-01-20 21:37:25,698 iteration 3647 : loss : 0.025079, loss_ce: 0.010142
2022-01-20 21:37:26,439 iteration 3648 : loss : 0.039715, loss_ce: 0.017576
2022-01-20 21:37:27,092 iteration 3649 : loss : 0.026544, loss_ce: 0.008736
2022-01-20 21:37:27,732 iteration 3650 : loss : 0.024676, loss_ce: 0.008873
2022-01-20 21:37:28,395 iteration 3651 : loss : 0.021602, loss_ce: 0.008345
2022-01-20 21:37:29,004 iteration 3652 : loss : 0.021406, loss_ce: 0.009343
2022-01-20 21:37:29,713 iteration 3653 : loss : 0.036023, loss_ce: 0.008235
2022-01-20 21:37:30,361 iteration 3654 : loss : 0.022813, loss_ce: 0.006355
2022-01-20 21:37:30,362 Training Data Eval:
2022-01-20 21:37:33,256   Average segmentation loss on training set: 0.0155
2022-01-20 21:37:33,256 Validation Data Eval:
2022-01-20 21:37:34,207   Average segmentation loss on validation set: 0.0993
2022-01-20 21:37:34,742 iteration 3655 : loss : 0.022292, loss_ce: 0.007590
 54%|████████████████▋              | 215/400 [42:04<38:05, 12.35s/it]2022-01-20 21:37:35,465 iteration 3656 : loss : 0.048010, loss_ce: 0.008541
2022-01-20 21:37:36,072 iteration 3657 : loss : 0.021391, loss_ce: 0.009899
2022-01-20 21:37:36,707 iteration 3658 : loss : 0.022508, loss_ce: 0.010884
2022-01-20 21:37:37,384 iteration 3659 : loss : 0.022751, loss_ce: 0.006378
2022-01-20 21:37:38,120 iteration 3660 : loss : 0.044983, loss_ce: 0.015338
2022-01-20 21:37:38,866 iteration 3661 : loss : 0.029593, loss_ce: 0.013982
2022-01-20 21:37:39,427 iteration 3662 : loss : 0.022430, loss_ce: 0.007781
2022-01-20 21:37:40,033 iteration 3663 : loss : 0.019210, loss_ce: 0.006179
2022-01-20 21:37:40,651 iteration 3664 : loss : 0.029763, loss_ce: 0.008942
2022-01-20 21:37:41,285 iteration 3665 : loss : 0.023279, loss_ce: 0.010502
2022-01-20 21:37:42,028 iteration 3666 : loss : 0.030409, loss_ce: 0.013726
2022-01-20 21:37:42,707 iteration 3667 : loss : 0.034249, loss_ce: 0.012282
2022-01-20 21:37:43,387 iteration 3668 : loss : 0.032907, loss_ce: 0.012127
2022-01-20 21:37:44,036 iteration 3669 : loss : 0.031855, loss_ce: 0.016301
2022-01-20 21:37:44,650 iteration 3670 : loss : 0.029886, loss_ce: 0.009585
2022-01-20 21:37:45,331 iteration 3671 : loss : 0.028661, loss_ce: 0.011187
2022-01-20 21:37:45,924 iteration 3672 : loss : 0.023921, loss_ce: 0.010224
 54%|████████████████▋              | 216/400 [42:15<36:48, 12.00s/it]2022-01-20 21:37:46,590 iteration 3673 : loss : 0.023336, loss_ce: 0.010976
2022-01-20 21:37:47,235 iteration 3674 : loss : 0.027082, loss_ce: 0.011618
2022-01-20 21:37:47,860 iteration 3675 : loss : 0.022601, loss_ce: 0.010590
2022-01-20 21:37:48,480 iteration 3676 : loss : 0.026106, loss_ce: 0.008043
2022-01-20 21:37:49,105 iteration 3677 : loss : 0.022256, loss_ce: 0.010838
2022-01-20 21:37:49,826 iteration 3678 : loss : 0.042607, loss_ce: 0.013275
2022-01-20 21:37:50,454 iteration 3679 : loss : 0.025233, loss_ce: 0.010421
2022-01-20 21:37:51,066 iteration 3680 : loss : 0.028201, loss_ce: 0.008921
2022-01-20 21:37:51,749 iteration 3681 : loss : 0.025530, loss_ce: 0.008680
2022-01-20 21:37:52,365 iteration 3682 : loss : 0.026219, loss_ce: 0.010907
2022-01-20 21:37:53,050 iteration 3683 : loss : 0.061454, loss_ce: 0.006236
2022-01-20 21:37:53,652 iteration 3684 : loss : 0.013890, loss_ce: 0.004260
2022-01-20 21:37:54,265 iteration 3685 : loss : 0.026297, loss_ce: 0.011803
2022-01-20 21:37:54,918 iteration 3686 : loss : 0.034564, loss_ce: 0.014005
2022-01-20 21:37:55,556 iteration 3687 : loss : 0.033825, loss_ce: 0.010639
2022-01-20 21:37:56,182 iteration 3688 : loss : 0.033590, loss_ce: 0.015598
2022-01-20 21:37:56,753 iteration 3689 : loss : 0.027567, loss_ce: 0.010914
 54%|████████████████▊              | 217/400 [42:26<35:32, 11.65s/it]2022-01-20 21:37:57,385 iteration 3690 : loss : 0.028982, loss_ce: 0.007215
2022-01-20 21:37:58,097 iteration 3691 : loss : 0.064985, loss_ce: 0.016266
2022-01-20 21:37:58,740 iteration 3692 : loss : 0.034341, loss_ce: 0.017991
2022-01-20 21:37:59,444 iteration 3693 : loss : 0.047891, loss_ce: 0.019187
2022-01-20 21:38:00,086 iteration 3694 : loss : 0.026314, loss_ce: 0.010965
2022-01-20 21:38:00,672 iteration 3695 : loss : 0.026616, loss_ce: 0.011143
2022-01-20 21:38:01,346 iteration 3696 : loss : 0.030888, loss_ce: 0.015328
2022-01-20 21:38:01,965 iteration 3697 : loss : 0.032823, loss_ce: 0.009595
2022-01-20 21:38:02,602 iteration 3698 : loss : 0.031963, loss_ce: 0.011082
2022-01-20 21:38:03,311 iteration 3699 : loss : 0.027875, loss_ce: 0.010404
2022-01-20 21:38:03,955 iteration 3700 : loss : 0.026164, loss_ce: 0.011915
2022-01-20 21:38:04,573 iteration 3701 : loss : 0.030933, loss_ce: 0.011223
2022-01-20 21:38:05,177 iteration 3702 : loss : 0.033631, loss_ce: 0.013703
2022-01-20 21:38:05,927 iteration 3703 : loss : 0.048963, loss_ce: 0.023603
2022-01-20 21:38:06,525 iteration 3704 : loss : 0.022953, loss_ce: 0.006398
2022-01-20 21:38:07,113 iteration 3705 : loss : 0.029921, loss_ce: 0.009576
2022-01-20 21:38:07,698 iteration 3706 : loss : 0.018446, loss_ce: 0.005207
 55%|████████████████▉              | 218/400 [42:37<34:41, 11.44s/it]2022-01-20 21:38:08,369 iteration 3707 : loss : 0.047175, loss_ce: 0.025278
2022-01-20 21:38:09,012 iteration 3708 : loss : 0.025567, loss_ce: 0.010121
2022-01-20 21:38:09,659 iteration 3709 : loss : 0.024546, loss_ce: 0.007693
2022-01-20 21:38:10,350 iteration 3710 : loss : 0.028624, loss_ce: 0.009450
2022-01-20 21:38:10,967 iteration 3711 : loss : 0.020310, loss_ce: 0.007133
2022-01-20 21:38:11,631 iteration 3712 : loss : 0.027822, loss_ce: 0.008311
2022-01-20 21:38:12,227 iteration 3713 : loss : 0.023237, loss_ce: 0.008405
2022-01-20 21:38:12,836 iteration 3714 : loss : 0.029600, loss_ce: 0.011341
2022-01-20 21:38:13,489 iteration 3715 : loss : 0.029062, loss_ce: 0.011743
2022-01-20 21:38:14,087 iteration 3716 : loss : 0.030076, loss_ce: 0.011359
2022-01-20 21:38:14,744 iteration 3717 : loss : 0.035745, loss_ce: 0.014254
2022-01-20 21:38:15,435 iteration 3718 : loss : 0.024214, loss_ce: 0.010915
2022-01-20 21:38:16,021 iteration 3719 : loss : 0.022832, loss_ce: 0.006146
2022-01-20 21:38:16,680 iteration 3720 : loss : 0.019014, loss_ce: 0.009149
2022-01-20 21:38:17,326 iteration 3721 : loss : 0.023225, loss_ce: 0.009946
2022-01-20 21:38:17,947 iteration 3722 : loss : 0.031946, loss_ce: 0.012360
2022-01-20 21:38:18,544 iteration 3723 : loss : 0.032210, loss_ce: 0.009714
 55%|████████████████▉              | 219/400 [42:47<33:58, 11.26s/it]2022-01-20 21:38:19,144 iteration 3724 : loss : 0.017231, loss_ce: 0.007654
2022-01-20 21:38:19,733 iteration 3725 : loss : 0.023936, loss_ce: 0.010207
2022-01-20 21:38:20,419 iteration 3726 : loss : 0.025607, loss_ce: 0.011876
2022-01-20 21:38:21,057 iteration 3727 : loss : 0.021560, loss_ce: 0.008619
2022-01-20 21:38:21,704 iteration 3728 : loss : 0.022762, loss_ce: 0.005970
2022-01-20 21:38:22,294 iteration 3729 : loss : 0.021904, loss_ce: 0.006058
2022-01-20 21:38:22,908 iteration 3730 : loss : 0.022091, loss_ce: 0.009023
2022-01-20 21:38:23,516 iteration 3731 : loss : 0.023003, loss_ce: 0.008098
2022-01-20 21:38:24,175 iteration 3732 : loss : 0.032672, loss_ce: 0.013290
2022-01-20 21:38:24,760 iteration 3733 : loss : 0.022424, loss_ce: 0.008401
2022-01-20 21:38:25,408 iteration 3734 : loss : 0.030394, loss_ce: 0.013047
2022-01-20 21:38:26,052 iteration 3735 : loss : 0.021746, loss_ce: 0.006522
2022-01-20 21:38:26,750 iteration 3736 : loss : 0.029241, loss_ce: 0.014752
2022-01-20 21:38:27,348 iteration 3737 : loss : 0.019619, loss_ce: 0.006743
2022-01-20 21:38:27,976 iteration 3738 : loss : 0.020446, loss_ce: 0.007581
2022-01-20 21:38:28,565 iteration 3739 : loss : 0.023843, loss_ce: 0.009343
2022-01-20 21:38:28,565 Training Data Eval:
2022-01-20 21:38:31,465   Average segmentation loss on training set: 0.0173
2022-01-20 21:38:31,465 Validation Data Eval:
2022-01-20 21:38:32,422   Average segmentation loss on validation set: 0.1075
2022-01-20 21:38:33,205 iteration 3740 : loss : 0.034612, loss_ce: 0.015738
 55%|█████████████████              | 220/400 [43:02<36:50, 12.28s/it]2022-01-20 21:38:34,005 iteration 3741 : loss : 0.041821, loss_ce: 0.014976
2022-01-20 21:38:34,633 iteration 3742 : loss : 0.026585, loss_ce: 0.012119
2022-01-20 21:38:35,266 iteration 3743 : loss : 0.029609, loss_ce: 0.010278
2022-01-20 21:38:35,946 iteration 3744 : loss : 0.024798, loss_ce: 0.009322
2022-01-20 21:38:36,644 iteration 3745 : loss : 0.026332, loss_ce: 0.008297
2022-01-20 21:38:37,349 iteration 3746 : loss : 0.039031, loss_ce: 0.014438
2022-01-20 21:38:37,985 iteration 3747 : loss : 0.022781, loss_ce: 0.007670
2022-01-20 21:38:38,601 iteration 3748 : loss : 0.019608, loss_ce: 0.009070
2022-01-20 21:38:39,293 iteration 3749 : loss : 0.039803, loss_ce: 0.012272
2022-01-20 21:38:40,014 iteration 3750 : loss : 0.032610, loss_ce: 0.011779
2022-01-20 21:38:40,679 iteration 3751 : loss : 0.037893, loss_ce: 0.013128
2022-01-20 21:38:41,297 iteration 3752 : loss : 0.037361, loss_ce: 0.008499
2022-01-20 21:38:41,888 iteration 3753 : loss : 0.024351, loss_ce: 0.007765
2022-01-20 21:38:42,529 iteration 3754 : loss : 0.022956, loss_ce: 0.008805
2022-01-20 21:38:43,217 iteration 3755 : loss : 0.022642, loss_ce: 0.010846
2022-01-20 21:38:43,780 iteration 3756 : loss : 0.024810, loss_ce: 0.010597
2022-01-20 21:38:44,367 iteration 3757 : loss : 0.022480, loss_ce: 0.008948
 55%|█████████████████▏             | 221/400 [43:13<35:38, 11.95s/it]2022-01-20 21:38:45,111 iteration 3758 : loss : 0.023980, loss_ce: 0.008125
2022-01-20 21:38:45,702 iteration 3759 : loss : 0.022334, loss_ce: 0.007145
2022-01-20 21:38:46,313 iteration 3760 : loss : 0.020037, loss_ce: 0.008427
2022-01-20 21:38:46,986 iteration 3761 : loss : 0.027985, loss_ce: 0.010338
2022-01-20 21:38:47,679 iteration 3762 : loss : 0.022133, loss_ce: 0.011305
2022-01-20 21:38:48,418 iteration 3763 : loss : 0.033806, loss_ce: 0.013491
2022-01-20 21:38:49,052 iteration 3764 : loss : 0.033570, loss_ce: 0.011127
2022-01-20 21:38:49,644 iteration 3765 : loss : 0.020902, loss_ce: 0.008212
2022-01-20 21:38:50,336 iteration 3766 : loss : 0.026376, loss_ce: 0.010378
2022-01-20 21:38:50,975 iteration 3767 : loss : 0.020328, loss_ce: 0.007299
2022-01-20 21:38:51,576 iteration 3768 : loss : 0.027565, loss_ce: 0.008519
2022-01-20 21:38:52,184 iteration 3769 : loss : 0.019536, loss_ce: 0.008241
2022-01-20 21:38:52,854 iteration 3770 : loss : 0.029711, loss_ce: 0.006429
2022-01-20 21:38:53,618 iteration 3771 : loss : 0.024999, loss_ce: 0.008594
2022-01-20 21:38:54,326 iteration 3772 : loss : 0.026537, loss_ce: 0.007193
2022-01-20 21:38:54,989 iteration 3773 : loss : 0.015403, loss_ce: 0.005807
2022-01-20 21:38:55,692 iteration 3774 : loss : 0.028112, loss_ce: 0.013986
 56%|█████████████████▏             | 222/400 [43:25<34:52, 11.76s/it]2022-01-20 21:38:56,347 iteration 3775 : loss : 0.022508, loss_ce: 0.008866
2022-01-20 21:38:56,904 iteration 3776 : loss : 0.020830, loss_ce: 0.008800
2022-01-20 21:38:57,518 iteration 3777 : loss : 0.024287, loss_ce: 0.006551
2022-01-20 21:38:58,111 iteration 3778 : loss : 0.020337, loss_ce: 0.007602
2022-01-20 21:38:58,704 iteration 3779 : loss : 0.019583, loss_ce: 0.009125
2022-01-20 21:38:59,352 iteration 3780 : loss : 0.021982, loss_ce: 0.007392
2022-01-20 21:39:00,002 iteration 3781 : loss : 0.021916, loss_ce: 0.009665
2022-01-20 21:39:00,667 iteration 3782 : loss : 0.058612, loss_ce: 0.008377
2022-01-20 21:39:01,324 iteration 3783 : loss : 0.017848, loss_ce: 0.008078
2022-01-20 21:39:01,984 iteration 3784 : loss : 0.022318, loss_ce: 0.011088
2022-01-20 21:39:02,589 iteration 3785 : loss : 0.023388, loss_ce: 0.010032
2022-01-20 21:39:03,191 iteration 3786 : loss : 0.018437, loss_ce: 0.007612
2022-01-20 21:39:03,782 iteration 3787 : loss : 0.021939, loss_ce: 0.007100
2022-01-20 21:39:04,477 iteration 3788 : loss : 0.028495, loss_ce: 0.007721
2022-01-20 21:39:05,109 iteration 3789 : loss : 0.021170, loss_ce: 0.005919
2022-01-20 21:39:05,776 iteration 3790 : loss : 0.026701, loss_ce: 0.010003
2022-01-20 21:39:06,444 iteration 3791 : loss : 0.022085, loss_ce: 0.008282
 56%|█████████████████▎             | 223/400 [43:35<33:48, 11.46s/it]2022-01-20 21:39:07,087 iteration 3792 : loss : 0.014028, loss_ce: 0.005084
2022-01-20 21:39:07,770 iteration 3793 : loss : 0.021275, loss_ce: 0.006314
2022-01-20 21:39:08,439 iteration 3794 : loss : 0.030779, loss_ce: 0.012321
2022-01-20 21:39:09,082 iteration 3795 : loss : 0.023224, loss_ce: 0.008019
2022-01-20 21:39:09,626 iteration 3796 : loss : 0.018513, loss_ce: 0.006174
2022-01-20 21:39:10,241 iteration 3797 : loss : 0.019624, loss_ce: 0.006622
2022-01-20 21:39:10,807 iteration 3798 : loss : 0.019795, loss_ce: 0.007129
2022-01-20 21:39:11,420 iteration 3799 : loss : 0.025980, loss_ce: 0.010438
2022-01-20 21:39:12,034 iteration 3800 : loss : 0.017213, loss_ce: 0.004819
2022-01-20 21:39:12,653 iteration 3801 : loss : 0.041863, loss_ce: 0.012871
2022-01-20 21:39:13,259 iteration 3802 : loss : 0.021808, loss_ce: 0.010020
2022-01-20 21:39:13,885 iteration 3803 : loss : 0.016050, loss_ce: 0.004979
2022-01-20 21:39:14,512 iteration 3804 : loss : 0.025136, loss_ce: 0.009547
2022-01-20 21:39:15,114 iteration 3805 : loss : 0.024034, loss_ce: 0.010724
2022-01-20 21:39:15,712 iteration 3806 : loss : 0.021380, loss_ce: 0.009568
2022-01-20 21:39:16,381 iteration 3807 : loss : 0.023847, loss_ce: 0.008987
2022-01-20 21:39:17,027 iteration 3808 : loss : 0.020302, loss_ce: 0.009009
 56%|█████████████████▎             | 224/400 [43:46<32:50, 11.19s/it]2022-01-20 21:39:17,639 iteration 3809 : loss : 0.016083, loss_ce: 0.005205
2022-01-20 21:39:18,254 iteration 3810 : loss : 0.022346, loss_ce: 0.008476
2022-01-20 21:39:18,886 iteration 3811 : loss : 0.016994, loss_ce: 0.004631
2022-01-20 21:39:19,530 iteration 3812 : loss : 0.022035, loss_ce: 0.011340
2022-01-20 21:39:20,145 iteration 3813 : loss : 0.017704, loss_ce: 0.007814
2022-01-20 21:39:20,801 iteration 3814 : loss : 0.022021, loss_ce: 0.008155
2022-01-20 21:39:21,432 iteration 3815 : loss : 0.018935, loss_ce: 0.007252
2022-01-20 21:39:22,076 iteration 3816 : loss : 0.018400, loss_ce: 0.007365
2022-01-20 21:39:22,658 iteration 3817 : loss : 0.023491, loss_ce: 0.011725
2022-01-20 21:39:23,316 iteration 3818 : loss : 0.016653, loss_ce: 0.007465
2022-01-20 21:39:24,001 iteration 3819 : loss : 0.021263, loss_ce: 0.009938
2022-01-20 21:39:24,667 iteration 3820 : loss : 0.028098, loss_ce: 0.011741
2022-01-20 21:39:25,333 iteration 3821 : loss : 0.024954, loss_ce: 0.010367
2022-01-20 21:39:25,928 iteration 3822 : loss : 0.025665, loss_ce: 0.007900
2022-01-20 21:39:26,641 iteration 3823 : loss : 0.054885, loss_ce: 0.016228
2022-01-20 21:39:27,290 iteration 3824 : loss : 0.025952, loss_ce: 0.008629
2022-01-20 21:39:27,290 Training Data Eval:
2022-01-20 21:39:30,184   Average segmentation loss on training set: 0.0140
2022-01-20 21:39:30,185 Validation Data Eval:
2022-01-20 21:39:31,143   Average segmentation loss on validation set: 0.0840
2022-01-20 21:39:31,856 iteration 3825 : loss : 0.025613, loss_ce: 0.009742
 56%|█████████████████▍             | 225/400 [44:01<35:49, 12.28s/it]2022-01-20 21:39:32,547 iteration 3826 : loss : 0.026670, loss_ce: 0.012220
2022-01-20 21:39:33,137 iteration 3827 : loss : 0.020476, loss_ce: 0.007534
2022-01-20 21:39:33,790 iteration 3828 : loss : 0.018939, loss_ce: 0.007309
2022-01-20 21:39:34,428 iteration 3829 : loss : 0.022727, loss_ce: 0.006313
2022-01-20 21:39:35,026 iteration 3830 : loss : 0.015875, loss_ce: 0.005560
2022-01-20 21:39:35,612 iteration 3831 : loss : 0.019899, loss_ce: 0.006215
2022-01-20 21:39:36,192 iteration 3832 : loss : 0.021872, loss_ce: 0.005143
2022-01-20 21:39:36,818 iteration 3833 : loss : 0.020531, loss_ce: 0.009307
2022-01-20 21:39:37,479 iteration 3834 : loss : 0.023605, loss_ce: 0.010826
2022-01-20 21:39:38,123 iteration 3835 : loss : 0.025984, loss_ce: 0.010138
2022-01-20 21:39:38,760 iteration 3836 : loss : 0.021509, loss_ce: 0.008068
2022-01-20 21:39:39,425 iteration 3837 : loss : 0.025662, loss_ce: 0.009617
2022-01-20 21:39:40,152 iteration 3838 : loss : 0.023220, loss_ce: 0.008097
2022-01-20 21:39:40,781 iteration 3839 : loss : 0.023266, loss_ce: 0.009866
2022-01-20 21:39:41,421 iteration 3840 : loss : 0.023722, loss_ce: 0.005986
2022-01-20 21:39:42,020 iteration 3841 : loss : 0.021020, loss_ce: 0.007214
2022-01-20 21:39:42,673 iteration 3842 : loss : 0.027385, loss_ce: 0.013888
 56%|█████████████████▌             | 226/400 [44:12<34:20, 11.84s/it]2022-01-20 21:39:43,311 iteration 3843 : loss : 0.022142, loss_ce: 0.009015
2022-01-20 21:39:43,991 iteration 3844 : loss : 0.037436, loss_ce: 0.012190
2022-01-20 21:39:44,663 iteration 3845 : loss : 0.021012, loss_ce: 0.009303
2022-01-20 21:39:45,262 iteration 3846 : loss : 0.015963, loss_ce: 0.005846
2022-01-20 21:39:45,879 iteration 3847 : loss : 0.023963, loss_ce: 0.008690
2022-01-20 21:39:46,558 iteration 3848 : loss : 0.017998, loss_ce: 0.008091
2022-01-20 21:39:47,295 iteration 3849 : loss : 0.019982, loss_ce: 0.008073
2022-01-20 21:39:48,020 iteration 3850 : loss : 0.039567, loss_ce: 0.009207
2022-01-20 21:39:48,679 iteration 3851 : loss : 0.020434, loss_ce: 0.010212
2022-01-20 21:39:49,346 iteration 3852 : loss : 0.020295, loss_ce: 0.006146
2022-01-20 21:39:49,945 iteration 3853 : loss : 0.022916, loss_ce: 0.007545
2022-01-20 21:39:50,618 iteration 3854 : loss : 0.023896, loss_ce: 0.007751
2022-01-20 21:39:51,398 iteration 3855 : loss : 0.019421, loss_ce: 0.007457
2022-01-20 21:39:51,912 iteration 3856 : loss : 0.018653, loss_ce: 0.008462
2022-01-20 21:39:52,529 iteration 3857 : loss : 0.026511, loss_ce: 0.011294
2022-01-20 21:39:53,071 iteration 3858 : loss : 0.020560, loss_ce: 0.007719
2022-01-20 21:39:53,690 iteration 3859 : loss : 0.018282, loss_ce: 0.007974
 57%|█████████████████▌             | 227/400 [44:23<33:26, 11.60s/it]2022-01-20 21:39:54,358 iteration 3860 : loss : 0.018576, loss_ce: 0.007321
2022-01-20 21:39:55,060 iteration 3861 : loss : 0.031014, loss_ce: 0.013816
2022-01-20 21:39:55,722 iteration 3862 : loss : 0.036389, loss_ce: 0.012320
2022-01-20 21:39:56,380 iteration 3863 : loss : 0.018391, loss_ce: 0.006509
2022-01-20 21:39:57,062 iteration 3864 : loss : 0.029019, loss_ce: 0.009931
2022-01-20 21:39:57,698 iteration 3865 : loss : 0.025008, loss_ce: 0.009137
2022-01-20 21:39:58,453 iteration 3866 : loss : 0.024426, loss_ce: 0.007221
2022-01-20 21:39:59,083 iteration 3867 : loss : 0.025440, loss_ce: 0.008555
2022-01-20 21:39:59,774 iteration 3868 : loss : 0.062009, loss_ce: 0.020377
2022-01-20 21:40:00,444 iteration 3869 : loss : 0.029068, loss_ce: 0.013840
2022-01-20 21:40:01,133 iteration 3870 : loss : 0.021111, loss_ce: 0.008539
2022-01-20 21:40:01,800 iteration 3871 : loss : 0.038306, loss_ce: 0.010349
2022-01-20 21:40:02,401 iteration 3872 : loss : 0.028424, loss_ce: 0.009873
2022-01-20 21:40:03,000 iteration 3873 : loss : 0.018222, loss_ce: 0.009335
2022-01-20 21:40:03,658 iteration 3874 : loss : 0.022084, loss_ce: 0.009002
2022-01-20 21:40:04,312 iteration 3875 : loss : 0.026908, loss_ce: 0.010579
2022-01-20 21:40:04,970 iteration 3876 : loss : 0.030286, loss_ce: 0.009537
 57%|█████████████████▋             | 228/400 [44:34<32:58, 11.50s/it]2022-01-20 21:40:05,622 iteration 3877 : loss : 0.022451, loss_ce: 0.008510
2022-01-20 21:40:06,296 iteration 3878 : loss : 0.030181, loss_ce: 0.010832
2022-01-20 21:40:06,913 iteration 3879 : loss : 0.019167, loss_ce: 0.006478
2022-01-20 21:40:07,593 iteration 3880 : loss : 0.030540, loss_ce: 0.014602
2022-01-20 21:40:08,210 iteration 3881 : loss : 0.025182, loss_ce: 0.010827
2022-01-20 21:40:08,941 iteration 3882 : loss : 0.064828, loss_ce: 0.011264
2022-01-20 21:40:09,635 iteration 3883 : loss : 0.041103, loss_ce: 0.016299
2022-01-20 21:40:10,295 iteration 3884 : loss : 0.028642, loss_ce: 0.012194
2022-01-20 21:40:10,975 iteration 3885 : loss : 0.067071, loss_ce: 0.012788
2022-01-20 21:40:11,659 iteration 3886 : loss : 0.041185, loss_ce: 0.014897
2022-01-20 21:40:12,248 iteration 3887 : loss : 0.026196, loss_ce: 0.009074
2022-01-20 21:40:12,930 iteration 3888 : loss : 0.033467, loss_ce: 0.017915
2022-01-20 21:40:13,582 iteration 3889 : loss : 0.023309, loss_ce: 0.008121
2022-01-20 21:40:14,345 iteration 3890 : loss : 0.039127, loss_ce: 0.014372
2022-01-20 21:40:14,966 iteration 3891 : loss : 0.036721, loss_ce: 0.013996
2022-01-20 21:40:15,612 iteration 3892 : loss : 0.039464, loss_ce: 0.017170
2022-01-20 21:40:16,286 iteration 3893 : loss : 0.047280, loss_ce: 0.015701
 57%|█████████████████▋             | 229/400 [44:45<32:37, 11.45s/it]2022-01-20 21:40:16,948 iteration 3894 : loss : 0.023382, loss_ce: 0.007771
2022-01-20 21:40:17,545 iteration 3895 : loss : 0.021796, loss_ce: 0.007699
2022-01-20 21:40:18,185 iteration 3896 : loss : 0.037628, loss_ce: 0.017034
2022-01-20 21:40:18,860 iteration 3897 : loss : 0.026884, loss_ce: 0.011373
2022-01-20 21:40:19,533 iteration 3898 : loss : 0.029676, loss_ce: 0.009547
2022-01-20 21:40:20,113 iteration 3899 : loss : 0.024170, loss_ce: 0.008983
2022-01-20 21:40:20,725 iteration 3900 : loss : 0.043657, loss_ce: 0.013828
2022-01-20 21:40:21,313 iteration 3901 : loss : 0.034923, loss_ce: 0.013438
2022-01-20 21:40:21,905 iteration 3902 : loss : 0.024924, loss_ce: 0.009542
2022-01-20 21:40:22,466 iteration 3903 : loss : 0.024748, loss_ce: 0.007427
2022-01-20 21:40:23,083 iteration 3904 : loss : 0.020998, loss_ce: 0.007014
2022-01-20 21:40:23,704 iteration 3905 : loss : 0.050688, loss_ce: 0.016712
2022-01-20 21:40:24,254 iteration 3906 : loss : 0.017150, loss_ce: 0.007198
2022-01-20 21:40:24,788 iteration 3907 : loss : 0.017609, loss_ce: 0.006473
2022-01-20 21:40:25,348 iteration 3908 : loss : 0.021617, loss_ce: 0.008950
2022-01-20 21:40:25,975 iteration 3909 : loss : 0.028101, loss_ce: 0.014309
2022-01-20 21:40:25,975 Training Data Eval:
2022-01-20 21:40:28,873   Average segmentation loss on training set: 0.0174
2022-01-20 21:40:28,874 Validation Data Eval:
2022-01-20 21:40:29,825   Average segmentation loss on validation set: 0.1214
2022-01-20 21:40:30,515 iteration 3910 : loss : 0.019708, loss_ce: 0.006566
 57%|█████████████████▊             | 230/400 [44:59<34:48, 12.28s/it]2022-01-20 21:40:31,139 iteration 3911 : loss : 0.019644, loss_ce: 0.008803
2022-01-20 21:40:31,806 iteration 3912 : loss : 0.026952, loss_ce: 0.009219
2022-01-20 21:40:32,436 iteration 3913 : loss : 0.022340, loss_ce: 0.008281
2022-01-20 21:40:33,060 iteration 3914 : loss : 0.017759, loss_ce: 0.008349
2022-01-20 21:40:33,682 iteration 3915 : loss : 0.023058, loss_ce: 0.009919
2022-01-20 21:40:34,276 iteration 3916 : loss : 0.020215, loss_ce: 0.006995
2022-01-20 21:40:34,947 iteration 3917 : loss : 0.027138, loss_ce: 0.010526
2022-01-20 21:40:35,611 iteration 3918 : loss : 0.036308, loss_ce: 0.010142
2022-01-20 21:40:36,371 iteration 3919 : loss : 0.047988, loss_ce: 0.013651
2022-01-20 21:40:36,964 iteration 3920 : loss : 0.018384, loss_ce: 0.007056
2022-01-20 21:40:37,586 iteration 3921 : loss : 0.042304, loss_ce: 0.016246
2022-01-20 21:40:38,254 iteration 3922 : loss : 0.026870, loss_ce: 0.009810
2022-01-20 21:40:38,865 iteration 3923 : loss : 0.018575, loss_ce: 0.008806
2022-01-20 21:40:39,446 iteration 3924 : loss : 0.030515, loss_ce: 0.008355
2022-01-20 21:40:40,151 iteration 3925 : loss : 0.031129, loss_ce: 0.009941
2022-01-20 21:40:40,833 iteration 3926 : loss : 0.027237, loss_ce: 0.010070
2022-01-20 21:40:41,469 iteration 3927 : loss : 0.032018, loss_ce: 0.014452
 58%|█████████████████▉             | 231/400 [45:10<33:28, 11.88s/it]2022-01-20 21:40:42,198 iteration 3928 : loss : 0.032183, loss_ce: 0.013984
2022-01-20 21:40:42,840 iteration 3929 : loss : 0.024686, loss_ce: 0.011547
2022-01-20 21:40:43,529 iteration 3930 : loss : 0.031041, loss_ce: 0.014476
2022-01-20 21:40:44,203 iteration 3931 : loss : 0.021502, loss_ce: 0.008070
2022-01-20 21:40:44,881 iteration 3932 : loss : 0.029723, loss_ce: 0.010226
2022-01-20 21:40:45,606 iteration 3933 : loss : 0.024214, loss_ce: 0.010119
2022-01-20 21:40:46,283 iteration 3934 : loss : 0.021615, loss_ce: 0.008568
2022-01-20 21:40:46,851 iteration 3935 : loss : 0.018813, loss_ce: 0.007956
2022-01-20 21:40:47,625 iteration 3936 : loss : 0.043667, loss_ce: 0.016826
2022-01-20 21:40:48,226 iteration 3937 : loss : 0.021454, loss_ce: 0.009721
2022-01-20 21:40:48,918 iteration 3938 : loss : 0.040418, loss_ce: 0.008785
2022-01-20 21:40:49,484 iteration 3939 : loss : 0.027204, loss_ce: 0.009195
2022-01-20 21:40:50,096 iteration 3940 : loss : 0.026567, loss_ce: 0.008811
2022-01-20 21:40:50,732 iteration 3941 : loss : 0.024058, loss_ce: 0.010074
2022-01-20 21:40:51,420 iteration 3942 : loss : 0.031199, loss_ce: 0.013111
2022-01-20 21:40:52,017 iteration 3943 : loss : 0.024665, loss_ce: 0.006258
2022-01-20 21:40:52,708 iteration 3944 : loss : 0.031490, loss_ce: 0.011139
 58%|█████████████████▉             | 232/400 [45:22<32:43, 11.69s/it]2022-01-20 21:40:53,401 iteration 3945 : loss : 0.028238, loss_ce: 0.014451
2022-01-20 21:40:53,944 iteration 3946 : loss : 0.017153, loss_ce: 0.008606
2022-01-20 21:40:54,564 iteration 3947 : loss : 0.018979, loss_ce: 0.005593
2022-01-20 21:40:55,325 iteration 3948 : loss : 0.024535, loss_ce: 0.008196
2022-01-20 21:40:56,000 iteration 3949 : loss : 0.026754, loss_ce: 0.010286
2022-01-20 21:40:56,702 iteration 3950 : loss : 0.025282, loss_ce: 0.007050
2022-01-20 21:40:57,276 iteration 3951 : loss : 0.019787, loss_ce: 0.008602
2022-01-20 21:40:57,951 iteration 3952 : loss : 0.017799, loss_ce: 0.006699
2022-01-20 21:40:58,653 iteration 3953 : loss : 0.031554, loss_ce: 0.010561
2022-01-20 21:40:59,279 iteration 3954 : loss : 0.018028, loss_ce: 0.005503
2022-01-20 21:40:59,900 iteration 3955 : loss : 0.013735, loss_ce: 0.004711
2022-01-20 21:41:00,659 iteration 3956 : loss : 0.026979, loss_ce: 0.010561
2022-01-20 21:41:01,268 iteration 3957 : loss : 0.027367, loss_ce: 0.012005
2022-01-20 21:41:01,887 iteration 3958 : loss : 0.023448, loss_ce: 0.008671
2022-01-20 21:41:02,613 iteration 3959 : loss : 0.024226, loss_ce: 0.007312
2022-01-20 21:41:03,226 iteration 3960 : loss : 0.021674, loss_ce: 0.009440
2022-01-20 21:41:03,859 iteration 3961 : loss : 0.016942, loss_ce: 0.006107
 58%|██████████████████             | 233/400 [45:33<32:04, 11.53s/it]2022-01-20 21:41:04,560 iteration 3962 : loss : 0.028546, loss_ce: 0.010651
2022-01-20 21:41:05,195 iteration 3963 : loss : 0.023867, loss_ce: 0.010099
2022-01-20 21:41:05,927 iteration 3964 : loss : 0.028408, loss_ce: 0.012118
2022-01-20 21:41:06,525 iteration 3965 : loss : 0.019895, loss_ce: 0.005681
2022-01-20 21:41:07,214 iteration 3966 : loss : 0.033159, loss_ce: 0.011797
2022-01-20 21:41:07,866 iteration 3967 : loss : 0.022499, loss_ce: 0.007849
2022-01-20 21:41:08,410 iteration 3968 : loss : 0.021896, loss_ce: 0.007284
2022-01-20 21:41:09,067 iteration 3969 : loss : 0.024345, loss_ce: 0.007990
2022-01-20 21:41:09,691 iteration 3970 : loss : 0.026172, loss_ce: 0.007930
2022-01-20 21:41:10,225 iteration 3971 : loss : 0.017583, loss_ce: 0.007024
2022-01-20 21:41:10,893 iteration 3972 : loss : 0.022636, loss_ce: 0.005921
2022-01-20 21:41:11,485 iteration 3973 : loss : 0.032454, loss_ce: 0.015869
2022-01-20 21:41:12,032 iteration 3974 : loss : 0.017492, loss_ce: 0.005197
2022-01-20 21:41:12,682 iteration 3975 : loss : 0.019042, loss_ce: 0.007219
2022-01-20 21:41:13,392 iteration 3976 : loss : 0.021921, loss_ce: 0.008450
2022-01-20 21:41:14,091 iteration 3977 : loss : 0.022921, loss_ce: 0.009651
2022-01-20 21:41:14,809 iteration 3978 : loss : 0.029574, loss_ce: 0.009937
 58%|██████████████████▏            | 234/400 [45:44<31:24, 11.35s/it]2022-01-20 21:41:15,483 iteration 3979 : loss : 0.021560, loss_ce: 0.007459
2022-01-20 21:41:16,156 iteration 3980 : loss : 0.024105, loss_ce: 0.007285
2022-01-20 21:41:16,778 iteration 3981 : loss : 0.019646, loss_ce: 0.007307
2022-01-20 21:41:17,311 iteration 3982 : loss : 0.015853, loss_ce: 0.005623
2022-01-20 21:41:17,865 iteration 3983 : loss : 0.017801, loss_ce: 0.008119
2022-01-20 21:41:18,459 iteration 3984 : loss : 0.018724, loss_ce: 0.007705
2022-01-20 21:41:19,111 iteration 3985 : loss : 0.036011, loss_ce: 0.020897
2022-01-20 21:41:19,836 iteration 3986 : loss : 0.026437, loss_ce: 0.011513
2022-01-20 21:41:20,508 iteration 3987 : loss : 0.029962, loss_ce: 0.011134
2022-01-20 21:41:21,149 iteration 3988 : loss : 0.020760, loss_ce: 0.009532
2022-01-20 21:41:21,769 iteration 3989 : loss : 0.019115, loss_ce: 0.003862
2022-01-20 21:41:22,381 iteration 3990 : loss : 0.031565, loss_ce: 0.010171
2022-01-20 21:41:23,074 iteration 3991 : loss : 0.028236, loss_ce: 0.006207
2022-01-20 21:41:23,723 iteration 3992 : loss : 0.022509, loss_ce: 0.006634
2022-01-20 21:41:24,405 iteration 3993 : loss : 0.030462, loss_ce: 0.009482
2022-01-20 21:41:25,015 iteration 3994 : loss : 0.017286, loss_ce: 0.007940
2022-01-20 21:41:25,016 Training Data Eval:
2022-01-20 21:41:27,916   Average segmentation loss on training set: 0.0136
2022-01-20 21:41:27,916 Validation Data Eval:
2022-01-20 21:41:28,872   Average segmentation loss on validation set: 0.0839
2022-01-20 21:41:29,451 iteration 3995 : loss : 0.019634, loss_ce: 0.007939
 59%|██████████████████▏            | 235/400 [45:58<33:56, 12.34s/it]2022-01-20 21:41:30,189 iteration 3996 : loss : 0.017056, loss_ce: 0.005014
2022-01-20 21:41:30,768 iteration 3997 : loss : 0.022999, loss_ce: 0.006357
2022-01-20 21:41:31,428 iteration 3998 : loss : 0.019009, loss_ce: 0.009053
2022-01-20 21:41:32,047 iteration 3999 : loss : 0.019895, loss_ce: 0.005113
2022-01-20 21:41:32,734 iteration 4000 : loss : 0.023978, loss_ce: 0.012009
2022-01-20 21:41:33,304 iteration 4001 : loss : 0.023084, loss_ce: 0.008473
2022-01-20 21:41:33,942 iteration 4002 : loss : 0.024570, loss_ce: 0.011268
2022-01-20 21:41:34,594 iteration 4003 : loss : 0.020952, loss_ce: 0.008766
2022-01-20 21:41:35,268 iteration 4004 : loss : 0.022246, loss_ce: 0.006094
2022-01-20 21:41:35,907 iteration 4005 : loss : 0.024573, loss_ce: 0.011296
2022-01-20 21:41:36,490 iteration 4006 : loss : 0.019292, loss_ce: 0.007649
2022-01-20 21:41:37,180 iteration 4007 : loss : 0.025613, loss_ce: 0.007110
2022-01-20 21:41:37,780 iteration 4008 : loss : 0.016395, loss_ce: 0.005630
2022-01-20 21:41:38,413 iteration 4009 : loss : 0.029761, loss_ce: 0.011044
2022-01-20 21:41:39,118 iteration 4010 : loss : 0.025429, loss_ce: 0.010422
2022-01-20 21:41:39,708 iteration 4011 : loss : 0.017789, loss_ce: 0.004800
2022-01-20 21:41:40,419 iteration 4012 : loss : 0.020835, loss_ce: 0.008908
 59%|██████████████████▎            | 236/400 [46:09<32:36, 11.93s/it]2022-01-20 21:41:41,169 iteration 4013 : loss : 0.023344, loss_ce: 0.006653
2022-01-20 21:41:41,750 iteration 4014 : loss : 0.019579, loss_ce: 0.006320
2022-01-20 21:41:42,433 iteration 4015 : loss : 0.025489, loss_ce: 0.011487
2022-01-20 21:41:43,115 iteration 4016 : loss : 0.023502, loss_ce: 0.009533
2022-01-20 21:41:43,811 iteration 4017 : loss : 0.025483, loss_ce: 0.008720
2022-01-20 21:41:44,408 iteration 4018 : loss : 0.020071, loss_ce: 0.006720
2022-01-20 21:41:45,032 iteration 4019 : loss : 0.025669, loss_ce: 0.012067
2022-01-20 21:41:45,613 iteration 4020 : loss : 0.022413, loss_ce: 0.015022
2022-01-20 21:41:46,215 iteration 4021 : loss : 0.019344, loss_ce: 0.007996
2022-01-20 21:41:46,871 iteration 4022 : loss : 0.020365, loss_ce: 0.009632
2022-01-20 21:41:47,501 iteration 4023 : loss : 0.016602, loss_ce: 0.005646
2022-01-20 21:41:48,069 iteration 4024 : loss : 0.022958, loss_ce: 0.006993
2022-01-20 21:41:48,659 iteration 4025 : loss : 0.022560, loss_ce: 0.007735
2022-01-20 21:41:49,317 iteration 4026 : loss : 0.018867, loss_ce: 0.007359
2022-01-20 21:41:49,971 iteration 4027 : loss : 0.025304, loss_ce: 0.008311
2022-01-20 21:41:50,662 iteration 4028 : loss : 0.031707, loss_ce: 0.010190
2022-01-20 21:41:51,260 iteration 4029 : loss : 0.015949, loss_ce: 0.006135
 59%|██████████████████▎            | 237/400 [46:20<31:31, 11.60s/it]2022-01-20 21:41:52,005 iteration 4030 : loss : 0.031971, loss_ce: 0.012773
2022-01-20 21:41:52,672 iteration 4031 : loss : 0.030737, loss_ce: 0.008592
2022-01-20 21:41:53,306 iteration 4032 : loss : 0.030477, loss_ce: 0.013870
2022-01-20 21:41:53,942 iteration 4033 : loss : 0.025203, loss_ce: 0.008527
2022-01-20 21:41:54,514 iteration 4034 : loss : 0.019566, loss_ce: 0.006655
2022-01-20 21:41:55,130 iteration 4035 : loss : 0.014689, loss_ce: 0.004415
2022-01-20 21:41:55,801 iteration 4036 : loss : 0.025220, loss_ce: 0.007899
2022-01-20 21:41:56,390 iteration 4037 : loss : 0.017273, loss_ce: 0.007997
2022-01-20 21:41:57,087 iteration 4038 : loss : 0.027978, loss_ce: 0.008741
2022-01-20 21:41:57,807 iteration 4039 : loss : 0.021666, loss_ce: 0.007984
2022-01-20 21:41:58,518 iteration 4040 : loss : 0.025066, loss_ce: 0.009387
2022-01-20 21:41:59,220 iteration 4041 : loss : 0.023825, loss_ce: 0.007608
2022-01-20 21:41:59,824 iteration 4042 : loss : 0.024846, loss_ce: 0.010007
2022-01-20 21:42:00,472 iteration 4043 : loss : 0.179756, loss_ce: 0.009233
2022-01-20 21:42:01,070 iteration 4044 : loss : 0.021736, loss_ce: 0.008998
2022-01-20 21:42:01,697 iteration 4045 : loss : 0.017073, loss_ce: 0.008166
2022-01-20 21:42:02,396 iteration 4046 : loss : 0.022815, loss_ce: 0.009853
 60%|██████████████████▍            | 238/400 [46:31<30:56, 11.46s/it]2022-01-20 21:42:03,166 iteration 4047 : loss : 0.020348, loss_ce: 0.008589
2022-01-20 21:42:03,849 iteration 4048 : loss : 0.026618, loss_ce: 0.011264
2022-01-20 21:42:04,455 iteration 4049 : loss : 0.019113, loss_ce: 0.006746
2022-01-20 21:42:05,123 iteration 4050 : loss : 0.022455, loss_ce: 0.008609
2022-01-20 21:42:05,863 iteration 4051 : loss : 0.035615, loss_ce: 0.005320
2022-01-20 21:42:06,438 iteration 4052 : loss : 0.020011, loss_ce: 0.007529
2022-01-20 21:42:06,986 iteration 4053 : loss : 0.017387, loss_ce: 0.005666
2022-01-20 21:42:07,569 iteration 4054 : loss : 0.037087, loss_ce: 0.009810
2022-01-20 21:42:08,185 iteration 4055 : loss : 0.020955, loss_ce: 0.009965
2022-01-20 21:42:08,834 iteration 4056 : loss : 0.028946, loss_ce: 0.013546
2022-01-20 21:42:09,422 iteration 4057 : loss : 0.018472, loss_ce: 0.004415
2022-01-20 21:42:10,039 iteration 4058 : loss : 0.015059, loss_ce: 0.005482
2022-01-20 21:42:10,780 iteration 4059 : loss : 0.025682, loss_ce: 0.010768
2022-01-20 21:42:11,434 iteration 4060 : loss : 0.023596, loss_ce: 0.009833
2022-01-20 21:42:12,074 iteration 4061 : loss : 0.021507, loss_ce: 0.009024
2022-01-20 21:42:12,742 iteration 4062 : loss : 0.028182, loss_ce: 0.009381
2022-01-20 21:42:13,396 iteration 4063 : loss : 0.030413, loss_ce: 0.008125
 60%|██████████████████▌            | 239/400 [46:42<30:22, 11.32s/it]2022-01-20 21:42:14,046 iteration 4064 : loss : 0.025725, loss_ce: 0.005321
2022-01-20 21:42:14,653 iteration 4065 : loss : 0.018406, loss_ce: 0.005930
2022-01-20 21:42:15,351 iteration 4066 : loss : 0.030686, loss_ce: 0.012385
2022-01-20 21:42:15,952 iteration 4067 : loss : 0.017715, loss_ce: 0.007049
2022-01-20 21:42:16,580 iteration 4068 : loss : 0.022786, loss_ce: 0.008588
2022-01-20 21:42:17,237 iteration 4069 : loss : 0.026872, loss_ce: 0.010433
2022-01-20 21:42:17,896 iteration 4070 : loss : 0.029623, loss_ce: 0.010553
2022-01-20 21:42:18,603 iteration 4071 : loss : 0.028438, loss_ce: 0.009351
2022-01-20 21:42:19,240 iteration 4072 : loss : 0.017572, loss_ce: 0.005427
2022-01-20 21:42:19,842 iteration 4073 : loss : 0.016241, loss_ce: 0.005581
2022-01-20 21:42:20,483 iteration 4074 : loss : 0.020057, loss_ce: 0.008864
2022-01-20 21:42:21,164 iteration 4075 : loss : 0.019142, loss_ce: 0.006454
2022-01-20 21:42:21,757 iteration 4076 : loss : 0.023579, loss_ce: 0.008656
2022-01-20 21:42:22,382 iteration 4077 : loss : 0.017649, loss_ce: 0.005774
2022-01-20 21:42:23,064 iteration 4078 : loss : 0.022178, loss_ce: 0.008550
2022-01-20 21:42:23,730 iteration 4079 : loss : 0.024846, loss_ce: 0.011557
2022-01-20 21:42:23,730 Training Data Eval:
2022-01-20 21:42:26,624   Average segmentation loss on training set: 0.0137
2022-01-20 21:42:26,624 Validation Data Eval:
2022-01-20 21:42:27,575   Average segmentation loss on validation set: 0.0834
2022-01-20 21:42:28,256 iteration 4080 : loss : 0.023880, loss_ce: 0.010073
 60%|██████████████████▌            | 240/400 [46:57<33:01, 12.39s/it]2022-01-20 21:42:28,955 iteration 4081 : loss : 0.037704, loss_ce: 0.015139
2022-01-20 21:42:29,600 iteration 4082 : loss : 0.017635, loss_ce: 0.006340
2022-01-20 21:42:30,189 iteration 4083 : loss : 0.014642, loss_ce: 0.005833
2022-01-20 21:42:30,828 iteration 4084 : loss : 0.018628, loss_ce: 0.005388
2022-01-20 21:42:31,415 iteration 4085 : loss : 0.023898, loss_ce: 0.007347
2022-01-20 21:42:32,180 iteration 4086 : loss : 0.026397, loss_ce: 0.009302
2022-01-20 21:42:32,844 iteration 4087 : loss : 0.016549, loss_ce: 0.004761
2022-01-20 21:42:33,418 iteration 4088 : loss : 0.016523, loss_ce: 0.007623
2022-01-20 21:42:34,052 iteration 4089 : loss : 0.021642, loss_ce: 0.007244
2022-01-20 21:42:34,595 iteration 4090 : loss : 0.021586, loss_ce: 0.007032
2022-01-20 21:42:35,223 iteration 4091 : loss : 0.029696, loss_ce: 0.011622
2022-01-20 21:42:35,867 iteration 4092 : loss : 0.020543, loss_ce: 0.007460
2022-01-20 21:42:36,508 iteration 4093 : loss : 0.026453, loss_ce: 0.009552
2022-01-20 21:42:37,111 iteration 4094 : loss : 0.019928, loss_ce: 0.007510
2022-01-20 21:42:37,756 iteration 4095 : loss : 0.022380, loss_ce: 0.010095
2022-01-20 21:42:38,353 iteration 4096 : loss : 0.018482, loss_ce: 0.010435
2022-01-20 21:42:38,966 iteration 4097 : loss : 0.019278, loss_ce: 0.006935
 60%|██████████████████▋            | 241/400 [47:08<31:29, 11.88s/it]2022-01-20 21:42:39,615 iteration 4098 : loss : 0.018002, loss_ce: 0.006773
2022-01-20 21:42:40,211 iteration 4099 : loss : 0.020556, loss_ce: 0.005766
2022-01-20 21:42:40,847 iteration 4100 : loss : 0.018268, loss_ce: 0.005835
2022-01-20 21:42:41,532 iteration 4101 : loss : 0.022377, loss_ce: 0.007892
2022-01-20 21:42:42,214 iteration 4102 : loss : 0.029536, loss_ce: 0.012325
2022-01-20 21:42:42,879 iteration 4103 : loss : 0.022832, loss_ce: 0.009891
2022-01-20 21:42:43,525 iteration 4104 : loss : 0.019850, loss_ce: 0.008393
2022-01-20 21:42:44,181 iteration 4105 : loss : 0.023964, loss_ce: 0.009544
2022-01-20 21:42:44,801 iteration 4106 : loss : 0.022166, loss_ce: 0.008237
2022-01-20 21:42:45,415 iteration 4107 : loss : 0.017051, loss_ce: 0.007861
2022-01-20 21:42:46,044 iteration 4108 : loss : 0.017865, loss_ce: 0.006858
2022-01-20 21:42:46,618 iteration 4109 : loss : 0.016197, loss_ce: 0.005543
2022-01-20 21:42:47,281 iteration 4110 : loss : 0.022552, loss_ce: 0.011264
2022-01-20 21:42:48,060 iteration 4111 : loss : 0.034727, loss_ce: 0.017935
2022-01-20 21:42:48,662 iteration 4112 : loss : 0.018903, loss_ce: 0.006315
2022-01-20 21:42:49,338 iteration 4113 : loss : 0.031086, loss_ce: 0.009874
2022-01-20 21:42:49,968 iteration 4114 : loss : 0.019833, loss_ce: 0.009252
 60%|██████████████████▊            | 242/400 [47:19<30:35, 11.62s/it]2022-01-20 21:42:50,602 iteration 4115 : loss : 0.018039, loss_ce: 0.008677
2022-01-20 21:42:51,298 iteration 4116 : loss : 0.019138, loss_ce: 0.005977
2022-01-20 21:42:51,882 iteration 4117 : loss : 0.014678, loss_ce: 0.005333
2022-01-20 21:42:52,582 iteration 4118 : loss : 0.022448, loss_ce: 0.009975
2022-01-20 21:42:53,343 iteration 4119 : loss : 0.027262, loss_ce: 0.007499
2022-01-20 21:42:54,009 iteration 4120 : loss : 0.029484, loss_ce: 0.007165
2022-01-20 21:42:54,615 iteration 4121 : loss : 0.019069, loss_ce: 0.006215
2022-01-20 21:42:55,247 iteration 4122 : loss : 0.020027, loss_ce: 0.006116
2022-01-20 21:42:55,829 iteration 4123 : loss : 0.012642, loss_ce: 0.005047
2022-01-20 21:42:56,506 iteration 4124 : loss : 0.022019, loss_ce: 0.010049
2022-01-20 21:42:57,166 iteration 4125 : loss : 0.024623, loss_ce: 0.010437
2022-01-20 21:42:57,812 iteration 4126 : loss : 0.021628, loss_ce: 0.008548
2022-01-20 21:42:58,406 iteration 4127 : loss : 0.016709, loss_ce: 0.007823
2022-01-20 21:42:59,147 iteration 4128 : loss : 0.039288, loss_ce: 0.011899
2022-01-20 21:42:59,722 iteration 4129 : loss : 0.021052, loss_ce: 0.004826
2022-01-20 21:43:00,284 iteration 4130 : loss : 0.017531, loss_ce: 0.005593
2022-01-20 21:43:00,894 iteration 4131 : loss : 0.015197, loss_ce: 0.006376
 61%|██████████████████▊            | 243/400 [47:30<29:51, 11.41s/it]2022-01-20 21:43:01,645 iteration 4132 : loss : 0.023314, loss_ce: 0.006912
2022-01-20 21:43:02,296 iteration 4133 : loss : 0.018938, loss_ce: 0.005675
2022-01-20 21:43:02,960 iteration 4134 : loss : 0.031305, loss_ce: 0.012697
2022-01-20 21:43:03,518 iteration 4135 : loss : 0.021254, loss_ce: 0.009201
2022-01-20 21:43:04,145 iteration 4136 : loss : 0.026205, loss_ce: 0.011582
2022-01-20 21:43:04,709 iteration 4137 : loss : 0.013980, loss_ce: 0.005182
2022-01-20 21:43:05,367 iteration 4138 : loss : 0.018713, loss_ce: 0.008084
2022-01-20 21:43:06,032 iteration 4139 : loss : 0.016374, loss_ce: 0.006491
2022-01-20 21:43:06,682 iteration 4140 : loss : 0.017015, loss_ce: 0.007159
2022-01-20 21:43:07,341 iteration 4141 : loss : 0.024716, loss_ce: 0.008301
2022-01-20 21:43:08,050 iteration 4142 : loss : 0.033057, loss_ce: 0.011480
2022-01-20 21:43:08,593 iteration 4143 : loss : 0.025065, loss_ce: 0.007473
2022-01-20 21:43:09,161 iteration 4144 : loss : 0.017945, loss_ce: 0.003989
2022-01-20 21:43:09,844 iteration 4145 : loss : 0.024283, loss_ce: 0.009599
2022-01-20 21:43:10,448 iteration 4146 : loss : 0.019858, loss_ce: 0.010253
2022-01-20 21:43:11,102 iteration 4147 : loss : 0.020428, loss_ce: 0.007503
2022-01-20 21:43:11,710 iteration 4148 : loss : 0.025881, loss_ce: 0.009436
 61%|██████████████████▉            | 244/400 [47:41<29:12, 11.23s/it]2022-01-20 21:43:12,303 iteration 4149 : loss : 0.021100, loss_ce: 0.007322
2022-01-20 21:43:12,956 iteration 4150 : loss : 0.018004, loss_ce: 0.005562
2022-01-20 21:43:13,644 iteration 4151 : loss : 0.030732, loss_ce: 0.011033
2022-01-20 21:43:14,292 iteration 4152 : loss : 0.019620, loss_ce: 0.007074
2022-01-20 21:43:14,856 iteration 4153 : loss : 0.017717, loss_ce: 0.007127
2022-01-20 21:43:15,500 iteration 4154 : loss : 0.020517, loss_ce: 0.005872
2022-01-20 21:43:16,117 iteration 4155 : loss : 0.024693, loss_ce: 0.007803
2022-01-20 21:43:16,686 iteration 4156 : loss : 0.015976, loss_ce: 0.005766
2022-01-20 21:43:17,366 iteration 4157 : loss : 0.023123, loss_ce: 0.011867
2022-01-20 21:43:17,960 iteration 4158 : loss : 0.027486, loss_ce: 0.010299
2022-01-20 21:43:18,574 iteration 4159 : loss : 0.014750, loss_ce: 0.006255
2022-01-20 21:43:19,308 iteration 4160 : loss : 0.033715, loss_ce: 0.013498
2022-01-20 21:43:20,018 iteration 4161 : loss : 0.029520, loss_ce: 0.010149
2022-01-20 21:43:20,738 iteration 4162 : loss : 0.024222, loss_ce: 0.008922
2022-01-20 21:43:21,443 iteration 4163 : loss : 0.025323, loss_ce: 0.012263
2022-01-20 21:43:22,094 iteration 4164 : loss : 0.023691, loss_ce: 0.009384
2022-01-20 21:43:22,094 Training Data Eval:
2022-01-20 21:43:24,993   Average segmentation loss on training set: 0.0141
2022-01-20 21:43:24,994 Validation Data Eval:
2022-01-20 21:43:25,947   Average segmentation loss on validation set: 0.0711
2022-01-20 21:43:26,502 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:43:27,170 iteration 4165 : loss : 0.024948, loss_ce: 0.007758
 61%|██████████████████▉            | 245/400 [47:56<32:17, 12.50s/it]2022-01-20 21:43:27,836 iteration 4166 : loss : 0.019690, loss_ce: 0.008222
2022-01-20 21:43:28,393 iteration 4167 : loss : 0.020095, loss_ce: 0.006332
2022-01-20 21:43:28,977 iteration 4168 : loss : 0.013872, loss_ce: 0.005583
2022-01-20 21:43:29,563 iteration 4169 : loss : 0.016189, loss_ce: 0.007674
2022-01-20 21:43:30,300 iteration 4170 : loss : 0.025618, loss_ce: 0.012363
2022-01-20 21:43:30,860 iteration 4171 : loss : 0.020039, loss_ce: 0.005672
2022-01-20 21:43:31,479 iteration 4172 : loss : 0.018182, loss_ce: 0.008473
2022-01-20 21:43:32,138 iteration 4173 : loss : 0.019630, loss_ce: 0.005600
2022-01-20 21:43:32,744 iteration 4174 : loss : 0.019041, loss_ce: 0.005482
2022-01-20 21:43:33,323 iteration 4175 : loss : 0.015970, loss_ce: 0.006130
2022-01-20 21:43:33,933 iteration 4176 : loss : 0.020328, loss_ce: 0.008649
2022-01-20 21:43:34,603 iteration 4177 : loss : 0.016745, loss_ce: 0.004654
2022-01-20 21:43:35,184 iteration 4178 : loss : 0.019105, loss_ce: 0.007456
2022-01-20 21:43:35,791 iteration 4179 : loss : 0.018550, loss_ce: 0.008945
2022-01-20 21:43:36,387 iteration 4180 : loss : 0.017687, loss_ce: 0.005473
2022-01-20 21:43:37,004 iteration 4181 : loss : 0.019046, loss_ce: 0.007600
2022-01-20 21:43:37,627 iteration 4182 : loss : 0.016922, loss_ce: 0.004561
 62%|███████████████████            | 246/400 [48:07<30:30, 11.89s/it]2022-01-20 21:43:38,312 iteration 4183 : loss : 0.019290, loss_ce: 0.005925
2022-01-20 21:43:38,990 iteration 4184 : loss : 0.022083, loss_ce: 0.009685
2022-01-20 21:43:39,627 iteration 4185 : loss : 0.018584, loss_ce: 0.008515
2022-01-20 21:43:40,243 iteration 4186 : loss : 0.021817, loss_ce: 0.006468
2022-01-20 21:43:40,923 iteration 4187 : loss : 0.028815, loss_ce: 0.009325
2022-01-20 21:43:41,518 iteration 4188 : loss : 0.020795, loss_ce: 0.006767
2022-01-20 21:43:42,258 iteration 4189 : loss : 0.022197, loss_ce: 0.009362
2022-01-20 21:43:42,945 iteration 4190 : loss : 0.027687, loss_ce: 0.011519
2022-01-20 21:43:43,645 iteration 4191 : loss : 0.029311, loss_ce: 0.012348
2022-01-20 21:43:44,187 iteration 4192 : loss : 0.019166, loss_ce: 0.005789
2022-01-20 21:43:44,834 iteration 4193 : loss : 0.023946, loss_ce: 0.011401
2022-01-20 21:43:45,514 iteration 4194 : loss : 0.018585, loss_ce: 0.006440
2022-01-20 21:43:46,139 iteration 4195 : loss : 0.024913, loss_ce: 0.006730
2022-01-20 21:43:46,809 iteration 4196 : loss : 0.017776, loss_ce: 0.007839
2022-01-20 21:43:47,435 iteration 4197 : loss : 0.023343, loss_ce: 0.006467
2022-01-20 21:43:48,061 iteration 4198 : loss : 0.020258, loss_ce: 0.007427
2022-01-20 21:43:48,633 iteration 4199 : loss : 0.015980, loss_ce: 0.006447
 62%|███████████████████▏           | 247/400 [48:18<29:38, 11.62s/it]2022-01-20 21:43:49,299 iteration 4200 : loss : 0.019261, loss_ce: 0.006851
2022-01-20 21:43:49,957 iteration 4201 : loss : 0.023458, loss_ce: 0.009610
2022-01-20 21:43:50,613 iteration 4202 : loss : 0.017686, loss_ce: 0.007255
2022-01-20 21:43:51,345 iteration 4203 : loss : 0.021357, loss_ce: 0.009042
2022-01-20 21:43:51,966 iteration 4204 : loss : 0.016647, loss_ce: 0.006564
2022-01-20 21:43:52,594 iteration 4205 : loss : 0.019618, loss_ce: 0.008244
2022-01-20 21:43:53,358 iteration 4206 : loss : 0.024913, loss_ce: 0.008581
2022-01-20 21:43:54,036 iteration 4207 : loss : 0.021932, loss_ce: 0.008839
2022-01-20 21:43:54,584 iteration 4208 : loss : 0.013384, loss_ce: 0.004994
2022-01-20 21:43:55,190 iteration 4209 : loss : 0.022869, loss_ce: 0.009399
2022-01-20 21:43:55,797 iteration 4210 : loss : 0.018925, loss_ce: 0.007186
2022-01-20 21:43:56,451 iteration 4211 : loss : 0.019399, loss_ce: 0.008083
2022-01-20 21:43:57,138 iteration 4212 : loss : 0.021870, loss_ce: 0.007731
2022-01-20 21:43:57,739 iteration 4213 : loss : 0.018134, loss_ce: 0.004946
2022-01-20 21:43:58,412 iteration 4214 : loss : 0.024841, loss_ce: 0.008353
2022-01-20 21:43:59,038 iteration 4215 : loss : 0.020528, loss_ce: 0.007337
2022-01-20 21:43:59,656 iteration 4216 : loss : 0.018218, loss_ce: 0.005435
 62%|███████████████████▏           | 248/400 [48:29<28:59, 11.44s/it]2022-01-20 21:44:00,365 iteration 4217 : loss : 0.021819, loss_ce: 0.007648
2022-01-20 21:44:00,982 iteration 4218 : loss : 0.018916, loss_ce: 0.006098
2022-01-20 21:44:01,582 iteration 4219 : loss : 0.018978, loss_ce: 0.007764
2022-01-20 21:44:02,122 iteration 4220 : loss : 0.029255, loss_ce: 0.006782
2022-01-20 21:44:02,849 iteration 4221 : loss : 0.020475, loss_ce: 0.010075
2022-01-20 21:44:03,571 iteration 4222 : loss : 0.025377, loss_ce: 0.008352
2022-01-20 21:44:04,184 iteration 4223 : loss : 0.016527, loss_ce: 0.005674
2022-01-20 21:44:04,877 iteration 4224 : loss : 0.035689, loss_ce: 0.009555
2022-01-20 21:44:05,531 iteration 4225 : loss : 0.026609, loss_ce: 0.008203
2022-01-20 21:44:06,210 iteration 4226 : loss : 0.018208, loss_ce: 0.008179
2022-01-20 21:44:06,876 iteration 4227 : loss : 0.018632, loss_ce: 0.008127
2022-01-20 21:44:07,466 iteration 4228 : loss : 0.022993, loss_ce: 0.011348
2022-01-20 21:44:08,089 iteration 4229 : loss : 0.021676, loss_ce: 0.007890
2022-01-20 21:44:08,710 iteration 4230 : loss : 0.023621, loss_ce: 0.012445
2022-01-20 21:44:09,395 iteration 4231 : loss : 0.024627, loss_ce: 0.009728
2022-01-20 21:44:10,074 iteration 4232 : loss : 0.019237, loss_ce: 0.006295
2022-01-20 21:44:10,704 iteration 4233 : loss : 0.020952, loss_ce: 0.009996
 62%|███████████████████▎           | 249/400 [48:40<28:30, 11.32s/it]2022-01-20 21:44:11,290 iteration 4234 : loss : 0.022598, loss_ce: 0.005303
2022-01-20 21:44:11,853 iteration 4235 : loss : 0.013127, loss_ce: 0.004753
2022-01-20 21:44:12,508 iteration 4236 : loss : 0.018240, loss_ce: 0.006203
2022-01-20 21:44:13,094 iteration 4237 : loss : 0.017717, loss_ce: 0.007044
2022-01-20 21:44:13,713 iteration 4238 : loss : 0.026038, loss_ce: 0.012481
2022-01-20 21:44:14,481 iteration 4239 : loss : 0.035960, loss_ce: 0.016127
2022-01-20 21:44:15,140 iteration 4240 : loss : 0.016990, loss_ce: 0.004941
2022-01-20 21:44:15,690 iteration 4241 : loss : 0.015797, loss_ce: 0.007136
2022-01-20 21:44:16,327 iteration 4242 : loss : 0.020081, loss_ce: 0.006036
2022-01-20 21:44:16,938 iteration 4243 : loss : 0.018448, loss_ce: 0.006858
2022-01-20 21:44:17,493 iteration 4244 : loss : 0.014054, loss_ce: 0.006315
2022-01-20 21:44:18,172 iteration 4245 : loss : 0.023832, loss_ce: 0.009746
2022-01-20 21:44:18,892 iteration 4246 : loss : 0.019030, loss_ce: 0.004427
2022-01-20 21:44:19,565 iteration 4247 : loss : 0.018127, loss_ce: 0.007397
2022-01-20 21:44:20,141 iteration 4248 : loss : 0.025841, loss_ce: 0.011221
2022-01-20 21:44:20,835 iteration 4249 : loss : 0.026206, loss_ce: 0.007834
2022-01-20 21:44:20,836 Training Data Eval:
2022-01-20 21:44:23,737   Average segmentation loss on training set: 0.0126
2022-01-20 21:44:23,738 Validation Data Eval:
2022-01-20 21:44:24,688   Average segmentation loss on validation set: 0.0976
2022-01-20 21:44:25,312 iteration 4250 : loss : 0.025054, loss_ce: 0.009391
 62%|███████████████████▍           | 250/400 [48:54<30:46, 12.31s/it]2022-01-20 21:44:26,047 iteration 4251 : loss : 0.029499, loss_ce: 0.008183
2022-01-20 21:44:26,723 iteration 4252 : loss : 0.020786, loss_ce: 0.009633
2022-01-20 21:44:27,356 iteration 4253 : loss : 0.023550, loss_ce: 0.008330
2022-01-20 21:44:28,037 iteration 4254 : loss : 0.014461, loss_ce: 0.005375
2022-01-20 21:44:28,731 iteration 4255 : loss : 0.020093, loss_ce: 0.007456
2022-01-20 21:44:29,279 iteration 4256 : loss : 0.019120, loss_ce: 0.008014
2022-01-20 21:44:29,912 iteration 4257 : loss : 0.022538, loss_ce: 0.008325
2022-01-20 21:44:30,481 iteration 4258 : loss : 0.026553, loss_ce: 0.008293
2022-01-20 21:44:31,140 iteration 4259 : loss : 0.022974, loss_ce: 0.010436
2022-01-20 21:44:31,796 iteration 4260 : loss : 0.019921, loss_ce: 0.007003
2022-01-20 21:44:32,451 iteration 4261 : loss : 0.024764, loss_ce: 0.010603
2022-01-20 21:44:33,042 iteration 4262 : loss : 0.017909, loss_ce: 0.007582
2022-01-20 21:44:33,697 iteration 4263 : loss : 0.018432, loss_ce: 0.008082
2022-01-20 21:44:34,384 iteration 4264 : loss : 0.024587, loss_ce: 0.010323
2022-01-20 21:44:35,011 iteration 4265 : loss : 0.020410, loss_ce: 0.005212
2022-01-20 21:44:35,671 iteration 4266 : loss : 0.018668, loss_ce: 0.005771
2022-01-20 21:44:36,351 iteration 4267 : loss : 0.018195, loss_ce: 0.006452
 63%|███████████████████▍           | 251/400 [49:05<29:37, 11.93s/it]2022-01-20 21:44:37,028 iteration 4268 : loss : 0.020635, loss_ce: 0.004815
2022-01-20 21:44:37,651 iteration 4269 : loss : 0.028793, loss_ce: 0.009442
2022-01-20 21:44:38,250 iteration 4270 : loss : 0.017655, loss_ce: 0.008935
2022-01-20 21:44:38,807 iteration 4271 : loss : 0.016355, loss_ce: 0.006105
2022-01-20 21:44:39,427 iteration 4272 : loss : 0.017049, loss_ce: 0.008146
2022-01-20 21:44:39,994 iteration 4273 : loss : 0.014046, loss_ce: 0.005867
2022-01-20 21:44:40,720 iteration 4274 : loss : 0.019671, loss_ce: 0.009942
2022-01-20 21:44:41,337 iteration 4275 : loss : 0.016326, loss_ce: 0.005535
2022-01-20 21:44:42,024 iteration 4276 : loss : 0.021842, loss_ce: 0.006487
2022-01-20 21:44:42,714 iteration 4277 : loss : 0.022735, loss_ce: 0.006454
2022-01-20 21:44:43,396 iteration 4278 : loss : 0.037879, loss_ce: 0.010900
2022-01-20 21:44:44,012 iteration 4279 : loss : 0.020416, loss_ce: 0.010023
2022-01-20 21:44:44,655 iteration 4280 : loss : 0.020695, loss_ce: 0.006998
2022-01-20 21:44:45,296 iteration 4281 : loss : 0.022100, loss_ce: 0.006578
2022-01-20 21:44:45,864 iteration 4282 : loss : 0.022255, loss_ce: 0.008976
2022-01-20 21:44:46,483 iteration 4283 : loss : 0.022490, loss_ce: 0.006220
2022-01-20 21:44:47,077 iteration 4284 : loss : 0.024353, loss_ce: 0.011362
 63%|███████████████████▌           | 252/400 [49:16<28:31, 11.57s/it]2022-01-20 21:44:47,686 iteration 4285 : loss : 0.020357, loss_ce: 0.006080
2022-01-20 21:44:48,358 iteration 4286 : loss : 0.019816, loss_ce: 0.007482
2022-01-20 21:44:48,944 iteration 4287 : loss : 0.019662, loss_ce: 0.008835
2022-01-20 21:44:49,530 iteration 4288 : loss : 0.018725, loss_ce: 0.008774
2022-01-20 21:44:50,165 iteration 4289 : loss : 0.018003, loss_ce: 0.006802
2022-01-20 21:44:50,780 iteration 4290 : loss : 0.024424, loss_ce: 0.005743
2022-01-20 21:44:51,435 iteration 4291 : loss : 0.018985, loss_ce: 0.006472
2022-01-20 21:44:52,089 iteration 4292 : loss : 0.024591, loss_ce: 0.010870
2022-01-20 21:44:52,731 iteration 4293 : loss : 0.025281, loss_ce: 0.008366
2022-01-20 21:44:53,338 iteration 4294 : loss : 0.020788, loss_ce: 0.004907
2022-01-20 21:44:54,083 iteration 4295 : loss : 0.020553, loss_ce: 0.006895
2022-01-20 21:44:54,728 iteration 4296 : loss : 0.015749, loss_ce: 0.005202
2022-01-20 21:44:55,392 iteration 4297 : loss : 0.020469, loss_ce: 0.008457
2022-01-20 21:44:55,996 iteration 4298 : loss : 0.015122, loss_ce: 0.006738
2022-01-20 21:44:56,680 iteration 4299 : loss : 0.021344, loss_ce: 0.008818
2022-01-20 21:44:57,392 iteration 4300 : loss : 0.026655, loss_ce: 0.010750
2022-01-20 21:44:58,097 iteration 4301 : loss : 0.018713, loss_ce: 0.008243
 63%|███████████████████▌           | 253/400 [49:27<27:56, 11.41s/it]2022-01-20 21:44:58,815 iteration 4302 : loss : 0.027071, loss_ce: 0.010414
2022-01-20 21:44:59,525 iteration 4303 : loss : 0.034634, loss_ce: 0.007154
2022-01-20 21:45:00,130 iteration 4304 : loss : 0.022431, loss_ce: 0.008630
2022-01-20 21:45:00,744 iteration 4305 : loss : 0.032658, loss_ce: 0.010449
2022-01-20 21:45:01,362 iteration 4306 : loss : 0.015554, loss_ce: 0.004669
2022-01-20 21:45:01,944 iteration 4307 : loss : 0.018970, loss_ce: 0.008871
2022-01-20 21:45:02,615 iteration 4308 : loss : 0.022663, loss_ce: 0.008228
2022-01-20 21:45:03,323 iteration 4309 : loss : 0.025574, loss_ce: 0.009060
2022-01-20 21:45:03,976 iteration 4310 : loss : 0.015343, loss_ce: 0.006369
2022-01-20 21:45:04,573 iteration 4311 : loss : 0.019522, loss_ce: 0.007201
2022-01-20 21:45:05,152 iteration 4312 : loss : 0.025368, loss_ce: 0.009327
2022-01-20 21:45:05,747 iteration 4313 : loss : 0.017806, loss_ce: 0.008752
2022-01-20 21:45:06,350 iteration 4314 : loss : 0.019079, loss_ce: 0.006667
2022-01-20 21:45:07,015 iteration 4315 : loss : 0.018786, loss_ce: 0.006425
2022-01-20 21:45:07,615 iteration 4316 : loss : 0.026472, loss_ce: 0.007955
2022-01-20 21:45:08,310 iteration 4317 : loss : 0.019846, loss_ce: 0.007687
2022-01-20 21:45:08,889 iteration 4318 : loss : 0.019949, loss_ce: 0.007821
 64%|███████████████████▋           | 254/400 [49:38<27:17, 11.22s/it]2022-01-20 21:45:09,603 iteration 4319 : loss : 0.021874, loss_ce: 0.007735
2022-01-20 21:45:10,269 iteration 4320 : loss : 0.024704, loss_ce: 0.009967
2022-01-20 21:45:10,805 iteration 4321 : loss : 0.016752, loss_ce: 0.005153
2022-01-20 21:45:11,435 iteration 4322 : loss : 0.015865, loss_ce: 0.005386
2022-01-20 21:45:12,008 iteration 4323 : loss : 0.018192, loss_ce: 0.008564
2022-01-20 21:45:12,744 iteration 4324 : loss : 0.024455, loss_ce: 0.011076
2022-01-20 21:45:13,382 iteration 4325 : loss : 0.020504, loss_ce: 0.008464
2022-01-20 21:45:13,991 iteration 4326 : loss : 0.020608, loss_ce: 0.009554
2022-01-20 21:45:14,656 iteration 4327 : loss : 0.021099, loss_ce: 0.007111
2022-01-20 21:45:15,253 iteration 4328 : loss : 0.018956, loss_ce: 0.006205
2022-01-20 21:45:15,955 iteration 4329 : loss : 0.052526, loss_ce: 0.009890
2022-01-20 21:45:16,632 iteration 4330 : loss : 0.021217, loss_ce: 0.008890
2022-01-20 21:45:17,351 iteration 4331 : loss : 0.033678, loss_ce: 0.007353
2022-01-20 21:45:18,033 iteration 4332 : loss : 0.032696, loss_ce: 0.010449
2022-01-20 21:45:18,752 iteration 4333 : loss : 0.034237, loss_ce: 0.014387
2022-01-20 21:45:19,402 iteration 4334 : loss : 0.020077, loss_ce: 0.009786
2022-01-20 21:45:19,402 Training Data Eval:
2022-01-20 21:45:22,304   Average segmentation loss on training set: 0.0138
2022-01-20 21:45:22,305 Validation Data Eval:
2022-01-20 21:45:23,255   Average segmentation loss on validation set: 0.1017
2022-01-20 21:45:23,929 iteration 4335 : loss : 0.031453, loss_ce: 0.007692
 64%|███████████████████▊           | 255/400 [49:53<29:52, 12.36s/it]2022-01-20 21:45:24,491 iteration 4336 : loss : 0.014220, loss_ce: 0.006995
2022-01-20 21:45:25,199 iteration 4337 : loss : 0.029544, loss_ce: 0.012634
2022-01-20 21:45:25,827 iteration 4338 : loss : 0.020977, loss_ce: 0.006393
2022-01-20 21:45:26,410 iteration 4339 : loss : 0.018788, loss_ce: 0.006329
2022-01-20 21:45:27,074 iteration 4340 : loss : 0.022627, loss_ce: 0.009756
2022-01-20 21:45:27,650 iteration 4341 : loss : 0.015423, loss_ce: 0.004794
2022-01-20 21:45:28,321 iteration 4342 : loss : 0.025222, loss_ce: 0.007551
2022-01-20 21:45:28,989 iteration 4343 : loss : 0.024292, loss_ce: 0.008023
2022-01-20 21:45:29,656 iteration 4344 : loss : 0.021411, loss_ce: 0.009520
2022-01-20 21:45:30,391 iteration 4345 : loss : 0.026998, loss_ce: 0.011760
2022-01-20 21:45:30,965 iteration 4346 : loss : 0.024745, loss_ce: 0.007028
2022-01-20 21:45:31,605 iteration 4347 : loss : 0.017477, loss_ce: 0.007459
2022-01-20 21:45:32,191 iteration 4348 : loss : 0.015670, loss_ce: 0.007662
2022-01-20 21:45:32,730 iteration 4349 : loss : 0.015502, loss_ce: 0.004281
2022-01-20 21:45:33,267 iteration 4350 : loss : 0.020287, loss_ce: 0.007013
2022-01-20 21:45:33,917 iteration 4351 : loss : 0.021376, loss_ce: 0.007020
2022-01-20 21:45:34,556 iteration 4352 : loss : 0.021462, loss_ce: 0.008906
 64%|███████████████████▊           | 256/400 [50:04<28:26, 11.85s/it]2022-01-20 21:45:35,212 iteration 4353 : loss : 0.022284, loss_ce: 0.006660
2022-01-20 21:45:35,926 iteration 4354 : loss : 0.028879, loss_ce: 0.014978
2022-01-20 21:45:36,606 iteration 4355 : loss : 0.019056, loss_ce: 0.007462
2022-01-20 21:45:37,324 iteration 4356 : loss : 0.018663, loss_ce: 0.005294
2022-01-20 21:45:37,998 iteration 4357 : loss : 0.017114, loss_ce: 0.007844
2022-01-20 21:45:38,703 iteration 4358 : loss : 0.024999, loss_ce: 0.009134
2022-01-20 21:45:39,371 iteration 4359 : loss : 0.016937, loss_ce: 0.005059
2022-01-20 21:45:39,992 iteration 4360 : loss : 0.021056, loss_ce: 0.008270
2022-01-20 21:45:40,688 iteration 4361 : loss : 0.019300, loss_ce: 0.006644
2022-01-20 21:45:41,334 iteration 4362 : loss : 0.018023, loss_ce: 0.007975
2022-01-20 21:45:41,976 iteration 4363 : loss : 0.015104, loss_ce: 0.006115
2022-01-20 21:45:42,647 iteration 4364 : loss : 0.018357, loss_ce: 0.007351
2022-01-20 21:45:43,383 iteration 4365 : loss : 0.030915, loss_ce: 0.013083
2022-01-20 21:45:43,970 iteration 4366 : loss : 0.016401, loss_ce: 0.004803
2022-01-20 21:45:44,502 iteration 4367 : loss : 0.016411, loss_ce: 0.006267
2022-01-20 21:45:45,068 iteration 4368 : loss : 0.020426, loss_ce: 0.006810
2022-01-20 21:45:45,718 iteration 4369 : loss : 0.022069, loss_ce: 0.008087
 64%|███████████████████▉           | 257/400 [50:15<27:44, 11.64s/it]2022-01-20 21:45:46,399 iteration 4370 : loss : 0.018709, loss_ce: 0.006519
2022-01-20 21:45:47,055 iteration 4371 : loss : 0.020083, loss_ce: 0.010911
2022-01-20 21:45:47,715 iteration 4372 : loss : 0.023397, loss_ce: 0.008249
2022-01-20 21:45:48,375 iteration 4373 : loss : 0.020559, loss_ce: 0.010785
2022-01-20 21:45:49,045 iteration 4374 : loss : 0.021051, loss_ce: 0.007672
2022-01-20 21:45:49,715 iteration 4375 : loss : 0.019549, loss_ce: 0.008642
2022-01-20 21:45:50,331 iteration 4376 : loss : 0.024357, loss_ce: 0.008184
2022-01-20 21:45:50,947 iteration 4377 : loss : 0.022130, loss_ce: 0.006087
2022-01-20 21:45:51,515 iteration 4378 : loss : 0.014712, loss_ce: 0.005099
2022-01-20 21:45:52,093 iteration 4379 : loss : 0.016727, loss_ce: 0.005312
2022-01-20 21:45:52,644 iteration 4380 : loss : 0.017296, loss_ce: 0.005426
2022-01-20 21:45:53,303 iteration 4381 : loss : 0.034200, loss_ce: 0.010889
2022-01-20 21:45:53,935 iteration 4382 : loss : 0.047941, loss_ce: 0.007908
2022-01-20 21:45:54,543 iteration 4383 : loss : 0.021332, loss_ce: 0.005677
2022-01-20 21:45:55,245 iteration 4384 : loss : 0.017983, loss_ce: 0.007509
2022-01-20 21:45:55,936 iteration 4385 : loss : 0.030224, loss_ce: 0.011080
2022-01-20 21:45:56,534 iteration 4386 : loss : 0.018624, loss_ce: 0.008120
 64%|███████████████████▉           | 258/400 [50:25<26:57, 11.39s/it]2022-01-20 21:45:57,146 iteration 4387 : loss : 0.018844, loss_ce: 0.005465
2022-01-20 21:45:57,778 iteration 4388 : loss : 0.021074, loss_ce: 0.008998
2022-01-20 21:45:58,417 iteration 4389 : loss : 0.024379, loss_ce: 0.008024
2022-01-20 21:45:58,989 iteration 4390 : loss : 0.017394, loss_ce: 0.005341
2022-01-20 21:45:59,637 iteration 4391 : loss : 0.020495, loss_ce: 0.006172
2022-01-20 21:46:00,266 iteration 4392 : loss : 0.016301, loss_ce: 0.004979
2022-01-20 21:46:00,972 iteration 4393 : loss : 0.025258, loss_ce: 0.010507
2022-01-20 21:46:01,642 iteration 4394 : loss : 0.020437, loss_ce: 0.007937
2022-01-20 21:46:02,377 iteration 4395 : loss : 0.034923, loss_ce: 0.014377
2022-01-20 21:46:02,978 iteration 4396 : loss : 0.019183, loss_ce: 0.006022
2022-01-20 21:46:03,725 iteration 4397 : loss : 0.024556, loss_ce: 0.012149
2022-01-20 21:46:04,315 iteration 4398 : loss : 0.018849, loss_ce: 0.007628
2022-01-20 21:46:05,003 iteration 4399 : loss : 0.020633, loss_ce: 0.007875
2022-01-20 21:46:05,662 iteration 4400 : loss : 0.024898, loss_ce: 0.009006
2022-01-20 21:46:06,446 iteration 4401 : loss : 0.033410, loss_ce: 0.011894
2022-01-20 21:46:07,103 iteration 4402 : loss : 0.032018, loss_ce: 0.009037
2022-01-20 21:46:07,763 iteration 4403 : loss : 0.021364, loss_ce: 0.008254
 65%|████████████████████           | 259/400 [50:37<26:39, 11.34s/it]2022-01-20 21:46:08,405 iteration 4404 : loss : 0.020048, loss_ce: 0.008380
2022-01-20 21:46:09,082 iteration 4405 : loss : 0.019688, loss_ce: 0.009926
2022-01-20 21:46:09,753 iteration 4406 : loss : 0.021473, loss_ce: 0.009330
2022-01-20 21:46:10,467 iteration 4407 : loss : 0.030082, loss_ce: 0.011369
2022-01-20 21:46:11,093 iteration 4408 : loss : 0.016750, loss_ce: 0.006891
2022-01-20 21:46:11,764 iteration 4409 : loss : 0.021700, loss_ce: 0.007249
2022-01-20 21:46:12,557 iteration 4410 : loss : 0.028076, loss_ce: 0.009612
2022-01-20 21:46:13,258 iteration 4411 : loss : 0.021060, loss_ce: 0.008802
2022-01-20 21:46:13,908 iteration 4412 : loss : 0.024895, loss_ce: 0.009445
2022-01-20 21:46:14,581 iteration 4413 : loss : 0.015624, loss_ce: 0.005120
2022-01-20 21:46:15,162 iteration 4414 : loss : 0.016299, loss_ce: 0.004975
2022-01-20 21:46:15,841 iteration 4415 : loss : 0.015798, loss_ce: 0.005171
2022-01-20 21:46:16,545 iteration 4416 : loss : 0.031697, loss_ce: 0.010192
2022-01-20 21:46:17,183 iteration 4417 : loss : 0.016977, loss_ce: 0.005287
2022-01-20 21:46:17,835 iteration 4418 : loss : 0.022425, loss_ce: 0.009122
2022-01-20 21:46:18,526 iteration 4419 : loss : 0.018189, loss_ce: 0.006052
2022-01-20 21:46:18,526 Training Data Eval:
2022-01-20 21:46:21,427   Average segmentation loss on training set: 0.0126
2022-01-20 21:46:21,427 Validation Data Eval:
2022-01-20 21:46:22,379   Average segmentation loss on validation set: 0.0658
2022-01-20 21:46:22,915 Found new lowest validation loss at iteration 4419! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:46:23,491 iteration 4420 : loss : 0.014235, loss_ce: 0.006253
 65%|████████████████████▏          | 260/400 [50:52<29:32, 12.66s/it]2022-01-20 21:46:24,132 iteration 4421 : loss : 0.017254, loss_ce: 0.005741
2022-01-20 21:46:24,783 iteration 4422 : loss : 0.020167, loss_ce: 0.007832
2022-01-20 21:46:25,486 iteration 4423 : loss : 0.028557, loss_ce: 0.010948
2022-01-20 21:46:26,076 iteration 4424 : loss : 0.019705, loss_ce: 0.006053
2022-01-20 21:46:26,653 iteration 4425 : loss : 0.016204, loss_ce: 0.005349
2022-01-20 21:46:27,355 iteration 4426 : loss : 0.017924, loss_ce: 0.007164
2022-01-20 21:46:27,938 iteration 4427 : loss : 0.017506, loss_ce: 0.008206
2022-01-20 21:46:28,476 iteration 4428 : loss : 0.012916, loss_ce: 0.006122
2022-01-20 21:46:29,037 iteration 4429 : loss : 0.017820, loss_ce: 0.005620
2022-01-20 21:46:29,598 iteration 4430 : loss : 0.014492, loss_ce: 0.005744
2022-01-20 21:46:30,239 iteration 4431 : loss : 0.026675, loss_ce: 0.011090
2022-01-20 21:46:30,913 iteration 4432 : loss : 0.020631, loss_ce: 0.007897
2022-01-20 21:46:31,521 iteration 4433 : loss : 0.022925, loss_ce: 0.005384
2022-01-20 21:46:32,090 iteration 4434 : loss : 0.015928, loss_ce: 0.007133
2022-01-20 21:46:32,723 iteration 4435 : loss : 0.025764, loss_ce: 0.004745
2022-01-20 21:46:33,354 iteration 4436 : loss : 0.020161, loss_ce: 0.008583
2022-01-20 21:46:34,054 iteration 4437 : loss : 0.020871, loss_ce: 0.007932
 65%|████████████████████▏          | 261/400 [51:03<27:52, 12.03s/it]2022-01-20 21:46:34,790 iteration 4438 : loss : 0.030802, loss_ce: 0.009046
2022-01-20 21:46:35,454 iteration 4439 : loss : 0.020685, loss_ce: 0.007480
2022-01-20 21:46:36,101 iteration 4440 : loss : 0.019141, loss_ce: 0.005980
2022-01-20 21:46:36,851 iteration 4441 : loss : 0.025601, loss_ce: 0.006846
2022-01-20 21:46:37,560 iteration 4442 : loss : 0.013873, loss_ce: 0.006460
2022-01-20 21:46:38,231 iteration 4443 : loss : 0.027854, loss_ce: 0.010524
2022-01-20 21:46:38,804 iteration 4444 : loss : 0.020015, loss_ce: 0.005880
2022-01-20 21:46:39,430 iteration 4445 : loss : 0.020768, loss_ce: 0.009068
2022-01-20 21:46:40,103 iteration 4446 : loss : 0.022366, loss_ce: 0.009361
2022-01-20 21:46:40,718 iteration 4447 : loss : 0.018379, loss_ce: 0.006116
2022-01-20 21:46:41,383 iteration 4448 : loss : 0.023466, loss_ce: 0.008177
2022-01-20 21:46:42,031 iteration 4449 : loss : 0.022294, loss_ce: 0.008765
2022-01-20 21:46:42,731 iteration 4450 : loss : 0.039895, loss_ce: 0.011071
2022-01-20 21:46:43,335 iteration 4451 : loss : 0.017605, loss_ce: 0.006900
2022-01-20 21:46:43,988 iteration 4452 : loss : 0.014433, loss_ce: 0.006677
2022-01-20 21:46:44,600 iteration 4453 : loss : 0.026059, loss_ce: 0.009584
2022-01-20 21:46:45,208 iteration 4454 : loss : 0.028253, loss_ce: 0.014832
 66%|████████████████████▎          | 262/400 [51:14<27:03, 11.77s/it]2022-01-20 21:46:45,912 iteration 4455 : loss : 0.013581, loss_ce: 0.003700
2022-01-20 21:46:46,463 iteration 4456 : loss : 0.017685, loss_ce: 0.006575
2022-01-20 21:46:47,119 iteration 4457 : loss : 0.025790, loss_ce: 0.012263
2022-01-20 21:46:47,858 iteration 4458 : loss : 0.030331, loss_ce: 0.011774
2022-01-20 21:46:48,663 iteration 4459 : loss : 0.024127, loss_ce: 0.011600
2022-01-20 21:46:49,268 iteration 4460 : loss : 0.018117, loss_ce: 0.005790
2022-01-20 21:46:49,913 iteration 4461 : loss : 0.022001, loss_ce: 0.006465
2022-01-20 21:46:50,600 iteration 4462 : loss : 0.020855, loss_ce: 0.008081
2022-01-20 21:46:51,230 iteration 4463 : loss : 0.018890, loss_ce: 0.006898
2022-01-20 21:46:51,849 iteration 4464 : loss : 0.018493, loss_ce: 0.006756
2022-01-20 21:46:52,412 iteration 4465 : loss : 0.019205, loss_ce: 0.004436
2022-01-20 21:46:53,000 iteration 4466 : loss : 0.020040, loss_ce: 0.005970
2022-01-20 21:46:53,644 iteration 4467 : loss : 0.026685, loss_ce: 0.012000
2022-01-20 21:46:54,321 iteration 4468 : loss : 0.019306, loss_ce: 0.007937
2022-01-20 21:46:55,039 iteration 4469 : loss : 0.022939, loss_ce: 0.010405
2022-01-20 21:46:55,730 iteration 4470 : loss : 0.019912, loss_ce: 0.007926
2022-01-20 21:46:56,448 iteration 4471 : loss : 0.020468, loss_ce: 0.005621
 66%|████████████████████▍          | 263/400 [51:25<26:30, 11.61s/it]2022-01-20 21:46:57,093 iteration 4472 : loss : 0.015275, loss_ce: 0.006304
2022-01-20 21:46:57,686 iteration 4473 : loss : 0.017542, loss_ce: 0.007270
2022-01-20 21:46:58,330 iteration 4474 : loss : 0.018293, loss_ce: 0.008470
2022-01-20 21:46:58,959 iteration 4475 : loss : 0.021789, loss_ce: 0.006977
2022-01-20 21:46:59,564 iteration 4476 : loss : 0.025859, loss_ce: 0.007608
2022-01-20 21:47:00,178 iteration 4477 : loss : 0.019144, loss_ce: 0.008524
2022-01-20 21:47:00,929 iteration 4478 : loss : 0.028959, loss_ce: 0.017527
2022-01-20 21:47:01,568 iteration 4479 : loss : 0.017899, loss_ce: 0.004884
2022-01-20 21:47:02,229 iteration 4480 : loss : 0.019419, loss_ce: 0.006798
2022-01-20 21:47:02,825 iteration 4481 : loss : 0.022319, loss_ce: 0.008113
2022-01-20 21:47:03,410 iteration 4482 : loss : 0.018329, loss_ce: 0.005565
2022-01-20 21:47:04,014 iteration 4483 : loss : 0.017991, loss_ce: 0.005543
2022-01-20 21:47:04,659 iteration 4484 : loss : 0.015577, loss_ce: 0.004754
2022-01-20 21:47:05,227 iteration 4485 : loss : 0.015241, loss_ce: 0.006218
2022-01-20 21:47:05,927 iteration 4486 : loss : 0.019901, loss_ce: 0.008413
2022-01-20 21:47:06,601 iteration 4487 : loss : 0.029098, loss_ce: 0.012981
2022-01-20 21:47:07,193 iteration 4488 : loss : 0.021299, loss_ce: 0.007427
 66%|████████████████████▍          | 264/400 [51:36<25:43, 11.35s/it]2022-01-20 21:47:07,910 iteration 4489 : loss : 0.017136, loss_ce: 0.007474
2022-01-20 21:47:08,543 iteration 4490 : loss : 0.018422, loss_ce: 0.007877
2022-01-20 21:47:09,295 iteration 4491 : loss : 0.024093, loss_ce: 0.008428
2022-01-20 21:47:09,913 iteration 4492 : loss : 0.019143, loss_ce: 0.004772
2022-01-20 21:47:10,642 iteration 4493 : loss : 0.025126, loss_ce: 0.016005
2022-01-20 21:47:11,250 iteration 4494 : loss : 0.019937, loss_ce: 0.006906
2022-01-20 21:47:11,899 iteration 4495 : loss : 0.023050, loss_ce: 0.005325
2022-01-20 21:47:12,555 iteration 4496 : loss : 0.022825, loss_ce: 0.006503
2022-01-20 21:47:13,086 iteration 4497 : loss : 0.021436, loss_ce: 0.009276
2022-01-20 21:47:13,716 iteration 4498 : loss : 0.021092, loss_ce: 0.006956
2022-01-20 21:47:14,317 iteration 4499 : loss : 0.017846, loss_ce: 0.007713
2022-01-20 21:47:14,947 iteration 4500 : loss : 0.025966, loss_ce: 0.008308
2022-01-20 21:47:15,552 iteration 4501 : loss : 0.025712, loss_ce: 0.013638
2022-01-20 21:47:16,168 iteration 4502 : loss : 0.020214, loss_ce: 0.006579
2022-01-20 21:47:16,882 iteration 4503 : loss : 0.021997, loss_ce: 0.006874
2022-01-20 21:47:17,428 iteration 4504 : loss : 0.016100, loss_ce: 0.006009
2022-01-20 21:47:17,428 Training Data Eval:
2022-01-20 21:47:20,327   Average segmentation loss on training set: 0.0125
2022-01-20 21:47:20,328 Validation Data Eval:
2022-01-20 21:47:21,286   Average segmentation loss on validation set: 0.1080
2022-01-20 21:47:21,924 iteration 4505 : loss : 0.020279, loss_ce: 0.008100
 66%|████████████████████▌          | 265/400 [51:51<27:49, 12.37s/it]2022-01-20 21:47:22,623 iteration 4506 : loss : 0.029749, loss_ce: 0.011090
2022-01-20 21:47:23,330 iteration 4507 : loss : 0.027218, loss_ce: 0.010586
2022-01-20 21:47:23,980 iteration 4508 : loss : 0.022796, loss_ce: 0.009339
2022-01-20 21:47:24,552 iteration 4509 : loss : 0.033611, loss_ce: 0.011021
2022-01-20 21:47:25,193 iteration 4510 : loss : 0.014189, loss_ce: 0.004511
2022-01-20 21:47:25,934 iteration 4511 : loss : 0.018608, loss_ce: 0.007042
2022-01-20 21:47:26,484 iteration 4512 : loss : 0.016328, loss_ce: 0.005541
2022-01-20 21:47:27,097 iteration 4513 : loss : 0.015465, loss_ce: 0.005440
2022-01-20 21:47:27,703 iteration 4514 : loss : 0.019463, loss_ce: 0.008096
2022-01-20 21:47:28,329 iteration 4515 : loss : 0.015641, loss_ce: 0.005936
2022-01-20 21:47:28,978 iteration 4516 : loss : 0.019441, loss_ce: 0.008081
2022-01-20 21:47:29,654 iteration 4517 : loss : 0.020632, loss_ce: 0.007860
2022-01-20 21:47:30,270 iteration 4518 : loss : 0.023931, loss_ce: 0.009802
2022-01-20 21:47:30,835 iteration 4519 : loss : 0.023609, loss_ce: 0.007194
2022-01-20 21:47:31,479 iteration 4520 : loss : 0.019826, loss_ce: 0.006914
2022-01-20 21:47:32,132 iteration 4521 : loss : 0.024203, loss_ce: 0.011105
2022-01-20 21:47:32,827 iteration 4522 : loss : 0.033118, loss_ce: 0.011165
 66%|████████████████████▌          | 266/400 [52:02<26:38, 11.93s/it]2022-01-20 21:47:33,575 iteration 4523 : loss : 0.027795, loss_ce: 0.013631
2022-01-20 21:47:34,229 iteration 4524 : loss : 0.021909, loss_ce: 0.007693
2022-01-20 21:47:34,894 iteration 4525 : loss : 0.025708, loss_ce: 0.011533
2022-01-20 21:47:35,521 iteration 4526 : loss : 0.016643, loss_ce: 0.004718
2022-01-20 21:47:36,078 iteration 4527 : loss : 0.021717, loss_ce: 0.007707
2022-01-20 21:47:36,671 iteration 4528 : loss : 0.020868, loss_ce: 0.007145
2022-01-20 21:47:37,318 iteration 4529 : loss : 0.018993, loss_ce: 0.008036
2022-01-20 21:47:37,916 iteration 4530 : loss : 0.023380, loss_ce: 0.005544
2022-01-20 21:47:38,552 iteration 4531 : loss : 0.021327, loss_ce: 0.007311
2022-01-20 21:47:39,223 iteration 4532 : loss : 0.014536, loss_ce: 0.004470
2022-01-20 21:47:39,835 iteration 4533 : loss : 0.022111, loss_ce: 0.009233
2022-01-20 21:47:40,464 iteration 4534 : loss : 0.024165, loss_ce: 0.006332
2022-01-20 21:47:41,131 iteration 4535 : loss : 0.018371, loss_ce: 0.006466
2022-01-20 21:47:41,787 iteration 4536 : loss : 0.025259, loss_ce: 0.009418
2022-01-20 21:47:42,429 iteration 4537 : loss : 0.018958, loss_ce: 0.007762
2022-01-20 21:47:43,060 iteration 4538 : loss : 0.026558, loss_ce: 0.010251
2022-01-20 21:47:43,688 iteration 4539 : loss : 0.016260, loss_ce: 0.006543
 67%|████████████████████▋          | 267/400 [52:13<25:43, 11.61s/it]2022-01-20 21:47:44,335 iteration 4540 : loss : 0.014711, loss_ce: 0.005128
2022-01-20 21:47:44,996 iteration 4541 : loss : 0.020891, loss_ce: 0.009183
2022-01-20 21:47:45,582 iteration 4542 : loss : 0.018955, loss_ce: 0.006772
2022-01-20 21:47:46,192 iteration 4543 : loss : 0.021787, loss_ce: 0.007037
2022-01-20 21:47:46,782 iteration 4544 : loss : 0.018785, loss_ce: 0.006397
2022-01-20 21:47:47,488 iteration 4545 : loss : 0.019767, loss_ce: 0.008320
2022-01-20 21:47:48,247 iteration 4546 : loss : 0.032167, loss_ce: 0.015761
2022-01-20 21:47:48,984 iteration 4547 : loss : 0.023538, loss_ce: 0.009474
2022-01-20 21:47:49,561 iteration 4548 : loss : 0.017642, loss_ce: 0.006465
2022-01-20 21:47:50,148 iteration 4549 : loss : 0.016043, loss_ce: 0.004414
2022-01-20 21:47:50,793 iteration 4550 : loss : 0.018427, loss_ce: 0.006597
2022-01-20 21:47:51,456 iteration 4551 : loss : 0.017424, loss_ce: 0.007333
2022-01-20 21:47:52,177 iteration 4552 : loss : 0.026371, loss_ce: 0.008469
2022-01-20 21:47:52,836 iteration 4553 : loss : 0.018483, loss_ce: 0.006469
2022-01-20 21:47:53,426 iteration 4554 : loss : 0.018052, loss_ce: 0.007642
2022-01-20 21:47:54,046 iteration 4555 : loss : 0.014950, loss_ce: 0.005539
2022-01-20 21:47:54,665 iteration 4556 : loss : 0.024509, loss_ce: 0.007446
 67%|████████████████████▊          | 268/400 [52:24<25:06, 11.42s/it]2022-01-20 21:47:55,307 iteration 4557 : loss : 0.018654, loss_ce: 0.007458
2022-01-20 21:47:55,981 iteration 4558 : loss : 0.026144, loss_ce: 0.009500
2022-01-20 21:47:56,687 iteration 4559 : loss : 0.023971, loss_ce: 0.008943
2022-01-20 21:47:57,355 iteration 4560 : loss : 0.018473, loss_ce: 0.008587
2022-01-20 21:47:57,951 iteration 4561 : loss : 0.014887, loss_ce: 0.004975
2022-01-20 21:47:58,597 iteration 4562 : loss : 0.023293, loss_ce: 0.008799
2022-01-20 21:47:59,214 iteration 4563 : loss : 0.019909, loss_ce: 0.006389
2022-01-20 21:47:59,818 iteration 4564 : loss : 0.019104, loss_ce: 0.007960
2022-01-20 21:48:00,444 iteration 4565 : loss : 0.022109, loss_ce: 0.008643
2022-01-20 21:48:01,090 iteration 4566 : loss : 0.016807, loss_ce: 0.006376
2022-01-20 21:48:01,726 iteration 4567 : loss : 0.021080, loss_ce: 0.007503
2022-01-20 21:48:02,282 iteration 4568 : loss : 0.016106, loss_ce: 0.005322
2022-01-20 21:48:02,857 iteration 4569 : loss : 0.021055, loss_ce: 0.007780
2022-01-20 21:48:03,448 iteration 4570 : loss : 0.019159, loss_ce: 0.007046
2022-01-20 21:48:04,119 iteration 4571 : loss : 0.021214, loss_ce: 0.010347
2022-01-20 21:48:04,784 iteration 4572 : loss : 0.027481, loss_ce: 0.010319
2022-01-20 21:48:05,465 iteration 4573 : loss : 0.023449, loss_ce: 0.006876
 67%|████████████████████▊          | 269/400 [52:34<24:31, 11.23s/it]2022-01-20 21:48:06,076 iteration 4574 : loss : 0.012949, loss_ce: 0.004270
2022-01-20 21:48:06,732 iteration 4575 : loss : 0.020153, loss_ce: 0.004769
2022-01-20 21:48:07,296 iteration 4576 : loss : 0.015867, loss_ce: 0.006245
2022-01-20 21:48:07,877 iteration 4577 : loss : 0.015571, loss_ce: 0.007293
2022-01-20 21:48:08,508 iteration 4578 : loss : 0.018712, loss_ce: 0.006923
2022-01-20 21:48:09,097 iteration 4579 : loss : 0.016016, loss_ce: 0.006545
2022-01-20 21:48:09,707 iteration 4580 : loss : 0.019461, loss_ce: 0.007097
2022-01-20 21:48:10,341 iteration 4581 : loss : 0.021503, loss_ce: 0.008440
2022-01-20 21:48:10,969 iteration 4582 : loss : 0.021576, loss_ce: 0.008138
2022-01-20 21:48:11,595 iteration 4583 : loss : 0.019515, loss_ce: 0.007095
2022-01-20 21:48:12,206 iteration 4584 : loss : 0.017080, loss_ce: 0.006558
2022-01-20 21:48:12,858 iteration 4585 : loss : 0.025154, loss_ce: 0.008048
2022-01-20 21:48:13,432 iteration 4586 : loss : 0.015952, loss_ce: 0.006252
2022-01-20 21:48:14,025 iteration 4587 : loss : 0.015415, loss_ce: 0.004817
2022-01-20 21:48:14,621 iteration 4588 : loss : 0.019571, loss_ce: 0.006910
2022-01-20 21:48:15,258 iteration 4589 : loss : 0.024932, loss_ce: 0.009930
2022-01-20 21:48:15,259 Training Data Eval:
2022-01-20 21:48:18,156   Average segmentation loss on training set: 0.0124
2022-01-20 21:48:18,156 Validation Data Eval:
2022-01-20 21:48:19,112   Average segmentation loss on validation set: 0.0735
2022-01-20 21:48:19,727 iteration 4590 : loss : 0.019819, loss_ce: 0.009389
 68%|████████████████████▉          | 270/400 [52:49<26:18, 12.14s/it]2022-01-20 21:48:20,397 iteration 4591 : loss : 0.042395, loss_ce: 0.008719
2022-01-20 21:48:21,074 iteration 4592 : loss : 0.019238, loss_ce: 0.006377
2022-01-20 21:48:21,729 iteration 4593 : loss : 0.020985, loss_ce: 0.009546
2022-01-20 21:48:22,425 iteration 4594 : loss : 0.040502, loss_ce: 0.014188
2022-01-20 21:48:23,054 iteration 4595 : loss : 0.020245, loss_ce: 0.007279
2022-01-20 21:48:23,664 iteration 4596 : loss : 0.019427, loss_ce: 0.006910
2022-01-20 21:48:24,314 iteration 4597 : loss : 0.016539, loss_ce: 0.007491
2022-01-20 21:48:25,011 iteration 4598 : loss : 0.023682, loss_ce: 0.008122
2022-01-20 21:48:25,686 iteration 4599 : loss : 0.016350, loss_ce: 0.008039
2022-01-20 21:48:26,302 iteration 4600 : loss : 0.019476, loss_ce: 0.007137
2022-01-20 21:48:26,965 iteration 4601 : loss : 0.023358, loss_ce: 0.010461
2022-01-20 21:48:27,704 iteration 4602 : loss : 0.026157, loss_ce: 0.006171
2022-01-20 21:48:28,355 iteration 4603 : loss : 0.019610, loss_ce: 0.006946
2022-01-20 21:48:29,035 iteration 4604 : loss : 0.021073, loss_ce: 0.009306
2022-01-20 21:48:29,733 iteration 4605 : loss : 0.058060, loss_ce: 0.011897
2022-01-20 21:48:30,427 iteration 4606 : loss : 0.019682, loss_ce: 0.007609
2022-01-20 21:48:31,122 iteration 4607 : loss : 0.022437, loss_ce: 0.012181
 68%|█████████████████████          | 271/400 [53:00<25:37, 11.92s/it]2022-01-20 21:48:31,755 iteration 4608 : loss : 0.014431, loss_ce: 0.005277
2022-01-20 21:48:32,402 iteration 4609 : loss : 0.022212, loss_ce: 0.009222
2022-01-20 21:48:32,982 iteration 4610 : loss : 0.021970, loss_ce: 0.007334
2022-01-20 21:48:33,559 iteration 4611 : loss : 0.019396, loss_ce: 0.008084
2022-01-20 21:48:34,116 iteration 4612 : loss : 0.020596, loss_ce: 0.005969
2022-01-20 21:48:34,750 iteration 4613 : loss : 0.020972, loss_ce: 0.006811
2022-01-20 21:48:35,385 iteration 4614 : loss : 0.018452, loss_ce: 0.008613
2022-01-20 21:48:36,064 iteration 4615 : loss : 0.018695, loss_ce: 0.007765
2022-01-20 21:48:36,816 iteration 4616 : loss : 0.025965, loss_ce: 0.010952
2022-01-20 21:48:37,470 iteration 4617 : loss : 0.022726, loss_ce: 0.008237
2022-01-20 21:48:38,058 iteration 4618 : loss : 0.022740, loss_ce: 0.008581
2022-01-20 21:48:38,654 iteration 4619 : loss : 0.014456, loss_ce: 0.006659
2022-01-20 21:48:39,353 iteration 4620 : loss : 0.018065, loss_ce: 0.005714
2022-01-20 21:48:39,984 iteration 4621 : loss : 0.029801, loss_ce: 0.015953
2022-01-20 21:48:40,625 iteration 4622 : loss : 0.037736, loss_ce: 0.013727
2022-01-20 21:48:41,257 iteration 4623 : loss : 0.021164, loss_ce: 0.006791
2022-01-20 21:48:41,911 iteration 4624 : loss : 0.019337, loss_ce: 0.008719
 68%|█████████████████████          | 272/400 [53:11<24:42, 11.58s/it]2022-01-20 21:48:42,641 iteration 4625 : loss : 0.022434, loss_ce: 0.009138
2022-01-20 21:48:43,344 iteration 4626 : loss : 0.020848, loss_ce: 0.008948
2022-01-20 21:48:44,084 iteration 4627 : loss : 0.026034, loss_ce: 0.010148
2022-01-20 21:48:44,696 iteration 4628 : loss : 0.023230, loss_ce: 0.007615
2022-01-20 21:48:45,265 iteration 4629 : loss : 0.017037, loss_ce: 0.005570
2022-01-20 21:48:45,889 iteration 4630 : loss : 0.021069, loss_ce: 0.007634
2022-01-20 21:48:46,528 iteration 4631 : loss : 0.020191, loss_ce: 0.006828
2022-01-20 21:48:47,165 iteration 4632 : loss : 0.024770, loss_ce: 0.007650
2022-01-20 21:48:47,779 iteration 4633 : loss : 0.021969, loss_ce: 0.006712
2022-01-20 21:48:48,373 iteration 4634 : loss : 0.018606, loss_ce: 0.009081
2022-01-20 21:48:48,923 iteration 4635 : loss : 0.012862, loss_ce: 0.005052
2022-01-20 21:48:49,635 iteration 4636 : loss : 0.023287, loss_ce: 0.009259
2022-01-20 21:48:50,240 iteration 4637 : loss : 0.023109, loss_ce: 0.007407
2022-01-20 21:48:50,985 iteration 4638 : loss : 0.029474, loss_ce: 0.015035
2022-01-20 21:48:51,669 iteration 4639 : loss : 0.025262, loss_ce: 0.009096
2022-01-20 21:48:52,440 iteration 4640 : loss : 0.035383, loss_ce: 0.013979
2022-01-20 21:48:53,135 iteration 4641 : loss : 0.018998, loss_ce: 0.007121
 68%|█████████████████████▏         | 273/400 [53:22<24:17, 11.47s/it]2022-01-20 21:48:53,811 iteration 4642 : loss : 0.025813, loss_ce: 0.007041
2022-01-20 21:48:54,453 iteration 4643 : loss : 0.019194, loss_ce: 0.005389
2022-01-20 21:48:55,148 iteration 4644 : loss : 0.027372, loss_ce: 0.009313
2022-01-20 21:48:55,848 iteration 4645 : loss : 0.026843, loss_ce: 0.012410
2022-01-20 21:48:56,512 iteration 4646 : loss : 0.019683, loss_ce: 0.005165
2022-01-20 21:48:57,075 iteration 4647 : loss : 0.018461, loss_ce: 0.006087
2022-01-20 21:48:57,680 iteration 4648 : loss : 0.018973, loss_ce: 0.006486
2022-01-20 21:48:58,331 iteration 4649 : loss : 0.018606, loss_ce: 0.007764
2022-01-20 21:48:59,026 iteration 4650 : loss : 0.024695, loss_ce: 0.007406
2022-01-20 21:48:59,615 iteration 4651 : loss : 0.017291, loss_ce: 0.007570
2022-01-20 21:49:00,340 iteration 4652 : loss : 0.021065, loss_ce: 0.008027
2022-01-20 21:49:00,962 iteration 4653 : loss : 0.020310, loss_ce: 0.007916
2022-01-20 21:49:01,591 iteration 4654 : loss : 0.019543, loss_ce: 0.005180
2022-01-20 21:49:02,298 iteration 4655 : loss : 0.026534, loss_ce: 0.010153
2022-01-20 21:49:03,017 iteration 4656 : loss : 0.024196, loss_ce: 0.010775
2022-01-20 21:49:03,698 iteration 4657 : loss : 0.022751, loss_ce: 0.010900
2022-01-20 21:49:04,376 iteration 4658 : loss : 0.024950, loss_ce: 0.009211
 68%|█████████████████████▏         | 274/400 [53:33<23:56, 11.40s/it]2022-01-20 21:49:05,087 iteration 4659 : loss : 0.020570, loss_ce: 0.008531
2022-01-20 21:49:05,793 iteration 4660 : loss : 0.025250, loss_ce: 0.009841
2022-01-20 21:49:06,476 iteration 4661 : loss : 0.038631, loss_ce: 0.011514
2022-01-20 21:49:07,078 iteration 4662 : loss : 0.015283, loss_ce: 0.005941
2022-01-20 21:49:07,748 iteration 4663 : loss : 0.022681, loss_ce: 0.009328
2022-01-20 21:49:08,371 iteration 4664 : loss : 0.014118, loss_ce: 0.005375
2022-01-20 21:49:09,006 iteration 4665 : loss : 0.019598, loss_ce: 0.006657
2022-01-20 21:49:09,543 iteration 4666 : loss : 0.015980, loss_ce: 0.005383
2022-01-20 21:49:10,145 iteration 4667 : loss : 0.014251, loss_ce: 0.005449
2022-01-20 21:49:10,916 iteration 4668 : loss : 0.025789, loss_ce: 0.012317
2022-01-20 21:49:11,514 iteration 4669 : loss : 0.016298, loss_ce: 0.006928
2022-01-20 21:49:12,120 iteration 4670 : loss : 0.024691, loss_ce: 0.010512
2022-01-20 21:49:12,704 iteration 4671 : loss : 0.017181, loss_ce: 0.004829
2022-01-20 21:49:13,434 iteration 4672 : loss : 0.042735, loss_ce: 0.015215
2022-01-20 21:49:14,126 iteration 4673 : loss : 0.021031, loss_ce: 0.008422
2022-01-20 21:49:14,701 iteration 4674 : loss : 0.016558, loss_ce: 0.004916
2022-01-20 21:49:14,702 Training Data Eval:
2022-01-20 21:49:17,596   Average segmentation loss on training set: 0.0145
2022-01-20 21:49:17,596 Validation Data Eval:
2022-01-20 21:49:18,551   Average segmentation loss on validation set: 0.0847
2022-01-20 21:49:19,250 iteration 4675 : loss : 0.020172, loss_ce: 0.007803
 69%|█████████████████████▎         | 275/400 [53:48<25:55, 12.45s/it]2022-01-20 21:49:20,028 iteration 4676 : loss : 0.033403, loss_ce: 0.009698
2022-01-20 21:49:20,649 iteration 4677 : loss : 0.024893, loss_ce: 0.008065
2022-01-20 21:49:21,307 iteration 4678 : loss : 0.031014, loss_ce: 0.007896
2022-01-20 21:49:22,014 iteration 4679 : loss : 0.032644, loss_ce: 0.009206
2022-01-20 21:49:22,650 iteration 4680 : loss : 0.019669, loss_ce: 0.007893
2022-01-20 21:49:23,278 iteration 4681 : loss : 0.030996, loss_ce: 0.008453
2022-01-20 21:49:23,889 iteration 4682 : loss : 0.024202, loss_ce: 0.008850
2022-01-20 21:49:24,426 iteration 4683 : loss : 0.029611, loss_ce: 0.007525
2022-01-20 21:49:25,113 iteration 4684 : loss : 0.021158, loss_ce: 0.009803
2022-01-20 21:49:25,778 iteration 4685 : loss : 0.031337, loss_ce: 0.010570
2022-01-20 21:49:26,409 iteration 4686 : loss : 0.029223, loss_ce: 0.007957
2022-01-20 21:49:27,016 iteration 4687 : loss : 0.030359, loss_ce: 0.019370
2022-01-20 21:49:27,574 iteration 4688 : loss : 0.015188, loss_ce: 0.006281
2022-01-20 21:49:28,137 iteration 4689 : loss : 0.012413, loss_ce: 0.005249
2022-01-20 21:49:28,721 iteration 4690 : loss : 0.021722, loss_ce: 0.007868
2022-01-20 21:49:29,397 iteration 4691 : loss : 0.031257, loss_ce: 0.016943
2022-01-20 21:49:30,017 iteration 4692 : loss : 0.027938, loss_ce: 0.008348
 69%|█████████████████████▍         | 276/400 [53:59<24:40, 11.94s/it]2022-01-20 21:49:30,815 iteration 4693 : loss : 0.030224, loss_ce: 0.010557
2022-01-20 21:49:31,478 iteration 4694 : loss : 0.028276, loss_ce: 0.010651
2022-01-20 21:49:31,974 iteration 4695 : loss : 0.014720, loss_ce: 0.005215
2022-01-20 21:49:32,688 iteration 4696 : loss : 0.024096, loss_ce: 0.008438
2022-01-20 21:49:33,295 iteration 4697 : loss : 0.019420, loss_ce: 0.006857
2022-01-20 21:49:33,932 iteration 4698 : loss : 0.023977, loss_ce: 0.010562
2022-01-20 21:49:34,629 iteration 4699 : loss : 0.015625, loss_ce: 0.006794
2022-01-20 21:49:35,222 iteration 4700 : loss : 0.019585, loss_ce: 0.009267
2022-01-20 21:49:35,964 iteration 4701 : loss : 0.022296, loss_ce: 0.009178
2022-01-20 21:49:36,587 iteration 4702 : loss : 0.020003, loss_ce: 0.007668
2022-01-20 21:49:37,186 iteration 4703 : loss : 0.017019, loss_ce: 0.004675
2022-01-20 21:49:37,823 iteration 4704 : loss : 0.019408, loss_ce: 0.006570
2022-01-20 21:49:38,332 iteration 4705 : loss : 0.013829, loss_ce: 0.005901
2022-01-20 21:49:38,966 iteration 4706 : loss : 0.023188, loss_ce: 0.006281
2022-01-20 21:49:39,662 iteration 4707 : loss : 0.016735, loss_ce: 0.005988
2022-01-20 21:49:40,373 iteration 4708 : loss : 0.021638, loss_ce: 0.006422
2022-01-20 21:49:41,047 iteration 4709 : loss : 0.024700, loss_ce: 0.008079
 69%|█████████████████████▍         | 277/400 [54:10<23:55, 11.67s/it]2022-01-20 21:49:41,754 iteration 4710 : loss : 0.019704, loss_ce: 0.004779
2022-01-20 21:49:42,532 iteration 4711 : loss : 0.019966, loss_ce: 0.007100
2022-01-20 21:49:43,151 iteration 4712 : loss : 0.020280, loss_ce: 0.008590
2022-01-20 21:49:43,777 iteration 4713 : loss : 0.017532, loss_ce: 0.006508
2022-01-20 21:49:44,428 iteration 4714 : loss : 0.019236, loss_ce: 0.006316
2022-01-20 21:49:45,143 iteration 4715 : loss : 0.028485, loss_ce: 0.009083
2022-01-20 21:49:45,810 iteration 4716 : loss : 0.025988, loss_ce: 0.011850
2022-01-20 21:49:46,445 iteration 4717 : loss : 0.021768, loss_ce: 0.006942
2022-01-20 21:49:47,021 iteration 4718 : loss : 0.013530, loss_ce: 0.004947
2022-01-20 21:49:47,598 iteration 4719 : loss : 0.016246, loss_ce: 0.006682
2022-01-20 21:49:48,195 iteration 4720 : loss : 0.016724, loss_ce: 0.006746
2022-01-20 21:49:48,807 iteration 4721 : loss : 0.016277, loss_ce: 0.006508
2022-01-20 21:49:49,492 iteration 4722 : loss : 0.037566, loss_ce: 0.012239
2022-01-20 21:49:50,124 iteration 4723 : loss : 0.013280, loss_ce: 0.004842
2022-01-20 21:49:50,690 iteration 4724 : loss : 0.015130, loss_ce: 0.007044
2022-01-20 21:49:51,254 iteration 4725 : loss : 0.018453, loss_ce: 0.007017
2022-01-20 21:49:51,879 iteration 4726 : loss : 0.027405, loss_ce: 0.010903
 70%|█████████████████████▌         | 278/400 [54:21<23:13, 11.42s/it]2022-01-20 21:49:52,611 iteration 4727 : loss : 0.020877, loss_ce: 0.007273
2022-01-20 21:49:53,194 iteration 4728 : loss : 0.017577, loss_ce: 0.006856
2022-01-20 21:49:53,791 iteration 4729 : loss : 0.015024, loss_ce: 0.005443
2022-01-20 21:49:54,387 iteration 4730 : loss : 0.014325, loss_ce: 0.004819
2022-01-20 21:49:55,081 iteration 4731 : loss : 0.021295, loss_ce: 0.007943
2022-01-20 21:49:55,736 iteration 4732 : loss : 0.023130, loss_ce: 0.007680
2022-01-20 21:49:56,376 iteration 4733 : loss : 0.017297, loss_ce: 0.006877
2022-01-20 21:49:56,985 iteration 4734 : loss : 0.016768, loss_ce: 0.007154
2022-01-20 21:49:57,703 iteration 4735 : loss : 0.022723, loss_ce: 0.007739
2022-01-20 21:49:58,270 iteration 4736 : loss : 0.019272, loss_ce: 0.008351
2022-01-20 21:49:58,975 iteration 4737 : loss : 0.020752, loss_ce: 0.006672
2022-01-20 21:49:59,607 iteration 4738 : loss : 0.018078, loss_ce: 0.006592
2022-01-20 21:50:00,239 iteration 4739 : loss : 0.013457, loss_ce: 0.004789
2022-01-20 21:50:00,921 iteration 4740 : loss : 0.018301, loss_ce: 0.007666
2022-01-20 21:50:01,538 iteration 4741 : loss : 0.016886, loss_ce: 0.005155
2022-01-20 21:50:02,168 iteration 4742 : loss : 0.019387, loss_ce: 0.009399
2022-01-20 21:50:02,886 iteration 4743 : loss : 0.023861, loss_ce: 0.007270
 70%|█████████████████████▌         | 279/400 [54:32<22:46, 11.29s/it]2022-01-20 21:50:03,618 iteration 4744 : loss : 0.019352, loss_ce: 0.006155
2022-01-20 21:50:04,254 iteration 4745 : loss : 0.020540, loss_ce: 0.005920
2022-01-20 21:50:04,846 iteration 4746 : loss : 0.014501, loss_ce: 0.007218
2022-01-20 21:50:05,451 iteration 4747 : loss : 0.020386, loss_ce: 0.006709
2022-01-20 21:50:06,090 iteration 4748 : loss : 0.020425, loss_ce: 0.006800
2022-01-20 21:50:06,732 iteration 4749 : loss : 0.019267, loss_ce: 0.006773
2022-01-20 21:50:07,423 iteration 4750 : loss : 0.018749, loss_ce: 0.006913
2022-01-20 21:50:08,042 iteration 4751 : loss : 0.019543, loss_ce: 0.007315
2022-01-20 21:50:08,715 iteration 4752 : loss : 0.017748, loss_ce: 0.005805
2022-01-20 21:50:09,413 iteration 4753 : loss : 0.022320, loss_ce: 0.008542
2022-01-20 21:50:10,084 iteration 4754 : loss : 0.016127, loss_ce: 0.004970
2022-01-20 21:50:10,839 iteration 4755 : loss : 0.016179, loss_ce: 0.004657
2022-01-20 21:50:11,451 iteration 4756 : loss : 0.018412, loss_ce: 0.008607
2022-01-20 21:50:12,079 iteration 4757 : loss : 0.021206, loss_ce: 0.008165
2022-01-20 21:50:12,682 iteration 4758 : loss : 0.018298, loss_ce: 0.005762
2022-01-20 21:50:13,320 iteration 4759 : loss : 0.015447, loss_ce: 0.005206
2022-01-20 21:50:13,321 Training Data Eval:
2022-01-20 21:50:16,217   Average segmentation loss on training set: 0.0120
2022-01-20 21:50:16,218 Validation Data Eval:
2022-01-20 21:50:17,165   Average segmentation loss on validation set: 0.1051
2022-01-20 21:50:17,763 iteration 4760 : loss : 0.019140, loss_ce: 0.008295
 70%|█████████████████████▋         | 280/400 [54:47<24:44, 12.37s/it]2022-01-20 21:50:18,417 iteration 4761 : loss : 0.017628, loss_ce: 0.006469
2022-01-20 21:50:19,078 iteration 4762 : loss : 0.028138, loss_ce: 0.007362
2022-01-20 21:50:19,655 iteration 4763 : loss : 0.014476, loss_ce: 0.005842
2022-01-20 21:50:20,322 iteration 4764 : loss : 0.022326, loss_ce: 0.006871
2022-01-20 21:50:20,932 iteration 4765 : loss : 0.018104, loss_ce: 0.008329
2022-01-20 21:50:21,638 iteration 4766 : loss : 0.023956, loss_ce: 0.008414
2022-01-20 21:50:22,309 iteration 4767 : loss : 0.017214, loss_ce: 0.006734
2022-01-20 21:50:22,907 iteration 4768 : loss : 0.016861, loss_ce: 0.005570
2022-01-20 21:50:23,591 iteration 4769 : loss : 0.022982, loss_ce: 0.008585
2022-01-20 21:50:24,279 iteration 4770 : loss : 0.021639, loss_ce: 0.007638
2022-01-20 21:50:24,859 iteration 4771 : loss : 0.016817, loss_ce: 0.005051
2022-01-20 21:50:25,546 iteration 4772 : loss : 0.020498, loss_ce: 0.008269
2022-01-20 21:50:26,210 iteration 4773 : loss : 0.020697, loss_ce: 0.007322
2022-01-20 21:50:26,870 iteration 4774 : loss : 0.015562, loss_ce: 0.006273
2022-01-20 21:50:27,471 iteration 4775 : loss : 0.018705, loss_ce: 0.005608
2022-01-20 21:50:28,100 iteration 4776 : loss : 0.016989, loss_ce: 0.008413
2022-01-20 21:50:28,875 iteration 4777 : loss : 0.021516, loss_ce: 0.010437
 70%|█████████████████████▊         | 281/400 [54:58<23:46, 11.99s/it]2022-01-20 21:50:29,481 iteration 4778 : loss : 0.013087, loss_ce: 0.003609
2022-01-20 21:50:30,101 iteration 4779 : loss : 0.027269, loss_ce: 0.008217
2022-01-20 21:50:30,664 iteration 4780 : loss : 0.013282, loss_ce: 0.004559
2022-01-20 21:50:31,277 iteration 4781 : loss : 0.030171, loss_ce: 0.009884
2022-01-20 21:50:31,970 iteration 4782 : loss : 0.018869, loss_ce: 0.008155
2022-01-20 21:50:32,612 iteration 4783 : loss : 0.017180, loss_ce: 0.008035
2022-01-20 21:50:33,188 iteration 4784 : loss : 0.016079, loss_ce: 0.006577
2022-01-20 21:50:33,897 iteration 4785 : loss : 0.022680, loss_ce: 0.006954
2022-01-20 21:50:34,563 iteration 4786 : loss : 0.022460, loss_ce: 0.008581
2022-01-20 21:50:35,227 iteration 4787 : loss : 0.027343, loss_ce: 0.007975
2022-01-20 21:50:35,896 iteration 4788 : loss : 0.020102, loss_ce: 0.007072
2022-01-20 21:50:36,470 iteration 4789 : loss : 0.015701, loss_ce: 0.006874
2022-01-20 21:50:37,193 iteration 4790 : loss : 0.027708, loss_ce: 0.009058
2022-01-20 21:50:37,811 iteration 4791 : loss : 0.036957, loss_ce: 0.019456
2022-01-20 21:50:38,503 iteration 4792 : loss : 0.025711, loss_ce: 0.007114
2022-01-20 21:50:39,105 iteration 4793 : loss : 0.016569, loss_ce: 0.005692
2022-01-20 21:50:39,657 iteration 4794 : loss : 0.027115, loss_ce: 0.007533
 70%|█████████████████████▊         | 282/400 [55:09<22:52, 11.63s/it]2022-01-20 21:50:40,361 iteration 4795 : loss : 0.027472, loss_ce: 0.009955
2022-01-20 21:50:41,020 iteration 4796 : loss : 0.029915, loss_ce: 0.011477
2022-01-20 21:50:41,682 iteration 4797 : loss : 0.025255, loss_ce: 0.010105
2022-01-20 21:50:42,392 iteration 4798 : loss : 0.031571, loss_ce: 0.010734
2022-01-20 21:50:43,030 iteration 4799 : loss : 0.015959, loss_ce: 0.005348
2022-01-20 21:50:43,671 iteration 4800 : loss : 0.025929, loss_ce: 0.008548
2022-01-20 21:50:44,389 iteration 4801 : loss : 0.016682, loss_ce: 0.006062
2022-01-20 21:50:44,952 iteration 4802 : loss : 0.020538, loss_ce: 0.008236
2022-01-20 21:50:45,562 iteration 4803 : loss : 0.015617, loss_ce: 0.006494
2022-01-20 21:50:46,272 iteration 4804 : loss : 0.054746, loss_ce: 0.013983
2022-01-20 21:50:46,974 iteration 4805 : loss : 0.039864, loss_ce: 0.014575
2022-01-20 21:50:47,678 iteration 4806 : loss : 0.027970, loss_ce: 0.010821
2022-01-20 21:50:48,246 iteration 4807 : loss : 0.022306, loss_ce: 0.008811
2022-01-20 21:50:48,806 iteration 4808 : loss : 0.016310, loss_ce: 0.006807
2022-01-20 21:50:49,451 iteration 4809 : loss : 0.024736, loss_ce: 0.012154
2022-01-20 21:50:50,078 iteration 4810 : loss : 0.036875, loss_ce: 0.009855
2022-01-20 21:50:50,725 iteration 4811 : loss : 0.016996, loss_ce: 0.005838
 71%|█████████████████████▉         | 283/400 [55:20<22:20, 11.46s/it]2022-01-20 21:50:51,340 iteration 4812 : loss : 0.018039, loss_ce: 0.006986
2022-01-20 21:50:51,989 iteration 4813 : loss : 0.020133, loss_ce: 0.005621
2022-01-20 21:50:52,670 iteration 4814 : loss : 0.049696, loss_ce: 0.012583
2022-01-20 21:50:53,247 iteration 4815 : loss : 0.017688, loss_ce: 0.007734
2022-01-20 21:50:54,000 iteration 4816 : loss : 0.030701, loss_ce: 0.012944
2022-01-20 21:50:54,627 iteration 4817 : loss : 0.023414, loss_ce: 0.008654
2022-01-20 21:50:55,248 iteration 4818 : loss : 0.018220, loss_ce: 0.006887
2022-01-20 21:50:55,796 iteration 4819 : loss : 0.020201, loss_ce: 0.007310
2022-01-20 21:50:56,398 iteration 4820 : loss : 0.032304, loss_ce: 0.011650
2022-01-20 21:50:57,129 iteration 4821 : loss : 0.023143, loss_ce: 0.009935
2022-01-20 21:50:57,849 iteration 4822 : loss : 0.021821, loss_ce: 0.007405
2022-01-20 21:50:58,482 iteration 4823 : loss : 0.021274, loss_ce: 0.007742
2022-01-20 21:50:59,146 iteration 4824 : loss : 0.023290, loss_ce: 0.008501
2022-01-20 21:50:59,755 iteration 4825 : loss : 0.019661, loss_ce: 0.007437
2022-01-20 21:51:00,358 iteration 4826 : loss : 0.019822, loss_ce: 0.006202
2022-01-20 21:51:00,971 iteration 4827 : loss : 0.018160, loss_ce: 0.007082
2022-01-20 21:51:01,567 iteration 4828 : loss : 0.022503, loss_ce: 0.009354
 71%|██████████████████████         | 284/400 [55:30<21:48, 11.28s/it]2022-01-20 21:51:02,182 iteration 4829 : loss : 0.019299, loss_ce: 0.006167
2022-01-20 21:51:02,850 iteration 4830 : loss : 0.016855, loss_ce: 0.007381
2022-01-20 21:51:03,499 iteration 4831 : loss : 0.018615, loss_ce: 0.007493
2022-01-20 21:51:04,125 iteration 4832 : loss : 0.027667, loss_ce: 0.008950
2022-01-20 21:51:04,805 iteration 4833 : loss : 0.025670, loss_ce: 0.008797
2022-01-20 21:51:05,381 iteration 4834 : loss : 0.017010, loss_ce: 0.005576
2022-01-20 21:51:06,136 iteration 4835 : loss : 0.021736, loss_ce: 0.010717
2022-01-20 21:51:06,789 iteration 4836 : loss : 0.023085, loss_ce: 0.007077
2022-01-20 21:51:07,477 iteration 4837 : loss : 0.018321, loss_ce: 0.005328
2022-01-20 21:51:08,088 iteration 4838 : loss : 0.017136, loss_ce: 0.005364
2022-01-20 21:51:08,747 iteration 4839 : loss : 0.026804, loss_ce: 0.009424
2022-01-20 21:51:09,381 iteration 4840 : loss : 0.017327, loss_ce: 0.008035
2022-01-20 21:51:09,943 iteration 4841 : loss : 0.012042, loss_ce: 0.003852
2022-01-20 21:51:10,581 iteration 4842 : loss : 0.021637, loss_ce: 0.007728
2022-01-20 21:51:11,311 iteration 4843 : loss : 0.019764, loss_ce: 0.006134
2022-01-20 21:51:11,951 iteration 4844 : loss : 0.024771, loss_ce: 0.008775
2022-01-20 21:51:11,951 Training Data Eval:
2022-01-20 21:51:14,848   Average segmentation loss on training set: 0.0120
2022-01-20 21:51:14,848 Validation Data Eval:
2022-01-20 21:51:15,806   Average segmentation loss on validation set: 0.0762
2022-01-20 21:51:16,477 iteration 4845 : loss : 0.019933, loss_ce: 0.008473
 71%|██████████████████████         | 285/400 [55:45<23:42, 12.37s/it]2022-01-20 21:51:17,113 iteration 4846 : loss : 0.019546, loss_ce: 0.008306
2022-01-20 21:51:17,710 iteration 4847 : loss : 0.016679, loss_ce: 0.005987
2022-01-20 21:51:18,391 iteration 4848 : loss : 0.025713, loss_ce: 0.012284
2022-01-20 21:51:19,058 iteration 4849 : loss : 0.021468, loss_ce: 0.006856
2022-01-20 21:51:19,667 iteration 4850 : loss : 0.019894, loss_ce: 0.005189
2022-01-20 21:51:20,422 iteration 4851 : loss : 0.021938, loss_ce: 0.011121
2022-01-20 21:51:21,048 iteration 4852 : loss : 0.018807, loss_ce: 0.006357
2022-01-20 21:51:21,695 iteration 4853 : loss : 0.018862, loss_ce: 0.007938
2022-01-20 21:51:22,342 iteration 4854 : loss : 0.016995, loss_ce: 0.006438
2022-01-20 21:51:22,949 iteration 4855 : loss : 0.022279, loss_ce: 0.006352
2022-01-20 21:51:23,677 iteration 4856 : loss : 0.039763, loss_ce: 0.018806
2022-01-20 21:51:24,286 iteration 4857 : loss : 0.013428, loss_ce: 0.004858
2022-01-20 21:51:25,005 iteration 4858 : loss : 0.016723, loss_ce: 0.005935
2022-01-20 21:51:25,583 iteration 4859 : loss : 0.013204, loss_ce: 0.005317
2022-01-20 21:51:26,271 iteration 4860 : loss : 0.019678, loss_ce: 0.008638
2022-01-20 21:51:26,884 iteration 4861 : loss : 0.023657, loss_ce: 0.008399
2022-01-20 21:51:27,565 iteration 4862 : loss : 0.018387, loss_ce: 0.009215
 72%|██████████████████████▏        | 286/400 [55:56<22:45, 11.98s/it]2022-01-20 21:51:28,323 iteration 4863 : loss : 0.019148, loss_ce: 0.006215
2022-01-20 21:51:28,955 iteration 4864 : loss : 0.015970, loss_ce: 0.005852
2022-01-20 21:51:29,568 iteration 4865 : loss : 0.015669, loss_ce: 0.007479
2022-01-20 21:51:30,275 iteration 4866 : loss : 0.026945, loss_ce: 0.008247
2022-01-20 21:51:30,927 iteration 4867 : loss : 0.016545, loss_ce: 0.006043
2022-01-20 21:51:31,469 iteration 4868 : loss : 0.015440, loss_ce: 0.006678
2022-01-20 21:51:32,214 iteration 4869 : loss : 0.033992, loss_ce: 0.014703
2022-01-20 21:51:32,855 iteration 4870 : loss : 0.014877, loss_ce: 0.005137
2022-01-20 21:51:33,602 iteration 4871 : loss : 0.022786, loss_ce: 0.007786
2022-01-20 21:51:34,175 iteration 4872 : loss : 0.012592, loss_ce: 0.003885
2022-01-20 21:51:34,914 iteration 4873 : loss : 0.016109, loss_ce: 0.006249
2022-01-20 21:51:35,577 iteration 4874 : loss : 0.022603, loss_ce: 0.006486
2022-01-20 21:51:36,198 iteration 4875 : loss : 0.019974, loss_ce: 0.007090
2022-01-20 21:51:36,748 iteration 4876 : loss : 0.020363, loss_ce: 0.006074
2022-01-20 21:51:37,431 iteration 4877 : loss : 0.023101, loss_ce: 0.011851
2022-01-20 21:51:38,151 iteration 4878 : loss : 0.030187, loss_ce: 0.009345
2022-01-20 21:51:38,788 iteration 4879 : loss : 0.014851, loss_ce: 0.005104
 72%|██████████████████████▏        | 287/400 [56:08<22:08, 11.75s/it]2022-01-20 21:51:39,436 iteration 4880 : loss : 0.017404, loss_ce: 0.006850
2022-01-20 21:51:40,013 iteration 4881 : loss : 0.016991, loss_ce: 0.007125
2022-01-20 21:51:40,557 iteration 4882 : loss : 0.013996, loss_ce: 0.006061
2022-01-20 21:51:41,210 iteration 4883 : loss : 0.017749, loss_ce: 0.007711
2022-01-20 21:51:41,881 iteration 4884 : loss : 0.019419, loss_ce: 0.005395
2022-01-20 21:51:42,408 iteration 4885 : loss : 0.014800, loss_ce: 0.005713
2022-01-20 21:51:43,032 iteration 4886 : loss : 0.019602, loss_ce: 0.005138
2022-01-20 21:51:43,601 iteration 4887 : loss : 0.014138, loss_ce: 0.004264
2022-01-20 21:51:44,252 iteration 4888 : loss : 0.020179, loss_ce: 0.005557
2022-01-20 21:51:44,888 iteration 4889 : loss : 0.025923, loss_ce: 0.013108
2022-01-20 21:51:45,473 iteration 4890 : loss : 0.015589, loss_ce: 0.007761
2022-01-20 21:51:45,990 iteration 4891 : loss : 0.013209, loss_ce: 0.004702
2022-01-20 21:51:46,654 iteration 4892 : loss : 0.015693, loss_ce: 0.006222
2022-01-20 21:51:47,285 iteration 4893 : loss : 0.019285, loss_ce: 0.008145
2022-01-20 21:51:47,899 iteration 4894 : loss : 0.015567, loss_ce: 0.007322
2022-01-20 21:51:48,509 iteration 4895 : loss : 0.017015, loss_ce: 0.003787
2022-01-20 21:51:49,096 iteration 4896 : loss : 0.024221, loss_ce: 0.008183
 72%|██████████████████████▎        | 288/400 [56:18<21:07, 11.32s/it]2022-01-20 21:51:49,737 iteration 4897 : loss : 0.017030, loss_ce: 0.006190
2022-01-20 21:51:50,434 iteration 4898 : loss : 0.024321, loss_ce: 0.011933
2022-01-20 21:51:51,074 iteration 4899 : loss : 0.014273, loss_ce: 0.004090
2022-01-20 21:51:51,670 iteration 4900 : loss : 0.021473, loss_ce: 0.009514
2022-01-20 21:51:52,282 iteration 4901 : loss : 0.027806, loss_ce: 0.007246
2022-01-20 21:51:52,892 iteration 4902 : loss : 0.014126, loss_ce: 0.005067
2022-01-20 21:51:53,549 iteration 4903 : loss : 0.016728, loss_ce: 0.007825
2022-01-20 21:51:54,076 iteration 4904 : loss : 0.015738, loss_ce: 0.004900
2022-01-20 21:51:54,660 iteration 4905 : loss : 0.018685, loss_ce: 0.005031
2022-01-20 21:51:55,318 iteration 4906 : loss : 0.021200, loss_ce: 0.008860
2022-01-20 21:51:55,899 iteration 4907 : loss : 0.019882, loss_ce: 0.007065
2022-01-20 21:51:56,595 iteration 4908 : loss : 0.018265, loss_ce: 0.007853
2022-01-20 21:51:57,255 iteration 4909 : loss : 0.014285, loss_ce: 0.004691
2022-01-20 21:51:57,837 iteration 4910 : loss : 0.017694, loss_ce: 0.008599
2022-01-20 21:51:58,435 iteration 4911 : loss : 0.014934, loss_ce: 0.005470
2022-01-20 21:51:59,067 iteration 4912 : loss : 0.017459, loss_ce: 0.007831
2022-01-20 21:51:59,684 iteration 4913 : loss : 0.018290, loss_ce: 0.007259
 72%|██████████████████████▍        | 289/400 [56:29<20:32, 11.10s/it]2022-01-20 21:52:00,395 iteration 4914 : loss : 0.018665, loss_ce: 0.007816
2022-01-20 21:52:00,994 iteration 4915 : loss : 0.015982, loss_ce: 0.005466
2022-01-20 21:52:01,604 iteration 4916 : loss : 0.013316, loss_ce: 0.003631
2022-01-20 21:52:02,241 iteration 4917 : loss : 0.012795, loss_ce: 0.003834
2022-01-20 21:52:02,901 iteration 4918 : loss : 0.018866, loss_ce: 0.007509
2022-01-20 21:52:03,687 iteration 4919 : loss : 0.022856, loss_ce: 0.010030
2022-01-20 21:52:04,355 iteration 4920 : loss : 0.014654, loss_ce: 0.005933
2022-01-20 21:52:04,941 iteration 4921 : loss : 0.014891, loss_ce: 0.007186
2022-01-20 21:52:05,502 iteration 4922 : loss : 0.025167, loss_ce: 0.009711
2022-01-20 21:52:06,176 iteration 4923 : loss : 0.018211, loss_ce: 0.006642
2022-01-20 21:52:06,875 iteration 4924 : loss : 0.028302, loss_ce: 0.015380
2022-01-20 21:52:07,531 iteration 4925 : loss : 0.017847, loss_ce: 0.006280
2022-01-20 21:52:08,215 iteration 4926 : loss : 0.022099, loss_ce: 0.010698
2022-01-20 21:52:08,829 iteration 4927 : loss : 0.014840, loss_ce: 0.004614
2022-01-20 21:52:09,524 iteration 4928 : loss : 0.025230, loss_ce: 0.009813
2022-01-20 21:52:10,250 iteration 4929 : loss : 0.018199, loss_ce: 0.007868
2022-01-20 21:52:10,250 Training Data Eval:
2022-01-20 21:52:13,147   Average segmentation loss on training set: 0.0108
2022-01-20 21:52:13,148 Validation Data Eval:
2022-01-20 21:52:14,105   Average segmentation loss on validation set: 0.0788
2022-01-20 21:52:14,752 iteration 4930 : loss : 0.020280, loss_ce: 0.006030
 72%|██████████████████████▍        | 290/400 [56:44<22:31, 12.29s/it]2022-01-20 21:52:15,412 iteration 4931 : loss : 0.017717, loss_ce: 0.007477
2022-01-20 21:52:16,072 iteration 4932 : loss : 0.017604, loss_ce: 0.009020
2022-01-20 21:52:16,649 iteration 4933 : loss : 0.015676, loss_ce: 0.008374
2022-01-20 21:52:17,342 iteration 4934 : loss : 0.023805, loss_ce: 0.007437
2022-01-20 21:52:17,976 iteration 4935 : loss : 0.017283, loss_ce: 0.005593
2022-01-20 21:52:18,634 iteration 4936 : loss : 0.017661, loss_ce: 0.006773
2022-01-20 21:52:19,278 iteration 4937 : loss : 0.012809, loss_ce: 0.004784
2022-01-20 21:52:19,972 iteration 4938 : loss : 0.023230, loss_ce: 0.009486
2022-01-20 21:52:20,662 iteration 4939 : loss : 0.027817, loss_ce: 0.012506
2022-01-20 21:52:21,283 iteration 4940 : loss : 0.023076, loss_ce: 0.009568
2022-01-20 21:52:21,942 iteration 4941 : loss : 0.022538, loss_ce: 0.012667
2022-01-20 21:52:22,600 iteration 4942 : loss : 0.016435, loss_ce: 0.005472
2022-01-20 21:52:23,335 iteration 4943 : loss : 0.032631, loss_ce: 0.007050
2022-01-20 21:52:23,973 iteration 4944 : loss : 0.017981, loss_ce: 0.005373
2022-01-20 21:52:24,651 iteration 4945 : loss : 0.024579, loss_ce: 0.009430
2022-01-20 21:52:25,358 iteration 4946 : loss : 0.019572, loss_ce: 0.004533
2022-01-20 21:52:25,984 iteration 4947 : loss : 0.017036, loss_ce: 0.005505
 73%|██████████████████████▌        | 291/400 [56:55<21:45, 11.97s/it]2022-01-20 21:52:26,696 iteration 4948 : loss : 0.022776, loss_ce: 0.008508
2022-01-20 21:52:27,318 iteration 4949 : loss : 0.020548, loss_ce: 0.009046
2022-01-20 21:52:28,003 iteration 4950 : loss : 0.021090, loss_ce: 0.009067
2022-01-20 21:52:28,677 iteration 4951 : loss : 0.015636, loss_ce: 0.004715
2022-01-20 21:52:29,337 iteration 4952 : loss : 0.018906, loss_ce: 0.010640
2022-01-20 21:52:30,020 iteration 4953 : loss : 0.017369, loss_ce: 0.007448
2022-01-20 21:52:30,631 iteration 4954 : loss : 0.021755, loss_ce: 0.010142
2022-01-20 21:52:31,205 iteration 4955 : loss : 0.019309, loss_ce: 0.005214
2022-01-20 21:52:31,829 iteration 4956 : loss : 0.023820, loss_ce: 0.007056
2022-01-20 21:52:32,375 iteration 4957 : loss : 0.015857, loss_ce: 0.006025
2022-01-20 21:52:33,021 iteration 4958 : loss : 0.026992, loss_ce: 0.013319
2022-01-20 21:52:33,670 iteration 4959 : loss : 0.015920, loss_ce: 0.005654
2022-01-20 21:52:34,234 iteration 4960 : loss : 0.017663, loss_ce: 0.006105
2022-01-20 21:52:34,883 iteration 4961 : loss : 0.018239, loss_ce: 0.007898
2022-01-20 21:52:35,463 iteration 4962 : loss : 0.026147, loss_ce: 0.005134
2022-01-20 21:52:36,078 iteration 4963 : loss : 0.018659, loss_ce: 0.007240
2022-01-20 21:52:36,770 iteration 4964 : loss : 0.025981, loss_ce: 0.008726
 73%|██████████████████████▋        | 292/400 [57:06<20:54, 11.62s/it]2022-01-20 21:52:37,516 iteration 4965 : loss : 0.023374, loss_ce: 0.009706
2022-01-20 21:52:38,209 iteration 4966 : loss : 0.018135, loss_ce: 0.007523
2022-01-20 21:52:38,855 iteration 4967 : loss : 0.018903, loss_ce: 0.007941
2022-01-20 21:52:39,520 iteration 4968 : loss : 0.016831, loss_ce: 0.007631
2022-01-20 21:52:40,277 iteration 4969 : loss : 0.021748, loss_ce: 0.007443
2022-01-20 21:52:40,880 iteration 4970 : loss : 0.014617, loss_ce: 0.006319
2022-01-20 21:52:41,501 iteration 4971 : loss : 0.019025, loss_ce: 0.010242
2022-01-20 21:52:42,185 iteration 4972 : loss : 0.019312, loss_ce: 0.007750
2022-01-20 21:52:42,839 iteration 4973 : loss : 0.022394, loss_ce: 0.008745
2022-01-20 21:52:43,607 iteration 4974 : loss : 0.024671, loss_ce: 0.008045
2022-01-20 21:52:44,232 iteration 4975 : loss : 0.013762, loss_ce: 0.003982
2022-01-20 21:52:44,806 iteration 4976 : loss : 0.015142, loss_ce: 0.005612
2022-01-20 21:52:45,470 iteration 4977 : loss : 0.029576, loss_ce: 0.005873
2022-01-20 21:52:46,090 iteration 4978 : loss : 0.014668, loss_ce: 0.003386
2022-01-20 21:52:46,720 iteration 4979 : loss : 0.020064, loss_ce: 0.007973
2022-01-20 21:52:47,365 iteration 4980 : loss : 0.017408, loss_ce: 0.004893
2022-01-20 21:52:47,996 iteration 4981 : loss : 0.019022, loss_ce: 0.006236
 73%|██████████████████████▋        | 293/400 [57:17<20:30, 11.50s/it]2022-01-20 21:52:48,655 iteration 4982 : loss : 0.016192, loss_ce: 0.007544
2022-01-20 21:52:49,271 iteration 4983 : loss : 0.014904, loss_ce: 0.005827
2022-01-20 21:52:50,013 iteration 4984 : loss : 0.019108, loss_ce: 0.006405
2022-01-20 21:52:50,585 iteration 4985 : loss : 0.014622, loss_ce: 0.003982
2022-01-20 21:52:51,308 iteration 4986 : loss : 0.020789, loss_ce: 0.008536
2022-01-20 21:52:51,894 iteration 4987 : loss : 0.016879, loss_ce: 0.005025
2022-01-20 21:52:52,547 iteration 4988 : loss : 0.019236, loss_ce: 0.005656
2022-01-20 21:52:53,236 iteration 4989 : loss : 0.021322, loss_ce: 0.007889
2022-01-20 21:52:53,953 iteration 4990 : loss : 0.019140, loss_ce: 0.008639
2022-01-20 21:52:54,607 iteration 4991 : loss : 0.020233, loss_ce: 0.005466
2022-01-20 21:52:55,156 iteration 4992 : loss : 0.014045, loss_ce: 0.006762
2022-01-20 21:52:55,772 iteration 4993 : loss : 0.017608, loss_ce: 0.005750
2022-01-20 21:52:56,356 iteration 4994 : loss : 0.016201, loss_ce: 0.005293
2022-01-20 21:52:56,959 iteration 4995 : loss : 0.018831, loss_ce: 0.008463
2022-01-20 21:52:57,651 iteration 4996 : loss : 0.022934, loss_ce: 0.007334
2022-01-20 21:52:58,213 iteration 4997 : loss : 0.016766, loss_ce: 0.005014
2022-01-20 21:52:58,792 iteration 4998 : loss : 0.015540, loss_ce: 0.005345
 74%|██████████████████████▊        | 294/400 [57:28<19:56, 11.29s/it]2022-01-20 21:52:59,438 iteration 4999 : loss : 0.014280, loss_ce: 0.005106
2022-01-20 21:53:00,054 iteration 5000 : loss : 0.022852, loss_ce: 0.009573
2022-01-20 21:53:00,675 iteration 5001 : loss : 0.015709, loss_ce: 0.007176
2022-01-20 21:53:01,285 iteration 5002 : loss : 0.010800, loss_ce: 0.003776
2022-01-20 21:53:01,944 iteration 5003 : loss : 0.037833, loss_ce: 0.008040
2022-01-20 21:53:02,571 iteration 5004 : loss : 0.021571, loss_ce: 0.009391
2022-01-20 21:53:03,208 iteration 5005 : loss : 0.019240, loss_ce: 0.008131
2022-01-20 21:53:03,910 iteration 5006 : loss : 0.020954, loss_ce: 0.008495
2022-01-20 21:53:04,591 iteration 5007 : loss : 0.020562, loss_ce: 0.008504
2022-01-20 21:53:05,275 iteration 5008 : loss : 0.024971, loss_ce: 0.008907
2022-01-20 21:53:05,956 iteration 5009 : loss : 0.015074, loss_ce: 0.003790
2022-01-20 21:53:06,620 iteration 5010 : loss : 0.023050, loss_ce: 0.009195
2022-01-20 21:53:07,237 iteration 5011 : loss : 0.015813, loss_ce: 0.007211
2022-01-20 21:53:07,886 iteration 5012 : loss : 0.019354, loss_ce: 0.008024
2022-01-20 21:53:08,463 iteration 5013 : loss : 0.017267, loss_ce: 0.006507
2022-01-20 21:53:09,089 iteration 5014 : loss : 0.027728, loss_ce: 0.012616
2022-01-20 21:53:09,090 Training Data Eval:
2022-01-20 21:53:11,992   Average segmentation loss on training set: 0.0105
2022-01-20 21:53:11,992 Validation Data Eval:
2022-01-20 21:53:12,949   Average segmentation loss on validation set: 0.0784
2022-01-20 21:53:13,580 iteration 5015 : loss : 0.015068, loss_ce: 0.004508
 74%|██████████████████████▊        | 295/400 [57:43<21:35, 12.34s/it]2022-01-20 21:53:14,249 iteration 5016 : loss : 0.020664, loss_ce: 0.010738
2022-01-20 21:53:14,859 iteration 5017 : loss : 0.020532, loss_ce: 0.006918
2022-01-20 21:53:15,482 iteration 5018 : loss : 0.016652, loss_ce: 0.006760
2022-01-20 21:53:16,140 iteration 5019 : loss : 0.019445, loss_ce: 0.005910
2022-01-20 21:53:16,805 iteration 5020 : loss : 0.016691, loss_ce: 0.005130
2022-01-20 21:53:17,493 iteration 5021 : loss : 0.016853, loss_ce: 0.008582
2022-01-20 21:53:18,078 iteration 5022 : loss : 0.018254, loss_ce: 0.005986
2022-01-20 21:53:18,712 iteration 5023 : loss : 0.028542, loss_ce: 0.008391
2022-01-20 21:53:19,440 iteration 5024 : loss : 0.030176, loss_ce: 0.006242
2022-01-20 21:53:20,156 iteration 5025 : loss : 0.034065, loss_ce: 0.007999
2022-01-20 21:53:20,811 iteration 5026 : loss : 0.016106, loss_ce: 0.005895
2022-01-20 21:53:21,419 iteration 5027 : loss : 0.018336, loss_ce: 0.007910
2022-01-20 21:53:22,041 iteration 5028 : loss : 0.022274, loss_ce: 0.008045
2022-01-20 21:53:22,771 iteration 5029 : loss : 0.021410, loss_ce: 0.004893
2022-01-20 21:53:23,408 iteration 5030 : loss : 0.018754, loss_ce: 0.009452
2022-01-20 21:53:24,114 iteration 5031 : loss : 0.024604, loss_ce: 0.012499
2022-01-20 21:53:24,760 iteration 5032 : loss : 0.017083, loss_ce: 0.008330
 74%|██████████████████████▉        | 296/400 [57:54<20:47, 11.99s/it]2022-01-20 21:53:25,553 iteration 5033 : loss : 0.028934, loss_ce: 0.010715
2022-01-20 21:53:26,175 iteration 5034 : loss : 0.023522, loss_ce: 0.006958
2022-01-20 21:53:26,781 iteration 5035 : loss : 0.017762, loss_ce: 0.007962
2022-01-20 21:53:27,392 iteration 5036 : loss : 0.017408, loss_ce: 0.006701
2022-01-20 21:53:28,032 iteration 5037 : loss : 0.028375, loss_ce: 0.009660
2022-01-20 21:53:28,638 iteration 5038 : loss : 0.021366, loss_ce: 0.004868
2022-01-20 21:53:29,354 iteration 5039 : loss : 0.022049, loss_ce: 0.010394
2022-01-20 21:53:30,000 iteration 5040 : loss : 0.016476, loss_ce: 0.005056
2022-01-20 21:53:30,712 iteration 5041 : loss : 0.018284, loss_ce: 0.006092
2022-01-20 21:53:31,316 iteration 5042 : loss : 0.015556, loss_ce: 0.006017
2022-01-20 21:53:31,957 iteration 5043 : loss : 0.018221, loss_ce: 0.008190
2022-01-20 21:53:32,598 iteration 5044 : loss : 0.019782, loss_ce: 0.008852
2022-01-20 21:53:33,284 iteration 5045 : loss : 0.026414, loss_ce: 0.010297
2022-01-20 21:53:33,940 iteration 5046 : loss : 0.022599, loss_ce: 0.005450
2022-01-20 21:53:34,561 iteration 5047 : loss : 0.025469, loss_ce: 0.006984
2022-01-20 21:53:35,170 iteration 5048 : loss : 0.019815, loss_ce: 0.008274
2022-01-20 21:53:35,781 iteration 5049 : loss : 0.014084, loss_ce: 0.005645
 74%|███████████████████████        | 297/400 [58:05<20:05, 11.70s/it]2022-01-20 21:53:36,509 iteration 5050 : loss : 0.021260, loss_ce: 0.006405
2022-01-20 21:53:37,142 iteration 5051 : loss : 0.023238, loss_ce: 0.008267
2022-01-20 21:53:37,780 iteration 5052 : loss : 0.016144, loss_ce: 0.007058
2022-01-20 21:53:38,404 iteration 5053 : loss : 0.018911, loss_ce: 0.007571
2022-01-20 21:53:39,047 iteration 5054 : loss : 0.021686, loss_ce: 0.006435
2022-01-20 21:53:39,670 iteration 5055 : loss : 0.017507, loss_ce: 0.005728
2022-01-20 21:53:40,283 iteration 5056 : loss : 0.022679, loss_ce: 0.005309
2022-01-20 21:53:40,974 iteration 5057 : loss : 0.015933, loss_ce: 0.008143
2022-01-20 21:53:41,675 iteration 5058 : loss : 0.023632, loss_ce: 0.010527
2022-01-20 21:53:42,196 iteration 5059 : loss : 0.017222, loss_ce: 0.004429
2022-01-20 21:53:42,828 iteration 5060 : loss : 0.027869, loss_ce: 0.007691
2022-01-20 21:53:43,499 iteration 5061 : loss : 0.015254, loss_ce: 0.005954
2022-01-20 21:53:44,163 iteration 5062 : loss : 0.027965, loss_ce: 0.007880
2022-01-20 21:53:44,875 iteration 5063 : loss : 0.018374, loss_ce: 0.007099
2022-01-20 21:53:45,482 iteration 5064 : loss : 0.016658, loss_ce: 0.006033
2022-01-20 21:53:46,094 iteration 5065 : loss : 0.019364, loss_ce: 0.007018
2022-01-20 21:53:46,745 iteration 5066 : loss : 0.014312, loss_ce: 0.007315
 74%|███████████████████████        | 298/400 [58:16<19:30, 11.48s/it]2022-01-20 21:53:47,524 iteration 5067 : loss : 0.029318, loss_ce: 0.010442
2022-01-20 21:53:48,189 iteration 5068 : loss : 0.019746, loss_ce: 0.007306
2022-01-20 21:53:48,847 iteration 5069 : loss : 0.019243, loss_ce: 0.005785
2022-01-20 21:53:49,472 iteration 5070 : loss : 0.018975, loss_ce: 0.006202
2022-01-20 21:53:50,173 iteration 5071 : loss : 0.020348, loss_ce: 0.008566
2022-01-20 21:53:50,697 iteration 5072 : loss : 0.014091, loss_ce: 0.004936
2022-01-20 21:53:51,323 iteration 5073 : loss : 0.017857, loss_ce: 0.008934
2022-01-20 21:53:51,998 iteration 5074 : loss : 0.018287, loss_ce: 0.005957
2022-01-20 21:53:52,645 iteration 5075 : loss : 0.014732, loss_ce: 0.005945
2022-01-20 21:53:53,343 iteration 5076 : loss : 0.019871, loss_ce: 0.009526
2022-01-20 21:53:53,954 iteration 5077 : loss : 0.016107, loss_ce: 0.005713
2022-01-20 21:53:54,602 iteration 5078 : loss : 0.014108, loss_ce: 0.003715
2022-01-20 21:53:55,216 iteration 5079 : loss : 0.021662, loss_ce: 0.008212
2022-01-20 21:53:55,862 iteration 5080 : loss : 0.018831, loss_ce: 0.005616
2022-01-20 21:53:56,532 iteration 5081 : loss : 0.020337, loss_ce: 0.008471
2022-01-20 21:53:57,226 iteration 5082 : loss : 0.026622, loss_ce: 0.013064
2022-01-20 21:53:57,888 iteration 5083 : loss : 0.018608, loss_ce: 0.005854
 75%|███████████████████████▏       | 299/400 [58:27<19:09, 11.38s/it]2022-01-20 21:53:58,547 iteration 5084 : loss : 0.014288, loss_ce: 0.004985
2022-01-20 21:53:59,194 iteration 5085 : loss : 0.022446, loss_ce: 0.008633
2022-01-20 21:53:59,807 iteration 5086 : loss : 0.015945, loss_ce: 0.005678
2022-01-20 21:54:00,505 iteration 5087 : loss : 0.024443, loss_ce: 0.008525
2022-01-20 21:54:01,167 iteration 5088 : loss : 0.016776, loss_ce: 0.005561
2022-01-20 21:54:01,760 iteration 5089 : loss : 0.015918, loss_ce: 0.004692
2022-01-20 21:54:02,368 iteration 5090 : loss : 0.013217, loss_ce: 0.004535
2022-01-20 21:54:03,105 iteration 5091 : loss : 0.025967, loss_ce: 0.009749
2022-01-20 21:54:03,746 iteration 5092 : loss : 0.012701, loss_ce: 0.005826
2022-01-20 21:54:04,349 iteration 5093 : loss : 0.017021, loss_ce: 0.007426
2022-01-20 21:54:04,927 iteration 5094 : loss : 0.014149, loss_ce: 0.005045
2022-01-20 21:54:05,611 iteration 5095 : loss : 0.027007, loss_ce: 0.008724
2022-01-20 21:54:06,205 iteration 5096 : loss : 0.013763, loss_ce: 0.005158
2022-01-20 21:54:06,808 iteration 5097 : loss : 0.015948, loss_ce: 0.006941
2022-01-20 21:54:07,466 iteration 5098 : loss : 0.024710, loss_ce: 0.008413
2022-01-20 21:54:08,095 iteration 5099 : loss : 0.014366, loss_ce: 0.004686
2022-01-20 21:54:08,096 Training Data Eval:
2022-01-20 21:54:10,998   Average segmentation loss on training set: 0.0112
2022-01-20 21:54:10,998 Validation Data Eval:
2022-01-20 21:54:11,948   Average segmentation loss on validation set: 0.0718
2022-01-20 21:54:12,574 iteration 5100 : loss : 0.014405, loss_ce: 0.006215
 75%|███████████████████████▎       | 300/400 [58:42<20:37, 12.37s/it]2022-01-20 21:54:13,264 iteration 5101 : loss : 0.020705, loss_ce: 0.010758
2022-01-20 21:54:13,865 iteration 5102 : loss : 0.012169, loss_ce: 0.004408
2022-01-20 21:54:14,489 iteration 5103 : loss : 0.018301, loss_ce: 0.007223
2022-01-20 21:54:15,189 iteration 5104 : loss : 0.017105, loss_ce: 0.006843
2022-01-20 21:54:15,775 iteration 5105 : loss : 0.015756, loss_ce: 0.005307
2022-01-20 21:54:16,489 iteration 5106 : loss : 0.017145, loss_ce: 0.006585
2022-01-20 21:54:17,082 iteration 5107 : loss : 0.014585, loss_ce: 0.005467
2022-01-20 21:54:17,753 iteration 5108 : loss : 0.020391, loss_ce: 0.006856
2022-01-20 21:54:18,396 iteration 5109 : loss : 0.029462, loss_ce: 0.010604
2022-01-20 21:54:19,024 iteration 5110 : loss : 0.021177, loss_ce: 0.009668
2022-01-20 21:54:19,696 iteration 5111 : loss : 0.016435, loss_ce: 0.006193
2022-01-20 21:54:20,284 iteration 5112 : loss : 0.018428, loss_ce: 0.005395
2022-01-20 21:54:20,979 iteration 5113 : loss : 0.027702, loss_ce: 0.004041
2022-01-20 21:54:21,596 iteration 5114 : loss : 0.015965, loss_ce: 0.007830
2022-01-20 21:54:22,193 iteration 5115 : loss : 0.033817, loss_ce: 0.011136
2022-01-20 21:54:22,798 iteration 5116 : loss : 0.015605, loss_ce: 0.006137
2022-01-20 21:54:23,495 iteration 5117 : loss : 0.021724, loss_ce: 0.009032
 75%|███████████████████████▎       | 301/400 [58:52<19:41, 11.94s/it]2022-01-20 21:54:24,178 iteration 5118 : loss : 0.010377, loss_ce: 0.003849
2022-01-20 21:54:24,824 iteration 5119 : loss : 0.023116, loss_ce: 0.007850
2022-01-20 21:54:25,424 iteration 5120 : loss : 0.030605, loss_ce: 0.010064
2022-01-20 21:54:26,056 iteration 5121 : loss : 0.019902, loss_ce: 0.008230
2022-01-20 21:54:26,647 iteration 5122 : loss : 0.016135, loss_ce: 0.006084
2022-01-20 21:54:27,270 iteration 5123 : loss : 0.023424, loss_ce: 0.006520
2022-01-20 21:54:27,934 iteration 5124 : loss : 0.019655, loss_ce: 0.007933
2022-01-20 21:54:28,478 iteration 5125 : loss : 0.018501, loss_ce: 0.008963
2022-01-20 21:54:29,060 iteration 5126 : loss : 0.020824, loss_ce: 0.006796
2022-01-20 21:54:29,742 iteration 5127 : loss : 0.021071, loss_ce: 0.006523
2022-01-20 21:54:30,355 iteration 5128 : loss : 0.013603, loss_ce: 0.005508
2022-01-20 21:54:31,017 iteration 5129 : loss : 0.018332, loss_ce: 0.005694
2022-01-20 21:54:31,660 iteration 5130 : loss : 0.017536, loss_ce: 0.005213
2022-01-20 21:54:32,214 iteration 5131 : loss : 0.011236, loss_ce: 0.004048
2022-01-20 21:54:32,842 iteration 5132 : loss : 0.019207, loss_ce: 0.008805
2022-01-20 21:54:33,440 iteration 5133 : loss : 0.017600, loss_ce: 0.005273
2022-01-20 21:54:34,020 iteration 5134 : loss : 0.018212, loss_ce: 0.007747
 76%|███████████████████████▍       | 302/400 [59:03<18:48, 11.51s/it]2022-01-20 21:54:34,839 iteration 5135 : loss : 0.033173, loss_ce: 0.014840
2022-01-20 21:54:35,467 iteration 5136 : loss : 0.018215, loss_ce: 0.005828
2022-01-20 21:54:36,148 iteration 5137 : loss : 0.016519, loss_ce: 0.004802
2022-01-20 21:54:36,744 iteration 5138 : loss : 0.017048, loss_ce: 0.006939
2022-01-20 21:54:37,376 iteration 5139 : loss : 0.013610, loss_ce: 0.005033
2022-01-20 21:54:38,100 iteration 5140 : loss : 0.017097, loss_ce: 0.006911
2022-01-20 21:54:38,693 iteration 5141 : loss : 0.022291, loss_ce: 0.007928
2022-01-20 21:54:39,345 iteration 5142 : loss : 0.024413, loss_ce: 0.008815
2022-01-20 21:54:39,903 iteration 5143 : loss : 0.015878, loss_ce: 0.006104
2022-01-20 21:54:40,568 iteration 5144 : loss : 0.017337, loss_ce: 0.009348
2022-01-20 21:54:41,121 iteration 5145 : loss : 0.012482, loss_ce: 0.004113
2022-01-20 21:54:41,824 iteration 5146 : loss : 0.023771, loss_ce: 0.009226
2022-01-20 21:54:42,537 iteration 5147 : loss : 0.018040, loss_ce: 0.005703
2022-01-20 21:54:43,157 iteration 5148 : loss : 0.014410, loss_ce: 0.006009
2022-01-20 21:54:43,778 iteration 5149 : loss : 0.026457, loss_ce: 0.007001
2022-01-20 21:54:44,397 iteration 5150 : loss : 0.019499, loss_ce: 0.009663
2022-01-20 21:54:45,045 iteration 5151 : loss : 0.026953, loss_ce: 0.005048
 76%|███████████████████████▍       | 303/400 [59:14<18:22, 11.37s/it]2022-01-20 21:54:45,677 iteration 5152 : loss : 0.012606, loss_ce: 0.003177
2022-01-20 21:54:46,220 iteration 5153 : loss : 0.012175, loss_ce: 0.004744
2022-01-20 21:54:46,926 iteration 5154 : loss : 0.023307, loss_ce: 0.010933
2022-01-20 21:54:47,501 iteration 5155 : loss : 0.012349, loss_ce: 0.004253
2022-01-20 21:54:48,122 iteration 5156 : loss : 0.020985, loss_ce: 0.009132
2022-01-20 21:54:48,691 iteration 5157 : loss : 0.014629, loss_ce: 0.004598
2022-01-20 21:54:49,305 iteration 5158 : loss : 0.018023, loss_ce: 0.006439
2022-01-20 21:54:49,996 iteration 5159 : loss : 0.021246, loss_ce: 0.006589
2022-01-20 21:54:50,572 iteration 5160 : loss : 0.012221, loss_ce: 0.004451
2022-01-20 21:54:51,195 iteration 5161 : loss : 0.014798, loss_ce: 0.005788
2022-01-20 21:54:51,770 iteration 5162 : loss : 0.016613, loss_ce: 0.006952
2022-01-20 21:54:52,416 iteration 5163 : loss : 0.015876, loss_ce: 0.006432
2022-01-20 21:54:53,061 iteration 5164 : loss : 0.015575, loss_ce: 0.007262
2022-01-20 21:54:53,624 iteration 5165 : loss : 0.017328, loss_ce: 0.005526
2022-01-20 21:54:54,245 iteration 5166 : loss : 0.015954, loss_ce: 0.006600
2022-01-20 21:54:54,884 iteration 5167 : loss : 0.022492, loss_ce: 0.007636
2022-01-20 21:54:55,562 iteration 5168 : loss : 0.017379, loss_ce: 0.006124
 76%|███████████████████████▌       | 304/400 [59:24<17:46, 11.11s/it]2022-01-20 21:54:56,339 iteration 5169 : loss : 0.027319, loss_ce: 0.009637
2022-01-20 21:54:56,917 iteration 5170 : loss : 0.020324, loss_ce: 0.005602
2022-01-20 21:54:57,614 iteration 5171 : loss : 0.017832, loss_ce: 0.007528
2022-01-20 21:54:58,177 iteration 5172 : loss : 0.013912, loss_ce: 0.004210
2022-01-20 21:54:58,678 iteration 5173 : loss : 0.012868, loss_ce: 0.005322
2022-01-20 21:54:59,386 iteration 5174 : loss : 0.022847, loss_ce: 0.008965
2022-01-20 21:54:59,983 iteration 5175 : loss : 0.015680, loss_ce: 0.007152
2022-01-20 21:55:00,746 iteration 5176 : loss : 0.017787, loss_ce: 0.006342
2022-01-20 21:55:01,336 iteration 5177 : loss : 0.016112, loss_ce: 0.006566
2022-01-20 21:55:01,950 iteration 5178 : loss : 0.014567, loss_ce: 0.004478
2022-01-20 21:55:02,631 iteration 5179 : loss : 0.020706, loss_ce: 0.006206
2022-01-20 21:55:03,260 iteration 5180 : loss : 0.016578, loss_ce: 0.005646
2022-01-20 21:55:03,843 iteration 5181 : loss : 0.014555, loss_ce: 0.003167
2022-01-20 21:55:04,468 iteration 5182 : loss : 0.017368, loss_ce: 0.006269
2022-01-20 21:55:05,071 iteration 5183 : loss : 0.016989, loss_ce: 0.007468
2022-01-20 21:55:05,660 iteration 5184 : loss : 0.019325, loss_ce: 0.007136
2022-01-20 21:55:05,660 Training Data Eval:
2022-01-20 21:55:08,555   Average segmentation loss on training set: 0.0106
2022-01-20 21:55:08,555 Validation Data Eval:
2022-01-20 21:55:09,505   Average segmentation loss on validation set: 0.0753
2022-01-20 21:55:10,121 iteration 5185 : loss : 0.017222, loss_ce: 0.006383
 76%|███████████████████████▋       | 305/400 [59:39<19:13, 12.15s/it]2022-01-20 21:55:10,815 iteration 5186 : loss : 0.016381, loss_ce: 0.007247
2022-01-20 21:55:11,394 iteration 5187 : loss : 0.017102, loss_ce: 0.006783
2022-01-20 21:55:11,985 iteration 5188 : loss : 0.014489, loss_ce: 0.005817
2022-01-20 21:55:12,581 iteration 5189 : loss : 0.016063, loss_ce: 0.006722
2022-01-20 21:55:13,160 iteration 5190 : loss : 0.017345, loss_ce: 0.007101
2022-01-20 21:55:13,839 iteration 5191 : loss : 0.021227, loss_ce: 0.005594
2022-01-20 21:55:14,502 iteration 5192 : loss : 0.019175, loss_ce: 0.005802
2022-01-20 21:55:15,080 iteration 5193 : loss : 0.011107, loss_ce: 0.003599
2022-01-20 21:55:15,739 iteration 5194 : loss : 0.019917, loss_ce: 0.007457
2022-01-20 21:55:16,337 iteration 5195 : loss : 0.015130, loss_ce: 0.004840
2022-01-20 21:55:16,864 iteration 5196 : loss : 0.011653, loss_ce: 0.003161
2022-01-20 21:55:17,425 iteration 5197 : loss : 0.015655, loss_ce: 0.004768
2022-01-20 21:55:18,008 iteration 5198 : loss : 0.013818, loss_ce: 0.006091
2022-01-20 21:55:18,665 iteration 5199 : loss : 0.012330, loss_ce: 0.004586
2022-01-20 21:55:19,282 iteration 5200 : loss : 0.021538, loss_ce: 0.006288
2022-01-20 21:55:19,922 iteration 5201 : loss : 0.015581, loss_ce: 0.004669
2022-01-20 21:55:20,627 iteration 5202 : loss : 0.019419, loss_ce: 0.008428
 76%|███████████████████████▋       | 306/400 [59:50<18:15, 11.65s/it]2022-01-20 21:55:21,262 iteration 5203 : loss : 0.011819, loss_ce: 0.004221
2022-01-20 21:55:21,861 iteration 5204 : loss : 0.020684, loss_ce: 0.008337
2022-01-20 21:55:22,608 iteration 5205 : loss : 0.024047, loss_ce: 0.009702
2022-01-20 21:55:23,232 iteration 5206 : loss : 0.017315, loss_ce: 0.006608
2022-01-20 21:55:23,871 iteration 5207 : loss : 0.017097, loss_ce: 0.007112
2022-01-20 21:55:24,584 iteration 5208 : loss : 0.019992, loss_ce: 0.008420
2022-01-20 21:55:25,172 iteration 5209 : loss : 0.015459, loss_ce: 0.006129
2022-01-20 21:55:25,854 iteration 5210 : loss : 0.018364, loss_ce: 0.007167
2022-01-20 21:55:26,514 iteration 5211 : loss : 0.016572, loss_ce: 0.006531
2022-01-20 21:55:27,150 iteration 5212 : loss : 0.019753, loss_ce: 0.006549
2022-01-20 21:55:27,677 iteration 5213 : loss : 0.012775, loss_ce: 0.004567
2022-01-20 21:55:28,406 iteration 5214 : loss : 0.022672, loss_ce: 0.009799
2022-01-20 21:55:29,079 iteration 5215 : loss : 0.015508, loss_ce: 0.004582
2022-01-20 21:55:29,770 iteration 5216 : loss : 0.020436, loss_ce: 0.006443
2022-01-20 21:55:30,486 iteration 5217 : loss : 0.020883, loss_ce: 0.008926
2022-01-20 21:55:31,076 iteration 5218 : loss : 0.020037, loss_ce: 0.003560
2022-01-20 21:55:31,797 iteration 5219 : loss : 0.015238, loss_ce: 0.005080
 77%|██████████████████████▎      | 307/400 [1:00:01<17:50, 11.51s/it]2022-01-20 21:55:32,452 iteration 5220 : loss : 0.020556, loss_ce: 0.005583
2022-01-20 21:55:33,072 iteration 5221 : loss : 0.015599, loss_ce: 0.005825
2022-01-20 21:55:33,645 iteration 5222 : loss : 0.015413, loss_ce: 0.005521
2022-01-20 21:55:34,320 iteration 5223 : loss : 0.018389, loss_ce: 0.006732
2022-01-20 21:55:34,938 iteration 5224 : loss : 0.018416, loss_ce: 0.006031
2022-01-20 21:55:35,629 iteration 5225 : loss : 0.015577, loss_ce: 0.005495
2022-01-20 21:55:36,252 iteration 5226 : loss : 0.019817, loss_ce: 0.008376
2022-01-20 21:55:36,978 iteration 5227 : loss : 0.020731, loss_ce: 0.008078
2022-01-20 21:55:37,581 iteration 5228 : loss : 0.014585, loss_ce: 0.004539
2022-01-20 21:55:38,340 iteration 5229 : loss : 0.018211, loss_ce: 0.007501
2022-01-20 21:55:38,869 iteration 5230 : loss : 0.011449, loss_ce: 0.004996
2022-01-20 21:55:39,527 iteration 5231 : loss : 0.017145, loss_ce: 0.006697
2022-01-20 21:55:40,169 iteration 5232 : loss : 0.018828, loss_ce: 0.005725
2022-01-20 21:55:40,835 iteration 5233 : loss : 0.016303, loss_ce: 0.006860
2022-01-20 21:55:41,433 iteration 5234 : loss : 0.014909, loss_ce: 0.006341
2022-01-20 21:55:42,071 iteration 5235 : loss : 0.016010, loss_ce: 0.005548
2022-01-20 21:55:42,745 iteration 5236 : loss : 0.021472, loss_ce: 0.008874
 77%|██████████████████████▎      | 308/400 [1:00:12<17:23, 11.34s/it]2022-01-20 21:55:43,295 iteration 5237 : loss : 0.011708, loss_ce: 0.004804
2022-01-20 21:55:43,955 iteration 5238 : loss : 0.014274, loss_ce: 0.006101
2022-01-20 21:55:44,602 iteration 5239 : loss : 0.017861, loss_ce: 0.007583
2022-01-20 21:55:45,274 iteration 5240 : loss : 0.171037, loss_ce: 0.002785
2022-01-20 21:55:45,873 iteration 5241 : loss : 0.013212, loss_ce: 0.005108
2022-01-20 21:55:46,501 iteration 5242 : loss : 0.020369, loss_ce: 0.008652
2022-01-20 21:55:47,218 iteration 5243 : loss : 0.027944, loss_ce: 0.008590
2022-01-20 21:55:47,892 iteration 5244 : loss : 0.017514, loss_ce: 0.007378
2022-01-20 21:55:48,545 iteration 5245 : loss : 0.015813, loss_ce: 0.005492
2022-01-20 21:55:49,206 iteration 5246 : loss : 0.026244, loss_ce: 0.008116
2022-01-20 21:55:49,764 iteration 5247 : loss : 0.012796, loss_ce: 0.005233
2022-01-20 21:55:50,441 iteration 5248 : loss : 0.021223, loss_ce: 0.007687
2022-01-20 21:55:51,163 iteration 5249 : loss : 0.023258, loss_ce: 0.008071
2022-01-20 21:55:51,824 iteration 5250 : loss : 0.019379, loss_ce: 0.009214
2022-01-20 21:55:52,380 iteration 5251 : loss : 0.012551, loss_ce: 0.004186
2022-01-20 21:55:53,015 iteration 5252 : loss : 0.014565, loss_ce: 0.005860
2022-01-20 21:55:53,682 iteration 5253 : loss : 0.029057, loss_ce: 0.007308
 77%|██████████████████████▍      | 309/400 [1:00:23<17:00, 11.22s/it]2022-01-20 21:55:54,354 iteration 5254 : loss : 0.011005, loss_ce: 0.003722
2022-01-20 21:55:54,986 iteration 5255 : loss : 0.016915, loss_ce: 0.008489
2022-01-20 21:55:55,555 iteration 5256 : loss : 0.012823, loss_ce: 0.005178
2022-01-20 21:55:56,196 iteration 5257 : loss : 0.014846, loss_ce: 0.006044
2022-01-20 21:55:56,872 iteration 5258 : loss : 0.018235, loss_ce: 0.004275
2022-01-20 21:55:57,454 iteration 5259 : loss : 0.017775, loss_ce: 0.004936
2022-01-20 21:55:58,100 iteration 5260 : loss : 0.014582, loss_ce: 0.005408
2022-01-20 21:55:58,756 iteration 5261 : loss : 0.025737, loss_ce: 0.010367
2022-01-20 21:55:59,389 iteration 5262 : loss : 0.011211, loss_ce: 0.004397
2022-01-20 21:56:00,029 iteration 5263 : loss : 0.018258, loss_ce: 0.008370
2022-01-20 21:56:00,609 iteration 5264 : loss : 0.012244, loss_ce: 0.004990
2022-01-20 21:56:01,279 iteration 5265 : loss : 0.017952, loss_ce: 0.006510
2022-01-20 21:56:02,000 iteration 5266 : loss : 0.018039, loss_ce: 0.005894
2022-01-20 21:56:02,637 iteration 5267 : loss : 0.026024, loss_ce: 0.008513
2022-01-20 21:56:03,292 iteration 5268 : loss : 0.021110, loss_ce: 0.005628
2022-01-20 21:56:04,048 iteration 5269 : loss : 0.024671, loss_ce: 0.008041
2022-01-20 21:56:04,049 Training Data Eval:
2022-01-20 21:56:06,944   Average segmentation loss on training set: 0.0101
2022-01-20 21:56:06,944 Validation Data Eval:
2022-01-20 21:56:07,896   Average segmentation loss on validation set: 0.0852
2022-01-20 21:56:08,520 iteration 5270 : loss : 0.014138, loss_ce: 0.006228
 78%|██████████████████████▍      | 310/400 [1:00:37<18:27, 12.30s/it]2022-01-20 21:56:09,159 iteration 5271 : loss : 0.013734, loss_ce: 0.005502
2022-01-20 21:56:09,820 iteration 5272 : loss : 0.020829, loss_ce: 0.009267
2022-01-20 21:56:10,429 iteration 5273 : loss : 0.014079, loss_ce: 0.004082
2022-01-20 21:56:11,044 iteration 5274 : loss : 0.014912, loss_ce: 0.005492
2022-01-20 21:56:11,597 iteration 5275 : loss : 0.012624, loss_ce: 0.005445
2022-01-20 21:56:12,257 iteration 5276 : loss : 0.016012, loss_ce: 0.006482
2022-01-20 21:56:12,890 iteration 5277 : loss : 0.016053, loss_ce: 0.006323
2022-01-20 21:56:13,436 iteration 5278 : loss : 0.013748, loss_ce: 0.005144
2022-01-20 21:56:14,062 iteration 5279 : loss : 0.013622, loss_ce: 0.005811
2022-01-20 21:56:14,824 iteration 5280 : loss : 0.022546, loss_ce: 0.009682
2022-01-20 21:56:15,441 iteration 5281 : loss : 0.016430, loss_ce: 0.005826
2022-01-20 21:56:16,005 iteration 5282 : loss : 0.012189, loss_ce: 0.003645
2022-01-20 21:56:16,638 iteration 5283 : loss : 0.024169, loss_ce: 0.007713
2022-01-20 21:56:17,287 iteration 5284 : loss : 0.021263, loss_ce: 0.005757
2022-01-20 21:56:17,908 iteration 5285 : loss : 0.015120, loss_ce: 0.006187
2022-01-20 21:56:18,454 iteration 5286 : loss : 0.013336, loss_ce: 0.005513
2022-01-20 21:56:19,065 iteration 5287 : loss : 0.014411, loss_ce: 0.002917
 78%|██████████████████████▌      | 311/400 [1:00:48<17:28, 11.78s/it]2022-01-20 21:56:19,769 iteration 5288 : loss : 0.017270, loss_ce: 0.007055
2022-01-20 21:56:20,442 iteration 5289 : loss : 0.022981, loss_ce: 0.006612
2022-01-20 21:56:21,067 iteration 5290 : loss : 0.024038, loss_ce: 0.006474
2022-01-20 21:56:21,676 iteration 5291 : loss : 0.020815, loss_ce: 0.006982
2022-01-20 21:56:22,351 iteration 5292 : loss : 0.015515, loss_ce: 0.005418
2022-01-20 21:56:23,006 iteration 5293 : loss : 0.017005, loss_ce: 0.007460
2022-01-20 21:56:23,690 iteration 5294 : loss : 0.020153, loss_ce: 0.007618
2022-01-20 21:56:24,415 iteration 5295 : loss : 0.022788, loss_ce: 0.008129
2022-01-20 21:56:25,089 iteration 5296 : loss : 0.031467, loss_ce: 0.007591
2022-01-20 21:56:25,766 iteration 5297 : loss : 0.012922, loss_ce: 0.003914
2022-01-20 21:56:26,442 iteration 5298 : loss : 0.021981, loss_ce: 0.008888
2022-01-20 21:56:27,123 iteration 5299 : loss : 0.015393, loss_ce: 0.005505
2022-01-20 21:56:27,822 iteration 5300 : loss : 0.017370, loss_ce: 0.005981
2022-01-20 21:56:28,400 iteration 5301 : loss : 0.014009, loss_ce: 0.005248
2022-01-20 21:56:28,979 iteration 5302 : loss : 0.013910, loss_ce: 0.006881
2022-01-20 21:56:29,567 iteration 5303 : loss : 0.013419, loss_ce: 0.004942
2022-01-20 21:56:30,125 iteration 5304 : loss : 0.015434, loss_ce: 0.005617
 78%|██████████████████████▌      | 312/400 [1:00:59<16:57, 11.56s/it]2022-01-20 21:56:30,820 iteration 5305 : loss : 0.018850, loss_ce: 0.006804
2022-01-20 21:56:31,563 iteration 5306 : loss : 0.021640, loss_ce: 0.009100
2022-01-20 21:56:32,322 iteration 5307 : loss : 0.020789, loss_ce: 0.007422
2022-01-20 21:56:33,036 iteration 5308 : loss : 0.025557, loss_ce: 0.008805
2022-01-20 21:56:33,735 iteration 5309 : loss : 0.022069, loss_ce: 0.007562
2022-01-20 21:56:34,343 iteration 5310 : loss : 0.020170, loss_ce: 0.008988
2022-01-20 21:56:34,936 iteration 5311 : loss : 0.023830, loss_ce: 0.005613
2022-01-20 21:56:35,629 iteration 5312 : loss : 0.019283, loss_ce: 0.009323
2022-01-20 21:56:36,382 iteration 5313 : loss : 0.021826, loss_ce: 0.008030
2022-01-20 21:56:37,039 iteration 5314 : loss : 0.015960, loss_ce: 0.005241
2022-01-20 21:56:37,739 iteration 5315 : loss : 0.026353, loss_ce: 0.006244
2022-01-20 21:56:38,424 iteration 5316 : loss : 0.025413, loss_ce: 0.009650
2022-01-20 21:56:39,061 iteration 5317 : loss : 0.016801, loss_ce: 0.007299
2022-01-20 21:56:39,671 iteration 5318 : loss : 0.011782, loss_ce: 0.004546
2022-01-20 21:56:40,376 iteration 5319 : loss : 0.019925, loss_ce: 0.007598
2022-01-20 21:56:41,068 iteration 5320 : loss : 0.022333, loss_ce: 0.010075
2022-01-20 21:56:41,783 iteration 5321 : loss : 0.023096, loss_ce: 0.008856
 78%|██████████████████████▋      | 313/400 [1:01:11<16:48, 11.59s/it]2022-01-20 21:56:42,387 iteration 5322 : loss : 0.012249, loss_ce: 0.004937
2022-01-20 21:56:43,041 iteration 5323 : loss : 0.019891, loss_ce: 0.008373
2022-01-20 21:56:43,614 iteration 5324 : loss : 0.019352, loss_ce: 0.006198
2022-01-20 21:56:44,214 iteration 5325 : loss : 0.015142, loss_ce: 0.003429
2022-01-20 21:56:44,884 iteration 5326 : loss : 0.018389, loss_ce: 0.006400
2022-01-20 21:56:45,482 iteration 5327 : loss : 0.017642, loss_ce: 0.006396
2022-01-20 21:56:46,102 iteration 5328 : loss : 0.016051, loss_ce: 0.008647
2022-01-20 21:56:46,786 iteration 5329 : loss : 0.029032, loss_ce: 0.010572
2022-01-20 21:56:47,445 iteration 5330 : loss : 0.020183, loss_ce: 0.007548
2022-01-20 21:56:48,074 iteration 5331 : loss : 0.020929, loss_ce: 0.006413
2022-01-20 21:56:48,717 iteration 5332 : loss : 0.015013, loss_ce: 0.004997
2022-01-20 21:56:49,391 iteration 5333 : loss : 0.018708, loss_ce: 0.010040
2022-01-20 21:56:50,052 iteration 5334 : loss : 0.023825, loss_ce: 0.009851
2022-01-20 21:56:50,732 iteration 5335 : loss : 0.019058, loss_ce: 0.005741
2022-01-20 21:56:51,385 iteration 5336 : loss : 0.020551, loss_ce: 0.008870
2022-01-20 21:56:51,988 iteration 5337 : loss : 0.012277, loss_ce: 0.004735
2022-01-20 21:56:52,590 iteration 5338 : loss : 0.014851, loss_ce: 0.006368
 78%|██████████████████████▊      | 314/400 [1:01:22<16:16, 11.35s/it]2022-01-20 21:56:53,442 iteration 5339 : loss : 0.024420, loss_ce: 0.009583
2022-01-20 21:56:54,139 iteration 5340 : loss : 0.021677, loss_ce: 0.012332
2022-01-20 21:56:54,803 iteration 5341 : loss : 0.019514, loss_ce: 0.003540
2022-01-20 21:56:55,454 iteration 5342 : loss : 0.015351, loss_ce: 0.008373
2022-01-20 21:56:56,063 iteration 5343 : loss : 0.013790, loss_ce: 0.004465
2022-01-20 21:56:56,718 iteration 5344 : loss : 0.016186, loss_ce: 0.005766
2022-01-20 21:56:57,346 iteration 5345 : loss : 0.015832, loss_ce: 0.005479
2022-01-20 21:56:58,031 iteration 5346 : loss : 0.027076, loss_ce: 0.010034
2022-01-20 21:56:58,727 iteration 5347 : loss : 0.017501, loss_ce: 0.005143
2022-01-20 21:56:59,429 iteration 5348 : loss : 0.018211, loss_ce: 0.004994
2022-01-20 21:57:00,092 iteration 5349 : loss : 0.019562, loss_ce: 0.006804
2022-01-20 21:57:00,669 iteration 5350 : loss : 0.013241, loss_ce: 0.005058
2022-01-20 21:57:01,256 iteration 5351 : loss : 0.019840, loss_ce: 0.007346
2022-01-20 21:57:01,945 iteration 5352 : loss : 0.033914, loss_ce: 0.012118
2022-01-20 21:57:02,634 iteration 5353 : loss : 0.015387, loss_ce: 0.005190
2022-01-20 21:57:03,240 iteration 5354 : loss : 0.016012, loss_ce: 0.006632
2022-01-20 21:57:03,241 Training Data Eval:
2022-01-20 21:57:06,136   Average segmentation loss on training set: 0.0110
2022-01-20 21:57:06,136 Validation Data Eval:
2022-01-20 21:57:07,091   Average segmentation loss on validation set: 0.0743
2022-01-20 21:57:07,667 iteration 5355 : loss : 0.017342, loss_ce: 0.006169
 79%|██████████████████████▊      | 315/400 [1:01:37<17:40, 12.47s/it]2022-01-20 21:57:08,360 iteration 5356 : loss : 0.017315, loss_ce: 0.007191
2022-01-20 21:57:08,934 iteration 5357 : loss : 0.017616, loss_ce: 0.003526
2022-01-20 21:57:09,711 iteration 5358 : loss : 0.026604, loss_ce: 0.011502
2022-01-20 21:57:10,276 iteration 5359 : loss : 0.011922, loss_ce: 0.004416
2022-01-20 21:57:10,927 iteration 5360 : loss : 0.019231, loss_ce: 0.007673
2022-01-20 21:57:11,578 iteration 5361 : loss : 0.019363, loss_ce: 0.006943
2022-01-20 21:57:12,255 iteration 5362 : loss : 0.020088, loss_ce: 0.006127
2022-01-20 21:57:12,910 iteration 5363 : loss : 0.021700, loss_ce: 0.008701
2022-01-20 21:57:13,559 iteration 5364 : loss : 0.022812, loss_ce: 0.004742
2022-01-20 21:57:14,184 iteration 5365 : loss : 0.016288, loss_ce: 0.006236
2022-01-20 21:57:14,851 iteration 5366 : loss : 0.018480, loss_ce: 0.007850
2022-01-20 21:57:15,548 iteration 5367 : loss : 0.014892, loss_ce: 0.006009
2022-01-20 21:57:16,173 iteration 5368 : loss : 0.015642, loss_ce: 0.007161
2022-01-20 21:57:16,833 iteration 5369 : loss : 0.013151, loss_ce: 0.004801
2022-01-20 21:57:17,456 iteration 5370 : loss : 0.011233, loss_ce: 0.004476
2022-01-20 21:57:18,104 iteration 5371 : loss : 0.026419, loss_ce: 0.014635
2022-01-20 21:57:18,715 iteration 5372 : loss : 0.017319, loss_ce: 0.005269
 79%|██████████████████████▉      | 316/400 [1:01:48<16:51, 12.05s/it]2022-01-20 21:57:19,400 iteration 5373 : loss : 0.014388, loss_ce: 0.006332
2022-01-20 21:57:20,006 iteration 5374 : loss : 0.017828, loss_ce: 0.007717
2022-01-20 21:57:20,674 iteration 5375 : loss : 0.011534, loss_ce: 0.003311
2022-01-20 21:57:21,296 iteration 5376 : loss : 0.015529, loss_ce: 0.004727
2022-01-20 21:57:21,905 iteration 5377 : loss : 0.013346, loss_ce: 0.004230
2022-01-20 21:57:22,551 iteration 5378 : loss : 0.015764, loss_ce: 0.005507
2022-01-20 21:57:23,124 iteration 5379 : loss : 0.014492, loss_ce: 0.006037
2022-01-20 21:57:23,764 iteration 5380 : loss : 0.018206, loss_ce: 0.007332
2022-01-20 21:57:24,376 iteration 5381 : loss : 0.019003, loss_ce: 0.007543
2022-01-20 21:57:25,037 iteration 5382 : loss : 0.016383, loss_ce: 0.004790
2022-01-20 21:57:25,769 iteration 5383 : loss : 0.024183, loss_ce: 0.012704
2022-01-20 21:57:26,572 iteration 5384 : loss : 0.019401, loss_ce: 0.007529
2022-01-20 21:57:27,187 iteration 5385 : loss : 0.016405, loss_ce: 0.006316
2022-01-20 21:57:27,743 iteration 5386 : loss : 0.012519, loss_ce: 0.004133
2022-01-20 21:57:28,350 iteration 5387 : loss : 0.015449, loss_ce: 0.006593
2022-01-20 21:57:29,027 iteration 5388 : loss : 0.015076, loss_ce: 0.005091
2022-01-20 21:57:29,781 iteration 5389 : loss : 0.019062, loss_ce: 0.005431
 79%|██████████████████████▉      | 317/400 [1:01:59<16:15, 11.75s/it]2022-01-20 21:57:30,447 iteration 5390 : loss : 0.026375, loss_ce: 0.005801
2022-01-20 21:57:31,141 iteration 5391 : loss : 0.022480, loss_ce: 0.008235
2022-01-20 21:57:31,835 iteration 5392 : loss : 0.016893, loss_ce: 0.008419
2022-01-20 21:57:32,477 iteration 5393 : loss : 0.039355, loss_ce: 0.010076
2022-01-20 21:57:33,085 iteration 5394 : loss : 0.016509, loss_ce: 0.007657
2022-01-20 21:57:33,745 iteration 5395 : loss : 0.019022, loss_ce: 0.005657
2022-01-20 21:57:34,334 iteration 5396 : loss : 0.019285, loss_ce: 0.010061
2022-01-20 21:57:35,039 iteration 5397 : loss : 0.017657, loss_ce: 0.005391
2022-01-20 21:57:35,692 iteration 5398 : loss : 0.015503, loss_ce: 0.006307
2022-01-20 21:57:36,263 iteration 5399 : loss : 0.023647, loss_ce: 0.006504
2022-01-20 21:57:36,990 iteration 5400 : loss : 0.028067, loss_ce: 0.008817
2022-01-20 21:57:37,659 iteration 5401 : loss : 0.017653, loss_ce: 0.008028
2022-01-20 21:57:38,302 iteration 5402 : loss : 0.016771, loss_ce: 0.005703
2022-01-20 21:57:38,908 iteration 5403 : loss : 0.018882, loss_ce: 0.007607
2022-01-20 21:57:39,499 iteration 5404 : loss : 0.014682, loss_ce: 0.004223
2022-01-20 21:57:40,105 iteration 5405 : loss : 0.012952, loss_ce: 0.005234
2022-01-20 21:57:40,788 iteration 5406 : loss : 0.016301, loss_ce: 0.004226
 80%|███████████████████████      | 318/400 [1:02:10<15:45, 11.53s/it]2022-01-20 21:57:41,506 iteration 5407 : loss : 0.020665, loss_ce: 0.008500
2022-01-20 21:57:42,149 iteration 5408 : loss : 0.018837, loss_ce: 0.005807
2022-01-20 21:57:42,870 iteration 5409 : loss : 0.025457, loss_ce: 0.011966
2022-01-20 21:57:43,479 iteration 5410 : loss : 0.017778, loss_ce: 0.008035
2022-01-20 21:57:44,114 iteration 5411 : loss : 0.016631, loss_ce: 0.006836
2022-01-20 21:57:44,766 iteration 5412 : loss : 0.015781, loss_ce: 0.006440
2022-01-20 21:57:45,380 iteration 5413 : loss : 0.014645, loss_ce: 0.007018
2022-01-20 21:57:46,031 iteration 5414 : loss : 0.017365, loss_ce: 0.007239
2022-01-20 21:57:46,759 iteration 5415 : loss : 0.026656, loss_ce: 0.010212
2022-01-20 21:57:47,340 iteration 5416 : loss : 0.012713, loss_ce: 0.004079
2022-01-20 21:57:48,008 iteration 5417 : loss : 0.016402, loss_ce: 0.004752
2022-01-20 21:57:48,627 iteration 5418 : loss : 0.019074, loss_ce: 0.007416
2022-01-20 21:57:49,297 iteration 5419 : loss : 0.021563, loss_ce: 0.006465
2022-01-20 21:57:50,004 iteration 5420 : loss : 0.017297, loss_ce: 0.006288
2022-01-20 21:57:50,677 iteration 5421 : loss : 0.018351, loss_ce: 0.007498
2022-01-20 21:57:51,198 iteration 5422 : loss : 0.012369, loss_ce: 0.005447
2022-01-20 21:57:51,872 iteration 5423 : loss : 0.024522, loss_ce: 0.005156
 80%|███████████████████████▏     | 319/400 [1:02:21<15:22, 11.39s/it]2022-01-20 21:57:52,627 iteration 5424 : loss : 0.016585, loss_ce: 0.005848
2022-01-20 21:57:53,234 iteration 5425 : loss : 0.013888, loss_ce: 0.004360
2022-01-20 21:57:53,873 iteration 5426 : loss : 0.016627, loss_ce: 0.004438
2022-01-20 21:57:54,426 iteration 5427 : loss : 0.016445, loss_ce: 0.006686
2022-01-20 21:57:55,038 iteration 5428 : loss : 0.015120, loss_ce: 0.005697
2022-01-20 21:57:55,700 iteration 5429 : loss : 0.012466, loss_ce: 0.004063
2022-01-20 21:57:56,351 iteration 5430 : loss : 0.016358, loss_ce: 0.006768
2022-01-20 21:57:56,930 iteration 5431 : loss : 0.019297, loss_ce: 0.006771
2022-01-20 21:57:57,639 iteration 5432 : loss : 0.016106, loss_ce: 0.007180
2022-01-20 21:57:58,339 iteration 5433 : loss : 0.018258, loss_ce: 0.007259
2022-01-20 21:57:58,927 iteration 5434 : loss : 0.015879, loss_ce: 0.006449
2022-01-20 21:57:59,634 iteration 5435 : loss : 0.021168, loss_ce: 0.008650
2022-01-20 21:58:00,293 iteration 5436 : loss : 0.013378, loss_ce: 0.005006
2022-01-20 21:58:00,972 iteration 5437 : loss : 0.041488, loss_ce: 0.006449
2022-01-20 21:58:01,665 iteration 5438 : loss : 0.014281, loss_ce: 0.005700
2022-01-20 21:58:02,294 iteration 5439 : loss : 0.018099, loss_ce: 0.007507
2022-01-20 21:58:02,295 Training Data Eval:
2022-01-20 21:58:05,189   Average segmentation loss on training set: 0.0106
2022-01-20 21:58:05,189 Validation Data Eval:
2022-01-20 21:58:06,140   Average segmentation loss on validation set: 0.0928
2022-01-20 21:58:06,715 iteration 5440 : loss : 0.021777, loss_ce: 0.005947
 80%|███████████████████████▏     | 320/400 [1:02:36<16:34, 12.43s/it]2022-01-20 21:58:07,361 iteration 5441 : loss : 0.018258, loss_ce: 0.006195
2022-01-20 21:58:07,940 iteration 5442 : loss : 0.020444, loss_ce: 0.007029
2022-01-20 21:58:08,557 iteration 5443 : loss : 0.027764, loss_ce: 0.008501
2022-01-20 21:58:09,110 iteration 5444 : loss : 0.014370, loss_ce: 0.004211
2022-01-20 21:58:09,749 iteration 5445 : loss : 0.033225, loss_ce: 0.012871
2022-01-20 21:58:10,335 iteration 5446 : loss : 0.018997, loss_ce: 0.008971
2022-01-20 21:58:11,047 iteration 5447 : loss : 0.029278, loss_ce: 0.008573
2022-01-20 21:58:11,627 iteration 5448 : loss : 0.017770, loss_ce: 0.006528
2022-01-20 21:58:12,268 iteration 5449 : loss : 0.025874, loss_ce: 0.013449
2022-01-20 21:58:12,894 iteration 5450 : loss : 0.020637, loss_ce: 0.007815
2022-01-20 21:58:13,465 iteration 5451 : loss : 0.026422, loss_ce: 0.007872
2022-01-20 21:58:14,104 iteration 5452 : loss : 0.029876, loss_ce: 0.011257
2022-01-20 21:58:14,690 iteration 5453 : loss : 0.018553, loss_ce: 0.006860
2022-01-20 21:58:15,378 iteration 5454 : loss : 0.020156, loss_ce: 0.009937
2022-01-20 21:58:16,036 iteration 5455 : loss : 0.041736, loss_ce: 0.010607
2022-01-20 21:58:16,680 iteration 5456 : loss : 0.011976, loss_ce: 0.002825
2022-01-20 21:58:17,269 iteration 5457 : loss : 0.015893, loss_ce: 0.004238
 80%|███████████████████████▎     | 321/400 [1:02:46<15:37, 11.87s/it]2022-01-20 21:58:17,929 iteration 5458 : loss : 0.022371, loss_ce: 0.006141
2022-01-20 21:58:18,502 iteration 5459 : loss : 0.018612, loss_ce: 0.008168
2022-01-20 21:58:19,135 iteration 5460 : loss : 0.016891, loss_ce: 0.005950
2022-01-20 21:58:19,764 iteration 5461 : loss : 0.022496, loss_ce: 0.008097
2022-01-20 21:58:20,384 iteration 5462 : loss : 0.016394, loss_ce: 0.005727
2022-01-20 21:58:21,038 iteration 5463 : loss : 0.023944, loss_ce: 0.007477
2022-01-20 21:58:21,686 iteration 5464 : loss : 0.021326, loss_ce: 0.009410
2022-01-20 21:58:22,391 iteration 5465 : loss : 0.020602, loss_ce: 0.007648
2022-01-20 21:58:23,079 iteration 5466 : loss : 0.016081, loss_ce: 0.005377
2022-01-20 21:58:23,739 iteration 5467 : loss : 0.043998, loss_ce: 0.019021
2022-01-20 21:58:24,400 iteration 5468 : loss : 0.017907, loss_ce: 0.007362
2022-01-20 21:58:24,965 iteration 5469 : loss : 0.015685, loss_ce: 0.005526
2022-01-20 21:58:25,579 iteration 5470 : loss : 0.010295, loss_ce: 0.003487
2022-01-20 21:58:26,196 iteration 5471 : loss : 0.019125, loss_ce: 0.005036
2022-01-20 21:58:26,856 iteration 5472 : loss : 0.022680, loss_ce: 0.007204
2022-01-20 21:58:27,435 iteration 5473 : loss : 0.014239, loss_ce: 0.004789
2022-01-20 21:58:28,023 iteration 5474 : loss : 0.015412, loss_ce: 0.005075
 80%|███████████████████████▎     | 322/400 [1:02:57<14:59, 11.53s/it]2022-01-20 21:58:28,711 iteration 5475 : loss : 0.018917, loss_ce: 0.005334
2022-01-20 21:58:29,400 iteration 5476 : loss : 0.019392, loss_ce: 0.008498
2022-01-20 21:58:30,031 iteration 5477 : loss : 0.034228, loss_ce: 0.006721
2022-01-20 21:58:30,586 iteration 5478 : loss : 0.016564, loss_ce: 0.005097
2022-01-20 21:58:31,204 iteration 5479 : loss : 0.013766, loss_ce: 0.005587
2022-01-20 21:58:31,823 iteration 5480 : loss : 0.016647, loss_ce: 0.005036
2022-01-20 21:58:32,418 iteration 5481 : loss : 0.020945, loss_ce: 0.007623
2022-01-20 21:58:33,135 iteration 5482 : loss : 0.024741, loss_ce: 0.006687
2022-01-20 21:58:33,687 iteration 5483 : loss : 0.014976, loss_ce: 0.005761
2022-01-20 21:58:34,327 iteration 5484 : loss : 0.022514, loss_ce: 0.006964
2022-01-20 21:58:34,957 iteration 5485 : loss : 0.014914, loss_ce: 0.005836
2022-01-20 21:58:35,587 iteration 5486 : loss : 0.024851, loss_ce: 0.011465
2022-01-20 21:58:36,240 iteration 5487 : loss : 0.014128, loss_ce: 0.004823
2022-01-20 21:58:36,838 iteration 5488 : loss : 0.014082, loss_ce: 0.006141
2022-01-20 21:58:37,428 iteration 5489 : loss : 0.013932, loss_ce: 0.007071
2022-01-20 21:58:38,138 iteration 5490 : loss : 0.023899, loss_ce: 0.009947
2022-01-20 21:58:38,743 iteration 5491 : loss : 0.013450, loss_ce: 0.004107
 81%|███████████████████████▍     | 323/400 [1:03:08<14:29, 11.29s/it]2022-01-20 21:58:39,331 iteration 5492 : loss : 0.013706, loss_ce: 0.005132
2022-01-20 21:58:39,991 iteration 5493 : loss : 0.021414, loss_ce: 0.006024
2022-01-20 21:58:40,579 iteration 5494 : loss : 0.018164, loss_ce: 0.005046
2022-01-20 21:58:41,217 iteration 5495 : loss : 0.012959, loss_ce: 0.003666
2022-01-20 21:58:41,864 iteration 5496 : loss : 0.015105, loss_ce: 0.003945
2022-01-20 21:58:42,514 iteration 5497 : loss : 0.015364, loss_ce: 0.006091
2022-01-20 21:58:43,192 iteration 5498 : loss : 0.022128, loss_ce: 0.007937
2022-01-20 21:58:43,859 iteration 5499 : loss : 0.021949, loss_ce: 0.013803
2022-01-20 21:58:44,433 iteration 5500 : loss : 0.014656, loss_ce: 0.006239
2022-01-20 21:58:45,076 iteration 5501 : loss : 0.018907, loss_ce: 0.008232
2022-01-20 21:58:45,668 iteration 5502 : loss : 0.010716, loss_ce: 0.004551
2022-01-20 21:58:46,291 iteration 5503 : loss : 0.019162, loss_ce: 0.005184
2022-01-20 21:58:46,883 iteration 5504 : loss : 0.015447, loss_ce: 0.005791
2022-01-20 21:58:47,507 iteration 5505 : loss : 0.018276, loss_ce: 0.007406
2022-01-20 21:58:48,163 iteration 5506 : loss : 0.014753, loss_ce: 0.005958
2022-01-20 21:58:48,783 iteration 5507 : loss : 0.014750, loss_ce: 0.006205
2022-01-20 21:58:49,423 iteration 5508 : loss : 0.023217, loss_ce: 0.007109
 81%|███████████████████████▍     | 324/400 [1:03:18<14:04, 11.11s/it]2022-01-20 21:58:50,107 iteration 5509 : loss : 0.020079, loss_ce: 0.006042
2022-01-20 21:58:50,833 iteration 5510 : loss : 0.016232, loss_ce: 0.005448
2022-01-20 21:58:51,454 iteration 5511 : loss : 0.013500, loss_ce: 0.005174
2022-01-20 21:58:52,141 iteration 5512 : loss : 0.019180, loss_ce: 0.007426
2022-01-20 21:58:52,749 iteration 5513 : loss : 0.015802, loss_ce: 0.007121
2022-01-20 21:58:53,311 iteration 5514 : loss : 0.010665, loss_ce: 0.003461
2022-01-20 21:58:53,998 iteration 5515 : loss : 0.030237, loss_ce: 0.006704
2022-01-20 21:58:54,605 iteration 5516 : loss : 0.016548, loss_ce: 0.006455
2022-01-20 21:58:55,241 iteration 5517 : loss : 0.014391, loss_ce: 0.005995
2022-01-20 21:58:55,874 iteration 5518 : loss : 0.018942, loss_ce: 0.006295
2022-01-20 21:58:56,527 iteration 5519 : loss : 0.023368, loss_ce: 0.009546
2022-01-20 21:58:57,158 iteration 5520 : loss : 0.013662, loss_ce: 0.006007
2022-01-20 21:58:57,808 iteration 5521 : loss : 0.021865, loss_ce: 0.007728
2022-01-20 21:58:58,438 iteration 5522 : loss : 0.022533, loss_ce: 0.009106
2022-01-20 21:58:59,038 iteration 5523 : loss : 0.011024, loss_ce: 0.003912
2022-01-20 21:58:59,644 iteration 5524 : loss : 0.016753, loss_ce: 0.007142
2022-01-20 21:58:59,645 Training Data Eval:
2022-01-20 21:59:02,541   Average segmentation loss on training set: 0.0109
2022-01-20 21:59:02,541 Validation Data Eval:
2022-01-20 21:59:03,493   Average segmentation loss on validation set: 0.0656
2022-01-20 21:59:04,107 Found new lowest validation loss at iteration 5524! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed1234.pth
2022-01-20 21:59:04,725 iteration 5525 : loss : 0.018443, loss_ce: 0.008628
 81%|███████████████████████▌     | 325/400 [1:03:34<15:27, 12.37s/it]2022-01-20 21:59:05,439 iteration 5526 : loss : 0.016882, loss_ce: 0.006619
2022-01-20 21:59:06,090 iteration 5527 : loss : 0.020255, loss_ce: 0.008974
2022-01-20 21:59:06,727 iteration 5528 : loss : 0.020399, loss_ce: 0.007437
2022-01-20 21:59:07,398 iteration 5529 : loss : 0.021244, loss_ce: 0.009783
2022-01-20 21:59:07,977 iteration 5530 : loss : 0.014412, loss_ce: 0.006259
2022-01-20 21:59:08,586 iteration 5531 : loss : 0.013336, loss_ce: 0.005491
2022-01-20 21:59:09,176 iteration 5532 : loss : 0.011819, loss_ce: 0.004724
2022-01-20 21:59:09,868 iteration 5533 : loss : 0.020995, loss_ce: 0.005435
2022-01-20 21:59:10,494 iteration 5534 : loss : 0.012855, loss_ce: 0.004426
2022-01-20 21:59:11,186 iteration 5535 : loss : 0.019160, loss_ce: 0.007057
2022-01-20 21:59:11,912 iteration 5536 : loss : 0.013901, loss_ce: 0.005987
2022-01-20 21:59:12,591 iteration 5537 : loss : 0.024589, loss_ce: 0.007743
2022-01-20 21:59:13,245 iteration 5538 : loss : 0.019276, loss_ce: 0.008134
2022-01-20 21:59:13,984 iteration 5539 : loss : 0.017971, loss_ce: 0.003790
2022-01-20 21:59:14,588 iteration 5540 : loss : 0.014353, loss_ce: 0.006762
2022-01-20 21:59:15,230 iteration 5541 : loss : 0.027334, loss_ce: 0.009030
2022-01-20 21:59:15,841 iteration 5542 : loss : 0.013967, loss_ce: 0.005393
 82%|███████████████████████▋     | 326/400 [1:03:45<14:47, 11.99s/it]2022-01-20 21:59:16,544 iteration 5543 : loss : 0.022457, loss_ce: 0.008546
2022-01-20 21:59:17,198 iteration 5544 : loss : 0.014004, loss_ce: 0.006457
2022-01-20 21:59:17,816 iteration 5545 : loss : 0.014041, loss_ce: 0.005157
2022-01-20 21:59:18,404 iteration 5546 : loss : 0.017982, loss_ce: 0.005883
2022-01-20 21:59:19,047 iteration 5547 : loss : 0.015641, loss_ce: 0.005546
2022-01-20 21:59:19,747 iteration 5548 : loss : 0.021173, loss_ce: 0.007108
2022-01-20 21:59:20,329 iteration 5549 : loss : 0.017179, loss_ce: 0.006638
2022-01-20 21:59:20,946 iteration 5550 : loss : 0.015300, loss_ce: 0.005703
2022-01-20 21:59:21,589 iteration 5551 : loss : 0.015427, loss_ce: 0.006523
2022-01-20 21:59:22,170 iteration 5552 : loss : 0.013071, loss_ce: 0.005079
2022-01-20 21:59:22,821 iteration 5553 : loss : 0.019546, loss_ce: 0.007723
2022-01-20 21:59:23,506 iteration 5554 : loss : 0.014215, loss_ce: 0.005124
2022-01-20 21:59:24,190 iteration 5555 : loss : 0.031334, loss_ce: 0.010539
2022-01-20 21:59:24,757 iteration 5556 : loss : 0.017467, loss_ce: 0.006627
2022-01-20 21:59:25,458 iteration 5557 : loss : 0.022146, loss_ce: 0.006464
2022-01-20 21:59:26,107 iteration 5558 : loss : 0.014962, loss_ce: 0.004872
2022-01-20 21:59:26,653 iteration 5559 : loss : 0.011648, loss_ce: 0.004601
 82%|███████████████████████▋     | 327/400 [1:03:56<14:09, 11.64s/it]2022-01-20 21:59:27,495 iteration 5560 : loss : 0.030190, loss_ce: 0.011091
2022-01-20 21:59:28,116 iteration 5561 : loss : 0.016344, loss_ce: 0.005448
2022-01-20 21:59:28,740 iteration 5562 : loss : 0.018282, loss_ce: 0.005160
2022-01-20 21:59:29,366 iteration 5563 : loss : 0.015016, loss_ce: 0.005880
2022-01-20 21:59:30,103 iteration 5564 : loss : 0.016245, loss_ce: 0.004530
2022-01-20 21:59:30,754 iteration 5565 : loss : 0.013395, loss_ce: 0.005540
2022-01-20 21:59:31,433 iteration 5566 : loss : 0.014550, loss_ce: 0.006539
2022-01-20 21:59:32,167 iteration 5567 : loss : 0.024310, loss_ce: 0.011336
2022-01-20 21:59:32,810 iteration 5568 : loss : 0.019843, loss_ce: 0.008012
2022-01-20 21:59:33,495 iteration 5569 : loss : 0.016042, loss_ce: 0.006983
2022-01-20 21:59:34,152 iteration 5570 : loss : 0.012847, loss_ce: 0.004447
2022-01-20 21:59:34,841 iteration 5571 : loss : 0.017751, loss_ce: 0.006827
2022-01-20 21:59:35,482 iteration 5572 : loss : 0.017298, loss_ce: 0.006276
2022-01-20 21:59:36,111 iteration 5573 : loss : 0.014974, loss_ce: 0.004445
2022-01-20 21:59:36,860 iteration 5574 : loss : 0.016239, loss_ce: 0.005569
2022-01-20 21:59:37,390 iteration 5575 : loss : 0.010831, loss_ce: 0.004612
2022-01-20 21:59:37,901 iteration 5576 : loss : 0.013673, loss_ce: 0.004144
 82%|███████████████████████▊     | 328/400 [1:04:07<13:49, 11.52s/it]2022-01-20 21:59:38,570 iteration 5577 : loss : 0.015427, loss_ce: 0.005499
2022-01-20 21:59:39,168 iteration 5578 : loss : 0.015229, loss_ce: 0.004135
2022-01-20 21:59:39,791 iteration 5579 : loss : 0.012842, loss_ce: 0.003733
2022-01-20 21:59:40,467 iteration 5580 : loss : 0.015812, loss_ce: 0.005484
2022-01-20 21:59:41,080 iteration 5581 : loss : 0.013658, loss_ce: 0.005092
2022-01-20 21:59:41,749 iteration 5582 : loss : 0.016428, loss_ce: 0.004984
2022-01-20 21:59:42,365 iteration 5583 : loss : 0.027440, loss_ce: 0.006917
2022-01-20 21:59:43,086 iteration 5584 : loss : 0.018083, loss_ce: 0.007140
2022-01-20 21:59:43,707 iteration 5585 : loss : 0.018936, loss_ce: 0.006931
2022-01-20 21:59:44,346 iteration 5586 : loss : 0.022920, loss_ce: 0.009480
2022-01-20 21:59:44,992 iteration 5587 : loss : 0.015227, loss_ce: 0.007081
2022-01-20 21:59:45,712 iteration 5588 : loss : 0.029744, loss_ce: 0.011011
2022-01-20 21:59:46,408 iteration 5589 : loss : 0.026374, loss_ce: 0.008930
2022-01-20 21:59:47,053 iteration 5590 : loss : 0.017177, loss_ce: 0.006719
2022-01-20 21:59:47,693 iteration 5591 : loss : 0.014012, loss_ce: 0.005770
2022-01-20 21:59:48,314 iteration 5592 : loss : 0.014921, loss_ce: 0.004553
2022-01-20 21:59:48,935 iteration 5593 : loss : 0.014174, loss_ce: 0.007666
 82%|███████████████████████▊     | 329/400 [1:04:18<13:27, 11.37s/it]2022-01-20 21:59:49,646 iteration 5594 : loss : 0.015143, loss_ce: 0.005406
2022-01-20 21:59:50,266 iteration 5595 : loss : 0.015415, loss_ce: 0.006800
2022-01-20 21:59:50,880 iteration 5596 : loss : 0.010336, loss_ce: 0.002893
2022-01-20 21:59:51,534 iteration 5597 : loss : 0.013353, loss_ce: 0.004214
2022-01-20 21:59:52,238 iteration 5598 : loss : 0.019314, loss_ce: 0.008358
2022-01-20 21:59:52,917 iteration 5599 : loss : 0.013759, loss_ce: 0.004591
2022-01-20 21:59:53,593 iteration 5600 : loss : 0.020084, loss_ce: 0.009950
2022-01-20 21:59:54,277 iteration 5601 : loss : 0.013652, loss_ce: 0.004122
2022-01-20 21:59:54,877 iteration 5602 : loss : 0.021527, loss_ce: 0.004867
2022-01-20 21:59:55,570 iteration 5603 : loss : 0.015673, loss_ce: 0.007218
2022-01-20 21:59:56,183 iteration 5604 : loss : 0.017457, loss_ce: 0.007692
2022-01-20 21:59:56,799 iteration 5605 : loss : 0.016098, loss_ce: 0.006255
2022-01-20 21:59:57,511 iteration 5606 : loss : 0.021496, loss_ce: 0.007503
2022-01-20 21:59:58,159 iteration 5607 : loss : 0.018571, loss_ce: 0.006557
2022-01-20 21:59:58,930 iteration 5608 : loss : 0.022789, loss_ce: 0.010617
2022-01-20 21:59:59,536 iteration 5609 : loss : 0.017648, loss_ce: 0.007665
2022-01-20 21:59:59,537 Training Data Eval:
2022-01-20 22:00:02,435   Average segmentation loss on training set: 0.0100
2022-01-20 22:00:02,436 Validation Data Eval:
2022-01-20 22:00:03,385   Average segmentation loss on validation set: 0.0779
2022-01-20 22:00:04,046 iteration 5610 : loss : 0.017336, loss_ce: 0.007213
 82%|███████████████████████▉     | 330/400 [1:04:33<14:34, 12.49s/it]2022-01-20 22:00:04,771 iteration 5611 : loss : 0.021945, loss_ce: 0.009876
2022-01-20 22:00:05,423 iteration 5612 : loss : 0.014262, loss_ce: 0.003933
2022-01-20 22:00:06,058 iteration 5613 : loss : 0.015178, loss_ce: 0.005861
2022-01-20 22:00:06,686 iteration 5614 : loss : 0.026834, loss_ce: 0.008595
2022-01-20 22:00:07,350 iteration 5615 : loss : 0.021615, loss_ce: 0.008126
2022-01-20 22:00:08,037 iteration 5616 : loss : 0.017094, loss_ce: 0.007268
2022-01-20 22:00:08,676 iteration 5617 : loss : 0.012330, loss_ce: 0.004086
2022-01-20 22:00:09,263 iteration 5618 : loss : 0.017237, loss_ce: 0.007513
2022-01-20 22:00:09,944 iteration 5619 : loss : 0.021088, loss_ce: 0.008682
2022-01-20 22:00:10,630 iteration 5620 : loss : 0.016668, loss_ce: 0.004676
2022-01-20 22:00:11,235 iteration 5621 : loss : 0.017443, loss_ce: 0.006887
2022-01-20 22:00:11,953 iteration 5622 : loss : 0.016328, loss_ce: 0.006898
2022-01-20 22:00:12,550 iteration 5623 : loss : 0.019782, loss_ce: 0.005953
2022-01-20 22:00:13,217 iteration 5624 : loss : 0.015583, loss_ce: 0.006475
2022-01-20 22:00:13,904 iteration 5625 : loss : 0.036075, loss_ce: 0.015598
2022-01-20 22:00:14,552 iteration 5626 : loss : 0.018293, loss_ce: 0.007190
2022-01-20 22:00:15,208 iteration 5627 : loss : 0.019529, loss_ce: 0.005964
 83%|███████████████████████▉     | 331/400 [1:04:44<13:54, 12.10s/it]2022-01-20 22:00:15,788 iteration 5628 : loss : 0.015271, loss_ce: 0.005673
2022-01-20 22:00:16,454 iteration 5629 : loss : 0.014112, loss_ce: 0.006303
2022-01-20 22:00:17,096 iteration 5630 : loss : 0.016505, loss_ce: 0.005130
2022-01-20 22:00:17,850 iteration 5631 : loss : 0.022098, loss_ce: 0.011980
2022-01-20 22:00:18,417 iteration 5632 : loss : 0.021639, loss_ce: 0.010292
2022-01-20 22:00:19,111 iteration 5633 : loss : 0.021007, loss_ce: 0.008248
2022-01-20 22:00:19,705 iteration 5634 : loss : 0.019205, loss_ce: 0.005782
2022-01-20 22:00:20,364 iteration 5635 : loss : 0.014973, loss_ce: 0.004147
2022-01-20 22:00:20,941 iteration 5636 : loss : 0.013079, loss_ce: 0.005267
2022-01-20 22:00:21,593 iteration 5637 : loss : 0.020601, loss_ce: 0.007978
2022-01-20 22:00:22,121 iteration 5638 : loss : 0.013037, loss_ce: 0.004029
2022-01-20 22:00:22,698 iteration 5639 : loss : 0.018823, loss_ce: 0.005648
2022-01-20 22:00:23,311 iteration 5640 : loss : 0.013832, loss_ce: 0.006256
2022-01-20 22:00:23,984 iteration 5641 : loss : 0.013143, loss_ce: 0.006697
2022-01-20 22:00:24,597 iteration 5642 : loss : 0.018823, loss_ce: 0.003624
2022-01-20 22:00:25,272 iteration 5643 : loss : 0.013307, loss_ce: 0.003371
2022-01-20 22:00:25,935 iteration 5644 : loss : 0.015486, loss_ce: 0.005858
 83%|████████████████████████     | 332/400 [1:04:55<13:14, 11.69s/it]2022-01-20 22:00:26,721 iteration 5645 : loss : 0.017659, loss_ce: 0.007045
2022-01-20 22:00:27,328 iteration 5646 : loss : 0.019261, loss_ce: 0.007131
2022-01-20 22:00:27,966 iteration 5647 : loss : 0.021365, loss_ce: 0.008960
2022-01-20 22:00:28,650 iteration 5648 : loss : 0.021602, loss_ce: 0.006881
2022-01-20 22:00:29,330 iteration 5649 : loss : 0.016495, loss_ce: 0.007148
2022-01-20 22:00:29,981 iteration 5650 : loss : 0.017650, loss_ce: 0.006551
2022-01-20 22:00:30,612 iteration 5651 : loss : 0.020931, loss_ce: 0.009331
2022-01-20 22:00:31,173 iteration 5652 : loss : 0.012167, loss_ce: 0.004116
2022-01-20 22:00:31,791 iteration 5653 : loss : 0.016854, loss_ce: 0.007141
2022-01-20 22:00:32,366 iteration 5654 : loss : 0.014556, loss_ce: 0.004010
2022-01-20 22:00:33,022 iteration 5655 : loss : 0.018053, loss_ce: 0.006979
2022-01-20 22:00:33,651 iteration 5656 : loss : 0.013646, loss_ce: 0.004488
2022-01-20 22:00:34,285 iteration 5657 : loss : 0.016179, loss_ce: 0.006117
2022-01-20 22:00:34,916 iteration 5658 : loss : 0.020008, loss_ce: 0.009195
2022-01-20 22:00:35,526 iteration 5659 : loss : 0.013317, loss_ce: 0.003674
2022-01-20 22:00:36,101 iteration 5660 : loss : 0.012056, loss_ce: 0.004163
2022-01-20 22:00:36,822 iteration 5661 : loss : 0.018530, loss_ce: 0.005554
 83%|████████████████████████▏    | 333/400 [1:05:06<12:46, 11.45s/it]2022-01-20 22:00:37,504 iteration 5662 : loss : 0.018035, loss_ce: 0.005231
2022-01-20 22:00:38,143 iteration 5663 : loss : 0.016725, loss_ce: 0.006559
2022-01-20 22:00:38,808 iteration 5664 : loss : 0.019452, loss_ce: 0.005728
2022-01-20 22:00:39,363 iteration 5665 : loss : 0.020160, loss_ce: 0.007009
2022-01-20 22:00:40,024 iteration 5666 : loss : 0.015165, loss_ce: 0.005553
2022-01-20 22:00:40,706 iteration 5667 : loss : 0.015970, loss_ce: 0.006012
2022-01-20 22:00:41,337 iteration 5668 : loss : 0.014939, loss_ce: 0.007618
2022-01-20 22:00:42,013 iteration 5669 : loss : 0.018852, loss_ce: 0.009152
2022-01-20 22:00:42,665 iteration 5670 : loss : 0.014105, loss_ce: 0.004760
2022-01-20 22:00:43,312 iteration 5671 : loss : 0.017376, loss_ce: 0.005800
2022-01-20 22:00:43,943 iteration 5672 : loss : 0.017139, loss_ce: 0.004546
2022-01-20 22:00:44,540 iteration 5673 : loss : 0.016139, loss_ce: 0.004744
2022-01-20 22:00:45,244 iteration 5674 : loss : 0.013596, loss_ce: 0.006336
2022-01-20 22:00:45,853 iteration 5675 : loss : 0.015374, loss_ce: 0.006709
2022-01-20 22:00:46,546 iteration 5676 : loss : 0.030538, loss_ce: 0.009945
2022-01-20 22:00:47,231 iteration 5677 : loss : 0.013015, loss_ce: 0.005741
2022-01-20 22:00:47,896 iteration 5678 : loss : 0.039375, loss_ce: 0.012142
 84%|████████████████████████▏    | 334/400 [1:05:17<12:27, 11.33s/it]2022-01-20 22:00:48,593 iteration 5679 : loss : 0.024774, loss_ce: 0.011295
2022-01-20 22:00:49,131 iteration 5680 : loss : 0.013747, loss_ce: 0.003407
2022-01-20 22:00:49,827 iteration 5681 : loss : 0.019769, loss_ce: 0.005732
2022-01-20 22:00:50,518 iteration 5682 : loss : 0.020332, loss_ce: 0.008749
2022-01-20 22:00:51,131 iteration 5683 : loss : 0.013053, loss_ce: 0.004396
2022-01-20 22:00:51,730 iteration 5684 : loss : 0.012259, loss_ce: 0.006019
2022-01-20 22:00:52,397 iteration 5685 : loss : 0.021977, loss_ce: 0.009218
2022-01-20 22:00:53,013 iteration 5686 : loss : 0.016919, loss_ce: 0.006295
2022-01-20 22:00:53,648 iteration 5687 : loss : 0.014309, loss_ce: 0.005912
2022-01-20 22:00:54,376 iteration 5688 : loss : 0.015758, loss_ce: 0.005467
2022-01-20 22:00:55,017 iteration 5689 : loss : 0.018002, loss_ce: 0.005548
2022-01-20 22:00:55,666 iteration 5690 : loss : 0.014744, loss_ce: 0.006060
2022-01-20 22:00:56,337 iteration 5691 : loss : 0.020540, loss_ce: 0.008875
2022-01-20 22:00:57,007 iteration 5692 : loss : 0.020670, loss_ce: 0.008597
2022-01-20 22:00:57,663 iteration 5693 : loss : 0.021596, loss_ce: 0.006059
2022-01-20 22:00:58,289 iteration 5694 : loss : 0.019044, loss_ce: 0.008453
2022-01-20 22:00:58,289 Training Data Eval:
2022-01-20 22:01:01,176   Average segmentation loss on training set: 0.0095
2022-01-20 22:01:01,176 Validation Data Eval:
2022-01-20 22:01:02,125   Average segmentation loss on validation set: 0.0880
2022-01-20 22:01:02,706 iteration 5695 : loss : 0.013070, loss_ce: 0.004063
 84%|████████████████████████▎    | 335/400 [1:05:32<13:24, 12.38s/it]2022-01-20 22:01:03,326 iteration 5696 : loss : 0.012186, loss_ce: 0.005921
2022-01-20 22:01:03,902 iteration 5697 : loss : 0.014437, loss_ce: 0.006728
2022-01-20 22:01:04,581 iteration 5698 : loss : 0.016114, loss_ce: 0.004761
2022-01-20 22:01:05,139 iteration 5699 : loss : 0.013282, loss_ce: 0.005533
2022-01-20 22:01:05,742 iteration 5700 : loss : 0.012355, loss_ce: 0.004185
2022-01-20 22:01:06,313 iteration 5701 : loss : 0.011164, loss_ce: 0.004763
2022-01-20 22:01:07,038 iteration 5702 : loss : 0.017479, loss_ce: 0.006907
2022-01-20 22:01:07,709 iteration 5703 : loss : 0.018200, loss_ce: 0.007628
2022-01-20 22:01:08,364 iteration 5704 : loss : 0.018769, loss_ce: 0.006938
2022-01-20 22:01:09,032 iteration 5705 : loss : 0.014565, loss_ce: 0.005167
2022-01-20 22:01:09,583 iteration 5706 : loss : 0.013483, loss_ce: 0.005346
2022-01-20 22:01:10,203 iteration 5707 : loss : 0.026727, loss_ce: 0.009074
2022-01-20 22:01:10,791 iteration 5708 : loss : 0.013941, loss_ce: 0.004880
2022-01-20 22:01:11,439 iteration 5709 : loss : 0.016761, loss_ce: 0.006361
2022-01-20 22:01:12,064 iteration 5710 : loss : 0.021240, loss_ce: 0.005863
2022-01-20 22:01:12,628 iteration 5711 : loss : 0.013041, loss_ce: 0.004265
2022-01-20 22:01:13,274 iteration 5712 : loss : 0.018034, loss_ce: 0.007316
 84%|████████████████████████▎    | 336/400 [1:05:42<12:37, 11.84s/it]2022-01-20 22:01:13,986 iteration 5713 : loss : 0.019881, loss_ce: 0.006675
2022-01-20 22:01:14,666 iteration 5714 : loss : 0.020273, loss_ce: 0.008321
2022-01-20 22:01:15,357 iteration 5715 : loss : 0.013941, loss_ce: 0.005106
2022-01-20 22:01:15,970 iteration 5716 : loss : 0.014977, loss_ce: 0.005756
2022-01-20 22:01:16,687 iteration 5717 : loss : 0.016823, loss_ce: 0.006816
2022-01-20 22:01:17,270 iteration 5718 : loss : 0.012922, loss_ce: 0.004042
2022-01-20 22:01:17,850 iteration 5719 : loss : 0.014751, loss_ce: 0.007259
2022-01-20 22:01:18,531 iteration 5720 : loss : 0.019893, loss_ce: 0.008139
2022-01-20 22:01:19,178 iteration 5721 : loss : 0.020807, loss_ce: 0.010230
2022-01-20 22:01:19,810 iteration 5722 : loss : 0.015269, loss_ce: 0.006150
2022-01-20 22:01:20,462 iteration 5723 : loss : 0.020401, loss_ce: 0.007476
2022-01-20 22:01:21,146 iteration 5724 : loss : 0.016978, loss_ce: 0.005733
2022-01-20 22:01:21,793 iteration 5725 : loss : 0.017640, loss_ce: 0.007003
2022-01-20 22:01:22,380 iteration 5726 : loss : 0.017388, loss_ce: 0.004233
2022-01-20 22:01:23,035 iteration 5727 : loss : 0.018831, loss_ce: 0.006069
2022-01-20 22:01:23,646 iteration 5728 : loss : 0.019712, loss_ce: 0.006438
2022-01-20 22:01:24,353 iteration 5729 : loss : 0.016191, loss_ce: 0.006426
 84%|████████████████████████▍    | 337/400 [1:05:53<12:11, 11.61s/it]2022-01-20 22:01:24,981 iteration 5730 : loss : 0.013566, loss_ce: 0.006247
2022-01-20 22:01:25,667 iteration 5731 : loss : 0.019015, loss_ce: 0.008116
2022-01-20 22:01:26,255 iteration 5732 : loss : 0.012866, loss_ce: 0.004809
2022-01-20 22:01:26,944 iteration 5733 : loss : 0.022449, loss_ce: 0.006330
2022-01-20 22:01:27,622 iteration 5734 : loss : 0.015045, loss_ce: 0.006041
2022-01-20 22:01:28,228 iteration 5735 : loss : 0.010924, loss_ce: 0.003411
2022-01-20 22:01:28,828 iteration 5736 : loss : 0.018602, loss_ce: 0.007029
2022-01-20 22:01:29,538 iteration 5737 : loss : 0.020631, loss_ce: 0.007344
2022-01-20 22:01:30,144 iteration 5738 : loss : 0.011758, loss_ce: 0.004041
2022-01-20 22:01:30,745 iteration 5739 : loss : 0.015421, loss_ce: 0.005467
2022-01-20 22:01:31,380 iteration 5740 : loss : 0.023352, loss_ce: 0.008294
2022-01-20 22:01:32,021 iteration 5741 : loss : 0.015301, loss_ce: 0.007159
2022-01-20 22:01:32,700 iteration 5742 : loss : 0.015432, loss_ce: 0.003043
2022-01-20 22:01:33,367 iteration 5743 : loss : 0.012704, loss_ce: 0.005279
2022-01-20 22:01:34,055 iteration 5744 : loss : 0.023901, loss_ce: 0.010430
2022-01-20 22:01:34,746 iteration 5745 : loss : 0.017468, loss_ce: 0.005880
2022-01-20 22:01:35,348 iteration 5746 : loss : 0.012018, loss_ce: 0.002859
 84%|████████████████████████▌    | 338/400 [1:06:04<11:48, 11.42s/it]2022-01-20 22:01:36,035 iteration 5747 : loss : 0.015528, loss_ce: 0.005567
2022-01-20 22:01:36,704 iteration 5748 : loss : 0.022447, loss_ce: 0.009577
2022-01-20 22:01:37,353 iteration 5749 : loss : 0.023024, loss_ce: 0.008784
2022-01-20 22:01:37,993 iteration 5750 : loss : 0.017199, loss_ce: 0.005799
2022-01-20 22:01:38,570 iteration 5751 : loss : 0.017757, loss_ce: 0.006989
2022-01-20 22:01:39,188 iteration 5752 : loss : 0.016887, loss_ce: 0.005455
2022-01-20 22:01:39,869 iteration 5753 : loss : 0.013736, loss_ce: 0.005203
2022-01-20 22:01:40,557 iteration 5754 : loss : 0.018535, loss_ce: 0.005223
2022-01-20 22:01:41,193 iteration 5755 : loss : 0.013067, loss_ce: 0.005189
2022-01-20 22:01:41,796 iteration 5756 : loss : 0.014657, loss_ce: 0.005128
