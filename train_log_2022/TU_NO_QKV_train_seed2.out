2022-01-14 14:52:06,689 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:52:06,689 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:52:06,689 ============================================================
2022-01-14 14:52:06,690 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:52:06,690 ============================================================
2022-01-14 14:52:06,690 Loading data...
2022-01-14 14:52:06,690 Reading NCI - RUNMC images...
2022-01-14 14:52:06,690 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-14 14:52:06,691 Already preprocessed this configuration. Loading now!
2022-01-14 14:52:06,713 Training Images: (256, 256, 286)
2022-01-14 14:52:06,713 Training Labels: (256, 256, 286)
2022-01-14 14:52:06,713 Validation Images: (256, 256, 98)
2022-01-14 14:52:06,713 Validation Labels: (256, 256, 98)
2022-01-14 14:52:06,713 ============================================================
2022-01-14 14:52:06,751 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-14 14:52:09,866 iteration 1 : loss : 0.925767, loss_ce: 1.120561
2022-01-14 14:52:11,184 iteration 2 : loss : 0.865494, loss_ce: 1.032492
2022-01-14 14:52:12,583 iteration 3 : loss : 0.804168, loss_ce: 0.937270
2022-01-14 14:52:13,933 iteration 4 : loss : 0.764356, loss_ce: 0.849181
2022-01-14 14:52:15,212 iteration 5 : loss : 0.727651, loss_ce: 0.773648
2022-01-14 14:52:16,541 iteration 6 : loss : 0.672775, loss_ce: 0.699915
2022-01-14 14:52:17,910 iteration 7 : loss : 0.630515, loss_ce: 0.638396
2022-01-14 14:52:19,334 iteration 8 : loss : 0.597788, loss_ce: 0.584889
2022-01-14 14:52:20,632 iteration 9 : loss : 0.587806, loss_ce: 0.537818
2022-01-14 14:52:21,938 iteration 10 : loss : 0.545156, loss_ce: 0.489951
2022-01-14 14:52:23,219 iteration 11 : loss : 0.528003, loss_ce: 0.447221
2022-01-14 14:52:24,557 iteration 12 : loss : 0.501559, loss_ce: 0.419618
2022-01-14 14:52:25,953 iteration 13 : loss : 0.475579, loss_ce: 0.400099
2022-01-14 14:52:27,238 iteration 14 : loss : 0.438747, loss_ce: 0.343164
2022-01-14 14:52:28,628 iteration 15 : loss : 0.418162, loss_ce: 0.314584
2022-01-14 14:52:29,965 iteration 16 : loss : 0.431735, loss_ce: 0.302693
2022-01-14 14:52:31,292 iteration 17 : loss : 0.412596, loss_ce: 0.294551
  0%|                               | 1/400 [00:24<2:43:34, 24.60s/it]2022-01-14 14:52:32,665 iteration 18 : loss : 0.378755, loss_ce: 0.251371
2022-01-14 14:52:34,026 iteration 19 : loss : 0.371835, loss_ce: 0.243255
2022-01-14 14:52:35,374 iteration 20 : loss : 0.348045, loss_ce: 0.223559
2022-01-14 14:52:36,799 iteration 21 : loss : 0.351467, loss_ce: 0.220407
2022-01-14 14:52:38,158 iteration 22 : loss : 0.338256, loss_ce: 0.199173
2022-01-14 14:52:39,539 iteration 23 : loss : 0.297682, loss_ce: 0.163966
2022-01-14 14:52:40,837 iteration 24 : loss : 0.323273, loss_ce: 0.185351
2022-01-14 14:52:42,096 iteration 25 : loss : 0.324366, loss_ce: 0.167643
2022-01-14 14:52:43,389 iteration 26 : loss : 0.327092, loss_ce: 0.158526
2022-01-14 14:52:44,744 iteration 27 : loss : 0.305927, loss_ce: 0.160659
2022-01-14 14:52:46,081 iteration 28 : loss : 0.291306, loss_ce: 0.137185
2022-01-14 14:52:47,639 iteration 29 : loss : 0.308420, loss_ce: 0.158075
2022-01-14 14:52:49,147 iteration 30 : loss : 0.292685, loss_ce: 0.138291
2022-01-14 14:52:50,568 iteration 31 : loss : 0.277077, loss_ce: 0.137675
2022-01-14 14:52:52,010 iteration 32 : loss : 0.294076, loss_ce: 0.143490
2022-01-14 14:52:53,548 iteration 33 : loss : 0.296867, loss_ce: 0.151315
2022-01-14 14:52:54,987 iteration 34 : loss : 0.281579, loss_ce: 0.122166
  0%|▏                              | 2/400 [00:48<2:39:34, 24.06s/it]2022-01-14 14:52:56,534 iteration 35 : loss : 0.310589, loss_ce: 0.166294
2022-01-14 14:52:58,008 iteration 36 : loss : 0.275936, loss_ce: 0.133356
2022-01-14 14:52:59,517 iteration 37 : loss : 0.274982, loss_ce: 0.141345
2022-01-14 14:53:01,094 iteration 38 : loss : 0.250101, loss_ce: 0.111064
2022-01-14 14:53:02,577 iteration 39 : loss : 0.320591, loss_ce: 0.134580
2022-01-14 14:53:04,095 iteration 40 : loss : 0.280368, loss_ce: 0.145596
2022-01-14 14:53:05,521 iteration 41 : loss : 0.275883, loss_ce: 0.112318
2022-01-14 14:53:07,118 iteration 42 : loss : 0.258256, loss_ce: 0.120725
2022-01-14 14:53:08,540 iteration 43 : loss : 0.268886, loss_ce: 0.102610
2022-01-14 14:53:10,038 iteration 44 : loss : 0.242762, loss_ce: 0.104564
2022-01-14 14:53:11,553 iteration 45 : loss : 0.343324, loss_ce: 0.143905
2022-01-14 14:53:12,940 iteration 46 : loss : 0.265440, loss_ce: 0.111413
2022-01-14 14:53:14,397 iteration 47 : loss : 0.313816, loss_ce: 0.119773
2022-01-14 14:53:15,895 iteration 48 : loss : 0.250227, loss_ce: 0.119537
2022-01-14 14:53:17,378 iteration 49 : loss : 0.308027, loss_ce: 0.126704
2022-01-14 14:53:18,900 iteration 50 : loss : 0.267701, loss_ce: 0.110636
2022-01-14 14:53:20,396 iteration 51 : loss : 0.282797, loss_ce: 0.139527
  1%|▏                              | 3/400 [01:13<2:43:15, 24.67s/it]2022-01-14 14:53:21,836 iteration 52 : loss : 0.283310, loss_ce: 0.132562
2022-01-14 14:53:23,240 iteration 53 : loss : 0.257018, loss_ce: 0.124658
2022-01-14 14:53:24,750 iteration 54 : loss : 0.209246, loss_ce: 0.098759
2022-01-14 14:53:26,239 iteration 55 : loss : 0.359390, loss_ce: 0.161367
2022-01-14 14:53:27,755 iteration 56 : loss : 0.250317, loss_ce: 0.109425
2022-01-14 14:53:29,259 iteration 57 : loss : 0.264150, loss_ce: 0.109904
2022-01-14 14:53:30,747 iteration 58 : loss : 0.275457, loss_ce: 0.124929
2022-01-14 14:53:32,209 iteration 59 : loss : 0.256777, loss_ce: 0.102830
2022-01-14 14:53:33,751 iteration 60 : loss : 0.269067, loss_ce: 0.108545
2022-01-14 14:53:35,302 iteration 61 : loss : 0.255608, loss_ce: 0.111562
2022-01-14 14:53:36,782 iteration 62 : loss : 0.292037, loss_ce: 0.127167
2022-01-14 14:53:38,189 iteration 63 : loss : 0.223112, loss_ce: 0.111687
2022-01-14 14:53:39,651 iteration 64 : loss : 0.276284, loss_ce: 0.150284
2022-01-14 14:53:41,108 iteration 65 : loss : 0.279874, loss_ce: 0.127137
2022-01-14 14:53:42,624 iteration 66 : loss : 0.268456, loss_ce: 0.128003
2022-01-14 14:53:44,049 iteration 67 : loss : 0.294060, loss_ce: 0.143948
2022-01-14 14:53:45,511 iteration 68 : loss : 0.302335, loss_ce: 0.123172
  1%|▎                              | 4/400 [01:38<2:44:00, 24.85s/it]2022-01-14 14:53:47,022 iteration 69 : loss : 0.266320, loss_ce: 0.106444
2022-01-14 14:53:48,523 iteration 70 : loss : 0.309311, loss_ce: 0.153154
2022-01-14 14:53:49,949 iteration 71 : loss : 0.248648, loss_ce: 0.105952
2022-01-14 14:53:51,471 iteration 72 : loss : 0.257943, loss_ce: 0.099213
2022-01-14 14:53:52,937 iteration 73 : loss : 0.248297, loss_ce: 0.118394
2022-01-14 14:53:54,485 iteration 74 : loss : 0.260358, loss_ce: 0.117269
2022-01-14 14:53:55,972 iteration 75 : loss : 0.255763, loss_ce: 0.139261
2022-01-14 14:53:57,499 iteration 76 : loss : 0.263366, loss_ce: 0.123562
2022-01-14 14:53:59,059 iteration 77 : loss : 0.245061, loss_ce: 0.094953
2022-01-14 14:54:00,591 iteration 78 : loss : 0.214632, loss_ce: 0.104335
2022-01-14 14:54:02,020 iteration 79 : loss : 0.208572, loss_ce: 0.081116
2022-01-14 14:54:03,548 iteration 80 : loss : 0.301205, loss_ce: 0.121905
2022-01-14 14:54:05,015 iteration 81 : loss : 0.232710, loss_ce: 0.090246
2022-01-14 14:54:06,515 iteration 82 : loss : 0.256263, loss_ce: 0.121451
2022-01-14 14:54:08,053 iteration 83 : loss : 0.225401, loss_ce: 0.083495
2022-01-14 14:54:09,501 iteration 84 : loss : 0.249527, loss_ce: 0.110955
2022-01-14 14:54:09,501 Training Data Eval:
2022-01-14 14:54:16,871   Average segmentation loss on training set: 0.3770
2022-01-14 14:54:16,872 Validation Data Eval:
2022-01-14 14:54:19,653   Average segmentation loss on validation set: 0.4256
2022-01-14 14:54:25,408 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed2.pth
2022-01-14 14:54:26,838 iteration 85 : loss : 0.227621, loss_ce: 0.095457
  1%|▍                              | 5/400 [02:20<3:22:42, 30.79s/it]2022-01-14 14:54:28,229 iteration 86 : loss : 0.302391, loss_ce: 0.111524
2022-01-14 14:54:29,509 iteration 87 : loss : 0.243939, loss_ce: 0.099842
2022-01-14 14:54:30,926 iteration 88 : loss : 0.228144, loss_ce: 0.087449
2022-01-14 14:54:32,468 iteration 89 : loss : 0.223547, loss_ce: 0.097294
2022-01-14 14:54:33,910 iteration 90 : loss : 0.203813, loss_ce: 0.087510
2022-01-14 14:54:35,411 iteration 91 : loss : 0.270082, loss_ce: 0.115925
2022-01-14 14:54:36,893 iteration 92 : loss : 0.222396, loss_ce: 0.090963
2022-01-14 14:54:38,436 iteration 93 : loss : 0.239753, loss_ce: 0.097078
2022-01-14 14:54:39,971 iteration 94 : loss : 0.222246, loss_ce: 0.106223
2022-01-14 14:54:41,427 iteration 95 : loss : 0.227096, loss_ce: 0.083884
2022-01-14 14:54:42,843 iteration 96 : loss : 0.219004, loss_ce: 0.078518
2022-01-14 14:54:44,261 iteration 97 : loss : 0.182439, loss_ce: 0.069913
2022-01-14 14:54:45,718 iteration 98 : loss : 0.286406, loss_ce: 0.130172
2022-01-14 14:54:47,309 iteration 99 : loss : 0.222371, loss_ce: 0.088075
2022-01-14 14:54:48,908 iteration 100 : loss : 0.226070, loss_ce: 0.091141
2022-01-14 14:54:50,386 iteration 101 : loss : 0.271704, loss_ce: 0.126558
2022-01-14 14:54:51,883 iteration 102 : loss : 0.224125, loss_ce: 0.079566
  2%|▍                              | 6/400 [02:45<3:09:22, 28.84s/it]2022-01-14 14:54:53,452 iteration 103 : loss : 0.231229, loss_ce: 0.090459
2022-01-14 14:54:55,020 iteration 104 : loss : 0.233629, loss_ce: 0.086448
2022-01-14 14:54:56,537 iteration 105 : loss : 0.218274, loss_ce: 0.090201
2022-01-14 14:54:58,039 iteration 106 : loss : 0.214050, loss_ce: 0.080422
2022-01-14 14:54:59,598 iteration 107 : loss : 0.200278, loss_ce: 0.082947
2022-01-14 14:55:01,065 iteration 108 : loss : 0.218445, loss_ce: 0.100042
2022-01-14 14:55:02,556 iteration 109 : loss : 0.188519, loss_ce: 0.070803
2022-01-14 14:55:04,077 iteration 110 : loss : 0.237744, loss_ce: 0.106237
2022-01-14 14:55:05,731 iteration 111 : loss : 0.195723, loss_ce: 0.077571
2022-01-14 14:55:07,185 iteration 112 : loss : 0.225153, loss_ce: 0.078559
2022-01-14 14:55:08,777 iteration 113 : loss : 0.183562, loss_ce: 0.062823
2022-01-14 14:55:10,271 iteration 114 : loss : 0.187220, loss_ce: 0.058521
2022-01-14 14:55:11,684 iteration 115 : loss : 0.184604, loss_ce: 0.064177
2022-01-14 14:55:13,172 iteration 116 : loss : 0.236702, loss_ce: 0.094229
2022-01-14 14:55:14,634 iteration 117 : loss : 0.198756, loss_ce: 0.076286
2022-01-14 14:55:16,173 iteration 118 : loss : 0.234496, loss_ce: 0.091080
2022-01-14 14:55:17,627 iteration 119 : loss : 0.255416, loss_ce: 0.118764
  2%|▌                              | 7/400 [03:10<3:02:15, 27.83s/it]2022-01-14 14:55:19,207 iteration 120 : loss : 0.234087, loss_ce: 0.105466
2022-01-14 14:55:20,726 iteration 121 : loss : 0.280114, loss_ce: 0.118668
2022-01-14 14:55:22,113 iteration 122 : loss : 0.207451, loss_ce: 0.084149
2022-01-14 14:55:23,604 iteration 123 : loss : 0.260408, loss_ce: 0.113133
2022-01-14 14:55:25,067 iteration 124 : loss : 0.244800, loss_ce: 0.095647
2022-01-14 14:55:26,534 iteration 125 : loss : 0.235248, loss_ce: 0.098431
2022-01-14 14:55:27,990 iteration 126 : loss : 0.201278, loss_ce: 0.085510
2022-01-14 14:55:29,468 iteration 127 : loss : 0.261971, loss_ce: 0.118845
2022-01-14 14:55:30,916 iteration 128 : loss : 0.231727, loss_ce: 0.087234
2022-01-14 14:55:32,454 iteration 129 : loss : 0.267159, loss_ce: 0.110267
2022-01-14 14:55:33,831 iteration 130 : loss : 0.210614, loss_ce: 0.082995
2022-01-14 14:55:35,288 iteration 131 : loss : 0.224909, loss_ce: 0.106077
2022-01-14 14:55:36,769 iteration 132 : loss : 0.232237, loss_ce: 0.088609
2022-01-14 14:55:38,253 iteration 133 : loss : 0.302326, loss_ce: 0.147552
2022-01-14 14:55:39,713 iteration 134 : loss : 0.162867, loss_ce: 0.056326
2022-01-14 14:55:41,165 iteration 135 : loss : 0.188985, loss_ce: 0.059133
2022-01-14 14:55:42,713 iteration 136 : loss : 0.207797, loss_ce: 0.083514
  2%|▌                              | 8/400 [03:36<2:56:05, 26.95s/it]2022-01-14 14:55:44,302 iteration 137 : loss : 0.206080, loss_ce: 0.071230
2022-01-14 14:55:45,723 iteration 138 : loss : 0.180941, loss_ce: 0.065829
2022-01-14 14:55:47,287 iteration 139 : loss : 0.203611, loss_ce: 0.058134
2022-01-14 14:55:48,757 iteration 140 : loss : 0.270365, loss_ce: 0.114293
2022-01-14 14:55:50,184 iteration 141 : loss : 0.252004, loss_ce: 0.104776
2022-01-14 14:55:51,646 iteration 142 : loss : 0.205447, loss_ce: 0.082362
2022-01-14 14:55:53,131 iteration 143 : loss : 0.219201, loss_ce: 0.079269
2022-01-14 14:55:54,586 iteration 144 : loss : 0.190283, loss_ce: 0.056994
2022-01-14 14:55:56,071 iteration 145 : loss : 0.228984, loss_ce: 0.106577
2022-01-14 14:55:57,589 iteration 146 : loss : 0.176472, loss_ce: 0.063529
2022-01-14 14:55:59,078 iteration 147 : loss : 0.255637, loss_ce: 0.113503
2022-01-14 14:56:00,652 iteration 148 : loss : 0.201207, loss_ce: 0.084619
2022-01-14 14:56:02,235 iteration 149 : loss : 0.224355, loss_ce: 0.093254
2022-01-14 14:56:03,793 iteration 150 : loss : 0.207517, loss_ce: 0.086502
2022-01-14 14:56:05,238 iteration 151 : loss : 0.196500, loss_ce: 0.099803
2022-01-14 14:56:06,629 iteration 152 : loss : 0.155082, loss_ce: 0.064977
2022-01-14 14:56:08,091 iteration 153 : loss : 0.194554, loss_ce: 0.074146
  2%|▋                              | 9/400 [04:01<2:52:25, 26.46s/it]2022-01-14 14:56:09,652 iteration 154 : loss : 0.225986, loss_ce: 0.104920
2022-01-14 14:56:11,130 iteration 155 : loss : 0.179150, loss_ce: 0.079747
2022-01-14 14:56:12,566 iteration 156 : loss : 0.215612, loss_ce: 0.086557
2022-01-14 14:56:14,008 iteration 157 : loss : 0.216886, loss_ce: 0.086393
2022-01-14 14:56:15,551 iteration 158 : loss : 0.235650, loss_ce: 0.088645
2022-01-14 14:56:17,088 iteration 159 : loss : 0.191719, loss_ce: 0.073613
2022-01-14 14:56:18,546 iteration 160 : loss : 0.193267, loss_ce: 0.067476
2022-01-14 14:56:20,112 iteration 161 : loss : 0.176217, loss_ce: 0.072523
2022-01-14 14:56:21,601 iteration 162 : loss : 0.202657, loss_ce: 0.070017
2022-01-14 14:56:23,093 iteration 163 : loss : 0.224718, loss_ce: 0.097819
2022-01-14 14:56:24,565 iteration 164 : loss : 0.219099, loss_ce: 0.069543
2022-01-14 14:56:25,982 iteration 165 : loss : 0.183628, loss_ce: 0.067595
2022-01-14 14:56:27,497 iteration 166 : loss : 0.257252, loss_ce: 0.131352
2022-01-14 14:56:29,090 iteration 167 : loss : 0.253941, loss_ce: 0.116280
2022-01-14 14:56:30,563 iteration 168 : loss : 0.222483, loss_ce: 0.069419
2022-01-14 14:56:32,066 iteration 169 : loss : 0.212626, loss_ce: 0.074537
2022-01-14 14:56:32,067 Training Data Eval:
2022-01-14 14:56:39,441   Average segmentation loss on training set: 0.4261
2022-01-14 14:56:39,442 Validation Data Eval:
2022-01-14 14:56:41,986   Average segmentation loss on validation set: 0.5017
2022-01-14 14:56:43,545 iteration 170 : loss : 0.254604, loss_ce: 0.109088
  2%|▊                             | 10/400 [04:36<3:10:01, 29.24s/it]2022-01-14 14:56:45,127 iteration 171 : loss : 0.155196, loss_ce: 0.062250
2022-01-14 14:56:46,576 iteration 172 : loss : 0.185596, loss_ce: 0.077416
2022-01-14 14:56:48,111 iteration 173 : loss : 0.210407, loss_ce: 0.081961
2022-01-14 14:56:49,514 iteration 174 : loss : 0.192804, loss_ce: 0.091389
2022-01-14 14:56:50,964 iteration 175 : loss : 0.196056, loss_ce: 0.065169
2022-01-14 14:56:52,414 iteration 176 : loss : 0.171315, loss_ce: 0.069955
2022-01-14 14:56:53,917 iteration 177 : loss : 0.160354, loss_ce: 0.059256
2022-01-14 14:56:55,387 iteration 178 : loss : 0.179722, loss_ce: 0.064795
2022-01-14 14:56:56,793 iteration 179 : loss : 0.176874, loss_ce: 0.062317
2022-01-14 14:56:58,353 iteration 180 : loss : 0.216400, loss_ce: 0.097062
2022-01-14 14:56:59,869 iteration 181 : loss : 0.204643, loss_ce: 0.093696
2022-01-14 14:57:01,344 iteration 182 : loss : 0.184006, loss_ce: 0.081857
2022-01-14 14:57:02,848 iteration 183 : loss : 0.194512, loss_ce: 0.064300
2022-01-14 14:57:04,476 iteration 184 : loss : 0.221246, loss_ce: 0.078452
2022-01-14 14:57:06,094 iteration 185 : loss : 0.192491, loss_ce: 0.080213
2022-01-14 14:57:07,561 iteration 186 : loss : 0.183946, loss_ce: 0.059549
2022-01-14 14:57:09,061 iteration 187 : loss : 0.159443, loss_ce: 0.060725
  3%|▊                             | 11/400 [05:02<3:02:09, 28.10s/it]2022-01-14 14:57:10,545 iteration 188 : loss : 0.195628, loss_ce: 0.080767
2022-01-14 14:57:12,118 iteration 189 : loss : 0.214887, loss_ce: 0.090457
2022-01-14 14:57:13,638 iteration 190 : loss : 0.247076, loss_ce: 0.109634
2022-01-14 14:57:15,145 iteration 191 : loss : 0.148648, loss_ce: 0.054701
2022-01-14 14:57:16,626 iteration 192 : loss : 0.198877, loss_ce: 0.072015
2022-01-14 14:57:18,040 iteration 193 : loss : 0.173382, loss_ce: 0.071054
2022-01-14 14:57:19,556 iteration 194 : loss : 0.172253, loss_ce: 0.068901
2022-01-14 14:57:21,120 iteration 195 : loss : 0.143976, loss_ce: 0.051271
2022-01-14 14:57:22,591 iteration 196 : loss : 0.155453, loss_ce: 0.061159
2022-01-14 14:57:24,111 iteration 197 : loss : 0.170426, loss_ce: 0.055172
2022-01-14 14:57:25,613 iteration 198 : loss : 0.161309, loss_ce: 0.060064
2022-01-14 14:57:27,001 iteration 199 : loss : 0.199626, loss_ce: 0.060715
2022-01-14 14:57:28,468 iteration 200 : loss : 0.200013, loss_ce: 0.092489
2022-01-14 14:57:30,072 iteration 201 : loss : 0.169520, loss_ce: 0.069975
2022-01-14 14:57:31,528 iteration 202 : loss : 0.146812, loss_ce: 0.060796
2022-01-14 14:57:32,966 iteration 203 : loss : 0.232781, loss_ce: 0.129186
2022-01-14 14:57:34,374 iteration 204 : loss : 0.141881, loss_ce: 0.062108
  3%|▉                             | 12/400 [05:27<2:56:14, 27.25s/it]2022-01-14 14:57:35,837 iteration 205 : loss : 0.177014, loss_ce: 0.076363
2022-01-14 14:57:37,339 iteration 206 : loss : 0.228461, loss_ce: 0.106694
2022-01-14 14:57:38,937 iteration 207 : loss : 0.170608, loss_ce: 0.077767
2022-01-14 14:57:40,523 iteration 208 : loss : 0.147691, loss_ce: 0.051652
2022-01-14 14:57:41,967 iteration 209 : loss : 0.139422, loss_ce: 0.053155
2022-01-14 14:57:43,383 iteration 210 : loss : 0.133281, loss_ce: 0.043054
2022-01-14 14:57:44,859 iteration 211 : loss : 0.142727, loss_ce: 0.049838
2022-01-14 14:57:46,251 iteration 212 : loss : 0.190572, loss_ce: 0.070860
2022-01-14 14:57:47,778 iteration 213 : loss : 0.134089, loss_ce: 0.053842
2022-01-14 14:57:49,276 iteration 214 : loss : 0.174106, loss_ce: 0.054450
2022-01-14 14:57:50,693 iteration 215 : loss : 0.166474, loss_ce: 0.069812
2022-01-14 14:57:52,229 iteration 216 : loss : 0.199644, loss_ce: 0.079375
2022-01-14 14:57:53,674 iteration 217 : loss : 0.134541, loss_ce: 0.058216
2022-01-14 14:57:55,128 iteration 218 : loss : 0.122987, loss_ce: 0.047010
2022-01-14 14:57:56,586 iteration 219 : loss : 0.129762, loss_ce: 0.045944
2022-01-14 14:57:58,004 iteration 220 : loss : 0.156372, loss_ce: 0.079215
2022-01-14 14:57:59,460 iteration 221 : loss : 0.124835, loss_ce: 0.065706
  3%|▉                             | 13/400 [05:52<2:51:33, 26.60s/it]2022-01-14 14:58:01,106 iteration 222 : loss : 0.163555, loss_ce: 0.058607
2022-01-14 14:58:02,633 iteration 223 : loss : 0.111773, loss_ce: 0.045062
2022-01-14 14:58:04,021 iteration 224 : loss : 0.127942, loss_ce: 0.056587
2022-01-14 14:58:05,576 iteration 225 : loss : 0.113530, loss_ce: 0.045601
2022-01-14 14:58:07,101 iteration 226 : loss : 0.165142, loss_ce: 0.051021
2022-01-14 14:58:08,621 iteration 227 : loss : 0.155035, loss_ce: 0.058344
2022-01-14 14:58:10,118 iteration 228 : loss : 0.162953, loss_ce: 0.061801
2022-01-14 14:58:11,613 iteration 229 : loss : 0.123242, loss_ce: 0.061861
2022-01-14 14:58:13,088 iteration 230 : loss : 0.176423, loss_ce: 0.083108
2022-01-14 14:58:14,536 iteration 231 : loss : 0.177135, loss_ce: 0.055773
2022-01-14 14:58:16,093 iteration 232 : loss : 0.147081, loss_ce: 0.083400
2022-01-14 14:58:17,638 iteration 233 : loss : 0.148989, loss_ce: 0.082963
2022-01-14 14:58:19,155 iteration 234 : loss : 0.172638, loss_ce: 0.053329
2022-01-14 14:58:20,632 iteration 235 : loss : 0.138749, loss_ce: 0.050807
2022-01-14 14:58:22,094 iteration 236 : loss : 0.199249, loss_ce: 0.080086
2022-01-14 14:58:23,547 iteration 237 : loss : 0.126513, loss_ce: 0.049142
2022-01-14 14:58:24,922 iteration 238 : loss : 0.146806, loss_ce: 0.072009
  4%|█                             | 14/400 [06:18<2:48:52, 26.25s/it]2022-01-14 14:58:26,393 iteration 239 : loss : 0.152925, loss_ce: 0.060978
2022-01-14 14:58:27,940 iteration 240 : loss : 0.124135, loss_ce: 0.067853
2022-01-14 14:58:29,383 iteration 241 : loss : 0.198852, loss_ce: 0.069718
2022-01-14 14:58:30,917 iteration 242 : loss : 0.129104, loss_ce: 0.054545
2022-01-14 14:58:32,466 iteration 243 : loss : 0.182177, loss_ce: 0.078398
2022-01-14 14:58:34,005 iteration 244 : loss : 0.120093, loss_ce: 0.054289
2022-01-14 14:58:35,413 iteration 245 : loss : 0.130492, loss_ce: 0.048611
2022-01-14 14:58:36,904 iteration 246 : loss : 0.155255, loss_ce: 0.057365
2022-01-14 14:58:38,325 iteration 247 : loss : 0.096578, loss_ce: 0.045792
2022-01-14 14:58:39,717 iteration 248 : loss : 0.094083, loss_ce: 0.035947
2022-01-14 14:58:41,290 iteration 249 : loss : 0.151127, loss_ce: 0.048305
2022-01-14 14:58:42,824 iteration 250 : loss : 0.160757, loss_ce: 0.073210
2022-01-14 14:58:44,288 iteration 251 : loss : 0.089538, loss_ce: 0.041071
2022-01-14 14:58:45,769 iteration 252 : loss : 0.134635, loss_ce: 0.073926
2022-01-14 14:58:47,197 iteration 253 : loss : 0.186250, loss_ce: 0.068707
2022-01-14 14:58:48,623 iteration 254 : loss : 0.143067, loss_ce: 0.063082
2022-01-14 14:58:48,624 Training Data Eval:
2022-01-14 14:58:56,005   Average segmentation loss on training set: 0.1654
2022-01-14 14:58:56,006 Validation Data Eval:
2022-01-14 14:58:58,547   Average segmentation loss on validation set: 0.1551
2022-01-14 14:59:04,330 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed2.pth
2022-01-14 14:59:05,723 iteration 255 : loss : 0.220038, loss_ce: 0.103829
  4%|█▏                            | 15/400 [06:59<3:16:35, 30.64s/it]2022-01-14 14:59:07,141 iteration 256 : loss : 0.132181, loss_ce: 0.050620
2022-01-14 14:59:08,492 iteration 257 : loss : 0.143584, loss_ce: 0.066736
2022-01-14 14:59:10,018 iteration 258 : loss : 0.178524, loss_ce: 0.058760
2022-01-14 14:59:11,446 iteration 259 : loss : 0.184291, loss_ce: 0.073829
2022-01-14 14:59:12,954 iteration 260 : loss : 0.156710, loss_ce: 0.075416
2022-01-14 14:59:14,479 iteration 261 : loss : 0.158305, loss_ce: 0.076462
2022-01-14 14:59:15,993 iteration 262 : loss : 0.155659, loss_ce: 0.085964
2022-01-14 14:59:17,439 iteration 263 : loss : 0.177933, loss_ce: 0.099883
2022-01-14 14:59:18,868 iteration 264 : loss : 0.166150, loss_ce: 0.067477
2022-01-14 14:59:20,385 iteration 265 : loss : 0.147483, loss_ce: 0.073414
2022-01-14 14:59:21,885 iteration 266 : loss : 0.210358, loss_ce: 0.074290
2022-01-14 14:59:23,349 iteration 267 : loss : 0.148605, loss_ce: 0.062277
2022-01-14 14:59:24,826 iteration 268 : loss : 0.120602, loss_ce: 0.056052
2022-01-14 14:59:26,279 iteration 269 : loss : 0.108317, loss_ce: 0.042779
2022-01-14 14:59:27,670 iteration 270 : loss : 0.145165, loss_ce: 0.052461
2022-01-14 14:59:29,162 iteration 271 : loss : 0.213385, loss_ce: 0.072975
2022-01-14 14:59:30,709 iteration 272 : loss : 0.163284, loss_ce: 0.078252
  4%|█▏                            | 16/400 [07:24<3:05:12, 28.94s/it]2022-01-14 14:59:32,250 iteration 273 : loss : 0.145801, loss_ce: 0.064708
2022-01-14 14:59:33,790 iteration 274 : loss : 0.144719, loss_ce: 0.061597
2022-01-14 14:59:35,304 iteration 275 : loss : 0.109935, loss_ce: 0.056665
2022-01-14 14:59:36,751 iteration 276 : loss : 0.154777, loss_ce: 0.076432
2022-01-14 14:59:38,303 iteration 277 : loss : 0.165199, loss_ce: 0.059800
2022-01-14 14:59:39,708 iteration 278 : loss : 0.280662, loss_ce: 0.098350
2022-01-14 14:59:41,183 iteration 279 : loss : 0.136301, loss_ce: 0.053576
2022-01-14 14:59:42,570 iteration 280 : loss : 0.121646, loss_ce: 0.061847
2022-01-14 14:59:44,054 iteration 281 : loss : 0.137131, loss_ce: 0.046577
2022-01-14 14:59:45,570 iteration 282 : loss : 0.178719, loss_ce: 0.077680
2022-01-14 14:59:47,056 iteration 283 : loss : 0.144792, loss_ce: 0.073434
2022-01-14 14:59:48,478 iteration 284 : loss : 0.081609, loss_ce: 0.037101
2022-01-14 14:59:49,959 iteration 285 : loss : 0.107622, loss_ce: 0.046520
2022-01-14 14:59:51,463 iteration 286 : loss : 0.104027, loss_ce: 0.042810
2022-01-14 14:59:52,890 iteration 287 : loss : 0.165162, loss_ce: 0.053558
2022-01-14 14:59:54,349 iteration 288 : loss : 0.096830, loss_ce: 0.046960
2022-01-14 14:59:55,814 iteration 289 : loss : 0.122589, loss_ce: 0.067977
  4%|█▎                            | 17/400 [07:49<2:57:22, 27.79s/it]2022-01-14 14:59:57,344 iteration 290 : loss : 0.112371, loss_ce: 0.048658
2022-01-14 14:59:58,818 iteration 291 : loss : 0.100086, loss_ce: 0.041654
2022-01-14 15:00:00,293 iteration 292 : loss : 0.101200, loss_ce: 0.042918
2022-01-14 15:00:01,901 iteration 293 : loss : 0.176266, loss_ce: 0.086230
2022-01-14 15:00:03,339 iteration 294 : loss : 0.086671, loss_ce: 0.036234
2022-01-14 15:00:04,775 iteration 295 : loss : 0.149973, loss_ce: 0.050839
2022-01-14 15:00:06,228 iteration 296 : loss : 0.121045, loss_ce: 0.048678
2022-01-14 15:00:07,762 iteration 297 : loss : 0.113558, loss_ce: 0.054188
2022-01-14 15:00:09,199 iteration 298 : loss : 0.115771, loss_ce: 0.050463
2022-01-14 15:00:10,700 iteration 299 : loss : 0.166024, loss_ce: 0.056948
2022-01-14 15:00:12,143 iteration 300 : loss : 0.131024, loss_ce: 0.049712
2022-01-14 15:00:13,613 iteration 301 : loss : 0.134844, loss_ce: 0.053581
2022-01-14 15:00:15,182 iteration 302 : loss : 0.150038, loss_ce: 0.074583
2022-01-14 15:00:16,692 iteration 303 : loss : 0.151143, loss_ce: 0.071620
2022-01-14 15:00:18,148 iteration 304 : loss : 0.101214, loss_ce: 0.040491
2022-01-14 15:00:19,623 iteration 305 : loss : 0.133594, loss_ce: 0.054079
2022-01-14 15:00:21,093 iteration 306 : loss : 0.160503, loss_ce: 0.065955
  4%|█▎                            | 18/400 [08:14<2:52:05, 27.03s/it]2022-01-14 15:00:22,585 iteration 307 : loss : 0.147519, loss_ce: 0.064432
2022-01-14 15:00:24,106 iteration 308 : loss : 0.153943, loss_ce: 0.053154
2022-01-14 15:00:25,584 iteration 309 : loss : 0.122207, loss_ce: 0.063122
2022-01-14 15:00:27,034 iteration 310 : loss : 0.108974, loss_ce: 0.042813
2022-01-14 15:00:28,472 iteration 311 : loss : 0.123438, loss_ce: 0.051634
2022-01-14 15:00:29,956 iteration 312 : loss : 0.170921, loss_ce: 0.040916
2022-01-14 15:00:31,475 iteration 313 : loss : 0.140743, loss_ce: 0.046814
2022-01-14 15:00:32,856 iteration 314 : loss : 0.139682, loss_ce: 0.056267
2022-01-14 15:00:34,301 iteration 315 : loss : 0.133097, loss_ce: 0.054451
2022-01-14 15:00:35,840 iteration 316 : loss : 0.177364, loss_ce: 0.071810
2022-01-14 15:00:37,389 iteration 317 : loss : 0.109375, loss_ce: 0.054658
2022-01-14 15:00:38,859 iteration 318 : loss : 0.143942, loss_ce: 0.067046
2022-01-14 15:00:40,344 iteration 319 : loss : 0.117186, loss_ce: 0.058928
2022-01-14 15:00:41,827 iteration 320 : loss : 0.158815, loss_ce: 0.069196
2022-01-14 15:00:43,269 iteration 321 : loss : 0.190433, loss_ce: 0.082993
2022-01-14 15:00:44,687 iteration 322 : loss : 0.119194, loss_ce: 0.064184
2022-01-14 15:00:46,142 iteration 323 : loss : 0.124945, loss_ce: 0.062934
  5%|█▍                            | 19/400 [08:39<2:47:52, 26.44s/it]2022-01-14 15:00:47,666 iteration 324 : loss : 0.110845, loss_ce: 0.050905
2022-01-14 15:00:49,107 iteration 325 : loss : 0.148295, loss_ce: 0.049195
2022-01-14 15:00:50,543 iteration 326 : loss : 0.162706, loss_ce: 0.061247
2022-01-14 15:00:51,960 iteration 327 : loss : 0.203064, loss_ce: 0.081465
2022-01-14 15:00:53,462 iteration 328 : loss : 0.099499, loss_ce: 0.032763
2022-01-14 15:00:54,996 iteration 329 : loss : 0.157176, loss_ce: 0.055755
2022-01-14 15:00:56,444 iteration 330 : loss : 0.119324, loss_ce: 0.062106
2022-01-14 15:00:57,912 iteration 331 : loss : 0.144200, loss_ce: 0.066182
2022-01-14 15:00:59,301 iteration 332 : loss : 0.087522, loss_ce: 0.044303
2022-01-14 15:01:00,824 iteration 333 : loss : 0.138523, loss_ce: 0.067401
2022-01-14 15:01:02,301 iteration 334 : loss : 0.108817, loss_ce: 0.048401
2022-01-14 15:01:03,840 iteration 335 : loss : 0.145996, loss_ce: 0.087022
2022-01-14 15:01:05,301 iteration 336 : loss : 0.128318, loss_ce: 0.060173
2022-01-14 15:01:06,747 iteration 337 : loss : 0.158178, loss_ce: 0.060937
2022-01-14 15:01:08,216 iteration 338 : loss : 0.099650, loss_ce: 0.044726
2022-01-14 15:01:09,659 iteration 339 : loss : 0.126447, loss_ce: 0.059949
2022-01-14 15:01:09,659 Training Data Eval:
2022-01-14 15:01:17,033   Average segmentation loss on training set: 0.1141
2022-01-14 15:01:17,033 Validation Data Eval:
2022-01-14 15:01:19,573   Average segmentation loss on validation set: 0.1208
2022-01-14 15:01:24,973 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed2.pth
2022-01-14 15:01:26,410 iteration 340 : loss : 0.154233, loss_ce: 0.081699
  5%|█▌                            | 20/400 [09:19<3:13:43, 30.59s/it]2022-01-14 15:01:27,819 iteration 341 : loss : 0.076700, loss_ce: 0.036713
2022-01-14 15:01:29,232 iteration 342 : loss : 0.100866, loss_ce: 0.047352
2022-01-14 15:01:30,729 iteration 343 : loss : 0.128425, loss_ce: 0.051958
2022-01-14 15:01:32,182 iteration 344 : loss : 0.127269, loss_ce: 0.063793
2022-01-14 15:01:33,635 iteration 345 : loss : 0.098618, loss_ce: 0.044116
2022-01-14 15:01:35,150 iteration 346 : loss : 0.094530, loss_ce: 0.038273
2022-01-14 15:01:36,673 iteration 347 : loss : 0.155724, loss_ce: 0.072180
2022-01-14 15:01:38,132 iteration 348 : loss : 0.113271, loss_ce: 0.046322
2022-01-14 15:01:39,601 iteration 349 : loss : 0.101699, loss_ce: 0.040156
2022-01-14 15:01:41,105 iteration 350 : loss : 0.159955, loss_ce: 0.077095
2022-01-14 15:01:42,571 iteration 351 : loss : 0.117150, loss_ce: 0.044790
2022-01-14 15:01:44,145 iteration 352 : loss : 0.093761, loss_ce: 0.056901
2022-01-14 15:01:45,709 iteration 353 : loss : 0.104402, loss_ce: 0.045359
2022-01-14 15:01:47,169 iteration 354 : loss : 0.138985, loss_ce: 0.045722
2022-01-14 15:01:48,683 iteration 355 : loss : 0.084451, loss_ce: 0.027290
2022-01-14 15:01:50,169 iteration 356 : loss : 0.101665, loss_ce: 0.031708
2022-01-14 15:01:51,669 iteration 357 : loss : 0.096247, loss_ce: 0.035003
  5%|█▌                            | 21/400 [09:44<3:03:06, 28.99s/it]2022-01-14 15:01:53,291 iteration 358 : loss : 0.147840, loss_ce: 0.077737
2022-01-14 15:01:54,856 iteration 359 : loss : 0.103599, loss_ce: 0.041329
2022-01-14 15:01:56,311 iteration 360 : loss : 0.091432, loss_ce: 0.031023
2022-01-14 15:01:57,823 iteration 361 : loss : 0.139209, loss_ce: 0.053083
2022-01-14 15:01:59,331 iteration 362 : loss : 0.105159, loss_ce: 0.058550
2022-01-14 15:02:00,742 iteration 363 : loss : 0.105985, loss_ce: 0.050575
2022-01-14 15:02:02,261 iteration 364 : loss : 0.203286, loss_ce: 0.074576
2022-01-14 15:02:03,697 iteration 365 : loss : 0.106880, loss_ce: 0.045909
2022-01-14 15:02:05,159 iteration 366 : loss : 0.160185, loss_ce: 0.051899
2022-01-14 15:02:06,647 iteration 367 : loss : 0.118873, loss_ce: 0.052410
2022-01-14 15:02:08,113 iteration 368 : loss : 0.117263, loss_ce: 0.050815
2022-01-14 15:02:09,554 iteration 369 : loss : 0.115877, loss_ce: 0.040611
2022-01-14 15:02:11,028 iteration 370 : loss : 0.141601, loss_ce: 0.073929
2022-01-14 15:02:12,504 iteration 371 : loss : 0.107142, loss_ce: 0.042364
2022-01-14 15:02:13,937 iteration 372 : loss : 0.102460, loss_ce: 0.043996
2022-01-14 15:02:15,402 iteration 373 : loss : 0.065076, loss_ce: 0.028511
2022-01-14 15:02:16,910 iteration 374 : loss : 0.086949, loss_ce: 0.038096
  6%|█▋                            | 22/400 [10:10<2:55:32, 27.86s/it]2022-01-14 15:02:18,433 iteration 375 : loss : 0.087690, loss_ce: 0.041841
2022-01-14 15:02:19,894 iteration 376 : loss : 0.156039, loss_ce: 0.044730
2022-01-14 15:02:21,377 iteration 377 : loss : 0.099146, loss_ce: 0.036775
2022-01-14 15:02:22,927 iteration 378 : loss : 0.092035, loss_ce: 0.033800
2022-01-14 15:02:24,428 iteration 379 : loss : 0.106947, loss_ce: 0.041559
2022-01-14 15:02:25,878 iteration 380 : loss : 0.113895, loss_ce: 0.057780
2022-01-14 15:02:27,374 iteration 381 : loss : 0.113798, loss_ce: 0.046315
2022-01-14 15:02:28,786 iteration 382 : loss : 0.092925, loss_ce: 0.042627
2022-01-14 15:02:30,280 iteration 383 : loss : 0.165753, loss_ce: 0.043394
2022-01-14 15:02:31,758 iteration 384 : loss : 0.131241, loss_ce: 0.048001
2022-01-14 15:02:33,209 iteration 385 : loss : 0.107220, loss_ce: 0.047794
2022-01-14 15:02:34,697 iteration 386 : loss : 0.108102, loss_ce: 0.039015
2022-01-14 15:02:36,134 iteration 387 : loss : 0.074772, loss_ce: 0.031865
2022-01-14 15:02:37,644 iteration 388 : loss : 0.118507, loss_ce: 0.051897
2022-01-14 15:02:39,110 iteration 389 : loss : 0.118447, loss_ce: 0.036958
2022-01-14 15:02:40,595 iteration 390 : loss : 0.118591, loss_ce: 0.060558
2022-01-14 15:02:42,102 iteration 391 : loss : 0.074256, loss_ce: 0.029208
  6%|█▋                            | 23/400 [10:35<2:50:03, 27.06s/it]2022-01-14 15:02:43,688 iteration 392 : loss : 0.104363, loss_ce: 0.046084
2022-01-14 15:02:45,118 iteration 393 : loss : 0.084317, loss_ce: 0.041095
2022-01-14 15:02:46,632 iteration 394 : loss : 0.114735, loss_ce: 0.046066
2022-01-14 15:02:48,064 iteration 395 : loss : 0.087349, loss_ce: 0.035688
2022-01-14 15:02:49,530 iteration 396 : loss : 0.085357, loss_ce: 0.035032
2022-01-14 15:02:51,084 iteration 397 : loss : 0.106218, loss_ce: 0.050347
2022-01-14 15:02:52,547 iteration 398 : loss : 0.092223, loss_ce: 0.034920
2022-01-14 15:02:54,030 iteration 399 : loss : 0.122213, loss_ce: 0.044625
2022-01-14 15:02:55,478 iteration 400 : loss : 0.077001, loss_ce: 0.033243
2022-01-14 15:02:56,971 iteration 401 : loss : 0.061586, loss_ce: 0.031108
2022-01-14 15:02:58,547 iteration 402 : loss : 0.077823, loss_ce: 0.031124
2022-01-14 15:03:00,069 iteration 403 : loss : 0.093582, loss_ce: 0.036112
2022-01-14 15:03:01,524 iteration 404 : loss : 0.073248, loss_ce: 0.026114
2022-01-14 15:03:02,991 iteration 405 : loss : 0.127521, loss_ce: 0.066308
2022-01-14 15:03:04,506 iteration 406 : loss : 0.110688, loss_ce: 0.050349
2022-01-14 15:03:06,018 iteration 407 : loss : 0.087228, loss_ce: 0.037361
2022-01-14 15:03:07,410 iteration 408 : loss : 0.081952, loss_ce: 0.037340
  6%|█▊                            | 24/400 [11:00<2:46:17, 26.54s/it]2022-01-14 15:03:08,996 iteration 409 : loss : 0.117850, loss_ce: 0.041148
2022-01-14 15:03:10,503 iteration 410 : loss : 0.108375, loss_ce: 0.039254
2022-01-14 15:03:12,010 iteration 411 : loss : 0.106180, loss_ce: 0.034210
2022-01-14 15:03:13,472 iteration 412 : loss : 0.100553, loss_ce: 0.044387
2022-01-14 15:03:14,943 iteration 413 : loss : 0.106595, loss_ce: 0.030396
2022-01-14 15:03:16,372 iteration 414 : loss : 0.108231, loss_ce: 0.044228
2022-01-14 15:03:17,913 iteration 415 : loss : 0.098723, loss_ce: 0.045483
2022-01-14 15:03:19,359 iteration 416 : loss : 0.083267, loss_ce: 0.037677
2022-01-14 15:03:20,865 iteration 417 : loss : 0.121513, loss_ce: 0.045535
2022-01-14 15:03:22,271 iteration 418 : loss : 0.090663, loss_ce: 0.057128
2022-01-14 15:03:23,730 iteration 419 : loss : 0.130716, loss_ce: 0.051097
2022-01-14 15:03:25,203 iteration 420 : loss : 0.091470, loss_ce: 0.041355
2022-01-14 15:03:26,749 iteration 421 : loss : 0.125107, loss_ce: 0.061210
2022-01-14 15:03:28,199 iteration 422 : loss : 0.071304, loss_ce: 0.023713
2022-01-14 15:03:29,677 iteration 423 : loss : 0.116361, loss_ce: 0.042152
2022-01-14 15:03:31,198 iteration 424 : loss : 0.082278, loss_ce: 0.031050
2022-01-14 15:03:31,199 Training Data Eval:
2022-01-14 15:03:38,574   Average segmentation loss on training set: 0.0768
2022-01-14 15:03:38,574 Validation Data Eval:
2022-01-14 15:03:41,120   Average segmentation loss on validation set: 0.0960
2022-01-14 15:03:46,899 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed2.pth
2022-01-14 15:03:48,352 iteration 425 : loss : 0.102717, loss_ce: 0.035496
  6%|█▉                            | 25/400 [11:41<3:12:51, 30.86s/it]2022-01-14 15:03:49,837 iteration 426 : loss : 0.087038, loss_ce: 0.035334
2022-01-14 15:03:51,223 iteration 427 : loss : 0.152472, loss_ce: 0.065788
2022-01-14 15:03:52,660 iteration 428 : loss : 0.094560, loss_ce: 0.042226
2022-01-14 15:03:54,111 iteration 429 : loss : 0.088424, loss_ce: 0.032173
2022-01-14 15:03:55,620 iteration 430 : loss : 0.129051, loss_ce: 0.051430
2022-01-14 15:03:57,046 iteration 431 : loss : 0.137381, loss_ce: 0.052022
2022-01-14 15:03:58,507 iteration 432 : loss : 0.068179, loss_ce: 0.032554
2022-01-14 15:03:59,995 iteration 433 : loss : 0.103381, loss_ce: 0.033589
2022-01-14 15:04:01,451 iteration 434 : loss : 0.087102, loss_ce: 0.033677
2022-01-14 15:04:02,917 iteration 435 : loss : 0.129364, loss_ce: 0.064234
2022-01-14 15:04:04,432 iteration 436 : loss : 0.122787, loss_ce: 0.044049
2022-01-14 15:04:05,910 iteration 437 : loss : 0.099488, loss_ce: 0.039313
2022-01-14 15:04:07,388 iteration 438 : loss : 0.127745, loss_ce: 0.068454
2022-01-14 15:04:08,858 iteration 439 : loss : 0.102465, loss_ce: 0.046138
2022-01-14 15:04:10,290 iteration 440 : loss : 0.075159, loss_ce: 0.030790
2022-01-14 15:04:11,748 iteration 441 : loss : 0.087915, loss_ce: 0.040590
2022-01-14 15:04:13,223 iteration 442 : loss : 0.155851, loss_ce: 0.059496
  6%|█▉                            | 26/400 [12:06<3:01:08, 29.06s/it]2022-01-14 15:04:14,794 iteration 443 : loss : 0.099968, loss_ce: 0.049302
2022-01-14 15:04:16,286 iteration 444 : loss : 0.121531, loss_ce: 0.046346
2022-01-14 15:04:17,999 iteration 445 : loss : 0.110273, loss_ce: 0.048396
2022-01-14 15:04:19,421 iteration 446 : loss : 0.172578, loss_ce: 0.069174
2022-01-14 15:04:20,974 iteration 447 : loss : 0.113943, loss_ce: 0.053160
2022-01-14 15:04:22,491 iteration 448 : loss : 0.079937, loss_ce: 0.035942
2022-01-14 15:04:23,949 iteration 449 : loss : 0.085176, loss_ce: 0.034646
2022-01-14 15:04:25,349 iteration 450 : loss : 0.069906, loss_ce: 0.031073
2022-01-14 15:04:26,816 iteration 451 : loss : 0.105687, loss_ce: 0.036856
2022-01-14 15:04:28,312 iteration 452 : loss : 0.089947, loss_ce: 0.046693
2022-01-14 15:04:29,793 iteration 453 : loss : 0.048903, loss_ce: 0.018441
2022-01-14 15:04:31,308 iteration 454 : loss : 0.179399, loss_ce: 0.060260
2022-01-14 15:04:32,861 iteration 455 : loss : 0.057695, loss_ce: 0.019069
2022-01-14 15:04:34,311 iteration 456 : loss : 0.091296, loss_ce: 0.031830
2022-01-14 15:04:35,759 iteration 457 : loss : 0.114440, loss_ce: 0.045610
2022-01-14 15:04:37,230 iteration 458 : loss : 0.118910, loss_ce: 0.047600
2022-01-14 15:04:38,716 iteration 459 : loss : 0.082526, loss_ce: 0.031386
  7%|██                            | 27/400 [12:32<2:54:01, 27.99s/it]2022-01-14 15:04:40,161 iteration 460 : loss : 0.089693, loss_ce: 0.029217
2022-01-14 15:04:41,659 iteration 461 : loss : 0.093011, loss_ce: 0.039932
2022-01-14 15:04:43,140 iteration 462 : loss : 0.112343, loss_ce: 0.034817
2022-01-14 15:04:44,529 iteration 463 : loss : 0.093084, loss_ce: 0.046577
2022-01-14 15:04:46,072 iteration 464 : loss : 0.069819, loss_ce: 0.027013
2022-01-14 15:04:47,533 iteration 465 : loss : 0.092342, loss_ce: 0.052650
2022-01-14 15:04:49,048 iteration 466 : loss : 0.102046, loss_ce: 0.044354
2022-01-14 15:04:50,491 iteration 467 : loss : 0.109660, loss_ce: 0.039422
2022-01-14 15:04:51,954 iteration 468 : loss : 0.081674, loss_ce: 0.030656
2022-01-14 15:04:53,388 iteration 469 : loss : 0.084473, loss_ce: 0.032585
2022-01-14 15:04:54,932 iteration 470 : loss : 0.096338, loss_ce: 0.046132
2022-01-14 15:04:56,367 iteration 471 : loss : 0.070558, loss_ce: 0.030096
2022-01-14 15:04:57,896 iteration 472 : loss : 0.126433, loss_ce: 0.045083
2022-01-14 15:04:59,412 iteration 473 : loss : 0.108358, loss_ce: 0.041641
2022-01-14 15:05:00,946 iteration 474 : loss : 0.092739, loss_ce: 0.038922
2022-01-14 15:05:02,434 iteration 475 : loss : 0.117594, loss_ce: 0.036445
2022-01-14 15:05:03,943 iteration 476 : loss : 0.083599, loss_ce: 0.044264
  7%|██                            | 28/400 [12:57<2:48:23, 27.16s/it]2022-01-14 15:05:05,453 iteration 477 : loss : 0.075080, loss_ce: 0.033664
2022-01-14 15:05:06,975 iteration 478 : loss : 0.111332, loss_ce: 0.043295
2022-01-14 15:05:08,398 iteration 479 : loss : 0.104311, loss_ce: 0.047308
2022-01-14 15:05:09,790 iteration 480 : loss : 0.094177, loss_ce: 0.042888
2022-01-14 15:05:11,253 iteration 481 : loss : 0.090027, loss_ce: 0.042895
2022-01-14 15:05:12,781 iteration 482 : loss : 0.090826, loss_ce: 0.032638
2022-01-14 15:05:14,275 iteration 483 : loss : 0.084550, loss_ce: 0.028501
2022-01-14 15:05:15,750 iteration 484 : loss : 0.081573, loss_ce: 0.031827
2022-01-14 15:05:17,160 iteration 485 : loss : 0.058343, loss_ce: 0.023329
2022-01-14 15:05:18,629 iteration 486 : loss : 0.186896, loss_ce: 0.044725
2022-01-14 15:05:20,142 iteration 487 : loss : 0.108034, loss_ce: 0.051701
2022-01-14 15:05:21,717 iteration 488 : loss : 0.172424, loss_ce: 0.064634
2022-01-14 15:05:23,223 iteration 489 : loss : 0.073866, loss_ce: 0.031605
2022-01-14 15:05:24,675 iteration 490 : loss : 0.090805, loss_ce: 0.037909
2022-01-14 15:05:26,206 iteration 491 : loss : 0.103124, loss_ce: 0.045363
2022-01-14 15:05:27,639 iteration 492 : loss : 0.083044, loss_ce: 0.033369
2022-01-14 15:05:29,099 iteration 493 : loss : 0.118906, loss_ce: 0.065678
  7%|██▏                           | 29/400 [13:22<2:44:13, 26.56s/it]2022-01-14 15:05:30,583 iteration 494 : loss : 0.104609, loss_ce: 0.042450
2022-01-14 15:05:32,054 iteration 495 : loss : 0.069668, loss_ce: 0.028738
2022-01-14 15:05:33,449 iteration 496 : loss : 0.119010, loss_ce: 0.052160
2022-01-14 15:05:34,963 iteration 497 : loss : 0.102888, loss_ce: 0.033639
2022-01-14 15:05:36,428 iteration 498 : loss : 0.099342, loss_ce: 0.041137
2022-01-14 15:05:37,973 iteration 499 : loss : 0.084403, loss_ce: 0.041586
2022-01-14 15:05:39,365 iteration 500 : loss : 0.081418, loss_ce: 0.035352
2022-01-14 15:05:40,850 iteration 501 : loss : 0.087360, loss_ce: 0.030779
2022-01-14 15:05:42,292 iteration 502 : loss : 0.076465, loss_ce: 0.025820
2022-01-14 15:05:43,767 iteration 503 : loss : 0.136519, loss_ce: 0.062453
2022-01-14 15:05:45,320 iteration 504 : loss : 0.068943, loss_ce: 0.023328
2022-01-14 15:05:46,874 iteration 505 : loss : 0.071497, loss_ce: 0.031799
2022-01-14 15:05:48,371 iteration 506 : loss : 0.113615, loss_ce: 0.056645
2022-01-14 15:05:49,835 iteration 507 : loss : 0.081074, loss_ce: 0.030112
2022-01-14 15:05:51,341 iteration 508 : loss : 0.102375, loss_ce: 0.033204
2022-01-14 15:05:52,871 iteration 509 : loss : 0.098261, loss_ce: 0.049630
2022-01-14 15:05:52,872 Training Data Eval:
2022-01-14 15:06:00,236   Average segmentation loss on training set: 0.0843
2022-01-14 15:06:00,237 Validation Data Eval:
2022-01-14 15:06:02,782   Average segmentation loss on validation set: 0.0976
2022-01-14 15:06:04,252 iteration 510 : loss : 0.068313, loss_ce: 0.029235
  8%|██▎                           | 30/400 [13:57<2:59:41, 29.14s/it]2022-01-14 15:06:05,737 iteration 511 : loss : 0.084490, loss_ce: 0.029521
2022-01-14 15:06:07,204 iteration 512 : loss : 0.087803, loss_ce: 0.041334
2022-01-14 15:06:08,701 iteration 513 : loss : 0.091488, loss_ce: 0.034892
2022-01-14 15:06:10,211 iteration 514 : loss : 0.073175, loss_ce: 0.032323
2022-01-14 15:06:11,619 iteration 515 : loss : 0.071702, loss_ce: 0.031379
2022-01-14 15:06:12,991 iteration 516 : loss : 0.056487, loss_ce: 0.020051
2022-01-14 15:06:14,538 iteration 517 : loss : 0.097500, loss_ce: 0.045007
2022-01-14 15:06:16,109 iteration 518 : loss : 0.121090, loss_ce: 0.045484
2022-01-14 15:06:17,662 iteration 519 : loss : 0.090530, loss_ce: 0.046023
2022-01-14 15:06:19,153 iteration 520 : loss : 0.080614, loss_ce: 0.035909
2022-01-14 15:06:20,568 iteration 521 : loss : 0.061403, loss_ce: 0.021696
2022-01-14 15:06:22,093 iteration 522 : loss : 0.117383, loss_ce: 0.042133
2022-01-14 15:06:23,557 iteration 523 : loss : 0.075554, loss_ce: 0.023696
2022-01-14 15:06:25,010 iteration 524 : loss : 0.083039, loss_ce: 0.040689
2022-01-14 15:06:26,467 iteration 525 : loss : 0.067698, loss_ce: 0.028285
2022-01-14 15:06:27,983 iteration 526 : loss : 0.078016, loss_ce: 0.027251
2022-01-14 15:06:29,491 iteration 527 : loss : 0.108218, loss_ce: 0.034433
  8%|██▎                           | 31/400 [14:22<2:52:00, 27.97s/it]2022-01-14 15:06:30,988 iteration 528 : loss : 0.064876, loss_ce: 0.025013
2022-01-14 15:06:32,576 iteration 529 : loss : 0.131365, loss_ce: 0.038483
2022-01-14 15:06:34,030 iteration 530 : loss : 0.074295, loss_ce: 0.027435
2022-01-14 15:06:35,462 iteration 531 : loss : 0.076962, loss_ce: 0.026616
2022-01-14 15:06:36,955 iteration 532 : loss : 0.107855, loss_ce: 0.048959
2022-01-14 15:06:38,436 iteration 533 : loss : 0.060630, loss_ce: 0.025503
2022-01-14 15:06:39,903 iteration 534 : loss : 0.082610, loss_ce: 0.031009
2022-01-14 15:06:41,419 iteration 535 : loss : 0.081361, loss_ce: 0.029321
2022-01-14 15:06:42,935 iteration 536 : loss : 0.085584, loss_ce: 0.041198
2022-01-14 15:06:44,402 iteration 537 : loss : 0.074230, loss_ce: 0.028651
2022-01-14 15:06:45,893 iteration 538 : loss : 0.093674, loss_ce: 0.048723
2022-01-14 15:06:47,299 iteration 539 : loss : 0.080668, loss_ce: 0.029720
2022-01-14 15:06:48,905 iteration 540 : loss : 0.095192, loss_ce: 0.046472
2022-01-14 15:06:50,486 iteration 541 : loss : 0.138969, loss_ce: 0.068826
2022-01-14 15:06:51,914 iteration 542 : loss : 0.117036, loss_ce: 0.054221
2022-01-14 15:06:53,398 iteration 543 : loss : 0.087547, loss_ce: 0.038468
2022-01-14 15:06:54,858 iteration 544 : loss : 0.186534, loss_ce: 0.063718
  8%|██▍                           | 32/400 [14:48<2:46:45, 27.19s/it]2022-01-14 15:06:56,451 iteration 545 : loss : 0.091613, loss_ce: 0.046255
2022-01-14 15:06:58,002 iteration 546 : loss : 0.073610, loss_ce: 0.032125
2022-01-14 15:06:59,538 iteration 547 : loss : 0.063060, loss_ce: 0.024553
2022-01-14 15:07:00,960 iteration 548 : loss : 0.121851, loss_ce: 0.042411
2022-01-14 15:07:02,384 iteration 549 : loss : 0.088989, loss_ce: 0.033228
2022-01-14 15:07:03,817 iteration 550 : loss : 0.081458, loss_ce: 0.029383
2022-01-14 15:07:05,246 iteration 551 : loss : 0.094068, loss_ce: 0.028711
2022-01-14 15:07:06,765 iteration 552 : loss : 0.141521, loss_ce: 0.058472
2022-01-14 15:07:08,265 iteration 553 : loss : 0.074294, loss_ce: 0.027657
2022-01-14 15:07:09,757 iteration 554 : loss : 0.128431, loss_ce: 0.045427
2022-01-14 15:07:11,273 iteration 555 : loss : 0.067543, loss_ce: 0.021731
2022-01-14 15:07:12,823 iteration 556 : loss : 0.089033, loss_ce: 0.041714
2022-01-14 15:07:14,264 iteration 557 : loss : 0.084087, loss_ce: 0.041466
2022-01-14 15:07:15,683 iteration 558 : loss : 0.087542, loss_ce: 0.034152
2022-01-14 15:07:17,138 iteration 559 : loss : 0.099787, loss_ce: 0.037964
2022-01-14 15:07:18,678 iteration 560 : loss : 0.095655, loss_ce: 0.043451
2022-01-14 15:07:20,199 iteration 561 : loss : 0.060823, loss_ce: 0.027220
  8%|██▍                           | 33/400 [15:13<2:42:54, 26.63s/it]2022-01-14 15:07:21,765 iteration 562 : loss : 0.136554, loss_ce: 0.048508
2022-01-14 15:07:23,196 iteration 563 : loss : 0.056878, loss_ce: 0.029006
2022-01-14 15:07:24,628 iteration 564 : loss : 0.088395, loss_ce: 0.042881
2022-01-14 15:07:26,134 iteration 565 : loss : 0.074430, loss_ce: 0.032163
2022-01-14 15:07:27,661 iteration 566 : loss : 0.096879, loss_ce: 0.030868
2022-01-14 15:07:29,172 iteration 567 : loss : 0.082656, loss_ce: 0.033500
2022-01-14 15:07:30,681 iteration 568 : loss : 0.096908, loss_ce: 0.025866
2022-01-14 15:07:32,246 iteration 569 : loss : 0.167988, loss_ce: 0.065384
2022-01-14 15:07:33,744 iteration 570 : loss : 0.078632, loss_ce: 0.033590
2022-01-14 15:07:35,270 iteration 571 : loss : 0.090138, loss_ce: 0.035953
2022-01-14 15:07:36,813 iteration 572 : loss : 0.095531, loss_ce: 0.033779
2022-01-14 15:07:38,261 iteration 573 : loss : 0.078275, loss_ce: 0.032020
2022-01-14 15:07:39,823 iteration 574 : loss : 0.086184, loss_ce: 0.035952
2022-01-14 15:07:41,297 iteration 575 : loss : 0.111955, loss_ce: 0.030267
2022-01-14 15:07:42,715 iteration 576 : loss : 0.076886, loss_ce: 0.040064
2022-01-14 15:07:44,310 iteration 577 : loss : 0.087316, loss_ce: 0.038179
2022-01-14 15:07:45,832 iteration 578 : loss : 0.065041, loss_ce: 0.030708
  8%|██▌                           | 34/400 [15:39<2:40:37, 26.33s/it]2022-01-14 15:07:47,288 iteration 579 : loss : 0.063097, loss_ce: 0.029315
2022-01-14 15:07:48,815 iteration 580 : loss : 0.075444, loss_ce: 0.029206
2022-01-14 15:07:50,430 iteration 581 : loss : 0.051286, loss_ce: 0.020623
2022-01-14 15:07:51,860 iteration 582 : loss : 0.063218, loss_ce: 0.027343
2022-01-14 15:07:53,356 iteration 583 : loss : 0.077761, loss_ce: 0.035625
2022-01-14 15:07:54,878 iteration 584 : loss : 0.094316, loss_ce: 0.036145
2022-01-14 15:07:56,331 iteration 585 : loss : 0.093589, loss_ce: 0.031568
2022-01-14 15:07:57,848 iteration 586 : loss : 0.107758, loss_ce: 0.039412
2022-01-14 15:07:59,347 iteration 587 : loss : 0.060586, loss_ce: 0.027091
2022-01-14 15:08:00,787 iteration 588 : loss : 0.076286, loss_ce: 0.026686
2022-01-14 15:08:02,328 iteration 589 : loss : 0.094573, loss_ce: 0.039014
2022-01-14 15:08:03,794 iteration 590 : loss : 0.075388, loss_ce: 0.028417
2022-01-14 15:08:05,261 iteration 591 : loss : 0.094673, loss_ce: 0.033391
2022-01-14 15:08:06,775 iteration 592 : loss : 0.079777, loss_ce: 0.035637
2022-01-14 15:08:08,199 iteration 593 : loss : 0.117658, loss_ce: 0.046202
2022-01-14 15:08:09,723 iteration 594 : loss : 0.083358, loss_ce: 0.028287
2022-01-14 15:08:09,723 Training Data Eval:
2022-01-14 15:08:17,091   Average segmentation loss on training set: 0.0667
2022-01-14 15:08:17,091 Validation Data Eval:
2022-01-14 15:08:19,633   Average segmentation loss on validation set: 0.1044
2022-01-14 15:08:21,126 iteration 595 : loss : 0.091572, loss_ce: 0.033044
  9%|██▋                           | 35/400 [16:14<2:56:32, 29.02s/it]2022-01-14 15:08:22,726 iteration 596 : loss : 0.083485, loss_ce: 0.034131
2022-01-14 15:08:24,207 iteration 597 : loss : 0.060265, loss_ce: 0.023648
2022-01-14 15:08:25,686 iteration 598 : loss : 0.073655, loss_ce: 0.023763
2022-01-14 15:08:27,220 iteration 599 : loss : 0.110327, loss_ce: 0.040749
2022-01-14 15:08:28,748 iteration 600 : loss : 0.069325, loss_ce: 0.024693
2022-01-14 15:08:30,272 iteration 601 : loss : 0.062966, loss_ce: 0.024273
2022-01-14 15:08:31,675 iteration 602 : loss : 0.094003, loss_ce: 0.047455
2022-01-14 15:08:33,150 iteration 603 : loss : 0.071553, loss_ce: 0.028169
2022-01-14 15:08:34,586 iteration 604 : loss : 0.127461, loss_ce: 0.044323
2022-01-14 15:08:36,166 iteration 605 : loss : 0.070693, loss_ce: 0.029065
2022-01-14 15:08:37,606 iteration 606 : loss : 0.068275, loss_ce: 0.026899
2022-01-14 15:08:39,044 iteration 607 : loss : 0.068474, loss_ce: 0.024430
2022-01-14 15:08:40,491 iteration 608 : loss : 0.051145, loss_ce: 0.026750
2022-01-14 15:08:41,921 iteration 609 : loss : 0.084916, loss_ce: 0.032436
2022-01-14 15:08:43,490 iteration 610 : loss : 0.124161, loss_ce: 0.061105
2022-01-14 15:08:44,958 iteration 611 : loss : 0.073747, loss_ce: 0.033188
2022-01-14 15:08:46,373 iteration 612 : loss : 0.061315, loss_ce: 0.026413
  9%|██▋                           | 36/400 [16:39<2:49:11, 27.89s/it]2022-01-14 15:08:47,887 iteration 613 : loss : 0.096013, loss_ce: 0.039232
2022-01-14 15:08:49,422 iteration 614 : loss : 0.075254, loss_ce: 0.032802
2022-01-14 15:08:50,908 iteration 615 : loss : 0.072851, loss_ce: 0.034544
2022-01-14 15:08:52,361 iteration 616 : loss : 0.109078, loss_ce: 0.038119
2022-01-14 15:08:53,918 iteration 617 : loss : 0.135933, loss_ce: 0.045642
2022-01-14 15:08:55,515 iteration 618 : loss : 0.058400, loss_ce: 0.027863
2022-01-14 15:08:57,055 iteration 619 : loss : 0.061209, loss_ce: 0.023981
2022-01-14 15:08:58,628 iteration 620 : loss : 0.066466, loss_ce: 0.032353
2022-01-14 15:09:00,030 iteration 621 : loss : 0.062505, loss_ce: 0.021787
2022-01-14 15:09:01,571 iteration 622 : loss : 0.079052, loss_ce: 0.030341
2022-01-14 15:09:03,120 iteration 623 : loss : 0.125818, loss_ce: 0.056185
2022-01-14 15:09:04,531 iteration 624 : loss : 0.097363, loss_ce: 0.039119
2022-01-14 15:09:06,133 iteration 625 : loss : 0.091158, loss_ce: 0.038668
2022-01-14 15:09:07,604 iteration 626 : loss : 0.069561, loss_ce: 0.027765
2022-01-14 15:09:09,024 iteration 627 : loss : 0.130453, loss_ce: 0.044454
2022-01-14 15:09:10,416 iteration 628 : loss : 0.095042, loss_ce: 0.032421
2022-01-14 15:09:11,915 iteration 629 : loss : 0.057267, loss_ce: 0.024737
  9%|██▊                           | 37/400 [17:05<2:44:28, 27.19s/it]2022-01-14 15:09:13,342 iteration 630 : loss : 0.091396, loss_ce: 0.036488
2022-01-14 15:09:14,813 iteration 631 : loss : 0.102430, loss_ce: 0.038380
2022-01-14 15:09:16,224 iteration 632 : loss : 0.057051, loss_ce: 0.021376
2022-01-14 15:09:17,735 iteration 633 : loss : 0.088695, loss_ce: 0.041518
2022-01-14 15:09:19,229 iteration 634 : loss : 0.060806, loss_ce: 0.027531
2022-01-14 15:09:20,742 iteration 635 : loss : 0.077474, loss_ce: 0.031573
2022-01-14 15:09:22,197 iteration 636 : loss : 0.135060, loss_ce: 0.039134
2022-01-14 15:09:23,638 iteration 637 : loss : 0.079706, loss_ce: 0.037807
2022-01-14 15:09:25,079 iteration 638 : loss : 0.058129, loss_ce: 0.027536
2022-01-14 15:09:26,593 iteration 639 : loss : 0.064326, loss_ce: 0.028870
2022-01-14 15:09:28,116 iteration 640 : loss : 0.068077, loss_ce: 0.023843
2022-01-14 15:09:29,545 iteration 641 : loss : 0.056851, loss_ce: 0.023777
2022-01-14 15:09:31,027 iteration 642 : loss : 0.054031, loss_ce: 0.020690
2022-01-14 15:09:32,484 iteration 643 : loss : 0.084743, loss_ce: 0.029855
2022-01-14 15:09:33,956 iteration 644 : loss : 0.081039, loss_ce: 0.031356
2022-01-14 15:09:35,399 iteration 645 : loss : 0.113289, loss_ce: 0.037182
2022-01-14 15:09:36,913 iteration 646 : loss : 0.061311, loss_ce: 0.026282
 10%|██▊                           | 38/400 [17:30<2:40:04, 26.53s/it]2022-01-14 15:09:38,408 iteration 647 : loss : 0.082233, loss_ce: 0.030335
2022-01-14 15:09:39,935 iteration 648 : loss : 0.078566, loss_ce: 0.033174
2022-01-14 15:09:41,430 iteration 649 : loss : 0.083759, loss_ce: 0.035987
2022-01-14 15:09:42,839 iteration 650 : loss : 0.060615, loss_ce: 0.030297
2022-01-14 15:09:44,316 iteration 651 : loss : 0.077343, loss_ce: 0.031703
2022-01-14 15:09:45,732 iteration 652 : loss : 0.090039, loss_ce: 0.026656
2022-01-14 15:09:47,220 iteration 653 : loss : 0.110567, loss_ce: 0.035019
2022-01-14 15:09:48,757 iteration 654 : loss : 0.082488, loss_ce: 0.027730
2022-01-14 15:09:50,267 iteration 655 : loss : 0.061222, loss_ce: 0.027355
2022-01-14 15:09:51,683 iteration 656 : loss : 0.058862, loss_ce: 0.022265
2022-01-14 15:09:53,163 iteration 657 : loss : 0.060105, loss_ce: 0.024148
2022-01-14 15:09:54,691 iteration 658 : loss : 0.114528, loss_ce: 0.036791
2022-01-14 15:09:56,226 iteration 659 : loss : 0.071916, loss_ce: 0.031922
2022-01-14 15:09:57,724 iteration 660 : loss : 0.079321, loss_ce: 0.029277
2022-01-14 15:09:59,209 iteration 661 : loss : 0.085797, loss_ce: 0.044415
2022-01-14 15:10:00,654 iteration 662 : loss : 0.061424, loss_ce: 0.028465
2022-01-14 15:10:02,131 iteration 663 : loss : 0.090952, loss_ce: 0.029337
 10%|██▉                           | 39/400 [17:55<2:37:15, 26.14s/it]2022-01-14 15:10:03,615 iteration 664 : loss : 0.097724, loss_ce: 0.051462
2022-01-14 15:10:05,078 iteration 665 : loss : 0.069379, loss_ce: 0.032178
2022-01-14 15:10:06,574 iteration 666 : loss : 0.068428, loss_ce: 0.027609
2022-01-14 15:10:08,009 iteration 667 : loss : 0.050422, loss_ce: 0.021497
2022-01-14 15:10:09,542 iteration 668 : loss : 0.063409, loss_ce: 0.025949
2022-01-14 15:10:10,983 iteration 669 : loss : 0.065025, loss_ce: 0.027753
2022-01-14 15:10:12,428 iteration 670 : loss : 0.056067, loss_ce: 0.024342
2022-01-14 15:10:13,965 iteration 671 : loss : 0.062164, loss_ce: 0.018865
2022-01-14 15:10:15,516 iteration 672 : loss : 0.060414, loss_ce: 0.022251
2022-01-14 15:10:16,948 iteration 673 : loss : 0.064292, loss_ce: 0.028281
2022-01-14 15:10:18,451 iteration 674 : loss : 0.104050, loss_ce: 0.045615
2022-01-14 15:10:19,971 iteration 675 : loss : 0.072351, loss_ce: 0.026696
2022-01-14 15:10:21,428 iteration 676 : loss : 0.087553, loss_ce: 0.033178
2022-01-14 15:10:22,917 iteration 677 : loss : 0.088048, loss_ce: 0.039680
2022-01-14 15:10:24,387 iteration 678 : loss : 0.058496, loss_ce: 0.021625
2022-01-14 15:10:25,816 iteration 679 : loss : 0.093418, loss_ce: 0.051028
2022-01-14 15:10:25,816 Training Data Eval:
2022-01-14 15:10:33,187   Average segmentation loss on training set: 0.0783
2022-01-14 15:10:33,187 Validation Data Eval:
2022-01-14 15:10:35,732   Average segmentation loss on validation set: 0.1974
2022-01-14 15:10:37,229 iteration 680 : loss : 0.166479, loss_ce: 0.046359
 10%|███                           | 40/400 [18:30<2:52:56, 28.82s/it]2022-01-14 15:10:38,808 iteration 681 : loss : 0.068259, loss_ce: 0.028299
2022-01-14 15:10:40,248 iteration 682 : loss : 0.047380, loss_ce: 0.017939
2022-01-14 15:10:41,748 iteration 683 : loss : 0.070472, loss_ce: 0.029058
2022-01-14 15:10:43,258 iteration 684 : loss : 0.059593, loss_ce: 0.023703
2022-01-14 15:10:44,793 iteration 685 : loss : 0.069756, loss_ce: 0.026518
2022-01-14 15:10:46,183 iteration 686 : loss : 0.069795, loss_ce: 0.022373
2022-01-14 15:10:47,620 iteration 687 : loss : 0.055868, loss_ce: 0.020318
2022-01-14 15:10:49,166 iteration 688 : loss : 0.095393, loss_ce: 0.036935
2022-01-14 15:10:50,657 iteration 689 : loss : 0.056140, loss_ce: 0.023549
2022-01-14 15:10:52,084 iteration 690 : loss : 0.082405, loss_ce: 0.042675
2022-01-14 15:10:53,645 iteration 691 : loss : 0.078113, loss_ce: 0.033846
2022-01-14 15:10:55,187 iteration 692 : loss : 0.090052, loss_ce: 0.031575
2022-01-14 15:10:56,713 iteration 693 : loss : 0.082722, loss_ce: 0.036840
2022-01-14 15:10:58,200 iteration 694 : loss : 0.077174, loss_ce: 0.032718
2022-01-14 15:10:59,680 iteration 695 : loss : 0.080618, loss_ce: 0.025684
2022-01-14 15:11:01,148 iteration 696 : loss : 0.067947, loss_ce: 0.030274
2022-01-14 15:11:02,636 iteration 697 : loss : 0.064579, loss_ce: 0.026198
 10%|███                           | 41/400 [18:55<2:46:19, 27.80s/it]2022-01-14 15:11:04,133 iteration 698 : loss : 0.059708, loss_ce: 0.023920
2022-01-14 15:11:05,611 iteration 699 : loss : 0.057367, loss_ce: 0.017603
2022-01-14 15:11:07,095 iteration 700 : loss : 0.089393, loss_ce: 0.039148
2022-01-14 15:11:08,561 iteration 701 : loss : 0.084280, loss_ce: 0.032628
2022-01-14 15:11:10,081 iteration 702 : loss : 0.056185, loss_ce: 0.017923
2022-01-14 15:11:11,555 iteration 703 : loss : 0.084066, loss_ce: 0.033984
2022-01-14 15:11:13,021 iteration 704 : loss : 0.123014, loss_ce: 0.040978
2022-01-14 15:11:14,458 iteration 705 : loss : 0.086603, loss_ce: 0.039290
2022-01-14 15:11:15,982 iteration 706 : loss : 0.074536, loss_ce: 0.030938
2022-01-14 15:11:17,486 iteration 707 : loss : 0.073512, loss_ce: 0.035838
2022-01-14 15:11:18,979 iteration 708 : loss : 0.092838, loss_ce: 0.040295
2022-01-14 15:11:20,488 iteration 709 : loss : 0.055954, loss_ce: 0.023536
2022-01-14 15:11:21,980 iteration 710 : loss : 0.107079, loss_ce: 0.038553
2022-01-14 15:11:23,542 iteration 711 : loss : 0.113419, loss_ce: 0.030427
2022-01-14 15:11:25,111 iteration 712 : loss : 0.057155, loss_ce: 0.027783
2022-01-14 15:11:26,552 iteration 713 : loss : 0.063711, loss_ce: 0.027514
2022-01-14 15:11:28,027 iteration 714 : loss : 0.039364, loss_ce: 0.017105
 10%|███▏                          | 42/400 [19:21<2:41:34, 27.08s/it]2022-01-14 15:11:29,546 iteration 715 : loss : 0.057478, loss_ce: 0.025976
2022-01-14 15:11:31,015 iteration 716 : loss : 0.112118, loss_ce: 0.031983
2022-01-14 15:11:32,481 iteration 717 : loss : 0.059660, loss_ce: 0.023006
2022-01-14 15:11:33,865 iteration 718 : loss : 0.057353, loss_ce: 0.021659
2022-01-14 15:11:35,336 iteration 719 : loss : 0.063593, loss_ce: 0.032831
2022-01-14 15:11:36,733 iteration 720 : loss : 0.066499, loss_ce: 0.027439
2022-01-14 15:11:38,333 iteration 721 : loss : 0.133824, loss_ce: 0.056003
2022-01-14 15:11:39,817 iteration 722 : loss : 0.047645, loss_ce: 0.021406
2022-01-14 15:11:41,312 iteration 723 : loss : 0.083641, loss_ce: 0.033382
2022-01-14 15:11:42,865 iteration 724 : loss : 0.076789, loss_ce: 0.030113
2022-01-14 15:11:44,304 iteration 725 : loss : 0.053087, loss_ce: 0.024081
2022-01-14 15:11:45,798 iteration 726 : loss : 0.073451, loss_ce: 0.037173
2022-01-14 15:11:47,245 iteration 727 : loss : 0.054099, loss_ce: 0.021689
2022-01-14 15:11:48,701 iteration 728 : loss : 0.073873, loss_ce: 0.021773
2022-01-14 15:11:50,156 iteration 729 : loss : 0.097768, loss_ce: 0.041159
2022-01-14 15:11:51,650 iteration 730 : loss : 0.072400, loss_ce: 0.028209
2022-01-14 15:11:53,093 iteration 731 : loss : 0.090060, loss_ce: 0.031750
 11%|███▏                          | 43/400 [19:46<2:37:30, 26.47s/it]2022-01-14 15:11:54,650 iteration 732 : loss : 0.095408, loss_ce: 0.042071
2022-01-14 15:11:56,153 iteration 733 : loss : 0.048456, loss_ce: 0.020892
2022-01-14 15:11:57,652 iteration 734 : loss : 0.087215, loss_ce: 0.036689
2022-01-14 15:11:59,163 iteration 735 : loss : 0.086551, loss_ce: 0.028671
2022-01-14 15:12:00,669 iteration 736 : loss : 0.055505, loss_ce: 0.021902
2022-01-14 15:12:02,092 iteration 737 : loss : 0.049797, loss_ce: 0.019976
2022-01-14 15:12:03,632 iteration 738 : loss : 0.074672, loss_ce: 0.031490
2022-01-14 15:12:05,138 iteration 739 : loss : 0.068477, loss_ce: 0.031210
2022-01-14 15:12:06,615 iteration 740 : loss : 0.062347, loss_ce: 0.021225
2022-01-14 15:12:08,151 iteration 741 : loss : 0.057735, loss_ce: 0.022668
2022-01-14 15:12:09,673 iteration 742 : loss : 0.060760, loss_ce: 0.022321
2022-01-14 15:12:11,137 iteration 743 : loss : 0.061876, loss_ce: 0.022242
2022-01-14 15:12:12,630 iteration 744 : loss : 0.057573, loss_ce: 0.025819
2022-01-14 15:12:14,109 iteration 745 : loss : 0.072064, loss_ce: 0.025381
2022-01-14 15:12:15,565 iteration 746 : loss : 0.126222, loss_ce: 0.044806
2022-01-14 15:12:17,025 iteration 747 : loss : 0.068952, loss_ce: 0.029488
2022-01-14 15:12:18,524 iteration 748 : loss : 0.082231, loss_ce: 0.031503
 11%|███▎                          | 44/400 [20:11<2:35:12, 26.16s/it]2022-01-14 15:12:20,014 iteration 749 : loss : 0.093833, loss_ce: 0.027701
2022-01-14 15:12:21,471 iteration 750 : loss : 0.059567, loss_ce: 0.020877
2022-01-14 15:12:22,985 iteration 751 : loss : 0.074013, loss_ce: 0.025788
2022-01-14 15:12:24,435 iteration 752 : loss : 0.057454, loss_ce: 0.023472
2022-01-14 15:12:25,949 iteration 753 : loss : 0.060886, loss_ce: 0.026420
2022-01-14 15:12:27,424 iteration 754 : loss : 0.040395, loss_ce: 0.013290
2022-01-14 15:12:28,916 iteration 755 : loss : 0.056837, loss_ce: 0.021554
2022-01-14 15:12:30,308 iteration 756 : loss : 0.072258, loss_ce: 0.030076
2022-01-14 15:12:31,722 iteration 757 : loss : 0.063181, loss_ce: 0.025431
2022-01-14 15:12:33,206 iteration 758 : loss : 0.077926, loss_ce: 0.035645
2022-01-14 15:12:34,724 iteration 759 : loss : 0.083920, loss_ce: 0.027351
2022-01-14 15:12:36,218 iteration 760 : loss : 0.060725, loss_ce: 0.020412
2022-01-14 15:12:37,732 iteration 761 : loss : 0.074157, loss_ce: 0.030194
2022-01-14 15:12:39,130 iteration 762 : loss : 0.044203, loss_ce: 0.019114
2022-01-14 15:12:40,604 iteration 763 : loss : 0.057968, loss_ce: 0.025977
2022-01-14 15:12:42,002 iteration 764 : loss : 0.062426, loss_ce: 0.021998
2022-01-14 15:12:42,002 Training Data Eval:
2022-01-14 15:12:49,371   Average segmentation loss on training set: 0.1919
2022-01-14 15:12:49,371 Validation Data Eval:
2022-01-14 15:12:51,916   Average segmentation loss on validation set: 0.1808
2022-01-14 15:12:53,304 iteration 765 : loss : 0.061578, loss_ce: 0.027297
 11%|███▍                          | 45/400 [20:46<2:50:04, 28.74s/it]2022-01-14 15:12:54,895 iteration 766 : loss : 0.077787, loss_ce: 0.030666
2022-01-14 15:12:56,510 iteration 767 : loss : 0.092489, loss_ce: 0.042172
2022-01-14 15:12:58,018 iteration 768 : loss : 0.085309, loss_ce: 0.035111
2022-01-14 15:12:59,568 iteration 769 : loss : 0.091754, loss_ce: 0.041548
2022-01-14 15:13:01,123 iteration 770 : loss : 0.071457, loss_ce: 0.035123
2022-01-14 15:13:02,627 iteration 771 : loss : 0.047720, loss_ce: 0.024085
2022-01-14 15:13:04,046 iteration 772 : loss : 0.054163, loss_ce: 0.022729
2022-01-14 15:13:05,516 iteration 773 : loss : 0.113453, loss_ce: 0.043923
2022-01-14 15:13:07,064 iteration 774 : loss : 0.056980, loss_ce: 0.024055
2022-01-14 15:13:08,477 iteration 775 : loss : 0.058961, loss_ce: 0.023554
2022-01-14 15:13:09,930 iteration 776 : loss : 0.121341, loss_ce: 0.036825
2022-01-14 15:13:11,515 iteration 777 : loss : 0.055742, loss_ce: 0.024149
2022-01-14 15:13:13,005 iteration 778 : loss : 0.056616, loss_ce: 0.016484
2022-01-14 15:13:14,478 iteration 779 : loss : 0.074901, loss_ce: 0.026487
2022-01-14 15:13:16,058 iteration 780 : loss : 0.101795, loss_ce: 0.039061
2022-01-14 15:13:17,593 iteration 781 : loss : 0.044824, loss_ce: 0.016256
2022-01-14 15:13:19,051 iteration 782 : loss : 0.071000, loss_ce: 0.028227
 12%|███▍                          | 46/400 [21:12<2:44:17, 27.85s/it]2022-01-14 15:13:20,564 iteration 783 : loss : 0.066344, loss_ce: 0.024876
2022-01-14 15:13:21,993 iteration 784 : loss : 0.046070, loss_ce: 0.015819
2022-01-14 15:13:23,532 iteration 785 : loss : 0.082530, loss_ce: 0.024196
2022-01-14 15:13:24,991 iteration 786 : loss : 0.063702, loss_ce: 0.023482
2022-01-14 15:13:26,513 iteration 787 : loss : 0.082504, loss_ce: 0.033400
2022-01-14 15:13:27,951 iteration 788 : loss : 0.066442, loss_ce: 0.028763
2022-01-14 15:13:29,470 iteration 789 : loss : 0.075386, loss_ce: 0.027787
2022-01-14 15:13:31,008 iteration 790 : loss : 0.058612, loss_ce: 0.024467
2022-01-14 15:13:32,426 iteration 791 : loss : 0.089237, loss_ce: 0.049181
2022-01-14 15:13:34,006 iteration 792 : loss : 0.071322, loss_ce: 0.026418
2022-01-14 15:13:35,556 iteration 793 : loss : 0.072192, loss_ce: 0.028499
2022-01-14 15:13:37,138 iteration 794 : loss : 0.062014, loss_ce: 0.022903
2022-01-14 15:13:38,687 iteration 795 : loss : 0.058329, loss_ce: 0.022356
2022-01-14 15:13:40,289 iteration 796 : loss : 0.070462, loss_ce: 0.027319
2022-01-14 15:13:41,769 iteration 797 : loss : 0.066904, loss_ce: 0.029202
2022-01-14 15:13:43,241 iteration 798 : loss : 0.054953, loss_ce: 0.023423
2022-01-14 15:13:44,832 iteration 799 : loss : 0.092713, loss_ce: 0.030327
 12%|███▌                          | 47/400 [21:38<2:40:11, 27.23s/it]2022-01-14 15:13:46,387 iteration 800 : loss : 0.079954, loss_ce: 0.037394
2022-01-14 15:13:47,851 iteration 801 : loss : 0.088256, loss_ce: 0.025272
2022-01-14 15:13:49,368 iteration 802 : loss : 0.090885, loss_ce: 0.044770
2022-01-14 15:13:50,777 iteration 803 : loss : 0.051258, loss_ce: 0.020551
2022-01-14 15:13:52,342 iteration 804 : loss : 0.085559, loss_ce: 0.029622
2022-01-14 15:13:53,802 iteration 805 : loss : 0.063754, loss_ce: 0.027214
2022-01-14 15:13:55,210 iteration 806 : loss : 0.059547, loss_ce: 0.020919
2022-01-14 15:13:56,686 iteration 807 : loss : 0.051807, loss_ce: 0.027628
2022-01-14 15:13:58,165 iteration 808 : loss : 0.070041, loss_ce: 0.020656
2022-01-14 15:13:59,697 iteration 809 : loss : 0.067474, loss_ce: 0.027617
2022-01-14 15:14:01,131 iteration 810 : loss : 0.050712, loss_ce: 0.016049
2022-01-14 15:14:02,640 iteration 811 : loss : 0.066059, loss_ce: 0.025709
2022-01-14 15:14:04,073 iteration 812 : loss : 0.075941, loss_ce: 0.031746
2022-01-14 15:14:05,613 iteration 813 : loss : 0.059382, loss_ce: 0.027764
2022-01-14 15:14:07,189 iteration 814 : loss : 0.179821, loss_ce: 0.053840
2022-01-14 15:14:08,543 iteration 815 : loss : 0.046903, loss_ce: 0.021839
2022-01-14 15:14:10,088 iteration 816 : loss : 0.080198, loss_ce: 0.032913
 12%|███▌                          | 48/400 [22:03<2:36:16, 26.64s/it]2022-01-14 15:14:11,580 iteration 817 : loss : 0.061392, loss_ce: 0.024973
2022-01-14 15:14:13,037 iteration 818 : loss : 0.059670, loss_ce: 0.025400
2022-01-14 15:14:14,642 iteration 819 : loss : 0.065616, loss_ce: 0.028140
2022-01-14 15:14:16,183 iteration 820 : loss : 0.083453, loss_ce: 0.034935
2022-01-14 15:14:17,700 iteration 821 : loss : 0.055409, loss_ce: 0.022095
2022-01-14 15:14:19,183 iteration 822 : loss : 0.059722, loss_ce: 0.025509
2022-01-14 15:14:20,693 iteration 823 : loss : 0.068297, loss_ce: 0.027554
2022-01-14 15:14:22,114 iteration 824 : loss : 0.056758, loss_ce: 0.019469
2022-01-14 15:14:23,582 iteration 825 : loss : 0.129469, loss_ce: 0.035896
2022-01-14 15:14:24,994 iteration 826 : loss : 0.066132, loss_ce: 0.030590
2022-01-14 15:14:26,467 iteration 827 : loss : 0.079322, loss_ce: 0.026366
2022-01-14 15:14:27,865 iteration 828 : loss : 0.057234, loss_ce: 0.020391
2022-01-14 15:14:29,409 iteration 829 : loss : 0.086890, loss_ce: 0.044503
2022-01-14 15:14:30,867 iteration 830 : loss : 0.088329, loss_ce: 0.043701
2022-01-14 15:14:32,374 iteration 831 : loss : 0.078283, loss_ce: 0.035443
2022-01-14 15:14:33,861 iteration 832 : loss : 0.066730, loss_ce: 0.019971
2022-01-14 15:14:35,349 iteration 833 : loss : 0.093231, loss_ce: 0.041044
 12%|███▋                          | 49/400 [22:28<2:33:24, 26.22s/it]2022-01-14 15:14:36,792 iteration 834 : loss : 0.068800, loss_ce: 0.023083
2022-01-14 15:14:38,179 iteration 835 : loss : 0.044329, loss_ce: 0.015951
2022-01-14 15:14:39,714 iteration 836 : loss : 0.060885, loss_ce: 0.020779
2022-01-14 15:14:41,157 iteration 837 : loss : 0.043534, loss_ce: 0.016450
2022-01-14 15:14:42,663 iteration 838 : loss : 0.066388, loss_ce: 0.030847
2022-01-14 15:14:44,058 iteration 839 : loss : 0.052718, loss_ce: 0.020352
2022-01-14 15:14:45,462 iteration 840 : loss : 0.035481, loss_ce: 0.016773
2022-01-14 15:14:46,888 iteration 841 : loss : 0.068509, loss_ce: 0.027632
2022-01-14 15:14:48,437 iteration 842 : loss : 0.084911, loss_ce: 0.031573
2022-01-14 15:14:49,876 iteration 843 : loss : 0.053098, loss_ce: 0.017868
2022-01-14 15:14:51,394 iteration 844 : loss : 0.059827, loss_ce: 0.022072
2022-01-14 15:14:52,853 iteration 845 : loss : 0.064262, loss_ce: 0.031646
2022-01-14 15:14:54,308 iteration 846 : loss : 0.045274, loss_ce: 0.021363
2022-01-14 15:14:55,878 iteration 847 : loss : 0.064744, loss_ce: 0.026524
2022-01-14 15:14:57,347 iteration 848 : loss : 0.048308, loss_ce: 0.018559
2022-01-14 15:14:58,797 iteration 849 : loss : 0.061176, loss_ce: 0.020141
2022-01-14 15:14:58,797 Training Data Eval:
2022-01-14 15:15:06,166   Average segmentation loss on training set: 0.1381
2022-01-14 15:15:06,166 Validation Data Eval:
2022-01-14 15:15:08,708   Average segmentation loss on validation set: 0.3047
2022-01-14 15:15:10,129 iteration 850 : loss : 0.081411, loss_ce: 0.039456
 12%|███▊                          | 50/400 [23:03<2:47:56, 28.79s/it]2022-01-14 15:15:11,651 iteration 851 : loss : 0.058108, loss_ce: 0.021842
2022-01-14 15:15:13,119 iteration 852 : loss : 0.077443, loss_ce: 0.026187
2022-01-14 15:15:14,602 iteration 853 : loss : 0.067961, loss_ce: 0.021337
2022-01-14 15:15:16,098 iteration 854 : loss : 0.050645, loss_ce: 0.024455
2022-01-14 15:15:17,542 iteration 855 : loss : 0.054476, loss_ce: 0.025187
2022-01-14 15:15:19,054 iteration 856 : loss : 0.074450, loss_ce: 0.032008
2022-01-14 15:15:20,509 iteration 857 : loss : 0.073166, loss_ce: 0.026782
2022-01-14 15:15:22,068 iteration 858 : loss : 0.039131, loss_ce: 0.015511
2022-01-14 15:15:23,419 iteration 859 : loss : 0.055547, loss_ce: 0.017927
2022-01-14 15:15:24,877 iteration 860 : loss : 0.044648, loss_ce: 0.016293
2022-01-14 15:15:26,345 iteration 861 : loss : 0.083898, loss_ce: 0.022855
2022-01-14 15:15:27,832 iteration 862 : loss : 0.056032, loss_ce: 0.025811
2022-01-14 15:15:29,304 iteration 863 : loss : 0.089007, loss_ce: 0.029121
2022-01-14 15:15:30,760 iteration 864 : loss : 0.051102, loss_ce: 0.022145
2022-01-14 15:15:32,244 iteration 865 : loss : 0.055609, loss_ce: 0.021367
2022-01-14 15:15:33,681 iteration 866 : loss : 0.052679, loss_ce: 0.023116
2022-01-14 15:15:35,187 iteration 867 : loss : 0.057322, loss_ce: 0.020851
 13%|███▊                          | 51/400 [23:28<2:40:56, 27.67s/it]2022-01-14 15:15:36,690 iteration 868 : loss : 0.057559, loss_ce: 0.024483
2022-01-14 15:15:38,201 iteration 869 : loss : 0.058062, loss_ce: 0.024607
2022-01-14 15:15:39,590 iteration 870 : loss : 0.056357, loss_ce: 0.025583
2022-01-14 15:15:41,041 iteration 871 : loss : 0.056349, loss_ce: 0.022445
2022-01-14 15:15:42,492 iteration 872 : loss : 0.069493, loss_ce: 0.030080
2022-01-14 15:15:43,982 iteration 873 : loss : 0.054189, loss_ce: 0.024035
2022-01-14 15:15:45,461 iteration 874 : loss : 0.062421, loss_ce: 0.024550
2022-01-14 15:15:46,942 iteration 875 : loss : 0.071245, loss_ce: 0.027001
2022-01-14 15:15:48,421 iteration 876 : loss : 0.052344, loss_ce: 0.017510
2022-01-14 15:15:49,962 iteration 877 : loss : 0.043603, loss_ce: 0.017082
2022-01-14 15:15:51,405 iteration 878 : loss : 0.102554, loss_ce: 0.025412
2022-01-14 15:15:52,868 iteration 879 : loss : 0.100790, loss_ce: 0.026800
2022-01-14 15:15:54,297 iteration 880 : loss : 0.047322, loss_ce: 0.020353
2022-01-14 15:15:55,833 iteration 881 : loss : 0.056240, loss_ce: 0.017302
2022-01-14 15:15:57,334 iteration 882 : loss : 0.066591, loss_ce: 0.021636
2022-01-14 15:15:58,773 iteration 883 : loss : 0.043093, loss_ce: 0.014216
2022-01-14 15:16:00,285 iteration 884 : loss : 0.079116, loss_ce: 0.033620
 13%|███▉                          | 52/400 [23:53<2:36:00, 26.90s/it]2022-01-14 15:16:01,814 iteration 885 : loss : 0.050282, loss_ce: 0.021726
2022-01-14 15:16:03,291 iteration 886 : loss : 0.062217, loss_ce: 0.030121
2022-01-14 15:16:04,794 iteration 887 : loss : 0.051090, loss_ce: 0.019807
2022-01-14 15:16:06,289 iteration 888 : loss : 0.060313, loss_ce: 0.024513
2022-01-14 15:16:07,779 iteration 889 : loss : 0.119152, loss_ce: 0.028473
2022-01-14 15:16:09,232 iteration 890 : loss : 0.044581, loss_ce: 0.018031
2022-01-14 15:16:10,717 iteration 891 : loss : 0.062137, loss_ce: 0.036832
2022-01-14 15:16:12,194 iteration 892 : loss : 0.038746, loss_ce: 0.016685
2022-01-14 15:16:13,659 iteration 893 : loss : 0.069157, loss_ce: 0.034643
2022-01-14 15:16:15,112 iteration 894 : loss : 0.050256, loss_ce: 0.016633
2022-01-14 15:16:16,566 iteration 895 : loss : 0.054017, loss_ce: 0.018931
2022-01-14 15:16:18,004 iteration 896 : loss : 0.053583, loss_ce: 0.024168
2022-01-14 15:16:19,618 iteration 897 : loss : 0.071844, loss_ce: 0.026321
2022-01-14 15:16:21,073 iteration 898 : loss : 0.063653, loss_ce: 0.026934
2022-01-14 15:16:22,595 iteration 899 : loss : 0.061844, loss_ce: 0.020752
2022-01-14 15:16:24,099 iteration 900 : loss : 0.052385, loss_ce: 0.016719
2022-01-14 15:16:25,545 iteration 901 : loss : 0.061060, loss_ce: 0.024092
 13%|███▉                          | 53/400 [24:18<2:32:44, 26.41s/it]2022-01-14 15:16:27,136 iteration 902 : loss : 0.060358, loss_ce: 0.030343
2022-01-14 15:16:28,639 iteration 903 : loss : 0.064871, loss_ce: 0.017936
2022-01-14 15:16:30,110 iteration 904 : loss : 0.065027, loss_ce: 0.030342
2022-01-14 15:16:31,567 iteration 905 : loss : 0.054116, loss_ce: 0.024386
2022-01-14 15:16:33,134 iteration 906 : loss : 0.051095, loss_ce: 0.021730
2022-01-14 15:16:34,570 iteration 907 : loss : 0.048897, loss_ce: 0.019600
2022-01-14 15:16:36,017 iteration 908 : loss : 0.054562, loss_ce: 0.027892
2022-01-14 15:16:37,521 iteration 909 : loss : 0.064031, loss_ce: 0.026805
2022-01-14 15:16:39,081 iteration 910 : loss : 0.047524, loss_ce: 0.019599
2022-01-14 15:16:40,553 iteration 911 : loss : 0.052577, loss_ce: 0.017456
2022-01-14 15:16:42,065 iteration 912 : loss : 0.068906, loss_ce: 0.028811
2022-01-14 15:16:43,541 iteration 913 : loss : 0.064149, loss_ce: 0.022608
2022-01-14 15:16:44,953 iteration 914 : loss : 0.065898, loss_ce: 0.023483
2022-01-14 15:16:46,438 iteration 915 : loss : 0.059661, loss_ce: 0.022945
2022-01-14 15:16:47,983 iteration 916 : loss : 0.087323, loss_ce: 0.026727
2022-01-14 15:16:49,500 iteration 917 : loss : 0.060824, loss_ce: 0.024452
2022-01-14 15:16:51,048 iteration 918 : loss : 0.103148, loss_ce: 0.026947
 14%|████                          | 54/400 [24:44<2:30:43, 26.14s/it]2022-01-14 15:16:52,542 iteration 919 : loss : 0.060994, loss_ce: 0.021961
2022-01-14 15:16:54,083 iteration 920 : loss : 0.045642, loss_ce: 0.020301
2022-01-14 15:16:55,505 iteration 921 : loss : 0.050719, loss_ce: 0.018594
2022-01-14 15:16:57,007 iteration 922 : loss : 0.043682, loss_ce: 0.014355
2022-01-14 15:16:58,420 iteration 923 : loss : 0.039533, loss_ce: 0.014871
2022-01-14 15:16:59,920 iteration 924 : loss : 0.070682, loss_ce: 0.021390
2022-01-14 15:17:01,425 iteration 925 : loss : 0.099705, loss_ce: 0.037867
2022-01-14 15:17:02,916 iteration 926 : loss : 0.055463, loss_ce: 0.018520
2022-01-14 15:17:04,323 iteration 927 : loss : 0.072231, loss_ce: 0.016367
2022-01-14 15:17:05,862 iteration 928 : loss : 0.058116, loss_ce: 0.025788
2022-01-14 15:17:07,320 iteration 929 : loss : 0.069862, loss_ce: 0.028039
2022-01-14 15:17:08,736 iteration 930 : loss : 0.042608, loss_ce: 0.018182
2022-01-14 15:17:10,170 iteration 931 : loss : 0.113661, loss_ce: 0.064889
2022-01-14 15:17:11,649 iteration 932 : loss : 0.050960, loss_ce: 0.026298
2022-01-14 15:17:13,163 iteration 933 : loss : 0.054044, loss_ce: 0.027393
2022-01-14 15:17:14,598 iteration 934 : loss : 0.054548, loss_ce: 0.019909
2022-01-14 15:17:14,598 Training Data Eval:
2022-01-14 15:17:21,969   Average segmentation loss on training set: 0.1041
2022-01-14 15:17:21,970 Validation Data Eval:
2022-01-14 15:17:24,523   Average segmentation loss on validation set: 0.1107
2022-01-14 15:17:26,024 iteration 935 : loss : 0.075262, loss_ce: 0.032848
 14%|████▏                         | 55/400 [25:19<2:45:31, 28.79s/it]2022-01-14 15:17:27,552 iteration 936 : loss : 0.057430, loss_ce: 0.025756
2022-01-14 15:17:29,014 iteration 937 : loss : 0.085897, loss_ce: 0.029658
2022-01-14 15:17:30,509 iteration 938 : loss : 0.052015, loss_ce: 0.024083
2022-01-14 15:17:32,102 iteration 939 : loss : 0.095140, loss_ce: 0.027108
2022-01-14 15:17:33,522 iteration 940 : loss : 0.056796, loss_ce: 0.021421
2022-01-14 15:17:34,969 iteration 941 : loss : 0.060283, loss_ce: 0.020892
2022-01-14 15:17:36,439 iteration 942 : loss : 0.079815, loss_ce: 0.031523
2022-01-14 15:17:37,943 iteration 943 : loss : 0.095095, loss_ce: 0.025787
2022-01-14 15:17:39,424 iteration 944 : loss : 0.109608, loss_ce: 0.038598
2022-01-14 15:17:40,925 iteration 945 : loss : 0.064966, loss_ce: 0.027720
2022-01-14 15:17:42,395 iteration 946 : loss : 0.057689, loss_ce: 0.021513
2022-01-14 15:17:43,876 iteration 947 : loss : 0.058931, loss_ce: 0.017401
2022-01-14 15:17:45,420 iteration 948 : loss : 0.091233, loss_ce: 0.039108
2022-01-14 15:17:46,963 iteration 949 : loss : 0.086039, loss_ce: 0.041245
2022-01-14 15:17:48,564 iteration 950 : loss : 0.078028, loss_ce: 0.029957
2022-01-14 15:17:50,029 iteration 951 : loss : 0.059104, loss_ce: 0.027744
2022-01-14 15:17:51,547 iteration 952 : loss : 0.092658, loss_ce: 0.030510
 14%|████▏                         | 56/400 [25:44<2:39:26, 27.81s/it]2022-01-14 15:17:53,042 iteration 953 : loss : 0.054234, loss_ce: 0.018810
2022-01-14 15:17:54,496 iteration 954 : loss : 0.059919, loss_ce: 0.021282
2022-01-14 15:17:56,005 iteration 955 : loss : 0.057022, loss_ce: 0.019059
2022-01-14 15:17:57,507 iteration 956 : loss : 0.051650, loss_ce: 0.016459
2022-01-14 15:17:58,993 iteration 957 : loss : 0.068051, loss_ce: 0.025334
2022-01-14 15:18:00,500 iteration 958 : loss : 0.059774, loss_ce: 0.021798
2022-01-14 15:18:02,067 iteration 959 : loss : 0.068957, loss_ce: 0.028920
2022-01-14 15:18:03,584 iteration 960 : loss : 0.068935, loss_ce: 0.031541
2022-01-14 15:18:05,079 iteration 961 : loss : 0.074697, loss_ce: 0.030699
2022-01-14 15:18:06,593 iteration 962 : loss : 0.091153, loss_ce: 0.026547
2022-01-14 15:18:08,021 iteration 963 : loss : 0.066526, loss_ce: 0.028056
2022-01-14 15:18:09,525 iteration 964 : loss : 0.083032, loss_ce: 0.023629
2022-01-14 15:18:10,970 iteration 965 : loss : 0.063145, loss_ce: 0.022015
2022-01-14 15:18:12,535 iteration 966 : loss : 0.059859, loss_ce: 0.020110
2022-01-14 15:18:14,032 iteration 967 : loss : 0.086767, loss_ce: 0.040396
2022-01-14 15:18:15,460 iteration 968 : loss : 0.065472, loss_ce: 0.023506
2022-01-14 15:18:16,986 iteration 969 : loss : 0.050183, loss_ce: 0.024642
 14%|████▎                         | 57/400 [26:10<2:34:53, 27.10s/it]2022-01-14 15:18:18,487 iteration 970 : loss : 0.074642, loss_ce: 0.033753
2022-01-14 15:18:20,030 iteration 971 : loss : 0.084492, loss_ce: 0.043384
2022-01-14 15:18:21,517 iteration 972 : loss : 0.075755, loss_ce: 0.029557
2022-01-14 15:18:23,020 iteration 973 : loss : 0.050107, loss_ce: 0.021274
2022-01-14 15:18:24,497 iteration 974 : loss : 0.076237, loss_ce: 0.029786
2022-01-14 15:18:25,930 iteration 975 : loss : 0.066606, loss_ce: 0.022937
2022-01-14 15:18:27,470 iteration 976 : loss : 0.063105, loss_ce: 0.025055
2022-01-14 15:18:28,939 iteration 977 : loss : 0.051134, loss_ce: 0.020028
2022-01-14 15:18:30,443 iteration 978 : loss : 0.052918, loss_ce: 0.020125
2022-01-14 15:18:31,899 iteration 979 : loss : 0.058624, loss_ce: 0.024920
2022-01-14 15:18:33,354 iteration 980 : loss : 0.062436, loss_ce: 0.020757
2022-01-14 15:18:34,796 iteration 981 : loss : 0.033359, loss_ce: 0.011638
2022-01-14 15:18:36,298 iteration 982 : loss : 0.079140, loss_ce: 0.024496
2022-01-14 15:18:37,837 iteration 983 : loss : 0.071087, loss_ce: 0.030046
2022-01-14 15:18:39,379 iteration 984 : loss : 0.048180, loss_ce: 0.020854
2022-01-14 15:18:40,894 iteration 985 : loss : 0.057602, loss_ce: 0.022620
2022-01-14 15:18:42,337 iteration 986 : loss : 0.057378, loss_ce: 0.020313
 14%|████▎                         | 58/400 [26:35<2:31:28, 26.57s/it]2022-01-14 15:18:43,775 iteration 987 : loss : 0.057359, loss_ce: 0.020378
2022-01-14 15:18:45,242 iteration 988 : loss : 0.052211, loss_ce: 0.017173
2022-01-14 15:18:46,704 iteration 989 : loss : 0.046726, loss_ce: 0.017474
2022-01-14 15:18:48,168 iteration 990 : loss : 0.063334, loss_ce: 0.019119
2022-01-14 15:18:49,640 iteration 991 : loss : 0.050430, loss_ce: 0.019814
2022-01-14 15:18:51,085 iteration 992 : loss : 0.048467, loss_ce: 0.018873
2022-01-14 15:18:52,488 iteration 993 : loss : 0.055239, loss_ce: 0.018340
2022-01-14 15:18:53,840 iteration 994 : loss : 0.065898, loss_ce: 0.021851
2022-01-14 15:18:55,382 iteration 995 : loss : 0.054517, loss_ce: 0.025080
2022-01-14 15:18:56,886 iteration 996 : loss : 0.051283, loss_ce: 0.025989
2022-01-14 15:18:58,409 iteration 997 : loss : 0.055667, loss_ce: 0.022618
2022-01-14 15:18:59,922 iteration 998 : loss : 0.046487, loss_ce: 0.017278
2022-01-14 15:19:01,358 iteration 999 : loss : 0.058404, loss_ce: 0.024283
2022-01-14 15:19:02,894 iteration 1000 : loss : 0.057251, loss_ce: 0.031491
2022-01-14 15:19:04,345 iteration 1001 : loss : 0.041084, loss_ce: 0.015883
2022-01-14 15:19:05,883 iteration 1002 : loss : 0.079647, loss_ce: 0.031397
2022-01-14 15:19:07,302 iteration 1003 : loss : 0.109226, loss_ce: 0.034601
 15%|████▍                         | 59/400 [27:00<2:28:16, 26.09s/it]2022-01-14 15:19:08,810 iteration 1004 : loss : 0.068771, loss_ce: 0.023231
2022-01-14 15:19:10,284 iteration 1005 : loss : 0.062081, loss_ce: 0.028190
2022-01-14 15:19:11,847 iteration 1006 : loss : 0.062297, loss_ce: 0.028358
2022-01-14 15:19:13,375 iteration 1007 : loss : 0.073694, loss_ce: 0.032590
2022-01-14 15:19:14,912 iteration 1008 : loss : 0.064557, loss_ce: 0.036286
2022-01-14 15:19:16,364 iteration 1009 : loss : 0.060067, loss_ce: 0.022622
2022-01-14 15:19:17,774 iteration 1010 : loss : 0.052149, loss_ce: 0.014588
2022-01-14 15:19:19,229 iteration 1011 : loss : 0.057833, loss_ce: 0.023380
2022-01-14 15:19:20,757 iteration 1012 : loss : 0.072731, loss_ce: 0.024729
2022-01-14 15:19:22,227 iteration 1013 : loss : 0.058015, loss_ce: 0.024291
2022-01-14 15:19:23,687 iteration 1014 : loss : 0.034576, loss_ce: 0.012713
2022-01-14 15:19:25,288 iteration 1015 : loss : 0.078472, loss_ce: 0.029340
2022-01-14 15:19:26,787 iteration 1016 : loss : 0.050159, loss_ce: 0.019148
2022-01-14 15:19:28,235 iteration 1017 : loss : 0.070586, loss_ce: 0.029316
2022-01-14 15:19:29,771 iteration 1018 : loss : 0.060561, loss_ce: 0.019948
2022-01-14 15:19:31,289 iteration 1019 : loss : 0.050075, loss_ce: 0.019201
2022-01-14 15:19:31,289 Training Data Eval:
2022-01-14 15:19:38,649   Average segmentation loss on training set: 0.0546
2022-01-14 15:19:38,650 Validation Data Eval:
2022-01-14 15:19:41,192   Average segmentation loss on validation set: 0.2088
2022-01-14 15:19:42,740 iteration 1020 : loss : 0.075136, loss_ce: 0.035977
 15%|████▌                         | 60/400 [27:36<2:43:44, 28.90s/it]2022-01-14 15:19:44,247 iteration 1021 : loss : 0.046053, loss_ce: 0.018105
2022-01-14 15:19:45,814 iteration 1022 : loss : 0.055269, loss_ce: 0.024133
2022-01-14 15:19:47,253 iteration 1023 : loss : 0.051165, loss_ce: 0.019256
2022-01-14 15:19:48,704 iteration 1024 : loss : 0.046682, loss_ce: 0.017874
2022-01-14 15:19:50,231 iteration 1025 : loss : 0.049008, loss_ce: 0.021903
2022-01-14 15:19:51,732 iteration 1026 : loss : 0.091057, loss_ce: 0.021996
2022-01-14 15:19:53,198 iteration 1027 : loss : 0.053837, loss_ce: 0.017810
2022-01-14 15:19:54,759 iteration 1028 : loss : 0.073359, loss_ce: 0.022630
2022-01-14 15:19:56,288 iteration 1029 : loss : 0.046407, loss_ce: 0.014519
2022-01-14 15:19:57,778 iteration 1030 : loss : 0.068707, loss_ce: 0.032610
2022-01-14 15:19:59,363 iteration 1031 : loss : 0.069223, loss_ce: 0.032451
2022-01-14 15:20:00,864 iteration 1032 : loss : 0.073468, loss_ce: 0.031778
2022-01-14 15:20:02,328 iteration 1033 : loss : 0.073828, loss_ce: 0.034003
2022-01-14 15:20:03,761 iteration 1034 : loss : 0.047533, loss_ce: 0.019255
2022-01-14 15:20:05,289 iteration 1035 : loss : 0.054426, loss_ce: 0.022216
2022-01-14 15:20:06,839 iteration 1036 : loss : 0.057517, loss_ce: 0.021533
2022-01-14 15:20:08,249 iteration 1037 : loss : 0.043776, loss_ce: 0.018118
 15%|████▌                         | 61/400 [28:01<2:37:31, 27.88s/it]2022-01-14 15:20:09,740 iteration 1038 : loss : 0.047456, loss_ce: 0.022353
2022-01-14 15:20:11,214 iteration 1039 : loss : 0.049592, loss_ce: 0.021540
2022-01-14 15:20:12,674 iteration 1040 : loss : 0.077850, loss_ce: 0.027088
2022-01-14 15:20:14,149 iteration 1041 : loss : 0.046455, loss_ce: 0.022086
2022-01-14 15:20:15,606 iteration 1042 : loss : 0.046098, loss_ce: 0.024358
2022-01-14 15:20:17,074 iteration 1043 : loss : 0.059292, loss_ce: 0.020523
2022-01-14 15:20:18,608 iteration 1044 : loss : 0.053655, loss_ce: 0.024874
2022-01-14 15:20:20,103 iteration 1045 : loss : 0.063458, loss_ce: 0.026358
2022-01-14 15:20:21,553 iteration 1046 : loss : 0.043551, loss_ce: 0.022006
2022-01-14 15:20:22,919 iteration 1047 : loss : 0.047416, loss_ce: 0.020189
2022-01-14 15:20:24,406 iteration 1048 : loss : 0.039520, loss_ce: 0.019014
2022-01-14 15:20:25,936 iteration 1049 : loss : 0.058077, loss_ce: 0.023900
2022-01-14 15:20:27,406 iteration 1050 : loss : 0.141479, loss_ce: 0.026922
2022-01-14 15:20:28,858 iteration 1051 : loss : 0.046180, loss_ce: 0.021100
2022-01-14 15:20:30,386 iteration 1052 : loss : 0.093822, loss_ce: 0.027683
2022-01-14 15:20:31,897 iteration 1053 : loss : 0.103766, loss_ce: 0.031720
2022-01-14 15:20:33,384 iteration 1054 : loss : 0.054527, loss_ce: 0.020174
 16%|████▋                         | 62/400 [28:26<2:32:24, 27.05s/it]2022-01-14 15:20:34,902 iteration 1055 : loss : 0.045630, loss_ce: 0.012939
2022-01-14 15:20:36,306 iteration 1056 : loss : 0.047208, loss_ce: 0.020675
2022-01-14 15:20:37,815 iteration 1057 : loss : 0.058079, loss_ce: 0.018783
2022-01-14 15:20:39,301 iteration 1058 : loss : 0.085323, loss_ce: 0.028506
2022-01-14 15:20:40,795 iteration 1059 : loss : 0.056917, loss_ce: 0.021844
2022-01-14 15:20:42,209 iteration 1060 : loss : 0.055927, loss_ce: 0.017748
2022-01-14 15:20:43,781 iteration 1061 : loss : 0.074635, loss_ce: 0.038883
2022-01-14 15:20:45,313 iteration 1062 : loss : 0.080326, loss_ce: 0.025016
2022-01-14 15:20:46,929 iteration 1063 : loss : 0.059807, loss_ce: 0.024468
2022-01-14 15:20:48,440 iteration 1064 : loss : 0.072988, loss_ce: 0.020421
2022-01-14 15:20:50,012 iteration 1065 : loss : 0.048524, loss_ce: 0.022825
2022-01-14 15:20:51,466 iteration 1066 : loss : 0.052443, loss_ce: 0.022368
2022-01-14 15:20:52,917 iteration 1067 : loss : 0.040402, loss_ce: 0.015364
2022-01-14 15:20:54,440 iteration 1068 : loss : 0.047997, loss_ce: 0.020103
2022-01-14 15:20:55,945 iteration 1069 : loss : 0.059821, loss_ce: 0.027771
2022-01-14 15:20:57,542 iteration 1070 : loss : 0.096019, loss_ce: 0.025933
2022-01-14 15:20:59,035 iteration 1071 : loss : 0.057178, loss_ce: 0.028837
 16%|████▋                         | 63/400 [28:52<2:29:36, 26.64s/it]2022-01-14 15:21:00,660 iteration 1072 : loss : 0.057634, loss_ce: 0.018886
2022-01-14 15:21:02,167 iteration 1073 : loss : 0.060049, loss_ce: 0.025275
2022-01-14 15:21:03,681 iteration 1074 : loss : 0.052987, loss_ce: 0.021269
2022-01-14 15:21:05,194 iteration 1075 : loss : 0.084043, loss_ce: 0.024358
2022-01-14 15:21:06,649 iteration 1076 : loss : 0.054669, loss_ce: 0.020017
2022-01-14 15:21:08,215 iteration 1077 : loss : 0.081209, loss_ce: 0.026918
2022-01-14 15:21:09,673 iteration 1078 : loss : 0.069792, loss_ce: 0.034341
2022-01-14 15:21:11,224 iteration 1079 : loss : 0.079587, loss_ce: 0.039525
2022-01-14 15:21:12,639 iteration 1080 : loss : 0.030002, loss_ce: 0.009596
2022-01-14 15:21:14,108 iteration 1081 : loss : 0.040180, loss_ce: 0.019758
2022-01-14 15:21:15,629 iteration 1082 : loss : 0.085482, loss_ce: 0.041242
2022-01-14 15:21:17,075 iteration 1083 : loss : 0.058230, loss_ce: 0.024677
2022-01-14 15:21:18,539 iteration 1084 : loss : 0.061435, loss_ce: 0.020941
2022-01-14 15:21:20,036 iteration 1085 : loss : 0.051219, loss_ce: 0.022426
2022-01-14 15:21:21,511 iteration 1086 : loss : 0.056594, loss_ce: 0.025515
2022-01-14 15:21:23,075 iteration 1087 : loss : 0.036659, loss_ce: 0.014449
2022-01-14 15:21:24,564 iteration 1088 : loss : 0.044537, loss_ce: 0.017600
 16%|████▊                         | 64/400 [29:17<2:27:16, 26.30s/it]2022-01-14 15:21:26,051 iteration 1089 : loss : 0.075922, loss_ce: 0.028212
2022-01-14 15:21:27,504 iteration 1090 : loss : 0.066531, loss_ce: 0.021505
2022-01-14 15:21:29,073 iteration 1091 : loss : 0.052519, loss_ce: 0.024861
2022-01-14 15:21:30,578 iteration 1092 : loss : 0.052554, loss_ce: 0.021774
2022-01-14 15:21:32,067 iteration 1093 : loss : 0.046332, loss_ce: 0.019071
2022-01-14 15:21:33,576 iteration 1094 : loss : 0.050501, loss_ce: 0.022474
2022-01-14 15:21:35,094 iteration 1095 : loss : 0.080100, loss_ce: 0.023689
2022-01-14 15:21:36,579 iteration 1096 : loss : 0.041253, loss_ce: 0.017226
2022-01-14 15:21:38,018 iteration 1097 : loss : 0.074658, loss_ce: 0.023575
2022-01-14 15:21:39,463 iteration 1098 : loss : 0.049550, loss_ce: 0.021647
2022-01-14 15:21:40,968 iteration 1099 : loss : 0.036649, loss_ce: 0.014668
2022-01-14 15:21:42,428 iteration 1100 : loss : 0.055434, loss_ce: 0.020480
2022-01-14 15:21:43,884 iteration 1101 : loss : 0.049712, loss_ce: 0.018347
2022-01-14 15:21:45,435 iteration 1102 : loss : 0.064342, loss_ce: 0.018417
2022-01-14 15:21:46,907 iteration 1103 : loss : 0.061354, loss_ce: 0.026143
2022-01-14 15:21:48,336 iteration 1104 : loss : 0.057419, loss_ce: 0.022856
2022-01-14 15:21:48,337 Training Data Eval:
2022-01-14 15:21:55,696   Average segmentation loss on training set: 0.0453
2022-01-14 15:21:55,697 Validation Data Eval:
2022-01-14 15:21:58,228   Average segmentation loss on validation set: 0.1319
2022-01-14 15:21:59,709 iteration 1105 : loss : 0.047073, loss_ce: 0.022306
 16%|████▉                         | 65/400 [29:52<2:41:39, 28.95s/it]2022-01-14 15:22:01,227 iteration 1106 : loss : 0.044278, loss_ce: 0.015248
2022-01-14 15:22:02,763 iteration 1107 : loss : 0.048562, loss_ce: 0.022643
2022-01-14 15:22:04,197 iteration 1108 : loss : 0.041601, loss_ce: 0.014567
2022-01-14 15:22:05,616 iteration 1109 : loss : 0.062382, loss_ce: 0.023873
2022-01-14 15:22:07,081 iteration 1110 : loss : 0.051518, loss_ce: 0.019594
2022-01-14 15:22:08,569 iteration 1111 : loss : 0.041819, loss_ce: 0.018165
2022-01-14 15:22:10,065 iteration 1112 : loss : 0.048341, loss_ce: 0.019492
2022-01-14 15:22:11,516 iteration 1113 : loss : 0.046720, loss_ce: 0.016340
2022-01-14 15:22:12,939 iteration 1114 : loss : 0.061743, loss_ce: 0.021344
2022-01-14 15:22:14,327 iteration 1115 : loss : 0.044559, loss_ce: 0.014838
2022-01-14 15:22:15,874 iteration 1116 : loss : 0.056198, loss_ce: 0.024878
2022-01-14 15:22:17,437 iteration 1117 : loss : 0.051881, loss_ce: 0.018749
2022-01-14 15:22:18,880 iteration 1118 : loss : 0.064046, loss_ce: 0.025988
2022-01-14 15:22:20,318 iteration 1119 : loss : 0.041097, loss_ce: 0.016651
2022-01-14 15:22:21,738 iteration 1120 : loss : 0.055440, loss_ce: 0.020745
2022-01-14 15:22:23,169 iteration 1121 : loss : 0.047276, loss_ce: 0.013837
2022-01-14 15:22:24,593 iteration 1122 : loss : 0.039781, loss_ce: 0.016888
 16%|████▉                         | 66/400 [30:17<2:34:23, 27.74s/it]2022-01-14 15:22:26,111 iteration 1123 : loss : 0.058231, loss_ce: 0.024282
2022-01-14 15:22:27,554 iteration 1124 : loss : 0.057894, loss_ce: 0.022722
2022-01-14 15:22:29,111 iteration 1125 : loss : 0.055228, loss_ce: 0.023201
2022-01-14 15:22:30,710 iteration 1126 : loss : 0.076840, loss_ce: 0.032516
2022-01-14 15:22:32,223 iteration 1127 : loss : 0.073969, loss_ce: 0.026400
2022-01-14 15:22:33,728 iteration 1128 : loss : 0.062454, loss_ce: 0.019229
2022-01-14 15:22:35,202 iteration 1129 : loss : 0.029363, loss_ce: 0.010098
2022-01-14 15:22:36,737 iteration 1130 : loss : 0.049055, loss_ce: 0.024951
2022-01-14 15:22:38,296 iteration 1131 : loss : 0.115554, loss_ce: 0.033320
2022-01-14 15:22:39,809 iteration 1132 : loss : 0.051733, loss_ce: 0.018958
2022-01-14 15:22:41,310 iteration 1133 : loss : 0.067633, loss_ce: 0.026263
2022-01-14 15:22:42,803 iteration 1134 : loss : 0.061638, loss_ce: 0.026151
2022-01-14 15:22:44,242 iteration 1135 : loss : 0.041576, loss_ce: 0.014259
2022-01-14 15:22:45,726 iteration 1136 : loss : 0.056162, loss_ce: 0.022548
2022-01-14 15:22:47,185 iteration 1137 : loss : 0.057263, loss_ce: 0.023428
2022-01-14 15:22:48,742 iteration 1138 : loss : 0.051238, loss_ce: 0.022672
2022-01-14 15:22:50,291 iteration 1139 : loss : 0.059812, loss_ce: 0.026987
 17%|█████                         | 67/400 [30:43<2:30:32, 27.12s/it]2022-01-14 15:22:51,800 iteration 1140 : loss : 0.062297, loss_ce: 0.025899
2022-01-14 15:22:53,286 iteration 1141 : loss : 0.043219, loss_ce: 0.017713
2022-01-14 15:22:54,723 iteration 1142 : loss : 0.036282, loss_ce: 0.014922
2022-01-14 15:22:56,259 iteration 1143 : loss : 0.090000, loss_ce: 0.033426
2022-01-14 15:22:57,844 iteration 1144 : loss : 0.048564, loss_ce: 0.020509
2022-01-14 15:22:59,353 iteration 1145 : loss : 0.040937, loss_ce: 0.014033
2022-01-14 15:23:00,895 iteration 1146 : loss : 0.046743, loss_ce: 0.018978
2022-01-14 15:23:02,312 iteration 1147 : loss : 0.033549, loss_ce: 0.012049
2022-01-14 15:23:03,785 iteration 1148 : loss : 0.044304, loss_ce: 0.015618
2022-01-14 15:23:05,309 iteration 1149 : loss : 0.042914, loss_ce: 0.020504
2022-01-14 15:23:06,795 iteration 1150 : loss : 0.047630, loss_ce: 0.019948
2022-01-14 15:23:08,281 iteration 1151 : loss : 0.045806, loss_ce: 0.012971
2022-01-14 15:23:09,792 iteration 1152 : loss : 0.121632, loss_ce: 0.017713
2022-01-14 15:23:11,280 iteration 1153 : loss : 0.040353, loss_ce: 0.014340
2022-01-14 15:23:12,700 iteration 1154 : loss : 0.048524, loss_ce: 0.023311
2022-01-14 15:23:14,260 iteration 1155 : loss : 0.055835, loss_ce: 0.021135
2022-01-14 15:23:15,775 iteration 1156 : loss : 0.087521, loss_ce: 0.029309
 17%|█████                         | 68/400 [31:09<2:27:21, 26.63s/it]2022-01-14 15:23:17,254 iteration 1157 : loss : 0.051110, loss_ce: 0.021864
2022-01-14 15:23:18,852 iteration 1158 : loss : 0.065675, loss_ce: 0.022856
2022-01-14 15:23:20,393 iteration 1159 : loss : 0.056324, loss_ce: 0.025917
2022-01-14 15:23:21,798 iteration 1160 : loss : 0.047369, loss_ce: 0.023564
2022-01-14 15:23:23,268 iteration 1161 : loss : 0.066642, loss_ce: 0.020883
2022-01-14 15:23:24,738 iteration 1162 : loss : 0.058730, loss_ce: 0.013689
2022-01-14 15:23:26,314 iteration 1163 : loss : 0.082754, loss_ce: 0.023608
2022-01-14 15:23:27,817 iteration 1164 : loss : 0.050505, loss_ce: 0.017515
2022-01-14 15:23:29,243 iteration 1165 : loss : 0.059113, loss_ce: 0.026853
2022-01-14 15:23:30,712 iteration 1166 : loss : 0.046895, loss_ce: 0.020628
2022-01-14 15:23:32,217 iteration 1167 : loss : 0.053445, loss_ce: 0.022453
2022-01-14 15:23:33,622 iteration 1168 : loss : 0.039814, loss_ce: 0.014095
2022-01-14 15:23:35,101 iteration 1169 : loss : 0.073479, loss_ce: 0.024619
2022-01-14 15:23:36,590 iteration 1170 : loss : 0.057058, loss_ce: 0.024320
2022-01-14 15:23:37,998 iteration 1171 : loss : 0.035370, loss_ce: 0.013897
2022-01-14 15:23:39,468 iteration 1172 : loss : 0.079794, loss_ce: 0.037196
2022-01-14 15:23:40,969 iteration 1173 : loss : 0.061224, loss_ce: 0.037309
 17%|█████▏                        | 69/400 [31:34<2:24:33, 26.20s/it]2022-01-14 15:23:42,527 iteration 1174 : loss : 0.066964, loss_ce: 0.020523
2022-01-14 15:23:43,991 iteration 1175 : loss : 0.052669, loss_ce: 0.024126
2022-01-14 15:23:45,521 iteration 1176 : loss : 0.077717, loss_ce: 0.036197
2022-01-14 15:23:47,093 iteration 1177 : loss : 0.102531, loss_ce: 0.043357
2022-01-14 15:23:48,599 iteration 1178 : loss : 0.074730, loss_ce: 0.028888
2022-01-14 15:23:50,005 iteration 1179 : loss : 0.047907, loss_ce: 0.022140
2022-01-14 15:23:51,527 iteration 1180 : loss : 0.044369, loss_ce: 0.017715
2022-01-14 15:23:52,934 iteration 1181 : loss : 0.042168, loss_ce: 0.018264
2022-01-14 15:23:54,506 iteration 1182 : loss : 0.085530, loss_ce: 0.032126
2022-01-14 15:23:55,985 iteration 1183 : loss : 0.046085, loss_ce: 0.019356
2022-01-14 15:23:57,401 iteration 1184 : loss : 0.049501, loss_ce: 0.020782
2022-01-14 15:23:58,897 iteration 1185 : loss : 0.072453, loss_ce: 0.029324
2022-01-14 15:24:00,338 iteration 1186 : loss : 0.049675, loss_ce: 0.019690
2022-01-14 15:24:01,836 iteration 1187 : loss : 0.047737, loss_ce: 0.019273
2022-01-14 15:24:03,262 iteration 1188 : loss : 0.041375, loss_ce: 0.014244
2022-01-14 15:24:04,734 iteration 1189 : loss : 0.046452, loss_ce: 0.019950
2022-01-14 15:24:04,734 Training Data Eval:
2022-01-14 15:24:12,101   Average segmentation loss on training set: 0.0442
2022-01-14 15:24:12,102 Validation Data Eval:
2022-01-14 15:24:14,639   Average segmentation loss on validation set: 0.1448
2022-01-14 15:24:16,133 iteration 1190 : loss : 0.065460, loss_ce: 0.024522
 18%|█████▎                        | 70/400 [32:09<2:38:52, 28.89s/it]2022-01-14 15:24:17,622 iteration 1191 : loss : 0.057431, loss_ce: 0.026314
2022-01-14 15:24:19,059 iteration 1192 : loss : 0.044893, loss_ce: 0.018269
2022-01-14 15:24:20,536 iteration 1193 : loss : 0.065039, loss_ce: 0.021427
2022-01-14 15:24:21,977 iteration 1194 : loss : 0.066783, loss_ce: 0.024302
2022-01-14 15:24:23,491 iteration 1195 : loss : 0.057749, loss_ce: 0.018709
2022-01-14 15:24:24,899 iteration 1196 : loss : 0.063820, loss_ce: 0.020624
2022-01-14 15:24:26,408 iteration 1197 : loss : 0.058612, loss_ce: 0.031669
2022-01-14 15:24:27,890 iteration 1198 : loss : 0.046824, loss_ce: 0.026587
2022-01-14 15:24:29,380 iteration 1199 : loss : 0.061233, loss_ce: 0.021687
2022-01-14 15:24:30,898 iteration 1200 : loss : 0.086680, loss_ce: 0.034473
2022-01-14 15:24:32,368 iteration 1201 : loss : 0.040124, loss_ce: 0.017472
2022-01-14 15:24:33,881 iteration 1202 : loss : 0.037721, loss_ce: 0.017461
2022-01-14 15:24:35,352 iteration 1203 : loss : 0.058440, loss_ce: 0.022452
2022-01-14 15:24:36,824 iteration 1204 : loss : 0.051035, loss_ce: 0.020988
2022-01-14 15:24:38,339 iteration 1205 : loss : 0.060996, loss_ce: 0.033839
2022-01-14 15:24:39,870 iteration 1206 : loss : 0.095556, loss_ce: 0.030027
2022-01-14 15:24:41,313 iteration 1207 : loss : 0.059199, loss_ce: 0.020001
 18%|█████▎                        | 71/400 [32:34<2:32:19, 27.78s/it]2022-01-14 15:24:42,780 iteration 1208 : loss : 0.052996, loss_ce: 0.025616
2022-01-14 15:24:44,261 iteration 1209 : loss : 0.051651, loss_ce: 0.015973
2022-01-14 15:24:45,666 iteration 1210 : loss : 0.040463, loss_ce: 0.012218
2022-01-14 15:24:47,176 iteration 1211 : loss : 0.068286, loss_ce: 0.023106
2022-01-14 15:24:48,611 iteration 1212 : loss : 0.036081, loss_ce: 0.014586
2022-01-14 15:24:50,092 iteration 1213 : loss : 0.067431, loss_ce: 0.018858
2022-01-14 15:24:51,613 iteration 1214 : loss : 0.038772, loss_ce: 0.015933
2022-01-14 15:24:53,088 iteration 1215 : loss : 0.053632, loss_ce: 0.022650
2022-01-14 15:24:54,544 iteration 1216 : loss : 0.039709, loss_ce: 0.014737
2022-01-14 15:24:56,061 iteration 1217 : loss : 0.050918, loss_ce: 0.021977
2022-01-14 15:24:57,441 iteration 1218 : loss : 0.039327, loss_ce: 0.018380
2022-01-14 15:24:58,949 iteration 1219 : loss : 0.057496, loss_ce: 0.021111
2022-01-14 15:25:00,406 iteration 1220 : loss : 0.053649, loss_ce: 0.018988
2022-01-14 15:25:01,993 iteration 1221 : loss : 0.049257, loss_ce: 0.020617
2022-01-14 15:25:03,511 iteration 1222 : loss : 0.045102, loss_ce: 0.015426
2022-01-14 15:25:04,970 iteration 1223 : loss : 0.036449, loss_ce: 0.014300
2022-01-14 15:25:06,479 iteration 1224 : loss : 0.047318, loss_ce: 0.020551
 18%|█████▍                        | 72/400 [32:59<2:27:33, 26.99s/it]2022-01-14 15:25:08,023 iteration 1225 : loss : 0.043230, loss_ce: 0.014277
2022-01-14 15:25:09,513 iteration 1226 : loss : 0.055888, loss_ce: 0.021184
2022-01-14 15:25:10,954 iteration 1227 : loss : 0.040076, loss_ce: 0.012342
2022-01-14 15:25:12,532 iteration 1228 : loss : 0.083642, loss_ce: 0.027948
2022-01-14 15:25:14,080 iteration 1229 : loss : 0.046877, loss_ce: 0.019756
2022-01-14 15:25:15,606 iteration 1230 : loss : 0.053506, loss_ce: 0.025764
2022-01-14 15:25:17,080 iteration 1231 : loss : 0.066630, loss_ce: 0.024929
2022-01-14 15:25:18,614 iteration 1232 : loss : 0.036109, loss_ce: 0.013658
2022-01-14 15:25:20,209 iteration 1233 : loss : 0.054104, loss_ce: 0.024992
2022-01-14 15:25:21,714 iteration 1234 : loss : 0.062156, loss_ce: 0.025693
2022-01-14 15:25:23,181 iteration 1235 : loss : 0.053327, loss_ce: 0.023008
2022-01-14 15:25:24,623 iteration 1236 : loss : 0.059381, loss_ce: 0.020268
2022-01-14 15:25:26,048 iteration 1237 : loss : 0.065774, loss_ce: 0.026813
2022-01-14 15:25:27,522 iteration 1238 : loss : 0.053919, loss_ce: 0.025455
2022-01-14 15:25:29,043 iteration 1239 : loss : 0.063640, loss_ce: 0.020982
2022-01-14 15:25:30,443 iteration 1240 : loss : 0.050909, loss_ce: 0.019105
2022-01-14 15:25:32,004 iteration 1241 : loss : 0.034348, loss_ce: 0.013926
 18%|█████▍                        | 73/400 [33:25<2:24:43, 26.56s/it]2022-01-14 15:25:33,455 iteration 1242 : loss : 0.043474, loss_ce: 0.018593
2022-01-14 15:25:34,867 iteration 1243 : loss : 0.031112, loss_ce: 0.014812
2022-01-14 15:25:36,286 iteration 1244 : loss : 0.060546, loss_ce: 0.020891
2022-01-14 15:25:37,745 iteration 1245 : loss : 0.051706, loss_ce: 0.020108
2022-01-14 15:25:39,225 iteration 1246 : loss : 0.045710, loss_ce: 0.018266
2022-01-14 15:25:40,735 iteration 1247 : loss : 0.060956, loss_ce: 0.019715
2022-01-14 15:25:42,170 iteration 1248 : loss : 0.038414, loss_ce: 0.014307
2022-01-14 15:25:43,661 iteration 1249 : loss : 0.051755, loss_ce: 0.015757
2022-01-14 15:25:45,102 iteration 1250 : loss : 0.051385, loss_ce: 0.018996
2022-01-14 15:25:46,600 iteration 1251 : loss : 0.056155, loss_ce: 0.022858
2022-01-14 15:25:48,094 iteration 1252 : loss : 0.086038, loss_ce: 0.020747
2022-01-14 15:25:49,584 iteration 1253 : loss : 0.063780, loss_ce: 0.028937
2022-01-14 15:25:51,041 iteration 1254 : loss : 0.078840, loss_ce: 0.032265
2022-01-14 15:25:52,560 iteration 1255 : loss : 0.052879, loss_ce: 0.022377
2022-01-14 15:25:54,106 iteration 1256 : loss : 0.062651, loss_ce: 0.023278
2022-01-14 15:25:55,591 iteration 1257 : loss : 0.057159, loss_ce: 0.030900
2022-01-14 15:25:57,149 iteration 1258 : loss : 0.042553, loss_ce: 0.018878
 18%|█████▌                        | 74/400 [33:50<2:21:58, 26.13s/it]2022-01-14 15:25:58,664 iteration 1259 : loss : 0.061820, loss_ce: 0.020092
2022-01-14 15:26:00,189 iteration 1260 : loss : 0.048779, loss_ce: 0.015193
2022-01-14 15:26:01,685 iteration 1261 : loss : 0.053050, loss_ce: 0.021325
2022-01-14 15:26:03,122 iteration 1262 : loss : 0.045034, loss_ce: 0.022176
2022-01-14 15:26:04,656 iteration 1263 : loss : 0.040141, loss_ce: 0.014292
2022-01-14 15:26:06,073 iteration 1264 : loss : 0.068006, loss_ce: 0.040147
2022-01-14 15:26:07,501 iteration 1265 : loss : 0.043210, loss_ce: 0.015853
2022-01-14 15:26:08,908 iteration 1266 : loss : 0.038271, loss_ce: 0.018364
2022-01-14 15:26:10,506 iteration 1267 : loss : 0.053914, loss_ce: 0.020148
2022-01-14 15:26:11,976 iteration 1268 : loss : 0.112900, loss_ce: 0.030191
2022-01-14 15:26:13,490 iteration 1269 : loss : 0.065837, loss_ce: 0.024290
2022-01-14 15:26:14,921 iteration 1270 : loss : 0.056792, loss_ce: 0.019242
2022-01-14 15:26:16,392 iteration 1271 : loss : 0.047334, loss_ce: 0.021472
2022-01-14 15:26:17,851 iteration 1272 : loss : 0.073543, loss_ce: 0.034222
2022-01-14 15:26:19,368 iteration 1273 : loss : 0.052684, loss_ce: 0.025948
2022-01-14 15:26:20,862 iteration 1274 : loss : 0.058804, loss_ce: 0.020898
2022-01-14 15:26:20,862 Training Data Eval:
2022-01-14 15:26:28,229   Average segmentation loss on training set: 0.0506
2022-01-14 15:26:28,230 Validation Data Eval:
2022-01-14 15:26:30,773   Average segmentation loss on validation set: 0.1749
2022-01-14 15:26:32,271 iteration 1275 : loss : 0.050314, loss_ce: 0.015797
 19%|█████▋                        | 75/400 [34:25<2:36:09, 28.83s/it]2022-01-14 15:26:33,884 iteration 1276 : loss : 0.070745, loss_ce: 0.021313
2022-01-14 15:26:35,316 iteration 1277 : loss : 0.039520, loss_ce: 0.015333
2022-01-14 15:26:36,869 iteration 1278 : loss : 0.070897, loss_ce: 0.031382
2022-01-14 15:26:38,250 iteration 1279 : loss : 0.044831, loss_ce: 0.022401
2022-01-14 15:26:39,634 iteration 1280 : loss : 0.045917, loss_ce: 0.023582
2022-01-14 15:26:41,160 iteration 1281 : loss : 0.037111, loss_ce: 0.016278
2022-01-14 15:26:42,586 iteration 1282 : loss : 0.056019, loss_ce: 0.030551
2022-01-14 15:26:44,037 iteration 1283 : loss : 0.051260, loss_ce: 0.019464
2022-01-14 15:26:45,510 iteration 1284 : loss : 0.058995, loss_ce: 0.028072
2022-01-14 15:26:47,132 iteration 1285 : loss : 0.062777, loss_ce: 0.021044
2022-01-14 15:26:48,657 iteration 1286 : loss : 0.057026, loss_ce: 0.021212
2022-01-14 15:26:50,114 iteration 1287 : loss : 0.051218, loss_ce: 0.017221
2022-01-14 15:26:51,614 iteration 1288 : loss : 0.053869, loss_ce: 0.022461
2022-01-14 15:26:53,198 iteration 1289 : loss : 0.040636, loss_ce: 0.016668
2022-01-14 15:26:54,646 iteration 1290 : loss : 0.068426, loss_ce: 0.021488
2022-01-14 15:26:56,132 iteration 1291 : loss : 0.043507, loss_ce: 0.015976
2022-01-14 15:26:57,556 iteration 1292 : loss : 0.033726, loss_ce: 0.012838
 19%|█████▋                        | 76/400 [34:50<2:29:55, 27.76s/it]2022-01-14 15:26:59,071 iteration 1293 : loss : 0.062257, loss_ce: 0.028695
2022-01-14 15:27:00,506 iteration 1294 : loss : 0.056195, loss_ce: 0.020416
2022-01-14 15:27:01,962 iteration 1295 : loss : 0.043796, loss_ce: 0.018497
2022-01-14 15:27:03,428 iteration 1296 : loss : 0.037164, loss_ce: 0.012646
2022-01-14 15:27:04,889 iteration 1297 : loss : 0.045745, loss_ce: 0.016760
2022-01-14 15:27:06,370 iteration 1298 : loss : 0.039166, loss_ce: 0.017936
2022-01-14 15:27:07,801 iteration 1299 : loss : 0.045804, loss_ce: 0.015077
2022-01-14 15:27:09,330 iteration 1300 : loss : 0.067926, loss_ce: 0.016884
2022-01-14 15:27:10,825 iteration 1301 : loss : 0.049885, loss_ce: 0.024538
2022-01-14 15:27:12,358 iteration 1302 : loss : 0.056446, loss_ce: 0.015977
2022-01-14 15:27:13,800 iteration 1303 : loss : 0.057396, loss_ce: 0.024763
2022-01-14 15:27:15,322 iteration 1304 : loss : 0.090781, loss_ce: 0.025577
2022-01-14 15:27:16,804 iteration 1305 : loss : 0.038577, loss_ce: 0.016623
2022-01-14 15:27:18,338 iteration 1306 : loss : 0.052115, loss_ce: 0.019361
2022-01-14 15:27:19,882 iteration 1307 : loss : 0.054277, loss_ce: 0.019984
2022-01-14 15:27:21,373 iteration 1308 : loss : 0.045690, loss_ce: 0.024970
2022-01-14 15:27:22,883 iteration 1309 : loss : 0.046667, loss_ce: 0.014932
 19%|█████▊                        | 77/400 [35:16<2:25:31, 27.03s/it]2022-01-14 15:27:24,411 iteration 1310 : loss : 0.046718, loss_ce: 0.020112
2022-01-14 15:27:25,963 iteration 1311 : loss : 0.044934, loss_ce: 0.016162
2022-01-14 15:27:27,435 iteration 1312 : loss : 0.049235, loss_ce: 0.024857
2022-01-14 15:27:28,852 iteration 1313 : loss : 0.036114, loss_ce: 0.015290
2022-01-14 15:27:30,339 iteration 1314 : loss : 0.040108, loss_ce: 0.016733
2022-01-14 15:27:31,836 iteration 1315 : loss : 0.049513, loss_ce: 0.020539
2022-01-14 15:27:33,290 iteration 1316 : loss : 0.049101, loss_ce: 0.021035
2022-01-14 15:27:34,801 iteration 1317 : loss : 0.038166, loss_ce: 0.018327
2022-01-14 15:27:36,355 iteration 1318 : loss : 0.059559, loss_ce: 0.027747
2022-01-14 15:27:37,832 iteration 1319 : loss : 0.051828, loss_ce: 0.017795
2022-01-14 15:27:39,332 iteration 1320 : loss : 0.048944, loss_ce: 0.016177
2022-01-14 15:27:40,848 iteration 1321 : loss : 0.063860, loss_ce: 0.023212
2022-01-14 15:27:42,470 iteration 1322 : loss : 0.051786, loss_ce: 0.019897
2022-01-14 15:27:43,985 iteration 1323 : loss : 0.030344, loss_ce: 0.011192
2022-01-14 15:27:45,499 iteration 1324 : loss : 0.029873, loss_ce: 0.009929
2022-01-14 15:27:47,032 iteration 1325 : loss : 0.044236, loss_ce: 0.013558
2022-01-14 15:27:48,456 iteration 1326 : loss : 0.045307, loss_ce: 0.015162
 20%|█████▊                        | 78/400 [35:41<2:22:44, 26.60s/it]2022-01-14 15:27:50,007 iteration 1327 : loss : 0.063259, loss_ce: 0.034592
2022-01-14 15:27:51,587 iteration 1328 : loss : 0.053471, loss_ce: 0.016327
2022-01-14 15:27:53,007 iteration 1329 : loss : 0.051628, loss_ce: 0.026482
2022-01-14 15:27:54,485 iteration 1330 : loss : 0.046579, loss_ce: 0.016390
2022-01-14 15:27:55,963 iteration 1331 : loss : 0.035742, loss_ce: 0.011886
2022-01-14 15:27:57,430 iteration 1332 : loss : 0.033352, loss_ce: 0.013842
2022-01-14 15:27:58,938 iteration 1333 : loss : 0.068098, loss_ce: 0.013703
2022-01-14 15:28:00,405 iteration 1334 : loss : 0.029488, loss_ce: 0.012114
2022-01-14 15:28:01,993 iteration 1335 : loss : 0.045975, loss_ce: 0.015854
2022-01-14 15:28:03,511 iteration 1336 : loss : 0.040561, loss_ce: 0.017090
2022-01-14 15:28:05,057 iteration 1337 : loss : 0.045559, loss_ce: 0.019376
2022-01-14 15:28:06,607 iteration 1338 : loss : 0.060951, loss_ce: 0.023300
2022-01-14 15:28:08,131 iteration 1339 : loss : 0.045418, loss_ce: 0.019361
2022-01-14 15:28:09,569 iteration 1340 : loss : 0.045134, loss_ce: 0.014269
2022-01-14 15:28:11,039 iteration 1341 : loss : 0.043246, loss_ce: 0.017735
2022-01-14 15:28:12,513 iteration 1342 : loss : 0.049856, loss_ce: 0.016851
2022-01-14 15:28:13,968 iteration 1343 : loss : 0.050791, loss_ce: 0.019775
 20%|█████▉                        | 79/400 [36:07<2:20:32, 26.27s/it]2022-01-14 15:28:15,466 iteration 1344 : loss : 0.034602, loss_ce: 0.013715
2022-01-14 15:28:16,909 iteration 1345 : loss : 0.040730, loss_ce: 0.016785
2022-01-14 15:28:18,339 iteration 1346 : loss : 0.038585, loss_ce: 0.014916
2022-01-14 15:28:19,887 iteration 1347 : loss : 0.109062, loss_ce: 0.019549
2022-01-14 15:28:21,439 iteration 1348 : loss : 0.043303, loss_ce: 0.016409
2022-01-14 15:28:22,941 iteration 1349 : loss : 0.068218, loss_ce: 0.030049
2022-01-14 15:28:24,466 iteration 1350 : loss : 0.067050, loss_ce: 0.026584
2022-01-14 15:28:25,901 iteration 1351 : loss : 0.050052, loss_ce: 0.016548
2022-01-14 15:28:27,461 iteration 1352 : loss : 0.045808, loss_ce: 0.016437
2022-01-14 15:28:28,872 iteration 1353 : loss : 0.040168, loss_ce: 0.018265
2022-01-14 15:28:30,378 iteration 1354 : loss : 0.035395, loss_ce: 0.013851
2022-01-14 15:28:31,801 iteration 1355 : loss : 0.068316, loss_ce: 0.021936
2022-01-14 15:28:33,317 iteration 1356 : loss : 0.057379, loss_ce: 0.020118
2022-01-14 15:28:34,742 iteration 1357 : loss : 0.051697, loss_ce: 0.028651
2022-01-14 15:28:36,213 iteration 1358 : loss : 0.041944, loss_ce: 0.014516
2022-01-14 15:28:37,631 iteration 1359 : loss : 0.046969, loss_ce: 0.025429
2022-01-14 15:28:37,631 Training Data Eval:
2022-01-14 15:28:44,984   Average segmentation loss on training set: 0.0615
2022-01-14 15:28:44,985 Validation Data Eval:
2022-01-14 15:28:47,520   Average segmentation loss on validation set: 0.1921
2022-01-14 15:28:48,980 iteration 1360 : loss : 0.065652, loss_ce: 0.025499
 20%|██████                        | 80/400 [36:42<2:34:05, 28.89s/it]2022-01-14 15:28:50,544 iteration 1361 : loss : 0.094172, loss_ce: 0.026183
2022-01-14 15:28:52,041 iteration 1362 : loss : 0.056230, loss_ce: 0.024765
2022-01-14 15:28:53,549 iteration 1363 : loss : 0.036372, loss_ce: 0.012436
2022-01-14 15:28:55,087 iteration 1364 : loss : 0.081969, loss_ce: 0.026405
2022-01-14 15:28:56,688 iteration 1365 : loss : 0.036610, loss_ce: 0.014321
2022-01-14 15:28:58,197 iteration 1366 : loss : 0.046949, loss_ce: 0.022354
2022-01-14 15:28:59,643 iteration 1367 : loss : 0.033290, loss_ce: 0.014257
2022-01-14 15:29:01,134 iteration 1368 : loss : 0.058459, loss_ce: 0.028693
2022-01-14 15:29:02,598 iteration 1369 : loss : 0.064211, loss_ce: 0.017326
2022-01-14 15:29:04,084 iteration 1370 : loss : 0.062060, loss_ce: 0.018230
2022-01-14 15:29:05,503 iteration 1371 : loss : 0.031857, loss_ce: 0.013072
2022-01-14 15:29:07,002 iteration 1372 : loss : 0.074089, loss_ce: 0.022630
2022-01-14 15:29:08,581 iteration 1373 : loss : 0.066357, loss_ce: 0.036294
2022-01-14 15:29:10,052 iteration 1374 : loss : 0.055349, loss_ce: 0.017768
2022-01-14 15:29:11,591 iteration 1375 : loss : 0.035555, loss_ce: 0.012867
2022-01-14 15:29:12,999 iteration 1376 : loss : 0.036646, loss_ce: 0.014845
2022-01-14 15:29:14,519 iteration 1377 : loss : 0.069891, loss_ce: 0.025889
 20%|██████                        | 81/400 [37:07<2:28:15, 27.89s/it]2022-01-14 15:29:16,115 iteration 1378 : loss : 0.051500, loss_ce: 0.024028
2022-01-14 15:29:17,662 iteration 1379 : loss : 0.074826, loss_ce: 0.019165
2022-01-14 15:29:19,151 iteration 1380 : loss : 0.036494, loss_ce: 0.016576
2022-01-14 15:29:20,653 iteration 1381 : loss : 0.039390, loss_ce: 0.017016
2022-01-14 15:29:22,124 iteration 1382 : loss : 0.037203, loss_ce: 0.014283
2022-01-14 15:29:23,606 iteration 1383 : loss : 0.056720, loss_ce: 0.016529
2022-01-14 15:29:25,186 iteration 1384 : loss : 0.059685, loss_ce: 0.025640
2022-01-14 15:29:26,598 iteration 1385 : loss : 0.032177, loss_ce: 0.011565
2022-01-14 15:29:28,170 iteration 1386 : loss : 0.047274, loss_ce: 0.019838
2022-01-14 15:29:29,622 iteration 1387 : loss : 0.067116, loss_ce: 0.017631
2022-01-14 15:29:31,153 iteration 1388 : loss : 0.039553, loss_ce: 0.011116
2022-01-14 15:29:32,687 iteration 1389 : loss : 0.070600, loss_ce: 0.039035
2022-01-14 15:29:34,106 iteration 1390 : loss : 0.041245, loss_ce: 0.017476
2022-01-14 15:29:35,612 iteration 1391 : loss : 0.080978, loss_ce: 0.025793
2022-01-14 15:29:37,088 iteration 1392 : loss : 0.054021, loss_ce: 0.026719
2022-01-14 15:29:38,579 iteration 1393 : loss : 0.068771, loss_ce: 0.020438
2022-01-14 15:29:40,064 iteration 1394 : loss : 0.042186, loss_ce: 0.014105
 20%|██████▏                       | 82/400 [37:33<2:24:03, 27.18s/it]2022-01-14 15:29:41,636 iteration 1395 : loss : 0.041518, loss_ce: 0.019754
2022-01-14 15:29:43,052 iteration 1396 : loss : 0.047190, loss_ce: 0.020615
2022-01-14 15:29:44,585 iteration 1397 : loss : 0.050366, loss_ce: 0.018140
2022-01-14 15:29:45,990 iteration 1398 : loss : 0.031239, loss_ce: 0.013288
2022-01-14 15:29:47,493 iteration 1399 : loss : 0.046289, loss_ce: 0.020250
2022-01-14 15:29:49,041 iteration 1400 : loss : 0.069299, loss_ce: 0.028701
2022-01-14 15:29:50,499 iteration 1401 : loss : 0.038291, loss_ce: 0.011444
2022-01-14 15:29:52,050 iteration 1402 : loss : 0.046890, loss_ce: 0.015982
2022-01-14 15:29:53,549 iteration 1403 : loss : 0.052344, loss_ce: 0.015868
2022-01-14 15:29:55,114 iteration 1404 : loss : 0.049936, loss_ce: 0.020239
2022-01-14 15:29:56,448 iteration 1405 : loss : 0.037944, loss_ce: 0.014307
2022-01-14 15:29:57,955 iteration 1406 : loss : 0.055100, loss_ce: 0.020254
2022-01-14 15:29:59,409 iteration 1407 : loss : 0.056523, loss_ce: 0.026135
2022-01-14 15:30:00,837 iteration 1408 : loss : 0.051677, loss_ce: 0.026665
2022-01-14 15:30:02,398 iteration 1409 : loss : 0.065445, loss_ce: 0.023644
2022-01-14 15:30:03,835 iteration 1410 : loss : 0.045974, loss_ce: 0.017863
2022-01-14 15:30:05,241 iteration 1411 : loss : 0.033701, loss_ce: 0.013927
 21%|██████▏                       | 83/400 [37:58<2:20:25, 26.58s/it]2022-01-14 15:30:06,823 iteration 1412 : loss : 0.063414, loss_ce: 0.027629
2022-01-14 15:30:08,240 iteration 1413 : loss : 0.042435, loss_ce: 0.017262
2022-01-14 15:30:09,750 iteration 1414 : loss : 0.035563, loss_ce: 0.014758
2022-01-14 15:30:11,170 iteration 1415 : loss : 0.048006, loss_ce: 0.018167
2022-01-14 15:30:12,642 iteration 1416 : loss : 0.037308, loss_ce: 0.015282
2022-01-14 15:30:14,139 iteration 1417 : loss : 0.047379, loss_ce: 0.017348
2022-01-14 15:30:15,626 iteration 1418 : loss : 0.038378, loss_ce: 0.013170
2022-01-14 15:30:17,029 iteration 1419 : loss : 0.045316, loss_ce: 0.019944
2022-01-14 15:30:18,490 iteration 1420 : loss : 0.044766, loss_ce: 0.011216
2022-01-14 15:30:19,958 iteration 1421 : loss : 0.065798, loss_ce: 0.035458
2022-01-14 15:30:21,452 iteration 1422 : loss : 0.041794, loss_ce: 0.016902
2022-01-14 15:30:22,891 iteration 1423 : loss : 0.043178, loss_ce: 0.015183
2022-01-14 15:30:24,288 iteration 1424 : loss : 0.028350, loss_ce: 0.011411
2022-01-14 15:30:25,789 iteration 1425 : loss : 0.053845, loss_ce: 0.017584
2022-01-14 15:30:27,297 iteration 1426 : loss : 0.052003, loss_ce: 0.028564
2022-01-14 15:30:28,776 iteration 1427 : loss : 0.079543, loss_ce: 0.015002
2022-01-14 15:30:30,355 iteration 1428 : loss : 0.058709, loss_ce: 0.022193
 21%|██████▎                       | 84/400 [38:23<2:17:41, 26.14s/it]2022-01-14 15:30:31,913 iteration 1429 : loss : 0.059837, loss_ce: 0.035924
2022-01-14 15:30:33,380 iteration 1430 : loss : 0.033483, loss_ce: 0.012397
2022-01-14 15:30:34,806 iteration 1431 : loss : 0.077181, loss_ce: 0.024181
2022-01-14 15:30:36,291 iteration 1432 : loss : 0.042463, loss_ce: 0.017599
2022-01-14 15:30:37,703 iteration 1433 : loss : 0.034805, loss_ce: 0.016181
2022-01-14 15:30:39,270 iteration 1434 : loss : 0.043032, loss_ce: 0.017580
2022-01-14 15:30:40,791 iteration 1435 : loss : 0.046737, loss_ce: 0.017793
2022-01-14 15:30:42,330 iteration 1436 : loss : 0.048526, loss_ce: 0.024584
2022-01-14 15:30:43,815 iteration 1437 : loss : 0.045913, loss_ce: 0.018264
2022-01-14 15:30:45,285 iteration 1438 : loss : 0.046513, loss_ce: 0.017846
2022-01-14 15:30:46,783 iteration 1439 : loss : 0.110815, loss_ce: 0.032890
2022-01-14 15:30:48,212 iteration 1440 : loss : 0.039375, loss_ce: 0.012164
2022-01-14 15:30:49,709 iteration 1441 : loss : 0.042524, loss_ce: 0.017260
2022-01-14 15:30:51,212 iteration 1442 : loss : 0.052027, loss_ce: 0.015617
2022-01-14 15:30:52,757 iteration 1443 : loss : 0.043433, loss_ce: 0.015649
2022-01-14 15:30:54,230 iteration 1444 : loss : 0.037918, loss_ce: 0.008888
2022-01-14 15:30:54,231 Training Data Eval:
2022-01-14 15:31:01,595   Average segmentation loss on training set: 0.0343
2022-01-14 15:31:01,596 Validation Data Eval:
2022-01-14 15:31:04,132   Average segmentation loss on validation set: 0.0944
2022-01-14 15:31:09,892 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed2.pth
2022-01-14 15:31:11,299 iteration 1445 : loss : 0.058399, loss_ce: 0.027116
 21%|██████▍                       | 85/400 [39:04<2:40:33, 30.58s/it]2022-01-14 15:31:12,631 iteration 1446 : loss : 0.039717, loss_ce: 0.014160
2022-01-14 15:31:13,916 iteration 1447 : loss : 0.039590, loss_ce: 0.018249
2022-01-14 15:31:15,365 iteration 1448 : loss : 0.034890, loss_ce: 0.009621
2022-01-14 15:31:16,887 iteration 1449 : loss : 0.046450, loss_ce: 0.015154
2022-01-14 15:31:18,345 iteration 1450 : loss : 0.043196, loss_ce: 0.017671
2022-01-14 15:31:19,847 iteration 1451 : loss : 0.033742, loss_ce: 0.009287
2022-01-14 15:31:21,316 iteration 1452 : loss : 0.052299, loss_ce: 0.032038
2022-01-14 15:31:22,822 iteration 1453 : loss : 0.038243, loss_ce: 0.016581
2022-01-14 15:31:24,306 iteration 1454 : loss : 0.043681, loss_ce: 0.012691
2022-01-14 15:31:25,810 iteration 1455 : loss : 0.039949, loss_ce: 0.013614
2022-01-14 15:31:27,251 iteration 1456 : loss : 0.042741, loss_ce: 0.012961
2022-01-14 15:31:28,786 iteration 1457 : loss : 0.045490, loss_ce: 0.017876
2022-01-14 15:31:30,293 iteration 1458 : loss : 0.031359, loss_ce: 0.012709
2022-01-14 15:31:31,749 iteration 1459 : loss : 0.041396, loss_ce: 0.016104
2022-01-14 15:31:33,213 iteration 1460 : loss : 0.036459, loss_ce: 0.013282
2022-01-14 15:31:34,636 iteration 1461 : loss : 0.050205, loss_ce: 0.018537
2022-01-14 15:31:36,177 iteration 1462 : loss : 0.054691, loss_ce: 0.025596
 22%|██████▍                       | 86/400 [39:29<2:31:06, 28.87s/it]2022-01-14 15:31:37,817 iteration 1463 : loss : 0.081300, loss_ce: 0.026293
2022-01-14 15:31:39,258 iteration 1464 : loss : 0.035009, loss_ce: 0.016153
2022-01-14 15:31:40,859 iteration 1465 : loss : 0.046550, loss_ce: 0.014345
2022-01-14 15:31:42,373 iteration 1466 : loss : 0.031449, loss_ce: 0.011825
2022-01-14 15:31:43,817 iteration 1467 : loss : 0.069106, loss_ce: 0.028730
2022-01-14 15:31:45,304 iteration 1468 : loss : 0.040542, loss_ce: 0.017968
2022-01-14 15:31:46,778 iteration 1469 : loss : 0.058633, loss_ce: 0.025379
2022-01-14 15:31:48,203 iteration 1470 : loss : 0.066263, loss_ce: 0.013339
2022-01-14 15:31:49,682 iteration 1471 : loss : 0.033648, loss_ce: 0.014636
2022-01-14 15:31:51,204 iteration 1472 : loss : 0.066088, loss_ce: 0.024028
2022-01-14 15:31:52,642 iteration 1473 : loss : 0.035287, loss_ce: 0.017329
2022-01-14 15:31:54,158 iteration 1474 : loss : 0.081623, loss_ce: 0.028798
2022-01-14 15:31:55,609 iteration 1475 : loss : 0.047170, loss_ce: 0.020069
2022-01-14 15:31:57,061 iteration 1476 : loss : 0.036687, loss_ce: 0.014618
2022-01-14 15:31:58,614 iteration 1477 : loss : 0.040039, loss_ce: 0.018528
2022-01-14 15:32:00,057 iteration 1478 : loss : 0.057895, loss_ce: 0.019444
2022-01-14 15:32:01,536 iteration 1479 : loss : 0.053012, loss_ce: 0.015399
 22%|██████▌                       | 87/400 [39:54<2:25:07, 27.82s/it]2022-01-14 15:32:02,935 iteration 1480 : loss : 0.030767, loss_ce: 0.010623
2022-01-14 15:32:04,512 iteration 1481 : loss : 0.051658, loss_ce: 0.023895
2022-01-14 15:32:05,982 iteration 1482 : loss : 0.042387, loss_ce: 0.020565
2022-01-14 15:32:07,518 iteration 1483 : loss : 0.046723, loss_ce: 0.018901
2022-01-14 15:32:09,031 iteration 1484 : loss : 0.044216, loss_ce: 0.013001
2022-01-14 15:32:10,554 iteration 1485 : loss : 0.038505, loss_ce: 0.018339
2022-01-14 15:32:12,024 iteration 1486 : loss : 0.055987, loss_ce: 0.016768
2022-01-14 15:32:13,496 iteration 1487 : loss : 0.030976, loss_ce: 0.012179
2022-01-14 15:32:14,914 iteration 1488 : loss : 0.037518, loss_ce: 0.016279
2022-01-14 15:32:16,360 iteration 1489 : loss : 0.046898, loss_ce: 0.019182
2022-01-14 15:32:17,900 iteration 1490 : loss : 0.048703, loss_ce: 0.017739
2022-01-14 15:32:19,312 iteration 1491 : loss : 0.057982, loss_ce: 0.019118
2022-01-14 15:32:20,757 iteration 1492 : loss : 0.054733, loss_ce: 0.024046
2022-01-14 15:32:22,302 iteration 1493 : loss : 0.048390, loss_ce: 0.020385
2022-01-14 15:32:23,769 iteration 1494 : loss : 0.045499, loss_ce: 0.014933
2022-01-14 15:32:25,178 iteration 1495 : loss : 0.036381, loss_ce: 0.010554
2022-01-14 15:32:26,694 iteration 1496 : loss : 0.051504, loss_ce: 0.023239
 22%|██████▌                       | 88/400 [40:19<2:20:29, 27.02s/it]2022-01-14 15:32:28,136 iteration 1497 : loss : 0.040153, loss_ce: 0.016256
2022-01-14 15:32:29,642 iteration 1498 : loss : 0.066304, loss_ce: 0.026908
2022-01-14 15:32:31,051 iteration 1499 : loss : 0.054212, loss_ce: 0.020028
2022-01-14 15:32:32,529 iteration 1500 : loss : 0.040107, loss_ce: 0.017902
2022-01-14 15:32:33,983 iteration 1501 : loss : 0.043228, loss_ce: 0.017609
2022-01-14 15:32:35,534 iteration 1502 : loss : 0.094380, loss_ce: 0.023533
2022-01-14 15:32:37,130 iteration 1503 : loss : 0.082056, loss_ce: 0.021553
2022-01-14 15:32:38,588 iteration 1504 : loss : 0.044112, loss_ce: 0.017252
2022-01-14 15:32:40,095 iteration 1505 : loss : 0.042626, loss_ce: 0.017732
2022-01-14 15:32:41,595 iteration 1506 : loss : 0.039781, loss_ce: 0.016541
2022-01-14 15:32:43,098 iteration 1507 : loss : 0.051020, loss_ce: 0.013074
2022-01-14 15:32:44,603 iteration 1508 : loss : 0.058374, loss_ce: 0.035021
2022-01-14 15:32:46,087 iteration 1509 : loss : 0.041247, loss_ce: 0.014436
2022-01-14 15:32:47,646 iteration 1510 : loss : 0.058000, loss_ce: 0.018135
2022-01-14 15:32:49,192 iteration 1511 : loss : 0.047629, loss_ce: 0.018313
2022-01-14 15:32:50,683 iteration 1512 : loss : 0.053518, loss_ce: 0.015330
2022-01-14 15:32:52,174 iteration 1513 : loss : 0.049209, loss_ce: 0.019726
 22%|██████▋                       | 89/400 [40:45<2:17:39, 26.56s/it]2022-01-14 15:32:53,739 iteration 1514 : loss : 0.030363, loss_ce: 0.010632
2022-01-14 15:32:55,167 iteration 1515 : loss : 0.030065, loss_ce: 0.011338
2022-01-14 15:32:56,649 iteration 1516 : loss : 0.047685, loss_ce: 0.017930
2022-01-14 15:32:58,048 iteration 1517 : loss : 0.036798, loss_ce: 0.013212
2022-01-14 15:32:59,553 iteration 1518 : loss : 0.041636, loss_ce: 0.015351
2022-01-14 15:33:01,097 iteration 1519 : loss : 0.053498, loss_ce: 0.020802
2022-01-14 15:33:02,623 iteration 1520 : loss : 0.052933, loss_ce: 0.020751
2022-01-14 15:33:04,114 iteration 1521 : loss : 0.090806, loss_ce: 0.027420
2022-01-14 15:33:05,558 iteration 1522 : loss : 0.035012, loss_ce: 0.012533
2022-01-14 15:33:07,005 iteration 1523 : loss : 0.038935, loss_ce: 0.012228
2022-01-14 15:33:08,488 iteration 1524 : loss : 0.042046, loss_ce: 0.015715
2022-01-14 15:33:09,895 iteration 1525 : loss : 0.052962, loss_ce: 0.022605
2022-01-14 15:33:11,395 iteration 1526 : loss : 0.068035, loss_ce: 0.035859
2022-01-14 15:33:12,909 iteration 1527 : loss : 0.042243, loss_ce: 0.020532
2022-01-14 15:33:14,342 iteration 1528 : loss : 0.049753, loss_ce: 0.022399
2022-01-14 15:33:15,768 iteration 1529 : loss : 0.041495, loss_ce: 0.015721
2022-01-14 15:33:15,768 Training Data Eval:
2022-01-14 15:33:23,103   Average segmentation loss on training set: 0.0450
2022-01-14 15:33:23,104 Validation Data Eval:
2022-01-14 15:33:25,643   Average segmentation loss on validation set: 0.0737
2022-01-14 15:33:31,410 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed2.pth
2022-01-14 15:33:32,836 iteration 1530 : loss : 0.057605, loss_ce: 0.023539
 22%|██████▊                       | 90/400 [41:26<2:39:05, 30.79s/it]2022-01-14 15:33:34,281 iteration 1531 : loss : 0.040877, loss_ce: 0.015874
2022-01-14 15:33:35,653 iteration 1532 : loss : 0.057505, loss_ce: 0.020659
2022-01-14 15:33:37,055 iteration 1533 : loss : 0.031580, loss_ce: 0.011045
2022-01-14 15:33:38,521 iteration 1534 : loss : 0.041260, loss_ce: 0.019218
2022-01-14 15:33:40,058 iteration 1535 : loss : 0.039040, loss_ce: 0.014429
2022-01-14 15:33:41,590 iteration 1536 : loss : 0.052131, loss_ce: 0.027539
2022-01-14 15:33:43,062 iteration 1537 : loss : 0.038088, loss_ce: 0.013572
2022-01-14 15:33:44,580 iteration 1538 : loss : 0.044177, loss_ce: 0.017934
2022-01-14 15:33:46,064 iteration 1539 : loss : 0.045931, loss_ce: 0.021177
2022-01-14 15:33:47,537 iteration 1540 : loss : 0.059248, loss_ce: 0.024851
2022-01-14 15:33:48,983 iteration 1541 : loss : 0.029058, loss_ce: 0.013580
2022-01-14 15:33:50,409 iteration 1542 : loss : 0.030427, loss_ce: 0.012748
2022-01-14 15:33:51,862 iteration 1543 : loss : 0.056122, loss_ce: 0.017308
2022-01-14 15:33:53,271 iteration 1544 : loss : 0.031606, loss_ce: 0.012597
2022-01-14 15:33:54,855 iteration 1545 : loss : 0.050810, loss_ce: 0.019505
2022-01-14 15:33:56,282 iteration 1546 : loss : 0.063963, loss_ce: 0.015645
2022-01-14 15:33:57,845 iteration 1547 : loss : 0.039486, loss_ce: 0.018650
 23%|██████▊                       | 91/400 [41:51<2:29:38, 29.06s/it]2022-01-14 15:33:59,391 iteration 1548 : loss : 0.046199, loss_ce: 0.018954
2022-01-14 15:34:00,783 iteration 1549 : loss : 0.032585, loss_ce: 0.013136
2022-01-14 15:34:02,220 iteration 1550 : loss : 0.048532, loss_ce: 0.017855
2022-01-14 15:34:03,585 iteration 1551 : loss : 0.034435, loss_ce: 0.011934
2022-01-14 15:34:05,077 iteration 1552 : loss : 0.039170, loss_ce: 0.012413
2022-01-14 15:34:06,603 iteration 1553 : loss : 0.057485, loss_ce: 0.022417
2022-01-14 15:34:08,104 iteration 1554 : loss : 0.039789, loss_ce: 0.014881
2022-01-14 15:34:09,562 iteration 1555 : loss : 0.050810, loss_ce: 0.019196
2022-01-14 15:34:11,065 iteration 1556 : loss : 0.037110, loss_ce: 0.011170
2022-01-14 15:34:12,513 iteration 1557 : loss : 0.051096, loss_ce: 0.021273
2022-01-14 15:34:13,987 iteration 1558 : loss : 0.044424, loss_ce: 0.021203
2022-01-14 15:34:15,472 iteration 1559 : loss : 0.049221, loss_ce: 0.015728
2022-01-14 15:34:16,895 iteration 1560 : loss : 0.031950, loss_ce: 0.014988
2022-01-14 15:34:18,396 iteration 1561 : loss : 0.055287, loss_ce: 0.020613
2022-01-14 15:34:19,825 iteration 1562 : loss : 0.076452, loss_ce: 0.025817
2022-01-14 15:34:21,346 iteration 1563 : loss : 0.037101, loss_ce: 0.015051
2022-01-14 15:34:22,861 iteration 1564 : loss : 0.041572, loss_ce: 0.019136
 23%|██████▉                       | 92/400 [42:16<2:22:55, 27.84s/it]2022-01-14 15:34:24,354 iteration 1565 : loss : 0.050273, loss_ce: 0.026326
2022-01-14 15:34:25,825 iteration 1566 : loss : 0.034343, loss_ce: 0.012627
2022-01-14 15:34:27,341 iteration 1567 : loss : 0.054727, loss_ce: 0.016975
2022-01-14 15:34:28,787 iteration 1568 : loss : 0.053810, loss_ce: 0.016508
2022-01-14 15:34:30,283 iteration 1569 : loss : 0.039658, loss_ce: 0.017850
2022-01-14 15:34:31,764 iteration 1570 : loss : 0.032344, loss_ce: 0.014861
2022-01-14 15:34:33,206 iteration 1571 : loss : 0.075381, loss_ce: 0.015260
2022-01-14 15:34:34,741 iteration 1572 : loss : 0.041883, loss_ce: 0.015286
2022-01-14 15:34:36,236 iteration 1573 : loss : 0.043257, loss_ce: 0.021699
2022-01-14 15:34:37,666 iteration 1574 : loss : 0.025960, loss_ce: 0.011586
2022-01-14 15:34:39,046 iteration 1575 : loss : 0.041122, loss_ce: 0.018256
2022-01-14 15:34:40,502 iteration 1576 : loss : 0.036042, loss_ce: 0.017488
2022-01-14 15:34:41,964 iteration 1577 : loss : 0.031296, loss_ce: 0.012772
2022-01-14 15:34:43,436 iteration 1578 : loss : 0.060126, loss_ce: 0.019904
2022-01-14 15:34:44,944 iteration 1579 : loss : 0.026501, loss_ce: 0.010008
2022-01-14 15:34:46,377 iteration 1580 : loss : 0.042828, loss_ce: 0.016265
2022-01-14 15:34:47,863 iteration 1581 : loss : 0.042995, loss_ce: 0.015307
 23%|██████▉                       | 93/400 [42:41<2:18:05, 26.99s/it]2022-01-14 15:34:49,455 iteration 1582 : loss : 0.041860, loss_ce: 0.013250
2022-01-14 15:34:50,920 iteration 1583 : loss : 0.057908, loss_ce: 0.015357
2022-01-14 15:34:52,418 iteration 1584 : loss : 0.032538, loss_ce: 0.017672
2022-01-14 15:34:53,889 iteration 1585 : loss : 0.033693, loss_ce: 0.010854
2022-01-14 15:34:55,345 iteration 1586 : loss : 0.038204, loss_ce: 0.016834
2022-01-14 15:34:56,721 iteration 1587 : loss : 0.028094, loss_ce: 0.011374
2022-01-14 15:34:58,218 iteration 1588 : loss : 0.040381, loss_ce: 0.018440
2022-01-14 15:34:59,695 iteration 1589 : loss : 0.033987, loss_ce: 0.014630
2022-01-14 15:35:01,296 iteration 1590 : loss : 0.066722, loss_ce: 0.022946
2022-01-14 15:35:02,728 iteration 1591 : loss : 0.031806, loss_ce: 0.009693
2022-01-14 15:35:04,201 iteration 1592 : loss : 0.041591, loss_ce: 0.014193
2022-01-14 15:35:05,770 iteration 1593 : loss : 0.047829, loss_ce: 0.017944
2022-01-14 15:35:07,327 iteration 1594 : loss : 0.056968, loss_ce: 0.018649
2022-01-14 15:35:08,794 iteration 1595 : loss : 0.025461, loss_ce: 0.008858
2022-01-14 15:35:10,278 iteration 1596 : loss : 0.037952, loss_ce: 0.016512
2022-01-14 15:35:11,750 iteration 1597 : loss : 0.056350, loss_ce: 0.024597
2022-01-14 15:35:13,246 iteration 1598 : loss : 0.032486, loss_ce: 0.011172
 24%|███████                       | 94/400 [43:06<2:15:12, 26.51s/it]2022-01-14 15:35:14,740 iteration 1599 : loss : 0.028255, loss_ce: 0.011205
2022-01-14 15:35:16,218 iteration 1600 : loss : 0.043003, loss_ce: 0.015094
2022-01-14 15:35:17,760 iteration 1601 : loss : 0.036966, loss_ce: 0.013759
2022-01-14 15:35:19,367 iteration 1602 : loss : 0.044129, loss_ce: 0.019107
2022-01-14 15:35:20,842 iteration 1603 : loss : 0.035599, loss_ce: 0.015362
2022-01-14 15:35:22,286 iteration 1604 : loss : 0.035847, loss_ce: 0.014729
2022-01-14 15:35:23,802 iteration 1605 : loss : 0.044226, loss_ce: 0.015216
2022-01-14 15:35:25,263 iteration 1606 : loss : 0.034122, loss_ce: 0.014918
2022-01-14 15:35:26,711 iteration 1607 : loss : 0.031324, loss_ce: 0.012611
2022-01-14 15:35:28,266 iteration 1608 : loss : 0.041084, loss_ce: 0.013834
2022-01-14 15:35:29,738 iteration 1609 : loss : 0.064650, loss_ce: 0.031196
2022-01-14 15:35:31,226 iteration 1610 : loss : 0.029966, loss_ce: 0.010904
2022-01-14 15:35:32,841 iteration 1611 : loss : 0.054130, loss_ce: 0.020390
2022-01-14 15:35:34,317 iteration 1612 : loss : 0.040962, loss_ce: 0.017008
2022-01-14 15:35:35,658 iteration 1613 : loss : 0.046137, loss_ce: 0.021085
2022-01-14 15:35:37,161 iteration 1614 : loss : 0.044314, loss_ce: 0.015965
2022-01-14 15:35:37,161 Training Data Eval:
2022-01-14 15:35:44,529   Average segmentation loss on training set: 0.0289
2022-01-14 15:35:44,530 Validation Data Eval:
2022-01-14 15:35:47,081   Average segmentation loss on validation set: 0.0938
2022-01-14 15:35:48,576 iteration 1615 : loss : 0.029588, loss_ce: 0.011294
 24%|███████▏                      | 95/400 [43:41<2:28:12, 29.15s/it]2022-01-14 15:35:50,135 iteration 1616 : loss : 0.038508, loss_ce: 0.013516
2022-01-14 15:35:51,634 iteration 1617 : loss : 0.056001, loss_ce: 0.017024
2022-01-14 15:35:53,039 iteration 1618 : loss : 0.026933, loss_ce: 0.012222
2022-01-14 15:35:54,450 iteration 1619 : loss : 0.024570, loss_ce: 0.008253
2022-01-14 15:35:55,834 iteration 1620 : loss : 0.035262, loss_ce: 0.011047
2022-01-14 15:35:57,314 iteration 1621 : loss : 0.055777, loss_ce: 0.035890
2022-01-14 15:35:58,920 iteration 1622 : loss : 0.048484, loss_ce: 0.014729
2022-01-14 15:36:00,395 iteration 1623 : loss : 0.045139, loss_ce: 0.017050
2022-01-14 15:36:01,833 iteration 1624 : loss : 0.033354, loss_ce: 0.012673
2022-01-14 15:36:03,291 iteration 1625 : loss : 0.030948, loss_ce: 0.011869
2022-01-14 15:36:04,740 iteration 1626 : loss : 0.029125, loss_ce: 0.012959
2022-01-14 15:36:06,202 iteration 1627 : loss : 0.037740, loss_ce: 0.013534
2022-01-14 15:36:07,752 iteration 1628 : loss : 0.036573, loss_ce: 0.015327
2022-01-14 15:36:09,214 iteration 1629 : loss : 0.030427, loss_ce: 0.011196
2022-01-14 15:36:10,632 iteration 1630 : loss : 0.040155, loss_ce: 0.015034
2022-01-14 15:36:12,224 iteration 1631 : loss : 0.047584, loss_ce: 0.020272
2022-01-14 15:36:13,780 iteration 1632 : loss : 0.051011, loss_ce: 0.017887
 24%|███████▏                      | 96/400 [44:07<2:21:42, 27.97s/it]2022-01-14 15:36:15,388 iteration 1633 : loss : 0.032703, loss_ce: 0.012329
2022-01-14 15:36:16,900 iteration 1634 : loss : 0.052788, loss_ce: 0.016517
2022-01-14 15:36:18,378 iteration 1635 : loss : 0.026749, loss_ce: 0.012318
2022-01-14 15:36:19,936 iteration 1636 : loss : 0.047962, loss_ce: 0.023759
2022-01-14 15:36:21,432 iteration 1637 : loss : 0.036535, loss_ce: 0.014134
2022-01-14 15:36:22,885 iteration 1638 : loss : 0.037523, loss_ce: 0.015558
2022-01-14 15:36:24,460 iteration 1639 : loss : 0.054978, loss_ce: 0.013106
2022-01-14 15:36:25,972 iteration 1640 : loss : 0.046794, loss_ce: 0.011266
2022-01-14 15:36:27,381 iteration 1641 : loss : 0.027355, loss_ce: 0.011677
2022-01-14 15:36:28,841 iteration 1642 : loss : 0.026474, loss_ce: 0.009197
2022-01-14 15:36:30,348 iteration 1643 : loss : 0.027602, loss_ce: 0.007403
2022-01-14 15:36:31,801 iteration 1644 : loss : 0.038958, loss_ce: 0.014144
2022-01-14 15:36:33,263 iteration 1645 : loss : 0.032893, loss_ce: 0.010975
2022-01-14 15:36:34,729 iteration 1646 : loss : 0.032420, loss_ce: 0.015052
2022-01-14 15:36:36,177 iteration 1647 : loss : 0.046660, loss_ce: 0.016234
2022-01-14 15:36:37,661 iteration 1648 : loss : 0.057407, loss_ce: 0.024811
2022-01-14 15:36:39,081 iteration 1649 : loss : 0.041278, loss_ce: 0.017176
 24%|███████▎                      | 97/400 [44:32<2:17:11, 27.17s/it]2022-01-14 15:36:40,627 iteration 1650 : loss : 0.056018, loss_ce: 0.029979
2022-01-14 15:36:42,227 iteration 1651 : loss : 0.060785, loss_ce: 0.022031
2022-01-14 15:36:43,651 iteration 1652 : loss : 0.054036, loss_ce: 0.018539
2022-01-14 15:36:45,075 iteration 1653 : loss : 0.030975, loss_ce: 0.009970
2022-01-14 15:36:46,586 iteration 1654 : loss : 0.064944, loss_ce: 0.015919
2022-01-14 15:36:48,119 iteration 1655 : loss : 0.044917, loss_ce: 0.017911
2022-01-14 15:36:49,584 iteration 1656 : loss : 0.035428, loss_ce: 0.013241
2022-01-14 15:36:51,172 iteration 1657 : loss : 0.044609, loss_ce: 0.013571
2022-01-14 15:36:52,699 iteration 1658 : loss : 0.064246, loss_ce: 0.037939
2022-01-14 15:36:54,127 iteration 1659 : loss : 0.028448, loss_ce: 0.009928
2022-01-14 15:36:55,715 iteration 1660 : loss : 0.050242, loss_ce: 0.017682
2022-01-14 15:36:57,278 iteration 1661 : loss : 0.038976, loss_ce: 0.011151
2022-01-14 15:36:58,765 iteration 1662 : loss : 0.048823, loss_ce: 0.020298
2022-01-14 15:37:00,143 iteration 1663 : loss : 0.027777, loss_ce: 0.014479
2022-01-14 15:37:01,745 iteration 1664 : loss : 0.048342, loss_ce: 0.017425
2022-01-14 15:37:03,303 iteration 1665 : loss : 0.035852, loss_ce: 0.012323
2022-01-14 15:37:04,904 iteration 1666 : loss : 0.037929, loss_ce: 0.015673
 24%|███████▎                      | 98/400 [44:58<2:14:43, 26.77s/it]2022-01-14 15:37:06,469 iteration 1667 : loss : 0.036801, loss_ce: 0.012340
2022-01-14 15:37:07,961 iteration 1668 : loss : 0.063059, loss_ce: 0.019078
2022-01-14 15:37:09,400 iteration 1669 : loss : 0.031802, loss_ce: 0.012340
2022-01-14 15:37:10,898 iteration 1670 : loss : 0.051970, loss_ce: 0.022798
2022-01-14 15:37:12,371 iteration 1671 : loss : 0.031964, loss_ce: 0.011903
2022-01-14 15:37:13,913 iteration 1672 : loss : 0.031241, loss_ce: 0.010515
2022-01-14 15:37:15,422 iteration 1673 : loss : 0.041205, loss_ce: 0.016830
2022-01-14 15:37:16,974 iteration 1674 : loss : 0.051438, loss_ce: 0.024500
2022-01-14 15:37:18,427 iteration 1675 : loss : 0.034586, loss_ce: 0.009490
2022-01-14 15:37:19,893 iteration 1676 : loss : 0.050562, loss_ce: 0.020093
2022-01-14 15:37:21,448 iteration 1677 : loss : 0.055521, loss_ce: 0.026390
2022-01-14 15:37:22,817 iteration 1678 : loss : 0.041399, loss_ce: 0.016991
2022-01-14 15:37:24,262 iteration 1679 : loss : 0.042588, loss_ce: 0.011957
2022-01-14 15:37:25,774 iteration 1680 : loss : 0.031653, loss_ce: 0.014496
2022-01-14 15:37:27,285 iteration 1681 : loss : 0.051947, loss_ce: 0.027745
2022-01-14 15:37:28,797 iteration 1682 : loss : 0.035981, loss_ce: 0.012465
2022-01-14 15:37:30,220 iteration 1683 : loss : 0.029329, loss_ce: 0.009095
 25%|███████▍                      | 99/400 [45:23<2:12:05, 26.33s/it]2022-01-14 15:37:31,771 iteration 1684 : loss : 0.036429, loss_ce: 0.011157
2022-01-14 15:37:33,252 iteration 1685 : loss : 0.038551, loss_ce: 0.012262
2022-01-14 15:37:34,716 iteration 1686 : loss : 0.028677, loss_ce: 0.010346
2022-01-14 15:37:36,131 iteration 1687 : loss : 0.036712, loss_ce: 0.016590
2022-01-14 15:37:37,731 iteration 1688 : loss : 0.032625, loss_ce: 0.013185
2022-01-14 15:37:39,231 iteration 1689 : loss : 0.067683, loss_ce: 0.024794
2022-01-14 15:37:40,758 iteration 1690 : loss : 0.038596, loss_ce: 0.016466
2022-01-14 15:37:42,167 iteration 1691 : loss : 0.104813, loss_ce: 0.028320
2022-01-14 15:37:43,692 iteration 1692 : loss : 0.072223, loss_ce: 0.023328
2022-01-14 15:37:45,047 iteration 1693 : loss : 0.030505, loss_ce: 0.011775
2022-01-14 15:37:46,551 iteration 1694 : loss : 0.027354, loss_ce: 0.010119
2022-01-14 15:37:48,092 iteration 1695 : loss : 0.048266, loss_ce: 0.019386
2022-01-14 15:37:49,640 iteration 1696 : loss : 0.053388, loss_ce: 0.020141
2022-01-14 15:37:51,111 iteration 1697 : loss : 0.040323, loss_ce: 0.013490
2022-01-14 15:37:52,638 iteration 1698 : loss : 0.041392, loss_ce: 0.014283
2022-01-14 15:37:54,124 iteration 1699 : loss : 0.035849, loss_ce: 0.018625
2022-01-14 15:37:54,124 Training Data Eval:
2022-01-14 15:38:01,476   Average segmentation loss on training set: 0.0340
2022-01-14 15:38:01,477 Validation Data Eval:
2022-01-14 15:38:04,012   Average segmentation loss on validation set: 0.1385
2022-01-14 15:38:05,460 iteration 1700 : loss : 0.043917, loss_ce: 0.015770
 25%|███████▎                     | 100/400 [45:58<2:25:01, 29.00s/it]2022-01-14 15:38:06,989 iteration 1701 : loss : 0.029273, loss_ce: 0.012357
2022-01-14 15:38:08,441 iteration 1702 : loss : 0.036880, loss_ce: 0.016763
2022-01-14 15:38:09,992 iteration 1703 : loss : 0.038652, loss_ce: 0.017217
2022-01-14 15:38:11,521 iteration 1704 : loss : 0.044127, loss_ce: 0.019434
2022-01-14 15:38:12,993 iteration 1705 : loss : 0.034922, loss_ce: 0.012116
2022-01-14 15:38:14,513 iteration 1706 : loss : 0.043340, loss_ce: 0.012026
2022-01-14 15:38:15,971 iteration 1707 : loss : 0.058079, loss_ce: 0.024069
2022-01-14 15:38:17,437 iteration 1708 : loss : 0.035460, loss_ce: 0.013346
2022-01-14 15:38:19,069 iteration 1709 : loss : 0.053018, loss_ce: 0.021489
2022-01-14 15:38:20,513 iteration 1710 : loss : 0.034963, loss_ce: 0.016735
2022-01-14 15:38:22,015 iteration 1711 : loss : 0.037116, loss_ce: 0.012382
2022-01-14 15:38:23,509 iteration 1712 : loss : 0.046562, loss_ce: 0.015050
2022-01-14 15:38:24,995 iteration 1713 : loss : 0.050078, loss_ce: 0.016338
2022-01-14 15:38:26,455 iteration 1714 : loss : 0.035998, loss_ce: 0.015319
2022-01-14 15:38:28,001 iteration 1715 : loss : 0.051557, loss_ce: 0.021858
2022-01-14 15:38:29,467 iteration 1716 : loss : 0.048084, loss_ce: 0.014066
2022-01-14 15:38:30,969 iteration 1717 : loss : 0.040588, loss_ce: 0.017523
 25%|███████▎                     | 101/400 [46:24<2:19:18, 27.96s/it]2022-01-14 15:38:32,539 iteration 1718 : loss : 0.040068, loss_ce: 0.013230
2022-01-14 15:38:34,099 iteration 1719 : loss : 0.036309, loss_ce: 0.009306
2022-01-14 15:38:35,625 iteration 1720 : loss : 0.067815, loss_ce: 0.023043
2022-01-14 15:38:37,127 iteration 1721 : loss : 0.040052, loss_ce: 0.017260
2022-01-14 15:38:38,567 iteration 1722 : loss : 0.026422, loss_ce: 0.010141
2022-01-14 15:38:40,023 iteration 1723 : loss : 0.028897, loss_ce: 0.012288
2022-01-14 15:38:41,428 iteration 1724 : loss : 0.031591, loss_ce: 0.014115
2022-01-14 15:38:42,849 iteration 1725 : loss : 0.037975, loss_ce: 0.019503
2022-01-14 15:38:44,435 iteration 1726 : loss : 0.037585, loss_ce: 0.012983
2022-01-14 15:38:45,961 iteration 1727 : loss : 0.039215, loss_ce: 0.013443
2022-01-14 15:38:47,537 iteration 1728 : loss : 0.050934, loss_ce: 0.023652
2022-01-14 15:38:48,987 iteration 1729 : loss : 0.032159, loss_ce: 0.012271
2022-01-14 15:38:50,484 iteration 1730 : loss : 0.037694, loss_ce: 0.013368
2022-01-14 15:38:51,923 iteration 1731 : loss : 0.038195, loss_ce: 0.017175
2022-01-14 15:38:53,415 iteration 1732 : loss : 0.033460, loss_ce: 0.015083
2022-01-14 15:38:54,902 iteration 1733 : loss : 0.036082, loss_ce: 0.011472
2022-01-14 15:38:56,362 iteration 1734 : loss : 0.050221, loss_ce: 0.013180
 26%|███████▍                     | 102/400 [46:49<2:15:00, 27.18s/it]2022-01-14 15:38:57,950 iteration 1735 : loss : 0.030682, loss_ce: 0.009201
2022-01-14 15:38:59,434 iteration 1736 : loss : 0.037063, loss_ce: 0.014378
2022-01-14 15:39:00,940 iteration 1737 : loss : 0.066170, loss_ce: 0.026574
2022-01-14 15:39:02,414 iteration 1738 : loss : 0.039412, loss_ce: 0.016809
2022-01-14 15:39:03,880 iteration 1739 : loss : 0.041049, loss_ce: 0.021245
2022-01-14 15:39:05,340 iteration 1740 : loss : 0.039736, loss_ce: 0.011119
2022-01-14 15:39:06,904 iteration 1741 : loss : 0.033982, loss_ce: 0.011117
2022-01-14 15:39:08,395 iteration 1742 : loss : 0.044256, loss_ce: 0.016468
2022-01-14 15:39:09,876 iteration 1743 : loss : 0.051669, loss_ce: 0.030871
2022-01-14 15:39:11,303 iteration 1744 : loss : 0.039858, loss_ce: 0.015831
2022-01-14 15:39:12,845 iteration 1745 : loss : 0.056215, loss_ce: 0.024765
2022-01-14 15:39:14,301 iteration 1746 : loss : 0.065031, loss_ce: 0.020671
2022-01-14 15:39:15,764 iteration 1747 : loss : 0.039193, loss_ce: 0.015288
2022-01-14 15:39:17,193 iteration 1748 : loss : 0.036564, loss_ce: 0.017911
2022-01-14 15:39:18,696 iteration 1749 : loss : 0.038132, loss_ce: 0.014502
2022-01-14 15:39:20,134 iteration 1750 : loss : 0.031754, loss_ce: 0.016404
2022-01-14 15:39:21,571 iteration 1751 : loss : 0.037646, loss_ce: 0.014039
 26%|███████▍                     | 103/400 [47:14<2:11:37, 26.59s/it]2022-01-14 15:39:23,086 iteration 1752 : loss : 0.034847, loss_ce: 0.014076
2022-01-14 15:39:24,645 iteration 1753 : loss : 0.049127, loss_ce: 0.021181
2022-01-14 15:39:26,153 iteration 1754 : loss : 0.032773, loss_ce: 0.014066
2022-01-14 15:39:27,658 iteration 1755 : loss : 0.056805, loss_ce: 0.020859
2022-01-14 15:39:29,193 iteration 1756 : loss : 0.051438, loss_ce: 0.022317
2022-01-14 15:39:30,716 iteration 1757 : loss : 0.040675, loss_ce: 0.011891
2022-01-14 15:39:32,222 iteration 1758 : loss : 0.041572, loss_ce: 0.015074
2022-01-14 15:39:33,692 iteration 1759 : loss : 0.036643, loss_ce: 0.011394
2022-01-14 15:39:35,227 iteration 1760 : loss : 0.042897, loss_ce: 0.020289
2022-01-14 15:39:36,653 iteration 1761 : loss : 0.034800, loss_ce: 0.015474
2022-01-14 15:39:38,194 iteration 1762 : loss : 0.042735, loss_ce: 0.017331
2022-01-14 15:39:39,639 iteration 1763 : loss : 0.043622, loss_ce: 0.013196
2022-01-14 15:39:41,152 iteration 1764 : loss : 0.099087, loss_ce: 0.033012
2022-01-14 15:39:42,675 iteration 1765 : loss : 0.057249, loss_ce: 0.018245
2022-01-14 15:39:44,106 iteration 1766 : loss : 0.033715, loss_ce: 0.014716
2022-01-14 15:39:45,578 iteration 1767 : loss : 0.040577, loss_ce: 0.016612
2022-01-14 15:39:47,130 iteration 1768 : loss : 0.050259, loss_ce: 0.017335
 26%|███████▌                     | 104/400 [47:40<2:09:39, 26.28s/it]2022-01-14 15:39:48,643 iteration 1769 : loss : 0.029487, loss_ce: 0.009507
2022-01-14 15:39:50,306 iteration 1770 : loss : 0.055775, loss_ce: 0.023842
2022-01-14 15:39:51,785 iteration 1771 : loss : 0.042892, loss_ce: 0.018946
2022-01-14 15:39:53,215 iteration 1772 : loss : 0.027100, loss_ce: 0.008495
2022-01-14 15:39:54,625 iteration 1773 : loss : 0.033126, loss_ce: 0.010055
2022-01-14 15:39:56,107 iteration 1774 : loss : 0.030529, loss_ce: 0.012536
2022-01-14 15:39:57,644 iteration 1775 : loss : 0.038944, loss_ce: 0.016259
2022-01-14 15:39:59,117 iteration 1776 : loss : 0.069342, loss_ce: 0.016970
2022-01-14 15:40:00,569 iteration 1777 : loss : 0.036988, loss_ce: 0.015311
2022-01-14 15:40:02,033 iteration 1778 : loss : 0.035861, loss_ce: 0.013251
2022-01-14 15:40:03,521 iteration 1779 : loss : 0.033120, loss_ce: 0.013126
2022-01-14 15:40:04,976 iteration 1780 : loss : 0.032917, loss_ce: 0.012143
2022-01-14 15:40:06,439 iteration 1781 : loss : 0.041213, loss_ce: 0.021319
2022-01-14 15:40:07,946 iteration 1782 : loss : 0.031536, loss_ce: 0.011556
2022-01-14 15:40:09,379 iteration 1783 : loss : 0.038770, loss_ce: 0.018030
2022-01-14 15:40:11,000 iteration 1784 : loss : 0.030499, loss_ce: 0.011643
2022-01-14 15:40:11,000 Training Data Eval:
2022-01-14 15:40:18,385   Average segmentation loss on training set: 0.0388
2022-01-14 15:40:18,385 Validation Data Eval:
2022-01-14 15:40:20,933   Average segmentation loss on validation set: 0.0597
2022-01-14 15:40:26,790 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed2.pth
2022-01-14 15:40:28,179 iteration 1785 : loss : 0.037950, loss_ce: 0.015371
 26%|███████▌                     | 105/400 [48:21<2:30:59, 30.71s/it]2022-01-14 15:40:29,703 iteration 1786 : loss : 0.037428, loss_ce: 0.017906
2022-01-14 15:40:31,170 iteration 1787 : loss : 0.037153, loss_ce: 0.013896
2022-01-14 15:40:32,576 iteration 1788 : loss : 0.038048, loss_ce: 0.014973
2022-01-14 15:40:34,050 iteration 1789 : loss : 0.035908, loss_ce: 0.011568
2022-01-14 15:40:35,520 iteration 1790 : loss : 0.033434, loss_ce: 0.014811
2022-01-14 15:40:36,937 iteration 1791 : loss : 0.026962, loss_ce: 0.012501
2022-01-14 15:40:38,448 iteration 1792 : loss : 0.044451, loss_ce: 0.015333
2022-01-14 15:40:39,975 iteration 1793 : loss : 0.028439, loss_ce: 0.012347
2022-01-14 15:40:41,423 iteration 1794 : loss : 0.029680, loss_ce: 0.014019
2022-01-14 15:40:42,919 iteration 1795 : loss : 0.036502, loss_ce: 0.015347
2022-01-14 15:40:44,403 iteration 1796 : loss : 0.040412, loss_ce: 0.012667
2022-01-14 15:40:45,980 iteration 1797 : loss : 0.034756, loss_ce: 0.013562
2022-01-14 15:40:47,471 iteration 1798 : loss : 0.040111, loss_ce: 0.012799
2022-01-14 15:40:48,989 iteration 1799 : loss : 0.043924, loss_ce: 0.017465
2022-01-14 15:40:50,496 iteration 1800 : loss : 0.056077, loss_ce: 0.025571
2022-01-14 15:40:52,017 iteration 1801 : loss : 0.031790, loss_ce: 0.012677
2022-01-14 15:40:53,420 iteration 1802 : loss : 0.054282, loss_ce: 0.014356
 26%|███████▋                     | 106/400 [48:46<2:22:26, 29.07s/it]2022-01-14 15:40:54,972 iteration 1803 : loss : 0.037449, loss_ce: 0.011985
2022-01-14 15:40:56,437 iteration 1804 : loss : 0.057020, loss_ce: 0.010377
2022-01-14 15:40:57,860 iteration 1805 : loss : 0.029995, loss_ce: 0.015196
2022-01-14 15:40:59,300 iteration 1806 : loss : 0.038835, loss_ce: 0.013197
2022-01-14 15:41:00,791 iteration 1807 : loss : 0.037224, loss_ce: 0.012409
2022-01-14 15:41:02,284 iteration 1808 : loss : 0.050082, loss_ce: 0.019281
2022-01-14 15:41:03,748 iteration 1809 : loss : 0.040907, loss_ce: 0.016408
2022-01-14 15:41:05,245 iteration 1810 : loss : 0.037526, loss_ce: 0.014362
2022-01-14 15:41:06,756 iteration 1811 : loss : 0.050355, loss_ce: 0.018070
2022-01-14 15:41:08,308 iteration 1812 : loss : 0.039528, loss_ce: 0.018587
2022-01-14 15:41:09,826 iteration 1813 : loss : 0.055817, loss_ce: 0.017901
2022-01-14 15:41:11,398 iteration 1814 : loss : 0.066354, loss_ce: 0.026363
2022-01-14 15:41:12,908 iteration 1815 : loss : 0.027077, loss_ce: 0.012325
2022-01-14 15:41:14,486 iteration 1816 : loss : 0.057233, loss_ce: 0.021151
2022-01-14 15:41:15,979 iteration 1817 : loss : 0.038592, loss_ce: 0.013345
2022-01-14 15:41:17,568 iteration 1818 : loss : 0.040821, loss_ce: 0.021313
2022-01-14 15:41:19,034 iteration 1819 : loss : 0.039564, loss_ce: 0.015632
 27%|███████▊                     | 107/400 [49:12<2:16:53, 28.03s/it]2022-01-14 15:41:20,611 iteration 1820 : loss : 0.057956, loss_ce: 0.016597
2022-01-14 15:41:22,063 iteration 1821 : loss : 0.034688, loss_ce: 0.011549
2022-01-14 15:41:23,513 iteration 1822 : loss : 0.038029, loss_ce: 0.018192
2022-01-14 15:41:25,038 iteration 1823 : loss : 0.035913, loss_ce: 0.014509
2022-01-14 15:41:26,510 iteration 1824 : loss : 0.030629, loss_ce: 0.010281
2022-01-14 15:41:28,013 iteration 1825 : loss : 0.041358, loss_ce: 0.013511
2022-01-14 15:41:29,418 iteration 1826 : loss : 0.040541, loss_ce: 0.016653
2022-01-14 15:41:30,860 iteration 1827 : loss : 0.050346, loss_ce: 0.012364
2022-01-14 15:41:32,380 iteration 1828 : loss : 0.040447, loss_ce: 0.019764
2022-01-14 15:41:33,894 iteration 1829 : loss : 0.057095, loss_ce: 0.015097
2022-01-14 15:41:35,375 iteration 1830 : loss : 0.028534, loss_ce: 0.011162
2022-01-14 15:41:36,838 iteration 1831 : loss : 0.036713, loss_ce: 0.016503
2022-01-14 15:41:38,303 iteration 1832 : loss : 0.029668, loss_ce: 0.010048
2022-01-14 15:41:39,749 iteration 1833 : loss : 0.032539, loss_ce: 0.018602
2022-01-14 15:41:41,341 iteration 1834 : loss : 0.036102, loss_ce: 0.012706
2022-01-14 15:41:42,768 iteration 1835 : loss : 0.038446, loss_ce: 0.013110
2022-01-14 15:41:44,246 iteration 1836 : loss : 0.034912, loss_ce: 0.013206
 27%|███████▊                     | 108/400 [49:37<2:12:19, 27.19s/it]2022-01-14 15:41:45,738 iteration 1837 : loss : 0.055477, loss_ce: 0.012406
2022-01-14 15:41:47,319 iteration 1838 : loss : 0.058904, loss_ce: 0.027121
2022-01-14 15:41:48,738 iteration 1839 : loss : 0.032115, loss_ce: 0.013957
2022-01-14 15:41:50,225 iteration 1840 : loss : 0.061886, loss_ce: 0.015777
2022-01-14 15:41:51,712 iteration 1841 : loss : 0.053307, loss_ce: 0.026045
2022-01-14 15:41:53,274 iteration 1842 : loss : 0.033319, loss_ce: 0.012137
2022-01-14 15:41:54,739 iteration 1843 : loss : 0.039632, loss_ce: 0.016364
2022-01-14 15:41:56,220 iteration 1844 : loss : 0.046530, loss_ce: 0.017060
2022-01-14 15:41:57,698 iteration 1845 : loss : 0.034525, loss_ce: 0.015077
2022-01-14 15:41:59,187 iteration 1846 : loss : 0.047501, loss_ce: 0.014683
2022-01-14 15:42:00,575 iteration 1847 : loss : 0.031891, loss_ce: 0.011321
2022-01-14 15:42:02,062 iteration 1848 : loss : 0.036655, loss_ce: 0.013418
2022-01-14 15:42:03,547 iteration 1849 : loss : 0.040592, loss_ce: 0.015455
2022-01-14 15:42:05,040 iteration 1850 : loss : 0.040677, loss_ce: 0.012815
2022-01-14 15:42:06,560 iteration 1851 : loss : 0.038279, loss_ce: 0.016434
2022-01-14 15:42:07,949 iteration 1852 : loss : 0.031636, loss_ce: 0.017155
2022-01-14 15:42:09,461 iteration 1853 : loss : 0.032592, loss_ce: 0.015092
 27%|███████▉                     | 109/400 [50:02<2:08:59, 26.60s/it]2022-01-14 15:42:11,003 iteration 1854 : loss : 0.049972, loss_ce: 0.015345
2022-01-14 15:42:12,540 iteration 1855 : loss : 0.035385, loss_ce: 0.013104
2022-01-14 15:42:13,928 iteration 1856 : loss : 0.034234, loss_ce: 0.014052
2022-01-14 15:42:15,318 iteration 1857 : loss : 0.027005, loss_ce: 0.011738
2022-01-14 15:42:16,741 iteration 1858 : loss : 0.024423, loss_ce: 0.011305
2022-01-14 15:42:18,229 iteration 1859 : loss : 0.037304, loss_ce: 0.014913
2022-01-14 15:42:19,747 iteration 1860 : loss : 0.056038, loss_ce: 0.025134
2022-01-14 15:42:21,235 iteration 1861 : loss : 0.033732, loss_ce: 0.015369
2022-01-14 15:42:22,743 iteration 1862 : loss : 0.028912, loss_ce: 0.013662
2022-01-14 15:42:24,261 iteration 1863 : loss : 0.045914, loss_ce: 0.015653
2022-01-14 15:42:25,766 iteration 1864 : loss : 0.031106, loss_ce: 0.010311
2022-01-14 15:42:27,253 iteration 1865 : loss : 0.045594, loss_ce: 0.014180
2022-01-14 15:42:28,738 iteration 1866 : loss : 0.026813, loss_ce: 0.009849
2022-01-14 15:42:30,115 iteration 1867 : loss : 0.025720, loss_ce: 0.007638
2022-01-14 15:42:31,557 iteration 1868 : loss : 0.030999, loss_ce: 0.010083
2022-01-14 15:42:32,999 iteration 1869 : loss : 0.035136, loss_ce: 0.016151
2022-01-14 15:42:32,999 Training Data Eval:
2022-01-14 15:42:40,375   Average segmentation loss on training set: 0.0314
2022-01-14 15:42:40,376 Validation Data Eval:
2022-01-14 15:42:42,922   Average segmentation loss on validation set: 0.1436
2022-01-14 15:42:44,418 iteration 1870 : loss : 0.042969, loss_ce: 0.017005
 28%|███████▉                     | 110/400 [50:37<2:20:40, 29.11s/it]2022-01-14 15:42:45,998 iteration 1871 : loss : 0.045484, loss_ce: 0.012496
2022-01-14 15:42:47,516 iteration 1872 : loss : 0.031582, loss_ce: 0.010112
2022-01-14 15:42:49,050 iteration 1873 : loss : 0.025274, loss_ce: 0.008979
2022-01-14 15:42:50,564 iteration 1874 : loss : 0.034886, loss_ce: 0.013028
2022-01-14 15:42:51,981 iteration 1875 : loss : 0.023399, loss_ce: 0.009905
2022-01-14 15:42:53,377 iteration 1876 : loss : 0.027346, loss_ce: 0.012478
2022-01-14 15:42:54,898 iteration 1877 : loss : 0.033822, loss_ce: 0.011632
2022-01-14 15:42:56,401 iteration 1878 : loss : 0.044208, loss_ce: 0.023525
2022-01-14 15:42:57,886 iteration 1879 : loss : 0.034489, loss_ce: 0.011288
2022-01-14 15:42:59,397 iteration 1880 : loss : 0.040114, loss_ce: 0.017421
2022-01-14 15:43:00,875 iteration 1881 : loss : 0.037905, loss_ce: 0.016012
2022-01-14 15:43:02,435 iteration 1882 : loss : 0.055367, loss_ce: 0.020587
2022-01-14 15:43:03,938 iteration 1883 : loss : 0.034834, loss_ce: 0.014636
2022-01-14 15:43:05,387 iteration 1884 : loss : 0.032422, loss_ce: 0.012435
2022-01-14 15:43:06,794 iteration 1885 : loss : 0.026881, loss_ce: 0.010299
2022-01-14 15:43:08,289 iteration 1886 : loss : 0.038103, loss_ce: 0.014848
2022-01-14 15:43:09,785 iteration 1887 : loss : 0.054063, loss_ce: 0.020487
 28%|████████                     | 111/400 [51:03<2:14:46, 27.98s/it]2022-01-14 15:43:11,420 iteration 1888 : loss : 0.044000, loss_ce: 0.014125
2022-01-14 15:43:12,848 iteration 1889 : loss : 0.039962, loss_ce: 0.011903
2022-01-14 15:43:14,260 iteration 1890 : loss : 0.033507, loss_ce: 0.014262
2022-01-14 15:43:15,686 iteration 1891 : loss : 0.031030, loss_ce: 0.009934
2022-01-14 15:43:17,154 iteration 1892 : loss : 0.031959, loss_ce: 0.013871
2022-01-14 15:43:18,652 iteration 1893 : loss : 0.026920, loss_ce: 0.007935
2022-01-14 15:43:20,126 iteration 1894 : loss : 0.042170, loss_ce: 0.015966
2022-01-14 15:43:21,539 iteration 1895 : loss : 0.027185, loss_ce: 0.011060
2022-01-14 15:43:23,085 iteration 1896 : loss : 0.049074, loss_ce: 0.021722
2022-01-14 15:43:24,593 iteration 1897 : loss : 0.046359, loss_ce: 0.016689
2022-01-14 15:43:26,162 iteration 1898 : loss : 0.031135, loss_ce: 0.014132
2022-01-14 15:43:27,647 iteration 1899 : loss : 0.044527, loss_ce: 0.014126
2022-01-14 15:43:29,083 iteration 1900 : loss : 0.040019, loss_ce: 0.017495
2022-01-14 15:43:30,494 iteration 1901 : loss : 0.029591, loss_ce: 0.009212
2022-01-14 15:43:31,968 iteration 1902 : loss : 0.035701, loss_ce: 0.014176
2022-01-14 15:43:33,492 iteration 1903 : loss : 0.032242, loss_ce: 0.013527
2022-01-14 15:43:35,035 iteration 1904 : loss : 0.031390, loss_ce: 0.011736
 28%|████████                     | 112/400 [51:28<2:10:23, 27.16s/it]2022-01-14 15:43:36,493 iteration 1905 : loss : 0.030038, loss_ce: 0.012626
2022-01-14 15:43:38,010 iteration 1906 : loss : 0.025801, loss_ce: 0.007664
2022-01-14 15:43:39,544 iteration 1907 : loss : 0.029937, loss_ce: 0.011792
2022-01-14 15:43:41,172 iteration 1908 : loss : 0.035916, loss_ce: 0.013162
2022-01-14 15:43:42,576 iteration 1909 : loss : 0.023453, loss_ce: 0.009932
2022-01-14 15:43:44,045 iteration 1910 : loss : 0.032503, loss_ce: 0.012525
2022-01-14 15:43:45,568 iteration 1911 : loss : 0.026746, loss_ce: 0.011576
2022-01-14 15:43:47,163 iteration 1912 : loss : 0.032230, loss_ce: 0.012822
2022-01-14 15:43:48,684 iteration 1913 : loss : 0.052056, loss_ce: 0.017835
2022-01-14 15:43:50,260 iteration 1914 : loss : 0.061481, loss_ce: 0.023275
2022-01-14 15:43:51,753 iteration 1915 : loss : 0.025920, loss_ce: 0.008959
2022-01-14 15:43:53,216 iteration 1916 : loss : 0.035597, loss_ce: 0.012168
2022-01-14 15:43:54,681 iteration 1917 : loss : 0.027467, loss_ce: 0.010777
2022-01-14 15:43:56,213 iteration 1918 : loss : 0.036575, loss_ce: 0.016267
2022-01-14 15:43:57,662 iteration 1919 : loss : 0.054662, loss_ce: 0.016088
2022-01-14 15:43:59,068 iteration 1920 : loss : 0.029023, loss_ce: 0.012414
2022-01-14 15:44:00,626 iteration 1921 : loss : 0.045877, loss_ce: 0.016458
 28%|████████▏                    | 113/400 [51:53<2:07:40, 26.69s/it]2022-01-14 15:44:02,209 iteration 1922 : loss : 0.050590, loss_ce: 0.020461
2022-01-14 15:44:03,652 iteration 1923 : loss : 0.027757, loss_ce: 0.010243
2022-01-14 15:44:05,200 iteration 1924 : loss : 0.062308, loss_ce: 0.018702
2022-01-14 15:44:06,631 iteration 1925 : loss : 0.044794, loss_ce: 0.012614
2022-01-14 15:44:08,174 iteration 1926 : loss : 0.041375, loss_ce: 0.014978
2022-01-14 15:44:09,733 iteration 1927 : loss : 0.037042, loss_ce: 0.017098
2022-01-14 15:44:11,198 iteration 1928 : loss : 0.037124, loss_ce: 0.011612
2022-01-14 15:44:12,858 iteration 1929 : loss : 0.066787, loss_ce: 0.031428
2022-01-14 15:44:14,349 iteration 1930 : loss : 0.039218, loss_ce: 0.017831
2022-01-14 15:44:15,895 iteration 1931 : loss : 0.043267, loss_ce: 0.014517
2022-01-14 15:44:17,406 iteration 1932 : loss : 0.060053, loss_ce: 0.015615
2022-01-14 15:44:18,919 iteration 1933 : loss : 0.037742, loss_ce: 0.012518
2022-01-14 15:44:20,395 iteration 1934 : loss : 0.041999, loss_ce: 0.012671
2022-01-14 15:44:21,889 iteration 1935 : loss : 0.031122, loss_ce: 0.011535
2022-01-14 15:44:23,358 iteration 1936 : loss : 0.035857, loss_ce: 0.013842
2022-01-14 15:44:24,785 iteration 1937 : loss : 0.035461, loss_ce: 0.013906
2022-01-14 15:44:26,292 iteration 1938 : loss : 0.033596, loss_ce: 0.015165
 28%|████████▎                    | 114/400 [52:19<2:05:46, 26.38s/it]2022-01-14 15:44:27,847 iteration 1939 : loss : 0.039398, loss_ce: 0.015751
2022-01-14 15:44:29,279 iteration 1940 : loss : 0.041035, loss_ce: 0.019500
2022-01-14 15:44:30,763 iteration 1941 : loss : 0.028828, loss_ce: 0.010714
2022-01-14 15:44:32,265 iteration 1942 : loss : 0.039477, loss_ce: 0.012823
2022-01-14 15:44:33,739 iteration 1943 : loss : 0.057143, loss_ce: 0.016310
2022-01-14 15:44:35,228 iteration 1944 : loss : 0.037292, loss_ce: 0.012215
2022-01-14 15:44:36,723 iteration 1945 : loss : 0.052093, loss_ce: 0.018894
2022-01-14 15:44:38,177 iteration 1946 : loss : 0.047639, loss_ce: 0.013114
2022-01-14 15:44:39,650 iteration 1947 : loss : 0.029799, loss_ce: 0.006995
2022-01-14 15:44:41,154 iteration 1948 : loss : 0.049190, loss_ce: 0.017878
2022-01-14 15:44:42,598 iteration 1949 : loss : 0.047156, loss_ce: 0.016362
2022-01-14 15:44:44,123 iteration 1950 : loss : 0.053095, loss_ce: 0.018327
2022-01-14 15:44:45,639 iteration 1951 : loss : 0.032861, loss_ce: 0.012384
2022-01-14 15:44:47,131 iteration 1952 : loss : 0.048599, loss_ce: 0.022929
2022-01-14 15:44:48,540 iteration 1953 : loss : 0.043415, loss_ce: 0.024712
2022-01-14 15:44:50,045 iteration 1954 : loss : 0.026880, loss_ce: 0.010403
2022-01-14 15:44:50,045 Training Data Eval:
2022-01-14 15:44:57,430   Average segmentation loss on training set: 0.0298
2022-01-14 15:44:57,431 Validation Data Eval:
2022-01-14 15:44:59,974   Average segmentation loss on validation set: 0.1035
2022-01-14 15:45:01,492 iteration 1955 : loss : 0.038238, loss_ce: 0.014158
 29%|████████▎                    | 115/400 [52:54<2:17:52, 29.03s/it]2022-01-14 15:45:03,003 iteration 1956 : loss : 0.045305, loss_ce: 0.018132
2022-01-14 15:45:04,539 iteration 1957 : loss : 0.047751, loss_ce: 0.024756
2022-01-14 15:45:06,014 iteration 1958 : loss : 0.082232, loss_ce: 0.017577
2022-01-14 15:45:07,474 iteration 1959 : loss : 0.044192, loss_ce: 0.013335
2022-01-14 15:45:08,860 iteration 1960 : loss : 0.029674, loss_ce: 0.011657
2022-01-14 15:45:10,224 iteration 1961 : loss : 0.031459, loss_ce: 0.011909
2022-01-14 15:45:11,746 iteration 1962 : loss : 0.044198, loss_ce: 0.016524
2022-01-14 15:45:13,173 iteration 1963 : loss : 0.030928, loss_ce: 0.011663
2022-01-14 15:45:14,696 iteration 1964 : loss : 0.041827, loss_ce: 0.012277
2022-01-14 15:45:16,088 iteration 1965 : loss : 0.032421, loss_ce: 0.015043
2022-01-14 15:45:17,561 iteration 1966 : loss : 0.044764, loss_ce: 0.018442
2022-01-14 15:45:19,146 iteration 1967 : loss : 0.035929, loss_ce: 0.013206
2022-01-14 15:45:20,789 iteration 1968 : loss : 0.049682, loss_ce: 0.021058
2022-01-14 15:45:22,319 iteration 1969 : loss : 0.047734, loss_ce: 0.017590
2022-01-14 15:45:23,732 iteration 1970 : loss : 0.031633, loss_ce: 0.012668
2022-01-14 15:45:25,223 iteration 1971 : loss : 0.034102, loss_ce: 0.010857
2022-01-14 15:45:26,713 iteration 1972 : loss : 0.052505, loss_ce: 0.014175
 29%|████████▍                    | 116/400 [53:20<2:11:59, 27.89s/it]2022-01-14 15:45:28,179 iteration 1973 : loss : 0.030055, loss_ce: 0.012903
2022-01-14 15:45:29,614 iteration 1974 : loss : 0.042171, loss_ce: 0.020004
2022-01-14 15:45:31,118 iteration 1975 : loss : 0.041438, loss_ce: 0.014607
2022-01-14 15:45:32,561 iteration 1976 : loss : 0.048368, loss_ce: 0.024138
2022-01-14 15:45:34,101 iteration 1977 : loss : 0.043299, loss_ce: 0.015528
2022-01-14 15:45:35,660 iteration 1978 : loss : 0.055226, loss_ce: 0.020422
2022-01-14 15:45:37,081 iteration 1979 : loss : 0.030270, loss_ce: 0.013024
2022-01-14 15:45:38,526 iteration 1980 : loss : 0.032801, loss_ce: 0.011743
2022-01-14 15:45:39,975 iteration 1981 : loss : 0.025911, loss_ce: 0.011758
2022-01-14 15:45:41,504 iteration 1982 : loss : 0.042379, loss_ce: 0.015644
2022-01-14 15:45:42,914 iteration 1983 : loss : 0.041044, loss_ce: 0.016489
2022-01-14 15:45:44,444 iteration 1984 : loss : 0.068199, loss_ce: 0.027722
2022-01-14 15:45:45,916 iteration 1985 : loss : 0.036149, loss_ce: 0.013210
2022-01-14 15:45:47,451 iteration 1986 : loss : 0.048059, loss_ce: 0.017625
2022-01-14 15:45:48,905 iteration 1987 : loss : 0.028230, loss_ce: 0.010623
2022-01-14 15:45:50,305 iteration 1988 : loss : 0.030693, loss_ce: 0.013322
2022-01-14 15:45:51,776 iteration 1989 : loss : 0.033431, loss_ce: 0.012080
 29%|████████▍                    | 117/400 [53:45<2:07:32, 27.04s/it]2022-01-14 15:45:53,303 iteration 1990 : loss : 0.048010, loss_ce: 0.012956
2022-01-14 15:45:54,714 iteration 1991 : loss : 0.024135, loss_ce: 0.010025
2022-01-14 15:45:56,219 iteration 1992 : loss : 0.042255, loss_ce: 0.014436
2022-01-14 15:45:57,720 iteration 1993 : loss : 0.029290, loss_ce: 0.009784
2022-01-14 15:45:59,264 iteration 1994 : loss : 0.036748, loss_ce: 0.015512
2022-01-14 15:46:00,724 iteration 1995 : loss : 0.029869, loss_ce: 0.011793
2022-01-14 15:46:02,242 iteration 1996 : loss : 0.028370, loss_ce: 0.011736
2022-01-14 15:46:03,672 iteration 1997 : loss : 0.029114, loss_ce: 0.012209
2022-01-14 15:46:05,158 iteration 1998 : loss : 0.034802, loss_ce: 0.012292
2022-01-14 15:46:06,667 iteration 1999 : loss : 0.042116, loss_ce: 0.015757
2022-01-14 15:46:08,148 iteration 2000 : loss : 0.036829, loss_ce: 0.017754
2022-01-14 15:46:09,577 iteration 2001 : loss : 0.038644, loss_ce: 0.012230
2022-01-14 15:46:11,106 iteration 2002 : loss : 0.026086, loss_ce: 0.010359
2022-01-14 15:46:12,536 iteration 2003 : loss : 0.036246, loss_ce: 0.011497
2022-01-14 15:46:14,046 iteration 2004 : loss : 0.033856, loss_ce: 0.015973
2022-01-14 15:46:15,482 iteration 2005 : loss : 0.036016, loss_ce: 0.017582
2022-01-14 15:46:16,952 iteration 2006 : loss : 0.040086, loss_ce: 0.014105
 30%|████████▌                    | 118/400 [54:10<2:04:26, 26.48s/it]2022-01-14 15:46:18,547 iteration 2007 : loss : 0.041374, loss_ce: 0.013908
2022-01-14 15:46:20,059 iteration 2008 : loss : 0.028585, loss_ce: 0.012035
2022-01-14 15:46:21,525 iteration 2009 : loss : 0.031564, loss_ce: 0.013764
2022-01-14 15:46:23,047 iteration 2010 : loss : 0.049117, loss_ce: 0.023338
2022-01-14 15:46:24,506 iteration 2011 : loss : 0.038512, loss_ce: 0.013112
2022-01-14 15:46:25,929 iteration 2012 : loss : 0.021420, loss_ce: 0.008042
2022-01-14 15:46:27,389 iteration 2013 : loss : 0.032440, loss_ce: 0.015545
2022-01-14 15:46:28,884 iteration 2014 : loss : 0.024729, loss_ce: 0.010136
2022-01-14 15:46:30,399 iteration 2015 : loss : 0.044020, loss_ce: 0.013333
2022-01-14 15:46:31,942 iteration 2016 : loss : 0.037965, loss_ce: 0.016283
2022-01-14 15:46:33,443 iteration 2017 : loss : 0.037999, loss_ce: 0.013939
2022-01-14 15:46:34,849 iteration 2018 : loss : 0.034701, loss_ce: 0.012037
2022-01-14 15:46:36,331 iteration 2019 : loss : 0.026996, loss_ce: 0.009518
2022-01-14 15:46:37,799 iteration 2020 : loss : 0.034269, loss_ce: 0.014187
2022-01-14 15:46:39,255 iteration 2021 : loss : 0.034540, loss_ce: 0.014577
2022-01-14 15:46:40,731 iteration 2022 : loss : 0.035748, loss_ce: 0.012128
2022-01-14 15:46:42,222 iteration 2023 : loss : 0.033696, loss_ce: 0.012596
 30%|████████▋                    | 119/400 [54:35<2:02:18, 26.12s/it]2022-01-14 15:46:43,775 iteration 2024 : loss : 0.035408, loss_ce: 0.015936
2022-01-14 15:46:45,406 iteration 2025 : loss : 0.049494, loss_ce: 0.017872
2022-01-14 15:46:46,855 iteration 2026 : loss : 0.035739, loss_ce: 0.010646
2022-01-14 15:46:48,363 iteration 2027 : loss : 0.036876, loss_ce: 0.010641
2022-01-14 15:46:49,741 iteration 2028 : loss : 0.027762, loss_ce: 0.011877
2022-01-14 15:46:51,148 iteration 2029 : loss : 0.035761, loss_ce: 0.010928
2022-01-14 15:46:52,644 iteration 2030 : loss : 0.039976, loss_ce: 0.014527
2022-01-14 15:46:54,145 iteration 2031 : loss : 0.038536, loss_ce: 0.013442
2022-01-14 15:46:55,633 iteration 2032 : loss : 0.045326, loss_ce: 0.021152
2022-01-14 15:46:57,010 iteration 2033 : loss : 0.022309, loss_ce: 0.009707
2022-01-14 15:46:58,444 iteration 2034 : loss : 0.030694, loss_ce: 0.010416
2022-01-14 15:46:59,950 iteration 2035 : loss : 0.039986, loss_ce: 0.015769
2022-01-14 15:47:01,398 iteration 2036 : loss : 0.027460, loss_ce: 0.011917
2022-01-14 15:47:02,825 iteration 2037 : loss : 0.030015, loss_ce: 0.011650
2022-01-14 15:47:04,397 iteration 2038 : loss : 0.064943, loss_ce: 0.017199
2022-01-14 15:47:05,910 iteration 2039 : loss : 0.027887, loss_ce: 0.009453
2022-01-14 15:47:05,911 Training Data Eval:
2022-01-14 15:47:13,280   Average segmentation loss on training set: 0.0233
2022-01-14 15:47:13,281 Validation Data Eval:
2022-01-14 15:47:15,817   Average segmentation loss on validation set: 0.0645
2022-01-14 15:47:17,343 iteration 2040 : loss : 0.030829, loss_ce: 0.013824
 30%|████████▋                    | 120/400 [55:10<2:14:29, 28.82s/it]2022-01-14 15:47:18,828 iteration 2041 : loss : 0.027458, loss_ce: 0.012778
2022-01-14 15:47:20,330 iteration 2042 : loss : 0.037570, loss_ce: 0.014798
2022-01-14 15:47:21,823 iteration 2043 : loss : 0.029975, loss_ce: 0.010269
2022-01-14 15:47:23,279 iteration 2044 : loss : 0.037471, loss_ce: 0.018609
2022-01-14 15:47:24,851 iteration 2045 : loss : 0.039083, loss_ce: 0.015368
2022-01-14 15:47:26,339 iteration 2046 : loss : 0.050856, loss_ce: 0.012837
2022-01-14 15:47:27,787 iteration 2047 : loss : 0.024732, loss_ce: 0.009094
2022-01-14 15:47:29,199 iteration 2048 : loss : 0.025082, loss_ce: 0.009793
2022-01-14 15:47:30,733 iteration 2049 : loss : 0.068773, loss_ce: 0.036012
2022-01-14 15:47:32,256 iteration 2050 : loss : 0.041824, loss_ce: 0.014372
2022-01-14 15:47:33,706 iteration 2051 : loss : 0.053251, loss_ce: 0.025956
2022-01-14 15:47:35,244 iteration 2052 : loss : 0.067427, loss_ce: 0.036419
2022-01-14 15:47:36,740 iteration 2053 : loss : 0.038918, loss_ce: 0.015290
2022-01-14 15:47:38,219 iteration 2054 : loss : 0.042857, loss_ce: 0.015375
2022-01-14 15:47:39,719 iteration 2055 : loss : 0.041617, loss_ce: 0.015101
2022-01-14 15:47:41,165 iteration 2056 : loss : 0.027999, loss_ce: 0.010127
2022-01-14 15:47:42,614 iteration 2057 : loss : 0.036987, loss_ce: 0.017441
 30%|████████▊                    | 121/400 [55:35<2:09:03, 27.75s/it]2022-01-14 15:47:44,137 iteration 2058 : loss : 0.044551, loss_ce: 0.021909
2022-01-14 15:47:45,667 iteration 2059 : loss : 0.034939, loss_ce: 0.012628
2022-01-14 15:47:47,220 iteration 2060 : loss : 0.051998, loss_ce: 0.020560
2022-01-14 15:47:48,698 iteration 2061 : loss : 0.033974, loss_ce: 0.017068
2022-01-14 15:47:50,128 iteration 2062 : loss : 0.047768, loss_ce: 0.020656
2022-01-14 15:47:51,768 iteration 2063 : loss : 0.048731, loss_ce: 0.020747
2022-01-14 15:47:53,260 iteration 2064 : loss : 0.052388, loss_ce: 0.021477
2022-01-14 15:47:54,812 iteration 2065 : loss : 0.047707, loss_ce: 0.016752
2022-01-14 15:47:56,282 iteration 2066 : loss : 0.035048, loss_ce: 0.014011
2022-01-14 15:47:57,803 iteration 2067 : loss : 0.041631, loss_ce: 0.014967
2022-01-14 15:47:59,232 iteration 2068 : loss : 0.027013, loss_ce: 0.009963
2022-01-14 15:48:00,717 iteration 2069 : loss : 0.046686, loss_ce: 0.021446
2022-01-14 15:48:02,249 iteration 2070 : loss : 0.034261, loss_ce: 0.015320
2022-01-14 15:48:03,686 iteration 2071 : loss : 0.028049, loss_ce: 0.011278
2022-01-14 15:48:05,121 iteration 2072 : loss : 0.034276, loss_ce: 0.017312
2022-01-14 15:48:06,645 iteration 2073 : loss : 0.044168, loss_ce: 0.018103
2022-01-14 15:48:08,058 iteration 2074 : loss : 0.039887, loss_ce: 0.011552
 30%|████████▊                    | 122/400 [56:01<2:05:22, 27.06s/it]2022-01-14 15:48:09,572 iteration 2075 : loss : 0.037307, loss_ce: 0.018472
2022-01-14 15:48:11,089 iteration 2076 : loss : 0.034626, loss_ce: 0.014020
2022-01-14 15:48:12,604 iteration 2077 : loss : 0.045942, loss_ce: 0.021051
2022-01-14 15:48:14,141 iteration 2078 : loss : 0.045006, loss_ce: 0.018241
2022-01-14 15:48:15,659 iteration 2079 : loss : 0.031855, loss_ce: 0.011326
2022-01-14 15:48:17,104 iteration 2080 : loss : 0.037266, loss_ce: 0.012159
2022-01-14 15:48:18,528 iteration 2081 : loss : 0.032184, loss_ce: 0.010924
2022-01-14 15:48:20,000 iteration 2082 : loss : 0.042132, loss_ce: 0.012990
2022-01-14 15:48:21,458 iteration 2083 : loss : 0.043783, loss_ce: 0.017444
2022-01-14 15:48:22,874 iteration 2084 : loss : 0.038311, loss_ce: 0.018042
2022-01-14 15:48:24,376 iteration 2085 : loss : 0.087717, loss_ce: 0.019564
2022-01-14 15:48:25,954 iteration 2086 : loss : 0.038027, loss_ce: 0.011849
2022-01-14 15:48:27,361 iteration 2087 : loss : 0.036654, loss_ce: 0.011811
2022-01-14 15:48:28,821 iteration 2088 : loss : 0.033621, loss_ce: 0.012404
2022-01-14 15:48:30,320 iteration 2089 : loss : 0.028314, loss_ce: 0.011098
2022-01-14 15:48:31,802 iteration 2090 : loss : 0.037354, loss_ce: 0.018678
2022-01-14 15:48:33,380 iteration 2091 : loss : 0.045826, loss_ce: 0.016542
 31%|████████▉                    | 123/400 [56:26<2:02:31, 26.54s/it]2022-01-14 15:48:34,884 iteration 2092 : loss : 0.033126, loss_ce: 0.009970
2022-01-14 15:48:36,297 iteration 2093 : loss : 0.023357, loss_ce: 0.009211
2022-01-14 15:48:37,809 iteration 2094 : loss : 0.033265, loss_ce: 0.011637
2022-01-14 15:48:39,462 iteration 2095 : loss : 0.046576, loss_ce: 0.016355
2022-01-14 15:48:40,928 iteration 2096 : loss : 0.030944, loss_ce: 0.012776
2022-01-14 15:48:42,393 iteration 2097 : loss : 0.056680, loss_ce: 0.016906
2022-01-14 15:48:43,810 iteration 2098 : loss : 0.038802, loss_ce: 0.012758
2022-01-14 15:48:45,272 iteration 2099 : loss : 0.026852, loss_ce: 0.010991
2022-01-14 15:48:46,796 iteration 2100 : loss : 0.044470, loss_ce: 0.015819
2022-01-14 15:48:48,183 iteration 2101 : loss : 0.036480, loss_ce: 0.011325
2022-01-14 15:48:49,693 iteration 2102 : loss : 0.033325, loss_ce: 0.015096
2022-01-14 15:48:51,123 iteration 2103 : loss : 0.045600, loss_ce: 0.022970
2022-01-14 15:48:52,536 iteration 2104 : loss : 0.029397, loss_ce: 0.010576
2022-01-14 15:48:54,027 iteration 2105 : loss : 0.031991, loss_ce: 0.013296
2022-01-14 15:48:55,516 iteration 2106 : loss : 0.034008, loss_ce: 0.014584
2022-01-14 15:48:56,951 iteration 2107 : loss : 0.036139, loss_ce: 0.011846
2022-01-14 15:48:58,364 iteration 2108 : loss : 0.027281, loss_ce: 0.010984
 31%|████████▉                    | 124/400 [56:51<1:59:56, 26.07s/it]2022-01-14 15:48:59,888 iteration 2109 : loss : 0.059834, loss_ce: 0.019130
2022-01-14 15:49:01,385 iteration 2110 : loss : 0.045792, loss_ce: 0.021372
2022-01-14 15:49:02,925 iteration 2111 : loss : 0.032320, loss_ce: 0.010940
2022-01-14 15:49:04,510 iteration 2112 : loss : 0.039743, loss_ce: 0.016514
2022-01-14 15:49:06,045 iteration 2113 : loss : 0.028497, loss_ce: 0.009266
2022-01-14 15:49:07,558 iteration 2114 : loss : 0.038503, loss_ce: 0.009415
2022-01-14 15:49:08,999 iteration 2115 : loss : 0.032315, loss_ce: 0.010227
2022-01-14 15:49:10,435 iteration 2116 : loss : 0.039543, loss_ce: 0.013780
2022-01-14 15:49:12,009 iteration 2117 : loss : 0.037464, loss_ce: 0.011747
2022-01-14 15:49:13,506 iteration 2118 : loss : 0.037988, loss_ce: 0.016648
2022-01-14 15:49:15,111 iteration 2119 : loss : 0.043749, loss_ce: 0.018912
2022-01-14 15:49:16,656 iteration 2120 : loss : 0.044966, loss_ce: 0.025527
2022-01-14 15:49:18,201 iteration 2121 : loss : 0.055912, loss_ce: 0.029655
2022-01-14 15:49:19,735 iteration 2122 : loss : 0.052352, loss_ce: 0.027449
2022-01-14 15:49:21,152 iteration 2123 : loss : 0.047097, loss_ce: 0.016010
2022-01-14 15:49:22,702 iteration 2124 : loss : 0.038904, loss_ce: 0.016958
2022-01-14 15:49:22,702 Training Data Eval:
2022-01-14 15:49:30,073   Average segmentation loss on training set: 0.2135
2022-01-14 15:49:30,074 Validation Data Eval:
2022-01-14 15:49:32,614   Average segmentation loss on validation set: 0.2057
2022-01-14 15:49:34,070 iteration 2125 : loss : 0.037497, loss_ce: 0.017446
 31%|█████████                    | 125/400 [57:27<2:12:45, 28.96s/it]2022-01-14 15:49:35,639 iteration 2126 : loss : 0.064398, loss_ce: 0.025887
2022-01-14 15:49:37,078 iteration 2127 : loss : 0.032756, loss_ce: 0.013576
2022-01-14 15:49:38,487 iteration 2128 : loss : 0.027455, loss_ce: 0.011805
2022-01-14 15:49:40,035 iteration 2129 : loss : 0.049680, loss_ce: 0.019584
2022-01-14 15:49:41,504 iteration 2130 : loss : 0.038538, loss_ce: 0.015531
2022-01-14 15:49:42,928 iteration 2131 : loss : 0.033042, loss_ce: 0.013545
2022-01-14 15:49:44,435 iteration 2132 : loss : 0.064845, loss_ce: 0.022156
2022-01-14 15:49:45,907 iteration 2133 : loss : 0.036169, loss_ce: 0.013390
2022-01-14 15:49:47,458 iteration 2134 : loss : 0.035600, loss_ce: 0.012430
2022-01-14 15:49:48,870 iteration 2135 : loss : 0.037858, loss_ce: 0.011703
2022-01-14 15:49:50,407 iteration 2136 : loss : 0.047898, loss_ce: 0.023137
2022-01-14 15:49:51,877 iteration 2137 : loss : 0.037364, loss_ce: 0.017858
2022-01-14 15:49:53,433 iteration 2138 : loss : 0.044171, loss_ce: 0.013957
2022-01-14 15:49:54,894 iteration 2139 : loss : 0.033676, loss_ce: 0.016507
2022-01-14 15:49:56,421 iteration 2140 : loss : 0.051910, loss_ce: 0.032193
2022-01-14 15:49:57,932 iteration 2141 : loss : 0.035038, loss_ce: 0.011682
2022-01-14 15:49:59,449 iteration 2142 : loss : 0.061724, loss_ce: 0.019440
 32%|█████████▏                   | 126/400 [57:52<2:07:21, 27.89s/it]2022-01-14 15:50:00,982 iteration 2143 : loss : 0.042037, loss_ce: 0.023520
2022-01-14 15:50:02,483 iteration 2144 : loss : 0.039269, loss_ce: 0.016385
2022-01-14 15:50:03,971 iteration 2145 : loss : 0.038518, loss_ce: 0.014413
2022-01-14 15:50:05,417 iteration 2146 : loss : 0.034003, loss_ce: 0.012252
2022-01-14 15:50:06,840 iteration 2147 : loss : 0.029514, loss_ce: 0.010692
2022-01-14 15:50:08,303 iteration 2148 : loss : 0.030384, loss_ce: 0.011461
2022-01-14 15:50:09,840 iteration 2149 : loss : 0.055334, loss_ce: 0.021163
2022-01-14 15:50:11,287 iteration 2150 : loss : 0.028344, loss_ce: 0.012446
2022-01-14 15:50:12,761 iteration 2151 : loss : 0.032331, loss_ce: 0.011621
2022-01-14 15:50:14,185 iteration 2152 : loss : 0.032083, loss_ce: 0.015590
2022-01-14 15:50:15,655 iteration 2153 : loss : 0.039544, loss_ce: 0.013487
2022-01-14 15:50:17,124 iteration 2154 : loss : 0.023782, loss_ce: 0.008185
2022-01-14 15:50:18,629 iteration 2155 : loss : 0.037418, loss_ce: 0.019860
2022-01-14 15:50:20,050 iteration 2156 : loss : 0.035936, loss_ce: 0.012713
2022-01-14 15:50:21,627 iteration 2157 : loss : 0.034279, loss_ce: 0.014135
2022-01-14 15:50:23,174 iteration 2158 : loss : 0.031344, loss_ce: 0.009889
2022-01-14 15:50:24,690 iteration 2159 : loss : 0.040745, loss_ce: 0.014856
 32%|█████████▏                   | 127/400 [58:17<2:03:15, 27.09s/it]2022-01-14 15:50:26,224 iteration 2160 : loss : 0.032855, loss_ce: 0.011637
2022-01-14 15:50:27,796 iteration 2161 : loss : 0.053624, loss_ce: 0.022581
2022-01-14 15:50:29,343 iteration 2162 : loss : 0.032257, loss_ce: 0.012619
2022-01-14 15:50:30,770 iteration 2163 : loss : 0.034972, loss_ce: 0.012042
2022-01-14 15:50:32,303 iteration 2164 : loss : 0.032885, loss_ce: 0.011225
2022-01-14 15:50:33,825 iteration 2165 : loss : 0.026303, loss_ce: 0.011389
2022-01-14 15:50:35,337 iteration 2166 : loss : 0.040721, loss_ce: 0.011002
2022-01-14 15:50:36,893 iteration 2167 : loss : 0.024546, loss_ce: 0.008397
2022-01-14 15:50:38,386 iteration 2168 : loss : 0.034675, loss_ce: 0.014976
2022-01-14 15:50:39,868 iteration 2169 : loss : 0.033039, loss_ce: 0.012516
2022-01-14 15:50:41,303 iteration 2170 : loss : 0.052978, loss_ce: 0.030363
2022-01-14 15:50:42,827 iteration 2171 : loss : 0.042677, loss_ce: 0.014027
2022-01-14 15:50:44,420 iteration 2172 : loss : 0.047599, loss_ce: 0.015472
2022-01-14 15:50:45,855 iteration 2173 : loss : 0.040082, loss_ce: 0.013009
2022-01-14 15:50:47,249 iteration 2174 : loss : 0.026516, loss_ce: 0.012646
2022-01-14 15:50:48,677 iteration 2175 : loss : 0.030140, loss_ce: 0.011137
2022-01-14 15:50:50,273 iteration 2176 : loss : 0.045695, loss_ce: 0.016685
 32%|█████████▎                   | 128/400 [58:43<2:00:46, 26.64s/it]2022-01-14 15:50:51,826 iteration 2177 : loss : 0.035403, loss_ce: 0.011792
2022-01-14 15:50:53,370 iteration 2178 : loss : 0.028012, loss_ce: 0.011240
2022-01-14 15:50:54,837 iteration 2179 : loss : 0.041900, loss_ce: 0.021866
2022-01-14 15:50:56,305 iteration 2180 : loss : 0.024955, loss_ce: 0.009432
2022-01-14 15:50:57,826 iteration 2181 : loss : 0.049619, loss_ce: 0.023467
2022-01-14 15:50:59,293 iteration 2182 : loss : 0.039264, loss_ce: 0.010549
2022-01-14 15:51:00,713 iteration 2183 : loss : 0.030738, loss_ce: 0.012448
2022-01-14 15:51:02,261 iteration 2184 : loss : 0.049769, loss_ce: 0.012574
2022-01-14 15:51:03,724 iteration 2185 : loss : 0.040394, loss_ce: 0.013964
2022-01-14 15:51:05,207 iteration 2186 : loss : 0.045384, loss_ce: 0.014797
2022-01-14 15:51:06,711 iteration 2187 : loss : 0.022463, loss_ce: 0.008298
2022-01-14 15:51:08,185 iteration 2188 : loss : 0.042500, loss_ce: 0.011474
2022-01-14 15:51:09,722 iteration 2189 : loss : 0.044289, loss_ce: 0.016754
2022-01-14 15:51:11,194 iteration 2190 : loss : 0.030154, loss_ce: 0.010099
2022-01-14 15:51:12,695 iteration 2191 : loss : 0.059080, loss_ce: 0.017116
2022-01-14 15:51:14,134 iteration 2192 : loss : 0.033466, loss_ce: 0.010410
2022-01-14 15:51:15,618 iteration 2193 : loss : 0.038353, loss_ce: 0.014278
 32%|█████████▎                   | 129/400 [59:08<1:58:34, 26.25s/it]2022-01-14 15:51:17,193 iteration 2194 : loss : 0.044824, loss_ce: 0.025182
2022-01-14 15:51:18,652 iteration 2195 : loss : 0.031972, loss_ce: 0.011536
2022-01-14 15:51:20,121 iteration 2196 : loss : 0.029059, loss_ce: 0.011020
2022-01-14 15:51:21,629 iteration 2197 : loss : 0.039215, loss_ce: 0.021680
2022-01-14 15:51:23,135 iteration 2198 : loss : 0.035561, loss_ce: 0.017262
2022-01-14 15:51:24,621 iteration 2199 : loss : 0.038415, loss_ce: 0.016808
2022-01-14 15:51:26,074 iteration 2200 : loss : 0.033992, loss_ce: 0.012007
2022-01-14 15:51:27,513 iteration 2201 : loss : 0.028088, loss_ce: 0.011042
2022-01-14 15:51:29,046 iteration 2202 : loss : 0.077437, loss_ce: 0.019528
2022-01-14 15:51:30,582 iteration 2203 : loss : 0.030781, loss_ce: 0.015516
2022-01-14 15:51:32,028 iteration 2204 : loss : 0.033625, loss_ce: 0.015496
2022-01-14 15:51:33,424 iteration 2205 : loss : 0.024777, loss_ce: 0.010624
2022-01-14 15:51:34,820 iteration 2206 : loss : 0.033759, loss_ce: 0.012098
2022-01-14 15:51:36,256 iteration 2207 : loss : 0.042384, loss_ce: 0.016571
2022-01-14 15:51:37,750 iteration 2208 : loss : 0.029183, loss_ce: 0.008190
2022-01-14 15:51:39,208 iteration 2209 : loss : 0.046232, loss_ce: 0.014905
2022-01-14 15:51:39,208 Training Data Eval:
2022-01-14 15:51:46,589   Average segmentation loss on training set: 0.0405
2022-01-14 15:51:46,589 Validation Data Eval:
2022-01-14 15:51:49,127   Average segmentation loss on validation set: 0.1921
2022-01-14 15:51:50,614 iteration 2210 : loss : 0.036477, loss_ce: 0.013108
 32%|█████████▍                   | 130/400 [59:43<2:09:56, 28.88s/it]2022-01-14 15:51:52,166 iteration 2211 : loss : 0.029355, loss_ce: 0.009820
2022-01-14 15:51:53,672 iteration 2212 : loss : 0.030648, loss_ce: 0.013089
2022-01-14 15:51:55,181 iteration 2213 : loss : 0.035564, loss_ce: 0.012873
2022-01-14 15:51:56,687 iteration 2214 : loss : 0.030810, loss_ce: 0.010336
2022-01-14 15:51:58,217 iteration 2215 : loss : 0.045959, loss_ce: 0.020825
2022-01-14 15:51:59,629 iteration 2216 : loss : 0.027969, loss_ce: 0.009076
2022-01-14 15:52:01,164 iteration 2217 : loss : 0.042365, loss_ce: 0.017309
2022-01-14 15:52:02,597 iteration 2218 : loss : 0.035927, loss_ce: 0.014568
2022-01-14 15:52:04,120 iteration 2219 : loss : 0.027812, loss_ce: 0.009673
2022-01-14 15:52:05,504 iteration 2220 : loss : 0.035072, loss_ce: 0.013100
2022-01-14 15:52:06,940 iteration 2221 : loss : 0.023711, loss_ce: 0.008409
2022-01-14 15:52:08,459 iteration 2222 : loss : 0.031551, loss_ce: 0.012901
2022-01-14 15:52:09,952 iteration 2223 : loss : 0.033899, loss_ce: 0.010394
2022-01-14 15:52:11,505 iteration 2224 : loss : 0.062816, loss_ce: 0.028810
2022-01-14 15:52:12,926 iteration 2225 : loss : 0.021841, loss_ce: 0.008365
2022-01-14 15:52:14,486 iteration 2226 : loss : 0.042945, loss_ce: 0.020177
2022-01-14 15:52:15,951 iteration 2227 : loss : 0.030508, loss_ce: 0.012632
 33%|████████▊                  | 131/400 [1:00:09<2:04:42, 27.81s/it]2022-01-14 15:52:17,535 iteration 2228 : loss : 0.025294, loss_ce: 0.012156
2022-01-14 15:52:19,028 iteration 2229 : loss : 0.032590, loss_ce: 0.012383
2022-01-14 15:52:20,565 iteration 2230 : loss : 0.034449, loss_ce: 0.011839
2022-01-14 15:52:21,951 iteration 2231 : loss : 0.023401, loss_ce: 0.010143
2022-01-14 15:52:23,399 iteration 2232 : loss : 0.036446, loss_ce: 0.015454
2022-01-14 15:52:24,867 iteration 2233 : loss : 0.033177, loss_ce: 0.012581
2022-01-14 15:52:26,328 iteration 2234 : loss : 0.035950, loss_ce: 0.012804
2022-01-14 15:52:27,786 iteration 2235 : loss : 0.048767, loss_ce: 0.008948
2022-01-14 15:52:29,401 iteration 2236 : loss : 0.048087, loss_ce: 0.024119
2022-01-14 15:52:30,889 iteration 2237 : loss : 0.030583, loss_ce: 0.013744
2022-01-14 15:52:32,386 iteration 2238 : loss : 0.046413, loss_ce: 0.027618
2022-01-14 15:52:33,872 iteration 2239 : loss : 0.029940, loss_ce: 0.011818
2022-01-14 15:52:35,401 iteration 2240 : loss : 0.035968, loss_ce: 0.015441
2022-01-14 15:52:36,952 iteration 2241 : loss : 0.036773, loss_ce: 0.008849
2022-01-14 15:52:38,496 iteration 2242 : loss : 0.025574, loss_ce: 0.009231
2022-01-14 15:52:40,089 iteration 2243 : loss : 0.045928, loss_ce: 0.015221
2022-01-14 15:52:41,576 iteration 2244 : loss : 0.031744, loss_ce: 0.013566
 33%|████████▉                  | 132/400 [1:00:34<2:01:17, 27.16s/it]2022-01-14 15:52:43,206 iteration 2245 : loss : 0.049147, loss_ce: 0.018658
2022-01-14 15:52:44,663 iteration 2246 : loss : 0.031470, loss_ce: 0.013395
2022-01-14 15:52:46,243 iteration 2247 : loss : 0.063323, loss_ce: 0.015806
2022-01-14 15:52:47,760 iteration 2248 : loss : 0.028571, loss_ce: 0.011626
2022-01-14 15:52:49,260 iteration 2249 : loss : 0.030806, loss_ce: 0.010759
2022-01-14 15:52:50,738 iteration 2250 : loss : 0.051176, loss_ce: 0.022253
2022-01-14 15:52:52,149 iteration 2251 : loss : 0.031207, loss_ce: 0.010286
2022-01-14 15:52:53,740 iteration 2252 : loss : 0.055659, loss_ce: 0.018678
2022-01-14 15:52:55,311 iteration 2253 : loss : 0.036692, loss_ce: 0.014504
2022-01-14 15:52:56,789 iteration 2254 : loss : 0.041270, loss_ce: 0.017977
2022-01-14 15:52:58,238 iteration 2255 : loss : 0.029925, loss_ce: 0.010219
2022-01-14 15:52:59,741 iteration 2256 : loss : 0.027297, loss_ce: 0.010975
2022-01-14 15:53:01,212 iteration 2257 : loss : 0.027387, loss_ce: 0.009702
2022-01-14 15:53:02,627 iteration 2258 : loss : 0.026681, loss_ce: 0.011297
2022-01-14 15:53:04,184 iteration 2259 : loss : 0.030532, loss_ce: 0.011094
2022-01-14 15:53:05,630 iteration 2260 : loss : 0.028589, loss_ce: 0.011316
2022-01-14 15:53:07,133 iteration 2261 : loss : 0.033699, loss_ce: 0.014569
 33%|████████▉                  | 133/400 [1:01:00<1:58:42, 26.67s/it]2022-01-14 15:53:08,677 iteration 2262 : loss : 0.031704, loss_ce: 0.013471
2022-01-14 15:53:10,169 iteration 2263 : loss : 0.024915, loss_ce: 0.010529
2022-01-14 15:53:11,700 iteration 2264 : loss : 0.035168, loss_ce: 0.014280
2022-01-14 15:53:13,180 iteration 2265 : loss : 0.027364, loss_ce: 0.009625
2022-01-14 15:53:14,649 iteration 2266 : loss : 0.028134, loss_ce: 0.008358
2022-01-14 15:53:16,051 iteration 2267 : loss : 0.021198, loss_ce: 0.009221
2022-01-14 15:53:17,510 iteration 2268 : loss : 0.025603, loss_ce: 0.011890
2022-01-14 15:53:18,952 iteration 2269 : loss : 0.038280, loss_ce: 0.018154
2022-01-14 15:53:20,369 iteration 2270 : loss : 0.022581, loss_ce: 0.007721
2022-01-14 15:53:21,835 iteration 2271 : loss : 0.045131, loss_ce: 0.016174
2022-01-14 15:53:23,374 iteration 2272 : loss : 0.039095, loss_ce: 0.016122
2022-01-14 15:53:24,912 iteration 2273 : loss : 0.037126, loss_ce: 0.013486
2022-01-14 15:53:26,396 iteration 2274 : loss : 0.031855, loss_ce: 0.012456
2022-01-14 15:53:27,869 iteration 2275 : loss : 0.041531, loss_ce: 0.013308
2022-01-14 15:53:29,297 iteration 2276 : loss : 0.037301, loss_ce: 0.014403
2022-01-14 15:53:30,759 iteration 2277 : loss : 0.034310, loss_ce: 0.010473
2022-01-14 15:53:32,262 iteration 2278 : loss : 0.037124, loss_ce: 0.014043
 34%|█████████                  | 134/400 [1:01:25<1:56:12, 26.21s/it]2022-01-14 15:53:33,738 iteration 2279 : loss : 0.019787, loss_ce: 0.007038
2022-01-14 15:53:35,154 iteration 2280 : loss : 0.033318, loss_ce: 0.016083
2022-01-14 15:53:36,626 iteration 2281 : loss : 0.046188, loss_ce: 0.014888
2022-01-14 15:53:38,036 iteration 2282 : loss : 0.046063, loss_ce: 0.015576
2022-01-14 15:53:39,525 iteration 2283 : loss : 0.033190, loss_ce: 0.008500
2022-01-14 15:53:40,930 iteration 2284 : loss : 0.036932, loss_ce: 0.018059
2022-01-14 15:53:42,444 iteration 2285 : loss : 0.051895, loss_ce: 0.026969
2022-01-14 15:53:43,899 iteration 2286 : loss : 0.042589, loss_ce: 0.020956
2022-01-14 15:53:45,369 iteration 2287 : loss : 0.034107, loss_ce: 0.010334
2022-01-14 15:53:46,840 iteration 2288 : loss : 0.048701, loss_ce: 0.012518
2022-01-14 15:53:48,337 iteration 2289 : loss : 0.027497, loss_ce: 0.008920
2022-01-14 15:53:49,823 iteration 2290 : loss : 0.041446, loss_ce: 0.016236
2022-01-14 15:53:51,406 iteration 2291 : loss : 0.037595, loss_ce: 0.014185
2022-01-14 15:53:52,925 iteration 2292 : loss : 0.031082, loss_ce: 0.013504
2022-01-14 15:53:54,417 iteration 2293 : loss : 0.038371, loss_ce: 0.014665
2022-01-14 15:53:55,878 iteration 2294 : loss : 0.029979, loss_ce: 0.013277
2022-01-14 15:53:55,878 Training Data Eval:
2022-01-14 15:54:03,269   Average segmentation loss on training set: 0.0359
2022-01-14 15:54:03,270 Validation Data Eval:
2022-01-14 15:54:05,817   Average segmentation loss on validation set: 0.2100
2022-01-14 15:54:07,295 iteration 2295 : loss : 0.050389, loss_ce: 0.015214
 34%|█████████                  | 135/400 [1:02:00<2:07:27, 28.86s/it]2022-01-14 15:54:08,759 iteration 2296 : loss : 0.026755, loss_ce: 0.010914
2022-01-14 15:54:10,290 iteration 2297 : loss : 0.031019, loss_ce: 0.011010
2022-01-14 15:54:11,778 iteration 2298 : loss : 0.028233, loss_ce: 0.009440
2022-01-14 15:54:13,296 iteration 2299 : loss : 0.028897, loss_ce: 0.009184
2022-01-14 15:54:14,752 iteration 2300 : loss : 0.029537, loss_ce: 0.013873
2022-01-14 15:54:16,237 iteration 2301 : loss : 0.037522, loss_ce: 0.013534
2022-01-14 15:54:17,795 iteration 2302 : loss : 0.027371, loss_ce: 0.009443
2022-01-14 15:54:19,323 iteration 2303 : loss : 0.039712, loss_ce: 0.011685
2022-01-14 15:54:20,836 iteration 2304 : loss : 0.035890, loss_ce: 0.016079
2022-01-14 15:54:22,304 iteration 2305 : loss : 0.033062, loss_ce: 0.013600
2022-01-14 15:54:23,758 iteration 2306 : loss : 0.040795, loss_ce: 0.012780
2022-01-14 15:54:25,313 iteration 2307 : loss : 0.031599, loss_ce: 0.012181
2022-01-14 15:54:26,755 iteration 2308 : loss : 0.028146, loss_ce: 0.010937
2022-01-14 15:54:28,281 iteration 2309 : loss : 0.041728, loss_ce: 0.020161
2022-01-14 15:54:29,790 iteration 2310 : loss : 0.036239, loss_ce: 0.015767
2022-01-14 15:54:31,234 iteration 2311 : loss : 0.036279, loss_ce: 0.012788
2022-01-14 15:54:32,649 iteration 2312 : loss : 0.024932, loss_ce: 0.008975
 34%|█████████▏                 | 136/400 [1:02:25<2:02:21, 27.81s/it]2022-01-14 15:54:34,160 iteration 2313 : loss : 0.042096, loss_ce: 0.013991
2022-01-14 15:54:35,661 iteration 2314 : loss : 0.028404, loss_ce: 0.008733
2022-01-14 15:54:37,233 iteration 2315 : loss : 0.043173, loss_ce: 0.011636
2022-01-14 15:54:38,640 iteration 2316 : loss : 0.027348, loss_ce: 0.009294
2022-01-14 15:54:40,188 iteration 2317 : loss : 0.046319, loss_ce: 0.011396
2022-01-14 15:54:41,698 iteration 2318 : loss : 0.035316, loss_ce: 0.014698
2022-01-14 15:54:43,195 iteration 2319 : loss : 0.033368, loss_ce: 0.014210
2022-01-14 15:54:44,737 iteration 2320 : loss : 0.035170, loss_ce: 0.016781
2022-01-14 15:54:46,170 iteration 2321 : loss : 0.030751, loss_ce: 0.009485
2022-01-14 15:54:47,647 iteration 2322 : loss : 0.038731, loss_ce: 0.016949
2022-01-14 15:54:49,117 iteration 2323 : loss : 0.034904, loss_ce: 0.015779
2022-01-14 15:54:50,627 iteration 2324 : loss : 0.034853, loss_ce: 0.011806
2022-01-14 15:54:52,085 iteration 2325 : loss : 0.029151, loss_ce: 0.013367
2022-01-14 15:54:53,582 iteration 2326 : loss : 0.047592, loss_ce: 0.021213
2022-01-14 15:54:55,046 iteration 2327 : loss : 0.024172, loss_ce: 0.009140
2022-01-14 15:54:56,560 iteration 2328 : loss : 0.053830, loss_ce: 0.030643
2022-01-14 15:54:58,012 iteration 2329 : loss : 0.023258, loss_ce: 0.009081
 34%|█████████▏                 | 137/400 [1:02:51<1:58:40, 27.07s/it]2022-01-14 15:54:59,510 iteration 2330 : loss : 0.024630, loss_ce: 0.009129
2022-01-14 15:55:01,006 iteration 2331 : loss : 0.036571, loss_ce: 0.015516
2022-01-14 15:55:02,542 iteration 2332 : loss : 0.038932, loss_ce: 0.015293
2022-01-14 15:55:04,093 iteration 2333 : loss : 0.031329, loss_ce: 0.014914
2022-01-14 15:55:05,560 iteration 2334 : loss : 0.024873, loss_ce: 0.011903
2022-01-14 15:55:07,036 iteration 2335 : loss : 0.040926, loss_ce: 0.016126
2022-01-14 15:55:08,568 iteration 2336 : loss : 0.044478, loss_ce: 0.014175
2022-01-14 15:55:10,089 iteration 2337 : loss : 0.029684, loss_ce: 0.014536
2022-01-14 15:55:11,555 iteration 2338 : loss : 0.023791, loss_ce: 0.009307
2022-01-14 15:55:13,061 iteration 2339 : loss : 0.026593, loss_ce: 0.009530
2022-01-14 15:55:14,605 iteration 2340 : loss : 0.041202, loss_ce: 0.019201
2022-01-14 15:55:16,018 iteration 2341 : loss : 0.028355, loss_ce: 0.007555
2022-01-14 15:55:17,516 iteration 2342 : loss : 0.038802, loss_ce: 0.017628
2022-01-14 15:55:19,066 iteration 2343 : loss : 0.053512, loss_ce: 0.022892
2022-01-14 15:55:20,584 iteration 2344 : loss : 0.029423, loss_ce: 0.010890
2022-01-14 15:55:22,129 iteration 2345 : loss : 0.046894, loss_ce: 0.017917
2022-01-14 15:55:23,629 iteration 2346 : loss : 0.029974, loss_ce: 0.012748
 34%|█████████▎                 | 138/400 [1:03:16<1:56:18, 26.64s/it]2022-01-14 15:55:25,168 iteration 2347 : loss : 0.026370, loss_ce: 0.009984
2022-01-14 15:55:26,640 iteration 2348 : loss : 0.038729, loss_ce: 0.014960
2022-01-14 15:55:28,187 iteration 2349 : loss : 0.033346, loss_ce: 0.014161
2022-01-14 15:55:29,655 iteration 2350 : loss : 0.036962, loss_ce: 0.013925
2022-01-14 15:55:31,176 iteration 2351 : loss : 0.087987, loss_ce: 0.024493
2022-01-14 15:55:32,671 iteration 2352 : loss : 0.036176, loss_ce: 0.012469
2022-01-14 15:55:34,207 iteration 2353 : loss : 0.035579, loss_ce: 0.014656
2022-01-14 15:55:35,753 iteration 2354 : loss : 0.031989, loss_ce: 0.012765
2022-01-14 15:55:37,161 iteration 2355 : loss : 0.030708, loss_ce: 0.011748
2022-01-14 15:55:38,644 iteration 2356 : loss : 0.034533, loss_ce: 0.013781
2022-01-14 15:55:40,121 iteration 2357 : loss : 0.053797, loss_ce: 0.018371
2022-01-14 15:55:41,633 iteration 2358 : loss : 0.031509, loss_ce: 0.013761
2022-01-14 15:55:43,233 iteration 2359 : loss : 0.034128, loss_ce: 0.014829
2022-01-14 15:55:44,719 iteration 2360 : loss : 0.026003, loss_ce: 0.010408
2022-01-14 15:55:46,280 iteration 2361 : loss : 0.045399, loss_ce: 0.015838
2022-01-14 15:55:47,926 iteration 2362 : loss : 0.049551, loss_ce: 0.022199
2022-01-14 15:55:49,390 iteration 2363 : loss : 0.027315, loss_ce: 0.011970
 35%|█████████▍                 | 139/400 [1:03:42<1:54:43, 26.37s/it]2022-01-14 15:55:50,841 iteration 2364 : loss : 0.043857, loss_ce: 0.010280
2022-01-14 15:55:52,286 iteration 2365 : loss : 0.045979, loss_ce: 0.011276
2022-01-14 15:55:53,792 iteration 2366 : loss : 0.033469, loss_ce: 0.014853
2022-01-14 15:55:55,254 iteration 2367 : loss : 0.035823, loss_ce: 0.016611
2022-01-14 15:55:56,706 iteration 2368 : loss : 0.034315, loss_ce: 0.013395
2022-01-14 15:55:58,203 iteration 2369 : loss : 0.041766, loss_ce: 0.017233
2022-01-14 15:55:59,602 iteration 2370 : loss : 0.038514, loss_ce: 0.014803
2022-01-14 15:56:01,127 iteration 2371 : loss : 0.044662, loss_ce: 0.016802
2022-01-14 15:56:02,601 iteration 2372 : loss : 0.036572, loss_ce: 0.013715
2022-01-14 15:56:04,035 iteration 2373 : loss : 0.028296, loss_ce: 0.012204
2022-01-14 15:56:05,485 iteration 2374 : loss : 0.029918, loss_ce: 0.012393
2022-01-14 15:56:06,991 iteration 2375 : loss : 0.039806, loss_ce: 0.011053
2022-01-14 15:56:08,515 iteration 2376 : loss : 0.028619, loss_ce: 0.009997
2022-01-14 15:56:09,979 iteration 2377 : loss : 0.030294, loss_ce: 0.011563
2022-01-14 15:56:11,448 iteration 2378 : loss : 0.021222, loss_ce: 0.007854
2022-01-14 15:56:12,935 iteration 2379 : loss : 0.051786, loss_ce: 0.031964
2022-01-14 15:56:12,935 Training Data Eval:
2022-01-14 15:56:20,305   Average segmentation loss on training set: 0.0239
2022-01-14 15:56:20,306 Validation Data Eval:
2022-01-14 15:56:22,848   Average segmentation loss on validation set: 0.1009
2022-01-14 15:56:24,274 iteration 2380 : loss : 0.028077, loss_ce: 0.015129
 35%|█████████▍                 | 140/400 [1:04:17<2:05:21, 28.93s/it]2022-01-14 15:56:25,897 iteration 2381 : loss : 0.049408, loss_ce: 0.014083
2022-01-14 15:56:27,402 iteration 2382 : loss : 0.031211, loss_ce: 0.011178
2022-01-14 15:56:28,873 iteration 2383 : loss : 0.045057, loss_ce: 0.022015
2022-01-14 15:56:30,299 iteration 2384 : loss : 0.033442, loss_ce: 0.011642
2022-01-14 15:56:31,779 iteration 2385 : loss : 0.028432, loss_ce: 0.009311
2022-01-14 15:56:33,305 iteration 2386 : loss : 0.033854, loss_ce: 0.008896
2022-01-14 15:56:34,838 iteration 2387 : loss : 0.033996, loss_ce: 0.012810
2022-01-14 15:56:36,331 iteration 2388 : loss : 0.032692, loss_ce: 0.015652
2022-01-14 15:56:37,819 iteration 2389 : loss : 0.038245, loss_ce: 0.012655
2022-01-14 15:56:39,259 iteration 2390 : loss : 0.035912, loss_ce: 0.013201
2022-01-14 15:56:40,666 iteration 2391 : loss : 0.029597, loss_ce: 0.011199
2022-01-14 15:56:42,278 iteration 2392 : loss : 0.032404, loss_ce: 0.008267
2022-01-14 15:56:43,824 iteration 2393 : loss : 0.032854, loss_ce: 0.011516
2022-01-14 15:56:45,314 iteration 2394 : loss : 0.032480, loss_ce: 0.013653
2022-01-14 15:56:46,856 iteration 2395 : loss : 0.034099, loss_ce: 0.014470
2022-01-14 15:56:48,288 iteration 2396 : loss : 0.032702, loss_ce: 0.012474
2022-01-14 15:56:49,830 iteration 2397 : loss : 0.027665, loss_ce: 0.015021
 35%|█████████▌                 | 141/400 [1:04:43<2:00:30, 27.92s/it]2022-01-14 15:56:51,330 iteration 2398 : loss : 0.030095, loss_ce: 0.015207
2022-01-14 15:56:52,897 iteration 2399 : loss : 0.026460, loss_ce: 0.010806
2022-01-14 15:56:54,363 iteration 2400 : loss : 0.046119, loss_ce: 0.018024
2022-01-14 15:56:55,973 iteration 2401 : loss : 0.063937, loss_ce: 0.021586
2022-01-14 15:56:57,453 iteration 2402 : loss : 0.034122, loss_ce: 0.013485
2022-01-14 15:56:58,919 iteration 2403 : loss : 0.028906, loss_ce: 0.010702
2022-01-14 15:57:00,365 iteration 2404 : loss : 0.026097, loss_ce: 0.008654
2022-01-14 15:57:01,896 iteration 2405 : loss : 0.035136, loss_ce: 0.012412
2022-01-14 15:57:03,321 iteration 2406 : loss : 0.037381, loss_ce: 0.016275
2022-01-14 15:57:04,804 iteration 2407 : loss : 0.026376, loss_ce: 0.009429
2022-01-14 15:57:06,470 iteration 2408 : loss : 0.036497, loss_ce: 0.011551
2022-01-14 15:57:07,917 iteration 2409 : loss : 0.025972, loss_ce: 0.010397
2022-01-14 15:57:09,368 iteration 2410 : loss : 0.025746, loss_ce: 0.008192
2022-01-14 15:57:10,807 iteration 2411 : loss : 0.029856, loss_ce: 0.012535
2022-01-14 15:57:12,258 iteration 2412 : loss : 0.026506, loss_ce: 0.009492
2022-01-14 15:57:13,687 iteration 2413 : loss : 0.037190, loss_ce: 0.014362
2022-01-14 15:57:15,113 iteration 2414 : loss : 0.025914, loss_ce: 0.011058
 36%|█████████▌                 | 142/400 [1:05:08<1:56:38, 27.13s/it]2022-01-14 15:57:16,687 iteration 2415 : loss : 0.026025, loss_ce: 0.008167
2022-01-14 15:57:18,143 iteration 2416 : loss : 0.031111, loss_ce: 0.012767
2022-01-14 15:57:19,625 iteration 2417 : loss : 0.027418, loss_ce: 0.013188
2022-01-14 15:57:21,050 iteration 2418 : loss : 0.033369, loss_ce: 0.010605
2022-01-14 15:57:22,532 iteration 2419 : loss : 0.039698, loss_ce: 0.015180
2022-01-14 15:57:24,081 iteration 2420 : loss : 0.040477, loss_ce: 0.020552
2022-01-14 15:57:25,559 iteration 2421 : loss : 0.023923, loss_ce: 0.010711
2022-01-14 15:57:27,035 iteration 2422 : loss : 0.037572, loss_ce: 0.016112
2022-01-14 15:57:28,442 iteration 2423 : loss : 0.036734, loss_ce: 0.015376
2022-01-14 15:57:29,921 iteration 2424 : loss : 0.025999, loss_ce: 0.010065
2022-01-14 15:57:31,427 iteration 2425 : loss : 0.028932, loss_ce: 0.010188
2022-01-14 15:57:32,897 iteration 2426 : loss : 0.028060, loss_ce: 0.009866
2022-01-14 15:57:34,318 iteration 2427 : loss : 0.023865, loss_ce: 0.011677
2022-01-14 15:57:35,775 iteration 2428 : loss : 0.023673, loss_ce: 0.006993
2022-01-14 15:57:37,209 iteration 2429 : loss : 0.044488, loss_ce: 0.013760
2022-01-14 15:57:38,679 iteration 2430 : loss : 0.032408, loss_ce: 0.013173
2022-01-14 15:57:40,179 iteration 2431 : loss : 0.035657, loss_ce: 0.009762
 36%|█████████▋                 | 143/400 [1:05:33<1:53:32, 26.51s/it]2022-01-14 15:57:41,631 iteration 2432 : loss : 0.029082, loss_ce: 0.009737
2022-01-14 15:57:43,078 iteration 2433 : loss : 0.039477, loss_ce: 0.022234
2022-01-14 15:57:44,583 iteration 2434 : loss : 0.031265, loss_ce: 0.012190
2022-01-14 15:57:46,055 iteration 2435 : loss : 0.023750, loss_ce: 0.009598
2022-01-14 15:57:47,600 iteration 2436 : loss : 0.030713, loss_ce: 0.011237
2022-01-14 15:57:49,076 iteration 2437 : loss : 0.028217, loss_ce: 0.010768
2022-01-14 15:57:50,489 iteration 2438 : loss : 0.022369, loss_ce: 0.008940
2022-01-14 15:57:51,953 iteration 2439 : loss : 0.029262, loss_ce: 0.011168
2022-01-14 15:57:53,424 iteration 2440 : loss : 0.031648, loss_ce: 0.011374
2022-01-14 15:57:55,004 iteration 2441 : loss : 0.059608, loss_ce: 0.017315
2022-01-14 15:57:56,519 iteration 2442 : loss : 0.026713, loss_ce: 0.008627
2022-01-14 15:57:58,034 iteration 2443 : loss : 0.026716, loss_ce: 0.009889
2022-01-14 15:57:59,545 iteration 2444 : loss : 0.039408, loss_ce: 0.014617
2022-01-14 15:58:01,124 iteration 2445 : loss : 0.028989, loss_ce: 0.010281
2022-01-14 15:58:02,576 iteration 2446 : loss : 0.033748, loss_ce: 0.012641
2022-01-14 15:58:04,119 iteration 2447 : loss : 0.038491, loss_ce: 0.014812
2022-01-14 15:58:05,549 iteration 2448 : loss : 0.061707, loss_ce: 0.034946
 36%|█████████▋                 | 144/400 [1:05:58<1:51:38, 26.17s/it]2022-01-14 15:58:07,069 iteration 2449 : loss : 0.026031, loss_ce: 0.006903
2022-01-14 15:58:08,490 iteration 2450 : loss : 0.027292, loss_ce: 0.010415
2022-01-14 15:58:09,909 iteration 2451 : loss : 0.035296, loss_ce: 0.012809
2022-01-14 15:58:11,359 iteration 2452 : loss : 0.048076, loss_ce: 0.027959
2022-01-14 15:58:12,820 iteration 2453 : loss : 0.028700, loss_ce: 0.012585
2022-01-14 15:58:14,288 iteration 2454 : loss : 0.033588, loss_ce: 0.011926
2022-01-14 15:58:15,873 iteration 2455 : loss : 0.032908, loss_ce: 0.014284
2022-01-14 15:58:17,366 iteration 2456 : loss : 0.026853, loss_ce: 0.013164
2022-01-14 15:58:18,808 iteration 2457 : loss : 0.030560, loss_ce: 0.014361
2022-01-14 15:58:20,314 iteration 2458 : loss : 0.047117, loss_ce: 0.016307
2022-01-14 15:58:21,783 iteration 2459 : loss : 0.024038, loss_ce: 0.008749
2022-01-14 15:58:23,313 iteration 2460 : loss : 0.036511, loss_ce: 0.010989
2022-01-14 15:58:24,826 iteration 2461 : loss : 0.033298, loss_ce: 0.009113
2022-01-14 15:58:26,416 iteration 2462 : loss : 0.038895, loss_ce: 0.018034
2022-01-14 15:58:27,870 iteration 2463 : loss : 0.034225, loss_ce: 0.013267
2022-01-14 15:58:29,359 iteration 2464 : loss : 0.052023, loss_ce: 0.034193
2022-01-14 15:58:29,359 Training Data Eval:
2022-01-14 15:58:36,738   Average segmentation loss on training set: 0.0355
2022-01-14 15:58:36,738 Validation Data Eval:
2022-01-14 15:58:39,284   Average segmentation loss on validation set: 0.0796
2022-01-14 15:58:40,765 iteration 2465 : loss : 0.027205, loss_ce: 0.011186
 36%|█████████▊                 | 145/400 [1:06:34<2:02:44, 28.88s/it]2022-01-14 15:58:42,313 iteration 2466 : loss : 0.026386, loss_ce: 0.009300
2022-01-14 15:58:43,769 iteration 2467 : loss : 0.021557, loss_ce: 0.007793
2022-01-14 15:58:45,320 iteration 2468 : loss : 0.032658, loss_ce: 0.011588
2022-01-14 15:58:46,749 iteration 2469 : loss : 0.032030, loss_ce: 0.014106
2022-01-14 15:58:48,266 iteration 2470 : loss : 0.043831, loss_ce: 0.016762
2022-01-14 15:58:49,770 iteration 2471 : loss : 0.029082, loss_ce: 0.014871
2022-01-14 15:58:51,276 iteration 2472 : loss : 0.026069, loss_ce: 0.009433
2022-01-14 15:58:52,749 iteration 2473 : loss : 0.023304, loss_ce: 0.008677
2022-01-14 15:58:54,130 iteration 2474 : loss : 0.024994, loss_ce: 0.010888
2022-01-14 15:58:55,637 iteration 2475 : loss : 0.034379, loss_ce: 0.019162
2022-01-14 15:58:57,138 iteration 2476 : loss : 0.032383, loss_ce: 0.010824
2022-01-14 15:58:58,648 iteration 2477 : loss : 0.027212, loss_ce: 0.010104
2022-01-14 15:59:00,128 iteration 2478 : loss : 0.032699, loss_ce: 0.009531
2022-01-14 15:59:01,651 iteration 2479 : loss : 0.028883, loss_ce: 0.008773
2022-01-14 15:59:03,114 iteration 2480 : loss : 0.022386, loss_ce: 0.007551
2022-01-14 15:59:04,556 iteration 2481 : loss : 0.026451, loss_ce: 0.011300
2022-01-14 15:59:06,139 iteration 2482 : loss : 0.046354, loss_ce: 0.017801
 36%|█████████▊                 | 146/400 [1:06:59<1:57:48, 27.83s/it]2022-01-14 15:59:07,645 iteration 2483 : loss : 0.036834, loss_ce: 0.016142
2022-01-14 15:59:09,148 iteration 2484 : loss : 0.042644, loss_ce: 0.009368
2022-01-14 15:59:10,646 iteration 2485 : loss : 0.038127, loss_ce: 0.011966
2022-01-14 15:59:12,133 iteration 2486 : loss : 0.033706, loss_ce: 0.014893
2022-01-14 15:59:13,558 iteration 2487 : loss : 0.021194, loss_ce: 0.009057
2022-01-14 15:59:15,093 iteration 2488 : loss : 0.030597, loss_ce: 0.015187
2022-01-14 15:59:16,607 iteration 2489 : loss : 0.029560, loss_ce: 0.012223
2022-01-14 15:59:18,155 iteration 2490 : loss : 0.049787, loss_ce: 0.021339
2022-01-14 15:59:19,651 iteration 2491 : loss : 0.028573, loss_ce: 0.008735
2022-01-14 15:59:21,155 iteration 2492 : loss : 0.035519, loss_ce: 0.013773
2022-01-14 15:59:22,592 iteration 2493 : loss : 0.029582, loss_ce: 0.010814
2022-01-14 15:59:24,064 iteration 2494 : loss : 0.031895, loss_ce: 0.011478
2022-01-14 15:59:25,617 iteration 2495 : loss : 0.023025, loss_ce: 0.009800
2022-01-14 15:59:26,985 iteration 2496 : loss : 0.018412, loss_ce: 0.007032
2022-01-14 15:59:28,414 iteration 2497 : loss : 0.024733, loss_ce: 0.008401
2022-01-14 15:59:30,016 iteration 2498 : loss : 0.025874, loss_ce: 0.009184
2022-01-14 15:59:31,499 iteration 2499 : loss : 0.031891, loss_ce: 0.013883
 37%|█████████▉                 | 147/400 [1:07:24<1:54:13, 27.09s/it]2022-01-14 15:59:33,035 iteration 2500 : loss : 0.033386, loss_ce: 0.013656
2022-01-14 15:59:34,544 iteration 2501 : loss : 0.026830, loss_ce: 0.011309
2022-01-14 15:59:36,053 iteration 2502 : loss : 0.026677, loss_ce: 0.013215
2022-01-14 15:59:37,516 iteration 2503 : loss : 0.025102, loss_ce: 0.012374
2022-01-14 15:59:39,025 iteration 2504 : loss : 0.032980, loss_ce: 0.011318
2022-01-14 15:59:40,514 iteration 2505 : loss : 0.035250, loss_ce: 0.012079
2022-01-14 15:59:42,015 iteration 2506 : loss : 0.018819, loss_ce: 0.007678
2022-01-14 15:59:43,449 iteration 2507 : loss : 0.019110, loss_ce: 0.006894
2022-01-14 15:59:44,844 iteration 2508 : loss : 0.023348, loss_ce: 0.009516
2022-01-14 15:59:46,296 iteration 2509 : loss : 0.023092, loss_ce: 0.010027
2022-01-14 15:59:47,711 iteration 2510 : loss : 0.036715, loss_ce: 0.010655
2022-01-14 15:59:49,172 iteration 2511 : loss : 0.026194, loss_ce: 0.011116
2022-01-14 15:59:50,647 iteration 2512 : loss : 0.030855, loss_ce: 0.012270
2022-01-14 15:59:52,112 iteration 2513 : loss : 0.058968, loss_ce: 0.026115
2022-01-14 15:59:53,598 iteration 2514 : loss : 0.027779, loss_ce: 0.010379
2022-01-14 15:59:55,055 iteration 2515 : loss : 0.047296, loss_ce: 0.015707
2022-01-14 15:59:56,483 iteration 2516 : loss : 0.032245, loss_ce: 0.014859
 37%|█████████▉                 | 148/400 [1:07:49<1:51:07, 26.46s/it]2022-01-14 15:59:57,976 iteration 2517 : loss : 0.027649, loss_ce: 0.010290
2022-01-14 15:59:59,560 iteration 2518 : loss : 0.031735, loss_ce: 0.012747
2022-01-14 16:00:01,037 iteration 2519 : loss : 0.035066, loss_ce: 0.011468
2022-01-14 16:00:02,487 iteration 2520 : loss : 0.028162, loss_ce: 0.008878
2022-01-14 16:00:03,990 iteration 2521 : loss : 0.026207, loss_ce: 0.012555
2022-01-14 16:00:05,404 iteration 2522 : loss : 0.021484, loss_ce: 0.007998
2022-01-14 16:00:06,767 iteration 2523 : loss : 0.032771, loss_ce: 0.008206
2022-01-14 16:00:08,279 iteration 2524 : loss : 0.026411, loss_ce: 0.012940
2022-01-14 16:00:09,717 iteration 2525 : loss : 0.027905, loss_ce: 0.011119
2022-01-14 16:00:11,152 iteration 2526 : loss : 0.031339, loss_ce: 0.011243
2022-01-14 16:00:12,687 iteration 2527 : loss : 0.028226, loss_ce: 0.009406
2022-01-14 16:00:14,128 iteration 2528 : loss : 0.037652, loss_ce: 0.013967
2022-01-14 16:00:15,621 iteration 2529 : loss : 0.030085, loss_ce: 0.011477
2022-01-14 16:00:17,095 iteration 2530 : loss : 0.026818, loss_ce: 0.007640
2022-01-14 16:00:18,554 iteration 2531 : loss : 0.035305, loss_ce: 0.011821
2022-01-14 16:00:20,054 iteration 2532 : loss : 0.031269, loss_ce: 0.010590
2022-01-14 16:00:21,536 iteration 2533 : loss : 0.031714, loss_ce: 0.017521
 37%|██████████                 | 149/400 [1:08:14<1:48:55, 26.04s/it]2022-01-14 16:00:22,995 iteration 2534 : loss : 0.019696, loss_ce: 0.008367
2022-01-14 16:00:24,494 iteration 2535 : loss : 0.023206, loss_ce: 0.006462
2022-01-14 16:00:26,055 iteration 2536 : loss : 0.029477, loss_ce: 0.015818
2022-01-14 16:00:27,624 iteration 2537 : loss : 0.050105, loss_ce: 0.015276
2022-01-14 16:00:29,205 iteration 2538 : loss : 0.043296, loss_ce: 0.016113
2022-01-14 16:00:30,658 iteration 2539 : loss : 0.025711, loss_ce: 0.009869
2022-01-14 16:00:32,132 iteration 2540 : loss : 0.042221, loss_ce: 0.014791
2022-01-14 16:00:33,723 iteration 2541 : loss : 0.052118, loss_ce: 0.015367
2022-01-14 16:00:35,138 iteration 2542 : loss : 0.027239, loss_ce: 0.009764
2022-01-14 16:00:36,607 iteration 2543 : loss : 0.032330, loss_ce: 0.011632
2022-01-14 16:00:38,157 iteration 2544 : loss : 0.037621, loss_ce: 0.015998
2022-01-14 16:00:39,679 iteration 2545 : loss : 0.034870, loss_ce: 0.016678
2022-01-14 16:00:41,105 iteration 2546 : loss : 0.027383, loss_ce: 0.010268
2022-01-14 16:00:42,580 iteration 2547 : loss : 0.063663, loss_ce: 0.013023
2022-01-14 16:00:44,042 iteration 2548 : loss : 0.029197, loss_ce: 0.011136
2022-01-14 16:00:45,568 iteration 2549 : loss : 0.045544, loss_ce: 0.015324
2022-01-14 16:00:45,568 Training Data Eval:
2022-01-14 16:00:52,938   Average segmentation loss on training set: 0.0208
2022-01-14 16:00:52,939 Validation Data Eval:
2022-01-14 16:00:55,479   Average segmentation loss on validation set: 0.0901
2022-01-14 16:00:56,933 iteration 2550 : loss : 0.031773, loss_ce: 0.017418
 38%|██████████▏                | 150/400 [1:08:50<2:00:10, 28.84s/it]2022-01-14 16:00:58,420 iteration 2551 : loss : 0.022484, loss_ce: 0.008075
2022-01-14 16:00:59,892 iteration 2552 : loss : 0.024979, loss_ce: 0.009338
2022-01-14 16:01:01,434 iteration 2553 : loss : 0.032754, loss_ce: 0.011736
2022-01-14 16:01:02,948 iteration 2554 : loss : 0.078601, loss_ce: 0.015733
2022-01-14 16:01:04,407 iteration 2555 : loss : 0.028068, loss_ce: 0.006965
2022-01-14 16:01:05,812 iteration 2556 : loss : 0.026600, loss_ce: 0.010767
2022-01-14 16:01:07,331 iteration 2557 : loss : 0.033214, loss_ce: 0.016359
2022-01-14 16:01:08,848 iteration 2558 : loss : 0.025357, loss_ce: 0.011480
2022-01-14 16:01:10,381 iteration 2559 : loss : 0.042527, loss_ce: 0.010124
2022-01-14 16:01:11,905 iteration 2560 : loss : 0.029986, loss_ce: 0.012210
2022-01-14 16:01:13,369 iteration 2561 : loss : 0.028946, loss_ce: 0.011274
2022-01-14 16:01:14,799 iteration 2562 : loss : 0.024957, loss_ce: 0.012560
2022-01-14 16:01:16,258 iteration 2563 : loss : 0.036232, loss_ce: 0.010696
2022-01-14 16:01:17,726 iteration 2564 : loss : 0.030476, loss_ce: 0.012742
2022-01-14 16:01:19,193 iteration 2565 : loss : 0.039337, loss_ce: 0.009842
2022-01-14 16:01:20,641 iteration 2566 : loss : 0.029606, loss_ce: 0.013465
2022-01-14 16:01:22,203 iteration 2567 : loss : 0.046252, loss_ce: 0.018485
 38%|██████████▏                | 151/400 [1:09:15<1:55:15, 27.77s/it]2022-01-14 16:01:23,721 iteration 2568 : loss : 0.025561, loss_ce: 0.011165
2022-01-14 16:01:25,196 iteration 2569 : loss : 0.041946, loss_ce: 0.015055
2022-01-14 16:01:26,642 iteration 2570 : loss : 0.044566, loss_ce: 0.013100
2022-01-14 16:01:28,120 iteration 2571 : loss : 0.037960, loss_ce: 0.013798
2022-01-14 16:01:29,529 iteration 2572 : loss : 0.026514, loss_ce: 0.007963
2022-01-14 16:01:30,960 iteration 2573 : loss : 0.022348, loss_ce: 0.008778
2022-01-14 16:01:32,420 iteration 2574 : loss : 0.022928, loss_ce: 0.007724
2022-01-14 16:01:33,919 iteration 2575 : loss : 0.029732, loss_ce: 0.009508
2022-01-14 16:01:35,493 iteration 2576 : loss : 0.038708, loss_ce: 0.018885
2022-01-14 16:01:36,945 iteration 2577 : loss : 0.035249, loss_ce: 0.011247
2022-01-14 16:01:38,442 iteration 2578 : loss : 0.036969, loss_ce: 0.020696
2022-01-14 16:01:39,893 iteration 2579 : loss : 0.035488, loss_ce: 0.013013
2022-01-14 16:01:41,402 iteration 2580 : loss : 0.023200, loss_ce: 0.007066
2022-01-14 16:01:42,986 iteration 2581 : loss : 0.037793, loss_ce: 0.012751
2022-01-14 16:01:44,361 iteration 2582 : loss : 0.030802, loss_ce: 0.012786
2022-01-14 16:01:45,877 iteration 2583 : loss : 0.022471, loss_ce: 0.007521
2022-01-14 16:01:47,341 iteration 2584 : loss : 0.021882, loss_ce: 0.008454
 38%|██████████▎                | 152/400 [1:09:40<1:51:31, 26.98s/it]2022-01-14 16:01:48,906 iteration 2585 : loss : 0.048914, loss_ce: 0.021925
2022-01-14 16:01:50,385 iteration 2586 : loss : 0.050408, loss_ce: 0.026656
2022-01-14 16:01:51,804 iteration 2587 : loss : 0.020686, loss_ce: 0.007075
2022-01-14 16:01:53,253 iteration 2588 : loss : 0.028777, loss_ce: 0.012018
2022-01-14 16:01:54,653 iteration 2589 : loss : 0.027368, loss_ce: 0.010280
2022-01-14 16:01:56,168 iteration 2590 : loss : 0.038304, loss_ce: 0.013165
2022-01-14 16:01:57,636 iteration 2591 : loss : 0.027838, loss_ce: 0.012475
2022-01-14 16:01:59,091 iteration 2592 : loss : 0.024766, loss_ce: 0.009815
2022-01-14 16:02:00,530 iteration 2593 : loss : 0.038484, loss_ce: 0.011924
2022-01-14 16:02:02,039 iteration 2594 : loss : 0.027745, loss_ce: 0.009313
2022-01-14 16:02:03,618 iteration 2595 : loss : 0.038367, loss_ce: 0.012782
2022-01-14 16:02:05,030 iteration 2596 : loss : 0.024417, loss_ce: 0.008007
2022-01-14 16:02:06,513 iteration 2597 : loss : 0.044261, loss_ce: 0.014083
2022-01-14 16:02:07,957 iteration 2598 : loss : 0.027401, loss_ce: 0.012135
2022-01-14 16:02:09,473 iteration 2599 : loss : 0.022112, loss_ce: 0.009654
2022-01-14 16:02:10,943 iteration 2600 : loss : 0.032959, loss_ce: 0.010952
2022-01-14 16:02:12,436 iteration 2601 : loss : 0.030876, loss_ce: 0.011689
 38%|██████████▎                | 153/400 [1:10:05<1:48:44, 26.42s/it]2022-01-14 16:02:13,977 iteration 2602 : loss : 0.025566, loss_ce: 0.008164
2022-01-14 16:02:15,546 iteration 2603 : loss : 0.030568, loss_ce: 0.011438
2022-01-14 16:02:17,023 iteration 2604 : loss : 0.041119, loss_ce: 0.017789
2022-01-14 16:02:18,381 iteration 2605 : loss : 0.021721, loss_ce: 0.006187
2022-01-14 16:02:19,987 iteration 2606 : loss : 0.038877, loss_ce: 0.012610
2022-01-14 16:02:21,507 iteration 2607 : loss : 0.035034, loss_ce: 0.012984
2022-01-14 16:02:22,989 iteration 2608 : loss : 0.024010, loss_ce: 0.011317
2022-01-14 16:02:24,562 iteration 2609 : loss : 0.033313, loss_ce: 0.011945
2022-01-14 16:02:26,088 iteration 2610 : loss : 0.035193, loss_ce: 0.013254
2022-01-14 16:02:27,593 iteration 2611 : loss : 0.030209, loss_ce: 0.012670
2022-01-14 16:02:29,128 iteration 2612 : loss : 0.037056, loss_ce: 0.022845
2022-01-14 16:02:30,559 iteration 2613 : loss : 0.026031, loss_ce: 0.011575
2022-01-14 16:02:32,109 iteration 2614 : loss : 0.033365, loss_ce: 0.010772
2022-01-14 16:02:33,555 iteration 2615 : loss : 0.037399, loss_ce: 0.013573
2022-01-14 16:02:35,069 iteration 2616 : loss : 0.029615, loss_ce: 0.016034
2022-01-14 16:02:36,536 iteration 2617 : loss : 0.032113, loss_ce: 0.009577
2022-01-14 16:02:37,969 iteration 2618 : loss : 0.024414, loss_ce: 0.010102
 38%|██████████▍                | 154/400 [1:10:31<1:47:13, 26.15s/it]2022-01-14 16:02:39,459 iteration 2619 : loss : 0.029791, loss_ce: 0.009019
2022-01-14 16:02:40,908 iteration 2620 : loss : 0.021291, loss_ce: 0.009885
2022-01-14 16:02:42,438 iteration 2621 : loss : 0.044504, loss_ce: 0.015711
2022-01-14 16:02:43,900 iteration 2622 : loss : 0.036870, loss_ce: 0.008632
2022-01-14 16:02:45,400 iteration 2623 : loss : 0.031869, loss_ce: 0.014397
2022-01-14 16:02:46,834 iteration 2624 : loss : 0.023782, loss_ce: 0.008061
2022-01-14 16:02:48,331 iteration 2625 : loss : 0.031880, loss_ce: 0.006328
2022-01-14 16:02:49,825 iteration 2626 : loss : 0.037696, loss_ce: 0.014911
2022-01-14 16:02:51,444 iteration 2627 : loss : 0.029027, loss_ce: 0.010052
2022-01-14 16:02:52,861 iteration 2628 : loss : 0.034115, loss_ce: 0.017914
2022-01-14 16:02:54,394 iteration 2629 : loss : 0.032126, loss_ce: 0.015842
2022-01-14 16:02:55,922 iteration 2630 : loss : 0.038045, loss_ce: 0.015853
2022-01-14 16:02:57,420 iteration 2631 : loss : 0.027316, loss_ce: 0.011086
2022-01-14 16:02:58,891 iteration 2632 : loss : 0.025363, loss_ce: 0.009314
2022-01-14 16:03:00,398 iteration 2633 : loss : 0.029597, loss_ce: 0.016305
2022-01-14 16:03:01,895 iteration 2634 : loss : 0.036457, loss_ce: 0.011921
2022-01-14 16:03:01,895 Training Data Eval:
2022-01-14 16:03:09,264   Average segmentation loss on training set: 0.0205
2022-01-14 16:03:09,264 Validation Data Eval:
2022-01-14 16:03:11,810   Average segmentation loss on validation set: 0.0834
2022-01-14 16:03:13,338 iteration 2635 : loss : 0.022453, loss_ce: 0.008076
 39%|██████████▍                | 155/400 [1:11:06<1:58:04, 28.92s/it]2022-01-14 16:03:14,862 iteration 2636 : loss : 0.029466, loss_ce: 0.014129
2022-01-14 16:03:16,416 iteration 2637 : loss : 0.037771, loss_ce: 0.014781
2022-01-14 16:03:17,869 iteration 2638 : loss : 0.040534, loss_ce: 0.016139
2022-01-14 16:03:19,296 iteration 2639 : loss : 0.026215, loss_ce: 0.013052
2022-01-14 16:03:20,748 iteration 2640 : loss : 0.025687, loss_ce: 0.008523
2022-01-14 16:03:22,210 iteration 2641 : loss : 0.035049, loss_ce: 0.015676
2022-01-14 16:03:23,642 iteration 2642 : loss : 0.021911, loss_ce: 0.008388
2022-01-14 16:03:25,228 iteration 2643 : loss : 0.030203, loss_ce: 0.010028
2022-01-14 16:03:26,683 iteration 2644 : loss : 0.039355, loss_ce: 0.015896
2022-01-14 16:03:28,114 iteration 2645 : loss : 0.022509, loss_ce: 0.008136
2022-01-14 16:03:29,756 iteration 2646 : loss : 0.033214, loss_ce: 0.012801
2022-01-14 16:03:31,297 iteration 2647 : loss : 0.039003, loss_ce: 0.017086
2022-01-14 16:03:32,768 iteration 2648 : loss : 0.033297, loss_ce: 0.015118
2022-01-14 16:03:34,262 iteration 2649 : loss : 0.033721, loss_ce: 0.014140
2022-01-14 16:03:35,796 iteration 2650 : loss : 0.021705, loss_ce: 0.006848
2022-01-14 16:03:37,300 iteration 2651 : loss : 0.032159, loss_ce: 0.014772
2022-01-14 16:03:38,723 iteration 2652 : loss : 0.025812, loss_ce: 0.009313
 39%|██████████▌                | 156/400 [1:11:32<1:53:17, 27.86s/it]2022-01-14 16:03:40,330 iteration 2653 : loss : 0.021924, loss_ce: 0.009389
2022-01-14 16:03:41,840 iteration 2654 : loss : 0.025420, loss_ce: 0.008333
2022-01-14 16:03:43,411 iteration 2655 : loss : 0.026736, loss_ce: 0.013469
2022-01-14 16:03:44,873 iteration 2656 : loss : 0.031779, loss_ce: 0.010234
2022-01-14 16:03:46,344 iteration 2657 : loss : 0.033851, loss_ce: 0.011891
2022-01-14 16:03:47,707 iteration 2658 : loss : 0.022279, loss_ce: 0.011752
2022-01-14 16:03:49,125 iteration 2659 : loss : 0.047519, loss_ce: 0.012663
2022-01-14 16:03:50,639 iteration 2660 : loss : 0.028066, loss_ce: 0.008506
2022-01-14 16:03:52,081 iteration 2661 : loss : 0.021972, loss_ce: 0.010166
2022-01-14 16:03:53,543 iteration 2662 : loss : 0.033119, loss_ce: 0.015246
2022-01-14 16:03:54,987 iteration 2663 : loss : 0.031274, loss_ce: 0.008494
2022-01-14 16:03:56,556 iteration 2664 : loss : 0.052106, loss_ce: 0.024847
2022-01-14 16:03:58,043 iteration 2665 : loss : 0.029553, loss_ce: 0.011980
2022-01-14 16:03:59,483 iteration 2666 : loss : 0.020086, loss_ce: 0.006703
2022-01-14 16:04:01,018 iteration 2667 : loss : 0.030132, loss_ce: 0.010952
2022-01-14 16:04:02,462 iteration 2668 : loss : 0.039944, loss_ce: 0.019433
2022-01-14 16:04:03,905 iteration 2669 : loss : 0.028409, loss_ce: 0.009994
 39%|██████████▌                | 157/400 [1:11:57<1:49:34, 27.05s/it]2022-01-14 16:04:05,455 iteration 2670 : loss : 0.030885, loss_ce: 0.012353
2022-01-14 16:04:07,045 iteration 2671 : loss : 0.055855, loss_ce: 0.021167
2022-01-14 16:04:08,558 iteration 2672 : loss : 0.021409, loss_ce: 0.007899
2022-01-14 16:04:09,983 iteration 2673 : loss : 0.021678, loss_ce: 0.010475
2022-01-14 16:04:11,488 iteration 2674 : loss : 0.038351, loss_ce: 0.016552
2022-01-14 16:04:12,856 iteration 2675 : loss : 0.020673, loss_ce: 0.008839
2022-01-14 16:04:14,438 iteration 2676 : loss : 0.037053, loss_ce: 0.009184
2022-01-14 16:04:15,950 iteration 2677 : loss : 0.032874, loss_ce: 0.011523
2022-01-14 16:04:17,422 iteration 2678 : loss : 0.027908, loss_ce: 0.011287
2022-01-14 16:04:18,909 iteration 2679 : loss : 0.036721, loss_ce: 0.012138
2022-01-14 16:04:20,377 iteration 2680 : loss : 0.029052, loss_ce: 0.012300
2022-01-14 16:04:21,863 iteration 2681 : loss : 0.024078, loss_ce: 0.007107
2022-01-14 16:04:23,377 iteration 2682 : loss : 0.031018, loss_ce: 0.011656
2022-01-14 16:04:24,843 iteration 2683 : loss : 0.034034, loss_ce: 0.008231
2022-01-14 16:04:26,269 iteration 2684 : loss : 0.031557, loss_ce: 0.017022
2022-01-14 16:04:27,758 iteration 2685 : loss : 0.021012, loss_ce: 0.008296
2022-01-14 16:04:29,180 iteration 2686 : loss : 0.041113, loss_ce: 0.018072
 40%|██████████▋                | 158/400 [1:12:22<1:46:58, 26.52s/it]2022-01-14 16:04:30,609 iteration 2687 : loss : 0.034015, loss_ce: 0.008918
2022-01-14 16:04:32,086 iteration 2688 : loss : 0.034882, loss_ce: 0.010587
2022-01-14 16:04:33,533 iteration 2689 : loss : 0.023940, loss_ce: 0.009175
2022-01-14 16:04:35,111 iteration 2690 : loss : 0.033366, loss_ce: 0.013416
2022-01-14 16:04:36,525 iteration 2691 : loss : 0.020128, loss_ce: 0.008047
2022-01-14 16:04:37,955 iteration 2692 : loss : 0.027060, loss_ce: 0.008193
2022-01-14 16:04:39,434 iteration 2693 : loss : 0.034126, loss_ce: 0.010696
2022-01-14 16:04:40,983 iteration 2694 : loss : 0.038926, loss_ce: 0.014205
2022-01-14 16:04:42,433 iteration 2695 : loss : 0.027699, loss_ce: 0.009703
2022-01-14 16:04:43,925 iteration 2696 : loss : 0.033912, loss_ce: 0.015864
2022-01-14 16:04:45,341 iteration 2697 : loss : 0.026253, loss_ce: 0.012464
2022-01-14 16:04:46,687 iteration 2698 : loss : 0.019902, loss_ce: 0.009030
2022-01-14 16:04:48,164 iteration 2699 : loss : 0.025303, loss_ce: 0.009356
2022-01-14 16:04:49,694 iteration 2700 : loss : 0.028012, loss_ce: 0.013447
2022-01-14 16:04:51,169 iteration 2701 : loss : 0.039646, loss_ce: 0.016031
2022-01-14 16:04:52,679 iteration 2702 : loss : 0.088145, loss_ce: 0.016429
2022-01-14 16:04:54,146 iteration 2703 : loss : 0.022938, loss_ce: 0.008576
 40%|██████████▋                | 159/400 [1:12:47<1:44:39, 26.05s/it]2022-01-14 16:04:55,767 iteration 2704 : loss : 0.037539, loss_ce: 0.014316
2022-01-14 16:04:57,199 iteration 2705 : loss : 0.030562, loss_ce: 0.007983
2022-01-14 16:04:58,632 iteration 2706 : loss : 0.032919, loss_ce: 0.017104
2022-01-14 16:05:00,182 iteration 2707 : loss : 0.033201, loss_ce: 0.008704
2022-01-14 16:05:01,578 iteration 2708 : loss : 0.025438, loss_ce: 0.009250
2022-01-14 16:05:03,051 iteration 2709 : loss : 0.034717, loss_ce: 0.008154
2022-01-14 16:05:04,474 iteration 2710 : loss : 0.023682, loss_ce: 0.008058
2022-01-14 16:05:06,042 iteration 2711 : loss : 0.043930, loss_ce: 0.013717
2022-01-14 16:05:07,478 iteration 2712 : loss : 0.018462, loss_ce: 0.006826
2022-01-14 16:05:09,116 iteration 2713 : loss : 0.048101, loss_ce: 0.016492
2022-01-14 16:05:10,554 iteration 2714 : loss : 0.026122, loss_ce: 0.008453
2022-01-14 16:05:12,085 iteration 2715 : loss : 0.031704, loss_ce: 0.014858
2022-01-14 16:05:13,528 iteration 2716 : loss : 0.041582, loss_ce: 0.013930
2022-01-14 16:05:14,940 iteration 2717 : loss : 0.019856, loss_ce: 0.009471
2022-01-14 16:05:16,362 iteration 2718 : loss : 0.027961, loss_ce: 0.009450
2022-01-14 16:05:17,890 iteration 2719 : loss : 0.056583, loss_ce: 0.019959
2022-01-14 16:05:17,891 Training Data Eval:
2022-01-14 16:05:25,260   Average segmentation loss on training set: 0.0293
2022-01-14 16:05:25,261 Validation Data Eval:
2022-01-14 16:05:27,797   Average segmentation loss on validation set: 0.1882
2022-01-14 16:05:29,202 iteration 2720 : loss : 0.025401, loss_ce: 0.010483
 40%|██████████▊                | 160/400 [1:13:22<1:55:01, 28.76s/it]2022-01-14 16:05:30,730 iteration 2721 : loss : 0.031438, loss_ce: 0.011977
2022-01-14 16:05:32,229 iteration 2722 : loss : 0.031802, loss_ce: 0.014119
2022-01-14 16:05:33,739 iteration 2723 : loss : 0.019680, loss_ce: 0.007006
2022-01-14 16:05:35,154 iteration 2724 : loss : 0.036891, loss_ce: 0.013495
2022-01-14 16:05:36,534 iteration 2725 : loss : 0.027984, loss_ce: 0.009630
2022-01-14 16:05:37,968 iteration 2726 : loss : 0.032450, loss_ce: 0.011942
2022-01-14 16:05:39,361 iteration 2727 : loss : 0.021266, loss_ce: 0.006696
2022-01-14 16:05:40,940 iteration 2728 : loss : 0.043119, loss_ce: 0.018668
2022-01-14 16:05:42,422 iteration 2729 : loss : 0.051208, loss_ce: 0.022565
2022-01-14 16:05:43,935 iteration 2730 : loss : 0.023678, loss_ce: 0.009831
2022-01-14 16:05:45,439 iteration 2731 : loss : 0.028069, loss_ce: 0.011026
2022-01-14 16:05:47,009 iteration 2732 : loss : 0.033415, loss_ce: 0.012460
2022-01-14 16:05:48,511 iteration 2733 : loss : 0.035119, loss_ce: 0.013974
2022-01-14 16:05:50,010 iteration 2734 : loss : 0.037754, loss_ce: 0.012879
2022-01-14 16:05:51,400 iteration 2735 : loss : 0.026493, loss_ce: 0.010747
2022-01-14 16:05:52,924 iteration 2736 : loss : 0.033561, loss_ce: 0.015906
2022-01-14 16:05:54,380 iteration 2737 : loss : 0.027666, loss_ce: 0.009561
 40%|██████████▊                | 161/400 [1:13:47<1:50:15, 27.68s/it]2022-01-14 16:05:55,883 iteration 2738 : loss : 0.031855, loss_ce: 0.015748
2022-01-14 16:05:57,333 iteration 2739 : loss : 0.028580, loss_ce: 0.013704
2022-01-14 16:05:58,822 iteration 2740 : loss : 0.030491, loss_ce: 0.011600
2022-01-14 16:06:00,318 iteration 2741 : loss : 0.022350, loss_ce: 0.006567
2022-01-14 16:06:01,720 iteration 2742 : loss : 0.028473, loss_ce: 0.011314
2022-01-14 16:06:03,192 iteration 2743 : loss : 0.038923, loss_ce: 0.021736
2022-01-14 16:06:04,699 iteration 2744 : loss : 0.031456, loss_ce: 0.012600
2022-01-14 16:06:06,183 iteration 2745 : loss : 0.026802, loss_ce: 0.009863
2022-01-14 16:06:07,601 iteration 2746 : loss : 0.029444, loss_ce: 0.009198
2022-01-14 16:06:09,080 iteration 2747 : loss : 0.026745, loss_ce: 0.009783
2022-01-14 16:06:10,592 iteration 2748 : loss : 0.031227, loss_ce: 0.010745
2022-01-14 16:06:12,001 iteration 2749 : loss : 0.029831, loss_ce: 0.012243
2022-01-14 16:06:13,501 iteration 2750 : loss : 0.023921, loss_ce: 0.007009
2022-01-14 16:06:14,940 iteration 2751 : loss : 0.020375, loss_ce: 0.008516
2022-01-14 16:06:16,334 iteration 2752 : loss : 0.032646, loss_ce: 0.007231
2022-01-14 16:06:17,886 iteration 2753 : loss : 0.029113, loss_ce: 0.012934
2022-01-14 16:06:19,405 iteration 2754 : loss : 0.024476, loss_ce: 0.012023
 40%|██████████▉                | 162/400 [1:14:12<1:46:38, 26.89s/it]2022-01-14 16:06:20,925 iteration 2755 : loss : 0.048966, loss_ce: 0.022325
2022-01-14 16:06:22,410 iteration 2756 : loss : 0.032316, loss_ce: 0.017769
2022-01-14 16:06:23,883 iteration 2757 : loss : 0.023369, loss_ce: 0.009375
2022-01-14 16:06:25,422 iteration 2758 : loss : 0.028548, loss_ce: 0.009306
2022-01-14 16:06:26,905 iteration 2759 : loss : 0.026457, loss_ce: 0.008668
2022-01-14 16:06:28,402 iteration 2760 : loss : 0.027081, loss_ce: 0.010913
2022-01-14 16:06:29,799 iteration 2761 : loss : 0.027438, loss_ce: 0.010694
2022-01-14 16:06:31,211 iteration 2762 : loss : 0.019606, loss_ce: 0.008191
2022-01-14 16:06:32,725 iteration 2763 : loss : 0.041138, loss_ce: 0.013412
2022-01-14 16:06:34,195 iteration 2764 : loss : 0.022478, loss_ce: 0.008996
2022-01-14 16:06:35,674 iteration 2765 : loss : 0.030228, loss_ce: 0.011037
2022-01-14 16:06:37,120 iteration 2766 : loss : 0.019769, loss_ce: 0.008381
2022-01-14 16:06:38,614 iteration 2767 : loss : 0.023353, loss_ce: 0.008632
2022-01-14 16:06:40,046 iteration 2768 : loss : 0.018872, loss_ce: 0.004829
2022-01-14 16:06:41,519 iteration 2769 : loss : 0.018637, loss_ce: 0.007928
2022-01-14 16:06:42,991 iteration 2770 : loss : 0.022106, loss_ce: 0.010400
2022-01-14 16:06:44,441 iteration 2771 : loss : 0.029725, loss_ce: 0.011813
 41%|███████████                | 163/400 [1:14:37<1:44:00, 26.33s/it]2022-01-14 16:06:46,007 iteration 2772 : loss : 0.026189, loss_ce: 0.011603
2022-01-14 16:06:47,424 iteration 2773 : loss : 0.020366, loss_ce: 0.007778
2022-01-14 16:06:48,827 iteration 2774 : loss : 0.026050, loss_ce: 0.006070
2022-01-14 16:06:50,265 iteration 2775 : loss : 0.024769, loss_ce: 0.009040
2022-01-14 16:06:51,697 iteration 2776 : loss : 0.020275, loss_ce: 0.007001
2022-01-14 16:06:53,159 iteration 2777 : loss : 0.017662, loss_ce: 0.006563
2022-01-14 16:06:54,701 iteration 2778 : loss : 0.031512, loss_ce: 0.011266
2022-01-14 16:06:56,279 iteration 2779 : loss : 0.028350, loss_ce: 0.011332
2022-01-14 16:06:57,701 iteration 2780 : loss : 0.016901, loss_ce: 0.005949
2022-01-14 16:06:59,216 iteration 2781 : loss : 0.038142, loss_ce: 0.012455
2022-01-14 16:07:00,674 iteration 2782 : loss : 0.027645, loss_ce: 0.009937
2022-01-14 16:07:02,100 iteration 2783 : loss : 0.030683, loss_ce: 0.015574
2022-01-14 16:07:03,677 iteration 2784 : loss : 0.035004, loss_ce: 0.010819
2022-01-14 16:07:05,214 iteration 2785 : loss : 0.034075, loss_ce: 0.009118
2022-01-14 16:07:06,720 iteration 2786 : loss : 0.025635, loss_ce: 0.009901
2022-01-14 16:07:08,239 iteration 2787 : loss : 0.019534, loss_ce: 0.008801
2022-01-14 16:07:09,677 iteration 2788 : loss : 0.023524, loss_ce: 0.011706
 41%|███████████                | 164/400 [1:15:02<1:42:16, 26.00s/it]2022-01-14 16:07:11,157 iteration 2789 : loss : 0.032206, loss_ce: 0.011992
2022-01-14 16:07:12,661 iteration 2790 : loss : 0.034385, loss_ce: 0.011441
2022-01-14 16:07:14,108 iteration 2791 : loss : 0.022126, loss_ce: 0.009278
2022-01-14 16:07:15,640 iteration 2792 : loss : 0.031295, loss_ce: 0.011522
2022-01-14 16:07:17,069 iteration 2793 : loss : 0.025916, loss_ce: 0.010046
2022-01-14 16:07:18,581 iteration 2794 : loss : 0.028425, loss_ce: 0.008918
2022-01-14 16:07:20,005 iteration 2795 : loss : 0.019014, loss_ce: 0.006453
2022-01-14 16:07:21,507 iteration 2796 : loss : 0.029348, loss_ce: 0.010861
2022-01-14 16:07:23,012 iteration 2797 : loss : 0.025142, loss_ce: 0.010373
2022-01-14 16:07:24,548 iteration 2798 : loss : 0.031920, loss_ce: 0.015147
2022-01-14 16:07:25,980 iteration 2799 : loss : 0.019284, loss_ce: 0.008176
2022-01-14 16:07:27,398 iteration 2800 : loss : 0.041425, loss_ce: 0.014717
2022-01-14 16:07:28,806 iteration 2801 : loss : 0.016074, loss_ce: 0.005014
2022-01-14 16:07:30,329 iteration 2802 : loss : 0.023456, loss_ce: 0.006965
2022-01-14 16:07:31,790 iteration 2803 : loss : 0.023418, loss_ce: 0.009556
2022-01-14 16:07:33,233 iteration 2804 : loss : 0.020439, loss_ce: 0.006890
2022-01-14 16:07:33,233 Training Data Eval:
2022-01-14 16:07:40,608   Average segmentation loss on training set: 0.0178
2022-01-14 16:07:40,608 Validation Data Eval:
2022-01-14 16:07:43,146   Average segmentation loss on validation set: 0.1072
2022-01-14 16:07:44,583 iteration 2805 : loss : 0.029606, loss_ce: 0.012684
 41%|███████████▏               | 165/400 [1:15:37<1:52:18, 28.67s/it]2022-01-14 16:07:46,214 iteration 2806 : loss : 0.027244, loss_ce: 0.011960
2022-01-14 16:07:47,616 iteration 2807 : loss : 0.020725, loss_ce: 0.007035
2022-01-14 16:07:49,039 iteration 2808 : loss : 0.023509, loss_ce: 0.009746
2022-01-14 16:07:50,532 iteration 2809 : loss : 0.018096, loss_ce: 0.006032
2022-01-14 16:07:51,988 iteration 2810 : loss : 0.029051, loss_ce: 0.012708
2022-01-14 16:07:53,545 iteration 2811 : loss : 0.039205, loss_ce: 0.013343
2022-01-14 16:07:55,122 iteration 2812 : loss : 0.029847, loss_ce: 0.010786
2022-01-14 16:07:56,511 iteration 2813 : loss : 0.021162, loss_ce: 0.008141
2022-01-14 16:07:58,002 iteration 2814 : loss : 0.023406, loss_ce: 0.011384
2022-01-14 16:07:59,515 iteration 2815 : loss : 0.024756, loss_ce: 0.009166
2022-01-14 16:08:00,967 iteration 2816 : loss : 0.019785, loss_ce: 0.006863
2022-01-14 16:08:02,423 iteration 2817 : loss : 0.034720, loss_ce: 0.016589
2022-01-14 16:08:03,987 iteration 2818 : loss : 0.034996, loss_ce: 0.012104
2022-01-14 16:08:05,521 iteration 2819 : loss : 0.027720, loss_ce: 0.012342
2022-01-14 16:08:06,973 iteration 2820 : loss : 0.026671, loss_ce: 0.009169
2022-01-14 16:08:08,455 iteration 2821 : loss : 0.016265, loss_ce: 0.006111
2022-01-14 16:08:09,973 iteration 2822 : loss : 0.050556, loss_ce: 0.009163
 42%|███████████▏               | 166/400 [1:16:03<1:47:58, 27.69s/it]2022-01-14 16:08:11,526 iteration 2823 : loss : 0.021421, loss_ce: 0.007457
2022-01-14 16:08:13,033 iteration 2824 : loss : 0.024820, loss_ce: 0.007421
2022-01-14 16:08:14,529 iteration 2825 : loss : 0.028673, loss_ce: 0.009605
2022-01-14 16:08:15,960 iteration 2826 : loss : 0.026680, loss_ce: 0.009608
2022-01-14 16:08:17,475 iteration 2827 : loss : 0.031631, loss_ce: 0.012284
2022-01-14 16:08:18,927 iteration 2828 : loss : 0.031769, loss_ce: 0.012519
2022-01-14 16:08:20,371 iteration 2829 : loss : 0.046229, loss_ce: 0.013890
2022-01-14 16:08:21,892 iteration 2830 : loss : 0.036455, loss_ce: 0.017320
2022-01-14 16:08:23,351 iteration 2831 : loss : 0.039165, loss_ce: 0.011370
2022-01-14 16:08:24,767 iteration 2832 : loss : 0.026647, loss_ce: 0.011107
2022-01-14 16:08:26,313 iteration 2833 : loss : 0.028987, loss_ce: 0.011804
2022-01-14 16:08:27,803 iteration 2834 : loss : 0.029122, loss_ce: 0.011957
2022-01-14 16:08:29,300 iteration 2835 : loss : 0.031015, loss_ce: 0.012471
2022-01-14 16:08:30,801 iteration 2836 : loss : 0.048226, loss_ce: 0.021151
2022-01-14 16:08:32,324 iteration 2837 : loss : 0.052670, loss_ce: 0.022348
2022-01-14 16:08:33,835 iteration 2838 : loss : 0.032298, loss_ce: 0.011077
2022-01-14 16:08:35,247 iteration 2839 : loss : 0.029650, loss_ce: 0.011239
 42%|███████████▎               | 167/400 [1:16:28<1:44:42, 26.96s/it]2022-01-14 16:08:36,753 iteration 2840 : loss : 0.031221, loss_ce: 0.011311
2022-01-14 16:08:38,190 iteration 2841 : loss : 0.022369, loss_ce: 0.010410
2022-01-14 16:08:39,586 iteration 2842 : loss : 0.022069, loss_ce: 0.008195
2022-01-14 16:08:41,045 iteration 2843 : loss : 0.049769, loss_ce: 0.015250
2022-01-14 16:08:42,560 iteration 2844 : loss : 0.031828, loss_ce: 0.014173
2022-01-14 16:08:44,095 iteration 2845 : loss : 0.025282, loss_ce: 0.008850
2022-01-14 16:08:45,557 iteration 2846 : loss : 0.031977, loss_ce: 0.011121
2022-01-14 16:08:47,051 iteration 2847 : loss : 0.039515, loss_ce: 0.016337
2022-01-14 16:08:48,621 iteration 2848 : loss : 0.047121, loss_ce: 0.023820
2022-01-14 16:08:50,079 iteration 2849 : loss : 0.026449, loss_ce: 0.008858
2022-01-14 16:08:51,514 iteration 2850 : loss : 0.024929, loss_ce: 0.008024
2022-01-14 16:08:52,992 iteration 2851 : loss : 0.028613, loss_ce: 0.011806
2022-01-14 16:08:54,475 iteration 2852 : loss : 0.030598, loss_ce: 0.013346
2022-01-14 16:08:55,918 iteration 2853 : loss : 0.026861, loss_ce: 0.011510
2022-01-14 16:08:57,432 iteration 2854 : loss : 0.029296, loss_ce: 0.013168
2022-01-14 16:08:58,909 iteration 2855 : loss : 0.035832, loss_ce: 0.016118
2022-01-14 16:09:00,442 iteration 2856 : loss : 0.035272, loss_ce: 0.012457
 42%|███████████▎               | 168/400 [1:16:53<1:42:12, 26.43s/it]2022-01-14 16:09:02,019 iteration 2857 : loss : 0.046163, loss_ce: 0.011631
2022-01-14 16:09:03,519 iteration 2858 : loss : 0.028734, loss_ce: 0.009900
2022-01-14 16:09:04,947 iteration 2859 : loss : 0.021414, loss_ce: 0.007418
2022-01-14 16:09:06,479 iteration 2860 : loss : 0.047448, loss_ce: 0.022563
2022-01-14 16:09:07,919 iteration 2861 : loss : 0.026691, loss_ce: 0.009391
2022-01-14 16:09:09,428 iteration 2862 : loss : 0.033123, loss_ce: 0.010406
2022-01-14 16:09:10,969 iteration 2863 : loss : 0.041165, loss_ce: 0.014167
2022-01-14 16:09:12,456 iteration 2864 : loss : 0.027051, loss_ce: 0.013283
2022-01-14 16:09:13,860 iteration 2865 : loss : 0.025602, loss_ce: 0.009072
2022-01-14 16:09:15,317 iteration 2866 : loss : 0.028466, loss_ce: 0.008869
2022-01-14 16:09:16,852 iteration 2867 : loss : 0.034126, loss_ce: 0.013296
2022-01-14 16:09:18,364 iteration 2868 : loss : 0.025840, loss_ce: 0.010583
2022-01-14 16:09:19,797 iteration 2869 : loss : 0.022866, loss_ce: 0.009939
2022-01-14 16:09:21,301 iteration 2870 : loss : 0.032591, loss_ce: 0.013809
2022-01-14 16:09:22,688 iteration 2871 : loss : 0.026326, loss_ce: 0.011611
2022-01-14 16:09:24,157 iteration 2872 : loss : 0.035314, loss_ce: 0.013784
2022-01-14 16:09:25,677 iteration 2873 : loss : 0.037924, loss_ce: 0.019117
 42%|███████████▍               | 169/400 [1:17:18<1:40:23, 26.08s/it]2022-01-14 16:09:27,167 iteration 2874 : loss : 0.047612, loss_ce: 0.016426
2022-01-14 16:09:28,557 iteration 2875 : loss : 0.024868, loss_ce: 0.010278
2022-01-14 16:09:29,998 iteration 2876 : loss : 0.027912, loss_ce: 0.012563
2022-01-14 16:09:31,479 iteration 2877 : loss : 0.034433, loss_ce: 0.011928
2022-01-14 16:09:32,975 iteration 2878 : loss : 0.039861, loss_ce: 0.013816
2022-01-14 16:09:34,400 iteration 2879 : loss : 0.024579, loss_ce: 0.012558
2022-01-14 16:09:35,940 iteration 2880 : loss : 0.049176, loss_ce: 0.020445
2022-01-14 16:09:37,400 iteration 2881 : loss : 0.034579, loss_ce: 0.015288
2022-01-14 16:09:38,965 iteration 2882 : loss : 0.050500, loss_ce: 0.014106
2022-01-14 16:09:40,523 iteration 2883 : loss : 0.034175, loss_ce: 0.014253
2022-01-14 16:09:42,078 iteration 2884 : loss : 0.024847, loss_ce: 0.007295
2022-01-14 16:09:43,564 iteration 2885 : loss : 0.025055, loss_ce: 0.011011
2022-01-14 16:09:45,001 iteration 2886 : loss : 0.025816, loss_ce: 0.006893
2022-01-14 16:09:46,468 iteration 2887 : loss : 0.023317, loss_ce: 0.008103
2022-01-14 16:09:48,034 iteration 2888 : loss : 0.024437, loss_ce: 0.008806
2022-01-14 16:09:49,565 iteration 2889 : loss : 0.040973, loss_ce: 0.020356
2022-01-14 16:09:49,566 Training Data Eval:
2022-01-14 16:09:56,944   Average segmentation loss on training set: 0.0299
2022-01-14 16:09:56,944 Validation Data Eval:
2022-01-14 16:09:59,475   Average segmentation loss on validation set: 0.2254
2022-01-14 16:10:00,990 iteration 2890 : loss : 0.060899, loss_ce: 0.025839
 42%|███████████▍               | 170/400 [1:17:54<1:50:34, 28.84s/it]2022-01-14 16:10:02,564 iteration 2891 : loss : 0.040957, loss_ce: 0.020695
2022-01-14 16:10:03,985 iteration 2892 : loss : 0.022890, loss_ce: 0.011432
2022-01-14 16:10:05,430 iteration 2893 : loss : 0.040926, loss_ce: 0.012705
2022-01-14 16:10:06,934 iteration 2894 : loss : 0.026155, loss_ce: 0.011595
2022-01-14 16:10:08,386 iteration 2895 : loss : 0.035239, loss_ce: 0.013026
2022-01-14 16:10:09,812 iteration 2896 : loss : 0.026210, loss_ce: 0.010040
2022-01-14 16:10:11,272 iteration 2897 : loss : 0.034933, loss_ce: 0.014228
2022-01-14 16:10:12,746 iteration 2898 : loss : 0.031396, loss_ce: 0.017308
2022-01-14 16:10:14,266 iteration 2899 : loss : 0.043281, loss_ce: 0.018122
2022-01-14 16:10:15,689 iteration 2900 : loss : 0.037676, loss_ce: 0.015691
2022-01-14 16:10:17,256 iteration 2901 : loss : 0.030584, loss_ce: 0.009758
2022-01-14 16:10:18,632 iteration 2902 : loss : 0.021826, loss_ce: 0.007704
2022-01-14 16:10:20,136 iteration 2903 : loss : 0.030958, loss_ce: 0.015324
2022-01-14 16:10:21,672 iteration 2904 : loss : 0.081471, loss_ce: 0.033760
2022-01-14 16:10:23,145 iteration 2905 : loss : 0.031285, loss_ce: 0.010716
2022-01-14 16:10:24,675 iteration 2906 : loss : 0.028949, loss_ce: 0.010267
2022-01-14 16:10:26,112 iteration 2907 : loss : 0.035102, loss_ce: 0.017207
 43%|███████████▌               | 171/400 [1:18:19<1:45:49, 27.73s/it]2022-01-14 16:10:27,629 iteration 2908 : loss : 0.037325, loss_ce: 0.019448
2022-01-14 16:10:29,035 iteration 2909 : loss : 0.030302, loss_ce: 0.007882
2022-01-14 16:10:30,546 iteration 2910 : loss : 0.044008, loss_ce: 0.015890
2022-01-14 16:10:32,024 iteration 2911 : loss : 0.038180, loss_ce: 0.018282
2022-01-14 16:10:33,490 iteration 2912 : loss : 0.026097, loss_ce: 0.009569
2022-01-14 16:10:35,002 iteration 2913 : loss : 0.031767, loss_ce: 0.013952
2022-01-14 16:10:36,490 iteration 2914 : loss : 0.032538, loss_ce: 0.013211
2022-01-14 16:10:38,015 iteration 2915 : loss : 0.032477, loss_ce: 0.011976
2022-01-14 16:10:39,433 iteration 2916 : loss : 0.027162, loss_ce: 0.014259
2022-01-14 16:10:40,966 iteration 2917 : loss : 0.037350, loss_ce: 0.015709
2022-01-14 16:10:42,466 iteration 2918 : loss : 0.036966, loss_ce: 0.013071
2022-01-14 16:10:43,975 iteration 2919 : loss : 0.040562, loss_ce: 0.019426
2022-01-14 16:10:45,479 iteration 2920 : loss : 0.033159, loss_ce: 0.009617
2022-01-14 16:10:47,030 iteration 2921 : loss : 0.031930, loss_ce: 0.009535
2022-01-14 16:10:48,493 iteration 2922 : loss : 0.025274, loss_ce: 0.010149
2022-01-14 16:10:50,008 iteration 2923 : loss : 0.028567, loss_ce: 0.011490
2022-01-14 16:10:51,471 iteration 2924 : loss : 0.026568, loss_ce: 0.008505
 43%|███████████▌               | 172/400 [1:18:44<1:42:40, 27.02s/it]2022-01-14 16:10:53,082 iteration 2925 : loss : 0.050839, loss_ce: 0.022301
2022-01-14 16:10:54,535 iteration 2926 : loss : 0.033080, loss_ce: 0.010299
2022-01-14 16:10:56,075 iteration 2927 : loss : 0.037803, loss_ce: 0.015832
2022-01-14 16:10:57,677 iteration 2928 : loss : 0.037837, loss_ce: 0.010800
2022-01-14 16:10:59,133 iteration 2929 : loss : 0.019333, loss_ce: 0.006411
2022-01-14 16:11:00,609 iteration 2930 : loss : 0.040888, loss_ce: 0.019408
2022-01-14 16:11:02,015 iteration 2931 : loss : 0.032421, loss_ce: 0.013319
2022-01-14 16:11:03,559 iteration 2932 : loss : 0.026971, loss_ce: 0.010429
2022-01-14 16:11:05,019 iteration 2933 : loss : 0.026655, loss_ce: 0.009228
2022-01-14 16:11:06,551 iteration 2934 : loss : 0.029695, loss_ce: 0.013323
2022-01-14 16:11:08,041 iteration 2935 : loss : 0.037389, loss_ce: 0.011783
2022-01-14 16:11:09,588 iteration 2936 : loss : 0.052349, loss_ce: 0.026822
2022-01-14 16:11:11,055 iteration 2937 : loss : 0.029650, loss_ce: 0.013574
2022-01-14 16:11:12,537 iteration 2938 : loss : 0.039302, loss_ce: 0.016712
2022-01-14 16:11:14,004 iteration 2939 : loss : 0.025088, loss_ce: 0.010985
2022-01-14 16:11:15,522 iteration 2940 : loss : 0.026960, loss_ce: 0.008223
2022-01-14 16:11:16,998 iteration 2941 : loss : 0.024958, loss_ce: 0.007531
 43%|███████████▋               | 173/400 [1:19:10<1:40:31, 26.57s/it]2022-01-14 16:11:18,540 iteration 2942 : loss : 0.039857, loss_ce: 0.015386
2022-01-14 16:11:19,939 iteration 2943 : loss : 0.020524, loss_ce: 0.008273
2022-01-14 16:11:21,355 iteration 2944 : loss : 0.025773, loss_ce: 0.009537
2022-01-14 16:11:22,888 iteration 2945 : loss : 0.028829, loss_ce: 0.012461
2022-01-14 16:11:24,331 iteration 2946 : loss : 0.023579, loss_ce: 0.010437
2022-01-14 16:11:25,760 iteration 2947 : loss : 0.017477, loss_ce: 0.005987
2022-01-14 16:11:27,234 iteration 2948 : loss : 0.033747, loss_ce: 0.012802
2022-01-14 16:11:28,745 iteration 2949 : loss : 0.026053, loss_ce: 0.009322
2022-01-14 16:11:30,212 iteration 2950 : loss : 0.032232, loss_ce: 0.012655
2022-01-14 16:11:31,639 iteration 2951 : loss : 0.024303, loss_ce: 0.008968
2022-01-14 16:11:33,115 iteration 2952 : loss : 0.024146, loss_ce: 0.006362
2022-01-14 16:11:34,587 iteration 2953 : loss : 0.032659, loss_ce: 0.013075
2022-01-14 16:11:36,096 iteration 2954 : loss : 0.048970, loss_ce: 0.013645
2022-01-14 16:11:37,529 iteration 2955 : loss : 0.028403, loss_ce: 0.013536
2022-01-14 16:11:38,996 iteration 2956 : loss : 0.021145, loss_ce: 0.010337
2022-01-14 16:11:40,471 iteration 2957 : loss : 0.036998, loss_ce: 0.009099
2022-01-14 16:11:41,945 iteration 2958 : loss : 0.040596, loss_ce: 0.016314
 44%|███████████▋               | 174/400 [1:19:35<1:38:14, 26.08s/it]2022-01-14 16:11:43,549 iteration 2959 : loss : 0.020112, loss_ce: 0.008843
2022-01-14 16:11:45,071 iteration 2960 : loss : 0.023024, loss_ce: 0.007982
2022-01-14 16:11:46,601 iteration 2961 : loss : 0.023807, loss_ce: 0.010825
2022-01-14 16:11:48,033 iteration 2962 : loss : 0.022473, loss_ce: 0.007632
2022-01-14 16:11:49,497 iteration 2963 : loss : 0.027733, loss_ce: 0.009363
2022-01-14 16:11:51,027 iteration 2964 : loss : 0.044728, loss_ce: 0.016801
2022-01-14 16:11:52,512 iteration 2965 : loss : 0.037612, loss_ce: 0.022318
2022-01-14 16:11:53,973 iteration 2966 : loss : 0.020915, loss_ce: 0.006581
2022-01-14 16:11:55,522 iteration 2967 : loss : 0.049467, loss_ce: 0.019575
2022-01-14 16:11:56,997 iteration 2968 : loss : 0.043726, loss_ce: 0.017130
2022-01-14 16:11:58,419 iteration 2969 : loss : 0.023722, loss_ce: 0.007245
2022-01-14 16:11:59,870 iteration 2970 : loss : 0.020339, loss_ce: 0.008205
2022-01-14 16:12:01,362 iteration 2971 : loss : 0.031729, loss_ce: 0.009847
2022-01-14 16:12:02,873 iteration 2972 : loss : 0.027943, loss_ce: 0.009787
2022-01-14 16:12:04,345 iteration 2973 : loss : 0.027491, loss_ce: 0.011828
2022-01-14 16:12:05,938 iteration 2974 : loss : 0.032682, loss_ce: 0.013672
2022-01-14 16:12:05,939 Training Data Eval:
2022-01-14 16:12:13,296   Average segmentation loss on training set: 0.0181
2022-01-14 16:12:13,297 Validation Data Eval:
2022-01-14 16:12:15,831   Average segmentation loss on validation set: 0.0889
2022-01-14 16:12:17,277 iteration 2975 : loss : 0.028590, loss_ce: 0.011684
 44%|███████████▊               | 175/400 [1:20:10<1:48:13, 28.86s/it]2022-01-14 16:12:18,856 iteration 2976 : loss : 0.038775, loss_ce: 0.016224
2022-01-14 16:12:20,497 iteration 2977 : loss : 0.031164, loss_ce: 0.011860
2022-01-14 16:12:21,991 iteration 2978 : loss : 0.023959, loss_ce: 0.010239
2022-01-14 16:12:23,550 iteration 2979 : loss : 0.043004, loss_ce: 0.013343
2022-01-14 16:12:25,187 iteration 2980 : loss : 0.035225, loss_ce: 0.013726
2022-01-14 16:12:26,672 iteration 2981 : loss : 0.022482, loss_ce: 0.009995
2022-01-14 16:12:28,153 iteration 2982 : loss : 0.030816, loss_ce: 0.011615
2022-01-14 16:12:29,669 iteration 2983 : loss : 0.028149, loss_ce: 0.008979
2022-01-14 16:12:31,171 iteration 2984 : loss : 0.032882, loss_ce: 0.015552
2022-01-14 16:12:32,663 iteration 2985 : loss : 0.024438, loss_ce: 0.011008
2022-01-14 16:12:34,138 iteration 2986 : loss : 0.036115, loss_ce: 0.016183
2022-01-14 16:12:35,595 iteration 2987 : loss : 0.029148, loss_ce: 0.010339
2022-01-14 16:12:37,100 iteration 2988 : loss : 0.028161, loss_ce: 0.012237
2022-01-14 16:12:38,549 iteration 2989 : loss : 0.020645, loss_ce: 0.007053
2022-01-14 16:12:40,037 iteration 2990 : loss : 0.028251, loss_ce: 0.013564
2022-01-14 16:12:41,482 iteration 2991 : loss : 0.025296, loss_ce: 0.006796
2022-01-14 16:12:42,983 iteration 2992 : loss : 0.023044, loss_ce: 0.009818
 44%|███████████▉               | 176/400 [1:20:36<1:44:12, 27.91s/it]2022-01-14 16:12:44,532 iteration 2993 : loss : 0.028447, loss_ce: 0.013679
2022-01-14 16:12:46,005 iteration 2994 : loss : 0.019328, loss_ce: 0.007242
2022-01-14 16:12:47,524 iteration 2995 : loss : 0.040901, loss_ce: 0.016330
2022-01-14 16:12:48,963 iteration 2996 : loss : 0.026696, loss_ce: 0.009693
2022-01-14 16:12:50,440 iteration 2997 : loss : 0.021017, loss_ce: 0.006442
2022-01-14 16:12:51,950 iteration 2998 : loss : 0.021768, loss_ce: 0.009464
2022-01-14 16:12:53,430 iteration 2999 : loss : 0.034301, loss_ce: 0.011959
2022-01-14 16:12:54,899 iteration 3000 : loss : 0.023701, loss_ce: 0.009120
2022-01-14 16:12:56,465 iteration 3001 : loss : 0.024212, loss_ce: 0.008897
2022-01-14 16:12:57,993 iteration 3002 : loss : 0.033586, loss_ce: 0.012433
2022-01-14 16:12:59,409 iteration 3003 : loss : 0.020998, loss_ce: 0.008371
2022-01-14 16:13:00,883 iteration 3004 : loss : 0.025082, loss_ce: 0.013093
2022-01-14 16:13:02,336 iteration 3005 : loss : 0.034578, loss_ce: 0.015716
2022-01-14 16:13:03,818 iteration 3006 : loss : 0.023332, loss_ce: 0.007899
2022-01-14 16:13:05,309 iteration 3007 : loss : 0.022028, loss_ce: 0.006873
2022-01-14 16:13:06,739 iteration 3008 : loss : 0.023811, loss_ce: 0.008666
2022-01-14 16:13:08,168 iteration 3009 : loss : 0.029508, loss_ce: 0.007629
 44%|███████████▉               | 177/400 [1:21:01<1:40:41, 27.09s/it]2022-01-14 16:13:09,772 iteration 3010 : loss : 0.037985, loss_ce: 0.011848
2022-01-14 16:13:11,232 iteration 3011 : loss : 0.047660, loss_ce: 0.012051
2022-01-14 16:13:12,671 iteration 3012 : loss : 0.032018, loss_ce: 0.010885
2022-01-14 16:13:14,227 iteration 3013 : loss : 0.023521, loss_ce: 0.008960
2022-01-14 16:13:15,735 iteration 3014 : loss : 0.029501, loss_ce: 0.012381
2022-01-14 16:13:17,231 iteration 3015 : loss : 0.022978, loss_ce: 0.006959
2022-01-14 16:13:18,636 iteration 3016 : loss : 0.020199, loss_ce: 0.006101
2022-01-14 16:13:20,173 iteration 3017 : loss : 0.038201, loss_ce: 0.019409
2022-01-14 16:13:21,734 iteration 3018 : loss : 0.029390, loss_ce: 0.016192
2022-01-14 16:13:23,364 iteration 3019 : loss : 0.036592, loss_ce: 0.014891
2022-01-14 16:13:24,824 iteration 3020 : loss : 0.023751, loss_ce: 0.007872
2022-01-14 16:13:26,297 iteration 3021 : loss : 0.025225, loss_ce: 0.010689
2022-01-14 16:13:27,702 iteration 3022 : loss : 0.019738, loss_ce: 0.009226
2022-01-14 16:13:29,145 iteration 3023 : loss : 0.029223, loss_ce: 0.011447
2022-01-14 16:13:30,630 iteration 3024 : loss : 0.043652, loss_ce: 0.019762
2022-01-14 16:13:32,110 iteration 3025 : loss : 0.028278, loss_ce: 0.012340
2022-01-14 16:13:33,542 iteration 3026 : loss : 0.026895, loss_ce: 0.007542
 44%|████████████               | 178/400 [1:21:26<1:38:19, 26.58s/it]2022-01-14 16:13:35,053 iteration 3027 : loss : 0.033655, loss_ce: 0.013828
2022-01-14 16:13:36,629 iteration 3028 : loss : 0.027520, loss_ce: 0.009824
2022-01-14 16:13:38,080 iteration 3029 : loss : 0.019238, loss_ce: 0.006527
2022-01-14 16:13:39,624 iteration 3030 : loss : 0.025481, loss_ce: 0.007720
2022-01-14 16:13:41,173 iteration 3031 : loss : 0.042729, loss_ce: 0.013036
2022-01-14 16:13:42,720 iteration 3032 : loss : 0.031158, loss_ce: 0.011841
2022-01-14 16:13:44,223 iteration 3033 : loss : 0.024474, loss_ce: 0.008981
2022-01-14 16:13:45,675 iteration 3034 : loss : 0.020101, loss_ce: 0.005327
2022-01-14 16:13:47,101 iteration 3035 : loss : 0.021405, loss_ce: 0.009171
2022-01-14 16:13:48,614 iteration 3036 : loss : 0.029925, loss_ce: 0.014214
2022-01-14 16:13:50,043 iteration 3037 : loss : 0.028860, loss_ce: 0.011910
2022-01-14 16:13:51,451 iteration 3038 : loss : 0.025023, loss_ce: 0.011493
2022-01-14 16:13:52,882 iteration 3039 : loss : 0.022214, loss_ce: 0.007721
2022-01-14 16:13:54,430 iteration 3040 : loss : 0.031607, loss_ce: 0.009076
2022-01-14 16:13:55,804 iteration 3041 : loss : 0.023389, loss_ce: 0.009045
2022-01-14 16:13:57,234 iteration 3042 : loss : 0.020081, loss_ce: 0.009273
2022-01-14 16:13:58,660 iteration 3043 : loss : 0.022985, loss_ce: 0.008841
 45%|████████████               | 179/400 [1:21:51<1:36:16, 26.14s/it]2022-01-14 16:14:00,204 iteration 3044 : loss : 0.024312, loss_ce: 0.008495
2022-01-14 16:14:01,604 iteration 3045 : loss : 0.038298, loss_ce: 0.012027
2022-01-14 16:14:03,192 iteration 3046 : loss : 0.035069, loss_ce: 0.015842
2022-01-14 16:14:04,767 iteration 3047 : loss : 0.028885, loss_ce: 0.010579
2022-01-14 16:14:06,282 iteration 3048 : loss : 0.029410, loss_ce: 0.011153
2022-01-14 16:14:07,796 iteration 3049 : loss : 0.018966, loss_ce: 0.006127
2022-01-14 16:14:09,324 iteration 3050 : loss : 0.031829, loss_ce: 0.007352
2022-01-14 16:14:10,884 iteration 3051 : loss : 0.022245, loss_ce: 0.008235
2022-01-14 16:14:12,402 iteration 3052 : loss : 0.028074, loss_ce: 0.013212
2022-01-14 16:14:13,813 iteration 3053 : loss : 0.019009, loss_ce: 0.006453
2022-01-14 16:14:15,255 iteration 3054 : loss : 0.027472, loss_ce: 0.011029
2022-01-14 16:14:16,677 iteration 3055 : loss : 0.029662, loss_ce: 0.011590
2022-01-14 16:14:18,073 iteration 3056 : loss : 0.017589, loss_ce: 0.005919
2022-01-14 16:14:19,667 iteration 3057 : loss : 0.037532, loss_ce: 0.015093
2022-01-14 16:14:21,107 iteration 3058 : loss : 0.028098, loss_ce: 0.010142
2022-01-14 16:14:22,551 iteration 3059 : loss : 0.022742, loss_ce: 0.012621
2022-01-14 16:14:22,551 Training Data Eval:
2022-01-14 16:14:29,917   Average segmentation loss on training set: 0.0185
2022-01-14 16:14:29,918 Validation Data Eval:
2022-01-14 16:14:32,461   Average segmentation loss on validation set: 0.0975
2022-01-14 16:14:34,015 iteration 3060 : loss : 0.029735, loss_ce: 0.011312
 45%|████████████▏              | 180/400 [1:22:27<1:45:58, 28.90s/it]2022-01-14 16:14:35,578 iteration 3061 : loss : 0.029637, loss_ce: 0.008273
2022-01-14 16:14:37,084 iteration 3062 : loss : 0.026277, loss_ce: 0.011155
2022-01-14 16:14:38,544 iteration 3063 : loss : 0.021702, loss_ce: 0.008602
2022-01-14 16:14:40,025 iteration 3064 : loss : 0.027810, loss_ce: 0.014272
2022-01-14 16:14:41,540 iteration 3065 : loss : 0.037923, loss_ce: 0.010798
2022-01-14 16:14:42,983 iteration 3066 : loss : 0.025216, loss_ce: 0.007227
2022-01-14 16:14:44,602 iteration 3067 : loss : 0.032038, loss_ce: 0.014093
2022-01-14 16:14:46,165 iteration 3068 : loss : 0.024493, loss_ce: 0.009519
2022-01-14 16:14:47,594 iteration 3069 : loss : 0.014223, loss_ce: 0.005055
2022-01-14 16:14:49,076 iteration 3070 : loss : 0.026716, loss_ce: 0.009237
2022-01-14 16:14:50,691 iteration 3071 : loss : 0.029415, loss_ce: 0.009181
2022-01-14 16:14:52,158 iteration 3072 : loss : 0.019739, loss_ce: 0.008473
2022-01-14 16:14:53,616 iteration 3073 : loss : 0.024086, loss_ce: 0.008003
2022-01-14 16:14:55,088 iteration 3074 : loss : 0.028631, loss_ce: 0.011378
2022-01-14 16:14:56,583 iteration 3075 : loss : 0.040149, loss_ce: 0.012837
2022-01-14 16:14:58,011 iteration 3076 : loss : 0.018284, loss_ce: 0.007017
2022-01-14 16:14:59,568 iteration 3077 : loss : 0.036060, loss_ce: 0.012180
 45%|████████████▏              | 181/400 [1:22:52<1:41:49, 27.90s/it]2022-01-14 16:15:01,131 iteration 3078 : loss : 0.038718, loss_ce: 0.006815
2022-01-14 16:15:02,590 iteration 3079 : loss : 0.026528, loss_ce: 0.008016
2022-01-14 16:15:04,056 iteration 3080 : loss : 0.019803, loss_ce: 0.005954
2022-01-14 16:15:05,538 iteration 3081 : loss : 0.029546, loss_ce: 0.011556
2022-01-14 16:15:07,020 iteration 3082 : loss : 0.025132, loss_ce: 0.008933
2022-01-14 16:15:08,506 iteration 3083 : loss : 0.032622, loss_ce: 0.010610
2022-01-14 16:15:10,011 iteration 3084 : loss : 0.029218, loss_ce: 0.011677
2022-01-14 16:15:11,423 iteration 3085 : loss : 0.023199, loss_ce: 0.009201
2022-01-14 16:15:12,881 iteration 3086 : loss : 0.025797, loss_ce: 0.011726
2022-01-14 16:15:14,399 iteration 3087 : loss : 0.024189, loss_ce: 0.008930
2022-01-14 16:15:15,872 iteration 3088 : loss : 0.029066, loss_ce: 0.013672
2022-01-14 16:15:17,426 iteration 3089 : loss : 0.033034, loss_ce: 0.010916
2022-01-14 16:15:18,842 iteration 3090 : loss : 0.024969, loss_ce: 0.010170
2022-01-14 16:15:20,360 iteration 3091 : loss : 0.026718, loss_ce: 0.011199
2022-01-14 16:15:21,799 iteration 3092 : loss : 0.026653, loss_ce: 0.011672
2022-01-14 16:15:23,227 iteration 3093 : loss : 0.019180, loss_ce: 0.007921
2022-01-14 16:15:24,690 iteration 3094 : loss : 0.043593, loss_ce: 0.012088
 46%|████████████▎              | 182/400 [1:23:17<1:38:20, 27.07s/it]2022-01-14 16:15:26,236 iteration 3095 : loss : 0.019861, loss_ce: 0.008023
2022-01-14 16:15:27,717 iteration 3096 : loss : 0.021768, loss_ce: 0.008133
2022-01-14 16:15:29,213 iteration 3097 : loss : 0.024931, loss_ce: 0.011165
2022-01-14 16:15:30,722 iteration 3098 : loss : 0.026030, loss_ce: 0.007351
2022-01-14 16:15:32,235 iteration 3099 : loss : 0.031356, loss_ce: 0.015320
2022-01-14 16:15:33,717 iteration 3100 : loss : 0.023597, loss_ce: 0.007599
2022-01-14 16:15:35,153 iteration 3101 : loss : 0.016971, loss_ce: 0.006207
2022-01-14 16:15:36,546 iteration 3102 : loss : 0.021771, loss_ce: 0.007962
2022-01-14 16:15:38,053 iteration 3103 : loss : 0.033396, loss_ce: 0.015998
2022-01-14 16:15:39,523 iteration 3104 : loss : 0.029704, loss_ce: 0.008890
2022-01-14 16:15:41,040 iteration 3105 : loss : 0.021490, loss_ce: 0.008551
2022-01-14 16:15:42,527 iteration 3106 : loss : 0.026303, loss_ce: 0.010096
2022-01-14 16:15:44,067 iteration 3107 : loss : 0.022453, loss_ce: 0.008400
2022-01-14 16:15:45,576 iteration 3108 : loss : 0.034212, loss_ce: 0.011585
2022-01-14 16:15:46,988 iteration 3109 : loss : 0.019543, loss_ce: 0.009074
2022-01-14 16:15:48,438 iteration 3110 : loss : 0.030233, loss_ce: 0.010941
2022-01-14 16:15:49,926 iteration 3111 : loss : 0.032291, loss_ce: 0.007885
 46%|████████████▎              | 183/400 [1:23:43<1:35:54, 26.52s/it]2022-01-14 16:15:51,409 iteration 3112 : loss : 0.019192, loss_ce: 0.007273
2022-01-14 16:15:52,911 iteration 3113 : loss : 0.033594, loss_ce: 0.012284
2022-01-14 16:15:54,350 iteration 3114 : loss : 0.020749, loss_ce: 0.009311
2022-01-14 16:15:55,857 iteration 3115 : loss : 0.021995, loss_ce: 0.009309
2022-01-14 16:15:57,273 iteration 3116 : loss : 0.023592, loss_ce: 0.009479
2022-01-14 16:15:58,827 iteration 3117 : loss : 0.031315, loss_ce: 0.006683
2022-01-14 16:16:00,323 iteration 3118 : loss : 0.021925, loss_ce: 0.009948
2022-01-14 16:16:01,819 iteration 3119 : loss : 0.019620, loss_ce: 0.008456
2022-01-14 16:16:03,240 iteration 3120 : loss : 0.019195, loss_ce: 0.005692
2022-01-14 16:16:04,748 iteration 3121 : loss : 0.042209, loss_ce: 0.012931
2022-01-14 16:16:06,217 iteration 3122 : loss : 0.037148, loss_ce: 0.018255
2022-01-14 16:16:07,809 iteration 3123 : loss : 0.038955, loss_ce: 0.013567
2022-01-14 16:16:09,259 iteration 3124 : loss : 0.025878, loss_ce: 0.009985
2022-01-14 16:16:10,701 iteration 3125 : loss : 0.016440, loss_ce: 0.007000
2022-01-14 16:16:12,145 iteration 3126 : loss : 0.024644, loss_ce: 0.010495
2022-01-14 16:16:13,602 iteration 3127 : loss : 0.026126, loss_ce: 0.011586
2022-01-14 16:16:15,068 iteration 3128 : loss : 0.032042, loss_ce: 0.006854
 46%|████████████▍              | 184/400 [1:24:08<1:33:58, 26.10s/it]2022-01-14 16:16:16,556 iteration 3129 : loss : 0.025167, loss_ce: 0.008495
2022-01-14 16:16:17,995 iteration 3130 : loss : 0.029765, loss_ce: 0.014108
2022-01-14 16:16:19,518 iteration 3131 : loss : 0.028907, loss_ce: 0.013397
2022-01-14 16:16:21,017 iteration 3132 : loss : 0.025227, loss_ce: 0.008842
2022-01-14 16:16:22,455 iteration 3133 : loss : 0.020442, loss_ce: 0.008798
2022-01-14 16:16:23,968 iteration 3134 : loss : 0.023994, loss_ce: 0.009765
2022-01-14 16:16:25,487 iteration 3135 : loss : 0.038770, loss_ce: 0.009923
2022-01-14 16:16:26,914 iteration 3136 : loss : 0.019761, loss_ce: 0.008564
2022-01-14 16:16:28,343 iteration 3137 : loss : 0.022147, loss_ce: 0.009689
2022-01-14 16:16:29,797 iteration 3138 : loss : 0.024047, loss_ce: 0.008853
2022-01-14 16:16:31,403 iteration 3139 : loss : 0.026430, loss_ce: 0.007240
2022-01-14 16:16:32,915 iteration 3140 : loss : 0.024764, loss_ce: 0.008774
2022-01-14 16:16:34,378 iteration 3141 : loss : 0.023526, loss_ce: 0.010134
2022-01-14 16:16:35,789 iteration 3142 : loss : 0.023283, loss_ce: 0.008475
2022-01-14 16:16:37,284 iteration 3143 : loss : 0.039602, loss_ce: 0.010908
2022-01-14 16:16:38,812 iteration 3144 : loss : 0.034869, loss_ce: 0.008988
2022-01-14 16:16:38,813 Training Data Eval:
2022-01-14 16:16:46,167   Average segmentation loss on training set: 0.0158
2022-01-14 16:16:46,168 Validation Data Eval:
2022-01-14 16:16:48,706   Average segmentation loss on validation set: 0.0969
2022-01-14 16:16:50,119 iteration 3145 : loss : 0.023378, loss_ce: 0.011365
 46%|████████████▍              | 185/400 [1:24:43<1:43:09, 28.79s/it]2022-01-14 16:16:51,720 iteration 3146 : loss : 0.026376, loss_ce: 0.011275
2022-01-14 16:16:53,262 iteration 3147 : loss : 0.023921, loss_ce: 0.009201
2022-01-14 16:16:54,682 iteration 3148 : loss : 0.024340, loss_ce: 0.008551
2022-01-14 16:16:56,159 iteration 3149 : loss : 0.038041, loss_ce: 0.010474
2022-01-14 16:16:57,639 iteration 3150 : loss : 0.038552, loss_ce: 0.010506
2022-01-14 16:16:59,033 iteration 3151 : loss : 0.023443, loss_ce: 0.010065
2022-01-14 16:17:00,586 iteration 3152 : loss : 0.020233, loss_ce: 0.010155
2022-01-14 16:17:02,050 iteration 3153 : loss : 0.027017, loss_ce: 0.012755
2022-01-14 16:17:03,542 iteration 3154 : loss : 0.027490, loss_ce: 0.007171
2022-01-14 16:17:05,032 iteration 3155 : loss : 0.019829, loss_ce: 0.006670
2022-01-14 16:17:06,540 iteration 3156 : loss : 0.024837, loss_ce: 0.008766
2022-01-14 16:17:07,950 iteration 3157 : loss : 0.028528, loss_ce: 0.007623
2022-01-14 16:17:09,497 iteration 3158 : loss : 0.038315, loss_ce: 0.018254
2022-01-14 16:17:10,975 iteration 3159 : loss : 0.046722, loss_ce: 0.024874
2022-01-14 16:17:12,444 iteration 3160 : loss : 0.022722, loss_ce: 0.009743
2022-01-14 16:17:14,008 iteration 3161 : loss : 0.028265, loss_ce: 0.010021
2022-01-14 16:17:15,591 iteration 3162 : loss : 0.028222, loss_ce: 0.015347
 46%|████████████▌              | 186/400 [1:25:08<1:39:07, 27.79s/it]2022-01-14 16:17:17,069 iteration 3163 : loss : 0.072300, loss_ce: 0.025843
2022-01-14 16:17:18,500 iteration 3164 : loss : 0.038548, loss_ce: 0.010647
2022-01-14 16:17:19,957 iteration 3165 : loss : 0.015758, loss_ce: 0.006783
2022-01-14 16:17:21,438 iteration 3166 : loss : 0.027573, loss_ce: 0.012888
2022-01-14 16:17:22,934 iteration 3167 : loss : 0.068907, loss_ce: 0.021965
2022-01-14 16:17:24,363 iteration 3168 : loss : 0.023918, loss_ce: 0.011041
2022-01-14 16:17:25,849 iteration 3169 : loss : 0.025781, loss_ce: 0.008681
2022-01-14 16:17:27,356 iteration 3170 : loss : 0.034741, loss_ce: 0.014917
2022-01-14 16:17:28,895 iteration 3171 : loss : 0.049358, loss_ce: 0.013552
2022-01-14 16:17:30,416 iteration 3172 : loss : 0.030274, loss_ce: 0.011205
2022-01-14 16:17:31,928 iteration 3173 : loss : 0.029794, loss_ce: 0.011435
2022-01-14 16:17:33,467 iteration 3174 : loss : 0.030479, loss_ce: 0.011217
2022-01-14 16:17:34,946 iteration 3175 : loss : 0.020905, loss_ce: 0.008074
2022-01-14 16:17:36,445 iteration 3176 : loss : 0.031573, loss_ce: 0.016339
2022-01-14 16:17:37,889 iteration 3177 : loss : 0.022708, loss_ce: 0.009637
2022-01-14 16:17:39,377 iteration 3178 : loss : 0.034485, loss_ce: 0.008886
2022-01-14 16:17:40,892 iteration 3179 : loss : 0.043788, loss_ce: 0.013491
 47%|████████████▌              | 187/400 [1:25:34<1:36:01, 27.05s/it]2022-01-14 16:17:42,486 iteration 3180 : loss : 0.019620, loss_ce: 0.008170
2022-01-14 16:17:43,977 iteration 3181 : loss : 0.024578, loss_ce: 0.009652
2022-01-14 16:17:45,534 iteration 3182 : loss : 0.024586, loss_ce: 0.008683
2022-01-14 16:17:47,063 iteration 3183 : loss : 0.024966, loss_ce: 0.010360
2022-01-14 16:17:48,459 iteration 3184 : loss : 0.021315, loss_ce: 0.009980
2022-01-14 16:17:49,878 iteration 3185 : loss : 0.033325, loss_ce: 0.012775
2022-01-14 16:17:51,317 iteration 3186 : loss : 0.029453, loss_ce: 0.015326
2022-01-14 16:17:52,738 iteration 3187 : loss : 0.020576, loss_ce: 0.006795
2022-01-14 16:17:54,207 iteration 3188 : loss : 0.025278, loss_ce: 0.008249
2022-01-14 16:17:55,622 iteration 3189 : loss : 0.017716, loss_ce: 0.008121
2022-01-14 16:17:57,145 iteration 3190 : loss : 0.034566, loss_ce: 0.012883
2022-01-14 16:17:58,651 iteration 3191 : loss : 0.024893, loss_ce: 0.008347
2022-01-14 16:18:00,116 iteration 3192 : loss : 0.016989, loss_ce: 0.007031
2022-01-14 16:18:01,544 iteration 3193 : loss : 0.021050, loss_ce: 0.008612
2022-01-14 16:18:02,953 iteration 3194 : loss : 0.023670, loss_ce: 0.008387
2022-01-14 16:18:04,407 iteration 3195 : loss : 0.025918, loss_ce: 0.006593
2022-01-14 16:18:05,917 iteration 3196 : loss : 0.023351, loss_ce: 0.005386
 47%|████████████▋              | 188/400 [1:25:59<1:33:25, 26.44s/it]2022-01-14 16:18:07,412 iteration 3197 : loss : 0.020530, loss_ce: 0.006039
2022-01-14 16:18:08,842 iteration 3198 : loss : 0.022578, loss_ce: 0.008086
2022-01-14 16:18:10,252 iteration 3199 : loss : 0.020335, loss_ce: 0.007462
2022-01-14 16:18:11,688 iteration 3200 : loss : 0.023716, loss_ce: 0.010644
2022-01-14 16:18:13,191 iteration 3201 : loss : 0.028415, loss_ce: 0.010697
2022-01-14 16:18:14,690 iteration 3202 : loss : 0.026540, loss_ce: 0.011695
2022-01-14 16:18:16,097 iteration 3203 : loss : 0.027484, loss_ce: 0.005575
2022-01-14 16:18:17,586 iteration 3204 : loss : 0.022959, loss_ce: 0.011812
2022-01-14 16:18:19,083 iteration 3205 : loss : 0.021372, loss_ce: 0.006769
2022-01-14 16:18:20,512 iteration 3206 : loss : 0.020949, loss_ce: 0.008384
2022-01-14 16:18:21,931 iteration 3207 : loss : 0.018679, loss_ce: 0.005820
2022-01-14 16:18:23,365 iteration 3208 : loss : 0.038060, loss_ce: 0.012870
2022-01-14 16:18:24,869 iteration 3209 : loss : 0.029398, loss_ce: 0.011712
2022-01-14 16:18:26,353 iteration 3210 : loss : 0.035458, loss_ce: 0.011345
2022-01-14 16:18:27,880 iteration 3211 : loss : 0.023790, loss_ce: 0.011523
2022-01-14 16:18:29,395 iteration 3212 : loss : 0.021179, loss_ce: 0.008549
2022-01-14 16:18:30,859 iteration 3213 : loss : 0.021209, loss_ce: 0.011709
 47%|████████████▊              | 189/400 [1:26:24<1:31:24, 25.99s/it]2022-01-14 16:18:32,362 iteration 3214 : loss : 0.020515, loss_ce: 0.008357
2022-01-14 16:18:33,802 iteration 3215 : loss : 0.019855, loss_ce: 0.008729
2022-01-14 16:18:35,257 iteration 3216 : loss : 0.023784, loss_ce: 0.011169
2022-01-14 16:18:36,786 iteration 3217 : loss : 0.044411, loss_ce: 0.015161
2022-01-14 16:18:38,217 iteration 3218 : loss : 0.020710, loss_ce: 0.008498
2022-01-14 16:18:39,650 iteration 3219 : loss : 0.020264, loss_ce: 0.006303
2022-01-14 16:18:41,138 iteration 3220 : loss : 0.026928, loss_ce: 0.012824
2022-01-14 16:18:42,635 iteration 3221 : loss : 0.021094, loss_ce: 0.007225
2022-01-14 16:18:44,059 iteration 3222 : loss : 0.018835, loss_ce: 0.006695
2022-01-14 16:18:45,547 iteration 3223 : loss : 0.046419, loss_ce: 0.013887
2022-01-14 16:18:47,013 iteration 3224 : loss : 0.016227, loss_ce: 0.006232
2022-01-14 16:18:48,417 iteration 3225 : loss : 0.025254, loss_ce: 0.009618
2022-01-14 16:18:49,878 iteration 3226 : loss : 0.025924, loss_ce: 0.011648
2022-01-14 16:18:51,359 iteration 3227 : loss : 0.032971, loss_ce: 0.012578
2022-01-14 16:18:52,825 iteration 3228 : loss : 0.030456, loss_ce: 0.012224
2022-01-14 16:18:54,322 iteration 3229 : loss : 0.018398, loss_ce: 0.006828
2022-01-14 16:18:54,322 Training Data Eval:
2022-01-14 16:19:01,680   Average segmentation loss on training set: 0.0248
2022-01-14 16:19:01,680 Validation Data Eval:
2022-01-14 16:19:04,212   Average segmentation loss on validation set: 0.1904
2022-01-14 16:19:05,654 iteration 3230 : loss : 0.027715, loss_ce: 0.014840
 48%|████████████▊              | 190/400 [1:26:58<1:40:12, 28.63s/it]2022-01-14 16:19:07,064 iteration 3231 : loss : 0.019079, loss_ce: 0.006709
2022-01-14 16:19:08,541 iteration 3232 : loss : 0.019606, loss_ce: 0.007721
2022-01-14 16:19:10,019 iteration 3233 : loss : 0.021473, loss_ce: 0.006199
2022-01-14 16:19:11,473 iteration 3234 : loss : 0.017909, loss_ce: 0.007540
2022-01-14 16:19:12,976 iteration 3235 : loss : 0.020129, loss_ce: 0.007583
2022-01-14 16:19:14,361 iteration 3236 : loss : 0.019147, loss_ce: 0.009809
2022-01-14 16:19:15,828 iteration 3237 : loss : 0.019255, loss_ce: 0.007573
2022-01-14 16:19:17,309 iteration 3238 : loss : 0.033743, loss_ce: 0.012038
2022-01-14 16:19:18,690 iteration 3239 : loss : 0.020305, loss_ce: 0.008517
2022-01-14 16:19:20,189 iteration 3240 : loss : 0.027408, loss_ce: 0.010290
2022-01-14 16:19:21,746 iteration 3241 : loss : 0.037881, loss_ce: 0.013833
2022-01-14 16:19:23,233 iteration 3242 : loss : 0.028252, loss_ce: 0.013234
2022-01-14 16:19:24,747 iteration 3243 : loss : 0.024258, loss_ce: 0.009327
2022-01-14 16:19:26,175 iteration 3244 : loss : 0.023685, loss_ce: 0.008372
2022-01-14 16:19:27,664 iteration 3245 : loss : 0.033743, loss_ce: 0.011267
2022-01-14 16:19:29,169 iteration 3246 : loss : 0.030012, loss_ce: 0.010417
2022-01-14 16:19:30,752 iteration 3247 : loss : 0.029965, loss_ce: 0.010250
 48%|████████████▉              | 191/400 [1:27:24<1:36:02, 27.57s/it]2022-01-14 16:19:32,320 iteration 3248 : loss : 0.040066, loss_ce: 0.010590
2022-01-14 16:19:33,838 iteration 3249 : loss : 0.025501, loss_ce: 0.009005
2022-01-14 16:19:35,320 iteration 3250 : loss : 0.022989, loss_ce: 0.007519
2022-01-14 16:19:36,810 iteration 3251 : loss : 0.030420, loss_ce: 0.011795
2022-01-14 16:19:38,189 iteration 3252 : loss : 0.018192, loss_ce: 0.008983
2022-01-14 16:19:39,638 iteration 3253 : loss : 0.024417, loss_ce: 0.008966
2022-01-14 16:19:41,152 iteration 3254 : loss : 0.027031, loss_ce: 0.012852
2022-01-14 16:19:42,633 iteration 3255 : loss : 0.032178, loss_ce: 0.014468
2022-01-14 16:19:44,144 iteration 3256 : loss : 0.025031, loss_ce: 0.010844
2022-01-14 16:19:45,629 iteration 3257 : loss : 0.024428, loss_ce: 0.009294
2022-01-14 16:19:47,051 iteration 3258 : loss : 0.020248, loss_ce: 0.005262
2022-01-14 16:19:48,530 iteration 3259 : loss : 0.037018, loss_ce: 0.015243
2022-01-14 16:19:50,033 iteration 3260 : loss : 0.024641, loss_ce: 0.009553
2022-01-14 16:19:51,499 iteration 3261 : loss : 0.020393, loss_ce: 0.007830
2022-01-14 16:19:53,055 iteration 3262 : loss : 0.029259, loss_ce: 0.010319
2022-01-14 16:19:54,509 iteration 3263 : loss : 0.021862, loss_ce: 0.008383
2022-01-14 16:19:56,054 iteration 3264 : loss : 0.031165, loss_ce: 0.011378
 48%|████████████▉              | 192/400 [1:27:49<1:33:13, 26.89s/it]2022-01-14 16:19:57,542 iteration 3265 : loss : 0.021912, loss_ce: 0.009358
2022-01-14 16:19:59,049 iteration 3266 : loss : 0.030918, loss_ce: 0.012642
2022-01-14 16:20:00,535 iteration 3267 : loss : 0.019308, loss_ce: 0.006780
2022-01-14 16:20:02,019 iteration 3268 : loss : 0.030279, loss_ce: 0.010649
2022-01-14 16:20:03,451 iteration 3269 : loss : 0.026325, loss_ce: 0.012898
2022-01-14 16:20:04,930 iteration 3270 : loss : 0.024823, loss_ce: 0.008881
2022-01-14 16:20:06,322 iteration 3271 : loss : 0.025213, loss_ce: 0.008173
2022-01-14 16:20:07,864 iteration 3272 : loss : 0.028301, loss_ce: 0.010360
2022-01-14 16:20:09,328 iteration 3273 : loss : 0.019071, loss_ce: 0.007711
2022-01-14 16:20:10,734 iteration 3274 : loss : 0.021999, loss_ce: 0.007183
2022-01-14 16:20:12,182 iteration 3275 : loss : 0.022471, loss_ce: 0.006930
2022-01-14 16:20:13,631 iteration 3276 : loss : 0.025404, loss_ce: 0.006970
2022-01-14 16:20:15,036 iteration 3277 : loss : 0.016979, loss_ce: 0.005679
2022-01-14 16:20:16,491 iteration 3278 : loss : 0.022583, loss_ce: 0.009778
2022-01-14 16:20:17,861 iteration 3279 : loss : 0.027389, loss_ce: 0.015667
2022-01-14 16:20:19,391 iteration 3280 : loss : 0.021389, loss_ce: 0.008725
2022-01-14 16:20:20,854 iteration 3281 : loss : 0.016821, loss_ce: 0.004636
 48%|█████████████              | 193/400 [1:28:14<1:30:35, 26.26s/it]2022-01-14 16:20:22,402 iteration 3282 : loss : 0.030224, loss_ce: 0.006569
2022-01-14 16:20:23,945 iteration 3283 : loss : 0.026077, loss_ce: 0.008790
2022-01-14 16:20:25,430 iteration 3284 : loss : 0.021591, loss_ce: 0.008246
2022-01-14 16:20:26,936 iteration 3285 : loss : 0.028208, loss_ce: 0.007887
2022-01-14 16:20:28,410 iteration 3286 : loss : 0.031994, loss_ce: 0.009020
2022-01-14 16:20:29,966 iteration 3287 : loss : 0.031948, loss_ce: 0.013265
2022-01-14 16:20:31,382 iteration 3288 : loss : 0.022953, loss_ce: 0.009164
2022-01-14 16:20:32,960 iteration 3289 : loss : 0.021923, loss_ce: 0.008876
2022-01-14 16:20:34,498 iteration 3290 : loss : 0.021852, loss_ce: 0.007331
2022-01-14 16:20:36,045 iteration 3291 : loss : 0.036950, loss_ce: 0.016901
2022-01-14 16:20:37,517 iteration 3292 : loss : 0.031070, loss_ce: 0.009956
2022-01-14 16:20:38,984 iteration 3293 : loss : 0.029043, loss_ce: 0.007404
2022-01-14 16:20:40,555 iteration 3294 : loss : 0.026519, loss_ce: 0.010925
2022-01-14 16:20:42,072 iteration 3295 : loss : 0.020467, loss_ce: 0.008913
2022-01-14 16:20:43,497 iteration 3296 : loss : 0.025516, loss_ce: 0.008780
2022-01-14 16:20:44,944 iteration 3297 : loss : 0.020099, loss_ce: 0.006957
2022-01-14 16:20:46,522 iteration 3298 : loss : 0.021987, loss_ce: 0.009715
 48%|█████████████              | 194/400 [1:28:39<1:29:33, 26.09s/it]2022-01-14 16:20:47,966 iteration 3299 : loss : 0.022711, loss_ce: 0.005502
2022-01-14 16:20:49,485 iteration 3300 : loss : 0.035860, loss_ce: 0.012970
2022-01-14 16:20:50,965 iteration 3301 : loss : 0.020841, loss_ce: 0.009362
2022-01-14 16:20:52,421 iteration 3302 : loss : 0.031638, loss_ce: 0.010746
2022-01-14 16:20:53,959 iteration 3303 : loss : 0.028574, loss_ce: 0.014165
2022-01-14 16:20:55,477 iteration 3304 : loss : 0.024785, loss_ce: 0.008673
2022-01-14 16:20:56,943 iteration 3305 : loss : 0.026345, loss_ce: 0.008484
2022-01-14 16:20:58,413 iteration 3306 : loss : 0.021562, loss_ce: 0.006200
2022-01-14 16:21:00,015 iteration 3307 : loss : 0.050911, loss_ce: 0.022390
2022-01-14 16:21:01,560 iteration 3308 : loss : 0.032047, loss_ce: 0.016006
2022-01-14 16:21:03,094 iteration 3309 : loss : 0.026289, loss_ce: 0.013601
2022-01-14 16:21:04,529 iteration 3310 : loss : 0.021989, loss_ce: 0.011516
2022-01-14 16:21:06,087 iteration 3311 : loss : 0.029228, loss_ce: 0.010044
2022-01-14 16:21:07,562 iteration 3312 : loss : 0.025215, loss_ce: 0.007260
2022-01-14 16:21:09,111 iteration 3313 : loss : 0.026510, loss_ce: 0.011048
2022-01-14 16:21:10,592 iteration 3314 : loss : 0.021075, loss_ce: 0.007057
2022-01-14 16:21:10,593 Training Data Eval:
2022-01-14 16:21:17,960   Average segmentation loss on training set: 0.0171
2022-01-14 16:21:17,961 Validation Data Eval:
2022-01-14 16:21:20,498   Average segmentation loss on validation set: 0.0959
2022-01-14 16:21:21,917 iteration 3315 : loss : 0.020051, loss_ce: 0.008195
 49%|█████████████▏             | 195/400 [1:29:15<1:38:40, 28.88s/it]2022-01-14 16:21:23,386 iteration 3316 : loss : 0.021235, loss_ce: 0.008369
2022-01-14 16:21:24,871 iteration 3317 : loss : 0.023954, loss_ce: 0.011930
2022-01-14 16:21:26,333 iteration 3318 : loss : 0.041642, loss_ce: 0.018136
2022-01-14 16:21:27,756 iteration 3319 : loss : 0.023541, loss_ce: 0.008420
2022-01-14 16:21:29,315 iteration 3320 : loss : 0.036387, loss_ce: 0.013438
2022-01-14 16:21:30,762 iteration 3321 : loss : 0.027553, loss_ce: 0.010174
2022-01-14 16:21:32,290 iteration 3322 : loss : 0.041524, loss_ce: 0.010387
2022-01-14 16:21:33,714 iteration 3323 : loss : 0.019923, loss_ce: 0.006457
2022-01-14 16:21:35,180 iteration 3324 : loss : 0.024650, loss_ce: 0.011560
2022-01-14 16:21:36,686 iteration 3325 : loss : 0.027842, loss_ce: 0.011011
2022-01-14 16:21:38,118 iteration 3326 : loss : 0.035526, loss_ce: 0.011858
2022-01-14 16:21:39,583 iteration 3327 : loss : 0.024048, loss_ce: 0.007877
2022-01-14 16:21:41,118 iteration 3328 : loss : 0.025224, loss_ce: 0.008696
2022-01-14 16:21:42,619 iteration 3329 : loss : 0.026881, loss_ce: 0.010299
2022-01-14 16:21:44,062 iteration 3330 : loss : 0.020546, loss_ce: 0.009880
2022-01-14 16:21:45,457 iteration 3331 : loss : 0.021092, loss_ce: 0.009061
2022-01-14 16:21:46,956 iteration 3332 : loss : 0.020161, loss_ce: 0.006192
 49%|█████████████▏             | 196/400 [1:29:40<1:34:16, 27.73s/it]2022-01-14 16:21:48,509 iteration 3333 : loss : 0.038516, loss_ce: 0.014339
2022-01-14 16:21:50,014 iteration 3334 : loss : 0.030204, loss_ce: 0.014891
2022-01-14 16:21:51,577 iteration 3335 : loss : 0.025628, loss_ce: 0.009921
2022-01-14 16:21:53,060 iteration 3336 : loss : 0.022935, loss_ce: 0.007594
2022-01-14 16:21:54,663 iteration 3337 : loss : 0.028391, loss_ce: 0.009733
2022-01-14 16:21:56,251 iteration 3338 : loss : 0.034820, loss_ce: 0.013925
2022-01-14 16:21:57,677 iteration 3339 : loss : 0.020935, loss_ce: 0.008258
2022-01-14 16:21:59,087 iteration 3340 : loss : 0.029778, loss_ce: 0.006918
2022-01-14 16:22:00,559 iteration 3341 : loss : 0.028025, loss_ce: 0.010439
2022-01-14 16:22:02,013 iteration 3342 : loss : 0.018799, loss_ce: 0.008773
2022-01-14 16:22:03,517 iteration 3343 : loss : 0.021103, loss_ce: 0.008489
2022-01-14 16:22:04,995 iteration 3344 : loss : 0.027156, loss_ce: 0.009031
2022-01-14 16:22:06,484 iteration 3345 : loss : 0.035297, loss_ce: 0.017264
2022-01-14 16:22:07,926 iteration 3346 : loss : 0.016948, loss_ce: 0.007979
2022-01-14 16:22:09,362 iteration 3347 : loss : 0.023851, loss_ce: 0.008834
2022-01-14 16:22:10,760 iteration 3348 : loss : 0.020404, loss_ce: 0.007934
2022-01-14 16:22:12,297 iteration 3349 : loss : 0.020583, loss_ce: 0.006249
 49%|█████████████▎             | 197/400 [1:30:05<1:31:23, 27.01s/it]2022-01-14 16:22:13,825 iteration 3350 : loss : 0.032164, loss_ce: 0.011000
2022-01-14 16:22:15,353 iteration 3351 : loss : 0.033309, loss_ce: 0.010381
2022-01-14 16:22:16,868 iteration 3352 : loss : 0.040244, loss_ce: 0.017358
2022-01-14 16:22:18,429 iteration 3353 : loss : 0.027634, loss_ce: 0.008546
2022-01-14 16:22:19,884 iteration 3354 : loss : 0.024203, loss_ce: 0.009869
2022-01-14 16:22:21,430 iteration 3355 : loss : 0.029121, loss_ce: 0.012038
2022-01-14 16:22:22,967 iteration 3356 : loss : 0.034581, loss_ce: 0.010608
2022-01-14 16:22:24,432 iteration 3357 : loss : 0.028629, loss_ce: 0.007388
2022-01-14 16:22:25,964 iteration 3358 : loss : 0.019499, loss_ce: 0.008223
2022-01-14 16:22:27,380 iteration 3359 : loss : 0.021376, loss_ce: 0.006968
2022-01-14 16:22:28,835 iteration 3360 : loss : 0.023555, loss_ce: 0.008444
2022-01-14 16:22:30,309 iteration 3361 : loss : 0.023938, loss_ce: 0.009060
2022-01-14 16:22:31,776 iteration 3362 : loss : 0.022627, loss_ce: 0.007092
2022-01-14 16:22:33,326 iteration 3363 : loss : 0.030112, loss_ce: 0.007737
2022-01-14 16:22:34,744 iteration 3364 : loss : 0.021935, loss_ce: 0.009622
2022-01-14 16:22:36,249 iteration 3365 : loss : 0.024050, loss_ce: 0.008646
2022-01-14 16:22:37,650 iteration 3366 : loss : 0.018460, loss_ce: 0.007494
 50%|█████████████▎             | 198/400 [1:30:30<1:29:15, 26.51s/it]2022-01-14 16:22:39,169 iteration 3367 : loss : 0.022318, loss_ce: 0.008512
2022-01-14 16:22:40,620 iteration 3368 : loss : 0.021783, loss_ce: 0.010777
2022-01-14 16:22:42,024 iteration 3369 : loss : 0.020642, loss_ce: 0.006639
2022-01-14 16:22:43,552 iteration 3370 : loss : 0.039118, loss_ce: 0.015760
2022-01-14 16:22:45,146 iteration 3371 : loss : 0.033855, loss_ce: 0.011674
2022-01-14 16:22:46,583 iteration 3372 : loss : 0.017887, loss_ce: 0.007192
2022-01-14 16:22:48,068 iteration 3373 : loss : 0.023663, loss_ce: 0.008068
2022-01-14 16:22:49,489 iteration 3374 : loss : 0.020494, loss_ce: 0.006943
2022-01-14 16:22:50,921 iteration 3375 : loss : 0.025179, loss_ce: 0.008804
2022-01-14 16:22:52,394 iteration 3376 : loss : 0.021892, loss_ce: 0.006002
2022-01-14 16:22:53,767 iteration 3377 : loss : 0.015637, loss_ce: 0.005927
2022-01-14 16:22:55,260 iteration 3378 : loss : 0.047054, loss_ce: 0.009086
2022-01-14 16:22:56,824 iteration 3379 : loss : 0.033027, loss_ce: 0.015048
2022-01-14 16:22:58,348 iteration 3380 : loss : 0.022205, loss_ce: 0.006408
2022-01-14 16:22:59,865 iteration 3381 : loss : 0.036685, loss_ce: 0.014284
2022-01-14 16:23:01,358 iteration 3382 : loss : 0.019716, loss_ce: 0.007296
2022-01-14 16:23:02,802 iteration 3383 : loss : 0.022967, loss_ce: 0.008487
 50%|█████████████▍             | 199/400 [1:30:56<1:27:26, 26.10s/it]2022-01-14 16:23:04,376 iteration 3384 : loss : 0.031304, loss_ce: 0.009407
2022-01-14 16:23:05,890 iteration 3385 : loss : 0.025554, loss_ce: 0.008909
2022-01-14 16:23:07,324 iteration 3386 : loss : 0.021102, loss_ce: 0.007173
2022-01-14 16:23:08,865 iteration 3387 : loss : 0.034088, loss_ce: 0.012969
2022-01-14 16:23:10,370 iteration 3388 : loss : 0.025056, loss_ce: 0.011167
2022-01-14 16:23:11,820 iteration 3389 : loss : 0.015554, loss_ce: 0.006209
2022-01-14 16:23:13,178 iteration 3390 : loss : 0.015987, loss_ce: 0.006428
2022-01-14 16:23:14,690 iteration 3391 : loss : 0.030473, loss_ce: 0.011934
2022-01-14 16:23:16,197 iteration 3392 : loss : 0.022150, loss_ce: 0.007542
2022-01-14 16:23:17,686 iteration 3393 : loss : 0.027397, loss_ce: 0.010556
2022-01-14 16:23:19,195 iteration 3394 : loss : 0.020475, loss_ce: 0.007527
2022-01-14 16:23:20,606 iteration 3395 : loss : 0.016710, loss_ce: 0.006681
2022-01-14 16:23:22,133 iteration 3396 : loss : 0.020803, loss_ce: 0.008008
2022-01-14 16:23:23,637 iteration 3397 : loss : 0.021870, loss_ce: 0.009386
2022-01-14 16:23:25,144 iteration 3398 : loss : 0.020612, loss_ce: 0.008832
2022-01-14 16:23:26,633 iteration 3399 : loss : 0.023675, loss_ce: 0.008393
2022-01-14 16:23:26,633 Training Data Eval:
2022-01-14 16:23:33,985   Average segmentation loss on training set: 0.0168
2022-01-14 16:23:33,985 Validation Data Eval:
2022-01-14 16:23:36,520   Average segmentation loss on validation set: 0.0904
2022-01-14 16:23:37,920 iteration 3400 : loss : 0.016905, loss_ce: 0.005348
 50%|█████████████▌             | 200/400 [1:31:31<1:36:02, 28.81s/it]2022-01-14 16:23:39,457 iteration 3401 : loss : 0.026838, loss_ce: 0.014423
2022-01-14 16:23:40,865 iteration 3402 : loss : 0.021094, loss_ce: 0.007706
2022-01-14 16:23:42,422 iteration 3403 : loss : 0.034864, loss_ce: 0.015617
2022-01-14 16:23:43,958 iteration 3404 : loss : 0.022549, loss_ce: 0.008034
2022-01-14 16:23:45,381 iteration 3405 : loss : 0.025419, loss_ce: 0.009834
2022-01-14 16:23:46,928 iteration 3406 : loss : 0.024418, loss_ce: 0.009745
2022-01-14 16:23:48,390 iteration 3407 : loss : 0.023537, loss_ce: 0.009667
2022-01-14 16:23:49,791 iteration 3408 : loss : 0.020699, loss_ce: 0.007690
2022-01-14 16:23:51,265 iteration 3409 : loss : 0.017926, loss_ce: 0.005839
2022-01-14 16:23:52,810 iteration 3410 : loss : 0.020707, loss_ce: 0.008593
2022-01-14 16:23:54,365 iteration 3411 : loss : 0.022009, loss_ce: 0.008691
2022-01-14 16:23:55,924 iteration 3412 : loss : 0.021499, loss_ce: 0.008355
2022-01-14 16:23:57,441 iteration 3413 : loss : 0.019033, loss_ce: 0.004657
2022-01-14 16:23:59,021 iteration 3414 : loss : 0.025378, loss_ce: 0.011558
2022-01-14 16:24:00,517 iteration 3415 : loss : 0.017101, loss_ce: 0.007281
2022-01-14 16:24:02,073 iteration 3416 : loss : 0.021676, loss_ce: 0.006815
2022-01-14 16:24:03,614 iteration 3417 : loss : 0.029224, loss_ce: 0.008711
 50%|█████████████▌             | 201/400 [1:31:56<1:32:26, 27.87s/it]2022-01-14 16:24:05,081 iteration 3418 : loss : 0.014027, loss_ce: 0.004468
2022-01-14 16:24:06,458 iteration 3419 : loss : 0.016709, loss_ce: 0.007443
2022-01-14 16:24:07,886 iteration 3420 : loss : 0.021209, loss_ce: 0.007612
2022-01-14 16:24:09,300 iteration 3421 : loss : 0.017067, loss_ce: 0.006424
2022-01-14 16:24:10,704 iteration 3422 : loss : 0.020931, loss_ce: 0.007197
2022-01-14 16:24:12,195 iteration 3423 : loss : 0.036323, loss_ce: 0.016614
2022-01-14 16:24:13,677 iteration 3424 : loss : 0.034588, loss_ce: 0.014307
2022-01-14 16:24:15,172 iteration 3425 : loss : 0.020449, loss_ce: 0.007485
2022-01-14 16:24:16,551 iteration 3426 : loss : 0.022113, loss_ce: 0.008161
2022-01-14 16:24:18,023 iteration 3427 : loss : 0.025604, loss_ce: 0.007420
2022-01-14 16:24:19,521 iteration 3428 : loss : 0.025828, loss_ce: 0.012195
2022-01-14 16:24:20,958 iteration 3429 : loss : 0.027745, loss_ce: 0.008951
2022-01-14 16:24:22,462 iteration 3430 : loss : 0.023022, loss_ce: 0.009232
2022-01-14 16:24:23,950 iteration 3431 : loss : 0.029454, loss_ce: 0.011049
2022-01-14 16:24:25,496 iteration 3432 : loss : 0.036322, loss_ce: 0.015781
2022-01-14 16:24:27,025 iteration 3433 : loss : 0.032194, loss_ce: 0.010130
2022-01-14 16:24:28,504 iteration 3434 : loss : 0.028152, loss_ce: 0.008716
 50%|█████████████▋             | 202/400 [1:32:21<1:29:01, 26.98s/it]2022-01-14 16:24:30,012 iteration 3435 : loss : 0.024533, loss_ce: 0.008862
2022-01-14 16:24:31,546 iteration 3436 : loss : 0.043836, loss_ce: 0.017171
2022-01-14 16:24:33,098 iteration 3437 : loss : 0.027607, loss_ce: 0.010536
2022-01-14 16:24:34,646 iteration 3438 : loss : 0.035824, loss_ce: 0.014213
2022-01-14 16:24:36,075 iteration 3439 : loss : 0.021948, loss_ce: 0.008227
2022-01-14 16:24:37,578 iteration 3440 : loss : 0.028669, loss_ce: 0.011706
2022-01-14 16:24:39,030 iteration 3441 : loss : 0.026873, loss_ce: 0.008926
2022-01-14 16:24:40,513 iteration 3442 : loss : 0.022614, loss_ce: 0.009145
2022-01-14 16:24:42,081 iteration 3443 : loss : 0.030070, loss_ce: 0.012802
2022-01-14 16:24:43,538 iteration 3444 : loss : 0.025275, loss_ce: 0.008559
2022-01-14 16:24:45,041 iteration 3445 : loss : 0.035562, loss_ce: 0.014028
2022-01-14 16:24:46,569 iteration 3446 : loss : 0.020969, loss_ce: 0.010286
2022-01-14 16:24:48,093 iteration 3447 : loss : 0.033218, loss_ce: 0.009544
2022-01-14 16:24:49,511 iteration 3448 : loss : 0.026856, loss_ce: 0.011986
2022-01-14 16:24:50,948 iteration 3449 : loss : 0.021690, loss_ce: 0.008497
2022-01-14 16:24:52,401 iteration 3450 : loss : 0.021476, loss_ce: 0.007500
2022-01-14 16:24:53,861 iteration 3451 : loss : 0.017563, loss_ce: 0.009057
 51%|█████████████▋             | 203/400 [1:32:47<1:26:59, 26.50s/it]2022-01-14 16:24:55,299 iteration 3452 : loss : 0.018193, loss_ce: 0.007791
2022-01-14 16:24:56,818 iteration 3453 : loss : 0.024072, loss_ce: 0.009361
2022-01-14 16:24:58,435 iteration 3454 : loss : 0.032880, loss_ce: 0.011705
2022-01-14 16:24:59,897 iteration 3455 : loss : 0.023952, loss_ce: 0.010020
2022-01-14 16:25:01,396 iteration 3456 : loss : 0.034026, loss_ce: 0.009104
2022-01-14 16:25:02,823 iteration 3457 : loss : 0.032095, loss_ce: 0.014839
2022-01-14 16:25:04,237 iteration 3458 : loss : 0.024431, loss_ce: 0.006801
2022-01-14 16:25:05,769 iteration 3459 : loss : 0.027164, loss_ce: 0.010807
2022-01-14 16:25:07,187 iteration 3460 : loss : 0.018872, loss_ce: 0.007438
2022-01-14 16:25:08,603 iteration 3461 : loss : 0.017211, loss_ce: 0.005945
2022-01-14 16:25:09,961 iteration 3462 : loss : 0.019553, loss_ce: 0.008848
2022-01-14 16:25:11,467 iteration 3463 : loss : 0.026330, loss_ce: 0.009853
2022-01-14 16:25:12,953 iteration 3464 : loss : 0.022637, loss_ce: 0.008774
2022-01-14 16:25:14,388 iteration 3465 : loss : 0.020527, loss_ce: 0.007176
2022-01-14 16:25:15,946 iteration 3466 : loss : 0.030930, loss_ce: 0.012674
2022-01-14 16:25:17,347 iteration 3467 : loss : 0.016094, loss_ce: 0.006071
2022-01-14 16:25:18,804 iteration 3468 : loss : 0.022012, loss_ce: 0.006678
 51%|█████████████▊             | 204/400 [1:33:12<1:25:01, 26.03s/it]2022-01-14 16:25:20,302 iteration 3469 : loss : 0.022748, loss_ce: 0.010741
2022-01-14 16:25:21,763 iteration 3470 : loss : 0.022744, loss_ce: 0.009917
2022-01-14 16:25:23,302 iteration 3471 : loss : 0.024174, loss_ce: 0.009914
2022-01-14 16:25:24,864 iteration 3472 : loss : 0.033766, loss_ce: 0.010505
2022-01-14 16:25:26,296 iteration 3473 : loss : 0.016860, loss_ce: 0.007745
2022-01-14 16:25:27,823 iteration 3474 : loss : 0.022877, loss_ce: 0.007858
2022-01-14 16:25:29,307 iteration 3475 : loss : 0.019829, loss_ce: 0.008603
2022-01-14 16:25:30,751 iteration 3476 : loss : 0.021742, loss_ce: 0.006188
2022-01-14 16:25:32,214 iteration 3477 : loss : 0.020084, loss_ce: 0.006501
2022-01-14 16:25:33,697 iteration 3478 : loss : 0.017222, loss_ce: 0.007998
2022-01-14 16:25:35,159 iteration 3479 : loss : 0.017778, loss_ce: 0.007606
2022-01-14 16:25:36,582 iteration 3480 : loss : 0.018053, loss_ce: 0.008712
2022-01-14 16:25:38,016 iteration 3481 : loss : 0.021202, loss_ce: 0.006365
2022-01-14 16:25:39,472 iteration 3482 : loss : 0.017422, loss_ce: 0.006376
2022-01-14 16:25:41,012 iteration 3483 : loss : 0.022693, loss_ce: 0.009271
2022-01-14 16:25:42,514 iteration 3484 : loss : 0.059502, loss_ce: 0.016526
2022-01-14 16:25:42,515 Training Data Eval:
2022-01-14 16:25:49,869   Average segmentation loss on training set: 0.0142
2022-01-14 16:25:49,869 Validation Data Eval:
2022-01-14 16:25:52,405   Average segmentation loss on validation set: 0.0726
2022-01-14 16:25:53,861 iteration 3485 : loss : 0.017092, loss_ce: 0.006059
 51%|█████████████▊             | 205/400 [1:33:47<1:33:23, 28.74s/it]2022-01-14 16:25:55,393 iteration 3486 : loss : 0.030236, loss_ce: 0.008491
2022-01-14 16:25:56,864 iteration 3487 : loss : 0.029014, loss_ce: 0.013470
2022-01-14 16:25:58,331 iteration 3488 : loss : 0.024808, loss_ce: 0.008219
2022-01-14 16:25:59,692 iteration 3489 : loss : 0.021803, loss_ce: 0.010243
2022-01-14 16:26:01,201 iteration 3490 : loss : 0.031408, loss_ce: 0.012891
2022-01-14 16:26:02,782 iteration 3491 : loss : 0.026549, loss_ce: 0.012419
2022-01-14 16:26:04,276 iteration 3492 : loss : 0.018587, loss_ce: 0.005473
2022-01-14 16:26:05,729 iteration 3493 : loss : 0.026785, loss_ce: 0.010943
2022-01-14 16:26:07,216 iteration 3494 : loss : 0.019407, loss_ce: 0.007444
2022-01-14 16:26:08,721 iteration 3495 : loss : 0.020645, loss_ce: 0.005936
2022-01-14 16:26:10,310 iteration 3496 : loss : 0.031832, loss_ce: 0.011034
2022-01-14 16:26:11,789 iteration 3497 : loss : 0.019311, loss_ce: 0.007379
2022-01-14 16:26:13,308 iteration 3498 : loss : 0.018481, loss_ce: 0.007466
2022-01-14 16:26:14,760 iteration 3499 : loss : 0.021842, loss_ce: 0.010215
2022-01-14 16:26:16,243 iteration 3500 : loss : 0.022608, loss_ce: 0.009587
2022-01-14 16:26:17,806 iteration 3501 : loss : 0.020451, loss_ce: 0.007908
2022-01-14 16:26:19,277 iteration 3502 : loss : 0.020587, loss_ce: 0.010575
 52%|█████████████▉             | 206/400 [1:34:12<1:29:41, 27.74s/it]2022-01-14 16:26:20,824 iteration 3503 : loss : 0.027212, loss_ce: 0.007370
2022-01-14 16:26:22,297 iteration 3504 : loss : 0.018955, loss_ce: 0.006555
2022-01-14 16:26:23,798 iteration 3505 : loss : 0.016165, loss_ce: 0.006843
2022-01-14 16:26:25,324 iteration 3506 : loss : 0.024539, loss_ce: 0.007917
2022-01-14 16:26:26,750 iteration 3507 : loss : 0.017091, loss_ce: 0.006499
2022-01-14 16:26:28,219 iteration 3508 : loss : 0.032795, loss_ce: 0.006303
2022-01-14 16:26:29,741 iteration 3509 : loss : 0.022026, loss_ce: 0.007961
2022-01-14 16:26:31,213 iteration 3510 : loss : 0.025911, loss_ce: 0.010894
2022-01-14 16:26:32,888 iteration 3511 : loss : 0.047781, loss_ce: 0.020438
2022-01-14 16:26:34,317 iteration 3512 : loss : 0.017465, loss_ce: 0.006210
2022-01-14 16:26:35,709 iteration 3513 : loss : 0.021889, loss_ce: 0.008977
2022-01-14 16:26:37,177 iteration 3514 : loss : 0.021094, loss_ce: 0.009540
2022-01-14 16:26:38,639 iteration 3515 : loss : 0.024069, loss_ce: 0.011384
2022-01-14 16:26:40,089 iteration 3516 : loss : 0.020498, loss_ce: 0.008937
2022-01-14 16:26:41,556 iteration 3517 : loss : 0.022129, loss_ce: 0.009893
2022-01-14 16:26:43,120 iteration 3518 : loss : 0.028629, loss_ce: 0.008615
2022-01-14 16:26:44,642 iteration 3519 : loss : 0.021343, loss_ce: 0.008572
 52%|█████████████▉             | 207/400 [1:34:37<1:26:56, 27.03s/it]2022-01-14 16:26:46,094 iteration 3520 : loss : 0.027177, loss_ce: 0.009415
2022-01-14 16:26:47,549 iteration 3521 : loss : 0.026967, loss_ce: 0.006267
2022-01-14 16:26:48,966 iteration 3522 : loss : 0.023890, loss_ce: 0.006950
2022-01-14 16:26:50,472 iteration 3523 : loss : 0.025454, loss_ce: 0.013199
2022-01-14 16:26:52,027 iteration 3524 : loss : 0.025018, loss_ce: 0.010382
2022-01-14 16:26:53,474 iteration 3525 : loss : 0.032437, loss_ce: 0.009844
2022-01-14 16:26:54,971 iteration 3526 : loss : 0.018523, loss_ce: 0.008931
2022-01-14 16:26:56,536 iteration 3527 : loss : 0.027732, loss_ce: 0.012325
2022-01-14 16:26:57,989 iteration 3528 : loss : 0.051484, loss_ce: 0.010639
2022-01-14 16:26:59,456 iteration 3529 : loss : 0.023730, loss_ce: 0.007521
2022-01-14 16:27:00,926 iteration 3530 : loss : 0.025035, loss_ce: 0.009757
2022-01-14 16:27:02,398 iteration 3531 : loss : 0.037022, loss_ce: 0.013735
2022-01-14 16:27:03,891 iteration 3532 : loss : 0.033271, loss_ce: 0.014257
2022-01-14 16:27:05,403 iteration 3533 : loss : 0.032334, loss_ce: 0.012323
2022-01-14 16:27:06,823 iteration 3534 : loss : 0.030643, loss_ce: 0.012365
2022-01-14 16:27:08,346 iteration 3535 : loss : 0.027489, loss_ce: 0.011017
2022-01-14 16:27:09,811 iteration 3536 : loss : 0.025396, loss_ce: 0.010195
 52%|██████████████             | 208/400 [1:35:03<1:24:41, 26.47s/it]2022-01-14 16:27:11,415 iteration 3537 : loss : 0.027854, loss_ce: 0.012823
2022-01-14 16:27:12,863 iteration 3538 : loss : 0.019283, loss_ce: 0.007184
2022-01-14 16:27:14,309 iteration 3539 : loss : 0.023619, loss_ce: 0.007672
2022-01-14 16:27:15,818 iteration 3540 : loss : 0.027786, loss_ce: 0.011707
2022-01-14 16:27:17,345 iteration 3541 : loss : 0.031597, loss_ce: 0.011622
2022-01-14 16:27:18,854 iteration 3542 : loss : 0.024496, loss_ce: 0.009086
2022-01-14 16:27:20,411 iteration 3543 : loss : 0.025048, loss_ce: 0.010415
2022-01-14 16:27:21,948 iteration 3544 : loss : 0.042522, loss_ce: 0.008656
2022-01-14 16:27:23,493 iteration 3545 : loss : 0.024104, loss_ce: 0.007473
2022-01-14 16:27:25,027 iteration 3546 : loss : 0.029122, loss_ce: 0.009850
2022-01-14 16:27:26,586 iteration 3547 : loss : 0.026623, loss_ce: 0.011813
2022-01-14 16:27:28,028 iteration 3548 : loss : 0.016965, loss_ce: 0.004638
2022-01-14 16:27:29,605 iteration 3549 : loss : 0.043784, loss_ce: 0.019572
2022-01-14 16:27:31,068 iteration 3550 : loss : 0.020404, loss_ce: 0.006797
2022-01-14 16:27:32,513 iteration 3551 : loss : 0.023188, loss_ce: 0.010401
2022-01-14 16:27:33,944 iteration 3552 : loss : 0.024748, loss_ce: 0.011578
2022-01-14 16:27:35,387 iteration 3553 : loss : 0.019753, loss_ce: 0.007432
 52%|██████████████             | 209/400 [1:35:28<1:23:24, 26.20s/it]2022-01-14 16:27:36,898 iteration 3554 : loss : 0.024287, loss_ce: 0.009169
2022-01-14 16:27:38,364 iteration 3555 : loss : 0.025335, loss_ce: 0.011005
2022-01-14 16:27:39,906 iteration 3556 : loss : 0.026512, loss_ce: 0.011742
2022-01-14 16:27:41,467 iteration 3557 : loss : 0.024663, loss_ce: 0.010344
2022-01-14 16:27:42,941 iteration 3558 : loss : 0.042415, loss_ce: 0.012351
2022-01-14 16:27:44,435 iteration 3559 : loss : 0.041034, loss_ce: 0.010200
2022-01-14 16:27:45,908 iteration 3560 : loss : 0.021316, loss_ce: 0.008753
2022-01-14 16:27:47,300 iteration 3561 : loss : 0.015690, loss_ce: 0.007538
2022-01-14 16:27:48,793 iteration 3562 : loss : 0.024324, loss_ce: 0.008976
2022-01-14 16:27:50,276 iteration 3563 : loss : 0.020374, loss_ce: 0.007295
2022-01-14 16:27:51,805 iteration 3564 : loss : 0.035353, loss_ce: 0.008638
2022-01-14 16:27:53,236 iteration 3565 : loss : 0.028591, loss_ce: 0.007703
2022-01-14 16:27:54,663 iteration 3566 : loss : 0.025721, loss_ce: 0.010800
2022-01-14 16:27:56,216 iteration 3567 : loss : 0.042861, loss_ce: 0.026172
2022-01-14 16:27:57,686 iteration 3568 : loss : 0.030048, loss_ce: 0.009909
2022-01-14 16:27:59,117 iteration 3569 : loss : 0.025778, loss_ce: 0.011051
2022-01-14 16:27:59,117 Training Data Eval:
2022-01-14 16:28:06,466   Average segmentation loss on training set: 0.0166
2022-01-14 16:28:06,467 Validation Data Eval:
2022-01-14 16:28:09,001   Average segmentation loss on validation set: 0.1260
2022-01-14 16:28:10,505 iteration 3570 : loss : 0.027871, loss_ce: 0.007569
 52%|██████████████▏            | 210/400 [1:36:03<1:31:26, 28.88s/it]2022-01-14 16:28:12,051 iteration 3571 : loss : 0.023316, loss_ce: 0.011347
2022-01-14 16:28:13,469 iteration 3572 : loss : 0.021662, loss_ce: 0.007240
2022-01-14 16:28:14,964 iteration 3573 : loss : 0.060696, loss_ce: 0.024302
2022-01-14 16:28:16,439 iteration 3574 : loss : 0.021591, loss_ce: 0.006508
2022-01-14 16:28:17,863 iteration 3575 : loss : 0.032890, loss_ce: 0.013975
2022-01-14 16:28:19,386 iteration 3576 : loss : 0.026227, loss_ce: 0.008868
2022-01-14 16:28:20,907 iteration 3577 : loss : 0.022674, loss_ce: 0.009344
2022-01-14 16:28:22,286 iteration 3578 : loss : 0.034664, loss_ce: 0.012560
2022-01-14 16:28:23,728 iteration 3579 : loss : 0.022399, loss_ce: 0.009062
2022-01-14 16:28:25,153 iteration 3580 : loss : 0.030435, loss_ce: 0.010676
2022-01-14 16:28:26,568 iteration 3581 : loss : 0.024204, loss_ce: 0.013913
2022-01-14 16:28:28,027 iteration 3582 : loss : 0.018156, loss_ce: 0.006812
2022-01-14 16:28:29,534 iteration 3583 : loss : 0.023230, loss_ce: 0.007291
2022-01-14 16:28:31,026 iteration 3584 : loss : 0.020950, loss_ce: 0.007829
2022-01-14 16:28:32,452 iteration 3585 : loss : 0.024549, loss_ce: 0.009273
2022-01-14 16:28:34,066 iteration 3586 : loss : 0.021322, loss_ce: 0.009477
2022-01-14 16:28:35,557 iteration 3587 : loss : 0.019036, loss_ce: 0.007817
 53%|██████████████▏            | 211/400 [1:36:28<1:27:21, 27.73s/it]2022-01-14 16:28:37,202 iteration 3588 : loss : 0.019854, loss_ce: 0.008146
2022-01-14 16:28:38,635 iteration 3589 : loss : 0.017400, loss_ce: 0.005702
2022-01-14 16:28:40,091 iteration 3590 : loss : 0.021264, loss_ce: 0.007829
2022-01-14 16:28:41,561 iteration 3591 : loss : 0.019926, loss_ce: 0.006795
2022-01-14 16:28:43,203 iteration 3592 : loss : 0.028002, loss_ce: 0.009562
2022-01-14 16:28:44,658 iteration 3593 : loss : 0.021716, loss_ce: 0.008739
2022-01-14 16:28:46,126 iteration 3594 : loss : 0.022816, loss_ce: 0.008792
2022-01-14 16:28:47,629 iteration 3595 : loss : 0.026932, loss_ce: 0.009940
2022-01-14 16:28:49,108 iteration 3596 : loss : 0.016530, loss_ce: 0.005984
2022-01-14 16:28:50,628 iteration 3597 : loss : 0.025542, loss_ce: 0.010175
2022-01-14 16:28:52,046 iteration 3598 : loss : 0.014387, loss_ce: 0.006085
2022-01-14 16:28:53,562 iteration 3599 : loss : 0.032486, loss_ce: 0.011636
2022-01-14 16:28:54,926 iteration 3600 : loss : 0.019069, loss_ce: 0.007164
2022-01-14 16:28:56,398 iteration 3601 : loss : 0.029504, loss_ce: 0.010799
2022-01-14 16:28:57,815 iteration 3602 : loss : 0.018576, loss_ce: 0.006042
2022-01-14 16:28:59,303 iteration 3603 : loss : 0.024899, loss_ce: 0.013245
2022-01-14 16:29:00,707 iteration 3604 : loss : 0.016644, loss_ce: 0.006901
 53%|██████████████▎            | 212/400 [1:36:54<1:24:27, 26.96s/it]2022-01-14 16:29:02,228 iteration 3605 : loss : 0.020519, loss_ce: 0.008490
2022-01-14 16:29:03,674 iteration 3606 : loss : 0.027863, loss_ce: 0.013497
2022-01-14 16:29:05,172 iteration 3607 : loss : 0.024989, loss_ce: 0.010146
2022-01-14 16:29:06,629 iteration 3608 : loss : 0.016718, loss_ce: 0.006114
2022-01-14 16:29:08,071 iteration 3609 : loss : 0.017411, loss_ce: 0.007890
2022-01-14 16:29:09,543 iteration 3610 : loss : 0.017514, loss_ce: 0.007598
2022-01-14 16:29:10,944 iteration 3611 : loss : 0.016272, loss_ce: 0.004531
2022-01-14 16:29:12,352 iteration 3612 : loss : 0.016416, loss_ce: 0.005817
2022-01-14 16:29:13,915 iteration 3613 : loss : 0.036610, loss_ce: 0.017167
2022-01-14 16:29:15,339 iteration 3614 : loss : 0.018218, loss_ce: 0.007334
2022-01-14 16:29:16,714 iteration 3615 : loss : 0.016936, loss_ce: 0.006272
2022-01-14 16:29:18,194 iteration 3616 : loss : 0.026242, loss_ce: 0.010120
2022-01-14 16:29:19,698 iteration 3617 : loss : 0.022940, loss_ce: 0.009600
2022-01-14 16:29:21,186 iteration 3618 : loss : 0.030613, loss_ce: 0.012080
2022-01-14 16:29:22,663 iteration 3619 : loss : 0.026706, loss_ce: 0.006911
2022-01-14 16:29:24,089 iteration 3620 : loss : 0.032816, loss_ce: 0.011475
2022-01-14 16:29:25,570 iteration 3621 : loss : 0.024494, loss_ce: 0.008103
 53%|██████████████▍            | 213/400 [1:37:18<1:22:02, 26.33s/it]2022-01-14 16:29:27,088 iteration 3622 : loss : 0.020008, loss_ce: 0.008877
2022-01-14 16:29:28,617 iteration 3623 : loss : 0.019139, loss_ce: 0.004424
2022-01-14 16:29:30,088 iteration 3624 : loss : 0.014338, loss_ce: 0.005725
2022-01-14 16:29:31,544 iteration 3625 : loss : 0.020664, loss_ce: 0.007849
2022-01-14 16:29:32,965 iteration 3626 : loss : 0.019750, loss_ce: 0.009181
2022-01-14 16:29:34,374 iteration 3627 : loss : 0.016647, loss_ce: 0.006051
2022-01-14 16:29:35,898 iteration 3628 : loss : 0.038495, loss_ce: 0.011603
2022-01-14 16:29:37,522 iteration 3629 : loss : 0.026319, loss_ce: 0.009832
2022-01-14 16:29:38,907 iteration 3630 : loss : 0.022328, loss_ce: 0.009179
2022-01-14 16:29:40,379 iteration 3631 : loss : 0.022890, loss_ce: 0.006433
2022-01-14 16:29:41,969 iteration 3632 : loss : 0.026738, loss_ce: 0.008771
2022-01-14 16:29:43,440 iteration 3633 : loss : 0.015208, loss_ce: 0.005443
2022-01-14 16:29:44,894 iteration 3634 : loss : 0.018219, loss_ce: 0.007864
2022-01-14 16:29:46,494 iteration 3635 : loss : 0.049898, loss_ce: 0.021725
2022-01-14 16:29:48,032 iteration 3636 : loss : 0.027085, loss_ce: 0.009589
2022-01-14 16:29:49,507 iteration 3637 : loss : 0.023775, loss_ce: 0.007922
2022-01-14 16:29:50,978 iteration 3638 : loss : 0.017646, loss_ce: 0.007721
 54%|██████████████▍            | 214/400 [1:37:44<1:20:45, 26.05s/it]2022-01-14 16:29:52,448 iteration 3639 : loss : 0.018278, loss_ce: 0.007308
2022-01-14 16:29:53,860 iteration 3640 : loss : 0.021633, loss_ce: 0.008351
2022-01-14 16:29:55,272 iteration 3641 : loss : 0.018786, loss_ce: 0.005924
2022-01-14 16:29:56,751 iteration 3642 : loss : 0.024019, loss_ce: 0.007442
2022-01-14 16:29:58,165 iteration 3643 : loss : 0.018742, loss_ce: 0.007775
2022-01-14 16:29:59,595 iteration 3644 : loss : 0.014496, loss_ce: 0.005175
2022-01-14 16:30:01,063 iteration 3645 : loss : 0.018546, loss_ce: 0.005810
2022-01-14 16:30:02,535 iteration 3646 : loss : 0.033091, loss_ce: 0.009883
2022-01-14 16:30:04,013 iteration 3647 : loss : 0.021296, loss_ce: 0.005162
2022-01-14 16:30:05,512 iteration 3648 : loss : 0.036001, loss_ce: 0.014787
2022-01-14 16:30:06,967 iteration 3649 : loss : 0.021653, loss_ce: 0.005514
2022-01-14 16:30:08,449 iteration 3650 : loss : 0.027560, loss_ce: 0.015095
2022-01-14 16:30:09,947 iteration 3651 : loss : 0.028194, loss_ce: 0.010236
2022-01-14 16:30:11,553 iteration 3652 : loss : 0.042453, loss_ce: 0.013469
2022-01-14 16:30:12,990 iteration 3653 : loss : 0.021172, loss_ce: 0.011420
2022-01-14 16:30:14,398 iteration 3654 : loss : 0.017651, loss_ce: 0.008809
2022-01-14 16:30:14,399 Training Data Eval:
2022-01-14 16:30:21,753   Average segmentation loss on training set: 0.0172
2022-01-14 16:30:21,754 Validation Data Eval:
2022-01-14 16:30:24,298   Average segmentation loss on validation set: 0.0619
2022-01-14 16:30:25,782 iteration 3655 : loss : 0.018686, loss_ce: 0.007477
 54%|██████████████▌            | 215/400 [1:38:19<1:28:25, 28.68s/it]2022-01-14 16:30:27,344 iteration 3656 : loss : 0.034009, loss_ce: 0.012142
2022-01-14 16:30:28,771 iteration 3657 : loss : 0.019474, loss_ce: 0.009745
2022-01-14 16:30:30,303 iteration 3658 : loss : 0.021461, loss_ce: 0.009382
2022-01-14 16:30:31,880 iteration 3659 : loss : 0.043406, loss_ce: 0.013706
2022-01-14 16:30:33,360 iteration 3660 : loss : 0.031594, loss_ce: 0.006902
2022-01-14 16:30:34,772 iteration 3661 : loss : 0.018866, loss_ce: 0.007895
2022-01-14 16:30:36,247 iteration 3662 : loss : 0.022018, loss_ce: 0.007682
2022-01-14 16:30:37,700 iteration 3663 : loss : 0.028490, loss_ce: 0.008137
2022-01-14 16:30:39,201 iteration 3664 : loss : 0.016275, loss_ce: 0.005559
2022-01-14 16:30:40,670 iteration 3665 : loss : 0.034329, loss_ce: 0.018454
2022-01-14 16:30:42,130 iteration 3666 : loss : 0.026763, loss_ce: 0.009689
2022-01-14 16:30:43,580 iteration 3667 : loss : 0.029565, loss_ce: 0.012929
2022-01-14 16:30:44,962 iteration 3668 : loss : 0.021616, loss_ce: 0.004894
2022-01-14 16:30:46,484 iteration 3669 : loss : 0.034626, loss_ce: 0.019794
2022-01-14 16:30:47,902 iteration 3670 : loss : 0.026854, loss_ce: 0.009239
2022-01-14 16:30:49,352 iteration 3671 : loss : 0.018764, loss_ce: 0.008784
2022-01-14 16:30:50,960 iteration 3672 : loss : 0.042213, loss_ce: 0.010839
 54%|██████████████▌            | 216/400 [1:38:44<1:24:43, 27.63s/it]2022-01-14 16:30:52,499 iteration 3673 : loss : 0.022045, loss_ce: 0.009415
2022-01-14 16:30:54,030 iteration 3674 : loss : 0.025008, loss_ce: 0.006579
2022-01-14 16:30:55,591 iteration 3675 : loss : 0.034642, loss_ce: 0.013819
2022-01-14 16:30:56,997 iteration 3676 : loss : 0.019329, loss_ce: 0.007790
2022-01-14 16:30:58,484 iteration 3677 : loss : 0.026229, loss_ce: 0.008072
2022-01-14 16:31:00,031 iteration 3678 : loss : 0.031529, loss_ce: 0.008919
2022-01-14 16:31:01,497 iteration 3679 : loss : 0.022201, loss_ce: 0.008391
2022-01-14 16:31:02,980 iteration 3680 : loss : 0.032744, loss_ce: 0.013766
2022-01-14 16:31:04,470 iteration 3681 : loss : 0.022226, loss_ce: 0.009973
2022-01-14 16:31:05,868 iteration 3682 : loss : 0.022325, loss_ce: 0.008607
2022-01-14 16:31:07,249 iteration 3683 : loss : 0.020267, loss_ce: 0.007606
2022-01-14 16:31:08,773 iteration 3684 : loss : 0.019312, loss_ce: 0.007509
2022-01-14 16:31:10,211 iteration 3685 : loss : 0.020516, loss_ce: 0.006405
2022-01-14 16:31:11,702 iteration 3686 : loss : 0.022147, loss_ce: 0.008029
2022-01-14 16:31:13,145 iteration 3687 : loss : 0.024609, loss_ce: 0.009908
2022-01-14 16:31:14,613 iteration 3688 : loss : 0.018931, loss_ce: 0.009764
2022-01-14 16:31:16,102 iteration 3689 : loss : 0.025147, loss_ce: 0.007713
 54%|██████████████▋            | 217/400 [1:39:09<1:21:58, 26.88s/it]2022-01-14 16:31:17,619 iteration 3690 : loss : 0.022673, loss_ce: 0.005101
2022-01-14 16:31:19,122 iteration 3691 : loss : 0.038833, loss_ce: 0.008240
2022-01-14 16:31:20,615 iteration 3692 : loss : 0.021419, loss_ce: 0.009463
2022-01-14 16:31:22,032 iteration 3693 : loss : 0.020578, loss_ce: 0.009205
2022-01-14 16:31:23,502 iteration 3694 : loss : 0.031885, loss_ce: 0.014676
2022-01-14 16:31:24,982 iteration 3695 : loss : 0.020407, loss_ce: 0.009602
2022-01-14 16:31:26,441 iteration 3696 : loss : 0.033998, loss_ce: 0.011733
2022-01-14 16:31:27,940 iteration 3697 : loss : 0.024697, loss_ce: 0.007889
2022-01-14 16:31:29,503 iteration 3698 : loss : 0.039512, loss_ce: 0.015075
2022-01-14 16:31:30,926 iteration 3699 : loss : 0.018555, loss_ce: 0.007781
2022-01-14 16:31:32,407 iteration 3700 : loss : 0.020241, loss_ce: 0.006136
2022-01-14 16:31:33,790 iteration 3701 : loss : 0.022052, loss_ce: 0.009609
2022-01-14 16:31:35,275 iteration 3702 : loss : 0.024488, loss_ce: 0.007977
2022-01-14 16:31:36,753 iteration 3703 : loss : 0.025032, loss_ce: 0.011736
2022-01-14 16:31:38,204 iteration 3704 : loss : 0.018210, loss_ce: 0.007553
2022-01-14 16:31:39,739 iteration 3705 : loss : 0.033643, loss_ce: 0.013157
2022-01-14 16:31:41,127 iteration 3706 : loss : 0.018081, loss_ce: 0.005478
 55%|██████████████▋            | 218/400 [1:39:34<1:19:51, 26.32s/it]2022-01-14 16:31:42,661 iteration 3707 : loss : 0.021726, loss_ce: 0.009833
2022-01-14 16:31:44,050 iteration 3708 : loss : 0.021688, loss_ce: 0.007055
2022-01-14 16:31:45,617 iteration 3709 : loss : 0.036412, loss_ce: 0.011862
2022-01-14 16:31:47,089 iteration 3710 : loss : 0.026233, loss_ce: 0.009602
2022-01-14 16:31:48,542 iteration 3711 : loss : 0.017457, loss_ce: 0.006112
2022-01-14 16:31:49,958 iteration 3712 : loss : 0.019688, loss_ce: 0.008869
2022-01-14 16:31:51,520 iteration 3713 : loss : 0.025541, loss_ce: 0.008850
2022-01-14 16:31:53,001 iteration 3714 : loss : 0.022473, loss_ce: 0.008314
2022-01-14 16:31:54,445 iteration 3715 : loss : 0.020711, loss_ce: 0.009090
2022-01-14 16:31:55,910 iteration 3716 : loss : 0.022323, loss_ce: 0.011883
2022-01-14 16:31:57,421 iteration 3717 : loss : 0.022199, loss_ce: 0.008932
2022-01-14 16:31:58,871 iteration 3718 : loss : 0.022148, loss_ce: 0.008152
2022-01-14 16:32:00,350 iteration 3719 : loss : 0.023048, loss_ce: 0.008231
2022-01-14 16:32:01,915 iteration 3720 : loss : 0.022746, loss_ce: 0.006338
2022-01-14 16:32:03,365 iteration 3721 : loss : 0.014663, loss_ce: 0.005450
2022-01-14 16:32:04,816 iteration 3722 : loss : 0.026462, loss_ce: 0.012439
2022-01-14 16:32:06,338 iteration 3723 : loss : 0.024379, loss_ce: 0.005843
 55%|██████████████▊            | 219/400 [1:39:59<1:18:24, 25.99s/it]2022-01-14 16:32:07,904 iteration 3724 : loss : 0.022309, loss_ce: 0.009428
2022-01-14 16:32:09,382 iteration 3725 : loss : 0.020837, loss_ce: 0.009517
2022-01-14 16:32:10,983 iteration 3726 : loss : 0.027634, loss_ce: 0.011390
2022-01-14 16:32:12,412 iteration 3727 : loss : 0.012906, loss_ce: 0.003987
2022-01-14 16:32:13,882 iteration 3728 : loss : 0.024181, loss_ce: 0.012182
2022-01-14 16:32:15,411 iteration 3729 : loss : 0.031777, loss_ce: 0.011873
2022-01-14 16:32:16,858 iteration 3730 : loss : 0.032979, loss_ce: 0.008947
2022-01-14 16:32:18,273 iteration 3731 : loss : 0.023193, loss_ce: 0.007461
2022-01-14 16:32:19,748 iteration 3732 : loss : 0.026154, loss_ce: 0.011149
2022-01-14 16:32:21,201 iteration 3733 : loss : 0.023679, loss_ce: 0.007032
2022-01-14 16:32:22,684 iteration 3734 : loss : 0.020288, loss_ce: 0.007541
2022-01-14 16:32:24,194 iteration 3735 : loss : 0.024363, loss_ce: 0.011360
2022-01-14 16:32:25,717 iteration 3736 : loss : 0.027040, loss_ce: 0.009435
2022-01-14 16:32:27,206 iteration 3737 : loss : 0.029237, loss_ce: 0.011129
2022-01-14 16:32:28,678 iteration 3738 : loss : 0.021707, loss_ce: 0.008708
2022-01-14 16:32:30,150 iteration 3739 : loss : 0.023472, loss_ce: 0.008584
2022-01-14 16:32:30,150 Training Data Eval:
2022-01-14 16:32:37,513   Average segmentation loss on training set: 0.0144
2022-01-14 16:32:37,514 Validation Data Eval:
2022-01-14 16:32:40,059   Average segmentation loss on validation set: 0.0818
2022-01-14 16:32:41,580 iteration 3740 : loss : 0.017153, loss_ce: 0.005584
 55%|██████████████▊            | 220/400 [1:40:34<1:26:17, 28.77s/it]2022-01-14 16:32:43,108 iteration 3741 : loss : 0.022972, loss_ce: 0.009962
2022-01-14 16:32:44,547 iteration 3742 : loss : 0.023008, loss_ce: 0.011101
2022-01-14 16:32:46,002 iteration 3743 : loss : 0.024311, loss_ce: 0.008002
2022-01-14 16:32:47,484 iteration 3744 : loss : 0.027045, loss_ce: 0.012975
2022-01-14 16:32:48,930 iteration 3745 : loss : 0.024140, loss_ce: 0.008583
2022-01-14 16:32:50,443 iteration 3746 : loss : 0.016417, loss_ce: 0.006194
2022-01-14 16:32:51,956 iteration 3747 : loss : 0.029551, loss_ce: 0.006038
2022-01-14 16:32:53,437 iteration 3748 : loss : 0.027700, loss_ce: 0.012306
2022-01-14 16:32:54,899 iteration 3749 : loss : 0.033878, loss_ce: 0.016846
2022-01-14 16:32:56,389 iteration 3750 : loss : 0.027281, loss_ce: 0.010993
2022-01-14 16:32:57,889 iteration 3751 : loss : 0.048469, loss_ce: 0.011676
2022-01-14 16:32:59,367 iteration 3752 : loss : 0.020956, loss_ce: 0.008158
2022-01-14 16:33:00,789 iteration 3753 : loss : 0.022084, loss_ce: 0.005942
2022-01-14 16:33:02,212 iteration 3754 : loss : 0.014134, loss_ce: 0.004762
2022-01-14 16:33:03,647 iteration 3755 : loss : 0.016303, loss_ce: 0.006574
2022-01-14 16:33:05,119 iteration 3756 : loss : 0.021599, loss_ce: 0.008369
2022-01-14 16:33:06,594 iteration 3757 : loss : 0.030927, loss_ce: 0.009439
 55%|██████████████▉            | 221/400 [1:40:59<1:22:27, 27.64s/it]2022-01-14 16:33:08,128 iteration 3758 : loss : 0.028197, loss_ce: 0.010555
2022-01-14 16:33:09,601 iteration 3759 : loss : 0.017770, loss_ce: 0.006448
2022-01-14 16:33:10,983 iteration 3760 : loss : 0.017348, loss_ce: 0.005892
2022-01-14 16:33:12,508 iteration 3761 : loss : 0.028536, loss_ce: 0.012129
2022-01-14 16:33:13,984 iteration 3762 : loss : 0.037283, loss_ce: 0.011613
2022-01-14 16:33:15,556 iteration 3763 : loss : 0.047734, loss_ce: 0.020548
2022-01-14 16:33:17,094 iteration 3764 : loss : 0.022993, loss_ce: 0.008611
2022-01-14 16:33:18,600 iteration 3765 : loss : 0.018640, loss_ce: 0.007208
2022-01-14 16:33:20,101 iteration 3766 : loss : 0.022654, loss_ce: 0.007824
2022-01-14 16:33:21,687 iteration 3767 : loss : 0.034966, loss_ce: 0.011043
2022-01-14 16:33:23,176 iteration 3768 : loss : 0.019628, loss_ce: 0.009458
2022-01-14 16:33:24,621 iteration 3769 : loss : 0.020409, loss_ce: 0.008550
2022-01-14 16:33:26,035 iteration 3770 : loss : 0.016457, loss_ce: 0.006029
2022-01-14 16:33:27,469 iteration 3771 : loss : 0.016842, loss_ce: 0.006215
2022-01-14 16:33:28,930 iteration 3772 : loss : 0.023237, loss_ce: 0.006860
2022-01-14 16:33:30,331 iteration 3773 : loss : 0.015123, loss_ce: 0.005456
2022-01-14 16:33:31,745 iteration 3774 : loss : 0.026454, loss_ce: 0.010877
 56%|██████████████▉            | 222/400 [1:41:25<1:19:46, 26.89s/it]2022-01-14 16:33:33,218 iteration 3775 : loss : 0.026987, loss_ce: 0.006191
2022-01-14 16:33:34,725 iteration 3776 : loss : 0.027698, loss_ce: 0.011710
2022-01-14 16:33:36,316 iteration 3777 : loss : 0.037074, loss_ce: 0.013880
2022-01-14 16:33:37,759 iteration 3778 : loss : 0.019153, loss_ce: 0.010629
2022-01-14 16:33:39,268 iteration 3779 : loss : 0.026180, loss_ce: 0.010875
2022-01-14 16:33:40,721 iteration 3780 : loss : 0.019920, loss_ce: 0.010340
2022-01-14 16:33:42,186 iteration 3781 : loss : 0.019096, loss_ce: 0.007238
2022-01-14 16:33:43,683 iteration 3782 : loss : 0.021209, loss_ce: 0.006743
2022-01-14 16:33:45,196 iteration 3783 : loss : 0.019333, loss_ce: 0.005679
2022-01-14 16:33:46,721 iteration 3784 : loss : 0.024037, loss_ce: 0.010431
2022-01-14 16:33:48,160 iteration 3785 : loss : 0.018000, loss_ce: 0.006666
2022-01-14 16:33:49,641 iteration 3786 : loss : 0.025751, loss_ce: 0.011083
2022-01-14 16:33:51,179 iteration 3787 : loss : 0.048922, loss_ce: 0.019159
2022-01-14 16:33:52,727 iteration 3788 : loss : 0.024822, loss_ce: 0.008565
2022-01-14 16:33:54,169 iteration 3789 : loss : 0.022220, loss_ce: 0.006579
2022-01-14 16:33:55,670 iteration 3790 : loss : 0.021732, loss_ce: 0.009692
2022-01-14 16:33:57,057 iteration 3791 : loss : 0.020018, loss_ce: 0.007857
 56%|███████████████            | 223/400 [1:41:50<1:17:55, 26.42s/it]2022-01-14 16:33:58,568 iteration 3792 : loss : 0.018138, loss_ce: 0.007603
2022-01-14 16:34:00,048 iteration 3793 : loss : 0.023747, loss_ce: 0.008898
2022-01-14 16:34:01,471 iteration 3794 : loss : 0.017629, loss_ce: 0.006415
2022-01-14 16:34:03,053 iteration 3795 : loss : 0.030542, loss_ce: 0.012847
2022-01-14 16:34:04,559 iteration 3796 : loss : 0.030005, loss_ce: 0.008175
2022-01-14 16:34:06,005 iteration 3797 : loss : 0.017241, loss_ce: 0.005590
2022-01-14 16:34:07,567 iteration 3798 : loss : 0.023511, loss_ce: 0.009625
2022-01-14 16:34:08,999 iteration 3799 : loss : 0.020071, loss_ce: 0.010480
2022-01-14 16:34:10,513 iteration 3800 : loss : 0.023234, loss_ce: 0.006637
2022-01-14 16:34:11,932 iteration 3801 : loss : 0.017536, loss_ce: 0.005855
2022-01-14 16:34:13,406 iteration 3802 : loss : 0.024011, loss_ce: 0.007257
2022-01-14 16:34:14,867 iteration 3803 : loss : 0.017145, loss_ce: 0.005932
2022-01-14 16:34:16,239 iteration 3804 : loss : 0.020710, loss_ce: 0.007879
2022-01-14 16:34:17,735 iteration 3805 : loss : 0.018305, loss_ce: 0.007487
2022-01-14 16:34:19,168 iteration 3806 : loss : 0.018759, loss_ce: 0.005345
2022-01-14 16:34:20,614 iteration 3807 : loss : 0.028166, loss_ce: 0.013569
2022-01-14 16:34:22,102 iteration 3808 : loss : 0.018939, loss_ce: 0.007043
 56%|███████████████            | 224/400 [1:42:15<1:16:17, 26.01s/it]2022-01-14 16:34:23,620 iteration 3809 : loss : 0.022502, loss_ce: 0.009941
2022-01-14 16:34:25,085 iteration 3810 : loss : 0.016675, loss_ce: 0.006430
2022-01-14 16:34:26,665 iteration 3811 : loss : 0.020773, loss_ce: 0.005967
2022-01-14 16:34:28,113 iteration 3812 : loss : 0.020419, loss_ce: 0.007657
2022-01-14 16:34:29,602 iteration 3813 : loss : 0.035299, loss_ce: 0.008182
2022-01-14 16:34:30,996 iteration 3814 : loss : 0.016556, loss_ce: 0.005685
2022-01-14 16:34:32,528 iteration 3815 : loss : 0.037223, loss_ce: 0.014732
2022-01-14 16:34:34,116 iteration 3816 : loss : 0.032076, loss_ce: 0.009809
2022-01-14 16:34:35,607 iteration 3817 : loss : 0.021327, loss_ce: 0.009560
2022-01-14 16:34:37,231 iteration 3818 : loss : 0.024255, loss_ce: 0.010761
2022-01-14 16:34:38,662 iteration 3819 : loss : 0.018624, loss_ce: 0.008374
2022-01-14 16:34:40,178 iteration 3820 : loss : 0.027625, loss_ce: 0.010723
2022-01-14 16:34:41,651 iteration 3821 : loss : 0.018403, loss_ce: 0.008744
2022-01-14 16:34:43,029 iteration 3822 : loss : 0.014427, loss_ce: 0.005793
2022-01-14 16:34:44,454 iteration 3823 : loss : 0.018273, loss_ce: 0.006188
2022-01-14 16:34:45,910 iteration 3824 : loss : 0.021131, loss_ce: 0.007871
2022-01-14 16:34:45,910 Training Data Eval:
2022-01-14 16:34:53,277   Average segmentation loss on training set: 0.0141
2022-01-14 16:34:53,278 Validation Data Eval:
2022-01-14 16:34:55,826   Average segmentation loss on validation set: 0.0631
2022-01-14 16:34:57,253 iteration 3825 : loss : 0.022404, loss_ce: 0.008540
 56%|███████████████▏           | 225/400 [1:42:50<1:23:51, 28.75s/it]2022-01-14 16:34:58,682 iteration 3826 : loss : 0.014365, loss_ce: 0.006715
2022-01-14 16:35:00,163 iteration 3827 : loss : 0.021033, loss_ce: 0.007770
2022-01-14 16:35:01,665 iteration 3828 : loss : 0.025923, loss_ce: 0.011250
2022-01-14 16:35:03,132 iteration 3829 : loss : 0.025937, loss_ce: 0.012082
2022-01-14 16:35:04,607 iteration 3830 : loss : 0.026185, loss_ce: 0.010467
2022-01-14 16:35:06,148 iteration 3831 : loss : 0.048487, loss_ce: 0.012251
2022-01-14 16:35:07,539 iteration 3832 : loss : 0.015424, loss_ce: 0.005402
2022-01-14 16:35:09,028 iteration 3833 : loss : 0.017716, loss_ce: 0.005520
2022-01-14 16:35:10,481 iteration 3834 : loss : 0.015301, loss_ce: 0.007269
2022-01-14 16:35:12,016 iteration 3835 : loss : 0.020041, loss_ce: 0.009114
2022-01-14 16:35:13,553 iteration 3836 : loss : 0.020939, loss_ce: 0.006679
2022-01-14 16:35:14,950 iteration 3837 : loss : 0.015144, loss_ce: 0.005809
2022-01-14 16:35:16,372 iteration 3838 : loss : 0.018412, loss_ce: 0.005576
2022-01-14 16:35:17,805 iteration 3839 : loss : 0.016318, loss_ce: 0.005465
2022-01-14 16:35:19,177 iteration 3840 : loss : 0.019119, loss_ce: 0.005132
2022-01-14 16:35:20,605 iteration 3841 : loss : 0.016814, loss_ce: 0.005612
2022-01-14 16:35:22,043 iteration 3842 : loss : 0.018181, loss_ce: 0.004235
 56%|███████████████▎           | 226/400 [1:43:15<1:19:55, 27.56s/it]2022-01-14 16:35:23,581 iteration 3843 : loss : 0.024539, loss_ce: 0.009607
2022-01-14 16:35:25,058 iteration 3844 : loss : 0.021034, loss_ce: 0.009859
2022-01-14 16:35:26,498 iteration 3845 : loss : 0.024337, loss_ce: 0.009016
2022-01-14 16:35:27,955 iteration 3846 : loss : 0.014653, loss_ce: 0.003699
2022-01-14 16:35:29,468 iteration 3847 : loss : 0.015181, loss_ce: 0.005754
2022-01-14 16:35:30,912 iteration 3848 : loss : 0.018407, loss_ce: 0.007158
2022-01-14 16:35:32,310 iteration 3849 : loss : 0.018314, loss_ce: 0.007126
2022-01-14 16:35:33,809 iteration 3850 : loss : 0.035772, loss_ce: 0.009635
2022-01-14 16:35:35,326 iteration 3851 : loss : 0.027509, loss_ce: 0.015405
2022-01-14 16:35:36,771 iteration 3852 : loss : 0.021077, loss_ce: 0.007387
2022-01-14 16:35:38,204 iteration 3853 : loss : 0.020125, loss_ce: 0.010918
2022-01-14 16:35:39,719 iteration 3854 : loss : 0.030696, loss_ce: 0.011594
2022-01-14 16:35:41,199 iteration 3855 : loss : 0.033234, loss_ce: 0.011810
2022-01-14 16:35:42,685 iteration 3856 : loss : 0.034317, loss_ce: 0.016127
2022-01-14 16:35:44,123 iteration 3857 : loss : 0.018591, loss_ce: 0.008205
2022-01-14 16:35:45,661 iteration 3858 : loss : 0.020794, loss_ce: 0.007971
2022-01-14 16:35:47,171 iteration 3859 : loss : 0.029018, loss_ce: 0.007216
 57%|███████████████▎           | 227/400 [1:43:40<1:17:22, 26.83s/it]2022-01-14 16:35:48,703 iteration 3860 : loss : 0.018046, loss_ce: 0.007899
2022-01-14 16:35:50,245 iteration 3861 : loss : 0.023646, loss_ce: 0.010383
2022-01-14 16:35:51,657 iteration 3862 : loss : 0.021721, loss_ce: 0.009916
2022-01-14 16:35:53,168 iteration 3863 : loss : 0.019955, loss_ce: 0.010205
2022-01-14 16:35:54,697 iteration 3864 : loss : 0.020831, loss_ce: 0.007358
2022-01-14 16:35:56,309 iteration 3865 : loss : 0.022085, loss_ce: 0.009214
2022-01-14 16:35:57,914 iteration 3866 : loss : 0.030395, loss_ce: 0.013361
2022-01-14 16:35:59,376 iteration 3867 : loss : 0.014244, loss_ce: 0.005305
2022-01-14 16:36:00,895 iteration 3868 : loss : 0.021544, loss_ce: 0.008661
2022-01-14 16:36:02,404 iteration 3869 : loss : 0.025377, loss_ce: 0.009300
2022-01-14 16:36:03,947 iteration 3870 : loss : 0.019260, loss_ce: 0.005973
2022-01-14 16:36:05,428 iteration 3871 : loss : 0.038630, loss_ce: 0.010462
2022-01-14 16:36:06,887 iteration 3872 : loss : 0.023473, loss_ce: 0.010478
2022-01-14 16:36:08,357 iteration 3873 : loss : 0.020450, loss_ce: 0.007693
2022-01-14 16:36:09,887 iteration 3874 : loss : 0.024077, loss_ce: 0.008437
2022-01-14 16:36:11,407 iteration 3875 : loss : 0.021878, loss_ce: 0.007553
2022-01-14 16:36:12,873 iteration 3876 : loss : 0.040069, loss_ce: 0.008747
 57%|███████████████▍           | 228/400 [1:44:06<1:15:56, 26.49s/it]2022-01-14 16:36:14,365 iteration 3877 : loss : 0.020228, loss_ce: 0.007703
2022-01-14 16:36:15,901 iteration 3878 : loss : 0.016917, loss_ce: 0.008159
2022-01-14 16:36:17,405 iteration 3879 : loss : 0.022448, loss_ce: 0.009208
2022-01-14 16:36:18,875 iteration 3880 : loss : 0.017671, loss_ce: 0.007461
2022-01-14 16:36:20,310 iteration 3881 : loss : 0.023555, loss_ce: 0.013057
2022-01-14 16:36:21,854 iteration 3882 : loss : 0.049611, loss_ce: 0.023063
2022-01-14 16:36:23,363 iteration 3883 : loss : 0.034504, loss_ce: 0.017688
2022-01-14 16:36:24,800 iteration 3884 : loss : 0.025326, loss_ce: 0.005369
2022-01-14 16:36:26,224 iteration 3885 : loss : 0.017834, loss_ce: 0.006066
2022-01-14 16:36:27,658 iteration 3886 : loss : 0.024786, loss_ce: 0.008830
2022-01-14 16:36:29,190 iteration 3887 : loss : 0.031300, loss_ce: 0.013431
2022-01-14 16:36:30,706 iteration 3888 : loss : 0.045773, loss_ce: 0.014663
2022-01-14 16:36:32,190 iteration 3889 : loss : 0.023836, loss_ce: 0.010606
2022-01-14 16:36:33,577 iteration 3890 : loss : 0.025556, loss_ce: 0.010390
2022-01-14 16:36:35,065 iteration 3891 : loss : 0.014937, loss_ce: 0.006576
2022-01-14 16:36:36,554 iteration 3892 : loss : 0.029694, loss_ce: 0.006635
2022-01-14 16:36:38,124 iteration 3893 : loss : 0.023770, loss_ce: 0.012776
 57%|███████████████▍           | 229/400 [1:44:31<1:14:26, 26.12s/it]2022-01-14 16:36:39,581 iteration 3894 : loss : 0.029585, loss_ce: 0.012241
2022-01-14 16:36:41,106 iteration 3895 : loss : 0.036421, loss_ce: 0.011999
2022-01-14 16:36:42,564 iteration 3896 : loss : 0.020717, loss_ce: 0.005881
2022-01-14 16:36:44,057 iteration 3897 : loss : 0.026380, loss_ce: 0.012357
2022-01-14 16:36:45,505 iteration 3898 : loss : 0.017756, loss_ce: 0.006762
2022-01-14 16:36:47,016 iteration 3899 : loss : 0.022663, loss_ce: 0.009742
2022-01-14 16:36:48,565 iteration 3900 : loss : 0.043338, loss_ce: 0.012860
2022-01-14 16:36:49,989 iteration 3901 : loss : 0.019812, loss_ce: 0.006101
2022-01-14 16:36:51,432 iteration 3902 : loss : 0.016163, loss_ce: 0.006090
2022-01-14 16:36:52,904 iteration 3903 : loss : 0.020790, loss_ce: 0.007701
2022-01-14 16:36:54,452 iteration 3904 : loss : 0.020047, loss_ce: 0.007206
2022-01-14 16:36:55,928 iteration 3905 : loss : 0.022284, loss_ce: 0.009994
2022-01-14 16:36:57,368 iteration 3906 : loss : 0.019423, loss_ce: 0.009123
2022-01-14 16:36:58,862 iteration 3907 : loss : 0.026340, loss_ce: 0.008496
2022-01-14 16:37:00,417 iteration 3908 : loss : 0.032259, loss_ce: 0.013119
2022-01-14 16:37:01,934 iteration 3909 : loss : 0.022428, loss_ce: 0.008746
2022-01-14 16:37:01,934 Training Data Eval:
2022-01-14 16:37:09,298   Average segmentation loss on training set: 0.0154
2022-01-14 16:37:09,299 Validation Data Eval:
2022-01-14 16:37:11,842   Average segmentation loss on validation set: 0.0633
2022-01-14 16:37:13,262 iteration 3910 : loss : 0.016543, loss_ce: 0.005047
 57%|███████████████▌           | 230/400 [1:45:06<1:21:40, 28.83s/it]2022-01-14 16:37:14,723 iteration 3911 : loss : 0.019367, loss_ce: 0.005734
2022-01-14 16:37:16,282 iteration 3912 : loss : 0.030071, loss_ce: 0.014665
2022-01-14 16:37:17,682 iteration 3913 : loss : 0.016124, loss_ce: 0.005472
2022-01-14 16:37:19,073 iteration 3914 : loss : 0.017985, loss_ce: 0.006337
2022-01-14 16:37:20,458 iteration 3915 : loss : 0.017285, loss_ce: 0.006108
2022-01-14 16:37:22,000 iteration 3916 : loss : 0.035826, loss_ce: 0.014475
2022-01-14 16:37:23,536 iteration 3917 : loss : 0.060647, loss_ce: 0.014436
2022-01-14 16:37:25,066 iteration 3918 : loss : 0.026111, loss_ce: 0.012109
2022-01-14 16:37:26,545 iteration 3919 : loss : 0.022395, loss_ce: 0.009005
2022-01-14 16:37:28,042 iteration 3920 : loss : 0.022695, loss_ce: 0.010386
2022-01-14 16:37:29,536 iteration 3921 : loss : 0.042450, loss_ce: 0.011479
2022-01-14 16:37:30,972 iteration 3922 : loss : 0.012490, loss_ce: 0.004988
2022-01-14 16:37:32,440 iteration 3923 : loss : 0.018865, loss_ce: 0.007735
2022-01-14 16:37:33,911 iteration 3924 : loss : 0.023788, loss_ce: 0.009869
2022-01-14 16:37:35,530 iteration 3925 : loss : 0.023896, loss_ce: 0.011151
2022-01-14 16:37:37,013 iteration 3926 : loss : 0.016789, loss_ce: 0.006048
2022-01-14 16:37:38,509 iteration 3927 : loss : 0.024911, loss_ce: 0.009403
 58%|███████████████▌           | 231/400 [1:45:31<1:18:10, 27.75s/it]2022-01-14 16:37:40,043 iteration 3928 : loss : 0.019377, loss_ce: 0.008189
2022-01-14 16:37:41,604 iteration 3929 : loss : 0.023779, loss_ce: 0.009697
2022-01-14 16:37:43,269 iteration 3930 : loss : 0.022595, loss_ce: 0.008147
2022-01-14 16:37:44,772 iteration 3931 : loss : 0.018843, loss_ce: 0.008970
2022-01-14 16:37:46,309 iteration 3932 : loss : 0.026409, loss_ce: 0.006790
2022-01-14 16:37:47,765 iteration 3933 : loss : 0.024606, loss_ce: 0.006203
2022-01-14 16:37:49,244 iteration 3934 : loss : 0.020494, loss_ce: 0.007588
2022-01-14 16:37:50,775 iteration 3935 : loss : 0.027158, loss_ce: 0.009545
2022-01-14 16:37:52,236 iteration 3936 : loss : 0.018067, loss_ce: 0.007319
2022-01-14 16:37:53,713 iteration 3937 : loss : 0.018788, loss_ce: 0.005984
2022-01-14 16:37:55,158 iteration 3938 : loss : 0.018365, loss_ce: 0.008788
2022-01-14 16:37:56,771 iteration 3939 : loss : 0.027394, loss_ce: 0.010298
2022-01-14 16:37:58,247 iteration 3940 : loss : 0.022276, loss_ce: 0.005222
2022-01-14 16:37:59,744 iteration 3941 : loss : 0.022944, loss_ce: 0.010306
2022-01-14 16:38:01,236 iteration 3942 : loss : 0.022227, loss_ce: 0.010281
2022-01-14 16:38:02,784 iteration 3943 : loss : 0.020205, loss_ce: 0.010232
2022-01-14 16:38:04,272 iteration 3944 : loss : 0.020127, loss_ce: 0.006396
 58%|███████████████▋           | 232/400 [1:45:57<1:16:01, 27.15s/it]2022-01-14 16:38:05,773 iteration 3945 : loss : 0.014805, loss_ce: 0.006976
2022-01-14 16:38:07,161 iteration 3946 : loss : 0.018160, loss_ce: 0.006651
2022-01-14 16:38:08,626 iteration 3947 : loss : 0.018361, loss_ce: 0.006569
2022-01-14 16:38:10,079 iteration 3948 : loss : 0.019541, loss_ce: 0.008085
2022-01-14 16:38:11,567 iteration 3949 : loss : 0.024926, loss_ce: 0.011255
2022-01-14 16:38:13,037 iteration 3950 : loss : 0.018427, loss_ce: 0.007504
2022-01-14 16:38:14,547 iteration 3951 : loss : 0.030445, loss_ce: 0.010853
2022-01-14 16:38:16,016 iteration 3952 : loss : 0.020629, loss_ce: 0.011418
2022-01-14 16:38:17,487 iteration 3953 : loss : 0.016370, loss_ce: 0.005013
2022-01-14 16:38:19,002 iteration 3954 : loss : 0.022484, loss_ce: 0.008953
2022-01-14 16:38:20,500 iteration 3955 : loss : 0.022159, loss_ce: 0.007671
2022-01-14 16:38:21,959 iteration 3956 : loss : 0.020133, loss_ce: 0.008076
2022-01-14 16:38:23,417 iteration 3957 : loss : 0.017647, loss_ce: 0.008241
2022-01-14 16:38:24,977 iteration 3958 : loss : 0.019388, loss_ce: 0.007933
2022-01-14 16:38:26,423 iteration 3959 : loss : 0.017031, loss_ce: 0.004966
2022-01-14 16:38:27,905 iteration 3960 : loss : 0.021241, loss_ce: 0.004762
2022-01-14 16:38:29,420 iteration 3961 : loss : 0.021033, loss_ce: 0.008004
 58%|███████████████▋           | 233/400 [1:46:22<1:13:54, 26.55s/it]2022-01-14 16:38:31,077 iteration 3962 : loss : 0.029371, loss_ce: 0.011399
2022-01-14 16:38:32,493 iteration 3963 : loss : 0.021809, loss_ce: 0.011135
2022-01-14 16:38:34,008 iteration 3964 : loss : 0.024405, loss_ce: 0.011269
2022-01-14 16:38:35,573 iteration 3965 : loss : 0.027973, loss_ce: 0.007610
2022-01-14 16:38:37,025 iteration 3966 : loss : 0.019673, loss_ce: 0.007911
2022-01-14 16:38:38,471 iteration 3967 : loss : 0.021339, loss_ce: 0.006009
2022-01-14 16:38:40,031 iteration 3968 : loss : 0.020813, loss_ce: 0.008187
2022-01-14 16:38:41,573 iteration 3969 : loss : 0.019533, loss_ce: 0.007598
2022-01-14 16:38:43,141 iteration 3970 : loss : 0.021936, loss_ce: 0.011644
2022-01-14 16:38:44,586 iteration 3971 : loss : 0.016173, loss_ce: 0.004901
2022-01-14 16:38:46,031 iteration 3972 : loss : 0.021497, loss_ce: 0.007157
2022-01-14 16:38:47,526 iteration 3973 : loss : 0.031736, loss_ce: 0.012133
2022-01-14 16:38:49,086 iteration 3974 : loss : 0.021464, loss_ce: 0.010931
2022-01-14 16:38:50,639 iteration 3975 : loss : 0.017155, loss_ce: 0.006091
2022-01-14 16:38:52,212 iteration 3976 : loss : 0.022846, loss_ce: 0.009651
2022-01-14 16:38:53,691 iteration 3977 : loss : 0.021808, loss_ce: 0.008224
2022-01-14 16:38:55,161 iteration 3978 : loss : 0.020473, loss_ce: 0.008493
 58%|███████████████▊           | 234/400 [1:46:48<1:12:47, 26.31s/it]2022-01-14 16:38:56,695 iteration 3979 : loss : 0.021981, loss_ce: 0.007159
2022-01-14 16:38:58,207 iteration 3980 : loss : 0.018056, loss_ce: 0.008662
2022-01-14 16:38:59,653 iteration 3981 : loss : 0.018357, loss_ce: 0.006765
2022-01-14 16:39:01,268 iteration 3982 : loss : 0.022207, loss_ce: 0.008256
2022-01-14 16:39:02,750 iteration 3983 : loss : 0.015975, loss_ce: 0.004603
2022-01-14 16:39:04,276 iteration 3984 : loss : 0.023446, loss_ce: 0.009924
2022-01-14 16:39:05,764 iteration 3985 : loss : 0.018967, loss_ce: 0.006747
2022-01-14 16:39:07,208 iteration 3986 : loss : 0.017807, loss_ce: 0.007121
2022-01-14 16:39:08,675 iteration 3987 : loss : 0.015083, loss_ce: 0.006674
2022-01-14 16:39:10,206 iteration 3988 : loss : 0.020685, loss_ce: 0.008696
2022-01-14 16:39:11,695 iteration 3989 : loss : 0.028017, loss_ce: 0.011302
2022-01-14 16:39:13,161 iteration 3990 : loss : 0.014205, loss_ce: 0.004807
2022-01-14 16:39:14,634 iteration 3991 : loss : 0.019366, loss_ce: 0.006508
2022-01-14 16:39:16,237 iteration 3992 : loss : 0.028838, loss_ce: 0.009030
2022-01-14 16:39:17,716 iteration 3993 : loss : 0.019314, loss_ce: 0.010246
2022-01-14 16:39:19,186 iteration 3994 : loss : 0.017817, loss_ce: 0.008111
2022-01-14 16:39:19,186 Training Data Eval:
2022-01-14 16:39:26,554   Average segmentation loss on training set: 0.0126
2022-01-14 16:39:26,555 Validation Data Eval:
2022-01-14 16:39:29,095   Average segmentation loss on validation set: 0.0874
2022-01-14 16:39:30,555 iteration 3995 : loss : 0.018390, loss_ce: 0.004805
 59%|███████████████▊           | 235/400 [1:47:23<1:19:50, 29.03s/it]2022-01-14 16:39:32,146 iteration 3996 : loss : 0.021197, loss_ce: 0.010894
2022-01-14 16:39:33,664 iteration 3997 : loss : 0.018572, loss_ce: 0.006692
2022-01-14 16:39:35,141 iteration 3998 : loss : 0.020518, loss_ce: 0.007807
2022-01-14 16:39:36,677 iteration 3999 : loss : 0.021594, loss_ce: 0.006197
2022-01-14 16:39:38,176 iteration 4000 : loss : 0.024624, loss_ce: 0.012310
2022-01-14 16:39:39,774 iteration 4001 : loss : 0.029411, loss_ce: 0.008613
2022-01-14 16:39:41,257 iteration 4002 : loss : 0.017523, loss_ce: 0.008345
2022-01-14 16:39:42,741 iteration 4003 : loss : 0.015458, loss_ce: 0.005545
2022-01-14 16:39:44,216 iteration 4004 : loss : 0.016832, loss_ce: 0.005946
2022-01-14 16:39:45,707 iteration 4005 : loss : 0.022353, loss_ce: 0.008363
2022-01-14 16:39:47,292 iteration 4006 : loss : 0.023785, loss_ce: 0.006403
2022-01-14 16:39:48,755 iteration 4007 : loss : 0.016271, loss_ce: 0.005955
2022-01-14 16:39:50,249 iteration 4008 : loss : 0.021486, loss_ce: 0.006784
2022-01-14 16:39:51,721 iteration 4009 : loss : 0.019174, loss_ce: 0.006782
2022-01-14 16:39:53,149 iteration 4010 : loss : 0.013285, loss_ce: 0.004802
2022-01-14 16:39:54,672 iteration 4011 : loss : 0.033473, loss_ce: 0.008488
2022-01-14 16:39:56,204 iteration 4012 : loss : 0.022860, loss_ce: 0.009796
 59%|███████████████▉           | 236/400 [1:47:49<1:16:34, 28.02s/it]2022-01-14 16:39:57,714 iteration 4013 : loss : 0.019946, loss_ce: 0.005492
2022-01-14 16:39:59,247 iteration 4014 : loss : 0.022892, loss_ce: 0.007608
2022-01-14 16:40:00,705 iteration 4015 : loss : 0.018320, loss_ce: 0.009359
2022-01-14 16:40:02,226 iteration 4016 : loss : 0.020987, loss_ce: 0.006908
2022-01-14 16:40:03,672 iteration 4017 : loss : 0.020076, loss_ce: 0.007108
2022-01-14 16:40:05,230 iteration 4018 : loss : 0.022681, loss_ce: 0.008282
2022-01-14 16:40:06,782 iteration 4019 : loss : 0.021855, loss_ce: 0.009899
2022-01-14 16:40:08,250 iteration 4020 : loss : 0.014767, loss_ce: 0.005670
2022-01-14 16:40:09,742 iteration 4021 : loss : 0.018023, loss_ce: 0.006633
2022-01-14 16:40:11,224 iteration 4022 : loss : 0.021891, loss_ce: 0.007460
2022-01-14 16:40:12,723 iteration 4023 : loss : 0.018326, loss_ce: 0.008408
2022-01-14 16:40:14,224 iteration 4024 : loss : 0.031541, loss_ce: 0.009410
2022-01-14 16:40:15,685 iteration 4025 : loss : 0.019713, loss_ce: 0.007410
2022-01-14 16:40:17,145 iteration 4026 : loss : 0.014357, loss_ce: 0.005703
2022-01-14 16:40:18,601 iteration 4027 : loss : 0.015983, loss_ce: 0.006283
2022-01-14 16:40:20,073 iteration 4028 : loss : 0.018017, loss_ce: 0.004786
2022-01-14 16:40:21,571 iteration 4029 : loss : 0.023186, loss_ce: 0.008913
 59%|███████████████▉           | 237/400 [1:48:14<1:13:57, 27.22s/it]2022-01-14 16:40:23,108 iteration 4030 : loss : 0.023687, loss_ce: 0.009251
2022-01-14 16:40:24,577 iteration 4031 : loss : 0.020224, loss_ce: 0.008083
2022-01-14 16:40:26,102 iteration 4032 : loss : 0.016625, loss_ce: 0.005431
2022-01-14 16:40:27,713 iteration 4033 : loss : 0.034225, loss_ce: 0.013549
2022-01-14 16:40:29,170 iteration 4034 : loss : 0.026170, loss_ce: 0.007630
2022-01-14 16:40:30,665 iteration 4035 : loss : 0.017848, loss_ce: 0.006004
2022-01-14 16:40:32,140 iteration 4036 : loss : 0.013131, loss_ce: 0.004483
2022-01-14 16:40:33,668 iteration 4037 : loss : 0.023783, loss_ce: 0.009359
2022-01-14 16:40:35,157 iteration 4038 : loss : 0.020430, loss_ce: 0.011719
2022-01-14 16:40:36,536 iteration 4039 : loss : 0.015558, loss_ce: 0.007232
2022-01-14 16:40:38,010 iteration 4040 : loss : 0.022857, loss_ce: 0.005057
2022-01-14 16:40:39,606 iteration 4041 : loss : 0.026984, loss_ce: 0.013140
2022-01-14 16:40:41,021 iteration 4042 : loss : 0.017168, loss_ce: 0.007328
2022-01-14 16:40:42,524 iteration 4043 : loss : 0.017856, loss_ce: 0.006901
2022-01-14 16:40:44,023 iteration 4044 : loss : 0.024976, loss_ce: 0.008908
2022-01-14 16:40:45,480 iteration 4045 : loss : 0.019886, loss_ce: 0.008497
2022-01-14 16:40:47,003 iteration 4046 : loss : 0.016279, loss_ce: 0.005400
 60%|████████████████           | 238/400 [1:48:40<1:12:03, 26.69s/it]2022-01-14 16:40:48,475 iteration 4047 : loss : 0.015303, loss_ce: 0.006492
2022-01-14 16:40:49,948 iteration 4048 : loss : 0.013164, loss_ce: 0.003796
2022-01-14 16:40:51,503 iteration 4049 : loss : 0.028039, loss_ce: 0.009453
2022-01-14 16:40:52,987 iteration 4050 : loss : 0.024344, loss_ce: 0.006509
2022-01-14 16:40:54,480 iteration 4051 : loss : 0.013532, loss_ce: 0.004526
2022-01-14 16:40:55,959 iteration 4052 : loss : 0.017906, loss_ce: 0.005277
2022-01-14 16:40:57,422 iteration 4053 : loss : 0.019491, loss_ce: 0.009424
2022-01-14 16:40:58,867 iteration 4054 : loss : 0.018058, loss_ce: 0.007308
2022-01-14 16:41:00,450 iteration 4055 : loss : 0.021008, loss_ce: 0.006361
2022-01-14 16:41:01,974 iteration 4056 : loss : 0.023815, loss_ce: 0.006964
2022-01-14 16:41:03,522 iteration 4057 : loss : 0.027852, loss_ce: 0.011128
2022-01-14 16:41:04,925 iteration 4058 : loss : 0.017751, loss_ce: 0.007296
2022-01-14 16:41:06,467 iteration 4059 : loss : 0.024538, loss_ce: 0.010941
2022-01-14 16:41:07,982 iteration 4060 : loss : 0.025346, loss_ce: 0.008349
2022-01-14 16:41:09,455 iteration 4061 : loss : 0.028895, loss_ce: 0.006386
2022-01-14 16:41:10,940 iteration 4062 : loss : 0.029258, loss_ce: 0.012210
2022-01-14 16:41:12,551 iteration 4063 : loss : 0.042349, loss_ce: 0.015053
 60%|████████████████▏          | 239/400 [1:49:05<1:10:41, 26.35s/it]2022-01-14 16:41:14,073 iteration 4064 : loss : 0.021155, loss_ce: 0.006525
2022-01-14 16:41:15,554 iteration 4065 : loss : 0.017888, loss_ce: 0.006830
2022-01-14 16:41:16,954 iteration 4066 : loss : 0.016991, loss_ce: 0.005396
2022-01-14 16:41:18,387 iteration 4067 : loss : 0.018077, loss_ce: 0.004183
2022-01-14 16:41:19,883 iteration 4068 : loss : 0.021088, loss_ce: 0.008184
2022-01-14 16:41:21,407 iteration 4069 : loss : 0.030120, loss_ce: 0.009144
2022-01-14 16:41:22,912 iteration 4070 : loss : 0.030306, loss_ce: 0.017124
2022-01-14 16:41:24,333 iteration 4071 : loss : 0.024463, loss_ce: 0.009413
2022-01-14 16:41:25,808 iteration 4072 : loss : 0.019793, loss_ce: 0.008067
2022-01-14 16:41:27,304 iteration 4073 : loss : 0.028925, loss_ce: 0.013803
2022-01-14 16:41:28,738 iteration 4074 : loss : 0.023796, loss_ce: 0.008091
2022-01-14 16:41:30,266 iteration 4075 : loss : 0.022267, loss_ce: 0.008893
2022-01-14 16:41:31,765 iteration 4076 : loss : 0.017408, loss_ce: 0.006027
2022-01-14 16:41:33,276 iteration 4077 : loss : 0.020295, loss_ce: 0.009224
2022-01-14 16:41:34,834 iteration 4078 : loss : 0.030613, loss_ce: 0.008441
2022-01-14 16:41:36,329 iteration 4079 : loss : 0.021461, loss_ce: 0.007328
2022-01-14 16:41:36,329 Training Data Eval:
2022-01-14 16:41:43,686   Average segmentation loss on training set: 0.0146
2022-01-14 16:41:43,687 Validation Data Eval:
2022-01-14 16:41:46,235   Average segmentation loss on validation set: 0.0624
2022-01-14 16:41:47,724 iteration 4080 : loss : 0.026643, loss_ce: 0.006923
 60%|████████████████▏          | 240/400 [1:49:41<1:17:18, 28.99s/it]2022-01-14 16:41:49,236 iteration 4081 : loss : 0.020560, loss_ce: 0.009675
2022-01-14 16:41:50,795 iteration 4082 : loss : 0.027952, loss_ce: 0.009297
2022-01-14 16:41:52,205 iteration 4083 : loss : 0.022827, loss_ce: 0.010343
2022-01-14 16:41:53,652 iteration 4084 : loss : 0.016678, loss_ce: 0.005904
2022-01-14 16:41:55,135 iteration 4085 : loss : 0.032269, loss_ce: 0.010733
2022-01-14 16:41:56,591 iteration 4086 : loss : 0.016433, loss_ce: 0.005992
2022-01-14 16:41:58,073 iteration 4087 : loss : 0.024089, loss_ce: 0.007025
2022-01-14 16:41:59,574 iteration 4088 : loss : 0.022209, loss_ce: 0.009782
2022-01-14 16:42:01,081 iteration 4089 : loss : 0.020767, loss_ce: 0.007530
2022-01-14 16:42:02,566 iteration 4090 : loss : 0.025569, loss_ce: 0.011823
2022-01-14 16:42:04,097 iteration 4091 : loss : 0.041329, loss_ce: 0.014941
2022-01-14 16:42:05,531 iteration 4092 : loss : 0.030091, loss_ce: 0.008549
2022-01-14 16:42:06,982 iteration 4093 : loss : 0.017206, loss_ce: 0.007405
2022-01-14 16:42:08,535 iteration 4094 : loss : 0.018900, loss_ce: 0.006885
2022-01-14 16:42:10,025 iteration 4095 : loss : 0.022438, loss_ce: 0.006354
2022-01-14 16:42:11,582 iteration 4096 : loss : 0.031447, loss_ce: 0.011853
2022-01-14 16:42:13,117 iteration 4097 : loss : 0.021295, loss_ce: 0.008285
 60%|████████████████▎          | 241/400 [1:50:06<1:13:58, 27.91s/it]2022-01-14 16:42:14,658 iteration 4098 : loss : 0.016181, loss_ce: 0.005943
2022-01-14 16:42:16,146 iteration 4099 : loss : 0.023249, loss_ce: 0.007067
2022-01-14 16:42:17,588 iteration 4100 : loss : 0.020491, loss_ce: 0.008466
2022-01-14 16:42:19,089 iteration 4101 : loss : 0.015995, loss_ce: 0.006971
2022-01-14 16:42:20,652 iteration 4102 : loss : 0.021102, loss_ce: 0.007282
2022-01-14 16:42:22,062 iteration 4103 : loss : 0.016329, loss_ce: 0.006472
2022-01-14 16:42:23,568 iteration 4104 : loss : 0.027088, loss_ce: 0.009254
2022-01-14 16:42:25,110 iteration 4105 : loss : 0.027072, loss_ce: 0.009440
2022-01-14 16:42:26,683 iteration 4106 : loss : 0.036760, loss_ce: 0.011603
2022-01-14 16:42:28,203 iteration 4107 : loss : 0.020243, loss_ce: 0.007507
2022-01-14 16:42:29,732 iteration 4108 : loss : 0.017580, loss_ce: 0.007398
2022-01-14 16:42:31,245 iteration 4109 : loss : 0.027191, loss_ce: 0.007731
2022-01-14 16:42:32,786 iteration 4110 : loss : 0.057554, loss_ce: 0.026258
2022-01-14 16:42:34,282 iteration 4111 : loss : 0.035585, loss_ce: 0.013731
2022-01-14 16:42:35,663 iteration 4112 : loss : 0.012986, loss_ce: 0.005216
2022-01-14 16:42:37,206 iteration 4113 : loss : 0.031205, loss_ce: 0.010355
2022-01-14 16:42:38,737 iteration 4114 : loss : 0.021151, loss_ce: 0.008699
 60%|████████████████▎          | 242/400 [1:50:32<1:11:41, 27.23s/it]2022-01-14 16:42:40,287 iteration 4115 : loss : 0.024194, loss_ce: 0.006380
2022-01-14 16:42:41,787 iteration 4116 : loss : 0.019839, loss_ce: 0.008668
2022-01-14 16:42:43,237 iteration 4117 : loss : 0.016097, loss_ce: 0.008205
2022-01-14 16:42:44,726 iteration 4118 : loss : 0.029096, loss_ce: 0.008244
2022-01-14 16:42:46,106 iteration 4119 : loss : 0.016730, loss_ce: 0.006307
2022-01-14 16:42:47,695 iteration 4120 : loss : 0.025077, loss_ce: 0.009877
2022-01-14 16:42:49,170 iteration 4121 : loss : 0.023443, loss_ce: 0.008812
2022-01-14 16:42:50,678 iteration 4122 : loss : 0.026014, loss_ce: 0.007241
2022-01-14 16:42:52,186 iteration 4123 : loss : 0.022899, loss_ce: 0.008490
2022-01-14 16:42:53,592 iteration 4124 : loss : 0.020675, loss_ce: 0.009155
2022-01-14 16:42:55,098 iteration 4125 : loss : 0.025465, loss_ce: 0.008693
2022-01-14 16:42:56,702 iteration 4126 : loss : 0.019764, loss_ce: 0.008180
2022-01-14 16:42:58,248 iteration 4127 : loss : 0.023158, loss_ce: 0.011291
2022-01-14 16:42:59,703 iteration 4128 : loss : 0.018132, loss_ce: 0.007538
2022-01-14 16:43:01,299 iteration 4129 : loss : 0.035038, loss_ce: 0.008081
2022-01-14 16:43:02,834 iteration 4130 : loss : 0.020901, loss_ce: 0.006945
2022-01-14 16:43:04,315 iteration 4131 : loss : 0.017535, loss_ce: 0.007161
 61%|████████████████▍          | 243/400 [1:50:57<1:09:56, 26.73s/it]2022-01-14 16:43:05,889 iteration 4132 : loss : 0.023461, loss_ce: 0.008717
2022-01-14 16:43:07,317 iteration 4133 : loss : 0.021087, loss_ce: 0.009637
2022-01-14 16:43:08,854 iteration 4134 : loss : 0.015395, loss_ce: 0.006176
2022-01-14 16:43:10,344 iteration 4135 : loss : 0.022839, loss_ce: 0.008799
2022-01-14 16:43:11,819 iteration 4136 : loss : 0.017181, loss_ce: 0.005269
2022-01-14 16:43:13,322 iteration 4137 : loss : 0.018773, loss_ce: 0.009137
2022-01-14 16:43:14,831 iteration 4138 : loss : 0.015145, loss_ce: 0.007212
2022-01-14 16:43:16,341 iteration 4139 : loss : 0.030432, loss_ce: 0.008307
2022-01-14 16:43:17,877 iteration 4140 : loss : 0.020032, loss_ce: 0.006414
2022-01-14 16:43:19,359 iteration 4141 : loss : 0.022517, loss_ce: 0.005848
2022-01-14 16:43:20,815 iteration 4142 : loss : 0.031956, loss_ce: 0.014616
2022-01-14 16:43:22,262 iteration 4143 : loss : 0.018428, loss_ce: 0.006364
2022-01-14 16:43:23,767 iteration 4144 : loss : 0.032764, loss_ce: 0.009781
2022-01-14 16:43:25,234 iteration 4145 : loss : 0.026272, loss_ce: 0.010084
2022-01-14 16:43:26,611 iteration 4146 : loss : 0.020345, loss_ce: 0.005176
2022-01-14 16:43:28,070 iteration 4147 : loss : 0.022176, loss_ce: 0.008347
2022-01-14 16:43:29,546 iteration 4148 : loss : 0.024875, loss_ce: 0.008913
 61%|████████████████▍          | 244/400 [1:51:22<1:08:19, 26.28s/it]2022-01-14 16:43:31,078 iteration 4149 : loss : 0.020118, loss_ce: 0.008329
2022-01-14 16:43:32,538 iteration 4150 : loss : 0.020075, loss_ce: 0.007576
2022-01-14 16:43:34,009 iteration 4151 : loss : 0.015794, loss_ce: 0.006533
2022-01-14 16:43:35,568 iteration 4152 : loss : 0.021733, loss_ce: 0.009300
2022-01-14 16:43:37,091 iteration 4153 : loss : 0.025597, loss_ce: 0.011131
2022-01-14 16:43:38,515 iteration 4154 : loss : 0.018007, loss_ce: 0.007110
2022-01-14 16:43:39,955 iteration 4155 : loss : 0.019778, loss_ce: 0.009215
2022-01-14 16:43:41,436 iteration 4156 : loss : 0.027747, loss_ce: 0.009111
2022-01-14 16:43:42,925 iteration 4157 : loss : 0.020788, loss_ce: 0.008982
2022-01-14 16:43:44,386 iteration 4158 : loss : 0.017954, loss_ce: 0.006447
2022-01-14 16:43:45,912 iteration 4159 : loss : 0.024627, loss_ce: 0.009700
2022-01-14 16:43:47,410 iteration 4160 : loss : 0.025161, loss_ce: 0.008989
2022-01-14 16:43:48,863 iteration 4161 : loss : 0.018915, loss_ce: 0.005741
2022-01-14 16:43:50,369 iteration 4162 : loss : 0.031606, loss_ce: 0.013319
2022-01-14 16:43:51,865 iteration 4163 : loss : 0.034243, loss_ce: 0.011593
2022-01-14 16:43:53,330 iteration 4164 : loss : 0.020197, loss_ce: 0.005497
2022-01-14 16:43:53,330 Training Data Eval:
2022-01-14 16:44:00,697   Average segmentation loss on training set: 0.0154
2022-01-14 16:44:00,698 Validation Data Eval:
2022-01-14 16:44:03,242   Average segmentation loss on validation set: 0.1162
2022-01-14 16:44:04,743 iteration 4165 : loss : 0.021163, loss_ce: 0.006986
 61%|████████████████▌          | 245/400 [1:51:58<1:14:48, 28.96s/it]2022-01-14 16:44:06,248 iteration 4166 : loss : 0.028449, loss_ce: 0.007245
2022-01-14 16:44:07,695 iteration 4167 : loss : 0.018804, loss_ce: 0.007322
2022-01-14 16:44:09,092 iteration 4168 : loss : 0.015967, loss_ce: 0.004813
2022-01-14 16:44:10,523 iteration 4169 : loss : 0.019579, loss_ce: 0.008868
2022-01-14 16:44:12,081 iteration 4170 : loss : 0.023506, loss_ce: 0.007936
2022-01-14 16:44:13,663 iteration 4171 : loss : 0.025082, loss_ce: 0.009714
2022-01-14 16:44:15,087 iteration 4172 : loss : 0.021656, loss_ce: 0.004686
2022-01-14 16:44:16,571 iteration 4173 : loss : 0.019086, loss_ce: 0.006556
2022-01-14 16:44:18,059 iteration 4174 : loss : 0.020650, loss_ce: 0.009540
2022-01-14 16:44:19,579 iteration 4175 : loss : 0.018878, loss_ce: 0.006315
2022-01-14 16:44:21,076 iteration 4176 : loss : 0.031836, loss_ce: 0.013708
2022-01-14 16:44:22,580 iteration 4177 : loss : 0.022743, loss_ce: 0.008027
2022-01-14 16:44:24,060 iteration 4178 : loss : 0.018081, loss_ce: 0.008050
2022-01-14 16:44:25,621 iteration 4179 : loss : 0.019767, loss_ce: 0.007250
2022-01-14 16:44:27,107 iteration 4180 : loss : 0.037479, loss_ce: 0.011774
2022-01-14 16:44:28,488 iteration 4181 : loss : 0.025475, loss_ce: 0.007372
2022-01-14 16:44:30,003 iteration 4182 : loss : 0.020633, loss_ce: 0.008382
 62%|████████████████▌          | 246/400 [1:52:23<1:11:28, 27.85s/it]2022-01-14 16:44:31,537 iteration 4183 : loss : 0.031340, loss_ce: 0.010120
2022-01-14 16:44:33,037 iteration 4184 : loss : 0.022430, loss_ce: 0.009322
2022-01-14 16:44:34,518 iteration 4185 : loss : 0.023553, loss_ce: 0.007543
2022-01-14 16:44:35,969 iteration 4186 : loss : 0.016261, loss_ce: 0.006205
2022-01-14 16:44:37,512 iteration 4187 : loss : 0.028831, loss_ce: 0.011152
2022-01-14 16:44:39,045 iteration 4188 : loss : 0.027245, loss_ce: 0.012770
2022-01-14 16:44:40,549 iteration 4189 : loss : 0.019189, loss_ce: 0.004797
2022-01-14 16:44:42,095 iteration 4190 : loss : 0.022073, loss_ce: 0.008961
2022-01-14 16:44:43,553 iteration 4191 : loss : 0.021997, loss_ce: 0.007825
2022-01-14 16:44:45,040 iteration 4192 : loss : 0.017886, loss_ce: 0.004805
2022-01-14 16:44:46,529 iteration 4193 : loss : 0.021288, loss_ce: 0.007403
2022-01-14 16:44:48,038 iteration 4194 : loss : 0.023099, loss_ce: 0.009603
2022-01-14 16:44:49,663 iteration 4195 : loss : 0.032907, loss_ce: 0.010713
2022-01-14 16:44:51,109 iteration 4196 : loss : 0.017087, loss_ce: 0.009233
2022-01-14 16:44:52,651 iteration 4197 : loss : 0.025023, loss_ce: 0.006684
2022-01-14 16:44:54,151 iteration 4198 : loss : 0.021583, loss_ce: 0.007653
2022-01-14 16:44:55,562 iteration 4199 : loss : 0.019793, loss_ce: 0.008118
 62%|████████████████▋          | 247/400 [1:52:48<1:09:15, 27.16s/it]2022-01-14 16:44:57,049 iteration 4200 : loss : 0.018671, loss_ce: 0.005941
2022-01-14 16:44:58,559 iteration 4201 : loss : 0.021598, loss_ce: 0.008414
2022-01-14 16:44:59,969 iteration 4202 : loss : 0.014888, loss_ce: 0.006748
2022-01-14 16:45:01,410 iteration 4203 : loss : 0.016700, loss_ce: 0.006644
2022-01-14 16:45:02,884 iteration 4204 : loss : 0.018371, loss_ce: 0.006267
2022-01-14 16:45:04,329 iteration 4205 : loss : 0.017052, loss_ce: 0.005657
2022-01-14 16:45:05,721 iteration 4206 : loss : 0.019862, loss_ce: 0.006055
2022-01-14 16:45:07,164 iteration 4207 : loss : 0.017685, loss_ce: 0.008110
2022-01-14 16:45:08,620 iteration 4208 : loss : 0.017089, loss_ce: 0.006174
2022-01-14 16:45:10,222 iteration 4209 : loss : 0.042556, loss_ce: 0.010654
2022-01-14 16:45:11,768 iteration 4210 : loss : 0.022760, loss_ce: 0.008822
2022-01-14 16:45:13,111 iteration 4211 : loss : 0.013216, loss_ce: 0.004995
2022-01-14 16:45:14,580 iteration 4212 : loss : 0.017768, loss_ce: 0.006929
2022-01-14 16:45:16,051 iteration 4213 : loss : 0.034747, loss_ce: 0.019752
2022-01-14 16:45:17,579 iteration 4214 : loss : 0.019315, loss_ce: 0.006227
2022-01-14 16:45:19,033 iteration 4215 : loss : 0.020197, loss_ce: 0.007126
2022-01-14 16:45:20,596 iteration 4216 : loss : 0.035410, loss_ce: 0.011636
 62%|████████████████▋          | 248/400 [1:53:13<1:07:11, 26.52s/it]2022-01-14 16:45:22,216 iteration 4217 : loss : 0.016818, loss_ce: 0.006766
2022-01-14 16:45:23,620 iteration 4218 : loss : 0.014336, loss_ce: 0.007407
2022-01-14 16:45:25,042 iteration 4219 : loss : 0.015371, loss_ce: 0.005915
2022-01-14 16:45:26,635 iteration 4220 : loss : 0.022437, loss_ce: 0.008193
2022-01-14 16:45:28,143 iteration 4221 : loss : 0.017537, loss_ce: 0.005013
2022-01-14 16:45:29,659 iteration 4222 : loss : 0.019715, loss_ce: 0.008311
2022-01-14 16:45:31,149 iteration 4223 : loss : 0.019487, loss_ce: 0.006565
2022-01-14 16:45:32,623 iteration 4224 : loss : 0.020433, loss_ce: 0.006837
2022-01-14 16:45:34,073 iteration 4225 : loss : 0.026299, loss_ce: 0.009059
2022-01-14 16:45:35,534 iteration 4226 : loss : 0.018958, loss_ce: 0.006077
2022-01-14 16:45:37,112 iteration 4227 : loss : 0.023164, loss_ce: 0.007142
2022-01-14 16:45:38,585 iteration 4228 : loss : 0.021267, loss_ce: 0.007993
2022-01-14 16:45:40,106 iteration 4229 : loss : 0.021003, loss_ce: 0.007550
2022-01-14 16:45:41,595 iteration 4230 : loss : 0.021394, loss_ce: 0.009852
2022-01-14 16:45:43,048 iteration 4231 : loss : 0.020574, loss_ce: 0.005873
2022-01-14 16:45:44,502 iteration 4232 : loss : 0.022249, loss_ce: 0.010695
2022-01-14 16:45:45,980 iteration 4233 : loss : 0.020582, loss_ce: 0.009640
 62%|████████████████▊          | 249/400 [1:53:39<1:05:53, 26.18s/it]2022-01-14 16:45:47,570 iteration 4234 : loss : 0.025580, loss_ce: 0.012949
2022-01-14 16:45:49,043 iteration 4235 : loss : 0.019522, loss_ce: 0.005312
2022-01-14 16:45:50,460 iteration 4236 : loss : 0.016774, loss_ce: 0.006875
2022-01-14 16:45:51,892 iteration 4237 : loss : 0.018406, loss_ce: 0.007228
2022-01-14 16:45:53,375 iteration 4238 : loss : 0.023861, loss_ce: 0.006965
2022-01-14 16:45:54,909 iteration 4239 : loss : 0.018140, loss_ce: 0.007199
2022-01-14 16:45:56,411 iteration 4240 : loss : 0.029278, loss_ce: 0.010772
2022-01-14 16:45:57,894 iteration 4241 : loss : 0.020247, loss_ce: 0.008766
2022-01-14 16:45:59,258 iteration 4242 : loss : 0.015264, loss_ce: 0.006161
2022-01-14 16:46:00,761 iteration 4243 : loss : 0.018909, loss_ce: 0.006999
2022-01-14 16:46:02,190 iteration 4244 : loss : 0.017573, loss_ce: 0.005524
2022-01-14 16:46:03,649 iteration 4245 : loss : 0.013458, loss_ce: 0.004981
2022-01-14 16:46:05,091 iteration 4246 : loss : 0.020735, loss_ce: 0.008457
2022-01-14 16:46:06,554 iteration 4247 : loss : 0.018119, loss_ce: 0.004960
2022-01-14 16:46:07,949 iteration 4248 : loss : 0.021127, loss_ce: 0.009146
2022-01-14 16:46:09,489 iteration 4249 : loss : 0.019336, loss_ce: 0.008017
2022-01-14 16:46:09,490 Training Data Eval:
2022-01-14 16:46:16,865   Average segmentation loss on training set: 0.0124
2022-01-14 16:46:16,866 Validation Data Eval:
2022-01-14 16:46:19,411   Average segmentation loss on validation set: 0.0889
2022-01-14 16:46:20,894 iteration 4250 : loss : 0.017765, loss_ce: 0.006847
 62%|████████████████▉          | 250/400 [1:54:14<1:12:00, 28.80s/it]2022-01-14 16:46:22,432 iteration 4251 : loss : 0.018615, loss_ce: 0.005894
2022-01-14 16:46:23,913 iteration 4252 : loss : 0.016588, loss_ce: 0.004181
2022-01-14 16:46:25,421 iteration 4253 : loss : 0.015464, loss_ce: 0.007359
2022-01-14 16:46:26,930 iteration 4254 : loss : 0.016971, loss_ce: 0.006694
2022-01-14 16:46:28,432 iteration 4255 : loss : 0.026167, loss_ce: 0.008116
2022-01-14 16:46:29,880 iteration 4256 : loss : 0.017052, loss_ce: 0.006344
2022-01-14 16:46:31,364 iteration 4257 : loss : 0.019515, loss_ce: 0.008258
2022-01-14 16:46:32,907 iteration 4258 : loss : 0.027504, loss_ce: 0.013768
2022-01-14 16:46:34,291 iteration 4259 : loss : 0.015033, loss_ce: 0.005301
2022-01-14 16:46:35,787 iteration 4260 : loss : 0.018352, loss_ce: 0.005786
2022-01-14 16:46:37,203 iteration 4261 : loss : 0.014031, loss_ce: 0.004574
2022-01-14 16:46:38,653 iteration 4262 : loss : 0.015062, loss_ce: 0.006319
2022-01-14 16:46:40,171 iteration 4263 : loss : 0.022068, loss_ce: 0.008696
2022-01-14 16:46:41,630 iteration 4264 : loss : 0.016579, loss_ce: 0.007360
2022-01-14 16:46:42,986 iteration 4265 : loss : 0.015013, loss_ce: 0.006529
2022-01-14 16:46:44,544 iteration 4266 : loss : 0.015825, loss_ce: 0.004963
2022-01-14 16:46:46,051 iteration 4267 : loss : 0.024955, loss_ce: 0.011124
 63%|████████████████▉          | 251/400 [1:54:39<1:08:48, 27.71s/it]2022-01-14 16:46:47,494 iteration 4268 : loss : 0.017054, loss_ce: 0.006512
2022-01-14 16:46:48,903 iteration 4269 : loss : 0.014361, loss_ce: 0.003619
2022-01-14 16:46:50,354 iteration 4270 : loss : 0.026144, loss_ce: 0.007120
2022-01-14 16:46:51,804 iteration 4271 : loss : 0.017686, loss_ce: 0.006463
2022-01-14 16:46:53,263 iteration 4272 : loss : 0.023511, loss_ce: 0.009351
2022-01-14 16:46:54,704 iteration 4273 : loss : 0.016993, loss_ce: 0.007218
2022-01-14 16:46:56,174 iteration 4274 : loss : 0.021403, loss_ce: 0.008429
2022-01-14 16:46:57,625 iteration 4275 : loss : 0.026234, loss_ce: 0.011444
2022-01-14 16:46:59,072 iteration 4276 : loss : 0.020122, loss_ce: 0.007424
2022-01-14 16:47:00,549 iteration 4277 : loss : 0.020194, loss_ce: 0.008800
2022-01-14 16:47:02,008 iteration 4278 : loss : 0.014729, loss_ce: 0.003847
2022-01-14 16:47:03,433 iteration 4279 : loss : 0.016279, loss_ce: 0.006331
2022-01-14 16:47:04,914 iteration 4280 : loss : 0.025372, loss_ce: 0.007680
2022-01-14 16:47:06,394 iteration 4281 : loss : 0.019949, loss_ce: 0.007335
2022-01-14 16:47:07,900 iteration 4282 : loss : 0.025364, loss_ce: 0.008858
2022-01-14 16:47:09,452 iteration 4283 : loss : 0.026424, loss_ce: 0.016876
2022-01-14 16:47:11,001 iteration 4284 : loss : 0.021379, loss_ce: 0.007546
 63%|█████████████████          | 252/400 [1:55:04<1:06:18, 26.88s/it]2022-01-14 16:47:12,458 iteration 4285 : loss : 0.015484, loss_ce: 0.007879
2022-01-14 16:47:13,892 iteration 4286 : loss : 0.016540, loss_ce: 0.005772
2022-01-14 16:47:15,375 iteration 4287 : loss : 0.021863, loss_ce: 0.008953
2022-01-14 16:47:16,798 iteration 4288 : loss : 0.014690, loss_ce: 0.004460
2022-01-14 16:47:18,225 iteration 4289 : loss : 0.015917, loss_ce: 0.007127
2022-01-14 16:47:19,721 iteration 4290 : loss : 0.016465, loss_ce: 0.006069
2022-01-14 16:47:21,301 iteration 4291 : loss : 0.023024, loss_ce: 0.009884
2022-01-14 16:47:22,866 iteration 4292 : loss : 0.023474, loss_ce: 0.013191
2022-01-14 16:47:24,261 iteration 4293 : loss : 0.017952, loss_ce: 0.007104
2022-01-14 16:47:25,714 iteration 4294 : loss : 0.017471, loss_ce: 0.008067
2022-01-14 16:47:27,316 iteration 4295 : loss : 0.029029, loss_ce: 0.010354
2022-01-14 16:47:28,769 iteration 4296 : loss : 0.019058, loss_ce: 0.007627
2022-01-14 16:47:30,206 iteration 4297 : loss : 0.016101, loss_ce: 0.004980
2022-01-14 16:47:31,738 iteration 4298 : loss : 0.021653, loss_ce: 0.008073
2022-01-14 16:47:33,241 iteration 4299 : loss : 0.021457, loss_ce: 0.006854
2022-01-14 16:47:34,815 iteration 4300 : loss : 0.024863, loss_ce: 0.008503
2022-01-14 16:47:36,296 iteration 4301 : loss : 0.029972, loss_ce: 0.011659
 63%|█████████████████          | 253/400 [1:55:29<1:04:41, 26.40s/it]2022-01-14 16:47:37,885 iteration 4302 : loss : 0.032253, loss_ce: 0.011640
2022-01-14 16:47:39,293 iteration 4303 : loss : 0.015393, loss_ce: 0.007445
2022-01-14 16:47:40,765 iteration 4304 : loss : 0.020710, loss_ce: 0.009353
2022-01-14 16:47:42,249 iteration 4305 : loss : 0.022547, loss_ce: 0.006530
2022-01-14 16:47:43,719 iteration 4306 : loss : 0.016275, loss_ce: 0.005118
2022-01-14 16:47:45,264 iteration 4307 : loss : 0.029458, loss_ce: 0.008978
2022-01-14 16:47:46,726 iteration 4308 : loss : 0.034512, loss_ce: 0.012677
2022-01-14 16:47:48,246 iteration 4309 : loss : 0.020765, loss_ce: 0.006318
2022-01-14 16:47:49,661 iteration 4310 : loss : 0.015763, loss_ce: 0.005316
2022-01-14 16:47:51,219 iteration 4311 : loss : 0.019995, loss_ce: 0.008059
2022-01-14 16:47:52,670 iteration 4312 : loss : 0.024124, loss_ce: 0.010131
2022-01-14 16:47:54,195 iteration 4313 : loss : 0.020008, loss_ce: 0.009310
2022-01-14 16:47:55,688 iteration 4314 : loss : 0.021978, loss_ce: 0.008024
2022-01-14 16:47:57,129 iteration 4315 : loss : 0.017175, loss_ce: 0.006006
2022-01-14 16:47:58,577 iteration 4316 : loss : 0.019767, loss_ce: 0.007538
2022-01-14 16:48:00,061 iteration 4317 : loss : 0.016370, loss_ce: 0.006840
2022-01-14 16:48:01,635 iteration 4318 : loss : 0.018466, loss_ce: 0.006427
 64%|█████████████████▏         | 254/400 [1:55:54<1:03:28, 26.09s/it]2022-01-14 16:48:03,131 iteration 4319 : loss : 0.023609, loss_ce: 0.009251
2022-01-14 16:48:04,511 iteration 4320 : loss : 0.015043, loss_ce: 0.006081
2022-01-14 16:48:06,119 iteration 4321 : loss : 0.025857, loss_ce: 0.013201
2022-01-14 16:48:07,589 iteration 4322 : loss : 0.027626, loss_ce: 0.009588
2022-01-14 16:48:09,060 iteration 4323 : loss : 0.023293, loss_ce: 0.007823
2022-01-14 16:48:10,515 iteration 4324 : loss : 0.015787, loss_ce: 0.006296
2022-01-14 16:48:11,959 iteration 4325 : loss : 0.025221, loss_ce: 0.007294
2022-01-14 16:48:13,475 iteration 4326 : loss : 0.021780, loss_ce: 0.007170
2022-01-14 16:48:15,031 iteration 4327 : loss : 0.019705, loss_ce: 0.009220
2022-01-14 16:48:16,543 iteration 4328 : loss : 0.017638, loss_ce: 0.008017
2022-01-14 16:48:17,999 iteration 4329 : loss : 0.015814, loss_ce: 0.005877
2022-01-14 16:48:19,414 iteration 4330 : loss : 0.015936, loss_ce: 0.006780
2022-01-14 16:48:20,864 iteration 4331 : loss : 0.015698, loss_ce: 0.006773
2022-01-14 16:48:22,280 iteration 4332 : loss : 0.013830, loss_ce: 0.004964
2022-01-14 16:48:23,656 iteration 4333 : loss : 0.021140, loss_ce: 0.008558
2022-01-14 16:48:25,140 iteration 4334 : loss : 0.014790, loss_ce: 0.005340
2022-01-14 16:48:25,140 Training Data Eval:
2022-01-14 16:48:32,498   Average segmentation loss on training set: 0.0113
2022-01-14 16:48:32,499 Validation Data Eval:
2022-01-14 16:48:35,038   Average segmentation loss on validation set: 0.0659
2022-01-14 16:48:36,539 iteration 4335 : loss : 0.031201, loss_ce: 0.007077
 64%|█████████████████▏         | 255/400 [1:56:29<1:09:25, 28.73s/it]2022-01-14 16:48:37,975 iteration 4336 : loss : 0.016953, loss_ce: 0.006700
2022-01-14 16:48:39,470 iteration 4337 : loss : 0.016945, loss_ce: 0.006770
2022-01-14 16:48:40,967 iteration 4338 : loss : 0.020520, loss_ce: 0.007544
2022-01-14 16:48:42,362 iteration 4339 : loss : 0.020660, loss_ce: 0.005257
2022-01-14 16:48:43,851 iteration 4340 : loss : 0.020075, loss_ce: 0.003796
2022-01-14 16:48:45,314 iteration 4341 : loss : 0.021800, loss_ce: 0.008178
2022-01-14 16:48:46,765 iteration 4342 : loss : 0.016913, loss_ce: 0.006583
2022-01-14 16:48:48,304 iteration 4343 : loss : 0.041647, loss_ce: 0.013478
2022-01-14 16:48:49,739 iteration 4344 : loss : 0.017790, loss_ce: 0.006680
2022-01-14 16:48:51,175 iteration 4345 : loss : 0.014777, loss_ce: 0.006104
2022-01-14 16:48:52,536 iteration 4346 : loss : 0.012559, loss_ce: 0.004415
2022-01-14 16:48:54,063 iteration 4347 : loss : 0.051021, loss_ce: 0.013547
2022-01-14 16:48:55,582 iteration 4348 : loss : 0.020461, loss_ce: 0.009328
2022-01-14 16:48:56,993 iteration 4349 : loss : 0.017452, loss_ce: 0.007599
2022-01-14 16:48:58,396 iteration 4350 : loss : 0.017864, loss_ce: 0.005825
2022-01-14 16:48:59,927 iteration 4351 : loss : 0.021431, loss_ce: 0.008761
2022-01-14 16:49:01,434 iteration 4352 : loss : 0.028762, loss_ce: 0.012125
 64%|█████████████████▎         | 256/400 [1:56:54<1:06:11, 27.58s/it]2022-01-14 16:49:02,916 iteration 4353 : loss : 0.016289, loss_ce: 0.005306
2022-01-14 16:49:04,457 iteration 4354 : loss : 0.020616, loss_ce: 0.006505
2022-01-14 16:49:05,960 iteration 4355 : loss : 0.015278, loss_ce: 0.004657
2022-01-14 16:49:07,397 iteration 4356 : loss : 0.022836, loss_ce: 0.009049
2022-01-14 16:49:08,943 iteration 4357 : loss : 0.022864, loss_ce: 0.008454
2022-01-14 16:49:10,387 iteration 4358 : loss : 0.024885, loss_ce: 0.011028
2022-01-14 16:49:11,889 iteration 4359 : loss : 0.024181, loss_ce: 0.007364
2022-01-14 16:49:13,300 iteration 4360 : loss : 0.015137, loss_ce: 0.006014
2022-01-14 16:49:14,827 iteration 4361 : loss : 0.021160, loss_ce: 0.008100
2022-01-14 16:49:16,254 iteration 4362 : loss : 0.014789, loss_ce: 0.004842
2022-01-14 16:49:17,756 iteration 4363 : loss : 0.016694, loss_ce: 0.006348
2022-01-14 16:49:19,225 iteration 4364 : loss : 0.016397, loss_ce: 0.007212
2022-01-14 16:49:20,743 iteration 4365 : loss : 0.018479, loss_ce: 0.006187
2022-01-14 16:49:22,179 iteration 4366 : loss : 0.016674, loss_ce: 0.006830
2022-01-14 16:49:23,581 iteration 4367 : loss : 0.017755, loss_ce: 0.007612
2022-01-14 16:49:25,022 iteration 4368 : loss : 0.014243, loss_ce: 0.005653
2022-01-14 16:49:26,541 iteration 4369 : loss : 0.026946, loss_ce: 0.011754
 64%|█████████████████▎         | 257/400 [1:57:19<1:03:57, 26.84s/it]2022-01-14 16:49:28,006 iteration 4370 : loss : 0.019580, loss_ce: 0.007149
2022-01-14 16:49:29,641 iteration 4371 : loss : 0.022889, loss_ce: 0.007799
2022-01-14 16:49:31,158 iteration 4372 : loss : 0.024903, loss_ce: 0.007280
2022-01-14 16:49:32,676 iteration 4373 : loss : 0.027928, loss_ce: 0.008894
2022-01-14 16:49:34,119 iteration 4374 : loss : 0.021791, loss_ce: 0.007754
2022-01-14 16:49:35,598 iteration 4375 : loss : 0.015463, loss_ce: 0.005811
2022-01-14 16:49:37,100 iteration 4376 : loss : 0.021952, loss_ce: 0.007300
2022-01-14 16:49:38,537 iteration 4377 : loss : 0.014402, loss_ce: 0.004803
2022-01-14 16:49:40,056 iteration 4378 : loss : 0.024306, loss_ce: 0.012658
2022-01-14 16:49:41,505 iteration 4379 : loss : 0.024132, loss_ce: 0.009513
2022-01-14 16:49:42,990 iteration 4380 : loss : 0.022200, loss_ce: 0.007840
2022-01-14 16:49:44,492 iteration 4381 : loss : 0.027385, loss_ce: 0.008848
2022-01-14 16:49:46,073 iteration 4382 : loss : 0.029349, loss_ce: 0.010314
2022-01-14 16:49:47,557 iteration 4383 : loss : 0.033876, loss_ce: 0.013383
2022-01-14 16:49:49,085 iteration 4384 : loss : 0.016428, loss_ce: 0.005645
2022-01-14 16:49:50,663 iteration 4385 : loss : 0.029193, loss_ce: 0.015557
2022-01-14 16:49:52,128 iteration 4386 : loss : 0.015788, loss_ce: 0.004121
 64%|█████████████████▍         | 258/400 [1:57:45<1:02:37, 26.46s/it]2022-01-14 16:49:53,721 iteration 4387 : loss : 0.031815, loss_ce: 0.007913
2022-01-14 16:49:55,223 iteration 4388 : loss : 0.022038, loss_ce: 0.010972
2022-01-14 16:49:56,724 iteration 4389 : loss : 0.016765, loss_ce: 0.007549
2022-01-14 16:49:58,245 iteration 4390 : loss : 0.021460, loss_ce: 0.009113
2022-01-14 16:49:59,798 iteration 4391 : loss : 0.025684, loss_ce: 0.008565
2022-01-14 16:50:01,309 iteration 4392 : loss : 0.028629, loss_ce: 0.012743
2022-01-14 16:50:02,885 iteration 4393 : loss : 0.017414, loss_ce: 0.007127
2022-01-14 16:50:04,296 iteration 4394 : loss : 0.013769, loss_ce: 0.005502
2022-01-14 16:50:05,781 iteration 4395 : loss : 0.014847, loss_ce: 0.006488
2022-01-14 16:50:07,271 iteration 4396 : loss : 0.019508, loss_ce: 0.007277
2022-01-14 16:50:08,687 iteration 4397 : loss : 0.016403, loss_ce: 0.006644
2022-01-14 16:50:10,163 iteration 4398 : loss : 0.015664, loss_ce: 0.006432
2022-01-14 16:50:11,643 iteration 4399 : loss : 0.018486, loss_ce: 0.005925
2022-01-14 16:50:13,066 iteration 4400 : loss : 0.015039, loss_ce: 0.005019
2022-01-14 16:50:14,578 iteration 4401 : loss : 0.020383, loss_ce: 0.009826
2022-01-14 16:50:15,975 iteration 4402 : loss : 0.015007, loss_ce: 0.005261
2022-01-14 16:50:17,464 iteration 4403 : loss : 0.020368, loss_ce: 0.005480
 65%|█████████████████▍         | 259/400 [1:58:10<1:01:23, 26.13s/it]2022-01-14 16:50:19,060 iteration 4404 : loss : 0.023067, loss_ce: 0.009537
2022-01-14 16:50:20,538 iteration 4405 : loss : 0.019991, loss_ce: 0.007284
2022-01-14 16:50:22,049 iteration 4406 : loss : 0.015807, loss_ce: 0.006900
2022-01-14 16:50:23,546 iteration 4407 : loss : 0.019736, loss_ce: 0.005261
2022-01-14 16:50:24,989 iteration 4408 : loss : 0.016666, loss_ce: 0.008253
2022-01-14 16:50:26,415 iteration 4409 : loss : 0.021521, loss_ce: 0.008075
2022-01-14 16:50:27,980 iteration 4410 : loss : 0.026010, loss_ce: 0.008361
2022-01-14 16:50:29,472 iteration 4411 : loss : 0.026258, loss_ce: 0.011367
2022-01-14 16:50:30,958 iteration 4412 : loss : 0.019280, loss_ce: 0.008112
2022-01-14 16:50:32,459 iteration 4413 : loss : 0.015236, loss_ce: 0.006699
2022-01-14 16:50:33,906 iteration 4414 : loss : 0.024074, loss_ce: 0.007413
2022-01-14 16:50:35,342 iteration 4415 : loss : 0.015167, loss_ce: 0.006783
2022-01-14 16:50:36,841 iteration 4416 : loss : 0.022445, loss_ce: 0.007811
2022-01-14 16:50:38,339 iteration 4417 : loss : 0.021889, loss_ce: 0.009646
2022-01-14 16:50:39,829 iteration 4418 : loss : 0.016146, loss_ce: 0.006007
2022-01-14 16:50:41,291 iteration 4419 : loss : 0.018797, loss_ce: 0.006504
2022-01-14 16:50:41,292 Training Data Eval:
2022-01-14 16:50:48,647   Average segmentation loss on training set: 0.0125
2022-01-14 16:50:48,648 Validation Data Eval:
2022-01-14 16:50:51,191   Average segmentation loss on validation set: 0.0870
2022-01-14 16:50:52,636 iteration 4420 : loss : 0.015950, loss_ce: 0.004627
 65%|█████████████████▌         | 260/400 [1:58:45<1:07:17, 28.84s/it]2022-01-14 16:50:54,147 iteration 4421 : loss : 0.025229, loss_ce: 0.007961
2022-01-14 16:50:55,602 iteration 4422 : loss : 0.018549, loss_ce: 0.006173
2022-01-14 16:50:57,048 iteration 4423 : loss : 0.012834, loss_ce: 0.004482
2022-01-14 16:50:58,562 iteration 4424 : loss : 0.019619, loss_ce: 0.007019
2022-01-14 16:51:00,030 iteration 4425 : loss : 0.026246, loss_ce: 0.009388
2022-01-14 16:51:01,488 iteration 4426 : loss : 0.027201, loss_ce: 0.006381
2022-01-14 16:51:02,973 iteration 4427 : loss : 0.023716, loss_ce: 0.010073
2022-01-14 16:51:04,472 iteration 4428 : loss : 0.024317, loss_ce: 0.009995
2022-01-14 16:51:05,846 iteration 4429 : loss : 0.022938, loss_ce: 0.010617
2022-01-14 16:51:07,331 iteration 4430 : loss : 0.020136, loss_ce: 0.009101
2022-01-14 16:51:08,845 iteration 4431 : loss : 0.032480, loss_ce: 0.010546
2022-01-14 16:51:10,383 iteration 4432 : loss : 0.021947, loss_ce: 0.008955
2022-01-14 16:51:11,888 iteration 4433 : loss : 0.030100, loss_ce: 0.008660
2022-01-14 16:51:13,406 iteration 4434 : loss : 0.023259, loss_ce: 0.010346
2022-01-14 16:51:14,835 iteration 4435 : loss : 0.019138, loss_ce: 0.006473
2022-01-14 16:51:16,291 iteration 4436 : loss : 0.022855, loss_ce: 0.014698
2022-01-14 16:51:17,766 iteration 4437 : loss : 0.021315, loss_ce: 0.007943
 65%|█████████████████▌         | 261/400 [1:59:11<1:04:13, 27.73s/it]2022-01-14 16:51:19,373 iteration 4438 : loss : 0.022129, loss_ce: 0.007662
2022-01-14 16:51:20,775 iteration 4439 : loss : 0.015097, loss_ce: 0.006627
2022-01-14 16:51:22,318 iteration 4440 : loss : 0.021400, loss_ce: 0.011126
2022-01-14 16:51:23,805 iteration 4441 : loss : 0.019474, loss_ce: 0.007655
2022-01-14 16:51:25,378 iteration 4442 : loss : 0.024853, loss_ce: 0.012122
2022-01-14 16:51:26,935 iteration 4443 : loss : 0.025794, loss_ce: 0.010556
2022-01-14 16:51:28,447 iteration 4444 : loss : 0.019299, loss_ce: 0.006715
2022-01-14 16:51:29,901 iteration 4445 : loss : 0.014619, loss_ce: 0.004670
2022-01-14 16:51:31,440 iteration 4446 : loss : 0.049368, loss_ce: 0.009788
2022-01-14 16:51:33,010 iteration 4447 : loss : 0.021088, loss_ce: 0.006606
2022-01-14 16:51:34,480 iteration 4448 : loss : 0.018322, loss_ce: 0.006074
2022-01-14 16:51:36,054 iteration 4449 : loss : 0.019757, loss_ce: 0.008737
2022-01-14 16:51:37,528 iteration 4450 : loss : 0.022386, loss_ce: 0.013563
2022-01-14 16:51:39,043 iteration 4451 : loss : 0.016600, loss_ce: 0.006160
2022-01-14 16:51:40,484 iteration 4452 : loss : 0.019516, loss_ce: 0.005634
2022-01-14 16:51:41,916 iteration 4453 : loss : 0.019684, loss_ce: 0.008874
2022-01-14 16:51:43,373 iteration 4454 : loss : 0.028021, loss_ce: 0.012351
 66%|█████████████████▋         | 262/400 [1:59:36<1:02:18, 27.09s/it]2022-01-14 16:51:44,871 iteration 4455 : loss : 0.032439, loss_ce: 0.013091
2022-01-14 16:51:46,276 iteration 4456 : loss : 0.017574, loss_ce: 0.006081
2022-01-14 16:51:47,753 iteration 4457 : loss : 0.015793, loss_ce: 0.006596
2022-01-14 16:51:49,192 iteration 4458 : loss : 0.018488, loss_ce: 0.007326
2022-01-14 16:51:50,702 iteration 4459 : loss : 0.075802, loss_ce: 0.020494
2022-01-14 16:51:52,135 iteration 4460 : loss : 0.014002, loss_ce: 0.005550
2022-01-14 16:51:53,588 iteration 4461 : loss : 0.019904, loss_ce: 0.009025
2022-01-14 16:51:55,139 iteration 4462 : loss : 0.032403, loss_ce: 0.012258
2022-01-14 16:51:56,552 iteration 4463 : loss : 0.019234, loss_ce: 0.007282
2022-01-14 16:51:57,997 iteration 4464 : loss : 0.014875, loss_ce: 0.006709
2022-01-14 16:51:59,574 iteration 4465 : loss : 0.087567, loss_ce: 0.017184
2022-01-14 16:52:00,997 iteration 4466 : loss : 0.017366, loss_ce: 0.007342
2022-01-14 16:52:02,520 iteration 4467 : loss : 0.019303, loss_ce: 0.009072
2022-01-14 16:52:04,031 iteration 4468 : loss : 0.026532, loss_ce: 0.009445
2022-01-14 16:52:05,538 iteration 4469 : loss : 0.017750, loss_ce: 0.005205
2022-01-14 16:52:07,026 iteration 4470 : loss : 0.027568, loss_ce: 0.012163
2022-01-14 16:52:08,544 iteration 4471 : loss : 0.034107, loss_ce: 0.009883
 66%|█████████████████▊         | 263/400 [2:00:01<1:00:32, 26.51s/it]2022-01-14 16:52:10,019 iteration 4472 : loss : 0.023549, loss_ce: 0.010289
2022-01-14 16:52:11,529 iteration 4473 : loss : 0.029142, loss_ce: 0.010082
2022-01-14 16:52:13,099 iteration 4474 : loss : 0.026463, loss_ce: 0.011700
2022-01-14 16:52:14,606 iteration 4475 : loss : 0.020623, loss_ce: 0.008283
2022-01-14 16:52:16,060 iteration 4476 : loss : 0.045078, loss_ce: 0.014318
2022-01-14 16:52:17,507 iteration 4477 : loss : 0.022171, loss_ce: 0.009128
2022-01-14 16:52:19,071 iteration 4478 : loss : 0.036381, loss_ce: 0.019031
2022-01-14 16:52:20,532 iteration 4479 : loss : 0.022452, loss_ce: 0.009964
2022-01-14 16:52:21,936 iteration 4480 : loss : 0.017803, loss_ce: 0.006531
2022-01-14 16:52:23,462 iteration 4481 : loss : 0.025285, loss_ce: 0.006596
2022-01-14 16:52:24,937 iteration 4482 : loss : 0.019055, loss_ce: 0.006860
2022-01-14 16:52:26,363 iteration 4483 : loss : 0.020867, loss_ce: 0.006469
2022-01-14 16:52:27,908 iteration 4484 : loss : 0.022049, loss_ce: 0.007524
2022-01-14 16:52:29,447 iteration 4485 : loss : 0.025087, loss_ce: 0.010958
2022-01-14 16:52:30,987 iteration 4486 : loss : 0.030090, loss_ce: 0.010949
2022-01-14 16:52:32,423 iteration 4487 : loss : 0.018730, loss_ce: 0.005201
2022-01-14 16:52:33,873 iteration 4488 : loss : 0.023316, loss_ce: 0.007972
 66%|███████████████████▏         | 264/400 [2:00:27<59:17, 26.16s/it]2022-01-14 16:52:35,429 iteration 4489 : loss : 0.020850, loss_ce: 0.009437
2022-01-14 16:52:36,856 iteration 4490 : loss : 0.017474, loss_ce: 0.009486
2022-01-14 16:52:38,369 iteration 4491 : loss : 0.019138, loss_ce: 0.006080
2022-01-14 16:52:39,937 iteration 4492 : loss : 0.020656, loss_ce: 0.008791
2022-01-14 16:52:41,395 iteration 4493 : loss : 0.046203, loss_ce: 0.017788
2022-01-14 16:52:42,867 iteration 4494 : loss : 0.017817, loss_ce: 0.005403
2022-01-14 16:52:44,355 iteration 4495 : loss : 0.052387, loss_ce: 0.016039
2022-01-14 16:52:45,797 iteration 4496 : loss : 0.015532, loss_ce: 0.007377
2022-01-14 16:52:47,338 iteration 4497 : loss : 0.022048, loss_ce: 0.009497
2022-01-14 16:52:48,810 iteration 4498 : loss : 0.030366, loss_ce: 0.008469
2022-01-14 16:52:50,316 iteration 4499 : loss : 0.030196, loss_ce: 0.010670
2022-01-14 16:52:51,730 iteration 4500 : loss : 0.014625, loss_ce: 0.005055
2022-01-14 16:52:53,168 iteration 4501 : loss : 0.025802, loss_ce: 0.009844
2022-01-14 16:52:54,611 iteration 4502 : loss : 0.030369, loss_ce: 0.010403
2022-01-14 16:52:56,162 iteration 4503 : loss : 0.016915, loss_ce: 0.006831
2022-01-14 16:52:57,629 iteration 4504 : loss : 0.016106, loss_ce: 0.005676
2022-01-14 16:52:57,630 Training Data Eval:
2022-01-14 16:53:04,983   Average segmentation loss on training set: 0.0146
2022-01-14 16:53:04,984 Validation Data Eval:
2022-01-14 16:53:07,528   Average segmentation loss on validation set: 0.1022
2022-01-14 16:53:09,026 iteration 4505 : loss : 0.018042, loss_ce: 0.006995
 66%|█████████████████▉         | 265/400 [2:01:02<1:04:55, 28.86s/it]2022-01-14 16:53:10,510 iteration 4506 : loss : 0.021408, loss_ce: 0.008073
2022-01-14 16:53:11,997 iteration 4507 : loss : 0.018050, loss_ce: 0.007710
2022-01-14 16:53:13,447 iteration 4508 : loss : 0.017771, loss_ce: 0.006622
2022-01-14 16:53:14,881 iteration 4509 : loss : 0.038131, loss_ce: 0.008392
2022-01-14 16:53:16,455 iteration 4510 : loss : 0.022120, loss_ce: 0.006480
2022-01-14 16:53:17,919 iteration 4511 : loss : 0.018629, loss_ce: 0.005023
2022-01-14 16:53:19,462 iteration 4512 : loss : 0.026544, loss_ce: 0.012585
2022-01-14 16:53:21,035 iteration 4513 : loss : 0.029867, loss_ce: 0.010356
2022-01-14 16:53:22,426 iteration 4514 : loss : 0.021672, loss_ce: 0.007223
2022-01-14 16:53:23,880 iteration 4515 : loss : 0.018867, loss_ce: 0.005754
2022-01-14 16:53:25,297 iteration 4516 : loss : 0.014285, loss_ce: 0.005412
2022-01-14 16:53:26,734 iteration 4517 : loss : 0.015333, loss_ce: 0.005995
2022-01-14 16:53:28,231 iteration 4518 : loss : 0.019998, loss_ce: 0.006868
2022-01-14 16:53:29,620 iteration 4519 : loss : 0.017118, loss_ce: 0.005907
2022-01-14 16:53:31,126 iteration 4520 : loss : 0.032996, loss_ce: 0.014601
2022-01-14 16:53:32,565 iteration 4521 : loss : 0.035473, loss_ce: 0.017453
2022-01-14 16:53:34,046 iteration 4522 : loss : 0.021799, loss_ce: 0.007732
 66%|█████████████████▉         | 266/400 [2:01:27<1:01:52, 27.71s/it]2022-01-14 16:53:35,646 iteration 4523 : loss : 0.023422, loss_ce: 0.008341
2022-01-14 16:53:37,084 iteration 4524 : loss : 0.018773, loss_ce: 0.007662
2022-01-14 16:53:38,480 iteration 4525 : loss : 0.014490, loss_ce: 0.006886
2022-01-14 16:53:39,920 iteration 4526 : loss : 0.024273, loss_ce: 0.008061
2022-01-14 16:53:41,360 iteration 4527 : loss : 0.012559, loss_ce: 0.005304
2022-01-14 16:53:42,834 iteration 4528 : loss : 0.019320, loss_ce: 0.007261
2022-01-14 16:53:44,235 iteration 4529 : loss : 0.017238, loss_ce: 0.006032
2022-01-14 16:53:45,707 iteration 4530 : loss : 0.022614, loss_ce: 0.008945
2022-01-14 16:53:47,278 iteration 4531 : loss : 0.026170, loss_ce: 0.007176
2022-01-14 16:53:48,674 iteration 4532 : loss : 0.014284, loss_ce: 0.005156
2022-01-14 16:53:50,291 iteration 4533 : loss : 0.026409, loss_ce: 0.010876
2022-01-14 16:53:51,730 iteration 4534 : loss : 0.016371, loss_ce: 0.007847
2022-01-14 16:53:53,242 iteration 4535 : loss : 0.027735, loss_ce: 0.013178
2022-01-14 16:53:54,734 iteration 4536 : loss : 0.016631, loss_ce: 0.004678
2022-01-14 16:53:56,183 iteration 4537 : loss : 0.022842, loss_ce: 0.008034
2022-01-14 16:53:57,643 iteration 4538 : loss : 0.020861, loss_ce: 0.010239
2022-01-14 16:53:59,017 iteration 4539 : loss : 0.013922, loss_ce: 0.005041
 67%|███████████████████▎         | 267/400 [2:01:52<59:35, 26.89s/it]2022-01-14 16:54:00,485 iteration 4540 : loss : 0.022768, loss_ce: 0.012451
2022-01-14 16:54:01,974 iteration 4541 : loss : 0.020366, loss_ce: 0.007587
2022-01-14 16:54:03,450 iteration 4542 : loss : 0.025954, loss_ce: 0.007311
2022-01-14 16:54:05,084 iteration 4543 : loss : 0.022457, loss_ce: 0.008490
2022-01-14 16:54:06,514 iteration 4544 : loss : 0.022203, loss_ce: 0.009326
2022-01-14 16:54:07,937 iteration 4545 : loss : 0.012854, loss_ce: 0.005106
2022-01-14 16:54:09,392 iteration 4546 : loss : 0.017040, loss_ce: 0.006806
2022-01-14 16:54:10,879 iteration 4547 : loss : 0.018398, loss_ce: 0.006670
2022-01-14 16:54:12,329 iteration 4548 : loss : 0.021385, loss_ce: 0.009793
2022-01-14 16:54:13,726 iteration 4549 : loss : 0.019299, loss_ce: 0.005852
2022-01-14 16:54:15,279 iteration 4550 : loss : 0.019836, loss_ce: 0.006406
2022-01-14 16:54:16,832 iteration 4551 : loss : 0.023396, loss_ce: 0.008407
2022-01-14 16:54:18,309 iteration 4552 : loss : 0.021027, loss_ce: 0.006631
2022-01-14 16:54:19,763 iteration 4553 : loss : 0.015329, loss_ce: 0.005092
2022-01-14 16:54:21,278 iteration 4554 : loss : 0.024389, loss_ce: 0.006639
2022-01-14 16:54:22,706 iteration 4555 : loss : 0.028946, loss_ce: 0.010270
2022-01-14 16:54:24,175 iteration 4556 : loss : 0.018105, loss_ce: 0.007158
 67%|███████████████████▍         | 268/400 [2:02:17<58:00, 26.37s/it]2022-01-14 16:54:25,676 iteration 4557 : loss : 0.013156, loss_ce: 0.006310
2022-01-14 16:54:27,163 iteration 4558 : loss : 0.020921, loss_ce: 0.008226
2022-01-14 16:54:28,678 iteration 4559 : loss : 0.018049, loss_ce: 0.005328
2022-01-14 16:54:30,159 iteration 4560 : loss : 0.021622, loss_ce: 0.005984
2022-01-14 16:54:31,673 iteration 4561 : loss : 0.025189, loss_ce: 0.006784
2022-01-14 16:54:33,112 iteration 4562 : loss : 0.019791, loss_ce: 0.006105
2022-01-14 16:54:34,616 iteration 4563 : loss : 0.016462, loss_ce: 0.006566
2022-01-14 16:54:36,162 iteration 4564 : loss : 0.025886, loss_ce: 0.010968
2022-01-14 16:54:37,741 iteration 4565 : loss : 0.048354, loss_ce: 0.016408
2022-01-14 16:54:39,273 iteration 4566 : loss : 0.027140, loss_ce: 0.013202
2022-01-14 16:54:40,739 iteration 4567 : loss : 0.018110, loss_ce: 0.006840
2022-01-14 16:54:42,207 iteration 4568 : loss : 0.017294, loss_ce: 0.005341
2022-01-14 16:54:43,772 iteration 4569 : loss : 0.024533, loss_ce: 0.004660
2022-01-14 16:54:45,352 iteration 4570 : loss : 0.023926, loss_ce: 0.009787
2022-01-14 16:54:46,820 iteration 4571 : loss : 0.023072, loss_ce: 0.009487
2022-01-14 16:54:48,236 iteration 4572 : loss : 0.021448, loss_ce: 0.007711
2022-01-14 16:54:49,742 iteration 4573 : loss : 0.025741, loss_ce: 0.011993
 67%|███████████████████▌         | 269/400 [2:02:43<57:02, 26.13s/it]2022-01-14 16:54:51,187 iteration 4574 : loss : 0.017052, loss_ce: 0.008689
2022-01-14 16:54:52,714 iteration 4575 : loss : 0.020838, loss_ce: 0.006426
2022-01-14 16:54:54,317 iteration 4576 : loss : 0.020676, loss_ce: 0.007357
2022-01-14 16:54:55,818 iteration 4577 : loss : 0.028843, loss_ce: 0.011036
2022-01-14 16:54:57,215 iteration 4578 : loss : 0.020257, loss_ce: 0.010721
2022-01-14 16:54:58,749 iteration 4579 : loss : 0.015507, loss_ce: 0.004698
2022-01-14 16:55:00,232 iteration 4580 : loss : 0.017175, loss_ce: 0.006750
2022-01-14 16:55:01,717 iteration 4581 : loss : 0.015580, loss_ce: 0.005442
2022-01-14 16:55:03,180 iteration 4582 : loss : 0.018188, loss_ce: 0.007399
2022-01-14 16:55:04,756 iteration 4583 : loss : 0.030182, loss_ce: 0.006914
2022-01-14 16:55:06,235 iteration 4584 : loss : 0.024802, loss_ce: 0.007842
2022-01-14 16:55:07,665 iteration 4585 : loss : 0.013328, loss_ce: 0.004431
2022-01-14 16:55:09,127 iteration 4586 : loss : 0.015928, loss_ce: 0.008008
2022-01-14 16:55:10,598 iteration 4587 : loss : 0.016187, loss_ce: 0.006152
2022-01-14 16:55:12,147 iteration 4588 : loss : 0.017700, loss_ce: 0.007167
2022-01-14 16:55:13,627 iteration 4589 : loss : 0.018757, loss_ce: 0.008871
2022-01-14 16:55:13,627 Training Data Eval:
2022-01-14 16:55:21,002   Average segmentation loss on training set: 0.0114
2022-01-14 16:55:21,003 Validation Data Eval:
2022-01-14 16:55:23,546   Average segmentation loss on validation set: 0.0929
2022-01-14 16:55:25,062 iteration 4590 : loss : 0.018140, loss_ce: 0.009523
 68%|██████████████████▏        | 270/400 [2:03:18<1:02:35, 28.89s/it]2022-01-14 16:55:26,728 iteration 4591 : loss : 0.021010, loss_ce: 0.006356
2022-01-14 16:55:28,211 iteration 4592 : loss : 0.020336, loss_ce: 0.008718
2022-01-14 16:55:29,695 iteration 4593 : loss : 0.021237, loss_ce: 0.007430
2022-01-14 16:55:31,189 iteration 4594 : loss : 0.017879, loss_ce: 0.006554
2022-01-14 16:55:32,669 iteration 4595 : loss : 0.016345, loss_ce: 0.006176
2022-01-14 16:55:34,253 iteration 4596 : loss : 0.029716, loss_ce: 0.011163
2022-01-14 16:55:35,680 iteration 4597 : loss : 0.017428, loss_ce: 0.005056
2022-01-14 16:55:37,069 iteration 4598 : loss : 0.016035, loss_ce: 0.005294
2022-01-14 16:55:38,516 iteration 4599 : loss : 0.016745, loss_ce: 0.006927
2022-01-14 16:55:40,007 iteration 4600 : loss : 0.019296, loss_ce: 0.006611
2022-01-14 16:55:41,517 iteration 4601 : loss : 0.016637, loss_ce: 0.008524
2022-01-14 16:55:43,089 iteration 4602 : loss : 0.019063, loss_ce: 0.007105
2022-01-14 16:55:44,651 iteration 4603 : loss : 0.025201, loss_ce: 0.010971
2022-01-14 16:55:46,084 iteration 4604 : loss : 0.023200, loss_ce: 0.008752
2022-01-14 16:55:47,561 iteration 4605 : loss : 0.014494, loss_ce: 0.004134
2022-01-14 16:55:49,020 iteration 4606 : loss : 0.020176, loss_ce: 0.006621
2022-01-14 16:55:50,482 iteration 4607 : loss : 0.018597, loss_ce: 0.007780
 68%|███████████████████▋         | 271/400 [2:03:43<59:51, 27.84s/it]2022-01-14 16:55:52,030 iteration 4608 : loss : 0.013412, loss_ce: 0.004215
2022-01-14 16:55:53,534 iteration 4609 : loss : 0.017158, loss_ce: 0.005412
2022-01-14 16:55:55,039 iteration 4610 : loss : 0.016251, loss_ce: 0.003857
2022-01-14 16:55:56,569 iteration 4611 : loss : 0.025674, loss_ce: 0.009286
2022-01-14 16:55:58,065 iteration 4612 : loss : 0.023643, loss_ce: 0.009824
2022-01-14 16:55:59,559 iteration 4613 : loss : 0.015517, loss_ce: 0.005280
2022-01-14 16:56:01,047 iteration 4614 : loss : 0.015665, loss_ce: 0.004801
2022-01-14 16:56:02,655 iteration 4615 : loss : 0.022197, loss_ce: 0.009635
2022-01-14 16:56:04,080 iteration 4616 : loss : 0.017478, loss_ce: 0.007665
2022-01-14 16:56:05,583 iteration 4617 : loss : 0.020069, loss_ce: 0.006987
2022-01-14 16:56:07,032 iteration 4618 : loss : 0.010404, loss_ce: 0.004027
2022-01-14 16:56:08,534 iteration 4619 : loss : 0.031736, loss_ce: 0.010381
2022-01-14 16:56:09,987 iteration 4620 : loss : 0.017317, loss_ce: 0.007063
2022-01-14 16:56:11,442 iteration 4621 : loss : 0.018204, loss_ce: 0.006593
2022-01-14 16:56:12,952 iteration 4622 : loss : 0.018597, loss_ce: 0.007376
2022-01-14 16:56:14,442 iteration 4623 : loss : 0.014636, loss_ce: 0.006305
2022-01-14 16:56:15,886 iteration 4624 : loss : 0.018956, loss_ce: 0.005682
 68%|███████████████████▋         | 272/400 [2:04:09<57:50, 27.11s/it]2022-01-14 16:56:17,471 iteration 4625 : loss : 0.030068, loss_ce: 0.009215
2022-01-14 16:56:18,993 iteration 4626 : loss : 0.022219, loss_ce: 0.007181
2022-01-14 16:56:20,460 iteration 4627 : loss : 0.014688, loss_ce: 0.006738
2022-01-14 16:56:21,945 iteration 4628 : loss : 0.016638, loss_ce: 0.005514
2022-01-14 16:56:23,369 iteration 4629 : loss : 0.027863, loss_ce: 0.004771
2022-01-14 16:56:24,861 iteration 4630 : loss : 0.021619, loss_ce: 0.012124
2022-01-14 16:56:26,310 iteration 4631 : loss : 0.038618, loss_ce: 0.012762
2022-01-14 16:56:27,799 iteration 4632 : loss : 0.015522, loss_ce: 0.004373
2022-01-14 16:56:29,300 iteration 4633 : loss : 0.016839, loss_ce: 0.005544
2022-01-14 16:56:30,863 iteration 4634 : loss : 0.019634, loss_ce: 0.008379
2022-01-14 16:56:32,224 iteration 4635 : loss : 0.014198, loss_ce: 0.004577
2022-01-14 16:56:33,631 iteration 4636 : loss : 0.013759, loss_ce: 0.005042
2022-01-14 16:56:35,118 iteration 4637 : loss : 0.029361, loss_ce: 0.007994
2022-01-14 16:56:36,589 iteration 4638 : loss : 0.025248, loss_ce: 0.011319
2022-01-14 16:56:38,098 iteration 4639 : loss : 0.018944, loss_ce: 0.006358
2022-01-14 16:56:39,615 iteration 4640 : loss : 0.020788, loss_ce: 0.008740
2022-01-14 16:56:41,100 iteration 4641 : loss : 0.019947, loss_ce: 0.006994
 68%|███████████████████▊         | 273/400 [2:04:34<56:10, 26.54s/it]2022-01-14 16:56:42,620 iteration 4642 : loss : 0.018165, loss_ce: 0.007382
2022-01-14 16:56:44,108 iteration 4643 : loss : 0.027325, loss_ce: 0.009323
2022-01-14 16:56:45,605 iteration 4644 : loss : 0.024886, loss_ce: 0.010929
2022-01-14 16:56:47,050 iteration 4645 : loss : 0.017998, loss_ce: 0.006433
2022-01-14 16:56:48,556 iteration 4646 : loss : 0.024836, loss_ce: 0.009805
2022-01-14 16:56:50,071 iteration 4647 : loss : 0.016531, loss_ce: 0.006649
2022-01-14 16:56:51,540 iteration 4648 : loss : 0.019836, loss_ce: 0.007546
2022-01-14 16:56:53,208 iteration 4649 : loss : 0.026157, loss_ce: 0.010056
2022-01-14 16:56:54,585 iteration 4650 : loss : 0.015387, loss_ce: 0.006054
2022-01-14 16:56:56,070 iteration 4651 : loss : 0.017767, loss_ce: 0.006329
2022-01-14 16:56:57,542 iteration 4652 : loss : 0.017435, loss_ce: 0.006600
2022-01-14 16:56:58,937 iteration 4653 : loss : 0.016131, loss_ce: 0.005717
2022-01-14 16:57:00,351 iteration 4654 : loss : 0.014222, loss_ce: 0.004140
2022-01-14 16:57:01,879 iteration 4655 : loss : 0.021965, loss_ce: 0.007767
2022-01-14 16:57:03,349 iteration 4656 : loss : 0.021356, loss_ce: 0.007322
2022-01-14 16:57:04,823 iteration 4657 : loss : 0.016850, loss_ce: 0.006922
2022-01-14 16:57:06,284 iteration 4658 : loss : 0.015562, loss_ce: 0.006602
 68%|███████████████████▊         | 274/400 [2:04:59<54:52, 26.13s/it]2022-01-14 16:57:07,815 iteration 4659 : loss : 0.019939, loss_ce: 0.007302
2022-01-14 16:57:09,251 iteration 4660 : loss : 0.014510, loss_ce: 0.005653
2022-01-14 16:57:10,779 iteration 4661 : loss : 0.023922, loss_ce: 0.011551
2022-01-14 16:57:12,158 iteration 4662 : loss : 0.012172, loss_ce: 0.005498
2022-01-14 16:57:13,726 iteration 4663 : loss : 0.021387, loss_ce: 0.008647
2022-01-14 16:57:15,197 iteration 4664 : loss : 0.018494, loss_ce: 0.005828
2022-01-14 16:57:16,663 iteration 4665 : loss : 0.019517, loss_ce: 0.008520
2022-01-14 16:57:18,194 iteration 4666 : loss : 0.018779, loss_ce: 0.008105
2022-01-14 16:57:19,729 iteration 4667 : loss : 0.021678, loss_ce: 0.007227
2022-01-14 16:57:21,189 iteration 4668 : loss : 0.012173, loss_ce: 0.005218
2022-01-14 16:57:22,715 iteration 4669 : loss : 0.018894, loss_ce: 0.006236
2022-01-14 16:57:24,207 iteration 4670 : loss : 0.027682, loss_ce: 0.007255
2022-01-14 16:57:25,650 iteration 4671 : loss : 0.015594, loss_ce: 0.005608
2022-01-14 16:57:27,085 iteration 4672 : loss : 0.012478, loss_ce: 0.004341
2022-01-14 16:57:28,469 iteration 4673 : loss : 0.013699, loss_ce: 0.004430
2022-01-14 16:57:29,963 iteration 4674 : loss : 0.018734, loss_ce: 0.004381
2022-01-14 16:57:29,963 Training Data Eval:
2022-01-14 16:57:37,309   Average segmentation loss on training set: 0.0116
2022-01-14 16:57:37,310 Validation Data Eval:
2022-01-14 16:57:39,844   Average segmentation loss on validation set: 0.1120
2022-01-14 16:57:41,238 iteration 4675 : loss : 0.013010, loss_ce: 0.004928
 69%|███████████████████▉         | 275/400 [2:05:34<59:57, 28.78s/it]2022-01-14 16:57:42,765 iteration 4676 : loss : 0.014711, loss_ce: 0.005979
2022-01-14 16:57:44,191 iteration 4677 : loss : 0.014995, loss_ce: 0.006620
2022-01-14 16:57:45,706 iteration 4678 : loss : 0.020384, loss_ce: 0.006260
2022-01-14 16:57:47,265 iteration 4679 : loss : 0.019271, loss_ce: 0.007279
2022-01-14 16:57:48,670 iteration 4680 : loss : 0.021056, loss_ce: 0.007370
2022-01-14 16:57:50,137 iteration 4681 : loss : 0.017157, loss_ce: 0.007096
2022-01-14 16:57:51,590 iteration 4682 : loss : 0.015400, loss_ce: 0.005869
2022-01-14 16:57:53,025 iteration 4683 : loss : 0.018616, loss_ce: 0.005575
2022-01-14 16:57:54,499 iteration 4684 : loss : 0.019489, loss_ce: 0.006536
2022-01-14 16:57:56,018 iteration 4685 : loss : 0.014363, loss_ce: 0.006129
2022-01-14 16:57:57,443 iteration 4686 : loss : 0.024696, loss_ce: 0.009242
2022-01-14 16:57:58,920 iteration 4687 : loss : 0.035494, loss_ce: 0.010142
2022-01-14 16:58:00,311 iteration 4688 : loss : 0.011262, loss_ce: 0.004916
2022-01-14 16:58:01,807 iteration 4689 : loss : 0.025112, loss_ce: 0.009114
2022-01-14 16:58:03,193 iteration 4690 : loss : 0.016754, loss_ce: 0.005371
2022-01-14 16:58:04,659 iteration 4691 : loss : 0.026558, loss_ce: 0.006471
2022-01-14 16:58:06,238 iteration 4692 : loss : 0.024074, loss_ce: 0.009511
 69%|████████████████████         | 276/400 [2:05:59<57:08, 27.65s/it]2022-01-14 16:58:07,746 iteration 4693 : loss : 0.014604, loss_ce: 0.005538
2022-01-14 16:58:09,207 iteration 4694 : loss : 0.016777, loss_ce: 0.004918
2022-01-14 16:58:10,711 iteration 4695 : loss : 0.016520, loss_ce: 0.005987
2022-01-14 16:58:12,212 iteration 4696 : loss : 0.019356, loss_ce: 0.006124
2022-01-14 16:58:13,640 iteration 4697 : loss : 0.018929, loss_ce: 0.008348
2022-01-14 16:58:15,074 iteration 4698 : loss : 0.014353, loss_ce: 0.005508
2022-01-14 16:58:16,531 iteration 4699 : loss : 0.020753, loss_ce: 0.005941
2022-01-14 16:58:17,999 iteration 4700 : loss : 0.020648, loss_ce: 0.007016
2022-01-14 16:58:19,450 iteration 4701 : loss : 0.018031, loss_ce: 0.004368
2022-01-14 16:58:20,977 iteration 4702 : loss : 0.034481, loss_ce: 0.011498
2022-01-14 16:58:22,467 iteration 4703 : loss : 0.028426, loss_ce: 0.015374
2022-01-14 16:58:23,968 iteration 4704 : loss : 0.028917, loss_ce: 0.007014
2022-01-14 16:58:25,469 iteration 4705 : loss : 0.023363, loss_ce: 0.006735
2022-01-14 16:58:26,869 iteration 4706 : loss : 0.013993, loss_ce: 0.005338
2022-01-14 16:58:28,317 iteration 4707 : loss : 0.021305, loss_ce: 0.006268
2022-01-14 16:58:29,784 iteration 4708 : loss : 0.016253, loss_ce: 0.007129
2022-01-14 16:58:31,233 iteration 4709 : loss : 0.023297, loss_ce: 0.010155
 69%|████████████████████         | 277/400 [2:06:24<55:02, 26.85s/it]2022-01-14 16:58:32,713 iteration 4710 : loss : 0.021508, loss_ce: 0.007623
2022-01-14 16:58:34,132 iteration 4711 : loss : 0.016664, loss_ce: 0.005339
2022-01-14 16:58:35,518 iteration 4712 : loss : 0.014092, loss_ce: 0.004715
2022-01-14 16:58:36,988 iteration 4713 : loss : 0.021436, loss_ce: 0.006260
2022-01-14 16:58:38,387 iteration 4714 : loss : 0.019619, loss_ce: 0.006968
2022-01-14 16:58:39,868 iteration 4715 : loss : 0.018805, loss_ce: 0.009298
2022-01-14 16:58:41,382 iteration 4716 : loss : 0.034713, loss_ce: 0.012619
2022-01-14 16:58:42,833 iteration 4717 : loss : 0.017557, loss_ce: 0.005904
2022-01-14 16:58:44,313 iteration 4718 : loss : 0.020689, loss_ce: 0.007676
2022-01-14 16:58:45,758 iteration 4719 : loss : 0.012378, loss_ce: 0.003970
2022-01-14 16:58:47,219 iteration 4720 : loss : 0.016118, loss_ce: 0.007570
2022-01-14 16:58:48,670 iteration 4721 : loss : 0.019676, loss_ce: 0.005546
2022-01-14 16:58:50,206 iteration 4722 : loss : 0.020783, loss_ce: 0.008206
2022-01-14 16:58:51,762 iteration 4723 : loss : 0.019033, loss_ce: 0.006595
2022-01-14 16:58:53,330 iteration 4724 : loss : 0.023315, loss_ce: 0.011978
2022-01-14 16:58:54,766 iteration 4725 : loss : 0.018632, loss_ce: 0.006449
2022-01-14 16:58:56,277 iteration 4726 : loss : 0.019640, loss_ce: 0.006513
 70%|████████████████████▏        | 278/400 [2:06:49<53:29, 26.31s/it]2022-01-14 16:58:57,810 iteration 4727 : loss : 0.021101, loss_ce: 0.008261
2022-01-14 16:58:59,308 iteration 4728 : loss : 0.013666, loss_ce: 0.004889
2022-01-14 16:59:00,753 iteration 4729 : loss : 0.018939, loss_ce: 0.005260
2022-01-14 16:59:02,239 iteration 4730 : loss : 0.016839, loss_ce: 0.006998
2022-01-14 16:59:03,715 iteration 4731 : loss : 0.022779, loss_ce: 0.006225
2022-01-14 16:59:05,201 iteration 4732 : loss : 0.016238, loss_ce: 0.005672
2022-01-14 16:59:06,621 iteration 4733 : loss : 0.016807, loss_ce: 0.006310
2022-01-14 16:59:08,035 iteration 4734 : loss : 0.012852, loss_ce: 0.004184
2022-01-14 16:59:09,576 iteration 4735 : loss : 0.024130, loss_ce: 0.013665
2022-01-14 16:59:11,078 iteration 4736 : loss : 0.028919, loss_ce: 0.012412
2022-01-14 16:59:12,643 iteration 4737 : loss : 0.024551, loss_ce: 0.007493
2022-01-14 16:59:14,182 iteration 4738 : loss : 0.033221, loss_ce: 0.005120
2022-01-14 16:59:15,643 iteration 4739 : loss : 0.015497, loss_ce: 0.006093
2022-01-14 16:59:17,053 iteration 4740 : loss : 0.014115, loss_ce: 0.005920
2022-01-14 16:59:18,543 iteration 4741 : loss : 0.022257, loss_ce: 0.013263
2022-01-14 16:59:19,941 iteration 4742 : loss : 0.013617, loss_ce: 0.004747
2022-01-14 16:59:21,421 iteration 4743 : loss : 0.011722, loss_ce: 0.003760
 70%|████████████████████▏        | 279/400 [2:07:14<52:21, 25.96s/it]2022-01-14 16:59:22,960 iteration 4744 : loss : 0.021165, loss_ce: 0.008869
2022-01-14 16:59:24,450 iteration 4745 : loss : 0.017906, loss_ce: 0.007486
2022-01-14 16:59:25,915 iteration 4746 : loss : 0.019088, loss_ce: 0.007809
2022-01-14 16:59:27,439 iteration 4747 : loss : 0.021826, loss_ce: 0.011528
2022-01-14 16:59:29,021 iteration 4748 : loss : 0.021573, loss_ce: 0.008827
2022-01-14 16:59:30,559 iteration 4749 : loss : 0.019350, loss_ce: 0.005576
2022-01-14 16:59:32,026 iteration 4750 : loss : 0.017714, loss_ce: 0.006586
2022-01-14 16:59:33,440 iteration 4751 : loss : 0.016559, loss_ce: 0.005968
2022-01-14 16:59:34,918 iteration 4752 : loss : 0.025539, loss_ce: 0.006803
2022-01-14 16:59:36,424 iteration 4753 : loss : 0.016272, loss_ce: 0.007921
2022-01-14 16:59:37,916 iteration 4754 : loss : 0.015989, loss_ce: 0.004823
2022-01-14 16:59:39,426 iteration 4755 : loss : 0.017784, loss_ce: 0.006196
2022-01-14 16:59:40,910 iteration 4756 : loss : 0.015693, loss_ce: 0.006319
2022-01-14 16:59:42,394 iteration 4757 : loss : 0.017977, loss_ce: 0.007449
2022-01-14 16:59:43,972 iteration 4758 : loss : 0.018881, loss_ce: 0.006385
2022-01-14 16:59:45,389 iteration 4759 : loss : 0.012173, loss_ce: 0.004370
2022-01-14 16:59:45,390 Training Data Eval:
2022-01-14 16:59:52,749   Average segmentation loss on training set: 0.0107
2022-01-14 16:59:52,750 Validation Data Eval:
2022-01-14 16:59:55,293   Average segmentation loss on validation set: 0.0638
2022-01-14 16:59:56,763 iteration 4760 : loss : 0.016992, loss_ce: 0.005780
 70%|████████████████████▎        | 280/400 [2:07:50<57:32, 28.77s/it]2022-01-14 16:59:58,293 iteration 4761 : loss : 0.015183, loss_ce: 0.006253
2022-01-14 16:59:59,810 iteration 4762 : loss : 0.023882, loss_ce: 0.008089
2022-01-14 17:00:01,302 iteration 4763 : loss : 0.018148, loss_ce: 0.005670
2022-01-14 17:00:02,884 iteration 4764 : loss : 0.014161, loss_ce: 0.004264
2022-01-14 17:00:04,417 iteration 4765 : loss : 0.015711, loss_ce: 0.006022
2022-01-14 17:00:06,007 iteration 4766 : loss : 0.018168, loss_ce: 0.004801
2022-01-14 17:00:07,603 iteration 4767 : loss : 0.037435, loss_ce: 0.021208
2022-01-14 17:00:09,113 iteration 4768 : loss : 0.024031, loss_ce: 0.010278
2022-01-14 17:00:10,527 iteration 4769 : loss : 0.012914, loss_ce: 0.004548
2022-01-14 17:00:12,055 iteration 4770 : loss : 0.025138, loss_ce: 0.012869
2022-01-14 17:00:13,521 iteration 4771 : loss : 0.028351, loss_ce: 0.009676
2022-01-14 17:00:14,962 iteration 4772 : loss : 0.016456, loss_ce: 0.006487
2022-01-14 17:00:16,370 iteration 4773 : loss : 0.013999, loss_ce: 0.006497
2022-01-14 17:00:17,881 iteration 4774 : loss : 0.022778, loss_ce: 0.008156
2022-01-14 17:00:19,290 iteration 4775 : loss : 0.014857, loss_ce: 0.005661
2022-01-14 17:00:20,759 iteration 4776 : loss : 0.017148, loss_ce: 0.005629
2022-01-14 17:00:22,219 iteration 4777 : loss : 0.017268, loss_ce: 0.005983
 70%|████████████████████▎        | 281/400 [2:08:15<55:05, 27.78s/it]2022-01-14 17:00:23,750 iteration 4778 : loss : 0.019816, loss_ce: 0.009197
2022-01-14 17:00:25,188 iteration 4779 : loss : 0.014094, loss_ce: 0.005477
2022-01-14 17:00:26,623 iteration 4780 : loss : 0.018497, loss_ce: 0.007798
2022-01-14 17:00:28,130 iteration 4781 : loss : 0.033655, loss_ce: 0.011794
2022-01-14 17:00:29,651 iteration 4782 : loss : 0.022699, loss_ce: 0.008694
2022-01-14 17:00:31,117 iteration 4783 : loss : 0.021406, loss_ce: 0.010161
2022-01-14 17:00:32,650 iteration 4784 : loss : 0.024333, loss_ce: 0.007136
2022-01-14 17:00:34,125 iteration 4785 : loss : 0.016069, loss_ce: 0.005385
2022-01-14 17:00:35,587 iteration 4786 : loss : 0.013666, loss_ce: 0.005124
2022-01-14 17:00:37,050 iteration 4787 : loss : 0.024254, loss_ce: 0.008783
2022-01-14 17:00:38,549 iteration 4788 : loss : 0.020327, loss_ce: 0.004844
2022-01-14 17:00:39,924 iteration 4789 : loss : 0.013765, loss_ce: 0.004975
2022-01-14 17:00:41,294 iteration 4790 : loss : 0.012872, loss_ce: 0.004484
2022-01-14 17:00:42,784 iteration 4791 : loss : 0.024761, loss_ce: 0.010744
2022-01-14 17:00:44,270 iteration 4792 : loss : 0.020950, loss_ce: 0.007606
2022-01-14 17:00:45,809 iteration 4793 : loss : 0.024949, loss_ce: 0.008732
2022-01-14 17:00:47,270 iteration 4794 : loss : 0.018403, loss_ce: 0.005155
 70%|████████████████████▍        | 282/400 [2:08:40<53:01, 26.96s/it]2022-01-14 17:00:48,821 iteration 4795 : loss : 0.049955, loss_ce: 0.019125
2022-01-14 17:00:50,332 iteration 4796 : loss : 0.019935, loss_ce: 0.005297
2022-01-14 17:00:51,818 iteration 4797 : loss : 0.015728, loss_ce: 0.005646
2022-01-14 17:00:53,327 iteration 4798 : loss : 0.023899, loss_ce: 0.010799
2022-01-14 17:00:54,794 iteration 4799 : loss : 0.014914, loss_ce: 0.003686
2022-01-14 17:00:56,292 iteration 4800 : loss : 0.018379, loss_ce: 0.006947
2022-01-14 17:00:57,746 iteration 4801 : loss : 0.016791, loss_ce: 0.007240
2022-01-14 17:00:59,265 iteration 4802 : loss : 0.017468, loss_ce: 0.007381
2022-01-14 17:01:00,736 iteration 4803 : loss : 0.013683, loss_ce: 0.005295
2022-01-14 17:01:02,239 iteration 4804 : loss : 0.015997, loss_ce: 0.005954
2022-01-14 17:01:03,810 iteration 4805 : loss : 0.020147, loss_ce: 0.007460
2022-01-14 17:01:05,329 iteration 4806 : loss : 0.022576, loss_ce: 0.004592
2022-01-14 17:01:06,753 iteration 4807 : loss : 0.016993, loss_ce: 0.004533
2022-01-14 17:01:08,284 iteration 4808 : loss : 0.016930, loss_ce: 0.006471
2022-01-14 17:01:09,714 iteration 4809 : loss : 0.019318, loss_ce: 0.008523
2022-01-14 17:01:11,189 iteration 4810 : loss : 0.025759, loss_ce: 0.008922
2022-01-14 17:01:12,702 iteration 4811 : loss : 0.021217, loss_ce: 0.008779
 71%|████████████████████▌        | 283/400 [2:09:05<51:40, 26.50s/it]2022-01-14 17:01:14,215 iteration 4812 : loss : 0.016885, loss_ce: 0.005910
2022-01-14 17:01:15,652 iteration 4813 : loss : 0.014141, loss_ce: 0.005302
2022-01-14 17:01:17,259 iteration 4814 : loss : 0.029832, loss_ce: 0.010636
2022-01-14 17:01:18,721 iteration 4815 : loss : 0.013938, loss_ce: 0.004930
2022-01-14 17:01:20,148 iteration 4816 : loss : 0.017422, loss_ce: 0.006503
2022-01-14 17:01:21,565 iteration 4817 : loss : 0.012780, loss_ce: 0.004731
2022-01-14 17:01:23,002 iteration 4818 : loss : 0.019044, loss_ce: 0.007929
2022-01-14 17:01:24,498 iteration 4819 : loss : 0.024694, loss_ce: 0.006970
2022-01-14 17:01:25,928 iteration 4820 : loss : 0.017919, loss_ce: 0.008037
2022-01-14 17:01:27,403 iteration 4821 : loss : 0.016006, loss_ce: 0.005627
2022-01-14 17:01:28,932 iteration 4822 : loss : 0.019661, loss_ce: 0.007282
2022-01-14 17:01:30,448 iteration 4823 : loss : 0.022871, loss_ce: 0.004982
2022-01-14 17:01:31,926 iteration 4824 : loss : 0.024261, loss_ce: 0.006888
2022-01-14 17:01:33,493 iteration 4825 : loss : 0.018976, loss_ce: 0.008890
2022-01-14 17:01:35,219 iteration 4826 : loss : 0.023993, loss_ce: 0.011238
2022-01-14 17:01:36,667 iteration 4827 : loss : 0.019643, loss_ce: 0.009887
2022-01-14 17:01:38,093 iteration 4828 : loss : 0.013295, loss_ce: 0.004881
 71%|████████████████████▌        | 284/400 [2:09:31<50:35, 26.17s/it]2022-01-14 17:01:39,583 iteration 4829 : loss : 0.019550, loss_ce: 0.013248
2022-01-14 17:01:41,107 iteration 4830 : loss : 0.016025, loss_ce: 0.006805
2022-01-14 17:01:42,615 iteration 4831 : loss : 0.017647, loss_ce: 0.008695
2022-01-14 17:01:44,129 iteration 4832 : loss : 0.016035, loss_ce: 0.005763
2022-01-14 17:01:45,598 iteration 4833 : loss : 0.013955, loss_ce: 0.006626
2022-01-14 17:01:47,152 iteration 4834 : loss : 0.032655, loss_ce: 0.014877
2022-01-14 17:01:48,614 iteration 4835 : loss : 0.019818, loss_ce: 0.007831
2022-01-14 17:01:50,055 iteration 4836 : loss : 0.019269, loss_ce: 0.006046
2022-01-14 17:01:51,544 iteration 4837 : loss : 0.013734, loss_ce: 0.003756
2022-01-14 17:01:53,042 iteration 4838 : loss : 0.016932, loss_ce: 0.007184
2022-01-14 17:01:54,421 iteration 4839 : loss : 0.016010, loss_ce: 0.006461
2022-01-14 17:01:55,870 iteration 4840 : loss : 0.016499, loss_ce: 0.005995
2022-01-14 17:01:57,383 iteration 4841 : loss : 0.016499, loss_ce: 0.005938
2022-01-14 17:01:58,879 iteration 4842 : loss : 0.025005, loss_ce: 0.011250
2022-01-14 17:02:00,339 iteration 4843 : loss : 0.014744, loss_ce: 0.004389
2022-01-14 17:02:01,870 iteration 4844 : loss : 0.020168, loss_ce: 0.005051
2022-01-14 17:02:01,870 Training Data Eval:
2022-01-14 17:02:09,237   Average segmentation loss on training set: 0.0109
2022-01-14 17:02:09,238 Validation Data Eval:
2022-01-14 17:02:11,783   Average segmentation loss on validation set: 0.0629
2022-01-14 17:02:13,208 iteration 4845 : loss : 0.016990, loss_ce: 0.006092
 71%|████████████████████▋        | 285/400 [2:10:06<55:18, 28.85s/it]2022-01-14 17:02:14,729 iteration 4846 : loss : 0.019206, loss_ce: 0.008431
2022-01-14 17:02:16,144 iteration 4847 : loss : 0.013460, loss_ce: 0.004212
2022-01-14 17:02:17,708 iteration 4848 : loss : 0.015844, loss_ce: 0.006589
2022-01-14 17:02:19,154 iteration 4849 : loss : 0.014341, loss_ce: 0.004467
2022-01-14 17:02:20,553 iteration 4850 : loss : 0.012466, loss_ce: 0.006114
2022-01-14 17:02:22,125 iteration 4851 : loss : 0.019054, loss_ce: 0.006162
2022-01-14 17:02:23,590 iteration 4852 : loss : 0.014814, loss_ce: 0.007039
2022-01-14 17:02:25,096 iteration 4853 : loss : 0.024652, loss_ce: 0.005793
2022-01-14 17:02:26,715 iteration 4854 : loss : 0.020419, loss_ce: 0.007431
2022-01-14 17:02:28,214 iteration 4855 : loss : 0.019961, loss_ce: 0.006899
2022-01-14 17:02:29,626 iteration 4856 : loss : 0.013223, loss_ce: 0.004099
2022-01-14 17:02:31,157 iteration 4857 : loss : 0.014396, loss_ce: 0.006502
2022-01-14 17:02:32,668 iteration 4858 : loss : 0.021254, loss_ce: 0.007934
2022-01-14 17:02:34,151 iteration 4859 : loss : 0.012938, loss_ce: 0.005630
2022-01-14 17:02:35,663 iteration 4860 : loss : 0.025184, loss_ce: 0.008821
2022-01-14 17:02:37,141 iteration 4861 : loss : 0.017267, loss_ce: 0.006396
2022-01-14 17:02:38,562 iteration 4862 : loss : 0.012689, loss_ce: 0.005174
 72%|████████████████████▋        | 286/400 [2:10:31<52:49, 27.80s/it]2022-01-14 17:02:40,036 iteration 4863 : loss : 0.014310, loss_ce: 0.004644
2022-01-14 17:02:41,563 iteration 4864 : loss : 0.021893, loss_ce: 0.007717
2022-01-14 17:02:43,129 iteration 4865 : loss : 0.023413, loss_ce: 0.006714
2022-01-14 17:02:44,592 iteration 4866 : loss : 0.012904, loss_ce: 0.005130
2022-01-14 17:02:46,074 iteration 4867 : loss : 0.028948, loss_ce: 0.014290
2022-01-14 17:02:47,517 iteration 4868 : loss : 0.017345, loss_ce: 0.008134
2022-01-14 17:02:48,962 iteration 4869 : loss : 0.015731, loss_ce: 0.005997
2022-01-14 17:02:50,530 iteration 4870 : loss : 0.017928, loss_ce: 0.005402
2022-01-14 17:02:52,051 iteration 4871 : loss : 0.020584, loss_ce: 0.007015
2022-01-14 17:02:53,469 iteration 4872 : loss : 0.015474, loss_ce: 0.005868
2022-01-14 17:02:54,863 iteration 4873 : loss : 0.014240, loss_ce: 0.004722
2022-01-14 17:02:56,241 iteration 4874 : loss : 0.011687, loss_ce: 0.005159
2022-01-14 17:02:57,707 iteration 4875 : loss : 0.013205, loss_ce: 0.004252
2022-01-14 17:02:59,114 iteration 4876 : loss : 0.018281, loss_ce: 0.005835
2022-01-14 17:03:00,687 iteration 4877 : loss : 0.021121, loss_ce: 0.009328
2022-01-14 17:03:02,157 iteration 4878 : loss : 0.023243, loss_ce: 0.008485
2022-01-14 17:03:03,623 iteration 4879 : loss : 0.017772, loss_ce: 0.006710
 72%|████████████████████▊        | 287/400 [2:10:56<50:48, 26.98s/it]2022-01-14 17:03:05,211 iteration 4880 : loss : 0.020684, loss_ce: 0.012160
2022-01-14 17:03:06,660 iteration 4881 : loss : 0.024184, loss_ce: 0.009167
2022-01-14 17:03:08,127 iteration 4882 : loss : 0.012502, loss_ce: 0.003363
2022-01-14 17:03:09,610 iteration 4883 : loss : 0.018819, loss_ce: 0.005691
2022-01-14 17:03:11,099 iteration 4884 : loss : 0.011512, loss_ce: 0.006386
2022-01-14 17:03:12,712 iteration 4885 : loss : 0.019471, loss_ce: 0.005744
2022-01-14 17:03:14,249 iteration 4886 : loss : 0.020157, loss_ce: 0.007056
2022-01-14 17:03:15,806 iteration 4887 : loss : 0.029553, loss_ce: 0.011926
2022-01-14 17:03:17,277 iteration 4888 : loss : 0.016278, loss_ce: 0.004935
2022-01-14 17:03:18,741 iteration 4889 : loss : 0.013890, loss_ce: 0.004693
2022-01-14 17:03:20,282 iteration 4890 : loss : 0.020339, loss_ce: 0.007213
2022-01-14 17:03:21,826 iteration 4891 : loss : 0.036915, loss_ce: 0.022179
2022-01-14 17:03:23,244 iteration 4892 : loss : 0.016374, loss_ce: 0.006458
2022-01-14 17:03:24,689 iteration 4893 : loss : 0.016166, loss_ce: 0.007537
2022-01-14 17:03:26,173 iteration 4894 : loss : 0.019455, loss_ce: 0.004229
2022-01-14 17:03:27,608 iteration 4895 : loss : 0.015219, loss_ce: 0.005699
2022-01-14 17:03:29,097 iteration 4896 : loss : 0.018346, loss_ce: 0.006598
 72%|████████████████████▉        | 288/400 [2:11:22<49:30, 26.53s/it]2022-01-14 17:03:30,597 iteration 4897 : loss : 0.018188, loss_ce: 0.006722
2022-01-14 17:03:32,107 iteration 4898 : loss : 0.047161, loss_ce: 0.011698
2022-01-14 17:03:33,449 iteration 4899 : loss : 0.015043, loss_ce: 0.006251
2022-01-14 17:03:35,014 iteration 4900 : loss : 0.021848, loss_ce: 0.007621
2022-01-14 17:03:36,465 iteration 4901 : loss : 0.013134, loss_ce: 0.003274
2022-01-14 17:03:38,002 iteration 4902 : loss : 0.030354, loss_ce: 0.012800
2022-01-14 17:03:39,576 iteration 4903 : loss : 0.028318, loss_ce: 0.011255
2022-01-14 17:03:41,128 iteration 4904 : loss : 0.029530, loss_ce: 0.013835
2022-01-14 17:03:42,637 iteration 4905 : loss : 0.038276, loss_ce: 0.009247
2022-01-14 17:03:44,143 iteration 4906 : loss : 0.024039, loss_ce: 0.009219
2022-01-14 17:03:45,529 iteration 4907 : loss : 0.013329, loss_ce: 0.005175
2022-01-14 17:03:46,960 iteration 4908 : loss : 0.016894, loss_ce: 0.006539
2022-01-14 17:03:48,434 iteration 4909 : loss : 0.018471, loss_ce: 0.006616
2022-01-14 17:03:49,904 iteration 4910 : loss : 0.016872, loss_ce: 0.006083
2022-01-14 17:03:51,335 iteration 4911 : loss : 0.017314, loss_ce: 0.005295
2022-01-14 17:03:52,849 iteration 4912 : loss : 0.037476, loss_ce: 0.011983
2022-01-14 17:03:54,325 iteration 4913 : loss : 0.023454, loss_ce: 0.007630
 72%|████████████████████▉        | 289/400 [2:11:47<48:21, 26.14s/it]2022-01-14 17:03:55,784 iteration 4914 : loss : 0.016697, loss_ce: 0.006891
2022-01-14 17:03:57,262 iteration 4915 : loss : 0.015558, loss_ce: 0.007283
2022-01-14 17:03:58,790 iteration 4916 : loss : 0.026299, loss_ce: 0.007983
2022-01-14 17:04:00,294 iteration 4917 : loss : 0.018559, loss_ce: 0.005730
2022-01-14 17:04:01,796 iteration 4918 : loss : 0.018547, loss_ce: 0.007747
2022-01-14 17:04:03,259 iteration 4919 : loss : 0.015129, loss_ce: 0.006497
2022-01-14 17:04:04,805 iteration 4920 : loss : 0.020255, loss_ce: 0.008350
2022-01-14 17:04:06,221 iteration 4921 : loss : 0.017117, loss_ce: 0.006052
2022-01-14 17:04:07,734 iteration 4922 : loss : 0.018116, loss_ce: 0.005859
2022-01-14 17:04:09,220 iteration 4923 : loss : 0.019464, loss_ce: 0.007692
2022-01-14 17:04:10,722 iteration 4924 : loss : 0.018570, loss_ce: 0.007827
2022-01-14 17:04:12,178 iteration 4925 : loss : 0.020384, loss_ce: 0.006977
2022-01-14 17:04:13,556 iteration 4926 : loss : 0.013680, loss_ce: 0.006260
2022-01-14 17:04:15,027 iteration 4927 : loss : 0.014726, loss_ce: 0.005465
2022-01-14 17:04:16,526 iteration 4928 : loss : 0.016204, loss_ce: 0.007023
2022-01-14 17:04:17,950 iteration 4929 : loss : 0.022516, loss_ce: 0.006248
2022-01-14 17:04:17,951 Training Data Eval:
2022-01-14 17:04:25,314   Average segmentation loss on training set: 0.0112
2022-01-14 17:04:25,315 Validation Data Eval:
2022-01-14 17:04:27,856   Average segmentation loss on validation set: 0.0822
2022-01-14 17:04:29,335 iteration 4930 : loss : 0.021048, loss_ce: 0.005791
 72%|█████████████████████        | 290/400 [2:12:22<52:48, 28.80s/it]2022-01-14 17:04:30,897 iteration 4931 : loss : 0.019931, loss_ce: 0.009576
2022-01-14 17:04:32,409 iteration 4932 : loss : 0.019340, loss_ce: 0.005448
2022-01-14 17:04:33,823 iteration 4933 : loss : 0.016896, loss_ce: 0.006740
2022-01-14 17:04:35,300 iteration 4934 : loss : 0.020132, loss_ce: 0.008256
2022-01-14 17:04:36,754 iteration 4935 : loss : 0.013568, loss_ce: 0.003698
2022-01-14 17:04:38,253 iteration 4936 : loss : 0.020443, loss_ce: 0.006952
2022-01-14 17:04:39,706 iteration 4937 : loss : 0.024029, loss_ce: 0.011725
2022-01-14 17:04:41,127 iteration 4938 : loss : 0.016157, loss_ce: 0.006470
2022-01-14 17:04:42,704 iteration 4939 : loss : 0.021482, loss_ce: 0.008889
2022-01-14 17:04:44,157 iteration 4940 : loss : 0.016924, loss_ce: 0.006499
2022-01-14 17:04:45,648 iteration 4941 : loss : 0.023355, loss_ce: 0.011489
2022-01-14 17:04:47,299 iteration 4942 : loss : 0.019918, loss_ce: 0.009355
2022-01-14 17:04:48,753 iteration 4943 : loss : 0.016343, loss_ce: 0.006462
2022-01-14 17:04:50,200 iteration 4944 : loss : 0.016415, loss_ce: 0.007952
2022-01-14 17:04:51,669 iteration 4945 : loss : 0.012884, loss_ce: 0.004715
2022-01-14 17:04:53,075 iteration 4946 : loss : 0.015668, loss_ce: 0.006358
2022-01-14 17:04:54,612 iteration 4947 : loss : 0.025857, loss_ce: 0.010553
 73%|█████████████████████        | 291/400 [2:12:47<50:23, 27.74s/it]2022-01-14 17:04:56,160 iteration 4948 : loss : 0.019454, loss_ce: 0.007015
2022-01-14 17:04:57,747 iteration 4949 : loss : 0.034872, loss_ce: 0.014296
2022-01-14 17:04:59,187 iteration 4950 : loss : 0.021400, loss_ce: 0.010764
2022-01-14 17:05:00,659 iteration 4951 : loss : 0.023928, loss_ce: 0.008991
2022-01-14 17:05:02,130 iteration 4952 : loss : 0.016274, loss_ce: 0.006114
2022-01-14 17:05:03,684 iteration 4953 : loss : 0.019048, loss_ce: 0.005016
2022-01-14 17:05:05,074 iteration 4954 : loss : 0.017303, loss_ce: 0.005583
2022-01-14 17:05:06,500 iteration 4955 : loss : 0.014610, loss_ce: 0.006983
2022-01-14 17:05:08,013 iteration 4956 : loss : 0.020310, loss_ce: 0.005684
2022-01-14 17:05:09,497 iteration 4957 : loss : 0.021972, loss_ce: 0.008586
2022-01-14 17:05:11,131 iteration 4958 : loss : 0.020905, loss_ce: 0.008684
2022-01-14 17:05:12,694 iteration 4959 : loss : 0.017840, loss_ce: 0.006760
2022-01-14 17:05:14,302 iteration 4960 : loss : 0.016287, loss_ce: 0.007239
2022-01-14 17:05:15,769 iteration 4961 : loss : 0.018950, loss_ce: 0.004310
2022-01-14 17:05:17,257 iteration 4962 : loss : 0.014536, loss_ce: 0.006288
2022-01-14 17:05:18,782 iteration 4963 : loss : 0.020962, loss_ce: 0.009234
2022-01-14 17:05:20,309 iteration 4964 : loss : 0.012913, loss_ce: 0.004088
 73%|█████████████████████▏       | 292/400 [2:13:13<48:49, 27.13s/it]2022-01-14 17:05:21,804 iteration 4965 : loss : 0.017840, loss_ce: 0.005512
2022-01-14 17:05:23,289 iteration 4966 : loss : 0.016332, loss_ce: 0.006177
2022-01-14 17:05:24,775 iteration 4967 : loss : 0.024414, loss_ce: 0.006332
2022-01-14 17:05:26,245 iteration 4968 : loss : 0.020435, loss_ce: 0.006068
2022-01-14 17:05:27,743 iteration 4969 : loss : 0.040151, loss_ce: 0.014782
2022-01-14 17:05:29,259 iteration 4970 : loss : 0.016114, loss_ce: 0.008708
2022-01-14 17:05:30,718 iteration 4971 : loss : 0.016169, loss_ce: 0.006372
2022-01-14 17:05:32,145 iteration 4972 : loss : 0.017921, loss_ce: 0.005363
2022-01-14 17:05:33,599 iteration 4973 : loss : 0.014768, loss_ce: 0.004684
2022-01-14 17:05:35,095 iteration 4974 : loss : 0.019539, loss_ce: 0.009938
2022-01-14 17:05:36,689 iteration 4975 : loss : 0.020766, loss_ce: 0.006909
2022-01-14 17:05:38,136 iteration 4976 : loss : 0.018643, loss_ce: 0.006511
2022-01-14 17:05:39,600 iteration 4977 : loss : 0.014132, loss_ce: 0.005928
2022-01-14 17:05:41,086 iteration 4978 : loss : 0.020295, loss_ce: 0.007900
2022-01-14 17:05:42,520 iteration 4979 : loss : 0.014734, loss_ce: 0.005150
2022-01-14 17:05:43,926 iteration 4980 : loss : 0.012511, loss_ce: 0.004043
2022-01-14 17:05:45,390 iteration 4981 : loss : 0.016539, loss_ce: 0.005968
 73%|█████████████████████▏       | 293/400 [2:13:38<47:17, 26.52s/it]2022-01-14 17:05:46,935 iteration 4982 : loss : 0.024612, loss_ce: 0.005394
2022-01-14 17:05:48,333 iteration 4983 : loss : 0.015679, loss_ce: 0.005114
2022-01-14 17:05:49,820 iteration 4984 : loss : 0.022116, loss_ce: 0.006306
2022-01-14 17:05:51,220 iteration 4985 : loss : 0.013512, loss_ce: 0.005412
2022-01-14 17:05:52,647 iteration 4986 : loss : 0.015341, loss_ce: 0.005384
2022-01-14 17:05:54,124 iteration 4987 : loss : 0.020104, loss_ce: 0.011569
2022-01-14 17:05:55,616 iteration 4988 : loss : 0.017982, loss_ce: 0.008979
2022-01-14 17:05:57,067 iteration 4989 : loss : 0.016871, loss_ce: 0.008484
2022-01-14 17:05:58,576 iteration 4990 : loss : 0.014573, loss_ce: 0.006154
2022-01-14 17:06:00,028 iteration 4991 : loss : 0.019176, loss_ce: 0.005851
2022-01-14 17:06:01,512 iteration 4992 : loss : 0.021150, loss_ce: 0.006634
2022-01-14 17:06:02,984 iteration 4993 : loss : 0.018029, loss_ce: 0.007747
2022-01-14 17:06:04,591 iteration 4994 : loss : 0.021844, loss_ce: 0.009268
2022-01-14 17:06:06,129 iteration 4995 : loss : 0.022488, loss_ce: 0.011341
2022-01-14 17:06:07,565 iteration 4996 : loss : 0.019288, loss_ce: 0.005078
2022-01-14 17:06:09,058 iteration 4997 : loss : 0.019011, loss_ce: 0.007445
2022-01-14 17:06:10,548 iteration 4998 : loss : 0.015669, loss_ce: 0.006365
 74%|█████████████████████▎       | 294/400 [2:14:03<46:07, 26.11s/it]2022-01-14 17:06:12,099 iteration 4999 : loss : 0.015517, loss_ce: 0.006463
2022-01-14 17:06:13,531 iteration 5000 : loss : 0.015677, loss_ce: 0.004409
2022-01-14 17:06:15,085 iteration 5001 : loss : 0.017908, loss_ce: 0.004733
2022-01-14 17:06:16,697 iteration 5002 : loss : 0.018248, loss_ce: 0.006167
2022-01-14 17:06:18,280 iteration 5003 : loss : 0.020325, loss_ce: 0.008682
2022-01-14 17:06:19,754 iteration 5004 : loss : 0.016288, loss_ce: 0.007405
2022-01-14 17:06:21,255 iteration 5005 : loss : 0.022217, loss_ce: 0.008793
2022-01-14 17:06:22,681 iteration 5006 : loss : 0.012880, loss_ce: 0.004815
2022-01-14 17:06:24,187 iteration 5007 : loss : 0.019919, loss_ce: 0.004595
2022-01-14 17:06:25,613 iteration 5008 : loss : 0.014003, loss_ce: 0.004921
2022-01-14 17:06:27,037 iteration 5009 : loss : 0.013049, loss_ce: 0.006252
2022-01-14 17:06:28,552 iteration 5010 : loss : 0.014519, loss_ce: 0.006960
2022-01-14 17:06:29,977 iteration 5011 : loss : 0.012739, loss_ce: 0.004964
2022-01-14 17:06:31,426 iteration 5012 : loss : 0.019003, loss_ce: 0.006332
2022-01-14 17:06:32,982 iteration 5013 : loss : 0.017303, loss_ce: 0.007019
2022-01-14 17:06:34,389 iteration 5014 : loss : 0.015348, loss_ce: 0.005661
2022-01-14 17:06:34,390 Training Data Eval:
2022-01-14 17:06:41,757   Average segmentation loss on training set: 0.0102
2022-01-14 17:06:41,757 Validation Data Eval:
2022-01-14 17:06:44,299   Average segmentation loss on validation set: 0.0715
2022-01-14 17:06:45,755 iteration 5015 : loss : 0.022192, loss_ce: 0.006246
 74%|█████████████████████▍       | 295/400 [2:14:39<50:27, 28.84s/it]2022-01-14 17:06:47,302 iteration 5016 : loss : 0.022046, loss_ce: 0.008850
2022-01-14 17:06:48,682 iteration 5017 : loss : 0.013476, loss_ce: 0.004874
2022-01-14 17:06:50,253 iteration 5018 : loss : 0.017839, loss_ce: 0.007364
2022-01-14 17:06:51,660 iteration 5019 : loss : 0.013282, loss_ce: 0.004720
2022-01-14 17:06:53,185 iteration 5020 : loss : 0.019951, loss_ce: 0.006538
2022-01-14 17:06:54,652 iteration 5021 : loss : 0.017219, loss_ce: 0.006275
2022-01-14 17:06:56,116 iteration 5022 : loss : 0.015668, loss_ce: 0.004760
2022-01-14 17:06:57,588 iteration 5023 : loss : 0.019083, loss_ce: 0.008154
2022-01-14 17:06:59,130 iteration 5024 : loss : 0.024436, loss_ce: 0.009798
2022-01-14 17:07:00,616 iteration 5025 : loss : 0.017929, loss_ce: 0.006073
2022-01-14 17:07:02,149 iteration 5026 : loss : 0.017486, loss_ce: 0.006006
2022-01-14 17:07:03,581 iteration 5027 : loss : 0.012690, loss_ce: 0.004724
2022-01-14 17:07:04,984 iteration 5028 : loss : 0.012759, loss_ce: 0.005400
2022-01-14 17:07:06,509 iteration 5029 : loss : 0.019543, loss_ce: 0.008693
2022-01-14 17:07:07,956 iteration 5030 : loss : 0.014143, loss_ce: 0.005984
2022-01-14 17:07:09,477 iteration 5031 : loss : 0.030468, loss_ce: 0.011288
2022-01-14 17:07:10,883 iteration 5032 : loss : 0.013797, loss_ce: 0.005069
 74%|█████████████████████▍       | 296/400 [2:15:04<48:03, 27.72s/it]2022-01-14 17:07:12,339 iteration 5033 : loss : 0.017314, loss_ce: 0.006616
2022-01-14 17:07:13,761 iteration 5034 : loss : 0.016020, loss_ce: 0.005063
2022-01-14 17:07:15,220 iteration 5035 : loss : 0.015431, loss_ce: 0.004994
2022-01-14 17:07:16,644 iteration 5036 : loss : 0.023561, loss_ce: 0.009116
2022-01-14 17:07:18,103 iteration 5037 : loss : 0.014430, loss_ce: 0.004636
2022-01-14 17:07:19,541 iteration 5038 : loss : 0.013655, loss_ce: 0.004235
2022-01-14 17:07:21,026 iteration 5039 : loss : 0.018896, loss_ce: 0.007207
2022-01-14 17:07:22,540 iteration 5040 : loss : 0.010712, loss_ce: 0.004021
2022-01-14 17:07:24,003 iteration 5041 : loss : 0.014221, loss_ce: 0.005658
2022-01-14 17:07:25,574 iteration 5042 : loss : 0.020576, loss_ce: 0.007471
2022-01-14 17:07:26,953 iteration 5043 : loss : 0.017450, loss_ce: 0.005764
2022-01-14 17:07:28,466 iteration 5044 : loss : 0.013758, loss_ce: 0.004912
2022-01-14 17:07:29,961 iteration 5045 : loss : 0.022762, loss_ce: 0.009750
2022-01-14 17:07:31,443 iteration 5046 : loss : 0.032172, loss_ce: 0.007392
2022-01-14 17:07:32,859 iteration 5047 : loss : 0.012793, loss_ce: 0.003259
2022-01-14 17:07:34,260 iteration 5048 : loss : 0.010654, loss_ce: 0.005024
2022-01-14 17:07:35,647 iteration 5049 : loss : 0.012268, loss_ce: 0.005201
 74%|█████████████████████▌       | 297/400 [2:15:28<46:04, 26.84s/it]2022-01-14 17:07:37,190 iteration 5050 : loss : 0.014785, loss_ce: 0.004690
2022-01-14 17:07:38,731 iteration 5051 : loss : 0.024813, loss_ce: 0.008273
2022-01-14 17:07:40,302 iteration 5052 : loss : 0.017739, loss_ce: 0.006284
2022-01-14 17:07:41,862 iteration 5053 : loss : 0.023957, loss_ce: 0.008610
2022-01-14 17:07:43,319 iteration 5054 : loss : 0.017736, loss_ce: 0.003749
2022-01-14 17:07:44,815 iteration 5055 : loss : 0.023132, loss_ce: 0.008986
2022-01-14 17:07:46,319 iteration 5056 : loss : 0.018395, loss_ce: 0.007410
2022-01-14 17:07:47,886 iteration 5057 : loss : 0.020125, loss_ce: 0.008205
2022-01-14 17:07:49,454 iteration 5058 : loss : 0.022825, loss_ce: 0.009027
2022-01-14 17:07:50,930 iteration 5059 : loss : 0.017413, loss_ce: 0.007277
2022-01-14 17:07:52,460 iteration 5060 : loss : 0.019308, loss_ce: 0.007857
2022-01-14 17:07:54,005 iteration 5061 : loss : 0.023561, loss_ce: 0.008297
2022-01-14 17:07:55,585 iteration 5062 : loss : 0.024623, loss_ce: 0.008651
2022-01-14 17:07:57,156 iteration 5063 : loss : 0.024353, loss_ce: 0.009485
2022-01-14 17:07:58,627 iteration 5064 : loss : 0.017878, loss_ce: 0.006147
2022-01-14 17:08:00,170 iteration 5065 : loss : 0.013761, loss_ce: 0.006495
2022-01-14 17:08:01,600 iteration 5066 : loss : 0.015060, loss_ce: 0.005656
 74%|█████████████████████▌       | 298/400 [2:15:54<45:10, 26.57s/it]2022-01-14 17:08:03,001 iteration 5067 : loss : 0.017103, loss_ce: 0.005840
2022-01-14 17:08:04,522 iteration 5068 : loss : 0.019412, loss_ce: 0.006223
2022-01-14 17:08:06,022 iteration 5069 : loss : 0.016079, loss_ce: 0.007906
2022-01-14 17:08:07,448 iteration 5070 : loss : 0.016923, loss_ce: 0.005536
2022-01-14 17:08:08,961 iteration 5071 : loss : 0.028346, loss_ce: 0.018654
2022-01-14 17:08:10,363 iteration 5072 : loss : 0.013372, loss_ce: 0.004913
2022-01-14 17:08:11,901 iteration 5073 : loss : 0.019250, loss_ce: 0.008682
2022-01-14 17:08:13,350 iteration 5074 : loss : 0.026400, loss_ce: 0.012699
2022-01-14 17:08:14,803 iteration 5075 : loss : 0.015637, loss_ce: 0.005869
2022-01-14 17:08:16,298 iteration 5076 : loss : 0.019270, loss_ce: 0.003871
2022-01-14 17:08:17,783 iteration 5077 : loss : 0.018228, loss_ce: 0.005949
2022-01-14 17:08:19,213 iteration 5078 : loss : 0.016626, loss_ce: 0.008219
2022-01-14 17:08:20,623 iteration 5079 : loss : 0.013627, loss_ce: 0.005699
2022-01-14 17:08:22,054 iteration 5080 : loss : 0.016831, loss_ce: 0.005994
2022-01-14 17:08:23,558 iteration 5081 : loss : 0.017283, loss_ce: 0.005118
2022-01-14 17:08:25,010 iteration 5082 : loss : 0.016161, loss_ce: 0.005882
2022-01-14 17:08:26,500 iteration 5083 : loss : 0.022142, loss_ce: 0.004447
 75%|█████████████████████▋       | 299/400 [2:16:19<43:52, 26.07s/it]2022-01-14 17:08:28,051 iteration 5084 : loss : 0.016443, loss_ce: 0.007642
2022-01-14 17:08:29,614 iteration 5085 : loss : 0.023525, loss_ce: 0.007271
2022-01-14 17:08:31,136 iteration 5086 : loss : 0.013725, loss_ce: 0.004416
2022-01-14 17:08:32,555 iteration 5087 : loss : 0.018107, loss_ce: 0.007675
2022-01-14 17:08:33,980 iteration 5088 : loss : 0.017538, loss_ce: 0.007520
2022-01-14 17:08:35,477 iteration 5089 : loss : 0.019602, loss_ce: 0.005821
2022-01-14 17:08:36,962 iteration 5090 : loss : 0.014838, loss_ce: 0.003183
2022-01-14 17:08:38,509 iteration 5091 : loss : 0.022580, loss_ce: 0.006889
2022-01-14 17:08:40,006 iteration 5092 : loss : 0.018011, loss_ce: 0.006879
2022-01-14 17:08:41,449 iteration 5093 : loss : 0.016177, loss_ce: 0.004822
2022-01-14 17:08:42,985 iteration 5094 : loss : 0.020551, loss_ce: 0.008116
2022-01-14 17:08:44,409 iteration 5095 : loss : 0.015310, loss_ce: 0.005936
2022-01-14 17:08:45,877 iteration 5096 : loss : 0.015437, loss_ce: 0.006835
2022-01-14 17:08:47,281 iteration 5097 : loss : 0.019336, loss_ce: 0.009006
2022-01-14 17:08:48,834 iteration 5098 : loss : 0.019109, loss_ce: 0.005716
2022-01-14 17:08:50,340 iteration 5099 : loss : 0.020486, loss_ce: 0.006821
2022-01-14 17:08:50,340 Training Data Eval:
2022-01-14 17:08:57,703   Average segmentation loss on training set: 0.0098
2022-01-14 17:08:57,704 Validation Data Eval:
2022-01-14 17:09:00,247   Average segmentation loss on validation set: 0.0592
2022-01-14 17:09:06,091 Found new lowest validation loss at iteration 5099! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed2.pth
2022-01-14 17:09:07,558 iteration 5100 : loss : 0.025310, loss_ce: 0.007666
 75%|█████████████████████▊       | 300/400 [2:17:00<50:56, 30.57s/it]2022-01-14 17:09:09,082 iteration 5101 : loss : 0.020636, loss_ce: 0.006758
2022-01-14 17:09:10,452 iteration 5102 : loss : 0.015364, loss_ce: 0.005132
2022-01-14 17:09:11,841 iteration 5103 : loss : 0.018167, loss_ce: 0.009317
2022-01-14 17:09:13,387 iteration 5104 : loss : 0.023780, loss_ce: 0.007891
2022-01-14 17:09:14,849 iteration 5105 : loss : 0.017101, loss_ce: 0.006659
2022-01-14 17:09:16,310 iteration 5106 : loss : 0.017545, loss_ce: 0.006180
2022-01-14 17:09:17,868 iteration 5107 : loss : 0.022554, loss_ce: 0.007509
2022-01-14 17:09:19,386 iteration 5108 : loss : 0.014838, loss_ce: 0.006761
2022-01-14 17:09:20,882 iteration 5109 : loss : 0.020540, loss_ce: 0.008206
2022-01-14 17:09:22,321 iteration 5110 : loss : 0.012590, loss_ce: 0.003716
2022-01-14 17:09:23,837 iteration 5111 : loss : 0.014677, loss_ce: 0.005210
2022-01-14 17:09:25,435 iteration 5112 : loss : 0.036915, loss_ce: 0.014783
2022-01-14 17:09:26,974 iteration 5113 : loss : 0.018181, loss_ce: 0.005901
2022-01-14 17:09:28,533 iteration 5114 : loss : 0.017362, loss_ce: 0.006178
2022-01-14 17:09:30,016 iteration 5115 : loss : 0.018443, loss_ce: 0.006031
2022-01-14 17:09:31,472 iteration 5116 : loss : 0.016964, loss_ce: 0.008441
2022-01-14 17:09:32,987 iteration 5117 : loss : 0.016803, loss_ce: 0.007661
 75%|█████████████████████▊       | 301/400 [2:17:26<47:53, 29.03s/it]2022-01-14 17:09:34,544 iteration 5118 : loss : 0.018882, loss_ce: 0.005130
2022-01-14 17:09:36,012 iteration 5119 : loss : 0.013412, loss_ce: 0.005999
2022-01-14 17:09:37,434 iteration 5120 : loss : 0.017103, loss_ce: 0.006932
2022-01-14 17:09:38,968 iteration 5121 : loss : 0.014678, loss_ce: 0.004047
2022-01-14 17:09:40,539 iteration 5122 : loss : 0.016983, loss_ce: 0.008333
2022-01-14 17:09:42,097 iteration 5123 : loss : 0.026959, loss_ce: 0.009340
2022-01-14 17:09:43,526 iteration 5124 : loss : 0.013324, loss_ce: 0.006695
2022-01-14 17:09:44,950 iteration 5125 : loss : 0.016440, loss_ce: 0.005513
2022-01-14 17:09:46,442 iteration 5126 : loss : 0.026180, loss_ce: 0.008713
2022-01-14 17:09:47,911 iteration 5127 : loss : 0.018323, loss_ce: 0.007774
2022-01-14 17:09:49,352 iteration 5128 : loss : 0.016511, loss_ce: 0.005053
2022-01-14 17:09:50,843 iteration 5129 : loss : 0.023059, loss_ce: 0.008985
2022-01-14 17:09:52,314 iteration 5130 : loss : 0.018225, loss_ce: 0.007295
2022-01-14 17:09:53,813 iteration 5131 : loss : 0.012072, loss_ce: 0.004342
2022-01-14 17:09:55,288 iteration 5132 : loss : 0.015122, loss_ce: 0.005461
2022-01-14 17:09:56,834 iteration 5133 : loss : 0.028919, loss_ce: 0.010603
2022-01-14 17:09:58,305 iteration 5134 : loss : 0.023103, loss_ce: 0.005902
 76%|█████████████████████▉       | 302/400 [2:17:51<45:35, 27.91s/it]2022-01-14 17:09:59,810 iteration 5135 : loss : 0.015671, loss_ce: 0.007816
2022-01-14 17:10:01,285 iteration 5136 : loss : 0.011488, loss_ce: 0.003761
2022-01-14 17:10:02,709 iteration 5137 : loss : 0.014386, loss_ce: 0.005129
2022-01-14 17:10:04,225 iteration 5138 : loss : 0.024609, loss_ce: 0.011239
2022-01-14 17:10:05,805 iteration 5139 : loss : 0.021489, loss_ce: 0.008134
2022-01-14 17:10:07,357 iteration 5140 : loss : 0.020378, loss_ce: 0.007417
2022-01-14 17:10:08,789 iteration 5141 : loss : 0.025954, loss_ce: 0.008256
2022-01-14 17:10:10,293 iteration 5142 : loss : 0.014114, loss_ce: 0.005038
2022-01-14 17:10:11,761 iteration 5143 : loss : 0.013751, loss_ce: 0.006513
2022-01-14 17:10:13,326 iteration 5144 : loss : 0.016875, loss_ce: 0.006323
2022-01-14 17:10:14,944 iteration 5145 : loss : 0.016924, loss_ce: 0.003802
2022-01-14 17:10:16,469 iteration 5146 : loss : 0.025585, loss_ce: 0.008227
2022-01-14 17:10:17,896 iteration 5147 : loss : 0.016604, loss_ce: 0.003751
2022-01-14 17:10:19,367 iteration 5148 : loss : 0.025335, loss_ce: 0.008692
2022-01-14 17:10:20,827 iteration 5149 : loss : 0.018142, loss_ce: 0.005999
2022-01-14 17:10:22,290 iteration 5150 : loss : 0.016427, loss_ce: 0.008432
2022-01-14 17:10:23,813 iteration 5151 : loss : 0.017055, loss_ce: 0.007933
 76%|█████████████████████▉       | 303/400 [2:18:17<43:57, 27.19s/it]2022-01-14 17:10:25,317 iteration 5152 : loss : 0.024140, loss_ce: 0.010547
2022-01-14 17:10:26,821 iteration 5153 : loss : 0.016325, loss_ce: 0.006010
2022-01-14 17:10:28,228 iteration 5154 : loss : 0.013749, loss_ce: 0.004627
2022-01-14 17:10:29,654 iteration 5155 : loss : 0.013736, loss_ce: 0.004653
2022-01-14 17:10:31,120 iteration 5156 : loss : 0.019827, loss_ce: 0.005062
2022-01-14 17:10:32,543 iteration 5157 : loss : 0.010587, loss_ce: 0.003984
2022-01-14 17:10:33,981 iteration 5158 : loss : 0.014804, loss_ce: 0.005759
2022-01-14 17:10:35,477 iteration 5159 : loss : 0.014969, loss_ce: 0.005574
2022-01-14 17:10:36,966 iteration 5160 : loss : 0.016767, loss_ce: 0.007332
2022-01-14 17:10:38,474 iteration 5161 : loss : 0.019060, loss_ce: 0.006663
2022-01-14 17:10:40,052 iteration 5162 : loss : 0.023568, loss_ce: 0.008929
2022-01-14 17:10:41,560 iteration 5163 : loss : 0.019223, loss_ce: 0.010036
2022-01-14 17:10:42,993 iteration 5164 : loss : 0.012536, loss_ce: 0.004707
2022-01-14 17:10:44,544 iteration 5165 : loss : 0.016281, loss_ce: 0.005917
2022-01-14 17:10:46,043 iteration 5166 : loss : 0.018404, loss_ce: 0.006316
2022-01-14 17:10:47,571 iteration 5167 : loss : 0.020795, loss_ce: 0.005570
2022-01-14 17:10:48,961 iteration 5168 : loss : 0.015138, loss_ce: 0.007350
 76%|██████████████████████       | 304/400 [2:18:42<42:31, 26.58s/it]2022-01-14 17:10:50,530 iteration 5169 : loss : 0.014773, loss_ce: 0.003822
2022-01-14 17:10:51,993 iteration 5170 : loss : 0.012390, loss_ce: 0.006206
2022-01-14 17:10:53,515 iteration 5171 : loss : 0.020035, loss_ce: 0.006307
2022-01-14 17:10:55,049 iteration 5172 : loss : 0.020908, loss_ce: 0.006849
2022-01-14 17:10:56,660 iteration 5173 : loss : 0.030998, loss_ce: 0.011258
2022-01-14 17:10:58,182 iteration 5174 : loss : 0.013292, loss_ce: 0.003558
2022-01-14 17:10:59,720 iteration 5175 : loss : 0.016111, loss_ce: 0.005305
2022-01-14 17:11:01,288 iteration 5176 : loss : 0.024154, loss_ce: 0.006806
2022-01-14 17:11:02,788 iteration 5177 : loss : 0.020128, loss_ce: 0.008018
2022-01-14 17:11:04,290 iteration 5178 : loss : 0.022945, loss_ce: 0.010424
2022-01-14 17:11:05,747 iteration 5179 : loss : 0.014285, loss_ce: 0.007002
2022-01-14 17:11:07,156 iteration 5180 : loss : 0.014670, loss_ce: 0.006211
2022-01-14 17:11:08,598 iteration 5181 : loss : 0.014891, loss_ce: 0.005019
2022-01-14 17:11:10,058 iteration 5182 : loss : 0.018546, loss_ce: 0.008406
2022-01-14 17:11:11,513 iteration 5183 : loss : 0.023123, loss_ce: 0.009619
2022-01-14 17:11:12,941 iteration 5184 : loss : 0.019032, loss_ce: 0.009497
2022-01-14 17:11:12,941 Training Data Eval:
2022-01-14 17:11:20,306   Average segmentation loss on training set: 0.0097
2022-01-14 17:11:20,306 Validation Data Eval:
2022-01-14 17:11:22,851   Average segmentation loss on validation set: 0.0776
2022-01-14 17:11:24,302 iteration 5185 : loss : 0.012026, loss_ce: 0.004391
 76%|██████████████████████       | 305/400 [2:19:17<46:14, 29.21s/it]2022-01-14 17:11:25,866 iteration 5186 : loss : 0.019261, loss_ce: 0.005764
2022-01-14 17:11:27,288 iteration 5187 : loss : 0.011533, loss_ce: 0.004885
2022-01-14 17:11:28,762 iteration 5188 : loss : 0.013912, loss_ce: 0.004495
2022-01-14 17:11:30,256 iteration 5189 : loss : 0.040903, loss_ce: 0.011054
2022-01-14 17:11:31,826 iteration 5190 : loss : 0.018255, loss_ce: 0.005938
2022-01-14 17:11:33,280 iteration 5191 : loss : 0.016411, loss_ce: 0.006276
2022-01-14 17:11:34,749 iteration 5192 : loss : 0.020616, loss_ce: 0.007667
2022-01-14 17:11:36,267 iteration 5193 : loss : 0.014172, loss_ce: 0.006298
2022-01-14 17:11:37,768 iteration 5194 : loss : 0.023248, loss_ce: 0.006324
2022-01-14 17:11:39,235 iteration 5195 : loss : 0.016741, loss_ce: 0.004306
2022-01-14 17:11:40,815 iteration 5196 : loss : 0.022714, loss_ce: 0.007796
2022-01-14 17:11:42,284 iteration 5197 : loss : 0.015470, loss_ce: 0.004532
2022-01-14 17:11:43,717 iteration 5198 : loss : 0.015506, loss_ce: 0.009307
2022-01-14 17:11:45,301 iteration 5199 : loss : 0.015818, loss_ce: 0.005624
2022-01-14 17:11:46,704 iteration 5200 : loss : 0.022770, loss_ce: 0.010007
2022-01-14 17:11:48,113 iteration 5201 : loss : 0.013814, loss_ce: 0.005840
2022-01-14 17:11:49,570 iteration 5202 : loss : 0.017707, loss_ce: 0.006875
 76%|██████████████████████▏      | 306/400 [2:19:42<43:54, 28.03s/it]2022-01-14 17:11:51,070 iteration 5203 : loss : 0.017138, loss_ce: 0.007055
2022-01-14 17:11:52,606 iteration 5204 : loss : 0.014480, loss_ce: 0.005802
2022-01-14 17:11:54,124 iteration 5205 : loss : 0.027108, loss_ce: 0.009110
2022-01-14 17:11:55,734 iteration 5206 : loss : 0.030631, loss_ce: 0.011176
2022-01-14 17:11:57,274 iteration 5207 : loss : 0.041478, loss_ce: 0.007254
2022-01-14 17:11:58,776 iteration 5208 : loss : 0.011926, loss_ce: 0.005597
2022-01-14 17:12:00,313 iteration 5209 : loss : 0.020911, loss_ce: 0.008087
2022-01-14 17:12:01,848 iteration 5210 : loss : 0.016590, loss_ce: 0.007633
2022-01-14 17:12:03,326 iteration 5211 : loss : 0.017280, loss_ce: 0.005749
2022-01-14 17:12:04,860 iteration 5212 : loss : 0.025752, loss_ce: 0.008367
2022-01-14 17:12:06,325 iteration 5213 : loss : 0.018229, loss_ce: 0.007071
2022-01-14 17:12:07,801 iteration 5214 : loss : 0.014057, loss_ce: 0.006137
2022-01-14 17:12:09,197 iteration 5215 : loss : 0.012622, loss_ce: 0.004293
2022-01-14 17:12:10,643 iteration 5216 : loss : 0.013031, loss_ce: 0.004011
2022-01-14 17:12:12,189 iteration 5217 : loss : 0.022972, loss_ce: 0.009895
2022-01-14 17:12:13,620 iteration 5218 : loss : 0.015595, loss_ce: 0.005452
2022-01-14 17:12:15,127 iteration 5219 : loss : 0.014772, loss_ce: 0.005584
 77%|██████████████████████▎      | 307/400 [2:20:08<42:17, 27.29s/it]2022-01-14 17:12:16,563 iteration 5220 : loss : 0.012178, loss_ce: 0.005104
2022-01-14 17:12:17,975 iteration 5221 : loss : 0.017538, loss_ce: 0.004708
2022-01-14 17:12:19,494 iteration 5222 : loss : 0.019121, loss_ce: 0.006075
2022-01-14 17:12:20,962 iteration 5223 : loss : 0.012605, loss_ce: 0.005355
2022-01-14 17:12:22,518 iteration 5224 : loss : 0.024124, loss_ce: 0.006176
2022-01-14 17:12:23,973 iteration 5225 : loss : 0.012891, loss_ce: 0.005122
2022-01-14 17:12:25,470 iteration 5226 : loss : 0.012796, loss_ce: 0.004592
2022-01-14 17:12:26,976 iteration 5227 : loss : 0.016008, loss_ce: 0.006016
2022-01-14 17:12:28,379 iteration 5228 : loss : 0.010707, loss_ce: 0.003151
2022-01-14 17:12:29,894 iteration 5229 : loss : 0.017068, loss_ce: 0.006438
2022-01-14 17:12:31,319 iteration 5230 : loss : 0.012992, loss_ce: 0.004526
2022-01-14 17:12:32,805 iteration 5231 : loss : 0.014558, loss_ce: 0.004206
2022-01-14 17:12:34,375 iteration 5232 : loss : 0.022657, loss_ce: 0.006978
2022-01-14 17:12:35,737 iteration 5233 : loss : 0.013118, loss_ce: 0.005591
2022-01-14 17:12:37,214 iteration 5234 : loss : 0.019183, loss_ce: 0.006674
2022-01-14 17:12:38,729 iteration 5235 : loss : 0.015473, loss_ce: 0.007085
2022-01-14 17:12:40,295 iteration 5236 : loss : 0.026173, loss_ce: 0.012285
 77%|██████████████████████▎      | 308/400 [2:20:33<40:51, 26.65s/it]2022-01-14 17:12:41,741 iteration 5237 : loss : 0.011336, loss_ce: 0.005214
2022-01-14 17:12:43,208 iteration 5238 : loss : 0.016710, loss_ce: 0.007609
2022-01-14 17:12:44,664 iteration 5239 : loss : 0.015325, loss_ce: 0.004946
2022-01-14 17:12:46,199 iteration 5240 : loss : 0.032016, loss_ce: 0.007957
2022-01-14 17:12:47,695 iteration 5241 : loss : 0.017630, loss_ce: 0.006242
2022-01-14 17:12:49,306 iteration 5242 : loss : 0.020633, loss_ce: 0.009379
2022-01-14 17:12:50,823 iteration 5243 : loss : 0.028013, loss_ce: 0.013211
2022-01-14 17:12:52,284 iteration 5244 : loss : 0.015496, loss_ce: 0.005672
2022-01-14 17:12:53,827 iteration 5245 : loss : 0.017407, loss_ce: 0.005084
2022-01-14 17:12:55,334 iteration 5246 : loss : 0.023824, loss_ce: 0.009146
2022-01-14 17:12:56,800 iteration 5247 : loss : 0.016847, loss_ce: 0.006037
2022-01-14 17:12:58,345 iteration 5248 : loss : 0.022501, loss_ce: 0.011182
2022-01-14 17:12:59,805 iteration 5249 : loss : 0.018343, loss_ce: 0.006296
2022-01-14 17:13:01,292 iteration 5250 : loss : 0.013058, loss_ce: 0.004430
2022-01-14 17:13:02,836 iteration 5251 : loss : 0.023906, loss_ce: 0.010125
2022-01-14 17:13:04,299 iteration 5252 : loss : 0.012586, loss_ce: 0.005857
2022-01-14 17:13:05,759 iteration 5253 : loss : 0.012871, loss_ce: 0.004589
 77%|██████████████████████▍      | 309/400 [2:20:59<39:52, 26.29s/it]2022-01-14 17:13:07,262 iteration 5254 : loss : 0.014124, loss_ce: 0.005769
2022-01-14 17:13:08,796 iteration 5255 : loss : 0.018329, loss_ce: 0.006170
2022-01-14 17:13:10,290 iteration 5256 : loss : 0.022171, loss_ce: 0.009306
2022-01-14 17:13:11,804 iteration 5257 : loss : 0.016046, loss_ce: 0.006243
2022-01-14 17:13:13,212 iteration 5258 : loss : 0.013249, loss_ce: 0.005329
2022-01-14 17:13:14,664 iteration 5259 : loss : 0.016777, loss_ce: 0.005984
2022-01-14 17:13:16,239 iteration 5260 : loss : 0.020293, loss_ce: 0.006740
2022-01-14 17:13:17,710 iteration 5261 : loss : 0.015351, loss_ce: 0.006961
2022-01-14 17:13:19,158 iteration 5262 : loss : 0.020391, loss_ce: 0.010179
2022-01-14 17:13:20,669 iteration 5263 : loss : 0.047240, loss_ce: 0.019637
2022-01-14 17:13:22,182 iteration 5264 : loss : 0.018272, loss_ce: 0.006722
2022-01-14 17:13:23,746 iteration 5265 : loss : 0.020326, loss_ce: 0.007864
2022-01-14 17:13:25,207 iteration 5266 : loss : 0.014525, loss_ce: 0.005273
2022-01-14 17:13:26,774 iteration 5267 : loss : 0.020307, loss_ce: 0.009571
2022-01-14 17:13:28,130 iteration 5268 : loss : 0.011371, loss_ce: 0.002650
2022-01-14 17:13:29,505 iteration 5269 : loss : 0.013500, loss_ce: 0.004956
2022-01-14 17:13:29,506 Training Data Eval:
2022-01-14 17:13:36,882   Average segmentation loss on training set: 0.0091
2022-01-14 17:13:36,882 Validation Data Eval:
2022-01-14 17:13:39,423   Average segmentation loss on validation set: 0.0640
2022-01-14 17:13:40,874 iteration 5270 : loss : 0.017932, loss_ce: 0.002995
 78%|██████████████████████▍      | 310/400 [2:21:34<43:24, 28.94s/it]2022-01-14 17:13:42,508 iteration 5271 : loss : 0.019634, loss_ce: 0.006674
2022-01-14 17:13:44,071 iteration 5272 : loss : 0.021493, loss_ce: 0.007278
2022-01-14 17:13:45,560 iteration 5273 : loss : 0.015556, loss_ce: 0.006115
2022-01-14 17:13:47,052 iteration 5274 : loss : 0.019305, loss_ce: 0.007571
2022-01-14 17:13:48,503 iteration 5275 : loss : 0.014138, loss_ce: 0.005796
2022-01-14 17:13:49,947 iteration 5276 : loss : 0.019644, loss_ce: 0.006860
2022-01-14 17:13:51,537 iteration 5277 : loss : 0.022235, loss_ce: 0.009113
2022-01-14 17:13:53,010 iteration 5278 : loss : 0.017309, loss_ce: 0.004161
2022-01-14 17:13:54,535 iteration 5279 : loss : 0.029961, loss_ce: 0.010867
2022-01-14 17:13:55,956 iteration 5280 : loss : 0.013706, loss_ce: 0.003529
2022-01-14 17:13:57,404 iteration 5281 : loss : 0.012727, loss_ce: 0.005462
2022-01-14 17:13:58,849 iteration 5282 : loss : 0.016161, loss_ce: 0.006344
2022-01-14 17:14:00,284 iteration 5283 : loss : 0.014306, loss_ce: 0.005428
2022-01-14 17:14:01,772 iteration 5284 : loss : 0.012769, loss_ce: 0.004703
2022-01-14 17:14:03,233 iteration 5285 : loss : 0.016019, loss_ce: 0.005724
2022-01-14 17:14:04,660 iteration 5286 : loss : 0.014314, loss_ce: 0.006674
2022-01-14 17:14:06,155 iteration 5287 : loss : 0.014366, loss_ce: 0.004794
 78%|██████████████████████▌      | 311/400 [2:21:59<41:18, 27.84s/it]2022-01-14 17:14:07,711 iteration 5288 : loss : 0.018481, loss_ce: 0.008083
2022-01-14 17:14:09,149 iteration 5289 : loss : 0.017566, loss_ce: 0.005975
2022-01-14 17:14:10,757 iteration 5290 : loss : 0.018774, loss_ce: 0.005189
2022-01-14 17:14:12,245 iteration 5291 : loss : 0.015383, loss_ce: 0.006766
2022-01-14 17:14:13,753 iteration 5292 : loss : 0.019243, loss_ce: 0.004978
2022-01-14 17:14:15,181 iteration 5293 : loss : 0.015353, loss_ce: 0.005283
2022-01-14 17:14:16,703 iteration 5294 : loss : 0.030814, loss_ce: 0.009007
2022-01-14 17:14:18,196 iteration 5295 : loss : 0.019992, loss_ce: 0.006109
2022-01-14 17:14:19,612 iteration 5296 : loss : 0.027824, loss_ce: 0.007119
2022-01-14 17:14:21,065 iteration 5297 : loss : 0.019908, loss_ce: 0.005616
2022-01-14 17:14:22,501 iteration 5298 : loss : 0.015693, loss_ce: 0.006382
2022-01-14 17:14:23,946 iteration 5299 : loss : 0.021651, loss_ce: 0.004490
2022-01-14 17:14:25,383 iteration 5300 : loss : 0.013047, loss_ce: 0.005133
2022-01-14 17:14:26,841 iteration 5301 : loss : 0.030077, loss_ce: 0.006474
2022-01-14 17:14:28,389 iteration 5302 : loss : 0.032919, loss_ce: 0.016985
2022-01-14 17:14:29,903 iteration 5303 : loss : 0.014500, loss_ce: 0.006555
2022-01-14 17:14:31,372 iteration 5304 : loss : 0.018472, loss_ce: 0.009543
 78%|██████████████████████▌      | 312/400 [2:22:24<39:40, 27.05s/it]2022-01-14 17:14:32,818 iteration 5305 : loss : 0.010930, loss_ce: 0.003635
2022-01-14 17:14:34,340 iteration 5306 : loss : 0.019794, loss_ce: 0.008422
2022-01-14 17:14:35,835 iteration 5307 : loss : 0.019363, loss_ce: 0.007375
2022-01-14 17:14:37,288 iteration 5308 : loss : 0.012294, loss_ce: 0.004209
2022-01-14 17:14:38,782 iteration 5309 : loss : 0.015377, loss_ce: 0.007521
2022-01-14 17:14:40,374 iteration 5310 : loss : 0.017957, loss_ce: 0.005685
2022-01-14 17:14:41,846 iteration 5311 : loss : 0.018298, loss_ce: 0.006473
2022-01-14 17:14:43,394 iteration 5312 : loss : 0.030885, loss_ce: 0.011567
2022-01-14 17:14:44,848 iteration 5313 : loss : 0.015898, loss_ce: 0.007896
2022-01-14 17:14:46,326 iteration 5314 : loss : 0.018032, loss_ce: 0.006406
2022-01-14 17:14:47,768 iteration 5315 : loss : 0.016312, loss_ce: 0.005392
2022-01-14 17:14:49,230 iteration 5316 : loss : 0.015694, loss_ce: 0.004371
2022-01-14 17:14:50,681 iteration 5317 : loss : 0.013793, loss_ce: 0.004252
2022-01-14 17:14:52,213 iteration 5318 : loss : 0.023793, loss_ce: 0.007834
2022-01-14 17:14:53,679 iteration 5319 : loss : 0.022976, loss_ce: 0.008079
2022-01-14 17:14:55,111 iteration 5320 : loss : 0.019161, loss_ce: 0.007176
2022-01-14 17:14:56,551 iteration 5321 : loss : 0.020442, loss_ce: 0.007877
 78%|██████████████████████▋      | 313/400 [2:22:49<38:24, 26.49s/it]2022-01-14 17:14:58,012 iteration 5322 : loss : 0.017671, loss_ce: 0.006906
2022-01-14 17:14:59,540 iteration 5323 : loss : 0.016606, loss_ce: 0.004521
2022-01-14 17:15:00,994 iteration 5324 : loss : 0.018125, loss_ce: 0.006200
2022-01-14 17:15:02,531 iteration 5325 : loss : 0.015658, loss_ce: 0.006128
2022-01-14 17:15:04,052 iteration 5326 : loss : 0.017144, loss_ce: 0.005444
2022-01-14 17:15:05,533 iteration 5327 : loss : 0.014179, loss_ce: 0.005481
2022-01-14 17:15:07,042 iteration 5328 : loss : 0.011150, loss_ce: 0.003943
2022-01-14 17:15:08,554 iteration 5329 : loss : 0.018799, loss_ce: 0.009687
2022-01-14 17:15:10,088 iteration 5330 : loss : 0.014322, loss_ce: 0.005324
2022-01-14 17:15:11,511 iteration 5331 : loss : 0.016718, loss_ce: 0.005593
2022-01-14 17:15:12,949 iteration 5332 : loss : 0.016191, loss_ce: 0.006248
2022-01-14 17:15:14,413 iteration 5333 : loss : 0.019956, loss_ce: 0.006143
2022-01-14 17:15:15,863 iteration 5334 : loss : 0.014367, loss_ce: 0.004288
2022-01-14 17:15:17,441 iteration 5335 : loss : 0.024473, loss_ce: 0.008976
2022-01-14 17:15:18,934 iteration 5336 : loss : 0.020046, loss_ce: 0.006651
2022-01-14 17:15:20,412 iteration 5337 : loss : 0.015981, loss_ce: 0.005273
2022-01-14 17:15:21,797 iteration 5338 : loss : 0.012983, loss_ce: 0.005034
 78%|██████████████████████▊      | 314/400 [2:23:15<37:26, 26.12s/it]2022-01-14 17:15:23,299 iteration 5339 : loss : 0.015223, loss_ce: 0.005279
2022-01-14 17:15:24,843 iteration 5340 : loss : 0.014081, loss_ce: 0.008596
2022-01-14 17:15:26,345 iteration 5341 : loss : 0.015301, loss_ce: 0.005953
2022-01-14 17:15:27,865 iteration 5342 : loss : 0.016484, loss_ce: 0.004481
2022-01-14 17:15:29,315 iteration 5343 : loss : 0.015476, loss_ce: 0.005741
2022-01-14 17:15:30,764 iteration 5344 : loss : 0.015107, loss_ce: 0.006990
2022-01-14 17:15:32,184 iteration 5345 : loss : 0.018326, loss_ce: 0.005232
2022-01-14 17:15:33,640 iteration 5346 : loss : 0.018876, loss_ce: 0.006667
2022-01-14 17:15:35,256 iteration 5347 : loss : 0.016517, loss_ce: 0.006882
2022-01-14 17:15:36,807 iteration 5348 : loss : 0.018747, loss_ce: 0.006893
2022-01-14 17:15:38,316 iteration 5349 : loss : 0.014152, loss_ce: 0.006422
2022-01-14 17:15:39,762 iteration 5350 : loss : 0.012335, loss_ce: 0.004828
2022-01-14 17:15:41,289 iteration 5351 : loss : 0.017482, loss_ce: 0.003209
2022-01-14 17:15:42,769 iteration 5352 : loss : 0.013489, loss_ce: 0.004862
2022-01-14 17:15:44,298 iteration 5353 : loss : 0.016631, loss_ce: 0.007702
2022-01-14 17:15:45,728 iteration 5354 : loss : 0.016133, loss_ce: 0.006567
2022-01-14 17:15:45,728 Training Data Eval:
2022-01-14 17:15:53,092   Average segmentation loss on training set: 0.0097
2022-01-14 17:15:53,092 Validation Data Eval:
2022-01-14 17:15:55,627   Average segmentation loss on validation set: 0.0764
2022-01-14 17:15:57,040 iteration 5355 : loss : 0.012302, loss_ce: 0.004510
 79%|██████████████████████▊      | 315/400 [2:23:50<40:52, 28.86s/it]2022-01-14 17:15:58,614 iteration 5356 : loss : 0.019838, loss_ce: 0.008314
2022-01-14 17:16:00,004 iteration 5357 : loss : 0.010605, loss_ce: 0.002895
2022-01-14 17:16:01,473 iteration 5358 : loss : 0.014694, loss_ce: 0.003187
2022-01-14 17:16:02,913 iteration 5359 : loss : 0.013306, loss_ce: 0.007527
2022-01-14 17:16:04,374 iteration 5360 : loss : 0.012362, loss_ce: 0.004131
2022-01-14 17:16:05,907 iteration 5361 : loss : 0.019218, loss_ce: 0.006193
2022-01-14 17:16:07,433 iteration 5362 : loss : 0.016257, loss_ce: 0.009777
2022-01-14 17:16:08,917 iteration 5363 : loss : 0.013683, loss_ce: 0.005826
2022-01-14 17:16:10,297 iteration 5364 : loss : 0.014735, loss_ce: 0.002020
2022-01-14 17:16:11,815 iteration 5365 : loss : 0.012280, loss_ce: 0.004219
2022-01-14 17:16:13,225 iteration 5366 : loss : 0.015791, loss_ce: 0.005464
2022-01-14 17:16:14,724 iteration 5367 : loss : 0.016073, loss_ce: 0.003801
2022-01-14 17:16:16,289 iteration 5368 : loss : 0.015799, loss_ce: 0.005733
2022-01-14 17:16:17,784 iteration 5369 : loss : 0.017614, loss_ce: 0.007886
2022-01-14 17:16:19,280 iteration 5370 : loss : 0.016379, loss_ce: 0.004823
2022-01-14 17:16:20,834 iteration 5371 : loss : 0.016324, loss_ce: 0.005350
2022-01-14 17:16:22,291 iteration 5372 : loss : 0.017283, loss_ce: 0.007267
 79%|██████████████████████▉      | 316/400 [2:24:15<38:53, 27.78s/it]2022-01-14 17:16:23,732 iteration 5373 : loss : 0.013182, loss_ce: 0.005785
2022-01-14 17:16:25,231 iteration 5374 : loss : 0.022495, loss_ce: 0.006747
2022-01-14 17:16:26,664 iteration 5375 : loss : 0.013638, loss_ce: 0.004950
2022-01-14 17:16:28,077 iteration 5376 : loss : 0.013785, loss_ce: 0.004611
2022-01-14 17:16:29,444 iteration 5377 : loss : 0.016816, loss_ce: 0.002490
2022-01-14 17:16:30,810 iteration 5378 : loss : 0.010586, loss_ce: 0.003893
2022-01-14 17:16:32,301 iteration 5379 : loss : 0.018289, loss_ce: 0.005731
2022-01-14 17:16:33,738 iteration 5380 : loss : 0.012012, loss_ce: 0.004782
2022-01-14 17:16:35,209 iteration 5381 : loss : 0.015631, loss_ce: 0.006107
2022-01-14 17:16:36,721 iteration 5382 : loss : 0.019631, loss_ce: 0.006232
2022-01-14 17:16:38,246 iteration 5383 : loss : 0.015980, loss_ce: 0.006384
2022-01-14 17:16:39,709 iteration 5384 : loss : 0.016756, loss_ce: 0.007641
2022-01-14 17:16:41,178 iteration 5385 : loss : 0.018684, loss_ce: 0.008126
2022-01-14 17:16:42,697 iteration 5386 : loss : 0.014647, loss_ce: 0.005322
2022-01-14 17:16:44,181 iteration 5387 : loss : 0.014023, loss_ce: 0.005564
2022-01-14 17:16:45,576 iteration 5388 : loss : 0.012939, loss_ce: 0.004727
2022-01-14 17:16:47,027 iteration 5389 : loss : 0.016229, loss_ce: 0.005214
 79%|██████████████████████▉      | 317/400 [2:24:40<37:09, 26.86s/it]2022-01-14 17:16:48,620 iteration 5390 : loss : 0.024137, loss_ce: 0.007485
2022-01-14 17:16:50,001 iteration 5391 : loss : 0.020056, loss_ce: 0.006762
2022-01-14 17:16:51,506 iteration 5392 : loss : 0.015412, loss_ce: 0.007291
2022-01-14 17:16:53,023 iteration 5393 : loss : 0.017872, loss_ce: 0.005611
2022-01-14 17:16:54,493 iteration 5394 : loss : 0.012737, loss_ce: 0.004982
2022-01-14 17:16:55,912 iteration 5395 : loss : 0.012617, loss_ce: 0.005687
2022-01-14 17:16:57,440 iteration 5396 : loss : 0.021945, loss_ce: 0.005696
2022-01-14 17:16:58,924 iteration 5397 : loss : 0.018345, loss_ce: 0.006221
2022-01-14 17:17:00,297 iteration 5398 : loss : 0.010673, loss_ce: 0.005237
2022-01-14 17:17:01,740 iteration 5399 : loss : 0.012828, loss_ce: 0.005744
2022-01-14 17:17:03,295 iteration 5400 : loss : 0.023581, loss_ce: 0.006737
2022-01-14 17:17:04,817 iteration 5401 : loss : 0.016666, loss_ce: 0.005282
2022-01-14 17:17:06,285 iteration 5402 : loss : 0.020571, loss_ce: 0.008099
2022-01-14 17:17:07,800 iteration 5403 : loss : 0.028412, loss_ce: 0.008391
2022-01-14 17:17:09,240 iteration 5404 : loss : 0.013403, loss_ce: 0.006218
2022-01-14 17:17:10,653 iteration 5405 : loss : 0.015100, loss_ce: 0.005532
2022-01-14 17:17:12,029 iteration 5406 : loss : 0.016814, loss_ce: 0.003736
 80%|███████████████████████      | 318/400 [2:25:05<35:57, 26.31s/it]2022-01-14 17:17:13,616 iteration 5407 : loss : 0.016404, loss_ce: 0.004511
2022-01-14 17:17:15,066 iteration 5408 : loss : 0.013629, loss_ce: 0.003696
2022-01-14 17:17:16,486 iteration 5409 : loss : 0.011666, loss_ce: 0.005229
2022-01-14 17:17:17,918 iteration 5410 : loss : 0.014800, loss_ce: 0.005105
2022-01-14 17:17:19,417 iteration 5411 : loss : 0.015129, loss_ce: 0.005156
2022-01-14 17:17:20,933 iteration 5412 : loss : 0.020669, loss_ce: 0.009923
2022-01-14 17:17:22,353 iteration 5413 : loss : 0.013568, loss_ce: 0.005143
2022-01-14 17:17:23,877 iteration 5414 : loss : 0.020249, loss_ce: 0.006536
2022-01-14 17:17:25,342 iteration 5415 : loss : 0.016517, loss_ce: 0.005610
2022-01-14 17:17:26,869 iteration 5416 : loss : 0.016027, loss_ce: 0.006560
2022-01-14 17:17:28,311 iteration 5417 : loss : 0.018715, loss_ce: 0.006558
2022-01-14 17:17:29,775 iteration 5418 : loss : 0.013530, loss_ce: 0.004334
2022-01-14 17:17:31,218 iteration 5419 : loss : 0.012878, loss_ce: 0.006629
2022-01-14 17:17:32,700 iteration 5420 : loss : 0.014720, loss_ce: 0.006064
2022-01-14 17:17:34,205 iteration 5421 : loss : 0.019854, loss_ce: 0.006767
2022-01-14 17:17:35,692 iteration 5422 : loss : 0.022510, loss_ce: 0.007165
2022-01-14 17:17:37,219 iteration 5423 : loss : 0.022908, loss_ce: 0.008994
 80%|███████████████████████▏     | 319/400 [2:25:30<35:03, 25.97s/it]2022-01-14 17:17:38,764 iteration 5424 : loss : 0.015648, loss_ce: 0.005942
2022-01-14 17:17:40,256 iteration 5425 : loss : 0.029354, loss_ce: 0.010539
2022-01-14 17:17:41,764 iteration 5426 : loss : 0.013966, loss_ce: 0.003706
2022-01-14 17:17:43,361 iteration 5427 : loss : 0.021334, loss_ce: 0.007846
2022-01-14 17:17:44,909 iteration 5428 : loss : 0.031499, loss_ce: 0.011577
2022-01-14 17:17:46,349 iteration 5429 : loss : 0.014002, loss_ce: 0.005793
2022-01-14 17:17:47,742 iteration 5430 : loss : 0.013488, loss_ce: 0.005487
2022-01-14 17:17:49,283 iteration 5431 : loss : 0.017864, loss_ce: 0.006383
2022-01-14 17:17:50,727 iteration 5432 : loss : 0.014093, loss_ce: 0.004770
2022-01-14 17:17:52,324 iteration 5433 : loss : 0.023970, loss_ce: 0.009381
2022-01-14 17:17:53,888 iteration 5434 : loss : 0.019341, loss_ce: 0.006358
2022-01-14 17:17:55,400 iteration 5435 : loss : 0.018387, loss_ce: 0.008303
2022-01-14 17:17:56,926 iteration 5436 : loss : 0.016753, loss_ce: 0.008240
2022-01-14 17:17:58,396 iteration 5437 : loss : 0.016865, loss_ce: 0.004154
2022-01-14 17:17:59,882 iteration 5438 : loss : 0.014116, loss_ce: 0.005962
2022-01-14 17:18:01,392 iteration 5439 : loss : 0.018129, loss_ce: 0.005495
2022-01-14 17:18:01,392 Training Data Eval:
2022-01-14 17:18:08,774   Average segmentation loss on training set: 0.0091
2022-01-14 17:18:08,775 Validation Data Eval:
2022-01-14 17:18:11,323   Average segmentation loss on validation set: 0.0721
2022-01-14 17:18:12,809 iteration 5440 : loss : 0.014285, loss_ce: 0.005155
 80%|███████████████████████▏     | 320/400 [2:26:06<38:28, 28.86s/it]2022-01-14 17:18:14,270 iteration 5441 : loss : 0.013040, loss_ce: 0.005521
2022-01-14 17:18:15,867 iteration 5442 : loss : 0.019948, loss_ce: 0.006932
2022-01-14 17:18:17,384 iteration 5443 : loss : 0.019858, loss_ce: 0.007802
2022-01-14 17:18:18,849 iteration 5444 : loss : 0.013323, loss_ce: 0.005790
2022-01-14 17:18:20,300 iteration 5445 : loss : 0.018122, loss_ce: 0.007036
2022-01-14 17:18:21,774 iteration 5446 : loss : 0.020994, loss_ce: 0.007710
2022-01-14 17:18:23,178 iteration 5447 : loss : 0.014204, loss_ce: 0.002457
2022-01-14 17:18:24,677 iteration 5448 : loss : 0.019873, loss_ce: 0.007051
2022-01-14 17:18:26,135 iteration 5449 : loss : 0.011736, loss_ce: 0.003633
2022-01-14 17:18:27,571 iteration 5450 : loss : 0.019783, loss_ce: 0.007242
2022-01-14 17:18:29,057 iteration 5451 : loss : 0.010655, loss_ce: 0.003019
2022-01-14 17:18:30,548 iteration 5452 : loss : 0.012778, loss_ce: 0.005131
2022-01-14 17:18:32,071 iteration 5453 : loss : 0.015403, loss_ce: 0.005243
2022-01-14 17:18:33,569 iteration 5454 : loss : 0.018221, loss_ce: 0.007621
2022-01-14 17:18:35,055 iteration 5455 : loss : 0.016141, loss_ce: 0.007892
2022-01-14 17:18:36,566 iteration 5456 : loss : 0.016456, loss_ce: 0.004824
2022-01-14 17:18:38,067 iteration 5457 : loss : 0.014500, loss_ce: 0.005653
 80%|███████████████████████▎     | 321/400 [2:26:31<36:34, 27.78s/it]2022-01-14 17:18:39,666 iteration 5458 : loss : 0.018314, loss_ce: 0.005240
2022-01-14 17:18:41,100 iteration 5459 : loss : 0.013095, loss_ce: 0.004348
2022-01-14 17:18:42,583 iteration 5460 : loss : 0.014766, loss_ce: 0.006098
2022-01-14 17:18:44,090 iteration 5461 : loss : 0.014786, loss_ce: 0.005300
2022-01-14 17:18:45,610 iteration 5462 : loss : 0.015034, loss_ce: 0.006410
2022-01-14 17:18:47,062 iteration 5463 : loss : 0.010558, loss_ce: 0.003434
2022-01-14 17:18:48,688 iteration 5464 : loss : 0.022973, loss_ce: 0.009299
2022-01-14 17:18:50,143 iteration 5465 : loss : 0.014380, loss_ce: 0.005183
2022-01-14 17:18:51,589 iteration 5466 : loss : 0.013674, loss_ce: 0.005681
2022-01-14 17:18:53,140 iteration 5467 : loss : 0.015633, loss_ce: 0.005247
2022-01-14 17:18:54,681 iteration 5468 : loss : 0.015669, loss_ce: 0.007198
2022-01-14 17:18:56,222 iteration 5469 : loss : 0.020621, loss_ce: 0.007735
2022-01-14 17:18:57,679 iteration 5470 : loss : 0.013968, loss_ce: 0.006458
2022-01-14 17:18:59,131 iteration 5471 : loss : 0.013701, loss_ce: 0.007015
2022-01-14 17:19:00,674 iteration 5472 : loss : 0.019796, loss_ce: 0.010545
2022-01-14 17:19:02,129 iteration 5473 : loss : 0.012437, loss_ce: 0.003464
2022-01-14 17:19:03,660 iteration 5474 : loss : 0.015887, loss_ce: 0.004687
 80%|███████████████████████▎     | 322/400 [2:26:56<35:15, 27.12s/it]2022-01-14 17:19:05,145 iteration 5475 : loss : 0.013422, loss_ce: 0.005127
2022-01-14 17:19:06,606 iteration 5476 : loss : 0.010918, loss_ce: 0.004686
2022-01-14 17:19:08,127 iteration 5477 : loss : 0.013277, loss_ce: 0.004943
2022-01-14 17:19:09,664 iteration 5478 : loss : 0.018348, loss_ce: 0.008498
2022-01-14 17:19:11,115 iteration 5479 : loss : 0.020847, loss_ce: 0.005424
2022-01-14 17:19:12,593 iteration 5480 : loss : 0.016134, loss_ce: 0.003708
2022-01-14 17:19:14,089 iteration 5481 : loss : 0.015789, loss_ce: 0.006125
2022-01-14 17:19:15,572 iteration 5482 : loss : 0.015918, loss_ce: 0.005325
2022-01-14 17:19:17,000 iteration 5483 : loss : 0.014043, loss_ce: 0.005125
2022-01-14 17:19:18,543 iteration 5484 : loss : 0.016692, loss_ce: 0.006805
2022-01-14 17:19:19,959 iteration 5485 : loss : 0.018308, loss_ce: 0.010919
2022-01-14 17:19:21,561 iteration 5486 : loss : 0.048509, loss_ce: 0.014444
2022-01-14 17:19:22,987 iteration 5487 : loss : 0.013808, loss_ce: 0.007754
2022-01-14 17:19:24,500 iteration 5488 : loss : 0.024075, loss_ce: 0.007537
2022-01-14 17:19:25,924 iteration 5489 : loss : 0.018429, loss_ce: 0.004605
2022-01-14 17:19:27,439 iteration 5490 : loss : 0.013999, loss_ce: 0.004962
2022-01-14 17:19:28,878 iteration 5491 : loss : 0.012133, loss_ce: 0.004123
 81%|███████████████████████▍     | 323/400 [2:27:22<34:04, 26.55s/it]2022-01-14 17:19:30,422 iteration 5492 : loss : 0.032905, loss_ce: 0.014982
2022-01-14 17:19:31,839 iteration 5493 : loss : 0.012574, loss_ce: 0.003891
2022-01-14 17:19:33,286 iteration 5494 : loss : 0.014399, loss_ce: 0.006667
2022-01-14 17:19:34,828 iteration 5495 : loss : 0.027611, loss_ce: 0.005577
2022-01-14 17:19:36,257 iteration 5496 : loss : 0.014058, loss_ce: 0.004274
2022-01-14 17:19:37,743 iteration 5497 : loss : 0.021606, loss_ce: 0.009037
2022-01-14 17:19:39,268 iteration 5498 : loss : 0.013844, loss_ce: 0.005831
2022-01-14 17:19:40,750 iteration 5499 : loss : 0.015085, loss_ce: 0.004052
2022-01-14 17:19:42,235 iteration 5500 : loss : 0.012894, loss_ce: 0.004263
2022-01-14 17:19:43,686 iteration 5501 : loss : 0.011019, loss_ce: 0.003783
2022-01-14 17:19:45,132 iteration 5502 : loss : 0.013425, loss_ce: 0.006277
2022-01-14 17:19:46,738 iteration 5503 : loss : 0.026099, loss_ce: 0.007664
2022-01-14 17:19:48,241 iteration 5504 : loss : 0.017140, loss_ce: 0.007396
2022-01-14 17:19:49,663 iteration 5505 : loss : 0.012497, loss_ce: 0.004402
2022-01-14 17:19:51,101 iteration 5506 : loss : 0.013630, loss_ce: 0.004971
2022-01-14 17:19:52,662 iteration 5507 : loss : 0.027708, loss_ce: 0.010113
2022-01-14 17:19:54,181 iteration 5508 : loss : 0.019010, loss_ce: 0.008327
 81%|███████████████████████▍     | 324/400 [2:27:47<33:09, 26.18s/it]2022-01-14 17:19:55,746 iteration 5509 : loss : 0.018866, loss_ce: 0.007859
2022-01-14 17:19:57,205 iteration 5510 : loss : 0.014299, loss_ce: 0.005354
2022-01-14 17:19:58,705 iteration 5511 : loss : 0.026870, loss_ce: 0.009795
2022-01-14 17:20:00,175 iteration 5512 : loss : 0.019764, loss_ce: 0.009030
2022-01-14 17:20:01,645 iteration 5513 : loss : 0.016650, loss_ce: 0.009666
2022-01-14 17:20:03,191 iteration 5514 : loss : 0.029225, loss_ce: 0.011247
2022-01-14 17:20:04,661 iteration 5515 : loss : 0.025368, loss_ce: 0.011699
2022-01-14 17:20:06,133 iteration 5516 : loss : 0.012690, loss_ce: 0.006427
2022-01-14 17:20:07,635 iteration 5517 : loss : 0.024878, loss_ce: 0.007398
2022-01-14 17:20:09,044 iteration 5518 : loss : 0.012775, loss_ce: 0.004296
2022-01-14 17:20:10,604 iteration 5519 : loss : 0.020899, loss_ce: 0.005613
2022-01-14 17:20:12,078 iteration 5520 : loss : 0.016843, loss_ce: 0.002861
2022-01-14 17:20:13,646 iteration 5521 : loss : 0.018864, loss_ce: 0.007628
2022-01-14 17:20:15,125 iteration 5522 : loss : 0.013488, loss_ce: 0.005159
2022-01-14 17:20:16,698 iteration 5523 : loss : 0.020838, loss_ce: 0.008832
2022-01-14 17:20:18,306 iteration 5524 : loss : 0.025910, loss_ce: 0.008652
2022-01-14 17:20:18,306 Training Data Eval:
2022-01-14 17:20:25,685   Average segmentation loss on training set: 0.0112
2022-01-14 17:20:25,685 Validation Data Eval:
2022-01-14 17:20:28,224   Average segmentation loss on validation set: 0.1129
2022-01-14 17:20:29,787 iteration 5525 : loss : 0.023327, loss_ce: 0.010321
 81%|███████████████████████▌     | 325/400 [2:28:23<36:15, 29.01s/it]2022-01-14 17:20:31,307 iteration 5526 : loss : 0.022770, loss_ce: 0.006837
2022-01-14 17:20:32,718 iteration 5527 : loss : 0.015522, loss_ce: 0.006245
2022-01-14 17:20:34,268 iteration 5528 : loss : 0.025586, loss_ce: 0.008414
2022-01-14 17:20:35,716 iteration 5529 : loss : 0.012359, loss_ce: 0.004297
2022-01-14 17:20:37,142 iteration 5530 : loss : 0.013813, loss_ce: 0.005440
2022-01-14 17:20:38,528 iteration 5531 : loss : 0.010909, loss_ce: 0.003351
2022-01-14 17:20:39,940 iteration 5532 : loss : 0.015502, loss_ce: 0.005515
2022-01-14 17:20:41,448 iteration 5533 : loss : 0.015182, loss_ce: 0.006683
2022-01-14 17:20:42,852 iteration 5534 : loss : 0.010839, loss_ce: 0.003736
2022-01-14 17:20:44,295 iteration 5535 : loss : 0.013990, loss_ce: 0.005567
2022-01-14 17:20:45,809 iteration 5536 : loss : 0.015092, loss_ce: 0.004837
2022-01-14 17:20:47,327 iteration 5537 : loss : 0.016979, loss_ce: 0.007435
2022-01-14 17:20:48,892 iteration 5538 : loss : 0.013917, loss_ce: 0.003272
2022-01-14 17:20:50,379 iteration 5539 : loss : 0.015470, loss_ce: 0.005003
2022-01-14 17:20:51,787 iteration 5540 : loss : 0.015319, loss_ce: 0.006350
2022-01-14 17:20:53,376 iteration 5541 : loss : 0.023493, loss_ce: 0.009831
2022-01-14 17:20:54,868 iteration 5542 : loss : 0.021529, loss_ce: 0.007711
 82%|███████████████████████▋     | 326/400 [2:28:48<34:19, 27.83s/it]2022-01-14 17:20:56,455 iteration 5543 : loss : 0.023923, loss_ce: 0.010356
2022-01-14 17:20:57,900 iteration 5544 : loss : 0.013556, loss_ce: 0.004634
2022-01-14 17:20:59,419 iteration 5545 : loss : 0.018494, loss_ce: 0.008961
2022-01-14 17:21:00,993 iteration 5546 : loss : 0.056902, loss_ce: 0.014673
2022-01-14 17:21:02,521 iteration 5547 : loss : 0.014770, loss_ce: 0.005749
2022-01-14 17:21:03,980 iteration 5548 : loss : 0.014473, loss_ce: 0.003333
2022-01-14 17:21:05,436 iteration 5549 : loss : 0.015142, loss_ce: 0.004317
2022-01-14 17:21:06,942 iteration 5550 : loss : 0.015350, loss_ce: 0.004931
2022-01-14 17:21:08,395 iteration 5551 : loss : 0.022846, loss_ce: 0.011775
2022-01-14 17:21:09,756 iteration 5552 : loss : 0.014635, loss_ce: 0.004554
2022-01-14 17:21:11,241 iteration 5553 : loss : 0.022931, loss_ce: 0.010343
2022-01-14 17:21:12,703 iteration 5554 : loss : 0.013903, loss_ce: 0.006262
2022-01-14 17:21:14,097 iteration 5555 : loss : 0.014776, loss_ce: 0.006371
2022-01-14 17:21:15,627 iteration 5556 : loss : 0.019890, loss_ce: 0.007070
2022-01-14 17:21:17,131 iteration 5557 : loss : 0.013156, loss_ce: 0.005689
2022-01-14 17:21:18,611 iteration 5558 : loss : 0.019352, loss_ce: 0.006003
2022-01-14 17:21:20,079 iteration 5559 : loss : 0.014413, loss_ce: 0.004025
 82%|███████████████████████▋     | 327/400 [2:29:13<32:54, 27.04s/it]2022-01-14 17:21:21,618 iteration 5560 : loss : 0.013580, loss_ce: 0.004741
2022-01-14 17:21:23,064 iteration 5561 : loss : 0.019290, loss_ce: 0.006913
2022-01-14 17:21:24,526 iteration 5562 : loss : 0.012566, loss_ce: 0.005671
2022-01-14 17:21:25,979 iteration 5563 : loss : 0.016183, loss_ce: 0.006944
2022-01-14 17:21:27,490 iteration 5564 : loss : 0.017495, loss_ce: 0.007587
2022-01-14 17:21:29,011 iteration 5565 : loss : 0.016257, loss_ce: 0.007125
2022-01-14 17:21:30,498 iteration 5566 : loss : 0.018936, loss_ce: 0.008583
2022-01-14 17:21:32,012 iteration 5567 : loss : 0.016594, loss_ce: 0.008857
2022-01-14 17:21:33,471 iteration 5568 : loss : 0.019781, loss_ce: 0.007153
2022-01-14 17:21:34,956 iteration 5569 : loss : 0.015814, loss_ce: 0.005291
2022-01-14 17:21:36,386 iteration 5570 : loss : 0.010515, loss_ce: 0.002963
2022-01-14 17:21:37,765 iteration 5571 : loss : 0.011339, loss_ce: 0.004429
2022-01-14 17:21:39,196 iteration 5572 : loss : 0.017452, loss_ce: 0.006691
2022-01-14 17:21:40,598 iteration 5573 : loss : 0.009979, loss_ce: 0.002932
2022-01-14 17:21:42,062 iteration 5574 : loss : 0.013694, loss_ce: 0.004364
2022-01-14 17:21:43,631 iteration 5575 : loss : 0.026199, loss_ce: 0.008909
2022-01-14 17:21:45,137 iteration 5576 : loss : 0.017715, loss_ce: 0.005883
 82%|███████████████████████▊     | 328/400 [2:29:38<31:44, 26.45s/it]2022-01-14 17:21:46,677 iteration 5577 : loss : 0.015876, loss_ce: 0.007032
2022-01-14 17:21:48,197 iteration 5578 : loss : 0.021010, loss_ce: 0.007075
2022-01-14 17:21:49,744 iteration 5579 : loss : 0.017811, loss_ce: 0.008678
2022-01-14 17:21:51,201 iteration 5580 : loss : 0.020935, loss_ce: 0.007942
2022-01-14 17:21:52,632 iteration 5581 : loss : 0.012810, loss_ce: 0.005103
2022-01-14 17:21:54,116 iteration 5582 : loss : 0.017573, loss_ce: 0.004650
2022-01-14 17:21:55,583 iteration 5583 : loss : 0.009270, loss_ce: 0.003354
2022-01-14 17:21:57,116 iteration 5584 : loss : 0.020947, loss_ce: 0.009711
2022-01-14 17:21:58,573 iteration 5585 : loss : 0.013949, loss_ce: 0.003951
2022-01-14 17:22:00,117 iteration 5586 : loss : 0.019132, loss_ce: 0.006281
2022-01-14 17:22:01,541 iteration 5587 : loss : 0.020686, loss_ce: 0.006916
2022-01-14 17:22:03,006 iteration 5588 : loss : 0.013791, loss_ce: 0.004929
2022-01-14 17:22:04,418 iteration 5589 : loss : 0.010733, loss_ce: 0.003203
2022-01-14 17:22:05,855 iteration 5590 : loss : 0.012929, loss_ce: 0.003634
2022-01-14 17:22:07,302 iteration 5591 : loss : 0.012700, loss_ce: 0.005100
2022-01-14 17:22:08,845 iteration 5592 : loss : 0.023006, loss_ce: 0.007961
2022-01-14 17:22:10,349 iteration 5593 : loss : 0.019732, loss_ce: 0.008269
 82%|███████████████████████▊     | 329/400 [2:30:03<30:51, 26.08s/it]2022-01-14 17:22:11,825 iteration 5594 : loss : 0.015011, loss_ce: 0.004248
2022-01-14 17:22:13,341 iteration 5595 : loss : 0.016729, loss_ce: 0.007667
2022-01-14 17:22:14,795 iteration 5596 : loss : 0.018504, loss_ce: 0.007887
2022-01-14 17:22:16,333 iteration 5597 : loss : 0.016921, loss_ce: 0.005427
2022-01-14 17:22:17,751 iteration 5598 : loss : 0.010903, loss_ce: 0.004392
2022-01-14 17:22:19,223 iteration 5599 : loss : 0.017171, loss_ce: 0.007196
2022-01-14 17:22:20,683 iteration 5600 : loss : 0.011805, loss_ce: 0.004775
2022-01-14 17:22:22,128 iteration 5601 : loss : 0.009287, loss_ce: 0.003342
2022-01-14 17:22:23,621 iteration 5602 : loss : 0.015979, loss_ce: 0.007236
2022-01-14 17:22:25,042 iteration 5603 : loss : 0.010200, loss_ce: 0.004008
2022-01-14 17:22:26,538 iteration 5604 : loss : 0.020872, loss_ce: 0.005266
2022-01-14 17:22:28,047 iteration 5605 : loss : 0.021194, loss_ce: 0.009053
2022-01-14 17:22:29,539 iteration 5606 : loss : 0.018302, loss_ce: 0.006841
2022-01-14 17:22:31,015 iteration 5607 : loss : 0.016942, loss_ce: 0.005041
2022-01-14 17:22:32,491 iteration 5608 : loss : 0.012799, loss_ce: 0.004032
2022-01-14 17:22:34,005 iteration 5609 : loss : 0.016932, loss_ce: 0.007328
2022-01-14 17:22:34,005 Training Data Eval:
2022-01-14 17:22:41,379   Average segmentation loss on training set: 0.0094
2022-01-14 17:22:41,379 Validation Data Eval:
2022-01-14 17:22:43,921   Average segmentation loss on validation set: 0.0899
2022-01-14 17:22:45,352 iteration 5610 : loss : 0.013106, loss_ce: 0.004580
 82%|███████████████████████▉     | 330/400 [2:30:38<33:32, 28.75s/it]2022-01-14 17:22:46,887 iteration 5611 : loss : 0.015492, loss_ce: 0.004975
2022-01-14 17:22:48,378 iteration 5612 : loss : 0.019717, loss_ce: 0.003988
2022-01-14 17:22:49,854 iteration 5613 : loss : 0.013270, loss_ce: 0.004989
2022-01-14 17:22:51,327 iteration 5614 : loss : 0.015058, loss_ce: 0.005623
2022-01-14 17:22:52,720 iteration 5615 : loss : 0.009772, loss_ce: 0.004073
2022-01-14 17:22:54,226 iteration 5616 : loss : 0.013331, loss_ce: 0.005865
2022-01-14 17:22:55,762 iteration 5617 : loss : 0.016571, loss_ce: 0.005977
2022-01-14 17:22:57,268 iteration 5618 : loss : 0.018179, loss_ce: 0.008452
2022-01-14 17:22:58,717 iteration 5619 : loss : 0.018540, loss_ce: 0.005925
2022-01-14 17:23:00,256 iteration 5620 : loss : 0.018116, loss_ce: 0.007096
2022-01-14 17:23:01,662 iteration 5621 : loss : 0.015331, loss_ce: 0.005077
2022-01-14 17:23:03,147 iteration 5622 : loss : 0.017083, loss_ce: 0.006355
2022-01-14 17:23:04,706 iteration 5623 : loss : 0.025427, loss_ce: 0.012870
2022-01-14 17:23:06,130 iteration 5624 : loss : 0.015662, loss_ce: 0.004507
2022-01-14 17:23:07,545 iteration 5625 : loss : 0.018193, loss_ce: 0.010795
2022-01-14 17:23:08,988 iteration 5626 : loss : 0.016800, loss_ce: 0.003999
2022-01-14 17:23:10,491 iteration 5627 : loss : 0.014326, loss_ce: 0.005680
 83%|███████████████████████▉     | 331/400 [2:31:03<31:49, 27.67s/it]2022-01-14 17:23:12,119 iteration 5628 : loss : 0.034278, loss_ce: 0.016639
2022-01-14 17:23:13,557 iteration 5629 : loss : 0.014535, loss_ce: 0.006351
2022-01-14 17:23:15,064 iteration 5630 : loss : 0.014245, loss_ce: 0.005642
2022-01-14 17:23:16,536 iteration 5631 : loss : 0.021136, loss_ce: 0.009633
2022-01-14 17:23:18,056 iteration 5632 : loss : 0.015059, loss_ce: 0.006397
2022-01-14 17:23:19,599 iteration 5633 : loss : 0.025008, loss_ce: 0.008131
2022-01-14 17:23:21,093 iteration 5634 : loss : 0.011050, loss_ce: 0.004465
2022-01-14 17:23:22,559 iteration 5635 : loss : 0.015016, loss_ce: 0.006078
2022-01-14 17:23:24,052 iteration 5636 : loss : 0.017017, loss_ce: 0.004778
2022-01-14 17:23:25,524 iteration 5637 : loss : 0.014512, loss_ce: 0.004675
2022-01-14 17:23:27,012 iteration 5638 : loss : 0.015987, loss_ce: 0.006954
2022-01-14 17:23:28,514 iteration 5639 : loss : 0.016145, loss_ce: 0.006072
2022-01-14 17:23:30,016 iteration 5640 : loss : 0.014983, loss_ce: 0.006636
2022-01-14 17:23:31,446 iteration 5641 : loss : 0.016113, loss_ce: 0.004411
2022-01-14 17:23:32,875 iteration 5642 : loss : 0.017257, loss_ce: 0.007350
2022-01-14 17:23:34,342 iteration 5643 : loss : 0.013421, loss_ce: 0.004401
2022-01-14 17:23:35,796 iteration 5644 : loss : 0.012510, loss_ce: 0.005080
 83%|████████████████████████     | 332/400 [2:31:29<30:33, 26.96s/it]2022-01-14 17:23:37,287 iteration 5645 : loss : 0.012986, loss_ce: 0.004171
2022-01-14 17:23:38,758 iteration 5646 : loss : 0.013810, loss_ce: 0.004565
2022-01-14 17:23:40,274 iteration 5647 : loss : 0.013695, loss_ce: 0.004262
2022-01-14 17:23:41,765 iteration 5648 : loss : 0.017989, loss_ce: 0.005595
2022-01-14 17:23:43,237 iteration 5649 : loss : 0.011943, loss_ce: 0.004557
2022-01-14 17:23:44,759 iteration 5650 : loss : 0.015397, loss_ce: 0.004715
2022-01-14 17:23:46,222 iteration 5651 : loss : 0.014368, loss_ce: 0.006679
2022-01-14 17:23:47,666 iteration 5652 : loss : 0.012626, loss_ce: 0.005315
2022-01-14 17:23:49,119 iteration 5653 : loss : 0.023491, loss_ce: 0.007963
2022-01-14 17:23:50,674 iteration 5654 : loss : 0.015949, loss_ce: 0.007383
2022-01-14 17:23:52,140 iteration 5655 : loss : 0.013552, loss_ce: 0.005199
2022-01-14 17:23:53,644 iteration 5656 : loss : 0.022228, loss_ce: 0.009695
2022-01-14 17:23:55,104 iteration 5657 : loss : 0.016248, loss_ce: 0.008106
2022-01-14 17:23:56,647 iteration 5658 : loss : 0.027353, loss_ce: 0.007523
2022-01-14 17:23:58,216 iteration 5659 : loss : 0.023944, loss_ce: 0.016812
2022-01-14 17:23:59,606 iteration 5660 : loss : 0.010174, loss_ce: 0.003729
2022-01-14 17:24:01,116 iteration 5661 : loss : 0.033024, loss_ce: 0.016286
 83%|████████████████████████▏    | 333/400 [2:31:54<29:33, 26.47s/it]2022-01-14 17:24:02,593 iteration 5662 : loss : 0.012011, loss_ce: 0.005347
2022-01-14 17:24:04,115 iteration 5663 : loss : 0.013015, loss_ce: 0.005807
2022-01-14 17:24:05,655 iteration 5664 : loss : 0.018809, loss_ce: 0.007828
2022-01-14 17:24:07,116 iteration 5665 : loss : 0.011410, loss_ce: 0.002524
2022-01-14 17:24:08,664 iteration 5666 : loss : 0.013471, loss_ce: 0.004598
2022-01-14 17:24:10,168 iteration 5667 : loss : 0.024189, loss_ce: 0.008157
2022-01-14 17:24:11,672 iteration 5668 : loss : 0.021204, loss_ce: 0.007325
2022-01-14 17:24:13,229 iteration 5669 : loss : 0.017907, loss_ce: 0.008157
2022-01-14 17:24:14,732 iteration 5670 : loss : 0.017124, loss_ce: 0.005612
2022-01-14 17:24:16,287 iteration 5671 : loss : 0.017645, loss_ce: 0.005426
2022-01-14 17:24:17,685 iteration 5672 : loss : 0.012912, loss_ce: 0.003673
2022-01-14 17:24:19,151 iteration 5673 : loss : 0.014100, loss_ce: 0.006526
2022-01-14 17:24:20,570 iteration 5674 : loss : 0.023375, loss_ce: 0.008714
2022-01-14 17:24:22,163 iteration 5675 : loss : 0.022648, loss_ce: 0.008956
2022-01-14 17:24:23,640 iteration 5676 : loss : 0.023296, loss_ce: 0.012302
2022-01-14 17:24:25,087 iteration 5677 : loss : 0.014691, loss_ce: 0.005373
2022-01-14 17:24:26,556 iteration 5678 : loss : 0.017145, loss_ce: 0.007188
 84%|████████████████████████▏    | 334/400 [2:32:19<28:46, 26.16s/it]2022-01-14 17:24:28,098 iteration 5679 : loss : 0.018754, loss_ce: 0.006360
2022-01-14 17:24:29,573 iteration 5680 : loss : 0.012992, loss_ce: 0.005668
2022-01-14 17:24:31,117 iteration 5681 : loss : 0.016965, loss_ce: 0.004923
2022-01-14 17:24:32,524 iteration 5682 : loss : 0.011571, loss_ce: 0.003915
2022-01-14 17:24:33,920 iteration 5683 : loss : 0.010191, loss_ce: 0.004326
2022-01-14 17:24:35,456 iteration 5684 : loss : 0.019322, loss_ce: 0.010959
2022-01-14 17:24:36,955 iteration 5685 : loss : 0.012754, loss_ce: 0.004121
2022-01-14 17:24:38,433 iteration 5686 : loss : 0.014579, loss_ce: 0.005315
2022-01-14 17:24:39,942 iteration 5687 : loss : 0.018107, loss_ce: 0.004816
2022-01-14 17:24:41,492 iteration 5688 : loss : 0.022535, loss_ce: 0.010219
2022-01-14 17:24:42,950 iteration 5689 : loss : 0.013469, loss_ce: 0.005521
2022-01-14 17:24:44,388 iteration 5690 : loss : 0.013489, loss_ce: 0.005055
2022-01-14 17:24:45,887 iteration 5691 : loss : 0.014241, loss_ce: 0.006612
2022-01-14 17:24:47,360 iteration 5692 : loss : 0.009345, loss_ce: 0.002733
2022-01-14 17:24:48,714 iteration 5693 : loss : 0.011226, loss_ce: 0.004716
2022-01-14 17:24:50,203 iteration 5694 : loss : 0.012955, loss_ce: 0.005671
2022-01-14 17:24:50,203 Training Data Eval:
2022-01-14 17:24:57,581   Average segmentation loss on training set: 0.0086
2022-01-14 17:24:57,582 Validation Data Eval:
2022-01-14 17:25:00,126   Average segmentation loss on validation set: 0.0941
2022-01-14 17:25:01,614 iteration 5695 : loss : 0.018783, loss_ce: 0.009865
 84%|████████████████████████▎    | 335/400 [2:32:54<31:13, 28.83s/it]2022-01-14 17:25:03,182 iteration 5696 : loss : 0.016688, loss_ce: 0.004958
2022-01-14 17:25:04,612 iteration 5697 : loss : 0.012821, loss_ce: 0.004298
2022-01-14 17:25:06,150 iteration 5698 : loss : 0.019064, loss_ce: 0.006906
2022-01-14 17:25:07,699 iteration 5699 : loss : 0.015238, loss_ce: 0.003822
2022-01-14 17:25:09,091 iteration 5700 : loss : 0.011523, loss_ce: 0.005112
2022-01-14 17:25:10,663 iteration 5701 : loss : 0.029162, loss_ce: 0.004947
2022-01-14 17:25:12,167 iteration 5702 : loss : 0.014727, loss_ce: 0.005501
2022-01-14 17:25:13,716 iteration 5703 : loss : 0.018182, loss_ce: 0.007861
2022-01-14 17:25:15,161 iteration 5704 : loss : 0.014461, loss_ce: 0.005747
2022-01-14 17:25:16,605 iteration 5705 : loss : 0.011828, loss_ce: 0.004765
2022-01-14 17:25:18,038 iteration 5706 : loss : 0.013815, loss_ce: 0.005467
2022-01-14 17:25:19,539 iteration 5707 : loss : 0.023648, loss_ce: 0.006674
2022-01-14 17:25:21,011 iteration 5708 : loss : 0.015849, loss_ce: 0.007536
2022-01-14 17:25:22,436 iteration 5709 : loss : 0.016112, loss_ce: 0.006979
2022-01-14 17:25:23,889 iteration 5710 : loss : 0.016455, loss_ce: 0.008332
2022-01-14 17:25:25,371 iteration 5711 : loss : 0.010671, loss_ce: 0.004612
2022-01-14 17:25:26,850 iteration 5712 : loss : 0.016555, loss_ce: 0.007002
 84%|████████████████████████▎    | 336/400 [2:33:20<29:36, 27.75s/it]2022-01-14 17:25:28,381 iteration 5713 : loss : 0.010089, loss_ce: 0.004377
2022-01-14 17:25:29,889 iteration 5714 : loss : 0.023129, loss_ce: 0.006189
2022-01-14 17:25:31,313 iteration 5715 : loss : 0.013365, loss_ce: 0.005098
2022-01-14 17:25:32,830 iteration 5716 : loss : 0.020818, loss_ce: 0.007455
2022-01-14 17:25:34,240 iteration 5717 : loss : 0.010753, loss_ce: 0.003941
2022-01-14 17:25:35,668 iteration 5718 : loss : 0.023660, loss_ce: 0.010776
2022-01-14 17:25:37,177 iteration 5719 : loss : 0.016425, loss_ce: 0.004342
2022-01-14 17:25:38,707 iteration 5720 : loss : 0.024014, loss_ce: 0.009710
2022-01-14 17:25:40,127 iteration 5721 : loss : 0.014411, loss_ce: 0.004220
2022-01-14 17:25:41,638 iteration 5722 : loss : 0.018257, loss_ce: 0.006268
2022-01-14 17:25:43,178 iteration 5723 : loss : 0.020358, loss_ce: 0.007596
2022-01-14 17:25:44,679 iteration 5724 : loss : 0.013253, loss_ce: 0.005383
2022-01-14 17:25:46,135 iteration 5725 : loss : 0.013263, loss_ce: 0.005333
2022-01-14 17:25:47,648 iteration 5726 : loss : 0.012971, loss_ce: 0.005381
2022-01-14 17:25:49,143 iteration 5727 : loss : 0.018095, loss_ce: 0.009091
2022-01-14 17:25:50,582 iteration 5728 : loss : 0.016317, loss_ce: 0.005307
2022-01-14 17:25:51,984 iteration 5729 : loss : 0.012808, loss_ce: 0.003699
 84%|████████████████████████▍    | 337/400 [2:33:45<28:18, 26.97s/it]2022-01-14 17:25:53,589 iteration 5730 : loss : 0.016304, loss_ce: 0.005770
2022-01-14 17:25:55,134 iteration 5731 : loss : 0.020321, loss_ce: 0.007706
2022-01-14 17:25:56,651 iteration 5732 : loss : 0.021932, loss_ce: 0.005290
2022-01-14 17:25:58,127 iteration 5733 : loss : 0.016469, loss_ce: 0.006549
2022-01-14 17:25:59,570 iteration 5734 : loss : 0.009999, loss_ce: 0.003479
2022-01-14 17:26:01,146 iteration 5735 : loss : 0.035912, loss_ce: 0.017594
2022-01-14 17:26:02,695 iteration 5736 : loss : 0.016167, loss_ce: 0.006718
2022-01-14 17:26:04,168 iteration 5737 : loss : 0.015194, loss_ce: 0.006555
2022-01-14 17:26:05,612 iteration 5738 : loss : 0.017873, loss_ce: 0.008468
2022-01-14 17:26:07,107 iteration 5739 : loss : 0.016927, loss_ce: 0.004894
2022-01-14 17:26:08,643 iteration 5740 : loss : 0.017523, loss_ce: 0.007324
2022-01-14 17:26:10,138 iteration 5741 : loss : 0.011943, loss_ce: 0.005165
2022-01-14 17:26:11,591 iteration 5742 : loss : 0.020718, loss_ce: 0.004797
2022-01-14 17:26:13,081 iteration 5743 : loss : 0.013145, loss_ce: 0.004062
2022-01-14 17:26:14,521 iteration 5744 : loss : 0.013032, loss_ce: 0.005710
2022-01-14 17:26:16,018 iteration 5745 : loss : 0.011706, loss_ce: 0.003928
2022-01-14 17:26:17,460 iteration 5746 : loss : 0.016265, loss_ce: 0.007732
 84%|████████████████████████▌    | 338/400 [2:34:10<27:24, 26.52s/it]2022-01-14 17:26:19,019 iteration 5747 : loss : 0.016161, loss_ce: 0.006059
2022-01-14 17:26:20,471 iteration 5748 : loss : 0.018574, loss_ce: 0.006584
2022-01-14 17:26:21,998 iteration 5749 : loss : 0.022305, loss_ce: 0.010117
2022-01-14 17:26:23,493 iteration 5750 : loss : 0.013378, loss_ce: 0.003759
2022-01-14 17:26:25,033 iteration 5751 : loss : 0.018438, loss_ce: 0.007870
2022-01-14 17:26:26,526 iteration 5752 : loss : 0.015576, loss_ce: 0.005556
2022-01-14 17:26:28,047 iteration 5753 : loss : 0.021201, loss_ce: 0.013041
2022-01-14 17:26:29,515 iteration 5754 : loss : 0.013999, loss_ce: 0.004876
2022-01-14 17:26:30,970 iteration 5755 : loss : 0.016359, loss_ce: 0.005120
2022-01-14 17:26:32,418 iteration 5756 : loss : 0.017257, loss_ce: 0.008427
2022-01-14 17:26:33,913 iteration 5757 : loss : 0.015098, loss_ce: 0.004466
2022-01-14 17:26:35,328 iteration 5758 : loss : 0.008949, loss_ce: 0.002601
2022-01-14 17:26:36,864 iteration 5759 : loss : 0.015257, loss_ce: 0.004166
2022-01-14 17:26:38,336 iteration 5760 : loss : 0.012733, loss_ce: 0.004677
2022-01-14 17:26:39,848 iteration 5761 : loss : 0.012901, loss_ce: 0.004626
2022-01-14 17:26:41,401 iteration 5762 : loss : 0.029590, loss_ce: 0.010580
2022-01-14 17:26:42,914 iteration 5763 : loss : 0.018493, loss_ce: 0.007811
 85%|████████████████████████▌    | 339/400 [2:34:36<26:38, 26.20s/it]2022-01-14 17:26:44,509 iteration 5764 : loss : 0.021851, loss_ce: 0.007719
2022-01-14 17:26:46,010 iteration 5765 : loss : 0.016588, loss_ce: 0.005799
2022-01-14 17:26:47,460 iteration 5766 : loss : 0.016146, loss_ce: 0.005355
2022-01-14 17:26:48,986 iteration 5767 : loss : 0.014989, loss_ce: 0.006413
2022-01-14 17:26:50,516 iteration 5768 : loss : 0.025023, loss_ce: 0.007683
2022-01-14 17:26:52,026 iteration 5769 : loss : 0.016486, loss_ce: 0.004281
2022-01-14 17:26:53,537 iteration 5770 : loss : 0.028137, loss_ce: 0.010871
2022-01-14 17:26:54,940 iteration 5771 : loss : 0.010623, loss_ce: 0.004516
2022-01-14 17:26:56,433 iteration 5772 : loss : 0.012912, loss_ce: 0.004729
2022-01-14 17:26:57,842 iteration 5773 : loss : 0.012190, loss_ce: 0.004305
2022-01-14 17:26:59,277 iteration 5774 : loss : 0.011603, loss_ce: 0.004396
2022-01-14 17:27:00,775 iteration 5775 : loss : 0.019593, loss_ce: 0.007824
2022-01-14 17:27:02,149 iteration 5776 : loss : 0.016837, loss_ce: 0.006648
2022-01-14 17:27:03,603 iteration 5777 : loss : 0.011213, loss_ce: 0.003867
2022-01-14 17:27:05,102 iteration 5778 : loss : 0.012681, loss_ce: 0.004359
2022-01-14 17:27:06,587 iteration 5779 : loss : 0.010496, loss_ce: 0.004467
2022-01-14 17:27:06,587 Training Data Eval:
2022-01-14 17:27:13,952   Average segmentation loss on training set: 0.0083
2022-01-14 17:27:13,953 Validation Data Eval:
2022-01-14 17:27:16,494   Average segmentation loss on validation set: 0.0735
2022-01-14 17:27:17,951 iteration 5780 : loss : 0.012390, loss_ce: 0.004575
 85%|████████████████████████▋    | 340/400 [2:35:11<28:51, 28.85s/it]2022-01-14 17:27:19,472 iteration 5781 : loss : 0.016116, loss_ce: 0.005528
2022-01-14 17:27:20,862 iteration 5782 : loss : 0.009465, loss_ce: 0.003465
2022-01-14 17:27:22,358 iteration 5783 : loss : 0.014122, loss_ce: 0.004203
2022-01-14 17:27:23,864 iteration 5784 : loss : 0.012505, loss_ce: 0.003931
2022-01-14 17:27:25,358 iteration 5785 : loss : 0.011340, loss_ce: 0.005787
2022-01-14 17:27:26,898 iteration 5786 : loss : 0.013351, loss_ce: 0.005426
2022-01-14 17:27:28,408 iteration 5787 : loss : 0.015915, loss_ce: 0.005391
2022-01-14 17:27:29,898 iteration 5788 : loss : 0.020001, loss_ce: 0.007798
2022-01-14 17:27:31,379 iteration 5789 : loss : 0.014976, loss_ce: 0.004302
2022-01-14 17:27:32,891 iteration 5790 : loss : 0.018745, loss_ce: 0.008790
2022-01-14 17:27:34,410 iteration 5791 : loss : 0.011442, loss_ce: 0.004346
2022-01-14 17:27:35,962 iteration 5792 : loss : 0.015206, loss_ce: 0.004738
2022-01-14 17:27:37,406 iteration 5793 : loss : 0.012930, loss_ce: 0.005199
2022-01-14 17:27:38,845 iteration 5794 : loss : 0.016085, loss_ce: 0.005364
2022-01-14 17:27:40,301 iteration 5795 : loss : 0.016972, loss_ce: 0.007006
2022-01-14 17:27:41,759 iteration 5796 : loss : 0.011575, loss_ce: 0.004261
2022-01-14 17:27:43,207 iteration 5797 : loss : 0.012638, loss_ce: 0.004067
 85%|████████████████████████▋    | 341/400 [2:35:36<27:18, 27.77s/it]2022-01-14 17:27:44,685 iteration 5798 : loss : 0.011443, loss_ce: 0.003791
2022-01-14 17:27:46,122 iteration 5799 : loss : 0.012323, loss_ce: 0.004530
2022-01-14 17:27:47,492 iteration 5800 : loss : 0.010473, loss_ce: 0.004707
2022-01-14 17:27:48,966 iteration 5801 : loss : 0.014248, loss_ce: 0.006857
2022-01-14 17:27:50,389 iteration 5802 : loss : 0.012065, loss_ce: 0.004915
2022-01-14 17:27:51,900 iteration 5803 : loss : 0.013905, loss_ce: 0.004548
2022-01-14 17:27:53,329 iteration 5804 : loss : 0.013401, loss_ce: 0.004484
2022-01-14 17:27:54,752 iteration 5805 : loss : 0.014449, loss_ce: 0.004071
2022-01-14 17:27:56,160 iteration 5806 : loss : 0.011851, loss_ce: 0.005639
2022-01-14 17:27:57,655 iteration 5807 : loss : 0.015764, loss_ce: 0.006105
2022-01-14 17:27:59,174 iteration 5808 : loss : 0.027291, loss_ce: 0.008295
2022-01-14 17:28:00,695 iteration 5809 : loss : 0.016146, loss_ce: 0.005692
2022-01-14 17:28:02,258 iteration 5810 : loss : 0.018933, loss_ce: 0.005368
2022-01-14 17:28:03,785 iteration 5811 : loss : 0.013655, loss_ce: 0.005591
2022-01-14 17:28:05,242 iteration 5812 : loss : 0.013810, loss_ce: 0.005993
2022-01-14 17:28:06,675 iteration 5813 : loss : 0.014057, loss_ce: 0.004349
2022-01-14 17:28:08,125 iteration 5814 : loss : 0.017873, loss_ce: 0.006046
 86%|████████████████████████▊    | 342/400 [2:36:01<26:01, 26.92s/it]2022-01-14 17:28:09,704 iteration 5815 : loss : 0.019129, loss_ce: 0.006512
2022-01-14 17:28:11,170 iteration 5816 : loss : 0.012151, loss_ce: 0.004384
2022-01-14 17:28:12,752 iteration 5817 : loss : 0.017220, loss_ce: 0.007949
2022-01-14 17:28:14,283 iteration 5818 : loss : 0.017726, loss_ce: 0.007113
2022-01-14 17:28:15,744 iteration 5819 : loss : 0.013637, loss_ce: 0.003369
2022-01-14 17:28:17,186 iteration 5820 : loss : 0.015278, loss_ce: 0.005231
2022-01-14 17:28:18,680 iteration 5821 : loss : 0.013009, loss_ce: 0.004661
2022-01-14 17:28:20,231 iteration 5822 : loss : 0.018017, loss_ce: 0.005294
2022-01-14 17:28:21,652 iteration 5823 : loss : 0.011729, loss_ce: 0.005625
2022-01-14 17:28:23,212 iteration 5824 : loss : 0.023797, loss_ce: 0.005284
2022-01-14 17:28:24,705 iteration 5825 : loss : 0.014234, loss_ce: 0.004719
2022-01-14 17:28:26,192 iteration 5826 : loss : 0.013167, loss_ce: 0.005699
2022-01-14 17:28:27,616 iteration 5827 : loss : 0.018036, loss_ce: 0.007172
2022-01-14 17:28:29,171 iteration 5828 : loss : 0.023386, loss_ce: 0.004777
2022-01-14 17:28:30,641 iteration 5829 : loss : 0.013796, loss_ce: 0.004764
2022-01-14 17:28:32,067 iteration 5830 : loss : 0.013415, loss_ce: 0.004499
2022-01-14 17:28:33,612 iteration 5831 : loss : 0.023477, loss_ce: 0.009267
 86%|████████████████████████▊    | 343/400 [2:36:26<25:09, 26.49s/it]2022-01-14 17:28:35,167 iteration 5832 : loss : 0.015887, loss_ce: 0.006772
2022-01-14 17:28:36,710 iteration 5833 : loss : 0.022205, loss_ce: 0.006661
2022-01-14 17:28:38,187 iteration 5834 : loss : 0.013817, loss_ce: 0.006519
2022-01-14 17:28:39,651 iteration 5835 : loss : 0.016356, loss_ce: 0.006303
2022-01-14 17:28:41,106 iteration 5836 : loss : 0.016946, loss_ce: 0.005813
2022-01-14 17:28:42,650 iteration 5837 : loss : 0.022488, loss_ce: 0.008652
2022-01-14 17:28:44,129 iteration 5838 : loss : 0.014829, loss_ce: 0.004038
2022-01-14 17:28:45,610 iteration 5839 : loss : 0.022998, loss_ce: 0.008306
2022-01-14 17:28:47,083 iteration 5840 : loss : 0.012270, loss_ce: 0.004668
2022-01-14 17:28:48,610 iteration 5841 : loss : 0.018803, loss_ce: 0.006154
2022-01-14 17:28:50,038 iteration 5842 : loss : 0.013181, loss_ce: 0.003952
2022-01-14 17:28:51,463 iteration 5843 : loss : 0.012430, loss_ce: 0.004727
2022-01-14 17:28:52,943 iteration 5844 : loss : 0.015723, loss_ce: 0.005986
2022-01-14 17:28:54,366 iteration 5845 : loss : 0.011174, loss_ce: 0.004215
2022-01-14 17:28:55,806 iteration 5846 : loss : 0.011094, loss_ce: 0.004240
2022-01-14 17:28:57,244 iteration 5847 : loss : 0.014326, loss_ce: 0.005590
2022-01-14 17:28:58,690 iteration 5848 : loss : 0.012737, loss_ce: 0.004406
 86%|████████████████████████▉    | 344/400 [2:36:51<24:19, 26.07s/it]2022-01-14 17:29:00,218 iteration 5849 : loss : 0.016824, loss_ce: 0.005240
2022-01-14 17:29:01,764 iteration 5850 : loss : 0.016804, loss_ce: 0.009303
2022-01-14 17:29:03,280 iteration 5851 : loss : 0.012109, loss_ce: 0.003089
2022-01-14 17:29:04,776 iteration 5852 : loss : 0.017419, loss_ce: 0.009660
2022-01-14 17:29:06,213 iteration 5853 : loss : 0.017097, loss_ce: 0.006041
2022-01-14 17:29:07,737 iteration 5854 : loss : 0.017354, loss_ce: 0.006410
2022-01-14 17:29:09,209 iteration 5855 : loss : 0.012854, loss_ce: 0.005773
2022-01-14 17:29:10,685 iteration 5856 : loss : 0.017199, loss_ce: 0.006594
2022-01-14 17:29:12,188 iteration 5857 : loss : 0.014549, loss_ce: 0.005495
2022-01-14 17:29:13,706 iteration 5858 : loss : 0.013400, loss_ce: 0.004881
2022-01-14 17:29:15,277 iteration 5859 : loss : 0.023942, loss_ce: 0.008545
2022-01-14 17:29:16,775 iteration 5860 : loss : 0.011614, loss_ce: 0.003964
2022-01-14 17:29:18,229 iteration 5861 : loss : 0.015216, loss_ce: 0.006419
2022-01-14 17:29:19,723 iteration 5862 : loss : 0.013662, loss_ce: 0.005605
2022-01-14 17:29:21,210 iteration 5863 : loss : 0.037828, loss_ce: 0.009700
2022-01-14 17:29:22,781 iteration 5864 : loss : 0.020226, loss_ce: 0.009000
2022-01-14 17:29:22,781 Training Data Eval:
2022-01-14 17:29:30,146   Average segmentation loss on training set: 0.0083
2022-01-14 17:29:30,146 Validation Data Eval:
2022-01-14 17:29:32,685   Average segmentation loss on validation set: 0.0710
2022-01-14 17:29:34,246 iteration 5865 : loss : 0.021759, loss_ce: 0.005967
 86%|█████████████████████████    | 345/400 [2:37:27<26:30, 28.91s/it]2022-01-14 17:29:35,705 iteration 5866 : loss : 0.014874, loss_ce: 0.003787
2022-01-14 17:29:37,156 iteration 5867 : loss : 0.012132, loss_ce: 0.005287
2022-01-14 17:29:38,670 iteration 5868 : loss : 0.012670, loss_ce: 0.004700
2022-01-14 17:29:40,144 iteration 5869 : loss : 0.014806, loss_ce: 0.004623
2022-01-14 17:29:41,797 iteration 5870 : loss : 0.019928, loss_ce: 0.007916
2022-01-14 17:29:43,293 iteration 5871 : loss : 0.013382, loss_ce: 0.004538
2022-01-14 17:29:44,759 iteration 5872 : loss : 0.014933, loss_ce: 0.004761
2022-01-14 17:29:46,253 iteration 5873 : loss : 0.018569, loss_ce: 0.011480
2022-01-14 17:29:47,746 iteration 5874 : loss : 0.017791, loss_ce: 0.005946
2022-01-14 17:29:49,240 iteration 5875 : loss : 0.013231, loss_ce: 0.006310
2022-01-14 17:29:50,804 iteration 5876 : loss : 0.014034, loss_ce: 0.005482
2022-01-14 17:29:52,336 iteration 5877 : loss : 0.024663, loss_ce: 0.009829
2022-01-14 17:29:53,759 iteration 5878 : loss : 0.012651, loss_ce: 0.003717
2022-01-14 17:29:55,225 iteration 5879 : loss : 0.016968, loss_ce: 0.006186
2022-01-14 17:29:56,724 iteration 5880 : loss : 0.016668, loss_ce: 0.004481
2022-01-14 17:29:58,163 iteration 5881 : loss : 0.011640, loss_ce: 0.004575
2022-01-14 17:29:59,580 iteration 5882 : loss : 0.013239, loss_ce: 0.004311
 86%|█████████████████████████    | 346/400 [2:37:52<25:03, 27.84s/it]2022-01-14 17:30:01,061 iteration 5883 : loss : 0.012836, loss_ce: 0.003614
2022-01-14 17:30:02,447 iteration 5884 : loss : 0.011144, loss_ce: 0.004142
2022-01-14 17:30:03,979 iteration 5885 : loss : 0.015861, loss_ce: 0.004055
2022-01-14 17:30:05,440 iteration 5886 : loss : 0.016045, loss_ce: 0.004899
2022-01-14 17:30:06,956 iteration 5887 : loss : 0.014563, loss_ce: 0.005195
2022-01-14 17:30:08,431 iteration 5888 : loss : 0.010852, loss_ce: 0.004500
2022-01-14 17:30:09,971 iteration 5889 : loss : 0.012834, loss_ce: 0.004235
2022-01-14 17:30:11,437 iteration 5890 : loss : 0.017163, loss_ce: 0.006731
2022-01-14 17:30:12,913 iteration 5891 : loss : 0.025869, loss_ce: 0.007690
2022-01-14 17:30:14,417 iteration 5892 : loss : 0.021389, loss_ce: 0.006260
2022-01-14 17:30:15,872 iteration 5893 : loss : 0.022235, loss_ce: 0.010414
2022-01-14 17:30:17,289 iteration 5894 : loss : 0.016253, loss_ce: 0.006838
2022-01-14 17:30:18,705 iteration 5895 : loss : 0.010320, loss_ce: 0.004064
2022-01-14 17:30:20,131 iteration 5896 : loss : 0.016379, loss_ce: 0.006470
2022-01-14 17:30:21,602 iteration 5897 : loss : 0.015637, loss_ce: 0.007107
2022-01-14 17:30:23,037 iteration 5898 : loss : 0.023676, loss_ce: 0.006954
2022-01-14 17:30:24,547 iteration 5899 : loss : 0.016672, loss_ce: 0.007104
 87%|█████████████████████████▏   | 347/400 [2:38:17<23:49, 26.98s/it]2022-01-14 17:30:25,998 iteration 5900 : loss : 0.013502, loss_ce: 0.004691
2022-01-14 17:30:27,572 iteration 5901 : loss : 0.016899, loss_ce: 0.008145
2022-01-14 17:30:29,132 iteration 5902 : loss : 0.018585, loss_ce: 0.008402
2022-01-14 17:30:30,598 iteration 5903 : loss : 0.017099, loss_ce: 0.005760
2022-01-14 17:30:32,084 iteration 5904 : loss : 0.014332, loss_ce: 0.006659
2022-01-14 17:30:33,501 iteration 5905 : loss : 0.014594, loss_ce: 0.005227
2022-01-14 17:30:34,963 iteration 5906 : loss : 0.015773, loss_ce: 0.006471
2022-01-14 17:30:36,448 iteration 5907 : loss : 0.019076, loss_ce: 0.007415
2022-01-14 17:30:37,917 iteration 5908 : loss : 0.022224, loss_ce: 0.007141
2022-01-14 17:30:39,344 iteration 5909 : loss : 0.010583, loss_ce: 0.004066
2022-01-14 17:30:40,791 iteration 5910 : loss : 0.014051, loss_ce: 0.006168
2022-01-14 17:30:42,245 iteration 5911 : loss : 0.013003, loss_ce: 0.005568
2022-01-14 17:30:43,833 iteration 5912 : loss : 0.042628, loss_ce: 0.007807
2022-01-14 17:30:45,239 iteration 5913 : loss : 0.014044, loss_ce: 0.004759
2022-01-14 17:30:46,783 iteration 5914 : loss : 0.022041, loss_ce: 0.008326
2022-01-14 17:30:48,303 iteration 5915 : loss : 0.025215, loss_ce: 0.011814
2022-01-14 17:30:49,779 iteration 5916 : loss : 0.014565, loss_ce: 0.005280
 87%|█████████████████████████▏   | 348/400 [2:38:43<22:55, 26.45s/it]2022-01-14 17:30:51,309 iteration 5917 : loss : 0.016624, loss_ce: 0.003778
2022-01-14 17:30:52,877 iteration 5918 : loss : 0.020286, loss_ce: 0.007904
2022-01-14 17:30:54,313 iteration 5919 : loss : 0.014315, loss_ce: 0.008947
2022-01-14 17:30:55,893 iteration 5920 : loss : 0.016328, loss_ce: 0.006270
2022-01-14 17:30:57,363 iteration 5921 : loss : 0.012814, loss_ce: 0.003847
2022-01-14 17:30:58,877 iteration 5922 : loss : 0.019438, loss_ce: 0.009806
2022-01-14 17:31:00,341 iteration 5923 : loss : 0.016271, loss_ce: 0.003821
2022-01-14 17:31:01,774 iteration 5924 : loss : 0.012331, loss_ce: 0.004912
2022-01-14 17:31:03,228 iteration 5925 : loss : 0.015356, loss_ce: 0.004708
2022-01-14 17:31:04,694 iteration 5926 : loss : 0.014904, loss_ce: 0.005700
2022-01-14 17:31:06,239 iteration 5927 : loss : 0.017555, loss_ce: 0.006264
2022-01-14 17:31:07,627 iteration 5928 : loss : 0.012155, loss_ce: 0.005074
2022-01-14 17:31:09,053 iteration 5929 : loss : 0.020646, loss_ce: 0.005056
2022-01-14 17:31:10,539 iteration 5930 : loss : 0.016162, loss_ce: 0.005955
2022-01-14 17:31:12,024 iteration 5931 : loss : 0.016189, loss_ce: 0.007092
2022-01-14 17:31:13,485 iteration 5932 : loss : 0.015980, loss_ce: 0.005618
2022-01-14 17:31:14,916 iteration 5933 : loss : 0.011224, loss_ce: 0.004522
 87%|█████████████████████████▎   | 349/400 [2:39:08<22:09, 26.06s/it]2022-01-14 17:31:16,373 iteration 5934 : loss : 0.011542, loss_ce: 0.004006
2022-01-14 17:31:17,782 iteration 5935 : loss : 0.013681, loss_ce: 0.006290
2022-01-14 17:31:19,183 iteration 5936 : loss : 0.012734, loss_ce: 0.004874
2022-01-14 17:31:20,684 iteration 5937 : loss : 0.018502, loss_ce: 0.008370
2022-01-14 17:31:22,184 iteration 5938 : loss : 0.017195, loss_ce: 0.008891
2022-01-14 17:31:23,724 iteration 5939 : loss : 0.025235, loss_ce: 0.008492
2022-01-14 17:31:25,168 iteration 5940 : loss : 0.010436, loss_ce: 0.003683
2022-01-14 17:31:26,684 iteration 5941 : loss : 0.012932, loss_ce: 0.004727
2022-01-14 17:31:28,167 iteration 5942 : loss : 0.012674, loss_ce: 0.004874
2022-01-14 17:31:29,690 iteration 5943 : loss : 0.015578, loss_ce: 0.005728
2022-01-14 17:31:31,078 iteration 5944 : loss : 0.015978, loss_ce: 0.006359
2022-01-14 17:31:32,668 iteration 5945 : loss : 0.029269, loss_ce: 0.008036
2022-01-14 17:31:34,163 iteration 5946 : loss : 0.011993, loss_ce: 0.004956
2022-01-14 17:31:35,786 iteration 5947 : loss : 0.018981, loss_ce: 0.006180
2022-01-14 17:31:37,329 iteration 5948 : loss : 0.033598, loss_ce: 0.009306
2022-01-14 17:31:38,798 iteration 5949 : loss : 0.020793, loss_ce: 0.006548
2022-01-14 17:31:38,798 Training Data Eval:
2022-01-14 17:31:46,165   Average segmentation loss on training set: 0.0082
2022-01-14 17:31:46,166 Validation Data Eval:
2022-01-14 17:31:48,712   Average segmentation loss on validation set: 0.0781
2022-01-14 17:31:50,126 iteration 5950 : loss : 0.010324, loss_ce: 0.003282
 88%|█████████████████████████▍   | 350/400 [2:39:43<24:00, 28.81s/it]2022-01-14 17:31:51,569 iteration 5951 : loss : 0.019060, loss_ce: 0.005772
2022-01-14 17:31:53,054 iteration 5952 : loss : 0.015472, loss_ce: 0.007057
2022-01-14 17:31:54,628 iteration 5953 : loss : 0.022020, loss_ce: 0.009919
2022-01-14 17:31:56,074 iteration 5954 : loss : 0.016177, loss_ce: 0.004102
2022-01-14 17:31:57,655 iteration 5955 : loss : 0.018723, loss_ce: 0.006594
2022-01-14 17:31:59,109 iteration 5956 : loss : 0.019591, loss_ce: 0.004531
2022-01-14 17:32:00,618 iteration 5957 : loss : 0.040973, loss_ce: 0.017137
2022-01-14 17:32:02,138 iteration 5958 : loss : 0.020312, loss_ce: 0.009289
2022-01-14 17:32:03,645 iteration 5959 : loss : 0.015411, loss_ce: 0.003909
2022-01-14 17:32:05,092 iteration 5960 : loss : 0.018187, loss_ce: 0.005593
2022-01-14 17:32:06,606 iteration 5961 : loss : 0.019197, loss_ce: 0.010071
2022-01-14 17:32:08,113 iteration 5962 : loss : 0.014977, loss_ce: 0.005114
2022-01-14 17:32:09,573 iteration 5963 : loss : 0.017500, loss_ce: 0.006386
2022-01-14 17:32:11,124 iteration 5964 : loss : 0.017163, loss_ce: 0.007167
2022-01-14 17:32:12,623 iteration 5965 : loss : 0.011284, loss_ce: 0.005401
2022-01-14 17:32:14,080 iteration 5966 : loss : 0.010922, loss_ce: 0.003712
2022-01-14 17:32:15,639 iteration 5967 : loss : 0.014140, loss_ce: 0.004977
 88%|█████████████████████████▍   | 351/400 [2:40:08<22:42, 27.82s/it]2022-01-14 17:32:17,143 iteration 5968 : loss : 0.015159, loss_ce: 0.006072
2022-01-14 17:32:18,616 iteration 5969 : loss : 0.015043, loss_ce: 0.007652
2022-01-14 17:32:20,124 iteration 5970 : loss : 0.015851, loss_ce: 0.006249
2022-01-14 17:32:21,558 iteration 5971 : loss : 0.011834, loss_ce: 0.005071
2022-01-14 17:32:22,981 iteration 5972 : loss : 0.016079, loss_ce: 0.003928
2022-01-14 17:32:24,408 iteration 5973 : loss : 0.016109, loss_ce: 0.006876
2022-01-14 17:32:25,873 iteration 5974 : loss : 0.022180, loss_ce: 0.007072
2022-01-14 17:32:27,355 iteration 5975 : loss : 0.021942, loss_ce: 0.013008
2022-01-14 17:32:28,861 iteration 5976 : loss : 0.014218, loss_ce: 0.005093
2022-01-14 17:32:30,283 iteration 5977 : loss : 0.014431, loss_ce: 0.004993
2022-01-14 17:32:31,740 iteration 5978 : loss : 0.019329, loss_ce: 0.006494
2022-01-14 17:32:33,210 iteration 5979 : loss : 0.018061, loss_ce: 0.005118
2022-01-14 17:32:34,750 iteration 5980 : loss : 0.022053, loss_ce: 0.004859
2022-01-14 17:32:36,306 iteration 5981 : loss : 0.028297, loss_ce: 0.010527
2022-01-14 17:32:37,797 iteration 5982 : loss : 0.027831, loss_ce: 0.012222
2022-01-14 17:32:39,287 iteration 5983 : loss : 0.019074, loss_ce: 0.004899
2022-01-14 17:32:40,835 iteration 5984 : loss : 0.018535, loss_ce: 0.006311
 88%|█████████████████████████▌   | 352/400 [2:40:34<21:37, 27.03s/it]2022-01-14 17:32:42,405 iteration 5985 : loss : 0.019545, loss_ce: 0.006566
2022-01-14 17:32:43,788 iteration 5986 : loss : 0.010695, loss_ce: 0.004993
2022-01-14 17:32:45,313 iteration 5987 : loss : 0.028027, loss_ce: 0.007854
2022-01-14 17:32:46,717 iteration 5988 : loss : 0.012235, loss_ce: 0.004984
2022-01-14 17:32:48,203 iteration 5989 : loss : 0.013116, loss_ce: 0.004993
2022-01-14 17:32:49,659 iteration 5990 : loss : 0.014912, loss_ce: 0.005143
2022-01-14 17:32:51,206 iteration 5991 : loss : 0.021893, loss_ce: 0.005995
2022-01-14 17:32:52,740 iteration 5992 : loss : 0.022248, loss_ce: 0.005806
2022-01-14 17:32:54,231 iteration 5993 : loss : 0.015276, loss_ce: 0.005910
2022-01-14 17:32:55,631 iteration 5994 : loss : 0.011343, loss_ce: 0.005033
2022-01-14 17:32:57,187 iteration 5995 : loss : 0.018124, loss_ce: 0.005978
2022-01-14 17:32:58,700 iteration 5996 : loss : 0.011672, loss_ce: 0.005668
2022-01-14 17:33:00,132 iteration 5997 : loss : 0.014456, loss_ce: 0.004193
2022-01-14 17:33:01,719 iteration 5998 : loss : 0.019668, loss_ce: 0.007722
2022-01-14 17:33:03,170 iteration 5999 : loss : 0.016750, loss_ce: 0.005687
2022-01-14 17:33:04,763 iteration 6000 : loss : 0.019212, loss_ce: 0.006892
2022-01-14 17:33:06,188 iteration 6001 : loss : 0.010638, loss_ce: 0.003910
 88%|█████████████████████████▌   | 353/400 [2:40:59<20:46, 26.52s/it]2022-01-14 17:33:07,646 iteration 6002 : loss : 0.015186, loss_ce: 0.005506
2022-01-14 17:33:09,143 iteration 6003 : loss : 0.011471, loss_ce: 0.005210
2022-01-14 17:33:10,600 iteration 6004 : loss : 0.013631, loss_ce: 0.005541
2022-01-14 17:33:12,044 iteration 6005 : loss : 0.015226, loss_ce: 0.006152
2022-01-14 17:33:13,569 iteration 6006 : loss : 0.025751, loss_ce: 0.010482
2022-01-14 17:33:14,999 iteration 6007 : loss : 0.012990, loss_ce: 0.004788
2022-01-14 17:33:16,465 iteration 6008 : loss : 0.017605, loss_ce: 0.006310
2022-01-14 17:33:17,981 iteration 6009 : loss : 0.016499, loss_ce: 0.004961
2022-01-14 17:33:19,409 iteration 6010 : loss : 0.015934, loss_ce: 0.003354
2022-01-14 17:33:20,919 iteration 6011 : loss : 0.016615, loss_ce: 0.005017
2022-01-14 17:33:22,458 iteration 6012 : loss : 0.015623, loss_ce: 0.006873
2022-01-14 17:33:23,922 iteration 6013 : loss : 0.016757, loss_ce: 0.006521
2022-01-14 17:33:25,351 iteration 6014 : loss : 0.013737, loss_ce: 0.005108
2022-01-14 17:33:26,739 iteration 6015 : loss : 0.012378, loss_ce: 0.006200
2022-01-14 17:33:28,184 iteration 6016 : loss : 0.016976, loss_ce: 0.004566
2022-01-14 17:33:29,662 iteration 6017 : loss : 0.017673, loss_ce: 0.006903
2022-01-14 17:33:31,053 iteration 6018 : loss : 0.013977, loss_ce: 0.005678
 88%|█████████████████████████▋   | 354/400 [2:41:24<19:57, 26.03s/it]2022-01-14 17:33:32,613 iteration 6019 : loss : 0.016309, loss_ce: 0.006378
2022-01-14 17:33:34,107 iteration 6020 : loss : 0.017405, loss_ce: 0.005838
2022-01-14 17:33:35,536 iteration 6021 : loss : 0.009853, loss_ce: 0.003598
2022-01-14 17:33:37,044 iteration 6022 : loss : 0.014858, loss_ce: 0.005671
2022-01-14 17:33:38,561 iteration 6023 : loss : 0.015192, loss_ce: 0.006421
2022-01-14 17:33:40,045 iteration 6024 : loss : 0.010438, loss_ce: 0.004022
2022-01-14 17:33:41,464 iteration 6025 : loss : 0.018622, loss_ce: 0.003867
2022-01-14 17:33:42,913 iteration 6026 : loss : 0.024462, loss_ce: 0.008698
2022-01-14 17:33:44,436 iteration 6027 : loss : 0.011104, loss_ce: 0.004812
2022-01-14 17:33:45,891 iteration 6028 : loss : 0.011502, loss_ce: 0.005327
2022-01-14 17:33:47,370 iteration 6029 : loss : 0.015133, loss_ce: 0.006708
2022-01-14 17:33:48,901 iteration 6030 : loss : 0.018079, loss_ce: 0.008302
2022-01-14 17:33:50,419 iteration 6031 : loss : 0.021073, loss_ce: 0.006229
2022-01-14 17:33:51,904 iteration 6032 : loss : 0.031010, loss_ce: 0.009799
2022-01-14 17:33:53,371 iteration 6033 : loss : 0.024537, loss_ce: 0.008976
2022-01-14 17:33:54,799 iteration 6034 : loss : 0.011115, loss_ce: 0.003986
2022-01-14 17:33:54,799 Training Data Eval:
2022-01-14 17:34:02,162   Average segmentation loss on training set: 0.0081
2022-01-14 17:34:02,162 Validation Data Eval:
2022-01-14 17:34:04,706   Average segmentation loss on validation set: 0.0777
2022-01-14 17:34:06,128 iteration 6035 : loss : 0.014209, loss_ce: 0.006263
 89%|█████████████████████████▋   | 355/400 [2:41:59<21:33, 28.74s/it]2022-01-14 17:34:07,679 iteration 6036 : loss : 0.013201, loss_ce: 0.005935
2022-01-14 17:34:09,092 iteration 6037 : loss : 0.011786, loss_ce: 0.004981
2022-01-14 17:34:10,522 iteration 6038 : loss : 0.011648, loss_ce: 0.004451
2022-01-14 17:34:11,894 iteration 6039 : loss : 0.011187, loss_ce: 0.003732
2022-01-14 17:34:13,325 iteration 6040 : loss : 0.014593, loss_ce: 0.004185
2022-01-14 17:34:14,840 iteration 6041 : loss : 0.014577, loss_ce: 0.005849
2022-01-14 17:34:16,259 iteration 6042 : loss : 0.013413, loss_ce: 0.003380
2022-01-14 17:34:17,648 iteration 6043 : loss : 0.008819, loss_ce: 0.002207
2022-01-14 17:34:19,143 iteration 6044 : loss : 0.013134, loss_ce: 0.003773
2022-01-14 17:34:20,599 iteration 6045 : loss : 0.010477, loss_ce: 0.003978
2022-01-14 17:34:22,090 iteration 6046 : loss : 0.014839, loss_ce: 0.005675
2022-01-14 17:34:23,570 iteration 6047 : loss : 0.010914, loss_ce: 0.004072
2022-01-14 17:34:25,105 iteration 6048 : loss : 0.016316, loss_ce: 0.007021
2022-01-14 17:34:26,581 iteration 6049 : loss : 0.011843, loss_ce: 0.005839
2022-01-14 17:34:28,045 iteration 6050 : loss : 0.011756, loss_ce: 0.004003
2022-01-14 17:34:29,624 iteration 6051 : loss : 0.012854, loss_ce: 0.004151
2022-01-14 17:34:31,076 iteration 6052 : loss : 0.012802, loss_ce: 0.005403
 89%|█████████████████████████▊   | 356/400 [2:42:24<20:14, 27.60s/it]2022-01-14 17:34:32,544 iteration 6053 : loss : 0.012935, loss_ce: 0.004874
2022-01-14 17:34:33,946 iteration 6054 : loss : 0.012175, loss_ce: 0.006075
2022-01-14 17:34:35,460 iteration 6055 : loss : 0.012968, loss_ce: 0.004384
2022-01-14 17:34:36,914 iteration 6056 : loss : 0.012917, loss_ce: 0.005526
2022-01-14 17:34:38,339 iteration 6057 : loss : 0.011626, loss_ce: 0.003374
2022-01-14 17:34:39,826 iteration 6058 : loss : 0.015219, loss_ce: 0.004676
2022-01-14 17:34:41,348 iteration 6059 : loss : 0.016183, loss_ce: 0.007893
2022-01-14 17:34:42,961 iteration 6060 : loss : 0.042364, loss_ce: 0.014942
2022-01-14 17:34:44,437 iteration 6061 : loss : 0.012373, loss_ce: 0.005196
2022-01-14 17:34:45,988 iteration 6062 : loss : 0.024715, loss_ce: 0.007481
2022-01-14 17:34:47,421 iteration 6063 : loss : 0.018132, loss_ce: 0.005585
2022-01-14 17:34:48,966 iteration 6064 : loss : 0.014748, loss_ce: 0.006346
2022-01-14 17:34:50,384 iteration 6065 : loss : 0.008731, loss_ce: 0.003430
2022-01-14 17:34:51,809 iteration 6066 : loss : 0.010069, loss_ce: 0.003159
2022-01-14 17:34:53,267 iteration 6067 : loss : 0.010944, loss_ce: 0.004562
2022-01-14 17:34:54,695 iteration 6068 : loss : 0.010627, loss_ce: 0.002836
2022-01-14 17:34:56,147 iteration 6069 : loss : 0.021369, loss_ce: 0.008844
 89%|█████████████████████████▉   | 357/400 [2:42:49<19:14, 26.85s/it]2022-01-14 17:34:57,662 iteration 6070 : loss : 0.009090, loss_ce: 0.004635
2022-01-14 17:34:59,080 iteration 6071 : loss : 0.010729, loss_ce: 0.003519
2022-01-14 17:35:00,515 iteration 6072 : loss : 0.011014, loss_ce: 0.005695
2022-01-14 17:35:01,989 iteration 6073 : loss : 0.011632, loss_ce: 0.003959
2022-01-14 17:35:03,490 iteration 6074 : loss : 0.016035, loss_ce: 0.006848
2022-01-14 17:35:04,875 iteration 6075 : loss : 0.009984, loss_ce: 0.004289
2022-01-14 17:35:06,322 iteration 6076 : loss : 0.013078, loss_ce: 0.003036
2022-01-14 17:35:07,797 iteration 6077 : loss : 0.014168, loss_ce: 0.005442
2022-01-14 17:35:09,322 iteration 6078 : loss : 0.024341, loss_ce: 0.008896
2022-01-14 17:35:10,906 iteration 6079 : loss : 0.016482, loss_ce: 0.006353
2022-01-14 17:35:12,388 iteration 6080 : loss : 0.021113, loss_ce: 0.007962
2022-01-14 17:35:13,899 iteration 6081 : loss : 0.024862, loss_ce: 0.010592
2022-01-14 17:35:15,294 iteration 6082 : loss : 0.018070, loss_ce: 0.004986
2022-01-14 17:35:16,717 iteration 6083 : loss : 0.012697, loss_ce: 0.003279
2022-01-14 17:35:18,191 iteration 6084 : loss : 0.035547, loss_ce: 0.009689
2022-01-14 17:35:19,644 iteration 6085 : loss : 0.022019, loss_ce: 0.006109
2022-01-14 17:35:21,090 iteration 6086 : loss : 0.012132, loss_ce: 0.004221
 90%|█████████████████████████▉   | 358/400 [2:43:14<18:23, 26.27s/it]2022-01-14 17:35:22,546 iteration 6087 : loss : 0.012500, loss_ce: 0.003981
2022-01-14 17:35:24,051 iteration 6088 : loss : 0.011363, loss_ce: 0.004429
2022-01-14 17:35:25,504 iteration 6089 : loss : 0.015583, loss_ce: 0.004775
2022-01-14 17:35:26,868 iteration 6090 : loss : 0.010533, loss_ce: 0.004627
2022-01-14 17:35:28,349 iteration 6091 : loss : 0.010886, loss_ce: 0.003847
2022-01-14 17:35:29,834 iteration 6092 : loss : 0.013997, loss_ce: 0.003958
2022-01-14 17:35:31,296 iteration 6093 : loss : 0.015261, loss_ce: 0.006919
2022-01-14 17:35:32,727 iteration 6094 : loss : 0.013267, loss_ce: 0.004586
2022-01-14 17:35:34,160 iteration 6095 : loss : 0.012858, loss_ce: 0.004062
2022-01-14 17:35:35,646 iteration 6096 : loss : 0.018202, loss_ce: 0.005281
2022-01-14 17:35:37,140 iteration 6097 : loss : 0.009137, loss_ce: 0.003516
2022-01-14 17:35:38,701 iteration 6098 : loss : 0.019848, loss_ce: 0.007397
2022-01-14 17:35:40,227 iteration 6099 : loss : 0.013378, loss_ce: 0.005535
2022-01-14 17:35:41,735 iteration 6100 : loss : 0.013181, loss_ce: 0.006151
2022-01-14 17:35:43,226 iteration 6101 : loss : 0.018669, loss_ce: 0.007616
2022-01-14 17:35:44,740 iteration 6102 : loss : 0.023153, loss_ce: 0.011720
2022-01-14 17:35:46,267 iteration 6103 : loss : 0.017454, loss_ce: 0.006586
 90%|██████████████████████████   | 359/400 [2:43:39<17:43, 25.95s/it]2022-01-14 17:35:47,855 iteration 6104 : loss : 0.015223, loss_ce: 0.006836
2022-01-14 17:35:49,390 iteration 6105 : loss : 0.015347, loss_ce: 0.006683
2022-01-14 17:35:50,891 iteration 6106 : loss : 0.017763, loss_ce: 0.009067
2022-01-14 17:35:52,371 iteration 6107 : loss : 0.014943, loss_ce: 0.005728
2022-01-14 17:35:53,827 iteration 6108 : loss : 0.011230, loss_ce: 0.004457
2022-01-14 17:35:55,290 iteration 6109 : loss : 0.014925, loss_ce: 0.003463
2022-01-14 17:35:56,732 iteration 6110 : loss : 0.011848, loss_ce: 0.005131
2022-01-14 17:35:58,185 iteration 6111 : loss : 0.014759, loss_ce: 0.006649
2022-01-14 17:35:59,649 iteration 6112 : loss : 0.023446, loss_ce: 0.005639
2022-01-14 17:36:01,121 iteration 6113 : loss : 0.013236, loss_ce: 0.005508
2022-01-14 17:36:02,635 iteration 6114 : loss : 0.015377, loss_ce: 0.005219
2022-01-14 17:36:04,100 iteration 6115 : loss : 0.014811, loss_ce: 0.005331
2022-01-14 17:36:05,591 iteration 6116 : loss : 0.014550, loss_ce: 0.004320
2022-01-14 17:36:07,022 iteration 6117 : loss : 0.012087, loss_ce: 0.004702
2022-01-14 17:36:08,438 iteration 6118 : loss : 0.010955, loss_ce: 0.003634
2022-01-14 17:36:10,002 iteration 6119 : loss : 0.016908, loss_ce: 0.007431
2022-01-14 17:36:10,002 Training Data Eval:
2022-01-14 17:36:17,359   Average segmentation loss on training set: 0.0075
2022-01-14 17:36:17,360 Validation Data Eval:
2022-01-14 17:36:19,897   Average segmentation loss on validation set: 0.0704
2022-01-14 17:36:21,353 iteration 6120 : loss : 0.013722, loss_ce: 0.003972
 90%|██████████████████████████   | 360/400 [2:44:14<19:07, 28.69s/it]2022-01-14 17:36:22,847 iteration 6121 : loss : 0.013747, loss_ce: 0.003785
2022-01-14 17:36:24,347 iteration 6122 : loss : 0.013839, loss_ce: 0.005324
2022-01-14 17:36:25,813 iteration 6123 : loss : 0.016322, loss_ce: 0.006871
2022-01-14 17:36:27,230 iteration 6124 : loss : 0.010112, loss_ce: 0.003644
2022-01-14 17:36:28,700 iteration 6125 : loss : 0.019523, loss_ce: 0.007236
2022-01-14 17:36:30,127 iteration 6126 : loss : 0.011309, loss_ce: 0.005854
2022-01-14 17:36:31,630 iteration 6127 : loss : 0.012217, loss_ce: 0.003817
2022-01-14 17:36:33,082 iteration 6128 : loss : 0.014729, loss_ce: 0.005061
2022-01-14 17:36:34,643 iteration 6129 : loss : 0.011255, loss_ce: 0.004137
2022-01-14 17:36:36,087 iteration 6130 : loss : 0.012883, loss_ce: 0.003397
2022-01-14 17:36:37,646 iteration 6131 : loss : 0.015947, loss_ce: 0.008299
2022-01-14 17:36:39,100 iteration 6132 : loss : 0.018840, loss_ce: 0.011373
2022-01-14 17:36:40,598 iteration 6133 : loss : 0.015551, loss_ce: 0.004324
2022-01-14 17:36:42,081 iteration 6134 : loss : 0.017823, loss_ce: 0.006220
2022-01-14 17:36:43,654 iteration 6135 : loss : 0.030551, loss_ce: 0.011054
2022-01-14 17:36:45,128 iteration 6136 : loss : 0.014951, loss_ce: 0.003801
2022-01-14 17:36:46,565 iteration 6137 : loss : 0.012805, loss_ce: 0.005251
 90%|██████████████████████████▏  | 361/400 [2:44:39<17:58, 27.64s/it]2022-01-14 17:36:48,041 iteration 6138 : loss : 0.013887, loss_ce: 0.004542
2022-01-14 17:36:49,509 iteration 6139 : loss : 0.012791, loss_ce: 0.005176
2022-01-14 17:36:50,984 iteration 6140 : loss : 0.011948, loss_ce: 0.005347
2022-01-14 17:36:52,388 iteration 6141 : loss : 0.010292, loss_ce: 0.003879
2022-01-14 17:36:53,770 iteration 6142 : loss : 0.009360, loss_ce: 0.003939
2022-01-14 17:36:55,291 iteration 6143 : loss : 0.016992, loss_ce: 0.004864
2022-01-14 17:36:56,749 iteration 6144 : loss : 0.018704, loss_ce: 0.007190
2022-01-14 17:36:58,194 iteration 6145 : loss : 0.013674, loss_ce: 0.005705
2022-01-14 17:36:59,619 iteration 6146 : loss : 0.014697, loss_ce: 0.004219
2022-01-14 17:37:01,074 iteration 6147 : loss : 0.010854, loss_ce: 0.004465
2022-01-14 17:37:02,587 iteration 6148 : loss : 0.013760, loss_ce: 0.004725
2022-01-14 17:37:04,090 iteration 6149 : loss : 0.016843, loss_ce: 0.005688
2022-01-14 17:37:05,642 iteration 6150 : loss : 0.019865, loss_ce: 0.006489
2022-01-14 17:37:07,193 iteration 6151 : loss : 0.015477, loss_ce: 0.003703
2022-01-14 17:37:08,623 iteration 6152 : loss : 0.013124, loss_ce: 0.004963
2022-01-14 17:37:10,111 iteration 6153 : loss : 0.013982, loss_ce: 0.003776
2022-01-14 17:37:11,611 iteration 6154 : loss : 0.019165, loss_ce: 0.008424
 90%|██████████████████████████▏  | 362/400 [2:45:04<17:00, 26.86s/it]2022-01-14 17:37:13,178 iteration 6155 : loss : 0.016736, loss_ce: 0.006011
2022-01-14 17:37:14,686 iteration 6156 : loss : 0.023976, loss_ce: 0.010744
2022-01-14 17:37:16,174 iteration 6157 : loss : 0.016545, loss_ce: 0.006392
2022-01-14 17:37:17,728 iteration 6158 : loss : 0.013848, loss_ce: 0.003949
2022-01-14 17:37:19,170 iteration 6159 : loss : 0.010326, loss_ce: 0.003395
2022-01-14 17:37:20,624 iteration 6160 : loss : 0.012867, loss_ce: 0.004464
2022-01-14 17:37:22,136 iteration 6161 : loss : 0.017095, loss_ce: 0.004769
2022-01-14 17:37:23,680 iteration 6162 : loss : 0.022197, loss_ce: 0.007319
2022-01-14 17:37:25,161 iteration 6163 : loss : 0.016175, loss_ce: 0.006709
2022-01-14 17:37:26,562 iteration 6164 : loss : 0.012691, loss_ce: 0.003398
2022-01-14 17:37:28,093 iteration 6165 : loss : 0.018207, loss_ce: 0.006737
2022-01-14 17:37:29,537 iteration 6166 : loss : 0.015979, loss_ce: 0.005566
2022-01-14 17:37:31,076 iteration 6167 : loss : 0.020496, loss_ce: 0.010581
2022-01-14 17:37:32,570 iteration 6168 : loss : 0.015220, loss_ce: 0.005564
2022-01-14 17:37:34,035 iteration 6169 : loss : 0.018298, loss_ce: 0.004795
2022-01-14 17:37:35,483 iteration 6170 : loss : 0.011626, loss_ce: 0.005668
2022-01-14 17:37:36,934 iteration 6171 : loss : 0.014969, loss_ce: 0.007156
 91%|██████████████████████████▎  | 363/400 [2:45:30<16:16, 26.40s/it]2022-01-14 17:37:38,429 iteration 6172 : loss : 0.013906, loss_ce: 0.004888
2022-01-14 17:37:39,982 iteration 6173 : loss : 0.028564, loss_ce: 0.007106
2022-01-14 17:37:41,480 iteration 6174 : loss : 0.013219, loss_ce: 0.005264
2022-01-14 17:37:43,066 iteration 6175 : loss : 0.016398, loss_ce: 0.005218
2022-01-14 17:37:44,566 iteration 6176 : loss : 0.014306, loss_ce: 0.005252
2022-01-14 17:37:46,036 iteration 6177 : loss : 0.015623, loss_ce: 0.008311
2022-01-14 17:37:47,521 iteration 6178 : loss : 0.017811, loss_ce: 0.005974
2022-01-14 17:37:48,958 iteration 6179 : loss : 0.016831, loss_ce: 0.005051
2022-01-14 17:37:50,484 iteration 6180 : loss : 0.018623, loss_ce: 0.008058
2022-01-14 17:37:51,922 iteration 6181 : loss : 0.010140, loss_ce: 0.003317
2022-01-14 17:37:53,365 iteration 6182 : loss : 0.014079, loss_ce: 0.003310
2022-01-14 17:37:54,889 iteration 6183 : loss : 0.014215, loss_ce: 0.005657
2022-01-14 17:37:56,384 iteration 6184 : loss : 0.015652, loss_ce: 0.006414
2022-01-14 17:37:57,920 iteration 6185 : loss : 0.022031, loss_ce: 0.006109
2022-01-14 17:37:59,383 iteration 6186 : loss : 0.011464, loss_ce: 0.004084
2022-01-14 17:38:00,876 iteration 6187 : loss : 0.014371, loss_ce: 0.007514
2022-01-14 17:38:02,437 iteration 6188 : loss : 0.019082, loss_ce: 0.008891
 91%|██████████████████████████▍  | 364/400 [2:45:55<15:40, 26.13s/it]2022-01-14 17:38:04,025 iteration 6189 : loss : 0.015926, loss_ce: 0.003129
2022-01-14 17:38:05,566 iteration 6190 : loss : 0.019563, loss_ce: 0.004737
2022-01-14 17:38:07,022 iteration 6191 : loss : 0.013140, loss_ce: 0.006510
2022-01-14 17:38:08,436 iteration 6192 : loss : 0.009692, loss_ce: 0.003739
2022-01-14 17:38:09,900 iteration 6193 : loss : 0.016790, loss_ce: 0.005422
2022-01-14 17:38:11,317 iteration 6194 : loss : 0.013445, loss_ce: 0.005517
2022-01-14 17:38:12,877 iteration 6195 : loss : 0.016187, loss_ce: 0.005019
2022-01-14 17:38:14,339 iteration 6196 : loss : 0.014460, loss_ce: 0.004887
2022-01-14 17:38:15,757 iteration 6197 : loss : 0.011084, loss_ce: 0.005343
2022-01-14 17:38:17,349 iteration 6198 : loss : 0.020047, loss_ce: 0.005837
2022-01-14 17:38:18,833 iteration 6199 : loss : 0.013247, loss_ce: 0.005363
2022-01-14 17:38:20,285 iteration 6200 : loss : 0.011957, loss_ce: 0.005091
2022-01-14 17:38:21,770 iteration 6201 : loss : 0.013004, loss_ce: 0.005174
2022-01-14 17:38:23,183 iteration 6202 : loss : 0.017818, loss_ce: 0.005715
2022-01-14 17:38:24,807 iteration 6203 : loss : 0.018227, loss_ce: 0.008627
2022-01-14 17:38:26,224 iteration 6204 : loss : 0.010089, loss_ce: 0.004445
2022-01-14 17:38:26,225 Training Data Eval:
2022-01-14 17:38:33,584   Average segmentation loss on training set: 0.0075
2022-01-14 17:38:33,585 Validation Data Eval:
2022-01-14 17:38:36,126   Average segmentation loss on validation set: 0.0686
2022-01-14 17:38:37,649 iteration 6205 : loss : 0.017779, loss_ce: 0.005548
 91%|██████████████████████████▍  | 365/400 [2:46:30<16:50, 28.86s/it]2022-01-14 17:38:39,190 iteration 6206 : loss : 0.022889, loss_ce: 0.011190
2022-01-14 17:38:40,689 iteration 6207 : loss : 0.011679, loss_ce: 0.004274
2022-01-14 17:38:42,212 iteration 6208 : loss : 0.019968, loss_ce: 0.006745
2022-01-14 17:38:43,697 iteration 6209 : loss : 0.013692, loss_ce: 0.004827
2022-01-14 17:38:45,191 iteration 6210 : loss : 0.009488, loss_ce: 0.003310
2022-01-14 17:38:46,653 iteration 6211 : loss : 0.013844, loss_ce: 0.006831
2022-01-14 17:38:48,090 iteration 6212 : loss : 0.011109, loss_ce: 0.004083
2022-01-14 17:38:49,472 iteration 6213 : loss : 0.010322, loss_ce: 0.003677
2022-01-14 17:38:51,017 iteration 6214 : loss : 0.032942, loss_ce: 0.011926
2022-01-14 17:38:52,485 iteration 6215 : loss : 0.011850, loss_ce: 0.003257
2022-01-14 17:38:53,968 iteration 6216 : loss : 0.014259, loss_ce: 0.004682
2022-01-14 17:38:55,477 iteration 6217 : loss : 0.018926, loss_ce: 0.007550
2022-01-14 17:38:56,904 iteration 6218 : loss : 0.014067, loss_ce: 0.006017
2022-01-14 17:38:58,395 iteration 6219 : loss : 0.017258, loss_ce: 0.005827
2022-01-14 17:38:59,788 iteration 6220 : loss : 0.010679, loss_ce: 0.002759
2022-01-14 17:39:01,340 iteration 6221 : loss : 0.013728, loss_ce: 0.004271
2022-01-14 17:39:02,857 iteration 6222 : loss : 0.012114, loss_ce: 0.005477
 92%|██████████████████████████▌  | 366/400 [2:46:56<15:43, 27.76s/it]2022-01-14 17:39:04,434 iteration 6223 : loss : 0.015988, loss_ce: 0.006715
2022-01-14 17:39:05,989 iteration 6224 : loss : 0.019841, loss_ce: 0.010296
2022-01-14 17:39:07,536 iteration 6225 : loss : 0.010670, loss_ce: 0.004776
2022-01-14 17:39:09,012 iteration 6226 : loss : 0.012236, loss_ce: 0.004678
2022-01-14 17:39:10,569 iteration 6227 : loss : 0.011126, loss_ce: 0.003612
2022-01-14 17:39:12,036 iteration 6228 : loss : 0.018594, loss_ce: 0.006987
2022-01-14 17:39:13,545 iteration 6229 : loss : 0.027162, loss_ce: 0.007905
2022-01-14 17:39:15,072 iteration 6230 : loss : 0.031363, loss_ce: 0.006018
2022-01-14 17:39:16,498 iteration 6231 : loss : 0.012431, loss_ce: 0.005349
2022-01-14 17:39:17,953 iteration 6232 : loss : 0.017443, loss_ce: 0.006885
2022-01-14 17:39:19,503 iteration 6233 : loss : 0.020828, loss_ce: 0.007933
2022-01-14 17:39:20,966 iteration 6234 : loss : 0.026725, loss_ce: 0.011056
2022-01-14 17:39:22,436 iteration 6235 : loss : 0.015138, loss_ce: 0.004651
2022-01-14 17:39:23,960 iteration 6236 : loss : 0.024966, loss_ce: 0.010027
2022-01-14 17:39:25,459 iteration 6237 : loss : 0.016832, loss_ce: 0.005166
2022-01-14 17:39:26,990 iteration 6238 : loss : 0.014718, loss_ce: 0.005434
2022-01-14 17:39:28,538 iteration 6239 : loss : 0.027018, loss_ce: 0.011630
 92%|██████████████████████████▌  | 367/400 [2:47:21<14:55, 27.14s/it]2022-01-14 17:39:30,019 iteration 6240 : loss : 0.013216, loss_ce: 0.004461
2022-01-14 17:39:31,443 iteration 6241 : loss : 0.012028, loss_ce: 0.004920
2022-01-14 17:39:32,943 iteration 6242 : loss : 0.016954, loss_ce: 0.007631
2022-01-14 17:39:34,417 iteration 6243 : loss : 0.011683, loss_ce: 0.004448
2022-01-14 17:39:35,900 iteration 6244 : loss : 0.020302, loss_ce: 0.008226
2022-01-14 17:39:37,395 iteration 6245 : loss : 0.010857, loss_ce: 0.004080
2022-01-14 17:39:38,849 iteration 6246 : loss : 0.011621, loss_ce: 0.004589
2022-01-14 17:39:40,285 iteration 6247 : loss : 0.013140, loss_ce: 0.004060
2022-01-14 17:39:41,788 iteration 6248 : loss : 0.034237, loss_ce: 0.007860
2022-01-14 17:39:43,298 iteration 6249 : loss : 0.016210, loss_ce: 0.005864
2022-01-14 17:39:44,675 iteration 6250 : loss : 0.014125, loss_ce: 0.003313
2022-01-14 17:39:46,195 iteration 6251 : loss : 0.020646, loss_ce: 0.010840
2022-01-14 17:39:47,600 iteration 6252 : loss : 0.010021, loss_ce: 0.003099
2022-01-14 17:39:49,167 iteration 6253 : loss : 0.014108, loss_ce: 0.005424
2022-01-14 17:39:50,556 iteration 6254 : loss : 0.008581, loss_ce: 0.003700
2022-01-14 17:39:52,175 iteration 6255 : loss : 0.032867, loss_ce: 0.010891
2022-01-14 17:39:53,623 iteration 6256 : loss : 0.024302, loss_ce: 0.008889
 92%|██████████████████████████▋  | 368/400 [2:47:46<14:08, 26.52s/it]2022-01-14 17:39:55,186 iteration 6257 : loss : 0.016812, loss_ce: 0.007997
2022-01-14 17:39:56,645 iteration 6258 : loss : 0.014148, loss_ce: 0.007467
2022-01-14 17:39:58,147 iteration 6259 : loss : 0.019361, loss_ce: 0.007630
2022-01-14 17:39:59,618 iteration 6260 : loss : 0.015770, loss_ce: 0.004126
2022-01-14 17:40:01,052 iteration 6261 : loss : 0.012720, loss_ce: 0.005037
2022-01-14 17:40:02,557 iteration 6262 : loss : 0.013045, loss_ce: 0.005383
2022-01-14 17:40:04,080 iteration 6263 : loss : 0.019728, loss_ce: 0.005597
2022-01-14 17:40:05,542 iteration 6264 : loss : 0.015086, loss_ce: 0.006911
2022-01-14 17:40:06,972 iteration 6265 : loss : 0.016329, loss_ce: 0.007938
2022-01-14 17:40:08,450 iteration 6266 : loss : 0.010862, loss_ce: 0.004672
2022-01-14 17:40:09,927 iteration 6267 : loss : 0.018638, loss_ce: 0.006549
2022-01-14 17:40:11,391 iteration 6268 : loss : 0.020794, loss_ce: 0.007556
2022-01-14 17:40:12,837 iteration 6269 : loss : 0.020105, loss_ce: 0.006171
2022-01-14 17:40:14,362 iteration 6270 : loss : 0.015960, loss_ce: 0.004605
2022-01-14 17:40:15,837 iteration 6271 : loss : 0.020351, loss_ce: 0.004305
2022-01-14 17:40:17,292 iteration 6272 : loss : 0.010567, loss_ce: 0.002977
2022-01-14 17:40:18,686 iteration 6273 : loss : 0.009881, loss_ce: 0.004088
 92%|██████████████████████████▊  | 369/400 [2:48:11<13:28, 26.08s/it]2022-01-14 17:40:20,182 iteration 6274 : loss : 0.013700, loss_ce: 0.004245
2022-01-14 17:40:21,651 iteration 6275 : loss : 0.020849, loss_ce: 0.008664
2022-01-14 17:40:23,112 iteration 6276 : loss : 0.015939, loss_ce: 0.005174
2022-01-14 17:40:24,642 iteration 6277 : loss : 0.023572, loss_ce: 0.005348
2022-01-14 17:40:26,187 iteration 6278 : loss : 0.025531, loss_ce: 0.010506
2022-01-14 17:40:27,783 iteration 6279 : loss : 0.022947, loss_ce: 0.006913
2022-01-14 17:40:29,275 iteration 6280 : loss : 0.012792, loss_ce: 0.005984
2022-01-14 17:40:30,741 iteration 6281 : loss : 0.011761, loss_ce: 0.003669
2022-01-14 17:40:32,185 iteration 6282 : loss : 0.011667, loss_ce: 0.004408
2022-01-14 17:40:33,713 iteration 6283 : loss : 0.018096, loss_ce: 0.004959
2022-01-14 17:40:35,265 iteration 6284 : loss : 0.016515, loss_ce: 0.007498
2022-01-14 17:40:36,747 iteration 6285 : loss : 0.014496, loss_ce: 0.005696
2022-01-14 17:40:38,224 iteration 6286 : loss : 0.019829, loss_ce: 0.011059
2022-01-14 17:40:39,746 iteration 6287 : loss : 0.011294, loss_ce: 0.003860
2022-01-14 17:40:41,290 iteration 6288 : loss : 0.018901, loss_ce: 0.006553
2022-01-14 17:40:42,744 iteration 6289 : loss : 0.013266, loss_ce: 0.005213
2022-01-14 17:40:42,745 Training Data Eval:
2022-01-14 17:40:50,103   Average segmentation loss on training set: 0.0077
2022-01-14 17:40:50,104 Validation Data Eval:
2022-01-14 17:40:52,652   Average segmentation loss on validation set: 0.0736
2022-01-14 17:40:54,091 iteration 6290 : loss : 0.013352, loss_ce: 0.004532
 92%|██████████████████████████▊  | 370/400 [2:48:47<14:26, 28.88s/it]2022-01-14 17:40:55,603 iteration 6291 : loss : 0.011723, loss_ce: 0.002710
2022-01-14 17:40:57,171 iteration 6292 : loss : 0.013124, loss_ce: 0.004430
2022-01-14 17:40:58,647 iteration 6293 : loss : 0.022137, loss_ce: 0.007766
2022-01-14 17:41:00,144 iteration 6294 : loss : 0.016634, loss_ce: 0.006573
2022-01-14 17:41:01,648 iteration 6295 : loss : 0.017584, loss_ce: 0.006566
2022-01-14 17:41:03,101 iteration 6296 : loss : 0.011219, loss_ce: 0.003981
2022-01-14 17:41:04,573 iteration 6297 : loss : 0.016295, loss_ce: 0.004802
2022-01-14 17:41:06,019 iteration 6298 : loss : 0.010916, loss_ce: 0.003580
2022-01-14 17:41:07,539 iteration 6299 : loss : 0.017065, loss_ce: 0.006849
2022-01-14 17:41:09,013 iteration 6300 : loss : 0.018356, loss_ce: 0.006060
2022-01-14 17:41:10,453 iteration 6301 : loss : 0.013933, loss_ce: 0.005366
2022-01-14 17:41:11,880 iteration 6302 : loss : 0.011930, loss_ce: 0.004892
2022-01-14 17:41:13,373 iteration 6303 : loss : 0.015992, loss_ce: 0.006325
2022-01-14 17:41:14,820 iteration 6304 : loss : 0.012556, loss_ce: 0.004706
2022-01-14 17:41:16,221 iteration 6305 : loss : 0.011818, loss_ce: 0.004904
2022-01-14 17:41:17,631 iteration 6306 : loss : 0.012457, loss_ce: 0.004377
2022-01-14 17:41:19,172 iteration 6307 : loss : 0.014931, loss_ce: 0.005405
 93%|██████████████████████████▉  | 371/400 [2:49:12<13:24, 27.74s/it]2022-01-14 17:41:20,652 iteration 6308 : loss : 0.011704, loss_ce: 0.004758
2022-01-14 17:41:22,150 iteration 6309 : loss : 0.016034, loss_ce: 0.006423
2022-01-14 17:41:23,639 iteration 6310 : loss : 0.014915, loss_ce: 0.005694
2022-01-14 17:41:25,081 iteration 6311 : loss : 0.014390, loss_ce: 0.003900
2022-01-14 17:41:26,587 iteration 6312 : loss : 0.016641, loss_ce: 0.005573
2022-01-14 17:41:28,041 iteration 6313 : loss : 0.015566, loss_ce: 0.002932
2022-01-14 17:41:29,555 iteration 6314 : loss : 0.017437, loss_ce: 0.006515
2022-01-14 17:41:31,091 iteration 6315 : loss : 0.016225, loss_ce: 0.005550
2022-01-14 17:41:32,586 iteration 6316 : loss : 0.016722, loss_ce: 0.008386
2022-01-14 17:41:34,110 iteration 6317 : loss : 0.010875, loss_ce: 0.003854
2022-01-14 17:41:35,659 iteration 6318 : loss : 0.015473, loss_ce: 0.007073
2022-01-14 17:41:37,236 iteration 6319 : loss : 0.013930, loss_ce: 0.004427
2022-01-14 17:41:38,812 iteration 6320 : loss : 0.013481, loss_ce: 0.005570
2022-01-14 17:41:40,343 iteration 6321 : loss : 0.015455, loss_ce: 0.006349
2022-01-14 17:41:41,899 iteration 6322 : loss : 0.015875, loss_ce: 0.006012
2022-01-14 17:41:43,251 iteration 6323 : loss : 0.010280, loss_ce: 0.004628
2022-01-14 17:41:44,735 iteration 6324 : loss : 0.014846, loss_ce: 0.003872
 93%|██████████████████████████▉  | 372/400 [2:49:38<12:38, 27.09s/it]2022-01-14 17:41:46,197 iteration 6325 : loss : 0.012518, loss_ce: 0.004318
2022-01-14 17:41:47,601 iteration 6326 : loss : 0.010105, loss_ce: 0.004630
2022-01-14 17:41:48,992 iteration 6327 : loss : 0.010422, loss_ce: 0.003698
2022-01-14 17:41:50,529 iteration 6328 : loss : 0.015599, loss_ce: 0.006727
2022-01-14 17:41:52,102 iteration 6329 : loss : 0.013615, loss_ce: 0.004809
2022-01-14 17:41:53,600 iteration 6330 : loss : 0.009614, loss_ce: 0.003665
2022-01-14 17:41:55,135 iteration 6331 : loss : 0.014323, loss_ce: 0.006607
2022-01-14 17:41:56,592 iteration 6332 : loss : 0.014082, loss_ce: 0.004918
2022-01-14 17:41:58,057 iteration 6333 : loss : 0.013206, loss_ce: 0.005154
2022-01-14 17:41:59,556 iteration 6334 : loss : 0.011057, loss_ce: 0.004681
2022-01-14 17:42:01,184 iteration 6335 : loss : 0.021758, loss_ce: 0.009867
2022-01-14 17:42:02,697 iteration 6336 : loss : 0.011741, loss_ce: 0.004309
2022-01-14 17:42:04,100 iteration 6337 : loss : 0.011766, loss_ce: 0.004760
2022-01-14 17:42:05,651 iteration 6338 : loss : 0.015926, loss_ce: 0.005714
2022-01-14 17:42:07,101 iteration 6339 : loss : 0.013129, loss_ce: 0.003849
2022-01-14 17:42:08,587 iteration 6340 : loss : 0.017286, loss_ce: 0.007754
2022-01-14 17:42:10,095 iteration 6341 : loss : 0.017366, loss_ce: 0.005102
 93%|███████████████████████████  | 373/400 [2:50:03<11:57, 26.57s/it]2022-01-14 17:42:11,730 iteration 6342 : loss : 0.017311, loss_ce: 0.006278
2022-01-14 17:42:13,204 iteration 6343 : loss : 0.012084, loss_ce: 0.003349
2022-01-14 17:42:14,698 iteration 6344 : loss : 0.012253, loss_ce: 0.005555
2022-01-14 17:42:16,188 iteration 6345 : loss : 0.013758, loss_ce: 0.005999
2022-01-14 17:42:17,642 iteration 6346 : loss : 0.011614, loss_ce: 0.003018
2022-01-14 17:42:19,116 iteration 6347 : loss : 0.013955, loss_ce: 0.005166
2022-01-14 17:42:20,693 iteration 6348 : loss : 0.020654, loss_ce: 0.007576
2022-01-14 17:42:22,126 iteration 6349 : loss : 0.010837, loss_ce: 0.004515
2022-01-14 17:42:23,579 iteration 6350 : loss : 0.013343, loss_ce: 0.003523
2022-01-14 17:42:25,025 iteration 6351 : loss : 0.010737, loss_ce: 0.003721
2022-01-14 17:42:26,553 iteration 6352 : loss : 0.013501, loss_ce: 0.005715
2022-01-14 17:42:28,085 iteration 6353 : loss : 0.016821, loss_ce: 0.006496
2022-01-14 17:42:29,662 iteration 6354 : loss : 0.012762, loss_ce: 0.004899
2022-01-14 17:42:31,105 iteration 6355 : loss : 0.011939, loss_ce: 0.005465
2022-01-14 17:42:32,604 iteration 6356 : loss : 0.015618, loss_ce: 0.007303
2022-01-14 17:42:34,060 iteration 6357 : loss : 0.017333, loss_ce: 0.005727
2022-01-14 17:42:35,606 iteration 6358 : loss : 0.014919, loss_ce: 0.005188
 94%|███████████████████████████  | 374/400 [2:50:28<11:22, 26.25s/it]2022-01-14 17:42:37,130 iteration 6359 : loss : 0.014604, loss_ce: 0.004728
2022-01-14 17:42:38,568 iteration 6360 : loss : 0.031726, loss_ce: 0.007527
2022-01-14 17:42:40,060 iteration 6361 : loss : 0.019076, loss_ce: 0.005189
2022-01-14 17:42:41,571 iteration 6362 : loss : 0.013023, loss_ce: 0.006064
2022-01-14 17:42:43,129 iteration 6363 : loss : 0.015848, loss_ce: 0.006524
2022-01-14 17:42:44,559 iteration 6364 : loss : 0.012130, loss_ce: 0.005029
2022-01-14 17:42:45,973 iteration 6365 : loss : 0.011510, loss_ce: 0.004374
2022-01-14 17:42:47,487 iteration 6366 : loss : 0.017754, loss_ce: 0.006414
2022-01-14 17:42:48,945 iteration 6367 : loss : 0.012027, loss_ce: 0.005087
2022-01-14 17:42:50,392 iteration 6368 : loss : 0.019583, loss_ce: 0.010332
2022-01-14 17:42:51,887 iteration 6369 : loss : 0.012148, loss_ce: 0.005218
2022-01-14 17:42:53,400 iteration 6370 : loss : 0.018865, loss_ce: 0.004968
2022-01-14 17:42:54,916 iteration 6371 : loss : 0.015886, loss_ce: 0.005810
2022-01-14 17:42:56,403 iteration 6372 : loss : 0.012202, loss_ce: 0.006019
2022-01-14 17:42:57,758 iteration 6373 : loss : 0.007660, loss_ce: 0.002016
2022-01-14 17:42:59,188 iteration 6374 : loss : 0.008597, loss_ce: 0.003374
2022-01-14 17:42:59,189 Training Data Eval:
2022-01-14 17:43:06,549   Average segmentation loss on training set: 0.0073
2022-01-14 17:43:06,549 Validation Data Eval:
2022-01-14 17:43:09,088   Average segmentation loss on validation set: 0.0653
2022-01-14 17:43:10,547 iteration 6375 : loss : 0.015258, loss_ce: 0.005115
 94%|███████████████████████████▏ | 375/400 [2:51:03<12:01, 28.86s/it]2022-01-14 17:43:12,259 iteration 6376 : loss : 0.022756, loss_ce: 0.007969
2022-01-14 17:43:13,746 iteration 6377 : loss : 0.011169, loss_ce: 0.004517
2022-01-14 17:43:15,196 iteration 6378 : loss : 0.013552, loss_ce: 0.004509
2022-01-14 17:43:16,707 iteration 6379 : loss : 0.013162, loss_ce: 0.003079
2022-01-14 17:43:18,109 iteration 6380 : loss : 0.009855, loss_ce: 0.004675
2022-01-14 17:43:19,511 iteration 6381 : loss : 0.013786, loss_ce: 0.004781
2022-01-14 17:43:21,006 iteration 6382 : loss : 0.015731, loss_ce: 0.006548
2022-01-14 17:43:22,518 iteration 6383 : loss : 0.012581, loss_ce: 0.004821
2022-01-14 17:43:23,979 iteration 6384 : loss : 0.013929, loss_ce: 0.005850
2022-01-14 17:43:25,537 iteration 6385 : loss : 0.016370, loss_ce: 0.007000
2022-01-14 17:43:27,016 iteration 6386 : loss : 0.015694, loss_ce: 0.005970
2022-01-14 17:43:28,614 iteration 6387 : loss : 0.025017, loss_ce: 0.011471
2022-01-14 17:43:30,075 iteration 6388 : loss : 0.009238, loss_ce: 0.003142
2022-01-14 17:43:31,455 iteration 6389 : loss : 0.010815, loss_ce: 0.003461
2022-01-14 17:43:32,916 iteration 6390 : loss : 0.011084, loss_ce: 0.003883
2022-01-14 17:43:34,694 iteration 6391 : loss : 0.019524, loss_ce: 0.004631
2022-01-14 17:43:36,111 iteration 6392 : loss : 0.008823, loss_ce: 0.003558
 94%|███████████████████████████▎ | 376/400 [2:51:29<11:08, 27.87s/it]2022-01-14 17:43:37,627 iteration 6393 : loss : 0.011432, loss_ce: 0.004058
2022-01-14 17:43:39,125 iteration 6394 : loss : 0.015750, loss_ce: 0.004934
2022-01-14 17:43:40,567 iteration 6395 : loss : 0.010492, loss_ce: 0.004814
2022-01-14 17:43:42,135 iteration 6396 : loss : 0.019460, loss_ce: 0.007475
2022-01-14 17:43:43,603 iteration 6397 : loss : 0.013096, loss_ce: 0.005000
2022-01-14 17:43:45,034 iteration 6398 : loss : 0.010797, loss_ce: 0.003464
2022-01-14 17:43:46,572 iteration 6399 : loss : 0.014021, loss_ce: 0.004036
2022-01-14 17:43:48,085 iteration 6400 : loss : 0.013038, loss_ce: 0.006295
2022-01-14 17:43:49,509 iteration 6401 : loss : 0.011300, loss_ce: 0.004357
2022-01-14 17:43:50,984 iteration 6402 : loss : 0.023202, loss_ce: 0.008378
2022-01-14 17:43:52,582 iteration 6403 : loss : 0.018845, loss_ce: 0.006579
2022-01-14 17:43:54,046 iteration 6404 : loss : 0.016396, loss_ce: 0.005056
2022-01-14 17:43:55,511 iteration 6405 : loss : 0.017047, loss_ce: 0.006682
2022-01-14 17:43:57,148 iteration 6406 : loss : 0.014245, loss_ce: 0.006865
2022-01-14 17:43:58,571 iteration 6407 : loss : 0.014043, loss_ce: 0.003784
2022-01-14 17:44:00,045 iteration 6408 : loss : 0.013662, loss_ce: 0.003590
2022-01-14 17:44:01,488 iteration 6409 : loss : 0.014427, loss_ce: 0.005574
 94%|███████████████████████████▎ | 377/400 [2:51:54<10:23, 27.12s/it]2022-01-14 17:44:03,131 iteration 6410 : loss : 0.016550, loss_ce: 0.006753
2022-01-14 17:44:04,702 iteration 6411 : loss : 0.018887, loss_ce: 0.008217
2022-01-14 17:44:06,203 iteration 6412 : loss : 0.013291, loss_ce: 0.005991
2022-01-14 17:44:07,680 iteration 6413 : loss : 0.008350, loss_ce: 0.002617
2022-01-14 17:44:09,195 iteration 6414 : loss : 0.015139, loss_ce: 0.005475
2022-01-14 17:44:10,644 iteration 6415 : loss : 0.013829, loss_ce: 0.004443
2022-01-14 17:44:12,107 iteration 6416 : loss : 0.015369, loss_ce: 0.003978
2022-01-14 17:44:13,619 iteration 6417 : loss : 0.018528, loss_ce: 0.008935
2022-01-14 17:44:15,124 iteration 6418 : loss : 0.012870, loss_ce: 0.004526
2022-01-14 17:44:16,600 iteration 6419 : loss : 0.013810, loss_ce: 0.004635
2022-01-14 17:44:18,122 iteration 6420 : loss : 0.012736, loss_ce: 0.003968
2022-01-14 17:44:19,607 iteration 6421 : loss : 0.013275, loss_ce: 0.005156
2022-01-14 17:44:21,017 iteration 6422 : loss : 0.016675, loss_ce: 0.006106
2022-01-14 17:44:22,531 iteration 6423 : loss : 0.015915, loss_ce: 0.004740
2022-01-14 17:44:24,056 iteration 6424 : loss : 0.013573, loss_ce: 0.006173
2022-01-14 17:44:25,457 iteration 6425 : loss : 0.011800, loss_ce: 0.003742
2022-01-14 17:44:26,967 iteration 6426 : loss : 0.015673, loss_ce: 0.006007
 94%|███████████████████████████▍ | 378/400 [2:52:20<09:45, 26.63s/it]2022-01-14 17:44:28,507 iteration 6427 : loss : 0.014052, loss_ce: 0.005545
2022-01-14 17:44:29,910 iteration 6428 : loss : 0.010457, loss_ce: 0.004907
2022-01-14 17:44:31,424 iteration 6429 : loss : 0.015531, loss_ce: 0.005322
2022-01-14 17:44:32,838 iteration 6430 : loss : 0.010587, loss_ce: 0.002872
2022-01-14 17:44:34,320 iteration 6431 : loss : 0.014401, loss_ce: 0.004957
2022-01-14 17:44:35,809 iteration 6432 : loss : 0.012203, loss_ce: 0.004412
2022-01-14 17:44:37,355 iteration 6433 : loss : 0.017188, loss_ce: 0.006147
2022-01-14 17:44:38,747 iteration 6434 : loss : 0.008625, loss_ce: 0.003069
2022-01-14 17:44:40,221 iteration 6435 : loss : 0.009704, loss_ce: 0.004685
2022-01-14 17:44:41,684 iteration 6436 : loss : 0.013341, loss_ce: 0.004949
2022-01-14 17:44:43,192 iteration 6437 : loss : 0.021763, loss_ce: 0.005246
2022-01-14 17:44:44,707 iteration 6438 : loss : 0.017400, loss_ce: 0.006409
2022-01-14 17:44:46,214 iteration 6439 : loss : 0.011869, loss_ce: 0.004160
2022-01-14 17:44:47,761 iteration 6440 : loss : 0.016821, loss_ce: 0.006462
2022-01-14 17:44:49,258 iteration 6441 : loss : 0.011901, loss_ce: 0.003077
2022-01-14 17:44:50,733 iteration 6442 : loss : 0.014972, loss_ce: 0.005626
2022-01-14 17:44:52,242 iteration 6443 : loss : 0.020428, loss_ce: 0.007323
 95%|███████████████████████████▍ | 379/400 [2:52:45<09:10, 26.22s/it]2022-01-14 17:44:53,810 iteration 6444 : loss : 0.011944, loss_ce: 0.005317
2022-01-14 17:44:55,364 iteration 6445 : loss : 0.012351, loss_ce: 0.004459
2022-01-14 17:44:56,861 iteration 6446 : loss : 0.013408, loss_ce: 0.003581
2022-01-14 17:44:58,340 iteration 6447 : loss : 0.026246, loss_ce: 0.015496
2022-01-14 17:44:59,825 iteration 6448 : loss : 0.011704, loss_ce: 0.005316
2022-01-14 17:45:01,365 iteration 6449 : loss : 0.013980, loss_ce: 0.004527
2022-01-14 17:45:02,800 iteration 6450 : loss : 0.010673, loss_ce: 0.004523
2022-01-14 17:45:04,221 iteration 6451 : loss : 0.014608, loss_ce: 0.005129
2022-01-14 17:45:05,755 iteration 6452 : loss : 0.012915, loss_ce: 0.005995
2022-01-14 17:45:07,243 iteration 6453 : loss : 0.013193, loss_ce: 0.005350
2022-01-14 17:45:08,703 iteration 6454 : loss : 0.011556, loss_ce: 0.003973
2022-01-14 17:45:10,163 iteration 6455 : loss : 0.013199, loss_ce: 0.004508
2022-01-14 17:45:11,750 iteration 6456 : loss : 0.017946, loss_ce: 0.007040
2022-01-14 17:45:13,242 iteration 6457 : loss : 0.012210, loss_ce: 0.003381
2022-01-14 17:45:14,686 iteration 6458 : loss : 0.012068, loss_ce: 0.003581
2022-01-14 17:45:16,109 iteration 6459 : loss : 0.012619, loss_ce: 0.004463
2022-01-14 17:45:16,109 Training Data Eval:
2022-01-14 17:45:23,473   Average segmentation loss on training set: 0.0070
2022-01-14 17:45:23,474 Validation Data Eval:
2022-01-14 17:45:26,008   Average segmentation loss on validation set: 0.0748
2022-01-14 17:45:27,517 iteration 6460 : loss : 0.023963, loss_ce: 0.007090
 95%|███████████████████████████▌ | 380/400 [2:53:20<09:38, 28.94s/it]2022-01-14 17:45:29,058 iteration 6461 : loss : 0.014767, loss_ce: 0.004164
2022-01-14 17:45:30,551 iteration 6462 : loss : 0.011457, loss_ce: 0.004466
2022-01-14 17:45:31,983 iteration 6463 : loss : 0.008793, loss_ce: 0.002446
2022-01-14 17:45:33,414 iteration 6464 : loss : 0.012008, loss_ce: 0.004376
2022-01-14 17:45:34,877 iteration 6465 : loss : 0.013823, loss_ce: 0.004817
2022-01-14 17:45:36,384 iteration 6466 : loss : 0.011978, loss_ce: 0.004623
2022-01-14 17:45:37,919 iteration 6467 : loss : 0.014011, loss_ce: 0.006802
2022-01-14 17:45:39,471 iteration 6468 : loss : 0.025787, loss_ce: 0.012295
2022-01-14 17:45:40,950 iteration 6469 : loss : 0.017786, loss_ce: 0.007833
2022-01-14 17:45:42,404 iteration 6470 : loss : 0.017165, loss_ce: 0.004997
2022-01-14 17:45:43,861 iteration 6471 : loss : 0.037529, loss_ce: 0.010622
2022-01-14 17:45:45,325 iteration 6472 : loss : 0.015168, loss_ce: 0.004384
2022-01-14 17:45:46,740 iteration 6473 : loss : 0.013121, loss_ce: 0.006275
2022-01-14 17:45:48,277 iteration 6474 : loss : 0.015395, loss_ce: 0.007960
2022-01-14 17:45:49,686 iteration 6475 : loss : 0.010294, loss_ce: 0.003800
2022-01-14 17:45:51,130 iteration 6476 : loss : 0.011571, loss_ce: 0.004114
2022-01-14 17:45:52,537 iteration 6477 : loss : 0.011936, loss_ce: 0.004259
 95%|███████████████████████████▌ | 381/400 [2:53:45<08:47, 27.76s/it]2022-01-14 17:45:54,091 iteration 6478 : loss : 0.013087, loss_ce: 0.005505
2022-01-14 17:45:55,725 iteration 6479 : loss : 0.015729, loss_ce: 0.008371
2022-01-14 17:45:57,238 iteration 6480 : loss : 0.025197, loss_ce: 0.006542
2022-01-14 17:45:58,745 iteration 6481 : loss : 0.014268, loss_ce: 0.005414
2022-01-14 17:46:00,247 iteration 6482 : loss : 0.017662, loss_ce: 0.006513
2022-01-14 17:46:01,702 iteration 6483 : loss : 0.013732, loss_ce: 0.004865
2022-01-14 17:46:03,173 iteration 6484 : loss : 0.010965, loss_ce: 0.003005
2022-01-14 17:46:04,677 iteration 6485 : loss : 0.017274, loss_ce: 0.007353
2022-01-14 17:46:06,240 iteration 6486 : loss : 0.014188, loss_ce: 0.004795
2022-01-14 17:46:07,745 iteration 6487 : loss : 0.016379, loss_ce: 0.005289
2022-01-14 17:46:09,131 iteration 6488 : loss : 0.009617, loss_ce: 0.003960
2022-01-14 17:46:10,663 iteration 6489 : loss : 0.017052, loss_ce: 0.006251
2022-01-14 17:46:12,054 iteration 6490 : loss : 0.009573, loss_ce: 0.003396
2022-01-14 17:46:13,576 iteration 6491 : loss : 0.020957, loss_ce: 0.006726
2022-01-14 17:46:15,048 iteration 6492 : loss : 0.011439, loss_ce: 0.004102
2022-01-14 17:46:16,561 iteration 6493 : loss : 0.023245, loss_ce: 0.006340
2022-01-14 17:46:18,039 iteration 6494 : loss : 0.013072, loss_ce: 0.004724
 96%|███████████████████████████▋ | 382/400 [2:54:11<08:07, 27.09s/it]2022-01-14 17:46:19,610 iteration 6495 : loss : 0.010107, loss_ce: 0.002847
2022-01-14 17:46:21,075 iteration 6496 : loss : 0.016835, loss_ce: 0.005514
2022-01-14 17:46:22,587 iteration 6497 : loss : 0.011826, loss_ce: 0.004071
2022-01-14 17:46:24,087 iteration 6498 : loss : 0.016022, loss_ce: 0.007850
2022-01-14 17:46:25,678 iteration 6499 : loss : 0.018286, loss_ce: 0.006202
2022-01-14 17:46:27,209 iteration 6500 : loss : 0.023714, loss_ce: 0.010163
2022-01-14 17:46:28,759 iteration 6501 : loss : 0.011993, loss_ce: 0.003078
2022-01-14 17:46:30,299 iteration 6502 : loss : 0.019624, loss_ce: 0.007536
2022-01-14 17:46:31,885 iteration 6503 : loss : 0.019282, loss_ce: 0.006523
2022-01-14 17:46:33,319 iteration 6504 : loss : 0.010297, loss_ce: 0.004808
2022-01-14 17:46:34,778 iteration 6505 : loss : 0.012459, loss_ce: 0.003642
2022-01-14 17:46:36,250 iteration 6506 : loss : 0.013183, loss_ce: 0.003978
2022-01-14 17:46:37,722 iteration 6507 : loss : 0.014310, loss_ce: 0.006262
2022-01-14 17:46:39,205 iteration 6508 : loss : 0.016884, loss_ce: 0.004852
2022-01-14 17:46:40,680 iteration 6509 : loss : 0.015475, loss_ce: 0.007007
2022-01-14 17:46:42,130 iteration 6510 : loss : 0.012393, loss_ce: 0.004206
2022-01-14 17:46:43,610 iteration 6511 : loss : 0.012984, loss_ce: 0.005738
 96%|███████████████████████████▊ | 383/400 [2:54:36<07:32, 26.63s/it]2022-01-14 17:46:45,135 iteration 6512 : loss : 0.012750, loss_ce: 0.005102
2022-01-14 17:46:46,558 iteration 6513 : loss : 0.010446, loss_ce: 0.003953
2022-01-14 17:46:48,025 iteration 6514 : loss : 0.011773, loss_ce: 0.002862
2022-01-14 17:46:49,502 iteration 6515 : loss : 0.015961, loss_ce: 0.004703
2022-01-14 17:46:50,977 iteration 6516 : loss : 0.013582, loss_ce: 0.003907
2022-01-14 17:46:52,534 iteration 6517 : loss : 0.023645, loss_ce: 0.010385
2022-01-14 17:46:53,961 iteration 6518 : loss : 0.014295, loss_ce: 0.005965
2022-01-14 17:46:55,517 iteration 6519 : loss : 0.016806, loss_ce: 0.005426
2022-01-14 17:46:56,929 iteration 6520 : loss : 0.010493, loss_ce: 0.004567
2022-01-14 17:46:58,484 iteration 6521 : loss : 0.010270, loss_ce: 0.004145
2022-01-14 17:46:59,966 iteration 6522 : loss : 0.017608, loss_ce: 0.008507
2022-01-14 17:47:01,386 iteration 6523 : loss : 0.017888, loss_ce: 0.005398
2022-01-14 17:47:02,871 iteration 6524 : loss : 0.019373, loss_ce: 0.007758
2022-01-14 17:47:04,332 iteration 6525 : loss : 0.011512, loss_ce: 0.003791
2022-01-14 17:47:05,837 iteration 6526 : loss : 0.012191, loss_ce: 0.004859
2022-01-14 17:47:07,382 iteration 6527 : loss : 0.014715, loss_ce: 0.005202
2022-01-14 17:47:08,891 iteration 6528 : loss : 0.018978, loss_ce: 0.006946
 96%|███████████████████████████▊ | 384/400 [2:55:02<06:59, 26.22s/it]2022-01-14 17:47:10,368 iteration 6529 : loss : 0.011746, loss_ce: 0.004295
2022-01-14 17:47:11,769 iteration 6530 : loss : 0.009405, loss_ce: 0.004243
2022-01-14 17:47:13,250 iteration 6531 : loss : 0.014346, loss_ce: 0.003347
2022-01-14 17:47:14,781 iteration 6532 : loss : 0.010897, loss_ce: 0.003283
2022-01-14 17:47:16,228 iteration 6533 : loss : 0.012304, loss_ce: 0.005118
2022-01-14 17:47:17,747 iteration 6534 : loss : 0.018756, loss_ce: 0.005368
2022-01-14 17:47:19,236 iteration 6535 : loss : 0.012906, loss_ce: 0.004933
2022-01-14 17:47:20,760 iteration 6536 : loss : 0.013723, loss_ce: 0.005336
2022-01-14 17:47:22,353 iteration 6537 : loss : 0.021763, loss_ce: 0.006977
2022-01-14 17:47:23,792 iteration 6538 : loss : 0.019745, loss_ce: 0.006610
2022-01-14 17:47:25,401 iteration 6539 : loss : 0.018890, loss_ce: 0.008422
2022-01-14 17:47:26,841 iteration 6540 : loss : 0.013902, loss_ce: 0.006136
2022-01-14 17:47:28,245 iteration 6541 : loss : 0.013745, loss_ce: 0.005227
2022-01-14 17:47:29,709 iteration 6542 : loss : 0.013776, loss_ce: 0.005522
2022-01-14 17:47:31,260 iteration 6543 : loss : 0.014787, loss_ce: 0.005619
2022-01-14 17:47:32,732 iteration 6544 : loss : 0.017346, loss_ce: 0.006326
2022-01-14 17:47:32,732 Training Data Eval:
2022-01-14 17:47:40,095   Average segmentation loss on training set: 0.0071
2022-01-14 17:47:40,095 Validation Data Eval:
2022-01-14 17:47:42,635   Average segmentation loss on validation set: 0.0745
2022-01-14 17:47:44,111 iteration 6545 : loss : 0.009396, loss_ce: 0.002305
 96%|███████████████████████████▉ | 385/400 [2:55:37<07:13, 28.92s/it]2022-01-14 17:47:45,705 iteration 6546 : loss : 0.017342, loss_ce: 0.006439
2022-01-14 17:47:47,130 iteration 6547 : loss : 0.013983, loss_ce: 0.002829
2022-01-14 17:47:48,626 iteration 6548 : loss : 0.017009, loss_ce: 0.005666
2022-01-14 17:47:50,229 iteration 6549 : loss : 0.024095, loss_ce: 0.007172
2022-01-14 17:47:51,710 iteration 6550 : loss : 0.012615, loss_ce: 0.005778
2022-01-14 17:47:53,253 iteration 6551 : loss : 0.014167, loss_ce: 0.006315
2022-01-14 17:47:54,843 iteration 6552 : loss : 0.019444, loss_ce: 0.007426
2022-01-14 17:47:56,318 iteration 6553 : loss : 0.016635, loss_ce: 0.007292
2022-01-14 17:47:57,930 iteration 6554 : loss : 0.029300, loss_ce: 0.014389
2022-01-14 17:47:59,374 iteration 6555 : loss : 0.014845, loss_ce: 0.005554
2022-01-14 17:48:00,879 iteration 6556 : loss : 0.017512, loss_ce: 0.006342
2022-01-14 17:48:02,292 iteration 6557 : loss : 0.008682, loss_ce: 0.003071
2022-01-14 17:48:03,828 iteration 6558 : loss : 0.018791, loss_ce: 0.007171
2022-01-14 17:48:05,243 iteration 6559 : loss : 0.009887, loss_ce: 0.003349
2022-01-14 17:48:06,680 iteration 6560 : loss : 0.010560, loss_ce: 0.004966
2022-01-14 17:48:08,179 iteration 6561 : loss : 0.012622, loss_ce: 0.004357
2022-01-14 17:48:09,666 iteration 6562 : loss : 0.013736, loss_ce: 0.006226
 96%|███████████████████████████▉ | 386/400 [2:56:02<06:30, 27.91s/it]2022-01-14 17:48:11,217 iteration 6563 : loss : 0.015272, loss_ce: 0.007815
2022-01-14 17:48:12,767 iteration 6564 : loss : 0.014465, loss_ce: 0.004638
2022-01-14 17:48:14,206 iteration 6565 : loss : 0.015755, loss_ce: 0.004412
2022-01-14 17:48:15,762 iteration 6566 : loss : 0.019359, loss_ce: 0.007409
2022-01-14 17:48:17,253 iteration 6567 : loss : 0.016307, loss_ce: 0.005379
2022-01-14 17:48:18,730 iteration 6568 : loss : 0.009336, loss_ce: 0.003393
2022-01-14 17:48:20,181 iteration 6569 : loss : 0.020169, loss_ce: 0.005747
2022-01-14 17:48:21,762 iteration 6570 : loss : 0.022990, loss_ce: 0.008419
2022-01-14 17:48:23,170 iteration 6571 : loss : 0.010445, loss_ce: 0.004374
2022-01-14 17:48:24,635 iteration 6572 : loss : 0.012443, loss_ce: 0.004221
2022-01-14 17:48:26,080 iteration 6573 : loss : 0.010762, loss_ce: 0.003028
2022-01-14 17:48:27,623 iteration 6574 : loss : 0.014305, loss_ce: 0.005478
2022-01-14 17:48:29,027 iteration 6575 : loss : 0.008947, loss_ce: 0.003646
2022-01-14 17:48:30,548 iteration 6576 : loss : 0.021431, loss_ce: 0.009429
2022-01-14 17:48:32,063 iteration 6577 : loss : 0.014552, loss_ce: 0.005132
2022-01-14 17:48:33,565 iteration 6578 : loss : 0.011687, loss_ce: 0.006211
2022-01-14 17:48:35,035 iteration 6579 : loss : 0.014472, loss_ce: 0.003380
 97%|████████████████████████████ | 387/400 [2:56:28<05:52, 27.15s/it]2022-01-14 17:48:36,612 iteration 6580 : loss : 0.013118, loss_ce: 0.004803
2022-01-14 17:48:38,138 iteration 6581 : loss : 0.019222, loss_ce: 0.005534
2022-01-14 17:48:39,679 iteration 6582 : loss : 0.019580, loss_ce: 0.010564
2022-01-14 17:48:41,170 iteration 6583 : loss : 0.009433, loss_ce: 0.003284
2022-01-14 17:48:42,674 iteration 6584 : loss : 0.014012, loss_ce: 0.004885
2022-01-14 17:48:44,116 iteration 6585 : loss : 0.011173, loss_ce: 0.003759
2022-01-14 17:48:45,614 iteration 6586 : loss : 0.013737, loss_ce: 0.005351
2022-01-14 17:48:47,035 iteration 6587 : loss : 0.011216, loss_ce: 0.004943
2022-01-14 17:48:48,566 iteration 6588 : loss : 0.015813, loss_ce: 0.005897
2022-01-14 17:48:50,042 iteration 6589 : loss : 0.013100, loss_ce: 0.004249
2022-01-14 17:48:51,500 iteration 6590 : loss : 0.012065, loss_ce: 0.004634
2022-01-14 17:48:52,937 iteration 6591 : loss : 0.011682, loss_ce: 0.004864
2022-01-14 17:48:54,417 iteration 6592 : loss : 0.010133, loss_ce: 0.003365
2022-01-14 17:48:55,952 iteration 6593 : loss : 0.017261, loss_ce: 0.007275
2022-01-14 17:48:57,412 iteration 6594 : loss : 0.011816, loss_ce: 0.004157
2022-01-14 17:48:58,825 iteration 6595 : loss : 0.015211, loss_ce: 0.004464
2022-01-14 17:49:00,260 iteration 6596 : loss : 0.007827, loss_ce: 0.003041
 97%|████████████████████████████▏| 388/400 [2:56:53<05:18, 26.57s/it]2022-01-14 17:49:01,847 iteration 6597 : loss : 0.018000, loss_ce: 0.007993
2022-01-14 17:49:03,394 iteration 6598 : loss : 0.017044, loss_ce: 0.004020
2022-01-14 17:49:04,825 iteration 6599 : loss : 0.018338, loss_ce: 0.006630
2022-01-14 17:49:06,343 iteration 6600 : loss : 0.020356, loss_ce: 0.008613
2022-01-14 17:49:07,768 iteration 6601 : loss : 0.010077, loss_ce: 0.004202
2022-01-14 17:49:09,148 iteration 6602 : loss : 0.008367, loss_ce: 0.002933
2022-01-14 17:49:10,651 iteration 6603 : loss : 0.022297, loss_ce: 0.006668
2022-01-14 17:49:12,209 iteration 6604 : loss : 0.014638, loss_ce: 0.005493
2022-01-14 17:49:13,719 iteration 6605 : loss : 0.015028, loss_ce: 0.005638
2022-01-14 17:49:15,215 iteration 6606 : loss : 0.013529, loss_ce: 0.006638
2022-01-14 17:49:16,657 iteration 6607 : loss : 0.012641, loss_ce: 0.003889
2022-01-14 17:49:18,167 iteration 6608 : loss : 0.013198, loss_ce: 0.004308
2022-01-14 17:49:19,712 iteration 6609 : loss : 0.015468, loss_ce: 0.006904
2022-01-14 17:49:21,173 iteration 6610 : loss : 0.016402, loss_ce: 0.004174
2022-01-14 17:49:22,557 iteration 6611 : loss : 0.010892, loss_ce: 0.004738
2022-01-14 17:49:24,040 iteration 6612 : loss : 0.013537, loss_ce: 0.005047
2022-01-14 17:49:25,567 iteration 6613 : loss : 0.017166, loss_ce: 0.004613
 97%|████████████████████████████▏| 389/400 [2:57:18<04:48, 26.19s/it]2022-01-14 17:49:26,986 iteration 6614 : loss : 0.009060, loss_ce: 0.003598
2022-01-14 17:49:28,487 iteration 6615 : loss : 0.019379, loss_ce: 0.008228
2022-01-14 17:49:29,998 iteration 6616 : loss : 0.013896, loss_ce: 0.005913
2022-01-14 17:49:31,447 iteration 6617 : loss : 0.010686, loss_ce: 0.002083
2022-01-14 17:49:32,931 iteration 6618 : loss : 0.014872, loss_ce: 0.005298
2022-01-14 17:49:34,446 iteration 6619 : loss : 0.015092, loss_ce: 0.005639
2022-01-14 17:49:35,930 iteration 6620 : loss : 0.015210, loss_ce: 0.004550
2022-01-14 17:49:37,349 iteration 6621 : loss : 0.014802, loss_ce: 0.007523
2022-01-14 17:49:38,718 iteration 6622 : loss : 0.009155, loss_ce: 0.003053
2022-01-14 17:49:40,200 iteration 6623 : loss : 0.028786, loss_ce: 0.012683
2022-01-14 17:49:41,564 iteration 6624 : loss : 0.011233, loss_ce: 0.003989
2022-01-14 17:49:42,972 iteration 6625 : loss : 0.008527, loss_ce: 0.003460
2022-01-14 17:49:44,441 iteration 6626 : loss : 0.026675, loss_ce: 0.009189
2022-01-14 17:49:45,860 iteration 6627 : loss : 0.008449, loss_ce: 0.002911
2022-01-14 17:49:47,385 iteration 6628 : loss : 0.012366, loss_ce: 0.004603
2022-01-14 17:49:48,819 iteration 6629 : loss : 0.011730, loss_ce: 0.004839
2022-01-14 17:49:48,819 Training Data Eval:
2022-01-14 17:49:56,198   Average segmentation loss on training set: 0.0069
2022-01-14 17:49:56,199 Validation Data Eval:
2022-01-14 17:49:58,743   Average segmentation loss on validation set: 0.0703
2022-01-14 17:50:00,225 iteration 6630 : loss : 0.017033, loss_ce: 0.007129
 98%|████████████████████████████▎| 390/400 [2:57:53<04:47, 28.73s/it]2022-01-14 17:50:01,651 iteration 6631 : loss : 0.009940, loss_ce: 0.003862
2022-01-14 17:50:03,146 iteration 6632 : loss : 0.016155, loss_ce: 0.003399
2022-01-14 17:50:04,605 iteration 6633 : loss : 0.009637, loss_ce: 0.003420
2022-01-14 17:50:06,033 iteration 6634 : loss : 0.012065, loss_ce: 0.005139
2022-01-14 17:50:07,551 iteration 6635 : loss : 0.010572, loss_ce: 0.004364
2022-01-14 17:50:08,986 iteration 6636 : loss : 0.010687, loss_ce: 0.005724
2022-01-14 17:50:10,487 iteration 6637 : loss : 0.017067, loss_ce: 0.006043
2022-01-14 17:50:11,983 iteration 6638 : loss : 0.012876, loss_ce: 0.003918
2022-01-14 17:50:13,477 iteration 6639 : loss : 0.014308, loss_ce: 0.004652
2022-01-14 17:50:14,981 iteration 6640 : loss : 0.017583, loss_ce: 0.006428
2022-01-14 17:50:16,444 iteration 6641 : loss : 0.015522, loss_ce: 0.006311
2022-01-14 17:50:17,917 iteration 6642 : loss : 0.012463, loss_ce: 0.003729
2022-01-14 17:50:19,463 iteration 6643 : loss : 0.020801, loss_ce: 0.009055
2022-01-14 17:50:21,035 iteration 6644 : loss : 0.015523, loss_ce: 0.006739
2022-01-14 17:50:22,504 iteration 6645 : loss : 0.020873, loss_ce: 0.008448
2022-01-14 17:50:23,980 iteration 6646 : loss : 0.012793, loss_ce: 0.005854
2022-01-14 17:50:25,463 iteration 6647 : loss : 0.014726, loss_ce: 0.002851
 98%|████████████████████████████▎| 391/400 [2:58:18<04:09, 27.68s/it]2022-01-14 17:50:27,013 iteration 6648 : loss : 0.015880, loss_ce: 0.005713
2022-01-14 17:50:28,533 iteration 6649 : loss : 0.016489, loss_ce: 0.004779
2022-01-14 17:50:29,959 iteration 6650 : loss : 0.012180, loss_ce: 0.004439
2022-01-14 17:50:31,415 iteration 6651 : loss : 0.012834, loss_ce: 0.005384
2022-01-14 17:50:32,922 iteration 6652 : loss : 0.010843, loss_ce: 0.004471
2022-01-14 17:50:34,461 iteration 6653 : loss : 0.012924, loss_ce: 0.003896
2022-01-14 17:50:36,070 iteration 6654 : loss : 0.018534, loss_ce: 0.005831
2022-01-14 17:50:37,540 iteration 6655 : loss : 0.011084, loss_ce: 0.004807
2022-01-14 17:50:39,100 iteration 6656 : loss : 0.016088, loss_ce: 0.006833
2022-01-14 17:50:40,600 iteration 6657 : loss : 0.014438, loss_ce: 0.004368
2022-01-14 17:50:42,143 iteration 6658 : loss : 0.015850, loss_ce: 0.005547
2022-01-14 17:50:43,637 iteration 6659 : loss : 0.017139, loss_ce: 0.005016
2022-01-14 17:50:45,112 iteration 6660 : loss : 0.011845, loss_ce: 0.004560
2022-01-14 17:50:46,552 iteration 6661 : loss : 0.010680, loss_ce: 0.003932
2022-01-14 17:50:48,071 iteration 6662 : loss : 0.014578, loss_ce: 0.005380
2022-01-14 17:50:49,521 iteration 6663 : loss : 0.017011, loss_ce: 0.007868
2022-01-14 17:50:51,043 iteration 6664 : loss : 0.009238, loss_ce: 0.004320
 98%|████████████████████████████▍| 392/400 [2:58:44<03:36, 27.05s/it]2022-01-14 17:50:52,585 iteration 6665 : loss : 0.017925, loss_ce: 0.006812
2022-01-14 17:50:54,111 iteration 6666 : loss : 0.022026, loss_ce: 0.007282
2022-01-14 17:50:55,629 iteration 6667 : loss : 0.015176, loss_ce: 0.005754
2022-01-14 17:50:57,259 iteration 6668 : loss : 0.013828, loss_ce: 0.006208
2022-01-14 17:50:58,692 iteration 6669 : loss : 0.022292, loss_ce: 0.006960
2022-01-14 17:51:00,131 iteration 6670 : loss : 0.009260, loss_ce: 0.003579
2022-01-14 17:51:01,585 iteration 6671 : loss : 0.012963, loss_ce: 0.005721
2022-01-14 17:51:02,988 iteration 6672 : loss : 0.009378, loss_ce: 0.002479
2022-01-14 17:51:04,503 iteration 6673 : loss : 0.014808, loss_ce: 0.005751
2022-01-14 17:51:05,978 iteration 6674 : loss : 0.011174, loss_ce: 0.004644
2022-01-14 17:51:07,509 iteration 6675 : loss : 0.018708, loss_ce: 0.005591
2022-01-14 17:51:08,939 iteration 6676 : loss : 0.009629, loss_ce: 0.002939
2022-01-14 17:51:10,399 iteration 6677 : loss : 0.012690, loss_ce: 0.003147
2022-01-14 17:51:11,759 iteration 6678 : loss : 0.008925, loss_ce: 0.003880
2022-01-14 17:51:13,353 iteration 6679 : loss : 0.012064, loss_ce: 0.005511
2022-01-14 17:51:14,838 iteration 6680 : loss : 0.015458, loss_ce: 0.005462
2022-01-14 17:51:16,366 iteration 6681 : loss : 0.013318, loss_ce: 0.006541
 98%|████████████████████████████▍| 393/400 [2:59:09<03:05, 26.53s/it]2022-01-14 17:51:17,900 iteration 6682 : loss : 0.012709, loss_ce: 0.006632
2022-01-14 17:51:19,479 iteration 6683 : loss : 0.012310, loss_ce: 0.004602
2022-01-14 17:51:20,914 iteration 6684 : loss : 0.013045, loss_ce: 0.005009
2022-01-14 17:51:22,454 iteration 6685 : loss : 0.019870, loss_ce: 0.010002
2022-01-14 17:51:23,884 iteration 6686 : loss : 0.012919, loss_ce: 0.006275
2022-01-14 17:51:25,352 iteration 6687 : loss : 0.014378, loss_ce: 0.003143
2022-01-14 17:51:26,888 iteration 6688 : loss : 0.018870, loss_ce: 0.007759
2022-01-14 17:51:28,341 iteration 6689 : loss : 0.010106, loss_ce: 0.003603
2022-01-14 17:51:29,792 iteration 6690 : loss : 0.013060, loss_ce: 0.005374
2022-01-14 17:51:31,334 iteration 6691 : loss : 0.023372, loss_ce: 0.009210
2022-01-14 17:51:32,843 iteration 6692 : loss : 0.016132, loss_ce: 0.005127
2022-01-14 17:51:34,383 iteration 6693 : loss : 0.010866, loss_ce: 0.003404
2022-01-14 17:51:35,896 iteration 6694 : loss : 0.012587, loss_ce: 0.004811
2022-01-14 17:51:37,436 iteration 6695 : loss : 0.012828, loss_ce: 0.005535
2022-01-14 17:51:38,865 iteration 6696 : loss : 0.010456, loss_ce: 0.004663
2022-01-14 17:51:40,432 iteration 6697 : loss : 0.019358, loss_ce: 0.007046
2022-01-14 17:51:41,920 iteration 6698 : loss : 0.012602, loss_ce: 0.004172
 98%|████████████████████████████▌| 394/400 [2:59:35<02:37, 26.24s/it]2022-01-14 17:51:43,409 iteration 6699 : loss : 0.012817, loss_ce: 0.006774
2022-01-14 17:51:44,961 iteration 6700 : loss : 0.017642, loss_ce: 0.006864
2022-01-14 17:51:46,436 iteration 6701 : loss : 0.012696, loss_ce: 0.006298
2022-01-14 17:51:47,890 iteration 6702 : loss : 0.017502, loss_ce: 0.005441
2022-01-14 17:51:49,357 iteration 6703 : loss : 0.011310, loss_ce: 0.004169
2022-01-14 17:51:50,883 iteration 6704 : loss : 0.014878, loss_ce: 0.004633
2022-01-14 17:51:52,332 iteration 6705 : loss : 0.017060, loss_ce: 0.005270
2022-01-14 17:51:53,770 iteration 6706 : loss : 0.009233, loss_ce: 0.004500
2022-01-14 17:51:55,212 iteration 6707 : loss : 0.016162, loss_ce: 0.004485
2022-01-14 17:51:56,611 iteration 6708 : loss : 0.010341, loss_ce: 0.003519
2022-01-14 17:51:58,048 iteration 6709 : loss : 0.011223, loss_ce: 0.003583
2022-01-14 17:51:59,489 iteration 6710 : loss : 0.010146, loss_ce: 0.003446
2022-01-14 17:52:00,924 iteration 6711 : loss : 0.018129, loss_ce: 0.003728
2022-01-14 17:52:02,429 iteration 6712 : loss : 0.017451, loss_ce: 0.007915
2022-01-14 17:52:03,983 iteration 6713 : loss : 0.015106, loss_ce: 0.005133
2022-01-14 17:52:05,489 iteration 6714 : loss : 0.014273, loss_ce: 0.006526
2022-01-14 17:52:05,489 Training Data Eval:
2022-01-14 17:52:12,868   Average segmentation loss on training set: 0.0066
2022-01-14 17:52:12,869 Validation Data Eval:
2022-01-14 17:52:15,413   Average segmentation loss on validation set: 0.0753
2022-01-14 17:52:16,934 iteration 6715 : loss : 0.012670, loss_ce: 0.004506
 99%|████████████████████████████▋| 395/400 [3:00:10<02:24, 28.87s/it]2022-01-14 17:52:18,466 iteration 6716 : loss : 0.006980, loss_ce: 0.002482
2022-01-14 17:52:19,945 iteration 6717 : loss : 0.014870, loss_ce: 0.006299
2022-01-14 17:52:21,359 iteration 6718 : loss : 0.010424, loss_ce: 0.003363
2022-01-14 17:52:22,815 iteration 6719 : loss : 0.013686, loss_ce: 0.004849
2022-01-14 17:52:24,287 iteration 6720 : loss : 0.016459, loss_ce: 0.007003
2022-01-14 17:52:25,807 iteration 6721 : loss : 0.016884, loss_ce: 0.005945
2022-01-14 17:52:27,335 iteration 6722 : loss : 0.015447, loss_ce: 0.004788
2022-01-14 17:52:28,808 iteration 6723 : loss : 0.019659, loss_ce: 0.006190
2022-01-14 17:52:30,255 iteration 6724 : loss : 0.011449, loss_ce: 0.004920
2022-01-14 17:52:31,796 iteration 6725 : loss : 0.016721, loss_ce: 0.006373
2022-01-14 17:52:33,286 iteration 6726 : loss : 0.015864, loss_ce: 0.005246
2022-01-14 17:52:34,797 iteration 6727 : loss : 0.017667, loss_ce: 0.008256
2022-01-14 17:52:36,309 iteration 6728 : loss : 0.015852, loss_ce: 0.007767
2022-01-14 17:52:37,731 iteration 6729 : loss : 0.011038, loss_ce: 0.003507
2022-01-14 17:52:39,178 iteration 6730 : loss : 0.020126, loss_ce: 0.007051
2022-01-14 17:52:40,625 iteration 6731 : loss : 0.009963, loss_ce: 0.004302
2022-01-14 17:52:42,102 iteration 6732 : loss : 0.011871, loss_ce: 0.006098
 99%|████████████████████████████▋| 396/400 [3:00:35<01:51, 27.76s/it]2022-01-14 17:52:43,672 iteration 6733 : loss : 0.014785, loss_ce: 0.006535
2022-01-14 17:52:45,107 iteration 6734 : loss : 0.006631, loss_ce: 0.002018
2022-01-14 17:52:46,600 iteration 6735 : loss : 0.012494, loss_ce: 0.005723
2022-01-14 17:52:48,080 iteration 6736 : loss : 0.010333, loss_ce: 0.003021
2022-01-14 17:52:49,523 iteration 6737 : loss : 0.008634, loss_ce: 0.003653
2022-01-14 17:52:50,992 iteration 6738 : loss : 0.012102, loss_ce: 0.004759
2022-01-14 17:52:52,501 iteration 6739 : loss : 0.014577, loss_ce: 0.005522
2022-01-14 17:52:54,056 iteration 6740 : loss : 0.011656, loss_ce: 0.003978
2022-01-14 17:52:55,478 iteration 6741 : loss : 0.009242, loss_ce: 0.004001
2022-01-14 17:52:56,999 iteration 6742 : loss : 0.016038, loss_ce: 0.006887
2022-01-14 17:52:58,508 iteration 6743 : loss : 0.015004, loss_ce: 0.004740
2022-01-14 17:53:00,071 iteration 6744 : loss : 0.013219, loss_ce: 0.006442
2022-01-14 17:53:01,519 iteration 6745 : loss : 0.016579, loss_ce: 0.004645
2022-01-14 17:53:02,975 iteration 6746 : loss : 0.019867, loss_ce: 0.007967
2022-01-14 17:53:04,446 iteration 6747 : loss : 0.016281, loss_ce: 0.005467
2022-01-14 17:53:05,937 iteration 6748 : loss : 0.013029, loss_ce: 0.004945
2022-01-14 17:53:07,487 iteration 6749 : loss : 0.018110, loss_ce: 0.006109
 99%|████████████████████████████▊| 397/400 [3:01:00<01:21, 27.05s/it]2022-01-14 17:53:09,036 iteration 6750 : loss : 0.014410, loss_ce: 0.005386
2022-01-14 17:53:10,606 iteration 6751 : loss : 0.016520, loss_ce: 0.007062
2022-01-14 17:53:12,168 iteration 6752 : loss : 0.026657, loss_ce: 0.016457
2022-01-14 17:53:13,658 iteration 6753 : loss : 0.013036, loss_ce: 0.004888
2022-01-14 17:53:15,187 iteration 6754 : loss : 0.017323, loss_ce: 0.005356
2022-01-14 17:53:16,668 iteration 6755 : loss : 0.009788, loss_ce: 0.003313
2022-01-14 17:53:18,154 iteration 6756 : loss : 0.010494, loss_ce: 0.003901
2022-01-14 17:53:19,646 iteration 6757 : loss : 0.014565, loss_ce: 0.007383
2022-01-14 17:53:21,076 iteration 6758 : loss : 0.007911, loss_ce: 0.003264
2022-01-14 17:53:22,588 iteration 6759 : loss : 0.013960, loss_ce: 0.004473
2022-01-14 17:53:24,054 iteration 6760 : loss : 0.012822, loss_ce: 0.004945
2022-01-14 17:53:25,575 iteration 6761 : loss : 0.012144, loss_ce: 0.004800
2022-01-14 17:53:26,951 iteration 6762 : loss : 0.008727, loss_ce: 0.003144
2022-01-14 17:53:28,433 iteration 6763 : loss : 0.013695, loss_ce: 0.003507
2022-01-14 17:53:29,883 iteration 6764 : loss : 0.011163, loss_ce: 0.003848
2022-01-14 17:53:31,312 iteration 6765 : loss : 0.011873, loss_ce: 0.003998
2022-01-14 17:53:32,761 iteration 6766 : loss : 0.013382, loss_ce: 0.004911
100%|████████████████████████████▊| 398/400 [3:01:26<00:53, 26.52s/it]2022-01-14 17:53:34,386 iteration 6767 : loss : 0.010253, loss_ce: 0.003355
2022-01-14 17:53:35,804 iteration 6768 : loss : 0.012242, loss_ce: 0.005523
2022-01-14 17:53:37,275 iteration 6769 : loss : 0.012079, loss_ce: 0.003205
2022-01-14 17:53:38,687 iteration 6770 : loss : 0.010651, loss_ce: 0.004028
2022-01-14 17:53:40,148 iteration 6771 : loss : 0.010833, loss_ce: 0.003133
2022-01-14 17:53:41,694 iteration 6772 : loss : 0.018235, loss_ce: 0.005474
2022-01-14 17:53:43,188 iteration 6773 : loss : 0.011061, loss_ce: 0.004660
2022-01-14 17:53:44,661 iteration 6774 : loss : 0.012311, loss_ce: 0.004743
2022-01-14 17:53:46,123 iteration 6775 : loss : 0.015525, loss_ce: 0.006133
2022-01-14 17:53:47,653 iteration 6776 : loss : 0.017689, loss_ce: 0.007286
2022-01-14 17:53:49,135 iteration 6777 : loss : 0.013771, loss_ce: 0.005266
2022-01-14 17:53:50,573 iteration 6778 : loss : 0.010352, loss_ce: 0.003112
2022-01-14 17:53:52,025 iteration 6779 : loss : 0.010976, loss_ce: 0.003250
2022-01-14 17:53:53,424 iteration 6780 : loss : 0.008790, loss_ce: 0.002960
2022-01-14 17:53:54,852 iteration 6781 : loss : 0.010435, loss_ce: 0.004869
2022-01-14 17:53:56,328 iteration 6782 : loss : 0.012109, loss_ce: 0.005433
2022-01-14 17:53:57,804 iteration 6783 : loss : 0.011019, loss_ce: 0.004189
100%|████████████████████████████▉| 399/400 [3:01:51<00:26, 26.07s/it]2022-01-14 17:53:59,415 iteration 6784 : loss : 0.014674, loss_ce: 0.004186
2022-01-14 17:54:00,829 iteration 6785 : loss : 0.013993, loss_ce: 0.005981
2022-01-14 17:54:02,208 iteration 6786 : loss : 0.009223, loss_ce: 0.003930
2022-01-14 17:54:03,702 iteration 6787 : loss : 0.018008, loss_ce: 0.006626
2022-01-14 17:54:05,104 iteration 6788 : loss : 0.014302, loss_ce: 0.003294
2022-01-14 17:54:06,593 iteration 6789 : loss : 0.012113, loss_ce: 0.005614
2022-01-14 17:54:08,096 iteration 6790 : loss : 0.013224, loss_ce: 0.006061
2022-01-14 17:54:09,623 iteration 6791 : loss : 0.015064, loss_ce: 0.005177
2022-01-14 17:54:11,136 iteration 6792 : loss : 0.010224, loss_ce: 0.003857
2022-01-14 17:54:12,617 iteration 6793 : loss : 0.013758, loss_ce: 0.004612
2022-01-14 17:54:14,115 iteration 6794 : loss : 0.011705, loss_ce: 0.004342
2022-01-14 17:54:15,577 iteration 6795 : loss : 0.010895, loss_ce: 0.004285
2022-01-14 17:54:17,053 iteration 6796 : loss : 0.015234, loss_ce: 0.005365
2022-01-14 17:54:18,493 iteration 6797 : loss : 0.012301, loss_ce: 0.004576
2022-01-14 17:54:19,887 iteration 6798 : loss : 0.011006, loss_ce: 0.003940
2022-01-14 17:54:21,361 iteration 6799 : loss : 0.016532, loss_ce: 0.007591
2022-01-14 17:54:21,361 Training Data Eval:
2022-01-14 17:54:28,734   Average segmentation loss on training set: 0.0067
2022-01-14 17:54:28,735 Validation Data Eval:
2022-01-14 17:54:31,276   Average segmentation loss on validation set: 0.0690
2022-01-14 17:54:32,735 iteration 6800 : loss : 0.013275, loss_ce: 0.006572
100%|█████████████████████████████| 400/400 [3:02:26<00:00, 28.73s/it]100%|█████████████████████████████| 400/400 [3:02:26<00:00, 27.37s/it]
