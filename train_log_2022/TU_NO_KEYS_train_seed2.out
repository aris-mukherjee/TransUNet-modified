2022-01-08 14:59:53,123 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-08 14:59:53,123 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-08 14:59:53,124 ============================================================
2022-01-08 14:59:53,124 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-08 14:59:53,124 ============================================================
2022-01-08 14:59:53,124 Loading data...
2022-01-08 14:59:53,124 Reading NCI - RUNMC images...
2022-01-08 14:59:53,124 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-08 14:59:53,125 Already preprocessed this configuration. Loading now!
2022-01-08 14:59:53,142 Training Images: (256, 256, 286)
2022-01-08 14:59:53,142 Training Labels: (256, 256, 286)
2022-01-08 14:59:53,142 Validation Images: (256, 256, 98)
2022-01-08 14:59:53,142 Validation Labels: (256, 256, 98)
2022-01-08 14:59:53,142 ============================================================
2022-01-08 14:59:53,178 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-08 14:59:55,759 iteration 1 : loss : 0.926215, loss_ce: 1.121374
2022-01-08 14:59:57,143 iteration 2 : loss : 0.860455, loss_ce: 1.027192
2022-01-08 14:59:58,623 iteration 3 : loss : 0.799666, loss_ce: 0.932974
2022-01-08 15:00:00,085 iteration 4 : loss : 0.760216, loss_ce: 0.844171
2022-01-08 15:00:01,435 iteration 5 : loss : 0.725573, loss_ce: 0.770230
2022-01-08 15:00:02,851 iteration 6 : loss : 0.672926, loss_ce: 0.701281
2022-01-08 15:00:04,320 iteration 7 : loss : 0.634742, loss_ce: 0.641659
2022-01-08 15:00:05,824 iteration 8 : loss : 0.599871, loss_ce: 0.586607
2022-01-08 15:00:07,182 iteration 9 : loss : 0.588979, loss_ce: 0.540522
2022-01-08 15:00:08,556 iteration 10 : loss : 0.545875, loss_ce: 0.493691
2022-01-08 15:00:09,914 iteration 11 : loss : 0.527776, loss_ce: 0.449430
2022-01-08 15:00:11,317 iteration 12 : loss : 0.505723, loss_ce: 0.428158
2022-01-08 15:00:12,782 iteration 13 : loss : 0.488457, loss_ce: 0.415100
2022-01-08 15:00:14,141 iteration 14 : loss : 0.454824, loss_ce: 0.370102
2022-01-08 15:00:15,593 iteration 15 : loss : 0.433614, loss_ce: 0.335087
2022-01-08 15:00:16,995 iteration 16 : loss : 0.442314, loss_ce: 0.322881
2022-01-08 15:00:18,384 iteration 17 : loss : 0.439394, loss_ce: 0.328055
  0%|                               | 1/400 [00:25<2:48:01, 25.27s/it]2022-01-08 15:00:19,827 iteration 18 : loss : 0.396566, loss_ce: 0.262002
2022-01-08 15:00:21,252 iteration 19 : loss : 0.380319, loss_ce: 0.247874
2022-01-08 15:00:22,665 iteration 20 : loss : 0.358375, loss_ce: 0.233159
2022-01-08 15:00:24,150 iteration 21 : loss : 0.362052, loss_ce: 0.228728
2022-01-08 15:00:25,546 iteration 22 : loss : 0.339382, loss_ce: 0.208140
2022-01-08 15:00:26,975 iteration 23 : loss : 0.296780, loss_ce: 0.171513
2022-01-08 15:00:28,336 iteration 24 : loss : 0.320978, loss_ce: 0.191731
2022-01-08 15:00:29,655 iteration 25 : loss : 0.309452, loss_ce: 0.169238
2022-01-08 15:00:31,012 iteration 26 : loss : 0.333287, loss_ce: 0.172584
2022-01-08 15:00:32,431 iteration 27 : loss : 0.274713, loss_ce: 0.150549
2022-01-08 15:00:33,826 iteration 28 : loss : 0.293786, loss_ce: 0.147369
2022-01-08 15:00:35,379 iteration 29 : loss : 0.291145, loss_ce: 0.154258
2022-01-08 15:00:36,833 iteration 30 : loss : 0.277388, loss_ce: 0.136150
2022-01-08 15:00:38,200 iteration 31 : loss : 0.269281, loss_ce: 0.138128
2022-01-08 15:00:39,589 iteration 32 : loss : 0.279151, loss_ce: 0.138855
2022-01-08 15:00:41,075 iteration 33 : loss : 0.268474, loss_ce: 0.144113
2022-01-08 15:00:42,464 iteration 34 : loss : 0.276503, loss_ce: 0.124802
  0%|▏                              | 2/400 [00:49<2:42:55, 24.56s/it]2022-01-08 15:00:43,986 iteration 35 : loss : 0.248926, loss_ce: 0.130532
2022-01-08 15:00:45,418 iteration 36 : loss : 0.275756, loss_ce: 0.142373
2022-01-08 15:00:46,884 iteration 37 : loss : 0.279429, loss_ce: 0.150860
2022-01-08 15:00:48,397 iteration 38 : loss : 0.242088, loss_ce: 0.111335
2022-01-08 15:00:49,830 iteration 39 : loss : 0.318872, loss_ce: 0.140103
2022-01-08 15:00:51,297 iteration 40 : loss : 0.260498, loss_ce: 0.135769
2022-01-08 15:00:52,661 iteration 41 : loss : 0.274137, loss_ce: 0.115905
2022-01-08 15:00:54,215 iteration 42 : loss : 0.241598, loss_ce: 0.114893
2022-01-08 15:00:55,584 iteration 43 : loss : 0.277170, loss_ce: 0.115885
2022-01-08 15:00:57,040 iteration 44 : loss : 0.229788, loss_ce: 0.102978
2022-01-08 15:00:58,502 iteration 45 : loss : 0.305015, loss_ce: 0.133261
2022-01-08 15:00:59,851 iteration 46 : loss : 0.216577, loss_ce: 0.089390
2022-01-08 15:01:01,265 iteration 47 : loss : 0.302571, loss_ce: 0.114258
2022-01-08 15:01:02,720 iteration 48 : loss : 0.203329, loss_ce: 0.089541
2022-01-08 15:01:04,153 iteration 49 : loss : 0.261175, loss_ce: 0.102693
2022-01-08 15:01:05,644 iteration 50 : loss : 0.241042, loss_ce: 0.097618
2022-01-08 15:01:07,103 iteration 51 : loss : 0.249564, loss_ce: 0.124103
  1%|▏                              | 3/400 [01:13<2:42:43, 24.59s/it]2022-01-08 15:01:08,496 iteration 52 : loss : 0.274549, loss_ce: 0.128098
2022-01-08 15:01:09,891 iteration 53 : loss : 0.249035, loss_ce: 0.115478
2022-01-08 15:01:11,463 iteration 54 : loss : 0.198502, loss_ce: 0.089999
2022-01-08 15:01:13,023 iteration 55 : loss : 0.328676, loss_ce: 0.147013
2022-01-08 15:01:14,618 iteration 56 : loss : 0.250716, loss_ce: 0.111346
2022-01-08 15:01:16,200 iteration 57 : loss : 0.222779, loss_ce: 0.091583
2022-01-08 15:01:17,758 iteration 58 : loss : 0.255212, loss_ce: 0.118669
2022-01-08 15:01:19,310 iteration 59 : loss : 0.249378, loss_ce: 0.097940
2022-01-08 15:01:20,935 iteration 60 : loss : 0.261721, loss_ce: 0.099816
2022-01-08 15:01:22,564 iteration 61 : loss : 0.226908, loss_ce: 0.095790
2022-01-08 15:01:24,122 iteration 62 : loss : 0.236476, loss_ce: 0.091981
2022-01-08 15:01:25,622 iteration 63 : loss : 0.211940, loss_ce: 0.101239
2022-01-08 15:01:27,167 iteration 64 : loss : 0.268710, loss_ce: 0.141047
2022-01-08 15:01:28,722 iteration 65 : loss : 0.249787, loss_ce: 0.108081
2022-01-08 15:01:30,334 iteration 66 : loss : 0.229873, loss_ce: 0.101516
2022-01-08 15:01:31,855 iteration 67 : loss : 0.267301, loss_ce: 0.120890
2022-01-08 15:01:33,413 iteration 68 : loss : 0.272483, loss_ce: 0.112584
  1%|▎                              | 4/400 [01:40<2:46:50, 25.28s/it]2022-01-08 15:01:35,036 iteration 69 : loss : 0.234511, loss_ce: 0.086497
2022-01-08 15:01:36,632 iteration 70 : loss : 0.234864, loss_ce: 0.104277
2022-01-08 15:01:38,156 iteration 71 : loss : 0.233913, loss_ce: 0.102601
2022-01-08 15:01:39,782 iteration 72 : loss : 0.247826, loss_ce: 0.092712
2022-01-08 15:01:41,338 iteration 73 : loss : 0.248017, loss_ce: 0.119311
2022-01-08 15:01:42,974 iteration 74 : loss : 0.241829, loss_ce: 0.104108
2022-01-08 15:01:44,559 iteration 75 : loss : 0.262967, loss_ce: 0.133395
2022-01-08 15:01:46,189 iteration 76 : loss : 0.259642, loss_ce: 0.111714
2022-01-08 15:01:47,844 iteration 77 : loss : 0.236256, loss_ce: 0.092142
2022-01-08 15:01:49,456 iteration 78 : loss : 0.197444, loss_ce: 0.092530
2022-01-08 15:01:50,976 iteration 79 : loss : 0.207591, loss_ce: 0.075937
2022-01-08 15:01:52,599 iteration 80 : loss : 0.293602, loss_ce: 0.111266
2022-01-08 15:01:54,148 iteration 81 : loss : 0.218342, loss_ce: 0.084644
2022-01-08 15:01:55,719 iteration 82 : loss : 0.249823, loss_ce: 0.119229
2022-01-08 15:01:57,352 iteration 83 : loss : 0.214815, loss_ce: 0.082395
2022-01-08 15:01:58,884 iteration 84 : loss : 0.233593, loss_ce: 0.107694
2022-01-08 15:01:58,884 Training Data Eval:
2022-01-08 15:02:06,730   Average segmentation loss on training set: 0.2102
2022-01-08 15:02:06,731 Validation Data Eval:
2022-01-08 15:02:09,575   Average segmentation loss on validation set: 0.2307
2022-01-08 15:02:15,554 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 15:02:17,062 iteration 85 : loss : 0.186260, loss_ce: 0.077838
  1%|▍                              | 5/400 [02:23<3:29:58, 31.90s/it]2022-01-08 15:02:18,505 iteration 86 : loss : 0.280435, loss_ce: 0.098840
2022-01-08 15:02:19,849 iteration 87 : loss : 0.227955, loss_ce: 0.087138
2022-01-08 15:02:21,243 iteration 88 : loss : 0.207385, loss_ce: 0.072567
2022-01-08 15:02:22,772 iteration 89 : loss : 0.201733, loss_ce: 0.080787
2022-01-08 15:02:24,276 iteration 90 : loss : 0.185387, loss_ce: 0.075732
2022-01-08 15:02:25,853 iteration 91 : loss : 0.260143, loss_ce: 0.111762
2022-01-08 15:02:27,398 iteration 92 : loss : 0.192426, loss_ce: 0.075630
2022-01-08 15:02:29,032 iteration 93 : loss : 0.205029, loss_ce: 0.087691
2022-01-08 15:02:30,667 iteration 94 : loss : 0.222260, loss_ce: 0.112071
2022-01-08 15:02:32,215 iteration 95 : loss : 0.236161, loss_ce: 0.095596
2022-01-08 15:02:33,725 iteration 96 : loss : 0.203071, loss_ce: 0.072863
2022-01-08 15:02:35,244 iteration 97 : loss : 0.191140, loss_ce: 0.073475
2022-01-08 15:02:36,827 iteration 98 : loss : 0.237988, loss_ce: 0.090432
2022-01-08 15:02:38,547 iteration 99 : loss : 0.207070, loss_ce: 0.085006
2022-01-08 15:02:40,261 iteration 100 : loss : 0.243658, loss_ce: 0.100370
2022-01-08 15:02:41,799 iteration 101 : loss : 0.274665, loss_ce: 0.120614
2022-01-08 15:02:43,362 iteration 102 : loss : 0.221540, loss_ce: 0.074057
  2%|▍                              | 6/400 [02:50<3:17:00, 30.00s/it]2022-01-08 15:02:45,002 iteration 103 : loss : 0.259656, loss_ce: 0.104131
2022-01-08 15:02:46,627 iteration 104 : loss : 0.243804, loss_ce: 0.088478
2022-01-08 15:02:48,213 iteration 105 : loss : 0.208354, loss_ce: 0.085141
2022-01-08 15:02:49,804 iteration 106 : loss : 0.209934, loss_ce: 0.077120
2022-01-08 15:02:51,455 iteration 107 : loss : 0.204255, loss_ce: 0.085508
2022-01-08 15:02:53,019 iteration 108 : loss : 0.237604, loss_ce: 0.110521
2022-01-08 15:02:54,600 iteration 109 : loss : 0.174763, loss_ce: 0.068653
2022-01-08 15:02:56,203 iteration 110 : loss : 0.250000, loss_ce: 0.119432
2022-01-08 15:02:57,959 iteration 111 : loss : 0.190658, loss_ce: 0.077750
2022-01-08 15:02:59,492 iteration 112 : loss : 0.241027, loss_ce: 0.094787
2022-01-08 15:03:01,174 iteration 113 : loss : 0.177037, loss_ce: 0.062815
2022-01-08 15:03:02,760 iteration 114 : loss : 0.180373, loss_ce: 0.057514
2022-01-08 15:03:04,259 iteration 115 : loss : 0.169016, loss_ce: 0.060157
2022-01-08 15:03:05,825 iteration 116 : loss : 0.232534, loss_ce: 0.095724
2022-01-08 15:03:07,368 iteration 117 : loss : 0.162502, loss_ce: 0.065046
2022-01-08 15:03:08,998 iteration 118 : loss : 0.222030, loss_ce: 0.085282
2022-01-08 15:03:10,532 iteration 119 : loss : 0.260578, loss_ce: 0.109905
  2%|▌                              | 7/400 [03:17<3:10:24, 29.07s/it]2022-01-08 15:03:12,209 iteration 120 : loss : 0.242648, loss_ce: 0.122836
2022-01-08 15:03:13,819 iteration 121 : loss : 0.269434, loss_ce: 0.113569
2022-01-08 15:03:15,288 iteration 122 : loss : 0.215448, loss_ce: 0.089082
2022-01-08 15:03:16,870 iteration 123 : loss : 0.245481, loss_ce: 0.106593
2022-01-08 15:03:18,424 iteration 124 : loss : 0.223326, loss_ce: 0.085398
2022-01-08 15:03:19,966 iteration 125 : loss : 0.231649, loss_ce: 0.087491
2022-01-08 15:03:21,516 iteration 126 : loss : 0.204941, loss_ce: 0.083062
2022-01-08 15:03:23,089 iteration 127 : loss : 0.251491, loss_ce: 0.111155
2022-01-08 15:03:24,629 iteration 128 : loss : 0.196261, loss_ce: 0.067636
2022-01-08 15:03:26,250 iteration 129 : loss : 0.267151, loss_ce: 0.120173
2022-01-08 15:03:27,712 iteration 130 : loss : 0.177063, loss_ce: 0.065964
2022-01-08 15:03:29,248 iteration 131 : loss : 0.204144, loss_ce: 0.098050
2022-01-08 15:03:30,822 iteration 132 : loss : 0.200459, loss_ce: 0.077836
2022-01-08 15:03:32,401 iteration 133 : loss : 0.266003, loss_ce: 0.145846
2022-01-08 15:03:33,948 iteration 134 : loss : 0.190105, loss_ce: 0.071497
2022-01-08 15:03:35,490 iteration 135 : loss : 0.177094, loss_ce: 0.058818
2022-01-08 15:03:37,138 iteration 136 : loss : 0.172478, loss_ce: 0.071673
  2%|▌                              | 8/400 [03:44<3:04:47, 28.28s/it]2022-01-08 15:03:38,835 iteration 137 : loss : 0.192717, loss_ce: 0.064660
2022-01-08 15:03:40,350 iteration 138 : loss : 0.252471, loss_ce: 0.101391
2022-01-08 15:03:42,015 iteration 139 : loss : 0.221696, loss_ce: 0.064033
2022-01-08 15:03:43,581 iteration 140 : loss : 0.277577, loss_ce: 0.119852
2022-01-08 15:03:45,097 iteration 141 : loss : 0.266717, loss_ce: 0.112398
2022-01-08 15:03:46,649 iteration 142 : loss : 0.232769, loss_ce: 0.098275
2022-01-08 15:03:48,231 iteration 143 : loss : 0.246266, loss_ce: 0.095758
2022-01-08 15:03:49,785 iteration 144 : loss : 0.190999, loss_ce: 0.058746
2022-01-08 15:03:51,370 iteration 145 : loss : 0.218809, loss_ce: 0.110780
2022-01-08 15:03:52,983 iteration 146 : loss : 0.176919, loss_ce: 0.070217
2022-01-08 15:03:54,563 iteration 147 : loss : 0.268915, loss_ce: 0.128974
2022-01-08 15:03:56,242 iteration 148 : loss : 0.213393, loss_ce: 0.093348
2022-01-08 15:03:57,896 iteration 149 : loss : 0.232965, loss_ce: 0.095058
2022-01-08 15:03:59,549 iteration 150 : loss : 0.180999, loss_ce: 0.078602
2022-01-08 15:04:01,084 iteration 151 : loss : 0.184122, loss_ce: 0.094205
2022-01-08 15:04:02,565 iteration 152 : loss : 0.159247, loss_ce: 0.070833
2022-01-08 15:04:04,120 iteration 153 : loss : 0.183515, loss_ce: 0.071171
  2%|▋                              | 9/400 [04:10<3:01:39, 27.88s/it]2022-01-08 15:04:05,760 iteration 154 : loss : 0.231137, loss_ce: 0.110611
2022-01-08 15:04:07,330 iteration 155 : loss : 0.183597, loss_ce: 0.086581
2022-01-08 15:04:08,857 iteration 156 : loss : 0.200913, loss_ce: 0.082810
2022-01-08 15:04:10,383 iteration 157 : loss : 0.194723, loss_ce: 0.081423
2022-01-08 15:04:12,014 iteration 158 : loss : 0.206310, loss_ce: 0.081169
2022-01-08 15:04:13,648 iteration 159 : loss : 0.184158, loss_ce: 0.069209
2022-01-08 15:04:15,194 iteration 160 : loss : 0.154922, loss_ce: 0.060795
2022-01-08 15:04:16,845 iteration 161 : loss : 0.153366, loss_ce: 0.067605
2022-01-08 15:04:18,432 iteration 162 : loss : 0.210833, loss_ce: 0.075686
2022-01-08 15:04:20,002 iteration 163 : loss : 0.234503, loss_ce: 0.105955
2022-01-08 15:04:21,571 iteration 164 : loss : 0.213698, loss_ce: 0.071228
2022-01-08 15:04:23,072 iteration 165 : loss : 0.165196, loss_ce: 0.057193
2022-01-08 15:04:24,667 iteration 166 : loss : 0.217199, loss_ce: 0.123256
2022-01-08 15:04:26,339 iteration 167 : loss : 0.266686, loss_ce: 0.120148
2022-01-08 15:04:27,903 iteration 168 : loss : 0.242514, loss_ce: 0.078709
2022-01-08 15:04:29,499 iteration 169 : loss : 0.201933, loss_ce: 0.073183
2022-01-08 15:04:29,499 Training Data Eval:
2022-01-08 15:04:37,341   Average segmentation loss on training set: 0.2716
2022-01-08 15:04:37,342 Validation Data Eval:
2022-01-08 15:04:40,049   Average segmentation loss on validation set: 0.3298
2022-01-08 15:04:41,708 iteration 170 : loss : 0.199206, loss_ce: 0.077396
  2%|▊                             | 10/400 [04:48<3:20:40, 30.87s/it]2022-01-08 15:04:43,387 iteration 171 : loss : 0.143683, loss_ce: 0.064365
2022-01-08 15:04:44,907 iteration 172 : loss : 0.180114, loss_ce: 0.082082
2022-01-08 15:04:46,527 iteration 173 : loss : 0.213427, loss_ce: 0.073644
2022-01-08 15:04:48,015 iteration 174 : loss : 0.217199, loss_ce: 0.108645
2022-01-08 15:04:49,557 iteration 175 : loss : 0.184318, loss_ce: 0.064986
2022-01-08 15:04:51,092 iteration 176 : loss : 0.156719, loss_ce: 0.072048
2022-01-08 15:04:52,699 iteration 177 : loss : 0.158487, loss_ce: 0.062958
2022-01-08 15:04:54,267 iteration 178 : loss : 0.196742, loss_ce: 0.075730
2022-01-08 15:04:55,764 iteration 179 : loss : 0.202659, loss_ce: 0.071866
2022-01-08 15:04:57,431 iteration 180 : loss : 0.219350, loss_ce: 0.102548
2022-01-08 15:04:59,045 iteration 181 : loss : 0.171214, loss_ce: 0.075564
2022-01-08 15:05:00,609 iteration 182 : loss : 0.166827, loss_ce: 0.074970
2022-01-08 15:05:02,204 iteration 183 : loss : 0.197942, loss_ce: 0.060114
2022-01-08 15:05:03,934 iteration 184 : loss : 0.199093, loss_ce: 0.070877
2022-01-08 15:05:05,648 iteration 185 : loss : 0.189382, loss_ce: 0.082623
2022-01-08 15:05:07,214 iteration 186 : loss : 0.205599, loss_ce: 0.079696
2022-01-08 15:05:08,815 iteration 187 : loss : 0.139814, loss_ce: 0.056640
  3%|▊                             | 11/400 [05:15<3:12:41, 29.72s/it]2022-01-08 15:05:10,402 iteration 188 : loss : 0.160282, loss_ce: 0.060748
2022-01-08 15:05:12,073 iteration 189 : loss : 0.173257, loss_ce: 0.069922
2022-01-08 15:05:13,691 iteration 190 : loss : 0.228899, loss_ce: 0.107742
2022-01-08 15:05:15,287 iteration 191 : loss : 0.158445, loss_ce: 0.064805
2022-01-08 15:05:16,858 iteration 192 : loss : 0.164967, loss_ce: 0.062162
2022-01-08 15:05:18,356 iteration 193 : loss : 0.179596, loss_ce: 0.082785
2022-01-08 15:05:19,959 iteration 194 : loss : 0.182279, loss_ce: 0.080969
2022-01-08 15:05:21,597 iteration 195 : loss : 0.136528, loss_ce: 0.048978
2022-01-08 15:05:23,169 iteration 196 : loss : 0.147012, loss_ce: 0.067489
2022-01-08 15:05:24,780 iteration 197 : loss : 0.165562, loss_ce: 0.060223
2022-01-08 15:05:26,364 iteration 198 : loss : 0.159232, loss_ce: 0.052918
2022-01-08 15:05:27,837 iteration 199 : loss : 0.196783, loss_ce: 0.059022
2022-01-08 15:05:29,393 iteration 200 : loss : 0.201449, loss_ce: 0.094275
2022-01-08 15:05:31,086 iteration 201 : loss : 0.198328, loss_ce: 0.089167
2022-01-08 15:05:32,638 iteration 202 : loss : 0.158368, loss_ce: 0.066135
2022-01-08 15:05:34,161 iteration 203 : loss : 0.214222, loss_ce: 0.109297
2022-01-08 15:05:35,653 iteration 204 : loss : 0.115749, loss_ce: 0.051821
  3%|▉                             | 12/400 [05:42<3:06:34, 28.85s/it]2022-01-08 15:05:37,211 iteration 205 : loss : 0.193841, loss_ce: 0.087947
2022-01-08 15:05:38,802 iteration 206 : loss : 0.226881, loss_ce: 0.114935
2022-01-08 15:05:40,480 iteration 207 : loss : 0.199917, loss_ce: 0.096472
2022-01-08 15:05:42,139 iteration 208 : loss : 0.130854, loss_ce: 0.050134
2022-01-08 15:05:43,663 iteration 209 : loss : 0.149291, loss_ce: 0.060874
2022-01-08 15:05:45,169 iteration 210 : loss : 0.145819, loss_ce: 0.050899
2022-01-08 15:05:46,726 iteration 211 : loss : 0.174115, loss_ce: 0.066933
2022-01-08 15:05:48,203 iteration 212 : loss : 0.200627, loss_ce: 0.068949
2022-01-08 15:05:49,822 iteration 213 : loss : 0.175023, loss_ce: 0.079770
2022-01-08 15:05:51,408 iteration 214 : loss : 0.190005, loss_ce: 0.056406
2022-01-08 15:05:52,910 iteration 215 : loss : 0.149634, loss_ce: 0.062671
2022-01-08 15:05:54,543 iteration 216 : loss : 0.174541, loss_ce: 0.076568
2022-01-08 15:05:56,084 iteration 217 : loss : 0.192224, loss_ce: 0.080648
2022-01-08 15:05:57,633 iteration 218 : loss : 0.131603, loss_ce: 0.055810
2022-01-08 15:05:59,182 iteration 219 : loss : 0.170851, loss_ce: 0.061429
2022-01-08 15:06:00,690 iteration 220 : loss : 0.176673, loss_ce: 0.089076
2022-01-08 15:06:02,243 iteration 221 : loss : 0.144009, loss_ce: 0.071205
  3%|▉                             | 13/400 [06:09<3:01:40, 28.17s/it]2022-01-08 15:06:04,001 iteration 222 : loss : 0.178068, loss_ce: 0.068308
2022-01-08 15:06:05,627 iteration 223 : loss : 0.145309, loss_ce: 0.045282
2022-01-08 15:06:07,102 iteration 224 : loss : 0.154880, loss_ce: 0.062983
2022-01-08 15:06:08,720 iteration 225 : loss : 0.159684, loss_ce: 0.056289
2022-01-08 15:06:10,377 iteration 226 : loss : 0.218597, loss_ce: 0.072540
2022-01-08 15:06:11,995 iteration 227 : loss : 0.161110, loss_ce: 0.062087
2022-01-08 15:06:13,587 iteration 228 : loss : 0.164692, loss_ce: 0.064355
2022-01-08 15:06:15,177 iteration 229 : loss : 0.153347, loss_ce: 0.069013
2022-01-08 15:06:16,748 iteration 230 : loss : 0.216365, loss_ce: 0.095423
2022-01-08 15:06:18,287 iteration 231 : loss : 0.216024, loss_ce: 0.078858
2022-01-08 15:06:19,939 iteration 232 : loss : 0.148895, loss_ce: 0.079464
2022-01-08 15:06:21,569 iteration 233 : loss : 0.155855, loss_ce: 0.080629
2022-01-08 15:06:23,181 iteration 234 : loss : 0.165519, loss_ce: 0.050244
2022-01-08 15:06:24,754 iteration 235 : loss : 0.124449, loss_ce: 0.046993
2022-01-08 15:06:26,364 iteration 236 : loss : 0.220827, loss_ce: 0.088110
2022-01-08 15:06:28,093 iteration 237 : loss : 0.134164, loss_ce: 0.049814
2022-01-08 15:06:29,907 iteration 238 : loss : 0.135274, loss_ce: 0.063796
  4%|█                             | 14/400 [06:36<3:00:12, 28.01s/it]2022-01-08 15:06:31,914 iteration 239 : loss : 0.133829, loss_ce: 0.056028
2022-01-08 15:06:33,937 iteration 240 : loss : 0.172093, loss_ce: 0.090311
2022-01-08 15:06:35,871 iteration 241 : loss : 0.221382, loss_ce: 0.085736
2022-01-08 15:06:37,856 iteration 242 : loss : 0.149129, loss_ce: 0.065548
2022-01-08 15:06:39,920 iteration 243 : loss : 0.160849, loss_ce: 0.074340
2022-01-08 15:06:41,954 iteration 244 : loss : 0.152350, loss_ce: 0.067146
2022-01-08 15:06:43,892 iteration 245 : loss : 0.141700, loss_ce: 0.043524
2022-01-08 15:06:45,937 iteration 246 : loss : 0.157722, loss_ce: 0.059898
2022-01-08 15:06:47,917 iteration 247 : loss : 0.115443, loss_ce: 0.049952
2022-01-08 15:06:49,867 iteration 248 : loss : 0.123952, loss_ce: 0.045348
2022-01-08 15:06:52,030 iteration 249 : loss : 0.132901, loss_ce: 0.046882
2022-01-08 15:06:54,070 iteration 250 : loss : 0.163656, loss_ce: 0.070068
2022-01-08 15:06:56,014 iteration 251 : loss : 0.096898, loss_ce: 0.043267
2022-01-08 15:06:58,036 iteration 252 : loss : 0.163666, loss_ce: 0.083826
2022-01-08 15:07:00,110 iteration 253 : loss : 0.184802, loss_ce: 0.061918
2022-01-08 15:07:02,133 iteration 254 : loss : 0.151576, loss_ce: 0.062994
2022-01-08 15:07:02,134 Training Data Eval:
2022-01-08 15:07:13,035   Average segmentation loss on training set: 0.1879
2022-01-08 15:07:13,035 Validation Data Eval:
2022-01-08 15:07:17,223   Average segmentation loss on validation set: 0.1973
2022-01-08 15:07:23,027 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 15:07:24,620 iteration 255 : loss : 0.232557, loss_ce: 0.101305
  4%|█▏                            | 15/400 [07:31<3:51:22, 36.06s/it]2022-01-08 15:07:26,237 iteration 256 : loss : 0.161672, loss_ce: 0.067076
2022-01-08 15:07:27,781 iteration 257 : loss : 0.151651, loss_ce: 0.079812
2022-01-08 15:07:29,485 iteration 258 : loss : 0.163222, loss_ce: 0.057129
2022-01-08 15:07:31,125 iteration 259 : loss : 0.163584, loss_ce: 0.068691
2022-01-08 15:07:32,934 iteration 260 : loss : 0.148553, loss_ce: 0.061907
2022-01-08 15:07:34,841 iteration 261 : loss : 0.202644, loss_ce: 0.078665
2022-01-08 15:07:36,774 iteration 262 : loss : 0.148400, loss_ce: 0.081939
2022-01-08 15:07:38,731 iteration 263 : loss : 0.167380, loss_ce: 0.083575
2022-01-08 15:07:40,813 iteration 264 : loss : 0.165888, loss_ce: 0.062475
2022-01-08 15:07:42,952 iteration 265 : loss : 0.155717, loss_ce: 0.070376
2022-01-08 15:07:45,100 iteration 266 : loss : 0.170099, loss_ce: 0.054470
2022-01-08 15:07:47,279 iteration 267 : loss : 0.155819, loss_ce: 0.074466
2022-01-08 15:07:49,520 iteration 268 : loss : 0.116583, loss_ce: 0.056640
2022-01-08 15:07:51,749 iteration 269 : loss : 0.119344, loss_ce: 0.051143
2022-01-08 15:07:53,955 iteration 270 : loss : 0.140641, loss_ce: 0.053531
2022-01-08 15:07:56,246 iteration 271 : loss : 0.262037, loss_ce: 0.095222
2022-01-08 15:07:58,583 iteration 272 : loss : 0.166085, loss_ce: 0.068844
  4%|█▏                            | 16/400 [08:05<3:46:45, 35.43s/it]2022-01-08 15:08:00,851 iteration 273 : loss : 0.160469, loss_ce: 0.057609
2022-01-08 15:08:03,165 iteration 274 : loss : 0.174898, loss_ce: 0.069810
2022-01-08 15:08:05,393 iteration 275 : loss : 0.136866, loss_ce: 0.058800
2022-01-08 15:08:07,645 iteration 276 : loss : 0.166968, loss_ce: 0.080266
2022-01-08 15:08:10,037 iteration 277 : loss : 0.169102, loss_ce: 0.061840
2022-01-08 15:08:12,265 iteration 278 : loss : 0.272233, loss_ce: 0.099232
2022-01-08 15:08:14,523 iteration 279 : loss : 0.147977, loss_ce: 0.056223
2022-01-08 15:08:16,663 iteration 280 : loss : 0.162708, loss_ce: 0.085396
2022-01-08 15:08:18,894 iteration 281 : loss : 0.161144, loss_ce: 0.060010
2022-01-08 15:08:21,125 iteration 282 : loss : 0.150893, loss_ce: 0.070314
2022-01-08 15:08:23,409 iteration 283 : loss : 0.130372, loss_ce: 0.061053
2022-01-08 15:08:25,688 iteration 284 : loss : 0.102211, loss_ce: 0.039963
2022-01-08 15:08:27,999 iteration 285 : loss : 0.139884, loss_ce: 0.049885
2022-01-08 15:08:30,284 iteration 286 : loss : 0.121115, loss_ce: 0.043301
2022-01-08 15:08:32,479 iteration 287 : loss : 0.141345, loss_ce: 0.049052
2022-01-08 15:08:34,883 iteration 288 : loss : 0.115649, loss_ce: 0.051121
2022-01-08 15:08:37,255 iteration 289 : loss : 0.145469, loss_ce: 0.070692
  4%|█▎                            | 17/400 [08:44<3:52:22, 36.40s/it]2022-01-08 15:08:39,655 iteration 290 : loss : 0.104771, loss_ce: 0.045071
2022-01-08 15:08:42,007 iteration 291 : loss : 0.118600, loss_ce: 0.049036
2022-01-08 15:08:44,427 iteration 292 : loss : 0.092636, loss_ce: 0.038627
2022-01-08 15:08:46,913 iteration 293 : loss : 0.157494, loss_ce: 0.075059
2022-01-08 15:08:49,195 iteration 294 : loss : 0.091980, loss_ce: 0.038587
2022-01-08 15:08:51,579 iteration 295 : loss : 0.155233, loss_ce: 0.055922
2022-01-08 15:08:53,934 iteration 296 : loss : 0.156649, loss_ce: 0.060492
2022-01-08 15:08:56,318 iteration 297 : loss : 0.130013, loss_ce: 0.049745
2022-01-08 15:08:58,626 iteration 298 : loss : 0.121956, loss_ce: 0.041961
2022-01-08 15:09:01,025 iteration 299 : loss : 0.186112, loss_ce: 0.061169
2022-01-08 15:09:03,382 iteration 300 : loss : 0.139030, loss_ce: 0.050899
2022-01-08 15:09:05,897 iteration 301 : loss : 0.189683, loss_ce: 0.057132
2022-01-08 15:09:08,345 iteration 302 : loss : 0.172524, loss_ce: 0.087435
2022-01-08 15:09:10,768 iteration 303 : loss : 0.148223, loss_ce: 0.073469
2022-01-08 15:09:13,074 iteration 304 : loss : 0.106877, loss_ce: 0.045586
2022-01-08 15:09:15,498 iteration 305 : loss : 0.119710, loss_ce: 0.046250
2022-01-08 15:09:17,853 iteration 306 : loss : 0.177578, loss_ce: 0.065912
  4%|█▎                            | 18/400 [09:24<3:59:46, 37.66s/it]2022-01-08 15:09:20,259 iteration 307 : loss : 0.140348, loss_ce: 0.061872
2022-01-08 15:09:22,647 iteration 308 : loss : 0.169056, loss_ce: 0.063498
2022-01-08 15:09:24,917 iteration 309 : loss : 0.164785, loss_ce: 0.077941
2022-01-08 15:09:27,105 iteration 310 : loss : 0.111796, loss_ce: 0.041918
2022-01-08 15:09:29,454 iteration 311 : loss : 0.126385, loss_ce: 0.048630
2022-01-08 15:09:31,883 iteration 312 : loss : 0.227822, loss_ce: 0.056240
2022-01-08 15:09:34,312 iteration 313 : loss : 0.137303, loss_ce: 0.051695
2022-01-08 15:09:36,619 iteration 314 : loss : 0.139149, loss_ce: 0.056889
2022-01-08 15:09:39,008 iteration 315 : loss : 0.137587, loss_ce: 0.061387
2022-01-08 15:09:41,426 iteration 316 : loss : 0.135198, loss_ce: 0.051604
2022-01-08 15:09:43,858 iteration 317 : loss : 0.126848, loss_ce: 0.058394
2022-01-08 15:09:46,247 iteration 318 : loss : 0.169406, loss_ce: 0.086762
2022-01-08 15:09:48,677 iteration 319 : loss : 0.093397, loss_ce: 0.043876
2022-01-08 15:09:51,043 iteration 320 : loss : 0.114586, loss_ce: 0.041406
2022-01-08 15:09:53,536 iteration 321 : loss : 0.122092, loss_ce: 0.045843
2022-01-08 15:09:55,864 iteration 322 : loss : 0.088960, loss_ce: 0.040923
2022-01-08 15:09:58,257 iteration 323 : loss : 0.090373, loss_ce: 0.042425
  5%|█▍                            | 19/400 [10:05<4:04:24, 38.49s/it]2022-01-08 15:10:00,675 iteration 324 : loss : 0.087327, loss_ce: 0.037336
2022-01-08 15:10:03,020 iteration 325 : loss : 0.130733, loss_ce: 0.043479
2022-01-08 15:10:05,327 iteration 326 : loss : 0.142383, loss_ce: 0.054653
2022-01-08 15:10:07,664 iteration 327 : loss : 0.136965, loss_ce: 0.051888
2022-01-08 15:10:10,048 iteration 328 : loss : 0.079191, loss_ce: 0.027467
2022-01-08 15:10:12,525 iteration 329 : loss : 0.146643, loss_ce: 0.050669
2022-01-08 15:10:15,074 iteration 330 : loss : 0.140712, loss_ce: 0.067068
2022-01-08 15:10:17,487 iteration 331 : loss : 0.154162, loss_ce: 0.062995
2022-01-08 15:10:19,779 iteration 332 : loss : 0.086993, loss_ce: 0.037294
2022-01-08 15:10:22,174 iteration 333 : loss : 0.147221, loss_ce: 0.068862
2022-01-08 15:10:24,599 iteration 334 : loss : 0.110482, loss_ce: 0.048564
2022-01-08 15:10:27,011 iteration 335 : loss : 0.135272, loss_ce: 0.070384
2022-01-08 15:10:29,338 iteration 336 : loss : 0.110982, loss_ce: 0.051837
2022-01-08 15:10:31,780 iteration 337 : loss : 0.155467, loss_ce: 0.061995
2022-01-08 15:10:34,204 iteration 338 : loss : 0.116414, loss_ce: 0.052410
2022-01-08 15:10:36,556 iteration 339 : loss : 0.129474, loss_ce: 0.057137
2022-01-08 15:10:36,556 Training Data Eval:
2022-01-08 15:10:49,374   Average segmentation loss on training set: 0.3713
2022-01-08 15:10:49,375 Validation Data Eval:
2022-01-08 15:10:53,887   Average segmentation loss on validation set: 0.3073
2022-01-08 15:10:56,313 iteration 340 : loss : 0.160754, loss_ce: 0.077781
  5%|█▌                            | 20/400 [11:03<4:40:56, 44.36s/it]2022-01-08 15:10:58,681 iteration 341 : loss : 0.082374, loss_ce: 0.037984
2022-01-08 15:11:01,036 iteration 342 : loss : 0.114426, loss_ce: 0.053768
2022-01-08 15:11:03,303 iteration 343 : loss : 0.119254, loss_ce: 0.053011
2022-01-08 15:11:05,550 iteration 344 : loss : 0.120111, loss_ce: 0.056572
2022-01-08 15:11:07,836 iteration 345 : loss : 0.118253, loss_ce: 0.049042
2022-01-08 15:11:10,217 iteration 346 : loss : 0.079930, loss_ce: 0.030823
2022-01-08 15:11:12,644 iteration 347 : loss : 0.112770, loss_ce: 0.050105
2022-01-08 15:11:14,972 iteration 348 : loss : 0.105193, loss_ce: 0.041346
2022-01-08 15:11:17,258 iteration 349 : loss : 0.100031, loss_ce: 0.036112
2022-01-08 15:11:19,607 iteration 350 : loss : 0.122250, loss_ce: 0.053408
2022-01-08 15:11:21,936 iteration 351 : loss : 0.121464, loss_ce: 0.039799
2022-01-08 15:11:24,412 iteration 352 : loss : 0.103871, loss_ce: 0.051995
2022-01-08 15:11:26,871 iteration 353 : loss : 0.109985, loss_ce: 0.044868
2022-01-08 15:11:29,195 iteration 354 : loss : 0.096261, loss_ce: 0.035692
2022-01-08 15:11:31,584 iteration 355 : loss : 0.090256, loss_ce: 0.031136
2022-01-08 15:11:34,009 iteration 356 : loss : 0.072168, loss_ce: 0.026536
2022-01-08 15:11:36,420 iteration 357 : loss : 0.114615, loss_ce: 0.045319
  5%|█▌                            | 21/400 [11:43<4:32:08, 43.08s/it]2022-01-08 15:11:38,955 iteration 358 : loss : 0.147948, loss_ce: 0.072681
2022-01-08 15:11:41,340 iteration 359 : loss : 0.105324, loss_ce: 0.044749
2022-01-08 15:11:43,667 iteration 360 : loss : 0.091500, loss_ce: 0.032704
2022-01-08 15:11:46,284 iteration 361 : loss : 0.137949, loss_ce: 0.046031
2022-01-08 15:11:48,713 iteration 362 : loss : 0.117432, loss_ce: 0.063704
2022-01-08 15:11:51,035 iteration 363 : loss : 0.094221, loss_ce: 0.043310
2022-01-08 15:11:53,402 iteration 364 : loss : 0.214544, loss_ce: 0.087614
2022-01-08 15:11:55,780 iteration 365 : loss : 0.102506, loss_ce: 0.044940
2022-01-08 15:11:58,358 iteration 366 : loss : 0.113283, loss_ce: 0.036034
2022-01-08 15:12:00,755 iteration 367 : loss : 0.135283, loss_ce: 0.057371
2022-01-08 15:12:03,276 iteration 368 : loss : 0.130484, loss_ce: 0.060021
2022-01-08 15:12:05,651 iteration 369 : loss : 0.093469, loss_ce: 0.039029
2022-01-08 15:12:07,999 iteration 370 : loss : 0.140336, loss_ce: 0.066593
2022-01-08 15:12:10,321 iteration 371 : loss : 0.117472, loss_ce: 0.042660
2022-01-08 15:12:12,707 iteration 372 : loss : 0.101173, loss_ce: 0.040706
2022-01-08 15:12:15,087 iteration 373 : loss : 0.082070, loss_ce: 0.035676
2022-01-08 15:12:17,517 iteration 374 : loss : 0.088947, loss_ce: 0.038705
  6%|█▋                            | 22/400 [12:24<4:27:40, 42.49s/it]2022-01-08 15:12:19,973 iteration 375 : loss : 0.097650, loss_ce: 0.042810
2022-01-08 15:12:22,382 iteration 376 : loss : 0.149988, loss_ce: 0.045218
2022-01-08 15:12:24,770 iteration 377 : loss : 0.136515, loss_ce: 0.051392
2022-01-08 15:12:27,270 iteration 378 : loss : 0.113257, loss_ce: 0.043211
2022-01-08 15:12:29,681 iteration 379 : loss : 0.096955, loss_ce: 0.040441
2022-01-08 15:12:32,010 iteration 380 : loss : 0.132249, loss_ce: 0.065487
2022-01-08 15:12:34,419 iteration 381 : loss : 0.106830, loss_ce: 0.044389
2022-01-08 15:12:36,782 iteration 382 : loss : 0.094166, loss_ce: 0.041278
2022-01-08 15:12:39,192 iteration 383 : loss : 0.148221, loss_ce: 0.035771
2022-01-08 15:12:41,615 iteration 384 : loss : 0.099942, loss_ce: 0.036769
2022-01-08 15:12:44,118 iteration 385 : loss : 0.117032, loss_ce: 0.052381
2022-01-08 15:12:46,511 iteration 386 : loss : 0.108003, loss_ce: 0.037031
2022-01-08 15:12:48,826 iteration 387 : loss : 0.079166, loss_ce: 0.032235
2022-01-08 15:12:51,233 iteration 388 : loss : 0.092152, loss_ce: 0.041786
2022-01-08 15:12:53,761 iteration 389 : loss : 0.089915, loss_ce: 0.032625
2022-01-08 15:12:56,159 iteration 390 : loss : 0.105354, loss_ce: 0.048423
2022-01-08 15:12:58,655 iteration 391 : loss : 0.069655, loss_ce: 0.029547
  6%|█▋                            | 23/400 [13:05<4:24:25, 42.08s/it]2022-01-08 15:13:01,159 iteration 392 : loss : 0.113490, loss_ce: 0.052898
2022-01-08 15:13:03,477 iteration 393 : loss : 0.119374, loss_ce: 0.058120
2022-01-08 15:13:05,875 iteration 394 : loss : 0.120065, loss_ce: 0.043721
2022-01-08 15:13:08,249 iteration 395 : loss : 0.101804, loss_ce: 0.035972
2022-01-08 15:13:10,625 iteration 396 : loss : 0.114562, loss_ce: 0.042329
2022-01-08 15:13:13,076 iteration 397 : loss : 0.091243, loss_ce: 0.042615
2022-01-08 15:13:15,431 iteration 398 : loss : 0.100726, loss_ce: 0.037113
2022-01-08 15:13:17,826 iteration 399 : loss : 0.131197, loss_ce: 0.050931
2022-01-08 15:13:20,226 iteration 400 : loss : 0.084407, loss_ce: 0.030688
2022-01-08 15:13:22,624 iteration 401 : loss : 0.090738, loss_ce: 0.043245
2022-01-08 15:13:25,115 iteration 402 : loss : 0.088589, loss_ce: 0.037630
2022-01-08 15:13:27,477 iteration 403 : loss : 0.107768, loss_ce: 0.038580
2022-01-08 15:13:29,810 iteration 404 : loss : 0.087522, loss_ce: 0.032134
2022-01-08 15:13:32,148 iteration 405 : loss : 0.115129, loss_ce: 0.055908
2022-01-08 15:13:34,574 iteration 406 : loss : 0.127599, loss_ce: 0.053440
2022-01-08 15:13:36,945 iteration 407 : loss : 0.097664, loss_ce: 0.040842
2022-01-08 15:13:39,348 iteration 408 : loss : 0.083548, loss_ce: 0.036380
  6%|█▊                            | 24/400 [13:46<4:21:08, 41.67s/it]2022-01-08 15:13:41,868 iteration 409 : loss : 0.134259, loss_ce: 0.039435
2022-01-08 15:13:44,285 iteration 410 : loss : 0.108709, loss_ce: 0.034994
2022-01-08 15:13:46,736 iteration 411 : loss : 0.167682, loss_ce: 0.055761
2022-01-08 15:13:49,180 iteration 412 : loss : 0.074771, loss_ce: 0.032172
2022-01-08 15:13:51,600 iteration 413 : loss : 0.112188, loss_ce: 0.035630
2022-01-08 15:13:53,935 iteration 414 : loss : 0.079786, loss_ce: 0.030561
2022-01-08 15:13:56,300 iteration 415 : loss : 0.120755, loss_ce: 0.051596
2022-01-08 15:13:58,582 iteration 416 : loss : 0.124442, loss_ce: 0.053015
2022-01-08 15:14:01,012 iteration 417 : loss : 0.087686, loss_ce: 0.027514
2022-01-08 15:14:03,325 iteration 418 : loss : 0.112470, loss_ce: 0.068804
2022-01-08 15:14:05,669 iteration 419 : loss : 0.118264, loss_ce: 0.034603
2022-01-08 15:14:08,016 iteration 420 : loss : 0.097716, loss_ce: 0.044546
2022-01-08 15:14:10,402 iteration 421 : loss : 0.168101, loss_ce: 0.087258
2022-01-08 15:14:12,765 iteration 422 : loss : 0.093869, loss_ce: 0.032689
2022-01-08 15:14:15,242 iteration 423 : loss : 0.122867, loss_ce: 0.048180
2022-01-08 15:14:17,657 iteration 424 : loss : 0.106258, loss_ce: 0.044301
2022-01-08 15:14:17,657 Training Data Eval:
2022-01-08 15:14:30,430   Average segmentation loss on training set: 0.1985
2022-01-08 15:14:30,430 Validation Data Eval:
2022-01-08 15:14:34,816   Average segmentation loss on validation set: 0.1790
2022-01-08 15:14:40,536 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 15:14:42,219 iteration 425 : loss : 0.130884, loss_ce: 0.054189
  6%|█▉                            | 25/400 [14:49<5:00:09, 48.03s/it]2022-01-08 15:14:43,906 iteration 426 : loss : 0.094959, loss_ce: 0.042565
2022-01-08 15:14:45,561 iteration 427 : loss : 0.119383, loss_ce: 0.045576
2022-01-08 15:14:47,365 iteration 428 : loss : 0.101980, loss_ce: 0.046184
2022-01-08 15:14:49,274 iteration 429 : loss : 0.093031, loss_ce: 0.032947
2022-01-08 15:14:51,357 iteration 430 : loss : 0.173768, loss_ce: 0.068151
2022-01-08 15:14:53,443 iteration 431 : loss : 0.129675, loss_ce: 0.043787
2022-01-08 15:14:55,609 iteration 432 : loss : 0.061593, loss_ce: 0.024491
2022-01-08 15:14:57,826 iteration 433 : loss : 0.107541, loss_ce: 0.032955
2022-01-08 15:15:00,047 iteration 434 : loss : 0.101450, loss_ce: 0.036309
2022-01-08 15:15:02,316 iteration 435 : loss : 0.156940, loss_ce: 0.074742
2022-01-08 15:15:04,743 iteration 436 : loss : 0.112248, loss_ce: 0.039617
2022-01-08 15:15:07,105 iteration 437 : loss : 0.133516, loss_ce: 0.053237
2022-01-08 15:15:09,457 iteration 438 : loss : 0.119815, loss_ce: 0.063652
2022-01-08 15:15:11,754 iteration 439 : loss : 0.110845, loss_ce: 0.053958
2022-01-08 15:15:14,004 iteration 440 : loss : 0.077387, loss_ce: 0.031052
2022-01-08 15:15:16,366 iteration 441 : loss : 0.104701, loss_ce: 0.051007
2022-01-08 15:15:18,679 iteration 442 : loss : 0.143956, loss_ce: 0.047920
  6%|█▉                            | 26/400 [15:25<4:37:43, 44.56s/it]2022-01-08 15:15:21,087 iteration 443 : loss : 0.074557, loss_ce: 0.039752
2022-01-08 15:15:23,609 iteration 444 : loss : 0.120755, loss_ce: 0.048875
2022-01-08 15:15:26,150 iteration 445 : loss : 0.150016, loss_ce: 0.070434
2022-01-08 15:15:28,392 iteration 446 : loss : 0.166582, loss_ce: 0.066952
2022-01-08 15:15:30,738 iteration 447 : loss : 0.123069, loss_ce: 0.055877
2022-01-08 15:15:33,194 iteration 448 : loss : 0.081168, loss_ce: 0.038646
2022-01-08 15:15:35,573 iteration 449 : loss : 0.089870, loss_ce: 0.038662
2022-01-08 15:15:37,836 iteration 450 : loss : 0.072749, loss_ce: 0.032650
2022-01-08 15:15:40,193 iteration 451 : loss : 0.085536, loss_ce: 0.030827
2022-01-08 15:15:42,603 iteration 452 : loss : 0.065085, loss_ce: 0.028530
2022-01-08 15:15:44,958 iteration 453 : loss : 0.072755, loss_ce: 0.023453
2022-01-08 15:15:47,347 iteration 454 : loss : 0.158677, loss_ce: 0.049481
2022-01-08 15:15:49,701 iteration 455 : loss : 0.072035, loss_ce: 0.022861
2022-01-08 15:15:52,009 iteration 456 : loss : 0.120509, loss_ce: 0.034370
2022-01-08 15:15:54,324 iteration 457 : loss : 0.109353, loss_ce: 0.041190
2022-01-08 15:15:56,666 iteration 458 : loss : 0.126623, loss_ce: 0.055773
2022-01-08 15:15:59,064 iteration 459 : loss : 0.077550, loss_ce: 0.030526
  7%|██                            | 27/400 [16:05<4:29:13, 43.31s/it]2022-01-08 15:16:01,471 iteration 460 : loss : 0.086662, loss_ce: 0.030552
2022-01-08 15:16:03,885 iteration 461 : loss : 0.120965, loss_ce: 0.048319
2022-01-08 15:16:06,330 iteration 462 : loss : 0.156934, loss_ce: 0.048509
2022-01-08 15:16:08,672 iteration 463 : loss : 0.083007, loss_ce: 0.040423
2022-01-08 15:16:11,122 iteration 464 : loss : 0.091345, loss_ce: 0.039803
2022-01-08 15:16:13,496 iteration 465 : loss : 0.077157, loss_ce: 0.037976
2022-01-08 15:16:15,843 iteration 466 : loss : 0.105252, loss_ce: 0.044192
2022-01-08 15:16:18,091 iteration 467 : loss : 0.104833, loss_ce: 0.038882
2022-01-08 15:16:20,424 iteration 468 : loss : 0.109110, loss_ce: 0.043502
2022-01-08 15:16:22,738 iteration 469 : loss : 0.097741, loss_ce: 0.035380
2022-01-08 15:16:25,268 iteration 470 : loss : 0.122606, loss_ce: 0.054036
2022-01-08 15:16:27,625 iteration 471 : loss : 0.076609, loss_ce: 0.029953
2022-01-08 15:16:30,042 iteration 472 : loss : 0.100851, loss_ce: 0.035916
2022-01-08 15:16:32,395 iteration 473 : loss : 0.083238, loss_ce: 0.032544
2022-01-08 15:16:34,876 iteration 474 : loss : 0.088983, loss_ce: 0.034229
2022-01-08 15:16:37,283 iteration 475 : loss : 0.103709, loss_ce: 0.032254
2022-01-08 15:16:39,669 iteration 476 : loss : 0.083372, loss_ce: 0.040321
  7%|██                            | 28/400 [16:46<4:23:29, 42.50s/it]2022-01-08 15:16:41,995 iteration 477 : loss : 0.103162, loss_ce: 0.043790
2022-01-08 15:16:44,415 iteration 478 : loss : 0.121148, loss_ce: 0.043944
2022-01-08 15:16:46,756 iteration 479 : loss : 0.086561, loss_ce: 0.035404
2022-01-08 15:16:49,020 iteration 480 : loss : 0.105140, loss_ce: 0.047348
2022-01-08 15:16:51,326 iteration 481 : loss : 0.089637, loss_ce: 0.041114
2022-01-08 15:16:53,861 iteration 482 : loss : 0.089967, loss_ce: 0.034652
2022-01-08 15:16:56,286 iteration 483 : loss : 0.083282, loss_ce: 0.029697
2022-01-08 15:16:58,607 iteration 484 : loss : 0.075041, loss_ce: 0.028771
2022-01-08 15:17:00,927 iteration 485 : loss : 0.066652, loss_ce: 0.027369
2022-01-08 15:17:03,344 iteration 486 : loss : 0.234003, loss_ce: 0.072512
2022-01-08 15:17:05,766 iteration 487 : loss : 0.114447, loss_ce: 0.052994
2022-01-08 15:17:08,212 iteration 488 : loss : 0.126617, loss_ce: 0.046909
2022-01-08 15:17:10,717 iteration 489 : loss : 0.071843, loss_ce: 0.027580
2022-01-08 15:17:13,098 iteration 490 : loss : 0.081429, loss_ce: 0.036917
2022-01-08 15:17:15,502 iteration 491 : loss : 0.095559, loss_ce: 0.041328
2022-01-08 15:17:17,999 iteration 492 : loss : 0.091029, loss_ce: 0.037862
2022-01-08 15:17:20,397 iteration 493 : loss : 0.120515, loss_ce: 0.054824
  7%|██▏                           | 29/400 [17:27<4:19:29, 41.97s/it]2022-01-08 15:17:22,789 iteration 494 : loss : 0.125919, loss_ce: 0.047729
2022-01-08 15:17:25,174 iteration 495 : loss : 0.087102, loss_ce: 0.032766
2022-01-08 15:17:27,558 iteration 496 : loss : 0.113563, loss_ce: 0.050532
2022-01-08 15:17:29,989 iteration 497 : loss : 0.114306, loss_ce: 0.041171
2022-01-08 15:17:32,402 iteration 498 : loss : 0.107060, loss_ce: 0.044216
2022-01-08 15:17:34,870 iteration 499 : loss : 0.093585, loss_ce: 0.043082
2022-01-08 15:17:37,133 iteration 500 : loss : 0.075362, loss_ce: 0.030923
2022-01-08 15:17:39,455 iteration 501 : loss : 0.098438, loss_ce: 0.033277
2022-01-08 15:17:41,783 iteration 502 : loss : 0.099122, loss_ce: 0.033830
2022-01-08 15:17:44,140 iteration 503 : loss : 0.108003, loss_ce: 0.051208
2022-01-08 15:17:46,590 iteration 504 : loss : 0.080315, loss_ce: 0.029360
2022-01-08 15:17:49,031 iteration 505 : loss : 0.080745, loss_ce: 0.034496
2022-01-08 15:17:51,442 iteration 506 : loss : 0.110156, loss_ce: 0.056077
2022-01-08 15:17:53,790 iteration 507 : loss : 0.095356, loss_ce: 0.032368
2022-01-08 15:17:56,169 iteration 508 : loss : 0.087118, loss_ce: 0.028579
2022-01-08 15:17:58,567 iteration 509 : loss : 0.079850, loss_ce: 0.038095
2022-01-08 15:17:58,567 Training Data Eval:
2022-01-08 15:18:11,375   Average segmentation loss on training set: 0.1132
2022-01-08 15:18:11,376 Validation Data Eval:
2022-01-08 15:18:15,770   Average segmentation loss on validation set: 0.2002
2022-01-08 15:18:18,178 iteration 510 : loss : 0.078473, loss_ce: 0.032159
  8%|██▎                           | 30/400 [18:25<4:48:04, 46.71s/it]2022-01-08 15:18:20,551 iteration 511 : loss : 0.076689, loss_ce: 0.025932
2022-01-08 15:18:22,866 iteration 512 : loss : 0.092187, loss_ce: 0.043917
2022-01-08 15:18:25,287 iteration 513 : loss : 0.081567, loss_ce: 0.030247
2022-01-08 15:18:27,672 iteration 514 : loss : 0.089997, loss_ce: 0.037928
2022-01-08 15:18:29,899 iteration 515 : loss : 0.077691, loss_ce: 0.033615
2022-01-08 15:18:32,129 iteration 516 : loss : 0.062715, loss_ce: 0.022880
2022-01-08 15:18:34,516 iteration 517 : loss : 0.081906, loss_ce: 0.037459
2022-01-08 15:18:36,908 iteration 518 : loss : 0.152133, loss_ce: 0.062421
2022-01-08 15:18:39,269 iteration 519 : loss : 0.083552, loss_ce: 0.039922
2022-01-08 15:18:41,586 iteration 520 : loss : 0.079662, loss_ce: 0.035454
2022-01-08 15:18:43,869 iteration 521 : loss : 0.060376, loss_ce: 0.021100
2022-01-08 15:18:46,345 iteration 522 : loss : 0.103371, loss_ce: 0.035487
2022-01-08 15:18:48,723 iteration 523 : loss : 0.088909, loss_ce: 0.028126
2022-01-08 15:18:51,031 iteration 524 : loss : 0.080006, loss_ce: 0.037285
2022-01-08 15:18:53,445 iteration 525 : loss : 0.067826, loss_ce: 0.026021
2022-01-08 15:18:55,851 iteration 526 : loss : 0.074017, loss_ce: 0.026445
2022-01-08 15:18:58,225 iteration 527 : loss : 0.087006, loss_ce: 0.028627
  8%|██▎                           | 31/400 [19:05<4:34:59, 44.71s/it]2022-01-08 15:19:00,587 iteration 528 : loss : 0.068902, loss_ce: 0.029666
2022-01-08 15:19:03,009 iteration 529 : loss : 0.111556, loss_ce: 0.036523
2022-01-08 15:19:05,275 iteration 530 : loss : 0.073537, loss_ce: 0.026921
2022-01-08 15:19:07,625 iteration 531 : loss : 0.080548, loss_ce: 0.029515
2022-01-08 15:19:10,054 iteration 532 : loss : 0.100603, loss_ce: 0.043851
2022-01-08 15:19:12,451 iteration 533 : loss : 0.090176, loss_ce: 0.037609
2022-01-08 15:19:14,797 iteration 534 : loss : 0.095907, loss_ce: 0.035905
2022-01-08 15:19:17,225 iteration 535 : loss : 0.073353, loss_ce: 0.026359
2022-01-08 15:19:19,600 iteration 536 : loss : 0.080304, loss_ce: 0.038591
2022-01-08 15:19:21,941 iteration 537 : loss : 0.125700, loss_ce: 0.057498
2022-01-08 15:19:24,332 iteration 538 : loss : 0.098414, loss_ce: 0.047349
2022-01-08 15:19:26,623 iteration 539 : loss : 0.088184, loss_ce: 0.034050
2022-01-08 15:19:29,102 iteration 540 : loss : 0.113777, loss_ce: 0.061866
2022-01-08 15:19:31,425 iteration 541 : loss : 0.132776, loss_ce: 0.062900
2022-01-08 15:19:33,635 iteration 542 : loss : 0.139187, loss_ce: 0.060502
2022-01-08 15:19:35,878 iteration 543 : loss : 0.070513, loss_ce: 0.031727
2022-01-08 15:19:38,211 iteration 544 : loss : 0.160750, loss_ce: 0.046959
  8%|██▍                           | 32/400 [19:45<4:25:32, 43.29s/it]2022-01-08 15:19:40,588 iteration 545 : loss : 0.098773, loss_ce: 0.049526
2022-01-08 15:19:42,900 iteration 546 : loss : 0.080229, loss_ce: 0.033080
2022-01-08 15:19:45,329 iteration 547 : loss : 0.117552, loss_ce: 0.045425
2022-01-08 15:19:47,700 iteration 548 : loss : 0.133047, loss_ce: 0.048271
2022-01-08 15:19:50,036 iteration 549 : loss : 0.099435, loss_ce: 0.037328
2022-01-08 15:19:52,344 iteration 550 : loss : 0.086778, loss_ce: 0.029545
2022-01-08 15:19:54,680 iteration 551 : loss : 0.067925, loss_ce: 0.019795
2022-01-08 15:19:57,024 iteration 552 : loss : 0.116760, loss_ce: 0.046640
2022-01-08 15:19:59,312 iteration 553 : loss : 0.076440, loss_ce: 0.029364
2022-01-08 15:20:01,595 iteration 554 : loss : 0.096321, loss_ce: 0.033135
2022-01-08 15:20:03,924 iteration 555 : loss : 0.073402, loss_ce: 0.022385
2022-01-08 15:20:06,356 iteration 556 : loss : 0.084038, loss_ce: 0.037748
2022-01-08 15:20:08,584 iteration 557 : loss : 0.087709, loss_ce: 0.043742
2022-01-08 15:20:10,841 iteration 558 : loss : 0.087547, loss_ce: 0.034436
2022-01-08 15:20:13,123 iteration 559 : loss : 0.090497, loss_ce: 0.036350
2022-01-08 15:20:15,499 iteration 560 : loss : 0.083795, loss_ce: 0.039595
2022-01-08 15:20:17,845 iteration 561 : loss : 0.066456, loss_ce: 0.029870
  8%|██▍                           | 33/400 [20:24<4:18:05, 42.20s/it]2022-01-08 15:20:20,229 iteration 562 : loss : 0.087061, loss_ce: 0.029200
2022-01-08 15:20:22,481 iteration 563 : loss : 0.054737, loss_ce: 0.026042
2022-01-08 15:20:24,716 iteration 564 : loss : 0.080866, loss_ce: 0.040533
2022-01-08 15:20:27,017 iteration 565 : loss : 0.073529, loss_ce: 0.034614
2022-01-08 15:20:29,359 iteration 566 : loss : 0.085869, loss_ce: 0.027755
2022-01-08 15:20:31,769 iteration 567 : loss : 0.126438, loss_ce: 0.049786
2022-01-08 15:20:34,134 iteration 568 : loss : 0.098011, loss_ce: 0.024599
2022-01-08 15:20:36,520 iteration 569 : loss : 0.131185, loss_ce: 0.041463
2022-01-08 15:20:38,802 iteration 570 : loss : 0.121298, loss_ce: 0.057777
2022-01-08 15:20:41,066 iteration 571 : loss : 0.075589, loss_ce: 0.032523
2022-01-08 15:20:43,358 iteration 572 : loss : 0.113066, loss_ce: 0.059790
2022-01-08 15:20:45,625 iteration 573 : loss : 0.092577, loss_ce: 0.039669
2022-01-08 15:20:48,023 iteration 574 : loss : 0.076910, loss_ce: 0.029613
2022-01-08 15:20:50,326 iteration 575 : loss : 0.106382, loss_ce: 0.030327
2022-01-08 15:20:52,589 iteration 576 : loss : 0.077705, loss_ce: 0.037226
2022-01-08 15:20:55,073 iteration 577 : loss : 0.085366, loss_ce: 0.036995
2022-01-08 15:20:57,388 iteration 578 : loss : 0.060761, loss_ce: 0.027113
  8%|██▌                           | 34/400 [21:04<4:12:31, 41.40s/it]2022-01-08 15:20:59,602 iteration 579 : loss : 0.062712, loss_ce: 0.028842
2022-01-08 15:21:01,809 iteration 580 : loss : 0.083968, loss_ce: 0.033672
2022-01-08 15:21:04,130 iteration 581 : loss : 0.056260, loss_ce: 0.023365
2022-01-08 15:21:06,339 iteration 582 : loss : 0.071154, loss_ce: 0.031408
2022-01-08 15:21:08,564 iteration 583 : loss : 0.084774, loss_ce: 0.037566
2022-01-08 15:21:10,839 iteration 584 : loss : 0.070753, loss_ce: 0.029733
2022-01-08 15:21:13,080 iteration 585 : loss : 0.084998, loss_ce: 0.031093
2022-01-08 15:21:15,430 iteration 586 : loss : 0.084434, loss_ce: 0.031232
2022-01-08 15:21:17,741 iteration 587 : loss : 0.054200, loss_ce: 0.025205
2022-01-08 15:21:20,086 iteration 588 : loss : 0.083766, loss_ce: 0.031087
2022-01-08 15:21:22,452 iteration 589 : loss : 0.091825, loss_ce: 0.039485
2022-01-08 15:21:24,739 iteration 590 : loss : 0.064974, loss_ce: 0.023233
2022-01-08 15:21:27,038 iteration 591 : loss : 0.103888, loss_ce: 0.035364
2022-01-08 15:21:29,394 iteration 592 : loss : 0.063919, loss_ce: 0.028741
2022-01-08 15:21:31,696 iteration 593 : loss : 0.087904, loss_ce: 0.034084
2022-01-08 15:21:34,101 iteration 594 : loss : 0.073288, loss_ce: 0.025823
2022-01-08 15:21:34,101 Training Data Eval:
2022-01-08 15:21:46,771   Average segmentation loss on training set: 0.2082
2022-01-08 15:21:46,771 Validation Data Eval:
2022-01-08 15:21:51,282   Average segmentation loss on validation set: 0.3403
2022-01-08 15:21:53,779 iteration 595 : loss : 0.118745, loss_ce: 0.042397
  9%|██▋                           | 35/400 [22:00<4:39:12, 45.90s/it]2022-01-08 15:21:56,313 iteration 596 : loss : 0.084510, loss_ce: 0.034570
2022-01-08 15:21:58,640 iteration 597 : loss : 0.056602, loss_ce: 0.024347
2022-01-08 15:22:01,078 iteration 598 : loss : 0.058327, loss_ce: 0.021306
2022-01-08 15:22:03,500 iteration 599 : loss : 0.099657, loss_ce: 0.031437
2022-01-08 15:22:05,888 iteration 600 : loss : 0.054039, loss_ce: 0.019485
2022-01-08 15:22:08,315 iteration 601 : loss : 0.064729, loss_ce: 0.023729
2022-01-08 15:22:10,605 iteration 602 : loss : 0.071306, loss_ce: 0.031419
2022-01-08 15:22:12,986 iteration 603 : loss : 0.083312, loss_ce: 0.032520
2022-01-08 15:22:15,364 iteration 604 : loss : 0.106890, loss_ce: 0.034740
2022-01-08 15:22:17,825 iteration 605 : loss : 0.074902, loss_ce: 0.030654
2022-01-08 15:22:20,339 iteration 606 : loss : 0.062508, loss_ce: 0.027226
2022-01-08 15:22:22,720 iteration 607 : loss : 0.061894, loss_ce: 0.021158
2022-01-08 15:22:25,064 iteration 608 : loss : 0.049311, loss_ce: 0.023239
2022-01-08 15:22:27,358 iteration 609 : loss : 0.081230, loss_ce: 0.028793
2022-01-08 15:22:29,765 iteration 610 : loss : 0.086926, loss_ce: 0.037870
2022-01-08 15:22:32,136 iteration 611 : loss : 0.069252, loss_ce: 0.029539
2022-01-08 15:22:34,449 iteration 612 : loss : 0.054825, loss_ce: 0.021408
  9%|██▋                           | 36/400 [22:41<4:28:55, 44.33s/it]2022-01-08 15:22:36,849 iteration 613 : loss : 0.092693, loss_ce: 0.032539
2022-01-08 15:22:39,209 iteration 614 : loss : 0.086641, loss_ce: 0.036030
2022-01-08 15:22:41,541 iteration 615 : loss : 0.063607, loss_ce: 0.030427
2022-01-08 15:22:43,945 iteration 616 : loss : 0.091874, loss_ce: 0.033898
2022-01-08 15:22:46,418 iteration 617 : loss : 0.097715, loss_ce: 0.034415
2022-01-08 15:22:48,883 iteration 618 : loss : 0.064323, loss_ce: 0.027572
2022-01-08 15:22:51,230 iteration 619 : loss : 0.062076, loss_ce: 0.024332
2022-01-08 15:22:53,656 iteration 620 : loss : 0.052109, loss_ce: 0.021962
2022-01-08 15:22:55,963 iteration 621 : loss : 0.061611, loss_ce: 0.022094
2022-01-08 15:22:58,463 iteration 622 : loss : 0.077772, loss_ce: 0.030701
2022-01-08 15:23:00,902 iteration 623 : loss : 0.075098, loss_ce: 0.032866
2022-01-08 15:23:03,222 iteration 624 : loss : 0.079453, loss_ce: 0.032299
2022-01-08 15:23:05,675 iteration 625 : loss : 0.073103, loss_ce: 0.032573
2022-01-08 15:23:08,045 iteration 626 : loss : 0.066988, loss_ce: 0.024054
2022-01-08 15:23:10,375 iteration 627 : loss : 0.089109, loss_ce: 0.028329
2022-01-08 15:23:12,699 iteration 628 : loss : 0.092044, loss_ce: 0.032197
2022-01-08 15:23:15,109 iteration 629 : loss : 0.074162, loss_ce: 0.031002
  9%|██▊                           | 37/400 [23:21<4:21:31, 43.23s/it]2022-01-08 15:23:17,517 iteration 630 : loss : 0.054925, loss_ce: 0.026146
2022-01-08 15:23:19,938 iteration 631 : loss : 0.082682, loss_ce: 0.028982
2022-01-08 15:23:22,426 iteration 632 : loss : 0.055383, loss_ce: 0.020980
2022-01-08 15:23:24,850 iteration 633 : loss : 0.067222, loss_ce: 0.029224
2022-01-08 15:23:27,254 iteration 634 : loss : 0.054551, loss_ce: 0.024543
2022-01-08 15:23:29,555 iteration 635 : loss : 0.070783, loss_ce: 0.028417
2022-01-08 15:23:31,827 iteration 636 : loss : 0.104707, loss_ce: 0.029664
2022-01-08 15:23:34,092 iteration 637 : loss : 0.066749, loss_ce: 0.032785
2022-01-08 15:23:36,444 iteration 638 : loss : 0.048449, loss_ce: 0.022382
2022-01-08 15:23:38,860 iteration 639 : loss : 0.057286, loss_ce: 0.027834
2022-01-08 15:23:41,263 iteration 640 : loss : 0.076577, loss_ce: 0.027929
2022-01-08 15:23:43,629 iteration 641 : loss : 0.070528, loss_ce: 0.025649
2022-01-08 15:23:45,993 iteration 642 : loss : 0.057709, loss_ce: 0.020041
2022-01-08 15:23:48,282 iteration 643 : loss : 0.089133, loss_ce: 0.029367
2022-01-08 15:23:50,697 iteration 644 : loss : 0.068001, loss_ce: 0.021867
2022-01-08 15:23:53,076 iteration 645 : loss : 0.103855, loss_ce: 0.044296
2022-01-08 15:23:55,464 iteration 646 : loss : 0.081754, loss_ce: 0.033614
 10%|██▊                           | 38/400 [24:02<4:15:36, 42.37s/it]2022-01-08 15:23:57,853 iteration 647 : loss : 0.066778, loss_ce: 0.031337
2022-01-08 15:24:00,449 iteration 648 : loss : 0.082501, loss_ce: 0.036543
2022-01-08 15:24:02,858 iteration 649 : loss : 0.092797, loss_ce: 0.045371
2022-01-08 15:24:05,137 iteration 650 : loss : 0.076456, loss_ce: 0.042531
2022-01-08 15:24:07,510 iteration 651 : loss : 0.074747, loss_ce: 0.028191
2022-01-08 15:24:09,875 iteration 652 : loss : 0.086849, loss_ce: 0.025369
2022-01-08 15:24:12,226 iteration 653 : loss : 0.105951, loss_ce: 0.032933
2022-01-08 15:24:14,565 iteration 654 : loss : 0.085023, loss_ce: 0.032339
2022-01-08 15:24:17,035 iteration 655 : loss : 0.055197, loss_ce: 0.021957
2022-01-08 15:24:19,395 iteration 656 : loss : 0.070488, loss_ce: 0.025823
2022-01-08 15:24:21,800 iteration 657 : loss : 0.052541, loss_ce: 0.021530
2022-01-08 15:24:24,263 iteration 658 : loss : 0.124605, loss_ce: 0.042496
2022-01-08 15:24:26,693 iteration 659 : loss : 0.071748, loss_ce: 0.029596
2022-01-08 15:24:29,090 iteration 660 : loss : 0.070323, loss_ce: 0.027991
2022-01-08 15:24:31,469 iteration 661 : loss : 0.073193, loss_ce: 0.031536
2022-01-08 15:24:33,814 iteration 662 : loss : 0.052553, loss_ce: 0.026210
2022-01-08 15:24:36,133 iteration 663 : loss : 0.069936, loss_ce: 0.021284
 10%|██▉                           | 39/400 [24:43<4:11:51, 41.86s/it]2022-01-08 15:24:38,496 iteration 664 : loss : 0.071346, loss_ce: 0.036155
2022-01-08 15:24:40,749 iteration 665 : loss : 0.068761, loss_ce: 0.029912
2022-01-08 15:24:43,047 iteration 666 : loss : 0.066912, loss_ce: 0.023863
2022-01-08 15:24:45,389 iteration 667 : loss : 0.048390, loss_ce: 0.020022
2022-01-08 15:24:47,748 iteration 668 : loss : 0.081884, loss_ce: 0.028935
2022-01-08 15:24:50,055 iteration 669 : loss : 0.069802, loss_ce: 0.030777
2022-01-08 15:24:52,413 iteration 670 : loss : 0.052118, loss_ce: 0.022065
2022-01-08 15:24:54,849 iteration 671 : loss : 0.068951, loss_ce: 0.020965
2022-01-08 15:24:57,243 iteration 672 : loss : 0.059408, loss_ce: 0.022054
2022-01-08 15:24:59,647 iteration 673 : loss : 0.064593, loss_ce: 0.029261
2022-01-08 15:25:02,100 iteration 674 : loss : 0.084569, loss_ce: 0.035111
2022-01-08 15:25:04,534 iteration 675 : loss : 0.075746, loss_ce: 0.026947
2022-01-08 15:25:06,861 iteration 676 : loss : 0.080622, loss_ce: 0.024573
2022-01-08 15:25:09,231 iteration 677 : loss : 0.078347, loss_ce: 0.036331
2022-01-08 15:25:11,625 iteration 678 : loss : 0.048976, loss_ce: 0.017850
2022-01-08 15:25:14,100 iteration 679 : loss : 0.081529, loss_ce: 0.040161
2022-01-08 15:25:14,101 Training Data Eval:
2022-01-08 15:25:26,977   Average segmentation loss on training set: 0.0772
2022-01-08 15:25:26,978 Validation Data Eval:
2022-01-08 15:25:31,484   Average segmentation loss on validation set: 0.0914
2022-01-08 15:25:37,296 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 15:25:38,936 iteration 680 : loss : 0.133818, loss_ce: 0.034748
 10%|███                           | 40/400 [25:45<4:48:50, 48.14s/it]2022-01-08 15:25:40,635 iteration 681 : loss : 0.075257, loss_ce: 0.035409
2022-01-08 15:25:42,264 iteration 682 : loss : 0.043716, loss_ce: 0.016769
2022-01-08 15:25:44,153 iteration 683 : loss : 0.071169, loss_ce: 0.029064
2022-01-08 15:25:46,223 iteration 684 : loss : 0.071181, loss_ce: 0.028215
2022-01-08 15:25:48,432 iteration 685 : loss : 0.052812, loss_ce: 0.022301
2022-01-08 15:25:50,599 iteration 686 : loss : 0.069132, loss_ce: 0.022009
2022-01-08 15:25:52,792 iteration 687 : loss : 0.057006, loss_ce: 0.019830
2022-01-08 15:25:55,084 iteration 688 : loss : 0.071017, loss_ce: 0.032991
2022-01-08 15:25:57,380 iteration 689 : loss : 0.053797, loss_ce: 0.022653
2022-01-08 15:25:59,723 iteration 690 : loss : 0.106443, loss_ce: 0.056470
2022-01-08 15:26:02,209 iteration 691 : loss : 0.068846, loss_ce: 0.033013
2022-01-08 15:26:04,662 iteration 692 : loss : 0.073199, loss_ce: 0.025285
2022-01-08 15:26:07,279 iteration 693 : loss : 0.109295, loss_ce: 0.044515
2022-01-08 15:26:09,686 iteration 694 : loss : 0.065035, loss_ce: 0.024646
2022-01-08 15:26:12,084 iteration 695 : loss : 0.074453, loss_ce: 0.024513
2022-01-08 15:26:14,462 iteration 696 : loss : 0.075360, loss_ce: 0.031345
2022-01-08 15:26:16,845 iteration 697 : loss : 0.072535, loss_ce: 0.029302
 10%|███                           | 41/400 [26:23<4:29:41, 45.07s/it]2022-01-08 15:26:19,274 iteration 698 : loss : 0.068867, loss_ce: 0.025421
2022-01-08 15:26:21,808 iteration 699 : loss : 0.064266, loss_ce: 0.020928
2022-01-08 15:26:24,207 iteration 700 : loss : 0.080220, loss_ce: 0.029908
2022-01-08 15:26:26,553 iteration 701 : loss : 0.088626, loss_ce: 0.033443
2022-01-08 15:26:28,896 iteration 702 : loss : 0.063955, loss_ce: 0.020585
2022-01-08 15:26:31,181 iteration 703 : loss : 0.072335, loss_ce: 0.030077
2022-01-08 15:26:33,725 iteration 704 : loss : 0.101572, loss_ce: 0.036975
2022-01-08 15:26:36,106 iteration 705 : loss : 0.088299, loss_ce: 0.043562
2022-01-08 15:26:38,544 iteration 706 : loss : 0.074076, loss_ce: 0.030604
2022-01-08 15:26:40,892 iteration 707 : loss : 0.084460, loss_ce: 0.034335
2022-01-08 15:26:43,255 iteration 708 : loss : 0.075443, loss_ce: 0.029116
2022-01-08 15:26:45,578 iteration 709 : loss : 0.069263, loss_ce: 0.030200
2022-01-08 15:26:47,905 iteration 710 : loss : 0.059201, loss_ce: 0.020909
2022-01-08 15:26:50,269 iteration 711 : loss : 0.123370, loss_ce: 0.040215
2022-01-08 15:26:52,764 iteration 712 : loss : 0.062690, loss_ce: 0.028825
2022-01-08 15:26:55,117 iteration 713 : loss : 0.059968, loss_ce: 0.025841
2022-01-08 15:26:57,500 iteration 714 : loss : 0.059992, loss_ce: 0.027678
 10%|███▏                          | 42/400 [27:04<4:21:00, 43.74s/it]2022-01-08 15:26:59,936 iteration 715 : loss : 0.061992, loss_ce: 0.028180
2022-01-08 15:27:02,354 iteration 716 : loss : 0.106096, loss_ce: 0.033214
2022-01-08 15:27:04,735 iteration 717 : loss : 0.055924, loss_ce: 0.023077
2022-01-08 15:27:07,115 iteration 718 : loss : 0.046265, loss_ce: 0.017733
2022-01-08 15:27:09,639 iteration 719 : loss : 0.060964, loss_ce: 0.033260
2022-01-08 15:27:11,979 iteration 720 : loss : 0.058834, loss_ce: 0.025544
2022-01-08 15:27:14,453 iteration 721 : loss : 0.109364, loss_ce: 0.041729
2022-01-08 15:27:16,792 iteration 722 : loss : 0.060455, loss_ce: 0.031691
2022-01-08 15:27:19,107 iteration 723 : loss : 0.101514, loss_ce: 0.041761
2022-01-08 15:27:21,550 iteration 724 : loss : 0.088709, loss_ce: 0.036279
2022-01-08 15:27:23,897 iteration 725 : loss : 0.050666, loss_ce: 0.022639
2022-01-08 15:27:26,343 iteration 726 : loss : 0.079611, loss_ce: 0.043069
2022-01-08 15:27:28,738 iteration 727 : loss : 0.050155, loss_ce: 0.020676
2022-01-08 15:27:31,118 iteration 728 : loss : 0.074392, loss_ce: 0.023753
2022-01-08 15:27:33,452 iteration 729 : loss : 0.095643, loss_ce: 0.049053
2022-01-08 15:27:35,862 iteration 730 : loss : 0.066591, loss_ce: 0.027427
2022-01-08 15:27:38,294 iteration 731 : loss : 0.090550, loss_ce: 0.030224
 11%|███▏                          | 43/400 [27:45<4:15:00, 42.86s/it]2022-01-08 15:27:40,764 iteration 732 : loss : 0.050691, loss_ce: 0.020668
2022-01-08 15:27:43,179 iteration 733 : loss : 0.061078, loss_ce: 0.025771
2022-01-08 15:27:45,658 iteration 734 : loss : 0.095415, loss_ce: 0.044529
2022-01-08 15:27:48,079 iteration 735 : loss : 0.059139, loss_ce: 0.022939
2022-01-08 15:27:50,474 iteration 736 : loss : 0.047135, loss_ce: 0.017611
2022-01-08 15:27:52,872 iteration 737 : loss : 0.056948, loss_ce: 0.021480
2022-01-08 15:27:55,324 iteration 738 : loss : 0.070809, loss_ce: 0.027846
2022-01-08 15:27:57,658 iteration 739 : loss : 0.081395, loss_ce: 0.041446
2022-01-08 15:28:00,033 iteration 740 : loss : 0.064661, loss_ce: 0.023665
2022-01-08 15:28:02,478 iteration 741 : loss : 0.060420, loss_ce: 0.023726
2022-01-08 15:28:04,826 iteration 742 : loss : 0.070067, loss_ce: 0.025631
2022-01-08 15:28:07,154 iteration 743 : loss : 0.068146, loss_ce: 0.022706
2022-01-08 15:28:09,434 iteration 744 : loss : 0.052388, loss_ce: 0.021819
2022-01-08 15:28:11,621 iteration 745 : loss : 0.069328, loss_ce: 0.025081
2022-01-08 15:28:13,802 iteration 746 : loss : 0.126426, loss_ce: 0.044492
2022-01-08 15:28:16,208 iteration 747 : loss : 0.083777, loss_ce: 0.037888
2022-01-08 15:28:18,580 iteration 748 : loss : 0.070141, loss_ce: 0.027325
 11%|███▎                          | 44/400 [28:25<4:09:41, 42.08s/it]2022-01-08 15:28:20,860 iteration 749 : loss : 0.084143, loss_ce: 0.029482
2022-01-08 15:28:23,102 iteration 750 : loss : 0.040141, loss_ce: 0.013026
2022-01-08 15:28:25,449 iteration 751 : loss : 0.079479, loss_ce: 0.032537
2022-01-08 15:28:27,746 iteration 752 : loss : 0.055729, loss_ce: 0.023168
2022-01-08 15:28:30,084 iteration 753 : loss : 0.051344, loss_ce: 0.019360
2022-01-08 15:28:32,345 iteration 754 : loss : 0.038392, loss_ce: 0.012824
2022-01-08 15:28:34,624 iteration 755 : loss : 0.053406, loss_ce: 0.022079
2022-01-08 15:28:36,927 iteration 756 : loss : 0.057723, loss_ce: 0.025385
2022-01-08 15:28:39,325 iteration 757 : loss : 0.057125, loss_ce: 0.022824
2022-01-08 15:28:41,735 iteration 758 : loss : 0.068649, loss_ce: 0.026940
2022-01-08 15:28:44,168 iteration 759 : loss : 0.079902, loss_ce: 0.030862
2022-01-08 15:28:46,539 iteration 760 : loss : 0.061947, loss_ce: 0.021882
2022-01-08 15:28:48,858 iteration 761 : loss : 0.078071, loss_ce: 0.031697
2022-01-08 15:28:51,112 iteration 762 : loss : 0.051443, loss_ce: 0.020832
2022-01-08 15:28:53,532 iteration 763 : loss : 0.044639, loss_ce: 0.019645
2022-01-08 15:28:55,907 iteration 764 : loss : 0.054191, loss_ce: 0.018625
2022-01-08 15:28:55,908 Training Data Eval:
2022-01-08 15:29:08,566   Average segmentation loss on training set: 0.0501
2022-01-08 15:29:08,566 Validation Data Eval:
2022-01-08 15:29:13,067   Average segmentation loss on validation set: 0.0789
2022-01-08 15:29:18,801 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 15:29:20,339 iteration 765 : loss : 0.069458, loss_ce: 0.028726
 11%|███▍                          | 45/400 [29:27<4:43:55, 47.99s/it]2022-01-08 15:29:22,027 iteration 766 : loss : 0.074273, loss_ce: 0.026648
2022-01-08 15:29:23,774 iteration 767 : loss : 0.078039, loss_ce: 0.033288
2022-01-08 15:29:25,526 iteration 768 : loss : 0.074899, loss_ce: 0.026373
2022-01-08 15:29:27,494 iteration 769 : loss : 0.079141, loss_ce: 0.036410
2022-01-08 15:29:29,677 iteration 770 : loss : 0.068517, loss_ce: 0.036607
2022-01-08 15:29:31,881 iteration 771 : loss : 0.048924, loss_ce: 0.024048
2022-01-08 15:29:33,974 iteration 772 : loss : 0.059151, loss_ce: 0.025227
2022-01-08 15:29:36,176 iteration 773 : loss : 0.128137, loss_ce: 0.045547
2022-01-08 15:29:38,475 iteration 774 : loss : 0.074336, loss_ce: 0.029680
2022-01-08 15:29:40,675 iteration 775 : loss : 0.047692, loss_ce: 0.019139
2022-01-08 15:29:42,882 iteration 776 : loss : 0.151239, loss_ce: 0.043247
2022-01-08 15:29:45,296 iteration 777 : loss : 0.060875, loss_ce: 0.028539
2022-01-08 15:29:47,564 iteration 778 : loss : 0.052726, loss_ce: 0.017650
2022-01-08 15:29:49,868 iteration 779 : loss : 0.082924, loss_ce: 0.026087
2022-01-08 15:29:52,321 iteration 780 : loss : 0.126050, loss_ce: 0.051721
2022-01-08 15:29:54,684 iteration 781 : loss : 0.050460, loss_ce: 0.017818
2022-01-08 15:29:56,974 iteration 782 : loss : 0.056520, loss_ce: 0.022657
 12%|███▍                          | 46/400 [30:03<4:23:02, 44.58s/it]2022-01-08 15:29:59,336 iteration 783 : loss : 0.060314, loss_ce: 0.025414
2022-01-08 15:30:01,624 iteration 784 : loss : 0.043531, loss_ce: 0.015585
2022-01-08 15:30:03,966 iteration 785 : loss : 0.077485, loss_ce: 0.022241
2022-01-08 15:30:06,228 iteration 786 : loss : 0.063319, loss_ce: 0.022434
2022-01-08 15:30:08,600 iteration 787 : loss : 0.075547, loss_ce: 0.030876
2022-01-08 15:30:10,985 iteration 788 : loss : 0.084393, loss_ce: 0.036842
2022-01-08 15:30:13,417 iteration 789 : loss : 0.073643, loss_ce: 0.025988
2022-01-08 15:30:15,871 iteration 790 : loss : 0.078255, loss_ce: 0.031459
2022-01-08 15:30:18,197 iteration 791 : loss : 0.085124, loss_ce: 0.044264
2022-01-08 15:30:20,649 iteration 792 : loss : 0.066566, loss_ce: 0.027098
2022-01-08 15:30:23,020 iteration 793 : loss : 0.085895, loss_ce: 0.031490
2022-01-08 15:30:25,394 iteration 794 : loss : 0.063132, loss_ce: 0.026160
2022-01-08 15:30:27,749 iteration 795 : loss : 0.069175, loss_ce: 0.026181
2022-01-08 15:30:30,234 iteration 796 : loss : 0.060663, loss_ce: 0.026245
2022-01-08 15:30:32,586 iteration 797 : loss : 0.050199, loss_ce: 0.022108
2022-01-08 15:30:34,862 iteration 798 : loss : 0.063826, loss_ce: 0.026827
2022-01-08 15:30:37,249 iteration 799 : loss : 0.099976, loss_ce: 0.033081
 12%|███▌                          | 47/400 [30:44<4:14:41, 43.29s/it]2022-01-08 15:30:39,583 iteration 800 : loss : 0.072430, loss_ce: 0.034042
2022-01-08 15:30:41,850 iteration 801 : loss : 0.071508, loss_ce: 0.018449
2022-01-08 15:30:44,251 iteration 802 : loss : 0.080787, loss_ce: 0.040122
2022-01-08 15:30:46,568 iteration 803 : loss : 0.044888, loss_ce: 0.016764
2022-01-08 15:30:48,956 iteration 804 : loss : 0.076703, loss_ce: 0.024296
2022-01-08 15:30:51,264 iteration 805 : loss : 0.062929, loss_ce: 0.027816
2022-01-08 15:30:53,521 iteration 806 : loss : 0.078005, loss_ce: 0.026862
2022-01-08 15:30:55,851 iteration 807 : loss : 0.059797, loss_ce: 0.032206
2022-01-08 15:30:58,224 iteration 808 : loss : 0.080241, loss_ce: 0.024786
2022-01-08 15:31:00,637 iteration 809 : loss : 0.063228, loss_ce: 0.028448
2022-01-08 15:31:02,914 iteration 810 : loss : 0.048237, loss_ce: 0.016401
2022-01-08 15:31:05,333 iteration 811 : loss : 0.117191, loss_ce: 0.052078
2022-01-08 15:31:07,628 iteration 812 : loss : 0.069012, loss_ce: 0.031298
2022-01-08 15:31:09,994 iteration 813 : loss : 0.062415, loss_ce: 0.026405
2022-01-08 15:31:12,443 iteration 814 : loss : 0.129624, loss_ce: 0.029132
2022-01-08 15:31:14,667 iteration 815 : loss : 0.045655, loss_ce: 0.022448
2022-01-08 15:31:17,121 iteration 816 : loss : 0.076827, loss_ce: 0.030834
 12%|███▌                          | 48/400 [31:23<4:07:58, 42.27s/it]2022-01-08 15:31:19,496 iteration 817 : loss : 0.058672, loss_ce: 0.022942
2022-01-08 15:31:21,738 iteration 818 : loss : 0.053034, loss_ce: 0.027644
2022-01-08 15:31:24,083 iteration 819 : loss : 0.075814, loss_ce: 0.031560
2022-01-08 15:31:26,363 iteration 820 : loss : 0.082914, loss_ce: 0.034005
2022-01-08 15:31:28,618 iteration 821 : loss : 0.074909, loss_ce: 0.030797
2022-01-08 15:31:30,840 iteration 822 : loss : 0.054786, loss_ce: 0.023015
2022-01-08 15:31:33,154 iteration 823 : loss : 0.062768, loss_ce: 0.028650
2022-01-08 15:31:35,453 iteration 824 : loss : 0.061408, loss_ce: 0.021610
2022-01-08 15:31:37,794 iteration 825 : loss : 0.097362, loss_ce: 0.029347
2022-01-08 15:31:40,078 iteration 826 : loss : 0.046461, loss_ce: 0.017257
2022-01-08 15:31:42,430 iteration 827 : loss : 0.064789, loss_ce: 0.021871
2022-01-08 15:31:44,703 iteration 828 : loss : 0.065659, loss_ce: 0.024022
2022-01-08 15:31:47,037 iteration 829 : loss : 0.076570, loss_ce: 0.035981
2022-01-08 15:31:49,246 iteration 830 : loss : 0.078821, loss_ce: 0.038663
2022-01-08 15:31:51,521 iteration 831 : loss : 0.089842, loss_ce: 0.040982
2022-01-08 15:31:53,800 iteration 832 : loss : 0.054555, loss_ce: 0.017275
2022-01-08 15:31:56,034 iteration 833 : loss : 0.076027, loss_ce: 0.034150
 12%|███▋                          | 49/400 [32:02<4:01:22, 41.26s/it]2022-01-08 15:31:58,207 iteration 834 : loss : 0.057843, loss_ce: 0.020390
2022-01-08 15:32:00,366 iteration 835 : loss : 0.040847, loss_ce: 0.014386
2022-01-08 15:32:02,706 iteration 836 : loss : 0.066401, loss_ce: 0.022780
2022-01-08 15:32:04,993 iteration 837 : loss : 0.041215, loss_ce: 0.016558
2022-01-08 15:32:07,333 iteration 838 : loss : 0.067413, loss_ce: 0.027588
2022-01-08 15:32:09,509 iteration 839 : loss : 0.048208, loss_ce: 0.018296
2022-01-08 15:32:11,741 iteration 840 : loss : 0.044278, loss_ce: 0.021001
2022-01-08 15:32:14,001 iteration 841 : loss : 0.062899, loss_ce: 0.021894
2022-01-08 15:32:16,431 iteration 842 : loss : 0.087663, loss_ce: 0.039393
2022-01-08 15:32:18,717 iteration 843 : loss : 0.053750, loss_ce: 0.018728
2022-01-08 15:32:21,073 iteration 844 : loss : 0.044546, loss_ce: 0.016672
2022-01-08 15:32:23,406 iteration 845 : loss : 0.064586, loss_ce: 0.031196
2022-01-08 15:32:25,773 iteration 846 : loss : 0.052828, loss_ce: 0.026164
2022-01-08 15:32:28,163 iteration 847 : loss : 0.069155, loss_ce: 0.025669
2022-01-08 15:32:30,455 iteration 848 : loss : 0.044083, loss_ce: 0.017662
2022-01-08 15:32:32,747 iteration 849 : loss : 0.062216, loss_ce: 0.022353
2022-01-08 15:32:32,747 Training Data Eval:
2022-01-08 15:32:45,262   Average segmentation loss on training set: 0.0460
2022-01-08 15:32:45,262 Validation Data Eval:
2022-01-08 15:32:49,613   Average segmentation loss on validation set: 0.0879
2022-01-08 15:32:51,937 iteration 850 : loss : 0.068741, loss_ce: 0.032703
 12%|███▊                          | 50/400 [32:58<4:26:18, 45.65s/it]2022-01-08 15:32:54,330 iteration 851 : loss : 0.053761, loss_ce: 0.022195
2022-01-08 15:32:56,865 iteration 852 : loss : 0.073645, loss_ce: 0.028751
2022-01-08 15:32:59,304 iteration 853 : loss : 0.058059, loss_ce: 0.019636
2022-01-08 15:33:01,713 iteration 854 : loss : 0.046724, loss_ce: 0.021297
2022-01-08 15:33:03,991 iteration 855 : loss : 0.052175, loss_ce: 0.024001
2022-01-08 15:33:06,377 iteration 856 : loss : 0.051003, loss_ce: 0.022700
2022-01-08 15:33:08,658 iteration 857 : loss : 0.071442, loss_ce: 0.028000
2022-01-08 15:33:10,999 iteration 858 : loss : 0.035126, loss_ce: 0.012953
2022-01-08 15:33:13,256 iteration 859 : loss : 0.044736, loss_ce: 0.014517
2022-01-08 15:33:15,666 iteration 860 : loss : 0.041606, loss_ce: 0.015149
2022-01-08 15:33:17,998 iteration 861 : loss : 0.046803, loss_ce: 0.013227
2022-01-08 15:33:20,308 iteration 862 : loss : 0.061889, loss_ce: 0.029463
2022-01-08 15:33:22,555 iteration 863 : loss : 0.063469, loss_ce: 0.020736
2022-01-08 15:33:24,764 iteration 864 : loss : 0.051217, loss_ce: 0.023400
2022-01-08 15:33:27,041 iteration 865 : loss : 0.058164, loss_ce: 0.028484
2022-01-08 15:33:29,314 iteration 866 : loss : 0.050589, loss_ce: 0.022906
2022-01-08 15:33:31,684 iteration 867 : loss : 0.070753, loss_ce: 0.030987
 13%|███▊                          | 51/400 [33:38<4:15:14, 43.88s/it]2022-01-08 15:33:34,064 iteration 868 : loss : 0.052255, loss_ce: 0.023052
2022-01-08 15:33:36,379 iteration 869 : loss : 0.050755, loss_ce: 0.021477
2022-01-08 15:33:38,633 iteration 870 : loss : 0.046415, loss_ce: 0.022323
2022-01-08 15:33:41,005 iteration 871 : loss : 0.043161, loss_ce: 0.017938
2022-01-08 15:33:43,398 iteration 872 : loss : 0.064320, loss_ce: 0.026247
2022-01-08 15:33:45,807 iteration 873 : loss : 0.055660, loss_ce: 0.023348
2022-01-08 15:33:48,159 iteration 874 : loss : 0.056330, loss_ce: 0.023887
2022-01-08 15:33:50,490 iteration 875 : loss : 0.083256, loss_ce: 0.031373
2022-01-08 15:33:52,915 iteration 876 : loss : 0.054076, loss_ce: 0.019663
2022-01-08 15:33:55,352 iteration 877 : loss : 0.053032, loss_ce: 0.019566
2022-01-08 15:33:57,670 iteration 878 : loss : 0.096935, loss_ce: 0.022073
2022-01-08 15:33:59,955 iteration 879 : loss : 0.097248, loss_ce: 0.027319
2022-01-08 15:34:02,283 iteration 880 : loss : 0.047237, loss_ce: 0.019352
2022-01-08 15:34:04,741 iteration 881 : loss : 0.096929, loss_ce: 0.028269
2022-01-08 15:34:07,114 iteration 882 : loss : 0.069800, loss_ce: 0.025014
2022-01-08 15:34:09,445 iteration 883 : loss : 0.044041, loss_ce: 0.012120
2022-01-08 15:34:11,852 iteration 884 : loss : 0.081896, loss_ce: 0.032873
 13%|███▉                          | 52/400 [34:18<4:08:01, 42.76s/it]2022-01-08 15:34:14,266 iteration 885 : loss : 0.063590, loss_ce: 0.027232
2022-01-08 15:34:16,658 iteration 886 : loss : 0.071338, loss_ce: 0.036258
2022-01-08 15:34:19,008 iteration 887 : loss : 0.064893, loss_ce: 0.027937
2022-01-08 15:34:21,464 iteration 888 : loss : 0.074560, loss_ce: 0.034689
2022-01-08 15:34:23,904 iteration 889 : loss : 0.128346, loss_ce: 0.031611
2022-01-08 15:34:26,269 iteration 890 : loss : 0.044944, loss_ce: 0.019963
2022-01-08 15:34:28,623 iteration 891 : loss : 0.045940, loss_ce: 0.027379
2022-01-08 15:34:30,958 iteration 892 : loss : 0.049599, loss_ce: 0.021053
2022-01-08 15:34:33,368 iteration 893 : loss : 0.051271, loss_ce: 0.025188
2022-01-08 15:34:35,793 iteration 894 : loss : 0.060027, loss_ce: 0.020795
2022-01-08 15:34:38,155 iteration 895 : loss : 0.085668, loss_ce: 0.030739
2022-01-08 15:34:40,552 iteration 896 : loss : 0.054391, loss_ce: 0.023271
2022-01-08 15:34:43,089 iteration 897 : loss : 0.091178, loss_ce: 0.037508
2022-01-08 15:34:45,411 iteration 898 : loss : 0.060203, loss_ce: 0.024148
2022-01-08 15:34:47,772 iteration 899 : loss : 0.068315, loss_ce: 0.025653
2022-01-08 15:34:50,069 iteration 900 : loss : 0.053833, loss_ce: 0.018295
2022-01-08 15:34:52,504 iteration 901 : loss : 0.063308, loss_ce: 0.024110
 13%|███▉                          | 53/400 [34:59<4:03:39, 42.13s/it]2022-01-08 15:34:54,994 iteration 902 : loss : 0.062205, loss_ce: 0.028387
2022-01-08 15:34:57,356 iteration 903 : loss : 0.070975, loss_ce: 0.022527
2022-01-08 15:34:59,798 iteration 904 : loss : 0.068953, loss_ce: 0.028432
2022-01-08 15:35:02,197 iteration 905 : loss : 0.061369, loss_ce: 0.024485
2022-01-08 15:35:04,662 iteration 906 : loss : 0.049143, loss_ce: 0.020995
2022-01-08 15:35:06,941 iteration 907 : loss : 0.052468, loss_ce: 0.020487
2022-01-08 15:35:09,274 iteration 908 : loss : 0.049479, loss_ce: 0.025026
2022-01-08 15:35:11,659 iteration 909 : loss : 0.067738, loss_ce: 0.027363
2022-01-08 15:35:14,011 iteration 910 : loss : 0.051992, loss_ce: 0.021475
2022-01-08 15:35:16,281 iteration 911 : loss : 0.044592, loss_ce: 0.017223
2022-01-08 15:35:18,619 iteration 912 : loss : 0.069236, loss_ce: 0.026455
2022-01-08 15:35:20,910 iteration 913 : loss : 0.064838, loss_ce: 0.022387
2022-01-08 15:35:23,194 iteration 914 : loss : 0.059716, loss_ce: 0.021166
2022-01-08 15:35:25,591 iteration 915 : loss : 0.072487, loss_ce: 0.024047
2022-01-08 15:35:27,991 iteration 916 : loss : 0.099524, loss_ce: 0.030281
2022-01-08 15:35:30,373 iteration 917 : loss : 0.054856, loss_ce: 0.019296
2022-01-08 15:35:32,805 iteration 918 : loss : 0.093965, loss_ce: 0.026207
 14%|████                          | 54/400 [35:39<3:59:49, 41.59s/it]2022-01-08 15:35:35,128 iteration 919 : loss : 0.052305, loss_ce: 0.017010
2022-01-08 15:35:37,545 iteration 920 : loss : 0.041048, loss_ce: 0.018551
2022-01-08 15:35:39,908 iteration 921 : loss : 0.052659, loss_ce: 0.022043
2022-01-08 15:35:42,521 iteration 922 : loss : 0.050150, loss_ce: 0.016400
2022-01-08 15:35:44,877 iteration 923 : loss : 0.041580, loss_ce: 0.014310
2022-01-08 15:35:47,254 iteration 924 : loss : 0.116208, loss_ce: 0.034135
2022-01-08 15:35:49,620 iteration 925 : loss : 0.079263, loss_ce: 0.025115
2022-01-08 15:35:51,963 iteration 926 : loss : 0.061321, loss_ce: 0.019734
2022-01-08 15:35:54,319 iteration 927 : loss : 0.076502, loss_ce: 0.020668
2022-01-08 15:35:56,738 iteration 928 : loss : 0.074606, loss_ce: 0.034664
2022-01-08 15:35:59,113 iteration 929 : loss : 0.056238, loss_ce: 0.024128
2022-01-08 15:36:01,474 iteration 930 : loss : 0.055752, loss_ce: 0.021591
2022-01-08 15:36:03,826 iteration 931 : loss : 0.119587, loss_ce: 0.068601
2022-01-08 15:36:06,280 iteration 932 : loss : 0.064378, loss_ce: 0.035265
2022-01-08 15:36:08,724 iteration 933 : loss : 0.061949, loss_ce: 0.030832
2022-01-08 15:36:11,071 iteration 934 : loss : 0.061584, loss_ce: 0.020529
2022-01-08 15:36:11,071 Training Data Eval:
2022-01-08 15:36:23,846   Average segmentation loss on training set: 0.0626
2022-01-08 15:36:23,846 Validation Data Eval:
2022-01-08 15:36:28,481   Average segmentation loss on validation set: 0.0841
2022-01-08 15:36:30,939 iteration 935 : loss : 0.067677, loss_ce: 0.034019
 14%|████▏                         | 55/400 [36:37<4:27:40, 46.55s/it]2022-01-08 15:36:33,371 iteration 936 : loss : 0.059784, loss_ce: 0.028011
2022-01-08 15:36:35,741 iteration 937 : loss : 0.095467, loss_ce: 0.039084
2022-01-08 15:36:38,107 iteration 938 : loss : 0.083865, loss_ce: 0.039111
2022-01-08 15:36:40,528 iteration 939 : loss : 0.107968, loss_ce: 0.037162
2022-01-08 15:36:42,828 iteration 940 : loss : 0.062664, loss_ce: 0.023493
2022-01-08 15:36:45,199 iteration 941 : loss : 0.074952, loss_ce: 0.029289
2022-01-08 15:36:47,692 iteration 942 : loss : 0.070880, loss_ce: 0.027260
2022-01-08 15:36:50,169 iteration 943 : loss : 0.119405, loss_ce: 0.038266
2022-01-08 15:36:52,644 iteration 944 : loss : 0.086973, loss_ce: 0.032220
2022-01-08 15:36:55,072 iteration 945 : loss : 0.060004, loss_ce: 0.026384
2022-01-08 15:36:57,521 iteration 946 : loss : 0.052676, loss_ce: 0.019836
2022-01-08 15:37:00,020 iteration 947 : loss : 0.055955, loss_ce: 0.019475
2022-01-08 15:37:02,477 iteration 948 : loss : 0.085545, loss_ce: 0.036144
2022-01-08 15:37:04,883 iteration 949 : loss : 0.102917, loss_ce: 0.045772
2022-01-08 15:37:07,355 iteration 950 : loss : 0.078560, loss_ce: 0.032720
2022-01-08 15:37:09,706 iteration 951 : loss : 0.065720, loss_ce: 0.028802
2022-01-08 15:37:12,151 iteration 952 : loss : 0.071287, loss_ce: 0.025950
 14%|████▏                         | 56/400 [37:19<4:17:42, 44.95s/it]2022-01-08 15:37:14,564 iteration 953 : loss : 0.067703, loss_ce: 0.026389
2022-01-08 15:37:16,952 iteration 954 : loss : 0.059922, loss_ce: 0.023572
2022-01-08 15:37:19,365 iteration 955 : loss : 0.080885, loss_ce: 0.029758
2022-01-08 15:37:21,707 iteration 956 : loss : 0.057659, loss_ce: 0.021054
2022-01-08 15:37:24,115 iteration 957 : loss : 0.106521, loss_ce: 0.040792
2022-01-08 15:37:26,637 iteration 958 : loss : 0.062656, loss_ce: 0.029219
2022-01-08 15:37:29,082 iteration 959 : loss : 0.072327, loss_ce: 0.034421
2022-01-08 15:37:31,475 iteration 960 : loss : 0.060337, loss_ce: 0.026980
2022-01-08 15:37:34,025 iteration 961 : loss : 0.099354, loss_ce: 0.038248
2022-01-08 15:37:36,457 iteration 962 : loss : 0.089762, loss_ce: 0.024953
2022-01-08 15:37:38,750 iteration 963 : loss : 0.050227, loss_ce: 0.025367
2022-01-08 15:37:41,072 iteration 964 : loss : 0.081787, loss_ce: 0.023904
2022-01-08 15:37:43,359 iteration 965 : loss : 0.055979, loss_ce: 0.017056
2022-01-08 15:37:45,879 iteration 966 : loss : 0.089507, loss_ce: 0.028008
2022-01-08 15:37:48,328 iteration 967 : loss : 0.086440, loss_ce: 0.040253
2022-01-08 15:37:50,801 iteration 968 : loss : 0.054658, loss_ce: 0.019913
2022-01-08 15:37:53,199 iteration 969 : loss : 0.074334, loss_ce: 0.034458
 14%|████▎                         | 57/400 [38:00<4:10:15, 43.78s/it]2022-01-08 15:37:55,565 iteration 970 : loss : 0.070386, loss_ce: 0.034731
2022-01-08 15:37:57,960 iteration 971 : loss : 0.069562, loss_ce: 0.036682
2022-01-08 15:38:00,343 iteration 972 : loss : 0.061958, loss_ce: 0.022566
2022-01-08 15:38:02,775 iteration 973 : loss : 0.050449, loss_ce: 0.019851
2022-01-08 15:38:05,157 iteration 974 : loss : 0.064407, loss_ce: 0.024384
2022-01-08 15:38:07,490 iteration 975 : loss : 0.053230, loss_ce: 0.018540
2022-01-08 15:38:09,912 iteration 976 : loss : 0.056091, loss_ce: 0.025390
2022-01-08 15:38:12,288 iteration 977 : loss : 0.045075, loss_ce: 0.018706
2022-01-08 15:38:14,736 iteration 978 : loss : 0.043339, loss_ce: 0.016203
2022-01-08 15:38:17,091 iteration 979 : loss : 0.053413, loss_ce: 0.019729
2022-01-08 15:38:19,415 iteration 980 : loss : 0.070872, loss_ce: 0.026850
2022-01-08 15:38:21,926 iteration 981 : loss : 0.030318, loss_ce: 0.010748
2022-01-08 15:38:24,354 iteration 982 : loss : 0.065879, loss_ce: 0.023281
2022-01-08 15:38:26,801 iteration 983 : loss : 0.062573, loss_ce: 0.025621
2022-01-08 15:38:29,188 iteration 984 : loss : 0.056039, loss_ce: 0.024361
2022-01-08 15:38:31,531 iteration 985 : loss : 0.057892, loss_ce: 0.024090
2022-01-08 15:38:33,911 iteration 986 : loss : 0.040785, loss_ce: 0.012757
 14%|████▎                         | 58/400 [38:40<4:04:16, 42.86s/it]2022-01-08 15:38:36,296 iteration 987 : loss : 0.051891, loss_ce: 0.017988
2022-01-08 15:38:38,712 iteration 988 : loss : 0.052672, loss_ce: 0.018039
2022-01-08 15:38:41,181 iteration 989 : loss : 0.035120, loss_ce: 0.013276
2022-01-08 15:38:43,642 iteration 990 : loss : 0.052085, loss_ce: 0.016958
2022-01-08 15:38:46,058 iteration 991 : loss : 0.046069, loss_ce: 0.016900
2022-01-08 15:38:48,412 iteration 992 : loss : 0.041540, loss_ce: 0.017606
2022-01-08 15:38:50,760 iteration 993 : loss : 0.044355, loss_ce: 0.015192
2022-01-08 15:38:53,054 iteration 994 : loss : 0.045324, loss_ce: 0.016544
2022-01-08 15:38:55,496 iteration 995 : loss : 0.059408, loss_ce: 0.026169
2022-01-08 15:38:57,901 iteration 996 : loss : 0.047366, loss_ce: 0.023092
2022-01-08 15:39:00,459 iteration 997 : loss : 0.055777, loss_ce: 0.021589
2022-01-08 15:39:02,881 iteration 998 : loss : 0.042261, loss_ce: 0.015014
2022-01-08 15:39:05,186 iteration 999 : loss : 0.056449, loss_ce: 0.023793
2022-01-08 15:39:07,548 iteration 1000 : loss : 0.053862, loss_ce: 0.028509
2022-01-08 15:39:09,824 iteration 1001 : loss : 0.040567, loss_ce: 0.015799
2022-01-08 15:39:12,224 iteration 1002 : loss : 0.049881, loss_ce: 0.021461
2022-01-08 15:39:14,547 iteration 1003 : loss : 0.078398, loss_ce: 0.024029
 15%|████▍                         | 59/400 [39:21<3:59:47, 42.19s/it]2022-01-08 15:39:16,951 iteration 1004 : loss : 0.054231, loss_ce: 0.018726
2022-01-08 15:39:19,326 iteration 1005 : loss : 0.058975, loss_ce: 0.027463
2022-01-08 15:39:21,790 iteration 1006 : loss : 0.050134, loss_ce: 0.023549
2022-01-08 15:39:24,260 iteration 1007 : loss : 0.060281, loss_ce: 0.025092
2022-01-08 15:39:26,710 iteration 1008 : loss : 0.054266, loss_ce: 0.027720
2022-01-08 15:39:29,102 iteration 1009 : loss : 0.046594, loss_ce: 0.017639
2022-01-08 15:39:31,420 iteration 1010 : loss : 0.036226, loss_ce: 0.011801
2022-01-08 15:39:33,832 iteration 1011 : loss : 0.064320, loss_ce: 0.024573
2022-01-08 15:39:36,283 iteration 1012 : loss : 0.052435, loss_ce: 0.021144
2022-01-08 15:39:38,743 iteration 1013 : loss : 0.036224, loss_ce: 0.013377
2022-01-08 15:39:41,205 iteration 1014 : loss : 0.031050, loss_ce: 0.011981
2022-01-08 15:39:43,713 iteration 1015 : loss : 0.067434, loss_ce: 0.023502
2022-01-08 15:39:46,050 iteration 1016 : loss : 0.046458, loss_ce: 0.018685
2022-01-08 15:39:48,432 iteration 1017 : loss : 0.064450, loss_ce: 0.026865
2022-01-08 15:39:50,863 iteration 1018 : loss : 0.079393, loss_ce: 0.026144
2022-01-08 15:39:53,286 iteration 1019 : loss : 0.047062, loss_ce: 0.016912
2022-01-08 15:39:53,287 Training Data Eval:
2022-01-08 15:40:06,124   Average segmentation loss on training set: 0.0428
2022-01-08 15:40:06,124 Validation Data Eval:
2022-01-08 15:40:10,769   Average segmentation loss on validation set: 0.1448
2022-01-08 15:40:13,233 iteration 1020 : loss : 0.075805, loss_ce: 0.033961
 15%|████▌                         | 60/400 [40:20<4:27:08, 47.14s/it]2022-01-08 15:40:15,615 iteration 1021 : loss : 0.047008, loss_ce: 0.017255
2022-01-08 15:40:18,014 iteration 1022 : loss : 0.055824, loss_ce: 0.025935
2022-01-08 15:40:20,275 iteration 1023 : loss : 0.042819, loss_ce: 0.014518
2022-01-08 15:40:22,634 iteration 1024 : loss : 0.038146, loss_ce: 0.014743
2022-01-08 15:40:24,996 iteration 1025 : loss : 0.042747, loss_ce: 0.017898
2022-01-08 15:40:27,361 iteration 1026 : loss : 0.067568, loss_ce: 0.013973
2022-01-08 15:40:29,888 iteration 1027 : loss : 0.047618, loss_ce: 0.014902
2022-01-08 15:40:32,359 iteration 1028 : loss : 0.071088, loss_ce: 0.021375
2022-01-08 15:40:34,813 iteration 1029 : loss : 0.065839, loss_ce: 0.020460
2022-01-08 15:40:37,246 iteration 1030 : loss : 0.052568, loss_ce: 0.021573
2022-01-08 15:40:39,712 iteration 1031 : loss : 0.068958, loss_ce: 0.035758
2022-01-08 15:40:42,121 iteration 1032 : loss : 0.053446, loss_ce: 0.021676
2022-01-08 15:40:44,415 iteration 1033 : loss : 0.065770, loss_ce: 0.031116
2022-01-08 15:40:46,826 iteration 1034 : loss : 0.039384, loss_ce: 0.014222
2022-01-08 15:40:49,265 iteration 1035 : loss : 0.052242, loss_ce: 0.022492
2022-01-08 15:40:51,638 iteration 1036 : loss : 0.067744, loss_ce: 0.028166
2022-01-08 15:40:53,877 iteration 1037 : loss : 0.048626, loss_ce: 0.023069
 15%|████▌                         | 61/400 [41:00<4:15:19, 45.19s/it]2022-01-08 15:40:56,284 iteration 1038 : loss : 0.050887, loss_ce: 0.022982
2022-01-08 15:40:58,617 iteration 1039 : loss : 0.048113, loss_ce: 0.021086
2022-01-08 15:41:00,997 iteration 1040 : loss : 0.059694, loss_ce: 0.018491
2022-01-08 15:41:03,446 iteration 1041 : loss : 0.050569, loss_ce: 0.022909
2022-01-08 15:41:05,808 iteration 1042 : loss : 0.046301, loss_ce: 0.025209
2022-01-08 15:41:08,151 iteration 1043 : loss : 0.051280, loss_ce: 0.018218
2022-01-08 15:41:10,597 iteration 1044 : loss : 0.066619, loss_ce: 0.032885
2022-01-08 15:41:13,008 iteration 1045 : loss : 0.073612, loss_ce: 0.030559
2022-01-08 15:41:15,405 iteration 1046 : loss : 0.044375, loss_ce: 0.022344
2022-01-08 15:41:17,752 iteration 1047 : loss : 0.047245, loss_ce: 0.020233
2022-01-08 15:41:20,146 iteration 1048 : loss : 0.041028, loss_ce: 0.019605
2022-01-08 15:41:22,497 iteration 1049 : loss : 0.059085, loss_ce: 0.024618
2022-01-08 15:41:24,845 iteration 1050 : loss : 0.146016, loss_ce: 0.030147
2022-01-08 15:41:27,340 iteration 1051 : loss : 0.056322, loss_ce: 0.024253
2022-01-08 15:41:29,779 iteration 1052 : loss : 0.070709, loss_ce: 0.022033
2022-01-08 15:41:32,147 iteration 1053 : loss : 0.083208, loss_ce: 0.021710
2022-01-08 15:41:34,518 iteration 1054 : loss : 0.059076, loss_ce: 0.019159
 16%|████▋                         | 62/400 [41:41<4:06:52, 43.83s/it]2022-01-08 15:41:36,925 iteration 1055 : loss : 0.036153, loss_ce: 0.011000
2022-01-08 15:41:39,229 iteration 1056 : loss : 0.037330, loss_ce: 0.015941
2022-01-08 15:41:41,639 iteration 1057 : loss : 0.075158, loss_ce: 0.024568
2022-01-08 15:41:44,083 iteration 1058 : loss : 0.083071, loss_ce: 0.029030
2022-01-08 15:41:46,490 iteration 1059 : loss : 0.058416, loss_ce: 0.023232
2022-01-08 15:41:48,837 iteration 1060 : loss : 0.047952, loss_ce: 0.014324
2022-01-08 15:41:51,282 iteration 1061 : loss : 0.076419, loss_ce: 0.038382
2022-01-08 15:41:53,604 iteration 1062 : loss : 0.061322, loss_ce: 0.018906
2022-01-08 15:41:56,015 iteration 1063 : loss : 0.070572, loss_ce: 0.031417
2022-01-08 15:41:58,384 iteration 1064 : loss : 0.070173, loss_ce: 0.020518
2022-01-08 15:42:00,797 iteration 1065 : loss : 0.057521, loss_ce: 0.029113
2022-01-08 15:42:03,120 iteration 1066 : loss : 0.042325, loss_ce: 0.017239
2022-01-08 15:42:05,426 iteration 1067 : loss : 0.054247, loss_ce: 0.020777
2022-01-08 15:42:07,875 iteration 1068 : loss : 0.049236, loss_ce: 0.019010
2022-01-08 15:42:10,246 iteration 1069 : loss : 0.056330, loss_ce: 0.023544
2022-01-08 15:42:12,676 iteration 1070 : loss : 0.090090, loss_ce: 0.022993
2022-01-08 15:42:15,033 iteration 1071 : loss : 0.055498, loss_ce: 0.028108
 16%|████▋                         | 63/400 [42:21<4:00:33, 42.83s/it]2022-01-08 15:42:17,440 iteration 1072 : loss : 0.048449, loss_ce: 0.014527
2022-01-08 15:42:19,726 iteration 1073 : loss : 0.075113, loss_ce: 0.030798
2022-01-08 15:42:22,073 iteration 1074 : loss : 0.054103, loss_ce: 0.020445
2022-01-08 15:42:24,414 iteration 1075 : loss : 0.092135, loss_ce: 0.028880
2022-01-08 15:42:26,686 iteration 1076 : loss : 0.046996, loss_ce: 0.017243
2022-01-08 15:42:29,129 iteration 1077 : loss : 0.058319, loss_ce: 0.017082
2022-01-08 15:42:31,444 iteration 1078 : loss : 0.066242, loss_ce: 0.027804
2022-01-08 15:42:33,858 iteration 1079 : loss : 0.064447, loss_ce: 0.028485
2022-01-08 15:42:36,216 iteration 1080 : loss : 0.028410, loss_ce: 0.009225
2022-01-08 15:42:38,590 iteration 1081 : loss : 0.055818, loss_ce: 0.029155
2022-01-08 15:42:40,939 iteration 1082 : loss : 0.078294, loss_ce: 0.045233
2022-01-08 15:42:43,194 iteration 1083 : loss : 0.048154, loss_ce: 0.019262
2022-01-08 15:42:45,504 iteration 1084 : loss : 0.051719, loss_ce: 0.015649
2022-01-08 15:42:47,873 iteration 1085 : loss : 0.049168, loss_ce: 0.020881
2022-01-08 15:42:50,172 iteration 1086 : loss : 0.054871, loss_ce: 0.024413
2022-01-08 15:42:52,625 iteration 1087 : loss : 0.042862, loss_ce: 0.018545
2022-01-08 15:42:55,020 iteration 1088 : loss : 0.040906, loss_ce: 0.017772
 16%|████▊                         | 64/400 [43:01<3:55:03, 41.97s/it]2022-01-08 15:42:57,416 iteration 1089 : loss : 0.086348, loss_ce: 0.034508
2022-01-08 15:42:59,738 iteration 1090 : loss : 0.062015, loss_ce: 0.020151
2022-01-08 15:43:02,100 iteration 1091 : loss : 0.042012, loss_ce: 0.021520
2022-01-08 15:43:04,433 iteration 1092 : loss : 0.048629, loss_ce: 0.021740
2022-01-08 15:43:06,756 iteration 1093 : loss : 0.037419, loss_ce: 0.015337
2022-01-08 15:43:09,140 iteration 1094 : loss : 0.045017, loss_ce: 0.020377
2022-01-08 15:43:11,539 iteration 1095 : loss : 0.095504, loss_ce: 0.037450
2022-01-08 15:43:13,950 iteration 1096 : loss : 0.040172, loss_ce: 0.017159
2022-01-08 15:43:16,325 iteration 1097 : loss : 0.067299, loss_ce: 0.019466
2022-01-08 15:43:18,682 iteration 1098 : loss : 0.041855, loss_ce: 0.020266
2022-01-08 15:43:21,059 iteration 1099 : loss : 0.042287, loss_ce: 0.016902
2022-01-08 15:43:23,329 iteration 1100 : loss : 0.064334, loss_ce: 0.032410
2022-01-08 15:43:25,683 iteration 1101 : loss : 0.049881, loss_ce: 0.017947
2022-01-08 15:43:28,067 iteration 1102 : loss : 0.064443, loss_ce: 0.017576
2022-01-08 15:43:30,403 iteration 1103 : loss : 0.059274, loss_ce: 0.022578
2022-01-08 15:43:32,677 iteration 1104 : loss : 0.054968, loss_ce: 0.023082
2022-01-08 15:43:32,677 Training Data Eval:
2022-01-08 15:43:45,186   Average segmentation loss on training set: 0.0350
2022-01-08 15:43:45,187 Validation Data Eval:
2022-01-08 15:43:49,525   Average segmentation loss on validation set: 0.0788
2022-01-08 15:43:55,260 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 15:43:56,887 iteration 1105 : loss : 0.060827, loss_ce: 0.031567
 16%|████▉                         | 65/400 [44:03<4:27:42, 47.95s/it]2022-01-08 15:43:58,520 iteration 1106 : loss : 0.047674, loss_ce: 0.014749
2022-01-08 15:44:00,206 iteration 1107 : loss : 0.054819, loss_ce: 0.025769
2022-01-08 15:44:01,872 iteration 1108 : loss : 0.034082, loss_ce: 0.012388
2022-01-08 15:44:03,677 iteration 1109 : loss : 0.070957, loss_ce: 0.030696
2022-01-08 15:44:05,673 iteration 1110 : loss : 0.046071, loss_ce: 0.019095
2022-01-08 15:44:07,784 iteration 1111 : loss : 0.043300, loss_ce: 0.019588
2022-01-08 15:44:09,919 iteration 1112 : loss : 0.051620, loss_ce: 0.023772
2022-01-08 15:44:12,056 iteration 1113 : loss : 0.046904, loss_ce: 0.017815
2022-01-08 15:44:14,272 iteration 1114 : loss : 0.056780, loss_ce: 0.020128
2022-01-08 15:44:16,526 iteration 1115 : loss : 0.044903, loss_ce: 0.015567
2022-01-08 15:44:18,857 iteration 1116 : loss : 0.085522, loss_ce: 0.038435
2022-01-08 15:44:21,153 iteration 1117 : loss : 0.052500, loss_ce: 0.019044
2022-01-08 15:44:23,335 iteration 1118 : loss : 0.035092, loss_ce: 0.014528
2022-01-08 15:44:25,599 iteration 1119 : loss : 0.035111, loss_ce: 0.012989
2022-01-08 15:44:27,888 iteration 1120 : loss : 0.051681, loss_ce: 0.016384
2022-01-08 15:44:30,168 iteration 1121 : loss : 0.038901, loss_ce: 0.011078
2022-01-08 15:44:32,531 iteration 1122 : loss : 0.043442, loss_ce: 0.016611
 16%|████▉                         | 66/400 [44:39<4:06:21, 44.25s/it]2022-01-08 15:44:34,914 iteration 1123 : loss : 0.046746, loss_ce: 0.019749
2022-01-08 15:44:37,168 iteration 1124 : loss : 0.037867, loss_ce: 0.016145
2022-01-08 15:44:39,469 iteration 1125 : loss : 0.051755, loss_ce: 0.021722
2022-01-08 15:44:41,891 iteration 1126 : loss : 0.054033, loss_ce: 0.021493
2022-01-08 15:44:44,220 iteration 1127 : loss : 0.065501, loss_ce: 0.026762
2022-01-08 15:44:46,497 iteration 1128 : loss : 0.044478, loss_ce: 0.013077
2022-01-08 15:44:48,735 iteration 1129 : loss : 0.055994, loss_ce: 0.024664
2022-01-08 15:44:51,091 iteration 1130 : loss : 0.048782, loss_ce: 0.025136
2022-01-08 15:44:53,545 iteration 1131 : loss : 0.095759, loss_ce: 0.029839
2022-01-08 15:44:55,885 iteration 1132 : loss : 0.063483, loss_ce: 0.023362
2022-01-08 15:44:58,212 iteration 1133 : loss : 0.059707, loss_ce: 0.025545
2022-01-08 15:45:00,547 iteration 1134 : loss : 0.069688, loss_ce: 0.028405
2022-01-08 15:45:02,886 iteration 1135 : loss : 0.036668, loss_ce: 0.011723
2022-01-08 15:45:05,238 iteration 1136 : loss : 0.065961, loss_ce: 0.028080
2022-01-08 15:45:07,513 iteration 1137 : loss : 0.045955, loss_ce: 0.016137
2022-01-08 15:45:09,826 iteration 1138 : loss : 0.079549, loss_ce: 0.038766
2022-01-08 15:45:12,217 iteration 1139 : loss : 0.042815, loss_ce: 0.017848
 17%|█████                         | 67/400 [45:19<3:58:00, 42.88s/it]2022-01-08 15:45:14,601 iteration 1140 : loss : 0.044915, loss_ce: 0.017721
2022-01-08 15:45:16,940 iteration 1141 : loss : 0.050006, loss_ce: 0.020460
2022-01-08 15:45:19,259 iteration 1142 : loss : 0.035319, loss_ce: 0.013763
2022-01-08 15:45:21,668 iteration 1143 : loss : 0.087318, loss_ce: 0.031670
2022-01-08 15:45:24,022 iteration 1144 : loss : 0.037094, loss_ce: 0.014792
2022-01-08 15:45:26,329 iteration 1145 : loss : 0.043394, loss_ce: 0.014449
2022-01-08 15:45:28,751 iteration 1146 : loss : 0.067406, loss_ce: 0.028518
2022-01-08 15:45:31,083 iteration 1147 : loss : 0.035976, loss_ce: 0.012419
2022-01-08 15:45:33,386 iteration 1148 : loss : 0.042983, loss_ce: 0.015398
2022-01-08 15:45:35,696 iteration 1149 : loss : 0.044767, loss_ce: 0.022569
2022-01-08 15:45:38,011 iteration 1150 : loss : 0.046165, loss_ce: 0.019689
2022-01-08 15:45:40,411 iteration 1151 : loss : 0.041638, loss_ce: 0.012955
2022-01-08 15:45:42,787 iteration 1152 : loss : 0.111406, loss_ce: 0.019808
2022-01-08 15:45:45,087 iteration 1153 : loss : 0.046758, loss_ce: 0.016016
2022-01-08 15:45:47,409 iteration 1154 : loss : 0.044281, loss_ce: 0.019608
2022-01-08 15:45:49,806 iteration 1155 : loss : 0.051661, loss_ce: 0.017420
2022-01-08 15:45:52,158 iteration 1156 : loss : 0.085904, loss_ce: 0.025816
 17%|█████                         | 68/400 [45:59<3:52:23, 42.00s/it]2022-01-08 15:45:54,515 iteration 1157 : loss : 0.049899, loss_ce: 0.021420
2022-01-08 15:45:56,988 iteration 1158 : loss : 0.059265, loss_ce: 0.019013
2022-01-08 15:45:59,312 iteration 1159 : loss : 0.065826, loss_ce: 0.024853
2022-01-08 15:46:01,506 iteration 1160 : loss : 0.044614, loss_ce: 0.020533
2022-01-08 15:46:03,934 iteration 1161 : loss : 0.045377, loss_ce: 0.017140
2022-01-08 15:46:06,359 iteration 1162 : loss : 0.051530, loss_ce: 0.013053
2022-01-08 15:46:08,814 iteration 1163 : loss : 0.086638, loss_ce: 0.026162
2022-01-08 15:46:11,159 iteration 1164 : loss : 0.047767, loss_ce: 0.019378
2022-01-08 15:46:13,396 iteration 1165 : loss : 0.045308, loss_ce: 0.023388
2022-01-08 15:46:15,722 iteration 1166 : loss : 0.042634, loss_ce: 0.019240
2022-01-08 15:46:18,061 iteration 1167 : loss : 0.057347, loss_ce: 0.025699
2022-01-08 15:46:20,412 iteration 1168 : loss : 0.042842, loss_ce: 0.016708
2022-01-08 15:46:22,802 iteration 1169 : loss : 0.068317, loss_ce: 0.022872
2022-01-08 15:46:25,174 iteration 1170 : loss : 0.043768, loss_ce: 0.016072
2022-01-08 15:46:27,491 iteration 1171 : loss : 0.041173, loss_ce: 0.016127
2022-01-08 15:46:29,834 iteration 1172 : loss : 0.043377, loss_ce: 0.018275
2022-01-08 15:46:32,133 iteration 1173 : loss : 0.057302, loss_ce: 0.032456
 17%|█████▏                        | 69/400 [46:39<3:48:21, 41.39s/it]2022-01-08 15:46:34,547 iteration 1174 : loss : 0.046056, loss_ce: 0.015640
2022-01-08 15:46:36,887 iteration 1175 : loss : 0.038040, loss_ce: 0.016670
2022-01-08 15:46:39,431 iteration 1176 : loss : 0.068555, loss_ce: 0.032326
2022-01-08 15:46:41,920 iteration 1177 : loss : 0.072868, loss_ce: 0.029294
2022-01-08 15:46:44,257 iteration 1178 : loss : 0.051714, loss_ce: 0.022976
2022-01-08 15:46:46,544 iteration 1179 : loss : 0.046300, loss_ce: 0.019948
2022-01-08 15:46:48,978 iteration 1180 : loss : 0.053632, loss_ce: 0.022002
2022-01-08 15:46:51,337 iteration 1181 : loss : 0.041252, loss_ce: 0.017148
2022-01-08 15:46:53,774 iteration 1182 : loss : 0.055901, loss_ce: 0.022663
2022-01-08 15:46:56,091 iteration 1183 : loss : 0.045463, loss_ce: 0.021286
2022-01-08 15:46:58,377 iteration 1184 : loss : 0.039141, loss_ce: 0.015652
2022-01-08 15:47:00,798 iteration 1185 : loss : 0.090687, loss_ce: 0.031289
2022-01-08 15:47:03,239 iteration 1186 : loss : 0.059682, loss_ce: 0.023967
2022-01-08 15:47:05,653 iteration 1187 : loss : 0.051970, loss_ce: 0.022970
2022-01-08 15:47:07,945 iteration 1188 : loss : 0.033764, loss_ce: 0.012197
2022-01-08 15:47:10,344 iteration 1189 : loss : 0.042145, loss_ce: 0.015898
2022-01-08 15:47:10,345 Training Data Eval:
2022-01-08 15:47:23,324   Average segmentation loss on training set: 0.0632
2022-01-08 15:47:23,324 Validation Data Eval:
2022-01-08 15:47:27,818   Average segmentation loss on validation set: 0.2054
2022-01-08 15:47:30,226 iteration 1190 : loss : 0.055330, loss_ce: 0.021374
 18%|█████▎                        | 70/400 [47:37<4:15:12, 46.40s/it]2022-01-08 15:47:32,582 iteration 1191 : loss : 0.046955, loss_ce: 0.019379
2022-01-08 15:47:34,967 iteration 1192 : loss : 0.039569, loss_ce: 0.016487
2022-01-08 15:47:37,353 iteration 1193 : loss : 0.071015, loss_ce: 0.027562
2022-01-08 15:47:39,698 iteration 1194 : loss : 0.058760, loss_ce: 0.020410
2022-01-08 15:47:42,090 iteration 1195 : loss : 0.055768, loss_ce: 0.017500
2022-01-08 15:47:44,546 iteration 1196 : loss : 0.047554, loss_ce: 0.016046
2022-01-08 15:47:46,964 iteration 1197 : loss : 0.047994, loss_ce: 0.023596
2022-01-08 15:47:49,327 iteration 1198 : loss : 0.047807, loss_ce: 0.025057
2022-01-08 15:47:51,705 iteration 1199 : loss : 0.069808, loss_ce: 0.027103
2022-01-08 15:47:54,117 iteration 1200 : loss : 0.069200, loss_ce: 0.022775
2022-01-08 15:47:56,529 iteration 1201 : loss : 0.033054, loss_ce: 0.014454
2022-01-08 15:47:58,893 iteration 1202 : loss : 0.036656, loss_ce: 0.016820
2022-01-08 15:48:01,315 iteration 1203 : loss : 0.047711, loss_ce: 0.017503
2022-01-08 15:48:03,691 iteration 1204 : loss : 0.048886, loss_ce: 0.023060
2022-01-08 15:48:06,074 iteration 1205 : loss : 0.055653, loss_ce: 0.027819
2022-01-08 15:48:08,520 iteration 1206 : loss : 0.085659, loss_ce: 0.026555
2022-01-08 15:48:10,936 iteration 1207 : loss : 0.054612, loss_ce: 0.018872
 18%|█████▎                        | 71/400 [48:17<4:05:04, 44.70s/it]2022-01-08 15:48:13,337 iteration 1208 : loss : 0.037561, loss_ce: 0.016182
2022-01-08 15:48:15,728 iteration 1209 : loss : 0.063884, loss_ce: 0.019057
2022-01-08 15:48:18,092 iteration 1210 : loss : 0.038641, loss_ce: 0.011023
2022-01-08 15:48:20,516 iteration 1211 : loss : 0.063229, loss_ce: 0.019467
2022-01-08 15:48:22,937 iteration 1212 : loss : 0.034765, loss_ce: 0.015207
2022-01-08 15:48:25,327 iteration 1213 : loss : 0.064834, loss_ce: 0.024520
2022-01-08 15:48:27,750 iteration 1214 : loss : 0.046944, loss_ce: 0.019679
2022-01-08 15:48:30,123 iteration 1215 : loss : 0.045407, loss_ce: 0.018636
2022-01-08 15:48:32,493 iteration 1216 : loss : 0.039769, loss_ce: 0.014952
2022-01-08 15:48:35,098 iteration 1217 : loss : 0.046791, loss_ce: 0.019320
2022-01-08 15:48:37,419 iteration 1218 : loss : 0.036234, loss_ce: 0.016630
2022-01-08 15:48:39,812 iteration 1219 : loss : 0.056356, loss_ce: 0.022829
2022-01-08 15:48:42,135 iteration 1220 : loss : 0.055402, loss_ce: 0.018584
2022-01-08 15:48:44,640 iteration 1221 : loss : 0.055575, loss_ce: 0.022476
2022-01-08 15:48:47,039 iteration 1222 : loss : 0.052989, loss_ce: 0.018024
2022-01-08 15:48:49,413 iteration 1223 : loss : 0.033264, loss_ce: 0.013869
2022-01-08 15:48:51,877 iteration 1224 : loss : 0.045623, loss_ce: 0.019368
 18%|█████▍                        | 72/400 [48:58<3:58:09, 43.57s/it]2022-01-08 15:48:54,288 iteration 1225 : loss : 0.042802, loss_ce: 0.015471
2022-01-08 15:48:56,623 iteration 1226 : loss : 0.051461, loss_ce: 0.022139
2022-01-08 15:48:59,031 iteration 1227 : loss : 0.040372, loss_ce: 0.012508
2022-01-08 15:49:01,524 iteration 1228 : loss : 0.077146, loss_ce: 0.021738
2022-01-08 15:49:03,895 iteration 1229 : loss : 0.048747, loss_ce: 0.020674
2022-01-08 15:49:06,245 iteration 1230 : loss : 0.047208, loss_ce: 0.023076
2022-01-08 15:49:08,555 iteration 1231 : loss : 0.050371, loss_ce: 0.019868
2022-01-08 15:49:11,005 iteration 1232 : loss : 0.047801, loss_ce: 0.019142
2022-01-08 15:49:13,516 iteration 1233 : loss : 0.059510, loss_ce: 0.026086
2022-01-08 15:49:15,839 iteration 1234 : loss : 0.044625, loss_ce: 0.017677
2022-01-08 15:49:18,210 iteration 1235 : loss : 0.047120, loss_ce: 0.019269
2022-01-08 15:49:20,567 iteration 1236 : loss : 0.041358, loss_ce: 0.016970
2022-01-08 15:49:22,960 iteration 1237 : loss : 0.045073, loss_ce: 0.018403
2022-01-08 15:49:25,338 iteration 1238 : loss : 0.038162, loss_ce: 0.015181
2022-01-08 15:49:27,694 iteration 1239 : loss : 0.041909, loss_ce: 0.014481
2022-01-08 15:49:30,032 iteration 1240 : loss : 0.033771, loss_ce: 0.012181
2022-01-08 15:49:32,503 iteration 1241 : loss : 0.031692, loss_ce: 0.013788
 18%|█████▍                        | 73/400 [49:39<3:52:40, 42.69s/it]2022-01-08 15:49:34,850 iteration 1242 : loss : 0.056604, loss_ce: 0.023113
2022-01-08 15:49:37,245 iteration 1243 : loss : 0.032694, loss_ce: 0.016351
2022-01-08 15:49:39,649 iteration 1244 : loss : 0.049609, loss_ce: 0.017842
2022-01-08 15:49:42,053 iteration 1245 : loss : 0.045704, loss_ce: 0.018922
2022-01-08 15:49:44,450 iteration 1246 : loss : 0.059713, loss_ce: 0.028098
2022-01-08 15:49:46,868 iteration 1247 : loss : 0.042893, loss_ce: 0.015767
2022-01-08 15:49:49,279 iteration 1248 : loss : 0.041475, loss_ce: 0.014850
2022-01-08 15:49:51,717 iteration 1249 : loss : 0.049372, loss_ce: 0.017561
2022-01-08 15:49:54,267 iteration 1250 : loss : 0.038209, loss_ce: 0.014182
2022-01-08 15:49:56,713 iteration 1251 : loss : 0.037668, loss_ce: 0.015881
2022-01-08 15:49:59,101 iteration 1252 : loss : 0.095376, loss_ce: 0.023837
2022-01-08 15:50:01,467 iteration 1253 : loss : 0.033353, loss_ce: 0.014164
2022-01-08 15:50:03,838 iteration 1254 : loss : 0.059784, loss_ce: 0.026071
2022-01-08 15:50:06,400 iteration 1255 : loss : 0.044650, loss_ce: 0.016133
2022-01-08 15:50:08,822 iteration 1256 : loss : 0.052865, loss_ce: 0.017657
2022-01-08 15:50:11,101 iteration 1257 : loss : 0.041478, loss_ce: 0.019124
2022-01-08 15:50:13,485 iteration 1258 : loss : 0.043611, loss_ce: 0.019380
 18%|█████▌                        | 74/400 [50:20<3:49:09, 42.18s/it]2022-01-08 15:50:15,790 iteration 1259 : loss : 0.041456, loss_ce: 0.015263
2022-01-08 15:50:18,139 iteration 1260 : loss : 0.044175, loss_ce: 0.015128
2022-01-08 15:50:20,512 iteration 1261 : loss : 0.049891, loss_ce: 0.019757
2022-01-08 15:50:22,812 iteration 1262 : loss : 0.035031, loss_ce: 0.016655
2022-01-08 15:50:25,293 iteration 1263 : loss : 0.034755, loss_ce: 0.011545
2022-01-08 15:50:27,613 iteration 1264 : loss : 0.037188, loss_ce: 0.017506
2022-01-08 15:50:30,036 iteration 1265 : loss : 0.037247, loss_ce: 0.014525
2022-01-08 15:50:32,387 iteration 1266 : loss : 0.041153, loss_ce: 0.018183
2022-01-08 15:50:35,074 iteration 1267 : loss : 0.044459, loss_ce: 0.015876
2022-01-08 15:50:37,481 iteration 1268 : loss : 0.113731, loss_ce: 0.031880
2022-01-08 15:50:39,887 iteration 1269 : loss : 0.064937, loss_ce: 0.024796
2022-01-08 15:50:42,222 iteration 1270 : loss : 0.042686, loss_ce: 0.014495
2022-01-08 15:50:44,643 iteration 1271 : loss : 0.031383, loss_ce: 0.012194
2022-01-08 15:50:46,983 iteration 1272 : loss : 0.051772, loss_ce: 0.024440
2022-01-08 15:50:49,418 iteration 1273 : loss : 0.046974, loss_ce: 0.022121
2022-01-08 15:50:51,861 iteration 1274 : loss : 0.043333, loss_ce: 0.015429
2022-01-08 15:50:51,861 Training Data Eval:
2022-01-08 15:51:04,823   Average segmentation loss on training set: 0.0345
2022-01-08 15:51:04,823 Validation Data Eval:
2022-01-08 15:51:09,322   Average segmentation loss on validation set: 0.1116
2022-01-08 15:51:11,734 iteration 1275 : loss : 0.045078, loss_ce: 0.014722
 19%|█████▋                        | 75/400 [51:18<4:14:33, 47.00s/it]2022-01-08 15:51:14,168 iteration 1276 : loss : 0.078614, loss_ce: 0.022677
2022-01-08 15:51:16,406 iteration 1277 : loss : 0.040036, loss_ce: 0.015792
2022-01-08 15:51:18,937 iteration 1278 : loss : 0.036064, loss_ce: 0.015557
2022-01-08 15:51:21,259 iteration 1279 : loss : 0.037476, loss_ce: 0.018413
2022-01-08 15:51:23,539 iteration 1280 : loss : 0.050549, loss_ce: 0.026706
2022-01-08 15:51:25,897 iteration 1281 : loss : 0.039657, loss_ce: 0.016401
2022-01-08 15:51:28,135 iteration 1282 : loss : 0.061193, loss_ce: 0.033800
2022-01-08 15:51:30,447 iteration 1283 : loss : 0.045787, loss_ce: 0.020429
2022-01-08 15:51:32,916 iteration 1284 : loss : 0.037803, loss_ce: 0.017488
2022-01-08 15:51:35,454 iteration 1285 : loss : 0.059408, loss_ce: 0.021164
2022-01-08 15:51:37,802 iteration 1286 : loss : 0.039699, loss_ce: 0.014288
2022-01-08 15:51:40,093 iteration 1287 : loss : 0.056147, loss_ce: 0.019976
2022-01-08 15:51:42,495 iteration 1288 : loss : 0.052792, loss_ce: 0.018267
2022-01-08 15:51:44,928 iteration 1289 : loss : 0.040049, loss_ce: 0.015634
2022-01-08 15:51:47,268 iteration 1290 : loss : 0.053540, loss_ce: 0.018323
2022-01-08 15:51:49,674 iteration 1291 : loss : 0.032306, loss_ce: 0.012782
2022-01-08 15:51:52,096 iteration 1292 : loss : 0.030927, loss_ce: 0.012494
 19%|█████▋                        | 76/400 [51:58<4:03:02, 45.01s/it]2022-01-08 15:51:54,535 iteration 1293 : loss : 0.064900, loss_ce: 0.026656
2022-01-08 15:51:56,886 iteration 1294 : loss : 0.048572, loss_ce: 0.019131
2022-01-08 15:51:59,286 iteration 1295 : loss : 0.045331, loss_ce: 0.019006
2022-01-08 15:52:01,663 iteration 1296 : loss : 0.042763, loss_ce: 0.015774
2022-01-08 15:52:03,976 iteration 1297 : loss : 0.046132, loss_ce: 0.016315
2022-01-08 15:52:06,478 iteration 1298 : loss : 0.061263, loss_ce: 0.031202
2022-01-08 15:52:08,858 iteration 1299 : loss : 0.050052, loss_ce: 0.017148
2022-01-08 15:52:11,270 iteration 1300 : loss : 0.061171, loss_ce: 0.015672
2022-01-08 15:52:13,564 iteration 1301 : loss : 0.043957, loss_ce: 0.019763
2022-01-08 15:52:16,020 iteration 1302 : loss : 0.052321, loss_ce: 0.017175
2022-01-08 15:52:18,446 iteration 1303 : loss : 0.041535, loss_ce: 0.017900
2022-01-08 15:52:20,880 iteration 1304 : loss : 0.077256, loss_ce: 0.021010
2022-01-08 15:52:23,229 iteration 1305 : loss : 0.050099, loss_ce: 0.022028
2022-01-08 15:52:25,701 iteration 1306 : loss : 0.065660, loss_ce: 0.021688
2022-01-08 15:52:28,134 iteration 1307 : loss : 0.056037, loss_ce: 0.021610
2022-01-08 15:52:30,533 iteration 1308 : loss : 0.052677, loss_ce: 0.031033
2022-01-08 15:52:32,932 iteration 1309 : loss : 0.055873, loss_ce: 0.023187
 19%|█████▊                        | 77/400 [52:39<3:55:33, 43.76s/it]2022-01-08 15:52:35,405 iteration 1310 : loss : 0.058551, loss_ce: 0.022935
2022-01-08 15:52:37,830 iteration 1311 : loss : 0.039191, loss_ce: 0.013023
2022-01-08 15:52:40,118 iteration 1312 : loss : 0.056536, loss_ce: 0.028342
2022-01-08 15:52:42,354 iteration 1313 : loss : 0.035406, loss_ce: 0.015059
2022-01-08 15:52:44,710 iteration 1314 : loss : 0.037208, loss_ce: 0.015829
2022-01-08 15:52:47,034 iteration 1315 : loss : 0.047959, loss_ce: 0.021380
2022-01-08 15:52:49,297 iteration 1316 : loss : 0.038093, loss_ce: 0.017428
2022-01-08 15:52:51,687 iteration 1317 : loss : 0.042157, loss_ce: 0.019169
2022-01-08 15:52:54,121 iteration 1318 : loss : 0.050749, loss_ce: 0.022582
2022-01-08 15:52:56,458 iteration 1319 : loss : 0.045195, loss_ce: 0.014609
2022-01-08 15:52:58,835 iteration 1320 : loss : 0.042531, loss_ce: 0.015327
2022-01-08 15:53:01,212 iteration 1321 : loss : 0.054873, loss_ce: 0.021268
2022-01-08 15:53:03,666 iteration 1322 : loss : 0.046650, loss_ce: 0.017343
2022-01-08 15:53:05,986 iteration 1323 : loss : 0.039864, loss_ce: 0.015846
2022-01-08 15:53:08,325 iteration 1324 : loss : 0.035504, loss_ce: 0.011881
2022-01-08 15:53:10,634 iteration 1325 : loss : 0.049354, loss_ce: 0.017931
2022-01-08 15:53:12,930 iteration 1326 : loss : 0.040829, loss_ce: 0.014066
 20%|█████▊                        | 78/400 [53:19<3:48:47, 42.63s/it]2022-01-08 15:53:15,359 iteration 1327 : loss : 0.051632, loss_ce: 0.026109
2022-01-08 15:53:17,753 iteration 1328 : loss : 0.057160, loss_ce: 0.018786
2022-01-08 15:53:20,003 iteration 1329 : loss : 0.042355, loss_ce: 0.019202
2022-01-08 15:53:22,357 iteration 1330 : loss : 0.044049, loss_ce: 0.016806
2022-01-08 15:53:24,647 iteration 1331 : loss : 0.030853, loss_ce: 0.009960
2022-01-08 15:53:26,972 iteration 1332 : loss : 0.029967, loss_ce: 0.012279
2022-01-08 15:53:29,388 iteration 1333 : loss : 0.065981, loss_ce: 0.013347
2022-01-08 15:53:31,734 iteration 1334 : loss : 0.034981, loss_ce: 0.014822
2022-01-08 15:53:34,198 iteration 1335 : loss : 0.041592, loss_ce: 0.013607
2022-01-08 15:53:36,516 iteration 1336 : loss : 0.039072, loss_ce: 0.016047
2022-01-08 15:53:38,881 iteration 1337 : loss : 0.039762, loss_ce: 0.017562
2022-01-08 15:53:41,189 iteration 1338 : loss : 0.051698, loss_ce: 0.020357
2022-01-08 15:53:43,498 iteration 1339 : loss : 0.040459, loss_ce: 0.015990
2022-01-08 15:53:45,777 iteration 1340 : loss : 0.036593, loss_ce: 0.011862
2022-01-08 15:53:48,084 iteration 1341 : loss : 0.040077, loss_ce: 0.017617
2022-01-08 15:53:50,464 iteration 1342 : loss : 0.045346, loss_ce: 0.016178
2022-01-08 15:53:52,828 iteration 1343 : loss : 0.036238, loss_ce: 0.012913
 20%|█████▉                        | 79/400 [53:59<3:43:40, 41.81s/it]2022-01-08 15:53:55,216 iteration 1344 : loss : 0.027107, loss_ce: 0.010164
2022-01-08 15:53:57,608 iteration 1345 : loss : 0.036340, loss_ce: 0.015605
2022-01-08 15:53:59,944 iteration 1346 : loss : 0.048203, loss_ce: 0.014317
2022-01-08 15:54:02,329 iteration 1347 : loss : 0.085530, loss_ce: 0.017874
2022-01-08 15:54:04,714 iteration 1348 : loss : 0.035459, loss_ce: 0.013852
2022-01-08 15:54:07,001 iteration 1349 : loss : 0.070882, loss_ce: 0.033740
2022-01-08 15:54:09,361 iteration 1350 : loss : 0.070434, loss_ce: 0.029660
2022-01-08 15:54:11,663 iteration 1351 : loss : 0.074415, loss_ce: 0.027347
2022-01-08 15:54:14,022 iteration 1352 : loss : 0.039150, loss_ce: 0.014126
2022-01-08 15:54:16,300 iteration 1353 : loss : 0.043897, loss_ce: 0.018079
2022-01-08 15:54:18,802 iteration 1354 : loss : 0.048101, loss_ce: 0.017734
2022-01-08 15:54:21,193 iteration 1355 : loss : 0.073718, loss_ce: 0.026874
2022-01-08 15:54:23,663 iteration 1356 : loss : 0.056715, loss_ce: 0.020403
2022-01-08 15:54:25,995 iteration 1357 : loss : 0.048494, loss_ce: 0.028540
2022-01-08 15:54:28,301 iteration 1358 : loss : 0.047351, loss_ce: 0.016291
2022-01-08 15:54:30,627 iteration 1359 : loss : 0.050680, loss_ce: 0.029472
2022-01-08 15:54:30,627 Training Data Eval:
2022-01-08 15:54:43,398   Average segmentation loss on training set: 0.0476
2022-01-08 15:54:43,398 Validation Data Eval:
2022-01-08 15:54:47,772   Average segmentation loss on validation set: 0.0734
2022-01-08 15:54:53,609 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 15:54:55,213 iteration 1360 : loss : 0.067571, loss_ce: 0.024472
 20%|██████                        | 80/400 [55:02<4:15:54, 47.98s/it]2022-01-08 15:54:56,899 iteration 1361 : loss : 0.093653, loss_ce: 0.032975
2022-01-08 15:54:58,537 iteration 1362 : loss : 0.039031, loss_ce: 0.016969
2022-01-08 15:55:00,314 iteration 1363 : loss : 0.037076, loss_ce: 0.013660
2022-01-08 15:55:02,247 iteration 1364 : loss : 0.064736, loss_ce: 0.019962
2022-01-08 15:55:04,364 iteration 1365 : loss : 0.056687, loss_ce: 0.022571
2022-01-08 15:55:06,425 iteration 1366 : loss : 0.051098, loss_ce: 0.022811
2022-01-08 15:55:08,500 iteration 1367 : loss : 0.056234, loss_ce: 0.025111
2022-01-08 15:55:10,749 iteration 1368 : loss : 0.058476, loss_ce: 0.022575
2022-01-08 15:55:13,031 iteration 1369 : loss : 0.055296, loss_ce: 0.014549
2022-01-08 15:55:15,298 iteration 1370 : loss : 0.046866, loss_ce: 0.015212
2022-01-08 15:55:17,457 iteration 1371 : loss : 0.036552, loss_ce: 0.014635
2022-01-08 15:55:19,724 iteration 1372 : loss : 0.076959, loss_ce: 0.021670
2022-01-08 15:55:22,109 iteration 1373 : loss : 0.063276, loss_ce: 0.034924
2022-01-08 15:55:24,366 iteration 1374 : loss : 0.047905, loss_ce: 0.015899
2022-01-08 15:55:26,677 iteration 1375 : loss : 0.048182, loss_ce: 0.016400
2022-01-08 15:55:28,990 iteration 1376 : loss : 0.038024, loss_ce: 0.015571
2022-01-08 15:55:31,381 iteration 1377 : loss : 0.055831, loss_ce: 0.020363
 20%|██████                        | 81/400 [55:38<3:56:15, 44.44s/it]2022-01-08 15:55:33,780 iteration 1378 : loss : 0.042155, loss_ce: 0.018958
2022-01-08 15:55:36,067 iteration 1379 : loss : 0.075029, loss_ce: 0.021334
2022-01-08 15:55:38,353 iteration 1380 : loss : 0.034086, loss_ce: 0.014239
2022-01-08 15:55:40,762 iteration 1381 : loss : 0.036897, loss_ce: 0.016142
2022-01-08 15:55:43,078 iteration 1382 : loss : 0.038792, loss_ce: 0.016073
2022-01-08 15:55:45,428 iteration 1383 : loss : 0.048760, loss_ce: 0.013990
2022-01-08 15:55:47,826 iteration 1384 : loss : 0.049093, loss_ce: 0.022024
2022-01-08 15:55:50,100 iteration 1385 : loss : 0.033207, loss_ce: 0.012343
2022-01-08 15:55:52,516 iteration 1386 : loss : 0.050096, loss_ce: 0.023475
2022-01-08 15:55:54,838 iteration 1387 : loss : 0.053207, loss_ce: 0.015566
2022-01-08 15:55:57,140 iteration 1388 : loss : 0.037731, loss_ce: 0.012214
2022-01-08 15:55:59,395 iteration 1389 : loss : 0.055009, loss_ce: 0.031180
2022-01-08 15:56:01,653 iteration 1390 : loss : 0.030590, loss_ce: 0.012686
2022-01-08 15:56:03,982 iteration 1391 : loss : 0.061371, loss_ce: 0.019944
2022-01-08 15:56:06,235 iteration 1392 : loss : 0.046605, loss_ce: 0.021844
2022-01-08 15:56:08,475 iteration 1393 : loss : 0.051581, loss_ce: 0.017368
2022-01-08 15:56:10,736 iteration 1394 : loss : 0.045145, loss_ce: 0.012513
 20%|██████▏                       | 82/400 [56:17<3:47:24, 42.91s/it]2022-01-08 15:56:13,010 iteration 1395 : loss : 0.053654, loss_ce: 0.026851
2022-01-08 15:56:15,128 iteration 1396 : loss : 0.042864, loss_ce: 0.019847
2022-01-08 15:56:17,421 iteration 1397 : loss : 0.040947, loss_ce: 0.017264
2022-01-08 15:56:19,613 iteration 1398 : loss : 0.028536, loss_ce: 0.010681
2022-01-08 15:56:21,914 iteration 1399 : loss : 0.034931, loss_ce: 0.015471
2022-01-08 15:56:24,188 iteration 1400 : loss : 0.056316, loss_ce: 0.018647
2022-01-08 15:56:26,437 iteration 1401 : loss : 0.029309, loss_ce: 0.010118
2022-01-08 15:56:28,831 iteration 1402 : loss : 0.038479, loss_ce: 0.014088
2022-01-08 15:56:31,213 iteration 1403 : loss : 0.045187, loss_ce: 0.014842
2022-01-08 15:56:33,533 iteration 1404 : loss : 0.054937, loss_ce: 0.020594
2022-01-08 15:56:35,685 iteration 1405 : loss : 0.031188, loss_ce: 0.011246
2022-01-08 15:56:37,972 iteration 1406 : loss : 0.040911, loss_ce: 0.016078
2022-01-08 15:56:40,346 iteration 1407 : loss : 0.050368, loss_ce: 0.023227
2022-01-08 15:56:42,718 iteration 1408 : loss : 0.037757, loss_ce: 0.018809
2022-01-08 15:56:45,151 iteration 1409 : loss : 0.069116, loss_ce: 0.020128
2022-01-08 15:56:47,412 iteration 1410 : loss : 0.034221, loss_ce: 0.013128
2022-01-08 15:56:49,688 iteration 1411 : loss : 0.029075, loss_ce: 0.011869
 21%|██████▏                       | 83/400 [56:56<3:40:25, 41.72s/it]2022-01-08 15:56:52,075 iteration 1412 : loss : 0.037061, loss_ce: 0.019414
2022-01-08 15:56:54,391 iteration 1413 : loss : 0.028601, loss_ce: 0.010043
2022-01-08 15:56:56,763 iteration 1414 : loss : 0.030297, loss_ce: 0.012811
2022-01-08 15:56:59,026 iteration 1415 : loss : 0.040853, loss_ce: 0.015368
2022-01-08 15:57:01,334 iteration 1416 : loss : 0.033948, loss_ce: 0.012665
2022-01-08 15:57:03,836 iteration 1417 : loss : 0.050756, loss_ce: 0.020061
2022-01-08 15:57:06,230 iteration 1418 : loss : 0.034814, loss_ce: 0.010936
2022-01-08 15:57:08,504 iteration 1419 : loss : 0.046245, loss_ce: 0.021386
2022-01-08 15:57:10,788 iteration 1420 : loss : 0.046728, loss_ce: 0.012741
2022-01-08 15:57:13,026 iteration 1421 : loss : 0.064110, loss_ce: 0.032688
2022-01-08 15:57:15,269 iteration 1422 : loss : 0.041319, loss_ce: 0.019290
2022-01-08 15:57:17,487 iteration 1423 : loss : 0.034529, loss_ce: 0.010596
2022-01-08 15:57:19,670 iteration 1424 : loss : 0.024897, loss_ce: 0.010069
2022-01-08 15:57:22,017 iteration 1425 : loss : 0.069986, loss_ce: 0.017911
2022-01-08 15:57:24,347 iteration 1426 : loss : 0.045752, loss_ce: 0.026576
2022-01-08 15:57:26,666 iteration 1427 : loss : 0.089735, loss_ce: 0.016270
2022-01-08 15:57:29,087 iteration 1428 : loss : 0.048059, loss_ce: 0.018368
 21%|██████▎                       | 84/400 [57:35<3:36:05, 41.03s/it]2022-01-08 15:57:31,405 iteration 1429 : loss : 0.058636, loss_ce: 0.028624
2022-01-08 15:57:33,589 iteration 1430 : loss : 0.030459, loss_ce: 0.011515
2022-01-08 15:57:35,790 iteration 1431 : loss : 0.060672, loss_ce: 0.021233
2022-01-08 15:57:38,098 iteration 1432 : loss : 0.038226, loss_ce: 0.017867
2022-01-08 15:57:40,422 iteration 1433 : loss : 0.030402, loss_ce: 0.013460
2022-01-08 15:57:42,906 iteration 1434 : loss : 0.037889, loss_ce: 0.015913
2022-01-08 15:57:45,378 iteration 1435 : loss : 0.061632, loss_ce: 0.019798
2022-01-08 15:57:47,792 iteration 1436 : loss : 0.047671, loss_ce: 0.023282
2022-01-08 15:57:50,063 iteration 1437 : loss : 0.038276, loss_ce: 0.014787
2022-01-08 15:57:52,349 iteration 1438 : loss : 0.045387, loss_ce: 0.019081
2022-01-08 15:57:54,651 iteration 1439 : loss : 0.058430, loss_ce: 0.025325
2022-01-08 15:57:56,983 iteration 1440 : loss : 0.039005, loss_ce: 0.012998
2022-01-08 15:57:59,302 iteration 1441 : loss : 0.060980, loss_ce: 0.025870
2022-01-08 15:58:01,644 iteration 1442 : loss : 0.044954, loss_ce: 0.012676
2022-01-08 15:58:04,020 iteration 1443 : loss : 0.037452, loss_ce: 0.015672
2022-01-08 15:58:06,403 iteration 1444 : loss : 0.038752, loss_ce: 0.011046
2022-01-08 15:58:06,403 Training Data Eval:
2022-01-08 15:58:18,749   Average segmentation loss on training set: 0.0340
2022-01-08 15:58:18,750 Validation Data Eval:
2022-01-08 15:58:23,146   Average segmentation loss on validation set: 0.0982
2022-01-08 15:58:25,578 iteration 1445 : loss : 0.053679, loss_ce: 0.026848
 21%|██████▍                       | 85/400 [58:32<3:59:45, 45.67s/it]2022-01-08 15:58:27,919 iteration 1446 : loss : 0.042068, loss_ce: 0.017635
2022-01-08 15:58:30,172 iteration 1447 : loss : 0.029373, loss_ce: 0.014473
2022-01-08 15:58:32,578 iteration 1448 : loss : 0.045281, loss_ce: 0.012013
2022-01-08 15:58:34,974 iteration 1449 : loss : 0.042462, loss_ce: 0.014600
2022-01-08 15:58:37,300 iteration 1450 : loss : 0.040381, loss_ce: 0.015628
2022-01-08 15:58:39,707 iteration 1451 : loss : 0.030735, loss_ce: 0.009327
2022-01-08 15:58:42,002 iteration 1452 : loss : 0.059933, loss_ce: 0.037040
2022-01-08 15:58:44,290 iteration 1453 : loss : 0.036734, loss_ce: 0.015492
2022-01-08 15:58:46,603 iteration 1454 : loss : 0.035617, loss_ce: 0.010482
2022-01-08 15:58:48,889 iteration 1455 : loss : 0.034473, loss_ce: 0.011675
2022-01-08 15:58:51,151 iteration 1456 : loss : 0.036525, loss_ce: 0.010968
2022-01-08 15:58:53,517 iteration 1457 : loss : 0.038523, loss_ce: 0.016179
2022-01-08 15:58:55,782 iteration 1458 : loss : 0.035328, loss_ce: 0.015779
2022-01-08 15:58:57,997 iteration 1459 : loss : 0.032038, loss_ce: 0.011427
2022-01-08 15:59:00,243 iteration 1460 : loss : 0.039439, loss_ce: 0.015578
2022-01-08 15:59:02,458 iteration 1461 : loss : 0.038474, loss_ce: 0.013053
2022-01-08 15:59:04,788 iteration 1462 : loss : 0.036990, loss_ce: 0.016323
 22%|██████▍                       | 86/400 [59:11<3:48:51, 43.73s/it]2022-01-08 15:59:07,191 iteration 1463 : loss : 0.072264, loss_ce: 0.019891
2022-01-08 15:59:09,340 iteration 1464 : loss : 0.047307, loss_ce: 0.024170
2022-01-08 15:59:11,679 iteration 1465 : loss : 0.053926, loss_ce: 0.018202
2022-01-08 15:59:13,939 iteration 1466 : loss : 0.038138, loss_ce: 0.015341
2022-01-08 15:59:16,253 iteration 1467 : loss : 0.042214, loss_ce: 0.014538
2022-01-08 15:59:18,543 iteration 1468 : loss : 0.034112, loss_ce: 0.014519
2022-01-08 15:59:20,846 iteration 1469 : loss : 0.069892, loss_ce: 0.027763
2022-01-08 15:59:23,074 iteration 1470 : loss : 0.063784, loss_ce: 0.013231
2022-01-08 15:59:25,406 iteration 1471 : loss : 0.034410, loss_ce: 0.015451
2022-01-08 15:59:27,757 iteration 1472 : loss : 0.054910, loss_ce: 0.021696
2022-01-08 15:59:29,985 iteration 1473 : loss : 0.033251, loss_ce: 0.016727
2022-01-08 15:59:32,326 iteration 1474 : loss : 0.057002, loss_ce: 0.017756
2022-01-08 15:59:34,581 iteration 1475 : loss : 0.035068, loss_ce: 0.015298
2022-01-08 15:59:36,884 iteration 1476 : loss : 0.033328, loss_ce: 0.012886
2022-01-08 15:59:39,353 iteration 1477 : loss : 0.038151, loss_ce: 0.017810
2022-01-08 15:59:41,661 iteration 1478 : loss : 0.059041, loss_ce: 0.018160
2022-01-08 15:59:43,992 iteration 1479 : loss : 0.042240, loss_ce: 0.014444
 22%|██████▌                       | 87/400 [59:50<3:41:03, 42.37s/it]2022-01-08 15:59:46,342 iteration 1480 : loss : 0.025647, loss_ce: 0.009119
2022-01-08 15:59:48,821 iteration 1481 : loss : 0.037633, loss_ce: 0.015232
2022-01-08 15:59:51,327 iteration 1482 : loss : 0.031886, loss_ce: 0.011621
2022-01-08 15:59:53,787 iteration 1483 : loss : 0.041530, loss_ce: 0.015426
2022-01-08 15:59:56,296 iteration 1484 : loss : 0.043365, loss_ce: 0.012615
2022-01-08 15:59:58,733 iteration 1485 : loss : 0.041800, loss_ce: 0.021929
2022-01-08 16:00:01,093 iteration 1486 : loss : 0.035304, loss_ce: 0.011685
2022-01-08 16:00:03,359 iteration 1487 : loss : 0.028259, loss_ce: 0.010471
2022-01-08 16:00:05,659 iteration 1488 : loss : 0.033330, loss_ce: 0.015390
2022-01-08 16:00:08,058 iteration 1489 : loss : 0.040610, loss_ce: 0.017515
2022-01-08 16:00:10,455 iteration 1490 : loss : 0.039168, loss_ce: 0.016659
2022-01-08 16:00:12,758 iteration 1491 : loss : 0.045882, loss_ce: 0.014652
2022-01-08 16:00:15,162 iteration 1492 : loss : 0.064091, loss_ce: 0.034050
2022-01-08 16:00:17,606 iteration 1493 : loss : 0.036007, loss_ce: 0.017343
2022-01-08 16:00:19,973 iteration 1494 : loss : 0.040306, loss_ce: 0.011889
2022-01-08 16:00:22,257 iteration 1495 : loss : 0.035058, loss_ce: 0.009545
2022-01-08 16:00:24,688 iteration 1496 : loss : 0.049984, loss_ce: 0.022460
 22%|██████▏                     | 88/400 [1:00:31<3:37:41, 41.86s/it]2022-01-08 16:00:27,076 iteration 1497 : loss : 0.027144, loss_ce: 0.011110
2022-01-08 16:00:29,495 iteration 1498 : loss : 0.056371, loss_ce: 0.022058
2022-01-08 16:00:31,808 iteration 1499 : loss : 0.046526, loss_ce: 0.016833
2022-01-08 16:00:34,114 iteration 1500 : loss : 0.035614, loss_ce: 0.015963
2022-01-08 16:00:36,400 iteration 1501 : loss : 0.035562, loss_ce: 0.015570
2022-01-08 16:00:38,796 iteration 1502 : loss : 0.074971, loss_ce: 0.018955
2022-01-08 16:00:41,272 iteration 1503 : loss : 0.093119, loss_ce: 0.023854
2022-01-08 16:00:43,679 iteration 1504 : loss : 0.032339, loss_ce: 0.013113
2022-01-08 16:00:46,063 iteration 1505 : loss : 0.055352, loss_ce: 0.023759
2022-01-08 16:00:48,394 iteration 1506 : loss : 0.044111, loss_ce: 0.016444
2022-01-08 16:00:50,661 iteration 1507 : loss : 0.050011, loss_ce: 0.013084
2022-01-08 16:00:52,949 iteration 1508 : loss : 0.073265, loss_ce: 0.047861
2022-01-08 16:00:55,302 iteration 1509 : loss : 0.048347, loss_ce: 0.019724
2022-01-08 16:00:57,670 iteration 1510 : loss : 0.053082, loss_ce: 0.017741
2022-01-08 16:01:00,021 iteration 1511 : loss : 0.043726, loss_ce: 0.016414
2022-01-08 16:01:02,295 iteration 1512 : loss : 0.068921, loss_ce: 0.019440
2022-01-08 16:01:04,537 iteration 1513 : loss : 0.038828, loss_ce: 0.013388
 22%|██████▏                     | 89/400 [1:01:11<3:33:51, 41.26s/it]2022-01-08 16:01:06,987 iteration 1514 : loss : 0.044429, loss_ce: 0.015845
2022-01-08 16:01:09,283 iteration 1515 : loss : 0.040330, loss_ce: 0.016517
2022-01-08 16:01:11,667 iteration 1516 : loss : 0.060329, loss_ce: 0.024088
2022-01-08 16:01:14,030 iteration 1517 : loss : 0.032392, loss_ce: 0.012584
2022-01-08 16:01:16,490 iteration 1518 : loss : 0.037034, loss_ce: 0.013168
2022-01-08 16:01:18,952 iteration 1519 : loss : 0.043950, loss_ce: 0.015851
2022-01-08 16:01:21,436 iteration 1520 : loss : 0.042369, loss_ce: 0.015202
2022-01-08 16:01:23,846 iteration 1521 : loss : 0.042838, loss_ce: 0.013719
2022-01-08 16:01:26,119 iteration 1522 : loss : 0.039330, loss_ce: 0.016040
2022-01-08 16:01:28,425 iteration 1523 : loss : 0.039700, loss_ce: 0.012304
2022-01-08 16:01:30,783 iteration 1524 : loss : 0.036499, loss_ce: 0.013528
2022-01-08 16:01:33,191 iteration 1525 : loss : 0.039756, loss_ce: 0.015804
2022-01-08 16:01:35,611 iteration 1526 : loss : 0.043550, loss_ce: 0.020169
2022-01-08 16:01:38,047 iteration 1527 : loss : 0.048930, loss_ce: 0.022016
2022-01-08 16:01:40,372 iteration 1528 : loss : 0.036601, loss_ce: 0.015475
2022-01-08 16:01:42,720 iteration 1529 : loss : 0.039654, loss_ce: 0.015409
2022-01-08 16:01:42,721 Training Data Eval:
2022-01-08 16:01:55,507   Average segmentation loss on training set: 0.0389
2022-01-08 16:01:55,507 Validation Data Eval:
2022-01-08 16:02:00,163   Average segmentation loss on validation set: 0.1439
2022-01-08 16:02:02,581 iteration 1530 : loss : 0.038025, loss_ce: 0.018759
 22%|██████▎                     | 90/400 [1:02:09<3:59:11, 46.30s/it]2022-01-08 16:02:05,002 iteration 1531 : loss : 0.036036, loss_ce: 0.015158
2022-01-08 16:02:07,362 iteration 1532 : loss : 0.041093, loss_ce: 0.014320
2022-01-08 16:02:09,852 iteration 1533 : loss : 0.029884, loss_ce: 0.010666
2022-01-08 16:02:12,262 iteration 1534 : loss : 0.037210, loss_ce: 0.017514
2022-01-08 16:02:14,684 iteration 1535 : loss : 0.040962, loss_ce: 0.016344
2022-01-08 16:02:17,123 iteration 1536 : loss : 0.050001, loss_ce: 0.027900
2022-01-08 16:02:19,615 iteration 1537 : loss : 0.040698, loss_ce: 0.013674
2022-01-08 16:02:22,040 iteration 1538 : loss : 0.029103, loss_ce: 0.011391
2022-01-08 16:02:24,467 iteration 1539 : loss : 0.044817, loss_ce: 0.018855
2022-01-08 16:02:26,846 iteration 1540 : loss : 0.065083, loss_ce: 0.031129
2022-01-08 16:02:29,259 iteration 1541 : loss : 0.023278, loss_ce: 0.010070
2022-01-08 16:02:31,619 iteration 1542 : loss : 0.028371, loss_ce: 0.011805
2022-01-08 16:02:33,982 iteration 1543 : loss : 0.065170, loss_ce: 0.022181
2022-01-08 16:02:36,339 iteration 1544 : loss : 0.036815, loss_ce: 0.014770
2022-01-08 16:02:38,811 iteration 1545 : loss : 0.039782, loss_ce: 0.013938
2022-01-08 16:02:41,112 iteration 1546 : loss : 0.055434, loss_ce: 0.018932
2022-01-08 16:02:43,561 iteration 1547 : loss : 0.032780, loss_ce: 0.013842
 23%|██████▎                     | 91/400 [1:02:50<3:50:12, 44.70s/it]2022-01-08 16:02:46,013 iteration 1548 : loss : 0.034566, loss_ce: 0.014043
2022-01-08 16:02:48,285 iteration 1549 : loss : 0.027543, loss_ce: 0.011005
2022-01-08 16:02:50,640 iteration 1550 : loss : 0.041008, loss_ce: 0.015432
2022-01-08 16:02:53,001 iteration 1551 : loss : 0.030242, loss_ce: 0.010844
2022-01-08 16:02:55,449 iteration 1552 : loss : 0.029661, loss_ce: 0.010350
2022-01-08 16:02:57,903 iteration 1553 : loss : 0.054485, loss_ce: 0.021788
2022-01-08 16:03:00,350 iteration 1554 : loss : 0.045459, loss_ce: 0.022411
2022-01-08 16:03:02,720 iteration 1555 : loss : 0.037290, loss_ce: 0.016038
2022-01-08 16:03:05,050 iteration 1556 : loss : 0.039893, loss_ce: 0.013887
2022-01-08 16:03:07,295 iteration 1557 : loss : 0.040822, loss_ce: 0.016945
2022-01-08 16:03:09,652 iteration 1558 : loss : 0.036829, loss_ce: 0.018365
2022-01-08 16:03:12,143 iteration 1559 : loss : 0.035468, loss_ce: 0.012490
2022-01-08 16:03:14,482 iteration 1560 : loss : 0.028733, loss_ce: 0.013211
2022-01-08 16:03:16,935 iteration 1561 : loss : 0.029055, loss_ce: 0.010529
2022-01-08 16:03:19,274 iteration 1562 : loss : 0.059350, loss_ce: 0.014245
2022-01-08 16:03:21,625 iteration 1563 : loss : 0.033510, loss_ce: 0.014234
2022-01-08 16:03:24,115 iteration 1564 : loss : 0.033512, loss_ce: 0.014004
 23%|██████▍                     | 92/400 [1:03:30<3:43:05, 43.46s/it]2022-01-08 16:03:26,599 iteration 1565 : loss : 0.038231, loss_ce: 0.018118
2022-01-08 16:03:29,017 iteration 1566 : loss : 0.032619, loss_ce: 0.012974
2022-01-08 16:03:31,452 iteration 1567 : loss : 0.048790, loss_ce: 0.015116
2022-01-08 16:03:33,879 iteration 1568 : loss : 0.046713, loss_ce: 0.016605
2022-01-08 16:03:36,289 iteration 1569 : loss : 0.035415, loss_ce: 0.015704
2022-01-08 16:03:38,673 iteration 1570 : loss : 0.024778, loss_ce: 0.011279
2022-01-08 16:03:40,996 iteration 1571 : loss : 0.067434, loss_ce: 0.014982
2022-01-08 16:03:43,426 iteration 1572 : loss : 0.044594, loss_ce: 0.015374
2022-01-08 16:03:45,842 iteration 1573 : loss : 0.049959, loss_ce: 0.026831
2022-01-08 16:03:48,251 iteration 1574 : loss : 0.024527, loss_ce: 0.010192
2022-01-08 16:03:50,709 iteration 1575 : loss : 0.035406, loss_ce: 0.012974
2022-01-08 16:03:53,078 iteration 1576 : loss : 0.033720, loss_ce: 0.015710
2022-01-08 16:03:55,482 iteration 1577 : loss : 0.028482, loss_ce: 0.011349
2022-01-08 16:03:57,909 iteration 1578 : loss : 0.042699, loss_ce: 0.014354
2022-01-08 16:04:00,327 iteration 1579 : loss : 0.028522, loss_ce: 0.011164
2022-01-08 16:04:02,650 iteration 1580 : loss : 0.033424, loss_ce: 0.012856
2022-01-08 16:04:05,039 iteration 1581 : loss : 0.035185, loss_ce: 0.012538
 23%|██████▌                     | 93/400 [1:04:11<3:38:28, 42.70s/it]2022-01-08 16:04:07,522 iteration 1582 : loss : 0.049536, loss_ce: 0.016946
2022-01-08 16:04:09,895 iteration 1583 : loss : 0.044924, loss_ce: 0.012009
2022-01-08 16:04:12,262 iteration 1584 : loss : 0.036643, loss_ce: 0.021435
2022-01-08 16:04:14,726 iteration 1585 : loss : 0.032152, loss_ce: 0.011142
2022-01-08 16:04:17,191 iteration 1586 : loss : 0.041162, loss_ce: 0.018399
2022-01-08 16:04:19,505 iteration 1587 : loss : 0.027931, loss_ce: 0.011517
2022-01-08 16:04:21,886 iteration 1588 : loss : 0.041820, loss_ce: 0.021010
2022-01-08 16:04:24,257 iteration 1589 : loss : 0.043931, loss_ce: 0.017074
2022-01-08 16:04:26,695 iteration 1590 : loss : 0.050208, loss_ce: 0.016701
2022-01-08 16:04:28,993 iteration 1591 : loss : 0.031605, loss_ce: 0.010984
2022-01-08 16:04:31,348 iteration 1592 : loss : 0.039804, loss_ce: 0.014183
2022-01-08 16:04:33,776 iteration 1593 : loss : 0.041282, loss_ce: 0.017991
2022-01-08 16:04:36,129 iteration 1594 : loss : 0.048637, loss_ce: 0.016637
2022-01-08 16:04:38,481 iteration 1595 : loss : 0.024732, loss_ce: 0.007701
2022-01-08 16:04:40,865 iteration 1596 : loss : 0.058786, loss_ce: 0.025482
2022-01-08 16:04:43,254 iteration 1597 : loss : 0.054123, loss_ce: 0.024191
2022-01-08 16:04:45,667 iteration 1598 : loss : 0.032252, loss_ce: 0.011997
 24%|██████▌                     | 94/400 [1:04:52<3:34:36, 42.08s/it]2022-01-08 16:04:48,113 iteration 1599 : loss : 0.028430, loss_ce: 0.011333
2022-01-08 16:04:50,502 iteration 1600 : loss : 0.048642, loss_ce: 0.016579
2022-01-08 16:04:53,148 iteration 1601 : loss : 0.033198, loss_ce: 0.012826
2022-01-08 16:04:55,667 iteration 1602 : loss : 0.053369, loss_ce: 0.022942
2022-01-08 16:04:57,999 iteration 1603 : loss : 0.041754, loss_ce: 0.014796
2022-01-08 16:05:00,261 iteration 1604 : loss : 0.057298, loss_ce: 0.021312
2022-01-08 16:05:02,572 iteration 1605 : loss : 0.048926, loss_ce: 0.017431
2022-01-08 16:05:04,905 iteration 1606 : loss : 0.035047, loss_ce: 0.016024
2022-01-08 16:05:07,291 iteration 1607 : loss : 0.023655, loss_ce: 0.009478
2022-01-08 16:05:09,757 iteration 1608 : loss : 0.038076, loss_ce: 0.012844
2022-01-08 16:05:12,206 iteration 1609 : loss : 0.057790, loss_ce: 0.026584
2022-01-08 16:05:14,600 iteration 1610 : loss : 0.036766, loss_ce: 0.013341
2022-01-08 16:05:16,997 iteration 1611 : loss : 0.070977, loss_ce: 0.023914
2022-01-08 16:05:19,368 iteration 1612 : loss : 0.033136, loss_ce: 0.016543
2022-01-08 16:05:21,654 iteration 1613 : loss : 0.047549, loss_ce: 0.021968
2022-01-08 16:05:24,061 iteration 1614 : loss : 0.038058, loss_ce: 0.010246
2022-01-08 16:05:24,061 Training Data Eval:
2022-01-08 16:05:36,812   Average segmentation loss on training set: 0.0264
2022-01-08 16:05:36,812 Validation Data Eval:
2022-01-08 16:05:41,312   Average segmentation loss on validation set: 0.0833
2022-01-08 16:05:43,711 iteration 1615 : loss : 0.030734, loss_ce: 0.012119
 24%|██████▋                     | 95/400 [1:05:50<3:58:13, 46.87s/it]2022-01-08 16:05:46,184 iteration 1616 : loss : 0.036359, loss_ce: 0.011730
2022-01-08 16:05:48,552 iteration 1617 : loss : 0.047022, loss_ce: 0.012938
2022-01-08 16:05:50,869 iteration 1618 : loss : 0.026436, loss_ce: 0.011784
2022-01-08 16:05:53,264 iteration 1619 : loss : 0.027708, loss_ce: 0.008779
2022-01-08 16:05:55,587 iteration 1620 : loss : 0.034335, loss_ce: 0.010269
2022-01-08 16:05:58,002 iteration 1621 : loss : 0.044244, loss_ce: 0.025931
2022-01-08 16:06:00,524 iteration 1622 : loss : 0.060556, loss_ce: 0.016023
2022-01-08 16:06:02,870 iteration 1623 : loss : 0.041692, loss_ce: 0.015419
2022-01-08 16:06:05,252 iteration 1624 : loss : 0.027867, loss_ce: 0.011036
2022-01-08 16:06:07,619 iteration 1625 : loss : 0.034330, loss_ce: 0.014559
2022-01-08 16:06:10,009 iteration 1626 : loss : 0.026354, loss_ce: 0.011780
2022-01-08 16:06:12,427 iteration 1627 : loss : 0.044677, loss_ce: 0.016456
2022-01-08 16:06:14,812 iteration 1628 : loss : 0.044137, loss_ce: 0.016916
2022-01-08 16:06:17,084 iteration 1629 : loss : 0.032954, loss_ce: 0.011537
2022-01-08 16:06:19,352 iteration 1630 : loss : 0.033200, loss_ce: 0.011645
2022-01-08 16:06:21,869 iteration 1631 : loss : 0.045457, loss_ce: 0.018214
2022-01-08 16:06:24,260 iteration 1632 : loss : 0.041356, loss_ce: 0.014457
 24%|██████▋                     | 96/400 [1:06:31<3:47:49, 44.97s/it]2022-01-08 16:06:26,696 iteration 1633 : loss : 0.038836, loss_ce: 0.015375
2022-01-08 16:06:29,120 iteration 1634 : loss : 0.041086, loss_ce: 0.013225
2022-01-08 16:06:31,425 iteration 1635 : loss : 0.029538, loss_ce: 0.014016
2022-01-08 16:06:33,747 iteration 1636 : loss : 0.038463, loss_ce: 0.018141
2022-01-08 16:06:36,108 iteration 1637 : loss : 0.044151, loss_ce: 0.014704
2022-01-08 16:06:38,396 iteration 1638 : loss : 0.052877, loss_ce: 0.022618
2022-01-08 16:06:40,845 iteration 1639 : loss : 0.055592, loss_ce: 0.012690
2022-01-08 16:06:43,184 iteration 1640 : loss : 0.052825, loss_ce: 0.012906
2022-01-08 16:06:45,465 iteration 1641 : loss : 0.023892, loss_ce: 0.010668
2022-01-08 16:06:47,873 iteration 1642 : loss : 0.033264, loss_ce: 0.011385
2022-01-08 16:06:50,278 iteration 1643 : loss : 0.026136, loss_ce: 0.007407
2022-01-08 16:06:52,725 iteration 1644 : loss : 0.030944, loss_ce: 0.011822
2022-01-08 16:06:55,088 iteration 1645 : loss : 0.031260, loss_ce: 0.011442
2022-01-08 16:06:57,453 iteration 1646 : loss : 0.036704, loss_ce: 0.014561
2022-01-08 16:06:59,993 iteration 1647 : loss : 0.041678, loss_ce: 0.013983
2022-01-08 16:07:02,423 iteration 1648 : loss : 0.044190, loss_ce: 0.019632
2022-01-08 16:07:04,752 iteration 1649 : loss : 0.036651, loss_ce: 0.017743
 24%|██████▊                     | 97/400 [1:07:11<3:40:18, 43.63s/it]2022-01-08 16:07:07,219 iteration 1650 : loss : 0.074374, loss_ce: 0.037427
2022-01-08 16:07:09,640 iteration 1651 : loss : 0.050616, loss_ce: 0.014667
2022-01-08 16:07:11,860 iteration 1652 : loss : 0.047151, loss_ce: 0.014139
2022-01-08 16:07:14,323 iteration 1653 : loss : 0.034898, loss_ce: 0.011882
2022-01-08 16:07:16,752 iteration 1654 : loss : 0.067289, loss_ce: 0.014946
2022-01-08 16:07:19,157 iteration 1655 : loss : 0.045744, loss_ce: 0.017443
2022-01-08 16:07:21,422 iteration 1656 : loss : 0.028993, loss_ce: 0.010196
2022-01-08 16:07:23,843 iteration 1657 : loss : 0.061299, loss_ce: 0.018867
2022-01-08 16:07:26,253 iteration 1658 : loss : 0.061032, loss_ce: 0.032794
2022-01-08 16:07:28,582 iteration 1659 : loss : 0.026845, loss_ce: 0.007918
2022-01-08 16:07:31,021 iteration 1660 : loss : 0.032360, loss_ce: 0.011881
2022-01-08 16:07:33,423 iteration 1661 : loss : 0.027618, loss_ce: 0.008933
2022-01-08 16:07:35,774 iteration 1662 : loss : 0.045611, loss_ce: 0.020421
2022-01-08 16:07:38,043 iteration 1663 : loss : 0.026110, loss_ce: 0.012708
2022-01-08 16:07:40,540 iteration 1664 : loss : 0.060723, loss_ce: 0.023910
2022-01-08 16:07:43,057 iteration 1665 : loss : 0.039374, loss_ce: 0.014249
2022-01-08 16:07:45,516 iteration 1666 : loss : 0.044031, loss_ce: 0.018389
 24%|██████▊                     | 98/400 [1:07:52<3:35:16, 42.77s/it]2022-01-08 16:07:47,909 iteration 1667 : loss : 0.051461, loss_ce: 0.017532
2022-01-08 16:07:50,263 iteration 1668 : loss : 0.046628, loss_ce: 0.017917
2022-01-08 16:07:52,549 iteration 1669 : loss : 0.036042, loss_ce: 0.014072
2022-01-08 16:07:54,919 iteration 1670 : loss : 0.038052, loss_ce: 0.019836
2022-01-08 16:07:57,386 iteration 1671 : loss : 0.041917, loss_ce: 0.017789
2022-01-08 16:07:59,829 iteration 1672 : loss : 0.050657, loss_ce: 0.022819
2022-01-08 16:08:02,161 iteration 1673 : loss : 0.036887, loss_ce: 0.014681
2022-01-08 16:08:04,505 iteration 1674 : loss : 0.043658, loss_ce: 0.019462
2022-01-08 16:08:06,841 iteration 1675 : loss : 0.049460, loss_ce: 0.013807
2022-01-08 16:08:09,219 iteration 1676 : loss : 0.050419, loss_ce: 0.015933
2022-01-08 16:08:11,678 iteration 1677 : loss : 0.053279, loss_ce: 0.026722
2022-01-08 16:08:14,136 iteration 1678 : loss : 0.040611, loss_ce: 0.017779
2022-01-08 16:08:16,532 iteration 1679 : loss : 0.033511, loss_ce: 0.009422
2022-01-08 16:08:18,928 iteration 1680 : loss : 0.031495, loss_ce: 0.014389
2022-01-08 16:08:21,331 iteration 1681 : loss : 0.035403, loss_ce: 0.020609
2022-01-08 16:08:23,755 iteration 1682 : loss : 0.063273, loss_ce: 0.025495
2022-01-08 16:08:26,061 iteration 1683 : loss : 0.030153, loss_ce: 0.010817
 25%|██████▉                     | 99/400 [1:08:32<3:31:12, 42.10s/it]2022-01-08 16:08:28,482 iteration 1684 : loss : 0.043408, loss_ce: 0.014888
2022-01-08 16:08:30,823 iteration 1685 : loss : 0.049337, loss_ce: 0.015471
2022-01-08 16:08:33,125 iteration 1686 : loss : 0.030579, loss_ce: 0.010879
2022-01-08 16:08:35,481 iteration 1687 : loss : 0.051979, loss_ce: 0.024813
2022-01-08 16:08:38,005 iteration 1688 : loss : 0.033709, loss_ce: 0.015197
2022-01-08 16:08:40,359 iteration 1689 : loss : 0.037009, loss_ce: 0.015220
2022-01-08 16:08:42,795 iteration 1690 : loss : 0.047190, loss_ce: 0.021413
2022-01-08 16:08:45,186 iteration 1691 : loss : 0.078085, loss_ce: 0.018907
2022-01-08 16:08:47,632 iteration 1692 : loss : 0.074344, loss_ce: 0.024961
2022-01-08 16:08:49,880 iteration 1693 : loss : 0.035555, loss_ce: 0.014631
2022-01-08 16:08:52,274 iteration 1694 : loss : 0.033520, loss_ce: 0.012127
2022-01-08 16:08:54,773 iteration 1695 : loss : 0.048693, loss_ce: 0.017812
2022-01-08 16:08:57,222 iteration 1696 : loss : 0.093027, loss_ce: 0.032905
2022-01-08 16:08:59,564 iteration 1697 : loss : 0.035736, loss_ce: 0.013898
2022-01-08 16:09:01,951 iteration 1698 : loss : 0.049992, loss_ce: 0.017885
2022-01-08 16:09:04,263 iteration 1699 : loss : 0.038631, loss_ce: 0.018691
2022-01-08 16:09:04,263 Training Data Eval:
2022-01-08 16:09:17,075   Average segmentation loss on training set: 0.0262
2022-01-08 16:09:17,076 Validation Data Eval:
2022-01-08 16:09:21,567   Average segmentation loss on validation set: 0.0944
2022-01-08 16:09:23,967 iteration 1700 : loss : 0.047345, loss_ce: 0.015803
 25%|██████▊                    | 100/400 [1:09:30<3:54:12, 46.84s/it]2022-01-08 16:09:26,397 iteration 1701 : loss : 0.035890, loss_ce: 0.015022
2022-01-08 16:09:28,799 iteration 1702 : loss : 0.048052, loss_ce: 0.018068
2022-01-08 16:09:31,229 iteration 1703 : loss : 0.037263, loss_ce: 0.015524
2022-01-08 16:09:33,564 iteration 1704 : loss : 0.036144, loss_ce: 0.014682
2022-01-08 16:09:36,093 iteration 1705 : loss : 0.050716, loss_ce: 0.016156
2022-01-08 16:09:38,525 iteration 1706 : loss : 0.051788, loss_ce: 0.016457
2022-01-08 16:09:40,856 iteration 1707 : loss : 0.036254, loss_ce: 0.015055
2022-01-08 16:09:43,149 iteration 1708 : loss : 0.038088, loss_ce: 0.013881
2022-01-08 16:09:45,657 iteration 1709 : loss : 0.043216, loss_ce: 0.015810
2022-01-08 16:09:48,026 iteration 1710 : loss : 0.031043, loss_ce: 0.014563
2022-01-08 16:09:50,384 iteration 1711 : loss : 0.042709, loss_ce: 0.014979
2022-01-08 16:09:52,833 iteration 1712 : loss : 0.052141, loss_ce: 0.018494
2022-01-08 16:09:55,232 iteration 1713 : loss : 0.053141, loss_ce: 0.017980
2022-01-08 16:09:57,515 iteration 1714 : loss : 0.031925, loss_ce: 0.013521
2022-01-08 16:09:59,862 iteration 1715 : loss : 0.053833, loss_ce: 0.020408
2022-01-08 16:10:02,154 iteration 1716 : loss : 0.049187, loss_ce: 0.014842
2022-01-08 16:10:04,433 iteration 1717 : loss : 0.026392, loss_ce: 0.011411
 25%|██████▊                    | 101/400 [1:10:11<3:43:55, 44.93s/it]2022-01-08 16:10:06,794 iteration 1718 : loss : 0.038527, loss_ce: 0.014931
2022-01-08 16:10:09,138 iteration 1719 : loss : 0.029312, loss_ce: 0.008606
2022-01-08 16:10:11,417 iteration 1720 : loss : 0.041191, loss_ce: 0.013766
2022-01-08 16:10:13,768 iteration 1721 : loss : 0.044671, loss_ce: 0.019145
2022-01-08 16:10:16,068 iteration 1722 : loss : 0.025915, loss_ce: 0.010665
2022-01-08 16:10:18,401 iteration 1723 : loss : 0.032206, loss_ce: 0.013652
2022-01-08 16:10:20,598 iteration 1724 : loss : 0.027117, loss_ce: 0.013127
2022-01-08 16:10:22,858 iteration 1725 : loss : 0.028683, loss_ce: 0.012251
2022-01-08 16:10:25,298 iteration 1726 : loss : 0.036306, loss_ce: 0.011808
2022-01-08 16:10:27,686 iteration 1727 : loss : 0.054466, loss_ce: 0.017834
2022-01-08 16:10:30,092 iteration 1728 : loss : 0.049410, loss_ce: 0.023614
2022-01-08 16:10:32,328 iteration 1729 : loss : 0.038143, loss_ce: 0.015811
2022-01-08 16:10:34,615 iteration 1730 : loss : 0.033813, loss_ce: 0.012113
2022-01-08 16:10:36,895 iteration 1731 : loss : 0.035398, loss_ce: 0.015688
2022-01-08 16:10:39,273 iteration 1732 : loss : 0.036251, loss_ce: 0.015889
2022-01-08 16:10:41,652 iteration 1733 : loss : 0.036947, loss_ce: 0.013177
2022-01-08 16:10:44,021 iteration 1734 : loss : 0.045550, loss_ce: 0.013123
 26%|██████▉                    | 102/400 [1:10:50<3:35:11, 43.33s/it]2022-01-08 16:10:46,459 iteration 1735 : loss : 0.039539, loss_ce: 0.014590
2022-01-08 16:10:48,811 iteration 1736 : loss : 0.032028, loss_ce: 0.012432
2022-01-08 16:10:51,122 iteration 1737 : loss : 0.040287, loss_ce: 0.016274
2022-01-08 16:10:53,453 iteration 1738 : loss : 0.033511, loss_ce: 0.013107
2022-01-08 16:10:55,868 iteration 1739 : loss : 0.048553, loss_ce: 0.024678
2022-01-08 16:10:58,227 iteration 1740 : loss : 0.046304, loss_ce: 0.010668
2022-01-08 16:11:00,640 iteration 1741 : loss : 0.039709, loss_ce: 0.012282
2022-01-08 16:11:03,009 iteration 1742 : loss : 0.033394, loss_ce: 0.012545
2022-01-08 16:11:05,359 iteration 1743 : loss : 0.043405, loss_ce: 0.026250
2022-01-08 16:11:07,646 iteration 1744 : loss : 0.030925, loss_ce: 0.010367
2022-01-08 16:11:10,095 iteration 1745 : loss : 0.028152, loss_ce: 0.011357
2022-01-08 16:11:12,422 iteration 1746 : loss : 0.033463, loss_ce: 0.010671
2022-01-08 16:11:14,744 iteration 1747 : loss : 0.030269, loss_ce: 0.010223
2022-01-08 16:11:17,041 iteration 1748 : loss : 0.027481, loss_ce: 0.013166
2022-01-08 16:11:19,369 iteration 1749 : loss : 0.030583, loss_ce: 0.010954
2022-01-08 16:11:21,584 iteration 1750 : loss : 0.026759, loss_ce: 0.013768
2022-01-08 16:11:23,835 iteration 1751 : loss : 0.031406, loss_ce: 0.011417
 26%|██████▉                    | 103/400 [1:11:30<3:29:15, 42.28s/it]2022-01-08 16:11:26,219 iteration 1752 : loss : 0.029245, loss_ce: 0.012145
2022-01-08 16:11:28,606 iteration 1753 : loss : 0.030375, loss_ce: 0.013707
2022-01-08 16:11:30,879 iteration 1754 : loss : 0.028711, loss_ce: 0.012399
2022-01-08 16:11:33,192 iteration 1755 : loss : 0.041977, loss_ce: 0.015251
2022-01-08 16:11:35,518 iteration 1756 : loss : 0.032578, loss_ce: 0.013883
2022-01-08 16:11:37,799 iteration 1757 : loss : 0.038434, loss_ce: 0.011082
2022-01-08 16:11:40,101 iteration 1758 : loss : 0.035272, loss_ce: 0.012982
2022-01-08 16:11:42,403 iteration 1759 : loss : 0.038702, loss_ce: 0.012086
2022-01-08 16:11:44,825 iteration 1760 : loss : 0.030194, loss_ce: 0.013138
2022-01-08 16:11:47,154 iteration 1761 : loss : 0.026119, loss_ce: 0.010571
2022-01-08 16:11:49,518 iteration 1762 : loss : 0.057601, loss_ce: 0.025562
2022-01-08 16:11:51,752 iteration 1763 : loss : 0.041913, loss_ce: 0.013069
2022-01-08 16:11:54,072 iteration 1764 : loss : 0.082352, loss_ce: 0.021360
2022-01-08 16:11:56,508 iteration 1765 : loss : 0.048114, loss_ce: 0.013793
2022-01-08 16:11:58,874 iteration 1766 : loss : 0.030893, loss_ce: 0.013632
2022-01-08 16:12:01,264 iteration 1767 : loss : 0.049683, loss_ce: 0.019609
2022-01-08 16:12:03,679 iteration 1768 : loss : 0.040034, loss_ce: 0.013039
 26%|███████                    | 104/400 [1:12:10<3:24:56, 41.54s/it]2022-01-08 16:12:06,103 iteration 1769 : loss : 0.047272, loss_ce: 0.013947
2022-01-08 16:12:08,544 iteration 1770 : loss : 0.086270, loss_ce: 0.048058
2022-01-08 16:12:10,859 iteration 1771 : loss : 0.053074, loss_ce: 0.020796
2022-01-08 16:12:13,186 iteration 1772 : loss : 0.039657, loss_ce: 0.011028
2022-01-08 16:12:15,475 iteration 1773 : loss : 0.034430, loss_ce: 0.011344
2022-01-08 16:12:17,832 iteration 1774 : loss : 0.036587, loss_ce: 0.015307
2022-01-08 16:12:20,436 iteration 1775 : loss : 0.030600, loss_ce: 0.013292
2022-01-08 16:12:22,839 iteration 1776 : loss : 0.054314, loss_ce: 0.013495
2022-01-08 16:12:25,241 iteration 1777 : loss : 0.040845, loss_ce: 0.016166
2022-01-08 16:12:27,616 iteration 1778 : loss : 0.038134, loss_ce: 0.011269
2022-01-08 16:12:29,939 iteration 1779 : loss : 0.030165, loss_ce: 0.011599
2022-01-08 16:12:32,172 iteration 1780 : loss : 0.037837, loss_ce: 0.014849
2022-01-08 16:12:34,632 iteration 1781 : loss : 0.037540, loss_ce: 0.017084
2022-01-08 16:12:37,053 iteration 1782 : loss : 0.037016, loss_ce: 0.012856
2022-01-08 16:12:39,321 iteration 1783 : loss : 0.037876, loss_ce: 0.018530
2022-01-08 16:12:41,725 iteration 1784 : loss : 0.030799, loss_ce: 0.011125
2022-01-08 16:12:41,725 Training Data Eval:
2022-01-08 16:12:54,351   Average segmentation loss on training set: 0.0321
2022-01-08 16:12:54,351 Validation Data Eval:
2022-01-08 16:12:58,739   Average segmentation loss on validation set: 0.0620
2022-01-08 16:13:04,542 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 16:13:06,171 iteration 1785 : loss : 0.037499, loss_ce: 0.014938
 26%|███████                    | 105/400 [1:13:13<3:55:08, 47.83s/it]2022-01-08 16:13:07,907 iteration 1786 : loss : 0.045139, loss_ce: 0.022203
2022-01-08 16:13:09,676 iteration 1787 : loss : 0.040095, loss_ce: 0.016298
2022-01-08 16:13:11,477 iteration 1788 : loss : 0.032787, loss_ce: 0.013333
2022-01-08 16:13:13,418 iteration 1789 : loss : 0.033346, loss_ce: 0.010665
2022-01-08 16:13:15,478 iteration 1790 : loss : 0.029877, loss_ce: 0.013681
2022-01-08 16:13:17,534 iteration 1791 : loss : 0.026665, loss_ce: 0.012449
2022-01-08 16:13:19,649 iteration 1792 : loss : 0.032524, loss_ce: 0.010869
2022-01-08 16:13:21,805 iteration 1793 : loss : 0.050063, loss_ce: 0.022266
2022-01-08 16:13:23,931 iteration 1794 : loss : 0.028607, loss_ce: 0.011976
2022-01-08 16:13:26,298 iteration 1795 : loss : 0.035980, loss_ce: 0.015570
2022-01-08 16:13:28,600 iteration 1796 : loss : 0.046406, loss_ce: 0.018102
2022-01-08 16:13:30,928 iteration 1797 : loss : 0.033092, loss_ce: 0.014278
2022-01-08 16:13:33,123 iteration 1798 : loss : 0.036701, loss_ce: 0.012023
2022-01-08 16:13:35,413 iteration 1799 : loss : 0.029144, loss_ce: 0.011125
2022-01-08 16:13:37,704 iteration 1800 : loss : 0.040500, loss_ce: 0.019501
2022-01-08 16:13:40,010 iteration 1801 : loss : 0.046782, loss_ce: 0.026337
2022-01-08 16:13:42,305 iteration 1802 : loss : 0.048004, loss_ce: 0.012935
 26%|███████▏                   | 106/400 [1:13:49<3:37:09, 44.32s/it]2022-01-08 16:13:44,733 iteration 1803 : loss : 0.048038, loss_ce: 0.017538
2022-01-08 16:13:47,068 iteration 1804 : loss : 0.024492, loss_ce: 0.005928
2022-01-08 16:13:49,435 iteration 1805 : loss : 0.033878, loss_ce: 0.015408
2022-01-08 16:13:51,923 iteration 1806 : loss : 0.046176, loss_ce: 0.014335
2022-01-08 16:13:54,327 iteration 1807 : loss : 0.025759, loss_ce: 0.008254
2022-01-08 16:13:56,765 iteration 1808 : loss : 0.035566, loss_ce: 0.013725
2022-01-08 16:13:59,137 iteration 1809 : loss : 0.033440, loss_ce: 0.013374
2022-01-08 16:14:01,495 iteration 1810 : loss : 0.031273, loss_ce: 0.011882
2022-01-08 16:14:03,891 iteration 1811 : loss : 0.032001, loss_ce: 0.012631
2022-01-08 16:14:06,362 iteration 1812 : loss : 0.036204, loss_ce: 0.016875
2022-01-08 16:14:08,876 iteration 1813 : loss : 0.065316, loss_ce: 0.021968
2022-01-08 16:14:11,365 iteration 1814 : loss : 0.080858, loss_ce: 0.029286
2022-01-08 16:14:13,721 iteration 1815 : loss : 0.031007, loss_ce: 0.015233
2022-01-08 16:14:16,159 iteration 1816 : loss : 0.060622, loss_ce: 0.021599
2022-01-08 16:14:18,529 iteration 1817 : loss : 0.034214, loss_ce: 0.011021
2022-01-08 16:14:21,001 iteration 1818 : loss : 0.038108, loss_ce: 0.020689
2022-01-08 16:14:23,378 iteration 1819 : loss : 0.035207, loss_ce: 0.012077
 27%|███████▏                   | 107/400 [1:14:30<3:31:39, 43.34s/it]2022-01-08 16:14:25,821 iteration 1820 : loss : 0.048485, loss_ce: 0.014265
2022-01-08 16:14:28,218 iteration 1821 : loss : 0.036774, loss_ce: 0.012095
2022-01-08 16:14:30,584 iteration 1822 : loss : 0.031579, loss_ce: 0.014578
2022-01-08 16:14:33,018 iteration 1823 : loss : 0.038121, loss_ce: 0.016127
2022-01-08 16:14:35,362 iteration 1824 : loss : 0.043692, loss_ce: 0.012664
2022-01-08 16:14:37,738 iteration 1825 : loss : 0.047050, loss_ce: 0.014990
2022-01-08 16:14:40,090 iteration 1826 : loss : 0.044738, loss_ce: 0.019872
2022-01-08 16:14:42,437 iteration 1827 : loss : 0.052000, loss_ce: 0.014199
2022-01-08 16:14:44,847 iteration 1828 : loss : 0.035172, loss_ce: 0.016680
2022-01-08 16:14:47,274 iteration 1829 : loss : 0.049859, loss_ce: 0.013503
2022-01-08 16:14:49,619 iteration 1830 : loss : 0.030414, loss_ce: 0.012067
2022-01-08 16:14:52,066 iteration 1831 : loss : 0.041388, loss_ce: 0.016653
2022-01-08 16:14:54,479 iteration 1832 : loss : 0.030583, loss_ce: 0.010395
2022-01-08 16:14:56,811 iteration 1833 : loss : 0.029635, loss_ce: 0.016077
2022-01-08 16:14:59,229 iteration 1834 : loss : 0.041035, loss_ce: 0.013903
2022-01-08 16:15:01,653 iteration 1835 : loss : 0.040040, loss_ce: 0.015144
2022-01-08 16:15:04,001 iteration 1836 : loss : 0.032907, loss_ce: 0.013012
 27%|███████▎                   | 108/400 [1:15:10<3:26:59, 42.53s/it]2022-01-08 16:15:06,341 iteration 1837 : loss : 0.051348, loss_ce: 0.009639
2022-01-08 16:15:08,796 iteration 1838 : loss : 0.035220, loss_ce: 0.014733
2022-01-08 16:15:11,316 iteration 1839 : loss : 0.036238, loss_ce: 0.014287
2022-01-08 16:15:13,747 iteration 1840 : loss : 0.052902, loss_ce: 0.014401
2022-01-08 16:15:16,131 iteration 1841 : loss : 0.033571, loss_ce: 0.010873
2022-01-08 16:15:18,543 iteration 1842 : loss : 0.030848, loss_ce: 0.011811
2022-01-08 16:15:20,952 iteration 1843 : loss : 0.029456, loss_ce: 0.012566
2022-01-08 16:15:23,352 iteration 1844 : loss : 0.043942, loss_ce: 0.018501
2022-01-08 16:15:25,736 iteration 1845 : loss : 0.031104, loss_ce: 0.012641
2022-01-08 16:15:28,097 iteration 1846 : loss : 0.039851, loss_ce: 0.012608
2022-01-08 16:15:30,345 iteration 1847 : loss : 0.026244, loss_ce: 0.010601
2022-01-08 16:15:32,717 iteration 1848 : loss : 0.036988, loss_ce: 0.013812
2022-01-08 16:15:35,080 iteration 1849 : loss : 0.035629, loss_ce: 0.011910
2022-01-08 16:15:37,491 iteration 1850 : loss : 0.041260, loss_ce: 0.015118
2022-01-08 16:15:39,975 iteration 1851 : loss : 0.029488, loss_ce: 0.011975
2022-01-08 16:15:42,310 iteration 1852 : loss : 0.030806, loss_ce: 0.016385
2022-01-08 16:15:44,710 iteration 1853 : loss : 0.034345, loss_ce: 0.015530
 27%|███████▎                   | 109/400 [1:15:51<3:23:36, 41.98s/it]2022-01-08 16:15:47,165 iteration 1854 : loss : 0.041379, loss_ce: 0.013569
2022-01-08 16:15:49,587 iteration 1855 : loss : 0.038663, loss_ce: 0.014230
2022-01-08 16:15:51,984 iteration 1856 : loss : 0.033616, loss_ce: 0.014386
2022-01-08 16:15:54,319 iteration 1857 : loss : 0.024105, loss_ce: 0.011387
2022-01-08 16:15:56,647 iteration 1858 : loss : 0.021018, loss_ce: 0.009540
2022-01-08 16:15:59,039 iteration 1859 : loss : 0.032657, loss_ce: 0.012252
2022-01-08 16:16:01,555 iteration 1860 : loss : 0.056458, loss_ce: 0.022757
2022-01-08 16:16:03,952 iteration 1861 : loss : 0.029153, loss_ce: 0.013481
2022-01-08 16:16:06,411 iteration 1862 : loss : 0.024542, loss_ce: 0.011309
2022-01-08 16:16:08,844 iteration 1863 : loss : 0.046285, loss_ce: 0.018389
2022-01-08 16:16:11,231 iteration 1864 : loss : 0.027733, loss_ce: 0.009795
2022-01-08 16:16:13,549 iteration 1865 : loss : 0.047124, loss_ce: 0.016858
2022-01-08 16:16:16,098 iteration 1866 : loss : 0.025540, loss_ce: 0.010196
2022-01-08 16:16:18,418 iteration 1867 : loss : 0.026123, loss_ce: 0.008095
2022-01-08 16:16:20,788 iteration 1868 : loss : 0.033488, loss_ce: 0.010216
2022-01-08 16:16:23,172 iteration 1869 : loss : 0.032355, loss_ce: 0.014940
2022-01-08 16:16:23,172 Training Data Eval:
2022-01-08 16:16:36,004   Average segmentation loss on training set: 0.0292
2022-01-08 16:16:36,004 Validation Data Eval:
2022-01-08 16:16:40,505   Average segmentation loss on validation set: 0.1296
2022-01-08 16:16:42,916 iteration 1870 : loss : 0.035760, loss_ce: 0.014242
 28%|███████▍                   | 110/400 [1:16:49<3:46:28, 46.86s/it]2022-01-08 16:16:45,331 iteration 1871 : loss : 0.039412, loss_ce: 0.010386
2022-01-08 16:16:47,646 iteration 1872 : loss : 0.025281, loss_ce: 0.008212
2022-01-08 16:16:49,960 iteration 1873 : loss : 0.040721, loss_ce: 0.013254
2022-01-08 16:16:52,307 iteration 1874 : loss : 0.053892, loss_ce: 0.016616
2022-01-08 16:16:54,607 iteration 1875 : loss : 0.029996, loss_ce: 0.013574
2022-01-08 16:16:56,882 iteration 1876 : loss : 0.023897, loss_ce: 0.010627
2022-01-08 16:16:59,289 iteration 1877 : loss : 0.022649, loss_ce: 0.007361
2022-01-08 16:17:01,712 iteration 1878 : loss : 0.048136, loss_ce: 0.022985
2022-01-08 16:17:04,068 iteration 1879 : loss : 0.032308, loss_ce: 0.011034
2022-01-08 16:17:06,422 iteration 1880 : loss : 0.049334, loss_ce: 0.020013
2022-01-08 16:17:08,810 iteration 1881 : loss : 0.034254, loss_ce: 0.014135
2022-01-08 16:17:11,246 iteration 1882 : loss : 0.061648, loss_ce: 0.020839
2022-01-08 16:17:13,632 iteration 1883 : loss : 0.021781, loss_ce: 0.007006
2022-01-08 16:17:15,989 iteration 1884 : loss : 0.032559, loss_ce: 0.013396
2022-01-08 16:17:18,307 iteration 1885 : loss : 0.022047, loss_ce: 0.008576
2022-01-08 16:17:20,906 iteration 1886 : loss : 0.036622, loss_ce: 0.014330
2022-01-08 16:17:23,316 iteration 1887 : loss : 0.051684, loss_ce: 0.021403
 28%|███████▍                   | 111/400 [1:17:30<3:36:20, 44.92s/it]2022-01-08 16:17:25,776 iteration 1888 : loss : 0.048696, loss_ce: 0.014902
2022-01-08 16:17:28,036 iteration 1889 : loss : 0.043008, loss_ce: 0.014098
2022-01-08 16:17:30,327 iteration 1890 : loss : 0.033987, loss_ce: 0.016040
2022-01-08 16:17:32,660 iteration 1891 : loss : 0.027522, loss_ce: 0.009499
2022-01-08 16:17:35,095 iteration 1892 : loss : 0.031345, loss_ce: 0.013833
2022-01-08 16:17:37,573 iteration 1893 : loss : 0.030234, loss_ce: 0.008040
2022-01-08 16:17:39,997 iteration 1894 : loss : 0.060978, loss_ce: 0.027927
2022-01-08 16:17:42,316 iteration 1895 : loss : 0.025806, loss_ce: 0.011093
2022-01-08 16:17:44,783 iteration 1896 : loss : 0.032742, loss_ce: 0.013415
2022-01-08 16:17:47,192 iteration 1897 : loss : 0.050035, loss_ce: 0.017575
2022-01-08 16:17:49,620 iteration 1898 : loss : 0.031976, loss_ce: 0.013754
2022-01-08 16:17:51,996 iteration 1899 : loss : 0.036648, loss_ce: 0.013454
2022-01-08 16:17:54,335 iteration 1900 : loss : 0.038015, loss_ce: 0.015277
2022-01-08 16:17:56,678 iteration 1901 : loss : 0.027481, loss_ce: 0.009923
2022-01-08 16:17:59,155 iteration 1902 : loss : 0.032799, loss_ce: 0.013021
2022-01-08 16:18:01,631 iteration 1903 : loss : 0.034616, loss_ce: 0.013435
2022-01-08 16:18:04,100 iteration 1904 : loss : 0.034215, loss_ce: 0.015360
 28%|███████▌                   | 112/400 [1:18:10<3:29:39, 43.68s/it]2022-01-08 16:18:06,484 iteration 1905 : loss : 0.031138, loss_ce: 0.013231
2022-01-08 16:18:08,918 iteration 1906 : loss : 0.034590, loss_ce: 0.012613
2022-01-08 16:18:11,279 iteration 1907 : loss : 0.042069, loss_ce: 0.018051
2022-01-08 16:18:13,703 iteration 1908 : loss : 0.032543, loss_ce: 0.012374
2022-01-08 16:18:16,065 iteration 1909 : loss : 0.021999, loss_ce: 0.009531
2022-01-08 16:18:18,450 iteration 1910 : loss : 0.032614, loss_ce: 0.012066
2022-01-08 16:18:20,854 iteration 1911 : loss : 0.037379, loss_ce: 0.015420
2022-01-08 16:18:23,247 iteration 1912 : loss : 0.037552, loss_ce: 0.013224
2022-01-08 16:18:25,688 iteration 1913 : loss : 0.055557, loss_ce: 0.024649
2022-01-08 16:18:28,187 iteration 1914 : loss : 0.045446, loss_ce: 0.017709
2022-01-08 16:18:30,542 iteration 1915 : loss : 0.030599, loss_ce: 0.010570
2022-01-08 16:18:32,891 iteration 1916 : loss : 0.030133, loss_ce: 0.010189
2022-01-08 16:18:35,271 iteration 1917 : loss : 0.031573, loss_ce: 0.013147
2022-01-08 16:18:37,726 iteration 1918 : loss : 0.046173, loss_ce: 0.024300
2022-01-08 16:18:40,123 iteration 1919 : loss : 0.034655, loss_ce: 0.010864
2022-01-08 16:18:42,436 iteration 1920 : loss : 0.027852, loss_ce: 0.013437
2022-01-08 16:18:44,951 iteration 1921 : loss : 0.051215, loss_ce: 0.021212
 28%|███████▋                   | 113/400 [1:18:51<3:24:52, 42.83s/it]2022-01-08 16:18:47,414 iteration 1922 : loss : 0.042008, loss_ce: 0.016668
2022-01-08 16:18:49,707 iteration 1923 : loss : 0.029383, loss_ce: 0.011365
2022-01-08 16:18:52,154 iteration 1924 : loss : 0.048655, loss_ce: 0.016086
2022-01-08 16:18:54,455 iteration 1925 : loss : 0.038465, loss_ce: 0.012996
2022-01-08 16:18:56,846 iteration 1926 : loss : 0.031350, loss_ce: 0.011606
2022-01-08 16:18:59,342 iteration 1927 : loss : 0.033941, loss_ce: 0.015556
2022-01-08 16:19:01,732 iteration 1928 : loss : 0.046417, loss_ce: 0.014132
2022-01-08 16:19:04,237 iteration 1929 : loss : 0.045569, loss_ce: 0.024063
2022-01-08 16:19:06,544 iteration 1930 : loss : 0.033089, loss_ce: 0.015754
2022-01-08 16:19:08,871 iteration 1931 : loss : 0.037491, loss_ce: 0.012932
2022-01-08 16:19:11,225 iteration 1932 : loss : 0.060787, loss_ce: 0.014862
2022-01-08 16:19:13,601 iteration 1933 : loss : 0.040518, loss_ce: 0.013979
2022-01-08 16:19:15,987 iteration 1934 : loss : 0.056255, loss_ce: 0.015957
2022-01-08 16:19:18,361 iteration 1935 : loss : 0.036242, loss_ce: 0.013871
2022-01-08 16:19:20,672 iteration 1936 : loss : 0.030476, loss_ce: 0.012583
2022-01-08 16:19:22,978 iteration 1937 : loss : 0.040520, loss_ce: 0.016456
2022-01-08 16:19:25,397 iteration 1938 : loss : 0.035198, loss_ce: 0.013540
 28%|███████▋                   | 114/400 [1:19:32<3:20:45, 42.12s/it]2022-01-08 16:19:27,897 iteration 1939 : loss : 0.047448, loss_ce: 0.019440
2022-01-08 16:19:30,275 iteration 1940 : loss : 0.033607, loss_ce: 0.017420
2022-01-08 16:19:32,668 iteration 1941 : loss : 0.027525, loss_ce: 0.011570
2022-01-08 16:19:35,082 iteration 1942 : loss : 0.033659, loss_ce: 0.012041
2022-01-08 16:19:37,531 iteration 1943 : loss : 0.043393, loss_ce: 0.014898
2022-01-08 16:19:39,970 iteration 1944 : loss : 0.038166, loss_ce: 0.014476
2022-01-08 16:19:42,398 iteration 1945 : loss : 0.047803, loss_ce: 0.020880
2022-01-08 16:19:44,773 iteration 1946 : loss : 0.032442, loss_ce: 0.008075
2022-01-08 16:19:47,194 iteration 1947 : loss : 0.028613, loss_ce: 0.007128
2022-01-08 16:19:49,623 iteration 1948 : loss : 0.076519, loss_ce: 0.038381
2022-01-08 16:19:52,002 iteration 1949 : loss : 0.031783, loss_ce: 0.010907
2022-01-08 16:19:54,400 iteration 1950 : loss : 0.055068, loss_ce: 0.024924
2022-01-08 16:19:56,765 iteration 1951 : loss : 0.029286, loss_ce: 0.011434
2022-01-08 16:19:59,150 iteration 1952 : loss : 0.033471, loss_ce: 0.016752
2022-01-08 16:20:01,413 iteration 1953 : loss : 0.037624, loss_ce: 0.021382
2022-01-08 16:20:03,826 iteration 1954 : loss : 0.032352, loss_ce: 0.016881
2022-01-08 16:20:03,827 Training Data Eval:
2022-01-08 16:20:16,356   Average segmentation loss on training set: 0.0259
2022-01-08 16:20:16,356 Validation Data Eval:
2022-01-08 16:20:20,997   Average segmentation loss on validation set: 0.0939
2022-01-08 16:20:23,427 iteration 1955 : loss : 0.034918, loss_ce: 0.015873
 29%|███████▊                   | 115/400 [1:20:30<3:42:43, 46.89s/it]2022-01-08 16:20:25,824 iteration 1956 : loss : 0.050145, loss_ce: 0.019099
2022-01-08 16:20:28,184 iteration 1957 : loss : 0.042013, loss_ce: 0.020943
2022-01-08 16:20:30,470 iteration 1958 : loss : 0.064961, loss_ce: 0.018408
2022-01-08 16:20:32,790 iteration 1959 : loss : 0.045086, loss_ce: 0.013560
2022-01-08 16:20:35,130 iteration 1960 : loss : 0.030313, loss_ce: 0.011904
2022-01-08 16:20:37,441 iteration 1961 : loss : 0.026881, loss_ce: 0.010274
2022-01-08 16:20:39,845 iteration 1962 : loss : 0.030649, loss_ce: 0.011476
2022-01-08 16:20:42,190 iteration 1963 : loss : 0.030984, loss_ce: 0.010452
2022-01-08 16:20:44,618 iteration 1964 : loss : 0.053425, loss_ce: 0.016009
2022-01-08 16:20:46,959 iteration 1965 : loss : 0.027181, loss_ce: 0.012598
2022-01-08 16:20:49,339 iteration 1966 : loss : 0.027764, loss_ce: 0.012125
2022-01-08 16:20:51,851 iteration 1967 : loss : 0.032722, loss_ce: 0.012470
2022-01-08 16:20:54,411 iteration 1968 : loss : 0.059051, loss_ce: 0.025902
2022-01-08 16:20:56,851 iteration 1969 : loss : 0.059046, loss_ce: 0.023351
2022-01-08 16:20:59,186 iteration 1970 : loss : 0.026835, loss_ce: 0.011315
2022-01-08 16:21:01,591 iteration 1971 : loss : 0.030796, loss_ce: 0.010636
2022-01-08 16:21:03,912 iteration 1972 : loss : 0.033978, loss_ce: 0.010308
 29%|███████▊                   | 116/400 [1:21:10<3:32:51, 44.97s/it]2022-01-08 16:21:06,228 iteration 1973 : loss : 0.028745, loss_ce: 0.012359
2022-01-08 16:21:08,620 iteration 1974 : loss : 0.030777, loss_ce: 0.012471
2022-01-08 16:21:11,042 iteration 1975 : loss : 0.034150, loss_ce: 0.013442
2022-01-08 16:21:13,352 iteration 1976 : loss : 0.056404, loss_ce: 0.026838
2022-01-08 16:21:15,732 iteration 1977 : loss : 0.040999, loss_ce: 0.015635
2022-01-08 16:21:18,152 iteration 1978 : loss : 0.042168, loss_ce: 0.013091
2022-01-08 16:21:20,519 iteration 1979 : loss : 0.031571, loss_ce: 0.013708
2022-01-08 16:21:23,028 iteration 1980 : loss : 0.028749, loss_ce: 0.010599
2022-01-08 16:21:25,432 iteration 1981 : loss : 0.028965, loss_ce: 0.013384
2022-01-08 16:21:27,828 iteration 1982 : loss : 0.048610, loss_ce: 0.020206
2022-01-08 16:21:30,062 iteration 1983 : loss : 0.035226, loss_ce: 0.013917
2022-01-08 16:21:32,346 iteration 1984 : loss : 0.063726, loss_ce: 0.026009
2022-01-08 16:21:34,543 iteration 1985 : loss : 0.039729, loss_ce: 0.014797
2022-01-08 16:21:36,910 iteration 1986 : loss : 0.057125, loss_ce: 0.022038
2022-01-08 16:21:39,235 iteration 1987 : loss : 0.028552, loss_ce: 0.010041
2022-01-08 16:21:41,552 iteration 1988 : loss : 0.026475, loss_ce: 0.010335
2022-01-08 16:21:43,935 iteration 1989 : loss : 0.051383, loss_ce: 0.019067
 29%|███████▉                   | 117/400 [1:21:50<3:25:06, 43.48s/it]2022-01-08 16:21:46,426 iteration 1990 : loss : 0.037513, loss_ce: 0.009199
2022-01-08 16:21:48,742 iteration 1991 : loss : 0.026364, loss_ce: 0.010550
2022-01-08 16:21:51,096 iteration 1992 : loss : 0.030987, loss_ce: 0.010789
2022-01-08 16:21:53,559 iteration 1993 : loss : 0.043767, loss_ce: 0.016595
2022-01-08 16:21:56,017 iteration 1994 : loss : 0.040329, loss_ce: 0.016964
2022-01-08 16:21:58,345 iteration 1995 : loss : 0.037570, loss_ce: 0.016042
2022-01-08 16:22:00,662 iteration 1996 : loss : 0.036553, loss_ce: 0.015617
2022-01-08 16:22:02,914 iteration 1997 : loss : 0.029220, loss_ce: 0.012052
2022-01-08 16:22:05,237 iteration 1998 : loss : 0.030381, loss_ce: 0.012452
2022-01-08 16:22:07,569 iteration 1999 : loss : 0.037861, loss_ce: 0.014342
2022-01-08 16:22:09,845 iteration 2000 : loss : 0.033471, loss_ce: 0.016040
2022-01-08 16:22:12,223 iteration 2001 : loss : 0.037037, loss_ce: 0.012829
2022-01-08 16:22:14,615 iteration 2002 : loss : 0.035169, loss_ce: 0.014239
2022-01-08 16:22:16,865 iteration 2003 : loss : 0.044859, loss_ce: 0.015199
2022-01-08 16:22:19,178 iteration 2004 : loss : 0.034480, loss_ce: 0.014701
2022-01-08 16:22:21,463 iteration 2005 : loss : 0.033710, loss_ce: 0.015837
2022-01-08 16:22:23,876 iteration 2006 : loss : 0.035324, loss_ce: 0.011402
 30%|███████▉                   | 118/400 [1:22:30<3:19:22, 42.42s/it]2022-01-08 16:22:26,365 iteration 2007 : loss : 0.047162, loss_ce: 0.015111
2022-01-08 16:22:28,678 iteration 2008 : loss : 0.027635, loss_ce: 0.010913
2022-01-08 16:22:30,950 iteration 2009 : loss : 0.034201, loss_ce: 0.014772
2022-01-08 16:22:33,282 iteration 2010 : loss : 0.038141, loss_ce: 0.015511
2022-01-08 16:22:35,579 iteration 2011 : loss : 0.039168, loss_ce: 0.014468
2022-01-08 16:22:37,897 iteration 2012 : loss : 0.021984, loss_ce: 0.007898
2022-01-08 16:22:40,246 iteration 2013 : loss : 0.031282, loss_ce: 0.014673
2022-01-08 16:22:42,640 iteration 2014 : loss : 0.025165, loss_ce: 0.009839
2022-01-08 16:22:45,093 iteration 2015 : loss : 0.036864, loss_ce: 0.011078
2022-01-08 16:22:47,555 iteration 2016 : loss : 0.043062, loss_ce: 0.020038
2022-01-08 16:22:49,899 iteration 2017 : loss : 0.038008, loss_ce: 0.014092
2022-01-08 16:22:52,205 iteration 2018 : loss : 0.035479, loss_ce: 0.011106
2022-01-08 16:22:54,597 iteration 2019 : loss : 0.026375, loss_ce: 0.010236
2022-01-08 16:22:56,945 iteration 2020 : loss : 0.048851, loss_ce: 0.018604
2022-01-08 16:22:59,241 iteration 2021 : loss : 0.024026, loss_ce: 0.009239
2022-01-08 16:23:01,633 iteration 2022 : loss : 0.027894, loss_ce: 0.010084
2022-01-08 16:23:04,044 iteration 2023 : loss : 0.026416, loss_ce: 0.008576
 30%|████████                   | 119/400 [1:23:10<3:15:29, 41.74s/it]2022-01-08 16:23:06,442 iteration 2024 : loss : 0.061229, loss_ce: 0.033777
2022-01-08 16:23:08,910 iteration 2025 : loss : 0.045491, loss_ce: 0.013756
2022-01-08 16:23:11,260 iteration 2026 : loss : 0.040018, loss_ce: 0.011262
2022-01-08 16:23:13,647 iteration 2027 : loss : 0.029366, loss_ce: 0.008247
2022-01-08 16:23:15,864 iteration 2028 : loss : 0.023775, loss_ce: 0.010249
2022-01-08 16:23:18,256 iteration 2029 : loss : 0.036042, loss_ce: 0.011297
2022-01-08 16:23:20,660 iteration 2030 : loss : 0.049089, loss_ce: 0.017597
2022-01-08 16:23:22,991 iteration 2031 : loss : 0.038337, loss_ce: 0.014644
2022-01-08 16:23:25,285 iteration 2032 : loss : 0.045029, loss_ce: 0.020323
2022-01-08 16:23:27,504 iteration 2033 : loss : 0.023715, loss_ce: 0.010597
2022-01-08 16:23:29,976 iteration 2034 : loss : 0.033020, loss_ce: 0.011432
2022-01-08 16:23:32,390 iteration 2035 : loss : 0.035587, loss_ce: 0.013320
2022-01-08 16:23:34,674 iteration 2036 : loss : 0.042772, loss_ce: 0.016911
2022-01-08 16:23:37,052 iteration 2037 : loss : 0.026787, loss_ce: 0.010837
2022-01-08 16:23:39,508 iteration 2038 : loss : 0.084846, loss_ce: 0.027102
2022-01-08 16:23:41,897 iteration 2039 : loss : 0.036284, loss_ce: 0.013730
2022-01-08 16:23:41,898 Training Data Eval:
2022-01-08 16:23:54,409   Average segmentation loss on training set: 0.0228
2022-01-08 16:23:54,409 Validation Data Eval:
2022-01-08 16:23:58,909   Average segmentation loss on validation set: 0.0903
2022-01-08 16:24:01,363 iteration 2040 : loss : 0.035490, loss_ce: 0.016997
 30%|████████                   | 120/400 [1:24:08<3:36:36, 46.41s/it]2022-01-08 16:24:03,723 iteration 2041 : loss : 0.025669, loss_ce: 0.011406
2022-01-08 16:24:06,101 iteration 2042 : loss : 0.033673, loss_ce: 0.011625
2022-01-08 16:24:08,417 iteration 2043 : loss : 0.030866, loss_ce: 0.009405
2022-01-08 16:24:10,666 iteration 2044 : loss : 0.034592, loss_ce: 0.017504
2022-01-08 16:24:13,070 iteration 2045 : loss : 0.028962, loss_ce: 0.011270
2022-01-08 16:24:15,419 iteration 2046 : loss : 0.038250, loss_ce: 0.008957
2022-01-08 16:24:17,791 iteration 2047 : loss : 0.030829, loss_ce: 0.012344
2022-01-08 16:24:20,074 iteration 2048 : loss : 0.026966, loss_ce: 0.009778
2022-01-08 16:24:22,498 iteration 2049 : loss : 0.056140, loss_ce: 0.028819
2022-01-08 16:24:24,888 iteration 2050 : loss : 0.037378, loss_ce: 0.010904
2022-01-08 16:24:27,164 iteration 2051 : loss : 0.027555, loss_ce: 0.012089
2022-01-08 16:24:29,482 iteration 2052 : loss : 0.035564, loss_ce: 0.015682
2022-01-08 16:24:31,770 iteration 2053 : loss : 0.030773, loss_ce: 0.012996
2022-01-08 16:24:34,102 iteration 2054 : loss : 0.043562, loss_ce: 0.016732
2022-01-08 16:24:36,540 iteration 2055 : loss : 0.040101, loss_ce: 0.013064
2022-01-08 16:24:38,898 iteration 2056 : loss : 0.026512, loss_ce: 0.010101
2022-01-08 16:24:41,219 iteration 2057 : loss : 0.029968, loss_ce: 0.012346
 30%|████████▏                  | 121/400 [1:24:48<3:26:41, 44.45s/it]2022-01-08 16:24:43,587 iteration 2058 : loss : 0.032176, loss_ce: 0.016020
2022-01-08 16:24:45,927 iteration 2059 : loss : 0.042614, loss_ce: 0.015866
2022-01-08 16:24:48,245 iteration 2060 : loss : 0.035930, loss_ce: 0.013467
2022-01-08 16:24:50,512 iteration 2061 : loss : 0.033141, loss_ce: 0.015688
2022-01-08 16:24:52,766 iteration 2062 : loss : 0.035578, loss_ce: 0.014629
2022-01-08 16:24:55,217 iteration 2063 : loss : 0.058083, loss_ce: 0.029868
2022-01-08 16:24:57,537 iteration 2064 : loss : 0.033736, loss_ce: 0.012277
2022-01-08 16:24:59,968 iteration 2065 : loss : 0.043244, loss_ce: 0.015541
2022-01-08 16:25:02,277 iteration 2066 : loss : 0.031937, loss_ce: 0.012908
2022-01-08 16:25:04,627 iteration 2067 : loss : 0.039412, loss_ce: 0.015861
2022-01-08 16:25:06,858 iteration 2068 : loss : 0.024308, loss_ce: 0.008865
2022-01-08 16:25:09,181 iteration 2069 : loss : 0.029227, loss_ce: 0.014448
2022-01-08 16:25:11,578 iteration 2070 : loss : 0.034762, loss_ce: 0.017146
2022-01-08 16:25:13,959 iteration 2071 : loss : 0.021862, loss_ce: 0.008503
2022-01-08 16:25:16,267 iteration 2072 : loss : 0.029272, loss_ce: 0.013258
2022-01-08 16:25:18,646 iteration 2073 : loss : 0.041919, loss_ce: 0.020079
2022-01-08 16:25:20,933 iteration 2074 : loss : 0.026908, loss_ce: 0.007640
 30%|████████▏                  | 122/400 [1:25:27<3:19:22, 43.03s/it]2022-01-08 16:25:23,291 iteration 2075 : loss : 0.028582, loss_ce: 0.013375
2022-01-08 16:25:25,617 iteration 2076 : loss : 0.034197, loss_ce: 0.013724
2022-01-08 16:25:27,913 iteration 2077 : loss : 0.037780, loss_ce: 0.016791
2022-01-08 16:25:30,272 iteration 2078 : loss : 0.033884, loss_ce: 0.012524
2022-01-08 16:25:32,661 iteration 2079 : loss : 0.040258, loss_ce: 0.013974
2022-01-08 16:25:34,940 iteration 2080 : loss : 0.039578, loss_ce: 0.014221
2022-01-08 16:25:37,221 iteration 2081 : loss : 0.025994, loss_ce: 0.009085
2022-01-08 16:25:39,539 iteration 2082 : loss : 0.055235, loss_ce: 0.013074
2022-01-08 16:25:41,943 iteration 2083 : loss : 0.031271, loss_ce: 0.010213
2022-01-08 16:25:44,265 iteration 2084 : loss : 0.031006, loss_ce: 0.013732
2022-01-08 16:25:46,601 iteration 2085 : loss : 0.053084, loss_ce: 0.010314
2022-01-08 16:25:49,009 iteration 2086 : loss : 0.025382, loss_ce: 0.007724
2022-01-08 16:25:51,332 iteration 2087 : loss : 0.030634, loss_ce: 0.009795
2022-01-08 16:25:53,741 iteration 2088 : loss : 0.035954, loss_ce: 0.013625
2022-01-08 16:25:56,139 iteration 2089 : loss : 0.048356, loss_ce: 0.017079
2022-01-08 16:25:58,485 iteration 2090 : loss : 0.033935, loss_ce: 0.015097
2022-01-08 16:26:00,927 iteration 2091 : loss : 0.040880, loss_ce: 0.016662
 31%|████████▎                  | 123/400 [1:26:07<3:14:27, 42.12s/it]2022-01-08 16:26:03,308 iteration 2092 : loss : 0.026020, loss_ce: 0.008420
2022-01-08 16:26:05,664 iteration 2093 : loss : 0.019254, loss_ce: 0.007628
2022-01-08 16:26:08,080 iteration 2094 : loss : 0.027778, loss_ce: 0.010115
2022-01-08 16:26:10,624 iteration 2095 : loss : 0.041743, loss_ce: 0.016612
2022-01-08 16:26:12,994 iteration 2096 : loss : 0.026258, loss_ce: 0.010937
2022-01-08 16:26:15,329 iteration 2097 : loss : 0.049361, loss_ce: 0.014932
2022-01-08 16:26:17,622 iteration 2098 : loss : 0.031903, loss_ce: 0.011243
2022-01-08 16:26:20,064 iteration 2099 : loss : 0.023823, loss_ce: 0.009591
2022-01-08 16:26:22,500 iteration 2100 : loss : 0.049076, loss_ce: 0.015667
2022-01-08 16:26:24,828 iteration 2101 : loss : 0.030060, loss_ce: 0.008898
2022-01-08 16:26:27,229 iteration 2102 : loss : 0.040452, loss_ce: 0.016676
2022-01-08 16:26:29,587 iteration 2103 : loss : 0.026370, loss_ce: 0.013600
2022-01-08 16:26:32,087 iteration 2104 : loss : 0.026959, loss_ce: 0.009897
2022-01-08 16:26:34,484 iteration 2105 : loss : 0.038021, loss_ce: 0.014984
2022-01-08 16:26:36,911 iteration 2106 : loss : 0.042613, loss_ce: 0.014953
2022-01-08 16:26:39,317 iteration 2107 : loss : 0.031673, loss_ce: 0.011890
2022-01-08 16:26:41,669 iteration 2108 : loss : 0.032415, loss_ce: 0.012350
 31%|████████▎                  | 124/400 [1:26:48<3:11:50, 41.70s/it]2022-01-08 16:26:44,112 iteration 2109 : loss : 0.055986, loss_ce: 0.015758
2022-01-08 16:26:46,464 iteration 2110 : loss : 0.036066, loss_ce: 0.015204
2022-01-08 16:26:48,858 iteration 2111 : loss : 0.028241, loss_ce: 0.009924
2022-01-08 16:26:51,279 iteration 2112 : loss : 0.032686, loss_ce: 0.012993
2022-01-08 16:26:53,702 iteration 2113 : loss : 0.047434, loss_ce: 0.018372
2022-01-08 16:26:56,080 iteration 2114 : loss : 0.051181, loss_ce: 0.018286
2022-01-08 16:26:58,376 iteration 2115 : loss : 0.034686, loss_ce: 0.010678
2022-01-08 16:27:00,761 iteration 2116 : loss : 0.032063, loss_ce: 0.010416
2022-01-08 16:27:03,208 iteration 2117 : loss : 0.033779, loss_ce: 0.009565
2022-01-08 16:27:05,545 iteration 2118 : loss : 0.034006, loss_ce: 0.013628
2022-01-08 16:27:08,007 iteration 2119 : loss : 0.033589, loss_ce: 0.012944
2022-01-08 16:27:10,384 iteration 2120 : loss : 0.031411, loss_ce: 0.017326
2022-01-08 16:27:12,751 iteration 2121 : loss : 0.052430, loss_ce: 0.021559
2022-01-08 16:27:15,245 iteration 2122 : loss : 0.064480, loss_ce: 0.041392
2022-01-08 16:27:17,574 iteration 2123 : loss : 0.034525, loss_ce: 0.010615
2022-01-08 16:27:19,968 iteration 2124 : loss : 0.032819, loss_ce: 0.013758
2022-01-08 16:27:19,969 Training Data Eval:
2022-01-08 16:27:32,920   Average segmentation loss on training set: 0.0268
2022-01-08 16:27:32,920 Validation Data Eval:
2022-01-08 16:27:37,312   Average segmentation loss on validation set: 0.0592
2022-01-08 16:27:43,065 Found new lowest validation loss at iteration 2124! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed2.pth
2022-01-08 16:27:44,666 iteration 2125 : loss : 0.029499, loss_ce: 0.012985
 31%|████████▍                  | 125/400 [1:27:51<3:40:26, 48.10s/it]2022-01-08 16:27:46,377 iteration 2126 : loss : 0.067592, loss_ce: 0.019541
2022-01-08 16:27:48,046 iteration 2127 : loss : 0.025321, loss_ce: 0.010747
2022-01-08 16:27:49,889 iteration 2128 : loss : 0.028426, loss_ce: 0.011502
2022-01-08 16:27:51,998 iteration 2129 : loss : 0.043738, loss_ce: 0.018053
2022-01-08 16:27:54,142 iteration 2130 : loss : 0.036042, loss_ce: 0.013209
2022-01-08 16:27:56,340 iteration 2131 : loss : 0.027755, loss_ce: 0.009636
2022-01-08 16:27:58,561 iteration 2132 : loss : 0.037947, loss_ce: 0.011146
2022-01-08 16:28:00,790 iteration 2133 : loss : 0.032896, loss_ce: 0.013797
2022-01-08 16:28:03,086 iteration 2134 : loss : 0.042095, loss_ce: 0.014048
2022-01-08 16:28:05,332 iteration 2135 : loss : 0.034197, loss_ce: 0.010650
2022-01-08 16:28:07,745 iteration 2136 : loss : 0.028691, loss_ce: 0.011776
2022-01-08 16:28:10,056 iteration 2137 : loss : 0.033840, loss_ce: 0.013516
2022-01-08 16:28:12,432 iteration 2138 : loss : 0.028951, loss_ce: 0.008135
2022-01-08 16:28:14,755 iteration 2139 : loss : 0.037559, loss_ce: 0.020638
2022-01-08 16:28:17,162 iteration 2140 : loss : 0.035478, loss_ce: 0.022614
2022-01-08 16:28:19,606 iteration 2141 : loss : 0.028669, loss_ce: 0.009621
2022-01-08 16:28:22,039 iteration 2142 : loss : 0.064570, loss_ce: 0.021144
 32%|████████▌                  | 126/400 [1:28:28<3:24:55, 44.88s/it]2022-01-08 16:28:24,431 iteration 2143 : loss : 0.031045, loss_ce: 0.017770
2022-01-08 16:28:26,815 iteration 2144 : loss : 0.027693, loss_ce: 0.010624
2022-01-08 16:28:29,253 iteration 2145 : loss : 0.028836, loss_ce: 0.012103
2022-01-08 16:28:31,760 iteration 2146 : loss : 0.038886, loss_ce: 0.015719
2022-01-08 16:28:34,101 iteration 2147 : loss : 0.028457, loss_ce: 0.009524
2022-01-08 16:28:36,509 iteration 2148 : loss : 0.032592, loss_ce: 0.014401
2022-01-08 16:28:38,927 iteration 2149 : loss : 0.041155, loss_ce: 0.015671
2022-01-08 16:28:41,235 iteration 2150 : loss : 0.023010, loss_ce: 0.009251
2022-01-08 16:28:43,626 iteration 2151 : loss : 0.025533, loss_ce: 0.009008
2022-01-08 16:28:46,021 iteration 2152 : loss : 0.030009, loss_ce: 0.014183
2022-01-08 16:28:48,441 iteration 2153 : loss : 0.040279, loss_ce: 0.013561
2022-01-08 16:28:50,829 iteration 2154 : loss : 0.027226, loss_ce: 0.009703
2022-01-08 16:28:53,157 iteration 2155 : loss : 0.035135, loss_ce: 0.017528
2022-01-08 16:28:55,467 iteration 2156 : loss : 0.029834, loss_ce: 0.011450
2022-01-08 16:28:57,939 iteration 2157 : loss : 0.039876, loss_ce: 0.016440
2022-01-08 16:29:00,419 iteration 2158 : loss : 0.031837, loss_ce: 0.009279
2022-01-08 16:29:02,846 iteration 2159 : loss : 0.031294, loss_ce: 0.011441
 32%|████████▌                  | 127/400 [1:29:09<3:18:36, 43.65s/it]2022-01-08 16:29:05,305 iteration 2160 : loss : 0.030777, loss_ce: 0.011722
2022-01-08 16:29:07,790 iteration 2161 : loss : 0.042638, loss_ce: 0.022837
2022-01-08 16:29:10,245 iteration 2162 : loss : 0.032657, loss_ce: 0.012831
2022-01-08 16:29:12,661 iteration 2163 : loss : 0.034114, loss_ce: 0.011531
2022-01-08 16:29:15,109 iteration 2164 : loss : 0.035423, loss_ce: 0.012976
2022-01-08 16:29:17,617 iteration 2165 : loss : 0.023036, loss_ce: 0.009566
2022-01-08 16:29:20,035 iteration 2166 : loss : 0.029401, loss_ce: 0.007120
2022-01-08 16:29:22,623 iteration 2167 : loss : 0.018846, loss_ce: 0.005799
2022-01-08 16:29:25,072 iteration 2168 : loss : 0.022246, loss_ce: 0.008225
2022-01-08 16:29:27,485 iteration 2169 : loss : 0.029208, loss_ce: 0.011689
2022-01-08 16:29:29,863 iteration 2170 : loss : 0.052773, loss_ce: 0.025448
2022-01-08 16:29:32,263 iteration 2171 : loss : 0.047903, loss_ce: 0.015496
2022-01-08 16:29:34,653 iteration 2172 : loss : 0.030733, loss_ce: 0.009277
2022-01-08 16:29:36,941 iteration 2173 : loss : 0.034179, loss_ce: 0.010703
2022-01-08 16:29:39,288 iteration 2174 : loss : 0.024946, loss_ce: 0.011923
2022-01-08 16:29:41,730 iteration 2175 : loss : 0.024583, loss_ce: 0.008258
2022-01-08 16:29:44,242 iteration 2176 : loss : 0.037903, loss_ce: 0.014707
 32%|████████▋                  | 128/400 [1:29:51<3:14:50, 42.98s/it]2022-01-08 16:29:46,734 iteration 2177 : loss : 0.030248, loss_ce: 0.009665
2022-01-08 16:29:49,197 iteration 2178 : loss : 0.039710, loss_ce: 0.016396
2022-01-08 16:29:51,588 iteration 2179 : loss : 0.047895, loss_ce: 0.024455
2022-01-08 16:29:54,030 iteration 2180 : loss : 0.025588, loss_ce: 0.010169
2022-01-08 16:29:56,467 iteration 2181 : loss : 0.040936, loss_ce: 0.020933
2022-01-08 16:29:58,816 iteration 2182 : loss : 0.050196, loss_ce: 0.011695
2022-01-08 16:30:01,283 iteration 2183 : loss : 0.027834, loss_ce: 0.012565
2022-01-08 16:30:03,748 iteration 2184 : loss : 0.029878, loss_ce: 0.008735
2022-01-08 16:30:06,115 iteration 2185 : loss : 0.034995, loss_ce: 0.013992
2022-01-08 16:30:08,507 iteration 2186 : loss : 0.051110, loss_ce: 0.019644
2022-01-08 16:30:11,045 iteration 2187 : loss : 0.030575, loss_ce: 0.011591
2022-01-08 16:30:13,446 iteration 2188 : loss : 0.038756, loss_ce: 0.009495
2022-01-08 16:30:15,900 iteration 2189 : loss : 0.037121, loss_ce: 0.013256
2022-01-08 16:30:18,238 iteration 2190 : loss : 0.032217, loss_ce: 0.010649
2022-01-08 16:30:20,532 iteration 2191 : loss : 0.084789, loss_ce: 0.023230
2022-01-08 16:30:22,746 iteration 2192 : loss : 0.026585, loss_ce: 0.008890
2022-01-08 16:30:25,065 iteration 2193 : loss : 0.037954, loss_ce: 0.014740
 32%|████████▋                  | 129/400 [1:30:31<3:11:11, 42.33s/it]2022-01-08 16:30:27,480 iteration 2194 : loss : 0.044859, loss_ce: 0.024365
2022-01-08 16:30:29,924 iteration 2195 : loss : 0.036274, loss_ce: 0.012128
2022-01-08 16:30:32,345 iteration 2196 : loss : 0.034676, loss_ce: 0.012518
2022-01-08 16:30:34,736 iteration 2197 : loss : 0.040716, loss_ce: 0.019731
2022-01-08 16:30:37,159 iteration 2198 : loss : 0.027094, loss_ce: 0.012169
2022-01-08 16:30:39,631 iteration 2199 : loss : 0.035445, loss_ce: 0.015551
2022-01-08 16:30:42,069 iteration 2200 : loss : 0.037874, loss_ce: 0.013096
2022-01-08 16:30:44,422 iteration 2201 : loss : 0.024214, loss_ce: 0.008917
2022-01-08 16:30:46,870 iteration 2202 : loss : 0.095955, loss_ce: 0.024598
2022-01-08 16:30:49,329 iteration 2203 : loss : 0.028160, loss_ce: 0.013477
2022-01-08 16:30:51,724 iteration 2204 : loss : 0.024246, loss_ce: 0.010472
2022-01-08 16:30:54,260 iteration 2205 : loss : 0.022212, loss_ce: 0.009211
2022-01-08 16:30:56,595 iteration 2206 : loss : 0.032821, loss_ce: 0.008885
2022-01-08 16:30:58,937 iteration 2207 : loss : 0.029619, loss_ce: 0.009567
2022-01-08 16:31:01,403 iteration 2208 : loss : 0.031283, loss_ce: 0.009181
2022-01-08 16:31:03,854 iteration 2209 : loss : 0.037797, loss_ce: 0.016849
2022-01-08 16:31:03,855 Training Data Eval:
2022-01-08 16:31:16,913   Average segmentation loss on training set: 0.0459
2022-01-08 16:31:16,913 Validation Data Eval:
2022-01-08 16:31:21,481   Average segmentation loss on validation set: 0.2263
2022-01-08 16:31:23,907 iteration 2210 : loss : 0.042646, loss_ce: 0.015706
 32%|████████▊                  | 130/400 [1:31:30<3:32:46, 47.28s/it]2022-01-08 16:31:26,391 iteration 2211 : loss : 0.045932, loss_ce: 0.019532
2022-01-08 16:31:28,834 iteration 2212 : loss : 0.048044, loss_ce: 0.020613
2022-01-08 16:31:31,272 iteration 2213 : loss : 0.035129, loss_ce: 0.013839
2022-01-08 16:31:33,731 iteration 2214 : loss : 0.028630, loss_ce: 0.009806
2022-01-08 16:31:36,182 iteration 2215 : loss : 0.058550, loss_ce: 0.028553
2022-01-08 16:31:38,576 iteration 2216 : loss : 0.029030, loss_ce: 0.009249
2022-01-08 16:31:41,034 iteration 2217 : loss : 0.045407, loss_ce: 0.017945
2022-01-08 16:31:43,445 iteration 2218 : loss : 0.029876, loss_ce: 0.011849
2022-01-08 16:31:45,887 iteration 2219 : loss : 0.038955, loss_ce: 0.016983
2022-01-08 16:31:48,181 iteration 2220 : loss : 0.038892, loss_ce: 0.011846
2022-01-08 16:31:50,700 iteration 2221 : loss : 0.034020, loss_ce: 0.010618
2022-01-08 16:31:53,134 iteration 2222 : loss : 0.032489, loss_ce: 0.013819
2022-01-08 16:31:55,546 iteration 2223 : loss : 0.034192, loss_ce: 0.010539
2022-01-08 16:31:58,027 iteration 2224 : loss : 0.041071, loss_ce: 0.020545
2022-01-08 16:32:00,439 iteration 2225 : loss : 0.022183, loss_ce: 0.007805
2022-01-08 16:32:02,923 iteration 2226 : loss : 0.041534, loss_ce: 0.017127
2022-01-08 16:32:05,341 iteration 2227 : loss : 0.032529, loss_ce: 0.015172
 33%|████████▊                  | 131/400 [1:32:12<3:24:07, 45.53s/it]2022-01-08 16:32:07,898 iteration 2228 : loss : 0.023280, loss_ce: 0.010935
2022-01-08 16:32:10,338 iteration 2229 : loss : 0.039518, loss_ce: 0.015878
2022-01-08 16:32:12,788 iteration 2230 : loss : 0.030801, loss_ce: 0.010697
2022-01-08 16:32:15,071 iteration 2231 : loss : 0.018748, loss_ce: 0.007867
2022-01-08 16:32:17,415 iteration 2232 : loss : 0.031892, loss_ce: 0.013378
2022-01-08 16:32:19,785 iteration 2233 : loss : 0.032578, loss_ce: 0.012982
2022-01-08 16:32:22,191 iteration 2234 : loss : 0.028016, loss_ce: 0.010910
2022-01-08 16:32:24,550 iteration 2235 : loss : 0.042477, loss_ce: 0.009534
2022-01-08 16:32:26,989 iteration 2236 : loss : 0.059459, loss_ce: 0.026866
2022-01-08 16:32:29,400 iteration 2237 : loss : 0.022607, loss_ce: 0.009740
2022-01-08 16:32:31,841 iteration 2238 : loss : 0.043214, loss_ce: 0.023810
2022-01-08 16:32:34,258 iteration 2239 : loss : 0.032309, loss_ce: 0.011831
2022-01-08 16:32:36,705 iteration 2240 : loss : 0.033681, loss_ce: 0.012675
2022-01-08 16:32:39,092 iteration 2241 : loss : 0.031800, loss_ce: 0.009518
2022-01-08 16:32:41,522 iteration 2242 : loss : 0.032733, loss_ce: 0.012061
2022-01-08 16:32:43,994 iteration 2243 : loss : 0.045536, loss_ce: 0.015111
2022-01-08 16:32:46,324 iteration 2244 : loss : 0.033035, loss_ce: 0.014398
 33%|████████▉                  | 132/400 [1:32:53<3:17:15, 44.16s/it]2022-01-08 16:32:48,855 iteration 2245 : loss : 0.051982, loss_ce: 0.017818
2022-01-08 16:32:51,183 iteration 2246 : loss : 0.028878, loss_ce: 0.010862
2022-01-08 16:32:53,564 iteration 2247 : loss : 0.045202, loss_ce: 0.011611
2022-01-08 16:32:55,917 iteration 2248 : loss : 0.031507, loss_ce: 0.012463
2022-01-08 16:32:58,377 iteration 2249 : loss : 0.036767, loss_ce: 0.011860
2022-01-08 16:33:00,768 iteration 2250 : loss : 0.035483, loss_ce: 0.016494
2022-01-08 16:33:03,126 iteration 2251 : loss : 0.028762, loss_ce: 0.009027
2022-01-08 16:33:05,627 iteration 2252 : loss : 0.070209, loss_ce: 0.026965
2022-01-08 16:33:08,074 iteration 2253 : loss : 0.034771, loss_ce: 0.012695
2022-01-08 16:33:10,387 iteration 2254 : loss : 0.034723, loss_ce: 0.016112
2022-01-08 16:33:12,762 iteration 2255 : loss : 0.030672, loss_ce: 0.009755
2022-01-08 16:33:15,179 iteration 2256 : loss : 0.025175, loss_ce: 0.009158
2022-01-08 16:33:17,668 iteration 2257 : loss : 0.027365, loss_ce: 0.010435
2022-01-08 16:33:20,164 iteration 2258 : loss : 0.024645, loss_ce: 0.010611
2022-01-08 16:33:22,605 iteration 2259 : loss : 0.029260, loss_ce: 0.011681
2022-01-08 16:33:24,900 iteration 2260 : loss : 0.032087, loss_ce: 0.012411
2022-01-08 16:33:27,287 iteration 2261 : loss : 0.034676, loss_ce: 0.014273
 33%|████████▉                  | 133/400 [1:33:34<3:12:15, 43.20s/it]2022-01-08 16:33:29,768 iteration 2262 : loss : 0.030543, loss_ce: 0.012825
2022-01-08 16:33:32,169 iteration 2263 : loss : 0.027131, loss_ce: 0.011532
2022-01-08 16:33:34,533 iteration 2264 : loss : 0.035099, loss_ce: 0.013842
2022-01-08 16:33:36,859 iteration 2265 : loss : 0.023871, loss_ce: 0.008464
2022-01-08 16:33:39,298 iteration 2266 : loss : 0.022961, loss_ce: 0.006425
2022-01-08 16:33:41,642 iteration 2267 : loss : 0.020921, loss_ce: 0.008287
2022-01-08 16:33:44,003 iteration 2268 : loss : 0.025746, loss_ce: 0.011750
2022-01-08 16:33:46,384 iteration 2269 : loss : 0.031348, loss_ce: 0.014875
2022-01-08 16:33:48,710 iteration 2270 : loss : 0.022034, loss_ce: 0.008028
2022-01-08 16:33:51,049 iteration 2271 : loss : 0.040322, loss_ce: 0.015262
2022-01-08 16:33:53,406 iteration 2272 : loss : 0.028530, loss_ce: 0.011323
2022-01-08 16:33:55,842 iteration 2273 : loss : 0.027541, loss_ce: 0.009396
2022-01-08 16:33:58,148 iteration 2274 : loss : 0.034343, loss_ce: 0.012646
2022-01-08 16:34:00,436 iteration 2275 : loss : 0.042996, loss_ce: 0.012666
2022-01-08 16:34:02,753 iteration 2276 : loss : 0.038922, loss_ce: 0.019229
2022-01-08 16:34:05,118 iteration 2277 : loss : 0.022663, loss_ce: 0.006249
2022-01-08 16:34:07,569 iteration 2278 : loss : 0.081464, loss_ce: 0.045101
 34%|█████████                  | 134/400 [1:34:14<3:07:39, 42.33s/it]2022-01-08 16:34:10,026 iteration 2279 : loss : 0.023599, loss_ce: 0.008493
2022-01-08 16:34:12,435 iteration 2280 : loss : 0.029286, loss_ce: 0.013110
2022-01-08 16:34:14,878 iteration 2281 : loss : 0.044794, loss_ce: 0.015590
2022-01-08 16:34:17,198 iteration 2282 : loss : 0.035434, loss_ce: 0.011892
2022-01-08 16:34:19,669 iteration 2283 : loss : 0.033157, loss_ce: 0.008737
2022-01-08 16:34:22,024 iteration 2284 : loss : 0.031071, loss_ce: 0.016437
2022-01-08 16:34:24,477 iteration 2285 : loss : 0.064408, loss_ce: 0.035162
2022-01-08 16:34:26,848 iteration 2286 : loss : 0.046597, loss_ce: 0.023930
2022-01-08 16:34:29,191 iteration 2287 : loss : 0.027245, loss_ce: 0.008018
2022-01-08 16:34:31,530 iteration 2288 : loss : 0.044876, loss_ce: 0.011937
2022-01-08 16:34:33,867 iteration 2289 : loss : 0.031336, loss_ce: 0.008932
2022-01-08 16:34:36,226 iteration 2290 : loss : 0.034766, loss_ce: 0.013062
2022-01-08 16:34:38,717 iteration 2291 : loss : 0.040083, loss_ce: 0.015746
2022-01-08 16:34:41,108 iteration 2292 : loss : 0.038151, loss_ce: 0.015784
2022-01-08 16:34:43,573 iteration 2293 : loss : 0.060172, loss_ce: 0.026020
2022-01-08 16:34:45,969 iteration 2294 : loss : 0.029600, loss_ce: 0.014776
2022-01-08 16:34:45,969 Training Data Eval:
2022-01-08 16:34:58,668   Average segmentation loss on training set: 0.0276
2022-01-08 16:34:58,668 Validation Data Eval:
2022-01-08 16:35:03,257   Average segmentation loss on validation set: 0.0733
2022-01-08 16:35:05,675 iteration 2295 : loss : 0.038028, loss_ce: 0.013067
 34%|█████████                  | 135/400 [1:35:12<3:27:50, 47.06s/it]2022-01-08 16:35:08,205 iteration 2296 : loss : 0.027558, loss_ce: 0.010597
2022-01-08 16:35:10,632 iteration 2297 : loss : 0.023861, loss_ce: 0.008968
2022-01-08 16:35:13,008 iteration 2298 : loss : 0.031326, loss_ce: 0.010637
2022-01-08 16:35:15,408 iteration 2299 : loss : 0.043577, loss_ce: 0.013795
2022-01-08 16:35:17,769 iteration 2300 : loss : 0.025421, loss_ce: 0.011108
2022-01-08 16:35:20,251 iteration 2301 : loss : 0.035341, loss_ce: 0.012855
2022-01-08 16:35:22,731 iteration 2302 : loss : 0.040245, loss_ce: 0.014702
2022-01-08 16:35:25,160 iteration 2303 : loss : 0.051427, loss_ce: 0.016166
2022-01-08 16:35:27,541 iteration 2304 : loss : 0.029451, loss_ce: 0.011114
2022-01-08 16:35:29,876 iteration 2305 : loss : 0.032228, loss_ce: 0.013545
2022-01-08 16:35:32,399 iteration 2306 : loss : 0.029423, loss_ce: 0.011091
2022-01-08 16:35:34,868 iteration 2307 : loss : 0.038693, loss_ce: 0.018031
2022-01-08 16:35:37,301 iteration 2308 : loss : 0.035790, loss_ce: 0.013578
2022-01-08 16:35:39,743 iteration 2309 : loss : 0.039575, loss_ce: 0.015804
2022-01-08 16:35:42,122 iteration 2310 : loss : 0.044002, loss_ce: 0.018135
2022-01-08 16:35:44,415 iteration 2311 : loss : 0.028750, loss_ce: 0.011346
2022-01-08 16:35:46,920 iteration 2312 : loss : 0.021687, loss_ce: 0.008471
 34%|█████████▏                 | 136/400 [1:35:53<3:19:24, 45.32s/it]2022-01-08 16:35:49,353 iteration 2313 : loss : 0.032408, loss_ce: 0.011917
2022-01-08 16:35:51,807 iteration 2314 : loss : 0.030161, loss_ce: 0.009862
2022-01-08 16:35:54,298 iteration 2315 : loss : 0.055352, loss_ce: 0.019282
2022-01-08 16:35:56,578 iteration 2316 : loss : 0.028577, loss_ce: 0.010476
2022-01-08 16:35:58,928 iteration 2317 : loss : 0.040843, loss_ce: 0.010667
2022-01-08 16:36:01,280 iteration 2318 : loss : 0.036633, loss_ce: 0.019337
2022-01-08 16:36:03,624 iteration 2319 : loss : 0.027682, loss_ce: 0.010444
2022-01-08 16:36:06,108 iteration 2320 : loss : 0.025679, loss_ce: 0.010931
2022-01-08 16:36:08,458 iteration 2321 : loss : 0.034009, loss_ce: 0.011007
2022-01-08 16:36:10,841 iteration 2322 : loss : 0.035164, loss_ce: 0.016725
2022-01-08 16:36:13,261 iteration 2323 : loss : 0.031613, loss_ce: 0.014801
2022-01-08 16:36:15,652 iteration 2324 : loss : 0.030429, loss_ce: 0.010250
2022-01-08 16:36:18,022 iteration 2325 : loss : 0.026766, loss_ce: 0.011439
2022-01-08 16:36:20,417 iteration 2326 : loss : 0.035034, loss_ce: 0.017063
2022-01-08 16:36:22,793 iteration 2327 : loss : 0.028878, loss_ce: 0.012928
2022-01-08 16:36:25,210 iteration 2328 : loss : 0.043651, loss_ce: 0.020775
2022-01-08 16:36:27,589 iteration 2329 : loss : 0.023439, loss_ce: 0.009258
 34%|█████████▏                 | 137/400 [1:36:34<3:12:31, 43.92s/it]2022-01-08 16:36:30,041 iteration 2330 : loss : 0.031678, loss_ce: 0.011512
2022-01-08 16:36:32,428 iteration 2331 : loss : 0.045743, loss_ce: 0.023123
2022-01-08 16:36:34,874 iteration 2332 : loss : 0.042903, loss_ce: 0.016608
2022-01-08 16:36:37,338 iteration 2333 : loss : 0.032312, loss_ce: 0.015770
2022-01-08 16:36:39,754 iteration 2334 : loss : 0.027536, loss_ce: 0.012379
2022-01-08 16:36:42,143 iteration 2335 : loss : 0.030975, loss_ce: 0.008760
2022-01-08 16:36:44,554 iteration 2336 : loss : 0.044517, loss_ce: 0.011665
2022-01-08 16:36:46,963 iteration 2337 : loss : 0.029515, loss_ce: 0.013474
2022-01-08 16:36:49,336 iteration 2338 : loss : 0.024936, loss_ce: 0.009750
2022-01-08 16:36:51,736 iteration 2339 : loss : 0.028187, loss_ce: 0.009985
2022-01-08 16:36:54,192 iteration 2340 : loss : 0.041591, loss_ce: 0.019042
2022-01-08 16:36:56,488 iteration 2341 : loss : 0.020325, loss_ce: 0.005433
2022-01-08 16:36:58,921 iteration 2342 : loss : 0.022732, loss_ce: 0.009124
2022-01-08 16:37:01,379 iteration 2343 : loss : 0.041243, loss_ce: 0.014495
2022-01-08 16:37:03,800 iteration 2344 : loss : 0.026574, loss_ce: 0.011087
2022-01-08 16:37:06,249 iteration 2345 : loss : 0.023277, loss_ce: 0.008014
2022-01-08 16:37:08,577 iteration 2346 : loss : 0.028300, loss_ce: 0.012600
 34%|█████████▎                 | 138/400 [1:37:15<3:07:57, 43.04s/it]2022-01-08 16:37:11,042 iteration 2347 : loss : 0.024545, loss_ce: 0.008435
2022-01-08 16:37:13,379 iteration 2348 : loss : 0.031382, loss_ce: 0.010349
2022-01-08 16:37:15,701 iteration 2349 : loss : 0.029791, loss_ce: 0.012223
2022-01-08 16:37:17,932 iteration 2350 : loss : 0.035525, loss_ce: 0.012840
2022-01-08 16:37:20,342 iteration 2351 : loss : 0.081439, loss_ce: 0.014583
2022-01-08 16:37:22,709 iteration 2352 : loss : 0.029612, loss_ce: 0.008952
2022-01-08 16:37:25,145 iteration 2353 : loss : 0.026038, loss_ce: 0.010160
2022-01-08 16:37:27,555 iteration 2354 : loss : 0.024968, loss_ce: 0.010944
2022-01-08 16:37:29,812 iteration 2355 : loss : 0.025571, loss_ce: 0.009681
2022-01-08 16:37:32,182 iteration 2356 : loss : 0.027246, loss_ce: 0.011036
2022-01-08 16:37:34,635 iteration 2357 : loss : 0.039926, loss_ce: 0.012849
2022-01-08 16:37:37,258 iteration 2358 : loss : 0.029840, loss_ce: 0.012961
2022-01-08 16:37:39,787 iteration 2359 : loss : 0.037057, loss_ce: 0.014091
2022-01-08 16:37:42,134 iteration 2360 : loss : 0.030139, loss_ce: 0.012419
2022-01-08 16:37:44,564 iteration 2361 : loss : 0.035370, loss_ce: 0.013347
2022-01-08 16:37:46,971 iteration 2362 : loss : 0.054537, loss_ce: 0.024612
2022-01-08 16:37:49,228 iteration 2363 : loss : 0.027385, loss_ce: 0.012606
 35%|█████████▍                 | 139/400 [1:37:56<3:04:07, 42.33s/it]2022-01-08 16:37:51,603 iteration 2364 : loss : 0.072974, loss_ce: 0.015865
2022-01-08 16:37:53,939 iteration 2365 : loss : 0.044048, loss_ce: 0.013254
2022-01-08 16:37:56,328 iteration 2366 : loss : 0.036773, loss_ce: 0.013928
2022-01-08 16:37:58,871 iteration 2367 : loss : 0.060868, loss_ce: 0.032978
2022-01-08 16:38:01,301 iteration 2368 : loss : 0.032248, loss_ce: 0.013435
2022-01-08 16:38:03,691 iteration 2369 : loss : 0.037492, loss_ce: 0.014007
2022-01-08 16:38:05,994 iteration 2370 : loss : 0.033244, loss_ce: 0.011182
2022-01-08 16:38:08,359 iteration 2371 : loss : 0.042297, loss_ce: 0.016745
2022-01-08 16:38:10,701 iteration 2372 : loss : 0.043756, loss_ce: 0.016315
2022-01-08 16:38:13,078 iteration 2373 : loss : 0.047403, loss_ce: 0.017476
2022-01-08 16:38:15,444 iteration 2374 : loss : 0.032315, loss_ce: 0.011589
2022-01-08 16:38:17,873 iteration 2375 : loss : 0.035107, loss_ce: 0.011613
2022-01-08 16:38:20,312 iteration 2376 : loss : 0.027119, loss_ce: 0.009253
2022-01-08 16:38:22,662 iteration 2377 : loss : 0.034729, loss_ce: 0.012347
2022-01-08 16:38:25,009 iteration 2378 : loss : 0.025559, loss_ce: 0.009483
2022-01-08 16:38:27,407 iteration 2379 : loss : 0.046783, loss_ce: 0.023595
2022-01-08 16:38:27,407 Training Data Eval:
2022-01-08 16:38:40,325   Average segmentation loss on training set: 0.0291
2022-01-08 16:38:40,326 Validation Data Eval:
2022-01-08 16:38:44,716   Average segmentation loss on validation set: 0.1017
2022-01-08 16:38:47,090 iteration 2380 : loss : 0.028627, loss_ce: 0.014942
 35%|█████████▍                 | 140/400 [1:38:53<3:23:37, 46.99s/it]2022-01-08 16:38:49,623 iteration 2381 : loss : 0.052196, loss_ce: 0.016746
2022-01-08 16:38:52,028 iteration 2382 : loss : 0.038401, loss_ce: 0.014450
2022-01-08 16:38:54,410 iteration 2383 : loss : 0.041940, loss_ce: 0.015045
2022-01-08 16:38:56,821 iteration 2384 : loss : 0.027605, loss_ce: 0.009750
2022-01-08 16:38:59,221 iteration 2385 : loss : 0.028699, loss_ce: 0.009341
2022-01-08 16:39:01,660 iteration 2386 : loss : 0.033921, loss_ce: 0.008687
2022-01-08 16:39:04,030 iteration 2387 : loss : 0.026601, loss_ce: 0.009261
2022-01-08 16:39:06,367 iteration 2388 : loss : 0.041717, loss_ce: 0.020012
2022-01-08 16:39:08,726 iteration 2389 : loss : 0.031215, loss_ce: 0.010277
2022-01-08 16:39:11,026 iteration 2390 : loss : 0.034332, loss_ce: 0.013623
2022-01-08 16:39:13,354 iteration 2391 : loss : 0.025440, loss_ce: 0.009478
2022-01-08 16:39:15,888 iteration 2392 : loss : 0.035471, loss_ce: 0.008427
2022-01-08 16:39:18,265 iteration 2393 : loss : 0.043690, loss_ce: 0.021352
2022-01-08 16:39:20,627 iteration 2394 : loss : 0.038025, loss_ce: 0.015782
2022-01-08 16:39:23,086 iteration 2395 : loss : 0.033506, loss_ce: 0.014376
2022-01-08 16:39:25,389 iteration 2396 : loss : 0.027539, loss_ce: 0.011237
2022-01-08 16:39:27,840 iteration 2397 : loss : 0.041525, loss_ce: 0.022961
 35%|█████████▌                 | 141/400 [1:39:34<3:14:45, 45.12s/it]2022-01-08 16:39:30,231 iteration 2398 : loss : 0.031467, loss_ce: 0.014802
2022-01-08 16:39:32,694 iteration 2399 : loss : 0.026101, loss_ce: 0.011153
2022-01-08 16:39:35,038 iteration 2400 : loss : 0.037440, loss_ce: 0.016127
2022-01-08 16:39:37,441 iteration 2401 : loss : 0.053284, loss_ce: 0.017910
2022-01-08 16:39:39,768 iteration 2402 : loss : 0.037549, loss_ce: 0.016487
2022-01-08 16:39:42,148 iteration 2403 : loss : 0.032014, loss_ce: 0.011916
2022-01-08 16:39:44,462 iteration 2404 : loss : 0.022732, loss_ce: 0.007784
2022-01-08 16:39:46,911 iteration 2405 : loss : 0.030995, loss_ce: 0.011253
2022-01-08 16:39:49,243 iteration 2406 : loss : 0.033938, loss_ce: 0.014126
2022-01-08 16:39:51,654 iteration 2407 : loss : 0.031408, loss_ce: 0.011300
2022-01-08 16:39:54,152 iteration 2408 : loss : 0.042747, loss_ce: 0.015567
2022-01-08 16:39:56,469 iteration 2409 : loss : 0.026894, loss_ce: 0.011803
2022-01-08 16:39:58,813 iteration 2410 : loss : 0.022387, loss_ce: 0.007685
2022-01-08 16:40:01,202 iteration 2411 : loss : 0.026125, loss_ce: 0.010913
2022-01-08 16:40:03,556 iteration 2412 : loss : 0.025606, loss_ce: 0.008852
2022-01-08 16:40:05,982 iteration 2413 : loss : 0.028538, loss_ce: 0.010725
2022-01-08 16:40:08,352 iteration 2414 : loss : 0.025864, loss_ce: 0.010546
 36%|█████████▌                 | 142/400 [1:40:15<3:08:02, 43.73s/it]2022-01-08 16:40:11,031 iteration 2415 : loss : 0.024784, loss_ce: 0.007998
2022-01-08 16:40:13,472 iteration 2416 : loss : 0.031602, loss_ce: 0.014145
2022-01-08 16:40:15,870 iteration 2417 : loss : 0.027283, loss_ce: 0.013314
2022-01-08 16:40:18,166 iteration 2418 : loss : 0.034818, loss_ce: 0.011155
2022-01-08 16:40:20,527 iteration 2419 : loss : 0.051879, loss_ce: 0.015262
2022-01-08 16:40:22,989 iteration 2420 : loss : 0.028490, loss_ce: 0.012311
2022-01-08 16:40:25,346 iteration 2421 : loss : 0.024170, loss_ce: 0.011464
2022-01-08 16:40:27,717 iteration 2422 : loss : 0.031690, loss_ce: 0.012789
2022-01-08 16:40:30,052 iteration 2423 : loss : 0.024415, loss_ce: 0.010388
2022-01-08 16:40:32,444 iteration 2424 : loss : 0.029540, loss_ce: 0.011743
2022-01-08 16:40:34,798 iteration 2425 : loss : 0.023702, loss_ce: 0.006754
2022-01-08 16:40:37,220 iteration 2426 : loss : 0.030221, loss_ce: 0.010297
2022-01-08 16:40:39,543 iteration 2427 : loss : 0.031181, loss_ce: 0.014760
2022-01-08 16:40:41,898 iteration 2428 : loss : 0.033181, loss_ce: 0.011371
2022-01-08 16:40:44,243 iteration 2429 : loss : 0.047972, loss_ce: 0.017667
2022-01-08 16:40:46,588 iteration 2430 : loss : 0.035371, loss_ce: 0.012810
2022-01-08 16:40:48,959 iteration 2431 : loss : 0.023763, loss_ce: 0.007387
 36%|█████████▋                 | 143/400 [1:40:55<3:03:19, 42.80s/it]2022-01-08 16:40:51,529 iteration 2432 : loss : 0.023062, loss_ce: 0.008914
2022-01-08 16:40:53,924 iteration 2433 : loss : 0.023660, loss_ce: 0.010398
2022-01-08 16:40:56,344 iteration 2434 : loss : 0.036685, loss_ce: 0.013946
2022-01-08 16:40:58,788 iteration 2435 : loss : 0.024850, loss_ce: 0.011219
2022-01-08 16:41:01,261 iteration 2436 : loss : 0.026122, loss_ce: 0.010151
2022-01-08 16:41:03,612 iteration 2437 : loss : 0.024977, loss_ce: 0.011437
2022-01-08 16:41:05,919 iteration 2438 : loss : 0.022400, loss_ce: 0.009204
2022-01-08 16:41:08,257 iteration 2439 : loss : 0.027001, loss_ce: 0.009095
2022-01-08 16:41:10,687 iteration 2440 : loss : 0.026492, loss_ce: 0.009530
2022-01-08 16:41:13,153 iteration 2441 : loss : 0.069124, loss_ce: 0.019990
2022-01-08 16:41:15,541 iteration 2442 : loss : 0.027555, loss_ce: 0.009112
2022-01-08 16:41:18,054 iteration 2443 : loss : 0.030699, loss_ce: 0.013582
2022-01-08 16:41:20,494 iteration 2444 : loss : 0.035734, loss_ce: 0.013671
2022-01-08 16:41:22,929 iteration 2445 : loss : 0.029704, loss_ce: 0.010019
2022-01-08 16:41:25,336 iteration 2446 : loss : 0.033871, loss_ce: 0.013819
2022-01-08 16:41:27,788 iteration 2447 : loss : 0.033407, loss_ce: 0.013127
2022-01-08 16:41:30,171 iteration 2448 : loss : 0.038568, loss_ce: 0.021808
 36%|█████████▋                 | 144/400 [1:41:37<3:00:34, 42.32s/it]2022-01-08 16:41:32,623 iteration 2449 : loss : 0.025068, loss_ce: 0.007972
2022-01-08 16:41:34,980 iteration 2450 : loss : 0.028425, loss_ce: 0.011578
2022-01-08 16:41:37,314 iteration 2451 : loss : 0.030499, loss_ce: 0.008841
2022-01-08 16:41:39,640 iteration 2452 : loss : 0.036287, loss_ce: 0.016497
2022-01-08 16:41:41,970 iteration 2453 : loss : 0.028900, loss_ce: 0.012668
2022-01-08 16:41:44,370 iteration 2454 : loss : 0.028203, loss_ce: 0.010878
2022-01-08 16:41:46,866 iteration 2455 : loss : 0.029995, loss_ce: 0.010078
2022-01-08 16:41:49,292 iteration 2456 : loss : 0.034485, loss_ce: 0.015734
2022-01-08 16:41:51,680 iteration 2457 : loss : 0.025966, loss_ce: 0.010822
2022-01-08 16:41:54,259 iteration 2458 : loss : 0.030819, loss_ce: 0.010843
2022-01-08 16:41:56,644 iteration 2459 : loss : 0.025842, loss_ce: 0.009423
2022-01-08 16:41:59,087 iteration 2460 : loss : 0.048464, loss_ce: 0.011990
2022-01-08 16:42:01,471 iteration 2461 : loss : 0.040415, loss_ce: 0.011856
2022-01-08 16:42:03,927 iteration 2462 : loss : 0.034588, loss_ce: 0.016040
2022-01-08 16:42:06,373 iteration 2463 : loss : 0.027152, loss_ce: 0.010023
2022-01-08 16:42:08,779 iteration 2464 : loss : 0.030323, loss_ce: 0.016266
2022-01-08 16:42:08,779 Training Data Eval:
2022-01-08 16:42:21,775   Average segmentation loss on training set: 0.0191
2022-01-08 16:42:21,776 Validation Data Eval:
2022-01-08 16:42:26,275   Average segmentation loss on validation set: 0.0744
2022-01-08 16:42:28,708 iteration 2465 : loss : 0.026935, loss_ce: 0.011542
 36%|█████████▊                 | 145/400 [1:42:35<3:20:32, 47.19s/it]2022-01-08 16:42:31,161 iteration 2466 : loss : 0.049313, loss_ce: 0.018044
2022-01-08 16:42:33,484 iteration 2467 : loss : 0.022361, loss_ce: 0.007344
2022-01-08 16:42:35,955 iteration 2468 : loss : 0.033030, loss_ce: 0.010922
2022-01-08 16:42:38,339 iteration 2469 : loss : 0.031682, loss_ce: 0.015305
2022-01-08 16:42:40,769 iteration 2470 : loss : 0.037096, loss_ce: 0.015496
2022-01-08 16:42:43,163 iteration 2471 : loss : 0.032552, loss_ce: 0.016426
2022-01-08 16:42:45,609 iteration 2472 : loss : 0.025809, loss_ce: 0.009030
2022-01-08 16:42:48,151 iteration 2473 : loss : 0.025519, loss_ce: 0.009664
2022-01-08 16:42:50,493 iteration 2474 : loss : 0.023380, loss_ce: 0.009514
2022-01-08 16:42:52,915 iteration 2475 : loss : 0.036260, loss_ce: 0.021117
2022-01-08 16:42:55,297 iteration 2476 : loss : 0.029664, loss_ce: 0.008826
2022-01-08 16:42:57,732 iteration 2477 : loss : 0.035685, loss_ce: 0.013271
2022-01-08 16:43:00,069 iteration 2478 : loss : 0.030839, loss_ce: 0.010271
2022-01-08 16:43:02,454 iteration 2479 : loss : 0.037437, loss_ce: 0.012710
2022-01-08 16:43:04,859 iteration 2480 : loss : 0.020458, loss_ce: 0.007388
2022-01-08 16:43:07,226 iteration 2481 : loss : 0.025873, loss_ce: 0.010747
2022-01-08 16:43:09,721 iteration 2482 : loss : 0.058354, loss_ce: 0.019965
 36%|█████████▊                 | 146/400 [1:43:16<3:11:54, 45.33s/it]2022-01-08 16:43:12,146 iteration 2483 : loss : 0.050089, loss_ce: 0.022566
2022-01-08 16:43:14,529 iteration 2484 : loss : 0.079612, loss_ce: 0.012346
2022-01-08 16:43:16,855 iteration 2485 : loss : 0.040484, loss_ce: 0.014175
2022-01-08 16:43:19,205 iteration 2486 : loss : 0.033084, loss_ce: 0.014195
2022-01-08 16:43:21,594 iteration 2487 : loss : 0.023614, loss_ce: 0.009729
2022-01-08 16:43:24,051 iteration 2488 : loss : 0.030294, loss_ce: 0.015971
2022-01-08 16:43:26,421 iteration 2489 : loss : 0.044230, loss_ce: 0.017221
2022-01-08 16:43:28,974 iteration 2490 : loss : 0.036938, loss_ce: 0.015297
2022-01-08 16:43:31,386 iteration 2491 : loss : 0.032298, loss_ce: 0.009875
2022-01-08 16:43:33,775 iteration 2492 : loss : 0.048582, loss_ce: 0.017016
2022-01-08 16:43:36,283 iteration 2493 : loss : 0.024721, loss_ce: 0.008698
2022-01-08 16:43:38,671 iteration 2494 : loss : 0.058439, loss_ce: 0.022349
2022-01-08 16:43:41,090 iteration 2495 : loss : 0.027331, loss_ce: 0.011409
2022-01-08 16:43:43,346 iteration 2496 : loss : 0.022742, loss_ce: 0.007737
2022-01-08 16:43:45,692 iteration 2497 : loss : 0.032796, loss_ce: 0.011924
2022-01-08 16:43:48,213 iteration 2498 : loss : 0.030341, loss_ce: 0.010944
2022-01-08 16:43:50,584 iteration 2499 : loss : 0.024948, loss_ce: 0.011122
 37%|█████████▉                 | 147/400 [1:43:57<3:05:30, 43.99s/it]2022-01-08 16:43:53,061 iteration 2500 : loss : 0.032788, loss_ce: 0.013820
2022-01-08 16:43:55,510 iteration 2501 : loss : 0.027818, loss_ce: 0.011136
2022-01-08 16:43:57,966 iteration 2502 : loss : 0.024417, loss_ce: 0.012480
2022-01-08 16:44:00,330 iteration 2503 : loss : 0.026295, loss_ce: 0.013866
2022-01-08 16:44:02,678 iteration 2504 : loss : 0.026591, loss_ce: 0.009498
2022-01-08 16:44:05,063 iteration 2505 : loss : 0.026032, loss_ce: 0.008917
2022-01-08 16:44:07,422 iteration 2506 : loss : 0.021720, loss_ce: 0.008333
2022-01-08 16:44:09,885 iteration 2507 : loss : 0.021549, loss_ce: 0.008630
2022-01-08 16:44:12,225 iteration 2508 : loss : 0.021847, loss_ce: 0.009143
2022-01-08 16:44:14,743 iteration 2509 : loss : 0.024259, loss_ce: 0.012690
2022-01-08 16:44:17,096 iteration 2510 : loss : 0.049422, loss_ce: 0.014166
2022-01-08 16:44:19,660 iteration 2511 : loss : 0.026699, loss_ce: 0.011912
2022-01-08 16:44:22,064 iteration 2512 : loss : 0.024374, loss_ce: 0.008805
2022-01-08 16:44:24,405 iteration 2513 : loss : 0.032024, loss_ce: 0.012464
2022-01-08 16:44:26,706 iteration 2514 : loss : 0.026685, loss_ce: 0.009323
2022-01-08 16:44:29,030 iteration 2515 : loss : 0.031856, loss_ce: 0.010338
2022-01-08 16:44:31,404 iteration 2516 : loss : 0.036512, loss_ce: 0.016101
 37%|█████████▉                 | 148/400 [1:44:38<3:00:45, 43.04s/it]2022-01-08 16:44:33,810 iteration 2517 : loss : 0.022074, loss_ce: 0.007242
2022-01-08 16:44:36,337 iteration 2518 : loss : 0.029853, loss_ce: 0.013314
2022-01-08 16:44:38,724 iteration 2519 : loss : 0.026407, loss_ce: 0.011436
2022-01-08 16:44:41,120 iteration 2520 : loss : 0.020476, loss_ce: 0.006681
2022-01-08 16:44:43,524 iteration 2521 : loss : 0.022394, loss_ce: 0.010676
2022-01-08 16:44:45,855 iteration 2522 : loss : 0.019505, loss_ce: 0.007709
2022-01-08 16:44:48,367 iteration 2523 : loss : 0.027865, loss_ce: 0.006948
2022-01-08 16:44:50,786 iteration 2524 : loss : 0.026279, loss_ce: 0.012663
2022-01-08 16:44:53,104 iteration 2525 : loss : 0.018666, loss_ce: 0.007084
2022-01-08 16:44:55,446 iteration 2526 : loss : 0.024338, loss_ce: 0.008797
2022-01-08 16:44:57,801 iteration 2527 : loss : 0.025941, loss_ce: 0.010394
2022-01-08 16:45:00,182 iteration 2528 : loss : 0.035021, loss_ce: 0.014041
2022-01-08 16:45:02,753 iteration 2529 : loss : 0.027622, loss_ce: 0.011383
2022-01-08 16:45:05,153 iteration 2530 : loss : 0.024182, loss_ce: 0.006409
2022-01-08 16:45:07,597 iteration 2531 : loss : 0.025630, loss_ce: 0.008608
2022-01-08 16:45:10,079 iteration 2532 : loss : 0.029404, loss_ce: 0.012025
2022-01-08 16:45:12,509 iteration 2533 : loss : 0.029971, loss_ce: 0.017996
 37%|██████████                 | 149/400 [1:45:19<2:57:37, 42.46s/it]2022-01-08 16:45:14,906 iteration 2534 : loss : 0.018078, loss_ce: 0.007811
2022-01-08 16:45:17,482 iteration 2535 : loss : 0.027763, loss_ce: 0.008016
2022-01-08 16:45:19,917 iteration 2536 : loss : 0.031668, loss_ce: 0.015257
2022-01-08 16:45:22,309 iteration 2537 : loss : 0.045138, loss_ce: 0.014510
2022-01-08 16:45:24,734 iteration 2538 : loss : 0.039756, loss_ce: 0.016003
2022-01-08 16:45:27,057 iteration 2539 : loss : 0.022523, loss_ce: 0.008854
2022-01-08 16:45:29,461 iteration 2540 : loss : 0.025515, loss_ce: 0.008803
2022-01-08 16:45:31,960 iteration 2541 : loss : 0.052856, loss_ce: 0.014021
2022-01-08 16:45:34,290 iteration 2542 : loss : 0.023833, loss_ce: 0.008759
2022-01-08 16:45:36,760 iteration 2543 : loss : 0.024111, loss_ce: 0.008007
2022-01-08 16:45:39,212 iteration 2544 : loss : 0.029721, loss_ce: 0.011832
2022-01-08 16:45:41,568 iteration 2545 : loss : 0.025591, loss_ce: 0.012063
2022-01-08 16:45:43,839 iteration 2546 : loss : 0.029385, loss_ce: 0.009811
2022-01-08 16:45:46,290 iteration 2547 : loss : 0.031943, loss_ce: 0.006805
2022-01-08 16:45:48,658 iteration 2548 : loss : 0.024671, loss_ce: 0.009214
2022-01-08 16:45:51,030 iteration 2549 : loss : 0.035428, loss_ce: 0.014700
2022-01-08 16:45:51,030 Training Data Eval:
2022-01-08 16:46:03,883   Average segmentation loss on training set: 0.0212
2022-01-08 16:46:03,884 Validation Data Eval:
2022-01-08 16:46:08,502   Average segmentation loss on validation set: 0.1215
2022-01-08 16:46:10,913 iteration 2550 : loss : 0.033859, loss_ce: 0.020433
 38%|██████████▏                | 150/400 [1:46:17<3:16:49, 47.24s/it]2022-01-08 16:46:13,313 iteration 2551 : loss : 0.022336, loss_ce: 0.007932
2022-01-08 16:46:15,623 iteration 2552 : loss : 0.023937, loss_ce: 0.010050
2022-01-08 16:46:18,049 iteration 2553 : loss : 0.043215, loss_ce: 0.015821
2022-01-08 16:46:20,489 iteration 2554 : loss : 0.047483, loss_ce: 0.017379
2022-01-08 16:46:22,897 iteration 2555 : loss : 0.030675, loss_ce: 0.008472
2022-01-08 16:46:25,349 iteration 2556 : loss : 0.026207, loss_ce: 0.010498
2022-01-08 16:46:27,785 iteration 2557 : loss : 0.025320, loss_ce: 0.011123
2022-01-08 16:46:30,159 iteration 2558 : loss : 0.026844, loss_ce: 0.011873
2022-01-08 16:46:32,568 iteration 2559 : loss : 0.044495, loss_ce: 0.010129
2022-01-08 16:46:34,985 iteration 2560 : loss : 0.029019, loss_ce: 0.011251
2022-01-08 16:46:37,357 iteration 2561 : loss : 0.027175, loss_ce: 0.012587
2022-01-08 16:46:39,660 iteration 2562 : loss : 0.025705, loss_ce: 0.013444
2022-01-08 16:46:41,979 iteration 2563 : loss : 0.026823, loss_ce: 0.010203
2022-01-08 16:46:44,309 iteration 2564 : loss : 0.026409, loss_ce: 0.012119
2022-01-08 16:46:46,724 iteration 2565 : loss : 0.040721, loss_ce: 0.011949
2022-01-08 16:46:49,076 iteration 2566 : loss : 0.026841, loss_ce: 0.011815
2022-01-08 16:46:51,709 iteration 2567 : loss : 0.035800, loss_ce: 0.013003
 38%|██████████▏                | 151/400 [1:46:58<3:08:02, 45.31s/it]2022-01-08 16:46:54,155 iteration 2568 : loss : 0.026697, loss_ce: 0.011721
2022-01-08 16:46:56,511 iteration 2569 : loss : 0.029455, loss_ce: 0.011249
2022-01-08 16:46:59,006 iteration 2570 : loss : 0.033298, loss_ce: 0.008914
2022-01-08 16:47:01,439 iteration 2571 : loss : 0.040733, loss_ce: 0.015375
2022-01-08 16:47:03,759 iteration 2572 : loss : 0.024384, loss_ce: 0.007404
2022-01-08 16:47:06,092 iteration 2573 : loss : 0.022266, loss_ce: 0.008795
2022-01-08 16:47:08,477 iteration 2574 : loss : 0.028264, loss_ce: 0.009439
2022-01-08 16:47:10,934 iteration 2575 : loss : 0.029791, loss_ce: 0.009935
2022-01-08 16:47:13,394 iteration 2576 : loss : 0.032495, loss_ce: 0.017567
2022-01-08 16:47:15,710 iteration 2577 : loss : 0.031119, loss_ce: 0.010858
2022-01-08 16:47:18,285 iteration 2578 : loss : 0.027799, loss_ce: 0.014272
2022-01-08 16:47:20,691 iteration 2579 : loss : 0.028333, loss_ce: 0.009156
2022-01-08 16:47:23,088 iteration 2580 : loss : 0.022401, loss_ce: 0.006492
2022-01-08 16:47:25,556 iteration 2581 : loss : 0.028112, loss_ce: 0.010281
2022-01-08 16:47:27,756 iteration 2582 : loss : 0.024707, loss_ce: 0.010584
2022-01-08 16:47:30,076 iteration 2583 : loss : 0.022945, loss_ce: 0.008314
2022-01-08 16:47:32,372 iteration 2584 : loss : 0.022397, loss_ce: 0.008139
 38%|██████████▎                | 152/400 [1:47:39<3:01:31, 43.92s/it]2022-01-08 16:47:34,829 iteration 2585 : loss : 0.047932, loss_ce: 0.020386
2022-01-08 16:47:37,153 iteration 2586 : loss : 0.051924, loss_ce: 0.023450
2022-01-08 16:47:39,519 iteration 2587 : loss : 0.026482, loss_ce: 0.008500
2022-01-08 16:47:41,874 iteration 2588 : loss : 0.024944, loss_ce: 0.010592
2022-01-08 16:47:44,259 iteration 2589 : loss : 0.028128, loss_ce: 0.010014
2022-01-08 16:47:46,727 iteration 2590 : loss : 0.041733, loss_ce: 0.013363
2022-01-08 16:47:49,097 iteration 2591 : loss : 0.027866, loss_ce: 0.011855
2022-01-08 16:47:51,456 iteration 2592 : loss : 0.041064, loss_ce: 0.015523
2022-01-08 16:47:53,801 iteration 2593 : loss : 0.032072, loss_ce: 0.015913
2022-01-08 16:47:56,409 iteration 2594 : loss : 0.026592, loss_ce: 0.010428
2022-01-08 16:47:58,888 iteration 2595 : loss : 0.052888, loss_ce: 0.016092
2022-01-08 16:48:01,173 iteration 2596 : loss : 0.027937, loss_ce: 0.009308
2022-01-08 16:48:03,490 iteration 2597 : loss : 0.039792, loss_ce: 0.012225
2022-01-08 16:48:05,816 iteration 2598 : loss : 0.027344, loss_ce: 0.011204
2022-01-08 16:48:08,271 iteration 2599 : loss : 0.028059, loss_ce: 0.012170
2022-01-08 16:48:10,852 iteration 2600 : loss : 0.042531, loss_ce: 0.012220
2022-01-08 16:48:13,280 iteration 2601 : loss : 0.026917, loss_ce: 0.009829
 38%|██████████▎                | 153/400 [1:48:20<2:57:04, 43.02s/it]2022-01-08 16:48:15,713 iteration 2602 : loss : 0.028187, loss_ce: 0.008875
2022-01-08 16:48:18,081 iteration 2603 : loss : 0.033043, loss_ce: 0.013414
2022-01-08 16:48:20,443 iteration 2604 : loss : 0.028653, loss_ce: 0.012508
2022-01-08 16:48:22,743 iteration 2605 : loss : 0.021268, loss_ce: 0.006260
2022-01-08 16:48:25,207 iteration 2606 : loss : 0.046195, loss_ce: 0.015747
2022-01-08 16:48:27,719 iteration 2607 : loss : 0.025699, loss_ce: 0.008993
2022-01-08 16:48:30,160 iteration 2608 : loss : 0.027240, loss_ce: 0.012375
2022-01-08 16:48:32,623 iteration 2609 : loss : 0.040416, loss_ce: 0.013192
2022-01-08 16:48:35,074 iteration 2610 : loss : 0.026003, loss_ce: 0.009758
2022-01-08 16:48:37,554 iteration 2611 : loss : 0.036886, loss_ce: 0.012711
2022-01-08 16:48:39,971 iteration 2612 : loss : 0.031570, loss_ce: 0.014084
2022-01-08 16:48:42,275 iteration 2613 : loss : 0.024661, loss_ce: 0.010220
2022-01-08 16:48:44,878 iteration 2614 : loss : 0.034550, loss_ce: 0.012835
2022-01-08 16:48:47,274 iteration 2615 : loss : 0.034286, loss_ce: 0.011748
2022-01-08 16:48:49,688 iteration 2616 : loss : 0.027230, loss_ce: 0.013605
2022-01-08 16:48:52,068 iteration 2617 : loss : 0.026805, loss_ce: 0.008191
2022-01-08 16:48:54,484 iteration 2618 : loss : 0.025810, loss_ce: 0.010449
 38%|██████████▍                | 154/400 [1:49:01<2:54:07, 42.47s/it]2022-01-08 16:48:56,910 iteration 2619 : loss : 0.035328, loss_ce: 0.009960
2022-01-08 16:48:59,223 iteration 2620 : loss : 0.023512, loss_ce: 0.011041
2022-01-08 16:49:01,615 iteration 2621 : loss : 0.033913, loss_ce: 0.011744
2022-01-08 16:49:04,016 iteration 2622 : loss : 0.050115, loss_ce: 0.010622
2022-01-08 16:49:06,409 iteration 2623 : loss : 0.035556, loss_ce: 0.015767
2022-01-08 16:49:08,747 iteration 2624 : loss : 0.032903, loss_ce: 0.011602
2022-01-08 16:49:11,199 iteration 2625 : loss : 0.032929, loss_ce: 0.006048
2022-01-08 16:49:13,672 iteration 2626 : loss : 0.030910, loss_ce: 0.012218
2022-01-08 16:49:16,173 iteration 2627 : loss : 0.045311, loss_ce: 0.017449
2022-01-08 16:49:18,674 iteration 2628 : loss : 0.022923, loss_ce: 0.009571
2022-01-08 16:49:21,115 iteration 2629 : loss : 0.030920, loss_ce: 0.014689
2022-01-08 16:49:23,415 iteration 2630 : loss : 0.028298, loss_ce: 0.012255
2022-01-08 16:49:25,754 iteration 2631 : loss : 0.026962, loss_ce: 0.010842
2022-01-08 16:49:28,176 iteration 2632 : loss : 0.021346, loss_ce: 0.008021
2022-01-08 16:49:30,576 iteration 2633 : loss : 0.029598, loss_ce: 0.014842
2022-01-08 16:49:32,984 iteration 2634 : loss : 0.028781, loss_ce: 0.010181
2022-01-08 16:49:32,984 Training Data Eval:
2022-01-08 16:49:45,800   Average segmentation loss on training set: 0.0211
2022-01-08 16:49:45,801 Validation Data Eval:
2022-01-08 16:49:50,304   Average segmentation loss on validation set: 0.0627
2022-01-08 16:49:52,687 iteration 2635 : loss : 0.023307, loss_ce: 0.008827
 39%|██████████▍                | 155/400 [1:49:59<3:12:41, 47.19s/it]2022-01-08 16:49:55,160 iteration 2636 : loss : 0.029004, loss_ce: 0.013048
2022-01-08 16:49:57,619 iteration 2637 : loss : 0.038085, loss_ce: 0.013610
2022-01-08 16:49:59,954 iteration 2638 : loss : 0.029281, loss_ce: 0.010333
2022-01-08 16:50:02,282 iteration 2639 : loss : 0.025301, loss_ce: 0.011650
2022-01-08 16:50:04,793 iteration 2640 : loss : 0.028058, loss_ce: 0.010713
2022-01-08 16:50:07,205 iteration 2641 : loss : 0.043367, loss_ce: 0.021278
2022-01-08 16:50:09,515 iteration 2642 : loss : 0.024577, loss_ce: 0.007935
2022-01-08 16:50:11,981 iteration 2643 : loss : 0.029384, loss_ce: 0.009827
2022-01-08 16:50:14,270 iteration 2644 : loss : 0.026354, loss_ce: 0.009589
2022-01-08 16:50:16,579 iteration 2645 : loss : 0.019668, loss_ce: 0.006526
2022-01-08 16:50:19,105 iteration 2646 : loss : 0.030423, loss_ce: 0.008988
2022-01-08 16:50:21,561 iteration 2647 : loss : 0.032785, loss_ce: 0.014772
2022-01-08 16:50:23,890 iteration 2648 : loss : 0.036460, loss_ce: 0.015915
2022-01-08 16:50:26,241 iteration 2649 : loss : 0.027115, loss_ce: 0.010854
2022-01-08 16:50:28,632 iteration 2650 : loss : 0.026143, loss_ce: 0.009050
2022-01-08 16:50:30,991 iteration 2651 : loss : 0.028327, loss_ce: 0.011903
2022-01-08 16:50:33,401 iteration 2652 : loss : 0.022164, loss_ce: 0.008119
 39%|██████████▌                | 156/400 [1:50:40<3:04:00, 45.25s/it]2022-01-08 16:50:35,873 iteration 2653 : loss : 0.025480, loss_ce: 0.011551
2022-01-08 16:50:38,160 iteration 2654 : loss : 0.024581, loss_ce: 0.008271
2022-01-08 16:50:40,603 iteration 2655 : loss : 0.028034, loss_ce: 0.013756
2022-01-08 16:50:43,032 iteration 2656 : loss : 0.030704, loss_ce: 0.009436
2022-01-08 16:50:45,424 iteration 2657 : loss : 0.030451, loss_ce: 0.011477
2022-01-08 16:50:47,696 iteration 2658 : loss : 0.022717, loss_ce: 0.010916
2022-01-08 16:50:49,988 iteration 2659 : loss : 0.040797, loss_ce: 0.009058
2022-01-08 16:50:52,297 iteration 2660 : loss : 0.026808, loss_ce: 0.008679
2022-01-08 16:50:54,555 iteration 2661 : loss : 0.023007, loss_ce: 0.009783
2022-01-08 16:50:56,859 iteration 2662 : loss : 0.028063, loss_ce: 0.013360
2022-01-08 16:50:59,217 iteration 2663 : loss : 0.025455, loss_ce: 0.007109
2022-01-08 16:51:01,625 iteration 2664 : loss : 0.034263, loss_ce: 0.014727
2022-01-08 16:51:03,907 iteration 2665 : loss : 0.029648, loss_ce: 0.011822
2022-01-08 16:51:06,194 iteration 2666 : loss : 0.020539, loss_ce: 0.006526
2022-01-08 16:51:08,630 iteration 2667 : loss : 0.026971, loss_ce: 0.010004
2022-01-08 16:51:10,954 iteration 2668 : loss : 0.019782, loss_ce: 0.006724
2022-01-08 16:51:13,268 iteration 2669 : loss : 0.027448, loss_ce: 0.010875
 39%|██████████▌                | 157/400 [1:51:20<2:56:42, 43.63s/it]2022-01-08 16:51:15,663 iteration 2670 : loss : 0.037710, loss_ce: 0.018037
2022-01-08 16:51:18,106 iteration 2671 : loss : 0.040720, loss_ce: 0.012869
2022-01-08 16:51:20,558 iteration 2672 : loss : 0.022650, loss_ce: 0.007883
2022-01-08 16:51:23,059 iteration 2673 : loss : 0.021004, loss_ce: 0.010229
2022-01-08 16:51:25,486 iteration 2674 : loss : 0.028788, loss_ce: 0.012768
2022-01-08 16:51:27,760 iteration 2675 : loss : 0.020889, loss_ce: 0.008467
2022-01-08 16:51:30,172 iteration 2676 : loss : 0.039011, loss_ce: 0.008766
2022-01-08 16:51:32,564 iteration 2677 : loss : 0.026129, loss_ce: 0.009988
2022-01-08 16:51:34,933 iteration 2678 : loss : 0.026266, loss_ce: 0.011174
2022-01-08 16:51:37,379 iteration 2679 : loss : 0.035825, loss_ce: 0.012332
2022-01-08 16:51:39,763 iteration 2680 : loss : 0.020641, loss_ce: 0.008033
2022-01-08 16:51:42,168 iteration 2681 : loss : 0.027495, loss_ce: 0.009085
2022-01-08 16:51:44,539 iteration 2682 : loss : 0.029078, loss_ce: 0.010527
2022-01-08 16:51:47,014 iteration 2683 : loss : 0.033501, loss_ce: 0.008728
2022-01-08 16:51:49,384 iteration 2684 : loss : 0.024648, loss_ce: 0.012393
2022-01-08 16:51:51,743 iteration 2685 : loss : 0.026646, loss_ce: 0.010474
2022-01-08 16:51:54,000 iteration 2686 : loss : 0.027629, loss_ce: 0.011802
 40%|██████████▋                | 158/400 [1:52:00<2:52:28, 42.76s/it]2022-01-08 16:51:56,415 iteration 2687 : loss : 0.026136, loss_ce: 0.007521
2022-01-08 16:51:58,911 iteration 2688 : loss : 0.030477, loss_ce: 0.010390
2022-01-08 16:52:01,314 iteration 2689 : loss : 0.039414, loss_ce: 0.015046
2022-01-08 16:52:03,770 iteration 2690 : loss : 0.030424, loss_ce: 0.012561
2022-01-08 16:52:06,086 iteration 2691 : loss : 0.029536, loss_ce: 0.011826
2022-01-08 16:52:08,384 iteration 2692 : loss : 0.029924, loss_ce: 0.009538
2022-01-08 16:52:10,680 iteration 2693 : loss : 0.043866, loss_ce: 0.013085
2022-01-08 16:52:13,067 iteration 2694 : loss : 0.032144, loss_ce: 0.010913
2022-01-08 16:52:15,419 iteration 2695 : loss : 0.024894, loss_ce: 0.010817
2022-01-08 16:52:17,911 iteration 2696 : loss : 0.029950, loss_ce: 0.012706
2022-01-08 16:52:20,304 iteration 2697 : loss : 0.028251, loss_ce: 0.010961
2022-01-08 16:52:22,593 iteration 2698 : loss : 0.022341, loss_ce: 0.010162
2022-01-08 16:52:24,985 iteration 2699 : loss : 0.029256, loss_ce: 0.011326
2022-01-08 16:52:27,360 iteration 2700 : loss : 0.029436, loss_ce: 0.014224
2022-01-08 16:52:29,731 iteration 2701 : loss : 0.031444, loss_ce: 0.012694
2022-01-08 16:52:32,141 iteration 2702 : loss : 0.103752, loss_ce: 0.023208
2022-01-08 16:52:34,460 iteration 2703 : loss : 0.025083, loss_ce: 0.009893
 40%|██████████▋                | 159/400 [1:52:41<2:48:59, 42.07s/it]2022-01-08 16:52:36,907 iteration 2704 : loss : 0.037249, loss_ce: 0.014983
2022-01-08 16:52:39,200 iteration 2705 : loss : 0.028833, loss_ce: 0.008262
2022-01-08 16:52:41,500 iteration 2706 : loss : 0.030982, loss_ce: 0.014638
2022-01-08 16:52:43,864 iteration 2707 : loss : 0.032830, loss_ce: 0.011611
2022-01-08 16:52:46,205 iteration 2708 : loss : 0.020950, loss_ce: 0.007775
2022-01-08 16:52:48,677 iteration 2709 : loss : 0.027983, loss_ce: 0.008141
2022-01-08 16:52:51,085 iteration 2710 : loss : 0.023480, loss_ce: 0.008187
2022-01-08 16:52:53,572 iteration 2711 : loss : 0.032178, loss_ce: 0.010048
2022-01-08 16:52:55,860 iteration 2712 : loss : 0.020487, loss_ce: 0.007841
2022-01-08 16:52:58,270 iteration 2713 : loss : 0.045700, loss_ce: 0.013175
2022-01-08 16:53:00,521 iteration 2714 : loss : 0.033800, loss_ce: 0.010391
2022-01-08 16:53:03,003 iteration 2715 : loss : 0.044406, loss_ce: 0.021975
2022-01-08 16:53:05,392 iteration 2716 : loss : 0.039672, loss_ce: 0.013535
2022-01-08 16:53:07,732 iteration 2717 : loss : 0.027253, loss_ce: 0.013266
2022-01-08 16:53:10,107 iteration 2718 : loss : 0.045537, loss_ce: 0.017689
2022-01-08 16:53:12,555 iteration 2719 : loss : 0.071018, loss_ce: 0.022725
2022-01-08 16:53:12,555 Training Data Eval:
2022-01-08 16:53:25,324   Average segmentation loss on training set: 0.0234
2022-01-08 16:53:25,324 Validation Data Eval:
2022-01-08 16:53:29,963   Average segmentation loss on validation set: 0.0786
2022-01-08 16:53:32,314 iteration 2720 : loss : 0.023481, loss_ce: 0.009833
 40%|██████████▊                | 160/400 [1:53:39<3:07:13, 46.81s/it]2022-01-08 16:53:34,772 iteration 2721 : loss : 0.030120, loss_ce: 0.011709
2022-01-08 16:53:37,153 iteration 2722 : loss : 0.028549, loss_ce: 0.012516
2022-01-08 16:53:39,494 iteration 2723 : loss : 0.025646, loss_ce: 0.009971
2022-01-08 16:53:41,731 iteration 2724 : loss : 0.032893, loss_ce: 0.010231
2022-01-08 16:53:43,999 iteration 2725 : loss : 0.026315, loss_ce: 0.009825
2022-01-08 16:53:46,379 iteration 2726 : loss : 0.030279, loss_ce: 0.010408
2022-01-08 16:53:48,876 iteration 2727 : loss : 0.021008, loss_ce: 0.006423
2022-01-08 16:53:51,365 iteration 2728 : loss : 0.053976, loss_ce: 0.024332
2022-01-08 16:53:53,718 iteration 2729 : loss : 0.043081, loss_ce: 0.016754
2022-01-08 16:53:56,020 iteration 2730 : loss : 0.034513, loss_ce: 0.013438
2022-01-08 16:53:58,335 iteration 2731 : loss : 0.028883, loss_ce: 0.011609
2022-01-08 16:54:00,829 iteration 2732 : loss : 0.034526, loss_ce: 0.016163
2022-01-08 16:54:03,272 iteration 2733 : loss : 0.041529, loss_ce: 0.016678
2022-01-08 16:54:05,711 iteration 2734 : loss : 0.030010, loss_ce: 0.008231
2022-01-08 16:54:08,079 iteration 2735 : loss : 0.025712, loss_ce: 0.010443
2022-01-08 16:54:10,603 iteration 2736 : loss : 0.032953, loss_ce: 0.015090
2022-01-08 16:54:12,974 iteration 2737 : loss : 0.028997, loss_ce: 0.010497
 40%|██████████▊                | 161/400 [1:54:19<2:59:04, 44.96s/it]2022-01-08 16:54:15,320 iteration 2738 : loss : 0.033155, loss_ce: 0.017831
2022-01-08 16:54:17,640 iteration 2739 : loss : 0.033618, loss_ce: 0.017001
2022-01-08 16:54:19,964 iteration 2740 : loss : 0.026543, loss_ce: 0.010319
2022-01-08 16:54:22,316 iteration 2741 : loss : 0.025080, loss_ce: 0.007616
2022-01-08 16:54:24,666 iteration 2742 : loss : 0.030485, loss_ce: 0.011928
2022-01-08 16:54:27,042 iteration 2743 : loss : 0.041386, loss_ce: 0.023153
2022-01-08 16:54:29,540 iteration 2744 : loss : 0.035880, loss_ce: 0.012638
2022-01-08 16:54:31,932 iteration 2745 : loss : 0.032577, loss_ce: 0.012299
2022-01-08 16:54:34,323 iteration 2746 : loss : 0.039006, loss_ce: 0.013108
2022-01-08 16:54:36,745 iteration 2747 : loss : 0.031541, loss_ce: 0.010589
2022-01-08 16:54:39,175 iteration 2748 : loss : 0.036296, loss_ce: 0.014921
2022-01-08 16:54:41,564 iteration 2749 : loss : 0.038998, loss_ce: 0.018014
2022-01-08 16:54:43,982 iteration 2750 : loss : 0.028386, loss_ce: 0.009711
2022-01-08 16:54:46,372 iteration 2751 : loss : 0.022076, loss_ce: 0.009706
2022-01-08 16:54:48,708 iteration 2752 : loss : 0.032737, loss_ce: 0.006961
2022-01-08 16:54:51,176 iteration 2753 : loss : 0.034384, loss_ce: 0.013510
2022-01-08 16:54:53,583 iteration 2754 : loss : 0.021687, loss_ce: 0.010063
 40%|██████████▉                | 162/400 [1:55:00<2:53:09, 43.65s/it]2022-01-08 16:54:55,984 iteration 2755 : loss : 0.024580, loss_ce: 0.009449
2022-01-08 16:54:58,350 iteration 2756 : loss : 0.043524, loss_ce: 0.023494
2022-01-08 16:55:00,744 iteration 2757 : loss : 0.053080, loss_ce: 0.029484
2022-01-08 16:55:03,284 iteration 2758 : loss : 0.039514, loss_ce: 0.012469
2022-01-08 16:55:05,700 iteration 2759 : loss : 0.026189, loss_ce: 0.007706
2022-01-08 16:55:08,176 iteration 2760 : loss : 0.030767, loss_ce: 0.012114
2022-01-08 16:55:10,584 iteration 2761 : loss : 0.028550, loss_ce: 0.010704
2022-01-08 16:55:12,947 iteration 2762 : loss : 0.022243, loss_ce: 0.008649
2022-01-08 16:55:15,342 iteration 2763 : loss : 0.043938, loss_ce: 0.014705
2022-01-08 16:55:17,666 iteration 2764 : loss : 0.027801, loss_ce: 0.010431
2022-01-08 16:55:20,219 iteration 2765 : loss : 0.045741, loss_ce: 0.018020
2022-01-08 16:55:22,613 iteration 2766 : loss : 0.025767, loss_ce: 0.009895
2022-01-08 16:55:25,029 iteration 2767 : loss : 0.025445, loss_ce: 0.008651
2022-01-08 16:55:27,395 iteration 2768 : loss : 0.020981, loss_ce: 0.006006
2022-01-08 16:55:29,782 iteration 2769 : loss : 0.020771, loss_ce: 0.008434
2022-01-08 16:55:32,239 iteration 2770 : loss : 0.035807, loss_ce: 0.018456
2022-01-08 16:55:34,733 iteration 2771 : loss : 0.027130, loss_ce: 0.009671
 41%|███████████                | 163/400 [1:55:41<2:49:29, 42.91s/it]2022-01-08 16:55:37,193 iteration 2772 : loss : 0.029940, loss_ce: 0.012699
2022-01-08 16:55:39,464 iteration 2773 : loss : 0.020920, loss_ce: 0.008470
2022-01-08 16:55:41,766 iteration 2774 : loss : 0.033946, loss_ce: 0.009459
2022-01-08 16:55:44,118 iteration 2775 : loss : 0.026311, loss_ce: 0.009328
2022-01-08 16:55:46,502 iteration 2776 : loss : 0.022607, loss_ce: 0.008229
2022-01-08 16:55:48,904 iteration 2777 : loss : 0.024199, loss_ce: 0.009034
2022-01-08 16:55:51,328 iteration 2778 : loss : 0.042121, loss_ce: 0.017823
2022-01-08 16:55:53,780 iteration 2779 : loss : 0.033708, loss_ce: 0.011583
2022-01-08 16:55:56,123 iteration 2780 : loss : 0.021764, loss_ce: 0.007137
2022-01-08 16:55:58,542 iteration 2781 : loss : 0.034861, loss_ce: 0.011917
2022-01-08 16:56:01,158 iteration 2782 : loss : 0.023777, loss_ce: 0.008280
2022-01-08 16:56:03,533 iteration 2783 : loss : 0.042337, loss_ce: 0.020782
2022-01-08 16:56:05,986 iteration 2784 : loss : 0.030599, loss_ce: 0.011446
2022-01-08 16:56:08,398 iteration 2785 : loss : 0.035255, loss_ce: 0.010262
2022-01-08 16:56:10,823 iteration 2786 : loss : 0.029936, loss_ce: 0.012217
2022-01-08 16:56:13,401 iteration 2787 : loss : 0.022132, loss_ce: 0.009896
2022-01-08 16:56:15,791 iteration 2788 : loss : 0.020386, loss_ce: 0.010378
 41%|███████████                | 164/400 [1:56:22<2:46:34, 42.35s/it]2022-01-08 16:56:18,191 iteration 2789 : loss : 0.028121, loss_ce: 0.010094
2022-01-08 16:56:20,613 iteration 2790 : loss : 0.026240, loss_ce: 0.009475
2022-01-08 16:56:23,010 iteration 2791 : loss : 0.028796, loss_ce: 0.011997
2022-01-08 16:56:25,463 iteration 2792 : loss : 0.042191, loss_ce: 0.016500
2022-01-08 16:56:27,813 iteration 2793 : loss : 0.026627, loss_ce: 0.010592
2022-01-08 16:56:30,236 iteration 2794 : loss : 0.027654, loss_ce: 0.009361
2022-01-08 16:56:32,614 iteration 2795 : loss : 0.019737, loss_ce: 0.006484
2022-01-08 16:56:35,024 iteration 2796 : loss : 0.030271, loss_ce: 0.011930
2022-01-08 16:56:37,420 iteration 2797 : loss : 0.028440, loss_ce: 0.011240
2022-01-08 16:56:39,860 iteration 2798 : loss : 0.036526, loss_ce: 0.018130
2022-01-08 16:56:42,231 iteration 2799 : loss : 0.021852, loss_ce: 0.009080
2022-01-08 16:56:44,597 iteration 2800 : loss : 0.031448, loss_ce: 0.011607
2022-01-08 16:56:47,079 iteration 2801 : loss : 0.017591, loss_ce: 0.005806
2022-01-08 16:56:49,505 iteration 2802 : loss : 0.036627, loss_ce: 0.011919
2022-01-08 16:56:51,840 iteration 2803 : loss : 0.020771, loss_ce: 0.008529
2022-01-08 16:56:54,334 iteration 2804 : loss : 0.020425, loss_ce: 0.007014
2022-01-08 16:56:54,335 Training Data Eval:
2022-01-08 16:57:07,302   Average segmentation loss on training set: 0.0176
2022-01-08 16:57:07,303 Validation Data Eval:
2022-01-08 16:57:11,796   Average segmentation loss on validation set: 0.0882
2022-01-08 16:57:14,181 iteration 2805 : loss : 0.022310, loss_ce: 0.008403
 41%|███████████▏               | 165/400 [1:57:21<3:04:42, 47.16s/it]2022-01-08 16:57:16,643 iteration 2806 : loss : 0.031712, loss_ce: 0.013798
2022-01-08 16:57:18,875 iteration 2807 : loss : 0.022027, loss_ce: 0.007781
2022-01-08 16:57:21,353 iteration 2808 : loss : 0.020006, loss_ce: 0.007912
2022-01-08 16:57:23,757 iteration 2809 : loss : 0.018692, loss_ce: 0.006289
2022-01-08 16:57:26,106 iteration 2810 : loss : 0.028704, loss_ce: 0.013096
2022-01-08 16:57:28,581 iteration 2811 : loss : 0.028126, loss_ce: 0.009250
2022-01-08 16:57:31,022 iteration 2812 : loss : 0.033298, loss_ce: 0.015868
2022-01-08 16:57:33,319 iteration 2813 : loss : 0.021346, loss_ce: 0.008071
2022-01-08 16:57:35,723 iteration 2814 : loss : 0.024733, loss_ce: 0.012236
2022-01-08 16:57:38,110 iteration 2815 : loss : 0.028104, loss_ce: 0.010596
2022-01-08 16:57:40,389 iteration 2816 : loss : 0.017972, loss_ce: 0.006275
2022-01-08 16:57:42,695 iteration 2817 : loss : 0.032938, loss_ce: 0.012440
2022-01-08 16:57:45,141 iteration 2818 : loss : 0.027316, loss_ce: 0.009402
2022-01-08 16:57:47,510 iteration 2819 : loss : 0.028222, loss_ce: 0.013185
2022-01-08 16:57:49,865 iteration 2820 : loss : 0.023069, loss_ce: 0.008868
2022-01-08 16:57:52,265 iteration 2821 : loss : 0.017237, loss_ce: 0.006443
2022-01-08 16:57:54,689 iteration 2822 : loss : 0.040433, loss_ce: 0.007799
 42%|███████████▏               | 166/400 [1:58:01<2:56:08, 45.17s/it]2022-01-08 16:57:57,168 iteration 2823 : loss : 0.023868, loss_ce: 0.009024
2022-01-08 16:57:59,510 iteration 2824 : loss : 0.031315, loss_ce: 0.009099
2022-01-08 16:58:01,991 iteration 2825 : loss : 0.025550, loss_ce: 0.008747
2022-01-08 16:58:04,376 iteration 2826 : loss : 0.017274, loss_ce: 0.005830
2022-01-08 16:58:06,764 iteration 2827 : loss : 0.039024, loss_ce: 0.015908
2022-01-08 16:58:09,124 iteration 2828 : loss : 0.033515, loss_ce: 0.013599
2022-01-08 16:58:11,443 iteration 2829 : loss : 0.030760, loss_ce: 0.009641
2022-01-08 16:58:13,783 iteration 2830 : loss : 0.023196, loss_ce: 0.009771
2022-01-08 16:58:16,283 iteration 2831 : loss : 0.041830, loss_ce: 0.014636
2022-01-08 16:58:18,645 iteration 2832 : loss : 0.021044, loss_ce: 0.008727
2022-01-08 16:58:21,088 iteration 2833 : loss : 0.027704, loss_ce: 0.011587
2022-01-08 16:58:23,457 iteration 2834 : loss : 0.025576, loss_ce: 0.010214
2022-01-08 16:58:25,873 iteration 2835 : loss : 0.036076, loss_ce: 0.013915
2022-01-08 16:58:28,218 iteration 2836 : loss : 0.029536, loss_ce: 0.010550
2022-01-08 16:58:30,624 iteration 2837 : loss : 0.021422, loss_ce: 0.007085
2022-01-08 16:58:33,055 iteration 2838 : loss : 0.031596, loss_ce: 0.010978
2022-01-08 16:58:35,402 iteration 2839 : loss : 0.019625, loss_ce: 0.008061
 42%|███████████▎               | 167/400 [1:58:42<2:50:12, 43.83s/it]2022-01-08 16:58:37,836 iteration 2840 : loss : 0.028044, loss_ce: 0.009425
2022-01-08 16:58:40,156 iteration 2841 : loss : 0.020162, loss_ce: 0.008351
2022-01-08 16:58:42,458 iteration 2842 : loss : 0.018839, loss_ce: 0.006426
2022-01-08 16:58:44,819 iteration 2843 : loss : 0.030754, loss_ce: 0.009936
2022-01-08 16:58:47,250 iteration 2844 : loss : 0.030416, loss_ce: 0.013723
2022-01-08 16:58:49,731 iteration 2845 : loss : 0.029369, loss_ce: 0.010005
2022-01-08 16:58:52,175 iteration 2846 : loss : 0.016874, loss_ce: 0.005357
2022-01-08 16:58:54,663 iteration 2847 : loss : 0.028057, loss_ce: 0.012242
2022-01-08 16:58:57,153 iteration 2848 : loss : 0.033422, loss_ce: 0.016434
2022-01-08 16:58:59,546 iteration 2849 : loss : 0.025832, loss_ce: 0.008298
2022-01-08 16:59:01,942 iteration 2850 : loss : 0.023076, loss_ce: 0.008191
2022-01-08 16:59:04,336 iteration 2851 : loss : 0.034950, loss_ce: 0.019059
2022-01-08 16:59:06,694 iteration 2852 : loss : 0.033118, loss_ce: 0.017768
2022-01-08 16:59:09,043 iteration 2853 : loss : 0.021272, loss_ce: 0.008612
2022-01-08 16:59:11,433 iteration 2854 : loss : 0.030734, loss_ce: 0.013769
2022-01-08 16:59:13,799 iteration 2855 : loss : 0.028302, loss_ce: 0.011280
2022-01-08 16:59:16,222 iteration 2856 : loss : 0.021052, loss_ce: 0.007722
 42%|███████████▎               | 168/400 [1:59:23<2:45:58, 42.93s/it]2022-01-08 16:59:18,745 iteration 2857 : loss : 0.026724, loss_ce: 0.006272
2022-01-08 16:59:21,172 iteration 2858 : loss : 0.028677, loss_ce: 0.008774
2022-01-08 16:59:23,543 iteration 2859 : loss : 0.019330, loss_ce: 0.006232
2022-01-08 16:59:25,956 iteration 2860 : loss : 0.028605, loss_ce: 0.011753
2022-01-08 16:59:28,473 iteration 2861 : loss : 0.021786, loss_ce: 0.008200
2022-01-08 16:59:30,890 iteration 2862 : loss : 0.022770, loss_ce: 0.007721
2022-01-08 16:59:33,281 iteration 2863 : loss : 0.050834, loss_ce: 0.017818
2022-01-08 16:59:35,671 iteration 2864 : loss : 0.023832, loss_ce: 0.009356
2022-01-08 16:59:37,990 iteration 2865 : loss : 0.021999, loss_ce: 0.008549
2022-01-08 16:59:40,355 iteration 2866 : loss : 0.022410, loss_ce: 0.006625
2022-01-08 16:59:42,972 iteration 2867 : loss : 0.022029, loss_ce: 0.008184
2022-01-08 16:59:45,427 iteration 2868 : loss : 0.028351, loss_ce: 0.010255
2022-01-08 16:59:47,788 iteration 2869 : loss : 0.023074, loss_ce: 0.010171
2022-01-08 16:59:50,350 iteration 2870 : loss : 0.029781, loss_ce: 0.014757
2022-01-08 16:59:52,721 iteration 2871 : loss : 0.020499, loss_ce: 0.009709
2022-01-08 16:59:55,094 iteration 2872 : loss : 0.032495, loss_ce: 0.012105
2022-01-08 16:59:57,459 iteration 2873 : loss : 0.033419, loss_ce: 0.018659
 42%|███████████▍               | 169/400 [2:00:04<2:43:18, 42.42s/it]2022-01-08 16:59:59,897 iteration 2874 : loss : 0.025523, loss_ce: 0.007056
2022-01-08 17:00:02,208 iteration 2875 : loss : 0.019238, loss_ce: 0.007650
2022-01-08 17:00:04,625 iteration 2876 : loss : 0.018954, loss_ce: 0.007933
2022-01-08 17:00:07,018 iteration 2877 : loss : 0.020708, loss_ce: 0.007684
2022-01-08 17:00:09,399 iteration 2878 : loss : 0.029638, loss_ce: 0.010258
2022-01-08 17:00:11,792 iteration 2879 : loss : 0.022363, loss_ce: 0.010780
2022-01-08 17:00:14,254 iteration 2880 : loss : 0.043298, loss_ce: 0.019612
2022-01-08 17:00:16,659 iteration 2881 : loss : 0.028342, loss_ce: 0.013965
2022-01-08 17:00:19,118 iteration 2882 : loss : 0.032034, loss_ce: 0.009385
2022-01-08 17:00:21,600 iteration 2883 : loss : 0.042365, loss_ce: 0.019674
2022-01-08 17:00:24,128 iteration 2884 : loss : 0.028038, loss_ce: 0.008539
2022-01-08 17:00:26,622 iteration 2885 : loss : 0.031293, loss_ce: 0.016145
2022-01-08 17:00:29,028 iteration 2886 : loss : 0.024668, loss_ce: 0.006040
2022-01-08 17:00:31,433 iteration 2887 : loss : 0.023650, loss_ce: 0.008141
2022-01-08 17:00:33,971 iteration 2888 : loss : 0.030883, loss_ce: 0.012324
2022-01-08 17:00:36,457 iteration 2889 : loss : 0.032921, loss_ce: 0.016946
2022-01-08 17:00:36,457 Training Data Eval:
2022-01-08 17:00:49,388   Average segmentation loss on training set: 0.0169
2022-01-08 17:00:49,388 Validation Data Eval:
2022-01-08 17:00:53,734   Average segmentation loss on validation set: 0.0735
2022-01-08 17:00:56,191 iteration 2890 : loss : 0.034887, loss_ce: 0.013565
 42%|███████████▍               | 170/400 [2:01:03<3:01:22, 47.31s/it]2022-01-08 17:00:58,736 iteration 2891 : loss : 0.028630, loss_ce: 0.013491
2022-01-08 17:01:01,103 iteration 2892 : loss : 0.020851, loss_ce: 0.010456
2022-01-08 17:01:03,449 iteration 2893 : loss : 0.033061, loss_ce: 0.010132
2022-01-08 17:01:05,821 iteration 2894 : loss : 0.017394, loss_ce: 0.006940
2022-01-08 17:01:08,140 iteration 2895 : loss : 0.025439, loss_ce: 0.007657
2022-01-08 17:01:10,505 iteration 2896 : loss : 0.021765, loss_ce: 0.008092
2022-01-08 17:01:12,878 iteration 2897 : loss : 0.024296, loss_ce: 0.008645
2022-01-08 17:01:15,350 iteration 2898 : loss : 0.037177, loss_ce: 0.022601
2022-01-08 17:01:17,779 iteration 2899 : loss : 0.036555, loss_ce: 0.013364
2022-01-08 17:01:20,076 iteration 2900 : loss : 0.024452, loss_ce: 0.007884
2022-01-08 17:01:22,538 iteration 2901 : loss : 0.028928, loss_ce: 0.008783
2022-01-08 17:01:25,010 iteration 2902 : loss : 0.018541, loss_ce: 0.006031
2022-01-08 17:01:27,460 iteration 2903 : loss : 0.023764, loss_ce: 0.009851
2022-01-08 17:01:29,877 iteration 2904 : loss : 0.038615, loss_ce: 0.011902
2022-01-08 17:01:32,199 iteration 2905 : loss : 0.022928, loss_ce: 0.008559
2022-01-08 17:01:34,643 iteration 2906 : loss : 0.028339, loss_ce: 0.009812
2022-01-08 17:01:37,035 iteration 2907 : loss : 0.018697, loss_ce: 0.007411
 43%|███████████▌               | 171/400 [2:01:43<2:53:10, 45.37s/it]2022-01-08 17:01:39,481 iteration 2908 : loss : 0.024554, loss_ce: 0.009131
2022-01-08 17:01:41,816 iteration 2909 : loss : 0.024003, loss_ce: 0.005706
2022-01-08 17:01:44,243 iteration 2910 : loss : 0.027364, loss_ce: 0.009851
2022-01-08 17:01:46,603 iteration 2911 : loss : 0.024204, loss_ce: 0.009734
2022-01-08 17:01:49,006 iteration 2912 : loss : 0.024030, loss_ce: 0.007987
2022-01-08 17:01:51,562 iteration 2913 : loss : 0.021264, loss_ce: 0.007828
2022-01-08 17:01:53,966 iteration 2914 : loss : 0.029773, loss_ce: 0.011862
2022-01-08 17:01:56,330 iteration 2915 : loss : 0.024539, loss_ce: 0.008725
2022-01-08 17:01:58,624 iteration 2916 : loss : 0.020586, loss_ce: 0.011103
2022-01-08 17:02:00,995 iteration 2917 : loss : 0.027985, loss_ce: 0.013212
2022-01-08 17:02:03,408 iteration 2918 : loss : 0.026398, loss_ce: 0.008922
2022-01-08 17:02:05,746 iteration 2919 : loss : 0.035046, loss_ce: 0.016464
2022-01-08 17:02:08,101 iteration 2920 : loss : 0.032536, loss_ce: 0.007996
2022-01-08 17:02:10,579 iteration 2921 : loss : 0.022454, loss_ce: 0.006633
2022-01-08 17:02:12,986 iteration 2922 : loss : 0.023431, loss_ce: 0.009398
2022-01-08 17:02:15,384 iteration 2923 : loss : 0.024586, loss_ce: 0.009680
2022-01-08 17:02:17,661 iteration 2924 : loss : 0.024512, loss_ce: 0.007835
 43%|███████████▌               | 172/400 [2:02:24<2:47:01, 43.95s/it]2022-01-08 17:02:20,042 iteration 2925 : loss : 0.037547, loss_ce: 0.017665
2022-01-08 17:02:22,304 iteration 2926 : loss : 0.021290, loss_ce: 0.006806
2022-01-08 17:02:24,668 iteration 2927 : loss : 0.029663, loss_ce: 0.013403
2022-01-08 17:02:27,113 iteration 2928 : loss : 0.055779, loss_ce: 0.022550
2022-01-08 17:02:29,328 iteration 2929 : loss : 0.019214, loss_ce: 0.006077
2022-01-08 17:02:31,624 iteration 2930 : loss : 0.034170, loss_ce: 0.016653
2022-01-08 17:02:33,868 iteration 2931 : loss : 0.031486, loss_ce: 0.011996
2022-01-08 17:02:36,241 iteration 2932 : loss : 0.019663, loss_ce: 0.007426
2022-01-08 17:02:38,479 iteration 2933 : loss : 0.024027, loss_ce: 0.008864
2022-01-08 17:02:40,833 iteration 2934 : loss : 0.024954, loss_ce: 0.010808
2022-01-08 17:02:43,170 iteration 2935 : loss : 0.036296, loss_ce: 0.012170
2022-01-08 17:02:45,557 iteration 2936 : loss : 0.025138, loss_ce: 0.012369
2022-01-08 17:02:47,874 iteration 2937 : loss : 0.019041, loss_ce: 0.007869
2022-01-08 17:02:50,302 iteration 2938 : loss : 0.023258, loss_ce: 0.008772
2022-01-08 17:02:52,670 iteration 2939 : loss : 0.021356, loss_ce: 0.009518
2022-01-08 17:02:55,023 iteration 2940 : loss : 0.026344, loss_ce: 0.008464
2022-01-08 17:02:57,367 iteration 2941 : loss : 0.028262, loss_ce: 0.009923
 43%|███████████▋               | 173/400 [2:03:04<2:41:27, 42.68s/it]2022-01-08 17:02:59,725 iteration 2942 : loss : 0.024802, loss_ce: 0.009509
2022-01-08 17:03:01,972 iteration 2943 : loss : 0.019230, loss_ce: 0.007530
2022-01-08 17:03:04,331 iteration 2944 : loss : 0.025573, loss_ce: 0.008871
2022-01-08 17:03:06,738 iteration 2945 : loss : 0.030327, loss_ce: 0.013013
2022-01-08 17:03:09,205 iteration 2946 : loss : 0.021097, loss_ce: 0.008912
2022-01-08 17:03:11,576 iteration 2947 : loss : 0.015740, loss_ce: 0.005216
2022-01-08 17:03:13,908 iteration 2948 : loss : 0.024279, loss_ce: 0.009616
2022-01-08 17:03:16,256 iteration 2949 : loss : 0.031586, loss_ce: 0.013487
2022-01-08 17:03:18,591 iteration 2950 : loss : 0.022712, loss_ce: 0.009810
2022-01-08 17:03:21,092 iteration 2951 : loss : 0.024906, loss_ce: 0.008561
2022-01-08 17:03:23,473 iteration 2952 : loss : 0.026479, loss_ce: 0.007080
2022-01-08 17:03:25,773 iteration 2953 : loss : 0.031936, loss_ce: 0.013127
2022-01-08 17:03:28,069 iteration 2954 : loss : 0.032481, loss_ce: 0.011085
2022-01-08 17:03:30,337 iteration 2955 : loss : 0.018820, loss_ce: 0.008307
2022-01-08 17:03:32,676 iteration 2956 : loss : 0.021314, loss_ce: 0.009816
2022-01-08 17:03:34,955 iteration 2957 : loss : 0.029311, loss_ce: 0.007071
2022-01-08 17:03:37,256 iteration 2958 : loss : 0.037085, loss_ce: 0.014103
 44%|███████████▋               | 174/400 [2:03:44<2:37:35, 41.84s/it]2022-01-08 17:03:39,672 iteration 2959 : loss : 0.021640, loss_ce: 0.009992
2022-01-08 17:03:42,058 iteration 2960 : loss : 0.037563, loss_ce: 0.012730
2022-01-08 17:03:44,381 iteration 2961 : loss : 0.023425, loss_ce: 0.011370
2022-01-08 17:03:46,553 iteration 2962 : loss : 0.020315, loss_ce: 0.006228
2022-01-08 17:03:48,849 iteration 2963 : loss : 0.026685, loss_ce: 0.009386
2022-01-08 17:03:51,136 iteration 2964 : loss : 0.052909, loss_ce: 0.017878
2022-01-08 17:03:53,342 iteration 2965 : loss : 0.020789, loss_ce: 0.008600
2022-01-08 17:03:55,568 iteration 2966 : loss : 0.030461, loss_ce: 0.008416
2022-01-08 17:03:58,001 iteration 2967 : loss : 0.048397, loss_ce: 0.017951
2022-01-08 17:04:00,314 iteration 2968 : loss : 0.032838, loss_ce: 0.012663
2022-01-08 17:04:02,682 iteration 2969 : loss : 0.023739, loss_ce: 0.006933
2022-01-08 17:04:05,082 iteration 2970 : loss : 0.022004, loss_ce: 0.008796
2022-01-08 17:04:07,488 iteration 2971 : loss : 0.032816, loss_ce: 0.011156
2022-01-08 17:04:09,834 iteration 2972 : loss : 0.021282, loss_ce: 0.007807
2022-01-08 17:04:12,090 iteration 2973 : loss : 0.023190, loss_ce: 0.010712
2022-01-08 17:04:14,423 iteration 2974 : loss : 0.040026, loss_ce: 0.015585
2022-01-08 17:04:14,424 Training Data Eval:
2022-01-08 17:04:27,078   Average segmentation loss on training set: 0.0199
2022-01-08 17:04:27,079 Validation Data Eval:
2022-01-08 17:04:31,470   Average segmentation loss on validation set: 0.0820
2022-01-08 17:04:33,869 iteration 2975 : loss : 0.042366, loss_ce: 0.013056
 44%|███████████▊               | 175/400 [2:04:40<2:53:31, 46.27s/it]2022-01-08 17:04:36,314 iteration 2976 : loss : 0.028080, loss_ce: 0.011584
2022-01-08 17:04:38,719 iteration 2977 : loss : 0.027789, loss_ce: 0.010810
2022-01-08 17:04:40,963 iteration 2978 : loss : 0.028873, loss_ce: 0.011885
2022-01-08 17:04:43,245 iteration 2979 : loss : 0.033365, loss_ce: 0.008636
2022-01-08 17:04:45,664 iteration 2980 : loss : 0.037012, loss_ce: 0.014949
2022-01-08 17:04:47,930 iteration 2981 : loss : 0.024803, loss_ce: 0.010962
2022-01-08 17:04:50,147 iteration 2982 : loss : 0.031146, loss_ce: 0.012004
2022-01-08 17:04:52,423 iteration 2983 : loss : 0.022334, loss_ce: 0.006274
2022-01-08 17:04:54,806 iteration 2984 : loss : 0.028996, loss_ce: 0.014296
2022-01-08 17:04:57,115 iteration 2985 : loss : 0.023053, loss_ce: 0.010814
2022-01-08 17:04:59,497 iteration 2986 : loss : 0.025195, loss_ce: 0.009308
2022-01-08 17:05:01,801 iteration 2987 : loss : 0.027095, loss_ce: 0.010334
2022-01-08 17:05:04,254 iteration 2988 : loss : 0.035304, loss_ce: 0.012260
2022-01-08 17:05:06,612 iteration 2989 : loss : 0.020447, loss_ce: 0.007418
2022-01-08 17:05:08,964 iteration 2990 : loss : 0.029218, loss_ce: 0.012655
2022-01-08 17:05:11,239 iteration 2991 : loss : 0.023629, loss_ce: 0.006998
2022-01-08 17:05:13,610 iteration 2992 : loss : 0.022635, loss_ce: 0.010043
 44%|███████████▉               | 176/400 [2:05:20<2:45:26, 44.31s/it]2022-01-08 17:05:16,001 iteration 2993 : loss : 0.031681, loss_ce: 0.013366
2022-01-08 17:05:18,381 iteration 2994 : loss : 0.024747, loss_ce: 0.009628
2022-01-08 17:05:20,785 iteration 2995 : loss : 0.038242, loss_ce: 0.015426
2022-01-08 17:05:23,054 iteration 2996 : loss : 0.033458, loss_ce: 0.015429
2022-01-08 17:05:25,382 iteration 2997 : loss : 0.022328, loss_ce: 0.006982
2022-01-08 17:05:27,770 iteration 2998 : loss : 0.020440, loss_ce: 0.009106
2022-01-08 17:05:30,054 iteration 2999 : loss : 0.040510, loss_ce: 0.015449
2022-01-08 17:05:32,355 iteration 3000 : loss : 0.019595, loss_ce: 0.007105
2022-01-08 17:05:34,740 iteration 3001 : loss : 0.031671, loss_ce: 0.012281
2022-01-08 17:05:37,113 iteration 3002 : loss : 0.028658, loss_ce: 0.011902
2022-01-08 17:05:39,404 iteration 3003 : loss : 0.020955, loss_ce: 0.008614
2022-01-08 17:05:41,788 iteration 3004 : loss : 0.020698, loss_ce: 0.010179
2022-01-08 17:05:44,111 iteration 3005 : loss : 0.024587, loss_ce: 0.010049
2022-01-08 17:05:46,365 iteration 3006 : loss : 0.026475, loss_ce: 0.010363
2022-01-08 17:05:48,681 iteration 3007 : loss : 0.021822, loss_ce: 0.007502
2022-01-08 17:05:51,018 iteration 3008 : loss : 0.022486, loss_ce: 0.007791
2022-01-08 17:05:53,321 iteration 3009 : loss : 0.022430, loss_ce: 0.005491
 44%|███████████▉               | 177/400 [2:06:00<2:39:33, 42.93s/it]2022-01-08 17:05:55,767 iteration 3010 : loss : 0.024529, loss_ce: 0.009403
2022-01-08 17:05:58,070 iteration 3011 : loss : 0.041128, loss_ce: 0.012665
2022-01-08 17:06:00,399 iteration 3012 : loss : 0.034283, loss_ce: 0.011315
2022-01-08 17:06:02,834 iteration 3013 : loss : 0.026715, loss_ce: 0.008556
2022-01-08 17:06:05,172 iteration 3014 : loss : 0.024590, loss_ce: 0.010244
2022-01-08 17:06:07,465 iteration 3015 : loss : 0.027645, loss_ce: 0.008380
2022-01-08 17:06:09,723 iteration 3016 : loss : 0.019925, loss_ce: 0.006222
2022-01-08 17:06:12,093 iteration 3017 : loss : 0.043113, loss_ce: 0.026671
2022-01-08 17:06:14,433 iteration 3018 : loss : 0.025069, loss_ce: 0.012827
2022-01-08 17:06:16,881 iteration 3019 : loss : 0.032399, loss_ce: 0.012605
2022-01-08 17:06:19,178 iteration 3020 : loss : 0.025658, loss_ce: 0.007710
2022-01-08 17:06:21,556 iteration 3021 : loss : 0.024391, loss_ce: 0.009492
2022-01-08 17:06:23,921 iteration 3022 : loss : 0.018006, loss_ce: 0.008250
2022-01-08 17:06:26,386 iteration 3023 : loss : 0.019309, loss_ce: 0.006877
2022-01-08 17:06:28,818 iteration 3024 : loss : 0.027672, loss_ce: 0.011420
2022-01-08 17:06:31,186 iteration 3025 : loss : 0.026426, loss_ce: 0.010812
2022-01-08 17:06:33,528 iteration 3026 : loss : 0.028425, loss_ce: 0.007743
 44%|████████████               | 178/400 [2:06:40<2:35:49, 42.11s/it]2022-01-08 17:06:36,005 iteration 3027 : loss : 0.027625, loss_ce: 0.012209
2022-01-08 17:06:38,448 iteration 3028 : loss : 0.032816, loss_ce: 0.012628
2022-01-08 17:06:40,737 iteration 3029 : loss : 0.015681, loss_ce: 0.005039
2022-01-08 17:06:43,191 iteration 3030 : loss : 0.020807, loss_ce: 0.006161
2022-01-08 17:06:45,568 iteration 3031 : loss : 0.032723, loss_ce: 0.012777
2022-01-08 17:06:47,911 iteration 3032 : loss : 0.023669, loss_ce: 0.008622
2022-01-08 17:06:50,300 iteration 3033 : loss : 0.025342, loss_ce: 0.008404
2022-01-08 17:06:52,700 iteration 3034 : loss : 0.023225, loss_ce: 0.006273
2022-01-08 17:06:55,071 iteration 3035 : loss : 0.022575, loss_ce: 0.008871
2022-01-08 17:06:57,500 iteration 3036 : loss : 0.025697, loss_ce: 0.012429
2022-01-08 17:06:59,873 iteration 3037 : loss : 0.023340, loss_ce: 0.010151
2022-01-08 17:07:02,392 iteration 3038 : loss : 0.024082, loss_ce: 0.011574
2022-01-08 17:07:04,812 iteration 3039 : loss : 0.022806, loss_ce: 0.009342
2022-01-08 17:07:07,275 iteration 3040 : loss : 0.028836, loss_ce: 0.007950
2022-01-08 17:07:09,516 iteration 3041 : loss : 0.018999, loss_ce: 0.007419
2022-01-08 17:07:11,798 iteration 3042 : loss : 0.028314, loss_ce: 0.013021
2022-01-08 17:07:14,163 iteration 3043 : loss : 0.022617, loss_ce: 0.008528
 45%|████████████               | 179/400 [2:07:21<2:33:29, 41.67s/it]2022-01-08 17:07:16,643 iteration 3044 : loss : 0.023531, loss_ce: 0.008552
2022-01-08 17:07:18,918 iteration 3045 : loss : 0.022513, loss_ce: 0.007609
2022-01-08 17:07:21,374 iteration 3046 : loss : 0.023533, loss_ce: 0.010469
2022-01-08 17:07:23,873 iteration 3047 : loss : 0.023003, loss_ce: 0.007977
2022-01-08 17:07:26,309 iteration 3048 : loss : 0.027885, loss_ce: 0.010004
2022-01-08 17:07:28,727 iteration 3049 : loss : 0.020950, loss_ce: 0.006704
2022-01-08 17:07:31,183 iteration 3050 : loss : 0.024096, loss_ce: 0.005761
2022-01-08 17:07:33,596 iteration 3051 : loss : 0.020772, loss_ce: 0.007964
2022-01-08 17:07:36,009 iteration 3052 : loss : 0.028819, loss_ce: 0.013075
2022-01-08 17:07:38,364 iteration 3053 : loss : 0.016855, loss_ce: 0.005736
2022-01-08 17:07:40,733 iteration 3054 : loss : 0.025994, loss_ce: 0.011473
2022-01-08 17:07:43,027 iteration 3055 : loss : 0.030625, loss_ce: 0.013774
2022-01-08 17:07:45,466 iteration 3056 : loss : 0.018371, loss_ce: 0.005738
2022-01-08 17:07:48,025 iteration 3057 : loss : 0.025514, loss_ce: 0.009708
2022-01-08 17:07:50,363 iteration 3058 : loss : 0.019625, loss_ce: 0.006378
2022-01-08 17:07:52,740 iteration 3059 : loss : 0.023662, loss_ce: 0.013648
2022-01-08 17:07:52,740 Training Data Eval:
2022-01-08 17:08:05,723   Average segmentation loss on training set: 0.0154
2022-01-08 17:08:05,724 Validation Data Eval:
2022-01-08 17:08:10,276   Average segmentation loss on validation set: 0.0674
2022-01-08 17:08:12,722 iteration 3060 : loss : 0.024104, loss_ce: 0.009772
 45%|████████████▏              | 180/400 [2:08:19<2:51:21, 46.74s/it]2022-01-08 17:08:15,103 iteration 3061 : loss : 0.018852, loss_ce: 0.005638
2022-01-08 17:08:17,625 iteration 3062 : loss : 0.029515, loss_ce: 0.013783
2022-01-08 17:08:20,021 iteration 3063 : loss : 0.022901, loss_ce: 0.008447
2022-01-08 17:08:22,449 iteration 3064 : loss : 0.026220, loss_ce: 0.013664
2022-01-08 17:08:24,865 iteration 3065 : loss : 0.025895, loss_ce: 0.006993
2022-01-08 17:08:27,275 iteration 3066 : loss : 0.020611, loss_ce: 0.006312
2022-01-08 17:08:29,718 iteration 3067 : loss : 0.023210, loss_ce: 0.009680
2022-01-08 17:08:32,179 iteration 3068 : loss : 0.024158, loss_ce: 0.009752
2022-01-08 17:08:34,528 iteration 3069 : loss : 0.011811, loss_ce: 0.004516
2022-01-08 17:08:36,915 iteration 3070 : loss : 0.024270, loss_ce: 0.008035
2022-01-08 17:08:39,393 iteration 3071 : loss : 0.034260, loss_ce: 0.011743
2022-01-08 17:08:42,011 iteration 3072 : loss : 0.018212, loss_ce: 0.007580
2022-01-08 17:08:44,491 iteration 3073 : loss : 0.022487, loss_ce: 0.007358
2022-01-08 17:08:47,069 iteration 3074 : loss : 0.021696, loss_ce: 0.009358
2022-01-08 17:08:49,753 iteration 3075 : loss : 0.031408, loss_ce: 0.010770
2022-01-08 17:08:52,159 iteration 3076 : loss : 0.016457, loss_ce: 0.006191
2022-01-08 17:08:54,895 iteration 3077 : loss : 0.028500, loss_ce: 0.010369
 45%|████████████▏              | 181/400 [2:09:01<2:45:34, 45.36s/it]2022-01-08 17:08:57,560 iteration 3078 : loss : 0.029302, loss_ce: 0.006588
2022-01-08 17:08:59,961 iteration 3079 : loss : 0.019909, loss_ce: 0.005837
2022-01-08 17:09:02,618 iteration 3080 : loss : 0.021043, loss_ce: 0.006793
2022-01-08 17:09:05,180 iteration 3081 : loss : 0.028062, loss_ce: 0.011577
2022-01-08 17:09:07,803 iteration 3082 : loss : 0.024244, loss_ce: 0.008522
2022-01-08 17:09:10,424 iteration 3083 : loss : 0.038940, loss_ce: 0.011800
2022-01-08 17:09:13,125 iteration 3084 : loss : 0.028363, loss_ce: 0.010629
2022-01-08 17:09:15,649 iteration 3085 : loss : 0.026671, loss_ce: 0.009345
2022-01-08 17:09:18,439 iteration 3086 : loss : 0.029480, loss_ce: 0.014066
2022-01-08 17:09:20,976 iteration 3087 : loss : 0.023816, loss_ce: 0.009938
2022-01-08 17:09:23,596 iteration 3088 : loss : 0.024678, loss_ce: 0.011228
2022-01-08 17:09:26,317 iteration 3089 : loss : 0.038201, loss_ce: 0.014225
2022-01-08 17:09:28,903 iteration 3090 : loss : 0.019438, loss_ce: 0.007678
2022-01-08 17:09:31,504 iteration 3091 : loss : 0.034479, loss_ce: 0.014390
2022-01-08 17:09:34,169 iteration 3092 : loss : 0.025620, loss_ce: 0.009967
2022-01-08 17:09:36,811 iteration 3093 : loss : 0.019199, loss_ce: 0.007936
2022-01-08 17:09:39,541 iteration 3094 : loss : 0.033729, loss_ce: 0.008698
 46%|████████████▎              | 182/400 [2:09:46<2:44:02, 45.15s/it]2022-01-08 17:09:42,166 iteration 3095 : loss : 0.017241, loss_ce: 0.007084
2022-01-08 17:09:44,863 iteration 3096 : loss : 0.020771, loss_ce: 0.007466
2022-01-08 17:09:47,394 iteration 3097 : loss : 0.021022, loss_ce: 0.008721
2022-01-08 17:09:50,052 iteration 3098 : loss : 0.031935, loss_ce: 0.008946
2022-01-08 17:09:52,845 iteration 3099 : loss : 0.040853, loss_ce: 0.020180
2022-01-08 17:09:55,445 iteration 3100 : loss : 0.020814, loss_ce: 0.007061
2022-01-08 17:09:57,973 iteration 3101 : loss : 0.017528, loss_ce: 0.006234
2022-01-08 17:10:00,616 iteration 3102 : loss : 0.020075, loss_ce: 0.007486
2022-01-08 17:10:03,304 iteration 3103 : loss : 0.034550, loss_ce: 0.016990
2022-01-08 17:10:05,887 iteration 3104 : loss : 0.032428, loss_ce: 0.010306
2022-01-08 17:10:08,643 iteration 3105 : loss : 0.027662, loss_ce: 0.011840
2022-01-08 17:10:11,309 iteration 3106 : loss : 0.021158, loss_ce: 0.008060
2022-01-08 17:10:14,124 iteration 3107 : loss : 0.026617, loss_ce: 0.011962
2022-01-08 17:10:16,611 iteration 3108 : loss : 0.032192, loss_ce: 0.012157
2022-01-08 17:10:19,181 iteration 3109 : loss : 0.019726, loss_ce: 0.008746
2022-01-08 17:10:21,771 iteration 3110 : loss : 0.027179, loss_ce: 0.009574
2022-01-08 17:10:24,349 iteration 3111 : loss : 0.033748, loss_ce: 0.009286
 46%|████████████▎              | 183/400 [2:10:31<2:42:55, 45.05s/it]2022-01-08 17:10:26,896 iteration 3112 : loss : 0.020076, loss_ce: 0.007478
2022-01-08 17:10:29,524 iteration 3113 : loss : 0.031284, loss_ce: 0.012626
2022-01-08 17:10:32,134 iteration 3114 : loss : 0.022837, loss_ce: 0.010499
2022-01-08 17:10:34,774 iteration 3115 : loss : 0.022869, loss_ce: 0.008193
2022-01-08 17:10:37,334 iteration 3116 : loss : 0.019761, loss_ce: 0.008119
2022-01-08 17:10:39,955 iteration 3117 : loss : 0.028732, loss_ce: 0.007195
2022-01-08 17:10:42,581 iteration 3118 : loss : 0.019804, loss_ce: 0.008667
2022-01-08 17:10:45,282 iteration 3119 : loss : 0.020267, loss_ce: 0.008502
2022-01-08 17:10:47,814 iteration 3120 : loss : 0.020502, loss_ce: 0.006099
2022-01-08 17:10:50,444 iteration 3121 : loss : 0.033969, loss_ce: 0.010691
2022-01-08 17:10:53,060 iteration 3122 : loss : 0.029143, loss_ce: 0.013843
2022-01-08 17:10:55,761 iteration 3123 : loss : 0.060898, loss_ce: 0.023933
2022-01-08 17:10:58,386 iteration 3124 : loss : 0.018450, loss_ce: 0.006775
2022-01-08 17:11:00,992 iteration 3125 : loss : 0.015210, loss_ce: 0.006519
2022-01-08 17:11:03,422 iteration 3126 : loss : 0.020113, loss_ce: 0.007167
2022-01-08 17:11:06,034 iteration 3127 : loss : 0.026891, loss_ce: 0.011191
2022-01-08 17:11:08,632 iteration 3128 : loss : 0.028014, loss_ce: 0.007830
 46%|████████████▍              | 184/400 [2:11:15<2:41:20, 44.82s/it]2022-01-08 17:11:11,310 iteration 3129 : loss : 0.024538, loss_ce: 0.008962
2022-01-08 17:11:13,764 iteration 3130 : loss : 0.020212, loss_ce: 0.007745
2022-01-08 17:11:16,320 iteration 3131 : loss : 0.030058, loss_ce: 0.015004
2022-01-08 17:11:18,900 iteration 3132 : loss : 0.025195, loss_ce: 0.008695
2022-01-08 17:11:21,363 iteration 3133 : loss : 0.019637, loss_ce: 0.007942
2022-01-08 17:11:23,906 iteration 3134 : loss : 0.033020, loss_ce: 0.014707
2022-01-08 17:11:26,550 iteration 3135 : loss : 0.035410, loss_ce: 0.008892
2022-01-08 17:11:29,053 iteration 3136 : loss : 0.018773, loss_ce: 0.008599
2022-01-08 17:11:31,611 iteration 3137 : loss : 0.018076, loss_ce: 0.007816
2022-01-08 17:11:34,168 iteration 3138 : loss : 0.022723, loss_ce: 0.008579
2022-01-08 17:11:36,841 iteration 3139 : loss : 0.031496, loss_ce: 0.009129
2022-01-08 17:11:39,397 iteration 3140 : loss : 0.026308, loss_ce: 0.009824
2022-01-08 17:11:41,847 iteration 3141 : loss : 0.023032, loss_ce: 0.010209
2022-01-08 17:11:44,289 iteration 3142 : loss : 0.018775, loss_ce: 0.007109
2022-01-08 17:11:46,913 iteration 3143 : loss : 0.033968, loss_ce: 0.009853
2022-01-08 17:11:49,459 iteration 3144 : loss : 0.029753, loss_ce: 0.006973
2022-01-08 17:11:49,459 Training Data Eval:
2022-01-08 17:12:03,158   Average segmentation loss on training set: 0.0154
2022-01-08 17:12:03,158 Validation Data Eval:
2022-01-08 17:12:07,933   Average segmentation loss on validation set: 0.0906
2022-01-08 17:12:10,332 iteration 3145 : loss : 0.024698, loss_ce: 0.012072
 46%|████████████▍              | 185/400 [2:12:17<2:58:44, 49.88s/it]2022-01-08 17:12:13,001 iteration 3146 : loss : 0.029162, loss_ce: 0.014818
2022-01-08 17:12:15,608 iteration 3147 : loss : 0.048184, loss_ce: 0.021334
2022-01-08 17:12:18,134 iteration 3148 : loss : 0.016918, loss_ce: 0.006602
2022-01-08 17:12:20,659 iteration 3149 : loss : 0.027192, loss_ce: 0.007626
2022-01-08 17:12:23,216 iteration 3150 : loss : 0.035410, loss_ce: 0.010369
2022-01-08 17:12:25,791 iteration 3151 : loss : 0.018991, loss_ce: 0.008425
2022-01-08 17:12:28,335 iteration 3152 : loss : 0.020900, loss_ce: 0.010092
2022-01-08 17:12:30,926 iteration 3153 : loss : 0.019785, loss_ce: 0.008688
2022-01-08 17:12:33,362 iteration 3154 : loss : 0.031266, loss_ce: 0.008275
2022-01-08 17:12:35,928 iteration 3155 : loss : 0.027835, loss_ce: 0.010021
2022-01-08 17:12:38,424 iteration 3156 : loss : 0.023793, loss_ce: 0.008280
2022-01-08 17:12:40,817 iteration 3157 : loss : 0.031189, loss_ce: 0.010703
2022-01-08 17:12:43,405 iteration 3158 : loss : 0.024077, loss_ce: 0.009349
2022-01-08 17:12:45,953 iteration 3159 : loss : 0.024786, loss_ce: 0.010929
2022-01-08 17:12:48,575 iteration 3160 : loss : 0.021950, loss_ce: 0.011471
2022-01-08 17:12:51,195 iteration 3161 : loss : 0.035099, loss_ce: 0.014221
2022-01-08 17:12:53,677 iteration 3162 : loss : 0.024381, loss_ce: 0.010553
 46%|████████████▌              | 186/400 [2:13:00<2:50:55, 47.92s/it]2022-01-08 17:12:56,178 iteration 3163 : loss : 0.032176, loss_ce: 0.011565
2022-01-08 17:12:58,766 iteration 3164 : loss : 0.021549, loss_ce: 0.005696
2022-01-08 17:13:01,177 iteration 3165 : loss : 0.014875, loss_ce: 0.006007
2022-01-08 17:13:03,715 iteration 3166 : loss : 0.026373, loss_ce: 0.012440
2022-01-08 17:13:06,214 iteration 3167 : loss : 0.033844, loss_ce: 0.011424
2022-01-08 17:13:08,744 iteration 3168 : loss : 0.021877, loss_ce: 0.011109
2022-01-08 17:13:11,314 iteration 3169 : loss : 0.023176, loss_ce: 0.007308
2022-01-08 17:13:13,718 iteration 3170 : loss : 0.030739, loss_ce: 0.012443
2022-01-08 17:13:16,241 iteration 3171 : loss : 0.029747, loss_ce: 0.009095
2022-01-08 17:13:18,880 iteration 3172 : loss : 0.029496, loss_ce: 0.012228
2022-01-08 17:13:21,401 iteration 3173 : loss : 0.017828, loss_ce: 0.006672
2022-01-08 17:13:24,013 iteration 3174 : loss : 0.024305, loss_ce: 0.008235
2022-01-08 17:13:26,487 iteration 3175 : loss : 0.021460, loss_ce: 0.008556
2022-01-08 17:13:29,032 iteration 3176 : loss : 0.019823, loss_ce: 0.009724
2022-01-08 17:13:31,398 iteration 3177 : loss : 0.024637, loss_ce: 0.010953
2022-01-08 17:13:33,865 iteration 3178 : loss : 0.029045, loss_ce: 0.007478
2022-01-08 17:13:36,363 iteration 3179 : loss : 0.033535, loss_ce: 0.008744
 47%|████████████▌              | 187/400 [2:13:43<2:44:32, 46.35s/it]2022-01-08 17:13:39,005 iteration 3180 : loss : 0.017731, loss_ce: 0.007364
2022-01-08 17:13:41,436 iteration 3181 : loss : 0.022927, loss_ce: 0.008576
2022-01-08 17:13:44,012 iteration 3182 : loss : 0.029750, loss_ce: 0.010923
2022-01-08 17:13:46,445 iteration 3183 : loss : 0.024939, loss_ce: 0.010235
2022-01-08 17:13:48,792 iteration 3184 : loss : 0.018306, loss_ce: 0.008391
2022-01-08 17:13:51,392 iteration 3185 : loss : 0.023333, loss_ce: 0.009276
2022-01-08 17:13:53,818 iteration 3186 : loss : 0.020424, loss_ce: 0.009445
2022-01-08 17:13:56,381 iteration 3187 : loss : 0.022179, loss_ce: 0.006619
2022-01-08 17:13:58,784 iteration 3188 : loss : 0.021740, loss_ce: 0.007005
2022-01-08 17:14:01,107 iteration 3189 : loss : 0.016626, loss_ce: 0.007393
2022-01-08 17:14:03,605 iteration 3190 : loss : 0.031249, loss_ce: 0.010870
2022-01-08 17:14:06,148 iteration 3191 : loss : 0.025116, loss_ce: 0.008027
2022-01-08 17:14:08,677 iteration 3192 : loss : 0.017208, loss_ce: 0.007361
2022-01-08 17:14:11,046 iteration 3193 : loss : 0.021512, loss_ce: 0.008957
2022-01-08 17:14:13,500 iteration 3194 : loss : 0.023139, loss_ce: 0.007081
2022-01-08 17:14:16,017 iteration 3195 : loss : 0.018117, loss_ce: 0.005139
2022-01-08 17:14:18,472 iteration 3196 : loss : 0.021195, loss_ce: 0.006269
 47%|████████████▋              | 188/400 [2:14:25<2:39:16, 45.08s/it]2022-01-08 17:14:20,885 iteration 3197 : loss : 0.020108, loss_ce: 0.006066
2022-01-08 17:14:23,416 iteration 3198 : loss : 0.022641, loss_ce: 0.008285
2022-01-08 17:14:25,868 iteration 3199 : loss : 0.019512, loss_ce: 0.007162
2022-01-08 17:14:28,414 iteration 3200 : loss : 0.020584, loss_ce: 0.009131
2022-01-08 17:14:30,824 iteration 3201 : loss : 0.024320, loss_ce: 0.008462
2022-01-08 17:14:33,428 iteration 3202 : loss : 0.027538, loss_ce: 0.012966
2022-01-08 17:14:35,817 iteration 3203 : loss : 0.041341, loss_ce: 0.007439
2022-01-08 17:14:38,375 iteration 3204 : loss : 0.026800, loss_ce: 0.013692
2022-01-08 17:14:40,782 iteration 3205 : loss : 0.016463, loss_ce: 0.005211
2022-01-08 17:14:43,178 iteration 3206 : loss : 0.021390, loss_ce: 0.007953
2022-01-08 17:14:45,585 iteration 3207 : loss : 0.017886, loss_ce: 0.005304
2022-01-08 17:14:48,181 iteration 3208 : loss : 0.024737, loss_ce: 0.009415
2022-01-08 17:14:50,670 iteration 3209 : loss : 0.021393, loss_ce: 0.007958
2022-01-08 17:14:53,142 iteration 3210 : loss : 0.029823, loss_ce: 0.009765
2022-01-08 17:14:55,725 iteration 3211 : loss : 0.032252, loss_ce: 0.013336
2022-01-08 17:14:58,179 iteration 3212 : loss : 0.025192, loss_ce: 0.012180
2022-01-08 17:15:00,554 iteration 3213 : loss : 0.021092, loss_ce: 0.010677
 47%|████████████▊              | 189/400 [2:15:07<2:35:21, 44.18s/it]2022-01-08 17:15:03,139 iteration 3214 : loss : 0.023713, loss_ce: 0.008750
2022-01-08 17:15:05,549 iteration 3215 : loss : 0.016985, loss_ce: 0.007165
2022-01-08 17:15:07,917 iteration 3216 : loss : 0.026762, loss_ce: 0.010324
2022-01-08 17:15:10,478 iteration 3217 : loss : 0.027665, loss_ce: 0.007639
2022-01-08 17:15:12,821 iteration 3218 : loss : 0.021046, loss_ce: 0.008363
2022-01-08 17:15:15,235 iteration 3219 : loss : 0.018143, loss_ce: 0.005362
2022-01-08 17:15:17,691 iteration 3220 : loss : 0.032771, loss_ce: 0.016200
2022-01-08 17:15:20,173 iteration 3221 : loss : 0.027930, loss_ce: 0.009646
2022-01-08 17:15:22,600 iteration 3222 : loss : 0.017195, loss_ce: 0.005944
2022-01-08 17:15:25,083 iteration 3223 : loss : 0.021640, loss_ce: 0.005356
2022-01-08 17:15:27,530 iteration 3224 : loss : 0.015599, loss_ce: 0.005393
2022-01-08 17:15:30,045 iteration 3225 : loss : 0.019470, loss_ce: 0.007924
2022-01-08 17:15:32,615 iteration 3226 : loss : 0.024483, loss_ce: 0.011988
2022-01-08 17:15:35,098 iteration 3227 : loss : 0.024644, loss_ce: 0.009300
2022-01-08 17:15:37,580 iteration 3228 : loss : 0.023682, loss_ce: 0.009788
2022-01-08 17:15:40,014 iteration 3229 : loss : 0.020676, loss_ce: 0.008375
2022-01-08 17:15:40,014 Training Data Eval:
2022-01-08 17:15:53,002   Average segmentation loss on training set: 0.0147
2022-01-08 17:15:53,003 Validation Data Eval:
2022-01-08 17:15:57,634   Average segmentation loss on validation set: 0.0812
2022-01-08 17:16:00,099 iteration 3230 : loss : 0.020530, loss_ce: 0.010372
 48%|████████████▊              | 190/400 [2:16:06<2:50:45, 48.79s/it]2022-01-08 17:16:02,527 iteration 3231 : loss : 0.018233, loss_ce: 0.006740
2022-01-08 17:16:04,946 iteration 3232 : loss : 0.016639, loss_ce: 0.007111
2022-01-08 17:16:07,461 iteration 3233 : loss : 0.022895, loss_ce: 0.007106
2022-01-08 17:16:09,883 iteration 3234 : loss : 0.017482, loss_ce: 0.006873
2022-01-08 17:16:12,351 iteration 3235 : loss : 0.016773, loss_ce: 0.006290
2022-01-08 17:16:14,819 iteration 3236 : loss : 0.016559, loss_ce: 0.008074
2022-01-08 17:16:17,200 iteration 3237 : loss : 0.017904, loss_ce: 0.007208
2022-01-08 17:16:19,565 iteration 3238 : loss : 0.020108, loss_ce: 0.007430
2022-01-08 17:16:22,021 iteration 3239 : loss : 0.017163, loss_ce: 0.007174
2022-01-08 17:16:24,429 iteration 3240 : loss : 0.028291, loss_ce: 0.010840
2022-01-08 17:16:27,099 iteration 3241 : loss : 0.029025, loss_ce: 0.009748
2022-01-08 17:16:29,527 iteration 3242 : loss : 0.018223, loss_ce: 0.006365
2022-01-08 17:16:32,129 iteration 3243 : loss : 0.031028, loss_ce: 0.015036
2022-01-08 17:16:34,493 iteration 3244 : loss : 0.027043, loss_ce: 0.008403
2022-01-08 17:16:36,896 iteration 3245 : loss : 0.027833, loss_ce: 0.008924
2022-01-08 17:16:39,388 iteration 3246 : loss : 0.030053, loss_ce: 0.012430
2022-01-08 17:16:41,882 iteration 3247 : loss : 0.042822, loss_ce: 0.017338
 48%|████████████▉              | 191/400 [2:16:48<2:42:37, 46.69s/it]2022-01-08 17:16:44,530 iteration 3248 : loss : 0.031433, loss_ce: 0.008344
2022-01-08 17:16:46,953 iteration 3249 : loss : 0.022555, loss_ce: 0.007963
2022-01-08 17:16:49,309 iteration 3250 : loss : 0.034083, loss_ce: 0.016110
2022-01-08 17:16:51,834 iteration 3251 : loss : 0.026458, loss_ce: 0.009495
2022-01-08 17:16:54,193 iteration 3252 : loss : 0.015448, loss_ce: 0.007421
2022-01-08 17:16:56,616 iteration 3253 : loss : 0.022127, loss_ce: 0.007600
2022-01-08 17:16:59,249 iteration 3254 : loss : 0.027831, loss_ce: 0.012024
2022-01-08 17:17:01,672 iteration 3255 : loss : 0.025905, loss_ce: 0.009912
2022-01-08 17:17:04,088 iteration 3256 : loss : 0.022068, loss_ce: 0.009631
2022-01-08 17:17:06,630 iteration 3257 : loss : 0.027901, loss_ce: 0.010019
2022-01-08 17:17:08,991 iteration 3258 : loss : 0.017562, loss_ce: 0.004643
2022-01-08 17:17:11,353 iteration 3259 : loss : 0.026897, loss_ce: 0.010133
2022-01-08 17:17:13,903 iteration 3260 : loss : 0.027251, loss_ce: 0.011500
2022-01-08 17:17:16,281 iteration 3261 : loss : 0.027320, loss_ce: 0.010609
2022-01-08 17:17:18,826 iteration 3262 : loss : 0.046883, loss_ce: 0.018013
2022-01-08 17:17:21,265 iteration 3263 : loss : 0.031424, loss_ce: 0.011111
2022-01-08 17:17:23,711 iteration 3264 : loss : 0.033603, loss_ce: 0.011670
 48%|████████████▉              | 192/400 [2:17:30<2:36:47, 45.23s/it]2022-01-08 17:17:26,138 iteration 3265 : loss : 0.026692, loss_ce: 0.010126
2022-01-08 17:17:28,552 iteration 3266 : loss : 0.021956, loss_ce: 0.007321
2022-01-08 17:17:31,028 iteration 3267 : loss : 0.021185, loss_ce: 0.007434
2022-01-08 17:17:33,457 iteration 3268 : loss : 0.029233, loss_ce: 0.009453
2022-01-08 17:17:35,928 iteration 3269 : loss : 0.019148, loss_ce: 0.009783
2022-01-08 17:17:38,400 iteration 3270 : loss : 0.019947, loss_ce: 0.007882
2022-01-08 17:17:40,768 iteration 3271 : loss : 0.022667, loss_ce: 0.006717
2022-01-08 17:17:43,371 iteration 3272 : loss : 0.029896, loss_ce: 0.013089
2022-01-08 17:17:45,737 iteration 3273 : loss : 0.027654, loss_ce: 0.013474
2022-01-08 17:17:48,081 iteration 3274 : loss : 0.022500, loss_ce: 0.007689
2022-01-08 17:17:50,595 iteration 3275 : loss : 0.022190, loss_ce: 0.008045
2022-01-08 17:17:52,948 iteration 3276 : loss : 0.023664, loss_ce: 0.006955
2022-01-08 17:17:55,302 iteration 3277 : loss : 0.016518, loss_ce: 0.005635
2022-01-08 17:17:57,838 iteration 3278 : loss : 0.018993, loss_ce: 0.007245
2022-01-08 17:18:00,152 iteration 3279 : loss : 0.022078, loss_ce: 0.011700
2022-01-08 17:18:02,614 iteration 3280 : loss : 0.022055, loss_ce: 0.009242
2022-01-08 17:18:05,068 iteration 3281 : loss : 0.017212, loss_ce: 0.005172
 48%|█████████████              | 193/400 [2:18:11<2:32:01, 44.07s/it]2022-01-08 17:18:07,687 iteration 3282 : loss : 0.024655, loss_ce: 0.005525
2022-01-08 17:18:10,109 iteration 3283 : loss : 0.022385, loss_ce: 0.008175
2022-01-08 17:18:12,598 iteration 3284 : loss : 0.022387, loss_ce: 0.008869
2022-01-08 17:18:15,014 iteration 3285 : loss : 0.025772, loss_ce: 0.009444
2022-01-08 17:18:17,430 iteration 3286 : loss : 0.022673, loss_ce: 0.006542
2022-01-08 17:18:19,882 iteration 3287 : loss : 0.034775, loss_ce: 0.014400
2022-01-08 17:18:22,216 iteration 3288 : loss : 0.025297, loss_ce: 0.010085
2022-01-08 17:18:24,691 iteration 3289 : loss : 0.025085, loss_ce: 0.011367
2022-01-08 17:18:27,170 iteration 3290 : loss : 0.022051, loss_ce: 0.008009
2022-01-08 17:18:29,796 iteration 3291 : loss : 0.022110, loss_ce: 0.010595
2022-01-08 17:18:32,210 iteration 3292 : loss : 0.030219, loss_ce: 0.010262
2022-01-08 17:18:34,589 iteration 3293 : loss : 0.032512, loss_ce: 0.007971
2022-01-08 17:18:37,200 iteration 3294 : loss : 0.025499, loss_ce: 0.011721
2022-01-08 17:18:39,625 iteration 3295 : loss : 0.024241, loss_ce: 0.010288
2022-01-08 17:18:41,918 iteration 3296 : loss : 0.022926, loss_ce: 0.007809
2022-01-08 17:18:44,262 iteration 3297 : loss : 0.021055, loss_ce: 0.008095
2022-01-08 17:18:46,735 iteration 3298 : loss : 0.025219, loss_ce: 0.011377
 48%|█████████████              | 194/400 [2:18:53<2:28:49, 43.35s/it]2022-01-08 17:18:49,083 iteration 3299 : loss : 0.027107, loss_ce: 0.006425
2022-01-08 17:18:51,701 iteration 3300 : loss : 0.029614, loss_ce: 0.009371
2022-01-08 17:18:54,142 iteration 3301 : loss : 0.026864, loss_ce: 0.013028
2022-01-08 17:18:56,577 iteration 3302 : loss : 0.037023, loss_ce: 0.013045
2022-01-08 17:18:59,080 iteration 3303 : loss : 0.024017, loss_ce: 0.010600
2022-01-08 17:19:01,578 iteration 3304 : loss : 0.034290, loss_ce: 0.017128
2022-01-08 17:19:03,977 iteration 3305 : loss : 0.020707, loss_ce: 0.007415
2022-01-08 17:19:06,492 iteration 3306 : loss : 0.030633, loss_ce: 0.008125
2022-01-08 17:19:08,961 iteration 3307 : loss : 0.028943, loss_ce: 0.013651
2022-01-08 17:19:11,369 iteration 3308 : loss : 0.042568, loss_ce: 0.018186
2022-01-08 17:19:13,804 iteration 3309 : loss : 0.022443, loss_ce: 0.010168
2022-01-08 17:19:16,157 iteration 3310 : loss : 0.020261, loss_ce: 0.010735
2022-01-08 17:19:18,618 iteration 3311 : loss : 0.030611, loss_ce: 0.010609
2022-01-08 17:19:21,021 iteration 3312 : loss : 0.028657, loss_ce: 0.007372
2022-01-08 17:19:23,493 iteration 3313 : loss : 0.028328, loss_ce: 0.011327
2022-01-08 17:19:25,913 iteration 3314 : loss : 0.035524, loss_ce: 0.010653
2022-01-08 17:19:25,914 Training Data Eval:
2022-01-08 17:19:39,015   Average segmentation loss on training set: 0.0154
2022-01-08 17:19:39,015 Validation Data Eval:
2022-01-08 17:19:43,508   Average segmentation loss on validation set: 0.0908
2022-01-08 17:19:45,910 iteration 3315 : loss : 0.018749, loss_ce: 0.007002
 49%|█████████████▏             | 195/400 [2:19:52<2:44:19, 48.10s/it]2022-01-08 17:19:48,421 iteration 3316 : loss : 0.017826, loss_ce: 0.007829
2022-01-08 17:19:50,892 iteration 3317 : loss : 0.022675, loss_ce: 0.010532
2022-01-08 17:19:53,372 iteration 3318 : loss : 0.026468, loss_ce: 0.011907
2022-01-08 17:19:55,764 iteration 3319 : loss : 0.027185, loss_ce: 0.010447
2022-01-08 17:19:58,189 iteration 3320 : loss : 0.060278, loss_ce: 0.023454
2022-01-08 17:20:00,701 iteration 3321 : loss : 0.024409, loss_ce: 0.008986
2022-01-08 17:20:03,133 iteration 3322 : loss : 0.023245, loss_ce: 0.006581
2022-01-08 17:20:05,483 iteration 3323 : loss : 0.017705, loss_ce: 0.005470
2022-01-08 17:20:07,884 iteration 3324 : loss : 0.022249, loss_ce: 0.009775
2022-01-08 17:20:10,454 iteration 3325 : loss : 0.032466, loss_ce: 0.013998
2022-01-08 17:20:12,993 iteration 3326 : loss : 0.026381, loss_ce: 0.009387
2022-01-08 17:20:15,399 iteration 3327 : loss : 0.019498, loss_ce: 0.006640
2022-01-08 17:20:17,886 iteration 3328 : loss : 0.026289, loss_ce: 0.009127
2022-01-08 17:20:20,304 iteration 3329 : loss : 0.029536, loss_ce: 0.011132
2022-01-08 17:20:22,657 iteration 3330 : loss : 0.019689, loss_ce: 0.009793
2022-01-08 17:20:24,996 iteration 3331 : loss : 0.018719, loss_ce: 0.008544
2022-01-08 17:20:27,561 iteration 3332 : loss : 0.021619, loss_ce: 0.006498
 49%|█████████████▏             | 196/400 [2:20:34<2:36:57, 46.16s/it]2022-01-08 17:20:30,208 iteration 3333 : loss : 0.023992, loss_ce: 0.008227
2022-01-08 17:20:32,821 iteration 3334 : loss : 0.024981, loss_ce: 0.010872
2022-01-08 17:20:35,303 iteration 3335 : loss : 0.034709, loss_ce: 0.014319
2022-01-08 17:20:37,722 iteration 3336 : loss : 0.023714, loss_ce: 0.007355
2022-01-08 17:20:40,340 iteration 3337 : loss : 0.036513, loss_ce: 0.014058
2022-01-08 17:20:42,838 iteration 3338 : loss : 0.029213, loss_ce: 0.012049
2022-01-08 17:20:45,240 iteration 3339 : loss : 0.018977, loss_ce: 0.007159
2022-01-08 17:20:47,635 iteration 3340 : loss : 0.027867, loss_ce: 0.006760
2022-01-08 17:20:50,051 iteration 3341 : loss : 0.029484, loss_ce: 0.011221
2022-01-08 17:20:52,568 iteration 3342 : loss : 0.017418, loss_ce: 0.007968
2022-01-08 17:20:54,982 iteration 3343 : loss : 0.020526, loss_ce: 0.009335
2022-01-08 17:20:57,488 iteration 3344 : loss : 0.023847, loss_ce: 0.007805
2022-01-08 17:20:59,922 iteration 3345 : loss : 0.025574, loss_ce: 0.011579
2022-01-08 17:21:02,410 iteration 3346 : loss : 0.016268, loss_ce: 0.007494
2022-01-08 17:21:04,813 iteration 3347 : loss : 0.020865, loss_ce: 0.007386
2022-01-08 17:21:07,194 iteration 3348 : loss : 0.019146, loss_ce: 0.007212
2022-01-08 17:21:09,641 iteration 3349 : loss : 0.032295, loss_ce: 0.009376
 49%|█████████████▎             | 197/400 [2:21:16<2:32:02, 44.94s/it]2022-01-08 17:21:12,229 iteration 3350 : loss : 0.020348, loss_ce: 0.007297
2022-01-08 17:21:14,665 iteration 3351 : loss : 0.018648, loss_ce: 0.005692
2022-01-08 17:21:17,122 iteration 3352 : loss : 0.040729, loss_ce: 0.017945
2022-01-08 17:21:19,591 iteration 3353 : loss : 0.024107, loss_ce: 0.007280
2022-01-08 17:21:22,060 iteration 3354 : loss : 0.029576, loss_ce: 0.013542
2022-01-08 17:21:24,503 iteration 3355 : loss : 0.040887, loss_ce: 0.022119
2022-01-08 17:21:26,967 iteration 3356 : loss : 0.022549, loss_ce: 0.008378
2022-01-08 17:21:29,390 iteration 3357 : loss : 0.027527, loss_ce: 0.007724
2022-01-08 17:21:31,904 iteration 3358 : loss : 0.017689, loss_ce: 0.007109
2022-01-08 17:21:34,317 iteration 3359 : loss : 0.021363, loss_ce: 0.007511
2022-01-08 17:21:36,756 iteration 3360 : loss : 0.026889, loss_ce: 0.010041
2022-01-08 17:21:39,234 iteration 3361 : loss : 0.021431, loss_ce: 0.008745
2022-01-08 17:21:41,671 iteration 3362 : loss : 0.022887, loss_ce: 0.008656
2022-01-08 17:21:44,128 iteration 3363 : loss : 0.031335, loss_ce: 0.009173
2022-01-08 17:21:46,535 iteration 3364 : loss : 0.016429, loss_ce: 0.006902
2022-01-08 17:21:48,987 iteration 3365 : loss : 0.029690, loss_ce: 0.013306
2022-01-08 17:21:51,459 iteration 3366 : loss : 0.016619, loss_ce: 0.006785
 50%|█████████████▎             | 198/400 [2:21:58<2:28:08, 44.00s/it]2022-01-08 17:21:54,041 iteration 3367 : loss : 0.022202, loss_ce: 0.008309
2022-01-08 17:21:56,536 iteration 3368 : loss : 0.022485, loss_ce: 0.010106
2022-01-08 17:21:58,929 iteration 3369 : loss : 0.021845, loss_ce: 0.006998
2022-01-08 17:22:01,534 iteration 3370 : loss : 0.029539, loss_ce: 0.015308
2022-01-08 17:22:04,031 iteration 3371 : loss : 0.029059, loss_ce: 0.009520
2022-01-08 17:22:06,339 iteration 3372 : loss : 0.018116, loss_ce: 0.007790
2022-01-08 17:22:08,730 iteration 3373 : loss : 0.025257, loss_ce: 0.008502
2022-01-08 17:22:11,097 iteration 3374 : loss : 0.016634, loss_ce: 0.005344
2022-01-08 17:22:13,512 iteration 3375 : loss : 0.021195, loss_ce: 0.007816
2022-01-08 17:22:15,960 iteration 3376 : loss : 0.020012, loss_ce: 0.006259
2022-01-08 17:22:18,319 iteration 3377 : loss : 0.013568, loss_ce: 0.005482
2022-01-08 17:22:20,782 iteration 3378 : loss : 0.035906, loss_ce: 0.008644
2022-01-08 17:22:23,281 iteration 3379 : loss : 0.042082, loss_ce: 0.017937
2022-01-08 17:22:25,867 iteration 3380 : loss : 0.029602, loss_ce: 0.009545
2022-01-08 17:22:28,435 iteration 3381 : loss : 0.028438, loss_ce: 0.011521
2022-01-08 17:22:30,869 iteration 3382 : loss : 0.017169, loss_ce: 0.006401
2022-01-08 17:22:33,357 iteration 3383 : loss : 0.018873, loss_ce: 0.007366
 50%|█████████████▍             | 199/400 [2:22:40<2:25:17, 43.37s/it]2022-01-08 17:22:35,849 iteration 3384 : loss : 0.035102, loss_ce: 0.013203
2022-01-08 17:22:38,437 iteration 3385 : loss : 0.030253, loss_ce: 0.012880
2022-01-08 17:22:40,809 iteration 3386 : loss : 0.019422, loss_ce: 0.006214
2022-01-08 17:22:43,296 iteration 3387 : loss : 0.027968, loss_ce: 0.010737
2022-01-08 17:22:45,798 iteration 3388 : loss : 0.025040, loss_ce: 0.011120
2022-01-08 17:22:48,213 iteration 3389 : loss : 0.018499, loss_ce: 0.008924
2022-01-08 17:22:50,539 iteration 3390 : loss : 0.016431, loss_ce: 0.006530
2022-01-08 17:22:53,036 iteration 3391 : loss : 0.030320, loss_ce: 0.010739
2022-01-08 17:22:55,579 iteration 3392 : loss : 0.024374, loss_ce: 0.007364
2022-01-08 17:22:57,968 iteration 3393 : loss : 0.027528, loss_ce: 0.011314
2022-01-08 17:23:00,498 iteration 3394 : loss : 0.018611, loss_ce: 0.007064
2022-01-08 17:23:02,972 iteration 3395 : loss : 0.016374, loss_ce: 0.006901
2022-01-08 17:23:05,378 iteration 3396 : loss : 0.033908, loss_ce: 0.012906
2022-01-08 17:23:07,827 iteration 3397 : loss : 0.019841, loss_ce: 0.008039
2022-01-08 17:23:10,248 iteration 3398 : loss : 0.020389, loss_ce: 0.008811
2022-01-08 17:23:12,698 iteration 3399 : loss : 0.023768, loss_ce: 0.008880
2022-01-08 17:23:12,698 Training Data Eval:
2022-01-08 17:23:25,792   Average segmentation loss on training set: 0.0179
2022-01-08 17:23:25,792 Validation Data Eval:
2022-01-08 17:23:30,482   Average segmentation loss on validation set: 0.0665
2022-01-08 17:23:32,898 iteration 3400 : loss : 0.024382, loss_ce: 0.007720
 50%|█████████████▌             | 200/400 [2:23:39<2:40:44, 48.22s/it]2022-01-08 17:23:35,329 iteration 3401 : loss : 0.025888, loss_ce: 0.012122
2022-01-08 17:23:37,821 iteration 3402 : loss : 0.024093, loss_ce: 0.008550
2022-01-08 17:23:40,277 iteration 3403 : loss : 0.027231, loss_ce: 0.009811
2022-01-08 17:23:42,752 iteration 3404 : loss : 0.023664, loss_ce: 0.008497
2022-01-08 17:23:45,239 iteration 3405 : loss : 0.027732, loss_ce: 0.008133
2022-01-08 17:23:47,690 iteration 3406 : loss : 0.023257, loss_ce: 0.008742
2022-01-08 17:23:50,121 iteration 3407 : loss : 0.022830, loss_ce: 0.008882
2022-01-08 17:23:52,640 iteration 3408 : loss : 0.025635, loss_ce: 0.010321
2022-01-08 17:23:55,211 iteration 3409 : loss : 0.019597, loss_ce: 0.006599
2022-01-08 17:23:57,626 iteration 3410 : loss : 0.023486, loss_ce: 0.010553
2022-01-08 17:24:00,059 iteration 3411 : loss : 0.031443, loss_ce: 0.013282
2022-01-08 17:24:02,621 iteration 3412 : loss : 0.020703, loss_ce: 0.007717
2022-01-08 17:24:05,013 iteration 3413 : loss : 0.027839, loss_ce: 0.007049
2022-01-08 17:24:07,546 iteration 3414 : loss : 0.024745, loss_ce: 0.010952
2022-01-08 17:24:10,153 iteration 3415 : loss : 0.018447, loss_ce: 0.008079
2022-01-08 17:24:12,612 iteration 3416 : loss : 0.024004, loss_ce: 0.007857
2022-01-08 17:24:15,145 iteration 3417 : loss : 0.024688, loss_ce: 0.007303
 50%|█████████████▌             | 201/400 [2:24:22<2:33:59, 46.43s/it]2022-01-08 17:24:17,524 iteration 3418 : loss : 0.013642, loss_ce: 0.004565
2022-01-08 17:24:19,989 iteration 3419 : loss : 0.033047, loss_ce: 0.014440
2022-01-08 17:24:22,394 iteration 3420 : loss : 0.019665, loss_ce: 0.006995
2022-01-08 17:24:24,792 iteration 3421 : loss : 0.016533, loss_ce: 0.006315
2022-01-08 17:24:27,191 iteration 3422 : loss : 0.019554, loss_ce: 0.006724
2022-01-08 17:24:29,623 iteration 3423 : loss : 0.028170, loss_ce: 0.014982
2022-01-08 17:24:32,219 iteration 3424 : loss : 0.027496, loss_ce: 0.013246
2022-01-08 17:24:34,734 iteration 3425 : loss : 0.025262, loss_ce: 0.009404
2022-01-08 17:24:37,096 iteration 3426 : loss : 0.024064, loss_ce: 0.008617
2022-01-08 17:24:39,493 iteration 3427 : loss : 0.022123, loss_ce: 0.006439
2022-01-08 17:24:42,135 iteration 3428 : loss : 0.022116, loss_ce: 0.008342
2022-01-08 17:24:44,513 iteration 3429 : loss : 0.017169, loss_ce: 0.005364
2022-01-08 17:24:47,074 iteration 3430 : loss : 0.032375, loss_ce: 0.011954
2022-01-08 17:24:49,468 iteration 3431 : loss : 0.025315, loss_ce: 0.009715
2022-01-08 17:24:51,985 iteration 3432 : loss : 0.027263, loss_ce: 0.010810
2022-01-08 17:24:54,423 iteration 3433 : loss : 0.050187, loss_ce: 0.017908
2022-01-08 17:24:56,777 iteration 3434 : loss : 0.030142, loss_ce: 0.008798
 50%|█████████████▋             | 202/400 [2:25:03<2:28:27, 44.99s/it]2022-01-08 17:24:59,223 iteration 3435 : loss : 0.020723, loss_ce: 0.006980
2022-01-08 17:25:01,819 iteration 3436 : loss : 0.047816, loss_ce: 0.020604
2022-01-08 17:25:04,280 iteration 3437 : loss : 0.029071, loss_ce: 0.009465
2022-01-08 17:25:06,890 iteration 3438 : loss : 0.034041, loss_ce: 0.016232
2022-01-08 17:25:09,224 iteration 3439 : loss : 0.023460, loss_ce: 0.009353
2022-01-08 17:25:11,677 iteration 3440 : loss : 0.020506, loss_ce: 0.007829
2022-01-08 17:25:14,277 iteration 3441 : loss : 0.030481, loss_ce: 0.009163
2022-01-08 17:25:16,671 iteration 3442 : loss : 0.019181, loss_ce: 0.007564
2022-01-08 17:25:19,154 iteration 3443 : loss : 0.023856, loss_ce: 0.009728
2022-01-08 17:25:21,672 iteration 3444 : loss : 0.038823, loss_ce: 0.011270
2022-01-08 17:25:24,116 iteration 3445 : loss : 0.027900, loss_ce: 0.012468
2022-01-08 17:25:26,755 iteration 3446 : loss : 0.020670, loss_ce: 0.009324
2022-01-08 17:25:29,222 iteration 3447 : loss : 0.044273, loss_ce: 0.013954
2022-01-08 17:25:31,679 iteration 3448 : loss : 0.023190, loss_ce: 0.009522
2022-01-08 17:25:34,059 iteration 3449 : loss : 0.021793, loss_ce: 0.008800
2022-01-08 17:25:36,547 iteration 3450 : loss : 0.022819, loss_ce: 0.007145
2022-01-08 17:25:39,076 iteration 3451 : loss : 0.018046, loss_ce: 0.009222
 51%|█████████████▋             | 203/400 [2:25:45<2:25:04, 44.19s/it]2022-01-08 17:25:41,455 iteration 3452 : loss : 0.016283, loss_ce: 0.006989
2022-01-08 17:25:43,864 iteration 3453 : loss : 0.029332, loss_ce: 0.012003
2022-01-08 17:25:46,449 iteration 3454 : loss : 0.043665, loss_ce: 0.016263
2022-01-08 17:25:48,874 iteration 3455 : loss : 0.024499, loss_ce: 0.010017
2022-01-08 17:25:51,310 iteration 3456 : loss : 0.044440, loss_ce: 0.010387
2022-01-08 17:25:53,653 iteration 3457 : loss : 0.020030, loss_ce: 0.007956
2022-01-08 17:25:56,002 iteration 3458 : loss : 0.020849, loss_ce: 0.006308
2022-01-08 17:25:58,519 iteration 3459 : loss : 0.020274, loss_ce: 0.008936
2022-01-08 17:26:00,876 iteration 3460 : loss : 0.018043, loss_ce: 0.007127
2022-01-08 17:26:03,374 iteration 3461 : loss : 0.015725, loss_ce: 0.005189
2022-01-08 17:26:05,713 iteration 3462 : loss : 0.018293, loss_ce: 0.008020
2022-01-08 17:26:08,159 iteration 3463 : loss : 0.020775, loss_ce: 0.008467
2022-01-08 17:26:10,692 iteration 3464 : loss : 0.025794, loss_ce: 0.008021
2022-01-08 17:26:13,063 iteration 3465 : loss : 0.019240, loss_ce: 0.006902
2022-01-08 17:26:15,663 iteration 3466 : loss : 0.027259, loss_ce: 0.010825
2022-01-08 17:26:18,042 iteration 3467 : loss : 0.015664, loss_ce: 0.005892
2022-01-08 17:26:20,461 iteration 3468 : loss : 0.021980, loss_ce: 0.006371
 51%|█████████████▊             | 204/400 [2:26:27<2:21:35, 43.35s/it]2022-01-08 17:26:23,076 iteration 3469 : loss : 0.017613, loss_ce: 0.006688
2022-01-08 17:26:25,435 iteration 3470 : loss : 0.022112, loss_ce: 0.009481
2022-01-08 17:26:27,838 iteration 3471 : loss : 0.021094, loss_ce: 0.008563
2022-01-08 17:26:30,393 iteration 3472 : loss : 0.027013, loss_ce: 0.009307
2022-01-08 17:26:32,732 iteration 3473 : loss : 0.017528, loss_ce: 0.007462
2022-01-08 17:26:35,245 iteration 3474 : loss : 0.024997, loss_ce: 0.008692
2022-01-08 17:26:37,722 iteration 3475 : loss : 0.021556, loss_ce: 0.009435
2022-01-08 17:26:40,280 iteration 3476 : loss : 0.021455, loss_ce: 0.006602
2022-01-08 17:26:42,680 iteration 3477 : loss : 0.015216, loss_ce: 0.005117
2022-01-08 17:26:45,087 iteration 3478 : loss : 0.019329, loss_ce: 0.008410
2022-01-08 17:26:47,532 iteration 3479 : loss : 0.018732, loss_ce: 0.008118
2022-01-08 17:26:49,944 iteration 3480 : loss : 0.020158, loss_ce: 0.009891
2022-01-08 17:26:52,317 iteration 3481 : loss : 0.022660, loss_ce: 0.007055
2022-01-08 17:26:54,847 iteration 3482 : loss : 0.017120, loss_ce: 0.005874
2022-01-08 17:26:57,321 iteration 3483 : loss : 0.036133, loss_ce: 0.022131
2022-01-08 17:26:59,723 iteration 3484 : loss : 0.026307, loss_ce: 0.010254
2022-01-08 17:26:59,723 Training Data Eval:
2022-01-08 17:27:12,896   Average segmentation loss on training set: 0.0135
2022-01-08 17:27:12,897 Validation Data Eval:
2022-01-08 17:27:17,516   Average segmentation loss on validation set: 0.0655
2022-01-08 17:27:19,965 iteration 3485 : loss : 0.018627, loss_ce: 0.007573
 51%|█████████████▊             | 205/400 [2:27:26<2:36:37, 48.19s/it]2022-01-08 17:27:22,417 iteration 3486 : loss : 0.024835, loss_ce: 0.006910
2022-01-08 17:27:24,961 iteration 3487 : loss : 0.023129, loss_ce: 0.010248
2022-01-08 17:27:27,403 iteration 3488 : loss : 0.021970, loss_ce: 0.006694
2022-01-08 17:27:29,853 iteration 3489 : loss : 0.020288, loss_ce: 0.009041
2022-01-08 17:27:32,293 iteration 3490 : loss : 0.027433, loss_ce: 0.009327
2022-01-08 17:27:34,775 iteration 3491 : loss : 0.026857, loss_ce: 0.012227
2022-01-08 17:27:37,209 iteration 3492 : loss : 0.018517, loss_ce: 0.005585
2022-01-08 17:27:39,602 iteration 3493 : loss : 0.023422, loss_ce: 0.008914
2022-01-08 17:27:42,028 iteration 3494 : loss : 0.020825, loss_ce: 0.007326
2022-01-08 17:27:44,609 iteration 3495 : loss : 0.016314, loss_ce: 0.005311
2022-01-08 17:27:47,104 iteration 3496 : loss : 0.034229, loss_ce: 0.012975
2022-01-08 17:27:49,466 iteration 3497 : loss : 0.022518, loss_ce: 0.008893
2022-01-08 17:27:51,910 iteration 3498 : loss : 0.018868, loss_ce: 0.007528
2022-01-08 17:27:54,443 iteration 3499 : loss : 0.022259, loss_ce: 0.012842
2022-01-08 17:27:56,931 iteration 3500 : loss : 0.018626, loss_ce: 0.007167
2022-01-08 17:27:59,404 iteration 3501 : loss : 0.026411, loss_ce: 0.009832
2022-01-08 17:28:01,818 iteration 3502 : loss : 0.020131, loss_ce: 0.010735
 52%|█████████████▉             | 206/400 [2:28:08<2:29:39, 46.29s/it]2022-01-08 17:28:04,271 iteration 3503 : loss : 0.030881, loss_ce: 0.008383
2022-01-08 17:28:06,701 iteration 3504 : loss : 0.018991, loss_ce: 0.007393
2022-01-08 17:28:09,334 iteration 3505 : loss : 0.016393, loss_ce: 0.007140
2022-01-08 17:28:11,802 iteration 3506 : loss : 0.033778, loss_ce: 0.014055
2022-01-08 17:28:14,131 iteration 3507 : loss : 0.016594, loss_ce: 0.006732
2022-01-08 17:28:16,546 iteration 3508 : loss : 0.022568, loss_ce: 0.005317
2022-01-08 17:28:18,999 iteration 3509 : loss : 0.019701, loss_ce: 0.007254
2022-01-08 17:28:21,381 iteration 3510 : loss : 0.015981, loss_ce: 0.006425
2022-01-08 17:28:24,012 iteration 3511 : loss : 0.030720, loss_ce: 0.013263
2022-01-08 17:28:26,378 iteration 3512 : loss : 0.016973, loss_ce: 0.006201
2022-01-08 17:28:28,850 iteration 3513 : loss : 0.024523, loss_ce: 0.010917
2022-01-08 17:28:31,303 iteration 3514 : loss : 0.017718, loss_ce: 0.007330
2022-01-08 17:28:33,738 iteration 3515 : loss : 0.025394, loss_ce: 0.012309
2022-01-08 17:28:36,128 iteration 3516 : loss : 0.018252, loss_ce: 0.007969
2022-01-08 17:28:38,667 iteration 3517 : loss : 0.019503, loss_ce: 0.008825
2022-01-08 17:28:41,165 iteration 3518 : loss : 0.032039, loss_ce: 0.011952
2022-01-08 17:28:43,574 iteration 3519 : loss : 0.025160, loss_ce: 0.010286
 52%|█████████████▉             | 207/400 [2:28:50<2:24:30, 44.93s/it]2022-01-08 17:28:46,080 iteration 3520 : loss : 0.021772, loss_ce: 0.007452
2022-01-08 17:28:48,475 iteration 3521 : loss : 0.024803, loss_ce: 0.005430
2022-01-08 17:28:50,967 iteration 3522 : loss : 0.020944, loss_ce: 0.005740
2022-01-08 17:28:53,374 iteration 3523 : loss : 0.022413, loss_ce: 0.011018
2022-01-08 17:28:55,805 iteration 3524 : loss : 0.024653, loss_ce: 0.010168
2022-01-08 17:28:58,147 iteration 3525 : loss : 0.024342, loss_ce: 0.006952
2022-01-08 17:29:00,511 iteration 3526 : loss : 0.020594, loss_ce: 0.009836
2022-01-08 17:29:02,904 iteration 3527 : loss : 0.027636, loss_ce: 0.010631
2022-01-08 17:29:05,312 iteration 3528 : loss : 0.049647, loss_ce: 0.007601
2022-01-08 17:29:07,745 iteration 3529 : loss : 0.022518, loss_ce: 0.007837
2022-01-08 17:29:10,200 iteration 3530 : loss : 0.022252, loss_ce: 0.007991
2022-01-08 17:29:12,860 iteration 3531 : loss : 0.031092, loss_ce: 0.011155
2022-01-08 17:29:15,277 iteration 3532 : loss : 0.019964, loss_ce: 0.008637
2022-01-08 17:29:17,618 iteration 3533 : loss : 0.029648, loss_ce: 0.011371
2022-01-08 17:29:19,958 iteration 3534 : loss : 0.032843, loss_ce: 0.010958
2022-01-08 17:29:22,519 iteration 3535 : loss : 0.024723, loss_ce: 0.010104
2022-01-08 17:29:24,911 iteration 3536 : loss : 0.025061, loss_ce: 0.010612
 52%|██████████████             | 208/400 [2:29:31<2:20:19, 43.85s/it]2022-01-08 17:29:27,384 iteration 3537 : loss : 0.035463, loss_ce: 0.017499
2022-01-08 17:29:29,897 iteration 3538 : loss : 0.024324, loss_ce: 0.009803
2022-01-08 17:29:32,278 iteration 3539 : loss : 0.023630, loss_ce: 0.007413
2022-01-08 17:29:34,879 iteration 3540 : loss : 0.034394, loss_ce: 0.016225
2022-01-08 17:29:37,348 iteration 3541 : loss : 0.027794, loss_ce: 0.010150
2022-01-08 17:29:39,721 iteration 3542 : loss : 0.030503, loss_ce: 0.011260
2022-01-08 17:29:42,204 iteration 3543 : loss : 0.033324, loss_ce: 0.013760
2022-01-08 17:29:44,632 iteration 3544 : loss : 0.047496, loss_ce: 0.010028
2022-01-08 17:29:47,037 iteration 3545 : loss : 0.031616, loss_ce: 0.010082
2022-01-08 17:29:49,462 iteration 3546 : loss : 0.034042, loss_ce: 0.012295
2022-01-08 17:29:51,898 iteration 3547 : loss : 0.037055, loss_ce: 0.015673
2022-01-08 17:29:54,409 iteration 3548 : loss : 0.015933, loss_ce: 0.004463
2022-01-08 17:29:56,888 iteration 3549 : loss : 0.071716, loss_ce: 0.046810
2022-01-08 17:29:59,334 iteration 3550 : loss : 0.021350, loss_ce: 0.007309
2022-01-08 17:30:01,762 iteration 3551 : loss : 0.024348, loss_ce: 0.010478
2022-01-08 17:30:04,102 iteration 3552 : loss : 0.026133, loss_ce: 0.011962
2022-01-08 17:30:06,566 iteration 3553 : loss : 0.019532, loss_ce: 0.007029
 52%|██████████████             | 209/400 [2:30:13<2:17:30, 43.19s/it]2022-01-08 17:30:09,021 iteration 3554 : loss : 0.023262, loss_ce: 0.009389
2022-01-08 17:30:11,536 iteration 3555 : loss : 0.024659, loss_ce: 0.010433
2022-01-08 17:30:13,985 iteration 3556 : loss : 0.023781, loss_ce: 0.009888
2022-01-08 17:30:16,383 iteration 3557 : loss : 0.030439, loss_ce: 0.013371
2022-01-08 17:30:18,809 iteration 3558 : loss : 0.024508, loss_ce: 0.008298
2022-01-08 17:30:21,243 iteration 3559 : loss : 0.030005, loss_ce: 0.007741
2022-01-08 17:30:23,621 iteration 3560 : loss : 0.020434, loss_ce: 0.007956
2022-01-08 17:30:26,027 iteration 3561 : loss : 0.016321, loss_ce: 0.008207
2022-01-08 17:30:28,427 iteration 3562 : loss : 0.033581, loss_ce: 0.013492
2022-01-08 17:30:30,869 iteration 3563 : loss : 0.029673, loss_ce: 0.011880
2022-01-08 17:30:33,361 iteration 3564 : loss : 0.035591, loss_ce: 0.011211
2022-01-08 17:30:35,767 iteration 3565 : loss : 0.021669, loss_ce: 0.006204
2022-01-08 17:30:38,277 iteration 3566 : loss : 0.027892, loss_ce: 0.010720
2022-01-08 17:30:40,745 iteration 3567 : loss : 0.031677, loss_ce: 0.017910
2022-01-08 17:30:43,206 iteration 3568 : loss : 0.026878, loss_ce: 0.008892
2022-01-08 17:30:45,652 iteration 3569 : loss : 0.023240, loss_ce: 0.009339
2022-01-08 17:30:45,652 Training Data Eval:
2022-01-08 17:30:58,653   Average segmentation loss on training set: 0.0159
2022-01-08 17:30:58,653 Validation Data Eval:
2022-01-08 17:31:03,285   Average segmentation loss on validation set: 0.0818
2022-01-08 17:31:05,732 iteration 3570 : loss : 0.022013, loss_ce: 0.006533
 52%|██████████████▏            | 210/400 [2:31:12<2:31:57, 47.99s/it]2022-01-08 17:31:08,376 iteration 3571 : loss : 0.024659, loss_ce: 0.014183
2022-01-08 17:31:10,734 iteration 3572 : loss : 0.019047, loss_ce: 0.007505
2022-01-08 17:31:13,110 iteration 3573 : loss : 0.034146, loss_ce: 0.010348
2022-01-08 17:31:15,492 iteration 3574 : loss : 0.026121, loss_ce: 0.008156
2022-01-08 17:31:17,920 iteration 3575 : loss : 0.019513, loss_ce: 0.007002
2022-01-08 17:31:20,349 iteration 3576 : loss : 0.024475, loss_ce: 0.007499
2022-01-08 17:31:22,920 iteration 3577 : loss : 0.024705, loss_ce: 0.011795
2022-01-08 17:31:25,269 iteration 3578 : loss : 0.021121, loss_ce: 0.008536
2022-01-08 17:31:27,696 iteration 3579 : loss : 0.022319, loss_ce: 0.009227
2022-01-08 17:31:30,105 iteration 3580 : loss : 0.022869, loss_ce: 0.009512
2022-01-08 17:31:32,521 iteration 3581 : loss : 0.029997, loss_ce: 0.017401
2022-01-08 17:31:35,047 iteration 3582 : loss : 0.018280, loss_ce: 0.006558
2022-01-08 17:31:37,464 iteration 3583 : loss : 0.023000, loss_ce: 0.007790
2022-01-08 17:31:39,945 iteration 3584 : loss : 0.017224, loss_ce: 0.006119
2022-01-08 17:31:42,309 iteration 3585 : loss : 0.023954, loss_ce: 0.008129
2022-01-08 17:31:44,767 iteration 3586 : loss : 0.021064, loss_ce: 0.009768
2022-01-08 17:31:47,304 iteration 3587 : loss : 0.023823, loss_ce: 0.009598
 53%|██████████████▏            | 211/400 [2:31:54<2:25:05, 46.06s/it]2022-01-08 17:31:49,782 iteration 3588 : loss : 0.018381, loss_ce: 0.007885
2022-01-08 17:31:52,116 iteration 3589 : loss : 0.020285, loss_ce: 0.006538
2022-01-08 17:31:54,536 iteration 3590 : loss : 0.023829, loss_ce: 0.009304
2022-01-08 17:31:56,944 iteration 3591 : loss : 0.021853, loss_ce: 0.007362
2022-01-08 17:31:59,499 iteration 3592 : loss : 0.023613, loss_ce: 0.010056
2022-01-08 17:32:01,871 iteration 3593 : loss : 0.016907, loss_ce: 0.006013
2022-01-08 17:32:04,497 iteration 3594 : loss : 0.024521, loss_ce: 0.008149
2022-01-08 17:32:06,905 iteration 3595 : loss : 0.045015, loss_ce: 0.019518
2022-01-08 17:32:09,283 iteration 3596 : loss : 0.019428, loss_ce: 0.007650
2022-01-08 17:32:11,723 iteration 3597 : loss : 0.024263, loss_ce: 0.008488
2022-01-08 17:32:14,120 iteration 3598 : loss : 0.015075, loss_ce: 0.006095
2022-01-08 17:32:16,610 iteration 3599 : loss : 0.037202, loss_ce: 0.013574
2022-01-08 17:32:19,065 iteration 3600 : loss : 0.016073, loss_ce: 0.006293
2022-01-08 17:32:21,525 iteration 3601 : loss : 0.021436, loss_ce: 0.009925
2022-01-08 17:32:23,912 iteration 3602 : loss : 0.017885, loss_ce: 0.005963
2022-01-08 17:32:26,345 iteration 3603 : loss : 0.023086, loss_ce: 0.011676
2022-01-08 17:32:28,737 iteration 3604 : loss : 0.017100, loss_ce: 0.007010
 53%|██████████████▎            | 212/400 [2:32:35<2:19:58, 44.67s/it]2022-01-08 17:32:31,159 iteration 3605 : loss : 0.022806, loss_ce: 0.007828
2022-01-08 17:32:33,575 iteration 3606 : loss : 0.022232, loss_ce: 0.011541
2022-01-08 17:32:36,056 iteration 3607 : loss : 0.021130, loss_ce: 0.008163
2022-01-08 17:32:38,522 iteration 3608 : loss : 0.016759, loss_ce: 0.006248
2022-01-08 17:32:40,927 iteration 3609 : loss : 0.017332, loss_ce: 0.007820
2022-01-08 17:32:43,413 iteration 3610 : loss : 0.022490, loss_ce: 0.009276
2022-01-08 17:32:45,805 iteration 3611 : loss : 0.017044, loss_ce: 0.004622
2022-01-08 17:32:48,199 iteration 3612 : loss : 0.014792, loss_ce: 0.004906
2022-01-08 17:32:50,673 iteration 3613 : loss : 0.021770, loss_ce: 0.008962
2022-01-08 17:32:53,082 iteration 3614 : loss : 0.016921, loss_ce: 0.006371
2022-01-08 17:32:55,438 iteration 3615 : loss : 0.017641, loss_ce: 0.006121
2022-01-08 17:32:58,095 iteration 3616 : loss : 0.027507, loss_ce: 0.009715
2022-01-08 17:33:00,517 iteration 3617 : loss : 0.020048, loss_ce: 0.008630
2022-01-08 17:33:03,089 iteration 3618 : loss : 0.025560, loss_ce: 0.011176
2022-01-08 17:33:05,571 iteration 3619 : loss : 0.020499, loss_ce: 0.005919
2022-01-08 17:33:07,939 iteration 3620 : loss : 0.029090, loss_ce: 0.009635
2022-01-08 17:33:10,484 iteration 3621 : loss : 0.033490, loss_ce: 0.012488
 53%|██████████████▍            | 213/400 [2:33:17<2:16:29, 43.79s/it]2022-01-08 17:33:12,916 iteration 3622 : loss : 0.018858, loss_ce: 0.008467
2022-01-08 17:33:15,389 iteration 3623 : loss : 0.016239, loss_ce: 0.003796
2022-01-08 17:33:17,968 iteration 3624 : loss : 0.016499, loss_ce: 0.006501
2022-01-08 17:33:20,405 iteration 3625 : loss : 0.017214, loss_ce: 0.006542
2022-01-08 17:33:22,767 iteration 3626 : loss : 0.024126, loss_ce: 0.012048
2022-01-08 17:33:25,210 iteration 3627 : loss : 0.019478, loss_ce: 0.007057
2022-01-08 17:33:27,717 iteration 3628 : loss : 0.038368, loss_ce: 0.010148
2022-01-08 17:33:30,235 iteration 3629 : loss : 0.030622, loss_ce: 0.013170
2022-01-08 17:33:32,566 iteration 3630 : loss : 0.025912, loss_ce: 0.009268
2022-01-08 17:33:35,028 iteration 3631 : loss : 0.030567, loss_ce: 0.010540
2022-01-08 17:33:37,533 iteration 3632 : loss : 0.043696, loss_ce: 0.015446
2022-01-08 17:33:39,987 iteration 3633 : loss : 0.019282, loss_ce: 0.007803
2022-01-08 17:33:42,405 iteration 3634 : loss : 0.019601, loss_ce: 0.008483
2022-01-08 17:33:45,060 iteration 3635 : loss : 0.045328, loss_ce: 0.020731
2022-01-08 17:33:47,500 iteration 3636 : loss : 0.025894, loss_ce: 0.006967
2022-01-08 17:33:49,930 iteration 3637 : loss : 0.035194, loss_ce: 0.011815
2022-01-08 17:33:52,304 iteration 3638 : loss : 0.018469, loss_ce: 0.007629
 54%|██████████████▍            | 214/400 [2:33:59<2:13:55, 43.20s/it]2022-01-08 17:33:54,710 iteration 3639 : loss : 0.018722, loss_ce: 0.007908
2022-01-08 17:33:57,184 iteration 3640 : loss : 0.019343, loss_ce: 0.007459
2022-01-08 17:33:59,758 iteration 3641 : loss : 0.016925, loss_ce: 0.005443
2022-01-08 17:34:02,173 iteration 3642 : loss : 0.028238, loss_ce: 0.009413
2022-01-08 17:34:04,492 iteration 3643 : loss : 0.023750, loss_ce: 0.008590
2022-01-08 17:34:06,892 iteration 3644 : loss : 0.013276, loss_ce: 0.004854
2022-01-08 17:34:09,401 iteration 3645 : loss : 0.029595, loss_ce: 0.009527
2022-01-08 17:34:11,777 iteration 3646 : loss : 0.028775, loss_ce: 0.010161
2022-01-08 17:34:14,232 iteration 3647 : loss : 0.026280, loss_ce: 0.007093
2022-01-08 17:34:16,625 iteration 3648 : loss : 0.021851, loss_ce: 0.008920
2022-01-08 17:34:19,030 iteration 3649 : loss : 0.017043, loss_ce: 0.004916
2022-01-08 17:34:21,486 iteration 3650 : loss : 0.028034, loss_ce: 0.016962
2022-01-08 17:34:23,988 iteration 3651 : loss : 0.021789, loss_ce: 0.007553
2022-01-08 17:34:26,657 iteration 3652 : loss : 0.037587, loss_ce: 0.011563
2022-01-08 17:34:29,032 iteration 3653 : loss : 0.017998, loss_ce: 0.009096
2022-01-08 17:34:31,476 iteration 3654 : loss : 0.016369, loss_ce: 0.007781
2022-01-08 17:34:31,477 Training Data Eval:
2022-01-08 17:34:44,687   Average segmentation loss on training set: 0.0142
2022-01-08 17:34:44,687 Validation Data Eval:
2022-01-08 17:34:49,362   Average segmentation loss on validation set: 0.0721
2022-01-08 17:34:51,797 iteration 3655 : loss : 0.017978, loss_ce: 0.006937
 54%|██████████████▌            | 215/400 [2:34:58<2:28:16, 48.09s/it]2022-01-08 17:34:54,409 iteration 3656 : loss : 0.020098, loss_ce: 0.007535
2022-01-08 17:34:56,814 iteration 3657 : loss : 0.018487, loss_ce: 0.009545
2022-01-08 17:34:59,250 iteration 3658 : loss : 0.021310, loss_ce: 0.009602
2022-01-08 17:35:01,734 iteration 3659 : loss : 0.024985, loss_ce: 0.009287
2022-01-08 17:35:04,155 iteration 3660 : loss : 0.019945, loss_ce: 0.004754
2022-01-08 17:35:06,538 iteration 3661 : loss : 0.016320, loss_ce: 0.006905
2022-01-08 17:35:09,053 iteration 3662 : loss : 0.026408, loss_ce: 0.009467
2022-01-08 17:35:11,490 iteration 3663 : loss : 0.025245, loss_ce: 0.008014
2022-01-08 17:35:13,984 iteration 3664 : loss : 0.016378, loss_ce: 0.006377
2022-01-08 17:35:16,440 iteration 3665 : loss : 0.020681, loss_ce: 0.010404
2022-01-08 17:35:18,893 iteration 3666 : loss : 0.019985, loss_ce: 0.006538
2022-01-08 17:35:21,357 iteration 3667 : loss : 0.028877, loss_ce: 0.013200
2022-01-08 17:35:23,682 iteration 3668 : loss : 0.024813, loss_ce: 0.006892
2022-01-08 17:35:26,133 iteration 3669 : loss : 0.018724, loss_ce: 0.007668
2022-01-08 17:35:28,701 iteration 3670 : loss : 0.014285, loss_ce: 0.005118
2022-01-08 17:35:31,092 iteration 3671 : loss : 0.015404, loss_ce: 0.006966
2022-01-08 17:35:33,567 iteration 3672 : loss : 0.049553, loss_ce: 0.012714
 54%|██████████████▌            | 216/400 [2:35:40<2:21:39, 46.19s/it]2022-01-08 17:35:36,050 iteration 3673 : loss : 0.022841, loss_ce: 0.010067
2022-01-08 17:35:38,626 iteration 3674 : loss : 0.027835, loss_ce: 0.007394
2022-01-08 17:35:41,090 iteration 3675 : loss : 0.022175, loss_ce: 0.007195
2022-01-08 17:35:43,484 iteration 3676 : loss : 0.015916, loss_ce: 0.006538
2022-01-08 17:35:45,878 iteration 3677 : loss : 0.029876, loss_ce: 0.009746
2022-01-08 17:35:48,407 iteration 3678 : loss : 0.023374, loss_ce: 0.006830
2022-01-08 17:35:50,862 iteration 3679 : loss : 0.020575, loss_ce: 0.007379
2022-01-08 17:35:53,327 iteration 3680 : loss : 0.027523, loss_ce: 0.010089
2022-01-08 17:35:55,738 iteration 3681 : loss : 0.022846, loss_ce: 0.010068
2022-01-08 17:35:58,210 iteration 3682 : loss : 0.016687, loss_ce: 0.006268
2022-01-08 17:36:00,560 iteration 3683 : loss : 0.018176, loss_ce: 0.006467
2022-01-08 17:36:03,000 iteration 3684 : loss : 0.016627, loss_ce: 0.006532
2022-01-08 17:36:05,575 iteration 3685 : loss : 0.017919, loss_ce: 0.005553
2022-01-08 17:36:07,985 iteration 3686 : loss : 0.021245, loss_ce: 0.008988
2022-01-08 17:36:10,409 iteration 3687 : loss : 0.016537, loss_ce: 0.005882
2022-01-08 17:36:12,950 iteration 3688 : loss : 0.021660, loss_ce: 0.012097
2022-01-08 17:36:15,356 iteration 3689 : loss : 0.022067, loss_ce: 0.006295
 54%|██████████████▋            | 217/400 [2:36:22<2:16:51, 44.87s/it]2022-01-08 17:36:18,045 iteration 3690 : loss : 0.039089, loss_ce: 0.010026
2022-01-08 17:36:20,453 iteration 3691 : loss : 0.020173, loss_ce: 0.005031
2022-01-08 17:36:22,810 iteration 3692 : loss : 0.019062, loss_ce: 0.009034
2022-01-08 17:36:25,166 iteration 3693 : loss : 0.020679, loss_ce: 0.008716
2022-01-08 17:36:27,694 iteration 3694 : loss : 0.052162, loss_ce: 0.026549
2022-01-08 17:36:30,146 iteration 3695 : loss : 0.021076, loss_ce: 0.011053
2022-01-08 17:36:32,570 iteration 3696 : loss : 0.027425, loss_ce: 0.008775
2022-01-08 17:36:35,071 iteration 3697 : loss : 0.026142, loss_ce: 0.008529
2022-01-08 17:36:37,529 iteration 3698 : loss : 0.035343, loss_ce: 0.013457
2022-01-08 17:36:39,884 iteration 3699 : loss : 0.017072, loss_ce: 0.006629
2022-01-08 17:36:42,439 iteration 3700 : loss : 0.016728, loss_ce: 0.005068
2022-01-08 17:36:44,797 iteration 3701 : loss : 0.025171, loss_ce: 0.010718
2022-01-08 17:36:47,336 iteration 3702 : loss : 0.024647, loss_ce: 0.008132
2022-01-08 17:36:49,781 iteration 3703 : loss : 0.029760, loss_ce: 0.015594
2022-01-08 17:36:52,258 iteration 3704 : loss : 0.020149, loss_ce: 0.008496
2022-01-08 17:36:54,737 iteration 3705 : loss : 0.030896, loss_ce: 0.011188
2022-01-08 17:36:57,191 iteration 3706 : loss : 0.013942, loss_ce: 0.003990
 55%|██████████████▋            | 218/400 [2:37:04<2:13:21, 43.97s/it]2022-01-08 17:36:59,652 iteration 3707 : loss : 0.023085, loss_ce: 0.011091
2022-01-08 17:37:02,000 iteration 3708 : loss : 0.018061, loss_ce: 0.006547
2022-01-08 17:37:04,672 iteration 3709 : loss : 0.039737, loss_ce: 0.011680
2022-01-08 17:37:07,090 iteration 3710 : loss : 0.032190, loss_ce: 0.011940
2022-01-08 17:37:09,618 iteration 3711 : loss : 0.016270, loss_ce: 0.005732
2022-01-08 17:37:12,021 iteration 3712 : loss : 0.017062, loss_ce: 0.008029
2022-01-08 17:37:14,487 iteration 3713 : loss : 0.018545, loss_ce: 0.006523
2022-01-08 17:37:16,982 iteration 3714 : loss : 0.018931, loss_ce: 0.006730
2022-01-08 17:37:19,334 iteration 3715 : loss : 0.019897, loss_ce: 0.007950
2022-01-08 17:37:21,790 iteration 3716 : loss : 0.021503, loss_ce: 0.011406
2022-01-08 17:37:24,284 iteration 3717 : loss : 0.020771, loss_ce: 0.008306
2022-01-08 17:37:26,680 iteration 3718 : loss : 0.015511, loss_ce: 0.005991
2022-01-08 17:37:29,205 iteration 3719 : loss : 0.023157, loss_ce: 0.008181
2022-01-08 17:37:31,682 iteration 3720 : loss : 0.022516, loss_ce: 0.006613
2022-01-08 17:37:34,259 iteration 3721 : loss : 0.016889, loss_ce: 0.006452
2022-01-08 17:37:36,647 iteration 3722 : loss : 0.020502, loss_ce: 0.009886
2022-01-08 17:37:39,074 iteration 3723 : loss : 0.024320, loss_ce: 0.006395
 55%|██████████████▊            | 219/400 [2:37:45<2:10:44, 43.34s/it]2022-01-08 17:37:41,565 iteration 3724 : loss : 0.026085, loss_ce: 0.010054
2022-01-08 17:37:43,994 iteration 3725 : loss : 0.025107, loss_ce: 0.011115
2022-01-08 17:37:46,690 iteration 3726 : loss : 0.016323, loss_ce: 0.005025
2022-01-08 17:37:49,104 iteration 3727 : loss : 0.013598, loss_ce: 0.004314
2022-01-08 17:37:51,475 iteration 3728 : loss : 0.021474, loss_ce: 0.011220
2022-01-08 17:37:53,944 iteration 3729 : loss : 0.033678, loss_ce: 0.011454
2022-01-08 17:37:56,401 iteration 3730 : loss : 0.026333, loss_ce: 0.008246
2022-01-08 17:37:58,778 iteration 3731 : loss : 0.023379, loss_ce: 0.007889
2022-01-08 17:38:01,298 iteration 3732 : loss : 0.020787, loss_ce: 0.008760
2022-01-08 17:38:03,684 iteration 3733 : loss : 0.022450, loss_ce: 0.006218
2022-01-08 17:38:06,199 iteration 3734 : loss : 0.018345, loss_ce: 0.007103
2022-01-08 17:38:08,637 iteration 3735 : loss : 0.031489, loss_ce: 0.017128
2022-01-08 17:38:11,275 iteration 3736 : loss : 0.025148, loss_ce: 0.006502
2022-01-08 17:38:13,695 iteration 3737 : loss : 0.018120, loss_ce: 0.007035
2022-01-08 17:38:16,118 iteration 3738 : loss : 0.024628, loss_ce: 0.010180
2022-01-08 17:38:18,568 iteration 3739 : loss : 0.020732, loss_ce: 0.006777
2022-01-08 17:38:18,568 Training Data Eval:
2022-01-08 17:38:31,747   Average segmentation loss on training set: 0.0130
2022-01-08 17:38:31,748 Validation Data Eval:
2022-01-08 17:38:36,533   Average segmentation loss on validation set: 0.0854
2022-01-08 17:38:38,958 iteration 3740 : loss : 0.016215, loss_ce: 0.005383
 55%|██████████████▊            | 220/400 [2:38:45<2:24:54, 48.31s/it]2022-01-08 17:38:41,435 iteration 3741 : loss : 0.020804, loss_ce: 0.008619
2022-01-08 17:38:43,810 iteration 3742 : loss : 0.020689, loss_ce: 0.009196
2022-01-08 17:38:46,186 iteration 3743 : loss : 0.021030, loss_ce: 0.007090
2022-01-08 17:38:48,712 iteration 3744 : loss : 0.020817, loss_ce: 0.011004
2022-01-08 17:38:51,082 iteration 3745 : loss : 0.018070, loss_ce: 0.006738
2022-01-08 17:38:53,698 iteration 3746 : loss : 0.016565, loss_ce: 0.006603
2022-01-08 17:38:56,121 iteration 3747 : loss : 0.028581, loss_ce: 0.006590
2022-01-08 17:38:58,563 iteration 3748 : loss : 0.023311, loss_ce: 0.009266
2022-01-08 17:39:01,092 iteration 3749 : loss : 0.018429, loss_ce: 0.007465
2022-01-08 17:39:03,568 iteration 3750 : loss : 0.023954, loss_ce: 0.009729
2022-01-08 17:39:06,007 iteration 3751 : loss : 0.029518, loss_ce: 0.007648
2022-01-08 17:39:08,402 iteration 3752 : loss : 0.018561, loss_ce: 0.007511
2022-01-08 17:39:10,904 iteration 3753 : loss : 0.022781, loss_ce: 0.006163
2022-01-08 17:39:13,295 iteration 3754 : loss : 0.016930, loss_ce: 0.005746
2022-01-08 17:39:15,715 iteration 3755 : loss : 0.020586, loss_ce: 0.009197
2022-01-08 17:39:18,227 iteration 3756 : loss : 0.027709, loss_ce: 0.009281
2022-01-08 17:39:20,611 iteration 3757 : loss : 0.020381, loss_ce: 0.006938
 55%|██████████████▉            | 221/400 [2:39:27<2:18:09, 46.31s/it]2022-01-08 17:39:23,081 iteration 3758 : loss : 0.024763, loss_ce: 0.010234
2022-01-08 17:39:25,520 iteration 3759 : loss : 0.016509, loss_ce: 0.006055
2022-01-08 17:39:27,870 iteration 3760 : loss : 0.016040, loss_ce: 0.005546
2022-01-08 17:39:30,334 iteration 3761 : loss : 0.024889, loss_ce: 0.010979
2022-01-08 17:39:32,725 iteration 3762 : loss : 0.023372, loss_ce: 0.006571
2022-01-08 17:39:35,159 iteration 3763 : loss : 0.026799, loss_ce: 0.012014
2022-01-08 17:39:37,717 iteration 3764 : loss : 0.020052, loss_ce: 0.007607
2022-01-08 17:39:40,197 iteration 3765 : loss : 0.018095, loss_ce: 0.007207
2022-01-08 17:39:42,677 iteration 3766 : loss : 0.016881, loss_ce: 0.006150
2022-01-08 17:39:45,116 iteration 3767 : loss : 0.022500, loss_ce: 0.006910
2022-01-08 17:39:47,465 iteration 3768 : loss : 0.017692, loss_ce: 0.007552
2022-01-08 17:39:49,767 iteration 3769 : loss : 0.016432, loss_ce: 0.006664
2022-01-08 17:39:52,310 iteration 3770 : loss : 0.021756, loss_ce: 0.008014
2022-01-08 17:39:54,742 iteration 3771 : loss : 0.014019, loss_ce: 0.005344
2022-01-08 17:39:57,140 iteration 3772 : loss : 0.019223, loss_ce: 0.006119
2022-01-08 17:39:59,447 iteration 3773 : loss : 0.014424, loss_ce: 0.005180
2022-01-08 17:40:01,849 iteration 3774 : loss : 0.022567, loss_ce: 0.008880
 56%|██████████████▉            | 222/400 [2:40:08<2:12:51, 44.78s/it]2022-01-08 17:40:04,325 iteration 3775 : loss : 0.020269, loss_ce: 0.005881
2022-01-08 17:40:06,850 iteration 3776 : loss : 0.022883, loss_ce: 0.009479
2022-01-08 17:40:09,348 iteration 3777 : loss : 0.028543, loss_ce: 0.009594
2022-01-08 17:40:11,761 iteration 3778 : loss : 0.016389, loss_ce: 0.008323
2022-01-08 17:40:14,208 iteration 3779 : loss : 0.020134, loss_ce: 0.008216
2022-01-08 17:40:16,715 iteration 3780 : loss : 0.017621, loss_ce: 0.008308
2022-01-08 17:40:19,140 iteration 3781 : loss : 0.019047, loss_ce: 0.007873
2022-01-08 17:40:21,551 iteration 3782 : loss : 0.028593, loss_ce: 0.010238
2022-01-08 17:40:24,059 iteration 3783 : loss : 0.016822, loss_ce: 0.005655
2022-01-08 17:40:26,489 iteration 3784 : loss : 0.026909, loss_ce: 0.013193
2022-01-08 17:40:28,867 iteration 3785 : loss : 0.016114, loss_ce: 0.006146
2022-01-08 17:40:31,271 iteration 3786 : loss : 0.030289, loss_ce: 0.011453
2022-01-08 17:40:33,722 iteration 3787 : loss : 0.025866, loss_ce: 0.009857
2022-01-08 17:40:36,168 iteration 3788 : loss : 0.021366, loss_ce: 0.007855
2022-01-08 17:40:38,559 iteration 3789 : loss : 0.021298, loss_ce: 0.005431
2022-01-08 17:40:41,013 iteration 3790 : loss : 0.026710, loss_ce: 0.011874
2022-01-08 17:40:43,384 iteration 3791 : loss : 0.015860, loss_ce: 0.006155
 56%|███████████████            | 223/400 [2:40:50<2:09:14, 43.81s/it]2022-01-08 17:40:45,959 iteration 3792 : loss : 0.016210, loss_ce: 0.007153
2022-01-08 17:40:48,382 iteration 3793 : loss : 0.017000, loss_ce: 0.007078
2022-01-08 17:40:50,876 iteration 3794 : loss : 0.018667, loss_ce: 0.008067
2022-01-08 17:40:53,434 iteration 3795 : loss : 0.027965, loss_ce: 0.011517
2022-01-08 17:40:55,841 iteration 3796 : loss : 0.033104, loss_ce: 0.008642
2022-01-08 17:40:58,241 iteration 3797 : loss : 0.017983, loss_ce: 0.006305
2022-01-08 17:41:00,713 iteration 3798 : loss : 0.019463, loss_ce: 0.007689
2022-01-08 17:41:03,144 iteration 3799 : loss : 0.022445, loss_ce: 0.011410
2022-01-08 17:41:05,771 iteration 3800 : loss : 0.019904, loss_ce: 0.006093
2022-01-08 17:41:08,135 iteration 3801 : loss : 0.014608, loss_ce: 0.005407
2022-01-08 17:41:10,547 iteration 3802 : loss : 0.019231, loss_ce: 0.005968
2022-01-08 17:41:13,006 iteration 3803 : loss : 0.015739, loss_ce: 0.005429
2022-01-08 17:41:15,358 iteration 3804 : loss : 0.015736, loss_ce: 0.006006
2022-01-08 17:41:17,921 iteration 3805 : loss : 0.019776, loss_ce: 0.008215
2022-01-08 17:41:20,330 iteration 3806 : loss : 0.017844, loss_ce: 0.004334
2022-01-08 17:41:22,723 iteration 3807 : loss : 0.018965, loss_ce: 0.007829
2022-01-08 17:41:25,095 iteration 3808 : loss : 0.018884, loss_ce: 0.007326
 56%|███████████████            | 224/400 [2:41:31<2:06:40, 43.18s/it]2022-01-08 17:41:27,528 iteration 3809 : loss : 0.018091, loss_ce: 0.007240
2022-01-08 17:41:29,908 iteration 3810 : loss : 0.016444, loss_ce: 0.006267
2022-01-08 17:41:32,434 iteration 3811 : loss : 0.020530, loss_ce: 0.006996
2022-01-08 17:41:34,922 iteration 3812 : loss : 0.017439, loss_ce: 0.006182
2022-01-08 17:41:37,378 iteration 3813 : loss : 0.031929, loss_ce: 0.006594
2022-01-08 17:41:39,745 iteration 3814 : loss : 0.013602, loss_ce: 0.004673
2022-01-08 17:41:42,187 iteration 3815 : loss : 0.028705, loss_ce: 0.010051
2022-01-08 17:41:44,722 iteration 3816 : loss : 0.021994, loss_ce: 0.006639
2022-01-08 17:41:47,186 iteration 3817 : loss : 0.019678, loss_ce: 0.008653
2022-01-08 17:41:49,681 iteration 3818 : loss : 0.023771, loss_ce: 0.011547
2022-01-08 17:41:51,977 iteration 3819 : loss : 0.021122, loss_ce: 0.010843
2022-01-08 17:41:54,400 iteration 3820 : loss : 0.018946, loss_ce: 0.007538
2022-01-08 17:41:56,831 iteration 3821 : loss : 0.019370, loss_ce: 0.009262
2022-01-08 17:41:59,171 iteration 3822 : loss : 0.014660, loss_ce: 0.006198
2022-01-08 17:42:01,575 iteration 3823 : loss : 0.016361, loss_ce: 0.006047
2022-01-08 17:42:04,014 iteration 3824 : loss : 0.017121, loss_ce: 0.006762
2022-01-08 17:42:04,014 Training Data Eval:
2022-01-08 17:42:17,052   Average segmentation loss on training set: 0.0131
2022-01-08 17:42:17,052 Validation Data Eval:
2022-01-08 17:42:21,478   Average segmentation loss on validation set: 0.0642
2022-01-08 17:42:23,891 iteration 3825 : loss : 0.020934, loss_ce: 0.007176
 56%|███████████████▏           | 225/400 [2:42:30<2:19:36, 47.87s/it]2022-01-08 17:42:26,317 iteration 3826 : loss : 0.015159, loss_ce: 0.006656
2022-01-08 17:42:28,786 iteration 3827 : loss : 0.029871, loss_ce: 0.012014
2022-01-08 17:42:31,228 iteration 3828 : loss : 0.025860, loss_ce: 0.013040
2022-01-08 17:42:33,771 iteration 3829 : loss : 0.020650, loss_ce: 0.009572
2022-01-08 17:42:36,163 iteration 3830 : loss : 0.023731, loss_ce: 0.009818
2022-01-08 17:42:38,607 iteration 3831 : loss : 0.049545, loss_ce: 0.013754
2022-01-08 17:42:40,956 iteration 3832 : loss : 0.014583, loss_ce: 0.005101
2022-01-08 17:42:43,516 iteration 3833 : loss : 0.017295, loss_ce: 0.005800
2022-01-08 17:42:45,966 iteration 3834 : loss : 0.014613, loss_ce: 0.006880
2022-01-08 17:42:48,400 iteration 3835 : loss : 0.022259, loss_ce: 0.011464
2022-01-08 17:42:50,919 iteration 3836 : loss : 0.016444, loss_ce: 0.005760
2022-01-08 17:42:53,283 iteration 3837 : loss : 0.017309, loss_ce: 0.006436
2022-01-08 17:42:55,687 iteration 3838 : loss : 0.017200, loss_ce: 0.005601
2022-01-08 17:42:58,073 iteration 3839 : loss : 0.018096, loss_ce: 0.007029
2022-01-08 17:43:00,563 iteration 3840 : loss : 0.020599, loss_ce: 0.005545
2022-01-08 17:43:02,997 iteration 3841 : loss : 0.014694, loss_ce: 0.005016
2022-01-08 17:43:05,444 iteration 3842 : loss : 0.017201, loss_ce: 0.003802
 56%|███████████████▎           | 226/400 [2:43:12<2:13:18, 45.97s/it]2022-01-08 17:43:07,906 iteration 3843 : loss : 0.020114, loss_ce: 0.007236
2022-01-08 17:43:10,325 iteration 3844 : loss : 0.018809, loss_ce: 0.008753
2022-01-08 17:43:12,730 iteration 3845 : loss : 0.022871, loss_ce: 0.007680
2022-01-08 17:43:15,119 iteration 3846 : loss : 0.013889, loss_ce: 0.003367
2022-01-08 17:43:17,705 iteration 3847 : loss : 0.013784, loss_ce: 0.005188
2022-01-08 17:43:20,123 iteration 3848 : loss : 0.015599, loss_ce: 0.006241
2022-01-08 17:43:22,498 iteration 3849 : loss : 0.015733, loss_ce: 0.006070
2022-01-08 17:43:24,903 iteration 3850 : loss : 0.046659, loss_ce: 0.016376
2022-01-08 17:43:27,385 iteration 3851 : loss : 0.032825, loss_ce: 0.019321
2022-01-08 17:43:29,820 iteration 3852 : loss : 0.031242, loss_ce: 0.009726
2022-01-08 17:43:32,225 iteration 3853 : loss : 0.015881, loss_ce: 0.008564
2022-01-08 17:43:34,681 iteration 3854 : loss : 0.019270, loss_ce: 0.007947
2022-01-08 17:43:37,231 iteration 3855 : loss : 0.017960, loss_ce: 0.006423
2022-01-08 17:43:39,631 iteration 3856 : loss : 0.018244, loss_ce: 0.005830
2022-01-08 17:43:42,042 iteration 3857 : loss : 0.021486, loss_ce: 0.008616
2022-01-08 17:43:44,486 iteration 3858 : loss : 0.018588, loss_ce: 0.007132
2022-01-08 17:43:46,884 iteration 3859 : loss : 0.027722, loss_ce: 0.005711
 57%|███████████████▎           | 227/400 [2:43:53<2:08:37, 44.61s/it]2022-01-08 17:43:49,483 iteration 3860 : loss : 0.020593, loss_ce: 0.008494
2022-01-08 17:43:51,927 iteration 3861 : loss : 0.020955, loss_ce: 0.009040
2022-01-08 17:43:54,222 iteration 3862 : loss : 0.016669, loss_ce: 0.007835
2022-01-08 17:43:56,678 iteration 3863 : loss : 0.023026, loss_ce: 0.010888
2022-01-08 17:43:59,265 iteration 3864 : loss : 0.024002, loss_ce: 0.009106
2022-01-08 17:44:01,783 iteration 3865 : loss : 0.021665, loss_ce: 0.008925
2022-01-08 17:44:04,239 iteration 3866 : loss : 0.026619, loss_ce: 0.011928
2022-01-08 17:44:06,629 iteration 3867 : loss : 0.013786, loss_ce: 0.005088
2022-01-08 17:44:09,139 iteration 3868 : loss : 0.019190, loss_ce: 0.007552
2022-01-08 17:44:11,545 iteration 3869 : loss : 0.021721, loss_ce: 0.008315
2022-01-08 17:44:14,026 iteration 3870 : loss : 0.018830, loss_ce: 0.005418
2022-01-08 17:44:16,479 iteration 3871 : loss : 0.020396, loss_ce: 0.005355
2022-01-08 17:44:18,870 iteration 3872 : loss : 0.019787, loss_ce: 0.008326
2022-01-08 17:44:21,426 iteration 3873 : loss : 0.019050, loss_ce: 0.006853
2022-01-08 17:44:23,849 iteration 3874 : loss : 0.017921, loss_ce: 0.007360
2022-01-08 17:44:26,230 iteration 3875 : loss : 0.017153, loss_ce: 0.005831
2022-01-08 17:44:28,571 iteration 3876 : loss : 0.022112, loss_ce: 0.004210
 57%|███████████████▍           | 228/400 [2:44:35<2:05:22, 43.73s/it]2022-01-08 17:44:31,056 iteration 3877 : loss : 0.016257, loss_ce: 0.006429
2022-01-08 17:44:33,501 iteration 3878 : loss : 0.018190, loss_ce: 0.008799
2022-01-08 17:44:35,936 iteration 3879 : loss : 0.024327, loss_ce: 0.010574
2022-01-08 17:44:38,376 iteration 3880 : loss : 0.016213, loss_ce: 0.007224
2022-01-08 17:44:40,779 iteration 3881 : loss : 0.016490, loss_ce: 0.008130
2022-01-08 17:44:43,225 iteration 3882 : loss : 0.026658, loss_ce: 0.010574
2022-01-08 17:44:45,764 iteration 3883 : loss : 0.042579, loss_ce: 0.017179
2022-01-08 17:44:48,138 iteration 3884 : loss : 0.033300, loss_ce: 0.005255
2022-01-08 17:44:50,643 iteration 3885 : loss : 0.015371, loss_ce: 0.005153
2022-01-08 17:44:53,018 iteration 3886 : loss : 0.019389, loss_ce: 0.007068
2022-01-08 17:44:55,442 iteration 3887 : loss : 0.025288, loss_ce: 0.010807
2022-01-08 17:44:57,973 iteration 3888 : loss : 0.018407, loss_ce: 0.006953
2022-01-08 17:45:00,357 iteration 3889 : loss : 0.027901, loss_ce: 0.011190
2022-01-08 17:45:02,666 iteration 3890 : loss : 0.019021, loss_ce: 0.006482
2022-01-08 17:45:05,063 iteration 3891 : loss : 0.012205, loss_ce: 0.004533
2022-01-08 17:45:07,490 iteration 3892 : loss : 0.023037, loss_ce: 0.005493
2022-01-08 17:45:10,002 iteration 3893 : loss : 0.024757, loss_ce: 0.012889
 57%|███████████████▍           | 229/400 [2:45:16<2:02:40, 43.04s/it]2022-01-08 17:45:12,583 iteration 3894 : loss : 0.017249, loss_ce: 0.007742
2022-01-08 17:45:15,015 iteration 3895 : loss : 0.019401, loss_ce: 0.008049
2022-01-08 17:45:17,347 iteration 3896 : loss : 0.018329, loss_ce: 0.005182
2022-01-08 17:45:19,741 iteration 3897 : loss : 0.038579, loss_ce: 0.017334
2022-01-08 17:45:22,169 iteration 3898 : loss : 0.020686, loss_ce: 0.008085
2022-01-08 17:45:24,637 iteration 3899 : loss : 0.024967, loss_ce: 0.010575
2022-01-08 17:45:27,124 iteration 3900 : loss : 0.025959, loss_ce: 0.008222
2022-01-08 17:45:29,454 iteration 3901 : loss : 0.015133, loss_ce: 0.004881
2022-01-08 17:45:31,861 iteration 3902 : loss : 0.014112, loss_ce: 0.004931
2022-01-08 17:45:34,266 iteration 3903 : loss : 0.019570, loss_ce: 0.007273
2022-01-08 17:45:36,914 iteration 3904 : loss : 0.028272, loss_ce: 0.012184
2022-01-08 17:45:39,328 iteration 3905 : loss : 0.038886, loss_ce: 0.024229
2022-01-08 17:45:41,670 iteration 3906 : loss : 0.020226, loss_ce: 0.009978
2022-01-08 17:45:44,171 iteration 3907 : loss : 0.017256, loss_ce: 0.005517
2022-01-08 17:45:46,630 iteration 3908 : loss : 0.031646, loss_ce: 0.010159
2022-01-08 17:45:48,979 iteration 3909 : loss : 0.027770, loss_ce: 0.011332
2022-01-08 17:45:48,979 Training Data Eval:
2022-01-08 17:46:02,010   Average segmentation loss on training set: 0.0128
2022-01-08 17:46:02,010 Validation Data Eval:
2022-01-08 17:46:06,647   Average segmentation loss on validation set: 0.0713
2022-01-08 17:46:09,071 iteration 3910 : loss : 0.015073, loss_ce: 0.005034
 57%|███████████████▌           | 230/400 [2:46:15<2:15:34, 47.85s/it]2022-01-08 17:46:11,493 iteration 3911 : loss : 0.016572, loss_ce: 0.005283
2022-01-08 17:46:13,962 iteration 3912 : loss : 0.021791, loss_ce: 0.008502
2022-01-08 17:46:16,340 iteration 3913 : loss : 0.017366, loss_ce: 0.005332
2022-01-08 17:46:18,745 iteration 3914 : loss : 0.016268, loss_ce: 0.005958
2022-01-08 17:46:21,222 iteration 3915 : loss : 0.018176, loss_ce: 0.006176
2022-01-08 17:46:23,658 iteration 3916 : loss : 0.027092, loss_ce: 0.010863
2022-01-08 17:46:26,171 iteration 3917 : loss : 0.044844, loss_ce: 0.013002
2022-01-08 17:46:28,598 iteration 3918 : loss : 0.021331, loss_ce: 0.008782
2022-01-08 17:46:31,059 iteration 3919 : loss : 0.020743, loss_ce: 0.007990
2022-01-08 17:46:33,536 iteration 3920 : loss : 0.024037, loss_ce: 0.010827
2022-01-08 17:46:35,964 iteration 3921 : loss : 0.039794, loss_ce: 0.011696
2022-01-08 17:46:38,452 iteration 3922 : loss : 0.014225, loss_ce: 0.006007
2022-01-08 17:46:40,904 iteration 3923 : loss : 0.020467, loss_ce: 0.009301
2022-01-08 17:46:43,354 iteration 3924 : loss : 0.019922, loss_ce: 0.008384
2022-01-08 17:46:45,865 iteration 3925 : loss : 0.023473, loss_ce: 0.009410
2022-01-08 17:46:48,470 iteration 3926 : loss : 0.026240, loss_ce: 0.008404
2022-01-08 17:46:50,865 iteration 3927 : loss : 0.035089, loss_ce: 0.019339
 58%|███████████████▌           | 231/400 [2:46:57<2:09:39, 46.04s/it]2022-01-08 17:46:53,359 iteration 3928 : loss : 0.022300, loss_ce: 0.009281
2022-01-08 17:46:56,011 iteration 3929 : loss : 0.037842, loss_ce: 0.016767
2022-01-08 17:46:58,540 iteration 3930 : loss : 0.029460, loss_ce: 0.010713
2022-01-08 17:47:00,889 iteration 3931 : loss : 0.020221, loss_ce: 0.008798
2022-01-08 17:47:03,331 iteration 3932 : loss : 0.018645, loss_ce: 0.005323
2022-01-08 17:47:05,692 iteration 3933 : loss : 0.027638, loss_ce: 0.006234
2022-01-08 17:47:08,157 iteration 3934 : loss : 0.022134, loss_ce: 0.007940
2022-01-08 17:47:10,599 iteration 3935 : loss : 0.021396, loss_ce: 0.007410
2022-01-08 17:47:13,068 iteration 3936 : loss : 0.021279, loss_ce: 0.009299
2022-01-08 17:47:15,652 iteration 3937 : loss : 0.014658, loss_ce: 0.004128
2022-01-08 17:47:18,042 iteration 3938 : loss : 0.018572, loss_ce: 0.009537
2022-01-08 17:47:20,502 iteration 3939 : loss : 0.027377, loss_ce: 0.009672
2022-01-08 17:47:23,047 iteration 3940 : loss : 0.028744, loss_ce: 0.006684
2022-01-08 17:47:25,414 iteration 3941 : loss : 0.022171, loss_ce: 0.011691
2022-01-08 17:47:27,847 iteration 3942 : loss : 0.021796, loss_ce: 0.009459
2022-01-08 17:47:30,261 iteration 3943 : loss : 0.018188, loss_ce: 0.008631
2022-01-08 17:47:32,718 iteration 3944 : loss : 0.022761, loss_ce: 0.007788
 58%|███████████████▋           | 232/400 [2:47:39<2:05:22, 44.78s/it]2022-01-08 17:47:35,207 iteration 3945 : loss : 0.015659, loss_ce: 0.007133
2022-01-08 17:47:37,563 iteration 3946 : loss : 0.014340, loss_ce: 0.005371
2022-01-08 17:47:40,014 iteration 3947 : loss : 0.018870, loss_ce: 0.006842
2022-01-08 17:47:42,515 iteration 3948 : loss : 0.018065, loss_ce: 0.007717
2022-01-08 17:47:44,968 iteration 3949 : loss : 0.027017, loss_ce: 0.011999
2022-01-08 17:47:47,459 iteration 3950 : loss : 0.018597, loss_ce: 0.006307
2022-01-08 17:47:49,873 iteration 3951 : loss : 0.023909, loss_ce: 0.009954
2022-01-08 17:47:52,348 iteration 3952 : loss : 0.016684, loss_ce: 0.007407
2022-01-08 17:47:54,815 iteration 3953 : loss : 0.016636, loss_ce: 0.005124
2022-01-08 17:47:57,317 iteration 3954 : loss : 0.022280, loss_ce: 0.009068
2022-01-08 17:47:59,789 iteration 3955 : loss : 0.027291, loss_ce: 0.009092
2022-01-08 17:48:02,183 iteration 3956 : loss : 0.024064, loss_ce: 0.009504
2022-01-08 17:48:04,706 iteration 3957 : loss : 0.018752, loss_ce: 0.008240
2022-01-08 17:48:07,177 iteration 3958 : loss : 0.029075, loss_ce: 0.012297
2022-01-08 17:48:09,621 iteration 3959 : loss : 0.019960, loss_ce: 0.005449
2022-01-08 17:48:12,199 iteration 3960 : loss : 0.022256, loss_ce: 0.004656
2022-01-08 17:48:14,618 iteration 3961 : loss : 0.017277, loss_ce: 0.006687
 58%|███████████████▋           | 233/400 [2:48:21<2:02:14, 43.92s/it]2022-01-08 17:48:17,147 iteration 3962 : loss : 0.029131, loss_ce: 0.013911
2022-01-08 17:48:19,582 iteration 3963 : loss : 0.018941, loss_ce: 0.008041
2022-01-08 17:48:22,066 iteration 3964 : loss : 0.036094, loss_ce: 0.015920
2022-01-08 17:48:24,712 iteration 3965 : loss : 0.025114, loss_ce: 0.007896
2022-01-08 17:48:27,138 iteration 3966 : loss : 0.023906, loss_ce: 0.008200
2022-01-08 17:48:29,623 iteration 3967 : loss : 0.024552, loss_ce: 0.006702
2022-01-08 17:48:32,087 iteration 3968 : loss : 0.033160, loss_ce: 0.013450
2022-01-08 17:48:34,674 iteration 3969 : loss : 0.026089, loss_ce: 0.011413
2022-01-08 17:48:37,155 iteration 3970 : loss : 0.020789, loss_ce: 0.011248
2022-01-08 17:48:39,502 iteration 3971 : loss : 0.016887, loss_ce: 0.005644
2022-01-08 17:48:41,995 iteration 3972 : loss : 0.022793, loss_ce: 0.009001
2022-01-08 17:48:44,391 iteration 3973 : loss : 0.029704, loss_ce: 0.012575
2022-01-08 17:48:46,793 iteration 3974 : loss : 0.024044, loss_ce: 0.009467
2022-01-08 17:48:49,312 iteration 3975 : loss : 0.018630, loss_ce: 0.006434
2022-01-08 17:48:51,949 iteration 3976 : loss : 0.022773, loss_ce: 0.008748
2022-01-08 17:48:54,370 iteration 3977 : loss : 0.021201, loss_ce: 0.007924
2022-01-08 17:48:56,739 iteration 3978 : loss : 0.019191, loss_ce: 0.007837
 58%|███████████████▊           | 234/400 [2:49:03<2:00:00, 43.38s/it]2022-01-08 17:48:59,199 iteration 3979 : loss : 0.031437, loss_ce: 0.010213
2022-01-08 17:49:01,622 iteration 3980 : loss : 0.019701, loss_ce: 0.008996
2022-01-08 17:49:04,035 iteration 3981 : loss : 0.018238, loss_ce: 0.006516
2022-01-08 17:49:06,711 iteration 3982 : loss : 0.022510, loss_ce: 0.007141
2022-01-08 17:49:09,165 iteration 3983 : loss : 0.019954, loss_ce: 0.005723
2022-01-08 17:49:11,680 iteration 3984 : loss : 0.025268, loss_ce: 0.009426
2022-01-08 17:49:14,086 iteration 3985 : loss : 0.019482, loss_ce: 0.005901
2022-01-08 17:49:16,513 iteration 3986 : loss : 0.015953, loss_ce: 0.006594
2022-01-08 17:49:18,907 iteration 3987 : loss : 0.014025, loss_ce: 0.006085
2022-01-08 17:49:21,358 iteration 3988 : loss : 0.025840, loss_ce: 0.011442
2022-01-08 17:49:23,835 iteration 3989 : loss : 0.028639, loss_ce: 0.013532
2022-01-08 17:49:26,434 iteration 3990 : loss : 0.015283, loss_ce: 0.005426
2022-01-08 17:49:28,816 iteration 3991 : loss : 0.023377, loss_ce: 0.008573
2022-01-08 17:49:31,329 iteration 3992 : loss : 0.036727, loss_ce: 0.010361
2022-01-08 17:49:33,763 iteration 3993 : loss : 0.025742, loss_ce: 0.011949
2022-01-08 17:49:36,205 iteration 3994 : loss : 0.020146, loss_ce: 0.007895
2022-01-08 17:49:36,206 Training Data Eval:
2022-01-08 17:49:49,319   Average segmentation loss on training set: 0.0137
2022-01-08 17:49:49,319 Validation Data Eval:
2022-01-08 17:49:53,954   Average segmentation loss on validation set: 0.0805
2022-01-08 17:49:56,469 iteration 3995 : loss : 0.019733, loss_ce: 0.005227
 59%|███████████████▊           | 235/400 [2:50:03<2:12:46, 48.28s/it]2022-01-08 17:49:58,971 iteration 3996 : loss : 0.026366, loss_ce: 0.013996
2022-01-08 17:50:01,541 iteration 3997 : loss : 0.019523, loss_ce: 0.006655
2022-01-08 17:50:03,956 iteration 3998 : loss : 0.023823, loss_ce: 0.008728
2022-01-08 17:50:06,417 iteration 3999 : loss : 0.018481, loss_ce: 0.006065
2022-01-08 17:50:08,833 iteration 4000 : loss : 0.023026, loss_ce: 0.009392
2022-01-08 17:50:11,332 iteration 4001 : loss : 0.036617, loss_ce: 0.012397
2022-01-08 17:50:13,670 iteration 4002 : loss : 0.018205, loss_ce: 0.008981
2022-01-08 17:50:16,306 iteration 4003 : loss : 0.019879, loss_ce: 0.007804
2022-01-08 17:50:18,785 iteration 4004 : loss : 0.017106, loss_ce: 0.006312
2022-01-08 17:50:21,210 iteration 4005 : loss : 0.022378, loss_ce: 0.010384
2022-01-08 17:50:23,726 iteration 4006 : loss : 0.027326, loss_ce: 0.009045
2022-01-08 17:50:26,307 iteration 4007 : loss : 0.016832, loss_ce: 0.006333
2022-01-08 17:50:28,815 iteration 4008 : loss : 0.028485, loss_ce: 0.009716
2022-01-08 17:50:31,288 iteration 4009 : loss : 0.016098, loss_ce: 0.006121
2022-01-08 17:50:33,716 iteration 4010 : loss : 0.013630, loss_ce: 0.004938
2022-01-08 17:50:36,229 iteration 4011 : loss : 0.028982, loss_ce: 0.007609
2022-01-08 17:50:38,659 iteration 4012 : loss : 0.020503, loss_ce: 0.009719
 59%|███████████████▉           | 236/400 [2:50:45<2:06:58, 46.46s/it]2022-01-08 17:50:41,221 iteration 4013 : loss : 0.025624, loss_ce: 0.006648
2022-01-08 17:50:43,659 iteration 4014 : loss : 0.018243, loss_ce: 0.005770
2022-01-08 17:50:46,074 iteration 4015 : loss : 0.018587, loss_ce: 0.009100
2022-01-08 17:50:48,676 iteration 4016 : loss : 0.020624, loss_ce: 0.007011
2022-01-08 17:50:51,091 iteration 4017 : loss : 0.020036, loss_ce: 0.007798
2022-01-08 17:50:53,591 iteration 4018 : loss : 0.021382, loss_ce: 0.007987
2022-01-08 17:50:56,044 iteration 4019 : loss : 0.021694, loss_ce: 0.009706
2022-01-08 17:50:58,436 iteration 4020 : loss : 0.017326, loss_ce: 0.006569
2022-01-08 17:51:01,000 iteration 4021 : loss : 0.019503, loss_ce: 0.006480
2022-01-08 17:51:03,388 iteration 4022 : loss : 0.023878, loss_ce: 0.006962
2022-01-08 17:51:05,861 iteration 4023 : loss : 0.022170, loss_ce: 0.009257
2022-01-08 17:51:08,406 iteration 4024 : loss : 0.028478, loss_ce: 0.010084
2022-01-08 17:51:10,772 iteration 4025 : loss : 0.022789, loss_ce: 0.008907
2022-01-08 17:51:13,387 iteration 4026 : loss : 0.012314, loss_ce: 0.004932
2022-01-08 17:51:15,786 iteration 4027 : loss : 0.015629, loss_ce: 0.006103
2022-01-08 17:51:18,303 iteration 4028 : loss : 0.015253, loss_ce: 0.003752
2022-01-08 17:51:20,706 iteration 4029 : loss : 0.019898, loss_ce: 0.007164
 59%|███████████████▉           | 237/400 [2:51:27<2:02:35, 45.13s/it]2022-01-08 17:51:23,106 iteration 4030 : loss : 0.024320, loss_ce: 0.010971
2022-01-08 17:51:25,732 iteration 4031 : loss : 0.022686, loss_ce: 0.010244
2022-01-08 17:51:28,158 iteration 4032 : loss : 0.020135, loss_ce: 0.008121
2022-01-08 17:51:30,587 iteration 4033 : loss : 0.030576, loss_ce: 0.008868
2022-01-08 17:51:33,046 iteration 4034 : loss : 0.021729, loss_ce: 0.007271
2022-01-08 17:51:35,457 iteration 4035 : loss : 0.028066, loss_ce: 0.009381
2022-01-08 17:51:37,903 iteration 4036 : loss : 0.019283, loss_ce: 0.007811
2022-01-08 17:51:40,336 iteration 4037 : loss : 0.018841, loss_ce: 0.005946
2022-01-08 17:51:42,790 iteration 4038 : loss : 0.018950, loss_ce: 0.011380
2022-01-08 17:51:45,139 iteration 4039 : loss : 0.015412, loss_ce: 0.007604
2022-01-08 17:51:47,677 iteration 4040 : loss : 0.025974, loss_ce: 0.005979
2022-01-08 17:51:50,344 iteration 4041 : loss : 0.031864, loss_ce: 0.017053
2022-01-08 17:51:52,697 iteration 4042 : loss : 0.017649, loss_ce: 0.007845
2022-01-08 17:51:55,089 iteration 4043 : loss : 0.016462, loss_ce: 0.005806
2022-01-08 17:51:57,501 iteration 4044 : loss : 0.021386, loss_ce: 0.008730
2022-01-08 17:51:59,897 iteration 4045 : loss : 0.018366, loss_ce: 0.007441
2022-01-08 17:52:02,338 iteration 4046 : loss : 0.022228, loss_ce: 0.006922
 60%|████████████████           | 238/400 [2:52:09<1:59:00, 44.08s/it]2022-01-08 17:52:04,876 iteration 4047 : loss : 0.015243, loss_ce: 0.006463
2022-01-08 17:52:07,264 iteration 4048 : loss : 0.015175, loss_ce: 0.004621
2022-01-08 17:52:09,692 iteration 4049 : loss : 0.029184, loss_ce: 0.011289
2022-01-08 17:52:12,053 iteration 4050 : loss : 0.017793, loss_ce: 0.004682
2022-01-08 17:52:14,535 iteration 4051 : loss : 0.013340, loss_ce: 0.004322
2022-01-08 17:52:16,948 iteration 4052 : loss : 0.017158, loss_ce: 0.005037
2022-01-08 17:52:19,485 iteration 4053 : loss : 0.018915, loss_ce: 0.009469
2022-01-08 17:52:21,873 iteration 4054 : loss : 0.019404, loss_ce: 0.007678
2022-01-08 17:52:24,319 iteration 4055 : loss : 0.023956, loss_ce: 0.007220
2022-01-08 17:52:26,751 iteration 4056 : loss : 0.021531, loss_ce: 0.006756
2022-01-08 17:52:29,276 iteration 4057 : loss : 0.022578, loss_ce: 0.009331
2022-01-08 17:52:31,619 iteration 4058 : loss : 0.018976, loss_ce: 0.007704
2022-01-08 17:52:34,089 iteration 4059 : loss : 0.019423, loss_ce: 0.008786
2022-01-08 17:52:36,681 iteration 4060 : loss : 0.019902, loss_ce: 0.007372
2022-01-08 17:52:39,086 iteration 4061 : loss : 0.023382, loss_ce: 0.007132
2022-01-08 17:52:41,446 iteration 4062 : loss : 0.025441, loss_ce: 0.010932
2022-01-08 17:52:44,025 iteration 4063 : loss : 0.040177, loss_ce: 0.012615
 60%|████████████████▏          | 239/400 [2:52:50<1:56:22, 43.37s/it]2022-01-08 17:52:46,614 iteration 4064 : loss : 0.027857, loss_ce: 0.009748
2022-01-08 17:52:48,988 iteration 4065 : loss : 0.018179, loss_ce: 0.006648
2022-01-08 17:52:51,374 iteration 4066 : loss : 0.013652, loss_ce: 0.004230
2022-01-08 17:52:53,739 iteration 4067 : loss : 0.025938, loss_ce: 0.004411
2022-01-08 17:52:56,182 iteration 4068 : loss : 0.019342, loss_ce: 0.007444
2022-01-08 17:52:58,625 iteration 4069 : loss : 0.023771, loss_ce: 0.007626
2022-01-08 17:53:01,218 iteration 4070 : loss : 0.018912, loss_ce: 0.009971
2022-01-08 17:53:03,651 iteration 4071 : loss : 0.018544, loss_ce: 0.007382
2022-01-08 17:53:06,068 iteration 4072 : loss : 0.016564, loss_ce: 0.006900
2022-01-08 17:53:08,469 iteration 4073 : loss : 0.022945, loss_ce: 0.009582
2022-01-08 17:53:10,777 iteration 4074 : loss : 0.028361, loss_ce: 0.009341
2022-01-08 17:53:13,346 iteration 4075 : loss : 0.017189, loss_ce: 0.006527
2022-01-08 17:53:15,748 iteration 4076 : loss : 0.018264, loss_ce: 0.005617
2022-01-08 17:53:18,156 iteration 4077 : loss : 0.016392, loss_ce: 0.006881
2022-01-08 17:53:20,618 iteration 4078 : loss : 0.027424, loss_ce: 0.007409
2022-01-08 17:53:23,082 iteration 4079 : loss : 0.016592, loss_ce: 0.005741
2022-01-08 17:53:23,083 Training Data Eval:
2022-01-08 17:53:36,176   Average segmentation loss on training set: 0.0116
2022-01-08 17:53:36,177 Validation Data Eval:
2022-01-08 17:53:40,790   Average segmentation loss on validation set: 0.0679
2022-01-08 17:53:43,250 iteration 4080 : loss : 0.025546, loss_ce: 0.007213
 60%|████████████████▏          | 240/400 [2:53:50<2:08:18, 48.12s/it]2022-01-08 17:53:45,673 iteration 4081 : loss : 0.017581, loss_ce: 0.008480
2022-01-08 17:53:48,138 iteration 4082 : loss : 0.022728, loss_ce: 0.008222
2022-01-08 17:53:50,490 iteration 4083 : loss : 0.015930, loss_ce: 0.006166
2022-01-08 17:53:52,988 iteration 4084 : loss : 0.015827, loss_ce: 0.005414
2022-01-08 17:53:55,375 iteration 4085 : loss : 0.027159, loss_ce: 0.006690
2022-01-08 17:53:57,811 iteration 4086 : loss : 0.016151, loss_ce: 0.005519
2022-01-08 17:54:00,297 iteration 4087 : loss : 0.020165, loss_ce: 0.006372
2022-01-08 17:54:02,776 iteration 4088 : loss : 0.020824, loss_ce: 0.009566
2022-01-08 17:54:05,183 iteration 4089 : loss : 0.030518, loss_ce: 0.010251
2022-01-08 17:54:07,583 iteration 4090 : loss : 0.026268, loss_ce: 0.013360
2022-01-08 17:54:10,023 iteration 4091 : loss : 0.029183, loss_ce: 0.012051
2022-01-08 17:54:12,442 iteration 4092 : loss : 0.021148, loss_ce: 0.005623
2022-01-08 17:54:14,891 iteration 4093 : loss : 0.015976, loss_ce: 0.007183
2022-01-08 17:54:17,330 iteration 4094 : loss : 0.020288, loss_ce: 0.006416
2022-01-08 17:54:19,960 iteration 4095 : loss : 0.020120, loss_ce: 0.005903
2022-01-08 17:54:22,388 iteration 4096 : loss : 0.020305, loss_ce: 0.008205
2022-01-08 17:54:24,763 iteration 4097 : loss : 0.020674, loss_ce: 0.008158
 60%|████████████████▎          | 241/400 [2:54:31<2:02:15, 46.14s/it]2022-01-08 17:54:27,276 iteration 4098 : loss : 0.014526, loss_ce: 0.005384
2022-01-08 17:54:29,735 iteration 4099 : loss : 0.017518, loss_ce: 0.006226
2022-01-08 17:54:32,144 iteration 4100 : loss : 0.020100, loss_ce: 0.007662
2022-01-08 17:54:34,578 iteration 4101 : loss : 0.015891, loss_ce: 0.007146
2022-01-08 17:54:37,014 iteration 4102 : loss : 0.026973, loss_ce: 0.010110
2022-01-08 17:54:39,399 iteration 4103 : loss : 0.015587, loss_ce: 0.006396
2022-01-08 17:54:41,971 iteration 4104 : loss : 0.025945, loss_ce: 0.009352
2022-01-08 17:54:44,411 iteration 4105 : loss : 0.026826, loss_ce: 0.009131
2022-01-08 17:54:47,069 iteration 4106 : loss : 0.025821, loss_ce: 0.008601
2022-01-08 17:54:49,485 iteration 4107 : loss : 0.018811, loss_ce: 0.006980
2022-01-08 17:54:51,955 iteration 4108 : loss : 0.026370, loss_ce: 0.011353
2022-01-08 17:54:54,370 iteration 4109 : loss : 0.034337, loss_ce: 0.011448
2022-01-08 17:54:56,856 iteration 4110 : loss : 0.017940, loss_ce: 0.006402
2022-01-08 17:54:59,397 iteration 4111 : loss : 0.019720, loss_ce: 0.005779
2022-01-08 17:55:01,720 iteration 4112 : loss : 0.013306, loss_ce: 0.005540
2022-01-08 17:55:04,201 iteration 4113 : loss : 0.022419, loss_ce: 0.007319
2022-01-08 17:55:06,597 iteration 4114 : loss : 0.023484, loss_ce: 0.009628
 60%|████████████████▎          | 242/400 [2:55:13<1:58:05, 44.85s/it]2022-01-08 17:55:08,952 iteration 4115 : loss : 0.018601, loss_ce: 0.004820
2022-01-08 17:55:11,340 iteration 4116 : loss : 0.017684, loss_ce: 0.007837
2022-01-08 17:55:13,692 iteration 4117 : loss : 0.015280, loss_ce: 0.007874
2022-01-08 17:55:16,165 iteration 4118 : loss : 0.022292, loss_ce: 0.006183
2022-01-08 17:55:18,528 iteration 4119 : loss : 0.014598, loss_ce: 0.005435
2022-01-08 17:55:21,227 iteration 4120 : loss : 0.020973, loss_ce: 0.006523
2022-01-08 17:55:23,680 iteration 4121 : loss : 0.016195, loss_ce: 0.006243
2022-01-08 17:55:26,095 iteration 4122 : loss : 0.019010, loss_ce: 0.007103
2022-01-08 17:55:28,423 iteration 4123 : loss : 0.023130, loss_ce: 0.009678
2022-01-08 17:55:30,697 iteration 4124 : loss : 0.019955, loss_ce: 0.007214
2022-01-08 17:55:33,174 iteration 4125 : loss : 0.024596, loss_ce: 0.007723
2022-01-08 17:55:35,691 iteration 4126 : loss : 0.021908, loss_ce: 0.010103
2022-01-08 17:55:38,151 iteration 4127 : loss : 0.023998, loss_ce: 0.010830
2022-01-08 17:55:40,594 iteration 4128 : loss : 0.015719, loss_ce: 0.007078
2022-01-08 17:55:43,101 iteration 4129 : loss : 0.029074, loss_ce: 0.006864
2022-01-08 17:55:45,506 iteration 4130 : loss : 0.025237, loss_ce: 0.009098
2022-01-08 17:55:47,968 iteration 4131 : loss : 0.015219, loss_ce: 0.006112
 61%|████████████████▍          | 243/400 [2:55:54<1:54:36, 43.80s/it]2022-01-08 17:55:50,436 iteration 4132 : loss : 0.028279, loss_ce: 0.008186
2022-01-08 17:55:52,804 iteration 4133 : loss : 0.021411, loss_ce: 0.010933
2022-01-08 17:55:55,387 iteration 4134 : loss : 0.015258, loss_ce: 0.006480
2022-01-08 17:55:57,787 iteration 4135 : loss : 0.030487, loss_ce: 0.010310
2022-01-08 17:56:00,194 iteration 4136 : loss : 0.018362, loss_ce: 0.006030
2022-01-08 17:56:02,738 iteration 4137 : loss : 0.018754, loss_ce: 0.009474
2022-01-08 17:56:05,145 iteration 4138 : loss : 0.014509, loss_ce: 0.007564
2022-01-08 17:56:07,648 iteration 4139 : loss : 0.023570, loss_ce: 0.005838
2022-01-08 17:56:10,239 iteration 4140 : loss : 0.019537, loss_ce: 0.006496
2022-01-08 17:56:12,627 iteration 4141 : loss : 0.017864, loss_ce: 0.004711
2022-01-08 17:56:14,957 iteration 4142 : loss : 0.017395, loss_ce: 0.007980
2022-01-08 17:56:17,458 iteration 4143 : loss : 0.018269, loss_ce: 0.006422
2022-01-08 17:56:19,867 iteration 4144 : loss : 0.017582, loss_ce: 0.006112
2022-01-08 17:56:22,273 iteration 4145 : loss : 0.022841, loss_ce: 0.008184
2022-01-08 17:56:24,632 iteration 4146 : loss : 0.015889, loss_ce: 0.003955
2022-01-08 17:56:27,028 iteration 4147 : loss : 0.015624, loss_ce: 0.005888
2022-01-08 17:56:29,549 iteration 4148 : loss : 0.022833, loss_ce: 0.007652
 61%|████████████████▍          | 244/400 [2:56:36<1:52:10, 43.14s/it]2022-01-08 17:56:32,002 iteration 4149 : loss : 0.021660, loss_ce: 0.008271
2022-01-08 17:56:34,445 iteration 4150 : loss : 0.016042, loss_ce: 0.005814
2022-01-08 17:56:36,900 iteration 4151 : loss : 0.015617, loss_ce: 0.006354
2022-01-08 17:56:39,364 iteration 4152 : loss : 0.024912, loss_ce: 0.011785
2022-01-08 17:56:41,809 iteration 4153 : loss : 0.021076, loss_ce: 0.009701
2022-01-08 17:56:44,248 iteration 4154 : loss : 0.016356, loss_ce: 0.006898
2022-01-08 17:56:46,633 iteration 4155 : loss : 0.018090, loss_ce: 0.008765
2022-01-08 17:56:49,017 iteration 4156 : loss : 0.020713, loss_ce: 0.007226
2022-01-08 17:56:51,413 iteration 4157 : loss : 0.018251, loss_ce: 0.006711
2022-01-08 17:56:53,866 iteration 4158 : loss : 0.014894, loss_ce: 0.005782
2022-01-08 17:56:56,291 iteration 4159 : loss : 0.014626, loss_ce: 0.005992
2022-01-08 17:56:58,798 iteration 4160 : loss : 0.021603, loss_ce: 0.007681
2022-01-08 17:57:01,208 iteration 4161 : loss : 0.017412, loss_ce: 0.005012
2022-01-08 17:57:03,710 iteration 4162 : loss : 0.023799, loss_ce: 0.008751
2022-01-08 17:57:06,106 iteration 4163 : loss : 0.019188, loss_ce: 0.006861
2022-01-08 17:57:08,455 iteration 4164 : loss : 0.017292, loss_ce: 0.004933
2022-01-08 17:57:08,455 Training Data Eval:
2022-01-08 17:57:21,392   Average segmentation loss on training set: 0.0110
2022-01-08 17:57:21,392 Validation Data Eval:
2022-01-08 17:57:26,034   Average segmentation loss on validation set: 0.0685
2022-01-08 17:57:28,478 iteration 4165 : loss : 0.019916, loss_ce: 0.005626
 61%|████████████████▌          | 245/400 [2:57:35<2:03:41, 47.88s/it]2022-01-08 17:57:31,057 iteration 4166 : loss : 0.023602, loss_ce: 0.005714
2022-01-08 17:57:33,411 iteration 4167 : loss : 0.013545, loss_ce: 0.005608
2022-01-08 17:57:35,823 iteration 4168 : loss : 0.014026, loss_ce: 0.004286
2022-01-08 17:57:38,195 iteration 4169 : loss : 0.017802, loss_ce: 0.007571
2022-01-08 17:57:40,629 iteration 4170 : loss : 0.018525, loss_ce: 0.006211
2022-01-08 17:57:43,086 iteration 4171 : loss : 0.022080, loss_ce: 0.007880
2022-01-08 17:57:45,589 iteration 4172 : loss : 0.014115, loss_ce: 0.003176
2022-01-08 17:57:47,981 iteration 4173 : loss : 0.019422, loss_ce: 0.006430
2022-01-08 17:57:50,409 iteration 4174 : loss : 0.022142, loss_ce: 0.010875
2022-01-08 17:57:52,827 iteration 4175 : loss : 0.019588, loss_ce: 0.006805
2022-01-08 17:57:55,325 iteration 4176 : loss : 0.018914, loss_ce: 0.009041
2022-01-08 17:57:57,731 iteration 4177 : loss : 0.023428, loss_ce: 0.007684
2022-01-08 17:58:00,202 iteration 4178 : loss : 0.016680, loss_ce: 0.006716
2022-01-08 17:58:02,662 iteration 4179 : loss : 0.019217, loss_ce: 0.007467
2022-01-08 17:58:05,013 iteration 4180 : loss : 0.024454, loss_ce: 0.008385
2022-01-08 17:58:07,304 iteration 4181 : loss : 0.026330, loss_ce: 0.007533
2022-01-08 17:58:09,752 iteration 4182 : loss : 0.025606, loss_ce: 0.011016
 62%|████████████████▌          | 246/400 [2:58:16<1:57:47, 45.89s/it]2022-01-08 17:58:12,345 iteration 4183 : loss : 0.034564, loss_ce: 0.012477
2022-01-08 17:58:14,937 iteration 4184 : loss : 0.020361, loss_ce: 0.008865
2022-01-08 17:58:17,376 iteration 4185 : loss : 0.017221, loss_ce: 0.006378
2022-01-08 17:58:19,795 iteration 4186 : loss : 0.016251, loss_ce: 0.006041
2022-01-08 17:58:22,232 iteration 4187 : loss : 0.019103, loss_ce: 0.006091
2022-01-08 17:58:24,588 iteration 4188 : loss : 0.020704, loss_ce: 0.009509
2022-01-08 17:58:27,023 iteration 4189 : loss : 0.017880, loss_ce: 0.005192
2022-01-08 17:58:29,666 iteration 4190 : loss : 0.025200, loss_ce: 0.010188
2022-01-08 17:58:32,067 iteration 4191 : loss : 0.020450, loss_ce: 0.006549
2022-01-08 17:58:34,418 iteration 4192 : loss : 0.021272, loss_ce: 0.005516
2022-01-08 17:58:36,746 iteration 4193 : loss : 0.017020, loss_ce: 0.005316
2022-01-08 17:58:39,335 iteration 4194 : loss : 0.020706, loss_ce: 0.008110
2022-01-08 17:58:41,862 iteration 4195 : loss : 0.034802, loss_ce: 0.010875
2022-01-08 17:58:44,247 iteration 4196 : loss : 0.015154, loss_ce: 0.008492
2022-01-08 17:58:46,760 iteration 4197 : loss : 0.018651, loss_ce: 0.005237
2022-01-08 17:58:49,163 iteration 4198 : loss : 0.023519, loss_ce: 0.008212
2022-01-08 17:58:51,753 iteration 4199 : loss : 0.020197, loss_ce: 0.008155
 62%|████████████████▋          | 247/400 [2:58:58<1:54:03, 44.73s/it]2022-01-08 17:58:54,197 iteration 4200 : loss : 0.018621, loss_ce: 0.006016
2022-01-08 17:58:56,632 iteration 4201 : loss : 0.016522, loss_ce: 0.006833
2022-01-08 17:58:59,034 iteration 4202 : loss : 0.012878, loss_ce: 0.005688
2022-01-08 17:59:01,471 iteration 4203 : loss : 0.013717, loss_ce: 0.005627
2022-01-08 17:59:03,882 iteration 4204 : loss : 0.014969, loss_ce: 0.005429
2022-01-08 17:59:06,388 iteration 4205 : loss : 0.014584, loss_ce: 0.005018
2022-01-08 17:59:08,720 iteration 4206 : loss : 0.017529, loss_ce: 0.005249
2022-01-08 17:59:11,196 iteration 4207 : loss : 0.016371, loss_ce: 0.006964
2022-01-08 17:59:13,549 iteration 4208 : loss : 0.017679, loss_ce: 0.006563
2022-01-08 17:59:15,964 iteration 4209 : loss : 0.028756, loss_ce: 0.007178
2022-01-08 17:59:18,453 iteration 4210 : loss : 0.019390, loss_ce: 0.007171
2022-01-08 17:59:20,778 iteration 4211 : loss : 0.011322, loss_ce: 0.004564
2022-01-08 17:59:23,222 iteration 4212 : loss : 0.015025, loss_ce: 0.005862
2022-01-08 17:59:25,829 iteration 4213 : loss : 0.018171, loss_ce: 0.008270
2022-01-08 17:59:28,255 iteration 4214 : loss : 0.046589, loss_ce: 0.017121
2022-01-08 17:59:30,648 iteration 4215 : loss : 0.015687, loss_ce: 0.005356
2022-01-08 17:59:33,129 iteration 4216 : loss : 0.023633, loss_ce: 0.008136
 62%|████████████████▋          | 248/400 [2:59:40<1:50:45, 43.72s/it]2022-01-08 17:59:35,647 iteration 4217 : loss : 0.018917, loss_ce: 0.008501
2022-01-08 17:59:37,956 iteration 4218 : loss : 0.014298, loss_ce: 0.007034
2022-01-08 17:59:40,389 iteration 4219 : loss : 0.019500, loss_ce: 0.007601
2022-01-08 17:59:42,887 iteration 4220 : loss : 0.032512, loss_ce: 0.012023
2022-01-08 17:59:45,232 iteration 4221 : loss : 0.031071, loss_ce: 0.008731
2022-01-08 17:59:47,607 iteration 4222 : loss : 0.019994, loss_ce: 0.008695
2022-01-08 17:59:50,010 iteration 4223 : loss : 0.018945, loss_ce: 0.006272
2022-01-08 17:59:52,639 iteration 4224 : loss : 0.023339, loss_ce: 0.007551
2022-01-08 17:59:55,102 iteration 4225 : loss : 0.017301, loss_ce: 0.005840
2022-01-08 17:59:57,505 iteration 4226 : loss : 0.019864, loss_ce: 0.005688
2022-01-08 17:59:59,998 iteration 4227 : loss : 0.018263, loss_ce: 0.005775
2022-01-08 18:00:02,436 iteration 4228 : loss : 0.043541, loss_ce: 0.016487
2022-01-08 18:00:04,944 iteration 4229 : loss : 0.017579, loss_ce: 0.006714
2022-01-08 18:00:07,371 iteration 4230 : loss : 0.036594, loss_ce: 0.022652
2022-01-08 18:00:09,877 iteration 4231 : loss : 0.022741, loss_ce: 0.007477
2022-01-08 18:00:12,323 iteration 4232 : loss : 0.025444, loss_ce: 0.011168
2022-01-08 18:00:14,768 iteration 4233 : loss : 0.023560, loss_ce: 0.010677
 62%|████████████████▊          | 249/400 [3:00:21<1:48:27, 43.10s/it]2022-01-08 18:00:17,274 iteration 4234 : loss : 0.027710, loss_ce: 0.013241
2022-01-08 18:00:19,713 iteration 4235 : loss : 0.019670, loss_ce: 0.005822
2022-01-08 18:00:22,066 iteration 4236 : loss : 0.018548, loss_ce: 0.007607
2022-01-08 18:00:24,558 iteration 4237 : loss : 0.020408, loss_ce: 0.009273
2022-01-08 18:00:27,106 iteration 4238 : loss : 0.023605, loss_ce: 0.007106
2022-01-08 18:00:29,556 iteration 4239 : loss : 0.019562, loss_ce: 0.007760
2022-01-08 18:00:31,962 iteration 4240 : loss : 0.030843, loss_ce: 0.012878
2022-01-08 18:00:34,421 iteration 4241 : loss : 0.019954, loss_ce: 0.008594
2022-01-08 18:00:36,874 iteration 4242 : loss : 0.016525, loss_ce: 0.006346
2022-01-08 18:00:39,329 iteration 4243 : loss : 0.018908, loss_ce: 0.006592
2022-01-08 18:00:41,797 iteration 4244 : loss : 0.018455, loss_ce: 0.005922
2022-01-08 18:00:44,191 iteration 4245 : loss : 0.022903, loss_ce: 0.009126
2022-01-08 18:00:46,572 iteration 4246 : loss : 0.020423, loss_ce: 0.006713
2022-01-08 18:00:48,966 iteration 4247 : loss : 0.016295, loss_ce: 0.004619
2022-01-08 18:00:51,486 iteration 4248 : loss : 0.016306, loss_ce: 0.006404
2022-01-08 18:00:54,094 iteration 4249 : loss : 0.017885, loss_ce: 0.006968
2022-01-08 18:00:54,094 Training Data Eval:
2022-01-08 18:01:07,059   Average segmentation loss on training set: 0.0118
2022-01-08 18:01:07,059 Validation Data Eval:
2022-01-08 18:01:11,592   Average segmentation loss on validation set: 0.0633
2022-01-08 18:01:14,102 iteration 4250 : loss : 0.046003, loss_ce: 0.023621
 62%|████████████████▉          | 250/400 [3:01:20<1:59:55, 47.97s/it]2022-01-08 18:01:16,561 iteration 4251 : loss : 0.022351, loss_ce: 0.007277
2022-01-08 18:01:18,922 iteration 4252 : loss : 0.019385, loss_ce: 0.005167
2022-01-08 18:01:21,344 iteration 4253 : loss : 0.015863, loss_ce: 0.007271
2022-01-08 18:01:23,823 iteration 4254 : loss : 0.033203, loss_ce: 0.013402
2022-01-08 18:01:26,427 iteration 4255 : loss : 0.035580, loss_ce: 0.011841
2022-01-08 18:01:28,778 iteration 4256 : loss : 0.020738, loss_ce: 0.007585
2022-01-08 18:01:31,247 iteration 4257 : loss : 0.026537, loss_ce: 0.012716
2022-01-08 18:01:33,702 iteration 4258 : loss : 0.028641, loss_ce: 0.013515
2022-01-08 18:01:36,071 iteration 4259 : loss : 0.016971, loss_ce: 0.006068
2022-01-08 18:01:38,529 iteration 4260 : loss : 0.017757, loss_ce: 0.005661
2022-01-08 18:01:40,940 iteration 4261 : loss : 0.013884, loss_ce: 0.004607
2022-01-08 18:01:43,458 iteration 4262 : loss : 0.021139, loss_ce: 0.009937
2022-01-08 18:01:45,881 iteration 4263 : loss : 0.023040, loss_ce: 0.009375
2022-01-08 18:01:48,308 iteration 4264 : loss : 0.019206, loss_ce: 0.008769
2022-01-08 18:01:50,734 iteration 4265 : loss : 0.015406, loss_ce: 0.006879
2022-01-08 18:01:53,258 iteration 4266 : loss : 0.023199, loss_ce: 0.007852
2022-01-08 18:01:55,662 iteration 4267 : loss : 0.019999, loss_ce: 0.007832
 63%|████████████████▉          | 251/400 [3:02:02<1:54:20, 46.04s/it]2022-01-08 18:01:58,057 iteration 4268 : loss : 0.018682, loss_ce: 0.007485
2022-01-08 18:02:00,403 iteration 4269 : loss : 0.014186, loss_ce: 0.003958
2022-01-08 18:02:02,923 iteration 4270 : loss : 0.023426, loss_ce: 0.007477
2022-01-08 18:02:05,355 iteration 4271 : loss : 0.019576, loss_ce: 0.007211
2022-01-08 18:02:07,997 iteration 4272 : loss : 0.019904, loss_ce: 0.008028
2022-01-08 18:02:10,409 iteration 4273 : loss : 0.018102, loss_ce: 0.008200
2022-01-08 18:02:12,779 iteration 4274 : loss : 0.022161, loss_ce: 0.010318
2022-01-08 18:02:15,214 iteration 4275 : loss : 0.023417, loss_ce: 0.008866
2022-01-08 18:02:17,641 iteration 4276 : loss : 0.019557, loss_ce: 0.007462
2022-01-08 18:02:20,099 iteration 4277 : loss : 0.017222, loss_ce: 0.008232
2022-01-08 18:02:22,543 iteration 4278 : loss : 0.019014, loss_ce: 0.005157
2022-01-08 18:02:25,144 iteration 4279 : loss : 0.018740, loss_ce: 0.007480
2022-01-08 18:02:27,563 iteration 4280 : loss : 0.025918, loss_ce: 0.007699
2022-01-08 18:02:30,102 iteration 4281 : loss : 0.019690, loss_ce: 0.007721
2022-01-08 18:02:32,656 iteration 4282 : loss : 0.022111, loss_ce: 0.007953
2022-01-08 18:02:35,109 iteration 4283 : loss : 0.020226, loss_ce: 0.009684
2022-01-08 18:02:37,701 iteration 4284 : loss : 0.027902, loss_ce: 0.010469
 63%|█████████████████          | 252/400 [3:02:44<1:50:36, 44.84s/it]2022-01-08 18:02:40,070 iteration 4285 : loss : 0.014261, loss_ce: 0.006994
2022-01-08 18:02:42,435 iteration 4286 : loss : 0.015633, loss_ce: 0.005909
2022-01-08 18:02:44,881 iteration 4287 : loss : 0.020666, loss_ce: 0.008918
2022-01-08 18:02:47,286 iteration 4288 : loss : 0.015866, loss_ce: 0.004873
2022-01-08 18:02:49,804 iteration 4289 : loss : 0.015054, loss_ce: 0.006615
2022-01-08 18:02:52,256 iteration 4290 : loss : 0.023104, loss_ce: 0.010297
2022-01-08 18:02:54,730 iteration 4291 : loss : 0.019056, loss_ce: 0.007951
2022-01-08 18:02:57,290 iteration 4292 : loss : 0.022779, loss_ce: 0.012449
2022-01-08 18:02:59,660 iteration 4293 : loss : 0.017137, loss_ce: 0.006688
2022-01-08 18:03:02,074 iteration 4294 : loss : 0.017970, loss_ce: 0.008389
2022-01-08 18:03:04,579 iteration 4295 : loss : 0.023823, loss_ce: 0.008894
2022-01-08 18:03:07,009 iteration 4296 : loss : 0.017598, loss_ce: 0.006830
2022-01-08 18:03:09,385 iteration 4297 : loss : 0.013680, loss_ce: 0.004331
2022-01-08 18:03:11,847 iteration 4298 : loss : 0.021297, loss_ce: 0.006671
2022-01-08 18:03:14,436 iteration 4299 : loss : 0.019375, loss_ce: 0.005593
2022-01-08 18:03:17,071 iteration 4300 : loss : 0.017415, loss_ce: 0.005427
2022-01-08 18:03:19,646 iteration 4301 : loss : 0.043131, loss_ce: 0.014274
 63%|█████████████████          | 253/400 [3:03:26<1:47:44, 43.97s/it]2022-01-08 18:03:22,154 iteration 4302 : loss : 0.019144, loss_ce: 0.007003
2022-01-08 18:03:24,471 iteration 4303 : loss : 0.015080, loss_ce: 0.007216
2022-01-08 18:03:26,933 iteration 4304 : loss : 0.020974, loss_ce: 0.009218
2022-01-08 18:03:29,396 iteration 4305 : loss : 0.019311, loss_ce: 0.005472
2022-01-08 18:03:31,855 iteration 4306 : loss : 0.017068, loss_ce: 0.005094
2022-01-08 18:03:34,467 iteration 4307 : loss : 0.020374, loss_ce: 0.006323
2022-01-08 18:03:36,916 iteration 4308 : loss : 0.015156, loss_ce: 0.005617
2022-01-08 18:03:39,376 iteration 4309 : loss : 0.013767, loss_ce: 0.004995
2022-01-08 18:03:41,832 iteration 4310 : loss : 0.014431, loss_ce: 0.004736
2022-01-08 18:03:44,300 iteration 4311 : loss : 0.027628, loss_ce: 0.011834
2022-01-08 18:03:46,734 iteration 4312 : loss : 0.017372, loss_ce: 0.008728
2022-01-08 18:03:49,204 iteration 4313 : loss : 0.022011, loss_ce: 0.010803
2022-01-08 18:03:51,739 iteration 4314 : loss : 0.021147, loss_ce: 0.008559
2022-01-08 18:03:54,294 iteration 4315 : loss : 0.016695, loss_ce: 0.005805
2022-01-08 18:03:56,678 iteration 4316 : loss : 0.025983, loss_ce: 0.008871
2022-01-08 18:03:59,092 iteration 4317 : loss : 0.015669, loss_ce: 0.006625
2022-01-08 18:04:01,571 iteration 4318 : loss : 0.016881, loss_ce: 0.005894
 64%|█████████████████▏         | 254/400 [3:04:08<1:45:30, 43.36s/it]2022-01-08 18:04:03,959 iteration 4319 : loss : 0.017058, loss_ce: 0.006245
2022-01-08 18:04:06,424 iteration 4320 : loss : 0.016157, loss_ce: 0.006856
2022-01-08 18:04:09,092 iteration 4321 : loss : 0.028018, loss_ce: 0.013450
2022-01-08 18:04:11,544 iteration 4322 : loss : 0.020968, loss_ce: 0.008382
2022-01-08 18:04:13,953 iteration 4323 : loss : 0.024477, loss_ce: 0.007716
2022-01-08 18:04:16,468 iteration 4324 : loss : 0.014125, loss_ce: 0.006233
2022-01-08 18:04:18,925 iteration 4325 : loss : 0.032888, loss_ce: 0.009349
2022-01-08 18:04:21,340 iteration 4326 : loss : 0.029337, loss_ce: 0.011430
2022-01-08 18:04:23,821 iteration 4327 : loss : 0.018971, loss_ce: 0.007845
2022-01-08 18:04:26,278 iteration 4328 : loss : 0.016943, loss_ce: 0.008050
2022-01-08 18:04:28,808 iteration 4329 : loss : 0.015672, loss_ce: 0.005630
2022-01-08 18:04:31,207 iteration 4330 : loss : 0.020368, loss_ce: 0.009828
2022-01-08 18:04:33,832 iteration 4331 : loss : 0.025253, loss_ce: 0.010827
2022-01-08 18:04:36,187 iteration 4332 : loss : 0.016101, loss_ce: 0.005355
2022-01-08 18:04:38,674 iteration 4333 : loss : 0.012875, loss_ce: 0.005024
2022-01-08 18:04:41,098 iteration 4334 : loss : 0.014585, loss_ce: 0.005485
2022-01-08 18:04:41,098 Training Data Eval:
2022-01-08 18:04:54,210   Average segmentation loss on training set: 0.0129
2022-01-08 18:04:54,211 Validation Data Eval:
2022-01-08 18:04:58,962   Average segmentation loss on validation set: 0.0648
2022-01-08 18:05:01,394 iteration 4335 : loss : 0.038538, loss_ce: 0.008859
 64%|█████████████████▏         | 255/400 [3:05:08<1:56:43, 48.30s/it]2022-01-08 18:05:03,761 iteration 4336 : loss : 0.017864, loss_ce: 0.007665
2022-01-08 18:05:06,186 iteration 4337 : loss : 0.023565, loss_ce: 0.008649
2022-01-08 18:05:08,727 iteration 4338 : loss : 0.022543, loss_ce: 0.008095
2022-01-08 18:05:11,136 iteration 4339 : loss : 0.026012, loss_ce: 0.006434
2022-01-08 18:05:13,667 iteration 4340 : loss : 0.039029, loss_ce: 0.010212
2022-01-08 18:05:16,159 iteration 4341 : loss : 0.018660, loss_ce: 0.007689
2022-01-08 18:05:18,530 iteration 4342 : loss : 0.016026, loss_ce: 0.005747
2022-01-08 18:05:20,963 iteration 4343 : loss : 0.029035, loss_ce: 0.008401
2022-01-08 18:05:23,322 iteration 4344 : loss : 0.018896, loss_ce: 0.008127
2022-01-08 18:05:25,687 iteration 4345 : loss : 0.015538, loss_ce: 0.006442
2022-01-08 18:05:28,137 iteration 4346 : loss : 0.012981, loss_ce: 0.004344
2022-01-08 18:05:30,637 iteration 4347 : loss : 0.043219, loss_ce: 0.011804
2022-01-08 18:05:33,072 iteration 4348 : loss : 0.019963, loss_ce: 0.010015
2022-01-08 18:05:35,481 iteration 4349 : loss : 0.022303, loss_ce: 0.009106
2022-01-08 18:05:38,038 iteration 4350 : loss : 0.015697, loss_ce: 0.005452
2022-01-08 18:05:40,511 iteration 4351 : loss : 0.021560, loss_ce: 0.010484
2022-01-08 18:05:42,921 iteration 4352 : loss : 0.023408, loss_ce: 0.009584
 64%|█████████████████▎         | 256/400 [3:05:49<1:51:03, 46.27s/it]2022-01-08 18:05:45,511 iteration 4353 : loss : 0.014579, loss_ce: 0.005079
2022-01-08 18:05:47,988 iteration 4354 : loss : 0.018173, loss_ce: 0.005337
2022-01-08 18:05:50,601 iteration 4355 : loss : 0.016536, loss_ce: 0.004921
2022-01-08 18:05:52,977 iteration 4356 : loss : 0.021126, loss_ce: 0.007624
2022-01-08 18:05:55,613 iteration 4357 : loss : 0.025573, loss_ce: 0.010579
2022-01-08 18:05:57,964 iteration 4358 : loss : 0.021970, loss_ce: 0.009237
2022-01-08 18:06:00,387 iteration 4359 : loss : 0.025284, loss_ce: 0.007025
2022-01-08 18:06:02,787 iteration 4360 : loss : 0.016768, loss_ce: 0.006567
2022-01-08 18:06:05,220 iteration 4361 : loss : 0.028972, loss_ce: 0.010563
2022-01-08 18:06:07,571 iteration 4362 : loss : 0.024147, loss_ce: 0.008604
2022-01-08 18:06:10,071 iteration 4363 : loss : 0.023683, loss_ce: 0.010399
2022-01-08 18:06:12,502 iteration 4364 : loss : 0.014896, loss_ce: 0.006433
2022-01-08 18:06:14,926 iteration 4365 : loss : 0.020527, loss_ce: 0.008025
2022-01-08 18:06:17,339 iteration 4366 : loss : 0.026756, loss_ce: 0.009890
2022-01-08 18:06:19,918 iteration 4367 : loss : 0.018280, loss_ce: 0.008150
2022-01-08 18:06:22,294 iteration 4368 : loss : 0.013213, loss_ce: 0.005001
2022-01-08 18:06:24,734 iteration 4369 : loss : 0.042290, loss_ce: 0.017959
 64%|█████████████████▎         | 257/400 [3:06:31<1:47:04, 44.93s/it]2022-01-08 18:06:27,118 iteration 4370 : loss : 0.017681, loss_ce: 0.006296
2022-01-08 18:06:29,608 iteration 4371 : loss : 0.026676, loss_ce: 0.010133
2022-01-08 18:06:32,201 iteration 4372 : loss : 0.028511, loss_ce: 0.008913
2022-01-08 18:06:34,657 iteration 4373 : loss : 0.036732, loss_ce: 0.015828
2022-01-08 18:06:37,154 iteration 4374 : loss : 0.017388, loss_ce: 0.006741
2022-01-08 18:06:39,539 iteration 4375 : loss : 0.019315, loss_ce: 0.007897
2022-01-08 18:06:41,967 iteration 4376 : loss : 0.019295, loss_ce: 0.006472
2022-01-08 18:06:44,343 iteration 4377 : loss : 0.016903, loss_ce: 0.005684
2022-01-08 18:06:46,845 iteration 4378 : loss : 0.018160, loss_ce: 0.008827
2022-01-08 18:06:49,298 iteration 4379 : loss : 0.017442, loss_ce: 0.007065
2022-01-08 18:06:51,696 iteration 4380 : loss : 0.016728, loss_ce: 0.006191
2022-01-08 18:06:54,183 iteration 4381 : loss : 0.033843, loss_ce: 0.009384
2022-01-08 18:06:56,666 iteration 4382 : loss : 0.036619, loss_ce: 0.013599
2022-01-08 18:06:59,056 iteration 4383 : loss : 0.019149, loss_ce: 0.006549
2022-01-08 18:07:01,567 iteration 4384 : loss : 0.015932, loss_ce: 0.005763
2022-01-08 18:07:04,183 iteration 4385 : loss : 0.022761, loss_ce: 0.011425
2022-01-08 18:07:06,581 iteration 4386 : loss : 0.013869, loss_ce: 0.003650
 64%|█████████████████▍         | 258/400 [3:07:13<1:44:08, 44.00s/it]2022-01-08 18:07:09,116 iteration 4387 : loss : 0.027305, loss_ce: 0.006949
2022-01-08 18:07:11,723 iteration 4388 : loss : 0.018092, loss_ce: 0.008571
2022-01-08 18:07:14,151 iteration 4389 : loss : 0.021407, loss_ce: 0.009336
2022-01-08 18:07:16,550 iteration 4390 : loss : 0.023586, loss_ce: 0.010642
2022-01-08 18:07:18,971 iteration 4391 : loss : 0.017539, loss_ce: 0.005559
2022-01-08 18:07:21,383 iteration 4392 : loss : 0.019752, loss_ce: 0.008481
2022-01-08 18:07:23,817 iteration 4393 : loss : 0.020969, loss_ce: 0.008802
2022-01-08 18:07:26,285 iteration 4394 : loss : 0.012871, loss_ce: 0.004900
2022-01-08 18:07:28,758 iteration 4395 : loss : 0.014990, loss_ce: 0.006529
2022-01-08 18:07:31,208 iteration 4396 : loss : 0.020553, loss_ce: 0.007556
2022-01-08 18:07:33,557 iteration 4397 : loss : 0.013196, loss_ce: 0.004116
2022-01-08 18:07:35,993 iteration 4398 : loss : 0.013857, loss_ce: 0.005497
2022-01-08 18:07:38,380 iteration 4399 : loss : 0.032223, loss_ce: 0.012647
2022-01-08 18:07:40,969 iteration 4400 : loss : 0.015693, loss_ce: 0.004875
2022-01-08 18:07:43,412 iteration 4401 : loss : 0.018252, loss_ce: 0.007884
2022-01-08 18:07:45,931 iteration 4402 : loss : 0.014485, loss_ce: 0.004582
2022-01-08 18:07:48,347 iteration 4403 : loss : 0.019434, loss_ce: 0.006459
 65%|█████████████████▍         | 259/400 [3:07:55<1:41:50, 43.33s/it]2022-01-08 18:07:50,773 iteration 4404 : loss : 0.022849, loss_ce: 0.011640
2022-01-08 18:07:53,085 iteration 4405 : loss : 0.022023, loss_ce: 0.007451
2022-01-08 18:07:55,581 iteration 4406 : loss : 0.019402, loss_ce: 0.007599
2022-01-08 18:07:58,067 iteration 4407 : loss : 0.022957, loss_ce: 0.005700
2022-01-08 18:08:00,489 iteration 4408 : loss : 0.015234, loss_ce: 0.007643
2022-01-08 18:08:02,845 iteration 4409 : loss : 0.015495, loss_ce: 0.005665
2022-01-08 18:08:05,389 iteration 4410 : loss : 0.024285, loss_ce: 0.009470
2022-01-08 18:08:07,852 iteration 4411 : loss : 0.029457, loss_ce: 0.009893
2022-01-08 18:08:10,347 iteration 4412 : loss : 0.015363, loss_ce: 0.005390
2022-01-08 18:08:12,847 iteration 4413 : loss : 0.015965, loss_ce: 0.006689
2022-01-08 18:08:15,395 iteration 4414 : loss : 0.023696, loss_ce: 0.007366
2022-01-08 18:08:17,753 iteration 4415 : loss : 0.014310, loss_ce: 0.006152
2022-01-08 18:08:20,118 iteration 4416 : loss : 0.021928, loss_ce: 0.008252
2022-01-08 18:08:22,623 iteration 4417 : loss : 0.020758, loss_ce: 0.008766
2022-01-08 18:08:25,018 iteration 4418 : loss : 0.015936, loss_ce: 0.006279
2022-01-08 18:08:27,499 iteration 4419 : loss : 0.012606, loss_ce: 0.004306
2022-01-08 18:08:27,499 Training Data Eval:
2022-01-08 18:08:40,581   Average segmentation loss on training set: 0.0116
2022-01-08 18:08:40,581 Validation Data Eval:
2022-01-08 18:08:45,112   Average segmentation loss on validation set: 0.0707
2022-01-08 18:08:47,496 iteration 4420 : loss : 0.014434, loss_ce: 0.004375
 65%|█████████████████▌         | 260/400 [3:08:54<1:52:10, 48.08s/it]2022-01-08 18:08:49,963 iteration 4421 : loss : 0.035297, loss_ce: 0.011991
2022-01-08 18:08:52,401 iteration 4422 : loss : 0.015097, loss_ce: 0.004886
2022-01-08 18:08:54,829 iteration 4423 : loss : 0.015793, loss_ce: 0.005509
2022-01-08 18:08:57,422 iteration 4424 : loss : 0.019382, loss_ce: 0.006775
2022-01-08 18:08:59,824 iteration 4425 : loss : 0.025510, loss_ce: 0.006970
2022-01-08 18:09:02,222 iteration 4426 : loss : 0.015401, loss_ce: 0.004173
2022-01-08 18:09:04,650 iteration 4427 : loss : 0.023972, loss_ce: 0.009650
2022-01-08 18:09:07,078 iteration 4428 : loss : 0.018880, loss_ce: 0.008552
2022-01-08 18:09:09,600 iteration 4429 : loss : 0.022202, loss_ce: 0.009691
2022-01-08 18:09:12,068 iteration 4430 : loss : 0.015609, loss_ce: 0.006747
2022-01-08 18:09:14,484 iteration 4431 : loss : 0.043117, loss_ce: 0.016655
2022-01-08 18:09:17,074 iteration 4432 : loss : 0.022339, loss_ce: 0.009091
2022-01-08 18:09:19,562 iteration 4433 : loss : 0.023835, loss_ce: 0.006562
2022-01-08 18:09:21,981 iteration 4434 : loss : 0.028280, loss_ce: 0.017245
2022-01-08 18:09:24,345 iteration 4435 : loss : 0.016949, loss_ce: 0.005207
2022-01-08 18:09:26,903 iteration 4436 : loss : 0.021135, loss_ce: 0.011049
2022-01-08 18:09:29,298 iteration 4437 : loss : 0.017330, loss_ce: 0.006428
 65%|█████████████████▌         | 261/400 [3:09:36<1:47:01, 46.20s/it]2022-01-08 18:09:31,758 iteration 4438 : loss : 0.024221, loss_ce: 0.008839
2022-01-08 18:09:34,144 iteration 4439 : loss : 0.015376, loss_ce: 0.006751
2022-01-08 18:09:36,753 iteration 4440 : loss : 0.018474, loss_ce: 0.008462
2022-01-08 18:09:39,138 iteration 4441 : loss : 0.016177, loss_ce: 0.006107
2022-01-08 18:09:41,813 iteration 4442 : loss : 0.027445, loss_ce: 0.010567
2022-01-08 18:09:44,268 iteration 4443 : loss : 0.021763, loss_ce: 0.008528
2022-01-08 18:09:46,645 iteration 4444 : loss : 0.017347, loss_ce: 0.006491
2022-01-08 18:09:49,134 iteration 4445 : loss : 0.017937, loss_ce: 0.005527
2022-01-08 18:09:51,575 iteration 4446 : loss : 0.060742, loss_ce: 0.013702
2022-01-08 18:09:54,039 iteration 4447 : loss : 0.029143, loss_ce: 0.009819
2022-01-08 18:09:56,434 iteration 4448 : loss : 0.019585, loss_ce: 0.006968
2022-01-08 18:09:58,898 iteration 4449 : loss : 0.027360, loss_ce: 0.012184
2022-01-08 18:10:01,292 iteration 4450 : loss : 0.020712, loss_ce: 0.011966
2022-01-08 18:10:03,799 iteration 4451 : loss : 0.015716, loss_ce: 0.005746
2022-01-08 18:10:06,174 iteration 4452 : loss : 0.025911, loss_ce: 0.008274
2022-01-08 18:10:08,659 iteration 4453 : loss : 0.021199, loss_ce: 0.010766
2022-01-08 18:10:11,085 iteration 4454 : loss : 0.018963, loss_ce: 0.007972
 66%|█████████████████▋         | 262/400 [3:10:17<1:43:12, 44.87s/it]2022-01-08 18:10:13,501 iteration 4455 : loss : 0.030729, loss_ce: 0.010300
2022-01-08 18:10:15,890 iteration 4456 : loss : 0.020216, loss_ce: 0.007091
2022-01-08 18:10:18,335 iteration 4457 : loss : 0.020938, loss_ce: 0.008498
2022-01-08 18:10:20,737 iteration 4458 : loss : 0.017972, loss_ce: 0.007118
2022-01-08 18:10:23,147 iteration 4459 : loss : 0.032404, loss_ce: 0.009130
2022-01-08 18:10:25,522 iteration 4460 : loss : 0.014962, loss_ce: 0.006350
2022-01-08 18:10:27,958 iteration 4461 : loss : 0.016357, loss_ce: 0.007296
2022-01-08 18:10:30,513 iteration 4462 : loss : 0.037348, loss_ce: 0.015978
2022-01-08 18:10:32,868 iteration 4463 : loss : 0.015639, loss_ce: 0.005721
2022-01-08 18:10:35,363 iteration 4464 : loss : 0.015801, loss_ce: 0.007157
2022-01-08 18:10:38,004 iteration 4465 : loss : 0.043801, loss_ce: 0.007599
2022-01-08 18:10:40,342 iteration 4466 : loss : 0.016281, loss_ce: 0.005502
2022-01-08 18:10:42,730 iteration 4467 : loss : 0.019334, loss_ce: 0.008407
2022-01-08 18:10:45,303 iteration 4468 : loss : 0.027171, loss_ce: 0.009311
2022-01-08 18:10:47,746 iteration 4469 : loss : 0.019604, loss_ce: 0.005521
2022-01-08 18:10:50,268 iteration 4470 : loss : 0.022626, loss_ce: 0.010052
2022-01-08 18:10:52,727 iteration 4471 : loss : 0.021380, loss_ce: 0.005661
 66%|█████████████████▊         | 263/400 [3:10:59<1:40:14, 43.90s/it]2022-01-08 18:10:55,109 iteration 4472 : loss : 0.016462, loss_ce: 0.006921
2022-01-08 18:10:57,581 iteration 4473 : loss : 0.020115, loss_ce: 0.007697
2022-01-08 18:11:00,055 iteration 4474 : loss : 0.027467, loss_ce: 0.012474
2022-01-08 18:11:02,470 iteration 4475 : loss : 0.019680, loss_ce: 0.008607
2022-01-08 18:11:05,017 iteration 4476 : loss : 0.026509, loss_ce: 0.008791
2022-01-08 18:11:07,431 iteration 4477 : loss : 0.021251, loss_ce: 0.008854
2022-01-08 18:11:09,879 iteration 4478 : loss : 0.030407, loss_ce: 0.013806
2022-01-08 18:11:12,404 iteration 4479 : loss : 0.029285, loss_ce: 0.015099
2022-01-08 18:11:14,749 iteration 4480 : loss : 0.016275, loss_ce: 0.006070
2022-01-08 18:11:17,197 iteration 4481 : loss : 0.021234, loss_ce: 0.005414
2022-01-08 18:11:19,588 iteration 4482 : loss : 0.015727, loss_ce: 0.005550
2022-01-08 18:11:22,000 iteration 4483 : loss : 0.043385, loss_ce: 0.011128
2022-01-08 18:11:24,515 iteration 4484 : loss : 0.018206, loss_ce: 0.006178
2022-01-08 18:11:27,131 iteration 4485 : loss : 0.024931, loss_ce: 0.012063
2022-01-08 18:11:29,577 iteration 4486 : loss : 0.021648, loss_ce: 0.006538
2022-01-08 18:11:32,004 iteration 4487 : loss : 0.023856, loss_ce: 0.006698
2022-01-08 18:11:34,438 iteration 4488 : loss : 0.021575, loss_ce: 0.008269
 66%|█████████████████▊         | 264/400 [3:11:41<1:38:01, 43.25s/it]2022-01-08 18:11:36,932 iteration 4489 : loss : 0.022724, loss_ce: 0.010432
2022-01-08 18:11:39,336 iteration 4490 : loss : 0.016421, loss_ce: 0.008179
2022-01-08 18:11:41,909 iteration 4491 : loss : 0.024090, loss_ce: 0.007823
2022-01-08 18:11:44,386 iteration 4492 : loss : 0.021785, loss_ce: 0.008458
2022-01-08 18:11:46,825 iteration 4493 : loss : 0.025087, loss_ce: 0.009932
2022-01-08 18:11:49,277 iteration 4494 : loss : 0.020157, loss_ce: 0.006282
2022-01-08 18:11:51,750 iteration 4495 : loss : 0.032343, loss_ce: 0.009087
2022-01-08 18:11:54,206 iteration 4496 : loss : 0.016410, loss_ce: 0.007493
2022-01-08 18:11:56,654 iteration 4497 : loss : 0.019694, loss_ce: 0.008865
2022-01-08 18:11:59,064 iteration 4498 : loss : 0.036512, loss_ce: 0.010713
2022-01-08 18:12:01,553 iteration 4499 : loss : 0.024597, loss_ce: 0.008836
2022-01-08 18:12:04,068 iteration 4500 : loss : 0.014723, loss_ce: 0.004998
2022-01-08 18:12:06,459 iteration 4501 : loss : 0.018491, loss_ce: 0.005559
2022-01-08 18:12:09,000 iteration 4502 : loss : 0.029408, loss_ce: 0.009265
2022-01-08 18:12:11,441 iteration 4503 : loss : 0.019537, loss_ce: 0.007810
2022-01-08 18:12:13,802 iteration 4504 : loss : 0.019946, loss_ce: 0.007567
2022-01-08 18:12:13,802 Training Data Eval:
2022-01-08 18:12:26,996   Average segmentation loss on training set: 0.0137
2022-01-08 18:12:26,997 Validation Data Eval:
2022-01-08 18:12:31,636   Average segmentation loss on validation set: 0.0774
2022-01-08 18:12:34,129 iteration 4505 : loss : 0.017589, loss_ce: 0.007190
 66%|█████████████████▉         | 265/400 [3:12:41<1:48:24, 48.18s/it]2022-01-08 18:12:36,570 iteration 4506 : loss : 0.032631, loss_ce: 0.016562
2022-01-08 18:12:39,105 iteration 4507 : loss : 0.018884, loss_ce: 0.007832
2022-01-08 18:12:41,459 iteration 4508 : loss : 0.031066, loss_ce: 0.009998
2022-01-08 18:12:43,939 iteration 4509 : loss : 0.023406, loss_ce: 0.005255
2022-01-08 18:12:46,394 iteration 4510 : loss : 0.021736, loss_ce: 0.006940
2022-01-08 18:12:48,863 iteration 4511 : loss : 0.018821, loss_ce: 0.004824
2022-01-08 18:12:51,507 iteration 4512 : loss : 0.022489, loss_ce: 0.013828
2022-01-08 18:12:53,989 iteration 4513 : loss : 0.030270, loss_ce: 0.011685
2022-01-08 18:12:56,242 iteration 4514 : loss : 0.018377, loss_ce: 0.005715
2022-01-08 18:12:58,694 iteration 4515 : loss : 0.031053, loss_ce: 0.013266
2022-01-08 18:13:01,075 iteration 4516 : loss : 0.013176, loss_ce: 0.005296
2022-01-08 18:13:03,469 iteration 4517 : loss : 0.015496, loss_ce: 0.005858
2022-01-08 18:13:05,943 iteration 4518 : loss : 0.022875, loss_ce: 0.007807
2022-01-08 18:13:08,344 iteration 4519 : loss : 0.015215, loss_ce: 0.005409
2022-01-08 18:13:10,757 iteration 4520 : loss : 0.035163, loss_ce: 0.014203
2022-01-08 18:13:13,287 iteration 4521 : loss : 0.023870, loss_ce: 0.010423
2022-01-08 18:13:15,665 iteration 4522 : loss : 0.023324, loss_ce: 0.009059
 66%|█████████████████▉         | 266/400 [3:13:22<1:43:09, 46.19s/it]2022-01-08 18:13:18,118 iteration 4523 : loss : 0.017269, loss_ce: 0.006674
2022-01-08 18:13:20,538 iteration 4524 : loss : 0.024379, loss_ce: 0.008362
2022-01-08 18:13:23,029 iteration 4525 : loss : 0.015102, loss_ce: 0.006921
2022-01-08 18:13:25,406 iteration 4526 : loss : 0.021103, loss_ce: 0.005971
2022-01-08 18:13:27,958 iteration 4527 : loss : 0.014859, loss_ce: 0.006562
2022-01-08 18:13:30,406 iteration 4528 : loss : 0.016480, loss_ce: 0.006384
2022-01-08 18:13:32,795 iteration 4529 : loss : 0.021937, loss_ce: 0.007995
2022-01-08 18:13:35,345 iteration 4530 : loss : 0.025644, loss_ce: 0.010234
2022-01-08 18:13:37,819 iteration 4531 : loss : 0.029915, loss_ce: 0.009503
2022-01-08 18:13:40,173 iteration 4532 : loss : 0.014367, loss_ce: 0.005323
2022-01-08 18:13:42,678 iteration 4533 : loss : 0.034635, loss_ce: 0.012745
2022-01-08 18:13:45,150 iteration 4534 : loss : 0.021611, loss_ce: 0.011588
2022-01-08 18:13:47,729 iteration 4535 : loss : 0.038883, loss_ce: 0.016604
2022-01-08 18:13:50,119 iteration 4536 : loss : 0.026670, loss_ce: 0.008632
2022-01-08 18:13:52,552 iteration 4537 : loss : 0.024142, loss_ce: 0.006908
2022-01-08 18:13:55,033 iteration 4538 : loss : 0.015360, loss_ce: 0.006618
2022-01-08 18:13:57,345 iteration 4539 : loss : 0.014702, loss_ce: 0.005691
 67%|██████████████████         | 267/400 [3:14:04<1:39:23, 44.84s/it]2022-01-08 18:13:59,757 iteration 4540 : loss : 0.016794, loss_ce: 0.007142
2022-01-08 18:14:02,168 iteration 4541 : loss : 0.040678, loss_ce: 0.014720
2022-01-08 18:14:04,709 iteration 4542 : loss : 0.024479, loss_ce: 0.006719
2022-01-08 18:14:07,243 iteration 4543 : loss : 0.036588, loss_ce: 0.016836
2022-01-08 18:14:09,655 iteration 4544 : loss : 0.018507, loss_ce: 0.007817
2022-01-08 18:14:12,005 iteration 4545 : loss : 0.012681, loss_ce: 0.005010
2022-01-08 18:14:14,536 iteration 4546 : loss : 0.019326, loss_ce: 0.007601
2022-01-08 18:14:16,952 iteration 4547 : loss : 0.021879, loss_ce: 0.008601
2022-01-08 18:14:19,474 iteration 4548 : loss : 0.019687, loss_ce: 0.009755
2022-01-08 18:14:21,875 iteration 4549 : loss : 0.021827, loss_ce: 0.006430
2022-01-08 18:14:24,336 iteration 4550 : loss : 0.030550, loss_ce: 0.010443
2022-01-08 18:14:26,917 iteration 4551 : loss : 0.021872, loss_ce: 0.008234
2022-01-08 18:14:29,468 iteration 4552 : loss : 0.019593, loss_ce: 0.005797
2022-01-08 18:14:31,851 iteration 4553 : loss : 0.015841, loss_ce: 0.005207
2022-01-08 18:14:34,268 iteration 4554 : loss : 0.048314, loss_ce: 0.013279
2022-01-08 18:14:36,674 iteration 4555 : loss : 0.019604, loss_ce: 0.006677
2022-01-08 18:14:39,127 iteration 4556 : loss : 0.018570, loss_ce: 0.008423
 67%|██████████████████         | 268/400 [3:14:46<1:36:37, 43.92s/it]2022-01-08 18:14:41,559 iteration 4557 : loss : 0.014180, loss_ce: 0.006888
2022-01-08 18:14:44,178 iteration 4558 : loss : 0.022646, loss_ce: 0.009196
2022-01-08 18:14:46,600 iteration 4559 : loss : 0.018002, loss_ce: 0.005641
2022-01-08 18:14:49,102 iteration 4560 : loss : 0.025288, loss_ce: 0.007935
2022-01-08 18:14:51,534 iteration 4561 : loss : 0.027871, loss_ce: 0.007625
2022-01-08 18:14:54,144 iteration 4562 : loss : 0.016608, loss_ce: 0.005049
2022-01-08 18:14:56,560 iteration 4563 : loss : 0.020485, loss_ce: 0.008472
2022-01-08 18:14:58,991 iteration 4564 : loss : 0.018510, loss_ce: 0.007105
2022-01-08 18:15:01,446 iteration 4565 : loss : 0.033271, loss_ce: 0.015022
2022-01-08 18:15:03,856 iteration 4566 : loss : 0.028398, loss_ce: 0.013578
2022-01-08 18:15:06,477 iteration 4567 : loss : 0.016106, loss_ce: 0.005873
2022-01-08 18:15:08,962 iteration 4568 : loss : 0.019766, loss_ce: 0.006563
2022-01-08 18:15:11,420 iteration 4569 : loss : 0.038107, loss_ce: 0.007878
2022-01-08 18:15:14,002 iteration 4570 : loss : 0.021994, loss_ce: 0.009182
2022-01-08 18:15:16,376 iteration 4571 : loss : 0.022983, loss_ce: 0.008812
2022-01-08 18:15:18,803 iteration 4572 : loss : 0.018030, loss_ce: 0.006389
2022-01-08 18:15:21,210 iteration 4573 : loss : 0.028195, loss_ce: 0.012090
 67%|██████████████████▏        | 269/400 [3:15:28<1:34:41, 43.37s/it]2022-01-08 18:15:23,635 iteration 4574 : loss : 0.017404, loss_ce: 0.008867
2022-01-08 18:15:26,062 iteration 4575 : loss : 0.016630, loss_ce: 0.005624
2022-01-08 18:15:28,699 iteration 4576 : loss : 0.017454, loss_ce: 0.006286
2022-01-08 18:15:31,102 iteration 4577 : loss : 0.019396, loss_ce: 0.006107
2022-01-08 18:15:33,642 iteration 4578 : loss : 0.015819, loss_ce: 0.006439
2022-01-08 18:15:36,116 iteration 4579 : loss : 0.016801, loss_ce: 0.005726
2022-01-08 18:15:38,465 iteration 4580 : loss : 0.014076, loss_ce: 0.005463
2022-01-08 18:15:40,987 iteration 4581 : loss : 0.023325, loss_ce: 0.009968
2022-01-08 18:15:43,387 iteration 4582 : loss : 0.015206, loss_ce: 0.006217
2022-01-08 18:15:45,868 iteration 4583 : loss : 0.029018, loss_ce: 0.006269
2022-01-08 18:15:48,319 iteration 4584 : loss : 0.024690, loss_ce: 0.007670
2022-01-08 18:15:50,730 iteration 4585 : loss : 0.013984, loss_ce: 0.004499
2022-01-08 18:15:53,162 iteration 4586 : loss : 0.013268, loss_ce: 0.005749
2022-01-08 18:15:55,731 iteration 4587 : loss : 0.017839, loss_ce: 0.006801
2022-01-08 18:15:58,178 iteration 4588 : loss : 0.022654, loss_ce: 0.009851
2022-01-08 18:16:00,680 iteration 4589 : loss : 0.019284, loss_ce: 0.008507
2022-01-08 18:16:00,680 Training Data Eval:
2022-01-08 18:16:13,746   Average segmentation loss on training set: 0.0112
2022-01-08 18:16:13,747 Validation Data Eval:
2022-01-08 18:16:18,444   Average segmentation loss on validation set: 0.0825
2022-01-08 18:16:21,032 iteration 4590 : loss : 0.024038, loss_ce: 0.013823
 68%|██████████████████▏        | 270/400 [3:16:27<1:44:39, 48.31s/it]2022-01-08 18:16:23,606 iteration 4591 : loss : 0.021860, loss_ce: 0.006828
2022-01-08 18:16:26,012 iteration 4592 : loss : 0.026335, loss_ce: 0.013682
2022-01-08 18:16:28,393 iteration 4593 : loss : 0.022681, loss_ce: 0.008584
2022-01-08 18:16:30,871 iteration 4594 : loss : 0.033728, loss_ce: 0.012020
2022-01-08 18:16:33,515 iteration 4595 : loss : 0.014385, loss_ce: 0.005904
2022-01-08 18:16:35,998 iteration 4596 : loss : 0.019877, loss_ce: 0.009075
2022-01-08 18:16:38,361 iteration 4597 : loss : 0.017892, loss_ce: 0.005780
2022-01-08 18:16:40,839 iteration 4598 : loss : 0.016863, loss_ce: 0.005563
2022-01-08 18:16:43,181 iteration 4599 : loss : 0.016209, loss_ce: 0.006605
2022-01-08 18:16:45,636 iteration 4600 : loss : 0.018797, loss_ce: 0.006987
2022-01-08 18:16:48,095 iteration 4601 : loss : 0.018932, loss_ce: 0.009347
2022-01-08 18:16:50,687 iteration 4602 : loss : 0.024616, loss_ce: 0.009480
2022-01-08 18:16:53,154 iteration 4603 : loss : 0.023312, loss_ce: 0.007718
2022-01-08 18:16:55,494 iteration 4604 : loss : 0.016915, loss_ce: 0.005996
2022-01-08 18:16:57,957 iteration 4605 : loss : 0.013459, loss_ce: 0.004045
2022-01-08 18:17:00,559 iteration 4606 : loss : 0.023228, loss_ce: 0.008713
2022-01-08 18:17:02,956 iteration 4607 : loss : 0.029775, loss_ce: 0.011856
 68%|██████████████████▎        | 271/400 [3:17:09<1:39:44, 46.39s/it]2022-01-08 18:17:05,624 iteration 4608 : loss : 0.014456, loss_ce: 0.005417
2022-01-08 18:17:08,109 iteration 4609 : loss : 0.016857, loss_ce: 0.005220
2022-01-08 18:17:10,629 iteration 4610 : loss : 0.017620, loss_ce: 0.004111
2022-01-08 18:17:13,066 iteration 4611 : loss : 0.019173, loss_ce: 0.007443
2022-01-08 18:17:15,447 iteration 4612 : loss : 0.022429, loss_ce: 0.009436
2022-01-08 18:17:17,885 iteration 4613 : loss : 0.019467, loss_ce: 0.005774
2022-01-08 18:17:20,411 iteration 4614 : loss : 0.015846, loss_ce: 0.004805
2022-01-08 18:17:22,957 iteration 4615 : loss : 0.028333, loss_ce: 0.014033
2022-01-08 18:17:25,366 iteration 4616 : loss : 0.016078, loss_ce: 0.007253
2022-01-08 18:17:27,800 iteration 4617 : loss : 0.021336, loss_ce: 0.007429
2022-01-08 18:17:30,162 iteration 4618 : loss : 0.011145, loss_ce: 0.004290
2022-01-08 18:17:32,733 iteration 4619 : loss : 0.022906, loss_ce: 0.009115
2022-01-08 18:17:35,169 iteration 4620 : loss : 0.016633, loss_ce: 0.006430
2022-01-08 18:17:37,607 iteration 4621 : loss : 0.015091, loss_ce: 0.005310
2022-01-08 18:17:40,065 iteration 4622 : loss : 0.016863, loss_ce: 0.006423
2022-01-08 18:17:42,495 iteration 4623 : loss : 0.013524, loss_ce: 0.005572
2022-01-08 18:17:44,969 iteration 4624 : loss : 0.022255, loss_ce: 0.007269
 68%|██████████████████▎        | 272/400 [3:17:51<1:36:09, 45.08s/it]2022-01-08 18:17:47,449 iteration 4625 : loss : 0.014872, loss_ce: 0.004589
2022-01-08 18:17:49,879 iteration 4626 : loss : 0.029422, loss_ce: 0.010165
2022-01-08 18:17:52,333 iteration 4627 : loss : 0.021916, loss_ce: 0.010473
2022-01-08 18:17:54,876 iteration 4628 : loss : 0.021488, loss_ce: 0.007608
2022-01-08 18:17:57,278 iteration 4629 : loss : 0.026007, loss_ce: 0.004635
2022-01-08 18:17:59,731 iteration 4630 : loss : 0.020102, loss_ce: 0.010737
2022-01-08 18:18:02,195 iteration 4631 : loss : 0.030853, loss_ce: 0.011817
2022-01-08 18:18:04,698 iteration 4632 : loss : 0.018114, loss_ce: 0.005238
2022-01-08 18:18:07,138 iteration 4633 : loss : 0.015326, loss_ce: 0.005265
2022-01-08 18:18:09,562 iteration 4634 : loss : 0.019077, loss_ce: 0.008113
2022-01-08 18:18:12,055 iteration 4635 : loss : 0.013659, loss_ce: 0.004245
2022-01-08 18:18:14,395 iteration 4636 : loss : 0.013416, loss_ce: 0.005012
2022-01-08 18:18:16,765 iteration 4637 : loss : 0.022335, loss_ce: 0.007797
2022-01-08 18:18:19,277 iteration 4638 : loss : 0.019119, loss_ce: 0.008571
2022-01-08 18:18:21,691 iteration 4639 : loss : 0.015016, loss_ce: 0.004620
2022-01-08 18:18:24,135 iteration 4640 : loss : 0.019553, loss_ce: 0.007925
2022-01-08 18:18:26,611 iteration 4641 : loss : 0.022159, loss_ce: 0.008367
 68%|██████████████████▍        | 273/400 [3:18:33<1:33:13, 44.05s/it]2022-01-08 18:18:29,061 iteration 4642 : loss : 0.016421, loss_ce: 0.006618
2022-01-08 18:18:31,528 iteration 4643 : loss : 0.024820, loss_ce: 0.008715
2022-01-08 18:18:33,950 iteration 4644 : loss : 0.022629, loss_ce: 0.009563
2022-01-08 18:18:36,442 iteration 4645 : loss : 0.021543, loss_ce: 0.006714
2022-01-08 18:18:38,959 iteration 4646 : loss : 0.016898, loss_ce: 0.006526
2022-01-08 18:18:41,339 iteration 4647 : loss : 0.017346, loss_ce: 0.006865
2022-01-08 18:18:43,708 iteration 4648 : loss : 0.016974, loss_ce: 0.008794
2022-01-08 18:18:46,211 iteration 4649 : loss : 0.018003, loss_ce: 0.006416
2022-01-08 18:18:48,660 iteration 4650 : loss : 0.013707, loss_ce: 0.005409
2022-01-08 18:18:51,118 iteration 4651 : loss : 0.016545, loss_ce: 0.005862
2022-01-08 18:18:53,520 iteration 4652 : loss : 0.017667, loss_ce: 0.006188
2022-01-08 18:18:56,013 iteration 4653 : loss : 0.013428, loss_ce: 0.004968
2022-01-08 18:18:58,357 iteration 4654 : loss : 0.014405, loss_ce: 0.004253
2022-01-08 18:19:00,845 iteration 4655 : loss : 0.019365, loss_ce: 0.006094
2022-01-08 18:19:03,297 iteration 4656 : loss : 0.018126, loss_ce: 0.005756
2022-01-08 18:19:05,681 iteration 4657 : loss : 0.016073, loss_ce: 0.006300
2022-01-08 18:19:08,098 iteration 4658 : loss : 0.022172, loss_ce: 0.009676
 68%|██████████████████▍        | 274/400 [3:19:14<1:30:52, 43.27s/it]2022-01-08 18:19:10,702 iteration 4659 : loss : 0.016406, loss_ce: 0.006397
2022-01-08 18:19:13,075 iteration 4660 : loss : 0.013536, loss_ce: 0.005485
2022-01-08 18:19:15,512 iteration 4661 : loss : 0.026466, loss_ce: 0.013364
2022-01-08 18:19:17,969 iteration 4662 : loss : 0.012181, loss_ce: 0.005402
2022-01-08 18:19:20,598 iteration 4663 : loss : 0.025618, loss_ce: 0.011068
2022-01-08 18:19:22,986 iteration 4664 : loss : 0.018893, loss_ce: 0.006769
2022-01-08 18:19:25,430 iteration 4665 : loss : 0.020021, loss_ce: 0.008521
2022-01-08 18:19:28,033 iteration 4666 : loss : 0.015896, loss_ce: 0.006659
2022-01-08 18:19:30,476 iteration 4667 : loss : 0.029853, loss_ce: 0.011547
2022-01-08 18:19:32,937 iteration 4668 : loss : 0.012702, loss_ce: 0.005274
2022-01-08 18:19:35,367 iteration 4669 : loss : 0.015892, loss_ce: 0.005832
2022-01-08 18:19:37,731 iteration 4670 : loss : 0.029981, loss_ce: 0.007570
2022-01-08 18:19:40,084 iteration 4671 : loss : 0.014959, loss_ce: 0.005752
2022-01-08 18:19:42,499 iteration 4672 : loss : 0.013488, loss_ce: 0.005050
2022-01-08 18:19:44,943 iteration 4673 : loss : 0.012106, loss_ce: 0.004371
2022-01-08 18:19:47,496 iteration 4674 : loss : 0.012374, loss_ce: 0.002780
2022-01-08 18:19:47,496 Training Data Eval:
2022-01-08 18:20:00,704   Average segmentation loss on training set: 0.0099
2022-01-08 18:20:00,705 Validation Data Eval:
2022-01-08 18:20:05,174   Average segmentation loss on validation set: 0.0693
2022-01-08 18:20:07,537 iteration 4675 : loss : 0.011859, loss_ce: 0.004475
 69%|██████████████████▌        | 275/400 [3:20:14<1:40:15, 48.12s/it]2022-01-08 18:20:10,041 iteration 4676 : loss : 0.012721, loss_ce: 0.004971
2022-01-08 18:20:12,444 iteration 4677 : loss : 0.012515, loss_ce: 0.005477
2022-01-08 18:20:14,953 iteration 4678 : loss : 0.020748, loss_ce: 0.006632
2022-01-08 18:20:17,423 iteration 4679 : loss : 0.018036, loss_ce: 0.006443
2022-01-08 18:20:19,974 iteration 4680 : loss : 0.014792, loss_ce: 0.005560
2022-01-08 18:20:22,343 iteration 4681 : loss : 0.017580, loss_ce: 0.007130
2022-01-08 18:20:24,779 iteration 4682 : loss : 0.014253, loss_ce: 0.005529
2022-01-08 18:20:27,394 iteration 4683 : loss : 0.013447, loss_ce: 0.004178
2022-01-08 18:20:29,770 iteration 4684 : loss : 0.017992, loss_ce: 0.005604
2022-01-08 18:20:32,146 iteration 4685 : loss : 0.018493, loss_ce: 0.010023
2022-01-08 18:20:34,490 iteration 4686 : loss : 0.016632, loss_ce: 0.005948
2022-01-08 18:20:37,039 iteration 4687 : loss : 0.027232, loss_ce: 0.007205
2022-01-08 18:20:39,395 iteration 4688 : loss : 0.010784, loss_ce: 0.004640
2022-01-08 18:20:41,800 iteration 4689 : loss : 0.017880, loss_ce: 0.006326
2022-01-08 18:20:44,179 iteration 4690 : loss : 0.014604, loss_ce: 0.005011
2022-01-08 18:20:46,699 iteration 4691 : loss : 0.016132, loss_ce: 0.004567
2022-01-08 18:20:49,184 iteration 4692 : loss : 0.021593, loss_ce: 0.008767
 69%|██████████████████▋        | 276/400 [3:20:56<1:35:26, 46.18s/it]2022-01-08 18:20:51,584 iteration 4693 : loss : 0.014771, loss_ce: 0.005458
2022-01-08 18:20:53,983 iteration 4694 : loss : 0.013313, loss_ce: 0.004310
2022-01-08 18:20:56,379 iteration 4695 : loss : 0.018563, loss_ce: 0.006767
2022-01-08 18:20:58,851 iteration 4696 : loss : 0.016445, loss_ce: 0.005527
2022-01-08 18:21:01,255 iteration 4697 : loss : 0.036251, loss_ce: 0.017176
2022-01-08 18:21:03,618 iteration 4698 : loss : 0.015600, loss_ce: 0.006063
2022-01-08 18:21:06,144 iteration 4699 : loss : 0.027595, loss_ce: 0.012678
2022-01-08 18:21:08,578 iteration 4700 : loss : 0.030387, loss_ce: 0.009851
2022-01-08 18:21:10,990 iteration 4701 : loss : 0.012459, loss_ce: 0.003304
2022-01-08 18:21:13,441 iteration 4702 : loss : 0.026579, loss_ce: 0.009145
2022-01-08 18:21:15,987 iteration 4703 : loss : 0.027454, loss_ce: 0.014021
2022-01-08 18:21:18,380 iteration 4704 : loss : 0.022964, loss_ce: 0.005603
2022-01-08 18:21:20,817 iteration 4705 : loss : 0.035610, loss_ce: 0.010495
2022-01-08 18:21:23,145 iteration 4706 : loss : 0.015161, loss_ce: 0.005582
2022-01-08 18:21:25,680 iteration 4707 : loss : 0.017096, loss_ce: 0.005310
2022-01-08 18:21:28,111 iteration 4708 : loss : 0.018880, loss_ce: 0.008744
2022-01-08 18:21:30,654 iteration 4709 : loss : 0.021289, loss_ce: 0.009384
 69%|██████████████████▋        | 277/400 [3:21:37<1:31:46, 44.77s/it]2022-01-08 18:21:33,072 iteration 4710 : loss : 0.017043, loss_ce: 0.006408
2022-01-08 18:21:35,391 iteration 4711 : loss : 0.014954, loss_ce: 0.005044
2022-01-08 18:21:37,861 iteration 4712 : loss : 0.014161, loss_ce: 0.004750
2022-01-08 18:21:40,489 iteration 4713 : loss : 0.028092, loss_ce: 0.008583
2022-01-08 18:21:42,826 iteration 4714 : loss : 0.013049, loss_ce: 0.004053
2022-01-08 18:21:45,401 iteration 4715 : loss : 0.023582, loss_ce: 0.011505
2022-01-08 18:21:47,822 iteration 4716 : loss : 0.030295, loss_ce: 0.011811
2022-01-08 18:21:50,172 iteration 4717 : loss : 0.019059, loss_ce: 0.006657
2022-01-08 18:21:52,616 iteration 4718 : loss : 0.016821, loss_ce: 0.006609
2022-01-08 18:21:55,070 iteration 4719 : loss : 0.015305, loss_ce: 0.005262
2022-01-08 18:21:57,503 iteration 4720 : loss : 0.015836, loss_ce: 0.007690
2022-01-08 18:22:00,119 iteration 4721 : loss : 0.023974, loss_ce: 0.009432
2022-01-08 18:22:02,562 iteration 4722 : loss : 0.021820, loss_ce: 0.009528
2022-01-08 18:22:04,927 iteration 4723 : loss : 0.025583, loss_ce: 0.008757
2022-01-08 18:22:07,263 iteration 4724 : loss : 0.029617, loss_ce: 0.020630
2022-01-08 18:22:09,641 iteration 4725 : loss : 0.015229, loss_ce: 0.005201
2022-01-08 18:22:12,061 iteration 4726 : loss : 0.023104, loss_ce: 0.006635
 70%|██████████████████▊        | 278/400 [3:22:18<1:28:58, 43.76s/it]2022-01-08 18:22:14,575 iteration 4727 : loss : 0.015220, loss_ce: 0.004929
2022-01-08 18:22:16,975 iteration 4728 : loss : 0.024898, loss_ce: 0.011505
2022-01-08 18:22:19,522 iteration 4729 : loss : 0.015087, loss_ce: 0.004241
2022-01-08 18:22:21,926 iteration 4730 : loss : 0.024201, loss_ce: 0.009238
2022-01-08 18:22:24,353 iteration 4731 : loss : 0.017952, loss_ce: 0.004917
2022-01-08 18:22:26,806 iteration 4732 : loss : 0.016242, loss_ce: 0.006816
2022-01-08 18:22:29,208 iteration 4733 : loss : 0.019965, loss_ce: 0.006384
2022-01-08 18:22:31,702 iteration 4734 : loss : 0.014635, loss_ce: 0.004663
2022-01-08 18:22:34,173 iteration 4735 : loss : 0.018534, loss_ce: 0.008710
2022-01-08 18:22:36,577 iteration 4736 : loss : 0.018003, loss_ce: 0.006917
2022-01-08 18:22:39,139 iteration 4737 : loss : 0.029316, loss_ce: 0.009495
2022-01-08 18:22:41,580 iteration 4738 : loss : 0.056398, loss_ce: 0.007660
2022-01-08 18:22:43,992 iteration 4739 : loss : 0.018497, loss_ce: 0.007872
2022-01-08 18:22:46,338 iteration 4740 : loss : 0.013434, loss_ce: 0.005737
2022-01-08 18:22:48,873 iteration 4741 : loss : 0.034316, loss_ce: 0.019596
2022-01-08 18:22:51,242 iteration 4742 : loss : 0.015165, loss_ce: 0.005482
2022-01-08 18:22:53,651 iteration 4743 : loss : 0.014651, loss_ce: 0.004744
 70%|██████████████████▊        | 279/400 [3:23:00<1:26:56, 43.11s/it]2022-01-08 18:22:56,061 iteration 4744 : loss : 0.029759, loss_ce: 0.011023
2022-01-08 18:22:58,453 iteration 4745 : loss : 0.018124, loss_ce: 0.007233
2022-01-08 18:23:00,899 iteration 4746 : loss : 0.019543, loss_ce: 0.008027
2022-01-08 18:23:03,461 iteration 4747 : loss : 0.024228, loss_ce: 0.009225
2022-01-08 18:23:05,967 iteration 4748 : loss : 0.033401, loss_ce: 0.012687
2022-01-08 18:23:08,402 iteration 4749 : loss : 0.030014, loss_ce: 0.008820
2022-01-08 18:23:10,799 iteration 4750 : loss : 0.015903, loss_ce: 0.006075
2022-01-08 18:23:13,147 iteration 4751 : loss : 0.016911, loss_ce: 0.006504
2022-01-08 18:23:15,654 iteration 4752 : loss : 0.019668, loss_ce: 0.004907
2022-01-08 18:23:18,056 iteration 4753 : loss : 0.022854, loss_ce: 0.012419
2022-01-08 18:23:20,500 iteration 4754 : loss : 0.020457, loss_ce: 0.005740
2022-01-08 18:23:22,914 iteration 4755 : loss : 0.018761, loss_ce: 0.006814
2022-01-08 18:23:25,371 iteration 4756 : loss : 0.018849, loss_ce: 0.008460
2022-01-08 18:23:27,831 iteration 4757 : loss : 0.015661, loss_ce: 0.006140
2022-01-08 18:23:30,313 iteration 4758 : loss : 0.024745, loss_ce: 0.008940
2022-01-08 18:23:32,670 iteration 4759 : loss : 0.013412, loss_ce: 0.005065
2022-01-08 18:23:32,671 Training Data Eval:
2022-01-08 18:23:45,999   Average segmentation loss on training set: 0.0115
2022-01-08 18:23:45,999 Validation Data Eval:
2022-01-08 18:23:50,526   Average segmentation loss on validation set: 0.0881
2022-01-08 18:23:53,058 iteration 4760 : loss : 0.020195, loss_ce: 0.006645
 70%|██████████████████▉        | 280/400 [3:23:59<1:35:59, 48.00s/it]2022-01-08 18:23:55,494 iteration 4761 : loss : 0.015036, loss_ce: 0.005574
2022-01-08 18:23:57,950 iteration 4762 : loss : 0.020669, loss_ce: 0.006618
2022-01-08 18:24:00,527 iteration 4763 : loss : 0.016541, loss_ce: 0.005799
2022-01-08 18:24:03,080 iteration 4764 : loss : 0.017521, loss_ce: 0.004957
2022-01-08 18:24:05,495 iteration 4765 : loss : 0.015499, loss_ce: 0.005782
2022-01-08 18:24:07,983 iteration 4766 : loss : 0.029110, loss_ce: 0.008713
2022-01-08 18:24:10,472 iteration 4767 : loss : 0.018952, loss_ce: 0.009353
2022-01-08 18:24:12,918 iteration 4768 : loss : 0.018814, loss_ce: 0.007300
2022-01-08 18:24:15,397 iteration 4769 : loss : 0.014029, loss_ce: 0.004659
2022-01-08 18:24:17,834 iteration 4770 : loss : 0.022429, loss_ce: 0.010422
2022-01-08 18:24:20,455 iteration 4771 : loss : 0.016914, loss_ce: 0.005664
2022-01-08 18:24:22,868 iteration 4772 : loss : 0.016634, loss_ce: 0.006257
2022-01-08 18:24:25,262 iteration 4773 : loss : 0.013113, loss_ce: 0.005685
2022-01-08 18:24:27,852 iteration 4774 : loss : 0.019383, loss_ce: 0.006965
2022-01-08 18:24:30,203 iteration 4775 : loss : 0.013525, loss_ce: 0.005172
2022-01-08 18:24:32,625 iteration 4776 : loss : 0.019582, loss_ce: 0.006984
2022-01-08 18:24:35,044 iteration 4777 : loss : 0.016515, loss_ce: 0.005986
 70%|██████████████████▉        | 281/400 [3:24:41<1:31:36, 46.19s/it]2022-01-08 18:24:37,514 iteration 4778 : loss : 0.016582, loss_ce: 0.008443
2022-01-08 18:24:39,857 iteration 4779 : loss : 0.014263, loss_ce: 0.005932
2022-01-08 18:24:42,383 iteration 4780 : loss : 0.016366, loss_ce: 0.006791
2022-01-08 18:24:44,869 iteration 4781 : loss : 0.019555, loss_ce: 0.006730
2022-01-08 18:24:47,374 iteration 4782 : loss : 0.031714, loss_ce: 0.011372
2022-01-08 18:24:49,800 iteration 4783 : loss : 0.016277, loss_ce: 0.007029
2022-01-08 18:24:52,366 iteration 4784 : loss : 0.017364, loss_ce: 0.005881
2022-01-08 18:24:54,905 iteration 4785 : loss : 0.016973, loss_ce: 0.006037
2022-01-08 18:24:57,382 iteration 4786 : loss : 0.012819, loss_ce: 0.005252
2022-01-08 18:24:59,827 iteration 4787 : loss : 0.026947, loss_ce: 0.007755
2022-01-08 18:25:02,300 iteration 4788 : loss : 0.017783, loss_ce: 0.004779
2022-01-08 18:25:04,826 iteration 4789 : loss : 0.012803, loss_ce: 0.004981
2022-01-08 18:25:07,131 iteration 4790 : loss : 0.016245, loss_ce: 0.008251
2022-01-08 18:25:09,583 iteration 4791 : loss : 0.034629, loss_ce: 0.015928
2022-01-08 18:25:12,116 iteration 4792 : loss : 0.019802, loss_ce: 0.008104
2022-01-08 18:25:14,567 iteration 4793 : loss : 0.019562, loss_ce: 0.006411
2022-01-08 18:25:17,197 iteration 4794 : loss : 0.014173, loss_ce: 0.003887
 70%|███████████████████        | 282/400 [3:25:24<1:28:27, 44.98s/it]2022-01-08 18:25:19,652 iteration 4795 : loss : 0.028892, loss_ce: 0.012164
2022-01-08 18:25:22,161 iteration 4796 : loss : 0.014003, loss_ce: 0.003718
2022-01-08 18:25:24,585 iteration 4797 : loss : 0.016922, loss_ce: 0.009064
2022-01-08 18:25:27,127 iteration 4798 : loss : 0.022097, loss_ce: 0.010498
2022-01-08 18:25:29,488 iteration 4799 : loss : 0.021271, loss_ce: 0.007155
2022-01-08 18:25:31,956 iteration 4800 : loss : 0.015989, loss_ce: 0.006010
2022-01-08 18:25:34,371 iteration 4801 : loss : 0.015416, loss_ce: 0.006634
2022-01-08 18:25:37,003 iteration 4802 : loss : 0.018993, loss_ce: 0.007118
2022-01-08 18:25:39,468 iteration 4803 : loss : 0.011322, loss_ce: 0.004341
2022-01-08 18:25:41,878 iteration 4804 : loss : 0.016331, loss_ce: 0.006804
2022-01-08 18:25:44,487 iteration 4805 : loss : 0.020242, loss_ce: 0.009956
2022-01-08 18:25:46,900 iteration 4806 : loss : 0.028550, loss_ce: 0.004982
2022-01-08 18:25:49,235 iteration 4807 : loss : 0.013419, loss_ce: 0.004731
2022-01-08 18:25:51,732 iteration 4808 : loss : 0.020966, loss_ce: 0.007210
2022-01-08 18:25:54,326 iteration 4809 : loss : 0.017537, loss_ce: 0.009987
2022-01-08 18:25:56,783 iteration 4810 : loss : 0.020774, loss_ce: 0.006824
2022-01-08 18:25:59,193 iteration 4811 : loss : 0.021800, loss_ce: 0.008684
 71%|███████████████████        | 283/400 [3:26:06<1:25:58, 44.09s/it]2022-01-08 18:26:01,650 iteration 4812 : loss : 0.020131, loss_ce: 0.005715
2022-01-08 18:26:04,120 iteration 4813 : loss : 0.020877, loss_ce: 0.010176
2022-01-08 18:26:06,792 iteration 4814 : loss : 0.026395, loss_ce: 0.011257
2022-01-08 18:26:09,232 iteration 4815 : loss : 0.014890, loss_ce: 0.005619
2022-01-08 18:26:11,624 iteration 4816 : loss : 0.026311, loss_ce: 0.011635
2022-01-08 18:26:14,013 iteration 4817 : loss : 0.013424, loss_ce: 0.005024
2022-01-08 18:26:16,436 iteration 4818 : loss : 0.016264, loss_ce: 0.005591
2022-01-08 18:26:18,911 iteration 4819 : loss : 0.019546, loss_ce: 0.005467
2022-01-08 18:26:21,324 iteration 4820 : loss : 0.021384, loss_ce: 0.009812
2022-01-08 18:26:23,776 iteration 4821 : loss : 0.017530, loss_ce: 0.005475
2022-01-08 18:26:26,281 iteration 4822 : loss : 0.032957, loss_ce: 0.012765
2022-01-08 18:26:28,740 iteration 4823 : loss : 0.025515, loss_ce: 0.005294
2022-01-08 18:26:31,190 iteration 4824 : loss : 0.018196, loss_ce: 0.005020
2022-01-08 18:26:33,805 iteration 4825 : loss : 0.020095, loss_ce: 0.009653
2022-01-08 18:26:36,355 iteration 4826 : loss : 0.022385, loss_ce: 0.009807
2022-01-08 18:26:38,784 iteration 4827 : loss : 0.017572, loss_ce: 0.009270
2022-01-08 18:26:41,193 iteration 4828 : loss : 0.012891, loss_ce: 0.004569
 71%|███████████████████▏       | 284/400 [3:26:48<1:24:01, 43.46s/it]2022-01-08 18:26:43,696 iteration 4829 : loss : 0.015735, loss_ce: 0.008073
2022-01-08 18:26:46,283 iteration 4830 : loss : 0.020024, loss_ce: 0.008527
2022-01-08 18:26:48,780 iteration 4831 : loss : 0.019677, loss_ce: 0.010611
2022-01-08 18:26:51,407 iteration 4832 : loss : 0.015571, loss_ce: 0.005396
2022-01-08 18:26:53,813 iteration 4833 : loss : 0.015776, loss_ce: 0.007491
2022-01-08 18:26:56,253 iteration 4834 : loss : 0.020062, loss_ce: 0.008491
2022-01-08 18:26:58,796 iteration 4835 : loss : 0.019821, loss_ce: 0.007942
2022-01-08 18:27:01,205 iteration 4836 : loss : 0.015408, loss_ce: 0.004813
2022-01-08 18:27:03,678 iteration 4837 : loss : 0.014121, loss_ce: 0.004147
2022-01-08 18:27:06,176 iteration 4838 : loss : 0.020682, loss_ce: 0.008246
2022-01-08 18:27:08,490 iteration 4839 : loss : 0.013693, loss_ce: 0.005537
2022-01-08 18:27:11,002 iteration 4840 : loss : 0.014092, loss_ce: 0.004758
2022-01-08 18:27:13,562 iteration 4841 : loss : 0.024327, loss_ce: 0.008653
2022-01-08 18:27:16,157 iteration 4842 : loss : 0.025122, loss_ce: 0.010925
2022-01-08 18:27:18,579 iteration 4843 : loss : 0.014368, loss_ce: 0.004313
2022-01-08 18:27:21,018 iteration 4844 : loss : 0.020942, loss_ce: 0.006037
2022-01-08 18:27:21,019 Training Data Eval:
2022-01-08 18:27:34,194   Average segmentation loss on training set: 0.0104
2022-01-08 18:27:34,195 Validation Data Eval:
2022-01-08 18:27:38,873   Average segmentation loss on validation set: 0.0762
2022-01-08 18:27:41,205 iteration 4845 : loss : 0.018339, loss_ce: 0.006156
 71%|███████████████████▏       | 285/400 [3:27:48<1:32:49, 48.43s/it]2022-01-08 18:27:43,788 iteration 4846 : loss : 0.016079, loss_ce: 0.006584
2022-01-08 18:27:46,305 iteration 4847 : loss : 0.011989, loss_ce: 0.003938
2022-01-08 18:27:48,801 iteration 4848 : loss : 0.025202, loss_ce: 0.010332
2022-01-08 18:27:51,245 iteration 4849 : loss : 0.015796, loss_ce: 0.005279
2022-01-08 18:27:53,590 iteration 4850 : loss : 0.012376, loss_ce: 0.005450
2022-01-08 18:27:56,159 iteration 4851 : loss : 0.023392, loss_ce: 0.006264
2022-01-08 18:27:58,555 iteration 4852 : loss : 0.016647, loss_ce: 0.008573
2022-01-08 18:28:01,058 iteration 4853 : loss : 0.024454, loss_ce: 0.004570
2022-01-08 18:28:03,595 iteration 4854 : loss : 0.019414, loss_ce: 0.006777
2022-01-08 18:28:06,161 iteration 4855 : loss : 0.020387, loss_ce: 0.007011
2022-01-08 18:28:08,515 iteration 4856 : loss : 0.013236, loss_ce: 0.003991
2022-01-08 18:28:11,011 iteration 4857 : loss : 0.015910, loss_ce: 0.007595
2022-01-08 18:28:13,574 iteration 4858 : loss : 0.034864, loss_ce: 0.019608
2022-01-08 18:28:15,970 iteration 4859 : loss : 0.013301, loss_ce: 0.005686
2022-01-08 18:28:18,444 iteration 4860 : loss : 0.048476, loss_ce: 0.019825
2022-01-08 18:28:20,909 iteration 4861 : loss : 0.019659, loss_ce: 0.007610
2022-01-08 18:28:23,301 iteration 4862 : loss : 0.014597, loss_ce: 0.006105
 72%|███████████████████▎       | 286/400 [3:28:30<1:28:24, 46.53s/it]2022-01-08 18:28:25,714 iteration 4863 : loss : 0.016295, loss_ce: 0.005604
2022-01-08 18:28:28,313 iteration 4864 : loss : 0.021338, loss_ce: 0.007766
2022-01-08 18:28:30,823 iteration 4865 : loss : 0.021405, loss_ce: 0.005926
2022-01-08 18:28:33,252 iteration 4866 : loss : 0.012739, loss_ce: 0.005042
2022-01-08 18:28:35,865 iteration 4867 : loss : 0.015875, loss_ce: 0.006332
2022-01-08 18:28:38,253 iteration 4868 : loss : 0.014916, loss_ce: 0.007235
2022-01-08 18:28:40,586 iteration 4869 : loss : 0.015913, loss_ce: 0.006725
2022-01-08 18:28:43,134 iteration 4870 : loss : 0.024781, loss_ce: 0.008123
2022-01-08 18:28:45,563 iteration 4871 : loss : 0.014008, loss_ce: 0.005655
2022-01-08 18:28:48,154 iteration 4872 : loss : 0.021799, loss_ce: 0.007686
2022-01-08 18:28:50,495 iteration 4873 : loss : 0.015066, loss_ce: 0.005413
2022-01-08 18:28:52,924 iteration 4874 : loss : 0.012283, loss_ce: 0.005187
2022-01-08 18:28:55,345 iteration 4875 : loss : 0.013478, loss_ce: 0.004458
2022-01-08 18:28:57,834 iteration 4876 : loss : 0.014844, loss_ce: 0.004913
2022-01-08 18:29:00,557 iteration 4877 : loss : 0.028189, loss_ce: 0.011208
2022-01-08 18:29:02,983 iteration 4878 : loss : 0.018906, loss_ce: 0.006412
2022-01-08 18:29:05,547 iteration 4879 : loss : 0.021314, loss_ce: 0.008613
 72%|███████████████████▎       | 287/400 [3:29:12<1:25:12, 45.24s/it]2022-01-08 18:29:08,084 iteration 4880 : loss : 0.027841, loss_ce: 0.018778
2022-01-08 18:29:10,466 iteration 4881 : loss : 0.019130, loss_ce: 0.006563
2022-01-08 18:29:13,030 iteration 4882 : loss : 0.013367, loss_ce: 0.003755
2022-01-08 18:29:15,561 iteration 4883 : loss : 0.025229, loss_ce: 0.006898
2022-01-08 18:29:17,971 iteration 4884 : loss : 0.012620, loss_ce: 0.006819
2022-01-08 18:29:20,541 iteration 4885 : loss : 0.019495, loss_ce: 0.006176
2022-01-08 18:29:23,148 iteration 4886 : loss : 0.019105, loss_ce: 0.006428
2022-01-08 18:29:25,630 iteration 4887 : loss : 0.021178, loss_ce: 0.008097
2022-01-08 18:29:27,983 iteration 4888 : loss : 0.022339, loss_ce: 0.006872
2022-01-08 18:29:30,508 iteration 4889 : loss : 0.014848, loss_ce: 0.005421
2022-01-08 18:29:33,059 iteration 4890 : loss : 0.026183, loss_ce: 0.009249
2022-01-08 18:29:35,678 iteration 4891 : loss : 0.017442, loss_ce: 0.009475
2022-01-08 18:29:38,069 iteration 4892 : loss : 0.015520, loss_ce: 0.006451
2022-01-08 18:29:40,577 iteration 4893 : loss : 0.013440, loss_ce: 0.006046
2022-01-08 18:29:43,154 iteration 4894 : loss : 0.021230, loss_ce: 0.004824
2022-01-08 18:29:45,578 iteration 4895 : loss : 0.020897, loss_ce: 0.009227
2022-01-08 18:29:48,000 iteration 4896 : loss : 0.020405, loss_ce: 0.006579
 72%|███████████████████▍       | 288/400 [3:29:54<1:22:53, 44.40s/it]2022-01-08 18:29:50,506 iteration 4897 : loss : 0.030957, loss_ce: 0.012181
2022-01-08 18:29:53,112 iteration 4898 : loss : 0.021115, loss_ce: 0.009608
2022-01-08 18:29:55,437 iteration 4899 : loss : 0.014868, loss_ce: 0.006280
2022-01-08 18:29:58,143 iteration 4900 : loss : 0.025030, loss_ce: 0.008936
2022-01-08 18:30:00,585 iteration 4901 : loss : 0.015580, loss_ce: 0.004099
2022-01-08 18:30:03,052 iteration 4902 : loss : 0.024072, loss_ce: 0.009158
2022-01-08 18:30:05,710 iteration 4903 : loss : 0.019628, loss_ce: 0.009274
2022-01-08 18:30:08,389 iteration 4904 : loss : 0.021380, loss_ce: 0.009973
2022-01-08 18:30:11,030 iteration 4905 : loss : 0.021061, loss_ce: 0.006521
2022-01-08 18:30:13,462 iteration 4906 : loss : 0.019591, loss_ce: 0.007724
2022-01-08 18:30:15,772 iteration 4907 : loss : 0.013643, loss_ce: 0.005580
2022-01-08 18:30:18,196 iteration 4908 : loss : 0.014234, loss_ce: 0.005880
2022-01-08 18:30:20,756 iteration 4909 : loss : 0.014336, loss_ce: 0.004776
2022-01-08 18:30:23,204 iteration 4910 : loss : 0.021258, loss_ce: 0.009088
2022-01-08 18:30:25,615 iteration 4911 : loss : 0.016488, loss_ce: 0.005137
2022-01-08 18:30:28,159 iteration 4912 : loss : 0.018940, loss_ce: 0.006177
2022-01-08 18:30:30,785 iteration 4913 : loss : 0.016243, loss_ce: 0.005868
 72%|███████████████████▌       | 289/400 [3:30:37<1:21:15, 43.92s/it]2022-01-08 18:30:33,239 iteration 4914 : loss : 0.014115, loss_ce: 0.005446
2022-01-08 18:30:35,699 iteration 4915 : loss : 0.014450, loss_ce: 0.006611
2022-01-08 18:30:38,149 iteration 4916 : loss : 0.024987, loss_ce: 0.006739
2022-01-08 18:30:40,799 iteration 4917 : loss : 0.019758, loss_ce: 0.006553
2022-01-08 18:30:43,281 iteration 4918 : loss : 0.016451, loss_ce: 0.006591
2022-01-08 18:30:45,766 iteration 4919 : loss : 0.013903, loss_ce: 0.006415
2022-01-08 18:30:48,243 iteration 4920 : loss : 0.022335, loss_ce: 0.007613
2022-01-08 18:30:50,689 iteration 4921 : loss : 0.014436, loss_ce: 0.005222
2022-01-08 18:30:53,288 iteration 4922 : loss : 0.018966, loss_ce: 0.006790
2022-01-08 18:30:55,808 iteration 4923 : loss : 0.017835, loss_ce: 0.006530
2022-01-08 18:30:58,359 iteration 4924 : loss : 0.016647, loss_ce: 0.007233
2022-01-08 18:31:00,863 iteration 4925 : loss : 0.033251, loss_ce: 0.011968
2022-01-08 18:31:03,235 iteration 4926 : loss : 0.012951, loss_ce: 0.005897
2022-01-08 18:31:05,777 iteration 4927 : loss : 0.011052, loss_ce: 0.003822
2022-01-08 18:31:08,282 iteration 4928 : loss : 0.015995, loss_ce: 0.006893
2022-01-08 18:31:10,810 iteration 4929 : loss : 0.015476, loss_ce: 0.003690
2022-01-08 18:31:10,811 Training Data Eval:
2022-01-08 18:31:24,125   Average segmentation loss on training set: 0.0109
2022-01-08 18:31:24,125 Validation Data Eval:
2022-01-08 18:31:28,757   Average segmentation loss on validation set: 0.0731
2022-01-08 18:31:31,223 iteration 4930 : loss : 0.026742, loss_ce: 0.008915
 72%|███████████████████▌       | 290/400 [3:31:38<1:29:36, 48.88s/it]2022-01-08 18:31:33,858 iteration 4931 : loss : 0.018027, loss_ce: 0.008352
2022-01-08 18:31:36,363 iteration 4932 : loss : 0.023776, loss_ce: 0.006481
2022-01-08 18:31:38,778 iteration 4933 : loss : 0.016082, loss_ce: 0.006505
2022-01-08 18:31:41,282 iteration 4934 : loss : 0.014567, loss_ce: 0.004559
2022-01-08 18:31:43,688 iteration 4935 : loss : 0.014578, loss_ce: 0.003867
2022-01-08 18:31:46,250 iteration 4936 : loss : 0.015106, loss_ce: 0.005202
2022-01-08 18:31:48,760 iteration 4937 : loss : 0.023900, loss_ce: 0.007817
2022-01-08 18:31:51,169 iteration 4938 : loss : 0.016113, loss_ce: 0.006380
2022-01-08 18:31:53,812 iteration 4939 : loss : 0.024354, loss_ce: 0.010492
2022-01-08 18:31:56,365 iteration 4940 : loss : 0.016129, loss_ce: 0.006584
2022-01-08 18:31:58,836 iteration 4941 : loss : 0.017486, loss_ce: 0.006766
2022-01-08 18:32:01,638 iteration 4942 : loss : 0.020941, loss_ce: 0.009558
2022-01-08 18:32:04,085 iteration 4943 : loss : 0.014148, loss_ce: 0.005853
2022-01-08 18:32:06,460 iteration 4944 : loss : 0.017405, loss_ce: 0.008936
2022-01-08 18:32:08,911 iteration 4945 : loss : 0.011002, loss_ce: 0.004109
2022-01-08 18:32:11,425 iteration 4946 : loss : 0.015770, loss_ce: 0.005602
2022-01-08 18:32:14,033 iteration 4947 : loss : 0.020257, loss_ce: 0.008108
 73%|███████████████████▋       | 291/400 [3:32:20<1:25:29, 47.06s/it]2022-01-08 18:32:16,671 iteration 4948 : loss : 0.018472, loss_ce: 0.006544
2022-01-08 18:32:19,185 iteration 4949 : loss : 0.025272, loss_ce: 0.010863
2022-01-08 18:32:21,616 iteration 4950 : loss : 0.012125, loss_ce: 0.005908
2022-01-08 18:32:24,246 iteration 4951 : loss : 0.018608, loss_ce: 0.007226
2022-01-08 18:32:26,776 iteration 4952 : loss : 0.016761, loss_ce: 0.006984
2022-01-08 18:32:29,261 iteration 4953 : loss : 0.021068, loss_ce: 0.007141
2022-01-08 18:32:31,825 iteration 4954 : loss : 0.015264, loss_ce: 0.004845
2022-01-08 18:32:34,239 iteration 4955 : loss : 0.016892, loss_ce: 0.008176
2022-01-08 18:32:36,745 iteration 4956 : loss : 0.019267, loss_ce: 0.005465
2022-01-08 18:32:39,239 iteration 4957 : loss : 0.015089, loss_ce: 0.005674
2022-01-08 18:32:41,995 iteration 4958 : loss : 0.023885, loss_ce: 0.010044
2022-01-08 18:32:44,684 iteration 4959 : loss : 0.027987, loss_ce: 0.012320
2022-01-08 18:32:47,217 iteration 4960 : loss : 0.014870, loss_ce: 0.006516
2022-01-08 18:32:49,649 iteration 4961 : loss : 0.015891, loss_ce: 0.003845
2022-01-08 18:32:52,291 iteration 4962 : loss : 0.015643, loss_ce: 0.006940
2022-01-08 18:32:54,942 iteration 4963 : loss : 0.016509, loss_ce: 0.006139
2022-01-08 18:32:57,584 iteration 4964 : loss : 0.012841, loss_ce: 0.004608
 73%|███████████████████▋       | 292/400 [3:33:04<1:22:48, 46.01s/it]2022-01-08 18:33:00,101 iteration 4965 : loss : 0.021480, loss_ce: 0.006543
2022-01-08 18:33:02,580 iteration 4966 : loss : 0.018146, loss_ce: 0.007262
2022-01-08 18:33:05,120 iteration 4967 : loss : 0.023869, loss_ce: 0.007067
2022-01-08 18:33:07,684 iteration 4968 : loss : 0.021595, loss_ce: 0.005029
2022-01-08 18:33:10,102 iteration 4969 : loss : 0.025203, loss_ce: 0.008999
2022-01-08 18:33:12,578 iteration 4970 : loss : 0.041918, loss_ce: 0.024850
2022-01-08 18:33:15,036 iteration 4971 : loss : 0.021509, loss_ce: 0.009494
2022-01-08 18:33:17,483 iteration 4972 : loss : 0.017489, loss_ce: 0.005716
2022-01-08 18:33:20,129 iteration 4973 : loss : 0.014545, loss_ce: 0.004635
2022-01-08 18:33:22,614 iteration 4974 : loss : 0.012921, loss_ce: 0.006018
2022-01-08 18:33:25,250 iteration 4975 : loss : 0.013336, loss_ce: 0.004953
2022-01-08 18:33:27,878 iteration 4976 : loss : 0.014609, loss_ce: 0.005221
2022-01-08 18:33:30,344 iteration 4977 : loss : 0.013138, loss_ce: 0.005400
2022-01-08 18:33:32,862 iteration 4978 : loss : 0.013412, loss_ce: 0.005548
2022-01-08 18:33:35,322 iteration 4979 : loss : 0.014296, loss_ce: 0.005294
2022-01-08 18:33:37,767 iteration 4980 : loss : 0.011702, loss_ce: 0.004090
2022-01-08 18:33:40,230 iteration 4981 : loss : 0.020528, loss_ce: 0.007482
 73%|███████████████████▊       | 293/400 [3:33:47<1:20:14, 45.00s/it]2022-01-08 18:33:42,898 iteration 4982 : loss : 0.021485, loss_ce: 0.004741
2022-01-08 18:33:45,289 iteration 4983 : loss : 0.012696, loss_ce: 0.003954
2022-01-08 18:33:47,976 iteration 4984 : loss : 0.017333, loss_ce: 0.004644
2022-01-08 18:33:50,365 iteration 4985 : loss : 0.010317, loss_ce: 0.003519
2022-01-08 18:33:52,920 iteration 4986 : loss : 0.019122, loss_ce: 0.006347
2022-01-08 18:33:55,392 iteration 4987 : loss : 0.013965, loss_ce: 0.006707
2022-01-08 18:33:57,954 iteration 4988 : loss : 0.016335, loss_ce: 0.008213
2022-01-08 18:34:00,407 iteration 4989 : loss : 0.024610, loss_ce: 0.009258
2022-01-08 18:34:02,980 iteration 4990 : loss : 0.016008, loss_ce: 0.006664
2022-01-08 18:34:05,426 iteration 4991 : loss : 0.017397, loss_ce: 0.005791
2022-01-08 18:34:07,948 iteration 4992 : loss : 0.019842, loss_ce: 0.006776
2022-01-08 18:34:10,420 iteration 4993 : loss : 0.018474, loss_ce: 0.009183
2022-01-08 18:34:13,109 iteration 4994 : loss : 0.021058, loss_ce: 0.007700
2022-01-08 18:34:15,714 iteration 4995 : loss : 0.017007, loss_ce: 0.007311
2022-01-08 18:34:18,307 iteration 4996 : loss : 0.014011, loss_ce: 0.003601
2022-01-08 18:34:20,783 iteration 4997 : loss : 0.016497, loss_ce: 0.006543
2022-01-08 18:34:23,223 iteration 4998 : loss : 0.016574, loss_ce: 0.005699
 74%|███████████████████▊       | 294/400 [3:34:30<1:18:26, 44.40s/it]2022-01-08 18:34:26,001 iteration 4999 : loss : 0.017038, loss_ce: 0.007330
2022-01-08 18:34:28,406 iteration 5000 : loss : 0.014790, loss_ce: 0.004550
2022-01-08 18:34:31,027 iteration 5001 : loss : 0.017435, loss_ce: 0.005132
2022-01-08 18:34:33,674 iteration 5002 : loss : 0.019899, loss_ce: 0.005814
2022-01-08 18:34:36,289 iteration 5003 : loss : 0.017058, loss_ce: 0.007716
2022-01-08 18:34:38,799 iteration 5004 : loss : 0.016486, loss_ce: 0.007611
2022-01-08 18:34:41,408 iteration 5005 : loss : 0.014952, loss_ce: 0.005381
2022-01-08 18:34:43,812 iteration 5006 : loss : 0.013879, loss_ce: 0.005245
2022-01-08 18:34:46,380 iteration 5007 : loss : 0.022780, loss_ce: 0.006685
2022-01-08 18:34:48,908 iteration 5008 : loss : 0.013758, loss_ce: 0.004482
2022-01-08 18:34:51,312 iteration 5009 : loss : 0.013892, loss_ce: 0.007096
2022-01-08 18:34:53,961 iteration 5010 : loss : 0.018367, loss_ce: 0.009202
2022-01-08 18:34:56,383 iteration 5011 : loss : 0.015042, loss_ce: 0.006404
2022-01-08 18:34:58,899 iteration 5012 : loss : 0.019075, loss_ce: 0.005938
2022-01-08 18:35:01,533 iteration 5013 : loss : 0.014399, loss_ce: 0.005968
2022-01-08 18:35:03,907 iteration 5014 : loss : 0.014915, loss_ce: 0.005346
2022-01-08 18:35:03,907 Training Data Eval:
2022-01-08 18:35:17,394   Average segmentation loss on training set: 0.0096
2022-01-08 18:35:17,395 Validation Data Eval:
2022-01-08 18:35:22,049   Average segmentation loss on validation set: 0.0772
2022-01-08 18:35:24,563 iteration 5015 : loss : 0.030603, loss_ce: 0.010302
 74%|███████████████████▉       | 295/400 [3:35:31<1:26:34, 49.47s/it]2022-01-08 18:35:27,182 iteration 5016 : loss : 0.019831, loss_ce: 0.008567
2022-01-08 18:35:29,505 iteration 5017 : loss : 0.010748, loss_ce: 0.004380
2022-01-08 18:35:32,087 iteration 5018 : loss : 0.015065, loss_ce: 0.006392
2022-01-08 18:35:34,671 iteration 5019 : loss : 0.013763, loss_ce: 0.004916
2022-01-08 18:35:37,116 iteration 5020 : loss : 0.028036, loss_ce: 0.008689
2022-01-08 18:35:39,571 iteration 5021 : loss : 0.027017, loss_ce: 0.010270
2022-01-08 18:35:42,217 iteration 5022 : loss : 0.015844, loss_ce: 0.005081
2022-01-08 18:35:44,664 iteration 5023 : loss : 0.019756, loss_ce: 0.009163
2022-01-08 18:35:47,113 iteration 5024 : loss : 0.025852, loss_ce: 0.011687
2022-01-08 18:35:49,783 iteration 5025 : loss : 0.016770, loss_ce: 0.006287
2022-01-08 18:35:52,505 iteration 5026 : loss : 0.021478, loss_ce: 0.006825
2022-01-08 18:35:54,883 iteration 5027 : loss : 0.011132, loss_ce: 0.004143
2022-01-08 18:35:57,339 iteration 5028 : loss : 0.013784, loss_ce: 0.006102
2022-01-08 18:35:59,915 iteration 5029 : loss : 0.028657, loss_ce: 0.010542
2022-01-08 18:36:02,362 iteration 5030 : loss : 0.013126, loss_ce: 0.005615
2022-01-08 18:36:04,858 iteration 5031 : loss : 0.025608, loss_ce: 0.008089
2022-01-08 18:36:07,440 iteration 5032 : loss : 0.013078, loss_ce: 0.004835
 74%|███████████████████▉       | 296/400 [3:36:14<1:22:19, 47.50s/it]2022-01-08 18:36:09,935 iteration 5033 : loss : 0.014700, loss_ce: 0.004813
2022-01-08 18:36:12,346 iteration 5034 : loss : 0.019724, loss_ce: 0.006531
2022-01-08 18:36:14,777 iteration 5035 : loss : 0.015777, loss_ce: 0.005393
2022-01-08 18:36:17,285 iteration 5036 : loss : 0.016360, loss_ce: 0.006175
2022-01-08 18:36:19,901 iteration 5037 : loss : 0.017256, loss_ce: 0.006394
2022-01-08 18:36:22,322 iteration 5038 : loss : 0.015265, loss_ce: 0.004585
2022-01-08 18:36:24,885 iteration 5039 : loss : 0.017051, loss_ce: 0.006283
2022-01-08 18:36:27,494 iteration 5040 : loss : 0.016267, loss_ce: 0.007424
2022-01-08 18:36:29,912 iteration 5041 : loss : 0.013959, loss_ce: 0.005505
2022-01-08 18:36:32,601 iteration 5042 : loss : 0.025264, loss_ce: 0.009897
2022-01-08 18:36:34,942 iteration 5043 : loss : 0.015423, loss_ce: 0.005629
2022-01-08 18:36:37,394 iteration 5044 : loss : 0.015310, loss_ce: 0.004697
2022-01-08 18:36:39,970 iteration 5045 : loss : 0.019849, loss_ce: 0.008687
2022-01-08 18:36:42,493 iteration 5046 : loss : 0.023848, loss_ce: 0.005714
2022-01-08 18:36:44,868 iteration 5047 : loss : 0.011314, loss_ce: 0.003434
2022-01-08 18:36:47,249 iteration 5048 : loss : 0.016441, loss_ce: 0.007506
2022-01-08 18:36:49,756 iteration 5049 : loss : 0.011657, loss_ce: 0.004973
 74%|████████████████████       | 297/400 [3:36:56<1:18:52, 45.94s/it]2022-01-08 18:36:52,348 iteration 5050 : loss : 0.014222, loss_ce: 0.004822
2022-01-08 18:36:54,795 iteration 5051 : loss : 0.029627, loss_ce: 0.011322
2022-01-08 18:36:57,288 iteration 5052 : loss : 0.017546, loss_ce: 0.006642
2022-01-08 18:36:59,813 iteration 5053 : loss : 0.019971, loss_ce: 0.006484
2022-01-08 18:37:02,343 iteration 5054 : loss : 0.017270, loss_ce: 0.004151
2022-01-08 18:37:04,821 iteration 5055 : loss : 0.020394, loss_ce: 0.007829
2022-01-08 18:37:07,475 iteration 5056 : loss : 0.015270, loss_ce: 0.006000
2022-01-08 18:37:09,945 iteration 5057 : loss : 0.017556, loss_ce: 0.007336
2022-01-08 18:37:12,352 iteration 5058 : loss : 0.019774, loss_ce: 0.008092
2022-01-08 18:37:14,801 iteration 5059 : loss : 0.016708, loss_ce: 0.006466
2022-01-08 18:37:17,311 iteration 5060 : loss : 0.019048, loss_ce: 0.010260
2022-01-08 18:37:19,917 iteration 5061 : loss : 0.022102, loss_ce: 0.007463
2022-01-08 18:37:22,403 iteration 5062 : loss : 0.016235, loss_ce: 0.005115
2022-01-08 18:37:24,918 iteration 5063 : loss : 0.020888, loss_ce: 0.007526
2022-01-08 18:37:27,371 iteration 5064 : loss : 0.019684, loss_ce: 0.006673
2022-01-08 18:37:29,824 iteration 5065 : loss : 0.015056, loss_ce: 0.007420
2022-01-08 18:37:32,360 iteration 5066 : loss : 0.013185, loss_ce: 0.005271
 74%|████████████████████       | 298/400 [3:37:39<1:16:23, 44.94s/it]2022-01-08 18:37:34,733 iteration 5067 : loss : 0.016244, loss_ce: 0.005594
2022-01-08 18:37:37,243 iteration 5068 : loss : 0.015092, loss_ce: 0.004228
2022-01-08 18:37:39,834 iteration 5069 : loss : 0.014570, loss_ce: 0.007072
2022-01-08 18:37:42,197 iteration 5070 : loss : 0.016056, loss_ce: 0.005370
2022-01-08 18:37:44,639 iteration 5071 : loss : 0.019077, loss_ce: 0.009318
2022-01-08 18:37:47,023 iteration 5072 : loss : 0.012000, loss_ce: 0.004436
2022-01-08 18:37:49,662 iteration 5073 : loss : 0.021074, loss_ce: 0.009410
2022-01-08 18:37:52,078 iteration 5074 : loss : 0.012196, loss_ce: 0.004576
2022-01-08 18:37:54,600 iteration 5075 : loss : 0.016920, loss_ce: 0.005986
2022-01-08 18:37:57,036 iteration 5076 : loss : 0.023959, loss_ce: 0.005220
2022-01-08 18:37:59,422 iteration 5077 : loss : 0.019667, loss_ce: 0.006398
2022-01-08 18:38:01,796 iteration 5078 : loss : 0.018510, loss_ce: 0.008687
2022-01-08 18:38:04,215 iteration 5079 : loss : 0.012008, loss_ce: 0.004832
2022-01-08 18:38:06,617 iteration 5080 : loss : 0.015758, loss_ce: 0.006144
2022-01-08 18:38:09,178 iteration 5081 : loss : 0.016353, loss_ce: 0.004473
2022-01-08 18:38:11,595 iteration 5082 : loss : 0.013259, loss_ce: 0.004792
2022-01-08 18:38:14,075 iteration 5083 : loss : 0.020046, loss_ce: 0.004334
 75%|████████████████████▏      | 299/400 [3:38:20<1:14:01, 43.97s/it]2022-01-08 18:38:16,700 iteration 5084 : loss : 0.016911, loss_ce: 0.008140
2022-01-08 18:38:19,169 iteration 5085 : loss : 0.019525, loss_ce: 0.006654
2022-01-08 18:38:21,635 iteration 5086 : loss : 0.013312, loss_ce: 0.004280
2022-01-08 18:38:24,025 iteration 5087 : loss : 0.016206, loss_ce: 0.007321
2022-01-08 18:38:26,426 iteration 5088 : loss : 0.016524, loss_ce: 0.006977
2022-01-08 18:38:29,000 iteration 5089 : loss : 0.017681, loss_ce: 0.005088
2022-01-08 18:38:31,484 iteration 5090 : loss : 0.015501, loss_ce: 0.003243
2022-01-08 18:38:33,938 iteration 5091 : loss : 0.016778, loss_ce: 0.005561
2022-01-08 18:38:36,397 iteration 5092 : loss : 0.018487, loss_ce: 0.007780
2022-01-08 18:38:38,793 iteration 5093 : loss : 0.013259, loss_ce: 0.003960
2022-01-08 18:38:41,276 iteration 5094 : loss : 0.022856, loss_ce: 0.008578
2022-01-08 18:38:43,667 iteration 5095 : loss : 0.015964, loss_ce: 0.006162
2022-01-08 18:38:46,106 iteration 5096 : loss : 0.022075, loss_ce: 0.010867
2022-01-08 18:38:48,493 iteration 5097 : loss : 0.016386, loss_ce: 0.006669
2022-01-08 18:38:51,119 iteration 5098 : loss : 0.023562, loss_ce: 0.009581
2022-01-08 18:38:53,678 iteration 5099 : loss : 0.024301, loss_ce: 0.007103
2022-01-08 18:38:53,679 Training Data Eval:
2022-01-08 18:39:06,731   Average segmentation loss on training set: 0.0092
2022-01-08 18:39:06,732 Validation Data Eval:
2022-01-08 18:39:11,401   Average segmentation loss on validation set: 0.0728
2022-01-08 18:39:14,040 iteration 5100 : loss : 0.024109, loss_ce: 0.006156
 75%|████████████████████▎      | 300/400 [3:39:20<1:21:17, 48.77s/it]2022-01-08 18:39:16,562 iteration 5101 : loss : 0.017804, loss_ce: 0.007311
2022-01-08 18:39:18,994 iteration 5102 : loss : 0.015199, loss_ce: 0.005318
2022-01-08 18:39:21,429 iteration 5103 : loss : 0.013871, loss_ce: 0.006999
2022-01-08 18:39:23,888 iteration 5104 : loss : 0.015659, loss_ce: 0.005304
2022-01-08 18:39:26,499 iteration 5105 : loss : 0.017462, loss_ce: 0.006479
2022-01-08 18:39:28,927 iteration 5106 : loss : 0.015380, loss_ce: 0.006356
2022-01-08 18:39:31,503 iteration 5107 : loss : 0.031056, loss_ce: 0.012820
2022-01-08 18:39:34,109 iteration 5108 : loss : 0.014602, loss_ce: 0.006578
2022-01-08 18:39:36,587 iteration 5109 : loss : 0.023976, loss_ce: 0.009231
2022-01-08 18:39:38,982 iteration 5110 : loss : 0.013039, loss_ce: 0.004038
2022-01-08 18:39:41,414 iteration 5111 : loss : 0.015647, loss_ce: 0.005381
2022-01-08 18:39:43,943 iteration 5112 : loss : 0.020023, loss_ce: 0.006842
2022-01-08 18:39:46,375 iteration 5113 : loss : 0.019083, loss_ce: 0.006613
2022-01-08 18:39:48,966 iteration 5114 : loss : 0.014266, loss_ce: 0.005003
2022-01-08 18:39:51,343 iteration 5115 : loss : 0.021155, loss_ce: 0.007158
2022-01-08 18:39:53,812 iteration 5116 : loss : 0.015412, loss_ce: 0.005887
2022-01-08 18:39:56,366 iteration 5117 : loss : 0.017594, loss_ce: 0.008078
 75%|████████████████████▎      | 301/400 [3:40:03<1:17:17, 46.84s/it]2022-01-08 18:39:58,825 iteration 5118 : loss : 0.017500, loss_ce: 0.004297
2022-01-08 18:40:01,168 iteration 5119 : loss : 0.014445, loss_ce: 0.006111
2022-01-08 18:40:03,612 iteration 5120 : loss : 0.015066, loss_ce: 0.005963
2022-01-08 18:40:06,130 iteration 5121 : loss : 0.013549, loss_ce: 0.003598
2022-01-08 18:40:08,774 iteration 5122 : loss : 0.015568, loss_ce: 0.007333
2022-01-08 18:40:11,235 iteration 5123 : loss : 0.020556, loss_ce: 0.006818
2022-01-08 18:40:13,774 iteration 5124 : loss : 0.012112, loss_ce: 0.005707
2022-01-08 18:40:16,172 iteration 5125 : loss : 0.015283, loss_ce: 0.005243
2022-01-08 18:40:18,576 iteration 5126 : loss : 0.015174, loss_ce: 0.005678
2022-01-08 18:40:21,020 iteration 5127 : loss : 0.022221, loss_ce: 0.009446
2022-01-08 18:40:23,439 iteration 5128 : loss : 0.021100, loss_ce: 0.007417
2022-01-08 18:40:26,084 iteration 5129 : loss : 0.015855, loss_ce: 0.006633
2022-01-08 18:40:28,528 iteration 5130 : loss : 0.013722, loss_ce: 0.005473
2022-01-08 18:40:30,925 iteration 5131 : loss : 0.014287, loss_ce: 0.005388
2022-01-08 18:40:33,344 iteration 5132 : loss : 0.019812, loss_ce: 0.006777
2022-01-08 18:40:35,787 iteration 5133 : loss : 0.019790, loss_ce: 0.007895
2022-01-08 18:40:38,253 iteration 5134 : loss : 0.025523, loss_ce: 0.005922
 76%|████████████████████▍      | 302/400 [3:40:45<1:14:04, 45.35s/it]2022-01-08 18:40:40,662 iteration 5135 : loss : 0.016371, loss_ce: 0.008123
2022-01-08 18:40:43,134 iteration 5136 : loss : 0.011614, loss_ce: 0.003766
2022-01-08 18:40:45,526 iteration 5137 : loss : 0.013950, loss_ce: 0.004792
2022-01-08 18:40:47,939 iteration 5138 : loss : 0.015602, loss_ce: 0.006715
2022-01-08 18:40:50,583 iteration 5139 : loss : 0.017368, loss_ce: 0.006944
2022-01-08 18:40:53,037 iteration 5140 : loss : 0.026142, loss_ce: 0.009108
2022-01-08 18:40:55,451 iteration 5141 : loss : 0.030385, loss_ce: 0.008986
2022-01-08 18:40:58,086 iteration 5142 : loss : 0.013617, loss_ce: 0.004690
2022-01-08 18:41:00,493 iteration 5143 : loss : 0.011795, loss_ce: 0.005653
2022-01-08 18:41:02,956 iteration 5144 : loss : 0.015054, loss_ce: 0.006667
2022-01-08 18:41:05,600 iteration 5145 : loss : 0.014628, loss_ce: 0.004628
2022-01-08 18:41:08,028 iteration 5146 : loss : 0.014365, loss_ce: 0.004341
2022-01-08 18:41:10,394 iteration 5147 : loss : 0.016573, loss_ce: 0.003973
2022-01-08 18:41:12,917 iteration 5148 : loss : 0.019498, loss_ce: 0.008558
2022-01-08 18:41:15,357 iteration 5149 : loss : 0.013614, loss_ce: 0.004669
2022-01-08 18:41:17,757 iteration 5150 : loss : 0.016645, loss_ce: 0.007949
2022-01-08 18:41:20,398 iteration 5151 : loss : 0.016325, loss_ce: 0.007750
 76%|████████████████████▍      | 303/400 [3:41:27<1:11:46, 44.40s/it]2022-01-08 18:41:23,026 iteration 5152 : loss : 0.022260, loss_ce: 0.008650
2022-01-08 18:41:25,416 iteration 5153 : loss : 0.016543, loss_ce: 0.006242
2022-01-08 18:41:27,790 iteration 5154 : loss : 0.013894, loss_ce: 0.004855
2022-01-08 18:41:30,186 iteration 5155 : loss : 0.011562, loss_ce: 0.004110
2022-01-08 18:41:32,621 iteration 5156 : loss : 0.022644, loss_ce: 0.005446
2022-01-08 18:41:35,040 iteration 5157 : loss : 0.011067, loss_ce: 0.004278
2022-01-08 18:41:37,447 iteration 5158 : loss : 0.030645, loss_ce: 0.009979
2022-01-08 18:41:39,875 iteration 5159 : loss : 0.015395, loss_ce: 0.005622
2022-01-08 18:41:42,398 iteration 5160 : loss : 0.017316, loss_ce: 0.008130
2022-01-08 18:41:44,800 iteration 5161 : loss : 0.017603, loss_ce: 0.006671
2022-01-08 18:41:47,427 iteration 5162 : loss : 0.013189, loss_ce: 0.003446
2022-01-08 18:41:49,925 iteration 5163 : loss : 0.018401, loss_ce: 0.009015
2022-01-08 18:41:52,364 iteration 5164 : loss : 0.012535, loss_ce: 0.004673
2022-01-08 18:41:54,821 iteration 5165 : loss : 0.022889, loss_ce: 0.007724
2022-01-08 18:41:57,182 iteration 5166 : loss : 0.014698, loss_ce: 0.005093
2022-01-08 18:41:59,663 iteration 5167 : loss : 0.023107, loss_ce: 0.005908
2022-01-08 18:42:02,145 iteration 5168 : loss : 0.011418, loss_ce: 0.005467
 76%|████████████████████▌      | 304/400 [3:42:09<1:09:45, 43.60s/it]2022-01-08 18:42:04,714 iteration 5169 : loss : 0.012423, loss_ce: 0.003273
2022-01-08 18:42:07,153 iteration 5170 : loss : 0.011641, loss_ce: 0.005574
2022-01-08 18:42:09,681 iteration 5171 : loss : 0.021998, loss_ce: 0.006428
2022-01-08 18:42:12,262 iteration 5172 : loss : 0.022550, loss_ce: 0.008643
2022-01-08 18:42:14,808 iteration 5173 : loss : 0.023855, loss_ce: 0.008605
2022-01-08 18:42:17,201 iteration 5174 : loss : 0.010897, loss_ce: 0.002882
2022-01-08 18:42:19,625 iteration 5175 : loss : 0.013445, loss_ce: 0.004856
2022-01-08 18:42:22,094 iteration 5176 : loss : 0.018304, loss_ce: 0.006913
2022-01-08 18:42:24,529 iteration 5177 : loss : 0.017920, loss_ce: 0.006138
2022-01-08 18:42:27,018 iteration 5178 : loss : 0.016238, loss_ce: 0.007786
2022-01-08 18:42:29,443 iteration 5179 : loss : 0.014759, loss_ce: 0.006370
2022-01-08 18:42:31,834 iteration 5180 : loss : 0.017915, loss_ce: 0.007102
2022-01-08 18:42:34,333 iteration 5181 : loss : 0.013932, loss_ce: 0.004368
2022-01-08 18:42:36,760 iteration 5182 : loss : 0.015854, loss_ce: 0.007177
2022-01-08 18:42:39,247 iteration 5183 : loss : 0.017850, loss_ce: 0.006831
2022-01-08 18:42:41,574 iteration 5184 : loss : 0.014085, loss_ce: 0.006381
2022-01-08 18:42:41,574 Training Data Eval:
2022-01-08 18:42:54,637   Average segmentation loss on training set: 0.0096
2022-01-08 18:42:54,637 Validation Data Eval:
2022-01-08 18:42:59,155   Average segmentation loss on validation set: 0.0745
2022-01-08 18:43:01,585 iteration 5185 : loss : 0.011910, loss_ce: 0.004563
 76%|████████████████████▌      | 305/400 [3:43:08<1:16:33, 48.35s/it]2022-01-08 18:43:04,084 iteration 5186 : loss : 0.023878, loss_ce: 0.007332
2022-01-08 18:43:06,575 iteration 5187 : loss : 0.013377, loss_ce: 0.005533
2022-01-08 18:43:09,026 iteration 5188 : loss : 0.013615, loss_ce: 0.004232
2022-01-08 18:43:11,490 iteration 5189 : loss : 0.028097, loss_ce: 0.009576
2022-01-08 18:43:14,113 iteration 5190 : loss : 0.016769, loss_ce: 0.005306
2022-01-08 18:43:16,528 iteration 5191 : loss : 0.018489, loss_ce: 0.007508
2022-01-08 18:43:18,969 iteration 5192 : loss : 0.012587, loss_ce: 0.004603
2022-01-08 18:43:21,475 iteration 5193 : loss : 0.017790, loss_ce: 0.008082
2022-01-08 18:43:23,888 iteration 5194 : loss : 0.015943, loss_ce: 0.004348
2022-01-08 18:43:26,291 iteration 5195 : loss : 0.024050, loss_ce: 0.008357
2022-01-08 18:43:28,805 iteration 5196 : loss : 0.018614, loss_ce: 0.006576
2022-01-08 18:43:31,216 iteration 5197 : loss : 0.014036, loss_ce: 0.004188
2022-01-08 18:43:33,726 iteration 5198 : loss : 0.013706, loss_ce: 0.008251
2022-01-08 18:43:36,223 iteration 5199 : loss : 0.013985, loss_ce: 0.004963
2022-01-08 18:43:38,593 iteration 5200 : loss : 0.014154, loss_ce: 0.006110
2022-01-08 18:43:41,063 iteration 5201 : loss : 0.012392, loss_ce: 0.005118
2022-01-08 18:43:43,590 iteration 5202 : loss : 0.015380, loss_ce: 0.006044
 76%|████████████████████▋      | 306/400 [3:43:50<1:12:46, 46.45s/it]2022-01-08 18:43:46,024 iteration 5203 : loss : 0.016757, loss_ce: 0.006810
2022-01-08 18:43:48,495 iteration 5204 : loss : 0.026590, loss_ce: 0.012218
2022-01-08 18:43:50,917 iteration 5205 : loss : 0.021735, loss_ce: 0.007852
2022-01-08 18:43:53,587 iteration 5206 : loss : 0.019810, loss_ce: 0.007600
2022-01-08 18:43:56,226 iteration 5207 : loss : 0.031243, loss_ce: 0.007649
2022-01-08 18:43:58,632 iteration 5208 : loss : 0.018174, loss_ce: 0.009002
2022-01-08 18:44:01,200 iteration 5209 : loss : 0.018862, loss_ce: 0.006989
2022-01-08 18:44:03,641 iteration 5210 : loss : 0.014933, loss_ce: 0.006747
2022-01-08 18:44:06,037 iteration 5211 : loss : 0.012965, loss_ce: 0.004507
2022-01-08 18:44:08,470 iteration 5212 : loss : 0.025524, loss_ce: 0.006992
2022-01-08 18:44:11,004 iteration 5213 : loss : 0.017323, loss_ce: 0.006546
2022-01-08 18:44:13,416 iteration 5214 : loss : 0.014191, loss_ce: 0.006775
2022-01-08 18:44:15,853 iteration 5215 : loss : 0.011966, loss_ce: 0.004196
2022-01-08 18:44:18,205 iteration 5216 : loss : 0.014337, loss_ce: 0.004707
2022-01-08 18:44:20,666 iteration 5217 : loss : 0.018644, loss_ce: 0.008022
2022-01-08 18:44:23,071 iteration 5218 : loss : 0.015305, loss_ce: 0.004993
2022-01-08 18:44:25,549 iteration 5219 : loss : 0.015972, loss_ce: 0.006113
 77%|████████████████████▋      | 307/400 [3:44:32<1:09:54, 45.10s/it]2022-01-08 18:44:27,943 iteration 5220 : loss : 0.010774, loss_ce: 0.004576
2022-01-08 18:44:30,488 iteration 5221 : loss : 0.017032, loss_ce: 0.004401
2022-01-08 18:44:32,909 iteration 5222 : loss : 0.016196, loss_ce: 0.004776
2022-01-08 18:44:35,383 iteration 5223 : loss : 0.012734, loss_ce: 0.005494
2022-01-08 18:44:37,874 iteration 5224 : loss : 0.022104, loss_ce: 0.005204
2022-01-08 18:44:40,371 iteration 5225 : loss : 0.014545, loss_ce: 0.006031
2022-01-08 18:44:42,776 iteration 5226 : loss : 0.014229, loss_ce: 0.006421
2022-01-08 18:44:45,374 iteration 5227 : loss : 0.020189, loss_ce: 0.006321
2022-01-08 18:44:47,709 iteration 5228 : loss : 0.010295, loss_ce: 0.003359
2022-01-08 18:44:50,087 iteration 5229 : loss : 0.017220, loss_ce: 0.006723
2022-01-08 18:44:52,396 iteration 5230 : loss : 0.011480, loss_ce: 0.004113
2022-01-08 18:44:54,928 iteration 5231 : loss : 0.012111, loss_ce: 0.003714
2022-01-08 18:44:57,395 iteration 5232 : loss : 0.024113, loss_ce: 0.007372
2022-01-08 18:44:59,762 iteration 5233 : loss : 0.013126, loss_ce: 0.005445
2022-01-08 18:45:02,201 iteration 5234 : loss : 0.020610, loss_ce: 0.008428
2022-01-08 18:45:04,640 iteration 5235 : loss : 0.017057, loss_ce: 0.008486
2022-01-08 18:45:07,106 iteration 5236 : loss : 0.025902, loss_ce: 0.011018
 77%|████████████████████▊      | 308/400 [3:45:13<1:07:31, 44.04s/it]2022-01-08 18:45:09,531 iteration 5237 : loss : 0.010691, loss_ce: 0.004663
2022-01-08 18:45:11,902 iteration 5238 : loss : 0.016991, loss_ce: 0.006782
2022-01-08 18:45:14,320 iteration 5239 : loss : 0.010979, loss_ce: 0.003847
2022-01-08 18:45:16,897 iteration 5240 : loss : 0.033013, loss_ce: 0.006334
2022-01-08 18:45:19,295 iteration 5241 : loss : 0.020745, loss_ce: 0.006878
2022-01-08 18:45:21,794 iteration 5242 : loss : 0.016402, loss_ce: 0.007406
2022-01-08 18:45:24,368 iteration 5243 : loss : 0.017495, loss_ce: 0.008397
2022-01-08 18:45:26,815 iteration 5244 : loss : 0.015115, loss_ce: 0.004759
2022-01-08 18:45:29,253 iteration 5245 : loss : 0.016173, loss_ce: 0.005208
2022-01-08 18:45:31,737 iteration 5246 : loss : 0.025571, loss_ce: 0.008290
2022-01-08 18:45:34,162 iteration 5247 : loss : 0.020654, loss_ce: 0.007421
2022-01-08 18:45:36,649 iteration 5248 : loss : 0.020849, loss_ce: 0.010092
2022-01-08 18:45:39,015 iteration 5249 : loss : 0.028603, loss_ce: 0.011841
2022-01-08 18:45:41,483 iteration 5250 : loss : 0.014205, loss_ce: 0.004826
2022-01-08 18:45:44,031 iteration 5251 : loss : 0.018890, loss_ce: 0.006929
2022-01-08 18:45:46,430 iteration 5252 : loss : 0.014559, loss_ce: 0.006654
2022-01-08 18:45:48,923 iteration 5253 : loss : 0.014951, loss_ce: 0.005847
 77%|████████████████████▊      | 309/400 [3:45:55<1:05:46, 43.37s/it]2022-01-08 18:45:51,383 iteration 5254 : loss : 0.015659, loss_ce: 0.007051
2022-01-08 18:45:53,865 iteration 5255 : loss : 0.016412, loss_ce: 0.004762
2022-01-08 18:45:56,337 iteration 5256 : loss : 0.020713, loss_ce: 0.007922
2022-01-08 18:45:58,824 iteration 5257 : loss : 0.017261, loss_ce: 0.006655
2022-01-08 18:46:01,161 iteration 5258 : loss : 0.012924, loss_ce: 0.005189
2022-01-08 18:46:03,650 iteration 5259 : loss : 0.024838, loss_ce: 0.007030
2022-01-08 18:46:06,117 iteration 5260 : loss : 0.026362, loss_ce: 0.007959
2022-01-08 18:46:08,584 iteration 5261 : loss : 0.014305, loss_ce: 0.006272
2022-01-08 18:46:11,035 iteration 5262 : loss : 0.017099, loss_ce: 0.007215
2022-01-08 18:46:13,646 iteration 5263 : loss : 0.015738, loss_ce: 0.006224
2022-01-08 18:46:16,158 iteration 5264 : loss : 0.018806, loss_ce: 0.007178
2022-01-08 18:46:18,622 iteration 5265 : loss : 0.026384, loss_ce: 0.010623
2022-01-08 18:46:20,976 iteration 5266 : loss : 0.016323, loss_ce: 0.007003
2022-01-08 18:46:23,531 iteration 5267 : loss : 0.020991, loss_ce: 0.010042
2022-01-08 18:46:25,970 iteration 5268 : loss : 0.011467, loss_ce: 0.002622
2022-01-08 18:46:28,446 iteration 5269 : loss : 0.012382, loss_ce: 0.004515
2022-01-08 18:46:28,446 Training Data Eval:
2022-01-08 18:46:41,533   Average segmentation loss on training set: 0.0092
2022-01-08 18:46:41,533 Validation Data Eval:
2022-01-08 18:46:46,016   Average segmentation loss on validation set: 0.0676
2022-01-08 18:46:48,439 iteration 5270 : loss : 0.050626, loss_ce: 0.006685
 78%|████████████████████▉      | 310/400 [3:46:55<1:12:19, 48.22s/it]2022-01-08 18:46:50,960 iteration 5271 : loss : 0.024028, loss_ce: 0.006590
2022-01-08 18:46:53,622 iteration 5272 : loss : 0.031309, loss_ce: 0.013952
2022-01-08 18:46:56,019 iteration 5273 : loss : 0.018080, loss_ce: 0.007286
2022-01-08 18:46:58,598 iteration 5274 : loss : 0.024405, loss_ce: 0.009045
2022-01-08 18:47:00,984 iteration 5275 : loss : 0.017360, loss_ce: 0.007467
2022-01-08 18:47:03,333 iteration 5276 : loss : 0.020733, loss_ce: 0.007169
2022-01-08 18:47:05,817 iteration 5277 : loss : 0.029749, loss_ce: 0.013288
2022-01-08 18:47:08,212 iteration 5278 : loss : 0.015355, loss_ce: 0.003650
2022-01-08 18:47:10,736 iteration 5279 : loss : 0.022633, loss_ce: 0.007346
2022-01-08 18:47:13,097 iteration 5280 : loss : 0.013831, loss_ce: 0.004174
2022-01-08 18:47:15,594 iteration 5281 : loss : 0.014992, loss_ce: 0.008051
2022-01-08 18:47:18,039 iteration 5282 : loss : 0.015320, loss_ce: 0.006236
2022-01-08 18:47:20,411 iteration 5283 : loss : 0.016727, loss_ce: 0.007438
2022-01-08 18:47:22,805 iteration 5284 : loss : 0.013313, loss_ce: 0.004704
2022-01-08 18:47:25,238 iteration 5285 : loss : 0.020178, loss_ce: 0.009785
2022-01-08 18:47:27,642 iteration 5286 : loss : 0.014052, loss_ce: 0.006679
2022-01-08 18:47:30,099 iteration 5287 : loss : 0.014507, loss_ce: 0.004987
 78%|████████████████████▉      | 311/400 [3:47:36<1:08:36, 46.25s/it]2022-01-08 18:47:32,631 iteration 5288 : loss : 0.017414, loss_ce: 0.007474
2022-01-08 18:47:35,002 iteration 5289 : loss : 0.018223, loss_ce: 0.006726
2022-01-08 18:47:37,548 iteration 5290 : loss : 0.023923, loss_ce: 0.006700
2022-01-08 18:47:39,937 iteration 5291 : loss : 0.018581, loss_ce: 0.008355
2022-01-08 18:47:42,427 iteration 5292 : loss : 0.020332, loss_ce: 0.005223
2022-01-08 18:47:44,866 iteration 5293 : loss : 0.019160, loss_ce: 0.006517
2022-01-08 18:47:47,293 iteration 5294 : loss : 0.026234, loss_ce: 0.007041
2022-01-08 18:47:49,758 iteration 5295 : loss : 0.015451, loss_ce: 0.004385
2022-01-08 18:47:52,138 iteration 5296 : loss : 0.017594, loss_ce: 0.005032
2022-01-08 18:47:54,660 iteration 5297 : loss : 0.018467, loss_ce: 0.005511
2022-01-08 18:47:57,032 iteration 5298 : loss : 0.013973, loss_ce: 0.006711
2022-01-08 18:47:59,378 iteration 5299 : loss : 0.017248, loss_ce: 0.003316
2022-01-08 18:48:01,983 iteration 5300 : loss : 0.012422, loss_ce: 0.004997
2022-01-08 18:48:04,429 iteration 5301 : loss : 0.026335, loss_ce: 0.006740
2022-01-08 18:48:06,873 iteration 5302 : loss : 0.014717, loss_ce: 0.005919
2022-01-08 18:48:09,233 iteration 5303 : loss : 0.014344, loss_ce: 0.006679
2022-01-08 18:48:11,684 iteration 5304 : loss : 0.015297, loss_ce: 0.007571
 78%|█████████████████████      | 312/400 [3:48:18<1:05:46, 44.85s/it]2022-01-08 18:48:14,106 iteration 5305 : loss : 0.009007, loss_ce: 0.003262
2022-01-08 18:48:16,613 iteration 5306 : loss : 0.022098, loss_ce: 0.009021
2022-01-08 18:48:19,018 iteration 5307 : loss : 0.015380, loss_ce: 0.005492
2022-01-08 18:48:21,500 iteration 5308 : loss : 0.011523, loss_ce: 0.003752
2022-01-08 18:48:23,998 iteration 5309 : loss : 0.016419, loss_ce: 0.008080
2022-01-08 18:48:26,490 iteration 5310 : loss : 0.015990, loss_ce: 0.004875
2022-01-08 18:48:28,899 iteration 5311 : loss : 0.016738, loss_ce: 0.005961
2022-01-08 18:48:31,375 iteration 5312 : loss : 0.019520, loss_ce: 0.009044
2022-01-08 18:48:33,789 iteration 5313 : loss : 0.015768, loss_ce: 0.007728
2022-01-08 18:48:36,225 iteration 5314 : loss : 0.014069, loss_ce: 0.004570
2022-01-08 18:48:38,701 iteration 5315 : loss : 0.015825, loss_ce: 0.005671
2022-01-08 18:48:41,161 iteration 5316 : loss : 0.012330, loss_ce: 0.003495
2022-01-08 18:48:43,615 iteration 5317 : loss : 0.015792, loss_ce: 0.005157
2022-01-08 18:48:46,049 iteration 5318 : loss : 0.017913, loss_ce: 0.006729
2022-01-08 18:48:48,476 iteration 5319 : loss : 0.018710, loss_ce: 0.006174
2022-01-08 18:48:50,807 iteration 5320 : loss : 0.012040, loss_ce: 0.004264
2022-01-08 18:48:53,226 iteration 5321 : loss : 0.016884, loss_ce: 0.007356
 78%|█████████████████████▏     | 313/400 [3:49:00<1:03:35, 43.86s/it]2022-01-08 18:48:55,700 iteration 5322 : loss : 0.015656, loss_ce: 0.005556
2022-01-08 18:48:58,140 iteration 5323 : loss : 0.027136, loss_ce: 0.007866
2022-01-08 18:49:00,663 iteration 5324 : loss : 0.021880, loss_ce: 0.008762
2022-01-08 18:49:03,100 iteration 5325 : loss : 0.016203, loss_ce: 0.005958
2022-01-08 18:49:05,494 iteration 5326 : loss : 0.016629, loss_ce: 0.005328
2022-01-08 18:49:08,036 iteration 5327 : loss : 0.012857, loss_ce: 0.005073
2022-01-08 18:49:10,452 iteration 5328 : loss : 0.010313, loss_ce: 0.003582
2022-01-08 18:49:12,875 iteration 5329 : loss : 0.017436, loss_ce: 0.008789
2022-01-08 18:49:15,413 iteration 5330 : loss : 0.015163, loss_ce: 0.004837
2022-01-08 18:49:18,007 iteration 5331 : loss : 0.014441, loss_ce: 0.005583
2022-01-08 18:49:20,385 iteration 5332 : loss : 0.016005, loss_ce: 0.006349
2022-01-08 18:49:22,725 iteration 5333 : loss : 0.018843, loss_ce: 0.006045
2022-01-08 18:49:25,222 iteration 5334 : loss : 0.016834, loss_ce: 0.004992
2022-01-08 18:49:27,690 iteration 5335 : loss : 0.021154, loss_ce: 0.006838
2022-01-08 18:49:30,124 iteration 5336 : loss : 0.018558, loss_ce: 0.006652
2022-01-08 18:49:32,495 iteration 5337 : loss : 0.011958, loss_ce: 0.004145
2022-01-08 18:49:34,799 iteration 5338 : loss : 0.011074, loss_ce: 0.004206
 78%|█████████████████████▏     | 314/400 [3:49:41<1:01:52, 43.17s/it]2022-01-08 18:49:37,293 iteration 5339 : loss : 0.013600, loss_ce: 0.004801
2022-01-08 18:49:39,714 iteration 5340 : loss : 0.014395, loss_ce: 0.009472
2022-01-08 18:49:42,332 iteration 5341 : loss : 0.014985, loss_ce: 0.005909
2022-01-08 18:49:44,795 iteration 5342 : loss : 0.027625, loss_ce: 0.008659
2022-01-08 18:49:47,316 iteration 5343 : loss : 0.015701, loss_ce: 0.005343
2022-01-08 18:49:49,700 iteration 5344 : loss : 0.019216, loss_ce: 0.009748
2022-01-08 18:49:52,012 iteration 5345 : loss : 0.019493, loss_ce: 0.005583
2022-01-08 18:49:54,608 iteration 5346 : loss : 0.018435, loss_ce: 0.006301
2022-01-08 18:49:57,227 iteration 5347 : loss : 0.020788, loss_ce: 0.010612
2022-01-08 18:49:59,634 iteration 5348 : loss : 0.019153, loss_ce: 0.009215
2022-01-08 18:50:02,056 iteration 5349 : loss : 0.013279, loss_ce: 0.005374
2022-01-08 18:50:04,408 iteration 5350 : loss : 0.010624, loss_ce: 0.003823
2022-01-08 18:50:06,804 iteration 5351 : loss : 0.020214, loss_ce: 0.003396
2022-01-08 18:50:09,333 iteration 5352 : loss : 0.020101, loss_ce: 0.006877
2022-01-08 18:50:11,763 iteration 5353 : loss : 0.026490, loss_ce: 0.013210
2022-01-08 18:50:14,134 iteration 5354 : loss : 0.021921, loss_ce: 0.008259
2022-01-08 18:50:14,134 Training Data Eval:
2022-01-08 18:50:27,134   Average segmentation loss on training set: 0.0097
2022-01-08 18:50:27,135 Validation Data Eval:
2022-01-08 18:50:31,894   Average segmentation loss on validation set: 0.0835
2022-01-08 18:50:34,247 iteration 5355 : loss : 0.011914, loss_ce: 0.004586
 79%|█████████████████████▎     | 315/400 [3:50:41<1:08:04, 48.06s/it]2022-01-08 18:50:36,749 iteration 5356 : loss : 0.032920, loss_ce: 0.013564
2022-01-08 18:50:39,116 iteration 5357 : loss : 0.010280, loss_ce: 0.002981
2022-01-08 18:50:41,603 iteration 5358 : loss : 0.013329, loss_ce: 0.003519
2022-01-08 18:50:43,976 iteration 5359 : loss : 0.015728, loss_ce: 0.009059
2022-01-08 18:50:46,509 iteration 5360 : loss : 0.013411, loss_ce: 0.004661
2022-01-08 18:50:49,080 iteration 5361 : loss : 0.019528, loss_ce: 0.005893
2022-01-08 18:50:51,516 iteration 5362 : loss : 0.016853, loss_ce: 0.009621
2022-01-08 18:50:53,910 iteration 5363 : loss : 0.016340, loss_ce: 0.006227
2022-01-08 18:50:56,268 iteration 5364 : loss : 0.017055, loss_ce: 0.002503
2022-01-08 18:50:58,698 iteration 5365 : loss : 0.017140, loss_ce: 0.006185
2022-01-08 18:51:01,094 iteration 5366 : loss : 0.016498, loss_ce: 0.005552
2022-01-08 18:51:03,557 iteration 5367 : loss : 0.023181, loss_ce: 0.006367
2022-01-08 18:51:06,031 iteration 5368 : loss : 0.016029, loss_ce: 0.005924
2022-01-08 18:51:08,560 iteration 5369 : loss : 0.019015, loss_ce: 0.008024
2022-01-08 18:51:11,084 iteration 5370 : loss : 0.017151, loss_ce: 0.005093
2022-01-08 18:51:13,541 iteration 5371 : loss : 0.015924, loss_ce: 0.004024
2022-01-08 18:51:15,990 iteration 5372 : loss : 0.022127, loss_ce: 0.008989
 79%|█████████████████████▎     | 316/400 [3:51:22<1:04:37, 46.16s/it]2022-01-08 18:51:18,387 iteration 5373 : loss : 0.011853, loss_ce: 0.005047
2022-01-08 18:51:20,938 iteration 5374 : loss : 0.021601, loss_ce: 0.006320
2022-01-08 18:51:23,390 iteration 5375 : loss : 0.013956, loss_ce: 0.004891
2022-01-08 18:51:25,817 iteration 5376 : loss : 0.012914, loss_ce: 0.004004
2022-01-08 18:51:28,164 iteration 5377 : loss : 0.014195, loss_ce: 0.001966
2022-01-08 18:51:30,495 iteration 5378 : loss : 0.010417, loss_ce: 0.003992
2022-01-08 18:51:32,969 iteration 5379 : loss : 0.013923, loss_ce: 0.004351
2022-01-08 18:51:35,377 iteration 5380 : loss : 0.013013, loss_ce: 0.005485
2022-01-08 18:51:37,917 iteration 5381 : loss : 0.017607, loss_ce: 0.007835
2022-01-08 18:51:40,547 iteration 5382 : loss : 0.020255, loss_ce: 0.006657
2022-01-08 18:51:42,975 iteration 5383 : loss : 0.017255, loss_ce: 0.006089
2022-01-08 18:51:45,445 iteration 5384 : loss : 0.014626, loss_ce: 0.006934
2022-01-08 18:51:47,970 iteration 5385 : loss : 0.016092, loss_ce: 0.006702
2022-01-08 18:51:50,393 iteration 5386 : loss : 0.012170, loss_ce: 0.004469
2022-01-08 18:51:52,747 iteration 5387 : loss : 0.019996, loss_ce: 0.009771
2022-01-08 18:51:55,172 iteration 5388 : loss : 0.013200, loss_ce: 0.005182
2022-01-08 18:51:57,558 iteration 5389 : loss : 0.011423, loss_ce: 0.003821
 79%|█████████████████████▍     | 317/400 [3:52:04<1:01:56, 44.78s/it]2022-01-08 18:52:00,033 iteration 5390 : loss : 0.018918, loss_ce: 0.005848
2022-01-08 18:52:02,375 iteration 5391 : loss : 0.012663, loss_ce: 0.004311
2022-01-08 18:52:04,919 iteration 5392 : loss : 0.015041, loss_ce: 0.006070
2022-01-08 18:52:07,409 iteration 5393 : loss : 0.034012, loss_ce: 0.009412
2022-01-08 18:52:09,867 iteration 5394 : loss : 0.013454, loss_ce: 0.005492
2022-01-08 18:52:12,219 iteration 5395 : loss : 0.012751, loss_ce: 0.005893
2022-01-08 18:52:14,712 iteration 5396 : loss : 0.018426, loss_ce: 0.005347
2022-01-08 18:52:17,181 iteration 5397 : loss : 0.020490, loss_ce: 0.007558
2022-01-08 18:52:19,672 iteration 5398 : loss : 0.010722, loss_ce: 0.005190
2022-01-08 18:52:22,054 iteration 5399 : loss : 0.012968, loss_ce: 0.005867
2022-01-08 18:52:24,511 iteration 5400 : loss : 0.019776, loss_ce: 0.005596
2022-01-08 18:52:26,937 iteration 5401 : loss : 0.015137, loss_ce: 0.005132
2022-01-08 18:52:29,374 iteration 5402 : loss : 0.011779, loss_ce: 0.004052
2022-01-08 18:52:31,809 iteration 5403 : loss : 0.026038, loss_ce: 0.007127
2022-01-08 18:52:34,223 iteration 5404 : loss : 0.013914, loss_ce: 0.006673
2022-01-08 18:52:36,606 iteration 5405 : loss : 0.010826, loss_ce: 0.003361
2022-01-08 18:52:38,960 iteration 5406 : loss : 0.014343, loss_ce: 0.003411
 80%|███████████████████████      | 318/400 [3:52:45<59:48, 43.77s/it]2022-01-08 18:52:41,613 iteration 5407 : loss : 0.012519, loss_ce: 0.003751
2022-01-08 18:52:44,033 iteration 5408 : loss : 0.013862, loss_ce: 0.003797
2022-01-08 18:52:46,563 iteration 5409 : loss : 0.011920, loss_ce: 0.005769
2022-01-08 18:52:49,035 iteration 5410 : loss : 0.016140, loss_ce: 0.004672
2022-01-08 18:52:51,433 iteration 5411 : loss : 0.016422, loss_ce: 0.005680
2022-01-08 18:52:53,853 iteration 5412 : loss : 0.029335, loss_ce: 0.015112
2022-01-08 18:52:56,249 iteration 5413 : loss : 0.012806, loss_ce: 0.004667
2022-01-08 18:52:58,674 iteration 5414 : loss : 0.017765, loss_ce: 0.006724
2022-01-08 18:53:01,122 iteration 5415 : loss : 0.015822, loss_ce: 0.005622
2022-01-08 18:53:03,710 iteration 5416 : loss : 0.014690, loss_ce: 0.006258
2022-01-08 18:53:06,093 iteration 5417 : loss : 0.015300, loss_ce: 0.005721
2022-01-08 18:53:08,612 iteration 5418 : loss : 0.011269, loss_ce: 0.003448
2022-01-08 18:53:11,042 iteration 5419 : loss : 0.014349, loss_ce: 0.007192
2022-01-08 18:53:13,506 iteration 5420 : loss : 0.012800, loss_ce: 0.005924
2022-01-08 18:53:16,191 iteration 5421 : loss : 0.017455, loss_ce: 0.005392
2022-01-08 18:53:18,614 iteration 5422 : loss : 0.016215, loss_ce: 0.005549
2022-01-08 18:53:21,032 iteration 5423 : loss : 0.020719, loss_ce: 0.006072
 80%|███████████████████████▏     | 319/400 [3:53:27<58:23, 43.25s/it]2022-01-08 18:53:23,454 iteration 5424 : loss : 0.021361, loss_ce: 0.007853
2022-01-08 18:53:26,004 iteration 5425 : loss : 0.016536, loss_ce: 0.006371
2022-01-08 18:53:28,414 iteration 5426 : loss : 0.015129, loss_ce: 0.004193
2022-01-08 18:53:31,057 iteration 5427 : loss : 0.016411, loss_ce: 0.006582
2022-01-08 18:53:33,509 iteration 5428 : loss : 0.037467, loss_ce: 0.018057
2022-01-08 18:53:35,955 iteration 5429 : loss : 0.011270, loss_ce: 0.004724
2022-01-08 18:53:38,326 iteration 5430 : loss : 0.010385, loss_ce: 0.004317
2022-01-08 18:53:40,842 iteration 5431 : loss : 0.018974, loss_ce: 0.006852
2022-01-08 18:53:43,269 iteration 5432 : loss : 0.015323, loss_ce: 0.005355
2022-01-08 18:53:45,892 iteration 5433 : loss : 0.024397, loss_ce: 0.008308
2022-01-08 18:53:48,390 iteration 5434 : loss : 0.021446, loss_ce: 0.006953
2022-01-08 18:53:50,800 iteration 5435 : loss : 0.014341, loss_ce: 0.005490
2022-01-08 18:53:53,296 iteration 5436 : loss : 0.017040, loss_ce: 0.007705
2022-01-08 18:53:55,738 iteration 5437 : loss : 0.017404, loss_ce: 0.004263
2022-01-08 18:53:58,227 iteration 5438 : loss : 0.015162, loss_ce: 0.006832
2022-01-08 18:54:00,634 iteration 5439 : loss : 0.025221, loss_ce: 0.008121
2022-01-08 18:54:00,635 Training Data Eval:
2022-01-08 18:54:13,827   Average segmentation loss on training set: 0.0100
2022-01-08 18:54:13,827 Validation Data Eval:
2022-01-08 18:54:18,493   Average segmentation loss on validation set: 0.0781
2022-01-08 18:54:20,986 iteration 5440 : loss : 0.015543, loss_ce: 0.006152
 80%|█████████████████████▌     | 320/400 [3:54:27<1:04:21, 48.27s/it]2022-01-08 18:54:23,424 iteration 5441 : loss : 0.013249, loss_ce: 0.005535
2022-01-08 18:54:25,924 iteration 5442 : loss : 0.022692, loss_ce: 0.008019
2022-01-08 18:54:28,502 iteration 5443 : loss : 0.024096, loss_ce: 0.008161
2022-01-08 18:54:30,971 iteration 5444 : loss : 0.012294, loss_ce: 0.005385
2022-01-08 18:54:33,426 iteration 5445 : loss : 0.014915, loss_ce: 0.006248
2022-01-08 18:54:35,887 iteration 5446 : loss : 0.015384, loss_ce: 0.006412
2022-01-08 18:54:38,227 iteration 5447 : loss : 0.014403, loss_ce: 0.002373
2022-01-08 18:54:40,678 iteration 5448 : loss : 0.018423, loss_ce: 0.005926
2022-01-08 18:54:43,174 iteration 5449 : loss : 0.013480, loss_ce: 0.004316
2022-01-08 18:54:45,502 iteration 5450 : loss : 0.019119, loss_ce: 0.005718
2022-01-08 18:54:47,936 iteration 5451 : loss : 0.010087, loss_ce: 0.002691
2022-01-08 18:54:50,414 iteration 5452 : loss : 0.011904, loss_ce: 0.004332
2022-01-08 18:54:52,902 iteration 5453 : loss : 0.017220, loss_ce: 0.006068
2022-01-08 18:54:55,354 iteration 5454 : loss : 0.019018, loss_ce: 0.008129
2022-01-08 18:54:57,803 iteration 5455 : loss : 0.014655, loss_ce: 0.007350
2022-01-08 18:55:00,268 iteration 5456 : loss : 0.014155, loss_ce: 0.004882
2022-01-08 18:55:02,753 iteration 5457 : loss : 0.014143, loss_ce: 0.005714
 80%|█████████████████████▋     | 321/400 [3:55:09<1:00:58, 46.32s/it]2022-01-08 18:55:05,391 iteration 5458 : loss : 0.018525, loss_ce: 0.005176
2022-01-08 18:55:07,807 iteration 5459 : loss : 0.013129, loss_ce: 0.004882
2022-01-08 18:55:10,303 iteration 5460 : loss : 0.020196, loss_ce: 0.007919
2022-01-08 18:55:12,717 iteration 5461 : loss : 0.017663, loss_ce: 0.006750
2022-01-08 18:55:15,227 iteration 5462 : loss : 0.018438, loss_ce: 0.008569
2022-01-08 18:55:17,691 iteration 5463 : loss : 0.011265, loss_ce: 0.003622
2022-01-08 18:55:20,204 iteration 5464 : loss : 0.021725, loss_ce: 0.007553
2022-01-08 18:55:22,608 iteration 5465 : loss : 0.023221, loss_ce: 0.008788
2022-01-08 18:55:25,030 iteration 5466 : loss : 0.013002, loss_ce: 0.004526
2022-01-08 18:55:27,655 iteration 5467 : loss : 0.013991, loss_ce: 0.004580
2022-01-08 18:55:30,179 iteration 5468 : loss : 0.015987, loss_ce: 0.007384
2022-01-08 18:55:32,628 iteration 5469 : loss : 0.023416, loss_ce: 0.009843
2022-01-08 18:55:35,066 iteration 5470 : loss : 0.014895, loss_ce: 0.006471
2022-01-08 18:55:37,488 iteration 5471 : loss : 0.012137, loss_ce: 0.005796
2022-01-08 18:55:40,072 iteration 5472 : loss : 0.017155, loss_ce: 0.007465
2022-01-08 18:55:42,564 iteration 5473 : loss : 0.012622, loss_ce: 0.003523
2022-01-08 18:55:45,007 iteration 5474 : loss : 0.014661, loss_ce: 0.004093
 80%|███████████████████████▎     | 322/400 [3:55:51<58:37, 45.10s/it]2022-01-08 18:55:47,523 iteration 5475 : loss : 0.015053, loss_ce: 0.005435
2022-01-08 18:55:50,056 iteration 5476 : loss : 0.012126, loss_ce: 0.005383
2022-01-08 18:55:52,499 iteration 5477 : loss : 0.011427, loss_ce: 0.003992
2022-01-08 18:55:54,937 iteration 5478 : loss : 0.019790, loss_ce: 0.007888
2022-01-08 18:55:57,344 iteration 5479 : loss : 0.020183, loss_ce: 0.005599
2022-01-08 18:55:59,800 iteration 5480 : loss : 0.018433, loss_ce: 0.004280
2022-01-08 18:56:02,356 iteration 5481 : loss : 0.015914, loss_ce: 0.006330
2022-01-08 18:56:04,778 iteration 5482 : loss : 0.015637, loss_ce: 0.005823
2022-01-08 18:56:07,253 iteration 5483 : loss : 0.016110, loss_ce: 0.005607
2022-01-08 18:56:09,688 iteration 5484 : loss : 0.024166, loss_ce: 0.009606
2022-01-08 18:56:12,058 iteration 5485 : loss : 0.013862, loss_ce: 0.006471
2022-01-08 18:56:14,770 iteration 5486 : loss : 0.021790, loss_ce: 0.006505
2022-01-08 18:56:17,169 iteration 5487 : loss : 0.014061, loss_ce: 0.007278
2022-01-08 18:56:19,586 iteration 5488 : loss : 0.021756, loss_ce: 0.005996
2022-01-08 18:56:21,983 iteration 5489 : loss : 0.015370, loss_ce: 0.003744
2022-01-08 18:56:24,437 iteration 5490 : loss : 0.014761, loss_ce: 0.005402
2022-01-08 18:56:26,938 iteration 5491 : loss : 0.013068, loss_ce: 0.004655
 81%|███████████████████████▍     | 323/400 [3:56:33<56:39, 44.15s/it]2022-01-08 18:56:29,537 iteration 5492 : loss : 0.016872, loss_ce: 0.008355
2022-01-08 18:56:31,926 iteration 5493 : loss : 0.013237, loss_ce: 0.004299
2022-01-08 18:56:34,274 iteration 5494 : loss : 0.013173, loss_ce: 0.006088
2022-01-08 18:56:36,886 iteration 5495 : loss : 0.023605, loss_ce: 0.004740
2022-01-08 18:56:39,287 iteration 5496 : loss : 0.011953, loss_ce: 0.003613
2022-01-08 18:56:41,846 iteration 5497 : loss : 0.013690, loss_ce: 0.005883
2022-01-08 18:56:44,271 iteration 5498 : loss : 0.014901, loss_ce: 0.006262
2022-01-08 18:56:46,724 iteration 5499 : loss : 0.014094, loss_ce: 0.004645
2022-01-08 18:56:49,199 iteration 5500 : loss : 0.011173, loss_ce: 0.003721
2022-01-08 18:56:51,610 iteration 5501 : loss : 0.010911, loss_ce: 0.003908
2022-01-08 18:56:54,120 iteration 5502 : loss : 0.013071, loss_ce: 0.005999
2022-01-08 18:56:56,640 iteration 5503 : loss : 0.018551, loss_ce: 0.004905
2022-01-08 18:56:59,111 iteration 5504 : loss : 0.016449, loss_ce: 0.007313
2022-01-08 18:57:01,501 iteration 5505 : loss : 0.012689, loss_ce: 0.004375
2022-01-08 18:57:03,915 iteration 5506 : loss : 0.011813, loss_ce: 0.004443
2022-01-08 18:57:06,613 iteration 5507 : loss : 0.026565, loss_ce: 0.010414
2022-01-08 18:57:09,174 iteration 5508 : loss : 0.019208, loss_ce: 0.010137
 81%|███████████████████████▍     | 324/400 [3:57:16<55:11, 43.57s/it]2022-01-08 18:57:11,635 iteration 5509 : loss : 0.017363, loss_ce: 0.007411
2022-01-08 18:57:14,020 iteration 5510 : loss : 0.014334, loss_ce: 0.005394
2022-01-08 18:57:16,451 iteration 5511 : loss : 0.021432, loss_ce: 0.006742
2022-01-08 18:57:18,955 iteration 5512 : loss : 0.021747, loss_ce: 0.009186
2022-01-08 18:57:21,404 iteration 5513 : loss : 0.013593, loss_ce: 0.007676
2022-01-08 18:57:23,837 iteration 5514 : loss : 0.029619, loss_ce: 0.013884
2022-01-08 18:57:26,251 iteration 5515 : loss : 0.017070, loss_ce: 0.007655
2022-01-08 18:57:28,683 iteration 5516 : loss : 0.011610, loss_ce: 0.005490
2022-01-08 18:57:31,174 iteration 5517 : loss : 0.014597, loss_ce: 0.004712
2022-01-08 18:57:33,651 iteration 5518 : loss : 0.011773, loss_ce: 0.003923
2022-01-08 18:57:36,113 iteration 5519 : loss : 0.022447, loss_ce: 0.006312
2022-01-08 18:57:38,534 iteration 5520 : loss : 0.014384, loss_ce: 0.002604
2022-01-08 18:57:41,005 iteration 5521 : loss : 0.017283, loss_ce: 0.007047
2022-01-08 18:57:43,648 iteration 5522 : loss : 0.015112, loss_ce: 0.005643
2022-01-08 18:57:46,084 iteration 5523 : loss : 0.023006, loss_ce: 0.008812
2022-01-08 18:57:48,460 iteration 5524 : loss : 0.019247, loss_ce: 0.006708
2022-01-08 18:57:48,460 Training Data Eval:
2022-01-08 18:58:01,699   Average segmentation loss on training set: 0.0085
2022-01-08 18:58:01,700 Validation Data Eval:
2022-01-08 18:58:06,327   Average segmentation loss on validation set: 0.0769
2022-01-08 18:58:08,940 iteration 5525 : loss : 0.014911, loss_ce: 0.006628
 81%|█████████████████████▉     | 325/400 [3:58:15<1:00:32, 48.43s/it]2022-01-08 18:58:11,359 iteration 5526 : loss : 0.019683, loss_ce: 0.005920
2022-01-08 18:58:13,686 iteration 5527 : loss : 0.013728, loss_ce: 0.005561
2022-01-08 18:58:16,140 iteration 5528 : loss : 0.021519, loss_ce: 0.006650
2022-01-08 18:58:18,723 iteration 5529 : loss : 0.012428, loss_ce: 0.004476
2022-01-08 18:58:21,117 iteration 5530 : loss : 0.011321, loss_ce: 0.004428
2022-01-08 18:58:23,466 iteration 5531 : loss : 0.010600, loss_ce: 0.003138
2022-01-08 18:58:25,842 iteration 5532 : loss : 0.018186, loss_ce: 0.007009
2022-01-08 18:58:28,348 iteration 5533 : loss : 0.012119, loss_ce: 0.005538
2022-01-08 18:58:30,687 iteration 5534 : loss : 0.010294, loss_ce: 0.003750
2022-01-08 18:58:33,165 iteration 5535 : loss : 0.012708, loss_ce: 0.005200
2022-01-08 18:58:35,587 iteration 5536 : loss : 0.015889, loss_ce: 0.005005
2022-01-08 18:58:38,145 iteration 5537 : loss : 0.022014, loss_ce: 0.009534
2022-01-08 18:58:40,770 iteration 5538 : loss : 0.014183, loss_ce: 0.003657
2022-01-08 18:58:43,158 iteration 5539 : loss : 0.012352, loss_ce: 0.004543
2022-01-08 18:58:45,547 iteration 5540 : loss : 0.015057, loss_ce: 0.005879
2022-01-08 18:58:48,200 iteration 5541 : loss : 0.023716, loss_ce: 0.010224
2022-01-08 18:58:50,599 iteration 5542 : loss : 0.028367, loss_ce: 0.010296
 82%|███████████████████████▋     | 326/400 [3:58:57<57:13, 46.40s/it]2022-01-08 18:58:53,076 iteration 5543 : loss : 0.017381, loss_ce: 0.007839
2022-01-08 18:58:55,516 iteration 5544 : loss : 0.011085, loss_ce: 0.003718
2022-01-08 18:58:57,942 iteration 5545 : loss : 0.017121, loss_ce: 0.007125
2022-01-08 18:59:00,415 iteration 5546 : loss : 0.027217, loss_ce: 0.005975
2022-01-08 18:59:02,991 iteration 5547 : loss : 0.018657, loss_ce: 0.007031
2022-01-08 18:59:05,553 iteration 5548 : loss : 0.015841, loss_ce: 0.003545
2022-01-08 18:59:07,985 iteration 5549 : loss : 0.011992, loss_ce: 0.003184
2022-01-08 18:59:10,576 iteration 5550 : loss : 0.012564, loss_ce: 0.004716
2022-01-08 18:59:12,957 iteration 5551 : loss : 0.022270, loss_ce: 0.011228
2022-01-08 18:59:15,298 iteration 5552 : loss : 0.011861, loss_ce: 0.003911
2022-01-08 18:59:17,781 iteration 5553 : loss : 0.015380, loss_ce: 0.005796
2022-01-08 18:59:20,179 iteration 5554 : loss : 0.014445, loss_ce: 0.006182
2022-01-08 18:59:22,655 iteration 5555 : loss : 0.012985, loss_ce: 0.005673
2022-01-08 18:59:25,104 iteration 5556 : loss : 0.018317, loss_ce: 0.007079
2022-01-08 18:59:27,611 iteration 5557 : loss : 0.017609, loss_ce: 0.009403
2022-01-08 18:59:30,179 iteration 5558 : loss : 0.024287, loss_ce: 0.010412
2022-01-08 18:59:32,636 iteration 5559 : loss : 0.018373, loss_ce: 0.005715
 82%|███████████████████████▋     | 327/400 [3:59:39<54:51, 45.09s/it]2022-01-08 18:59:35,154 iteration 5560 : loss : 0.017431, loss_ce: 0.005520
2022-01-08 18:59:37,540 iteration 5561 : loss : 0.021316, loss_ce: 0.007464
2022-01-08 18:59:40,087 iteration 5562 : loss : 0.012995, loss_ce: 0.006006
2022-01-08 18:59:42,519 iteration 5563 : loss : 0.015634, loss_ce: 0.006744
2022-01-08 18:59:45,063 iteration 5564 : loss : 0.015992, loss_ce: 0.007565
2022-01-08 18:59:47,628 iteration 5565 : loss : 0.014121, loss_ce: 0.006039
2022-01-08 18:59:50,010 iteration 5566 : loss : 0.023010, loss_ce: 0.014634
2022-01-08 18:59:52,465 iteration 5567 : loss : 0.015346, loss_ce: 0.007648
2022-01-08 18:59:54,882 iteration 5568 : loss : 0.019759, loss_ce: 0.006842
2022-01-08 18:59:57,400 iteration 5569 : loss : 0.024553, loss_ce: 0.012845
2022-01-08 18:59:59,892 iteration 5570 : loss : 0.011794, loss_ce: 0.003551
2022-01-08 19:00:02,261 iteration 5571 : loss : 0.011654, loss_ce: 0.004487
2022-01-08 19:00:04,615 iteration 5572 : loss : 0.015493, loss_ce: 0.005538
2022-01-08 19:00:07,028 iteration 5573 : loss : 0.009856, loss_ce: 0.002964
2022-01-08 19:00:09,466 iteration 5574 : loss : 0.013756, loss_ce: 0.004510
2022-01-08 19:00:12,163 iteration 5575 : loss : 0.026653, loss_ce: 0.008736
2022-01-08 19:00:14,636 iteration 5576 : loss : 0.016836, loss_ce: 0.005888
 82%|███████████████████████▊     | 328/400 [4:00:21<52:59, 44.16s/it]2022-01-08 19:00:17,276 iteration 5577 : loss : 0.013449, loss_ce: 0.005667
2022-01-08 19:00:19,697 iteration 5578 : loss : 0.016979, loss_ce: 0.006748
2022-01-08 19:00:22,159 iteration 5579 : loss : 0.014436, loss_ce: 0.006234
2022-01-08 19:00:24,648 iteration 5580 : loss : 0.017513, loss_ce: 0.006644
2022-01-08 19:00:27,049 iteration 5581 : loss : 0.011606, loss_ce: 0.004677
2022-01-08 19:00:29,595 iteration 5582 : loss : 0.010815, loss_ce: 0.003080
2022-01-08 19:00:32,033 iteration 5583 : loss : 0.009299, loss_ce: 0.003421
2022-01-08 19:00:34,502 iteration 5584 : loss : 0.019776, loss_ce: 0.008690
2022-01-08 19:00:37,033 iteration 5585 : loss : 0.014280, loss_ce: 0.003924
2022-01-08 19:00:39,632 iteration 5586 : loss : 0.020782, loss_ce: 0.006169
2022-01-08 19:00:41,992 iteration 5587 : loss : 0.014553, loss_ce: 0.005040
2022-01-08 19:00:44,365 iteration 5588 : loss : 0.012415, loss_ce: 0.004723
2022-01-08 19:00:46,766 iteration 5589 : loss : 0.012669, loss_ce: 0.004169
2022-01-08 19:00:49,381 iteration 5590 : loss : 0.010906, loss_ce: 0.002863
2022-01-08 19:00:51,765 iteration 5591 : loss : 0.012821, loss_ce: 0.005186
2022-01-08 19:00:54,247 iteration 5592 : loss : 0.017301, loss_ce: 0.005511
2022-01-08 19:00:56,812 iteration 5593 : loss : 0.020954, loss_ce: 0.008856
 82%|███████████████████████▊     | 329/400 [4:01:03<51:33, 43.57s/it]2022-01-08 19:00:59,241 iteration 5594 : loss : 0.014419, loss_ce: 0.004197
2022-01-08 19:01:01,666 iteration 5595 : loss : 0.017916, loss_ce: 0.008324
2022-01-08 19:01:04,154 iteration 5596 : loss : 0.030849, loss_ce: 0.014383
2022-01-08 19:01:06,584 iteration 5597 : loss : 0.011834, loss_ce: 0.004549
2022-01-08 19:01:09,074 iteration 5598 : loss : 0.010789, loss_ce: 0.004359
2022-01-08 19:01:11,481 iteration 5599 : loss : 0.016019, loss_ce: 0.007039
2022-01-08 19:01:13,834 iteration 5600 : loss : 0.011370, loss_ce: 0.004353
2022-01-08 19:01:16,350 iteration 5601 : loss : 0.010668, loss_ce: 0.004275
2022-01-08 19:01:18,775 iteration 5602 : loss : 0.012876, loss_ce: 0.005275
2022-01-08 19:01:21,249 iteration 5603 : loss : 0.009924, loss_ce: 0.003975
2022-01-08 19:01:23,653 iteration 5604 : loss : 0.015273, loss_ce: 0.003603
2022-01-08 19:01:26,147 iteration 5605 : loss : 0.019407, loss_ce: 0.008334
2022-01-08 19:01:28,778 iteration 5606 : loss : 0.014073, loss_ce: 0.004477
2022-01-08 19:01:31,194 iteration 5607 : loss : 0.016045, loss_ce: 0.004958
2022-01-08 19:01:33,577 iteration 5608 : loss : 0.012532, loss_ce: 0.003994
2022-01-08 19:01:36,169 iteration 5609 : loss : 0.013118, loss_ce: 0.005772
2022-01-08 19:01:36,169 Training Data Eval:
2022-01-08 19:01:49,182   Average segmentation loss on training set: 0.0083
2022-01-08 19:01:49,182 Validation Data Eval:
2022-01-08 19:01:53,675   Average segmentation loss on validation set: 0.0765
2022-01-08 19:01:56,100 iteration 5610 : loss : 0.012191, loss_ce: 0.003952
 82%|███████████████████████▉     | 330/400 [4:02:02<56:19, 48.28s/it]2022-01-08 19:01:58,681 iteration 5611 : loss : 0.027492, loss_ce: 0.008919
2022-01-08 19:02:01,274 iteration 5612 : loss : 0.028490, loss_ce: 0.005088
2022-01-08 19:02:03,686 iteration 5613 : loss : 0.012412, loss_ce: 0.004902
2022-01-08 19:02:06,043 iteration 5614 : loss : 0.014164, loss_ce: 0.005459
2022-01-08 19:02:08,470 iteration 5615 : loss : 0.009044, loss_ce: 0.003890
2022-01-08 19:02:10,871 iteration 5616 : loss : 0.013691, loss_ce: 0.005857
2022-01-08 19:02:13,427 iteration 5617 : loss : 0.012381, loss_ce: 0.004702
2022-01-08 19:02:15,826 iteration 5618 : loss : 0.014216, loss_ce: 0.005777
2022-01-08 19:02:18,252 iteration 5619 : loss : 0.016022, loss_ce: 0.004760
2022-01-08 19:02:20,686 iteration 5620 : loss : 0.012250, loss_ce: 0.004437
2022-01-08 19:02:23,073 iteration 5621 : loss : 0.013129, loss_ce: 0.004634
2022-01-08 19:02:25,484 iteration 5622 : loss : 0.014288, loss_ce: 0.004325
2022-01-08 19:02:27,943 iteration 5623 : loss : 0.019611, loss_ce: 0.006655
2022-01-08 19:02:30,461 iteration 5624 : loss : 0.013295, loss_ce: 0.003486
2022-01-08 19:02:32,812 iteration 5625 : loss : 0.014927, loss_ce: 0.006820
2022-01-08 19:02:35,327 iteration 5626 : loss : 0.015566, loss_ce: 0.004594
2022-01-08 19:02:37,737 iteration 5627 : loss : 0.013061, loss_ce: 0.005111
 83%|███████████████████████▉     | 331/400 [4:02:44<53:13, 46.29s/it]2022-01-08 19:02:40,439 iteration 5628 : loss : 0.018083, loss_ce: 0.008485
2022-01-08 19:02:42,816 iteration 5629 : loss : 0.011807, loss_ce: 0.004847
2022-01-08 19:02:45,266 iteration 5630 : loss : 0.014102, loss_ce: 0.005572
2022-01-08 19:02:47,648 iteration 5631 : loss : 0.015010, loss_ce: 0.006007
2022-01-08 19:02:50,268 iteration 5632 : loss : 0.013482, loss_ce: 0.005890
2022-01-08 19:02:52,720 iteration 5633 : loss : 0.021554, loss_ce: 0.006251
2022-01-08 19:02:55,224 iteration 5634 : loss : 0.010821, loss_ce: 0.004474
2022-01-08 19:02:57,588 iteration 5635 : loss : 0.012731, loss_ce: 0.004787
2022-01-08 19:02:59,931 iteration 5636 : loss : 0.015898, loss_ce: 0.003984
2022-01-08 19:03:02,345 iteration 5637 : loss : 0.014096, loss_ce: 0.004250
2022-01-08 19:03:04,767 iteration 5638 : loss : 0.019712, loss_ce: 0.009370
2022-01-08 19:03:07,317 iteration 5639 : loss : 0.011355, loss_ce: 0.003821
2022-01-08 19:03:09,732 iteration 5640 : loss : 0.014731, loss_ce: 0.005617
2022-01-08 19:03:12,082 iteration 5641 : loss : 0.018570, loss_ce: 0.004989
2022-01-08 19:03:14,556 iteration 5642 : loss : 0.011569, loss_ce: 0.003884
2022-01-08 19:03:16,914 iteration 5643 : loss : 0.013829, loss_ce: 0.005093
2022-01-08 19:03:19,366 iteration 5644 : loss : 0.010815, loss_ce: 0.004167
 83%|████████████████████████     | 332/400 [4:03:26<50:52, 44.89s/it]2022-01-08 19:03:21,825 iteration 5645 : loss : 0.017048, loss_ce: 0.005119
2022-01-08 19:03:24,259 iteration 5646 : loss : 0.009807, loss_ce: 0.002914
2022-01-08 19:03:26,703 iteration 5647 : loss : 0.011899, loss_ce: 0.003752
2022-01-08 19:03:29,110 iteration 5648 : loss : 0.015059, loss_ce: 0.005228
2022-01-08 19:03:31,652 iteration 5649 : loss : 0.015032, loss_ce: 0.005424
2022-01-08 19:03:34,079 iteration 5650 : loss : 0.018330, loss_ce: 0.005064
2022-01-08 19:03:36,474 iteration 5651 : loss : 0.012124, loss_ce: 0.006142
2022-01-08 19:03:38,992 iteration 5652 : loss : 0.012589, loss_ce: 0.005297
2022-01-08 19:03:41,378 iteration 5653 : loss : 0.016183, loss_ce: 0.007364
2022-01-08 19:03:43,861 iteration 5654 : loss : 0.012506, loss_ce: 0.005045
2022-01-08 19:03:46,231 iteration 5655 : loss : 0.018681, loss_ce: 0.006479
2022-01-08 19:03:48,713 iteration 5656 : loss : 0.016962, loss_ce: 0.007763
2022-01-08 19:03:51,106 iteration 5657 : loss : 0.015747, loss_ce: 0.007811
2022-01-08 19:03:53,687 iteration 5658 : loss : 0.022464, loss_ce: 0.007126
2022-01-08 19:03:56,159 iteration 5659 : loss : 0.015536, loss_ce: 0.006288
2022-01-08 19:03:58,623 iteration 5660 : loss : 0.011217, loss_ce: 0.004504
2022-01-08 19:04:01,179 iteration 5661 : loss : 0.017463, loss_ce: 0.006879
 83%|████████████████████████▏    | 333/400 [4:04:08<49:05, 43.97s/it]2022-01-08 19:04:03,559 iteration 5662 : loss : 0.013508, loss_ce: 0.005772
2022-01-08 19:04:05,997 iteration 5663 : loss : 0.013086, loss_ce: 0.005833
2022-01-08 19:04:08,497 iteration 5664 : loss : 0.017515, loss_ce: 0.005913
2022-01-08 19:04:10,895 iteration 5665 : loss : 0.010212, loss_ce: 0.002299
2022-01-08 19:04:13,359 iteration 5666 : loss : 0.012967, loss_ce: 0.004390
2022-01-08 19:04:15,765 iteration 5667 : loss : 0.014023, loss_ce: 0.004168
2022-01-08 19:04:18,310 iteration 5668 : loss : 0.020939, loss_ce: 0.006514
2022-01-08 19:04:20,812 iteration 5669 : loss : 0.025601, loss_ce: 0.015160
2022-01-08 19:04:23,295 iteration 5670 : loss : 0.013937, loss_ce: 0.004624
2022-01-08 19:04:25,763 iteration 5671 : loss : 0.022813, loss_ce: 0.005367
2022-01-08 19:04:28,173 iteration 5672 : loss : 0.012255, loss_ce: 0.003381
2022-01-08 19:04:30,608 iteration 5673 : loss : 0.011874, loss_ce: 0.005648
2022-01-08 19:04:33,009 iteration 5674 : loss : 0.013779, loss_ce: 0.004633
2022-01-08 19:04:35,494 iteration 5675 : loss : 0.021951, loss_ce: 0.008599
2022-01-08 19:04:37,947 iteration 5676 : loss : 0.018590, loss_ce: 0.009725
2022-01-08 19:04:40,504 iteration 5677 : loss : 0.015343, loss_ce: 0.005988
2022-01-08 19:04:42,925 iteration 5678 : loss : 0.016918, loss_ce: 0.007347
 84%|████████████████████████▏    | 334/400 [4:04:49<47:38, 43.30s/it]2022-01-08 19:04:45,385 iteration 5679 : loss : 0.019188, loss_ce: 0.007247
2022-01-08 19:04:47,832 iteration 5680 : loss : 0.011943, loss_ce: 0.005292
2022-01-08 19:04:50,276 iteration 5681 : loss : 0.016065, loss_ce: 0.004828
2022-01-08 19:04:52,606 iteration 5682 : loss : 0.012584, loss_ce: 0.004294
2022-01-08 19:04:55,067 iteration 5683 : loss : 0.009792, loss_ce: 0.004297
2022-01-08 19:04:57,676 iteration 5684 : loss : 0.014812, loss_ce: 0.008006
2022-01-08 19:05:00,082 iteration 5685 : loss : 0.015066, loss_ce: 0.004741
2022-01-08 19:05:02,500 iteration 5686 : loss : 0.012999, loss_ce: 0.004812
2022-01-08 19:05:04,953 iteration 5687 : loss : 0.012293, loss_ce: 0.003588
2022-01-08 19:05:07,413 iteration 5688 : loss : 0.028158, loss_ce: 0.010509
2022-01-08 19:05:09,855 iteration 5689 : loss : 0.013423, loss_ce: 0.005737
2022-01-08 19:05:12,239 iteration 5690 : loss : 0.010220, loss_ce: 0.003275
2022-01-08 19:05:14,727 iteration 5691 : loss : 0.011383, loss_ce: 0.004826
2022-01-08 19:05:17,261 iteration 5692 : loss : 0.009743, loss_ce: 0.002727
2022-01-08 19:05:19,595 iteration 5693 : loss : 0.011087, loss_ce: 0.004560
2022-01-08 19:05:22,067 iteration 5694 : loss : 0.016180, loss_ce: 0.005932
2022-01-08 19:05:22,067 Training Data Eval:
2022-01-08 19:05:35,378   Average segmentation loss on training set: 0.0082
2022-01-08 19:05:35,378 Validation Data Eval:
2022-01-08 19:05:39,860   Average segmentation loss on validation set: 0.0776
2022-01-08 19:05:42,298 iteration 5695 : loss : 0.014172, loss_ce: 0.005700
 84%|████████████████████████▎    | 335/400 [4:05:49<52:07, 48.12s/it]2022-01-08 19:05:44,793 iteration 5696 : loss : 0.018516, loss_ce: 0.005376
2022-01-08 19:05:47,244 iteration 5697 : loss : 0.012870, loss_ce: 0.004224
2022-01-08 19:05:49,911 iteration 5698 : loss : 0.017909, loss_ce: 0.006394
2022-01-08 19:05:52,358 iteration 5699 : loss : 0.015398, loss_ce: 0.004269
2022-01-08 19:05:54,668 iteration 5700 : loss : 0.010928, loss_ce: 0.004827
2022-01-08 19:05:57,144 iteration 5701 : loss : 0.019637, loss_ce: 0.003116
2022-01-08 19:05:59,660 iteration 5702 : loss : 0.015369, loss_ce: 0.005513
2022-01-08 19:06:02,099 iteration 5703 : loss : 0.019790, loss_ce: 0.010391
2022-01-08 19:06:04,455 iteration 5704 : loss : 0.013166, loss_ce: 0.006137
2022-01-08 19:06:06,993 iteration 5705 : loss : 0.013579, loss_ce: 0.006087
2022-01-08 19:06:09,342 iteration 5706 : loss : 0.013202, loss_ce: 0.004851
2022-01-08 19:06:11,822 iteration 5707 : loss : 0.014306, loss_ce: 0.003772
2022-01-08 19:06:14,284 iteration 5708 : loss : 0.013264, loss_ce: 0.006336
2022-01-08 19:06:16,649 iteration 5709 : loss : 0.012430, loss_ce: 0.004083
2022-01-08 19:06:19,227 iteration 5710 : loss : 0.015198, loss_ce: 0.007490
2022-01-08 19:06:21,644 iteration 5711 : loss : 0.011291, loss_ce: 0.005207
2022-01-08 19:06:24,164 iteration 5712 : loss : 0.013988, loss_ce: 0.005694
 84%|████████████████████████▎    | 336/400 [4:06:31<49:19, 46.25s/it]2022-01-08 19:06:26,765 iteration 5713 : loss : 0.010438, loss_ce: 0.004609
2022-01-08 19:06:29,172 iteration 5714 : loss : 0.015799, loss_ce: 0.004804
2022-01-08 19:06:31,683 iteration 5715 : loss : 0.014817, loss_ce: 0.005281
2022-01-08 19:06:34,131 iteration 5716 : loss : 0.017553, loss_ce: 0.006725
2022-01-08 19:06:36,611 iteration 5717 : loss : 0.008683, loss_ce: 0.003075
2022-01-08 19:06:39,011 iteration 5718 : loss : 0.014173, loss_ce: 0.006049
2022-01-08 19:06:41,504 iteration 5719 : loss : 0.015532, loss_ce: 0.004236
2022-01-08 19:06:44,008 iteration 5720 : loss : 0.020891, loss_ce: 0.008218
2022-01-08 19:06:46,413 iteration 5721 : loss : 0.015085, loss_ce: 0.004457
2022-01-08 19:06:48,903 iteration 5722 : loss : 0.013860, loss_ce: 0.004739
2022-01-08 19:06:51,534 iteration 5723 : loss : 0.025349, loss_ce: 0.009480
2022-01-08 19:06:53,949 iteration 5724 : loss : 0.013765, loss_ce: 0.005822
2022-01-08 19:06:56,387 iteration 5725 : loss : 0.012788, loss_ce: 0.005103
2022-01-08 19:06:58,811 iteration 5726 : loss : 0.010155, loss_ce: 0.003893
2022-01-08 19:07:01,223 iteration 5727 : loss : 0.016303, loss_ce: 0.008016
2022-01-08 19:07:03,644 iteration 5728 : loss : 0.011159, loss_ce: 0.003528
2022-01-08 19:07:06,041 iteration 5729 : loss : 0.013415, loss_ce: 0.003837
 84%|████████████████████████▍    | 337/400 [4:07:12<47:10, 44.93s/it]2022-01-08 19:07:08,572 iteration 5730 : loss : 0.015078, loss_ce: 0.005332
2022-01-08 19:07:11,062 iteration 5731 : loss : 0.022159, loss_ce: 0.007581
2022-01-08 19:07:13,666 iteration 5732 : loss : 0.040225, loss_ce: 0.007736
2022-01-08 19:07:16,081 iteration 5733 : loss : 0.015557, loss_ce: 0.006515
2022-01-08 19:07:18,591 iteration 5734 : loss : 0.008774, loss_ce: 0.003072
2022-01-08 19:07:21,078 iteration 5735 : loss : 0.017481, loss_ce: 0.005491
2022-01-08 19:07:23,526 iteration 5736 : loss : 0.019311, loss_ce: 0.008889
2022-01-08 19:07:25,983 iteration 5737 : loss : 0.012669, loss_ce: 0.004783
2022-01-08 19:07:28,435 iteration 5738 : loss : 0.011699, loss_ce: 0.005233
2022-01-08 19:07:30,832 iteration 5739 : loss : 0.011398, loss_ce: 0.003482
2022-01-08 19:07:33,311 iteration 5740 : loss : 0.015351, loss_ce: 0.006289
2022-01-08 19:07:35,841 iteration 5741 : loss : 0.010958, loss_ce: 0.004486
2022-01-08 19:07:38,274 iteration 5742 : loss : 0.018516, loss_ce: 0.004025
2022-01-08 19:07:40,703 iteration 5743 : loss : 0.015816, loss_ce: 0.004710
2022-01-08 19:07:43,218 iteration 5744 : loss : 0.011944, loss_ce: 0.005079
2022-01-08 19:07:45,622 iteration 5745 : loss : 0.011163, loss_ce: 0.003649
2022-01-08 19:07:48,004 iteration 5746 : loss : 0.015904, loss_ce: 0.006966
 84%|████████████████████████▌    | 338/400 [4:07:54<45:30, 44.04s/it]2022-01-08 19:07:50,624 iteration 5747 : loss : 0.020507, loss_ce: 0.007702
2022-01-08 19:07:53,011 iteration 5748 : loss : 0.020617, loss_ce: 0.007412
2022-01-08 19:07:55,467 iteration 5749 : loss : 0.029861, loss_ce: 0.013702
2022-01-08 19:07:58,066 iteration 5750 : loss : 0.015860, loss_ce: 0.004044
2022-01-08 19:08:00,523 iteration 5751 : loss : 0.024662, loss_ce: 0.008884
2022-01-08 19:08:03,001 iteration 5752 : loss : 0.017107, loss_ce: 0.005130
2022-01-08 19:08:05,506 iteration 5753 : loss : 0.021103, loss_ce: 0.009930
2022-01-08 19:08:07,919 iteration 5754 : loss : 0.014632, loss_ce: 0.005171
2022-01-08 19:08:10,412 iteration 5755 : loss : 0.015928, loss_ce: 0.004856
2022-01-08 19:08:12,829 iteration 5756 : loss : 0.014921, loss_ce: 0.007242
2022-01-08 19:08:15,263 iteration 5757 : loss : 0.015679, loss_ce: 0.004943
2022-01-08 19:08:17,678 iteration 5758 : loss : 0.008355, loss_ce: 0.002451
2022-01-08 19:08:20,132 iteration 5759 : loss : 0.018200, loss_ce: 0.005391
2022-01-08 19:08:22,646 iteration 5760 : loss : 0.014635, loss_ce: 0.005456
2022-01-08 19:08:25,043 iteration 5761 : loss : 0.015311, loss_ce: 0.005121
2022-01-08 19:08:27,584 iteration 5762 : loss : 0.020318, loss_ce: 0.009140
2022-01-08 19:08:29,986 iteration 5763 : loss : 0.018720, loss_ce: 0.007246
 85%|████████████████████████▌    | 339/400 [4:08:36<44:08, 43.42s/it]2022-01-08 19:08:32,569 iteration 5764 : loss : 0.024742, loss_ce: 0.010957
2022-01-08 19:08:35,187 iteration 5765 : loss : 0.014468, loss_ce: 0.004794
2022-01-08 19:08:37,574 iteration 5766 : loss : 0.017895, loss_ce: 0.005669
2022-01-08 19:08:39,997 iteration 5767 : loss : 0.014780, loss_ce: 0.005749
2022-01-08 19:08:42,579 iteration 5768 : loss : 0.029125, loss_ce: 0.008894
2022-01-08 19:08:44,978 iteration 5769 : loss : 0.014519, loss_ce: 0.004024
2022-01-08 19:08:47,365 iteration 5770 : loss : 0.019282, loss_ce: 0.007977
2022-01-08 19:08:49,825 iteration 5771 : loss : 0.010131, loss_ce: 0.004128
2022-01-08 19:08:52,223 iteration 5772 : loss : 0.013189, loss_ce: 0.004611
2022-01-08 19:08:54,811 iteration 5773 : loss : 0.012151, loss_ce: 0.004057
2022-01-08 19:08:57,183 iteration 5774 : loss : 0.013319, loss_ce: 0.004946
2022-01-08 19:08:59,552 iteration 5775 : loss : 0.024297, loss_ce: 0.009829
2022-01-08 19:09:02,050 iteration 5776 : loss : 0.015122, loss_ce: 0.006084
2022-01-08 19:09:04,470 iteration 5777 : loss : 0.013165, loss_ce: 0.004390
2022-01-08 19:09:06,934 iteration 5778 : loss : 0.012922, loss_ce: 0.004391
2022-01-08 19:09:09,404 iteration 5779 : loss : 0.009836, loss_ce: 0.004078
2022-01-08 19:09:09,404 Training Data Eval:
2022-01-08 19:09:22,569   Average segmentation loss on training set: 0.0081
2022-01-08 19:09:22,569 Validation Data Eval:
2022-01-08 19:09:27,198   Average segmentation loss on validation set: 0.0740
2022-01-08 19:09:29,634 iteration 5780 : loss : 0.017686, loss_ce: 0.007096
 85%|████████████████████████▋    | 340/400 [4:09:36<48:17, 48.30s/it]2022-01-08 19:09:32,127 iteration 5781 : loss : 0.017506, loss_ce: 0.006083
2022-01-08 19:09:34,496 iteration 5782 : loss : 0.010053, loss_ce: 0.003484
2022-01-08 19:09:37,028 iteration 5783 : loss : 0.016081, loss_ce: 0.005846
2022-01-08 19:09:39,520 iteration 5784 : loss : 0.012811, loss_ce: 0.004148
2022-01-08 19:09:41,925 iteration 5785 : loss : 0.011882, loss_ce: 0.005953
2022-01-08 19:09:44,597 iteration 5786 : loss : 0.016903, loss_ce: 0.006062
2022-01-08 19:09:47,000 iteration 5787 : loss : 0.013138, loss_ce: 0.004298
2022-01-08 19:09:49,393 iteration 5788 : loss : 0.017025, loss_ce: 0.007811
2022-01-08 19:09:51,804 iteration 5789 : loss : 0.018416, loss_ce: 0.005993
2022-01-08 19:09:54,290 iteration 5790 : loss : 0.017246, loss_ce: 0.007718
2022-01-08 19:09:56,834 iteration 5791 : loss : 0.013871, loss_ce: 0.005771
2022-01-08 19:09:59,289 iteration 5792 : loss : 0.018476, loss_ce: 0.004986
2022-01-08 19:10:01,844 iteration 5793 : loss : 0.012680, loss_ce: 0.004819
2022-01-08 19:10:04,253 iteration 5794 : loss : 0.013206, loss_ce: 0.004142
2022-01-08 19:10:06,649 iteration 5795 : loss : 0.017469, loss_ce: 0.007318
2022-01-08 19:10:09,156 iteration 5796 : loss : 0.013968, loss_ce: 0.005577
2022-01-08 19:10:11,575 iteration 5797 : loss : 0.013590, loss_ce: 0.005268
 85%|████████████████████████▋    | 341/400 [4:10:18<45:36, 46.39s/it]2022-01-08 19:10:14,113 iteration 5798 : loss : 0.016601, loss_ce: 0.005144
2022-01-08 19:10:16,532 iteration 5799 : loss : 0.012516, loss_ce: 0.004944
2022-01-08 19:10:19,004 iteration 5800 : loss : 0.008525, loss_ce: 0.003371
2022-01-08 19:10:21,420 iteration 5801 : loss : 0.013474, loss_ce: 0.005979
2022-01-08 19:10:23,859 iteration 5802 : loss : 0.015556, loss_ce: 0.005969
2022-01-08 19:10:26,338 iteration 5803 : loss : 0.016779, loss_ce: 0.005923
2022-01-08 19:10:28,713 iteration 5804 : loss : 0.015907, loss_ce: 0.005782
2022-01-08 19:10:31,142 iteration 5805 : loss : 0.013649, loss_ce: 0.004609
2022-01-08 19:10:33,565 iteration 5806 : loss : 0.010232, loss_ce: 0.004626
2022-01-08 19:10:35,990 iteration 5807 : loss : 0.016465, loss_ce: 0.006283
2022-01-08 19:10:38,557 iteration 5808 : loss : 0.015591, loss_ce: 0.005789
2022-01-08 19:10:40,985 iteration 5809 : loss : 0.013832, loss_ce: 0.005114
2022-01-08 19:10:43,452 iteration 5810 : loss : 0.031771, loss_ce: 0.011623
2022-01-08 19:10:46,024 iteration 5811 : loss : 0.018302, loss_ce: 0.007589
2022-01-08 19:10:48,442 iteration 5812 : loss : 0.016349, loss_ce: 0.006834
2022-01-08 19:10:50,817 iteration 5813 : loss : 0.011504, loss_ce: 0.003748
2022-01-08 19:10:53,309 iteration 5814 : loss : 0.021592, loss_ce: 0.007480
 86%|████████████████████████▊    | 342/400 [4:11:00<43:29, 44.99s/it]2022-01-08 19:10:55,795 iteration 5815 : loss : 0.015297, loss_ce: 0.005632
2022-01-08 19:10:58,316 iteration 5816 : loss : 0.013451, loss_ce: 0.004810
2022-01-08 19:11:00,975 iteration 5817 : loss : 0.018599, loss_ce: 0.009468
2022-01-08 19:11:03,391 iteration 5818 : loss : 0.019747, loss_ce: 0.007268
2022-01-08 19:11:05,821 iteration 5819 : loss : 0.011612, loss_ce: 0.003024
2022-01-08 19:11:08,169 iteration 5820 : loss : 0.016335, loss_ce: 0.005480
2022-01-08 19:11:10,639 iteration 5821 : loss : 0.013249, loss_ce: 0.004692
2022-01-08 19:11:13,092 iteration 5822 : loss : 0.018554, loss_ce: 0.005069
2022-01-08 19:11:15,462 iteration 5823 : loss : 0.011874, loss_ce: 0.005707
2022-01-08 19:11:18,076 iteration 5824 : loss : 0.022887, loss_ce: 0.005673
2022-01-08 19:11:20,470 iteration 5825 : loss : 0.009984, loss_ce: 0.003727
2022-01-08 19:11:22,882 iteration 5826 : loss : 0.012357, loss_ce: 0.005407
2022-01-08 19:11:25,244 iteration 5827 : loss : 0.012173, loss_ce: 0.004948
2022-01-08 19:11:27,772 iteration 5828 : loss : 0.027006, loss_ce: 0.006182
2022-01-08 19:11:30,217 iteration 5829 : loss : 0.012024, loss_ce: 0.004721
2022-01-08 19:11:32,622 iteration 5830 : loss : 0.012230, loss_ce: 0.004156
2022-01-08 19:11:35,074 iteration 5831 : loss : 0.020324, loss_ce: 0.007856
 86%|████████████████████████▊    | 343/400 [4:11:41<41:49, 44.03s/it]2022-01-08 19:11:37,693 iteration 5832 : loss : 0.019420, loss_ce: 0.010482
2022-01-08 19:11:40,140 iteration 5833 : loss : 0.015919, loss_ce: 0.005451
2022-01-08 19:11:42,543 iteration 5834 : loss : 0.016591, loss_ce: 0.008721
2022-01-08 19:11:44,946 iteration 5835 : loss : 0.015541, loss_ce: 0.006181
2022-01-08 19:11:47,435 iteration 5836 : loss : 0.022634, loss_ce: 0.006742
2022-01-08 19:11:49,882 iteration 5837 : loss : 0.016755, loss_ce: 0.005889
2022-01-08 19:11:52,273 iteration 5838 : loss : 0.018581, loss_ce: 0.004933
2022-01-08 19:11:54,914 iteration 5839 : loss : 0.014720, loss_ce: 0.005318
2022-01-08 19:11:57,317 iteration 5840 : loss : 0.013533, loss_ce: 0.005484
2022-01-08 19:11:59,750 iteration 5841 : loss : 0.016522, loss_ce: 0.005364
2022-01-08 19:12:02,231 iteration 5842 : loss : 0.012007, loss_ce: 0.003907
2022-01-08 19:12:04,620 iteration 5843 : loss : 0.011929, loss_ce: 0.004255
2022-01-08 19:12:07,127 iteration 5844 : loss : 0.015542, loss_ce: 0.006454
2022-01-08 19:12:09,619 iteration 5845 : loss : 0.010813, loss_ce: 0.003762
2022-01-08 19:12:11,975 iteration 5846 : loss : 0.010216, loss_ce: 0.004306
2022-01-08 19:12:14,321 iteration 5847 : loss : 0.013061, loss_ce: 0.004902
2022-01-08 19:12:16,917 iteration 5848 : loss : 0.012049, loss_ce: 0.004067
 86%|████████████████████████▉    | 344/400 [4:12:23<40:28, 43.37s/it]2022-01-08 19:12:19,392 iteration 5849 : loss : 0.015649, loss_ce: 0.004655
2022-01-08 19:12:22,040 iteration 5850 : loss : 0.015573, loss_ce: 0.006761
2022-01-08 19:12:24,495 iteration 5851 : loss : 0.011280, loss_ce: 0.002785
2022-01-08 19:12:26,897 iteration 5852 : loss : 0.020768, loss_ce: 0.009730
2022-01-08 19:12:29,270 iteration 5853 : loss : 0.014681, loss_ce: 0.004658
2022-01-08 19:12:31,735 iteration 5854 : loss : 0.014500, loss_ce: 0.004995
2022-01-08 19:12:34,215 iteration 5855 : loss : 0.015429, loss_ce: 0.006692
2022-01-08 19:12:36,785 iteration 5856 : loss : 0.017415, loss_ce: 0.007618
2022-01-08 19:12:39,222 iteration 5857 : loss : 0.011229, loss_ce: 0.003988
2022-01-08 19:12:41,653 iteration 5858 : loss : 0.011665, loss_ce: 0.003607
2022-01-08 19:12:44,118 iteration 5859 : loss : 0.015019, loss_ce: 0.005254
2022-01-08 19:12:46,476 iteration 5860 : loss : 0.012328, loss_ce: 0.004796
2022-01-08 19:12:48,943 iteration 5861 : loss : 0.015944, loss_ce: 0.006752
2022-01-08 19:12:51,414 iteration 5862 : loss : 0.015082, loss_ce: 0.006117
2022-01-08 19:12:53,875 iteration 5863 : loss : 0.026244, loss_ce: 0.006890
2022-01-08 19:12:56,360 iteration 5864 : loss : 0.018981, loss_ce: 0.008199
2022-01-08 19:12:56,360 Training Data Eval:
2022-01-08 19:13:09,568   Average segmentation loss on training set: 0.0077
2022-01-08 19:13:09,569 Validation Data Eval:
2022-01-08 19:13:14,045   Average segmentation loss on validation set: 0.0699
2022-01-08 19:13:16,592 iteration 5865 : loss : 0.020587, loss_ce: 0.005635
 86%|█████████████████████████    | 345/400 [4:13:23<44:14, 48.26s/it]2022-01-08 19:13:19,058 iteration 5866 : loss : 0.013909, loss_ce: 0.003640
2022-01-08 19:13:21,470 iteration 5867 : loss : 0.009991, loss_ce: 0.004113
2022-01-08 19:13:23,960 iteration 5868 : loss : 0.014052, loss_ce: 0.004992
2022-01-08 19:13:26,407 iteration 5869 : loss : 0.022888, loss_ce: 0.008722
2022-01-08 19:13:28,888 iteration 5870 : loss : 0.020133, loss_ce: 0.007806
2022-01-08 19:13:31,300 iteration 5871 : loss : 0.017507, loss_ce: 0.005413
2022-01-08 19:13:33,715 iteration 5872 : loss : 0.014491, loss_ce: 0.004886
2022-01-08 19:13:36,178 iteration 5873 : loss : 0.023859, loss_ce: 0.014514
2022-01-08 19:13:38,725 iteration 5874 : loss : 0.019415, loss_ce: 0.006758
2022-01-08 19:13:41,124 iteration 5875 : loss : 0.010951, loss_ce: 0.004926
2022-01-08 19:13:43,628 iteration 5876 : loss : 0.017643, loss_ce: 0.007238
2022-01-08 19:13:46,109 iteration 5877 : loss : 0.018911, loss_ce: 0.007329
2022-01-08 19:13:48,502 iteration 5878 : loss : 0.012934, loss_ce: 0.004044
2022-01-08 19:13:50,872 iteration 5879 : loss : 0.017939, loss_ce: 0.007476
2022-01-08 19:13:53,403 iteration 5880 : loss : 0.016198, loss_ce: 0.004267
2022-01-08 19:13:55,757 iteration 5881 : loss : 0.011194, loss_ce: 0.004603
2022-01-08 19:13:58,147 iteration 5882 : loss : 0.014848, loss_ce: 0.005003
 86%|█████████████████████████    | 346/400 [4:14:05<41:37, 46.25s/it]2022-01-08 19:14:00,603 iteration 5883 : loss : 0.012464, loss_ce: 0.004142
2022-01-08 19:14:03,064 iteration 5884 : loss : 0.011060, loss_ce: 0.004099
2022-01-08 19:14:05,583 iteration 5885 : loss : 0.015147, loss_ce: 0.004539
2022-01-08 19:14:08,025 iteration 5886 : loss : 0.016005, loss_ce: 0.004948
2022-01-08 19:14:10,440 iteration 5887 : loss : 0.015445, loss_ce: 0.005794
2022-01-08 19:14:12,840 iteration 5888 : loss : 0.008948, loss_ce: 0.003570
2022-01-08 19:14:15,279 iteration 5889 : loss : 0.014763, loss_ce: 0.004486
2022-01-08 19:14:17,852 iteration 5890 : loss : 0.014106, loss_ce: 0.005668
2022-01-08 19:14:20,229 iteration 5891 : loss : 0.018471, loss_ce: 0.005275
2022-01-08 19:14:22,646 iteration 5892 : loss : 0.012912, loss_ce: 0.003403
2022-01-08 19:14:24,996 iteration 5893 : loss : 0.017014, loss_ce: 0.006613
2022-01-08 19:14:27,397 iteration 5894 : loss : 0.013284, loss_ce: 0.005912
2022-01-08 19:14:29,798 iteration 5895 : loss : 0.012816, loss_ce: 0.005061
2022-01-08 19:14:32,206 iteration 5896 : loss : 0.012072, loss_ce: 0.004762
2022-01-08 19:14:34,820 iteration 5897 : loss : 0.013027, loss_ce: 0.006144
2022-01-08 19:14:37,190 iteration 5898 : loss : 0.034576, loss_ce: 0.009537
2022-01-08 19:14:39,640 iteration 5899 : loss : 0.034138, loss_ce: 0.013639
 87%|█████████████████████████▏   | 347/400 [4:14:46<39:35, 44.82s/it]2022-01-08 19:14:42,080 iteration 5900 : loss : 0.013980, loss_ce: 0.005269
2022-01-08 19:14:44,556 iteration 5901 : loss : 0.014105, loss_ce: 0.005621
2022-01-08 19:14:47,229 iteration 5902 : loss : 0.018233, loss_ce: 0.007806
2022-01-08 19:14:49,634 iteration 5903 : loss : 0.015262, loss_ce: 0.004629
2022-01-08 19:14:52,016 iteration 5904 : loss : 0.018387, loss_ce: 0.006823
2022-01-08 19:14:54,502 iteration 5905 : loss : 0.014355, loss_ce: 0.005187
2022-01-08 19:14:56,898 iteration 5906 : loss : 0.017826, loss_ce: 0.007393
2022-01-08 19:14:59,418 iteration 5907 : loss : 0.018785, loss_ce: 0.006128
2022-01-08 19:15:01,875 iteration 5908 : loss : 0.020451, loss_ce: 0.008667
2022-01-08 19:15:04,258 iteration 5909 : loss : 0.011367, loss_ce: 0.004525
2022-01-08 19:15:06,679 iteration 5910 : loss : 0.018138, loss_ce: 0.007642
2022-01-08 19:15:09,032 iteration 5911 : loss : 0.015512, loss_ce: 0.007045
2022-01-08 19:15:11,507 iteration 5912 : loss : 0.027988, loss_ce: 0.005019
2022-01-08 19:15:13,926 iteration 5913 : loss : 0.016106, loss_ce: 0.005478
2022-01-08 19:15:16,451 iteration 5914 : loss : 0.019180, loss_ce: 0.006809
2022-01-08 19:15:19,043 iteration 5915 : loss : 0.021813, loss_ce: 0.009460
2022-01-08 19:15:21,454 iteration 5916 : loss : 0.019054, loss_ce: 0.006654
 87%|█████████████████████████▏   | 348/400 [4:15:28<38:03, 43.92s/it]2022-01-08 19:15:23,869 iteration 5917 : loss : 0.017901, loss_ce: 0.003669
2022-01-08 19:15:26,285 iteration 5918 : loss : 0.017852, loss_ce: 0.006530
2022-01-08 19:15:28,696 iteration 5919 : loss : 0.011821, loss_ce: 0.006595
2022-01-08 19:15:31,341 iteration 5920 : loss : 0.017950, loss_ce: 0.008020
2022-01-08 19:15:33,822 iteration 5921 : loss : 0.013261, loss_ce: 0.004138
2022-01-08 19:15:36,244 iteration 5922 : loss : 0.018192, loss_ce: 0.009953
2022-01-08 19:15:38,711 iteration 5923 : loss : 0.015302, loss_ce: 0.004703
2022-01-08 19:15:41,151 iteration 5924 : loss : 0.012153, loss_ce: 0.004892
2022-01-08 19:15:43,542 iteration 5925 : loss : 0.011743, loss_ce: 0.003350
2022-01-08 19:15:45,974 iteration 5926 : loss : 0.011325, loss_ce: 0.004120
2022-01-08 19:15:48,424 iteration 5927 : loss : 0.021160, loss_ce: 0.007927
2022-01-08 19:15:50,823 iteration 5928 : loss : 0.011245, loss_ce: 0.004796
2022-01-08 19:15:53,214 iteration 5929 : loss : 0.017169, loss_ce: 0.004900
2022-01-08 19:15:55,601 iteration 5930 : loss : 0.016376, loss_ce: 0.005513
2022-01-08 19:15:58,167 iteration 5931 : loss : 0.011712, loss_ce: 0.004680
2022-01-08 19:16:00,559 iteration 5932 : loss : 0.022301, loss_ce: 0.007948
2022-01-08 19:16:02,884 iteration 5933 : loss : 0.010176, loss_ce: 0.004006
 87%|█████████████████████████▎   | 349/400 [4:16:09<36:41, 43.17s/it]2022-01-08 19:16:05,372 iteration 5934 : loss : 0.011106, loss_ce: 0.003912
2022-01-08 19:16:07,748 iteration 5935 : loss : 0.019725, loss_ce: 0.010915
2022-01-08 19:16:10,223 iteration 5936 : loss : 0.016623, loss_ce: 0.006214
2022-01-08 19:16:12,713 iteration 5937 : loss : 0.013453, loss_ce: 0.005633
2022-01-08 19:16:15,162 iteration 5938 : loss : 0.014350, loss_ce: 0.006615
2022-01-08 19:16:17,662 iteration 5939 : loss : 0.025676, loss_ce: 0.008914
2022-01-08 19:16:20,040 iteration 5940 : loss : 0.012189, loss_ce: 0.004011
2022-01-08 19:16:22,466 iteration 5941 : loss : 0.017396, loss_ce: 0.006092
2022-01-08 19:16:24,922 iteration 5942 : loss : 0.017105, loss_ce: 0.006798
2022-01-08 19:16:27,486 iteration 5943 : loss : 0.015578, loss_ce: 0.005406
2022-01-08 19:16:29,829 iteration 5944 : loss : 0.012949, loss_ce: 0.005229
2022-01-08 19:16:32,316 iteration 5945 : loss : 0.020328, loss_ce: 0.006635
2022-01-08 19:16:34,730 iteration 5946 : loss : 0.017144, loss_ce: 0.008233
2022-01-08 19:16:37,353 iteration 5947 : loss : 0.026116, loss_ce: 0.009146
2022-01-08 19:16:39,794 iteration 5948 : loss : 0.021594, loss_ce: 0.007117
2022-01-08 19:16:42,225 iteration 5949 : loss : 0.013220, loss_ce: 0.003135
2022-01-08 19:16:42,225 Training Data Eval:
2022-01-08 19:16:55,338   Average segmentation loss on training set: 0.0078
2022-01-08 19:16:55,339 Validation Data Eval:
2022-01-08 19:16:59,935   Average segmentation loss on validation set: 0.0701
2022-01-08 19:17:02,401 iteration 5950 : loss : 0.010707, loss_ce: 0.003391
 88%|█████████████████████████▍   | 350/400 [4:17:09<40:03, 48.08s/it]2022-01-08 19:17:04,824 iteration 5951 : loss : 0.013941, loss_ce: 0.004117
2022-01-08 19:17:07,385 iteration 5952 : loss : 0.016107, loss_ce: 0.008322
2022-01-08 19:17:09,858 iteration 5953 : loss : 0.023658, loss_ce: 0.009829
2022-01-08 19:17:12,224 iteration 5954 : loss : 0.014719, loss_ce: 0.003654
2022-01-08 19:17:14,907 iteration 5955 : loss : 0.024354, loss_ce: 0.007566
2022-01-08 19:17:17,296 iteration 5956 : loss : 0.016951, loss_ce: 0.004032
2022-01-08 19:17:19,688 iteration 5957 : loss : 0.018664, loss_ce: 0.008393
2022-01-08 19:17:22,294 iteration 5958 : loss : 0.018283, loss_ce: 0.007491
2022-01-08 19:17:24,814 iteration 5959 : loss : 0.015974, loss_ce: 0.003769
2022-01-08 19:17:27,190 iteration 5960 : loss : 0.013389, loss_ce: 0.003722
2022-01-08 19:17:29,602 iteration 5961 : loss : 0.018862, loss_ce: 0.012549
2022-01-08 19:17:31,986 iteration 5962 : loss : 0.018489, loss_ce: 0.007945
2022-01-08 19:17:34,426 iteration 5963 : loss : 0.014068, loss_ce: 0.004918
2022-01-08 19:17:36,894 iteration 5964 : loss : 0.020901, loss_ce: 0.008137
2022-01-08 19:17:39,443 iteration 5965 : loss : 0.011271, loss_ce: 0.005425
2022-01-08 19:17:41,807 iteration 5966 : loss : 0.009386, loss_ce: 0.003097
2022-01-08 19:17:44,451 iteration 5967 : loss : 0.015953, loss_ce: 0.005595
 88%|█████████████████████████▍   | 351/400 [4:17:51<37:46, 46.26s/it]2022-01-08 19:17:46,854 iteration 5968 : loss : 0.014634, loss_ce: 0.005371
2022-01-08 19:17:49,204 iteration 5969 : loss : 0.014329, loss_ce: 0.008494
2022-01-08 19:17:51,641 iteration 5970 : loss : 0.015382, loss_ce: 0.006238
2022-01-08 19:17:54,128 iteration 5971 : loss : 0.010429, loss_ce: 0.004219
2022-01-08 19:17:56,566 iteration 5972 : loss : 0.015653, loss_ce: 0.004217
2022-01-08 19:17:58,967 iteration 5973 : loss : 0.012411, loss_ce: 0.005077
2022-01-08 19:18:01,370 iteration 5974 : loss : 0.023726, loss_ce: 0.006339
2022-01-08 19:18:03,779 iteration 5975 : loss : 0.015769, loss_ce: 0.009039
2022-01-08 19:18:06,347 iteration 5976 : loss : 0.016663, loss_ce: 0.005122
2022-01-08 19:18:08,747 iteration 5977 : loss : 0.011511, loss_ce: 0.003776
2022-01-08 19:18:11,171 iteration 5978 : loss : 0.012758, loss_ce: 0.004496
2022-01-08 19:18:13,547 iteration 5979 : loss : 0.011203, loss_ce: 0.003066
2022-01-08 19:18:16,024 iteration 5980 : loss : 0.021428, loss_ce: 0.004753
2022-01-08 19:18:18,518 iteration 5981 : loss : 0.018952, loss_ce: 0.008113
2022-01-08 19:18:20,978 iteration 5982 : loss : 0.019369, loss_ce: 0.009481
2022-01-08 19:18:23,467 iteration 5983 : loss : 0.018688, loss_ce: 0.005250
2022-01-08 19:18:26,066 iteration 5984 : loss : 0.023579, loss_ce: 0.010264
 88%|█████████████████████████▌   | 352/400 [4:18:32<35:53, 44.87s/it]2022-01-08 19:18:28,533 iteration 5985 : loss : 0.019900, loss_ce: 0.007089
2022-01-08 19:18:31,080 iteration 5986 : loss : 0.010065, loss_ce: 0.004600
2022-01-08 19:18:33,546 iteration 5987 : loss : 0.019881, loss_ce: 0.005716
2022-01-08 19:18:36,054 iteration 5988 : loss : 0.011498, loss_ce: 0.004538
2022-01-08 19:18:38,553 iteration 5989 : loss : 0.010729, loss_ce: 0.003789
2022-01-08 19:18:40,944 iteration 5990 : loss : 0.024169, loss_ce: 0.006644
2022-01-08 19:18:43,592 iteration 5991 : loss : 0.019137, loss_ce: 0.005206
2022-01-08 19:18:46,019 iteration 5992 : loss : 0.029285, loss_ce: 0.007389
2022-01-08 19:18:48,471 iteration 5993 : loss : 0.015165, loss_ce: 0.005569
2022-01-08 19:18:50,852 iteration 5994 : loss : 0.012205, loss_ce: 0.005419
2022-01-08 19:18:53,318 iteration 5995 : loss : 0.014073, loss_ce: 0.004859
2022-01-08 19:18:55,810 iteration 5996 : loss : 0.011784, loss_ce: 0.006143
2022-01-08 19:18:58,389 iteration 5997 : loss : 0.016130, loss_ce: 0.004927
2022-01-08 19:19:00,888 iteration 5998 : loss : 0.019543, loss_ce: 0.007702
2022-01-08 19:19:03,303 iteration 5999 : loss : 0.021037, loss_ce: 0.008186
2022-01-08 19:19:05,969 iteration 6000 : loss : 0.023831, loss_ce: 0.009471
2022-01-08 19:19:08,326 iteration 6001 : loss : 0.009571, loss_ce: 0.003526
 88%|█████████████████████████▌   | 353/400 [4:19:15<34:32, 44.09s/it]2022-01-08 19:19:10,710 iteration 6002 : loss : 0.013501, loss_ce: 0.004936
2022-01-08 19:19:13,187 iteration 6003 : loss : 0.012362, loss_ce: 0.005541
2022-01-08 19:19:15,619 iteration 6004 : loss : 0.015020, loss_ce: 0.005333
2022-01-08 19:19:18,034 iteration 6005 : loss : 0.013911, loss_ce: 0.006321
2022-01-08 19:19:20,542 iteration 6006 : loss : 0.016951, loss_ce: 0.005260
2022-01-08 19:19:22,947 iteration 6007 : loss : 0.013836, loss_ce: 0.005435
2022-01-08 19:19:25,378 iteration 6008 : loss : 0.014950, loss_ce: 0.005345
2022-01-08 19:19:27,852 iteration 6009 : loss : 0.012310, loss_ce: 0.003544
2022-01-08 19:19:30,257 iteration 6010 : loss : 0.012779, loss_ce: 0.003135
2022-01-08 19:19:32,793 iteration 6011 : loss : 0.017358, loss_ce: 0.005893
2022-01-08 19:19:35,312 iteration 6012 : loss : 0.018940, loss_ce: 0.007364
2022-01-08 19:19:37,745 iteration 6013 : loss : 0.016500, loss_ce: 0.005489
2022-01-08 19:19:40,360 iteration 6014 : loss : 0.011426, loss_ce: 0.004155
2022-01-08 19:19:42,683 iteration 6015 : loss : 0.010611, loss_ce: 0.005078
2022-01-08 19:19:45,185 iteration 6016 : loss : 0.010675, loss_ce: 0.003151
2022-01-08 19:19:47,556 iteration 6017 : loss : 0.021677, loss_ce: 0.006967
2022-01-08 19:19:50,032 iteration 6018 : loss : 0.011918, loss_ce: 0.004824
 88%|█████████████████████████▋   | 354/400 [4:19:56<33:15, 43.38s/it]2022-01-08 19:19:52,514 iteration 6019 : loss : 0.013738, loss_ce: 0.005156
2022-01-08 19:19:54,950 iteration 6020 : loss : 0.017519, loss_ce: 0.005611
2022-01-08 19:19:57,396 iteration 6021 : loss : 0.010342, loss_ce: 0.003695
2022-01-08 19:19:59,840 iteration 6022 : loss : 0.014319, loss_ce: 0.005839
2022-01-08 19:20:02,402 iteration 6023 : loss : 0.010185, loss_ce: 0.004135
2022-01-08 19:20:04,788 iteration 6024 : loss : 0.016729, loss_ce: 0.007813
2022-01-08 19:20:07,177 iteration 6025 : loss : 0.020424, loss_ce: 0.004207
2022-01-08 19:20:09,595 iteration 6026 : loss : 0.014493, loss_ce: 0.005030
2022-01-08 19:20:12,184 iteration 6027 : loss : 0.011926, loss_ce: 0.005040
2022-01-08 19:20:14,622 iteration 6028 : loss : 0.011780, loss_ce: 0.005251
2022-01-08 19:20:17,009 iteration 6029 : loss : 0.017720, loss_ce: 0.008406
2022-01-08 19:20:19,501 iteration 6030 : loss : 0.020244, loss_ce: 0.006676
2022-01-08 19:20:22,055 iteration 6031 : loss : 0.017417, loss_ce: 0.005137
2022-01-08 19:20:24,429 iteration 6032 : loss : 0.017122, loss_ce: 0.004710
2022-01-08 19:20:26,868 iteration 6033 : loss : 0.020499, loss_ce: 0.007318
2022-01-08 19:20:29,303 iteration 6034 : loss : 0.009204, loss_ce: 0.003202
2022-01-08 19:20:29,303 Training Data Eval:
2022-01-08 19:20:42,631   Average segmentation loss on training set: 0.0076
2022-01-08 19:20:42,631 Validation Data Eval:
2022-01-08 19:20:47,244   Average segmentation loss on validation set: 0.0673
2022-01-08 19:20:49,601 iteration 6035 : loss : 0.013631, loss_ce: 0.006052
 89%|█████████████████████████▋   | 355/400 [4:20:56<36:10, 48.23s/it]2022-01-08 19:20:52,249 iteration 6036 : loss : 0.012119, loss_ce: 0.005545
2022-01-08 19:20:54,600 iteration 6037 : loss : 0.009369, loss_ce: 0.003681
2022-01-08 19:20:57,068 iteration 6038 : loss : 0.010777, loss_ce: 0.003907
2022-01-08 19:20:59,400 iteration 6039 : loss : 0.011300, loss_ce: 0.003769
2022-01-08 19:21:01,795 iteration 6040 : loss : 0.012702, loss_ce: 0.004151
2022-01-08 19:21:04,225 iteration 6041 : loss : 0.016070, loss_ce: 0.005886
2022-01-08 19:21:06,619 iteration 6042 : loss : 0.015240, loss_ce: 0.003649
2022-01-08 19:21:09,096 iteration 6043 : loss : 0.013714, loss_ce: 0.004255
2022-01-08 19:21:11,573 iteration 6044 : loss : 0.022624, loss_ce: 0.005930
2022-01-08 19:21:13,986 iteration 6045 : loss : 0.011847, loss_ce: 0.004846
2022-01-08 19:21:16,437 iteration 6046 : loss : 0.013450, loss_ce: 0.005050
2022-01-08 19:21:19,174 iteration 6047 : loss : 0.010558, loss_ce: 0.003960
2022-01-08 19:21:21,619 iteration 6048 : loss : 0.015442, loss_ce: 0.006707
2022-01-08 19:21:23,975 iteration 6049 : loss : 0.012480, loss_ce: 0.005746
2022-01-08 19:21:26,387 iteration 6050 : loss : 0.010930, loss_ce: 0.003616
2022-01-08 19:21:29,010 iteration 6051 : loss : 0.014310, loss_ce: 0.004589
2022-01-08 19:21:31,576 iteration 6052 : loss : 0.011968, loss_ce: 0.004775
 89%|█████████████████████████▊   | 356/400 [4:21:38<33:59, 46.36s/it]2022-01-08 19:21:33,971 iteration 6053 : loss : 0.017999, loss_ce: 0.006277
2022-01-08 19:21:36,462 iteration 6054 : loss : 0.010982, loss_ce: 0.005399
2022-01-08 19:21:38,907 iteration 6055 : loss : 0.015611, loss_ce: 0.005651
2022-01-08 19:21:41,305 iteration 6056 : loss : 0.011942, loss_ce: 0.004095
2022-01-08 19:21:43,706 iteration 6057 : loss : 0.010356, loss_ce: 0.002978
2022-01-08 19:21:46,169 iteration 6058 : loss : 0.013169, loss_ce: 0.004120
2022-01-08 19:21:48,654 iteration 6059 : loss : 0.012937, loss_ce: 0.006056
2022-01-08 19:21:51,378 iteration 6060 : loss : 0.031926, loss_ce: 0.010971
2022-01-08 19:21:53,783 iteration 6061 : loss : 0.011719, loss_ce: 0.004730
2022-01-08 19:21:56,259 iteration 6062 : loss : 0.019232, loss_ce: 0.006192
2022-01-08 19:21:58,665 iteration 6063 : loss : 0.015613, loss_ce: 0.005096
2022-01-08 19:22:01,113 iteration 6064 : loss : 0.014434, loss_ce: 0.006451
2022-01-08 19:22:03,647 iteration 6065 : loss : 0.008140, loss_ce: 0.002987
2022-01-08 19:22:06,011 iteration 6066 : loss : 0.008042, loss_ce: 0.002316
2022-01-08 19:22:08,513 iteration 6067 : loss : 0.012113, loss_ce: 0.005534
2022-01-08 19:22:10,927 iteration 6068 : loss : 0.009584, loss_ce: 0.002643
2022-01-08 19:22:13,374 iteration 6069 : loss : 0.020515, loss_ce: 0.008334
 89%|█████████████████████████▉   | 357/400 [4:22:20<32:14, 44.99s/it]2022-01-08 19:22:15,840 iteration 6070 : loss : 0.008570, loss_ce: 0.004277
2022-01-08 19:22:18,330 iteration 6071 : loss : 0.009773, loss_ce: 0.003204
2022-01-08 19:22:20,758 iteration 6072 : loss : 0.010192, loss_ce: 0.005164
2022-01-08 19:22:23,238 iteration 6073 : loss : 0.010993, loss_ce: 0.003599
2022-01-08 19:22:25,846 iteration 6074 : loss : 0.011814, loss_ce: 0.004405
2022-01-08 19:22:28,207 iteration 6075 : loss : 0.009599, loss_ce: 0.004226
2022-01-08 19:22:30,761 iteration 6076 : loss : 0.010432, loss_ce: 0.002279
2022-01-08 19:22:33,146 iteration 6077 : loss : 0.012477, loss_ce: 0.004521
2022-01-08 19:22:35,700 iteration 6078 : loss : 0.018156, loss_ce: 0.006913
2022-01-08 19:22:38,182 iteration 6079 : loss : 0.018619, loss_ce: 0.007235
2022-01-08 19:22:40,610 iteration 6080 : loss : 0.013001, loss_ce: 0.004398
2022-01-08 19:22:43,218 iteration 6081 : loss : 0.020032, loss_ce: 0.006859
2022-01-08 19:22:45,549 iteration 6082 : loss : 0.015588, loss_ce: 0.004307
2022-01-08 19:22:48,022 iteration 6083 : loss : 0.012114, loss_ce: 0.003234
2022-01-08 19:22:50,398 iteration 6084 : loss : 0.020865, loss_ce: 0.004603
2022-01-08 19:22:52,791 iteration 6085 : loss : 0.021697, loss_ce: 0.006138
2022-01-08 19:22:55,269 iteration 6086 : loss : 0.011079, loss_ce: 0.003592
 90%|█████████████████████████▉   | 358/400 [4:23:02<30:50, 44.06s/it]2022-01-08 19:22:57,636 iteration 6087 : loss : 0.012197, loss_ce: 0.003610
2022-01-08 19:23:00,128 iteration 6088 : loss : 0.011981, loss_ce: 0.004809
2022-01-08 19:23:02,555 iteration 6089 : loss : 0.012320, loss_ce: 0.004008
2022-01-08 19:23:04,905 iteration 6090 : loss : 0.010111, loss_ce: 0.004413
2022-01-08 19:23:07,564 iteration 6091 : loss : 0.010434, loss_ce: 0.003449
2022-01-08 19:23:10,006 iteration 6092 : loss : 0.018545, loss_ce: 0.006017
2022-01-08 19:23:12,371 iteration 6093 : loss : 0.014360, loss_ce: 0.006270
2022-01-08 19:23:14,821 iteration 6094 : loss : 0.013806, loss_ce: 0.005027
2022-01-08 19:23:17,216 iteration 6095 : loss : 0.012644, loss_ce: 0.004021
2022-01-08 19:23:19,759 iteration 6096 : loss : 0.012039, loss_ce: 0.003401
2022-01-08 19:23:22,345 iteration 6097 : loss : 0.008781, loss_ce: 0.003132
2022-01-08 19:23:24,819 iteration 6098 : loss : 0.022084, loss_ce: 0.009526
2022-01-08 19:23:27,335 iteration 6099 : loss : 0.011490, loss_ce: 0.004608
2022-01-08 19:23:29,774 iteration 6100 : loss : 0.013544, loss_ce: 0.007351
2022-01-08 19:23:32,302 iteration 6101 : loss : 0.020854, loss_ce: 0.007667
2022-01-08 19:23:34,723 iteration 6102 : loss : 0.018592, loss_ce: 0.009079
2022-01-08 19:23:37,333 iteration 6103 : loss : 0.021747, loss_ce: 0.006954
 90%|██████████████████████████   | 359/400 [4:23:44<29:41, 43.46s/it]2022-01-08 19:23:39,826 iteration 6104 : loss : 0.024003, loss_ce: 0.009894
2022-01-08 19:23:42,273 iteration 6105 : loss : 0.012161, loss_ce: 0.005379
2022-01-08 19:23:44,745 iteration 6106 : loss : 0.014848, loss_ce: 0.006734
2022-01-08 19:23:47,211 iteration 6107 : loss : 0.015978, loss_ce: 0.006504
2022-01-08 19:23:49,638 iteration 6108 : loss : 0.013242, loss_ce: 0.005406
2022-01-08 19:23:52,274 iteration 6109 : loss : 0.011937, loss_ce: 0.002427
2022-01-08 19:23:54,677 iteration 6110 : loss : 0.011618, loss_ce: 0.005087
2022-01-08 19:23:57,040 iteration 6111 : loss : 0.014452, loss_ce: 0.005850
2022-01-08 19:23:59,501 iteration 6112 : loss : 0.015427, loss_ce: 0.004319
2022-01-08 19:24:01,934 iteration 6113 : loss : 0.012644, loss_ce: 0.005177
2022-01-08 19:24:04,375 iteration 6114 : loss : 0.017192, loss_ce: 0.005380
2022-01-08 19:24:06,880 iteration 6115 : loss : 0.013281, loss_ce: 0.004516
2022-01-08 19:24:09,405 iteration 6116 : loss : 0.019385, loss_ce: 0.006469
2022-01-08 19:24:11,773 iteration 6117 : loss : 0.011681, loss_ce: 0.004664
2022-01-08 19:24:14,263 iteration 6118 : loss : 0.009227, loss_ce: 0.002727
2022-01-08 19:24:16,739 iteration 6119 : loss : 0.014813, loss_ce: 0.006978
2022-01-08 19:24:16,739 Training Data Eval:
2022-01-08 19:24:29,926   Average segmentation loss on training set: 0.0071
2022-01-08 19:24:29,927 Validation Data Eval:
2022-01-08 19:24:34,419   Average segmentation loss on validation set: 0.0708
2022-01-08 19:24:37,003 iteration 6120 : loss : 0.013396, loss_ce: 0.004290
 90%|██████████████████████████   | 360/400 [4:24:43<32:12, 48.32s/it]2022-01-08 19:24:39,532 iteration 6121 : loss : 0.016685, loss_ce: 0.004913
2022-01-08 19:24:41,905 iteration 6122 : loss : 0.014478, loss_ce: 0.006361
2022-01-08 19:24:44,355 iteration 6123 : loss : 0.017597, loss_ce: 0.008411
2022-01-08 19:24:46,755 iteration 6124 : loss : 0.013096, loss_ce: 0.005083
2022-01-08 19:24:49,165 iteration 6125 : loss : 0.022102, loss_ce: 0.008296
2022-01-08 19:24:51,565 iteration 6126 : loss : 0.013094, loss_ce: 0.007236
2022-01-08 19:24:54,132 iteration 6127 : loss : 0.011511, loss_ce: 0.003664
2022-01-08 19:24:56,510 iteration 6128 : loss : 0.012090, loss_ce: 0.004364
2022-01-08 19:24:59,054 iteration 6129 : loss : 0.012536, loss_ce: 0.004321
2022-01-08 19:25:01,470 iteration 6130 : loss : 0.014593, loss_ce: 0.003645
2022-01-08 19:25:03,969 iteration 6131 : loss : 0.014239, loss_ce: 0.006883
2022-01-08 19:25:06,319 iteration 6132 : loss : 0.017107, loss_ce: 0.011104
2022-01-08 19:25:08,852 iteration 6133 : loss : 0.016974, loss_ce: 0.005643
2022-01-08 19:25:11,236 iteration 6134 : loss : 0.014659, loss_ce: 0.004678
2022-01-08 19:25:13,865 iteration 6135 : loss : 0.034862, loss_ce: 0.011048
2022-01-08 19:25:16,237 iteration 6136 : loss : 0.013568, loss_ce: 0.003587
2022-01-08 19:25:18,650 iteration 6137 : loss : 0.015119, loss_ce: 0.005716
 90%|██████████████████████████▏  | 361/400 [4:25:25<30:06, 46.32s/it]2022-01-08 19:25:21,100 iteration 6138 : loss : 0.018505, loss_ce: 0.005542
2022-01-08 19:25:23,472 iteration 6139 : loss : 0.012372, loss_ce: 0.004845
2022-01-08 19:25:25,898 iteration 6140 : loss : 0.012692, loss_ce: 0.006133
2022-01-08 19:25:28,262 iteration 6141 : loss : 0.009463, loss_ce: 0.003412
2022-01-08 19:25:30,794 iteration 6142 : loss : 0.009630, loss_ce: 0.004268
2022-01-08 19:25:33,211 iteration 6143 : loss : 0.014271, loss_ce: 0.003598
2022-01-08 19:25:35,609 iteration 6144 : loss : 0.012630, loss_ce: 0.004276
2022-01-08 19:25:38,032 iteration 6145 : loss : 0.012117, loss_ce: 0.005253
2022-01-08 19:25:40,440 iteration 6146 : loss : 0.017843, loss_ce: 0.003937
2022-01-08 19:25:42,878 iteration 6147 : loss : 0.011676, loss_ce: 0.005018
2022-01-08 19:25:45,542 iteration 6148 : loss : 0.016253, loss_ce: 0.006104
2022-01-08 19:25:47,946 iteration 6149 : loss : 0.015058, loss_ce: 0.005159
2022-01-08 19:25:50,492 iteration 6150 : loss : 0.020567, loss_ce: 0.006878
2022-01-08 19:25:52,956 iteration 6151 : loss : 0.018443, loss_ce: 0.004242
2022-01-08 19:25:55,394 iteration 6152 : loss : 0.014331, loss_ce: 0.005959
2022-01-08 19:25:57,819 iteration 6153 : loss : 0.015595, loss_ce: 0.004874
2022-01-08 19:26:00,418 iteration 6154 : loss : 0.020505, loss_ce: 0.008925
 90%|██████████████████████████▏  | 362/400 [4:26:07<28:28, 44.95s/it]2022-01-08 19:26:02,913 iteration 6155 : loss : 0.020241, loss_ce: 0.007924
2022-01-08 19:26:05,314 iteration 6156 : loss : 0.015708, loss_ce: 0.006281
2022-01-08 19:26:07,877 iteration 6157 : loss : 0.013595, loss_ce: 0.005064
2022-01-08 19:26:10,328 iteration 6158 : loss : 0.013716, loss_ce: 0.003413
2022-01-08 19:26:12,695 iteration 6159 : loss : 0.012096, loss_ce: 0.004152
2022-01-08 19:26:15,049 iteration 6160 : loss : 0.011879, loss_ce: 0.004736
2022-01-08 19:26:17,468 iteration 6161 : loss : 0.016146, loss_ce: 0.005267
2022-01-08 19:26:19,997 iteration 6162 : loss : 0.018320, loss_ce: 0.004972
2022-01-08 19:26:22,464 iteration 6163 : loss : 0.015144, loss_ce: 0.005811
2022-01-08 19:26:24,846 iteration 6164 : loss : 0.010626, loss_ce: 0.002995
2022-01-08 19:26:27,358 iteration 6165 : loss : 0.014067, loss_ce: 0.005404
2022-01-08 19:26:29,766 iteration 6166 : loss : 0.012089, loss_ce: 0.004503
2022-01-08 19:26:32,297 iteration 6167 : loss : 0.018510, loss_ce: 0.009760
2022-01-08 19:26:34,766 iteration 6168 : loss : 0.015826, loss_ce: 0.005741
2022-01-08 19:26:37,139 iteration 6169 : loss : 0.018771, loss_ce: 0.004589
2022-01-08 19:26:39,538 iteration 6170 : loss : 0.011972, loss_ce: 0.005517
2022-01-08 19:26:41,893 iteration 6171 : loss : 0.015747, loss_ce: 0.006999
 91%|██████████████████████████▎  | 363/400 [4:26:48<27:04, 43.91s/it]2022-01-08 19:26:44,372 iteration 6172 : loss : 0.014246, loss_ce: 0.005273
2022-01-08 19:26:46,833 iteration 6173 : loss : 0.025373, loss_ce: 0.006729
2022-01-08 19:26:49,265 iteration 6174 : loss : 0.015630, loss_ce: 0.007032
2022-01-08 19:26:51,886 iteration 6175 : loss : 0.016507, loss_ce: 0.005509
2022-01-08 19:26:54,327 iteration 6176 : loss : 0.012994, loss_ce: 0.004507
2022-01-08 19:26:56,842 iteration 6177 : loss : 0.010223, loss_ce: 0.004593
2022-01-08 19:26:59,429 iteration 6178 : loss : 0.013717, loss_ce: 0.004732
2022-01-08 19:27:01,839 iteration 6179 : loss : 0.015896, loss_ce: 0.004931
2022-01-08 19:27:04,266 iteration 6180 : loss : 0.020295, loss_ce: 0.008918
2022-01-08 19:27:06,681 iteration 6181 : loss : 0.009776, loss_ce: 0.003116
2022-01-08 19:27:09,055 iteration 6182 : loss : 0.013427, loss_ce: 0.003192
2022-01-08 19:27:11,489 iteration 6183 : loss : 0.014537, loss_ce: 0.005445
2022-01-08 19:27:13,941 iteration 6184 : loss : 0.012984, loss_ce: 0.005367
2022-01-08 19:27:16,517 iteration 6185 : loss : 0.030277, loss_ce: 0.010083
2022-01-08 19:27:18,969 iteration 6186 : loss : 0.011541, loss_ce: 0.004342
2022-01-08 19:27:21,365 iteration 6187 : loss : 0.020452, loss_ce: 0.009574
2022-01-08 19:27:23,852 iteration 6188 : loss : 0.020428, loss_ce: 0.009937
 91%|██████████████████████████▍  | 364/400 [4:27:30<25:59, 43.33s/it]2022-01-08 19:27:26,321 iteration 6189 : loss : 0.013979, loss_ce: 0.003022
2022-01-08 19:27:28,900 iteration 6190 : loss : 0.013929, loss_ce: 0.004487
2022-01-08 19:27:31,260 iteration 6191 : loss : 0.012881, loss_ce: 0.006258
2022-01-08 19:27:33,661 iteration 6192 : loss : 0.009465, loss_ce: 0.003711
2022-01-08 19:27:36,226 iteration 6193 : loss : 0.017222, loss_ce: 0.005312
2022-01-08 19:27:38,627 iteration 6194 : loss : 0.012196, loss_ce: 0.004431
2022-01-08 19:27:41,088 iteration 6195 : loss : 0.019229, loss_ce: 0.007540
2022-01-08 19:27:43,429 iteration 6196 : loss : 0.015419, loss_ce: 0.004754
2022-01-08 19:27:45,966 iteration 6197 : loss : 0.010258, loss_ce: 0.004479
2022-01-08 19:27:48,462 iteration 6198 : loss : 0.035852, loss_ce: 0.012556
2022-01-08 19:27:50,881 iteration 6199 : loss : 0.015196, loss_ce: 0.006244
2022-01-08 19:27:53,272 iteration 6200 : loss : 0.011048, loss_ce: 0.004869
2022-01-08 19:27:55,719 iteration 6201 : loss : 0.011337, loss_ce: 0.004638
2022-01-08 19:27:58,067 iteration 6202 : loss : 0.010694, loss_ce: 0.003647
2022-01-08 19:28:00,636 iteration 6203 : loss : 0.022228, loss_ce: 0.010117
2022-01-08 19:28:02,993 iteration 6204 : loss : 0.010233, loss_ce: 0.004639
2022-01-08 19:28:02,993 Training Data Eval:
2022-01-08 19:28:16,176   Average segmentation loss on training set: 0.0074
2022-01-08 19:28:16,177 Validation Data Eval:
2022-01-08 19:28:20,818   Average segmentation loss on validation set: 0.0652
2022-01-08 19:28:23,436 iteration 6205 : loss : 0.016626, loss_ce: 0.005951
 91%|██████████████████████████▍  | 365/400 [4:28:30<28:07, 48.20s/it]2022-01-08 19:28:25,874 iteration 6206 : loss : 0.015355, loss_ce: 0.006354
2022-01-08 19:28:28,201 iteration 6207 : loss : 0.012016, loss_ce: 0.004850
2022-01-08 19:28:30,587 iteration 6208 : loss : 0.019082, loss_ce: 0.006305
2022-01-08 19:28:32,974 iteration 6209 : loss : 0.014366, loss_ce: 0.005442
2022-01-08 19:28:35,363 iteration 6210 : loss : 0.017825, loss_ce: 0.008532
2022-01-08 19:28:37,776 iteration 6211 : loss : 0.015001, loss_ce: 0.007202
2022-01-08 19:28:40,240 iteration 6212 : loss : 0.011297, loss_ce: 0.004085
2022-01-08 19:28:42,737 iteration 6213 : loss : 0.010264, loss_ce: 0.003521
2022-01-08 19:28:45,186 iteration 6214 : loss : 0.018103, loss_ce: 0.006600
2022-01-08 19:28:47,594 iteration 6215 : loss : 0.014101, loss_ce: 0.004003
2022-01-08 19:28:50,013 iteration 6216 : loss : 0.012261, loss_ce: 0.003785
2022-01-08 19:28:52,471 iteration 6217 : loss : 0.014807, loss_ce: 0.005510
2022-01-08 19:28:54,872 iteration 6218 : loss : 0.011002, loss_ce: 0.004068
2022-01-08 19:28:57,393 iteration 6219 : loss : 0.025190, loss_ce: 0.011482
2022-01-08 19:28:59,723 iteration 6220 : loss : 0.010067, loss_ce: 0.002611
2022-01-08 19:29:02,224 iteration 6221 : loss : 0.016962, loss_ce: 0.005341
2022-01-08 19:29:04,746 iteration 6222 : loss : 0.012854, loss_ce: 0.006204
 92%|██████████████████████████▌  | 366/400 [4:29:11<26:08, 46.13s/it]2022-01-08 19:29:07,358 iteration 6223 : loss : 0.021271, loss_ce: 0.011265
2022-01-08 19:29:09,777 iteration 6224 : loss : 0.014233, loss_ce: 0.006600
2022-01-08 19:29:12,210 iteration 6225 : loss : 0.010597, loss_ce: 0.004904
2022-01-08 19:29:14,779 iteration 6226 : loss : 0.010864, loss_ce: 0.004102
2022-01-08 19:29:17,239 iteration 6227 : loss : 0.011710, loss_ce: 0.004092
2022-01-08 19:29:19,757 iteration 6228 : loss : 0.015339, loss_ce: 0.005605
2022-01-08 19:29:22,312 iteration 6229 : loss : 0.013169, loss_ce: 0.003638
2022-01-08 19:29:24,740 iteration 6230 : loss : 0.020132, loss_ce: 0.003842
2022-01-08 19:29:27,105 iteration 6231 : loss : 0.011957, loss_ce: 0.005417
2022-01-08 19:29:29,525 iteration 6232 : loss : 0.013306, loss_ce: 0.004703
2022-01-08 19:29:31,980 iteration 6233 : loss : 0.024261, loss_ce: 0.008603
2022-01-08 19:29:34,319 iteration 6234 : loss : 0.014849, loss_ce: 0.005707
2022-01-08 19:29:36,774 iteration 6235 : loss : 0.015150, loss_ce: 0.005105
2022-01-08 19:29:39,282 iteration 6236 : loss : 0.021041, loss_ce: 0.007733
2022-01-08 19:29:41,853 iteration 6237 : loss : 0.023797, loss_ce: 0.007322
2022-01-08 19:29:44,367 iteration 6238 : loss : 0.017002, loss_ce: 0.007881
2022-01-08 19:29:46,824 iteration 6239 : loss : 0.016644, loss_ce: 0.007396
 92%|██████████████████████████▌  | 367/400 [4:29:53<24:42, 44.92s/it]2022-01-08 19:29:49,268 iteration 6240 : loss : 0.014849, loss_ce: 0.005023
2022-01-08 19:29:51,679 iteration 6241 : loss : 0.013574, loss_ce: 0.005510
2022-01-08 19:29:54,166 iteration 6242 : loss : 0.016859, loss_ce: 0.008139
2022-01-08 19:29:56,791 iteration 6243 : loss : 0.014495, loss_ce: 0.006553
2022-01-08 19:29:59,183 iteration 6244 : loss : 0.014778, loss_ce: 0.005359
2022-01-08 19:30:01,717 iteration 6245 : loss : 0.010738, loss_ce: 0.004224
2022-01-08 19:30:04,264 iteration 6246 : loss : 0.010008, loss_ce: 0.003921
2022-01-08 19:30:06,691 iteration 6247 : loss : 0.012077, loss_ce: 0.004050
2022-01-08 19:30:09,097 iteration 6248 : loss : 0.022616, loss_ce: 0.005080
2022-01-08 19:30:11,597 iteration 6249 : loss : 0.015835, loss_ce: 0.005167
2022-01-08 19:30:13,955 iteration 6250 : loss : 0.015303, loss_ce: 0.004078
2022-01-08 19:30:16,380 iteration 6251 : loss : 0.018966, loss_ce: 0.010590
2022-01-08 19:30:18,788 iteration 6252 : loss : 0.010575, loss_ce: 0.003256
2022-01-08 19:30:21,245 iteration 6253 : loss : 0.016739, loss_ce: 0.006139
2022-01-08 19:30:23,571 iteration 6254 : loss : 0.008749, loss_ce: 0.003731
2022-01-08 19:30:26,162 iteration 6255 : loss : 0.032859, loss_ce: 0.012608
2022-01-08 19:30:28,615 iteration 6256 : loss : 0.016320, loss_ce: 0.007148
 92%|██████████████████████████▋  | 368/400 [4:30:35<23:27, 43.98s/it]2022-01-08 19:30:31,075 iteration 6257 : loss : 0.016969, loss_ce: 0.007286
2022-01-08 19:30:33,450 iteration 6258 : loss : 0.009244, loss_ce: 0.004494
2022-01-08 19:30:35,998 iteration 6259 : loss : 0.013358, loss_ce: 0.006042
2022-01-08 19:30:38,567 iteration 6260 : loss : 0.016552, loss_ce: 0.004736
2022-01-08 19:30:40,980 iteration 6261 : loss : 0.011985, loss_ce: 0.004829
2022-01-08 19:30:43,384 iteration 6262 : loss : 0.013956, loss_ce: 0.005810
2022-01-08 19:30:45,815 iteration 6263 : loss : 0.015181, loss_ce: 0.004178
2022-01-08 19:30:48,442 iteration 6264 : loss : 0.011953, loss_ce: 0.005460
2022-01-08 19:30:50,804 iteration 6265 : loss : 0.012145, loss_ce: 0.005001
2022-01-08 19:30:53,193 iteration 6266 : loss : 0.012276, loss_ce: 0.005096
2022-01-08 19:30:55,820 iteration 6267 : loss : 0.019520, loss_ce: 0.007440
2022-01-08 19:30:58,224 iteration 6268 : loss : 0.012636, loss_ce: 0.004886
2022-01-08 19:31:00,568 iteration 6269 : loss : 0.019323, loss_ce: 0.005951
2022-01-08 19:31:03,037 iteration 6270 : loss : 0.018191, loss_ce: 0.006373
2022-01-08 19:31:05,513 iteration 6271 : loss : 0.013658, loss_ce: 0.003201
2022-01-08 19:31:08,097 iteration 6272 : loss : 0.009411, loss_ce: 0.002563
2022-01-08 19:31:10,466 iteration 6273 : loss : 0.010849, loss_ce: 0.004847
 92%|██████████████████████████▊  | 369/400 [4:31:17<22:23, 43.34s/it]2022-01-08 19:31:12,993 iteration 6274 : loss : 0.018063, loss_ce: 0.005175
2022-01-08 19:31:15,368 iteration 6275 : loss : 0.014852, loss_ce: 0.006479
2022-01-08 19:31:17,821 iteration 6276 : loss : 0.016909, loss_ce: 0.005266
2022-01-08 19:31:20,414 iteration 6277 : loss : 0.017903, loss_ce: 0.005800
2022-01-08 19:31:22,874 iteration 6278 : loss : 0.017437, loss_ce: 0.006645
2022-01-08 19:31:25,539 iteration 6279 : loss : 0.024339, loss_ce: 0.007024
2022-01-08 19:31:27,970 iteration 6280 : loss : 0.011516, loss_ce: 0.005372
2022-01-08 19:31:30,339 iteration 6281 : loss : 0.012278, loss_ce: 0.004062
2022-01-08 19:31:32,714 iteration 6282 : loss : 0.010521, loss_ce: 0.004233
2022-01-08 19:31:35,338 iteration 6283 : loss : 0.016567, loss_ce: 0.005122
2022-01-08 19:31:37,793 iteration 6284 : loss : 0.011711, loss_ce: 0.005136
2022-01-08 19:31:40,273 iteration 6285 : loss : 0.022871, loss_ce: 0.007050
2022-01-08 19:31:42,723 iteration 6286 : loss : 0.012528, loss_ce: 0.006644
2022-01-08 19:31:45,212 iteration 6287 : loss : 0.011083, loss_ce: 0.003833
2022-01-08 19:31:47,665 iteration 6288 : loss : 0.021928, loss_ce: 0.007637
2022-01-08 19:31:50,129 iteration 6289 : loss : 0.011018, loss_ce: 0.003597
2022-01-08 19:31:50,129 Training Data Eval:
2022-01-08 19:32:03,344   Average segmentation loss on training set: 0.0074
2022-01-08 19:32:03,344 Validation Data Eval:
2022-01-08 19:32:08,012   Average segmentation loss on validation set: 0.0767
2022-01-08 19:32:10,434 iteration 6290 : loss : 0.012100, loss_ce: 0.004324
 92%|██████████████████████████▊  | 370/400 [4:32:17<24:09, 48.33s/it]2022-01-08 19:32:12,884 iteration 6291 : loss : 0.015578, loss_ce: 0.003688
2022-01-08 19:32:15,399 iteration 6292 : loss : 0.010747, loss_ce: 0.003550
2022-01-08 19:32:17,759 iteration 6293 : loss : 0.015575, loss_ce: 0.005758
2022-01-08 19:32:20,200 iteration 6294 : loss : 0.015292, loss_ce: 0.006140
2022-01-08 19:32:22,693 iteration 6295 : loss : 0.014631, loss_ce: 0.005069
2022-01-08 19:32:25,125 iteration 6296 : loss : 0.010852, loss_ce: 0.003936
2022-01-08 19:32:27,770 iteration 6297 : loss : 0.013551, loss_ce: 0.003576
2022-01-08 19:32:30,187 iteration 6298 : loss : 0.011664, loss_ce: 0.004129
2022-01-08 19:32:32,603 iteration 6299 : loss : 0.013585, loss_ce: 0.005202
2022-01-08 19:32:35,154 iteration 6300 : loss : 0.014160, loss_ce: 0.005121
2022-01-08 19:32:37,601 iteration 6301 : loss : 0.015077, loss_ce: 0.005700
2022-01-08 19:32:40,001 iteration 6302 : loss : 0.014496, loss_ce: 0.006307
2022-01-08 19:32:42,582 iteration 6303 : loss : 0.015200, loss_ce: 0.007179
2022-01-08 19:32:44,965 iteration 6304 : loss : 0.011538, loss_ce: 0.004535
2022-01-08 19:32:47,268 iteration 6305 : loss : 0.010252, loss_ce: 0.004278
2022-01-08 19:32:49,797 iteration 6306 : loss : 0.013363, loss_ce: 0.004820
2022-01-08 19:32:52,239 iteration 6307 : loss : 0.012866, loss_ce: 0.004348
 93%|██████████████████████████▉  | 371/400 [4:32:59<22:24, 46.37s/it]2022-01-08 19:32:54,761 iteration 6308 : loss : 0.014027, loss_ce: 0.006210
2022-01-08 19:32:57,320 iteration 6309 : loss : 0.021656, loss_ce: 0.007832
2022-01-08 19:32:59,712 iteration 6310 : loss : 0.014200, loss_ce: 0.005766
2022-01-08 19:33:02,125 iteration 6311 : loss : 0.014207, loss_ce: 0.003755
2022-01-08 19:33:04,681 iteration 6312 : loss : 0.017190, loss_ce: 0.007206
2022-01-08 19:33:07,115 iteration 6313 : loss : 0.009096, loss_ce: 0.002111
2022-01-08 19:33:09,608 iteration 6314 : loss : 0.015390, loss_ce: 0.005297
2022-01-08 19:33:12,222 iteration 6315 : loss : 0.015385, loss_ce: 0.005320
2022-01-08 19:33:14,711 iteration 6316 : loss : 0.018295, loss_ce: 0.008371
2022-01-08 19:33:17,120 iteration 6317 : loss : 0.011439, loss_ce: 0.004218
2022-01-08 19:33:19,812 iteration 6318 : loss : 0.016111, loss_ce: 0.007313
2022-01-08 19:33:22,290 iteration 6319 : loss : 0.019656, loss_ce: 0.006025
2022-01-08 19:33:24,689 iteration 6320 : loss : 0.012929, loss_ce: 0.004811
2022-01-08 19:33:27,182 iteration 6321 : loss : 0.017320, loss_ce: 0.007788
2022-01-08 19:33:29,641 iteration 6322 : loss : 0.014913, loss_ce: 0.006462
2022-01-08 19:33:32,052 iteration 6323 : loss : 0.009444, loss_ce: 0.004366
2022-01-08 19:33:34,511 iteration 6324 : loss : 0.013760, loss_ce: 0.003653
 93%|██████████████████████████▉  | 372/400 [4:33:41<21:04, 45.14s/it]2022-01-08 19:33:37,009 iteration 6325 : loss : 0.013012, loss_ce: 0.004408
2022-01-08 19:33:39,459 iteration 6326 : loss : 0.008867, loss_ce: 0.003789
2022-01-08 19:33:41,849 iteration 6327 : loss : 0.009758, loss_ce: 0.003509
2022-01-08 19:33:44,434 iteration 6328 : loss : 0.023465, loss_ce: 0.013453
2022-01-08 19:33:46,900 iteration 6329 : loss : 0.014666, loss_ce: 0.006235
2022-01-08 19:33:49,491 iteration 6330 : loss : 0.013107, loss_ce: 0.005225
2022-01-08 19:33:51,918 iteration 6331 : loss : 0.013155, loss_ce: 0.005631
2022-01-08 19:33:54,344 iteration 6332 : loss : 0.013926, loss_ce: 0.005175
2022-01-08 19:33:56,871 iteration 6333 : loss : 0.013183, loss_ce: 0.005334
2022-01-08 19:33:59,329 iteration 6334 : loss : 0.009331, loss_ce: 0.003764
2022-01-08 19:34:02,010 iteration 6335 : loss : 0.018063, loss_ce: 0.008291
2022-01-08 19:34:04,430 iteration 6336 : loss : 0.012887, loss_ce: 0.004189
2022-01-08 19:34:06,943 iteration 6337 : loss : 0.012630, loss_ce: 0.004841
2022-01-08 19:34:09,390 iteration 6338 : loss : 0.015819, loss_ce: 0.005118
2022-01-08 19:34:11,726 iteration 6339 : loss : 0.010056, loss_ce: 0.003354
2022-01-08 19:34:14,302 iteration 6340 : loss : 0.017643, loss_ce: 0.009525
2022-01-08 19:34:16,708 iteration 6341 : loss : 0.015968, loss_ce: 0.004368
 93%|███████████████████████████  | 373/400 [4:34:23<19:54, 44.26s/it]2022-01-08 19:34:19,234 iteration 6342 : loss : 0.016324, loss_ce: 0.006129
2022-01-08 19:34:21,695 iteration 6343 : loss : 0.012508, loss_ce: 0.003735
2022-01-08 19:34:24,318 iteration 6344 : loss : 0.012545, loss_ce: 0.005467
2022-01-08 19:34:26,745 iteration 6345 : loss : 0.016404, loss_ce: 0.008128
2022-01-08 19:34:29,246 iteration 6346 : loss : 0.012197, loss_ce: 0.003335
2022-01-08 19:34:31,621 iteration 6347 : loss : 0.013244, loss_ce: 0.005837
2022-01-08 19:34:34,175 iteration 6348 : loss : 0.019077, loss_ce: 0.006930
2022-01-08 19:34:36,576 iteration 6349 : loss : 0.010838, loss_ce: 0.004574
2022-01-08 19:34:39,007 iteration 6350 : loss : 0.012265, loss_ce: 0.003346
2022-01-08 19:34:41,540 iteration 6351 : loss : 0.012062, loss_ce: 0.004155
2022-01-08 19:34:43,972 iteration 6352 : loss : 0.011286, loss_ce: 0.004362
2022-01-08 19:34:46,586 iteration 6353 : loss : 0.014207, loss_ce: 0.005681
2022-01-08 19:34:49,108 iteration 6354 : loss : 0.013618, loss_ce: 0.005353
2022-01-08 19:34:51,558 iteration 6355 : loss : 0.016734, loss_ce: 0.007802
2022-01-08 19:34:54,045 iteration 6356 : loss : 0.014350, loss_ce: 0.006466
2022-01-08 19:34:56,488 iteration 6357 : loss : 0.017973, loss_ce: 0.006489
2022-01-08 19:34:58,934 iteration 6358 : loss : 0.015009, loss_ce: 0.005968
 94%|███████████████████████████  | 374/400 [4:35:05<18:54, 43.65s/it]2022-01-08 19:35:01,332 iteration 6359 : loss : 0.013323, loss_ce: 0.004415
2022-01-08 19:35:03,835 iteration 6360 : loss : 0.014722, loss_ce: 0.004596
2022-01-08 19:35:06,262 iteration 6361 : loss : 0.015606, loss_ce: 0.004159
2022-01-08 19:35:08,677 iteration 6362 : loss : 0.011644, loss_ce: 0.005180
2022-01-08 19:35:11,147 iteration 6363 : loss : 0.021326, loss_ce: 0.010957
2022-01-08 19:35:13,650 iteration 6364 : loss : 0.007854, loss_ce: 0.002846
2022-01-08 19:35:16,041 iteration 6365 : loss : 0.012698, loss_ce: 0.004905
2022-01-08 19:35:18,459 iteration 6366 : loss : 0.014701, loss_ce: 0.005850
2022-01-08 19:35:20,862 iteration 6367 : loss : 0.011743, loss_ce: 0.004974
2022-01-08 19:35:23,264 iteration 6368 : loss : 0.013259, loss_ce: 0.004581
2022-01-08 19:35:25,742 iteration 6369 : loss : 0.016612, loss_ce: 0.008732
2022-01-08 19:35:28,235 iteration 6370 : loss : 0.024476, loss_ce: 0.007171
2022-01-08 19:35:30,689 iteration 6371 : loss : 0.015733, loss_ce: 0.005635
2022-01-08 19:35:33,235 iteration 6372 : loss : 0.012986, loss_ce: 0.006993
2022-01-08 19:35:35,525 iteration 6373 : loss : 0.007969, loss_ce: 0.002102
2022-01-08 19:35:37,936 iteration 6374 : loss : 0.008968, loss_ce: 0.003500
2022-01-08 19:35:37,936 Training Data Eval:
2022-01-08 19:35:51,100   Average segmentation loss on training set: 0.0067
2022-01-08 19:35:51,101 Validation Data Eval:
2022-01-08 19:35:55,719   Average segmentation loss on validation set: 0.0651
2022-01-08 19:35:58,107 iteration 6375 : loss : 0.013219, loss_ce: 0.004631
 94%|███████████████████████████▏ | 375/400 [4:36:04<20:07, 48.31s/it]2022-01-08 19:36:00,774 iteration 6376 : loss : 0.020854, loss_ce: 0.008280
2022-01-08 19:36:03,186 iteration 6377 : loss : 0.018623, loss_ce: 0.008223
2022-01-08 19:36:05,664 iteration 6378 : loss : 0.013379, loss_ce: 0.004522
2022-01-08 19:36:08,081 iteration 6379 : loss : 0.015872, loss_ce: 0.004105
2022-01-08 19:36:10,456 iteration 6380 : loss : 0.009701, loss_ce: 0.004489
2022-01-08 19:36:12,832 iteration 6381 : loss : 0.012532, loss_ce: 0.004558
2022-01-08 19:36:15,327 iteration 6382 : loss : 0.015435, loss_ce: 0.006276
2022-01-08 19:36:17,789 iteration 6383 : loss : 0.015601, loss_ce: 0.006130
2022-01-08 19:36:20,266 iteration 6384 : loss : 0.011910, loss_ce: 0.004625
2022-01-08 19:36:22,706 iteration 6385 : loss : 0.022614, loss_ce: 0.010697
2022-01-08 19:36:25,118 iteration 6386 : loss : 0.012929, loss_ce: 0.004217
2022-01-08 19:36:27,700 iteration 6387 : loss : 0.016814, loss_ce: 0.007208
2022-01-08 19:36:30,145 iteration 6388 : loss : 0.008940, loss_ce: 0.003059
2022-01-08 19:36:32,480 iteration 6389 : loss : 0.015533, loss_ce: 0.004329
2022-01-08 19:36:35,001 iteration 6390 : loss : 0.010959, loss_ce: 0.003995
2022-01-08 19:36:37,648 iteration 6391 : loss : 0.015788, loss_ce: 0.004619
2022-01-08 19:36:39,970 iteration 6392 : loss : 0.011293, loss_ce: 0.005103
 94%|███████████████████████████▎ | 376/400 [4:36:46<18:32, 46.37s/it]2022-01-08 19:36:42,394 iteration 6393 : loss : 0.008862, loss_ce: 0.002686
2022-01-08 19:36:44,825 iteration 6394 : loss : 0.019340, loss_ce: 0.006952
2022-01-08 19:36:47,349 iteration 6395 : loss : 0.009341, loss_ce: 0.004260
2022-01-08 19:36:49,957 iteration 6396 : loss : 0.016306, loss_ce: 0.006600
2022-01-08 19:36:52,376 iteration 6397 : loss : 0.015835, loss_ce: 0.005749
2022-01-08 19:36:54,839 iteration 6398 : loss : 0.012342, loss_ce: 0.003849
2022-01-08 19:36:57,318 iteration 6399 : loss : 0.014076, loss_ce: 0.004787
2022-01-08 19:36:59,799 iteration 6400 : loss : 0.016995, loss_ce: 0.009228
2022-01-08 19:37:02,230 iteration 6401 : loss : 0.011707, loss_ce: 0.005008
2022-01-08 19:37:04,670 iteration 6402 : loss : 0.017949, loss_ce: 0.007543
2022-01-08 19:37:07,164 iteration 6403 : loss : 0.016575, loss_ce: 0.005911
2022-01-08 19:37:09,637 iteration 6404 : loss : 0.011681, loss_ce: 0.003638
2022-01-08 19:37:12,086 iteration 6405 : loss : 0.015977, loss_ce: 0.005520
2022-01-08 19:37:14,762 iteration 6406 : loss : 0.013953, loss_ce: 0.006031
2022-01-08 19:37:17,181 iteration 6407 : loss : 0.013571, loss_ce: 0.004092
2022-01-08 19:37:19,593 iteration 6408 : loss : 0.016486, loss_ce: 0.004733
2022-01-08 19:37:22,073 iteration 6409 : loss : 0.013953, loss_ce: 0.005138
 94%|███████████████████████████▎ | 377/400 [4:37:28<17:17, 45.09s/it]2022-01-08 19:37:24,606 iteration 6410 : loss : 0.018914, loss_ce: 0.008130
2022-01-08 19:37:27,028 iteration 6411 : loss : 0.015056, loss_ce: 0.006198
2022-01-08 19:37:29,478 iteration 6412 : loss : 0.013919, loss_ce: 0.006717
2022-01-08 19:37:31,936 iteration 6413 : loss : 0.011916, loss_ce: 0.004853
2022-01-08 19:37:34,393 iteration 6414 : loss : 0.015807, loss_ce: 0.006063
2022-01-08 19:37:36,908 iteration 6415 : loss : 0.014617, loss_ce: 0.004596
2022-01-08 19:37:39,348 iteration 6416 : loss : 0.017338, loss_ce: 0.004470
2022-01-08 19:37:41,770 iteration 6417 : loss : 0.018960, loss_ce: 0.008849
2022-01-08 19:37:44,262 iteration 6418 : loss : 0.010572, loss_ce: 0.004222
2022-01-08 19:37:46,717 iteration 6419 : loss : 0.013989, loss_ce: 0.004650
2022-01-08 19:37:49,310 iteration 6420 : loss : 0.012380, loss_ce: 0.003853
2022-01-08 19:37:51,780 iteration 6421 : loss : 0.010057, loss_ce: 0.003537
2022-01-08 19:37:54,176 iteration 6422 : loss : 0.013325, loss_ce: 0.005281
2022-01-08 19:37:56,664 iteration 6423 : loss : 0.016956, loss_ce: 0.005468
2022-01-08 19:37:59,171 iteration 6424 : loss : 0.014440, loss_ce: 0.006658
2022-01-08 19:38:01,682 iteration 6425 : loss : 0.011818, loss_ce: 0.004293
2022-01-08 19:38:04,109 iteration 6426 : loss : 0.013383, loss_ce: 0.005800
 94%|███████████████████████████▍ | 378/400 [4:38:10<16:11, 44.18s/it]2022-01-08 19:38:06,728 iteration 6427 : loss : 0.014795, loss_ce: 0.006185
2022-01-08 19:38:09,109 iteration 6428 : loss : 0.009902, loss_ce: 0.004705
2022-01-08 19:38:11,710 iteration 6429 : loss : 0.015740, loss_ce: 0.005301
2022-01-08 19:38:14,184 iteration 6430 : loss : 0.012177, loss_ce: 0.003207
2022-01-08 19:38:16,566 iteration 6431 : loss : 0.014493, loss_ce: 0.004909
2022-01-08 19:38:18,940 iteration 6432 : loss : 0.011321, loss_ce: 0.004058
2022-01-08 19:38:21,623 iteration 6433 : loss : 0.014097, loss_ce: 0.005305
2022-01-08 19:38:23,947 iteration 6434 : loss : 0.008070, loss_ce: 0.002952
2022-01-08 19:38:26,490 iteration 6435 : loss : 0.011584, loss_ce: 0.005088
2022-01-08 19:38:28,922 iteration 6436 : loss : 0.012005, loss_ce: 0.005605
2022-01-08 19:38:31,493 iteration 6437 : loss : 0.024492, loss_ce: 0.007004
2022-01-08 19:38:33,939 iteration 6438 : loss : 0.015146, loss_ce: 0.006662
2022-01-08 19:38:36,350 iteration 6439 : loss : 0.010870, loss_ce: 0.004239
2022-01-08 19:38:38,942 iteration 6440 : loss : 0.022245, loss_ce: 0.009456
2022-01-08 19:38:41,419 iteration 6441 : loss : 0.012814, loss_ce: 0.003634
2022-01-08 19:38:43,824 iteration 6442 : loss : 0.015160, loss_ce: 0.007133
2022-01-08 19:38:46,366 iteration 6443 : loss : 0.014489, loss_ce: 0.005478
 95%|███████████████████████████▍ | 379/400 [4:38:53<15:15, 43.60s/it]2022-01-08 19:38:49,067 iteration 6444 : loss : 0.015508, loss_ce: 0.006480
2022-01-08 19:38:51,521 iteration 6445 : loss : 0.019427, loss_ce: 0.007616
2022-01-08 19:38:54,039 iteration 6446 : loss : 0.012917, loss_ce: 0.003489
2022-01-08 19:38:56,460 iteration 6447 : loss : 0.020161, loss_ce: 0.010591
2022-01-08 19:38:58,842 iteration 6448 : loss : 0.011624, loss_ce: 0.005161
2022-01-08 19:39:01,279 iteration 6449 : loss : 0.013988, loss_ce: 0.004388
2022-01-08 19:39:03,809 iteration 6450 : loss : 0.009746, loss_ce: 0.004063
2022-01-08 19:39:06,262 iteration 6451 : loss : 0.012212, loss_ce: 0.004472
2022-01-08 19:39:08,667 iteration 6452 : loss : 0.011487, loss_ce: 0.005014
2022-01-08 19:39:11,102 iteration 6453 : loss : 0.015029, loss_ce: 0.007414
2022-01-08 19:39:13,545 iteration 6454 : loss : 0.014274, loss_ce: 0.005653
2022-01-08 19:39:15,978 iteration 6455 : loss : 0.010334, loss_ce: 0.003127
2022-01-08 19:39:18,602 iteration 6456 : loss : 0.024920, loss_ce: 0.009538
2022-01-08 19:39:21,004 iteration 6457 : loss : 0.012122, loss_ce: 0.003541
2022-01-08 19:39:23,539 iteration 6458 : loss : 0.015220, loss_ce: 0.005730
2022-01-08 19:39:25,918 iteration 6459 : loss : 0.010615, loss_ce: 0.003611
2022-01-08 19:39:25,918 Training Data Eval:
2022-01-08 19:39:39,130   Average segmentation loss on training set: 0.0067
2022-01-08 19:39:39,130 Validation Data Eval:
2022-01-08 19:39:43,748   Average segmentation loss on validation set: 0.0774
2022-01-08 19:39:46,236 iteration 6460 : loss : 0.017426, loss_ce: 0.004630
 95%|███████████████████████████▌ | 380/400 [4:39:53<16:09, 48.48s/it]2022-01-08 19:39:48,751 iteration 6461 : loss : 0.018014, loss_ce: 0.004756
2022-01-08 19:39:51,225 iteration 6462 : loss : 0.016076, loss_ce: 0.006669
2022-01-08 19:39:53,648 iteration 6463 : loss : 0.007857, loss_ce: 0.002217
2022-01-08 19:39:56,009 iteration 6464 : loss : 0.013741, loss_ce: 0.005806
2022-01-08 19:39:58,412 iteration 6465 : loss : 0.020468, loss_ce: 0.006110
2022-01-08 19:40:00,978 iteration 6466 : loss : 0.013935, loss_ce: 0.005110
2022-01-08 19:40:03,426 iteration 6467 : loss : 0.013444, loss_ce: 0.006096
2022-01-08 19:40:05,963 iteration 6468 : loss : 0.016959, loss_ce: 0.010000
2022-01-08 19:40:08,429 iteration 6469 : loss : 0.011741, loss_ce: 0.005777
2022-01-08 19:40:10,896 iteration 6470 : loss : 0.016787, loss_ce: 0.004665
2022-01-08 19:40:13,325 iteration 6471 : loss : 0.010289, loss_ce: 0.003541
2022-01-08 19:40:15,761 iteration 6472 : loss : 0.013634, loss_ce: 0.003973
2022-01-08 19:40:18,148 iteration 6473 : loss : 0.011514, loss_ce: 0.005851
2022-01-08 19:40:20,576 iteration 6474 : loss : 0.013223, loss_ce: 0.006608
2022-01-08 19:40:22,922 iteration 6475 : loss : 0.008520, loss_ce: 0.002664
2022-01-08 19:40:25,531 iteration 6476 : loss : 0.012071, loss_ce: 0.004476
2022-01-08 19:40:27,875 iteration 6477 : loss : 0.011101, loss_ce: 0.003824
 95%|███████████████████████████▌ | 381/400 [4:40:34<14:42, 46.43s/it]2022-01-08 19:40:30,332 iteration 6478 : loss : 0.013584, loss_ce: 0.005611
2022-01-08 19:40:33,010 iteration 6479 : loss : 0.016409, loss_ce: 0.008807
2022-01-08 19:40:35,452 iteration 6480 : loss : 0.025562, loss_ce: 0.006629
2022-01-08 19:40:38,071 iteration 6481 : loss : 0.013397, loss_ce: 0.005394
2022-01-08 19:40:40,577 iteration 6482 : loss : 0.018127, loss_ce: 0.006428
2022-01-08 19:40:42,973 iteration 6483 : loss : 0.013559, loss_ce: 0.005012
2022-01-08 19:40:45,348 iteration 6484 : loss : 0.011435, loss_ce: 0.003501
2022-01-08 19:40:47,910 iteration 6485 : loss : 0.017218, loss_ce: 0.008094
2022-01-08 19:40:50,365 iteration 6486 : loss : 0.011852, loss_ce: 0.004088
2022-01-08 19:40:52,833 iteration 6487 : loss : 0.014253, loss_ce: 0.004820
2022-01-08 19:40:55,197 iteration 6488 : loss : 0.008719, loss_ce: 0.003496
2022-01-08 19:40:57,773 iteration 6489 : loss : 0.016160, loss_ce: 0.004191
2022-01-08 19:41:00,093 iteration 6490 : loss : 0.009656, loss_ce: 0.003384
2022-01-08 19:41:02,537 iteration 6491 : loss : 0.014334, loss_ce: 0.003965
2022-01-08 19:41:04,927 iteration 6492 : loss : 0.010956, loss_ce: 0.003860
2022-01-08 19:41:07,478 iteration 6493 : loss : 0.017083, loss_ce: 0.004529
2022-01-08 19:41:10,034 iteration 6494 : loss : 0.013616, loss_ce: 0.005136
 96%|███████████████████████████▋ | 382/400 [4:41:16<13:32, 45.15s/it]2022-01-08 19:41:12,526 iteration 6495 : loss : 0.010791, loss_ce: 0.003526
2022-01-08 19:41:14,970 iteration 6496 : loss : 0.011436, loss_ce: 0.004655
2022-01-08 19:41:17,422 iteration 6497 : loss : 0.010913, loss_ce: 0.003835
2022-01-08 19:41:19,825 iteration 6498 : loss : 0.021026, loss_ce: 0.010555
2022-01-08 19:41:22,392 iteration 6499 : loss : 0.019232, loss_ce: 0.006411
2022-01-08 19:41:24,954 iteration 6500 : loss : 0.018965, loss_ce: 0.007042
2022-01-08 19:41:27,376 iteration 6501 : loss : 0.019600, loss_ce: 0.004323
2022-01-08 19:41:30,022 iteration 6502 : loss : 0.016831, loss_ce: 0.007211
2022-01-08 19:41:32,513 iteration 6503 : loss : 0.017073, loss_ce: 0.006204
2022-01-08 19:41:34,879 iteration 6504 : loss : 0.012895, loss_ce: 0.006766
2022-01-08 19:41:37,315 iteration 6505 : loss : 0.011547, loss_ce: 0.003004
2022-01-08 19:41:39,749 iteration 6506 : loss : 0.011931, loss_ce: 0.003603
2022-01-08 19:41:42,155 iteration 6507 : loss : 0.014116, loss_ce: 0.006304
2022-01-08 19:41:44,692 iteration 6508 : loss : 0.011186, loss_ce: 0.004071
2022-01-08 19:41:47,207 iteration 6509 : loss : 0.010814, loss_ce: 0.004593
2022-01-08 19:41:49,755 iteration 6510 : loss : 0.011306, loss_ce: 0.003759
2022-01-08 19:41:52,136 iteration 6511 : loss : 0.011868, loss_ce: 0.005049
 96%|███████████████████████████▊ | 383/400 [4:41:59<12:31, 44.24s/it]2022-01-08 19:41:54,579 iteration 6512 : loss : 0.013613, loss_ce: 0.005749
2022-01-08 19:41:56,896 iteration 6513 : loss : 0.014074, loss_ce: 0.004872
2022-01-08 19:41:59,275 iteration 6514 : loss : 0.009969, loss_ce: 0.002452
2022-01-08 19:42:01,871 iteration 6515 : loss : 0.011291, loss_ce: 0.003348
2022-01-08 19:42:04,285 iteration 6516 : loss : 0.012755, loss_ce: 0.003755
2022-01-08 19:42:06,931 iteration 6517 : loss : 0.015689, loss_ce: 0.008230
2022-01-08 19:42:09,286 iteration 6518 : loss : 0.014169, loss_ce: 0.005981
2022-01-08 19:42:11,773 iteration 6519 : loss : 0.017634, loss_ce: 0.005973
2022-01-08 19:42:14,339 iteration 6520 : loss : 0.012148, loss_ce: 0.005456
2022-01-08 19:42:16,750 iteration 6521 : loss : 0.010645, loss_ce: 0.004446
2022-01-08 19:42:19,086 iteration 6522 : loss : 0.015094, loss_ce: 0.005678
2022-01-08 19:42:21,564 iteration 6523 : loss : 0.014784, loss_ce: 0.004961
2022-01-08 19:42:23,955 iteration 6524 : loss : 0.020333, loss_ce: 0.007075
2022-01-08 19:42:26,340 iteration 6525 : loss : 0.009373, loss_ce: 0.002964
2022-01-08 19:42:28,782 iteration 6526 : loss : 0.009871, loss_ce: 0.003513
2022-01-08 19:42:31,236 iteration 6527 : loss : 0.012708, loss_ce: 0.004543
2022-01-08 19:42:33,658 iteration 6528 : loss : 0.012546, loss_ce: 0.005069
 96%|███████████████████████████▊ | 384/400 [4:42:40<11:34, 43.42s/it]2022-01-08 19:42:36,276 iteration 6529 : loss : 0.010699, loss_ce: 0.003988
2022-01-08 19:42:38,848 iteration 6530 : loss : 0.009383, loss_ce: 0.004328
2022-01-08 19:42:41,261 iteration 6531 : loss : 0.009763, loss_ce: 0.002184
2022-01-08 19:42:43,656 iteration 6532 : loss : 0.011781, loss_ce: 0.003565
2022-01-08 19:42:46,109 iteration 6533 : loss : 0.010625, loss_ce: 0.004237
2022-01-08 19:42:48,530 iteration 6534 : loss : 0.022219, loss_ce: 0.007144
2022-01-08 19:42:50,913 iteration 6535 : loss : 0.017371, loss_ce: 0.006070
2022-01-08 19:42:53,375 iteration 6536 : loss : 0.015141, loss_ce: 0.005718
2022-01-08 19:42:55,885 iteration 6537 : loss : 0.022486, loss_ce: 0.008965
2022-01-08 19:42:58,311 iteration 6538 : loss : 0.012451, loss_ce: 0.004064
2022-01-08 19:43:00,801 iteration 6539 : loss : 0.015172, loss_ce: 0.006634
2022-01-08 19:43:03,310 iteration 6540 : loss : 0.017422, loss_ce: 0.008308
2022-01-08 19:43:05,753 iteration 6541 : loss : 0.009837, loss_ce: 0.004076
2022-01-08 19:43:08,156 iteration 6542 : loss : 0.019944, loss_ce: 0.007908
2022-01-08 19:43:10,608 iteration 6543 : loss : 0.013513, loss_ce: 0.004481
2022-01-08 19:43:13,062 iteration 6544 : loss : 0.015142, loss_ce: 0.006019
2022-01-08 19:43:13,062 Training Data Eval:
2022-01-08 19:43:26,237   Average segmentation loss on training set: 0.0066
2022-01-08 19:43:26,237 Validation Data Eval:
2022-01-08 19:43:30,890   Average segmentation loss on validation set: 0.0691
2022-01-08 19:43:33,304 iteration 6545 : loss : 0.008946, loss_ce: 0.002210
 96%|███████████████████████████▉ | 385/400 [4:43:40<12:04, 48.29s/it]2022-01-08 19:43:35,816 iteration 6546 : loss : 0.017899, loss_ce: 0.006237
2022-01-08 19:43:38,130 iteration 6547 : loss : 0.011206, loss_ce: 0.002380
2022-01-08 19:43:40,565 iteration 6548 : loss : 0.019462, loss_ce: 0.005885
2022-01-08 19:43:43,042 iteration 6549 : loss : 0.019056, loss_ce: 0.006547
2022-01-08 19:43:45,496 iteration 6550 : loss : 0.016479, loss_ce: 0.009102
2022-01-08 19:43:47,948 iteration 6551 : loss : 0.018441, loss_ce: 0.008151
2022-01-08 19:43:50,453 iteration 6552 : loss : 0.016225, loss_ce: 0.006498
2022-01-08 19:43:52,915 iteration 6553 : loss : 0.016686, loss_ce: 0.005938
2022-01-08 19:43:55,582 iteration 6554 : loss : 0.021078, loss_ce: 0.007437
2022-01-08 19:43:57,961 iteration 6555 : loss : 0.015859, loss_ce: 0.005878
2022-01-08 19:44:00,375 iteration 6556 : loss : 0.016312, loss_ce: 0.006350
2022-01-08 19:44:02,876 iteration 6557 : loss : 0.007565, loss_ce: 0.002606
2022-01-08 19:44:05,351 iteration 6558 : loss : 0.015578, loss_ce: 0.005515
2022-01-08 19:44:07,832 iteration 6559 : loss : 0.010411, loss_ce: 0.003951
2022-01-08 19:44:10,261 iteration 6560 : loss : 0.010861, loss_ce: 0.004879
2022-01-08 19:44:12,699 iteration 6561 : loss : 0.011905, loss_ce: 0.004143
2022-01-08 19:44:15,090 iteration 6562 : loss : 0.014066, loss_ce: 0.005857
 96%|███████████████████████████▉ | 386/400 [4:44:21<10:48, 46.34s/it]2022-01-08 19:44:17,696 iteration 6563 : loss : 0.014701, loss_ce: 0.006891
2022-01-08 19:44:20,313 iteration 6564 : loss : 0.016732, loss_ce: 0.005199
2022-01-08 19:44:22,692 iteration 6565 : loss : 0.017832, loss_ce: 0.005768
2022-01-08 19:44:25,151 iteration 6566 : loss : 0.015874, loss_ce: 0.005901
2022-01-08 19:44:27,754 iteration 6567 : loss : 0.018158, loss_ce: 0.005277
2022-01-08 19:44:30,167 iteration 6568 : loss : 0.010814, loss_ce: 0.003955
2022-01-08 19:44:32,526 iteration 6569 : loss : 0.015993, loss_ce: 0.005012
2022-01-08 19:44:35,089 iteration 6570 : loss : 0.016080, loss_ce: 0.005787
2022-01-08 19:44:37,502 iteration 6571 : loss : 0.009932, loss_ce: 0.004157
2022-01-08 19:44:39,882 iteration 6572 : loss : 0.016086, loss_ce: 0.005494
2022-01-08 19:44:42,373 iteration 6573 : loss : 0.009601, loss_ce: 0.002871
2022-01-08 19:44:44,927 iteration 6574 : loss : 0.012715, loss_ce: 0.004824
2022-01-08 19:44:47,302 iteration 6575 : loss : 0.008485, loss_ce: 0.003463
2022-01-08 19:44:49,686 iteration 6576 : loss : 0.023403, loss_ce: 0.010981
2022-01-08 19:44:52,042 iteration 6577 : loss : 0.012658, loss_ce: 0.004496
2022-01-08 19:44:54,535 iteration 6578 : loss : 0.010221, loss_ce: 0.004068
2022-01-08 19:44:56,984 iteration 6579 : loss : 0.014877, loss_ce: 0.004581
 97%|████████████████████████████ | 387/400 [4:45:03<09:45, 45.00s/it]2022-01-08 19:44:59,643 iteration 6580 : loss : 0.016532, loss_ce: 0.006033
2022-01-08 19:45:02,084 iteration 6581 : loss : 0.016438, loss_ce: 0.004769
2022-01-08 19:45:04,603 iteration 6582 : loss : 0.014231, loss_ce: 0.006926
2022-01-08 19:45:07,008 iteration 6583 : loss : 0.013533, loss_ce: 0.006810
2022-01-08 19:45:09,450 iteration 6584 : loss : 0.014840, loss_ce: 0.005481
2022-01-08 19:45:11,963 iteration 6585 : loss : 0.012819, loss_ce: 0.004177
2022-01-08 19:45:14,434 iteration 6586 : loss : 0.013840, loss_ce: 0.005431
2022-01-08 19:45:16,824 iteration 6587 : loss : 0.010226, loss_ce: 0.004272
2022-01-08 19:45:19,341 iteration 6588 : loss : 0.018728, loss_ce: 0.006622
2022-01-08 19:45:21,937 iteration 6589 : loss : 0.014576, loss_ce: 0.004585
2022-01-08 19:45:24,359 iteration 6590 : loss : 0.013423, loss_ce: 0.005625
2022-01-08 19:45:26,792 iteration 6591 : loss : 0.013159, loss_ce: 0.005710
2022-01-08 19:45:29,181 iteration 6592 : loss : 0.011730, loss_ce: 0.003750
2022-01-08 19:45:31,783 iteration 6593 : loss : 0.015539, loss_ce: 0.006564
2022-01-08 19:45:34,237 iteration 6594 : loss : 0.010202, loss_ce: 0.003595
2022-01-08 19:45:36,622 iteration 6595 : loss : 0.013185, loss_ce: 0.004018
2022-01-08 19:45:38,961 iteration 6596 : loss : 0.007438, loss_ce: 0.002761
 97%|████████████████████████████▏| 388/400 [4:45:45<08:49, 44.10s/it]2022-01-08 19:45:41,656 iteration 6597 : loss : 0.012448, loss_ce: 0.006591
2022-01-08 19:45:44,174 iteration 6598 : loss : 0.021300, loss_ce: 0.004905
2022-01-08 19:45:46,718 iteration 6599 : loss : 0.013634, loss_ce: 0.005035
2022-01-08 19:45:49,138 iteration 6600 : loss : 0.013490, loss_ce: 0.004791
2022-01-08 19:45:51,461 iteration 6601 : loss : 0.013218, loss_ce: 0.005016
2022-01-08 19:45:53,969 iteration 6602 : loss : 0.007955, loss_ce: 0.002732
2022-01-08 19:45:56,374 iteration 6603 : loss : 0.023191, loss_ce: 0.007472
2022-01-08 19:45:58,867 iteration 6604 : loss : 0.015408, loss_ce: 0.006004
2022-01-08 19:46:01,276 iteration 6605 : loss : 0.015264, loss_ce: 0.006508
2022-01-08 19:46:03,747 iteration 6606 : loss : 0.011997, loss_ce: 0.006529
2022-01-08 19:46:06,173 iteration 6607 : loss : 0.015009, loss_ce: 0.006150
2022-01-08 19:46:08,663 iteration 6608 : loss : 0.016088, loss_ce: 0.006591
2022-01-08 19:46:11,109 iteration 6609 : loss : 0.012778, loss_ce: 0.004870
2022-01-08 19:46:13,647 iteration 6610 : loss : 0.027653, loss_ce: 0.007406
2022-01-08 19:46:16,011 iteration 6611 : loss : 0.010634, loss_ce: 0.004778
2022-01-08 19:46:18,480 iteration 6612 : loss : 0.012354, loss_ce: 0.004550
2022-01-08 19:46:21,117 iteration 6613 : loss : 0.019862, loss_ce: 0.005777
 97%|████████████████████████████▏| 389/400 [4:46:27<07:58, 43.51s/it]2022-01-08 19:46:23,512 iteration 6614 : loss : 0.008324, loss_ce: 0.003282
2022-01-08 19:46:26,100 iteration 6615 : loss : 0.014198, loss_ce: 0.005352
2022-01-08 19:46:28,547 iteration 6616 : loss : 0.012330, loss_ce: 0.005043
2022-01-08 19:46:31,030 iteration 6617 : loss : 0.014802, loss_ce: 0.002580
2022-01-08 19:46:33,615 iteration 6618 : loss : 0.013258, loss_ce: 0.004529
2022-01-08 19:46:36,036 iteration 6619 : loss : 0.017428, loss_ce: 0.007112
2022-01-08 19:46:38,432 iteration 6620 : loss : 0.019184, loss_ce: 0.007355
2022-01-08 19:46:40,848 iteration 6621 : loss : 0.010967, loss_ce: 0.004593
2022-01-08 19:46:43,189 iteration 6622 : loss : 0.008589, loss_ce: 0.002875
2022-01-08 19:46:45,744 iteration 6623 : loss : 0.013432, loss_ce: 0.006360
2022-01-08 19:46:48,038 iteration 6624 : loss : 0.010902, loss_ce: 0.003941
2022-01-08 19:46:50,473 iteration 6625 : loss : 0.008256, loss_ce: 0.003369
2022-01-08 19:46:52,875 iteration 6626 : loss : 0.017338, loss_ce: 0.006146
2022-01-08 19:46:55,374 iteration 6627 : loss : 0.008506, loss_ce: 0.002890
2022-01-08 19:46:57,815 iteration 6628 : loss : 0.017687, loss_ce: 0.006912
2022-01-08 19:47:00,293 iteration 6629 : loss : 0.010619, loss_ce: 0.004426
2022-01-08 19:47:00,293 Training Data Eval:
2022-01-08 19:47:13,582   Average segmentation loss on training set: 0.0066
2022-01-08 19:47:13,582 Validation Data Eval:
2022-01-08 19:47:18,112   Average segmentation loss on validation set: 0.0724
2022-01-08 19:47:20,652 iteration 6630 : loss : 0.019915, loss_ce: 0.008021
 98%|████████████████████████████▎| 390/400 [4:47:27<08:03, 48.32s/it]2022-01-08 19:47:22,976 iteration 6631 : loss : 0.009756, loss_ce: 0.003696
2022-01-08 19:47:25,446 iteration 6632 : loss : 0.016575, loss_ce: 0.003578
2022-01-08 19:47:27,919 iteration 6633 : loss : 0.015291, loss_ce: 0.006227
2022-01-08 19:47:30,282 iteration 6634 : loss : 0.011189, loss_ce: 0.004741
2022-01-08 19:47:32,729 iteration 6635 : loss : 0.016293, loss_ce: 0.005876
2022-01-08 19:47:35,121 iteration 6636 : loss : 0.009973, loss_ce: 0.004962
2022-01-08 19:47:37,672 iteration 6637 : loss : 0.026082, loss_ce: 0.009034
2022-01-08 19:47:40,203 iteration 6638 : loss : 0.008563, loss_ce: 0.002513
2022-01-08 19:47:42,601 iteration 6639 : loss : 0.017619, loss_ce: 0.005616
2022-01-08 19:47:45,268 iteration 6640 : loss : 0.012477, loss_ce: 0.003728
2022-01-08 19:47:47,663 iteration 6641 : loss : 0.015746, loss_ce: 0.007813
2022-01-08 19:47:50,036 iteration 6642 : loss : 0.013564, loss_ce: 0.004204
2022-01-08 19:47:52,655 iteration 6643 : loss : 0.015937, loss_ce: 0.007232
2022-01-08 19:47:55,128 iteration 6644 : loss : 0.017507, loss_ce: 0.008288
2022-01-08 19:47:57,579 iteration 6645 : loss : 0.014224, loss_ce: 0.005516
2022-01-08 19:48:00,062 iteration 6646 : loss : 0.012610, loss_ce: 0.005662
2022-01-08 19:48:02,483 iteration 6647 : loss : 0.018954, loss_ce: 0.003826
 98%|████████████████████████████▎| 391/400 [4:48:09<06:57, 46.37s/it]2022-01-08 19:48:04,935 iteration 6648 : loss : 0.014962, loss_ce: 0.005600
2022-01-08 19:48:07,429 iteration 6649 : loss : 0.019817, loss_ce: 0.005075
2022-01-08 19:48:09,821 iteration 6650 : loss : 0.009649, loss_ce: 0.003545
2022-01-08 19:48:12,182 iteration 6651 : loss : 0.012984, loss_ce: 0.005668
2022-01-08 19:48:14,643 iteration 6652 : loss : 0.011518, loss_ce: 0.004894
2022-01-08 19:48:17,081 iteration 6653 : loss : 0.014852, loss_ce: 0.004946
2022-01-08 19:48:19,587 iteration 6654 : loss : 0.016478, loss_ce: 0.005452
2022-01-08 19:48:22,017 iteration 6655 : loss : 0.015800, loss_ce: 0.006029
2022-01-08 19:48:24,646 iteration 6656 : loss : 0.018882, loss_ce: 0.007829
2022-01-08 19:48:27,054 iteration 6657 : loss : 0.020423, loss_ce: 0.006353
2022-01-08 19:48:29,602 iteration 6658 : loss : 0.016251, loss_ce: 0.006321
2022-01-08 19:48:32,002 iteration 6659 : loss : 0.015172, loss_ce: 0.004380
2022-01-08 19:48:34,394 iteration 6660 : loss : 0.011550, loss_ce: 0.004724
2022-01-08 19:48:36,919 iteration 6661 : loss : 0.010747, loss_ce: 0.003746
2022-01-08 19:48:39,339 iteration 6662 : loss : 0.013966, loss_ce: 0.004962
2022-01-08 19:48:41,703 iteration 6663 : loss : 0.009904, loss_ce: 0.003769
2022-01-08 19:48:44,299 iteration 6664 : loss : 0.008807, loss_ce: 0.003859
 98%|████████████████████████████▍| 392/400 [4:48:51<06:00, 45.01s/it]2022-01-08 19:48:46,739 iteration 6665 : loss : 0.028115, loss_ce: 0.009162
2022-01-08 19:48:49,127 iteration 6666 : loss : 0.010102, loss_ce: 0.003153
2022-01-08 19:48:51,547 iteration 6667 : loss : 0.020856, loss_ce: 0.008198
2022-01-08 19:48:54,069 iteration 6668 : loss : 0.014129, loss_ce: 0.006748
2022-01-08 19:48:56,593 iteration 6669 : loss : 0.011998, loss_ce: 0.004171
2022-01-08 19:48:59,039 iteration 6670 : loss : 0.008427, loss_ce: 0.003286
2022-01-08 19:49:01,423 iteration 6671 : loss : 0.011087, loss_ce: 0.004672
2022-01-08 19:49:03,880 iteration 6672 : loss : 0.009236, loss_ce: 0.002469
2022-01-08 19:49:06,449 iteration 6673 : loss : 0.022559, loss_ce: 0.007540
2022-01-08 19:49:09,021 iteration 6674 : loss : 0.011349, loss_ce: 0.005201
2022-01-08 19:49:11,450 iteration 6675 : loss : 0.012828, loss_ce: 0.004102
2022-01-08 19:49:13,804 iteration 6676 : loss : 0.008971, loss_ce: 0.002609
2022-01-08 19:49:16,234 iteration 6677 : loss : 0.012958, loss_ce: 0.003006
2022-01-08 19:49:18,532 iteration 6678 : loss : 0.008436, loss_ce: 0.003592
2022-01-08 19:49:21,026 iteration 6679 : loss : 0.013895, loss_ce: 0.005918
2022-01-08 19:49:23,407 iteration 6680 : loss : 0.015303, loss_ce: 0.005945
2022-01-08 19:49:25,904 iteration 6681 : loss : 0.012788, loss_ce: 0.005799
 98%|████████████████████████████▍| 393/400 [4:49:32<05:07, 43.99s/it]2022-01-08 19:49:28,392 iteration 6682 : loss : 0.013627, loss_ce: 0.007020
2022-01-08 19:49:30,858 iteration 6683 : loss : 0.014904, loss_ce: 0.004192
2022-01-08 19:49:33,278 iteration 6684 : loss : 0.015812, loss_ce: 0.005129
2022-01-08 19:49:35,725 iteration 6685 : loss : 0.014335, loss_ce: 0.006565
2022-01-08 19:49:38,250 iteration 6686 : loss : 0.010483, loss_ce: 0.004736
2022-01-08 19:49:40,619 iteration 6687 : loss : 0.010528, loss_ce: 0.002256
2022-01-08 19:49:43,067 iteration 6688 : loss : 0.022765, loss_ce: 0.009828
2022-01-08 19:49:45,452 iteration 6689 : loss : 0.008521, loss_ce: 0.002870
2022-01-08 19:49:47,880 iteration 6690 : loss : 0.010862, loss_ce: 0.004675
2022-01-08 19:49:50,319 iteration 6691 : loss : 0.022199, loss_ce: 0.008626
2022-01-08 19:49:52,825 iteration 6692 : loss : 0.016057, loss_ce: 0.004776
2022-01-08 19:49:55,273 iteration 6693 : loss : 0.013938, loss_ce: 0.005014
2022-01-08 19:49:57,838 iteration 6694 : loss : 0.010990, loss_ce: 0.004272
2022-01-08 19:50:00,284 iteration 6695 : loss : 0.012158, loss_ce: 0.004987
2022-01-08 19:50:02,681 iteration 6696 : loss : 0.011069, loss_ce: 0.004984
2022-01-08 19:50:05,259 iteration 6697 : loss : 0.015411, loss_ce: 0.005187
2022-01-08 19:50:07,650 iteration 6698 : loss : 0.011829, loss_ce: 0.003812
 98%|████████████████████████████▌| 394/400 [4:50:14<04:19, 43.31s/it]2022-01-08 19:50:10,121 iteration 6699 : loss : 0.011748, loss_ce: 0.006155
2022-01-08 19:50:12,583 iteration 6700 : loss : 0.014569, loss_ce: 0.006436
2022-01-08 19:50:15,036 iteration 6701 : loss : 0.011908, loss_ce: 0.005105
2022-01-08 19:50:17,502 iteration 6702 : loss : 0.015691, loss_ce: 0.005153
2022-01-08 19:50:19,929 iteration 6703 : loss : 0.012030, loss_ce: 0.003425
2022-01-08 19:50:22,435 iteration 6704 : loss : 0.019766, loss_ce: 0.007894
2022-01-08 19:50:24,864 iteration 6705 : loss : 0.013436, loss_ce: 0.004409
2022-01-08 19:50:27,293 iteration 6706 : loss : 0.009342, loss_ce: 0.004672
2022-01-08 19:50:29,702 iteration 6707 : loss : 0.015153, loss_ce: 0.004579
2022-01-08 19:50:32,239 iteration 6708 : loss : 0.010033, loss_ce: 0.003579
2022-01-08 19:50:34,683 iteration 6709 : loss : 0.009657, loss_ce: 0.003238
2022-01-08 19:50:37,088 iteration 6710 : loss : 0.009482, loss_ce: 0.003457
2022-01-08 19:50:39,498 iteration 6711 : loss : 0.012681, loss_ce: 0.002218
2022-01-08 19:50:42,026 iteration 6712 : loss : 0.015411, loss_ce: 0.006018
2022-01-08 19:50:44,484 iteration 6713 : loss : 0.016325, loss_ce: 0.005835
2022-01-08 19:50:46,959 iteration 6714 : loss : 0.016431, loss_ce: 0.008340
2022-01-08 19:50:46,959 Training Data Eval:
2022-01-08 19:51:00,275   Average segmentation loss on training set: 0.0063
2022-01-08 19:51:00,275 Validation Data Eval:
2022-01-08 19:51:04,756   Average segmentation loss on validation set: 0.0740
2022-01-08 19:51:07,265 iteration 6715 : loss : 0.012096, loss_ce: 0.004120
 99%|████████████████████████████▋| 395/400 [4:51:14<04:01, 48.20s/it]2022-01-08 19:51:09,835 iteration 6716 : loss : 0.007577, loss_ce: 0.002935
2022-01-08 19:51:12,217 iteration 6717 : loss : 0.017399, loss_ce: 0.006646
2022-01-08 19:51:14,634 iteration 6718 : loss : 0.010347, loss_ce: 0.003265
2022-01-08 19:51:17,241 iteration 6719 : loss : 0.010429, loss_ce: 0.003298
2022-01-08 19:51:19,615 iteration 6720 : loss : 0.011151, loss_ce: 0.003858
2022-01-08 19:51:21,989 iteration 6721 : loss : 0.013476, loss_ce: 0.004935
2022-01-08 19:51:24,504 iteration 6722 : loss : 0.013543, loss_ce: 0.003645
2022-01-08 19:51:27,121 iteration 6723 : loss : 0.012174, loss_ce: 0.003741
2022-01-08 19:51:29,574 iteration 6724 : loss : 0.010266, loss_ce: 0.004312
2022-01-08 19:51:31,997 iteration 6725 : loss : 0.010753, loss_ce: 0.004475
2022-01-08 19:51:34,468 iteration 6726 : loss : 0.012729, loss_ce: 0.003432
2022-01-08 19:51:36,986 iteration 6727 : loss : 0.015579, loss_ce: 0.006668
2022-01-08 19:51:39,472 iteration 6728 : loss : 0.012557, loss_ce: 0.005834
2022-01-08 19:51:41,882 iteration 6729 : loss : 0.010489, loss_ce: 0.003535
2022-01-08 19:51:44,300 iteration 6730 : loss : 0.012873, loss_ce: 0.004512
2022-01-08 19:51:46,714 iteration 6731 : loss : 0.011090, loss_ce: 0.005154
2022-01-08 19:51:49,249 iteration 6732 : loss : 0.010810, loss_ce: 0.005082
 99%|████████████████████████████▋| 396/400 [4:51:56<03:05, 46.34s/it]2022-01-08 19:51:51,710 iteration 6733 : loss : 0.016387, loss_ce: 0.007095
2022-01-08 19:51:54,152 iteration 6734 : loss : 0.006588, loss_ce: 0.001957
2022-01-08 19:51:56,621 iteration 6735 : loss : 0.011339, loss_ce: 0.005389
2022-01-08 19:51:59,059 iteration 6736 : loss : 0.010783, loss_ce: 0.003189
2022-01-08 19:52:01,498 iteration 6737 : loss : 0.008782, loss_ce: 0.003972
2022-01-08 19:52:03,927 iteration 6738 : loss : 0.009666, loss_ce: 0.003471
2022-01-08 19:52:06,417 iteration 6739 : loss : 0.016905, loss_ce: 0.007339
2022-01-08 19:52:08,931 iteration 6740 : loss : 0.016247, loss_ce: 0.005892
2022-01-08 19:52:11,322 iteration 6741 : loss : 0.008302, loss_ce: 0.003311
2022-01-08 19:52:13,822 iteration 6742 : loss : 0.014854, loss_ce: 0.007558
2022-01-08 19:52:16,304 iteration 6743 : loss : 0.015480, loss_ce: 0.005114
2022-01-08 19:52:18,765 iteration 6744 : loss : 0.014057, loss_ce: 0.006863
2022-01-08 19:52:21,196 iteration 6745 : loss : 0.014300, loss_ce: 0.004274
2022-01-08 19:52:23,626 iteration 6746 : loss : 0.013901, loss_ce: 0.005502
2022-01-08 19:52:26,116 iteration 6747 : loss : 0.015473, loss_ce: 0.005314
2022-01-08 19:52:28,588 iteration 6748 : loss : 0.013013, loss_ce: 0.005032
2022-01-08 19:52:31,078 iteration 6749 : loss : 0.015461, loss_ce: 0.005212
 99%|████████████████████████████▊| 397/400 [4:52:37<02:14, 44.98s/it]2022-01-08 19:52:33,520 iteration 6750 : loss : 0.014870, loss_ce: 0.005862
2022-01-08 19:52:35,989 iteration 6751 : loss : 0.013372, loss_ce: 0.005579
2022-01-08 19:52:38,590 iteration 6752 : loss : 0.014581, loss_ce: 0.007242
2022-01-08 19:52:41,089 iteration 6753 : loss : 0.010615, loss_ce: 0.004440
2022-01-08 19:52:43,526 iteration 6754 : loss : 0.015837, loss_ce: 0.004975
2022-01-08 19:52:45,981 iteration 6755 : loss : 0.007332, loss_ce: 0.002138
2022-01-08 19:52:48,441 iteration 6756 : loss : 0.010176, loss_ce: 0.003675
2022-01-08 19:52:50,876 iteration 6757 : loss : 0.015191, loss_ce: 0.006866
2022-01-08 19:52:53,384 iteration 6758 : loss : 0.007435, loss_ce: 0.003019
2022-01-08 19:52:55,807 iteration 6759 : loss : 0.012149, loss_ce: 0.004432
2022-01-08 19:52:58,276 iteration 6760 : loss : 0.012458, loss_ce: 0.005165
2022-01-08 19:53:00,741 iteration 6761 : loss : 0.012741, loss_ce: 0.005354
2022-01-08 19:53:03,149 iteration 6762 : loss : 0.008468, loss_ce: 0.003021
2022-01-08 19:53:05,593 iteration 6763 : loss : 0.014409, loss_ce: 0.003524
2022-01-08 19:53:07,952 iteration 6764 : loss : 0.018673, loss_ce: 0.005982
2022-01-08 19:53:10,361 iteration 6765 : loss : 0.013522, loss_ce: 0.003964
2022-01-08 19:53:12,837 iteration 6766 : loss : 0.017966, loss_ce: 0.006572
100%|████████████████████████████▊| 398/400 [4:53:19<01:28, 44.02s/it]2022-01-08 19:53:15,362 iteration 6767 : loss : 0.015123, loss_ce: 0.005046
2022-01-08 19:53:17,913 iteration 6768 : loss : 0.011169, loss_ce: 0.005404
2022-01-08 19:53:20,355 iteration 6769 : loss : 0.012697, loss_ce: 0.004620
2022-01-08 19:53:22,707 iteration 6770 : loss : 0.008636, loss_ce: 0.003382
2022-01-08 19:53:25,225 iteration 6771 : loss : 0.013904, loss_ce: 0.005302
2022-01-08 19:53:27,812 iteration 6772 : loss : 0.022157, loss_ce: 0.005905
2022-01-08 19:53:30,210 iteration 6773 : loss : 0.010696, loss_ce: 0.004451
2022-01-08 19:53:32,857 iteration 6774 : loss : 0.011418, loss_ce: 0.004640
2022-01-08 19:53:35,288 iteration 6775 : loss : 0.012586, loss_ce: 0.004876
2022-01-08 19:53:37,758 iteration 6776 : loss : 0.018999, loss_ce: 0.007218
2022-01-08 19:53:40,283 iteration 6777 : loss : 0.014164, loss_ce: 0.005680
2022-01-08 19:53:42,622 iteration 6778 : loss : 0.010241, loss_ce: 0.003335
2022-01-08 19:53:44,930 iteration 6779 : loss : 0.010063, loss_ce: 0.003163
2022-01-08 19:53:47,401 iteration 6780 : loss : 0.008584, loss_ce: 0.002935
2022-01-08 19:53:49,755 iteration 6781 : loss : 0.010922, loss_ce: 0.005449
2022-01-08 19:53:52,315 iteration 6782 : loss : 0.008590, loss_ce: 0.003667
2022-01-08 19:53:54,723 iteration 6783 : loss : 0.009574, loss_ce: 0.003881
100%|████████████████████████████▉| 399/400 [4:54:01<00:43, 43.38s/it]2022-01-08 19:53:57,391 iteration 6784 : loss : 0.019903, loss_ce: 0.006695
2022-01-08 19:53:59,786 iteration 6785 : loss : 0.016233, loss_ce: 0.007547
2022-01-08 19:54:02,134 iteration 6786 : loss : 0.009509, loss_ce: 0.004304
2022-01-08 19:54:04,558 iteration 6787 : loss : 0.012906, loss_ce: 0.004090
2022-01-08 19:54:06,878 iteration 6788 : loss : 0.016020, loss_ce: 0.003727
2022-01-08 19:54:09,352 iteration 6789 : loss : 0.008388, loss_ce: 0.003356
2022-01-08 19:54:11,837 iteration 6790 : loss : 0.014484, loss_ce: 0.005039
2022-01-08 19:54:14,291 iteration 6791 : loss : 0.021869, loss_ce: 0.006345
2022-01-08 19:54:16,894 iteration 6792 : loss : 0.012238, loss_ce: 0.004449
2022-01-08 19:54:19,302 iteration 6793 : loss : 0.015822, loss_ce: 0.005158
2022-01-08 19:54:21,707 iteration 6794 : loss : 0.012810, loss_ce: 0.004663
2022-01-08 19:54:24,112 iteration 6795 : loss : 0.009627, loss_ce: 0.003453
2022-01-08 19:54:26,633 iteration 6796 : loss : 0.012346, loss_ce: 0.004252
2022-01-08 19:54:29,002 iteration 6797 : loss : 0.012673, loss_ce: 0.004396
2022-01-08 19:54:31,425 iteration 6798 : loss : 0.010656, loss_ce: 0.003721
2022-01-08 19:54:33,809 iteration 6799 : loss : 0.015407, loss_ce: 0.007935
2022-01-08 19:54:33,810 Training Data Eval:
2022-01-08 19:54:47,008   Average segmentation loss on training set: 0.0064
2022-01-08 19:54:47,008 Validation Data Eval:
2022-01-08 19:54:51,492   Average segmentation loss on validation set: 0.0723
2022-01-08 19:54:53,950 iteration 6800 : loss : 0.013372, loss_ce: 0.006001
100%|█████████████████████████████| 400/400 [4:55:00<00:00, 48.13s/it]100%|█████████████████████████████| 400/400 [4:55:00<00:00, 44.25s/it]
