2022-01-15 23:39:11,671 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:11,672 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:11,672 ============================================================
2022-01-15 23:39:11,672 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:11,672 ============================================================
2022-01-15 23:39:11,672 Loading data...
2022-01-15 23:39:11,672 Reading NCI - RUNMC images...
2022-01-15 23:39:11,672 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-15 23:39:11,674 Already preprocessed this configuration. Loading now!
2022-01-15 23:39:11,688 Training Images: (256, 256, 286)
2022-01-15 23:39:11,688 Training Labels: (256, 256, 286)
2022-01-15 23:39:11,688 Validation Images: (256, 256, 98)
2022-01-15 23:39:11,689 Validation Labels: (256, 256, 98)
2022-01-15 23:39:11,689 ============================================================
2022-01-15 23:39:11,733 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-15 23:39:14,914 iteration 1 : loss : 0.763153, loss_ce: 0.846096
2022-01-15 23:39:15,814 iteration 2 : loss : 0.707299, loss_ce: 0.767114
2022-01-15 23:39:16,786 iteration 3 : loss : 0.649784, loss_ce: 0.670941
2022-01-15 23:39:17,712 iteration 4 : loss : 0.614821, loss_ce: 0.593240
2022-01-15 23:39:18,567 iteration 5 : loss : 0.585814, loss_ce: 0.526239
2022-01-15 23:39:19,478 iteration 6 : loss : 0.549538, loss_ce: 0.476330
2022-01-15 23:39:20,424 iteration 7 : loss : 0.517442, loss_ce: 0.440257
2022-01-15 23:39:21,417 iteration 8 : loss : 0.491708, loss_ce: 0.398892
2022-01-15 23:39:22,276 iteration 9 : loss : 0.488860, loss_ce: 0.360449
2022-01-15 23:39:23,139 iteration 10 : loss : 0.453183, loss_ce: 0.330414
2022-01-15 23:39:23,984 iteration 11 : loss : 0.445742, loss_ce: 0.300351
2022-01-15 23:39:24,881 iteration 12 : loss : 0.428394, loss_ce: 0.286153
2022-01-15 23:39:25,831 iteration 13 : loss : 0.419871, loss_ce: 0.296000
2022-01-15 23:39:26,679 iteration 14 : loss : 0.376352, loss_ce: 0.244981
2022-01-15 23:39:27,625 iteration 15 : loss : 0.370002, loss_ce: 0.231287
2022-01-15 23:39:28,513 iteration 16 : loss : 0.384867, loss_ce: 0.226405
2022-01-15 23:39:29,392 iteration 17 : loss : 0.355634, loss_ce: 0.219040
  0%|                               | 1/400 [00:17<1:57:57, 17.74s/it]2022-01-15 23:39:30,349 iteration 18 : loss : 0.323307, loss_ce: 0.173982
2022-01-15 23:39:31,263 iteration 19 : loss : 0.327657, loss_ce: 0.170995
2022-01-15 23:39:32,161 iteration 20 : loss : 0.298875, loss_ce: 0.158159
2022-01-15 23:39:33,134 iteration 21 : loss : 0.313137, loss_ce: 0.159728
2022-01-15 23:39:34,024 iteration 22 : loss : 0.305012, loss_ce: 0.155267
2022-01-15 23:39:34,936 iteration 23 : loss : 0.274727, loss_ce: 0.132582
2022-01-15 23:39:35,787 iteration 24 : loss : 0.308002, loss_ce: 0.166143
2022-01-15 23:39:36,600 iteration 25 : loss : 0.295960, loss_ce: 0.146399
2022-01-15 23:39:37,450 iteration 26 : loss : 0.304033, loss_ce: 0.144548
2022-01-15 23:39:38,355 iteration 27 : loss : 0.253103, loss_ce: 0.128599
2022-01-15 23:39:39,238 iteration 28 : loss : 0.260474, loss_ce: 0.118661
2022-01-15 23:39:40,260 iteration 29 : loss : 0.269880, loss_ce: 0.126923
2022-01-15 23:39:41,207 iteration 30 : loss : 0.258795, loss_ce: 0.114086
2022-01-15 23:39:42,065 iteration 31 : loss : 0.246594, loss_ce: 0.115171
2022-01-15 23:39:42,948 iteration 32 : loss : 0.275173, loss_ce: 0.129876
2022-01-15 23:39:43,936 iteration 33 : loss : 0.255626, loss_ce: 0.129317
2022-01-15 23:39:44,812 iteration 34 : loss : 0.265149, loss_ce: 0.116668
  0%|▏                              | 2/400 [00:33<1:48:31, 16.36s/it]2022-01-15 23:39:45,816 iteration 35 : loss : 0.243409, loss_ce: 0.120634
2022-01-15 23:39:46,728 iteration 36 : loss : 0.245085, loss_ce: 0.113631
2022-01-15 23:39:47,671 iteration 37 : loss : 0.250212, loss_ce: 0.127999
2022-01-15 23:39:48,678 iteration 38 : loss : 0.228943, loss_ce: 0.097334
2022-01-15 23:39:49,592 iteration 39 : loss : 0.305229, loss_ce: 0.122362
2022-01-15 23:39:50,542 iteration 40 : loss : 0.242779, loss_ce: 0.127954
2022-01-15 23:39:51,398 iteration 41 : loss : 0.246596, loss_ce: 0.101706
2022-01-15 23:39:52,429 iteration 42 : loss : 0.225143, loss_ce: 0.106864
2022-01-15 23:39:53,287 iteration 43 : loss : 0.256505, loss_ce: 0.103348
2022-01-15 23:39:54,220 iteration 44 : loss : 0.225037, loss_ce: 0.092281
2022-01-15 23:39:55,167 iteration 45 : loss : 0.321153, loss_ce: 0.141455
2022-01-15 23:39:55,999 iteration 46 : loss : 0.268045, loss_ce: 0.110994
2022-01-15 23:39:56,889 iteration 47 : loss : 0.260387, loss_ce: 0.094981
2022-01-15 23:39:57,822 iteration 48 : loss : 0.194052, loss_ce: 0.087077
2022-01-15 23:39:58,737 iteration 49 : loss : 0.248701, loss_ce: 0.091504
2022-01-15 23:39:59,692 iteration 50 : loss : 0.239364, loss_ce: 0.091097
2022-01-15 23:40:00,620 iteration 51 : loss : 0.236625, loss_ce: 0.116182
  1%|▏                              | 3/400 [00:48<1:46:34, 16.11s/it]2022-01-15 23:40:01,514 iteration 52 : loss : 0.271013, loss_ce: 0.125327
2022-01-15 23:40:02,345 iteration 53 : loss : 0.216759, loss_ce: 0.101464
2022-01-15 23:40:03,282 iteration 54 : loss : 0.177796, loss_ce: 0.079680
2022-01-15 23:40:04,206 iteration 55 : loss : 0.326077, loss_ce: 0.140764
2022-01-15 23:40:05,155 iteration 56 : loss : 0.215926, loss_ce: 0.091299
2022-01-15 23:40:06,122 iteration 57 : loss : 0.218805, loss_ce: 0.094031
2022-01-15 23:40:07,048 iteration 58 : loss : 0.255221, loss_ce: 0.125485
2022-01-15 23:40:07,953 iteration 59 : loss : 0.221551, loss_ce: 0.089360
2022-01-15 23:40:08,927 iteration 60 : loss : 0.237465, loss_ce: 0.090118
2022-01-15 23:40:09,908 iteration 61 : loss : 0.227323, loss_ce: 0.100602
2022-01-15 23:40:10,827 iteration 62 : loss : 0.222179, loss_ce: 0.084802
2022-01-15 23:40:11,680 iteration 63 : loss : 0.192527, loss_ce: 0.090786
2022-01-15 23:40:12,581 iteration 64 : loss : 0.266144, loss_ce: 0.144247
2022-01-15 23:40:13,477 iteration 65 : loss : 0.247611, loss_ce: 0.103088
2022-01-15 23:40:14,429 iteration 66 : loss : 0.225824, loss_ce: 0.108326
2022-01-15 23:40:15,295 iteration 67 : loss : 0.227952, loss_ce: 0.111287
2022-01-15 23:40:16,198 iteration 68 : loss : 0.275907, loss_ce: 0.124073
  1%|▎                              | 4/400 [01:04<1:44:56, 15.90s/it]2022-01-15 23:40:17,170 iteration 69 : loss : 0.231150, loss_ce: 0.088085
2022-01-15 23:40:18,109 iteration 70 : loss : 0.263491, loss_ce: 0.113003
2022-01-15 23:40:18,981 iteration 71 : loss : 0.211236, loss_ce: 0.076612
2022-01-15 23:40:19,945 iteration 72 : loss : 0.250154, loss_ce: 0.084925
2022-01-15 23:40:20,853 iteration 73 : loss : 0.208506, loss_ce: 0.103413
2022-01-15 23:40:21,847 iteration 74 : loss : 0.211565, loss_ce: 0.091036
2022-01-15 23:40:22,780 iteration 75 : loss : 0.200484, loss_ce: 0.111246
2022-01-15 23:40:23,768 iteration 76 : loss : 0.238485, loss_ce: 0.104813
2022-01-15 23:40:24,788 iteration 77 : loss : 0.215887, loss_ce: 0.083373
2022-01-15 23:40:25,783 iteration 78 : loss : 0.149383, loss_ce: 0.075647
2022-01-15 23:40:26,687 iteration 79 : loss : 0.209496, loss_ce: 0.084110
2022-01-15 23:40:27,687 iteration 80 : loss : 0.288401, loss_ce: 0.120107
2022-01-15 23:40:28,618 iteration 81 : loss : 0.193823, loss_ce: 0.073744
2022-01-15 23:40:29,585 iteration 82 : loss : 0.254770, loss_ce: 0.122525
2022-01-15 23:40:30,590 iteration 83 : loss : 0.172067, loss_ce: 0.066492
2022-01-15 23:40:31,515 iteration 84 : loss : 0.210833, loss_ce: 0.098495
2022-01-15 23:40:31,515 Training Data Eval:
2022-01-15 23:40:36,129   Average segmentation loss on training set: 0.3204
2022-01-15 23:40:36,129 Validation Data Eval:
2022-01-15 23:40:37,963   Average segmentation loss on validation set: 0.3578
2022-01-15 23:40:38,810 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed2.pth
2022-01-15 23:40:39,809 iteration 85 : loss : 0.179435, loss_ce: 0.090523
  1%|▍                              | 5/400 [01:28<2:02:58, 18.68s/it]2022-01-15 23:40:40,799 iteration 86 : loss : 0.264268, loss_ce: 0.099678
2022-01-15 23:40:41,689 iteration 87 : loss : 0.211474, loss_ce: 0.091860
2022-01-15 23:40:42,640 iteration 88 : loss : 0.210648, loss_ce: 0.080679
2022-01-15 23:40:43,668 iteration 89 : loss : 0.169238, loss_ce: 0.074595
2022-01-15 23:40:44,603 iteration 90 : loss : 0.159117, loss_ce: 0.074081
2022-01-15 23:40:45,586 iteration 91 : loss : 0.231780, loss_ce: 0.109735
2022-01-15 23:40:46,537 iteration 92 : loss : 0.174540, loss_ce: 0.077566
2022-01-15 23:40:47,565 iteration 93 : loss : 0.187298, loss_ce: 0.085612
2022-01-15 23:40:48,586 iteration 94 : loss : 0.182384, loss_ce: 0.098818
2022-01-15 23:40:49,524 iteration 95 : loss : 0.215089, loss_ce: 0.089272
2022-01-15 23:40:50,440 iteration 96 : loss : 0.164921, loss_ce: 0.065671
2022-01-15 23:40:51,356 iteration 97 : loss : 0.132251, loss_ce: 0.059629
2022-01-15 23:40:52,310 iteration 98 : loss : 0.228765, loss_ce: 0.096301
2022-01-15 23:40:53,413 iteration 99 : loss : 0.156649, loss_ce: 0.064838
2022-01-15 23:40:54,501 iteration 100 : loss : 0.210415, loss_ce: 0.083116
2022-01-15 23:40:55,425 iteration 101 : loss : 0.243011, loss_ce: 0.111308
2022-01-15 23:40:56,381 iteration 102 : loss : 0.193727, loss_ce: 0.061482
  2%|▍                              | 6/400 [01:44<1:57:59, 17.97s/it]2022-01-15 23:40:57,412 iteration 103 : loss : 0.174294, loss_ce: 0.063580
2022-01-15 23:40:58,427 iteration 104 : loss : 0.202314, loss_ce: 0.072747
2022-01-15 23:40:59,422 iteration 105 : loss : 0.177996, loss_ce: 0.076782
2022-01-15 23:41:00,423 iteration 106 : loss : 0.187522, loss_ce: 0.069405
2022-01-15 23:41:01,479 iteration 107 : loss : 0.148585, loss_ce: 0.064747
2022-01-15 23:41:02,445 iteration 108 : loss : 0.166523, loss_ce: 0.069494
2022-01-15 23:41:03,441 iteration 109 : loss : 0.130233, loss_ce: 0.051776
2022-01-15 23:41:04,471 iteration 110 : loss : 0.186525, loss_ce: 0.089895
2022-01-15 23:41:05,624 iteration 111 : loss : 0.162328, loss_ce: 0.073744
2022-01-15 23:41:06,588 iteration 112 : loss : 0.228510, loss_ce: 0.095533
2022-01-15 23:41:07,672 iteration 113 : loss : 0.164207, loss_ce: 0.063421
2022-01-15 23:41:08,671 iteration 114 : loss : 0.152452, loss_ce: 0.053747
2022-01-15 23:41:09,590 iteration 115 : loss : 0.135465, loss_ce: 0.059352
2022-01-15 23:41:10,570 iteration 116 : loss : 0.215031, loss_ce: 0.089599
2022-01-15 23:41:11,519 iteration 117 : loss : 0.122930, loss_ce: 0.053330
2022-01-15 23:41:12,544 iteration 118 : loss : 0.199036, loss_ce: 0.075504
2022-01-15 23:41:13,489 iteration 119 : loss : 0.236788, loss_ce: 0.095040
  2%|▌                              | 7/400 [02:01<1:55:49, 17.68s/it]2022-01-15 23:41:14,600 iteration 120 : loss : 0.233765, loss_ce: 0.111055
2022-01-15 23:41:15,612 iteration 121 : loss : 0.255258, loss_ce: 0.100064
2022-01-15 23:41:16,512 iteration 122 : loss : 0.161241, loss_ce: 0.060761
2022-01-15 23:41:17,513 iteration 123 : loss : 0.179558, loss_ce: 0.077577
2022-01-15 23:41:18,504 iteration 124 : loss : 0.164563, loss_ce: 0.065554
2022-01-15 23:41:19,483 iteration 125 : loss : 0.187212, loss_ce: 0.068213
2022-01-15 23:41:20,461 iteration 126 : loss : 0.145920, loss_ce: 0.062263
2022-01-15 23:41:21,484 iteration 127 : loss : 0.207433, loss_ce: 0.095766
2022-01-15 23:41:22,456 iteration 128 : loss : 0.151434, loss_ce: 0.058111
2022-01-15 23:41:23,510 iteration 129 : loss : 0.224526, loss_ce: 0.102538
2022-01-15 23:41:24,411 iteration 130 : loss : 0.157427, loss_ce: 0.065586
2022-01-15 23:41:25,386 iteration 131 : loss : 0.180778, loss_ce: 0.079444
2022-01-15 23:41:26,389 iteration 132 : loss : 0.190204, loss_ce: 0.071193
2022-01-15 23:41:27,398 iteration 133 : loss : 0.213643, loss_ce: 0.107062
2022-01-15 23:41:28,385 iteration 134 : loss : 0.165970, loss_ce: 0.065843
2022-01-15 23:41:29,360 iteration 135 : loss : 0.208854, loss_ce: 0.076408
2022-01-15 23:41:30,431 iteration 136 : loss : 0.165547, loss_ce: 0.075813
  2%|▌                              | 8/400 [02:18<1:53:59, 17.45s/it]2022-01-15 23:41:31,559 iteration 137 : loss : 0.180220, loss_ce: 0.065876
2022-01-15 23:41:32,510 iteration 138 : loss : 0.150287, loss_ce: 0.060069
2022-01-15 23:41:33,595 iteration 139 : loss : 0.190994, loss_ce: 0.058715
2022-01-15 23:41:34,590 iteration 140 : loss : 0.218138, loss_ce: 0.092239
2022-01-15 23:41:35,545 iteration 141 : loss : 0.218154, loss_ce: 0.075835
2022-01-15 23:41:36,530 iteration 142 : loss : 0.184860, loss_ce: 0.070165
2022-01-15 23:41:37,535 iteration 143 : loss : 0.175654, loss_ce: 0.063835
2022-01-15 23:41:38,518 iteration 144 : loss : 0.173566, loss_ce: 0.056272
2022-01-15 23:41:39,525 iteration 145 : loss : 0.175272, loss_ce: 0.084321
2022-01-15 23:41:40,586 iteration 146 : loss : 0.131317, loss_ce: 0.052563
2022-01-15 23:41:41,596 iteration 147 : loss : 0.227445, loss_ce: 0.102082
2022-01-15 23:41:42,689 iteration 148 : loss : 0.162638, loss_ce: 0.069144
2022-01-15 23:41:43,766 iteration 149 : loss : 0.170935, loss_ce: 0.071020
2022-01-15 23:41:44,836 iteration 150 : loss : 0.166361, loss_ce: 0.069492
2022-01-15 23:41:45,803 iteration 151 : loss : 0.158477, loss_ce: 0.090500
2022-01-15 23:41:46,721 iteration 152 : loss : 0.111403, loss_ce: 0.053996
2022-01-15 23:41:47,706 iteration 153 : loss : 0.133009, loss_ce: 0.051419
  2%|▋                              | 9/400 [02:36<1:53:19, 17.39s/it]2022-01-15 23:41:48,799 iteration 154 : loss : 0.195511, loss_ce: 0.091182
2022-01-15 23:41:49,788 iteration 155 : loss : 0.134632, loss_ce: 0.066352
2022-01-15 23:41:50,750 iteration 156 : loss : 0.144334, loss_ce: 0.062486
2022-01-15 23:41:51,715 iteration 157 : loss : 0.185426, loss_ce: 0.076717
2022-01-15 23:41:52,775 iteration 158 : loss : 0.194446, loss_ce: 0.069841
2022-01-15 23:41:53,821 iteration 159 : loss : 0.112520, loss_ce: 0.045567
2022-01-15 23:41:54,793 iteration 160 : loss : 0.152503, loss_ce: 0.057330
2022-01-15 23:41:55,870 iteration 161 : loss : 0.116601, loss_ce: 0.053195
2022-01-15 23:41:56,885 iteration 162 : loss : 0.187938, loss_ce: 0.066094
2022-01-15 23:41:57,892 iteration 163 : loss : 0.215264, loss_ce: 0.089763
2022-01-15 23:41:58,888 iteration 164 : loss : 0.182703, loss_ce: 0.066450
2022-01-15 23:41:59,828 iteration 165 : loss : 0.131247, loss_ce: 0.055467
2022-01-15 23:42:00,861 iteration 166 : loss : 0.207012, loss_ce: 0.131313
2022-01-15 23:42:01,972 iteration 167 : loss : 0.197029, loss_ce: 0.088011
2022-01-15 23:42:02,969 iteration 168 : loss : 0.156222, loss_ce: 0.048815
2022-01-15 23:42:04,013 iteration 169 : loss : 0.133730, loss_ce: 0.050405
2022-01-15 23:42:04,013 Training Data Eval:
2022-01-15 23:42:08,806   Average segmentation loss on training set: 0.1390
2022-01-15 23:42:08,806 Validation Data Eval:
2022-01-15 23:42:10,434   Average segmentation loss on validation set: 0.1673
2022-01-15 23:42:11,337 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed2.pth
2022-01-15 23:42:12,383 iteration 170 : loss : 0.189583, loss_ce: 0.073303
  2%|▊                             | 10/400 [03:00<2:07:39, 19.64s/it]2022-01-15 23:42:13,475 iteration 171 : loss : 0.159984, loss_ce: 0.065439
2022-01-15 23:42:14,423 iteration 172 : loss : 0.170239, loss_ce: 0.069291
2022-01-15 23:42:15,482 iteration 173 : loss : 0.146329, loss_ce: 0.062218
2022-01-15 23:42:16,410 iteration 174 : loss : 0.150597, loss_ce: 0.074401
2022-01-15 23:42:17,383 iteration 175 : loss : 0.180829, loss_ce: 0.064966
2022-01-15 23:42:18,352 iteration 176 : loss : 0.138065, loss_ce: 0.055201
2022-01-15 23:42:19,377 iteration 177 : loss : 0.117237, loss_ce: 0.051879
2022-01-15 23:42:20,372 iteration 178 : loss : 0.149387, loss_ce: 0.058777
2022-01-15 23:42:21,301 iteration 179 : loss : 0.136417, loss_ce: 0.050769
2022-01-15 23:42:22,373 iteration 180 : loss : 0.186566, loss_ce: 0.087932
2022-01-15 23:42:23,413 iteration 181 : loss : 0.180663, loss_ce: 0.075707
2022-01-15 23:42:24,394 iteration 182 : loss : 0.156811, loss_ce: 0.072022
2022-01-15 23:42:25,402 iteration 183 : loss : 0.167190, loss_ce: 0.051159
2022-01-15 23:42:26,526 iteration 184 : loss : 0.189511, loss_ce: 0.058866
2022-01-15 23:42:27,668 iteration 185 : loss : 0.166409, loss_ce: 0.068372
2022-01-15 23:42:28,631 iteration 186 : loss : 0.134174, loss_ce: 0.048674
2022-01-15 23:42:29,624 iteration 187 : loss : 0.095224, loss_ce: 0.040890
  3%|▊                             | 11/400 [03:17<2:02:34, 18.91s/it]2022-01-15 23:42:30,616 iteration 188 : loss : 0.152396, loss_ce: 0.059472
2022-01-15 23:42:31,667 iteration 189 : loss : 0.157892, loss_ce: 0.069778
2022-01-15 23:42:32,665 iteration 190 : loss : 0.207988, loss_ce: 0.097838
2022-01-15 23:42:33,654 iteration 191 : loss : 0.114455, loss_ce: 0.047746
2022-01-15 23:42:34,659 iteration 192 : loss : 0.153062, loss_ce: 0.058162
2022-01-15 23:42:35,568 iteration 193 : loss : 0.156609, loss_ce: 0.073060
2022-01-15 23:42:36,591 iteration 194 : loss : 0.132225, loss_ce: 0.060255
2022-01-15 23:42:37,626 iteration 195 : loss : 0.117569, loss_ce: 0.045181
2022-01-15 23:42:38,604 iteration 196 : loss : 0.135241, loss_ce: 0.058620
2022-01-15 23:42:39,636 iteration 197 : loss : 0.148982, loss_ce: 0.056880
2022-01-15 23:42:40,655 iteration 198 : loss : 0.141665, loss_ce: 0.048329
2022-01-15 23:42:41,569 iteration 199 : loss : 0.184555, loss_ce: 0.064694
2022-01-15 23:42:42,549 iteration 200 : loss : 0.159661, loss_ce: 0.064922
2022-01-15 23:42:43,649 iteration 201 : loss : 0.189933, loss_ce: 0.064773
2022-01-15 23:42:44,607 iteration 202 : loss : 0.137825, loss_ce: 0.052391
2022-01-15 23:42:45,548 iteration 203 : loss : 0.182356, loss_ce: 0.092402
2022-01-15 23:42:46,457 iteration 204 : loss : 0.107858, loss_ce: 0.045990
  3%|▉                             | 12/400 [03:34<1:58:12, 18.28s/it]2022-01-15 23:42:47,447 iteration 205 : loss : 0.164877, loss_ce: 0.071498
2022-01-15 23:42:48,454 iteration 206 : loss : 0.182138, loss_ce: 0.079804
2022-01-15 23:42:49,527 iteration 207 : loss : 0.159726, loss_ce: 0.073770
2022-01-15 23:42:50,613 iteration 208 : loss : 0.110865, loss_ce: 0.041075
2022-01-15 23:42:51,550 iteration 209 : loss : 0.131108, loss_ce: 0.050631
2022-01-15 23:42:52,484 iteration 210 : loss : 0.141396, loss_ce: 0.046954
2022-01-15 23:42:53,464 iteration 211 : loss : 0.137536, loss_ce: 0.052364
2022-01-15 23:42:54,371 iteration 212 : loss : 0.149662, loss_ce: 0.053008
2022-01-15 23:42:55,405 iteration 213 : loss : 0.121836, loss_ce: 0.053553
2022-01-15 23:42:56,404 iteration 214 : loss : 0.187595, loss_ce: 0.061431
2022-01-15 23:42:57,325 iteration 215 : loss : 0.175719, loss_ce: 0.078130
2022-01-15 23:42:58,361 iteration 216 : loss : 0.182236, loss_ce: 0.070697
2022-01-15 23:42:59,313 iteration 217 : loss : 0.115539, loss_ce: 0.046433
2022-01-15 23:43:00,265 iteration 218 : loss : 0.105507, loss_ce: 0.039863
2022-01-15 23:43:01,215 iteration 219 : loss : 0.127133, loss_ce: 0.043884
2022-01-15 23:43:02,136 iteration 220 : loss : 0.149975, loss_ce: 0.075194
2022-01-15 23:43:03,097 iteration 221 : loss : 0.112753, loss_ce: 0.058115
  3%|▉                             | 13/400 [03:51<1:54:42, 17.78s/it]2022-01-15 23:43:04,243 iteration 222 : loss : 0.196589, loss_ce: 0.078691
2022-01-15 23:43:05,249 iteration 223 : loss : 0.136161, loss_ce: 0.051821
2022-01-15 23:43:06,120 iteration 224 : loss : 0.140465, loss_ce: 0.062982
2022-01-15 23:43:07,117 iteration 225 : loss : 0.140464, loss_ce: 0.055021
2022-01-15 23:43:08,117 iteration 226 : loss : 0.180189, loss_ce: 0.057404
2022-01-15 23:43:09,111 iteration 227 : loss : 0.193511, loss_ce: 0.082223
2022-01-15 23:43:10,082 iteration 228 : loss : 0.177995, loss_ce: 0.065627
2022-01-15 23:43:11,047 iteration 229 : loss : 0.151063, loss_ce: 0.059704
2022-01-15 23:43:11,995 iteration 230 : loss : 0.163781, loss_ce: 0.067084
2022-01-15 23:43:12,921 iteration 231 : loss : 0.190596, loss_ce: 0.062030
2022-01-15 23:43:13,952 iteration 232 : loss : 0.133033, loss_ce: 0.069311
2022-01-15 23:43:14,970 iteration 233 : loss : 0.146753, loss_ce: 0.073790
2022-01-15 23:43:15,979 iteration 234 : loss : 0.171918, loss_ce: 0.055890
2022-01-15 23:43:16,925 iteration 235 : loss : 0.121957, loss_ce: 0.050580
2022-01-15 23:43:17,855 iteration 236 : loss : 0.171764, loss_ce: 0.075681
2022-01-15 23:43:18,776 iteration 237 : loss : 0.107564, loss_ce: 0.044567
2022-01-15 23:43:19,626 iteration 238 : loss : 0.121179, loss_ce: 0.058246
  4%|█                             | 14/400 [04:07<1:51:56, 17.40s/it]2022-01-15 23:43:20,589 iteration 239 : loss : 0.094114, loss_ce: 0.037470
2022-01-15 23:43:21,599 iteration 240 : loss : 0.174189, loss_ce: 0.077901
2022-01-15 23:43:22,502 iteration 241 : loss : 0.143992, loss_ce: 0.048545
2022-01-15 23:43:23,500 iteration 242 : loss : 0.119656, loss_ce: 0.049330
2022-01-15 23:43:24,510 iteration 243 : loss : 0.166221, loss_ce: 0.072169
2022-01-15 23:43:25,510 iteration 244 : loss : 0.149336, loss_ce: 0.062498
2022-01-15 23:43:26,389 iteration 245 : loss : 0.125593, loss_ce: 0.043480
2022-01-15 23:43:27,354 iteration 246 : loss : 0.151031, loss_ce: 0.053452
2022-01-15 23:43:28,254 iteration 247 : loss : 0.142788, loss_ce: 0.066750
2022-01-15 23:43:29,125 iteration 248 : loss : 0.103545, loss_ce: 0.040341
2022-01-15 23:43:30,163 iteration 249 : loss : 0.140747, loss_ce: 0.046784
2022-01-15 23:43:31,156 iteration 250 : loss : 0.156362, loss_ce: 0.069990
2022-01-15 23:43:32,083 iteration 251 : loss : 0.107663, loss_ce: 0.042818
2022-01-15 23:43:33,028 iteration 252 : loss : 0.127835, loss_ce: 0.060940
2022-01-15 23:43:33,923 iteration 253 : loss : 0.158812, loss_ce: 0.053103
2022-01-15 23:43:34,825 iteration 254 : loss : 0.130900, loss_ce: 0.048794
2022-01-15 23:43:34,826 Training Data Eval:
2022-01-15 23:43:39,418   Average segmentation loss on training set: 0.1830
2022-01-15 23:43:39,418 Validation Data Eval:
2022-01-15 23:43:40,989   Average segmentation loss on validation set: 0.2116
2022-01-15 23:43:41,945 iteration 255 : loss : 0.170631, loss_ce: 0.076215
  4%|█▏                            | 15/400 [04:30<2:01:09, 18.88s/it]2022-01-15 23:43:42,953 iteration 256 : loss : 0.131730, loss_ce: 0.051488
2022-01-15 23:43:43,886 iteration 257 : loss : 0.139090, loss_ce: 0.073963
2022-01-15 23:43:44,946 iteration 258 : loss : 0.147580, loss_ce: 0.050110
2022-01-15 23:43:45,838 iteration 259 : loss : 0.175178, loss_ce: 0.072983
2022-01-15 23:43:46,801 iteration 260 : loss : 0.145758, loss_ce: 0.061583
2022-01-15 23:43:47,783 iteration 261 : loss : 0.164677, loss_ce: 0.067986
2022-01-15 23:43:48,748 iteration 262 : loss : 0.153952, loss_ce: 0.082781
2022-01-15 23:43:49,657 iteration 263 : loss : 0.166293, loss_ce: 0.090702
2022-01-15 23:43:50,560 iteration 264 : loss : 0.152496, loss_ce: 0.055512
2022-01-15 23:43:51,558 iteration 265 : loss : 0.139166, loss_ce: 0.055595
2022-01-15 23:43:52,545 iteration 266 : loss : 0.158048, loss_ce: 0.046138
2022-01-15 23:43:53,508 iteration 267 : loss : 0.146095, loss_ce: 0.058958
2022-01-15 23:43:54,482 iteration 268 : loss : 0.121492, loss_ce: 0.053359
2022-01-15 23:43:55,437 iteration 269 : loss : 0.130108, loss_ce: 0.053593
2022-01-15 23:43:56,339 iteration 270 : loss : 0.161574, loss_ce: 0.061850
2022-01-15 23:43:57,335 iteration 271 : loss : 0.235960, loss_ce: 0.085212
2022-01-15 23:43:58,390 iteration 272 : loss : 0.152473, loss_ce: 0.061472
  4%|█▏                            | 16/400 [04:46<1:56:10, 18.15s/it]2022-01-15 23:43:59,425 iteration 273 : loss : 0.129961, loss_ce: 0.046927
2022-01-15 23:44:00,425 iteration 274 : loss : 0.160358, loss_ce: 0.055724
2022-01-15 23:44:01,409 iteration 275 : loss : 0.155244, loss_ce: 0.063342
2022-01-15 23:44:02,334 iteration 276 : loss : 0.146419, loss_ce: 0.060827
2022-01-15 23:44:03,405 iteration 277 : loss : 0.139978, loss_ce: 0.049318
2022-01-15 23:44:04,311 iteration 278 : loss : 0.256872, loss_ce: 0.090097
2022-01-15 23:44:05,297 iteration 279 : loss : 0.125329, loss_ce: 0.049170
2022-01-15 23:44:06,187 iteration 280 : loss : 0.122538, loss_ce: 0.058901
2022-01-15 23:44:07,171 iteration 281 : loss : 0.145058, loss_ce: 0.054496
2022-01-15 23:44:08,179 iteration 282 : loss : 0.140015, loss_ce: 0.056438
2022-01-15 23:44:09,156 iteration 283 : loss : 0.120756, loss_ce: 0.053210
2022-01-15 23:44:10,073 iteration 284 : loss : 0.099850, loss_ce: 0.039417
2022-01-15 23:44:11,052 iteration 285 : loss : 0.114481, loss_ce: 0.040782
2022-01-15 23:44:12,046 iteration 286 : loss : 0.102593, loss_ce: 0.039077
2022-01-15 23:44:12,966 iteration 287 : loss : 0.158774, loss_ce: 0.063625
2022-01-15 23:44:13,917 iteration 288 : loss : 0.100431, loss_ce: 0.044749
2022-01-15 23:44:14,881 iteration 289 : loss : 0.129690, loss_ce: 0.062647
  4%|█▎                            | 17/400 [05:03<1:52:41, 17.65s/it]2022-01-15 23:44:15,924 iteration 290 : loss : 0.115971, loss_ce: 0.048959
2022-01-15 23:44:16,895 iteration 291 : loss : 0.087083, loss_ce: 0.033490
2022-01-15 23:44:17,878 iteration 292 : loss : 0.078391, loss_ce: 0.032776
2022-01-15 23:44:18,989 iteration 293 : loss : 0.135693, loss_ce: 0.065362
2022-01-15 23:44:19,935 iteration 294 : loss : 0.111099, loss_ce: 0.044736
2022-01-15 23:44:20,889 iteration 295 : loss : 0.174605, loss_ce: 0.051665
2022-01-15 23:44:21,867 iteration 296 : loss : 0.143793, loss_ce: 0.060038
2022-01-15 23:44:22,923 iteration 297 : loss : 0.136403, loss_ce: 0.059029
2022-01-15 23:44:23,883 iteration 298 : loss : 0.138261, loss_ce: 0.049352
2022-01-15 23:44:24,910 iteration 299 : loss : 0.177530, loss_ce: 0.059930
2022-01-15 23:44:25,878 iteration 300 : loss : 0.122056, loss_ce: 0.046865
2022-01-15 23:44:26,874 iteration 301 : loss : 0.155858, loss_ce: 0.046863
2022-01-15 23:44:27,968 iteration 302 : loss : 0.208319, loss_ce: 0.104219
2022-01-15 23:44:29,005 iteration 303 : loss : 0.121659, loss_ce: 0.058646
2022-01-15 23:44:30,038 iteration 304 : loss : 0.108764, loss_ce: 0.043436
2022-01-15 23:44:31,051 iteration 305 : loss : 0.117410, loss_ce: 0.048437
2022-01-15 23:44:32,046 iteration 306 : loss : 0.161615, loss_ce: 0.066235
  4%|█▎                            | 18/400 [05:20<1:51:26, 17.50s/it]2022-01-15 23:44:33,071 iteration 307 : loss : 0.148142, loss_ce: 0.064969
2022-01-15 23:44:34,113 iteration 308 : loss : 0.148814, loss_ce: 0.054166
2022-01-15 23:44:35,117 iteration 309 : loss : 0.173876, loss_ce: 0.082630
2022-01-15 23:44:36,090 iteration 310 : loss : 0.098405, loss_ce: 0.037306
2022-01-15 23:44:37,056 iteration 311 : loss : 0.123097, loss_ce: 0.047786
2022-01-15 23:44:38,065 iteration 312 : loss : 0.186024, loss_ce: 0.059291
2022-01-15 23:44:39,110 iteration 313 : loss : 0.141937, loss_ce: 0.061144
2022-01-15 23:44:40,017 iteration 314 : loss : 0.163245, loss_ce: 0.060048
2022-01-15 23:44:40,985 iteration 315 : loss : 0.150631, loss_ce: 0.062568
2022-01-15 23:44:42,049 iteration 316 : loss : 0.125080, loss_ce: 0.053019
2022-01-15 23:44:43,125 iteration 317 : loss : 0.152724, loss_ce: 0.071483
2022-01-15 23:44:44,118 iteration 318 : loss : 0.173748, loss_ce: 0.105031
2022-01-15 23:44:45,130 iteration 319 : loss : 0.118655, loss_ce: 0.055699
2022-01-15 23:44:46,138 iteration 320 : loss : 0.130636, loss_ce: 0.049720
2022-01-15 23:44:47,107 iteration 321 : loss : 0.160821, loss_ce: 0.066574
2022-01-15 23:44:48,055 iteration 322 : loss : 0.117476, loss_ce: 0.056995
2022-01-15 23:44:49,035 iteration 323 : loss : 0.152133, loss_ce: 0.069823
  5%|█▍                            | 19/400 [05:37<1:50:10, 17.35s/it]2022-01-15 23:44:50,097 iteration 324 : loss : 0.132970, loss_ce: 0.054809
2022-01-15 23:44:51,064 iteration 325 : loss : 0.164088, loss_ce: 0.053290
2022-01-15 23:44:52,026 iteration 326 : loss : 0.207463, loss_ce: 0.089393
2022-01-15 23:44:52,964 iteration 327 : loss : 0.180470, loss_ce: 0.078426
2022-01-15 23:44:53,986 iteration 328 : loss : 0.083377, loss_ce: 0.027041
2022-01-15 23:44:55,056 iteration 329 : loss : 0.168169, loss_ce: 0.059149
2022-01-15 23:44:56,039 iteration 330 : loss : 0.164129, loss_ce: 0.070528
2022-01-15 23:44:57,040 iteration 331 : loss : 0.142274, loss_ce: 0.057623
2022-01-15 23:44:57,956 iteration 332 : loss : 0.105145, loss_ce: 0.042484
2022-01-15 23:44:59,001 iteration 333 : loss : 0.151159, loss_ce: 0.062456
2022-01-15 23:45:00,003 iteration 334 : loss : 0.099822, loss_ce: 0.037792
2022-01-15 23:45:01,065 iteration 335 : loss : 0.122576, loss_ce: 0.062354
2022-01-15 23:45:02,053 iteration 336 : loss : 0.145613, loss_ce: 0.066455
2022-01-15 23:45:03,041 iteration 337 : loss : 0.178492, loss_ce: 0.067761
2022-01-15 23:45:04,038 iteration 338 : loss : 0.114340, loss_ce: 0.048586
2022-01-15 23:45:05,006 iteration 339 : loss : 0.127472, loss_ce: 0.059391
2022-01-15 23:45:05,006 Training Data Eval:
2022-01-15 23:45:09,801   Average segmentation loss on training set: 0.1128
2022-01-15 23:45:09,802 Validation Data Eval:
2022-01-15 23:45:11,423   Average segmentation loss on validation set: 0.2194
2022-01-15 23:45:12,464 iteration 340 : loss : 0.154508, loss_ce: 0.077792
  5%|█▌                            | 20/400 [06:00<2:01:26, 19.17s/it]2022-01-15 23:45:13,499 iteration 341 : loss : 0.082069, loss_ce: 0.037224
2022-01-15 23:45:14,546 iteration 342 : loss : 0.151320, loss_ce: 0.074051
2022-01-15 23:45:15,581 iteration 343 : loss : 0.147037, loss_ce: 0.061965
2022-01-15 23:45:16,560 iteration 344 : loss : 0.104744, loss_ce: 0.051985
2022-01-15 23:45:17,541 iteration 345 : loss : 0.101768, loss_ce: 0.039943
2022-01-15 23:45:18,598 iteration 346 : loss : 0.087808, loss_ce: 0.033111
2022-01-15 23:45:19,645 iteration 347 : loss : 0.133156, loss_ce: 0.055700
2022-01-15 23:45:20,645 iteration 348 : loss : 0.099980, loss_ce: 0.035469
2022-01-15 23:45:21,647 iteration 349 : loss : 0.105624, loss_ce: 0.039822
2022-01-15 23:45:22,686 iteration 350 : loss : 0.149720, loss_ce: 0.061615
2022-01-15 23:45:23,674 iteration 351 : loss : 0.114115, loss_ce: 0.042258
2022-01-15 23:45:24,766 iteration 352 : loss : 0.104183, loss_ce: 0.049199
2022-01-15 23:45:25,851 iteration 353 : loss : 0.114950, loss_ce: 0.047697
2022-01-15 23:45:26,835 iteration 354 : loss : 0.117026, loss_ce: 0.036631
2022-01-15 23:45:27,872 iteration 355 : loss : 0.105272, loss_ce: 0.029827
2022-01-15 23:45:28,879 iteration 356 : loss : 0.140004, loss_ce: 0.045740
2022-01-15 23:45:29,901 iteration 357 : loss : 0.107380, loss_ce: 0.037822
  5%|█▌                            | 21/400 [06:18<1:57:49, 18.65s/it]2022-01-15 23:45:31,061 iteration 358 : loss : 0.166630, loss_ce: 0.075212
2022-01-15 23:45:32,141 iteration 359 : loss : 0.102032, loss_ce: 0.039445
2022-01-15 23:45:33,122 iteration 360 : loss : 0.091713, loss_ce: 0.032599
2022-01-15 23:45:34,155 iteration 361 : loss : 0.197530, loss_ce: 0.080114
2022-01-15 23:45:35,186 iteration 362 : loss : 0.137404, loss_ce: 0.068317
2022-01-15 23:45:36,125 iteration 363 : loss : 0.117409, loss_ce: 0.052344
2022-01-15 23:45:37,137 iteration 364 : loss : 0.207996, loss_ce: 0.067952
2022-01-15 23:45:38,097 iteration 365 : loss : 0.112705, loss_ce: 0.044997
2022-01-15 23:45:39,082 iteration 366 : loss : 0.151456, loss_ce: 0.045574
2022-01-15 23:45:40,094 iteration 367 : loss : 0.153610, loss_ce: 0.054086
2022-01-15 23:45:41,082 iteration 368 : loss : 0.134325, loss_ce: 0.055032
2022-01-15 23:45:42,048 iteration 369 : loss : 0.110062, loss_ce: 0.039499
2022-01-15 23:45:43,047 iteration 370 : loss : 0.164253, loss_ce: 0.075903
2022-01-15 23:45:44,067 iteration 371 : loss : 0.125283, loss_ce: 0.050412
2022-01-15 23:45:45,024 iteration 372 : loss : 0.112444, loss_ce: 0.044359
2022-01-15 23:45:46,023 iteration 373 : loss : 0.087277, loss_ce: 0.034629
2022-01-15 23:45:47,067 iteration 374 : loss : 0.132272, loss_ce: 0.055266
  6%|█▋                            | 22/400 [06:35<1:54:42, 18.21s/it]2022-01-15 23:45:48,124 iteration 375 : loss : 0.113196, loss_ce: 0.050651
2022-01-15 23:45:49,112 iteration 376 : loss : 0.154339, loss_ce: 0.046032
2022-01-15 23:45:50,118 iteration 377 : loss : 0.133152, loss_ce: 0.049229
2022-01-15 23:45:51,190 iteration 378 : loss : 0.145764, loss_ce: 0.048943
2022-01-15 23:45:52,212 iteration 379 : loss : 0.111695, loss_ce: 0.045511
2022-01-15 23:45:53,187 iteration 380 : loss : 0.148177, loss_ce: 0.072272
2022-01-15 23:45:54,205 iteration 381 : loss : 0.130317, loss_ce: 0.051023
2022-01-15 23:45:55,145 iteration 382 : loss : 0.100054, loss_ce: 0.041704
2022-01-15 23:45:56,163 iteration 383 : loss : 0.169977, loss_ce: 0.039163
2022-01-15 23:45:57,163 iteration 384 : loss : 0.107932, loss_ce: 0.041170
2022-01-15 23:45:58,141 iteration 385 : loss : 0.091214, loss_ce: 0.040884
2022-01-15 23:45:59,149 iteration 386 : loss : 0.120576, loss_ce: 0.039584
2022-01-15 23:46:00,109 iteration 387 : loss : 0.083598, loss_ce: 0.034712
2022-01-15 23:46:01,141 iteration 388 : loss : 0.107651, loss_ce: 0.044019
2022-01-15 23:46:02,131 iteration 389 : loss : 0.101688, loss_ce: 0.038881
2022-01-15 23:46:03,140 iteration 390 : loss : 0.128996, loss_ce: 0.075746
2022-01-15 23:46:04,166 iteration 391 : loss : 0.080275, loss_ce: 0.031943
  6%|█▋                            | 23/400 [06:52<1:52:19, 17.88s/it]2022-01-15 23:46:05,286 iteration 392 : loss : 0.119216, loss_ce: 0.050828
2022-01-15 23:46:06,240 iteration 393 : loss : 0.115915, loss_ce: 0.051107
2022-01-15 23:46:07,248 iteration 394 : loss : 0.116288, loss_ce: 0.041114
2022-01-15 23:46:08,205 iteration 395 : loss : 0.085915, loss_ce: 0.031611
2022-01-15 23:46:09,217 iteration 396 : loss : 0.116277, loss_ce: 0.041306
2022-01-15 23:46:10,294 iteration 397 : loss : 0.151483, loss_ce: 0.078551
2022-01-15 23:46:11,295 iteration 398 : loss : 0.117363, loss_ce: 0.038396
2022-01-15 23:46:12,312 iteration 399 : loss : 0.119691, loss_ce: 0.045333
2022-01-15 23:46:13,287 iteration 400 : loss : 0.099433, loss_ce: 0.042508
2022-01-15 23:46:14,305 iteration 401 : loss : 0.085007, loss_ce: 0.036648
2022-01-15 23:46:15,402 iteration 402 : loss : 0.105980, loss_ce: 0.052687
2022-01-15 23:46:16,448 iteration 403 : loss : 0.110555, loss_ce: 0.042299
2022-01-15 23:46:17,428 iteration 404 : loss : 0.091091, loss_ce: 0.034769
2022-01-15 23:46:18,416 iteration 405 : loss : 0.125161, loss_ce: 0.060437
2022-01-15 23:46:19,455 iteration 406 : loss : 0.110294, loss_ce: 0.047014
2022-01-15 23:46:20,493 iteration 407 : loss : 0.096296, loss_ce: 0.038833
2022-01-15 23:46:21,411 iteration 408 : loss : 0.087431, loss_ce: 0.038698
  6%|█▊                            | 24/400 [07:09<1:50:50, 17.69s/it]2022-01-15 23:46:22,536 iteration 409 : loss : 0.129589, loss_ce: 0.036392
2022-01-15 23:46:23,568 iteration 410 : loss : 0.100726, loss_ce: 0.039199
2022-01-15 23:46:24,599 iteration 411 : loss : 0.134229, loss_ce: 0.047814
2022-01-15 23:46:25,580 iteration 412 : loss : 0.102895, loss_ce: 0.045745
2022-01-15 23:46:26,580 iteration 413 : loss : 0.094576, loss_ce: 0.031244
2022-01-15 23:46:27,536 iteration 414 : loss : 0.094166, loss_ce: 0.034007
2022-01-15 23:46:28,601 iteration 415 : loss : 0.092788, loss_ce: 0.034187
2022-01-15 23:46:29,572 iteration 416 : loss : 0.119019, loss_ce: 0.055268
2022-01-15 23:46:30,603 iteration 417 : loss : 0.088709, loss_ce: 0.029769
2022-01-15 23:46:31,534 iteration 418 : loss : 0.115718, loss_ce: 0.059004
2022-01-15 23:46:32,520 iteration 419 : loss : 0.187994, loss_ce: 0.069775
2022-01-15 23:46:33,519 iteration 420 : loss : 0.079319, loss_ce: 0.033249
2022-01-15 23:46:34,616 iteration 421 : loss : 0.132959, loss_ce: 0.071703
2022-01-15 23:46:35,597 iteration 422 : loss : 0.110371, loss_ce: 0.037975
2022-01-15 23:46:36,613 iteration 423 : loss : 0.109597, loss_ce: 0.043215
2022-01-15 23:46:37,659 iteration 424 : loss : 0.105780, loss_ce: 0.040861
2022-01-15 23:46:37,659 Training Data Eval:
2022-01-15 23:46:42,447   Average segmentation loss on training set: 0.0910
2022-01-15 23:46:42,448 Validation Data Eval:
2022-01-15 23:46:44,075   Average segmentation loss on validation set: 0.1958
2022-01-15 23:46:45,128 iteration 425 : loss : 0.109268, loss_ce: 0.041605
  6%|█▉                            | 25/400 [07:33<2:01:50, 19.49s/it]2022-01-15 23:46:46,241 iteration 426 : loss : 0.097201, loss_ce: 0.043435
2022-01-15 23:46:47,254 iteration 427 : loss : 0.143614, loss_ce: 0.055894
2022-01-15 23:46:48,305 iteration 428 : loss : 0.106587, loss_ce: 0.042617
2022-01-15 23:46:49,277 iteration 429 : loss : 0.094403, loss_ce: 0.036094
2022-01-15 23:46:50,298 iteration 430 : loss : 0.150242, loss_ce: 0.057763
2022-01-15 23:46:51,245 iteration 431 : loss : 0.114052, loss_ce: 0.041347
2022-01-15 23:46:52,222 iteration 432 : loss : 0.070241, loss_ce: 0.027922
2022-01-15 23:46:53,235 iteration 433 : loss : 0.124000, loss_ce: 0.039039
2022-01-15 23:46:54,220 iteration 434 : loss : 0.082907, loss_ce: 0.030355
2022-01-15 23:46:55,208 iteration 435 : loss : 0.149749, loss_ce: 0.079378
2022-01-15 23:46:56,249 iteration 436 : loss : 0.152025, loss_ce: 0.058596
2022-01-15 23:46:57,254 iteration 437 : loss : 0.124132, loss_ce: 0.046361
2022-01-15 23:46:58,259 iteration 438 : loss : 0.146322, loss_ce: 0.078298
2022-01-15 23:46:59,270 iteration 439 : loss : 0.107073, loss_ce: 0.051210
2022-01-15 23:47:00,269 iteration 440 : loss : 0.079191, loss_ce: 0.033285
2022-01-15 23:47:01,267 iteration 441 : loss : 0.117328, loss_ce: 0.053382
2022-01-15 23:47:02,253 iteration 442 : loss : 0.199361, loss_ce: 0.070494
  6%|█▉                            | 26/400 [07:50<1:57:05, 18.78s/it]2022-01-15 23:47:03,366 iteration 443 : loss : 0.094106, loss_ce: 0.044946
2022-01-15 23:47:04,352 iteration 444 : loss : 0.147990, loss_ce: 0.058192
2022-01-15 23:47:05,530 iteration 445 : loss : 0.118929, loss_ce: 0.055663
2022-01-15 23:47:06,479 iteration 446 : loss : 0.164518, loss_ce: 0.064776
2022-01-15 23:47:07,557 iteration 447 : loss : 0.126209, loss_ce: 0.053595
2022-01-15 23:47:08,599 iteration 448 : loss : 0.109685, loss_ce: 0.052845
2022-01-15 23:47:09,587 iteration 449 : loss : 0.109740, loss_ce: 0.039591
2022-01-15 23:47:10,514 iteration 450 : loss : 0.090361, loss_ce: 0.037309
2022-01-15 23:47:11,506 iteration 451 : loss : 0.095904, loss_ce: 0.033824
2022-01-15 23:47:12,527 iteration 452 : loss : 0.079791, loss_ce: 0.032440
2022-01-15 23:47:13,535 iteration 453 : loss : 0.093213, loss_ce: 0.024333
2022-01-15 23:47:14,576 iteration 454 : loss : 0.178775, loss_ce: 0.061779
2022-01-15 23:47:15,650 iteration 455 : loss : 0.100282, loss_ce: 0.031808
2022-01-15 23:47:16,628 iteration 456 : loss : 0.104716, loss_ce: 0.035515
2022-01-15 23:47:17,605 iteration 457 : loss : 0.079269, loss_ce: 0.030511
2022-01-15 23:47:18,602 iteration 458 : loss : 0.108749, loss_ce: 0.046689
2022-01-15 23:47:19,646 iteration 459 : loss : 0.096331, loss_ce: 0.039687
  7%|██                            | 27/400 [08:07<1:54:10, 18.37s/it]2022-01-15 23:47:20,626 iteration 460 : loss : 0.104711, loss_ce: 0.037967
2022-01-15 23:47:21,651 iteration 461 : loss : 0.153046, loss_ce: 0.065634
2022-01-15 23:47:22,661 iteration 462 : loss : 0.156404, loss_ce: 0.046426
2022-01-15 23:47:23,582 iteration 463 : loss : 0.090706, loss_ce: 0.043354
2022-01-15 23:47:24,669 iteration 464 : loss : 0.118487, loss_ce: 0.047815
2022-01-15 23:47:25,655 iteration 465 : loss : 0.112322, loss_ce: 0.063274
2022-01-15 23:47:26,710 iteration 466 : loss : 0.102279, loss_ce: 0.046949
2022-01-15 23:47:27,685 iteration 467 : loss : 0.124487, loss_ce: 0.046729
2022-01-15 23:47:28,681 iteration 468 : loss : 0.102616, loss_ce: 0.039725
2022-01-15 23:47:29,642 iteration 469 : loss : 0.129305, loss_ce: 0.050754
2022-01-15 23:47:30,710 iteration 470 : loss : 0.103501, loss_ce: 0.048952
2022-01-15 23:47:31,669 iteration 471 : loss : 0.096873, loss_ce: 0.035672
2022-01-15 23:47:32,720 iteration 472 : loss : 0.141220, loss_ce: 0.056613
2022-01-15 23:47:33,759 iteration 473 : loss : 0.089023, loss_ce: 0.033757
2022-01-15 23:47:34,819 iteration 474 : loss : 0.093365, loss_ce: 0.037996
2022-01-15 23:47:35,833 iteration 475 : loss : 0.131673, loss_ce: 0.041990
2022-01-15 23:47:36,868 iteration 476 : loss : 0.105005, loss_ce: 0.050466
  7%|██                            | 28/400 [08:25<1:51:44, 18.02s/it]2022-01-15 23:47:37,923 iteration 477 : loss : 0.102838, loss_ce: 0.045483
2022-01-15 23:47:38,969 iteration 478 : loss : 0.124966, loss_ce: 0.047967
2022-01-15 23:47:39,919 iteration 479 : loss : 0.094965, loss_ce: 0.040624
2022-01-15 23:47:40,837 iteration 480 : loss : 0.096724, loss_ce: 0.042380
2022-01-15 23:47:41,826 iteration 481 : loss : 0.083905, loss_ce: 0.035318
2022-01-15 23:47:42,880 iteration 482 : loss : 0.110611, loss_ce: 0.041254
2022-01-15 23:47:43,898 iteration 483 : loss : 0.094381, loss_ce: 0.030133
2022-01-15 23:47:44,898 iteration 484 : loss : 0.100525, loss_ce: 0.037923
2022-01-15 23:47:45,838 iteration 485 : loss : 0.073470, loss_ce: 0.028168
2022-01-15 23:47:46,833 iteration 486 : loss : 0.207089, loss_ce: 0.068952
2022-01-15 23:47:47,868 iteration 487 : loss : 0.139275, loss_ce: 0.070587
2022-01-15 23:47:48,967 iteration 488 : loss : 0.126539, loss_ce: 0.050646
2022-01-15 23:47:50,020 iteration 489 : loss : 0.084858, loss_ce: 0.035309
2022-01-15 23:47:50,983 iteration 490 : loss : 0.107717, loss_ce: 0.049685
2022-01-15 23:47:52,060 iteration 491 : loss : 0.131431, loss_ce: 0.056402
2022-01-15 23:47:53,022 iteration 492 : loss : 0.109181, loss_ce: 0.040119
2022-01-15 23:47:54,007 iteration 493 : loss : 0.143035, loss_ce: 0.062066
  7%|██▏                           | 29/400 [08:42<1:49:47, 17.76s/it]2022-01-15 23:47:55,032 iteration 494 : loss : 0.108641, loss_ce: 0.045952
2022-01-15 23:47:56,030 iteration 495 : loss : 0.079377, loss_ce: 0.032924
2022-01-15 23:47:56,949 iteration 496 : loss : 0.117352, loss_ce: 0.053662
2022-01-15 23:47:57,988 iteration 497 : loss : 0.106156, loss_ce: 0.035956
2022-01-15 23:47:58,979 iteration 498 : loss : 0.115460, loss_ce: 0.047816
2022-01-15 23:48:00,052 iteration 499 : loss : 0.103707, loss_ce: 0.044541
2022-01-15 23:48:00,973 iteration 500 : loss : 0.070441, loss_ce: 0.027173
2022-01-15 23:48:01,986 iteration 501 : loss : 0.093537, loss_ce: 0.029228
2022-01-15 23:48:02,960 iteration 502 : loss : 0.086716, loss_ce: 0.028932
2022-01-15 23:48:03,961 iteration 503 : loss : 0.124281, loss_ce: 0.060263
2022-01-15 23:48:05,035 iteration 504 : loss : 0.063985, loss_ce: 0.025198
2022-01-15 23:48:06,111 iteration 505 : loss : 0.085747, loss_ce: 0.035181
2022-01-15 23:48:07,136 iteration 506 : loss : 0.097729, loss_ce: 0.048417
2022-01-15 23:48:08,127 iteration 507 : loss : 0.072968, loss_ce: 0.028178
2022-01-15 23:48:09,161 iteration 508 : loss : 0.122375, loss_ce: 0.038837
2022-01-15 23:48:10,218 iteration 509 : loss : 0.120373, loss_ce: 0.057835
2022-01-15 23:48:10,219 Training Data Eval:
2022-01-15 23:48:15,021   Average segmentation loss on training set: 0.0759
2022-01-15 23:48:15,021 Validation Data Eval:
2022-01-15 23:48:16,656   Average segmentation loss on validation set: 0.1102
2022-01-15 23:48:17,647 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed2.pth
2022-01-15 23:48:18,639 iteration 510 : loss : 0.075218, loss_ce: 0.032257
  8%|██▎                           | 30/400 [09:06<2:02:13, 19.82s/it]2022-01-15 23:48:19,661 iteration 511 : loss : 0.088436, loss_ce: 0.031266
2022-01-15 23:48:20,647 iteration 512 : loss : 0.098539, loss_ce: 0.048062
2022-01-15 23:48:21,650 iteration 513 : loss : 0.078210, loss_ce: 0.030936
2022-01-15 23:48:22,681 iteration 514 : loss : 0.112469, loss_ce: 0.042738
2022-01-15 23:48:23,615 iteration 515 : loss : 0.099894, loss_ce: 0.042459
2022-01-15 23:48:24,515 iteration 516 : loss : 0.069891, loss_ce: 0.025182
2022-01-15 23:48:25,586 iteration 517 : loss : 0.096398, loss_ce: 0.047603
2022-01-15 23:48:26,675 iteration 518 : loss : 0.155021, loss_ce: 0.059665
2022-01-15 23:48:27,753 iteration 519 : loss : 0.100433, loss_ce: 0.048356
2022-01-15 23:48:28,769 iteration 520 : loss : 0.082036, loss_ce: 0.034574
2022-01-15 23:48:29,712 iteration 521 : loss : 0.075239, loss_ce: 0.028394
2022-01-15 23:48:30,757 iteration 522 : loss : 0.115495, loss_ce: 0.047691
2022-01-15 23:48:31,752 iteration 523 : loss : 0.099598, loss_ce: 0.032773
2022-01-15 23:48:32,730 iteration 524 : loss : 0.105557, loss_ce: 0.050487
2022-01-15 23:48:33,716 iteration 525 : loss : 0.075788, loss_ce: 0.029970
2022-01-15 23:48:34,755 iteration 526 : loss : 0.090103, loss_ce: 0.040188
2022-01-15 23:48:35,789 iteration 527 : loss : 0.111697, loss_ce: 0.041711
  8%|██▎                           | 31/400 [09:24<1:56:58, 19.02s/it]2022-01-15 23:48:36,831 iteration 528 : loss : 0.082113, loss_ce: 0.033745
2022-01-15 23:48:37,944 iteration 529 : loss : 0.139240, loss_ce: 0.045506
2022-01-15 23:48:38,920 iteration 530 : loss : 0.060142, loss_ce: 0.022575
2022-01-15 23:48:39,882 iteration 531 : loss : 0.079435, loss_ce: 0.031692
2022-01-15 23:48:40,901 iteration 532 : loss : 0.103329, loss_ce: 0.042884
2022-01-15 23:48:41,921 iteration 533 : loss : 0.077583, loss_ce: 0.032681
2022-01-15 23:48:42,925 iteration 534 : loss : 0.086503, loss_ce: 0.035530
2022-01-15 23:48:43,975 iteration 535 : loss : 0.101918, loss_ce: 0.034134
2022-01-15 23:48:44,983 iteration 536 : loss : 0.088209, loss_ce: 0.045365
2022-01-15 23:48:45,970 iteration 537 : loss : 0.111313, loss_ce: 0.045482
2022-01-15 23:48:46,977 iteration 538 : loss : 0.096454, loss_ce: 0.045439
2022-01-15 23:48:47,912 iteration 539 : loss : 0.086767, loss_ce: 0.034025
2022-01-15 23:48:49,036 iteration 540 : loss : 0.115224, loss_ce: 0.058645
2022-01-15 23:48:50,134 iteration 541 : loss : 0.146424, loss_ce: 0.074029
2022-01-15 23:48:51,086 iteration 542 : loss : 0.115451, loss_ce: 0.047852
2022-01-15 23:48:52,094 iteration 543 : loss : 0.086209, loss_ce: 0.036635
2022-01-15 23:48:53,081 iteration 544 : loss : 0.176293, loss_ce: 0.059324
  8%|██▍                           | 32/400 [09:41<1:53:28, 18.50s/it]2022-01-15 23:48:54,205 iteration 545 : loss : 0.096045, loss_ce: 0.042205
2022-01-15 23:48:55,279 iteration 546 : loss : 0.078004, loss_ce: 0.032687
2022-01-15 23:48:56,337 iteration 547 : loss : 0.093452, loss_ce: 0.037365
2022-01-15 23:48:57,287 iteration 548 : loss : 0.134562, loss_ce: 0.051277
2022-01-15 23:48:58,241 iteration 549 : loss : 0.117103, loss_ce: 0.048521
2022-01-15 23:48:59,203 iteration 550 : loss : 0.097611, loss_ce: 0.038967
2022-01-15 23:49:00,161 iteration 551 : loss : 0.121251, loss_ce: 0.034763
2022-01-15 23:49:01,202 iteration 552 : loss : 0.173761, loss_ce: 0.080317
2022-01-15 23:49:02,224 iteration 553 : loss : 0.072694, loss_ce: 0.028030
2022-01-15 23:49:03,242 iteration 554 : loss : 0.126809, loss_ce: 0.050293
2022-01-15 23:49:04,283 iteration 555 : loss : 0.076177, loss_ce: 0.023538
2022-01-15 23:49:05,386 iteration 556 : loss : 0.123652, loss_ce: 0.051325
2022-01-15 23:49:06,355 iteration 557 : loss : 0.104443, loss_ce: 0.050620
2022-01-15 23:49:07,308 iteration 558 : loss : 0.074729, loss_ce: 0.030339
2022-01-15 23:49:08,290 iteration 559 : loss : 0.098804, loss_ce: 0.038124
2022-01-15 23:49:09,355 iteration 560 : loss : 0.099654, loss_ce: 0.047242
2022-01-15 23:49:10,398 iteration 561 : loss : 0.068309, loss_ce: 0.032106
  8%|██▍                           | 33/400 [09:58<1:50:59, 18.15s/it]2022-01-15 23:49:11,497 iteration 562 : loss : 0.115103, loss_ce: 0.043387
2022-01-15 23:49:12,456 iteration 563 : loss : 0.079250, loss_ce: 0.038613
2022-01-15 23:49:13,412 iteration 564 : loss : 0.101393, loss_ce: 0.049997
2022-01-15 23:49:14,441 iteration 565 : loss : 0.083648, loss_ce: 0.033262
2022-01-15 23:49:15,459 iteration 566 : loss : 0.120763, loss_ce: 0.040775
2022-01-15 23:49:16,493 iteration 567 : loss : 0.122780, loss_ce: 0.048866
2022-01-15 23:49:17,523 iteration 568 : loss : 0.141171, loss_ce: 0.038963
2022-01-15 23:49:18,608 iteration 569 : loss : 0.129907, loss_ce: 0.043728
2022-01-15 23:49:19,629 iteration 570 : loss : 0.072519, loss_ce: 0.030125
2022-01-15 23:49:20,675 iteration 571 : loss : 0.092844, loss_ce: 0.040093
2022-01-15 23:49:21,741 iteration 572 : loss : 0.101939, loss_ce: 0.044346
2022-01-15 23:49:22,715 iteration 573 : loss : 0.102276, loss_ce: 0.046467
2022-01-15 23:49:23,799 iteration 574 : loss : 0.103000, loss_ce: 0.041143
2022-01-15 23:49:24,795 iteration 575 : loss : 0.117533, loss_ce: 0.032636
2022-01-15 23:49:25,742 iteration 576 : loss : 0.111210, loss_ce: 0.050393
2022-01-15 23:49:26,866 iteration 577 : loss : 0.115234, loss_ce: 0.048810
2022-01-15 23:49:27,913 iteration 578 : loss : 0.077488, loss_ce: 0.033237
  8%|██▌                           | 34/400 [10:16<1:49:31, 17.95s/it]2022-01-15 23:49:28,914 iteration 579 : loss : 0.063720, loss_ce: 0.027489
2022-01-15 23:49:29,961 iteration 580 : loss : 0.079906, loss_ce: 0.030827
2022-01-15 23:49:31,109 iteration 581 : loss : 0.058377, loss_ce: 0.025841
2022-01-15 23:49:32,077 iteration 582 : loss : 0.068648, loss_ce: 0.028947
2022-01-15 23:49:33,101 iteration 583 : loss : 0.095702, loss_ce: 0.042057
2022-01-15 23:49:34,150 iteration 584 : loss : 0.104682, loss_ce: 0.046917
2022-01-15 23:49:35,129 iteration 585 : loss : 0.096956, loss_ce: 0.032688
2022-01-15 23:49:36,187 iteration 586 : loss : 0.082031, loss_ce: 0.031113
2022-01-15 23:49:37,218 iteration 587 : loss : 0.070966, loss_ce: 0.031216
2022-01-15 23:49:38,188 iteration 588 : loss : 0.102212, loss_ce: 0.037739
2022-01-15 23:49:39,255 iteration 589 : loss : 0.123489, loss_ce: 0.056853
2022-01-15 23:49:40,245 iteration 590 : loss : 0.102392, loss_ce: 0.036772
2022-01-15 23:49:41,235 iteration 591 : loss : 0.093719, loss_ce: 0.032097
2022-01-15 23:49:42,274 iteration 592 : loss : 0.062720, loss_ce: 0.026747
2022-01-15 23:49:43,226 iteration 593 : loss : 0.121520, loss_ce: 0.045611
2022-01-15 23:49:44,280 iteration 594 : loss : 0.077426, loss_ce: 0.025612
2022-01-15 23:49:44,280 Training Data Eval:
2022-01-15 23:49:49,083   Average segmentation loss on training set: 0.0692
2022-01-15 23:49:49,083 Validation Data Eval:
2022-01-15 23:49:50,711   Average segmentation loss on validation set: 0.1209
2022-01-15 23:49:51,732 iteration 595 : loss : 0.128404, loss_ce: 0.041943
  9%|██▋                           | 35/400 [10:40<1:59:56, 19.72s/it]2022-01-15 23:49:52,873 iteration 596 : loss : 0.101602, loss_ce: 0.043059
2022-01-15 23:49:53,880 iteration 597 : loss : 0.071917, loss_ce: 0.026276
2022-01-15 23:49:54,885 iteration 598 : loss : 0.082161, loss_ce: 0.025787
2022-01-15 23:49:55,921 iteration 599 : loss : 0.118078, loss_ce: 0.046758
2022-01-15 23:49:56,971 iteration 600 : loss : 0.088550, loss_ce: 0.027954
2022-01-15 23:49:58,013 iteration 601 : loss : 0.073816, loss_ce: 0.025235
2022-01-15 23:49:58,938 iteration 602 : loss : 0.103030, loss_ce: 0.048767
2022-01-15 23:49:59,950 iteration 603 : loss : 0.062269, loss_ce: 0.025166
2022-01-15 23:50:00,922 iteration 604 : loss : 0.114768, loss_ce: 0.038856
2022-01-15 23:50:02,039 iteration 605 : loss : 0.083375, loss_ce: 0.031631
2022-01-15 23:50:03,008 iteration 606 : loss : 0.066904, loss_ce: 0.026126
2022-01-15 23:50:03,972 iteration 607 : loss : 0.073543, loss_ce: 0.026533
2022-01-15 23:50:04,933 iteration 608 : loss : 0.054624, loss_ce: 0.026752
2022-01-15 23:50:05,893 iteration 609 : loss : 0.095535, loss_ce: 0.038177
2022-01-15 23:50:06,987 iteration 610 : loss : 0.119454, loss_ce: 0.056557
2022-01-15 23:50:07,980 iteration 611 : loss : 0.078835, loss_ce: 0.032171
2022-01-15 23:50:08,922 iteration 612 : loss : 0.062945, loss_ce: 0.026284
  9%|██▋                           | 36/400 [10:57<1:55:00, 18.96s/it]2022-01-15 23:50:09,980 iteration 613 : loss : 0.100372, loss_ce: 0.036897
2022-01-15 23:50:11,038 iteration 614 : loss : 0.061747, loss_ce: 0.026236
2022-01-15 23:50:12,082 iteration 615 : loss : 0.073035, loss_ce: 0.032924
2022-01-15 23:50:13,064 iteration 616 : loss : 0.083135, loss_ce: 0.029145
2022-01-15 23:50:14,105 iteration 617 : loss : 0.128729, loss_ce: 0.048990
2022-01-15 23:50:15,178 iteration 618 : loss : 0.075254, loss_ce: 0.033121
2022-01-15 23:50:16,209 iteration 619 : loss : 0.084787, loss_ce: 0.030245
2022-01-15 23:50:17,265 iteration 620 : loss : 0.067820, loss_ce: 0.027464
2022-01-15 23:50:18,188 iteration 621 : loss : 0.065820, loss_ce: 0.023138
2022-01-15 23:50:19,254 iteration 622 : loss : 0.093978, loss_ce: 0.037992
2022-01-15 23:50:20,324 iteration 623 : loss : 0.095293, loss_ce: 0.041058
2022-01-15 23:50:21,263 iteration 624 : loss : 0.083338, loss_ce: 0.033274
2022-01-15 23:50:22,390 iteration 625 : loss : 0.068699, loss_ce: 0.029370
2022-01-15 23:50:23,421 iteration 626 : loss : 0.061840, loss_ce: 0.025949
2022-01-15 23:50:24,380 iteration 627 : loss : 0.124927, loss_ce: 0.040447
2022-01-15 23:50:25,301 iteration 628 : loss : 0.106253, loss_ce: 0.037603
2022-01-15 23:50:26,340 iteration 629 : loss : 0.059196, loss_ce: 0.024986
  9%|██▊                           | 37/400 [11:14<1:51:53, 18.50s/it]2022-01-15 23:50:27,309 iteration 630 : loss : 0.084806, loss_ce: 0.036250
2022-01-15 23:50:28,306 iteration 631 : loss : 0.092829, loss_ce: 0.036878
2022-01-15 23:50:29,245 iteration 632 : loss : 0.063216, loss_ce: 0.024048
2022-01-15 23:50:30,276 iteration 633 : loss : 0.084786, loss_ce: 0.041782
2022-01-15 23:50:31,296 iteration 634 : loss : 0.062833, loss_ce: 0.025936
2022-01-15 23:50:32,330 iteration 635 : loss : 0.077329, loss_ce: 0.031296
2022-01-15 23:50:33,312 iteration 636 : loss : 0.121488, loss_ce: 0.034721
2022-01-15 23:50:34,279 iteration 637 : loss : 0.082491, loss_ce: 0.038212
2022-01-15 23:50:35,246 iteration 638 : loss : 0.071957, loss_ce: 0.032791
2022-01-15 23:50:36,287 iteration 639 : loss : 0.067553, loss_ce: 0.031266
2022-01-15 23:50:37,337 iteration 640 : loss : 0.081417, loss_ce: 0.027630
2022-01-15 23:50:38,293 iteration 641 : loss : 0.075247, loss_ce: 0.027415
2022-01-15 23:50:39,305 iteration 642 : loss : 0.068221, loss_ce: 0.026426
2022-01-15 23:50:40,289 iteration 643 : loss : 0.083878, loss_ce: 0.027694
2022-01-15 23:50:41,288 iteration 644 : loss : 0.064353, loss_ce: 0.022376
2022-01-15 23:50:42,258 iteration 645 : loss : 0.140006, loss_ce: 0.049655
2022-01-15 23:50:43,297 iteration 646 : loss : 0.064511, loss_ce: 0.024773
 10%|██▊                           | 38/400 [11:31<1:48:49, 18.04s/it]2022-01-15 23:50:44,337 iteration 647 : loss : 0.083096, loss_ce: 0.030375
2022-01-15 23:50:45,388 iteration 648 : loss : 0.078600, loss_ce: 0.031255
2022-01-15 23:50:46,411 iteration 649 : loss : 0.089073, loss_ce: 0.039162
2022-01-15 23:50:47,350 iteration 650 : loss : 0.075287, loss_ce: 0.036829
2022-01-15 23:50:48,355 iteration 651 : loss : 0.094854, loss_ce: 0.037352
2022-01-15 23:50:49,317 iteration 652 : loss : 0.096699, loss_ce: 0.032036
2022-01-15 23:50:50,331 iteration 653 : loss : 0.142813, loss_ce: 0.039633
2022-01-15 23:50:51,414 iteration 654 : loss : 0.119570, loss_ce: 0.037883
2022-01-15 23:50:52,461 iteration 655 : loss : 0.055212, loss_ce: 0.021272
2022-01-15 23:50:53,403 iteration 656 : loss : 0.063609, loss_ce: 0.023835
2022-01-15 23:50:54,410 iteration 657 : loss : 0.065848, loss_ce: 0.026892
2022-01-15 23:50:55,463 iteration 658 : loss : 0.153333, loss_ce: 0.061604
2022-01-15 23:50:56,523 iteration 659 : loss : 0.070960, loss_ce: 0.030608
2022-01-15 23:50:57,544 iteration 660 : loss : 0.078351, loss_ce: 0.026489
2022-01-15 23:50:58,555 iteration 661 : loss : 0.079900, loss_ce: 0.036661
2022-01-15 23:50:59,523 iteration 662 : loss : 0.077494, loss_ce: 0.036444
2022-01-15 23:51:00,524 iteration 663 : loss : 0.082522, loss_ce: 0.025330
 10%|██▉                           | 39/400 [11:48<1:47:03, 17.79s/it]2022-01-15 23:51:01,546 iteration 664 : loss : 0.081741, loss_ce: 0.039488
2022-01-15 23:51:02,536 iteration 665 : loss : 0.080330, loss_ce: 0.037988
2022-01-15 23:51:03,554 iteration 666 : loss : 0.080445, loss_ce: 0.032317
2022-01-15 23:51:04,515 iteration 667 : loss : 0.064975, loss_ce: 0.028743
2022-01-15 23:51:05,573 iteration 668 : loss : 0.076889, loss_ce: 0.030714
2022-01-15 23:51:06,540 iteration 669 : loss : 0.090319, loss_ce: 0.039194
2022-01-15 23:51:07,511 iteration 670 : loss : 0.061546, loss_ce: 0.026632
2022-01-15 23:51:08,559 iteration 671 : loss : 0.071367, loss_ce: 0.026955
2022-01-15 23:51:09,613 iteration 672 : loss : 0.065840, loss_ce: 0.025602
2022-01-15 23:51:10,570 iteration 673 : loss : 0.112965, loss_ce: 0.053514
2022-01-15 23:51:11,599 iteration 674 : loss : 0.098296, loss_ce: 0.039565
2022-01-15 23:51:12,645 iteration 675 : loss : 0.094451, loss_ce: 0.034278
2022-01-15 23:51:13,629 iteration 676 : loss : 0.119917, loss_ce: 0.038572
2022-01-15 23:51:14,644 iteration 677 : loss : 0.074874, loss_ce: 0.031216
2022-01-15 23:51:15,654 iteration 678 : loss : 0.110000, loss_ce: 0.040698
2022-01-15 23:51:16,615 iteration 679 : loss : 0.115469, loss_ce: 0.058238
2022-01-15 23:51:16,616 Training Data Eval:
2022-01-15 23:51:21,410   Average segmentation loss on training set: 0.0673
2022-01-15 23:51:21,411 Validation Data Eval:
2022-01-15 23:51:23,042   Average segmentation loss on validation set: 0.1572
2022-01-15 23:51:24,064 iteration 680 : loss : 0.171226, loss_ce: 0.049047
 10%|███                           | 40/400 [12:12<1:57:05, 19.52s/it]2022-01-15 23:51:25,180 iteration 681 : loss : 0.089550, loss_ce: 0.037636
2022-01-15 23:51:26,147 iteration 682 : loss : 0.074055, loss_ce: 0.024906
2022-01-15 23:51:27,174 iteration 683 : loss : 0.092958, loss_ce: 0.040890
2022-01-15 23:51:28,207 iteration 684 : loss : 0.074827, loss_ce: 0.026779
2022-01-15 23:51:29,268 iteration 685 : loss : 0.075625, loss_ce: 0.027492
2022-01-15 23:51:30,188 iteration 686 : loss : 0.090478, loss_ce: 0.027387
2022-01-15 23:51:31,150 iteration 687 : loss : 0.067512, loss_ce: 0.023679
2022-01-15 23:51:32,215 iteration 688 : loss : 0.096809, loss_ce: 0.039009
2022-01-15 23:51:33,227 iteration 689 : loss : 0.070966, loss_ce: 0.029973
2022-01-15 23:51:34,181 iteration 690 : loss : 0.091498, loss_ce: 0.046274
2022-01-15 23:51:35,270 iteration 691 : loss : 0.078797, loss_ce: 0.031001
2022-01-15 23:51:36,331 iteration 692 : loss : 0.091838, loss_ce: 0.034059
2022-01-15 23:51:37,380 iteration 693 : loss : 0.105580, loss_ce: 0.040295
2022-01-15 23:51:38,392 iteration 694 : loss : 0.093565, loss_ce: 0.037819
2022-01-15 23:51:39,410 iteration 695 : loss : 0.091025, loss_ce: 0.032661
2022-01-15 23:51:40,415 iteration 696 : loss : 0.079283, loss_ce: 0.034873
2022-01-15 23:51:41,436 iteration 697 : loss : 0.126663, loss_ce: 0.040952
 10%|███                           | 41/400 [12:29<1:52:55, 18.87s/it]2022-01-15 23:51:42,481 iteration 698 : loss : 0.096848, loss_ce: 0.042222
2022-01-15 23:51:43,484 iteration 699 : loss : 0.083177, loss_ce: 0.027551
2022-01-15 23:51:44,495 iteration 700 : loss : 0.099183, loss_ce: 0.038227
2022-01-15 23:51:45,484 iteration 701 : loss : 0.122327, loss_ce: 0.051287
2022-01-15 23:51:46,522 iteration 702 : loss : 0.077891, loss_ce: 0.024825
2022-01-15 23:51:47,522 iteration 703 : loss : 0.109862, loss_ce: 0.040620
2022-01-15 23:51:48,514 iteration 704 : loss : 0.086330, loss_ce: 0.026138
2022-01-15 23:51:49,474 iteration 705 : loss : 0.086843, loss_ce: 0.037338
2022-01-15 23:51:50,522 iteration 706 : loss : 0.058206, loss_ce: 0.024505
2022-01-15 23:51:51,554 iteration 707 : loss : 0.084421, loss_ce: 0.042773
2022-01-15 23:51:52,571 iteration 708 : loss : 0.085210, loss_ce: 0.031212
2022-01-15 23:51:53,604 iteration 709 : loss : 0.072192, loss_ce: 0.030010
2022-01-15 23:51:54,622 iteration 710 : loss : 0.088754, loss_ce: 0.027848
2022-01-15 23:51:55,672 iteration 711 : loss : 0.135154, loss_ce: 0.040028
2022-01-15 23:51:56,740 iteration 712 : loss : 0.067198, loss_ce: 0.030434
2022-01-15 23:51:57,710 iteration 713 : loss : 0.073129, loss_ce: 0.029552
2022-01-15 23:51:58,709 iteration 714 : loss : 0.066805, loss_ce: 0.034388
 10%|███▏                          | 42/400 [12:47<1:49:45, 18.39s/it]2022-01-15 23:51:59,761 iteration 715 : loss : 0.063752, loss_ce: 0.029853
2022-01-15 23:52:00,760 iteration 716 : loss : 0.120450, loss_ce: 0.035556
2022-01-15 23:52:01,745 iteration 717 : loss : 0.073081, loss_ce: 0.027434
2022-01-15 23:52:02,656 iteration 718 : loss : 0.075514, loss_ce: 0.027235
2022-01-15 23:52:03,662 iteration 719 : loss : 0.084266, loss_ce: 0.045149
2022-01-15 23:52:04,585 iteration 720 : loss : 0.060368, loss_ce: 0.026186
2022-01-15 23:52:05,719 iteration 721 : loss : 0.097353, loss_ce: 0.039160
2022-01-15 23:52:06,726 iteration 722 : loss : 0.056826, loss_ce: 0.024610
2022-01-15 23:52:07,743 iteration 723 : loss : 0.089861, loss_ce: 0.034427
2022-01-15 23:52:08,849 iteration 724 : loss : 0.072902, loss_ce: 0.031316
2022-01-15 23:52:09,816 iteration 725 : loss : 0.063888, loss_ce: 0.029273
2022-01-15 23:52:10,833 iteration 726 : loss : 0.115735, loss_ce: 0.065559
2022-01-15 23:52:11,805 iteration 727 : loss : 0.054702, loss_ce: 0.020886
2022-01-15 23:52:12,790 iteration 728 : loss : 0.061329, loss_ce: 0.019675
2022-01-15 23:52:13,768 iteration 729 : loss : 0.100679, loss_ce: 0.048799
2022-01-15 23:52:14,785 iteration 730 : loss : 0.073359, loss_ce: 0.027336
2022-01-15 23:52:15,754 iteration 731 : loss : 0.121917, loss_ce: 0.047993
 11%|███▏                          | 43/400 [13:04<1:47:02, 17.99s/it]2022-01-15 23:52:16,852 iteration 732 : loss : 0.066094, loss_ce: 0.027096
2022-01-15 23:52:17,876 iteration 733 : loss : 0.064629, loss_ce: 0.024284
2022-01-15 23:52:18,897 iteration 734 : loss : 0.168199, loss_ce: 0.103747
2022-01-15 23:52:19,933 iteration 735 : loss : 0.100204, loss_ce: 0.029187
2022-01-15 23:52:20,962 iteration 736 : loss : 0.075157, loss_ce: 0.030326
2022-01-15 23:52:21,910 iteration 737 : loss : 0.060723, loss_ce: 0.023679
2022-01-15 23:52:22,973 iteration 738 : loss : 0.067645, loss_ce: 0.028955
2022-01-15 23:52:24,002 iteration 739 : loss : 0.086976, loss_ce: 0.042383
2022-01-15 23:52:25,005 iteration 740 : loss : 0.071626, loss_ce: 0.023083
2022-01-15 23:52:26,038 iteration 741 : loss : 0.094984, loss_ce: 0.034585
2022-01-15 23:52:27,100 iteration 742 : loss : 0.068886, loss_ce: 0.026300
2022-01-15 23:52:28,090 iteration 743 : loss : 0.063470, loss_ce: 0.022682
2022-01-15 23:52:29,159 iteration 744 : loss : 0.060790, loss_ce: 0.024015
2022-01-15 23:52:30,162 iteration 745 : loss : 0.085495, loss_ce: 0.027845
2022-01-15 23:52:31,143 iteration 746 : loss : 0.123438, loss_ce: 0.041432
2022-01-15 23:52:32,130 iteration 747 : loss : 0.091648, loss_ce: 0.043440
2022-01-15 23:52:33,153 iteration 748 : loss : 0.074261, loss_ce: 0.023892
 11%|███▎                          | 44/400 [13:21<1:45:39, 17.81s/it]2022-01-15 23:52:34,186 iteration 749 : loss : 0.104631, loss_ce: 0.030135
2022-01-15 23:52:35,166 iteration 750 : loss : 0.069809, loss_ce: 0.024151
2022-01-15 23:52:36,206 iteration 751 : loss : 0.087019, loss_ce: 0.032197
2022-01-15 23:52:37,182 iteration 752 : loss : 0.064787, loss_ce: 0.025604
2022-01-15 23:52:38,217 iteration 753 : loss : 0.055555, loss_ce: 0.022132
2022-01-15 23:52:39,216 iteration 754 : loss : 0.055602, loss_ce: 0.017271
2022-01-15 23:52:40,232 iteration 755 : loss : 0.052008, loss_ce: 0.020745
2022-01-15 23:52:41,154 iteration 756 : loss : 0.059436, loss_ce: 0.024966
2022-01-15 23:52:42,096 iteration 757 : loss : 0.064441, loss_ce: 0.024773
2022-01-15 23:52:43,103 iteration 758 : loss : 0.083209, loss_ce: 0.027222
2022-01-15 23:52:44,145 iteration 759 : loss : 0.110233, loss_ce: 0.038113
2022-01-15 23:52:45,161 iteration 760 : loss : 0.070908, loss_ce: 0.024331
2022-01-15 23:52:46,201 iteration 761 : loss : 0.074746, loss_ce: 0.023344
2022-01-15 23:52:47,127 iteration 762 : loss : 0.067742, loss_ce: 0.026736
2022-01-15 23:52:48,123 iteration 763 : loss : 0.061391, loss_ce: 0.025955
2022-01-15 23:52:49,049 iteration 764 : loss : 0.068199, loss_ce: 0.024095
2022-01-15 23:52:49,049 Training Data Eval:
2022-01-15 23:52:53,866   Average segmentation loss on training set: 0.0664
2022-01-15 23:52:53,866 Validation Data Eval:
2022-01-15 23:52:55,494   Average segmentation loss on validation set: 0.1702
2022-01-15 23:52:56,412 iteration 765 : loss : 0.055316, loss_ce: 0.023925
 11%|███▍                          | 45/400 [13:44<1:55:02, 19.44s/it]2022-01-15 23:52:57,545 iteration 766 : loss : 0.066049, loss_ce: 0.025659
2022-01-15 23:52:58,684 iteration 767 : loss : 0.092893, loss_ce: 0.041988
2022-01-15 23:52:59,720 iteration 768 : loss : 0.076104, loss_ce: 0.028726
2022-01-15 23:53:00,762 iteration 769 : loss : 0.075251, loss_ce: 0.033393
2022-01-15 23:53:01,837 iteration 770 : loss : 0.075563, loss_ce: 0.035658
2022-01-15 23:53:02,866 iteration 771 : loss : 0.051604, loss_ce: 0.025371
2022-01-15 23:53:03,813 iteration 772 : loss : 0.058316, loss_ce: 0.024042
2022-01-15 23:53:04,809 iteration 773 : loss : 0.138862, loss_ce: 0.045448
2022-01-15 23:53:05,880 iteration 774 : loss : 0.051802, loss_ce: 0.022936
2022-01-15 23:53:06,823 iteration 775 : loss : 0.061831, loss_ce: 0.024103
2022-01-15 23:53:07,799 iteration 776 : loss : 0.132965, loss_ce: 0.042611
2022-01-15 23:53:08,906 iteration 777 : loss : 0.069088, loss_ce: 0.031028
2022-01-15 23:53:09,919 iteration 778 : loss : 0.092046, loss_ce: 0.036705
2022-01-15 23:53:10,919 iteration 779 : loss : 0.077855, loss_ce: 0.024892
2022-01-15 23:53:12,021 iteration 780 : loss : 0.125929, loss_ce: 0.044542
2022-01-15 23:53:13,071 iteration 781 : loss : 0.068991, loss_ce: 0.021062
2022-01-15 23:53:14,058 iteration 782 : loss : 0.090563, loss_ce: 0.031079
 12%|███▍                          | 46/400 [14:02<1:51:32, 18.91s/it]2022-01-15 23:53:15,124 iteration 783 : loss : 0.064650, loss_ce: 0.023040
2022-01-15 23:53:16,076 iteration 784 : loss : 0.044192, loss_ce: 0.015709
2022-01-15 23:53:17,141 iteration 785 : loss : 0.090755, loss_ce: 0.025147
2022-01-15 23:53:18,129 iteration 786 : loss : 0.072455, loss_ce: 0.025973
2022-01-15 23:53:19,175 iteration 787 : loss : 0.102232, loss_ce: 0.038530
2022-01-15 23:53:20,138 iteration 788 : loss : 0.084243, loss_ce: 0.034261
2022-01-15 23:53:21,186 iteration 789 : loss : 0.100151, loss_ce: 0.037411
2022-01-15 23:53:22,249 iteration 790 : loss : 0.067386, loss_ce: 0.027824
2022-01-15 23:53:23,192 iteration 791 : loss : 0.060223, loss_ce: 0.029316
2022-01-15 23:53:24,257 iteration 792 : loss : 0.081341, loss_ce: 0.032197
2022-01-15 23:53:25,293 iteration 793 : loss : 0.089481, loss_ce: 0.033468
2022-01-15 23:53:26,343 iteration 794 : loss : 0.050425, loss_ce: 0.019586
2022-01-15 23:53:27,381 iteration 795 : loss : 0.076515, loss_ce: 0.030121
2022-01-15 23:53:28,474 iteration 796 : loss : 0.076144, loss_ce: 0.031982
2022-01-15 23:53:29,477 iteration 797 : loss : 0.069361, loss_ce: 0.030369
2022-01-15 23:53:30,475 iteration 798 : loss : 0.076718, loss_ce: 0.036989
2022-01-15 23:53:31,590 iteration 799 : loss : 0.177458, loss_ce: 0.064810
 12%|███▌                          | 47/400 [14:19<1:48:47, 18.49s/it]2022-01-15 23:53:32,682 iteration 800 : loss : 0.084793, loss_ce: 0.043004
2022-01-15 23:53:33,674 iteration 801 : loss : 0.119788, loss_ce: 0.038782
2022-01-15 23:53:34,716 iteration 802 : loss : 0.088768, loss_ce: 0.042553
2022-01-15 23:53:35,652 iteration 803 : loss : 0.059325, loss_ce: 0.024838
2022-01-15 23:53:36,768 iteration 804 : loss : 0.101909, loss_ce: 0.036612
2022-01-15 23:53:37,755 iteration 805 : loss : 0.091711, loss_ce: 0.042827
2022-01-15 23:53:38,690 iteration 806 : loss : 0.064729, loss_ce: 0.023142
2022-01-15 23:53:39,688 iteration 807 : loss : 0.053836, loss_ce: 0.029139
2022-01-15 23:53:40,690 iteration 808 : loss : 0.085056, loss_ce: 0.027851
2022-01-15 23:53:41,745 iteration 809 : loss : 0.077647, loss_ce: 0.031529
2022-01-15 23:53:42,706 iteration 810 : loss : 0.063628, loss_ce: 0.019859
2022-01-15 23:53:43,736 iteration 811 : loss : 0.068555, loss_ce: 0.026507
2022-01-15 23:53:44,693 iteration 812 : loss : 0.109330, loss_ce: 0.051616
2022-01-15 23:53:45,762 iteration 813 : loss : 0.071402, loss_ce: 0.027665
2022-01-15 23:53:46,858 iteration 814 : loss : 0.152148, loss_ce: 0.039790
2022-01-15 23:53:47,738 iteration 815 : loss : 0.061098, loss_ce: 0.028920
2022-01-15 23:53:48,803 iteration 816 : loss : 0.098338, loss_ce: 0.037596
 12%|███▌                          | 48/400 [14:37<1:46:14, 18.11s/it]2022-01-15 23:53:49,826 iteration 817 : loss : 0.072274, loss_ce: 0.028862
2022-01-15 23:53:50,823 iteration 818 : loss : 0.062646, loss_ce: 0.028661
2022-01-15 23:53:51,971 iteration 819 : loss : 0.084357, loss_ce: 0.039052
2022-01-15 23:53:53,053 iteration 820 : loss : 0.086156, loss_ce: 0.032078
2022-01-15 23:53:54,108 iteration 821 : loss : 0.094263, loss_ce: 0.035945
2022-01-15 23:53:55,144 iteration 822 : loss : 0.061421, loss_ce: 0.025927
2022-01-15 23:53:56,202 iteration 823 : loss : 0.061936, loss_ce: 0.024271
2022-01-15 23:53:57,208 iteration 824 : loss : 0.070536, loss_ce: 0.026122
2022-01-15 23:53:58,314 iteration 825 : loss : 0.110711, loss_ce: 0.032791
2022-01-15 23:53:59,419 iteration 826 : loss : 0.056353, loss_ce: 0.019590
2022-01-15 23:54:00,598 iteration 827 : loss : 0.080388, loss_ce: 0.026024
2022-01-15 23:54:01,706 iteration 828 : loss : 0.084100, loss_ce: 0.030858
2022-01-15 23:54:02,920 iteration 829 : loss : 0.112706, loss_ce: 0.054202
2022-01-15 23:54:04,041 iteration 830 : loss : 0.081846, loss_ce: 0.034895
2022-01-15 23:54:05,199 iteration 831 : loss : 0.075842, loss_ce: 0.032946
2022-01-15 23:54:06,302 iteration 832 : loss : 0.093294, loss_ce: 0.024871
2022-01-15 23:54:07,381 iteration 833 : loss : 0.065522, loss_ce: 0.026250
 12%|███▋                          | 49/400 [14:55<1:46:45, 18.25s/it]2022-01-15 23:54:08,413 iteration 834 : loss : 0.077346, loss_ce: 0.026894
2022-01-15 23:54:09,380 iteration 835 : loss : 0.045897, loss_ce: 0.017031
2022-01-15 23:54:10,497 iteration 836 : loss : 0.083454, loss_ce: 0.028038
2022-01-15 23:54:11,531 iteration 837 : loss : 0.050286, loss_ce: 0.018995
2022-01-15 23:54:12,628 iteration 838 : loss : 0.096100, loss_ce: 0.047248
2022-01-15 23:54:13,638 iteration 839 : loss : 0.056504, loss_ce: 0.021339
2022-01-15 23:54:14,683 iteration 840 : loss : 0.046661, loss_ce: 0.021620
2022-01-15 23:54:15,717 iteration 841 : loss : 0.085065, loss_ce: 0.030250
2022-01-15 23:54:16,867 iteration 842 : loss : 0.070101, loss_ce: 0.023114
2022-01-15 23:54:17,891 iteration 843 : loss : 0.075060, loss_ce: 0.024080
2022-01-15 23:54:18,967 iteration 844 : loss : 0.065899, loss_ce: 0.023387
2022-01-15 23:54:19,954 iteration 845 : loss : 0.074125, loss_ce: 0.035454
2022-01-15 23:54:20,938 iteration 846 : loss : 0.051065, loss_ce: 0.025188
2022-01-15 23:54:22,012 iteration 847 : loss : 0.061333, loss_ce: 0.023570
2022-01-15 23:54:23,024 iteration 848 : loss : 0.053694, loss_ce: 0.020455
2022-01-15 23:54:24,001 iteration 849 : loss : 0.062889, loss_ce: 0.023388
2022-01-15 23:54:24,001 Training Data Eval:
2022-01-15 23:54:28,798   Average segmentation loss on training set: 0.0678
2022-01-15 23:54:28,798 Validation Data Eval:
2022-01-15 23:54:30,426   Average segmentation loss on validation set: 0.1159
2022-01-15 23:54:31,371 iteration 850 : loss : 0.088147, loss_ce: 0.042868
 12%|███▊                          | 50/400 [15:19<1:56:29, 19.97s/it]2022-01-15 23:54:32,421 iteration 851 : loss : 0.059550, loss_ce: 0.022392
2022-01-15 23:54:33,416 iteration 852 : loss : 0.070398, loss_ce: 0.022912
2022-01-15 23:54:34,425 iteration 853 : loss : 0.081252, loss_ce: 0.030416
2022-01-15 23:54:35,443 iteration 854 : loss : 0.063631, loss_ce: 0.027905
2022-01-15 23:54:36,413 iteration 855 : loss : 0.064672, loss_ce: 0.031852
2022-01-15 23:54:37,448 iteration 856 : loss : 0.063981, loss_ce: 0.028370
2022-01-15 23:54:38,428 iteration 857 : loss : 0.078388, loss_ce: 0.031860
2022-01-15 23:54:39,514 iteration 858 : loss : 0.041424, loss_ce: 0.015502
2022-01-15 23:54:40,393 iteration 859 : loss : 0.053426, loss_ce: 0.017282
2022-01-15 23:54:41,381 iteration 860 : loss : 0.053370, loss_ce: 0.018474
2022-01-15 23:54:42,374 iteration 861 : loss : 0.084004, loss_ce: 0.022903
2022-01-15 23:54:43,386 iteration 862 : loss : 0.064138, loss_ce: 0.027844
2022-01-15 23:54:44,379 iteration 863 : loss : 0.103742, loss_ce: 0.037139
2022-01-15 23:54:45,362 iteration 864 : loss : 0.053223, loss_ce: 0.025182
2022-01-15 23:54:46,395 iteration 865 : loss : 0.057463, loss_ce: 0.021377
2022-01-15 23:54:47,357 iteration 866 : loss : 0.073183, loss_ce: 0.028805
2022-01-15 23:54:48,393 iteration 867 : loss : 0.081287, loss_ce: 0.032563
 13%|███▊                          | 51/400 [15:36<1:51:01, 19.09s/it]2022-01-15 23:54:49,440 iteration 868 : loss : 0.053752, loss_ce: 0.023125
2022-01-15 23:54:50,481 iteration 869 : loss : 0.056460, loss_ce: 0.024375
2022-01-15 23:54:51,397 iteration 870 : loss : 0.056450, loss_ce: 0.024058
2022-01-15 23:54:52,375 iteration 871 : loss : 0.071207, loss_ce: 0.040471
2022-01-15 23:54:53,353 iteration 872 : loss : 0.069111, loss_ce: 0.029427
2022-01-15 23:54:54,372 iteration 873 : loss : 0.082009, loss_ce: 0.038568
2022-01-15 23:54:55,377 iteration 874 : loss : 0.055542, loss_ce: 0.022586
2022-01-15 23:54:56,386 iteration 875 : loss : 0.101640, loss_ce: 0.037118
2022-01-15 23:54:57,393 iteration 876 : loss : 0.061574, loss_ce: 0.020325
2022-01-15 23:54:58,462 iteration 877 : loss : 0.051283, loss_ce: 0.020382
2022-01-15 23:54:59,429 iteration 878 : loss : 0.128659, loss_ce: 0.031300
2022-01-15 23:55:00,420 iteration 879 : loss : 0.120546, loss_ce: 0.031321
2022-01-15 23:55:01,380 iteration 880 : loss : 0.052333, loss_ce: 0.023076
2022-01-15 23:55:02,447 iteration 881 : loss : 0.083396, loss_ce: 0.027987
2022-01-15 23:55:03,475 iteration 882 : loss : 0.104878, loss_ce: 0.037459
2022-01-15 23:55:04,442 iteration 883 : loss : 0.068595, loss_ce: 0.020770
2022-01-15 23:55:05,480 iteration 884 : loss : 0.110487, loss_ce: 0.045079
 13%|███▉                          | 52/400 [15:53<1:47:13, 18.49s/it]2022-01-15 23:55:06,555 iteration 885 : loss : 0.056151, loss_ce: 0.025396
2022-01-15 23:55:07,562 iteration 886 : loss : 0.078842, loss_ce: 0.039372
2022-01-15 23:55:08,564 iteration 887 : loss : 0.079650, loss_ce: 0.030746
2022-01-15 23:55:09,625 iteration 888 : loss : 0.085377, loss_ce: 0.034097
2022-01-15 23:55:10,652 iteration 889 : loss : 0.220372, loss_ce: 0.075404
2022-01-15 23:55:11,655 iteration 890 : loss : 0.070597, loss_ce: 0.030266
2022-01-15 23:55:12,703 iteration 891 : loss : 0.067913, loss_ce: 0.039413
2022-01-15 23:55:13,766 iteration 892 : loss : 0.061964, loss_ce: 0.027841
2022-01-15 23:55:14,884 iteration 893 : loss : 0.060831, loss_ce: 0.027627
2022-01-15 23:55:16,073 iteration 894 : loss : 0.079625, loss_ce: 0.032898
2022-01-15 23:55:17,326 iteration 895 : loss : 0.091528, loss_ce: 0.032054
2022-01-15 23:55:18,603 iteration 896 : loss : 0.082234, loss_ce: 0.045217
2022-01-15 23:55:20,020 iteration 897 : loss : 0.079823, loss_ce: 0.028805
2022-01-15 23:55:21,301 iteration 898 : loss : 0.067425, loss_ce: 0.027143
2022-01-15 23:55:22,671 iteration 899 : loss : 0.096277, loss_ce: 0.036805
2022-01-15 23:55:24,038 iteration 900 : loss : 0.057525, loss_ce: 0.020098
2022-01-15 23:55:25,373 iteration 901 : loss : 0.057744, loss_ce: 0.023974
 13%|███▉                          | 53/400 [16:13<1:49:22, 18.91s/it]2022-01-15 23:55:26,868 iteration 902 : loss : 0.070697, loss_ce: 0.034277
2022-01-15 23:55:28,277 iteration 903 : loss : 0.092220, loss_ce: 0.028751
2022-01-15 23:55:29,635 iteration 904 : loss : 0.097992, loss_ce: 0.046251
2022-01-15 23:55:31,005 iteration 905 : loss : 0.059271, loss_ce: 0.026053
2022-01-15 23:55:32,502 iteration 906 : loss : 0.082463, loss_ce: 0.035666
2022-01-15 23:55:33,980 iteration 907 : loss : 0.056501, loss_ce: 0.021808
2022-01-15 23:55:35,517 iteration 908 : loss : 0.063884, loss_ce: 0.032487
2022-01-15 23:55:37,055 iteration 909 : loss : 0.058543, loss_ce: 0.024317
2022-01-15 23:55:38,726 iteration 910 : loss : 0.065067, loss_ce: 0.028183
2022-01-15 23:55:40,285 iteration 911 : loss : 0.060363, loss_ce: 0.022859
2022-01-15 23:55:41,881 iteration 912 : loss : 0.069391, loss_ce: 0.028648
2022-01-15 23:55:43,390 iteration 913 : loss : 0.095769, loss_ce: 0.031667
2022-01-15 23:55:44,852 iteration 914 : loss : 0.054214, loss_ce: 0.025875
2022-01-15 23:55:46,387 iteration 915 : loss : 0.082677, loss_ce: 0.028121
2022-01-15 23:55:47,940 iteration 916 : loss : 0.080959, loss_ce: 0.028905
2022-01-15 23:55:49,462 iteration 917 : loss : 0.059135, loss_ce: 0.020559
2022-01-15 23:55:51,037 iteration 918 : loss : 0.123910, loss_ce: 0.029283
 14%|████                          | 54/400 [16:39<2:00:44, 20.94s/it]2022-01-15 23:55:52,528 iteration 919 : loss : 0.058582, loss_ce: 0.018878
2022-01-15 23:55:53,998 iteration 920 : loss : 0.064701, loss_ce: 0.028585
2022-01-15 23:55:55,374 iteration 921 : loss : 0.067298, loss_ce: 0.028710
2022-01-15 23:55:56,806 iteration 922 : loss : 0.060664, loss_ce: 0.021151
2022-01-15 23:55:58,112 iteration 923 : loss : 0.049489, loss_ce: 0.017692
2022-01-15 23:55:59,519 iteration 924 : loss : 0.081706, loss_ce: 0.024540
2022-01-15 23:56:00,989 iteration 925 : loss : 0.080885, loss_ce: 0.022582
2022-01-15 23:56:02,522 iteration 926 : loss : 0.069593, loss_ce: 0.025756
2022-01-15 23:56:04,029 iteration 927 : loss : 0.079809, loss_ce: 0.023775
2022-01-15 23:56:05,695 iteration 928 : loss : 0.086844, loss_ce: 0.046970
2022-01-15 23:56:07,242 iteration 929 : loss : 0.052515, loss_ce: 0.020111
2022-01-15 23:56:08,918 iteration 930 : loss : 0.061989, loss_ce: 0.026441
2022-01-15 23:56:10,457 iteration 931 : loss : 0.108285, loss_ce: 0.064951
2022-01-15 23:56:12,155 iteration 932 : loss : 0.060228, loss_ce: 0.029762
2022-01-15 23:56:13,852 iteration 933 : loss : 0.066804, loss_ce: 0.030513
2022-01-15 23:56:15,454 iteration 934 : loss : 0.064831, loss_ce: 0.023200
2022-01-15 23:56:15,454 Training Data Eval:
2022-01-15 23:56:23,676   Average segmentation loss on training set: 0.0695
2022-01-15 23:56:23,677 Validation Data Eval:
2022-01-15 23:56:26,488   Average segmentation loss on validation set: 0.0788
2022-01-15 23:56:27,372 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed2.pth
2022-01-15 23:56:28,803 iteration 935 : loss : 0.068148, loss_ce: 0.029380
 14%|████▏                         | 55/400 [17:17<2:29:24, 25.98s/it]2022-01-15 23:56:30,228 iteration 936 : loss : 0.065612, loss_ce: 0.033238
2022-01-15 23:56:31,538 iteration 937 : loss : 0.113755, loss_ce: 0.043706
2022-01-15 23:56:32,888 iteration 938 : loss : 0.050778, loss_ce: 0.020373
2022-01-15 23:56:34,265 iteration 939 : loss : 0.095413, loss_ce: 0.026730
2022-01-15 23:56:35,473 iteration 940 : loss : 0.077567, loss_ce: 0.030376
2022-01-15 23:56:36,732 iteration 941 : loss : 0.069957, loss_ce: 0.025705
2022-01-15 23:56:38,028 iteration 942 : loss : 0.098522, loss_ce: 0.039208
2022-01-15 23:56:39,426 iteration 943 : loss : 0.116609, loss_ce: 0.041430
2022-01-15 23:56:40,757 iteration 944 : loss : 0.099210, loss_ce: 0.041772
2022-01-15 23:56:42,123 iteration 945 : loss : 0.070268, loss_ce: 0.027212
2022-01-15 23:56:43,509 iteration 946 : loss : 0.054500, loss_ce: 0.020621
2022-01-15 23:56:44,956 iteration 947 : loss : 0.067678, loss_ce: 0.020506
2022-01-15 23:56:46,514 iteration 948 : loss : 0.092731, loss_ce: 0.043303
2022-01-15 23:56:48,138 iteration 949 : loss : 0.123173, loss_ce: 0.056599
2022-01-15 23:56:49,740 iteration 950 : loss : 0.085334, loss_ce: 0.032655
2022-01-15 23:56:51,214 iteration 951 : loss : 0.056104, loss_ce: 0.022384
2022-01-15 23:56:52,758 iteration 952 : loss : 0.084675, loss_ce: 0.029780
 14%|████▏                         | 56/400 [17:41<2:25:29, 25.38s/it]2022-01-15 23:56:54,297 iteration 953 : loss : 0.063913, loss_ce: 0.022946
2022-01-15 23:56:55,831 iteration 954 : loss : 0.055539, loss_ce: 0.019196
2022-01-15 23:56:57,370 iteration 955 : loss : 0.092266, loss_ce: 0.033550
2022-01-15 23:56:58,919 iteration 956 : loss : 0.068869, loss_ce: 0.022910
2022-01-15 23:57:00,406 iteration 957 : loss : 0.086678, loss_ce: 0.033540
2022-01-15 23:57:02,025 iteration 958 : loss : 0.055673, loss_ce: 0.023200
2022-01-15 23:57:03,659 iteration 959 : loss : 0.070099, loss_ce: 0.034786
2022-01-15 23:57:05,268 iteration 960 : loss : 0.075454, loss_ce: 0.028644
2022-01-15 23:57:06,791 iteration 961 : loss : 0.091752, loss_ce: 0.036898
2022-01-15 23:57:08,422 iteration 962 : loss : 0.079014, loss_ce: 0.023618
2022-01-15 23:57:09,938 iteration 963 : loss : 0.069462, loss_ce: 0.030781
2022-01-15 23:57:11,491 iteration 964 : loss : 0.119616, loss_ce: 0.032195
2022-01-15 23:57:13,172 iteration 965 : loss : 0.059258, loss_ce: 0.019049
2022-01-15 23:57:14,821 iteration 966 : loss : 0.080446, loss_ce: 0.024614
2022-01-15 23:57:16,544 iteration 967 : loss : 0.092805, loss_ce: 0.039204
2022-01-15 23:57:18,152 iteration 968 : loss : 0.065946, loss_ce: 0.024567
2022-01-15 23:57:19,718 iteration 969 : loss : 0.066222, loss_ce: 0.030786
 14%|████▎                         | 57/400 [18:08<2:27:45, 25.85s/it]2022-01-15 23:57:21,306 iteration 970 : loss : 0.063987, loss_ce: 0.026622
2022-01-15 23:57:22,913 iteration 971 : loss : 0.078299, loss_ce: 0.042336
2022-01-15 23:57:24,597 iteration 972 : loss : 0.067710, loss_ce: 0.024572
2022-01-15 23:57:26,201 iteration 973 : loss : 0.062667, loss_ce: 0.024804
2022-01-15 23:57:27,763 iteration 974 : loss : 0.097171, loss_ce: 0.042770
2022-01-15 23:57:29,306 iteration 975 : loss : 0.076021, loss_ce: 0.027195
2022-01-15 23:57:31,015 iteration 976 : loss : 0.053491, loss_ce: 0.021786
2022-01-15 23:57:32,582 iteration 977 : loss : 0.061989, loss_ce: 0.027065
2022-01-15 23:57:34,183 iteration 978 : loss : 0.056904, loss_ce: 0.020357
2022-01-15 23:57:35,717 iteration 979 : loss : 0.051449, loss_ce: 0.021031
2022-01-15 23:57:37,281 iteration 980 : loss : 0.065471, loss_ce: 0.021417
2022-01-15 23:57:38,913 iteration 981 : loss : 0.027519, loss_ce: 0.010391
2022-01-15 23:57:40,599 iteration 982 : loss : 0.086433, loss_ce: 0.027305
2022-01-15 23:57:42,324 iteration 983 : loss : 0.067224, loss_ce: 0.031833
2022-01-15 23:57:43,916 iteration 984 : loss : 0.062556, loss_ce: 0.026914
2022-01-15 23:57:45,459 iteration 985 : loss : 0.061226, loss_ce: 0.024707
2022-01-15 23:57:47,189 iteration 986 : loss : 0.071160, loss_ce: 0.025098
 14%|████▎                         | 58/400 [18:35<2:30:07, 26.34s/it]2022-01-15 23:57:48,750 iteration 987 : loss : 0.057413, loss_ce: 0.019921
2022-01-15 23:57:50,343 iteration 988 : loss : 0.061705, loss_ce: 0.022377
2022-01-15 23:57:51,901 iteration 989 : loss : 0.047034, loss_ce: 0.018023
2022-01-15 23:57:53,525 iteration 990 : loss : 0.065544, loss_ce: 0.022153
2022-01-15 23:57:55,233 iteration 991 : loss : 0.078801, loss_ce: 0.027359
2022-01-15 23:57:56,724 iteration 992 : loss : 0.053107, loss_ce: 0.019438
2022-01-15 23:57:58,196 iteration 993 : loss : 0.071994, loss_ce: 0.022054
2022-01-15 23:57:59,827 iteration 994 : loss : 0.052750, loss_ce: 0.017900
2022-01-15 23:58:01,534 iteration 995 : loss : 0.075806, loss_ce: 0.036206
2022-01-15 23:58:03,094 iteration 996 : loss : 0.065050, loss_ce: 0.029775
2022-01-15 23:58:04,797 iteration 997 : loss : 0.075996, loss_ce: 0.033367
2022-01-15 23:58:06,401 iteration 998 : loss : 0.055233, loss_ce: 0.020252
2022-01-15 23:58:07,964 iteration 999 : loss : 0.069314, loss_ce: 0.028821
2022-01-15 23:58:09,602 iteration 1000 : loss : 0.066495, loss_ce: 0.031476
2022-01-15 23:58:11,257 iteration 1001 : loss : 0.046541, loss_ce: 0.018016
2022-01-15 23:58:12,913 iteration 1002 : loss : 0.080821, loss_ce: 0.033629
2022-01-15 23:58:14,418 iteration 1003 : loss : 0.147112, loss_ce: 0.045429
 15%|████▍                         | 59/400 [19:02<2:31:11, 26.60s/it]2022-01-15 23:58:16,030 iteration 1004 : loss : 0.060692, loss_ce: 0.020705
2022-01-15 23:58:17,758 iteration 1005 : loss : 0.080548, loss_ce: 0.037105
2022-01-15 23:58:19,398 iteration 1006 : loss : 0.071006, loss_ce: 0.031162
2022-01-15 23:58:21,102 iteration 1007 : loss : 0.085723, loss_ce: 0.032007
2022-01-15 23:58:22,741 iteration 1008 : loss : 0.090813, loss_ce: 0.052802
2022-01-15 23:58:24,313 iteration 1009 : loss : 0.054756, loss_ce: 0.017921
2022-01-15 23:58:25,929 iteration 1010 : loss : 0.042907, loss_ce: 0.011662
2022-01-15 23:58:27,489 iteration 1011 : loss : 0.069553, loss_ce: 0.026841
2022-01-15 23:58:29,121 iteration 1012 : loss : 0.080168, loss_ce: 0.025936
2022-01-15 23:58:30,697 iteration 1013 : loss : 0.052252, loss_ce: 0.019612
2022-01-15 23:58:32,275 iteration 1014 : loss : 0.036457, loss_ce: 0.014493
2022-01-15 23:58:34,047 iteration 1015 : loss : 0.088388, loss_ce: 0.029799
2022-01-15 23:58:35,623 iteration 1016 : loss : 0.062296, loss_ce: 0.023499
2022-01-15 23:58:37,186 iteration 1017 : loss : 0.062797, loss_ce: 0.025186
2022-01-15 23:58:38,914 iteration 1018 : loss : 0.096762, loss_ce: 0.030748
2022-01-15 23:58:40,534 iteration 1019 : loss : 0.068115, loss_ce: 0.023813
2022-01-15 23:58:40,534 Training Data Eval:
2022-01-15 23:58:49,043   Average segmentation loss on training set: 0.0453
2022-01-15 23:58:49,044 Validation Data Eval:
2022-01-15 23:58:51,957   Average segmentation loss on validation set: 0.1111
2022-01-15 23:58:53,629 iteration 1020 : loss : 0.063383, loss_ce: 0.024748
 15%|████▌                         | 60/400 [19:41<2:52:11, 30.39s/it]2022-01-15 23:58:55,249 iteration 1021 : loss : 0.061572, loss_ce: 0.024879
2022-01-15 23:58:56,983 iteration 1022 : loss : 0.060493, loss_ce: 0.027633
2022-01-15 23:58:58,518 iteration 1023 : loss : 0.048520, loss_ce: 0.016497
2022-01-15 23:59:00,165 iteration 1024 : loss : 0.043942, loss_ce: 0.016204
2022-01-15 23:59:01,876 iteration 1025 : loss : 0.060351, loss_ce: 0.024656
2022-01-15 23:59:03,476 iteration 1026 : loss : 0.089260, loss_ce: 0.020751
2022-01-15 23:59:05,030 iteration 1027 : loss : 0.058343, loss_ce: 0.018392
2022-01-15 23:59:06,762 iteration 1028 : loss : 0.073678, loss_ce: 0.021863
2022-01-15 23:59:08,398 iteration 1029 : loss : 0.093772, loss_ce: 0.026344
2022-01-15 23:59:09,980 iteration 1030 : loss : 0.068695, loss_ce: 0.025897
2022-01-15 23:59:11,719 iteration 1031 : loss : 0.074333, loss_ce: 0.033806
2022-01-15 23:59:13,267 iteration 1032 : loss : 0.069305, loss_ce: 0.029155
2022-01-15 23:59:14,735 iteration 1033 : loss : 0.075717, loss_ce: 0.034404
2022-01-15 23:59:16,172 iteration 1034 : loss : 0.054499, loss_ce: 0.020368
2022-01-15 23:59:17,698 iteration 1035 : loss : 0.058759, loss_ce: 0.024241
2022-01-15 23:59:19,205 iteration 1036 : loss : 0.065258, loss_ce: 0.028386
2022-01-15 23:59:20,613 iteration 1037 : loss : 0.041174, loss_ce: 0.016531
 15%|████▌                         | 61/400 [20:08<2:45:54, 29.37s/it]2022-01-15 23:59:22,136 iteration 1038 : loss : 0.053290, loss_ce: 0.023704
2022-01-15 23:59:23,595 iteration 1039 : loss : 0.065869, loss_ce: 0.029031
2022-01-15 23:59:25,033 iteration 1040 : loss : 0.078484, loss_ce: 0.024932
2022-01-15 23:59:26,463 iteration 1041 : loss : 0.060619, loss_ce: 0.026062
2022-01-15 23:59:27,845 iteration 1042 : loss : 0.049744, loss_ce: 0.024440
2022-01-15 23:59:29,223 iteration 1043 : loss : 0.061260, loss_ce: 0.019934
2022-01-15 23:59:30,680 iteration 1044 : loss : 0.063484, loss_ce: 0.026834
2022-01-15 23:59:32,152 iteration 1045 : loss : 0.069862, loss_ce: 0.030872
2022-01-15 23:59:33,581 iteration 1046 : loss : 0.046803, loss_ce: 0.022600
2022-01-15 23:59:34,980 iteration 1047 : loss : 0.049842, loss_ce: 0.018508
2022-01-15 23:59:36,515 iteration 1048 : loss : 0.040481, loss_ce: 0.016457
2022-01-15 23:59:38,051 iteration 1049 : loss : 0.085115, loss_ce: 0.032891
2022-01-15 23:59:39,474 iteration 1050 : loss : 0.158248, loss_ce: 0.035848
2022-01-15 23:59:40,853 iteration 1051 : loss : 0.060381, loss_ce: 0.027047
2022-01-15 23:59:42,264 iteration 1052 : loss : 0.063728, loss_ce: 0.019995
2022-01-15 23:59:43,625 iteration 1053 : loss : 0.073187, loss_ce: 0.020497
2022-01-15 23:59:44,974 iteration 1054 : loss : 0.056371, loss_ce: 0.022194
 16%|████▋                         | 62/400 [20:33<2:36:57, 27.86s/it]2022-01-15 23:59:46,329 iteration 1055 : loss : 0.043988, loss_ce: 0.012239
2022-01-15 23:59:47,544 iteration 1056 : loss : 0.052557, loss_ce: 0.022432
2022-01-15 23:59:48,869 iteration 1057 : loss : 0.061989, loss_ce: 0.022434
2022-01-15 23:59:50,139 iteration 1058 : loss : 0.113110, loss_ce: 0.040740
2022-01-15 23:59:51,410 iteration 1059 : loss : 0.076675, loss_ce: 0.028597
2022-01-15 23:59:52,616 iteration 1060 : loss : 0.044234, loss_ce: 0.014357
2022-01-15 23:59:53,972 iteration 1061 : loss : 0.076862, loss_ce: 0.039861
2022-01-15 23:59:55,229 iteration 1062 : loss : 0.068474, loss_ce: 0.023285
2022-01-15 23:59:56,594 iteration 1063 : loss : 0.058860, loss_ce: 0.023174
2022-01-15 23:59:57,842 iteration 1064 : loss : 0.080699, loss_ce: 0.025267
2022-01-15 23:59:59,170 iteration 1065 : loss : 0.061740, loss_ce: 0.029676
2022-01-16 00:00:00,393 iteration 1066 : loss : 0.051591, loss_ce: 0.018482
2022-01-16 00:00:01,634 iteration 1067 : loss : 0.047594, loss_ce: 0.019223
2022-01-16 00:00:02,974 iteration 1068 : loss : 0.072954, loss_ce: 0.028921
2022-01-16 00:00:04,321 iteration 1069 : loss : 0.054251, loss_ce: 0.023237
2022-01-16 00:00:05,721 iteration 1070 : loss : 0.116667, loss_ce: 0.032953
2022-01-16 00:00:07,006 iteration 1071 : loss : 0.070188, loss_ce: 0.034212
 16%|████▋                         | 63/400 [20:55<2:26:40, 26.11s/it]2022-01-16 00:00:08,443 iteration 1072 : loss : 0.079308, loss_ce: 0.024037
2022-01-16 00:00:09,794 iteration 1073 : loss : 0.063442, loss_ce: 0.027858
2022-01-16 00:00:11,169 iteration 1074 : loss : 0.066718, loss_ce: 0.023530
2022-01-16 00:00:12,512 iteration 1075 : loss : 0.084592, loss_ce: 0.025638
2022-01-16 00:00:13,841 iteration 1076 : loss : 0.053359, loss_ce: 0.021522
2022-01-16 00:00:15,388 iteration 1077 : loss : 0.058304, loss_ce: 0.017964
2022-01-16 00:00:16,797 iteration 1078 : loss : 0.061547, loss_ce: 0.027176
2022-01-16 00:00:18,279 iteration 1079 : loss : 0.056163, loss_ce: 0.022681
2022-01-16 00:00:19,657 iteration 1080 : loss : 0.036754, loss_ce: 0.011282
2022-01-16 00:00:21,066 iteration 1081 : loss : 0.055205, loss_ce: 0.028657
2022-01-16 00:00:22,469 iteration 1082 : loss : 0.064679, loss_ce: 0.030077
2022-01-16 00:00:23,765 iteration 1083 : loss : 0.050089, loss_ce: 0.016454
2022-01-16 00:00:25,102 iteration 1084 : loss : 0.059731, loss_ce: 0.019663
2022-01-16 00:00:26,498 iteration 1085 : loss : 0.059826, loss_ce: 0.022434
2022-01-16 00:00:27,885 iteration 1086 : loss : 0.069021, loss_ce: 0.031697
2022-01-16 00:00:29,370 iteration 1087 : loss : 0.046559, loss_ce: 0.018759
2022-01-16 00:00:30,783 iteration 1088 : loss : 0.057000, loss_ce: 0.023960
 16%|████▊                         | 64/400 [21:19<2:22:18, 25.41s/it]2022-01-16 00:00:32,203 iteration 1089 : loss : 0.084145, loss_ce: 0.035373
2022-01-16 00:00:33,585 iteration 1090 : loss : 0.072231, loss_ce: 0.023847
2022-01-16 00:00:35,003 iteration 1091 : loss : 0.055326, loss_ce: 0.024804
2022-01-16 00:00:36,351 iteration 1092 : loss : 0.049553, loss_ce: 0.021090
2022-01-16 00:00:37,688 iteration 1093 : loss : 0.056151, loss_ce: 0.023952
2022-01-16 00:00:39,069 iteration 1094 : loss : 0.060268, loss_ce: 0.025734
2022-01-16 00:00:40,446 iteration 1095 : loss : 0.094824, loss_ce: 0.027218
2022-01-16 00:00:41,782 iteration 1096 : loss : 0.050837, loss_ce: 0.021865
2022-01-16 00:00:43,132 iteration 1097 : loss : 0.062309, loss_ce: 0.019941
2022-01-16 00:00:44,583 iteration 1098 : loss : 0.059648, loss_ce: 0.027149
2022-01-16 00:00:46,069 iteration 1099 : loss : 0.048879, loss_ce: 0.019548
2022-01-16 00:00:47,542 iteration 1100 : loss : 0.060394, loss_ce: 0.025436
2022-01-16 00:00:49,137 iteration 1101 : loss : 0.049742, loss_ce: 0.017836
2022-01-16 00:00:50,872 iteration 1102 : loss : 0.069853, loss_ce: 0.018332
2022-01-16 00:00:52,390 iteration 1103 : loss : 0.065649, loss_ce: 0.025295
2022-01-16 00:00:53,987 iteration 1104 : loss : 0.064981, loss_ce: 0.024188
2022-01-16 00:00:53,987 Training Data Eval:
2022-01-16 00:01:02,167   Average segmentation loss on training set: 0.0436
2022-01-16 00:01:02,168 Validation Data Eval:
2022-01-16 00:01:04,918   Average segmentation loss on validation set: 0.1343
2022-01-16 00:01:06,497 iteration 1105 : loss : 0.046009, loss_ce: 0.022103
 16%|████▉                         | 65/400 [21:54<2:39:08, 28.50s/it]2022-01-16 00:01:08,083 iteration 1106 : loss : 0.061567, loss_ce: 0.019584
2022-01-16 00:01:09,650 iteration 1107 : loss : 0.071022, loss_ce: 0.027390
2022-01-16 00:01:11,137 iteration 1108 : loss : 0.040764, loss_ce: 0.013998
2022-01-16 00:01:12,704 iteration 1109 : loss : 0.071825, loss_ce: 0.029895
2022-01-16 00:01:14,229 iteration 1110 : loss : 0.052326, loss_ce: 0.021624
2022-01-16 00:01:15,815 iteration 1111 : loss : 0.052922, loss_ce: 0.030085
2022-01-16 00:01:17,360 iteration 1112 : loss : 0.058109, loss_ce: 0.024120
2022-01-16 00:01:18,820 iteration 1113 : loss : 0.057989, loss_ce: 0.020786
2022-01-16 00:01:20,222 iteration 1114 : loss : 0.059185, loss_ce: 0.021554
2022-01-16 00:01:21,578 iteration 1115 : loss : 0.050132, loss_ce: 0.016011
2022-01-16 00:01:23,078 iteration 1116 : loss : 0.053052, loss_ce: 0.023613
2022-01-16 00:01:24,547 iteration 1117 : loss : 0.051448, loss_ce: 0.020783
2022-01-16 00:01:25,896 iteration 1118 : loss : 0.041486, loss_ce: 0.016665
2022-01-16 00:01:27,224 iteration 1119 : loss : 0.043962, loss_ce: 0.015935
2022-01-16 00:01:28,550 iteration 1120 : loss : 0.050855, loss_ce: 0.017255
2022-01-16 00:01:29,877 iteration 1121 : loss : 0.056364, loss_ce: 0.016593
2022-01-16 00:01:31,170 iteration 1122 : loss : 0.048813, loss_ce: 0.020475
 16%|████▉                         | 66/400 [22:19<2:32:17, 27.36s/it]2022-01-16 00:01:32,598 iteration 1123 : loss : 0.055504, loss_ce: 0.022415
2022-01-16 00:01:33,947 iteration 1124 : loss : 0.058583, loss_ce: 0.024922
2022-01-16 00:01:35,332 iteration 1125 : loss : 0.074081, loss_ce: 0.032183
2022-01-16 00:01:36,756 iteration 1126 : loss : 0.063843, loss_ce: 0.031242
2022-01-16 00:01:38,116 iteration 1127 : loss : 0.063424, loss_ce: 0.026276
2022-01-16 00:01:39,485 iteration 1128 : loss : 0.068561, loss_ce: 0.021667
2022-01-16 00:01:40,853 iteration 1129 : loss : 0.035898, loss_ce: 0.012895
2022-01-16 00:01:42,297 iteration 1130 : loss : 0.060765, loss_ce: 0.029905
2022-01-16 00:01:43,713 iteration 1131 : loss : 0.130353, loss_ce: 0.040322
2022-01-16 00:01:45,047 iteration 1132 : loss : 0.061494, loss_ce: 0.022776
2022-01-16 00:01:46,352 iteration 1133 : loss : 0.070467, loss_ce: 0.028071
2022-01-16 00:01:47,639 iteration 1134 : loss : 0.100638, loss_ce: 0.043842
2022-01-16 00:01:48,887 iteration 1135 : loss : 0.060699, loss_ce: 0.021968
2022-01-16 00:01:50,179 iteration 1136 : loss : 0.054531, loss_ce: 0.021619
2022-01-16 00:01:51,489 iteration 1137 : loss : 0.057748, loss_ce: 0.020489
2022-01-16 00:01:52,961 iteration 1138 : loss : 0.062735, loss_ce: 0.025879
2022-01-16 00:01:54,433 iteration 1139 : loss : 0.078574, loss_ce: 0.033383
 17%|█████                         | 67/400 [22:42<2:25:00, 26.13s/it]2022-01-16 00:01:55,921 iteration 1140 : loss : 0.061663, loss_ce: 0.027391
2022-01-16 00:01:57,393 iteration 1141 : loss : 0.050136, loss_ce: 0.019066
2022-01-16 00:01:58,842 iteration 1142 : loss : 0.042189, loss_ce: 0.016254
2022-01-16 00:02:00,510 iteration 1143 : loss : 0.084836, loss_ce: 0.028566
2022-01-16 00:02:02,089 iteration 1144 : loss : 0.069950, loss_ce: 0.029214
2022-01-16 00:02:03,592 iteration 1145 : loss : 0.050570, loss_ce: 0.014622
2022-01-16 00:02:05,077 iteration 1146 : loss : 0.051725, loss_ce: 0.020997
2022-01-16 00:02:06,482 iteration 1147 : loss : 0.037782, loss_ce: 0.013278
2022-01-16 00:02:08,126 iteration 1148 : loss : 0.057093, loss_ce: 0.023013
2022-01-16 00:02:09,675 iteration 1149 : loss : 0.046759, loss_ce: 0.019443
2022-01-16 00:02:11,173 iteration 1150 : loss : 0.050515, loss_ce: 0.021553
2022-01-16 00:02:12,838 iteration 1151 : loss : 0.061223, loss_ce: 0.018447
2022-01-16 00:02:14,398 iteration 1152 : loss : 0.102397, loss_ce: 0.020887
2022-01-16 00:02:15,914 iteration 1153 : loss : 0.049445, loss_ce: 0.016915
2022-01-16 00:02:17,361 iteration 1154 : loss : 0.057842, loss_ce: 0.024548
2022-01-16 00:02:18,947 iteration 1155 : loss : 0.060724, loss_ce: 0.021671
2022-01-16 00:02:20,428 iteration 1156 : loss : 0.089545, loss_ce: 0.026393
 17%|█████                         | 68/400 [23:08<2:24:20, 26.08s/it]2022-01-16 00:02:21,871 iteration 1157 : loss : 0.061142, loss_ce: 0.023133
2022-01-16 00:02:23,371 iteration 1158 : loss : 0.072004, loss_ce: 0.019331
2022-01-16 00:02:24,798 iteration 1159 : loss : 0.068058, loss_ce: 0.026266
2022-01-16 00:02:26,080 iteration 1160 : loss : 0.063815, loss_ce: 0.029949
2022-01-16 00:02:27,445 iteration 1161 : loss : 0.050126, loss_ce: 0.015042
2022-01-16 00:02:28,828 iteration 1162 : loss : 0.052594, loss_ce: 0.010636
2022-01-16 00:02:30,265 iteration 1163 : loss : 0.083203, loss_ce: 0.030198
2022-01-16 00:02:31,592 iteration 1164 : loss : 0.055733, loss_ce: 0.021665
2022-01-16 00:02:32,836 iteration 1165 : loss : 0.053647, loss_ce: 0.027434
2022-01-16 00:02:34,133 iteration 1166 : loss : 0.048177, loss_ce: 0.019940
2022-01-16 00:02:35,463 iteration 1167 : loss : 0.056693, loss_ce: 0.025893
2022-01-16 00:02:36,682 iteration 1168 : loss : 0.052323, loss_ce: 0.020396
2022-01-16 00:02:37,984 iteration 1169 : loss : 0.065509, loss_ce: 0.020862
2022-01-16 00:02:39,276 iteration 1170 : loss : 0.059105, loss_ce: 0.022372
2022-01-16 00:02:40,483 iteration 1171 : loss : 0.059972, loss_ce: 0.019902
2022-01-16 00:02:41,711 iteration 1172 : loss : 0.064307, loss_ce: 0.030414
2022-01-16 00:02:42,973 iteration 1173 : loss : 0.071522, loss_ce: 0.045584
 17%|█████▏                        | 69/400 [23:31<2:18:04, 25.03s/it]2022-01-16 00:02:44,297 iteration 1174 : loss : 0.058638, loss_ce: 0.017143
2022-01-16 00:02:45,540 iteration 1175 : loss : 0.055374, loss_ce: 0.024377
2022-01-16 00:02:46,842 iteration 1176 : loss : 0.076724, loss_ce: 0.035058
2022-01-16 00:02:48,196 iteration 1177 : loss : 0.073660, loss_ce: 0.033827
2022-01-16 00:02:49,527 iteration 1178 : loss : 0.065723, loss_ce: 0.031347
2022-01-16 00:02:50,784 iteration 1179 : loss : 0.057951, loss_ce: 0.023161
2022-01-16 00:02:52,175 iteration 1180 : loss : 0.072386, loss_ce: 0.031358
2022-01-16 00:02:53,478 iteration 1181 : loss : 0.046258, loss_ce: 0.018457
2022-01-16 00:02:54,967 iteration 1182 : loss : 0.095128, loss_ce: 0.038189
2022-01-16 00:02:56,433 iteration 1183 : loss : 0.053655, loss_ce: 0.024428
2022-01-16 00:02:57,875 iteration 1184 : loss : 0.045270, loss_ce: 0.019341
2022-01-16 00:02:59,385 iteration 1185 : loss : 0.062134, loss_ce: 0.024240
2022-01-16 00:03:00,854 iteration 1186 : loss : 0.051301, loss_ce: 0.019319
2022-01-16 00:03:02,365 iteration 1187 : loss : 0.051657, loss_ce: 0.018657
2022-01-16 00:03:03,818 iteration 1188 : loss : 0.047872, loss_ce: 0.016058
2022-01-16 00:03:05,274 iteration 1189 : loss : 0.045984, loss_ce: 0.017587
2022-01-16 00:03:05,274 Training Data Eval:
2022-01-16 00:03:12,224   Average segmentation loss on training set: 0.0563
2022-01-16 00:03:12,225 Validation Data Eval:
2022-01-16 00:03:14,717   Average segmentation loss on validation set: 0.1685
2022-01-16 00:03:16,200 iteration 1190 : loss : 0.075072, loss_ce: 0.030452
 18%|█████▎                        | 70/400 [24:04<2:31:09, 27.48s/it]2022-01-16 00:03:17,723 iteration 1191 : loss : 0.063997, loss_ce: 0.029118
2022-01-16 00:03:19,188 iteration 1192 : loss : 0.053222, loss_ce: 0.023225
2022-01-16 00:03:20,670 iteration 1193 : loss : 0.053891, loss_ce: 0.016645
2022-01-16 00:03:22,161 iteration 1194 : loss : 0.068842, loss_ce: 0.027396
2022-01-16 00:03:23,705 iteration 1195 : loss : 0.064985, loss_ce: 0.023651
2022-01-16 00:03:25,123 iteration 1196 : loss : 0.057123, loss_ce: 0.018572
2022-01-16 00:03:26,600 iteration 1197 : loss : 0.053577, loss_ce: 0.025938
2022-01-16 00:03:28,126 iteration 1198 : loss : 0.041417, loss_ce: 0.020502
2022-01-16 00:03:29,644 iteration 1199 : loss : 0.073302, loss_ce: 0.025874
2022-01-16 00:03:31,167 iteration 1200 : loss : 0.074753, loss_ce: 0.027627
2022-01-16 00:03:32,622 iteration 1201 : loss : 0.041993, loss_ce: 0.017008
2022-01-16 00:03:34,155 iteration 1202 : loss : 0.041622, loss_ce: 0.017546
2022-01-16 00:03:35,664 iteration 1203 : loss : 0.047090, loss_ce: 0.016501
2022-01-16 00:03:37,223 iteration 1204 : loss : 0.050928, loss_ce: 0.023929
2022-01-16 00:03:38,771 iteration 1205 : loss : 0.092862, loss_ce: 0.057449
2022-01-16 00:03:40,401 iteration 1206 : loss : 0.103223, loss_ce: 0.031209
2022-01-16 00:03:41,933 iteration 1207 : loss : 0.061268, loss_ce: 0.018917
 18%|█████▎                        | 71/400 [24:30<2:27:50, 26.96s/it]2022-01-16 00:03:43,444 iteration 1208 : loss : 0.048262, loss_ce: 0.021971
2022-01-16 00:03:44,929 iteration 1209 : loss : 0.063209, loss_ce: 0.020193
2022-01-16 00:03:46,314 iteration 1210 : loss : 0.051773, loss_ce: 0.015614
2022-01-16 00:03:47,786 iteration 1211 : loss : 0.073222, loss_ce: 0.025199
2022-01-16 00:03:49,210 iteration 1212 : loss : 0.040827, loss_ce: 0.015643
2022-01-16 00:03:50,952 iteration 1213 : loss : 0.094427, loss_ce: 0.024918
2022-01-16 00:03:52,546 iteration 1214 : loss : 0.067272, loss_ce: 0.025507
2022-01-16 00:03:54,126 iteration 1215 : loss : 0.067862, loss_ce: 0.027829
2022-01-16 00:03:55,679 iteration 1216 : loss : 0.039319, loss_ce: 0.013937
2022-01-16 00:03:57,287 iteration 1217 : loss : 0.065767, loss_ce: 0.030446
2022-01-16 00:03:58,908 iteration 1218 : loss : 0.045536, loss_ce: 0.020572
2022-01-16 00:04:00,507 iteration 1219 : loss : 0.079223, loss_ce: 0.032983
2022-01-16 00:04:02,071 iteration 1220 : loss : 0.070903, loss_ce: 0.027445
2022-01-16 00:04:03,767 iteration 1221 : loss : 0.059063, loss_ce: 0.023164
2022-01-16 00:04:05,392 iteration 1222 : loss : 0.046971, loss_ce: 0.016274
2022-01-16 00:04:06,979 iteration 1223 : loss : 0.046925, loss_ce: 0.018711
2022-01-16 00:04:08,614 iteration 1224 : loss : 0.059340, loss_ce: 0.025912
 18%|█████▍                        | 72/400 [24:56<2:26:54, 26.87s/it]2022-01-16 00:04:10,351 iteration 1225 : loss : 0.051229, loss_ce: 0.016722
2022-01-16 00:04:11,957 iteration 1226 : loss : 0.072053, loss_ce: 0.033259
2022-01-16 00:04:13,524 iteration 1227 : loss : 0.052226, loss_ce: 0.016597
2022-01-16 00:04:15,301 iteration 1228 : loss : 0.097958, loss_ce: 0.033679
2022-01-16 00:04:17,008 iteration 1229 : loss : 0.049779, loss_ce: 0.022866
2022-01-16 00:04:18,720 iteration 1230 : loss : 0.049357, loss_ce: 0.021853
2022-01-16 00:04:20,289 iteration 1231 : loss : 0.092827, loss_ce: 0.038325
2022-01-16 00:04:21,871 iteration 1232 : loss : 0.047118, loss_ce: 0.017132
2022-01-16 00:04:23,472 iteration 1233 : loss : 0.063061, loss_ce: 0.027472
2022-01-16 00:04:24,933 iteration 1234 : loss : 0.100586, loss_ce: 0.046222
2022-01-16 00:04:26,384 iteration 1235 : loss : 0.052256, loss_ce: 0.024650
2022-01-16 00:04:27,836 iteration 1236 : loss : 0.036265, loss_ce: 0.013500
2022-01-16 00:04:29,238 iteration 1237 : loss : 0.071199, loss_ce: 0.025520
2022-01-16 00:04:30,722 iteration 1238 : loss : 0.054391, loss_ce: 0.022927
2022-01-16 00:04:32,251 iteration 1239 : loss : 0.074870, loss_ce: 0.029511
2022-01-16 00:04:33,644 iteration 1240 : loss : 0.050000, loss_ce: 0.020919
2022-01-16 00:04:35,277 iteration 1241 : loss : 0.038866, loss_ce: 0.016969
 18%|█████▍                        | 73/400 [25:23<2:26:08, 26.81s/it]2022-01-16 00:04:36,835 iteration 1242 : loss : 0.048776, loss_ce: 0.020524
2022-01-16 00:04:38,328 iteration 1243 : loss : 0.038746, loss_ce: 0.016654
2022-01-16 00:04:39,833 iteration 1244 : loss : 0.051619, loss_ce: 0.018571
2022-01-16 00:04:41,398 iteration 1245 : loss : 0.052058, loss_ce: 0.019207
2022-01-16 00:04:43,005 iteration 1246 : loss : 0.051869, loss_ce: 0.019197
2022-01-16 00:04:44,629 iteration 1247 : loss : 0.062811, loss_ce: 0.019704
2022-01-16 00:04:46,317 iteration 1248 : loss : 0.036194, loss_ce: 0.013166
2022-01-16 00:04:47,936 iteration 1249 : loss : 0.068642, loss_ce: 0.023275
2022-01-16 00:04:49,535 iteration 1250 : loss : 0.059530, loss_ce: 0.020688
2022-01-16 00:04:51,204 iteration 1251 : loss : 0.039788, loss_ce: 0.014304
2022-01-16 00:04:52,896 iteration 1252 : loss : 0.080326, loss_ce: 0.022904
2022-01-16 00:04:54,610 iteration 1253 : loss : 0.056071, loss_ce: 0.020582
2022-01-16 00:04:56,189 iteration 1254 : loss : 0.074330, loss_ce: 0.035338
2022-01-16 00:04:57,857 iteration 1255 : loss : 0.043991, loss_ce: 0.018508
2022-01-16 00:04:59,615 iteration 1256 : loss : 0.061612, loss_ce: 0.019717
2022-01-16 00:05:01,216 iteration 1257 : loss : 0.045088, loss_ce: 0.021470
2022-01-16 00:05:02,983 iteration 1258 : loss : 0.061029, loss_ce: 0.025064
 18%|█████▌                        | 74/400 [25:51<2:27:07, 27.08s/it]2022-01-16 00:05:04,703 iteration 1259 : loss : 0.046999, loss_ce: 0.016644
2022-01-16 00:05:06,348 iteration 1260 : loss : 0.048486, loss_ce: 0.016128
2022-01-16 00:05:08,037 iteration 1261 : loss : 0.046410, loss_ce: 0.017901
2022-01-16 00:05:09,557 iteration 1262 : loss : 0.035009, loss_ce: 0.016101
2022-01-16 00:05:11,246 iteration 1263 : loss : 0.058493, loss_ce: 0.020776
2022-01-16 00:05:12,854 iteration 1264 : loss : 0.047191, loss_ce: 0.023004
2022-01-16 00:05:14,527 iteration 1265 : loss : 0.044805, loss_ce: 0.016886
2022-01-16 00:05:16,176 iteration 1266 : loss : 0.040826, loss_ce: 0.018854
2022-01-16 00:05:17,863 iteration 1267 : loss : 0.044041, loss_ce: 0.019154
2022-01-16 00:05:19,589 iteration 1268 : loss : 0.130895, loss_ce: 0.029445
2022-01-16 00:05:21,196 iteration 1269 : loss : 0.075246, loss_ce: 0.030459
2022-01-16 00:05:22,882 iteration 1270 : loss : 0.055465, loss_ce: 0.018883
2022-01-16 00:05:24,570 iteration 1271 : loss : 0.075580, loss_ce: 0.033096
2022-01-16 00:05:26,251 iteration 1272 : loss : 0.075965, loss_ce: 0.031490
2022-01-16 00:05:27,883 iteration 1273 : loss : 0.068048, loss_ce: 0.032779
2022-01-16 00:05:29,609 iteration 1274 : loss : 0.060260, loss_ce: 0.019675
2022-01-16 00:05:29,609 Training Data Eval:
2022-01-16 00:05:37,969   Average segmentation loss on training set: 0.0382
2022-01-16 00:05:37,970 Validation Data Eval:
2022-01-16 00:05:40,885   Average segmentation loss on validation set: 0.0899
2022-01-16 00:05:42,480 iteration 1275 : loss : 0.066244, loss_ce: 0.020981
 19%|█████▋                        | 75/400 [26:30<2:46:52, 30.81s/it]2022-01-16 00:05:44,140 iteration 1276 : loss : 0.094097, loss_ce: 0.025418
2022-01-16 00:05:45,596 iteration 1277 : loss : 0.036598, loss_ce: 0.014966
2022-01-16 00:05:47,117 iteration 1278 : loss : 0.044444, loss_ce: 0.019077
2022-01-16 00:05:48,596 iteration 1279 : loss : 0.043105, loss_ce: 0.020336
2022-01-16 00:05:50,030 iteration 1280 : loss : 0.052544, loss_ce: 0.025600
2022-01-16 00:05:51,719 iteration 1281 : loss : 0.042188, loss_ce: 0.019918
2022-01-16 00:05:53,196 iteration 1282 : loss : 0.056246, loss_ce: 0.029179
2022-01-16 00:05:54,810 iteration 1283 : loss : 0.056237, loss_ce: 0.020526
2022-01-16 00:05:56,355 iteration 1284 : loss : 0.055396, loss_ce: 0.026408
2022-01-16 00:05:58,002 iteration 1285 : loss : 0.097859, loss_ce: 0.031268
2022-01-16 00:05:59,628 iteration 1286 : loss : 0.053120, loss_ce: 0.018484
2022-01-16 00:06:01,169 iteration 1287 : loss : 0.053711, loss_ce: 0.019888
2022-01-16 00:06:02,767 iteration 1288 : loss : 0.050617, loss_ce: 0.019028
2022-01-16 00:06:04,505 iteration 1289 : loss : 0.040177, loss_ce: 0.015004
2022-01-16 00:06:06,001 iteration 1290 : loss : 0.059031, loss_ce: 0.018405
2022-01-16 00:06:07,657 iteration 1291 : loss : 0.045500, loss_ce: 0.015120
2022-01-16 00:06:09,173 iteration 1292 : loss : 0.034216, loss_ce: 0.012957
 19%|█████▋                        | 76/400 [26:57<2:39:40, 29.57s/it]2022-01-16 00:06:10,738 iteration 1293 : loss : 0.059719, loss_ce: 0.027188
2022-01-16 00:06:12,262 iteration 1294 : loss : 0.051071, loss_ce: 0.019045
2022-01-16 00:06:13,814 iteration 1295 : loss : 0.040492, loss_ce: 0.016404
2022-01-16 00:06:15,330 iteration 1296 : loss : 0.045069, loss_ce: 0.016478
2022-01-16 00:06:16,800 iteration 1297 : loss : 0.050193, loss_ce: 0.018120
2022-01-16 00:06:18,270 iteration 1298 : loss : 0.034653, loss_ce: 0.014129
2022-01-16 00:06:19,705 iteration 1299 : loss : 0.048701, loss_ce: 0.017087
2022-01-16 00:06:21,214 iteration 1300 : loss : 0.073324, loss_ce: 0.018653
2022-01-16 00:06:22,692 iteration 1301 : loss : 0.052449, loss_ce: 0.026131
2022-01-16 00:06:24,291 iteration 1302 : loss : 0.059149, loss_ce: 0.016338
2022-01-16 00:06:25,761 iteration 1303 : loss : 0.055367, loss_ce: 0.025645
2022-01-16 00:06:27,259 iteration 1304 : loss : 0.089781, loss_ce: 0.023160
2022-01-16 00:06:28,708 iteration 1305 : loss : 0.053707, loss_ce: 0.024774
2022-01-16 00:06:30,240 iteration 1306 : loss : 0.055089, loss_ce: 0.018219
2022-01-16 00:06:31,768 iteration 1307 : loss : 0.058999, loss_ce: 0.019100
2022-01-16 00:06:33,276 iteration 1308 : loss : 0.057475, loss_ce: 0.030239
2022-01-16 00:06:34,927 iteration 1309 : loss : 0.054601, loss_ce: 0.018170
 19%|█████▊                        | 77/400 [27:23<2:33:01, 28.43s/it]2022-01-16 00:06:36,547 iteration 1310 : loss : 0.066806, loss_ce: 0.029692
2022-01-16 00:06:38,343 iteration 1311 : loss : 0.047125, loss_ce: 0.017123
2022-01-16 00:06:39,870 iteration 1312 : loss : 0.062279, loss_ce: 0.030565
2022-01-16 00:06:41,315 iteration 1313 : loss : 0.050372, loss_ce: 0.019093
2022-01-16 00:06:42,813 iteration 1314 : loss : 0.045665, loss_ce: 0.019757
2022-01-16 00:06:44,326 iteration 1315 : loss : 0.046731, loss_ce: 0.019151
2022-01-16 00:06:45,812 iteration 1316 : loss : 0.052534, loss_ce: 0.022466
2022-01-16 00:06:47,356 iteration 1317 : loss : 0.043739, loss_ce: 0.018881
2022-01-16 00:06:48,972 iteration 1318 : loss : 0.049249, loss_ce: 0.020825
2022-01-16 00:06:50,519 iteration 1319 : loss : 0.059152, loss_ce: 0.018676
2022-01-16 00:06:52,106 iteration 1320 : loss : 0.047585, loss_ce: 0.016289
2022-01-16 00:06:53,698 iteration 1321 : loss : 0.068762, loss_ce: 0.027424
2022-01-16 00:06:55,385 iteration 1322 : loss : 0.051035, loss_ce: 0.017712
2022-01-16 00:06:56,951 iteration 1323 : loss : 0.037698, loss_ce: 0.013848
2022-01-16 00:06:58,495 iteration 1324 : loss : 0.045098, loss_ce: 0.014354
2022-01-16 00:07:00,066 iteration 1325 : loss : 0.048450, loss_ce: 0.015765
2022-01-16 00:07:01,590 iteration 1326 : loss : 0.051126, loss_ce: 0.016523
 20%|█████▊                        | 78/400 [27:49<2:29:43, 27.90s/it]2022-01-16 00:07:03,187 iteration 1327 : loss : 0.066613, loss_ce: 0.036009
2022-01-16 00:07:04,761 iteration 1328 : loss : 0.079958, loss_ce: 0.025180
2022-01-16 00:07:06,231 iteration 1329 : loss : 0.042666, loss_ce: 0.020115
2022-01-16 00:07:07,742 iteration 1330 : loss : 0.043463, loss_ce: 0.014873
2022-01-16 00:07:09,313 iteration 1331 : loss : 0.049977, loss_ce: 0.015544
2022-01-16 00:07:10,826 iteration 1332 : loss : 0.033416, loss_ce: 0.013914
2022-01-16 00:07:12,338 iteration 1333 : loss : 0.088780, loss_ce: 0.018497
2022-01-16 00:07:13,795 iteration 1334 : loss : 0.034797, loss_ce: 0.013698
2022-01-16 00:07:15,368 iteration 1335 : loss : 0.047316, loss_ce: 0.016051
2022-01-16 00:07:16,900 iteration 1336 : loss : 0.043196, loss_ce: 0.017680
2022-01-16 00:07:18,449 iteration 1337 : loss : 0.049489, loss_ce: 0.023689
2022-01-16 00:07:19,963 iteration 1338 : loss : 0.068589, loss_ce: 0.029759
2022-01-16 00:07:21,468 iteration 1339 : loss : 0.055205, loss_ce: 0.021547
2022-01-16 00:07:22,930 iteration 1340 : loss : 0.044979, loss_ce: 0.015252
2022-01-16 00:07:24,365 iteration 1341 : loss : 0.047415, loss_ce: 0.016810
2022-01-16 00:07:25,757 iteration 1342 : loss : 0.049064, loss_ce: 0.017073
2022-01-16 00:07:27,155 iteration 1343 : loss : 0.050516, loss_ce: 0.017314
 20%|█████▉                        | 79/400 [28:15<2:25:30, 27.20s/it]2022-01-16 00:07:28,606 iteration 1344 : loss : 0.037281, loss_ce: 0.013368
2022-01-16 00:07:30,005 iteration 1345 : loss : 0.044609, loss_ce: 0.019650
2022-01-16 00:07:31,367 iteration 1346 : loss : 0.043210, loss_ce: 0.013991
2022-01-16 00:07:32,820 iteration 1347 : loss : 0.103328, loss_ce: 0.023457
2022-01-16 00:07:34,255 iteration 1348 : loss : 0.047062, loss_ce: 0.019678
2022-01-16 00:07:35,619 iteration 1349 : loss : 0.083518, loss_ce: 0.042887
2022-01-16 00:07:36,964 iteration 1350 : loss : 0.077214, loss_ce: 0.031570
2022-01-16 00:07:38,202 iteration 1351 : loss : 0.061193, loss_ce: 0.021892
2022-01-16 00:07:39,535 iteration 1352 : loss : 0.039756, loss_ce: 0.014859
2022-01-16 00:07:40,736 iteration 1353 : loss : 0.048852, loss_ce: 0.020582
2022-01-16 00:07:41,994 iteration 1354 : loss : 0.043723, loss_ce: 0.017378
2022-01-16 00:07:43,140 iteration 1355 : loss : 0.082008, loss_ce: 0.026133
2022-01-16 00:07:44,352 iteration 1356 : loss : 0.060616, loss_ce: 0.021574
2022-01-16 00:07:45,455 iteration 1357 : loss : 0.051978, loss_ce: 0.029795
2022-01-16 00:07:46,582 iteration 1358 : loss : 0.057507, loss_ce: 0.018962
2022-01-16 00:07:47,675 iteration 1359 : loss : 0.050618, loss_ce: 0.026274
2022-01-16 00:07:47,676 Training Data Eval:
2022-01-16 00:07:53,424   Average segmentation loss on training set: 0.0596
2022-01-16 00:07:53,424 Validation Data Eval:
2022-01-16 00:07:55,575   Average segmentation loss on validation set: 0.0768
2022-01-16 00:07:56,454 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed2.pth
2022-01-16 00:07:57,637 iteration 1360 : loss : 0.065697, loss_ce: 0.025502
 20%|██████                        | 80/400 [28:45<2:30:18, 28.18s/it]2022-01-16 00:07:58,912 iteration 1361 : loss : 0.070252, loss_ce: 0.021020
2022-01-16 00:08:00,124 iteration 1362 : loss : 0.047812, loss_ce: 0.021653
2022-01-16 00:08:01,369 iteration 1363 : loss : 0.036326, loss_ce: 0.012873
2022-01-16 00:08:02,616 iteration 1364 : loss : 0.071201, loss_ce: 0.021441
2022-01-16 00:08:03,898 iteration 1365 : loss : 0.058790, loss_ce: 0.021921
2022-01-16 00:08:05,090 iteration 1366 : loss : 0.059572, loss_ce: 0.025292
2022-01-16 00:08:06,263 iteration 1367 : loss : 0.041821, loss_ce: 0.019300
2022-01-16 00:08:07,520 iteration 1368 : loss : 0.051199, loss_ce: 0.022483
2022-01-16 00:08:08,732 iteration 1369 : loss : 0.062527, loss_ce: 0.018917
2022-01-16 00:08:09,934 iteration 1370 : loss : 0.051760, loss_ce: 0.018118
2022-01-16 00:08:11,077 iteration 1371 : loss : 0.047161, loss_ce: 0.020704
2022-01-16 00:08:12,283 iteration 1372 : loss : 0.085527, loss_ce: 0.024316
2022-01-16 00:08:13,594 iteration 1373 : loss : 0.061746, loss_ce: 0.030740
2022-01-16 00:08:14,832 iteration 1374 : loss : 0.064482, loss_ce: 0.017984
2022-01-16 00:08:16,148 iteration 1375 : loss : 0.046102, loss_ce: 0.015420
2022-01-16 00:08:17,417 iteration 1376 : loss : 0.046645, loss_ce: 0.018253
2022-01-16 00:08:18,835 iteration 1377 : loss : 0.071597, loss_ce: 0.026718
 20%|██████                        | 81/400 [29:07<2:18:41, 26.09s/it]2022-01-16 00:08:20,408 iteration 1378 : loss : 0.059033, loss_ce: 0.030624
2022-01-16 00:08:21,930 iteration 1379 : loss : 0.071260, loss_ce: 0.020413
2022-01-16 00:08:23,449 iteration 1380 : loss : 0.039952, loss_ce: 0.017676
2022-01-16 00:08:24,999 iteration 1381 : loss : 0.041645, loss_ce: 0.017357
2022-01-16 00:08:26,480 iteration 1382 : loss : 0.050412, loss_ce: 0.020884
2022-01-16 00:08:28,146 iteration 1383 : loss : 0.081129, loss_ce: 0.022569
2022-01-16 00:08:29,752 iteration 1384 : loss : 0.069568, loss_ce: 0.029285
2022-01-16 00:08:31,356 iteration 1385 : loss : 0.037916, loss_ce: 0.014818
2022-01-16 00:08:33,096 iteration 1386 : loss : 0.075928, loss_ce: 0.037127
2022-01-16 00:08:34,651 iteration 1387 : loss : 0.092620, loss_ce: 0.026323
2022-01-16 00:08:36,287 iteration 1388 : loss : 0.084614, loss_ce: 0.021112
2022-01-16 00:08:37,927 iteration 1389 : loss : 0.065544, loss_ce: 0.034448
2022-01-16 00:08:39,396 iteration 1390 : loss : 0.050237, loss_ce: 0.022016
2022-01-16 00:08:41,130 iteration 1391 : loss : 0.073694, loss_ce: 0.023225
2022-01-16 00:08:42,678 iteration 1392 : loss : 0.082642, loss_ce: 0.041943
2022-01-16 00:08:44,275 iteration 1393 : loss : 0.102234, loss_ce: 0.030963
2022-01-16 00:08:45,947 iteration 1394 : loss : 0.053303, loss_ce: 0.017181
 20%|██████▏                       | 82/400 [29:34<2:19:52, 26.39s/it]2022-01-16 00:08:47,565 iteration 1395 : loss : 0.052917, loss_ce: 0.028754
2022-01-16 00:08:49,032 iteration 1396 : loss : 0.048111, loss_ce: 0.021483
2022-01-16 00:08:50,665 iteration 1397 : loss : 0.045497, loss_ce: 0.017242
2022-01-16 00:08:52,157 iteration 1398 : loss : 0.034993, loss_ce: 0.014616
2022-01-16 00:08:53,757 iteration 1399 : loss : 0.040997, loss_ce: 0.018244
2022-01-16 00:08:55,378 iteration 1400 : loss : 0.071110, loss_ce: 0.025130
2022-01-16 00:08:56,957 iteration 1401 : loss : 0.039977, loss_ce: 0.013560
2022-01-16 00:08:58,613 iteration 1402 : loss : 0.048030, loss_ce: 0.017007
2022-01-16 00:09:00,234 iteration 1403 : loss : 0.055946, loss_ce: 0.017611
2022-01-16 00:09:01,990 iteration 1404 : loss : 0.065908, loss_ce: 0.024927
2022-01-16 00:09:03,440 iteration 1405 : loss : 0.057661, loss_ce: 0.020240
2022-01-16 00:09:05,139 iteration 1406 : loss : 0.052330, loss_ce: 0.016871
2022-01-16 00:09:06,683 iteration 1407 : loss : 0.041762, loss_ce: 0.016580
2022-01-16 00:09:08,347 iteration 1408 : loss : 0.064498, loss_ce: 0.027745
2022-01-16 00:09:10,000 iteration 1409 : loss : 0.094699, loss_ce: 0.027967
2022-01-16 00:09:11,563 iteration 1410 : loss : 0.064782, loss_ce: 0.021743
2022-01-16 00:09:13,061 iteration 1411 : loss : 0.036061, loss_ce: 0.013977
 21%|██████▏                       | 83/400 [30:01<2:20:34, 26.61s/it]2022-01-16 00:09:14,714 iteration 1412 : loss : 0.045491, loss_ce: 0.020371
2022-01-16 00:09:16,358 iteration 1413 : loss : 0.043674, loss_ce: 0.017535
2022-01-16 00:09:17,894 iteration 1414 : loss : 0.057746, loss_ce: 0.028091
2022-01-16 00:09:19,329 iteration 1415 : loss : 0.062975, loss_ce: 0.024275
2022-01-16 00:09:20,940 iteration 1416 : loss : 0.042973, loss_ce: 0.017590
2022-01-16 00:09:22,488 iteration 1417 : loss : 0.085229, loss_ce: 0.037327
2022-01-16 00:09:24,025 iteration 1418 : loss : 0.046435, loss_ce: 0.015265
2022-01-16 00:09:25,480 iteration 1419 : loss : 0.051079, loss_ce: 0.021585
2022-01-16 00:09:26,980 iteration 1420 : loss : 0.045593, loss_ce: 0.013095
2022-01-16 00:09:28,545 iteration 1421 : loss : 0.089945, loss_ce: 0.055089
2022-01-16 00:09:30,118 iteration 1422 : loss : 0.053483, loss_ce: 0.021456
2022-01-16 00:09:31,586 iteration 1423 : loss : 0.053748, loss_ce: 0.016013
2022-01-16 00:09:33,031 iteration 1424 : loss : 0.031523, loss_ce: 0.012243
2022-01-16 00:09:34,570 iteration 1425 : loss : 0.060241, loss_ce: 0.020153
2022-01-16 00:09:36,080 iteration 1426 : loss : 0.060522, loss_ce: 0.031055
2022-01-16 00:09:37,537 iteration 1427 : loss : 0.082389, loss_ce: 0.016803
2022-01-16 00:09:39,052 iteration 1428 : loss : 0.056465, loss_ce: 0.019791
 21%|██████▎                       | 84/400 [30:27<2:19:10, 26.43s/it]2022-01-16 00:09:40,547 iteration 1429 : loss : 0.066570, loss_ce: 0.034290
2022-01-16 00:09:41,924 iteration 1430 : loss : 0.040449, loss_ce: 0.015288
2022-01-16 00:09:43,314 iteration 1431 : loss : 0.056137, loss_ce: 0.017648
2022-01-16 00:09:44,807 iteration 1432 : loss : 0.055379, loss_ce: 0.023850
2022-01-16 00:09:46,170 iteration 1433 : loss : 0.041770, loss_ce: 0.018830
2022-01-16 00:09:47,638 iteration 1434 : loss : 0.041211, loss_ce: 0.017008
2022-01-16 00:09:49,017 iteration 1435 : loss : 0.059352, loss_ce: 0.022422
2022-01-16 00:09:50,398 iteration 1436 : loss : 0.054581, loss_ce: 0.027492
2022-01-16 00:09:51,697 iteration 1437 : loss : 0.038369, loss_ce: 0.016833
2022-01-16 00:09:52,951 iteration 1438 : loss : 0.044662, loss_ce: 0.018828
2022-01-16 00:09:54,232 iteration 1439 : loss : 0.101017, loss_ce: 0.034841
2022-01-16 00:09:55,460 iteration 1440 : loss : 0.048917, loss_ce: 0.016979
2022-01-16 00:09:56,750 iteration 1441 : loss : 0.052644, loss_ce: 0.021589
2022-01-16 00:09:58,016 iteration 1442 : loss : 0.057448, loss_ce: 0.016619
2022-01-16 00:09:59,356 iteration 1443 : loss : 0.043250, loss_ce: 0.016220
2022-01-16 00:10:00,652 iteration 1444 : loss : 0.047510, loss_ce: 0.012583
2022-01-16 00:10:00,652 Training Data Eval:
2022-01-16 00:10:06,831   Average segmentation loss on training set: 0.0412
2022-01-16 00:10:06,832 Validation Data Eval:
2022-01-16 00:10:09,060   Average segmentation loss on validation set: 0.1252
2022-01-16 00:10:10,483 iteration 1445 : loss : 0.069036, loss_ce: 0.032298
 21%|██████▍                       | 85/400 [30:58<2:26:37, 27.93s/it]2022-01-16 00:10:11,813 iteration 1446 : loss : 0.046760, loss_ce: 0.016888
2022-01-16 00:10:13,072 iteration 1447 : loss : 0.043249, loss_ce: 0.020923
2022-01-16 00:10:14,456 iteration 1448 : loss : 0.053083, loss_ce: 0.012999
2022-01-16 00:10:15,848 iteration 1449 : loss : 0.051721, loss_ce: 0.017117
2022-01-16 00:10:17,209 iteration 1450 : loss : 0.052942, loss_ce: 0.016345
2022-01-16 00:10:18,559 iteration 1451 : loss : 0.038572, loss_ce: 0.010910
2022-01-16 00:10:19,865 iteration 1452 : loss : 0.058763, loss_ce: 0.033943
2022-01-16 00:10:21,155 iteration 1453 : loss : 0.054168, loss_ce: 0.024018
2022-01-16 00:10:22,416 iteration 1454 : loss : 0.066481, loss_ce: 0.025701
2022-01-16 00:10:23,701 iteration 1455 : loss : 0.044052, loss_ce: 0.015079
2022-01-16 00:10:24,922 iteration 1456 : loss : 0.049799, loss_ce: 0.016581
2022-01-16 00:10:26,228 iteration 1457 : loss : 0.043439, loss_ce: 0.018743
2022-01-16 00:10:27,469 iteration 1458 : loss : 0.044258, loss_ce: 0.018644
2022-01-16 00:10:28,644 iteration 1459 : loss : 0.048136, loss_ce: 0.016170
2022-01-16 00:10:29,846 iteration 1460 : loss : 0.043165, loss_ce: 0.015946
2022-01-16 00:10:30,996 iteration 1461 : loss : 0.048036, loss_ce: 0.016699
2022-01-16 00:10:32,272 iteration 1462 : loss : 0.048395, loss_ce: 0.019187
 22%|██████▍                       | 86/400 [31:20<2:16:31, 26.09s/it]2022-01-16 00:10:33,630 iteration 1463 : loss : 0.073088, loss_ce: 0.026066
2022-01-16 00:10:34,774 iteration 1464 : loss : 0.050527, loss_ce: 0.023738
2022-01-16 00:10:36,080 iteration 1465 : loss : 0.044228, loss_ce: 0.013186
2022-01-16 00:10:37,277 iteration 1466 : loss : 0.062498, loss_ce: 0.021863
2022-01-16 00:10:38,454 iteration 1467 : loss : 0.056892, loss_ce: 0.022803
2022-01-16 00:10:39,712 iteration 1468 : loss : 0.040462, loss_ce: 0.017643
2022-01-16 00:10:40,975 iteration 1469 : loss : 0.056187, loss_ce: 0.022247
2022-01-16 00:10:42,217 iteration 1470 : loss : 0.087279, loss_ce: 0.017377
2022-01-16 00:10:43,466 iteration 1471 : loss : 0.042889, loss_ce: 0.018130
2022-01-16 00:10:44,797 iteration 1472 : loss : 0.049251, loss_ce: 0.018624
2022-01-16 00:10:46,092 iteration 1473 : loss : 0.036787, loss_ce: 0.017546
2022-01-16 00:10:47,435 iteration 1474 : loss : 0.064097, loss_ce: 0.019969
2022-01-16 00:10:48,689 iteration 1475 : loss : 0.038219, loss_ce: 0.016485
2022-01-16 00:10:49,926 iteration 1476 : loss : 0.042535, loss_ce: 0.017410
2022-01-16 00:10:51,237 iteration 1477 : loss : 0.050379, loss_ce: 0.022636
2022-01-16 00:10:52,434 iteration 1478 : loss : 0.059041, loss_ce: 0.017419
2022-01-16 00:10:53,668 iteration 1479 : loss : 0.040787, loss_ce: 0.014005
 22%|██████▌                       | 87/400 [31:41<2:08:44, 24.68s/it]2022-01-16 00:10:54,858 iteration 1480 : loss : 0.032621, loss_ce: 0.010890
2022-01-16 00:10:56,176 iteration 1481 : loss : 0.060190, loss_ce: 0.026941
2022-01-16 00:10:57,387 iteration 1482 : loss : 0.031418, loss_ce: 0.011988
2022-01-16 00:10:58,617 iteration 1483 : loss : 0.046248, loss_ce: 0.018133
2022-01-16 00:10:59,789 iteration 1484 : loss : 0.039719, loss_ce: 0.011039
2022-01-16 00:11:00,945 iteration 1485 : loss : 0.046712, loss_ce: 0.021942
2022-01-16 00:11:02,035 iteration 1486 : loss : 0.049183, loss_ce: 0.015977
2022-01-16 00:11:03,131 iteration 1487 : loss : 0.035388, loss_ce: 0.013593
2022-01-16 00:11:04,161 iteration 1488 : loss : 0.054244, loss_ce: 0.022477
2022-01-16 00:11:05,212 iteration 1489 : loss : 0.054999, loss_ce: 0.022332
2022-01-16 00:11:06,293 iteration 1490 : loss : 0.058899, loss_ce: 0.020157
2022-01-16 00:11:07,280 iteration 1491 : loss : 0.058139, loss_ce: 0.017376
2022-01-16 00:11:08,299 iteration 1492 : loss : 0.043686, loss_ce: 0.019172
2022-01-16 00:11:09,403 iteration 1493 : loss : 0.046450, loss_ce: 0.019379
2022-01-16 00:11:10,431 iteration 1494 : loss : 0.053338, loss_ce: 0.020328
2022-01-16 00:11:11,407 iteration 1495 : loss : 0.052784, loss_ce: 0.014667
2022-01-16 00:11:12,469 iteration 1496 : loss : 0.039689, loss_ce: 0.018570
 22%|██████▌                       | 88/400 [32:00<1:59:09, 22.91s/it]2022-01-16 00:11:13,479 iteration 1497 : loss : 0.037221, loss_ce: 0.014951
2022-01-16 00:11:14,520 iteration 1498 : loss : 0.050915, loss_ce: 0.019186
2022-01-16 00:11:15,472 iteration 1499 : loss : 0.062439, loss_ce: 0.020395
2022-01-16 00:11:16,487 iteration 1500 : loss : 0.039539, loss_ce: 0.017549
2022-01-16 00:11:17,486 iteration 1501 : loss : 0.052968, loss_ce: 0.020333
2022-01-16 00:11:18,584 iteration 1502 : loss : 0.061127, loss_ce: 0.015683
2022-01-16 00:11:19,727 iteration 1503 : loss : 0.096982, loss_ce: 0.035498
2022-01-16 00:11:20,737 iteration 1504 : loss : 0.037533, loss_ce: 0.014937
2022-01-16 00:11:21,817 iteration 1505 : loss : 0.043109, loss_ce: 0.018316
2022-01-16 00:11:22,923 iteration 1506 : loss : 0.035908, loss_ce: 0.014905
2022-01-16 00:11:24,034 iteration 1507 : loss : 0.067008, loss_ce: 0.021971
2022-01-16 00:11:25,156 iteration 1508 : loss : 0.046704, loss_ce: 0.024913
2022-01-16 00:11:26,310 iteration 1509 : loss : 0.037839, loss_ce: 0.014075
2022-01-16 00:11:27,595 iteration 1510 : loss : 0.050413, loss_ce: 0.015545
2022-01-16 00:11:28,875 iteration 1511 : loss : 0.045132, loss_ce: 0.019389
2022-01-16 00:11:30,141 iteration 1512 : loss : 0.055422, loss_ce: 0.015337
2022-01-16 00:11:31,442 iteration 1513 : loss : 0.041991, loss_ce: 0.013984
 22%|██████▋                       | 89/400 [32:19<1:52:39, 21.73s/it]2022-01-16 00:11:32,946 iteration 1514 : loss : 0.044993, loss_ce: 0.017503
2022-01-16 00:11:34,350 iteration 1515 : loss : 0.042470, loss_ce: 0.015978
2022-01-16 00:11:36,046 iteration 1516 : loss : 0.057220, loss_ce: 0.020273
2022-01-16 00:11:37,556 iteration 1517 : loss : 0.033961, loss_ce: 0.011789
2022-01-16 00:11:39,167 iteration 1518 : loss : 0.035979, loss_ce: 0.013755
2022-01-16 00:11:40,816 iteration 1519 : loss : 0.043650, loss_ce: 0.014198
2022-01-16 00:11:42,452 iteration 1520 : loss : 0.047220, loss_ce: 0.017551
2022-01-16 00:11:44,029 iteration 1521 : loss : 0.036195, loss_ce: 0.010739
2022-01-16 00:11:45,581 iteration 1522 : loss : 0.048574, loss_ce: 0.017440
2022-01-16 00:11:47,081 iteration 1523 : loss : 0.040351, loss_ce: 0.011472
2022-01-16 00:11:48,582 iteration 1524 : loss : 0.047841, loss_ce: 0.016931
2022-01-16 00:11:50,089 iteration 1525 : loss : 0.056834, loss_ce: 0.020282
2022-01-16 00:11:51,640 iteration 1526 : loss : 0.044953, loss_ce: 0.021580
2022-01-16 00:11:53,172 iteration 1527 : loss : 0.042357, loss_ce: 0.018972
2022-01-16 00:11:54,639 iteration 1528 : loss : 0.047940, loss_ce: 0.022512
2022-01-16 00:11:56,120 iteration 1529 : loss : 0.062680, loss_ce: 0.022085
2022-01-16 00:11:56,120 Training Data Eval:
2022-01-16 00:12:03,514   Average segmentation loss on training set: 0.0338
2022-01-16 00:12:03,514 Validation Data Eval:
2022-01-16 00:12:06,019   Average segmentation loss on validation set: 0.1240
2022-01-16 00:12:07,479 iteration 1530 : loss : 0.067518, loss_ce: 0.028622
 22%|██████▊                       | 90/400 [32:55<2:14:27, 26.02s/it]2022-01-16 00:12:08,957 iteration 1531 : loss : 0.045851, loss_ce: 0.018136
2022-01-16 00:12:10,342 iteration 1532 : loss : 0.059410, loss_ce: 0.021538
2022-01-16 00:12:11,700 iteration 1533 : loss : 0.034289, loss_ce: 0.012753
2022-01-16 00:12:13,103 iteration 1534 : loss : 0.040160, loss_ce: 0.019269
2022-01-16 00:12:14,619 iteration 1535 : loss : 0.042147, loss_ce: 0.016592
2022-01-16 00:12:16,151 iteration 1536 : loss : 0.057038, loss_ce: 0.026220
2022-01-16 00:12:17,616 iteration 1537 : loss : 0.048386, loss_ce: 0.015460
2022-01-16 00:12:19,128 iteration 1538 : loss : 0.046491, loss_ce: 0.019542
2022-01-16 00:12:20,695 iteration 1539 : loss : 0.039788, loss_ce: 0.017253
2022-01-16 00:12:22,212 iteration 1540 : loss : 0.053948, loss_ce: 0.022612
2022-01-16 00:12:23,847 iteration 1541 : loss : 0.030509, loss_ce: 0.013315
2022-01-16 00:12:25,350 iteration 1542 : loss : 0.035749, loss_ce: 0.014562
2022-01-16 00:12:26,908 iteration 1543 : loss : 0.061371, loss_ce: 0.019221
2022-01-16 00:12:28,364 iteration 1544 : loss : 0.036847, loss_ce: 0.014036
2022-01-16 00:12:30,037 iteration 1545 : loss : 0.055442, loss_ce: 0.020720
2022-01-16 00:12:31,647 iteration 1546 : loss : 0.067314, loss_ce: 0.019493
2022-01-16 00:12:33,280 iteration 1547 : loss : 0.040479, loss_ce: 0.013664
 23%|██████▊                       | 91/400 [33:21<2:13:40, 25.96s/it]2022-01-16 00:12:34,945 iteration 1548 : loss : 0.045461, loss_ce: 0.017781
2022-01-16 00:12:36,522 iteration 1549 : loss : 0.034340, loss_ce: 0.013218
2022-01-16 00:12:38,047 iteration 1550 : loss : 0.049972, loss_ce: 0.021397
2022-01-16 00:12:39,531 iteration 1551 : loss : 0.034622, loss_ce: 0.011739
2022-01-16 00:12:41,051 iteration 1552 : loss : 0.038927, loss_ce: 0.012052
2022-01-16 00:12:42,678 iteration 1553 : loss : 0.061301, loss_ce: 0.026538
2022-01-16 00:12:44,303 iteration 1554 : loss : 0.040051, loss_ce: 0.016063
2022-01-16 00:12:45,849 iteration 1555 : loss : 0.047242, loss_ce: 0.020752
2022-01-16 00:12:47,383 iteration 1556 : loss : 0.039741, loss_ce: 0.013324
2022-01-16 00:12:48,922 iteration 1557 : loss : 0.050310, loss_ce: 0.019957
2022-01-16 00:12:50,488 iteration 1558 : loss : 0.048702, loss_ce: 0.020961
2022-01-16 00:12:52,061 iteration 1559 : loss : 0.064075, loss_ce: 0.024644
2022-01-16 00:12:53,535 iteration 1560 : loss : 0.048401, loss_ce: 0.024886
2022-01-16 00:12:55,072 iteration 1561 : loss : 0.057148, loss_ce: 0.020607
2022-01-16 00:12:56,602 iteration 1562 : loss : 0.068701, loss_ce: 0.017119
2022-01-16 00:12:58,207 iteration 1563 : loss : 0.044233, loss_ce: 0.019209
2022-01-16 00:12:59,769 iteration 1564 : loss : 0.059642, loss_ce: 0.031050
 23%|██████▉                       | 92/400 [33:48<2:14:03, 26.11s/it]2022-01-16 00:13:01,309 iteration 1565 : loss : 0.070523, loss_ce: 0.034661
2022-01-16 00:13:02,872 iteration 1566 : loss : 0.045877, loss_ce: 0.015928
2022-01-16 00:13:04,414 iteration 1567 : loss : 0.044527, loss_ce: 0.013712
2022-01-16 00:13:05,949 iteration 1568 : loss : 0.051571, loss_ce: 0.016520
2022-01-16 00:13:07,478 iteration 1569 : loss : 0.042310, loss_ce: 0.018832
2022-01-16 00:13:09,092 iteration 1570 : loss : 0.032856, loss_ce: 0.013955
2022-01-16 00:13:10,627 iteration 1571 : loss : 0.062650, loss_ce: 0.014692
2022-01-16 00:13:12,192 iteration 1572 : loss : 0.057060, loss_ce: 0.020652
2022-01-16 00:13:13,790 iteration 1573 : loss : 0.055929, loss_ce: 0.025035
2022-01-16 00:13:15,267 iteration 1574 : loss : 0.029393, loss_ce: 0.013544
2022-01-16 00:13:16,838 iteration 1575 : loss : 0.048067, loss_ce: 0.019245
2022-01-16 00:13:18,324 iteration 1576 : loss : 0.046233, loss_ce: 0.022807
2022-01-16 00:13:19,792 iteration 1577 : loss : 0.031814, loss_ce: 0.012310
2022-01-16 00:13:21,249 iteration 1578 : loss : 0.059365, loss_ce: 0.020964
2022-01-16 00:13:22,761 iteration 1579 : loss : 0.033969, loss_ce: 0.012721
2022-01-16 00:13:24,220 iteration 1580 : loss : 0.051078, loss_ce: 0.018512
2022-01-16 00:13:25,664 iteration 1581 : loss : 0.048102, loss_ce: 0.016297
 23%|██████▉                       | 93/400 [34:13<2:13:17, 26.05s/it]2022-01-16 00:13:27,271 iteration 1582 : loss : 0.043514, loss_ce: 0.015996
2022-01-16 00:13:28,764 iteration 1583 : loss : 0.060008, loss_ce: 0.014748
2022-01-16 00:13:30,270 iteration 1584 : loss : 0.047465, loss_ce: 0.021971
2022-01-16 00:13:31,926 iteration 1585 : loss : 0.035252, loss_ce: 0.011472
2022-01-16 00:13:33,485 iteration 1586 : loss : 0.042441, loss_ce: 0.017455
2022-01-16 00:13:34,958 iteration 1587 : loss : 0.038031, loss_ce: 0.015443
2022-01-16 00:13:36,503 iteration 1588 : loss : 0.051334, loss_ce: 0.023847
2022-01-16 00:13:37,991 iteration 1589 : loss : 0.033606, loss_ce: 0.013941
2022-01-16 00:13:39,592 iteration 1590 : loss : 0.047083, loss_ce: 0.018595
2022-01-16 00:13:41,013 iteration 1591 : loss : 0.033094, loss_ce: 0.012534
2022-01-16 00:13:42,490 iteration 1592 : loss : 0.052340, loss_ce: 0.018638
2022-01-16 00:13:44,034 iteration 1593 : loss : 0.061910, loss_ce: 0.025380
2022-01-16 00:13:45,522 iteration 1594 : loss : 0.064051, loss_ce: 0.020960
2022-01-16 00:13:46,941 iteration 1595 : loss : 0.040248, loss_ce: 0.011903
2022-01-16 00:13:48,374 iteration 1596 : loss : 0.051070, loss_ce: 0.025349
2022-01-16 00:13:49,846 iteration 1597 : loss : 0.056303, loss_ce: 0.024440
2022-01-16 00:13:51,317 iteration 1598 : loss : 0.045482, loss_ce: 0.016989
 24%|███████                       | 94/400 [34:39<2:12:15, 25.93s/it]2022-01-16 00:13:52,787 iteration 1599 : loss : 0.034600, loss_ce: 0.013720
2022-01-16 00:13:54,261 iteration 1600 : loss : 0.044309, loss_ce: 0.017820
2022-01-16 00:13:55,812 iteration 1601 : loss : 0.048349, loss_ce: 0.018856
2022-01-16 00:13:57,422 iteration 1602 : loss : 0.053875, loss_ce: 0.019214
2022-01-16 00:13:58,908 iteration 1603 : loss : 0.037026, loss_ce: 0.015917
2022-01-16 00:14:00,381 iteration 1604 : loss : 0.041675, loss_ce: 0.015448
2022-01-16 00:14:01,927 iteration 1605 : loss : 0.048864, loss_ce: 0.016142
2022-01-16 00:14:03,439 iteration 1606 : loss : 0.054498, loss_ce: 0.026307
2022-01-16 00:14:04,914 iteration 1607 : loss : 0.033676, loss_ce: 0.013288
2022-01-16 00:14:06,491 iteration 1608 : loss : 0.048194, loss_ce: 0.016186
2022-01-16 00:14:08,011 iteration 1609 : loss : 0.061558, loss_ce: 0.031813
2022-01-16 00:14:09,505 iteration 1610 : loss : 0.039017, loss_ce: 0.014079
2022-01-16 00:14:11,053 iteration 1611 : loss : 0.059328, loss_ce: 0.018961
2022-01-16 00:14:12,538 iteration 1612 : loss : 0.030772, loss_ce: 0.014269
2022-01-16 00:14:13,912 iteration 1613 : loss : 0.050782, loss_ce: 0.022520
2022-01-16 00:14:15,556 iteration 1614 : loss : 0.053785, loss_ce: 0.016665
2022-01-16 00:14:15,556 Training Data Eval:
2022-01-16 00:14:23,147   Average segmentation loss on training set: 0.0308
2022-01-16 00:14:23,147 Validation Data Eval:
2022-01-16 00:14:25,731   Average segmentation loss on validation set: 0.0956
2022-01-16 00:14:27,233 iteration 1615 : loss : 0.038438, loss_ce: 0.013918
 24%|███████▏                      | 95/400 [35:15<2:27:03, 28.93s/it]2022-01-16 00:14:28,771 iteration 1616 : loss : 0.039428, loss_ce: 0.013170
2022-01-16 00:14:30,255 iteration 1617 : loss : 0.056966, loss_ce: 0.018431
2022-01-16 00:14:31,674 iteration 1618 : loss : 0.042087, loss_ce: 0.017700
2022-01-16 00:14:33,115 iteration 1619 : loss : 0.028428, loss_ce: 0.009828
2022-01-16 00:14:34,689 iteration 1620 : loss : 0.041510, loss_ce: 0.014020
2022-01-16 00:14:36,263 iteration 1621 : loss : 0.056857, loss_ce: 0.032819
2022-01-16 00:14:38,011 iteration 1622 : loss : 0.061167, loss_ce: 0.018351
2022-01-16 00:14:39,533 iteration 1623 : loss : 0.059574, loss_ce: 0.021492
2022-01-16 00:14:41,092 iteration 1624 : loss : 0.042566, loss_ce: 0.016995
2022-01-16 00:14:42,657 iteration 1625 : loss : 0.032281, loss_ce: 0.012134
2022-01-16 00:14:44,220 iteration 1626 : loss : 0.038254, loss_ce: 0.017151
2022-01-16 00:14:45,860 iteration 1627 : loss : 0.042404, loss_ce: 0.015871
2022-01-16 00:14:47,485 iteration 1628 : loss : 0.052996, loss_ce: 0.024271
2022-01-16 00:14:49,194 iteration 1629 : loss : 0.040085, loss_ce: 0.015724
2022-01-16 00:14:50,716 iteration 1630 : loss : 0.041951, loss_ce: 0.015435
2022-01-16 00:14:52,356 iteration 1631 : loss : 0.047086, loss_ce: 0.019452
2022-01-16 00:14:54,134 iteration 1632 : loss : 0.048329, loss_ce: 0.017385
 24%|███████▏                      | 96/400 [35:42<2:23:27, 28.32s/it]2022-01-16 00:14:55,832 iteration 1633 : loss : 0.039080, loss_ce: 0.014835
2022-01-16 00:14:57,445 iteration 1634 : loss : 0.046362, loss_ce: 0.017336
2022-01-16 00:14:59,008 iteration 1635 : loss : 0.031332, loss_ce: 0.014871
2022-01-16 00:15:00,747 iteration 1636 : loss : 0.052079, loss_ce: 0.024641
2022-01-16 00:15:02,352 iteration 1637 : loss : 0.051559, loss_ce: 0.017920
2022-01-16 00:15:03,888 iteration 1638 : loss : 0.045028, loss_ce: 0.020897
2022-01-16 00:15:05,648 iteration 1639 : loss : 0.082957, loss_ce: 0.020267
2022-01-16 00:15:07,212 iteration 1640 : loss : 0.047116, loss_ce: 0.012134
2022-01-16 00:15:08,655 iteration 1641 : loss : 0.029048, loss_ce: 0.013259
2022-01-16 00:15:10,146 iteration 1642 : loss : 0.042891, loss_ce: 0.014630
2022-01-16 00:15:11,741 iteration 1643 : loss : 0.036996, loss_ce: 0.010416
2022-01-16 00:15:13,238 iteration 1644 : loss : 0.042184, loss_ce: 0.014631
2022-01-16 00:15:14,733 iteration 1645 : loss : 0.038528, loss_ce: 0.013470
2022-01-16 00:15:16,201 iteration 1646 : loss : 0.058047, loss_ce: 0.019609
2022-01-16 00:15:17,628 iteration 1647 : loss : 0.048375, loss_ce: 0.016544
2022-01-16 00:15:19,042 iteration 1648 : loss : 0.086394, loss_ce: 0.045003
2022-01-16 00:15:20,404 iteration 1649 : loss : 0.047789, loss_ce: 0.024738
 24%|███████▎                      | 97/400 [36:08<2:19:54, 27.70s/it]2022-01-16 00:15:21,940 iteration 1650 : loss : 0.037348, loss_ce: 0.017048
2022-01-16 00:15:23,499 iteration 1651 : loss : 0.055813, loss_ce: 0.018852
2022-01-16 00:15:24,912 iteration 1652 : loss : 0.054594, loss_ce: 0.017638
2022-01-16 00:15:26,348 iteration 1653 : loss : 0.037785, loss_ce: 0.013623
2022-01-16 00:15:28,027 iteration 1654 : loss : 0.088176, loss_ce: 0.030229
2022-01-16 00:15:29,617 iteration 1655 : loss : 0.046089, loss_ce: 0.015047
2022-01-16 00:15:31,115 iteration 1656 : loss : 0.042020, loss_ce: 0.017959
2022-01-16 00:15:32,728 iteration 1657 : loss : 0.054266, loss_ce: 0.017273
2022-01-16 00:15:34,355 iteration 1658 : loss : 0.050997, loss_ce: 0.030691
2022-01-16 00:15:35,967 iteration 1659 : loss : 0.029578, loss_ce: 0.009759
2022-01-16 00:15:37,645 iteration 1660 : loss : 0.054899, loss_ce: 0.021259
2022-01-16 00:15:39,384 iteration 1661 : loss : 0.045352, loss_ce: 0.016077
2022-01-16 00:15:40,958 iteration 1662 : loss : 0.036315, loss_ce: 0.013091
2022-01-16 00:15:42,447 iteration 1663 : loss : 0.034607, loss_ce: 0.017713
2022-01-16 00:15:44,131 iteration 1664 : loss : 0.047092, loss_ce: 0.020921
2022-01-16 00:15:45,910 iteration 1665 : loss : 0.038562, loss_ce: 0.013460
2022-01-16 00:15:47,575 iteration 1666 : loss : 0.050977, loss_ce: 0.020824
 24%|███████▎                      | 98/400 [36:35<2:18:38, 27.55s/it]2022-01-16 00:15:49,318 iteration 1667 : loss : 0.053357, loss_ce: 0.017074
2022-01-16 00:15:50,935 iteration 1668 : loss : 0.055241, loss_ce: 0.020588
2022-01-16 00:15:52,658 iteration 1669 : loss : 0.030465, loss_ce: 0.012894
2022-01-16 00:15:54,393 iteration 1670 : loss : 0.049019, loss_ce: 0.021762
2022-01-16 00:15:56,007 iteration 1671 : loss : 0.038370, loss_ce: 0.015809
2022-01-16 00:15:57,805 iteration 1672 : loss : 0.035742, loss_ce: 0.013535
2022-01-16 00:15:59,428 iteration 1673 : loss : 0.044727, loss_ce: 0.018494
2022-01-16 00:16:01,163 iteration 1674 : loss : 0.048329, loss_ce: 0.023280
2022-01-16 00:16:02,875 iteration 1675 : loss : 0.046592, loss_ce: 0.014432
2022-01-16 00:16:04,522 iteration 1676 : loss : 0.056933, loss_ce: 0.021356
2022-01-16 00:16:06,171 iteration 1677 : loss : 0.068449, loss_ce: 0.034026
2022-01-16 00:16:07,808 iteration 1678 : loss : 0.040956, loss_ce: 0.016894
2022-01-16 00:16:09,524 iteration 1679 : loss : 0.035059, loss_ce: 0.010154
2022-01-16 00:16:11,141 iteration 1680 : loss : 0.047542, loss_ce: 0.020701
2022-01-16 00:16:12,772 iteration 1681 : loss : 0.046966, loss_ce: 0.024089
2022-01-16 00:16:14,375 iteration 1682 : loss : 0.043554, loss_ce: 0.015983
2022-01-16 00:16:15,985 iteration 1683 : loss : 0.040222, loss_ce: 0.014625
 25%|███████▍                      | 99/400 [37:04<2:19:29, 27.81s/it]2022-01-16 00:16:17,754 iteration 1684 : loss : 0.044229, loss_ce: 0.016449
2022-01-16 00:16:19,362 iteration 1685 : loss : 0.050440, loss_ce: 0.017302
2022-01-16 00:16:20,954 iteration 1686 : loss : 0.029556, loss_ce: 0.010924
2022-01-16 00:16:22,577 iteration 1687 : loss : 0.054258, loss_ce: 0.022575
2022-01-16 00:16:24,280 iteration 1688 : loss : 0.038123, loss_ce: 0.016829
2022-01-16 00:16:26,016 iteration 1689 : loss : 0.050288, loss_ce: 0.021692
2022-01-16 00:16:27,625 iteration 1690 : loss : 0.047786, loss_ce: 0.022361
2022-01-16 00:16:29,120 iteration 1691 : loss : 0.091474, loss_ce: 0.025669
2022-01-16 00:16:30,812 iteration 1692 : loss : 0.067319, loss_ce: 0.021283
2022-01-16 00:16:32,296 iteration 1693 : loss : 0.036350, loss_ce: 0.014660
2022-01-16 00:16:33,880 iteration 1694 : loss : 0.032924, loss_ce: 0.012635
2022-01-16 00:16:35,518 iteration 1695 : loss : 0.045189, loss_ce: 0.015942
2022-01-16 00:16:37,163 iteration 1696 : loss : 0.084618, loss_ce: 0.034716
2022-01-16 00:16:38,685 iteration 1697 : loss : 0.041614, loss_ce: 0.015431
2022-01-16 00:16:40,226 iteration 1698 : loss : 0.041521, loss_ce: 0.016576
2022-01-16 00:16:41,737 iteration 1699 : loss : 0.038061, loss_ce: 0.019070
2022-01-16 00:16:41,737 Training Data Eval:
2022-01-16 00:16:49,913   Average segmentation loss on training set: 0.0383
2022-01-16 00:16:49,914 Validation Data Eval:
2022-01-16 00:16:52,629   Average segmentation loss on validation set: 0.0705
2022-01-16 00:16:53,521 Found new lowest validation loss at iteration 1699! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed2.pth
2022-01-16 00:16:54,918 iteration 1700 : loss : 0.037614, loss_ce: 0.012818
 25%|███████▎                     | 100/400 [37:43<2:35:42, 31.14s/it]2022-01-16 00:16:56,413 iteration 1701 : loss : 0.053916, loss_ce: 0.024785
2022-01-16 00:16:57,894 iteration 1702 : loss : 0.049388, loss_ce: 0.021415
2022-01-16 00:16:59,649 iteration 1703 : loss : 0.054060, loss_ce: 0.022136
2022-01-16 00:17:01,268 iteration 1704 : loss : 0.049101, loss_ce: 0.021031
2022-01-16 00:17:02,922 iteration 1705 : loss : 0.043456, loss_ce: 0.014358
2022-01-16 00:17:04,534 iteration 1706 : loss : 0.062079, loss_ce: 0.018059
2022-01-16 00:17:06,090 iteration 1707 : loss : 0.044037, loss_ce: 0.018301
2022-01-16 00:17:07,634 iteration 1708 : loss : 0.035914, loss_ce: 0.013394
2022-01-16 00:17:09,308 iteration 1709 : loss : 0.061678, loss_ce: 0.025178
2022-01-16 00:17:10,786 iteration 1710 : loss : 0.043598, loss_ce: 0.019605
2022-01-16 00:17:12,348 iteration 1711 : loss : 0.045416, loss_ce: 0.017273
2022-01-16 00:17:13,871 iteration 1712 : loss : 0.042243, loss_ce: 0.013473
2022-01-16 00:17:15,462 iteration 1713 : loss : 0.046111, loss_ce: 0.016709
2022-01-16 00:17:17,015 iteration 1714 : loss : 0.039386, loss_ce: 0.016533
2022-01-16 00:17:18,588 iteration 1715 : loss : 0.044889, loss_ce: 0.016066
2022-01-16 00:17:20,178 iteration 1716 : loss : 0.051490, loss_ce: 0.016094
2022-01-16 00:17:21,726 iteration 1717 : loss : 0.034878, loss_ce: 0.014455
 25%|███████▎                     | 101/400 [38:10<2:28:42, 29.84s/it]2022-01-16 00:17:23,307 iteration 1718 : loss : 0.047221, loss_ce: 0.017193
2022-01-16 00:17:24,876 iteration 1719 : loss : 0.045884, loss_ce: 0.012375
2022-01-16 00:17:26,423 iteration 1720 : loss : 0.043561, loss_ce: 0.013383
2022-01-16 00:17:27,932 iteration 1721 : loss : 0.045776, loss_ce: 0.020549
2022-01-16 00:17:29,619 iteration 1722 : loss : 0.032476, loss_ce: 0.012065
2022-01-16 00:17:31,119 iteration 1723 : loss : 0.037594, loss_ce: 0.013869
2022-01-16 00:17:32,671 iteration 1724 : loss : 0.032634, loss_ce: 0.014850
2022-01-16 00:17:34,219 iteration 1725 : loss : 0.052557, loss_ce: 0.024749
2022-01-16 00:17:35,853 iteration 1726 : loss : 0.055948, loss_ce: 0.022652
2022-01-16 00:17:37,377 iteration 1727 : loss : 0.051093, loss_ce: 0.015953
2022-01-16 00:17:38,970 iteration 1728 : loss : 0.037094, loss_ce: 0.016203
2022-01-16 00:17:40,607 iteration 1729 : loss : 0.045054, loss_ce: 0.018140
2022-01-16 00:17:42,196 iteration 1730 : loss : 0.038581, loss_ce: 0.013841
2022-01-16 00:17:43,764 iteration 1731 : loss : 0.045828, loss_ce: 0.020463
2022-01-16 00:17:45,360 iteration 1732 : loss : 0.043099, loss_ce: 0.018927
2022-01-16 00:17:47,031 iteration 1733 : loss : 0.044882, loss_ce: 0.013072
2022-01-16 00:17:48,576 iteration 1734 : loss : 0.057792, loss_ce: 0.015523
 26%|███████▍                     | 102/400 [38:36<2:23:44, 28.94s/it]2022-01-16 00:17:50,335 iteration 1735 : loss : 0.048848, loss_ce: 0.013471
2022-01-16 00:17:51,999 iteration 1736 : loss : 0.052567, loss_ce: 0.022296
2022-01-16 00:17:53,669 iteration 1737 : loss : 0.066926, loss_ce: 0.025699
2022-01-16 00:17:55,243 iteration 1738 : loss : 0.053147, loss_ce: 0.018789
2022-01-16 00:17:56,760 iteration 1739 : loss : 0.054643, loss_ce: 0.031943
2022-01-16 00:17:58,255 iteration 1740 : loss : 0.047195, loss_ce: 0.014278
2022-01-16 00:17:59,925 iteration 1741 : loss : 0.036255, loss_ce: 0.011201
2022-01-16 00:18:01,517 iteration 1742 : loss : 0.044815, loss_ce: 0.016557
2022-01-16 00:18:03,055 iteration 1743 : loss : 0.052167, loss_ce: 0.030427
2022-01-16 00:18:04,510 iteration 1744 : loss : 0.047736, loss_ce: 0.016498
2022-01-16 00:18:06,035 iteration 1745 : loss : 0.038440, loss_ce: 0.014820
2022-01-16 00:18:07,504 iteration 1746 : loss : 0.053293, loss_ce: 0.018909
2022-01-16 00:18:08,997 iteration 1747 : loss : 0.039321, loss_ce: 0.013557
2022-01-16 00:18:10,503 iteration 1748 : loss : 0.034518, loss_ce: 0.015866
2022-01-16 00:18:12,028 iteration 1749 : loss : 0.042321, loss_ce: 0.014661
2022-01-16 00:18:13,476 iteration 1750 : loss : 0.045529, loss_ce: 0.022062
2022-01-16 00:18:15,053 iteration 1751 : loss : 0.043745, loss_ce: 0.015350
 26%|███████▍                     | 103/400 [39:03<2:19:36, 28.21s/it]2022-01-16 00:18:16,695 iteration 1752 : loss : 0.046435, loss_ce: 0.018991
2022-01-16 00:18:18,277 iteration 1753 : loss : 0.045963, loss_ce: 0.020516
2022-01-16 00:18:19,792 iteration 1754 : loss : 0.035966, loss_ce: 0.016175
2022-01-16 00:18:21,342 iteration 1755 : loss : 0.052515, loss_ce: 0.017680
2022-01-16 00:18:22,880 iteration 1756 : loss : 0.039196, loss_ce: 0.017448
2022-01-16 00:18:24,373 iteration 1757 : loss : 0.119070, loss_ce: 0.028231
2022-01-16 00:18:25,872 iteration 1758 : loss : 0.047523, loss_ce: 0.018109
2022-01-16 00:18:27,376 iteration 1759 : loss : 0.048975, loss_ce: 0.014389
2022-01-16 00:18:28,915 iteration 1760 : loss : 0.044569, loss_ce: 0.021398
2022-01-16 00:18:30,372 iteration 1761 : loss : 0.028435, loss_ce: 0.013091
2022-01-16 00:18:31,939 iteration 1762 : loss : 0.057154, loss_ce: 0.023028
2022-01-16 00:18:33,430 iteration 1763 : loss : 0.040155, loss_ce: 0.013110
2022-01-16 00:18:34,947 iteration 1764 : loss : 0.114552, loss_ce: 0.041422
2022-01-16 00:18:36,442 iteration 1765 : loss : 0.064009, loss_ce: 0.017254
2022-01-16 00:18:37,827 iteration 1766 : loss : 0.039135, loss_ce: 0.016379
2022-01-16 00:18:39,238 iteration 1767 : loss : 0.062187, loss_ce: 0.025071
2022-01-16 00:18:40,748 iteration 1768 : loss : 0.044196, loss_ce: 0.017401
 26%|███████▌                     | 104/400 [39:29<2:15:25, 27.45s/it]2022-01-16 00:18:42,230 iteration 1769 : loss : 0.036317, loss_ce: 0.010716
2022-01-16 00:18:43,772 iteration 1770 : loss : 0.057677, loss_ce: 0.030740
2022-01-16 00:18:45,110 iteration 1771 : loss : 0.037393, loss_ce: 0.014698
2022-01-16 00:18:46,382 iteration 1772 : loss : 0.026076, loss_ce: 0.009058
2022-01-16 00:18:47,667 iteration 1773 : loss : 0.038300, loss_ce: 0.013104
2022-01-16 00:18:49,037 iteration 1774 : loss : 0.031613, loss_ce: 0.013900
2022-01-16 00:18:50,462 iteration 1775 : loss : 0.079658, loss_ce: 0.048030
2022-01-16 00:18:51,853 iteration 1776 : loss : 0.065868, loss_ce: 0.025809
2022-01-16 00:18:53,288 iteration 1777 : loss : 0.042081, loss_ce: 0.017292
2022-01-16 00:18:54,753 iteration 1778 : loss : 0.052219, loss_ce: 0.017139
2022-01-16 00:18:56,329 iteration 1779 : loss : 0.044954, loss_ce: 0.020072
2022-01-16 00:18:57,910 iteration 1780 : loss : 0.051048, loss_ce: 0.019243
2022-01-16 00:18:59,469 iteration 1781 : loss : 0.051750, loss_ce: 0.024530
2022-01-16 00:19:01,005 iteration 1782 : loss : 0.044024, loss_ce: 0.015420
2022-01-16 00:19:02,540 iteration 1783 : loss : 0.046565, loss_ce: 0.021204
2022-01-16 00:19:04,274 iteration 1784 : loss : 0.047984, loss_ce: 0.019089
2022-01-16 00:19:04,275 Training Data Eval:
2022-01-16 00:19:11,991   Average segmentation loss on training set: 0.0308
2022-01-16 00:19:11,991 Validation Data Eval:
2022-01-16 00:19:14,602   Average segmentation loss on validation set: 0.0794
2022-01-16 00:19:16,118 iteration 1785 : loss : 0.043786, loss_ce: 0.017535
 26%|███████▌                     | 105/400 [40:04<2:26:39, 29.83s/it]2022-01-16 00:19:17,764 iteration 1786 : loss : 0.051230, loss_ce: 0.022730
2022-01-16 00:19:19,265 iteration 1787 : loss : 0.051696, loss_ce: 0.019558
2022-01-16 00:19:20,690 iteration 1788 : loss : 0.043797, loss_ce: 0.018493
2022-01-16 00:19:22,161 iteration 1789 : loss : 0.050259, loss_ce: 0.016832
2022-01-16 00:19:23,645 iteration 1790 : loss : 0.032411, loss_ce: 0.015000
2022-01-16 00:19:25,092 iteration 1791 : loss : 0.030225, loss_ce: 0.015084
2022-01-16 00:19:26,724 iteration 1792 : loss : 0.034578, loss_ce: 0.010931
2022-01-16 00:19:28,343 iteration 1793 : loss : 0.031041, loss_ce: 0.013997
2022-01-16 00:19:29,885 iteration 1794 : loss : 0.056667, loss_ce: 0.032075
2022-01-16 00:19:31,499 iteration 1795 : loss : 0.046816, loss_ce: 0.018251
2022-01-16 00:19:33,074 iteration 1796 : loss : 0.035842, loss_ce: 0.012916
2022-01-16 00:19:34,696 iteration 1797 : loss : 0.030876, loss_ce: 0.012323
2022-01-16 00:19:36,191 iteration 1798 : loss : 0.050051, loss_ce: 0.021316
2022-01-16 00:19:37,705 iteration 1799 : loss : 0.044745, loss_ce: 0.018727
2022-01-16 00:19:39,259 iteration 1800 : loss : 0.065349, loss_ce: 0.031269
2022-01-16 00:19:40,811 iteration 1801 : loss : 0.037512, loss_ce: 0.015090
2022-01-16 00:19:42,301 iteration 1802 : loss : 0.064730, loss_ce: 0.019051
 26%|███████▋                     | 106/400 [40:30<2:20:47, 28.73s/it]2022-01-16 00:19:43,895 iteration 1803 : loss : 0.046051, loss_ce: 0.015635
2022-01-16 00:19:45,414 iteration 1804 : loss : 0.047511, loss_ce: 0.009630
2022-01-16 00:19:46,929 iteration 1805 : loss : 0.039461, loss_ce: 0.019119
2022-01-16 00:19:48,474 iteration 1806 : loss : 0.048736, loss_ce: 0.016285
2022-01-16 00:19:50,063 iteration 1807 : loss : 0.040405, loss_ce: 0.014413
2022-01-16 00:19:51,645 iteration 1808 : loss : 0.060404, loss_ce: 0.028115
2022-01-16 00:19:53,339 iteration 1809 : loss : 0.043816, loss_ce: 0.019485
2022-01-16 00:19:54,924 iteration 1810 : loss : 0.043144, loss_ce: 0.017541
2022-01-16 00:19:56,466 iteration 1811 : loss : 0.038555, loss_ce: 0.014753
2022-01-16 00:19:58,117 iteration 1812 : loss : 0.040060, loss_ce: 0.021658
2022-01-16 00:19:59,759 iteration 1813 : loss : 0.062438, loss_ce: 0.019492
2022-01-16 00:20:01,359 iteration 1814 : loss : 0.048728, loss_ce: 0.020015
2022-01-16 00:20:02,943 iteration 1815 : loss : 0.032339, loss_ce: 0.016020
2022-01-16 00:20:04,515 iteration 1816 : loss : 0.085984, loss_ce: 0.031024
2022-01-16 00:20:06,056 iteration 1817 : loss : 0.036987, loss_ce: 0.012149
2022-01-16 00:20:07,668 iteration 1818 : loss : 0.033005, loss_ce: 0.017590
2022-01-16 00:20:09,124 iteration 1819 : loss : 0.030487, loss_ce: 0.011953
 27%|███████▊                     | 107/400 [40:57<2:17:30, 28.16s/it]2022-01-16 00:20:10,782 iteration 1820 : loss : 0.054532, loss_ce: 0.018365
2022-01-16 00:20:12,283 iteration 1821 : loss : 0.040455, loss_ce: 0.013591
2022-01-16 00:20:13,903 iteration 1822 : loss : 0.049242, loss_ce: 0.023168
2022-01-16 00:20:15,453 iteration 1823 : loss : 0.038683, loss_ce: 0.016034
2022-01-16 00:20:16,975 iteration 1824 : loss : 0.030842, loss_ce: 0.011237
2022-01-16 00:20:18,635 iteration 1825 : loss : 0.043597, loss_ce: 0.015784
2022-01-16 00:20:20,130 iteration 1826 : loss : 0.034149, loss_ce: 0.014129
2022-01-16 00:20:21,680 iteration 1827 : loss : 0.052696, loss_ce: 0.013885
2022-01-16 00:20:23,302 iteration 1828 : loss : 0.045680, loss_ce: 0.021207
2022-01-16 00:20:24,941 iteration 1829 : loss : 0.054216, loss_ce: 0.014876
2022-01-16 00:20:26,520 iteration 1830 : loss : 0.033187, loss_ce: 0.013994
2022-01-16 00:20:28,066 iteration 1831 : loss : 0.041677, loss_ce: 0.018146
2022-01-16 00:20:29,637 iteration 1832 : loss : 0.037085, loss_ce: 0.012779
2022-01-16 00:20:31,176 iteration 1833 : loss : 0.041196, loss_ce: 0.024412
2022-01-16 00:20:32,873 iteration 1834 : loss : 0.039166, loss_ce: 0.013873
2022-01-16 00:20:34,507 iteration 1835 : loss : 0.042112, loss_ce: 0.014483
2022-01-16 00:20:36,001 iteration 1836 : loss : 0.044561, loss_ce: 0.020378
 27%|███████▊                     | 108/400 [41:24<2:15:10, 27.78s/it]2022-01-16 00:20:37,710 iteration 1837 : loss : 0.063282, loss_ce: 0.012916
2022-01-16 00:20:39,340 iteration 1838 : loss : 0.040985, loss_ce: 0.017116
2022-01-16 00:20:40,859 iteration 1839 : loss : 0.029809, loss_ce: 0.013183
2022-01-16 00:20:42,439 iteration 1840 : loss : 0.053709, loss_ce: 0.015235
2022-01-16 00:20:44,022 iteration 1841 : loss : 0.053886, loss_ce: 0.020824
2022-01-16 00:20:45,767 iteration 1842 : loss : 0.041652, loss_ce: 0.017389
2022-01-16 00:20:47,317 iteration 1843 : loss : 0.029828, loss_ce: 0.012874
2022-01-16 00:20:48,908 iteration 1844 : loss : 0.045436, loss_ce: 0.018694
2022-01-16 00:20:50,482 iteration 1845 : loss : 0.048374, loss_ce: 0.023814
2022-01-16 00:20:52,138 iteration 1846 : loss : 0.043252, loss_ce: 0.015033
2022-01-16 00:20:53,735 iteration 1847 : loss : 0.029267, loss_ce: 0.010986
2022-01-16 00:20:55,287 iteration 1848 : loss : 0.041985, loss_ce: 0.014642
2022-01-16 00:20:56,993 iteration 1849 : loss : 0.075120, loss_ce: 0.031250
2022-01-16 00:20:58,525 iteration 1850 : loss : 0.052863, loss_ce: 0.017342
2022-01-16 00:21:00,154 iteration 1851 : loss : 0.047329, loss_ce: 0.020375
2022-01-16 00:21:01,715 iteration 1852 : loss : 0.033146, loss_ce: 0.016905
2022-01-16 00:21:03,403 iteration 1853 : loss : 0.039113, loss_ce: 0.016931
 27%|███████▉                     | 109/400 [41:51<2:14:10, 27.66s/it]2022-01-16 00:21:05,090 iteration 1854 : loss : 0.037799, loss_ce: 0.013888
2022-01-16 00:21:06,793 iteration 1855 : loss : 0.044267, loss_ce: 0.018334
2022-01-16 00:21:08,395 iteration 1856 : loss : 0.038773, loss_ce: 0.016878
2022-01-16 00:21:09,983 iteration 1857 : loss : 0.033618, loss_ce: 0.015570
2022-01-16 00:21:11,623 iteration 1858 : loss : 0.025729, loss_ce: 0.012819
2022-01-16 00:21:13,209 iteration 1859 : loss : 0.047648, loss_ce: 0.019823
2022-01-16 00:21:14,910 iteration 1860 : loss : 0.072426, loss_ce: 0.027859
2022-01-16 00:21:16,481 iteration 1861 : loss : 0.031952, loss_ce: 0.015028
2022-01-16 00:21:18,078 iteration 1862 : loss : 0.030263, loss_ce: 0.014897
2022-01-16 00:21:19,625 iteration 1863 : loss : 0.072107, loss_ce: 0.030888
2022-01-16 00:21:21,250 iteration 1864 : loss : 0.032802, loss_ce: 0.013384
2022-01-16 00:21:22,842 iteration 1865 : loss : 0.068105, loss_ce: 0.018673
2022-01-16 00:21:24,428 iteration 1866 : loss : 0.030248, loss_ce: 0.010707
2022-01-16 00:21:25,860 iteration 1867 : loss : 0.035026, loss_ce: 0.011155
2022-01-16 00:21:27,329 iteration 1868 : loss : 0.047609, loss_ce: 0.013711
2022-01-16 00:21:28,758 iteration 1869 : loss : 0.050666, loss_ce: 0.022510
2022-01-16 00:21:28,758 Training Data Eval:
2022-01-16 00:21:36,678   Average segmentation loss on training set: 0.0494
2022-01-16 00:21:36,679 Validation Data Eval:
2022-01-16 00:21:39,396   Average segmentation loss on validation set: 0.1717
2022-01-16 00:21:40,925 iteration 1870 : loss : 0.056787, loss_ce: 0.022585
 28%|███████▉                     | 110/400 [42:29<2:28:00, 30.62s/it]2022-01-16 00:21:42,552 iteration 1871 : loss : 0.033686, loss_ce: 0.009189
2022-01-16 00:21:44,165 iteration 1872 : loss : 0.032625, loss_ce: 0.010875
2022-01-16 00:21:45,816 iteration 1873 : loss : 0.033280, loss_ce: 0.010319
2022-01-16 00:21:47,381 iteration 1874 : loss : 0.043054, loss_ce: 0.015323
2022-01-16 00:21:48,974 iteration 1875 : loss : 0.031526, loss_ce: 0.013195
2022-01-16 00:21:50,560 iteration 1876 : loss : 0.031535, loss_ce: 0.014637
2022-01-16 00:21:52,130 iteration 1877 : loss : 0.032125, loss_ce: 0.010115
2022-01-16 00:21:53,667 iteration 1878 : loss : 0.048972, loss_ce: 0.024145
2022-01-16 00:21:55,200 iteration 1879 : loss : 0.052231, loss_ce: 0.016776
2022-01-16 00:21:56,737 iteration 1880 : loss : 0.045214, loss_ce: 0.019362
2022-01-16 00:21:58,274 iteration 1881 : loss : 0.059169, loss_ce: 0.030805
2022-01-16 00:21:59,866 iteration 1882 : loss : 0.066143, loss_ce: 0.024202
2022-01-16 00:22:01,376 iteration 1883 : loss : 0.030230, loss_ce: 0.010213
2022-01-16 00:22:03,014 iteration 1884 : loss : 0.043562, loss_ce: 0.016094
2022-01-16 00:22:04,471 iteration 1885 : loss : 0.027513, loss_ce: 0.011117
2022-01-16 00:22:06,135 iteration 1886 : loss : 0.059164, loss_ce: 0.021804
2022-01-16 00:22:07,676 iteration 1887 : loss : 0.082711, loss_ce: 0.037610
 28%|████████                     | 111/400 [42:55<2:21:53, 29.46s/it]2022-01-16 00:22:09,337 iteration 1888 : loss : 0.064552, loss_ce: 0.018435
2022-01-16 00:22:10,817 iteration 1889 : loss : 0.051791, loss_ce: 0.016002
2022-01-16 00:22:12,260 iteration 1890 : loss : 0.038011, loss_ce: 0.017572
2022-01-16 00:22:13,778 iteration 1891 : loss : 0.032323, loss_ce: 0.011031
2022-01-16 00:22:15,294 iteration 1892 : loss : 0.039188, loss_ce: 0.018239
2022-01-16 00:22:16,858 iteration 1893 : loss : 0.038587, loss_ce: 0.014322
2022-01-16 00:22:18,352 iteration 1894 : loss : 0.046895, loss_ce: 0.018235
2022-01-16 00:22:19,814 iteration 1895 : loss : 0.032179, loss_ce: 0.011645
2022-01-16 00:22:21,528 iteration 1896 : loss : 0.034558, loss_ce: 0.014697
2022-01-16 00:22:23,069 iteration 1897 : loss : 0.040486, loss_ce: 0.014650
2022-01-16 00:22:24,638 iteration 1898 : loss : 0.046201, loss_ce: 0.020243
2022-01-16 00:22:26,078 iteration 1899 : loss : 0.054151, loss_ce: 0.018890
2022-01-16 00:22:27,490 iteration 1900 : loss : 0.051984, loss_ce: 0.019615
2022-01-16 00:22:28,869 iteration 1901 : loss : 0.044704, loss_ce: 0.016311
2022-01-16 00:22:30,514 iteration 1902 : loss : 0.035563, loss_ce: 0.013639
2022-01-16 00:22:32,133 iteration 1903 : loss : 0.040565, loss_ce: 0.016380
2022-01-16 00:22:33,701 iteration 1904 : loss : 0.033432, loss_ce: 0.013429
 28%|████████                     | 112/400 [43:22<2:16:28, 28.43s/it]2022-01-16 00:22:35,271 iteration 1905 : loss : 0.038540, loss_ce: 0.015978
2022-01-16 00:22:36,818 iteration 1906 : loss : 0.042805, loss_ce: 0.013001
2022-01-16 00:22:38,454 iteration 1907 : loss : 0.029783, loss_ce: 0.012569
2022-01-16 00:22:40,142 iteration 1908 : loss : 0.049893, loss_ce: 0.022440
2022-01-16 00:22:41,646 iteration 1909 : loss : 0.026215, loss_ce: 0.010852
2022-01-16 00:22:43,370 iteration 1910 : loss : 0.038475, loss_ce: 0.014771
2022-01-16 00:22:44,988 iteration 1911 : loss : 0.034143, loss_ce: 0.012780
2022-01-16 00:22:46,684 iteration 1912 : loss : 0.046929, loss_ce: 0.017808
2022-01-16 00:22:48,277 iteration 1913 : loss : 0.045706, loss_ce: 0.015543
2022-01-16 00:22:49,928 iteration 1914 : loss : 0.061832, loss_ce: 0.026348
2022-01-16 00:22:51,543 iteration 1915 : loss : 0.039573, loss_ce: 0.014073
2022-01-16 00:22:53,097 iteration 1916 : loss : 0.039473, loss_ce: 0.011890
2022-01-16 00:22:54,669 iteration 1917 : loss : 0.027698, loss_ce: 0.011010
2022-01-16 00:22:56,419 iteration 1918 : loss : 0.053307, loss_ce: 0.028111
2022-01-16 00:22:58,060 iteration 1919 : loss : 0.059564, loss_ce: 0.016826
2022-01-16 00:22:59,540 iteration 1920 : loss : 0.045097, loss_ce: 0.019393
2022-01-16 00:23:01,199 iteration 1921 : loss : 0.045649, loss_ce: 0.017496
 28%|████████▏                    | 113/400 [43:49<2:14:39, 28.15s/it]2022-01-16 00:23:02,828 iteration 1922 : loss : 0.049830, loss_ce: 0.020734
2022-01-16 00:23:04,359 iteration 1923 : loss : 0.028861, loss_ce: 0.010679
2022-01-16 00:23:05,938 iteration 1924 : loss : 0.055198, loss_ce: 0.016515
2022-01-16 00:23:07,500 iteration 1925 : loss : 0.068736, loss_ce: 0.017863
2022-01-16 00:23:09,127 iteration 1926 : loss : 0.039843, loss_ce: 0.015270
2022-01-16 00:23:10,790 iteration 1927 : loss : 0.034097, loss_ce: 0.016004
2022-01-16 00:23:12,312 iteration 1928 : loss : 0.040771, loss_ce: 0.013556
2022-01-16 00:23:13,969 iteration 1929 : loss : 0.062986, loss_ce: 0.027480
2022-01-16 00:23:15,532 iteration 1930 : loss : 0.047130, loss_ce: 0.020564
2022-01-16 00:23:17,173 iteration 1931 : loss : 0.060577, loss_ce: 0.022710
2022-01-16 00:23:18,790 iteration 1932 : loss : 0.068267, loss_ce: 0.019803
2022-01-16 00:23:20,412 iteration 1933 : loss : 0.044527, loss_ce: 0.016420
2022-01-16 00:23:21,979 iteration 1934 : loss : 0.040531, loss_ce: 0.012160
2022-01-16 00:23:23,660 iteration 1935 : loss : 0.046405, loss_ce: 0.017729
2022-01-16 00:23:25,212 iteration 1936 : loss : 0.038502, loss_ce: 0.013842
2022-01-16 00:23:26,690 iteration 1937 : loss : 0.042418, loss_ce: 0.016614
2022-01-16 00:23:28,228 iteration 1938 : loss : 0.029870, loss_ce: 0.012809
 28%|████████▎                    | 114/400 [44:16<2:12:35, 27.82s/it]2022-01-16 00:23:29,863 iteration 1939 : loss : 0.059331, loss_ce: 0.024032
2022-01-16 00:23:31,315 iteration 1940 : loss : 0.034904, loss_ce: 0.015385
2022-01-16 00:23:32,793 iteration 1941 : loss : 0.030698, loss_ce: 0.010853
2022-01-16 00:23:34,309 iteration 1942 : loss : 0.034723, loss_ce: 0.010881
2022-01-16 00:23:35,790 iteration 1943 : loss : 0.041794, loss_ce: 0.013182
2022-01-16 00:23:37,263 iteration 1944 : loss : 0.042915, loss_ce: 0.014648
2022-01-16 00:23:38,767 iteration 1945 : loss : 0.047873, loss_ce: 0.019526
2022-01-16 00:23:40,220 iteration 1946 : loss : 0.037810, loss_ce: 0.010408
2022-01-16 00:23:41,785 iteration 1947 : loss : 0.034750, loss_ce: 0.008860
2022-01-16 00:23:43,389 iteration 1948 : loss : 0.044409, loss_ce: 0.016699
2022-01-16 00:23:44,922 iteration 1949 : loss : 0.035418, loss_ce: 0.013602
2022-01-16 00:23:46,475 iteration 1950 : loss : 0.051602, loss_ce: 0.018681
2022-01-16 00:23:48,093 iteration 1951 : loss : 0.036635, loss_ce: 0.014071
2022-01-16 00:23:49,817 iteration 1952 : loss : 0.039308, loss_ce: 0.018506
2022-01-16 00:23:51,451 iteration 1953 : loss : 0.054824, loss_ce: 0.032479
2022-01-16 00:23:52,984 iteration 1954 : loss : 0.029820, loss_ce: 0.012013
2022-01-16 00:23:52,985 Training Data Eval:
2022-01-16 00:24:01,268   Average segmentation loss on training set: 0.0308
2022-01-16 00:24:01,269 Validation Data Eval:
2022-01-16 00:24:03,983   Average segmentation loss on validation set: 0.0901
2022-01-16 00:24:05,593 iteration 1955 : loss : 0.038380, loss_ce: 0.013712
 29%|████████▎                    | 115/400 [44:53<2:25:43, 30.68s/it]2022-01-16 00:24:07,169 iteration 1956 : loss : 0.066555, loss_ce: 0.024811
2022-01-16 00:24:08,928 iteration 1957 : loss : 0.052060, loss_ce: 0.031367
2022-01-16 00:24:10,484 iteration 1958 : loss : 0.072517, loss_ce: 0.018207
2022-01-16 00:24:12,044 iteration 1959 : loss : 0.047725, loss_ce: 0.012993
2022-01-16 00:24:13,630 iteration 1960 : loss : 0.038655, loss_ce: 0.014863
2022-01-16 00:24:15,100 iteration 1961 : loss : 0.032400, loss_ce: 0.012289
2022-01-16 00:24:16,700 iteration 1962 : loss : 0.032330, loss_ce: 0.012033
2022-01-16 00:24:18,225 iteration 1963 : loss : 0.029504, loss_ce: 0.010236
2022-01-16 00:24:19,867 iteration 1964 : loss : 0.044041, loss_ce: 0.012947
2022-01-16 00:24:21,311 iteration 1965 : loss : 0.037578, loss_ce: 0.017064
2022-01-16 00:24:22,949 iteration 1966 : loss : 0.033204, loss_ce: 0.014245
2022-01-16 00:24:24,559 iteration 1967 : loss : 0.043330, loss_ce: 0.015715
2022-01-16 00:24:26,183 iteration 1968 : loss : 0.046870, loss_ce: 0.017550
2022-01-16 00:24:27,718 iteration 1969 : loss : 0.072289, loss_ce: 0.026370
2022-01-16 00:24:29,119 iteration 1970 : loss : 0.033288, loss_ce: 0.013460
2022-01-16 00:24:30,703 iteration 1971 : loss : 0.033934, loss_ce: 0.011986
2022-01-16 00:24:32,299 iteration 1972 : loss : 0.043313, loss_ce: 0.013434
 29%|████████▍                    | 116/400 [45:20<2:19:34, 29.49s/it]2022-01-16 00:24:33,878 iteration 1973 : loss : 0.047767, loss_ce: 0.023489
2022-01-16 00:24:35,426 iteration 1974 : loss : 0.036462, loss_ce: 0.014978
2022-01-16 00:24:37,032 iteration 1975 : loss : 0.039334, loss_ce: 0.016166
2022-01-16 00:24:38,531 iteration 1976 : loss : 0.054338, loss_ce: 0.028786
2022-01-16 00:24:40,137 iteration 1977 : loss : 0.054442, loss_ce: 0.023446
2022-01-16 00:24:41,728 iteration 1978 : loss : 0.046158, loss_ce: 0.016948
2022-01-16 00:24:43,200 iteration 1979 : loss : 0.036027, loss_ce: 0.014851
2022-01-16 00:24:44,656 iteration 1980 : loss : 0.032933, loss_ce: 0.010662
2022-01-16 00:24:46,123 iteration 1981 : loss : 0.028179, loss_ce: 0.012516
2022-01-16 00:24:47,659 iteration 1982 : loss : 0.034030, loss_ce: 0.012989
2022-01-16 00:24:49,106 iteration 1983 : loss : 0.049304, loss_ce: 0.018319
2022-01-16 00:24:50,688 iteration 1984 : loss : 0.056987, loss_ce: 0.022574
2022-01-16 00:24:52,167 iteration 1985 : loss : 0.041803, loss_ce: 0.015210
2022-01-16 00:24:53,672 iteration 1986 : loss : 0.061161, loss_ce: 0.020640
2022-01-16 00:24:55,079 iteration 1987 : loss : 0.030340, loss_ce: 0.010821
2022-01-16 00:24:56,410 iteration 1988 : loss : 0.035549, loss_ce: 0.015486
2022-01-16 00:24:57,769 iteration 1989 : loss : 0.038812, loss_ce: 0.014372
 29%|████████▍                    | 117/400 [45:46<2:13:23, 28.28s/it]2022-01-16 00:24:59,163 iteration 1990 : loss : 0.039412, loss_ce: 0.010295
2022-01-16 00:25:00,439 iteration 1991 : loss : 0.034391, loss_ce: 0.015590
2022-01-16 00:25:01,789 iteration 1992 : loss : 0.029653, loss_ce: 0.009614
2022-01-16 00:25:03,152 iteration 1993 : loss : 0.036562, loss_ce: 0.013227
2022-01-16 00:25:04,524 iteration 1994 : loss : 0.029980, loss_ce: 0.013474
2022-01-16 00:25:05,838 iteration 1995 : loss : 0.029049, loss_ce: 0.012398
2022-01-16 00:25:07,170 iteration 1996 : loss : 0.029806, loss_ce: 0.013594
2022-01-16 00:25:08,386 iteration 1997 : loss : 0.030194, loss_ce: 0.011960
2022-01-16 00:25:09,635 iteration 1998 : loss : 0.038632, loss_ce: 0.015229
2022-01-16 00:25:10,889 iteration 1999 : loss : 0.043164, loss_ce: 0.018159
2022-01-16 00:25:12,112 iteration 2000 : loss : 0.047812, loss_ce: 0.025597
2022-01-16 00:25:13,311 iteration 2001 : loss : 0.043457, loss_ce: 0.015046
2022-01-16 00:25:14,644 iteration 2002 : loss : 0.035126, loss_ce: 0.016108
2022-01-16 00:25:15,901 iteration 2003 : loss : 0.048642, loss_ce: 0.016401
2022-01-16 00:25:17,247 iteration 2004 : loss : 0.049730, loss_ce: 0.023415
2022-01-16 00:25:18,530 iteration 2005 : loss : 0.044453, loss_ce: 0.019424
2022-01-16 00:25:19,889 iteration 2006 : loss : 0.037476, loss_ce: 0.012213
 30%|████████▌                    | 118/400 [46:08<2:04:13, 26.43s/it]2022-01-16 00:25:21,455 iteration 2007 : loss : 0.044124, loss_ce: 0.014275
2022-01-16 00:25:22,891 iteration 2008 : loss : 0.041798, loss_ce: 0.016136
2022-01-16 00:25:24,253 iteration 2009 : loss : 0.036476, loss_ce: 0.016763
2022-01-16 00:25:25,701 iteration 2010 : loss : 0.035442, loss_ce: 0.013894
2022-01-16 00:25:27,251 iteration 2011 : loss : 0.060361, loss_ce: 0.017931
2022-01-16 00:25:28,716 iteration 2012 : loss : 0.028608, loss_ce: 0.011403
2022-01-16 00:25:30,182 iteration 2013 : loss : 0.044513, loss_ce: 0.023548
2022-01-16 00:25:31,679 iteration 2014 : loss : 0.025791, loss_ce: 0.010541
2022-01-16 00:25:33,201 iteration 2015 : loss : 0.040439, loss_ce: 0.013232
2022-01-16 00:25:34,696 iteration 2016 : loss : 0.049171, loss_ce: 0.020366
2022-01-16 00:25:36,107 iteration 2017 : loss : 0.037478, loss_ce: 0.014068
2022-01-16 00:25:37,398 iteration 2018 : loss : 0.037971, loss_ce: 0.012735
2022-01-16 00:25:38,720 iteration 2019 : loss : 0.030257, loss_ce: 0.010522
2022-01-16 00:25:40,015 iteration 2020 : loss : 0.034832, loss_ce: 0.012430
2022-01-16 00:25:41,265 iteration 2021 : loss : 0.025486, loss_ce: 0.010528
2022-01-16 00:25:42,530 iteration 2022 : loss : 0.040275, loss_ce: 0.015823
2022-01-16 00:25:43,803 iteration 2023 : loss : 0.031787, loss_ce: 0.010047
 30%|████████▋                    | 119/400 [46:32<2:00:15, 25.68s/it]2022-01-16 00:25:45,156 iteration 2024 : loss : 0.051876, loss_ce: 0.023521
2022-01-16 00:25:46,574 iteration 2025 : loss : 0.053465, loss_ce: 0.019309
2022-01-16 00:25:47,794 iteration 2026 : loss : 0.033326, loss_ce: 0.010313
2022-01-16 00:25:49,078 iteration 2027 : loss : 0.030156, loss_ce: 0.010555
2022-01-16 00:25:50,250 iteration 2028 : loss : 0.036134, loss_ce: 0.016389
2022-01-16 00:25:51,466 iteration 2029 : loss : 0.043402, loss_ce: 0.011301
2022-01-16 00:25:52,731 iteration 2030 : loss : 0.031525, loss_ce: 0.010146
2022-01-16 00:25:53,973 iteration 2031 : loss : 0.035008, loss_ce: 0.012748
2022-01-16 00:25:55,163 iteration 2032 : loss : 0.036378, loss_ce: 0.016365
2022-01-16 00:25:56,237 iteration 2033 : loss : 0.026332, loss_ce: 0.010783
2022-01-16 00:25:57,337 iteration 2034 : loss : 0.028646, loss_ce: 0.008945
2022-01-16 00:25:58,489 iteration 2035 : loss : 0.038399, loss_ce: 0.015004
2022-01-16 00:25:59,560 iteration 2036 : loss : 0.037040, loss_ce: 0.015753
2022-01-16 00:26:00,594 iteration 2037 : loss : 0.032861, loss_ce: 0.013853
2022-01-16 00:26:01,749 iteration 2038 : loss : 0.088313, loss_ce: 0.027388
2022-01-16 00:26:02,820 iteration 2039 : loss : 0.035452, loss_ce: 0.011117
2022-01-16 00:26:02,820 Training Data Eval:
2022-01-16 00:26:07,689   Average segmentation loss on training set: 0.0309
2022-01-16 00:26:07,690 Validation Data Eval:
2022-01-16 00:26:09,368   Average segmentation loss on validation set: 0.2022
2022-01-16 00:26:10,444 iteration 2040 : loss : 0.041292, loss_ce: 0.019501
 30%|████████▋                    | 120/400 [46:58<2:01:10, 25.97s/it]2022-01-16 00:26:11,483 iteration 2041 : loss : 0.027525, loss_ce: 0.011767
2022-01-16 00:26:12,516 iteration 2042 : loss : 0.037814, loss_ce: 0.012590
2022-01-16 00:26:13,543 iteration 2043 : loss : 0.026693, loss_ce: 0.009864
2022-01-16 00:26:14,531 iteration 2044 : loss : 0.038652, loss_ce: 0.018870
2022-01-16 00:26:15,641 iteration 2045 : loss : 0.038701, loss_ce: 0.013747
2022-01-16 00:26:16,675 iteration 2046 : loss : 0.038550, loss_ce: 0.009420
2022-01-16 00:26:17,659 iteration 2047 : loss : 0.039049, loss_ce: 0.013671
2022-01-16 00:26:18,604 iteration 2048 : loss : 0.033545, loss_ce: 0.012277
2022-01-16 00:26:19,668 iteration 2049 : loss : 0.050178, loss_ce: 0.023354
2022-01-16 00:26:20,721 iteration 2050 : loss : 0.051918, loss_ce: 0.013746
2022-01-16 00:26:21,703 iteration 2051 : loss : 0.033723, loss_ce: 0.014633
2022-01-16 00:26:22,765 iteration 2052 : loss : 0.037256, loss_ce: 0.015416
2022-01-16 00:26:23,787 iteration 2053 : loss : 0.037562, loss_ce: 0.015395
2022-01-16 00:26:24,790 iteration 2054 : loss : 0.039028, loss_ce: 0.013650
2022-01-16 00:26:25,817 iteration 2055 : loss : 0.047137, loss_ce: 0.017096
2022-01-16 00:26:26,794 iteration 2056 : loss : 0.034588, loss_ce: 0.012188
2022-01-16 00:26:27,769 iteration 2057 : loss : 0.035999, loss_ce: 0.013986
 30%|████████▊                    | 121/400 [47:16<1:48:41, 23.37s/it]2022-01-16 00:26:28,823 iteration 2058 : loss : 0.044401, loss_ce: 0.020706
2022-01-16 00:26:29,878 iteration 2059 : loss : 0.050157, loss_ce: 0.019113
2022-01-16 00:26:30,959 iteration 2060 : loss : 0.034433, loss_ce: 0.012276
2022-01-16 00:26:31,966 iteration 2061 : loss : 0.034724, loss_ce: 0.015125
2022-01-16 00:26:32,921 iteration 2062 : loss : 0.049564, loss_ce: 0.018887
2022-01-16 00:26:34,085 iteration 2063 : loss : 0.035307, loss_ce: 0.013415
2022-01-16 00:26:35,107 iteration 2064 : loss : 0.052175, loss_ce: 0.018519
2022-01-16 00:26:36,190 iteration 2065 : loss : 0.039485, loss_ce: 0.013697
2022-01-16 00:26:37,190 iteration 2066 : loss : 0.040092, loss_ce: 0.017895
2022-01-16 00:26:38,263 iteration 2067 : loss : 0.040596, loss_ce: 0.014607
2022-01-16 00:26:39,222 iteration 2068 : loss : 0.030000, loss_ce: 0.010525
2022-01-16 00:26:40,245 iteration 2069 : loss : 0.043361, loss_ce: 0.017792
2022-01-16 00:26:41,305 iteration 2070 : loss : 0.052496, loss_ce: 0.021351
2022-01-16 00:26:42,272 iteration 2071 : loss : 0.026727, loss_ce: 0.010798
2022-01-16 00:26:43,238 iteration 2072 : loss : 0.039393, loss_ce: 0.018450
2022-01-16 00:26:44,295 iteration 2073 : loss : 0.055622, loss_ce: 0.025377
2022-01-16 00:26:45,239 iteration 2074 : loss : 0.034876, loss_ce: 0.010987
 30%|████████▊                    | 122/400 [47:33<1:40:05, 21.60s/it]2022-01-16 00:26:46,298 iteration 2075 : loss : 0.035264, loss_ce: 0.015840
2022-01-16 00:26:47,342 iteration 2076 : loss : 0.037370, loss_ce: 0.014742
2022-01-16 00:26:48,385 iteration 2077 : loss : 0.042542, loss_ce: 0.018434
2022-01-16 00:26:49,446 iteration 2078 : loss : 0.035842, loss_ce: 0.013165
2022-01-16 00:26:50,494 iteration 2079 : loss : 0.036010, loss_ce: 0.013492
2022-01-16 00:26:51,466 iteration 2080 : loss : 0.042892, loss_ce: 0.015551
2022-01-16 00:26:52,411 iteration 2081 : loss : 0.029519, loss_ce: 0.011134
2022-01-16 00:26:53,414 iteration 2082 : loss : 0.044760, loss_ce: 0.013457
2022-01-16 00:26:54,404 iteration 2083 : loss : 0.056111, loss_ce: 0.019765
2022-01-16 00:26:55,349 iteration 2084 : loss : 0.037847, loss_ce: 0.018689
2022-01-16 00:26:56,377 iteration 2085 : loss : 0.056353, loss_ce: 0.010002
2022-01-16 00:26:57,485 iteration 2086 : loss : 0.045505, loss_ce: 0.015011
2022-01-16 00:26:58,423 iteration 2087 : loss : 0.038339, loss_ce: 0.011344
2022-01-16 00:26:59,414 iteration 2088 : loss : 0.044686, loss_ce: 0.016428
2022-01-16 00:27:00,439 iteration 2089 : loss : 0.030440, loss_ce: 0.012332
2022-01-16 00:27:01,475 iteration 2090 : loss : 0.062775, loss_ce: 0.034548
2022-01-16 00:27:02,575 iteration 2091 : loss : 0.052885, loss_ce: 0.021313
 31%|████████▉                    | 123/400 [47:50<1:33:49, 20.32s/it]2022-01-16 00:27:03,621 iteration 2092 : loss : 0.040154, loss_ce: 0.014010
2022-01-16 00:27:04,565 iteration 2093 : loss : 0.026831, loss_ce: 0.011154
2022-01-16 00:27:05,605 iteration 2094 : loss : 0.036538, loss_ce: 0.014024
2022-01-16 00:27:06,782 iteration 2095 : loss : 0.048907, loss_ce: 0.018448
2022-01-16 00:27:07,788 iteration 2096 : loss : 0.034046, loss_ce: 0.015711
2022-01-16 00:27:08,781 iteration 2097 : loss : 0.073057, loss_ce: 0.019472
2022-01-16 00:27:09,726 iteration 2098 : loss : 0.036636, loss_ce: 0.013135
2022-01-16 00:27:10,714 iteration 2099 : loss : 0.030662, loss_ce: 0.012601
2022-01-16 00:27:11,763 iteration 2100 : loss : 0.036885, loss_ce: 0.012672
2022-01-16 00:27:12,681 iteration 2101 : loss : 0.036491, loss_ce: 0.011359
2022-01-16 00:27:13,719 iteration 2102 : loss : 0.045656, loss_ce: 0.019576
2022-01-16 00:27:14,683 iteration 2103 : loss : 0.045075, loss_ce: 0.022384
2022-01-16 00:27:15,610 iteration 2104 : loss : 0.033761, loss_ce: 0.011688
2022-01-16 00:27:16,637 iteration 2105 : loss : 0.047735, loss_ce: 0.021049
2022-01-16 00:27:17,667 iteration 2106 : loss : 0.039801, loss_ce: 0.015459
2022-01-16 00:27:18,658 iteration 2107 : loss : 0.039667, loss_ce: 0.014655
2022-01-16 00:27:19,656 iteration 2108 : loss : 0.031459, loss_ce: 0.012998
 31%|████████▉                    | 124/400 [48:07<1:29:01, 19.35s/it]2022-01-16 00:27:20,773 iteration 2109 : loss : 0.070516, loss_ce: 0.023968
2022-01-16 00:27:21,845 iteration 2110 : loss : 0.046767, loss_ce: 0.022497
2022-01-16 00:27:23,010 iteration 2111 : loss : 0.035411, loss_ce: 0.013490
2022-01-16 00:27:24,259 iteration 2112 : loss : 0.035529, loss_ce: 0.014565
2022-01-16 00:27:25,470 iteration 2113 : loss : 0.035028, loss_ce: 0.011872
2022-01-16 00:27:26,699 iteration 2114 : loss : 0.036850, loss_ce: 0.010902
2022-01-16 00:27:27,894 iteration 2115 : loss : 0.025690, loss_ce: 0.007932
2022-01-16 00:27:29,128 iteration 2116 : loss : 0.039924, loss_ce: 0.014239
2022-01-16 00:27:30,532 iteration 2117 : loss : 0.035495, loss_ce: 0.011094
2022-01-16 00:27:31,876 iteration 2118 : loss : 0.035982, loss_ce: 0.014770
2022-01-16 00:27:33,367 iteration 2119 : loss : 0.058598, loss_ce: 0.028779
2022-01-16 00:27:34,849 iteration 2120 : loss : 0.034719, loss_ce: 0.018616
2022-01-16 00:27:36,397 iteration 2121 : loss : 0.052813, loss_ce: 0.023593
2022-01-16 00:27:37,960 iteration 2122 : loss : 0.056000, loss_ce: 0.027608
2022-01-16 00:27:39,395 iteration 2123 : loss : 0.041262, loss_ce: 0.012787
2022-01-16 00:27:40,947 iteration 2124 : loss : 0.043167, loss_ce: 0.016836
2022-01-16 00:27:40,947 Training Data Eval:
2022-01-16 00:27:48,411   Average segmentation loss on training set: 0.0397
2022-01-16 00:27:48,411 Validation Data Eval:
2022-01-16 00:27:51,058   Average segmentation loss on validation set: 0.0679
2022-01-16 00:27:51,938 Found new lowest validation loss at iteration 2124! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed2.pth
2022-01-16 00:27:53,340 iteration 2125 : loss : 0.038709, loss_ce: 0.017307
 31%|█████████                    | 125/400 [48:41<1:48:24, 23.65s/it]2022-01-16 00:27:54,856 iteration 2126 : loss : 0.071542, loss_ce: 0.022566
2022-01-16 00:27:56,209 iteration 2127 : loss : 0.030685, loss_ce: 0.013339
2022-01-16 00:27:57,581 iteration 2128 : loss : 0.027926, loss_ce: 0.012556
2022-01-16 00:27:59,134 iteration 2129 : loss : 0.046521, loss_ce: 0.019321
2022-01-16 00:28:00,550 iteration 2130 : loss : 0.045310, loss_ce: 0.018674
2022-01-16 00:28:01,905 iteration 2131 : loss : 0.035935, loss_ce: 0.013603
2022-01-16 00:28:03,325 iteration 2132 : loss : 0.044022, loss_ce: 0.012492
2022-01-16 00:28:04,727 iteration 2133 : loss : 0.028175, loss_ce: 0.011460
2022-01-16 00:28:06,170 iteration 2134 : loss : 0.051852, loss_ce: 0.017582
2022-01-16 00:28:07,493 iteration 2135 : loss : 0.038731, loss_ce: 0.011182
2022-01-16 00:28:08,955 iteration 2136 : loss : 0.032831, loss_ce: 0.013451
2022-01-16 00:28:10,411 iteration 2137 : loss : 0.034250, loss_ce: 0.014855
2022-01-16 00:28:12,002 iteration 2138 : loss : 0.038265, loss_ce: 0.010153
2022-01-16 00:28:13,429 iteration 2139 : loss : 0.037704, loss_ce: 0.018294
2022-01-16 00:28:14,863 iteration 2140 : loss : 0.061641, loss_ce: 0.041085
2022-01-16 00:28:16,234 iteration 2141 : loss : 0.030448, loss_ce: 0.009995
2022-01-16 00:28:17,588 iteration 2142 : loss : 0.049672, loss_ce: 0.016907
 32%|█████████▏                   | 126/400 [49:05<1:48:49, 23.83s/it]2022-01-16 00:28:18,948 iteration 2143 : loss : 0.045629, loss_ce: 0.023519
2022-01-16 00:28:20,272 iteration 2144 : loss : 0.041506, loss_ce: 0.016344
2022-01-16 00:28:21,623 iteration 2145 : loss : 0.029210, loss_ce: 0.011030
2022-01-16 00:28:22,964 iteration 2146 : loss : 0.042808, loss_ce: 0.017442
2022-01-16 00:28:24,299 iteration 2147 : loss : 0.025715, loss_ce: 0.010485
2022-01-16 00:28:25,716 iteration 2148 : loss : 0.031260, loss_ce: 0.012643
2022-01-16 00:28:27,231 iteration 2149 : loss : 0.045135, loss_ce: 0.017891
2022-01-16 00:28:28,635 iteration 2150 : loss : 0.031220, loss_ce: 0.012720
2022-01-16 00:28:30,088 iteration 2151 : loss : 0.031115, loss_ce: 0.011185
2022-01-16 00:28:31,468 iteration 2152 : loss : 0.034383, loss_ce: 0.016113
2022-01-16 00:28:32,846 iteration 2153 : loss : 0.047370, loss_ce: 0.013578
2022-01-16 00:28:34,202 iteration 2154 : loss : 0.025509, loss_ce: 0.008968
2022-01-16 00:28:35,569 iteration 2155 : loss : 0.032860, loss_ce: 0.016810
2022-01-16 00:28:36,835 iteration 2156 : loss : 0.031363, loss_ce: 0.011880
2022-01-16 00:28:38,230 iteration 2157 : loss : 0.045737, loss_ce: 0.021035
2022-01-16 00:28:39,581 iteration 2158 : loss : 0.038338, loss_ce: 0.013387
2022-01-16 00:28:40,865 iteration 2159 : loss : 0.035026, loss_ce: 0.013078
 32%|█████████▏                   | 127/400 [49:29<1:47:39, 23.66s/it]2022-01-16 00:28:42,187 iteration 2160 : loss : 0.039187, loss_ce: 0.014714
2022-01-16 00:28:43,551 iteration 2161 : loss : 0.059988, loss_ce: 0.029179
2022-01-16 00:28:44,907 iteration 2162 : loss : 0.031013, loss_ce: 0.011529
2022-01-16 00:28:46,225 iteration 2163 : loss : 0.034423, loss_ce: 0.011254
2022-01-16 00:28:47,680 iteration 2164 : loss : 0.045142, loss_ce: 0.016290
2022-01-16 00:28:49,188 iteration 2165 : loss : 0.029429, loss_ce: 0.012155
2022-01-16 00:28:50,770 iteration 2166 : loss : 0.042007, loss_ce: 0.011478
2022-01-16 00:28:52,410 iteration 2167 : loss : 0.029538, loss_ce: 0.009465
2022-01-16 00:28:53,986 iteration 2168 : loss : 0.034311, loss_ce: 0.014290
2022-01-16 00:28:55,498 iteration 2169 : loss : 0.036264, loss_ce: 0.014341
2022-01-16 00:28:57,050 iteration 2170 : loss : 0.050379, loss_ce: 0.023056
2022-01-16 00:28:58,606 iteration 2171 : loss : 0.048876, loss_ce: 0.019368
2022-01-16 00:29:00,223 iteration 2172 : loss : 0.042218, loss_ce: 0.011398
2022-01-16 00:29:01,679 iteration 2173 : loss : 0.046488, loss_ce: 0.015414
2022-01-16 00:29:03,274 iteration 2174 : loss : 0.030513, loss_ce: 0.014285
2022-01-16 00:29:04,803 iteration 2175 : loss : 0.029194, loss_ce: 0.010053
2022-01-16 00:29:06,531 iteration 2176 : loss : 0.045833, loss_ce: 0.018594
 32%|█████████▎                   | 128/400 [49:54<1:50:00, 24.27s/it]2022-01-16 00:29:08,203 iteration 2177 : loss : 0.045006, loss_ce: 0.016894
2022-01-16 00:29:09,841 iteration 2178 : loss : 0.032775, loss_ce: 0.013675
2022-01-16 00:29:11,391 iteration 2179 : loss : 0.029784, loss_ce: 0.014368
2022-01-16 00:29:12,954 iteration 2180 : loss : 0.029339, loss_ce: 0.011110
2022-01-16 00:29:14,506 iteration 2181 : loss : 0.036467, loss_ce: 0.015729
2022-01-16 00:29:16,022 iteration 2182 : loss : 0.054777, loss_ce: 0.013261
2022-01-16 00:29:17,468 iteration 2183 : loss : 0.042924, loss_ce: 0.024838
2022-01-16 00:29:19,044 iteration 2184 : loss : 0.041710, loss_ce: 0.011477
2022-01-16 00:29:20,605 iteration 2185 : loss : 0.028909, loss_ce: 0.010195
2022-01-16 00:29:22,112 iteration 2186 : loss : 0.044401, loss_ce: 0.015892
2022-01-16 00:29:23,616 iteration 2187 : loss : 0.026277, loss_ce: 0.009576
2022-01-16 00:29:25,109 iteration 2188 : loss : 0.050834, loss_ce: 0.013888
2022-01-16 00:29:26,680 iteration 2189 : loss : 0.050140, loss_ce: 0.015564
2022-01-16 00:29:28,168 iteration 2190 : loss : 0.040897, loss_ce: 0.013145
2022-01-16 00:29:29,658 iteration 2191 : loss : 0.081855, loss_ce: 0.023532
2022-01-16 00:29:31,109 iteration 2192 : loss : 0.033063, loss_ce: 0.010989
2022-01-16 00:29:32,572 iteration 2193 : loss : 0.043218, loss_ce: 0.016577
 32%|█████████▎                   | 129/400 [50:20<1:52:00, 24.80s/it]2022-01-16 00:29:34,089 iteration 2194 : loss : 0.055214, loss_ce: 0.026497
2022-01-16 00:29:35,456 iteration 2195 : loss : 0.049456, loss_ce: 0.016975
2022-01-16 00:29:36,809 iteration 2196 : loss : 0.043409, loss_ce: 0.014780
2022-01-16 00:29:38,180 iteration 2197 : loss : 0.036691, loss_ce: 0.018321
2022-01-16 00:29:39,516 iteration 2198 : loss : 0.040632, loss_ce: 0.018938
2022-01-16 00:29:40,847 iteration 2199 : loss : 0.045406, loss_ce: 0.019140
2022-01-16 00:29:42,161 iteration 2200 : loss : 0.049897, loss_ce: 0.019606
2022-01-16 00:29:43,471 iteration 2201 : loss : 0.030416, loss_ce: 0.011887
2022-01-16 00:29:44,905 iteration 2202 : loss : 0.088621, loss_ce: 0.022406
2022-01-16 00:29:46,312 iteration 2203 : loss : 0.060621, loss_ce: 0.034752
2022-01-16 00:29:47,648 iteration 2204 : loss : 0.058919, loss_ce: 0.029050
2022-01-16 00:29:48,961 iteration 2205 : loss : 0.029906, loss_ce: 0.011986
2022-01-16 00:29:50,328 iteration 2206 : loss : 0.044328, loss_ce: 0.013359
2022-01-16 00:29:51,731 iteration 2207 : loss : 0.054134, loss_ce: 0.017721
2022-01-16 00:29:53,202 iteration 2208 : loss : 0.033703, loss_ce: 0.010311
2022-01-16 00:29:54,664 iteration 2209 : loss : 0.039322, loss_ce: 0.013083
2022-01-16 00:29:54,664 Training Data Eval:
2022-01-16 00:30:02,176   Average segmentation loss on training set: 0.0266
2022-01-16 00:30:02,176 Validation Data Eval:
2022-01-16 00:30:04,781   Average segmentation loss on validation set: 0.0817
2022-01-16 00:30:06,312 iteration 2210 : loss : 0.061851, loss_ce: 0.025814
 32%|█████████▍                   | 130/400 [50:54<2:03:39, 27.48s/it]2022-01-16 00:30:07,889 iteration 2211 : loss : 0.078842, loss_ce: 0.034826
2022-01-16 00:30:09,367 iteration 2212 : loss : 0.032431, loss_ce: 0.013655
2022-01-16 00:30:10,885 iteration 2213 : loss : 0.040542, loss_ce: 0.015571
2022-01-16 00:30:12,394 iteration 2214 : loss : 0.045230, loss_ce: 0.017591
2022-01-16 00:30:13,941 iteration 2215 : loss : 0.056092, loss_ce: 0.026230
2022-01-16 00:30:15,390 iteration 2216 : loss : 0.044726, loss_ce: 0.016985
2022-01-16 00:30:17,096 iteration 2217 : loss : 0.057846, loss_ce: 0.029110
2022-01-16 00:30:18,656 iteration 2218 : loss : 0.057719, loss_ce: 0.028160
2022-01-16 00:30:20,306 iteration 2219 : loss : 0.035753, loss_ce: 0.014944
2022-01-16 00:30:21,805 iteration 2220 : loss : 0.045612, loss_ce: 0.015413
2022-01-16 00:30:23,426 iteration 2221 : loss : 0.036522, loss_ce: 0.014282
2022-01-16 00:30:24,977 iteration 2222 : loss : 0.038197, loss_ce: 0.016578
2022-01-16 00:30:26,487 iteration 2223 : loss : 0.068123, loss_ce: 0.020942
2022-01-16 00:30:28,109 iteration 2224 : loss : 0.069543, loss_ce: 0.038337
2022-01-16 00:30:29,626 iteration 2225 : loss : 0.024741, loss_ce: 0.009864
2022-01-16 00:30:31,332 iteration 2226 : loss : 0.044151, loss_ce: 0.019679
2022-01-16 00:30:33,001 iteration 2227 : loss : 0.032269, loss_ce: 0.013501
 33%|█████████▍                   | 131/400 [51:21<2:02:08, 27.24s/it]2022-01-16 00:30:34,628 iteration 2228 : loss : 0.026880, loss_ce: 0.012093
2022-01-16 00:30:36,221 iteration 2229 : loss : 0.043380, loss_ce: 0.019472
2022-01-16 00:30:37,839 iteration 2230 : loss : 0.035283, loss_ce: 0.011006
2022-01-16 00:30:39,306 iteration 2231 : loss : 0.022927, loss_ce: 0.009571
2022-01-16 00:30:40,796 iteration 2232 : loss : 0.039599, loss_ce: 0.015009
2022-01-16 00:30:42,485 iteration 2233 : loss : 0.036442, loss_ce: 0.013118
2022-01-16 00:30:44,045 iteration 2234 : loss : 0.039143, loss_ce: 0.013722
2022-01-16 00:30:45,551 iteration 2235 : loss : 0.058424, loss_ce: 0.012681
2022-01-16 00:30:47,176 iteration 2236 : loss : 0.046034, loss_ce: 0.021006
2022-01-16 00:30:48,688 iteration 2237 : loss : 0.028880, loss_ce: 0.012431
2022-01-16 00:30:50,271 iteration 2238 : loss : 0.036400, loss_ce: 0.018135
2022-01-16 00:30:51,804 iteration 2239 : loss : 0.032343, loss_ce: 0.010476
2022-01-16 00:30:53,364 iteration 2240 : loss : 0.042201, loss_ce: 0.014812
2022-01-16 00:30:54,937 iteration 2241 : loss : 0.035767, loss_ce: 0.009539
2022-01-16 00:30:56,620 iteration 2242 : loss : 0.024956, loss_ce: 0.009558
2022-01-16 00:30:58,244 iteration 2243 : loss : 0.042591, loss_ce: 0.010855
2022-01-16 00:30:59,825 iteration 2244 : loss : 0.040949, loss_ce: 0.016100
 33%|█████████▌                   | 132/400 [51:48<2:01:07, 27.12s/it]2022-01-16 00:31:01,493 iteration 2245 : loss : 0.046607, loss_ce: 0.015483
2022-01-16 00:31:02,974 iteration 2246 : loss : 0.029183, loss_ce: 0.012965
2022-01-16 00:31:04,557 iteration 2247 : loss : 0.069945, loss_ce: 0.015801
2022-01-16 00:31:06,072 iteration 2248 : loss : 0.044917, loss_ce: 0.021304
2022-01-16 00:31:07,590 iteration 2249 : loss : 0.036122, loss_ce: 0.011335
2022-01-16 00:31:09,027 iteration 2250 : loss : 0.041991, loss_ce: 0.018967
2022-01-16 00:31:10,424 iteration 2251 : loss : 0.031379, loss_ce: 0.010806
2022-01-16 00:31:12,021 iteration 2252 : loss : 0.083810, loss_ce: 0.026334
2022-01-16 00:31:13,603 iteration 2253 : loss : 0.048389, loss_ce: 0.024988
2022-01-16 00:31:15,092 iteration 2254 : loss : 0.033346, loss_ce: 0.014588
2022-01-16 00:31:16,614 iteration 2255 : loss : 0.033160, loss_ce: 0.010525
2022-01-16 00:31:18,211 iteration 2256 : loss : 0.037765, loss_ce: 0.014658
2022-01-16 00:31:19,774 iteration 2257 : loss : 0.033944, loss_ce: 0.013680
2022-01-16 00:31:21,297 iteration 2258 : loss : 0.030854, loss_ce: 0.013368
2022-01-16 00:31:22,956 iteration 2259 : loss : 0.028267, loss_ce: 0.010141
2022-01-16 00:31:24,473 iteration 2260 : loss : 0.038794, loss_ce: 0.016074
2022-01-16 00:31:26,029 iteration 2261 : loss : 0.049699, loss_ce: 0.026265
 33%|█████████▋                   | 133/400 [52:14<1:59:26, 26.84s/it]2022-01-16 00:31:27,628 iteration 2262 : loss : 0.045615, loss_ce: 0.020037
2022-01-16 00:31:29,166 iteration 2263 : loss : 0.038066, loss_ce: 0.016224
2022-01-16 00:31:30,708 iteration 2264 : loss : 0.051224, loss_ce: 0.017879
2022-01-16 00:31:32,219 iteration 2265 : loss : 0.033357, loss_ce: 0.011984
2022-01-16 00:31:33,736 iteration 2266 : loss : 0.065716, loss_ce: 0.023188
2022-01-16 00:31:35,172 iteration 2267 : loss : 0.027223, loss_ce: 0.010940
2022-01-16 00:31:36,625 iteration 2268 : loss : 0.038733, loss_ce: 0.015930
2022-01-16 00:31:38,077 iteration 2269 : loss : 0.048035, loss_ce: 0.021537
2022-01-16 00:31:39,523 iteration 2270 : loss : 0.026619, loss_ce: 0.009907
2022-01-16 00:31:41,003 iteration 2271 : loss : 0.051296, loss_ce: 0.016625
2022-01-16 00:31:42,562 iteration 2272 : loss : 0.035679, loss_ce: 0.012949
2022-01-16 00:31:44,083 iteration 2273 : loss : 0.029571, loss_ce: 0.011141
2022-01-16 00:31:45,611 iteration 2274 : loss : 0.037837, loss_ce: 0.015109
2022-01-16 00:31:47,175 iteration 2275 : loss : 0.054079, loss_ce: 0.017607
2022-01-16 00:31:48,686 iteration 2276 : loss : 0.049799, loss_ce: 0.019573
2022-01-16 00:31:50,179 iteration 2277 : loss : 0.033420, loss_ce: 0.008818
2022-01-16 00:31:51,780 iteration 2278 : loss : 0.043454, loss_ce: 0.014721
 34%|█████████▋                   | 134/400 [52:40<1:57:33, 26.52s/it]2022-01-16 00:31:53,347 iteration 2279 : loss : 0.029172, loss_ce: 0.010885
2022-01-16 00:31:54,870 iteration 2280 : loss : 0.035582, loss_ce: 0.015979
2022-01-16 00:31:56,370 iteration 2281 : loss : 0.043953, loss_ce: 0.015514
2022-01-16 00:31:57,784 iteration 2282 : loss : 0.046284, loss_ce: 0.016473
2022-01-16 00:31:59,250 iteration 2283 : loss : 0.038476, loss_ce: 0.010320
2022-01-16 00:32:00,605 iteration 2284 : loss : 0.030717, loss_ce: 0.014014
2022-01-16 00:32:02,044 iteration 2285 : loss : 0.046409, loss_ce: 0.021564
2022-01-16 00:32:03,404 iteration 2286 : loss : 0.040219, loss_ce: 0.019024
2022-01-16 00:32:04,764 iteration 2287 : loss : 0.033660, loss_ce: 0.008378
2022-01-16 00:32:06,142 iteration 2288 : loss : 0.068113, loss_ce: 0.017210
2022-01-16 00:32:07,522 iteration 2289 : loss : 0.033263, loss_ce: 0.009800
2022-01-16 00:32:08,862 iteration 2290 : loss : 0.037877, loss_ce: 0.013799
2022-01-16 00:32:10,281 iteration 2291 : loss : 0.049310, loss_ce: 0.017716
2022-01-16 00:32:11,616 iteration 2292 : loss : 0.030965, loss_ce: 0.011209
2022-01-16 00:32:12,895 iteration 2293 : loss : 0.059411, loss_ce: 0.021992
2022-01-16 00:32:14,128 iteration 2294 : loss : 0.036918, loss_ce: 0.018681
2022-01-16 00:32:14,128 Training Data Eval:
2022-01-16 00:32:21,107   Average segmentation loss on training set: 0.0283
2022-01-16 00:32:21,107 Validation Data Eval:
2022-01-16 00:32:23,918   Average segmentation loss on validation set: 0.0748
2022-01-16 00:32:25,426 iteration 2295 : loss : 0.052704, loss_ce: 0.015160
 34%|█████████▊                   | 135/400 [53:13<2:06:33, 28.65s/it]2022-01-16 00:32:27,002 iteration 2296 : loss : 0.033242, loss_ce: 0.011770
2022-01-16 00:32:28,561 iteration 2297 : loss : 0.030098, loss_ce: 0.010315
2022-01-16 00:32:30,078 iteration 2298 : loss : 0.029539, loss_ce: 0.009945
2022-01-16 00:32:31,645 iteration 2299 : loss : 0.075554, loss_ce: 0.023708
2022-01-16 00:32:33,274 iteration 2300 : loss : 0.026643, loss_ce: 0.010649
2022-01-16 00:32:34,829 iteration 2301 : loss : 0.038712, loss_ce: 0.014856
2022-01-16 00:32:36,398 iteration 2302 : loss : 0.038330, loss_ce: 0.012183
2022-01-16 00:32:37,944 iteration 2303 : loss : 0.051808, loss_ce: 0.015806
2022-01-16 00:32:39,486 iteration 2304 : loss : 0.037796, loss_ce: 0.014552
2022-01-16 00:32:40,988 iteration 2305 : loss : 0.036589, loss_ce: 0.016754
2022-01-16 00:32:42,529 iteration 2306 : loss : 0.036703, loss_ce: 0.013656
2022-01-16 00:32:44,105 iteration 2307 : loss : 0.056045, loss_ce: 0.026727
2022-01-16 00:32:45,555 iteration 2308 : loss : 0.030319, loss_ce: 0.012242
2022-01-16 00:32:47,036 iteration 2309 : loss : 0.037299, loss_ce: 0.016564
2022-01-16 00:32:48,471 iteration 2310 : loss : 0.042882, loss_ce: 0.017358
2022-01-16 00:32:49,857 iteration 2311 : loss : 0.045534, loss_ce: 0.015412
2022-01-16 00:32:51,235 iteration 2312 : loss : 0.034574, loss_ce: 0.012786
 34%|█████████▊                   | 136/400 [53:39<2:02:20, 27.80s/it]2022-01-16 00:32:52,743 iteration 2313 : loss : 0.039058, loss_ce: 0.013474
2022-01-16 00:32:54,174 iteration 2314 : loss : 0.036650, loss_ce: 0.011124
2022-01-16 00:32:55,651 iteration 2315 : loss : 0.048339, loss_ce: 0.011985
2022-01-16 00:32:57,013 iteration 2316 : loss : 0.032750, loss_ce: 0.012107
2022-01-16 00:32:58,544 iteration 2317 : loss : 0.049663, loss_ce: 0.013305
2022-01-16 00:32:59,995 iteration 2318 : loss : 0.035923, loss_ce: 0.016479
2022-01-16 00:33:01,405 iteration 2319 : loss : 0.052736, loss_ce: 0.024622
2022-01-16 00:33:02,906 iteration 2320 : loss : 0.047579, loss_ce: 0.024718
2022-01-16 00:33:04,428 iteration 2321 : loss : 0.035124, loss_ce: 0.010374
2022-01-16 00:33:06,005 iteration 2322 : loss : 0.042384, loss_ce: 0.020623
2022-01-16 00:33:07,579 iteration 2323 : loss : 0.035620, loss_ce: 0.016457
2022-01-16 00:33:09,134 iteration 2324 : loss : 0.041683, loss_ce: 0.016196
2022-01-16 00:33:10,618 iteration 2325 : loss : 0.030666, loss_ce: 0.011735
2022-01-16 00:33:12,139 iteration 2326 : loss : 0.044248, loss_ce: 0.023702
2022-01-16 00:33:13,617 iteration 2327 : loss : 0.034691, loss_ce: 0.012906
2022-01-16 00:33:15,197 iteration 2328 : loss : 0.055860, loss_ce: 0.030152
2022-01-16 00:33:16,735 iteration 2329 : loss : 0.027536, loss_ce: 0.010633
 34%|█████████▉                   | 137/400 [54:05<1:58:49, 27.11s/it]2022-01-16 00:33:18,283 iteration 2330 : loss : 0.027050, loss_ce: 0.010466
2022-01-16 00:33:19,866 iteration 2331 : loss : 0.042087, loss_ce: 0.018859
2022-01-16 00:33:21,505 iteration 2332 : loss : 0.041167, loss_ce: 0.015250
2022-01-16 00:33:23,127 iteration 2333 : loss : 0.030423, loss_ce: 0.015149
2022-01-16 00:33:24,647 iteration 2334 : loss : 0.026504, loss_ce: 0.012380
2022-01-16 00:33:26,367 iteration 2335 : loss : 0.044425, loss_ce: 0.013560
2022-01-16 00:33:27,945 iteration 2336 : loss : 0.072419, loss_ce: 0.020149
2022-01-16 00:33:29,479 iteration 2337 : loss : 0.030089, loss_ce: 0.014650
2022-01-16 00:33:30,947 iteration 2338 : loss : 0.031869, loss_ce: 0.011977
2022-01-16 00:33:32,427 iteration 2339 : loss : 0.039082, loss_ce: 0.013613
2022-01-16 00:33:33,898 iteration 2340 : loss : 0.042461, loss_ce: 0.018018
2022-01-16 00:33:35,216 iteration 2341 : loss : 0.025257, loss_ce: 0.006493
2022-01-16 00:33:36,585 iteration 2342 : loss : 0.027288, loss_ce: 0.010585
2022-01-16 00:33:38,023 iteration 2343 : loss : 0.050906, loss_ce: 0.018870
2022-01-16 00:33:39,422 iteration 2344 : loss : 0.034779, loss_ce: 0.013830
2022-01-16 00:33:40,806 iteration 2345 : loss : 0.042387, loss_ce: 0.014923
2022-01-16 00:33:42,129 iteration 2346 : loss : 0.034539, loss_ce: 0.015180
 34%|██████████                   | 138/400 [54:30<1:56:07, 26.59s/it]2022-01-16 00:33:43,502 iteration 2347 : loss : 0.034496, loss_ce: 0.010990
2022-01-16 00:33:44,820 iteration 2348 : loss : 0.038611, loss_ce: 0.012759
2022-01-16 00:33:46,218 iteration 2349 : loss : 0.041864, loss_ce: 0.018452
2022-01-16 00:33:47,591 iteration 2350 : loss : 0.043110, loss_ce: 0.015914
2022-01-16 00:33:49,001 iteration 2351 : loss : 0.092371, loss_ce: 0.020718
2022-01-16 00:33:50,432 iteration 2352 : loss : 0.033735, loss_ce: 0.010066
2022-01-16 00:33:51,921 iteration 2353 : loss : 0.040814, loss_ce: 0.019582
2022-01-16 00:33:53,400 iteration 2354 : loss : 0.028559, loss_ce: 0.012259
2022-01-16 00:33:54,809 iteration 2355 : loss : 0.029038, loss_ce: 0.010928
2022-01-16 00:33:56,299 iteration 2356 : loss : 0.029485, loss_ce: 0.011620
2022-01-16 00:33:57,728 iteration 2357 : loss : 0.050605, loss_ce: 0.015446
2022-01-16 00:33:59,165 iteration 2358 : loss : 0.031190, loss_ce: 0.013406
2022-01-16 00:34:00,678 iteration 2359 : loss : 0.038675, loss_ce: 0.014665
2022-01-16 00:34:02,063 iteration 2360 : loss : 0.037076, loss_ce: 0.015552
2022-01-16 00:34:03,491 iteration 2361 : loss : 0.040079, loss_ce: 0.012966
2022-01-16 00:34:04,997 iteration 2362 : loss : 0.053750, loss_ce: 0.032205
2022-01-16 00:34:06,363 iteration 2363 : loss : 0.031857, loss_ce: 0.013916
 35%|██████████                   | 139/400 [54:54<1:52:36, 25.89s/it]2022-01-16 00:34:07,793 iteration 2364 : loss : 0.101995, loss_ce: 0.020813
2022-01-16 00:34:09,211 iteration 2365 : loss : 0.044284, loss_ce: 0.013173
2022-01-16 00:34:10,721 iteration 2366 : loss : 0.036031, loss_ce: 0.014058
2022-01-16 00:34:12,201 iteration 2367 : loss : 0.047464, loss_ce: 0.025849
2022-01-16 00:34:13,681 iteration 2368 : loss : 0.047722, loss_ce: 0.017564
2022-01-16 00:34:15,211 iteration 2369 : loss : 0.044203, loss_ce: 0.017529
2022-01-16 00:34:16,803 iteration 2370 : loss : 0.066468, loss_ce: 0.030506
2022-01-16 00:34:18,410 iteration 2371 : loss : 0.054646, loss_ce: 0.027064
2022-01-16 00:34:19,963 iteration 2372 : loss : 0.040271, loss_ce: 0.016848
2022-01-16 00:34:21,500 iteration 2373 : loss : 0.035747, loss_ce: 0.013473
2022-01-16 00:34:22,978 iteration 2374 : loss : 0.035770, loss_ce: 0.015098
2022-01-16 00:34:24,540 iteration 2375 : loss : 0.048303, loss_ce: 0.014291
2022-01-16 00:34:26,156 iteration 2376 : loss : 0.036205, loss_ce: 0.012583
2022-01-16 00:34:27,844 iteration 2377 : loss : 0.033338, loss_ce: 0.013546
2022-01-16 00:34:29,402 iteration 2378 : loss : 0.031820, loss_ce: 0.013867
2022-01-16 00:34:30,962 iteration 2379 : loss : 0.056093, loss_ce: 0.034903
2022-01-16 00:34:30,962 Training Data Eval:
2022-01-16 00:34:39,585   Average segmentation loss on training set: 0.0423
2022-01-16 00:34:39,586 Validation Data Eval:
2022-01-16 00:34:42,557   Average segmentation loss on validation set: 0.1634
2022-01-16 00:34:44,190 iteration 2380 : loss : 0.030952, loss_ce: 0.015905
 35%|██████████▏                  | 140/400 [55:32<2:07:42, 29.47s/it]2022-01-16 00:34:45,930 iteration 2381 : loss : 0.068899, loss_ce: 0.017147
2022-01-16 00:34:47,541 iteration 2382 : loss : 0.053466, loss_ce: 0.022039
2022-01-16 00:34:49,270 iteration 2383 : loss : 0.039727, loss_ce: 0.016862
2022-01-16 00:34:50,829 iteration 2384 : loss : 0.035114, loss_ce: 0.012426
2022-01-16 00:34:52,483 iteration 2385 : loss : 0.046075, loss_ce: 0.024055
2022-01-16 00:34:54,187 iteration 2386 : loss : 0.049465, loss_ce: 0.016149
2022-01-16 00:34:55,921 iteration 2387 : loss : 0.033399, loss_ce: 0.011127
2022-01-16 00:34:57,673 iteration 2388 : loss : 0.037317, loss_ce: 0.017134
2022-01-16 00:34:59,265 iteration 2389 : loss : 0.032348, loss_ce: 0.011816
2022-01-16 00:35:00,976 iteration 2390 : loss : 0.046194, loss_ce: 0.017432
2022-01-16 00:35:02,639 iteration 2391 : loss : 0.033489, loss_ce: 0.012534
2022-01-16 00:35:04,499 iteration 2392 : loss : 0.041900, loss_ce: 0.011884
2022-01-16 00:35:06,171 iteration 2393 : loss : 0.043948, loss_ce: 0.018604
2022-01-16 00:35:07,785 iteration 2394 : loss : 0.089084, loss_ce: 0.039008
2022-01-16 00:35:09,655 iteration 2395 : loss : 0.038536, loss_ce: 0.016604
2022-01-16 00:35:11,323 iteration 2396 : loss : 0.039751, loss_ce: 0.015814
2022-01-16 00:35:13,109 iteration 2397 : loss : 0.035034, loss_ce: 0.017393
 35%|██████████▏                  | 141/400 [56:01<2:06:30, 29.31s/it]2022-01-16 00:35:14,751 iteration 2398 : loss : 0.032662, loss_ce: 0.016172
2022-01-16 00:35:16,425 iteration 2399 : loss : 0.036509, loss_ce: 0.014874
2022-01-16 00:35:18,152 iteration 2400 : loss : 0.038623, loss_ce: 0.015946
2022-01-16 00:35:19,964 iteration 2401 : loss : 0.049646, loss_ce: 0.020241
2022-01-16 00:35:21,707 iteration 2402 : loss : 0.040291, loss_ce: 0.015488
2022-01-16 00:35:23,261 iteration 2403 : loss : 0.032372, loss_ce: 0.011927
2022-01-16 00:35:24,961 iteration 2404 : loss : 0.026541, loss_ce: 0.009249
2022-01-16 00:35:26,616 iteration 2405 : loss : 0.036846, loss_ce: 0.014105
2022-01-16 00:35:28,292 iteration 2406 : loss : 0.077814, loss_ce: 0.043431
2022-01-16 00:35:29,850 iteration 2407 : loss : 0.034940, loss_ce: 0.011629
2022-01-16 00:35:31,647 iteration 2408 : loss : 0.043243, loss_ce: 0.015056
2022-01-16 00:35:33,171 iteration 2409 : loss : 0.041622, loss_ce: 0.016184
2022-01-16 00:35:34,751 iteration 2410 : loss : 0.033243, loss_ce: 0.011246
2022-01-16 00:35:36,434 iteration 2411 : loss : 0.027131, loss_ce: 0.010132
2022-01-16 00:35:38,075 iteration 2412 : loss : 0.030157, loss_ce: 0.010659
2022-01-16 00:35:39,627 iteration 2413 : loss : 0.036359, loss_ce: 0.013921
2022-01-16 00:35:41,286 iteration 2414 : loss : 0.035777, loss_ce: 0.016496
 36%|██████████▎                  | 142/400 [56:29<2:04:33, 28.97s/it]2022-01-16 00:35:42,962 iteration 2415 : loss : 0.033489, loss_ce: 0.012182
2022-01-16 00:35:44,525 iteration 2416 : loss : 0.033664, loss_ce: 0.014080
2022-01-16 00:35:46,262 iteration 2417 : loss : 0.025597, loss_ce: 0.012832
2022-01-16 00:35:47,793 iteration 2418 : loss : 0.036544, loss_ce: 0.012746
2022-01-16 00:35:49,375 iteration 2419 : loss : 0.051765, loss_ce: 0.019025
2022-01-16 00:35:51,055 iteration 2420 : loss : 0.035171, loss_ce: 0.013746
2022-01-16 00:35:52,699 iteration 2421 : loss : 0.031372, loss_ce: 0.014456
2022-01-16 00:35:54,411 iteration 2422 : loss : 0.032772, loss_ce: 0.013527
2022-01-16 00:35:56,036 iteration 2423 : loss : 0.035903, loss_ce: 0.014468
2022-01-16 00:35:57,624 iteration 2424 : loss : 0.030141, loss_ce: 0.011519
2022-01-16 00:35:59,236 iteration 2425 : loss : 0.030083, loss_ce: 0.011191
2022-01-16 00:36:00,971 iteration 2426 : loss : 0.039980, loss_ce: 0.014539
2022-01-16 00:36:02,500 iteration 2427 : loss : 0.027183, loss_ce: 0.012935
2022-01-16 00:36:04,170 iteration 2428 : loss : 0.031881, loss_ce: 0.011320
2022-01-16 00:36:05,725 iteration 2429 : loss : 0.043397, loss_ce: 0.012887
2022-01-16 00:36:07,433 iteration 2430 : loss : 0.043770, loss_ce: 0.015837
2022-01-16 00:36:09,051 iteration 2431 : loss : 0.026280, loss_ce: 0.007810
 36%|██████████▎                  | 143/400 [56:57<2:02:31, 28.61s/it]2022-01-16 00:36:10,711 iteration 2432 : loss : 0.026476, loss_ce: 0.008654
2022-01-16 00:36:12,374 iteration 2433 : loss : 0.028372, loss_ce: 0.012395
2022-01-16 00:36:13,984 iteration 2434 : loss : 0.040442, loss_ce: 0.016032
2022-01-16 00:36:15,630 iteration 2435 : loss : 0.026520, loss_ce: 0.010815
2022-01-16 00:36:17,282 iteration 2436 : loss : 0.030099, loss_ce: 0.011055
2022-01-16 00:36:19,018 iteration 2437 : loss : 0.037212, loss_ce: 0.013224
2022-01-16 00:36:20,555 iteration 2438 : loss : 0.023007, loss_ce: 0.008610
2022-01-16 00:36:22,120 iteration 2439 : loss : 0.032117, loss_ce: 0.011310
2022-01-16 00:36:23,680 iteration 2440 : loss : 0.032399, loss_ce: 0.012353
2022-01-16 00:36:25,289 iteration 2441 : loss : 0.076885, loss_ce: 0.023940
2022-01-16 00:36:26,880 iteration 2442 : loss : 0.026564, loss_ce: 0.007682
2022-01-16 00:36:28,503 iteration 2443 : loss : 0.025171, loss_ce: 0.010757
2022-01-16 00:36:30,067 iteration 2444 : loss : 0.040281, loss_ce: 0.015212
2022-01-16 00:36:31,695 iteration 2445 : loss : 0.027743, loss_ce: 0.010601
2022-01-16 00:36:33,249 iteration 2446 : loss : 0.034857, loss_ce: 0.016156
2022-01-16 00:36:34,822 iteration 2447 : loss : 0.039166, loss_ce: 0.013121
2022-01-16 00:36:36,305 iteration 2448 : loss : 0.040734, loss_ce: 0.023073
 36%|██████████▍                  | 144/400 [57:24<2:00:19, 28.20s/it]2022-01-16 00:36:37,914 iteration 2449 : loss : 0.022752, loss_ce: 0.006305
2022-01-16 00:36:39,389 iteration 2450 : loss : 0.032684, loss_ce: 0.012420
2022-01-16 00:36:40,843 iteration 2451 : loss : 0.025168, loss_ce: 0.008671
2022-01-16 00:36:42,528 iteration 2452 : loss : 0.038493, loss_ce: 0.016379
2022-01-16 00:36:44,089 iteration 2453 : loss : 0.032169, loss_ce: 0.014622
2022-01-16 00:36:45,627 iteration 2454 : loss : 0.037076, loss_ce: 0.014703
2022-01-16 00:36:47,324 iteration 2455 : loss : 0.036141, loss_ce: 0.012276
2022-01-16 00:36:48,989 iteration 2456 : loss : 0.026397, loss_ce: 0.011745
2022-01-16 00:36:50,498 iteration 2457 : loss : 0.033308, loss_ce: 0.012575
2022-01-16 00:36:52,034 iteration 2458 : loss : 0.034963, loss_ce: 0.011242
2022-01-16 00:36:53,595 iteration 2459 : loss : 0.029074, loss_ce: 0.009889
2022-01-16 00:36:55,154 iteration 2460 : loss : 0.042990, loss_ce: 0.011335
2022-01-16 00:36:56,769 iteration 2461 : loss : 0.041168, loss_ce: 0.010457
2022-01-16 00:36:58,454 iteration 2462 : loss : 0.032598, loss_ce: 0.014618
2022-01-16 00:37:00,143 iteration 2463 : loss : 0.042285, loss_ce: 0.017580
2022-01-16 00:37:01,728 iteration 2464 : loss : 0.039706, loss_ce: 0.021563
2022-01-16 00:37:01,729 Training Data Eval:
2022-01-16 00:37:10,063   Average segmentation loss on training set: 0.0232
2022-01-16 00:37:10,063 Validation Data Eval:
2022-01-16 00:37:12,835   Average segmentation loss on validation set: 0.1035
2022-01-16 00:37:14,534 iteration 2465 : loss : 0.027953, loss_ce: 0.012378
 36%|██████████▌                  | 145/400 [58:02<2:12:37, 31.21s/it]2022-01-16 00:37:16,204 iteration 2466 : loss : 0.049358, loss_ce: 0.022636
2022-01-16 00:37:17,770 iteration 2467 : loss : 0.025366, loss_ce: 0.009057
2022-01-16 00:37:19,375 iteration 2468 : loss : 0.031490, loss_ce: 0.012052
2022-01-16 00:37:20,914 iteration 2469 : loss : 0.036281, loss_ce: 0.015468
2022-01-16 00:37:22,475 iteration 2470 : loss : 0.033243, loss_ce: 0.011740
2022-01-16 00:37:23,990 iteration 2471 : loss : 0.044860, loss_ce: 0.022843
2022-01-16 00:37:25,528 iteration 2472 : loss : 0.037604, loss_ce: 0.015440
2022-01-16 00:37:27,051 iteration 2473 : loss : 0.026359, loss_ce: 0.009581
2022-01-16 00:37:28,461 iteration 2474 : loss : 0.040048, loss_ce: 0.018489
2022-01-16 00:37:29,946 iteration 2475 : loss : 0.035537, loss_ce: 0.020673
2022-01-16 00:37:31,407 iteration 2476 : loss : 0.041368, loss_ce: 0.015095
2022-01-16 00:37:32,871 iteration 2477 : loss : 0.030263, loss_ce: 0.011113
2022-01-16 00:37:34,339 iteration 2478 : loss : 0.028864, loss_ce: 0.010026
2022-01-16 00:37:35,819 iteration 2479 : loss : 0.032830, loss_ce: 0.010346
2022-01-16 00:37:37,253 iteration 2480 : loss : 0.028725, loss_ce: 0.010889
2022-01-16 00:37:38,725 iteration 2481 : loss : 0.038875, loss_ce: 0.018457
2022-01-16 00:37:40,310 iteration 2482 : loss : 0.060483, loss_ce: 0.023363
 36%|██████████▌                  | 146/400 [58:28<2:05:12, 29.58s/it]2022-01-16 00:37:41,841 iteration 2483 : loss : 0.040406, loss_ce: 0.016180
2022-01-16 00:37:43,337 iteration 2484 : loss : 0.059789, loss_ce: 0.012946
2022-01-16 00:37:44,943 iteration 2485 : loss : 0.049454, loss_ce: 0.016560
2022-01-16 00:37:46,534 iteration 2486 : loss : 0.041167, loss_ce: 0.016914
2022-01-16 00:37:48,013 iteration 2487 : loss : 0.024872, loss_ce: 0.010734
2022-01-16 00:37:49,556 iteration 2488 : loss : 0.040176, loss_ce: 0.020900
2022-01-16 00:37:51,027 iteration 2489 : loss : 0.039767, loss_ce: 0.016790
2022-01-16 00:37:52,480 iteration 2490 : loss : 0.045615, loss_ce: 0.018721
2022-01-16 00:37:53,866 iteration 2491 : loss : 0.030785, loss_ce: 0.009789
2022-01-16 00:37:55,256 iteration 2492 : loss : 0.032157, loss_ce: 0.012956
2022-01-16 00:37:56,561 iteration 2493 : loss : 0.028714, loss_ce: 0.011283
2022-01-16 00:37:57,927 iteration 2494 : loss : 0.028346, loss_ce: 0.010359
2022-01-16 00:37:59,369 iteration 2495 : loss : 0.026808, loss_ce: 0.011216
2022-01-16 00:38:00,657 iteration 2496 : loss : 0.022771, loss_ce: 0.008401
2022-01-16 00:38:02,071 iteration 2497 : loss : 0.031543, loss_ce: 0.010283
2022-01-16 00:38:03,702 iteration 2498 : loss : 0.030945, loss_ce: 0.011530
2022-01-16 00:38:05,235 iteration 2499 : loss : 0.029755, loss_ce: 0.012182
 37%|██████████▋                  | 147/400 [58:53<1:58:50, 28.18s/it]2022-01-16 00:38:06,804 iteration 2500 : loss : 0.029495, loss_ce: 0.011070
2022-01-16 00:38:08,301 iteration 2501 : loss : 0.025791, loss_ce: 0.010524
2022-01-16 00:38:09,810 iteration 2502 : loss : 0.031821, loss_ce: 0.016412
2022-01-16 00:38:11,229 iteration 2503 : loss : 0.026955, loss_ce: 0.011118
2022-01-16 00:38:12,646 iteration 2504 : loss : 0.037009, loss_ce: 0.013239
2022-01-16 00:38:14,010 iteration 2505 : loss : 0.031864, loss_ce: 0.009817
2022-01-16 00:38:15,389 iteration 2506 : loss : 0.028837, loss_ce: 0.014108
2022-01-16 00:38:16,687 iteration 2507 : loss : 0.029152, loss_ce: 0.009753
2022-01-16 00:38:17,946 iteration 2508 : loss : 0.027030, loss_ce: 0.011624
2022-01-16 00:38:19,263 iteration 2509 : loss : 0.024625, loss_ce: 0.013076
2022-01-16 00:38:20,562 iteration 2510 : loss : 0.042941, loss_ce: 0.012612
2022-01-16 00:38:21,886 iteration 2511 : loss : 0.030900, loss_ce: 0.013636
2022-01-16 00:38:23,184 iteration 2512 : loss : 0.029432, loss_ce: 0.011064
2022-01-16 00:38:24,474 iteration 2513 : loss : 0.037036, loss_ce: 0.015715
2022-01-16 00:38:25,763 iteration 2514 : loss : 0.029751, loss_ce: 0.010375
2022-01-16 00:38:27,001 iteration 2515 : loss : 0.029460, loss_ce: 0.008618
2022-01-16 00:38:28,216 iteration 2516 : loss : 0.041227, loss_ce: 0.018081
 37%|██████████▋                  | 148/400 [59:16<1:51:49, 26.62s/it]2022-01-16 00:38:29,567 iteration 2517 : loss : 0.035746, loss_ce: 0.017859
2022-01-16 00:38:30,906 iteration 2518 : loss : 0.042714, loss_ce: 0.016243
2022-01-16 00:38:32,172 iteration 2519 : loss : 0.026504, loss_ce: 0.010339
2022-01-16 00:38:33,448 iteration 2520 : loss : 0.022854, loss_ce: 0.007507
2022-01-16 00:38:34,817 iteration 2521 : loss : 0.030621, loss_ce: 0.014198
2022-01-16 00:38:36,126 iteration 2522 : loss : 0.031020, loss_ce: 0.012055
2022-01-16 00:38:37,420 iteration 2523 : loss : 0.032681, loss_ce: 0.007473
2022-01-16 00:38:38,827 iteration 2524 : loss : 0.032498, loss_ce: 0.014443
2022-01-16 00:38:40,172 iteration 2525 : loss : 0.029080, loss_ce: 0.011359
2022-01-16 00:38:41,469 iteration 2526 : loss : 0.031494, loss_ce: 0.011420
2022-01-16 00:38:42,813 iteration 2527 : loss : 0.029029, loss_ce: 0.010329
2022-01-16 00:38:44,084 iteration 2528 : loss : 0.046327, loss_ce: 0.017001
2022-01-16 00:38:45,426 iteration 2529 : loss : 0.032449, loss_ce: 0.012624
2022-01-16 00:38:46,752 iteration 2530 : loss : 0.026282, loss_ce: 0.006786
2022-01-16 00:38:48,093 iteration 2531 : loss : 0.031777, loss_ce: 0.010732
2022-01-16 00:38:49,525 iteration 2532 : loss : 0.033717, loss_ce: 0.012845
2022-01-16 00:38:50,988 iteration 2533 : loss : 0.040192, loss_ce: 0.022925
 37%|██████████▊                  | 149/400 [59:39<1:46:32, 25.47s/it]2022-01-16 00:38:52,420 iteration 2534 : loss : 0.026258, loss_ce: 0.010809
2022-01-16 00:38:53,910 iteration 2535 : loss : 0.032094, loss_ce: 0.008025
2022-01-16 00:38:55,447 iteration 2536 : loss : 0.031184, loss_ce: 0.013913
2022-01-16 00:38:56,984 iteration 2537 : loss : 0.043506, loss_ce: 0.016856
2022-01-16 00:38:58,502 iteration 2538 : loss : 0.044746, loss_ce: 0.014855
2022-01-16 00:38:59,888 iteration 2539 : loss : 0.026723, loss_ce: 0.010051
2022-01-16 00:39:01,391 iteration 2540 : loss : 0.043432, loss_ce: 0.014477
2022-01-16 00:39:03,025 iteration 2541 : loss : 0.067737, loss_ce: 0.018760
2022-01-16 00:39:04,551 iteration 2542 : loss : 0.029808, loss_ce: 0.010948
2022-01-16 00:39:06,074 iteration 2543 : loss : 0.031925, loss_ce: 0.012534
2022-01-16 00:39:07,623 iteration 2544 : loss : 0.036113, loss_ce: 0.014910
2022-01-16 00:39:09,127 iteration 2545 : loss : 0.035123, loss_ce: 0.016790
2022-01-16 00:39:10,514 iteration 2546 : loss : 0.031117, loss_ce: 0.011326
2022-01-16 00:39:11,967 iteration 2547 : loss : 0.034560, loss_ce: 0.009122
2022-01-16 00:39:13,394 iteration 2548 : loss : 0.033514, loss_ce: 0.011931
2022-01-16 00:39:14,938 iteration 2549 : loss : 0.041949, loss_ce: 0.014390
2022-01-16 00:39:14,938 Training Data Eval:
2022-01-16 00:39:23,097   Average segmentation loss on training set: 0.0227
2022-01-16 00:39:23,098 Validation Data Eval:
2022-01-16 00:39:26,034   Average segmentation loss on validation set: 0.0931
2022-01-16 00:39:27,573 iteration 2550 : loss : 0.032043, loss_ce: 0.017484
 38%|██████████▏                | 150/400 [1:00:15<2:00:00, 28.80s/it]2022-01-16 00:39:29,319 iteration 2551 : loss : 0.025522, loss_ce: 0.009120
2022-01-16 00:39:31,016 iteration 2552 : loss : 0.028129, loss_ce: 0.011278
2022-01-16 00:39:32,723 iteration 2553 : loss : 0.043795, loss_ce: 0.021415
2022-01-16 00:39:34,425 iteration 2554 : loss : 0.037476, loss_ce: 0.011153
2022-01-16 00:39:35,968 iteration 2555 : loss : 0.032317, loss_ce: 0.008294
2022-01-16 00:39:37,584 iteration 2556 : loss : 0.025130, loss_ce: 0.010738
2022-01-16 00:39:39,213 iteration 2557 : loss : 0.028234, loss_ce: 0.014001
2022-01-16 00:39:40,845 iteration 2558 : loss : 0.027605, loss_ce: 0.012431
2022-01-16 00:39:42,496 iteration 2559 : loss : 0.047052, loss_ce: 0.011165
2022-01-16 00:39:44,129 iteration 2560 : loss : 0.031637, loss_ce: 0.011704
2022-01-16 00:39:45,834 iteration 2561 : loss : 0.035825, loss_ce: 0.014009
2022-01-16 00:39:47,375 iteration 2562 : loss : 0.031556, loss_ce: 0.016351
2022-01-16 00:39:48,924 iteration 2563 : loss : 0.028516, loss_ce: 0.009939
2022-01-16 00:39:50,494 iteration 2564 : loss : 0.029808, loss_ce: 0.013194
2022-01-16 00:39:52,072 iteration 2565 : loss : 0.040496, loss_ce: 0.012088
2022-01-16 00:39:53,614 iteration 2566 : loss : 0.029517, loss_ce: 0.014295
2022-01-16 00:39:55,367 iteration 2567 : loss : 0.032410, loss_ce: 0.012746
 38%|██████████▏                | 151/400 [1:00:43<1:58:16, 28.50s/it]2022-01-16 00:39:57,006 iteration 2568 : loss : 0.023033, loss_ce: 0.011019
2022-01-16 00:39:58,720 iteration 2569 : loss : 0.040776, loss_ce: 0.014487
2022-01-16 00:40:00,382 iteration 2570 : loss : 0.045646, loss_ce: 0.013411
2022-01-16 00:40:01,973 iteration 2571 : loss : 0.045177, loss_ce: 0.019324
2022-01-16 00:40:03,512 iteration 2572 : loss : 0.035135, loss_ce: 0.009646
2022-01-16 00:40:05,044 iteration 2573 : loss : 0.025221, loss_ce: 0.009551
2022-01-16 00:40:06,792 iteration 2574 : loss : 0.033712, loss_ce: 0.010765
2022-01-16 00:40:08,384 iteration 2575 : loss : 0.031343, loss_ce: 0.010838
2022-01-16 00:40:10,134 iteration 2576 : loss : 0.030798, loss_ce: 0.014084
2022-01-16 00:40:11,876 iteration 2577 : loss : 0.041884, loss_ce: 0.013805
2022-01-16 00:40:13,469 iteration 2578 : loss : 0.034981, loss_ce: 0.017505
2022-01-16 00:40:15,031 iteration 2579 : loss : 0.029862, loss_ce: 0.009584
2022-01-16 00:40:16,648 iteration 2580 : loss : 0.022929, loss_ce: 0.006960
2022-01-16 00:40:18,400 iteration 2581 : loss : 0.041831, loss_ce: 0.013264
2022-01-16 00:40:20,049 iteration 2582 : loss : 0.031400, loss_ce: 0.011564
2022-01-16 00:40:21,739 iteration 2583 : loss : 0.024049, loss_ce: 0.007422
2022-01-16 00:40:23,300 iteration 2584 : loss : 0.024842, loss_ce: 0.008883
 38%|██████████▎                | 152/400 [1:01:11<1:57:05, 28.33s/it]2022-01-16 00:40:25,056 iteration 2585 : loss : 0.035626, loss_ce: 0.015573
2022-01-16 00:40:26,741 iteration 2586 : loss : 0.037553, loss_ce: 0.018196
2022-01-16 00:40:28,285 iteration 2587 : loss : 0.025840, loss_ce: 0.008581
2022-01-16 00:40:29,929 iteration 2588 : loss : 0.030789, loss_ce: 0.015097
2022-01-16 00:40:31,542 iteration 2589 : loss : 0.037877, loss_ce: 0.012924
2022-01-16 00:40:33,238 iteration 2590 : loss : 0.040110, loss_ce: 0.012712
2022-01-16 00:40:34,922 iteration 2591 : loss : 0.031334, loss_ce: 0.012815
2022-01-16 00:40:36,479 iteration 2592 : loss : 0.026539, loss_ce: 0.009928
2022-01-16 00:40:38,115 iteration 2593 : loss : 0.028821, loss_ce: 0.011598
2022-01-16 00:40:39,735 iteration 2594 : loss : 0.031770, loss_ce: 0.011774
2022-01-16 00:40:41,531 iteration 2595 : loss : 0.039995, loss_ce: 0.011967
2022-01-16 00:40:43,023 iteration 2596 : loss : 0.023082, loss_ce: 0.008059
2022-01-16 00:40:44,574 iteration 2597 : loss : 0.053260, loss_ce: 0.016647
2022-01-16 00:40:46,166 iteration 2598 : loss : 0.030393, loss_ce: 0.012668
2022-01-16 00:40:47,787 iteration 2599 : loss : 0.027566, loss_ce: 0.012228
2022-01-16 00:40:49,346 iteration 2600 : loss : 0.047030, loss_ce: 0.018372
2022-01-16 00:40:50,863 iteration 2601 : loss : 0.025749, loss_ce: 0.009206
 38%|██████████▎                | 153/400 [1:01:39<1:55:41, 28.10s/it]2022-01-16 00:40:52,454 iteration 2602 : loss : 0.034690, loss_ce: 0.010662
2022-01-16 00:40:54,054 iteration 2603 : loss : 0.037663, loss_ce: 0.011044
2022-01-16 00:40:55,567 iteration 2604 : loss : 0.039509, loss_ce: 0.016750
2022-01-16 00:40:56,979 iteration 2605 : loss : 0.029201, loss_ce: 0.008281
2022-01-16 00:40:58,586 iteration 2606 : loss : 0.056014, loss_ce: 0.019984
2022-01-16 00:41:00,064 iteration 2607 : loss : 0.033657, loss_ce: 0.010927
2022-01-16 00:41:01,533 iteration 2608 : loss : 0.029251, loss_ce: 0.012909
2022-01-16 00:41:03,099 iteration 2609 : loss : 0.042842, loss_ce: 0.015904
2022-01-16 00:41:04,652 iteration 2610 : loss : 0.034699, loss_ce: 0.013228
2022-01-16 00:41:06,163 iteration 2611 : loss : 0.033965, loss_ce: 0.013797
2022-01-16 00:41:07,653 iteration 2612 : loss : 0.033595, loss_ce: 0.014569
2022-01-16 00:41:09,074 iteration 2613 : loss : 0.028355, loss_ce: 0.012394
2022-01-16 00:41:10,685 iteration 2614 : loss : 0.034725, loss_ce: 0.010855
2022-01-16 00:41:12,184 iteration 2615 : loss : 0.041006, loss_ce: 0.013153
2022-01-16 00:41:13,727 iteration 2616 : loss : 0.047826, loss_ce: 0.022437
2022-01-16 00:41:15,233 iteration 2617 : loss : 0.037351, loss_ce: 0.012057
2022-01-16 00:41:16,763 iteration 2618 : loss : 0.025692, loss_ce: 0.010993
 38%|██████████▍                | 154/400 [1:02:05<1:52:30, 27.44s/it]2022-01-16 00:41:18,314 iteration 2619 : loss : 0.035328, loss_ce: 0.010818
2022-01-16 00:41:19,996 iteration 2620 : loss : 0.022728, loss_ce: 0.009825
2022-01-16 00:41:21,623 iteration 2621 : loss : 0.027712, loss_ce: 0.010106
2022-01-16 00:41:23,196 iteration 2622 : loss : 0.047255, loss_ce: 0.011123
2022-01-16 00:41:24,824 iteration 2623 : loss : 0.038841, loss_ce: 0.017946
2022-01-16 00:41:26,350 iteration 2624 : loss : 0.025409, loss_ce: 0.008038
2022-01-16 00:41:27,967 iteration 2625 : loss : 0.034859, loss_ce: 0.006697
2022-01-16 00:41:29,570 iteration 2626 : loss : 0.041470, loss_ce: 0.018678
2022-01-16 00:41:31,426 iteration 2627 : loss : 0.047012, loss_ce: 0.015541
2022-01-16 00:41:32,939 iteration 2628 : loss : 0.028181, loss_ce: 0.012100
2022-01-16 00:41:34,539 iteration 2629 : loss : 0.035578, loss_ce: 0.017219
2022-01-16 00:41:36,278 iteration 2630 : loss : 0.033064, loss_ce: 0.013529
2022-01-16 00:41:37,828 iteration 2631 : loss : 0.037827, loss_ce: 0.017794
2022-01-16 00:41:39,513 iteration 2632 : loss : 0.028589, loss_ce: 0.010556
2022-01-16 00:41:41,205 iteration 2633 : loss : 0.026228, loss_ce: 0.012813
2022-01-16 00:41:42,823 iteration 2634 : loss : 0.036200, loss_ce: 0.011649
2022-01-16 00:41:42,824 Training Data Eval:
2022-01-16 00:41:51,334   Average segmentation loss on training set: 0.0241
2022-01-16 00:41:51,334 Validation Data Eval:
2022-01-16 00:41:54,243   Average segmentation loss on validation set: 0.0987
2022-01-16 00:41:55,823 iteration 2635 : loss : 0.038007, loss_ce: 0.017943
 39%|██████████▍                | 155/400 [1:02:44<2:06:16, 30.93s/it]2022-01-16 00:41:57,500 iteration 2636 : loss : 0.034314, loss_ce: 0.016034
2022-01-16 00:41:59,142 iteration 2637 : loss : 0.039804, loss_ce: 0.016313
2022-01-16 00:42:00,702 iteration 2638 : loss : 0.045291, loss_ce: 0.017007
2022-01-16 00:42:02,228 iteration 2639 : loss : 0.034706, loss_ce: 0.016225
2022-01-16 00:42:03,812 iteration 2640 : loss : 0.028597, loss_ce: 0.011051
2022-01-16 00:42:05,540 iteration 2641 : loss : 0.039277, loss_ce: 0.017544
2022-01-16 00:42:07,071 iteration 2642 : loss : 0.035920, loss_ce: 0.013104
2022-01-16 00:42:08,685 iteration 2643 : loss : 0.031308, loss_ce: 0.012369
2022-01-16 00:42:10,249 iteration 2644 : loss : 0.029194, loss_ce: 0.010516
2022-01-16 00:42:11,794 iteration 2645 : loss : 0.023810, loss_ce: 0.008241
2022-01-16 00:42:13,462 iteration 2646 : loss : 0.035785, loss_ce: 0.013332
2022-01-16 00:42:14,988 iteration 2647 : loss : 0.044995, loss_ce: 0.020005
2022-01-16 00:42:16,468 iteration 2648 : loss : 0.045925, loss_ce: 0.019024
2022-01-16 00:42:18,137 iteration 2649 : loss : 0.044927, loss_ce: 0.017428
2022-01-16 00:42:19,886 iteration 2650 : loss : 0.029753, loss_ce: 0.008777
2022-01-16 00:42:21,483 iteration 2651 : loss : 0.030599, loss_ce: 0.012413
2022-01-16 00:42:23,007 iteration 2652 : loss : 0.025573, loss_ce: 0.009742
 39%|██████████▌                | 156/400 [1:03:11<2:01:11, 29.80s/it]2022-01-16 00:42:24,691 iteration 2653 : loss : 0.025816, loss_ce: 0.011729
2022-01-16 00:42:26,292 iteration 2654 : loss : 0.034826, loss_ce: 0.012096
2022-01-16 00:42:28,105 iteration 2655 : loss : 0.035100, loss_ce: 0.017993
2022-01-16 00:42:29,660 iteration 2656 : loss : 0.043732, loss_ce: 0.013461
2022-01-16 00:42:31,250 iteration 2657 : loss : 0.031601, loss_ce: 0.012174
2022-01-16 00:42:32,726 iteration 2658 : loss : 0.026346, loss_ce: 0.011840
2022-01-16 00:42:34,383 iteration 2659 : loss : 0.073494, loss_ce: 0.016663
2022-01-16 00:42:35,988 iteration 2660 : loss : 0.039224, loss_ce: 0.011496
2022-01-16 00:42:37,541 iteration 2661 : loss : 0.027550, loss_ce: 0.011582
2022-01-16 00:42:39,089 iteration 2662 : loss : 0.034504, loss_ce: 0.015923
2022-01-16 00:42:40,787 iteration 2663 : loss : 0.039165, loss_ce: 0.010974
2022-01-16 00:42:42,615 iteration 2664 : loss : 0.038302, loss_ce: 0.016912
2022-01-16 00:42:44,213 iteration 2665 : loss : 0.032644, loss_ce: 0.011366
2022-01-16 00:42:45,762 iteration 2666 : loss : 0.021037, loss_ce: 0.007019
2022-01-16 00:42:47,481 iteration 2667 : loss : 0.034055, loss_ce: 0.011973
2022-01-16 00:42:49,176 iteration 2668 : loss : 0.036531, loss_ce: 0.018128
2022-01-16 00:42:50,841 iteration 2669 : loss : 0.027208, loss_ce: 0.009950
 39%|██████████▌                | 157/400 [1:03:39<1:58:18, 29.21s/it]2022-01-16 00:42:52,512 iteration 2670 : loss : 0.033843, loss_ce: 0.015302
2022-01-16 00:42:54,320 iteration 2671 : loss : 0.039304, loss_ce: 0.013517
2022-01-16 00:42:56,070 iteration 2672 : loss : 0.026334, loss_ce: 0.010193
2022-01-16 00:42:57,720 iteration 2673 : loss : 0.025008, loss_ce: 0.012095
2022-01-16 00:42:59,419 iteration 2674 : loss : 0.033032, loss_ce: 0.013816
2022-01-16 00:43:01,012 iteration 2675 : loss : 0.024903, loss_ce: 0.010193
2022-01-16 00:43:02,743 iteration 2676 : loss : 0.048798, loss_ce: 0.011776
2022-01-16 00:43:04,476 iteration 2677 : loss : 0.036711, loss_ce: 0.014770
2022-01-16 00:43:06,070 iteration 2678 : loss : 0.031347, loss_ce: 0.014294
2022-01-16 00:43:07,591 iteration 2679 : loss : 0.032428, loss_ce: 0.010263
2022-01-16 00:43:09,249 iteration 2680 : loss : 0.024051, loss_ce: 0.009669
2022-01-16 00:43:10,830 iteration 2681 : loss : 0.028424, loss_ce: 0.008564
2022-01-16 00:43:12,420 iteration 2682 : loss : 0.029789, loss_ce: 0.011359
2022-01-16 00:43:13,938 iteration 2683 : loss : 0.057592, loss_ce: 0.013378
2022-01-16 00:43:15,399 iteration 2684 : loss : 0.042762, loss_ce: 0.027285
2022-01-16 00:43:16,937 iteration 2685 : loss : 0.026294, loss_ce: 0.011104
2022-01-16 00:43:18,394 iteration 2686 : loss : 0.034594, loss_ce: 0.016040
 40%|██████████▋                | 158/400 [1:04:06<1:55:48, 28.71s/it]2022-01-16 00:43:19,918 iteration 2687 : loss : 0.032012, loss_ce: 0.009154
2022-01-16 00:43:21,426 iteration 2688 : loss : 0.034085, loss_ce: 0.010462
2022-01-16 00:43:22,926 iteration 2689 : loss : 0.040754, loss_ce: 0.015331
2022-01-16 00:43:24,510 iteration 2690 : loss : 0.038976, loss_ce: 0.016472
2022-01-16 00:43:25,924 iteration 2691 : loss : 0.021328, loss_ce: 0.008321
2022-01-16 00:43:27,386 iteration 2692 : loss : 0.028193, loss_ce: 0.008682
2022-01-16 00:43:29,039 iteration 2693 : loss : 0.029441, loss_ce: 0.008679
2022-01-16 00:43:30,617 iteration 2694 : loss : 0.040792, loss_ce: 0.014275
2022-01-16 00:43:32,075 iteration 2695 : loss : 0.028548, loss_ce: 0.012046
2022-01-16 00:43:33,544 iteration 2696 : loss : 0.029116, loss_ce: 0.012549
2022-01-16 00:43:34,921 iteration 2697 : loss : 0.025013, loss_ce: 0.011299
2022-01-16 00:43:36,273 iteration 2698 : loss : 0.022218, loss_ce: 0.010137
2022-01-16 00:43:37,712 iteration 2699 : loss : 0.036575, loss_ce: 0.015016
2022-01-16 00:43:39,198 iteration 2700 : loss : 0.027915, loss_ce: 0.013627
2022-01-16 00:43:40,611 iteration 2701 : loss : 0.037720, loss_ce: 0.012842
2022-01-16 00:43:42,082 iteration 2702 : loss : 0.056297, loss_ce: 0.010914
2022-01-16 00:43:43,538 iteration 2703 : loss : 0.029145, loss_ce: 0.010018
 40%|██████████▋                | 159/400 [1:04:31<1:51:02, 27.64s/it]2022-01-16 00:43:45,162 iteration 2704 : loss : 0.035690, loss_ce: 0.012538
2022-01-16 00:43:46,690 iteration 2705 : loss : 0.037647, loss_ce: 0.011291
2022-01-16 00:43:48,227 iteration 2706 : loss : 0.034870, loss_ce: 0.017521
2022-01-16 00:43:49,807 iteration 2707 : loss : 0.036576, loss_ce: 0.011396
2022-01-16 00:43:51,286 iteration 2708 : loss : 0.020726, loss_ce: 0.007975
2022-01-16 00:43:52,809 iteration 2709 : loss : 0.031273, loss_ce: 0.008857
2022-01-16 00:43:54,266 iteration 2710 : loss : 0.022225, loss_ce: 0.007936
2022-01-16 00:43:55,975 iteration 2711 : loss : 0.035390, loss_ce: 0.012064
2022-01-16 00:43:57,623 iteration 2712 : loss : 0.023327, loss_ce: 0.009622
2022-01-16 00:43:59,228 iteration 2713 : loss : 0.039864, loss_ce: 0.013026
2022-01-16 00:44:00,717 iteration 2714 : loss : 0.028993, loss_ce: 0.009320
2022-01-16 00:44:02,292 iteration 2715 : loss : 0.047984, loss_ce: 0.023402
2022-01-16 00:44:03,832 iteration 2716 : loss : 0.037015, loss_ce: 0.012574
2022-01-16 00:44:05,339 iteration 2717 : loss : 0.022964, loss_ce: 0.010810
2022-01-16 00:44:06,884 iteration 2718 : loss : 0.024202, loss_ce: 0.009420
2022-01-16 00:44:08,586 iteration 2719 : loss : 0.047524, loss_ce: 0.016294
2022-01-16 00:44:08,586 Training Data Eval:
2022-01-16 00:44:16,685   Average segmentation loss on training set: 0.0208
2022-01-16 00:44:16,685 Validation Data Eval:
2022-01-16 00:44:19,602   Average segmentation loss on validation set: 0.0962
2022-01-16 00:44:21,089 iteration 2720 : loss : 0.023423, loss_ce: 0.009838
 40%|██████████▊                | 160/400 [1:05:09<2:02:27, 30.62s/it]2022-01-16 00:44:22,734 iteration 2721 : loss : 0.034235, loss_ce: 0.013541
2022-01-16 00:44:24,463 iteration 2722 : loss : 0.030355, loss_ce: 0.013414
2022-01-16 00:44:26,085 iteration 2723 : loss : 0.024399, loss_ce: 0.009238
2022-01-16 00:44:27,699 iteration 2724 : loss : 0.026345, loss_ce: 0.008836
2022-01-16 00:44:29,186 iteration 2725 : loss : 0.026347, loss_ce: 0.009894
2022-01-16 00:44:30,716 iteration 2726 : loss : 0.030769, loss_ce: 0.012084
2022-01-16 00:44:32,168 iteration 2727 : loss : 0.022700, loss_ce: 0.007338
2022-01-16 00:44:33,762 iteration 2728 : loss : 0.060715, loss_ce: 0.032826
2022-01-16 00:44:35,275 iteration 2729 : loss : 0.038931, loss_ce: 0.014529
2022-01-16 00:44:36,879 iteration 2730 : loss : 0.024795, loss_ce: 0.009814
2022-01-16 00:44:38,417 iteration 2731 : loss : 0.026805, loss_ce: 0.012105
2022-01-16 00:44:39,986 iteration 2732 : loss : 0.035834, loss_ce: 0.012560
2022-01-16 00:44:41,569 iteration 2733 : loss : 0.036404, loss_ce: 0.014448
2022-01-16 00:44:43,115 iteration 2734 : loss : 0.028116, loss_ce: 0.008175
2022-01-16 00:44:44,599 iteration 2735 : loss : 0.026524, loss_ce: 0.011208
2022-01-16 00:44:46,295 iteration 2736 : loss : 0.031795, loss_ce: 0.014853
2022-01-16 00:44:47,850 iteration 2737 : loss : 0.026572, loss_ce: 0.009566
 40%|██████████▊                | 161/400 [1:05:36<1:57:20, 29.46s/it]2022-01-16 00:44:49,480 iteration 2738 : loss : 0.026118, loss_ce: 0.012228
2022-01-16 00:44:50,982 iteration 2739 : loss : 0.035609, loss_ce: 0.018053
2022-01-16 00:44:52,544 iteration 2740 : loss : 0.025304, loss_ce: 0.010254
2022-01-16 00:44:54,143 iteration 2741 : loss : 0.021884, loss_ce: 0.006130
2022-01-16 00:44:55,598 iteration 2742 : loss : 0.029739, loss_ce: 0.011961
2022-01-16 00:44:57,104 iteration 2743 : loss : 0.036510, loss_ce: 0.017272
2022-01-16 00:44:58,607 iteration 2744 : loss : 0.027934, loss_ce: 0.013086
2022-01-16 00:45:00,128 iteration 2745 : loss : 0.027007, loss_ce: 0.009885
2022-01-16 00:45:01,642 iteration 2746 : loss : 0.043425, loss_ce: 0.011020
2022-01-16 00:45:03,157 iteration 2747 : loss : 0.027034, loss_ce: 0.008599
2022-01-16 00:45:04,782 iteration 2748 : loss : 0.029319, loss_ce: 0.009980
2022-01-16 00:45:06,393 iteration 2749 : loss : 0.026068, loss_ce: 0.011207
2022-01-16 00:45:07,926 iteration 2750 : loss : 0.038030, loss_ce: 0.011449
2022-01-16 00:45:09,417 iteration 2751 : loss : 0.025481, loss_ce: 0.012270
2022-01-16 00:45:10,840 iteration 2752 : loss : 0.057983, loss_ce: 0.010216
2022-01-16 00:45:12,375 iteration 2753 : loss : 0.050417, loss_ce: 0.023123
2022-01-16 00:45:13,849 iteration 2754 : loss : 0.026180, loss_ce: 0.011446
 40%|██████████▉                | 162/400 [1:06:02<1:52:44, 28.42s/it]2022-01-16 00:45:15,315 iteration 2755 : loss : 0.024870, loss_ce: 0.009749
2022-01-16 00:45:16,739 iteration 2756 : loss : 0.040056, loss_ce: 0.020201
2022-01-16 00:45:18,175 iteration 2757 : loss : 0.032513, loss_ce: 0.013105
2022-01-16 00:45:19,669 iteration 2758 : loss : 0.043370, loss_ce: 0.017565
2022-01-16 00:45:21,083 iteration 2759 : loss : 0.031000, loss_ce: 0.009360
2022-01-16 00:45:22,467 iteration 2760 : loss : 0.037675, loss_ce: 0.013663
2022-01-16 00:45:23,771 iteration 2761 : loss : 0.043579, loss_ce: 0.016195
2022-01-16 00:45:25,091 iteration 2762 : loss : 0.023227, loss_ce: 0.008901
2022-01-16 00:45:26,541 iteration 2763 : loss : 0.071387, loss_ce: 0.025139
2022-01-16 00:45:27,945 iteration 2764 : loss : 0.028239, loss_ce: 0.010367
2022-01-16 00:45:29,410 iteration 2765 : loss : 0.035524, loss_ce: 0.013683
2022-01-16 00:45:30,868 iteration 2766 : loss : 0.030192, loss_ce: 0.011334
2022-01-16 00:45:32,527 iteration 2767 : loss : 0.032165, loss_ce: 0.011584
2022-01-16 00:45:34,066 iteration 2768 : loss : 0.023199, loss_ce: 0.006430
2022-01-16 00:45:35,630 iteration 2769 : loss : 0.025426, loss_ce: 0.010555
2022-01-16 00:45:37,210 iteration 2770 : loss : 0.026595, loss_ce: 0.013191
2022-01-16 00:45:38,745 iteration 2771 : loss : 0.022756, loss_ce: 0.007724
 41%|███████████                | 163/400 [1:06:27<1:48:05, 27.36s/it]2022-01-16 00:45:40,474 iteration 2772 : loss : 0.030238, loss_ce: 0.013963
2022-01-16 00:45:41,960 iteration 2773 : loss : 0.022186, loss_ce: 0.009007
2022-01-16 00:45:43,396 iteration 2774 : loss : 0.041994, loss_ce: 0.010409
2022-01-16 00:45:44,865 iteration 2775 : loss : 0.028589, loss_ce: 0.010487
2022-01-16 00:45:46,329 iteration 2776 : loss : 0.023211, loss_ce: 0.008243
2022-01-16 00:45:47,838 iteration 2777 : loss : 0.020337, loss_ce: 0.007316
2022-01-16 00:45:49,367 iteration 2778 : loss : 0.033947, loss_ce: 0.012462
2022-01-16 00:45:50,923 iteration 2779 : loss : 0.029397, loss_ce: 0.009700
2022-01-16 00:45:52,313 iteration 2780 : loss : 0.019330, loss_ce: 0.006940
2022-01-16 00:45:53,806 iteration 2781 : loss : 0.037711, loss_ce: 0.012655
2022-01-16 00:45:55,220 iteration 2782 : loss : 0.027185, loss_ce: 0.009468
2022-01-16 00:45:56,587 iteration 2783 : loss : 0.035450, loss_ce: 0.017204
2022-01-16 00:45:58,114 iteration 2784 : loss : 0.041942, loss_ce: 0.012527
2022-01-16 00:45:59,578 iteration 2785 : loss : 0.043920, loss_ce: 0.013586
2022-01-16 00:46:01,032 iteration 2786 : loss : 0.031684, loss_ce: 0.012313
2022-01-16 00:46:02,567 iteration 2787 : loss : 0.021815, loss_ce: 0.009147
2022-01-16 00:46:04,100 iteration 2788 : loss : 0.029295, loss_ce: 0.014381
 41%|███████████                | 164/400 [1:06:52<1:45:15, 26.76s/it]2022-01-16 00:46:05,634 iteration 2789 : loss : 0.039705, loss_ce: 0.015282
2022-01-16 00:46:07,371 iteration 2790 : loss : 0.038637, loss_ce: 0.012528
2022-01-16 00:46:08,868 iteration 2791 : loss : 0.030563, loss_ce: 0.013460
2022-01-16 00:46:10,482 iteration 2792 : loss : 0.030564, loss_ce: 0.010681
2022-01-16 00:46:12,034 iteration 2793 : loss : 0.027678, loss_ce: 0.010961
2022-01-16 00:46:13,654 iteration 2794 : loss : 0.035116, loss_ce: 0.011508
2022-01-16 00:46:15,174 iteration 2795 : loss : 0.022413, loss_ce: 0.008017
2022-01-16 00:46:16,705 iteration 2796 : loss : 0.026244, loss_ce: 0.009514
2022-01-16 00:46:18,226 iteration 2797 : loss : 0.028455, loss_ce: 0.010694
2022-01-16 00:46:19,762 iteration 2798 : loss : 0.036652, loss_ce: 0.017704
2022-01-16 00:46:21,211 iteration 2799 : loss : 0.021204, loss_ce: 0.009368
2022-01-16 00:46:22,716 iteration 2800 : loss : 0.039657, loss_ce: 0.013007
2022-01-16 00:46:24,221 iteration 2801 : loss : 0.021363, loss_ce: 0.006315
2022-01-16 00:46:25,928 iteration 2802 : loss : 0.026096, loss_ce: 0.007252
2022-01-16 00:46:27,478 iteration 2803 : loss : 0.026292, loss_ce: 0.010858
2022-01-16 00:46:29,028 iteration 2804 : loss : 0.026952, loss_ce: 0.008957
2022-01-16 00:46:29,028 Training Data Eval:
2022-01-16 00:46:37,221   Average segmentation loss on training set: 0.0192
2022-01-16 00:46:37,221 Validation Data Eval:
2022-01-16 00:46:39,986   Average segmentation loss on validation set: 0.0940
2022-01-16 00:46:41,624 iteration 2805 : loss : 0.024782, loss_ce: 0.010010
 41%|███████████▏               | 165/400 [1:07:29<1:57:27, 29.99s/it]2022-01-16 00:46:43,277 iteration 2806 : loss : 0.033560, loss_ce: 0.013884
2022-01-16 00:46:44,776 iteration 2807 : loss : 0.037318, loss_ce: 0.012918
2022-01-16 00:46:46,290 iteration 2808 : loss : 0.020771, loss_ce: 0.008083
2022-01-16 00:46:47,820 iteration 2809 : loss : 0.018441, loss_ce: 0.006063
2022-01-16 00:46:49,358 iteration 2810 : loss : 0.029063, loss_ce: 0.014103
2022-01-16 00:46:51,102 iteration 2811 : loss : 0.046132, loss_ce: 0.014478
2022-01-16 00:46:52,847 iteration 2812 : loss : 0.022463, loss_ce: 0.007399
2022-01-16 00:46:54,463 iteration 2813 : loss : 0.027941, loss_ce: 0.010148
2022-01-16 00:46:56,025 iteration 2814 : loss : 0.025603, loss_ce: 0.013428
2022-01-16 00:46:57,643 iteration 2815 : loss : 0.034708, loss_ce: 0.013345
2022-01-16 00:46:59,207 iteration 2816 : loss : 0.025208, loss_ce: 0.008547
2022-01-16 00:47:00,748 iteration 2817 : loss : 0.043160, loss_ce: 0.014478
2022-01-16 00:47:02,349 iteration 2818 : loss : 0.049595, loss_ce: 0.018832
2022-01-16 00:47:03,989 iteration 2819 : loss : 0.025097, loss_ce: 0.010857
2022-01-16 00:47:05,538 iteration 2820 : loss : 0.027232, loss_ce: 0.009728
2022-01-16 00:47:07,117 iteration 2821 : loss : 0.021904, loss_ce: 0.008650
2022-01-16 00:47:08,734 iteration 2822 : loss : 0.050920, loss_ce: 0.008735
 42%|███████████▏               | 166/400 [1:07:57<1:53:35, 29.12s/it]2022-01-16 00:47:10,331 iteration 2823 : loss : 0.033623, loss_ce: 0.010102
2022-01-16 00:47:11,856 iteration 2824 : loss : 0.039515, loss_ce: 0.011128
2022-01-16 00:47:13,388 iteration 2825 : loss : 0.053178, loss_ce: 0.019496
2022-01-16 00:47:14,921 iteration 2826 : loss : 0.022080, loss_ce: 0.007206
2022-01-16 00:47:16,547 iteration 2827 : loss : 0.056614, loss_ce: 0.034176
2022-01-16 00:47:18,130 iteration 2828 : loss : 0.032902, loss_ce: 0.013218
2022-01-16 00:47:19,673 iteration 2829 : loss : 0.038933, loss_ce: 0.013095
2022-01-16 00:47:21,360 iteration 2830 : loss : 0.030884, loss_ce: 0.013006
2022-01-16 00:47:22,912 iteration 2831 : loss : 0.063807, loss_ce: 0.017087
2022-01-16 00:47:24,416 iteration 2832 : loss : 0.042288, loss_ce: 0.018631
2022-01-16 00:47:25,993 iteration 2833 : loss : 0.028301, loss_ce: 0.012377
2022-01-16 00:47:27,591 iteration 2834 : loss : 0.035419, loss_ce: 0.013601
2022-01-16 00:47:29,138 iteration 2835 : loss : 0.046689, loss_ce: 0.020424
2022-01-16 00:47:30,653 iteration 2836 : loss : 0.047629, loss_ce: 0.020702
2022-01-16 00:47:32,207 iteration 2837 : loss : 0.040378, loss_ce: 0.015447
2022-01-16 00:47:33,752 iteration 2838 : loss : 0.030637, loss_ce: 0.009966
2022-01-16 00:47:35,261 iteration 2839 : loss : 0.031534, loss_ce: 0.012593
 42%|███████████▎               | 167/400 [1:08:23<1:50:04, 28.34s/it]2022-01-16 00:47:36,817 iteration 2840 : loss : 0.042900, loss_ce: 0.014742
2022-01-16 00:47:38,302 iteration 2841 : loss : 0.027717, loss_ce: 0.013374
2022-01-16 00:47:39,734 iteration 2842 : loss : 0.027309, loss_ce: 0.011478
2022-01-16 00:47:41,314 iteration 2843 : loss : 0.032163, loss_ce: 0.009741
2022-01-16 00:47:42,904 iteration 2844 : loss : 0.040130, loss_ce: 0.021130
2022-01-16 00:47:44,518 iteration 2845 : loss : 0.025720, loss_ce: 0.008652
2022-01-16 00:47:46,034 iteration 2846 : loss : 0.040404, loss_ce: 0.012907
2022-01-16 00:47:47,660 iteration 2847 : loss : 0.040388, loss_ce: 0.016509
2022-01-16 00:47:49,262 iteration 2848 : loss : 0.037843, loss_ce: 0.018339
2022-01-16 00:47:50,935 iteration 2849 : loss : 0.037475, loss_ce: 0.012592
2022-01-16 00:47:52,462 iteration 2850 : loss : 0.034113, loss_ce: 0.011880
2022-01-16 00:47:54,105 iteration 2851 : loss : 0.032881, loss_ce: 0.015365
2022-01-16 00:47:55,620 iteration 2852 : loss : 0.052484, loss_ce: 0.018704
2022-01-16 00:47:57,316 iteration 2853 : loss : 0.034930, loss_ce: 0.014543
2022-01-16 00:47:58,994 iteration 2854 : loss : 0.041895, loss_ce: 0.019035
2022-01-16 00:48:00,573 iteration 2855 : loss : 0.063617, loss_ce: 0.030945
2022-01-16 00:48:02,214 iteration 2856 : loss : 0.036469, loss_ce: 0.014592
 42%|███████████▎               | 168/400 [1:08:50<1:47:59, 27.93s/it]2022-01-16 00:48:03,889 iteration 2857 : loss : 0.050931, loss_ce: 0.016201
2022-01-16 00:48:05,617 iteration 2858 : loss : 0.040327, loss_ce: 0.013186
2022-01-16 00:48:07,094 iteration 2859 : loss : 0.021667, loss_ce: 0.007842
2022-01-16 00:48:08,795 iteration 2860 : loss : 0.038859, loss_ce: 0.016429
2022-01-16 00:48:10,342 iteration 2861 : loss : 0.031955, loss_ce: 0.009741
2022-01-16 00:48:11,972 iteration 2862 : loss : 0.038721, loss_ce: 0.014346
2022-01-16 00:48:13,771 iteration 2863 : loss : 0.064155, loss_ce: 0.021240
2022-01-16 00:48:15,343 iteration 2864 : loss : 0.030845, loss_ce: 0.013532
2022-01-16 00:48:16,875 iteration 2865 : loss : 0.047872, loss_ce: 0.022188
2022-01-16 00:48:18,446 iteration 2866 : loss : 0.030077, loss_ce: 0.008276
2022-01-16 00:48:20,208 iteration 2867 : loss : 0.028992, loss_ce: 0.011963
2022-01-16 00:48:21,828 iteration 2868 : loss : 0.023479, loss_ce: 0.009089
2022-01-16 00:48:23,361 iteration 2869 : loss : 0.024310, loss_ce: 0.011119
2022-01-16 00:48:25,101 iteration 2870 : loss : 0.035810, loss_ce: 0.016178
2022-01-16 00:48:26,692 iteration 2871 : loss : 0.025091, loss_ce: 0.011759
2022-01-16 00:48:28,246 iteration 2872 : loss : 0.040966, loss_ce: 0.015455
2022-01-16 00:48:29,797 iteration 2873 : loss : 0.035354, loss_ce: 0.019611
 42%|███████████▍               | 169/400 [1:09:18<1:47:08, 27.83s/it]2022-01-16 00:48:31,407 iteration 2874 : loss : 0.041516, loss_ce: 0.014199
2022-01-16 00:48:32,906 iteration 2875 : loss : 0.023676, loss_ce: 0.010037
2022-01-16 00:48:34,479 iteration 2876 : loss : 0.024097, loss_ce: 0.009797
2022-01-16 00:48:36,161 iteration 2877 : loss : 0.046844, loss_ce: 0.018092
2022-01-16 00:48:37,792 iteration 2878 : loss : 0.030811, loss_ce: 0.011748
2022-01-16 00:48:39,455 iteration 2879 : loss : 0.024478, loss_ce: 0.012653
2022-01-16 00:48:41,026 iteration 2880 : loss : 0.043859, loss_ce: 0.018417
2022-01-16 00:48:42,578 iteration 2881 : loss : 0.032693, loss_ce: 0.014627
2022-01-16 00:48:44,171 iteration 2882 : loss : 0.076576, loss_ce: 0.021398
2022-01-16 00:48:45,890 iteration 2883 : loss : 0.047257, loss_ce: 0.022927
2022-01-16 00:48:47,654 iteration 2884 : loss : 0.039823, loss_ce: 0.011298
2022-01-16 00:48:49,391 iteration 2885 : loss : 0.029617, loss_ce: 0.013403
2022-01-16 00:48:50,927 iteration 2886 : loss : 0.029894, loss_ce: 0.007836
2022-01-16 00:48:52,491 iteration 2887 : loss : 0.022622, loss_ce: 0.007695
2022-01-16 00:48:54,100 iteration 2888 : loss : 0.042249, loss_ce: 0.015249
2022-01-16 00:48:55,685 iteration 2889 : loss : 0.041411, loss_ce: 0.015350
2022-01-16 00:48:55,685 Training Data Eval:
2022-01-16 00:49:03,881   Average segmentation loss on training set: 0.0396
2022-01-16 00:49:03,881 Validation Data Eval:
2022-01-16 00:49:06,775   Average segmentation loss on validation set: 0.2259
2022-01-16 00:49:08,380 iteration 2890 : loss : 0.039626, loss_ce: 0.013709
 42%|███████████▍               | 170/400 [1:09:56<1:59:01, 31.05s/it]2022-01-16 00:49:10,073 iteration 2891 : loss : 0.036937, loss_ce: 0.017312
2022-01-16 00:49:11,742 iteration 2892 : loss : 0.022166, loss_ce: 0.011234
2022-01-16 00:49:13,291 iteration 2893 : loss : 0.041358, loss_ce: 0.012430
2022-01-16 00:49:15,041 iteration 2894 : loss : 0.019940, loss_ce: 0.007652
2022-01-16 00:49:16,579 iteration 2895 : loss : 0.029501, loss_ce: 0.009909
2022-01-16 00:49:18,109 iteration 2896 : loss : 0.028507, loss_ce: 0.010984
2022-01-16 00:49:19,758 iteration 2897 : loss : 0.037178, loss_ce: 0.013855
2022-01-16 00:49:21,327 iteration 2898 : loss : 0.032052, loss_ce: 0.015800
2022-01-16 00:49:22,874 iteration 2899 : loss : 0.050566, loss_ce: 0.020660
2022-01-16 00:49:24,392 iteration 2900 : loss : 0.027504, loss_ce: 0.008683
2022-01-16 00:49:25,992 iteration 2901 : loss : 0.027060, loss_ce: 0.010106
2022-01-16 00:49:27,471 iteration 2902 : loss : 0.025963, loss_ce: 0.008371
2022-01-16 00:49:29,006 iteration 2903 : loss : 0.029529, loss_ce: 0.013248
2022-01-16 00:49:30,644 iteration 2904 : loss : 0.049563, loss_ce: 0.014637
2022-01-16 00:49:32,206 iteration 2905 : loss : 0.027992, loss_ce: 0.010254
2022-01-16 00:49:33,765 iteration 2906 : loss : 0.033576, loss_ce: 0.013365
2022-01-16 00:49:35,219 iteration 2907 : loss : 0.023724, loss_ce: 0.010046
 43%|███████████▌               | 171/400 [1:10:23<1:53:41, 29.79s/it]2022-01-16 00:49:36,826 iteration 2908 : loss : 0.037438, loss_ce: 0.015487
2022-01-16 00:49:38,327 iteration 2909 : loss : 0.029696, loss_ce: 0.006975
2022-01-16 00:49:39,863 iteration 2910 : loss : 0.033515, loss_ce: 0.011523
2022-01-16 00:49:41,361 iteration 2911 : loss : 0.029396, loss_ce: 0.012307
2022-01-16 00:49:42,859 iteration 2912 : loss : 0.029467, loss_ce: 0.009825
2022-01-16 00:49:44,363 iteration 2913 : loss : 0.032540, loss_ce: 0.012357
2022-01-16 00:49:45,866 iteration 2914 : loss : 0.034716, loss_ce: 0.013357
2022-01-16 00:49:47,450 iteration 2915 : loss : 0.025929, loss_ce: 0.009256
2022-01-16 00:49:48,969 iteration 2916 : loss : 0.028183, loss_ce: 0.015065
2022-01-16 00:49:50,548 iteration 2917 : loss : 0.034747, loss_ce: 0.013950
2022-01-16 00:49:52,071 iteration 2918 : loss : 0.037005, loss_ce: 0.013303
2022-01-16 00:49:53,549 iteration 2919 : loss : 0.033148, loss_ce: 0.015530
2022-01-16 00:49:54,960 iteration 2920 : loss : 0.038767, loss_ce: 0.010566
2022-01-16 00:49:56,379 iteration 2921 : loss : 0.031871, loss_ce: 0.009801
2022-01-16 00:49:57,722 iteration 2922 : loss : 0.027723, loss_ce: 0.010083
2022-01-16 00:49:59,123 iteration 2923 : loss : 0.029900, loss_ce: 0.012984
2022-01-16 00:50:00,486 iteration 2924 : loss : 0.025301, loss_ce: 0.008557
 43%|███████████▌               | 172/400 [1:10:48<1:48:02, 28.43s/it]2022-01-16 00:50:02,074 iteration 2925 : loss : 0.037444, loss_ce: 0.015952
2022-01-16 00:50:03,489 iteration 2926 : loss : 0.024297, loss_ce: 0.007361
2022-01-16 00:50:05,020 iteration 2927 : loss : 0.026121, loss_ce: 0.010488
2022-01-16 00:50:06,603 iteration 2928 : loss : 0.037778, loss_ce: 0.010646
2022-01-16 00:50:08,014 iteration 2929 : loss : 0.020156, loss_ce: 0.006515
2022-01-16 00:50:09,421 iteration 2930 : loss : 0.034168, loss_ce: 0.015296
2022-01-16 00:50:10,760 iteration 2931 : loss : 0.032207, loss_ce: 0.011618
2022-01-16 00:50:12,213 iteration 2932 : loss : 0.024655, loss_ce: 0.009226
2022-01-16 00:50:13,559 iteration 2933 : loss : 0.027400, loss_ce: 0.011679
2022-01-16 00:50:14,955 iteration 2934 : loss : 0.032398, loss_ce: 0.014733
2022-01-16 00:50:16,260 iteration 2935 : loss : 0.056423, loss_ce: 0.018747
2022-01-16 00:50:17,629 iteration 2936 : loss : 0.024905, loss_ce: 0.011021
2022-01-16 00:50:18,892 iteration 2937 : loss : 0.024567, loss_ce: 0.010038
2022-01-16 00:50:20,166 iteration 2938 : loss : 0.025279, loss_ce: 0.009509
2022-01-16 00:50:21,444 iteration 2939 : loss : 0.029648, loss_ce: 0.012177
2022-01-16 00:50:22,778 iteration 2940 : loss : 0.028230, loss_ce: 0.008764
2022-01-16 00:50:24,047 iteration 2941 : loss : 0.029094, loss_ce: 0.008318
 43%|███████████▋               | 173/400 [1:11:12<1:42:02, 26.97s/it]2022-01-16 00:50:25,413 iteration 2942 : loss : 0.030774, loss_ce: 0.011475
2022-01-16 00:50:26,648 iteration 2943 : loss : 0.021363, loss_ce: 0.008581
2022-01-16 00:50:27,960 iteration 2944 : loss : 0.028782, loss_ce: 0.010806
2022-01-16 00:50:29,396 iteration 2945 : loss : 0.030121, loss_ce: 0.012053
2022-01-16 00:50:30,736 iteration 2946 : loss : 0.025896, loss_ce: 0.011237
2022-01-16 00:50:32,080 iteration 2947 : loss : 0.017650, loss_ce: 0.005969
2022-01-16 00:50:33,487 iteration 2948 : loss : 0.030839, loss_ce: 0.010139
2022-01-16 00:50:34,949 iteration 2949 : loss : 0.025183, loss_ce: 0.009204
2022-01-16 00:50:36,353 iteration 2950 : loss : 0.030190, loss_ce: 0.012849
2022-01-16 00:50:37,721 iteration 2951 : loss : 0.023619, loss_ce: 0.008886
2022-01-16 00:50:39,174 iteration 2952 : loss : 0.027951, loss_ce: 0.008323
2022-01-16 00:50:40,623 iteration 2953 : loss : 0.032577, loss_ce: 0.012569
2022-01-16 00:50:42,055 iteration 2954 : loss : 0.040035, loss_ce: 0.012531
2022-01-16 00:50:43,403 iteration 2955 : loss : 0.021562, loss_ce: 0.009210
2022-01-16 00:50:44,758 iteration 2956 : loss : 0.024589, loss_ce: 0.011387
2022-01-16 00:50:46,094 iteration 2957 : loss : 0.055601, loss_ce: 0.013648
2022-01-16 00:50:47,420 iteration 2958 : loss : 0.043778, loss_ce: 0.014236
 44%|███████████▋               | 174/400 [1:11:35<1:37:31, 25.89s/it]2022-01-16 00:50:48,886 iteration 2959 : loss : 0.025881, loss_ce: 0.011019
2022-01-16 00:50:50,276 iteration 2960 : loss : 0.028257, loss_ce: 0.009847
2022-01-16 00:50:51,743 iteration 2961 : loss : 0.029121, loss_ce: 0.013743
2022-01-16 00:50:53,164 iteration 2962 : loss : 0.023062, loss_ce: 0.007385
2022-01-16 00:50:54,657 iteration 2963 : loss : 0.028754, loss_ce: 0.010274
2022-01-16 00:50:56,238 iteration 2964 : loss : 0.042006, loss_ce: 0.016351
2022-01-16 00:50:57,813 iteration 2965 : loss : 0.024308, loss_ce: 0.010630
2022-01-16 00:50:59,310 iteration 2966 : loss : 0.031265, loss_ce: 0.009082
2022-01-16 00:51:00,964 iteration 2967 : loss : 0.046123, loss_ce: 0.016833
2022-01-16 00:51:02,491 iteration 2968 : loss : 0.036354, loss_ce: 0.013910
2022-01-16 00:51:03,951 iteration 2969 : loss : 0.025968, loss_ce: 0.007283
2022-01-16 00:51:05,534 iteration 2970 : loss : 0.024411, loss_ce: 0.009587
2022-01-16 00:51:07,240 iteration 2971 : loss : 0.039386, loss_ce: 0.013889
2022-01-16 00:51:08,806 iteration 2972 : loss : 0.026698, loss_ce: 0.009426
2022-01-16 00:51:10,310 iteration 2973 : loss : 0.069196, loss_ce: 0.040801
2022-01-16 00:51:11,930 iteration 2974 : loss : 0.038525, loss_ce: 0.016352
2022-01-16 00:51:11,930 Training Data Eval:
2022-01-16 00:51:19,353   Average segmentation loss on training set: 0.0210
2022-01-16 00:51:19,353 Validation Data Eval:
2022-01-16 00:51:21,944   Average segmentation loss on validation set: 0.0768
2022-01-16 00:51:23,493 iteration 2975 : loss : 0.038753, loss_ce: 0.015336
 44%|███████████▊               | 175/400 [1:12:11<1:48:33, 28.95s/it]2022-01-16 00:51:25,095 iteration 2976 : loss : 0.053195, loss_ce: 0.021098
2022-01-16 00:51:26,731 iteration 2977 : loss : 0.026566, loss_ce: 0.009945
2022-01-16 00:51:28,255 iteration 2978 : loss : 0.033070, loss_ce: 0.012873
2022-01-16 00:51:29,837 iteration 2979 : loss : 0.051141, loss_ce: 0.016435
2022-01-16 00:51:31,447 iteration 2980 : loss : 0.044284, loss_ce: 0.018833
2022-01-16 00:51:32,903 iteration 2981 : loss : 0.021407, loss_ce: 0.009194
2022-01-16 00:51:34,327 iteration 2982 : loss : 0.030933, loss_ce: 0.011935
2022-01-16 00:51:35,805 iteration 2983 : loss : 0.027346, loss_ce: 0.006462
2022-01-16 00:51:37,476 iteration 2984 : loss : 0.037749, loss_ce: 0.017983
2022-01-16 00:51:39,066 iteration 2985 : loss : 0.030774, loss_ce: 0.014397
2022-01-16 00:51:40,590 iteration 2986 : loss : 0.033486, loss_ce: 0.013860
2022-01-16 00:51:42,216 iteration 2987 : loss : 0.048456, loss_ce: 0.019097
2022-01-16 00:51:43,770 iteration 2988 : loss : 0.036659, loss_ce: 0.013033
2022-01-16 00:51:45,248 iteration 2989 : loss : 0.023871, loss_ce: 0.008682
2022-01-16 00:51:46,739 iteration 2990 : loss : 0.028698, loss_ce: 0.013632
2022-01-16 00:51:48,182 iteration 2991 : loss : 0.028324, loss_ce: 0.008472
2022-01-16 00:51:49,687 iteration 2992 : loss : 0.031476, loss_ce: 0.013393
 44%|███████████▉               | 176/400 [1:12:38<1:44:58, 28.12s/it]2022-01-16 00:51:51,349 iteration 2993 : loss : 0.034233, loss_ce: 0.015322
2022-01-16 00:51:52,871 iteration 2994 : loss : 0.022085, loss_ce: 0.008229
2022-01-16 00:51:54,402 iteration 2995 : loss : 0.044320, loss_ce: 0.017910
2022-01-16 00:51:55,888 iteration 2996 : loss : 0.027672, loss_ce: 0.012427
2022-01-16 00:51:57,386 iteration 2997 : loss : 0.026224, loss_ce: 0.007995
2022-01-16 00:51:58,856 iteration 2998 : loss : 0.020784, loss_ce: 0.009968
2022-01-16 00:52:00,242 iteration 2999 : loss : 0.027340, loss_ce: 0.009308
2022-01-16 00:52:01,596 iteration 3000 : loss : 0.022776, loss_ce: 0.008742
2022-01-16 00:52:03,017 iteration 3001 : loss : 0.026282, loss_ce: 0.010140
2022-01-16 00:52:04,404 iteration 3002 : loss : 0.038895, loss_ce: 0.011657
2022-01-16 00:52:05,664 iteration 3003 : loss : 0.023221, loss_ce: 0.009693
2022-01-16 00:52:06,970 iteration 3004 : loss : 0.024991, loss_ce: 0.011703
2022-01-16 00:52:08,285 iteration 3005 : loss : 0.028573, loss_ce: 0.014056
2022-01-16 00:52:09,659 iteration 3006 : loss : 0.028412, loss_ce: 0.010199
2022-01-16 00:52:11,088 iteration 3007 : loss : 0.024165, loss_ce: 0.007333
2022-01-16 00:52:12,479 iteration 3008 : loss : 0.026149, loss_ce: 0.009188
2022-01-16 00:52:13,889 iteration 3009 : loss : 0.027215, loss_ce: 0.006647
 44%|███████████▉               | 177/400 [1:13:02<1:40:08, 26.95s/it]2022-01-16 00:52:15,440 iteration 3010 : loss : 0.039001, loss_ce: 0.013893
2022-01-16 00:52:16,817 iteration 3011 : loss : 0.044534, loss_ce: 0.011689
2022-01-16 00:52:18,213 iteration 3012 : loss : 0.032413, loss_ce: 0.010573
2022-01-16 00:52:19,676 iteration 3013 : loss : 0.022061, loss_ce: 0.007728
2022-01-16 00:52:21,072 iteration 3014 : loss : 0.045556, loss_ce: 0.021505
2022-01-16 00:52:22,431 iteration 3015 : loss : 0.026202, loss_ce: 0.007300
2022-01-16 00:52:23,672 iteration 3016 : loss : 0.022966, loss_ce: 0.007446
2022-01-16 00:52:25,031 iteration 3017 : loss : 0.039209, loss_ce: 0.021887
2022-01-16 00:52:26,380 iteration 3018 : loss : 0.037788, loss_ce: 0.020834
2022-01-16 00:52:27,760 iteration 3019 : loss : 0.051346, loss_ce: 0.018784
2022-01-16 00:52:29,000 iteration 3020 : loss : 0.023662, loss_ce: 0.008034
2022-01-16 00:52:30,266 iteration 3021 : loss : 0.028987, loss_ce: 0.011361
2022-01-16 00:52:31,487 iteration 3022 : loss : 0.019119, loss_ce: 0.009329
2022-01-16 00:52:32,761 iteration 3023 : loss : 0.022640, loss_ce: 0.008000
2022-01-16 00:52:34,090 iteration 3024 : loss : 0.031014, loss_ce: 0.013464
2022-01-16 00:52:35,370 iteration 3025 : loss : 0.027557, loss_ce: 0.011387
2022-01-16 00:52:36,608 iteration 3026 : loss : 0.029129, loss_ce: 0.008732
 44%|████████████               | 178/400 [1:13:24<1:35:00, 25.68s/it]2022-01-16 00:52:37,909 iteration 3027 : loss : 0.029584, loss_ce: 0.012749
2022-01-16 00:52:39,209 iteration 3028 : loss : 0.031435, loss_ce: 0.011919
2022-01-16 00:52:40,357 iteration 3029 : loss : 0.019045, loss_ce: 0.006626
2022-01-16 00:52:41,561 iteration 3030 : loss : 0.021969, loss_ce: 0.006921
2022-01-16 00:52:42,746 iteration 3031 : loss : 0.055044, loss_ce: 0.017352
2022-01-16 00:52:43,940 iteration 3032 : loss : 0.021789, loss_ce: 0.008876
2022-01-16 00:52:45,093 iteration 3033 : loss : 0.032068, loss_ce: 0.010212
2022-01-16 00:52:46,196 iteration 3034 : loss : 0.024429, loss_ce: 0.006447
2022-01-16 00:52:47,267 iteration 3035 : loss : 0.023747, loss_ce: 0.009641
2022-01-16 00:52:48,418 iteration 3036 : loss : 0.030912, loss_ce: 0.014848
2022-01-16 00:52:49,460 iteration 3037 : loss : 0.025832, loss_ce: 0.011089
2022-01-16 00:52:50,493 iteration 3038 : loss : 0.031194, loss_ce: 0.015718
2022-01-16 00:52:51,557 iteration 3039 : loss : 0.028647, loss_ce: 0.010581
2022-01-16 00:52:52,713 iteration 3040 : loss : 0.036943, loss_ce: 0.011653
2022-01-16 00:52:53,693 iteration 3041 : loss : 0.024634, loss_ce: 0.009004
2022-01-16 00:52:54,715 iteration 3042 : loss : 0.023451, loss_ce: 0.011174
2022-01-16 00:52:55,714 iteration 3043 : loss : 0.023937, loss_ce: 0.009392
 45%|████████████               | 179/400 [1:13:44<1:27:19, 23.71s/it]2022-01-16 00:52:56,824 iteration 3044 : loss : 0.023387, loss_ce: 0.008398
2022-01-16 00:52:57,758 iteration 3045 : loss : 0.027467, loss_ce: 0.009710
2022-01-16 00:52:58,852 iteration 3046 : loss : 0.030229, loss_ce: 0.014220
2022-01-16 00:52:59,953 iteration 3047 : loss : 0.029793, loss_ce: 0.010132
2022-01-16 00:53:00,994 iteration 3048 : loss : 0.027611, loss_ce: 0.009684
2022-01-16 00:53:02,036 iteration 3049 : loss : 0.027621, loss_ce: 0.009566
2022-01-16 00:53:03,090 iteration 3050 : loss : 0.033325, loss_ce: 0.007392
2022-01-16 00:53:04,178 iteration 3051 : loss : 0.025810, loss_ce: 0.009685
2022-01-16 00:53:05,226 iteration 3052 : loss : 0.026626, loss_ce: 0.013601
2022-01-16 00:53:06,165 iteration 3053 : loss : 0.018218, loss_ce: 0.006543
2022-01-16 00:53:07,142 iteration 3054 : loss : 0.034710, loss_ce: 0.014413
2022-01-16 00:53:08,085 iteration 3055 : loss : 0.040626, loss_ce: 0.018786
2022-01-16 00:53:09,016 iteration 3056 : loss : 0.018419, loss_ce: 0.005780
2022-01-16 00:53:10,135 iteration 3057 : loss : 0.036212, loss_ce: 0.012442
2022-01-16 00:53:11,136 iteration 3058 : loss : 0.029319, loss_ce: 0.009381
2022-01-16 00:53:12,129 iteration 3059 : loss : 0.025221, loss_ce: 0.013753
2022-01-16 00:53:12,130 Training Data Eval:
2022-01-16 00:53:17,854   Average segmentation loss on training set: 0.0192
2022-01-16 00:53:17,854 Validation Data Eval:
2022-01-16 00:53:19,866   Average segmentation loss on validation set: 0.1012
2022-01-16 00:53:21,100 iteration 3060 : loss : 0.025976, loss_ce: 0.009659
 45%|████████████▏              | 180/400 [1:14:09<1:28:45, 24.21s/it]2022-01-16 00:53:22,336 iteration 3061 : loss : 0.025837, loss_ce: 0.006792
2022-01-16 00:53:23,520 iteration 3062 : loss : 0.053083, loss_ce: 0.023308
2022-01-16 00:53:24,646 iteration 3063 : loss : 0.024038, loss_ce: 0.009324
2022-01-16 00:53:25,795 iteration 3064 : loss : 0.028150, loss_ce: 0.015094
2022-01-16 00:53:26,978 iteration 3065 : loss : 0.024678, loss_ce: 0.006731
2022-01-16 00:53:28,098 iteration 3066 : loss : 0.027174, loss_ce: 0.008291
2022-01-16 00:53:29,323 iteration 3067 : loss : 0.026672, loss_ce: 0.011397
2022-01-16 00:53:30,568 iteration 3068 : loss : 0.040785, loss_ce: 0.021500
2022-01-16 00:53:31,737 iteration 3069 : loss : 0.015236, loss_ce: 0.005657
2022-01-16 00:53:33,007 iteration 3070 : loss : 0.028593, loss_ce: 0.009171
2022-01-16 00:53:34,442 iteration 3071 : loss : 0.035106, loss_ce: 0.011063
2022-01-16 00:53:35,774 iteration 3072 : loss : 0.023547, loss_ce: 0.009438
2022-01-16 00:53:37,105 iteration 3073 : loss : 0.037949, loss_ce: 0.012279
2022-01-16 00:53:38,505 iteration 3074 : loss : 0.026094, loss_ce: 0.011187
2022-01-16 00:53:39,922 iteration 3075 : loss : 0.049967, loss_ce: 0.017854
2022-01-16 00:53:41,235 iteration 3076 : loss : 0.019974, loss_ce: 0.007588
2022-01-16 00:53:42,632 iteration 3077 : loss : 0.039659, loss_ce: 0.014362
 45%|████████████▏              | 181/400 [1:14:30<1:25:25, 23.40s/it]2022-01-16 00:53:44,027 iteration 3078 : loss : 0.063871, loss_ce: 0.014060
2022-01-16 00:53:45,327 iteration 3079 : loss : 0.029054, loss_ce: 0.009046
2022-01-16 00:53:46,686 iteration 3080 : loss : 0.026538, loss_ce: 0.008468
2022-01-16 00:53:48,089 iteration 3081 : loss : 0.033393, loss_ce: 0.013718
2022-01-16 00:53:49,511 iteration 3082 : loss : 0.028760, loss_ce: 0.010152
2022-01-16 00:53:50,955 iteration 3083 : loss : 0.064272, loss_ce: 0.022047
2022-01-16 00:53:52,456 iteration 3084 : loss : 0.057634, loss_ce: 0.028167
2022-01-16 00:53:53,948 iteration 3085 : loss : 0.026853, loss_ce: 0.010170
2022-01-16 00:53:55,506 iteration 3086 : loss : 0.027607, loss_ce: 0.013034
2022-01-16 00:53:57,216 iteration 3087 : loss : 0.028858, loss_ce: 0.012340
2022-01-16 00:53:58,742 iteration 3088 : loss : 0.034015, loss_ce: 0.015474
2022-01-16 00:54:00,466 iteration 3089 : loss : 0.045018, loss_ce: 0.016291
2022-01-16 00:54:02,011 iteration 3090 : loss : 0.030552, loss_ce: 0.012852
2022-01-16 00:54:03,640 iteration 3091 : loss : 0.031123, loss_ce: 0.013218
2022-01-16 00:54:05,202 iteration 3092 : loss : 0.034074, loss_ce: 0.015257
2022-01-16 00:54:06,745 iteration 3093 : loss : 0.022878, loss_ce: 0.009501
2022-01-16 00:54:08,269 iteration 3094 : loss : 0.064969, loss_ce: 0.017626
 46%|████████████▎              | 182/400 [1:14:56<1:27:28, 24.07s/it]2022-01-16 00:54:09,850 iteration 3095 : loss : 0.028601, loss_ce: 0.011271
2022-01-16 00:54:11,366 iteration 3096 : loss : 0.031021, loss_ce: 0.011513
2022-01-16 00:54:12,896 iteration 3097 : loss : 0.030581, loss_ce: 0.013415
2022-01-16 00:54:14,419 iteration 3098 : loss : 0.032723, loss_ce: 0.009121
2022-01-16 00:54:15,895 iteration 3099 : loss : 0.030889, loss_ce: 0.014004
2022-01-16 00:54:17,369 iteration 3100 : loss : 0.031641, loss_ce: 0.011256
2022-01-16 00:54:18,828 iteration 3101 : loss : 0.022789, loss_ce: 0.009334
2022-01-16 00:54:20,260 iteration 3102 : loss : 0.026088, loss_ce: 0.010634
2022-01-16 00:54:21,850 iteration 3103 : loss : 0.036499, loss_ce: 0.019295
2022-01-16 00:54:23,415 iteration 3104 : loss : 0.039624, loss_ce: 0.011045
2022-01-16 00:54:24,964 iteration 3105 : loss : 0.031691, loss_ce: 0.015304
2022-01-16 00:54:26,460 iteration 3106 : loss : 0.031929, loss_ce: 0.011913
2022-01-16 00:54:27,963 iteration 3107 : loss : 0.022381, loss_ce: 0.008495
2022-01-16 00:54:29,454 iteration 3108 : loss : 0.040332, loss_ce: 0.013489
2022-01-16 00:54:30,844 iteration 3109 : loss : 0.028335, loss_ce: 0.011400
2022-01-16 00:54:32,292 iteration 3110 : loss : 0.025165, loss_ce: 0.009406
2022-01-16 00:54:33,796 iteration 3111 : loss : 0.038553, loss_ce: 0.011726
 46%|████████████▎              | 183/400 [1:15:22<1:28:39, 24.51s/it]2022-01-16 00:54:35,272 iteration 3112 : loss : 0.025426, loss_ce: 0.009391
2022-01-16 00:54:36,708 iteration 3113 : loss : 0.039800, loss_ce: 0.014012
2022-01-16 00:54:38,054 iteration 3114 : loss : 0.025112, loss_ce: 0.011652
2022-01-16 00:54:39,447 iteration 3115 : loss : 0.026225, loss_ce: 0.010361
2022-01-16 00:54:40,766 iteration 3116 : loss : 0.027193, loss_ce: 0.010632
2022-01-16 00:54:42,196 iteration 3117 : loss : 0.029671, loss_ce: 0.007159
2022-01-16 00:54:43,588 iteration 3118 : loss : 0.042775, loss_ce: 0.025530
2022-01-16 00:54:44,993 iteration 3119 : loss : 0.025227, loss_ce: 0.010102
2022-01-16 00:54:46,303 iteration 3120 : loss : 0.024907, loss_ce: 0.007737
2022-01-16 00:54:47,677 iteration 3121 : loss : 0.053150, loss_ce: 0.012429
2022-01-16 00:54:49,038 iteration 3122 : loss : 0.037611, loss_ce: 0.016725
2022-01-16 00:54:50,520 iteration 3123 : loss : 0.042211, loss_ce: 0.016752
2022-01-16 00:54:51,878 iteration 3124 : loss : 0.023735, loss_ce: 0.008640
2022-01-16 00:54:53,261 iteration 3125 : loss : 0.020642, loss_ce: 0.008539
2022-01-16 00:54:54,670 iteration 3126 : loss : 0.023214, loss_ce: 0.009487
2022-01-16 00:54:56,116 iteration 3127 : loss : 0.025827, loss_ce: 0.011046
2022-01-16 00:54:57,694 iteration 3128 : loss : 0.043984, loss_ce: 0.009799
 46%|████████████▍              | 184/400 [1:15:46<1:27:35, 24.33s/it]2022-01-16 00:54:59,280 iteration 3129 : loss : 0.045988, loss_ce: 0.017718
2022-01-16 00:55:00,896 iteration 3130 : loss : 0.024061, loss_ce: 0.008717
2022-01-16 00:55:02,469 iteration 3131 : loss : 0.030012, loss_ce: 0.014027
2022-01-16 00:55:03,998 iteration 3132 : loss : 0.040137, loss_ce: 0.012810
2022-01-16 00:55:05,638 iteration 3133 : loss : 0.027446, loss_ce: 0.011365
2022-01-16 00:55:07,248 iteration 3134 : loss : 0.031050, loss_ce: 0.012993
2022-01-16 00:55:08,982 iteration 3135 : loss : 0.037910, loss_ce: 0.008113
2022-01-16 00:55:10,506 iteration 3136 : loss : 0.032272, loss_ce: 0.016989
2022-01-16 00:55:12,050 iteration 3137 : loss : 0.027601, loss_ce: 0.011235
2022-01-16 00:55:13,585 iteration 3138 : loss : 0.028144, loss_ce: 0.010616
2022-01-16 00:55:15,362 iteration 3139 : loss : 0.033543, loss_ce: 0.010576
2022-01-16 00:55:16,975 iteration 3140 : loss : 0.031325, loss_ce: 0.011956
2022-01-16 00:55:18,590 iteration 3141 : loss : 0.028097, loss_ce: 0.012447
2022-01-16 00:55:20,181 iteration 3142 : loss : 0.025301, loss_ce: 0.009805
2022-01-16 00:55:21,882 iteration 3143 : loss : 0.030634, loss_ce: 0.010055
2022-01-16 00:55:23,544 iteration 3144 : loss : 0.033043, loss_ce: 0.008990
2022-01-16 00:55:23,545 Training Data Eval:
2022-01-16 00:55:31,902   Average segmentation loss on training set: 0.0216
2022-01-16 00:55:31,902 Validation Data Eval:
2022-01-16 00:55:34,822   Average segmentation loss on validation set: 0.0889
2022-01-16 00:55:36,325 iteration 3145 : loss : 0.024834, loss_ce: 0.011181
 46%|████████████▍              | 185/400 [1:16:24<1:42:32, 28.62s/it]2022-01-16 00:55:38,113 iteration 3146 : loss : 0.024077, loss_ce: 0.009532
2022-01-16 00:55:39,687 iteration 3147 : loss : 0.032166, loss_ce: 0.013160
2022-01-16 00:55:41,297 iteration 3148 : loss : 0.025631, loss_ce: 0.008450
2022-01-16 00:55:42,871 iteration 3149 : loss : 0.033284, loss_ce: 0.009565
2022-01-16 00:55:44,606 iteration 3150 : loss : 0.033063, loss_ce: 0.008944
2022-01-16 00:55:46,100 iteration 3151 : loss : 0.022137, loss_ce: 0.009549
2022-01-16 00:55:47,886 iteration 3152 : loss : 0.029254, loss_ce: 0.013729
2022-01-16 00:55:49,437 iteration 3153 : loss : 0.051489, loss_ce: 0.035301
2022-01-16 00:55:51,090 iteration 3154 : loss : 0.032281, loss_ce: 0.009207
2022-01-16 00:55:52,635 iteration 3155 : loss : 0.023487, loss_ce: 0.008760
2022-01-16 00:55:54,385 iteration 3156 : loss : 0.028831, loss_ce: 0.010586
2022-01-16 00:55:55,983 iteration 3157 : loss : 0.039139, loss_ce: 0.010579
2022-01-16 00:55:57,620 iteration 3158 : loss : 0.029157, loss_ce: 0.013570
2022-01-16 00:55:59,193 iteration 3159 : loss : 0.023733, loss_ce: 0.011135
2022-01-16 00:56:00,766 iteration 3160 : loss : 0.027813, loss_ce: 0.012836
2022-01-16 00:56:02,377 iteration 3161 : loss : 0.034673, loss_ce: 0.012567
2022-01-16 00:56:03,962 iteration 3162 : loss : 0.028854, loss_ce: 0.014018
 46%|████████████▌              | 186/400 [1:16:52<1:41:01, 28.32s/it]2022-01-16 00:56:05,423 iteration 3163 : loss : 0.027137, loss_ce: 0.008408
2022-01-16 00:56:06,837 iteration 3164 : loss : 0.030625, loss_ce: 0.008752
2022-01-16 00:56:08,278 iteration 3165 : loss : 0.018940, loss_ce: 0.007779
2022-01-16 00:56:09,789 iteration 3166 : loss : 0.028584, loss_ce: 0.013675
2022-01-16 00:56:11,319 iteration 3167 : loss : 0.033717, loss_ce: 0.011238
2022-01-16 00:56:12,809 iteration 3168 : loss : 0.023208, loss_ce: 0.010930
2022-01-16 00:56:14,321 iteration 3169 : loss : 0.021097, loss_ce: 0.008506
2022-01-16 00:56:15,842 iteration 3170 : loss : 0.027608, loss_ce: 0.011237
2022-01-16 00:56:17,402 iteration 3171 : loss : 0.048112, loss_ce: 0.012516
2022-01-16 00:56:18,952 iteration 3172 : loss : 0.028671, loss_ce: 0.012564
2022-01-16 00:56:20,487 iteration 3173 : loss : 0.020990, loss_ce: 0.007688
2022-01-16 00:56:22,044 iteration 3174 : loss : 0.024082, loss_ce: 0.007829
2022-01-16 00:56:23,536 iteration 3175 : loss : 0.024556, loss_ce: 0.009263
2022-01-16 00:56:25,066 iteration 3176 : loss : 0.027498, loss_ce: 0.012751
2022-01-16 00:56:26,626 iteration 3177 : loss : 0.020927, loss_ce: 0.008953
2022-01-16 00:56:28,221 iteration 3178 : loss : 0.035610, loss_ce: 0.009141
2022-01-16 00:56:29,780 iteration 3179 : loss : 0.039584, loss_ce: 0.010549
 47%|████████████▌              | 187/400 [1:17:18<1:37:53, 27.57s/it]2022-01-16 00:56:31,492 iteration 3180 : loss : 0.024202, loss_ce: 0.011724
2022-01-16 00:56:33,072 iteration 3181 : loss : 0.037874, loss_ce: 0.014486
2022-01-16 00:56:34,756 iteration 3182 : loss : 0.032433, loss_ce: 0.013188
2022-01-16 00:56:36,522 iteration 3183 : loss : 0.028711, loss_ce: 0.012494
2022-01-16 00:56:38,030 iteration 3184 : loss : 0.024753, loss_ce: 0.010489
2022-01-16 00:56:39,647 iteration 3185 : loss : 0.027807, loss_ce: 0.011804
2022-01-16 00:56:41,278 iteration 3186 : loss : 0.023874, loss_ce: 0.010766
2022-01-16 00:56:42,779 iteration 3187 : loss : 0.019440, loss_ce: 0.006516
2022-01-16 00:56:44,369 iteration 3188 : loss : 0.026347, loss_ce: 0.008508
2022-01-16 00:56:45,820 iteration 3189 : loss : 0.019242, loss_ce: 0.008690
2022-01-16 00:56:47,419 iteration 3190 : loss : 0.034146, loss_ce: 0.012750
2022-01-16 00:56:48,958 iteration 3191 : loss : 0.034820, loss_ce: 0.012181
2022-01-16 00:56:50,516 iteration 3192 : loss : 0.021012, loss_ce: 0.008697
2022-01-16 00:56:52,043 iteration 3193 : loss : 0.023287, loss_ce: 0.009379
2022-01-16 00:56:53,543 iteration 3194 : loss : 0.024740, loss_ce: 0.007700
2022-01-16 00:56:55,105 iteration 3195 : loss : 0.036250, loss_ce: 0.009587
2022-01-16 00:56:56,688 iteration 3196 : loss : 0.016441, loss_ce: 0.004505
 47%|████████████▋              | 188/400 [1:17:45<1:36:43, 27.37s/it]2022-01-16 00:56:58,349 iteration 3197 : loss : 0.021004, loss_ce: 0.006595
2022-01-16 00:56:59,865 iteration 3198 : loss : 0.027135, loss_ce: 0.008428
2022-01-16 00:57:01,541 iteration 3199 : loss : 0.022548, loss_ce: 0.008194
2022-01-16 00:57:03,077 iteration 3200 : loss : 0.025357, loss_ce: 0.010866
2022-01-16 00:57:04,681 iteration 3201 : loss : 0.055083, loss_ce: 0.028026
2022-01-16 00:57:06,233 iteration 3202 : loss : 0.028972, loss_ce: 0.012242
2022-01-16 00:57:07,816 iteration 3203 : loss : 0.042213, loss_ce: 0.007161
2022-01-16 00:57:09,406 iteration 3204 : loss : 0.032594, loss_ce: 0.015747
2022-01-16 00:57:11,012 iteration 3205 : loss : 0.023069, loss_ce: 0.007147
2022-01-16 00:57:12,534 iteration 3206 : loss : 0.024452, loss_ce: 0.010013
2022-01-16 00:57:14,084 iteration 3207 : loss : 0.023614, loss_ce: 0.006992
2022-01-16 00:57:15,605 iteration 3208 : loss : 0.033886, loss_ce: 0.010566
2022-01-16 00:57:17,219 iteration 3209 : loss : 0.026704, loss_ce: 0.010285
2022-01-16 00:57:18,962 iteration 3210 : loss : 0.031018, loss_ce: 0.008996
2022-01-16 00:57:20,574 iteration 3211 : loss : 0.034524, loss_ce: 0.015204
2022-01-16 00:57:22,121 iteration 3212 : loss : 0.030016, loss_ce: 0.012429
2022-01-16 00:57:23,759 iteration 3213 : loss : 0.029447, loss_ce: 0.013505
 47%|████████████▊              | 189/400 [1:18:12<1:35:56, 27.28s/it]2022-01-16 00:57:25,329 iteration 3214 : loss : 0.027175, loss_ce: 0.010580
2022-01-16 00:57:26,881 iteration 3215 : loss : 0.020802, loss_ce: 0.008478
2022-01-16 00:57:28,466 iteration 3216 : loss : 0.034925, loss_ce: 0.012995
2022-01-16 00:57:30,078 iteration 3217 : loss : 0.040482, loss_ce: 0.010841
2022-01-16 00:57:31,598 iteration 3218 : loss : 0.024549, loss_ce: 0.009406
2022-01-16 00:57:33,142 iteration 3219 : loss : 0.031290, loss_ce: 0.009658
2022-01-16 00:57:34,748 iteration 3220 : loss : 0.031903, loss_ce: 0.014603
2022-01-16 00:57:36,276 iteration 3221 : loss : 0.037690, loss_ce: 0.011677
2022-01-16 00:57:37,790 iteration 3222 : loss : 0.020401, loss_ce: 0.007090
2022-01-16 00:57:39,313 iteration 3223 : loss : 0.048188, loss_ce: 0.012636
2022-01-16 00:57:40,826 iteration 3224 : loss : 0.026830, loss_ce: 0.011920
2022-01-16 00:57:42,261 iteration 3225 : loss : 0.034839, loss_ce: 0.012686
2022-01-16 00:57:43,741 iteration 3226 : loss : 0.046538, loss_ce: 0.023131
2022-01-16 00:57:45,237 iteration 3227 : loss : 0.034919, loss_ce: 0.013842
2022-01-16 00:57:46,736 iteration 3228 : loss : 0.045211, loss_ce: 0.021439
2022-01-16 00:57:48,330 iteration 3229 : loss : 0.021236, loss_ce: 0.007993
2022-01-16 00:57:48,330 Training Data Eval:
2022-01-16 00:57:56,397   Average segmentation loss on training set: 0.0361
2022-01-16 00:57:56,397 Validation Data Eval:
2022-01-16 00:57:59,264   Average segmentation loss on validation set: 0.1571
2022-01-16 00:58:00,821 iteration 3230 : loss : 0.027961, loss_ce: 0.014658
 48%|████████████▊              | 190/400 [1:18:49<1:45:44, 30.21s/it]2022-01-16 00:58:02,345 iteration 3231 : loss : 0.030795, loss_ce: 0.010751
2022-01-16 00:58:03,925 iteration 3232 : loss : 0.023050, loss_ce: 0.009016
2022-01-16 00:58:05,514 iteration 3233 : loss : 0.048082, loss_ce: 0.012814
2022-01-16 00:58:07,178 iteration 3234 : loss : 0.022653, loss_ce: 0.008784
2022-01-16 00:58:08,739 iteration 3235 : loss : 0.030965, loss_ce: 0.012774
2022-01-16 00:58:10,364 iteration 3236 : loss : 0.024097, loss_ce: 0.012104
2022-01-16 00:58:11,903 iteration 3237 : loss : 0.023365, loss_ce: 0.008586
2022-01-16 00:58:13,476 iteration 3238 : loss : 0.033300, loss_ce: 0.013004
2022-01-16 00:58:15,036 iteration 3239 : loss : 0.026223, loss_ce: 0.010570
2022-01-16 00:58:16,632 iteration 3240 : loss : 0.036600, loss_ce: 0.016142
2022-01-16 00:58:18,343 iteration 3241 : loss : 0.040007, loss_ce: 0.013554
2022-01-16 00:58:20,012 iteration 3242 : loss : 0.025184, loss_ce: 0.009334
2022-01-16 00:58:21,765 iteration 3243 : loss : 0.029518, loss_ce: 0.011187
2022-01-16 00:58:23,371 iteration 3244 : loss : 0.025650, loss_ce: 0.008803
2022-01-16 00:58:24,968 iteration 3245 : loss : 0.028978, loss_ce: 0.009290
2022-01-16 00:58:26,582 iteration 3246 : loss : 0.035233, loss_ce: 0.012345
2022-01-16 00:58:28,328 iteration 3247 : loss : 0.046082, loss_ce: 0.017448
 48%|████████████▉              | 191/400 [1:19:16<1:42:25, 29.40s/it]2022-01-16 00:58:29,945 iteration 3248 : loss : 0.044925, loss_ce: 0.014190
2022-01-16 00:58:31,539 iteration 3249 : loss : 0.036066, loss_ce: 0.011583
2022-01-16 00:58:33,073 iteration 3250 : loss : 0.027277, loss_ce: 0.007995
2022-01-16 00:58:34,632 iteration 3251 : loss : 0.033417, loss_ce: 0.012901
2022-01-16 00:58:36,199 iteration 3252 : loss : 0.020255, loss_ce: 0.009717
2022-01-16 00:58:37,739 iteration 3253 : loss : 0.025828, loss_ce: 0.008494
2022-01-16 00:58:39,356 iteration 3254 : loss : 0.034548, loss_ce: 0.015464
2022-01-16 00:58:40,947 iteration 3255 : loss : 0.041154, loss_ce: 0.015702
2022-01-16 00:58:42,718 iteration 3256 : loss : 0.029121, loss_ce: 0.011277
2022-01-16 00:58:44,291 iteration 3257 : loss : 0.031321, loss_ce: 0.012307
2022-01-16 00:58:45,814 iteration 3258 : loss : 0.023951, loss_ce: 0.006161
2022-01-16 00:58:47,523 iteration 3259 : loss : 0.034940, loss_ce: 0.014578
2022-01-16 00:58:49,153 iteration 3260 : loss : 0.025164, loss_ce: 0.010255
2022-01-16 00:58:50,858 iteration 3261 : loss : 0.032374, loss_ce: 0.012528
2022-01-16 00:58:52,507 iteration 3262 : loss : 0.037803, loss_ce: 0.014764
2022-01-16 00:58:54,056 iteration 3263 : loss : 0.027053, loss_ce: 0.009325
2022-01-16 00:58:55,725 iteration 3264 : loss : 0.035602, loss_ce: 0.012106
 48%|████████████▉              | 192/400 [1:19:44<1:39:50, 28.80s/it]2022-01-16 00:58:57,365 iteration 3265 : loss : 0.028770, loss_ce: 0.012193
2022-01-16 00:58:59,112 iteration 3266 : loss : 0.026873, loss_ce: 0.009255
2022-01-16 00:59:00,679 iteration 3267 : loss : 0.018400, loss_ce: 0.006174
2022-01-16 00:59:02,258 iteration 3268 : loss : 0.025125, loss_ce: 0.008493
2022-01-16 00:59:03,771 iteration 3269 : loss : 0.023260, loss_ce: 0.012028
2022-01-16 00:59:05,345 iteration 3270 : loss : 0.024421, loss_ce: 0.009633
2022-01-16 00:59:06,824 iteration 3271 : loss : 0.025889, loss_ce: 0.007703
2022-01-16 00:59:08,395 iteration 3272 : loss : 0.030949, loss_ce: 0.012206
2022-01-16 00:59:09,877 iteration 3273 : loss : 0.031116, loss_ce: 0.013389
2022-01-16 00:59:11,423 iteration 3274 : loss : 0.031527, loss_ce: 0.010243
2022-01-16 00:59:12,948 iteration 3275 : loss : 0.028728, loss_ce: 0.009740
2022-01-16 00:59:14,428 iteration 3276 : loss : 0.023988, loss_ce: 0.006916
2022-01-16 00:59:15,854 iteration 3277 : loss : 0.020158, loss_ce: 0.007524
2022-01-16 00:59:17,497 iteration 3278 : loss : 0.020481, loss_ce: 0.008294
2022-01-16 00:59:19,066 iteration 3279 : loss : 0.025639, loss_ce: 0.014422
2022-01-16 00:59:20,771 iteration 3280 : loss : 0.023132, loss_ce: 0.008904
2022-01-16 00:59:22,430 iteration 3281 : loss : 0.020225, loss_ce: 0.006109
 48%|█████████████              | 193/400 [1:20:10<1:37:10, 28.17s/it]2022-01-16 00:59:24,045 iteration 3282 : loss : 0.023990, loss_ce: 0.005622
2022-01-16 00:59:25,629 iteration 3283 : loss : 0.028701, loss_ce: 0.011579
2022-01-16 00:59:27,227 iteration 3284 : loss : 0.024677, loss_ce: 0.008924
2022-01-16 00:59:28,842 iteration 3285 : loss : 0.053206, loss_ce: 0.013342
2022-01-16 00:59:30,396 iteration 3286 : loss : 0.021562, loss_ce: 0.006581
2022-01-16 00:59:31,978 iteration 3287 : loss : 0.039726, loss_ce: 0.017176
2022-01-16 00:59:33,415 iteration 3288 : loss : 0.025012, loss_ce: 0.010150
2022-01-16 00:59:35,026 iteration 3289 : loss : 0.021138, loss_ce: 0.008143
2022-01-16 00:59:36,661 iteration 3290 : loss : 0.031014, loss_ce: 0.009663
2022-01-16 00:59:38,257 iteration 3291 : loss : 0.027338, loss_ce: 0.012179
2022-01-16 00:59:39,765 iteration 3292 : loss : 0.030628, loss_ce: 0.010301
2022-01-16 00:59:41,284 iteration 3293 : loss : 0.045707, loss_ce: 0.015197
2022-01-16 00:59:42,860 iteration 3294 : loss : 0.029846, loss_ce: 0.013362
2022-01-16 00:59:44,363 iteration 3295 : loss : 0.024498, loss_ce: 0.010395
2022-01-16 00:59:45,801 iteration 3296 : loss : 0.025655, loss_ce: 0.008753
2022-01-16 00:59:47,281 iteration 3297 : loss : 0.025041, loss_ce: 0.008898
2022-01-16 00:59:48,900 iteration 3298 : loss : 0.022178, loss_ce: 0.010000
 48%|█████████████              | 194/400 [1:20:37<1:34:58, 27.66s/it]2022-01-16 00:59:50,381 iteration 3299 : loss : 0.018982, loss_ce: 0.004917
2022-01-16 00:59:52,073 iteration 3300 : loss : 0.032796, loss_ce: 0.012923
2022-01-16 00:59:53,601 iteration 3301 : loss : 0.025471, loss_ce: 0.012532
2022-01-16 00:59:55,063 iteration 3302 : loss : 0.027985, loss_ce: 0.008620
2022-01-16 00:59:56,584 iteration 3303 : loss : 0.034888, loss_ce: 0.017709
2022-01-16 00:59:58,108 iteration 3304 : loss : 0.028026, loss_ce: 0.011129
2022-01-16 00:59:59,622 iteration 3305 : loss : 0.027339, loss_ce: 0.011205
2022-01-16 01:00:01,120 iteration 3306 : loss : 0.021820, loss_ce: 0.005837
2022-01-16 01:00:02,698 iteration 3307 : loss : 0.044013, loss_ce: 0.018184
2022-01-16 01:00:04,198 iteration 3308 : loss : 0.047324, loss_ce: 0.020656
2022-01-16 01:00:05,693 iteration 3309 : loss : 0.022550, loss_ce: 0.009753
2022-01-16 01:00:07,157 iteration 3310 : loss : 0.021248, loss_ce: 0.011224
2022-01-16 01:00:08,773 iteration 3311 : loss : 0.052466, loss_ce: 0.018067
2022-01-16 01:00:10,298 iteration 3312 : loss : 0.034937, loss_ce: 0.010286
2022-01-16 01:00:11,862 iteration 3313 : loss : 0.055938, loss_ce: 0.025737
2022-01-16 01:00:13,488 iteration 3314 : loss : 0.028391, loss_ce: 0.010798
2022-01-16 01:00:13,489 Training Data Eval:
2022-01-16 01:00:21,748   Average segmentation loss on training set: 0.0306
2022-01-16 01:00:21,749 Validation Data Eval:
2022-01-16 01:00:24,644   Average segmentation loss on validation set: 0.0729
2022-01-16 01:00:26,195 iteration 3315 : loss : 0.027616, loss_ce: 0.011460
 49%|█████████████▏             | 195/400 [1:21:14<1:44:23, 30.55s/it]2022-01-16 01:00:27,920 iteration 3316 : loss : 0.018687, loss_ce: 0.007792
2022-01-16 01:00:29,529 iteration 3317 : loss : 0.028272, loss_ce: 0.011891
2022-01-16 01:00:31,125 iteration 3318 : loss : 0.047591, loss_ce: 0.018848
2022-01-16 01:00:32,751 iteration 3319 : loss : 0.033494, loss_ce: 0.011772
2022-01-16 01:00:34,414 iteration 3320 : loss : 0.037140, loss_ce: 0.015579
2022-01-16 01:00:36,057 iteration 3321 : loss : 0.023426, loss_ce: 0.007826
2022-01-16 01:00:37,798 iteration 3322 : loss : 0.041681, loss_ce: 0.012501
2022-01-16 01:00:39,356 iteration 3323 : loss : 0.022148, loss_ce: 0.006618
2022-01-16 01:00:40,956 iteration 3324 : loss : 0.028377, loss_ce: 0.012384
2022-01-16 01:00:42,594 iteration 3325 : loss : 0.044195, loss_ce: 0.016197
2022-01-16 01:00:44,326 iteration 3326 : loss : 0.023495, loss_ce: 0.008833
2022-01-16 01:00:45,971 iteration 3327 : loss : 0.020307, loss_ce: 0.006170
2022-01-16 01:00:47,665 iteration 3328 : loss : 0.023279, loss_ce: 0.008703
2022-01-16 01:00:49,295 iteration 3329 : loss : 0.036252, loss_ce: 0.013620
2022-01-16 01:00:50,919 iteration 3330 : loss : 0.025814, loss_ce: 0.014073
2022-01-16 01:00:52,571 iteration 3331 : loss : 0.023027, loss_ce: 0.010186
2022-01-16 01:00:54,236 iteration 3332 : loss : 0.026834, loss_ce: 0.008486
 49%|█████████████▏             | 196/400 [1:21:42<1:41:18, 29.80s/it]2022-01-16 01:00:55,969 iteration 3333 : loss : 0.032748, loss_ce: 0.012279
2022-01-16 01:00:57,580 iteration 3334 : loss : 0.030619, loss_ce: 0.015295
2022-01-16 01:00:59,308 iteration 3335 : loss : 0.026498, loss_ce: 0.010743
2022-01-16 01:01:00,826 iteration 3336 : loss : 0.036015, loss_ce: 0.012743
2022-01-16 01:01:02,467 iteration 3337 : loss : 0.030787, loss_ce: 0.011583
2022-01-16 01:01:04,245 iteration 3338 : loss : 0.048913, loss_ce: 0.017547
2022-01-16 01:01:05,772 iteration 3339 : loss : 0.024070, loss_ce: 0.010138
2022-01-16 01:01:07,233 iteration 3340 : loss : 0.035278, loss_ce: 0.010659
2022-01-16 01:01:08,741 iteration 3341 : loss : 0.029407, loss_ce: 0.012411
2022-01-16 01:01:10,244 iteration 3342 : loss : 0.023142, loss_ce: 0.010668
2022-01-16 01:01:11,780 iteration 3343 : loss : 0.026806, loss_ce: 0.013292
2022-01-16 01:01:13,266 iteration 3344 : loss : 0.026931, loss_ce: 0.009473
2022-01-16 01:01:14,734 iteration 3345 : loss : 0.024865, loss_ce: 0.009542
2022-01-16 01:01:16,211 iteration 3346 : loss : 0.027793, loss_ce: 0.011835
2022-01-16 01:01:17,738 iteration 3347 : loss : 0.027286, loss_ce: 0.009879
2022-01-16 01:01:19,246 iteration 3348 : loss : 0.027942, loss_ce: 0.010854
2022-01-16 01:01:20,887 iteration 3349 : loss : 0.038188, loss_ce: 0.011718
 49%|█████████████▎             | 197/400 [1:22:09<1:37:37, 28.85s/it]2022-01-16 01:01:22,533 iteration 3350 : loss : 0.035461, loss_ce: 0.012472
2022-01-16 01:01:24,161 iteration 3351 : loss : 0.046359, loss_ce: 0.023504
2022-01-16 01:01:25,766 iteration 3352 : loss : 0.032747, loss_ce: 0.013807
2022-01-16 01:01:27,377 iteration 3353 : loss : 0.026286, loss_ce: 0.008058
2022-01-16 01:01:29,018 iteration 3354 : loss : 0.021220, loss_ce: 0.009334
2022-01-16 01:01:30,649 iteration 3355 : loss : 0.029231, loss_ce: 0.011891
2022-01-16 01:01:32,372 iteration 3356 : loss : 0.026594, loss_ce: 0.010008
2022-01-16 01:01:33,967 iteration 3357 : loss : 0.028210, loss_ce: 0.008806
2022-01-16 01:01:35,585 iteration 3358 : loss : 0.023839, loss_ce: 0.010435
2022-01-16 01:01:37,239 iteration 3359 : loss : 0.023905, loss_ce: 0.009101
2022-01-16 01:01:38,775 iteration 3360 : loss : 0.031106, loss_ce: 0.011429
2022-01-16 01:01:40,357 iteration 3361 : loss : 0.026899, loss_ce: 0.009821
2022-01-16 01:01:41,947 iteration 3362 : loss : 0.026980, loss_ce: 0.009136
2022-01-16 01:01:43,550 iteration 3363 : loss : 0.043234, loss_ce: 0.012429
2022-01-16 01:01:44,978 iteration 3364 : loss : 0.021301, loss_ce: 0.009756
2022-01-16 01:01:46,444 iteration 3365 : loss : 0.029801, loss_ce: 0.012612
2022-01-16 01:01:47,849 iteration 3366 : loss : 0.021113, loss_ce: 0.008916
 50%|█████████████▎             | 198/400 [1:22:36<1:35:13, 28.29s/it]2022-01-16 01:01:49,342 iteration 3367 : loss : 0.035723, loss_ce: 0.013784
2022-01-16 01:01:50,724 iteration 3368 : loss : 0.018781, loss_ce: 0.009171
2022-01-16 01:01:52,037 iteration 3369 : loss : 0.024283, loss_ce: 0.007627
2022-01-16 01:01:53,459 iteration 3370 : loss : 0.040899, loss_ce: 0.017932
2022-01-16 01:01:54,946 iteration 3371 : loss : 0.049087, loss_ce: 0.017076
2022-01-16 01:01:56,299 iteration 3372 : loss : 0.019439, loss_ce: 0.007760
2022-01-16 01:01:57,737 iteration 3373 : loss : 0.024134, loss_ce: 0.008376
2022-01-16 01:01:59,201 iteration 3374 : loss : 0.019832, loss_ce: 0.006693
2022-01-16 01:02:00,728 iteration 3375 : loss : 0.024424, loss_ce: 0.009300
2022-01-16 01:02:02,304 iteration 3376 : loss : 0.043018, loss_ce: 0.013749
2022-01-16 01:02:03,767 iteration 3377 : loss : 0.016570, loss_ce: 0.006524
2022-01-16 01:02:05,382 iteration 3378 : loss : 0.039641, loss_ce: 0.008256
2022-01-16 01:02:07,022 iteration 3379 : loss : 0.043424, loss_ce: 0.021688
2022-01-16 01:02:08,663 iteration 3380 : loss : 0.028831, loss_ce: 0.009385
2022-01-16 01:02:10,268 iteration 3381 : loss : 0.035473, loss_ce: 0.014057
2022-01-16 01:02:11,869 iteration 3382 : loss : 0.026933, loss_ce: 0.011067
2022-01-16 01:02:13,409 iteration 3383 : loss : 0.025742, loss_ce: 0.009140
 50%|█████████████▍             | 199/400 [1:23:01<1:32:01, 27.47s/it]2022-01-16 01:02:15,040 iteration 3384 : loss : 0.030024, loss_ce: 0.009725
2022-01-16 01:02:16,562 iteration 3385 : loss : 0.024656, loss_ce: 0.008540
2022-01-16 01:02:17,983 iteration 3386 : loss : 0.021431, loss_ce: 0.006262
2022-01-16 01:02:19,514 iteration 3387 : loss : 0.026733, loss_ce: 0.010623
2022-01-16 01:02:21,003 iteration 3388 : loss : 0.028044, loss_ce: 0.011742
2022-01-16 01:02:22,427 iteration 3389 : loss : 0.017810, loss_ce: 0.007735
2022-01-16 01:02:23,772 iteration 3390 : loss : 0.019699, loss_ce: 0.007626
2022-01-16 01:02:25,241 iteration 3391 : loss : 0.039570, loss_ce: 0.013479
2022-01-16 01:02:26,677 iteration 3392 : loss : 0.030594, loss_ce: 0.009592
2022-01-16 01:02:28,078 iteration 3393 : loss : 0.032733, loss_ce: 0.012968
2022-01-16 01:02:29,473 iteration 3394 : loss : 0.018388, loss_ce: 0.007181
2022-01-16 01:02:30,807 iteration 3395 : loss : 0.017378, loss_ce: 0.007101
2022-01-16 01:02:32,271 iteration 3396 : loss : 0.024737, loss_ce: 0.008706
2022-01-16 01:02:33,712 iteration 3397 : loss : 0.027689, loss_ce: 0.011509
2022-01-16 01:02:35,171 iteration 3398 : loss : 0.029941, loss_ce: 0.014165
2022-01-16 01:02:36,805 iteration 3399 : loss : 0.026902, loss_ce: 0.010245
2022-01-16 01:02:36,805 Training Data Eval:
2022-01-16 01:02:44,351   Average segmentation loss on training set: 0.0175
2022-01-16 01:02:44,352 Validation Data Eval:
2022-01-16 01:02:46,914   Average segmentation loss on validation set: 0.0864
2022-01-16 01:02:48,325 iteration 3400 : loss : 0.032731, loss_ce: 0.010123
 50%|█████████████▌             | 200/400 [1:23:36<1:39:00, 29.70s/it]2022-01-16 01:02:49,883 iteration 3401 : loss : 0.029199, loss_ce: 0.014561
2022-01-16 01:02:51,373 iteration 3402 : loss : 0.021140, loss_ce: 0.007524
2022-01-16 01:02:52,967 iteration 3403 : loss : 0.030261, loss_ce: 0.011284
2022-01-16 01:02:54,547 iteration 3404 : loss : 0.023863, loss_ce: 0.008578
2022-01-16 01:02:56,023 iteration 3405 : loss : 0.025607, loss_ce: 0.008837
2022-01-16 01:02:57,754 iteration 3406 : loss : 0.025489, loss_ce: 0.010525
2022-01-16 01:02:59,309 iteration 3407 : loss : 0.029241, loss_ce: 0.010792
2022-01-16 01:03:00,816 iteration 3408 : loss : 0.023582, loss_ce: 0.008505
2022-01-16 01:03:02,382 iteration 3409 : loss : 0.019316, loss_ce: 0.006703
2022-01-16 01:03:03,919 iteration 3410 : loss : 0.020310, loss_ce: 0.007581
2022-01-16 01:03:05,571 iteration 3411 : loss : 0.047627, loss_ce: 0.023042
2022-01-16 01:03:07,180 iteration 3412 : loss : 0.025040, loss_ce: 0.010631
2022-01-16 01:03:08,713 iteration 3413 : loss : 0.022970, loss_ce: 0.005634
2022-01-16 01:03:10,268 iteration 3414 : loss : 0.022639, loss_ce: 0.009666
2022-01-16 01:03:11,750 iteration 3415 : loss : 0.036529, loss_ce: 0.016682
2022-01-16 01:03:13,304 iteration 3416 : loss : 0.017354, loss_ce: 0.005408
2022-01-16 01:03:14,956 iteration 3417 : loss : 0.035310, loss_ce: 0.014017
 50%|█████████████▌             | 201/400 [1:24:03<1:35:26, 28.78s/it]2022-01-16 01:03:16,531 iteration 3418 : loss : 0.015979, loss_ce: 0.005427
2022-01-16 01:03:17,969 iteration 3419 : loss : 0.018582, loss_ce: 0.008335
2022-01-16 01:03:19,432 iteration 3420 : loss : 0.025095, loss_ce: 0.008705
2022-01-16 01:03:20,948 iteration 3421 : loss : 0.019897, loss_ce: 0.007535
2022-01-16 01:03:22,448 iteration 3422 : loss : 0.026868, loss_ce: 0.008748
2022-01-16 01:03:23,992 iteration 3423 : loss : 0.028698, loss_ce: 0.014175
2022-01-16 01:03:25,651 iteration 3424 : loss : 0.043114, loss_ce: 0.020188
2022-01-16 01:03:27,258 iteration 3425 : loss : 0.022019, loss_ce: 0.007909
2022-01-16 01:03:28,841 iteration 3426 : loss : 0.026245, loss_ce: 0.010995
2022-01-16 01:03:30,372 iteration 3427 : loss : 0.028836, loss_ce: 0.008572
2022-01-16 01:03:32,048 iteration 3428 : loss : 0.024542, loss_ce: 0.009680
2022-01-16 01:03:33,565 iteration 3429 : loss : 0.022860, loss_ce: 0.007974
2022-01-16 01:03:35,101 iteration 3430 : loss : 0.021498, loss_ce: 0.008171
2022-01-16 01:03:36,609 iteration 3431 : loss : 0.024833, loss_ce: 0.009032
2022-01-16 01:03:38,174 iteration 3432 : loss : 0.030586, loss_ce: 0.011638
2022-01-16 01:03:39,746 iteration 3433 : loss : 0.040447, loss_ce: 0.012505
2022-01-16 01:03:41,272 iteration 3434 : loss : 0.032083, loss_ce: 0.009425
 50%|█████████████▋             | 202/400 [1:24:29<1:32:31, 28.04s/it]2022-01-16 01:03:42,784 iteration 3435 : loss : 0.030373, loss_ce: 0.009815
2022-01-16 01:03:44,299 iteration 3436 : loss : 0.034388, loss_ce: 0.013821
2022-01-16 01:03:45,778 iteration 3437 : loss : 0.025796, loss_ce: 0.009389
2022-01-16 01:03:47,227 iteration 3438 : loss : 0.030778, loss_ce: 0.012348
2022-01-16 01:03:48,577 iteration 3439 : loss : 0.027563, loss_ce: 0.010454
2022-01-16 01:03:50,019 iteration 3440 : loss : 0.023617, loss_ce: 0.008635
2022-01-16 01:03:51,437 iteration 3441 : loss : 0.030273, loss_ce: 0.008811
2022-01-16 01:03:52,913 iteration 3442 : loss : 0.024590, loss_ce: 0.009670
2022-01-16 01:03:54,464 iteration 3443 : loss : 0.022057, loss_ce: 0.008660
2022-01-16 01:03:55,935 iteration 3444 : loss : 0.037352, loss_ce: 0.012799
2022-01-16 01:03:57,611 iteration 3445 : loss : 0.029288, loss_ce: 0.012508
2022-01-16 01:03:59,173 iteration 3446 : loss : 0.021396, loss_ce: 0.009945
2022-01-16 01:04:00,749 iteration 3447 : loss : 0.033812, loss_ce: 0.010367
2022-01-16 01:04:02,337 iteration 3448 : loss : 0.024743, loss_ce: 0.009710
2022-01-16 01:04:03,880 iteration 3449 : loss : 0.024215, loss_ce: 0.009340
2022-01-16 01:04:05,388 iteration 3450 : loss : 0.021872, loss_ce: 0.007419
2022-01-16 01:04:06,875 iteration 3451 : loss : 0.021634, loss_ce: 0.013865
 51%|█████████████▋             | 203/400 [1:24:55<1:29:40, 27.31s/it]2022-01-16 01:04:08,431 iteration 3452 : loss : 0.016764, loss_ce: 0.007199
2022-01-16 01:04:10,048 iteration 3453 : loss : 0.022726, loss_ce: 0.008075
2022-01-16 01:04:11,697 iteration 3454 : loss : 0.041162, loss_ce: 0.017716
2022-01-16 01:04:13,175 iteration 3455 : loss : 0.027699, loss_ce: 0.011038
2022-01-16 01:04:14,706 iteration 3456 : loss : 0.037152, loss_ce: 0.008318
2022-01-16 01:04:16,213 iteration 3457 : loss : 0.032733, loss_ce: 0.015009
2022-01-16 01:04:17,722 iteration 3458 : loss : 0.032050, loss_ce: 0.008263
2022-01-16 01:04:19,284 iteration 3459 : loss : 0.025976, loss_ce: 0.012424
2022-01-16 01:04:20,902 iteration 3460 : loss : 0.020184, loss_ce: 0.007911
2022-01-16 01:04:22,550 iteration 3461 : loss : 0.015530, loss_ce: 0.004917
2022-01-16 01:04:24,037 iteration 3462 : loss : 0.019036, loss_ce: 0.008485
2022-01-16 01:04:25,718 iteration 3463 : loss : 0.024063, loss_ce: 0.010475
2022-01-16 01:04:27,306 iteration 3464 : loss : 0.028455, loss_ce: 0.010456
2022-01-16 01:04:28,830 iteration 3465 : loss : 0.019922, loss_ce: 0.007930
2022-01-16 01:04:30,523 iteration 3466 : loss : 0.035029, loss_ce: 0.013622
2022-01-16 01:04:32,143 iteration 3467 : loss : 0.017398, loss_ce: 0.006139
2022-01-16 01:04:33,686 iteration 3468 : loss : 0.020150, loss_ce: 0.005802
 51%|█████████████▊             | 204/400 [1:25:22<1:28:43, 27.16s/it]2022-01-16 01:04:35,365 iteration 3469 : loss : 0.024330, loss_ce: 0.010882
2022-01-16 01:04:36,932 iteration 3470 : loss : 0.033913, loss_ce: 0.016227
2022-01-16 01:04:38,550 iteration 3471 : loss : 0.019997, loss_ce: 0.007829
2022-01-16 01:04:40,363 iteration 3472 : loss : 0.042384, loss_ce: 0.013152
2022-01-16 01:04:41,889 iteration 3473 : loss : 0.017095, loss_ce: 0.007874
2022-01-16 01:04:43,461 iteration 3474 : loss : 0.027181, loss_ce: 0.009987
2022-01-16 01:04:45,115 iteration 3475 : loss : 0.021604, loss_ce: 0.009392
2022-01-16 01:04:46,612 iteration 3476 : loss : 0.025760, loss_ce: 0.008169
2022-01-16 01:04:48,107 iteration 3477 : loss : 0.018049, loss_ce: 0.006220
2022-01-16 01:04:49,684 iteration 3478 : loss : 0.020294, loss_ce: 0.008398
2022-01-16 01:04:51,183 iteration 3479 : loss : 0.021152, loss_ce: 0.008691
2022-01-16 01:04:52,659 iteration 3480 : loss : 0.018397, loss_ce: 0.008995
2022-01-16 01:04:54,127 iteration 3481 : loss : 0.034532, loss_ce: 0.012548
2022-01-16 01:04:55,603 iteration 3482 : loss : 0.025342, loss_ce: 0.010014
2022-01-16 01:04:57,151 iteration 3483 : loss : 0.027340, loss_ce: 0.013189
2022-01-16 01:04:58,643 iteration 3484 : loss : 0.024799, loss_ce: 0.008101
2022-01-16 01:04:58,644 Training Data Eval:
2022-01-16 01:05:06,327   Average segmentation loss on training set: 0.0165
2022-01-16 01:05:06,328 Validation Data Eval:
2022-01-16 01:05:08,949   Average segmentation loss on validation set: 0.0869
2022-01-16 01:05:10,439 iteration 3485 : loss : 0.042233, loss_ce: 0.016261
 51%|█████████████▊             | 205/400 [1:25:58<1:37:37, 30.04s/it]2022-01-16 01:05:11,967 iteration 3486 : loss : 0.021206, loss_ce: 0.005543
2022-01-16 01:05:13,407 iteration 3487 : loss : 0.021117, loss_ce: 0.008727
2022-01-16 01:05:14,817 iteration 3488 : loss : 0.021759, loss_ce: 0.006631
2022-01-16 01:05:16,136 iteration 3489 : loss : 0.024426, loss_ce: 0.011128
2022-01-16 01:05:17,555 iteration 3490 : loss : 0.028905, loss_ce: 0.010784
2022-01-16 01:05:19,043 iteration 3491 : loss : 0.028243, loss_ce: 0.011780
2022-01-16 01:05:20,398 iteration 3492 : loss : 0.021175, loss_ce: 0.006098
2022-01-16 01:05:21,687 iteration 3493 : loss : 0.029383, loss_ce: 0.011785
2022-01-16 01:05:23,015 iteration 3494 : loss : 0.019182, loss_ce: 0.006812
2022-01-16 01:05:24,372 iteration 3495 : loss : 0.021321, loss_ce: 0.006868
2022-01-16 01:05:25,792 iteration 3496 : loss : 0.026660, loss_ce: 0.010114
2022-01-16 01:05:27,123 iteration 3497 : loss : 0.022819, loss_ce: 0.008936
2022-01-16 01:05:28,515 iteration 3498 : loss : 0.028044, loss_ce: 0.011682
2022-01-16 01:05:29,881 iteration 3499 : loss : 0.023411, loss_ce: 0.012370
2022-01-16 01:05:31,294 iteration 3500 : loss : 0.025339, loss_ce: 0.010808
2022-01-16 01:05:32,750 iteration 3501 : loss : 0.034011, loss_ce: 0.015127
2022-01-16 01:05:34,110 iteration 3502 : loss : 0.025641, loss_ce: 0.012436
 52%|█████████████▉             | 206/400 [1:26:22<1:30:56, 28.13s/it]2022-01-16 01:05:35,512 iteration 3503 : loss : 0.045603, loss_ce: 0.012265
2022-01-16 01:05:36,819 iteration 3504 : loss : 0.022537, loss_ce: 0.007747
2022-01-16 01:05:38,089 iteration 3505 : loss : 0.019911, loss_ce: 0.008666
2022-01-16 01:05:39,409 iteration 3506 : loss : 0.034883, loss_ce: 0.012647
2022-01-16 01:05:40,628 iteration 3507 : loss : 0.018905, loss_ce: 0.007530
2022-01-16 01:05:41,937 iteration 3508 : loss : 0.035775, loss_ce: 0.008359
2022-01-16 01:05:43,330 iteration 3509 : loss : 0.024252, loss_ce: 0.009162
2022-01-16 01:05:44,714 iteration 3510 : loss : 0.023222, loss_ce: 0.008108
2022-01-16 01:05:46,328 iteration 3511 : loss : 0.053646, loss_ce: 0.022658
2022-01-16 01:05:47,719 iteration 3512 : loss : 0.023508, loss_ce: 0.008419
2022-01-16 01:05:49,183 iteration 3513 : loss : 0.025913, loss_ce: 0.010423
2022-01-16 01:05:50,738 iteration 3514 : loss : 0.024652, loss_ce: 0.010345
2022-01-16 01:05:52,373 iteration 3515 : loss : 0.038394, loss_ce: 0.017628
2022-01-16 01:05:53,924 iteration 3516 : loss : 0.019128, loss_ce: 0.008762
2022-01-16 01:05:55,495 iteration 3517 : loss : 0.030232, loss_ce: 0.013454
2022-01-16 01:05:57,165 iteration 3518 : loss : 0.056397, loss_ce: 0.019940
2022-01-16 01:05:58,796 iteration 3519 : loss : 0.026427, loss_ce: 0.010187
 52%|█████████████▉             | 207/400 [1:26:47<1:27:09, 27.09s/it]2022-01-16 01:06:00,345 iteration 3520 : loss : 0.026693, loss_ce: 0.009083
2022-01-16 01:06:01,912 iteration 3521 : loss : 0.054846, loss_ce: 0.012753
2022-01-16 01:06:03,457 iteration 3522 : loss : 0.029741, loss_ce: 0.008457
2022-01-16 01:06:05,148 iteration 3523 : loss : 0.021833, loss_ce: 0.010533
2022-01-16 01:06:06,825 iteration 3524 : loss : 0.035583, loss_ce: 0.013459
2022-01-16 01:06:08,359 iteration 3525 : loss : 0.048242, loss_ce: 0.014055
2022-01-16 01:06:09,888 iteration 3526 : loss : 0.025816, loss_ce: 0.013227
2022-01-16 01:06:11,500 iteration 3527 : loss : 0.043033, loss_ce: 0.016940
2022-01-16 01:06:13,213 iteration 3528 : loss : 0.065005, loss_ce: 0.011485
2022-01-16 01:06:14,735 iteration 3529 : loss : 0.031716, loss_ce: 0.010504
2022-01-16 01:06:16,223 iteration 3530 : loss : 0.031603, loss_ce: 0.010989
2022-01-16 01:06:17,730 iteration 3531 : loss : 0.042212, loss_ce: 0.014882
2022-01-16 01:06:19,319 iteration 3532 : loss : 0.032247, loss_ce: 0.012973
2022-01-16 01:06:20,933 iteration 3533 : loss : 0.044740, loss_ce: 0.016448
2022-01-16 01:06:22,444 iteration 3534 : loss : 0.034561, loss_ce: 0.011501
2022-01-16 01:06:24,128 iteration 3535 : loss : 0.031432, loss_ce: 0.011442
2022-01-16 01:06:25,683 iteration 3536 : loss : 0.032212, loss_ce: 0.012306
 52%|██████████████             | 208/400 [1:27:13<1:26:29, 27.03s/it]2022-01-16 01:06:27,333 iteration 3537 : loss : 0.042749, loss_ce: 0.020049
2022-01-16 01:06:28,892 iteration 3538 : loss : 0.038128, loss_ce: 0.014651
2022-01-16 01:06:30,427 iteration 3539 : loss : 0.031283, loss_ce: 0.010260
2022-01-16 01:06:31,969 iteration 3540 : loss : 0.041879, loss_ce: 0.021849
2022-01-16 01:06:33,527 iteration 3541 : loss : 0.034467, loss_ce: 0.012707
2022-01-16 01:06:35,108 iteration 3542 : loss : 0.034834, loss_ce: 0.013630
2022-01-16 01:06:36,696 iteration 3543 : loss : 0.032382, loss_ce: 0.013560
2022-01-16 01:06:38,357 iteration 3544 : loss : 0.070795, loss_ce: 0.013353
2022-01-16 01:06:40,001 iteration 3545 : loss : 0.024981, loss_ce: 0.007594
2022-01-16 01:06:41,567 iteration 3546 : loss : 0.034707, loss_ce: 0.013847
2022-01-16 01:06:43,381 iteration 3547 : loss : 0.035357, loss_ce: 0.015752
2022-01-16 01:06:44,923 iteration 3548 : loss : 0.017811, loss_ce: 0.004984
2022-01-16 01:06:46,533 iteration 3549 : loss : 0.046454, loss_ce: 0.022423
2022-01-16 01:06:48,115 iteration 3550 : loss : 0.025768, loss_ce: 0.008476
2022-01-16 01:06:49,604 iteration 3551 : loss : 0.029714, loss_ce: 0.011278
2022-01-16 01:06:51,121 iteration 3552 : loss : 0.031949, loss_ce: 0.015166
2022-01-16 01:06:52,670 iteration 3553 : loss : 0.033099, loss_ce: 0.012985
 52%|██████████████             | 209/400 [1:27:40<1:26:01, 27.02s/it]2022-01-16 01:06:54,252 iteration 3554 : loss : 0.025631, loss_ce: 0.009888
2022-01-16 01:06:55,727 iteration 3555 : loss : 0.029779, loss_ce: 0.013004
2022-01-16 01:06:57,274 iteration 3556 : loss : 0.045002, loss_ce: 0.016747
2022-01-16 01:06:58,866 iteration 3557 : loss : 0.030284, loss_ce: 0.011495
2022-01-16 01:07:00,351 iteration 3558 : loss : 0.024849, loss_ce: 0.008294
2022-01-16 01:07:01,819 iteration 3559 : loss : 0.034844, loss_ce: 0.010090
2022-01-16 01:07:03,303 iteration 3560 : loss : 0.026767, loss_ce: 0.010772
2022-01-16 01:07:04,708 iteration 3561 : loss : 0.019739, loss_ce: 0.009437
2022-01-16 01:07:06,157 iteration 3562 : loss : 0.028933, loss_ce: 0.011065
2022-01-16 01:07:07,578 iteration 3563 : loss : 0.028842, loss_ce: 0.010999
2022-01-16 01:07:09,043 iteration 3564 : loss : 0.045883, loss_ce: 0.013252
2022-01-16 01:07:10,410 iteration 3565 : loss : 0.033084, loss_ce: 0.008154
2022-01-16 01:07:11,830 iteration 3566 : loss : 0.026329, loss_ce: 0.010387
2022-01-16 01:07:13,413 iteration 3567 : loss : 0.032932, loss_ce: 0.016757
2022-01-16 01:07:14,867 iteration 3568 : loss : 0.030836, loss_ce: 0.011327
2022-01-16 01:07:16,259 iteration 3569 : loss : 0.032392, loss_ce: 0.013322
2022-01-16 01:07:16,259 Training Data Eval:
2022-01-16 01:07:23,327   Average segmentation loss on training set: 0.0251
2022-01-16 01:07:23,328 Validation Data Eval:
2022-01-16 01:07:26,016   Average segmentation loss on validation set: 0.1374
2022-01-16 01:07:27,614 iteration 3570 : loss : 0.032212, loss_ce: 0.009274
 52%|██████████████▏            | 210/400 [1:28:15<1:33:05, 29.40s/it]2022-01-16 01:07:29,212 iteration 3571 : loss : 0.028220, loss_ce: 0.014165
2022-01-16 01:07:30,741 iteration 3572 : loss : 0.027154, loss_ce: 0.010611
2022-01-16 01:07:32,329 iteration 3573 : loss : 0.040957, loss_ce: 0.012935
2022-01-16 01:07:33,879 iteration 3574 : loss : 0.027950, loss_ce: 0.008793
2022-01-16 01:07:35,560 iteration 3575 : loss : 0.021648, loss_ce: 0.006999
2022-01-16 01:07:37,188 iteration 3576 : loss : 0.021355, loss_ce: 0.005877
2022-01-16 01:07:38,782 iteration 3577 : loss : 0.025234, loss_ce: 0.010384
2022-01-16 01:07:40,273 iteration 3578 : loss : 0.028345, loss_ce: 0.009594
2022-01-16 01:07:41,824 iteration 3579 : loss : 0.031884, loss_ce: 0.014132
2022-01-16 01:07:43,342 iteration 3580 : loss : 0.029424, loss_ce: 0.011487
2022-01-16 01:07:44,890 iteration 3581 : loss : 0.026869, loss_ce: 0.014085
2022-01-16 01:07:46,512 iteration 3582 : loss : 0.021708, loss_ce: 0.007122
2022-01-16 01:07:48,256 iteration 3583 : loss : 0.035489, loss_ce: 0.012743
2022-01-16 01:07:49,821 iteration 3584 : loss : 0.027886, loss_ce: 0.009718
2022-01-16 01:07:51,364 iteration 3585 : loss : 0.027293, loss_ce: 0.009207
2022-01-16 01:07:53,089 iteration 3586 : loss : 0.035579, loss_ce: 0.017699
2022-01-16 01:07:54,642 iteration 3587 : loss : 0.019304, loss_ce: 0.008636
 53%|██████████████▏            | 211/400 [1:28:42<1:30:22, 28.69s/it]2022-01-16 01:07:56,406 iteration 3588 : loss : 0.020819, loss_ce: 0.008786
2022-01-16 01:07:58,023 iteration 3589 : loss : 0.027230, loss_ce: 0.008528
2022-01-16 01:07:59,554 iteration 3590 : loss : 0.023071, loss_ce: 0.009614
2022-01-16 01:08:01,061 iteration 3591 : loss : 0.023199, loss_ce: 0.008850
2022-01-16 01:08:02,688 iteration 3592 : loss : 0.034566, loss_ce: 0.013792
2022-01-16 01:08:04,162 iteration 3593 : loss : 0.040855, loss_ce: 0.012669
2022-01-16 01:08:05,815 iteration 3594 : loss : 0.022150, loss_ce: 0.007957
2022-01-16 01:08:07,425 iteration 3595 : loss : 0.047234, loss_ce: 0.016051
2022-01-16 01:08:09,003 iteration 3596 : loss : 0.023273, loss_ce: 0.008559
2022-01-16 01:08:10,550 iteration 3597 : loss : 0.033529, loss_ce: 0.013455
2022-01-16 01:08:11,985 iteration 3598 : loss : 0.019245, loss_ce: 0.007681
2022-01-16 01:08:13,671 iteration 3599 : loss : 0.026494, loss_ce: 0.008455
2022-01-16 01:08:15,095 iteration 3600 : loss : 0.024276, loss_ce: 0.008900
2022-01-16 01:08:16,666 iteration 3601 : loss : 0.026058, loss_ce: 0.010124
2022-01-16 01:08:18,176 iteration 3602 : loss : 0.023731, loss_ce: 0.007573
2022-01-16 01:08:19,697 iteration 3603 : loss : 0.023601, loss_ce: 0.012093
2022-01-16 01:08:21,301 iteration 3604 : loss : 0.022149, loss_ce: 0.009445
 53%|██████████████▎            | 212/400 [1:29:09<1:27:59, 28.08s/it]2022-01-16 01:08:22,894 iteration 3605 : loss : 0.028556, loss_ce: 0.010871
2022-01-16 01:08:24,381 iteration 3606 : loss : 0.038471, loss_ce: 0.022520
2022-01-16 01:08:25,969 iteration 3607 : loss : 0.029379, loss_ce: 0.012149
2022-01-16 01:08:27,455 iteration 3608 : loss : 0.018539, loss_ce: 0.007074
2022-01-16 01:08:28,987 iteration 3609 : loss : 0.022507, loss_ce: 0.010039
2022-01-16 01:08:30,513 iteration 3610 : loss : 0.019925, loss_ce: 0.007333
2022-01-16 01:08:31,950 iteration 3611 : loss : 0.023738, loss_ce: 0.006079
2022-01-16 01:08:33,415 iteration 3612 : loss : 0.019037, loss_ce: 0.006485
2022-01-16 01:08:35,010 iteration 3613 : loss : 0.024300, loss_ce: 0.009568
2022-01-16 01:08:36,533 iteration 3614 : loss : 0.018078, loss_ce: 0.007024
2022-01-16 01:08:37,965 iteration 3615 : loss : 0.019323, loss_ce: 0.006908
2022-01-16 01:08:39,483 iteration 3616 : loss : 0.024871, loss_ce: 0.010151
2022-01-16 01:08:41,018 iteration 3617 : loss : 0.032918, loss_ce: 0.012648
2022-01-16 01:08:42,523 iteration 3618 : loss : 0.020954, loss_ce: 0.008467
2022-01-16 01:08:44,026 iteration 3619 : loss : 0.020335, loss_ce: 0.005715
2022-01-16 01:08:45,475 iteration 3620 : loss : 0.022814, loss_ce: 0.006694
2022-01-16 01:08:47,010 iteration 3621 : loss : 0.037082, loss_ce: 0.016321
 53%|██████████████▍            | 213/400 [1:29:35<1:25:17, 27.36s/it]2022-01-16 01:08:48,503 iteration 3622 : loss : 0.027904, loss_ce: 0.012538
2022-01-16 01:08:49,946 iteration 3623 : loss : 0.026073, loss_ce: 0.006109
2022-01-16 01:08:51,327 iteration 3624 : loss : 0.014726, loss_ce: 0.005681
2022-01-16 01:08:52,673 iteration 3625 : loss : 0.034220, loss_ce: 0.015287
2022-01-16 01:08:53,972 iteration 3626 : loss : 0.023686, loss_ce: 0.011414
2022-01-16 01:08:55,272 iteration 3627 : loss : 0.020700, loss_ce: 0.007437
2022-01-16 01:08:56,639 iteration 3628 : loss : 0.035084, loss_ce: 0.011390
2022-01-16 01:08:58,065 iteration 3629 : loss : 0.022465, loss_ce: 0.009314
2022-01-16 01:08:59,240 iteration 3630 : loss : 0.023724, loss_ce: 0.009304
2022-01-16 01:09:00,491 iteration 3631 : loss : 0.029283, loss_ce: 0.008544
2022-01-16 01:09:01,856 iteration 3632 : loss : 0.033506, loss_ce: 0.010827
2022-01-16 01:09:03,069 iteration 3633 : loss : 0.019522, loss_ce: 0.007540
2022-01-16 01:09:04,266 iteration 3634 : loss : 0.022871, loss_ce: 0.010132
2022-01-16 01:09:05,570 iteration 3635 : loss : 0.032167, loss_ce: 0.013076
2022-01-16 01:09:06,874 iteration 3636 : loss : 0.029094, loss_ce: 0.008413
2022-01-16 01:09:08,111 iteration 3637 : loss : 0.045741, loss_ce: 0.016771
2022-01-16 01:09:09,367 iteration 3638 : loss : 0.019894, loss_ce: 0.008240
 54%|██████████████▍            | 214/400 [1:29:57<1:20:10, 25.86s/it]2022-01-16 01:09:10,633 iteration 3639 : loss : 0.019461, loss_ce: 0.007588
2022-01-16 01:09:11,838 iteration 3640 : loss : 0.020224, loss_ce: 0.007981
2022-01-16 01:09:13,084 iteration 3641 : loss : 0.019132, loss_ce: 0.006475
2022-01-16 01:09:14,484 iteration 3642 : loss : 0.033620, loss_ce: 0.010159
2022-01-16 01:09:15,854 iteration 3643 : loss : 0.018932, loss_ce: 0.007645
2022-01-16 01:09:17,317 iteration 3644 : loss : 0.015309, loss_ce: 0.005573
2022-01-16 01:09:19,001 iteration 3645 : loss : 0.020256, loss_ce: 0.006911
2022-01-16 01:09:20,504 iteration 3646 : loss : 0.028090, loss_ce: 0.011290
2022-01-16 01:09:22,072 iteration 3647 : loss : 0.022331, loss_ce: 0.005452
2022-01-16 01:09:23,599 iteration 3648 : loss : 0.035666, loss_ce: 0.014638
2022-01-16 01:09:25,060 iteration 3649 : loss : 0.020474, loss_ce: 0.005669
2022-01-16 01:09:26,533 iteration 3650 : loss : 0.020349, loss_ce: 0.009159
2022-01-16 01:09:28,106 iteration 3651 : loss : 0.028328, loss_ce: 0.010031
2022-01-16 01:09:29,740 iteration 3652 : loss : 0.035816, loss_ce: 0.010996
2022-01-16 01:09:31,339 iteration 3653 : loss : 0.022753, loss_ce: 0.011488
2022-01-16 01:09:32,867 iteration 3654 : loss : 0.018441, loss_ce: 0.008608
2022-01-16 01:09:32,867 Training Data Eval:
2022-01-16 01:09:41,062   Average segmentation loss on training set: 0.0157
2022-01-16 01:09:41,062 Validation Data Eval:
2022-01-16 01:09:43,824   Average segmentation loss on validation set: 0.0847
2022-01-16 01:09:45,406 iteration 3655 : loss : 0.022621, loss_ce: 0.009212
 54%|██████████████▌            | 215/400 [1:30:33<1:29:09, 28.92s/it]2022-01-16 01:09:47,172 iteration 3656 : loss : 0.018419, loss_ce: 0.007153
2022-01-16 01:09:48,697 iteration 3657 : loss : 0.022118, loss_ce: 0.010953
2022-01-16 01:09:50,295 iteration 3658 : loss : 0.022601, loss_ce: 0.009779
2022-01-16 01:09:52,088 iteration 3659 : loss : 0.029351, loss_ce: 0.010460
2022-01-16 01:09:53,669 iteration 3660 : loss : 0.031002, loss_ce: 0.007576
2022-01-16 01:09:55,291 iteration 3661 : loss : 0.018242, loss_ce: 0.007755
2022-01-16 01:09:56,830 iteration 3662 : loss : 0.019693, loss_ce: 0.006855
2022-01-16 01:09:58,520 iteration 3663 : loss : 0.030634, loss_ce: 0.010394
2022-01-16 01:10:00,055 iteration 3664 : loss : 0.017835, loss_ce: 0.006771
2022-01-16 01:10:01,788 iteration 3665 : loss : 0.023323, loss_ce: 0.011772
2022-01-16 01:10:03,328 iteration 3666 : loss : 0.026164, loss_ce: 0.008849
2022-01-16 01:10:04,871 iteration 3667 : loss : 0.021253, loss_ce: 0.008781
2022-01-16 01:10:06,354 iteration 3668 : loss : 0.028991, loss_ce: 0.007788
2022-01-16 01:10:07,909 iteration 3669 : loss : 0.019740, loss_ce: 0.008259
2022-01-16 01:10:09,411 iteration 3670 : loss : 0.017754, loss_ce: 0.006300
2022-01-16 01:10:11,033 iteration 3671 : loss : 0.018677, loss_ce: 0.008659
2022-01-16 01:10:12,813 iteration 3672 : loss : 0.034510, loss_ce: 0.010281
 54%|██████████████▌            | 216/400 [1:31:01<1:27:17, 28.46s/it]2022-01-16 01:10:14,554 iteration 3673 : loss : 0.024059, loss_ce: 0.010021
2022-01-16 01:10:16,211 iteration 3674 : loss : 0.025710, loss_ce: 0.007263
2022-01-16 01:10:17,874 iteration 3675 : loss : 0.031819, loss_ce: 0.010248
2022-01-16 01:10:19,473 iteration 3676 : loss : 0.022573, loss_ce: 0.009983
2022-01-16 01:10:21,054 iteration 3677 : loss : 0.022659, loss_ce: 0.006671
2022-01-16 01:10:22,631 iteration 3678 : loss : 0.036087, loss_ce: 0.011040
2022-01-16 01:10:24,204 iteration 3679 : loss : 0.024370, loss_ce: 0.009911
2022-01-16 01:10:25,735 iteration 3680 : loss : 0.042277, loss_ce: 0.016502
2022-01-16 01:10:27,375 iteration 3681 : loss : 0.023058, loss_ce: 0.009209
2022-01-16 01:10:28,966 iteration 3682 : loss : 0.019646, loss_ce: 0.007617
2022-01-16 01:10:30,403 iteration 3683 : loss : 0.023871, loss_ce: 0.008793
2022-01-16 01:10:31,956 iteration 3684 : loss : 0.021433, loss_ce: 0.008178
2022-01-16 01:10:33,491 iteration 3685 : loss : 0.023873, loss_ce: 0.007158
2022-01-16 01:10:35,028 iteration 3686 : loss : 0.021720, loss_ce: 0.008556
2022-01-16 01:10:36,484 iteration 3687 : loss : 0.022005, loss_ce: 0.007033
2022-01-16 01:10:37,980 iteration 3688 : loss : 0.027782, loss_ce: 0.015813
2022-01-16 01:10:39,522 iteration 3689 : loss : 0.033631, loss_ce: 0.009687
 54%|██████████████▋            | 217/400 [1:31:27<1:25:12, 27.94s/it]2022-01-16 01:10:41,087 iteration 3690 : loss : 0.028693, loss_ce: 0.007532
2022-01-16 01:10:42,696 iteration 3691 : loss : 0.036563, loss_ce: 0.010153
2022-01-16 01:10:44,295 iteration 3692 : loss : 0.027036, loss_ce: 0.013340
2022-01-16 01:10:45,900 iteration 3693 : loss : 0.024938, loss_ce: 0.010828
2022-01-16 01:10:47,458 iteration 3694 : loss : 0.029296, loss_ce: 0.012315
2022-01-16 01:10:49,034 iteration 3695 : loss : 0.026387, loss_ce: 0.014657
2022-01-16 01:10:50,590 iteration 3696 : loss : 0.026803, loss_ce: 0.007782
2022-01-16 01:10:52,182 iteration 3697 : loss : 0.024883, loss_ce: 0.007940
2022-01-16 01:10:53,943 iteration 3698 : loss : 0.042284, loss_ce: 0.015127
2022-01-16 01:10:55,462 iteration 3699 : loss : 0.018340, loss_ce: 0.007660
2022-01-16 01:10:56,990 iteration 3700 : loss : 0.019872, loss_ce: 0.006078
2022-01-16 01:10:58,467 iteration 3701 : loss : 0.020273, loss_ce: 0.008766
2022-01-16 01:11:00,064 iteration 3702 : loss : 0.023322, loss_ce: 0.008392
2022-01-16 01:11:01,592 iteration 3703 : loss : 0.028432, loss_ce: 0.013376
2022-01-16 01:11:03,160 iteration 3704 : loss : 0.025139, loss_ce: 0.009077
2022-01-16 01:11:04,766 iteration 3705 : loss : 0.028950, loss_ce: 0.010621
2022-01-16 01:11:06,360 iteration 3706 : loss : 0.023751, loss_ce: 0.007497
 55%|██████████████▋            | 218/400 [1:31:54<1:23:44, 27.61s/it]2022-01-16 01:11:08,086 iteration 3707 : loss : 0.018305, loss_ce: 0.008167
2022-01-16 01:11:09,566 iteration 3708 : loss : 0.021927, loss_ce: 0.007662
2022-01-16 01:11:11,163 iteration 3709 : loss : 0.026762, loss_ce: 0.008175
2022-01-16 01:11:12,851 iteration 3710 : loss : 0.027851, loss_ce: 0.009861
2022-01-16 01:11:14,360 iteration 3711 : loss : 0.021015, loss_ce: 0.007302
2022-01-16 01:11:15,870 iteration 3712 : loss : 0.020243, loss_ce: 0.009289
2022-01-16 01:11:17,522 iteration 3713 : loss : 0.027055, loss_ce: 0.009501
2022-01-16 01:11:19,111 iteration 3714 : loss : 0.025428, loss_ce: 0.009670
2022-01-16 01:11:20,623 iteration 3715 : loss : 0.017887, loss_ce: 0.007313
2022-01-16 01:11:22,136 iteration 3716 : loss : 0.029872, loss_ce: 0.017306
2022-01-16 01:11:23,678 iteration 3717 : loss : 0.019072, loss_ce: 0.007091
2022-01-16 01:11:25,235 iteration 3718 : loss : 0.025181, loss_ce: 0.008820
2022-01-16 01:11:26,762 iteration 3719 : loss : 0.024235, loss_ce: 0.009593
2022-01-16 01:11:28,330 iteration 3720 : loss : 0.034766, loss_ce: 0.011729
2022-01-16 01:11:29,766 iteration 3721 : loss : 0.018763, loss_ce: 0.006844
2022-01-16 01:11:31,225 iteration 3722 : loss : 0.024477, loss_ce: 0.010809
2022-01-16 01:11:32,747 iteration 3723 : loss : 0.032347, loss_ce: 0.008513
 55%|██████████████▊            | 219/400 [1:32:21<1:22:10, 27.24s/it]2022-01-16 01:11:34,315 iteration 3724 : loss : 0.028299, loss_ce: 0.011737
2022-01-16 01:11:35,813 iteration 3725 : loss : 0.033904, loss_ce: 0.015153
2022-01-16 01:11:37,427 iteration 3726 : loss : 0.024189, loss_ce: 0.007604
2022-01-16 01:11:39,028 iteration 3727 : loss : 0.024883, loss_ce: 0.007313
2022-01-16 01:11:40,601 iteration 3728 : loss : 0.026425, loss_ce: 0.014267
2022-01-16 01:11:42,209 iteration 3729 : loss : 0.032391, loss_ce: 0.010300
2022-01-16 01:11:43,689 iteration 3730 : loss : 0.030051, loss_ce: 0.009222
2022-01-16 01:11:45,267 iteration 3731 : loss : 0.023049, loss_ce: 0.008569
2022-01-16 01:11:46,782 iteration 3732 : loss : 0.037163, loss_ce: 0.016250
2022-01-16 01:11:48,508 iteration 3733 : loss : 0.025169, loss_ce: 0.007593
2022-01-16 01:11:50,064 iteration 3734 : loss : 0.022300, loss_ce: 0.008798
2022-01-16 01:11:51,676 iteration 3735 : loss : 0.042991, loss_ce: 0.020621
2022-01-16 01:11:53,300 iteration 3736 : loss : 0.042747, loss_ce: 0.012241
2022-01-16 01:11:54,874 iteration 3737 : loss : 0.028788, loss_ce: 0.010948
2022-01-16 01:11:56,378 iteration 3738 : loss : 0.026173, loss_ce: 0.012087
2022-01-16 01:11:57,941 iteration 3739 : loss : 0.023461, loss_ce: 0.007912
2022-01-16 01:11:57,942 Training Data Eval:
2022-01-16 01:12:05,956   Average segmentation loss on training set: 0.0185
2022-01-16 01:12:05,956 Validation Data Eval:
2022-01-16 01:12:08,878   Average segmentation loss on validation set: 0.0817
2022-01-16 01:12:10,503 iteration 3740 : loss : 0.020528, loss_ce: 0.006899
 55%|██████████████▊            | 220/400 [1:32:58<1:31:11, 30.40s/it]2022-01-16 01:12:12,200 iteration 3741 : loss : 0.023807, loss_ce: 0.009988
2022-01-16 01:12:13,761 iteration 3742 : loss : 0.025592, loss_ce: 0.012333
2022-01-16 01:12:15,248 iteration 3743 : loss : 0.032383, loss_ce: 0.011800
2022-01-16 01:12:16,834 iteration 3744 : loss : 0.022204, loss_ce: 0.010502
2022-01-16 01:12:18,459 iteration 3745 : loss : 0.021471, loss_ce: 0.007857
2022-01-16 01:12:20,164 iteration 3746 : loss : 0.018485, loss_ce: 0.007234
2022-01-16 01:12:21,725 iteration 3747 : loss : 0.061398, loss_ce: 0.008743
2022-01-16 01:12:23,216 iteration 3748 : loss : 0.054805, loss_ce: 0.032983
2022-01-16 01:12:24,709 iteration 3749 : loss : 0.029438, loss_ce: 0.012203
2022-01-16 01:12:26,166 iteration 3750 : loss : 0.029071, loss_ce: 0.011993
2022-01-16 01:12:27,544 iteration 3751 : loss : 0.034694, loss_ce: 0.009497
2022-01-16 01:12:28,836 iteration 3752 : loss : 0.027115, loss_ce: 0.011629
2022-01-16 01:12:30,048 iteration 3753 : loss : 0.026865, loss_ce: 0.007265
2022-01-16 01:12:31,207 iteration 3754 : loss : 0.019722, loss_ce: 0.007787
2022-01-16 01:12:32,366 iteration 3755 : loss : 0.023233, loss_ce: 0.009913
2022-01-16 01:12:33,531 iteration 3756 : loss : 0.035667, loss_ce: 0.012614
2022-01-16 01:12:34,671 iteration 3757 : loss : 0.032348, loss_ce: 0.010279
 55%|██████████████▉            | 221/400 [1:33:22<1:25:06, 28.53s/it]2022-01-16 01:12:35,875 iteration 3758 : loss : 0.033948, loss_ce: 0.014414
2022-01-16 01:12:36,974 iteration 3759 : loss : 0.031915, loss_ce: 0.014428
2022-01-16 01:12:38,026 iteration 3760 : loss : 0.029147, loss_ce: 0.008565
2022-01-16 01:12:39,213 iteration 3761 : loss : 0.025910, loss_ce: 0.012501
2022-01-16 01:12:40,414 iteration 3762 : loss : 0.036440, loss_ce: 0.010756
2022-01-16 01:12:41,689 iteration 3763 : loss : 0.032540, loss_ce: 0.012696
2022-01-16 01:12:42,911 iteration 3764 : loss : 0.027973, loss_ce: 0.010997
2022-01-16 01:12:44,096 iteration 3765 : loss : 0.022518, loss_ce: 0.008936
2022-01-16 01:12:45,279 iteration 3766 : loss : 0.019350, loss_ce: 0.007195
2022-01-16 01:12:46,515 iteration 3767 : loss : 0.032689, loss_ce: 0.011395
2022-01-16 01:12:47,667 iteration 3768 : loss : 0.025748, loss_ce: 0.010875
2022-01-16 01:12:48,790 iteration 3769 : loss : 0.020148, loss_ce: 0.008550
2022-01-16 01:12:49,866 iteration 3770 : loss : 0.018445, loss_ce: 0.006268
2022-01-16 01:12:50,950 iteration 3771 : loss : 0.016917, loss_ce: 0.006396
2022-01-16 01:12:52,079 iteration 3772 : loss : 0.023398, loss_ce: 0.007853
2022-01-16 01:12:53,147 iteration 3773 : loss : 0.016526, loss_ce: 0.005892
2022-01-16 01:12:54,211 iteration 3774 : loss : 0.028054, loss_ce: 0.010828
 56%|██████████████▉            | 222/400 [1:33:42<1:16:37, 25.83s/it]2022-01-16 01:12:55,354 iteration 3775 : loss : 0.023291, loss_ce: 0.006886
2022-01-16 01:12:56,541 iteration 3776 : loss : 0.025045, loss_ce: 0.011040
2022-01-16 01:12:57,823 iteration 3777 : loss : 0.041395, loss_ce: 0.015333
2022-01-16 01:12:58,998 iteration 3778 : loss : 0.019220, loss_ce: 0.009787
2022-01-16 01:13:00,242 iteration 3779 : loss : 0.019217, loss_ce: 0.006826
2022-01-16 01:13:01,469 iteration 3780 : loss : 0.020987, loss_ce: 0.010322
2022-01-16 01:13:02,740 iteration 3781 : loss : 0.022810, loss_ce: 0.008317
2022-01-16 01:13:04,186 iteration 3782 : loss : 0.026911, loss_ce: 0.009052
2022-01-16 01:13:05,667 iteration 3783 : loss : 0.016160, loss_ce: 0.005025
2022-01-16 01:13:07,184 iteration 3784 : loss : 0.030137, loss_ce: 0.014200
2022-01-16 01:13:08,831 iteration 3785 : loss : 0.018838, loss_ce: 0.006493
2022-01-16 01:13:10,361 iteration 3786 : loss : 0.023694, loss_ce: 0.008595
2022-01-16 01:13:11,950 iteration 3787 : loss : 0.060239, loss_ce: 0.021982
2022-01-16 01:13:13,667 iteration 3788 : loss : 0.025234, loss_ce: 0.009126
2022-01-16 01:13:15,300 iteration 3789 : loss : 0.024644, loss_ce: 0.007205
2022-01-16 01:13:16,900 iteration 3790 : loss : 0.025911, loss_ce: 0.009913
2022-01-16 01:13:18,375 iteration 3791 : loss : 0.019408, loss_ce: 0.007775
 56%|███████████████            | 223/400 [1:34:06<1:14:43, 25.33s/it]2022-01-16 01:13:19,938 iteration 3792 : loss : 0.017688, loss_ce: 0.007574
2022-01-16 01:13:21,668 iteration 3793 : loss : 0.021416, loss_ce: 0.008883
2022-01-16 01:13:23,184 iteration 3794 : loss : 0.018618, loss_ce: 0.007121
2022-01-16 01:13:24,866 iteration 3795 : loss : 0.025461, loss_ce: 0.010891
2022-01-16 01:13:26,476 iteration 3796 : loss : 0.047213, loss_ce: 0.010614
2022-01-16 01:13:28,014 iteration 3797 : loss : 0.027303, loss_ce: 0.010141
2022-01-16 01:13:29,614 iteration 3798 : loss : 0.023697, loss_ce: 0.009049
2022-01-16 01:13:31,145 iteration 3799 : loss : 0.020926, loss_ce: 0.011922
2022-01-16 01:13:32,826 iteration 3800 : loss : 0.024009, loss_ce: 0.008048
2022-01-16 01:13:34,488 iteration 3801 : loss : 0.017416, loss_ce: 0.006104
2022-01-16 01:13:36,054 iteration 3802 : loss : 0.021019, loss_ce: 0.005972
2022-01-16 01:13:37,552 iteration 3803 : loss : 0.020930, loss_ce: 0.007625
2022-01-16 01:13:39,133 iteration 3804 : loss : 0.020648, loss_ce: 0.008412
2022-01-16 01:13:40,670 iteration 3805 : loss : 0.022168, loss_ce: 0.008919
2022-01-16 01:13:42,345 iteration 3806 : loss : 0.026378, loss_ce: 0.007024
2022-01-16 01:13:43,876 iteration 3807 : loss : 0.022658, loss_ce: 0.009165
2022-01-16 01:13:45,459 iteration 3808 : loss : 0.027360, loss_ce: 0.011246
 56%|███████████████            | 224/400 [1:34:33<1:15:51, 25.86s/it]2022-01-16 01:13:47,192 iteration 3809 : loss : 0.022145, loss_ce: 0.009160
2022-01-16 01:13:48,893 iteration 3810 : loss : 0.023672, loss_ce: 0.007892
2022-01-16 01:13:50,568 iteration 3811 : loss : 0.022592, loss_ce: 0.006734
2022-01-16 01:13:52,146 iteration 3812 : loss : 0.023688, loss_ce: 0.008772
2022-01-16 01:13:53,885 iteration 3813 : loss : 0.033963, loss_ce: 0.010153
2022-01-16 01:13:55,465 iteration 3814 : loss : 0.017127, loss_ce: 0.005922
2022-01-16 01:13:57,039 iteration 3815 : loss : 0.033914, loss_ce: 0.012090
2022-01-16 01:13:58,747 iteration 3816 : loss : 0.025062, loss_ce: 0.008102
2022-01-16 01:14:00,443 iteration 3817 : loss : 0.021371, loss_ce: 0.009508
2022-01-16 01:14:02,136 iteration 3818 : loss : 0.026525, loss_ce: 0.010490
2022-01-16 01:14:03,661 iteration 3819 : loss : 0.021980, loss_ce: 0.010224
2022-01-16 01:14:05,212 iteration 3820 : loss : 0.023539, loss_ce: 0.009205
2022-01-16 01:14:06,814 iteration 3821 : loss : 0.020671, loss_ce: 0.009668
2022-01-16 01:14:08,373 iteration 3822 : loss : 0.020797, loss_ce: 0.009726
2022-01-16 01:14:09,899 iteration 3823 : loss : 0.020959, loss_ce: 0.007284
2022-01-16 01:14:11,405 iteration 3824 : loss : 0.030486, loss_ce: 0.010951
2022-01-16 01:14:11,406 Training Data Eval:
2022-01-16 01:14:18,723   Average segmentation loss on training set: 0.0150
2022-01-16 01:14:18,723 Validation Data Eval:
2022-01-16 01:14:21,157   Average segmentation loss on validation set: 0.0705
2022-01-16 01:14:22,517 iteration 3825 : loss : 0.034383, loss_ce: 0.015157
 56%|███████████████▏           | 225/400 [1:35:10<1:25:13, 29.22s/it]2022-01-16 01:14:23,896 iteration 3826 : loss : 0.020273, loss_ce: 0.008096
2022-01-16 01:14:25,320 iteration 3827 : loss : 0.022989, loss_ce: 0.009126
2022-01-16 01:14:26,752 iteration 3828 : loss : 0.022072, loss_ce: 0.009378
2022-01-16 01:14:28,214 iteration 3829 : loss : 0.022347, loss_ce: 0.010117
2022-01-16 01:14:29,792 iteration 3830 : loss : 0.034671, loss_ce: 0.016329
2022-01-16 01:14:31,383 iteration 3831 : loss : 0.039160, loss_ce: 0.009671
2022-01-16 01:14:32,948 iteration 3832 : loss : 0.016626, loss_ce: 0.005996
2022-01-16 01:14:34,487 iteration 3833 : loss : 0.020893, loss_ce: 0.006969
2022-01-16 01:14:35,969 iteration 3834 : loss : 0.017550, loss_ce: 0.008112
2022-01-16 01:14:37,603 iteration 3835 : loss : 0.021030, loss_ce: 0.010159
2022-01-16 01:14:39,246 iteration 3836 : loss : 0.020362, loss_ce: 0.006687
2022-01-16 01:14:40,873 iteration 3837 : loss : 0.019440, loss_ce: 0.007339
2022-01-16 01:14:42,393 iteration 3838 : loss : 0.034944, loss_ce: 0.011216
2022-01-16 01:14:43,934 iteration 3839 : loss : 0.032495, loss_ce: 0.013512
2022-01-16 01:14:45,644 iteration 3840 : loss : 0.024903, loss_ce: 0.006586
2022-01-16 01:14:47,255 iteration 3841 : loss : 0.020141, loss_ce: 0.006478
2022-01-16 01:14:48,809 iteration 3842 : loss : 0.024688, loss_ce: 0.006094
 56%|███████████████▎           | 226/400 [1:35:37<1:22:10, 28.34s/it]2022-01-16 01:14:50,483 iteration 3843 : loss : 0.023343, loss_ce: 0.010023
2022-01-16 01:14:52,023 iteration 3844 : loss : 0.065011, loss_ce: 0.030143
2022-01-16 01:14:53,634 iteration 3845 : loss : 0.029995, loss_ce: 0.011609
2022-01-16 01:14:55,190 iteration 3846 : loss : 0.030757, loss_ce: 0.005635
2022-01-16 01:14:56,780 iteration 3847 : loss : 0.017001, loss_ce: 0.006592
2022-01-16 01:14:58,412 iteration 3848 : loss : 0.020574, loss_ce: 0.008202
2022-01-16 01:15:00,023 iteration 3849 : loss : 0.020450, loss_ce: 0.007629
2022-01-16 01:15:01,702 iteration 3850 : loss : 0.036132, loss_ce: 0.007996
2022-01-16 01:15:03,319 iteration 3851 : loss : 0.046509, loss_ce: 0.024739
2022-01-16 01:15:04,962 iteration 3852 : loss : 0.027631, loss_ce: 0.009928
2022-01-16 01:15:06,493 iteration 3853 : loss : 0.022018, loss_ce: 0.012106
2022-01-16 01:15:08,130 iteration 3854 : loss : 0.044270, loss_ce: 0.018811
2022-01-16 01:15:09,866 iteration 3855 : loss : 0.028241, loss_ce: 0.011565
2022-01-16 01:15:11,442 iteration 3856 : loss : 0.033320, loss_ce: 0.011461
2022-01-16 01:15:13,014 iteration 3857 : loss : 0.020297, loss_ce: 0.008361
2022-01-16 01:15:14,776 iteration 3858 : loss : 0.032226, loss_ce: 0.012503
2022-01-16 01:15:16,376 iteration 3859 : loss : 0.054102, loss_ce: 0.016625
 57%|███████████████▎           | 227/400 [1:36:04<1:21:02, 28.11s/it]2022-01-16 01:15:18,081 iteration 3860 : loss : 0.020436, loss_ce: 0.009219
2022-01-16 01:15:19,791 iteration 3861 : loss : 0.027840, loss_ce: 0.013981
2022-01-16 01:15:21,295 iteration 3862 : loss : 0.026611, loss_ce: 0.012566
2022-01-16 01:15:22,987 iteration 3863 : loss : 0.023304, loss_ce: 0.011305
2022-01-16 01:15:24,641 iteration 3864 : loss : 0.023528, loss_ce: 0.009723
2022-01-16 01:15:26,415 iteration 3865 : loss : 0.028717, loss_ce: 0.015126
2022-01-16 01:15:28,232 iteration 3866 : loss : 0.035311, loss_ce: 0.015509
2022-01-16 01:15:29,802 iteration 3867 : loss : 0.018911, loss_ce: 0.007078
2022-01-16 01:15:31,573 iteration 3868 : loss : 0.030530, loss_ce: 0.012773
2022-01-16 01:15:33,162 iteration 3869 : loss : 0.023236, loss_ce: 0.008888
2022-01-16 01:15:34,853 iteration 3870 : loss : 0.022711, loss_ce: 0.006824
2022-01-16 01:15:36,486 iteration 3871 : loss : 0.030494, loss_ce: 0.008178
2022-01-16 01:15:38,191 iteration 3872 : loss : 0.024294, loss_ce: 0.010179
2022-01-16 01:15:39,778 iteration 3873 : loss : 0.024285, loss_ce: 0.008926
2022-01-16 01:15:41,524 iteration 3874 : loss : 0.024457, loss_ce: 0.008587
2022-01-16 01:15:43,296 iteration 3875 : loss : 0.021692, loss_ce: 0.008033
2022-01-16 01:15:44,978 iteration 3876 : loss : 0.046696, loss_ce: 0.009726
 57%|███████████████▍           | 228/400 [1:36:33<1:21:00, 28.26s/it]2022-01-16 01:15:46,601 iteration 3877 : loss : 0.024962, loss_ce: 0.009929
2022-01-16 01:15:48,375 iteration 3878 : loss : 0.025775, loss_ce: 0.013412
2022-01-16 01:15:50,098 iteration 3879 : loss : 0.028669, loss_ce: 0.013154
2022-01-16 01:15:51,793 iteration 3880 : loss : 0.021985, loss_ce: 0.008849
2022-01-16 01:15:53,336 iteration 3881 : loss : 0.021892, loss_ce: 0.010910
2022-01-16 01:15:54,984 iteration 3882 : loss : 0.048006, loss_ce: 0.015909
2022-01-16 01:15:56,598 iteration 3883 : loss : 0.031434, loss_ce: 0.015080
2022-01-16 01:15:58,222 iteration 3884 : loss : 0.028755, loss_ce: 0.005432
2022-01-16 01:15:59,751 iteration 3885 : loss : 0.019814, loss_ce: 0.006802
2022-01-16 01:16:01,311 iteration 3886 : loss : 0.024633, loss_ce: 0.008803
2022-01-16 01:16:03,103 iteration 3887 : loss : 0.024808, loss_ce: 0.010556
2022-01-16 01:16:04,673 iteration 3888 : loss : 0.026670, loss_ce: 0.010344
2022-01-16 01:16:06,282 iteration 3889 : loss : 0.024772, loss_ce: 0.010382
2022-01-16 01:16:07,762 iteration 3890 : loss : 0.020817, loss_ce: 0.007550
2022-01-16 01:16:09,285 iteration 3891 : loss : 0.016129, loss_ce: 0.006143
2022-01-16 01:16:10,824 iteration 3892 : loss : 0.033308, loss_ce: 0.008811
2022-01-16 01:16:12,381 iteration 3893 : loss : 0.041463, loss_ce: 0.025143
 57%|███████████████▍           | 229/400 [1:37:00<1:19:47, 28.00s/it]2022-01-16 01:16:13,789 iteration 3894 : loss : 0.017627, loss_ce: 0.007699
2022-01-16 01:16:15,202 iteration 3895 : loss : 0.025443, loss_ce: 0.009854
2022-01-16 01:16:16,504 iteration 3896 : loss : 0.028274, loss_ce: 0.008063
2022-01-16 01:16:17,830 iteration 3897 : loss : 0.036683, loss_ce: 0.015005
2022-01-16 01:16:19,122 iteration 3898 : loss : 0.019623, loss_ce: 0.007559
2022-01-16 01:16:20,457 iteration 3899 : loss : 0.025308, loss_ce: 0.011655
2022-01-16 01:16:21,833 iteration 3900 : loss : 0.041516, loss_ce: 0.015444
2022-01-16 01:16:23,082 iteration 3901 : loss : 0.020341, loss_ce: 0.006728
2022-01-16 01:16:24,350 iteration 3902 : loss : 0.019819, loss_ce: 0.007623
2022-01-16 01:16:25,627 iteration 3903 : loss : 0.021610, loss_ce: 0.007575
2022-01-16 01:16:26,942 iteration 3904 : loss : 0.023419, loss_ce: 0.009059
2022-01-16 01:16:28,192 iteration 3905 : loss : 0.026728, loss_ce: 0.012205
2022-01-16 01:16:29,438 iteration 3906 : loss : 0.023816, loss_ce: 0.011802
2022-01-16 01:16:30,729 iteration 3907 : loss : 0.023425, loss_ce: 0.007734
2022-01-16 01:16:32,076 iteration 3908 : loss : 0.031219, loss_ce: 0.012548
2022-01-16 01:16:33,401 iteration 3909 : loss : 0.020600, loss_ce: 0.007297
2022-01-16 01:16:33,402 Training Data Eval:
2022-01-16 01:16:39,871   Average segmentation loss on training set: 0.0169
2022-01-16 01:16:39,871 Validation Data Eval:
2022-01-16 01:16:42,172   Average segmentation loss on validation set: 0.0690
2022-01-16 01:16:43,464 iteration 3910 : loss : 0.018234, loss_ce: 0.006013
 57%|███████████████▌           | 230/400 [1:37:31<1:21:57, 28.92s/it]2022-01-16 01:16:44,906 iteration 3911 : loss : 0.026435, loss_ce: 0.009639
2022-01-16 01:16:46,391 iteration 3912 : loss : 0.022741, loss_ce: 0.009190
2022-01-16 01:16:47,752 iteration 3913 : loss : 0.019341, loss_ce: 0.005935
2022-01-16 01:16:49,137 iteration 3914 : loss : 0.021234, loss_ce: 0.007894
2022-01-16 01:16:50,537 iteration 3915 : loss : 0.017393, loss_ce: 0.006107
2022-01-16 01:16:52,028 iteration 3916 : loss : 0.021932, loss_ce: 0.007861
2022-01-16 01:16:53,472 iteration 3917 : loss : 0.033579, loss_ce: 0.008186
2022-01-16 01:16:54,910 iteration 3918 : loss : 0.026549, loss_ce: 0.011210
2022-01-16 01:16:56,261 iteration 3919 : loss : 0.022842, loss_ce: 0.008457
2022-01-16 01:16:57,601 iteration 3920 : loss : 0.030470, loss_ce: 0.016123
2022-01-16 01:16:58,902 iteration 3921 : loss : 0.029694, loss_ce: 0.009976
2022-01-16 01:17:00,127 iteration 3922 : loss : 0.014747, loss_ce: 0.005562
2022-01-16 01:17:01,366 iteration 3923 : loss : 0.020377, loss_ce: 0.008146
2022-01-16 01:17:02,587 iteration 3924 : loss : 0.024061, loss_ce: 0.010184
2022-01-16 01:17:03,912 iteration 3925 : loss : 0.022880, loss_ce: 0.009616
2022-01-16 01:17:05,073 iteration 3926 : loss : 0.018502, loss_ce: 0.006802
2022-01-16 01:17:06,264 iteration 3927 : loss : 0.028369, loss_ce: 0.011709
 58%|███████████████▌           | 231/400 [1:37:54<1:16:18, 27.09s/it]2022-01-16 01:17:07,520 iteration 3928 : loss : 0.025347, loss_ce: 0.009808
2022-01-16 01:17:08,763 iteration 3929 : loss : 0.028650, loss_ce: 0.012521
2022-01-16 01:17:10,093 iteration 3930 : loss : 0.038479, loss_ce: 0.016392
2022-01-16 01:17:11,303 iteration 3931 : loss : 0.024024, loss_ce: 0.011956
2022-01-16 01:17:12,556 iteration 3932 : loss : 0.025194, loss_ce: 0.006638
2022-01-16 01:17:13,798 iteration 3933 : loss : 0.024715, loss_ce: 0.006538
2022-01-16 01:17:15,131 iteration 3934 : loss : 0.024811, loss_ce: 0.007874
2022-01-16 01:17:16,612 iteration 3935 : loss : 0.025428, loss_ce: 0.009770
2022-01-16 01:17:18,094 iteration 3936 : loss : 0.025482, loss_ce: 0.012197
2022-01-16 01:17:19,600 iteration 3937 : loss : 0.018129, loss_ce: 0.005072
2022-01-16 01:17:21,092 iteration 3938 : loss : 0.018932, loss_ce: 0.007918
2022-01-16 01:17:22,707 iteration 3939 : loss : 0.032098, loss_ce: 0.011716
2022-01-16 01:17:24,188 iteration 3940 : loss : 0.027207, loss_ce: 0.006652
2022-01-16 01:17:25,643 iteration 3941 : loss : 0.020355, loss_ce: 0.009163
2022-01-16 01:17:27,035 iteration 3942 : loss : 0.032864, loss_ce: 0.015310
2022-01-16 01:17:28,449 iteration 3943 : loss : 0.023420, loss_ce: 0.011662
2022-01-16 01:17:29,836 iteration 3944 : loss : 0.019038, loss_ce: 0.005565
 58%|███████████████▋           | 232/400 [1:38:18<1:12:53, 26.03s/it]2022-01-16 01:17:31,273 iteration 3945 : loss : 0.015895, loss_ce: 0.007161
2022-01-16 01:17:32,597 iteration 3946 : loss : 0.016248, loss_ce: 0.006411
2022-01-16 01:17:33,956 iteration 3947 : loss : 0.017036, loss_ce: 0.006029
2022-01-16 01:17:35,321 iteration 3948 : loss : 0.026845, loss_ce: 0.011954
2022-01-16 01:17:36,698 iteration 3949 : loss : 0.025467, loss_ce: 0.012392
2022-01-16 01:17:38,061 iteration 3950 : loss : 0.020874, loss_ce: 0.008146
2022-01-16 01:17:39,428 iteration 3951 : loss : 0.021747, loss_ce: 0.008912
2022-01-16 01:17:40,714 iteration 3952 : loss : 0.019340, loss_ce: 0.009172
2022-01-16 01:17:41,971 iteration 3953 : loss : 0.020900, loss_ce: 0.007122
2022-01-16 01:17:43,242 iteration 3954 : loss : 0.023613, loss_ce: 0.008699
2022-01-16 01:17:44,463 iteration 3955 : loss : 0.019491, loss_ce: 0.006890
2022-01-16 01:17:45,626 iteration 3956 : loss : 0.023989, loss_ce: 0.010120
2022-01-16 01:17:46,794 iteration 3957 : loss : 0.022731, loss_ce: 0.009705
2022-01-16 01:17:48,091 iteration 3958 : loss : 0.023500, loss_ce: 0.009959
2022-01-16 01:17:49,257 iteration 3959 : loss : 0.018643, loss_ce: 0.005706
2022-01-16 01:17:50,448 iteration 3960 : loss : 0.022038, loss_ce: 0.005171
2022-01-16 01:17:51,638 iteration 3961 : loss : 0.015956, loss_ce: 0.005645
 58%|███████████████▋           | 233/400 [1:38:39<1:08:55, 24.76s/it]2022-01-16 01:17:52,941 iteration 3962 : loss : 0.030117, loss_ce: 0.012606
2022-01-16 01:17:53,984 iteration 3963 : loss : 0.019318, loss_ce: 0.008028
2022-01-16 01:17:55,109 iteration 3964 : loss : 0.032144, loss_ce: 0.014362
2022-01-16 01:17:56,264 iteration 3965 : loss : 0.033209, loss_ce: 0.009976
2022-01-16 01:17:57,306 iteration 3966 : loss : 0.019856, loss_ce: 0.007101
2022-01-16 01:17:58,369 iteration 3967 : loss : 0.019676, loss_ce: 0.005069
2022-01-16 01:17:59,536 iteration 3968 : loss : 0.021392, loss_ce: 0.008238
2022-01-16 01:18:00,667 iteration 3969 : loss : 0.020857, loss_ce: 0.009250
2022-01-16 01:18:01,790 iteration 3970 : loss : 0.026224, loss_ce: 0.013230
2022-01-16 01:18:02,809 iteration 3971 : loss : 0.018102, loss_ce: 0.006112
2022-01-16 01:18:03,827 iteration 3972 : loss : 0.022584, loss_ce: 0.007988
2022-01-16 01:18:04,906 iteration 3973 : loss : 0.027820, loss_ce: 0.010274
2022-01-16 01:18:06,028 iteration 3974 : loss : 0.024678, loss_ce: 0.011185
2022-01-16 01:18:07,138 iteration 3975 : loss : 0.019212, loss_ce: 0.006520
2022-01-16 01:18:08,271 iteration 3976 : loss : 0.031786, loss_ce: 0.016695
2022-01-16 01:18:09,311 iteration 3977 : loss : 0.024301, loss_ce: 0.009459
2022-01-16 01:18:10,354 iteration 3978 : loss : 0.022969, loss_ce: 0.010987
 58%|███████████████▊           | 234/400 [1:38:58<1:03:29, 22.95s/it]2022-01-16 01:18:11,521 iteration 3979 : loss : 0.024322, loss_ce: 0.007903
2022-01-16 01:18:12,665 iteration 3980 : loss : 0.022834, loss_ce: 0.010753
2022-01-16 01:18:13,797 iteration 3981 : loss : 0.021140, loss_ce: 0.008105
2022-01-16 01:18:15,146 iteration 3982 : loss : 0.023621, loss_ce: 0.007398
2022-01-16 01:18:16,420 iteration 3983 : loss : 0.031252, loss_ce: 0.009585
2022-01-16 01:18:17,758 iteration 3984 : loss : 0.021549, loss_ce: 0.008441
2022-01-16 01:18:19,142 iteration 3985 : loss : 0.023293, loss_ce: 0.007928
2022-01-16 01:18:20,532 iteration 3986 : loss : 0.019930, loss_ce: 0.007981
2022-01-16 01:18:22,013 iteration 3987 : loss : 0.016780, loss_ce: 0.007148
2022-01-16 01:18:23,555 iteration 3988 : loss : 0.022103, loss_ce: 0.010067
2022-01-16 01:18:25,005 iteration 3989 : loss : 0.023909, loss_ce: 0.008599
2022-01-16 01:18:26,439 iteration 3990 : loss : 0.017964, loss_ce: 0.007027
2022-01-16 01:18:27,990 iteration 3991 : loss : 0.040695, loss_ce: 0.015772
2022-01-16 01:18:29,622 iteration 3992 : loss : 0.052193, loss_ce: 0.012774
2022-01-16 01:18:31,117 iteration 3993 : loss : 0.022093, loss_ce: 0.010386
2022-01-16 01:18:32,622 iteration 3994 : loss : 0.019860, loss_ce: 0.008010
2022-01-16 01:18:32,623 Training Data Eval:
2022-01-16 01:18:40,365   Average segmentation loss on training set: 0.0148
2022-01-16 01:18:40,366 Validation Data Eval:
2022-01-16 01:18:43,135   Average segmentation loss on validation set: 0.0719
2022-01-16 01:18:44,683 iteration 3995 : loss : 0.023817, loss_ce: 0.005882
 59%|███████████████▊           | 235/400 [1:39:33<1:12:29, 26.36s/it]2022-01-16 01:18:46,461 iteration 3996 : loss : 0.027781, loss_ce: 0.015013
2022-01-16 01:18:48,011 iteration 3997 : loss : 0.023473, loss_ce: 0.008245
2022-01-16 01:18:49,568 iteration 3998 : loss : 0.023709, loss_ce: 0.008780
2022-01-16 01:18:51,166 iteration 3999 : loss : 0.021592, loss_ce: 0.006434
2022-01-16 01:18:52,900 iteration 4000 : loss : 0.024472, loss_ce: 0.010651
2022-01-16 01:18:54,619 iteration 4001 : loss : 0.028525, loss_ce: 0.007840
2022-01-16 01:18:56,183 iteration 4002 : loss : 0.024078, loss_ce: 0.011081
2022-01-16 01:18:57,695 iteration 4003 : loss : 0.021372, loss_ce: 0.008240
2022-01-16 01:18:59,229 iteration 4004 : loss : 0.029394, loss_ce: 0.011638
2022-01-16 01:19:00,902 iteration 4005 : loss : 0.028426, loss_ce: 0.012991
2022-01-16 01:19:02,521 iteration 4006 : loss : 0.028353, loss_ce: 0.008709
2022-01-16 01:19:04,049 iteration 4007 : loss : 0.018949, loss_ce: 0.007374
2022-01-16 01:19:05,757 iteration 4008 : loss : 0.027060, loss_ce: 0.008274
2022-01-16 01:19:07,327 iteration 4009 : loss : 0.018592, loss_ce: 0.007179
2022-01-16 01:19:08,854 iteration 4010 : loss : 0.014855, loss_ce: 0.005348
2022-01-16 01:19:10,413 iteration 4011 : loss : 0.023169, loss_ce: 0.006864
2022-01-16 01:19:12,047 iteration 4012 : loss : 0.033354, loss_ce: 0.014627
 59%|███████████████▉           | 236/400 [1:40:00<1:12:52, 26.66s/it]2022-01-16 01:19:13,630 iteration 4013 : loss : 0.021526, loss_ce: 0.005763
2022-01-16 01:19:15,230 iteration 4014 : loss : 0.023000, loss_ce: 0.008604
2022-01-16 01:19:16,774 iteration 4015 : loss : 0.018877, loss_ce: 0.009907
2022-01-16 01:19:18,396 iteration 4016 : loss : 0.021667, loss_ce: 0.006618
2022-01-16 01:19:19,941 iteration 4017 : loss : 0.022862, loss_ce: 0.008741
2022-01-16 01:19:21,670 iteration 4018 : loss : 0.026242, loss_ce: 0.008237
2022-01-16 01:19:23,409 iteration 4019 : loss : 0.027858, loss_ce: 0.012662
2022-01-16 01:19:24,911 iteration 4020 : loss : 0.019679, loss_ce: 0.006714
2022-01-16 01:19:26,411 iteration 4021 : loss : 0.019065, loss_ce: 0.006752
2022-01-16 01:19:27,871 iteration 4022 : loss : 0.026562, loss_ce: 0.008506
2022-01-16 01:19:29,338 iteration 4023 : loss : 0.021170, loss_ce: 0.009458
2022-01-16 01:19:30,874 iteration 4024 : loss : 0.022280, loss_ce: 0.007228
2022-01-16 01:19:32,465 iteration 4025 : loss : 0.019484, loss_ce: 0.007509
2022-01-16 01:19:34,008 iteration 4026 : loss : 0.015641, loss_ce: 0.006234
2022-01-16 01:19:35,577 iteration 4027 : loss : 0.020506, loss_ce: 0.007454
2022-01-16 01:19:37,174 iteration 4028 : loss : 0.018990, loss_ce: 0.005150
2022-01-16 01:19:38,767 iteration 4029 : loss : 0.017548, loss_ce: 0.006579
 59%|███████████████▉           | 237/400 [1:40:27<1:12:28, 26.68s/it]2022-01-16 01:19:40,469 iteration 4030 : loss : 0.027378, loss_ce: 0.010261
2022-01-16 01:19:41,991 iteration 4031 : loss : 0.019890, loss_ce: 0.007243
2022-01-16 01:19:43,537 iteration 4032 : loss : 0.021358, loss_ce: 0.008386
2022-01-16 01:19:45,143 iteration 4033 : loss : 0.030116, loss_ce: 0.007375
2022-01-16 01:19:46,689 iteration 4034 : loss : 0.022320, loss_ce: 0.007656
2022-01-16 01:19:48,282 iteration 4035 : loss : 0.023763, loss_ce: 0.007938
2022-01-16 01:19:49,849 iteration 4036 : loss : 0.021553, loss_ce: 0.008215
2022-01-16 01:19:51,428 iteration 4037 : loss : 0.020937, loss_ce: 0.006453
2022-01-16 01:19:52,952 iteration 4038 : loss : 0.022351, loss_ce: 0.013272
2022-01-16 01:19:54,535 iteration 4039 : loss : 0.019992, loss_ce: 0.009376
2022-01-16 01:19:56,058 iteration 4040 : loss : 0.027613, loss_ce: 0.006518
2022-01-16 01:19:57,662 iteration 4041 : loss : 0.053100, loss_ce: 0.027913
2022-01-16 01:19:59,060 iteration 4042 : loss : 0.018638, loss_ce: 0.008326
2022-01-16 01:20:00,522 iteration 4043 : loss : 0.019354, loss_ce: 0.007126
2022-01-16 01:20:01,981 iteration 4044 : loss : 0.020132, loss_ce: 0.008290
2022-01-16 01:20:03,577 iteration 4045 : loss : 0.023545, loss_ce: 0.011879
2022-01-16 01:20:05,151 iteration 4046 : loss : 0.018109, loss_ce: 0.006514
 60%|████████████████           | 238/400 [1:40:53<1:11:47, 26.59s/it]2022-01-16 01:20:06,733 iteration 4047 : loss : 0.021366, loss_ce: 0.009244
2022-01-16 01:20:08,313 iteration 4048 : loss : 0.016185, loss_ce: 0.005002
2022-01-16 01:20:09,968 iteration 4049 : loss : 0.031212, loss_ce: 0.010388
2022-01-16 01:20:11,536 iteration 4050 : loss : 0.022885, loss_ce: 0.006550
2022-01-16 01:20:13,127 iteration 4051 : loss : 0.014972, loss_ce: 0.004925
2022-01-16 01:20:14,654 iteration 4052 : loss : 0.018462, loss_ce: 0.005295
2022-01-16 01:20:16,147 iteration 4053 : loss : 0.022991, loss_ce: 0.012256
2022-01-16 01:20:17,645 iteration 4054 : loss : 0.022897, loss_ce: 0.009677
2022-01-16 01:20:19,242 iteration 4055 : loss : 0.023260, loss_ce: 0.006970
2022-01-16 01:20:20,772 iteration 4056 : loss : 0.026531, loss_ce: 0.008195
2022-01-16 01:20:22,297 iteration 4057 : loss : 0.031670, loss_ce: 0.016489
2022-01-16 01:20:23,668 iteration 4058 : loss : 0.023532, loss_ce: 0.009750
2022-01-16 01:20:25,197 iteration 4059 : loss : 0.024119, loss_ce: 0.010506
2022-01-16 01:20:26,893 iteration 4060 : loss : 0.020163, loss_ce: 0.007556
2022-01-16 01:20:28,418 iteration 4061 : loss : 0.042561, loss_ce: 0.013186
2022-01-16 01:20:30,057 iteration 4062 : loss : 0.024027, loss_ce: 0.010849
2022-01-16 01:20:31,675 iteration 4063 : loss : 0.047830, loss_ce: 0.018669
 60%|████████████████▏          | 239/400 [1:41:20<1:11:18, 26.57s/it]2022-01-16 01:20:33,270 iteration 4064 : loss : 0.020854, loss_ce: 0.007896
2022-01-16 01:20:34,936 iteration 4065 : loss : 0.021395, loss_ce: 0.008516
2022-01-16 01:20:36,416 iteration 4066 : loss : 0.016277, loss_ce: 0.005378
2022-01-16 01:20:37,923 iteration 4067 : loss : 0.023018, loss_ce: 0.006627
2022-01-16 01:20:39,510 iteration 4068 : loss : 0.029095, loss_ce: 0.011095
2022-01-16 01:20:41,255 iteration 4069 : loss : 0.021831, loss_ce: 0.006773
2022-01-16 01:20:42,849 iteration 4070 : loss : 0.024526, loss_ce: 0.012977
2022-01-16 01:20:44,380 iteration 4071 : loss : 0.022982, loss_ce: 0.010051
2022-01-16 01:20:45,981 iteration 4072 : loss : 0.021823, loss_ce: 0.009089
2022-01-16 01:20:47,716 iteration 4073 : loss : 0.022956, loss_ce: 0.011124
2022-01-16 01:20:49,306 iteration 4074 : loss : 0.035313, loss_ce: 0.011937
2022-01-16 01:20:50,951 iteration 4075 : loss : 0.027792, loss_ce: 0.011701
2022-01-16 01:20:52,561 iteration 4076 : loss : 0.019047, loss_ce: 0.006595
2022-01-16 01:20:54,125 iteration 4077 : loss : 0.016641, loss_ce: 0.007186
2022-01-16 01:20:55,697 iteration 4078 : loss : 0.031221, loss_ce: 0.009516
2022-01-16 01:20:57,208 iteration 4079 : loss : 0.018352, loss_ce: 0.006601
2022-01-16 01:20:57,208 Training Data Eval:
2022-01-16 01:21:05,287   Average segmentation loss on training set: 0.0159
2022-01-16 01:21:05,287 Validation Data Eval:
2022-01-16 01:21:08,051   Average segmentation loss on validation set: 0.0625
2022-01-16 01:21:09,069 Found new lowest validation loss at iteration 4079! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed2.pth
2022-01-16 01:21:10,514 iteration 4080 : loss : 0.024861, loss_ce: 0.007592
 60%|████████████████▏          | 240/400 [1:41:58<1:20:40, 30.25s/it]2022-01-16 01:21:12,080 iteration 4081 : loss : 0.021692, loss_ce: 0.010949
2022-01-16 01:21:13,719 iteration 4082 : loss : 0.029611, loss_ce: 0.011403
2022-01-16 01:21:15,263 iteration 4083 : loss : 0.023043, loss_ce: 0.009756
2022-01-16 01:21:16,813 iteration 4084 : loss : 0.019451, loss_ce: 0.006869
2022-01-16 01:21:18,523 iteration 4085 : loss : 0.022831, loss_ce: 0.004688
2022-01-16 01:21:20,065 iteration 4086 : loss : 0.021569, loss_ce: 0.007723
2022-01-16 01:21:21,662 iteration 4087 : loss : 0.028264, loss_ce: 0.008499
2022-01-16 01:21:23,386 iteration 4088 : loss : 0.019821, loss_ce: 0.008901
2022-01-16 01:21:24,934 iteration 4089 : loss : 0.033755, loss_ce: 0.013524
2022-01-16 01:21:26,677 iteration 4090 : loss : 0.029201, loss_ce: 0.013058
2022-01-16 01:21:28,239 iteration 4091 : loss : 0.024814, loss_ce: 0.008618
2022-01-16 01:21:29,892 iteration 4092 : loss : 0.024377, loss_ce: 0.007561
2022-01-16 01:21:31,602 iteration 4093 : loss : 0.020525, loss_ce: 0.009200
2022-01-16 01:21:33,239 iteration 4094 : loss : 0.031574, loss_ce: 0.014481
2022-01-16 01:21:34,760 iteration 4095 : loss : 0.036781, loss_ce: 0.013262
2022-01-16 01:21:36,336 iteration 4096 : loss : 0.020664, loss_ce: 0.008138
2022-01-16 01:21:38,017 iteration 4097 : loss : 0.019885, loss_ce: 0.008732
 60%|████████████████▎          | 241/400 [1:42:26<1:17:58, 29.43s/it]2022-01-16 01:21:39,641 iteration 4098 : loss : 0.018207, loss_ce: 0.007057
2022-01-16 01:21:41,326 iteration 4099 : loss : 0.022856, loss_ce: 0.008245
2022-01-16 01:21:42,823 iteration 4100 : loss : 0.019716, loss_ce: 0.008082
2022-01-16 01:21:44,397 iteration 4101 : loss : 0.019168, loss_ce: 0.009250
2022-01-16 01:21:46,152 iteration 4102 : loss : 0.027461, loss_ce: 0.009193
2022-01-16 01:21:47,662 iteration 4103 : loss : 0.015104, loss_ce: 0.006640
2022-01-16 01:21:49,213 iteration 4104 : loss : 0.025369, loss_ce: 0.009192
2022-01-16 01:21:50,749 iteration 4105 : loss : 0.022556, loss_ce: 0.008338
2022-01-16 01:21:52,295 iteration 4106 : loss : 0.035632, loss_ce: 0.016062
2022-01-16 01:21:53,845 iteration 4107 : loss : 0.022951, loss_ce: 0.007971
2022-01-16 01:21:55,468 iteration 4108 : loss : 0.032761, loss_ce: 0.014086
2022-01-16 01:21:57,028 iteration 4109 : loss : 0.021834, loss_ce: 0.005809
2022-01-16 01:21:58,603 iteration 4110 : loss : 0.024260, loss_ce: 0.007454
2022-01-16 01:22:00,128 iteration 4111 : loss : 0.020540, loss_ce: 0.005540
2022-01-16 01:22:01,547 iteration 4112 : loss : 0.014344, loss_ce: 0.005717
2022-01-16 01:22:03,193 iteration 4113 : loss : 0.023490, loss_ce: 0.007466
2022-01-16 01:22:04,762 iteration 4114 : loss : 0.023145, loss_ce: 0.009483
 60%|████████████████▎          | 242/400 [1:42:53<1:15:22, 28.62s/it]2022-01-16 01:22:06,325 iteration 4115 : loss : 0.022623, loss_ce: 0.005940
2022-01-16 01:22:07,761 iteration 4116 : loss : 0.016540, loss_ce: 0.007137
2022-01-16 01:22:09,145 iteration 4117 : loss : 0.017197, loss_ce: 0.008381
2022-01-16 01:22:10,549 iteration 4118 : loss : 0.023999, loss_ce: 0.006999
2022-01-16 01:22:11,920 iteration 4119 : loss : 0.017588, loss_ce: 0.006629
2022-01-16 01:22:13,515 iteration 4120 : loss : 0.020026, loss_ce: 0.005994
2022-01-16 01:22:14,992 iteration 4121 : loss : 0.020068, loss_ce: 0.008423
2022-01-16 01:22:16,534 iteration 4122 : loss : 0.027112, loss_ce: 0.009193
2022-01-16 01:22:18,071 iteration 4123 : loss : 0.025064, loss_ce: 0.008954
2022-01-16 01:22:19,511 iteration 4124 : loss : 0.018980, loss_ce: 0.007626
2022-01-16 01:22:21,006 iteration 4125 : loss : 0.035317, loss_ce: 0.011988
2022-01-16 01:22:22,593 iteration 4126 : loss : 0.020857, loss_ce: 0.009550
2022-01-16 01:22:24,077 iteration 4127 : loss : 0.023151, loss_ce: 0.010799
2022-01-16 01:22:25,489 iteration 4128 : loss : 0.019837, loss_ce: 0.009022
2022-01-16 01:22:27,002 iteration 4129 : loss : 0.035732, loss_ce: 0.010255
2022-01-16 01:22:28,469 iteration 4130 : loss : 0.024003, loss_ce: 0.006778
2022-01-16 01:22:29,866 iteration 4131 : loss : 0.018508, loss_ce: 0.008022
 61%|████████████████▍          | 243/400 [1:43:18<1:12:07, 27.57s/it]2022-01-16 01:22:31,361 iteration 4132 : loss : 0.025172, loss_ce: 0.009737
2022-01-16 01:22:32,659 iteration 4133 : loss : 0.025862, loss_ce: 0.012641
2022-01-16 01:22:34,022 iteration 4134 : loss : 0.017563, loss_ce: 0.007925
2022-01-16 01:22:35,366 iteration 4135 : loss : 0.030503, loss_ce: 0.009053
2022-01-16 01:22:36,708 iteration 4136 : loss : 0.028209, loss_ce: 0.008408
2022-01-16 01:22:38,087 iteration 4137 : loss : 0.023070, loss_ce: 0.012367
2022-01-16 01:22:39,541 iteration 4138 : loss : 0.018625, loss_ce: 0.009612
2022-01-16 01:22:41,039 iteration 4139 : loss : 0.051671, loss_ce: 0.012916
2022-01-16 01:22:42,552 iteration 4140 : loss : 0.031272, loss_ce: 0.009123
2022-01-16 01:22:43,992 iteration 4141 : loss : 0.022641, loss_ce: 0.005796
2022-01-16 01:22:45,381 iteration 4142 : loss : 0.020492, loss_ce: 0.009430
2022-01-16 01:22:46,742 iteration 4143 : loss : 0.020430, loss_ce: 0.007595
2022-01-16 01:22:48,156 iteration 4144 : loss : 0.023973, loss_ce: 0.008263
2022-01-16 01:22:49,508 iteration 4145 : loss : 0.024218, loss_ce: 0.009345
2022-01-16 01:22:50,774 iteration 4146 : loss : 0.024276, loss_ce: 0.006307
2022-01-16 01:22:52,094 iteration 4147 : loss : 0.023442, loss_ce: 0.008390
2022-01-16 01:22:53,404 iteration 4148 : loss : 0.025995, loss_ce: 0.010355
 61%|████████████████▍          | 244/400 [1:43:41<1:08:31, 26.36s/it]2022-01-16 01:22:54,797 iteration 4149 : loss : 0.024919, loss_ce: 0.009563
2022-01-16 01:22:56,103 iteration 4150 : loss : 0.032206, loss_ce: 0.011938
2022-01-16 01:22:57,413 iteration 4151 : loss : 0.019427, loss_ce: 0.007701
2022-01-16 01:22:58,807 iteration 4152 : loss : 0.028893, loss_ce: 0.013717
2022-01-16 01:23:00,121 iteration 4153 : loss : 0.024227, loss_ce: 0.011019
2022-01-16 01:23:01,426 iteration 4154 : loss : 0.017864, loss_ce: 0.006898
2022-01-16 01:23:02,856 iteration 4155 : loss : 0.020343, loss_ce: 0.009382
2022-01-16 01:23:04,345 iteration 4156 : loss : 0.024234, loss_ce: 0.007593
2022-01-16 01:23:05,791 iteration 4157 : loss : 0.021176, loss_ce: 0.007529
2022-01-16 01:23:07,181 iteration 4158 : loss : 0.015966, loss_ce: 0.006203
2022-01-16 01:23:08,596 iteration 4159 : loss : 0.014266, loss_ce: 0.006465
2022-01-16 01:23:09,964 iteration 4160 : loss : 0.026286, loss_ce: 0.010036
2022-01-16 01:23:11,323 iteration 4161 : loss : 0.019597, loss_ce: 0.005456
2022-01-16 01:23:12,777 iteration 4162 : loss : 0.026443, loss_ce: 0.008725
2022-01-16 01:23:14,211 iteration 4163 : loss : 0.031413, loss_ce: 0.011590
2022-01-16 01:23:15,646 iteration 4164 : loss : 0.019158, loss_ce: 0.005300
2022-01-16 01:23:15,647 Training Data Eval:
2022-01-16 01:23:23,575   Average segmentation loss on training set: 0.0138
2022-01-16 01:23:23,576 Validation Data Eval:
2022-01-16 01:23:26,470   Average segmentation loss on validation set: 0.0921
2022-01-16 01:23:28,062 iteration 4165 : loss : 0.017469, loss_ce: 0.005908
 61%|████████████████▌          | 245/400 [1:44:16<1:14:31, 28.85s/it]2022-01-16 01:23:29,653 iteration 4166 : loss : 0.033047, loss_ce: 0.009287
2022-01-16 01:23:31,380 iteration 4167 : loss : 0.015339, loss_ce: 0.006521
2022-01-16 01:23:32,912 iteration 4168 : loss : 0.019158, loss_ce: 0.004961
2022-01-16 01:23:34,461 iteration 4169 : loss : 0.022001, loss_ce: 0.009069
2022-01-16 01:23:36,195 iteration 4170 : loss : 0.030985, loss_ce: 0.009692
2022-01-16 01:23:38,026 iteration 4171 : loss : 0.025811, loss_ce: 0.009552
2022-01-16 01:23:39,563 iteration 4172 : loss : 0.018753, loss_ce: 0.004011
2022-01-16 01:23:41,303 iteration 4173 : loss : 0.032437, loss_ce: 0.011461
2022-01-16 01:23:43,026 iteration 4174 : loss : 0.023306, loss_ce: 0.009454
2022-01-16 01:23:44,642 iteration 4175 : loss : 0.023250, loss_ce: 0.008206
2022-01-16 01:23:46,245 iteration 4176 : loss : 0.022367, loss_ce: 0.009034
2022-01-16 01:23:47,876 iteration 4177 : loss : 0.032092, loss_ce: 0.010315
2022-01-16 01:23:49,598 iteration 4178 : loss : 0.026577, loss_ce: 0.011398
2022-01-16 01:23:51,253 iteration 4179 : loss : 0.021640, loss_ce: 0.008194
2022-01-16 01:23:52,838 iteration 4180 : loss : 0.065849, loss_ce: 0.022842
2022-01-16 01:23:54,449 iteration 4181 : loss : 0.027432, loss_ce: 0.008274
2022-01-16 01:23:56,062 iteration 4182 : loss : 0.021743, loss_ce: 0.008112
 62%|████████████████▌          | 246/400 [1:44:44<1:13:23, 28.59s/it]2022-01-16 01:23:57,714 iteration 4183 : loss : 0.020482, loss_ce: 0.006716
2022-01-16 01:23:59,262 iteration 4184 : loss : 0.021206, loss_ce: 0.007783
2022-01-16 01:24:00,755 iteration 4185 : loss : 0.020828, loss_ce: 0.007591
2022-01-16 01:24:02,238 iteration 4186 : loss : 0.019045, loss_ce: 0.006728
2022-01-16 01:24:03,828 iteration 4187 : loss : 0.032861, loss_ce: 0.012060
2022-01-16 01:24:05,393 iteration 4188 : loss : 0.026047, loss_ce: 0.012007
2022-01-16 01:24:06,927 iteration 4189 : loss : 0.022444, loss_ce: 0.005802
2022-01-16 01:24:08,483 iteration 4190 : loss : 0.023428, loss_ce: 0.008590
2022-01-16 01:24:09,975 iteration 4191 : loss : 0.022772, loss_ce: 0.007637
2022-01-16 01:24:11,556 iteration 4192 : loss : 0.016700, loss_ce: 0.004964
2022-01-16 01:24:13,095 iteration 4193 : loss : 0.019742, loss_ce: 0.006206
2022-01-16 01:24:14,704 iteration 4194 : loss : 0.020635, loss_ce: 0.009230
2022-01-16 01:24:16,359 iteration 4195 : loss : 0.040747, loss_ce: 0.012735
2022-01-16 01:24:17,821 iteration 4196 : loss : 0.016328, loss_ce: 0.008253
2022-01-16 01:24:19,375 iteration 4197 : loss : 0.024973, loss_ce: 0.007764
2022-01-16 01:24:20,880 iteration 4198 : loss : 0.020538, loss_ce: 0.007343
2022-01-16 01:24:22,284 iteration 4199 : loss : 0.023324, loss_ce: 0.009126
 62%|████████████████▋          | 247/400 [1:45:10<1:11:06, 27.88s/it]2022-01-16 01:24:23,817 iteration 4200 : loss : 0.018827, loss_ce: 0.005194
2022-01-16 01:24:25,344 iteration 4201 : loss : 0.022934, loss_ce: 0.010590
2022-01-16 01:24:26,844 iteration 4202 : loss : 0.017073, loss_ce: 0.007576
2022-01-16 01:24:28,395 iteration 4203 : loss : 0.019403, loss_ce: 0.008331
2022-01-16 01:24:29,960 iteration 4204 : loss : 0.020665, loss_ce: 0.007037
2022-01-16 01:24:31,514 iteration 4205 : loss : 0.016628, loss_ce: 0.006020
2022-01-16 01:24:32,993 iteration 4206 : loss : 0.021970, loss_ce: 0.006951
2022-01-16 01:24:34,536 iteration 4207 : loss : 0.016880, loss_ce: 0.007158
2022-01-16 01:24:36,098 iteration 4208 : loss : 0.023133, loss_ce: 0.008909
2022-01-16 01:24:37,718 iteration 4209 : loss : 0.037182, loss_ce: 0.011606
2022-01-16 01:24:39,261 iteration 4210 : loss : 0.020329, loss_ce: 0.007499
2022-01-16 01:24:40,788 iteration 4211 : loss : 0.015017, loss_ce: 0.005901
2022-01-16 01:24:42,311 iteration 4212 : loss : 0.023485, loss_ce: 0.008777
2022-01-16 01:24:43,813 iteration 4213 : loss : 0.027339, loss_ce: 0.013062
2022-01-16 01:24:45,455 iteration 4214 : loss : 0.020566, loss_ce: 0.007567
2022-01-16 01:24:47,014 iteration 4215 : loss : 0.019420, loss_ce: 0.006946
2022-01-16 01:24:48,612 iteration 4216 : loss : 0.035445, loss_ce: 0.011756
 62%|████████████████▋          | 248/400 [1:45:36<1:09:27, 27.42s/it]2022-01-16 01:24:50,272 iteration 4217 : loss : 0.021157, loss_ce: 0.008555
2022-01-16 01:24:51,749 iteration 4218 : loss : 0.014778, loss_ce: 0.007281
2022-01-16 01:24:53,223 iteration 4219 : loss : 0.016326, loss_ce: 0.006264
2022-01-16 01:24:54,831 iteration 4220 : loss : 0.028842, loss_ce: 0.011061
2022-01-16 01:24:56,563 iteration 4221 : loss : 0.031249, loss_ce: 0.009551
2022-01-16 01:24:58,114 iteration 4222 : loss : 0.021795, loss_ce: 0.008243
2022-01-16 01:24:59,738 iteration 4223 : loss : 0.021005, loss_ce: 0.007234
2022-01-16 01:25:01,363 iteration 4224 : loss : 0.028656, loss_ce: 0.007809
2022-01-16 01:25:02,925 iteration 4225 : loss : 0.022860, loss_ce: 0.007697
2022-01-16 01:25:04,423 iteration 4226 : loss : 0.018934, loss_ce: 0.005476
2022-01-16 01:25:06,013 iteration 4227 : loss : 0.028799, loss_ce: 0.009571
2022-01-16 01:25:07,442 iteration 4228 : loss : 0.020923, loss_ce: 0.007375
2022-01-16 01:25:08,887 iteration 4229 : loss : 0.025150, loss_ce: 0.009482
2022-01-16 01:25:10,339 iteration 4230 : loss : 0.023973, loss_ce: 0.011974
2022-01-16 01:25:11,786 iteration 4231 : loss : 0.020454, loss_ce: 0.006964
2022-01-16 01:25:13,272 iteration 4232 : loss : 0.020957, loss_ce: 0.008783
2022-01-16 01:25:14,754 iteration 4233 : loss : 0.022899, loss_ce: 0.009891
 62%|████████████████▊          | 249/400 [1:46:03<1:08:01, 27.03s/it]2022-01-16 01:25:16,317 iteration 4234 : loss : 0.032582, loss_ce: 0.016155
2022-01-16 01:25:17,770 iteration 4235 : loss : 0.025281, loss_ce: 0.006689
2022-01-16 01:25:19,142 iteration 4236 : loss : 0.020181, loss_ce: 0.007977
2022-01-16 01:25:20,522 iteration 4237 : loss : 0.024288, loss_ce: 0.011927
2022-01-16 01:25:21,955 iteration 4238 : loss : 0.024246, loss_ce: 0.007300
2022-01-16 01:25:23,435 iteration 4239 : loss : 0.022024, loss_ce: 0.008759
2022-01-16 01:25:24,912 iteration 4240 : loss : 0.044525, loss_ce: 0.014976
2022-01-16 01:25:26,444 iteration 4241 : loss : 0.022318, loss_ce: 0.009410
2022-01-16 01:25:27,903 iteration 4242 : loss : 0.015462, loss_ce: 0.005703
2022-01-16 01:25:29,507 iteration 4243 : loss : 0.037527, loss_ce: 0.011784
2022-01-16 01:25:31,062 iteration 4244 : loss : 0.021407, loss_ce: 0.006993
2022-01-16 01:25:32,621 iteration 4245 : loss : 0.016532, loss_ce: 0.006086
2022-01-16 01:25:34,187 iteration 4246 : loss : 0.019949, loss_ce: 0.006383
2022-01-16 01:25:35,751 iteration 4247 : loss : 0.025962, loss_ce: 0.007121
2022-01-16 01:25:37,359 iteration 4248 : loss : 0.021460, loss_ce: 0.008401
2022-01-16 01:25:38,931 iteration 4249 : loss : 0.020398, loss_ce: 0.008147
2022-01-16 01:25:38,931 Training Data Eval:
2022-01-16 01:25:47,116   Average segmentation loss on training set: 0.0149
2022-01-16 01:25:47,117 Validation Data Eval:
2022-01-16 01:25:50,181   Average segmentation loss on validation set: 0.0907
2022-01-16 01:25:51,790 iteration 4250 : loss : 0.022514, loss_ce: 0.008608
 62%|████████████████▉          | 250/400 [1:46:40<1:15:05, 30.04s/it]2022-01-16 01:25:53,459 iteration 4251 : loss : 0.018572, loss_ce: 0.006053
2022-01-16 01:25:55,163 iteration 4252 : loss : 0.030661, loss_ce: 0.008573
2022-01-16 01:25:56,753 iteration 4253 : loss : 0.022940, loss_ce: 0.011973
2022-01-16 01:25:58,357 iteration 4254 : loss : 0.021910, loss_ce: 0.008338
2022-01-16 01:25:59,986 iteration 4255 : loss : 0.027631, loss_ce: 0.007660
2022-01-16 01:26:01,531 iteration 4256 : loss : 0.019487, loss_ce: 0.006960
2022-01-16 01:26:03,200 iteration 4257 : loss : 0.025555, loss_ce: 0.012299
2022-01-16 01:26:05,003 iteration 4258 : loss : 0.028787, loss_ce: 0.013610
2022-01-16 01:26:06,611 iteration 4259 : loss : 0.019213, loss_ce: 0.006477
2022-01-16 01:26:08,276 iteration 4260 : loss : 0.027277, loss_ce: 0.009895
2022-01-16 01:26:09,941 iteration 4261 : loss : 0.016422, loss_ce: 0.005760
2022-01-16 01:26:11,495 iteration 4262 : loss : 0.023910, loss_ce: 0.011519
2022-01-16 01:26:13,117 iteration 4263 : loss : 0.027405, loss_ce: 0.011466
2022-01-16 01:26:14,689 iteration 4264 : loss : 0.019631, loss_ce: 0.008671
2022-01-16 01:26:16,264 iteration 4265 : loss : 0.017336, loss_ce: 0.007399
2022-01-16 01:26:17,846 iteration 4266 : loss : 0.019675, loss_ce: 0.005795
2022-01-16 01:26:19,454 iteration 4267 : loss : 0.027631, loss_ce: 0.010273
 63%|████████████████▉          | 251/400 [1:47:07<1:12:49, 29.32s/it]2022-01-16 01:26:21,004 iteration 4268 : loss : 0.021147, loss_ce: 0.009030
2022-01-16 01:26:22,524 iteration 4269 : loss : 0.013610, loss_ce: 0.003374
2022-01-16 01:26:24,036 iteration 4270 : loss : 0.023998, loss_ce: 0.007298
2022-01-16 01:26:25,504 iteration 4271 : loss : 0.024238, loss_ce: 0.008872
2022-01-16 01:26:26,976 iteration 4272 : loss : 0.018407, loss_ce: 0.007293
2022-01-16 01:26:28,398 iteration 4273 : loss : 0.020137, loss_ce: 0.008465
2022-01-16 01:26:29,825 iteration 4274 : loss : 0.028659, loss_ce: 0.016456
2022-01-16 01:26:31,199 iteration 4275 : loss : 0.016178, loss_ce: 0.006212
2022-01-16 01:26:32,588 iteration 4276 : loss : 0.021136, loss_ce: 0.007638
2022-01-16 01:26:34,019 iteration 4277 : loss : 0.024381, loss_ce: 0.010430
2022-01-16 01:26:35,411 iteration 4278 : loss : 0.020714, loss_ce: 0.005507
2022-01-16 01:26:36,753 iteration 4279 : loss : 0.017993, loss_ce: 0.007350
2022-01-16 01:26:38,140 iteration 4280 : loss : 0.028416, loss_ce: 0.008139
2022-01-16 01:26:39,485 iteration 4281 : loss : 0.024790, loss_ce: 0.009088
2022-01-16 01:26:40,833 iteration 4282 : loss : 0.031159, loss_ce: 0.011679
2022-01-16 01:26:42,186 iteration 4283 : loss : 0.017526, loss_ce: 0.007425
2022-01-16 01:26:43,508 iteration 4284 : loss : 0.020783, loss_ce: 0.009228
 63%|█████████████████          | 252/400 [1:47:31<1:08:25, 27.74s/it]2022-01-16 01:26:44,759 iteration 4285 : loss : 0.016965, loss_ce: 0.008224
2022-01-16 01:26:45,937 iteration 4286 : loss : 0.019430, loss_ce: 0.007010
2022-01-16 01:26:47,176 iteration 4287 : loss : 0.023841, loss_ce: 0.009337
2022-01-16 01:26:48,357 iteration 4288 : loss : 0.017094, loss_ce: 0.005434
2022-01-16 01:26:49,528 iteration 4289 : loss : 0.015581, loss_ce: 0.006793
2022-01-16 01:26:50,755 iteration 4290 : loss : 0.018866, loss_ce: 0.009373
2022-01-16 01:26:52,060 iteration 4291 : loss : 0.021132, loss_ce: 0.008866
2022-01-16 01:26:53,308 iteration 4292 : loss : 0.023914, loss_ce: 0.013123
2022-01-16 01:26:54,412 iteration 4293 : loss : 0.020357, loss_ce: 0.008030
2022-01-16 01:26:55,570 iteration 4294 : loss : 0.024826, loss_ce: 0.011910
2022-01-16 01:26:56,911 iteration 4295 : loss : 0.027817, loss_ce: 0.009462
2022-01-16 01:26:58,155 iteration 4296 : loss : 0.017280, loss_ce: 0.006234
2022-01-16 01:26:59,493 iteration 4297 : loss : 0.016504, loss_ce: 0.005164
2022-01-16 01:27:00,982 iteration 4298 : loss : 0.018867, loss_ce: 0.006844
2022-01-16 01:27:02,425 iteration 4299 : loss : 0.025429, loss_ce: 0.006447
2022-01-16 01:27:03,951 iteration 4300 : loss : 0.024062, loss_ce: 0.008447
2022-01-16 01:27:05,394 iteration 4301 : loss : 0.046434, loss_ce: 0.017475
 63%|█████████████████          | 253/400 [1:47:53<1:03:39, 25.98s/it]2022-01-16 01:27:06,985 iteration 4302 : loss : 0.017937, loss_ce: 0.006972
2022-01-16 01:27:08,488 iteration 4303 : loss : 0.018880, loss_ce: 0.009193
2022-01-16 01:27:09,991 iteration 4304 : loss : 0.023515, loss_ce: 0.010370
2022-01-16 01:27:11,483 iteration 4305 : loss : 0.026256, loss_ce: 0.008380
2022-01-16 01:27:12,943 iteration 4306 : loss : 0.018811, loss_ce: 0.005908
2022-01-16 01:27:14,425 iteration 4307 : loss : 0.023960, loss_ce: 0.008092
2022-01-16 01:27:15,843 iteration 4308 : loss : 0.034221, loss_ce: 0.015215
2022-01-16 01:27:17,269 iteration 4309 : loss : 0.022562, loss_ce: 0.007652
2022-01-16 01:27:18,581 iteration 4310 : loss : 0.017520, loss_ce: 0.006259
2022-01-16 01:27:20,050 iteration 4311 : loss : 0.026352, loss_ce: 0.010018
2022-01-16 01:27:21,394 iteration 4312 : loss : 0.022205, loss_ce: 0.009224
2022-01-16 01:27:22,765 iteration 4313 : loss : 0.021467, loss_ce: 0.009460
2022-01-16 01:27:24,084 iteration 4314 : loss : 0.035127, loss_ce: 0.020100
2022-01-16 01:27:25,336 iteration 4315 : loss : 0.019799, loss_ce: 0.007234
2022-01-16 01:27:26,595 iteration 4316 : loss : 0.020944, loss_ce: 0.008068
2022-01-16 01:27:27,928 iteration 4317 : loss : 0.018182, loss_ce: 0.007447
2022-01-16 01:27:29,344 iteration 4318 : loss : 0.019796, loss_ce: 0.006807
 64%|█████████████████▏         | 254/400 [1:48:17<1:01:44, 25.38s/it]2022-01-16 01:27:30,664 iteration 4319 : loss : 0.020596, loss_ce: 0.007364
2022-01-16 01:27:31,858 iteration 4320 : loss : 0.017365, loss_ce: 0.007231
2022-01-16 01:27:33,278 iteration 4321 : loss : 0.025722, loss_ce: 0.011909
2022-01-16 01:27:34,599 iteration 4322 : loss : 0.022638, loss_ce: 0.007903
2022-01-16 01:27:35,957 iteration 4323 : loss : 0.023051, loss_ce: 0.007400
2022-01-16 01:27:37,274 iteration 4324 : loss : 0.017697, loss_ce: 0.006759
2022-01-16 01:27:38,600 iteration 4325 : loss : 0.019961, loss_ce: 0.006203
2022-01-16 01:27:39,984 iteration 4326 : loss : 0.028711, loss_ce: 0.009813
2022-01-16 01:27:41,364 iteration 4327 : loss : 0.018154, loss_ce: 0.007897
2022-01-16 01:27:42,684 iteration 4328 : loss : 0.018647, loss_ce: 0.008028
2022-01-16 01:27:43,911 iteration 4329 : loss : 0.018973, loss_ce: 0.006317
2022-01-16 01:27:45,079 iteration 4330 : loss : 0.020556, loss_ce: 0.008710
2022-01-16 01:27:46,268 iteration 4331 : loss : 0.018558, loss_ce: 0.008000
2022-01-16 01:27:47,405 iteration 4332 : loss : 0.017009, loss_ce: 0.005791
2022-01-16 01:27:48,493 iteration 4333 : loss : 0.014650, loss_ce: 0.005792
2022-01-16 01:27:49,700 iteration 4334 : loss : 0.016152, loss_ce: 0.005898
2022-01-16 01:27:49,700 Training Data Eval:
2022-01-16 01:27:55,793   Average segmentation loss on training set: 0.0134
2022-01-16 01:27:55,793 Validation Data Eval:
2022-01-16 01:27:58,254   Average segmentation loss on validation set: 0.0707
2022-01-16 01:27:59,739 iteration 4335 : loss : 0.030624, loss_ce: 0.007297
 64%|█████████████████▏         | 255/400 [1:48:48<1:04:57, 26.88s/it]2022-01-16 01:28:01,226 iteration 4336 : loss : 0.017791, loss_ce: 0.007049
2022-01-16 01:28:02,761 iteration 4337 : loss : 0.017043, loss_ce: 0.007080
2022-01-16 01:28:04,266 iteration 4338 : loss : 0.023940, loss_ce: 0.009404
2022-01-16 01:28:05,673 iteration 4339 : loss : 0.024205, loss_ce: 0.006193
2022-01-16 01:28:07,122 iteration 4340 : loss : 0.025096, loss_ce: 0.004057
2022-01-16 01:28:08,565 iteration 4341 : loss : 0.017441, loss_ce: 0.007585
2022-01-16 01:28:09,976 iteration 4342 : loss : 0.016890, loss_ce: 0.006317
2022-01-16 01:28:11,469 iteration 4343 : loss : 0.048829, loss_ce: 0.020822
2022-01-16 01:28:12,844 iteration 4344 : loss : 0.021105, loss_ce: 0.008210
2022-01-16 01:28:14,234 iteration 4345 : loss : 0.017142, loss_ce: 0.007075
2022-01-16 01:28:15,537 iteration 4346 : loss : 0.015370, loss_ce: 0.005074
2022-01-16 01:28:17,018 iteration 4347 : loss : 0.023427, loss_ce: 0.007208
2022-01-16 01:28:18,486 iteration 4348 : loss : 0.020030, loss_ce: 0.009285
2022-01-16 01:28:19,861 iteration 4349 : loss : 0.019647, loss_ce: 0.008677
2022-01-16 01:28:21,276 iteration 4350 : loss : 0.019906, loss_ce: 0.007232
2022-01-16 01:28:22,925 iteration 4351 : loss : 0.019310, loss_ce: 0.008804
2022-01-16 01:28:24,518 iteration 4352 : loss : 0.021758, loss_ce: 0.009495
 64%|█████████████████▎         | 256/400 [1:49:12<1:03:00, 26.25s/it]2022-01-16 01:28:26,155 iteration 4353 : loss : 0.016369, loss_ce: 0.005708
2022-01-16 01:28:27,889 iteration 4354 : loss : 0.024373, loss_ce: 0.007559
2022-01-16 01:28:29,426 iteration 4355 : loss : 0.019639, loss_ce: 0.005851
2022-01-16 01:28:31,060 iteration 4356 : loss : 0.018512, loss_ce: 0.007147
2022-01-16 01:28:32,710 iteration 4357 : loss : 0.022260, loss_ce: 0.008777
2022-01-16 01:28:34,188 iteration 4358 : loss : 0.024539, loss_ce: 0.011108
2022-01-16 01:28:35,797 iteration 4359 : loss : 0.029703, loss_ce: 0.013454
2022-01-16 01:28:37,407 iteration 4360 : loss : 0.016124, loss_ce: 0.006714
2022-01-16 01:28:39,117 iteration 4361 : loss : 0.031186, loss_ce: 0.011977
2022-01-16 01:28:40,629 iteration 4362 : loss : 0.017618, loss_ce: 0.005832
2022-01-16 01:28:42,165 iteration 4363 : loss : 0.022254, loss_ce: 0.008300
2022-01-16 01:28:43,764 iteration 4364 : loss : 0.057658, loss_ce: 0.030130
2022-01-16 01:28:45,370 iteration 4365 : loss : 0.024918, loss_ce: 0.008718
2022-01-16 01:28:46,916 iteration 4366 : loss : 0.020939, loss_ce: 0.007906
2022-01-16 01:28:48,417 iteration 4367 : loss : 0.019310, loss_ce: 0.008315
2022-01-16 01:28:49,976 iteration 4368 : loss : 0.015103, loss_ce: 0.005644
2022-01-16 01:28:51,618 iteration 4369 : loss : 0.025850, loss_ce: 0.008596
 64%|█████████████████▎         | 257/400 [1:49:39<1:03:10, 26.50s/it]2022-01-16 01:28:53,212 iteration 4370 : loss : 0.024132, loss_ce: 0.009341
2022-01-16 01:28:55,026 iteration 4371 : loss : 0.027171, loss_ce: 0.011217
2022-01-16 01:28:56,672 iteration 4372 : loss : 0.035098, loss_ce: 0.009993
2022-01-16 01:28:58,371 iteration 4373 : loss : 0.044295, loss_ce: 0.016239
2022-01-16 01:28:59,918 iteration 4374 : loss : 0.020214, loss_ce: 0.007426
2022-01-16 01:29:01,579 iteration 4375 : loss : 0.016851, loss_ce: 0.007666
2022-01-16 01:29:03,173 iteration 4376 : loss : 0.019786, loss_ce: 0.007202
2022-01-16 01:29:04,739 iteration 4377 : loss : 0.018405, loss_ce: 0.006588
2022-01-16 01:29:06,481 iteration 4378 : loss : 0.024985, loss_ce: 0.011455
2022-01-16 01:29:08,026 iteration 4379 : loss : 0.022737, loss_ce: 0.008730
2022-01-16 01:29:09,713 iteration 4380 : loss : 0.018638, loss_ce: 0.006899
2022-01-16 01:29:11,402 iteration 4381 : loss : 0.033240, loss_ce: 0.009725
2022-01-16 01:29:13,114 iteration 4382 : loss : 0.029632, loss_ce: 0.009635
2022-01-16 01:29:14,832 iteration 4383 : loss : 0.025008, loss_ce: 0.008850
2022-01-16 01:29:16,422 iteration 4384 : loss : 0.029163, loss_ce: 0.011958
2022-01-16 01:29:18,188 iteration 4385 : loss : 0.024316, loss_ce: 0.011162
2022-01-16 01:29:19,742 iteration 4386 : loss : 0.015946, loss_ce: 0.003989
 64%|█████████████████▍         | 258/400 [1:50:08<1:03:52, 26.99s/it]2022-01-16 01:29:21,373 iteration 4387 : loss : 0.031905, loss_ce: 0.010610
2022-01-16 01:29:22,886 iteration 4388 : loss : 0.024552, loss_ce: 0.012380
2022-01-16 01:29:24,417 iteration 4389 : loss : 0.027789, loss_ce: 0.012002
2022-01-16 01:29:26,187 iteration 4390 : loss : 0.030861, loss_ce: 0.012232
2022-01-16 01:29:27,812 iteration 4391 : loss : 0.024852, loss_ce: 0.008739
2022-01-16 01:29:29,418 iteration 4392 : loss : 0.030391, loss_ce: 0.013218
2022-01-16 01:29:31,170 iteration 4393 : loss : 0.025013, loss_ce: 0.010364
2022-01-16 01:29:32,671 iteration 4394 : loss : 0.016209, loss_ce: 0.006161
2022-01-16 01:29:34,214 iteration 4395 : loss : 0.017908, loss_ce: 0.007951
2022-01-16 01:29:35,921 iteration 4396 : loss : 0.026555, loss_ce: 0.010161
2022-01-16 01:29:37,450 iteration 4397 : loss : 0.017671, loss_ce: 0.005704
2022-01-16 01:29:39,015 iteration 4398 : loss : 0.019907, loss_ce: 0.009576
2022-01-16 01:29:40,591 iteration 4399 : loss : 0.029835, loss_ce: 0.010375
2022-01-16 01:29:42,145 iteration 4400 : loss : 0.018908, loss_ce: 0.006432
2022-01-16 01:29:43,855 iteration 4401 : loss : 0.021493, loss_ce: 0.011151
2022-01-16 01:29:45,341 iteration 4402 : loss : 0.017971, loss_ce: 0.005655
2022-01-16 01:29:47,084 iteration 4403 : loss : 0.020851, loss_ce: 0.006039
 65%|█████████████████▍         | 259/400 [1:50:35<1:03:40, 27.10s/it]2022-01-16 01:29:48,724 iteration 4404 : loss : 0.026092, loss_ce: 0.011920
2022-01-16 01:29:50,474 iteration 4405 : loss : 0.023469, loss_ce: 0.008856
2022-01-16 01:29:52,164 iteration 4406 : loss : 0.024075, loss_ce: 0.010324
2022-01-16 01:29:53,755 iteration 4407 : loss : 0.032952, loss_ce: 0.008380
2022-01-16 01:29:55,385 iteration 4408 : loss : 0.027804, loss_ce: 0.014138
2022-01-16 01:29:57,061 iteration 4409 : loss : 0.021360, loss_ce: 0.008472
2022-01-16 01:29:58,865 iteration 4410 : loss : 0.033388, loss_ce: 0.011476
2022-01-16 01:30:00,459 iteration 4411 : loss : 0.032242, loss_ce: 0.010260
2022-01-16 01:30:02,200 iteration 4412 : loss : 0.021581, loss_ce: 0.007105
2022-01-16 01:30:03,795 iteration 4413 : loss : 0.020050, loss_ce: 0.008803
2022-01-16 01:30:05,415 iteration 4414 : loss : 0.029062, loss_ce: 0.009312
2022-01-16 01:30:07,092 iteration 4415 : loss : 0.018979, loss_ce: 0.008945
2022-01-16 01:30:08,680 iteration 4416 : loss : 0.023689, loss_ce: 0.009058
2022-01-16 01:30:10,264 iteration 4417 : loss : 0.021527, loss_ce: 0.010038
2022-01-16 01:30:11,865 iteration 4418 : loss : 0.020481, loss_ce: 0.007807
2022-01-16 01:30:13,421 iteration 4419 : loss : 0.018163, loss_ce: 0.006530
2022-01-16 01:30:13,421 Training Data Eval:
2022-01-16 01:30:21,757   Average segmentation loss on training set: 0.0139
2022-01-16 01:30:21,757 Validation Data Eval:
2022-01-16 01:30:24,673   Average segmentation loss on validation set: 0.0627
2022-01-16 01:30:26,308 iteration 4420 : loss : 0.016904, loss_ce: 0.004912
 65%|█████████████████▌         | 260/400 [1:51:14<1:11:42, 30.73s/it]2022-01-16 01:30:27,935 iteration 4421 : loss : 0.029705, loss_ce: 0.007958
2022-01-16 01:30:29,512 iteration 4422 : loss : 0.026342, loss_ce: 0.011758
2022-01-16 01:30:31,061 iteration 4423 : loss : 0.016471, loss_ce: 0.005532
2022-01-16 01:30:32,766 iteration 4424 : loss : 0.022969, loss_ce: 0.009069
2022-01-16 01:30:34,322 iteration 4425 : loss : 0.027169, loss_ce: 0.007833
2022-01-16 01:30:35,823 iteration 4426 : loss : 0.015300, loss_ce: 0.004445
2022-01-16 01:30:37,406 iteration 4427 : loss : 0.017182, loss_ce: 0.006613
2022-01-16 01:30:38,941 iteration 4428 : loss : 0.021635, loss_ce: 0.009098
2022-01-16 01:30:40,404 iteration 4429 : loss : 0.019662, loss_ce: 0.007625
2022-01-16 01:30:42,010 iteration 4430 : loss : 0.031785, loss_ce: 0.016556
2022-01-16 01:30:43,599 iteration 4431 : loss : 0.041317, loss_ce: 0.016022
2022-01-16 01:30:45,244 iteration 4432 : loss : 0.028186, loss_ce: 0.011607
2022-01-16 01:30:46,830 iteration 4433 : loss : 0.023533, loss_ce: 0.005882
2022-01-16 01:30:48,375 iteration 4434 : loss : 0.030216, loss_ce: 0.015073
2022-01-16 01:30:49,813 iteration 4435 : loss : 0.017622, loss_ce: 0.005546
2022-01-16 01:30:51,250 iteration 4436 : loss : 0.019377, loss_ce: 0.009698
2022-01-16 01:30:52,663 iteration 4437 : loss : 0.017478, loss_ce: 0.006660
 65%|█████████████████▌         | 261/400 [1:51:40<1:08:09, 29.42s/it]2022-01-16 01:30:54,158 iteration 4438 : loss : 0.022369, loss_ce: 0.008554
2022-01-16 01:30:55,404 iteration 4439 : loss : 0.015586, loss_ce: 0.007084
2022-01-16 01:30:56,736 iteration 4440 : loss : 0.019630, loss_ce: 0.009289
2022-01-16 01:30:57,990 iteration 4441 : loss : 0.026103, loss_ce: 0.010156
2022-01-16 01:30:59,304 iteration 4442 : loss : 0.025047, loss_ce: 0.009824
2022-01-16 01:31:00,631 iteration 4443 : loss : 0.021147, loss_ce: 0.008183
2022-01-16 01:31:01,979 iteration 4444 : loss : 0.019381, loss_ce: 0.006757
2022-01-16 01:31:03,344 iteration 4445 : loss : 0.020372, loss_ce: 0.006245
2022-01-16 01:31:04,830 iteration 4446 : loss : 0.037971, loss_ce: 0.007910
2022-01-16 01:31:06,417 iteration 4447 : loss : 0.027469, loss_ce: 0.009689
2022-01-16 01:31:08,059 iteration 4448 : loss : 0.019713, loss_ce: 0.006544
2022-01-16 01:31:09,708 iteration 4449 : loss : 0.039778, loss_ce: 0.016346
2022-01-16 01:31:11,358 iteration 4450 : loss : 0.019774, loss_ce: 0.009923
2022-01-16 01:31:12,923 iteration 4451 : loss : 0.018528, loss_ce: 0.006473
2022-01-16 01:31:14,505 iteration 4452 : loss : 0.021262, loss_ce: 0.006563
2022-01-16 01:31:16,168 iteration 4453 : loss : 0.018013, loss_ce: 0.007282
2022-01-16 01:31:17,675 iteration 4454 : loss : 0.019152, loss_ce: 0.006879
 66%|█████████████████▋         | 262/400 [1:52:05<1:04:37, 28.10s/it]2022-01-16 01:31:19,364 iteration 4455 : loss : 0.025857, loss_ce: 0.007769
2022-01-16 01:31:20,821 iteration 4456 : loss : 0.016617, loss_ce: 0.006050
2022-01-16 01:31:22,381 iteration 4457 : loss : 0.023194, loss_ce: 0.010409
2022-01-16 01:31:23,925 iteration 4458 : loss : 0.017276, loss_ce: 0.006178
2022-01-16 01:31:25,513 iteration 4459 : loss : 0.039199, loss_ce: 0.010834
2022-01-16 01:31:27,157 iteration 4460 : loss : 0.015921, loss_ce: 0.006039
2022-01-16 01:31:28,716 iteration 4461 : loss : 0.018558, loss_ce: 0.008043
2022-01-16 01:31:30,362 iteration 4462 : loss : 0.024427, loss_ce: 0.008614
2022-01-16 01:31:31,854 iteration 4463 : loss : 0.015621, loss_ce: 0.005596
2022-01-16 01:31:33,523 iteration 4464 : loss : 0.014958, loss_ce: 0.006703
2022-01-16 01:31:35,179 iteration 4465 : loss : 0.071204, loss_ce: 0.011511
2022-01-16 01:31:36,827 iteration 4466 : loss : 0.014344, loss_ce: 0.005382
2022-01-16 01:31:38,412 iteration 4467 : loss : 0.020945, loss_ce: 0.008770
2022-01-16 01:31:39,985 iteration 4468 : loss : 0.026458, loss_ce: 0.008972
2022-01-16 01:31:41,714 iteration 4469 : loss : 0.018412, loss_ce: 0.004841
2022-01-16 01:31:43,268 iteration 4470 : loss : 0.039149, loss_ce: 0.021596
2022-01-16 01:31:44,956 iteration 4471 : loss : 0.021459, loss_ce: 0.005613
 66%|█████████████████▊         | 263/400 [1:52:33<1:03:35, 27.85s/it]2022-01-16 01:31:46,682 iteration 4472 : loss : 0.019920, loss_ce: 0.009120
2022-01-16 01:31:48,436 iteration 4473 : loss : 0.021713, loss_ce: 0.009454
2022-01-16 01:31:50,138 iteration 4474 : loss : 0.025384, loss_ce: 0.010814
2022-01-16 01:31:51,749 iteration 4475 : loss : 0.025898, loss_ce: 0.012917
2022-01-16 01:31:53,403 iteration 4476 : loss : 0.022046, loss_ce: 0.007277
2022-01-16 01:31:55,097 iteration 4477 : loss : 0.014496, loss_ce: 0.005837
2022-01-16 01:31:56,767 iteration 4478 : loss : 0.023206, loss_ce: 0.011248
2022-01-16 01:31:58,364 iteration 4479 : loss : 0.027836, loss_ce: 0.011933
2022-01-16 01:31:59,965 iteration 4480 : loss : 0.017270, loss_ce: 0.006598
2022-01-16 01:32:01,665 iteration 4481 : loss : 0.027144, loss_ce: 0.007946
2022-01-16 01:32:03,270 iteration 4482 : loss : 0.018720, loss_ce: 0.006403
2022-01-16 01:32:05,016 iteration 4483 : loss : 0.019552, loss_ce: 0.005793
2022-01-16 01:32:06,750 iteration 4484 : loss : 0.026323, loss_ce: 0.011717
2022-01-16 01:32:08,417 iteration 4485 : loss : 0.031061, loss_ce: 0.015098
2022-01-16 01:32:10,065 iteration 4486 : loss : 0.024182, loss_ce: 0.008286
2022-01-16 01:32:11,727 iteration 4487 : loss : 0.024586, loss_ce: 0.005969
2022-01-16 01:32:13,416 iteration 4488 : loss : 0.026887, loss_ce: 0.009451
 66%|█████████████████▊         | 264/400 [1:53:01<1:03:33, 28.04s/it]2022-01-16 01:32:15,147 iteration 4489 : loss : 0.020138, loss_ce: 0.009406
2022-01-16 01:32:16,662 iteration 4490 : loss : 0.016912, loss_ce: 0.008913
2022-01-16 01:32:18,275 iteration 4491 : loss : 0.021249, loss_ce: 0.007221
2022-01-16 01:32:20,025 iteration 4492 : loss : 0.024811, loss_ce: 0.011951
2022-01-16 01:32:21,570 iteration 4493 : loss : 0.023613, loss_ce: 0.008739
2022-01-16 01:32:23,299 iteration 4494 : loss : 0.022388, loss_ce: 0.006799
2022-01-16 01:32:24,881 iteration 4495 : loss : 0.061604, loss_ce: 0.024174
2022-01-16 01:32:26,578 iteration 4496 : loss : 0.017302, loss_ce: 0.008682
2022-01-16 01:32:28,218 iteration 4497 : loss : 0.018644, loss_ce: 0.008196
2022-01-16 01:32:29,778 iteration 4498 : loss : 0.046814, loss_ce: 0.015224
2022-01-16 01:32:31,499 iteration 4499 : loss : 0.026833, loss_ce: 0.009498
2022-01-16 01:32:33,021 iteration 4500 : loss : 0.016418, loss_ce: 0.005645
2022-01-16 01:32:34,583 iteration 4501 : loss : 0.020291, loss_ce: 0.006646
2022-01-16 01:32:36,057 iteration 4502 : loss : 0.023843, loss_ce: 0.008174
2022-01-16 01:32:37,725 iteration 4503 : loss : 0.021628, loss_ce: 0.009296
2022-01-16 01:32:39,305 iteration 4504 : loss : 0.034504, loss_ce: 0.014447
2022-01-16 01:32:39,305 Training Data Eval:
2022-01-16 01:32:47,185   Average segmentation loss on training set: 0.0138
2022-01-16 01:32:47,186 Validation Data Eval:
2022-01-16 01:32:49,799   Average segmentation loss on validation set: 0.0938
2022-01-16 01:32:51,352 iteration 4505 : loss : 0.017933, loss_ce: 0.007170
 66%|█████████████████▉         | 265/400 [1:53:39<1:09:45, 31.00s/it]2022-01-16 01:32:52,860 iteration 4506 : loss : 0.026764, loss_ce: 0.011219
2022-01-16 01:32:54,329 iteration 4507 : loss : 0.015961, loss_ce: 0.006843
2022-01-16 01:32:55,797 iteration 4508 : loss : 0.017498, loss_ce: 0.006332
2022-01-16 01:32:57,262 iteration 4509 : loss : 0.033678, loss_ce: 0.007555
2022-01-16 01:32:58,784 iteration 4510 : loss : 0.020605, loss_ce: 0.006545
2022-01-16 01:33:00,212 iteration 4511 : loss : 0.039385, loss_ce: 0.011242
2022-01-16 01:33:01,733 iteration 4512 : loss : 0.023278, loss_ce: 0.011611
2022-01-16 01:33:03,244 iteration 4513 : loss : 0.032669, loss_ce: 0.011450
2022-01-16 01:33:04,614 iteration 4514 : loss : 0.021718, loss_ce: 0.007090
2022-01-16 01:33:06,055 iteration 4515 : loss : 0.023320, loss_ce: 0.008241
2022-01-16 01:33:07,506 iteration 4516 : loss : 0.015934, loss_ce: 0.006753
2022-01-16 01:33:09,030 iteration 4517 : loss : 0.017356, loss_ce: 0.006709
2022-01-16 01:33:10,633 iteration 4518 : loss : 0.022339, loss_ce: 0.008063
2022-01-16 01:33:12,077 iteration 4519 : loss : 0.016165, loss_ce: 0.006078
2022-01-16 01:33:13,682 iteration 4520 : loss : 0.030194, loss_ce: 0.011770
2022-01-16 01:33:15,220 iteration 4521 : loss : 0.016118, loss_ce: 0.006424
2022-01-16 01:33:16,751 iteration 4522 : loss : 0.023452, loss_ce: 0.008091
 66%|█████████████████▉         | 266/400 [1:54:05<1:05:29, 29.32s/it]2022-01-16 01:33:18,370 iteration 4523 : loss : 0.017682, loss_ce: 0.007240
2022-01-16 01:33:19,796 iteration 4524 : loss : 0.024361, loss_ce: 0.008834
2022-01-16 01:33:21,212 iteration 4525 : loss : 0.018984, loss_ce: 0.008571
2022-01-16 01:33:22,687 iteration 4526 : loss : 0.020257, loss_ce: 0.005589
2022-01-16 01:33:24,224 iteration 4527 : loss : 0.017544, loss_ce: 0.007718
2022-01-16 01:33:25,806 iteration 4528 : loss : 0.015061, loss_ce: 0.005513
2022-01-16 01:33:27,412 iteration 4529 : loss : 0.015316, loss_ce: 0.005205
2022-01-16 01:33:28,934 iteration 4530 : loss : 0.024017, loss_ce: 0.009574
2022-01-16 01:33:30,571 iteration 4531 : loss : 0.035094, loss_ce: 0.009589
2022-01-16 01:33:32,062 iteration 4532 : loss : 0.015643, loss_ce: 0.005594
2022-01-16 01:33:33,742 iteration 4533 : loss : 0.029449, loss_ce: 0.010122
2022-01-16 01:33:35,202 iteration 4534 : loss : 0.015323, loss_ce: 0.007308
2022-01-16 01:33:36,853 iteration 4535 : loss : 0.022932, loss_ce: 0.010557
2022-01-16 01:33:38,397 iteration 4536 : loss : 0.016743, loss_ce: 0.004341
2022-01-16 01:33:40,009 iteration 4537 : loss : 0.021764, loss_ce: 0.006453
2022-01-16 01:33:41,566 iteration 4538 : loss : 0.019981, loss_ce: 0.008725
2022-01-16 01:33:43,134 iteration 4539 : loss : 0.015060, loss_ce: 0.005266
 67%|██████████████████         | 267/400 [1:54:31<1:03:02, 28.44s/it]2022-01-16 01:33:44,666 iteration 4540 : loss : 0.021413, loss_ce: 0.010131
2022-01-16 01:33:46,324 iteration 4541 : loss : 0.021093, loss_ce: 0.008054
2022-01-16 01:33:47,888 iteration 4542 : loss : 0.021197, loss_ce: 0.005907
2022-01-16 01:33:49,548 iteration 4543 : loss : 0.019631, loss_ce: 0.007355
2022-01-16 01:33:51,067 iteration 4544 : loss : 0.018306, loss_ce: 0.007373
2022-01-16 01:33:52,536 iteration 4545 : loss : 0.012790, loss_ce: 0.004768
2022-01-16 01:33:54,163 iteration 4546 : loss : 0.020717, loss_ce: 0.008410
2022-01-16 01:33:55,745 iteration 4547 : loss : 0.019603, loss_ce: 0.007238
2022-01-16 01:33:57,313 iteration 4548 : loss : 0.025495, loss_ce: 0.010467
2022-01-16 01:33:58,924 iteration 4549 : loss : 0.022637, loss_ce: 0.007255
2022-01-16 01:34:00,502 iteration 4550 : loss : 0.020072, loss_ce: 0.006395
2022-01-16 01:34:02,056 iteration 4551 : loss : 0.030094, loss_ce: 0.010409
2022-01-16 01:34:03,618 iteration 4552 : loss : 0.019615, loss_ce: 0.006073
2022-01-16 01:34:05,120 iteration 4553 : loss : 0.016841, loss_ce: 0.006070
2022-01-16 01:34:06,664 iteration 4554 : loss : 0.023105, loss_ce: 0.006544
2022-01-16 01:34:08,114 iteration 4555 : loss : 0.019208, loss_ce: 0.006287
2022-01-16 01:34:09,590 iteration 4556 : loss : 0.021489, loss_ce: 0.009027
 67%|██████████████████         | 268/400 [1:54:57<1:01:15, 27.85s/it]2022-01-16 01:34:11,062 iteration 4557 : loss : 0.018732, loss_ce: 0.008995
2022-01-16 01:34:12,485 iteration 4558 : loss : 0.020196, loss_ce: 0.008895
2022-01-16 01:34:13,965 iteration 4559 : loss : 0.018945, loss_ce: 0.006018
2022-01-16 01:34:15,424 iteration 4560 : loss : 0.026432, loss_ce: 0.008304
2022-01-16 01:34:16,886 iteration 4561 : loss : 0.022490, loss_ce: 0.005508
2022-01-16 01:34:18,258 iteration 4562 : loss : 0.022487, loss_ce: 0.007086
2022-01-16 01:34:19,667 iteration 4563 : loss : 0.017448, loss_ce: 0.007852
2022-01-16 01:34:21,073 iteration 4564 : loss : 0.031240, loss_ce: 0.010603
2022-01-16 01:34:22,482 iteration 4565 : loss : 0.025420, loss_ce: 0.008753
2022-01-16 01:34:23,812 iteration 4566 : loss : 0.027477, loss_ce: 0.012104
2022-01-16 01:34:25,060 iteration 4567 : loss : 0.018419, loss_ce: 0.007193
2022-01-16 01:34:26,313 iteration 4568 : loss : 0.022184, loss_ce: 0.006814
2022-01-16 01:34:27,687 iteration 4569 : loss : 0.061543, loss_ce: 0.009170
2022-01-16 01:34:29,067 iteration 4570 : loss : 0.034391, loss_ce: 0.014854
2022-01-16 01:34:30,331 iteration 4571 : loss : 0.025523, loss_ce: 0.009625
2022-01-16 01:34:31,567 iteration 4572 : loss : 0.021860, loss_ce: 0.009495
2022-01-16 01:34:32,925 iteration 4573 : loss : 0.043032, loss_ce: 0.020297
 67%|███████████████████▌         | 269/400 [1:55:21<57:50, 26.49s/it]2022-01-16 01:34:34,172 iteration 4574 : loss : 0.019683, loss_ce: 0.008704
2022-01-16 01:34:35,448 iteration 4575 : loss : 0.039749, loss_ce: 0.011344
2022-01-16 01:34:36,773 iteration 4576 : loss : 0.034796, loss_ce: 0.014112
2022-01-16 01:34:37,994 iteration 4577 : loss : 0.020195, loss_ce: 0.007399
2022-01-16 01:34:39,116 iteration 4578 : loss : 0.028958, loss_ce: 0.010423
2022-01-16 01:34:40,399 iteration 4579 : loss : 0.022757, loss_ce: 0.008716
2022-01-16 01:34:41,601 iteration 4580 : loss : 0.020532, loss_ce: 0.009797
2022-01-16 01:34:42,789 iteration 4581 : loss : 0.023948, loss_ce: 0.009451
2022-01-16 01:34:43,967 iteration 4582 : loss : 0.023799, loss_ce: 0.010647
2022-01-16 01:34:45,201 iteration 4583 : loss : 0.048023, loss_ce: 0.013130
2022-01-16 01:34:46,296 iteration 4584 : loss : 0.031441, loss_ce: 0.009503
2022-01-16 01:34:47,332 iteration 4585 : loss : 0.019147, loss_ce: 0.006306
2022-01-16 01:34:48,395 iteration 4586 : loss : 0.023381, loss_ce: 0.015063
2022-01-16 01:34:49,478 iteration 4587 : loss : 0.020072, loss_ce: 0.007864
2022-01-16 01:34:50,610 iteration 4588 : loss : 0.027764, loss_ce: 0.012927
2022-01-16 01:34:51,666 iteration 4589 : loss : 0.022600, loss_ce: 0.009658
2022-01-16 01:34:51,666 Training Data Eval:
2022-01-16 01:34:56,575   Average segmentation loss on training set: 0.0164
2022-01-16 01:34:56,576 Validation Data Eval:
2022-01-16 01:34:58,226   Average segmentation loss on validation set: 0.1409
2022-01-16 01:34:59,271 iteration 4590 : loss : 0.030667, loss_ce: 0.017738
 68%|███████████████████▌         | 270/400 [1:55:47<57:18, 26.45s/it]2022-01-16 01:35:00,477 iteration 4591 : loss : 0.032315, loss_ce: 0.012307
2022-01-16 01:35:01,493 iteration 4592 : loss : 0.025079, loss_ce: 0.011198
2022-01-16 01:35:02,510 iteration 4593 : loss : 0.023544, loss_ce: 0.009301
2022-01-16 01:35:03,530 iteration 4594 : loss : 0.024954, loss_ce: 0.009054
2022-01-16 01:35:04,539 iteration 4595 : loss : 0.017630, loss_ce: 0.007294
2022-01-16 01:35:05,647 iteration 4596 : loss : 0.025231, loss_ce: 0.010974
2022-01-16 01:35:06,605 iteration 4597 : loss : 0.029344, loss_ce: 0.009921
2022-01-16 01:35:07,530 iteration 4598 : loss : 0.021236, loss_ce: 0.006824
2022-01-16 01:35:08,517 iteration 4599 : loss : 0.020638, loss_ce: 0.008376
2022-01-16 01:35:09,536 iteration 4600 : loss : 0.019331, loss_ce: 0.007140
2022-01-16 01:35:10,573 iteration 4601 : loss : 0.021592, loss_ce: 0.010865
2022-01-16 01:35:11,668 iteration 4602 : loss : 0.029719, loss_ce: 0.011594
2022-01-16 01:35:12,759 iteration 4603 : loss : 0.026395, loss_ce: 0.009459
2022-01-16 01:35:13,722 iteration 4604 : loss : 0.025254, loss_ce: 0.008717
2022-01-16 01:35:14,728 iteration 4605 : loss : 0.017487, loss_ce: 0.005115
2022-01-16 01:35:15,719 iteration 4606 : loss : 0.029356, loss_ce: 0.010248
2022-01-16 01:35:16,710 iteration 4607 : loss : 0.022789, loss_ce: 0.009081
 68%|███████████████████▋         | 271/400 [1:56:05<51:02, 23.74s/it]2022-01-16 01:35:17,802 iteration 4608 : loss : 0.016069, loss_ce: 0.005924
2022-01-16 01:35:18,834 iteration 4609 : loss : 0.016048, loss_ce: 0.004925
2022-01-16 01:35:19,866 iteration 4610 : loss : 0.018858, loss_ce: 0.005058
2022-01-16 01:35:20,927 iteration 4611 : loss : 0.033143, loss_ce: 0.013293
2022-01-16 01:35:21,954 iteration 4612 : loss : 0.029713, loss_ce: 0.011947
2022-01-16 01:35:22,976 iteration 4613 : loss : 0.019073, loss_ce: 0.007263
2022-01-16 01:35:23,993 iteration 4614 : loss : 0.018011, loss_ce: 0.005465
2022-01-16 01:35:25,124 iteration 4615 : loss : 0.035785, loss_ce: 0.016928
2022-01-16 01:35:26,081 iteration 4616 : loss : 0.017796, loss_ce: 0.008486
2022-01-16 01:35:27,109 iteration 4617 : loss : 0.023740, loss_ce: 0.008086
2022-01-16 01:35:28,093 iteration 4618 : loss : 0.012951, loss_ce: 0.005261
2022-01-16 01:35:29,122 iteration 4619 : loss : 0.023448, loss_ce: 0.009608
2022-01-16 01:35:30,108 iteration 4620 : loss : 0.018722, loss_ce: 0.007086
2022-01-16 01:35:31,096 iteration 4621 : loss : 0.020582, loss_ce: 0.006531
2022-01-16 01:35:32,142 iteration 4622 : loss : 0.018725, loss_ce: 0.007398
2022-01-16 01:35:33,163 iteration 4623 : loss : 0.020375, loss_ce: 0.008507
2022-01-16 01:35:34,140 iteration 4624 : loss : 0.019320, loss_ce: 0.005843
 68%|███████████████████▋         | 272/400 [1:56:22<46:36, 21.85s/it]2022-01-16 01:35:35,278 iteration 4625 : loss : 0.024270, loss_ce: 0.009248
2022-01-16 01:35:36,330 iteration 4626 : loss : 0.027469, loss_ce: 0.009660
2022-01-16 01:35:37,329 iteration 4627 : loss : 0.015471, loss_ce: 0.007120
2022-01-16 01:35:38,339 iteration 4628 : loss : 0.021513, loss_ce: 0.006864
2022-01-16 01:35:39,296 iteration 4629 : loss : 0.028173, loss_ce: 0.005181
2022-01-16 01:35:40,317 iteration 4630 : loss : 0.016073, loss_ce: 0.008783
2022-01-16 01:35:41,299 iteration 4631 : loss : 0.019177, loss_ce: 0.006934
2022-01-16 01:35:42,320 iteration 4632 : loss : 0.018794, loss_ce: 0.005569
2022-01-16 01:35:43,353 iteration 4633 : loss : 0.019353, loss_ce: 0.006212
2022-01-16 01:35:44,441 iteration 4634 : loss : 0.018572, loss_ce: 0.007587
2022-01-16 01:35:45,340 iteration 4635 : loss : 0.014195, loss_ce: 0.004673
2022-01-16 01:35:46,288 iteration 4636 : loss : 0.012887, loss_ce: 0.004800
2022-01-16 01:35:47,295 iteration 4637 : loss : 0.021888, loss_ce: 0.006833
2022-01-16 01:35:48,331 iteration 4638 : loss : 0.019404, loss_ce: 0.009201
2022-01-16 01:35:49,431 iteration 4639 : loss : 0.026742, loss_ce: 0.009575
2022-01-16 01:35:50,576 iteration 4640 : loss : 0.021128, loss_ce: 0.008888
2022-01-16 01:35:51,719 iteration 4641 : loss : 0.019617, loss_ce: 0.006736
 68%|███████████████████▊         | 273/400 [1:56:40<43:32, 20.57s/it]2022-01-16 01:35:52,917 iteration 4642 : loss : 0.018943, loss_ce: 0.007346
2022-01-16 01:35:54,135 iteration 4643 : loss : 0.026268, loss_ce: 0.009771
2022-01-16 01:35:55,414 iteration 4644 : loss : 0.025705, loss_ce: 0.013237
2022-01-16 01:35:56,692 iteration 4645 : loss : 0.019380, loss_ce: 0.006880
2022-01-16 01:35:58,013 iteration 4646 : loss : 0.019671, loss_ce: 0.007951
2022-01-16 01:35:59,424 iteration 4647 : loss : 0.018693, loss_ce: 0.007545
2022-01-16 01:36:00,826 iteration 4648 : loss : 0.016879, loss_ce: 0.007458
2022-01-16 01:36:02,392 iteration 4649 : loss : 0.020174, loss_ce: 0.007872
2022-01-16 01:36:03,747 iteration 4650 : loss : 0.015407, loss_ce: 0.006325
2022-01-16 01:36:05,260 iteration 4651 : loss : 0.020016, loss_ce: 0.007029
2022-01-16 01:36:06,706 iteration 4652 : loss : 0.018879, loss_ce: 0.006660
2022-01-16 01:36:08,060 iteration 4653 : loss : 0.016801, loss_ce: 0.006223
2022-01-16 01:36:09,414 iteration 4654 : loss : 0.015718, loss_ce: 0.004343
2022-01-16 01:36:10,873 iteration 4655 : loss : 0.030069, loss_ce: 0.009679
2022-01-16 01:36:12,251 iteration 4656 : loss : 0.022249, loss_ce: 0.006714
2022-01-16 01:36:13,593 iteration 4657 : loss : 0.020438, loss_ce: 0.008411
2022-01-16 01:36:14,884 iteration 4658 : loss : 0.013654, loss_ce: 0.005096
 68%|███████████████████▊         | 274/400 [1:57:03<44:49, 21.35s/it]2022-01-16 01:36:16,218 iteration 4659 : loss : 0.015540, loss_ce: 0.005738
2022-01-16 01:36:17,441 iteration 4660 : loss : 0.014525, loss_ce: 0.005758
2022-01-16 01:36:18,742 iteration 4661 : loss : 0.023413, loss_ce: 0.011304
2022-01-16 01:36:19,877 iteration 4662 : loss : 0.012343, loss_ce: 0.005717
2022-01-16 01:36:21,177 iteration 4663 : loss : 0.019708, loss_ce: 0.006738
2022-01-16 01:36:22,367 iteration 4664 : loss : 0.021235, loss_ce: 0.007639
2022-01-16 01:36:23,576 iteration 4665 : loss : 0.023568, loss_ce: 0.010603
2022-01-16 01:36:24,805 iteration 4666 : loss : 0.019584, loss_ce: 0.007961
2022-01-16 01:36:26,054 iteration 4667 : loss : 0.028892, loss_ce: 0.009355
2022-01-16 01:36:27,236 iteration 4668 : loss : 0.015519, loss_ce: 0.006103
2022-01-16 01:36:28,470 iteration 4669 : loss : 0.020314, loss_ce: 0.007446
2022-01-16 01:36:29,703 iteration 4670 : loss : 0.028837, loss_ce: 0.008347
2022-01-16 01:36:30,925 iteration 4671 : loss : 0.015331, loss_ce: 0.005571
2022-01-16 01:36:32,158 iteration 4672 : loss : 0.012658, loss_ce: 0.004537
2022-01-16 01:36:33,390 iteration 4673 : loss : 0.014227, loss_ce: 0.004842
2022-01-16 01:36:34,761 iteration 4674 : loss : 0.017888, loss_ce: 0.004613
2022-01-16 01:36:34,761 Training Data Eval:
2022-01-16 01:36:41,615   Average segmentation loss on training set: 0.0117
2022-01-16 01:36:41,615 Validation Data Eval:
2022-01-16 01:36:44,036   Average segmentation loss on validation set: 0.0818
2022-01-16 01:36:45,395 iteration 4675 : loss : 0.014579, loss_ce: 0.005560
 69%|███████████████████▉         | 275/400 [1:57:33<50:12, 24.10s/it]2022-01-16 01:36:46,895 iteration 4676 : loss : 0.015412, loss_ce: 0.006135
2022-01-16 01:36:48,310 iteration 4677 : loss : 0.016447, loss_ce: 0.006709
2022-01-16 01:36:49,803 iteration 4678 : loss : 0.016878, loss_ce: 0.006428
2022-01-16 01:36:51,346 iteration 4679 : loss : 0.034025, loss_ce: 0.016092
2022-01-16 01:36:52,763 iteration 4680 : loss : 0.016063, loss_ce: 0.006364
2022-01-16 01:36:54,207 iteration 4681 : loss : 0.017801, loss_ce: 0.007784
2022-01-16 01:36:55,645 iteration 4682 : loss : 0.017144, loss_ce: 0.006691
2022-01-16 01:36:57,255 iteration 4683 : loss : 0.017111, loss_ce: 0.005604
2022-01-16 01:36:58,776 iteration 4684 : loss : 0.019169, loss_ce: 0.006685
2022-01-16 01:37:00,321 iteration 4685 : loss : 0.018235, loss_ce: 0.008591
2022-01-16 01:37:01,756 iteration 4686 : loss : 0.021328, loss_ce: 0.007365
2022-01-16 01:37:03,231 iteration 4687 : loss : 0.023678, loss_ce: 0.007397
2022-01-16 01:37:04,852 iteration 4688 : loss : 0.012555, loss_ce: 0.005396
2022-01-16 01:37:06,385 iteration 4689 : loss : 0.022963, loss_ce: 0.008375
2022-01-16 01:37:07,969 iteration 4690 : loss : 0.015543, loss_ce: 0.005202
2022-01-16 01:37:09,465 iteration 4691 : loss : 0.022350, loss_ce: 0.006389
2022-01-16 01:37:11,092 iteration 4692 : loss : 0.017043, loss_ce: 0.005775
 69%|████████████████████         | 276/400 [1:57:59<50:47, 24.58s/it]2022-01-16 01:37:12,718 iteration 4693 : loss : 0.020026, loss_ce: 0.008096
2022-01-16 01:37:14,261 iteration 4694 : loss : 0.014699, loss_ce: 0.004466
2022-01-16 01:37:15,929 iteration 4695 : loss : 0.025673, loss_ce: 0.009250
2022-01-16 01:37:17,648 iteration 4696 : loss : 0.019272, loss_ce: 0.006719
2022-01-16 01:37:19,124 iteration 4697 : loss : 0.019528, loss_ce: 0.008195
2022-01-16 01:37:20,747 iteration 4698 : loss : 0.016956, loss_ce: 0.006181
2022-01-16 01:37:22,326 iteration 4699 : loss : 0.022270, loss_ce: 0.006152
2022-01-16 01:37:23,883 iteration 4700 : loss : 0.019020, loss_ce: 0.006976
2022-01-16 01:37:25,580 iteration 4701 : loss : 0.016875, loss_ce: 0.004930
2022-01-16 01:37:27,138 iteration 4702 : loss : 0.032289, loss_ce: 0.009918
2022-01-16 01:37:28,754 iteration 4703 : loss : 0.041280, loss_ce: 0.021016
2022-01-16 01:37:30,392 iteration 4704 : loss : 0.026517, loss_ce: 0.005247
2022-01-16 01:37:32,000 iteration 4705 : loss : 0.026976, loss_ce: 0.007350
2022-01-16 01:37:33,588 iteration 4706 : loss : 0.019589, loss_ce: 0.006916
2022-01-16 01:37:35,121 iteration 4707 : loss : 0.018902, loss_ce: 0.005902
2022-01-16 01:37:36,696 iteration 4708 : loss : 0.029353, loss_ce: 0.014575
2022-01-16 01:37:38,432 iteration 4709 : loss : 0.021347, loss_ce: 0.009115
 69%|████████████████████         | 277/400 [1:58:26<52:04, 25.41s/it]2022-01-16 01:37:40,026 iteration 4710 : loss : 0.018737, loss_ce: 0.006767
2022-01-16 01:37:41,678 iteration 4711 : loss : 0.024931, loss_ce: 0.007903
2022-01-16 01:37:43,275 iteration 4712 : loss : 0.014887, loss_ce: 0.005196
2022-01-16 01:37:44,852 iteration 4713 : loss : 0.017177, loss_ce: 0.004850
2022-01-16 01:37:46,360 iteration 4714 : loss : 0.016052, loss_ce: 0.005678
2022-01-16 01:37:47,953 iteration 4715 : loss : 0.017666, loss_ce: 0.008654
2022-01-16 01:37:49,573 iteration 4716 : loss : 0.028318, loss_ce: 0.011954
2022-01-16 01:37:51,119 iteration 4717 : loss : 0.017404, loss_ce: 0.006502
2022-01-16 01:37:52,656 iteration 4718 : loss : 0.021741, loss_ce: 0.008299
2022-01-16 01:37:54,207 iteration 4719 : loss : 0.013838, loss_ce: 0.004757
2022-01-16 01:37:55,769 iteration 4720 : loss : 0.018475, loss_ce: 0.008993
2022-01-16 01:37:57,308 iteration 4721 : loss : 0.017370, loss_ce: 0.005155
2022-01-16 01:37:58,873 iteration 4722 : loss : 0.023457, loss_ce: 0.010052
2022-01-16 01:38:00,415 iteration 4723 : loss : 0.026261, loss_ce: 0.008013
2022-01-16 01:38:02,029 iteration 4724 : loss : 0.020858, loss_ce: 0.010580
2022-01-16 01:38:03,669 iteration 4725 : loss : 0.018070, loss_ce: 0.006048
2022-01-16 01:38:05,273 iteration 4726 : loss : 0.024083, loss_ce: 0.006854
 70%|████████████████████▏        | 278/400 [1:58:53<52:32, 25.84s/it]2022-01-16 01:38:06,921 iteration 4727 : loss : 0.018878, loss_ce: 0.007169
2022-01-16 01:38:08,642 iteration 4728 : loss : 0.015268, loss_ce: 0.005828
2022-01-16 01:38:10,180 iteration 4729 : loss : 0.018537, loss_ce: 0.005656
2022-01-16 01:38:11,743 iteration 4730 : loss : 0.033540, loss_ce: 0.011813
2022-01-16 01:38:13,354 iteration 4731 : loss : 0.024103, loss_ce: 0.006722
2022-01-16 01:38:15,070 iteration 4732 : loss : 0.018445, loss_ce: 0.006670
2022-01-16 01:38:16,596 iteration 4733 : loss : 0.018416, loss_ce: 0.006079
2022-01-16 01:38:18,215 iteration 4734 : loss : 0.014063, loss_ce: 0.004635
2022-01-16 01:38:19,935 iteration 4735 : loss : 0.032385, loss_ce: 0.015011
2022-01-16 01:38:21,528 iteration 4736 : loss : 0.019012, loss_ce: 0.007429
2022-01-16 01:38:23,269 iteration 4737 : loss : 0.030910, loss_ce: 0.008129
2022-01-16 01:38:24,891 iteration 4738 : loss : 0.044081, loss_ce: 0.007698
2022-01-16 01:38:26,401 iteration 4739 : loss : 0.015255, loss_ce: 0.005640
2022-01-16 01:38:27,982 iteration 4740 : loss : 0.014557, loss_ce: 0.006511
2022-01-16 01:38:29,542 iteration 4741 : loss : 0.020228, loss_ce: 0.012097
2022-01-16 01:38:31,124 iteration 4742 : loss : 0.014829, loss_ce: 0.004961
2022-01-16 01:38:32,632 iteration 4743 : loss : 0.022199, loss_ce: 0.008003
 70%|████████████████████▏        | 279/400 [1:59:20<53:01, 26.30s/it]2022-01-16 01:38:34,289 iteration 4744 : loss : 0.039872, loss_ce: 0.021045
2022-01-16 01:38:35,880 iteration 4745 : loss : 0.020802, loss_ce: 0.009184
2022-01-16 01:38:37,434 iteration 4746 : loss : 0.030205, loss_ce: 0.012630
2022-01-16 01:38:39,040 iteration 4747 : loss : 0.027242, loss_ce: 0.011028
2022-01-16 01:38:40,820 iteration 4748 : loss : 0.021566, loss_ce: 0.008075
2022-01-16 01:38:42,386 iteration 4749 : loss : 0.019763, loss_ce: 0.004896
2022-01-16 01:38:43,936 iteration 4750 : loss : 0.017554, loss_ce: 0.006982
2022-01-16 01:38:45,450 iteration 4751 : loss : 0.020613, loss_ce: 0.006768
2022-01-16 01:38:47,035 iteration 4752 : loss : 0.020329, loss_ce: 0.004888
2022-01-16 01:38:48,704 iteration 4753 : loss : 0.018470, loss_ce: 0.008245
2022-01-16 01:38:50,375 iteration 4754 : loss : 0.016757, loss_ce: 0.005011
2022-01-16 01:38:51,975 iteration 4755 : loss : 0.022525, loss_ce: 0.007811
2022-01-16 01:38:53,623 iteration 4756 : loss : 0.014904, loss_ce: 0.006293
2022-01-16 01:38:55,332 iteration 4757 : loss : 0.019120, loss_ce: 0.008555
2022-01-16 01:38:57,017 iteration 4758 : loss : 0.020653, loss_ce: 0.006285
2022-01-16 01:38:58,657 iteration 4759 : loss : 0.014686, loss_ce: 0.005502
2022-01-16 01:38:58,658 Training Data Eval:
2022-01-16 01:39:07,137   Average segmentation loss on training set: 0.0129
2022-01-16 01:39:07,138 Validation Data Eval:
2022-01-16 01:39:10,127   Average segmentation loss on validation set: 0.0721
2022-01-16 01:39:11,861 iteration 4760 : loss : 0.019352, loss_ce: 0.006857
 70%|██████████████████▉        | 280/400 [2:00:00<1:00:20, 30.17s/it]2022-01-16 01:39:13,492 iteration 4761 : loss : 0.018040, loss_ce: 0.007519
2022-01-16 01:39:15,174 iteration 4762 : loss : 0.019677, loss_ce: 0.005970
2022-01-16 01:39:16,784 iteration 4763 : loss : 0.023252, loss_ce: 0.006950
2022-01-16 01:39:18,509 iteration 4764 : loss : 0.017728, loss_ce: 0.005452
2022-01-16 01:39:20,256 iteration 4765 : loss : 0.017123, loss_ce: 0.005969
2022-01-16 01:39:21,951 iteration 4766 : loss : 0.042171, loss_ce: 0.013938
2022-01-16 01:39:23,652 iteration 4767 : loss : 0.026822, loss_ce: 0.012536
2022-01-16 01:39:25,238 iteration 4768 : loss : 0.018914, loss_ce: 0.008152
2022-01-16 01:39:26,762 iteration 4769 : loss : 0.015524, loss_ce: 0.005519
2022-01-16 01:39:28,371 iteration 4770 : loss : 0.023243, loss_ce: 0.010129
2022-01-16 01:39:29,937 iteration 4771 : loss : 0.023623, loss_ce: 0.007807
2022-01-16 01:39:31,468 iteration 4772 : loss : 0.018331, loss_ce: 0.006897
2022-01-16 01:39:32,959 iteration 4773 : loss : 0.014197, loss_ce: 0.006268
2022-01-16 01:39:34,564 iteration 4774 : loss : 0.026262, loss_ce: 0.009981
2022-01-16 01:39:36,029 iteration 4775 : loss : 0.016177, loss_ce: 0.006116
2022-01-16 01:39:37,529 iteration 4776 : loss : 0.030969, loss_ce: 0.012607
2022-01-16 01:39:39,021 iteration 4777 : loss : 0.016501, loss_ce: 0.005550
 70%|████████████████████▎        | 281/400 [2:00:27<58:02, 29.27s/it]2022-01-16 01:39:40,598 iteration 4778 : loss : 0.020113, loss_ce: 0.010242
2022-01-16 01:39:42,053 iteration 4779 : loss : 0.015750, loss_ce: 0.006780
2022-01-16 01:39:43,605 iteration 4780 : loss : 0.018020, loss_ce: 0.007681
2022-01-16 01:39:45,221 iteration 4781 : loss : 0.020176, loss_ce: 0.007181
2022-01-16 01:39:46,779 iteration 4782 : loss : 0.021772, loss_ce: 0.008321
2022-01-16 01:39:48,349 iteration 4783 : loss : 0.020736, loss_ce: 0.009811
2022-01-16 01:39:50,081 iteration 4784 : loss : 0.018241, loss_ce: 0.005791
2022-01-16 01:39:51,604 iteration 4785 : loss : 0.021511, loss_ce: 0.007655
2022-01-16 01:39:53,157 iteration 4786 : loss : 0.016865, loss_ce: 0.006981
2022-01-16 01:39:54,725 iteration 4787 : loss : 0.027801, loss_ce: 0.009091
2022-01-16 01:39:56,277 iteration 4788 : loss : 0.017690, loss_ce: 0.004367
2022-01-16 01:39:57,682 iteration 4789 : loss : 0.014287, loss_ce: 0.005448
2022-01-16 01:39:59,147 iteration 4790 : loss : 0.014072, loss_ce: 0.005132
2022-01-16 01:40:00,671 iteration 4791 : loss : 0.024942, loss_ce: 0.010549
2022-01-16 01:40:02,259 iteration 4792 : loss : 0.017826, loss_ce: 0.007016
2022-01-16 01:40:03,832 iteration 4793 : loss : 0.024668, loss_ce: 0.008075
2022-01-16 01:40:05,399 iteration 4794 : loss : 0.015006, loss_ce: 0.004231
 70%|████████████████████▍        | 282/400 [2:00:53<55:51, 28.40s/it]2022-01-16 01:40:07,162 iteration 4795 : loss : 0.031134, loss_ce: 0.013225
2022-01-16 01:40:08,764 iteration 4796 : loss : 0.016808, loss_ce: 0.004570
2022-01-16 01:40:10,347 iteration 4797 : loss : 0.015738, loss_ce: 0.005959
2022-01-16 01:40:12,027 iteration 4798 : loss : 0.015545, loss_ce: 0.005656
2022-01-16 01:40:13,547 iteration 4799 : loss : 0.018317, loss_ce: 0.004343
2022-01-16 01:40:15,083 iteration 4800 : loss : 0.020706, loss_ce: 0.007392
2022-01-16 01:40:16,563 iteration 4801 : loss : 0.018930, loss_ce: 0.008203
2022-01-16 01:40:18,091 iteration 4802 : loss : 0.018332, loss_ce: 0.006619
2022-01-16 01:40:19,544 iteration 4803 : loss : 0.014789, loss_ce: 0.005876
2022-01-16 01:40:20,980 iteration 4804 : loss : 0.014519, loss_ce: 0.005330
2022-01-16 01:40:22,398 iteration 4805 : loss : 0.020022, loss_ce: 0.008233
2022-01-16 01:40:23,709 iteration 4806 : loss : 0.033641, loss_ce: 0.006486
2022-01-16 01:40:24,903 iteration 4807 : loss : 0.018636, loss_ce: 0.005454
2022-01-16 01:40:26,170 iteration 4808 : loss : 0.021705, loss_ce: 0.007494
2022-01-16 01:40:27,322 iteration 4809 : loss : 0.018006, loss_ce: 0.008842
2022-01-16 01:40:28,509 iteration 4810 : loss : 0.022190, loss_ce: 0.007721
2022-01-16 01:40:29,763 iteration 4811 : loss : 0.021785, loss_ce: 0.008224
 71%|████████████████████▌        | 283/400 [2:01:18<53:01, 27.19s/it]2022-01-16 01:40:31,100 iteration 4812 : loss : 0.024037, loss_ce: 0.006893
2022-01-16 01:40:32,329 iteration 4813 : loss : 0.023732, loss_ce: 0.009182
2022-01-16 01:40:33,727 iteration 4814 : loss : 0.031434, loss_ce: 0.012698
2022-01-16 01:40:34,964 iteration 4815 : loss : 0.016924, loss_ce: 0.005775
2022-01-16 01:40:36,182 iteration 4816 : loss : 0.019686, loss_ce: 0.007841
2022-01-16 01:40:37,378 iteration 4817 : loss : 0.014972, loss_ce: 0.005771
2022-01-16 01:40:38,580 iteration 4818 : loss : 0.024101, loss_ce: 0.008717
2022-01-16 01:40:39,817 iteration 4819 : loss : 0.027211, loss_ce: 0.007638
2022-01-16 01:40:40,972 iteration 4820 : loss : 0.017998, loss_ce: 0.008059
2022-01-16 01:40:42,146 iteration 4821 : loss : 0.024123, loss_ce: 0.008112
2022-01-16 01:40:43,372 iteration 4822 : loss : 0.030750, loss_ce: 0.013238
2022-01-16 01:40:44,525 iteration 4823 : loss : 0.021487, loss_ce: 0.005112
2022-01-16 01:40:45,617 iteration 4824 : loss : 0.020970, loss_ce: 0.005167
2022-01-16 01:40:46,767 iteration 4825 : loss : 0.021598, loss_ce: 0.012809
2022-01-16 01:40:48,014 iteration 4826 : loss : 0.024218, loss_ce: 0.010796
2022-01-16 01:40:49,065 iteration 4827 : loss : 0.021416, loss_ce: 0.010898
2022-01-16 01:40:50,084 iteration 4828 : loss : 0.014337, loss_ce: 0.005215
 71%|████████████████████▌        | 284/400 [2:01:38<48:34, 25.13s/it]2022-01-16 01:40:51,180 iteration 4829 : loss : 0.015338, loss_ce: 0.007708
2022-01-16 01:40:52,315 iteration 4830 : loss : 0.024317, loss_ce: 0.009590
2022-01-16 01:40:53,477 iteration 4831 : loss : 0.023382, loss_ce: 0.012870
2022-01-16 01:40:54,670 iteration 4832 : loss : 0.015596, loss_ce: 0.005255
2022-01-16 01:40:55,806 iteration 4833 : loss : 0.021058, loss_ce: 0.010279
2022-01-16 01:40:57,015 iteration 4834 : loss : 0.019031, loss_ce: 0.007068
2022-01-16 01:40:58,118 iteration 4835 : loss : 0.021232, loss_ce: 0.008403
2022-01-16 01:40:59,188 iteration 4836 : loss : 0.019943, loss_ce: 0.005291
2022-01-16 01:41:00,306 iteration 4837 : loss : 0.014223, loss_ce: 0.004118
2022-01-16 01:41:01,394 iteration 4838 : loss : 0.022351, loss_ce: 0.008981
2022-01-16 01:41:02,379 iteration 4839 : loss : 0.017572, loss_ce: 0.006996
2022-01-16 01:41:03,418 iteration 4840 : loss : 0.022338, loss_ce: 0.007318
2022-01-16 01:41:04,497 iteration 4841 : loss : 0.019315, loss_ce: 0.007428
2022-01-16 01:41:05,542 iteration 4842 : loss : 0.022600, loss_ce: 0.008835
2022-01-16 01:41:06,537 iteration 4843 : loss : 0.016441, loss_ce: 0.005275
2022-01-16 01:41:07,603 iteration 4844 : loss : 0.015798, loss_ce: 0.004021
2022-01-16 01:41:07,603 Training Data Eval:
2022-01-16 01:41:12,470   Average segmentation loss on training set: 0.0117
2022-01-16 01:41:12,470 Validation Data Eval:
2022-01-16 01:41:14,124   Average segmentation loss on validation set: 0.0794
2022-01-16 01:41:15,083 iteration 4845 : loss : 0.017696, loss_ce: 0.005730
 71%|████████████████████▋        | 285/400 [2:02:03<48:05, 25.09s/it]2022-01-16 01:41:16,150 iteration 4846 : loss : 0.018177, loss_ce: 0.007398
2022-01-16 01:41:17,098 iteration 4847 : loss : 0.012987, loss_ce: 0.004459
2022-01-16 01:41:18,194 iteration 4848 : loss : 0.023216, loss_ce: 0.010374
2022-01-16 01:41:19,175 iteration 4849 : loss : 0.015672, loss_ce: 0.005486
2022-01-16 01:41:20,109 iteration 4850 : loss : 0.013934, loss_ce: 0.006529
2022-01-16 01:41:21,214 iteration 4851 : loss : 0.025461, loss_ce: 0.009814
2022-01-16 01:41:22,212 iteration 4852 : loss : 0.019108, loss_ce: 0.009732
2022-01-16 01:41:23,248 iteration 4853 : loss : 0.026766, loss_ce: 0.007875
2022-01-16 01:41:24,398 iteration 4854 : loss : 0.022867, loss_ce: 0.007575
2022-01-16 01:41:25,443 iteration 4855 : loss : 0.021910, loss_ce: 0.007486
2022-01-16 01:41:26,389 iteration 4856 : loss : 0.015570, loss_ce: 0.004794
2022-01-16 01:41:27,450 iteration 4857 : loss : 0.019892, loss_ce: 0.010087
2022-01-16 01:41:28,492 iteration 4858 : loss : 0.029375, loss_ce: 0.010645
2022-01-16 01:41:29,505 iteration 4859 : loss : 0.014664, loss_ce: 0.006165
2022-01-16 01:41:30,543 iteration 4860 : loss : 0.025574, loss_ce: 0.008919
2022-01-16 01:41:31,555 iteration 4861 : loss : 0.018476, loss_ce: 0.007565
2022-01-16 01:41:32,510 iteration 4862 : loss : 0.015327, loss_ce: 0.005897
 72%|████████████████████▋        | 286/400 [2:02:20<43:18, 22.79s/it]2022-01-16 01:41:33,533 iteration 4863 : loss : 0.017298, loss_ce: 0.006083
2022-01-16 01:41:34,590 iteration 4864 : loss : 0.021660, loss_ce: 0.007512
2022-01-16 01:41:35,688 iteration 4865 : loss : 0.032747, loss_ce: 0.009997
2022-01-16 01:41:36,680 iteration 4866 : loss : 0.026685, loss_ce: 0.014022
2022-01-16 01:41:37,698 iteration 4867 : loss : 0.020836, loss_ce: 0.008839
2022-01-16 01:41:38,671 iteration 4868 : loss : 0.016973, loss_ce: 0.007642
2022-01-16 01:41:39,647 iteration 4869 : loss : 0.019930, loss_ce: 0.007060
2022-01-16 01:41:40,737 iteration 4870 : loss : 0.020481, loss_ce: 0.006537
2022-01-16 01:41:41,771 iteration 4871 : loss : 0.017557, loss_ce: 0.007256
2022-01-16 01:41:42,721 iteration 4872 : loss : 0.036198, loss_ce: 0.014052
2022-01-16 01:41:43,664 iteration 4873 : loss : 0.021082, loss_ce: 0.008953
2022-01-16 01:41:44,593 iteration 4874 : loss : 0.014785, loss_ce: 0.006434
2022-01-16 01:41:45,610 iteration 4875 : loss : 0.019595, loss_ce: 0.007515
2022-01-16 01:41:46,613 iteration 4876 : loss : 0.023156, loss_ce: 0.008276
2022-01-16 01:41:47,816 iteration 4877 : loss : 0.023781, loss_ce: 0.009076
2022-01-16 01:41:48,986 iteration 4878 : loss : 0.018578, loss_ce: 0.007140
2022-01-16 01:41:50,162 iteration 4879 : loss : 0.021462, loss_ce: 0.007724
 72%|████████████████████▊        | 287/400 [2:02:38<40:01, 21.25s/it]2022-01-16 01:41:51,486 iteration 4880 : loss : 0.021046, loss_ce: 0.011631
2022-01-16 01:41:52,696 iteration 4881 : loss : 0.024411, loss_ce: 0.007567
2022-01-16 01:41:53,939 iteration 4882 : loss : 0.017178, loss_ce: 0.005796
2022-01-16 01:41:55,208 iteration 4883 : loss : 0.022746, loss_ce: 0.007350
2022-01-16 01:41:56,469 iteration 4884 : loss : 0.013556, loss_ce: 0.007460
2022-01-16 01:41:57,834 iteration 4885 : loss : 0.021753, loss_ce: 0.007611
2022-01-16 01:41:59,089 iteration 4886 : loss : 0.023258, loss_ce: 0.008437
2022-01-16 01:42:00,336 iteration 4887 : loss : 0.038094, loss_ce: 0.016658
2022-01-16 01:42:01,495 iteration 4888 : loss : 0.026128, loss_ce: 0.008253
2022-01-16 01:42:02,682 iteration 4889 : loss : 0.017434, loss_ce: 0.006310
2022-01-16 01:42:03,918 iteration 4890 : loss : 0.026981, loss_ce: 0.008943
2022-01-16 01:42:05,184 iteration 4891 : loss : 0.022719, loss_ce: 0.011989
2022-01-16 01:42:06,360 iteration 4892 : loss : 0.018835, loss_ce: 0.007623
2022-01-16 01:42:07,565 iteration 4893 : loss : 0.014550, loss_ce: 0.006610
2022-01-16 01:42:08,788 iteration 4894 : loss : 0.021095, loss_ce: 0.004962
2022-01-16 01:42:09,966 iteration 4895 : loss : 0.018476, loss_ce: 0.007131
2022-01-16 01:42:11,183 iteration 4896 : loss : 0.033230, loss_ce: 0.015578
 72%|████████████████████▉        | 288/400 [2:02:59<39:32, 21.18s/it]2022-01-16 01:42:12,389 iteration 4897 : loss : 0.018079, loss_ce: 0.006207
2022-01-16 01:42:13,538 iteration 4898 : loss : 0.031539, loss_ce: 0.013288
2022-01-16 01:42:14,507 iteration 4899 : loss : 0.019763, loss_ce: 0.008008
2022-01-16 01:42:15,685 iteration 4900 : loss : 0.028480, loss_ce: 0.010147
2022-01-16 01:42:16,733 iteration 4901 : loss : 0.014451, loss_ce: 0.003477
2022-01-16 01:42:17,838 iteration 4902 : loss : 0.024350, loss_ce: 0.008298
2022-01-16 01:42:18,954 iteration 4903 : loss : 0.031454, loss_ce: 0.014706
2022-01-16 01:42:20,037 iteration 4904 : loss : 0.025929, loss_ce: 0.012678
2022-01-16 01:42:21,079 iteration 4905 : loss : 0.030535, loss_ce: 0.010020
2022-01-16 01:42:22,120 iteration 4906 : loss : 0.026861, loss_ce: 0.010015
2022-01-16 01:42:23,053 iteration 4907 : loss : 0.014458, loss_ce: 0.005838
2022-01-16 01:42:24,037 iteration 4908 : loss : 0.017679, loss_ce: 0.006976
2022-01-16 01:42:25,074 iteration 4909 : loss : 0.015037, loss_ce: 0.004989
2022-01-16 01:42:26,132 iteration 4910 : loss : 0.014557, loss_ce: 0.005192
2022-01-16 01:42:27,168 iteration 4911 : loss : 0.023190, loss_ce: 0.008555
2022-01-16 01:42:28,306 iteration 4912 : loss : 0.022465, loss_ce: 0.007753
2022-01-16 01:42:29,446 iteration 4913 : loss : 0.024218, loss_ce: 0.008933
 72%|████████████████████▉        | 289/400 [2:03:17<37:33, 20.31s/it]2022-01-16 01:42:30,641 iteration 4914 : loss : 0.033824, loss_ce: 0.015663
2022-01-16 01:42:31,877 iteration 4915 : loss : 0.015550, loss_ce: 0.007399
2022-01-16 01:42:33,191 iteration 4916 : loss : 0.043139, loss_ce: 0.012833
2022-01-16 01:42:34,546 iteration 4917 : loss : 0.013492, loss_ce: 0.004294
2022-01-16 01:42:35,940 iteration 4918 : loss : 0.019597, loss_ce: 0.008553
2022-01-16 01:42:37,368 iteration 4919 : loss : 0.015275, loss_ce: 0.006655
2022-01-16 01:42:38,920 iteration 4920 : loss : 0.024583, loss_ce: 0.009073
2022-01-16 01:42:40,365 iteration 4921 : loss : 0.019500, loss_ce: 0.007386
2022-01-16 01:42:41,927 iteration 4922 : loss : 0.015870, loss_ce: 0.005232
2022-01-16 01:42:43,424 iteration 4923 : loss : 0.020091, loss_ce: 0.007268
2022-01-16 01:42:44,880 iteration 4924 : loss : 0.019097, loss_ce: 0.007641
2022-01-16 01:42:46,253 iteration 4925 : loss : 0.017825, loss_ce: 0.007192
2022-01-16 01:42:47,564 iteration 4926 : loss : 0.015706, loss_ce: 0.007378
2022-01-16 01:42:48,959 iteration 4927 : loss : 0.013033, loss_ce: 0.004479
2022-01-16 01:42:50,372 iteration 4928 : loss : 0.023595, loss_ce: 0.010264
2022-01-16 01:42:51,730 iteration 4929 : loss : 0.017859, loss_ce: 0.004676
2022-01-16 01:42:51,731 Training Data Eval:
2022-01-16 01:42:58,849   Average segmentation loss on training set: 0.0121
2022-01-16 01:42:58,850 Validation Data Eval:
2022-01-16 01:43:01,624   Average segmentation loss on validation set: 0.0856
2022-01-16 01:43:03,147 iteration 4930 : loss : 0.026540, loss_ce: 0.008341
 72%|█████████████████████        | 290/400 [2:03:51<44:35, 24.33s/it]2022-01-16 01:43:04,819 iteration 4931 : loss : 0.018883, loss_ce: 0.009220
2022-01-16 01:43:06,381 iteration 4932 : loss : 0.028119, loss_ce: 0.007597
2022-01-16 01:43:07,831 iteration 4933 : loss : 0.017489, loss_ce: 0.007107
2022-01-16 01:43:09,363 iteration 4934 : loss : 0.017809, loss_ce: 0.006493
2022-01-16 01:43:10,996 iteration 4935 : loss : 0.016907, loss_ce: 0.004266
2022-01-16 01:43:12,546 iteration 4936 : loss : 0.015864, loss_ce: 0.005508
2022-01-16 01:43:14,022 iteration 4937 : loss : 0.022054, loss_ce: 0.008456
2022-01-16 01:43:15,539 iteration 4938 : loss : 0.016037, loss_ce: 0.006036
2022-01-16 01:43:17,147 iteration 4939 : loss : 0.024809, loss_ce: 0.010799
2022-01-16 01:43:18,690 iteration 4940 : loss : 0.015662, loss_ce: 0.006198
2022-01-16 01:43:20,254 iteration 4941 : loss : 0.020177, loss_ce: 0.007851
2022-01-16 01:43:21,976 iteration 4942 : loss : 0.027628, loss_ce: 0.012984
2022-01-16 01:43:23,494 iteration 4943 : loss : 0.014925, loss_ce: 0.006138
2022-01-16 01:43:25,095 iteration 4944 : loss : 0.016469, loss_ce: 0.008267
2022-01-16 01:43:26,658 iteration 4945 : loss : 0.016028, loss_ce: 0.006162
2022-01-16 01:43:28,119 iteration 4946 : loss : 0.018453, loss_ce: 0.006596
2022-01-16 01:43:29,764 iteration 4947 : loss : 0.026990, loss_ce: 0.010773
 73%|█████████████████████        | 291/400 [2:04:18<45:26, 25.01s/it]2022-01-16 01:43:31,426 iteration 4948 : loss : 0.025532, loss_ce: 0.009921
2022-01-16 01:43:33,045 iteration 4949 : loss : 0.019356, loss_ce: 0.007715
2022-01-16 01:43:34,577 iteration 4950 : loss : 0.020485, loss_ce: 0.009956
2022-01-16 01:43:36,095 iteration 4951 : loss : 0.024552, loss_ce: 0.009889
2022-01-16 01:43:37,602 iteration 4952 : loss : 0.018503, loss_ce: 0.006518
2022-01-16 01:43:39,184 iteration 4953 : loss : 0.021709, loss_ce: 0.006330
2022-01-16 01:43:40,606 iteration 4954 : loss : 0.016461, loss_ce: 0.005397
2022-01-16 01:43:42,049 iteration 4955 : loss : 0.016073, loss_ce: 0.007516
2022-01-16 01:43:43,550 iteration 4956 : loss : 0.022334, loss_ce: 0.006249
2022-01-16 01:43:45,066 iteration 4957 : loss : 0.024752, loss_ce: 0.008565
2022-01-16 01:43:46,654 iteration 4958 : loss : 0.029959, loss_ce: 0.012782
2022-01-16 01:43:48,130 iteration 4959 : loss : 0.018947, loss_ce: 0.007552
2022-01-16 01:43:49,676 iteration 4960 : loss : 0.023188, loss_ce: 0.012347
2022-01-16 01:43:51,158 iteration 4961 : loss : 0.020502, loss_ce: 0.004934
2022-01-16 01:43:52,674 iteration 4962 : loss : 0.017927, loss_ce: 0.007823
2022-01-16 01:43:54,300 iteration 4963 : loss : 0.018239, loss_ce: 0.006785
2022-01-16 01:43:55,969 iteration 4964 : loss : 0.015555, loss_ce: 0.004992
 73%|█████████████████████▏       | 292/400 [2:04:44<45:39, 25.37s/it]2022-01-16 01:43:57,535 iteration 4965 : loss : 0.016805, loss_ce: 0.005117
2022-01-16 01:43:59,049 iteration 4966 : loss : 0.022113, loss_ce: 0.009229
2022-01-16 01:44:00,551 iteration 4967 : loss : 0.018813, loss_ce: 0.005344
2022-01-16 01:44:02,051 iteration 4968 : loss : 0.022662, loss_ce: 0.005712
2022-01-16 01:44:03,553 iteration 4969 : loss : 0.021965, loss_ce: 0.008263
2022-01-16 01:44:05,176 iteration 4970 : loss : 0.020259, loss_ce: 0.010725
2022-01-16 01:44:06,728 iteration 4971 : loss : 0.019107, loss_ce: 0.007377
2022-01-16 01:44:08,233 iteration 4972 : loss : 0.018541, loss_ce: 0.005769
2022-01-16 01:44:09,755 iteration 4973 : loss : 0.014157, loss_ce: 0.004345
2022-01-16 01:44:11,432 iteration 4974 : loss : 0.015671, loss_ce: 0.007699
2022-01-16 01:44:13,031 iteration 4975 : loss : 0.014016, loss_ce: 0.004882
2022-01-16 01:44:14,580 iteration 4976 : loss : 0.015126, loss_ce: 0.005322
2022-01-16 01:44:16,077 iteration 4977 : loss : 0.015581, loss_ce: 0.006842
2022-01-16 01:44:17,672 iteration 4978 : loss : 0.018121, loss_ce: 0.007152
2022-01-16 01:44:19,162 iteration 4979 : loss : 0.016251, loss_ce: 0.005681
2022-01-16 01:44:20,605 iteration 4980 : loss : 0.012343, loss_ce: 0.004200
2022-01-16 01:44:22,159 iteration 4981 : loss : 0.020256, loss_ce: 0.007157
 73%|█████████████████████▏       | 293/400 [2:05:10<45:41, 25.62s/it]2022-01-16 01:44:23,774 iteration 4982 : loss : 0.026126, loss_ce: 0.006575
2022-01-16 01:44:25,203 iteration 4983 : loss : 0.018598, loss_ce: 0.007178
2022-01-16 01:44:26,708 iteration 4984 : loss : 0.018405, loss_ce: 0.004711
2022-01-16 01:44:28,143 iteration 4985 : loss : 0.011328, loss_ce: 0.004193
2022-01-16 01:44:29,667 iteration 4986 : loss : 0.019940, loss_ce: 0.005816
2022-01-16 01:44:31,243 iteration 4987 : loss : 0.016673, loss_ce: 0.007736
2022-01-16 01:44:32,848 iteration 4988 : loss : 0.023784, loss_ce: 0.014215
2022-01-16 01:44:34,408 iteration 4989 : loss : 0.037783, loss_ce: 0.014551
2022-01-16 01:44:35,954 iteration 4990 : loss : 0.016037, loss_ce: 0.006797
2022-01-16 01:44:37,488 iteration 4991 : loss : 0.019999, loss_ce: 0.006646
2022-01-16 01:44:39,006 iteration 4992 : loss : 0.017871, loss_ce: 0.005637
2022-01-16 01:44:40,563 iteration 4993 : loss : 0.018810, loss_ce: 0.007869
2022-01-16 01:44:42,267 iteration 4994 : loss : 0.024883, loss_ce: 0.010961
2022-01-16 01:44:43,903 iteration 4995 : loss : 0.023825, loss_ce: 0.009796
2022-01-16 01:44:45,431 iteration 4996 : loss : 0.016518, loss_ce: 0.004689
2022-01-16 01:44:47,116 iteration 4997 : loss : 0.019405, loss_ce: 0.007475
2022-01-16 01:44:48,689 iteration 4998 : loss : 0.019521, loss_ce: 0.007893
 74%|█████████████████████▎       | 294/400 [2:05:37<45:44, 25.89s/it]2022-01-16 01:44:50,261 iteration 4999 : loss : 0.017754, loss_ce: 0.007467
2022-01-16 01:44:51,863 iteration 5000 : loss : 0.014396, loss_ce: 0.004645
2022-01-16 01:44:53,498 iteration 5001 : loss : 0.020959, loss_ce: 0.005494
2022-01-16 01:44:55,230 iteration 5002 : loss : 0.014388, loss_ce: 0.004280
2022-01-16 01:44:56,841 iteration 5003 : loss : 0.023537, loss_ce: 0.010111
2022-01-16 01:44:58,530 iteration 5004 : loss : 0.014042, loss_ce: 0.006046
2022-01-16 01:45:00,211 iteration 5005 : loss : 0.017826, loss_ce: 0.007069
2022-01-16 01:45:01,768 iteration 5006 : loss : 0.016695, loss_ce: 0.006283
2022-01-16 01:45:03,537 iteration 5007 : loss : 0.027624, loss_ce: 0.008656
2022-01-16 01:45:05,061 iteration 5008 : loss : 0.015126, loss_ce: 0.005902
2022-01-16 01:45:06,724 iteration 5009 : loss : 0.015523, loss_ce: 0.007435
2022-01-16 01:45:08,428 iteration 5010 : loss : 0.017172, loss_ce: 0.007569
2022-01-16 01:45:10,006 iteration 5011 : loss : 0.015506, loss_ce: 0.006610
2022-01-16 01:45:11,639 iteration 5012 : loss : 0.021957, loss_ce: 0.005721
2022-01-16 01:45:13,370 iteration 5013 : loss : 0.013866, loss_ce: 0.005635
2022-01-16 01:45:14,945 iteration 5014 : loss : 0.016649, loss_ce: 0.006061
2022-01-16 01:45:14,946 Training Data Eval:
2022-01-16 01:45:23,511   Average segmentation loss on training set: 0.0108
2022-01-16 01:45:23,511 Validation Data Eval:
2022-01-16 01:45:26,427   Average segmentation loss on validation set: 0.0702
2022-01-16 01:45:28,055 iteration 5015 : loss : 0.019182, loss_ce: 0.006456
 74%|█████████████████████▍       | 295/400 [2:06:16<52:22, 29.93s/it]2022-01-16 01:45:29,812 iteration 5016 : loss : 0.024556, loss_ce: 0.009711
2022-01-16 01:45:31,400 iteration 5017 : loss : 0.012005, loss_ce: 0.004989
2022-01-16 01:45:33,078 iteration 5018 : loss : 0.019144, loss_ce: 0.008531
2022-01-16 01:45:34,601 iteration 5019 : loss : 0.014490, loss_ce: 0.005157
2022-01-16 01:45:36,281 iteration 5020 : loss : 0.019731, loss_ce: 0.007036
2022-01-16 01:45:37,808 iteration 5021 : loss : 0.020034, loss_ce: 0.008135
2022-01-16 01:45:39,536 iteration 5022 : loss : 0.018706, loss_ce: 0.005911
2022-01-16 01:45:41,173 iteration 5023 : loss : 0.021480, loss_ce: 0.011548
2022-01-16 01:45:42,902 iteration 5024 : loss : 0.022140, loss_ce: 0.009135
2022-01-16 01:45:44,522 iteration 5025 : loss : 0.020412, loss_ce: 0.006724
2022-01-16 01:45:46,168 iteration 5026 : loss : 0.026530, loss_ce: 0.010639
2022-01-16 01:45:47,869 iteration 5027 : loss : 0.013593, loss_ce: 0.004817
2022-01-16 01:45:49,419 iteration 5028 : loss : 0.014373, loss_ce: 0.005888
2022-01-16 01:45:51,127 iteration 5029 : loss : 0.021615, loss_ce: 0.008580
2022-01-16 01:45:52,800 iteration 5030 : loss : 0.018655, loss_ce: 0.007667
2022-01-16 01:45:54,357 iteration 5031 : loss : 0.028855, loss_ce: 0.008756
2022-01-16 01:45:55,819 iteration 5032 : loss : 0.013584, loss_ce: 0.004919
 74%|█████████████████████▍       | 296/400 [2:06:44<50:45, 29.28s/it]2022-01-16 01:45:57,443 iteration 5033 : loss : 0.021889, loss_ce: 0.008186
2022-01-16 01:45:59,085 iteration 5034 : loss : 0.018510, loss_ce: 0.006198
2022-01-16 01:46:00,598 iteration 5035 : loss : 0.024290, loss_ce: 0.007658
2022-01-16 01:46:02,065 iteration 5036 : loss : 0.026040, loss_ce: 0.010422
2022-01-16 01:46:03,621 iteration 5037 : loss : 0.016721, loss_ce: 0.005450
2022-01-16 01:46:05,160 iteration 5038 : loss : 0.021568, loss_ce: 0.005945
2022-01-16 01:46:06,678 iteration 5039 : loss : 0.018299, loss_ce: 0.006973
2022-01-16 01:46:08,296 iteration 5040 : loss : 0.016258, loss_ce: 0.005483
2022-01-16 01:46:09,849 iteration 5041 : loss : 0.016713, loss_ce: 0.006866
2022-01-16 01:46:11,446 iteration 5042 : loss : 0.029160, loss_ce: 0.011517
2022-01-16 01:46:12,913 iteration 5043 : loss : 0.017564, loss_ce: 0.005999
2022-01-16 01:46:14,635 iteration 5044 : loss : 0.016570, loss_ce: 0.005730
2022-01-16 01:46:16,249 iteration 5045 : loss : 0.020277, loss_ce: 0.009555
2022-01-16 01:46:17,811 iteration 5046 : loss : 0.033970, loss_ce: 0.009697
2022-01-16 01:46:19,334 iteration 5047 : loss : 0.012881, loss_ce: 0.003856
2022-01-16 01:46:20,934 iteration 5048 : loss : 0.012675, loss_ce: 0.006065
2022-01-16 01:46:22,448 iteration 5049 : loss : 0.014839, loss_ce: 0.006719
 74%|█████████████████████▌       | 297/400 [2:07:10<48:53, 28.48s/it]2022-01-16 01:46:24,024 iteration 5050 : loss : 0.017208, loss_ce: 0.005553
2022-01-16 01:46:25,672 iteration 5051 : loss : 0.025120, loss_ce: 0.008190
2022-01-16 01:46:27,340 iteration 5052 : loss : 0.020765, loss_ce: 0.007845
2022-01-16 01:46:28,963 iteration 5053 : loss : 0.025936, loss_ce: 0.008730
2022-01-16 01:46:30,511 iteration 5054 : loss : 0.018446, loss_ce: 0.004152
2022-01-16 01:46:32,033 iteration 5055 : loss : 0.017809, loss_ce: 0.006263
2022-01-16 01:46:33,578 iteration 5056 : loss : 0.016985, loss_ce: 0.007091
2022-01-16 01:46:35,189 iteration 5057 : loss : 0.024180, loss_ce: 0.012014
2022-01-16 01:46:36,760 iteration 5058 : loss : 0.025455, loss_ce: 0.009688
2022-01-16 01:46:38,228 iteration 5059 : loss : 0.016107, loss_ce: 0.006554
2022-01-16 01:46:39,705 iteration 5060 : loss : 0.020556, loss_ce: 0.012099
2022-01-16 01:46:41,147 iteration 5061 : loss : 0.016939, loss_ce: 0.006331
2022-01-16 01:46:42,579 iteration 5062 : loss : 0.018394, loss_ce: 0.006072
2022-01-16 01:46:43,991 iteration 5063 : loss : 0.031235, loss_ce: 0.011287
2022-01-16 01:46:45,285 iteration 5064 : loss : 0.016911, loss_ce: 0.005956
2022-01-16 01:46:46,596 iteration 5065 : loss : 0.017440, loss_ce: 0.009072
2022-01-16 01:46:47,777 iteration 5066 : loss : 0.016189, loss_ce: 0.006467
 74%|█████████████████████▌       | 298/400 [2:07:36<46:48, 27.54s/it]2022-01-16 01:46:48,915 iteration 5067 : loss : 0.014822, loss_ce: 0.005979
2022-01-16 01:46:50,131 iteration 5068 : loss : 0.017580, loss_ce: 0.005455
2022-01-16 01:46:51,309 iteration 5069 : loss : 0.019350, loss_ce: 0.009990
2022-01-16 01:46:52,427 iteration 5070 : loss : 0.018585, loss_ce: 0.005837
2022-01-16 01:46:53,635 iteration 5071 : loss : 0.021214, loss_ce: 0.008950
2022-01-16 01:46:54,717 iteration 5072 : loss : 0.015031, loss_ce: 0.005506
2022-01-16 01:46:55,907 iteration 5073 : loss : 0.018410, loss_ce: 0.007538
2022-01-16 01:46:57,032 iteration 5074 : loss : 0.013556, loss_ce: 0.005184
2022-01-16 01:46:58,197 iteration 5075 : loss : 0.019855, loss_ce: 0.007345
2022-01-16 01:46:59,402 iteration 5076 : loss : 0.023114, loss_ce: 0.004409
2022-01-16 01:47:00,615 iteration 5077 : loss : 0.023805, loss_ce: 0.008240
2022-01-16 01:47:01,813 iteration 5078 : loss : 0.019805, loss_ce: 0.009672
2022-01-16 01:47:03,094 iteration 5079 : loss : 0.014626, loss_ce: 0.006011
2022-01-16 01:47:04,457 iteration 5080 : loss : 0.015833, loss_ce: 0.006398
2022-01-16 01:47:05,924 iteration 5081 : loss : 0.018430, loss_ce: 0.005409
2022-01-16 01:47:07,310 iteration 5082 : loss : 0.015454, loss_ce: 0.005555
2022-01-16 01:47:08,718 iteration 5083 : loss : 0.022387, loss_ce: 0.005806
 75%|█████████████████████▋       | 299/400 [2:07:57<43:01, 25.56s/it]2022-01-16 01:47:10,200 iteration 5084 : loss : 0.019367, loss_ce: 0.009232
2022-01-16 01:47:11,628 iteration 5085 : loss : 0.021013, loss_ce: 0.008386
2022-01-16 01:47:12,993 iteration 5086 : loss : 0.015996, loss_ce: 0.005204
2022-01-16 01:47:14,248 iteration 5087 : loss : 0.018375, loss_ce: 0.008078
2022-01-16 01:47:15,518 iteration 5088 : loss : 0.021247, loss_ce: 0.008189
2022-01-16 01:47:16,848 iteration 5089 : loss : 0.019280, loss_ce: 0.005311
2022-01-16 01:47:18,172 iteration 5090 : loss : 0.018009, loss_ce: 0.003670
2022-01-16 01:47:19,549 iteration 5091 : loss : 0.025344, loss_ce: 0.010851
2022-01-16 01:47:20,892 iteration 5092 : loss : 0.025473, loss_ce: 0.012704
2022-01-16 01:47:22,188 iteration 5093 : loss : 0.014947, loss_ce: 0.004487
2022-01-16 01:47:23,583 iteration 5094 : loss : 0.019582, loss_ce: 0.007451
2022-01-16 01:47:24,878 iteration 5095 : loss : 0.014015, loss_ce: 0.005759
2022-01-16 01:47:26,232 iteration 5096 : loss : 0.020826, loss_ce: 0.009635
2022-01-16 01:47:27,545 iteration 5097 : loss : 0.022805, loss_ce: 0.009024
2022-01-16 01:47:28,963 iteration 5098 : loss : 0.019143, loss_ce: 0.006048
2022-01-16 01:47:30,332 iteration 5099 : loss : 0.020967, loss_ce: 0.006251
2022-01-16 01:47:30,332 Training Data Eval:
2022-01-16 01:47:36,824   Average segmentation loss on training set: 0.0108
2022-01-16 01:47:36,824 Validation Data Eval:
2022-01-16 01:47:38,945   Average segmentation loss on validation set: 0.0995
2022-01-16 01:47:40,213 iteration 5100 : loss : 0.045621, loss_ce: 0.013807
 75%|█████████████████████▊       | 300/400 [2:08:28<45:34, 27.34s/it]2022-01-16 01:47:41,504 iteration 5101 : loss : 0.027773, loss_ce: 0.009879
2022-01-16 01:47:42,596 iteration 5102 : loss : 0.024567, loss_ce: 0.008168
2022-01-16 01:47:43,677 iteration 5103 : loss : 0.018116, loss_ce: 0.009046
2022-01-16 01:47:44,798 iteration 5104 : loss : 0.023152, loss_ce: 0.007015
2022-01-16 01:47:45,814 iteration 5105 : loss : 0.015218, loss_ce: 0.005795
2022-01-16 01:47:46,821 iteration 5106 : loss : 0.019556, loss_ce: 0.007097
2022-01-16 01:47:47,903 iteration 5107 : loss : 0.025865, loss_ce: 0.008234
2022-01-16 01:47:48,951 iteration 5108 : loss : 0.021970, loss_ce: 0.013895
2022-01-16 01:47:49,991 iteration 5109 : loss : 0.020648, loss_ce: 0.007717
2022-01-16 01:47:51,002 iteration 5110 : loss : 0.015659, loss_ce: 0.004920
2022-01-16 01:47:52,084 iteration 5111 : loss : 0.024797, loss_ce: 0.009122
2022-01-16 01:47:53,244 iteration 5112 : loss : 0.019425, loss_ce: 0.006435
2022-01-16 01:47:54,306 iteration 5113 : loss : 0.021793, loss_ce: 0.008186
2022-01-16 01:47:55,412 iteration 5114 : loss : 0.021253, loss_ce: 0.009121
2022-01-16 01:47:56,431 iteration 5115 : loss : 0.024836, loss_ce: 0.007874
2022-01-16 01:47:57,421 iteration 5116 : loss : 0.024221, loss_ce: 0.012421
2022-01-16 01:47:58,473 iteration 5117 : loss : 0.023794, loss_ce: 0.009410
 75%|█████████████████████▊       | 301/400 [2:08:46<40:37, 24.62s/it]2022-01-16 01:47:59,579 iteration 5118 : loss : 0.026635, loss_ce: 0.007840
2022-01-16 01:48:00,578 iteration 5119 : loss : 0.015051, loss_ce: 0.006588
2022-01-16 01:48:01,531 iteration 5120 : loss : 0.014051, loss_ce: 0.005875
2022-01-16 01:48:02,592 iteration 5121 : loss : 0.020009, loss_ce: 0.005913
2022-01-16 01:48:03,688 iteration 5122 : loss : 0.019922, loss_ce: 0.008745
2022-01-16 01:48:04,776 iteration 5123 : loss : 0.022275, loss_ce: 0.007060
2022-01-16 01:48:05,735 iteration 5124 : loss : 0.014299, loss_ce: 0.006667
2022-01-16 01:48:06,692 iteration 5125 : loss : 0.017804, loss_ce: 0.006032
2022-01-16 01:48:07,715 iteration 5126 : loss : 0.036986, loss_ce: 0.012759
2022-01-16 01:48:08,713 iteration 5127 : loss : 0.018216, loss_ce: 0.007399
2022-01-16 01:48:09,681 iteration 5128 : loss : 0.022277, loss_ce: 0.006784
2022-01-16 01:48:10,701 iteration 5129 : loss : 0.015728, loss_ce: 0.006643
2022-01-16 01:48:11,703 iteration 5130 : loss : 0.015104, loss_ce: 0.006136
2022-01-16 01:48:12,731 iteration 5131 : loss : 0.026290, loss_ce: 0.010001
2022-01-16 01:48:13,737 iteration 5132 : loss : 0.017347, loss_ce: 0.006456
2022-01-16 01:48:14,812 iteration 5133 : loss : 0.035918, loss_ce: 0.012971
2022-01-16 01:48:15,816 iteration 5134 : loss : 0.021928, loss_ce: 0.005895
 76%|█████████████████████▉       | 302/400 [2:09:04<36:38, 22.43s/it]2022-01-16 01:48:16,869 iteration 5135 : loss : 0.018076, loss_ce: 0.009608
2022-01-16 01:48:17,895 iteration 5136 : loss : 0.014969, loss_ce: 0.004949
2022-01-16 01:48:18,850 iteration 5137 : loss : 0.017940, loss_ce: 0.006348
2022-01-16 01:48:19,905 iteration 5138 : loss : 0.018539, loss_ce: 0.007696
2022-01-16 01:48:21,023 iteration 5139 : loss : 0.026115, loss_ce: 0.010730
2022-01-16 01:48:22,102 iteration 5140 : loss : 0.019998, loss_ce: 0.007381
2022-01-16 01:48:23,065 iteration 5141 : loss : 0.020724, loss_ce: 0.007769
2022-01-16 01:48:24,091 iteration 5142 : loss : 0.019637, loss_ce: 0.005932
2022-01-16 01:48:25,088 iteration 5143 : loss : 0.013977, loss_ce: 0.006449
2022-01-16 01:48:26,176 iteration 5144 : loss : 0.017481, loss_ce: 0.007653
2022-01-16 01:48:27,315 iteration 5145 : loss : 0.012841, loss_ce: 0.003725
2022-01-16 01:48:28,366 iteration 5146 : loss : 0.012826, loss_ce: 0.003857
2022-01-16 01:48:29,320 iteration 5147 : loss : 0.018379, loss_ce: 0.003940
2022-01-16 01:48:30,322 iteration 5148 : loss : 0.019883, loss_ce: 0.007660
2022-01-16 01:48:31,309 iteration 5149 : loss : 0.017052, loss_ce: 0.006155
2022-01-16 01:48:32,300 iteration 5150 : loss : 0.017135, loss_ce: 0.008472
2022-01-16 01:48:33,352 iteration 5151 : loss : 0.015929, loss_ce: 0.007106
 76%|█████████████████████▉       | 303/400 [2:09:21<33:53, 20.97s/it]2022-01-16 01:48:34,403 iteration 5152 : loss : 0.019755, loss_ce: 0.008398
2022-01-16 01:48:35,423 iteration 5153 : loss : 0.016456, loss_ce: 0.006267
2022-01-16 01:48:36,363 iteration 5154 : loss : 0.016416, loss_ce: 0.005184
2022-01-16 01:48:37,319 iteration 5155 : loss : 0.015060, loss_ce: 0.005396
2022-01-16 01:48:38,312 iteration 5156 : loss : 0.020568, loss_ce: 0.004952
2022-01-16 01:48:39,267 iteration 5157 : loss : 0.011016, loss_ce: 0.004134
2022-01-16 01:48:40,236 iteration 5158 : loss : 0.018049, loss_ce: 0.007523
2022-01-16 01:48:41,261 iteration 5159 : loss : 0.016014, loss_ce: 0.006250
2022-01-16 01:48:42,277 iteration 5160 : loss : 0.017431, loss_ce: 0.007555
2022-01-16 01:48:43,332 iteration 5161 : loss : 0.019910, loss_ce: 0.007812
2022-01-16 01:48:44,417 iteration 5162 : loss : 0.015502, loss_ce: 0.003938
2022-01-16 01:48:45,450 iteration 5163 : loss : 0.015497, loss_ce: 0.007447
2022-01-16 01:48:46,410 iteration 5164 : loss : 0.015120, loss_ce: 0.005191
2022-01-16 01:48:47,488 iteration 5165 : loss : 0.019168, loss_ce: 0.006769
2022-01-16 01:48:48,515 iteration 5166 : loss : 0.015833, loss_ce: 0.005987
2022-01-16 01:48:49,573 iteration 5167 : loss : 0.024873, loss_ce: 0.006391
2022-01-16 01:48:50,494 iteration 5168 : loss : 0.013692, loss_ce: 0.006497
 76%|██████████████████████       | 304/400 [2:09:38<31:42, 19.82s/it]2022-01-16 01:48:51,606 iteration 5169 : loss : 0.014894, loss_ce: 0.004009
2022-01-16 01:48:52,596 iteration 5170 : loss : 0.013115, loss_ce: 0.006614
2022-01-16 01:48:53,606 iteration 5171 : loss : 0.026383, loss_ce: 0.007631
2022-01-16 01:48:54,629 iteration 5172 : loss : 0.019888, loss_ce: 0.007219
2022-01-16 01:48:55,717 iteration 5173 : loss : 0.020761, loss_ce: 0.008385
2022-01-16 01:48:56,736 iteration 5174 : loss : 0.011668, loss_ce: 0.003237
2022-01-16 01:48:57,784 iteration 5175 : loss : 0.015307, loss_ce: 0.005255
2022-01-16 01:48:58,879 iteration 5176 : loss : 0.016668, loss_ce: 0.005547
2022-01-16 01:48:59,905 iteration 5177 : loss : 0.015243, loss_ce: 0.005266
2022-01-16 01:49:00,936 iteration 5178 : loss : 0.014938, loss_ce: 0.007238
2022-01-16 01:49:01,926 iteration 5179 : loss : 0.015086, loss_ce: 0.006465
2022-01-16 01:49:02,865 iteration 5180 : loss : 0.016194, loss_ce: 0.006802
2022-01-16 01:49:03,834 iteration 5181 : loss : 0.016903, loss_ce: 0.005887
2022-01-16 01:49:04,822 iteration 5182 : loss : 0.016601, loss_ce: 0.007462
2022-01-16 01:49:05,807 iteration 5183 : loss : 0.012303, loss_ce: 0.003871
2022-01-16 01:49:06,780 iteration 5184 : loss : 0.018452, loss_ce: 0.009436
2022-01-16 01:49:06,780 Training Data Eval:
2022-01-16 01:49:11,586   Average segmentation loss on training set: 0.0100
2022-01-16 01:49:11,586 Validation Data Eval:
2022-01-16 01:49:13,221   Average segmentation loss on validation set: 0.0849
2022-01-16 01:49:14,200 iteration 5185 : loss : 0.012452, loss_ce: 0.004616
 76%|██████████████████████       | 305/400 [2:10:02<33:13, 20.98s/it]2022-01-16 01:49:15,302 iteration 5186 : loss : 0.021346, loss_ce: 0.006195
2022-01-16 01:49:16,254 iteration 5187 : loss : 0.012279, loss_ce: 0.005298
2022-01-16 01:49:17,258 iteration 5188 : loss : 0.030906, loss_ce: 0.007962
2022-01-16 01:49:18,279 iteration 5189 : loss : 0.022408, loss_ce: 0.006605
2022-01-16 01:49:19,378 iteration 5190 : loss : 0.026465, loss_ce: 0.011930
2022-01-16 01:49:20,361 iteration 5191 : loss : 0.017202, loss_ce: 0.006160
2022-01-16 01:49:21,363 iteration 5192 : loss : 0.017107, loss_ce: 0.006859
2022-01-16 01:49:22,412 iteration 5193 : loss : 0.017169, loss_ce: 0.008041
2022-01-16 01:49:23,446 iteration 5194 : loss : 0.020382, loss_ce: 0.005349
2022-01-16 01:49:24,443 iteration 5195 : loss : 0.025652, loss_ce: 0.008031
2022-01-16 01:49:25,551 iteration 5196 : loss : 0.022386, loss_ce: 0.007423
2022-01-16 01:49:26,556 iteration 5197 : loss : 0.030610, loss_ce: 0.008365
2022-01-16 01:49:27,523 iteration 5198 : loss : 0.014679, loss_ce: 0.008755
2022-01-16 01:49:28,642 iteration 5199 : loss : 0.015532, loss_ce: 0.005445
2022-01-16 01:49:29,578 iteration 5200 : loss : 0.014812, loss_ce: 0.006193
2022-01-16 01:49:30,521 iteration 5201 : loss : 0.013269, loss_ce: 0.005672
2022-01-16 01:49:31,523 iteration 5202 : loss : 0.016317, loss_ce: 0.006471
 76%|██████████████████████▏      | 306/400 [2:10:19<31:09, 19.89s/it]2022-01-16 01:49:32,573 iteration 5203 : loss : 0.017844, loss_ce: 0.007552
2022-01-16 01:49:33,636 iteration 5204 : loss : 0.016408, loss_ce: 0.006829
2022-01-16 01:49:34,685 iteration 5205 : loss : 0.030316, loss_ce: 0.007100
2022-01-16 01:49:35,826 iteration 5206 : loss : 0.021030, loss_ce: 0.008396
2022-01-16 01:49:36,896 iteration 5207 : loss : 0.037782, loss_ce: 0.009699
2022-01-16 01:49:37,924 iteration 5208 : loss : 0.012164, loss_ce: 0.005426
2022-01-16 01:49:39,002 iteration 5209 : loss : 0.020859, loss_ce: 0.007998
2022-01-16 01:49:40,079 iteration 5210 : loss : 0.024686, loss_ce: 0.011585
2022-01-16 01:49:41,125 iteration 5211 : loss : 0.049563, loss_ce: 0.018840
2022-01-16 01:49:42,214 iteration 5212 : loss : 0.032370, loss_ce: 0.010405
2022-01-16 01:49:43,265 iteration 5213 : loss : 0.014989, loss_ce: 0.005492
2022-01-16 01:49:44,330 iteration 5214 : loss : 0.016864, loss_ce: 0.007629
2022-01-16 01:49:45,368 iteration 5215 : loss : 0.014157, loss_ce: 0.004997
2022-01-16 01:49:46,522 iteration 5216 : loss : 0.018739, loss_ce: 0.005863
2022-01-16 01:49:47,799 iteration 5217 : loss : 0.024838, loss_ce: 0.011049
2022-01-16 01:49:49,042 iteration 5218 : loss : 0.028892, loss_ce: 0.014277
2022-01-16 01:49:50,397 iteration 5219 : loss : 0.030213, loss_ce: 0.014642
 77%|██████████████████████▎      | 307/400 [2:10:38<30:21, 19.58s/it]2022-01-16 01:49:51,768 iteration 5220 : loss : 0.018137, loss_ce: 0.008083
2022-01-16 01:49:53,112 iteration 5221 : loss : 0.034100, loss_ce: 0.011397
2022-01-16 01:49:54,565 iteration 5222 : loss : 0.023827, loss_ce: 0.007176
2022-01-16 01:49:55,994 iteration 5223 : loss : 0.024526, loss_ce: 0.011075
2022-01-16 01:49:57,472 iteration 5224 : loss : 0.033817, loss_ce: 0.008202
2022-01-16 01:49:58,830 iteration 5225 : loss : 0.016465, loss_ce: 0.006677
2022-01-16 01:50:00,196 iteration 5226 : loss : 0.018326, loss_ce: 0.007410
2022-01-16 01:50:01,580 iteration 5227 : loss : 0.028479, loss_ce: 0.010475
2022-01-16 01:50:02,858 iteration 5228 : loss : 0.017118, loss_ce: 0.005609
2022-01-16 01:50:04,240 iteration 5229 : loss : 0.027866, loss_ce: 0.010992
2022-01-16 01:50:05,551 iteration 5230 : loss : 0.016644, loss_ce: 0.005734
2022-01-16 01:50:06,892 iteration 5231 : loss : 0.018809, loss_ce: 0.005379
2022-01-16 01:50:08,308 iteration 5232 : loss : 0.026776, loss_ce: 0.009379
2022-01-16 01:50:09,566 iteration 5233 : loss : 0.019986, loss_ce: 0.007873
2022-01-16 01:50:10,954 iteration 5234 : loss : 0.025315, loss_ce: 0.009310
2022-01-16 01:50:12,402 iteration 5235 : loss : 0.024233, loss_ce: 0.010780
2022-01-16 01:50:13,951 iteration 5236 : loss : 0.033945, loss_ce: 0.013769
 77%|██████████████████████▎      | 308/400 [2:11:02<31:51, 20.77s/it]2022-01-16 01:50:15,582 iteration 5237 : loss : 0.014652, loss_ce: 0.006685
2022-01-16 01:50:17,149 iteration 5238 : loss : 0.018063, loss_ce: 0.007566
2022-01-16 01:50:18,692 iteration 5239 : loss : 0.017544, loss_ce: 0.005998
2022-01-16 01:50:20,259 iteration 5240 : loss : 0.051370, loss_ce: 0.007951
2022-01-16 01:50:21,862 iteration 5241 : loss : 0.020652, loss_ce: 0.007593
2022-01-16 01:50:23,627 iteration 5242 : loss : 0.026286, loss_ce: 0.011150
2022-01-16 01:50:25,225 iteration 5243 : loss : 0.022882, loss_ce: 0.011844
2022-01-16 01:50:26,857 iteration 5244 : loss : 0.019655, loss_ce: 0.006618
2022-01-16 01:50:28,491 iteration 5245 : loss : 0.020766, loss_ce: 0.006188
2022-01-16 01:50:30,223 iteration 5246 : loss : 0.022145, loss_ce: 0.008172
2022-01-16 01:50:31,738 iteration 5247 : loss : 0.020131, loss_ce: 0.006807
2022-01-16 01:50:33,295 iteration 5248 : loss : 0.021565, loss_ce: 0.009975
2022-01-16 01:50:34,785 iteration 5249 : loss : 0.017901, loss_ce: 0.006671
2022-01-16 01:50:36,378 iteration 5250 : loss : 0.017326, loss_ce: 0.005623
2022-01-16 01:50:38,012 iteration 5251 : loss : 0.036063, loss_ce: 0.016686
2022-01-16 01:50:39,584 iteration 5252 : loss : 0.016004, loss_ce: 0.007801
2022-01-16 01:50:41,086 iteration 5253 : loss : 0.016551, loss_ce: 0.005840
 77%|██████████████████████▍      | 309/400 [2:11:29<34:24, 22.68s/it]2022-01-16 01:50:42,663 iteration 5254 : loss : 0.019273, loss_ce: 0.008683
2022-01-16 01:50:44,155 iteration 5255 : loss : 0.014910, loss_ce: 0.004350
2022-01-16 01:50:45,636 iteration 5256 : loss : 0.026447, loss_ce: 0.011690
2022-01-16 01:50:47,223 iteration 5257 : loss : 0.018732, loss_ce: 0.006880
2022-01-16 01:50:48,720 iteration 5258 : loss : 0.014986, loss_ce: 0.006141
2022-01-16 01:50:50,278 iteration 5259 : loss : 0.023779, loss_ce: 0.008364
2022-01-16 01:50:51,919 iteration 5260 : loss : 0.034323, loss_ce: 0.010844
2022-01-16 01:50:53,485 iteration 5261 : loss : 0.016184, loss_ce: 0.006517
2022-01-16 01:50:55,040 iteration 5262 : loss : 0.019141, loss_ce: 0.007911
2022-01-16 01:50:56,655 iteration 5263 : loss : 0.018287, loss_ce: 0.008323
2022-01-16 01:50:58,275 iteration 5264 : loss : 0.022653, loss_ce: 0.008477
2022-01-16 01:51:00,060 iteration 5265 : loss : 0.020899, loss_ce: 0.009851
2022-01-16 01:51:01,564 iteration 5266 : loss : 0.018087, loss_ce: 0.006539
2022-01-16 01:51:03,292 iteration 5267 : loss : 0.024034, loss_ce: 0.011273
2022-01-16 01:51:04,868 iteration 5268 : loss : 0.014611, loss_ce: 0.003237
2022-01-16 01:51:06,334 iteration 5269 : loss : 0.016093, loss_ce: 0.005918
2022-01-16 01:51:06,334 Training Data Eval:
2022-01-16 01:51:14,671   Average segmentation loss on training set: 0.0115
2022-01-16 01:51:14,671 Validation Data Eval:
2022-01-16 01:51:17,441   Average segmentation loss on validation set: 0.0725
2022-01-16 01:51:19,009 iteration 5270 : loss : 0.020238, loss_ce: 0.002949
 78%|██████████████████████▍      | 310/400 [2:12:07<40:53, 27.26s/it]2022-01-16 01:51:20,681 iteration 5271 : loss : 0.034684, loss_ce: 0.009999
2022-01-16 01:51:22,226 iteration 5272 : loss : 0.021439, loss_ce: 0.008099
2022-01-16 01:51:23,726 iteration 5273 : loss : 0.023121, loss_ce: 0.012044
2022-01-16 01:51:25,244 iteration 5274 : loss : 0.021443, loss_ce: 0.007556
2022-01-16 01:51:26,721 iteration 5275 : loss : 0.015906, loss_ce: 0.006427
2022-01-16 01:51:28,187 iteration 5276 : loss : 0.021607, loss_ce: 0.008322
2022-01-16 01:51:29,785 iteration 5277 : loss : 0.025317, loss_ce: 0.010300
2022-01-16 01:51:31,289 iteration 5278 : loss : 0.024701, loss_ce: 0.006071
2022-01-16 01:51:32,933 iteration 5279 : loss : 0.034290, loss_ce: 0.014451
2022-01-16 01:51:34,432 iteration 5280 : loss : 0.016861, loss_ce: 0.004697
2022-01-16 01:51:35,999 iteration 5281 : loss : 0.014389, loss_ce: 0.006288
2022-01-16 01:51:37,528 iteration 5282 : loss : 0.020946, loss_ce: 0.008510
2022-01-16 01:51:39,083 iteration 5283 : loss : 0.019482, loss_ce: 0.008540
2022-01-16 01:51:40,619 iteration 5284 : loss : 0.017471, loss_ce: 0.005899
2022-01-16 01:51:42,108 iteration 5285 : loss : 0.019340, loss_ce: 0.007097
2022-01-16 01:51:43,650 iteration 5286 : loss : 0.020587, loss_ce: 0.011390
2022-01-16 01:51:45,238 iteration 5287 : loss : 0.013815, loss_ce: 0.004910
 78%|██████████████████████▌      | 311/400 [2:12:33<39:58, 26.95s/it]2022-01-16 01:51:46,819 iteration 5288 : loss : 0.019873, loss_ce: 0.009757
2022-01-16 01:51:48,548 iteration 5289 : loss : 0.019210, loss_ce: 0.006996
2022-01-16 01:51:50,293 iteration 5290 : loss : 0.024716, loss_ce: 0.006942
2022-01-16 01:51:52,022 iteration 5291 : loss : 0.018446, loss_ce: 0.006690
2022-01-16 01:51:53,576 iteration 5292 : loss : 0.020681, loss_ce: 0.005299
2022-01-16 01:51:55,193 iteration 5293 : loss : 0.020812, loss_ce: 0.006976
2022-01-16 01:51:56,948 iteration 5294 : loss : 0.022888, loss_ce: 0.006891
2022-01-16 01:51:58,532 iteration 5295 : loss : 0.015910, loss_ce: 0.004918
2022-01-16 01:52:00,041 iteration 5296 : loss : 0.021306, loss_ce: 0.005460
2022-01-16 01:52:01,600 iteration 5297 : loss : 0.021327, loss_ce: 0.006963
2022-01-16 01:52:03,246 iteration 5298 : loss : 0.014522, loss_ce: 0.006508
2022-01-16 01:52:04,812 iteration 5299 : loss : 0.020889, loss_ce: 0.004213
2022-01-16 01:52:06,440 iteration 5300 : loss : 0.014175, loss_ce: 0.005767
2022-01-16 01:52:07,986 iteration 5301 : loss : 0.022678, loss_ce: 0.006211
2022-01-16 01:52:09,687 iteration 5302 : loss : 0.017878, loss_ce: 0.006947
2022-01-16 01:52:11,366 iteration 5303 : loss : 0.018240, loss_ce: 0.008205
2022-01-16 01:52:13,063 iteration 5304 : loss : 0.021583, loss_ce: 0.011663
 78%|██████████████████████▌      | 312/400 [2:13:01<39:54, 27.21s/it]2022-01-16 01:52:14,655 iteration 5305 : loss : 0.010416, loss_ce: 0.003734
2022-01-16 01:52:16,412 iteration 5306 : loss : 0.029419, loss_ce: 0.012069
2022-01-16 01:52:17,986 iteration 5307 : loss : 0.024179, loss_ce: 0.008961
2022-01-16 01:52:19,709 iteration 5308 : loss : 0.011772, loss_ce: 0.004028
2022-01-16 01:52:21,310 iteration 5309 : loss : 0.018737, loss_ce: 0.008955
2022-01-16 01:52:23,113 iteration 5310 : loss : 0.016040, loss_ce: 0.004973
2022-01-16 01:52:24,804 iteration 5311 : loss : 0.019700, loss_ce: 0.008100
2022-01-16 01:52:26,534 iteration 5312 : loss : 0.023302, loss_ce: 0.009924
2022-01-16 01:52:28,220 iteration 5313 : loss : 0.016685, loss_ce: 0.008301
2022-01-16 01:52:29,826 iteration 5314 : loss : 0.018513, loss_ce: 0.006379
2022-01-16 01:52:31,496 iteration 5315 : loss : 0.019071, loss_ce: 0.006205
2022-01-16 01:52:33,199 iteration 5316 : loss : 0.014345, loss_ce: 0.004389
2022-01-16 01:52:34,761 iteration 5317 : loss : 0.014518, loss_ce: 0.004568
2022-01-16 01:52:36,412 iteration 5318 : loss : 0.020355, loss_ce: 0.008064
2022-01-16 01:52:38,004 iteration 5319 : loss : 0.031099, loss_ce: 0.009029
2022-01-16 01:52:39,521 iteration 5320 : loss : 0.016523, loss_ce: 0.005587
2022-01-16 01:52:41,194 iteration 5321 : loss : 0.016812, loss_ce: 0.006640
 78%|██████████████████████▋      | 313/400 [2:13:29<39:51, 27.49s/it]2022-01-16 01:52:42,893 iteration 5322 : loss : 0.020438, loss_ce: 0.007608
2022-01-16 01:52:44,489 iteration 5323 : loss : 0.018551, loss_ce: 0.004816
2022-01-16 01:52:46,190 iteration 5324 : loss : 0.017534, loss_ce: 0.005706
2022-01-16 01:52:47,985 iteration 5325 : loss : 0.018763, loss_ce: 0.007706
2022-01-16 01:52:49,696 iteration 5326 : loss : 0.020915, loss_ce: 0.007987
2022-01-16 01:52:51,394 iteration 5327 : loss : 0.018259, loss_ce: 0.008699
2022-01-16 01:52:53,013 iteration 5328 : loss : 0.015292, loss_ce: 0.004634
2022-01-16 01:52:54,650 iteration 5329 : loss : 0.018674, loss_ce: 0.009485
2022-01-16 01:52:56,343 iteration 5330 : loss : 0.015303, loss_ce: 0.005093
2022-01-16 01:52:58,022 iteration 5331 : loss : 0.016039, loss_ce: 0.005538
2022-01-16 01:52:59,713 iteration 5332 : loss : 0.018062, loss_ce: 0.006715
2022-01-16 01:53:01,268 iteration 5333 : loss : 0.021602, loss_ce: 0.006555
2022-01-16 01:53:02,965 iteration 5334 : loss : 0.012872, loss_ce: 0.003862
2022-01-16 01:53:04,671 iteration 5335 : loss : 0.022538, loss_ce: 0.007053
2022-01-16 01:53:06,285 iteration 5336 : loss : 0.017305, loss_ce: 0.005837
2022-01-16 01:53:07,950 iteration 5337 : loss : 0.017965, loss_ce: 0.006932
2022-01-16 01:53:09,421 iteration 5338 : loss : 0.013783, loss_ce: 0.004995
 78%|██████████████████████▊      | 314/400 [2:13:57<39:42, 27.71s/it]2022-01-16 01:53:11,133 iteration 5339 : loss : 0.017382, loss_ce: 0.006840
2022-01-16 01:53:12,698 iteration 5340 : loss : 0.015247, loss_ce: 0.009432
2022-01-16 01:53:14,228 iteration 5341 : loss : 0.020974, loss_ce: 0.008006
2022-01-16 01:53:15,737 iteration 5342 : loss : 0.019219, loss_ce: 0.004778
2022-01-16 01:53:17,192 iteration 5343 : loss : 0.021532, loss_ce: 0.008259
2022-01-16 01:53:18,628 iteration 5344 : loss : 0.016682, loss_ce: 0.007959
2022-01-16 01:53:20,062 iteration 5345 : loss : 0.016305, loss_ce: 0.004392
2022-01-16 01:53:21,555 iteration 5346 : loss : 0.018406, loss_ce: 0.006988
2022-01-16 01:53:23,263 iteration 5347 : loss : 0.018547, loss_ce: 0.007939
2022-01-16 01:53:24,823 iteration 5348 : loss : 0.022902, loss_ce: 0.008875
2022-01-16 01:53:26,353 iteration 5349 : loss : 0.013424, loss_ce: 0.005807
2022-01-16 01:53:27,855 iteration 5350 : loss : 0.013236, loss_ce: 0.004824
2022-01-16 01:53:29,448 iteration 5351 : loss : 0.019437, loss_ce: 0.004250
2022-01-16 01:53:31,193 iteration 5352 : loss : 0.020156, loss_ce: 0.006921
2022-01-16 01:53:32,821 iteration 5353 : loss : 0.019098, loss_ce: 0.008866
2022-01-16 01:53:34,352 iteration 5354 : loss : 0.014793, loss_ce: 0.005791
2022-01-16 01:53:34,352 Training Data Eval:
2022-01-16 01:53:42,064   Average segmentation loss on training set: 0.0101
2022-01-16 01:53:42,064 Validation Data Eval:
2022-01-16 01:53:44,664   Average segmentation loss on validation set: 0.0649
2022-01-16 01:53:46,108 iteration 5355 : loss : 0.012381, loss_ce: 0.004761
 79%|██████████████████████▊      | 315/400 [2:14:34<43:04, 30.40s/it]2022-01-16 01:53:47,725 iteration 5356 : loss : 0.018052, loss_ce: 0.007925
2022-01-16 01:53:49,135 iteration 5357 : loss : 0.011265, loss_ce: 0.003299
2022-01-16 01:53:50,778 iteration 5358 : loss : 0.014446, loss_ce: 0.003835
2022-01-16 01:53:52,270 iteration 5359 : loss : 0.014904, loss_ce: 0.008580
2022-01-16 01:53:53,899 iteration 5360 : loss : 0.013733, loss_ce: 0.004747
2022-01-16 01:53:55,469 iteration 5361 : loss : 0.021712, loss_ce: 0.006556
2022-01-16 01:53:57,117 iteration 5362 : loss : 0.022800, loss_ce: 0.013037
2022-01-16 01:53:58,692 iteration 5363 : loss : 0.015238, loss_ce: 0.006422
2022-01-16 01:54:00,255 iteration 5364 : loss : 0.015028, loss_ce: 0.002195
2022-01-16 01:54:01,812 iteration 5365 : loss : 0.017292, loss_ce: 0.006482
2022-01-16 01:54:03,322 iteration 5366 : loss : 0.016815, loss_ce: 0.006078
2022-01-16 01:54:04,855 iteration 5367 : loss : 0.016743, loss_ce: 0.003816
2022-01-16 01:54:06,450 iteration 5368 : loss : 0.018459, loss_ce: 0.007214
2022-01-16 01:54:07,958 iteration 5369 : loss : 0.030572, loss_ce: 0.019557
2022-01-16 01:54:09,612 iteration 5370 : loss : 0.022766, loss_ce: 0.006686
2022-01-16 01:54:11,213 iteration 5371 : loss : 0.017447, loss_ce: 0.004577
2022-01-16 01:54:12,698 iteration 5372 : loss : 0.019184, loss_ce: 0.008513
 79%|██████████████████████▉      | 316/400 [2:15:01<40:57, 29.26s/it]2022-01-16 01:54:14,167 iteration 5373 : loss : 0.015972, loss_ce: 0.007683
2022-01-16 01:54:15,624 iteration 5374 : loss : 0.021617, loss_ce: 0.006082
2022-01-16 01:54:17,037 iteration 5375 : loss : 0.016962, loss_ce: 0.006676
2022-01-16 01:54:18,414 iteration 5376 : loss : 0.015537, loss_ce: 0.004986
2022-01-16 01:54:19,799 iteration 5377 : loss : 0.019518, loss_ce: 0.002997
2022-01-16 01:54:21,219 iteration 5378 : loss : 0.012168, loss_ce: 0.004778
2022-01-16 01:54:22,747 iteration 5379 : loss : 0.023135, loss_ce: 0.006856
2022-01-16 01:54:24,235 iteration 5380 : loss : 0.014895, loss_ce: 0.006841
2022-01-16 01:54:25,716 iteration 5381 : loss : 0.022062, loss_ce: 0.008137
2022-01-16 01:54:27,216 iteration 5382 : loss : 0.034706, loss_ce: 0.009883
2022-01-16 01:54:28,751 iteration 5383 : loss : 0.019137, loss_ce: 0.008348
2022-01-16 01:54:30,245 iteration 5384 : loss : 0.017740, loss_ce: 0.007942
2022-01-16 01:54:31,726 iteration 5385 : loss : 0.016163, loss_ce: 0.007508
2022-01-16 01:54:33,256 iteration 5386 : loss : 0.016052, loss_ce: 0.006145
2022-01-16 01:54:34,754 iteration 5387 : loss : 0.016276, loss_ce: 0.007005
2022-01-16 01:54:36,245 iteration 5388 : loss : 0.015129, loss_ce: 0.005757
2022-01-16 01:54:37,784 iteration 5389 : loss : 0.015395, loss_ce: 0.005167
 79%|██████████████████████▉      | 317/400 [2:15:26<38:44, 28.00s/it]2022-01-16 01:54:39,422 iteration 5390 : loss : 0.017085, loss_ce: 0.005273
2022-01-16 01:54:41,018 iteration 5391 : loss : 0.016088, loss_ce: 0.005287
2022-01-16 01:54:42,550 iteration 5392 : loss : 0.016249, loss_ce: 0.007725
2022-01-16 01:54:44,172 iteration 5393 : loss : 0.021358, loss_ce: 0.007345
2022-01-16 01:54:45,731 iteration 5394 : loss : 0.014582, loss_ce: 0.005685
2022-01-16 01:54:47,263 iteration 5395 : loss : 0.013491, loss_ce: 0.005956
2022-01-16 01:54:48,888 iteration 5396 : loss : 0.022550, loss_ce: 0.006986
2022-01-16 01:54:50,501 iteration 5397 : loss : 0.025805, loss_ce: 0.008842
2022-01-16 01:54:52,124 iteration 5398 : loss : 0.011654, loss_ce: 0.005755
2022-01-16 01:54:53,814 iteration 5399 : loss : 0.015551, loss_ce: 0.006676
2022-01-16 01:54:55,590 iteration 5400 : loss : 0.023756, loss_ce: 0.007583
2022-01-16 01:54:57,201 iteration 5401 : loss : 0.021200, loss_ce: 0.006971
2022-01-16 01:54:58,770 iteration 5402 : loss : 0.014310, loss_ce: 0.005077
2022-01-16 01:55:00,556 iteration 5403 : loss : 0.020675, loss_ce: 0.006010
2022-01-16 01:55:02,110 iteration 5404 : loss : 0.015466, loss_ce: 0.007245
2022-01-16 01:55:03,784 iteration 5405 : loss : 0.012083, loss_ce: 0.004128
2022-01-16 01:55:05,380 iteration 5406 : loss : 0.016647, loss_ce: 0.004138
 80%|███████████████████████      | 318/400 [2:15:53<38:06, 27.89s/it]2022-01-16 01:55:07,151 iteration 5407 : loss : 0.015322, loss_ce: 0.004735
2022-01-16 01:55:08,725 iteration 5408 : loss : 0.016606, loss_ce: 0.004561
2022-01-16 01:55:10,326 iteration 5409 : loss : 0.013607, loss_ce: 0.006232
2022-01-16 01:55:11,876 iteration 5410 : loss : 0.014218, loss_ce: 0.004581
2022-01-16 01:55:13,635 iteration 5411 : loss : 0.015545, loss_ce: 0.005103
2022-01-16 01:55:15,275 iteration 5412 : loss : 0.025482, loss_ce: 0.012954
2022-01-16 01:55:16,868 iteration 5413 : loss : 0.014397, loss_ce: 0.005413
2022-01-16 01:55:18,602 iteration 5414 : loss : 0.016300, loss_ce: 0.005804
2022-01-16 01:55:20,197 iteration 5415 : loss : 0.020405, loss_ce: 0.008112
2022-01-16 01:55:21,823 iteration 5416 : loss : 0.020181, loss_ce: 0.008575
2022-01-16 01:55:23,456 iteration 5417 : loss : 0.015776, loss_ce: 0.005953
2022-01-16 01:55:24,969 iteration 5418 : loss : 0.014786, loss_ce: 0.005173
2022-01-16 01:55:26,598 iteration 5419 : loss : 0.014563, loss_ce: 0.006663
2022-01-16 01:55:28,129 iteration 5420 : loss : 0.013398, loss_ce: 0.005760
2022-01-16 01:55:29,647 iteration 5421 : loss : 0.021312, loss_ce: 0.006815
2022-01-16 01:55:31,165 iteration 5422 : loss : 0.027023, loss_ce: 0.008446
2022-01-16 01:55:32,720 iteration 5423 : loss : 0.026649, loss_ce: 0.007405
 80%|███████████████████████▏     | 319/400 [2:16:21<37:25, 27.72s/it]2022-01-16 01:55:34,358 iteration 5424 : loss : 0.019252, loss_ce: 0.007220
2022-01-16 01:55:35,923 iteration 5425 : loss : 0.033693, loss_ce: 0.014903
2022-01-16 01:55:37,454 iteration 5426 : loss : 0.015590, loss_ce: 0.004558
2022-01-16 01:55:39,009 iteration 5427 : loss : 0.016524, loss_ce: 0.005513
2022-01-16 01:55:40,463 iteration 5428 : loss : 0.024439, loss_ce: 0.010496
2022-01-16 01:55:41,765 iteration 5429 : loss : 0.016884, loss_ce: 0.006355
2022-01-16 01:55:43,002 iteration 5430 : loss : 0.016455, loss_ce: 0.006793
2022-01-16 01:55:44,346 iteration 5431 : loss : 0.021717, loss_ce: 0.007735
2022-01-16 01:55:45,558 iteration 5432 : loss : 0.019355, loss_ce: 0.006804
2022-01-16 01:55:46,863 iteration 5433 : loss : 0.019787, loss_ce: 0.006533
2022-01-16 01:55:48,094 iteration 5434 : loss : 0.021661, loss_ce: 0.008221
2022-01-16 01:55:49,239 iteration 5435 : loss : 0.017129, loss_ce: 0.006641
2022-01-16 01:55:50,372 iteration 5436 : loss : 0.019553, loss_ce: 0.009429
2022-01-16 01:55:51,434 iteration 5437 : loss : 0.018669, loss_ce: 0.004782
2022-01-16 01:55:52,553 iteration 5438 : loss : 0.024229, loss_ce: 0.009788
2022-01-16 01:55:53,695 iteration 5439 : loss : 0.019110, loss_ce: 0.006605
2022-01-16 01:55:53,695 Training Data Eval:
2022-01-16 01:55:58,948   Average segmentation loss on training set: 0.0101
2022-01-16 01:55:58,948 Validation Data Eval:
2022-01-16 01:56:00,672   Average segmentation loss on validation set: 0.0728
2022-01-16 01:56:01,720 iteration 5440 : loss : 0.016404, loss_ce: 0.006131
 80%|███████████████████████▏     | 320/400 [2:16:50<37:28, 28.11s/it]2022-01-16 01:56:02,733 iteration 5441 : loss : 0.014030, loss_ce: 0.006049
2022-01-16 01:56:03,860 iteration 5442 : loss : 0.022891, loss_ce: 0.009024
2022-01-16 01:56:04,905 iteration 5443 : loss : 0.024333, loss_ce: 0.009900
2022-01-16 01:56:05,900 iteration 5444 : loss : 0.015435, loss_ce: 0.007075
2022-01-16 01:56:06,884 iteration 5445 : loss : 0.017843, loss_ce: 0.007522
2022-01-16 01:56:07,892 iteration 5446 : loss : 0.019371, loss_ce: 0.007888
2022-01-16 01:56:08,830 iteration 5447 : loss : 0.017482, loss_ce: 0.003132
2022-01-16 01:56:09,876 iteration 5448 : loss : 0.021032, loss_ce: 0.008136
2022-01-16 01:56:10,902 iteration 5449 : loss : 0.014009, loss_ce: 0.004117
2022-01-16 01:56:11,927 iteration 5450 : loss : 0.018147, loss_ce: 0.005683
2022-01-16 01:56:13,039 iteration 5451 : loss : 0.011420, loss_ce: 0.003230
2022-01-16 01:56:14,181 iteration 5452 : loss : 0.012430, loss_ce: 0.004888
2022-01-16 01:56:15,378 iteration 5453 : loss : 0.015314, loss_ce: 0.005426
2022-01-16 01:56:16,623 iteration 5454 : loss : 0.023492, loss_ce: 0.010268
2022-01-16 01:56:17,918 iteration 5455 : loss : 0.016140, loss_ce: 0.008177
2022-01-16 01:56:19,247 iteration 5456 : loss : 0.016250, loss_ce: 0.004630
2022-01-16 01:56:20,573 iteration 5457 : loss : 0.017779, loss_ce: 0.007109
 80%|███████████████████████▎     | 321/400 [2:17:08<33:20, 25.33s/it]2022-01-16 01:56:22,007 iteration 5458 : loss : 0.020277, loss_ce: 0.005512
2022-01-16 01:56:23,243 iteration 5459 : loss : 0.017744, loss_ce: 0.006658
2022-01-16 01:56:24,494 iteration 5460 : loss : 0.018507, loss_ce: 0.006935
2022-01-16 01:56:25,755 iteration 5461 : loss : 0.022903, loss_ce: 0.009606
2022-01-16 01:56:27,053 iteration 5462 : loss : 0.014388, loss_ce: 0.005587
2022-01-16 01:56:28,245 iteration 5463 : loss : 0.012573, loss_ce: 0.003951
2022-01-16 01:56:29,557 iteration 5464 : loss : 0.026410, loss_ce: 0.008982
2022-01-16 01:56:30,699 iteration 5465 : loss : 0.017546, loss_ce: 0.006016
2022-01-16 01:56:31,818 iteration 5466 : loss : 0.019911, loss_ce: 0.007174
2022-01-16 01:56:33,000 iteration 5467 : loss : 0.016784, loss_ce: 0.006820
2022-01-16 01:56:34,169 iteration 5468 : loss : 0.014524, loss_ce: 0.006596
2022-01-16 01:56:35,328 iteration 5469 : loss : 0.030494, loss_ce: 0.010515
2022-01-16 01:56:36,425 iteration 5470 : loss : 0.013060, loss_ce: 0.005864
2022-01-16 01:56:37,541 iteration 5471 : loss : 0.012682, loss_ce: 0.005836
2022-01-16 01:56:38,752 iteration 5472 : loss : 0.017396, loss_ce: 0.007634
2022-01-16 01:56:39,930 iteration 5473 : loss : 0.015990, loss_ce: 0.004238
2022-01-16 01:56:41,251 iteration 5474 : loss : 0.015553, loss_ce: 0.004576
 80%|███████████████████████▎     | 322/400 [2:17:29<31:06, 23.93s/it]2022-01-16 01:56:42,545 iteration 5475 : loss : 0.016775, loss_ce: 0.006915
2022-01-16 01:56:43,833 iteration 5476 : loss : 0.018029, loss_ce: 0.008991
2022-01-16 01:56:45,204 iteration 5477 : loss : 0.012438, loss_ce: 0.004428
2022-01-16 01:56:46,610 iteration 5478 : loss : 0.018427, loss_ce: 0.007860
2022-01-16 01:56:47,954 iteration 5479 : loss : 0.019678, loss_ce: 0.005409
2022-01-16 01:56:49,338 iteration 5480 : loss : 0.018254, loss_ce: 0.004262
2022-01-16 01:56:50,745 iteration 5481 : loss : 0.018559, loss_ce: 0.007364
2022-01-16 01:56:52,156 iteration 5482 : loss : 0.022323, loss_ce: 0.008474
2022-01-16 01:56:53,476 iteration 5483 : loss : 0.016813, loss_ce: 0.005556
2022-01-16 01:56:54,861 iteration 5484 : loss : 0.022505, loss_ce: 0.009201
2022-01-16 01:56:56,103 iteration 5485 : loss : 0.013591, loss_ce: 0.006481
2022-01-16 01:56:57,487 iteration 5486 : loss : 0.031959, loss_ce: 0.009685
2022-01-16 01:56:58,686 iteration 5487 : loss : 0.013182, loss_ce: 0.006898
2022-01-16 01:56:59,940 iteration 5488 : loss : 0.017664, loss_ce: 0.005371
2022-01-16 01:57:01,129 iteration 5489 : loss : 0.020657, loss_ce: 0.004936
2022-01-16 01:57:02,402 iteration 5490 : loss : 0.019568, loss_ce: 0.007789
2022-01-16 01:57:03,618 iteration 5491 : loss : 0.017396, loss_ce: 0.005694
 81%|███████████████████████▍     | 323/400 [2:17:51<30:06, 23.46s/it]2022-01-16 01:57:04,947 iteration 5492 : loss : 0.028793, loss_ce: 0.014028
2022-01-16 01:57:06,141 iteration 5493 : loss : 0.014398, loss_ce: 0.004743
2022-01-16 01:57:07,410 iteration 5494 : loss : 0.018312, loss_ce: 0.008160
2022-01-16 01:57:08,762 iteration 5495 : loss : 0.022173, loss_ce: 0.004677
2022-01-16 01:57:10,040 iteration 5496 : loss : 0.014246, loss_ce: 0.004524
2022-01-16 01:57:11,468 iteration 5497 : loss : 0.016793, loss_ce: 0.007213
2022-01-16 01:57:12,980 iteration 5498 : loss : 0.014209, loss_ce: 0.005750
2022-01-16 01:57:14,478 iteration 5499 : loss : 0.017503, loss_ce: 0.004851
2022-01-16 01:57:16,166 iteration 5500 : loss : 0.013639, loss_ce: 0.004689
2022-01-16 01:57:17,709 iteration 5501 : loss : 0.013656, loss_ce: 0.004817
2022-01-16 01:57:19,257 iteration 5502 : loss : 0.015554, loss_ce: 0.007778
2022-01-16 01:57:20,955 iteration 5503 : loss : 0.023726, loss_ce: 0.007247
2022-01-16 01:57:22,686 iteration 5504 : loss : 0.017034, loss_ce: 0.007019
2022-01-16 01:57:24,155 iteration 5505 : loss : 0.014238, loss_ce: 0.005178
2022-01-16 01:57:25,794 iteration 5506 : loss : 0.014936, loss_ce: 0.005256
2022-01-16 01:57:27,543 iteration 5507 : loss : 0.022246, loss_ce: 0.008893
2022-01-16 01:57:29,155 iteration 5508 : loss : 0.019759, loss_ce: 0.008807
 81%|███████████████████████▍     | 324/400 [2:18:17<30:30, 24.09s/it]2022-01-16 01:57:30,880 iteration 5509 : loss : 0.018615, loss_ce: 0.007914
2022-01-16 01:57:32,544 iteration 5510 : loss : 0.013288, loss_ce: 0.005079
2022-01-16 01:57:34,138 iteration 5511 : loss : 0.018833, loss_ce: 0.006493
2022-01-16 01:57:35,658 iteration 5512 : loss : 0.016958, loss_ce: 0.007407
2022-01-16 01:57:37,156 iteration 5513 : loss : 0.016135, loss_ce: 0.009109
2022-01-16 01:57:38,674 iteration 5514 : loss : 0.020321, loss_ce: 0.008393
2022-01-16 01:57:40,155 iteration 5515 : loss : 0.016583, loss_ce: 0.007231
2022-01-16 01:57:41,608 iteration 5516 : loss : 0.013631, loss_ce: 0.006885
2022-01-16 01:57:43,060 iteration 5517 : loss : 0.018061, loss_ce: 0.005481
2022-01-16 01:57:44,385 iteration 5518 : loss : 0.012924, loss_ce: 0.004086
2022-01-16 01:57:45,874 iteration 5519 : loss : 0.030648, loss_ce: 0.008838
2022-01-16 01:57:47,253 iteration 5520 : loss : 0.013843, loss_ce: 0.002372
2022-01-16 01:57:48,703 iteration 5521 : loss : 0.014987, loss_ce: 0.004990
2022-01-16 01:57:50,044 iteration 5522 : loss : 0.013012, loss_ce: 0.004282
2022-01-16 01:57:51,425 iteration 5523 : loss : 0.019555, loss_ce: 0.007437
2022-01-16 01:57:52,900 iteration 5524 : loss : 0.027030, loss_ce: 0.009151
2022-01-16 01:57:52,900 Training Data Eval:
2022-01-16 01:58:00,119   Average segmentation loss on training set: 0.0099
2022-01-16 01:58:00,119 Validation Data Eval:
2022-01-16 01:58:02,777   Average segmentation loss on validation set: 0.0695
2022-01-16 01:58:04,381 iteration 5525 : loss : 0.016094, loss_ce: 0.006650
 81%|███████████████████████▌     | 325/400 [2:18:52<34:17, 27.43s/it]2022-01-16 01:58:05,964 iteration 5526 : loss : 0.018279, loss_ce: 0.006183
2022-01-16 01:58:07,428 iteration 5527 : loss : 0.013612, loss_ce: 0.005472
2022-01-16 01:58:09,005 iteration 5528 : loss : 0.026613, loss_ce: 0.009533
2022-01-16 01:58:10,482 iteration 5529 : loss : 0.014619, loss_ce: 0.005558
2022-01-16 01:58:11,930 iteration 5530 : loss : 0.013605, loss_ce: 0.005585
2022-01-16 01:58:13,354 iteration 5531 : loss : 0.012182, loss_ce: 0.003562
2022-01-16 01:58:14,822 iteration 5532 : loss : 0.015174, loss_ce: 0.005623
2022-01-16 01:58:16,346 iteration 5533 : loss : 0.016659, loss_ce: 0.007503
2022-01-16 01:58:17,847 iteration 5534 : loss : 0.013017, loss_ce: 0.004664
2022-01-16 01:58:19,385 iteration 5535 : loss : 0.016361, loss_ce: 0.006570
2022-01-16 01:58:20,987 iteration 5536 : loss : 0.016269, loss_ce: 0.005810
2022-01-16 01:58:22,537 iteration 5537 : loss : 0.019528, loss_ce: 0.008764
2022-01-16 01:58:24,089 iteration 5538 : loss : 0.021362, loss_ce: 0.005389
2022-01-16 01:58:25,593 iteration 5539 : loss : 0.014173, loss_ce: 0.005134
2022-01-16 01:58:27,038 iteration 5540 : loss : 0.018137, loss_ce: 0.007345
2022-01-16 01:58:28,658 iteration 5541 : loss : 0.021535, loss_ce: 0.009722
2022-01-16 01:58:30,160 iteration 5542 : loss : 0.018146, loss_ce: 0.007788
 82%|███████████████████████▋     | 326/400 [2:19:18<33:13, 26.93s/it]2022-01-16 01:58:31,728 iteration 5543 : loss : 0.018083, loss_ce: 0.008003
2022-01-16 01:58:33,169 iteration 5544 : loss : 0.012779, loss_ce: 0.004748
2022-01-16 01:58:34,701 iteration 5545 : loss : 0.018357, loss_ce: 0.007734
2022-01-16 01:58:36,243 iteration 5546 : loss : 0.029162, loss_ce: 0.006969
2022-01-16 01:58:37,751 iteration 5547 : loss : 0.016981, loss_ce: 0.007507
2022-01-16 01:58:39,145 iteration 5548 : loss : 0.012904, loss_ce: 0.003372
2022-01-16 01:58:40,512 iteration 5549 : loss : 0.014989, loss_ce: 0.004072
2022-01-16 01:58:41,906 iteration 5550 : loss : 0.015364, loss_ce: 0.005108
2022-01-16 01:58:43,246 iteration 5551 : loss : 0.019341, loss_ce: 0.009889
2022-01-16 01:58:44,474 iteration 5552 : loss : 0.013025, loss_ce: 0.004054
2022-01-16 01:58:45,810 iteration 5553 : loss : 0.016235, loss_ce: 0.006553
2022-01-16 01:58:47,121 iteration 5554 : loss : 0.014475, loss_ce: 0.006333
2022-01-16 01:58:48,383 iteration 5555 : loss : 0.014607, loss_ce: 0.006288
2022-01-16 01:58:49,739 iteration 5556 : loss : 0.023352, loss_ce: 0.009101
2022-01-16 01:58:51,049 iteration 5557 : loss : 0.014262, loss_ce: 0.005980
2022-01-16 01:58:52,318 iteration 5558 : loss : 0.022391, loss_ce: 0.010091
2022-01-16 01:58:53,595 iteration 5559 : loss : 0.019194, loss_ce: 0.005221
 82%|███████████████████████▋     | 327/400 [2:19:41<31:29, 25.89s/it]2022-01-16 01:58:54,914 iteration 5560 : loss : 0.017633, loss_ce: 0.006765
2022-01-16 01:58:56,116 iteration 5561 : loss : 0.017305, loss_ce: 0.005808
2022-01-16 01:58:57,325 iteration 5562 : loss : 0.013698, loss_ce: 0.005901
2022-01-16 01:58:58,531 iteration 5563 : loss : 0.018903, loss_ce: 0.008390
2022-01-16 01:58:59,798 iteration 5564 : loss : 0.017897, loss_ce: 0.007630
2022-01-16 01:59:01,029 iteration 5565 : loss : 0.018812, loss_ce: 0.008756
2022-01-16 01:59:02,238 iteration 5566 : loss : 0.017530, loss_ce: 0.006824
2022-01-16 01:59:03,434 iteration 5567 : loss : 0.017027, loss_ce: 0.008555
2022-01-16 01:59:04,573 iteration 5568 : loss : 0.023419, loss_ce: 0.009353
2022-01-16 01:59:05,757 iteration 5569 : loss : 0.018648, loss_ce: 0.007145
2022-01-16 01:59:06,943 iteration 5570 : loss : 0.013372, loss_ce: 0.004181
2022-01-16 01:59:08,127 iteration 5571 : loss : 0.011200, loss_ce: 0.004299
2022-01-16 01:59:09,426 iteration 5572 : loss : 0.020603, loss_ce: 0.006301
2022-01-16 01:59:10,742 iteration 5573 : loss : 0.010614, loss_ce: 0.003193
2022-01-16 01:59:12,156 iteration 5574 : loss : 0.013225, loss_ce: 0.004132
2022-01-16 01:59:13,661 iteration 5575 : loss : 0.018117, loss_ce: 0.005442
2022-01-16 01:59:15,101 iteration 5576 : loss : 0.022326, loss_ce: 0.008106
 82%|███████████████████████▊     | 328/400 [2:20:03<29:28, 24.57s/it]2022-01-16 01:59:16,617 iteration 5577 : loss : 0.017185, loss_ce: 0.007954
2022-01-16 01:59:18,113 iteration 5578 : loss : 0.020507, loss_ce: 0.007639
2022-01-16 01:59:19,676 iteration 5579 : loss : 0.022984, loss_ce: 0.010304
2022-01-16 01:59:21,162 iteration 5580 : loss : 0.021955, loss_ce: 0.007791
2022-01-16 01:59:22,649 iteration 5581 : loss : 0.012181, loss_ce: 0.005039
2022-01-16 01:59:24,207 iteration 5582 : loss : 0.012989, loss_ce: 0.003626
2022-01-16 01:59:25,781 iteration 5583 : loss : 0.010286, loss_ce: 0.003751
2022-01-16 01:59:27,433 iteration 5584 : loss : 0.021173, loss_ce: 0.008443
2022-01-16 01:59:29,125 iteration 5585 : loss : 0.014884, loss_ce: 0.004313
2022-01-16 01:59:30,717 iteration 5586 : loss : 0.024096, loss_ce: 0.007010
2022-01-16 01:59:32,173 iteration 5587 : loss : 0.031192, loss_ce: 0.010700
2022-01-16 01:59:33,651 iteration 5588 : loss : 0.015829, loss_ce: 0.005839
2022-01-16 01:59:35,097 iteration 5589 : loss : 0.012089, loss_ce: 0.003608
2022-01-16 01:59:36,590 iteration 5590 : loss : 0.012632, loss_ce: 0.003196
2022-01-16 01:59:38,129 iteration 5591 : loss : 0.014302, loss_ce: 0.006240
2022-01-16 01:59:39,858 iteration 5592 : loss : 0.027488, loss_ce: 0.009271
2022-01-16 01:59:41,457 iteration 5593 : loss : 0.022895, loss_ce: 0.008817
 82%|███████████████████████▊     | 329/400 [2:20:29<29:42, 25.11s/it]2022-01-16 01:59:43,139 iteration 5594 : loss : 0.015540, loss_ce: 0.004612
2022-01-16 01:59:44,745 iteration 5595 : loss : 0.021035, loss_ce: 0.010098
2022-01-16 01:59:46,297 iteration 5596 : loss : 0.017222, loss_ce: 0.006338
2022-01-16 01:59:47,932 iteration 5597 : loss : 0.013671, loss_ce: 0.004975
2022-01-16 01:59:49,446 iteration 5598 : loss : 0.011229, loss_ce: 0.004691
2022-01-16 01:59:51,015 iteration 5599 : loss : 0.017058, loss_ce: 0.006690
2022-01-16 01:59:52,595 iteration 5600 : loss : 0.012642, loss_ce: 0.005233
2022-01-16 01:59:54,160 iteration 5601 : loss : 0.011916, loss_ce: 0.004606
2022-01-16 01:59:55,838 iteration 5602 : loss : 0.020012, loss_ce: 0.008854
2022-01-16 01:59:57,366 iteration 5603 : loss : 0.012191, loss_ce: 0.005060
2022-01-16 01:59:58,940 iteration 5604 : loss : 0.024217, loss_ce: 0.006456
2022-01-16 02:00:00,552 iteration 5605 : loss : 0.015988, loss_ce: 0.006237
2022-01-16 02:00:02,139 iteration 5606 : loss : 0.015929, loss_ce: 0.005130
2022-01-16 02:00:03,840 iteration 5607 : loss : 0.020003, loss_ce: 0.005727
2022-01-16 02:00:05,351 iteration 5608 : loss : 0.014470, loss_ce: 0.004806
2022-01-16 02:00:06,878 iteration 5609 : loss : 0.013323, loss_ce: 0.006169
2022-01-16 02:00:06,878 Training Data Eval:
2022-01-16 02:00:14,477   Average segmentation loss on training set: 0.0096
2022-01-16 02:00:14,477 Validation Data Eval:
2022-01-16 02:00:17,092   Average segmentation loss on validation set: 0.0799
2022-01-16 02:00:18,559 iteration 5610 : loss : 0.014119, loss_ce: 0.004871
 82%|███████████████████████▉     | 330/400 [2:21:06<33:29, 28.70s/it]2022-01-16 02:00:20,108 iteration 5611 : loss : 0.024599, loss_ce: 0.007726
2022-01-16 02:00:21,703 iteration 5612 : loss : 0.039139, loss_ce: 0.009336
2022-01-16 02:00:23,233 iteration 5613 : loss : 0.021267, loss_ce: 0.008383
2022-01-16 02:00:24,737 iteration 5614 : loss : 0.016929, loss_ce: 0.005919
2022-01-16 02:00:26,352 iteration 5615 : loss : 0.010764, loss_ce: 0.004582
2022-01-16 02:00:27,949 iteration 5616 : loss : 0.017407, loss_ce: 0.007721
2022-01-16 02:00:29,516 iteration 5617 : loss : 0.016368, loss_ce: 0.005868
2022-01-16 02:00:31,140 iteration 5618 : loss : 0.016159, loss_ce: 0.006848
2022-01-16 02:00:32,691 iteration 5619 : loss : 0.016938, loss_ce: 0.005462
2022-01-16 02:00:34,415 iteration 5620 : loss : 0.017113, loss_ce: 0.006594
2022-01-16 02:00:35,923 iteration 5621 : loss : 0.015080, loss_ce: 0.005746
2022-01-16 02:00:37,600 iteration 5622 : loss : 0.014447, loss_ce: 0.004705
2022-01-16 02:00:39,211 iteration 5623 : loss : 0.021331, loss_ce: 0.008030
2022-01-16 02:00:40,668 iteration 5624 : loss : 0.016775, loss_ce: 0.004895
2022-01-16 02:00:42,192 iteration 5625 : loss : 0.016707, loss_ce: 0.008045
2022-01-16 02:00:43,729 iteration 5626 : loss : 0.017434, loss_ce: 0.005140
2022-01-16 02:00:45,263 iteration 5627 : loss : 0.015986, loss_ce: 0.006325
 83%|███████████████████████▉     | 331/400 [2:21:33<32:19, 28.10s/it]2022-01-16 02:00:46,989 iteration 5628 : loss : 0.020070, loss_ce: 0.009259
2022-01-16 02:00:48,669 iteration 5629 : loss : 0.014094, loss_ce: 0.005790
2022-01-16 02:00:50,269 iteration 5630 : loss : 0.020869, loss_ce: 0.009671
2022-01-16 02:00:51,845 iteration 5631 : loss : 0.017037, loss_ce: 0.006486
2022-01-16 02:00:53,442 iteration 5632 : loss : 0.015158, loss_ce: 0.006274
2022-01-16 02:00:55,093 iteration 5633 : loss : 0.027688, loss_ce: 0.007949
2022-01-16 02:00:56,845 iteration 5634 : loss : 0.012400, loss_ce: 0.005410
2022-01-16 02:00:58,408 iteration 5635 : loss : 0.016615, loss_ce: 0.006142
2022-01-16 02:01:00,023 iteration 5636 : loss : 0.020273, loss_ce: 0.005291
2022-01-16 02:01:01,605 iteration 5637 : loss : 0.020404, loss_ce: 0.006412
2022-01-16 02:01:03,217 iteration 5638 : loss : 0.016787, loss_ce: 0.006832
2022-01-16 02:01:04,869 iteration 5639 : loss : 0.012694, loss_ce: 0.004093
2022-01-16 02:01:06,467 iteration 5640 : loss : 0.012740, loss_ce: 0.005101
2022-01-16 02:01:07,988 iteration 5641 : loss : 0.019928, loss_ce: 0.004923
2022-01-16 02:01:09,515 iteration 5642 : loss : 0.014856, loss_ce: 0.005162
2022-01-16 02:01:11,060 iteration 5643 : loss : 0.014917, loss_ce: 0.004651
2022-01-16 02:01:12,602 iteration 5644 : loss : 0.013042, loss_ce: 0.005089
 83%|████████████████████████     | 332/400 [2:22:00<31:35, 27.88s/it]2022-01-16 02:01:14,178 iteration 5645 : loss : 0.019022, loss_ce: 0.007071
2022-01-16 02:01:15,876 iteration 5646 : loss : 0.017130, loss_ce: 0.004583
2022-01-16 02:01:17,469 iteration 5647 : loss : 0.020099, loss_ce: 0.005865
2022-01-16 02:01:19,094 iteration 5648 : loss : 0.022556, loss_ce: 0.006472
2022-01-16 02:01:20,674 iteration 5649 : loss : 0.013176, loss_ce: 0.004731
2022-01-16 02:01:22,457 iteration 5650 : loss : 0.030954, loss_ce: 0.008585
2022-01-16 02:01:23,993 iteration 5651 : loss : 0.016710, loss_ce: 0.007958
2022-01-16 02:01:25,654 iteration 5652 : loss : 0.014244, loss_ce: 0.006225
2022-01-16 02:01:27,187 iteration 5653 : loss : 0.016445, loss_ce: 0.005874
2022-01-16 02:01:29,000 iteration 5654 : loss : 0.015808, loss_ce: 0.006115
2022-01-16 02:01:30,563 iteration 5655 : loss : 0.021632, loss_ce: 0.008552
2022-01-16 02:01:32,175 iteration 5656 : loss : 0.017288, loss_ce: 0.007495
2022-01-16 02:01:33,763 iteration 5657 : loss : 0.020010, loss_ce: 0.010221
2022-01-16 02:01:35,408 iteration 5658 : loss : 0.032306, loss_ce: 0.008733
2022-01-16 02:01:37,073 iteration 5659 : loss : 0.024605, loss_ce: 0.014714
2022-01-16 02:01:38,555 iteration 5660 : loss : 0.011003, loss_ce: 0.004274
2022-01-16 02:01:40,163 iteration 5661 : loss : 0.037968, loss_ce: 0.012909
 83%|████████████████████████▏    | 333/400 [2:22:28<31:01, 27.78s/it]2022-01-16 02:01:41,769 iteration 5662 : loss : 0.014840, loss_ce: 0.006154
2022-01-16 02:01:43,390 iteration 5663 : loss : 0.014061, loss_ce: 0.006565
2022-01-16 02:01:45,007 iteration 5664 : loss : 0.023618, loss_ce: 0.008487
2022-01-16 02:01:46,533 iteration 5665 : loss : 0.014363, loss_ce: 0.003336
2022-01-16 02:01:48,315 iteration 5666 : loss : 0.017378, loss_ce: 0.006349
2022-01-16 02:01:49,871 iteration 5667 : loss : 0.016692, loss_ce: 0.004991
2022-01-16 02:01:51,404 iteration 5668 : loss : 0.020835, loss_ce: 0.006441
2022-01-16 02:01:52,952 iteration 5669 : loss : 0.020318, loss_ce: 0.009157
2022-01-16 02:01:54,450 iteration 5670 : loss : 0.017090, loss_ce: 0.005504
2022-01-16 02:01:56,102 iteration 5671 : loss : 0.034110, loss_ce: 0.007778
2022-01-16 02:01:57,559 iteration 5672 : loss : 0.014970, loss_ce: 0.004013
2022-01-16 02:01:59,054 iteration 5673 : loss : 0.016454, loss_ce: 0.007700
2022-01-16 02:02:00,487 iteration 5674 : loss : 0.017327, loss_ce: 0.006160
2022-01-16 02:02:02,082 iteration 5675 : loss : 0.023604, loss_ce: 0.008441
2022-01-16 02:02:03,549 iteration 5676 : loss : 0.019255, loss_ce: 0.009809
2022-01-16 02:02:05,056 iteration 5677 : loss : 0.015772, loss_ce: 0.005631
2022-01-16 02:02:06,573 iteration 5678 : loss : 0.016542, loss_ce: 0.006326
 84%|████████████████████████▏    | 334/400 [2:22:54<30:06, 27.37s/it]2022-01-16 02:02:08,146 iteration 5679 : loss : 0.017941, loss_ce: 0.006686
2022-01-16 02:02:09,633 iteration 5680 : loss : 0.014067, loss_ce: 0.006045
2022-01-16 02:02:11,318 iteration 5681 : loss : 0.020643, loss_ce: 0.005413
2022-01-16 02:02:12,812 iteration 5682 : loss : 0.014444, loss_ce: 0.004632
2022-01-16 02:02:14,319 iteration 5683 : loss : 0.011525, loss_ce: 0.005004
2022-01-16 02:02:15,918 iteration 5684 : loss : 0.016417, loss_ce: 0.008858
2022-01-16 02:02:17,509 iteration 5685 : loss : 0.018118, loss_ce: 0.005756
2022-01-16 02:02:19,076 iteration 5686 : loss : 0.021630, loss_ce: 0.009353
2022-01-16 02:02:20,616 iteration 5687 : loss : 0.014422, loss_ce: 0.004387
2022-01-16 02:02:22,198 iteration 5688 : loss : 0.021538, loss_ce: 0.008287
2022-01-16 02:02:23,758 iteration 5689 : loss : 0.015309, loss_ce: 0.006591
2022-01-16 02:02:25,270 iteration 5690 : loss : 0.012792, loss_ce: 0.004253
2022-01-16 02:02:26,800 iteration 5691 : loss : 0.013743, loss_ce: 0.006005
2022-01-16 02:02:28,281 iteration 5692 : loss : 0.011385, loss_ce: 0.003432
2022-01-16 02:02:29,709 iteration 5693 : loss : 0.012386, loss_ce: 0.005168
2022-01-16 02:02:31,252 iteration 5694 : loss : 0.018150, loss_ce: 0.007808
2022-01-16 02:02:31,252 Training Data Eval:
2022-01-16 02:02:38,740   Average segmentation loss on training set: 0.0094
2022-01-16 02:02:38,740 Validation Data Eval:
2022-01-16 02:02:41,306   Average segmentation loss on validation set: 0.0681
2022-01-16 02:02:42,749 iteration 5695 : loss : 0.016357, loss_ce: 0.006853
 84%|████████████████████████▎    | 335/400 [2:23:31<32:30, 30.01s/it]2022-01-16 02:02:44,217 iteration 5696 : loss : 0.018662, loss_ce: 0.006010
2022-01-16 02:02:45,500 iteration 5697 : loss : 0.013034, loss_ce: 0.004002
2022-01-16 02:02:46,830 iteration 5698 : loss : 0.020774, loss_ce: 0.007155
2022-01-16 02:02:48,118 iteration 5699 : loss : 0.014683, loss_ce: 0.003626
2022-01-16 02:02:49,238 iteration 5700 : loss : 0.012820, loss_ce: 0.005470
2022-01-16 02:02:50,532 iteration 5701 : loss : 0.022932, loss_ce: 0.004136
2022-01-16 02:02:51,732 iteration 5702 : loss : 0.015578, loss_ce: 0.005969
2022-01-16 02:02:53,005 iteration 5703 : loss : 0.019014, loss_ce: 0.008183
2022-01-16 02:02:54,230 iteration 5704 : loss : 0.016481, loss_ce: 0.008519
2022-01-16 02:02:55,489 iteration 5705 : loss : 0.013623, loss_ce: 0.005486
2022-01-16 02:02:56,772 iteration 5706 : loss : 0.012521, loss_ce: 0.004595
2022-01-16 02:02:58,160 iteration 5707 : loss : 0.021579, loss_ce: 0.005676
2022-01-16 02:02:59,499 iteration 5708 : loss : 0.018804, loss_ce: 0.008774
2022-01-16 02:03:00,788 iteration 5709 : loss : 0.017378, loss_ce: 0.006785
2022-01-16 02:03:02,062 iteration 5710 : loss : 0.015519, loss_ce: 0.007084
2022-01-16 02:03:03,371 iteration 5711 : loss : 0.014264, loss_ce: 0.006300
2022-01-16 02:03:04,663 iteration 5712 : loss : 0.017966, loss_ce: 0.007986
 84%|████████████████████████▎    | 336/400 [2:23:52<29:25, 27.58s/it]2022-01-16 02:03:06,038 iteration 5713 : loss : 0.011755, loss_ce: 0.005071
2022-01-16 02:03:07,371 iteration 5714 : loss : 0.019000, loss_ce: 0.006691
2022-01-16 02:03:08,694 iteration 5715 : loss : 0.013630, loss_ce: 0.005222
2022-01-16 02:03:10,188 iteration 5716 : loss : 0.030621, loss_ce: 0.011665
2022-01-16 02:03:11,771 iteration 5717 : loss : 0.010422, loss_ce: 0.003630
2022-01-16 02:03:13,253 iteration 5718 : loss : 0.015998, loss_ce: 0.007163
2022-01-16 02:03:14,775 iteration 5719 : loss : 0.023265, loss_ce: 0.007426
2022-01-16 02:03:16,288 iteration 5720 : loss : 0.025198, loss_ce: 0.012839
2022-01-16 02:03:17,667 iteration 5721 : loss : 0.014115, loss_ce: 0.004052
2022-01-16 02:03:19,118 iteration 5722 : loss : 0.017678, loss_ce: 0.006249
2022-01-16 02:03:20,612 iteration 5723 : loss : 0.020658, loss_ce: 0.007305
2022-01-16 02:03:22,085 iteration 5724 : loss : 0.017116, loss_ce: 0.008603
2022-01-16 02:03:23,656 iteration 5725 : loss : 0.016025, loss_ce: 0.006487
2022-01-16 02:03:25,231 iteration 5726 : loss : 0.015047, loss_ce: 0.006552
2022-01-16 02:03:26,825 iteration 5727 : loss : 0.018719, loss_ce: 0.010283
2022-01-16 02:03:28,300 iteration 5728 : loss : 0.013141, loss_ce: 0.004194
2022-01-16 02:03:29,757 iteration 5729 : loss : 0.013620, loss_ce: 0.004105
 84%|████████████████████████▍    | 337/400 [2:24:18<28:10, 26.84s/it]2022-01-16 02:03:31,399 iteration 5730 : loss : 0.023961, loss_ce: 0.007435
2022-01-16 02:03:33,018 iteration 5731 : loss : 0.022067, loss_ce: 0.009087
2022-01-16 02:03:34,571 iteration 5732 : loss : 0.019696, loss_ce: 0.004491
2022-01-16 02:03:36,145 iteration 5733 : loss : 0.018174, loss_ce: 0.007582
2022-01-16 02:03:37,716 iteration 5734 : loss : 0.011645, loss_ce: 0.004331
2022-01-16 02:03:39,327 iteration 5735 : loss : 0.022121, loss_ce: 0.007727
2022-01-16 02:03:40,980 iteration 5736 : loss : 0.020694, loss_ce: 0.009721
2022-01-16 02:03:42,562 iteration 5737 : loss : 0.016706, loss_ce: 0.006295
2022-01-16 02:03:44,116 iteration 5738 : loss : 0.014757, loss_ce: 0.006885
2022-01-16 02:03:45,842 iteration 5739 : loss : 0.013597, loss_ce: 0.004053
2022-01-16 02:03:47,438 iteration 5740 : loss : 0.016710, loss_ce: 0.006966
2022-01-16 02:03:48,913 iteration 5741 : loss : 0.012026, loss_ce: 0.004882
2022-01-16 02:03:50,297 iteration 5742 : loss : 0.021236, loss_ce: 0.004195
2022-01-16 02:03:51,691 iteration 5743 : loss : 0.018269, loss_ce: 0.006190
2022-01-16 02:03:53,042 iteration 5744 : loss : 0.014189, loss_ce: 0.006322
2022-01-16 02:03:54,430 iteration 5745 : loss : 0.016115, loss_ce: 0.006107
2022-01-16 02:03:55,762 iteration 5746 : loss : 0.019855, loss_ce: 0.009792
 84%|████████████████████████▌    | 338/400 [2:24:44<27:28, 26.59s/it]2022-01-16 02:03:57,197 iteration 5747 : loss : 0.028145, loss_ce: 0.010082
2022-01-16 02:03:58,518 iteration 5748 : loss : 0.014367, loss_ce: 0.005551
2022-01-16 02:03:59,910 iteration 5749 : loss : 0.021488, loss_ce: 0.010014
2022-01-16 02:04:01,272 iteration 5750 : loss : 0.016382, loss_ce: 0.004306
2022-01-16 02:04:02,640 iteration 5751 : loss : 0.019794, loss_ce: 0.007971
2022-01-16 02:04:03,920 iteration 5752 : loss : 0.016803, loss_ce: 0.006414
2022-01-16 02:04:05,221 iteration 5753 : loss : 0.020513, loss_ce: 0.011147
2022-01-16 02:04:06,475 iteration 5754 : loss : 0.017237, loss_ce: 0.005905
2022-01-16 02:04:07,704 iteration 5755 : loss : 0.015091, loss_ce: 0.004736
2022-01-16 02:04:08,937 iteration 5756 : loss : 0.017670, loss_ce: 0.008731
2022-01-16 02:04:10,211 iteration 5757 : loss : 0.022889, loss_ce: 0.007158
2022-01-16 02:04:11,405 iteration 5758 : loss : 0.009483, loss_ce: 0.002869
2022-01-16 02:04:12,710 iteration 5759 : loss : 0.020566, loss_ce: 0.005680
2022-01-16 02:04:13,940 iteration 5760 : loss : 0.014501, loss_ce: 0.005482
2022-01-16 02:04:15,213 iteration 5761 : loss : 0.014305, loss_ce: 0.004588
2022-01-16 02:04:16,503 iteration 5762 : loss : 0.019979, loss_ce: 0.009105
2022-01-16 02:04:17,720 iteration 5763 : loss : 0.017056, loss_ce: 0.007323
 85%|████████████████████████▌    | 339/400 [2:25:06<25:36, 25.20s/it]2022-01-16 02:04:18,992 iteration 5764 : loss : 0.016336, loss_ce: 0.007125
2022-01-16 02:04:20,153 iteration 5765 : loss : 0.027469, loss_ce: 0.008325
2022-01-16 02:04:21,297 iteration 5766 : loss : 0.016236, loss_ce: 0.005673
2022-01-16 02:04:22,563 iteration 5767 : loss : 0.017097, loss_ce: 0.007043
2022-01-16 02:04:23,872 iteration 5768 : loss : 0.034606, loss_ce: 0.009898
2022-01-16 02:04:25,197 iteration 5769 : loss : 0.021606, loss_ce: 0.006004
2022-01-16 02:04:26,550 iteration 5770 : loss : 0.020568, loss_ce: 0.008546
2022-01-16 02:04:27,849 iteration 5771 : loss : 0.010902, loss_ce: 0.004771
2022-01-16 02:04:29,256 iteration 5772 : loss : 0.015620, loss_ce: 0.005773
2022-01-16 02:04:30,609 iteration 5773 : loss : 0.013605, loss_ce: 0.004772
2022-01-16 02:04:32,015 iteration 5774 : loss : 0.011748, loss_ce: 0.004602
2022-01-16 02:04:33,513 iteration 5775 : loss : 0.028855, loss_ce: 0.009616
2022-01-16 02:04:34,847 iteration 5776 : loss : 0.014935, loss_ce: 0.005938
2022-01-16 02:04:36,231 iteration 5777 : loss : 0.012308, loss_ce: 0.004123
2022-01-16 02:04:37,641 iteration 5778 : loss : 0.012769, loss_ce: 0.004235
2022-01-16 02:04:38,989 iteration 5779 : loss : 0.011861, loss_ce: 0.004705
2022-01-16 02:04:38,989 Training Data Eval:
2022-01-16 02:04:45,483   Average segmentation loss on training set: 0.0092
2022-01-16 02:04:45,484 Validation Data Eval:
2022-01-16 02:04:47,671   Average segmentation loss on validation set: 0.0683
2022-01-16 02:04:48,915 iteration 5780 : loss : 0.019174, loss_ce: 0.007098
 85%|████████████████████████▋    | 340/400 [2:25:37<26:59, 27.00s/it]2022-01-16 02:04:50,208 iteration 5781 : loss : 0.017523, loss_ce: 0.006246
2022-01-16 02:04:51,372 iteration 5782 : loss : 0.009972, loss_ce: 0.003526
2022-01-16 02:04:52,606 iteration 5783 : loss : 0.012967, loss_ce: 0.004084
2022-01-16 02:04:53,832 iteration 5784 : loss : 0.015108, loss_ce: 0.004145
2022-01-16 02:04:55,023 iteration 5785 : loss : 0.014291, loss_ce: 0.006674
2022-01-16 02:04:56,270 iteration 5786 : loss : 0.020717, loss_ce: 0.007716
2022-01-16 02:04:57,417 iteration 5787 : loss : 0.019920, loss_ce: 0.005910
2022-01-16 02:04:58,621 iteration 5788 : loss : 0.014937, loss_ce: 0.005684
2022-01-16 02:04:59,803 iteration 5789 : loss : 0.016048, loss_ce: 0.004760
2022-01-16 02:05:01,021 iteration 5790 : loss : 0.017610, loss_ce: 0.007780
2022-01-16 02:05:02,224 iteration 5791 : loss : 0.013020, loss_ce: 0.005153
2022-01-16 02:05:03,423 iteration 5792 : loss : 0.018116, loss_ce: 0.005472
2022-01-16 02:05:04,485 iteration 5793 : loss : 0.014156, loss_ce: 0.005300
2022-01-16 02:05:05,529 iteration 5794 : loss : 0.015909, loss_ce: 0.005051
2022-01-16 02:05:06,575 iteration 5795 : loss : 0.017474, loss_ce: 0.008136
2022-01-16 02:05:07,615 iteration 5796 : loss : 0.020769, loss_ce: 0.009035
2022-01-16 02:05:08,630 iteration 5797 : loss : 0.014914, loss_ce: 0.004903
 85%|████████████████████████▋    | 341/400 [2:25:56<24:23, 24.81s/it]2022-01-16 02:05:09,674 iteration 5798 : loss : 0.013502, loss_ce: 0.004068
2022-01-16 02:05:10,695 iteration 5799 : loss : 0.014416, loss_ce: 0.005362
2022-01-16 02:05:11,684 iteration 5800 : loss : 0.009973, loss_ce: 0.003984
2022-01-16 02:05:12,801 iteration 5801 : loss : 0.014307, loss_ce: 0.006304
2022-01-16 02:05:13,894 iteration 5802 : loss : 0.015376, loss_ce: 0.007044
2022-01-16 02:05:15,099 iteration 5803 : loss : 0.014458, loss_ce: 0.004818
2022-01-16 02:05:16,261 iteration 5804 : loss : 0.019708, loss_ce: 0.006114
2022-01-16 02:05:17,501 iteration 5805 : loss : 0.014618, loss_ce: 0.005256
2022-01-16 02:05:18,816 iteration 5806 : loss : 0.011200, loss_ce: 0.004868
2022-01-16 02:05:20,248 iteration 5807 : loss : 0.022781, loss_ce: 0.008215
2022-01-16 02:05:21,696 iteration 5808 : loss : 0.018451, loss_ce: 0.005971
2022-01-16 02:05:23,129 iteration 5809 : loss : 0.020003, loss_ce: 0.008012
2022-01-16 02:05:24,658 iteration 5810 : loss : 0.018504, loss_ce: 0.005028
2022-01-16 02:05:26,125 iteration 5811 : loss : 0.024877, loss_ce: 0.009459
2022-01-16 02:05:27,497 iteration 5812 : loss : 0.022256, loss_ce: 0.010048
2022-01-16 02:05:28,869 iteration 5813 : loss : 0.013800, loss_ce: 0.004564
2022-01-16 02:05:30,281 iteration 5814 : loss : 0.018083, loss_ce: 0.006084
 86%|████████████████████████▊    | 342/400 [2:26:18<23:04, 23.87s/it]2022-01-16 02:05:31,840 iteration 5815 : loss : 0.019449, loss_ce: 0.006604
2022-01-16 02:05:33,285 iteration 5816 : loss : 0.014944, loss_ce: 0.005183
2022-01-16 02:05:34,792 iteration 5817 : loss : 0.018123, loss_ce: 0.008905
2022-01-16 02:05:36,316 iteration 5818 : loss : 0.019658, loss_ce: 0.007295
2022-01-16 02:05:37,883 iteration 5819 : loss : 0.014732, loss_ce: 0.003918
2022-01-16 02:05:39,415 iteration 5820 : loss : 0.018079, loss_ce: 0.006152
2022-01-16 02:05:41,017 iteration 5821 : loss : 0.014259, loss_ce: 0.005515
2022-01-16 02:05:42,736 iteration 5822 : loss : 0.017072, loss_ce: 0.005129
2022-01-16 02:05:44,263 iteration 5823 : loss : 0.012781, loss_ce: 0.006236
2022-01-16 02:05:45,901 iteration 5824 : loss : 0.022834, loss_ce: 0.005536
2022-01-16 02:05:47,445 iteration 5825 : loss : 0.010988, loss_ce: 0.003877
2022-01-16 02:05:48,952 iteration 5826 : loss : 0.015330, loss_ce: 0.006985
2022-01-16 02:05:50,463 iteration 5827 : loss : 0.016473, loss_ce: 0.006763
2022-01-16 02:05:52,050 iteration 5828 : loss : 0.022589, loss_ce: 0.006050
2022-01-16 02:05:53,631 iteration 5829 : loss : 0.013289, loss_ce: 0.005260
2022-01-16 02:05:55,112 iteration 5830 : loss : 0.014836, loss_ce: 0.004935
2022-01-16 02:05:56,684 iteration 5831 : loss : 0.020317, loss_ce: 0.008453
 86%|████████████████████████▊    | 343/400 [2:26:45<23:23, 24.63s/it]2022-01-16 02:05:58,264 iteration 5832 : loss : 0.028128, loss_ce: 0.011776
2022-01-16 02:05:59,845 iteration 5833 : loss : 0.017826, loss_ce: 0.005687
2022-01-16 02:06:01,431 iteration 5834 : loss : 0.016295, loss_ce: 0.007924
2022-01-16 02:06:03,085 iteration 5835 : loss : 0.021865, loss_ce: 0.010950
2022-01-16 02:06:04,635 iteration 5836 : loss : 0.016838, loss_ce: 0.005432
2022-01-16 02:06:06,216 iteration 5837 : loss : 0.029485, loss_ce: 0.011648
2022-01-16 02:06:07,809 iteration 5838 : loss : 0.023398, loss_ce: 0.006852
2022-01-16 02:06:09,376 iteration 5839 : loss : 0.035175, loss_ce: 0.017320
2022-01-16 02:06:10,882 iteration 5840 : loss : 0.013898, loss_ce: 0.004773
2022-01-16 02:06:12,474 iteration 5841 : loss : 0.021528, loss_ce: 0.007141
2022-01-16 02:06:14,102 iteration 5842 : loss : 0.015426, loss_ce: 0.005046
2022-01-16 02:06:15,622 iteration 5843 : loss : 0.013891, loss_ce: 0.004843
2022-01-16 02:06:17,206 iteration 5844 : loss : 0.022967, loss_ce: 0.008971
2022-01-16 02:06:18,720 iteration 5845 : loss : 0.016706, loss_ce: 0.006400
2022-01-16 02:06:20,272 iteration 5846 : loss : 0.011032, loss_ce: 0.004560
2022-01-16 02:06:21,744 iteration 5847 : loss : 0.016417, loss_ce: 0.006144
2022-01-16 02:06:23,283 iteration 5848 : loss : 0.015273, loss_ce: 0.005258
 86%|████████████████████████▉    | 344/400 [2:27:11<23:32, 25.22s/it]2022-01-16 02:06:24,922 iteration 5849 : loss : 0.015633, loss_ce: 0.004747
2022-01-16 02:06:26,670 iteration 5850 : loss : 0.018360, loss_ce: 0.008536
2022-01-16 02:06:28,237 iteration 5851 : loss : 0.011799, loss_ce: 0.002682
2022-01-16 02:06:29,746 iteration 5852 : loss : 0.021725, loss_ce: 0.011548
2022-01-16 02:06:31,324 iteration 5853 : loss : 0.022300, loss_ce: 0.008292
2022-01-16 02:06:33,033 iteration 5854 : loss : 0.020544, loss_ce: 0.008536
2022-01-16 02:06:34,598 iteration 5855 : loss : 0.018233, loss_ce: 0.010373
2022-01-16 02:06:36,171 iteration 5856 : loss : 0.020062, loss_ce: 0.008108
2022-01-16 02:06:37,709 iteration 5857 : loss : 0.014508, loss_ce: 0.005295
2022-01-16 02:06:39,325 iteration 5858 : loss : 0.013983, loss_ce: 0.004282
2022-01-16 02:06:40,930 iteration 5859 : loss : 0.019558, loss_ce: 0.007515
2022-01-16 02:06:42,477 iteration 5860 : loss : 0.014459, loss_ce: 0.005223
2022-01-16 02:06:43,965 iteration 5861 : loss : 0.018637, loss_ce: 0.008753
2022-01-16 02:06:45,489 iteration 5862 : loss : 0.014290, loss_ce: 0.006333
2022-01-16 02:06:46,992 iteration 5863 : loss : 0.026833, loss_ce: 0.009407
2022-01-16 02:06:48,584 iteration 5864 : loss : 0.015528, loss_ce: 0.006487
2022-01-16 02:06:48,585 Training Data Eval:
2022-01-16 02:06:56,834   Average segmentation loss on training set: 0.0095
2022-01-16 02:06:56,834 Validation Data Eval:
2022-01-16 02:06:59,749   Average segmentation loss on validation set: 0.0667
2022-01-16 02:07:01,345 iteration 5865 : loss : 0.027930, loss_ce: 0.008287
 86%|█████████████████████████    | 345/400 [2:27:49<26:38, 29.07s/it]2022-01-16 02:07:03,070 iteration 5866 : loss : 0.015880, loss_ce: 0.004025
2022-01-16 02:07:04,637 iteration 5867 : loss : 0.011952, loss_ce: 0.004821
2022-01-16 02:07:06,227 iteration 5868 : loss : 0.017642, loss_ce: 0.006089
2022-01-16 02:07:07,801 iteration 5869 : loss : 0.014903, loss_ce: 0.004467
2022-01-16 02:07:09,485 iteration 5870 : loss : 0.028163, loss_ce: 0.012355
2022-01-16 02:07:11,169 iteration 5871 : loss : 0.011144, loss_ce: 0.003912
2022-01-16 02:07:12,720 iteration 5872 : loss : 0.016776, loss_ce: 0.005738
2022-01-16 02:07:14,339 iteration 5873 : loss : 0.016331, loss_ce: 0.009318
2022-01-16 02:07:15,921 iteration 5874 : loss : 0.015865, loss_ce: 0.005913
2022-01-16 02:07:17,445 iteration 5875 : loss : 0.013147, loss_ce: 0.006036
2022-01-16 02:07:19,042 iteration 5876 : loss : 0.014347, loss_ce: 0.006155
2022-01-16 02:07:20,623 iteration 5877 : loss : 0.026357, loss_ce: 0.014950
2022-01-16 02:07:22,093 iteration 5878 : loss : 0.014127, loss_ce: 0.004331
2022-01-16 02:07:23,543 iteration 5879 : loss : 0.018248, loss_ce: 0.006310
2022-01-16 02:07:24,996 iteration 5880 : loss : 0.018927, loss_ce: 0.005448
2022-01-16 02:07:26,386 iteration 5881 : loss : 0.014955, loss_ce: 0.005906
2022-01-16 02:07:27,823 iteration 5882 : loss : 0.014622, loss_ce: 0.004815
 86%|█████████████████████████    | 346/400 [2:28:16<25:27, 28.29s/it]2022-01-16 02:07:29,331 iteration 5883 : loss : 0.014477, loss_ce: 0.004814
2022-01-16 02:07:30,809 iteration 5884 : loss : 0.013222, loss_ce: 0.004896
2022-01-16 02:07:32,372 iteration 5885 : loss : 0.015023, loss_ce: 0.004067
2022-01-16 02:07:33,915 iteration 5886 : loss : 0.019233, loss_ce: 0.005632
2022-01-16 02:07:35,461 iteration 5887 : loss : 0.014733, loss_ce: 0.005531
2022-01-16 02:07:36,943 iteration 5888 : loss : 0.011276, loss_ce: 0.004780
2022-01-16 02:07:38,458 iteration 5889 : loss : 0.015215, loss_ce: 0.005339
2022-01-16 02:07:39,936 iteration 5890 : loss : 0.014435, loss_ce: 0.006011
2022-01-16 02:07:41,441 iteration 5891 : loss : 0.019426, loss_ce: 0.005185
2022-01-16 02:07:42,950 iteration 5892 : loss : 0.022242, loss_ce: 0.005959
2022-01-16 02:07:44,385 iteration 5893 : loss : 0.013425, loss_ce: 0.005692
2022-01-16 02:07:45,776 iteration 5894 : loss : 0.021009, loss_ce: 0.009405
2022-01-16 02:07:47,129 iteration 5895 : loss : 0.011056, loss_ce: 0.004264
2022-01-16 02:07:48,478 iteration 5896 : loss : 0.017891, loss_ce: 0.007691
2022-01-16 02:07:49,857 iteration 5897 : loss : 0.019057, loss_ce: 0.008588
2022-01-16 02:07:51,183 iteration 5898 : loss : 0.023109, loss_ce: 0.007801
2022-01-16 02:07:52,581 iteration 5899 : loss : 0.017407, loss_ce: 0.007878
 87%|█████████████████████████▏   | 347/400 [2:28:40<24:03, 27.23s/it]2022-01-16 02:07:53,886 iteration 5900 : loss : 0.015275, loss_ce: 0.005037
2022-01-16 02:07:55,265 iteration 5901 : loss : 0.021993, loss_ce: 0.009848
2022-01-16 02:07:56,604 iteration 5902 : loss : 0.019332, loss_ce: 0.008752
2022-01-16 02:07:57,856 iteration 5903 : loss : 0.015346, loss_ce: 0.004599
2022-01-16 02:07:59,114 iteration 5904 : loss : 0.012240, loss_ce: 0.005307
2022-01-16 02:08:00,291 iteration 5905 : loss : 0.013782, loss_ce: 0.004664
2022-01-16 02:08:01,521 iteration 5906 : loss : 0.017395, loss_ce: 0.006651
2022-01-16 02:08:02,761 iteration 5907 : loss : 0.017462, loss_ce: 0.007401
2022-01-16 02:08:03,968 iteration 5908 : loss : 0.017514, loss_ce: 0.006298
2022-01-16 02:08:05,121 iteration 5909 : loss : 0.011193, loss_ce: 0.004534
2022-01-16 02:08:06,306 iteration 5910 : loss : 0.014150, loss_ce: 0.006519
2022-01-16 02:08:07,472 iteration 5911 : loss : 0.014741, loss_ce: 0.005890
2022-01-16 02:08:08,751 iteration 5912 : loss : 0.034257, loss_ce: 0.005296
2022-01-16 02:08:09,836 iteration 5913 : loss : 0.012829, loss_ce: 0.004396
2022-01-16 02:08:11,087 iteration 5914 : loss : 0.013275, loss_ce: 0.004948
2022-01-16 02:08:12,282 iteration 5915 : loss : 0.021649, loss_ce: 0.008666
2022-01-16 02:08:13,403 iteration 5916 : loss : 0.016755, loss_ce: 0.006733
 87%|█████████████████████████▏   | 348/400 [2:29:01<21:55, 25.31s/it]2022-01-16 02:08:14,546 iteration 5917 : loss : 0.024660, loss_ce: 0.005037
2022-01-16 02:08:15,730 iteration 5918 : loss : 0.021427, loss_ce: 0.009475
2022-01-16 02:08:16,772 iteration 5919 : loss : 0.015416, loss_ce: 0.010282
2022-01-16 02:08:17,936 iteration 5920 : loss : 0.017916, loss_ce: 0.007811
2022-01-16 02:08:18,982 iteration 5921 : loss : 0.019680, loss_ce: 0.006384
2022-01-16 02:08:20,055 iteration 5922 : loss : 0.020626, loss_ce: 0.010880
2022-01-16 02:08:21,074 iteration 5923 : loss : 0.016246, loss_ce: 0.003936
2022-01-16 02:08:22,065 iteration 5924 : loss : 0.012216, loss_ce: 0.004919
2022-01-16 02:08:23,068 iteration 5925 : loss : 0.015715, loss_ce: 0.004361
2022-01-16 02:08:24,087 iteration 5926 : loss : 0.012595, loss_ce: 0.004582
2022-01-16 02:08:25,173 iteration 5927 : loss : 0.019635, loss_ce: 0.007107
2022-01-16 02:08:26,110 iteration 5928 : loss : 0.012157, loss_ce: 0.005267
2022-01-16 02:08:27,077 iteration 5929 : loss : 0.024859, loss_ce: 0.006664
2022-01-16 02:08:28,095 iteration 5930 : loss : 0.015769, loss_ce: 0.004808
2022-01-16 02:08:29,119 iteration 5931 : loss : 0.013211, loss_ce: 0.005725
2022-01-16 02:08:30,109 iteration 5932 : loss : 0.021793, loss_ce: 0.008325
2022-01-16 02:08:31,083 iteration 5933 : loss : 0.011006, loss_ce: 0.004345
 87%|█████████████████████████▎   | 349/400 [2:29:19<19:34, 23.02s/it]2022-01-16 02:08:32,107 iteration 5934 : loss : 0.011667, loss_ce: 0.004224
2022-01-16 02:08:33,074 iteration 5935 : loss : 0.014034, loss_ce: 0.006317
2022-01-16 02:08:34,047 iteration 5936 : loss : 0.014103, loss_ce: 0.005275
2022-01-16 02:08:35,100 iteration 5937 : loss : 0.018003, loss_ce: 0.007952
2022-01-16 02:08:36,174 iteration 5938 : loss : 0.017400, loss_ce: 0.008503
2022-01-16 02:08:37,241 iteration 5939 : loss : 0.019051, loss_ce: 0.007071
2022-01-16 02:08:38,224 iteration 5940 : loss : 0.010173, loss_ce: 0.003857
2022-01-16 02:08:39,276 iteration 5941 : loss : 0.017473, loss_ce: 0.006876
2022-01-16 02:08:40,287 iteration 5942 : loss : 0.012331, loss_ce: 0.004841
2022-01-16 02:08:41,335 iteration 5943 : loss : 0.021424, loss_ce: 0.007299
2022-01-16 02:08:42,252 iteration 5944 : loss : 0.013986, loss_ce: 0.005556
2022-01-16 02:08:43,366 iteration 5945 : loss : 0.017199, loss_ce: 0.005483
2022-01-16 02:08:44,388 iteration 5946 : loss : 0.013073, loss_ce: 0.005458
2022-01-16 02:08:45,500 iteration 5947 : loss : 0.020214, loss_ce: 0.005926
2022-01-16 02:08:46,572 iteration 5948 : loss : 0.023480, loss_ce: 0.007648
2022-01-16 02:08:47,572 iteration 5949 : loss : 0.024689, loss_ce: 0.005686
2022-01-16 02:08:47,572 Training Data Eval:
2022-01-16 02:08:52,387   Average segmentation loss on training set: 0.0091
2022-01-16 02:08:52,387 Validation Data Eval:
2022-01-16 02:08:54,028   Average segmentation loss on validation set: 0.0798
2022-01-16 02:08:54,974 iteration 5950 : loss : 0.011002, loss_ce: 0.003679
 88%|█████████████████████████▍   | 350/400 [2:29:43<19:24, 23.29s/it]2022-01-16 02:08:56,019 iteration 5951 : loss : 0.018750, loss_ce: 0.005769
2022-01-16 02:08:57,036 iteration 5952 : loss : 0.017159, loss_ce: 0.009004
2022-01-16 02:08:58,147 iteration 5953 : loss : 0.021596, loss_ce: 0.010136
2022-01-16 02:08:59,141 iteration 5954 : loss : 0.017456, loss_ce: 0.004102
2022-01-16 02:09:00,277 iteration 5955 : loss : 0.032070, loss_ce: 0.014306
2022-01-16 02:09:01,319 iteration 5956 : loss : 0.024354, loss_ce: 0.006990
2022-01-16 02:09:02,429 iteration 5957 : loss : 0.016655, loss_ce: 0.006567
2022-01-16 02:09:03,539 iteration 5958 : loss : 0.022139, loss_ce: 0.010861
2022-01-16 02:09:04,697 iteration 5959 : loss : 0.017932, loss_ce: 0.005235
2022-01-16 02:09:05,885 iteration 5960 : loss : 0.016030, loss_ce: 0.004764
2022-01-16 02:09:07,206 iteration 5961 : loss : 0.029697, loss_ce: 0.019186
2022-01-16 02:09:08,601 iteration 5962 : loss : 0.016394, loss_ce: 0.006567
2022-01-16 02:09:09,965 iteration 5963 : loss : 0.013714, loss_ce: 0.004928
2022-01-16 02:09:11,412 iteration 5964 : loss : 0.020771, loss_ce: 0.008884
2022-01-16 02:09:12,820 iteration 5965 : loss : 0.012507, loss_ce: 0.006388
2022-01-16 02:09:14,157 iteration 5966 : loss : 0.013305, loss_ce: 0.004436
2022-01-16 02:09:15,572 iteration 5967 : loss : 0.017991, loss_ce: 0.007229
 88%|█████████████████████████▍   | 351/400 [2:30:03<18:21, 22.47s/it]2022-01-16 02:09:16,907 iteration 5968 : loss : 0.015170, loss_ce: 0.006375
2022-01-16 02:09:18,174 iteration 5969 : loss : 0.015743, loss_ce: 0.007399
2022-01-16 02:09:19,503 iteration 5970 : loss : 0.015928, loss_ce: 0.006930
2022-01-16 02:09:20,764 iteration 5971 : loss : 0.011428, loss_ce: 0.005000
2022-01-16 02:09:22,002 iteration 5972 : loss : 0.032595, loss_ce: 0.008695
2022-01-16 02:09:23,250 iteration 5973 : loss : 0.015319, loss_ce: 0.007012
2022-01-16 02:09:24,520 iteration 5974 : loss : 0.029902, loss_ce: 0.007981
2022-01-16 02:09:25,777 iteration 5975 : loss : 0.014819, loss_ce: 0.008693
2022-01-16 02:09:27,050 iteration 5976 : loss : 0.017274, loss_ce: 0.004911
2022-01-16 02:09:28,215 iteration 5977 : loss : 0.012536, loss_ce: 0.004061
2022-01-16 02:09:29,422 iteration 5978 : loss : 0.019931, loss_ce: 0.006405
2022-01-16 02:09:30,674 iteration 5979 : loss : 0.013269, loss_ce: 0.003583
2022-01-16 02:09:32,041 iteration 5980 : loss : 0.016771, loss_ce: 0.003658
2022-01-16 02:09:33,444 iteration 5981 : loss : 0.017211, loss_ce: 0.008105
2022-01-16 02:09:34,803 iteration 5982 : loss : 0.021566, loss_ce: 0.010273
2022-01-16 02:09:36,190 iteration 5983 : loss : 0.016722, loss_ce: 0.004181
2022-01-16 02:09:37,694 iteration 5984 : loss : 0.013909, loss_ce: 0.004459
 88%|█████████████████████████▌   | 352/400 [2:30:26<17:53, 22.37s/it]2022-01-16 02:09:39,254 iteration 5985 : loss : 0.022207, loss_ce: 0.008881
2022-01-16 02:09:40,601 iteration 5986 : loss : 0.010885, loss_ce: 0.004982
2022-01-16 02:09:42,113 iteration 5987 : loss : 0.018706, loss_ce: 0.005599
2022-01-16 02:09:43,546 iteration 5988 : loss : 0.012124, loss_ce: 0.004879
2022-01-16 02:09:45,063 iteration 5989 : loss : 0.015385, loss_ce: 0.006562
2022-01-16 02:09:46,549 iteration 5990 : loss : 0.028436, loss_ce: 0.007626
2022-01-16 02:09:48,072 iteration 5991 : loss : 0.022638, loss_ce: 0.007080
2022-01-16 02:09:49,542 iteration 5992 : loss : 0.023228, loss_ce: 0.006490
2022-01-16 02:09:50,939 iteration 5993 : loss : 0.014719, loss_ce: 0.005307
2022-01-16 02:09:52,252 iteration 5994 : loss : 0.011823, loss_ce: 0.005280
2022-01-16 02:09:53,727 iteration 5995 : loss : 0.017365, loss_ce: 0.006345
2022-01-16 02:09:55,177 iteration 5996 : loss : 0.012587, loss_ce: 0.006292
2022-01-16 02:09:56,568 iteration 5997 : loss : 0.015965, loss_ce: 0.004697
2022-01-16 02:09:58,084 iteration 5998 : loss : 0.020183, loss_ce: 0.007762
2022-01-16 02:09:59,478 iteration 5999 : loss : 0.017089, loss_ce: 0.005769
2022-01-16 02:10:01,001 iteration 6000 : loss : 0.025384, loss_ce: 0.011572
2022-01-16 02:10:02,414 iteration 6001 : loss : 0.011374, loss_ce: 0.004390
 88%|█████████████████████████▌   | 353/400 [2:30:50<18:04, 23.07s/it]2022-01-16 02:10:03,905 iteration 6002 : loss : 0.015018, loss_ce: 0.005982
2022-01-16 02:10:05,536 iteration 6003 : loss : 0.012510, loss_ce: 0.005489
2022-01-16 02:10:07,224 iteration 6004 : loss : 0.014987, loss_ce: 0.006028
2022-01-16 02:10:08,770 iteration 6005 : loss : 0.015740, loss_ce: 0.006604
2022-01-16 02:10:10,327 iteration 6006 : loss : 0.016244, loss_ce: 0.004593
2022-01-16 02:10:11,847 iteration 6007 : loss : 0.014742, loss_ce: 0.005670
2022-01-16 02:10:13,408 iteration 6008 : loss : 0.019929, loss_ce: 0.007721
2022-01-16 02:10:15,017 iteration 6009 : loss : 0.022498, loss_ce: 0.009502
2022-01-16 02:10:16,536 iteration 6010 : loss : 0.015869, loss_ce: 0.003974
2022-01-16 02:10:18,072 iteration 6011 : loss : 0.015303, loss_ce: 0.004988
2022-01-16 02:10:19,626 iteration 6012 : loss : 0.016844, loss_ce: 0.007354
2022-01-16 02:10:21,279 iteration 6013 : loss : 0.013963, loss_ce: 0.004740
2022-01-16 02:10:22,760 iteration 6014 : loss : 0.014060, loss_ce: 0.005078
2022-01-16 02:10:24,202 iteration 6015 : loss : 0.010992, loss_ce: 0.005288
2022-01-16 02:10:25,680 iteration 6016 : loss : 0.011567, loss_ce: 0.003715
2022-01-16 02:10:27,236 iteration 6017 : loss : 0.015324, loss_ce: 0.005578
2022-01-16 02:10:28,679 iteration 6018 : loss : 0.021154, loss_ce: 0.008228
 88%|█████████████████████████▋   | 354/400 [2:31:16<18:25, 24.03s/it]2022-01-16 02:10:30,265 iteration 6019 : loss : 0.012832, loss_ce: 0.004790
2022-01-16 02:10:31,742 iteration 6020 : loss : 0.018178, loss_ce: 0.006507
2022-01-16 02:10:33,185 iteration 6021 : loss : 0.011811, loss_ce: 0.004110
2022-01-16 02:10:34,698 iteration 6022 : loss : 0.015606, loss_ce: 0.006516
2022-01-16 02:10:36,206 iteration 6023 : loss : 0.012835, loss_ce: 0.005576
2022-01-16 02:10:37,673 iteration 6024 : loss : 0.011378, loss_ce: 0.004103
2022-01-16 02:10:39,116 iteration 6025 : loss : 0.017719, loss_ce: 0.003866
2022-01-16 02:10:40,637 iteration 6026 : loss : 0.015215, loss_ce: 0.005994
2022-01-16 02:10:42,252 iteration 6027 : loss : 0.012878, loss_ce: 0.005923
2022-01-16 02:10:43,776 iteration 6028 : loss : 0.013666, loss_ce: 0.006568
2022-01-16 02:10:45,445 iteration 6029 : loss : 0.021112, loss_ce: 0.009541
2022-01-16 02:10:47,024 iteration 6030 : loss : 0.018739, loss_ce: 0.007428
2022-01-16 02:10:48,706 iteration 6031 : loss : 0.023959, loss_ce: 0.007252
2022-01-16 02:10:50,221 iteration 6032 : loss : 0.018734, loss_ce: 0.005376
2022-01-16 02:10:51,780 iteration 6033 : loss : 0.019122, loss_ce: 0.006906
2022-01-16 02:10:53,334 iteration 6034 : loss : 0.010814, loss_ce: 0.004037
2022-01-16 02:10:53,334 Training Data Eval:
2022-01-16 02:11:01,482   Average segmentation loss on training set: 0.0086
2022-01-16 02:11:01,483 Validation Data Eval:
2022-01-16 02:11:04,146   Average segmentation loss on validation set: 0.0768
2022-01-16 02:11:05,649 iteration 6035 : loss : 0.014092, loss_ce: 0.006114
 89%|█████████████████████████▋   | 355/400 [2:31:53<20:56, 27.91s/it]2022-01-16 02:11:07,224 iteration 6036 : loss : 0.012023, loss_ce: 0.005466
2022-01-16 02:11:08,723 iteration 6037 : loss : 0.010648, loss_ce: 0.003988
2022-01-16 02:11:10,258 iteration 6038 : loss : 0.012406, loss_ce: 0.004708
2022-01-16 02:11:11,814 iteration 6039 : loss : 0.011149, loss_ce: 0.003776
2022-01-16 02:11:13,354 iteration 6040 : loss : 0.015153, loss_ce: 0.005423
2022-01-16 02:11:14,996 iteration 6041 : loss : 0.015757, loss_ce: 0.006094
2022-01-16 02:11:16,506 iteration 6042 : loss : 0.015230, loss_ce: 0.003636
2022-01-16 02:11:17,997 iteration 6043 : loss : 0.010871, loss_ce: 0.002456
2022-01-16 02:11:19,597 iteration 6044 : loss : 0.012806, loss_ce: 0.003966
2022-01-16 02:11:21,261 iteration 6045 : loss : 0.015766, loss_ce: 0.008013
2022-01-16 02:11:22,834 iteration 6046 : loss : 0.015600, loss_ce: 0.006711
2022-01-16 02:11:24,354 iteration 6047 : loss : 0.011366, loss_ce: 0.004213
2022-01-16 02:11:26,030 iteration 6048 : loss : 0.016355, loss_ce: 0.006911
2022-01-16 02:11:27,568 iteration 6049 : loss : 0.014694, loss_ce: 0.007031
2022-01-16 02:11:29,141 iteration 6050 : loss : 0.014327, loss_ce: 0.005036
2022-01-16 02:11:30,969 iteration 6051 : loss : 0.013488, loss_ce: 0.004387
2022-01-16 02:11:32,517 iteration 6052 : loss : 0.020099, loss_ce: 0.010653
 89%|█████████████████████████▊   | 356/400 [2:32:20<20:14, 27.60s/it]2022-01-16 02:11:34,080 iteration 6053 : loss : 0.016440, loss_ce: 0.006842
2022-01-16 02:11:35,780 iteration 6054 : loss : 0.012671, loss_ce: 0.006152
2022-01-16 02:11:37,387 iteration 6055 : loss : 0.019731, loss_ce: 0.007145
2022-01-16 02:11:38,949 iteration 6056 : loss : 0.011298, loss_ce: 0.004567
2022-01-16 02:11:40,564 iteration 6057 : loss : 0.019744, loss_ce: 0.005366
2022-01-16 02:11:42,140 iteration 6058 : loss : 0.015644, loss_ce: 0.005064
2022-01-16 02:11:43,883 iteration 6059 : loss : 0.018918, loss_ce: 0.009487
2022-01-16 02:11:45,528 iteration 6060 : loss : 0.030374, loss_ce: 0.010766
2022-01-16 02:11:47,132 iteration 6061 : loss : 0.013146, loss_ce: 0.005504
2022-01-16 02:11:48,779 iteration 6062 : loss : 0.018806, loss_ce: 0.006466
2022-01-16 02:11:50,295 iteration 6063 : loss : 0.016575, loss_ce: 0.004872
2022-01-16 02:11:51,869 iteration 6064 : loss : 0.016411, loss_ce: 0.006881
2022-01-16 02:11:53,476 iteration 6065 : loss : 0.010255, loss_ce: 0.003988
2022-01-16 02:11:54,953 iteration 6066 : loss : 0.009295, loss_ce: 0.002684
2022-01-16 02:11:56,447 iteration 6067 : loss : 0.012395, loss_ce: 0.005491
2022-01-16 02:11:57,928 iteration 6068 : loss : 0.011827, loss_ce: 0.003271
2022-01-16 02:11:59,410 iteration 6069 : loss : 0.019272, loss_ce: 0.007269
 89%|█████████████████████████▉   | 357/400 [2:32:47<19:37, 27.39s/it]2022-01-16 02:12:00,926 iteration 6070 : loss : 0.010868, loss_ce: 0.005395
2022-01-16 02:12:02,362 iteration 6071 : loss : 0.011764, loss_ce: 0.004015
2022-01-16 02:12:03,945 iteration 6072 : loss : 0.013020, loss_ce: 0.006708
2022-01-16 02:12:05,618 iteration 6073 : loss : 0.016813, loss_ce: 0.005427
2022-01-16 02:12:07,202 iteration 6074 : loss : 0.018605, loss_ce: 0.007756
2022-01-16 02:12:08,687 iteration 6075 : loss : 0.012408, loss_ce: 0.005415
2022-01-16 02:12:10,221 iteration 6076 : loss : 0.014182, loss_ce: 0.003367
2022-01-16 02:12:11,731 iteration 6077 : loss : 0.014732, loss_ce: 0.006071
2022-01-16 02:12:13,356 iteration 6078 : loss : 0.019556, loss_ce: 0.006397
2022-01-16 02:12:15,039 iteration 6079 : loss : 0.013759, loss_ce: 0.005088
2022-01-16 02:12:16,615 iteration 6080 : loss : 0.014146, loss_ce: 0.005061
2022-01-16 02:12:18,213 iteration 6081 : loss : 0.016888, loss_ce: 0.006254
2022-01-16 02:12:19,715 iteration 6082 : loss : 0.015214, loss_ce: 0.004306
2022-01-16 02:12:21,221 iteration 6083 : loss : 0.012255, loss_ce: 0.003424
2022-01-16 02:12:22,797 iteration 6084 : loss : 0.016008, loss_ce: 0.004160
2022-01-16 02:12:24,514 iteration 6085 : loss : 0.029180, loss_ce: 0.008621
2022-01-16 02:12:26,218 iteration 6086 : loss : 0.011902, loss_ce: 0.003889
 90%|█████████████████████████▉   | 358/400 [2:33:14<19:02, 27.21s/it]2022-01-16 02:12:27,774 iteration 6087 : loss : 0.014165, loss_ce: 0.004592
2022-01-16 02:12:29,387 iteration 6088 : loss : 0.013065, loss_ce: 0.005120
2022-01-16 02:12:30,967 iteration 6089 : loss : 0.016173, loss_ce: 0.004875
2022-01-16 02:12:32,541 iteration 6090 : loss : 0.012924, loss_ce: 0.005358
2022-01-16 02:12:34,183 iteration 6091 : loss : 0.011828, loss_ce: 0.004151
2022-01-16 02:12:35,710 iteration 6092 : loss : 0.020655, loss_ce: 0.006959
2022-01-16 02:12:37,405 iteration 6093 : loss : 0.016477, loss_ce: 0.007922
2022-01-16 02:12:38,910 iteration 6094 : loss : 0.014725, loss_ce: 0.005294
2022-01-16 02:12:40,595 iteration 6095 : loss : 0.013064, loss_ce: 0.004086
2022-01-16 02:12:42,167 iteration 6096 : loss : 0.017890, loss_ce: 0.005897
2022-01-16 02:12:43,816 iteration 6097 : loss : 0.011771, loss_ce: 0.004737
2022-01-16 02:12:45,520 iteration 6098 : loss : 0.021470, loss_ce: 0.011455
2022-01-16 02:12:47,261 iteration 6099 : loss : 0.013043, loss_ce: 0.005373
2022-01-16 02:12:48,870 iteration 6100 : loss : 0.012854, loss_ce: 0.006453
2022-01-16 02:12:50,605 iteration 6101 : loss : 0.016842, loss_ce: 0.006552
2022-01-16 02:12:52,265 iteration 6102 : loss : 0.019247, loss_ce: 0.010869
2022-01-16 02:12:54,069 iteration 6103 : loss : 0.027867, loss_ce: 0.012859
 90%|██████████████████████████   | 359/400 [2:33:42<18:43, 27.41s/it]2022-01-16 02:12:55,770 iteration 6104 : loss : 0.015789, loss_ce: 0.007010
2022-01-16 02:12:57,408 iteration 6105 : loss : 0.014679, loss_ce: 0.007702
2022-01-16 02:12:59,035 iteration 6106 : loss : 0.020216, loss_ce: 0.008769
2022-01-16 02:13:00,646 iteration 6107 : loss : 0.015025, loss_ce: 0.006007
2022-01-16 02:13:02,181 iteration 6108 : loss : 0.013085, loss_ce: 0.005418
2022-01-16 02:13:03,864 iteration 6109 : loss : 0.015314, loss_ce: 0.003670
2022-01-16 02:13:05,433 iteration 6110 : loss : 0.014178, loss_ce: 0.006349
2022-01-16 02:13:07,012 iteration 6111 : loss : 0.017778, loss_ce: 0.008552
2022-01-16 02:13:08,559 iteration 6112 : loss : 0.020984, loss_ce: 0.007387
2022-01-16 02:13:10,267 iteration 6113 : loss : 0.015116, loss_ce: 0.006210
2022-01-16 02:13:11,903 iteration 6114 : loss : 0.014340, loss_ce: 0.004001
2022-01-16 02:13:13,454 iteration 6115 : loss : 0.018032, loss_ce: 0.008150
2022-01-16 02:13:15,101 iteration 6116 : loss : 0.015344, loss_ce: 0.004948
2022-01-16 02:13:16,791 iteration 6117 : loss : 0.015985, loss_ce: 0.006838
2022-01-16 02:13:18,456 iteration 6118 : loss : 0.011248, loss_ce: 0.003522
2022-01-16 02:13:20,126 iteration 6119 : loss : 0.018201, loss_ce: 0.008521
2022-01-16 02:13:20,126 Training Data Eval:
2022-01-16 02:13:28,785   Average segmentation loss on training set: 0.0086
2022-01-16 02:13:28,785 Validation Data Eval:
2022-01-16 02:13:31,803   Average segmentation loss on validation set: 0.0730
2022-01-16 02:13:33,467 iteration 6120 : loss : 0.014448, loss_ce: 0.004407
 90%|██████████████████████████   | 360/400 [2:34:21<20:40, 31.00s/it]2022-01-16 02:13:35,106 iteration 6121 : loss : 0.018528, loss_ce: 0.005455
2022-01-16 02:13:36,655 iteration 6122 : loss : 0.016068, loss_ce: 0.007403
2022-01-16 02:13:38,287 iteration 6123 : loss : 0.016833, loss_ce: 0.006411
2022-01-16 02:13:39,810 iteration 6124 : loss : 0.015259, loss_ce: 0.006491
2022-01-16 02:13:41,406 iteration 6125 : loss : 0.018529, loss_ce: 0.007025
2022-01-16 02:13:42,932 iteration 6126 : loss : 0.012839, loss_ce: 0.006808
2022-01-16 02:13:44,552 iteration 6127 : loss : 0.012475, loss_ce: 0.003966
2022-01-16 02:13:46,080 iteration 6128 : loss : 0.015197, loss_ce: 0.005031
2022-01-16 02:13:47,674 iteration 6129 : loss : 0.013960, loss_ce: 0.005041
2022-01-16 02:13:49,226 iteration 6130 : loss : 0.013052, loss_ce: 0.003368
2022-01-16 02:13:50,815 iteration 6131 : loss : 0.013313, loss_ce: 0.005914
2022-01-16 02:13:52,355 iteration 6132 : loss : 0.014244, loss_ce: 0.007543
2022-01-16 02:13:53,901 iteration 6133 : loss : 0.018465, loss_ce: 0.005645
2022-01-16 02:13:55,414 iteration 6134 : loss : 0.017059, loss_ce: 0.005645
2022-01-16 02:13:57,012 iteration 6135 : loss : 0.019722, loss_ce: 0.007955
2022-01-16 02:13:58,499 iteration 6136 : loss : 0.013570, loss_ce: 0.003719
2022-01-16 02:13:59,962 iteration 6137 : loss : 0.020968, loss_ce: 0.007704
 90%|██████████████████████████▏  | 361/400 [2:34:48<19:16, 29.65s/it]2022-01-16 02:14:01,525 iteration 6138 : loss : 0.015020, loss_ce: 0.005170
2022-01-16 02:14:03,039 iteration 6139 : loss : 0.014934, loss_ce: 0.005730
2022-01-16 02:14:04,513 iteration 6140 : loss : 0.021543, loss_ce: 0.009079
2022-01-16 02:14:05,937 iteration 6141 : loss : 0.014853, loss_ce: 0.007030
2022-01-16 02:14:07,364 iteration 6142 : loss : 0.009749, loss_ce: 0.004362
2022-01-16 02:14:08,887 iteration 6143 : loss : 0.014018, loss_ce: 0.004207
2022-01-16 02:14:10,320 iteration 6144 : loss : 0.018620, loss_ce: 0.007742
2022-01-16 02:14:11,726 iteration 6145 : loss : 0.017062, loss_ce: 0.007835
2022-01-16 02:14:13,135 iteration 6146 : loss : 0.017848, loss_ce: 0.005181
2022-01-16 02:14:14,571 iteration 6147 : loss : 0.011136, loss_ce: 0.004448
2022-01-16 02:14:16,016 iteration 6148 : loss : 0.015472, loss_ce: 0.005847
2022-01-16 02:14:17,470 iteration 6149 : loss : 0.021812, loss_ce: 0.006851
2022-01-16 02:14:18,945 iteration 6150 : loss : 0.020528, loss_ce: 0.006877
2022-01-16 02:14:20,382 iteration 6151 : loss : 0.017871, loss_ce: 0.004376
2022-01-16 02:14:21,724 iteration 6152 : loss : 0.013339, loss_ce: 0.005368
2022-01-16 02:14:23,122 iteration 6153 : loss : 0.012982, loss_ce: 0.003624
2022-01-16 02:14:24,530 iteration 6154 : loss : 0.018917, loss_ce: 0.007520
 90%|██████████████████████████▏  | 362/400 [2:35:12<17:48, 28.12s/it]2022-01-16 02:14:26,009 iteration 6155 : loss : 0.022351, loss_ce: 0.007746
2022-01-16 02:14:27,481 iteration 6156 : loss : 0.016897, loss_ce: 0.006667
2022-01-16 02:14:28,995 iteration 6157 : loss : 0.017848, loss_ce: 0.006741
2022-01-16 02:14:30,537 iteration 6158 : loss : 0.016578, loss_ce: 0.004298
2022-01-16 02:14:32,030 iteration 6159 : loss : 0.013707, loss_ce: 0.004479
2022-01-16 02:14:33,576 iteration 6160 : loss : 0.011752, loss_ce: 0.004574
2022-01-16 02:14:35,116 iteration 6161 : loss : 0.016973, loss_ce: 0.005024
2022-01-16 02:14:36,761 iteration 6162 : loss : 0.021344, loss_ce: 0.005532
2022-01-16 02:14:38,335 iteration 6163 : loss : 0.018283, loss_ce: 0.007306
2022-01-16 02:14:39,944 iteration 6164 : loss : 0.011622, loss_ce: 0.003135
2022-01-16 02:14:41,600 iteration 6165 : loss : 0.020849, loss_ce: 0.006670
2022-01-16 02:14:43,127 iteration 6166 : loss : 0.012497, loss_ce: 0.004348
2022-01-16 02:14:44,743 iteration 6167 : loss : 0.018856, loss_ce: 0.009715
2022-01-16 02:14:46,340 iteration 6168 : loss : 0.016271, loss_ce: 0.006115
2022-01-16 02:14:47,899 iteration 6169 : loss : 0.018647, loss_ce: 0.005141
2022-01-16 02:14:49,411 iteration 6170 : loss : 0.012670, loss_ce: 0.006006
2022-01-16 02:14:50,960 iteration 6171 : loss : 0.015536, loss_ce: 0.006763
 91%|██████████████████████████▎  | 363/400 [2:35:39<17:01, 27.62s/it]2022-01-16 02:14:52,506 iteration 6172 : loss : 0.017853, loss_ce: 0.005997
2022-01-16 02:14:54,162 iteration 6173 : loss : 0.025753, loss_ce: 0.007154
2022-01-16 02:14:55,765 iteration 6174 : loss : 0.019050, loss_ce: 0.006677
2022-01-16 02:14:57,452 iteration 6175 : loss : 0.017756, loss_ce: 0.007208
2022-01-16 02:14:59,051 iteration 6176 : loss : 0.012577, loss_ce: 0.004305
2022-01-16 02:15:00,610 iteration 6177 : loss : 0.013168, loss_ce: 0.006026
2022-01-16 02:15:02,129 iteration 6178 : loss : 0.014074, loss_ce: 0.004988
2022-01-16 02:15:03,656 iteration 6179 : loss : 0.020510, loss_ce: 0.006645
2022-01-16 02:15:05,210 iteration 6180 : loss : 0.015211, loss_ce: 0.006653
2022-01-16 02:15:06,730 iteration 6181 : loss : 0.010326, loss_ce: 0.003400
2022-01-16 02:15:08,299 iteration 6182 : loss : 0.012510, loss_ce: 0.003515
2022-01-16 02:15:09,941 iteration 6183 : loss : 0.014476, loss_ce: 0.005585
2022-01-16 02:15:11,515 iteration 6184 : loss : 0.014816, loss_ce: 0.006836
2022-01-16 02:15:13,175 iteration 6185 : loss : 0.023853, loss_ce: 0.006271
2022-01-16 02:15:14,738 iteration 6186 : loss : 0.014053, loss_ce: 0.005122
2022-01-16 02:15:16,264 iteration 6187 : loss : 0.014915, loss_ce: 0.007599
2022-01-16 02:15:17,870 iteration 6188 : loss : 0.020386, loss_ce: 0.008548
 91%|██████████████████████████▍  | 364/400 [2:36:06<16:26, 27.41s/it]2022-01-16 02:15:19,502 iteration 6189 : loss : 0.013822, loss_ce: 0.002996
2022-01-16 02:15:21,068 iteration 6190 : loss : 0.021374, loss_ce: 0.006491
2022-01-16 02:15:22,532 iteration 6191 : loss : 0.014441, loss_ce: 0.006943
2022-01-16 02:15:23,930 iteration 6192 : loss : 0.010702, loss_ce: 0.004167
2022-01-16 02:15:25,347 iteration 6193 : loss : 0.017555, loss_ce: 0.005618
2022-01-16 02:15:26,694 iteration 6194 : loss : 0.014083, loss_ce: 0.005674
2022-01-16 02:15:28,163 iteration 6195 : loss : 0.014122, loss_ce: 0.004889
2022-01-16 02:15:29,564 iteration 6196 : loss : 0.016138, loss_ce: 0.005364
2022-01-16 02:15:30,968 iteration 6197 : loss : 0.012843, loss_ce: 0.006097
2022-01-16 02:15:32,729 iteration 6198 : loss : 0.021942, loss_ce: 0.007880
2022-01-16 02:15:34,244 iteration 6199 : loss : 0.020729, loss_ce: 0.008535
2022-01-16 02:15:35,726 iteration 6200 : loss : 0.012544, loss_ce: 0.005521
2022-01-16 02:15:37,221 iteration 6201 : loss : 0.016329, loss_ce: 0.005883
2022-01-16 02:15:38,626 iteration 6202 : loss : 0.012244, loss_ce: 0.004132
2022-01-16 02:15:40,236 iteration 6203 : loss : 0.023919, loss_ce: 0.012016
2022-01-16 02:15:41,667 iteration 6204 : loss : 0.014087, loss_ce: 0.006253
2022-01-16 02:15:41,668 Training Data Eval:
2022-01-16 02:15:49,724   Average segmentation loss on training set: 0.0083
2022-01-16 02:15:49,724 Validation Data Eval:
2022-01-16 02:15:52,590   Average segmentation loss on validation set: 0.0732
2022-01-16 02:15:54,164 iteration 6205 : loss : 0.016858, loss_ce: 0.005371
 91%|██████████████████████████▍  | 365/400 [2:36:42<17:32, 30.07s/it]2022-01-16 02:15:55,891 iteration 6206 : loss : 0.015429, loss_ce: 0.006136
2022-01-16 02:15:57,440 iteration 6207 : loss : 0.015188, loss_ce: 0.006324
2022-01-16 02:15:59,126 iteration 6208 : loss : 0.023313, loss_ce: 0.007636
2022-01-16 02:16:00,731 iteration 6209 : loss : 0.017210, loss_ce: 0.006245
2022-01-16 02:16:02,330 iteration 6210 : loss : 0.010499, loss_ce: 0.003940
2022-01-16 02:16:03,879 iteration 6211 : loss : 0.016940, loss_ce: 0.008934
2022-01-16 02:16:05,441 iteration 6212 : loss : 0.013977, loss_ce: 0.005779
2022-01-16 02:16:07,013 iteration 6213 : loss : 0.011724, loss_ce: 0.004231
2022-01-16 02:16:08,666 iteration 6214 : loss : 0.017611, loss_ce: 0.006038
2022-01-16 02:16:10,230 iteration 6215 : loss : 0.014764, loss_ce: 0.004486
2022-01-16 02:16:11,788 iteration 6216 : loss : 0.020871, loss_ce: 0.005963
2022-01-16 02:16:13,398 iteration 6217 : loss : 0.017978, loss_ce: 0.007058
2022-01-16 02:16:14,907 iteration 6218 : loss : 0.012975, loss_ce: 0.005280
2022-01-16 02:16:16,495 iteration 6219 : loss : 0.017221, loss_ce: 0.005677
2022-01-16 02:16:17,972 iteration 6220 : loss : 0.012425, loss_ce: 0.003275
2022-01-16 02:16:19,551 iteration 6221 : loss : 0.014381, loss_ce: 0.004420
2022-01-16 02:16:21,112 iteration 6222 : loss : 0.011867, loss_ce: 0.005287
 92%|██████████████████████████▌  | 366/400 [2:37:09<16:30, 29.13s/it]2022-01-16 02:16:22,791 iteration 6223 : loss : 0.015080, loss_ce: 0.006480
2022-01-16 02:16:24,358 iteration 6224 : loss : 0.019441, loss_ce: 0.008384
2022-01-16 02:16:25,909 iteration 6225 : loss : 0.014514, loss_ce: 0.007632
2022-01-16 02:16:27,479 iteration 6226 : loss : 0.014450, loss_ce: 0.004936
2022-01-16 02:16:29,120 iteration 6227 : loss : 0.010974, loss_ce: 0.003621
2022-01-16 02:16:30,668 iteration 6228 : loss : 0.015418, loss_ce: 0.005472
2022-01-16 02:16:32,205 iteration 6229 : loss : 0.016633, loss_ce: 0.005083
2022-01-16 02:16:33,777 iteration 6230 : loss : 0.027865, loss_ce: 0.005944
2022-01-16 02:16:35,383 iteration 6231 : loss : 0.014091, loss_ce: 0.006222
2022-01-16 02:16:37,095 iteration 6232 : loss : 0.017285, loss_ce: 0.007052
2022-01-16 02:16:38,723 iteration 6233 : loss : 0.017981, loss_ce: 0.006397
2022-01-16 02:16:40,378 iteration 6234 : loss : 0.017983, loss_ce: 0.006802
2022-01-16 02:16:41,932 iteration 6235 : loss : 0.016581, loss_ce: 0.005179
2022-01-16 02:16:43,484 iteration 6236 : loss : 0.025043, loss_ce: 0.008040
2022-01-16 02:16:45,032 iteration 6237 : loss : 0.025848, loss_ce: 0.011762
2022-01-16 02:16:46,590 iteration 6238 : loss : 0.018909, loss_ce: 0.008492
2022-01-16 02:16:48,118 iteration 6239 : loss : 0.015590, loss_ce: 0.006204
 92%|██████████████████████████▌  | 367/400 [2:37:36<15:40, 28.50s/it]2022-01-16 02:16:49,546 iteration 6240 : loss : 0.016108, loss_ce: 0.005743
2022-01-16 02:16:50,888 iteration 6241 : loss : 0.016327, loss_ce: 0.007315
2022-01-16 02:16:52,319 iteration 6242 : loss : 0.013938, loss_ce: 0.006151
2022-01-16 02:16:53,684 iteration 6243 : loss : 0.016315, loss_ce: 0.006796
2022-01-16 02:16:55,020 iteration 6244 : loss : 0.023316, loss_ce: 0.007544
2022-01-16 02:16:56,380 iteration 6245 : loss : 0.012715, loss_ce: 0.005235
2022-01-16 02:16:57,679 iteration 6246 : loss : 0.014234, loss_ce: 0.005638
2022-01-16 02:16:58,940 iteration 6247 : loss : 0.012944, loss_ce: 0.004330
2022-01-16 02:17:00,252 iteration 6248 : loss : 0.028666, loss_ce: 0.006410
2022-01-16 02:17:01,598 iteration 6249 : loss : 0.015502, loss_ce: 0.005051
2022-01-16 02:17:02,853 iteration 6250 : loss : 0.011901, loss_ce: 0.002894
2022-01-16 02:17:04,277 iteration 6251 : loss : 0.030258, loss_ce: 0.016043
2022-01-16 02:17:05,596 iteration 6252 : loss : 0.010658, loss_ce: 0.003273
2022-01-16 02:17:07,086 iteration 6253 : loss : 0.014838, loss_ce: 0.005608
2022-01-16 02:17:08,431 iteration 6254 : loss : 0.008995, loss_ce: 0.003746
2022-01-16 02:17:09,958 iteration 6255 : loss : 0.025515, loss_ce: 0.008909
2022-01-16 02:17:11,292 iteration 6256 : loss : 0.014304, loss_ce: 0.005410
 92%|██████████████████████████▋  | 368/400 [2:37:59<14:20, 26.90s/it]2022-01-16 02:17:12,712 iteration 6257 : loss : 0.014648, loss_ce: 0.006064
2022-01-16 02:17:13,989 iteration 6258 : loss : 0.010872, loss_ce: 0.005253
2022-01-16 02:17:15,290 iteration 6259 : loss : 0.015658, loss_ce: 0.007165
2022-01-16 02:17:16,564 iteration 6260 : loss : 0.025180, loss_ce: 0.005743
2022-01-16 02:17:17,794 iteration 6261 : loss : 0.012151, loss_ce: 0.005092
2022-01-16 02:17:19,083 iteration 6262 : loss : 0.018954, loss_ce: 0.007442
2022-01-16 02:17:20,362 iteration 6263 : loss : 0.014750, loss_ce: 0.004126
2022-01-16 02:17:21,597 iteration 6264 : loss : 0.011831, loss_ce: 0.005597
2022-01-16 02:17:22,821 iteration 6265 : loss : 0.015215, loss_ce: 0.006444
2022-01-16 02:17:24,100 iteration 6266 : loss : 0.013279, loss_ce: 0.005240
2022-01-16 02:17:25,359 iteration 6267 : loss : 0.023296, loss_ce: 0.008907
2022-01-16 02:17:26,595 iteration 6268 : loss : 0.015054, loss_ce: 0.005595
2022-01-16 02:17:27,830 iteration 6269 : loss : 0.020937, loss_ce: 0.006263
2022-01-16 02:17:29,115 iteration 6270 : loss : 0.020344, loss_ce: 0.005800
2022-01-16 02:17:30,370 iteration 6271 : loss : 0.019568, loss_ce: 0.004414
2022-01-16 02:17:31,577 iteration 6272 : loss : 0.011449, loss_ce: 0.003096
2022-01-16 02:17:32,722 iteration 6273 : loss : 0.009766, loss_ce: 0.003976
 92%|██████████████████████████▊  | 369/400 [2:38:21<13:02, 25.26s/it]2022-01-16 02:17:33,978 iteration 6274 : loss : 0.013726, loss_ce: 0.004648
2022-01-16 02:17:35,205 iteration 6275 : loss : 0.014515, loss_ce: 0.005999
2022-01-16 02:17:36,429 iteration 6276 : loss : 0.014552, loss_ce: 0.006353
2022-01-16 02:17:37,691 iteration 6277 : loss : 0.025247, loss_ce: 0.006393
2022-01-16 02:17:38,962 iteration 6278 : loss : 0.018626, loss_ce: 0.006974
2022-01-16 02:17:40,225 iteration 6279 : loss : 0.031109, loss_ce: 0.009206
2022-01-16 02:17:41,380 iteration 6280 : loss : 0.017567, loss_ce: 0.008320
2022-01-16 02:17:42,503 iteration 6281 : loss : 0.012754, loss_ce: 0.003941
2022-01-16 02:17:43,596 iteration 6282 : loss : 0.011208, loss_ce: 0.004650
2022-01-16 02:17:44,773 iteration 6283 : loss : 0.018143, loss_ce: 0.005258
2022-01-16 02:17:45,949 iteration 6284 : loss : 0.013102, loss_ce: 0.005764
2022-01-16 02:17:47,060 iteration 6285 : loss : 0.014096, loss_ce: 0.004401
2022-01-16 02:17:48,153 iteration 6286 : loss : 0.014224, loss_ce: 0.007423
2022-01-16 02:17:49,271 iteration 6287 : loss : 0.014783, loss_ce: 0.004997
2022-01-16 02:17:50,396 iteration 6288 : loss : 0.024343, loss_ce: 0.007838
2022-01-16 02:17:51,434 iteration 6289 : loss : 0.013917, loss_ce: 0.004782
2022-01-16 02:17:51,434 Training Data Eval:
2022-01-16 02:17:56,505   Average segmentation loss on training set: 0.0083
2022-01-16 02:17:56,506 Validation Data Eval:
2022-01-16 02:17:58,236   Average segmentation loss on validation set: 0.0882
2022-01-16 02:17:59,254 iteration 6290 : loss : 0.012896, loss_ce: 0.004506
 92%|██████████████████████████▊  | 370/400 [2:38:47<12:49, 25.64s/it]2022-01-16 02:18:00,359 iteration 6291 : loss : 0.016217, loss_ce: 0.003934
2022-01-16 02:18:01,525 iteration 6292 : loss : 0.015148, loss_ce: 0.005478
2022-01-16 02:18:02,577 iteration 6293 : loss : 0.015457, loss_ce: 0.005997
2022-01-16 02:18:03,732 iteration 6294 : loss : 0.015238, loss_ce: 0.006421
2022-01-16 02:18:04,895 iteration 6295 : loss : 0.014211, loss_ce: 0.005047
2022-01-16 02:18:06,033 iteration 6296 : loss : 0.010919, loss_ce: 0.003867
2022-01-16 02:18:07,258 iteration 6297 : loss : 0.019756, loss_ce: 0.005720
2022-01-16 02:18:08,515 iteration 6298 : loss : 0.011562, loss_ce: 0.004238
2022-01-16 02:18:09,922 iteration 6299 : loss : 0.016128, loss_ce: 0.006733
2022-01-16 02:18:11,322 iteration 6300 : loss : 0.018316, loss_ce: 0.006385
2022-01-16 02:18:12,827 iteration 6301 : loss : 0.019021, loss_ce: 0.007430
2022-01-16 02:18:14,348 iteration 6302 : loss : 0.012152, loss_ce: 0.004767
2022-01-16 02:18:15,876 iteration 6303 : loss : 0.021296, loss_ce: 0.009154
2022-01-16 02:18:17,417 iteration 6304 : loss : 0.013859, loss_ce: 0.005451
2022-01-16 02:18:18,899 iteration 6305 : loss : 0.010494, loss_ce: 0.004518
2022-01-16 02:18:20,407 iteration 6306 : loss : 0.012844, loss_ce: 0.004385
2022-01-16 02:18:21,976 iteration 6307 : loss : 0.015077, loss_ce: 0.005228
 93%|██████████████████████████▉  | 371/400 [2:39:10<11:58, 24.77s/it]2022-01-16 02:18:23,493 iteration 6308 : loss : 0.013505, loss_ce: 0.005348
2022-01-16 02:18:25,025 iteration 6309 : loss : 0.016368, loss_ce: 0.005825
2022-01-16 02:18:26,549 iteration 6310 : loss : 0.012342, loss_ce: 0.004974
2022-01-16 02:18:28,080 iteration 6311 : loss : 0.014481, loss_ce: 0.004031
2022-01-16 02:18:29,632 iteration 6312 : loss : 0.018680, loss_ce: 0.006276
2022-01-16 02:18:31,110 iteration 6313 : loss : 0.010134, loss_ce: 0.002223
2022-01-16 02:18:32,637 iteration 6314 : loss : 0.018525, loss_ce: 0.007049
2022-01-16 02:18:34,209 iteration 6315 : loss : 0.017225, loss_ce: 0.005725
2022-01-16 02:18:35,872 iteration 6316 : loss : 0.012056, loss_ce: 0.005723
2022-01-16 02:18:37,426 iteration 6317 : loss : 0.012648, loss_ce: 0.004727
2022-01-16 02:18:38,984 iteration 6318 : loss : 0.017648, loss_ce: 0.008694
2022-01-16 02:18:40,729 iteration 6319 : loss : 0.017936, loss_ce: 0.006181
2022-01-16 02:18:42,331 iteration 6320 : loss : 0.016940, loss_ce: 0.006677
2022-01-16 02:18:43,880 iteration 6321 : loss : 0.017815, loss_ce: 0.008412
2022-01-16 02:18:45,449 iteration 6322 : loss : 0.015708, loss_ce: 0.006087
2022-01-16 02:18:46,888 iteration 6323 : loss : 0.011712, loss_ce: 0.005187
2022-01-16 02:18:48,627 iteration 6324 : loss : 0.016698, loss_ce: 0.004457
 93%|██████████████████████████▉  | 372/400 [2:39:36<11:49, 25.33s/it]2022-01-16 02:18:50,201 iteration 6325 : loss : 0.014224, loss_ce: 0.004886
2022-01-16 02:18:51,732 iteration 6326 : loss : 0.010313, loss_ce: 0.004495
2022-01-16 02:18:53,236 iteration 6327 : loss : 0.010697, loss_ce: 0.003883
2022-01-16 02:18:54,978 iteration 6328 : loss : 0.019532, loss_ce: 0.008915
2022-01-16 02:18:56,639 iteration 6329 : loss : 0.014847, loss_ce: 0.005094
2022-01-16 02:18:58,269 iteration 6330 : loss : 0.011743, loss_ce: 0.004501
2022-01-16 02:18:59,908 iteration 6331 : loss : 0.015510, loss_ce: 0.006499
2022-01-16 02:19:01,489 iteration 6332 : loss : 0.012993, loss_ce: 0.004380
2022-01-16 02:19:03,039 iteration 6333 : loss : 0.012304, loss_ce: 0.004563
2022-01-16 02:19:04,701 iteration 6334 : loss : 0.013270, loss_ce: 0.005981
2022-01-16 02:19:06,544 iteration 6335 : loss : 0.022710, loss_ce: 0.010673
2022-01-16 02:19:08,246 iteration 6336 : loss : 0.011830, loss_ce: 0.003824
2022-01-16 02:19:09,829 iteration 6337 : loss : 0.013273, loss_ce: 0.005218
2022-01-16 02:19:11,412 iteration 6338 : loss : 0.015683, loss_ce: 0.005353
2022-01-16 02:19:13,100 iteration 6339 : loss : 0.014171, loss_ce: 0.004766
2022-01-16 02:19:14,683 iteration 6340 : loss : 0.016002, loss_ce: 0.008614
2022-01-16 02:19:16,294 iteration 6341 : loss : 0.016431, loss_ce: 0.004861
 93%|███████████████████████████  | 373/400 [2:40:04<11:42, 26.03s/it]2022-01-16 02:19:18,116 iteration 6342 : loss : 0.012597, loss_ce: 0.004750
2022-01-16 02:19:19,662 iteration 6343 : loss : 0.012614, loss_ce: 0.003807
2022-01-16 02:19:21,352 iteration 6344 : loss : 0.017533, loss_ce: 0.007307
2022-01-16 02:19:22,959 iteration 6345 : loss : 0.020230, loss_ce: 0.010486
2022-01-16 02:19:24,503 iteration 6346 : loss : 0.010875, loss_ce: 0.002983
2022-01-16 02:19:26,079 iteration 6347 : loss : 0.031173, loss_ce: 0.020100
2022-01-16 02:19:27,826 iteration 6348 : loss : 0.022351, loss_ce: 0.008674
2022-01-16 02:19:29,306 iteration 6349 : loss : 0.012026, loss_ce: 0.004828
2022-01-16 02:19:30,809 iteration 6350 : loss : 0.013553, loss_ce: 0.003753
2022-01-16 02:19:32,345 iteration 6351 : loss : 0.014463, loss_ce: 0.005066
2022-01-16 02:19:33,993 iteration 6352 : loss : 0.012694, loss_ce: 0.005352
2022-01-16 02:19:35,552 iteration 6353 : loss : 0.014110, loss_ce: 0.005314
2022-01-16 02:19:37,206 iteration 6354 : loss : 0.012733, loss_ce: 0.004441
2022-01-16 02:19:38,738 iteration 6355 : loss : 0.010930, loss_ce: 0.004788
2022-01-16 02:19:40,416 iteration 6356 : loss : 0.018386, loss_ce: 0.009527
2022-01-16 02:19:41,921 iteration 6357 : loss : 0.018350, loss_ce: 0.006253
2022-01-16 02:19:43,500 iteration 6358 : loss : 0.022306, loss_ce: 0.008215
 94%|███████████████████████████  | 374/400 [2:40:31<11:26, 26.39s/it]2022-01-16 02:19:45,088 iteration 6359 : loss : 0.012605, loss_ce: 0.004525
2022-01-16 02:19:46,581 iteration 6360 : loss : 0.014650, loss_ce: 0.004155
2022-01-16 02:19:48,102 iteration 6361 : loss : 0.018975, loss_ce: 0.004994
2022-01-16 02:19:49,596 iteration 6362 : loss : 0.012390, loss_ce: 0.005832
2022-01-16 02:19:51,131 iteration 6363 : loss : 0.019375, loss_ce: 0.008927
2022-01-16 02:19:52,514 iteration 6364 : loss : 0.009495, loss_ce: 0.003591
2022-01-16 02:19:53,860 iteration 6365 : loss : 0.014056, loss_ce: 0.005316
2022-01-16 02:19:55,263 iteration 6366 : loss : 0.021580, loss_ce: 0.008525
2022-01-16 02:19:56,594 iteration 6367 : loss : 0.012273, loss_ce: 0.005206
2022-01-16 02:19:57,925 iteration 6368 : loss : 0.015739, loss_ce: 0.006156
2022-01-16 02:19:59,291 iteration 6369 : loss : 0.013360, loss_ce: 0.005638
2022-01-16 02:20:00,692 iteration 6370 : loss : 0.020296, loss_ce: 0.005641
2022-01-16 02:20:02,069 iteration 6371 : loss : 0.017254, loss_ce: 0.007084
2022-01-16 02:20:03,445 iteration 6372 : loss : 0.017423, loss_ce: 0.009731
2022-01-16 02:20:04,701 iteration 6373 : loss : 0.009667, loss_ce: 0.002464
2022-01-16 02:20:06,050 iteration 6374 : loss : 0.010122, loss_ce: 0.003942
2022-01-16 02:20:06,050 Training Data Eval:
2022-01-16 02:20:13,118   Average segmentation loss on training set: 0.0079
2022-01-16 02:20:13,118 Validation Data Eval:
2022-01-16 02:20:15,542   Average segmentation loss on validation set: 0.0681
2022-01-16 02:20:16,933 iteration 6375 : loss : 0.015109, loss_ce: 0.005006
 94%|███████████████████████████▏ | 375/400 [2:41:05<11:52, 28.50s/it]2022-01-16 02:20:18,555 iteration 6376 : loss : 0.019458, loss_ce: 0.007552
2022-01-16 02:20:19,954 iteration 6377 : loss : 0.012888, loss_ce: 0.004431
2022-01-16 02:20:21,374 iteration 6378 : loss : 0.015612, loss_ce: 0.005358
2022-01-16 02:20:22,835 iteration 6379 : loss : 0.016288, loss_ce: 0.004661
2022-01-16 02:20:24,426 iteration 6380 : loss : 0.011106, loss_ce: 0.005065
2022-01-16 02:20:25,929 iteration 6381 : loss : 0.013861, loss_ce: 0.004829
2022-01-16 02:20:27,476 iteration 6382 : loss : 0.017531, loss_ce: 0.007915
2022-01-16 02:20:28,995 iteration 6383 : loss : 0.018807, loss_ce: 0.006590
2022-01-16 02:20:30,435 iteration 6384 : loss : 0.012185, loss_ce: 0.004671
2022-01-16 02:20:32,012 iteration 6385 : loss : 0.016642, loss_ce: 0.007382
2022-01-16 02:20:33,560 iteration 6386 : loss : 0.015012, loss_ce: 0.005592
2022-01-16 02:20:35,188 iteration 6387 : loss : 0.019070, loss_ce: 0.008680
2022-01-16 02:20:36,639 iteration 6388 : loss : 0.010351, loss_ce: 0.003452
2022-01-16 02:20:38,034 iteration 6389 : loss : 0.012100, loss_ce: 0.003564
2022-01-16 02:20:39,522 iteration 6390 : loss : 0.012742, loss_ce: 0.004433
2022-01-16 02:20:41,076 iteration 6391 : loss : 0.037106, loss_ce: 0.012203
2022-01-16 02:20:42,457 iteration 6392 : loss : 0.010435, loss_ce: 0.004463
 94%|███████████████████████████▎ | 376/400 [2:41:30<11:02, 27.61s/it]2022-01-16 02:20:43,943 iteration 6393 : loss : 0.012071, loss_ce: 0.003803
2022-01-16 02:20:45,379 iteration 6394 : loss : 0.015853, loss_ce: 0.004873
2022-01-16 02:20:46,785 iteration 6395 : loss : 0.011086, loss_ce: 0.005218
2022-01-16 02:20:48,330 iteration 6396 : loss : 0.017298, loss_ce: 0.007441
2022-01-16 02:20:49,738 iteration 6397 : loss : 0.016152, loss_ce: 0.006398
2022-01-16 02:20:51,142 iteration 6398 : loss : 0.011817, loss_ce: 0.003420
2022-01-16 02:20:52,649 iteration 6399 : loss : 0.014345, loss_ce: 0.004391
2022-01-16 02:20:54,139 iteration 6400 : loss : 0.013588, loss_ce: 0.006288
2022-01-16 02:20:55,540 iteration 6401 : loss : 0.012734, loss_ce: 0.005036
2022-01-16 02:20:56,995 iteration 6402 : loss : 0.015100, loss_ce: 0.005559
2022-01-16 02:20:58,544 iteration 6403 : loss : 0.017270, loss_ce: 0.006914
2022-01-16 02:21:00,003 iteration 6404 : loss : 0.016616, loss_ce: 0.004528
2022-01-16 02:21:01,434 iteration 6405 : loss : 0.016620, loss_ce: 0.005971
2022-01-16 02:21:03,027 iteration 6406 : loss : 0.015135, loss_ce: 0.007201
2022-01-16 02:21:04,387 iteration 6407 : loss : 0.011399, loss_ce: 0.003325
2022-01-16 02:21:05,816 iteration 6408 : loss : 0.018885, loss_ce: 0.004717
2022-01-16 02:21:07,236 iteration 6409 : loss : 0.013723, loss_ce: 0.005618
 94%|███████████████████████████▎ | 377/400 [2:41:55<10:15, 26.76s/it]2022-01-16 02:21:08,909 iteration 6410 : loss : 0.018595, loss_ce: 0.006779
2022-01-16 02:21:10,458 iteration 6411 : loss : 0.013048, loss_ce: 0.005014
2022-01-16 02:21:11,947 iteration 6412 : loss : 0.013463, loss_ce: 0.006120
2022-01-16 02:21:13,432 iteration 6413 : loss : 0.013761, loss_ce: 0.005069
2022-01-16 02:21:14,939 iteration 6414 : loss : 0.016249, loss_ce: 0.005832
2022-01-16 02:21:16,446 iteration 6415 : loss : 0.014454, loss_ce: 0.004858
2022-01-16 02:21:17,941 iteration 6416 : loss : 0.017240, loss_ce: 0.004084
2022-01-16 02:21:19,511 iteration 6417 : loss : 0.018736, loss_ce: 0.009297
2022-01-16 02:21:21,111 iteration 6418 : loss : 0.012646, loss_ce: 0.004699
2022-01-16 02:21:22,816 iteration 6419 : loss : 0.012886, loss_ce: 0.003936
2022-01-16 02:21:24,393 iteration 6420 : loss : 0.016792, loss_ce: 0.005581
2022-01-16 02:21:25,894 iteration 6421 : loss : 0.010859, loss_ce: 0.003858
2022-01-16 02:21:27,332 iteration 6422 : loss : 0.015615, loss_ce: 0.006242
2022-01-16 02:21:28,853 iteration 6423 : loss : 0.017962, loss_ce: 0.005764
2022-01-16 02:21:30,333 iteration 6424 : loss : 0.023296, loss_ce: 0.012391
2022-01-16 02:21:31,675 iteration 6425 : loss : 0.012348, loss_ce: 0.004041
2022-01-16 02:21:33,152 iteration 6426 : loss : 0.019061, loss_ce: 0.010506
 94%|███████████████████████████▍ | 378/400 [2:42:21<09:43, 26.51s/it]2022-01-16 02:21:34,669 iteration 6427 : loss : 0.018976, loss_ce: 0.008970
2022-01-16 02:21:36,051 iteration 6428 : loss : 0.010997, loss_ce: 0.005336
2022-01-16 02:21:37,501 iteration 6429 : loss : 0.014185, loss_ce: 0.005312
2022-01-16 02:21:38,870 iteration 6430 : loss : 0.010394, loss_ce: 0.002749
2022-01-16 02:21:40,293 iteration 6431 : loss : 0.014413, loss_ce: 0.004364
2022-01-16 02:21:41,745 iteration 6432 : loss : 0.013075, loss_ce: 0.004901
2022-01-16 02:21:43,287 iteration 6433 : loss : 0.015249, loss_ce: 0.005514
2022-01-16 02:21:44,732 iteration 6434 : loss : 0.009810, loss_ce: 0.003640
2022-01-16 02:21:46,224 iteration 6435 : loss : 0.013893, loss_ce: 0.006590
2022-01-16 02:21:47,726 iteration 6436 : loss : 0.014021, loss_ce: 0.005421
2022-01-16 02:21:49,282 iteration 6437 : loss : 0.015458, loss_ce: 0.004116
2022-01-16 02:21:50,828 iteration 6438 : loss : 0.013873, loss_ce: 0.005350
2022-01-16 02:21:52,364 iteration 6439 : loss : 0.016485, loss_ce: 0.005600
2022-01-16 02:21:53,923 iteration 6440 : loss : 0.017339, loss_ce: 0.007247
2022-01-16 02:21:55,451 iteration 6441 : loss : 0.013354, loss_ce: 0.003632
2022-01-16 02:21:56,945 iteration 6442 : loss : 0.013675, loss_ce: 0.005284
2022-01-16 02:21:58,527 iteration 6443 : loss : 0.023524, loss_ce: 0.010222
 95%|███████████████████████████▍ | 379/400 [2:42:46<09:09, 26.16s/it]2022-01-16 02:22:00,143 iteration 6444 : loss : 0.016851, loss_ce: 0.007241
2022-01-16 02:22:01,768 iteration 6445 : loss : 0.018966, loss_ce: 0.006684
2022-01-16 02:22:03,365 iteration 6446 : loss : 0.013165, loss_ce: 0.003900
2022-01-16 02:22:04,870 iteration 6447 : loss : 0.015847, loss_ce: 0.008450
2022-01-16 02:22:06,430 iteration 6448 : loss : 0.013698, loss_ce: 0.006220
2022-01-16 02:22:07,996 iteration 6449 : loss : 0.012978, loss_ce: 0.003837
2022-01-16 02:22:09,456 iteration 6450 : loss : 0.012628, loss_ce: 0.005478
2022-01-16 02:22:10,875 iteration 6451 : loss : 0.013241, loss_ce: 0.004871
2022-01-16 02:22:12,364 iteration 6452 : loss : 0.012951, loss_ce: 0.006088
2022-01-16 02:22:13,822 iteration 6453 : loss : 0.015870, loss_ce: 0.006763
2022-01-16 02:22:15,332 iteration 6454 : loss : 0.013555, loss_ce: 0.004989
2022-01-16 02:22:16,941 iteration 6455 : loss : 0.012674, loss_ce: 0.004177
2022-01-16 02:22:18,573 iteration 6456 : loss : 0.016321, loss_ce: 0.007128
2022-01-16 02:22:20,091 iteration 6457 : loss : 0.012208, loss_ce: 0.003831
2022-01-16 02:22:21,610 iteration 6458 : loss : 0.013134, loss_ce: 0.003949
2022-01-16 02:22:23,084 iteration 6459 : loss : 0.012370, loss_ce: 0.004472
2022-01-16 02:22:23,085 Training Data Eval:
2022-01-16 02:22:30,927   Average segmentation loss on training set: 0.0076
2022-01-16 02:22:30,927 Validation Data Eval:
2022-01-16 02:22:33,683   Average segmentation loss on validation set: 0.0800
2022-01-16 02:22:35,278 iteration 6460 : loss : 0.025815, loss_ce: 0.008109
 95%|███████████████████████████▌ | 380/400 [2:43:23<09:46, 29.34s/it]2022-01-16 02:22:36,976 iteration 6461 : loss : 0.013846, loss_ce: 0.003648
2022-01-16 02:22:38,679 iteration 6462 : loss : 0.014073, loss_ce: 0.005134
2022-01-16 02:22:40,208 iteration 6463 : loss : 0.009490, loss_ce: 0.002702
2022-01-16 02:22:41,741 iteration 6464 : loss : 0.010633, loss_ce: 0.003432
2022-01-16 02:22:43,308 iteration 6465 : loss : 0.020218, loss_ce: 0.005970
2022-01-16 02:22:44,932 iteration 6466 : loss : 0.013587, loss_ce: 0.005038
2022-01-16 02:22:46,610 iteration 6467 : loss : 0.012871, loss_ce: 0.005487
2022-01-16 02:22:48,261 iteration 6468 : loss : 0.018070, loss_ce: 0.009147
2022-01-16 02:22:49,839 iteration 6469 : loss : 0.015405, loss_ce: 0.008115
2022-01-16 02:22:51,328 iteration 6470 : loss : 0.014745, loss_ce: 0.004308
2022-01-16 02:22:52,879 iteration 6471 : loss : 0.015113, loss_ce: 0.005278
2022-01-16 02:22:54,510 iteration 6472 : loss : 0.014513, loss_ce: 0.004266
2022-01-16 02:22:56,182 iteration 6473 : loss : 0.013078, loss_ce: 0.006302
2022-01-16 02:22:57,912 iteration 6474 : loss : 0.013498, loss_ce: 0.007113
2022-01-16 02:22:59,415 iteration 6475 : loss : 0.009727, loss_ce: 0.003206
2022-01-16 02:23:00,966 iteration 6476 : loss : 0.011037, loss_ce: 0.004079
2022-01-16 02:23:02,457 iteration 6477 : loss : 0.011315, loss_ce: 0.003990
 95%|███████████████████████████▌ | 381/400 [2:43:50<09:05, 28.69s/it]2022-01-16 02:23:04,060 iteration 6478 : loss : 0.014586, loss_ce: 0.005886
2022-01-16 02:23:05,812 iteration 6479 : loss : 0.019925, loss_ce: 0.010473
2022-01-16 02:23:07,532 iteration 6480 : loss : 0.024868, loss_ce: 0.005460
2022-01-16 02:23:09,144 iteration 6481 : loss : 0.015703, loss_ce: 0.005902
2022-01-16 02:23:10,750 iteration 6482 : loss : 0.015774, loss_ce: 0.006087
2022-01-16 02:23:12,288 iteration 6483 : loss : 0.014579, loss_ce: 0.005040
2022-01-16 02:23:13,866 iteration 6484 : loss : 0.013254, loss_ce: 0.003609
2022-01-16 02:23:15,472 iteration 6485 : loss : 0.015389, loss_ce: 0.006507
2022-01-16 02:23:17,137 iteration 6486 : loss : 0.012681, loss_ce: 0.004266
2022-01-16 02:23:18,752 iteration 6487 : loss : 0.016582, loss_ce: 0.004802
2022-01-16 02:23:20,324 iteration 6488 : loss : 0.016465, loss_ce: 0.006213
2022-01-16 02:23:21,894 iteration 6489 : loss : 0.021142, loss_ce: 0.005039
2022-01-16 02:23:23,375 iteration 6490 : loss : 0.010766, loss_ce: 0.004061
2022-01-16 02:23:24,896 iteration 6491 : loss : 0.018514, loss_ce: 0.005457
2022-01-16 02:23:26,339 iteration 6492 : loss : 0.012541, loss_ce: 0.004513
2022-01-16 02:23:27,857 iteration 6493 : loss : 0.018394, loss_ce: 0.004726
2022-01-16 02:23:29,360 iteration 6494 : loss : 0.014095, loss_ce: 0.005514
 96%|███████████████████████████▋ | 382/400 [2:44:17<08:26, 28.16s/it]2022-01-16 02:23:30,935 iteration 6495 : loss : 0.011748, loss_ce: 0.003293
2022-01-16 02:23:32,412 iteration 6496 : loss : 0.015907, loss_ce: 0.006432
2022-01-16 02:23:33,931 iteration 6497 : loss : 0.010544, loss_ce: 0.003864
2022-01-16 02:23:35,419 iteration 6498 : loss : 0.023074, loss_ce: 0.012678
2022-01-16 02:23:37,040 iteration 6499 : loss : 0.018442, loss_ce: 0.006986
2022-01-16 02:23:38,666 iteration 6500 : loss : 0.019740, loss_ce: 0.007525
2022-01-16 02:23:40,245 iteration 6501 : loss : 0.013373, loss_ce: 0.003615
2022-01-16 02:23:41,829 iteration 6502 : loss : 0.018599, loss_ce: 0.007307
2022-01-16 02:23:43,457 iteration 6503 : loss : 0.021939, loss_ce: 0.007691
2022-01-16 02:23:44,932 iteration 6504 : loss : 0.010558, loss_ce: 0.005370
2022-01-16 02:23:46,479 iteration 6505 : loss : 0.012048, loss_ce: 0.003211
2022-01-16 02:23:48,051 iteration 6506 : loss : 0.010957, loss_ce: 0.003230
2022-01-16 02:23:49,608 iteration 6507 : loss : 0.016081, loss_ce: 0.006401
2022-01-16 02:23:51,124 iteration 6508 : loss : 0.013247, loss_ce: 0.006072
2022-01-16 02:23:52,834 iteration 6509 : loss : 0.015515, loss_ce: 0.006224
2022-01-16 02:23:54,379 iteration 6510 : loss : 0.020165, loss_ce: 0.006675
2022-01-16 02:23:55,950 iteration 6511 : loss : 0.021768, loss_ce: 0.009946
 96%|███████████████████████████▊ | 383/400 [2:44:44<07:50, 27.69s/it]2022-01-16 02:23:57,585 iteration 6512 : loss : 0.011444, loss_ce: 0.004639
2022-01-16 02:23:59,255 iteration 6513 : loss : 0.010730, loss_ce: 0.004262
2022-01-16 02:24:00,815 iteration 6514 : loss : 0.011505, loss_ce: 0.002660
2022-01-16 02:24:02,397 iteration 6515 : loss : 0.015951, loss_ce: 0.004728
2022-01-16 02:24:03,959 iteration 6516 : loss : 0.015262, loss_ce: 0.004639
2022-01-16 02:24:05,661 iteration 6517 : loss : 0.014383, loss_ce: 0.006711
2022-01-16 02:24:07,314 iteration 6518 : loss : 0.015616, loss_ce: 0.006762
2022-01-16 02:24:08,917 iteration 6519 : loss : 0.022512, loss_ce: 0.007530
2022-01-16 02:24:10,527 iteration 6520 : loss : 0.011569, loss_ce: 0.004961
2022-01-16 02:24:12,076 iteration 6521 : loss : 0.010611, loss_ce: 0.004172
2022-01-16 02:24:13,570 iteration 6522 : loss : 0.013313, loss_ce: 0.006075
2022-01-16 02:24:15,023 iteration 6523 : loss : 0.014346, loss_ce: 0.004796
2022-01-16 02:24:16,510 iteration 6524 : loss : 0.021935, loss_ce: 0.007521
2022-01-16 02:24:18,063 iteration 6525 : loss : 0.011225, loss_ce: 0.003624
2022-01-16 02:24:19,593 iteration 6526 : loss : 0.010829, loss_ce: 0.003753
2022-01-16 02:24:21,126 iteration 6527 : loss : 0.014060, loss_ce: 0.004880
2022-01-16 02:24:22,617 iteration 6528 : loss : 0.013792, loss_ce: 0.005854
 96%|███████████████████████████▊ | 384/400 [2:45:10<07:18, 27.38s/it]2022-01-16 02:24:24,090 iteration 6529 : loss : 0.012512, loss_ce: 0.004789
2022-01-16 02:24:25,679 iteration 6530 : loss : 0.010159, loss_ce: 0.004524
2022-01-16 02:24:27,245 iteration 6531 : loss : 0.011309, loss_ce: 0.002705
2022-01-16 02:24:28,806 iteration 6532 : loss : 0.011848, loss_ce: 0.003442
2022-01-16 02:24:30,276 iteration 6533 : loss : 0.014138, loss_ce: 0.006452
2022-01-16 02:24:31,813 iteration 6534 : loss : 0.018099, loss_ce: 0.004665
2022-01-16 02:24:33,328 iteration 6535 : loss : 0.013625, loss_ce: 0.005287
2022-01-16 02:24:34,852 iteration 6536 : loss : 0.012782, loss_ce: 0.004893
2022-01-16 02:24:36,396 iteration 6537 : loss : 0.018384, loss_ce: 0.005317
2022-01-16 02:24:37,787 iteration 6538 : loss : 0.018693, loss_ce: 0.006436
2022-01-16 02:24:39,379 iteration 6539 : loss : 0.017368, loss_ce: 0.006968
2022-01-16 02:24:40,827 iteration 6540 : loss : 0.012660, loss_ce: 0.005567
2022-01-16 02:24:42,213 iteration 6541 : loss : 0.011221, loss_ce: 0.004507
2022-01-16 02:24:43,630 iteration 6542 : loss : 0.017183, loss_ce: 0.006414
2022-01-16 02:24:45,088 iteration 6543 : loss : 0.014304, loss_ce: 0.004910
2022-01-16 02:24:46,456 iteration 6544 : loss : 0.015128, loss_ce: 0.006112
2022-01-16 02:24:46,456 Training Data Eval:
2022-01-16 02:24:53,568   Average segmentation loss on training set: 0.0075
2022-01-16 02:24:53,568 Validation Data Eval:
2022-01-16 02:24:56,238   Average segmentation loss on validation set: 0.0798
2022-01-16 02:24:57,923 iteration 6545 : loss : 0.013613, loss_ce: 0.004113
 96%|███████████████████████████▉ | 385/400 [2:45:46<07:26, 29.76s/it]2022-01-16 02:24:59,582 iteration 6546 : loss : 0.019601, loss_ce: 0.006904
2022-01-16 02:25:01,253 iteration 6547 : loss : 0.015287, loss_ce: 0.003342
2022-01-16 02:25:02,843 iteration 6548 : loss : 0.025985, loss_ce: 0.007229
2022-01-16 02:25:04,486 iteration 6549 : loss : 0.026387, loss_ce: 0.008676
2022-01-16 02:25:06,061 iteration 6550 : loss : 0.013377, loss_ce: 0.006113
2022-01-16 02:25:07,678 iteration 6551 : loss : 0.015339, loss_ce: 0.007026
2022-01-16 02:25:09,271 iteration 6552 : loss : 0.016313, loss_ce: 0.006812
2022-01-16 02:25:10,888 iteration 6553 : loss : 0.022675, loss_ce: 0.009366
2022-01-16 02:25:12,600 iteration 6554 : loss : 0.028063, loss_ce: 0.011256
2022-01-16 02:25:14,078 iteration 6555 : loss : 0.013128, loss_ce: 0.005112
2022-01-16 02:25:15,688 iteration 6556 : loss : 0.015992, loss_ce: 0.005569
2022-01-16 02:25:17,297 iteration 6557 : loss : 0.011343, loss_ce: 0.004054
2022-01-16 02:25:19,018 iteration 6558 : loss : 0.026835, loss_ce: 0.011201
2022-01-16 02:25:20,487 iteration 6559 : loss : 0.010600, loss_ce: 0.003750
2022-01-16 02:25:21,960 iteration 6560 : loss : 0.011232, loss_ce: 0.005187
2022-01-16 02:25:23,489 iteration 6561 : loss : 0.012497, loss_ce: 0.004270
2022-01-16 02:25:25,059 iteration 6562 : loss : 0.016069, loss_ce: 0.006608
 96%|███████████████████████████▉ | 386/400 [2:46:13<06:45, 28.97s/it]2022-01-16 02:25:26,643 iteration 6563 : loss : 0.016225, loss_ce: 0.007236
2022-01-16 02:25:28,171 iteration 6564 : loss : 0.025406, loss_ce: 0.008326
2022-01-16 02:25:29,573 iteration 6565 : loss : 0.014170, loss_ce: 0.003862
2022-01-16 02:25:31,087 iteration 6566 : loss : 0.024368, loss_ce: 0.010481
2022-01-16 02:25:32,567 iteration 6567 : loss : 0.022592, loss_ce: 0.007176
2022-01-16 02:25:34,053 iteration 6568 : loss : 0.011704, loss_ce: 0.004394
2022-01-16 02:25:35,482 iteration 6569 : loss : 0.014162, loss_ce: 0.004388
2022-01-16 02:25:36,997 iteration 6570 : loss : 0.015861, loss_ce: 0.006396
2022-01-16 02:25:38,389 iteration 6571 : loss : 0.011406, loss_ce: 0.004700
2022-01-16 02:25:39,853 iteration 6572 : loss : 0.015234, loss_ce: 0.004633
2022-01-16 02:25:41,311 iteration 6573 : loss : 0.010950, loss_ce: 0.003347
2022-01-16 02:25:42,804 iteration 6574 : loss : 0.013696, loss_ce: 0.005327
2022-01-16 02:25:44,180 iteration 6575 : loss : 0.009730, loss_ce: 0.003947
2022-01-16 02:25:45,631 iteration 6576 : loss : 0.022257, loss_ce: 0.009870
2022-01-16 02:25:47,081 iteration 6577 : loss : 0.014582, loss_ce: 0.005065
2022-01-16 02:25:48,500 iteration 6578 : loss : 0.013721, loss_ce: 0.005729
2022-01-16 02:25:49,901 iteration 6579 : loss : 0.012008, loss_ce: 0.002837
 97%|████████████████████████████ | 387/400 [2:46:38<06:00, 27.73s/it]2022-01-16 02:25:51,423 iteration 6580 : loss : 0.013562, loss_ce: 0.004869
2022-01-16 02:25:52,963 iteration 6581 : loss : 0.017016, loss_ce: 0.005230
2022-01-16 02:25:54,534 iteration 6582 : loss : 0.013218, loss_ce: 0.006150
2022-01-16 02:25:56,057 iteration 6583 : loss : 0.010515, loss_ce: 0.004060
2022-01-16 02:25:57,656 iteration 6584 : loss : 0.015423, loss_ce: 0.005676
2022-01-16 02:25:59,291 iteration 6585 : loss : 0.012034, loss_ce: 0.004026
2022-01-16 02:26:00,878 iteration 6586 : loss : 0.012730, loss_ce: 0.004919
2022-01-16 02:26:02,405 iteration 6587 : loss : 0.012101, loss_ce: 0.004971
2022-01-16 02:26:04,063 iteration 6588 : loss : 0.018083, loss_ce: 0.008071
2022-01-16 02:26:05,639 iteration 6589 : loss : 0.015258, loss_ce: 0.005115
2022-01-16 02:26:07,279 iteration 6590 : loss : 0.013853, loss_ce: 0.005846
2022-01-16 02:26:08,811 iteration 6591 : loss : 0.023421, loss_ce: 0.010767
2022-01-16 02:26:10,400 iteration 6592 : loss : 0.018563, loss_ce: 0.005196
2022-01-16 02:26:12,085 iteration 6593 : loss : 0.018194, loss_ce: 0.008063
2022-01-16 02:26:13,767 iteration 6594 : loss : 0.012018, loss_ce: 0.004267
2022-01-16 02:26:15,288 iteration 6595 : loss : 0.012272, loss_ce: 0.003936
2022-01-16 02:26:16,807 iteration 6596 : loss : 0.008370, loss_ce: 0.003200
 97%|████████████████████████████▏| 388/400 [2:47:05<05:29, 27.49s/it]2022-01-16 02:26:18,437 iteration 6597 : loss : 0.022422, loss_ce: 0.009961
2022-01-16 02:26:20,144 iteration 6598 : loss : 0.013974, loss_ce: 0.003607
2022-01-16 02:26:21,749 iteration 6599 : loss : 0.013717, loss_ce: 0.004975
2022-01-16 02:26:23,314 iteration 6600 : loss : 0.013308, loss_ce: 0.004674
2022-01-16 02:26:24,772 iteration 6601 : loss : 0.012188, loss_ce: 0.005011
2022-01-16 02:26:26,202 iteration 6602 : loss : 0.008842, loss_ce: 0.002994
2022-01-16 02:26:27,741 iteration 6603 : loss : 0.024760, loss_ce: 0.007779
2022-01-16 02:26:29,326 iteration 6604 : loss : 0.016565, loss_ce: 0.006511
2022-01-16 02:26:30,812 iteration 6605 : loss : 0.017355, loss_ce: 0.007580
2022-01-16 02:26:32,261 iteration 6606 : loss : 0.014170, loss_ce: 0.007554
2022-01-16 02:26:33,680 iteration 6607 : loss : 0.015010, loss_ce: 0.005120
2022-01-16 02:26:35,204 iteration 6608 : loss : 0.015011, loss_ce: 0.005087
2022-01-16 02:26:36,786 iteration 6609 : loss : 0.019607, loss_ce: 0.010176
2022-01-16 02:26:38,290 iteration 6610 : loss : 0.020878, loss_ce: 0.007513
2022-01-16 02:26:39,862 iteration 6611 : loss : 0.011939, loss_ce: 0.005026
2022-01-16 02:26:41,437 iteration 6612 : loss : 0.014490, loss_ce: 0.005712
2022-01-16 02:26:43,056 iteration 6613 : loss : 0.016262, loss_ce: 0.004889
 97%|████████████████████████████▏| 389/400 [2:47:31<04:58, 27.12s/it]2022-01-16 02:26:44,741 iteration 6614 : loss : 0.009134, loss_ce: 0.003606
2022-01-16 02:26:46,293 iteration 6615 : loss : 0.018532, loss_ce: 0.006859
2022-01-16 02:26:47,968 iteration 6616 : loss : 0.012883, loss_ce: 0.005120
2022-01-16 02:26:49,592 iteration 6617 : loss : 0.015584, loss_ce: 0.002753
2022-01-16 02:26:51,174 iteration 6618 : loss : 0.014203, loss_ce: 0.004947
2022-01-16 02:26:52,814 iteration 6619 : loss : 0.012347, loss_ce: 0.004298
2022-01-16 02:26:54,402 iteration 6620 : loss : 0.015330, loss_ce: 0.005309
2022-01-16 02:26:56,008 iteration 6621 : loss : 0.012930, loss_ce: 0.005962
2022-01-16 02:26:57,563 iteration 6622 : loss : 0.010475, loss_ce: 0.003357
2022-01-16 02:26:59,119 iteration 6623 : loss : 0.013954, loss_ce: 0.007361
2022-01-16 02:27:00,697 iteration 6624 : loss : 0.011426, loss_ce: 0.004139
2022-01-16 02:27:02,152 iteration 6625 : loss : 0.009243, loss_ce: 0.003731
2022-01-16 02:27:03,696 iteration 6626 : loss : 0.017262, loss_ce: 0.006475
2022-01-16 02:27:05,164 iteration 6627 : loss : 0.009429, loss_ce: 0.003167
2022-01-16 02:27:06,675 iteration 6628 : loss : 0.014381, loss_ce: 0.004933
2022-01-16 02:27:08,066 iteration 6629 : loss : 0.010906, loss_ce: 0.004667
2022-01-16 02:27:08,066 Training Data Eval:
2022-01-16 02:27:15,014   Average segmentation loss on training set: 0.0075
2022-01-16 02:27:15,015 Validation Data Eval:
2022-01-16 02:27:17,395   Average segmentation loss on validation set: 0.0749
2022-01-16 02:27:18,785 iteration 6630 : loss : 0.015776, loss_ce: 0.005788
 98%|████████████████████████████▎| 390/400 [2:48:07<04:56, 29.70s/it]2022-01-16 02:27:20,141 iteration 6631 : loss : 0.010943, loss_ce: 0.004188
2022-01-16 02:27:21,548 iteration 6632 : loss : 0.019518, loss_ce: 0.004139
2022-01-16 02:27:22,943 iteration 6633 : loss : 0.012012, loss_ce: 0.004648
2022-01-16 02:27:24,331 iteration 6634 : loss : 0.012014, loss_ce: 0.004835
2022-01-16 02:27:25,835 iteration 6635 : loss : 0.010975, loss_ce: 0.004378
2022-01-16 02:27:27,298 iteration 6636 : loss : 0.010565, loss_ce: 0.005241
2022-01-16 02:27:28,807 iteration 6637 : loss : 0.018112, loss_ce: 0.006164
2022-01-16 02:27:30,276 iteration 6638 : loss : 0.009216, loss_ce: 0.002703
2022-01-16 02:27:31,727 iteration 6639 : loss : 0.016459, loss_ce: 0.005736
2022-01-16 02:27:33,216 iteration 6640 : loss : 0.021243, loss_ce: 0.005079
2022-01-16 02:27:34,750 iteration 6641 : loss : 0.021959, loss_ce: 0.010341
2022-01-16 02:27:36,313 iteration 6642 : loss : 0.011954, loss_ce: 0.003585
2022-01-16 02:27:37,885 iteration 6643 : loss : 0.014535, loss_ce: 0.007246
2022-01-16 02:27:39,471 iteration 6644 : loss : 0.021025, loss_ce: 0.010779
2022-01-16 02:27:40,957 iteration 6645 : loss : 0.022999, loss_ce: 0.009095
2022-01-16 02:27:42,463 iteration 6646 : loss : 0.012764, loss_ce: 0.006035
2022-01-16 02:27:43,995 iteration 6647 : loss : 0.014029, loss_ce: 0.002709
 98%|████████████████████████████▎| 391/400 [2:48:32<04:15, 28.35s/it]2022-01-16 02:27:45,569 iteration 6648 : loss : 0.011836, loss_ce: 0.004622
2022-01-16 02:27:47,042 iteration 6649 : loss : 0.020785, loss_ce: 0.005831
2022-01-16 02:27:48,417 iteration 6650 : loss : 0.011385, loss_ce: 0.004240
2022-01-16 02:27:49,873 iteration 6651 : loss : 0.012275, loss_ce: 0.005257
2022-01-16 02:27:51,366 iteration 6652 : loss : 0.014182, loss_ce: 0.007215
2022-01-16 02:27:52,879 iteration 6653 : loss : 0.015602, loss_ce: 0.004992
2022-01-16 02:27:54,434 iteration 6654 : loss : 0.015505, loss_ce: 0.004727
2022-01-16 02:27:55,814 iteration 6655 : loss : 0.014703, loss_ce: 0.006618
2022-01-16 02:27:57,223 iteration 6656 : loss : 0.019459, loss_ce: 0.007114
2022-01-16 02:27:58,505 iteration 6657 : loss : 0.017130, loss_ce: 0.005369
2022-01-16 02:27:59,770 iteration 6658 : loss : 0.015898, loss_ce: 0.006047
2022-01-16 02:28:00,973 iteration 6659 : loss : 0.024640, loss_ce: 0.006654
2022-01-16 02:28:02,139 iteration 6660 : loss : 0.010933, loss_ce: 0.004645
2022-01-16 02:28:03,249 iteration 6661 : loss : 0.011957, loss_ce: 0.004717
2022-01-16 02:28:04,424 iteration 6662 : loss : 0.017471, loss_ce: 0.006659
2022-01-16 02:28:05,507 iteration 6663 : loss : 0.010327, loss_ce: 0.004300
2022-01-16 02:28:06,645 iteration 6664 : loss : 0.011652, loss_ce: 0.006006
 98%|████████████████████████████▍| 392/400 [2:48:54<03:33, 26.64s/it]2022-01-16 02:28:07,822 iteration 6665 : loss : 0.022948, loss_ce: 0.008296
2022-01-16 02:28:08,948 iteration 6666 : loss : 0.011000, loss_ce: 0.003385
2022-01-16 02:28:10,046 iteration 6667 : loss : 0.013361, loss_ce: 0.005152
2022-01-16 02:28:11,273 iteration 6668 : loss : 0.018959, loss_ce: 0.009397
2022-01-16 02:28:12,328 iteration 6669 : loss : 0.013035, loss_ce: 0.005082
2022-01-16 02:28:13,416 iteration 6670 : loss : 0.010041, loss_ce: 0.003983
2022-01-16 02:28:14,558 iteration 6671 : loss : 0.015069, loss_ce: 0.006090
2022-01-16 02:28:15,668 iteration 6672 : loss : 0.013554, loss_ce: 0.003605
2022-01-16 02:28:16,917 iteration 6673 : loss : 0.020854, loss_ce: 0.007752
2022-01-16 02:28:18,138 iteration 6674 : loss : 0.014633, loss_ce: 0.006224
2022-01-16 02:28:19,417 iteration 6675 : loss : 0.015225, loss_ce: 0.004439
2022-01-16 02:28:20,651 iteration 6676 : loss : 0.009418, loss_ce: 0.002798
2022-01-16 02:28:21,965 iteration 6677 : loss : 0.011330, loss_ce: 0.003271
2022-01-16 02:28:23,255 iteration 6678 : loss : 0.009425, loss_ce: 0.003947
2022-01-16 02:28:24,759 iteration 6679 : loss : 0.014833, loss_ce: 0.007002
2022-01-16 02:28:26,176 iteration 6680 : loss : 0.016778, loss_ce: 0.005809
2022-01-16 02:28:27,707 iteration 6681 : loss : 0.014495, loss_ce: 0.005999
 98%|████████████████████████████▍| 393/400 [2:49:16<02:54, 24.97s/it]2022-01-16 02:28:29,226 iteration 6682 : loss : 0.011340, loss_ce: 0.005433
2022-01-16 02:28:30,796 iteration 6683 : loss : 0.013185, loss_ce: 0.004623
2022-01-16 02:28:32,299 iteration 6684 : loss : 0.013082, loss_ce: 0.004107
2022-01-16 02:28:33,938 iteration 6685 : loss : 0.017440, loss_ce: 0.008025
2022-01-16 02:28:35,413 iteration 6686 : loss : 0.011347, loss_ce: 0.004958
2022-01-16 02:28:37,059 iteration 6687 : loss : 0.016976, loss_ce: 0.004774
2022-01-16 02:28:38,763 iteration 6688 : loss : 0.013921, loss_ce: 0.004819
2022-01-16 02:28:40,332 iteration 6689 : loss : 0.014914, loss_ce: 0.006115
2022-01-16 02:28:41,845 iteration 6690 : loss : 0.013769, loss_ce: 0.005775
2022-01-16 02:28:43,400 iteration 6691 : loss : 0.024600, loss_ce: 0.009374
2022-01-16 02:28:44,895 iteration 6692 : loss : 0.021103, loss_ce: 0.005950
2022-01-16 02:28:46,430 iteration 6693 : loss : 0.012692, loss_ce: 0.003754
2022-01-16 02:28:47,955 iteration 6694 : loss : 0.016082, loss_ce: 0.005777
2022-01-16 02:28:49,509 iteration 6695 : loss : 0.015485, loss_ce: 0.006428
2022-01-16 02:28:50,969 iteration 6696 : loss : 0.013068, loss_ce: 0.006492
2022-01-16 02:28:52,508 iteration 6697 : loss : 0.018396, loss_ce: 0.006669
2022-01-16 02:28:53,950 iteration 6698 : loss : 0.013961, loss_ce: 0.004736
 98%|████████████████████████████▌| 394/400 [2:49:42<02:32, 25.35s/it]2022-01-16 02:28:55,373 iteration 6699 : loss : 0.017833, loss_ce: 0.009330
2022-01-16 02:28:56,835 iteration 6700 : loss : 0.017529, loss_ce: 0.007468
2022-01-16 02:28:58,213 iteration 6701 : loss : 0.013196, loss_ce: 0.006732
2022-01-16 02:28:59,554 iteration 6702 : loss : 0.022933, loss_ce: 0.007487
2022-01-16 02:29:00,953 iteration 6703 : loss : 0.016437, loss_ce: 0.004938
2022-01-16 02:29:02,427 iteration 6704 : loss : 0.014378, loss_ce: 0.004721
2022-01-16 02:29:03,823 iteration 6705 : loss : 0.013926, loss_ce: 0.004513
2022-01-16 02:29:05,282 iteration 6706 : loss : 0.010095, loss_ce: 0.004769
2022-01-16 02:29:06,756 iteration 6707 : loss : 0.016096, loss_ce: 0.004527
2022-01-16 02:29:08,251 iteration 6708 : loss : 0.011130, loss_ce: 0.003734
2022-01-16 02:29:09,789 iteration 6709 : loss : 0.011117, loss_ce: 0.004027
2022-01-16 02:29:11,321 iteration 6710 : loss : 0.012850, loss_ce: 0.004483
2022-01-16 02:29:12,862 iteration 6711 : loss : 0.015839, loss_ce: 0.002842
2022-01-16 02:29:14,458 iteration 6712 : loss : 0.014750, loss_ce: 0.006381
2022-01-16 02:29:16,111 iteration 6713 : loss : 0.018288, loss_ce: 0.006797
2022-01-16 02:29:17,704 iteration 6714 : loss : 0.013038, loss_ce: 0.005782
2022-01-16 02:29:17,704 Training Data Eval:
2022-01-16 02:29:25,442   Average segmentation loss on training set: 0.0073
2022-01-16 02:29:25,442 Validation Data Eval:
2022-01-16 02:29:28,217   Average segmentation loss on validation set: 0.0767
2022-01-16 02:29:29,787 iteration 6715 : loss : 0.013660, loss_ce: 0.005218
 99%|████████████████████████████▋| 395/400 [2:50:18<02:22, 28.50s/it]2022-01-16 02:29:31,347 iteration 6716 : loss : 0.010197, loss_ce: 0.004003
2022-01-16 02:29:32,817 iteration 6717 : loss : 0.015560, loss_ce: 0.005972
2022-01-16 02:29:34,227 iteration 6718 : loss : 0.012486, loss_ce: 0.004163
2022-01-16 02:29:35,831 iteration 6719 : loss : 0.012956, loss_ce: 0.004121
2022-01-16 02:29:37,354 iteration 6720 : loss : 0.012041, loss_ce: 0.004402
2022-01-16 02:29:38,935 iteration 6721 : loss : 0.018029, loss_ce: 0.006709
2022-01-16 02:29:40,546 iteration 6722 : loss : 0.022817, loss_ce: 0.006313
2022-01-16 02:29:42,065 iteration 6723 : loss : 0.018708, loss_ce: 0.006413
2022-01-16 02:29:43,540 iteration 6724 : loss : 0.014225, loss_ce: 0.006967
2022-01-16 02:29:45,042 iteration 6725 : loss : 0.013336, loss_ce: 0.005344
2022-01-16 02:29:46,539 iteration 6726 : loss : 0.022504, loss_ce: 0.008498
2022-01-16 02:29:48,060 iteration 6727 : loss : 0.014124, loss_ce: 0.006411
2022-01-16 02:29:49,604 iteration 6728 : loss : 0.013637, loss_ce: 0.005817
2022-01-16 02:29:51,076 iteration 6729 : loss : 0.010540, loss_ce: 0.003480
2022-01-16 02:29:52,552 iteration 6730 : loss : 0.013582, loss_ce: 0.004723
2022-01-16 02:29:53,979 iteration 6731 : loss : 0.010366, loss_ce: 0.004414
2022-01-16 02:29:55,385 iteration 6732 : loss : 0.012105, loss_ce: 0.005741
 99%|████████████████████████████▋| 396/400 [2:50:43<01:50, 27.62s/it]2022-01-16 02:29:56,848 iteration 6733 : loss : 0.018272, loss_ce: 0.009879
2022-01-16 02:29:58,147 iteration 6734 : loss : 0.007860, loss_ce: 0.002374
2022-01-16 02:29:59,515 iteration 6735 : loss : 0.014048, loss_ce: 0.006965
2022-01-16 02:30:00,875 iteration 6736 : loss : 0.011292, loss_ce: 0.003179
2022-01-16 02:30:02,204 iteration 6737 : loss : 0.010001, loss_ce: 0.004280
2022-01-16 02:30:03,546 iteration 6738 : loss : 0.009567, loss_ce: 0.003245
2022-01-16 02:30:04,946 iteration 6739 : loss : 0.016389, loss_ce: 0.006533
2022-01-16 02:30:06,407 iteration 6740 : loss : 0.014257, loss_ce: 0.004976
2022-01-16 02:30:07,722 iteration 6741 : loss : 0.010924, loss_ce: 0.004911
2022-01-16 02:30:09,133 iteration 6742 : loss : 0.016924, loss_ce: 0.008875
2022-01-16 02:30:10,521 iteration 6743 : loss : 0.017944, loss_ce: 0.005535
2022-01-16 02:30:11,931 iteration 6744 : loss : 0.012475, loss_ce: 0.005120
2022-01-16 02:30:13,248 iteration 6745 : loss : 0.016861, loss_ce: 0.004951
2022-01-16 02:30:14,613 iteration 6746 : loss : 0.015589, loss_ce: 0.006173
2022-01-16 02:30:16,039 iteration 6747 : loss : 0.017959, loss_ce: 0.005824
2022-01-16 02:30:17,476 iteration 6748 : loss : 0.012559, loss_ce: 0.004814
2022-01-16 02:30:18,955 iteration 6749 : loss : 0.017608, loss_ce: 0.005778
 99%|████████████████████████████▊| 397/400 [2:51:07<01:19, 26.41s/it]2022-01-16 02:30:20,501 iteration 6750 : loss : 0.013127, loss_ce: 0.005135
2022-01-16 02:30:22,098 iteration 6751 : loss : 0.017762, loss_ce: 0.008655
2022-01-16 02:30:23,742 iteration 6752 : loss : 0.016535, loss_ce: 0.008334
2022-01-16 02:30:25,283 iteration 6753 : loss : 0.013764, loss_ce: 0.006322
2022-01-16 02:30:26,823 iteration 6754 : loss : 0.018495, loss_ce: 0.005647
2022-01-16 02:30:28,290 iteration 6755 : loss : 0.008189, loss_ce: 0.002365
2022-01-16 02:30:29,789 iteration 6756 : loss : 0.015256, loss_ce: 0.006581
2022-01-16 02:30:31,290 iteration 6757 : loss : 0.015437, loss_ce: 0.007198
2022-01-16 02:30:32,711 iteration 6758 : loss : 0.008954, loss_ce: 0.003752
2022-01-16 02:30:34,238 iteration 6759 : loss : 0.014543, loss_ce: 0.005799
2022-01-16 02:30:35,735 iteration 6760 : loss : 0.014706, loss_ce: 0.006682
2022-01-16 02:30:37,348 iteration 6761 : loss : 0.014535, loss_ce: 0.005967
2022-01-16 02:30:38,857 iteration 6762 : loss : 0.009458, loss_ce: 0.003395
2022-01-16 02:30:40,433 iteration 6763 : loss : 0.017731, loss_ce: 0.005248
2022-01-16 02:30:41,995 iteration 6764 : loss : 0.012520, loss_ce: 0.004371
2022-01-16 02:30:43,558 iteration 6765 : loss : 0.010994, loss_ce: 0.003527
2022-01-16 02:30:45,096 iteration 6766 : loss : 0.014092, loss_ce: 0.005410
100%|████████████████████████████▊| 398/400 [2:51:33<00:52, 26.33s/it]2022-01-16 02:30:46,932 iteration 6767 : loss : 0.012852, loss_ce: 0.004366
2022-01-16 02:30:48,413 iteration 6768 : loss : 0.012568, loss_ce: 0.005540
2022-01-16 02:30:49,925 iteration 6769 : loss : 0.014217, loss_ce: 0.003926
2022-01-16 02:30:51,393 iteration 6770 : loss : 0.009781, loss_ce: 0.003891
2022-01-16 02:30:52,961 iteration 6771 : loss : 0.018862, loss_ce: 0.005644
2022-01-16 02:30:54,534 iteration 6772 : loss : 0.021071, loss_ce: 0.005766
2022-01-16 02:30:56,024 iteration 6773 : loss : 0.013153, loss_ce: 0.005467
2022-01-16 02:30:57,478 iteration 6774 : loss : 0.017232, loss_ce: 0.007044
2022-01-16 02:30:58,887 iteration 6775 : loss : 0.012919, loss_ce: 0.004301
2022-01-16 02:31:00,369 iteration 6776 : loss : 0.021236, loss_ce: 0.008673
2022-01-16 02:31:01,864 iteration 6777 : loss : 0.011604, loss_ce: 0.004368
2022-01-16 02:31:03,336 iteration 6778 : loss : 0.011935, loss_ce: 0.003769
2022-01-16 02:31:04,899 iteration 6779 : loss : 0.010968, loss_ce: 0.003423
2022-01-16 02:31:06,390 iteration 6780 : loss : 0.010109, loss_ce: 0.003446
2022-01-16 02:31:07,865 iteration 6781 : loss : 0.014502, loss_ce: 0.008045
2022-01-16 02:31:09,370 iteration 6782 : loss : 0.009053, loss_ce: 0.003818
2022-01-16 02:31:10,942 iteration 6783 : loss : 0.011188, loss_ce: 0.004724
100%|████████████████████████████▉| 399/400 [2:51:59<00:26, 26.18s/it]2022-01-16 02:31:12,600 iteration 6784 : loss : 0.023327, loss_ce: 0.007175
2022-01-16 02:31:14,070 iteration 6785 : loss : 0.014537, loss_ce: 0.006505
2022-01-16 02:31:15,566 iteration 6786 : loss : 0.009841, loss_ce: 0.004143
2022-01-16 02:31:17,184 iteration 6787 : loss : 0.012615, loss_ce: 0.004186
2022-01-16 02:31:18,785 iteration 6788 : loss : 0.021789, loss_ce: 0.005273
2022-01-16 02:31:20,355 iteration 6789 : loss : 0.012077, loss_ce: 0.004729
2022-01-16 02:31:21,950 iteration 6790 : loss : 0.012864, loss_ce: 0.003908
2022-01-16 02:31:23,582 iteration 6791 : loss : 0.052292, loss_ce: 0.016586
2022-01-16 02:31:25,213 iteration 6792 : loss : 0.012140, loss_ce: 0.004709
2022-01-16 02:31:26,801 iteration 6793 : loss : 0.015833, loss_ce: 0.004758
2022-01-16 02:31:28,396 iteration 6794 : loss : 0.014422, loss_ce: 0.005245
2022-01-16 02:31:30,095 iteration 6795 : loss : 0.017190, loss_ce: 0.007447
2022-01-16 02:31:31,621 iteration 6796 : loss : 0.013345, loss_ce: 0.004545
2022-01-16 02:31:33,221 iteration 6797 : loss : 0.011830, loss_ce: 0.004852
2022-01-16 02:31:34,710 iteration 6798 : loss : 0.012934, loss_ce: 0.004551
2022-01-16 02:31:36,255 iteration 6799 : loss : 0.017020, loss_ce: 0.008352
2022-01-16 02:31:36,256 Training Data Eval:
2022-01-16 02:31:44,434   Average segmentation loss on training set: 0.0074
2022-01-16 02:31:44,435 Validation Data Eval:
2022-01-16 02:31:47,363   Average segmentation loss on validation set: 0.0757
2022-01-16 02:31:48,905 iteration 6800 : loss : 0.014187, loss_ce: 0.006873
100%|█████████████████████████████| 400/400 [2:52:37<00:00, 29.72s/it]100%|█████████████████████████████| 400/400 [2:52:37<00:00, 25.89s/it]
