2022-01-13 19:34:28,093 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-13 19:34:28,094 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-13 19:34:28,094 ============================================================
2022-01-13 19:34:28,094 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-13 19:34:28,094 ============================================================
2022-01-13 19:34:28,094 Loading data...
2022-01-13 19:34:28,094 Reading NCI - RUNMC images...
2022-01-13 19:34:28,094 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-13 19:34:28,121 Already preprocessed this configuration. Loading now!
2022-01-13 19:34:28,179 Training Images: (256, 256, 286)
2022-01-13 19:34:28,180 Training Labels: (256, 256, 286)
2022-01-13 19:34:28,180 Validation Images: (256, 256, 98)
2022-01-13 19:34:28,180 Validation Labels: (256, 256, 98)
2022-01-13 19:34:28,180 ============================================================
2022-01-13 19:34:28,304 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-13 19:34:32,207 iteration 1 : loss : 0.985132, loss_ce: 1.214253
2022-01-13 19:34:33,542 iteration 2 : loss : 0.918935, loss_ce: 1.109898
2022-01-13 19:34:34,975 iteration 3 : loss : 0.865049, loss_ce: 1.013973
2022-01-13 19:34:36,311 iteration 4 : loss : 0.808514, loss_ce: 0.920246
2022-01-13 19:34:37,667 iteration 5 : loss : 0.759664, loss_ce: 0.852358
2022-01-13 19:34:39,082 iteration 6 : loss : 0.731910, loss_ce: 0.792243
2022-01-13 19:34:40,505 iteration 7 : loss : 0.686552, loss_ce: 0.728927
2022-01-13 19:34:41,869 iteration 8 : loss : 0.670711, loss_ce: 0.675243
2022-01-13 19:34:43,264 iteration 9 : loss : 0.608848, loss_ce: 0.638157
2022-01-13 19:34:44,668 iteration 10 : loss : 0.608298, loss_ce: 0.576531
2022-01-13 19:34:46,155 iteration 11 : loss : 0.568541, loss_ce: 0.546069
2022-01-13 19:34:47,504 iteration 12 : loss : 0.543359, loss_ce: 0.495107
2022-01-13 19:34:48,838 iteration 13 : loss : 0.539151, loss_ce: 0.471937
2022-01-13 19:34:50,161 iteration 14 : loss : 0.504765, loss_ce: 0.434654
2022-01-13 19:34:51,555 iteration 15 : loss : 0.473762, loss_ce: 0.397471
2022-01-13 19:34:52,909 iteration 16 : loss : 0.483611, loss_ce: 0.385496
2022-01-13 19:34:54,274 iteration 17 : loss : 0.427917, loss_ce: 0.348775
  0%|                               | 1/400 [00:26<2:53:33, 26.10s/it]2022-01-13 19:34:55,783 iteration 18 : loss : 0.448650, loss_ce: 0.313245
2022-01-13 19:34:57,083 iteration 19 : loss : 0.388862, loss_ce: 0.276846
2022-01-13 19:34:58,499 iteration 20 : loss : 0.376473, loss_ce: 0.256140
2022-01-13 19:34:59,831 iteration 21 : loss : 0.388925, loss_ce: 0.238475
2022-01-13 19:35:01,181 iteration 22 : loss : 0.361276, loss_ce: 0.235002
2022-01-13 19:35:02,612 iteration 23 : loss : 0.346209, loss_ce: 0.204392
2022-01-13 19:35:03,965 iteration 24 : loss : 0.327598, loss_ce: 0.199410
2022-01-13 19:35:05,371 iteration 25 : loss : 0.366434, loss_ce: 0.235849
2022-01-13 19:35:06,713 iteration 26 : loss : 0.308722, loss_ce: 0.176002
2022-01-13 19:35:07,999 iteration 27 : loss : 0.309031, loss_ce: 0.178049
2022-01-13 19:35:09,303 iteration 28 : loss : 0.288412, loss_ce: 0.156634
2022-01-13 19:35:10,695 iteration 29 : loss : 0.286747, loss_ce: 0.148871
2022-01-13 19:35:12,077 iteration 30 : loss : 0.270507, loss_ce: 0.139779
2022-01-13 19:35:13,377 iteration 31 : loss : 0.285091, loss_ce: 0.151030
2022-01-13 19:35:14,789 iteration 32 : loss : 0.300222, loss_ce: 0.170196
2022-01-13 19:35:16,180 iteration 33 : loss : 0.292931, loss_ce: 0.167106
2022-01-13 19:35:17,573 iteration 34 : loss : 0.289863, loss_ce: 0.172007
  0%|▏                              | 2/400 [00:49<2:41:56, 24.41s/it]2022-01-13 19:35:19,035 iteration 35 : loss : 0.260936, loss_ce: 0.132578
2022-01-13 19:35:20,441 iteration 36 : loss : 0.265670, loss_ce: 0.140120
2022-01-13 19:35:21,857 iteration 37 : loss : 0.285120, loss_ce: 0.117613
2022-01-13 19:35:23,195 iteration 38 : loss : 0.263436, loss_ce: 0.134722
2022-01-13 19:35:24,542 iteration 39 : loss : 0.222811, loss_ce: 0.104709
2022-01-13 19:35:25,957 iteration 40 : loss : 0.275614, loss_ce: 0.138931
2022-01-13 19:35:27,365 iteration 41 : loss : 0.318556, loss_ce: 0.157844
2022-01-13 19:35:28,749 iteration 42 : loss : 0.253924, loss_ce: 0.128854
2022-01-13 19:35:30,050 iteration 43 : loss : 0.262249, loss_ce: 0.123272
2022-01-13 19:35:31,480 iteration 44 : loss : 0.247637, loss_ce: 0.116746
2022-01-13 19:35:32,848 iteration 45 : loss : 0.220843, loss_ce: 0.097624
2022-01-13 19:35:34,236 iteration 46 : loss : 0.248230, loss_ce: 0.100728
2022-01-13 19:35:35,649 iteration 47 : loss : 0.216625, loss_ce: 0.087317
2022-01-13 19:35:37,076 iteration 48 : loss : 0.209254, loss_ce: 0.091621
2022-01-13 19:35:38,508 iteration 49 : loss : 0.277948, loss_ce: 0.135631
2022-01-13 19:35:39,838 iteration 50 : loss : 0.301666, loss_ce: 0.139834
2022-01-13 19:35:41,151 iteration 51 : loss : 0.290872, loss_ce: 0.140747
  1%|▏                              | 3/400 [01:12<2:38:59, 24.03s/it]2022-01-13 19:35:42,623 iteration 52 : loss : 0.307525, loss_ce: 0.158572
2022-01-13 19:35:44,027 iteration 53 : loss : 0.255006, loss_ce: 0.117618
2022-01-13 19:35:45,398 iteration 54 : loss : 0.258969, loss_ce: 0.110575
2022-01-13 19:35:46,783 iteration 55 : loss : 0.311473, loss_ce: 0.156920
2022-01-13 19:35:48,152 iteration 56 : loss : 0.270739, loss_ce: 0.116762
2022-01-13 19:35:49,545 iteration 57 : loss : 0.226202, loss_ce: 0.093299
2022-01-13 19:35:50,935 iteration 58 : loss : 0.321903, loss_ce: 0.132318
2022-01-13 19:35:52,295 iteration 59 : loss : 0.242053, loss_ce: 0.109598
2022-01-13 19:35:53,682 iteration 60 : loss : 0.299544, loss_ce: 0.127428
2022-01-13 19:35:55,058 iteration 61 : loss : 0.266314, loss_ce: 0.130730
2022-01-13 19:35:56,422 iteration 62 : loss : 0.329214, loss_ce: 0.131715
2022-01-13 19:35:57,721 iteration 63 : loss : 0.302433, loss_ce: 0.152108
2022-01-13 19:35:59,070 iteration 64 : loss : 0.326409, loss_ce: 0.153599
2022-01-13 19:36:00,380 iteration 65 : loss : 0.263718, loss_ce: 0.110014
2022-01-13 19:36:01,720 iteration 66 : loss : 0.237460, loss_ce: 0.107133
2022-01-13 19:36:03,141 iteration 67 : loss : 0.262421, loss_ce: 0.097123
2022-01-13 19:36:04,501 iteration 68 : loss : 0.251569, loss_ce: 0.110506
  1%|▎                              | 4/400 [01:36<2:36:48, 23.76s/it]2022-01-13 19:36:05,952 iteration 69 : loss : 0.229054, loss_ce: 0.093492
2022-01-13 19:36:07,401 iteration 70 : loss : 0.243546, loss_ce: 0.104048
2022-01-13 19:36:08,739 iteration 71 : loss : 0.233004, loss_ce: 0.097611
2022-01-13 19:36:10,122 iteration 72 : loss : 0.217497, loss_ce: 0.089626
2022-01-13 19:36:11,452 iteration 73 : loss : 0.246372, loss_ce: 0.116078
2022-01-13 19:36:12,752 iteration 74 : loss : 0.225931, loss_ce: 0.092089
2022-01-13 19:36:14,084 iteration 75 : loss : 0.224177, loss_ce: 0.095786
2022-01-13 19:36:15,406 iteration 76 : loss : 0.240273, loss_ce: 0.099122
2022-01-13 19:36:16,655 iteration 77 : loss : 0.234063, loss_ce: 0.103858
2022-01-13 19:36:18,003 iteration 78 : loss : 0.269217, loss_ce: 0.119277
2022-01-13 19:36:19,327 iteration 79 : loss : 0.263506, loss_ce: 0.096137
2022-01-13 19:36:20,639 iteration 80 : loss : 0.254716, loss_ce: 0.111841
2022-01-13 19:36:21,941 iteration 81 : loss : 0.242350, loss_ce: 0.100878
2022-01-13 19:36:23,263 iteration 82 : loss : 0.250729, loss_ce: 0.096810
2022-01-13 19:36:24,581 iteration 83 : loss : 0.261059, loss_ce: 0.098492
2022-01-13 19:36:25,990 iteration 84 : loss : 0.252260, loss_ce: 0.136145
2022-01-13 19:36:25,990 Training Data Eval:
2022-01-13 19:36:32,732   Average segmentation loss on training set: 0.7988
2022-01-13 19:36:32,732 Validation Data Eval:
2022-01-13 19:36:35,407   Average segmentation loss on validation set: 0.7958
2022-01-13 19:36:41,815 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 19:36:43,204 iteration 85 : loss : 0.283442, loss_ce: 0.124681
  1%|▍                              | 5/400 [02:14<3:11:52, 29.15s/it]2022-01-13 19:36:44,619 iteration 86 : loss : 0.291466, loss_ce: 0.110250
2022-01-13 19:36:46,090 iteration 87 : loss : 0.217850, loss_ce: 0.092881
2022-01-13 19:36:47,399 iteration 88 : loss : 0.239038, loss_ce: 0.104986
2022-01-13 19:36:48,783 iteration 89 : loss : 0.316326, loss_ce: 0.130549
2022-01-13 19:36:50,160 iteration 90 : loss : 0.233488, loss_ce: 0.092488
2022-01-13 19:36:51,593 iteration 91 : loss : 0.237818, loss_ce: 0.114706
2022-01-13 19:36:52,892 iteration 92 : loss : 0.235275, loss_ce: 0.100842
2022-01-13 19:36:54,234 iteration 93 : loss : 0.247303, loss_ce: 0.095930
2022-01-13 19:36:55,582 iteration 94 : loss : 0.251470, loss_ce: 0.103448
2022-01-13 19:36:57,056 iteration 95 : loss : 0.239176, loss_ce: 0.112036
2022-01-13 19:36:58,386 iteration 96 : loss : 0.250225, loss_ce: 0.111046
2022-01-13 19:36:59,721 iteration 97 : loss : 0.262968, loss_ce: 0.107553
2022-01-13 19:37:01,073 iteration 98 : loss : 0.263275, loss_ce: 0.110668
2022-01-13 19:37:02,503 iteration 99 : loss : 0.224487, loss_ce: 0.090937
2022-01-13 19:37:03,886 iteration 100 : loss : 0.241379, loss_ce: 0.102248
2022-01-13 19:37:05,245 iteration 101 : loss : 0.178187, loss_ce: 0.069139
2022-01-13 19:37:06,542 iteration 102 : loss : 0.230977, loss_ce: 0.093343
  2%|▍                              | 6/400 [02:38<2:58:27, 27.18s/it]2022-01-13 19:37:08,047 iteration 103 : loss : 0.209198, loss_ce: 0.089219
2022-01-13 19:37:09,487 iteration 104 : loss : 0.260314, loss_ce: 0.112465
2022-01-13 19:37:10,970 iteration 105 : loss : 0.265257, loss_ce: 0.115115
2022-01-13 19:37:12,298 iteration 106 : loss : 0.246248, loss_ce: 0.103412
2022-01-13 19:37:13,804 iteration 107 : loss : 0.207962, loss_ce: 0.090514
2022-01-13 19:37:15,108 iteration 108 : loss : 0.261108, loss_ce: 0.105104
2022-01-13 19:37:16,447 iteration 109 : loss : 0.210429, loss_ce: 0.087480
2022-01-13 19:37:17,741 iteration 110 : loss : 0.183553, loss_ce: 0.076950
2022-01-13 19:37:19,117 iteration 111 : loss : 0.265962, loss_ce: 0.121042
2022-01-13 19:37:20,409 iteration 112 : loss : 0.197725, loss_ce: 0.079118
2022-01-13 19:37:21,769 iteration 113 : loss : 0.267223, loss_ce: 0.133012
2022-01-13 19:37:23,095 iteration 114 : loss : 0.235159, loss_ce: 0.083810
2022-01-13 19:37:24,442 iteration 115 : loss : 0.205309, loss_ce: 0.085708
2022-01-13 19:37:25,842 iteration 116 : loss : 0.255424, loss_ce: 0.118291
2022-01-13 19:37:27,244 iteration 117 : loss : 0.215903, loss_ce: 0.099962
2022-01-13 19:37:28,604 iteration 118 : loss : 0.250173, loss_ce: 0.109829
2022-01-13 19:37:29,979 iteration 119 : loss : 0.210005, loss_ce: 0.080114
  2%|▌                              | 7/400 [03:01<2:50:00, 25.95s/it]2022-01-13 19:37:31,358 iteration 120 : loss : 0.341121, loss_ce: 0.162885
2022-01-13 19:37:32,661 iteration 121 : loss : 0.219827, loss_ce: 0.099057
2022-01-13 19:37:34,072 iteration 122 : loss : 0.271803, loss_ce: 0.113353
2022-01-13 19:37:35,440 iteration 123 : loss : 0.274214, loss_ce: 0.123772
2022-01-13 19:37:36,786 iteration 124 : loss : 0.227198, loss_ce: 0.095881
2022-01-13 19:37:38,099 iteration 125 : loss : 0.227539, loss_ce: 0.109432
2022-01-13 19:37:39,478 iteration 126 : loss : 0.244924, loss_ce: 0.091830
2022-01-13 19:37:40,781 iteration 127 : loss : 0.220331, loss_ce: 0.098201
2022-01-13 19:37:42,110 iteration 128 : loss : 0.221711, loss_ce: 0.087777
2022-01-13 19:37:43,508 iteration 129 : loss : 0.243187, loss_ce: 0.088675
2022-01-13 19:37:44,853 iteration 130 : loss : 0.223326, loss_ce: 0.090535
2022-01-13 19:37:46,292 iteration 131 : loss : 0.250329, loss_ce: 0.129078
2022-01-13 19:37:47,746 iteration 132 : loss : 0.210297, loss_ce: 0.059829
2022-01-13 19:37:49,081 iteration 133 : loss : 0.198340, loss_ce: 0.075524
2022-01-13 19:37:50,505 iteration 134 : loss : 0.228519, loss_ce: 0.096926
2022-01-13 19:37:51,945 iteration 135 : loss : 0.240331, loss_ce: 0.099568
2022-01-13 19:37:53,297 iteration 136 : loss : 0.159917, loss_ce: 0.073866
  2%|▌                              | 8/400 [03:25<2:44:03, 25.11s/it]2022-01-13 19:37:54,783 iteration 137 : loss : 0.238802, loss_ce: 0.086865
2022-01-13 19:37:56,113 iteration 138 : loss : 0.221143, loss_ce: 0.122794
2022-01-13 19:37:57,495 iteration 139 : loss : 0.249893, loss_ce: 0.107880
2022-01-13 19:37:58,858 iteration 140 : loss : 0.215582, loss_ce: 0.084673
2022-01-13 19:38:00,257 iteration 141 : loss : 0.217351, loss_ce: 0.106949
2022-01-13 19:38:01,672 iteration 142 : loss : 0.261482, loss_ce: 0.118380
2022-01-13 19:38:03,110 iteration 143 : loss : 0.222204, loss_ce: 0.105059
2022-01-13 19:38:04,514 iteration 144 : loss : 0.266480, loss_ce: 0.115442
2022-01-13 19:38:05,867 iteration 145 : loss : 0.232718, loss_ce: 0.092772
2022-01-13 19:38:07,259 iteration 146 : loss : 0.222683, loss_ce: 0.109933
2022-01-13 19:38:08,665 iteration 147 : loss : 0.200478, loss_ce: 0.083737
2022-01-13 19:38:09,940 iteration 148 : loss : 0.227526, loss_ce: 0.103534
2022-01-13 19:38:11,281 iteration 149 : loss : 0.285460, loss_ce: 0.129028
2022-01-13 19:38:12,603 iteration 150 : loss : 0.308455, loss_ce: 0.121772
2022-01-13 19:38:13,932 iteration 151 : loss : 0.233818, loss_ce: 0.116855
2022-01-13 19:38:15,267 iteration 152 : loss : 0.248644, loss_ce: 0.087454
2022-01-13 19:38:16,652 iteration 153 : loss : 0.240681, loss_ce: 0.103852
  2%|▋                              | 9/400 [03:48<2:40:04, 24.56s/it]2022-01-13 19:38:18,011 iteration 154 : loss : 0.321444, loss_ce: 0.145827
2022-01-13 19:38:19,381 iteration 155 : loss : 0.219583, loss_ce: 0.081768
2022-01-13 19:38:20,818 iteration 156 : loss : 0.249140, loss_ce: 0.092690
2022-01-13 19:38:22,200 iteration 157 : loss : 0.269427, loss_ce: 0.102523
2022-01-13 19:38:23,685 iteration 158 : loss : 0.228609, loss_ce: 0.107650
2022-01-13 19:38:24,940 iteration 159 : loss : 0.197811, loss_ce: 0.084914
2022-01-13 19:38:26,374 iteration 160 : loss : 0.191945, loss_ce: 0.068331
2022-01-13 19:38:27,793 iteration 161 : loss : 0.284585, loss_ce: 0.113408
2022-01-13 19:38:29,229 iteration 162 : loss : 0.229593, loss_ce: 0.114457
2022-01-13 19:38:30,593 iteration 163 : loss : 0.239662, loss_ce: 0.095678
2022-01-13 19:38:31,978 iteration 164 : loss : 0.242728, loss_ce: 0.089533
2022-01-13 19:38:33,337 iteration 165 : loss : 0.239262, loss_ce: 0.106058
2022-01-13 19:38:34,678 iteration 166 : loss : 0.235057, loss_ce: 0.090825
2022-01-13 19:38:36,032 iteration 167 : loss : 0.189981, loss_ce: 0.079684
2022-01-13 19:38:37,424 iteration 168 : loss : 0.246446, loss_ce: 0.122707
2022-01-13 19:38:38,790 iteration 169 : loss : 0.210972, loss_ce: 0.102697
2022-01-13 19:38:38,790 Training Data Eval:
2022-01-13 19:38:45,538   Average segmentation loss on training set: 0.2811
2022-01-13 19:38:45,538 Validation Data Eval:
2022-01-13 19:38:47,859   Average segmentation loss on validation set: 0.2974
2022-01-13 19:38:53,684 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 19:38:55,150 iteration 170 : loss : 0.207147, loss_ce: 0.092405
  2%|▊                             | 10/400 [04:26<3:07:36, 28.86s/it]2022-01-13 19:38:56,580 iteration 171 : loss : 0.246523, loss_ce: 0.108291
2022-01-13 19:38:57,968 iteration 172 : loss : 0.243447, loss_ce: 0.113255
2022-01-13 19:38:59,373 iteration 173 : loss : 0.201807, loss_ce: 0.095256
2022-01-13 19:39:00,697 iteration 174 : loss : 0.225962, loss_ce: 0.106531
2022-01-13 19:39:02,005 iteration 175 : loss : 0.269379, loss_ce: 0.119417
2022-01-13 19:39:03,392 iteration 176 : loss : 0.203048, loss_ce: 0.102087
2022-01-13 19:39:04,742 iteration 177 : loss : 0.250561, loss_ce: 0.095681
2022-01-13 19:39:06,094 iteration 178 : loss : 0.168570, loss_ce: 0.080193
2022-01-13 19:39:07,448 iteration 179 : loss : 0.234341, loss_ce: 0.100783
2022-01-13 19:39:08,780 iteration 180 : loss : 0.206585, loss_ce: 0.081712
2022-01-13 19:39:10,163 iteration 181 : loss : 0.192949, loss_ce: 0.078255
2022-01-13 19:39:11,490 iteration 182 : loss : 0.160063, loss_ce: 0.064293
2022-01-13 19:39:12,796 iteration 183 : loss : 0.195932, loss_ce: 0.067950
2022-01-13 19:39:14,069 iteration 184 : loss : 0.210467, loss_ce: 0.075640
2022-01-13 19:39:15,458 iteration 185 : loss : 0.292582, loss_ce: 0.102965
2022-01-13 19:39:16,846 iteration 186 : loss : 0.250208, loss_ce: 0.111918
2022-01-13 19:39:18,264 iteration 187 : loss : 0.264652, loss_ce: 0.112079
  3%|▊                             | 11/400 [04:50<2:55:43, 27.10s/it]2022-01-13 19:39:19,706 iteration 188 : loss : 0.278795, loss_ce: 0.110879
2022-01-13 19:39:21,088 iteration 189 : loss : 0.207149, loss_ce: 0.089608
2022-01-13 19:39:22,473 iteration 190 : loss : 0.188419, loss_ce: 0.067595
2022-01-13 19:39:23,809 iteration 191 : loss : 0.180082, loss_ce: 0.072303
2022-01-13 19:39:25,104 iteration 192 : loss : 0.216060, loss_ce: 0.101052
2022-01-13 19:39:26,516 iteration 193 : loss : 0.217592, loss_ce: 0.101135
2022-01-13 19:39:27,856 iteration 194 : loss : 0.266404, loss_ce: 0.088326
2022-01-13 19:39:29,174 iteration 195 : loss : 0.256012, loss_ce: 0.117826
2022-01-13 19:39:30,449 iteration 196 : loss : 0.231324, loss_ce: 0.081705
2022-01-13 19:39:31,808 iteration 197 : loss : 0.282142, loss_ce: 0.120368
2022-01-13 19:39:33,196 iteration 198 : loss : 0.195075, loss_ce: 0.081930
2022-01-13 19:39:34,517 iteration 199 : loss : 0.218760, loss_ce: 0.097685
2022-01-13 19:39:35,853 iteration 200 : loss : 0.227670, loss_ce: 0.095881
2022-01-13 19:39:37,222 iteration 201 : loss : 0.172822, loss_ce: 0.066872
2022-01-13 19:39:38,612 iteration 202 : loss : 0.196257, loss_ce: 0.087926
2022-01-13 19:39:39,924 iteration 203 : loss : 0.202551, loss_ce: 0.083036
2022-01-13 19:39:41,364 iteration 204 : loss : 0.272838, loss_ce: 0.104184
  3%|▉                             | 12/400 [05:13<2:47:23, 25.89s/it]2022-01-13 19:39:42,746 iteration 205 : loss : 0.193612, loss_ce: 0.078400
2022-01-13 19:39:44,097 iteration 206 : loss : 0.184704, loss_ce: 0.063092
2022-01-13 19:39:45,470 iteration 207 : loss : 0.163867, loss_ce: 0.074485
2022-01-13 19:39:46,807 iteration 208 : loss : 0.219118, loss_ce: 0.074567
2022-01-13 19:39:48,239 iteration 209 : loss : 0.290333, loss_ce: 0.145023
2022-01-13 19:39:49,514 iteration 210 : loss : 0.168317, loss_ce: 0.062052
2022-01-13 19:39:50,912 iteration 211 : loss : 0.230507, loss_ce: 0.108267
2022-01-13 19:39:52,285 iteration 212 : loss : 0.256497, loss_ce: 0.093092
2022-01-13 19:39:53,753 iteration 213 : loss : 0.178000, loss_ce: 0.079062
2022-01-13 19:39:55,114 iteration 214 : loss : 0.234261, loss_ce: 0.083120
2022-01-13 19:39:56,473 iteration 215 : loss : 0.235520, loss_ce: 0.092025
2022-01-13 19:39:57,989 iteration 216 : loss : 0.246877, loss_ce: 0.093648
2022-01-13 19:39:59,448 iteration 217 : loss : 0.177223, loss_ce: 0.071295
2022-01-13 19:40:00,825 iteration 218 : loss : 0.209645, loss_ce: 0.091795
2022-01-13 19:40:02,092 iteration 219 : loss : 0.195070, loss_ce: 0.081443
2022-01-13 19:40:03,472 iteration 220 : loss : 0.186568, loss_ce: 0.083406
2022-01-13 19:40:04,834 iteration 221 : loss : 0.246019, loss_ce: 0.094228
  3%|▉                             | 13/400 [05:36<2:42:14, 25.15s/it]2022-01-13 19:40:06,267 iteration 222 : loss : 0.230570, loss_ce: 0.107758
2022-01-13 19:40:07,675 iteration 223 : loss : 0.159078, loss_ce: 0.066947
2022-01-13 19:40:09,034 iteration 224 : loss : 0.300695, loss_ce: 0.159359
2022-01-13 19:40:10,482 iteration 225 : loss : 0.305322, loss_ce: 0.105271
2022-01-13 19:40:11,838 iteration 226 : loss : 0.187703, loss_ce: 0.079993
2022-01-13 19:40:13,241 iteration 227 : loss : 0.267827, loss_ce: 0.128124
2022-01-13 19:40:14,602 iteration 228 : loss : 0.240865, loss_ce: 0.097523
2022-01-13 19:40:15,918 iteration 229 : loss : 0.198836, loss_ce: 0.073354
2022-01-13 19:40:17,287 iteration 230 : loss : 0.190943, loss_ce: 0.083508
2022-01-13 19:40:18,695 iteration 231 : loss : 0.291870, loss_ce: 0.108463
2022-01-13 19:40:20,093 iteration 232 : loss : 0.190576, loss_ce: 0.079212
2022-01-13 19:40:21,414 iteration 233 : loss : 0.296454, loss_ce: 0.125046
2022-01-13 19:40:22,838 iteration 234 : loss : 0.206314, loss_ce: 0.080089
2022-01-13 19:40:24,180 iteration 235 : loss : 0.223025, loss_ce: 0.098992
2022-01-13 19:40:25,569 iteration 236 : loss : 0.222439, loss_ce: 0.092107
2022-01-13 19:40:26,910 iteration 237 : loss : 0.190458, loss_ce: 0.076546
2022-01-13 19:40:28,270 iteration 238 : loss : 0.204337, loss_ce: 0.095959
  4%|█                             | 14/400 [06:00<2:38:29, 24.64s/it]2022-01-13 19:40:29,646 iteration 239 : loss : 0.224139, loss_ce: 0.088504
2022-01-13 19:40:31,038 iteration 240 : loss : 0.197784, loss_ce: 0.093132
2022-01-13 19:40:32,439 iteration 241 : loss : 0.267485, loss_ce: 0.107625
2022-01-13 19:40:33,823 iteration 242 : loss : 0.236984, loss_ce: 0.131214
2022-01-13 19:40:35,335 iteration 243 : loss : 0.261585, loss_ce: 0.114805
2022-01-13 19:40:36,655 iteration 244 : loss : 0.235321, loss_ce: 0.066887
2022-01-13 19:40:38,035 iteration 245 : loss : 0.196161, loss_ce: 0.089116
2022-01-13 19:40:39,448 iteration 246 : loss : 0.183910, loss_ce: 0.085365
2022-01-13 19:40:40,803 iteration 247 : loss : 0.261912, loss_ce: 0.095512
2022-01-13 19:40:42,157 iteration 248 : loss : 0.225932, loss_ce: 0.078646
2022-01-13 19:40:43,497 iteration 249 : loss : 0.242122, loss_ce: 0.116702
2022-01-13 19:40:44,854 iteration 250 : loss : 0.240985, loss_ce: 0.096754
2022-01-13 19:40:46,148 iteration 251 : loss : 0.246227, loss_ce: 0.085834
2022-01-13 19:40:47,498 iteration 252 : loss : 0.161199, loss_ce: 0.063055
2022-01-13 19:40:48,883 iteration 253 : loss : 0.210552, loss_ce: 0.081287
2022-01-13 19:40:50,326 iteration 254 : loss : 0.313372, loss_ce: 0.114533
2022-01-13 19:40:50,326 Training Data Eval:
2022-01-13 19:40:57,062   Average segmentation loss on training set: 0.2220
2022-01-13 19:40:57,063 Validation Data Eval:
2022-01-13 19:40:59,387   Average segmentation loss on validation set: 0.2337
2022-01-13 19:41:05,251 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 19:41:06,635 iteration 255 : loss : 0.231804, loss_ce: 0.099459
  4%|█▏                            | 15/400 [06:38<3:04:38, 28.78s/it]2022-01-13 19:41:08,078 iteration 256 : loss : 0.208141, loss_ce: 0.090834
2022-01-13 19:41:09,493 iteration 257 : loss : 0.202379, loss_ce: 0.089677
2022-01-13 19:41:10,952 iteration 258 : loss : 0.221748, loss_ce: 0.087844
2022-01-13 19:41:12,245 iteration 259 : loss : 0.172942, loss_ce: 0.081729
2022-01-13 19:41:13,668 iteration 260 : loss : 0.190588, loss_ce: 0.084948
2022-01-13 19:41:15,049 iteration 261 : loss : 0.277343, loss_ce: 0.107667
2022-01-13 19:41:16,512 iteration 262 : loss : 0.198322, loss_ce: 0.082789
2022-01-13 19:41:17,886 iteration 263 : loss : 0.212470, loss_ce: 0.085618
2022-01-13 19:41:19,283 iteration 264 : loss : 0.220852, loss_ce: 0.111345
2022-01-13 19:41:20,616 iteration 265 : loss : 0.161104, loss_ce: 0.068715
2022-01-13 19:41:22,011 iteration 266 : loss : 0.198166, loss_ce: 0.103004
2022-01-13 19:41:23,371 iteration 267 : loss : 0.220938, loss_ce: 0.072223
2022-01-13 19:41:24,746 iteration 268 : loss : 0.262925, loss_ce: 0.120193
2022-01-13 19:41:26,303 iteration 269 : loss : 0.224759, loss_ce: 0.074504
2022-01-13 19:41:27,776 iteration 270 : loss : 0.183191, loss_ce: 0.075522
2022-01-13 19:41:29,027 iteration 271 : loss : 0.226463, loss_ce: 0.065800
2022-01-13 19:41:30,404 iteration 272 : loss : 0.186134, loss_ce: 0.089336
  4%|█▏                            | 16/400 [07:02<2:54:31, 27.27s/it]2022-01-13 19:41:31,777 iteration 273 : loss : 0.168709, loss_ce: 0.060562
2022-01-13 19:41:33,078 iteration 274 : loss : 0.142961, loss_ce: 0.056867
2022-01-13 19:41:34,393 iteration 275 : loss : 0.168702, loss_ce: 0.065871
2022-01-13 19:41:35,766 iteration 276 : loss : 0.166189, loss_ce: 0.079738
2022-01-13 19:41:37,155 iteration 277 : loss : 0.170799, loss_ce: 0.064863
2022-01-13 19:41:38,397 iteration 278 : loss : 0.209070, loss_ce: 0.073380
2022-01-13 19:41:39,701 iteration 279 : loss : 0.223673, loss_ce: 0.083627
2022-01-13 19:41:41,002 iteration 280 : loss : 0.188244, loss_ce: 0.084602
2022-01-13 19:41:42,365 iteration 281 : loss : 0.206754, loss_ce: 0.091481
2022-01-13 19:41:43,705 iteration 282 : loss : 0.223265, loss_ce: 0.081245
2022-01-13 19:41:45,018 iteration 283 : loss : 0.242615, loss_ce: 0.108012
2022-01-13 19:41:46,434 iteration 284 : loss : 0.267552, loss_ce: 0.132779
2022-01-13 19:41:47,731 iteration 285 : loss : 0.212862, loss_ce: 0.077558
2022-01-13 19:41:49,053 iteration 286 : loss : 0.209793, loss_ce: 0.086016
2022-01-13 19:41:50,489 iteration 287 : loss : 0.276557, loss_ce: 0.122690
2022-01-13 19:41:51,902 iteration 288 : loss : 0.256156, loss_ce: 0.105887
2022-01-13 19:41:53,237 iteration 289 : loss : 0.207838, loss_ce: 0.080762
  4%|█▎                            | 17/400 [07:24<2:45:32, 25.93s/it]2022-01-13 19:41:54,665 iteration 290 : loss : 0.188084, loss_ce: 0.076292
2022-01-13 19:41:55,985 iteration 291 : loss : 0.250717, loss_ce: 0.103534
2022-01-13 19:41:57,312 iteration 292 : loss : 0.215139, loss_ce: 0.091240
2022-01-13 19:41:58,651 iteration 293 : loss : 0.260041, loss_ce: 0.115213
2022-01-13 19:42:00,013 iteration 294 : loss : 0.234369, loss_ce: 0.089007
2022-01-13 19:42:01,470 iteration 295 : loss : 0.217117, loss_ce: 0.077733
2022-01-13 19:42:02,804 iteration 296 : loss : 0.210940, loss_ce: 0.080020
2022-01-13 19:42:04,170 iteration 297 : loss : 0.185991, loss_ce: 0.067698
2022-01-13 19:42:05,497 iteration 298 : loss : 0.194787, loss_ce: 0.069955
2022-01-13 19:42:06,853 iteration 299 : loss : 0.196538, loss_ce: 0.070768
2022-01-13 19:42:08,210 iteration 300 : loss : 0.230582, loss_ce: 0.086570
2022-01-13 19:42:09,580 iteration 301 : loss : 0.320911, loss_ce: 0.173155
2022-01-13 19:42:11,006 iteration 302 : loss : 0.190509, loss_ce: 0.079334
2022-01-13 19:42:12,406 iteration 303 : loss : 0.212690, loss_ce: 0.093558
2022-01-13 19:42:13,786 iteration 304 : loss : 0.294560, loss_ce: 0.140779
2022-01-13 19:42:15,202 iteration 305 : loss : 0.207197, loss_ce: 0.095234
2022-01-13 19:42:16,613 iteration 306 : loss : 0.183115, loss_ce: 0.091907
  4%|█▎                            | 18/400 [07:48<2:40:14, 25.17s/it]2022-01-13 19:42:18,051 iteration 307 : loss : 0.244900, loss_ce: 0.103422
2022-01-13 19:42:19,380 iteration 308 : loss : 0.255960, loss_ce: 0.136859
2022-01-13 19:42:20,764 iteration 309 : loss : 0.293892, loss_ce: 0.123637
2022-01-13 19:42:22,172 iteration 310 : loss : 0.233745, loss_ce: 0.102058
2022-01-13 19:42:23,494 iteration 311 : loss : 0.211934, loss_ce: 0.074326
2022-01-13 19:42:24,853 iteration 312 : loss : 0.205679, loss_ce: 0.093877
2022-01-13 19:42:26,221 iteration 313 : loss : 0.240783, loss_ce: 0.122274
2022-01-13 19:42:27,514 iteration 314 : loss : 0.193679, loss_ce: 0.084957
2022-01-13 19:42:28,858 iteration 315 : loss : 0.220575, loss_ce: 0.079865
2022-01-13 19:42:30,235 iteration 316 : loss : 0.214159, loss_ce: 0.080451
2022-01-13 19:42:31,599 iteration 317 : loss : 0.250056, loss_ce: 0.105587
2022-01-13 19:42:32,981 iteration 318 : loss : 0.201746, loss_ce: 0.091089
2022-01-13 19:42:34,282 iteration 319 : loss : 0.189339, loss_ce: 0.079149
2022-01-13 19:42:35,719 iteration 320 : loss : 0.186326, loss_ce: 0.069007
2022-01-13 19:42:37,120 iteration 321 : loss : 0.207224, loss_ce: 0.064785
2022-01-13 19:42:38,478 iteration 322 : loss : 0.295599, loss_ce: 0.142573
2022-01-13 19:42:39,901 iteration 323 : loss : 0.215141, loss_ce: 0.067587
  5%|█▍                            | 19/400 [08:11<2:36:13, 24.60s/it]2022-01-13 19:42:41,315 iteration 324 : loss : 0.216142, loss_ce: 0.090810
2022-01-13 19:42:42,682 iteration 325 : loss : 0.234586, loss_ce: 0.078157
2022-01-13 19:42:44,076 iteration 326 : loss : 0.178440, loss_ce: 0.076821
2022-01-13 19:42:45,535 iteration 327 : loss : 0.229442, loss_ce: 0.097108
2022-01-13 19:42:46,892 iteration 328 : loss : 0.193747, loss_ce: 0.082321
2022-01-13 19:42:48,288 iteration 329 : loss : 0.219575, loss_ce: 0.107697
2022-01-13 19:42:49,700 iteration 330 : loss : 0.206715, loss_ce: 0.093042
2022-01-13 19:42:51,019 iteration 331 : loss : 0.243609, loss_ce: 0.119725
2022-01-13 19:42:52,369 iteration 332 : loss : 0.180226, loss_ce: 0.064358
2022-01-13 19:42:53,756 iteration 333 : loss : 0.165538, loss_ce: 0.074980
2022-01-13 19:42:55,126 iteration 334 : loss : 0.227402, loss_ce: 0.100936
2022-01-13 19:42:56,466 iteration 335 : loss : 0.269655, loss_ce: 0.098695
2022-01-13 19:42:57,883 iteration 336 : loss : 0.171637, loss_ce: 0.065082
2022-01-13 19:42:59,245 iteration 337 : loss : 0.202909, loss_ce: 0.070802
2022-01-13 19:43:00,568 iteration 338 : loss : 0.237714, loss_ce: 0.123474
2022-01-13 19:43:01,899 iteration 339 : loss : 0.210730, loss_ce: 0.075205
2022-01-13 19:43:01,899 Training Data Eval:
2022-01-13 19:43:08,666   Average segmentation loss on training set: 0.3149
2022-01-13 19:43:08,666 Validation Data Eval:
2022-01-13 19:43:10,994   Average segmentation loss on validation set: 0.3790
2022-01-13 19:43:12,400 iteration 340 : loss : 0.229310, loss_ce: 0.100793
  5%|█▌                            | 20/400 [08:44<2:50:48, 26.97s/it]2022-01-13 19:43:13,866 iteration 341 : loss : 0.190823, loss_ce: 0.077281
2022-01-13 19:43:15,269 iteration 342 : loss : 0.170635, loss_ce: 0.055915
2022-01-13 19:43:16,629 iteration 343 : loss : 0.187656, loss_ce: 0.069400
2022-01-13 19:43:18,025 iteration 344 : loss : 0.241555, loss_ce: 0.116315
2022-01-13 19:43:19,382 iteration 345 : loss : 0.158243, loss_ce: 0.053466
2022-01-13 19:43:20,808 iteration 346 : loss : 0.226610, loss_ce: 0.091527
2022-01-13 19:43:22,125 iteration 347 : loss : 0.228905, loss_ce: 0.122601
2022-01-13 19:43:23,509 iteration 348 : loss : 0.207149, loss_ce: 0.084188
2022-01-13 19:43:25,000 iteration 349 : loss : 0.221008, loss_ce: 0.118298
2022-01-13 19:43:26,404 iteration 350 : loss : 0.188486, loss_ce: 0.085338
2022-01-13 19:43:27,826 iteration 351 : loss : 0.192630, loss_ce: 0.094140
2022-01-13 19:43:29,220 iteration 352 : loss : 0.204490, loss_ce: 0.087227
2022-01-13 19:43:30,536 iteration 353 : loss : 0.232118, loss_ce: 0.092675
2022-01-13 19:43:31,903 iteration 354 : loss : 0.281777, loss_ce: 0.113175
2022-01-13 19:43:33,329 iteration 355 : loss : 0.215899, loss_ce: 0.090733
2022-01-13 19:43:34,815 iteration 356 : loss : 0.234084, loss_ce: 0.105759
2022-01-13 19:43:36,115 iteration 357 : loss : 0.153624, loss_ce: 0.063137
  5%|█▌                            | 21/400 [09:07<2:44:11, 25.99s/it]2022-01-13 19:43:37,566 iteration 358 : loss : 0.215381, loss_ce: 0.097381
2022-01-13 19:43:39,031 iteration 359 : loss : 0.200332, loss_ce: 0.083814
2022-01-13 19:43:40,349 iteration 360 : loss : 0.181313, loss_ce: 0.067679
2022-01-13 19:43:41,751 iteration 361 : loss : 0.239322, loss_ce: 0.091364
2022-01-13 19:43:43,202 iteration 362 : loss : 0.172777, loss_ce: 0.054254
2022-01-13 19:43:44,640 iteration 363 : loss : 0.209328, loss_ce: 0.071025
2022-01-13 19:43:46,032 iteration 364 : loss : 0.194992, loss_ce: 0.074100
2022-01-13 19:43:47,311 iteration 365 : loss : 0.212270, loss_ce: 0.100320
2022-01-13 19:43:48,712 iteration 366 : loss : 0.231780, loss_ce: 0.102091
2022-01-13 19:43:50,014 iteration 367 : loss : 0.193897, loss_ce: 0.082882
2022-01-13 19:43:51,425 iteration 368 : loss : 0.219301, loss_ce: 0.080583
2022-01-13 19:43:52,879 iteration 369 : loss : 0.223651, loss_ce: 0.078672
2022-01-13 19:43:54,333 iteration 370 : loss : 0.158283, loss_ce: 0.082246
2022-01-13 19:43:55,731 iteration 371 : loss : 0.270013, loss_ce: 0.093426
2022-01-13 19:43:57,142 iteration 372 : loss : 0.268468, loss_ce: 0.144370
2022-01-13 19:43:58,476 iteration 373 : loss : 0.231671, loss_ce: 0.079653
2022-01-13 19:43:59,830 iteration 374 : loss : 0.206208, loss_ce: 0.094089
  6%|█▋                            | 22/400 [09:31<2:39:28, 25.31s/it]2022-01-13 19:44:01,349 iteration 375 : loss : 0.324737, loss_ce: 0.144415
2022-01-13 19:44:02,693 iteration 376 : loss : 0.164907, loss_ce: 0.057801
2022-01-13 19:44:04,071 iteration 377 : loss : 0.192309, loss_ce: 0.069291
2022-01-13 19:44:05,527 iteration 378 : loss : 0.190641, loss_ce: 0.074311
2022-01-13 19:44:06,820 iteration 379 : loss : 0.193960, loss_ce: 0.087644
2022-01-13 19:44:08,240 iteration 380 : loss : 0.173477, loss_ce: 0.069535
2022-01-13 19:44:09,635 iteration 381 : loss : 0.149804, loss_ce: 0.055626
2022-01-13 19:44:10,936 iteration 382 : loss : 0.197990, loss_ce: 0.088266
2022-01-13 19:44:12,324 iteration 383 : loss : 0.205404, loss_ce: 0.087410
2022-01-13 19:44:13,737 iteration 384 : loss : 0.183544, loss_ce: 0.079441
2022-01-13 19:44:15,123 iteration 385 : loss : 0.151732, loss_ce: 0.068934
2022-01-13 19:44:16,521 iteration 386 : loss : 0.217079, loss_ce: 0.078213
2022-01-13 19:44:17,938 iteration 387 : loss : 0.252449, loss_ce: 0.087723
2022-01-13 19:44:19,375 iteration 388 : loss : 0.217378, loss_ce: 0.089322
2022-01-13 19:44:20,799 iteration 389 : loss : 0.271647, loss_ce: 0.139972
2022-01-13 19:44:22,174 iteration 390 : loss : 0.171849, loss_ce: 0.071877
2022-01-13 19:44:23,545 iteration 391 : loss : 0.252233, loss_ce: 0.143618
  6%|█▋                            | 23/400 [09:55<2:36:00, 24.83s/it]2022-01-13 19:44:25,018 iteration 392 : loss : 0.183275, loss_ce: 0.091291
2022-01-13 19:44:26,372 iteration 393 : loss : 0.162770, loss_ce: 0.064432
2022-01-13 19:44:27,819 iteration 394 : loss : 0.170396, loss_ce: 0.066709
2022-01-13 19:44:29,232 iteration 395 : loss : 0.196789, loss_ce: 0.089051
2022-01-13 19:44:30,594 iteration 396 : loss : 0.200581, loss_ce: 0.075028
2022-01-13 19:44:31,987 iteration 397 : loss : 0.205423, loss_ce: 0.095338
2022-01-13 19:44:33,400 iteration 398 : loss : 0.178954, loss_ce: 0.071673
2022-01-13 19:44:34,677 iteration 399 : loss : 0.191685, loss_ce: 0.083982
2022-01-13 19:44:36,078 iteration 400 : loss : 0.196344, loss_ce: 0.074541
2022-01-13 19:44:37,519 iteration 401 : loss : 0.239161, loss_ce: 0.105525
2022-01-13 19:44:38,887 iteration 402 : loss : 0.166648, loss_ce: 0.077526
2022-01-13 19:44:40,240 iteration 403 : loss : 0.175267, loss_ce: 0.074665
2022-01-13 19:44:41,658 iteration 404 : loss : 0.233623, loss_ce: 0.107607
2022-01-13 19:44:43,127 iteration 405 : loss : 0.250337, loss_ce: 0.106995
2022-01-13 19:44:44,490 iteration 406 : loss : 0.223017, loss_ce: 0.095707
2022-01-13 19:44:45,816 iteration 407 : loss : 0.227628, loss_ce: 0.090485
2022-01-13 19:44:47,191 iteration 408 : loss : 0.224895, loss_ce: 0.086035
  6%|█▊                            | 24/400 [10:18<2:33:23, 24.48s/it]2022-01-13 19:44:48,680 iteration 409 : loss : 0.221477, loss_ce: 0.117357
2022-01-13 19:44:50,085 iteration 410 : loss : 0.258826, loss_ce: 0.106535
2022-01-13 19:44:51,461 iteration 411 : loss : 0.321237, loss_ce: 0.108158
2022-01-13 19:44:52,740 iteration 412 : loss : 0.221131, loss_ce: 0.080347
2022-01-13 19:44:54,118 iteration 413 : loss : 0.225461, loss_ce: 0.083887
2022-01-13 19:44:55,446 iteration 414 : loss : 0.254244, loss_ce: 0.118752
2022-01-13 19:44:56,717 iteration 415 : loss : 0.200047, loss_ce: 0.072807
2022-01-13 19:44:58,087 iteration 416 : loss : 0.263967, loss_ce: 0.131130
2022-01-13 19:44:59,411 iteration 417 : loss : 0.263038, loss_ce: 0.099071
2022-01-13 19:45:00,867 iteration 418 : loss : 0.181592, loss_ce: 0.073102
2022-01-13 19:45:02,222 iteration 419 : loss : 0.242191, loss_ce: 0.133942
2022-01-13 19:45:03,621 iteration 420 : loss : 0.217196, loss_ce: 0.090388
2022-01-13 19:45:04,941 iteration 421 : loss : 0.236280, loss_ce: 0.099735
2022-01-13 19:45:06,262 iteration 422 : loss : 0.239474, loss_ce: 0.103603
2022-01-13 19:45:07,592 iteration 423 : loss : 0.220049, loss_ce: 0.077503
2022-01-13 19:45:08,980 iteration 424 : loss : 0.214852, loss_ce: 0.090833
2022-01-13 19:45:08,980 Training Data Eval:
2022-01-13 19:45:15,796   Average segmentation loss on training set: 0.2080
2022-01-13 19:45:15,796 Validation Data Eval:
2022-01-13 19:45:18,146   Average segmentation loss on validation set: 0.2074
2022-01-13 19:45:24,015 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 19:45:25,428 iteration 425 : loss : 0.274528, loss_ce: 0.112523
  6%|█▉                            | 25/400 [10:57<2:58:46, 28.60s/it]2022-01-13 19:45:26,817 iteration 426 : loss : 0.201391, loss_ce: 0.075005
2022-01-13 19:45:28,248 iteration 427 : loss : 0.165373, loss_ce: 0.060797
2022-01-13 19:45:29,638 iteration 428 : loss : 0.211923, loss_ce: 0.085954
2022-01-13 19:45:30,970 iteration 429 : loss : 0.281244, loss_ce: 0.149669
2022-01-13 19:45:32,314 iteration 430 : loss : 0.195418, loss_ce: 0.073134
2022-01-13 19:45:33,664 iteration 431 : loss : 0.303680, loss_ce: 0.127146
2022-01-13 19:45:35,083 iteration 432 : loss : 0.177143, loss_ce: 0.066066
2022-01-13 19:45:36,540 iteration 433 : loss : 0.187089, loss_ce: 0.072763
2022-01-13 19:45:37,933 iteration 434 : loss : 0.186605, loss_ce: 0.072012
2022-01-13 19:45:39,262 iteration 435 : loss : 0.199350, loss_ce: 0.084692
2022-01-13 19:45:40,626 iteration 436 : loss : 0.193542, loss_ce: 0.086842
2022-01-13 19:45:41,994 iteration 437 : loss : 0.280161, loss_ce: 0.150096
2022-01-13 19:45:43,310 iteration 438 : loss : 0.229341, loss_ce: 0.089855
2022-01-13 19:45:44,699 iteration 439 : loss : 0.239302, loss_ce: 0.086531
2022-01-13 19:45:46,062 iteration 440 : loss : 0.244788, loss_ce: 0.099662
2022-01-13 19:45:47,486 iteration 441 : loss : 0.201443, loss_ce: 0.087420
2022-01-13 19:45:48,898 iteration 442 : loss : 0.212302, loss_ce: 0.105196
  6%|█▉                            | 26/400 [11:20<2:48:42, 27.06s/it]2022-01-13 19:45:50,319 iteration 443 : loss : 0.241345, loss_ce: 0.127073
2022-01-13 19:45:51,648 iteration 444 : loss : 0.223747, loss_ce: 0.090162
2022-01-13 19:45:53,019 iteration 445 : loss : 0.219858, loss_ce: 0.075437
2022-01-13 19:45:54,537 iteration 446 : loss : 0.198687, loss_ce: 0.088353
2022-01-13 19:45:55,996 iteration 447 : loss : 0.223052, loss_ce: 0.117162
2022-01-13 19:45:57,417 iteration 448 : loss : 0.280082, loss_ce: 0.084345
2022-01-13 19:45:58,794 iteration 449 : loss : 0.233815, loss_ce: 0.108647
2022-01-13 19:46:00,151 iteration 450 : loss : 0.224994, loss_ce: 0.091237
2022-01-13 19:46:01,607 iteration 451 : loss : 0.166637, loss_ce: 0.069010
2022-01-13 19:46:03,025 iteration 452 : loss : 0.171539, loss_ce: 0.072290
2022-01-13 19:46:04,437 iteration 453 : loss : 0.240433, loss_ce: 0.094286
2022-01-13 19:46:05,849 iteration 454 : loss : 0.260194, loss_ce: 0.086385
2022-01-13 19:46:07,306 iteration 455 : loss : 0.188098, loss_ce: 0.080420
2022-01-13 19:46:08,717 iteration 456 : loss : 0.209963, loss_ce: 0.083894
2022-01-13 19:46:10,118 iteration 457 : loss : 0.191766, loss_ce: 0.080595
2022-01-13 19:46:11,577 iteration 458 : loss : 0.231487, loss_ce: 0.110572
2022-01-13 19:46:12,894 iteration 459 : loss : 0.137256, loss_ce: 0.054916
  7%|██                            | 27/400 [11:44<2:42:31, 26.14s/it]2022-01-13 19:46:14,356 iteration 460 : loss : 0.226491, loss_ce: 0.112859
2022-01-13 19:46:15,750 iteration 461 : loss : 0.206116, loss_ce: 0.096615
2022-01-13 19:46:17,122 iteration 462 : loss : 0.208539, loss_ce: 0.080040
2022-01-13 19:46:18,562 iteration 463 : loss : 0.203485, loss_ce: 0.086368
2022-01-13 19:46:19,948 iteration 464 : loss : 0.168892, loss_ce: 0.070539
2022-01-13 19:46:21,280 iteration 465 : loss : 0.195499, loss_ce: 0.068108
2022-01-13 19:46:22,648 iteration 466 : loss : 0.208094, loss_ce: 0.083739
2022-01-13 19:46:24,005 iteration 467 : loss : 0.174510, loss_ce: 0.068247
2022-01-13 19:46:25,492 iteration 468 : loss : 0.199111, loss_ce: 0.095215
2022-01-13 19:46:26,849 iteration 469 : loss : 0.191905, loss_ce: 0.069391
2022-01-13 19:46:28,225 iteration 470 : loss : 0.206561, loss_ce: 0.081817
2022-01-13 19:46:29,599 iteration 471 : loss : 0.220973, loss_ce: 0.077207
2022-01-13 19:46:31,046 iteration 472 : loss : 0.191347, loss_ce: 0.086381
2022-01-13 19:46:32,597 iteration 473 : loss : 0.236835, loss_ce: 0.098170
2022-01-13 19:46:34,066 iteration 474 : loss : 0.256602, loss_ce: 0.122999
2022-01-13 19:46:35,426 iteration 475 : loss : 0.151138, loss_ce: 0.057806
2022-01-13 19:46:36,875 iteration 476 : loss : 0.208469, loss_ce: 0.105265
  7%|██                            | 28/400 [12:08<2:38:03, 25.49s/it]2022-01-13 19:46:38,322 iteration 477 : loss : 0.179879, loss_ce: 0.062233
2022-01-13 19:46:39,767 iteration 478 : loss : 0.153575, loss_ce: 0.055916
2022-01-13 19:46:41,153 iteration 479 : loss : 0.176156, loss_ce: 0.082944
2022-01-13 19:46:42,568 iteration 480 : loss : 0.177110, loss_ce: 0.086795
2022-01-13 19:46:43,864 iteration 481 : loss : 0.226163, loss_ce: 0.106145
2022-01-13 19:46:45,265 iteration 482 : loss : 0.184185, loss_ce: 0.057995
2022-01-13 19:46:46,714 iteration 483 : loss : 0.225537, loss_ce: 0.081704
2022-01-13 19:46:48,150 iteration 484 : loss : 0.259247, loss_ce: 0.124398
2022-01-13 19:46:49,522 iteration 485 : loss : 0.165197, loss_ce: 0.072464
2022-01-13 19:46:50,880 iteration 486 : loss : 0.201276, loss_ce: 0.071932
2022-01-13 19:46:52,328 iteration 487 : loss : 0.211217, loss_ce: 0.089070
2022-01-13 19:46:53,660 iteration 488 : loss : 0.173811, loss_ce: 0.073566
2022-01-13 19:46:55,045 iteration 489 : loss : 0.206224, loss_ce: 0.098578
2022-01-13 19:46:56,319 iteration 490 : loss : 0.212011, loss_ce: 0.087407
2022-01-13 19:46:57,720 iteration 491 : loss : 0.191433, loss_ce: 0.089340
2022-01-13 19:46:59,088 iteration 492 : loss : 0.184759, loss_ce: 0.077163
2022-01-13 19:47:00,506 iteration 493 : loss : 0.215201, loss_ce: 0.104080
  7%|██▏                           | 29/400 [12:32<2:34:11, 24.94s/it]2022-01-13 19:47:01,956 iteration 494 : loss : 0.204778, loss_ce: 0.095961
2022-01-13 19:47:03,374 iteration 495 : loss : 0.187069, loss_ce: 0.072051
2022-01-13 19:47:04,740 iteration 496 : loss : 0.305613, loss_ce: 0.152855
2022-01-13 19:47:06,145 iteration 497 : loss : 0.220199, loss_ce: 0.100346
2022-01-13 19:47:07,607 iteration 498 : loss : 0.211945, loss_ce: 0.106797
2022-01-13 19:47:08,922 iteration 499 : loss : 0.165533, loss_ce: 0.073326
2022-01-13 19:47:10,261 iteration 500 : loss : 0.187775, loss_ce: 0.076783
2022-01-13 19:47:11,598 iteration 501 : loss : 0.216431, loss_ce: 0.094852
2022-01-13 19:47:13,032 iteration 502 : loss : 0.199339, loss_ce: 0.088552
2022-01-13 19:47:14,388 iteration 503 : loss : 0.212025, loss_ce: 0.071552
2022-01-13 19:47:15,803 iteration 504 : loss : 0.174005, loss_ce: 0.068650
2022-01-13 19:47:17,141 iteration 505 : loss : 0.133765, loss_ce: 0.055415
2022-01-13 19:47:18,633 iteration 506 : loss : 0.159401, loss_ce: 0.070158
2022-01-13 19:47:20,032 iteration 507 : loss : 0.263209, loss_ce: 0.106028
2022-01-13 19:47:21,400 iteration 508 : loss : 0.241680, loss_ce: 0.109351
2022-01-13 19:47:22,806 iteration 509 : loss : 0.184498, loss_ce: 0.067750
2022-01-13 19:47:22,806 Training Data Eval:
2022-01-13 19:47:29,534   Average segmentation loss on training set: 0.1734
2022-01-13 19:47:29,534 Validation Data Eval:
2022-01-13 19:47:31,862   Average segmentation loss on validation set: 0.1703
2022-01-13 19:47:37,675 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 19:47:39,119 iteration 510 : loss : 0.189518, loss_ce: 0.086839
  8%|██▎                           | 30/400 [13:10<2:59:02, 29.04s/it]2022-01-13 19:47:40,550 iteration 511 : loss : 0.248891, loss_ce: 0.113259
2022-01-13 19:47:41,867 iteration 512 : loss : 0.245935, loss_ce: 0.117865
2022-01-13 19:47:43,205 iteration 513 : loss : 0.177468, loss_ce: 0.058378
2022-01-13 19:47:44,560 iteration 514 : loss : 0.165096, loss_ce: 0.072215
2022-01-13 19:47:45,895 iteration 515 : loss : 0.240811, loss_ce: 0.103598
2022-01-13 19:47:47,277 iteration 516 : loss : 0.158655, loss_ce: 0.057821
2022-01-13 19:47:48,692 iteration 517 : loss : 0.184197, loss_ce: 0.085000
2022-01-13 19:47:50,005 iteration 518 : loss : 0.201718, loss_ce: 0.077384
2022-01-13 19:47:51,369 iteration 519 : loss : 0.222193, loss_ce: 0.096869
2022-01-13 19:47:52,675 iteration 520 : loss : 0.176485, loss_ce: 0.073916
2022-01-13 19:47:54,032 iteration 521 : loss : 0.216796, loss_ce: 0.086937
2022-01-13 19:47:55,425 iteration 522 : loss : 0.149318, loss_ce: 0.054019
2022-01-13 19:47:56,862 iteration 523 : loss : 0.171948, loss_ce: 0.074998
2022-01-13 19:47:58,313 iteration 524 : loss : 0.156318, loss_ce: 0.062501
2022-01-13 19:47:59,673 iteration 525 : loss : 0.220774, loss_ce: 0.107510
2022-01-13 19:48:01,027 iteration 526 : loss : 0.222493, loss_ce: 0.112469
2022-01-13 19:48:02,385 iteration 527 : loss : 0.198597, loss_ce: 0.074113
  8%|██▎                           | 31/400 [13:34<2:47:56, 27.31s/it]2022-01-13 19:48:03,777 iteration 528 : loss : 0.164114, loss_ce: 0.075377
2022-01-13 19:48:05,144 iteration 529 : loss : 0.220691, loss_ce: 0.081515
2022-01-13 19:48:06,469 iteration 530 : loss : 0.201133, loss_ce: 0.088628
2022-01-13 19:48:07,779 iteration 531 : loss : 0.204014, loss_ce: 0.078429
2022-01-13 19:48:09,104 iteration 532 : loss : 0.224536, loss_ce: 0.112836
2022-01-13 19:48:10,556 iteration 533 : loss : 0.175682, loss_ce: 0.076203
2022-01-13 19:48:11,868 iteration 534 : loss : 0.161202, loss_ce: 0.071360
2022-01-13 19:48:13,268 iteration 535 : loss : 0.176492, loss_ce: 0.074172
2022-01-13 19:48:14,702 iteration 536 : loss : 0.256059, loss_ce: 0.121363
2022-01-13 19:48:16,153 iteration 537 : loss : 0.226095, loss_ce: 0.079424
2022-01-13 19:48:17,537 iteration 538 : loss : 0.192236, loss_ce: 0.077719
2022-01-13 19:48:18,884 iteration 539 : loss : 0.191610, loss_ce: 0.084205
2022-01-13 19:48:20,266 iteration 540 : loss : 0.209417, loss_ce: 0.081040
2022-01-13 19:48:21,608 iteration 541 : loss : 0.148896, loss_ce: 0.064899
2022-01-13 19:48:22,966 iteration 542 : loss : 0.256706, loss_ce: 0.126126
2022-01-13 19:48:24,276 iteration 543 : loss : 0.142519, loss_ce: 0.063809
2022-01-13 19:48:25,614 iteration 544 : loss : 0.200827, loss_ce: 0.081130
  8%|██▍                           | 32/400 [13:57<2:39:58, 26.08s/it]2022-01-13 19:48:27,051 iteration 545 : loss : 0.154539, loss_ce: 0.075709
2022-01-13 19:48:28,407 iteration 546 : loss : 0.158041, loss_ce: 0.064483
2022-01-13 19:48:29,767 iteration 547 : loss : 0.180201, loss_ce: 0.077571
2022-01-13 19:48:31,114 iteration 548 : loss : 0.253726, loss_ce: 0.097857
2022-01-13 19:48:32,496 iteration 549 : loss : 0.202163, loss_ce: 0.087361
2022-01-13 19:48:33,829 iteration 550 : loss : 0.191629, loss_ce: 0.083831
2022-01-13 19:48:35,184 iteration 551 : loss : 0.202696, loss_ce: 0.094101
2022-01-13 19:48:36,519 iteration 552 : loss : 0.188411, loss_ce: 0.081786
2022-01-13 19:48:37,916 iteration 553 : loss : 0.193975, loss_ce: 0.067565
2022-01-13 19:48:39,215 iteration 554 : loss : 0.176299, loss_ce: 0.085902
2022-01-13 19:48:40,565 iteration 555 : loss : 0.170978, loss_ce: 0.058119
2022-01-13 19:48:41,961 iteration 556 : loss : 0.153979, loss_ce: 0.064615
2022-01-13 19:48:43,245 iteration 557 : loss : 0.195800, loss_ce: 0.069045
2022-01-13 19:48:44,636 iteration 558 : loss : 0.213317, loss_ce: 0.064731
2022-01-13 19:48:45,992 iteration 559 : loss : 0.180235, loss_ce: 0.071705
2022-01-13 19:48:47,367 iteration 560 : loss : 0.191314, loss_ce: 0.055527
2022-01-13 19:48:48,765 iteration 561 : loss : 0.206896, loss_ce: 0.101974
  8%|██▍                           | 33/400 [14:20<2:34:10, 25.20s/it]2022-01-13 19:48:50,288 iteration 562 : loss : 0.203434, loss_ce: 0.095300
2022-01-13 19:48:51,563 iteration 563 : loss : 0.158578, loss_ce: 0.077104
2022-01-13 19:48:52,946 iteration 564 : loss : 0.183810, loss_ce: 0.091505
2022-01-13 19:48:54,326 iteration 565 : loss : 0.201974, loss_ce: 0.097303
2022-01-13 19:48:55,734 iteration 566 : loss : 0.177723, loss_ce: 0.082292
2022-01-13 19:48:57,073 iteration 567 : loss : 0.175129, loss_ce: 0.067445
2022-01-13 19:48:58,401 iteration 568 : loss : 0.221207, loss_ce: 0.081821
2022-01-13 19:48:59,755 iteration 569 : loss : 0.277045, loss_ce: 0.122968
2022-01-13 19:49:01,148 iteration 570 : loss : 0.142909, loss_ce: 0.068736
2022-01-13 19:49:02,485 iteration 571 : loss : 0.308149, loss_ce: 0.119928
2022-01-13 19:49:03,862 iteration 572 : loss : 0.169267, loss_ce: 0.071266
2022-01-13 19:49:05,190 iteration 573 : loss : 0.165537, loss_ce: 0.067577
2022-01-13 19:49:06,547 iteration 574 : loss : 0.214929, loss_ce: 0.077319
2022-01-13 19:49:07,970 iteration 575 : loss : 0.208192, loss_ce: 0.070078
2022-01-13 19:49:09,373 iteration 576 : loss : 0.188249, loss_ce: 0.082929
2022-01-13 19:49:10,732 iteration 577 : loss : 0.187112, loss_ce: 0.078049
2022-01-13 19:49:12,051 iteration 578 : loss : 0.236558, loss_ce: 0.104087
  8%|██▌                           | 34/400 [14:43<2:30:14, 24.63s/it]2022-01-13 19:49:13,686 iteration 579 : loss : 0.172725, loss_ce: 0.069076
2022-01-13 19:49:15,066 iteration 580 : loss : 0.231481, loss_ce: 0.094013
2022-01-13 19:49:16,480 iteration 581 : loss : 0.187298, loss_ce: 0.059183
2022-01-13 19:49:17,832 iteration 582 : loss : 0.187193, loss_ce: 0.069584
2022-01-13 19:49:19,201 iteration 583 : loss : 0.229834, loss_ce: 0.067205
2022-01-13 19:49:20,533 iteration 584 : loss : 0.130538, loss_ce: 0.055564
2022-01-13 19:49:21,937 iteration 585 : loss : 0.172815, loss_ce: 0.070754
2022-01-13 19:49:23,260 iteration 586 : loss : 0.208681, loss_ce: 0.085880
2022-01-13 19:49:24,576 iteration 587 : loss : 0.195791, loss_ce: 0.091978
2022-01-13 19:49:25,960 iteration 588 : loss : 0.163606, loss_ce: 0.061445
2022-01-13 19:49:27,308 iteration 589 : loss : 0.138284, loss_ce: 0.051685
2022-01-13 19:49:28,669 iteration 590 : loss : 0.207421, loss_ce: 0.089863
2022-01-13 19:49:30,035 iteration 591 : loss : 0.159826, loss_ce: 0.067692
2022-01-13 19:49:31,396 iteration 592 : loss : 0.180811, loss_ce: 0.073707
2022-01-13 19:49:32,789 iteration 593 : loss : 0.106411, loss_ce: 0.038151
2022-01-13 19:49:34,169 iteration 594 : loss : 0.139633, loss_ce: 0.060017
2022-01-13 19:49:34,169 Training Data Eval:
2022-01-13 19:49:40,893   Average segmentation loss on training set: 0.2110
2022-01-13 19:49:40,893 Validation Data Eval:
2022-01-13 19:49:43,219   Average segmentation loss on validation set: 0.2092
2022-01-13 19:49:44,639 iteration 595 : loss : 0.283836, loss_ce: 0.171392
  9%|██▋                           | 35/400 [15:16<2:44:20, 27.02s/it]2022-01-13 19:49:46,066 iteration 596 : loss : 0.164465, loss_ce: 0.069723
2022-01-13 19:49:47,399 iteration 597 : loss : 0.175961, loss_ce: 0.057629
2022-01-13 19:49:48,725 iteration 598 : loss : 0.151646, loss_ce: 0.057961
2022-01-13 19:49:50,067 iteration 599 : loss : 0.189123, loss_ce: 0.069847
2022-01-13 19:49:51,411 iteration 600 : loss : 0.232843, loss_ce: 0.108830
2022-01-13 19:49:52,780 iteration 601 : loss : 0.180479, loss_ce: 0.063395
2022-01-13 19:49:54,164 iteration 602 : loss : 0.159882, loss_ce: 0.063355
2022-01-13 19:49:55,462 iteration 603 : loss : 0.196209, loss_ce: 0.067677
2022-01-13 19:49:56,774 iteration 604 : loss : 0.185647, loss_ce: 0.072430
2022-01-13 19:49:58,073 iteration 605 : loss : 0.178439, loss_ce: 0.071035
2022-01-13 19:49:59,610 iteration 606 : loss : 0.157539, loss_ce: 0.074307
2022-01-13 19:50:00,963 iteration 607 : loss : 0.201959, loss_ce: 0.085027
2022-01-13 19:50:02,320 iteration 608 : loss : 0.173365, loss_ce: 0.085905
2022-01-13 19:50:03,600 iteration 609 : loss : 0.152970, loss_ce: 0.068614
2022-01-13 19:50:04,998 iteration 610 : loss : 0.161068, loss_ce: 0.067583
2022-01-13 19:50:06,453 iteration 611 : loss : 0.203623, loss_ce: 0.100993
2022-01-13 19:50:07,833 iteration 612 : loss : 0.129880, loss_ce: 0.051079
  9%|██▋                           | 36/400 [15:39<2:36:57, 25.87s/it]2022-01-13 19:50:09,285 iteration 613 : loss : 0.147866, loss_ce: 0.059689
2022-01-13 19:50:10,613 iteration 614 : loss : 0.169435, loss_ce: 0.062465
2022-01-13 19:50:11,931 iteration 615 : loss : 0.257167, loss_ce: 0.128155
2022-01-13 19:50:13,362 iteration 616 : loss : 0.187285, loss_ce: 0.098616
2022-01-13 19:50:14,689 iteration 617 : loss : 0.178916, loss_ce: 0.083382
2022-01-13 19:50:16,061 iteration 618 : loss : 0.209181, loss_ce: 0.065516
2022-01-13 19:50:17,430 iteration 619 : loss : 0.273543, loss_ce: 0.132450
2022-01-13 19:50:18,888 iteration 620 : loss : 0.251095, loss_ce: 0.078798
2022-01-13 19:50:20,258 iteration 621 : loss : 0.134097, loss_ce: 0.047118
2022-01-13 19:50:21,739 iteration 622 : loss : 0.161858, loss_ce: 0.069179
2022-01-13 19:50:23,200 iteration 623 : loss : 0.206648, loss_ce: 0.121536
2022-01-13 19:50:24,555 iteration 624 : loss : 0.177285, loss_ce: 0.060523
2022-01-13 19:50:25,877 iteration 625 : loss : 0.167958, loss_ce: 0.077545
2022-01-13 19:50:27,287 iteration 626 : loss : 0.222707, loss_ce: 0.100900
2022-01-13 19:50:28,702 iteration 627 : loss : 0.199677, loss_ce: 0.074178
2022-01-13 19:50:30,163 iteration 628 : loss : 0.219995, loss_ce: 0.083691
2022-01-13 19:50:31,519 iteration 629 : loss : 0.126914, loss_ce: 0.054046
  9%|██▊                           | 37/400 [16:03<2:32:32, 25.21s/it]2022-01-13 19:50:32,972 iteration 630 : loss : 0.191616, loss_ce: 0.086207
2022-01-13 19:50:34,318 iteration 631 : loss : 0.129994, loss_ce: 0.057835
2022-01-13 19:50:35,662 iteration 632 : loss : 0.225511, loss_ce: 0.099498
2022-01-13 19:50:37,101 iteration 633 : loss : 0.173812, loss_ce: 0.072979
2022-01-13 19:50:38,477 iteration 634 : loss : 0.244512, loss_ce: 0.102342
2022-01-13 19:50:39,937 iteration 635 : loss : 0.180725, loss_ce: 0.077426
2022-01-13 19:50:41,329 iteration 636 : loss : 0.207299, loss_ce: 0.092498
2022-01-13 19:50:42,630 iteration 637 : loss : 0.222751, loss_ce: 0.102880
2022-01-13 19:50:44,076 iteration 638 : loss : 0.192418, loss_ce: 0.069145
2022-01-13 19:50:45,411 iteration 639 : loss : 0.152948, loss_ce: 0.069753
2022-01-13 19:50:46,717 iteration 640 : loss : 0.191711, loss_ce: 0.058026
2022-01-13 19:50:48,024 iteration 641 : loss : 0.179189, loss_ce: 0.078269
2022-01-13 19:50:49,343 iteration 642 : loss : 0.182813, loss_ce: 0.060016
2022-01-13 19:50:50,694 iteration 643 : loss : 0.177817, loss_ce: 0.065768
2022-01-13 19:50:52,049 iteration 644 : loss : 0.157816, loss_ce: 0.066723
2022-01-13 19:50:53,371 iteration 645 : loss : 0.156941, loss_ce: 0.049207
2022-01-13 19:50:54,792 iteration 646 : loss : 0.181294, loss_ce: 0.083647
 10%|██▊                           | 38/400 [16:26<2:28:36, 24.63s/it]2022-01-13 19:50:56,195 iteration 647 : loss : 0.203936, loss_ce: 0.093915
2022-01-13 19:50:57,559 iteration 648 : loss : 0.139366, loss_ce: 0.064250
2022-01-13 19:50:58,948 iteration 649 : loss : 0.173544, loss_ce: 0.072888
2022-01-13 19:51:00,378 iteration 650 : loss : 0.194143, loss_ce: 0.075449
2022-01-13 19:51:01,736 iteration 651 : loss : 0.131010, loss_ce: 0.053575
2022-01-13 19:51:03,005 iteration 652 : loss : 0.103516, loss_ce: 0.038918
2022-01-13 19:51:04,456 iteration 653 : loss : 0.178869, loss_ce: 0.078154
2022-01-13 19:51:05,771 iteration 654 : loss : 0.160292, loss_ce: 0.054298
2022-01-13 19:51:07,131 iteration 655 : loss : 0.220790, loss_ce: 0.082240
2022-01-13 19:51:08,500 iteration 656 : loss : 0.163180, loss_ce: 0.064822
2022-01-13 19:51:09,938 iteration 657 : loss : 0.131086, loss_ce: 0.046335
2022-01-13 19:51:11,328 iteration 658 : loss : 0.187834, loss_ce: 0.057809
2022-01-13 19:51:12,724 iteration 659 : loss : 0.234162, loss_ce: 0.096317
2022-01-13 19:51:14,059 iteration 660 : loss : 0.175927, loss_ce: 0.081602
2022-01-13 19:51:15,445 iteration 661 : loss : 0.166900, loss_ce: 0.070928
2022-01-13 19:51:16,905 iteration 662 : loss : 0.243767, loss_ce: 0.068942
2022-01-13 19:51:18,276 iteration 663 : loss : 0.164220, loss_ce: 0.072100
 10%|██▉                           | 39/400 [16:50<2:26:06, 24.28s/it]2022-01-13 19:51:19,717 iteration 664 : loss : 0.144712, loss_ce: 0.068834
2022-01-13 19:51:21,012 iteration 665 : loss : 0.167120, loss_ce: 0.076677
2022-01-13 19:51:22,366 iteration 666 : loss : 0.148429, loss_ce: 0.056070
2022-01-13 19:51:23,765 iteration 667 : loss : 0.126837, loss_ce: 0.056090
2022-01-13 19:51:25,138 iteration 668 : loss : 0.184315, loss_ce: 0.072994
2022-01-13 19:51:26,480 iteration 669 : loss : 0.186899, loss_ce: 0.068440
2022-01-13 19:51:27,964 iteration 670 : loss : 0.148242, loss_ce: 0.051712
2022-01-13 19:51:29,314 iteration 671 : loss : 0.238757, loss_ce: 0.086913
2022-01-13 19:51:30,744 iteration 672 : loss : 0.146144, loss_ce: 0.054344
2022-01-13 19:51:32,151 iteration 673 : loss : 0.173762, loss_ce: 0.074939
2022-01-13 19:51:33,541 iteration 674 : loss : 0.173441, loss_ce: 0.076457
2022-01-13 19:51:34,959 iteration 675 : loss : 0.213919, loss_ce: 0.088826
2022-01-13 19:51:36,319 iteration 676 : loss : 0.177765, loss_ce: 0.067472
2022-01-13 19:51:37,693 iteration 677 : loss : 0.179048, loss_ce: 0.086849
2022-01-13 19:51:39,096 iteration 678 : loss : 0.211267, loss_ce: 0.081014
2022-01-13 19:51:40,473 iteration 679 : loss : 0.210099, loss_ce: 0.100824
2022-01-13 19:51:40,473 Training Data Eval:
2022-01-13 19:51:47,211   Average segmentation loss on training set: 0.1586
2022-01-13 19:51:47,211 Validation Data Eval:
2022-01-13 19:51:49,532   Average segmentation loss on validation set: 0.1963
2022-01-13 19:51:50,898 iteration 680 : loss : 0.205293, loss_ce: 0.084824
 10%|███                           | 40/400 [17:22<2:40:43, 26.79s/it]2022-01-13 19:51:52,347 iteration 681 : loss : 0.173388, loss_ce: 0.061660
2022-01-13 19:51:53,640 iteration 682 : loss : 0.174258, loss_ce: 0.057318
2022-01-13 19:51:55,002 iteration 683 : loss : 0.127992, loss_ce: 0.061636
2022-01-13 19:51:56,326 iteration 684 : loss : 0.123272, loss_ce: 0.045076
2022-01-13 19:51:57,748 iteration 685 : loss : 0.203875, loss_ce: 0.087634
2022-01-13 19:51:59,152 iteration 686 : loss : 0.209592, loss_ce: 0.085158
2022-01-13 19:52:00,516 iteration 687 : loss : 0.167171, loss_ce: 0.073775
2022-01-13 19:52:01,864 iteration 688 : loss : 0.155380, loss_ce: 0.053795
2022-01-13 19:52:03,248 iteration 689 : loss : 0.172737, loss_ce: 0.073303
2022-01-13 19:52:04,606 iteration 690 : loss : 0.147135, loss_ce: 0.052878
2022-01-13 19:52:06,011 iteration 691 : loss : 0.201020, loss_ce: 0.088566
2022-01-13 19:52:07,429 iteration 692 : loss : 0.141427, loss_ce: 0.050969
2022-01-13 19:52:08,734 iteration 693 : loss : 0.146151, loss_ce: 0.065901
2022-01-13 19:52:10,107 iteration 694 : loss : 0.170206, loss_ce: 0.074888
2022-01-13 19:52:11,436 iteration 695 : loss : 0.190404, loss_ce: 0.095226
2022-01-13 19:52:12,857 iteration 696 : loss : 0.145015, loss_ce: 0.063013
2022-01-13 19:52:14,223 iteration 697 : loss : 0.161945, loss_ce: 0.070761
 10%|███                           | 41/400 [17:45<2:34:05, 25.75s/it]2022-01-13 19:52:15,616 iteration 698 : loss : 0.181034, loss_ce: 0.063109
2022-01-13 19:52:17,027 iteration 699 : loss : 0.198977, loss_ce: 0.094988
2022-01-13 19:52:18,369 iteration 700 : loss : 0.158908, loss_ce: 0.076151
2022-01-13 19:52:19,708 iteration 701 : loss : 0.174725, loss_ce: 0.092290
2022-01-13 19:52:21,106 iteration 702 : loss : 0.180243, loss_ce: 0.056251
2022-01-13 19:52:22,552 iteration 703 : loss : 0.101342, loss_ce: 0.042531
2022-01-13 19:52:23,855 iteration 704 : loss : 0.122487, loss_ce: 0.048036
2022-01-13 19:52:25,219 iteration 705 : loss : 0.208270, loss_ce: 0.075923
2022-01-13 19:52:26,594 iteration 706 : loss : 0.097811, loss_ce: 0.039452
2022-01-13 19:52:27,894 iteration 707 : loss : 0.130566, loss_ce: 0.058081
2022-01-13 19:52:29,246 iteration 708 : loss : 0.126068, loss_ce: 0.050445
2022-01-13 19:52:30,604 iteration 709 : loss : 0.153889, loss_ce: 0.070718
2022-01-13 19:52:32,000 iteration 710 : loss : 0.138631, loss_ce: 0.060169
2022-01-13 19:52:33,393 iteration 711 : loss : 0.159547, loss_ce: 0.075437
2022-01-13 19:52:34,841 iteration 712 : loss : 0.127766, loss_ce: 0.051866
2022-01-13 19:52:36,200 iteration 713 : loss : 0.143223, loss_ce: 0.068965
2022-01-13 19:52:37,630 iteration 714 : loss : 0.183724, loss_ce: 0.071200
 10%|███▏                          | 42/400 [18:09<2:29:27, 25.05s/it]2022-01-13 19:52:39,101 iteration 715 : loss : 0.144995, loss_ce: 0.058328
2022-01-13 19:52:40,513 iteration 716 : loss : 0.126813, loss_ce: 0.057493
2022-01-13 19:52:41,882 iteration 717 : loss : 0.212914, loss_ce: 0.081789
2022-01-13 19:52:43,262 iteration 718 : loss : 0.166298, loss_ce: 0.080147
2022-01-13 19:52:44,694 iteration 719 : loss : 0.151323, loss_ce: 0.065207
2022-01-13 19:52:46,061 iteration 720 : loss : 0.173798, loss_ce: 0.076818
2022-01-13 19:52:47,424 iteration 721 : loss : 0.148215, loss_ce: 0.048867
2022-01-13 19:52:48,777 iteration 722 : loss : 0.132743, loss_ce: 0.051768
2022-01-13 19:52:50,182 iteration 723 : loss : 0.154495, loss_ce: 0.071071
2022-01-13 19:52:51,529 iteration 724 : loss : 0.201924, loss_ce: 0.102095
2022-01-13 19:52:52,952 iteration 725 : loss : 0.133231, loss_ce: 0.047764
2022-01-13 19:52:54,315 iteration 726 : loss : 0.169135, loss_ce: 0.078418
2022-01-13 19:52:55,612 iteration 727 : loss : 0.106856, loss_ce: 0.040393
2022-01-13 19:52:57,007 iteration 728 : loss : 0.128541, loss_ce: 0.054097
2022-01-13 19:52:58,420 iteration 729 : loss : 0.114097, loss_ce: 0.046773
2022-01-13 19:52:59,801 iteration 730 : loss : 0.150694, loss_ce: 0.056512
2022-01-13 19:53:01,085 iteration 731 : loss : 0.110573, loss_ce: 0.045738
 11%|███▏                          | 43/400 [18:32<2:26:11, 24.57s/it]2022-01-13 19:53:02,451 iteration 732 : loss : 0.160201, loss_ce: 0.073051
2022-01-13 19:53:03,738 iteration 733 : loss : 0.148847, loss_ce: 0.079673
2022-01-13 19:53:05,146 iteration 734 : loss : 0.115001, loss_ce: 0.046516
2022-01-13 19:53:06,498 iteration 735 : loss : 0.141401, loss_ce: 0.059818
2022-01-13 19:53:07,827 iteration 736 : loss : 0.191556, loss_ce: 0.082184
2022-01-13 19:53:09,301 iteration 737 : loss : 0.142060, loss_ce: 0.066413
2022-01-13 19:53:10,585 iteration 738 : loss : 0.144112, loss_ce: 0.076366
2022-01-13 19:53:11,980 iteration 739 : loss : 0.135214, loss_ce: 0.049926
2022-01-13 19:53:13,327 iteration 740 : loss : 0.126627, loss_ce: 0.054583
2022-01-13 19:53:14,654 iteration 741 : loss : 0.136350, loss_ce: 0.053903
2022-01-13 19:53:15,940 iteration 742 : loss : 0.182415, loss_ce: 0.098957
2022-01-13 19:53:17,306 iteration 743 : loss : 0.142541, loss_ce: 0.054817
2022-01-13 19:53:18,694 iteration 744 : loss : 0.176027, loss_ce: 0.073619
2022-01-13 19:53:20,017 iteration 745 : loss : 0.171462, loss_ce: 0.039461
2022-01-13 19:53:21,345 iteration 746 : loss : 0.159758, loss_ce: 0.066794
2022-01-13 19:53:22,675 iteration 747 : loss : 0.191409, loss_ce: 0.083596
2022-01-13 19:53:23,995 iteration 748 : loss : 0.132500, loss_ce: 0.058350
 11%|███▎                          | 44/400 [18:55<2:22:49, 24.07s/it]2022-01-13 19:53:25,352 iteration 749 : loss : 0.249415, loss_ce: 0.045485
2022-01-13 19:53:26,689 iteration 750 : loss : 0.093705, loss_ce: 0.038333
2022-01-13 19:53:28,061 iteration 751 : loss : 0.116566, loss_ce: 0.039067
2022-01-13 19:53:29,401 iteration 752 : loss : 0.202408, loss_ce: 0.094445
2022-01-13 19:53:30,710 iteration 753 : loss : 0.166743, loss_ce: 0.066836
2022-01-13 19:53:32,026 iteration 754 : loss : 0.154735, loss_ce: 0.057250
2022-01-13 19:53:33,298 iteration 755 : loss : 0.164490, loss_ce: 0.081951
2022-01-13 19:53:34,580 iteration 756 : loss : 0.104917, loss_ce: 0.040170
2022-01-13 19:53:35,926 iteration 757 : loss : 0.151139, loss_ce: 0.075699
2022-01-13 19:53:37,363 iteration 758 : loss : 0.124459, loss_ce: 0.057314
2022-01-13 19:53:38,848 iteration 759 : loss : 0.162083, loss_ce: 0.066740
2022-01-13 19:53:40,191 iteration 760 : loss : 0.148213, loss_ce: 0.092267
2022-01-13 19:53:41,574 iteration 761 : loss : 0.137953, loss_ce: 0.065568
2022-01-13 19:53:42,975 iteration 762 : loss : 0.171059, loss_ce: 0.075567
2022-01-13 19:53:44,382 iteration 763 : loss : 0.123406, loss_ce: 0.054843
2022-01-13 19:53:45,719 iteration 764 : loss : 0.160408, loss_ce: 0.072390
2022-01-13 19:53:45,719 Training Data Eval:
2022-01-13 19:53:52,466   Average segmentation loss on training set: 0.2914
2022-01-13 19:53:52,467 Validation Data Eval:
2022-01-13 19:53:54,793   Average segmentation loss on validation set: 0.3958
2022-01-13 19:53:56,311 iteration 765 : loss : 0.133966, loss_ce: 0.057082
 11%|███▍                          | 45/400 [19:28<2:37:03, 26.55s/it]2022-01-13 19:53:57,790 iteration 766 : loss : 0.179328, loss_ce: 0.101020
2022-01-13 19:53:59,187 iteration 767 : loss : 0.145414, loss_ce: 0.060752
2022-01-13 19:54:00,574 iteration 768 : loss : 0.171256, loss_ce: 0.059817
2022-01-13 19:54:01,976 iteration 769 : loss : 0.147197, loss_ce: 0.067058
2022-01-13 19:54:03,264 iteration 770 : loss : 0.109389, loss_ce: 0.045843
2022-01-13 19:54:04,631 iteration 771 : loss : 0.131975, loss_ce: 0.034940
2022-01-13 19:54:06,008 iteration 772 : loss : 0.111959, loss_ce: 0.046633
2022-01-13 19:54:07,402 iteration 773 : loss : 0.119636, loss_ce: 0.035028
2022-01-13 19:54:08,869 iteration 774 : loss : 0.164777, loss_ce: 0.072549
2022-01-13 19:54:10,212 iteration 775 : loss : 0.193336, loss_ce: 0.094671
2022-01-13 19:54:11,535 iteration 776 : loss : 0.140063, loss_ce: 0.055714
2022-01-13 19:54:13,070 iteration 777 : loss : 0.155385, loss_ce: 0.070944
2022-01-13 19:54:14,363 iteration 778 : loss : 0.172957, loss_ce: 0.061165
2022-01-13 19:54:15,784 iteration 779 : loss : 0.158571, loss_ce: 0.072285
2022-01-13 19:54:17,205 iteration 780 : loss : 0.137360, loss_ce: 0.054406
2022-01-13 19:54:18,529 iteration 781 : loss : 0.139177, loss_ce: 0.063899
2022-01-13 19:54:19,814 iteration 782 : loss : 0.145881, loss_ce: 0.071510
 12%|███▍                          | 46/400 [19:51<2:31:13, 25.63s/it]2022-01-13 19:54:21,218 iteration 783 : loss : 0.167675, loss_ce: 0.083471
2022-01-13 19:54:22,542 iteration 784 : loss : 0.175900, loss_ce: 0.074162
2022-01-13 19:54:23,907 iteration 785 : loss : 0.167134, loss_ce: 0.079477
2022-01-13 19:54:25,243 iteration 786 : loss : 0.188912, loss_ce: 0.081609
2022-01-13 19:54:26,594 iteration 787 : loss : 0.141573, loss_ce: 0.069625
2022-01-13 19:54:28,007 iteration 788 : loss : 0.143923, loss_ce: 0.065962
2022-01-13 19:54:29,287 iteration 789 : loss : 0.138436, loss_ce: 0.049158
2022-01-13 19:54:30,688 iteration 790 : loss : 0.155606, loss_ce: 0.057802
2022-01-13 19:54:32,045 iteration 791 : loss : 0.121127, loss_ce: 0.045977
2022-01-13 19:54:33,345 iteration 792 : loss : 0.167086, loss_ce: 0.073736
2022-01-13 19:54:34,759 iteration 793 : loss : 0.196744, loss_ce: 0.096400
2022-01-13 19:54:36,032 iteration 794 : loss : 0.103459, loss_ce: 0.044442
2022-01-13 19:54:37,327 iteration 795 : loss : 0.185602, loss_ce: 0.077666
2022-01-13 19:54:38,624 iteration 796 : loss : 0.144363, loss_ce: 0.072267
2022-01-13 19:54:40,014 iteration 797 : loss : 0.212064, loss_ce: 0.105760
2022-01-13 19:54:41,348 iteration 798 : loss : 0.170873, loss_ce: 0.056224
2022-01-13 19:54:42,635 iteration 799 : loss : 0.100065, loss_ce: 0.047820
 12%|███▌                          | 47/400 [20:14<2:25:50, 24.79s/it]2022-01-13 19:54:44,144 iteration 800 : loss : 0.137961, loss_ce: 0.049857
2022-01-13 19:54:45,523 iteration 801 : loss : 0.136665, loss_ce: 0.060921
2022-01-13 19:54:46,883 iteration 802 : loss : 0.167951, loss_ce: 0.063267
2022-01-13 19:54:48,257 iteration 803 : loss : 0.115066, loss_ce: 0.065479
2022-01-13 19:54:49,697 iteration 804 : loss : 0.197523, loss_ce: 0.093648
2022-01-13 19:54:51,200 iteration 805 : loss : 0.093371, loss_ce: 0.034481
2022-01-13 19:54:52,540 iteration 806 : loss : 0.122482, loss_ce: 0.048240
2022-01-13 19:54:53,851 iteration 807 : loss : 0.108838, loss_ce: 0.039630
2022-01-13 19:54:55,243 iteration 808 : loss : 0.168991, loss_ce: 0.088567
2022-01-13 19:54:56,609 iteration 809 : loss : 0.103724, loss_ce: 0.037391
2022-01-13 19:54:57,939 iteration 810 : loss : 0.155410, loss_ce: 0.060422
2022-01-13 19:54:59,234 iteration 811 : loss : 0.169865, loss_ce: 0.099524
2022-01-13 19:55:00,558 iteration 812 : loss : 0.113352, loss_ce: 0.053052
2022-01-13 19:55:01,912 iteration 813 : loss : 0.197769, loss_ce: 0.068154
2022-01-13 19:55:03,376 iteration 814 : loss : 0.148724, loss_ce: 0.050365
2022-01-13 19:55:04,797 iteration 815 : loss : 0.177309, loss_ce: 0.078970
2022-01-13 19:55:06,171 iteration 816 : loss : 0.138817, loss_ce: 0.055834
 12%|███▌                          | 48/400 [20:37<2:23:12, 24.41s/it]2022-01-13 19:55:07,577 iteration 817 : loss : 0.150882, loss_ce: 0.070243
2022-01-13 19:55:08,883 iteration 818 : loss : 0.123197, loss_ce: 0.056021
2022-01-13 19:55:10,240 iteration 819 : loss : 0.106955, loss_ce: 0.040160
2022-01-13 19:55:11,530 iteration 820 : loss : 0.108906, loss_ce: 0.048721
2022-01-13 19:55:12,939 iteration 821 : loss : 0.109102, loss_ce: 0.044232
2022-01-13 19:55:14,332 iteration 822 : loss : 0.149840, loss_ce: 0.059003
2022-01-13 19:55:15,643 iteration 823 : loss : 0.104491, loss_ce: 0.042961
2022-01-13 19:55:16,945 iteration 824 : loss : 0.187128, loss_ce: 0.084211
2022-01-13 19:55:18,295 iteration 825 : loss : 0.111578, loss_ce: 0.045473
2022-01-13 19:55:19,636 iteration 826 : loss : 0.145509, loss_ce: 0.046372
2022-01-13 19:55:20,983 iteration 827 : loss : 0.183816, loss_ce: 0.065283
2022-01-13 19:55:22,332 iteration 828 : loss : 0.143704, loss_ce: 0.059590
2022-01-13 19:55:23,707 iteration 829 : loss : 0.149678, loss_ce: 0.062172
2022-01-13 19:55:25,115 iteration 830 : loss : 0.116018, loss_ce: 0.041533
2022-01-13 19:55:26,467 iteration 831 : loss : 0.142893, loss_ce: 0.064592
2022-01-13 19:55:27,802 iteration 832 : loss : 0.101946, loss_ce: 0.037857
2022-01-13 19:55:29,211 iteration 833 : loss : 0.145678, loss_ce: 0.070980
 12%|███▋                          | 49/400 [21:00<2:20:24, 24.00s/it]2022-01-13 19:55:30,628 iteration 834 : loss : 0.124563, loss_ce: 0.057380
2022-01-13 19:55:31,898 iteration 835 : loss : 0.149382, loss_ce: 0.050699
2022-01-13 19:55:33,258 iteration 836 : loss : 0.103786, loss_ce: 0.049641
2022-01-13 19:55:34,563 iteration 837 : loss : 0.124162, loss_ce: 0.069468
2022-01-13 19:55:35,843 iteration 838 : loss : 0.111292, loss_ce: 0.047867
2022-01-13 19:55:37,219 iteration 839 : loss : 0.132889, loss_ce: 0.059197
2022-01-13 19:55:38,561 iteration 840 : loss : 0.133074, loss_ce: 0.045890
2022-01-13 19:55:39,868 iteration 841 : loss : 0.154526, loss_ce: 0.063836
2022-01-13 19:55:41,206 iteration 842 : loss : 0.110816, loss_ce: 0.044545
2022-01-13 19:55:42,649 iteration 843 : loss : 0.107660, loss_ce: 0.042560
2022-01-13 19:55:43,991 iteration 844 : loss : 0.124827, loss_ce: 0.049418
2022-01-13 19:55:45,374 iteration 845 : loss : 0.158027, loss_ce: 0.054782
2022-01-13 19:55:46,845 iteration 846 : loss : 0.129084, loss_ce: 0.068030
2022-01-13 19:55:48,218 iteration 847 : loss : 0.107345, loss_ce: 0.041662
2022-01-13 19:55:49,491 iteration 848 : loss : 0.121485, loss_ce: 0.056903
2022-01-13 19:55:50,859 iteration 849 : loss : 0.128823, loss_ce: 0.058539
2022-01-13 19:55:50,859 Training Data Eval:
2022-01-13 19:55:57,617   Average segmentation loss on training set: 0.1439
2022-01-13 19:55:57,618 Validation Data Eval:
2022-01-13 19:55:59,947   Average segmentation loss on validation set: 0.1855
2022-01-13 19:56:01,339 iteration 850 : loss : 0.220182, loss_ce: 0.101088
 12%|███▊                          | 50/400 [21:33<2:34:13, 26.44s/it]2022-01-13 19:56:02,805 iteration 851 : loss : 0.118485, loss_ce: 0.047919
2022-01-13 19:56:04,144 iteration 852 : loss : 0.101916, loss_ce: 0.044784
2022-01-13 19:56:05,571 iteration 853 : loss : 0.122595, loss_ce: 0.062597
2022-01-13 19:56:06,955 iteration 854 : loss : 0.096943, loss_ce: 0.031443
2022-01-13 19:56:08,333 iteration 855 : loss : 0.126894, loss_ce: 0.054273
2022-01-13 19:56:09,731 iteration 856 : loss : 0.141204, loss_ce: 0.055415
2022-01-13 19:56:11,062 iteration 857 : loss : 0.118692, loss_ce: 0.054463
2022-01-13 19:56:12,338 iteration 858 : loss : 0.125006, loss_ce: 0.067697
2022-01-13 19:56:13,677 iteration 859 : loss : 0.132356, loss_ce: 0.046291
2022-01-13 19:56:14,979 iteration 860 : loss : 0.125618, loss_ce: 0.045766
2022-01-13 19:56:16,392 iteration 861 : loss : 0.119314, loss_ce: 0.052554
2022-01-13 19:56:17,677 iteration 862 : loss : 0.118112, loss_ce: 0.045178
2022-01-13 19:56:19,102 iteration 863 : loss : 0.172000, loss_ce: 0.083932
2022-01-13 19:56:20,494 iteration 864 : loss : 0.113182, loss_ce: 0.051794
2022-01-13 19:56:21,779 iteration 865 : loss : 0.112121, loss_ce: 0.048462
2022-01-13 19:56:23,198 iteration 866 : loss : 0.146360, loss_ce: 0.067418
2022-01-13 19:56:24,492 iteration 867 : loss : 0.065027, loss_ce: 0.027113
 13%|███▊                          | 51/400 [21:56<2:28:03, 25.45s/it]2022-01-13 19:56:25,942 iteration 868 : loss : 0.163617, loss_ce: 0.062118
2022-01-13 19:56:27,300 iteration 869 : loss : 0.117068, loss_ce: 0.052808
2022-01-13 19:56:28,605 iteration 870 : loss : 0.105525, loss_ce: 0.043424
2022-01-13 19:56:29,910 iteration 871 : loss : 0.105135, loss_ce: 0.045308
2022-01-13 19:56:31,229 iteration 872 : loss : 0.085767, loss_ce: 0.041013
2022-01-13 19:56:32,650 iteration 873 : loss : 0.110487, loss_ce: 0.041815
2022-01-13 19:56:33,924 iteration 874 : loss : 0.088721, loss_ce: 0.041892
2022-01-13 19:56:35,413 iteration 875 : loss : 0.130678, loss_ce: 0.051399
2022-01-13 19:56:36,767 iteration 876 : loss : 0.072939, loss_ce: 0.033447
2022-01-13 19:56:38,030 iteration 877 : loss : 0.071571, loss_ce: 0.028326
2022-01-13 19:56:39,428 iteration 878 : loss : 0.113765, loss_ce: 0.050614
2022-01-13 19:56:40,754 iteration 879 : loss : 0.153630, loss_ce: 0.075202
2022-01-13 19:56:42,133 iteration 880 : loss : 0.099570, loss_ce: 0.038565
2022-01-13 19:56:43,453 iteration 881 : loss : 0.192802, loss_ce: 0.099933
2022-01-13 19:56:44,843 iteration 882 : loss : 0.168002, loss_ce: 0.068628
2022-01-13 19:56:46,198 iteration 883 : loss : 0.132496, loss_ce: 0.066619
2022-01-13 19:56:47,643 iteration 884 : loss : 0.133678, loss_ce: 0.064848
 13%|███▉                          | 52/400 [22:19<2:23:37, 24.76s/it]2022-01-13 19:56:49,094 iteration 885 : loss : 0.110586, loss_ce: 0.050600
2022-01-13 19:56:50,482 iteration 886 : loss : 0.128926, loss_ce: 0.049476
2022-01-13 19:56:51,875 iteration 887 : loss : 0.200518, loss_ce: 0.099058
2022-01-13 19:56:53,241 iteration 888 : loss : 0.107880, loss_ce: 0.045135
2022-01-13 19:56:54,659 iteration 889 : loss : 0.110335, loss_ce: 0.041487
2022-01-13 19:56:56,124 iteration 890 : loss : 0.127397, loss_ce: 0.048402
2022-01-13 19:56:57,496 iteration 891 : loss : 0.097105, loss_ce: 0.041042
2022-01-13 19:56:58,860 iteration 892 : loss : 0.142066, loss_ce: 0.071637
2022-01-13 19:57:00,204 iteration 893 : loss : 0.130014, loss_ce: 0.049495
2022-01-13 19:57:01,667 iteration 894 : loss : 0.120384, loss_ce: 0.049437
2022-01-13 19:57:03,000 iteration 895 : loss : 0.210967, loss_ce: 0.070644
2022-01-13 19:57:04,420 iteration 896 : loss : 0.171761, loss_ce: 0.066727
2022-01-13 19:57:05,861 iteration 897 : loss : 0.145805, loss_ce: 0.069474
2022-01-13 19:57:07,208 iteration 898 : loss : 0.120979, loss_ce: 0.059368
2022-01-13 19:57:08,553 iteration 899 : loss : 0.148321, loss_ce: 0.072683
2022-01-13 19:57:09,855 iteration 900 : loss : 0.125272, loss_ce: 0.057031
2022-01-13 19:57:11,185 iteration 901 : loss : 0.212928, loss_ce: 0.092977
 13%|███▉                          | 53/400 [22:42<2:21:04, 24.39s/it]2022-01-13 19:57:12,625 iteration 902 : loss : 0.181534, loss_ce: 0.091399
2022-01-13 19:57:14,071 iteration 903 : loss : 0.209374, loss_ce: 0.091461
2022-01-13 19:57:15,469 iteration 904 : loss : 0.198967, loss_ce: 0.080448
2022-01-13 19:57:16,846 iteration 905 : loss : 0.194915, loss_ce: 0.090821
2022-01-13 19:57:18,204 iteration 906 : loss : 0.183084, loss_ce: 0.079460
2022-01-13 19:57:19,626 iteration 907 : loss : 0.209738, loss_ce: 0.070714
2022-01-13 19:57:20,894 iteration 908 : loss : 0.174372, loss_ce: 0.075028
2022-01-13 19:57:22,276 iteration 909 : loss : 0.170093, loss_ce: 0.078629
2022-01-13 19:57:23,566 iteration 910 : loss : 0.207452, loss_ce: 0.096748
2022-01-13 19:57:24,916 iteration 911 : loss : 0.144976, loss_ce: 0.062491
2022-01-13 19:57:26,258 iteration 912 : loss : 0.186292, loss_ce: 0.078755
2022-01-13 19:57:27,592 iteration 913 : loss : 0.249339, loss_ce: 0.098672
2022-01-13 19:57:28,937 iteration 914 : loss : 0.245940, loss_ce: 0.120394
2022-01-13 19:57:30,253 iteration 915 : loss : 0.233922, loss_ce: 0.086159
2022-01-13 19:57:31,575 iteration 916 : loss : 0.118963, loss_ce: 0.048711
2022-01-13 19:57:32,954 iteration 917 : loss : 0.157243, loss_ce: 0.071412
2022-01-13 19:57:34,352 iteration 918 : loss : 0.173170, loss_ce: 0.073129
 14%|████                          | 54/400 [23:06<2:18:32, 24.02s/it]2022-01-13 19:57:35,808 iteration 919 : loss : 0.156791, loss_ce: 0.075093
2022-01-13 19:57:37,185 iteration 920 : loss : 0.148348, loss_ce: 0.068809
2022-01-13 19:57:38,588 iteration 921 : loss : 0.155976, loss_ce: 0.061228
2022-01-13 19:57:40,007 iteration 922 : loss : 0.159609, loss_ce: 0.082008
2022-01-13 19:57:41,342 iteration 923 : loss : 0.137750, loss_ce: 0.070194
2022-01-13 19:57:42,748 iteration 924 : loss : 0.215847, loss_ce: 0.076998
2022-01-13 19:57:44,109 iteration 925 : loss : 0.130460, loss_ce: 0.049457
2022-01-13 19:57:45,520 iteration 926 : loss : 0.146751, loss_ce: 0.068019
2022-01-13 19:57:46,812 iteration 927 : loss : 0.188653, loss_ce: 0.076065
2022-01-13 19:57:48,159 iteration 928 : loss : 0.117460, loss_ce: 0.050885
2022-01-13 19:57:49,610 iteration 929 : loss : 0.128898, loss_ce: 0.047980
2022-01-13 19:57:50,988 iteration 930 : loss : 0.128812, loss_ce: 0.052204
2022-01-13 19:57:52,368 iteration 931 : loss : 0.165060, loss_ce: 0.046090
2022-01-13 19:57:53,734 iteration 932 : loss : 0.139952, loss_ce: 0.055066
2022-01-13 19:57:55,064 iteration 933 : loss : 0.160610, loss_ce: 0.063622
2022-01-13 19:57:56,420 iteration 934 : loss : 0.126625, loss_ce: 0.063692
2022-01-13 19:57:56,420 Training Data Eval:
2022-01-13 19:58:03,163   Average segmentation loss on training set: 0.1071
2022-01-13 19:58:03,163 Validation Data Eval:
2022-01-13 19:58:05,486   Average segmentation loss on validation set: 0.1333
2022-01-13 19:58:11,352 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 19:58:12,887 iteration 935 : loss : 0.177698, loss_ce: 0.064970
 14%|████▏                         | 55/400 [23:44<2:43:10, 28.38s/it]2022-01-13 19:58:14,275 iteration 936 : loss : 0.121750, loss_ce: 0.040818
2022-01-13 19:58:15,647 iteration 937 : loss : 0.121139, loss_ce: 0.040351
2022-01-13 19:58:17,084 iteration 938 : loss : 0.119594, loss_ce: 0.048056
2022-01-13 19:58:18,401 iteration 939 : loss : 0.150077, loss_ce: 0.057237
2022-01-13 19:58:19,775 iteration 940 : loss : 0.157380, loss_ce: 0.073885
2022-01-13 19:58:21,234 iteration 941 : loss : 0.160438, loss_ce: 0.061530
2022-01-13 19:58:22,554 iteration 942 : loss : 0.144151, loss_ce: 0.061476
2022-01-13 19:58:23,896 iteration 943 : loss : 0.132937, loss_ce: 0.068804
2022-01-13 19:58:25,213 iteration 944 : loss : 0.120945, loss_ce: 0.047660
2022-01-13 19:58:26,543 iteration 945 : loss : 0.131824, loss_ce: 0.057784
2022-01-13 19:58:27,867 iteration 946 : loss : 0.109550, loss_ce: 0.050652
2022-01-13 19:58:29,184 iteration 947 : loss : 0.157874, loss_ce: 0.064696
2022-01-13 19:58:30,496 iteration 948 : loss : 0.146580, loss_ce: 0.070386
2022-01-13 19:58:31,838 iteration 949 : loss : 0.112623, loss_ce: 0.047031
2022-01-13 19:58:33,172 iteration 950 : loss : 0.156537, loss_ce: 0.079497
2022-01-13 19:58:34,563 iteration 951 : loss : 0.136319, loss_ce: 0.074524
2022-01-13 19:58:35,872 iteration 952 : loss : 0.101781, loss_ce: 0.044153
 14%|████▏                         | 56/400 [24:07<2:33:25, 26.76s/it]2022-01-13 19:58:37,306 iteration 953 : loss : 0.108650, loss_ce: 0.044633
2022-01-13 19:58:38,710 iteration 954 : loss : 0.100023, loss_ce: 0.042949
2022-01-13 19:58:40,024 iteration 955 : loss : 0.099259, loss_ce: 0.043956
2022-01-13 19:58:41,416 iteration 956 : loss : 0.112087, loss_ce: 0.045212
2022-01-13 19:58:42,790 iteration 957 : loss : 0.143468, loss_ce: 0.053663
2022-01-13 19:58:44,176 iteration 958 : loss : 0.128541, loss_ce: 0.045068
2022-01-13 19:58:45,634 iteration 959 : loss : 0.186435, loss_ce: 0.079665
2022-01-13 19:58:47,145 iteration 960 : loss : 0.139042, loss_ce: 0.061490
2022-01-13 19:58:48,473 iteration 961 : loss : 0.176504, loss_ce: 0.061769
2022-01-13 19:58:49,770 iteration 962 : loss : 0.128056, loss_ce: 0.037793
2022-01-13 19:58:51,204 iteration 963 : loss : 0.133639, loss_ce: 0.047238
2022-01-13 19:58:52,603 iteration 964 : loss : 0.134969, loss_ce: 0.072032
2022-01-13 19:58:53,945 iteration 965 : loss : 0.112212, loss_ce: 0.050569
2022-01-13 19:58:55,312 iteration 966 : loss : 0.126011, loss_ce: 0.056744
2022-01-13 19:58:56,691 iteration 967 : loss : 0.112623, loss_ce: 0.045552
2022-01-13 19:58:58,008 iteration 968 : loss : 0.149828, loss_ce: 0.054080
2022-01-13 19:58:59,388 iteration 969 : loss : 0.108236, loss_ce: 0.045871
 14%|████▎                         | 57/400 [24:31<2:27:25, 25.79s/it]2022-01-13 19:59:00,789 iteration 970 : loss : 0.124802, loss_ce: 0.063931
2022-01-13 19:59:02,174 iteration 971 : loss : 0.171988, loss_ce: 0.063207
2022-01-13 19:59:03,475 iteration 972 : loss : 0.107555, loss_ce: 0.050046
2022-01-13 19:59:04,855 iteration 973 : loss : 0.119561, loss_ce: 0.042207
2022-01-13 19:59:06,158 iteration 974 : loss : 0.130511, loss_ce: 0.056352
2022-01-13 19:59:07,561 iteration 975 : loss : 0.170686, loss_ce: 0.065702
2022-01-13 19:59:08,902 iteration 976 : loss : 0.118411, loss_ce: 0.053520
2022-01-13 19:59:10,250 iteration 977 : loss : 0.101215, loss_ce: 0.034261
2022-01-13 19:59:11,631 iteration 978 : loss : 0.082074, loss_ce: 0.032844
2022-01-13 19:59:12,967 iteration 979 : loss : 0.180229, loss_ce: 0.098836
2022-01-13 19:59:14,309 iteration 980 : loss : 0.104362, loss_ce: 0.043881
2022-01-13 19:59:15,760 iteration 981 : loss : 0.106617, loss_ce: 0.051043
2022-01-13 19:59:17,099 iteration 982 : loss : 0.114991, loss_ce: 0.061354
2022-01-13 19:59:18,513 iteration 983 : loss : 0.166413, loss_ce: 0.052499
2022-01-13 19:59:19,801 iteration 984 : loss : 0.133771, loss_ce: 0.063328
2022-01-13 19:59:21,162 iteration 985 : loss : 0.107592, loss_ce: 0.043075
2022-01-13 19:59:22,575 iteration 986 : loss : 0.151629, loss_ce: 0.066711
 14%|████▎                         | 58/400 [24:54<2:22:33, 25.01s/it]2022-01-13 19:59:24,056 iteration 987 : loss : 0.122126, loss_ce: 0.056263
2022-01-13 19:59:25,448 iteration 988 : loss : 0.144682, loss_ce: 0.069101
2022-01-13 19:59:26,824 iteration 989 : loss : 0.148946, loss_ce: 0.065466
2022-01-13 19:59:28,184 iteration 990 : loss : 0.148715, loss_ce: 0.070290
2022-01-13 19:59:29,538 iteration 991 : loss : 0.119947, loss_ce: 0.056613
2022-01-13 19:59:30,976 iteration 992 : loss : 0.086453, loss_ce: 0.041559
2022-01-13 19:59:32,367 iteration 993 : loss : 0.117674, loss_ce: 0.042715
2022-01-13 19:59:33,839 iteration 994 : loss : 0.134067, loss_ce: 0.069254
2022-01-13 19:59:35,219 iteration 995 : loss : 0.175526, loss_ce: 0.059478
2022-01-13 19:59:36,645 iteration 996 : loss : 0.107685, loss_ce: 0.045967
2022-01-13 19:59:38,064 iteration 997 : loss : 0.222800, loss_ce: 0.100179
2022-01-13 19:59:39,379 iteration 998 : loss : 0.157185, loss_ce: 0.064630
2022-01-13 19:59:40,795 iteration 999 : loss : 0.113581, loss_ce: 0.049328
2022-01-13 19:59:42,122 iteration 1000 : loss : 0.148630, loss_ce: 0.049910
2022-01-13 19:59:43,458 iteration 1001 : loss : 0.177280, loss_ce: 0.051284
2022-01-13 19:59:44,920 iteration 1002 : loss : 0.134508, loss_ce: 0.064238
2022-01-13 19:59:46,361 iteration 1003 : loss : 0.138572, loss_ce: 0.054998
 15%|████▍                         | 59/400 [25:18<2:20:03, 24.64s/it]2022-01-13 19:59:47,795 iteration 1004 : loss : 0.202637, loss_ce: 0.098981
2022-01-13 19:59:49,151 iteration 1005 : loss : 0.125950, loss_ce: 0.050271
2022-01-13 19:59:50,602 iteration 1006 : loss : 0.174714, loss_ce: 0.084779
2022-01-13 19:59:51,931 iteration 1007 : loss : 0.119530, loss_ce: 0.061190
2022-01-13 19:59:53,248 iteration 1008 : loss : 0.210446, loss_ce: 0.096267
2022-01-13 19:59:54,568 iteration 1009 : loss : 0.137345, loss_ce: 0.055054
2022-01-13 19:59:55,894 iteration 1010 : loss : 0.168161, loss_ce: 0.064986
2022-01-13 19:59:57,311 iteration 1011 : loss : 0.132641, loss_ce: 0.060056
2022-01-13 19:59:58,656 iteration 1012 : loss : 0.094376, loss_ce: 0.037776
2022-01-13 19:59:59,963 iteration 1013 : loss : 0.097062, loss_ce: 0.035984
2022-01-13 20:00:01,336 iteration 1014 : loss : 0.153626, loss_ce: 0.071706
2022-01-13 20:00:02,633 iteration 1015 : loss : 0.128689, loss_ce: 0.051218
2022-01-13 20:00:04,007 iteration 1016 : loss : 0.120446, loss_ce: 0.053155
2022-01-13 20:00:05,310 iteration 1017 : loss : 0.073382, loss_ce: 0.029303
2022-01-13 20:00:06,578 iteration 1018 : loss : 0.114921, loss_ce: 0.045532
2022-01-13 20:00:07,921 iteration 1019 : loss : 0.146204, loss_ce: 0.067813
2022-01-13 20:00:07,922 Training Data Eval:
2022-01-13 20:00:14,662   Average segmentation loss on training set: 0.0904
2022-01-13 20:00:14,663 Validation Data Eval:
2022-01-13 20:00:16,987   Average segmentation loss on validation set: 0.1368
2022-01-13 20:00:18,293 iteration 1020 : loss : 0.109223, loss_ce: 0.043829
 15%|████▌                         | 60/400 [25:50<2:32:02, 26.83s/it]2022-01-13 20:00:19,784 iteration 1021 : loss : 0.165646, loss_ce: 0.056805
2022-01-13 20:00:21,137 iteration 1022 : loss : 0.130717, loss_ce: 0.062388
2022-01-13 20:00:22,498 iteration 1023 : loss : 0.176757, loss_ce: 0.051683
2022-01-13 20:00:23,914 iteration 1024 : loss : 0.089375, loss_ce: 0.035938
2022-01-13 20:00:25,318 iteration 1025 : loss : 0.100981, loss_ce: 0.053493
2022-01-13 20:00:26,593 iteration 1026 : loss : 0.095883, loss_ce: 0.042473
2022-01-13 20:00:27,997 iteration 1027 : loss : 0.112479, loss_ce: 0.040068
2022-01-13 20:00:29,393 iteration 1028 : loss : 0.159438, loss_ce: 0.074254
2022-01-13 20:00:30,741 iteration 1029 : loss : 0.084477, loss_ce: 0.039611
2022-01-13 20:00:32,102 iteration 1030 : loss : 0.123012, loss_ce: 0.055809
2022-01-13 20:00:33,516 iteration 1031 : loss : 0.160951, loss_ce: 0.088999
2022-01-13 20:00:34,901 iteration 1032 : loss : 0.151069, loss_ce: 0.077511
2022-01-13 20:00:36,235 iteration 1033 : loss : 0.102017, loss_ce: 0.039807
2022-01-13 20:00:37,661 iteration 1034 : loss : 0.130795, loss_ce: 0.060590
2022-01-13 20:00:39,043 iteration 1035 : loss : 0.111713, loss_ce: 0.049705
2022-01-13 20:00:40,425 iteration 1036 : loss : 0.120384, loss_ce: 0.059092
2022-01-13 20:00:41,754 iteration 1037 : loss : 0.151433, loss_ce: 0.058328
 15%|████▌                         | 61/400 [26:13<2:25:51, 25.82s/it]2022-01-13 20:00:43,185 iteration 1038 : loss : 0.099719, loss_ce: 0.045556
2022-01-13 20:00:44,543 iteration 1039 : loss : 0.104647, loss_ce: 0.052014
2022-01-13 20:00:45,941 iteration 1040 : loss : 0.132049, loss_ce: 0.068099
2022-01-13 20:00:47,321 iteration 1041 : loss : 0.085135, loss_ce: 0.039003
2022-01-13 20:00:48,712 iteration 1042 : loss : 0.090466, loss_ce: 0.040348
2022-01-13 20:00:50,081 iteration 1043 : loss : 0.175713, loss_ce: 0.064649
2022-01-13 20:00:51,475 iteration 1044 : loss : 0.086975, loss_ce: 0.037935
2022-01-13 20:00:52,755 iteration 1045 : loss : 0.114134, loss_ce: 0.054408
2022-01-13 20:00:54,070 iteration 1046 : loss : 0.152697, loss_ce: 0.050793
2022-01-13 20:00:55,475 iteration 1047 : loss : 0.149420, loss_ce: 0.058126
2022-01-13 20:00:56,841 iteration 1048 : loss : 0.140465, loss_ce: 0.056767
2022-01-13 20:00:58,213 iteration 1049 : loss : 0.172070, loss_ce: 0.075162
2022-01-13 20:00:59,625 iteration 1050 : loss : 0.138165, loss_ce: 0.042218
2022-01-13 20:01:00,983 iteration 1051 : loss : 0.104039, loss_ce: 0.045616
2022-01-13 20:01:02,346 iteration 1052 : loss : 0.171453, loss_ce: 0.070568
2022-01-13 20:01:03,638 iteration 1053 : loss : 0.131565, loss_ce: 0.043541
2022-01-13 20:01:05,066 iteration 1054 : loss : 0.106550, loss_ce: 0.055549
 16%|████▋                         | 62/400 [26:36<2:21:12, 25.07s/it]2022-01-13 20:01:06,489 iteration 1055 : loss : 0.080613, loss_ce: 0.027605
2022-01-13 20:01:07,825 iteration 1056 : loss : 0.110425, loss_ce: 0.055936
2022-01-13 20:01:09,161 iteration 1057 : loss : 0.160361, loss_ce: 0.085563
2022-01-13 20:01:10,515 iteration 1058 : loss : 0.118461, loss_ce: 0.058012
2022-01-13 20:01:11,797 iteration 1059 : loss : 0.097646, loss_ce: 0.036937
2022-01-13 20:01:13,145 iteration 1060 : loss : 0.084337, loss_ce: 0.032249
2022-01-13 20:01:14,528 iteration 1061 : loss : 0.117428, loss_ce: 0.060433
2022-01-13 20:01:15,907 iteration 1062 : loss : 0.124964, loss_ce: 0.050859
2022-01-13 20:01:17,336 iteration 1063 : loss : 0.145628, loss_ce: 0.052041
2022-01-13 20:01:18,690 iteration 1064 : loss : 0.124221, loss_ce: 0.040388
2022-01-13 20:01:19,991 iteration 1065 : loss : 0.097793, loss_ce: 0.043230
2022-01-13 20:01:21,386 iteration 1066 : loss : 0.133470, loss_ce: 0.058473
2022-01-13 20:01:22,728 iteration 1067 : loss : 0.182230, loss_ce: 0.050969
2022-01-13 20:01:24,141 iteration 1068 : loss : 0.116374, loss_ce: 0.053198
2022-01-13 20:01:25,528 iteration 1069 : loss : 0.146851, loss_ce: 0.067179
2022-01-13 20:01:26,883 iteration 1070 : loss : 0.092813, loss_ce: 0.038860
2022-01-13 20:01:28,231 iteration 1071 : loss : 0.105526, loss_ce: 0.050771
 16%|████▋                         | 63/400 [26:59<2:17:34, 24.50s/it]2022-01-13 20:01:29,747 iteration 1072 : loss : 0.097450, loss_ce: 0.037239
2022-01-13 20:01:31,090 iteration 1073 : loss : 0.182226, loss_ce: 0.046894
2022-01-13 20:01:32,436 iteration 1074 : loss : 0.110665, loss_ce: 0.050382
2022-01-13 20:01:33,826 iteration 1075 : loss : 0.119791, loss_ce: 0.045590
2022-01-13 20:01:35,135 iteration 1076 : loss : 0.098822, loss_ce: 0.040729
2022-01-13 20:01:36,475 iteration 1077 : loss : 0.104465, loss_ce: 0.038375
2022-01-13 20:01:37,897 iteration 1078 : loss : 0.156689, loss_ce: 0.089419
2022-01-13 20:01:39,220 iteration 1079 : loss : 0.098119, loss_ce: 0.042623
2022-01-13 20:01:40,528 iteration 1080 : loss : 0.100700, loss_ce: 0.043734
2022-01-13 20:01:41,910 iteration 1081 : loss : 0.100143, loss_ce: 0.034124
2022-01-13 20:01:43,292 iteration 1082 : loss : 0.098663, loss_ce: 0.050872
2022-01-13 20:01:44,702 iteration 1083 : loss : 0.124124, loss_ce: 0.055467
2022-01-13 20:01:46,078 iteration 1084 : loss : 0.124144, loss_ce: 0.069755
2022-01-13 20:01:47,514 iteration 1085 : loss : 0.108425, loss_ce: 0.046549
2022-01-13 20:01:48,853 iteration 1086 : loss : 0.115115, loss_ce: 0.053916
2022-01-13 20:01:50,211 iteration 1087 : loss : 0.124373, loss_ce: 0.054567
2022-01-13 20:01:51,625 iteration 1088 : loss : 0.101483, loss_ce: 0.051966
 16%|████▊                         | 64/400 [27:23<2:15:20, 24.17s/it]2022-01-13 20:01:53,020 iteration 1089 : loss : 0.141917, loss_ce: 0.056959
2022-01-13 20:01:54,358 iteration 1090 : loss : 0.120305, loss_ce: 0.063906
2022-01-13 20:01:55,716 iteration 1091 : loss : 0.108543, loss_ce: 0.052011
2022-01-13 20:01:57,074 iteration 1092 : loss : 0.066575, loss_ce: 0.029934
2022-01-13 20:01:58,451 iteration 1093 : loss : 0.118858, loss_ce: 0.050981
2022-01-13 20:01:59,877 iteration 1094 : loss : 0.095530, loss_ce: 0.039514
2022-01-13 20:02:01,192 iteration 1095 : loss : 0.094945, loss_ce: 0.046285
2022-01-13 20:02:02,644 iteration 1096 : loss : 0.101028, loss_ce: 0.038442
2022-01-13 20:02:04,028 iteration 1097 : loss : 0.120373, loss_ce: 0.048678
2022-01-13 20:02:05,351 iteration 1098 : loss : 0.072640, loss_ce: 0.034869
2022-01-13 20:02:06,737 iteration 1099 : loss : 0.137400, loss_ce: 0.044463
2022-01-13 20:02:08,174 iteration 1100 : loss : 0.112858, loss_ce: 0.048302
2022-01-13 20:02:09,531 iteration 1101 : loss : 0.101644, loss_ce: 0.047602
2022-01-13 20:02:10,964 iteration 1102 : loss : 0.144063, loss_ce: 0.047536
2022-01-13 20:02:12,312 iteration 1103 : loss : 0.139207, loss_ce: 0.055420
2022-01-13 20:02:13,657 iteration 1104 : loss : 0.136655, loss_ce: 0.055654
2022-01-13 20:02:13,657 Training Data Eval:
2022-01-13 20:02:20,418   Average segmentation loss on training set: 0.1268
2022-01-13 20:02:20,419 Validation Data Eval:
2022-01-13 20:02:22,751   Average segmentation loss on validation set: 0.1992
2022-01-13 20:02:24,163 iteration 1105 : loss : 0.103124, loss_ce: 0.034748
 16%|████▉                         | 65/400 [27:55<2:28:56, 26.68s/it]2022-01-13 20:02:25,517 iteration 1106 : loss : 0.127064, loss_ce: 0.051875
2022-01-13 20:02:26,856 iteration 1107 : loss : 0.107872, loss_ce: 0.052130
2022-01-13 20:02:28,224 iteration 1108 : loss : 0.124195, loss_ce: 0.035745
2022-01-13 20:02:29,525 iteration 1109 : loss : 0.112785, loss_ce: 0.051513
2022-01-13 20:02:30,890 iteration 1110 : loss : 0.115415, loss_ce: 0.050580
2022-01-13 20:02:32,228 iteration 1111 : loss : 0.082905, loss_ce: 0.035488
2022-01-13 20:02:33,569 iteration 1112 : loss : 0.094567, loss_ce: 0.039288
2022-01-13 20:02:34,896 iteration 1113 : loss : 0.113209, loss_ce: 0.041561
2022-01-13 20:02:36,310 iteration 1114 : loss : 0.095953, loss_ce: 0.048048
2022-01-13 20:02:37,789 iteration 1115 : loss : 0.125976, loss_ce: 0.060671
2022-01-13 20:02:39,197 iteration 1116 : loss : 0.160697, loss_ce: 0.054895
2022-01-13 20:02:40,677 iteration 1117 : loss : 0.098027, loss_ce: 0.038671
2022-01-13 20:02:42,084 iteration 1118 : loss : 0.134115, loss_ce: 0.054611
2022-01-13 20:02:43,424 iteration 1119 : loss : 0.085303, loss_ce: 0.040612
2022-01-13 20:02:44,751 iteration 1120 : loss : 0.127825, loss_ce: 0.042040
2022-01-13 20:02:46,130 iteration 1121 : loss : 0.140807, loss_ce: 0.047076
2022-01-13 20:02:47,496 iteration 1122 : loss : 0.138950, loss_ce: 0.065501
 16%|████▉                         | 66/400 [28:19<2:22:54, 25.67s/it]2022-01-13 20:02:48,916 iteration 1123 : loss : 0.167681, loss_ce: 0.083369
2022-01-13 20:02:50,313 iteration 1124 : loss : 0.105412, loss_ce: 0.050337
2022-01-13 20:02:51,708 iteration 1125 : loss : 0.091008, loss_ce: 0.031777
2022-01-13 20:02:53,055 iteration 1126 : loss : 0.126065, loss_ce: 0.047663
2022-01-13 20:02:54,391 iteration 1127 : loss : 0.121599, loss_ce: 0.056028
2022-01-13 20:02:55,810 iteration 1128 : loss : 0.123812, loss_ce: 0.048218
2022-01-13 20:02:57,227 iteration 1129 : loss : 0.110156, loss_ce: 0.040140
2022-01-13 20:02:58,569 iteration 1130 : loss : 0.099482, loss_ce: 0.051140
2022-01-13 20:02:59,918 iteration 1131 : loss : 0.101557, loss_ce: 0.042551
2022-01-13 20:03:01,318 iteration 1132 : loss : 0.110991, loss_ce: 0.044238
2022-01-13 20:03:02,623 iteration 1133 : loss : 0.094149, loss_ce: 0.048071
2022-01-13 20:03:03,981 iteration 1134 : loss : 0.140009, loss_ce: 0.052200
2022-01-13 20:03:05,309 iteration 1135 : loss : 0.092248, loss_ce: 0.039077
2022-01-13 20:03:06,660 iteration 1136 : loss : 0.060463, loss_ce: 0.024133
2022-01-13 20:03:07,990 iteration 1137 : loss : 0.155630, loss_ce: 0.080783
2022-01-13 20:03:09,388 iteration 1138 : loss : 0.103969, loss_ce: 0.044043
2022-01-13 20:03:10,765 iteration 1139 : loss : 0.094243, loss_ce: 0.033306
 17%|█████                         | 67/400 [28:42<2:18:29, 24.95s/it]2022-01-13 20:03:12,190 iteration 1140 : loss : 0.091354, loss_ce: 0.038627
2022-01-13 20:03:13,518 iteration 1141 : loss : 0.093385, loss_ce: 0.040813
2022-01-13 20:03:14,933 iteration 1142 : loss : 0.107620, loss_ce: 0.052562
2022-01-13 20:03:16,288 iteration 1143 : loss : 0.091751, loss_ce: 0.035627
2022-01-13 20:03:17,684 iteration 1144 : loss : 0.131172, loss_ce: 0.068558
2022-01-13 20:03:18,998 iteration 1145 : loss : 0.085845, loss_ce: 0.034275
2022-01-13 20:03:20,368 iteration 1146 : loss : 0.144423, loss_ce: 0.072019
2022-01-13 20:03:21,648 iteration 1147 : loss : 0.088519, loss_ce: 0.035285
2022-01-13 20:03:23,055 iteration 1148 : loss : 0.110146, loss_ce: 0.041210
2022-01-13 20:03:24,362 iteration 1149 : loss : 0.089951, loss_ce: 0.050764
2022-01-13 20:03:25,722 iteration 1150 : loss : 0.081397, loss_ce: 0.032896
2022-01-13 20:03:27,113 iteration 1151 : loss : 0.094011, loss_ce: 0.038406
2022-01-13 20:03:28,596 iteration 1152 : loss : 0.088261, loss_ce: 0.034204
2022-01-13 20:03:29,877 iteration 1153 : loss : 0.087302, loss_ce: 0.033937
2022-01-13 20:03:31,267 iteration 1154 : loss : 0.100025, loss_ce: 0.037244
2022-01-13 20:03:32,591 iteration 1155 : loss : 0.101569, loss_ce: 0.034151
2022-01-13 20:03:33,999 iteration 1156 : loss : 0.133670, loss_ce: 0.066524
 17%|█████                         | 68/400 [29:05<2:15:12, 24.44s/it]2022-01-13 20:03:35,399 iteration 1157 : loss : 0.168183, loss_ce: 0.058956
2022-01-13 20:03:36,772 iteration 1158 : loss : 0.102456, loss_ce: 0.037548
2022-01-13 20:03:38,205 iteration 1159 : loss : 0.089343, loss_ce: 0.030048
2022-01-13 20:03:39,678 iteration 1160 : loss : 0.126598, loss_ce: 0.056806
2022-01-13 20:03:41,098 iteration 1161 : loss : 0.090933, loss_ce: 0.040385
2022-01-13 20:03:42,488 iteration 1162 : loss : 0.066782, loss_ce: 0.024855
2022-01-13 20:03:43,832 iteration 1163 : loss : 0.109410, loss_ce: 0.048796
2022-01-13 20:03:45,182 iteration 1164 : loss : 0.122931, loss_ce: 0.049121
2022-01-13 20:03:46,540 iteration 1165 : loss : 0.099392, loss_ce: 0.055669
2022-01-13 20:03:47,974 iteration 1166 : loss : 0.056909, loss_ce: 0.022462
2022-01-13 20:03:49,305 iteration 1167 : loss : 0.082480, loss_ce: 0.037930
2022-01-13 20:03:50,650 iteration 1168 : loss : 0.081248, loss_ce: 0.040324
2022-01-13 20:03:51,978 iteration 1169 : loss : 0.101605, loss_ce: 0.043144
2022-01-13 20:03:53,312 iteration 1170 : loss : 0.086140, loss_ce: 0.035205
2022-01-13 20:03:54,685 iteration 1171 : loss : 0.071996, loss_ce: 0.026012
2022-01-13 20:03:56,053 iteration 1172 : loss : 0.143789, loss_ce: 0.076613
2022-01-13 20:03:57,449 iteration 1173 : loss : 0.109673, loss_ce: 0.042909
 17%|█████▏                        | 69/400 [29:29<2:13:09, 24.14s/it]2022-01-13 20:03:58,847 iteration 1174 : loss : 0.102921, loss_ce: 0.038390
2022-01-13 20:04:00,213 iteration 1175 : loss : 0.065121, loss_ce: 0.027321
2022-01-13 20:04:01,567 iteration 1176 : loss : 0.080595, loss_ce: 0.034008
2022-01-13 20:04:02,890 iteration 1177 : loss : 0.128601, loss_ce: 0.059419
2022-01-13 20:04:04,285 iteration 1178 : loss : 0.070458, loss_ce: 0.023986
2022-01-13 20:04:05,726 iteration 1179 : loss : 0.103210, loss_ce: 0.048409
2022-01-13 20:04:07,061 iteration 1180 : loss : 0.090950, loss_ce: 0.039423
2022-01-13 20:04:08,414 iteration 1181 : loss : 0.087352, loss_ce: 0.040752
2022-01-13 20:04:09,787 iteration 1182 : loss : 0.083537, loss_ce: 0.032948
2022-01-13 20:04:11,103 iteration 1183 : loss : 0.097687, loss_ce: 0.040598
2022-01-13 20:04:12,427 iteration 1184 : loss : 0.082235, loss_ce: 0.038932
2022-01-13 20:04:13,830 iteration 1185 : loss : 0.097632, loss_ce: 0.037453
2022-01-13 20:04:15,159 iteration 1186 : loss : 0.098761, loss_ce: 0.047667
2022-01-13 20:04:16,580 iteration 1187 : loss : 0.091553, loss_ce: 0.038910
2022-01-13 20:04:17,905 iteration 1188 : loss : 0.121788, loss_ce: 0.049434
2022-01-13 20:04:19,339 iteration 1189 : loss : 0.116316, loss_ce: 0.058088
2022-01-13 20:04:19,339 Training Data Eval:
2022-01-13 20:04:26,133   Average segmentation loss on training set: 0.0790
2022-01-13 20:04:26,133 Validation Data Eval:
2022-01-13 20:04:28,476   Average segmentation loss on validation set: 0.0945
2022-01-13 20:04:34,204 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 20:04:35,641 iteration 1190 : loss : 0.113735, loss_ce: 0.056315
 18%|█████▎                        | 70/400 [30:07<2:35:58, 28.36s/it]2022-01-13 20:04:37,129 iteration 1191 : loss : 0.155480, loss_ce: 0.082546
2022-01-13 20:04:38,445 iteration 1192 : loss : 0.064678, loss_ce: 0.031614
2022-01-13 20:04:39,897 iteration 1193 : loss : 0.107467, loss_ce: 0.040348
2022-01-13 20:04:41,243 iteration 1194 : loss : 0.099214, loss_ce: 0.034891
2022-01-13 20:04:42,551 iteration 1195 : loss : 0.097976, loss_ce: 0.045867
2022-01-13 20:04:43,861 iteration 1196 : loss : 0.093491, loss_ce: 0.042147
2022-01-13 20:04:45,136 iteration 1197 : loss : 0.083834, loss_ce: 0.033216
2022-01-13 20:04:46,536 iteration 1198 : loss : 0.069143, loss_ce: 0.034035
2022-01-13 20:04:47,901 iteration 1199 : loss : 0.082247, loss_ce: 0.031777
2022-01-13 20:04:49,238 iteration 1200 : loss : 0.124430, loss_ce: 0.040338
2022-01-13 20:04:50,558 iteration 1201 : loss : 0.084507, loss_ce: 0.040598
2022-01-13 20:04:51,954 iteration 1202 : loss : 0.104118, loss_ce: 0.048384
2022-01-13 20:04:53,329 iteration 1203 : loss : 0.104859, loss_ce: 0.037911
2022-01-13 20:04:54,683 iteration 1204 : loss : 0.106814, loss_ce: 0.039546
2022-01-13 20:04:56,058 iteration 1205 : loss : 0.134901, loss_ce: 0.064107
2022-01-13 20:04:57,429 iteration 1206 : loss : 0.071293, loss_ce: 0.030993
2022-01-13 20:04:58,837 iteration 1207 : loss : 0.068865, loss_ce: 0.026127
 18%|█████▎                        | 71/400 [30:30<2:27:00, 26.81s/it]2022-01-13 20:05:00,294 iteration 1208 : loss : 0.090386, loss_ce: 0.046446
2022-01-13 20:05:01,666 iteration 1209 : loss : 0.092414, loss_ce: 0.033747
2022-01-13 20:05:03,034 iteration 1210 : loss : 0.084022, loss_ce: 0.034216
2022-01-13 20:05:04,348 iteration 1211 : loss : 0.054462, loss_ce: 0.022780
2022-01-13 20:05:05,644 iteration 1212 : loss : 0.113351, loss_ce: 0.034444
2022-01-13 20:05:07,115 iteration 1213 : loss : 0.088711, loss_ce: 0.039079
2022-01-13 20:05:08,475 iteration 1214 : loss : 0.102466, loss_ce: 0.042768
2022-01-13 20:05:09,845 iteration 1215 : loss : 0.147425, loss_ce: 0.072569
2022-01-13 20:05:11,325 iteration 1216 : loss : 0.082727, loss_ce: 0.032308
2022-01-13 20:05:12,701 iteration 1217 : loss : 0.066510, loss_ce: 0.022143
2022-01-13 20:05:14,025 iteration 1218 : loss : 0.087597, loss_ce: 0.035944
2022-01-13 20:05:15,319 iteration 1219 : loss : 0.071382, loss_ce: 0.024998
2022-01-13 20:05:16,667 iteration 1220 : loss : 0.098264, loss_ce: 0.037111
2022-01-13 20:05:17,986 iteration 1221 : loss : 0.108296, loss_ce: 0.048181
2022-01-13 20:05:19,407 iteration 1222 : loss : 0.092711, loss_ce: 0.032388
2022-01-13 20:05:20,746 iteration 1223 : loss : 0.100160, loss_ce: 0.043222
2022-01-13 20:05:22,176 iteration 1224 : loss : 0.123342, loss_ce: 0.058579
 18%|█████▍                        | 72/400 [30:53<2:20:51, 25.77s/it]2022-01-13 20:05:23,592 iteration 1225 : loss : 0.099125, loss_ce: 0.041439
2022-01-13 20:05:25,008 iteration 1226 : loss : 0.137306, loss_ce: 0.084038
2022-01-13 20:05:26,330 iteration 1227 : loss : 0.098194, loss_ce: 0.035979
2022-01-13 20:05:27,692 iteration 1228 : loss : 0.094861, loss_ce: 0.036463
2022-01-13 20:05:28,990 iteration 1229 : loss : 0.108873, loss_ce: 0.034007
2022-01-13 20:05:30,307 iteration 1230 : loss : 0.085341, loss_ce: 0.032722
2022-01-13 20:05:31,695 iteration 1231 : loss : 0.085208, loss_ce: 0.039214
2022-01-13 20:05:33,013 iteration 1232 : loss : 0.099371, loss_ce: 0.048404
2022-01-13 20:05:34,338 iteration 1233 : loss : 0.057274, loss_ce: 0.023336
2022-01-13 20:05:35,729 iteration 1234 : loss : 0.090809, loss_ce: 0.038807
2022-01-13 20:05:37,119 iteration 1235 : loss : 0.109394, loss_ce: 0.033333
2022-01-13 20:05:38,437 iteration 1236 : loss : 0.076094, loss_ce: 0.031385
2022-01-13 20:05:39,710 iteration 1237 : loss : 0.156191, loss_ce: 0.069403
2022-01-13 20:05:41,147 iteration 1238 : loss : 0.061248, loss_ce: 0.021613
2022-01-13 20:05:42,450 iteration 1239 : loss : 0.057911, loss_ce: 0.022349
2022-01-13 20:05:43,760 iteration 1240 : loss : 0.072538, loss_ce: 0.029100
2022-01-13 20:05:45,069 iteration 1241 : loss : 0.126198, loss_ce: 0.067036
 18%|█████▍                        | 73/400 [31:16<2:15:43, 24.90s/it]2022-01-13 20:05:46,500 iteration 1242 : loss : 0.109358, loss_ce: 0.056702
2022-01-13 20:05:47,820 iteration 1243 : loss : 0.102222, loss_ce: 0.036529
2022-01-13 20:05:49,144 iteration 1244 : loss : 0.089189, loss_ce: 0.043539
2022-01-13 20:05:50,509 iteration 1245 : loss : 0.114508, loss_ce: 0.043032
2022-01-13 20:05:51,869 iteration 1246 : loss : 0.074475, loss_ce: 0.024704
2022-01-13 20:05:53,193 iteration 1247 : loss : 0.099947, loss_ce: 0.044894
2022-01-13 20:05:54,565 iteration 1248 : loss : 0.088640, loss_ce: 0.033361
2022-01-13 20:05:55,882 iteration 1249 : loss : 0.065885, loss_ce: 0.025287
2022-01-13 20:05:57,333 iteration 1250 : loss : 0.083168, loss_ce: 0.035503
2022-01-13 20:05:58,809 iteration 1251 : loss : 0.097105, loss_ce: 0.049195
2022-01-13 20:06:00,197 iteration 1252 : loss : 0.072486, loss_ce: 0.031458
2022-01-13 20:06:01,479 iteration 1253 : loss : 0.087291, loss_ce: 0.034815
2022-01-13 20:06:02,838 iteration 1254 : loss : 0.077579, loss_ce: 0.040994
2022-01-13 20:06:04,207 iteration 1255 : loss : 0.068262, loss_ce: 0.027473
2022-01-13 20:06:05,549 iteration 1256 : loss : 0.086005, loss_ce: 0.038791
2022-01-13 20:06:06,903 iteration 1257 : loss : 0.118274, loss_ce: 0.036581
2022-01-13 20:06:08,274 iteration 1258 : loss : 0.085292, loss_ce: 0.039109
 18%|█████▌                        | 74/400 [31:40<2:12:32, 24.39s/it]2022-01-13 20:06:09,644 iteration 1259 : loss : 0.076694, loss_ce: 0.034748
2022-01-13 20:06:11,051 iteration 1260 : loss : 0.070507, loss_ce: 0.031431
2022-01-13 20:06:12,386 iteration 1261 : loss : 0.063669, loss_ce: 0.023088
2022-01-13 20:06:13,819 iteration 1262 : loss : 0.112514, loss_ce: 0.042566
2022-01-13 20:06:15,275 iteration 1263 : loss : 0.132309, loss_ce: 0.059968
2022-01-13 20:06:16,616 iteration 1264 : loss : 0.062202, loss_ce: 0.028334
2022-01-13 20:06:18,030 iteration 1265 : loss : 0.082619, loss_ce: 0.045647
2022-01-13 20:06:19,438 iteration 1266 : loss : 0.081858, loss_ce: 0.036130
2022-01-13 20:06:20,821 iteration 1267 : loss : 0.105273, loss_ce: 0.047512
2022-01-13 20:06:22,149 iteration 1268 : loss : 0.108568, loss_ce: 0.042159
2022-01-13 20:06:23,578 iteration 1269 : loss : 0.148178, loss_ce: 0.045414
2022-01-13 20:06:24,970 iteration 1270 : loss : 0.079108, loss_ce: 0.036423
2022-01-13 20:06:26,327 iteration 1271 : loss : 0.093743, loss_ce: 0.044678
2022-01-13 20:06:27,611 iteration 1272 : loss : 0.078396, loss_ce: 0.027151
2022-01-13 20:06:28,942 iteration 1273 : loss : 0.078678, loss_ce: 0.029822
2022-01-13 20:06:30,293 iteration 1274 : loss : 0.088863, loss_ce: 0.025788
2022-01-13 20:06:30,293 Training Data Eval:
2022-01-13 20:06:37,049   Average segmentation loss on training set: 0.0609
2022-01-13 20:06:37,049 Validation Data Eval:
2022-01-13 20:06:39,386   Average segmentation loss on validation set: 0.0993
2022-01-13 20:06:40,734 iteration 1275 : loss : 0.074366, loss_ce: 0.029146
 19%|█████▋                        | 75/400 [32:12<2:25:14, 26.81s/it]2022-01-13 20:06:42,065 iteration 1276 : loss : 0.082714, loss_ce: 0.033038
2022-01-13 20:06:43,524 iteration 1277 : loss : 0.078299, loss_ce: 0.032033
2022-01-13 20:06:44,846 iteration 1278 : loss : 0.070869, loss_ce: 0.025003
2022-01-13 20:06:46,291 iteration 1279 : loss : 0.071142, loss_ce: 0.029860
2022-01-13 20:06:47,671 iteration 1280 : loss : 0.106341, loss_ce: 0.051491
2022-01-13 20:06:49,042 iteration 1281 : loss : 0.094711, loss_ce: 0.046294
2022-01-13 20:06:50,348 iteration 1282 : loss : 0.050532, loss_ce: 0.022895
2022-01-13 20:06:51,756 iteration 1283 : loss : 0.117352, loss_ce: 0.036090
2022-01-13 20:06:53,071 iteration 1284 : loss : 0.094473, loss_ce: 0.041220
2022-01-13 20:06:54,497 iteration 1285 : loss : 0.077609, loss_ce: 0.029444
2022-01-13 20:06:55,943 iteration 1286 : loss : 0.188104, loss_ce: 0.066770
2022-01-13 20:06:57,281 iteration 1287 : loss : 0.067598, loss_ce: 0.037725
2022-01-13 20:06:58,601 iteration 1288 : loss : 0.090099, loss_ce: 0.045363
2022-01-13 20:06:59,958 iteration 1289 : loss : 0.130946, loss_ce: 0.064628
2022-01-13 20:07:01,350 iteration 1290 : loss : 0.113605, loss_ce: 0.048598
2022-01-13 20:07:02,752 iteration 1291 : loss : 0.095452, loss_ce: 0.041722
2022-01-13 20:07:04,169 iteration 1292 : loss : 0.082469, loss_ce: 0.034536
 19%|█████▋                        | 76/400 [32:35<2:19:19, 25.80s/it]2022-01-13 20:07:05,617 iteration 1293 : loss : 0.104745, loss_ce: 0.046010
2022-01-13 20:07:07,010 iteration 1294 : loss : 0.102266, loss_ce: 0.043167
2022-01-13 20:07:08,446 iteration 1295 : loss : 0.105692, loss_ce: 0.025047
2022-01-13 20:07:09,835 iteration 1296 : loss : 0.088414, loss_ce: 0.033061
2022-01-13 20:07:11,158 iteration 1297 : loss : 0.089271, loss_ce: 0.048393
2022-01-13 20:07:12,454 iteration 1298 : loss : 0.061809, loss_ce: 0.025923
2022-01-13 20:07:13,821 iteration 1299 : loss : 0.096822, loss_ce: 0.044646
2022-01-13 20:07:15,172 iteration 1300 : loss : 0.070899, loss_ce: 0.025608
2022-01-13 20:07:16,559 iteration 1301 : loss : 0.064761, loss_ce: 0.029074
2022-01-13 20:07:17,892 iteration 1302 : loss : 0.087260, loss_ce: 0.038447
2022-01-13 20:07:19,233 iteration 1303 : loss : 0.085852, loss_ce: 0.036481
2022-01-13 20:07:20,594 iteration 1304 : loss : 0.072229, loss_ce: 0.029847
2022-01-13 20:07:21,951 iteration 1305 : loss : 0.092220, loss_ce: 0.037385
2022-01-13 20:07:23,351 iteration 1306 : loss : 0.119304, loss_ce: 0.047898
2022-01-13 20:07:24,746 iteration 1307 : loss : 0.069524, loss_ce: 0.034533
2022-01-13 20:07:26,119 iteration 1308 : loss : 0.123144, loss_ce: 0.039877
2022-01-13 20:07:27,423 iteration 1309 : loss : 0.082379, loss_ce: 0.032974
 19%|█████▊                        | 77/400 [32:59<2:14:47, 25.04s/it]2022-01-13 20:07:28,941 iteration 1310 : loss : 0.095685, loss_ce: 0.036830
2022-01-13 20:07:30,277 iteration 1311 : loss : 0.071780, loss_ce: 0.032772
2022-01-13 20:07:31,602 iteration 1312 : loss : 0.057861, loss_ce: 0.024458
2022-01-13 20:07:32,932 iteration 1313 : loss : 0.105157, loss_ce: 0.032389
2022-01-13 20:07:34,295 iteration 1314 : loss : 0.079051, loss_ce: 0.036734
2022-01-13 20:07:35,680 iteration 1315 : loss : 0.087845, loss_ce: 0.037241
2022-01-13 20:07:37,149 iteration 1316 : loss : 0.093064, loss_ce: 0.037516
2022-01-13 20:07:38,503 iteration 1317 : loss : 0.100933, loss_ce: 0.058773
2022-01-13 20:07:39,945 iteration 1318 : loss : 0.189985, loss_ce: 0.036278
2022-01-13 20:07:41,344 iteration 1319 : loss : 0.065645, loss_ce: 0.030317
2022-01-13 20:07:42,700 iteration 1320 : loss : 0.069389, loss_ce: 0.021995
2022-01-13 20:07:44,089 iteration 1321 : loss : 0.102662, loss_ce: 0.027378
2022-01-13 20:07:45,408 iteration 1322 : loss : 0.085017, loss_ce: 0.040173
2022-01-13 20:07:46,762 iteration 1323 : loss : 0.082186, loss_ce: 0.030196
2022-01-13 20:07:48,144 iteration 1324 : loss : 0.082662, loss_ce: 0.037712
2022-01-13 20:07:49,560 iteration 1325 : loss : 0.089124, loss_ce: 0.030860
2022-01-13 20:07:50,829 iteration 1326 : loss : 0.077192, loss_ce: 0.030188
 20%|█████▊                        | 78/400 [33:22<2:11:44, 24.55s/it]2022-01-13 20:07:52,218 iteration 1327 : loss : 0.082056, loss_ce: 0.030458
2022-01-13 20:07:53,599 iteration 1328 : loss : 0.118018, loss_ce: 0.065514
2022-01-13 20:07:54,957 iteration 1329 : loss : 0.057252, loss_ce: 0.024749
2022-01-13 20:07:56,287 iteration 1330 : loss : 0.144784, loss_ce: 0.044509
2022-01-13 20:07:57,585 iteration 1331 : loss : 0.085415, loss_ce: 0.044402
2022-01-13 20:07:58,893 iteration 1332 : loss : 0.071430, loss_ce: 0.026718
2022-01-13 20:08:00,231 iteration 1333 : loss : 0.097818, loss_ce: 0.033947
2022-01-13 20:08:01,584 iteration 1334 : loss : 0.094089, loss_ce: 0.038656
2022-01-13 20:08:02,915 iteration 1335 : loss : 0.075207, loss_ce: 0.027238
2022-01-13 20:08:04,250 iteration 1336 : loss : 0.094848, loss_ce: 0.041371
2022-01-13 20:08:05,661 iteration 1337 : loss : 0.104098, loss_ce: 0.049123
2022-01-13 20:08:07,049 iteration 1338 : loss : 0.107703, loss_ce: 0.038373
2022-01-13 20:08:08,466 iteration 1339 : loss : 0.092441, loss_ce: 0.042033
2022-01-13 20:08:09,848 iteration 1340 : loss : 0.092054, loss_ce: 0.046698
2022-01-13 20:08:11,219 iteration 1341 : loss : 0.098195, loss_ce: 0.037665
2022-01-13 20:08:12,568 iteration 1342 : loss : 0.106872, loss_ce: 0.044306
2022-01-13 20:08:13,874 iteration 1343 : loss : 0.067358, loss_ce: 0.028359
 20%|█████▉                        | 79/400 [33:45<2:08:54, 24.10s/it]2022-01-13 20:08:15,290 iteration 1344 : loss : 0.074825, loss_ce: 0.033435
2022-01-13 20:08:16,720 iteration 1345 : loss : 0.121545, loss_ce: 0.050722
2022-01-13 20:08:18,062 iteration 1346 : loss : 0.109619, loss_ce: 0.048955
2022-01-13 20:08:19,490 iteration 1347 : loss : 0.059035, loss_ce: 0.028355
2022-01-13 20:08:20,956 iteration 1348 : loss : 0.126190, loss_ce: 0.054174
2022-01-13 20:08:22,324 iteration 1349 : loss : 0.099691, loss_ce: 0.050026
2022-01-13 20:08:23,681 iteration 1350 : loss : 0.098570, loss_ce: 0.049963
2022-01-13 20:08:25,042 iteration 1351 : loss : 0.089728, loss_ce: 0.042025
2022-01-13 20:08:26,455 iteration 1352 : loss : 0.095641, loss_ce: 0.047104
2022-01-13 20:08:27,843 iteration 1353 : loss : 0.104501, loss_ce: 0.040707
2022-01-13 20:08:29,247 iteration 1354 : loss : 0.088688, loss_ce: 0.033948
2022-01-13 20:08:30,713 iteration 1355 : loss : 0.198088, loss_ce: 0.054251
2022-01-13 20:08:32,099 iteration 1356 : loss : 0.086245, loss_ce: 0.037760
2022-01-13 20:08:33,498 iteration 1357 : loss : 0.078145, loss_ce: 0.028685
2022-01-13 20:08:34,915 iteration 1358 : loss : 0.093121, loss_ce: 0.042817
2022-01-13 20:08:36,277 iteration 1359 : loss : 0.098495, loss_ce: 0.046739
2022-01-13 20:08:36,277 Training Data Eval:
2022-01-13 20:08:43,036   Average segmentation loss on training set: 0.0611
2022-01-13 20:08:43,036 Validation Data Eval:
2022-01-13 20:08:45,363   Average segmentation loss on validation set: 0.1422
2022-01-13 20:08:46,778 iteration 1360 : loss : 0.087882, loss_ce: 0.027661
 20%|██████                        | 80/400 [34:18<2:22:36, 26.74s/it]2022-01-13 20:08:48,287 iteration 1361 : loss : 0.103459, loss_ce: 0.041621
2022-01-13 20:08:49,661 iteration 1362 : loss : 0.103255, loss_ce: 0.038623
2022-01-13 20:08:51,178 iteration 1363 : loss : 0.099129, loss_ce: 0.044684
2022-01-13 20:08:52,425 iteration 1364 : loss : 0.096243, loss_ce: 0.027966
2022-01-13 20:08:53,854 iteration 1365 : loss : 0.096603, loss_ce: 0.048545
2022-01-13 20:08:55,238 iteration 1366 : loss : 0.081435, loss_ce: 0.034903
2022-01-13 20:08:56,593 iteration 1367 : loss : 0.067408, loss_ce: 0.026521
2022-01-13 20:08:57,967 iteration 1368 : loss : 0.082415, loss_ce: 0.042760
2022-01-13 20:08:59,301 iteration 1369 : loss : 0.085992, loss_ce: 0.031326
2022-01-13 20:09:00,708 iteration 1370 : loss : 0.097391, loss_ce: 0.048146
2022-01-13 20:09:02,049 iteration 1371 : loss : 0.072685, loss_ce: 0.025153
2022-01-13 20:09:03,380 iteration 1372 : loss : 0.086563, loss_ce: 0.037420
2022-01-13 20:09:04,700 iteration 1373 : loss : 0.088780, loss_ce: 0.039141
2022-01-13 20:09:06,073 iteration 1374 : loss : 0.092150, loss_ce: 0.034295
2022-01-13 20:09:07,456 iteration 1375 : loss : 0.091567, loss_ce: 0.045242
2022-01-13 20:09:08,832 iteration 1376 : loss : 0.085333, loss_ce: 0.030416
2022-01-13 20:09:10,185 iteration 1377 : loss : 0.044549, loss_ce: 0.017911
 20%|██████                        | 81/400 [34:41<2:16:51, 25.74s/it]2022-01-13 20:09:11,547 iteration 1378 : loss : 0.103196, loss_ce: 0.049937
2022-01-13 20:09:12,954 iteration 1379 : loss : 0.093905, loss_ce: 0.038764
2022-01-13 20:09:14,327 iteration 1380 : loss : 0.073488, loss_ce: 0.033806
2022-01-13 20:09:15,773 iteration 1381 : loss : 0.075242, loss_ce: 0.033761
2022-01-13 20:09:17,065 iteration 1382 : loss : 0.077324, loss_ce: 0.031757
2022-01-13 20:09:18,493 iteration 1383 : loss : 0.075605, loss_ce: 0.029016
2022-01-13 20:09:19,866 iteration 1384 : loss : 0.084700, loss_ce: 0.035045
2022-01-13 20:09:21,172 iteration 1385 : loss : 0.104467, loss_ce: 0.048553
2022-01-13 20:09:22,505 iteration 1386 : loss : 0.064775, loss_ce: 0.026492
2022-01-13 20:09:23,853 iteration 1387 : loss : 0.102035, loss_ce: 0.043114
2022-01-13 20:09:25,215 iteration 1388 : loss : 0.090119, loss_ce: 0.029363
2022-01-13 20:09:26,573 iteration 1389 : loss : 0.112996, loss_ce: 0.048465
2022-01-13 20:09:27,978 iteration 1390 : loss : 0.081790, loss_ce: 0.036198
2022-01-13 20:09:29,406 iteration 1391 : loss : 0.057910, loss_ce: 0.021854
2022-01-13 20:09:30,816 iteration 1392 : loss : 0.070034, loss_ce: 0.034830
2022-01-13 20:09:32,157 iteration 1393 : loss : 0.071992, loss_ce: 0.029530
2022-01-13 20:09:33,575 iteration 1394 : loss : 0.075792, loss_ce: 0.041498
 20%|██████▏                       | 82/400 [35:05<2:12:40, 25.03s/it]2022-01-13 20:09:34,983 iteration 1395 : loss : 0.070485, loss_ce: 0.029990
2022-01-13 20:09:36,324 iteration 1396 : loss : 0.087486, loss_ce: 0.045829
2022-01-13 20:09:37,742 iteration 1397 : loss : 0.098739, loss_ce: 0.037178
2022-01-13 20:09:39,175 iteration 1398 : loss : 0.087522, loss_ce: 0.040431
2022-01-13 20:09:40,470 iteration 1399 : loss : 0.076967, loss_ce: 0.036223
2022-01-13 20:09:41,757 iteration 1400 : loss : 0.076122, loss_ce: 0.026061
2022-01-13 20:09:43,177 iteration 1401 : loss : 0.072336, loss_ce: 0.027827
2022-01-13 20:09:44,558 iteration 1402 : loss : 0.088403, loss_ce: 0.035960
2022-01-13 20:09:45,872 iteration 1403 : loss : 0.079149, loss_ce: 0.034178
2022-01-13 20:09:47,220 iteration 1404 : loss : 0.048785, loss_ce: 0.023381
2022-01-13 20:09:48,579 iteration 1405 : loss : 0.093344, loss_ce: 0.034003
2022-01-13 20:09:49,946 iteration 1406 : loss : 0.104957, loss_ce: 0.042836
2022-01-13 20:09:51,351 iteration 1407 : loss : 0.054313, loss_ce: 0.023175
2022-01-13 20:09:52,708 iteration 1408 : loss : 0.071030, loss_ce: 0.024951
2022-01-13 20:09:54,078 iteration 1409 : loss : 0.097468, loss_ce: 0.037746
2022-01-13 20:09:55,512 iteration 1410 : loss : 0.060319, loss_ce: 0.025610
2022-01-13 20:09:56,852 iteration 1411 : loss : 0.070469, loss_ce: 0.026120
 21%|██████▏                       | 83/400 [35:28<2:09:28, 24.51s/it]2022-01-13 20:09:58,240 iteration 1412 : loss : 0.090596, loss_ce: 0.039310
2022-01-13 20:09:59,671 iteration 1413 : loss : 0.097211, loss_ce: 0.031168
2022-01-13 20:10:01,018 iteration 1414 : loss : 0.071949, loss_ce: 0.029653
2022-01-13 20:10:02,424 iteration 1415 : loss : 0.096969, loss_ce: 0.029625
2022-01-13 20:10:03,774 iteration 1416 : loss : 0.074677, loss_ce: 0.030783
2022-01-13 20:10:05,106 iteration 1417 : loss : 0.111153, loss_ce: 0.043372
2022-01-13 20:10:06,439 iteration 1418 : loss : 0.085473, loss_ce: 0.039031
2022-01-13 20:10:07,746 iteration 1419 : loss : 0.072779, loss_ce: 0.029768
2022-01-13 20:10:09,148 iteration 1420 : loss : 0.098115, loss_ce: 0.035011
2022-01-13 20:10:10,588 iteration 1421 : loss : 0.095755, loss_ce: 0.039302
2022-01-13 20:10:11,976 iteration 1422 : loss : 0.062699, loss_ce: 0.019482
2022-01-13 20:10:13,279 iteration 1423 : loss : 0.072739, loss_ce: 0.031047
2022-01-13 20:10:14,671 iteration 1424 : loss : 0.061607, loss_ce: 0.028908
2022-01-13 20:10:16,056 iteration 1425 : loss : 0.046928, loss_ce: 0.019888
2022-01-13 20:10:17,373 iteration 1426 : loss : 0.067168, loss_ce: 0.030806
2022-01-13 20:10:18,726 iteration 1427 : loss : 0.086549, loss_ce: 0.034559
2022-01-13 20:10:19,995 iteration 1428 : loss : 0.126219, loss_ce: 0.047321
 21%|██████▎                       | 84/400 [35:51<2:06:55, 24.10s/it]2022-01-13 20:10:21,487 iteration 1429 : loss : 0.089175, loss_ce: 0.041738
2022-01-13 20:10:22,805 iteration 1430 : loss : 0.205255, loss_ce: 0.065065
2022-01-13 20:10:24,162 iteration 1431 : loss : 0.138953, loss_ce: 0.067650
2022-01-13 20:10:25,537 iteration 1432 : loss : 0.088511, loss_ce: 0.039977
2022-01-13 20:10:26,950 iteration 1433 : loss : 0.069914, loss_ce: 0.024956
2022-01-13 20:10:28,289 iteration 1434 : loss : 0.065398, loss_ce: 0.028111
2022-01-13 20:10:29,675 iteration 1435 : loss : 0.078425, loss_ce: 0.034600
2022-01-13 20:10:31,076 iteration 1436 : loss : 0.089026, loss_ce: 0.037668
2022-01-13 20:10:32,480 iteration 1437 : loss : 0.093368, loss_ce: 0.033576
2022-01-13 20:10:33,854 iteration 1438 : loss : 0.065679, loss_ce: 0.031868
2022-01-13 20:10:35,273 iteration 1439 : loss : 0.113086, loss_ce: 0.050109
2022-01-13 20:10:36,675 iteration 1440 : loss : 0.078130, loss_ce: 0.036049
2022-01-13 20:10:38,026 iteration 1441 : loss : 0.051824, loss_ce: 0.024380
2022-01-13 20:10:39,398 iteration 1442 : loss : 0.069640, loss_ce: 0.032224
2022-01-13 20:10:40,788 iteration 1443 : loss : 0.082167, loss_ce: 0.031238
2022-01-13 20:10:42,157 iteration 1444 : loss : 0.146777, loss_ce: 0.046704
2022-01-13 20:10:42,157 Training Data Eval:
2022-01-13 20:10:48,915   Average segmentation loss on training set: 0.0511
2022-01-13 20:10:48,916 Validation Data Eval:
2022-01-13 20:10:51,238   Average segmentation loss on validation set: 0.0904
2022-01-13 20:10:56,963 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 20:10:58,407 iteration 1445 : loss : 0.075341, loss_ce: 0.026580
 21%|██████▍                       | 85/400 [36:30<2:29:02, 28.39s/it]2022-01-13 20:10:59,905 iteration 1446 : loss : 0.076306, loss_ce: 0.024867
2022-01-13 20:11:01,252 iteration 1447 : loss : 0.075782, loss_ce: 0.026502
2022-01-13 20:11:02,554 iteration 1448 : loss : 0.087447, loss_ce: 0.046687
2022-01-13 20:11:03,941 iteration 1449 : loss : 0.094228, loss_ce: 0.032954
2022-01-13 20:11:05,397 iteration 1450 : loss : 0.072435, loss_ce: 0.034629
2022-01-13 20:11:06,867 iteration 1451 : loss : 0.097243, loss_ce: 0.040457
2022-01-13 20:11:08,200 iteration 1452 : loss : 0.056052, loss_ce: 0.017842
2022-01-13 20:11:09,542 iteration 1453 : loss : 0.083446, loss_ce: 0.044623
2022-01-13 20:11:10,931 iteration 1454 : loss : 0.116696, loss_ce: 0.046757
2022-01-13 20:11:12,261 iteration 1455 : loss : 0.071321, loss_ce: 0.030287
2022-01-13 20:11:13,705 iteration 1456 : loss : 0.200627, loss_ce: 0.090108
2022-01-13 20:11:15,070 iteration 1457 : loss : 0.082111, loss_ce: 0.039301
2022-01-13 20:11:16,419 iteration 1458 : loss : 0.078470, loss_ce: 0.030227
2022-01-13 20:11:17,740 iteration 1459 : loss : 0.076452, loss_ce: 0.025050
2022-01-13 20:11:19,168 iteration 1460 : loss : 0.114511, loss_ce: 0.057839
2022-01-13 20:11:20,538 iteration 1461 : loss : 0.135147, loss_ce: 0.064899
2022-01-13 20:11:21,949 iteration 1462 : loss : 0.078881, loss_ce: 0.033725
 22%|██████▍                       | 86/400 [36:53<2:20:58, 26.94s/it]2022-01-13 20:11:23,366 iteration 1463 : loss : 0.081100, loss_ce: 0.038201
2022-01-13 20:11:24,703 iteration 1464 : loss : 0.075094, loss_ce: 0.031647
2022-01-13 20:11:26,093 iteration 1465 : loss : 0.099391, loss_ce: 0.028828
2022-01-13 20:11:27,483 iteration 1466 : loss : 0.057523, loss_ce: 0.024240
2022-01-13 20:11:28,857 iteration 1467 : loss : 0.098247, loss_ce: 0.053697
2022-01-13 20:11:30,199 iteration 1468 : loss : 0.057753, loss_ce: 0.027885
2022-01-13 20:11:31,561 iteration 1469 : loss : 0.068418, loss_ce: 0.027450
2022-01-13 20:11:32,955 iteration 1470 : loss : 0.107333, loss_ce: 0.041084
2022-01-13 20:11:34,343 iteration 1471 : loss : 0.134453, loss_ce: 0.089718
2022-01-13 20:11:35,610 iteration 1472 : loss : 0.067865, loss_ce: 0.027628
2022-01-13 20:11:37,058 iteration 1473 : loss : 0.053442, loss_ce: 0.021356
2022-01-13 20:11:38,467 iteration 1474 : loss : 0.093609, loss_ce: 0.033882
2022-01-13 20:11:39,828 iteration 1475 : loss : 0.074411, loss_ce: 0.032266
2022-01-13 20:11:41,275 iteration 1476 : loss : 0.146590, loss_ce: 0.055870
2022-01-13 20:11:42,715 iteration 1477 : loss : 0.091869, loss_ce: 0.034450
2022-01-13 20:11:44,154 iteration 1478 : loss : 0.073465, loss_ce: 0.028754
2022-01-13 20:11:45,481 iteration 1479 : loss : 0.074206, loss_ce: 0.027566
 22%|██████▌                       | 87/400 [37:17<2:15:12, 25.92s/it]2022-01-13 20:11:46,913 iteration 1480 : loss : 0.094033, loss_ce: 0.038577
2022-01-13 20:11:48,254 iteration 1481 : loss : 0.062609, loss_ce: 0.025545
2022-01-13 20:11:49,611 iteration 1482 : loss : 0.071736, loss_ce: 0.031562
2022-01-13 20:11:51,054 iteration 1483 : loss : 0.066684, loss_ce: 0.026289
2022-01-13 20:11:52,547 iteration 1484 : loss : 0.088346, loss_ce: 0.033104
2022-01-13 20:11:53,978 iteration 1485 : loss : 0.054984, loss_ce: 0.024702
2022-01-13 20:11:55,332 iteration 1486 : loss : 0.072872, loss_ce: 0.032047
2022-01-13 20:11:56,697 iteration 1487 : loss : 0.090646, loss_ce: 0.049740
2022-01-13 20:11:58,088 iteration 1488 : loss : 0.068083, loss_ce: 0.028344
2022-01-13 20:11:59,476 iteration 1489 : loss : 0.059330, loss_ce: 0.026986
2022-01-13 20:12:00,914 iteration 1490 : loss : 0.073677, loss_ce: 0.033421
2022-01-13 20:12:02,352 iteration 1491 : loss : 0.077597, loss_ce: 0.029617
2022-01-13 20:12:03,687 iteration 1492 : loss : 0.064472, loss_ce: 0.026661
2022-01-13 20:12:05,092 iteration 1493 : loss : 0.083639, loss_ce: 0.032182
2022-01-13 20:12:06,432 iteration 1494 : loss : 0.081373, loss_ce: 0.036607
2022-01-13 20:12:07,779 iteration 1495 : loss : 0.078811, loss_ce: 0.035328
2022-01-13 20:12:09,148 iteration 1496 : loss : 0.096450, loss_ce: 0.028506
 22%|██████▌                       | 88/400 [37:40<2:11:14, 25.24s/it]2022-01-13 20:12:10,527 iteration 1497 : loss : 0.105422, loss_ce: 0.058047
2022-01-13 20:12:11,865 iteration 1498 : loss : 0.046044, loss_ce: 0.014978
2022-01-13 20:12:13,271 iteration 1499 : loss : 0.076851, loss_ce: 0.036230
2022-01-13 20:12:14,570 iteration 1500 : loss : 0.091754, loss_ce: 0.028489
2022-01-13 20:12:15,918 iteration 1501 : loss : 0.074137, loss_ce: 0.028840
2022-01-13 20:12:17,311 iteration 1502 : loss : 0.068590, loss_ce: 0.027195
2022-01-13 20:12:18,656 iteration 1503 : loss : 0.053206, loss_ce: 0.024446
2022-01-13 20:12:19,998 iteration 1504 : loss : 0.056822, loss_ce: 0.020065
2022-01-13 20:12:21,305 iteration 1505 : loss : 0.063474, loss_ce: 0.023419
2022-01-13 20:12:22,656 iteration 1506 : loss : 0.073319, loss_ce: 0.028246
2022-01-13 20:12:24,016 iteration 1507 : loss : 0.100647, loss_ce: 0.039173
2022-01-13 20:12:25,350 iteration 1508 : loss : 0.075739, loss_ce: 0.033415
2022-01-13 20:12:26,699 iteration 1509 : loss : 0.086288, loss_ce: 0.033161
2022-01-13 20:12:28,017 iteration 1510 : loss : 0.055729, loss_ce: 0.022176
2022-01-13 20:12:29,392 iteration 1511 : loss : 0.095343, loss_ce: 0.049376
2022-01-13 20:12:30,715 iteration 1512 : loss : 0.049380, loss_ce: 0.019132
2022-01-13 20:12:32,090 iteration 1513 : loss : 0.081727, loss_ce: 0.040694
 22%|██████▋                       | 89/400 [38:03<2:07:15, 24.55s/it]2022-01-13 20:12:33,484 iteration 1514 : loss : 0.084874, loss_ce: 0.029460
2022-01-13 20:12:34,843 iteration 1515 : loss : 0.082349, loss_ce: 0.035145
2022-01-13 20:12:36,223 iteration 1516 : loss : 0.075920, loss_ce: 0.028949
2022-01-13 20:12:37,575 iteration 1517 : loss : 0.059752, loss_ce: 0.026050
2022-01-13 20:12:38,965 iteration 1518 : loss : 0.054671, loss_ce: 0.017630
2022-01-13 20:12:40,303 iteration 1519 : loss : 0.064717, loss_ce: 0.025524
2022-01-13 20:12:41,631 iteration 1520 : loss : 0.052328, loss_ce: 0.017973
2022-01-13 20:12:42,968 iteration 1521 : loss : 0.089726, loss_ce: 0.035867
2022-01-13 20:12:44,424 iteration 1522 : loss : 0.071450, loss_ce: 0.028754
2022-01-13 20:12:45,736 iteration 1523 : loss : 0.075317, loss_ce: 0.035601
2022-01-13 20:12:47,121 iteration 1524 : loss : 0.071323, loss_ce: 0.030618
2022-01-13 20:12:48,454 iteration 1525 : loss : 0.067047, loss_ce: 0.031832
2022-01-13 20:12:49,874 iteration 1526 : loss : 0.065471, loss_ce: 0.029140
2022-01-13 20:12:51,293 iteration 1527 : loss : 0.089839, loss_ce: 0.043821
2022-01-13 20:12:52,697 iteration 1528 : loss : 0.072353, loss_ce: 0.029211
2022-01-13 20:12:54,027 iteration 1529 : loss : 0.074262, loss_ce: 0.031151
2022-01-13 20:12:54,027 Training Data Eval:
2022-01-13 20:13:00,793   Average segmentation loss on training set: 0.0672
2022-01-13 20:13:00,793 Validation Data Eval:
2022-01-13 20:13:03,127   Average segmentation loss on validation set: 0.1706
2022-01-13 20:13:04,476 iteration 1530 : loss : 0.082897, loss_ce: 0.034837
 22%|██████▊                       | 90/400 [38:36<2:18:59, 26.90s/it]2022-01-13 20:13:06,012 iteration 1531 : loss : 0.070746, loss_ce: 0.027691
2022-01-13 20:13:07,421 iteration 1532 : loss : 0.060267, loss_ce: 0.023809
2022-01-13 20:13:08,747 iteration 1533 : loss : 0.047628, loss_ce: 0.021872
2022-01-13 20:13:10,161 iteration 1534 : loss : 0.097981, loss_ce: 0.034497
2022-01-13 20:13:11,509 iteration 1535 : loss : 0.049714, loss_ce: 0.019904
2022-01-13 20:13:12,842 iteration 1536 : loss : 0.097065, loss_ce: 0.056137
2022-01-13 20:13:14,169 iteration 1537 : loss : 0.097359, loss_ce: 0.031131
2022-01-13 20:13:15,481 iteration 1538 : loss : 0.174124, loss_ce: 0.043561
2022-01-13 20:13:16,836 iteration 1539 : loss : 0.059472, loss_ce: 0.025173
2022-01-13 20:13:18,196 iteration 1540 : loss : 0.084309, loss_ce: 0.041505
2022-01-13 20:13:19,478 iteration 1541 : loss : 0.055745, loss_ce: 0.019813
2022-01-13 20:13:20,845 iteration 1542 : loss : 0.069616, loss_ce: 0.034362
2022-01-13 20:13:22,186 iteration 1543 : loss : 0.107479, loss_ce: 0.037967
2022-01-13 20:13:23,482 iteration 1544 : loss : 0.058258, loss_ce: 0.022747
2022-01-13 20:13:24,834 iteration 1545 : loss : 0.068474, loss_ce: 0.028751
2022-01-13 20:13:26,177 iteration 1546 : loss : 0.076055, loss_ce: 0.035895
2022-01-13 20:13:27,512 iteration 1547 : loss : 0.087211, loss_ce: 0.032948
 23%|██████▊                       | 91/400 [38:59<2:12:34, 25.74s/it]2022-01-13 20:13:28,927 iteration 1548 : loss : 0.059795, loss_ce: 0.021964
2022-01-13 20:13:30,232 iteration 1549 : loss : 0.057168, loss_ce: 0.024458
2022-01-13 20:13:31,679 iteration 1550 : loss : 0.081050, loss_ce: 0.037842
2022-01-13 20:13:33,039 iteration 1551 : loss : 0.079011, loss_ce: 0.035216
2022-01-13 20:13:34,400 iteration 1552 : loss : 0.062307, loss_ce: 0.029200
2022-01-13 20:13:35,678 iteration 1553 : loss : 0.043033, loss_ce: 0.023239
2022-01-13 20:13:36,994 iteration 1554 : loss : 0.105390, loss_ce: 0.043113
2022-01-13 20:13:38,403 iteration 1555 : loss : 0.062430, loss_ce: 0.023889
2022-01-13 20:13:39,883 iteration 1556 : loss : 0.106216, loss_ce: 0.045691
2022-01-13 20:13:41,310 iteration 1557 : loss : 0.130574, loss_ce: 0.038186
2022-01-13 20:13:42,679 iteration 1558 : loss : 0.104152, loss_ce: 0.034070
2022-01-13 20:13:44,142 iteration 1559 : loss : 0.063555, loss_ce: 0.030274
2022-01-13 20:13:45,485 iteration 1560 : loss : 0.106316, loss_ce: 0.032276
2022-01-13 20:13:46,833 iteration 1561 : loss : 0.102115, loss_ce: 0.041904
2022-01-13 20:13:48,201 iteration 1562 : loss : 0.087975, loss_ce: 0.038401
2022-01-13 20:13:49,552 iteration 1563 : loss : 0.091819, loss_ce: 0.048058
2022-01-13 20:13:50,917 iteration 1564 : loss : 0.086880, loss_ce: 0.031744
 23%|██████▉                       | 92/400 [39:22<2:08:32, 25.04s/it]2022-01-13 20:13:52,362 iteration 1565 : loss : 0.071522, loss_ce: 0.025848
2022-01-13 20:13:53,706 iteration 1566 : loss : 0.078948, loss_ce: 0.034197
2022-01-13 20:13:55,136 iteration 1567 : loss : 0.079895, loss_ce: 0.024274
2022-01-13 20:13:56,592 iteration 1568 : loss : 0.118145, loss_ce: 0.053568
2022-01-13 20:13:57,934 iteration 1569 : loss : 0.063771, loss_ce: 0.024820
2022-01-13 20:13:59,316 iteration 1570 : loss : 0.089308, loss_ce: 0.039759
2022-01-13 20:14:00,664 iteration 1571 : loss : 0.087144, loss_ce: 0.038435
2022-01-13 20:14:02,021 iteration 1572 : loss : 0.087910, loss_ce: 0.049129
2022-01-13 20:14:03,388 iteration 1573 : loss : 0.100429, loss_ce: 0.033471
2022-01-13 20:14:04,759 iteration 1574 : loss : 0.100884, loss_ce: 0.052957
2022-01-13 20:14:06,151 iteration 1575 : loss : 0.116396, loss_ce: 0.052661
2022-01-13 20:14:07,496 iteration 1576 : loss : 0.089508, loss_ce: 0.036564
2022-01-13 20:14:08,810 iteration 1577 : loss : 0.109514, loss_ce: 0.042132
2022-01-13 20:14:10,081 iteration 1578 : loss : 0.066458, loss_ce: 0.027908
2022-01-13 20:14:11,427 iteration 1579 : loss : 0.058459, loss_ce: 0.024113
2022-01-13 20:14:12,801 iteration 1580 : loss : 0.101963, loss_ce: 0.039337
2022-01-13 20:14:14,183 iteration 1581 : loss : 0.073794, loss_ce: 0.031285
 23%|██████▉                       | 93/400 [39:45<2:05:24, 24.51s/it]2022-01-13 20:14:15,637 iteration 1582 : loss : 0.096044, loss_ce: 0.049501
2022-01-13 20:14:17,002 iteration 1583 : loss : 0.090272, loss_ce: 0.030041
2022-01-13 20:14:18,317 iteration 1584 : loss : 0.065615, loss_ce: 0.022325
2022-01-13 20:14:19,661 iteration 1585 : loss : 0.063015, loss_ce: 0.031127
2022-01-13 20:14:20,944 iteration 1586 : loss : 0.095116, loss_ce: 0.048108
2022-01-13 20:14:22,272 iteration 1587 : loss : 0.069828, loss_ce: 0.026213
2022-01-13 20:14:23,606 iteration 1588 : loss : 0.055092, loss_ce: 0.016814
2022-01-13 20:14:24,963 iteration 1589 : loss : 0.098306, loss_ce: 0.044045
2022-01-13 20:14:26,401 iteration 1590 : loss : 0.096891, loss_ce: 0.036745
2022-01-13 20:14:27,739 iteration 1591 : loss : 0.080083, loss_ce: 0.043167
2022-01-13 20:14:29,014 iteration 1592 : loss : 0.054800, loss_ce: 0.025748
2022-01-13 20:14:30,376 iteration 1593 : loss : 0.104618, loss_ce: 0.039973
2022-01-13 20:14:31,719 iteration 1594 : loss : 0.074600, loss_ce: 0.027351
2022-01-13 20:14:33,027 iteration 1595 : loss : 0.068087, loss_ce: 0.038672
2022-01-13 20:14:34,307 iteration 1596 : loss : 0.091453, loss_ce: 0.033119
2022-01-13 20:14:35,676 iteration 1597 : loss : 0.153419, loss_ce: 0.049410
2022-01-13 20:14:37,066 iteration 1598 : loss : 0.102515, loss_ce: 0.037801
 24%|███████                       | 94/400 [40:08<2:02:30, 24.02s/it]2022-01-13 20:14:38,517 iteration 1599 : loss : 0.070519, loss_ce: 0.030467
2022-01-13 20:14:39,858 iteration 1600 : loss : 0.055767, loss_ce: 0.025413
2022-01-13 20:14:41,251 iteration 1601 : loss : 0.077631, loss_ce: 0.031456
2022-01-13 20:14:42,620 iteration 1602 : loss : 0.089584, loss_ce: 0.028418
2022-01-13 20:14:43,967 iteration 1603 : loss : 0.066665, loss_ce: 0.028546
2022-01-13 20:14:45,302 iteration 1604 : loss : 0.078810, loss_ce: 0.023684
2022-01-13 20:14:46,643 iteration 1605 : loss : 0.072079, loss_ce: 0.026704
2022-01-13 20:14:48,008 iteration 1606 : loss : 0.067623, loss_ce: 0.028654
2022-01-13 20:14:49,360 iteration 1607 : loss : 0.079689, loss_ce: 0.037663
2022-01-13 20:14:50,797 iteration 1608 : loss : 0.110358, loss_ce: 0.052797
2022-01-13 20:14:52,138 iteration 1609 : loss : 0.067452, loss_ce: 0.026839
2022-01-13 20:14:53,580 iteration 1610 : loss : 0.064523, loss_ce: 0.026081
2022-01-13 20:14:55,019 iteration 1611 : loss : 0.073403, loss_ce: 0.034151
2022-01-13 20:14:56,477 iteration 1612 : loss : 0.058252, loss_ce: 0.023777
2022-01-13 20:14:57,849 iteration 1613 : loss : 0.060893, loss_ce: 0.022588
2022-01-13 20:14:59,273 iteration 1614 : loss : 0.081398, loss_ce: 0.039161
2022-01-13 20:14:59,274 Training Data Eval:
2022-01-13 20:15:06,045   Average segmentation loss on training set: 0.0467
2022-01-13 20:15:06,046 Validation Data Eval:
2022-01-13 20:15:08,377   Average segmentation loss on validation set: 0.1168
2022-01-13 20:15:09,784 iteration 1615 : loss : 0.092070, loss_ce: 0.036920
 24%|███████▏                      | 95/400 [40:41<2:15:22, 26.63s/it]2022-01-13 20:15:11,204 iteration 1616 : loss : 0.065918, loss_ce: 0.025193
2022-01-13 20:15:12,552 iteration 1617 : loss : 0.089651, loss_ce: 0.045743
2022-01-13 20:15:13,864 iteration 1618 : loss : 0.066887, loss_ce: 0.024010
2022-01-13 20:15:15,217 iteration 1619 : loss : 0.080863, loss_ce: 0.046409
2022-01-13 20:15:16,690 iteration 1620 : loss : 0.064407, loss_ce: 0.022484
2022-01-13 20:15:18,169 iteration 1621 : loss : 0.073426, loss_ce: 0.028177
2022-01-13 20:15:19,534 iteration 1622 : loss : 0.106805, loss_ce: 0.048435
2022-01-13 20:15:20,852 iteration 1623 : loss : 0.070560, loss_ce: 0.025661
2022-01-13 20:15:22,231 iteration 1624 : loss : 0.051595, loss_ce: 0.023338
2022-01-13 20:15:23,535 iteration 1625 : loss : 0.049603, loss_ce: 0.018070
2022-01-13 20:15:24,873 iteration 1626 : loss : 0.059804, loss_ce: 0.027404
2022-01-13 20:15:26,347 iteration 1627 : loss : 0.138755, loss_ce: 0.070785
2022-01-13 20:15:27,797 iteration 1628 : loss : 0.077829, loss_ce: 0.034652
2022-01-13 20:15:29,136 iteration 1629 : loss : 0.057313, loss_ce: 0.021215
2022-01-13 20:15:30,454 iteration 1630 : loss : 0.049490, loss_ce: 0.020671
2022-01-13 20:15:31,774 iteration 1631 : loss : 0.103704, loss_ce: 0.036314
2022-01-13 20:15:33,108 iteration 1632 : loss : 0.058028, loss_ce: 0.025154
 24%|███████▏                      | 96/400 [41:04<2:09:53, 25.64s/it]2022-01-13 20:15:34,530 iteration 1633 : loss : 0.099744, loss_ce: 0.034780
2022-01-13 20:15:35,911 iteration 1634 : loss : 0.072704, loss_ce: 0.029248
2022-01-13 20:15:37,251 iteration 1635 : loss : 0.080023, loss_ce: 0.029501
2022-01-13 20:15:38,541 iteration 1636 : loss : 0.067627, loss_ce: 0.031940
2022-01-13 20:15:39,916 iteration 1637 : loss : 0.071581, loss_ce: 0.024226
2022-01-13 20:15:41,274 iteration 1638 : loss : 0.060201, loss_ce: 0.029297
2022-01-13 20:15:42,688 iteration 1639 : loss : 0.075231, loss_ce: 0.035655
2022-01-13 20:15:44,015 iteration 1640 : loss : 0.066734, loss_ce: 0.024878
2022-01-13 20:15:45,450 iteration 1641 : loss : 0.062168, loss_ce: 0.024178
2022-01-13 20:15:46,770 iteration 1642 : loss : 0.053522, loss_ce: 0.021420
2022-01-13 20:15:48,067 iteration 1643 : loss : 0.062957, loss_ce: 0.024108
2022-01-13 20:15:49,478 iteration 1644 : loss : 0.068672, loss_ce: 0.027762
2022-01-13 20:15:50,928 iteration 1645 : loss : 0.070710, loss_ce: 0.032460
2022-01-13 20:15:52,255 iteration 1646 : loss : 0.079568, loss_ce: 0.029895
2022-01-13 20:15:53,595 iteration 1647 : loss : 0.109449, loss_ce: 0.035885
2022-01-13 20:15:54,879 iteration 1648 : loss : 0.053317, loss_ce: 0.023421
2022-01-13 20:15:56,175 iteration 1649 : loss : 0.045037, loss_ce: 0.018094
 24%|███████▎                      | 97/400 [41:27<2:05:34, 24.87s/it]2022-01-13 20:15:57,701 iteration 1650 : loss : 0.110243, loss_ce: 0.064067
2022-01-13 20:15:59,044 iteration 1651 : loss : 0.079828, loss_ce: 0.026524
2022-01-13 20:16:00,416 iteration 1652 : loss : 0.106365, loss_ce: 0.037847
2022-01-13 20:16:01,749 iteration 1653 : loss : 0.068599, loss_ce: 0.022547
2022-01-13 20:16:03,092 iteration 1654 : loss : 0.062462, loss_ce: 0.020227
2022-01-13 20:16:04,409 iteration 1655 : loss : 0.058319, loss_ce: 0.020443
2022-01-13 20:16:05,805 iteration 1656 : loss : 0.079386, loss_ce: 0.033652
2022-01-13 20:16:07,152 iteration 1657 : loss : 0.050525, loss_ce: 0.021696
2022-01-13 20:16:08,558 iteration 1658 : loss : 0.134001, loss_ce: 0.089401
2022-01-13 20:16:09,992 iteration 1659 : loss : 0.073374, loss_ce: 0.035306
2022-01-13 20:16:11,361 iteration 1660 : loss : 0.045191, loss_ce: 0.018458
2022-01-13 20:16:12,671 iteration 1661 : loss : 0.066124, loss_ce: 0.024770
2022-01-13 20:16:14,072 iteration 1662 : loss : 0.067708, loss_ce: 0.024384
2022-01-13 20:16:15,492 iteration 1663 : loss : 0.056250, loss_ce: 0.023488
2022-01-13 20:16:16,895 iteration 1664 : loss : 0.107738, loss_ce: 0.037156
2022-01-13 20:16:18,241 iteration 1665 : loss : 0.063920, loss_ce: 0.026126
2022-01-13 20:16:19,612 iteration 1666 : loss : 0.065541, loss_ce: 0.019919
 24%|███████▎                      | 98/400 [41:51<2:02:59, 24.43s/it]2022-01-13 20:16:20,977 iteration 1667 : loss : 0.053474, loss_ce: 0.027453
2022-01-13 20:16:22,408 iteration 1668 : loss : 0.070857, loss_ce: 0.023453
2022-01-13 20:16:23,801 iteration 1669 : loss : 0.083339, loss_ce: 0.034557
2022-01-13 20:16:25,093 iteration 1670 : loss : 0.037925, loss_ce: 0.014542
2022-01-13 20:16:26,399 iteration 1671 : loss : 0.048999, loss_ce: 0.022427
2022-01-13 20:16:27,823 iteration 1672 : loss : 0.066515, loss_ce: 0.024067
2022-01-13 20:16:29,218 iteration 1673 : loss : 0.075208, loss_ce: 0.021218
2022-01-13 20:16:30,672 iteration 1674 : loss : 0.078415, loss_ce: 0.027959
2022-01-13 20:16:32,009 iteration 1675 : loss : 0.075012, loss_ce: 0.024249
2022-01-13 20:16:33,427 iteration 1676 : loss : 0.063841, loss_ce: 0.029184
2022-01-13 20:16:34,815 iteration 1677 : loss : 0.125792, loss_ce: 0.041544
2022-01-13 20:16:36,215 iteration 1678 : loss : 0.065376, loss_ce: 0.034275
2022-01-13 20:16:37,589 iteration 1679 : loss : 0.096727, loss_ce: 0.047662
2022-01-13 20:16:39,012 iteration 1680 : loss : 0.075664, loss_ce: 0.035997
2022-01-13 20:16:40,396 iteration 1681 : loss : 0.092442, loss_ce: 0.045652
2022-01-13 20:16:41,784 iteration 1682 : loss : 0.065583, loss_ce: 0.029969
2022-01-13 20:16:43,140 iteration 1683 : loss : 0.088662, loss_ce: 0.050179
 25%|███████▍                      | 99/400 [42:14<2:01:14, 24.17s/it]2022-01-13 20:16:44,618 iteration 1684 : loss : 0.088399, loss_ce: 0.033191
2022-01-13 20:16:45,971 iteration 1685 : loss : 0.058400, loss_ce: 0.028575
2022-01-13 20:16:47,285 iteration 1686 : loss : 0.051739, loss_ce: 0.020349
2022-01-13 20:16:48,644 iteration 1687 : loss : 0.057187, loss_ce: 0.026600
2022-01-13 20:16:50,050 iteration 1688 : loss : 0.057203, loss_ce: 0.026344
2022-01-13 20:16:51,404 iteration 1689 : loss : 0.063085, loss_ce: 0.024758
2022-01-13 20:16:52,828 iteration 1690 : loss : 0.111004, loss_ce: 0.039587
2022-01-13 20:16:54,192 iteration 1691 : loss : 0.044876, loss_ce: 0.019493
2022-01-13 20:16:55,596 iteration 1692 : loss : 0.084450, loss_ce: 0.032439
2022-01-13 20:16:57,061 iteration 1693 : loss : 0.063594, loss_ce: 0.030305
2022-01-13 20:16:58,483 iteration 1694 : loss : 0.056619, loss_ce: 0.021364
2022-01-13 20:16:59,788 iteration 1695 : loss : 0.058106, loss_ce: 0.020649
2022-01-13 20:17:01,163 iteration 1696 : loss : 0.080983, loss_ce: 0.026146
2022-01-13 20:17:02,596 iteration 1697 : loss : 0.077249, loss_ce: 0.024212
2022-01-13 20:17:03,969 iteration 1698 : loss : 0.054565, loss_ce: 0.017904
2022-01-13 20:17:05,238 iteration 1699 : loss : 0.069917, loss_ce: 0.036040
2022-01-13 20:17:05,238 Training Data Eval:
2022-01-13 20:17:12,046   Average segmentation loss on training set: 0.0545
2022-01-13 20:17:12,046 Validation Data Eval:
2022-01-13 20:17:14,392   Average segmentation loss on validation set: 0.1212
2022-01-13 20:17:15,793 iteration 1700 : loss : 0.066937, loss_ce: 0.020365
 25%|███████▎                     | 100/400 [42:47<2:13:33, 26.71s/it]2022-01-13 20:17:17,282 iteration 1701 : loss : 0.062186, loss_ce: 0.024993
2022-01-13 20:17:18,679 iteration 1702 : loss : 0.066576, loss_ce: 0.030268
2022-01-13 20:17:20,008 iteration 1703 : loss : 0.060862, loss_ce: 0.026179
2022-01-13 20:17:21,472 iteration 1704 : loss : 0.076463, loss_ce: 0.031010
2022-01-13 20:17:22,848 iteration 1705 : loss : 0.060067, loss_ce: 0.029056
2022-01-13 20:17:24,243 iteration 1706 : loss : 0.056741, loss_ce: 0.028538
2022-01-13 20:17:25,623 iteration 1707 : loss : 0.088994, loss_ce: 0.031778
2022-01-13 20:17:27,051 iteration 1708 : loss : 0.052244, loss_ce: 0.018805
2022-01-13 20:17:28,367 iteration 1709 : loss : 0.052587, loss_ce: 0.023613
2022-01-13 20:17:29,664 iteration 1710 : loss : 0.046921, loss_ce: 0.022264
2022-01-13 20:17:31,056 iteration 1711 : loss : 0.051127, loss_ce: 0.020699
2022-01-13 20:17:32,386 iteration 1712 : loss : 0.051320, loss_ce: 0.017648
2022-01-13 20:17:33,700 iteration 1713 : loss : 0.062374, loss_ce: 0.024455
2022-01-13 20:17:35,174 iteration 1714 : loss : 0.074054, loss_ce: 0.022219
2022-01-13 20:17:36,598 iteration 1715 : loss : 0.108493, loss_ce: 0.029371
2022-01-13 20:17:38,069 iteration 1716 : loss : 0.079665, loss_ce: 0.026287
2022-01-13 20:17:39,454 iteration 1717 : loss : 0.064052, loss_ce: 0.026570
 25%|███████▎                     | 101/400 [43:11<2:08:33, 25.80s/it]2022-01-13 20:17:40,866 iteration 1718 : loss : 0.056793, loss_ce: 0.019741
2022-01-13 20:17:42,278 iteration 1719 : loss : 0.062620, loss_ce: 0.027465
2022-01-13 20:17:43,564 iteration 1720 : loss : 0.037520, loss_ce: 0.013138
2022-01-13 20:17:44,942 iteration 1721 : loss : 0.069419, loss_ce: 0.032580
2022-01-13 20:17:46,379 iteration 1722 : loss : 0.058769, loss_ce: 0.021436
2022-01-13 20:17:47,763 iteration 1723 : loss : 0.081931, loss_ce: 0.034167
2022-01-13 20:17:49,186 iteration 1724 : loss : 0.074745, loss_ce: 0.029336
2022-01-13 20:17:50,702 iteration 1725 : loss : 0.113490, loss_ce: 0.045198
2022-01-13 20:17:52,162 iteration 1726 : loss : 0.074163, loss_ce: 0.022529
2022-01-13 20:17:53,563 iteration 1727 : loss : 0.051538, loss_ce: 0.026039
2022-01-13 20:17:54,937 iteration 1728 : loss : 0.072914, loss_ce: 0.024059
2022-01-13 20:17:56,290 iteration 1729 : loss : 0.052480, loss_ce: 0.022580
2022-01-13 20:17:57,667 iteration 1730 : loss : 0.061577, loss_ce: 0.022204
2022-01-13 20:17:59,093 iteration 1731 : loss : 0.070724, loss_ce: 0.030418
2022-01-13 20:18:00,464 iteration 1732 : loss : 0.047647, loss_ce: 0.023029
2022-01-13 20:18:01,899 iteration 1733 : loss : 0.087224, loss_ce: 0.037676
2022-01-13 20:18:03,261 iteration 1734 : loss : 0.050435, loss_ce: 0.017650
 26%|███████▍                     | 102/400 [43:35<2:05:08, 25.20s/it]2022-01-13 20:18:04,648 iteration 1735 : loss : 0.082415, loss_ce: 0.029431
2022-01-13 20:18:05,995 iteration 1736 : loss : 0.047313, loss_ce: 0.019364
2022-01-13 20:18:07,357 iteration 1737 : loss : 0.074261, loss_ce: 0.027724
2022-01-13 20:18:08,688 iteration 1738 : loss : 0.055121, loss_ce: 0.019677
2022-01-13 20:18:10,136 iteration 1739 : loss : 0.077649, loss_ce: 0.034527
2022-01-13 20:18:11,534 iteration 1740 : loss : 0.096832, loss_ce: 0.037259
2022-01-13 20:18:12,888 iteration 1741 : loss : 0.054436, loss_ce: 0.021135
2022-01-13 20:18:14,350 iteration 1742 : loss : 0.080649, loss_ce: 0.034689
2022-01-13 20:18:15,701 iteration 1743 : loss : 0.060864, loss_ce: 0.020138
2022-01-13 20:18:17,091 iteration 1744 : loss : 0.050702, loss_ce: 0.020696
2022-01-13 20:18:18,594 iteration 1745 : loss : 0.100890, loss_ce: 0.057072
2022-01-13 20:18:19,954 iteration 1746 : loss : 0.050728, loss_ce: 0.021745
2022-01-13 20:18:21,299 iteration 1747 : loss : 0.043838, loss_ce: 0.019490
2022-01-13 20:18:22,666 iteration 1748 : loss : 0.059400, loss_ce: 0.024828
2022-01-13 20:18:24,031 iteration 1749 : loss : 0.084972, loss_ce: 0.029837
2022-01-13 20:18:25,343 iteration 1750 : loss : 0.054247, loss_ce: 0.023845
2022-01-13 20:18:26,792 iteration 1751 : loss : 0.085442, loss_ce: 0.036843
 26%|███████▍                     | 103/400 [43:58<2:02:14, 24.70s/it]2022-01-13 20:18:28,189 iteration 1752 : loss : 0.050258, loss_ce: 0.021051
2022-01-13 20:18:29,514 iteration 1753 : loss : 0.060687, loss_ce: 0.026744
2022-01-13 20:18:30,855 iteration 1754 : loss : 0.049279, loss_ce: 0.019959
2022-01-13 20:18:32,209 iteration 1755 : loss : 0.056368, loss_ce: 0.026262
2022-01-13 20:18:33,585 iteration 1756 : loss : 0.067694, loss_ce: 0.032626
2022-01-13 20:18:35,011 iteration 1757 : loss : 0.066710, loss_ce: 0.033594
2022-01-13 20:18:36,409 iteration 1758 : loss : 0.095804, loss_ce: 0.038669
2022-01-13 20:18:37,707 iteration 1759 : loss : 0.084384, loss_ce: 0.028772
2022-01-13 20:18:39,054 iteration 1760 : loss : 0.064261, loss_ce: 0.026781
2022-01-13 20:18:40,372 iteration 1761 : loss : 0.044923, loss_ce: 0.017134
2022-01-13 20:18:41,727 iteration 1762 : loss : 0.068198, loss_ce: 0.026847
2022-01-13 20:18:43,009 iteration 1763 : loss : 0.061584, loss_ce: 0.026615
2022-01-13 20:18:44,459 iteration 1764 : loss : 0.055999, loss_ce: 0.015760
2022-01-13 20:18:45,825 iteration 1765 : loss : 0.069918, loss_ce: 0.025592
2022-01-13 20:18:47,242 iteration 1766 : loss : 0.049991, loss_ce: 0.019800
2022-01-13 20:18:48,623 iteration 1767 : loss : 0.073244, loss_ce: 0.030684
2022-01-13 20:18:49,978 iteration 1768 : loss : 0.066798, loss_ce: 0.024317
 26%|███████▌                     | 104/400 [44:21<1:59:37, 24.25s/it]2022-01-13 20:18:51,430 iteration 1769 : loss : 0.067135, loss_ce: 0.027909
2022-01-13 20:18:52,782 iteration 1770 : loss : 0.064069, loss_ce: 0.020706
2022-01-13 20:18:54,105 iteration 1771 : loss : 0.050730, loss_ce: 0.016857
2022-01-13 20:18:55,520 iteration 1772 : loss : 0.078882, loss_ce: 0.035587
2022-01-13 20:18:56,900 iteration 1773 : loss : 0.076864, loss_ce: 0.031042
2022-01-13 20:18:58,231 iteration 1774 : loss : 0.059026, loss_ce: 0.019330
2022-01-13 20:18:59,571 iteration 1775 : loss : 0.060237, loss_ce: 0.023288
2022-01-13 20:19:00,899 iteration 1776 : loss : 0.079768, loss_ce: 0.028701
2022-01-13 20:19:02,208 iteration 1777 : loss : 0.065975, loss_ce: 0.026202
2022-01-13 20:19:03,611 iteration 1778 : loss : 0.067143, loss_ce: 0.030209
2022-01-13 20:19:04,979 iteration 1779 : loss : 0.061771, loss_ce: 0.029165
2022-01-13 20:19:06,366 iteration 1780 : loss : 0.124129, loss_ce: 0.046039
2022-01-13 20:19:07,755 iteration 1781 : loss : 0.061320, loss_ce: 0.023736
2022-01-13 20:19:09,050 iteration 1782 : loss : 0.075433, loss_ce: 0.020397
2022-01-13 20:19:10,375 iteration 1783 : loss : 0.072563, loss_ce: 0.032628
2022-01-13 20:19:11,759 iteration 1784 : loss : 0.087902, loss_ce: 0.042725
2022-01-13 20:19:11,759 Training Data Eval:
2022-01-13 20:19:18,492   Average segmentation loss on training set: 0.0428
2022-01-13 20:19:18,493 Validation Data Eval:
2022-01-13 20:19:20,816   Average segmentation loss on validation set: 0.1047
2022-01-13 20:19:22,172 iteration 1785 : loss : 0.057128, loss_ce: 0.026774
 26%|███████▌                     | 105/400 [44:53<2:10:56, 26.63s/it]2022-01-13 20:19:23,662 iteration 1786 : loss : 0.066533, loss_ce: 0.020596
2022-01-13 20:19:24,972 iteration 1787 : loss : 0.064380, loss_ce: 0.016676
2022-01-13 20:19:26,343 iteration 1788 : loss : 0.061512, loss_ce: 0.020165
2022-01-13 20:19:27,716 iteration 1789 : loss : 0.055035, loss_ce: 0.026816
2022-01-13 20:19:29,213 iteration 1790 : loss : 0.053152, loss_ce: 0.023342
2022-01-13 20:19:30,596 iteration 1791 : loss : 0.064465, loss_ce: 0.028054
2022-01-13 20:19:31,987 iteration 1792 : loss : 0.045920, loss_ce: 0.017728
2022-01-13 20:19:33,385 iteration 1793 : loss : 0.092592, loss_ce: 0.037748
2022-01-13 20:19:34,741 iteration 1794 : loss : 0.066038, loss_ce: 0.035871
2022-01-13 20:19:36,017 iteration 1795 : loss : 0.047430, loss_ce: 0.019756
2022-01-13 20:19:37,446 iteration 1796 : loss : 0.072945, loss_ce: 0.035960
2022-01-13 20:19:38,768 iteration 1797 : loss : 0.061085, loss_ce: 0.025666
2022-01-13 20:19:40,139 iteration 1798 : loss : 0.078001, loss_ce: 0.028170
2022-01-13 20:19:41,564 iteration 1799 : loss : 0.059754, loss_ce: 0.024665
2022-01-13 20:19:42,874 iteration 1800 : loss : 0.060867, loss_ce: 0.019787
2022-01-13 20:19:44,233 iteration 1801 : loss : 0.073652, loss_ce: 0.028902
2022-01-13 20:19:45,646 iteration 1802 : loss : 0.073366, loss_ce: 0.027955
 26%|███████▋                     | 106/400 [45:17<2:05:50, 25.68s/it]2022-01-13 20:19:47,157 iteration 1803 : loss : 0.064993, loss_ce: 0.026248
2022-01-13 20:19:48,471 iteration 1804 : loss : 0.062778, loss_ce: 0.022633
2022-01-13 20:19:49,985 iteration 1805 : loss : 0.072296, loss_ce: 0.027438
2022-01-13 20:19:51,467 iteration 1806 : loss : 0.077590, loss_ce: 0.038905
2022-01-13 20:19:52,831 iteration 1807 : loss : 0.060904, loss_ce: 0.025413
2022-01-13 20:19:54,277 iteration 1808 : loss : 0.037735, loss_ce: 0.016622
2022-01-13 20:19:55,659 iteration 1809 : loss : 0.067643, loss_ce: 0.034528
2022-01-13 20:19:57,095 iteration 1810 : loss : 0.076576, loss_ce: 0.035039
2022-01-13 20:19:58,472 iteration 1811 : loss : 0.072140, loss_ce: 0.028235
2022-01-13 20:19:59,843 iteration 1812 : loss : 0.052400, loss_ce: 0.019499
2022-01-13 20:20:01,244 iteration 1813 : loss : 0.067235, loss_ce: 0.035083
2022-01-13 20:20:02,611 iteration 1814 : loss : 0.082124, loss_ce: 0.029976
2022-01-13 20:20:04,093 iteration 1815 : loss : 0.081186, loss_ce: 0.025946
2022-01-13 20:20:05,509 iteration 1816 : loss : 0.050757, loss_ce: 0.021037
2022-01-13 20:20:06,993 iteration 1817 : loss : 0.059938, loss_ce: 0.025159
2022-01-13 20:20:08,329 iteration 1818 : loss : 0.042747, loss_ce: 0.016883
2022-01-13 20:20:09,781 iteration 1819 : loss : 0.094195, loss_ce: 0.045376
 27%|███████▊                     | 107/400 [45:41<2:03:09, 25.22s/it]2022-01-13 20:20:11,124 iteration 1820 : loss : 0.070967, loss_ce: 0.037340
2022-01-13 20:20:12,651 iteration 1821 : loss : 0.061295, loss_ce: 0.022319
2022-01-13 20:20:14,109 iteration 1822 : loss : 0.085732, loss_ce: 0.046091
2022-01-13 20:20:15,595 iteration 1823 : loss : 0.082574, loss_ce: 0.027475
2022-01-13 20:20:17,027 iteration 1824 : loss : 0.073928, loss_ce: 0.024104
2022-01-13 20:20:18,383 iteration 1825 : loss : 0.066304, loss_ce: 0.026788
2022-01-13 20:20:19,857 iteration 1826 : loss : 0.073376, loss_ce: 0.026365
2022-01-13 20:20:21,203 iteration 1827 : loss : 0.038229, loss_ce: 0.013556
2022-01-13 20:20:22,611 iteration 1828 : loss : 0.074674, loss_ce: 0.037373
2022-01-13 20:20:23,971 iteration 1829 : loss : 0.074641, loss_ce: 0.035754
2022-01-13 20:20:25,439 iteration 1830 : loss : 0.078694, loss_ce: 0.028509
2022-01-13 20:20:26,835 iteration 1831 : loss : 0.066196, loss_ce: 0.026889
2022-01-13 20:20:28,235 iteration 1832 : loss : 0.057685, loss_ce: 0.024515
2022-01-13 20:20:29,571 iteration 1833 : loss : 0.059772, loss_ce: 0.026999
2022-01-13 20:20:30,961 iteration 1834 : loss : 0.069735, loss_ce: 0.028175
2022-01-13 20:20:32,361 iteration 1835 : loss : 0.065127, loss_ce: 0.024358
2022-01-13 20:20:33,715 iteration 1836 : loss : 0.080207, loss_ce: 0.028535
 27%|███████▊                     | 108/400 [46:05<2:00:51, 24.83s/it]2022-01-13 20:20:35,217 iteration 1837 : loss : 0.058500, loss_ce: 0.022157
2022-01-13 20:20:36,526 iteration 1838 : loss : 0.059091, loss_ce: 0.027249
2022-01-13 20:20:37,876 iteration 1839 : loss : 0.074000, loss_ce: 0.031917
2022-01-13 20:20:39,293 iteration 1840 : loss : 0.046684, loss_ce: 0.021473
2022-01-13 20:20:40,619 iteration 1841 : loss : 0.071824, loss_ce: 0.035018
2022-01-13 20:20:41,996 iteration 1842 : loss : 0.043377, loss_ce: 0.015121
2022-01-13 20:20:43,395 iteration 1843 : loss : 0.045271, loss_ce: 0.023678
2022-01-13 20:20:44,773 iteration 1844 : loss : 0.059801, loss_ce: 0.022257
2022-01-13 20:20:46,133 iteration 1845 : loss : 0.072735, loss_ce: 0.025268
2022-01-13 20:20:47,604 iteration 1846 : loss : 0.065357, loss_ce: 0.032495
2022-01-13 20:20:48,965 iteration 1847 : loss : 0.068364, loss_ce: 0.027329
2022-01-13 20:20:50,337 iteration 1848 : loss : 0.074311, loss_ce: 0.028582
2022-01-13 20:20:51,694 iteration 1849 : loss : 0.067941, loss_ce: 0.028044
2022-01-13 20:20:53,225 iteration 1850 : loss : 0.089402, loss_ce: 0.032652
2022-01-13 20:20:54,612 iteration 1851 : loss : 0.107209, loss_ce: 0.034646
2022-01-13 20:20:56,025 iteration 1852 : loss : 0.062408, loss_ce: 0.028874
2022-01-13 20:20:57,388 iteration 1853 : loss : 0.070514, loss_ce: 0.031202
 27%|███████▉                     | 109/400 [46:29<1:58:45, 24.49s/it]2022-01-13 20:20:58,803 iteration 1854 : loss : 0.054096, loss_ce: 0.021445
2022-01-13 20:21:00,253 iteration 1855 : loss : 0.056226, loss_ce: 0.022092
2022-01-13 20:21:01,702 iteration 1856 : loss : 0.079478, loss_ce: 0.027255
2022-01-13 20:21:03,160 iteration 1857 : loss : 0.062184, loss_ce: 0.025047
2022-01-13 20:21:04,613 iteration 1858 : loss : 0.076358, loss_ce: 0.036978
2022-01-13 20:21:06,029 iteration 1859 : loss : 0.059826, loss_ce: 0.024020
2022-01-13 20:21:07,371 iteration 1860 : loss : 0.053095, loss_ce: 0.020557
2022-01-13 20:21:08,819 iteration 1861 : loss : 0.059159, loss_ce: 0.023487
2022-01-13 20:21:10,151 iteration 1862 : loss : 0.051936, loss_ce: 0.025756
2022-01-13 20:21:11,546 iteration 1863 : loss : 0.082483, loss_ce: 0.037981
2022-01-13 20:21:13,001 iteration 1864 : loss : 0.099804, loss_ce: 0.025857
2022-01-13 20:21:14,313 iteration 1865 : loss : 0.054970, loss_ce: 0.024614
2022-01-13 20:21:15,797 iteration 1866 : loss : 0.038021, loss_ce: 0.017171
2022-01-13 20:21:17,217 iteration 1867 : loss : 0.043432, loss_ce: 0.019520
2022-01-13 20:21:18,588 iteration 1868 : loss : 0.057219, loss_ce: 0.026513
2022-01-13 20:21:19,948 iteration 1869 : loss : 0.158490, loss_ce: 0.058525
2022-01-13 20:21:19,948 Training Data Eval:
2022-01-13 20:21:26,821   Average segmentation loss on training set: 0.0421
2022-01-13 20:21:26,821 Validation Data Eval:
2022-01-13 20:21:29,180   Average segmentation loss on validation set: 0.0911
2022-01-13 20:21:30,616 iteration 1870 : loss : 0.058072, loss_ce: 0.022150
 28%|███████▉                     | 110/400 [47:02<2:11:01, 27.11s/it]2022-01-13 20:21:32,126 iteration 1871 : loss : 0.100873, loss_ce: 0.041183
2022-01-13 20:21:33,643 iteration 1872 : loss : 0.090097, loss_ce: 0.027431
2022-01-13 20:21:34,984 iteration 1873 : loss : 0.056763, loss_ce: 0.023788
2022-01-13 20:21:36,452 iteration 1874 : loss : 0.088868, loss_ce: 0.039089
2022-01-13 20:21:37,756 iteration 1875 : loss : 0.052027, loss_ce: 0.019284
2022-01-13 20:21:39,231 iteration 1876 : loss : 0.044210, loss_ce: 0.013445
2022-01-13 20:21:40,675 iteration 1877 : loss : 0.080401, loss_ce: 0.034822
2022-01-13 20:21:42,043 iteration 1878 : loss : 0.050983, loss_ce: 0.021760
2022-01-13 20:21:43,404 iteration 1879 : loss : 0.054031, loss_ce: 0.023236
2022-01-13 20:21:44,756 iteration 1880 : loss : 0.064522, loss_ce: 0.029119
2022-01-13 20:21:46,148 iteration 1881 : loss : 0.071575, loss_ce: 0.025511
2022-01-13 20:21:47,533 iteration 1882 : loss : 0.066520, loss_ce: 0.026863
2022-01-13 20:21:48,834 iteration 1883 : loss : 0.074458, loss_ce: 0.025963
2022-01-13 20:21:50,263 iteration 1884 : loss : 0.059688, loss_ce: 0.024259
2022-01-13 20:21:51,559 iteration 1885 : loss : 0.060426, loss_ce: 0.027379
2022-01-13 20:21:53,037 iteration 1886 : loss : 0.067024, loss_ce: 0.031302
2022-01-13 20:21:54,509 iteration 1887 : loss : 0.087148, loss_ce: 0.040463
 28%|████████                     | 111/400 [47:26<2:05:55, 26.15s/it]2022-01-13 20:21:55,974 iteration 1888 : loss : 0.059894, loss_ce: 0.025788
2022-01-13 20:21:57,433 iteration 1889 : loss : 0.080772, loss_ce: 0.033538
2022-01-13 20:21:58,871 iteration 1890 : loss : 0.085254, loss_ce: 0.034665
2022-01-13 20:22:00,323 iteration 1891 : loss : 0.074449, loss_ce: 0.026227
2022-01-13 20:22:01,736 iteration 1892 : loss : 0.060470, loss_ce: 0.028912
2022-01-13 20:22:03,161 iteration 1893 : loss : 0.055851, loss_ce: 0.031533
2022-01-13 20:22:04,551 iteration 1894 : loss : 0.067151, loss_ce: 0.030059
2022-01-13 20:22:05,932 iteration 1895 : loss : 0.096702, loss_ce: 0.031480
2022-01-13 20:22:07,469 iteration 1896 : loss : 0.122012, loss_ce: 0.071565
2022-01-13 20:22:08,851 iteration 1897 : loss : 0.098359, loss_ce: 0.029988
2022-01-13 20:22:10,312 iteration 1898 : loss : 0.066254, loss_ce: 0.026692
2022-01-13 20:22:11,704 iteration 1899 : loss : 0.083700, loss_ce: 0.047473
2022-01-13 20:22:13,015 iteration 1900 : loss : 0.055570, loss_ce: 0.022210
2022-01-13 20:22:14,407 iteration 1901 : loss : 0.063008, loss_ce: 0.025440
2022-01-13 20:22:15,831 iteration 1902 : loss : 0.066475, loss_ce: 0.030570
2022-01-13 20:22:17,286 iteration 1903 : loss : 0.086235, loss_ce: 0.025910
2022-01-13 20:22:18,798 iteration 1904 : loss : 0.082026, loss_ce: 0.028973
 28%|████████                     | 112/400 [47:50<2:02:48, 25.59s/it]2022-01-13 20:22:20,198 iteration 1905 : loss : 0.060132, loss_ce: 0.027388
2022-01-13 20:22:21,664 iteration 1906 : loss : 0.086942, loss_ce: 0.039043
2022-01-13 20:22:23,188 iteration 1907 : loss : 0.068812, loss_ce: 0.023101
2022-01-13 20:22:24,629 iteration 1908 : loss : 0.080958, loss_ce: 0.032215
2022-01-13 20:22:26,104 iteration 1909 : loss : 0.078687, loss_ce: 0.042195
2022-01-13 20:22:27,564 iteration 1910 : loss : 0.051518, loss_ce: 0.023552
2022-01-13 20:22:29,105 iteration 1911 : loss : 0.056900, loss_ce: 0.023980
2022-01-13 20:22:30,559 iteration 1912 : loss : 0.108982, loss_ce: 0.032916
2022-01-13 20:22:31,953 iteration 1913 : loss : 0.086235, loss_ce: 0.036211
2022-01-13 20:22:33,310 iteration 1914 : loss : 0.064521, loss_ce: 0.029989
2022-01-13 20:22:34,720 iteration 1915 : loss : 0.087255, loss_ce: 0.035463
2022-01-13 20:22:36,116 iteration 1916 : loss : 0.072282, loss_ce: 0.029075
2022-01-13 20:22:37,550 iteration 1917 : loss : 0.074502, loss_ce: 0.029381
2022-01-13 20:22:38,906 iteration 1918 : loss : 0.101652, loss_ce: 0.051053
2022-01-13 20:22:40,287 iteration 1919 : loss : 0.069968, loss_ce: 0.029167
2022-01-13 20:22:41,677 iteration 1920 : loss : 0.059091, loss_ce: 0.021971
2022-01-13 20:22:43,115 iteration 1921 : loss : 0.090056, loss_ce: 0.037956
 28%|████████▏                    | 113/400 [48:14<2:00:33, 25.20s/it]2022-01-13 20:22:44,515 iteration 1922 : loss : 0.055124, loss_ce: 0.021452
2022-01-13 20:22:45,831 iteration 1923 : loss : 0.042011, loss_ce: 0.018589
2022-01-13 20:22:47,253 iteration 1924 : loss : 0.124407, loss_ce: 0.081145
2022-01-13 20:22:48,594 iteration 1925 : loss : 0.066527, loss_ce: 0.028134
2022-01-13 20:22:49,950 iteration 1926 : loss : 0.063403, loss_ce: 0.030650
2022-01-13 20:22:51,395 iteration 1927 : loss : 0.105203, loss_ce: 0.052842
2022-01-13 20:22:52,847 iteration 1928 : loss : 0.052727, loss_ce: 0.022480
2022-01-13 20:22:54,217 iteration 1929 : loss : 0.063559, loss_ce: 0.032093
2022-01-13 20:22:55,613 iteration 1930 : loss : 0.111814, loss_ce: 0.041966
2022-01-13 20:22:56,978 iteration 1931 : loss : 0.084434, loss_ce: 0.026593
2022-01-13 20:22:58,373 iteration 1932 : loss : 0.075649, loss_ce: 0.024908
2022-01-13 20:22:59,769 iteration 1933 : loss : 0.060307, loss_ce: 0.023854
2022-01-13 20:23:01,032 iteration 1934 : loss : 0.064011, loss_ce: 0.031071
2022-01-13 20:23:02,393 iteration 1935 : loss : 0.069179, loss_ce: 0.031845
2022-01-13 20:23:03,831 iteration 1936 : loss : 0.070188, loss_ce: 0.029380
2022-01-13 20:23:05,264 iteration 1937 : loss : 0.062392, loss_ce: 0.028722
2022-01-13 20:23:06,698 iteration 1938 : loss : 0.073559, loss_ce: 0.021025
 28%|████████▎                    | 114/400 [48:38<1:57:50, 24.72s/it]2022-01-13 20:23:08,085 iteration 1939 : loss : 0.041814, loss_ce: 0.018740
2022-01-13 20:23:09,454 iteration 1940 : loss : 0.035743, loss_ce: 0.013600
2022-01-13 20:23:10,907 iteration 1941 : loss : 0.056512, loss_ce: 0.029083
2022-01-13 20:23:12,297 iteration 1942 : loss : 0.062391, loss_ce: 0.017994
2022-01-13 20:23:13,609 iteration 1943 : loss : 0.074124, loss_ce: 0.023467
2022-01-13 20:23:14,967 iteration 1944 : loss : 0.049657, loss_ce: 0.019080
2022-01-13 20:23:16,342 iteration 1945 : loss : 0.056616, loss_ce: 0.029035
2022-01-13 20:23:17,719 iteration 1946 : loss : 0.075167, loss_ce: 0.028656
2022-01-13 20:23:19,087 iteration 1947 : loss : 0.079628, loss_ce: 0.029680
2022-01-13 20:23:20,448 iteration 1948 : loss : 0.062937, loss_ce: 0.028172
2022-01-13 20:23:21,757 iteration 1949 : loss : 0.062915, loss_ce: 0.031157
2022-01-13 20:23:23,190 iteration 1950 : loss : 0.053345, loss_ce: 0.020445
2022-01-13 20:23:24,696 iteration 1951 : loss : 0.079017, loss_ce: 0.031040
2022-01-13 20:23:26,027 iteration 1952 : loss : 0.069226, loss_ce: 0.021351
2022-01-13 20:23:27,438 iteration 1953 : loss : 0.056868, loss_ce: 0.030064
2022-01-13 20:23:28,909 iteration 1954 : loss : 0.065959, loss_ce: 0.022110
2022-01-13 20:23:28,910 Training Data Eval:
2022-01-13 20:23:35,723   Average segmentation loss on training set: 0.0461
2022-01-13 20:23:35,723 Validation Data Eval:
2022-01-13 20:23:38,073   Average segmentation loss on validation set: 0.1053
2022-01-13 20:23:39,441 iteration 1955 : loss : 0.052450, loss_ce: 0.019067
 29%|████████▎                    | 115/400 [49:11<2:08:51, 27.13s/it]2022-01-13 20:23:40,945 iteration 1956 : loss : 0.068094, loss_ce: 0.029888
2022-01-13 20:23:42,279 iteration 1957 : loss : 0.057013, loss_ce: 0.024479
2022-01-13 20:23:43,642 iteration 1958 : loss : 0.065324, loss_ce: 0.030628
2022-01-13 20:23:45,117 iteration 1959 : loss : 0.073750, loss_ce: 0.024762
2022-01-13 20:23:46,484 iteration 1960 : loss : 0.071271, loss_ce: 0.024459
2022-01-13 20:23:47,880 iteration 1961 : loss : 0.085690, loss_ce: 0.035837
2022-01-13 20:23:49,260 iteration 1962 : loss : 0.048560, loss_ce: 0.020587
2022-01-13 20:23:50,676 iteration 1963 : loss : 0.056427, loss_ce: 0.024627
2022-01-13 20:23:52,053 iteration 1964 : loss : 0.064859, loss_ce: 0.019600
2022-01-13 20:23:53,403 iteration 1965 : loss : 0.058459, loss_ce: 0.026950
2022-01-13 20:23:54,748 iteration 1966 : loss : 0.056135, loss_ce: 0.025735
2022-01-13 20:23:56,080 iteration 1967 : loss : 0.061679, loss_ce: 0.020320
2022-01-13 20:23:57,391 iteration 1968 : loss : 0.057278, loss_ce: 0.028594
2022-01-13 20:23:58,809 iteration 1969 : loss : 0.055996, loss_ce: 0.023965
2022-01-13 20:24:00,348 iteration 1970 : loss : 0.061611, loss_ce: 0.023212
2022-01-13 20:24:01,641 iteration 1971 : loss : 0.044947, loss_ce: 0.014505
2022-01-13 20:24:03,159 iteration 1972 : loss : 0.088147, loss_ce: 0.033255
 29%|████████▍                    | 116/400 [49:34<2:03:33, 26.11s/it]2022-01-13 20:24:04,520 iteration 1973 : loss : 0.037676, loss_ce: 0.015275
2022-01-13 20:24:05,836 iteration 1974 : loss : 0.059389, loss_ce: 0.028001
2022-01-13 20:24:07,308 iteration 1975 : loss : 0.052872, loss_ce: 0.024276
2022-01-13 20:24:08,613 iteration 1976 : loss : 0.078539, loss_ce: 0.037871
2022-01-13 20:24:10,093 iteration 1977 : loss : 0.107153, loss_ce: 0.049700
2022-01-13 20:24:11,444 iteration 1978 : loss : 0.054442, loss_ce: 0.022757
2022-01-13 20:24:12,810 iteration 1979 : loss : 0.048872, loss_ce: 0.024310
2022-01-13 20:24:14,249 iteration 1980 : loss : 0.056872, loss_ce: 0.020045
2022-01-13 20:24:15,590 iteration 1981 : loss : 0.049168, loss_ce: 0.021043
2022-01-13 20:24:17,043 iteration 1982 : loss : 0.049871, loss_ce: 0.019780
2022-01-13 20:24:18,532 iteration 1983 : loss : 0.063065, loss_ce: 0.027928
2022-01-13 20:24:19,887 iteration 1984 : loss : 0.066154, loss_ce: 0.023148
2022-01-13 20:24:21,253 iteration 1985 : loss : 0.059596, loss_ce: 0.019983
2022-01-13 20:24:22,598 iteration 1986 : loss : 0.074660, loss_ce: 0.028106
2022-01-13 20:24:23,938 iteration 1987 : loss : 0.027516, loss_ce: 0.011620
2022-01-13 20:24:25,420 iteration 1988 : loss : 0.053634, loss_ce: 0.026082
2022-01-13 20:24:26,809 iteration 1989 : loss : 0.044780, loss_ce: 0.022679
 29%|████████▍                    | 117/400 [49:58<1:59:37, 25.36s/it]2022-01-13 20:24:28,248 iteration 1990 : loss : 0.088036, loss_ce: 0.040515
2022-01-13 20:24:29,543 iteration 1991 : loss : 0.046086, loss_ce: 0.021796
2022-01-13 20:24:30,971 iteration 1992 : loss : 0.059729, loss_ce: 0.023940
2022-01-13 20:24:32,347 iteration 1993 : loss : 0.065440, loss_ce: 0.021829
2022-01-13 20:24:33,779 iteration 1994 : loss : 0.048793, loss_ce: 0.019378
2022-01-13 20:24:35,172 iteration 1995 : loss : 0.066890, loss_ce: 0.025138
2022-01-13 20:24:36,575 iteration 1996 : loss : 0.064012, loss_ce: 0.029092
2022-01-13 20:24:37,973 iteration 1997 : loss : 0.052991, loss_ce: 0.024089
2022-01-13 20:24:39,400 iteration 1998 : loss : 0.093293, loss_ce: 0.044245
2022-01-13 20:24:40,823 iteration 1999 : loss : 0.067967, loss_ce: 0.030233
2022-01-13 20:24:42,356 iteration 2000 : loss : 0.092060, loss_ce: 0.026158
2022-01-13 20:24:43,760 iteration 2001 : loss : 0.048685, loss_ce: 0.018939
2022-01-13 20:24:45,074 iteration 2002 : loss : 0.051855, loss_ce: 0.021865
2022-01-13 20:24:46,326 iteration 2003 : loss : 0.034217, loss_ce: 0.017619
2022-01-13 20:24:47,672 iteration 2004 : loss : 0.078840, loss_ce: 0.028026
2022-01-13 20:24:49,105 iteration 2005 : loss : 0.051201, loss_ce: 0.020410
2022-01-13 20:24:50,521 iteration 2006 : loss : 0.060582, loss_ce: 0.023146
 30%|████████▌                    | 118/400 [50:22<1:56:53, 24.87s/it]2022-01-13 20:24:52,039 iteration 2007 : loss : 0.049026, loss_ce: 0.018313
2022-01-13 20:24:53,569 iteration 2008 : loss : 0.050792, loss_ce: 0.018155
2022-01-13 20:24:54,971 iteration 2009 : loss : 0.049764, loss_ce: 0.020822
2022-01-13 20:24:56,359 iteration 2010 : loss : 0.051891, loss_ce: 0.023500
2022-01-13 20:24:57,851 iteration 2011 : loss : 0.063084, loss_ce: 0.024279
2022-01-13 20:24:59,260 iteration 2012 : loss : 0.044921, loss_ce: 0.021356
2022-01-13 20:25:00,575 iteration 2013 : loss : 0.044364, loss_ce: 0.018510
2022-01-13 20:25:01,941 iteration 2014 : loss : 0.059549, loss_ce: 0.022549
2022-01-13 20:25:03,378 iteration 2015 : loss : 0.042579, loss_ce: 0.019193
2022-01-13 20:25:04,761 iteration 2016 : loss : 0.068462, loss_ce: 0.025834
2022-01-13 20:25:06,209 iteration 2017 : loss : 0.037528, loss_ce: 0.012094
2022-01-13 20:25:07,722 iteration 2018 : loss : 0.098826, loss_ce: 0.056353
2022-01-13 20:25:09,104 iteration 2019 : loss : 0.066346, loss_ce: 0.023060
2022-01-13 20:25:10,467 iteration 2020 : loss : 0.035755, loss_ce: 0.012981
2022-01-13 20:25:11,893 iteration 2021 : loss : 0.057010, loss_ce: 0.021720
2022-01-13 20:25:13,320 iteration 2022 : loss : 0.039063, loss_ce: 0.017377
2022-01-13 20:25:14,793 iteration 2023 : loss : 0.055665, loss_ce: 0.020952
 30%|████████▋                    | 119/400 [50:46<1:55:37, 24.69s/it]2022-01-13 20:25:16,205 iteration 2024 : loss : 0.052003, loss_ce: 0.018295
2022-01-13 20:25:17,619 iteration 2025 : loss : 0.039721, loss_ce: 0.018894
2022-01-13 20:25:19,081 iteration 2026 : loss : 0.046135, loss_ce: 0.018865
2022-01-13 20:25:20,462 iteration 2027 : loss : 0.037182, loss_ce: 0.010918
2022-01-13 20:25:21,801 iteration 2028 : loss : 0.034310, loss_ce: 0.017416
2022-01-13 20:25:23,171 iteration 2029 : loss : 0.047065, loss_ce: 0.019018
2022-01-13 20:25:24,546 iteration 2030 : loss : 0.054199, loss_ce: 0.022317
2022-01-13 20:25:25,939 iteration 2031 : loss : 0.050767, loss_ce: 0.019541
2022-01-13 20:25:27,434 iteration 2032 : loss : 0.065192, loss_ce: 0.027033
2022-01-13 20:25:28,963 iteration 2033 : loss : 0.060820, loss_ce: 0.027797
2022-01-13 20:25:30,328 iteration 2034 : loss : 0.046570, loss_ce: 0.019015
2022-01-13 20:25:31,734 iteration 2035 : loss : 0.048172, loss_ce: 0.015977
2022-01-13 20:25:33,182 iteration 2036 : loss : 0.054039, loss_ce: 0.030049
2022-01-13 20:25:34,580 iteration 2037 : loss : 0.091542, loss_ce: 0.024028
2022-01-13 20:25:36,027 iteration 2038 : loss : 0.063465, loss_ce: 0.025276
2022-01-13 20:25:37,526 iteration 2039 : loss : 0.059105, loss_ce: 0.025821
2022-01-13 20:25:37,526 Training Data Eval:
2022-01-13 20:25:44,349   Average segmentation loss on training set: 0.0339
2022-01-13 20:25:44,349 Validation Data Eval:
2022-01-13 20:25:46,691   Average segmentation loss on validation set: 0.0954
2022-01-13 20:25:48,168 iteration 2040 : loss : 0.087008, loss_ce: 0.041017
 30%|████████▋                    | 120/400 [51:19<2:07:24, 27.30s/it]2022-01-13 20:25:49,686 iteration 2041 : loss : 0.070798, loss_ce: 0.020175
2022-01-13 20:25:51,061 iteration 2042 : loss : 0.045420, loss_ce: 0.018819
2022-01-13 20:25:52,432 iteration 2043 : loss : 0.036271, loss_ce: 0.014104
2022-01-13 20:25:53,820 iteration 2044 : loss : 0.047742, loss_ce: 0.019636
2022-01-13 20:25:55,180 iteration 2045 : loss : 0.037453, loss_ce: 0.012793
2022-01-13 20:25:56,589 iteration 2046 : loss : 0.068732, loss_ce: 0.032359
2022-01-13 20:25:57,955 iteration 2047 : loss : 0.054671, loss_ce: 0.023258
2022-01-13 20:25:59,361 iteration 2048 : loss : 0.043086, loss_ce: 0.016643
2022-01-13 20:26:00,727 iteration 2049 : loss : 0.050993, loss_ce: 0.015237
2022-01-13 20:26:02,143 iteration 2050 : loss : 0.060156, loss_ce: 0.028669
2022-01-13 20:26:03,558 iteration 2051 : loss : 0.050616, loss_ce: 0.023256
2022-01-13 20:26:04,890 iteration 2052 : loss : 0.074228, loss_ce: 0.031786
2022-01-13 20:26:06,301 iteration 2053 : loss : 0.065712, loss_ce: 0.020418
2022-01-13 20:26:07,672 iteration 2054 : loss : 0.038005, loss_ce: 0.015840
2022-01-13 20:26:09,054 iteration 2055 : loss : 0.055980, loss_ce: 0.018753
2022-01-13 20:26:10,499 iteration 2056 : loss : 0.059974, loss_ce: 0.025645
2022-01-13 20:26:11,839 iteration 2057 : loss : 0.054344, loss_ce: 0.023823
 30%|████████▊                    | 121/400 [51:43<2:01:51, 26.21s/it]2022-01-13 20:26:13,303 iteration 2058 : loss : 0.052328, loss_ce: 0.025781
2022-01-13 20:26:14,764 iteration 2059 : loss : 0.073818, loss_ce: 0.030376
2022-01-13 20:26:16,068 iteration 2060 : loss : 0.047710, loss_ce: 0.017340
2022-01-13 20:26:17,500 iteration 2061 : loss : 0.072231, loss_ce: 0.028088
2022-01-13 20:26:18,876 iteration 2062 : loss : 0.073343, loss_ce: 0.030202
2022-01-13 20:26:20,259 iteration 2063 : loss : 0.100511, loss_ce: 0.031158
2022-01-13 20:26:21,592 iteration 2064 : loss : 0.038087, loss_ce: 0.015525
2022-01-13 20:26:22,960 iteration 2065 : loss : 0.067542, loss_ce: 0.022869
2022-01-13 20:26:24,351 iteration 2066 : loss : 0.043861, loss_ce: 0.020040
2022-01-13 20:26:25,775 iteration 2067 : loss : 0.045106, loss_ce: 0.018140
2022-01-13 20:26:27,239 iteration 2068 : loss : 0.041299, loss_ce: 0.019040
2022-01-13 20:26:28,603 iteration 2069 : loss : 0.056883, loss_ce: 0.017536
2022-01-13 20:26:30,051 iteration 2070 : loss : 0.055820, loss_ce: 0.025145
2022-01-13 20:26:31,518 iteration 2071 : loss : 0.076108, loss_ce: 0.029762
2022-01-13 20:26:32,926 iteration 2072 : loss : 0.078018, loss_ce: 0.035538
2022-01-13 20:26:34,388 iteration 2073 : loss : 0.071493, loss_ce: 0.025350
2022-01-13 20:26:35,824 iteration 2074 : loss : 0.051231, loss_ce: 0.025765
 30%|████████▊                    | 122/400 [52:07<1:58:21, 25.54s/it]2022-01-13 20:26:37,254 iteration 2075 : loss : 0.035971, loss_ce: 0.013439
2022-01-13 20:26:38,663 iteration 2076 : loss : 0.047759, loss_ce: 0.014736
2022-01-13 20:26:40,090 iteration 2077 : loss : 0.068986, loss_ce: 0.032979
2022-01-13 20:26:41,627 iteration 2078 : loss : 0.061653, loss_ce: 0.022033
2022-01-13 20:26:43,007 iteration 2079 : loss : 0.055664, loss_ce: 0.021688
2022-01-13 20:26:44,473 iteration 2080 : loss : 0.064239, loss_ce: 0.025140
2022-01-13 20:26:45,778 iteration 2081 : loss : 0.047473, loss_ce: 0.018590
2022-01-13 20:26:47,062 iteration 2082 : loss : 0.040575, loss_ce: 0.018318
2022-01-13 20:26:48,439 iteration 2083 : loss : 0.067788, loss_ce: 0.036954
2022-01-13 20:26:49,815 iteration 2084 : loss : 0.067227, loss_ce: 0.032870
2022-01-13 20:26:51,156 iteration 2085 : loss : 0.068503, loss_ce: 0.022971
2022-01-13 20:26:52,539 iteration 2086 : loss : 0.070056, loss_ce: 0.030331
2022-01-13 20:26:53,889 iteration 2087 : loss : 0.073225, loss_ce: 0.027027
2022-01-13 20:26:55,360 iteration 2088 : loss : 0.056951, loss_ce: 0.021165
2022-01-13 20:26:56,805 iteration 2089 : loss : 0.067878, loss_ce: 0.032184
2022-01-13 20:26:58,126 iteration 2090 : loss : 0.057810, loss_ce: 0.021857
2022-01-13 20:26:59,566 iteration 2091 : loss : 0.055861, loss_ce: 0.023300
 31%|████████▉                    | 123/400 [52:31<1:55:25, 25.00s/it]2022-01-13 20:27:00,942 iteration 2092 : loss : 0.046946, loss_ce: 0.021393
2022-01-13 20:27:02,312 iteration 2093 : loss : 0.075855, loss_ce: 0.033062
2022-01-13 20:27:03,706 iteration 2094 : loss : 0.074390, loss_ce: 0.020383
2022-01-13 20:27:05,034 iteration 2095 : loss : 0.040010, loss_ce: 0.018456
2022-01-13 20:27:06,527 iteration 2096 : loss : 0.069918, loss_ce: 0.032408
2022-01-13 20:27:07,952 iteration 2097 : loss : 0.091926, loss_ce: 0.029393
2022-01-13 20:27:09,357 iteration 2098 : loss : 0.075524, loss_ce: 0.029050
2022-01-13 20:27:10,777 iteration 2099 : loss : 0.050768, loss_ce: 0.015013
2022-01-13 20:27:12,218 iteration 2100 : loss : 0.084128, loss_ce: 0.042651
2022-01-13 20:27:13,636 iteration 2101 : loss : 0.049523, loss_ce: 0.015687
2022-01-13 20:27:15,090 iteration 2102 : loss : 0.055569, loss_ce: 0.029866
2022-01-13 20:27:16,400 iteration 2103 : loss : 0.057045, loss_ce: 0.025952
2022-01-13 20:27:17,729 iteration 2104 : loss : 0.087253, loss_ce: 0.029974
2022-01-13 20:27:19,221 iteration 2105 : loss : 0.112478, loss_ce: 0.044511
2022-01-13 20:27:20,582 iteration 2106 : loss : 0.046058, loss_ce: 0.023129
2022-01-13 20:27:22,072 iteration 2107 : loss : 0.057908, loss_ce: 0.025934
2022-01-13 20:27:23,492 iteration 2108 : loss : 0.107657, loss_ce: 0.042948
 31%|████████▉                    | 124/400 [52:55<1:53:31, 24.68s/it]2022-01-13 20:27:24,942 iteration 2109 : loss : 0.077029, loss_ce: 0.035042
2022-01-13 20:27:26,382 iteration 2110 : loss : 0.056127, loss_ce: 0.022506
2022-01-13 20:27:27,882 iteration 2111 : loss : 0.085234, loss_ce: 0.027910
2022-01-13 20:27:29,301 iteration 2112 : loss : 0.091832, loss_ce: 0.041557
2022-01-13 20:27:30,661 iteration 2113 : loss : 0.083020, loss_ce: 0.047954
2022-01-13 20:27:32,095 iteration 2114 : loss : 0.054123, loss_ce: 0.028405
2022-01-13 20:27:33,523 iteration 2115 : loss : 0.074485, loss_ce: 0.028060
2022-01-13 20:27:34,945 iteration 2116 : loss : 0.097481, loss_ce: 0.034134
2022-01-13 20:27:36,356 iteration 2117 : loss : 0.051962, loss_ce: 0.022101
2022-01-13 20:27:37,808 iteration 2118 : loss : 0.068205, loss_ce: 0.020676
2022-01-13 20:27:39,263 iteration 2119 : loss : 0.067805, loss_ce: 0.023948
2022-01-13 20:27:40,675 iteration 2120 : loss : 0.071627, loss_ce: 0.021101
2022-01-13 20:27:41,988 iteration 2121 : loss : 0.046290, loss_ce: 0.017647
2022-01-13 20:27:43,359 iteration 2122 : loss : 0.071788, loss_ce: 0.028425
2022-01-13 20:27:44,820 iteration 2123 : loss : 0.102362, loss_ce: 0.050585
2022-01-13 20:27:46,309 iteration 2124 : loss : 0.075262, loss_ce: 0.031290
2022-01-13 20:27:46,309 Training Data Eval:
2022-01-13 20:27:53,139   Average segmentation loss on training set: 0.0685
2022-01-13 20:27:53,139 Validation Data Eval:
2022-01-13 20:27:55,488   Average segmentation loss on validation set: 0.1320
2022-01-13 20:27:56,907 iteration 2125 : loss : 0.065646, loss_ce: 0.037531
 31%|█████████                    | 125/400 [53:28<2:05:08, 27.30s/it]2022-01-13 20:27:58,424 iteration 2126 : loss : 0.065040, loss_ce: 0.028095
2022-01-13 20:27:59,860 iteration 2127 : loss : 0.092311, loss_ce: 0.045265
2022-01-13 20:28:01,285 iteration 2128 : loss : 0.047683, loss_ce: 0.015694
2022-01-13 20:28:02,645 iteration 2129 : loss : 0.062879, loss_ce: 0.025514
2022-01-13 20:28:04,090 iteration 2130 : loss : 0.127152, loss_ce: 0.047774
2022-01-13 20:28:05,470 iteration 2131 : loss : 0.083456, loss_ce: 0.032306
2022-01-13 20:28:06,872 iteration 2132 : loss : 0.066124, loss_ce: 0.025173
2022-01-13 20:28:08,349 iteration 2133 : loss : 0.084613, loss_ce: 0.033978
2022-01-13 20:28:09,674 iteration 2134 : loss : 0.063021, loss_ce: 0.029948
2022-01-13 20:28:11,073 iteration 2135 : loss : 0.073178, loss_ce: 0.030108
2022-01-13 20:28:12,458 iteration 2136 : loss : 0.058792, loss_ce: 0.024843
2022-01-13 20:28:13,854 iteration 2137 : loss : 0.068673, loss_ce: 0.028230
2022-01-13 20:28:15,207 iteration 2138 : loss : 0.075928, loss_ce: 0.031448
2022-01-13 20:28:16,649 iteration 2139 : loss : 0.052539, loss_ce: 0.027251
2022-01-13 20:28:18,050 iteration 2140 : loss : 0.081089, loss_ce: 0.043236
2022-01-13 20:28:19,521 iteration 2141 : loss : 0.084616, loss_ce: 0.025994
2022-01-13 20:28:20,879 iteration 2142 : loss : 0.052422, loss_ce: 0.019128
 32%|█████████▏                   | 126/400 [53:52<2:00:06, 26.30s/it]2022-01-13 20:28:22,262 iteration 2143 : loss : 0.059628, loss_ce: 0.025795
2022-01-13 20:28:23,683 iteration 2144 : loss : 0.077264, loss_ce: 0.026314
2022-01-13 20:28:25,118 iteration 2145 : loss : 0.053620, loss_ce: 0.017792
2022-01-13 20:28:26,456 iteration 2146 : loss : 0.032177, loss_ce: 0.014764
2022-01-13 20:28:27,874 iteration 2147 : loss : 0.082592, loss_ce: 0.027805
2022-01-13 20:28:29,246 iteration 2148 : loss : 0.067847, loss_ce: 0.027477
2022-01-13 20:28:30,642 iteration 2149 : loss : 0.070901, loss_ce: 0.028202
2022-01-13 20:28:32,012 iteration 2150 : loss : 0.048730, loss_ce: 0.019974
2022-01-13 20:28:33,482 iteration 2151 : loss : 0.088944, loss_ce: 0.037949
2022-01-13 20:28:34,829 iteration 2152 : loss : 0.061564, loss_ce: 0.027731
2022-01-13 20:28:36,167 iteration 2153 : loss : 0.044519, loss_ce: 0.017386
2022-01-13 20:28:37,709 iteration 2154 : loss : 0.087649, loss_ce: 0.032380
2022-01-13 20:28:39,111 iteration 2155 : loss : 0.053637, loss_ce: 0.022850
2022-01-13 20:28:40,457 iteration 2156 : loss : 0.063217, loss_ce: 0.028230
2022-01-13 20:28:42,012 iteration 2157 : loss : 0.122548, loss_ce: 0.039592
2022-01-13 20:28:43,522 iteration 2158 : loss : 0.090491, loss_ce: 0.045534
2022-01-13 20:28:44,953 iteration 2159 : loss : 0.108580, loss_ce: 0.036282
 32%|█████████▏                   | 127/400 [54:16<1:56:37, 25.63s/it]2022-01-13 20:28:46,367 iteration 2160 : loss : 0.056384, loss_ce: 0.021151
2022-01-13 20:28:47,703 iteration 2161 : loss : 0.057399, loss_ce: 0.022551
2022-01-13 20:28:49,078 iteration 2162 : loss : 0.063600, loss_ce: 0.026666
2022-01-13 20:28:50,433 iteration 2163 : loss : 0.050711, loss_ce: 0.022223
2022-01-13 20:28:51,875 iteration 2164 : loss : 0.070888, loss_ce: 0.040908
2022-01-13 20:28:53,295 iteration 2165 : loss : 0.080268, loss_ce: 0.028849
2022-01-13 20:28:54,637 iteration 2166 : loss : 0.056422, loss_ce: 0.025621
2022-01-13 20:28:55,943 iteration 2167 : loss : 0.048587, loss_ce: 0.019443
2022-01-13 20:28:57,306 iteration 2168 : loss : 0.036867, loss_ce: 0.016401
2022-01-13 20:28:58,721 iteration 2169 : loss : 0.084684, loss_ce: 0.040400
2022-01-13 20:28:59,994 iteration 2170 : loss : 0.052084, loss_ce: 0.018980
2022-01-13 20:29:01,356 iteration 2171 : loss : 0.064103, loss_ce: 0.024765
2022-01-13 20:29:02,712 iteration 2172 : loss : 0.072265, loss_ce: 0.027558
2022-01-13 20:29:04,057 iteration 2173 : loss : 0.051756, loss_ce: 0.015472
2022-01-13 20:29:05,450 iteration 2174 : loss : 0.072274, loss_ce: 0.030555
2022-01-13 20:29:06,934 iteration 2175 : loss : 0.042364, loss_ce: 0.018508
2022-01-13 20:29:08,209 iteration 2176 : loss : 0.043153, loss_ce: 0.021349
 32%|█████████▎                   | 128/400 [54:39<1:52:58, 24.92s/it]2022-01-13 20:29:09,584 iteration 2177 : loss : 0.079635, loss_ce: 0.046188
2022-01-13 20:29:10,972 iteration 2178 : loss : 0.043398, loss_ce: 0.014778
2022-01-13 20:29:12,445 iteration 2179 : loss : 0.061663, loss_ce: 0.021745
2022-01-13 20:29:13,888 iteration 2180 : loss : 0.046079, loss_ce: 0.019616
2022-01-13 20:29:15,208 iteration 2181 : loss : 0.041729, loss_ce: 0.016245
2022-01-13 20:29:16,597 iteration 2182 : loss : 0.060440, loss_ce: 0.023903
2022-01-13 20:29:18,009 iteration 2183 : loss : 0.077304, loss_ce: 0.024408
2022-01-13 20:29:19,341 iteration 2184 : loss : 0.061680, loss_ce: 0.030084
2022-01-13 20:29:20,678 iteration 2185 : loss : 0.053899, loss_ce: 0.020015
2022-01-13 20:29:22,153 iteration 2186 : loss : 0.055272, loss_ce: 0.023263
2022-01-13 20:29:23,663 iteration 2187 : loss : 0.052592, loss_ce: 0.016339
2022-01-13 20:29:25,278 iteration 2188 : loss : 0.064422, loss_ce: 0.034566
2022-01-13 20:29:26,882 iteration 2189 : loss : 0.062071, loss_ce: 0.019946
2022-01-13 20:29:28,295 iteration 2190 : loss : 0.060987, loss_ce: 0.027446
2022-01-13 20:29:29,725 iteration 2191 : loss : 0.040571, loss_ce: 0.014724
2022-01-13 20:29:31,091 iteration 2192 : loss : 0.058394, loss_ce: 0.021067
2022-01-13 20:29:32,536 iteration 2193 : loss : 0.037659, loss_ce: 0.014281
 32%|█████████▎                   | 129/400 [55:04<1:51:45, 24.74s/it]2022-01-13 20:29:34,029 iteration 2194 : loss : 0.045556, loss_ce: 0.017826
2022-01-13 20:29:35,455 iteration 2195 : loss : 0.058309, loss_ce: 0.031488
2022-01-13 20:29:36,920 iteration 2196 : loss : 0.041848, loss_ce: 0.018412
2022-01-13 20:29:38,427 iteration 2197 : loss : 0.057767, loss_ce: 0.021756
2022-01-13 20:29:39,833 iteration 2198 : loss : 0.057962, loss_ce: 0.019230
2022-01-13 20:29:41,248 iteration 2199 : loss : 0.051084, loss_ce: 0.023976
2022-01-13 20:29:42,739 iteration 2200 : loss : 0.127817, loss_ce: 0.026953
2022-01-13 20:29:44,079 iteration 2201 : loss : 0.041227, loss_ce: 0.016786
2022-01-13 20:29:45,605 iteration 2202 : loss : 0.094077, loss_ce: 0.044090
2022-01-13 20:29:47,039 iteration 2203 : loss : 0.075386, loss_ce: 0.028739
2022-01-13 20:29:48,372 iteration 2204 : loss : 0.038524, loss_ce: 0.011904
2022-01-13 20:29:49,787 iteration 2205 : loss : 0.069454, loss_ce: 0.035652
2022-01-13 20:29:51,286 iteration 2206 : loss : 0.064499, loss_ce: 0.024632
2022-01-13 20:29:52,725 iteration 2207 : loss : 0.057195, loss_ce: 0.019829
2022-01-13 20:29:54,199 iteration 2208 : loss : 0.069832, loss_ce: 0.022760
2022-01-13 20:29:55,612 iteration 2209 : loss : 0.080858, loss_ce: 0.027952
2022-01-13 20:29:55,613 Training Data Eval:
2022-01-13 20:30:02,440   Average segmentation loss on training set: 0.0384
2022-01-13 20:30:02,440 Validation Data Eval:
2022-01-13 20:30:04,797   Average segmentation loss on validation set: 0.1254
2022-01-13 20:30:06,228 iteration 2210 : loss : 0.050880, loss_ce: 0.025076
 32%|█████████▍                   | 130/400 [55:37<2:03:25, 27.43s/it]2022-01-13 20:30:07,697 iteration 2211 : loss : 0.049053, loss_ce: 0.014807
2022-01-13 20:30:09,045 iteration 2212 : loss : 0.075035, loss_ce: 0.037789
2022-01-13 20:30:10,453 iteration 2213 : loss : 0.072579, loss_ce: 0.020062
2022-01-13 20:30:11,769 iteration 2214 : loss : 0.054969, loss_ce: 0.020383
2022-01-13 20:30:13,080 iteration 2215 : loss : 0.033594, loss_ce: 0.013805
2022-01-13 20:30:14,439 iteration 2216 : loss : 0.053443, loss_ce: 0.026486
2022-01-13 20:30:15,776 iteration 2217 : loss : 0.052246, loss_ce: 0.024389
2022-01-13 20:30:17,142 iteration 2218 : loss : 0.035965, loss_ce: 0.014581
2022-01-13 20:30:18,568 iteration 2219 : loss : 0.044739, loss_ce: 0.019995
2022-01-13 20:30:20,061 iteration 2220 : loss : 0.057379, loss_ce: 0.025641
2022-01-13 20:30:21,545 iteration 2221 : loss : 0.050953, loss_ce: 0.017103
2022-01-13 20:30:22,857 iteration 2222 : loss : 0.062797, loss_ce: 0.025351
2022-01-13 20:30:24,196 iteration 2223 : loss : 0.074983, loss_ce: 0.027279
2022-01-13 20:30:25,667 iteration 2224 : loss : 0.077057, loss_ce: 0.035459
2022-01-13 20:30:27,090 iteration 2225 : loss : 0.046190, loss_ce: 0.017403
2022-01-13 20:30:28,576 iteration 2226 : loss : 0.053430, loss_ce: 0.024592
2022-01-13 20:30:30,035 iteration 2227 : loss : 0.073123, loss_ce: 0.024157
 33%|█████████▍                   | 131/400 [56:01<1:58:05, 26.34s/it]2022-01-13 20:30:31,585 iteration 2228 : loss : 0.050460, loss_ce: 0.023031
2022-01-13 20:30:33,010 iteration 2229 : loss : 0.056287, loss_ce: 0.022056
2022-01-13 20:30:34,579 iteration 2230 : loss : 0.105286, loss_ce: 0.050275
2022-01-13 20:30:35,977 iteration 2231 : loss : 0.087715, loss_ce: 0.052592
2022-01-13 20:30:37,366 iteration 2232 : loss : 0.070752, loss_ce: 0.035929
2022-01-13 20:30:38,983 iteration 2233 : loss : 0.124818, loss_ce: 0.038037
2022-01-13 20:30:40,425 iteration 2234 : loss : 0.067851, loss_ce: 0.019101
2022-01-13 20:30:41,835 iteration 2235 : loss : 0.044489, loss_ce: 0.017680
2022-01-13 20:30:43,219 iteration 2236 : loss : 0.040292, loss_ce: 0.016743
2022-01-13 20:30:44,638 iteration 2237 : loss : 0.052135, loss_ce: 0.027137
2022-01-13 20:30:45,988 iteration 2238 : loss : 0.049082, loss_ce: 0.015596
2022-01-13 20:30:47,383 iteration 2239 : loss : 0.061197, loss_ce: 0.018362
2022-01-13 20:30:48,696 iteration 2240 : loss : 0.063362, loss_ce: 0.017648
2022-01-13 20:30:50,091 iteration 2241 : loss : 0.059586, loss_ce: 0.020728
2022-01-13 20:30:51,566 iteration 2242 : loss : 0.079330, loss_ce: 0.026648
2022-01-13 20:30:53,011 iteration 2243 : loss : 0.074525, loss_ce: 0.037659
2022-01-13 20:30:54,389 iteration 2244 : loss : 0.030016, loss_ce: 0.010970
 33%|█████████▌                   | 132/400 [56:26<1:54:59, 25.75s/it]2022-01-13 20:30:55,836 iteration 2245 : loss : 0.032265, loss_ce: 0.011557
2022-01-13 20:30:57,133 iteration 2246 : loss : 0.042737, loss_ce: 0.012791
2022-01-13 20:30:58,545 iteration 2247 : loss : 0.059005, loss_ce: 0.028702
2022-01-13 20:30:59,999 iteration 2248 : loss : 0.073273, loss_ce: 0.032211
2022-01-13 20:31:01,370 iteration 2249 : loss : 0.052767, loss_ce: 0.024130
2022-01-13 20:31:02,742 iteration 2250 : loss : 0.033565, loss_ce: 0.011738
2022-01-13 20:31:04,137 iteration 2251 : loss : 0.044823, loss_ce: 0.019891
2022-01-13 20:31:05,509 iteration 2252 : loss : 0.053792, loss_ce: 0.017825
2022-01-13 20:31:06,976 iteration 2253 : loss : 0.078028, loss_ce: 0.031384
2022-01-13 20:31:08,399 iteration 2254 : loss : 0.038702, loss_ce: 0.015971
2022-01-13 20:31:09,771 iteration 2255 : loss : 0.037257, loss_ce: 0.015829
2022-01-13 20:31:11,126 iteration 2256 : loss : 0.033325, loss_ce: 0.013759
2022-01-13 20:31:12,447 iteration 2257 : loss : 0.055997, loss_ce: 0.018886
2022-01-13 20:31:13,768 iteration 2258 : loss : 0.064830, loss_ce: 0.021985
2022-01-13 20:31:15,192 iteration 2259 : loss : 0.048941, loss_ce: 0.021305
2022-01-13 20:31:16,494 iteration 2260 : loss : 0.044500, loss_ce: 0.020605
2022-01-13 20:31:17,882 iteration 2261 : loss : 0.060392, loss_ce: 0.026885
 33%|█████████▋                   | 133/400 [56:49<1:51:33, 25.07s/it]2022-01-13 20:31:19,260 iteration 2262 : loss : 0.045341, loss_ce: 0.024450
2022-01-13 20:31:20,691 iteration 2263 : loss : 0.097097, loss_ce: 0.039984
2022-01-13 20:31:22,152 iteration 2264 : loss : 0.046402, loss_ce: 0.014262
2022-01-13 20:31:23,548 iteration 2265 : loss : 0.036787, loss_ce: 0.013603
2022-01-13 20:31:24,890 iteration 2266 : loss : 0.059454, loss_ce: 0.025943
2022-01-13 20:31:26,238 iteration 2267 : loss : 0.038921, loss_ce: 0.015787
2022-01-13 20:31:27,608 iteration 2268 : loss : 0.042107, loss_ce: 0.016726
2022-01-13 20:31:28,938 iteration 2269 : loss : 0.046119, loss_ce: 0.027025
2022-01-13 20:31:30,301 iteration 2270 : loss : 0.060899, loss_ce: 0.024471
2022-01-13 20:31:31,637 iteration 2271 : loss : 0.059321, loss_ce: 0.026465
2022-01-13 20:31:32,992 iteration 2272 : loss : 0.077452, loss_ce: 0.042819
2022-01-13 20:31:34,383 iteration 2273 : loss : 0.036820, loss_ce: 0.011912
2022-01-13 20:31:35,768 iteration 2274 : loss : 0.050999, loss_ce: 0.019543
2022-01-13 20:31:37,193 iteration 2275 : loss : 0.067077, loss_ce: 0.026538
2022-01-13 20:31:38,509 iteration 2276 : loss : 0.039609, loss_ce: 0.015961
2022-01-13 20:31:39,883 iteration 2277 : loss : 0.069794, loss_ce: 0.026542
2022-01-13 20:31:41,201 iteration 2278 : loss : 0.038836, loss_ce: 0.014517
 34%|█████████▋                   | 134/400 [57:12<1:48:48, 24.54s/it]2022-01-13 20:31:42,551 iteration 2279 : loss : 0.118833, loss_ce: 0.053124
2022-01-13 20:31:43,920 iteration 2280 : loss : 0.040270, loss_ce: 0.016719
2022-01-13 20:31:45,285 iteration 2281 : loss : 0.130175, loss_ce: 0.041439
2022-01-13 20:31:46,676 iteration 2282 : loss : 0.035570, loss_ce: 0.014617
2022-01-13 20:31:48,114 iteration 2283 : loss : 0.058480, loss_ce: 0.024603
2022-01-13 20:31:49,457 iteration 2284 : loss : 0.051939, loss_ce: 0.026749
2022-01-13 20:31:50,804 iteration 2285 : loss : 0.036145, loss_ce: 0.015052
2022-01-13 20:31:52,152 iteration 2286 : loss : 0.040744, loss_ce: 0.015980
2022-01-13 20:31:53,503 iteration 2287 : loss : 0.046071, loss_ce: 0.020413
2022-01-13 20:31:54,902 iteration 2288 : loss : 0.047757, loss_ce: 0.019181
2022-01-13 20:31:56,224 iteration 2289 : loss : 0.046413, loss_ce: 0.015716
2022-01-13 20:31:57,641 iteration 2290 : loss : 0.037290, loss_ce: 0.019421
2022-01-13 20:31:58,999 iteration 2291 : loss : 0.040916, loss_ce: 0.017565
2022-01-13 20:32:00,344 iteration 2292 : loss : 0.053007, loss_ce: 0.024262
2022-01-13 20:32:01,630 iteration 2293 : loss : 0.049141, loss_ce: 0.024383
2022-01-13 20:32:03,026 iteration 2294 : loss : 0.083595, loss_ce: 0.028666
2022-01-13 20:32:03,026 Training Data Eval:
2022-01-13 20:32:09,806   Average segmentation loss on training set: 0.0398
2022-01-13 20:32:09,806 Validation Data Eval:
2022-01-13 20:32:12,143   Average segmentation loss on validation set: 0.0776
2022-01-13 20:32:17,875 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 20:32:19,358 iteration 2295 : loss : 0.059987, loss_ce: 0.025974
 34%|█████████▊                   | 135/400 [57:51<2:06:26, 28.63s/it]2022-01-13 20:32:20,701 iteration 2296 : loss : 0.031739, loss_ce: 0.013774
2022-01-13 20:32:22,046 iteration 2297 : loss : 0.041216, loss_ce: 0.019026
2022-01-13 20:32:23,392 iteration 2298 : loss : 0.036898, loss_ce: 0.017694
2022-01-13 20:32:24,821 iteration 2299 : loss : 0.072540, loss_ce: 0.035605
2022-01-13 20:32:26,154 iteration 2300 : loss : 0.032953, loss_ce: 0.014843
2022-01-13 20:32:27,592 iteration 2301 : loss : 0.040768, loss_ce: 0.012599
2022-01-13 20:32:28,998 iteration 2302 : loss : 0.073561, loss_ce: 0.025469
2022-01-13 20:32:30,431 iteration 2303 : loss : 0.043217, loss_ce: 0.015048
2022-01-13 20:32:31,881 iteration 2304 : loss : 0.043600, loss_ce: 0.015373
2022-01-13 20:32:33,284 iteration 2305 : loss : 0.041285, loss_ce: 0.016230
2022-01-13 20:32:34,747 iteration 2306 : loss : 0.055664, loss_ce: 0.027692
2022-01-13 20:32:36,103 iteration 2307 : loss : 0.063097, loss_ce: 0.022680
2022-01-13 20:32:37,426 iteration 2308 : loss : 0.043555, loss_ce: 0.015952
2022-01-13 20:32:38,770 iteration 2309 : loss : 0.041740, loss_ce: 0.019296
2022-01-13 20:32:40,198 iteration 2310 : loss : 0.053596, loss_ce: 0.022080
2022-01-13 20:32:41,492 iteration 2311 : loss : 0.055820, loss_ce: 0.020117
2022-01-13 20:32:42,865 iteration 2312 : loss : 0.060458, loss_ce: 0.024966
 34%|█████████▊                   | 136/400 [58:14<1:59:11, 27.09s/it]2022-01-13 20:32:44,326 iteration 2313 : loss : 0.039658, loss_ce: 0.015819
2022-01-13 20:32:45,597 iteration 2314 : loss : 0.035942, loss_ce: 0.012092
2022-01-13 20:32:46,916 iteration 2315 : loss : 0.030272, loss_ce: 0.011946
2022-01-13 20:32:48,356 iteration 2316 : loss : 0.053006, loss_ce: 0.023885
2022-01-13 20:32:49,662 iteration 2317 : loss : 0.036126, loss_ce: 0.012052
2022-01-13 20:32:51,005 iteration 2318 : loss : 0.041306, loss_ce: 0.021077
2022-01-13 20:32:52,367 iteration 2319 : loss : 0.057241, loss_ce: 0.032048
2022-01-13 20:32:53,804 iteration 2320 : loss : 0.051213, loss_ce: 0.023902
2022-01-13 20:32:55,163 iteration 2321 : loss : 0.043242, loss_ce: 0.016342
2022-01-13 20:32:56,538 iteration 2322 : loss : 0.049214, loss_ce: 0.021494
2022-01-13 20:32:57,817 iteration 2323 : loss : 0.032716, loss_ce: 0.013594
2022-01-13 20:32:59,161 iteration 2324 : loss : 0.036264, loss_ce: 0.016956
2022-01-13 20:33:00,414 iteration 2325 : loss : 0.033879, loss_ce: 0.015528
2022-01-13 20:33:01,757 iteration 2326 : loss : 0.088187, loss_ce: 0.022051
2022-01-13 20:33:03,078 iteration 2327 : loss : 0.037522, loss_ce: 0.016277
2022-01-13 20:33:04,434 iteration 2328 : loss : 0.051172, loss_ce: 0.023660
2022-01-13 20:33:05,742 iteration 2329 : loss : 0.039392, loss_ce: 0.015687
 34%|█████████▉                   | 137/400 [58:37<1:53:12, 25.83s/it]2022-01-13 20:33:07,174 iteration 2330 : loss : 0.064823, loss_ce: 0.027999
2022-01-13 20:33:08,490 iteration 2331 : loss : 0.035439, loss_ce: 0.012797
2022-01-13 20:33:09,927 iteration 2332 : loss : 0.048193, loss_ce: 0.019073
2022-01-13 20:33:11,291 iteration 2333 : loss : 0.053927, loss_ce: 0.025923
2022-01-13 20:33:12,777 iteration 2334 : loss : 0.034396, loss_ce: 0.014712
2022-01-13 20:33:14,252 iteration 2335 : loss : 0.046587, loss_ce: 0.019466
2022-01-13 20:33:15,693 iteration 2336 : loss : 0.050796, loss_ce: 0.024590
2022-01-13 20:33:17,062 iteration 2337 : loss : 0.063359, loss_ce: 0.021684
2022-01-13 20:33:18,459 iteration 2338 : loss : 0.054221, loss_ce: 0.022195
2022-01-13 20:33:19,850 iteration 2339 : loss : 0.059217, loss_ce: 0.023181
2022-01-13 20:33:21,156 iteration 2340 : loss : 0.038418, loss_ce: 0.016382
2022-01-13 20:33:22,536 iteration 2341 : loss : 0.041949, loss_ce: 0.017827
2022-01-13 20:33:23,929 iteration 2342 : loss : 0.039062, loss_ce: 0.016018
2022-01-13 20:33:25,420 iteration 2343 : loss : 0.045746, loss_ce: 0.015605
2022-01-13 20:33:26,745 iteration 2344 : loss : 0.069303, loss_ce: 0.019082
2022-01-13 20:33:28,082 iteration 2345 : loss : 0.071017, loss_ce: 0.037877
2022-01-13 20:33:29,439 iteration 2346 : loss : 0.071242, loss_ce: 0.029103
 34%|██████████                   | 138/400 [59:01<1:49:59, 25.19s/it]2022-01-13 20:33:30,952 iteration 2347 : loss : 0.070177, loss_ce: 0.029490
2022-01-13 20:33:32,336 iteration 2348 : loss : 0.050271, loss_ce: 0.019338
2022-01-13 20:33:33,680 iteration 2349 : loss : 0.039150, loss_ce: 0.015073
2022-01-13 20:33:35,033 iteration 2350 : loss : 0.070986, loss_ce: 0.020774
2022-01-13 20:33:36,473 iteration 2351 : loss : 0.067552, loss_ce: 0.032800
2022-01-13 20:33:37,801 iteration 2352 : loss : 0.034339, loss_ce: 0.016720
2022-01-13 20:33:39,134 iteration 2353 : loss : 0.039307, loss_ce: 0.017695
2022-01-13 20:33:40,451 iteration 2354 : loss : 0.030321, loss_ce: 0.015065
2022-01-13 20:33:41,783 iteration 2355 : loss : 0.055086, loss_ce: 0.018771
2022-01-13 20:33:43,199 iteration 2356 : loss : 0.053565, loss_ce: 0.019610
2022-01-13 20:33:44,576 iteration 2357 : loss : 0.064819, loss_ce: 0.020403
2022-01-13 20:33:45,952 iteration 2358 : loss : 0.046624, loss_ce: 0.019567
2022-01-13 20:33:47,292 iteration 2359 : loss : 0.056017, loss_ce: 0.018953
2022-01-13 20:33:48,609 iteration 2360 : loss : 0.072789, loss_ce: 0.022030
2022-01-13 20:33:49,963 iteration 2361 : loss : 0.051971, loss_ce: 0.017908
2022-01-13 20:33:51,446 iteration 2362 : loss : 0.077275, loss_ce: 0.036134
2022-01-13 20:33:52,819 iteration 2363 : loss : 0.046948, loss_ce: 0.024587
 35%|██████████                   | 139/400 [59:24<1:47:12, 24.65s/it]2022-01-13 20:33:54,324 iteration 2364 : loss : 0.042077, loss_ce: 0.016310
2022-01-13 20:33:55,783 iteration 2365 : loss : 0.041760, loss_ce: 0.015922
2022-01-13 20:33:57,200 iteration 2366 : loss : 0.061119, loss_ce: 0.025611
2022-01-13 20:33:58,518 iteration 2367 : loss : 0.053545, loss_ce: 0.015779
2022-01-13 20:33:59,840 iteration 2368 : loss : 0.043076, loss_ce: 0.020226
2022-01-13 20:34:01,212 iteration 2369 : loss : 0.045451, loss_ce: 0.014203
2022-01-13 20:34:02,561 iteration 2370 : loss : 0.070083, loss_ce: 0.029490
2022-01-13 20:34:03,958 iteration 2371 : loss : 0.054689, loss_ce: 0.022680
2022-01-13 20:34:05,285 iteration 2372 : loss : 0.059658, loss_ce: 0.024880
2022-01-13 20:34:06,631 iteration 2373 : loss : 0.049823, loss_ce: 0.019463
2022-01-13 20:34:07,946 iteration 2374 : loss : 0.042795, loss_ce: 0.018680
2022-01-13 20:34:09,276 iteration 2375 : loss : 0.036715, loss_ce: 0.012744
2022-01-13 20:34:10,655 iteration 2376 : loss : 0.046478, loss_ce: 0.022542
2022-01-13 20:34:12,033 iteration 2377 : loss : 0.041682, loss_ce: 0.018171
2022-01-13 20:34:13,409 iteration 2378 : loss : 0.028701, loss_ce: 0.011664
2022-01-13 20:34:14,810 iteration 2379 : loss : 0.054679, loss_ce: 0.022382
2022-01-13 20:34:14,811 Training Data Eval:
2022-01-13 20:34:21,568   Average segmentation loss on training set: 0.0299
2022-01-13 20:34:21,568 Validation Data Eval:
2022-01-13 20:34:23,896   Average segmentation loss on validation set: 0.0781
2022-01-13 20:34:25,221 iteration 2380 : loss : 0.052807, loss_ce: 0.025674
 35%|██████████▏                  | 140/400 [59:56<1:56:52, 26.97s/it]2022-01-13 20:34:26,593 iteration 2381 : loss : 0.043937, loss_ce: 0.015801
2022-01-13 20:34:27,989 iteration 2382 : loss : 0.040751, loss_ce: 0.013854
2022-01-13 20:34:29,308 iteration 2383 : loss : 0.037250, loss_ce: 0.013720
2022-01-13 20:34:30,719 iteration 2384 : loss : 0.063790, loss_ce: 0.030534
2022-01-13 20:34:32,142 iteration 2385 : loss : 0.048833, loss_ce: 0.018212
2022-01-13 20:34:33,497 iteration 2386 : loss : 0.041896, loss_ce: 0.014253
2022-01-13 20:34:34,827 iteration 2387 : loss : 0.051217, loss_ce: 0.017270
2022-01-13 20:34:36,191 iteration 2388 : loss : 0.066905, loss_ce: 0.031063
2022-01-13 20:34:37,494 iteration 2389 : loss : 0.023536, loss_ce: 0.008436
2022-01-13 20:34:38,867 iteration 2390 : loss : 0.045505, loss_ce: 0.023758
2022-01-13 20:34:40,218 iteration 2391 : loss : 0.047535, loss_ce: 0.028989
2022-01-13 20:34:41,608 iteration 2392 : loss : 0.067554, loss_ce: 0.029498
2022-01-13 20:34:42,994 iteration 2393 : loss : 0.055852, loss_ce: 0.019175
2022-01-13 20:34:44,273 iteration 2394 : loss : 0.037604, loss_ce: 0.013733
2022-01-13 20:34:45,692 iteration 2395 : loss : 0.059056, loss_ce: 0.022585
2022-01-13 20:34:47,012 iteration 2396 : loss : 0.038375, loss_ce: 0.018032
2022-01-13 20:34:48,402 iteration 2397 : loss : 0.047738, loss_ce: 0.022746
 35%|█████████▌                 | 141/400 [1:00:20<1:51:31, 25.84s/it]2022-01-13 20:34:49,813 iteration 2398 : loss : 0.061061, loss_ce: 0.023818
2022-01-13 20:34:51,141 iteration 2399 : loss : 0.041238, loss_ce: 0.015720
2022-01-13 20:34:52,566 iteration 2400 : loss : 0.042738, loss_ce: 0.019046
2022-01-13 20:34:53,934 iteration 2401 : loss : 0.039830, loss_ce: 0.015910
2022-01-13 20:34:55,349 iteration 2402 : loss : 0.038594, loss_ce: 0.020574
2022-01-13 20:34:56,682 iteration 2403 : loss : 0.038313, loss_ce: 0.016533
2022-01-13 20:34:57,995 iteration 2404 : loss : 0.053002, loss_ce: 0.024402
2022-01-13 20:34:59,276 iteration 2405 : loss : 0.043161, loss_ce: 0.017927
2022-01-13 20:35:00,763 iteration 2406 : loss : 0.066873, loss_ce: 0.024274
2022-01-13 20:35:02,068 iteration 2407 : loss : 0.050948, loss_ce: 0.028784
2022-01-13 20:35:03,371 iteration 2408 : loss : 0.032071, loss_ce: 0.014332
2022-01-13 20:35:04,779 iteration 2409 : loss : 0.034502, loss_ce: 0.012238
2022-01-13 20:35:06,199 iteration 2410 : loss : 0.049833, loss_ce: 0.022907
2022-01-13 20:35:07,594 iteration 2411 : loss : 0.057840, loss_ce: 0.016841
2022-01-13 20:35:08,917 iteration 2412 : loss : 0.032563, loss_ce: 0.013576
2022-01-13 20:35:10,347 iteration 2413 : loss : 0.059076, loss_ce: 0.026157
2022-01-13 20:35:11,723 iteration 2414 : loss : 0.041843, loss_ce: 0.017274
 36%|█████████▌                 | 142/400 [1:00:43<1:47:50, 25.08s/it]2022-01-13 20:35:13,158 iteration 2415 : loss : 0.048839, loss_ce: 0.015820
2022-01-13 20:35:14,505 iteration 2416 : loss : 0.041013, loss_ce: 0.017306
2022-01-13 20:35:15,862 iteration 2417 : loss : 0.051140, loss_ce: 0.017574
2022-01-13 20:35:17,309 iteration 2418 : loss : 0.043108, loss_ce: 0.015954
2022-01-13 20:35:18,687 iteration 2419 : loss : 0.057213, loss_ce: 0.027307
2022-01-13 20:35:20,153 iteration 2420 : loss : 0.071202, loss_ce: 0.031703
2022-01-13 20:35:21,601 iteration 2421 : loss : 0.056001, loss_ce: 0.020942
2022-01-13 20:35:23,027 iteration 2422 : loss : 0.056558, loss_ce: 0.020078
2022-01-13 20:35:24,396 iteration 2423 : loss : 0.058067, loss_ce: 0.023530
2022-01-13 20:35:25,748 iteration 2424 : loss : 0.043737, loss_ce: 0.019426
2022-01-13 20:35:27,220 iteration 2425 : loss : 0.041704, loss_ce: 0.014953
2022-01-13 20:35:28,569 iteration 2426 : loss : 0.046219, loss_ce: 0.014317
2022-01-13 20:35:29,845 iteration 2427 : loss : 0.038160, loss_ce: 0.016453
2022-01-13 20:35:31,167 iteration 2428 : loss : 0.064466, loss_ce: 0.020137
2022-01-13 20:35:32,495 iteration 2429 : loss : 0.046001, loss_ce: 0.016995
2022-01-13 20:35:33,827 iteration 2430 : loss : 0.030809, loss_ce: 0.013157
2022-01-13 20:35:35,193 iteration 2431 : loss : 0.043443, loss_ce: 0.022931
 36%|█████████▋                 | 143/400 [1:01:06<1:45:21, 24.60s/it]2022-01-13 20:35:36,571 iteration 2432 : loss : 0.042675, loss_ce: 0.014250
2022-01-13 20:35:37,922 iteration 2433 : loss : 0.043655, loss_ce: 0.017546
2022-01-13 20:35:39,290 iteration 2434 : loss : 0.036737, loss_ce: 0.012479
2022-01-13 20:35:40,734 iteration 2435 : loss : 0.059703, loss_ce: 0.031886
2022-01-13 20:35:42,021 iteration 2436 : loss : 0.049958, loss_ce: 0.022682
2022-01-13 20:35:43,428 iteration 2437 : loss : 0.035609, loss_ce: 0.012190
2022-01-13 20:35:44,844 iteration 2438 : loss : 0.060311, loss_ce: 0.019829
2022-01-13 20:35:46,245 iteration 2439 : loss : 0.038004, loss_ce: 0.013738
2022-01-13 20:35:47,665 iteration 2440 : loss : 0.052787, loss_ce: 0.020522
2022-01-13 20:35:49,020 iteration 2441 : loss : 0.040151, loss_ce: 0.015371
2022-01-13 20:35:50,360 iteration 2442 : loss : 0.045127, loss_ce: 0.017835
2022-01-13 20:35:51,661 iteration 2443 : loss : 0.041634, loss_ce: 0.014897
2022-01-13 20:35:53,021 iteration 2444 : loss : 0.046090, loss_ce: 0.018848
2022-01-13 20:35:54,393 iteration 2445 : loss : 0.033971, loss_ce: 0.014050
2022-01-13 20:35:55,845 iteration 2446 : loss : 0.053829, loss_ce: 0.024748
2022-01-13 20:35:57,151 iteration 2447 : loss : 0.033374, loss_ce: 0.011740
2022-01-13 20:35:58,557 iteration 2448 : loss : 0.051969, loss_ce: 0.019880
 36%|█████████▋                 | 144/400 [1:01:30<1:43:21, 24.23s/it]2022-01-13 20:35:59,905 iteration 2449 : loss : 0.072695, loss_ce: 0.030070
2022-01-13 20:36:01,208 iteration 2450 : loss : 0.031814, loss_ce: 0.016949
2022-01-13 20:36:02,544 iteration 2451 : loss : 0.042040, loss_ce: 0.013886
2022-01-13 20:36:03,861 iteration 2452 : loss : 0.040736, loss_ce: 0.015637
2022-01-13 20:36:05,230 iteration 2453 : loss : 0.049428, loss_ce: 0.016289
2022-01-13 20:36:06,572 iteration 2454 : loss : 0.043178, loss_ce: 0.017829
2022-01-13 20:36:07,890 iteration 2455 : loss : 0.041188, loss_ce: 0.019351
2022-01-13 20:36:09,190 iteration 2456 : loss : 0.040881, loss_ce: 0.017755
2022-01-13 20:36:10,529 iteration 2457 : loss : 0.033565, loss_ce: 0.013668
2022-01-13 20:36:11,839 iteration 2458 : loss : 0.041005, loss_ce: 0.018225
2022-01-13 20:36:13,103 iteration 2459 : loss : 0.027957, loss_ce: 0.011469
2022-01-13 20:36:14,430 iteration 2460 : loss : 0.057701, loss_ce: 0.016376
2022-01-13 20:36:15,850 iteration 2461 : loss : 0.051445, loss_ce: 0.020463
2022-01-13 20:36:17,233 iteration 2462 : loss : 0.059456, loss_ce: 0.021308
2022-01-13 20:36:18,571 iteration 2463 : loss : 0.036101, loss_ce: 0.014743
2022-01-13 20:36:19,949 iteration 2464 : loss : 0.039723, loss_ce: 0.017980
2022-01-13 20:36:19,949 Training Data Eval:
2022-01-13 20:36:26,711   Average segmentation loss on training set: 0.0266
2022-01-13 20:36:26,711 Validation Data Eval:
2022-01-13 20:36:29,040   Average segmentation loss on validation set: 0.0922
2022-01-13 20:36:30,378 iteration 2465 : loss : 0.038425, loss_ce: 0.015851
 36%|█████████▊                 | 145/400 [1:02:02<1:52:38, 26.51s/it]2022-01-13 20:36:31,850 iteration 2466 : loss : 0.048469, loss_ce: 0.020410
2022-01-13 20:36:33,286 iteration 2467 : loss : 0.046356, loss_ce: 0.021139
2022-01-13 20:36:34,625 iteration 2468 : loss : 0.048263, loss_ce: 0.027814
2022-01-13 20:36:35,934 iteration 2469 : loss : 0.028736, loss_ce: 0.013770
2022-01-13 20:36:37,281 iteration 2470 : loss : 0.039495, loss_ce: 0.014214
2022-01-13 20:36:38,722 iteration 2471 : loss : 0.064553, loss_ce: 0.023175
2022-01-13 20:36:40,047 iteration 2472 : loss : 0.056127, loss_ce: 0.021937
2022-01-13 20:36:41,456 iteration 2473 : loss : 0.047047, loss_ce: 0.019779
2022-01-13 20:36:42,784 iteration 2474 : loss : 0.041884, loss_ce: 0.014319
2022-01-13 20:36:44,138 iteration 2475 : loss : 0.039400, loss_ce: 0.015036
2022-01-13 20:36:45,447 iteration 2476 : loss : 0.039155, loss_ce: 0.019774
2022-01-13 20:36:46,886 iteration 2477 : loss : 0.046978, loss_ce: 0.018354
2022-01-13 20:36:48,278 iteration 2478 : loss : 0.038851, loss_ce: 0.015403
2022-01-13 20:36:49,559 iteration 2479 : loss : 0.039666, loss_ce: 0.012706
2022-01-13 20:36:50,924 iteration 2480 : loss : 0.046579, loss_ce: 0.018165
2022-01-13 20:36:52,338 iteration 2481 : loss : 0.049174, loss_ce: 0.021233
2022-01-13 20:36:53,672 iteration 2482 : loss : 0.033057, loss_ce: 0.014069
 36%|█████████▊                 | 146/400 [1:02:25<1:48:07, 25.54s/it]2022-01-13 20:36:55,169 iteration 2483 : loss : 0.054317, loss_ce: 0.024683
2022-01-13 20:36:56,558 iteration 2484 : loss : 0.065785, loss_ce: 0.014869
2022-01-13 20:36:57,883 iteration 2485 : loss : 0.039890, loss_ce: 0.017767
2022-01-13 20:36:59,234 iteration 2486 : loss : 0.029279, loss_ce: 0.011444
2022-01-13 20:37:00,577 iteration 2487 : loss : 0.048425, loss_ce: 0.015614
2022-01-13 20:37:01,990 iteration 2488 : loss : 0.056828, loss_ce: 0.024048
2022-01-13 20:37:03,337 iteration 2489 : loss : 0.037843, loss_ce: 0.017136
2022-01-13 20:37:04,741 iteration 2490 : loss : 0.061984, loss_ce: 0.026248
2022-01-13 20:37:06,184 iteration 2491 : loss : 0.036323, loss_ce: 0.016089
2022-01-13 20:37:07,461 iteration 2492 : loss : 0.035484, loss_ce: 0.013362
2022-01-13 20:37:08,837 iteration 2493 : loss : 0.038570, loss_ce: 0.017388
2022-01-13 20:37:10,182 iteration 2494 : loss : 0.062342, loss_ce: 0.019870
2022-01-13 20:37:11,521 iteration 2495 : loss : 0.050014, loss_ce: 0.027747
2022-01-13 20:37:13,056 iteration 2496 : loss : 0.066036, loss_ce: 0.021040
2022-01-13 20:37:14,462 iteration 2497 : loss : 0.058057, loss_ce: 0.023153
2022-01-13 20:37:15,878 iteration 2498 : loss : 0.056955, loss_ce: 0.029058
2022-01-13 20:37:17,184 iteration 2499 : loss : 0.029804, loss_ce: 0.008665
 37%|█████████▉                 | 147/400 [1:02:48<1:45:08, 24.93s/it]2022-01-13 20:37:18,585 iteration 2500 : loss : 0.062129, loss_ce: 0.020455
2022-01-13 20:37:19,935 iteration 2501 : loss : 0.037730, loss_ce: 0.011021
2022-01-13 20:37:21,366 iteration 2502 : loss : 0.077900, loss_ce: 0.031540
2022-01-13 20:37:22,677 iteration 2503 : loss : 0.046204, loss_ce: 0.017503
2022-01-13 20:37:24,003 iteration 2504 : loss : 0.038017, loss_ce: 0.014044
2022-01-13 20:37:25,402 iteration 2505 : loss : 0.062130, loss_ce: 0.024729
2022-01-13 20:37:26,758 iteration 2506 : loss : 0.061985, loss_ce: 0.021601
2022-01-13 20:37:28,069 iteration 2507 : loss : 0.046859, loss_ce: 0.021703
2022-01-13 20:37:29,407 iteration 2508 : loss : 0.046483, loss_ce: 0.015896
2022-01-13 20:37:30,748 iteration 2509 : loss : 0.045915, loss_ce: 0.016150
2022-01-13 20:37:32,073 iteration 2510 : loss : 0.038694, loss_ce: 0.017996
2022-01-13 20:37:33,443 iteration 2511 : loss : 0.048624, loss_ce: 0.021547
2022-01-13 20:37:34,825 iteration 2512 : loss : 0.039889, loss_ce: 0.014763
2022-01-13 20:37:36,240 iteration 2513 : loss : 0.051216, loss_ce: 0.017885
2022-01-13 20:37:37,613 iteration 2514 : loss : 0.055094, loss_ce: 0.018940
2022-01-13 20:37:38,963 iteration 2515 : loss : 0.026289, loss_ce: 0.014432
2022-01-13 20:37:40,307 iteration 2516 : loss : 0.032157, loss_ce: 0.016712
 37%|█████████▉                 | 148/400 [1:03:12<1:42:26, 24.39s/it]2022-01-13 20:37:41,705 iteration 2517 : loss : 0.033357, loss_ce: 0.013672
2022-01-13 20:37:43,063 iteration 2518 : loss : 0.053916, loss_ce: 0.018993
2022-01-13 20:37:44,450 iteration 2519 : loss : 0.047018, loss_ce: 0.019432
2022-01-13 20:37:45,807 iteration 2520 : loss : 0.055208, loss_ce: 0.022357
2022-01-13 20:37:47,152 iteration 2521 : loss : 0.028942, loss_ce: 0.010750
2022-01-13 20:37:48,522 iteration 2522 : loss : 0.055985, loss_ce: 0.029441
2022-01-13 20:37:49,932 iteration 2523 : loss : 0.049691, loss_ce: 0.011324
2022-01-13 20:37:51,273 iteration 2524 : loss : 0.051686, loss_ce: 0.022266
2022-01-13 20:37:52,643 iteration 2525 : loss : 0.039894, loss_ce: 0.016949
2022-01-13 20:37:54,030 iteration 2526 : loss : 0.058479, loss_ce: 0.024760
2022-01-13 20:37:55,397 iteration 2527 : loss : 0.032006, loss_ce: 0.012371
2022-01-13 20:37:56,783 iteration 2528 : loss : 0.048689, loss_ce: 0.018969
2022-01-13 20:37:58,154 iteration 2529 : loss : 0.054445, loss_ce: 0.022012
2022-01-13 20:37:59,530 iteration 2530 : loss : 0.057615, loss_ce: 0.029743
2022-01-13 20:38:00,967 iteration 2531 : loss : 0.042135, loss_ce: 0.018299
2022-01-13 20:38:02,329 iteration 2532 : loss : 0.043304, loss_ce: 0.014728
2022-01-13 20:38:03,708 iteration 2533 : loss : 0.052840, loss_ce: 0.014868
 37%|██████████                 | 149/400 [1:03:35<1:40:46, 24.09s/it]2022-01-13 20:38:05,059 iteration 2534 : loss : 0.041574, loss_ce: 0.018146
2022-01-13 20:38:06,489 iteration 2535 : loss : 0.059348, loss_ce: 0.025076
2022-01-13 20:38:07,819 iteration 2536 : loss : 0.039304, loss_ce: 0.019421
2022-01-13 20:38:09,155 iteration 2537 : loss : 0.036568, loss_ce: 0.014367
2022-01-13 20:38:10,422 iteration 2538 : loss : 0.038194, loss_ce: 0.017617
2022-01-13 20:38:11,804 iteration 2539 : loss : 0.041671, loss_ce: 0.017864
2022-01-13 20:38:13,121 iteration 2540 : loss : 0.033817, loss_ce: 0.011294
2022-01-13 20:38:14,457 iteration 2541 : loss : 0.037399, loss_ce: 0.016229
2022-01-13 20:38:15,758 iteration 2542 : loss : 0.026157, loss_ce: 0.010218
2022-01-13 20:38:17,056 iteration 2543 : loss : 0.044233, loss_ce: 0.015139
2022-01-13 20:38:18,415 iteration 2544 : loss : 0.062287, loss_ce: 0.025041
2022-01-13 20:38:19,892 iteration 2545 : loss : 0.046921, loss_ce: 0.019851
2022-01-13 20:38:21,378 iteration 2546 : loss : 0.044554, loss_ce: 0.019005
2022-01-13 20:38:22,687 iteration 2547 : loss : 0.033222, loss_ce: 0.016887
2022-01-13 20:38:24,076 iteration 2548 : loss : 0.040937, loss_ce: 0.018310
2022-01-13 20:38:25,443 iteration 2549 : loss : 0.048942, loss_ce: 0.015552
2022-01-13 20:38:25,444 Training Data Eval:
2022-01-13 20:38:32,212   Average segmentation loss on training set: 0.0404
2022-01-13 20:38:32,212 Validation Data Eval:
2022-01-13 20:38:34,542   Average segmentation loss on validation set: 0.0844
2022-01-13 20:38:35,870 iteration 2550 : loss : 0.056065, loss_ce: 0.022184
 38%|██████████▏                | 150/400 [1:04:07<1:50:29, 26.52s/it]2022-01-13 20:38:37,268 iteration 2551 : loss : 0.041078, loss_ce: 0.020679
2022-01-13 20:38:38,683 iteration 2552 : loss : 0.031301, loss_ce: 0.013156
2022-01-13 20:38:39,979 iteration 2553 : loss : 0.025210, loss_ce: 0.009128
2022-01-13 20:38:41,340 iteration 2554 : loss : 0.038749, loss_ce: 0.015264
2022-01-13 20:38:42,687 iteration 2555 : loss : 0.039854, loss_ce: 0.012909
2022-01-13 20:38:44,092 iteration 2556 : loss : 0.036784, loss_ce: 0.016170
2022-01-13 20:38:45,437 iteration 2557 : loss : 0.046081, loss_ce: 0.020812
2022-01-13 20:38:46,810 iteration 2558 : loss : 0.041703, loss_ce: 0.021468
2022-01-13 20:38:48,249 iteration 2559 : loss : 0.046862, loss_ce: 0.017327
2022-01-13 20:38:49,608 iteration 2560 : loss : 0.046984, loss_ce: 0.025830
2022-01-13 20:38:51,051 iteration 2561 : loss : 0.040387, loss_ce: 0.014677
2022-01-13 20:38:52,429 iteration 2562 : loss : 0.040878, loss_ce: 0.016679
2022-01-13 20:38:53,824 iteration 2563 : loss : 0.044973, loss_ce: 0.022738
2022-01-13 20:38:55,142 iteration 2564 : loss : 0.045879, loss_ce: 0.018979
2022-01-13 20:38:56,461 iteration 2565 : loss : 0.040426, loss_ce: 0.015090
2022-01-13 20:38:57,804 iteration 2566 : loss : 0.044705, loss_ce: 0.016038
2022-01-13 20:38:59,176 iteration 2567 : loss : 0.067935, loss_ce: 0.017438
 38%|██████████▏                | 151/400 [1:04:30<1:46:02, 25.55s/it]2022-01-13 20:39:00,616 iteration 2568 : loss : 0.039391, loss_ce: 0.018571
2022-01-13 20:39:01,957 iteration 2569 : loss : 0.044367, loss_ce: 0.021524
2022-01-13 20:39:03,300 iteration 2570 : loss : 0.040666, loss_ce: 0.015536
2022-01-13 20:39:04,647 iteration 2571 : loss : 0.027446, loss_ce: 0.012134
2022-01-13 20:39:05,943 iteration 2572 : loss : 0.051065, loss_ce: 0.017417
2022-01-13 20:39:07,246 iteration 2573 : loss : 0.043742, loss_ce: 0.016979
2022-01-13 20:39:08,581 iteration 2574 : loss : 0.056239, loss_ce: 0.018664
2022-01-13 20:39:10,048 iteration 2575 : loss : 0.062059, loss_ce: 0.026089
2022-01-13 20:39:11,424 iteration 2576 : loss : 0.043083, loss_ce: 0.017295
2022-01-13 20:39:12,796 iteration 2577 : loss : 0.046720, loss_ce: 0.021226
2022-01-13 20:39:14,173 iteration 2578 : loss : 0.071781, loss_ce: 0.029414
2022-01-13 20:39:15,479 iteration 2579 : loss : 0.035534, loss_ce: 0.009094
2022-01-13 20:39:16,897 iteration 2580 : loss : 0.053171, loss_ce: 0.013351
2022-01-13 20:39:18,301 iteration 2581 : loss : 0.043515, loss_ce: 0.017596
2022-01-13 20:39:19,740 iteration 2582 : loss : 0.047506, loss_ce: 0.018345
2022-01-13 20:39:21,092 iteration 2583 : loss : 0.032222, loss_ce: 0.012462
2022-01-13 20:39:22,368 iteration 2584 : loss : 0.042619, loss_ce: 0.016247
 38%|██████████▎                | 152/400 [1:04:54<1:42:41, 24.85s/it]2022-01-13 20:39:23,784 iteration 2585 : loss : 0.029588, loss_ce: 0.009676
2022-01-13 20:39:25,153 iteration 2586 : loss : 0.048610, loss_ce: 0.022529
2022-01-13 20:39:26,450 iteration 2587 : loss : 0.043966, loss_ce: 0.015717
2022-01-13 20:39:27,785 iteration 2588 : loss : 0.039335, loss_ce: 0.020825
2022-01-13 20:39:29,181 iteration 2589 : loss : 0.038314, loss_ce: 0.013106
2022-01-13 20:39:30,593 iteration 2590 : loss : 0.040311, loss_ce: 0.020128
2022-01-13 20:39:31,916 iteration 2591 : loss : 0.031537, loss_ce: 0.010355
2022-01-13 20:39:33,242 iteration 2592 : loss : 0.037143, loss_ce: 0.013167
2022-01-13 20:39:34,574 iteration 2593 : loss : 0.044152, loss_ce: 0.021863
2022-01-13 20:39:36,055 iteration 2594 : loss : 0.045939, loss_ce: 0.020678
2022-01-13 20:39:37,459 iteration 2595 : loss : 0.047166, loss_ce: 0.016070
2022-01-13 20:39:38,786 iteration 2596 : loss : 0.032991, loss_ce: 0.015495
2022-01-13 20:39:40,096 iteration 2597 : loss : 0.051813, loss_ce: 0.019770
2022-01-13 20:39:41,433 iteration 2598 : loss : 0.035931, loss_ce: 0.015812
2022-01-13 20:39:42,779 iteration 2599 : loss : 0.044697, loss_ce: 0.012413
2022-01-13 20:39:44,125 iteration 2600 : loss : 0.045856, loss_ce: 0.016578
2022-01-13 20:39:45,429 iteration 2601 : loss : 0.032280, loss_ce: 0.012689
 38%|██████████▎                | 153/400 [1:05:17<1:40:04, 24.31s/it]2022-01-13 20:39:46,868 iteration 2602 : loss : 0.040019, loss_ce: 0.016763
2022-01-13 20:39:48,156 iteration 2603 : loss : 0.028123, loss_ce: 0.011857
2022-01-13 20:39:49,494 iteration 2604 : loss : 0.029734, loss_ce: 0.010957
2022-01-13 20:39:50,971 iteration 2605 : loss : 0.036958, loss_ce: 0.012171
2022-01-13 20:39:52,327 iteration 2606 : loss : 0.045285, loss_ce: 0.018701
2022-01-13 20:39:53,691 iteration 2607 : loss : 0.046210, loss_ce: 0.019120
2022-01-13 20:39:54,999 iteration 2608 : loss : 0.033486, loss_ce: 0.015881
2022-01-13 20:39:56,318 iteration 2609 : loss : 0.039657, loss_ce: 0.012349
2022-01-13 20:39:57,788 iteration 2610 : loss : 0.053695, loss_ce: 0.021155
2022-01-13 20:39:59,119 iteration 2611 : loss : 0.051478, loss_ce: 0.017845
2022-01-13 20:40:00,384 iteration 2612 : loss : 0.030921, loss_ce: 0.014439
2022-01-13 20:40:01,711 iteration 2613 : loss : 0.038211, loss_ce: 0.012547
2022-01-13 20:40:03,132 iteration 2614 : loss : 0.083250, loss_ce: 0.027274
2022-01-13 20:40:04,455 iteration 2615 : loss : 0.046190, loss_ce: 0.017148
2022-01-13 20:40:05,790 iteration 2616 : loss : 0.038505, loss_ce: 0.014384
2022-01-13 20:40:07,220 iteration 2617 : loss : 0.042505, loss_ce: 0.011873
2022-01-13 20:40:08,595 iteration 2618 : loss : 0.054761, loss_ce: 0.025011
 38%|██████████▍                | 154/400 [1:05:40<1:38:15, 23.97s/it]2022-01-13 20:40:10,065 iteration 2619 : loss : 0.047029, loss_ce: 0.015624
2022-01-13 20:40:11,399 iteration 2620 : loss : 0.036528, loss_ce: 0.015538
2022-01-13 20:40:12,782 iteration 2621 : loss : 0.048815, loss_ce: 0.019722
2022-01-13 20:40:14,172 iteration 2622 : loss : 0.036480, loss_ce: 0.017397
2022-01-13 20:40:15,563 iteration 2623 : loss : 0.072013, loss_ce: 0.037432
2022-01-13 20:40:16,881 iteration 2624 : loss : 0.038956, loss_ce: 0.012706
2022-01-13 20:40:18,219 iteration 2625 : loss : 0.030060, loss_ce: 0.012850
2022-01-13 20:40:19,635 iteration 2626 : loss : 0.049272, loss_ce: 0.019134
2022-01-13 20:40:21,023 iteration 2627 : loss : 0.041987, loss_ce: 0.013786
2022-01-13 20:40:22,341 iteration 2628 : loss : 0.033745, loss_ce: 0.012444
2022-01-13 20:40:23,757 iteration 2629 : loss : 0.052188, loss_ce: 0.018129
2022-01-13 20:40:25,059 iteration 2630 : loss : 0.038921, loss_ce: 0.014339
2022-01-13 20:40:26,430 iteration 2631 : loss : 0.047006, loss_ce: 0.021028
2022-01-13 20:40:27,816 iteration 2632 : loss : 0.051433, loss_ce: 0.021859
2022-01-13 20:40:29,159 iteration 2633 : loss : 0.033481, loss_ce: 0.014868
2022-01-13 20:40:30,534 iteration 2634 : loss : 0.029918, loss_ce: 0.010561
2022-01-13 20:40:30,534 Training Data Eval:
2022-01-13 20:40:37,277   Average segmentation loss on training set: 0.0280
2022-01-13 20:40:37,277 Validation Data Eval:
2022-01-13 20:40:39,604   Average segmentation loss on validation set: 0.1088
2022-01-13 20:40:41,026 iteration 2635 : loss : 0.068098, loss_ce: 0.029132
 39%|██████████▍                | 155/400 [1:06:12<1:48:13, 26.50s/it]2022-01-13 20:40:42,400 iteration 2636 : loss : 0.026783, loss_ce: 0.008645
2022-01-13 20:40:43,882 iteration 2637 : loss : 0.059626, loss_ce: 0.018819
2022-01-13 20:40:45,250 iteration 2638 : loss : 0.033457, loss_ce: 0.012693
2022-01-13 20:40:46,506 iteration 2639 : loss : 0.026706, loss_ce: 0.009926
2022-01-13 20:40:47,817 iteration 2640 : loss : 0.034876, loss_ce: 0.013826
2022-01-13 20:40:49,258 iteration 2641 : loss : 0.037995, loss_ce: 0.015590
2022-01-13 20:40:50,662 iteration 2642 : loss : 0.042978, loss_ce: 0.013708
2022-01-13 20:40:52,061 iteration 2643 : loss : 0.043785, loss_ce: 0.012972
2022-01-13 20:40:53,386 iteration 2644 : loss : 0.041215, loss_ce: 0.012087
2022-01-13 20:40:54,711 iteration 2645 : loss : 0.039375, loss_ce: 0.019500
2022-01-13 20:40:56,043 iteration 2646 : loss : 0.041753, loss_ce: 0.014243
2022-01-13 20:40:57,454 iteration 2647 : loss : 0.047355, loss_ce: 0.025411
2022-01-13 20:40:58,737 iteration 2648 : loss : 0.021167, loss_ce: 0.009710
2022-01-13 20:41:00,126 iteration 2649 : loss : 0.038190, loss_ce: 0.015968
2022-01-13 20:41:01,514 iteration 2650 : loss : 0.044448, loss_ce: 0.019966
2022-01-13 20:41:02,847 iteration 2651 : loss : 0.054014, loss_ce: 0.022488
2022-01-13 20:41:04,207 iteration 2652 : loss : 0.031885, loss_ce: 0.014709
 39%|██████████▌                | 156/400 [1:06:35<1:43:44, 25.51s/it]2022-01-13 20:41:05,718 iteration 2653 : loss : 0.050986, loss_ce: 0.019030
2022-01-13 20:41:07,074 iteration 2654 : loss : 0.034617, loss_ce: 0.015319
2022-01-13 20:41:08,376 iteration 2655 : loss : 0.025890, loss_ce: 0.010671
2022-01-13 20:41:09,663 iteration 2656 : loss : 0.030346, loss_ce: 0.014363
2022-01-13 20:41:10,967 iteration 2657 : loss : 0.031416, loss_ce: 0.012058
2022-01-13 20:41:12,289 iteration 2658 : loss : 0.029589, loss_ce: 0.011844
2022-01-13 20:41:13,752 iteration 2659 : loss : 0.047278, loss_ce: 0.021949
2022-01-13 20:41:15,105 iteration 2660 : loss : 0.035502, loss_ce: 0.012909
2022-01-13 20:41:16,376 iteration 2661 : loss : 0.031430, loss_ce: 0.012224
2022-01-13 20:41:17,777 iteration 2662 : loss : 0.040979, loss_ce: 0.017375
2022-01-13 20:41:19,086 iteration 2663 : loss : 0.048114, loss_ce: 0.019581
2022-01-13 20:41:20,497 iteration 2664 : loss : 0.043354, loss_ce: 0.016957
2022-01-13 20:41:21,837 iteration 2665 : loss : 0.040001, loss_ce: 0.016505
2022-01-13 20:41:23,202 iteration 2666 : loss : 0.037226, loss_ce: 0.011745
2022-01-13 20:41:24,594 iteration 2667 : loss : 0.024830, loss_ce: 0.009430
2022-01-13 20:41:25,977 iteration 2668 : loss : 0.047558, loss_ce: 0.018560
2022-01-13 20:41:27,377 iteration 2669 : loss : 0.038823, loss_ce: 0.017543
 39%|██████████▌                | 157/400 [1:06:59<1:40:28, 24.81s/it]2022-01-13 20:41:28,819 iteration 2670 : loss : 0.058824, loss_ce: 0.017991
2022-01-13 20:41:30,191 iteration 2671 : loss : 0.046969, loss_ce: 0.014712
2022-01-13 20:41:31,574 iteration 2672 : loss : 0.027194, loss_ce: 0.010612
2022-01-13 20:41:32,991 iteration 2673 : loss : 0.065890, loss_ce: 0.028444
2022-01-13 20:41:34,313 iteration 2674 : loss : 0.038941, loss_ce: 0.019290
2022-01-13 20:41:35,722 iteration 2675 : loss : 0.046494, loss_ce: 0.019318
2022-01-13 20:41:37,096 iteration 2676 : loss : 0.045025, loss_ce: 0.013755
2022-01-13 20:41:38,404 iteration 2677 : loss : 0.034396, loss_ce: 0.017156
2022-01-13 20:41:39,695 iteration 2678 : loss : 0.032582, loss_ce: 0.011040
2022-01-13 20:41:41,071 iteration 2679 : loss : 0.060386, loss_ce: 0.029356
2022-01-13 20:41:42,484 iteration 2680 : loss : 0.050542, loss_ce: 0.024757
2022-01-13 20:41:43,834 iteration 2681 : loss : 0.048679, loss_ce: 0.021894
2022-01-13 20:41:45,138 iteration 2682 : loss : 0.030388, loss_ce: 0.012672
2022-01-13 20:41:46,504 iteration 2683 : loss : 0.036546, loss_ce: 0.018709
2022-01-13 20:41:47,860 iteration 2684 : loss : 0.057993, loss_ce: 0.019337
2022-01-13 20:41:49,221 iteration 2685 : loss : 0.034772, loss_ce: 0.016409
2022-01-13 20:41:50,565 iteration 2686 : loss : 0.039551, loss_ce: 0.015659
 40%|██████████▋                | 158/400 [1:07:22<1:38:05, 24.32s/it]2022-01-13 20:41:51,956 iteration 2687 : loss : 0.024295, loss_ce: 0.011511
2022-01-13 20:41:53,290 iteration 2688 : loss : 0.047169, loss_ce: 0.020202
2022-01-13 20:41:54,543 iteration 2689 : loss : 0.034197, loss_ce: 0.013902
2022-01-13 20:41:55,882 iteration 2690 : loss : 0.029331, loss_ce: 0.012538
2022-01-13 20:41:57,247 iteration 2691 : loss : 0.032485, loss_ce: 0.010733
2022-01-13 20:41:58,593 iteration 2692 : loss : 0.038247, loss_ce: 0.014417
2022-01-13 20:41:59,912 iteration 2693 : loss : 0.036808, loss_ce: 0.014625
2022-01-13 20:42:01,181 iteration 2694 : loss : 0.038625, loss_ce: 0.015334
2022-01-13 20:42:02,574 iteration 2695 : loss : 0.056370, loss_ce: 0.019494
2022-01-13 20:42:04,027 iteration 2696 : loss : 0.053691, loss_ce: 0.021188
2022-01-13 20:42:05,438 iteration 2697 : loss : 0.041021, loss_ce: 0.024698
2022-01-13 20:42:06,740 iteration 2698 : loss : 0.030955, loss_ce: 0.012829
2022-01-13 20:42:08,055 iteration 2699 : loss : 0.031509, loss_ce: 0.010958
2022-01-13 20:42:09,370 iteration 2700 : loss : 0.043136, loss_ce: 0.011845
2022-01-13 20:42:10,728 iteration 2701 : loss : 0.054157, loss_ce: 0.023595
2022-01-13 20:42:12,113 iteration 2702 : loss : 0.050248, loss_ce: 0.010959
2022-01-13 20:42:13,509 iteration 2703 : loss : 0.051790, loss_ce: 0.020491
 40%|██████████▋                | 159/400 [1:07:45<1:36:01, 23.91s/it]2022-01-13 20:42:14,873 iteration 2704 : loss : 0.032871, loss_ce: 0.012452
2022-01-13 20:42:16,176 iteration 2705 : loss : 0.034061, loss_ce: 0.009553
2022-01-13 20:42:17,560 iteration 2706 : loss : 0.042549, loss_ce: 0.020366
2022-01-13 20:42:18,908 iteration 2707 : loss : 0.028097, loss_ce: 0.010850
2022-01-13 20:42:20,242 iteration 2708 : loss : 0.059570, loss_ce: 0.020494
2022-01-13 20:42:21,660 iteration 2709 : loss : 0.047565, loss_ce: 0.015421
2022-01-13 20:42:23,063 iteration 2710 : loss : 0.038744, loss_ce: 0.016099
2022-01-13 20:42:24,395 iteration 2711 : loss : 0.030974, loss_ce: 0.011003
2022-01-13 20:42:25,735 iteration 2712 : loss : 0.050135, loss_ce: 0.016010
2022-01-13 20:42:27,098 iteration 2713 : loss : 0.032420, loss_ce: 0.011796
2022-01-13 20:42:28,455 iteration 2714 : loss : 0.037060, loss_ce: 0.014114
2022-01-13 20:42:29,802 iteration 2715 : loss : 0.035437, loss_ce: 0.019594
2022-01-13 20:42:31,145 iteration 2716 : loss : 0.043491, loss_ce: 0.012859
2022-01-13 20:42:32,439 iteration 2717 : loss : 0.040982, loss_ce: 0.014303
2022-01-13 20:42:33,819 iteration 2718 : loss : 0.040161, loss_ce: 0.016613
2022-01-13 20:42:35,141 iteration 2719 : loss : 0.036628, loss_ce: 0.018404
2022-01-13 20:42:35,141 Training Data Eval:
2022-01-13 20:42:41,906   Average segmentation loss on training set: 0.0294
2022-01-13 20:42:41,907 Validation Data Eval:
2022-01-13 20:42:44,233   Average segmentation loss on validation set: 0.0818
2022-01-13 20:42:45,573 iteration 2720 : loss : 0.028487, loss_ce: 0.011814
 40%|██████████▊                | 160/400 [1:08:17<1:45:24, 26.35s/it]2022-01-13 20:42:46,994 iteration 2721 : loss : 0.032145, loss_ce: 0.011604
2022-01-13 20:42:48,371 iteration 2722 : loss : 0.030810, loss_ce: 0.014701
2022-01-13 20:42:49,803 iteration 2723 : loss : 0.054067, loss_ce: 0.025565
2022-01-13 20:42:51,108 iteration 2724 : loss : 0.044039, loss_ce: 0.016929
2022-01-13 20:42:52,442 iteration 2725 : loss : 0.047861, loss_ce: 0.014250
2022-01-13 20:42:53,867 iteration 2726 : loss : 0.027311, loss_ce: 0.009932
2022-01-13 20:42:55,218 iteration 2727 : loss : 0.038451, loss_ce: 0.014495
2022-01-13 20:42:56,616 iteration 2728 : loss : 0.038936, loss_ce: 0.015467
2022-01-13 20:42:58,011 iteration 2729 : loss : 0.055610, loss_ce: 0.025461
2022-01-13 20:42:59,434 iteration 2730 : loss : 0.074641, loss_ce: 0.035019
2022-01-13 20:43:00,783 iteration 2731 : loss : 0.039958, loss_ce: 0.015945
2022-01-13 20:43:02,055 iteration 2732 : loss : 0.030863, loss_ce: 0.013187
2022-01-13 20:43:03,402 iteration 2733 : loss : 0.033062, loss_ce: 0.017323
2022-01-13 20:43:04,775 iteration 2734 : loss : 0.054670, loss_ce: 0.015263
2022-01-13 20:43:06,143 iteration 2735 : loss : 0.038807, loss_ce: 0.020285
2022-01-13 20:43:07,479 iteration 2736 : loss : 0.042377, loss_ce: 0.014363
2022-01-13 20:43:08,817 iteration 2737 : loss : 0.047246, loss_ce: 0.013918
 40%|██████████▊                | 161/400 [1:08:40<1:41:15, 25.42s/it]2022-01-13 20:43:10,271 iteration 2738 : loss : 0.047181, loss_ce: 0.021787
2022-01-13 20:43:11,578 iteration 2739 : loss : 0.046223, loss_ce: 0.011164
2022-01-13 20:43:13,012 iteration 2740 : loss : 0.057073, loss_ce: 0.021967
2022-01-13 20:43:14,370 iteration 2741 : loss : 0.035783, loss_ce: 0.016057
2022-01-13 20:43:15,736 iteration 2742 : loss : 0.057855, loss_ce: 0.026786
2022-01-13 20:43:17,038 iteration 2743 : loss : 0.048289, loss_ce: 0.020627
2022-01-13 20:43:18,386 iteration 2744 : loss : 0.034249, loss_ce: 0.011411
2022-01-13 20:43:19,702 iteration 2745 : loss : 0.039991, loss_ce: 0.016377
2022-01-13 20:43:21,148 iteration 2746 : loss : 0.126618, loss_ce: 0.030919
2022-01-13 20:43:22,479 iteration 2747 : loss : 0.036834, loss_ce: 0.016682
2022-01-13 20:43:23,879 iteration 2748 : loss : 0.035184, loss_ce: 0.009879
2022-01-13 20:43:25,308 iteration 2749 : loss : 0.041819, loss_ce: 0.016198
2022-01-13 20:43:26,652 iteration 2750 : loss : 0.043509, loss_ce: 0.017758
2022-01-13 20:43:28,009 iteration 2751 : loss : 0.063422, loss_ce: 0.018828
2022-01-13 20:43:29,461 iteration 2752 : loss : 0.049667, loss_ce: 0.019545
2022-01-13 20:43:30,927 iteration 2753 : loss : 0.060780, loss_ce: 0.025465
2022-01-13 20:43:32,299 iteration 2754 : loss : 0.035826, loss_ce: 0.019761
 40%|██████████▉                | 162/400 [1:09:04<1:38:31, 24.84s/it]2022-01-13 20:43:33,590 iteration 2755 : loss : 0.026646, loss_ce: 0.009042
2022-01-13 20:43:34,956 iteration 2756 : loss : 0.042039, loss_ce: 0.017332
2022-01-13 20:43:36,316 iteration 2757 : loss : 0.040980, loss_ce: 0.019770
2022-01-13 20:43:37,668 iteration 2758 : loss : 0.037050, loss_ce: 0.014749
2022-01-13 20:43:39,022 iteration 2759 : loss : 0.043970, loss_ce: 0.017868
2022-01-13 20:43:40,378 iteration 2760 : loss : 0.052061, loss_ce: 0.021751
2022-01-13 20:43:41,765 iteration 2761 : loss : 0.056586, loss_ce: 0.019518
2022-01-13 20:43:43,116 iteration 2762 : loss : 0.031604, loss_ce: 0.012594
2022-01-13 20:43:44,501 iteration 2763 : loss : 0.063896, loss_ce: 0.021309
2022-01-13 20:43:45,822 iteration 2764 : loss : 0.025513, loss_ce: 0.009973
2022-01-13 20:43:47,320 iteration 2765 : loss : 0.028579, loss_ce: 0.009422
2022-01-13 20:43:48,629 iteration 2766 : loss : 0.031686, loss_ce: 0.011975
2022-01-13 20:43:50,031 iteration 2767 : loss : 0.059473, loss_ce: 0.026698
2022-01-13 20:43:51,390 iteration 2768 : loss : 0.035950, loss_ce: 0.012125
2022-01-13 20:43:52,700 iteration 2769 : loss : 0.031938, loss_ce: 0.013046
2022-01-13 20:43:54,045 iteration 2770 : loss : 0.037997, loss_ce: 0.017049
2022-01-13 20:43:55,412 iteration 2771 : loss : 0.033672, loss_ce: 0.014419
 41%|███████████                | 163/400 [1:09:27<1:36:04, 24.32s/it]2022-01-13 20:43:56,779 iteration 2772 : loss : 0.048852, loss_ce: 0.016277
2022-01-13 20:43:58,169 iteration 2773 : loss : 0.031362, loss_ce: 0.011846
2022-01-13 20:43:59,559 iteration 2774 : loss : 0.060778, loss_ce: 0.014345
2022-01-13 20:44:00,958 iteration 2775 : loss : 0.061813, loss_ce: 0.023154
2022-01-13 20:44:02,320 iteration 2776 : loss : 0.051947, loss_ce: 0.024041
2022-01-13 20:44:03,760 iteration 2777 : loss : 0.025760, loss_ce: 0.009719
2022-01-13 20:44:05,097 iteration 2778 : loss : 0.040860, loss_ce: 0.014084
2022-01-13 20:44:06,439 iteration 2779 : loss : 0.030818, loss_ce: 0.012650
2022-01-13 20:44:07,801 iteration 2780 : loss : 0.028611, loss_ce: 0.014789
2022-01-13 20:44:09,280 iteration 2781 : loss : 0.036449, loss_ce: 0.014696
2022-01-13 20:44:10,741 iteration 2782 : loss : 0.038919, loss_ce: 0.017158
2022-01-13 20:44:12,115 iteration 2783 : loss : 0.039028, loss_ce: 0.012097
2022-01-13 20:44:13,381 iteration 2784 : loss : 0.037159, loss_ce: 0.011107
2022-01-13 20:44:14,694 iteration 2785 : loss : 0.032300, loss_ce: 0.014855
2022-01-13 20:44:16,000 iteration 2786 : loss : 0.028750, loss_ce: 0.011919
2022-01-13 20:44:17,336 iteration 2787 : loss : 0.032235, loss_ce: 0.013809
2022-01-13 20:44:18,860 iteration 2788 : loss : 0.046212, loss_ce: 0.018432
 41%|███████████                | 164/400 [1:09:50<1:34:38, 24.06s/it]2022-01-13 20:44:20,330 iteration 2789 : loss : 0.030443, loss_ce: 0.010038
2022-01-13 20:44:21,815 iteration 2790 : loss : 0.070095, loss_ce: 0.025638
2022-01-13 20:44:23,130 iteration 2791 : loss : 0.032703, loss_ce: 0.012200
2022-01-13 20:44:24,495 iteration 2792 : loss : 0.034172, loss_ce: 0.015895
2022-01-13 20:44:25,869 iteration 2793 : loss : 0.031189, loss_ce: 0.011090
2022-01-13 20:44:27,315 iteration 2794 : loss : 0.038169, loss_ce: 0.018243
2022-01-13 20:44:28,685 iteration 2795 : loss : 0.048575, loss_ce: 0.018108
2022-01-13 20:44:30,036 iteration 2796 : loss : 0.046518, loss_ce: 0.015686
2022-01-13 20:44:31,442 iteration 2797 : loss : 0.041695, loss_ce: 0.020634
2022-01-13 20:44:32,855 iteration 2798 : loss : 0.043544, loss_ce: 0.015216
2022-01-13 20:44:34,339 iteration 2799 : loss : 0.062479, loss_ce: 0.028444
2022-01-13 20:44:35,742 iteration 2800 : loss : 0.037276, loss_ce: 0.017123
2022-01-13 20:44:37,031 iteration 2801 : loss : 0.068890, loss_ce: 0.017141
2022-01-13 20:44:38,364 iteration 2802 : loss : 0.025866, loss_ce: 0.010130
2022-01-13 20:44:39,750 iteration 2803 : loss : 0.058136, loss_ce: 0.029115
2022-01-13 20:44:41,025 iteration 2804 : loss : 0.049498, loss_ce: 0.024363
2022-01-13 20:44:41,025 Training Data Eval:
2022-01-13 20:44:47,784   Average segmentation loss on training set: 0.0247
2022-01-13 20:44:47,784 Validation Data Eval:
2022-01-13 20:44:50,113   Average segmentation loss on validation set: 0.0818
2022-01-13 20:44:51,566 iteration 2805 : loss : 0.069814, loss_ce: 0.025116
 41%|███████████▏               | 165/400 [1:10:23<1:44:23, 26.65s/it]2022-01-13 20:44:53,053 iteration 2806 : loss : 0.052819, loss_ce: 0.026205
2022-01-13 20:44:54,492 iteration 2807 : loss : 0.061567, loss_ce: 0.017758
2022-01-13 20:44:55,909 iteration 2808 : loss : 0.037272, loss_ce: 0.012443
2022-01-13 20:44:57,292 iteration 2809 : loss : 0.044118, loss_ce: 0.018510
2022-01-13 20:44:58,589 iteration 2810 : loss : 0.044307, loss_ce: 0.015066
2022-01-13 20:44:59,997 iteration 2811 : loss : 0.036629, loss_ce: 0.016528
2022-01-13 20:45:01,295 iteration 2812 : loss : 0.023233, loss_ce: 0.010347
2022-01-13 20:45:02,719 iteration 2813 : loss : 0.056421, loss_ce: 0.029128
2022-01-13 20:45:04,099 iteration 2814 : loss : 0.035491, loss_ce: 0.013161
2022-01-13 20:45:05,465 iteration 2815 : loss : 0.039915, loss_ce: 0.018305
2022-01-13 20:45:06,821 iteration 2816 : loss : 0.048898, loss_ce: 0.018697
2022-01-13 20:45:08,260 iteration 2817 : loss : 0.052375, loss_ce: 0.013157
2022-01-13 20:45:09,671 iteration 2818 : loss : 0.045814, loss_ce: 0.018069
2022-01-13 20:45:11,013 iteration 2819 : loss : 0.031030, loss_ce: 0.012927
2022-01-13 20:45:12,473 iteration 2820 : loss : 0.054840, loss_ce: 0.018573
2022-01-13 20:45:13,907 iteration 2821 : loss : 0.064385, loss_ce: 0.024960
2022-01-13 20:45:15,302 iteration 2822 : loss : 0.036996, loss_ce: 0.014751
 42%|███████████▏               | 166/400 [1:10:47<1:40:31, 25.78s/it]2022-01-13 20:45:16,824 iteration 2823 : loss : 0.050582, loss_ce: 0.021673
2022-01-13 20:45:18,154 iteration 2824 : loss : 0.033696, loss_ce: 0.016670
2022-01-13 20:45:19,529 iteration 2825 : loss : 0.040644, loss_ce: 0.017422
2022-01-13 20:45:20,993 iteration 2826 : loss : 0.048971, loss_ce: 0.019715
2022-01-13 20:45:22,478 iteration 2827 : loss : 0.083031, loss_ce: 0.032159
2022-01-13 20:45:23,866 iteration 2828 : loss : 0.035325, loss_ce: 0.012251
2022-01-13 20:45:25,225 iteration 2829 : loss : 0.044477, loss_ce: 0.022166
2022-01-13 20:45:26,574 iteration 2830 : loss : 0.041317, loss_ce: 0.015046
2022-01-13 20:45:27,846 iteration 2831 : loss : 0.028426, loss_ce: 0.013295
2022-01-13 20:45:29,333 iteration 2832 : loss : 0.043679, loss_ce: 0.018733
2022-01-13 20:45:30,677 iteration 2833 : loss : 0.031383, loss_ce: 0.011350
2022-01-13 20:45:32,100 iteration 2834 : loss : 0.050769, loss_ce: 0.017865
2022-01-13 20:45:33,494 iteration 2835 : loss : 0.055108, loss_ce: 0.021143
2022-01-13 20:45:34,855 iteration 2836 : loss : 0.041521, loss_ce: 0.015604
2022-01-13 20:45:36,274 iteration 2837 : loss : 0.036910, loss_ce: 0.014075
2022-01-13 20:45:37,577 iteration 2838 : loss : 0.030665, loss_ce: 0.014223
2022-01-13 20:45:38,970 iteration 2839 : loss : 0.036339, loss_ce: 0.015987
 42%|███████████▎               | 167/400 [1:11:10<1:37:38, 25.14s/it]2022-01-13 20:45:40,445 iteration 2840 : loss : 0.045784, loss_ce: 0.017274
2022-01-13 20:45:41,796 iteration 2841 : loss : 0.037837, loss_ce: 0.012024
2022-01-13 20:45:43,145 iteration 2842 : loss : 0.031772, loss_ce: 0.011466
2022-01-13 20:45:44,552 iteration 2843 : loss : 0.061262, loss_ce: 0.021375
2022-01-13 20:45:45,935 iteration 2844 : loss : 0.042489, loss_ce: 0.017143
2022-01-13 20:45:47,295 iteration 2845 : loss : 0.061867, loss_ce: 0.033249
2022-01-13 20:45:48,666 iteration 2846 : loss : 0.025562, loss_ce: 0.009216
2022-01-13 20:45:49,916 iteration 2847 : loss : 0.021460, loss_ce: 0.011229
2022-01-13 20:45:51,284 iteration 2848 : loss : 0.049768, loss_ce: 0.018245
2022-01-13 20:45:52,700 iteration 2849 : loss : 0.048334, loss_ce: 0.019384
2022-01-13 20:45:54,102 iteration 2850 : loss : 0.063250, loss_ce: 0.021144
2022-01-13 20:45:55,515 iteration 2851 : loss : 0.035833, loss_ce: 0.014120
2022-01-13 20:45:56,897 iteration 2852 : loss : 0.049473, loss_ce: 0.013924
2022-01-13 20:45:58,326 iteration 2853 : loss : 0.032490, loss_ce: 0.011747
2022-01-13 20:45:59,718 iteration 2854 : loss : 0.036912, loss_ce: 0.016853
2022-01-13 20:46:01,046 iteration 2855 : loss : 0.033951, loss_ce: 0.016566
2022-01-13 20:46:02,446 iteration 2856 : loss : 0.059683, loss_ce: 0.030019
 42%|███████████▎               | 168/400 [1:11:34<1:35:17, 24.64s/it]2022-01-13 20:46:03,782 iteration 2857 : loss : 0.029589, loss_ce: 0.009934
2022-01-13 20:46:05,162 iteration 2858 : loss : 0.042900, loss_ce: 0.018161
2022-01-13 20:46:06,494 iteration 2859 : loss : 0.026139, loss_ce: 0.011435
2022-01-13 20:46:07,894 iteration 2860 : loss : 0.045065, loss_ce: 0.014004
2022-01-13 20:46:09,173 iteration 2861 : loss : 0.030475, loss_ce: 0.014435
2022-01-13 20:46:10,621 iteration 2862 : loss : 0.079976, loss_ce: 0.028486
2022-01-13 20:46:11,943 iteration 2863 : loss : 0.035649, loss_ce: 0.010427
2022-01-13 20:46:13,332 iteration 2864 : loss : 0.033022, loss_ce: 0.013896
2022-01-13 20:46:14,736 iteration 2865 : loss : 0.037523, loss_ce: 0.015574
2022-01-13 20:46:16,077 iteration 2866 : loss : 0.034929, loss_ce: 0.013996
2022-01-13 20:46:17,544 iteration 2867 : loss : 0.060107, loss_ce: 0.023926
2022-01-13 20:46:18,869 iteration 2868 : loss : 0.031954, loss_ce: 0.012531
2022-01-13 20:46:20,308 iteration 2869 : loss : 0.033784, loss_ce: 0.013950
2022-01-13 20:46:21,700 iteration 2870 : loss : 0.034528, loss_ce: 0.013751
2022-01-13 20:46:23,031 iteration 2871 : loss : 0.032564, loss_ce: 0.012996
2022-01-13 20:46:24,323 iteration 2872 : loss : 0.030949, loss_ce: 0.014520
2022-01-13 20:46:25,733 iteration 2873 : loss : 0.069150, loss_ce: 0.019012
 42%|███████████▍               | 169/400 [1:11:57<1:33:19, 24.24s/it]2022-01-13 20:46:27,189 iteration 2874 : loss : 0.034018, loss_ce: 0.011462
2022-01-13 20:46:28,569 iteration 2875 : loss : 0.033129, loss_ce: 0.013080
2022-01-13 20:46:29,941 iteration 2876 : loss : 0.046254, loss_ce: 0.020105
2022-01-13 20:46:31,361 iteration 2877 : loss : 0.042075, loss_ce: 0.013652
2022-01-13 20:46:32,728 iteration 2878 : loss : 0.039740, loss_ce: 0.019305
2022-01-13 20:46:34,139 iteration 2879 : loss : 0.032883, loss_ce: 0.011848
2022-01-13 20:46:35,563 iteration 2880 : loss : 0.036249, loss_ce: 0.012120
2022-01-13 20:46:36,941 iteration 2881 : loss : 0.024772, loss_ce: 0.010140
2022-01-13 20:46:38,366 iteration 2882 : loss : 0.038647, loss_ce: 0.018954
2022-01-13 20:46:39,704 iteration 2883 : loss : 0.066943, loss_ce: 0.042089
2022-01-13 20:46:41,053 iteration 2884 : loss : 0.028905, loss_ce: 0.012723
2022-01-13 20:46:42,442 iteration 2885 : loss : 0.049413, loss_ce: 0.022795
2022-01-13 20:46:43,729 iteration 2886 : loss : 0.050637, loss_ce: 0.015814
2022-01-13 20:46:45,164 iteration 2887 : loss : 0.044917, loss_ce: 0.026029
2022-01-13 20:46:46,543 iteration 2888 : loss : 0.059803, loss_ce: 0.016541
2022-01-13 20:46:48,022 iteration 2889 : loss : 0.067581, loss_ce: 0.031758
2022-01-13 20:46:48,022 Training Data Eval:
2022-01-13 20:46:54,765   Average segmentation loss on training set: 0.0811
2022-01-13 20:46:54,766 Validation Data Eval:
2022-01-13 20:46:57,096   Average segmentation loss on validation set: 0.0993
2022-01-13 20:46:58,517 iteration 2890 : loss : 0.050051, loss_ce: 0.017887
 42%|███████████▍               | 170/400 [1:12:30<1:42:43, 26.80s/it]2022-01-13 20:46:59,969 iteration 2891 : loss : 0.033370, loss_ce: 0.015072
2022-01-13 20:47:01,413 iteration 2892 : loss : 0.075538, loss_ce: 0.032974
2022-01-13 20:47:02,742 iteration 2893 : loss : 0.036744, loss_ce: 0.015002
2022-01-13 20:47:04,189 iteration 2894 : loss : 0.045511, loss_ce: 0.015340
2022-01-13 20:47:05,620 iteration 2895 : loss : 0.057237, loss_ce: 0.027369
2022-01-13 20:47:06,959 iteration 2896 : loss : 0.029764, loss_ce: 0.009714
2022-01-13 20:47:08,328 iteration 2897 : loss : 0.044196, loss_ce: 0.018824
2022-01-13 20:47:09,646 iteration 2898 : loss : 0.049614, loss_ce: 0.023038
2022-01-13 20:47:11,051 iteration 2899 : loss : 0.039248, loss_ce: 0.013887
2022-01-13 20:47:12,417 iteration 2900 : loss : 0.029524, loss_ce: 0.010258
2022-01-13 20:47:13,805 iteration 2901 : loss : 0.046647, loss_ce: 0.013674
2022-01-13 20:47:15,148 iteration 2902 : loss : 0.042091, loss_ce: 0.016465
2022-01-13 20:47:16,478 iteration 2903 : loss : 0.036992, loss_ce: 0.018020
2022-01-13 20:47:17,805 iteration 2904 : loss : 0.038594, loss_ce: 0.016977
2022-01-13 20:47:19,104 iteration 2905 : loss : 0.042843, loss_ce: 0.023433
2022-01-13 20:47:20,511 iteration 2906 : loss : 0.054531, loss_ce: 0.028039
2022-01-13 20:47:21,842 iteration 2907 : loss : 0.038930, loss_ce: 0.014511
 43%|███████████▌               | 171/400 [1:12:53<1:38:19, 25.76s/it]2022-01-13 20:47:23,312 iteration 2908 : loss : 0.048486, loss_ce: 0.023694
2022-01-13 20:47:24,741 iteration 2909 : loss : 0.039731, loss_ce: 0.019159
2022-01-13 20:47:26,122 iteration 2910 : loss : 0.044529, loss_ce: 0.017808
2022-01-13 20:47:27,544 iteration 2911 : loss : 0.040873, loss_ce: 0.014904
2022-01-13 20:47:28,890 iteration 2912 : loss : 0.037483, loss_ce: 0.014909
2022-01-13 20:47:30,330 iteration 2913 : loss : 0.047108, loss_ce: 0.020859
2022-01-13 20:47:31,681 iteration 2914 : loss : 0.054003, loss_ce: 0.021485
2022-01-13 20:47:33,034 iteration 2915 : loss : 0.028308, loss_ce: 0.011267
2022-01-13 20:47:34,419 iteration 2916 : loss : 0.029073, loss_ce: 0.011725
2022-01-13 20:47:35,723 iteration 2917 : loss : 0.030789, loss_ce: 0.013159
2022-01-13 20:47:37,052 iteration 2918 : loss : 0.039080, loss_ce: 0.012289
2022-01-13 20:47:38,427 iteration 2919 : loss : 0.047553, loss_ce: 0.015230
2022-01-13 20:47:39,823 iteration 2920 : loss : 0.033998, loss_ce: 0.013822
2022-01-13 20:47:41,179 iteration 2921 : loss : 0.043182, loss_ce: 0.019687
2022-01-13 20:47:42,481 iteration 2922 : loss : 0.053982, loss_ce: 0.021280
2022-01-13 20:47:43,821 iteration 2923 : loss : 0.041726, loss_ce: 0.013776
2022-01-13 20:47:45,190 iteration 2924 : loss : 0.053806, loss_ce: 0.019353
 43%|███████████▌               | 172/400 [1:13:16<1:35:08, 25.04s/it]2022-01-13 20:47:46,523 iteration 2925 : loss : 0.030347, loss_ce: 0.015870
2022-01-13 20:47:48,023 iteration 2926 : loss : 0.064009, loss_ce: 0.033063
2022-01-13 20:47:49,411 iteration 2927 : loss : 0.026805, loss_ce: 0.011610
2022-01-13 20:47:50,666 iteration 2928 : loss : 0.034195, loss_ce: 0.012775
2022-01-13 20:47:52,023 iteration 2929 : loss : 0.031310, loss_ce: 0.013072
2022-01-13 20:47:53,495 iteration 2930 : loss : 0.052466, loss_ce: 0.023938
2022-01-13 20:47:54,853 iteration 2931 : loss : 0.032211, loss_ce: 0.012177
2022-01-13 20:47:56,186 iteration 2932 : loss : 0.041592, loss_ce: 0.018146
2022-01-13 20:47:57,660 iteration 2933 : loss : 0.066990, loss_ce: 0.023607
2022-01-13 20:47:59,039 iteration 2934 : loss : 0.037814, loss_ce: 0.013314
2022-01-13 20:48:00,425 iteration 2935 : loss : 0.034358, loss_ce: 0.012386
2022-01-13 20:48:01,788 iteration 2936 : loss : 0.029276, loss_ce: 0.010454
2022-01-13 20:48:03,188 iteration 2937 : loss : 0.030847, loss_ce: 0.014586
2022-01-13 20:48:04,623 iteration 2938 : loss : 0.044140, loss_ce: 0.015264
2022-01-13 20:48:06,060 iteration 2939 : loss : 0.029379, loss_ce: 0.010406
2022-01-13 20:48:07,567 iteration 2940 : loss : 0.062092, loss_ce: 0.032772
2022-01-13 20:48:08,904 iteration 2941 : loss : 0.029924, loss_ce: 0.009746
 43%|███████████▋               | 173/400 [1:13:40<1:33:13, 24.64s/it]2022-01-13 20:48:10,277 iteration 2942 : loss : 0.031805, loss_ce: 0.011407
2022-01-13 20:48:11,685 iteration 2943 : loss : 0.041156, loss_ce: 0.011804
2022-01-13 20:48:13,025 iteration 2944 : loss : 0.039893, loss_ce: 0.021001
2022-01-13 20:48:14,418 iteration 2945 : loss : 0.029027, loss_ce: 0.008303
2022-01-13 20:48:15,694 iteration 2946 : loss : 0.046270, loss_ce: 0.018061
2022-01-13 20:48:17,039 iteration 2947 : loss : 0.034459, loss_ce: 0.013254
2022-01-13 20:48:18,387 iteration 2948 : loss : 0.035282, loss_ce: 0.011057
2022-01-13 20:48:19,838 iteration 2949 : loss : 0.043257, loss_ce: 0.016714
2022-01-13 20:48:21,279 iteration 2950 : loss : 0.029703, loss_ce: 0.012429
2022-01-13 20:48:22,716 iteration 2951 : loss : 0.027374, loss_ce: 0.011294
2022-01-13 20:48:24,148 iteration 2952 : loss : 0.025587, loss_ce: 0.008742
2022-01-13 20:48:25,612 iteration 2953 : loss : 0.033752, loss_ce: 0.016507
2022-01-13 20:48:27,109 iteration 2954 : loss : 0.054700, loss_ce: 0.015171
2022-01-13 20:48:28,455 iteration 2955 : loss : 0.032203, loss_ce: 0.015888
2022-01-13 20:48:29,814 iteration 2956 : loss : 0.030378, loss_ce: 0.012780
2022-01-13 20:48:31,142 iteration 2957 : loss : 0.038772, loss_ce: 0.014723
2022-01-13 20:48:32,527 iteration 2958 : loss : 0.035433, loss_ce: 0.018106
 44%|███████████▋               | 174/400 [1:14:04<1:31:38, 24.33s/it]2022-01-13 20:48:33,937 iteration 2959 : loss : 0.030460, loss_ce: 0.010834
2022-01-13 20:48:35,288 iteration 2960 : loss : 0.035686, loss_ce: 0.015412
2022-01-13 20:48:36,687 iteration 2961 : loss : 0.041365, loss_ce: 0.014761
2022-01-13 20:48:38,207 iteration 2962 : loss : 0.032983, loss_ce: 0.010702
2022-01-13 20:48:39,606 iteration 2963 : loss : 0.056086, loss_ce: 0.021692
2022-01-13 20:48:40,902 iteration 2964 : loss : 0.037857, loss_ce: 0.016851
2022-01-13 20:48:42,301 iteration 2965 : loss : 0.026736, loss_ce: 0.013845
2022-01-13 20:48:43,723 iteration 2966 : loss : 0.039890, loss_ce: 0.015529
2022-01-13 20:48:45,087 iteration 2967 : loss : 0.062484, loss_ce: 0.034366
2022-01-13 20:48:46,472 iteration 2968 : loss : 0.028201, loss_ce: 0.011743
2022-01-13 20:48:47,835 iteration 2969 : loss : 0.031952, loss_ce: 0.014606
2022-01-13 20:48:49,212 iteration 2970 : loss : 0.048968, loss_ce: 0.019573
2022-01-13 20:48:50,571 iteration 2971 : loss : 0.027335, loss_ce: 0.010730
2022-01-13 20:48:51,942 iteration 2972 : loss : 0.034640, loss_ce: 0.016258
2022-01-13 20:48:53,256 iteration 2973 : loss : 0.033704, loss_ce: 0.009321
2022-01-13 20:48:54,691 iteration 2974 : loss : 0.048487, loss_ce: 0.014741
2022-01-13 20:48:54,691 Training Data Eval:
2022-01-13 20:49:01,457   Average segmentation loss on training set: 0.0231
2022-01-13 20:49:01,458 Validation Data Eval:
2022-01-13 20:49:03,798   Average segmentation loss on validation set: 0.0991
2022-01-13 20:49:05,140 iteration 2975 : loss : 0.026896, loss_ce: 0.010666
 44%|███████████▊               | 175/400 [1:14:36<1:40:33, 26.82s/it]2022-01-13 20:49:06,473 iteration 2976 : loss : 0.028826, loss_ce: 0.012316
2022-01-13 20:49:07,877 iteration 2977 : loss : 0.037269, loss_ce: 0.018490
2022-01-13 20:49:09,272 iteration 2978 : loss : 0.037116, loss_ce: 0.013613
2022-01-13 20:49:10,689 iteration 2979 : loss : 0.030961, loss_ce: 0.011422
2022-01-13 20:49:12,106 iteration 2980 : loss : 0.058201, loss_ce: 0.017351
2022-01-13 20:49:13,592 iteration 2981 : loss : 0.045233, loss_ce: 0.022675
2022-01-13 20:49:14,965 iteration 2982 : loss : 0.025165, loss_ce: 0.009323
2022-01-13 20:49:16,361 iteration 2983 : loss : 0.038379, loss_ce: 0.016049
2022-01-13 20:49:17,755 iteration 2984 : loss : 0.055524, loss_ce: 0.020485
2022-01-13 20:49:19,161 iteration 2985 : loss : 0.049532, loss_ce: 0.023144
2022-01-13 20:49:20,471 iteration 2986 : loss : 0.035394, loss_ce: 0.015020
2022-01-13 20:49:21,865 iteration 2987 : loss : 0.058031, loss_ce: 0.016659
2022-01-13 20:49:23,286 iteration 2988 : loss : 0.033586, loss_ce: 0.014255
2022-01-13 20:49:24,707 iteration 2989 : loss : 0.038530, loss_ce: 0.014453
2022-01-13 20:49:26,036 iteration 2990 : loss : 0.031705, loss_ce: 0.012585
2022-01-13 20:49:27,412 iteration 2991 : loss : 0.031579, loss_ce: 0.013517
2022-01-13 20:49:28,860 iteration 2992 : loss : 0.031903, loss_ce: 0.013318
 44%|███████████▉               | 176/400 [1:15:00<1:36:38, 25.89s/it]2022-01-13 20:49:30,240 iteration 2993 : loss : 0.031279, loss_ce: 0.015228
2022-01-13 20:49:31,625 iteration 2994 : loss : 0.064180, loss_ce: 0.017305
2022-01-13 20:49:32,975 iteration 2995 : loss : 0.050811, loss_ce: 0.019775
2022-01-13 20:49:34,341 iteration 2996 : loss : 0.031226, loss_ce: 0.016032
2022-01-13 20:49:35,701 iteration 2997 : loss : 0.029451, loss_ce: 0.009764
2022-01-13 20:49:37,086 iteration 2998 : loss : 0.030465, loss_ce: 0.012338
2022-01-13 20:49:38,516 iteration 2999 : loss : 0.074224, loss_ce: 0.013338
2022-01-13 20:49:39,981 iteration 3000 : loss : 0.056439, loss_ce: 0.025768
2022-01-13 20:49:41,427 iteration 3001 : loss : 0.055460, loss_ce: 0.014556
2022-01-13 20:49:42,779 iteration 3002 : loss : 0.027805, loss_ce: 0.011238
2022-01-13 20:49:44,124 iteration 3003 : loss : 0.043794, loss_ce: 0.017392
2022-01-13 20:49:45,475 iteration 3004 : loss : 0.045506, loss_ce: 0.021464
2022-01-13 20:49:46,860 iteration 3005 : loss : 0.041497, loss_ce: 0.018117
2022-01-13 20:49:48,271 iteration 3006 : loss : 0.031795, loss_ce: 0.012853
2022-01-13 20:49:49,682 iteration 3007 : loss : 0.047462, loss_ce: 0.019964
2022-01-13 20:49:51,099 iteration 3008 : loss : 0.056663, loss_ce: 0.021339
2022-01-13 20:49:52,424 iteration 3009 : loss : 0.039031, loss_ce: 0.017029
 44%|███████████▉               | 177/400 [1:15:24<1:33:37, 25.19s/it]2022-01-13 20:49:54,019 iteration 3010 : loss : 0.059117, loss_ce: 0.021788
2022-01-13 20:49:55,460 iteration 3011 : loss : 0.040096, loss_ce: 0.020039
2022-01-13 20:49:56,803 iteration 3012 : loss : 0.024760, loss_ce: 0.010945
2022-01-13 20:49:58,110 iteration 3013 : loss : 0.048322, loss_ce: 0.015123
2022-01-13 20:49:59,506 iteration 3014 : loss : 0.036869, loss_ce: 0.012990
2022-01-13 20:50:00,889 iteration 3015 : loss : 0.054369, loss_ce: 0.012940
2022-01-13 20:50:02,299 iteration 3016 : loss : 0.036858, loss_ce: 0.014390
2022-01-13 20:50:03,652 iteration 3017 : loss : 0.035999, loss_ce: 0.018483
2022-01-13 20:50:05,011 iteration 3018 : loss : 0.022908, loss_ce: 0.010142
2022-01-13 20:50:06,327 iteration 3019 : loss : 0.032209, loss_ce: 0.011405
2022-01-13 20:50:07,777 iteration 3020 : loss : 0.042362, loss_ce: 0.014369
2022-01-13 20:50:09,182 iteration 3021 : loss : 0.023861, loss_ce: 0.008278
2022-01-13 20:50:10,550 iteration 3022 : loss : 0.032792, loss_ce: 0.010884
2022-01-13 20:50:11,953 iteration 3023 : loss : 0.039807, loss_ce: 0.014423
2022-01-13 20:50:13,444 iteration 3024 : loss : 0.050038, loss_ce: 0.028696
2022-01-13 20:50:14,932 iteration 3025 : loss : 0.069258, loss_ce: 0.029669
2022-01-13 20:50:16,277 iteration 3026 : loss : 0.027571, loss_ce: 0.011215
 44%|████████████               | 178/400 [1:15:48<1:31:43, 24.79s/it]2022-01-13 20:50:17,826 iteration 3027 : loss : 0.050165, loss_ce: 0.019325
2022-01-13 20:50:19,205 iteration 3028 : loss : 0.030018, loss_ce: 0.012344
2022-01-13 20:50:20,625 iteration 3029 : loss : 0.030429, loss_ce: 0.012697
2022-01-13 20:50:21,986 iteration 3030 : loss : 0.027455, loss_ce: 0.012820
2022-01-13 20:50:23,395 iteration 3031 : loss : 0.050136, loss_ce: 0.016339
2022-01-13 20:50:24,767 iteration 3032 : loss : 0.034276, loss_ce: 0.012034
2022-01-13 20:50:26,199 iteration 3033 : loss : 0.053131, loss_ce: 0.015999
2022-01-13 20:50:27,651 iteration 3034 : loss : 0.049535, loss_ce: 0.015995
2022-01-13 20:50:29,080 iteration 3035 : loss : 0.034988, loss_ce: 0.015654
2022-01-13 20:50:30,453 iteration 3036 : loss : 0.046732, loss_ce: 0.029220
2022-01-13 20:50:31,847 iteration 3037 : loss : 0.038422, loss_ce: 0.015302
2022-01-13 20:50:33,286 iteration 3038 : loss : 0.037770, loss_ce: 0.013960
2022-01-13 20:50:34,617 iteration 3039 : loss : 0.040291, loss_ce: 0.014066
2022-01-13 20:50:36,024 iteration 3040 : loss : 0.056166, loss_ce: 0.017115
2022-01-13 20:50:37,476 iteration 3041 : loss : 0.030440, loss_ce: 0.012336
2022-01-13 20:50:38,873 iteration 3042 : loss : 0.046443, loss_ce: 0.023617
2022-01-13 20:50:40,475 iteration 3043 : loss : 0.043968, loss_ce: 0.013868
 45%|████████████               | 179/400 [1:16:12<1:30:39, 24.61s/it]2022-01-13 20:50:41,958 iteration 3044 : loss : 0.046316, loss_ce: 0.019000
2022-01-13 20:50:43,299 iteration 3045 : loss : 0.029914, loss_ce: 0.011215
2022-01-13 20:50:44,667 iteration 3046 : loss : 0.031627, loss_ce: 0.010639
2022-01-13 20:50:46,176 iteration 3047 : loss : 0.049705, loss_ce: 0.026270
2022-01-13 20:50:47,518 iteration 3048 : loss : 0.036716, loss_ce: 0.013218
2022-01-13 20:50:48,916 iteration 3049 : loss : 0.036906, loss_ce: 0.014815
2022-01-13 20:50:50,343 iteration 3050 : loss : 0.034742, loss_ce: 0.016019
2022-01-13 20:50:51,738 iteration 3051 : loss : 0.042181, loss_ce: 0.011927
2022-01-13 20:50:53,111 iteration 3052 : loss : 0.032950, loss_ce: 0.011958
2022-01-13 20:50:54,594 iteration 3053 : loss : 0.028948, loss_ce: 0.011900
2022-01-13 20:50:55,932 iteration 3054 : loss : 0.034547, loss_ce: 0.010017
2022-01-13 20:50:57,342 iteration 3055 : loss : 0.043242, loss_ce: 0.014684
2022-01-13 20:50:58,700 iteration 3056 : loss : 0.024087, loss_ce: 0.010241
2022-01-13 20:51:00,023 iteration 3057 : loss : 0.032438, loss_ce: 0.016811
2022-01-13 20:51:01,424 iteration 3058 : loss : 0.031483, loss_ce: 0.013841
2022-01-13 20:51:02,857 iteration 3059 : loss : 0.034422, loss_ce: 0.011395
2022-01-13 20:51:02,857 Training Data Eval:
2022-01-13 20:51:09,662   Average segmentation loss on training set: 0.0215
2022-01-13 20:51:09,663 Validation Data Eval:
2022-01-13 20:51:12,021   Average segmentation loss on validation set: 0.0782
2022-01-13 20:51:13,365 iteration 3060 : loss : 0.029854, loss_ce: 0.015148
 45%|████████████▏              | 180/400 [1:16:45<1:39:21, 27.10s/it]2022-01-13 20:51:14,715 iteration 3061 : loss : 0.027453, loss_ce: 0.010473
2022-01-13 20:51:16,104 iteration 3062 : loss : 0.044223, loss_ce: 0.017364
2022-01-13 20:51:17,519 iteration 3063 : loss : 0.032811, loss_ce: 0.011451
2022-01-13 20:51:18,934 iteration 3064 : loss : 0.031370, loss_ce: 0.015140
2022-01-13 20:51:20,213 iteration 3065 : loss : 0.024941, loss_ce: 0.008813
2022-01-13 20:51:21,547 iteration 3066 : loss : 0.040559, loss_ce: 0.021031
2022-01-13 20:51:22,950 iteration 3067 : loss : 0.032606, loss_ce: 0.014852
2022-01-13 20:51:24,342 iteration 3068 : loss : 0.045817, loss_ce: 0.015235
2022-01-13 20:51:25,721 iteration 3069 : loss : 0.066226, loss_ce: 0.022360
2022-01-13 20:51:27,116 iteration 3070 : loss : 0.029431, loss_ce: 0.012361
2022-01-13 20:51:28,435 iteration 3071 : loss : 0.030443, loss_ce: 0.012760
2022-01-13 20:51:29,752 iteration 3072 : loss : 0.029980, loss_ce: 0.010930
2022-01-13 20:51:31,117 iteration 3073 : loss : 0.032661, loss_ce: 0.013443
2022-01-13 20:51:32,571 iteration 3074 : loss : 0.042809, loss_ce: 0.018181
2022-01-13 20:51:33,985 iteration 3075 : loss : 0.044125, loss_ce: 0.016839
2022-01-13 20:51:35,425 iteration 3076 : loss : 0.066884, loss_ce: 0.025799
2022-01-13 20:51:36,750 iteration 3077 : loss : 0.045139, loss_ce: 0.017582
 45%|████████████▏              | 181/400 [1:17:08<1:34:49, 25.98s/it]2022-01-13 20:51:38,129 iteration 3078 : loss : 0.030540, loss_ce: 0.012408
2022-01-13 20:51:39,615 iteration 3079 : loss : 0.037830, loss_ce: 0.014225
2022-01-13 20:51:40,921 iteration 3080 : loss : 0.034578, loss_ce: 0.010628
2022-01-13 20:51:42,347 iteration 3081 : loss : 0.037965, loss_ce: 0.013101
2022-01-13 20:51:43,705 iteration 3082 : loss : 0.036527, loss_ce: 0.010144
2022-01-13 20:51:45,153 iteration 3083 : loss : 0.040140, loss_ce: 0.014558
2022-01-13 20:51:46,416 iteration 3084 : loss : 0.028678, loss_ce: 0.012353
2022-01-13 20:51:47,800 iteration 3085 : loss : 0.030924, loss_ce: 0.013040
2022-01-13 20:51:49,297 iteration 3086 : loss : 0.037325, loss_ce: 0.019809
2022-01-13 20:51:50,647 iteration 3087 : loss : 0.059135, loss_ce: 0.026597
2022-01-13 20:51:52,044 iteration 3088 : loss : 0.021309, loss_ce: 0.006460
2022-01-13 20:51:53,535 iteration 3089 : loss : 0.044019, loss_ce: 0.013121
2022-01-13 20:51:54,851 iteration 3090 : loss : 0.034459, loss_ce: 0.016033
2022-01-13 20:51:56,234 iteration 3091 : loss : 0.036565, loss_ce: 0.020733
2022-01-13 20:51:57,762 iteration 3092 : loss : 0.049339, loss_ce: 0.017636
2022-01-13 20:51:59,111 iteration 3093 : loss : 0.031630, loss_ce: 0.014442
2022-01-13 20:52:00,506 iteration 3094 : loss : 0.030732, loss_ce: 0.013775
 46%|████████████▎              | 182/400 [1:17:32<1:31:59, 25.32s/it]2022-01-13 20:52:01,954 iteration 3095 : loss : 0.030237, loss_ce: 0.012425
2022-01-13 20:52:03,339 iteration 3096 : loss : 0.036267, loss_ce: 0.016747
2022-01-13 20:52:04,701 iteration 3097 : loss : 0.036269, loss_ce: 0.014691
2022-01-13 20:52:06,038 iteration 3098 : loss : 0.024554, loss_ce: 0.010727
2022-01-13 20:52:07,405 iteration 3099 : loss : 0.026674, loss_ce: 0.009487
2022-01-13 20:52:08,730 iteration 3100 : loss : 0.027399, loss_ce: 0.009364
2022-01-13 20:52:10,164 iteration 3101 : loss : 0.027597, loss_ce: 0.010439
2022-01-13 20:52:11,531 iteration 3102 : loss : 0.031628, loss_ce: 0.012167
2022-01-13 20:52:12,924 iteration 3103 : loss : 0.044247, loss_ce: 0.019859
2022-01-13 20:52:14,263 iteration 3104 : loss : 0.029826, loss_ce: 0.014098
2022-01-13 20:52:15,565 iteration 3105 : loss : 0.024541, loss_ce: 0.012313
2022-01-13 20:52:16,939 iteration 3106 : loss : 0.031288, loss_ce: 0.016107
2022-01-13 20:52:18,295 iteration 3107 : loss : 0.029925, loss_ce: 0.009334
2022-01-13 20:52:19,689 iteration 3108 : loss : 0.040870, loss_ce: 0.013110
2022-01-13 20:52:21,119 iteration 3109 : loss : 0.028251, loss_ce: 0.009356
2022-01-13 20:52:22,523 iteration 3110 : loss : 0.067980, loss_ce: 0.033460
2022-01-13 20:52:23,915 iteration 3111 : loss : 0.036186, loss_ce: 0.014658
 46%|████████████▎              | 183/400 [1:17:55<1:29:28, 24.74s/it]2022-01-13 20:52:25,383 iteration 3112 : loss : 0.042854, loss_ce: 0.017360
2022-01-13 20:52:26,723 iteration 3113 : loss : 0.036802, loss_ce: 0.014484
2022-01-13 20:52:28,137 iteration 3114 : loss : 0.036466, loss_ce: 0.012023
2022-01-13 20:52:29,521 iteration 3115 : loss : 0.038480, loss_ce: 0.017265
2022-01-13 20:52:30,887 iteration 3116 : loss : 0.025552, loss_ce: 0.011329
2022-01-13 20:52:32,334 iteration 3117 : loss : 0.026505, loss_ce: 0.010675
2022-01-13 20:52:33,692 iteration 3118 : loss : 0.038286, loss_ce: 0.014899
2022-01-13 20:52:35,161 iteration 3119 : loss : 0.042968, loss_ce: 0.015721
2022-01-13 20:52:36,482 iteration 3120 : loss : 0.024359, loss_ce: 0.009891
2022-01-13 20:52:37,914 iteration 3121 : loss : 0.026570, loss_ce: 0.011735
2022-01-13 20:52:39,270 iteration 3122 : loss : 0.042434, loss_ce: 0.011355
2022-01-13 20:52:40,714 iteration 3123 : loss : 0.032191, loss_ce: 0.014577
2022-01-13 20:52:42,023 iteration 3124 : loss : 0.023529, loss_ce: 0.008976
2022-01-13 20:52:43,389 iteration 3125 : loss : 0.033024, loss_ce: 0.010514
2022-01-13 20:52:44,826 iteration 3126 : loss : 0.025076, loss_ce: 0.011977
2022-01-13 20:52:46,282 iteration 3127 : loss : 0.033070, loss_ce: 0.011576
2022-01-13 20:52:47,731 iteration 3128 : loss : 0.032387, loss_ce: 0.011887
 46%|████████████▍              | 184/400 [1:18:19<1:28:04, 24.47s/it]2022-01-13 20:52:49,144 iteration 3129 : loss : 0.034116, loss_ce: 0.013614
2022-01-13 20:52:50,632 iteration 3130 : loss : 0.039326, loss_ce: 0.017651
2022-01-13 20:52:52,005 iteration 3131 : loss : 0.031113, loss_ce: 0.010050
2022-01-13 20:52:53,386 iteration 3132 : loss : 0.024747, loss_ce: 0.007864
2022-01-13 20:52:54,772 iteration 3133 : loss : 0.041736, loss_ce: 0.015805
2022-01-13 20:52:56,123 iteration 3134 : loss : 0.025565, loss_ce: 0.012293
2022-01-13 20:52:57,502 iteration 3135 : loss : 0.043094, loss_ce: 0.020367
2022-01-13 20:52:58,873 iteration 3136 : loss : 0.032358, loss_ce: 0.013749
2022-01-13 20:53:00,377 iteration 3137 : loss : 0.027182, loss_ce: 0.011280
2022-01-13 20:53:01,827 iteration 3138 : loss : 0.049276, loss_ce: 0.020193
2022-01-13 20:53:03,145 iteration 3139 : loss : 0.031729, loss_ce: 0.011645
2022-01-13 20:53:04,464 iteration 3140 : loss : 0.033999, loss_ce: 0.015102
2022-01-13 20:53:05,867 iteration 3141 : loss : 0.032466, loss_ce: 0.015338
2022-01-13 20:53:07,226 iteration 3142 : loss : 0.046823, loss_ce: 0.018190
2022-01-13 20:53:08,643 iteration 3143 : loss : 0.039831, loss_ce: 0.015893
2022-01-13 20:53:10,017 iteration 3144 : loss : 0.051702, loss_ce: 0.021805
2022-01-13 20:53:10,017 Training Data Eval:
2022-01-13 20:53:16,804   Average segmentation loss on training set: 0.0200
2022-01-13 20:53:16,804 Validation Data Eval:
2022-01-13 20:53:19,144   Average segmentation loss on validation set: 0.0999
2022-01-13 20:53:20,487 iteration 3145 : loss : 0.024522, loss_ce: 0.010008
 46%|████████████▍              | 185/400 [1:18:52<1:36:34, 26.95s/it]2022-01-13 20:53:22,071 iteration 3146 : loss : 0.041307, loss_ce: 0.013382
2022-01-13 20:53:23,502 iteration 3147 : loss : 0.031756, loss_ce: 0.014581
2022-01-13 20:53:24,841 iteration 3148 : loss : 0.024270, loss_ce: 0.008947
2022-01-13 20:53:26,273 iteration 3149 : loss : 0.035164, loss_ce: 0.011164
2022-01-13 20:53:27,695 iteration 3150 : loss : 0.040701, loss_ce: 0.015449
2022-01-13 20:53:29,118 iteration 3151 : loss : 0.046509, loss_ce: 0.018769
2022-01-13 20:53:30,538 iteration 3152 : loss : 0.035881, loss_ce: 0.013314
2022-01-13 20:53:31,943 iteration 3153 : loss : 0.037537, loss_ce: 0.019246
2022-01-13 20:53:33,407 iteration 3154 : loss : 0.032001, loss_ce: 0.012371
2022-01-13 20:53:34,828 iteration 3155 : loss : 0.028718, loss_ce: 0.011567
2022-01-13 20:53:36,141 iteration 3156 : loss : 0.034172, loss_ce: 0.011505
2022-01-13 20:53:37,541 iteration 3157 : loss : 0.039362, loss_ce: 0.017081
2022-01-13 20:53:38,880 iteration 3158 : loss : 0.047014, loss_ce: 0.011333
2022-01-13 20:53:40,299 iteration 3159 : loss : 0.050174, loss_ce: 0.029868
2022-01-13 20:53:41,731 iteration 3160 : loss : 0.031321, loss_ce: 0.013227
2022-01-13 20:53:43,200 iteration 3161 : loss : 0.038747, loss_ce: 0.015317
2022-01-13 20:53:44,587 iteration 3162 : loss : 0.049677, loss_ce: 0.015490
 46%|████████████▌              | 186/400 [1:19:16<1:33:04, 26.10s/it]2022-01-13 20:53:45,993 iteration 3163 : loss : 0.036524, loss_ce: 0.012940
2022-01-13 20:53:47,488 iteration 3164 : loss : 0.048636, loss_ce: 0.019304
2022-01-13 20:53:48,914 iteration 3165 : loss : 0.035257, loss_ce: 0.013844
2022-01-13 20:53:50,279 iteration 3166 : loss : 0.030471, loss_ce: 0.011982
2022-01-13 20:53:51,723 iteration 3167 : loss : 0.033223, loss_ce: 0.011000
2022-01-13 20:53:53,114 iteration 3168 : loss : 0.036284, loss_ce: 0.015272
2022-01-13 20:53:54,531 iteration 3169 : loss : 0.057477, loss_ce: 0.028582
2022-01-13 20:53:55,925 iteration 3170 : loss : 0.037023, loss_ce: 0.017429
2022-01-13 20:53:57,194 iteration 3171 : loss : 0.029053, loss_ce: 0.009132
2022-01-13 20:53:58,533 iteration 3172 : loss : 0.044546, loss_ce: 0.020322
2022-01-13 20:53:59,908 iteration 3173 : loss : 0.045490, loss_ce: 0.017805
2022-01-13 20:54:01,265 iteration 3174 : loss : 0.050390, loss_ce: 0.021604
2022-01-13 20:54:02,587 iteration 3175 : loss : 0.057470, loss_ce: 0.019579
2022-01-13 20:54:04,049 iteration 3176 : loss : 0.050802, loss_ce: 0.016092
2022-01-13 20:54:05,439 iteration 3177 : loss : 0.043779, loss_ce: 0.017611
2022-01-13 20:54:06,936 iteration 3178 : loss : 0.040550, loss_ce: 0.013392
2022-01-13 20:54:08,357 iteration 3179 : loss : 0.039639, loss_ce: 0.023752
 47%|████████████▌              | 187/400 [1:19:40<1:30:09, 25.40s/it]2022-01-13 20:54:09,805 iteration 3180 : loss : 0.083851, loss_ce: 0.044210
2022-01-13 20:54:11,160 iteration 3181 : loss : 0.047684, loss_ce: 0.020729
2022-01-13 20:54:12,483 iteration 3182 : loss : 0.047226, loss_ce: 0.026470
2022-01-13 20:54:13,915 iteration 3183 : loss : 0.052580, loss_ce: 0.017718
2022-01-13 20:54:15,294 iteration 3184 : loss : 0.042330, loss_ce: 0.017223
2022-01-13 20:54:16,686 iteration 3185 : loss : 0.046712, loss_ce: 0.015737
2022-01-13 20:54:18,106 iteration 3186 : loss : 0.037064, loss_ce: 0.017243
2022-01-13 20:54:19,538 iteration 3187 : loss : 0.031014, loss_ce: 0.011910
2022-01-13 20:54:20,988 iteration 3188 : loss : 0.038863, loss_ce: 0.014532
2022-01-13 20:54:22,354 iteration 3189 : loss : 0.041786, loss_ce: 0.016682
2022-01-13 20:54:23,859 iteration 3190 : loss : 0.039549, loss_ce: 0.017314
2022-01-13 20:54:25,278 iteration 3191 : loss : 0.036173, loss_ce: 0.014422
2022-01-13 20:54:26,600 iteration 3192 : loss : 0.048106, loss_ce: 0.010360
2022-01-13 20:54:27,994 iteration 3193 : loss : 0.046066, loss_ce: 0.019965
2022-01-13 20:54:29,505 iteration 3194 : loss : 0.055510, loss_ce: 0.023248
2022-01-13 20:54:30,914 iteration 3195 : loss : 0.027429, loss_ce: 0.011718
2022-01-13 20:54:32,293 iteration 3196 : loss : 0.039161, loss_ce: 0.018627
 47%|████████████▋              | 188/400 [1:20:04<1:28:11, 24.96s/it]2022-01-13 20:54:33,720 iteration 3197 : loss : 0.026700, loss_ce: 0.011817
2022-01-13 20:54:35,157 iteration 3198 : loss : 0.049627, loss_ce: 0.023633
2022-01-13 20:54:36,557 iteration 3199 : loss : 0.059606, loss_ce: 0.013852
2022-01-13 20:54:37,987 iteration 3200 : loss : 0.039714, loss_ce: 0.014221
2022-01-13 20:54:39,423 iteration 3201 : loss : 0.031543, loss_ce: 0.011307
2022-01-13 20:54:40,861 iteration 3202 : loss : 0.052288, loss_ce: 0.018405
2022-01-13 20:54:42,183 iteration 3203 : loss : 0.026044, loss_ce: 0.011535
2022-01-13 20:54:43,481 iteration 3204 : loss : 0.030807, loss_ce: 0.012981
2022-01-13 20:54:44,780 iteration 3205 : loss : 0.047472, loss_ce: 0.015553
2022-01-13 20:54:46,040 iteration 3206 : loss : 0.032355, loss_ce: 0.011462
2022-01-13 20:54:47,471 iteration 3207 : loss : 0.062408, loss_ce: 0.025308
2022-01-13 20:54:48,859 iteration 3208 : loss : 0.032728, loss_ce: 0.012097
2022-01-13 20:54:50,225 iteration 3209 : loss : 0.049937, loss_ce: 0.017445
2022-01-13 20:54:51,651 iteration 3210 : loss : 0.029223, loss_ce: 0.012564
2022-01-13 20:54:52,982 iteration 3211 : loss : 0.028830, loss_ce: 0.008437
2022-01-13 20:54:54,463 iteration 3212 : loss : 0.043826, loss_ce: 0.019195
2022-01-13 20:54:55,953 iteration 3213 : loss : 0.042303, loss_ce: 0.014849
 47%|████████████▊              | 189/400 [1:20:27<1:26:24, 24.57s/it]2022-01-13 20:54:57,378 iteration 3214 : loss : 0.023751, loss_ce: 0.010771
2022-01-13 20:54:58,774 iteration 3215 : loss : 0.031761, loss_ce: 0.015053
2022-01-13 20:55:00,166 iteration 3216 : loss : 0.041476, loss_ce: 0.016861
2022-01-13 20:55:01,589 iteration 3217 : loss : 0.034574, loss_ce: 0.015161
2022-01-13 20:55:02,993 iteration 3218 : loss : 0.045028, loss_ce: 0.015088
2022-01-13 20:55:04,408 iteration 3219 : loss : 0.036875, loss_ce: 0.016252
2022-01-13 20:55:05,749 iteration 3220 : loss : 0.023856, loss_ce: 0.009407
2022-01-13 20:55:07,259 iteration 3221 : loss : 0.071057, loss_ce: 0.034900
2022-01-13 20:55:08,638 iteration 3222 : loss : 0.029308, loss_ce: 0.008245
2022-01-13 20:55:10,100 iteration 3223 : loss : 0.032129, loss_ce: 0.010682
2022-01-13 20:55:11,568 iteration 3224 : loss : 0.052969, loss_ce: 0.015697
2022-01-13 20:55:12,984 iteration 3225 : loss : 0.046405, loss_ce: 0.020250
2022-01-13 20:55:14,382 iteration 3226 : loss : 0.037037, loss_ce: 0.014559
2022-01-13 20:55:15,778 iteration 3227 : loss : 0.053355, loss_ce: 0.024959
2022-01-13 20:55:17,136 iteration 3228 : loss : 0.028376, loss_ce: 0.009591
2022-01-13 20:55:18,467 iteration 3229 : loss : 0.036652, loss_ce: 0.011132
2022-01-13 20:55:18,467 Training Data Eval:
2022-01-13 20:55:25,282   Average segmentation loss on training set: 0.0230
2022-01-13 20:55:25,283 Validation Data Eval:
2022-01-13 20:55:27,632   Average segmentation loss on validation set: 0.0840
2022-01-13 20:55:28,950 iteration 3230 : loss : 0.028530, loss_ce: 0.010127
 48%|████████████▊              | 190/400 [1:21:00<1:34:50, 27.10s/it]2022-01-13 20:55:30,352 iteration 3231 : loss : 0.038972, loss_ce: 0.009165
2022-01-13 20:55:31,732 iteration 3232 : loss : 0.030915, loss_ce: 0.011128
2022-01-13 20:55:33,122 iteration 3233 : loss : 0.035772, loss_ce: 0.016902
2022-01-13 20:55:34,543 iteration 3234 : loss : 0.029464, loss_ce: 0.012274
2022-01-13 20:55:35,938 iteration 3235 : loss : 0.047550, loss_ce: 0.016164
2022-01-13 20:55:37,264 iteration 3236 : loss : 0.022364, loss_ce: 0.010830
2022-01-13 20:55:38,766 iteration 3237 : loss : 0.050816, loss_ce: 0.023318
2022-01-13 20:55:40,170 iteration 3238 : loss : 0.028528, loss_ce: 0.013297
2022-01-13 20:55:41,570 iteration 3239 : loss : 0.029118, loss_ce: 0.011879
2022-01-13 20:55:42,908 iteration 3240 : loss : 0.035099, loss_ce: 0.008857
2022-01-13 20:55:44,220 iteration 3241 : loss : 0.035713, loss_ce: 0.008734
2022-01-13 20:55:45,622 iteration 3242 : loss : 0.036310, loss_ce: 0.013694
2022-01-13 20:55:46,946 iteration 3243 : loss : 0.036088, loss_ce: 0.012563
2022-01-13 20:55:48,355 iteration 3244 : loss : 0.039693, loss_ce: 0.015494
2022-01-13 20:55:49,700 iteration 3245 : loss : 0.032140, loss_ce: 0.018569
2022-01-13 20:55:51,164 iteration 3246 : loss : 0.044224, loss_ce: 0.021719
2022-01-13 20:55:52,518 iteration 3247 : loss : 0.031531, loss_ce: 0.013212
 48%|████████████▉              | 191/400 [1:21:24<1:30:42, 26.04s/it]2022-01-13 20:55:53,902 iteration 3248 : loss : 0.026055, loss_ce: 0.010300
2022-01-13 20:55:55,233 iteration 3249 : loss : 0.029430, loss_ce: 0.010623
2022-01-13 20:55:56,602 iteration 3250 : loss : 0.037362, loss_ce: 0.012043
2022-01-13 20:55:57,959 iteration 3251 : loss : 0.028851, loss_ce: 0.012898
2022-01-13 20:55:59,349 iteration 3252 : loss : 0.028833, loss_ce: 0.009588
2022-01-13 20:56:00,714 iteration 3253 : loss : 0.029993, loss_ce: 0.013952
2022-01-13 20:56:02,069 iteration 3254 : loss : 0.043792, loss_ce: 0.018631
2022-01-13 20:56:03,366 iteration 3255 : loss : 0.037963, loss_ce: 0.018531
2022-01-13 20:56:04,723 iteration 3256 : loss : 0.026156, loss_ce: 0.010690
2022-01-13 20:56:06,066 iteration 3257 : loss : 0.024827, loss_ce: 0.010285
2022-01-13 20:56:07,449 iteration 3258 : loss : 0.032642, loss_ce: 0.013824
2022-01-13 20:56:08,770 iteration 3259 : loss : 0.034264, loss_ce: 0.014697
2022-01-13 20:56:10,170 iteration 3260 : loss : 0.026979, loss_ce: 0.011573
2022-01-13 20:56:11,521 iteration 3261 : loss : 0.052277, loss_ce: 0.015268
2022-01-13 20:56:12,930 iteration 3262 : loss : 0.037206, loss_ce: 0.013317
2022-01-13 20:56:14,445 iteration 3263 : loss : 0.052649, loss_ce: 0.013829
2022-01-13 20:56:15,834 iteration 3264 : loss : 0.057240, loss_ce: 0.025652
 48%|████████████▉              | 192/400 [1:21:47<1:27:26, 25.23s/it]2022-01-13 20:56:17,220 iteration 3265 : loss : 0.025751, loss_ce: 0.010886
2022-01-13 20:56:18,682 iteration 3266 : loss : 0.045465, loss_ce: 0.019052
2022-01-13 20:56:20,095 iteration 3267 : loss : 0.043115, loss_ce: 0.017415
2022-01-13 20:56:21,427 iteration 3268 : loss : 0.042573, loss_ce: 0.016832
2022-01-13 20:56:22,855 iteration 3269 : loss : 0.097960, loss_ce: 0.045057
2022-01-13 20:56:24,314 iteration 3270 : loss : 0.046769, loss_ce: 0.014702
2022-01-13 20:56:25,770 iteration 3271 : loss : 0.048019, loss_ce: 0.014352
2022-01-13 20:56:27,228 iteration 3272 : loss : 0.037734, loss_ce: 0.014875
2022-01-13 20:56:28,558 iteration 3273 : loss : 0.041203, loss_ce: 0.012583
2022-01-13 20:56:29,928 iteration 3274 : loss : 0.032290, loss_ce: 0.015797
2022-01-13 20:56:31,368 iteration 3275 : loss : 0.033811, loss_ce: 0.009289
2022-01-13 20:56:32,714 iteration 3276 : loss : 0.036376, loss_ce: 0.015403
2022-01-13 20:56:34,131 iteration 3277 : loss : 0.032367, loss_ce: 0.015967
2022-01-13 20:56:35,527 iteration 3278 : loss : 0.053466, loss_ce: 0.022536
2022-01-13 20:56:36,880 iteration 3279 : loss : 0.027997, loss_ce: 0.012013
2022-01-13 20:56:38,280 iteration 3280 : loss : 0.038846, loss_ce: 0.014183
2022-01-13 20:56:39,607 iteration 3281 : loss : 0.033699, loss_ce: 0.011231
 48%|█████████████              | 193/400 [1:22:11<1:25:30, 24.79s/it]2022-01-13 20:56:41,081 iteration 3282 : loss : 0.041646, loss_ce: 0.016163
2022-01-13 20:56:42,471 iteration 3283 : loss : 0.032698, loss_ce: 0.011144
2022-01-13 20:56:43,864 iteration 3284 : loss : 0.051741, loss_ce: 0.022073
2022-01-13 20:56:45,227 iteration 3285 : loss : 0.051879, loss_ce: 0.027376
2022-01-13 20:56:46,607 iteration 3286 : loss : 0.034464, loss_ce: 0.013423
2022-01-13 20:56:47,994 iteration 3287 : loss : 0.038627, loss_ce: 0.016502
2022-01-13 20:56:49,312 iteration 3288 : loss : 0.043527, loss_ce: 0.024753
2022-01-13 20:56:50,641 iteration 3289 : loss : 0.048474, loss_ce: 0.013770
2022-01-13 20:56:52,069 iteration 3290 : loss : 0.051892, loss_ce: 0.013925
2022-01-13 20:56:53,515 iteration 3291 : loss : 0.040238, loss_ce: 0.014359
2022-01-13 20:56:54,928 iteration 3292 : loss : 0.033311, loss_ce: 0.009342
2022-01-13 20:56:56,318 iteration 3293 : loss : 0.039895, loss_ce: 0.017717
2022-01-13 20:56:57,668 iteration 3294 : loss : 0.031725, loss_ce: 0.014956
2022-01-13 20:56:59,160 iteration 3295 : loss : 0.057495, loss_ce: 0.021685
2022-01-13 20:57:00,567 iteration 3296 : loss : 0.051123, loss_ce: 0.013667
2022-01-13 20:57:01,882 iteration 3297 : loss : 0.033247, loss_ce: 0.013991
2022-01-13 20:57:03,312 iteration 3298 : loss : 0.051232, loss_ce: 0.019794
 48%|█████████████              | 194/400 [1:22:35<1:23:59, 24.46s/it]2022-01-13 20:57:04,682 iteration 3299 : loss : 0.027941, loss_ce: 0.013564
2022-01-13 20:57:06,036 iteration 3300 : loss : 0.053495, loss_ce: 0.018572
2022-01-13 20:57:07,489 iteration 3301 : loss : 0.033943, loss_ce: 0.016045
2022-01-13 20:57:08,879 iteration 3302 : loss : 0.038894, loss_ce: 0.016116
2022-01-13 20:57:10,245 iteration 3303 : loss : 0.031008, loss_ce: 0.014008
2022-01-13 20:57:11,634 iteration 3304 : loss : 0.035390, loss_ce: 0.014232
2022-01-13 20:57:13,056 iteration 3305 : loss : 0.035864, loss_ce: 0.013324
2022-01-13 20:57:14,497 iteration 3306 : loss : 0.043192, loss_ce: 0.016232
2022-01-13 20:57:15,851 iteration 3307 : loss : 0.035297, loss_ce: 0.013035
2022-01-13 20:57:17,236 iteration 3308 : loss : 0.035642, loss_ce: 0.015615
2022-01-13 20:57:18,614 iteration 3309 : loss : 0.049532, loss_ce: 0.009506
2022-01-13 20:57:20,075 iteration 3310 : loss : 0.082846, loss_ce: 0.039788
2022-01-13 20:57:21,574 iteration 3311 : loss : 0.033603, loss_ce: 0.013356
2022-01-13 20:57:22,911 iteration 3312 : loss : 0.038371, loss_ce: 0.015796
2022-01-13 20:57:24,268 iteration 3313 : loss : 0.030708, loss_ce: 0.012273
2022-01-13 20:57:25,726 iteration 3314 : loss : 0.032935, loss_ce: 0.011437
2022-01-13 20:57:25,726 Training Data Eval:
2022-01-13 20:57:32,533   Average segmentation loss on training set: 0.0256
2022-01-13 20:57:32,533 Validation Data Eval:
2022-01-13 20:57:34,890   Average segmentation loss on validation set: 0.0761
2022-01-13 20:57:40,652 Found new lowest validation loss at iteration 3314! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 20:57:42,042 iteration 3315 : loss : 0.024912, loss_ce: 0.011929
 49%|█████████████▏             | 195/400 [1:23:13<1:38:12, 28.74s/it]2022-01-13 20:57:43,450 iteration 3316 : loss : 0.021133, loss_ce: 0.008723
2022-01-13 20:57:44,800 iteration 3317 : loss : 0.045031, loss_ce: 0.018196
2022-01-13 20:57:46,316 iteration 3318 : loss : 0.029050, loss_ce: 0.012608
2022-01-13 20:57:47,674 iteration 3319 : loss : 0.030120, loss_ce: 0.011431
2022-01-13 20:57:49,048 iteration 3320 : loss : 0.023772, loss_ce: 0.009671
2022-01-13 20:57:50,433 iteration 3321 : loss : 0.021522, loss_ce: 0.006434
2022-01-13 20:57:51,816 iteration 3322 : loss : 0.042252, loss_ce: 0.017765
2022-01-13 20:57:53,147 iteration 3323 : loss : 0.033650, loss_ce: 0.013318
2022-01-13 20:57:54,628 iteration 3324 : loss : 0.029407, loss_ce: 0.012486
2022-01-13 20:57:55,963 iteration 3325 : loss : 0.034988, loss_ce: 0.011679
2022-01-13 20:57:57,369 iteration 3326 : loss : 0.031467, loss_ce: 0.012690
2022-01-13 20:57:58,884 iteration 3327 : loss : 0.066619, loss_ce: 0.023307
2022-01-13 20:58:00,280 iteration 3328 : loss : 0.030688, loss_ce: 0.010846
2022-01-13 20:58:01,634 iteration 3329 : loss : 0.025990, loss_ce: 0.011167
2022-01-13 20:58:02,997 iteration 3330 : loss : 0.059087, loss_ce: 0.019138
2022-01-13 20:58:04,403 iteration 3331 : loss : 0.023562, loss_ce: 0.009509
2022-01-13 20:58:05,697 iteration 3332 : loss : 0.025194, loss_ce: 0.012658
 49%|█████████████▏             | 196/400 [1:23:37<1:32:32, 27.22s/it]2022-01-13 20:58:07,114 iteration 3333 : loss : 0.025423, loss_ce: 0.010583
2022-01-13 20:58:08,506 iteration 3334 : loss : 0.020794, loss_ce: 0.009251
2022-01-13 20:58:09,792 iteration 3335 : loss : 0.020393, loss_ce: 0.009289
2022-01-13 20:58:11,183 iteration 3336 : loss : 0.032495, loss_ce: 0.011257
2022-01-13 20:58:12,605 iteration 3337 : loss : 0.038096, loss_ce: 0.016015
2022-01-13 20:58:14,080 iteration 3338 : loss : 0.034424, loss_ce: 0.017875
2022-01-13 20:58:15,453 iteration 3339 : loss : 0.047539, loss_ce: 0.015316
2022-01-13 20:58:16,806 iteration 3340 : loss : 0.024282, loss_ce: 0.008193
2022-01-13 20:58:18,191 iteration 3341 : loss : 0.026896, loss_ce: 0.011743
2022-01-13 20:58:19,633 iteration 3342 : loss : 0.045828, loss_ce: 0.022740
2022-01-13 20:58:21,045 iteration 3343 : loss : 0.039611, loss_ce: 0.014838
2022-01-13 20:58:22,434 iteration 3344 : loss : 0.033472, loss_ce: 0.012061
2022-01-13 20:58:23,798 iteration 3345 : loss : 0.022982, loss_ce: 0.007848
2022-01-13 20:58:25,204 iteration 3346 : loss : 0.043051, loss_ce: 0.019527
2022-01-13 20:58:26,609 iteration 3347 : loss : 0.048107, loss_ce: 0.012830
2022-01-13 20:58:28,080 iteration 3348 : loss : 0.043025, loss_ce: 0.014496
2022-01-13 20:58:29,477 iteration 3349 : loss : 0.034906, loss_ce: 0.013444
 49%|█████████████▎             | 197/400 [1:24:01<1:28:35, 26.18s/it]2022-01-13 20:58:30,870 iteration 3350 : loss : 0.029674, loss_ce: 0.011792
2022-01-13 20:58:32,201 iteration 3351 : loss : 0.027636, loss_ce: 0.010866
2022-01-13 20:58:33,581 iteration 3352 : loss : 0.025400, loss_ce: 0.010003
2022-01-13 20:58:35,017 iteration 3353 : loss : 0.023425, loss_ce: 0.010283
2022-01-13 20:58:36,430 iteration 3354 : loss : 0.021235, loss_ce: 0.007185
2022-01-13 20:58:37,880 iteration 3355 : loss : 0.033113, loss_ce: 0.016753
2022-01-13 20:58:39,295 iteration 3356 : loss : 0.034905, loss_ce: 0.011428
2022-01-13 20:58:40,721 iteration 3357 : loss : 0.041138, loss_ce: 0.013951
2022-01-13 20:58:42,172 iteration 3358 : loss : 0.027029, loss_ce: 0.009465
2022-01-13 20:58:43,585 iteration 3359 : loss : 0.029286, loss_ce: 0.011413
2022-01-13 20:58:45,064 iteration 3360 : loss : 0.041328, loss_ce: 0.019241
2022-01-13 20:58:46,422 iteration 3361 : loss : 0.033722, loss_ce: 0.008774
2022-01-13 20:58:47,779 iteration 3362 : loss : 0.029468, loss_ce: 0.012028
2022-01-13 20:58:49,119 iteration 3363 : loss : 0.022429, loss_ce: 0.010117
2022-01-13 20:58:50,534 iteration 3364 : loss : 0.027291, loss_ce: 0.009552
2022-01-13 20:58:51,878 iteration 3365 : loss : 0.030989, loss_ce: 0.016778
2022-01-13 20:58:53,255 iteration 3366 : loss : 0.025251, loss_ce: 0.009709
 50%|█████████████▎             | 198/400 [1:24:25<1:25:43, 25.46s/it]2022-01-13 20:58:54,683 iteration 3367 : loss : 0.031096, loss_ce: 0.011366
2022-01-13 20:58:56,049 iteration 3368 : loss : 0.036503, loss_ce: 0.021226
2022-01-13 20:58:57,466 iteration 3369 : loss : 0.024644, loss_ce: 0.009080
2022-01-13 20:58:58,890 iteration 3370 : loss : 0.029285, loss_ce: 0.012540
2022-01-13 20:59:00,184 iteration 3371 : loss : 0.018823, loss_ce: 0.007705
2022-01-13 20:59:01,559 iteration 3372 : loss : 0.024312, loss_ce: 0.012509
2022-01-13 20:59:02,931 iteration 3373 : loss : 0.022797, loss_ce: 0.011259
2022-01-13 20:59:04,259 iteration 3374 : loss : 0.023345, loss_ce: 0.010591
2022-01-13 20:59:05,598 iteration 3375 : loss : 0.024033, loss_ce: 0.010061
2022-01-13 20:59:06,946 iteration 3376 : loss : 0.025178, loss_ce: 0.009955
2022-01-13 20:59:08,384 iteration 3377 : loss : 0.063704, loss_ce: 0.023235
2022-01-13 20:59:09,748 iteration 3378 : loss : 0.027671, loss_ce: 0.010302
2022-01-13 20:59:11,026 iteration 3379 : loss : 0.020996, loss_ce: 0.010001
2022-01-13 20:59:12,457 iteration 3380 : loss : 0.039059, loss_ce: 0.015284
2022-01-13 20:59:13,761 iteration 3381 : loss : 0.055776, loss_ce: 0.011744
2022-01-13 20:59:15,137 iteration 3382 : loss : 0.046443, loss_ce: 0.017483
2022-01-13 20:59:16,491 iteration 3383 : loss : 0.031817, loss_ce: 0.012624
 50%|█████████████▍             | 199/400 [1:24:48<1:23:03, 24.80s/it]2022-01-13 20:59:17,869 iteration 3384 : loss : 0.037331, loss_ce: 0.014648
2022-01-13 20:59:19,283 iteration 3385 : loss : 0.037669, loss_ce: 0.018816
2022-01-13 20:59:20,735 iteration 3386 : loss : 0.041221, loss_ce: 0.019128
2022-01-13 20:59:22,171 iteration 3387 : loss : 0.050846, loss_ce: 0.021520
2022-01-13 20:59:23,491 iteration 3388 : loss : 0.023986, loss_ce: 0.008738
2022-01-13 20:59:24,913 iteration 3389 : loss : 0.044634, loss_ce: 0.018279
2022-01-13 20:59:26,228 iteration 3390 : loss : 0.043883, loss_ce: 0.011499
2022-01-13 20:59:27,749 iteration 3391 : loss : 0.041012, loss_ce: 0.011725
2022-01-13 20:59:29,166 iteration 3392 : loss : 0.029517, loss_ce: 0.011680
2022-01-13 20:59:30,591 iteration 3393 : loss : 0.030237, loss_ce: 0.010975
2022-01-13 20:59:31,880 iteration 3394 : loss : 0.026087, loss_ce: 0.009795
2022-01-13 20:59:33,402 iteration 3395 : loss : 0.037780, loss_ce: 0.016947
2022-01-13 20:59:34,813 iteration 3396 : loss : 0.035503, loss_ce: 0.014249
2022-01-13 20:59:36,182 iteration 3397 : loss : 0.027448, loss_ce: 0.011925
2022-01-13 20:59:37,595 iteration 3398 : loss : 0.026625, loss_ce: 0.009580
2022-01-13 20:59:39,002 iteration 3399 : loss : 0.024894, loss_ce: 0.012550
2022-01-13 20:59:39,002 Training Data Eval:
2022-01-13 20:59:45,793   Average segmentation loss on training set: 0.0194
2022-01-13 20:59:45,793 Validation Data Eval:
2022-01-13 20:59:48,126   Average segmentation loss on validation set: 0.0850
2022-01-13 20:59:49,501 iteration 3400 : loss : 0.029097, loss_ce: 0.010242
 50%|█████████████▌             | 200/400 [1:25:21<1:30:52, 27.26s/it]2022-01-13 20:59:51,092 iteration 3401 : loss : 0.043548, loss_ce: 0.021876
2022-01-13 20:59:52,554 iteration 3402 : loss : 0.041196, loss_ce: 0.014467
2022-01-13 20:59:53,912 iteration 3403 : loss : 0.040715, loss_ce: 0.019764
2022-01-13 20:59:55,273 iteration 3404 : loss : 0.021421, loss_ce: 0.008003
2022-01-13 20:59:56,643 iteration 3405 : loss : 0.035282, loss_ce: 0.012801
2022-01-13 20:59:58,076 iteration 3406 : loss : 0.036022, loss_ce: 0.012727
2022-01-13 20:59:59,477 iteration 3407 : loss : 0.031446, loss_ce: 0.013422
2022-01-13 21:00:00,911 iteration 3408 : loss : 0.024458, loss_ce: 0.008903
2022-01-13 21:00:02,367 iteration 3409 : loss : 0.040899, loss_ce: 0.019907
2022-01-13 21:00:03,809 iteration 3410 : loss : 0.035785, loss_ce: 0.015144
2022-01-13 21:00:05,302 iteration 3411 : loss : 0.029010, loss_ce: 0.013098
2022-01-13 21:00:06,639 iteration 3412 : loss : 0.031866, loss_ce: 0.010927
2022-01-13 21:00:07,970 iteration 3413 : loss : 0.018818, loss_ce: 0.008343
2022-01-13 21:00:09,410 iteration 3414 : loss : 0.035852, loss_ce: 0.011230
2022-01-13 21:00:10,878 iteration 3415 : loss : 0.030891, loss_ce: 0.012455
2022-01-13 21:00:12,352 iteration 3416 : loss : 0.024690, loss_ce: 0.008025
2022-01-13 21:00:13,907 iteration 3417 : loss : 0.047577, loss_ce: 0.018991
 50%|█████████████▌             | 201/400 [1:25:45<1:27:34, 26.40s/it]2022-01-13 21:00:15,377 iteration 3418 : loss : 0.036364, loss_ce: 0.019728
2022-01-13 21:00:16,838 iteration 3419 : loss : 0.037392, loss_ce: 0.018737
2022-01-13 21:00:18,377 iteration 3420 : loss : 0.042899, loss_ce: 0.014519
2022-01-13 21:00:19,812 iteration 3421 : loss : 0.037317, loss_ce: 0.013835
2022-01-13 21:00:21,155 iteration 3422 : loss : 0.024502, loss_ce: 0.008291
2022-01-13 21:00:22,561 iteration 3423 : loss : 0.020951, loss_ce: 0.009235
2022-01-13 21:00:23,967 iteration 3424 : loss : 0.040686, loss_ce: 0.020917
2022-01-13 21:00:25,308 iteration 3425 : loss : 0.026683, loss_ce: 0.013077
2022-01-13 21:00:26,716 iteration 3426 : loss : 0.029686, loss_ce: 0.010097
2022-01-13 21:00:28,143 iteration 3427 : loss : 0.030251, loss_ce: 0.010277
2022-01-13 21:00:29,577 iteration 3428 : loss : 0.039601, loss_ce: 0.015194
2022-01-13 21:00:31,045 iteration 3429 : loss : 0.031802, loss_ce: 0.012144
2022-01-13 21:00:32,526 iteration 3430 : loss : 0.043853, loss_ce: 0.020379
2022-01-13 21:00:33,848 iteration 3431 : loss : 0.032993, loss_ce: 0.014249
2022-01-13 21:00:35,205 iteration 3432 : loss : 0.034607, loss_ce: 0.012140
2022-01-13 21:00:36,589 iteration 3433 : loss : 0.032184, loss_ce: 0.013285
2022-01-13 21:00:38,060 iteration 3434 : loss : 0.054846, loss_ce: 0.014968
 50%|█████████████▋             | 202/400 [1:26:09<1:24:54, 25.73s/it]2022-01-13 21:00:39,435 iteration 3435 : loss : 0.025715, loss_ce: 0.007850
2022-01-13 21:00:40,830 iteration 3436 : loss : 0.023416, loss_ce: 0.009305
2022-01-13 21:00:42,392 iteration 3437 : loss : 0.038418, loss_ce: 0.019519
2022-01-13 21:00:43,891 iteration 3438 : loss : 0.024383, loss_ce: 0.010950
2022-01-13 21:00:45,371 iteration 3439 : loss : 0.034054, loss_ce: 0.012840
2022-01-13 21:00:46,737 iteration 3440 : loss : 0.025498, loss_ce: 0.009724
2022-01-13 21:00:48,160 iteration 3441 : loss : 0.030148, loss_ce: 0.010673
2022-01-13 21:00:49,684 iteration 3442 : loss : 0.061078, loss_ce: 0.018426
2022-01-13 21:00:51,142 iteration 3443 : loss : 0.025658, loss_ce: 0.008701
2022-01-13 21:00:52,606 iteration 3444 : loss : 0.035259, loss_ce: 0.013914
2022-01-13 21:00:54,023 iteration 3445 : loss : 0.040612, loss_ce: 0.012586
2022-01-13 21:00:55,417 iteration 3446 : loss : 0.029282, loss_ce: 0.012306
2022-01-13 21:00:56,787 iteration 3447 : loss : 0.034072, loss_ce: 0.011277
2022-01-13 21:00:58,241 iteration 3448 : loss : 0.047270, loss_ce: 0.014557
2022-01-13 21:00:59,668 iteration 3449 : loss : 0.041628, loss_ce: 0.018301
2022-01-13 21:01:01,065 iteration 3450 : loss : 0.037790, loss_ce: 0.018092
2022-01-13 21:01:02,558 iteration 3451 : loss : 0.029459, loss_ce: 0.011706
 51%|█████████████▋             | 203/400 [1:26:34<1:23:15, 25.36s/it]2022-01-13 21:01:04,010 iteration 3452 : loss : 0.023319, loss_ce: 0.009000
2022-01-13 21:01:05,384 iteration 3453 : loss : 0.023135, loss_ce: 0.009036
2022-01-13 21:01:06,738 iteration 3454 : loss : 0.026090, loss_ce: 0.009252
2022-01-13 21:01:08,228 iteration 3455 : loss : 0.042042, loss_ce: 0.017174
2022-01-13 21:01:09,573 iteration 3456 : loss : 0.032527, loss_ce: 0.010719
2022-01-13 21:01:11,069 iteration 3457 : loss : 0.039591, loss_ce: 0.014425
2022-01-13 21:01:12,503 iteration 3458 : loss : 0.046556, loss_ce: 0.021775
2022-01-13 21:01:13,896 iteration 3459 : loss : 0.051856, loss_ce: 0.023006
2022-01-13 21:01:15,274 iteration 3460 : loss : 0.028629, loss_ce: 0.012424
2022-01-13 21:01:16,660 iteration 3461 : loss : 0.030429, loss_ce: 0.012170
2022-01-13 21:01:18,034 iteration 3462 : loss : 0.024386, loss_ce: 0.011537
2022-01-13 21:01:19,468 iteration 3463 : loss : 0.049306, loss_ce: 0.024046
2022-01-13 21:01:20,811 iteration 3464 : loss : 0.024965, loss_ce: 0.008941
2022-01-13 21:01:22,260 iteration 3465 : loss : 0.030823, loss_ce: 0.010212
2022-01-13 21:01:23,679 iteration 3466 : loss : 0.025532, loss_ce: 0.008755
2022-01-13 21:01:25,075 iteration 3467 : loss : 0.030382, loss_ce: 0.016496
2022-01-13 21:01:26,460 iteration 3468 : loss : 0.028876, loss_ce: 0.011830
 51%|█████████████▊             | 204/400 [1:26:58<1:21:24, 24.92s/it]2022-01-13 21:01:27,872 iteration 3469 : loss : 0.030343, loss_ce: 0.008420
2022-01-13 21:01:29,321 iteration 3470 : loss : 0.060281, loss_ce: 0.017716
2022-01-13 21:01:30,635 iteration 3471 : loss : 0.027439, loss_ce: 0.010305
2022-01-13 21:01:32,059 iteration 3472 : loss : 0.043611, loss_ce: 0.020656
2022-01-13 21:01:33,604 iteration 3473 : loss : 0.048227, loss_ce: 0.021265
2022-01-13 21:01:34,996 iteration 3474 : loss : 0.039479, loss_ce: 0.012802
2022-01-13 21:01:36,480 iteration 3475 : loss : 0.051485, loss_ce: 0.014162
2022-01-13 21:01:37,832 iteration 3476 : loss : 0.030439, loss_ce: 0.009274
2022-01-13 21:01:39,255 iteration 3477 : loss : 0.061233, loss_ce: 0.018362
2022-01-13 21:01:40,640 iteration 3478 : loss : 0.028530, loss_ce: 0.011179
2022-01-13 21:01:41,985 iteration 3479 : loss : 0.027333, loss_ce: 0.011594
2022-01-13 21:01:43,282 iteration 3480 : loss : 0.028517, loss_ce: 0.013048
2022-01-13 21:01:44,660 iteration 3481 : loss : 0.039094, loss_ce: 0.014909
2022-01-13 21:01:46,052 iteration 3482 : loss : 0.029297, loss_ce: 0.011259
2022-01-13 21:01:47,507 iteration 3483 : loss : 0.040950, loss_ce: 0.018668
2022-01-13 21:01:48,802 iteration 3484 : loss : 0.027193, loss_ce: 0.010793
2022-01-13 21:01:48,802 Training Data Eval:
2022-01-13 21:01:55,600   Average segmentation loss on training set: 0.0206
2022-01-13 21:01:55,600 Validation Data Eval:
2022-01-13 21:01:57,960   Average segmentation loss on validation set: 0.0791
2022-01-13 21:01:59,456 iteration 3485 : loss : 0.043938, loss_ce: 0.021303
 51%|█████████████▊             | 205/400 [1:27:31<1:28:52, 27.35s/it]2022-01-13 21:02:00,896 iteration 3486 : loss : 0.030650, loss_ce: 0.013655
2022-01-13 21:02:02,233 iteration 3487 : loss : 0.025702, loss_ce: 0.011238
2022-01-13 21:02:03,591 iteration 3488 : loss : 0.051272, loss_ce: 0.019890
2022-01-13 21:02:04,973 iteration 3489 : loss : 0.045035, loss_ce: 0.017563
2022-01-13 21:02:06,384 iteration 3490 : loss : 0.047970, loss_ce: 0.019138
2022-01-13 21:02:07,839 iteration 3491 : loss : 0.041213, loss_ce: 0.016160
2022-01-13 21:02:09,159 iteration 3492 : loss : 0.042064, loss_ce: 0.016528
2022-01-13 21:02:10,672 iteration 3493 : loss : 0.038699, loss_ce: 0.015570
2022-01-13 21:02:12,092 iteration 3494 : loss : 0.035028, loss_ce: 0.010652
2022-01-13 21:02:13,468 iteration 3495 : loss : 0.044333, loss_ce: 0.013391
2022-01-13 21:02:14,909 iteration 3496 : loss : 0.032528, loss_ce: 0.014673
2022-01-13 21:02:16,335 iteration 3497 : loss : 0.039188, loss_ce: 0.015724
2022-01-13 21:02:17,857 iteration 3498 : loss : 0.050446, loss_ce: 0.025074
2022-01-13 21:02:19,213 iteration 3499 : loss : 0.028434, loss_ce: 0.010951
2022-01-13 21:02:20,513 iteration 3500 : loss : 0.020667, loss_ce: 0.006531
2022-01-13 21:02:21,850 iteration 3501 : loss : 0.025133, loss_ce: 0.008385
2022-01-13 21:02:23,249 iteration 3502 : loss : 0.067765, loss_ce: 0.025231
 52%|█████████████▉             | 206/400 [1:27:55<1:24:57, 26.28s/it]2022-01-13 21:02:24,715 iteration 3503 : loss : 0.038474, loss_ce: 0.020620
2022-01-13 21:02:26,072 iteration 3504 : loss : 0.023923, loss_ce: 0.007224
2022-01-13 21:02:27,359 iteration 3505 : loss : 0.022820, loss_ce: 0.011789
2022-01-13 21:02:28,763 iteration 3506 : loss : 0.047924, loss_ce: 0.015342
2022-01-13 21:02:30,131 iteration 3507 : loss : 0.035598, loss_ce: 0.011467
2022-01-13 21:02:31,650 iteration 3508 : loss : 0.048888, loss_ce: 0.023532
2022-01-13 21:02:33,072 iteration 3509 : loss : 0.026752, loss_ce: 0.010403
2022-01-13 21:02:34,401 iteration 3510 : loss : 0.030246, loss_ce: 0.011867
2022-01-13 21:02:35,728 iteration 3511 : loss : 0.023011, loss_ce: 0.010971
2022-01-13 21:02:37,172 iteration 3512 : loss : 0.043021, loss_ce: 0.013630
2022-01-13 21:02:38,567 iteration 3513 : loss : 0.035940, loss_ce: 0.011114
2022-01-13 21:02:40,087 iteration 3514 : loss : 0.038049, loss_ce: 0.017397
2022-01-13 21:02:41,448 iteration 3515 : loss : 0.036487, loss_ce: 0.013376
2022-01-13 21:02:42,795 iteration 3516 : loss : 0.021368, loss_ce: 0.008724
2022-01-13 21:02:44,147 iteration 3517 : loss : 0.024694, loss_ce: 0.009767
2022-01-13 21:02:45,503 iteration 3518 : loss : 0.029259, loss_ce: 0.015687
2022-01-13 21:02:46,893 iteration 3519 : loss : 0.026084, loss_ce: 0.009749
 52%|█████████████▉             | 207/400 [1:28:18<1:21:59, 25.49s/it]2022-01-13 21:02:48,332 iteration 3520 : loss : 0.037379, loss_ce: 0.014896
2022-01-13 21:02:49,685 iteration 3521 : loss : 0.038455, loss_ce: 0.018237
2022-01-13 21:02:51,023 iteration 3522 : loss : 0.026661, loss_ce: 0.012886
2022-01-13 21:02:52,374 iteration 3523 : loss : 0.021119, loss_ce: 0.007995
2022-01-13 21:02:53,774 iteration 3524 : loss : 0.025337, loss_ce: 0.011260
2022-01-13 21:02:55,239 iteration 3525 : loss : 0.025092, loss_ce: 0.009970
2022-01-13 21:02:56,629 iteration 3526 : loss : 0.036356, loss_ce: 0.013901
2022-01-13 21:02:58,046 iteration 3527 : loss : 0.045600, loss_ce: 0.011529
2022-01-13 21:02:59,546 iteration 3528 : loss : 0.041298, loss_ce: 0.016934
2022-01-13 21:03:00,949 iteration 3529 : loss : 0.036340, loss_ce: 0.009689
2022-01-13 21:03:02,367 iteration 3530 : loss : 0.019473, loss_ce: 0.007894
2022-01-13 21:03:03,691 iteration 3531 : loss : 0.024127, loss_ce: 0.007082
2022-01-13 21:03:05,141 iteration 3532 : loss : 0.033639, loss_ce: 0.015173
2022-01-13 21:03:06,498 iteration 3533 : loss : 0.034967, loss_ce: 0.009940
2022-01-13 21:03:07,894 iteration 3534 : loss : 0.038383, loss_ce: 0.016176
2022-01-13 21:03:09,344 iteration 3535 : loss : 0.028800, loss_ce: 0.011149
2022-01-13 21:03:10,752 iteration 3536 : loss : 0.023367, loss_ce: 0.010086
 52%|██████████████             | 208/400 [1:28:42<1:19:59, 25.00s/it]2022-01-13 21:03:12,098 iteration 3537 : loss : 0.024590, loss_ce: 0.009519
2022-01-13 21:03:13,398 iteration 3538 : loss : 0.021268, loss_ce: 0.009378
2022-01-13 21:03:14,713 iteration 3539 : loss : 0.019316, loss_ce: 0.009139
2022-01-13 21:03:15,971 iteration 3540 : loss : 0.022672, loss_ce: 0.007251
2022-01-13 21:03:17,409 iteration 3541 : loss : 0.036145, loss_ce: 0.013517
2022-01-13 21:03:18,805 iteration 3542 : loss : 0.029812, loss_ce: 0.013167
2022-01-13 21:03:20,292 iteration 3543 : loss : 0.053719, loss_ce: 0.017078
2022-01-13 21:03:21,590 iteration 3544 : loss : 0.019529, loss_ce: 0.008138
2022-01-13 21:03:22,954 iteration 3545 : loss : 0.026687, loss_ce: 0.013677
2022-01-13 21:03:24,257 iteration 3546 : loss : 0.023922, loss_ce: 0.008914
2022-01-13 21:03:25,628 iteration 3547 : loss : 0.034753, loss_ce: 0.015537
2022-01-13 21:03:26,943 iteration 3548 : loss : 0.028458, loss_ce: 0.009654
2022-01-13 21:03:28,317 iteration 3549 : loss : 0.029047, loss_ce: 0.011537
2022-01-13 21:03:29,726 iteration 3550 : loss : 0.023325, loss_ce: 0.010633
2022-01-13 21:03:31,163 iteration 3551 : loss : 0.043410, loss_ce: 0.015099
2022-01-13 21:03:32,599 iteration 3552 : loss : 0.046719, loss_ce: 0.016763
2022-01-13 21:03:34,058 iteration 3553 : loss : 0.037585, loss_ce: 0.017403
 52%|██████████████             | 209/400 [1:29:05<1:17:58, 24.49s/it]2022-01-13 21:03:35,505 iteration 3554 : loss : 0.026626, loss_ce: 0.011555
2022-01-13 21:03:36,855 iteration 3555 : loss : 0.022575, loss_ce: 0.007725
2022-01-13 21:03:38,203 iteration 3556 : loss : 0.027176, loss_ce: 0.012075
2022-01-13 21:03:39,658 iteration 3557 : loss : 0.032741, loss_ce: 0.009193
2022-01-13 21:03:40,976 iteration 3558 : loss : 0.041287, loss_ce: 0.011187
2022-01-13 21:03:42,326 iteration 3559 : loss : 0.020209, loss_ce: 0.006142
2022-01-13 21:03:43,585 iteration 3560 : loss : 0.024099, loss_ce: 0.012361
2022-01-13 21:03:45,059 iteration 3561 : loss : 0.039139, loss_ce: 0.018105
2022-01-13 21:03:46,394 iteration 3562 : loss : 0.027124, loss_ce: 0.010209
2022-01-13 21:03:47,792 iteration 3563 : loss : 0.022562, loss_ce: 0.007954
2022-01-13 21:03:49,172 iteration 3564 : loss : 0.037680, loss_ce: 0.013573
2022-01-13 21:03:50,650 iteration 3565 : loss : 0.056051, loss_ce: 0.016661
2022-01-13 21:03:52,034 iteration 3566 : loss : 0.033508, loss_ce: 0.012853
2022-01-13 21:03:53,491 iteration 3567 : loss : 0.044902, loss_ce: 0.022136
2022-01-13 21:03:54,926 iteration 3568 : loss : 0.086798, loss_ce: 0.048511
2022-01-13 21:03:56,367 iteration 3569 : loss : 0.034910, loss_ce: 0.009435
2022-01-13 21:03:56,367 Training Data Eval:
2022-01-13 21:04:03,129   Average segmentation loss on training set: 0.0211
2022-01-13 21:04:03,130 Validation Data Eval:
2022-01-13 21:04:05,466   Average segmentation loss on validation set: 0.0710
2022-01-13 21:04:11,209 Found new lowest validation loss at iteration 3569! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 21:04:12,657 iteration 3570 : loss : 0.032662, loss_ce: 0.012360
 52%|██████████████▏            | 210/400 [1:29:44<1:30:57, 28.72s/it]2022-01-13 21:04:14,075 iteration 3571 : loss : 0.025951, loss_ce: 0.010714
2022-01-13 21:04:15,447 iteration 3572 : loss : 0.036392, loss_ce: 0.011958
2022-01-13 21:04:16,807 iteration 3573 : loss : 0.032278, loss_ce: 0.013631
2022-01-13 21:04:18,142 iteration 3574 : loss : 0.022041, loss_ce: 0.009243
2022-01-13 21:04:19,485 iteration 3575 : loss : 0.033143, loss_ce: 0.014875
2022-01-13 21:04:20,869 iteration 3576 : loss : 0.045905, loss_ce: 0.017988
2022-01-13 21:04:22,289 iteration 3577 : loss : 0.025265, loss_ce: 0.011686
2022-01-13 21:04:23,701 iteration 3578 : loss : 0.035661, loss_ce: 0.014695
2022-01-13 21:04:25,048 iteration 3579 : loss : 0.033500, loss_ce: 0.012506
2022-01-13 21:04:26,445 iteration 3580 : loss : 0.027879, loss_ce: 0.009981
2022-01-13 21:04:27,780 iteration 3581 : loss : 0.045835, loss_ce: 0.014657
2022-01-13 21:04:29,140 iteration 3582 : loss : 0.028675, loss_ce: 0.012677
2022-01-13 21:04:30,543 iteration 3583 : loss : 0.056741, loss_ce: 0.027692
2022-01-13 21:04:31,876 iteration 3584 : loss : 0.035427, loss_ce: 0.014660
2022-01-13 21:04:33,226 iteration 3585 : loss : 0.020836, loss_ce: 0.007249
2022-01-13 21:04:34,525 iteration 3586 : loss : 0.026450, loss_ce: 0.010667
2022-01-13 21:04:35,879 iteration 3587 : loss : 0.033283, loss_ce: 0.016600
 53%|██████████████▏            | 211/400 [1:30:07<1:25:16, 27.07s/it]2022-01-13 21:04:37,216 iteration 3588 : loss : 0.033485, loss_ce: 0.011226
2022-01-13 21:04:38,618 iteration 3589 : loss : 0.039796, loss_ce: 0.014618
2022-01-13 21:04:39,981 iteration 3590 : loss : 0.040728, loss_ce: 0.017604
2022-01-13 21:04:41,330 iteration 3591 : loss : 0.020785, loss_ce: 0.007442
2022-01-13 21:04:42,751 iteration 3592 : loss : 0.027519, loss_ce: 0.010464
2022-01-13 21:04:44,139 iteration 3593 : loss : 0.046319, loss_ce: 0.011525
2022-01-13 21:04:45,519 iteration 3594 : loss : 0.024210, loss_ce: 0.007864
2022-01-13 21:04:47,033 iteration 3595 : loss : 0.067010, loss_ce: 0.015970
2022-01-13 21:04:48,338 iteration 3596 : loss : 0.027639, loss_ce: 0.011518
2022-01-13 21:04:49,790 iteration 3597 : loss : 0.042350, loss_ce: 0.015332
2022-01-13 21:04:51,154 iteration 3598 : loss : 0.040164, loss_ce: 0.018313
2022-01-13 21:04:52,534 iteration 3599 : loss : 0.035069, loss_ce: 0.014222
2022-01-13 21:04:53,887 iteration 3600 : loss : 0.027507, loss_ce: 0.012919
2022-01-13 21:04:55,257 iteration 3601 : loss : 0.030837, loss_ce: 0.014969
2022-01-13 21:04:56,600 iteration 3602 : loss : 0.034813, loss_ce: 0.017826
2022-01-13 21:04:57,923 iteration 3603 : loss : 0.021614, loss_ce: 0.007887
2022-01-13 21:04:59,238 iteration 3604 : loss : 0.024366, loss_ce: 0.010103
 53%|██████████████▎            | 212/400 [1:30:30<1:21:20, 25.96s/it]2022-01-13 21:05:00,655 iteration 3605 : loss : 0.026284, loss_ce: 0.009642
2022-01-13 21:05:02,029 iteration 3606 : loss : 0.034550, loss_ce: 0.014205
2022-01-13 21:05:03,338 iteration 3607 : loss : 0.021396, loss_ce: 0.007801
2022-01-13 21:05:04,668 iteration 3608 : loss : 0.027852, loss_ce: 0.013075
2022-01-13 21:05:06,057 iteration 3609 : loss : 0.032718, loss_ce: 0.010777
2022-01-13 21:05:07,386 iteration 3610 : loss : 0.033921, loss_ce: 0.015153
2022-01-13 21:05:08,781 iteration 3611 : loss : 0.025901, loss_ce: 0.012101
2022-01-13 21:05:10,208 iteration 3612 : loss : 0.031634, loss_ce: 0.011928
2022-01-13 21:05:11,583 iteration 3613 : loss : 0.033091, loss_ce: 0.012491
2022-01-13 21:05:12,993 iteration 3614 : loss : 0.031157, loss_ce: 0.012653
2022-01-13 21:05:14,330 iteration 3615 : loss : 0.039482, loss_ce: 0.012348
2022-01-13 21:05:15,768 iteration 3616 : loss : 0.033733, loss_ce: 0.009437
2022-01-13 21:05:17,116 iteration 3617 : loss : 0.034741, loss_ce: 0.013949
2022-01-13 21:05:18,488 iteration 3618 : loss : 0.046297, loss_ce: 0.021759
2022-01-13 21:05:19,841 iteration 3619 : loss : 0.023004, loss_ce: 0.010468
2022-01-13 21:05:21,236 iteration 3620 : loss : 0.027160, loss_ce: 0.011203
2022-01-13 21:05:22,590 iteration 3621 : loss : 0.037517, loss_ce: 0.015156
 53%|██████████████▍            | 213/400 [1:30:54<1:18:27, 25.18s/it]2022-01-13 21:05:24,076 iteration 3622 : loss : 0.039729, loss_ce: 0.014515
2022-01-13 21:05:25,441 iteration 3623 : loss : 0.028518, loss_ce: 0.013072
2022-01-13 21:05:26,883 iteration 3624 : loss : 0.024346, loss_ce: 0.008095
2022-01-13 21:05:28,344 iteration 3625 : loss : 0.033506, loss_ce: 0.014636
2022-01-13 21:05:29,713 iteration 3626 : loss : 0.029948, loss_ce: 0.012198
2022-01-13 21:05:31,130 iteration 3627 : loss : 0.040920, loss_ce: 0.019530
2022-01-13 21:05:32,514 iteration 3628 : loss : 0.024553, loss_ce: 0.007523
2022-01-13 21:05:33,964 iteration 3629 : loss : 0.030933, loss_ce: 0.014036
2022-01-13 21:05:35,336 iteration 3630 : loss : 0.030238, loss_ce: 0.013113
2022-01-13 21:05:36,641 iteration 3631 : loss : 0.025416, loss_ce: 0.011083
2022-01-13 21:05:37,955 iteration 3632 : loss : 0.021453, loss_ce: 0.009334
2022-01-13 21:05:39,400 iteration 3633 : loss : 0.034592, loss_ce: 0.013632
2022-01-13 21:05:40,766 iteration 3634 : loss : 0.026953, loss_ce: 0.010675
2022-01-13 21:05:42,122 iteration 3635 : loss : 0.034709, loss_ce: 0.016187
2022-01-13 21:05:43,443 iteration 3636 : loss : 0.031680, loss_ce: 0.013199
2022-01-13 21:05:44,858 iteration 3637 : loss : 0.044729, loss_ce: 0.015067
2022-01-13 21:05:46,170 iteration 3638 : loss : 0.022279, loss_ce: 0.007318
 54%|██████████████▍            | 214/400 [1:31:17<1:16:33, 24.70s/it]2022-01-13 21:05:47,575 iteration 3639 : loss : 0.041936, loss_ce: 0.022049
2022-01-13 21:05:48,983 iteration 3640 : loss : 0.033628, loss_ce: 0.012863
2022-01-13 21:05:50,358 iteration 3641 : loss : 0.044565, loss_ce: 0.015124
2022-01-13 21:05:51,770 iteration 3642 : loss : 0.034213, loss_ce: 0.015168
2022-01-13 21:05:53,133 iteration 3643 : loss : 0.033404, loss_ce: 0.016327
2022-01-13 21:05:54,488 iteration 3644 : loss : 0.028404, loss_ce: 0.013632
2022-01-13 21:05:55,818 iteration 3645 : loss : 0.031857, loss_ce: 0.014035
2022-01-13 21:05:57,194 iteration 3646 : loss : 0.023004, loss_ce: 0.008457
2022-01-13 21:05:58,603 iteration 3647 : loss : 0.028718, loss_ce: 0.011990
2022-01-13 21:06:00,078 iteration 3648 : loss : 0.040093, loss_ce: 0.017620
2022-01-13 21:06:01,471 iteration 3649 : loss : 0.042382, loss_ce: 0.014895
2022-01-13 21:06:02,841 iteration 3650 : loss : 0.032630, loss_ce: 0.010688
2022-01-13 21:06:04,238 iteration 3651 : loss : 0.028860, loss_ce: 0.010632
2022-01-13 21:06:05,580 iteration 3652 : loss : 0.023019, loss_ce: 0.009718
2022-01-13 21:06:07,015 iteration 3653 : loss : 0.031572, loss_ce: 0.007933
2022-01-13 21:06:08,394 iteration 3654 : loss : 0.035297, loss_ce: 0.013996
2022-01-13 21:06:08,394 Training Data Eval:
2022-01-13 21:06:15,176   Average segmentation loss on training set: 0.0181
2022-01-13 21:06:15,177 Validation Data Eval:
2022-01-13 21:06:17,511   Average segmentation loss on validation set: 0.1082
2022-01-13 21:06:18,789 iteration 3655 : loss : 0.026191, loss_ce: 0.010001
 54%|██████████████▌            | 215/400 [1:31:50<1:23:28, 27.07s/it]2022-01-13 21:06:20,272 iteration 3656 : loss : 0.049222, loss_ce: 0.007803
2022-01-13 21:06:21,612 iteration 3657 : loss : 0.027790, loss_ce: 0.014381
2022-01-13 21:06:22,988 iteration 3658 : loss : 0.023762, loss_ce: 0.010279
2022-01-13 21:06:24,396 iteration 3659 : loss : 0.029060, loss_ce: 0.010165
2022-01-13 21:06:25,864 iteration 3660 : loss : 0.050530, loss_ce: 0.018127
2022-01-13 21:06:27,345 iteration 3661 : loss : 0.032083, loss_ce: 0.014464
2022-01-13 21:06:28,638 iteration 3662 : loss : 0.022652, loss_ce: 0.008150
2022-01-13 21:06:29,977 iteration 3663 : loss : 0.018600, loss_ce: 0.006144
2022-01-13 21:06:31,322 iteration 3664 : loss : 0.045132, loss_ce: 0.014120
2022-01-13 21:06:32,682 iteration 3665 : loss : 0.024069, loss_ce: 0.010762
2022-01-13 21:06:34,159 iteration 3666 : loss : 0.046696, loss_ce: 0.021821
2022-01-13 21:06:35,575 iteration 3667 : loss : 0.047471, loss_ce: 0.018381
2022-01-13 21:06:36,997 iteration 3668 : loss : 0.037782, loss_ce: 0.014580
2022-01-13 21:06:38,379 iteration 3669 : loss : 0.029686, loss_ce: 0.015030
2022-01-13 21:06:39,725 iteration 3670 : loss : 0.045778, loss_ce: 0.016079
2022-01-13 21:06:41,138 iteration 3671 : loss : 0.036824, loss_ce: 0.017850
2022-01-13 21:06:42,466 iteration 3672 : loss : 0.026181, loss_ce: 0.010490
 54%|██████████████▌            | 216/400 [1:32:14<1:19:54, 26.05s/it]2022-01-13 21:06:43,882 iteration 3673 : loss : 0.025196, loss_ce: 0.013541
2022-01-13 21:06:45,285 iteration 3674 : loss : 0.032930, loss_ce: 0.015735
2022-01-13 21:06:46,638 iteration 3675 : loss : 0.025652, loss_ce: 0.015439
2022-01-13 21:06:47,985 iteration 3676 : loss : 0.023361, loss_ce: 0.008438
2022-01-13 21:06:49,336 iteration 3677 : loss : 0.027342, loss_ce: 0.014207
2022-01-13 21:06:50,784 iteration 3678 : loss : 0.043191, loss_ce: 0.016565
2022-01-13 21:06:52,143 iteration 3679 : loss : 0.028700, loss_ce: 0.011538
2022-01-13 21:06:53,485 iteration 3680 : loss : 0.041820, loss_ce: 0.015269
2022-01-13 21:06:54,905 iteration 3681 : loss : 0.039783, loss_ce: 0.013988
2022-01-13 21:06:56,255 iteration 3682 : loss : 0.030350, loss_ce: 0.013329
2022-01-13 21:06:57,667 iteration 3683 : loss : 0.085627, loss_ce: 0.010317
2022-01-13 21:06:59,007 iteration 3684 : loss : 0.014365, loss_ce: 0.004641
2022-01-13 21:07:00,355 iteration 3685 : loss : 0.032688, loss_ce: 0.013480
2022-01-13 21:07:01,747 iteration 3686 : loss : 0.030264, loss_ce: 0.011249
2022-01-13 21:07:03,119 iteration 3687 : loss : 0.030912, loss_ce: 0.009567
2022-01-13 21:07:04,482 iteration 3688 : loss : 0.052078, loss_ce: 0.027713
2022-01-13 21:07:05,784 iteration 3689 : loss : 0.028604, loss_ce: 0.010483
 54%|██████████████▋            | 217/400 [1:32:37<1:16:58, 25.24s/it]2022-01-13 21:07:07,166 iteration 3690 : loss : 0.021315, loss_ce: 0.005314
2022-01-13 21:07:08,611 iteration 3691 : loss : 0.069561, loss_ce: 0.014521
2022-01-13 21:07:09,986 iteration 3692 : loss : 0.029654, loss_ce: 0.013763
2022-01-13 21:07:11,436 iteration 3693 : loss : 0.051657, loss_ce: 0.021569
2022-01-13 21:07:12,818 iteration 3694 : loss : 0.021766, loss_ce: 0.010105
2022-01-13 21:07:14,153 iteration 3695 : loss : 0.023533, loss_ce: 0.009952
2022-01-13 21:07:15,567 iteration 3696 : loss : 0.033933, loss_ce: 0.016942
2022-01-13 21:07:16,921 iteration 3697 : loss : 0.055793, loss_ce: 0.017988
2022-01-13 21:07:18,287 iteration 3698 : loss : 0.039090, loss_ce: 0.015023
2022-01-13 21:07:19,724 iteration 3699 : loss : 0.045245, loss_ce: 0.017045
2022-01-13 21:07:21,104 iteration 3700 : loss : 0.025878, loss_ce: 0.011281
2022-01-13 21:07:22,448 iteration 3701 : loss : 0.035264, loss_ce: 0.015040
2022-01-13 21:07:23,789 iteration 3702 : loss : 0.040729, loss_ce: 0.017572
2022-01-13 21:07:25,263 iteration 3703 : loss : 0.041656, loss_ce: 0.025978
2022-01-13 21:07:26,595 iteration 3704 : loss : 0.026268, loss_ce: 0.008715
2022-01-13 21:07:27,916 iteration 3705 : loss : 0.021188, loss_ce: 0.007178
2022-01-13 21:07:29,233 iteration 3706 : loss : 0.019435, loss_ce: 0.006026
 55%|██████████████▋            | 218/400 [1:33:00<1:14:54, 24.70s/it]2022-01-13 21:07:30,649 iteration 3707 : loss : 0.046111, loss_ce: 0.016393
2022-01-13 21:07:32,019 iteration 3708 : loss : 0.030277, loss_ce: 0.011430
2022-01-13 21:07:33,392 iteration 3709 : loss : 0.024784, loss_ce: 0.008130
2022-01-13 21:07:34,813 iteration 3710 : loss : 0.038052, loss_ce: 0.013574
2022-01-13 21:07:36,162 iteration 3711 : loss : 0.023765, loss_ce: 0.009278
2022-01-13 21:07:37,555 iteration 3712 : loss : 0.041907, loss_ce: 0.016447
2022-01-13 21:07:38,879 iteration 3713 : loss : 0.026002, loss_ce: 0.009906
2022-01-13 21:07:40,253 iteration 3714 : loss : 0.030794, loss_ce: 0.010677
2022-01-13 21:07:41,628 iteration 3715 : loss : 0.033392, loss_ce: 0.013414
2022-01-13 21:07:42,963 iteration 3716 : loss : 0.034251, loss_ce: 0.011448
2022-01-13 21:07:44,364 iteration 3717 : loss : 0.039528, loss_ce: 0.014991
2022-01-13 21:07:45,786 iteration 3718 : loss : 0.029745, loss_ce: 0.014287
2022-01-13 21:07:47,101 iteration 3719 : loss : 0.021815, loss_ce: 0.006352
2022-01-13 21:07:48,512 iteration 3720 : loss : 0.025002, loss_ce: 0.012380
2022-01-13 21:07:49,886 iteration 3721 : loss : 0.030699, loss_ce: 0.012992
2022-01-13 21:07:51,239 iteration 3722 : loss : 0.020817, loss_ce: 0.008272
2022-01-13 21:07:52,587 iteration 3723 : loss : 0.031620, loss_ce: 0.009920
 55%|██████████████▊            | 219/400 [1:33:24<1:13:17, 24.29s/it]2022-01-13 21:07:53,941 iteration 3724 : loss : 0.030822, loss_ce: 0.016083
2022-01-13 21:07:55,270 iteration 3725 : loss : 0.030162, loss_ce: 0.013029
2022-01-13 21:07:56,707 iteration 3726 : loss : 0.029253, loss_ce: 0.015048
2022-01-13 21:07:58,087 iteration 3727 : loss : 0.025438, loss_ce: 0.010973
2022-01-13 21:07:59,470 iteration 3728 : loss : 0.035167, loss_ce: 0.009827
2022-01-13 21:08:00,800 iteration 3729 : loss : 0.020902, loss_ce: 0.005751
2022-01-13 21:08:02,156 iteration 3730 : loss : 0.025648, loss_ce: 0.010519
2022-01-13 21:08:03,522 iteration 3731 : loss : 0.028712, loss_ce: 0.011295
2022-01-13 21:08:04,918 iteration 3732 : loss : 0.030988, loss_ce: 0.010799
2022-01-13 21:08:06,252 iteration 3733 : loss : 0.027717, loss_ce: 0.010904
2022-01-13 21:08:07,635 iteration 3734 : loss : 0.030875, loss_ce: 0.013199
2022-01-13 21:08:09,010 iteration 3735 : loss : 0.036634, loss_ce: 0.011731
2022-01-13 21:08:10,432 iteration 3736 : loss : 0.033773, loss_ce: 0.017336
2022-01-13 21:08:11,797 iteration 3737 : loss : 0.024699, loss_ce: 0.008887
2022-01-13 21:08:13,159 iteration 3738 : loss : 0.021230, loss_ce: 0.007868
2022-01-13 21:08:14,480 iteration 3739 : loss : 0.024187, loss_ce: 0.009842
2022-01-13 21:08:14,480 Training Data Eval:
2022-01-13 21:08:21,282   Average segmentation loss on training set: 0.0216
2022-01-13 21:08:21,282 Validation Data Eval:
2022-01-13 21:08:23,620   Average segmentation loss on validation set: 0.0712
2022-01-13 21:08:25,139 iteration 3740 : loss : 0.042803, loss_ce: 0.019322
 55%|██████████████▊            | 220/400 [1:33:56<1:20:18, 26.77s/it]2022-01-13 21:08:26,684 iteration 3741 : loss : 0.043336, loss_ce: 0.013670
2022-01-13 21:08:28,048 iteration 3742 : loss : 0.030289, loss_ce: 0.015319
2022-01-13 21:08:29,414 iteration 3743 : loss : 0.027443, loss_ce: 0.010702
2022-01-13 21:08:30,826 iteration 3744 : loss : 0.038054, loss_ce: 0.014321
2022-01-13 21:08:32,263 iteration 3745 : loss : 0.028613, loss_ce: 0.008999
2022-01-13 21:08:33,707 iteration 3746 : loss : 0.051634, loss_ce: 0.023150
2022-01-13 21:08:35,073 iteration 3747 : loss : 0.025990, loss_ce: 0.008162
2022-01-13 21:08:36,417 iteration 3748 : loss : 0.022390, loss_ce: 0.011700
2022-01-13 21:08:37,834 iteration 3749 : loss : 0.053710, loss_ce: 0.022480
2022-01-13 21:08:39,284 iteration 3750 : loss : 0.041580, loss_ce: 0.012902
2022-01-13 21:08:40,683 iteration 3751 : loss : 0.044872, loss_ce: 0.014622
2022-01-13 21:08:42,041 iteration 3752 : loss : 0.032902, loss_ce: 0.008753
2022-01-13 21:08:43,378 iteration 3753 : loss : 0.031489, loss_ce: 0.009287
2022-01-13 21:08:44,761 iteration 3754 : loss : 0.028030, loss_ce: 0.009362
2022-01-13 21:08:46,193 iteration 3755 : loss : 0.032222, loss_ce: 0.015467
2022-01-13 21:08:47,509 iteration 3756 : loss : 0.024429, loss_ce: 0.010635
2022-01-13 21:08:48,841 iteration 3757 : loss : 0.026694, loss_ce: 0.011411
 55%|██████████████▉            | 221/400 [1:34:20<1:17:07, 25.85s/it]2022-01-13 21:08:50,381 iteration 3758 : loss : 0.021221, loss_ce: 0.006730
2022-01-13 21:08:51,736 iteration 3759 : loss : 0.023823, loss_ce: 0.007515
2022-01-13 21:08:53,104 iteration 3760 : loss : 0.022475, loss_ce: 0.009550
2022-01-13 21:08:54,552 iteration 3761 : loss : 0.023538, loss_ce: 0.009660
2022-01-13 21:08:56,012 iteration 3762 : loss : 0.026740, loss_ce: 0.013496
2022-01-13 21:08:57,514 iteration 3763 : loss : 0.035159, loss_ce: 0.011480
2022-01-13 21:08:58,904 iteration 3764 : loss : 0.035447, loss_ce: 0.013169
2022-01-13 21:09:00,260 iteration 3765 : loss : 0.026235, loss_ce: 0.011004
2022-01-13 21:09:01,700 iteration 3766 : loss : 0.032653, loss_ce: 0.011291
2022-01-13 21:09:03,087 iteration 3767 : loss : 0.023075, loss_ce: 0.007872
2022-01-13 21:09:04,438 iteration 3768 : loss : 0.031023, loss_ce: 0.010339
2022-01-13 21:09:05,819 iteration 3769 : loss : 0.023886, loss_ce: 0.010854
2022-01-13 21:09:07,246 iteration 3770 : loss : 0.039618, loss_ce: 0.007362
2022-01-13 21:09:08,766 iteration 3771 : loss : 0.032176, loss_ce: 0.012412
2022-01-13 21:09:10,209 iteration 3772 : loss : 0.029063, loss_ce: 0.008094
2022-01-13 21:09:11,606 iteration 3773 : loss : 0.020536, loss_ce: 0.008186
2022-01-13 21:09:13,073 iteration 3774 : loss : 0.046931, loss_ce: 0.022325
 56%|██████████████▉            | 222/400 [1:34:44<1:15:14, 25.36s/it]2022-01-13 21:09:14,483 iteration 3775 : loss : 0.035542, loss_ce: 0.015332
2022-01-13 21:09:15,781 iteration 3776 : loss : 0.028700, loss_ce: 0.011929
2022-01-13 21:09:17,158 iteration 3777 : loss : 0.025668, loss_ce: 0.006787
2022-01-13 21:09:18,491 iteration 3778 : loss : 0.021581, loss_ce: 0.008662
2022-01-13 21:09:19,818 iteration 3779 : loss : 0.027256, loss_ce: 0.012523
2022-01-13 21:09:21,211 iteration 3780 : loss : 0.028006, loss_ce: 0.010563
2022-01-13 21:09:22,586 iteration 3781 : loss : 0.040045, loss_ce: 0.019029
2022-01-13 21:09:23,983 iteration 3782 : loss : 0.081532, loss_ce: 0.014065
2022-01-13 21:09:25,387 iteration 3783 : loss : 0.026026, loss_ce: 0.012558
2022-01-13 21:09:26,788 iteration 3784 : loss : 0.023104, loss_ce: 0.010857
2022-01-13 21:09:28,132 iteration 3785 : loss : 0.025166, loss_ce: 0.011030
2022-01-13 21:09:29,473 iteration 3786 : loss : 0.018738, loss_ce: 0.007274
2022-01-13 21:09:30,805 iteration 3787 : loss : 0.024827, loss_ce: 0.008614
2022-01-13 21:09:32,243 iteration 3788 : loss : 0.042368, loss_ce: 0.010716
2022-01-13 21:09:33,611 iteration 3789 : loss : 0.031639, loss_ce: 0.010909
2022-01-13 21:09:35,013 iteration 3790 : loss : 0.036835, loss_ce: 0.014117
2022-01-13 21:09:36,410 iteration 3791 : loss : 0.024151, loss_ce: 0.009720
 56%|███████████████            | 223/400 [1:35:08<1:13:02, 24.76s/it]2022-01-13 21:09:37,801 iteration 3792 : loss : 0.025589, loss_ce: 0.008560
2022-01-13 21:09:39,221 iteration 3793 : loss : 0.031634, loss_ce: 0.010047
2022-01-13 21:09:40,615 iteration 3794 : loss : 0.031761, loss_ce: 0.011323
2022-01-13 21:09:41,989 iteration 3795 : loss : 0.025567, loss_ce: 0.008746
2022-01-13 21:09:43,274 iteration 3796 : loss : 0.023869, loss_ce: 0.007850
2022-01-13 21:09:44,618 iteration 3797 : loss : 0.027471, loss_ce: 0.011250
2022-01-13 21:09:45,921 iteration 3798 : loss : 0.023400, loss_ce: 0.008701
2022-01-13 21:09:47,272 iteration 3799 : loss : 0.024890, loss_ce: 0.008377
2022-01-13 21:09:48,619 iteration 3800 : loss : 0.036517, loss_ce: 0.012633
2022-01-13 21:09:49,969 iteration 3801 : loss : 0.037636, loss_ce: 0.009225
2022-01-13 21:09:51,306 iteration 3802 : loss : 0.026083, loss_ce: 0.012428
2022-01-13 21:09:52,664 iteration 3803 : loss : 0.018291, loss_ce: 0.006236
2022-01-13 21:09:54,024 iteration 3804 : loss : 0.029776, loss_ce: 0.012726
2022-01-13 21:09:55,362 iteration 3805 : loss : 0.025841, loss_ce: 0.010581
2022-01-13 21:09:56,701 iteration 3806 : loss : 0.033599, loss_ce: 0.018224
2022-01-13 21:09:58,103 iteration 3807 : loss : 0.028041, loss_ce: 0.010784
2022-01-13 21:09:59,480 iteration 3808 : loss : 0.027404, loss_ce: 0.011260
 56%|███████████████            | 224/400 [1:35:31<1:11:08, 24.25s/it]2022-01-13 21:10:00,843 iteration 3809 : loss : 0.021697, loss_ce: 0.007525
2022-01-13 21:10:02,185 iteration 3810 : loss : 0.022309, loss_ce: 0.008797
2022-01-13 21:10:03,545 iteration 3811 : loss : 0.038517, loss_ce: 0.015263
2022-01-13 21:10:04,920 iteration 3812 : loss : 0.035122, loss_ce: 0.016079
2022-01-13 21:10:06,269 iteration 3813 : loss : 0.026803, loss_ce: 0.013918
2022-01-13 21:10:07,672 iteration 3814 : loss : 0.037014, loss_ce: 0.012585
2022-01-13 21:10:09,039 iteration 3815 : loss : 0.026952, loss_ce: 0.010907
2022-01-13 21:10:10,420 iteration 3816 : loss : 0.023240, loss_ce: 0.008787
2022-01-13 21:10:11,757 iteration 3817 : loss : 0.022142, loss_ce: 0.008785
2022-01-13 21:10:13,150 iteration 3818 : loss : 0.021967, loss_ce: 0.010694
2022-01-13 21:10:14,568 iteration 3819 : loss : 0.027462, loss_ce: 0.012945
2022-01-13 21:10:15,986 iteration 3820 : loss : 0.031117, loss_ce: 0.011062
2022-01-13 21:10:17,384 iteration 3821 : loss : 0.031634, loss_ce: 0.013330
2022-01-13 21:10:18,719 iteration 3822 : loss : 0.030951, loss_ce: 0.009503
2022-01-13 21:10:20,192 iteration 3823 : loss : 0.035785, loss_ce: 0.009062
2022-01-13 21:10:21,569 iteration 3824 : loss : 0.027922, loss_ce: 0.009465
2022-01-13 21:10:21,569 Training Data Eval:
2022-01-13 21:10:28,334   Average segmentation loss on training set: 0.0165
2022-01-13 21:10:28,334 Validation Data Eval:
2022-01-13 21:10:30,677   Average segmentation loss on validation set: 0.0709
2022-01-13 21:10:36,359 Found new lowest validation loss at iteration 3824! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 21:10:37,865 iteration 3825 : loss : 0.029325, loss_ce: 0.011149
 56%|███████████████▏           | 225/400 [1:36:09<1:23:05, 28.49s/it]2022-01-13 21:10:39,300 iteration 3826 : loss : 0.034375, loss_ce: 0.016392
2022-01-13 21:10:40,632 iteration 3827 : loss : 0.025910, loss_ce: 0.009027
2022-01-13 21:10:42,016 iteration 3828 : loss : 0.029578, loss_ce: 0.011633
2022-01-13 21:10:43,385 iteration 3829 : loss : 0.022833, loss_ce: 0.006891
2022-01-13 21:10:44,718 iteration 3830 : loss : 0.021253, loss_ce: 0.007643
2022-01-13 21:10:46,040 iteration 3831 : loss : 0.022097, loss_ce: 0.008121
2022-01-13 21:10:47,353 iteration 3832 : loss : 0.024414, loss_ce: 0.006280
2022-01-13 21:10:48,714 iteration 3833 : loss : 0.021818, loss_ce: 0.009730
2022-01-13 21:10:50,113 iteration 3834 : loss : 0.034438, loss_ce: 0.016363
2022-01-13 21:10:51,498 iteration 3835 : loss : 0.026877, loss_ce: 0.009819
2022-01-13 21:10:52,870 iteration 3836 : loss : 0.023135, loss_ce: 0.009600
2022-01-13 21:10:54,263 iteration 3837 : loss : 0.026513, loss_ce: 0.009642
2022-01-13 21:10:55,723 iteration 3838 : loss : 0.034619, loss_ce: 0.013671
2022-01-13 21:10:57,088 iteration 3839 : loss : 0.021101, loss_ce: 0.009063
2022-01-13 21:10:58,469 iteration 3840 : loss : 0.036710, loss_ce: 0.010204
2022-01-13 21:10:59,807 iteration 3841 : loss : 0.043699, loss_ce: 0.013646
2022-01-13 21:11:01,199 iteration 3842 : loss : 0.034175, loss_ce: 0.015472
 56%|███████████████▎           | 226/400 [1:36:32<1:18:08, 26.94s/it]2022-01-13 21:11:02,583 iteration 3843 : loss : 0.024558, loss_ce: 0.009861
2022-01-13 21:11:04,020 iteration 3844 : loss : 0.029199, loss_ce: 0.008876
2022-01-13 21:11:05,422 iteration 3845 : loss : 0.022249, loss_ce: 0.011310
2022-01-13 21:11:06,751 iteration 3846 : loss : 0.018858, loss_ce: 0.006973
2022-01-13 21:11:08,101 iteration 3847 : loss : 0.024391, loss_ce: 0.009178
2022-01-13 21:11:09,513 iteration 3848 : loss : 0.025606, loss_ce: 0.013173
2022-01-13 21:11:10,989 iteration 3849 : loss : 0.027556, loss_ce: 0.012044
2022-01-13 21:11:12,445 iteration 3850 : loss : 0.064253, loss_ce: 0.016802
2022-01-13 21:11:13,832 iteration 3851 : loss : 0.021822, loss_ce: 0.010707
2022-01-13 21:11:15,224 iteration 3852 : loss : 0.026797, loss_ce: 0.007987
2022-01-13 21:11:16,555 iteration 3853 : loss : 0.022051, loss_ce: 0.006448
2022-01-13 21:11:17,953 iteration 3854 : loss : 0.030755, loss_ce: 0.010284
2022-01-13 21:11:19,459 iteration 3855 : loss : 0.030790, loss_ce: 0.011426
2022-01-13 21:11:20,711 iteration 3856 : loss : 0.022623, loss_ce: 0.010428
2022-01-13 21:11:22,063 iteration 3857 : loss : 0.032447, loss_ce: 0.015999
2022-01-13 21:11:23,341 iteration 3858 : loss : 0.031634, loss_ce: 0.012860
2022-01-13 21:11:24,701 iteration 3859 : loss : 0.030124, loss_ce: 0.013407
 57%|███████████████▎           | 227/400 [1:36:56<1:14:42, 25.91s/it]2022-01-13 21:11:26,127 iteration 3860 : loss : 0.023843, loss_ce: 0.008805
2022-01-13 21:11:27,586 iteration 3861 : loss : 0.051209, loss_ce: 0.022771
2022-01-13 21:11:28,985 iteration 3862 : loss : 0.037242, loss_ce: 0.015531
2022-01-13 21:11:30,378 iteration 3863 : loss : 0.034330, loss_ce: 0.013642
2022-01-13 21:11:31,821 iteration 3864 : loss : 0.043229, loss_ce: 0.017951
2022-01-13 21:11:33,188 iteration 3865 : loss : 0.035566, loss_ce: 0.012105
2022-01-13 21:11:34,665 iteration 3866 : loss : 0.033067, loss_ce: 0.011722
2022-01-13 21:11:36,026 iteration 3867 : loss : 0.033528, loss_ce: 0.012055
2022-01-13 21:11:37,450 iteration 3868 : loss : 0.063254, loss_ce: 0.021197
2022-01-13 21:11:38,855 iteration 3869 : loss : 0.030503, loss_ce: 0.015093
2022-01-13 21:11:40,285 iteration 3870 : loss : 0.041879, loss_ce: 0.014220
2022-01-13 21:11:41,688 iteration 3871 : loss : 0.042245, loss_ce: 0.013219
2022-01-13 21:11:43,028 iteration 3872 : loss : 0.033809, loss_ce: 0.012765
2022-01-13 21:11:44,374 iteration 3873 : loss : 0.032798, loss_ce: 0.016879
2022-01-13 21:11:45,765 iteration 3874 : loss : 0.030194, loss_ce: 0.011842
2022-01-13 21:11:47,163 iteration 3875 : loss : 0.036004, loss_ce: 0.013886
2022-01-13 21:11:48,579 iteration 3876 : loss : 0.032345, loss_ce: 0.011100
 57%|███████████████▍           | 228/400 [1:37:20<1:12:32, 25.30s/it]2022-01-13 21:11:50,006 iteration 3877 : loss : 0.038447, loss_ce: 0.014624
2022-01-13 21:11:51,407 iteration 3878 : loss : 0.035419, loss_ce: 0.013301
2022-01-13 21:11:52,773 iteration 3879 : loss : 0.025370, loss_ce: 0.010018
2022-01-13 21:11:54,182 iteration 3880 : loss : 0.024271, loss_ce: 0.010695
2022-01-13 21:11:55,574 iteration 3881 : loss : 0.027312, loss_ce: 0.011907
2022-01-13 21:11:57,041 iteration 3882 : loss : 0.068372, loss_ce: 0.019648
2022-01-13 21:11:58,477 iteration 3883 : loss : 0.059177, loss_ce: 0.019365
2022-01-13 21:11:59,878 iteration 3884 : loss : 0.036739, loss_ce: 0.017009
2022-01-13 21:12:01,300 iteration 3885 : loss : 0.073539, loss_ce: 0.014987
2022-01-13 21:12:02,728 iteration 3886 : loss : 0.043356, loss_ce: 0.016715
2022-01-13 21:12:04,062 iteration 3887 : loss : 0.026146, loss_ce: 0.012093
2022-01-13 21:12:05,481 iteration 3888 : loss : 0.047934, loss_ce: 0.026804
2022-01-13 21:12:06,906 iteration 3889 : loss : 0.027274, loss_ce: 0.010448
2022-01-13 21:12:08,392 iteration 3890 : loss : 0.038135, loss_ce: 0.011585
2022-01-13 21:12:09,752 iteration 3891 : loss : 0.041898, loss_ce: 0.018172
2022-01-13 21:12:11,139 iteration 3892 : loss : 0.043076, loss_ce: 0.019821
2022-01-13 21:12:12,552 iteration 3893 : loss : 0.063872, loss_ce: 0.022868
 57%|███████████████▍           | 229/400 [1:37:44<1:10:58, 24.90s/it]2022-01-13 21:12:13,969 iteration 3894 : loss : 0.029866, loss_ce: 0.010995
2022-01-13 21:12:15,308 iteration 3895 : loss : 0.027459, loss_ce: 0.010266
2022-01-13 21:12:16,686 iteration 3896 : loss : 0.041518, loss_ce: 0.017687
2022-01-13 21:12:18,105 iteration 3897 : loss : 0.033835, loss_ce: 0.014530
2022-01-13 21:12:19,543 iteration 3898 : loss : 0.045207, loss_ce: 0.014285
2022-01-13 21:12:20,854 iteration 3899 : loss : 0.036696, loss_ce: 0.015071
2022-01-13 21:12:22,196 iteration 3900 : loss : 0.040640, loss_ce: 0.014368
2022-01-13 21:12:23,523 iteration 3901 : loss : 0.035613, loss_ce: 0.014437
2022-01-13 21:12:24,853 iteration 3902 : loss : 0.035494, loss_ce: 0.015335
2022-01-13 21:12:26,152 iteration 3903 : loss : 0.032356, loss_ce: 0.010612
2022-01-13 21:12:27,502 iteration 3904 : loss : 0.031902, loss_ce: 0.010418
2022-01-13 21:12:28,858 iteration 3905 : loss : 0.045355, loss_ce: 0.015038
2022-01-13 21:12:30,146 iteration 3906 : loss : 0.025809, loss_ce: 0.009804
2022-01-13 21:12:31,419 iteration 3907 : loss : 0.021535, loss_ce: 0.008111
2022-01-13 21:12:32,717 iteration 3908 : loss : 0.023487, loss_ce: 0.009239
2022-01-13 21:12:34,073 iteration 3909 : loss : 0.034646, loss_ce: 0.018667
2022-01-13 21:12:34,073 Training Data Eval:
2022-01-13 21:12:40,886   Average segmentation loss on training set: 0.0177
2022-01-13 21:12:40,886 Validation Data Eval:
2022-01-13 21:12:43,224   Average segmentation loss on validation set: 0.0792
2022-01-13 21:12:44,650 iteration 3910 : loss : 0.028456, loss_ce: 0.010045
 57%|███████████████▌           | 230/400 [1:38:16<1:16:40, 27.06s/it]2022-01-13 21:12:46,028 iteration 3911 : loss : 0.024391, loss_ce: 0.009656
2022-01-13 21:12:47,429 iteration 3912 : loss : 0.043184, loss_ce: 0.014119
2022-01-13 21:12:48,791 iteration 3913 : loss : 0.030521, loss_ce: 0.010713
2022-01-13 21:12:50,160 iteration 3914 : loss : 0.020123, loss_ce: 0.009566
2022-01-13 21:12:51,516 iteration 3915 : loss : 0.028823, loss_ce: 0.012606
2022-01-13 21:12:52,839 iteration 3916 : loss : 0.019008, loss_ce: 0.007048
2022-01-13 21:12:54,237 iteration 3917 : loss : 0.045304, loss_ce: 0.019357
2022-01-13 21:12:55,636 iteration 3918 : loss : 0.045026, loss_ce: 0.012443
2022-01-13 21:12:57,130 iteration 3919 : loss : 0.045245, loss_ce: 0.012994
2022-01-13 21:12:58,460 iteration 3920 : loss : 0.024045, loss_ce: 0.010386
2022-01-13 21:12:59,824 iteration 3921 : loss : 0.030644, loss_ce: 0.012512
2022-01-13 21:13:01,232 iteration 3922 : loss : 0.028861, loss_ce: 0.011030
2022-01-13 21:13:02,582 iteration 3923 : loss : 0.023169, loss_ce: 0.011436
2022-01-13 21:13:03,901 iteration 3924 : loss : 0.025997, loss_ce: 0.007052
2022-01-13 21:13:05,342 iteration 3925 : loss : 0.044915, loss_ce: 0.018387
2022-01-13 21:13:06,759 iteration 3926 : loss : 0.023405, loss_ce: 0.007999
2022-01-13 21:13:08,125 iteration 3927 : loss : 0.029365, loss_ce: 0.010916
 58%|███████████████▌           | 231/400 [1:38:39<1:13:11, 25.99s/it]2022-01-13 21:13:09,606 iteration 3928 : loss : 0.045422, loss_ce: 0.025090
2022-01-13 21:13:10,985 iteration 3929 : loss : 0.042935, loss_ce: 0.021059
2022-01-13 21:13:12,413 iteration 3930 : loss : 0.030007, loss_ce: 0.011132
2022-01-13 21:13:13,831 iteration 3931 : loss : 0.025982, loss_ce: 0.010744
2022-01-13 21:13:15,277 iteration 3932 : loss : 0.037422, loss_ce: 0.012506
2022-01-13 21:13:16,732 iteration 3933 : loss : 0.025046, loss_ce: 0.010152
2022-01-13 21:13:18,137 iteration 3934 : loss : 0.023017, loss_ce: 0.009168
2022-01-13 21:13:19,455 iteration 3935 : loss : 0.023260, loss_ce: 0.009508
2022-01-13 21:13:20,989 iteration 3936 : loss : 0.033220, loss_ce: 0.015741
2022-01-13 21:13:22,339 iteration 3937 : loss : 0.027652, loss_ce: 0.012555
2022-01-13 21:13:23,790 iteration 3938 : loss : 0.082363, loss_ce: 0.013633
2022-01-13 21:13:25,091 iteration 3939 : loss : 0.029971, loss_ce: 0.008383
2022-01-13 21:13:26,434 iteration 3940 : loss : 0.026445, loss_ce: 0.009592
2022-01-13 21:13:27,804 iteration 3941 : loss : 0.031756, loss_ce: 0.014639
2022-01-13 21:13:29,231 iteration 3942 : loss : 0.039106, loss_ce: 0.016941
2022-01-13 21:13:30,571 iteration 3943 : loss : 0.063117, loss_ce: 0.012917
2022-01-13 21:13:32,007 iteration 3944 : loss : 0.045362, loss_ce: 0.017130
 58%|███████████████▋           | 232/400 [1:39:03<1:10:59, 25.35s/it]2022-01-13 21:13:33,451 iteration 3945 : loss : 0.027121, loss_ce: 0.012386
2022-01-13 21:13:34,733 iteration 3946 : loss : 0.020527, loss_ce: 0.010411
2022-01-13 21:13:36,089 iteration 3947 : loss : 0.025728, loss_ce: 0.007307
2022-01-13 21:13:37,583 iteration 3948 : loss : 0.033325, loss_ce: 0.011443
2022-01-13 21:13:39,002 iteration 3949 : loss : 0.034433, loss_ce: 0.014189
2022-01-13 21:13:40,440 iteration 3950 : loss : 0.036499, loss_ce: 0.013937
2022-01-13 21:13:41,760 iteration 3951 : loss : 0.024014, loss_ce: 0.010210
2022-01-13 21:13:43,191 iteration 3952 : loss : 0.028210, loss_ce: 0.011694
2022-01-13 21:13:44,625 iteration 3953 : loss : 0.047341, loss_ce: 0.019110
2022-01-13 21:13:45,990 iteration 3954 : loss : 0.036161, loss_ce: 0.013120
2022-01-13 21:13:47,348 iteration 3955 : loss : 0.029526, loss_ce: 0.012939
2022-01-13 21:13:48,843 iteration 3956 : loss : 0.038414, loss_ce: 0.016491
2022-01-13 21:13:50,184 iteration 3957 : loss : 0.032266, loss_ce: 0.014272
2022-01-13 21:13:51,532 iteration 3958 : loss : 0.036152, loss_ce: 0.012773
2022-01-13 21:13:52,987 iteration 3959 : loss : 0.039374, loss_ce: 0.015171
2022-01-13 21:13:54,340 iteration 3960 : loss : 0.024136, loss_ce: 0.011241
2022-01-13 21:13:55,711 iteration 3961 : loss : 0.032570, loss_ce: 0.015621
 58%|███████████████▋           | 233/400 [1:39:27<1:09:11, 24.86s/it]2022-01-13 21:13:57,172 iteration 3962 : loss : 0.031961, loss_ce: 0.012469
2022-01-13 21:13:58,547 iteration 3963 : loss : 0.034192, loss_ce: 0.015487
2022-01-13 21:14:00,003 iteration 3964 : loss : 0.029411, loss_ce: 0.013441
2022-01-13 21:14:01,333 iteration 3965 : loss : 0.031802, loss_ce: 0.009420
2022-01-13 21:14:02,755 iteration 3966 : loss : 0.037111, loss_ce: 0.014803
2022-01-13 21:14:04,137 iteration 3967 : loss : 0.024297, loss_ce: 0.008769
2022-01-13 21:14:05,415 iteration 3968 : loss : 0.028963, loss_ce: 0.010643
2022-01-13 21:14:06,832 iteration 3969 : loss : 0.034608, loss_ce: 0.010385
2022-01-13 21:14:08,207 iteration 3970 : loss : 0.028493, loss_ce: 0.010167
2022-01-13 21:14:09,481 iteration 3971 : loss : 0.021906, loss_ce: 0.008942
2022-01-13 21:14:10,880 iteration 3972 : loss : 0.032866, loss_ce: 0.009295
2022-01-13 21:14:12,207 iteration 3973 : loss : 0.044930, loss_ce: 0.023891
2022-01-13 21:14:13,494 iteration 3974 : loss : 0.024331, loss_ce: 0.008494
2022-01-13 21:14:14,876 iteration 3975 : loss : 0.027171, loss_ce: 0.011135
2022-01-13 21:14:16,310 iteration 3976 : loss : 0.034481, loss_ce: 0.014454
2022-01-13 21:14:17,765 iteration 3977 : loss : 0.037990, loss_ce: 0.017749
2022-01-13 21:14:19,221 iteration 3978 : loss : 0.033532, loss_ce: 0.012115
 58%|███████████████▊           | 234/400 [1:39:50<1:07:39, 24.45s/it]2022-01-13 21:14:20,665 iteration 3979 : loss : 0.035522, loss_ce: 0.015015
2022-01-13 21:14:22,076 iteration 3980 : loss : 0.048225, loss_ce: 0.015538
2022-01-13 21:14:23,432 iteration 3981 : loss : 0.035124, loss_ce: 0.014808
2022-01-13 21:14:24,701 iteration 3982 : loss : 0.022941, loss_ce: 0.008365
2022-01-13 21:14:25,990 iteration 3983 : loss : 0.023831, loss_ce: 0.010934
2022-01-13 21:14:27,321 iteration 3984 : loss : 0.022059, loss_ce: 0.009090
2022-01-13 21:14:28,711 iteration 3985 : loss : 0.046121, loss_ce: 0.028766
2022-01-13 21:14:30,168 iteration 3986 : loss : 0.044830, loss_ce: 0.017981
2022-01-13 21:14:31,570 iteration 3987 : loss : 0.032185, loss_ce: 0.012898
2022-01-13 21:14:32,975 iteration 3988 : loss : 0.023961, loss_ce: 0.011370
2022-01-13 21:14:34,325 iteration 3989 : loss : 0.050815, loss_ce: 0.016695
2022-01-13 21:14:35,691 iteration 3990 : loss : 0.044545, loss_ce: 0.015650
2022-01-13 21:14:37,120 iteration 3991 : loss : 0.043210, loss_ce: 0.009401
2022-01-13 21:14:38,509 iteration 3992 : loss : 0.032704, loss_ce: 0.010501
2022-01-13 21:14:39,931 iteration 3993 : loss : 0.025278, loss_ce: 0.008475
2022-01-13 21:14:41,283 iteration 3994 : loss : 0.032748, loss_ce: 0.018601
2022-01-13 21:14:41,283 Training Data Eval:
2022-01-13 21:14:48,110   Average segmentation loss on training set: 0.0184
2022-01-13 21:14:48,110 Validation Data Eval:
2022-01-13 21:14:50,459   Average segmentation loss on validation set: 0.0850
2022-01-13 21:14:51,777 iteration 3995 : loss : 0.028928, loss_ce: 0.012608
 59%|███████████████▊           | 235/400 [1:40:23<1:13:56, 26.89s/it]2022-01-13 21:14:53,269 iteration 3996 : loss : 0.041917, loss_ce: 0.012483
2022-01-13 21:14:54,587 iteration 3997 : loss : 0.033144, loss_ce: 0.010641
2022-01-13 21:14:55,978 iteration 3998 : loss : 0.029248, loss_ce: 0.013896
2022-01-13 21:14:57,332 iteration 3999 : loss : 0.029178, loss_ce: 0.007769
2022-01-13 21:14:58,789 iteration 4000 : loss : 0.052190, loss_ce: 0.035517
2022-01-13 21:15:00,097 iteration 4001 : loss : 0.021352, loss_ce: 0.008765
2022-01-13 21:15:01,509 iteration 4002 : loss : 0.024854, loss_ce: 0.009245
2022-01-13 21:15:02,892 iteration 4003 : loss : 0.024446, loss_ce: 0.010221
2022-01-13 21:15:04,298 iteration 4004 : loss : 0.039652, loss_ce: 0.013864
2022-01-13 21:15:05,676 iteration 4005 : loss : 0.038242, loss_ce: 0.020084
2022-01-13 21:15:06,995 iteration 4006 : loss : 0.025119, loss_ce: 0.010746
2022-01-13 21:15:08,416 iteration 4007 : loss : 0.025941, loss_ce: 0.008723
2022-01-13 21:15:09,750 iteration 4008 : loss : 0.024225, loss_ce: 0.009302
2022-01-13 21:15:11,119 iteration 4009 : loss : 0.056165, loss_ce: 0.031063
2022-01-13 21:15:12,579 iteration 4010 : loss : 0.035959, loss_ce: 0.015643
2022-01-13 21:15:13,902 iteration 4011 : loss : 0.031716, loss_ce: 0.010556
2022-01-13 21:15:15,343 iteration 4012 : loss : 0.029223, loss_ce: 0.011831
 59%|███████████████▉           | 236/400 [1:40:47<1:10:46, 25.89s/it]2022-01-13 21:15:16,848 iteration 4013 : loss : 0.049060, loss_ce: 0.017175
2022-01-13 21:15:18,174 iteration 4014 : loss : 0.021935, loss_ce: 0.007252
2022-01-13 21:15:19,598 iteration 4015 : loss : 0.035711, loss_ce: 0.014260
2022-01-13 21:15:21,007 iteration 4016 : loss : 0.027392, loss_ce: 0.010874
2022-01-13 21:15:22,438 iteration 4017 : loss : 0.032569, loss_ce: 0.010432
2022-01-13 21:15:23,772 iteration 4018 : loss : 0.023527, loss_ce: 0.008900
2022-01-13 21:15:25,159 iteration 4019 : loss : 0.024553, loss_ce: 0.011992
2022-01-13 21:15:26,483 iteration 4020 : loss : 0.025159, loss_ce: 0.014362
2022-01-13 21:15:27,826 iteration 4021 : loss : 0.026697, loss_ce: 0.012090
2022-01-13 21:15:29,229 iteration 4022 : loss : 0.035393, loss_ce: 0.018154
2022-01-13 21:15:30,599 iteration 4023 : loss : 0.022104, loss_ce: 0.007972
2022-01-13 21:15:31,907 iteration 4024 : loss : 0.020809, loss_ce: 0.007770
2022-01-13 21:15:33,255 iteration 4025 : loss : 0.022038, loss_ce: 0.007862
2022-01-13 21:15:34,650 iteration 4026 : loss : 0.034394, loss_ce: 0.016259
2022-01-13 21:15:36,046 iteration 4027 : loss : 0.029357, loss_ce: 0.009010
2022-01-13 21:15:37,501 iteration 4028 : loss : 0.035562, loss_ce: 0.011178
2022-01-13 21:15:38,828 iteration 4029 : loss : 0.020781, loss_ce: 0.009108
 59%|███████████████▉           | 237/400 [1:41:10<1:08:22, 25.17s/it]2022-01-13 21:15:40,325 iteration 4030 : loss : 0.050738, loss_ce: 0.027624
2022-01-13 21:15:41,740 iteration 4031 : loss : 0.041162, loss_ce: 0.015387
2022-01-13 21:15:43,105 iteration 4032 : loss : 0.027394, loss_ce: 0.013128
2022-01-13 21:15:44,476 iteration 4033 : loss : 0.030326, loss_ce: 0.010365
2022-01-13 21:15:45,794 iteration 4034 : loss : 0.029355, loss_ce: 0.011553
2022-01-13 21:15:47,135 iteration 4035 : loss : 0.021301, loss_ce: 0.007480
2022-01-13 21:15:48,536 iteration 4036 : loss : 0.025205, loss_ce: 0.009038
2022-01-13 21:15:49,856 iteration 4037 : loss : 0.020791, loss_ce: 0.010228
2022-01-13 21:15:51,291 iteration 4038 : loss : 0.036713, loss_ce: 0.012748
2022-01-13 21:15:52,747 iteration 4039 : loss : 0.037862, loss_ce: 0.014470
2022-01-13 21:15:54,213 iteration 4040 : loss : 0.034386, loss_ce: 0.017495
2022-01-13 21:15:55,645 iteration 4041 : loss : 0.024169, loss_ce: 0.007593
2022-01-13 21:15:56,987 iteration 4042 : loss : 0.026374, loss_ce: 0.010044
2022-01-13 21:15:58,370 iteration 4043 : loss : 0.179964, loss_ce: 0.008588
2022-01-13 21:15:59,712 iteration 4044 : loss : 0.024743, loss_ce: 0.010512
2022-01-13 21:16:01,075 iteration 4045 : loss : 0.021854, loss_ce: 0.010977
2022-01-13 21:16:02,500 iteration 4046 : loss : 0.030664, loss_ce: 0.014254
 60%|████████████████           | 238/400 [1:41:34<1:06:44, 24.72s/it]2022-01-13 21:16:04,014 iteration 4047 : loss : 0.037100, loss_ce: 0.022311
2022-01-13 21:16:05,430 iteration 4048 : loss : 0.035581, loss_ce: 0.013868
2022-01-13 21:16:06,770 iteration 4049 : loss : 0.019904, loss_ce: 0.007530
2022-01-13 21:16:08,175 iteration 4050 : loss : 0.031071, loss_ce: 0.011292
2022-01-13 21:16:09,648 iteration 4051 : loss : 0.083487, loss_ce: 0.016727
2022-01-13 21:16:10,961 iteration 4052 : loss : 0.028515, loss_ce: 0.010701
2022-01-13 21:16:12,247 iteration 4053 : loss : 0.022705, loss_ce: 0.007923
2022-01-13 21:16:13,573 iteration 4054 : loss : 0.044028, loss_ce: 0.011549
2022-01-13 21:16:14,928 iteration 4055 : loss : 0.023676, loss_ce: 0.011127
2022-01-13 21:16:16,314 iteration 4056 : loss : 0.032735, loss_ce: 0.016184
2022-01-13 21:16:17,640 iteration 4057 : loss : 0.026628, loss_ce: 0.008551
2022-01-13 21:16:18,997 iteration 4058 : loss : 0.035779, loss_ce: 0.013786
2022-01-13 21:16:20,468 iteration 4059 : loss : 0.045802, loss_ce: 0.020619
2022-01-13 21:16:21,856 iteration 4060 : loss : 0.029964, loss_ce: 0.012548
2022-01-13 21:16:23,231 iteration 4061 : loss : 0.036056, loss_ce: 0.015599
2022-01-13 21:16:24,636 iteration 4062 : loss : 0.041300, loss_ce: 0.019241
2022-01-13 21:16:26,025 iteration 4063 : loss : 0.043243, loss_ce: 0.012565
 60%|████████████████▏          | 239/400 [1:41:57<1:05:21, 24.36s/it]2022-01-13 21:16:27,430 iteration 4064 : loss : 0.038235, loss_ce: 0.008756
2022-01-13 21:16:28,774 iteration 4065 : loss : 0.020584, loss_ce: 0.007615
2022-01-13 21:16:30,211 iteration 4066 : loss : 0.046021, loss_ce: 0.018204
2022-01-13 21:16:31,545 iteration 4067 : loss : 0.025502, loss_ce: 0.010284
2022-01-13 21:16:32,914 iteration 4068 : loss : 0.035861, loss_ce: 0.012460
2022-01-13 21:16:34,313 iteration 4069 : loss : 0.031021, loss_ce: 0.012681
2022-01-13 21:16:35,709 iteration 4070 : loss : 0.027680, loss_ce: 0.011851
2022-01-13 21:16:37,142 iteration 4071 : loss : 0.043087, loss_ce: 0.014893
2022-01-13 21:16:38,507 iteration 4072 : loss : 0.025812, loss_ce: 0.009056
2022-01-13 21:16:39,845 iteration 4073 : loss : 0.032355, loss_ce: 0.010751
2022-01-13 21:16:41,218 iteration 4074 : loss : 0.025709, loss_ce: 0.012350
2022-01-13 21:16:42,666 iteration 4075 : loss : 0.021491, loss_ce: 0.007461
2022-01-13 21:16:43,996 iteration 4076 : loss : 0.033391, loss_ce: 0.013286
2022-01-13 21:16:45,356 iteration 4077 : loss : 0.021149, loss_ce: 0.007608
2022-01-13 21:16:46,782 iteration 4078 : loss : 0.034598, loss_ce: 0.012477
2022-01-13 21:16:48,188 iteration 4079 : loss : 0.031850, loss_ce: 0.016045
2022-01-13 21:16:48,188 Training Data Eval:
2022-01-13 21:16:54,996   Average segmentation loss on training set: 0.0170
2022-01-13 21:16:54,997 Validation Data Eval:
2022-01-13 21:16:57,328   Average segmentation loss on validation set: 0.0795
2022-01-13 21:16:58,745 iteration 4080 : loss : 0.024389, loss_ce: 0.011124
 60%|████████████████▏          | 240/400 [1:42:30<1:11:39, 26.87s/it]2022-01-13 21:17:00,200 iteration 4081 : loss : 0.049127, loss_ce: 0.022701
2022-01-13 21:17:01,585 iteration 4082 : loss : 0.020498, loss_ce: 0.007828
2022-01-13 21:17:02,910 iteration 4083 : loss : 0.021418, loss_ce: 0.009258
2022-01-13 21:17:04,279 iteration 4084 : loss : 0.024227, loss_ce: 0.007503
2022-01-13 21:17:05,604 iteration 4085 : loss : 0.024245, loss_ce: 0.007240
2022-01-13 21:17:07,097 iteration 4086 : loss : 0.034227, loss_ce: 0.012073
2022-01-13 21:17:08,518 iteration 4087 : loss : 0.033063, loss_ce: 0.008677
2022-01-13 21:17:09,831 iteration 4088 : loss : 0.036215, loss_ce: 0.019210
2022-01-13 21:17:11,207 iteration 4089 : loss : 0.034790, loss_ce: 0.013082
2022-01-13 21:17:12,522 iteration 4090 : loss : 0.020473, loss_ce: 0.006425
2022-01-13 21:17:13,882 iteration 4091 : loss : 0.065527, loss_ce: 0.023282
2022-01-13 21:17:15,265 iteration 4092 : loss : 0.031665, loss_ce: 0.012842
2022-01-13 21:17:16,656 iteration 4093 : loss : 0.045327, loss_ce: 0.018613
2022-01-13 21:17:17,998 iteration 4094 : loss : 0.029011, loss_ce: 0.011104
2022-01-13 21:17:19,380 iteration 4095 : loss : 0.030471, loss_ce: 0.013624
2022-01-13 21:17:20,719 iteration 4096 : loss : 0.025732, loss_ce: 0.014741
2022-01-13 21:17:22,073 iteration 4097 : loss : 0.034601, loss_ce: 0.014177
 60%|████████████████▎          | 241/400 [1:42:53<1:08:23, 25.81s/it]2022-01-13 21:17:23,482 iteration 4098 : loss : 0.028607, loss_ce: 0.011241
2022-01-13 21:17:24,818 iteration 4099 : loss : 0.031402, loss_ce: 0.008795
2022-01-13 21:17:26,195 iteration 4100 : loss : 0.032502, loss_ce: 0.013550
2022-01-13 21:17:27,613 iteration 4101 : loss : 0.036615, loss_ce: 0.013001
2022-01-13 21:17:29,031 iteration 4102 : loss : 0.037512, loss_ce: 0.016517
2022-01-13 21:17:30,429 iteration 4103 : loss : 0.032393, loss_ce: 0.015168
2022-01-13 21:17:31,808 iteration 4104 : loss : 0.036221, loss_ce: 0.015658
2022-01-13 21:17:33,196 iteration 4105 : loss : 0.028936, loss_ce: 0.012851
2022-01-13 21:17:34,560 iteration 4106 : loss : 0.029283, loss_ce: 0.011754
2022-01-13 21:17:35,914 iteration 4107 : loss : 0.026987, loss_ce: 0.011516
2022-01-13 21:17:37,319 iteration 4108 : loss : 0.025203, loss_ce: 0.011410
2022-01-13 21:17:38,632 iteration 4109 : loss : 0.023648, loss_ce: 0.007839
2022-01-13 21:17:40,043 iteration 4110 : loss : 0.032428, loss_ce: 0.012293
2022-01-13 21:17:41,567 iteration 4111 : loss : 0.052769, loss_ce: 0.030320
2022-01-13 21:17:42,909 iteration 4112 : loss : 0.023435, loss_ce: 0.007977
2022-01-13 21:17:44,322 iteration 4113 : loss : 0.041491, loss_ce: 0.012803
2022-01-13 21:17:45,695 iteration 4114 : loss : 0.026108, loss_ce: 0.012158
 60%|████████████████▎          | 242/400 [1:43:17<1:06:13, 25.15s/it]2022-01-13 21:17:47,076 iteration 4115 : loss : 0.031636, loss_ce: 0.015429
2022-01-13 21:17:48,517 iteration 4116 : loss : 0.022749, loss_ce: 0.008093
2022-01-13 21:17:49,838 iteration 4117 : loss : 0.021617, loss_ce: 0.008401
2022-01-13 21:17:51,289 iteration 4118 : loss : 0.030762, loss_ce: 0.013785
2022-01-13 21:17:52,783 iteration 4119 : loss : 0.046784, loss_ce: 0.014732
2022-01-13 21:17:54,235 iteration 4120 : loss : 0.028228, loss_ce: 0.007602
2022-01-13 21:17:55,597 iteration 4121 : loss : 0.022228, loss_ce: 0.007890
2022-01-13 21:17:56,982 iteration 4122 : loss : 0.034797, loss_ce: 0.009862
2022-01-13 21:17:58,329 iteration 4123 : loss : 0.014603, loss_ce: 0.006374
2022-01-13 21:17:59,773 iteration 4124 : loss : 0.040325, loss_ce: 0.020159
2022-01-13 21:18:01,190 iteration 4125 : loss : 0.047676, loss_ce: 0.023111
2022-01-13 21:18:02,611 iteration 4126 : loss : 0.028746, loss_ce: 0.011492
2022-01-13 21:18:03,957 iteration 4127 : loss : 0.022132, loss_ce: 0.011493
2022-01-13 21:18:05,472 iteration 4128 : loss : 0.061735, loss_ce: 0.020499
2022-01-13 21:18:06,815 iteration 4129 : loss : 0.024713, loss_ce: 0.005976
2022-01-13 21:18:08,129 iteration 4130 : loss : 0.031510, loss_ce: 0.012170
2022-01-13 21:18:09,500 iteration 4131 : loss : 0.021129, loss_ce: 0.009344
 61%|████████████████▍          | 243/400 [1:43:41<1:04:45, 24.75s/it]2022-01-13 21:18:11,005 iteration 4132 : loss : 0.033901, loss_ce: 0.010314
2022-01-13 21:18:12,424 iteration 4133 : loss : 0.025295, loss_ce: 0.008658
2022-01-13 21:18:13,853 iteration 4134 : loss : 0.045100, loss_ce: 0.018138
2022-01-13 21:18:15,162 iteration 4135 : loss : 0.023599, loss_ce: 0.010972
2022-01-13 21:18:16,541 iteration 4136 : loss : 0.031075, loss_ce: 0.015262
2022-01-13 21:18:17,856 iteration 4137 : loss : 0.019381, loss_ce: 0.008264
2022-01-13 21:18:19,275 iteration 4138 : loss : 0.029904, loss_ce: 0.014267
2022-01-13 21:18:20,694 iteration 4139 : loss : 0.020072, loss_ce: 0.008415
2022-01-13 21:18:22,122 iteration 4140 : loss : 0.031675, loss_ce: 0.012968
2022-01-13 21:18:23,536 iteration 4141 : loss : 0.026519, loss_ce: 0.009058
2022-01-13 21:18:25,009 iteration 4142 : loss : 0.057147, loss_ce: 0.022531
2022-01-13 21:18:26,314 iteration 4143 : loss : 0.032106, loss_ce: 0.009593
2022-01-13 21:18:27,632 iteration 4144 : loss : 0.018878, loss_ce: 0.004490
2022-01-13 21:18:29,083 iteration 4145 : loss : 0.026615, loss_ce: 0.012365
2022-01-13 21:18:30,450 iteration 4146 : loss : 0.021571, loss_ce: 0.010772
2022-01-13 21:18:31,855 iteration 4147 : loss : 0.020602, loss_ce: 0.007222
2022-01-13 21:18:33,215 iteration 4148 : loss : 0.026971, loss_ce: 0.010138
 61%|████████████████▍          | 244/400 [1:44:04<1:03:32, 24.44s/it]2022-01-13 21:18:34,579 iteration 4149 : loss : 0.024031, loss_ce: 0.008336
2022-01-13 21:18:35,992 iteration 4150 : loss : 0.027389, loss_ce: 0.009766
2022-01-13 21:18:37,435 iteration 4151 : loss : 0.029938, loss_ce: 0.010124
2022-01-13 21:18:38,830 iteration 4152 : loss : 0.024226, loss_ce: 0.011141
2022-01-13 21:18:40,142 iteration 4153 : loss : 0.017302, loss_ce: 0.006550
2022-01-13 21:18:41,539 iteration 4154 : loss : 0.020448, loss_ce: 0.007036
2022-01-13 21:18:42,919 iteration 4155 : loss : 0.028842, loss_ce: 0.009248
2022-01-13 21:18:44,243 iteration 4156 : loss : 0.017021, loss_ce: 0.006067
2022-01-13 21:18:45,689 iteration 4157 : loss : 0.030380, loss_ce: 0.016002
2022-01-13 21:18:47,037 iteration 4158 : loss : 0.023301, loss_ce: 0.008603
2022-01-13 21:18:48,384 iteration 4159 : loss : 0.025830, loss_ce: 0.011669
2022-01-13 21:18:49,861 iteration 4160 : loss : 0.041795, loss_ce: 0.017007
2022-01-13 21:18:51,332 iteration 4161 : loss : 0.043584, loss_ce: 0.017052
2022-01-13 21:18:52,782 iteration 4162 : loss : 0.043247, loss_ce: 0.014318
2022-01-13 21:18:54,212 iteration 4163 : loss : 0.037896, loss_ce: 0.018128
2022-01-13 21:18:55,594 iteration 4164 : loss : 0.023054, loss_ce: 0.008593
2022-01-13 21:18:55,594 Training Data Eval:
2022-01-13 21:19:02,401   Average segmentation loss on training set: 0.0164
2022-01-13 21:19:02,401 Validation Data Eval:
2022-01-13 21:19:04,733   Average segmentation loss on validation set: 0.0821
2022-01-13 21:19:06,133 iteration 4165 : loss : 0.033664, loss_ce: 0.010508
 61%|████████████████▌          | 245/400 [1:44:37<1:09:41, 26.98s/it]2022-01-13 21:19:07,554 iteration 4166 : loss : 0.019256, loss_ce: 0.007505
2022-01-13 21:19:08,850 iteration 4167 : loss : 0.028008, loss_ce: 0.007807
2022-01-13 21:19:10,169 iteration 4168 : loss : 0.028447, loss_ce: 0.011674
2022-01-13 21:19:11,491 iteration 4169 : loss : 0.019827, loss_ce: 0.010052
2022-01-13 21:19:12,966 iteration 4170 : loss : 0.032552, loss_ce: 0.015986
2022-01-13 21:19:14,268 iteration 4171 : loss : 0.027522, loss_ce: 0.008135
2022-01-13 21:19:15,629 iteration 4172 : loss : 0.021752, loss_ce: 0.010076
2022-01-13 21:19:17,029 iteration 4173 : loss : 0.024803, loss_ce: 0.006749
2022-01-13 21:19:18,377 iteration 4174 : loss : 0.020029, loss_ce: 0.006035
2022-01-13 21:19:19,692 iteration 4175 : loss : 0.021644, loss_ce: 0.008380
2022-01-13 21:19:21,039 iteration 4176 : loss : 0.022505, loss_ce: 0.009868
2022-01-13 21:19:22,441 iteration 4177 : loss : 0.018818, loss_ce: 0.005600
2022-01-13 21:19:23,766 iteration 4178 : loss : 0.033201, loss_ce: 0.011791
2022-01-13 21:19:25,111 iteration 4179 : loss : 0.024228, loss_ce: 0.010509
2022-01-13 21:19:26,443 iteration 4180 : loss : 0.018346, loss_ce: 0.006067
2022-01-13 21:19:27,800 iteration 4181 : loss : 0.032251, loss_ce: 0.013882
2022-01-13 21:19:29,159 iteration 4182 : loss : 0.025945, loss_ce: 0.007369
 62%|████████████████▌          | 246/400 [1:45:00<1:06:12, 25.80s/it]2022-01-13 21:19:30,600 iteration 4183 : loss : 0.025635, loss_ce: 0.009450
2022-01-13 21:19:32,000 iteration 4184 : loss : 0.026044, loss_ce: 0.010739
2022-01-13 21:19:33,411 iteration 4185 : loss : 0.027146, loss_ce: 0.011538
2022-01-13 21:19:34,764 iteration 4186 : loss : 0.018604, loss_ce: 0.005549
2022-01-13 21:19:36,168 iteration 4187 : loss : 0.030597, loss_ce: 0.009603
2022-01-13 21:19:37,498 iteration 4188 : loss : 0.029548, loss_ce: 0.010006
2022-01-13 21:19:38,973 iteration 4189 : loss : 0.027192, loss_ce: 0.013583
2022-01-13 21:19:40,399 iteration 4190 : loss : 0.039263, loss_ce: 0.017873
2022-01-13 21:19:41,833 iteration 4191 : loss : 0.034489, loss_ce: 0.015321
2022-01-13 21:19:43,127 iteration 4192 : loss : 0.018046, loss_ce: 0.005823
2022-01-13 21:19:44,513 iteration 4193 : loss : 0.035509, loss_ce: 0.019126
2022-01-13 21:19:45,936 iteration 4194 : loss : 0.031368, loss_ce: 0.011298
2022-01-13 21:19:47,291 iteration 4195 : loss : 0.030774, loss_ce: 0.009788
2022-01-13 21:19:48,692 iteration 4196 : loss : 0.022163, loss_ce: 0.009777
2022-01-13 21:19:50,050 iteration 4197 : loss : 0.028939, loss_ce: 0.009431
2022-01-13 21:19:51,409 iteration 4198 : loss : 0.019598, loss_ce: 0.007941
2022-01-13 21:19:52,719 iteration 4199 : loss : 0.023106, loss_ce: 0.009102
 62%|████████████████▋          | 247/400 [1:45:24<1:04:04, 25.13s/it]2022-01-13 21:19:54,167 iteration 4200 : loss : 0.027344, loss_ce: 0.009722
2022-01-13 21:19:55,566 iteration 4201 : loss : 0.029817, loss_ce: 0.014659
2022-01-13 21:19:56,984 iteration 4202 : loss : 0.021441, loss_ce: 0.009331
2022-01-13 21:19:58,491 iteration 4203 : loss : 0.024900, loss_ce: 0.011170
2022-01-13 21:19:59,867 iteration 4204 : loss : 0.026839, loss_ce: 0.011474
2022-01-13 21:20:01,243 iteration 4205 : loss : 0.022532, loss_ce: 0.010450
2022-01-13 21:20:02,752 iteration 4206 : loss : 0.050346, loss_ce: 0.017374
2022-01-13 21:20:04,167 iteration 4207 : loss : 0.032255, loss_ce: 0.011809
2022-01-13 21:20:05,456 iteration 4208 : loss : 0.015363, loss_ce: 0.005440
2022-01-13 21:20:06,802 iteration 4209 : loss : 0.022011, loss_ce: 0.009626
2022-01-13 21:20:08,163 iteration 4210 : loss : 0.028295, loss_ce: 0.013387
2022-01-13 21:20:09,592 iteration 4211 : loss : 0.031287, loss_ce: 0.013804
2022-01-13 21:20:11,047 iteration 4212 : loss : 0.046067, loss_ce: 0.025152
2022-01-13 21:20:12,405 iteration 4213 : loss : 0.027977, loss_ce: 0.008881
2022-01-13 21:20:13,851 iteration 4214 : loss : 0.036238, loss_ce: 0.012196
2022-01-13 21:20:15,258 iteration 4215 : loss : 0.025080, loss_ce: 0.009205
2022-01-13 21:20:16,634 iteration 4216 : loss : 0.019739, loss_ce: 0.007047
 62%|████████████████▋          | 248/400 [1:45:48<1:02:43, 24.76s/it]2022-01-13 21:20:18,130 iteration 4217 : loss : 0.029074, loss_ce: 0.011002
2022-01-13 21:20:19,504 iteration 4218 : loss : 0.029159, loss_ce: 0.010277
2022-01-13 21:20:20,851 iteration 4219 : loss : 0.023559, loss_ce: 0.009924
2022-01-13 21:20:22,140 iteration 4220 : loss : 0.020402, loss_ce: 0.005341
2022-01-13 21:20:23,631 iteration 4221 : loss : 0.029165, loss_ce: 0.014888
2022-01-13 21:20:25,128 iteration 4222 : loss : 0.027794, loss_ce: 0.007906
2022-01-13 21:20:26,500 iteration 4223 : loss : 0.025235, loss_ce: 0.010637
2022-01-13 21:20:27,964 iteration 4224 : loss : 0.031765, loss_ce: 0.006764
2022-01-13 21:20:29,390 iteration 4225 : loss : 0.026132, loss_ce: 0.007665
2022-01-13 21:20:30,834 iteration 4226 : loss : 0.026150, loss_ce: 0.011906
2022-01-13 21:20:32,255 iteration 4227 : loss : 0.023547, loss_ce: 0.010023
2022-01-13 21:20:33,600 iteration 4228 : loss : 0.027464, loss_ce: 0.011801
2022-01-13 21:20:34,986 iteration 4229 : loss : 0.027359, loss_ce: 0.011222
2022-01-13 21:20:36,368 iteration 4230 : loss : 0.040452, loss_ce: 0.022649
2022-01-13 21:20:37,813 iteration 4231 : loss : 0.026980, loss_ce: 0.010489
2022-01-13 21:20:39,257 iteration 4232 : loss : 0.035582, loss_ce: 0.011535
2022-01-13 21:20:40,652 iteration 4233 : loss : 0.025046, loss_ce: 0.013038
 62%|████████████████▊          | 249/400 [1:46:12<1:01:45, 24.54s/it]2022-01-13 21:20:42,015 iteration 4234 : loss : 0.027440, loss_ce: 0.006676
2022-01-13 21:20:43,334 iteration 4235 : loss : 0.014502, loss_ce: 0.005822
2022-01-13 21:20:44,758 iteration 4236 : loss : 0.025252, loss_ce: 0.010234
2022-01-13 21:20:46,108 iteration 4237 : loss : 0.024280, loss_ce: 0.010064
2022-01-13 21:20:47,486 iteration 4238 : loss : 0.039447, loss_ce: 0.024555
2022-01-13 21:20:49,029 iteration 4239 : loss : 0.042472, loss_ce: 0.020719
2022-01-13 21:20:50,442 iteration 4240 : loss : 0.023664, loss_ce: 0.007854
2022-01-13 21:20:51,737 iteration 4241 : loss : 0.020849, loss_ce: 0.009452
2022-01-13 21:20:53,106 iteration 4242 : loss : 0.030486, loss_ce: 0.010120
2022-01-13 21:20:54,451 iteration 4243 : loss : 0.026431, loss_ce: 0.009483
2022-01-13 21:20:55,752 iteration 4244 : loss : 0.018579, loss_ce: 0.008588
2022-01-13 21:20:57,157 iteration 4245 : loss : 0.026488, loss_ce: 0.011335
2022-01-13 21:20:58,600 iteration 4246 : loss : 0.027474, loss_ce: 0.006795
2022-01-13 21:21:00,015 iteration 4247 : loss : 0.026370, loss_ce: 0.013273
2022-01-13 21:21:01,346 iteration 4248 : loss : 0.037136, loss_ce: 0.014572
2022-01-13 21:21:02,791 iteration 4249 : loss : 0.025658, loss_ce: 0.007891
2022-01-13 21:21:02,791 Training Data Eval:
2022-01-13 21:21:09,605   Average segmentation loss on training set: 0.0142
2022-01-13 21:21:09,605 Validation Data Eval:
2022-01-13 21:21:11,941   Average segmentation loss on validation set: 0.0758
2022-01-13 21:21:13,310 iteration 4250 : loss : 0.027494, loss_ce: 0.011720
 62%|████████████████▉          | 250/400 [1:46:45<1:07:25, 26.97s/it]2022-01-13 21:21:14,794 iteration 4251 : loss : 0.031825, loss_ce: 0.008619
2022-01-13 21:21:16,212 iteration 4252 : loss : 0.037306, loss_ce: 0.019861
2022-01-13 21:21:17,588 iteration 4253 : loss : 0.029571, loss_ce: 0.009785
2022-01-13 21:21:18,997 iteration 4254 : loss : 0.022747, loss_ce: 0.008840
2022-01-13 21:21:20,418 iteration 4255 : loss : 0.030798, loss_ce: 0.010940
2022-01-13 21:21:21,700 iteration 4256 : loss : 0.018276, loss_ce: 0.008587
2022-01-13 21:21:23,067 iteration 4257 : loss : 0.023828, loss_ce: 0.008613
2022-01-13 21:21:24,367 iteration 4258 : loss : 0.028067, loss_ce: 0.009560
2022-01-13 21:21:25,755 iteration 4259 : loss : 0.028262, loss_ce: 0.012878
2022-01-13 21:21:27,169 iteration 4260 : loss : 0.028894, loss_ce: 0.009422
2022-01-13 21:21:28,564 iteration 4261 : loss : 0.024220, loss_ce: 0.010152
2022-01-13 21:21:29,898 iteration 4262 : loss : 0.023984, loss_ce: 0.010307
2022-01-13 21:21:31,292 iteration 4263 : loss : 0.022915, loss_ce: 0.010140
2022-01-13 21:21:32,715 iteration 4264 : loss : 0.027822, loss_ce: 0.011266
2022-01-13 21:21:34,080 iteration 4265 : loss : 0.035785, loss_ce: 0.010032
2022-01-13 21:21:35,481 iteration 4266 : loss : 0.029792, loss_ce: 0.009287
2022-01-13 21:21:36,901 iteration 4267 : loss : 0.031799, loss_ce: 0.011659
 63%|████████████████▉          | 251/400 [1:47:08<1:04:27, 25.96s/it]2022-01-13 21:21:38,342 iteration 4268 : loss : 0.024192, loss_ce: 0.006039
2022-01-13 21:21:39,705 iteration 4269 : loss : 0.030877, loss_ce: 0.010329
2022-01-13 21:21:41,040 iteration 4270 : loss : 0.032464, loss_ce: 0.020585
2022-01-13 21:21:42,340 iteration 4271 : loss : 0.023176, loss_ce: 0.009310
2022-01-13 21:21:43,700 iteration 4272 : loss : 0.022479, loss_ce: 0.010946
2022-01-13 21:21:45,042 iteration 4273 : loss : 0.020744, loss_ce: 0.008432
2022-01-13 21:21:46,500 iteration 4274 : loss : 0.022684, loss_ce: 0.011014
2022-01-13 21:21:47,870 iteration 4275 : loss : 0.020781, loss_ce: 0.008057
2022-01-13 21:21:49,289 iteration 4276 : loss : 0.023651, loss_ce: 0.007649
2022-01-13 21:21:50,709 iteration 4277 : loss : 0.023970, loss_ce: 0.007770
2022-01-13 21:21:52,124 iteration 4278 : loss : 0.030170, loss_ce: 0.009790
2022-01-13 21:21:53,488 iteration 4279 : loss : 0.023970, loss_ce: 0.012116
2022-01-13 21:21:54,874 iteration 4280 : loss : 0.037312, loss_ce: 0.012303
2022-01-13 21:21:56,251 iteration 4281 : loss : 0.027463, loss_ce: 0.009110
2022-01-13 21:21:57,558 iteration 4282 : loss : 0.019305, loss_ce: 0.007907
2022-01-13 21:21:58,908 iteration 4283 : loss : 0.027148, loss_ce: 0.008521
2022-01-13 21:22:00,241 iteration 4284 : loss : 0.019840, loss_ce: 0.008296
 63%|█████████████████          | 252/400 [1:47:31<1:02:05, 25.17s/it]2022-01-13 21:22:01,604 iteration 4285 : loss : 0.024441, loss_ce: 0.008365
2022-01-13 21:22:03,016 iteration 4286 : loss : 0.029736, loss_ce: 0.012242
2022-01-13 21:22:04,339 iteration 4287 : loss : 0.020982, loss_ce: 0.009450
2022-01-13 21:22:05,675 iteration 4288 : loss : 0.026227, loss_ce: 0.013741
2022-01-13 21:22:07,051 iteration 4289 : loss : 0.023630, loss_ce: 0.009387
2022-01-13 21:22:08,407 iteration 4290 : loss : 0.038151, loss_ce: 0.009266
2022-01-13 21:22:09,802 iteration 4291 : loss : 0.019404, loss_ce: 0.007001
2022-01-13 21:22:11,197 iteration 4292 : loss : 0.030350, loss_ce: 0.013891
2022-01-13 21:22:12,569 iteration 4293 : loss : 0.026661, loss_ce: 0.007637
2022-01-13 21:22:13,912 iteration 4294 : loss : 0.018553, loss_ce: 0.005123
2022-01-13 21:22:15,383 iteration 4295 : loss : 0.026061, loss_ce: 0.008679
2022-01-13 21:22:16,759 iteration 4296 : loss : 0.022801, loss_ce: 0.006656
2022-01-13 21:22:18,147 iteration 4297 : loss : 0.021416, loss_ce: 0.008358
2022-01-13 21:22:19,490 iteration 4298 : loss : 0.020139, loss_ce: 0.009549
2022-01-13 21:22:20,911 iteration 4299 : loss : 0.025062, loss_ce: 0.011934
2022-01-13 21:22:22,354 iteration 4300 : loss : 0.037287, loss_ce: 0.019690
2022-01-13 21:22:23,793 iteration 4301 : loss : 0.022980, loss_ce: 0.011130
 63%|█████████████████          | 253/400 [1:47:55<1:00:29, 24.69s/it]2022-01-13 21:22:25,267 iteration 4302 : loss : 0.033573, loss_ce: 0.014506
2022-01-13 21:22:26,724 iteration 4303 : loss : 0.051887, loss_ce: 0.010817
2022-01-13 21:22:28,059 iteration 4304 : loss : 0.018187, loss_ce: 0.006969
2022-01-13 21:22:29,407 iteration 4305 : loss : 0.031269, loss_ce: 0.011909
2022-01-13 21:22:30,752 iteration 4306 : loss : 0.024987, loss_ce: 0.009749
2022-01-13 21:22:32,061 iteration 4307 : loss : 0.017421, loss_ce: 0.007952
2022-01-13 21:22:33,457 iteration 4308 : loss : 0.023416, loss_ce: 0.009231
2022-01-13 21:22:34,893 iteration 4309 : loss : 0.027554, loss_ce: 0.009672
2022-01-13 21:22:36,269 iteration 4310 : loss : 0.020603, loss_ce: 0.009402
2022-01-13 21:22:37,604 iteration 4311 : loss : 0.028820, loss_ce: 0.011166
2022-01-13 21:22:38,922 iteration 4312 : loss : 0.027147, loss_ce: 0.009877
2022-01-13 21:22:40,248 iteration 4313 : loss : 0.019642, loss_ce: 0.009810
2022-01-13 21:22:41,586 iteration 4314 : loss : 0.023502, loss_ce: 0.008393
2022-01-13 21:22:42,987 iteration 4315 : loss : 0.026748, loss_ce: 0.010125
2022-01-13 21:22:44,336 iteration 4316 : loss : 0.032592, loss_ce: 0.010110
2022-01-13 21:22:45,754 iteration 4317 : loss : 0.025366, loss_ce: 0.009510
2022-01-13 21:22:47,070 iteration 4318 : loss : 0.020035, loss_ce: 0.007929
 64%|██████████████████▍          | 254/400 [1:48:18<59:02, 24.26s/it]2022-01-13 21:22:48,534 iteration 4319 : loss : 0.027988, loss_ce: 0.010927
2022-01-13 21:22:49,945 iteration 4320 : loss : 0.029264, loss_ce: 0.011226
2022-01-13 21:22:51,220 iteration 4321 : loss : 0.020472, loss_ce: 0.006121
2022-01-13 21:22:52,586 iteration 4322 : loss : 0.020113, loss_ce: 0.006424
2022-01-13 21:22:53,916 iteration 4323 : loss : 0.023201, loss_ce: 0.011004
2022-01-13 21:22:55,429 iteration 4324 : loss : 0.044623, loss_ce: 0.025667
2022-01-13 21:22:56,826 iteration 4325 : loss : 0.023771, loss_ce: 0.009602
2022-01-13 21:22:58,205 iteration 4326 : loss : 0.031916, loss_ce: 0.014874
2022-01-13 21:22:59,616 iteration 4327 : loss : 0.023789, loss_ce: 0.006947
2022-01-13 21:23:00,947 iteration 4328 : loss : 0.027253, loss_ce: 0.009448
2022-01-13 21:23:02,409 iteration 4329 : loss : 0.053991, loss_ce: 0.015276
2022-01-13 21:23:03,851 iteration 4330 : loss : 0.023515, loss_ce: 0.009619
2022-01-13 21:23:05,346 iteration 4331 : loss : 0.052927, loss_ce: 0.011495
2022-01-13 21:23:06,790 iteration 4332 : loss : 0.031565, loss_ce: 0.011301
2022-01-13 21:23:08,271 iteration 4333 : loss : 0.031750, loss_ce: 0.013914
2022-01-13 21:23:09,681 iteration 4334 : loss : 0.026373, loss_ce: 0.012449
2022-01-13 21:23:09,681 Training Data Eval:
2022-01-13 21:23:16,517   Average segmentation loss on training set: 0.0179
2022-01-13 21:23:16,517 Validation Data Eval:
2022-01-13 21:23:18,875   Average segmentation loss on validation set: 0.0838
2022-01-13 21:23:20,314 iteration 4335 : loss : 0.057864, loss_ce: 0.014616
 64%|█████████████████▏         | 255/400 [1:48:52<1:05:08, 26.96s/it]2022-01-13 21:23:21,646 iteration 4336 : loss : 0.017849, loss_ce: 0.008832
2022-01-13 21:23:23,129 iteration 4337 : loss : 0.030190, loss_ce: 0.012881
2022-01-13 21:23:24,523 iteration 4338 : loss : 0.020985, loss_ce: 0.007038
2022-01-13 21:23:25,869 iteration 4339 : loss : 0.018346, loss_ce: 0.006847
2022-01-13 21:23:27,297 iteration 4340 : loss : 0.031365, loss_ce: 0.014296
2022-01-13 21:23:28,630 iteration 4341 : loss : 0.022279, loss_ce: 0.007179
2022-01-13 21:23:30,075 iteration 4342 : loss : 0.026680, loss_ce: 0.007934
2022-01-13 21:23:31,515 iteration 4343 : loss : 0.027173, loss_ce: 0.008210
2022-01-13 21:23:32,945 iteration 4344 : loss : 0.025301, loss_ce: 0.012151
2022-01-13 21:23:34,446 iteration 4345 : loss : 0.033640, loss_ce: 0.012145
2022-01-13 21:23:35,775 iteration 4346 : loss : 0.026285, loss_ce: 0.006853
2022-01-13 21:23:37,174 iteration 4347 : loss : 0.019017, loss_ce: 0.008472
2022-01-13 21:23:38,518 iteration 4348 : loss : 0.019833, loss_ce: 0.010346
2022-01-13 21:23:39,807 iteration 4349 : loss : 0.017743, loss_ce: 0.005145
2022-01-13 21:23:41,097 iteration 4350 : loss : 0.028876, loss_ce: 0.008953
2022-01-13 21:23:42,502 iteration 4351 : loss : 0.038263, loss_ce: 0.012498
2022-01-13 21:23:43,900 iteration 4352 : loss : 0.025482, loss_ce: 0.010744
 64%|█████████████████▎         | 256/400 [1:49:15<1:02:16, 25.95s/it]2022-01-13 21:23:45,316 iteration 4353 : loss : 0.023582, loss_ce: 0.008932
2022-01-13 21:23:46,819 iteration 4354 : loss : 0.025914, loss_ce: 0.011622
2022-01-13 21:23:48,257 iteration 4355 : loss : 0.021775, loss_ce: 0.009082
2022-01-13 21:23:49,720 iteration 4356 : loss : 0.046729, loss_ce: 0.011319
2022-01-13 21:23:51,139 iteration 4357 : loss : 0.021953, loss_ce: 0.010324
2022-01-13 21:23:52,578 iteration 4358 : loss : 0.038154, loss_ce: 0.012998
2022-01-13 21:23:53,975 iteration 4359 : loss : 0.031023, loss_ce: 0.010282
2022-01-13 21:23:55,338 iteration 4360 : loss : 0.033499, loss_ce: 0.016945
2022-01-13 21:23:56,764 iteration 4361 : loss : 0.035225, loss_ce: 0.012854
2022-01-13 21:23:58,136 iteration 4362 : loss : 0.026717, loss_ce: 0.012440
2022-01-13 21:23:59,509 iteration 4363 : loss : 0.022592, loss_ce: 0.009534
2022-01-13 21:24:00,917 iteration 4364 : loss : 0.020891, loss_ce: 0.008477
2022-01-13 21:24:02,409 iteration 4365 : loss : 0.028709, loss_ce: 0.014164
2022-01-13 21:24:03,748 iteration 4366 : loss : 0.021240, loss_ce: 0.005583
2022-01-13 21:24:05,019 iteration 4367 : loss : 0.023911, loss_ce: 0.010378
2022-01-13 21:24:06,329 iteration 4368 : loss : 0.028897, loss_ce: 0.009748
2022-01-13 21:24:07,725 iteration 4369 : loss : 0.027973, loss_ce: 0.010056
 64%|█████████████████▎         | 257/400 [1:49:39<1:00:19, 25.31s/it]2022-01-13 21:24:09,160 iteration 4370 : loss : 0.034127, loss_ce: 0.011568
2022-01-13 21:24:10,548 iteration 4371 : loss : 0.028517, loss_ce: 0.013351
2022-01-13 21:24:11,947 iteration 4372 : loss : 0.027301, loss_ce: 0.011158
2022-01-13 21:24:13,342 iteration 4373 : loss : 0.019159, loss_ce: 0.009687
2022-01-13 21:24:14,751 iteration 4374 : loss : 0.018990, loss_ce: 0.007312
2022-01-13 21:24:16,160 iteration 4375 : loss : 0.035176, loss_ce: 0.020163
2022-01-13 21:24:17,516 iteration 4376 : loss : 0.024459, loss_ce: 0.009092
2022-01-13 21:24:18,863 iteration 4377 : loss : 0.030878, loss_ce: 0.010357
2022-01-13 21:24:20,171 iteration 4378 : loss : 0.019900, loss_ce: 0.007947
2022-01-13 21:24:21,484 iteration 4379 : loss : 0.021283, loss_ce: 0.008283
2022-01-13 21:24:22,782 iteration 4380 : loss : 0.020328, loss_ce: 0.007620
2022-01-13 21:24:24,176 iteration 4381 : loss : 0.040950, loss_ce: 0.013702
2022-01-13 21:24:25,544 iteration 4382 : loss : 0.058862, loss_ce: 0.011701
2022-01-13 21:24:26,892 iteration 4383 : loss : 0.030059, loss_ce: 0.009383
2022-01-13 21:24:28,379 iteration 4384 : loss : 0.027172, loss_ce: 0.012327
2022-01-13 21:24:29,805 iteration 4385 : loss : 0.029663, loss_ce: 0.010663
2022-01-13 21:24:31,144 iteration 4386 : loss : 0.036323, loss_ce: 0.019240
 64%|██████████████████▋          | 258/400 [1:50:02<58:33, 24.74s/it]2022-01-13 21:24:32,514 iteration 4387 : loss : 0.030237, loss_ce: 0.009637
2022-01-13 21:24:33,883 iteration 4388 : loss : 0.056454, loss_ce: 0.025868
2022-01-13 21:24:35,255 iteration 4389 : loss : 0.029763, loss_ce: 0.009742
2022-01-13 21:24:36,566 iteration 4390 : loss : 0.025999, loss_ce: 0.008957
2022-01-13 21:24:37,972 iteration 4391 : loss : 0.035609, loss_ce: 0.012845
2022-01-13 21:24:39,337 iteration 4392 : loss : 0.030171, loss_ce: 0.008891
2022-01-13 21:24:40,774 iteration 4393 : loss : 0.036414, loss_ce: 0.014317
2022-01-13 21:24:42,182 iteration 4394 : loss : 0.035361, loss_ce: 0.013195
2022-01-13 21:24:43,665 iteration 4395 : loss : 0.036402, loss_ce: 0.013687
2022-01-13 21:24:45,009 iteration 4396 : loss : 0.062108, loss_ce: 0.023985
2022-01-13 21:24:46,488 iteration 4397 : loss : 0.036007, loss_ce: 0.020152
2022-01-13 21:24:47,811 iteration 4398 : loss : 0.024609, loss_ce: 0.009902
2022-01-13 21:24:49,252 iteration 4399 : loss : 0.042813, loss_ce: 0.018146
2022-01-13 21:24:50,637 iteration 4400 : loss : 0.037772, loss_ce: 0.013087
2022-01-13 21:24:52,151 iteration 4401 : loss : 0.038581, loss_ce: 0.014942
2022-01-13 21:24:53,541 iteration 4402 : loss : 0.049294, loss_ce: 0.016276
2022-01-13 21:24:54,963 iteration 4403 : loss : 0.028392, loss_ce: 0.009586
 65%|██████████████████▊          | 259/400 [1:50:26<57:29, 24.47s/it]2022-01-13 21:24:56,364 iteration 4404 : loss : 0.022754, loss_ce: 0.009623
2022-01-13 21:24:57,774 iteration 4405 : loss : 0.027869, loss_ce: 0.012769
2022-01-13 21:24:59,177 iteration 4406 : loss : 0.023054, loss_ce: 0.009603
2022-01-13 21:25:00,622 iteration 4407 : loss : 0.053536, loss_ce: 0.019511
2022-01-13 21:25:01,978 iteration 4408 : loss : 0.040424, loss_ce: 0.021077
2022-01-13 21:25:03,383 iteration 4409 : loss : 0.029868, loss_ce: 0.010332
2022-01-13 21:25:04,933 iteration 4410 : loss : 0.056878, loss_ce: 0.020063
2022-01-13 21:25:06,360 iteration 4411 : loss : 0.031229, loss_ce: 0.013373
2022-01-13 21:25:07,742 iteration 4412 : loss : 0.031266, loss_ce: 0.012882
2022-01-13 21:25:09,142 iteration 4413 : loss : 0.018979, loss_ce: 0.006540
2022-01-13 21:25:10,459 iteration 4414 : loss : 0.023674, loss_ce: 0.007662
2022-01-13 21:25:11,866 iteration 4415 : loss : 0.023622, loss_ce: 0.008256
2022-01-13 21:25:13,310 iteration 4416 : loss : 0.035102, loss_ce: 0.011667
2022-01-13 21:25:14,686 iteration 4417 : loss : 0.021646, loss_ce: 0.007346
2022-01-13 21:25:16,076 iteration 4418 : loss : 0.027281, loss_ce: 0.011298
2022-01-13 21:25:17,504 iteration 4419 : loss : 0.029008, loss_ce: 0.008689
2022-01-13 21:25:17,504 Training Data Eval:
2022-01-13 21:25:24,319   Average segmentation loss on training set: 0.0164
2022-01-13 21:25:24,319 Validation Data Eval:
2022-01-13 21:25:26,663   Average segmentation loss on validation set: 0.1076
2022-01-13 21:25:27,980 iteration 4420 : loss : 0.020325, loss_ce: 0.010142
 65%|█████████████████▌         | 260/400 [1:50:59<1:03:04, 27.03s/it]2022-01-13 21:25:29,383 iteration 4421 : loss : 0.024530, loss_ce: 0.009101
2022-01-13 21:25:30,791 iteration 4422 : loss : 0.024225, loss_ce: 0.010704
2022-01-13 21:25:32,247 iteration 4423 : loss : 0.042169, loss_ce: 0.017843
2022-01-13 21:25:33,574 iteration 4424 : loss : 0.022328, loss_ce: 0.007516
2022-01-13 21:25:34,896 iteration 4425 : loss : 0.021062, loss_ce: 0.007347
2022-01-13 21:25:36,346 iteration 4426 : loss : 0.019825, loss_ce: 0.008121
2022-01-13 21:25:37,667 iteration 4427 : loss : 0.025469, loss_ce: 0.011918
2022-01-13 21:25:38,947 iteration 4428 : loss : 0.018693, loss_ce: 0.008973
2022-01-13 21:25:40,253 iteration 4429 : loss : 0.026785, loss_ce: 0.009660
2022-01-13 21:25:41,562 iteration 4430 : loss : 0.017961, loss_ce: 0.007736
2022-01-13 21:25:42,961 iteration 4431 : loss : 0.029836, loss_ce: 0.012690
2022-01-13 21:25:44,399 iteration 4432 : loss : 0.034979, loss_ce: 0.016585
2022-01-13 21:25:45,765 iteration 4433 : loss : 0.027531, loss_ce: 0.008475
2022-01-13 21:25:47,097 iteration 4434 : loss : 0.016581, loss_ce: 0.007262
2022-01-13 21:25:48,495 iteration 4435 : loss : 0.033372, loss_ce: 0.007545
2022-01-13 21:25:49,880 iteration 4436 : loss : 0.021905, loss_ce: 0.010435
2022-01-13 21:25:51,363 iteration 4437 : loss : 0.020897, loss_ce: 0.007202
 65%|█████████████████▌         | 261/400 [1:51:23<1:00:05, 25.94s/it]2022-01-13 21:25:52,881 iteration 4438 : loss : 0.045167, loss_ce: 0.012794
2022-01-13 21:25:54,315 iteration 4439 : loss : 0.019019, loss_ce: 0.007045
2022-01-13 21:25:55,724 iteration 4440 : loss : 0.023256, loss_ce: 0.009841
2022-01-13 21:25:57,248 iteration 4441 : loss : 0.044955, loss_ce: 0.019092
2022-01-13 21:25:58,724 iteration 4442 : loss : 0.029830, loss_ce: 0.017490
2022-01-13 21:26:00,150 iteration 4443 : loss : 0.027158, loss_ce: 0.009953
2022-01-13 21:26:01,476 iteration 4444 : loss : 0.022170, loss_ce: 0.007069
2022-01-13 21:26:02,865 iteration 4445 : loss : 0.032700, loss_ce: 0.011360
2022-01-13 21:26:04,296 iteration 4446 : loss : 0.026461, loss_ce: 0.011878
2022-01-13 21:26:05,668 iteration 4447 : loss : 0.021958, loss_ce: 0.007366
2022-01-13 21:26:07,095 iteration 4448 : loss : 0.039105, loss_ce: 0.014056
2022-01-13 21:26:08,501 iteration 4449 : loss : 0.037218, loss_ce: 0.016149
2022-01-13 21:26:09,965 iteration 4450 : loss : 0.052931, loss_ce: 0.019018
2022-01-13 21:26:11,329 iteration 4451 : loss : 0.033406, loss_ce: 0.013532
2022-01-13 21:26:12,746 iteration 4452 : loss : 0.020893, loss_ce: 0.009425
2022-01-13 21:26:14,114 iteration 4453 : loss : 0.018968, loss_ce: 0.006778
2022-01-13 21:26:15,478 iteration 4454 : loss : 0.024578, loss_ce: 0.010087
 66%|██████████████████▉          | 262/400 [1:51:47<58:23, 25.39s/it]2022-01-13 21:26:16,950 iteration 4455 : loss : 0.035136, loss_ce: 0.011566
2022-01-13 21:26:18,251 iteration 4456 : loss : 0.017995, loss_ce: 0.007232
2022-01-13 21:26:19,675 iteration 4457 : loss : 0.028238, loss_ce: 0.012660
2022-01-13 21:26:21,183 iteration 4458 : loss : 0.030404, loss_ce: 0.012019
2022-01-13 21:26:22,759 iteration 4459 : loss : 0.030213, loss_ce: 0.015615
2022-01-13 21:26:24,101 iteration 4460 : loss : 0.025948, loss_ce: 0.009680
2022-01-13 21:26:25,480 iteration 4461 : loss : 0.024386, loss_ce: 0.008049
2022-01-13 21:26:26,904 iteration 4462 : loss : 0.030473, loss_ce: 0.013851
2022-01-13 21:26:28,265 iteration 4463 : loss : 0.033141, loss_ce: 0.012914
2022-01-13 21:26:29,613 iteration 4464 : loss : 0.021711, loss_ce: 0.007622
2022-01-13 21:26:30,908 iteration 4465 : loss : 0.020798, loss_ce: 0.005424
2022-01-13 21:26:32,230 iteration 4466 : loss : 0.023038, loss_ce: 0.007501
2022-01-13 21:26:33,599 iteration 4467 : loss : 0.045393, loss_ce: 0.020137
2022-01-13 21:26:35,002 iteration 4468 : loss : 0.030357, loss_ce: 0.018434
2022-01-13 21:26:36,454 iteration 4469 : loss : 0.026218, loss_ce: 0.012973
2022-01-13 21:26:37,904 iteration 4470 : loss : 0.028538, loss_ce: 0.012469
2022-01-13 21:26:39,362 iteration 4471 : loss : 0.031689, loss_ce: 0.009762
 66%|███████████████████          | 263/400 [1:52:11<56:56, 24.94s/it]2022-01-13 21:26:40,778 iteration 4472 : loss : 0.020417, loss_ce: 0.009453
2022-01-13 21:26:42,110 iteration 4473 : loss : 0.021235, loss_ce: 0.008997
2022-01-13 21:26:43,490 iteration 4474 : loss : 0.028119, loss_ce: 0.014890
2022-01-13 21:26:44,875 iteration 4475 : loss : 0.028669, loss_ce: 0.009087
2022-01-13 21:26:46,215 iteration 4476 : loss : 0.022460, loss_ce: 0.006931
2022-01-13 21:26:47,565 iteration 4477 : loss : 0.030745, loss_ce: 0.012338
2022-01-13 21:26:49,054 iteration 4478 : loss : 0.032420, loss_ce: 0.015867
2022-01-13 21:26:50,433 iteration 4479 : loss : 0.045287, loss_ce: 0.013427
2022-01-13 21:26:51,822 iteration 4480 : loss : 0.022538, loss_ce: 0.008781
2022-01-13 21:26:53,152 iteration 4481 : loss : 0.017683, loss_ce: 0.006660
2022-01-13 21:26:54,473 iteration 4482 : loss : 0.020980, loss_ce: 0.006600
2022-01-13 21:26:55,811 iteration 4483 : loss : 0.026826, loss_ce: 0.009409
2022-01-13 21:26:57,183 iteration 4484 : loss : 0.016816, loss_ce: 0.005649
2022-01-13 21:26:58,488 iteration 4485 : loss : 0.023898, loss_ce: 0.010440
2022-01-13 21:26:59,914 iteration 4486 : loss : 0.021014, loss_ce: 0.008019
2022-01-13 21:27:01,323 iteration 4487 : loss : 0.028744, loss_ce: 0.013406
2022-01-13 21:27:02,645 iteration 4488 : loss : 0.021916, loss_ce: 0.008216
 66%|███████████████████▏         | 264/400 [1:52:34<55:23, 24.44s/it]2022-01-13 21:27:04,121 iteration 4489 : loss : 0.019525, loss_ce: 0.009016
2022-01-13 21:27:05,485 iteration 4490 : loss : 0.021334, loss_ce: 0.009777
2022-01-13 21:27:06,953 iteration 4491 : loss : 0.036513, loss_ce: 0.014206
2022-01-13 21:27:08,299 iteration 4492 : loss : 0.028702, loss_ce: 0.007450
2022-01-13 21:27:09,755 iteration 4493 : loss : 0.035622, loss_ce: 0.022377
2022-01-13 21:27:11,105 iteration 4494 : loss : 0.022009, loss_ce: 0.007903
2022-01-13 21:27:12,487 iteration 4495 : loss : 0.033894, loss_ce: 0.008045
2022-01-13 21:27:13,871 iteration 4496 : loss : 0.020981, loss_ce: 0.006747
2022-01-13 21:27:15,144 iteration 4497 : loss : 0.025597, loss_ce: 0.014449
2022-01-13 21:27:16,529 iteration 4498 : loss : 0.022270, loss_ce: 0.007630
2022-01-13 21:27:17,868 iteration 4499 : loss : 0.019812, loss_ce: 0.008343
2022-01-13 21:27:19,252 iteration 4500 : loss : 0.020582, loss_ce: 0.007631
2022-01-13 21:27:20,609 iteration 4501 : loss : 0.019213, loss_ce: 0.008383
2022-01-13 21:27:21,965 iteration 4502 : loss : 0.029510, loss_ce: 0.010676
2022-01-13 21:27:23,424 iteration 4503 : loss : 0.024284, loss_ce: 0.008909
2022-01-13 21:27:24,704 iteration 4504 : loss : 0.023678, loss_ce: 0.009443
2022-01-13 21:27:24,704 Training Data Eval:
2022-01-13 21:27:31,488   Average segmentation loss on training set: 0.0135
2022-01-13 21:27:31,488 Validation Data Eval:
2022-01-13 21:27:33,835   Average segmentation loss on validation set: 0.0712
2022-01-13 21:27:35,210 iteration 4505 : loss : 0.018489, loss_ce: 0.006424
 66%|█████████████████▉         | 265/400 [1:53:06<1:00:28, 26.88s/it]2022-01-13 21:27:36,664 iteration 4506 : loss : 0.022825, loss_ce: 0.009019
2022-01-13 21:27:38,106 iteration 4507 : loss : 0.042488, loss_ce: 0.018568
2022-01-13 21:27:39,483 iteration 4508 : loss : 0.036368, loss_ce: 0.011697
2022-01-13 21:27:40,791 iteration 4509 : loss : 0.028337, loss_ce: 0.009385
2022-01-13 21:27:42,160 iteration 4510 : loss : 0.023632, loss_ce: 0.009258
2022-01-13 21:27:43,649 iteration 4511 : loss : 0.028747, loss_ce: 0.012394
2022-01-13 21:27:44,932 iteration 4512 : loss : 0.020798, loss_ce: 0.007662
2022-01-13 21:27:46,276 iteration 4513 : loss : 0.023845, loss_ce: 0.009251
2022-01-13 21:27:47,616 iteration 4514 : loss : 0.023792, loss_ce: 0.010192
2022-01-13 21:27:48,973 iteration 4515 : loss : 0.029986, loss_ce: 0.012752
2022-01-13 21:27:50,350 iteration 4516 : loss : 0.024832, loss_ce: 0.012029
2022-01-13 21:27:51,760 iteration 4517 : loss : 0.020823, loss_ce: 0.007700
2022-01-13 21:27:53,107 iteration 4518 : loss : 0.036802, loss_ce: 0.018114
2022-01-13 21:27:54,408 iteration 4519 : loss : 0.027150, loss_ce: 0.010052
2022-01-13 21:27:55,802 iteration 4520 : loss : 0.022142, loss_ce: 0.007572
2022-01-13 21:27:57,184 iteration 4521 : loss : 0.033898, loss_ce: 0.014730
2022-01-13 21:27:58,613 iteration 4522 : loss : 0.047083, loss_ce: 0.018611
 66%|███████████████████▎         | 266/400 [1:53:30<57:42, 25.84s/it]2022-01-13 21:28:00,115 iteration 4523 : loss : 0.026624, loss_ce: 0.012984
2022-01-13 21:28:01,534 iteration 4524 : loss : 0.038137, loss_ce: 0.019151
2022-01-13 21:28:02,948 iteration 4525 : loss : 0.022368, loss_ce: 0.009816
2022-01-13 21:28:04,330 iteration 4526 : loss : 0.022178, loss_ce: 0.007008
2022-01-13 21:28:05,624 iteration 4527 : loss : 0.025407, loss_ce: 0.008404
2022-01-13 21:28:06,954 iteration 4528 : loss : 0.019983, loss_ce: 0.006633
2022-01-13 21:28:08,346 iteration 4529 : loss : 0.029398, loss_ce: 0.013868
2022-01-13 21:28:09,681 iteration 4530 : loss : 0.025573, loss_ce: 0.007479
2022-01-13 21:28:11,055 iteration 4531 : loss : 0.022524, loss_ce: 0.008430
2022-01-13 21:28:12,452 iteration 4532 : loss : 0.021401, loss_ce: 0.007330
2022-01-13 21:28:13,793 iteration 4533 : loss : 0.022811, loss_ce: 0.010783
2022-01-13 21:28:15,148 iteration 4534 : loss : 0.029246, loss_ce: 0.008456
2022-01-13 21:28:16,548 iteration 4535 : loss : 0.025261, loss_ce: 0.009443
2022-01-13 21:28:17,942 iteration 4536 : loss : 0.022485, loss_ce: 0.009816
2022-01-13 21:28:19,316 iteration 4537 : loss : 0.026579, loss_ce: 0.011422
2022-01-13 21:28:20,683 iteration 4538 : loss : 0.032043, loss_ce: 0.013720
2022-01-13 21:28:22,053 iteration 4539 : loss : 0.017148, loss_ce: 0.006971
 67%|███████████████████▎         | 267/400 [1:53:53<55:40, 25.12s/it]2022-01-13 21:28:23,491 iteration 4540 : loss : 0.018252, loss_ce: 0.007598
2022-01-13 21:28:24,890 iteration 4541 : loss : 0.027990, loss_ce: 0.014257
2022-01-13 21:28:26,217 iteration 4542 : loss : 0.021402, loss_ce: 0.008327
2022-01-13 21:28:27,605 iteration 4543 : loss : 0.021328, loss_ce: 0.007661
2022-01-13 21:28:28,933 iteration 4544 : loss : 0.022583, loss_ce: 0.008352
2022-01-13 21:28:30,368 iteration 4545 : loss : 0.019956, loss_ce: 0.008273
2022-01-13 21:28:31,850 iteration 4546 : loss : 0.028262, loss_ce: 0.013186
2022-01-13 21:28:33,320 iteration 4547 : loss : 0.034303, loss_ce: 0.015465
2022-01-13 21:28:34,632 iteration 4548 : loss : 0.019928, loss_ce: 0.007494
2022-01-13 21:28:35,974 iteration 4549 : loss : 0.025243, loss_ce: 0.007601
2022-01-13 21:28:37,352 iteration 4550 : loss : 0.035718, loss_ce: 0.016255
2022-01-13 21:28:38,748 iteration 4551 : loss : 0.035590, loss_ce: 0.018329
2022-01-13 21:28:40,208 iteration 4552 : loss : 0.027111, loss_ce: 0.007681
2022-01-13 21:28:41,604 iteration 4553 : loss : 0.026398, loss_ce: 0.009123
2022-01-13 21:28:42,933 iteration 4554 : loss : 0.029647, loss_ce: 0.013290
2022-01-13 21:28:44,289 iteration 4555 : loss : 0.032277, loss_ce: 0.014116
2022-01-13 21:28:45,648 iteration 4556 : loss : 0.024969, loss_ce: 0.006889
 67%|███████████████████▍         | 268/400 [1:54:17<54:14, 24.66s/it]2022-01-13 21:28:47,072 iteration 4557 : loss : 0.016577, loss_ce: 0.007114
2022-01-13 21:28:48,465 iteration 4558 : loss : 0.028898, loss_ce: 0.011163
2022-01-13 21:28:49,901 iteration 4559 : loss : 0.030110, loss_ce: 0.010194
2022-01-13 21:28:51,307 iteration 4560 : loss : 0.023170, loss_ce: 0.010420
2022-01-13 21:28:52,644 iteration 4561 : loss : 0.017200, loss_ce: 0.005788
2022-01-13 21:28:54,030 iteration 4562 : loss : 0.022236, loss_ce: 0.008925
2022-01-13 21:28:55,384 iteration 4563 : loss : 0.022782, loss_ce: 0.007528
2022-01-13 21:28:56,726 iteration 4564 : loss : 0.025351, loss_ce: 0.011082
2022-01-13 21:28:58,089 iteration 4565 : loss : 0.027379, loss_ce: 0.011410
2022-01-13 21:28:59,471 iteration 4566 : loss : 0.026641, loss_ce: 0.010392
2022-01-13 21:29:00,854 iteration 4567 : loss : 0.019636, loss_ce: 0.007901
2022-01-13 21:29:02,146 iteration 4568 : loss : 0.019839, loss_ce: 0.006674
2022-01-13 21:29:03,460 iteration 4569 : loss : 0.027986, loss_ce: 0.009927
2022-01-13 21:29:04,782 iteration 4570 : loss : 0.018330, loss_ce: 0.005849
2022-01-13 21:29:06,188 iteration 4571 : loss : 0.023524, loss_ce: 0.010588
2022-01-13 21:29:07,611 iteration 4572 : loss : 0.029819, loss_ce: 0.011157
2022-01-13 21:29:09,027 iteration 4573 : loss : 0.024942, loss_ce: 0.008240
 67%|███████████████████▌         | 269/400 [1:54:40<52:59, 24.27s/it]2022-01-13 21:29:10,393 iteration 4574 : loss : 0.014629, loss_ce: 0.004755
2022-01-13 21:29:11,782 iteration 4575 : loss : 0.034237, loss_ce: 0.011329
2022-01-13 21:29:13,089 iteration 4576 : loss : 0.018810, loss_ce: 0.008349
2022-01-13 21:29:14,425 iteration 4577 : loss : 0.021891, loss_ce: 0.010718
2022-01-13 21:29:15,783 iteration 4578 : loss : 0.022907, loss_ce: 0.008557
2022-01-13 21:29:17,105 iteration 4579 : loss : 0.019713, loss_ce: 0.007993
2022-01-13 21:29:18,449 iteration 4580 : loss : 0.020981, loss_ce: 0.008210
2022-01-13 21:29:19,814 iteration 4581 : loss : 0.029457, loss_ce: 0.011952
2022-01-13 21:29:21,174 iteration 4582 : loss : 0.035862, loss_ce: 0.013619
2022-01-13 21:29:22,527 iteration 4583 : loss : 0.025388, loss_ce: 0.009130
2022-01-13 21:29:23,872 iteration 4584 : loss : 0.026593, loss_ce: 0.010629
2022-01-13 21:29:25,250 iteration 4585 : loss : 0.029193, loss_ce: 0.011387
2022-01-13 21:29:26,560 iteration 4586 : loss : 0.022512, loss_ce: 0.009725
2022-01-13 21:29:27,892 iteration 4587 : loss : 0.025638, loss_ce: 0.008160
2022-01-13 21:29:29,229 iteration 4588 : loss : 0.025186, loss_ce: 0.008930
2022-01-13 21:29:30,613 iteration 4589 : loss : 0.023640, loss_ce: 0.007895
2022-01-13 21:29:30,613 Training Data Eval:
2022-01-13 21:29:37,389   Average segmentation loss on training set: 0.0152
2022-01-13 21:29:37,390 Validation Data Eval:
2022-01-13 21:29:39,746   Average segmentation loss on validation set: 0.0847
2022-01-13 21:29:41,093 iteration 4590 : loss : 0.020125, loss_ce: 0.008931
 68%|███████████████████▌         | 270/400 [1:55:12<57:39, 26.61s/it]2022-01-13 21:29:42,520 iteration 4591 : loss : 0.059196, loss_ce: 0.013733
2022-01-13 21:29:43,941 iteration 4592 : loss : 0.018264, loss_ce: 0.005999
2022-01-13 21:29:45,342 iteration 4593 : loss : 0.025988, loss_ce: 0.012633
2022-01-13 21:29:46,776 iteration 4594 : loss : 0.067019, loss_ce: 0.019689
2022-01-13 21:29:48,143 iteration 4595 : loss : 0.026682, loss_ce: 0.010150
2022-01-13 21:29:49,483 iteration 4596 : loss : 0.047265, loss_ce: 0.013369
2022-01-13 21:29:50,864 iteration 4597 : loss : 0.030397, loss_ce: 0.012633
2022-01-13 21:29:52,293 iteration 4598 : loss : 0.032182, loss_ce: 0.010776
2022-01-13 21:29:53,704 iteration 4599 : loss : 0.023741, loss_ce: 0.010645
2022-01-13 21:29:55,057 iteration 4600 : loss : 0.028503, loss_ce: 0.010660
2022-01-13 21:29:56,449 iteration 4601 : loss : 0.026322, loss_ce: 0.011004
2022-01-13 21:29:57,919 iteration 4602 : loss : 0.040375, loss_ce: 0.010813
2022-01-13 21:29:59,311 iteration 4603 : loss : 0.025982, loss_ce: 0.009248
2022-01-13 21:30:00,749 iteration 4604 : loss : 0.023750, loss_ce: 0.010871
2022-01-13 21:30:02,178 iteration 4605 : loss : 0.058493, loss_ce: 0.008533
2022-01-13 21:30:03,601 iteration 4606 : loss : 0.032906, loss_ce: 0.014259
2022-01-13 21:30:05,085 iteration 4607 : loss : 0.024837, loss_ce: 0.014118
 68%|███████████████████▋         | 271/400 [1:55:36<55:31, 25.83s/it]2022-01-13 21:30:06,499 iteration 4608 : loss : 0.016642, loss_ce: 0.006610
2022-01-13 21:30:07,883 iteration 4609 : loss : 0.033844, loss_ce: 0.013308
2022-01-13 21:30:09,205 iteration 4610 : loss : 0.026592, loss_ce: 0.008528
2022-01-13 21:30:10,523 iteration 4611 : loss : 0.023999, loss_ce: 0.009955
2022-01-13 21:30:11,854 iteration 4612 : loss : 0.023140, loss_ce: 0.006716
2022-01-13 21:30:13,224 iteration 4613 : loss : 0.028771, loss_ce: 0.009701
2022-01-13 21:30:14,593 iteration 4614 : loss : 0.016614, loss_ce: 0.007091
2022-01-13 21:30:16,010 iteration 4615 : loss : 0.024309, loss_ce: 0.009817
2022-01-13 21:30:17,493 iteration 4616 : loss : 0.024541, loss_ce: 0.009760
2022-01-13 21:30:18,889 iteration 4617 : loss : 0.030795, loss_ce: 0.010421
2022-01-13 21:30:20,210 iteration 4618 : loss : 0.021521, loss_ce: 0.006528
2022-01-13 21:30:21,546 iteration 4619 : loss : 0.016281, loss_ce: 0.007068
2022-01-13 21:30:22,972 iteration 4620 : loss : 0.043953, loss_ce: 0.016048
2022-01-13 21:30:24,335 iteration 4621 : loss : 0.025667, loss_ce: 0.012685
2022-01-13 21:30:25,712 iteration 4622 : loss : 0.038053, loss_ce: 0.014067
2022-01-13 21:30:27,091 iteration 4623 : loss : 0.018738, loss_ce: 0.006436
2022-01-13 21:30:28,476 iteration 4624 : loss : 0.021689, loss_ce: 0.009733
 68%|███████████████████▋         | 272/400 [1:56:00<53:32, 25.09s/it]2022-01-13 21:30:29,936 iteration 4625 : loss : 0.019380, loss_ce: 0.006981
2022-01-13 21:30:31,412 iteration 4626 : loss : 0.025176, loss_ce: 0.012449
2022-01-13 21:30:32,917 iteration 4627 : loss : 0.028743, loss_ce: 0.011552
2022-01-13 21:30:34,264 iteration 4628 : loss : 0.021567, loss_ce: 0.007305
2022-01-13 21:30:35,568 iteration 4629 : loss : 0.020713, loss_ce: 0.006608
2022-01-13 21:30:36,928 iteration 4630 : loss : 0.021065, loss_ce: 0.007953
2022-01-13 21:30:38,307 iteration 4631 : loss : 0.028584, loss_ce: 0.010296
2022-01-13 21:30:39,681 iteration 4632 : loss : 0.031057, loss_ce: 0.008989
2022-01-13 21:30:41,035 iteration 4633 : loss : 0.018735, loss_ce: 0.006225
2022-01-13 21:30:42,367 iteration 4634 : loss : 0.017186, loss_ce: 0.007893
2022-01-13 21:30:43,658 iteration 4635 : loss : 0.014813, loss_ce: 0.006068
2022-01-13 21:30:45,133 iteration 4636 : loss : 0.031349, loss_ce: 0.013198
2022-01-13 21:30:46,476 iteration 4637 : loss : 0.030347, loss_ce: 0.010284
2022-01-13 21:30:47,959 iteration 4638 : loss : 0.045451, loss_ce: 0.018641
2022-01-13 21:30:49,378 iteration 4639 : loss : 0.034049, loss_ce: 0.014318
2022-01-13 21:30:50,873 iteration 4640 : loss : 0.034490, loss_ce: 0.015503
2022-01-13 21:30:52,294 iteration 4641 : loss : 0.038096, loss_ce: 0.014363
 68%|███████████████████▊         | 273/400 [1:56:24<52:18, 24.71s/it]2022-01-13 21:30:53,713 iteration 4642 : loss : 0.022693, loss_ce: 0.005329
2022-01-13 21:30:55,087 iteration 4643 : loss : 0.021512, loss_ce: 0.007647
2022-01-13 21:30:56,520 iteration 4644 : loss : 0.032138, loss_ce: 0.011468
2022-01-13 21:30:57,997 iteration 4645 : loss : 0.033179, loss_ce: 0.016140
2022-01-13 21:30:59,400 iteration 4646 : loss : 0.024778, loss_ce: 0.006829
2022-01-13 21:31:00,702 iteration 4647 : loss : 0.022627, loss_ce: 0.007960
2022-01-13 21:31:02,047 iteration 4648 : loss : 0.045374, loss_ce: 0.016867
2022-01-13 21:31:03,429 iteration 4649 : loss : 0.021850, loss_ce: 0.009344
2022-01-13 21:31:04,859 iteration 4650 : loss : 0.034156, loss_ce: 0.013432
2022-01-13 21:31:06,177 iteration 4651 : loss : 0.024649, loss_ce: 0.011205
2022-01-13 21:31:07,632 iteration 4652 : loss : 0.027342, loss_ce: 0.010769
2022-01-13 21:31:08,984 iteration 4653 : loss : 0.025813, loss_ce: 0.010110
2022-01-13 21:31:10,355 iteration 4654 : loss : 0.057725, loss_ce: 0.015656
2022-01-13 21:31:11,837 iteration 4655 : loss : 0.034470, loss_ce: 0.012898
2022-01-13 21:31:13,296 iteration 4656 : loss : 0.025819, loss_ce: 0.011217
2022-01-13 21:31:14,717 iteration 4657 : loss : 0.055102, loss_ce: 0.029099
2022-01-13 21:31:16,136 iteration 4658 : loss : 0.032692, loss_ce: 0.011844
 68%|███████████████████▊         | 274/400 [1:56:47<51:20, 24.45s/it]2022-01-13 21:31:17,603 iteration 4659 : loss : 0.029185, loss_ce: 0.012776
2022-01-13 21:31:19,041 iteration 4660 : loss : 0.033492, loss_ce: 0.016317
2022-01-13 21:31:20,452 iteration 4661 : loss : 0.039360, loss_ce: 0.014334
2022-01-13 21:31:21,784 iteration 4662 : loss : 0.027929, loss_ce: 0.009533
2022-01-13 21:31:23,218 iteration 4663 : loss : 0.026172, loss_ce: 0.010924
2022-01-13 21:31:24,568 iteration 4664 : loss : 0.020013, loss_ce: 0.007268
2022-01-13 21:31:25,940 iteration 4665 : loss : 0.026410, loss_ce: 0.009408
2022-01-13 21:31:27,217 iteration 4666 : loss : 0.022346, loss_ce: 0.008008
2022-01-13 21:31:28,550 iteration 4667 : loss : 0.019581, loss_ce: 0.008533
2022-01-13 21:31:30,052 iteration 4668 : loss : 0.029311, loss_ce: 0.014429
2022-01-13 21:31:31,385 iteration 4669 : loss : 0.020580, loss_ce: 0.009566
2022-01-13 21:31:32,721 iteration 4670 : loss : 0.029598, loss_ce: 0.012795
2022-01-13 21:31:34,039 iteration 4671 : loss : 0.031648, loss_ce: 0.011476
2022-01-13 21:31:35,527 iteration 4672 : loss : 0.038828, loss_ce: 0.014625
2022-01-13 21:31:36,958 iteration 4673 : loss : 0.021146, loss_ce: 0.009073
2022-01-13 21:31:38,265 iteration 4674 : loss : 0.020140, loss_ce: 0.006109
2022-01-13 21:31:38,265 Training Data Eval:
2022-01-13 21:31:45,046   Average segmentation loss on training set: 0.0141
2022-01-13 21:31:45,046 Validation Data Eval:
2022-01-13 21:31:47,398   Average segmentation loss on validation set: 0.0798
2022-01-13 21:31:48,844 iteration 4675 : loss : 0.029669, loss_ce: 0.012851
 69%|███████████████████▉         | 275/400 [1:57:20<56:06, 26.93s/it]2022-01-13 21:31:50,374 iteration 4676 : loss : 0.039936, loss_ce: 0.013036
2022-01-13 21:31:51,735 iteration 4677 : loss : 0.026456, loss_ce: 0.008403
2022-01-13 21:31:53,131 iteration 4678 : loss : 0.025508, loss_ce: 0.007791
2022-01-13 21:31:54,583 iteration 4679 : loss : 0.054532, loss_ce: 0.017254
2022-01-13 21:31:55,956 iteration 4680 : loss : 0.018216, loss_ce: 0.006920
2022-01-13 21:31:57,317 iteration 4681 : loss : 0.050964, loss_ce: 0.014915
2022-01-13 21:31:58,663 iteration 4682 : loss : 0.019955, loss_ce: 0.007701
2022-01-13 21:31:59,937 iteration 4683 : loss : 0.027950, loss_ce: 0.007880
2022-01-13 21:32:01,361 iteration 4684 : loss : 0.025113, loss_ce: 0.011636
2022-01-13 21:32:02,767 iteration 4685 : loss : 0.034562, loss_ce: 0.011756
2022-01-13 21:32:04,137 iteration 4686 : loss : 0.033366, loss_ce: 0.012084
2022-01-13 21:32:05,482 iteration 4687 : loss : 0.024467, loss_ce: 0.010909
2022-01-13 21:32:06,792 iteration 4688 : loss : 0.021977, loss_ce: 0.010256
2022-01-13 21:32:08,092 iteration 4689 : loss : 0.015194, loss_ce: 0.006526
2022-01-13 21:32:09,419 iteration 4690 : loss : 0.026924, loss_ce: 0.011418
2022-01-13 21:32:10,828 iteration 4691 : loss : 0.042559, loss_ce: 0.025696
2022-01-13 21:32:12,176 iteration 4692 : loss : 0.025687, loss_ce: 0.007738
 69%|████████████████████         | 276/400 [1:57:43<53:25, 25.85s/it]2022-01-13 21:32:13,666 iteration 4693 : loss : 0.030171, loss_ce: 0.010841
2022-01-13 21:32:15,083 iteration 4694 : loss : 0.039329, loss_ce: 0.013779
2022-01-13 21:32:16,316 iteration 4695 : loss : 0.020788, loss_ce: 0.006731
2022-01-13 21:32:17,762 iteration 4696 : loss : 0.037415, loss_ce: 0.014816
2022-01-13 21:32:19,101 iteration 4697 : loss : 0.024722, loss_ce: 0.008966
2022-01-13 21:32:20,475 iteration 4698 : loss : 0.031525, loss_ce: 0.015385
2022-01-13 21:32:21,907 iteration 4699 : loss : 0.024167, loss_ce: 0.011605
2022-01-13 21:32:23,234 iteration 4700 : loss : 0.030876, loss_ce: 0.013313
2022-01-13 21:32:24,707 iteration 4701 : loss : 0.026251, loss_ce: 0.010973
2022-01-13 21:32:26,058 iteration 4702 : loss : 0.024436, loss_ce: 0.009688
2022-01-13 21:32:27,385 iteration 4703 : loss : 0.026694, loss_ce: 0.007284
2022-01-13 21:32:28,753 iteration 4704 : loss : 0.022185, loss_ce: 0.007158
2022-01-13 21:32:29,994 iteration 4705 : loss : 0.014340, loss_ce: 0.006262
2022-01-13 21:32:31,358 iteration 4706 : loss : 0.023106, loss_ce: 0.005895
2022-01-13 21:32:32,777 iteration 4707 : loss : 0.033130, loss_ce: 0.015108
2022-01-13 21:32:34,213 iteration 4708 : loss : 0.020472, loss_ce: 0.006518
2022-01-13 21:32:35,621 iteration 4709 : loss : 0.026099, loss_ce: 0.008106
 69%|████████████████████         | 277/400 [1:58:07<51:30, 25.13s/it]2022-01-13 21:32:37,074 iteration 4710 : loss : 0.035065, loss_ce: 0.007836
2022-01-13 21:32:38,596 iteration 4711 : loss : 0.033027, loss_ce: 0.014395
2022-01-13 21:32:39,954 iteration 4712 : loss : 0.027927, loss_ce: 0.010754
2022-01-13 21:32:41,325 iteration 4713 : loss : 0.017853, loss_ce: 0.006872
2022-01-13 21:32:42,714 iteration 4714 : loss : 0.024170, loss_ce: 0.008459
2022-01-13 21:32:44,154 iteration 4715 : loss : 0.025549, loss_ce: 0.008039
2022-01-13 21:32:45,550 iteration 4716 : loss : 0.026025, loss_ce: 0.010971
2022-01-13 21:32:46,910 iteration 4717 : loss : 0.031858, loss_ce: 0.017212
2022-01-13 21:32:48,224 iteration 4718 : loss : 0.026116, loss_ce: 0.009371
2022-01-13 21:32:49,533 iteration 4719 : loss : 0.023511, loss_ce: 0.010529
2022-01-13 21:32:50,876 iteration 4720 : loss : 0.020142, loss_ce: 0.007998
2022-01-13 21:32:52,226 iteration 4721 : loss : 0.024599, loss_ce: 0.009754
2022-01-13 21:32:53,649 iteration 4722 : loss : 0.034698, loss_ce: 0.012592
2022-01-13 21:32:55,018 iteration 4723 : loss : 0.020989, loss_ce: 0.008132
2022-01-13 21:32:56,323 iteration 4724 : loss : 0.018453, loss_ce: 0.007119
2022-01-13 21:32:57,626 iteration 4725 : loss : 0.019793, loss_ce: 0.008123
2022-01-13 21:32:58,991 iteration 4726 : loss : 0.023623, loss_ce: 0.008970
 70%|████████████████████▏        | 278/400 [1:58:30<50:01, 24.60s/it]2022-01-13 21:33:00,477 iteration 4727 : loss : 0.028472, loss_ce: 0.009380
2022-01-13 21:33:01,791 iteration 4728 : loss : 0.017954, loss_ce: 0.006968
2022-01-13 21:33:03,120 iteration 4729 : loss : 0.022617, loss_ce: 0.007915
2022-01-13 21:33:04,447 iteration 4730 : loss : 0.032028, loss_ce: 0.011654
2022-01-13 21:33:05,868 iteration 4731 : loss : 0.020804, loss_ce: 0.007422
2022-01-13 21:33:07,254 iteration 4732 : loss : 0.028572, loss_ce: 0.009887
2022-01-13 21:33:08,628 iteration 4733 : loss : 0.023993, loss_ce: 0.009677
2022-01-13 21:33:09,976 iteration 4734 : loss : 0.023113, loss_ce: 0.008863
2022-01-13 21:33:11,433 iteration 4735 : loss : 0.046702, loss_ce: 0.015996
2022-01-13 21:33:12,736 iteration 4736 : loss : 0.036782, loss_ce: 0.017089
2022-01-13 21:33:14,174 iteration 4737 : loss : 0.031204, loss_ce: 0.014316
2022-01-13 21:33:15,545 iteration 4738 : loss : 0.025402, loss_ce: 0.008991
2022-01-13 21:33:16,909 iteration 4739 : loss : 0.028672, loss_ce: 0.011741
2022-01-13 21:33:18,325 iteration 4740 : loss : 0.030648, loss_ce: 0.012834
2022-01-13 21:33:19,675 iteration 4741 : loss : 0.028236, loss_ce: 0.008753
2022-01-13 21:33:21,033 iteration 4742 : loss : 0.024990, loss_ce: 0.011956
2022-01-13 21:33:22,492 iteration 4743 : loss : 0.030632, loss_ce: 0.010678
 70%|████████████████████▏        | 279/400 [1:58:54<48:56, 24.27s/it]2022-01-13 21:33:23,976 iteration 4744 : loss : 0.024011, loss_ce: 0.008276
2022-01-13 21:33:25,352 iteration 4745 : loss : 0.041038, loss_ce: 0.012878
2022-01-13 21:33:26,681 iteration 4746 : loss : 0.022905, loss_ce: 0.011442
2022-01-13 21:33:28,022 iteration 4747 : loss : 0.028309, loss_ce: 0.009325
2022-01-13 21:33:29,401 iteration 4748 : loss : 0.034241, loss_ce: 0.014541
2022-01-13 21:33:30,784 iteration 4749 : loss : 0.038301, loss_ce: 0.014792
2022-01-13 21:33:32,208 iteration 4750 : loss : 0.025663, loss_ce: 0.009986
2022-01-13 21:33:33,571 iteration 4751 : loss : 0.026605, loss_ce: 0.010594
2022-01-13 21:33:34,994 iteration 4752 : loss : 0.021923, loss_ce: 0.007487
2022-01-13 21:33:36,417 iteration 4753 : loss : 0.024219, loss_ce: 0.009083
2022-01-13 21:33:37,813 iteration 4754 : loss : 0.019515, loss_ce: 0.006605
2022-01-13 21:33:39,312 iteration 4755 : loss : 0.027262, loss_ce: 0.008407
2022-01-13 21:33:40,653 iteration 4756 : loss : 0.020821, loss_ce: 0.010288
2022-01-13 21:33:42,016 iteration 4757 : loss : 0.021260, loss_ce: 0.008850
2022-01-13 21:33:43,367 iteration 4758 : loss : 0.023095, loss_ce: 0.007451
2022-01-13 21:33:44,737 iteration 4759 : loss : 0.016277, loss_ce: 0.005896
2022-01-13 21:33:44,737 Training Data Eval:
2022-01-13 21:33:51,539   Average segmentation loss on training set: 0.0136
2022-01-13 21:33:51,540 Validation Data Eval:
2022-01-13 21:33:53,866   Average segmentation loss on validation set: 0.0710
2022-01-13 21:33:55,205 iteration 4760 : loss : 0.024515, loss_ce: 0.011762
 70%|████████████████████▎        | 280/400 [1:59:26<53:36, 26.80s/it]2022-01-13 21:33:56,613 iteration 4761 : loss : 0.024422, loss_ce: 0.009156
2022-01-13 21:33:58,018 iteration 4762 : loss : 0.060435, loss_ce: 0.018395
2022-01-13 21:33:59,344 iteration 4763 : loss : 0.019393, loss_ce: 0.008197
2022-01-13 21:34:00,744 iteration 4764 : loss : 0.028058, loss_ce: 0.009998
2022-01-13 21:34:02,109 iteration 4765 : loss : 0.025623, loss_ce: 0.012604
2022-01-13 21:34:03,545 iteration 4766 : loss : 0.035765, loss_ce: 0.013265
2022-01-13 21:34:04,939 iteration 4767 : loss : 0.021671, loss_ce: 0.008845
2022-01-13 21:34:06,282 iteration 4768 : loss : 0.031105, loss_ce: 0.009795
2022-01-13 21:34:07,691 iteration 4769 : loss : 0.038046, loss_ce: 0.016414
2022-01-13 21:34:09,109 iteration 4770 : loss : 0.031102, loss_ce: 0.011938
2022-01-13 21:34:10,423 iteration 4771 : loss : 0.027812, loss_ce: 0.009693
2022-01-13 21:34:11,844 iteration 4772 : loss : 0.024850, loss_ce: 0.010674
2022-01-13 21:34:13,247 iteration 4773 : loss : 0.025363, loss_ce: 0.009734
2022-01-13 21:34:14,640 iteration 4774 : loss : 0.026521, loss_ce: 0.011230
2022-01-13 21:34:15,978 iteration 4775 : loss : 0.046956, loss_ce: 0.016066
2022-01-13 21:34:17,342 iteration 4776 : loss : 0.024561, loss_ce: 0.013089
2022-01-13 21:34:18,872 iteration 4777 : loss : 0.028910, loss_ce: 0.013509
 70%|████████████████████▎        | 281/400 [1:59:50<51:17, 25.86s/it]2022-01-13 21:34:20,235 iteration 4778 : loss : 0.016928, loss_ce: 0.004920
2022-01-13 21:34:21,583 iteration 4779 : loss : 0.037037, loss_ce: 0.013142
2022-01-13 21:34:22,881 iteration 4780 : loss : 0.016314, loss_ce: 0.005478
2022-01-13 21:34:24,223 iteration 4781 : loss : 0.027321, loss_ce: 0.006840
2022-01-13 21:34:25,676 iteration 4782 : loss : 0.030175, loss_ce: 0.016025
2022-01-13 21:34:27,052 iteration 4783 : loss : 0.018559, loss_ce: 0.008401
2022-01-13 21:34:28,363 iteration 4784 : loss : 0.018237, loss_ce: 0.007580
2022-01-13 21:34:29,801 iteration 4785 : loss : 0.023540, loss_ce: 0.007889
2022-01-13 21:34:31,209 iteration 4786 : loss : 0.031523, loss_ce: 0.010252
2022-01-13 21:34:32,606 iteration 4787 : loss : 0.024689, loss_ce: 0.007872
2022-01-13 21:34:34,011 iteration 4788 : loss : 0.020645, loss_ce: 0.007519
2022-01-13 21:34:35,326 iteration 4789 : loss : 0.019587, loss_ce: 0.009307
2022-01-13 21:34:36,790 iteration 4790 : loss : 0.051374, loss_ce: 0.016084
2022-01-13 21:34:38,143 iteration 4791 : loss : 0.022025, loss_ce: 0.010094
2022-01-13 21:34:39,566 iteration 4792 : loss : 0.033052, loss_ce: 0.009594
2022-01-13 21:34:40,897 iteration 4793 : loss : 0.019499, loss_ce: 0.007047
2022-01-13 21:34:42,182 iteration 4794 : loss : 0.022735, loss_ce: 0.006996
 70%|████████████████████▍        | 282/400 [2:00:13<49:21, 25.09s/it]2022-01-13 21:34:43,631 iteration 4795 : loss : 0.025437, loss_ce: 0.007806
2022-01-13 21:34:45,020 iteration 4796 : loss : 0.022180, loss_ce: 0.008037
2022-01-13 21:34:46,419 iteration 4797 : loss : 0.030510, loss_ce: 0.014490
2022-01-13 21:34:47,861 iteration 4798 : loss : 0.044969, loss_ce: 0.011428
2022-01-13 21:34:49,243 iteration 4799 : loss : 0.015483, loss_ce: 0.004988
2022-01-13 21:34:50,622 iteration 4800 : loss : 0.023845, loss_ce: 0.006974
2022-01-13 21:34:52,085 iteration 4801 : loss : 0.027651, loss_ce: 0.010496
2022-01-13 21:34:53,385 iteration 4802 : loss : 0.015912, loss_ce: 0.006620
2022-01-13 21:34:54,734 iteration 4803 : loss : 0.023163, loss_ce: 0.010621
2022-01-13 21:34:56,181 iteration 4804 : loss : 0.051087, loss_ce: 0.012890
2022-01-13 21:34:57,616 iteration 4805 : loss : 0.039491, loss_ce: 0.014560
2022-01-13 21:34:59,059 iteration 4806 : loss : 0.018838, loss_ce: 0.008068
2022-01-13 21:35:00,368 iteration 4807 : loss : 0.021049, loss_ce: 0.008800
2022-01-13 21:35:01,667 iteration 4808 : loss : 0.018376, loss_ce: 0.008431
2022-01-13 21:35:03,048 iteration 4809 : loss : 0.029222, loss_ce: 0.014814
2022-01-13 21:35:04,413 iteration 4810 : loss : 0.035055, loss_ce: 0.009956
2022-01-13 21:35:05,800 iteration 4811 : loss : 0.026537, loss_ce: 0.009260
 71%|████████████████████▌        | 283/400 [2:00:37<48:04, 24.65s/it]2022-01-13 21:35:07,171 iteration 4812 : loss : 0.026824, loss_ce: 0.009703
2022-01-13 21:35:08,562 iteration 4813 : loss : 0.031350, loss_ce: 0.006987
2022-01-13 21:35:09,986 iteration 4814 : loss : 0.027561, loss_ce: 0.007167
2022-01-13 21:35:11,294 iteration 4815 : loss : 0.024313, loss_ce: 0.011589
2022-01-13 21:35:12,766 iteration 4816 : loss : 0.027223, loss_ce: 0.013593
2022-01-13 21:35:14,125 iteration 4817 : loss : 0.035955, loss_ce: 0.012592
2022-01-13 21:35:15,483 iteration 4818 : loss : 0.026613, loss_ce: 0.011072
2022-01-13 21:35:16,777 iteration 4819 : loss : 0.023480, loss_ce: 0.010035
2022-01-13 21:35:18,114 iteration 4820 : loss : 0.030080, loss_ce: 0.014540
2022-01-13 21:35:19,576 iteration 4821 : loss : 0.039025, loss_ce: 0.018155
2022-01-13 21:35:21,029 iteration 4822 : loss : 0.035397, loss_ce: 0.012984
2022-01-13 21:35:22,394 iteration 4823 : loss : 0.030029, loss_ce: 0.014562
2022-01-13 21:35:23,797 iteration 4824 : loss : 0.020778, loss_ce: 0.008673
2022-01-13 21:35:25,148 iteration 4825 : loss : 0.024481, loss_ce: 0.008965
2022-01-13 21:35:26,489 iteration 4826 : loss : 0.021012, loss_ce: 0.006530
2022-01-13 21:35:27,853 iteration 4827 : loss : 0.018754, loss_ce: 0.007816
2022-01-13 21:35:29,187 iteration 4828 : loss : 0.021687, loss_ce: 0.008440
 71%|████████████████████▌        | 284/400 [2:01:00<46:55, 24.27s/it]2022-01-13 21:35:30,558 iteration 4829 : loss : 0.019801, loss_ce: 0.006541
2022-01-13 21:35:31,963 iteration 4830 : loss : 0.020869, loss_ce: 0.010425
2022-01-13 21:35:33,352 iteration 4831 : loss : 0.028637, loss_ce: 0.011525
2022-01-13 21:35:34,707 iteration 4832 : loss : 0.035619, loss_ce: 0.010294
2022-01-13 21:35:36,116 iteration 4833 : loss : 0.032257, loss_ce: 0.014487
2022-01-13 21:35:37,429 iteration 4834 : loss : 0.016928, loss_ce: 0.005900
2022-01-13 21:35:38,915 iteration 4835 : loss : 0.026228, loss_ce: 0.011394
2022-01-13 21:35:40,300 iteration 4836 : loss : 0.033765, loss_ce: 0.009503
2022-01-13 21:35:41,724 iteration 4837 : loss : 0.034351, loss_ce: 0.010653
2022-01-13 21:35:43,087 iteration 4838 : loss : 0.017150, loss_ce: 0.005343
2022-01-13 21:35:44,486 iteration 4839 : loss : 0.030373, loss_ce: 0.012291
2022-01-13 21:35:45,866 iteration 4840 : loss : 0.026262, loss_ce: 0.012703
2022-01-13 21:35:47,165 iteration 4841 : loss : 0.015268, loss_ce: 0.005296
2022-01-13 21:35:48,542 iteration 4842 : loss : 0.022979, loss_ce: 0.009608
2022-01-13 21:35:50,002 iteration 4843 : loss : 0.023030, loss_ce: 0.007030
2022-01-13 21:35:51,376 iteration 4844 : loss : 0.025897, loss_ce: 0.009057
2022-01-13 21:35:51,376 Training Data Eval:
2022-01-13 21:35:58,164   Average segmentation loss on training set: 0.0137
2022-01-13 21:35:58,164 Validation Data Eval:
2022-01-13 21:36:00,516   Average segmentation loss on validation set: 0.0749
2022-01-13 21:36:01,930 iteration 4845 : loss : 0.025501, loss_ce: 0.011873
 71%|████████████████████▋        | 285/400 [2:01:33<51:23, 26.81s/it]2022-01-13 21:36:03,327 iteration 4846 : loss : 0.021936, loss_ce: 0.007956
2022-01-13 21:36:04,664 iteration 4847 : loss : 0.022543, loss_ce: 0.008759
2022-01-13 21:36:06,082 iteration 4848 : loss : 0.024389, loss_ce: 0.011873
2022-01-13 21:36:07,483 iteration 4849 : loss : 0.019252, loss_ce: 0.005890
2022-01-13 21:36:08,844 iteration 4850 : loss : 0.024589, loss_ce: 0.008216
2022-01-13 21:36:10,329 iteration 4851 : loss : 0.023853, loss_ce: 0.011096
2022-01-13 21:36:11,690 iteration 4852 : loss : 0.018658, loss_ce: 0.006307
2022-01-13 21:36:13,072 iteration 4853 : loss : 0.022509, loss_ce: 0.009998
2022-01-13 21:36:14,458 iteration 4854 : loss : 0.018230, loss_ce: 0.006916
2022-01-13 21:36:15,800 iteration 4855 : loss : 0.023732, loss_ce: 0.006646
2022-01-13 21:36:17,270 iteration 4856 : loss : 0.030752, loss_ce: 0.013130
2022-01-13 21:36:18,610 iteration 4857 : loss : 0.016149, loss_ce: 0.005776
2022-01-13 21:36:20,062 iteration 4858 : loss : 0.026586, loss_ce: 0.011844
2022-01-13 21:36:21,377 iteration 4859 : loss : 0.014793, loss_ce: 0.006486
2022-01-13 21:36:22,795 iteration 4860 : loss : 0.036285, loss_ce: 0.017533
2022-01-13 21:36:24,137 iteration 4861 : loss : 0.020915, loss_ce: 0.006998
2022-01-13 21:36:25,547 iteration 4862 : loss : 0.022599, loss_ce: 0.013064
 72%|████████████████████▋        | 286/400 [2:01:57<49:07, 25.85s/it]2022-01-13 21:36:27,061 iteration 4863 : loss : 0.026273, loss_ce: 0.007090
2022-01-13 21:36:28,434 iteration 4864 : loss : 0.020204, loss_ce: 0.007389
2022-01-13 21:36:29,781 iteration 4865 : loss : 0.024924, loss_ce: 0.010501
2022-01-13 21:36:31,225 iteration 4866 : loss : 0.020960, loss_ce: 0.006418
2022-01-13 21:36:32,610 iteration 4867 : loss : 0.023432, loss_ce: 0.008795
2022-01-13 21:36:33,899 iteration 4868 : loss : 0.025668, loss_ce: 0.011017
2022-01-13 21:36:35,369 iteration 4869 : loss : 0.031472, loss_ce: 0.016187
2022-01-13 21:36:36,744 iteration 4870 : loss : 0.014842, loss_ce: 0.005115
2022-01-13 21:36:38,219 iteration 4871 : loss : 0.033480, loss_ce: 0.012026
2022-01-13 21:36:39,530 iteration 4872 : loss : 0.015888, loss_ce: 0.005361
2022-01-13 21:36:40,996 iteration 4873 : loss : 0.020976, loss_ce: 0.009328
2022-01-13 21:36:42,394 iteration 4874 : loss : 0.034157, loss_ce: 0.010284
2022-01-13 21:36:43,754 iteration 4875 : loss : 0.029238, loss_ce: 0.012082
2022-01-13 21:36:45,045 iteration 4876 : loss : 0.023190, loss_ce: 0.007291
2022-01-13 21:36:46,467 iteration 4877 : loss : 0.038615, loss_ce: 0.020366
2022-01-13 21:36:47,914 iteration 4878 : loss : 0.032154, loss_ce: 0.010408
2022-01-13 21:36:49,289 iteration 4879 : loss : 0.016820, loss_ce: 0.006173
 72%|████████████████████▊        | 287/400 [2:02:21<47:29, 25.22s/it]2022-01-13 21:36:50,702 iteration 4880 : loss : 0.021068, loss_ce: 0.008685
2022-01-13 21:36:52,018 iteration 4881 : loss : 0.017847, loss_ce: 0.007236
2022-01-13 21:36:53,303 iteration 4882 : loss : 0.017634, loss_ce: 0.007436
2022-01-13 21:36:54,717 iteration 4883 : loss : 0.022186, loss_ce: 0.009826
2022-01-13 21:36:56,153 iteration 4884 : loss : 0.024004, loss_ce: 0.007321
2022-01-13 21:36:57,417 iteration 4885 : loss : 0.016346, loss_ce: 0.006397
2022-01-13 21:36:58,787 iteration 4886 : loss : 0.023593, loss_ce: 0.006152
2022-01-13 21:37:00,103 iteration 4887 : loss : 0.020873, loss_ce: 0.005642
2022-01-13 21:37:01,492 iteration 4888 : loss : 0.023729, loss_ce: 0.007045
2022-01-13 21:37:02,868 iteration 4889 : loss : 0.030180, loss_ce: 0.014998
2022-01-13 21:37:04,194 iteration 4890 : loss : 0.023319, loss_ce: 0.012557
2022-01-13 21:37:05,446 iteration 4891 : loss : 0.013472, loss_ce: 0.005182
2022-01-13 21:37:06,853 iteration 4892 : loss : 0.017719, loss_ce: 0.007638
2022-01-13 21:37:08,221 iteration 4893 : loss : 0.027309, loss_ce: 0.013788
2022-01-13 21:37:09,580 iteration 4894 : loss : 0.017087, loss_ce: 0.007964
2022-01-13 21:37:10,924 iteration 4895 : loss : 0.017275, loss_ce: 0.003842
2022-01-13 21:37:12,247 iteration 4896 : loss : 0.031169, loss_ce: 0.008539
 72%|████████████████████▉        | 288/400 [2:02:44<45:48, 24.54s/it]2022-01-13 21:37:13,642 iteration 4897 : loss : 0.021925, loss_ce: 0.008196
2022-01-13 21:37:15,085 iteration 4898 : loss : 0.041469, loss_ce: 0.021524
2022-01-13 21:37:16,459 iteration 4899 : loss : 0.014500, loss_ce: 0.004465
2022-01-13 21:37:17,821 iteration 4900 : loss : 0.025445, loss_ce: 0.010389
2022-01-13 21:37:19,166 iteration 4901 : loss : 0.031773, loss_ce: 0.009730
2022-01-13 21:37:20,512 iteration 4902 : loss : 0.018337, loss_ce: 0.007055
2022-01-13 21:37:21,906 iteration 4903 : loss : 0.027325, loss_ce: 0.012895
2022-01-13 21:37:23,173 iteration 4904 : loss : 0.019136, loss_ce: 0.006256
2022-01-13 21:37:24,496 iteration 4905 : loss : 0.020666, loss_ce: 0.006214
2022-01-13 21:37:25,886 iteration 4906 : loss : 0.023093, loss_ce: 0.009300
2022-01-13 21:37:27,232 iteration 4907 : loss : 0.028169, loss_ce: 0.011907
2022-01-13 21:37:28,671 iteration 4908 : loss : 0.022095, loss_ce: 0.009572
2022-01-13 21:37:30,069 iteration 4909 : loss : 0.018995, loss_ce: 0.006089
2022-01-13 21:37:31,388 iteration 4910 : loss : 0.020875, loss_ce: 0.010150
2022-01-13 21:37:32,729 iteration 4911 : loss : 0.015720, loss_ce: 0.005978
2022-01-13 21:37:34,124 iteration 4912 : loss : 0.021107, loss_ce: 0.010014
2022-01-13 21:37:35,482 iteration 4913 : loss : 0.033050, loss_ce: 0.012027
 72%|████████████████████▉        | 289/400 [2:03:07<44:40, 24.15s/it]2022-01-13 21:37:36,947 iteration 4914 : loss : 0.019523, loss_ce: 0.007111
2022-01-13 21:37:38,279 iteration 4915 : loss : 0.018360, loss_ce: 0.006736
2022-01-13 21:37:39,621 iteration 4916 : loss : 0.015134, loss_ce: 0.004259
2022-01-13 21:37:40,988 iteration 4917 : loss : 0.022260, loss_ce: 0.006227
2022-01-13 21:37:42,381 iteration 4918 : loss : 0.022506, loss_ce: 0.009269
2022-01-13 21:37:43,902 iteration 4919 : loss : 0.033261, loss_ce: 0.014045
2022-01-13 21:37:45,261 iteration 4920 : loss : 0.017263, loss_ce: 0.007048
2022-01-13 21:37:46,594 iteration 4921 : loss : 0.024252, loss_ce: 0.014244
2022-01-13 21:37:47,891 iteration 4922 : loss : 0.019292, loss_ce: 0.005399
2022-01-13 21:37:49,302 iteration 4923 : loss : 0.025776, loss_ce: 0.010090
2022-01-13 21:37:50,743 iteration 4924 : loss : 0.027305, loss_ce: 0.015888
2022-01-13 21:37:52,178 iteration 4925 : loss : 0.021112, loss_ce: 0.008521
2022-01-13 21:37:53,603 iteration 4926 : loss : 0.021635, loss_ce: 0.011613
2022-01-13 21:37:54,960 iteration 4927 : loss : 0.023907, loss_ce: 0.010120
2022-01-13 21:37:56,390 iteration 4928 : loss : 0.041595, loss_ce: 0.014838
2022-01-13 21:37:57,841 iteration 4929 : loss : 0.025479, loss_ce: 0.012301
2022-01-13 21:37:57,841 Training Data Eval:
2022-01-13 21:38:04,648   Average segmentation loss on training set: 0.0125
2022-01-13 21:38:04,649 Validation Data Eval:
2022-01-13 21:38:06,995   Average segmentation loss on validation set: 0.0689
2022-01-13 21:38:12,694 Found new lowest validation loss at iteration 4929! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed1234.pth
2022-01-13 21:38:14,129 iteration 4930 : loss : 0.023483, loss_ce: 0.007295
 72%|█████████████████████        | 290/400 [2:03:45<52:14, 28.50s/it]2022-01-13 21:38:15,539 iteration 4931 : loss : 0.022787, loss_ce: 0.010100
2022-01-13 21:38:16,933 iteration 4932 : loss : 0.024962, loss_ce: 0.013548
2022-01-13 21:38:18,259 iteration 4933 : loss : 0.016821, loss_ce: 0.009023
2022-01-13 21:38:19,687 iteration 4934 : loss : 0.041712, loss_ce: 0.014123
2022-01-13 21:38:21,053 iteration 4935 : loss : 0.029342, loss_ce: 0.010017
2022-01-13 21:38:22,444 iteration 4936 : loss : 0.020835, loss_ce: 0.008433
2022-01-13 21:38:23,826 iteration 4937 : loss : 0.015689, loss_ce: 0.006439
2022-01-13 21:38:25,249 iteration 4938 : loss : 0.038798, loss_ce: 0.014322
2022-01-13 21:38:26,671 iteration 4939 : loss : 0.029625, loss_ce: 0.011193
2022-01-13 21:38:28,022 iteration 4940 : loss : 0.021649, loss_ce: 0.009333
2022-01-13 21:38:29,407 iteration 4941 : loss : 0.025517, loss_ce: 0.012071
2022-01-13 21:38:30,795 iteration 4942 : loss : 0.021082, loss_ce: 0.006777
2022-01-13 21:38:32,262 iteration 4943 : loss : 0.049221, loss_ce: 0.010253
2022-01-13 21:38:33,635 iteration 4944 : loss : 0.030645, loss_ce: 0.009404
2022-01-13 21:38:35,054 iteration 4945 : loss : 0.035595, loss_ce: 0.015531
2022-01-13 21:38:36,489 iteration 4946 : loss : 0.032141, loss_ce: 0.009322
2022-01-13 21:38:37,848 iteration 4947 : loss : 0.035244, loss_ce: 0.012120
 73%|█████████████████████        | 291/400 [2:04:09<49:10, 27.07s/it]2022-01-13 21:38:39,303 iteration 4948 : loss : 0.044023, loss_ce: 0.014537
2022-01-13 21:38:40,654 iteration 4949 : loss : 0.028990, loss_ce: 0.013353
2022-01-13 21:38:42,076 iteration 4950 : loss : 0.024071, loss_ce: 0.012325
2022-01-13 21:38:43,504 iteration 4951 : loss : 0.025313, loss_ce: 0.008930
2022-01-13 21:38:44,902 iteration 4952 : loss : 0.017330, loss_ce: 0.009586
2022-01-13 21:38:46,315 iteration 4953 : loss : 0.019874, loss_ce: 0.007936
2022-01-13 21:38:47,669 iteration 4954 : loss : 0.018105, loss_ce: 0.006618
2022-01-13 21:38:48,981 iteration 4955 : loss : 0.027871, loss_ce: 0.008508
2022-01-13 21:38:50,342 iteration 4956 : loss : 0.034834, loss_ce: 0.011422
2022-01-13 21:38:51,629 iteration 4957 : loss : 0.017835, loss_ce: 0.007396
2022-01-13 21:38:53,007 iteration 4958 : loss : 0.026313, loss_ce: 0.013944
2022-01-13 21:38:54,386 iteration 4959 : loss : 0.026378, loss_ce: 0.010983
2022-01-13 21:38:55,684 iteration 4960 : loss : 0.019138, loss_ce: 0.007507
2022-01-13 21:38:57,066 iteration 4961 : loss : 0.020106, loss_ce: 0.008506
2022-01-13 21:38:58,378 iteration 4962 : loss : 0.030140, loss_ce: 0.008984
2022-01-13 21:38:59,720 iteration 4963 : loss : 0.019485, loss_ce: 0.007770
2022-01-13 21:39:01,136 iteration 4964 : loss : 0.024973, loss_ce: 0.008963
 73%|█████████████████████▏       | 292/400 [2:04:32<46:40, 25.93s/it]2022-01-13 21:39:02,655 iteration 4965 : loss : 0.031816, loss_ce: 0.012792
2022-01-13 21:39:04,087 iteration 4966 : loss : 0.034100, loss_ce: 0.012894
2022-01-13 21:39:05,472 iteration 4967 : loss : 0.023983, loss_ce: 0.010866
2022-01-13 21:39:06,872 iteration 4968 : loss : 0.027349, loss_ce: 0.013550
2022-01-13 21:39:08,364 iteration 4969 : loss : 0.040121, loss_ce: 0.013636
2022-01-13 21:39:09,712 iteration 4970 : loss : 0.016246, loss_ce: 0.007128
2022-01-13 21:39:11,070 iteration 4971 : loss : 0.018953, loss_ce: 0.010402
2022-01-13 21:39:12,508 iteration 4972 : loss : 0.032954, loss_ce: 0.015137
2022-01-13 21:39:13,893 iteration 4973 : loss : 0.022968, loss_ce: 0.008401
2022-01-13 21:39:15,409 iteration 4974 : loss : 0.027730, loss_ce: 0.009713
2022-01-13 21:39:16,776 iteration 4975 : loss : 0.018002, loss_ce: 0.005341
2022-01-13 21:39:18,088 iteration 4976 : loss : 0.018771, loss_ce: 0.007228
2022-01-13 21:39:19,492 iteration 4977 : loss : 0.043318, loss_ce: 0.007400
2022-01-13 21:39:20,854 iteration 4978 : loss : 0.024819, loss_ce: 0.005898
2022-01-13 21:39:22,221 iteration 4979 : loss : 0.019657, loss_ce: 0.007483
2022-01-13 21:39:23,607 iteration 4980 : loss : 0.022542, loss_ce: 0.006103
2022-01-13 21:39:24,979 iteration 4981 : loss : 0.026975, loss_ce: 0.008845
 73%|█████████████████████▏       | 293/400 [2:04:56<45:07, 25.31s/it]2022-01-13 21:39:26,388 iteration 4982 : loss : 0.019104, loss_ce: 0.008773
2022-01-13 21:39:27,754 iteration 4983 : loss : 0.020282, loss_ce: 0.008226
2022-01-13 21:39:29,224 iteration 4984 : loss : 0.024434, loss_ce: 0.008412
2022-01-13 21:39:30,532 iteration 4985 : loss : 0.016287, loss_ce: 0.004319
2022-01-13 21:39:31,987 iteration 4986 : loss : 0.038091, loss_ce: 0.017565
2022-01-13 21:39:33,309 iteration 4987 : loss : 0.022318, loss_ce: 0.006821
2022-01-13 21:39:34,696 iteration 4988 : loss : 0.024145, loss_ce: 0.007385
2022-01-13 21:39:36,133 iteration 4989 : loss : 0.024299, loss_ce: 0.008323
2022-01-13 21:39:37,594 iteration 4990 : loss : 0.023221, loss_ce: 0.009650
2022-01-13 21:39:38,987 iteration 4991 : loss : 0.028201, loss_ce: 0.008034
2022-01-13 21:39:40,283 iteration 4992 : loss : 0.021255, loss_ce: 0.011428
2022-01-13 21:39:41,638 iteration 4993 : loss : 0.024802, loss_ce: 0.009054
2022-01-13 21:39:42,964 iteration 4994 : loss : 0.022000, loss_ce: 0.006797
2022-01-13 21:39:44,302 iteration 4995 : loss : 0.028274, loss_ce: 0.013193
2022-01-13 21:39:45,731 iteration 4996 : loss : 0.033685, loss_ce: 0.008960
2022-01-13 21:39:47,034 iteration 4997 : loss : 0.017072, loss_ce: 0.004925
2022-01-13 21:39:48,353 iteration 4998 : loss : 0.018917, loss_ce: 0.007824
 74%|█████████████████████▎       | 294/400 [2:05:20<43:41, 24.73s/it]2022-01-13 21:39:49,749 iteration 4999 : loss : 0.019012, loss_ce: 0.006899
2022-01-13 21:39:51,097 iteration 5000 : loss : 0.018560, loss_ce: 0.007033
2022-01-13 21:39:52,454 iteration 5001 : loss : 0.022278, loss_ce: 0.009949
2022-01-13 21:39:53,801 iteration 5002 : loss : 0.014079, loss_ce: 0.004697
2022-01-13 21:39:55,193 iteration 5003 : loss : 0.072790, loss_ce: 0.010450
2022-01-13 21:39:56,558 iteration 5004 : loss : 0.025030, loss_ce: 0.009336
2022-01-13 21:39:57,920 iteration 5005 : loss : 0.020952, loss_ce: 0.008867
2022-01-13 21:39:59,369 iteration 5006 : loss : 0.018923, loss_ce: 0.007428
2022-01-13 21:40:00,798 iteration 5007 : loss : 0.033527, loss_ce: 0.015242
2022-01-13 21:40:02,249 iteration 5008 : loss : 0.028148, loss_ce: 0.012755
2022-01-13 21:40:03,681 iteration 5009 : loss : 0.023467, loss_ce: 0.006761
2022-01-13 21:40:05,102 iteration 5010 : loss : 0.036497, loss_ce: 0.012891
2022-01-13 21:40:06,456 iteration 5011 : loss : 0.020931, loss_ce: 0.010339
2022-01-13 21:40:07,844 iteration 5012 : loss : 0.021016, loss_ce: 0.007586
2022-01-13 21:40:09,162 iteration 5013 : loss : 0.027895, loss_ce: 0.009822
2022-01-13 21:40:10,528 iteration 5014 : loss : 0.036619, loss_ce: 0.015480
2022-01-13 21:40:10,528 Training Data Eval:
2022-01-13 21:40:17,298   Average segmentation loss on training set: 0.0126
2022-01-13 21:40:17,299 Validation Data Eval:
2022-01-13 21:40:19,649   Average segmentation loss on validation set: 0.0993
2022-01-13 21:40:21,013 iteration 5015 : loss : 0.019898, loss_ce: 0.006556
 74%|█████████████████████▍       | 295/400 [2:05:52<47:25, 27.10s/it]2022-01-13 21:40:22,434 iteration 5016 : loss : 0.030225, loss_ce: 0.016804
2022-01-13 21:40:23,782 iteration 5017 : loss : 0.018179, loss_ce: 0.007365
2022-01-13 21:40:25,153 iteration 5018 : loss : 0.023078, loss_ce: 0.010033
2022-01-13 21:40:26,541 iteration 5019 : loss : 0.016138, loss_ce: 0.005219
2022-01-13 21:40:27,959 iteration 5020 : loss : 0.027125, loss_ce: 0.007722
2022-01-13 21:40:29,377 iteration 5021 : loss : 0.030272, loss_ce: 0.017131
2022-01-13 21:40:30,698 iteration 5022 : loss : 0.018623, loss_ce: 0.006419
2022-01-13 21:40:32,072 iteration 5023 : loss : 0.025092, loss_ce: 0.006922
2022-01-13 21:40:33,544 iteration 5024 : loss : 0.021165, loss_ce: 0.005464
2022-01-13 21:40:34,987 iteration 5025 : loss : 0.040768, loss_ce: 0.006263
2022-01-13 21:40:36,376 iteration 5026 : loss : 0.028580, loss_ce: 0.012517
2022-01-13 21:40:37,728 iteration 5027 : loss : 0.026885, loss_ce: 0.011295
2022-01-13 21:40:39,082 iteration 5028 : loss : 0.022701, loss_ce: 0.008298
2022-01-13 21:40:40,540 iteration 5029 : loss : 0.026082, loss_ce: 0.006601
2022-01-13 21:40:41,915 iteration 5030 : loss : 0.022523, loss_ce: 0.011383
2022-01-13 21:40:43,362 iteration 5031 : loss : 0.029535, loss_ce: 0.013227
2022-01-13 21:40:44,745 iteration 5032 : loss : 0.024051, loss_ce: 0.011394
 74%|█████████████████████▍       | 296/400 [2:06:16<45:13, 26.09s/it]2022-01-13 21:40:46,294 iteration 5033 : loss : 0.035145, loss_ce: 0.010561
2022-01-13 21:40:47,657 iteration 5034 : loss : 0.022210, loss_ce: 0.006479
2022-01-13 21:40:49,001 iteration 5035 : loss : 0.023838, loss_ce: 0.010725
2022-01-13 21:40:50,363 iteration 5036 : loss : 0.020366, loss_ce: 0.008254
2022-01-13 21:40:51,740 iteration 5037 : loss : 0.040831, loss_ce: 0.015206
2022-01-13 21:40:53,101 iteration 5038 : loss : 0.028693, loss_ce: 0.007946
2022-01-13 21:40:54,561 iteration 5039 : loss : 0.026222, loss_ce: 0.013215
2022-01-13 21:40:55,944 iteration 5040 : loss : 0.018082, loss_ce: 0.005415
2022-01-13 21:40:57,387 iteration 5041 : loss : 0.023648, loss_ce: 0.008868
2022-01-13 21:40:58,723 iteration 5042 : loss : 0.020535, loss_ce: 0.008137
2022-01-13 21:41:00,098 iteration 5043 : loss : 0.019172, loss_ce: 0.008849
2022-01-13 21:41:01,481 iteration 5044 : loss : 0.024337, loss_ce: 0.011055
2022-01-13 21:41:02,923 iteration 5045 : loss : 0.030025, loss_ce: 0.011928
2022-01-13 21:41:04,317 iteration 5046 : loss : 0.023720, loss_ce: 0.006097
2022-01-13 21:41:05,679 iteration 5047 : loss : 0.027922, loss_ce: 0.008581
2022-01-13 21:41:07,023 iteration 5048 : loss : 0.021094, loss_ce: 0.008027
2022-01-13 21:41:08,373 iteration 5049 : loss : 0.016580, loss_ce: 0.006484
 74%|█████████████████████▌       | 297/400 [2:06:40<43:31, 25.36s/it]2022-01-13 21:41:09,815 iteration 5050 : loss : 0.027493, loss_ce: 0.008939
2022-01-13 21:41:11,177 iteration 5051 : loss : 0.023170, loss_ce: 0.008533
2022-01-13 21:41:12,542 iteration 5052 : loss : 0.022841, loss_ce: 0.009912
2022-01-13 21:41:13,893 iteration 5053 : loss : 0.018039, loss_ce: 0.006720
2022-01-13 21:41:15,267 iteration 5054 : loss : 0.025309, loss_ce: 0.008031
2022-01-13 21:41:16,617 iteration 5055 : loss : 0.026771, loss_ce: 0.008878
2022-01-13 21:41:17,962 iteration 5056 : loss : 0.023670, loss_ce: 0.005922
2022-01-13 21:41:19,406 iteration 5057 : loss : 0.029649, loss_ce: 0.019279
2022-01-13 21:41:20,845 iteration 5058 : loss : 0.030609, loss_ce: 0.014269
2022-01-13 21:41:22,105 iteration 5059 : loss : 0.017834, loss_ce: 0.005522
2022-01-13 21:41:23,480 iteration 5060 : loss : 0.022561, loss_ce: 0.006342
2022-01-13 21:41:24,883 iteration 5061 : loss : 0.018990, loss_ce: 0.008497
2022-01-13 21:41:26,276 iteration 5062 : loss : 0.028627, loss_ce: 0.008229
2022-01-13 21:41:27,709 iteration 5063 : loss : 0.023573, loss_ce: 0.009658
2022-01-13 21:41:29,046 iteration 5064 : loss : 0.021200, loss_ce: 0.008247
2022-01-13 21:41:30,387 iteration 5065 : loss : 0.026008, loss_ce: 0.010036
2022-01-13 21:41:31,762 iteration 5066 : loss : 0.015032, loss_ce: 0.007644
 74%|█████████████████████▌       | 298/400 [2:07:03<42:05, 24.76s/it]2022-01-13 21:41:33,284 iteration 5067 : loss : 0.024471, loss_ce: 0.009551
2022-01-13 21:41:34,704 iteration 5068 : loss : 0.018304, loss_ce: 0.007799
2022-01-13 21:41:36,103 iteration 5069 : loss : 0.023886, loss_ce: 0.007999
2022-01-13 21:41:37,466 iteration 5070 : loss : 0.018480, loss_ce: 0.005946
2022-01-13 21:41:38,904 iteration 5071 : loss : 0.024087, loss_ce: 0.008648
2022-01-13 21:41:40,164 iteration 5072 : loss : 0.017322, loss_ce: 0.005704
2022-01-13 21:41:41,525 iteration 5073 : loss : 0.017920, loss_ce: 0.008934
2022-01-13 21:41:42,937 iteration 5074 : loss : 0.022124, loss_ce: 0.006579
2022-01-13 21:41:44,312 iteration 5075 : loss : 0.021685, loss_ce: 0.008972
2022-01-13 21:41:45,764 iteration 5076 : loss : 0.027533, loss_ce: 0.013570
2022-01-13 21:41:47,119 iteration 5077 : loss : 0.021366, loss_ce: 0.008622
2022-01-13 21:41:48,521 iteration 5078 : loss : 0.018541, loss_ce: 0.005382
2022-01-13 21:41:49,872 iteration 5079 : loss : 0.025128, loss_ce: 0.012729
2022-01-13 21:41:51,257 iteration 5080 : loss : 0.021203, loss_ce: 0.007448
2022-01-13 21:41:52,662 iteration 5081 : loss : 0.018837, loss_ce: 0.008842
2022-01-13 21:41:54,093 iteration 5082 : loss : 0.038866, loss_ce: 0.019700
2022-01-13 21:41:55,493 iteration 5083 : loss : 0.024545, loss_ce: 0.008802
 75%|█████████████████████▋       | 299/400 [2:07:27<41:09, 24.45s/it]2022-01-13 21:41:56,903 iteration 5084 : loss : 0.018451, loss_ce: 0.006461
2022-01-13 21:41:58,276 iteration 5085 : loss : 0.034132, loss_ce: 0.011068
2022-01-13 21:41:59,617 iteration 5086 : loss : 0.020345, loss_ce: 0.006924
2022-01-13 21:42:01,038 iteration 5087 : loss : 0.030340, loss_ce: 0.011296
2022-01-13 21:42:02,436 iteration 5088 : loss : 0.019153, loss_ce: 0.007148
2022-01-13 21:42:03,770 iteration 5089 : loss : 0.016532, loss_ce: 0.005213
2022-01-13 21:42:05,117 iteration 5090 : loss : 0.016560, loss_ce: 0.005939
2022-01-13 21:42:06,597 iteration 5091 : loss : 0.031403, loss_ce: 0.012662
2022-01-13 21:42:07,975 iteration 5092 : loss : 0.015111, loss_ce: 0.006857
2022-01-13 21:42:09,315 iteration 5093 : loss : 0.020107, loss_ce: 0.009373
2022-01-13 21:42:10,630 iteration 5094 : loss : 0.015644, loss_ce: 0.005654
2022-01-13 21:42:12,069 iteration 5095 : loss : 0.035382, loss_ce: 0.013881
2022-01-13 21:42:13,395 iteration 5096 : loss : 0.014819, loss_ce: 0.005857
2022-01-13 21:42:14,737 iteration 5097 : loss : 0.016130, loss_ce: 0.007371
2022-01-13 21:42:16,126 iteration 5098 : loss : 0.025770, loss_ce: 0.009006
2022-01-13 21:42:17,495 iteration 5099 : loss : 0.018388, loss_ce: 0.006090
2022-01-13 21:42:17,495 Training Data Eval:
2022-01-13 21:42:24,290   Average segmentation loss on training set: 0.0119
2022-01-13 21:42:24,290 Validation Data Eval:
2022-01-13 21:42:26,628   Average segmentation loss on validation set: 0.0860
2022-01-13 21:42:27,996 iteration 5100 : loss : 0.014435, loss_ce: 0.006774
 75%|█████████████████████▊       | 300/400 [2:07:59<44:46, 26.87s/it]2022-01-13 21:42:29,483 iteration 5101 : loss : 0.027899, loss_ce: 0.014783
2022-01-13 21:42:30,823 iteration 5102 : loss : 0.018483, loss_ce: 0.007786
2022-01-13 21:42:32,186 iteration 5103 : loss : 0.019798, loss_ce: 0.008624
2022-01-13 21:42:33,625 iteration 5104 : loss : 0.022667, loss_ce: 0.010972
2022-01-13 21:42:34,948 iteration 5105 : loss : 0.022895, loss_ce: 0.007719
2022-01-13 21:42:36,390 iteration 5106 : loss : 0.026175, loss_ce: 0.009647
2022-01-13 21:42:37,731 iteration 5107 : loss : 0.016946, loss_ce: 0.006691
2022-01-13 21:42:39,126 iteration 5108 : loss : 0.023480, loss_ce: 0.008292
2022-01-13 21:42:40,503 iteration 5109 : loss : 0.033620, loss_ce: 0.010961
2022-01-13 21:42:41,870 iteration 5110 : loss : 0.019769, loss_ce: 0.009222
2022-01-13 21:42:43,271 iteration 5111 : loss : 0.022005, loss_ce: 0.008151
2022-01-13 21:42:44,607 iteration 5112 : loss : 0.020108, loss_ce: 0.006835
2022-01-13 21:42:46,041 iteration 5113 : loss : 0.029835, loss_ce: 0.006225
2022-01-13 21:42:47,398 iteration 5114 : loss : 0.017599, loss_ce: 0.009125
2022-01-13 21:42:48,729 iteration 5115 : loss : 0.026834, loss_ce: 0.007291
2022-01-13 21:42:50,074 iteration 5116 : loss : 0.021856, loss_ce: 0.008931
2022-01-13 21:42:51,504 iteration 5117 : loss : 0.024689, loss_ce: 0.012605
 75%|█████████████████████▊       | 301/400 [2:08:23<42:40, 25.86s/it]2022-01-13 21:42:52,947 iteration 5118 : loss : 0.019051, loss_ce: 0.008245
2022-01-13 21:42:54,329 iteration 5119 : loss : 0.021085, loss_ce: 0.007701
2022-01-13 21:42:55,669 iteration 5120 : loss : 0.030337, loss_ce: 0.007349
2022-01-13 21:42:57,056 iteration 5121 : loss : 0.023784, loss_ce: 0.010419
2022-01-13 21:42:58,390 iteration 5122 : loss : 0.021159, loss_ce: 0.008554
2022-01-13 21:42:59,753 iteration 5123 : loss : 0.020291, loss_ce: 0.005658
2022-01-13 21:43:01,146 iteration 5124 : loss : 0.027589, loss_ce: 0.013876
2022-01-13 21:43:02,432 iteration 5125 : loss : 0.018363, loss_ce: 0.009307
2022-01-13 21:43:03,758 iteration 5126 : loss : 0.022024, loss_ce: 0.007273
2022-01-13 21:43:05,169 iteration 5127 : loss : 0.030193, loss_ce: 0.010748
2022-01-13 21:43:06,510 iteration 5128 : loss : 0.018073, loss_ce: 0.008261
2022-01-13 21:43:07,900 iteration 5129 : loss : 0.019673, loss_ce: 0.006934
2022-01-13 21:43:09,280 iteration 5130 : loss : 0.026655, loss_ce: 0.007754
2022-01-13 21:43:10,569 iteration 5131 : loss : 0.012533, loss_ce: 0.004706
2022-01-13 21:43:11,929 iteration 5132 : loss : 0.019164, loss_ce: 0.008302
2022-01-13 21:43:13,268 iteration 5133 : loss : 0.022751, loss_ce: 0.007363
2022-01-13 21:43:14,594 iteration 5134 : loss : 0.019188, loss_ce: 0.008521
 76%|█████████████████████▉       | 302/400 [2:08:46<40:52, 25.03s/it]2022-01-13 21:43:16,163 iteration 5135 : loss : 0.026785, loss_ce: 0.010949
2022-01-13 21:43:17,564 iteration 5136 : loss : 0.024752, loss_ce: 0.008028
2022-01-13 21:43:18,987 iteration 5137 : loss : 0.020919, loss_ce: 0.006186
2022-01-13 21:43:20,319 iteration 5138 : loss : 0.017050, loss_ce: 0.007363
2022-01-13 21:43:21,691 iteration 5139 : loss : 0.014788, loss_ce: 0.005839
2022-01-13 21:43:23,151 iteration 5140 : loss : 0.019660, loss_ce: 0.007601
2022-01-13 21:43:24,483 iteration 5141 : loss : 0.021355, loss_ce: 0.007066
2022-01-13 21:43:25,865 iteration 5142 : loss : 0.032034, loss_ce: 0.011732
2022-01-13 21:43:27,156 iteration 5143 : loss : 0.016451, loss_ce: 0.006341
2022-01-13 21:43:28,587 iteration 5144 : loss : 0.038416, loss_ce: 0.022628
2022-01-13 21:43:29,877 iteration 5145 : loss : 0.014380, loss_ce: 0.004688
2022-01-13 21:43:31,315 iteration 5146 : loss : 0.026044, loss_ce: 0.012155
2022-01-13 21:43:32,755 iteration 5147 : loss : 0.022545, loss_ce: 0.007816
2022-01-13 21:43:34,106 iteration 5148 : loss : 0.017543, loss_ce: 0.008052
2022-01-13 21:43:35,463 iteration 5149 : loss : 0.028305, loss_ce: 0.007671
2022-01-13 21:43:36,810 iteration 5150 : loss : 0.016249, loss_ce: 0.006556
2022-01-13 21:43:38,187 iteration 5151 : loss : 0.027616, loss_ce: 0.005064
 76%|█████████████████████▉       | 303/400 [2:09:09<39:46, 24.60s/it]2022-01-13 21:43:39,589 iteration 5152 : loss : 0.022069, loss_ce: 0.004855
2022-01-13 21:43:40,868 iteration 5153 : loss : 0.015960, loss_ce: 0.006119
2022-01-13 21:43:42,299 iteration 5154 : loss : 0.036427, loss_ce: 0.014159
2022-01-13 21:43:43,609 iteration 5155 : loss : 0.014033, loss_ce: 0.004815
2022-01-13 21:43:44,961 iteration 5156 : loss : 0.022083, loss_ce: 0.008111
2022-01-13 21:43:46,266 iteration 5157 : loss : 0.014883, loss_ce: 0.004709
2022-01-13 21:43:47,610 iteration 5158 : loss : 0.018458, loss_ce: 0.006482
2022-01-13 21:43:49,033 iteration 5159 : loss : 0.036414, loss_ce: 0.016849
2022-01-13 21:43:50,345 iteration 5160 : loss : 0.025222, loss_ce: 0.008811
2022-01-13 21:43:51,698 iteration 5161 : loss : 0.020418, loss_ce: 0.008559
2022-01-13 21:43:53,009 iteration 5162 : loss : 0.018350, loss_ce: 0.008101
2022-01-13 21:43:54,424 iteration 5163 : loss : 0.024664, loss_ce: 0.012430
2022-01-13 21:43:55,809 iteration 5164 : loss : 0.022556, loss_ce: 0.013033
2022-01-13 21:43:57,111 iteration 5165 : loss : 0.021132, loss_ce: 0.007213
2022-01-13 21:43:58,475 iteration 5166 : loss : 0.019242, loss_ce: 0.008136
2022-01-13 21:43:59,854 iteration 5167 : loss : 0.028663, loss_ce: 0.009896
2022-01-13 21:44:01,272 iteration 5168 : loss : 0.028853, loss_ce: 0.011791
 76%|██████████████████████       | 304/400 [2:09:33<38:37, 24.15s/it]2022-01-13 21:44:02,808 iteration 5169 : loss : 0.041407, loss_ce: 0.017036
2022-01-13 21:44:04,126 iteration 5170 : loss : 0.017648, loss_ce: 0.005743
2022-01-13 21:44:05,556 iteration 5171 : loss : 0.023906, loss_ce: 0.011563
2022-01-13 21:44:06,855 iteration 5172 : loss : 0.021604, loss_ce: 0.007510
2022-01-13 21:44:08,097 iteration 5173 : loss : 0.015230, loss_ce: 0.006418
2022-01-13 21:44:09,529 iteration 5174 : loss : 0.029085, loss_ce: 0.010816
2022-01-13 21:44:10,861 iteration 5175 : loss : 0.019120, loss_ce: 0.009514
2022-01-13 21:44:12,358 iteration 5176 : loss : 0.026634, loss_ce: 0.009401
2022-01-13 21:44:13,690 iteration 5177 : loss : 0.020600, loss_ce: 0.007868
2022-01-13 21:44:15,044 iteration 5178 : loss : 0.017153, loss_ce: 0.006413
2022-01-13 21:44:16,491 iteration 5179 : loss : 0.017881, loss_ce: 0.005286
2022-01-13 21:44:17,862 iteration 5180 : loss : 0.017460, loss_ce: 0.006113
2022-01-13 21:44:19,186 iteration 5181 : loss : 0.018864, loss_ce: 0.006640
2022-01-13 21:44:20,579 iteration 5182 : loss : 0.016888, loss_ce: 0.006131
2022-01-13 21:44:21,924 iteration 5183 : loss : 0.021505, loss_ce: 0.010052
2022-01-13 21:44:23,261 iteration 5184 : loss : 0.022056, loss_ce: 0.007922
2022-01-13 21:44:23,261 Training Data Eval:
2022-01-13 21:44:30,069   Average segmentation loss on training set: 0.0115
2022-01-13 21:44:30,069 Validation Data Eval:
2022-01-13 21:44:32,410   Average segmentation loss on validation set: 0.0869
2022-01-13 21:44:33,761 iteration 5185 : loss : 0.025254, loss_ce: 0.009211
 76%|██████████████████████       | 305/400 [2:10:05<42:11, 26.65s/it]2022-01-13 21:44:35,203 iteration 5186 : loss : 0.019544, loss_ce: 0.009129
2022-01-13 21:44:36,520 iteration 5187 : loss : 0.018234, loss_ce: 0.007441
2022-01-13 21:44:37,845 iteration 5188 : loss : 0.015075, loss_ce: 0.006758
2022-01-13 21:44:39,177 iteration 5189 : loss : 0.020637, loss_ce: 0.008735
2022-01-13 21:44:40,492 iteration 5190 : loss : 0.017961, loss_ce: 0.007985
2022-01-13 21:44:41,903 iteration 5191 : loss : 0.032114, loss_ce: 0.008890
2022-01-13 21:44:43,303 iteration 5192 : loss : 0.025587, loss_ce: 0.008955
2022-01-13 21:44:44,616 iteration 5193 : loss : 0.012988, loss_ce: 0.004234
2022-01-13 21:44:46,059 iteration 5194 : loss : 0.027183, loss_ce: 0.010798
2022-01-13 21:44:47,396 iteration 5195 : loss : 0.017952, loss_ce: 0.006024
2022-01-13 21:44:48,666 iteration 5196 : loss : 0.014055, loss_ce: 0.003737
2022-01-13 21:44:49,969 iteration 5197 : loss : 0.016184, loss_ce: 0.005691
2022-01-13 21:44:51,291 iteration 5198 : loss : 0.023069, loss_ce: 0.010451
2022-01-13 21:44:52,676 iteration 5199 : loss : 0.014674, loss_ce: 0.005281
2022-01-13 21:44:54,027 iteration 5200 : loss : 0.024524, loss_ce: 0.009552
2022-01-13 21:44:55,402 iteration 5201 : loss : 0.025233, loss_ce: 0.008517
2022-01-13 21:44:56,858 iteration 5202 : loss : 0.025311, loss_ce: 0.011495
 76%|██████████████████████▏      | 306/400 [2:10:28<40:04, 25.58s/it]2022-01-13 21:44:58,254 iteration 5203 : loss : 0.015229, loss_ce: 0.005343
2022-01-13 21:44:59,599 iteration 5204 : loss : 0.028702, loss_ce: 0.011715
2022-01-13 21:45:01,089 iteration 5205 : loss : 0.035802, loss_ce: 0.014158
2022-01-13 21:45:02,455 iteration 5206 : loss : 0.017270, loss_ce: 0.005953
2022-01-13 21:45:03,832 iteration 5207 : loss : 0.025490, loss_ce: 0.011584
2022-01-13 21:45:05,275 iteration 5208 : loss : 0.037143, loss_ce: 0.019151
2022-01-13 21:45:06,594 iteration 5209 : loss : 0.016042, loss_ce: 0.006794
2022-01-13 21:45:08,032 iteration 5210 : loss : 0.019604, loss_ce: 0.007523
2022-01-13 21:45:09,415 iteration 5211 : loss : 0.017174, loss_ce: 0.006896
2022-01-13 21:45:10,784 iteration 5212 : loss : 0.026686, loss_ce: 0.010352
2022-01-13 21:45:12,063 iteration 5213 : loss : 0.016315, loss_ce: 0.006248
2022-01-13 21:45:13,518 iteration 5214 : loss : 0.034148, loss_ce: 0.015223
2022-01-13 21:45:14,915 iteration 5215 : loss : 0.028110, loss_ce: 0.010658
2022-01-13 21:45:16,337 iteration 5216 : loss : 0.021694, loss_ce: 0.007034
2022-01-13 21:45:17,792 iteration 5217 : loss : 0.022668, loss_ce: 0.009171
2022-01-13 21:45:19,123 iteration 5218 : loss : 0.024695, loss_ce: 0.004619
2022-01-13 21:45:20,584 iteration 5219 : loss : 0.026102, loss_ce: 0.009469
 77%|██████████████████████▎      | 307/400 [2:10:52<38:47, 25.03s/it]2022-01-13 21:45:21,997 iteration 5220 : loss : 0.021169, loss_ce: 0.006328
2022-01-13 21:45:23,355 iteration 5221 : loss : 0.023204, loss_ce: 0.008784
2022-01-13 21:45:24,669 iteration 5222 : loss : 0.016963, loss_ce: 0.006576
2022-01-13 21:45:26,083 iteration 5223 : loss : 0.021451, loss_ce: 0.008457
2022-01-13 21:45:27,437 iteration 5224 : loss : 0.020955, loss_ce: 0.007091
2022-01-13 21:45:28,859 iteration 5225 : loss : 0.021440, loss_ce: 0.007859
2022-01-13 21:45:30,233 iteration 5226 : loss : 0.024313, loss_ce: 0.009207
2022-01-13 21:45:31,690 iteration 5227 : loss : 0.022729, loss_ce: 0.009961
2022-01-13 21:45:33,026 iteration 5228 : loss : 0.016089, loss_ce: 0.005616
2022-01-13 21:45:34,511 iteration 5229 : loss : 0.030769, loss_ce: 0.013142
2022-01-13 21:45:35,778 iteration 5230 : loss : 0.013721, loss_ce: 0.005988
2022-01-13 21:45:37,165 iteration 5231 : loss : 0.031291, loss_ce: 0.016744
2022-01-13 21:45:38,571 iteration 5232 : loss : 0.036891, loss_ce: 0.011714
2022-01-13 21:45:39,973 iteration 5233 : loss : 0.019073, loss_ce: 0.008501
2022-01-13 21:45:41,307 iteration 5234 : loss : 0.021131, loss_ce: 0.010434
2022-01-13 21:45:42,686 iteration 5235 : loss : 0.021872, loss_ce: 0.007385
2022-01-13 21:45:44,103 iteration 5236 : loss : 0.030489, loss_ce: 0.012226
 77%|██████████████████████▎      | 308/400 [2:11:15<37:40, 24.57s/it]2022-01-13 21:45:45,413 iteration 5237 : loss : 0.014341, loss_ce: 0.005856
2022-01-13 21:45:46,808 iteration 5238 : loss : 0.022901, loss_ce: 0.008818
2022-01-13 21:45:48,220 iteration 5239 : loss : 0.022055, loss_ce: 0.007056
2022-01-13 21:45:49,639 iteration 5240 : loss : 0.183391, loss_ce: 0.010902
2022-01-13 21:45:50,981 iteration 5241 : loss : 0.016475, loss_ce: 0.006627
2022-01-13 21:45:52,373 iteration 5242 : loss : 0.027167, loss_ce: 0.011879
2022-01-13 21:45:53,829 iteration 5243 : loss : 0.027688, loss_ce: 0.009734
2022-01-13 21:45:55,242 iteration 5244 : loss : 0.019102, loss_ce: 0.008429
2022-01-13 21:45:56,628 iteration 5245 : loss : 0.020406, loss_ce: 0.007092
2022-01-13 21:45:58,027 iteration 5246 : loss : 0.022242, loss_ce: 0.006501
2022-01-13 21:45:59,324 iteration 5247 : loss : 0.015938, loss_ce: 0.006505
2022-01-13 21:46:00,733 iteration 5248 : loss : 0.024631, loss_ce: 0.008891
2022-01-13 21:46:02,191 iteration 5249 : loss : 0.024082, loss_ce: 0.008290
2022-01-13 21:46:03,596 iteration 5250 : loss : 0.027266, loss_ce: 0.012954
2022-01-13 21:46:04,902 iteration 5251 : loss : 0.015751, loss_ce: 0.005378
2022-01-13 21:46:06,284 iteration 5252 : loss : 0.019821, loss_ce: 0.007838
2022-01-13 21:46:07,714 iteration 5253 : loss : 0.044594, loss_ce: 0.010077
 77%|██████████████████████▍      | 309/400 [2:11:39<36:49, 24.28s/it]2022-01-13 21:46:09,138 iteration 5254 : loss : 0.014060, loss_ce: 0.005054
2022-01-13 21:46:10,504 iteration 5255 : loss : 0.029056, loss_ce: 0.016337
2022-01-13 21:46:11,810 iteration 5256 : loss : 0.016752, loss_ce: 0.006778
2022-01-13 21:46:13,185 iteration 5257 : loss : 0.022261, loss_ce: 0.008964
2022-01-13 21:46:14,609 iteration 5258 : loss : 0.027829, loss_ce: 0.008405
2022-01-13 21:46:15,930 iteration 5259 : loss : 0.020231, loss_ce: 0.005641
2022-01-13 21:46:17,317 iteration 5260 : loss : 0.014855, loss_ce: 0.005449
2022-01-13 21:46:18,707 iteration 5261 : loss : 0.025993, loss_ce: 0.011714
2022-01-13 21:46:20,082 iteration 5262 : loss : 0.015529, loss_ce: 0.006675
2022-01-13 21:46:21,479 iteration 5263 : loss : 0.018344, loss_ce: 0.007547
2022-01-13 21:46:22,794 iteration 5264 : loss : 0.015256, loss_ce: 0.006714
2022-01-13 21:46:24,210 iteration 5265 : loss : 0.025207, loss_ce: 0.010891
2022-01-13 21:46:25,693 iteration 5266 : loss : 0.023000, loss_ce: 0.008231
2022-01-13 21:46:27,060 iteration 5267 : loss : 0.027243, loss_ce: 0.007406
2022-01-13 21:46:28,443 iteration 5268 : loss : 0.022680, loss_ce: 0.006999
2022-01-13 21:46:29,984 iteration 5269 : loss : 0.022147, loss_ce: 0.006914
2022-01-13 21:46:29,984 Training Data Eval:
2022-01-13 21:46:36,823   Average segmentation loss on training set: 0.0111
2022-01-13 21:46:36,823 Validation Data Eval:
2022-01-13 21:46:39,173   Average segmentation loss on validation set: 0.0758
2022-01-13 21:46:40,563 iteration 5270 : loss : 0.017553, loss_ce: 0.008222
 78%|██████████████████████▍      | 310/400 [2:12:12<40:16, 26.85s/it]2022-01-13 21:46:41,979 iteration 5271 : loss : 0.020400, loss_ce: 0.007728
2022-01-13 21:46:43,398 iteration 5272 : loss : 0.025095, loss_ce: 0.011122
2022-01-13 21:46:44,753 iteration 5273 : loss : 0.015255, loss_ce: 0.004662
2022-01-13 21:46:46,120 iteration 5274 : loss : 0.031863, loss_ce: 0.011957
2022-01-13 21:46:47,427 iteration 5275 : loss : 0.015768, loss_ce: 0.006759
2022-01-13 21:46:48,844 iteration 5276 : loss : 0.025321, loss_ce: 0.010031
2022-01-13 21:46:50,243 iteration 5277 : loss : 0.018098, loss_ce: 0.006823
2022-01-13 21:46:51,541 iteration 5278 : loss : 0.015325, loss_ce: 0.005837
2022-01-13 21:46:52,927 iteration 5279 : loss : 0.014684, loss_ce: 0.006024
2022-01-13 21:46:54,457 iteration 5280 : loss : 0.025647, loss_ce: 0.011025
2022-01-13 21:46:55,837 iteration 5281 : loss : 0.019670, loss_ce: 0.006998
2022-01-13 21:46:57,158 iteration 5282 : loss : 0.014120, loss_ce: 0.004447
2022-01-13 21:46:58,564 iteration 5283 : loss : 0.022258, loss_ce: 0.006983
2022-01-13 21:46:59,983 iteration 5284 : loss : 0.029582, loss_ce: 0.007949
2022-01-13 21:47:01,371 iteration 5285 : loss : 0.019077, loss_ce: 0.008303
2022-01-13 21:47:02,676 iteration 5286 : loss : 0.014553, loss_ce: 0.006249
2022-01-13 21:47:04,054 iteration 5287 : loss : 0.019433, loss_ce: 0.004258
 78%|██████████████████████▌      | 311/400 [2:12:35<38:20, 25.85s/it]2022-01-13 21:47:05,550 iteration 5288 : loss : 0.022720, loss_ce: 0.009103
2022-01-13 21:47:06,981 iteration 5289 : loss : 0.024960, loss_ce: 0.007933
2022-01-13 21:47:08,367 iteration 5290 : loss : 0.035497, loss_ce: 0.007024
2022-01-13 21:47:09,729 iteration 5291 : loss : 0.026981, loss_ce: 0.010141
2022-01-13 21:47:11,167 iteration 5292 : loss : 0.023058, loss_ce: 0.009082
2022-01-13 21:47:12,587 iteration 5293 : loss : 0.029304, loss_ce: 0.015111
2022-01-13 21:47:14,039 iteration 5294 : loss : 0.022635, loss_ce: 0.009134
2022-01-13 21:47:15,548 iteration 5295 : loss : 0.022729, loss_ce: 0.009743
2022-01-13 21:47:16,993 iteration 5296 : loss : 0.029890, loss_ce: 0.006709
2022-01-13 21:47:18,438 iteration 5297 : loss : 0.022100, loss_ce: 0.008171
2022-01-13 21:47:19,895 iteration 5298 : loss : 0.029141, loss_ce: 0.011093
2022-01-13 21:47:21,336 iteration 5299 : loss : 0.016970, loss_ce: 0.005992
2022-01-13 21:47:22,808 iteration 5300 : loss : 0.024720, loss_ce: 0.008922
2022-01-13 21:47:24,120 iteration 5301 : loss : 0.030595, loss_ce: 0.012774
2022-01-13 21:47:25,433 iteration 5302 : loss : 0.015279, loss_ce: 0.007527
2022-01-13 21:47:26,754 iteration 5303 : loss : 0.017844, loss_ce: 0.006822
2022-01-13 21:47:28,057 iteration 5304 : loss : 0.017502, loss_ce: 0.006746
 78%|██████████████████████▌      | 312/400 [2:12:59<37:05, 25.29s/it]2022-01-13 21:47:29,505 iteration 5305 : loss : 0.019266, loss_ce: 0.006615
2022-01-13 21:47:30,984 iteration 5306 : loss : 0.033289, loss_ce: 0.016530
2022-01-13 21:47:32,473 iteration 5307 : loss : 0.025595, loss_ce: 0.009994
2022-01-13 21:47:33,919 iteration 5308 : loss : 0.033649, loss_ce: 0.013200
2022-01-13 21:47:35,359 iteration 5309 : loss : 0.035825, loss_ce: 0.012583
2022-01-13 21:47:36,706 iteration 5310 : loss : 0.021856, loss_ce: 0.010614
2022-01-13 21:47:38,041 iteration 5311 : loss : 0.029962, loss_ce: 0.007358
2022-01-13 21:47:39,479 iteration 5312 : loss : 0.019292, loss_ce: 0.008373
2022-01-13 21:47:40,964 iteration 5313 : loss : 0.032447, loss_ce: 0.008960
2022-01-13 21:47:42,381 iteration 5314 : loss : 0.016641, loss_ce: 0.006005
2022-01-13 21:47:43,822 iteration 5315 : loss : 0.031553, loss_ce: 0.007021
2022-01-13 21:47:45,247 iteration 5316 : loss : 0.025579, loss_ce: 0.010231
2022-01-13 21:47:46,619 iteration 5317 : loss : 0.029296, loss_ce: 0.013002
2022-01-13 21:47:47,982 iteration 5318 : loss : 0.020995, loss_ce: 0.008065
2022-01-13 21:47:49,412 iteration 5319 : loss : 0.034571, loss_ce: 0.015506
2022-01-13 21:47:50,864 iteration 5320 : loss : 0.031312, loss_ce: 0.016941
2022-01-13 21:47:52,307 iteration 5321 : loss : 0.030042, loss_ce: 0.012681
 78%|██████████████████████▋      | 313/400 [2:13:24<36:13, 24.98s/it]2022-01-13 21:47:53,668 iteration 5322 : loss : 0.013850, loss_ce: 0.005774
2022-01-13 21:47:55,056 iteration 5323 : loss : 0.023015, loss_ce: 0.009496
2022-01-13 21:47:56,370 iteration 5324 : loss : 0.019546, loss_ce: 0.006622
2022-01-13 21:47:57,708 iteration 5325 : loss : 0.019739, loss_ce: 0.004962
2022-01-13 21:47:59,117 iteration 5326 : loss : 0.023596, loss_ce: 0.008251
2022-01-13 21:48:00,453 iteration 5327 : loss : 0.019138, loss_ce: 0.006365
2022-01-13 21:48:01,808 iteration 5328 : loss : 0.025972, loss_ce: 0.014952
2022-01-13 21:48:03,231 iteration 5329 : loss : 0.027017, loss_ce: 0.009584
2022-01-13 21:48:04,631 iteration 5330 : loss : 0.022458, loss_ce: 0.008786
2022-01-13 21:48:06,001 iteration 5331 : loss : 0.016675, loss_ce: 0.005200
2022-01-13 21:48:07,389 iteration 5332 : loss : 0.028691, loss_ce: 0.010103
2022-01-13 21:48:08,800 iteration 5333 : loss : 0.034393, loss_ce: 0.017109
2022-01-13 21:48:10,197 iteration 5334 : loss : 0.049961, loss_ce: 0.022372
2022-01-13 21:48:11,613 iteration 5335 : loss : 0.020264, loss_ce: 0.007162
2022-01-13 21:48:13,004 iteration 5336 : loss : 0.022384, loss_ce: 0.008246
2022-01-13 21:48:14,359 iteration 5337 : loss : 0.016410, loss_ce: 0.006588
2022-01-13 21:48:15,700 iteration 5338 : loss : 0.018689, loss_ce: 0.007356
 78%|██████████████████████▊      | 314/400 [2:13:47<35:06, 24.50s/it]2022-01-13 21:48:17,280 iteration 5339 : loss : 0.024451, loss_ce: 0.010311
2022-01-13 21:48:18,711 iteration 5340 : loss : 0.031045, loss_ce: 0.015838
2022-01-13 21:48:20,133 iteration 5341 : loss : 0.037143, loss_ce: 0.006752
2022-01-13 21:48:21,555 iteration 5342 : loss : 0.016498, loss_ce: 0.008714
2022-01-13 21:48:22,905 iteration 5343 : loss : 0.016291, loss_ce: 0.005390
2022-01-13 21:48:24,301 iteration 5344 : loss : 0.027882, loss_ce: 0.009856
2022-01-13 21:48:25,671 iteration 5345 : loss : 0.018126, loss_ce: 0.006118
2022-01-13 21:48:27,095 iteration 5346 : loss : 0.030778, loss_ce: 0.010355
2022-01-13 21:48:28,515 iteration 5347 : loss : 0.017592, loss_ce: 0.005274
2022-01-13 21:48:29,943 iteration 5348 : loss : 0.024381, loss_ce: 0.008525
2022-01-13 21:48:31,337 iteration 5349 : loss : 0.022980, loss_ce: 0.008840
2022-01-13 21:48:32,646 iteration 5350 : loss : 0.014018, loss_ce: 0.005295
2022-01-13 21:48:33,970 iteration 5351 : loss : 0.027392, loss_ce: 0.011282
2022-01-13 21:48:35,394 iteration 5352 : loss : 0.026332, loss_ce: 0.011761
2022-01-13 21:48:36,820 iteration 5353 : loss : 0.016250, loss_ce: 0.005937
2022-01-13 21:48:38,172 iteration 5354 : loss : 0.018598, loss_ce: 0.008654
2022-01-13 21:48:38,172 Training Data Eval:
2022-01-13 21:48:44,998   Average segmentation loss on training set: 0.0212
2022-01-13 21:48:44,998 Validation Data Eval:
2022-01-13 21:48:47,345   Average segmentation loss on validation set: 0.0872
2022-01-13 21:48:48,661 iteration 5355 : loss : 0.019630, loss_ce: 0.007007
 79%|██████████████████████▊      | 315/400 [2:14:20<38:18, 27.04s/it]2022-01-13 21:48:50,106 iteration 5356 : loss : 0.024560, loss_ce: 0.011128
2022-01-13 21:48:51,415 iteration 5357 : loss : 0.021429, loss_ce: 0.004885
2022-01-13 21:48:52,933 iteration 5358 : loss : 0.044845, loss_ce: 0.022034
2022-01-13 21:48:54,243 iteration 5359 : loss : 0.016165, loss_ce: 0.005838
2022-01-13 21:48:55,639 iteration 5360 : loss : 0.019481, loss_ce: 0.007958
2022-01-13 21:48:57,061 iteration 5361 : loss : 0.027387, loss_ce: 0.008733
2022-01-13 21:48:58,473 iteration 5362 : loss : 0.028289, loss_ce: 0.009061
2022-01-13 21:48:59,854 iteration 5363 : loss : 0.040161, loss_ce: 0.016168
2022-01-13 21:49:01,234 iteration 5364 : loss : 0.034497, loss_ce: 0.008572
2022-01-13 21:49:02,598 iteration 5365 : loss : 0.017934, loss_ce: 0.007228
2022-01-13 21:49:04,002 iteration 5366 : loss : 0.020902, loss_ce: 0.007994
2022-01-13 21:49:05,463 iteration 5367 : loss : 0.016667, loss_ce: 0.006839
2022-01-13 21:49:06,820 iteration 5368 : loss : 0.016758, loss_ce: 0.007692
2022-01-13 21:49:08,212 iteration 5369 : loss : 0.017131, loss_ce: 0.006868
2022-01-13 21:49:09,576 iteration 5370 : loss : 0.013736, loss_ce: 0.005539
2022-01-13 21:49:10,971 iteration 5371 : loss : 0.035242, loss_ce: 0.015896
2022-01-13 21:49:12,320 iteration 5372 : loss : 0.024831, loss_ce: 0.008068
 79%|██████████████████████▉      | 316/400 [2:14:44<36:26, 26.03s/it]2022-01-13 21:49:13,763 iteration 5373 : loss : 0.017422, loss_ce: 0.008538
2022-01-13 21:49:15,104 iteration 5374 : loss : 0.019897, loss_ce: 0.008459
2022-01-13 21:49:16,507 iteration 5375 : loss : 0.013789, loss_ce: 0.004493
2022-01-13 21:49:17,860 iteration 5376 : loss : 0.020270, loss_ce: 0.008145
2022-01-13 21:49:19,219 iteration 5377 : loss : 0.014527, loss_ce: 0.004587
2022-01-13 21:49:20,600 iteration 5378 : loss : 0.026782, loss_ce: 0.009753
2022-01-13 21:49:21,912 iteration 5379 : loss : 0.013895, loss_ce: 0.005044
2022-01-13 21:49:23,290 iteration 5380 : loss : 0.020892, loss_ce: 0.008744
2022-01-13 21:49:24,640 iteration 5381 : loss : 0.019705, loss_ce: 0.009042
2022-01-13 21:49:26,036 iteration 5382 : loss : 0.017782, loss_ce: 0.005184
2022-01-13 21:49:27,498 iteration 5383 : loss : 0.031273, loss_ce: 0.014852
2022-01-13 21:49:29,030 iteration 5384 : loss : 0.026305, loss_ce: 0.010436
2022-01-13 21:49:30,386 iteration 5385 : loss : 0.016513, loss_ce: 0.006199
2022-01-13 21:49:31,697 iteration 5386 : loss : 0.016715, loss_ce: 0.006009
2022-01-13 21:49:33,058 iteration 5387 : loss : 0.025760, loss_ce: 0.012230
2022-01-13 21:49:34,518 iteration 5388 : loss : 0.015512, loss_ce: 0.005175
2022-01-13 21:49:36,041 iteration 5389 : loss : 0.038416, loss_ce: 0.012734
 79%|██████████████████████▉      | 317/400 [2:15:07<35:02, 25.34s/it]2022-01-13 21:49:37,506 iteration 5390 : loss : 0.032757, loss_ce: 0.011575
2022-01-13 21:49:38,923 iteration 5391 : loss : 0.024424, loss_ce: 0.009476
2022-01-13 21:49:40,378 iteration 5392 : loss : 0.020581, loss_ce: 0.010760
2022-01-13 21:49:41,760 iteration 5393 : loss : 0.056153, loss_ce: 0.016205
2022-01-13 21:49:43,109 iteration 5394 : loss : 0.019241, loss_ce: 0.008886
2022-01-13 21:49:44,513 iteration 5395 : loss : 0.031333, loss_ce: 0.013181
2022-01-13 21:49:45,855 iteration 5396 : loss : 0.023671, loss_ce: 0.012910
2022-01-13 21:49:47,309 iteration 5397 : loss : 0.031020, loss_ce: 0.010361
2022-01-13 21:49:48,732 iteration 5398 : loss : 0.026806, loss_ce: 0.010714
2022-01-13 21:49:50,042 iteration 5399 : loss : 0.029274, loss_ce: 0.008414
2022-01-13 21:49:51,515 iteration 5400 : loss : 0.041454, loss_ce: 0.014083
2022-01-13 21:49:52,925 iteration 5401 : loss : 0.025090, loss_ce: 0.012043
2022-01-13 21:49:54,316 iteration 5402 : loss : 0.032531, loss_ce: 0.011938
2022-01-13 21:49:55,670 iteration 5403 : loss : 0.021148, loss_ce: 0.008398
2022-01-13 21:49:57,021 iteration 5404 : loss : 0.019126, loss_ce: 0.005225
2022-01-13 21:49:58,388 iteration 5405 : loss : 0.023367, loss_ce: 0.010095
2022-01-13 21:49:59,835 iteration 5406 : loss : 0.020919, loss_ce: 0.005731
 80%|███████████████████████      | 318/400 [2:15:31<33:59, 24.87s/it]2022-01-13 21:50:01,327 iteration 5407 : loss : 0.026592, loss_ce: 0.009571
2022-01-13 21:50:02,723 iteration 5408 : loss : 0.023474, loss_ce: 0.008296
2022-01-13 21:50:04,212 iteration 5409 : loss : 0.024909, loss_ce: 0.010410
2022-01-13 21:50:05,575 iteration 5410 : loss : 0.021977, loss_ce: 0.010260
2022-01-13 21:50:06,975 iteration 5411 : loss : 0.018044, loss_ce: 0.007194
2022-01-13 21:50:08,386 iteration 5412 : loss : 0.024891, loss_ce: 0.011363
2022-01-13 21:50:09,763 iteration 5413 : loss : 0.025812, loss_ce: 0.013213
2022-01-13 21:50:11,180 iteration 5414 : loss : 0.026309, loss_ce: 0.011142
2022-01-13 21:50:12,679 iteration 5415 : loss : 0.044860, loss_ce: 0.019635
2022-01-13 21:50:14,012 iteration 5416 : loss : 0.013309, loss_ce: 0.004667
2022-01-13 21:50:15,456 iteration 5417 : loss : 0.016483, loss_ce: 0.005014
2022-01-13 21:50:16,834 iteration 5418 : loss : 0.032792, loss_ce: 0.015283
2022-01-13 21:50:18,281 iteration 5419 : loss : 0.024943, loss_ce: 0.007573
2022-01-13 21:50:19,760 iteration 5420 : loss : 0.024652, loss_ce: 0.009387
2022-01-13 21:50:21,184 iteration 5421 : loss : 0.026088, loss_ce: 0.014270
2022-01-13 21:50:22,458 iteration 5422 : loss : 0.013793, loss_ce: 0.006142
2022-01-13 21:50:23,902 iteration 5423 : loss : 0.036858, loss_ce: 0.007370
 80%|███████████████████████▏     | 319/400 [2:15:55<33:14, 24.63s/it]2022-01-13 21:50:25,442 iteration 5424 : loss : 0.026286, loss_ce: 0.009824
2022-01-13 21:50:26,803 iteration 5425 : loss : 0.017762, loss_ce: 0.006358
2022-01-13 21:50:28,199 iteration 5426 : loss : 0.021131, loss_ce: 0.006156
2022-01-13 21:50:29,502 iteration 5427 : loss : 0.028208, loss_ce: 0.009895
2022-01-13 21:50:30,864 iteration 5428 : loss : 0.025198, loss_ce: 0.012606
2022-01-13 21:50:32,281 iteration 5429 : loss : 0.016679, loss_ce: 0.006469
2022-01-13 21:50:33,693 iteration 5430 : loss : 0.022904, loss_ce: 0.009776
2022-01-13 21:50:35,021 iteration 5431 : loss : 0.020152, loss_ce: 0.006992
2022-01-13 21:50:36,504 iteration 5432 : loss : 0.027583, loss_ce: 0.013133
2022-01-13 21:50:37,966 iteration 5433 : loss : 0.027611, loss_ce: 0.012313
2022-01-13 21:50:39,312 iteration 5434 : loss : 0.022491, loss_ce: 0.010035
2022-01-13 21:50:40,755 iteration 5435 : loss : 0.023682, loss_ce: 0.010478
2022-01-13 21:50:42,157 iteration 5436 : loss : 0.020266, loss_ce: 0.007327
2022-01-13 21:50:43,574 iteration 5437 : loss : 0.053967, loss_ce: 0.013387
2022-01-13 21:50:44,998 iteration 5438 : loss : 0.026949, loss_ce: 0.010571
2022-01-13 21:50:46,353 iteration 5439 : loss : 0.022821, loss_ce: 0.009337
2022-01-13 21:50:46,353 Training Data Eval:
2022-01-13 21:50:53,124   Average segmentation loss on training set: 0.0119
2022-01-13 21:50:53,125 Validation Data Eval:
2022-01-13 21:50:55,465   Average segmentation loss on validation set: 0.0749
2022-01-13 21:50:56,783 iteration 5440 : loss : 0.019823, loss_ce: 0.006485
 80%|███████████████████████▏     | 320/400 [2:16:28<36:08, 27.10s/it]2022-01-13 21:50:58,188 iteration 5441 : loss : 0.018616, loss_ce: 0.007269
2022-01-13 21:50:59,502 iteration 5442 : loss : 0.025168, loss_ce: 0.009544
2022-01-13 21:51:00,860 iteration 5443 : loss : 0.029101, loss_ce: 0.010773
2022-01-13 21:51:02,146 iteration 5444 : loss : 0.017637, loss_ce: 0.005483
2022-01-13 21:51:03,522 iteration 5445 : loss : 0.028017, loss_ce: 0.010608
2022-01-13 21:51:04,845 iteration 5446 : loss : 0.019233, loss_ce: 0.008838
2022-01-13 21:51:06,299 iteration 5447 : loss : 0.033148, loss_ce: 0.013135
2022-01-13 21:51:07,616 iteration 5448 : loss : 0.019941, loss_ce: 0.007748
2022-01-13 21:51:08,995 iteration 5449 : loss : 0.027515, loss_ce: 0.014593
2022-01-13 21:51:10,362 iteration 5450 : loss : 0.031336, loss_ce: 0.013717
2022-01-13 21:51:11,669 iteration 5451 : loss : 0.016915, loss_ce: 0.006562
2022-01-13 21:51:13,048 iteration 5452 : loss : 0.023611, loss_ce: 0.008993
2022-01-13 21:51:14,374 iteration 5453 : loss : 0.018444, loss_ce: 0.007528
2022-01-13 21:51:15,797 iteration 5454 : loss : 0.038792, loss_ce: 0.023177
2022-01-13 21:51:17,216 iteration 5455 : loss : 0.026942, loss_ce: 0.008836
2022-01-13 21:51:18,597 iteration 5456 : loss : 0.017012, loss_ce: 0.003640
2022-01-13 21:51:19,927 iteration 5457 : loss : 0.021194, loss_ce: 0.007148
 80%|███████████████████████▎     | 321/400 [2:16:51<34:07, 25.92s/it]2022-01-13 21:51:21,337 iteration 5458 : loss : 0.022870, loss_ce: 0.008385
2022-01-13 21:51:22,648 iteration 5459 : loss : 0.019147, loss_ce: 0.008894
2022-01-13 21:51:24,018 iteration 5460 : loss : 0.016223, loss_ce: 0.005810
2022-01-13 21:51:25,378 iteration 5461 : loss : 0.022997, loss_ce: 0.008217
2022-01-13 21:51:26,731 iteration 5462 : loss : 0.017652, loss_ce: 0.006718
2022-01-13 21:51:28,119 iteration 5463 : loss : 0.022342, loss_ce: 0.006458
2022-01-13 21:51:29,497 iteration 5464 : loss : 0.018849, loss_ce: 0.008116
2022-01-13 21:51:30,938 iteration 5465 : loss : 0.028170, loss_ce: 0.010925
2022-01-13 21:51:32,370 iteration 5466 : loss : 0.033700, loss_ce: 0.011746
2022-01-13 21:51:33,770 iteration 5467 : loss : 0.026038, loss_ce: 0.012908
2022-01-13 21:51:35,165 iteration 5468 : loss : 0.019463, loss_ce: 0.008580
2022-01-13 21:51:36,470 iteration 5469 : loss : 0.019768, loss_ce: 0.006972
2022-01-13 21:51:37,823 iteration 5470 : loss : 0.012524, loss_ce: 0.004538
2022-01-13 21:51:39,194 iteration 5471 : loss : 0.024407, loss_ce: 0.007058
2022-01-13 21:51:40,583 iteration 5472 : loss : 0.026607, loss_ce: 0.009029
2022-01-13 21:51:41,898 iteration 5473 : loss : 0.015575, loss_ce: 0.006000
2022-01-13 21:51:43,236 iteration 5474 : loss : 0.020610, loss_ce: 0.006524
 80%|███████████████████████▎     | 322/400 [2:17:14<32:40, 25.13s/it]2022-01-13 21:51:44,687 iteration 5475 : loss : 0.038083, loss_ce: 0.011718
2022-01-13 21:51:46,116 iteration 5476 : loss : 0.027497, loss_ce: 0.013546
2022-01-13 21:51:47,489 iteration 5477 : loss : 0.041771, loss_ce: 0.005722
2022-01-13 21:51:48,782 iteration 5478 : loss : 0.017227, loss_ce: 0.005362
2022-01-13 21:51:50,147 iteration 5479 : loss : 0.015472, loss_ce: 0.006752
2022-01-13 21:51:51,506 iteration 5480 : loss : 0.028100, loss_ce: 0.009186
2022-01-13 21:51:52,840 iteration 5481 : loss : 0.023172, loss_ce: 0.007774
2022-01-13 21:51:54,309 iteration 5482 : loss : 0.032696, loss_ce: 0.008477
2022-01-13 21:51:55,600 iteration 5483 : loss : 0.014083, loss_ce: 0.005464
2022-01-13 21:51:56,983 iteration 5484 : loss : 0.022218, loss_ce: 0.008427
2022-01-13 21:51:58,344 iteration 5485 : loss : 0.015952, loss_ce: 0.006604
2022-01-13 21:51:59,711 iteration 5486 : loss : 0.021100, loss_ce: 0.009527
2022-01-13 21:52:01,097 iteration 5487 : loss : 0.018144, loss_ce: 0.006303
2022-01-13 21:52:02,436 iteration 5488 : loss : 0.017243, loss_ce: 0.007717
2022-01-13 21:52:03,763 iteration 5489 : loss : 0.014715, loss_ce: 0.007774
2022-01-13 21:52:05,207 iteration 5490 : loss : 0.025435, loss_ce: 0.010724
2022-01-13 21:52:06,549 iteration 5491 : loss : 0.017513, loss_ce: 0.005838
 81%|███████████████████████▍     | 323/400 [2:17:38<31:33, 24.59s/it]2022-01-13 21:52:07,892 iteration 5492 : loss : 0.018460, loss_ce: 0.007053
2022-01-13 21:52:09,306 iteration 5493 : loss : 0.020681, loss_ce: 0.006331
2022-01-13 21:52:10,638 iteration 5494 : loss : 0.023466, loss_ce: 0.006841
2022-01-13 21:52:12,012 iteration 5495 : loss : 0.014231, loss_ce: 0.004342
2022-01-13 21:52:13,400 iteration 5496 : loss : 0.016909, loss_ce: 0.004672
2022-01-13 21:52:14,790 iteration 5497 : loss : 0.017571, loss_ce: 0.007222
2022-01-13 21:52:16,234 iteration 5498 : loss : 0.049296, loss_ce: 0.015127
2022-01-13 21:52:17,638 iteration 5499 : loss : 0.019842, loss_ce: 0.009970
2022-01-13 21:52:18,947 iteration 5500 : loss : 0.024022, loss_ce: 0.014263
2022-01-13 21:52:20,324 iteration 5501 : loss : 0.028238, loss_ce: 0.012612
2022-01-13 21:52:21,651 iteration 5502 : loss : 0.011795, loss_ce: 0.004967
2022-01-13 21:52:23,013 iteration 5503 : loss : 0.018478, loss_ce: 0.005318
2022-01-13 21:52:24,345 iteration 5504 : loss : 0.021674, loss_ce: 0.008183
2022-01-13 21:52:25,712 iteration 5505 : loss : 0.024119, loss_ce: 0.011149
2022-01-13 21:52:27,115 iteration 5506 : loss : 0.018219, loss_ce: 0.006502
2022-01-13 21:52:28,475 iteration 5507 : loss : 0.017351, loss_ce: 0.007769
2022-01-13 21:52:29,853 iteration 5508 : loss : 0.031849, loss_ce: 0.012739
 81%|███████████████████████▍     | 324/400 [2:18:01<30:39, 24.21s/it]2022-01-13 21:52:31,288 iteration 5509 : loss : 0.026333, loss_ce: 0.008553
2022-01-13 21:52:32,737 iteration 5510 : loss : 0.018499, loss_ce: 0.007143
2022-01-13 21:52:34,088 iteration 5511 : loss : 0.015145, loss_ce: 0.006062
2022-01-13 21:52:35,528 iteration 5512 : loss : 0.030182, loss_ce: 0.011534
2022-01-13 21:52:36,880 iteration 5513 : loss : 0.014427, loss_ce: 0.006190
2022-01-13 21:52:38,193 iteration 5514 : loss : 0.012676, loss_ce: 0.004355
2022-01-13 21:52:39,623 iteration 5515 : loss : 0.034735, loss_ce: 0.007807
2022-01-13 21:52:40,967 iteration 5516 : loss : 0.017224, loss_ce: 0.006639
2022-01-13 21:52:42,341 iteration 5517 : loss : 0.018023, loss_ce: 0.008145
2022-01-13 21:52:43,731 iteration 5518 : loss : 0.023549, loss_ce: 0.007443
2022-01-13 21:52:45,139 iteration 5519 : loss : 0.019264, loss_ce: 0.007167
2022-01-13 21:52:46,523 iteration 5520 : loss : 0.022418, loss_ce: 0.010176
2022-01-13 21:52:47,927 iteration 5521 : loss : 0.026995, loss_ce: 0.009479
2022-01-13 21:52:49,289 iteration 5522 : loss : 0.023730, loss_ce: 0.008066
2022-01-13 21:52:50,624 iteration 5523 : loss : 0.012861, loss_ce: 0.004500
2022-01-13 21:52:51,994 iteration 5524 : loss : 0.022613, loss_ce: 0.009622
2022-01-13 21:52:51,994 Training Data Eval:
2022-01-13 21:52:58,794   Average segmentation loss on training set: 0.0113
2022-01-13 21:52:58,794 Validation Data Eval:
2022-01-13 21:53:01,144   Average segmentation loss on validation set: 0.0727
2022-01-13 21:53:02,509 iteration 5525 : loss : 0.027556, loss_ce: 0.017828
 81%|███████████████████████▌     | 325/400 [2:18:34<33:25, 26.74s/it]2022-01-13 21:53:04,003 iteration 5526 : loss : 0.020832, loss_ce: 0.007675
2022-01-13 21:53:05,383 iteration 5527 : loss : 0.021837, loss_ce: 0.010109
2022-01-13 21:53:06,753 iteration 5528 : loss : 0.032663, loss_ce: 0.012764
2022-01-13 21:53:08,160 iteration 5529 : loss : 0.026899, loss_ce: 0.013705
2022-01-13 21:53:09,477 iteration 5530 : loss : 0.017224, loss_ce: 0.008309
2022-01-13 21:53:10,846 iteration 5531 : loss : 0.017937, loss_ce: 0.008022
2022-01-13 21:53:12,165 iteration 5532 : loss : 0.014230, loss_ce: 0.006248
2022-01-13 21:53:13,591 iteration 5533 : loss : 0.025959, loss_ce: 0.007285
2022-01-13 21:53:14,964 iteration 5534 : loss : 0.020149, loss_ce: 0.007032
2022-01-13 21:53:16,395 iteration 5535 : loss : 0.025122, loss_ce: 0.009550
2022-01-13 21:53:17,894 iteration 5536 : loss : 0.019778, loss_ce: 0.008383
2022-01-13 21:53:19,305 iteration 5537 : loss : 0.026320, loss_ce: 0.010628
2022-01-13 21:53:20,689 iteration 5538 : loss : 0.019608, loss_ce: 0.007732
2022-01-13 21:53:22,158 iteration 5539 : loss : 0.020155, loss_ce: 0.004455
2022-01-13 21:53:23,501 iteration 5540 : loss : 0.017719, loss_ce: 0.008220
2022-01-13 21:53:24,882 iteration 5541 : loss : 0.023278, loss_ce: 0.008581
2022-01-13 21:53:26,245 iteration 5542 : loss : 0.016747, loss_ce: 0.006746
 82%|███████████████████████▋     | 326/400 [2:18:57<31:51, 25.84s/it]2022-01-13 21:53:27,710 iteration 5543 : loss : 0.018743, loss_ce: 0.006924
2022-01-13 21:53:29,096 iteration 5544 : loss : 0.017478, loss_ce: 0.007246
2022-01-13 21:53:30,444 iteration 5545 : loss : 0.021920, loss_ce: 0.007811
2022-01-13 21:53:31,767 iteration 5546 : loss : 0.018504, loss_ce: 0.007577
2022-01-13 21:53:33,140 iteration 5547 : loss : 0.022653, loss_ce: 0.010443
2022-01-13 21:53:34,569 iteration 5548 : loss : 0.026222, loss_ce: 0.008500
2022-01-13 21:53:35,880 iteration 5549 : loss : 0.023630, loss_ce: 0.009490
2022-01-13 21:53:37,233 iteration 5550 : loss : 0.019666, loss_ce: 0.006752
2022-01-13 21:53:38,604 iteration 5551 : loss : 0.017438, loss_ce: 0.007627
2022-01-13 21:53:39,918 iteration 5552 : loss : 0.015535, loss_ce: 0.006063
2022-01-13 21:53:41,303 iteration 5553 : loss : 0.026207, loss_ce: 0.012131
2022-01-13 21:53:42,726 iteration 5554 : loss : 0.029964, loss_ce: 0.011384
2022-01-13 21:53:44,139 iteration 5555 : loss : 0.023943, loss_ce: 0.007431
2022-01-13 21:53:45,443 iteration 5556 : loss : 0.018003, loss_ce: 0.007306
2022-01-13 21:53:46,877 iteration 5557 : loss : 0.049038, loss_ce: 0.012419
2022-01-13 21:53:48,260 iteration 5558 : loss : 0.016775, loss_ce: 0.005893
2022-01-13 21:53:49,542 iteration 5559 : loss : 0.014428, loss_ce: 0.006121
 82%|███████████████████████▋     | 327/400 [2:19:21<30:30, 25.07s/it]2022-01-13 21:53:51,142 iteration 5560 : loss : 0.052523, loss_ce: 0.020201
2022-01-13 21:53:52,533 iteration 5561 : loss : 0.020228, loss_ce: 0.007140
2022-01-13 21:53:53,902 iteration 5562 : loss : 0.022518, loss_ce: 0.005770
2022-01-13 21:53:55,265 iteration 5563 : loss : 0.020617, loss_ce: 0.008353
2022-01-13 21:53:56,731 iteration 5564 : loss : 0.021297, loss_ce: 0.007004
2022-01-13 21:53:58,111 iteration 5565 : loss : 0.015395, loss_ce: 0.006501
2022-01-13 21:53:59,543 iteration 5566 : loss : 0.020026, loss_ce: 0.008598
2022-01-13 21:54:01,017 iteration 5567 : loss : 0.020867, loss_ce: 0.009449
2022-01-13 21:54:02,394 iteration 5568 : loss : 0.024353, loss_ce: 0.009339
2022-01-13 21:54:03,815 iteration 5569 : loss : 0.020028, loss_ce: 0.008791
2022-01-13 21:54:05,208 iteration 5570 : loss : 0.013926, loss_ce: 0.004761
2022-01-13 21:54:06,632 iteration 5571 : loss : 0.020393, loss_ce: 0.008602
2022-01-13 21:54:08,011 iteration 5572 : loss : 0.026634, loss_ce: 0.010412
2022-01-13 21:54:09,377 iteration 5573 : loss : 0.015848, loss_ce: 0.005042
2022-01-13 21:54:10,859 iteration 5574 : loss : 0.037184, loss_ce: 0.011548
2022-01-13 21:54:12,130 iteration 5575 : loss : 0.012834, loss_ce: 0.005589
2022-01-13 21:54:13,384 iteration 5576 : loss : 0.014194, loss_ce: 0.004452
 82%|███████████████████████▊     | 328/400 [2:19:45<29:38, 24.70s/it]2022-01-13 21:54:14,818 iteration 5577 : loss : 0.018743, loss_ce: 0.006641
2022-01-13 21:54:16,158 iteration 5578 : loss : 0.023068, loss_ce: 0.006636
2022-01-13 21:54:17,521 iteration 5579 : loss : 0.016777, loss_ce: 0.005473
2022-01-13 21:54:18,976 iteration 5580 : loss : 0.017664, loss_ce: 0.007286
2022-01-13 21:54:20,329 iteration 5581 : loss : 0.019623, loss_ce: 0.007566
2022-01-13 21:54:21,749 iteration 5582 : loss : 0.022877, loss_ce: 0.006757
2022-01-13 21:54:23,110 iteration 5583 : loss : 0.022956, loss_ce: 0.006645
2022-01-13 21:54:24,573 iteration 5584 : loss : 0.051098, loss_ce: 0.018632
2022-01-13 21:54:25,926 iteration 5585 : loss : 0.038543, loss_ce: 0.016065
2022-01-13 21:54:27,299 iteration 5586 : loss : 0.022067, loss_ce: 0.010228
2022-01-13 21:54:28,670 iteration 5587 : loss : 0.023989, loss_ce: 0.013605
2022-01-13 21:54:30,116 iteration 5588 : loss : 0.026617, loss_ce: 0.008775
2022-01-13 21:54:31,543 iteration 5589 : loss : 0.025792, loss_ce: 0.010527
2022-01-13 21:54:32,925 iteration 5590 : loss : 0.023568, loss_ce: 0.008860
2022-01-13 21:54:34,309 iteration 5591 : loss : 0.018337, loss_ce: 0.008458
2022-01-13 21:54:35,672 iteration 5592 : loss : 0.019932, loss_ce: 0.007296
2022-01-13 21:54:37,046 iteration 5593 : loss : 0.015636, loss_ce: 0.008909
 82%|███████████████████████▊     | 329/400 [2:20:08<28:51, 24.39s/it]2022-01-13 21:54:38,511 iteration 5594 : loss : 0.025101, loss_ce: 0.011547
2022-01-13 21:54:39,863 iteration 5595 : loss : 0.019875, loss_ce: 0.009757
2022-01-13 21:54:41,214 iteration 5596 : loss : 0.012631, loss_ce: 0.003979
2022-01-13 21:54:42,607 iteration 5597 : loss : 0.015555, loss_ce: 0.004687
2022-01-13 21:54:44,069 iteration 5598 : loss : 0.028876, loss_ce: 0.010226
2022-01-13 21:54:45,522 iteration 5599 : loss : 0.020686, loss_ce: 0.006604
2022-01-13 21:54:46,936 iteration 5600 : loss : 0.019409, loss_ce: 0.008466
2022-01-13 21:54:48,353 iteration 5601 : loss : 0.020871, loss_ce: 0.006332
2022-01-13 21:54:49,694 iteration 5602 : loss : 0.021279, loss_ce: 0.005642
2022-01-13 21:54:51,119 iteration 5603 : loss : 0.023966, loss_ce: 0.010479
2022-01-13 21:54:52,468 iteration 5604 : loss : 0.023925, loss_ce: 0.011642
2022-01-13 21:54:53,818 iteration 5605 : loss : 0.020229, loss_ce: 0.006517
2022-01-13 21:54:55,261 iteration 5606 : loss : 0.027703, loss_ce: 0.008361
2022-01-13 21:54:56,637 iteration 5607 : loss : 0.024998, loss_ce: 0.009404
2022-01-13 21:54:58,135 iteration 5608 : loss : 0.029148, loss_ce: 0.014458
2022-01-13 21:54:59,483 iteration 5609 : loss : 0.018655, loss_ce: 0.008681
2022-01-13 21:54:59,483 Training Data Eval:
2022-01-13 21:55:06,287   Average segmentation loss on training set: 0.0107
2022-01-13 21:55:06,288 Validation Data Eval:
2022-01-13 21:55:08,619   Average segmentation loss on validation set: 0.0771
2022-01-13 21:55:10,015 iteration 5610 : loss : 0.016486, loss_ce: 0.006069
 82%|███████████████████████▉     | 330/400 [2:20:41<31:27, 26.96s/it]2022-01-13 21:55:11,493 iteration 5611 : loss : 0.020334, loss_ce: 0.009754
2022-01-13 21:55:12,895 iteration 5612 : loss : 0.021286, loss_ce: 0.006868
2022-01-13 21:55:14,288 iteration 5613 : loss : 0.023106, loss_ce: 0.010920
2022-01-13 21:55:15,665 iteration 5614 : loss : 0.022319, loss_ce: 0.009219
2022-01-13 21:55:17,070 iteration 5615 : loss : 0.022678, loss_ce: 0.008018
2022-01-13 21:55:18,489 iteration 5616 : loss : 0.018643, loss_ce: 0.008076
2022-01-13 21:55:19,870 iteration 5617 : loss : 0.018913, loss_ce: 0.008540
2022-01-13 21:55:21,196 iteration 5618 : loss : 0.017025, loss_ce: 0.007194
2022-01-13 21:55:22,653 iteration 5619 : loss : 0.035013, loss_ce: 0.012770
2022-01-13 21:55:24,084 iteration 5620 : loss : 0.023300, loss_ce: 0.007823
2022-01-13 21:55:25,427 iteration 5621 : loss : 0.020360, loss_ce: 0.007886
2022-01-13 21:55:26,887 iteration 5622 : loss : 0.022734, loss_ce: 0.010010
2022-01-13 21:55:28,226 iteration 5623 : loss : 0.033350, loss_ce: 0.009360
2022-01-13 21:55:29,622 iteration 5624 : loss : 0.018890, loss_ce: 0.008282
2022-01-13 21:55:31,031 iteration 5625 : loss : 0.038789, loss_ce: 0.016618
2022-01-13 21:55:32,411 iteration 5626 : loss : 0.019080, loss_ce: 0.008017
2022-01-13 21:55:33,772 iteration 5627 : loss : 0.025559, loss_ce: 0.008481
 83%|███████████████████████▉     | 331/400 [2:21:05<29:54, 26.00s/it]2022-01-13 21:55:35,102 iteration 5628 : loss : 0.016104, loss_ce: 0.006244
2022-01-13 21:55:36,503 iteration 5629 : loss : 0.026065, loss_ce: 0.012659
2022-01-13 21:55:37,872 iteration 5630 : loss : 0.014890, loss_ce: 0.005153
2022-01-13 21:55:39,370 iteration 5631 : loss : 0.026616, loss_ce: 0.012668
2022-01-13 21:55:40,672 iteration 5632 : loss : 0.021930, loss_ce: 0.009469
2022-01-13 21:55:42,092 iteration 5633 : loss : 0.022728, loss_ce: 0.009385
2022-01-13 21:55:43,421 iteration 5634 : loss : 0.021633, loss_ce: 0.007529
2022-01-13 21:55:44,819 iteration 5635 : loss : 0.027051, loss_ce: 0.008129
2022-01-13 21:55:46,141 iteration 5636 : loss : 0.015019, loss_ce: 0.006688
2022-01-13 21:55:47,535 iteration 5637 : loss : 0.028162, loss_ce: 0.011850
2022-01-13 21:55:48,803 iteration 5638 : loss : 0.014899, loss_ce: 0.004994
2022-01-13 21:55:50,122 iteration 5639 : loss : 0.020689, loss_ce: 0.006000
2022-01-13 21:55:51,474 iteration 5640 : loss : 0.016971, loss_ce: 0.008573
2022-01-13 21:55:52,884 iteration 5641 : loss : 0.017101, loss_ce: 0.009306
2022-01-13 21:55:54,242 iteration 5642 : loss : 0.020852, loss_ce: 0.003972
2022-01-13 21:55:55,665 iteration 5643 : loss : 0.016292, loss_ce: 0.004632
2022-01-13 21:55:57,066 iteration 5644 : loss : 0.033895, loss_ce: 0.012497
 83%|████████████████████████     | 332/400 [2:21:28<28:33, 25.19s/it]2022-01-13 21:55:58,614 iteration 5645 : loss : 0.033257, loss_ce: 0.011667
2022-01-13 21:55:59,955 iteration 5646 : loss : 0.018687, loss_ce: 0.006432
2022-01-13 21:56:01,344 iteration 5647 : loss : 0.031289, loss_ce: 0.017317
2022-01-13 21:56:02,785 iteration 5648 : loss : 0.031916, loss_ce: 0.011512
2022-01-13 21:56:04,228 iteration 5649 : loss : 0.021827, loss_ce: 0.009773
2022-01-13 21:56:05,617 iteration 5650 : loss : 0.020576, loss_ce: 0.008035
2022-01-13 21:56:07,017 iteration 5651 : loss : 0.022346, loss_ce: 0.012003
2022-01-13 21:56:08,329 iteration 5652 : loss : 0.013611, loss_ce: 0.005121
2022-01-13 21:56:09,681 iteration 5653 : loss : 0.016007, loss_ce: 0.005920
2022-01-13 21:56:10,997 iteration 5654 : loss : 0.015752, loss_ce: 0.004590
2022-01-13 21:56:12,391 iteration 5655 : loss : 0.023307, loss_ce: 0.008563
2022-01-13 21:56:13,756 iteration 5656 : loss : 0.034988, loss_ce: 0.011194
2022-01-13 21:56:15,129 iteration 5657 : loss : 0.022400, loss_ce: 0.009308
2022-01-13 21:56:16,508 iteration 5658 : loss : 0.025123, loss_ce: 0.011055
2022-01-13 21:56:17,856 iteration 5659 : loss : 0.021833, loss_ce: 0.006257
2022-01-13 21:56:19,173 iteration 5660 : loss : 0.022383, loss_ce: 0.008809
2022-01-13 21:56:20,634 iteration 5661 : loss : 0.022165, loss_ce: 0.007097
 83%|████████████████████████▏    | 333/400 [2:21:52<27:35, 24.71s/it]2022-01-13 21:56:22,067 iteration 5662 : loss : 0.022629, loss_ce: 0.006115
2022-01-13 21:56:23,434 iteration 5663 : loss : 0.025143, loss_ce: 0.009597
2022-01-13 21:56:24,826 iteration 5664 : loss : 0.024672, loss_ce: 0.008363
2022-01-13 21:56:26,120 iteration 5665 : loss : 0.016587, loss_ce: 0.005988
2022-01-13 21:56:27,515 iteration 5666 : loss : 0.019472, loss_ce: 0.007870
2022-01-13 21:56:28,929 iteration 5667 : loss : 0.023310, loss_ce: 0.009320
2022-01-13 21:56:30,303 iteration 5668 : loss : 0.019022, loss_ce: 0.008517
2022-01-13 21:56:31,729 iteration 5669 : loss : 0.021801, loss_ce: 0.010822
2022-01-13 21:56:33,118 iteration 5670 : loss : 0.015443, loss_ce: 0.005059
2022-01-13 21:56:34,506 iteration 5671 : loss : 0.017084, loss_ce: 0.006012
2022-01-13 21:56:35,880 iteration 5672 : loss : 0.027623, loss_ce: 0.008186
2022-01-13 21:56:37,220 iteration 5673 : loss : 0.016200, loss_ce: 0.005842
2022-01-13 21:56:38,665 iteration 5674 : loss : 0.022297, loss_ce: 0.011635
2022-01-13 21:56:40,015 iteration 5675 : loss : 0.016613, loss_ce: 0.007685
2022-01-13 21:56:41,455 iteration 5676 : loss : 0.022355, loss_ce: 0.007986
2022-01-13 21:56:42,874 iteration 5677 : loss : 0.018184, loss_ce: 0.009670
2022-01-13 21:56:44,268 iteration 5678 : loss : 0.049032, loss_ce: 0.016810
 84%|████████████████████████▏    | 334/400 [2:22:16<26:49, 24.38s/it]2022-01-13 21:56:45,713 iteration 5679 : loss : 0.028098, loss_ce: 0.010991
2022-01-13 21:56:46,989 iteration 5680 : loss : 0.016445, loss_ce: 0.004252
2022-01-13 21:56:48,419 iteration 5681 : loss : 0.031155, loss_ce: 0.010194
2022-01-13 21:56:49,839 iteration 5682 : loss : 0.021529, loss_ce: 0.010008
2022-01-13 21:56:51,183 iteration 5683 : loss : 0.017735, loss_ce: 0.006497
2022-01-13 21:56:52,524 iteration 5684 : loss : 0.015923, loss_ce: 0.009060
2022-01-13 21:56:53,917 iteration 5685 : loss : 0.023899, loss_ce: 0.010381
2022-01-13 21:56:55,271 iteration 5686 : loss : 0.020794, loss_ce: 0.008631
2022-01-13 21:56:56,638 iteration 5687 : loss : 0.014795, loss_ce: 0.006301
2022-01-13 21:56:58,119 iteration 5688 : loss : 0.029848, loss_ce: 0.010834
2022-01-13 21:56:59,501 iteration 5689 : loss : 0.024286, loss_ce: 0.007280
2022-01-13 21:57:00,894 iteration 5690 : loss : 0.022749, loss_ce: 0.009992
2022-01-13 21:57:02,308 iteration 5691 : loss : 0.027014, loss_ce: 0.012755
2022-01-13 21:57:03,715 iteration 5692 : loss : 0.030504, loss_ce: 0.014337
2022-01-13 21:57:05,108 iteration 5693 : loss : 0.024791, loss_ce: 0.005355
2022-01-13 21:57:06,467 iteration 5694 : loss : 0.024567, loss_ce: 0.010888
2022-01-13 21:57:06,468 Training Data Eval:
2022-01-13 21:57:13,252   Average segmentation loss on training set: 0.0109
2022-01-13 21:57:13,253 Validation Data Eval:
2022-01-13 21:57:15,597   Average segmentation loss on validation set: 0.0734
2022-01-13 21:57:16,923 iteration 5695 : loss : 0.015895, loss_ce: 0.005399
 84%|████████████████████████▎    | 335/400 [2:22:48<29:06, 26.86s/it]2022-01-13 21:57:18,306 iteration 5696 : loss : 0.015151, loss_ce: 0.007564
2022-01-13 21:57:19,628 iteration 5697 : loss : 0.016745, loss_ce: 0.008066
2022-01-13 21:57:21,044 iteration 5698 : loss : 0.026228, loss_ce: 0.009160
2022-01-13 21:57:22,346 iteration 5699 : loss : 0.023434, loss_ce: 0.010615
2022-01-13 21:57:23,703 iteration 5700 : loss : 0.015226, loss_ce: 0.005535
2022-01-13 21:57:25,016 iteration 5701 : loss : 0.021581, loss_ce: 0.009194
2022-01-13 21:57:26,487 iteration 5702 : loss : 0.021951, loss_ce: 0.010043
2022-01-13 21:57:27,897 iteration 5703 : loss : 0.027838, loss_ce: 0.012169
2022-01-13 21:57:29,290 iteration 5704 : loss : 0.019442, loss_ce: 0.007975
2022-01-13 21:57:30,700 iteration 5705 : loss : 0.016802, loss_ce: 0.005855
2022-01-13 21:57:31,988 iteration 5706 : loss : 0.016896, loss_ce: 0.006243
2022-01-13 21:57:33,337 iteration 5707 : loss : 0.023260, loss_ce: 0.007869
2022-01-13 21:57:34,656 iteration 5708 : loss : 0.016273, loss_ce: 0.006257
2022-01-13 21:57:36,031 iteration 5709 : loss : 0.017829, loss_ce: 0.007153
2022-01-13 21:57:37,396 iteration 5710 : loss : 0.021000, loss_ce: 0.006362
2022-01-13 21:57:38,700 iteration 5711 : loss : 0.017326, loss_ce: 0.006227
2022-01-13 21:57:40,082 iteration 5712 : loss : 0.022108, loss_ce: 0.009547
 84%|████████████████████████▎    | 336/400 [2:23:11<27:28, 25.75s/it]2022-01-13 21:57:41,549 iteration 5713 : loss : 0.018938, loss_ce: 0.006336
2022-01-13 21:57:42,965 iteration 5714 : loss : 0.034685, loss_ce: 0.013694
2022-01-13 21:57:44,409 iteration 5715 : loss : 0.020213, loss_ce: 0.009177
2022-01-13 21:57:45,767 iteration 5716 : loss : 0.017335, loss_ce: 0.006737
2022-01-13 21:57:47,231 iteration 5717 : loss : 0.021181, loss_ce: 0.009136
2022-01-13 21:57:48,555 iteration 5718 : loss : 0.017233, loss_ce: 0.005905
2022-01-13 21:57:49,890 iteration 5719 : loss : 0.018228, loss_ce: 0.008128
2022-01-13 21:57:51,309 iteration 5720 : loss : 0.035657, loss_ce: 0.014200
2022-01-13 21:57:52,706 iteration 5721 : loss : 0.025103, loss_ce: 0.012821
2022-01-13 21:57:54,073 iteration 5722 : loss : 0.017831, loss_ce: 0.007187
2022-01-13 21:57:55,456 iteration 5723 : loss : 0.021310, loss_ce: 0.008529
2022-01-13 21:57:56,876 iteration 5724 : loss : 0.022106, loss_ce: 0.008475
2022-01-13 21:57:58,257 iteration 5725 : loss : 0.015278, loss_ce: 0.005758
2022-01-13 21:57:59,582 iteration 5726 : loss : 0.018346, loss_ce: 0.004944
2022-01-13 21:58:00,971 iteration 5727 : loss : 0.017214, loss_ce: 0.005526
2022-01-13 21:58:02,323 iteration 5728 : loss : 0.021521, loss_ce: 0.007606
2022-01-13 21:58:03,764 iteration 5729 : loss : 0.016152, loss_ce: 0.006516
 84%|████████████████████████▍    | 337/400 [2:23:35<26:23, 25.13s/it]2022-01-13 21:58:05,150 iteration 5730 : loss : 0.015524, loss_ce: 0.007266
2022-01-13 21:58:06,575 iteration 5731 : loss : 0.019164, loss_ce: 0.008391
2022-01-13 21:58:07,903 iteration 5732 : loss : 0.014421, loss_ce: 0.005975
2022-01-13 21:58:09,334 iteration 5733 : loss : 0.030212, loss_ce: 0.007629
2022-01-13 21:58:10,756 iteration 5734 : loss : 0.020643, loss_ce: 0.008538
2022-01-13 21:58:12,102 iteration 5735 : loss : 0.016224, loss_ce: 0.004373
2022-01-13 21:58:13,444 iteration 5736 : loss : 0.028322, loss_ce: 0.014040
2022-01-13 21:58:14,911 iteration 5737 : loss : 0.043291, loss_ce: 0.016579
2022-01-13 21:58:16,251 iteration 5738 : loss : 0.015516, loss_ce: 0.005442
2022-01-13 21:58:17,584 iteration 5739 : loss : 0.014900, loss_ce: 0.005517
2022-01-13 21:58:18,953 iteration 5740 : loss : 0.022064, loss_ce: 0.009313
2022-01-13 21:58:20,326 iteration 5741 : loss : 0.022314, loss_ce: 0.010844
2022-01-13 21:58:21,714 iteration 5742 : loss : 0.016523, loss_ce: 0.003376
2022-01-13 21:58:23,120 iteration 5743 : loss : 0.014361, loss_ce: 0.006377
2022-01-13 21:58:24,545 iteration 5744 : loss : 0.027643, loss_ce: 0.012419
2022-01-13 21:58:25,982 iteration 5745 : loss : 0.022660, loss_ce: 0.010352
2022-01-13 21:58:27,326 iteration 5746 : loss : 0.018988, loss_ce: 0.005370
 84%|████████████████████████▌    | 338/400 [2:23:59<25:29, 24.66s/it]2022-01-13 21:58:28,761 iteration 5747 : loss : 0.019858, loss_ce: 0.007681
2022-01-13 21:58:30,153 iteration 5748 : loss : 0.019414, loss_ce: 0.007828
2022-01-13 21:58:31,528 iteration 5749 : loss : 0.023028, loss_ce: 0.009653
2022-01-13 21:58:32,899 iteration 5750 : loss : 0.017934, loss_ce: 0.006694
2022-01-13 21:58:34,217 iteration 5751 : loss : 0.020282, loss_ce: 0.007281
2022-01-13 21:58:35,604 iteration 5752 : loss : 0.022985, loss_ce: 0.007957
2022-01-13 21:58:37,024 iteration 5753 : loss : 0.015991, loss_ce: 0.006363
2022-01-13 21:58:38,453 iteration 5754 : loss : 0.029735, loss_ce: 0.010767
2022-01-13 21:58:39,831 iteration 5755 : loss : 0.019755, loss_ce: 0.008244
2022-01-13 21:58:41,179 iteration 5756 : loss : 0.017492, loss_ce: 0.006561
2022-01-13 21:58:42,451 iteration 5757 : loss : 0.013696, loss_ce: 0.005525
2022-01-13 21:58:43,891 iteration 5758 : loss : 0.028748, loss_ce: 0.014400
2022-01-13 21:58:45,332 iteration 5759 : loss : 0.020874, loss_ce: 0.009558
2022-01-13 21:58:46,794 iteration 5760 : loss : 0.020478, loss_ce: 0.010906
2022-01-13 21:58:48,272 iteration 5761 : loss : 0.034479, loss_ce: 0.014421
2022-01-13 21:58:49,599 iteration 5762 : loss : 0.018408, loss_ce: 0.009317
2022-01-13 21:58:51,020 iteration 5763 : loss : 0.015745, loss_ce: 0.006195
 85%|████████████████████████▌    | 339/400 [2:24:22<24:46, 24.37s/it]2022-01-13 21:58:52,480 iteration 5764 : loss : 0.019621, loss_ce: 0.007203
2022-01-13 21:58:53,923 iteration 5765 : loss : 0.058469, loss_ce: 0.013244
2022-01-13 21:58:55,328 iteration 5766 : loss : 0.022003, loss_ce: 0.012195
2022-01-13 21:58:56,704 iteration 5767 : loss : 0.017480, loss_ce: 0.010213
2022-01-13 21:58:58,187 iteration 5768 : loss : 0.021099, loss_ce: 0.007889
2022-01-13 21:58:59,618 iteration 5769 : loss : 0.024683, loss_ce: 0.007179
2022-01-13 21:59:00,977 iteration 5770 : loss : 0.015519, loss_ce: 0.005584
2022-01-13 21:59:02,378 iteration 5771 : loss : 0.025355, loss_ce: 0.009420
2022-01-13 21:59:03,749 iteration 5772 : loss : 0.021523, loss_ce: 0.007651
2022-01-13 21:59:05,056 iteration 5773 : loss : 0.017015, loss_ce: 0.005210
2022-01-13 21:59:06,344 iteration 5774 : loss : 0.017090, loss_ce: 0.004547
2022-01-13 21:59:07,738 iteration 5775 : loss : 0.017274, loss_ce: 0.006986
2022-01-13 21:59:09,213 iteration 5776 : loss : 0.024550, loss_ce: 0.010808
2022-01-13 21:59:10,505 iteration 5777 : loss : 0.017258, loss_ce: 0.007019
2022-01-13 21:59:11,857 iteration 5778 : loss : 0.028493, loss_ce: 0.007874
2022-01-13 21:59:13,227 iteration 5779 : loss : 0.015420, loss_ce: 0.005254
2022-01-13 21:59:13,228 Training Data Eval:
2022-01-13 21:59:20,044   Average segmentation loss on training set: 0.0109
2022-01-13 21:59:20,045 Validation Data Eval:
2022-01-13 21:59:22,388   Average segmentation loss on validation set: 0.0706
2022-01-13 21:59:23,752 iteration 5780 : loss : 0.022860, loss_ce: 0.007238
 85%|████████████████████████▋    | 340/400 [2:24:55<26:52, 26.88s/it]2022-01-13 21:59:25,150 iteration 5781 : loss : 0.025810, loss_ce: 0.007831
2022-01-13 21:59:26,584 iteration 5782 : loss : 0.038786, loss_ce: 0.015019
2022-01-13 21:59:27,955 iteration 5783 : loss : 0.021255, loss_ce: 0.008064
2022-01-13 21:59:29,354 iteration 5784 : loss : 0.021250, loss_ce: 0.010997
2022-01-13 21:59:30,690 iteration 5785 : loss : 0.015034, loss_ce: 0.005947
2022-01-13 21:59:32,034 iteration 5786 : loss : 0.024598, loss_ce: 0.012338
2022-01-13 21:59:33,375 iteration 5787 : loss : 0.018095, loss_ce: 0.007050
2022-01-13 21:59:34,924 iteration 5788 : loss : 0.019758, loss_ce: 0.007557
2022-01-13 21:59:36,323 iteration 5789 : loss : 0.017408, loss_ce: 0.005904
2022-01-13 21:59:37,705 iteration 5790 : loss : 0.017241, loss_ce: 0.006403
2022-01-13 21:59:39,037 iteration 5791 : loss : 0.014614, loss_ce: 0.005362
2022-01-13 21:59:40,441 iteration 5792 : loss : 0.048086, loss_ce: 0.021717
2022-01-13 21:59:41,928 iteration 5793 : loss : 0.026071, loss_ce: 0.011420
2022-01-13 21:59:43,326 iteration 5794 : loss : 0.022610, loss_ce: 0.009949
2022-01-13 21:59:44,701 iteration 5795 : loss : 0.020935, loss_ce: 0.008403
2022-01-13 21:59:46,030 iteration 5796 : loss : 0.012726, loss_ce: 0.003587
2022-01-13 21:59:47,426 iteration 5797 : loss : 0.022927, loss_ce: 0.009185
 85%|████████████████████████▋    | 341/400 [2:25:19<25:29, 25.92s/it]2022-01-13 21:59:48,897 iteration 5798 : loss : 0.023166, loss_ce: 0.009819
2022-01-13 21:59:50,292 iteration 5799 : loss : 0.029550, loss_ce: 0.014528
2022-01-13 21:59:51,661 iteration 5800 : loss : 0.018036, loss_ce: 0.007912
2022-01-13 21:59:53,029 iteration 5801 : loss : 0.017446, loss_ce: 0.006119
2022-01-13 21:59:54,339 iteration 5802 : loss : 0.013755, loss_ce: 0.006096
2022-01-13 21:59:55,679 iteration 5803 : loss : 0.014300, loss_ce: 0.006609
2022-01-13 21:59:57,045 iteration 5804 : loss : 0.028340, loss_ce: 0.011738
2022-01-13 21:59:58,508 iteration 5805 : loss : 0.018339, loss_ce: 0.006903
2022-01-13 21:59:59,887 iteration 5806 : loss : 0.026753, loss_ce: 0.009716
2022-01-13 22:00:01,369 iteration 5807 : loss : 0.025035, loss_ce: 0.009629
2022-01-13 22:00:02,776 iteration 5808 : loss : 0.020007, loss_ce: 0.009651
2022-01-13 22:00:04,094 iteration 5809 : loss : 0.024110, loss_ce: 0.008729
2022-01-13 22:00:05,433 iteration 5810 : loss : 0.040152, loss_ce: 0.013804
2022-01-13 22:00:06,779 iteration 5811 : loss : 0.013812, loss_ce: 0.004534
2022-01-13 22:00:08,182 iteration 5812 : loss : 0.021942, loss_ce: 0.008551
2022-01-13 22:00:09,493 iteration 5813 : loss : 0.017480, loss_ce: 0.007766
2022-01-13 22:00:10,876 iteration 5814 : loss : 0.022625, loss_ce: 0.010737
 86%|████████████████████████▊    | 342/400 [2:25:42<24:20, 25.18s/it]2022-01-13 22:00:12,240 iteration 5815 : loss : 0.013501, loss_ce: 0.004766
2022-01-13 22:00:13,591 iteration 5816 : loss : 0.012702, loss_ce: 0.005936
2022-01-13 22:00:14,930 iteration 5817 : loss : 0.014923, loss_ce: 0.005684
2022-01-13 22:00:16,207 iteration 5818 : loss : 0.018518, loss_ce: 0.007719
2022-01-13 22:00:17,625 iteration 5819 : loss : 0.020347, loss_ce: 0.007642
2022-01-13 22:00:19,081 iteration 5820 : loss : 0.024372, loss_ce: 0.011653
2022-01-13 22:00:20,391 iteration 5821 : loss : 0.013017, loss_ce: 0.004393
2022-01-13 22:00:21,724 iteration 5822 : loss : 0.013500, loss_ce: 0.005958
2022-01-13 22:00:23,193 iteration 5823 : loss : 0.026836, loss_ce: 0.011766
2022-01-13 22:00:24,562 iteration 5824 : loss : 0.015238, loss_ce: 0.004550
2022-01-13 22:00:25,979 iteration 5825 : loss : 0.020512, loss_ce: 0.007990
2022-01-13 22:00:27,432 iteration 5826 : loss : 0.019667, loss_ce: 0.004872
2022-01-13 22:00:28,810 iteration 5827 : loss : 0.022716, loss_ce: 0.007180
2022-01-13 22:00:30,286 iteration 5828 : loss : 0.023289, loss_ce: 0.009003
2022-01-13 22:00:31,657 iteration 5829 : loss : 0.015414, loss_ce: 0.006870
2022-01-13 22:00:32,998 iteration 5830 : loss : 0.025244, loss_ce: 0.009255
2022-01-13 22:00:34,349 iteration 5831 : loss : 0.017072, loss_ce: 0.005681
 86%|████████████████████████▊    | 343/400 [2:26:06<23:25, 24.66s/it]2022-01-13 22:00:35,777 iteration 5832 : loss : 0.014914, loss_ce: 0.004857
2022-01-13 22:00:37,190 iteration 5833 : loss : 0.016383, loss_ce: 0.007494
2022-01-13 22:00:38,505 iteration 5834 : loss : 0.015099, loss_ce: 0.005830
2022-01-13 22:00:39,830 iteration 5835 : loss : 0.026113, loss_ce: 0.008371
2022-01-13 22:00:41,251 iteration 5836 : loss : 0.029826, loss_ce: 0.015069
2022-01-13 22:00:42,624 iteration 5837 : loss : 0.017284, loss_ce: 0.004005
2022-01-13 22:00:43,907 iteration 5838 : loss : 0.011142, loss_ce: 0.003434
2022-01-13 22:00:45,266 iteration 5839 : loss : 0.020604, loss_ce: 0.007616
2022-01-13 22:00:46,680 iteration 5840 : loss : 0.024286, loss_ce: 0.009737
2022-01-13 22:00:48,026 iteration 5841 : loss : 0.016657, loss_ce: 0.007168
2022-01-13 22:00:49,371 iteration 5842 : loss : 0.011113, loss_ce: 0.004285
2022-01-13 22:00:50,721 iteration 5843 : loss : 0.034829, loss_ce: 0.011910
2022-01-13 22:00:52,226 iteration 5844 : loss : 0.027022, loss_ce: 0.007912
2022-01-13 22:00:53,624 iteration 5845 : loss : 0.022831, loss_ce: 0.009200
2022-01-13 22:00:55,011 iteration 5846 : loss : 0.021832, loss_ce: 0.009699
2022-01-13 22:00:56,399 iteration 5847 : loss : 0.019336, loss_ce: 0.007390
2022-01-13 22:00:57,765 iteration 5848 : loss : 0.017250, loss_ce: 0.006565
 86%|████████████████████████▉    | 344/400 [2:26:29<22:40, 24.29s/it]2022-01-13 22:00:59,208 iteration 5849 : loss : 0.023491, loss_ce: 0.010356
2022-01-13 22:01:00,564 iteration 5850 : loss : 0.013858, loss_ce: 0.005453
2022-01-13 22:01:01,935 iteration 5851 : loss : 0.019983, loss_ce: 0.007718
2022-01-13 22:01:03,280 iteration 5852 : loss : 0.016233, loss_ce: 0.006348
2022-01-13 22:01:04,569 iteration 5853 : loss : 0.014154, loss_ce: 0.004579
2022-01-13 22:01:05,908 iteration 5854 : loss : 0.024382, loss_ce: 0.008746
2022-01-13 22:01:07,382 iteration 5855 : loss : 0.020781, loss_ce: 0.009026
2022-01-13 22:01:08,756 iteration 5856 : loss : 0.017411, loss_ce: 0.007547
2022-01-13 22:01:10,136 iteration 5857 : loss : 0.016952, loss_ce: 0.005553
2022-01-13 22:01:11,434 iteration 5858 : loss : 0.015384, loss_ce: 0.005597
2022-01-13 22:01:12,847 iteration 5859 : loss : 0.019349, loss_ce: 0.007161
2022-01-13 22:01:14,261 iteration 5860 : loss : 0.023675, loss_ce: 0.007388
2022-01-13 22:01:15,623 iteration 5861 : loss : 0.020261, loss_ce: 0.005962
2022-01-13 22:01:17,017 iteration 5862 : loss : 0.025835, loss_ce: 0.013211
2022-01-13 22:01:18,297 iteration 5863 : loss : 0.010811, loss_ce: 0.003489
2022-01-13 22:01:19,694 iteration 5864 : loss : 0.025509, loss_ce: 0.007087
2022-01-13 22:01:19,695 Training Data Eval:
2022-01-13 22:01:26,510   Average segmentation loss on training set: 0.0102
2022-01-13 22:01:26,510 Validation Data Eval:
2022-01-13 22:01:28,853   Average segmentation loss on validation set: 0.0812
2022-01-13 22:01:30,165 iteration 5865 : loss : 0.019099, loss_ce: 0.005142
 86%|█████████████████████████    | 345/400 [2:27:01<24:29, 26.72s/it]2022-01-13 22:01:31,666 iteration 5866 : loss : 0.016512, loss_ce: 0.007512
2022-01-13 22:01:33,091 iteration 5867 : loss : 0.023607, loss_ce: 0.006834
2022-01-13 22:01:34,503 iteration 5868 : loss : 0.028000, loss_ce: 0.009577
2022-01-13 22:01:35,797 iteration 5869 : loss : 0.013985, loss_ce: 0.006234
2022-01-13 22:01:37,247 iteration 5870 : loss : 0.031540, loss_ce: 0.008943
2022-01-13 22:01:38,646 iteration 5871 : loss : 0.014137, loss_ce: 0.005016
2022-01-13 22:01:40,058 iteration 5872 : loss : 0.030795, loss_ce: 0.009865
2022-01-13 22:01:41,561 iteration 5873 : loss : 0.021231, loss_ce: 0.007027
2022-01-13 22:01:42,901 iteration 5874 : loss : 0.015809, loss_ce: 0.005612
2022-01-13 22:01:44,250 iteration 5875 : loss : 0.016297, loss_ce: 0.008251
2022-01-13 22:01:45,650 iteration 5876 : loss : 0.018909, loss_ce: 0.006608
2022-01-13 22:01:47,017 iteration 5877 : loss : 0.018126, loss_ce: 0.006716
2022-01-13 22:01:48,417 iteration 5878 : loss : 0.019342, loss_ce: 0.008874
2022-01-13 22:01:49,767 iteration 5879 : loss : 0.016351, loss_ce: 0.007317
2022-01-13 22:01:51,237 iteration 5880 : loss : 0.025480, loss_ce: 0.006476
2022-01-13 22:01:52,553 iteration 5881 : loss : 0.013111, loss_ce: 0.004569
2022-01-13 22:01:53,904 iteration 5882 : loss : 0.015207, loss_ce: 0.006699
 86%|█████████████████████████    | 346/400 [2:27:25<23:14, 25.83s/it]2022-01-13 22:01:55,316 iteration 5883 : loss : 0.014022, loss_ce: 0.004531
2022-01-13 22:01:56,684 iteration 5884 : loss : 0.033134, loss_ce: 0.014951
2022-01-13 22:01:58,243 iteration 5885 : loss : 0.028482, loss_ce: 0.010165
2022-01-13 22:01:59,591 iteration 5886 : loss : 0.015973, loss_ce: 0.004574
2022-01-13 22:02:00,934 iteration 5887 : loss : 0.013666, loss_ce: 0.005861
2022-01-13 22:02:02,399 iteration 5888 : loss : 0.021443, loss_ce: 0.007481
2022-01-13 22:02:03,863 iteration 5889 : loss : 0.023003, loss_ce: 0.008590
2022-01-13 22:02:05,263 iteration 5890 : loss : 0.015075, loss_ce: 0.005116
2022-01-13 22:02:06,738 iteration 5891 : loss : 0.029649, loss_ce: 0.009656
2022-01-13 22:02:08,259 iteration 5892 : loss : 0.022441, loss_ce: 0.009627
2022-01-13 22:02:09,631 iteration 5893 : loss : 0.013597, loss_ce: 0.004581
2022-01-13 22:02:11,130 iteration 5894 : loss : 0.023549, loss_ce: 0.009808
2022-01-13 22:02:12,578 iteration 5895 : loss : 0.024432, loss_ce: 0.009344
2022-01-13 22:02:13,975 iteration 5896 : loss : 0.015363, loss_ce: 0.007189
2022-01-13 22:02:15,480 iteration 5897 : loss : 0.042368, loss_ce: 0.023613
2022-01-13 22:02:16,965 iteration 5898 : loss : 0.015110, loss_ce: 0.005910
2022-01-13 22:02:18,344 iteration 5899 : loss : 0.017751, loss_ce: 0.006522
 87%|█████████████████████████▏   | 347/400 [2:27:50<22:26, 25.41s/it]2022-01-13 22:02:19,823 iteration 5900 : loss : 0.016594, loss_ce: 0.006332
2022-01-13 22:02:21,324 iteration 5901 : loss : 0.028377, loss_ce: 0.010487
2022-01-13 22:02:22,735 iteration 5902 : loss : 0.024637, loss_ce: 0.012333
2022-01-13 22:02:24,210 iteration 5903 : loss : 0.017129, loss_ce: 0.007586
2022-01-13 22:02:25,614 iteration 5904 : loss : 0.024263, loss_ce: 0.009418
2022-01-13 22:02:27,083 iteration 5905 : loss : 0.036350, loss_ce: 0.009938
2022-01-13 22:02:28,421 iteration 5906 : loss : 0.018666, loss_ce: 0.007052
2022-01-13 22:02:29,859 iteration 5907 : loss : 0.013851, loss_ce: 0.005188
2022-01-13 22:02:31,298 iteration 5908 : loss : 0.020557, loss_ce: 0.008999
2022-01-13 22:02:32,620 iteration 5909 : loss : 0.032573, loss_ce: 0.010169
2022-01-13 22:02:34,034 iteration 5910 : loss : 0.023049, loss_ce: 0.008661
2022-01-13 22:02:35,486 iteration 5911 : loss : 0.030396, loss_ce: 0.012631
2022-01-13 22:02:36,821 iteration 5912 : loss : 0.016572, loss_ce: 0.005540
2022-01-13 22:02:38,207 iteration 5913 : loss : 0.018901, loss_ce: 0.008871
2022-01-13 22:02:39,615 iteration 5914 : loss : 0.025018, loss_ce: 0.009383
2022-01-13 22:02:40,924 iteration 5915 : loss : 0.017280, loss_ce: 0.006622
2022-01-13 22:02:42,380 iteration 5916 : loss : 0.028233, loss_ce: 0.010382
 87%|█████████████████████████▏   | 348/400 [2:28:14<21:39, 25.00s/it]2022-01-13 22:02:43,806 iteration 5917 : loss : 0.018678, loss_ce: 0.006787
2022-01-13 22:02:45,132 iteration 5918 : loss : 0.015747, loss_ce: 0.006051
2022-01-13 22:02:46,571 iteration 5919 : loss : 0.026094, loss_ce: 0.011766
2022-01-13 22:02:48,032 iteration 5920 : loss : 0.026551, loss_ce: 0.015555
2022-01-13 22:02:49,565 iteration 5921 : loss : 0.037252, loss_ce: 0.009627
2022-01-13 22:02:50,923 iteration 5922 : loss : 0.015440, loss_ce: 0.004456
2022-01-13 22:02:52,319 iteration 5923 : loss : 0.018940, loss_ce: 0.005763
2022-01-13 22:02:53,826 iteration 5924 : loss : 0.022268, loss_ce: 0.005125
2022-01-13 22:02:55,218 iteration 5925 : loss : 0.019122, loss_ce: 0.006724
2022-01-13 22:02:56,600 iteration 5926 : loss : 0.019211, loss_ce: 0.008198
2022-01-13 22:02:58,003 iteration 5927 : loss : 0.017048, loss_ce: 0.006568
2022-01-13 22:02:59,320 iteration 5928 : loss : 0.016055, loss_ce: 0.004128
2022-01-13 22:03:00,637 iteration 5929 : loss : 0.018241, loss_ce: 0.009811
2022-01-13 22:03:01,952 iteration 5930 : loss : 0.017130, loss_ce: 0.007566
2022-01-13 22:03:03,339 iteration 5931 : loss : 0.025077, loss_ce: 0.006307
2022-01-13 22:03:04,759 iteration 5932 : loss : 0.022937, loss_ce: 0.009785
2022-01-13 22:03:06,161 iteration 5933 : loss : 0.025021, loss_ce: 0.011160
 87%|█████████████████████████▎   | 349/400 [2:28:37<20:56, 24.63s/it]2022-01-13 22:03:07,549 iteration 5934 : loss : 0.017245, loss_ce: 0.005804
2022-01-13 22:03:09,092 iteration 5935 : loss : 0.021028, loss_ce: 0.007102
2022-01-13 22:03:10,471 iteration 5936 : loss : 0.016065, loss_ce: 0.006750
2022-01-13 22:03:11,822 iteration 5937 : loss : 0.016633, loss_ce: 0.005524
2022-01-13 22:03:13,119 iteration 5938 : loss : 0.010577, loss_ce: 0.004130
2022-01-13 22:03:14,553 iteration 5939 : loss : 0.016325, loss_ce: 0.007337
2022-01-13 22:03:15,872 iteration 5940 : loss : 0.014172, loss_ce: 0.005928
2022-01-13 22:03:17,207 iteration 5941 : loss : 0.018622, loss_ce: 0.007927
2022-01-13 22:03:18,545 iteration 5942 : loss : 0.020703, loss_ce: 0.009784
2022-01-13 22:03:19,924 iteration 5943 : loss : 0.019226, loss_ce: 0.005088
2022-01-13 22:03:21,306 iteration 5944 : loss : 0.013794, loss_ce: 0.006582
2022-01-13 22:03:22,661 iteration 5945 : loss : 0.014466, loss_ce: 0.003617
2022-01-13 22:03:24,132 iteration 5946 : loss : 0.035877, loss_ce: 0.013752
2022-01-13 22:03:25,540 iteration 5947 : loss : 0.020982, loss_ce: 0.008075
2022-01-13 22:03:26,887 iteration 5948 : loss : 0.020360, loss_ce: 0.009140
2022-01-13 22:03:28,333 iteration 5949 : loss : 0.017418, loss_ce: 0.005885
2022-01-13 22:03:28,333 Training Data Eval:
2022-01-13 22:03:35,145   Average segmentation loss on training set: 0.0098
2022-01-13 22:03:35,145 Validation Data Eval:
2022-01-13 22:03:37,500   Average segmentation loss on validation set: 0.0712
2022-01-13 22:03:38,892 iteration 5950 : loss : 0.018610, loss_ce: 0.006463
 88%|█████████████████████████▍   | 350/400 [2:29:10<22:33, 27.06s/it]2022-01-13 22:03:40,273 iteration 5951 : loss : 0.018877, loss_ce: 0.006249
2022-01-13 22:03:41,646 iteration 5952 : loss : 0.018772, loss_ce: 0.007305
2022-01-13 22:03:43,020 iteration 5953 : loss : 0.019618, loss_ce: 0.008102
2022-01-13 22:03:44,356 iteration 5954 : loss : 0.019470, loss_ce: 0.007323
2022-01-13 22:03:45,731 iteration 5955 : loss : 0.021837, loss_ce: 0.006955
2022-01-13 22:03:47,133 iteration 5956 : loss : 0.024167, loss_ce: 0.013239
2022-01-13 22:03:48,532 iteration 5957 : loss : 0.012395, loss_ce: 0.004777
2022-01-13 22:03:49,864 iteration 5958 : loss : 0.016990, loss_ce: 0.007030
2022-01-13 22:03:51,227 iteration 5959 : loss : 0.030264, loss_ce: 0.011934
2022-01-13 22:03:52,552 iteration 5960 : loss : 0.017891, loss_ce: 0.005630
2022-01-13 22:03:53,870 iteration 5961 : loss : 0.022480, loss_ce: 0.004645
2022-01-13 22:03:55,225 iteration 5962 : loss : 0.069520, loss_ce: 0.010903
2022-01-13 22:03:56,658 iteration 5963 : loss : 0.021839, loss_ce: 0.009384
2022-01-13 22:03:58,027 iteration 5964 : loss : 0.012656, loss_ce: 0.005219
2022-01-13 22:03:59,339 iteration 5965 : loss : 0.014868, loss_ce: 0.007080
2022-01-13 22:04:00,789 iteration 5966 : loss : 0.017169, loss_ce: 0.004764
2022-01-13 22:04:02,175 iteration 5967 : loss : 0.020471, loss_ce: 0.007982
 88%|█████████████████████████▍   | 351/400 [2:29:33<21:10, 25.93s/it]2022-01-13 22:04:03,687 iteration 5968 : loss : 0.025657, loss_ce: 0.008212
2022-01-13 22:04:05,061 iteration 5969 : loss : 0.020041, loss_ce: 0.008002
2022-01-13 22:04:06,469 iteration 5970 : loss : 0.020496, loss_ce: 0.007585
2022-01-13 22:04:07,776 iteration 5971 : loss : 0.025612, loss_ce: 0.008675
2022-01-13 22:04:09,053 iteration 5972 : loss : 0.014953, loss_ce: 0.004544
2022-01-13 22:04:10,431 iteration 5973 : loss : 0.025425, loss_ce: 0.012176
2022-01-13 22:04:11,902 iteration 5974 : loss : 0.032642, loss_ce: 0.011128
2022-01-13 22:04:13,227 iteration 5975 : loss : 0.018020, loss_ce: 0.006152
2022-01-13 22:04:14,571 iteration 5976 : loss : 0.017251, loss_ce: 0.005409
2022-01-13 22:04:15,889 iteration 5977 : loss : 0.015986, loss_ce: 0.004552
2022-01-13 22:04:17,203 iteration 5978 : loss : 0.016476, loss_ce: 0.007882
2022-01-13 22:04:18,566 iteration 5979 : loss : 0.020302, loss_ce: 0.010146
2022-01-13 22:04:19,974 iteration 5980 : loss : 0.017396, loss_ce: 0.005982
2022-01-13 22:04:21,306 iteration 5981 : loss : 0.026970, loss_ce: 0.011991
2022-01-13 22:04:22,672 iteration 5982 : loss : 0.027794, loss_ce: 0.011584
2022-01-13 22:04:24,135 iteration 5983 : loss : 0.022358, loss_ce: 0.006653
2022-01-13 22:04:25,475 iteration 5984 : loss : 0.022354, loss_ce: 0.007771
 88%|█████████████████████████▌   | 352/400 [2:29:57<20:06, 25.14s/it]2022-01-13 22:04:26,904 iteration 5985 : loss : 0.018829, loss_ce: 0.005728
2022-01-13 22:04:28,183 iteration 5986 : loss : 0.016154, loss_ce: 0.005334
2022-01-13 22:04:29,575 iteration 5987 : loss : 0.024120, loss_ce: 0.010545
2022-01-13 22:04:31,000 iteration 5988 : loss : 0.017668, loss_ce: 0.006910
2022-01-13 22:04:32,381 iteration 5989 : loss : 0.014526, loss_ce: 0.005619
2022-01-13 22:04:33,725 iteration 5990 : loss : 0.021950, loss_ce: 0.006979
2022-01-13 22:04:35,115 iteration 5991 : loss : 0.024719, loss_ce: 0.009577
2022-01-13 22:04:36,501 iteration 5992 : loss : 0.029851, loss_ce: 0.011174
2022-01-13 22:04:37,862 iteration 5993 : loss : 0.014947, loss_ce: 0.006267
2022-01-13 22:04:39,298 iteration 5994 : loss : 0.031360, loss_ce: 0.012023
2022-01-13 22:04:40,655 iteration 5995 : loss : 0.017124, loss_ce: 0.006902
2022-01-13 22:04:41,977 iteration 5996 : loss : 0.014307, loss_ce: 0.004142
2022-01-13 22:04:43,364 iteration 5997 : loss : 0.023957, loss_ce: 0.009141
2022-01-13 22:04:44,811 iteration 5998 : loss : 0.053202, loss_ce: 0.028814
2022-01-13 22:04:46,290 iteration 5999 : loss : 0.022370, loss_ce: 0.008595
2022-01-13 22:04:47,701 iteration 6000 : loss : 0.016735, loss_ce: 0.007292
2022-01-13 22:04:48,996 iteration 6001 : loss : 0.015216, loss_ce: 0.007003
 88%|█████████████████████████▌   | 353/400 [2:30:20<19:18, 24.65s/it]2022-01-13 22:04:50,470 iteration 6002 : loss : 0.020346, loss_ce: 0.007637
2022-01-13 22:04:51,809 iteration 6003 : loss : 0.015955, loss_ce: 0.005646
2022-01-13 22:04:53,261 iteration 6004 : loss : 0.018313, loss_ce: 0.007953
2022-01-13 22:04:54,667 iteration 6005 : loss : 0.023141, loss_ce: 0.009216
2022-01-13 22:04:56,183 iteration 6006 : loss : 0.021499, loss_ce: 0.009348
2022-01-13 22:04:57,582 iteration 6007 : loss : 0.018756, loss_ce: 0.007853
2022-01-13 22:04:58,967 iteration 6008 : loss : 0.018402, loss_ce: 0.006670
2022-01-13 22:05:00,264 iteration 6009 : loss : 0.013621, loss_ce: 0.006451
2022-01-13 22:05:01,577 iteration 6010 : loss : 0.014309, loss_ce: 0.005761
2022-01-13 22:05:02,984 iteration 6011 : loss : 0.022611, loss_ce: 0.008300
2022-01-13 22:05:04,459 iteration 6012 : loss : 0.019357, loss_ce: 0.004829
2022-01-13 22:05:05,873 iteration 6013 : loss : 0.016164, loss_ce: 0.005309
2022-01-13 22:05:07,279 iteration 6014 : loss : 0.021991, loss_ce: 0.006397
2022-01-13 22:05:08,622 iteration 6015 : loss : 0.018026, loss_ce: 0.007332
2022-01-13 22:05:09,995 iteration 6016 : loss : 0.015869, loss_ce: 0.005521
2022-01-13 22:05:11,368 iteration 6017 : loss : 0.017743, loss_ce: 0.006972
2022-01-13 22:05:12,786 iteration 6018 : loss : 0.035894, loss_ce: 0.012103
 88%|█████████████████████████▋   | 354/400 [2:30:44<18:42, 24.39s/it]2022-01-13 22:05:14,227 iteration 6019 : loss : 0.020616, loss_ce: 0.010826
2022-01-13 22:05:15,615 iteration 6020 : loss : 0.019858, loss_ce: 0.008544
2022-01-13 22:05:17,009 iteration 6021 : loss : 0.023388, loss_ce: 0.005395
2022-01-13 22:05:18,327 iteration 6022 : loss : 0.013309, loss_ce: 0.005416
2022-01-13 22:05:19,738 iteration 6023 : loss : 0.018714, loss_ce: 0.007419
2022-01-13 22:05:21,094 iteration 6024 : loss : 0.016848, loss_ce: 0.005978
2022-01-13 22:05:22,434 iteration 6025 : loss : 0.017700, loss_ce: 0.006896
2022-01-13 22:05:23,821 iteration 6026 : loss : 0.029368, loss_ce: 0.011247
2022-01-13 22:05:25,206 iteration 6027 : loss : 0.020092, loss_ce: 0.007132
2022-01-13 22:05:26,613 iteration 6028 : loss : 0.018972, loss_ce: 0.009054
2022-01-13 22:05:27,971 iteration 6029 : loss : 0.017857, loss_ce: 0.004883
2022-01-13 22:05:29,275 iteration 6030 : loss : 0.015185, loss_ce: 0.007102
2022-01-13 22:05:30,664 iteration 6031 : loss : 0.018603, loss_ce: 0.009645
2022-01-13 22:05:31,990 iteration 6032 : loss : 0.019877, loss_ce: 0.005799
2022-01-13 22:05:33,410 iteration 6033 : loss : 0.020817, loss_ce: 0.007211
2022-01-13 22:05:34,791 iteration 6034 : loss : 0.019336, loss_ce: 0.007290
2022-01-13 22:05:34,791 Training Data Eval:
2022-01-13 22:05:41,615   Average segmentation loss on training set: 0.0097
2022-01-13 22:05:41,615 Validation Data Eval:
2022-01-13 22:05:43,957   Average segmentation loss on validation set: 0.0705
2022-01-13 22:05:45,227 iteration 6035 : loss : 0.011875, loss_ce: 0.004837
 89%|█████████████████████████▋   | 355/400 [2:31:16<20:06, 26.81s/it]2022-01-13 22:05:46,782 iteration 6036 : loss : 0.024431, loss_ce: 0.006701
2022-01-13 22:05:48,200 iteration 6037 : loss : 0.030312, loss_ce: 0.008820
2022-01-13 22:05:49,555 iteration 6038 : loss : 0.016126, loss_ce: 0.006275
2022-01-13 22:05:50,892 iteration 6039 : loss : 0.016601, loss_ce: 0.005079
2022-01-13 22:05:52,266 iteration 6040 : loss : 0.022055, loss_ce: 0.008223
2022-01-13 22:05:53,602 iteration 6041 : loss : 0.014848, loss_ce: 0.005174
2022-01-13 22:05:54,999 iteration 6042 : loss : 0.017182, loss_ce: 0.008166
2022-01-13 22:05:56,319 iteration 6043 : loss : 0.014302, loss_ce: 0.006721
2022-01-13 22:05:57,625 iteration 6044 : loss : 0.015958, loss_ce: 0.007961
2022-01-13 22:05:59,064 iteration 6045 : loss : 0.024683, loss_ce: 0.010304
2022-01-13 22:06:00,380 iteration 6046 : loss : 0.021987, loss_ce: 0.009874
2022-01-13 22:06:01,691 iteration 6047 : loss : 0.012942, loss_ce: 0.005715
2022-01-13 22:06:03,131 iteration 6048 : loss : 0.024797, loss_ce: 0.007794
2022-01-13 22:06:04,434 iteration 6049 : loss : 0.015800, loss_ce: 0.005256
2022-01-13 22:06:05,733 iteration 6050 : loss : 0.017844, loss_ce: 0.004480
2022-01-13 22:06:07,033 iteration 6051 : loss : 0.015978, loss_ce: 0.007324
2022-01-13 22:06:08,447 iteration 6052 : loss : 0.017287, loss_ce: 0.006708
 89%|█████████████████████████▊   | 356/400 [2:31:40<18:52, 25.73s/it]2022-01-13 22:06:09,845 iteration 6053 : loss : 0.016703, loss_ce: 0.005141
2022-01-13 22:06:11,178 iteration 6054 : loss : 0.014559, loss_ce: 0.004838
2022-01-13 22:06:12,572 iteration 6055 : loss : 0.023644, loss_ce: 0.009477
2022-01-13 22:06:13,917 iteration 6056 : loss : 0.018037, loss_ce: 0.006838
2022-01-13 22:06:15,203 iteration 6057 : loss : 0.014257, loss_ce: 0.005586
2022-01-13 22:06:16,511 iteration 6058 : loss : 0.012150, loss_ce: 0.006381
2022-01-13 22:06:17,935 iteration 6059 : loss : 0.025629, loss_ce: 0.007268
2022-01-13 22:06:19,314 iteration 6060 : loss : 0.017636, loss_ce: 0.005243
2022-01-13 22:06:20,656 iteration 6061 : loss : 0.020934, loss_ce: 0.010190
2022-01-13 22:06:22,149 iteration 6062 : loss : 0.024099, loss_ce: 0.008636
2022-01-13 22:06:23,471 iteration 6063 : loss : 0.013961, loss_ce: 0.006445
2022-01-13 22:06:24,805 iteration 6064 : loss : 0.013186, loss_ce: 0.004266
2022-01-13 22:06:26,196 iteration 6065 : loss : 0.022819, loss_ce: 0.008846
2022-01-13 22:06:27,501 iteration 6066 : loss : 0.016819, loss_ce: 0.006634
2022-01-13 22:06:28,907 iteration 6067 : loss : 0.029274, loss_ce: 0.010688
2022-01-13 22:06:30,273 iteration 6068 : loss : 0.020812, loss_ce: 0.004166
2022-01-13 22:06:31,721 iteration 6069 : loss : 0.028312, loss_ce: 0.013997
 89%|█████████████████████████▉   | 357/400 [2:32:03<17:54, 25.00s/it]2022-01-13 22:06:33,168 iteration 6070 : loss : 0.017594, loss_ce: 0.008323
2022-01-13 22:06:34,565 iteration 6071 : loss : 0.017348, loss_ce: 0.007136
2022-01-13 22:06:35,924 iteration 6072 : loss : 0.015236, loss_ce: 0.005645
2022-01-13 22:06:37,307 iteration 6073 : loss : 0.017029, loss_ce: 0.004315
2022-01-13 22:06:38,593 iteration 6074 : loss : 0.014195, loss_ce: 0.006442
2022-01-13 22:06:39,994 iteration 6075 : loss : 0.019585, loss_ce: 0.008741
2022-01-13 22:06:41,363 iteration 6076 : loss : 0.013427, loss_ce: 0.005544
2022-01-13 22:06:42,624 iteration 6077 : loss : 0.012429, loss_ce: 0.004417
2022-01-13 22:06:43,975 iteration 6078 : loss : 0.017767, loss_ce: 0.010277
2022-01-13 22:06:45,408 iteration 6079 : loss : 0.015970, loss_ce: 0.006866
2022-01-13 22:06:46,711 iteration 6080 : loss : 0.012801, loss_ce: 0.004519
2022-01-13 22:06:48,156 iteration 6081 : loss : 0.028999, loss_ce: 0.011283
2022-01-13 22:06:49,515 iteration 6082 : loss : 0.019000, loss_ce: 0.005914
2022-01-13 22:06:50,926 iteration 6083 : loss : 0.028475, loss_ce: 0.008930
2022-01-13 22:06:52,253 iteration 6084 : loss : 0.016222, loss_ce: 0.004423
2022-01-13 22:06:53,578 iteration 6085 : loss : 0.022375, loss_ce: 0.010601
2022-01-13 22:06:55,103 iteration 6086 : loss : 0.034748, loss_ce: 0.009638
 90%|█████████████████████████▉   | 358/400 [2:32:26<17:09, 24.51s/it]2022-01-13 22:06:56,480 iteration 6087 : loss : 0.015184, loss_ce: 0.005826
2022-01-13 22:06:57,856 iteration 6088 : loss : 0.025478, loss_ce: 0.011973
2022-01-13 22:06:59,205 iteration 6089 : loss : 0.029222, loss_ce: 0.014648
2022-01-13 22:07:00,598 iteration 6090 : loss : 0.019481, loss_ce: 0.005367
2022-01-13 22:07:01,960 iteration 6091 : loss : 0.012678, loss_ce: 0.004908
2022-01-13 22:07:03,342 iteration 6092 : loss : 0.013284, loss_ce: 0.005468
2022-01-13 22:07:04,634 iteration 6093 : loss : 0.015211, loss_ce: 0.005030
2022-01-13 22:07:05,947 iteration 6094 : loss : 0.016507, loss_ce: 0.005862
2022-01-13 22:07:07,337 iteration 6095 : loss : 0.016404, loss_ce: 0.006548
2022-01-13 22:07:08,729 iteration 6096 : loss : 0.026454, loss_ce: 0.008269
2022-01-13 22:07:10,021 iteration 6097 : loss : 0.015431, loss_ce: 0.006785
2022-01-13 22:07:11,406 iteration 6098 : loss : 0.033685, loss_ce: 0.016152
2022-01-13 22:07:12,816 iteration 6099 : loss : 0.024414, loss_ce: 0.006422
2022-01-13 22:07:14,261 iteration 6100 : loss : 0.020198, loss_ce: 0.006619
2022-01-13 22:07:15,717 iteration 6101 : loss : 0.016642, loss_ce: 0.006554
2022-01-13 22:07:17,048 iteration 6102 : loss : 0.017203, loss_ce: 0.006133
2022-01-13 22:07:18,307 iteration 6103 : loss : 0.010994, loss_ce: 0.004128
 90%|██████████████████████████   | 359/400 [2:32:50<16:28, 24.12s/it]2022-01-13 22:07:19,794 iteration 6104 : loss : 0.042829, loss_ce: 0.013738
2022-01-13 22:07:21,110 iteration 6105 : loss : 0.021951, loss_ce: 0.007968
2022-01-13 22:07:22,394 iteration 6106 : loss : 0.016930, loss_ce: 0.005604
2022-01-13 22:07:23,701 iteration 6107 : loss : 0.017324, loss_ce: 0.006156
2022-01-13 22:07:25,108 iteration 6108 : loss : 0.022708, loss_ce: 0.007162
2022-01-13 22:07:26,446 iteration 6109 : loss : 0.018062, loss_ce: 0.006793
2022-01-13 22:07:27,827 iteration 6110 : loss : 0.018760, loss_ce: 0.008815
2022-01-13 22:07:29,276 iteration 6111 : loss : 0.021728, loss_ce: 0.007925
2022-01-13 22:07:30,680 iteration 6112 : loss : 0.019949, loss_ce: 0.007431
2022-01-13 22:07:32,124 iteration 6113 : loss : 0.027361, loss_ce: 0.009666
2022-01-13 22:07:33,474 iteration 6114 : loss : 0.020850, loss_ce: 0.009281
2022-01-13 22:07:34,922 iteration 6115 : loss : 0.029619, loss_ce: 0.009801
2022-01-13 22:07:36,318 iteration 6116 : loss : 0.020750, loss_ce: 0.008696
2022-01-13 22:07:37,654 iteration 6117 : loss : 0.020759, loss_ce: 0.008813
2022-01-13 22:07:39,058 iteration 6118 : loss : 0.017916, loss_ce: 0.008297
2022-01-13 22:07:40,412 iteration 6119 : loss : 0.017857, loss_ce: 0.005547
2022-01-13 22:07:40,412 Training Data Eval:
2022-01-13 22:07:47,230   Average segmentation loss on training set: 0.0098
2022-01-13 22:07:47,230 Validation Data Eval:
2022-01-13 22:07:49,575   Average segmentation loss on validation set: 0.0762
2022-01-13 22:07:50,926 iteration 6120 : loss : 0.019705, loss_ce: 0.010254
 90%|██████████████████████████   | 360/400 [2:33:22<17:46, 26.67s/it]2022-01-13 22:07:52,367 iteration 6121 : loss : 0.018839, loss_ce: 0.008800
2022-01-13 22:07:53,804 iteration 6122 : loss : 0.024230, loss_ce: 0.007925
2022-01-13 22:07:55,271 iteration 6123 : loss : 0.016690, loss_ce: 0.006601
2022-01-13 22:07:56,653 iteration 6124 : loss : 0.018163, loss_ce: 0.005471
2022-01-13 22:07:58,119 iteration 6125 : loss : 0.020714, loss_ce: 0.006909
2022-01-13 22:07:59,476 iteration 6126 : loss : 0.025789, loss_ce: 0.005094
2022-01-13 22:08:00,821 iteration 6127 : loss : 0.016613, loss_ce: 0.006374
2022-01-13 22:08:02,284 iteration 6128 : loss : 0.017035, loss_ce: 0.005429
2022-01-13 22:08:03,708 iteration 6129 : loss : 0.020514, loss_ce: 0.007175
2022-01-13 22:08:05,167 iteration 6130 : loss : 0.019602, loss_ce: 0.009037
2022-01-13 22:08:06,557 iteration 6131 : loss : 0.033618, loss_ce: 0.016380
2022-01-13 22:08:07,949 iteration 6132 : loss : 0.022030, loss_ce: 0.005261
2022-01-13 22:08:09,282 iteration 6133 : loss : 0.016164, loss_ce: 0.009599
2022-01-13 22:08:10,584 iteration 6134 : loss : 0.010854, loss_ce: 0.004768
2022-01-13 22:08:11,886 iteration 6135 : loss : 0.012768, loss_ce: 0.005022
2022-01-13 22:08:13,269 iteration 6136 : loss : 0.014690, loss_ce: 0.005055
2022-01-13 22:08:14,619 iteration 6137 : loss : 0.015829, loss_ce: 0.005995
 90%|██████████████████████████▏  | 361/400 [2:33:46<16:45, 25.78s/it]2022-01-13 22:08:15,999 iteration 6138 : loss : 0.012258, loss_ce: 0.004202
2022-01-13 22:08:17,402 iteration 6139 : loss : 0.016315, loss_ce: 0.006993
2022-01-13 22:08:18,765 iteration 6140 : loss : 0.013259, loss_ce: 0.005009
2022-01-13 22:08:20,187 iteration 6141 : loss : 0.017618, loss_ce: 0.006669
2022-01-13 22:08:21,743 iteration 6142 : loss : 0.030819, loss_ce: 0.012000
2022-01-13 22:08:23,056 iteration 6143 : loss : 0.024352, loss_ce: 0.012502
2022-01-13 22:08:24,453 iteration 6144 : loss : 0.014240, loss_ce: 0.005741
2022-01-13 22:08:25,843 iteration 6145 : loss : 0.024670, loss_ce: 0.010783
2022-01-13 22:08:27,205 iteration 6146 : loss : 0.013884, loss_ce: 0.005960
2022-01-13 22:08:28,566 iteration 6147 : loss : 0.014619, loss_ce: 0.003821
2022-01-13 22:08:29,927 iteration 6148 : loss : 0.012264, loss_ce: 0.004209
2022-01-13 22:08:31,245 iteration 6149 : loss : 0.022821, loss_ce: 0.009182
2022-01-13 22:08:32,581 iteration 6150 : loss : 0.034024, loss_ce: 0.009750
2022-01-13 22:08:33,975 iteration 6151 : loss : 0.018201, loss_ce: 0.004615
2022-01-13 22:08:35,297 iteration 6152 : loss : 0.019301, loss_ce: 0.009105
2022-01-13 22:08:36,725 iteration 6153 : loss : 0.023773, loss_ce: 0.011867
2022-01-13 22:08:38,182 iteration 6154 : loss : 0.021066, loss_ce: 0.008677
 90%|██████████████████████████▏  | 362/400 [2:34:09<15:54, 25.11s/it]2022-01-13 22:08:39,583 iteration 6155 : loss : 0.022004, loss_ce: 0.010536
2022-01-13 22:08:40,941 iteration 6156 : loss : 0.012592, loss_ce: 0.005741
2022-01-13 22:08:42,354 iteration 6157 : loss : 0.019692, loss_ce: 0.006377
2022-01-13 22:08:43,693 iteration 6158 : loss : 0.015090, loss_ce: 0.004818
2022-01-13 22:08:44,984 iteration 6159 : loss : 0.011979, loss_ce: 0.004867
2022-01-13 22:08:46,555 iteration 6160 : loss : 0.038622, loss_ce: 0.024970
2022-01-13 22:08:47,869 iteration 6161 : loss : 0.036851, loss_ce: 0.011373
2022-01-13 22:08:49,269 iteration 6162 : loss : 0.013713, loss_ce: 0.004945
2022-01-13 22:08:50,622 iteration 6163 : loss : 0.015096, loss_ce: 0.006224
2022-01-13 22:08:51,947 iteration 6164 : loss : 0.016733, loss_ce: 0.004956
2022-01-13 22:08:53,361 iteration 6165 : loss : 0.014802, loss_ce: 0.005951
2022-01-13 22:08:54,765 iteration 6166 : loss : 0.026961, loss_ce: 0.011913
2022-01-13 22:08:56,054 iteration 6167 : loss : 0.012489, loss_ce: 0.004156
2022-01-13 22:08:57,525 iteration 6168 : loss : 0.034128, loss_ce: 0.011035
2022-01-13 22:08:58,881 iteration 6169 : loss : 0.015326, loss_ce: 0.006482
2022-01-13 22:09:00,280 iteration 6170 : loss : 0.018382, loss_ce: 0.009173
2022-01-13 22:09:01,644 iteration 6171 : loss : 0.030043, loss_ce: 0.008040
 91%|██████████████████████████▎  | 363/400 [2:34:33<15:10, 24.62s/it]2022-01-13 22:09:03,062 iteration 6172 : loss : 0.015899, loss_ce: 0.005417
2022-01-13 22:09:04,335 iteration 6173 : loss : 0.012037, loss_ce: 0.004372
2022-01-13 22:09:05,677 iteration 6174 : loss : 0.019942, loss_ce: 0.009077
2022-01-13 22:09:06,980 iteration 6175 : loss : 0.011707, loss_ce: 0.003339
2022-01-13 22:09:08,365 iteration 6176 : loss : 0.022760, loss_ce: 0.011575
2022-01-13 22:09:09,834 iteration 6177 : loss : 0.019074, loss_ce: 0.009169
2022-01-13 22:09:11,263 iteration 6178 : loss : 0.023382, loss_ce: 0.007690
2022-01-13 22:09:12,664 iteration 6179 : loss : 0.020794, loss_ce: 0.007050
2022-01-13 22:09:14,093 iteration 6180 : loss : 0.035865, loss_ce: 0.009975
2022-01-13 22:09:15,440 iteration 6181 : loss : 0.023152, loss_ce: 0.009228
2022-01-13 22:09:16,853 iteration 6182 : loss : 0.019472, loss_ce: 0.007361
2022-01-13 22:09:18,203 iteration 6183 : loss : 0.036748, loss_ce: 0.012581
2022-01-13 22:09:19,524 iteration 6184 : loss : 0.015011, loss_ce: 0.005859
2022-01-13 22:09:20,938 iteration 6185 : loss : 0.029421, loss_ce: 0.008587
2022-01-13 22:09:22,250 iteration 6186 : loss : 0.014122, loss_ce: 0.005091
2022-01-13 22:09:23,569 iteration 6187 : loss : 0.027054, loss_ce: 0.010686
2022-01-13 22:09:24,886 iteration 6188 : loss : 0.018991, loss_ce: 0.006759
 91%|██████████████████████████▍  | 364/400 [2:34:56<14:31, 24.21s/it]2022-01-13 22:09:26,392 iteration 6189 : loss : 0.028393, loss_ce: 0.012730
2022-01-13 22:09:27,803 iteration 6190 : loss : 0.018306, loss_ce: 0.007198
2022-01-13 22:09:29,243 iteration 6191 : loss : 0.015735, loss_ce: 0.006246
2022-01-13 22:09:30,655 iteration 6192 : loss : 0.019219, loss_ce: 0.007498
2022-01-13 22:09:31,985 iteration 6193 : loss : 0.014026, loss_ce: 0.004457
2022-01-13 22:09:33,395 iteration 6194 : loss : 0.015459, loss_ce: 0.005946
2022-01-13 22:09:34,843 iteration 6195 : loss : 0.024895, loss_ce: 0.008465
2022-01-13 22:09:36,172 iteration 6196 : loss : 0.025128, loss_ce: 0.011786
2022-01-13 22:09:37,650 iteration 6197 : loss : 0.029459, loss_ce: 0.010985
2022-01-13 22:09:39,155 iteration 6198 : loss : 0.023252, loss_ce: 0.009798
2022-01-13 22:09:40,496 iteration 6199 : loss : 0.013239, loss_ce: 0.005051
2022-01-13 22:09:41,896 iteration 6200 : loss : 0.040122, loss_ce: 0.015576
2022-01-13 22:09:43,268 iteration 6201 : loss : 0.026029, loss_ce: 0.010624
2022-01-13 22:09:44,626 iteration 6202 : loss : 0.015782, loss_ce: 0.004627
2022-01-13 22:09:45,975 iteration 6203 : loss : 0.018439, loss_ce: 0.006396
2022-01-13 22:09:47,389 iteration 6204 : loss : 0.020637, loss_ce: 0.011612
2022-01-13 22:09:47,389 Training Data Eval:
2022-01-13 22:09:54,170   Average segmentation loss on training set: 0.0098
2022-01-13 22:09:54,170 Validation Data Eval:
2022-01-13 22:09:56,516   Average segmentation loss on validation set: 0.0780
2022-01-13 22:09:57,983 iteration 6205 : loss : 0.021899, loss_ce: 0.011501
 91%|██████████████████████████▍  | 365/400 [2:35:29<15:40, 26.87s/it]2022-01-13 22:09:59,432 iteration 6206 : loss : 0.018002, loss_ce: 0.008174
2022-01-13 22:10:00,808 iteration 6207 : loss : 0.018912, loss_ce: 0.009286
2022-01-13 22:10:02,207 iteration 6208 : loss : 0.020986, loss_ce: 0.009156
2022-01-13 22:10:03,604 iteration 6209 : loss : 0.026538, loss_ce: 0.009740
2022-01-13 22:10:04,990 iteration 6210 : loss : 0.033899, loss_ce: 0.013175
2022-01-13 22:10:06,326 iteration 6211 : loss : 0.019851, loss_ce: 0.007784
2022-01-13 22:10:07,672 iteration 6212 : loss : 0.018750, loss_ce: 0.006226
2022-01-13 22:10:09,059 iteration 6213 : loss : 0.013780, loss_ce: 0.005302
2022-01-13 22:10:10,414 iteration 6214 : loss : 0.013608, loss_ce: 0.005456
2022-01-13 22:10:11,840 iteration 6215 : loss : 0.021731, loss_ce: 0.006785
2022-01-13 22:10:13,200 iteration 6216 : loss : 0.017227, loss_ce: 0.007198
2022-01-13 22:10:14,496 iteration 6217 : loss : 0.023200, loss_ce: 0.008967
2022-01-13 22:10:15,867 iteration 6218 : loss : 0.019982, loss_ce: 0.007393
2022-01-13 22:10:17,224 iteration 6219 : loss : 0.016968, loss_ce: 0.006167
2022-01-13 22:10:18,557 iteration 6220 : loss : 0.014532, loss_ce: 0.003334
2022-01-13 22:10:19,945 iteration 6221 : loss : 0.020585, loss_ce: 0.005546
2022-01-13 22:10:21,266 iteration 6222 : loss : 0.013387, loss_ce: 0.006519
 92%|██████████████████████████▌  | 366/400 [2:35:53<14:37, 25.80s/it]2022-01-13 22:10:22,729 iteration 6223 : loss : 0.020185, loss_ce: 0.009046
2022-01-13 22:10:24,089 iteration 6224 : loss : 0.017003, loss_ce: 0.006551
2022-01-13 22:10:25,465 iteration 6225 : loss : 0.020812, loss_ce: 0.005413
2022-01-13 22:10:26,802 iteration 6226 : loss : 0.014548, loss_ce: 0.004872
2022-01-13 22:10:28,114 iteration 6227 : loss : 0.014246, loss_ce: 0.005941
2022-01-13 22:10:29,485 iteration 6228 : loss : 0.015158, loss_ce: 0.005625
2022-01-13 22:10:30,869 iteration 6229 : loss : 0.011956, loss_ce: 0.005406
2022-01-13 22:10:32,299 iteration 6230 : loss : 0.020109, loss_ce: 0.005831
2022-01-13 22:10:33,712 iteration 6231 : loss : 0.019508, loss_ce: 0.007750
2022-01-13 22:10:35,098 iteration 6232 : loss : 0.015713, loss_ce: 0.006515
2022-01-13 22:10:36,462 iteration 6233 : loss : 0.015145, loss_ce: 0.006654
2022-01-13 22:10:37,808 iteration 6234 : loss : 0.023065, loss_ce: 0.005212
2022-01-13 22:10:39,128 iteration 6235 : loss : 0.018636, loss_ce: 0.011010
2022-01-13 22:10:40,492 iteration 6236 : loss : 0.014214, loss_ce: 0.006635
2022-01-13 22:10:41,880 iteration 6237 : loss : 0.025704, loss_ce: 0.012774
2022-01-13 22:10:43,317 iteration 6238 : loss : 0.021212, loss_ce: 0.006147
2022-01-13 22:10:44,696 iteration 6239 : loss : 0.024350, loss_ce: 0.006837
 92%|██████████████████████████▌  | 367/400 [2:36:16<13:47, 25.09s/it]2022-01-13 22:10:46,111 iteration 6240 : loss : 0.012233, loss_ce: 0.003792
2022-01-13 22:10:47,436 iteration 6241 : loss : 0.012764, loss_ce: 0.006178
2022-01-13 22:10:48,873 iteration 6242 : loss : 0.033754, loss_ce: 0.010804
2022-01-13 22:10:50,229 iteration 6243 : loss : 0.012128, loss_ce: 0.004893
2022-01-13 22:10:51,684 iteration 6244 : loss : 0.018987, loss_ce: 0.008680
2022-01-13 22:10:53,059 iteration 6245 : loss : 0.015767, loss_ce: 0.005646
2022-01-13 22:10:54,408 iteration 6246 : loss : 0.017576, loss_ce: 0.008115
2022-01-13 22:10:55,801 iteration 6247 : loss : 0.016578, loss_ce: 0.004056
2022-01-13 22:10:57,171 iteration 6248 : loss : 0.014064, loss_ce: 0.005267
2022-01-13 22:10:58,548 iteration 6249 : loss : 0.017831, loss_ce: 0.005276
2022-01-13 22:10:59,949 iteration 6250 : loss : 0.018711, loss_ce: 0.007945
2022-01-13 22:11:01,409 iteration 6251 : loss : 0.019669, loss_ce: 0.008564
2022-01-13 22:11:02,759 iteration 6252 : loss : 0.016162, loss_ce: 0.008777
2022-01-13 22:11:04,180 iteration 6253 : loss : 0.014409, loss_ce: 0.005118
2022-01-13 22:11:05,528 iteration 6254 : loss : 0.016626, loss_ce: 0.007466
2022-01-13 22:11:06,912 iteration 6255 : loss : 0.015339, loss_ce: 0.006509
2022-01-13 22:11:08,357 iteration 6256 : loss : 0.017787, loss_ce: 0.007525
 92%|██████████████████████████▋  | 368/400 [2:36:40<13:09, 24.66s/it]2022-01-13 22:11:09,833 iteration 6257 : loss : 0.020702, loss_ce: 0.006632
2022-01-13 22:11:11,252 iteration 6258 : loss : 0.028491, loss_ce: 0.011051
2022-01-13 22:11:12,697 iteration 6259 : loss : 0.018929, loss_ce: 0.007211
2022-01-13 22:11:14,054 iteration 6260 : loss : 0.028818, loss_ce: 0.011002
2022-01-13 22:11:15,407 iteration 6261 : loss : 0.018930, loss_ce: 0.007030
2022-01-13 22:11:16,805 iteration 6262 : loss : 0.026624, loss_ce: 0.007379
2022-01-13 22:11:18,192 iteration 6263 : loss : 0.027095, loss_ce: 0.005793
2022-01-13 22:11:19,583 iteration 6264 : loss : 0.013352, loss_ce: 0.005100
2022-01-13 22:11:20,970 iteration 6265 : loss : 0.024023, loss_ce: 0.009638
2022-01-13 22:11:22,318 iteration 6266 : loss : 0.034774, loss_ce: 0.019153
2022-01-13 22:11:23,672 iteration 6267 : loss : 0.016034, loss_ce: 0.007095
2022-01-13 22:11:25,039 iteration 6268 : loss : 0.016102, loss_ce: 0.006617
2022-01-13 22:11:26,279 iteration 6269 : loss : 0.011337, loss_ce: 0.004007
2022-01-13 22:11:27,625 iteration 6270 : loss : 0.013898, loss_ce: 0.006454
2022-01-13 22:11:28,997 iteration 6271 : loss : 0.017080, loss_ce: 0.005156
2022-01-13 22:11:30,411 iteration 6272 : loss : 0.018440, loss_ce: 0.007096
2022-01-13 22:11:31,817 iteration 6273 : loss : 0.016618, loss_ce: 0.006494
 92%|██████████████████████████▊  | 369/400 [2:37:03<12:33, 24.30s/it]2022-01-13 22:11:33,376 iteration 6274 : loss : 0.024367, loss_ce: 0.008692
2022-01-13 22:11:34,773 iteration 6275 : loss : 0.024958, loss_ce: 0.011343
2022-01-13 22:11:36,160 iteration 6276 : loss : 0.016220, loss_ce: 0.006685
2022-01-13 22:11:37,497 iteration 6277 : loss : 0.014071, loss_ce: 0.004110
2022-01-13 22:11:38,883 iteration 6278 : loss : 0.017591, loss_ce: 0.005939
2022-01-13 22:11:40,246 iteration 6279 : loss : 0.027531, loss_ce: 0.010221
2022-01-13 22:11:41,587 iteration 6280 : loss : 0.020634, loss_ce: 0.007702
2022-01-13 22:11:43,074 iteration 6281 : loss : 0.024989, loss_ce: 0.006024
2022-01-13 22:11:44,431 iteration 6282 : loss : 0.012528, loss_ce: 0.004946
2022-01-13 22:11:45,767 iteration 6283 : loss : 0.014703, loss_ce: 0.007755
2022-01-13 22:11:47,146 iteration 6284 : loss : 0.018976, loss_ce: 0.007777
2022-01-13 22:11:48,561 iteration 6285 : loss : 0.017733, loss_ce: 0.006279
2022-01-13 22:11:49,908 iteration 6286 : loss : 0.017619, loss_ce: 0.005709
2022-01-13 22:11:51,277 iteration 6287 : loss : 0.017766, loss_ce: 0.005363
2022-01-13 22:11:52,565 iteration 6288 : loss : 0.011724, loss_ce: 0.004242
2022-01-13 22:11:53,966 iteration 6289 : loss : 0.015994, loss_ce: 0.006753
2022-01-13 22:11:53,966 Training Data Eval:
2022-01-13 22:12:00,775   Average segmentation loss on training set: 0.0093
2022-01-13 22:12:00,776 Validation Data Eval:
2022-01-13 22:12:03,124   Average segmentation loss on validation set: 0.0754
2022-01-13 22:12:04,529 iteration 6290 : loss : 0.019612, loss_ce: 0.008125
 92%|██████████████████████████▊  | 370/400 [2:37:36<13:24, 26.82s/it]2022-01-13 22:12:05,970 iteration 6291 : loss : 0.017423, loss_ce: 0.007188
2022-01-13 22:12:07,346 iteration 6292 : loss : 0.015168, loss_ce: 0.004906
2022-01-13 22:12:08,750 iteration 6293 : loss : 0.028149, loss_ce: 0.012753
2022-01-13 22:12:10,165 iteration 6294 : loss : 0.021932, loss_ce: 0.006350
2022-01-13 22:12:11,535 iteration 6295 : loss : 0.017171, loss_ce: 0.007588
2022-01-13 22:12:12,985 iteration 6296 : loss : 0.024091, loss_ce: 0.008696
2022-01-13 22:12:14,375 iteration 6297 : loss : 0.020542, loss_ce: 0.007166
2022-01-13 22:12:15,794 iteration 6298 : loss : 0.039057, loss_ce: 0.013424
2022-01-13 22:12:17,186 iteration 6299 : loss : 0.015512, loss_ce: 0.005194
2022-01-13 22:12:18,535 iteration 6300 : loss : 0.019174, loss_ce: 0.006048
2022-01-13 22:12:19,871 iteration 6301 : loss : 0.014062, loss_ce: 0.008131
2022-01-13 22:12:21,260 iteration 6302 : loss : 0.019125, loss_ce: 0.007024
2022-01-13 22:12:22,549 iteration 6303 : loss : 0.014548, loss_ce: 0.003362
2022-01-13 22:12:23,846 iteration 6304 : loss : 0.013015, loss_ce: 0.003576
2022-01-13 22:12:25,234 iteration 6305 : loss : 0.020777, loss_ce: 0.009220
2022-01-13 22:12:26,586 iteration 6306 : loss : 0.026127, loss_ce: 0.006191
2022-01-13 22:12:27,950 iteration 6307 : loss : 0.015658, loss_ce: 0.007596
 93%|██████████████████████████▉  | 371/400 [2:37:59<12:28, 25.80s/it]2022-01-13 22:12:29,326 iteration 6308 : loss : 0.020370, loss_ce: 0.004086
2022-01-13 22:12:30,707 iteration 6309 : loss : 0.020202, loss_ce: 0.007445
2022-01-13 22:12:32,065 iteration 6310 : loss : 0.016186, loss_ce: 0.007198
2022-01-13 22:12:33,447 iteration 6311 : loss : 0.017554, loss_ce: 0.007919
2022-01-13 22:12:34,848 iteration 6312 : loss : 0.018399, loss_ce: 0.006112
2022-01-13 22:12:36,287 iteration 6313 : loss : 0.024230, loss_ce: 0.009750
2022-01-13 22:12:37,666 iteration 6314 : loss : 0.014810, loss_ce: 0.005244
2022-01-13 22:12:38,995 iteration 6315 : loss : 0.015328, loss_ce: 0.005331
2022-01-13 22:12:40,356 iteration 6316 : loss : 0.015456, loss_ce: 0.005908
2022-01-13 22:12:41,708 iteration 6317 : loss : 0.016681, loss_ce: 0.004785
2022-01-13 22:12:43,163 iteration 6318 : loss : 0.025351, loss_ce: 0.009277
2022-01-13 22:12:44,558 iteration 6319 : loss : 0.015742, loss_ce: 0.005757
2022-01-13 22:12:45,913 iteration 6320 : loss : 0.014760, loss_ce: 0.005027
2022-01-13 22:12:47,349 iteration 6321 : loss : 0.020097, loss_ce: 0.010351
2022-01-13 22:12:48,775 iteration 6322 : loss : 0.027377, loss_ce: 0.015477
2022-01-13 22:12:50,284 iteration 6323 : loss : 0.021772, loss_ce: 0.006867
2022-01-13 22:12:51,737 iteration 6324 : loss : 0.035080, loss_ce: 0.019718
 93%|██████████████████████████▉  | 372/400 [2:38:23<11:45, 25.20s/it]2022-01-13 22:12:53,202 iteration 6325 : loss : 0.020981, loss_ce: 0.006139
2022-01-13 22:12:54,548 iteration 6326 : loss : 0.017018, loss_ce: 0.007873
2022-01-13 22:12:55,916 iteration 6327 : loss : 0.017313, loss_ce: 0.006050
2022-01-13 22:12:57,342 iteration 6328 : loss : 0.017490, loss_ce: 0.009244
2022-01-13 22:12:58,649 iteration 6329 : loss : 0.020775, loss_ce: 0.013069
2022-01-13 22:13:00,010 iteration 6330 : loss : 0.019006, loss_ce: 0.007496
2022-01-13 22:13:01,438 iteration 6331 : loss : 0.024559, loss_ce: 0.009171
2022-01-13 22:13:02,845 iteration 6332 : loss : 0.018298, loss_ce: 0.005484
2022-01-13 22:13:04,222 iteration 6333 : loss : 0.012860, loss_ce: 0.006177
2022-01-13 22:13:05,590 iteration 6334 : loss : 0.029771, loss_ce: 0.007664
2022-01-13 22:13:07,050 iteration 6335 : loss : 0.016290, loss_ce: 0.006797
2022-01-13 22:13:08,392 iteration 6336 : loss : 0.016176, loss_ce: 0.006850
2022-01-13 22:13:09,799 iteration 6337 : loss : 0.022828, loss_ce: 0.006628
2022-01-13 22:13:11,173 iteration 6338 : loss : 0.016832, loss_ce: 0.005495
2022-01-13 22:13:12,547 iteration 6339 : loss : 0.016218, loss_ce: 0.005825
2022-01-13 22:13:13,918 iteration 6340 : loss : 0.016848, loss_ce: 0.008326
2022-01-13 22:13:15,214 iteration 6341 : loss : 0.012760, loss_ce: 0.004292
 93%|███████████████████████████  | 373/400 [2:38:46<11:06, 24.68s/it]2022-01-13 22:13:16,683 iteration 6342 : loss : 0.044217, loss_ce: 0.014914
2022-01-13 22:13:18,036 iteration 6343 : loss : 0.013320, loss_ce: 0.005222
2022-01-13 22:13:19,385 iteration 6344 : loss : 0.028006, loss_ce: 0.010516
2022-01-13 22:13:20,724 iteration 6345 : loss : 0.023772, loss_ce: 0.003308
2022-01-13 22:13:22,100 iteration 6346 : loss : 0.024966, loss_ce: 0.008202
2022-01-13 22:13:23,473 iteration 6347 : loss : 0.015940, loss_ce: 0.006106
2022-01-13 22:13:24,753 iteration 6348 : loss : 0.010667, loss_ce: 0.004561
2022-01-13 22:13:26,128 iteration 6349 : loss : 0.021494, loss_ce: 0.011042
2022-01-13 22:13:27,608 iteration 6350 : loss : 0.038892, loss_ce: 0.013210
2022-01-13 22:13:29,032 iteration 6351 : loss : 0.016884, loss_ce: 0.007752
2022-01-13 22:13:30,410 iteration 6352 : loss : 0.018888, loss_ce: 0.005533
2022-01-13 22:13:31,786 iteration 6353 : loss : 0.023234, loss_ce: 0.009243
2022-01-13 22:13:33,158 iteration 6354 : loss : 0.014121, loss_ce: 0.006279
2022-01-13 22:13:34,506 iteration 6355 : loss : 0.026995, loss_ce: 0.009890
2022-01-13 22:13:35,957 iteration 6356 : loss : 0.025020, loss_ce: 0.006819
2022-01-13 22:13:37,298 iteration 6357 : loss : 0.020382, loss_ce: 0.007012
2022-01-13 22:13:38,779 iteration 6358 : loss : 0.025239, loss_ce: 0.010050
 94%|███████████████████████████  | 374/400 [2:39:10<10:33, 24.35s/it]2022-01-13 22:13:40,270 iteration 6359 : loss : 0.020824, loss_ce: 0.005827
2022-01-13 22:13:41,591 iteration 6360 : loss : 0.022234, loss_ce: 0.013442
2022-01-13 22:13:42,990 iteration 6361 : loss : 0.020227, loss_ce: 0.007222
2022-01-13 22:13:44,414 iteration 6362 : loss : 0.017489, loss_ce: 0.007337
2022-01-13 22:13:45,845 iteration 6363 : loss : 0.025840, loss_ce: 0.009739
2022-01-13 22:13:47,180 iteration 6364 : loss : 0.016783, loss_ce: 0.004640
2022-01-13 22:13:48,565 iteration 6365 : loss : 0.036470, loss_ce: 0.020380
2022-01-13 22:13:50,044 iteration 6366 : loss : 0.022157, loss_ce: 0.008597
2022-01-13 22:13:51,542 iteration 6367 : loss : 0.019967, loss_ce: 0.007390
2022-01-13 22:13:52,966 iteration 6368 : loss : 0.025812, loss_ce: 0.011719
2022-01-13 22:13:54,352 iteration 6369 : loss : 0.015292, loss_ce: 0.006496
2022-01-13 22:13:55,743 iteration 6370 : loss : 0.014540, loss_ce: 0.004858
2022-01-13 22:13:57,223 iteration 6371 : loss : 0.026099, loss_ce: 0.007662
2022-01-13 22:13:58,565 iteration 6372 : loss : 0.011545, loss_ce: 0.005252
2022-01-13 22:13:59,916 iteration 6373 : loss : 0.012771, loss_ce: 0.004747
2022-01-13 22:14:01,314 iteration 6374 : loss : 0.019160, loss_ce: 0.007786
2022-01-13 22:14:01,314 Training Data Eval:
2022-01-13 22:14:08,133   Average segmentation loss on training set: 0.0092
2022-01-13 22:14:08,134 Validation Data Eval:
2022-01-13 22:14:10,476   Average segmentation loss on validation set: 0.0709
2022-01-13 22:14:11,940 iteration 6375 : loss : 0.023515, loss_ce: 0.008103
 94%|███████████████████████████▏ | 375/400 [2:39:43<11:14, 26.99s/it]2022-01-13 22:14:13,416 iteration 6376 : loss : 0.024836, loss_ce: 0.008450
2022-01-13 22:14:14,825 iteration 6377 : loss : 0.017911, loss_ce: 0.006136
2022-01-13 22:14:16,111 iteration 6378 : loss : 0.014107, loss_ce: 0.007104
2022-01-13 22:14:17,477 iteration 6379 : loss : 0.019151, loss_ce: 0.005038
2022-01-13 22:14:18,825 iteration 6380 : loss : 0.016424, loss_ce: 0.005704
2022-01-13 22:14:20,158 iteration 6381 : loss : 0.010991, loss_ce: 0.003559
2022-01-13 22:14:21,449 iteration 6382 : loss : 0.014915, loss_ce: 0.005145
2022-01-13 22:14:22,864 iteration 6383 : loss : 0.022343, loss_ce: 0.007936
2022-01-13 22:14:24,200 iteration 6384 : loss : 0.015238, loss_ce: 0.006315
2022-01-13 22:14:25,600 iteration 6385 : loss : 0.019541, loss_ce: 0.005929
2022-01-13 22:14:27,025 iteration 6386 : loss : 0.015899, loss_ce: 0.005274
2022-01-13 22:14:28,524 iteration 6387 : loss : 0.020198, loss_ce: 0.009405
2022-01-13 22:14:29,944 iteration 6388 : loss : 0.020026, loss_ce: 0.008379
2022-01-13 22:14:31,220 iteration 6389 : loss : 0.013621, loss_ce: 0.004790
2022-01-13 22:14:32,587 iteration 6390 : loss : 0.018946, loss_ce: 0.009062
2022-01-13 22:14:33,919 iteration 6391 : loss : 0.014704, loss_ce: 0.008034
2022-01-13 22:14:35,367 iteration 6392 : loss : 0.022465, loss_ce: 0.006705
 94%|███████████████████████████▎ | 376/400 [2:40:07<10:22, 25.92s/it]2022-01-13 22:14:36,792 iteration 6393 : loss : 0.015245, loss_ce: 0.005795
2022-01-13 22:14:38,214 iteration 6394 : loss : 0.019353, loss_ce: 0.007194
2022-01-13 22:14:39,572 iteration 6395 : loss : 0.016978, loss_ce: 0.005856
2022-01-13 22:14:40,937 iteration 6396 : loss : 0.014761, loss_ce: 0.005051
2022-01-13 22:14:42,326 iteration 6397 : loss : 0.025387, loss_ce: 0.010849
2022-01-13 22:14:43,723 iteration 6398 : loss : 0.015498, loss_ce: 0.005895
2022-01-13 22:14:45,087 iteration 6399 : loss : 0.017915, loss_ce: 0.005798
2022-01-13 22:14:46,439 iteration 6400 : loss : 0.015552, loss_ce: 0.006293
2022-01-13 22:14:47,836 iteration 6401 : loss : 0.015639, loss_ce: 0.005883
2022-01-13 22:14:49,195 iteration 6402 : loss : 0.018942, loss_ce: 0.009901
2022-01-13 22:14:50,642 iteration 6403 : loss : 0.026486, loss_ce: 0.011162
2022-01-13 22:14:51,994 iteration 6404 : loss : 0.013724, loss_ce: 0.005673
2022-01-13 22:14:53,330 iteration 6405 : loss : 0.020027, loss_ce: 0.005922
2022-01-13 22:14:54,883 iteration 6406 : loss : 0.043755, loss_ce: 0.013015
2022-01-13 22:14:56,287 iteration 6407 : loss : 0.017533, loss_ce: 0.004615
2022-01-13 22:14:57,555 iteration 6408 : loss : 0.012148, loss_ce: 0.004256
2022-01-13 22:14:58,911 iteration 6409 : loss : 0.020172, loss_ce: 0.008194
 94%|███████████████████████████▎ | 377/400 [2:40:30<09:39, 25.21s/it]2022-01-13 22:15:00,314 iteration 6410 : loss : 0.021907, loss_ce: 0.007175
2022-01-13 22:15:01,705 iteration 6411 : loss : 0.015803, loss_ce: 0.006579
2022-01-13 22:15:03,104 iteration 6412 : loss : 0.018317, loss_ce: 0.006730
2022-01-13 22:15:04,464 iteration 6413 : loss : 0.024467, loss_ce: 0.011140
2022-01-13 22:15:05,807 iteration 6414 : loss : 0.017257, loss_ce: 0.007341
2022-01-13 22:15:07,133 iteration 6415 : loss : 0.011527, loss_ce: 0.004062
2022-01-13 22:15:08,498 iteration 6416 : loss : 0.014534, loss_ce: 0.005899
2022-01-13 22:15:09,819 iteration 6417 : loss : 0.018488, loss_ce: 0.007554
2022-01-13 22:15:11,176 iteration 6418 : loss : 0.018648, loss_ce: 0.007687
2022-01-13 22:15:12,655 iteration 6419 : loss : 0.023882, loss_ce: 0.009878
2022-01-13 22:15:14,085 iteration 6420 : loss : 0.023269, loss_ce: 0.005914
2022-01-13 22:15:15,509 iteration 6421 : loss : 0.016651, loss_ce: 0.006155
2022-01-13 22:15:16,883 iteration 6422 : loss : 0.021815, loss_ce: 0.006133
2022-01-13 22:15:18,288 iteration 6423 : loss : 0.015707, loss_ce: 0.006974
2022-01-13 22:15:19,784 iteration 6424 : loss : 0.024155, loss_ce: 0.012402
2022-01-13 22:15:21,167 iteration 6425 : loss : 0.017689, loss_ce: 0.006367
2022-01-13 22:15:22,642 iteration 6426 : loss : 0.023552, loss_ce: 0.008463
 94%|███████████████████████████▍ | 378/400 [2:40:54<09:04, 24.76s/it]2022-01-13 22:15:24,137 iteration 6427 : loss : 0.020181, loss_ce: 0.006345
2022-01-13 22:15:25,524 iteration 6428 : loss : 0.021130, loss_ce: 0.006105
2022-01-13 22:15:26,910 iteration 6429 : loss : 0.020429, loss_ce: 0.006233
2022-01-13 22:15:28,337 iteration 6430 : loss : 0.021991, loss_ce: 0.009087
2022-01-13 22:15:29,648 iteration 6431 : loss : 0.013996, loss_ce: 0.005341
2022-01-13 22:15:31,035 iteration 6432 : loss : 0.014861, loss_ce: 0.006279
2022-01-13 22:15:32,404 iteration 6433 : loss : 0.013420, loss_ce: 0.004207
2022-01-13 22:15:33,778 iteration 6434 : loss : 0.015717, loss_ce: 0.006124
2022-01-13 22:15:35,140 iteration 6435 : loss : 0.015068, loss_ce: 0.005213
2022-01-13 22:15:36,489 iteration 6436 : loss : 0.014875, loss_ce: 0.006574
2022-01-13 22:15:37,866 iteration 6437 : loss : 0.028140, loss_ce: 0.009231
2022-01-13 22:15:39,272 iteration 6438 : loss : 0.020928, loss_ce: 0.005953
2022-01-13 22:15:40,599 iteration 6439 : loss : 0.014956, loss_ce: 0.006064
2022-01-13 22:15:42,009 iteration 6440 : loss : 0.023470, loss_ce: 0.012002
2022-01-13 22:15:43,320 iteration 6441 : loss : 0.015014, loss_ce: 0.007147
2022-01-13 22:15:44,699 iteration 6442 : loss : 0.020533, loss_ce: 0.005739
2022-01-13 22:15:46,003 iteration 6443 : loss : 0.013152, loss_ce: 0.004407
 95%|███████████████████████████▍ | 379/400 [2:41:17<08:31, 24.35s/it]2022-01-13 22:15:47,464 iteration 6444 : loss : 0.016453, loss_ce: 0.008919
2022-01-13 22:15:48,835 iteration 6445 : loss : 0.015631, loss_ce: 0.006555
2022-01-13 22:15:50,223 iteration 6446 : loss : 0.018939, loss_ce: 0.008206
2022-01-13 22:15:51,622 iteration 6447 : loss : 0.056351, loss_ce: 0.009033
2022-01-13 22:15:53,028 iteration 6448 : loss : 0.018188, loss_ce: 0.007086
2022-01-13 22:15:54,373 iteration 6449 : loss : 0.013126, loss_ce: 0.003427
2022-01-13 22:15:55,695 iteration 6450 : loss : 0.013589, loss_ce: 0.005893
2022-01-13 22:15:57,075 iteration 6451 : loss : 0.014805, loss_ce: 0.005130
2022-01-13 22:15:58,515 iteration 6452 : loss : 0.029319, loss_ce: 0.009402
2022-01-13 22:15:59,865 iteration 6453 : loss : 0.024734, loss_ce: 0.008988
2022-01-13 22:16:01,174 iteration 6454 : loss : 0.021446, loss_ce: 0.008316
2022-01-13 22:16:02,585 iteration 6455 : loss : 0.014153, loss_ce: 0.006653
2022-01-13 22:16:03,945 iteration 6456 : loss : 0.016886, loss_ce: 0.006906
2022-01-13 22:16:05,332 iteration 6457 : loss : 0.021779, loss_ce: 0.006832
2022-01-13 22:16:06,651 iteration 6458 : loss : 0.016971, loss_ce: 0.006348
2022-01-13 22:16:08,000 iteration 6459 : loss : 0.010429, loss_ce: 0.002709
2022-01-13 22:16:08,000 Training Data Eval:
2022-01-13 22:16:14,788   Average segmentation loss on training set: 0.0091
2022-01-13 22:16:14,789 Validation Data Eval:
2022-01-13 22:16:17,123   Average segmentation loss on validation set: 0.0754
2022-01-13 22:16:18,532 iteration 6460 : loss : 0.019391, loss_ce: 0.009303
 95%|███████████████████████████▌ | 380/400 [2:41:50<08:55, 26.80s/it]2022-01-13 22:16:20,020 iteration 6461 : loss : 0.034017, loss_ce: 0.014680
2022-01-13 22:16:21,388 iteration 6462 : loss : 0.013253, loss_ce: 0.005640
2022-01-13 22:16:22,811 iteration 6463 : loss : 0.020912, loss_ce: 0.008792
2022-01-13 22:16:24,181 iteration 6464 : loss : 0.022475, loss_ce: 0.006849
2022-01-13 22:16:25,591 iteration 6465 : loss : 0.027663, loss_ce: 0.010887
2022-01-13 22:16:26,921 iteration 6466 : loss : 0.014191, loss_ce: 0.004868
2022-01-13 22:16:28,270 iteration 6467 : loss : 0.015091, loss_ce: 0.005816
2022-01-13 22:16:29,696 iteration 6468 : loss : 0.019322, loss_ce: 0.006801
2022-01-13 22:16:31,056 iteration 6469 : loss : 0.017066, loss_ce: 0.006918
2022-01-13 22:16:32,421 iteration 6470 : loss : 0.016249, loss_ce: 0.004817
2022-01-13 22:16:33,791 iteration 6471 : loss : 0.013919, loss_ce: 0.004855
2022-01-13 22:16:35,170 iteration 6472 : loss : 0.025008, loss_ce: 0.008303
2022-01-13 22:16:36,507 iteration 6473 : loss : 0.013665, loss_ce: 0.004540
2022-01-13 22:16:37,936 iteration 6474 : loss : 0.017345, loss_ce: 0.008054
2022-01-13 22:16:39,370 iteration 6475 : loss : 0.023538, loss_ce: 0.012956
2022-01-13 22:16:40,643 iteration 6476 : loss : 0.012069, loss_ce: 0.004511
2022-01-13 22:16:42,103 iteration 6477 : loss : 0.025198, loss_ce: 0.008913
 95%|███████████████████████████▌ | 381/400 [2:42:13<08:10, 25.83s/it]2022-01-13 22:16:43,588 iteration 6478 : loss : 0.024850, loss_ce: 0.008369
2022-01-13 22:16:44,958 iteration 6479 : loss : 0.023492, loss_ce: 0.008175
2022-01-13 22:16:46,319 iteration 6480 : loss : 0.015559, loss_ce: 0.007520
2022-01-13 22:16:47,717 iteration 6481 : loss : 0.015518, loss_ce: 0.006821
2022-01-13 22:16:49,018 iteration 6482 : loss : 0.015627, loss_ce: 0.005537
2022-01-13 22:16:50,418 iteration 6483 : loss : 0.019405, loss_ce: 0.005113
2022-01-13 22:16:51,748 iteration 6484 : loss : 0.017965, loss_ce: 0.008189
2022-01-13 22:16:53,105 iteration 6485 : loss : 0.020760, loss_ce: 0.008879
2022-01-13 22:16:54,544 iteration 6486 : loss : 0.024467, loss_ce: 0.008843
2022-01-13 22:16:56,021 iteration 6487 : loss : 0.022403, loss_ce: 0.008587
2022-01-13 22:16:57,428 iteration 6488 : loss : 0.017627, loss_ce: 0.006712
2022-01-13 22:16:58,765 iteration 6489 : loss : 0.012558, loss_ce: 0.006578
2022-01-13 22:17:00,157 iteration 6490 : loss : 0.023154, loss_ce: 0.007589
2022-01-13 22:17:01,503 iteration 6491 : loss : 0.020309, loss_ce: 0.008668
2022-01-13 22:17:02,954 iteration 6492 : loss : 0.021299, loss_ce: 0.009528
2022-01-13 22:17:04,367 iteration 6493 : loss : 0.031467, loss_ce: 0.011429
2022-01-13 22:17:05,638 iteration 6494 : loss : 0.011083, loss_ce: 0.004166
 96%|███████████████████████████▋ | 382/400 [2:42:37<07:32, 25.14s/it]2022-01-13 22:17:07,059 iteration 6495 : loss : 0.018749, loss_ce: 0.008457
2022-01-13 22:17:08,436 iteration 6496 : loss : 0.023901, loss_ce: 0.006821
2022-01-13 22:17:09,844 iteration 6497 : loss : 0.016649, loss_ce: 0.007149
2022-01-13 22:17:11,254 iteration 6498 : loss : 0.035554, loss_ce: 0.014433
2022-01-13 22:17:12,662 iteration 6499 : loss : 0.018098, loss_ce: 0.007039
2022-01-13 22:17:14,026 iteration 6500 : loss : 0.013631, loss_ce: 0.005595
2022-01-13 22:17:15,423 iteration 6501 : loss : 0.024333, loss_ce: 0.011361
2022-01-13 22:17:16,848 iteration 6502 : loss : 0.014056, loss_ce: 0.007471
2022-01-13 22:17:18,189 iteration 6503 : loss : 0.014743, loss_ce: 0.005276
2022-01-13 22:17:19,504 iteration 6504 : loss : 0.013412, loss_ce: 0.004179
2022-01-13 22:17:20,749 iteration 6505 : loss : 0.011332, loss_ce: 0.005477
2022-01-13 22:17:22,092 iteration 6506 : loss : 0.020373, loss_ce: 0.006880
2022-01-13 22:17:23,536 iteration 6507 : loss : 0.021536, loss_ce: 0.011399
2022-01-13 22:17:24,940 iteration 6508 : loss : 0.018101, loss_ce: 0.007186
2022-01-13 22:17:26,322 iteration 6509 : loss : 0.019874, loss_ce: 0.008239
2022-01-13 22:17:27,710 iteration 6510 : loss : 0.016137, loss_ce: 0.006110
2022-01-13 22:17:29,002 iteration 6511 : loss : 0.013438, loss_ce: 0.004954
 96%|███████████████████████████▊ | 383/400 [2:43:00<06:58, 24.61s/it]2022-01-13 22:17:30,398 iteration 6512 : loss : 0.017544, loss_ce: 0.005691
2022-01-13 22:17:31,773 iteration 6513 : loss : 0.020969, loss_ce: 0.006827
2022-01-13 22:17:33,273 iteration 6514 : loss : 0.012819, loss_ce: 0.004106
2022-01-13 22:17:34,704 iteration 6515 : loss : 0.033108, loss_ce: 0.010089
2022-01-13 22:17:36,108 iteration 6516 : loss : 0.028327, loss_ce: 0.012339
2022-01-13 22:17:37,470 iteration 6517 : loss : 0.029588, loss_ce: 0.005563
2022-01-13 22:17:38,847 iteration 6518 : loss : 0.014952, loss_ce: 0.005397
2022-01-13 22:17:40,209 iteration 6519 : loss : 0.017554, loss_ce: 0.005801
2022-01-13 22:17:41,625 iteration 6520 : loss : 0.017383, loss_ce: 0.005780
2022-01-13 22:17:42,962 iteration 6521 : loss : 0.022429, loss_ce: 0.010626
2022-01-13 22:17:44,350 iteration 6522 : loss : 0.014723, loss_ce: 0.005701
2022-01-13 22:17:45,647 iteration 6523 : loss : 0.011328, loss_ce: 0.004493
2022-01-13 22:17:47,064 iteration 6524 : loss : 0.022830, loss_ce: 0.009613
2022-01-13 22:17:48,446 iteration 6525 : loss : 0.020473, loss_ce: 0.009014
2022-01-13 22:17:49,817 iteration 6526 : loss : 0.015925, loss_ce: 0.006138
2022-01-13 22:17:51,116 iteration 6527 : loss : 0.013299, loss_ce: 0.005938
2022-01-13 22:17:52,446 iteration 6528 : loss : 0.017232, loss_ce: 0.005685
 96%|███████████████████████████▊ | 384/400 [2:43:24<06:28, 24.26s/it]2022-01-13 22:17:53,927 iteration 6529 : loss : 0.029981, loss_ce: 0.012839
2022-01-13 22:17:55,328 iteration 6530 : loss : 0.014626, loss_ce: 0.005287
2022-01-13 22:17:56,644 iteration 6531 : loss : 0.015323, loss_ce: 0.004672
2022-01-13 22:17:58,042 iteration 6532 : loss : 0.018792, loss_ce: 0.008067
2022-01-13 22:17:59,347 iteration 6533 : loss : 0.010384, loss_ce: 0.003961
2022-01-13 22:18:00,720 iteration 6534 : loss : 0.017566, loss_ce: 0.008582
2022-01-13 22:18:02,104 iteration 6535 : loss : 0.018952, loss_ce: 0.008269
2022-01-13 22:18:03,505 iteration 6536 : loss : 0.018186, loss_ce: 0.005952
2022-01-13 22:18:04,893 iteration 6537 : loss : 0.019236, loss_ce: 0.007458
2022-01-13 22:18:06,292 iteration 6538 : loss : 0.018027, loss_ce: 0.005771
2022-01-13 22:18:07,709 iteration 6539 : loss : 0.020680, loss_ce: 0.011349
2022-01-13 22:18:09,019 iteration 6540 : loss : 0.012036, loss_ce: 0.004998
2022-01-13 22:18:10,356 iteration 6541 : loss : 0.017587, loss_ce: 0.010565
2022-01-13 22:18:11,814 iteration 6542 : loss : 0.014059, loss_ce: 0.004674
2022-01-13 22:18:13,155 iteration 6543 : loss : 0.012838, loss_ce: 0.003553
2022-01-13 22:18:14,558 iteration 6544 : loss : 0.028442, loss_ce: 0.010625
2022-01-13 22:18:14,559 Training Data Eval:
2022-01-13 22:18:21,379   Average segmentation loss on training set: 0.0087
2022-01-13 22:18:21,379 Validation Data Eval:
2022-01-13 22:18:23,735   Average segmentation loss on validation set: 0.0777
2022-01-13 22:18:25,176 iteration 6545 : loss : 0.020397, loss_ce: 0.008104
 96%|███████████████████████████▉ | 385/400 [2:43:56<06:41, 26.80s/it]2022-01-13 22:18:26,776 iteration 6546 : loss : 0.023109, loss_ce: 0.010581
2022-01-13 22:18:28,144 iteration 6547 : loss : 0.026385, loss_ce: 0.013722
2022-01-13 22:18:29,550 iteration 6548 : loss : 0.012201, loss_ce: 0.004844
2022-01-13 22:18:30,901 iteration 6549 : loss : 0.016177, loss_ce: 0.006425
2022-01-13 22:18:32,312 iteration 6550 : loss : 0.033496, loss_ce: 0.012373
2022-01-13 22:18:33,753 iteration 6551 : loss : 0.023629, loss_ce: 0.010525
2022-01-13 22:18:35,231 iteration 6552 : loss : 0.036667, loss_ce: 0.014648
2022-01-13 22:18:36,738 iteration 6553 : loss : 0.023616, loss_ce: 0.007445
2022-01-13 22:18:38,144 iteration 6554 : loss : 0.025931, loss_ce: 0.012194
2022-01-13 22:18:39,531 iteration 6555 : loss : 0.012129, loss_ce: 0.005063
2022-01-13 22:18:40,912 iteration 6556 : loss : 0.022121, loss_ce: 0.005470
2022-01-13 22:18:42,187 iteration 6557 : loss : 0.010254, loss_ce: 0.004251
2022-01-13 22:18:43,549 iteration 6558 : loss : 0.023872, loss_ce: 0.007778
2022-01-13 22:18:44,843 iteration 6559 : loss : 0.013961, loss_ce: 0.004909
2022-01-13 22:18:46,213 iteration 6560 : loss : 0.017174, loss_ce: 0.008513
2022-01-13 22:18:47,620 iteration 6561 : loss : 0.021706, loss_ce: 0.006128
2022-01-13 22:18:48,948 iteration 6562 : loss : 0.014040, loss_ce: 0.005496
 96%|███████████████████████████▉ | 386/400 [2:44:20<06:02, 25.89s/it]2022-01-13 22:18:50,510 iteration 6563 : loss : 0.031139, loss_ce: 0.013777
2022-01-13 22:18:51,882 iteration 6564 : loss : 0.015631, loss_ce: 0.007060
2022-01-13 22:18:53,203 iteration 6565 : loss : 0.016650, loss_ce: 0.003896
2022-01-13 22:18:54,516 iteration 6566 : loss : 0.012360, loss_ce: 0.004717
2022-01-13 22:18:55,806 iteration 6567 : loss : 0.016607, loss_ce: 0.006417
2022-01-13 22:18:57,150 iteration 6568 : loss : 0.014175, loss_ce: 0.005984
2022-01-13 22:18:58,516 iteration 6569 : loss : 0.011688, loss_ce: 0.004502
2022-01-13 22:18:59,843 iteration 6570 : loss : 0.009830, loss_ce: 0.004475
2022-01-13 22:19:01,192 iteration 6571 : loss : 0.016790, loss_ce: 0.005139
2022-01-13 22:19:02,482 iteration 6572 : loss : 0.012357, loss_ce: 0.005350
2022-01-13 22:19:03,914 iteration 6573 : loss : 0.020264, loss_ce: 0.007004
2022-01-13 22:19:05,392 iteration 6574 : loss : 0.011157, loss_ce: 0.004693
2022-01-13 22:19:06,843 iteration 6575 : loss : 0.042985, loss_ce: 0.010614
2022-01-13 22:19:08,212 iteration 6576 : loss : 0.018686, loss_ce: 0.008894
2022-01-13 22:19:09,598 iteration 6577 : loss : 0.025541, loss_ce: 0.006157
2022-01-13 22:19:10,916 iteration 6578 : loss : 0.016121, loss_ce: 0.006093
2022-01-13 22:19:12,289 iteration 6579 : loss : 0.021236, loss_ce: 0.008644
 97%|████████████████████████████ | 387/400 [2:44:44<05:26, 25.12s/it]2022-01-13 22:19:13,732 iteration 6580 : loss : 0.023983, loss_ce: 0.006859
2022-01-13 22:19:15,081 iteration 6581 : loss : 0.021494, loss_ce: 0.007802
2022-01-13 22:19:16,520 iteration 6582 : loss : 0.013852, loss_ce: 0.005108
2022-01-13 22:19:17,926 iteration 6583 : loss : 0.015763, loss_ce: 0.006477
2022-01-13 22:19:19,347 iteration 6584 : loss : 0.016215, loss_ce: 0.006366
2022-01-13 22:19:20,777 iteration 6585 : loss : 0.033421, loss_ce: 0.012853
2022-01-13 22:19:22,184 iteration 6586 : loss : 0.029269, loss_ce: 0.009915
2022-01-13 22:19:23,547 iteration 6587 : loss : 0.013279, loss_ce: 0.005280
2022-01-13 22:19:24,932 iteration 6588 : loss : 0.020175, loss_ce: 0.008340
2022-01-13 22:19:26,248 iteration 6589 : loss : 0.020312, loss_ce: 0.008897
2022-01-13 22:19:27,685 iteration 6590 : loss : 0.022024, loss_ce: 0.009516
2022-01-13 22:19:29,116 iteration 6591 : loss : 0.026568, loss_ce: 0.011246
2022-01-13 22:19:30,465 iteration 6592 : loss : 0.012243, loss_ce: 0.004722
2022-01-13 22:19:31,913 iteration 6593 : loss : 0.026604, loss_ce: 0.005596
2022-01-13 22:19:33,281 iteration 6594 : loss : 0.016744, loss_ce: 0.008504
2022-01-13 22:19:34,632 iteration 6595 : loss : 0.016865, loss_ce: 0.005858
2022-01-13 22:19:36,058 iteration 6596 : loss : 0.022451, loss_ce: 0.008919
 97%|████████████████████████████▏| 388/400 [2:45:07<04:56, 24.72s/it]2022-01-13 22:19:37,485 iteration 6597 : loss : 0.018511, loss_ce: 0.008052
2022-01-13 22:19:38,801 iteration 6598 : loss : 0.025429, loss_ce: 0.004310
2022-01-13 22:19:40,192 iteration 6599 : loss : 0.020339, loss_ce: 0.008393
2022-01-13 22:19:41,453 iteration 6600 : loss : 0.011596, loss_ce: 0.004677
2022-01-13 22:19:42,811 iteration 6601 : loss : 0.020288, loss_ce: 0.006951
2022-01-13 22:19:44,156 iteration 6602 : loss : 0.020236, loss_ce: 0.006563
2022-01-13 22:19:45,520 iteration 6603 : loss : 0.015299, loss_ce: 0.006120
2022-01-13 22:19:46,808 iteration 6604 : loss : 0.010543, loss_ce: 0.004489
2022-01-13 22:19:48,178 iteration 6605 : loss : 0.014442, loss_ce: 0.004976
2022-01-13 22:19:49,579 iteration 6606 : loss : 0.014779, loss_ce: 0.007149
2022-01-13 22:19:50,978 iteration 6607 : loss : 0.017706, loss_ce: 0.007943
2022-01-13 22:19:52,379 iteration 6608 : loss : 0.018410, loss_ce: 0.009602
2022-01-13 22:19:53,715 iteration 6609 : loss : 0.016849, loss_ce: 0.005951
2022-01-13 22:19:55,067 iteration 6610 : loss : 0.026616, loss_ce: 0.011195
2022-01-13 22:19:56,430 iteration 6611 : loss : 0.013209, loss_ce: 0.003309
2022-01-13 22:19:57,876 iteration 6612 : loss : 0.020439, loss_ce: 0.008168
2022-01-13 22:19:59,145 iteration 6613 : loss : 0.013492, loss_ce: 0.005665
 97%|████████████████████████████▏| 389/400 [2:45:30<04:26, 24.23s/it]2022-01-13 22:20:00,599 iteration 6614 : loss : 0.022968, loss_ce: 0.009288
2022-01-13 22:20:01,987 iteration 6615 : loss : 0.016269, loss_ce: 0.006813
2022-01-13 22:20:03,356 iteration 6616 : loss : 0.019337, loss_ce: 0.006831
2022-01-13 22:20:04,878 iteration 6617 : loss : 0.019229, loss_ce: 0.007080
2022-01-13 22:20:06,306 iteration 6618 : loss : 0.018577, loss_ce: 0.005292
2022-01-13 22:20:07,821 iteration 6619 : loss : 0.029099, loss_ce: 0.010835
2022-01-13 22:20:09,271 iteration 6620 : loss : 0.047801, loss_ce: 0.017967
2022-01-13 22:20:10,673 iteration 6621 : loss : 0.019568, loss_ce: 0.006222
2022-01-13 22:20:12,062 iteration 6622 : loss : 0.015240, loss_ce: 0.007384
2022-01-13 22:20:13,454 iteration 6623 : loss : 0.021117, loss_ce: 0.007567
2022-01-13 22:20:14,881 iteration 6624 : loss : 0.039346, loss_ce: 0.016897
2022-01-13 22:20:16,336 iteration 6625 : loss : 0.014958, loss_ce: 0.006079
2022-01-13 22:20:17,736 iteration 6626 : loss : 0.018572, loss_ce: 0.004734
2022-01-13 22:20:19,036 iteration 6627 : loss : 0.016427, loss_ce: 0.005407
2022-01-13 22:20:20,408 iteration 6628 : loss : 0.016482, loss_ce: 0.006942
2022-01-13 22:20:21,773 iteration 6629 : loss : 0.017673, loss_ce: 0.010070
2022-01-13 22:20:21,773 Training Data Eval:
2022-01-13 22:20:28,587   Average segmentation loss on training set: 0.0090
2022-01-13 22:20:28,588 Validation Data Eval:
2022-01-13 22:20:30,939   Average segmentation loss on validation set: 0.0740
2022-01-13 22:20:32,370 iteration 6630 : loss : 0.014272, loss_ce: 0.004827
 98%|████████████████████████████▎| 390/400 [2:46:04<04:29, 26.93s/it]2022-01-13 22:20:33,887 iteration 6631 : loss : 0.022049, loss_ce: 0.009180
2022-01-13 22:20:35,280 iteration 6632 : loss : 0.016593, loss_ce: 0.006946
2022-01-13 22:20:36,681 iteration 6633 : loss : 0.030008, loss_ce: 0.006812
2022-01-13 22:20:37,940 iteration 6634 : loss : 0.011326, loss_ce: 0.003601
2022-01-13 22:20:39,275 iteration 6635 : loss : 0.013983, loss_ce: 0.003718
2022-01-13 22:20:40,713 iteration 6636 : loss : 0.023406, loss_ce: 0.009970
2022-01-13 22:20:42,128 iteration 6637 : loss : 0.017412, loss_ce: 0.007833
2022-01-13 22:20:43,560 iteration 6638 : loss : 0.019237, loss_ce: 0.007447
2022-01-13 22:20:45,021 iteration 6639 : loss : 0.026142, loss_ce: 0.008551
2022-01-13 22:20:46,392 iteration 6640 : loss : 0.017471, loss_ce: 0.006036
2022-01-13 22:20:47,772 iteration 6641 : loss : 0.014019, loss_ce: 0.007294
2022-01-13 22:20:49,229 iteration 6642 : loss : 0.017931, loss_ce: 0.007022
2022-01-13 22:20:50,634 iteration 6643 : loss : 0.015581, loss_ce: 0.006604
2022-01-13 22:20:52,016 iteration 6644 : loss : 0.022523, loss_ce: 0.008596
2022-01-13 22:20:53,335 iteration 6645 : loss : 0.011956, loss_ce: 0.005551
2022-01-13 22:20:54,687 iteration 6646 : loss : 0.015230, loss_ce: 0.006548
2022-01-13 22:20:55,972 iteration 6647 : loss : 0.013651, loss_ce: 0.004471
 98%|████████████████████████████▎| 391/400 [2:46:27<03:53, 25.93s/it]2022-01-13 22:20:57,365 iteration 6648 : loss : 0.018023, loss_ce: 0.006088
2022-01-13 22:20:58,828 iteration 6649 : loss : 0.019615, loss_ce: 0.008129
2022-01-13 22:21:00,141 iteration 6650 : loss : 0.016443, loss_ce: 0.006274
2022-01-13 22:21:01,477 iteration 6651 : loss : 0.011224, loss_ce: 0.003861
2022-01-13 22:21:02,959 iteration 6652 : loss : 0.021666, loss_ce: 0.008155
2022-01-13 22:21:04,404 iteration 6653 : loss : 0.017119, loss_ce: 0.007323
2022-01-13 22:21:05,748 iteration 6654 : loss : 0.016926, loss_ce: 0.007444
2022-01-13 22:21:07,154 iteration 6655 : loss : 0.015469, loss_ce: 0.006482
2022-01-13 22:21:08,575 iteration 6656 : loss : 0.013830, loss_ce: 0.005487
2022-01-13 22:21:10,059 iteration 6657 : loss : 0.027304, loss_ce: 0.011407
2022-01-13 22:21:11,465 iteration 6658 : loss : 0.026398, loss_ce: 0.009883
2022-01-13 22:21:12,903 iteration 6659 : loss : 0.029963, loss_ce: 0.014397
2022-01-13 22:21:14,253 iteration 6660 : loss : 0.014198, loss_ce: 0.004677
2022-01-13 22:21:15,554 iteration 6661 : loss : 0.011972, loss_ce: 0.004283
2022-01-13 22:21:16,952 iteration 6662 : loss : 0.014528, loss_ce: 0.005388
2022-01-13 22:21:18,390 iteration 6663 : loss : 0.019883, loss_ce: 0.007494
2022-01-13 22:21:19,780 iteration 6664 : loss : 0.013385, loss_ce: 0.004379
 98%|████████████████████████████▍| 392/400 [2:46:51<03:22, 25.30s/it]2022-01-13 22:21:21,286 iteration 6665 : loss : 0.026736, loss_ce: 0.011792
2022-01-13 22:21:22,709 iteration 6666 : loss : 0.014668, loss_ce: 0.005236
2022-01-13 22:21:24,061 iteration 6667 : loss : 0.018368, loss_ce: 0.006651
2022-01-13 22:21:25,345 iteration 6668 : loss : 0.010456, loss_ce: 0.004293
2022-01-13 22:21:26,737 iteration 6669 : loss : 0.016021, loss_ce: 0.005308
2022-01-13 22:21:28,060 iteration 6670 : loss : 0.019657, loss_ce: 0.006478
2022-01-13 22:21:29,532 iteration 6671 : loss : 0.015538, loss_ce: 0.006653
2022-01-13 22:21:30,915 iteration 6672 : loss : 0.015963, loss_ce: 0.008950
2022-01-13 22:21:32,378 iteration 6673 : loss : 0.029757, loss_ce: 0.014039
2022-01-13 22:21:33,827 iteration 6674 : loss : 0.018478, loss_ce: 0.007356
2022-01-13 22:21:35,180 iteration 6675 : loss : 0.016645, loss_ce: 0.005064
2022-01-13 22:21:36,481 iteration 6676 : loss : 0.011923, loss_ce: 0.004562
2022-01-13 22:21:37,881 iteration 6677 : loss : 0.013779, loss_ce: 0.003286
2022-01-13 22:21:39,360 iteration 6678 : loss : 0.022174, loss_ce: 0.011398
2022-01-13 22:21:40,804 iteration 6679 : loss : 0.015580, loss_ce: 0.005305
2022-01-13 22:21:42,170 iteration 6680 : loss : 0.025017, loss_ce: 0.011431
2022-01-13 22:21:43,541 iteration 6681 : loss : 0.014524, loss_ce: 0.004833
 98%|████████████████████████████▍| 393/400 [2:47:15<02:53, 24.84s/it]2022-01-13 22:21:45,018 iteration 6682 : loss : 0.025133, loss_ce: 0.007742
2022-01-13 22:21:46,450 iteration 6683 : loss : 0.023443, loss_ce: 0.007986
2022-01-13 22:21:47,856 iteration 6684 : loss : 0.050153, loss_ce: 0.004852
2022-01-13 22:21:49,220 iteration 6685 : loss : 0.016077, loss_ce: 0.005871
2022-01-13 22:21:50,623 iteration 6686 : loss : 0.016939, loss_ce: 0.005688
2022-01-13 22:21:52,020 iteration 6687 : loss : 0.017513, loss_ce: 0.007043
2022-01-13 22:21:53,439 iteration 6688 : loss : 0.024376, loss_ce: 0.007642
2022-01-13 22:21:54,785 iteration 6689 : loss : 0.015347, loss_ce: 0.006516
2022-01-13 22:21:56,244 iteration 6690 : loss : 0.016364, loss_ce: 0.006415
2022-01-13 22:21:57,601 iteration 6691 : loss : 0.020075, loss_ce: 0.009961
2022-01-13 22:21:58,922 iteration 6692 : loss : 0.012632, loss_ce: 0.006384
2022-01-13 22:22:00,320 iteration 6693 : loss : 0.018365, loss_ce: 0.007790
2022-01-13 22:22:01,637 iteration 6694 : loss : 0.010956, loss_ce: 0.004694
2022-01-13 22:22:02,987 iteration 6695 : loss : 0.015077, loss_ce: 0.004121
2022-01-13 22:22:04,357 iteration 6696 : loss : 0.017308, loss_ce: 0.009365
2022-01-13 22:22:05,735 iteration 6697 : loss : 0.023217, loss_ce: 0.008140
2022-01-13 22:22:07,034 iteration 6698 : loss : 0.017786, loss_ce: 0.005597
 98%|████████████████████████████▌| 394/400 [2:47:38<02:26, 24.43s/it]2022-01-13 22:22:08,483 iteration 6699 : loss : 0.015081, loss_ce: 0.004638
2022-01-13 22:22:09,914 iteration 6700 : loss : 0.017181, loss_ce: 0.007557
2022-01-13 22:22:11,382 iteration 6701 : loss : 0.041345, loss_ce: 0.012368
2022-01-13 22:22:12,742 iteration 6702 : loss : 0.013713, loss_ce: 0.004754
2022-01-13 22:22:14,228 iteration 6703 : loss : 0.019681, loss_ce: 0.007329
2022-01-13 22:22:15,621 iteration 6704 : loss : 0.035739, loss_ce: 0.021251
2022-01-13 22:22:16,940 iteration 6705 : loss : 0.014124, loss_ce: 0.004550
2022-01-13 22:22:18,303 iteration 6706 : loss : 0.019645, loss_ce: 0.006456
2022-01-13 22:22:19,669 iteration 6707 : loss : 0.015965, loss_ce: 0.005632
2022-01-13 22:22:20,960 iteration 6708 : loss : 0.009608, loss_ce: 0.003107
2022-01-13 22:22:22,283 iteration 6709 : loss : 0.015639, loss_ce: 0.004150
2022-01-13 22:22:23,669 iteration 6710 : loss : 0.025988, loss_ce: 0.010100
2022-01-13 22:22:25,034 iteration 6711 : loss : 0.017713, loss_ce: 0.007507
2022-01-13 22:22:26,444 iteration 6712 : loss : 0.015930, loss_ce: 0.006090
2022-01-13 22:22:27,789 iteration 6713 : loss : 0.017243, loss_ce: 0.005483
2022-01-13 22:22:29,153 iteration 6714 : loss : 0.019243, loss_ce: 0.007467
2022-01-13 22:22:29,153 Training Data Eval:
2022-01-13 22:22:35,959   Average segmentation loss on training set: 0.0088
2022-01-13 22:22:35,959 Validation Data Eval:
2022-01-13 22:22:38,303   Average segmentation loss on validation set: 0.0724
2022-01-13 22:22:39,630 iteration 6715 : loss : 0.009752, loss_ce: 0.002890
 99%|████████████████████████████▋| 395/400 [2:48:11<02:14, 26.88s/it]2022-01-13 22:22:40,985 iteration 6716 : loss : 0.012752, loss_ce: 0.004151
2022-01-13 22:22:42,387 iteration 6717 : loss : 0.021281, loss_ce: 0.006397
2022-01-13 22:22:43,857 iteration 6718 : loss : 0.035058, loss_ce: 0.016285
2022-01-13 22:22:45,304 iteration 6719 : loss : 0.030947, loss_ce: 0.010009
2022-01-13 22:22:46,712 iteration 6720 : loss : 0.057131, loss_ce: 0.013293
2022-01-13 22:22:48,132 iteration 6721 : loss : 0.020717, loss_ce: 0.010857
2022-01-13 22:22:49,490 iteration 6722 : loss : 0.013330, loss_ce: 0.005239
2022-01-13 22:22:50,879 iteration 6723 : loss : 0.031786, loss_ce: 0.013315
2022-01-13 22:22:52,199 iteration 6724 : loss : 0.020073, loss_ce: 0.008520
2022-01-13 22:22:53,566 iteration 6725 : loss : 0.015953, loss_ce: 0.005140
2022-01-13 22:22:54,871 iteration 6726 : loss : 0.010142, loss_ce: 0.003580
2022-01-13 22:22:56,350 iteration 6727 : loss : 0.020973, loss_ce: 0.006961
2022-01-13 22:22:57,682 iteration 6728 : loss : 0.020318, loss_ce: 0.007353
2022-01-13 22:22:59,108 iteration 6729 : loss : 0.020290, loss_ce: 0.006987
2022-01-13 22:23:00,582 iteration 6730 : loss : 0.019162, loss_ce: 0.008566
2022-01-13 22:23:02,009 iteration 6731 : loss : 0.023203, loss_ce: 0.007425
2022-01-13 22:23:03,382 iteration 6732 : loss : 0.013961, loss_ce: 0.006622
 99%|████████████████████████████▋| 396/400 [2:48:35<01:43, 25.94s/it]2022-01-13 22:23:04,765 iteration 6733 : loss : 0.010537, loss_ce: 0.004899
2022-01-13 22:23:06,124 iteration 6734 : loss : 0.016982, loss_ce: 0.004158
2022-01-13 22:23:07,531 iteration 6735 : loss : 0.020210, loss_ce: 0.006352
2022-01-13 22:23:08,917 iteration 6736 : loss : 0.012021, loss_ce: 0.005480
2022-01-13 22:23:10,238 iteration 6737 : loss : 0.016818, loss_ce: 0.008516
2022-01-13 22:23:11,541 iteration 6738 : loss : 0.014697, loss_ce: 0.004494
2022-01-13 22:23:12,920 iteration 6739 : loss : 0.016308, loss_ce: 0.007412
2022-01-13 22:23:14,334 iteration 6740 : loss : 0.030016, loss_ce: 0.011487
2022-01-13 22:23:15,746 iteration 6741 : loss : 0.022784, loss_ce: 0.010797
2022-01-13 22:23:17,098 iteration 6742 : loss : 0.018580, loss_ce: 0.010827
2022-01-13 22:23:18,412 iteration 6743 : loss : 0.014418, loss_ce: 0.003503
2022-01-13 22:23:19,832 iteration 6744 : loss : 0.021313, loss_ce: 0.009038
2022-01-13 22:23:21,200 iteration 6745 : loss : 0.014543, loss_ce: 0.006754
2022-01-13 22:23:22,542 iteration 6746 : loss : 0.010676, loss_ce: 0.003153
2022-01-13 22:23:23,865 iteration 6747 : loss : 0.017508, loss_ce: 0.005510
2022-01-13 22:23:25,258 iteration 6748 : loss : 0.012612, loss_ce: 0.005784
2022-01-13 22:23:26,641 iteration 6749 : loss : 0.013767, loss_ce: 0.004044
 99%|████████████████████████████▊| 397/400 [2:48:58<01:15, 25.13s/it]2022-01-13 22:23:28,061 iteration 6750 : loss : 0.013047, loss_ce: 0.005957
2022-01-13 22:23:29,509 iteration 6751 : loss : 0.014325, loss_ce: 0.005069
2022-01-13 22:23:30,820 iteration 6752 : loss : 0.014425, loss_ce: 0.004740
2022-01-13 22:23:32,187 iteration 6753 : loss : 0.025088, loss_ce: 0.011538
2022-01-13 22:23:33,589 iteration 6754 : loss : 0.012705, loss_ce: 0.004459
2022-01-13 22:23:34,952 iteration 6755 : loss : 0.016716, loss_ce: 0.005486
2022-01-13 22:23:36,286 iteration 6756 : loss : 0.027818, loss_ce: 0.010428
2022-01-13 22:23:37,761 iteration 6757 : loss : 0.015858, loss_ce: 0.005666
2022-01-13 22:23:39,097 iteration 6758 : loss : 0.021127, loss_ce: 0.008536
2022-01-13 22:23:40,481 iteration 6759 : loss : 0.016200, loss_ce: 0.007704
2022-01-13 22:23:41,921 iteration 6760 : loss : 0.028829, loss_ce: 0.005350
2022-01-13 22:23:43,292 iteration 6761 : loss : 0.024850, loss_ce: 0.012906
2022-01-13 22:23:44,646 iteration 6762 : loss : 0.017741, loss_ce: 0.005351
2022-01-13 22:23:46,076 iteration 6763 : loss : 0.023503, loss_ce: 0.009008
2022-01-13 22:23:47,431 iteration 6764 : loss : 0.022111, loss_ce: 0.008756
2022-01-13 22:23:48,858 iteration 6765 : loss : 0.015932, loss_ce: 0.005979
2022-01-13 22:23:50,197 iteration 6766 : loss : 0.013154, loss_ce: 0.006391
100%|████████████████████████████▊| 398/400 [2:49:21<00:49, 24.66s/it]2022-01-13 22:23:51,620 iteration 6767 : loss : 0.019058, loss_ce: 0.006176
2022-01-13 22:23:53,084 iteration 6768 : loss : 0.021393, loss_ce: 0.008490
2022-01-13 22:23:54,480 iteration 6769 : loss : 0.014838, loss_ce: 0.006234
2022-01-13 22:23:55,833 iteration 6770 : loss : 0.016038, loss_ce: 0.008593
2022-01-13 22:23:57,306 iteration 6771 : loss : 0.039934, loss_ce: 0.010127
2022-01-13 22:23:58,650 iteration 6772 : loss : 0.013656, loss_ce: 0.005098
2022-01-13 22:23:59,903 iteration 6773 : loss : 0.012738, loss_ce: 0.003915
2022-01-13 22:24:01,304 iteration 6774 : loss : 0.027699, loss_ce: 0.006997
2022-01-13 22:24:02,700 iteration 6775 : loss : 0.017812, loss_ce: 0.005860
2022-01-13 22:24:04,056 iteration 6776 : loss : 0.015912, loss_ce: 0.005270
2022-01-13 22:24:05,504 iteration 6777 : loss : 0.020760, loss_ce: 0.009996
2022-01-13 22:24:06,868 iteration 6778 : loss : 0.013117, loss_ce: 0.004859
2022-01-13 22:24:08,323 iteration 6779 : loss : 0.021187, loss_ce: 0.009833
2022-01-13 22:24:09,710 iteration 6780 : loss : 0.015406, loss_ce: 0.006819
2022-01-13 22:24:11,137 iteration 6781 : loss : 0.030058, loss_ce: 0.013591
2022-01-13 22:24:12,559 iteration 6782 : loss : 0.013983, loss_ce: 0.005351
2022-01-13 22:24:13,904 iteration 6783 : loss : 0.015790, loss_ce: 0.005409
100%|████████████████████████████▉| 399/400 [2:49:45<00:24, 24.37s/it]2022-01-13 22:24:15,407 iteration 6784 : loss : 0.016401, loss_ce: 0.005258
2022-01-13 22:24:16,816 iteration 6785 : loss : 0.022277, loss_ce: 0.007815
2022-01-13 22:24:18,146 iteration 6786 : loss : 0.013269, loss_ce: 0.005362
2022-01-13 22:24:19,504 iteration 6787 : loss : 0.015079, loss_ce: 0.005874
2022-01-13 22:24:20,892 iteration 6788 : loss : 0.018079, loss_ce: 0.007616
2022-01-13 22:24:22,279 iteration 6789 : loss : 0.021089, loss_ce: 0.005961
2022-01-13 22:24:23,622 iteration 6790 : loss : 0.014226, loss_ce: 0.006145
2022-01-13 22:24:25,022 iteration 6791 : loss : 0.029319, loss_ce: 0.011385
2022-01-13 22:24:26,354 iteration 6792 : loss : 0.014230, loss_ce: 0.006339
2022-01-13 22:24:27,820 iteration 6793 : loss : 0.021819, loss_ce: 0.006937
2022-01-13 22:24:29,193 iteration 6794 : loss : 0.029128, loss_ce: 0.009768
2022-01-13 22:24:30,668 iteration 6795 : loss : 0.018869, loss_ce: 0.006931
2022-01-13 22:24:32,095 iteration 6796 : loss : 0.020253, loss_ce: 0.012280
2022-01-13 22:24:33,385 iteration 6797 : loss : 0.019207, loss_ce: 0.008688
2022-01-13 22:24:34,803 iteration 6798 : loss : 0.019098, loss_ce: 0.006103
2022-01-13 22:24:36,281 iteration 6799 : loss : 0.024760, loss_ce: 0.013678
2022-01-13 22:24:36,281 Training Data Eval:
2022-01-13 22:24:43,090   Average segmentation loss on training set: 0.0085
2022-01-13 22:24:43,090 Validation Data Eval:
2022-01-13 22:24:45,433   Average segmentation loss on validation set: 0.0718
2022-01-13 22:24:46,758 iteration 6800 : loss : 0.011869, loss_ce: 0.003316
100%|█████████████████████████████| 400/400 [2:50:18<00:00, 26.92s/it]100%|█████████████████████████████| 400/400 [2:50:18<00:00, 25.55s/it]
