2022-01-14 14:52:39,900 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:52:39,901 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:52:39,902 ============================================================
2022-01-14 14:52:39,902 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:52:39,902 ============================================================
2022-01-14 14:52:39,902 Loading data...
2022-01-14 14:52:39,902 Reading NCI - RUNMC images...
2022-01-14 14:52:39,902 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-14 14:52:39,904 Already preprocessed this configuration. Loading now!
2022-01-14 14:52:39,927 Training Images: (256, 256, 286)
2022-01-14 14:52:39,927 Training Labels: (256, 256, 286)
2022-01-14 14:52:39,927 Validation Images: (256, 256, 98)
2022-01-14 14:52:39,928 Validation Labels: (256, 256, 98)
2022-01-14 14:52:39,928 ============================================================
2022-01-14 14:52:39,968 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-14 14:52:43,289 iteration 1 : loss : 0.765864, loss_ce: 0.862296
2022-01-14 14:52:44,677 iteration 2 : loss : 0.724878, loss_ce: 0.774150
2022-01-14 14:52:46,053 iteration 3 : loss : 0.683697, loss_ce: 0.688624
2022-01-14 14:52:47,508 iteration 4 : loss : 0.623142, loss_ce: 0.625611
2022-01-14 14:52:48,824 iteration 5 : loss : 0.603354, loss_ce: 0.556121
2022-01-14 14:52:50,344 iteration 6 : loss : 0.553655, loss_ce: 0.495898
2022-01-14 14:52:51,813 iteration 7 : loss : 0.538321, loss_ce: 0.458052
2022-01-14 14:52:53,245 iteration 8 : loss : 0.493699, loss_ce: 0.410660
2022-01-14 14:52:54,572 iteration 9 : loss : 0.466530, loss_ce: 0.391747
2022-01-14 14:52:56,015 iteration 10 : loss : 0.468810, loss_ce: 0.370461
2022-01-14 14:52:57,460 iteration 11 : loss : 0.435883, loss_ce: 0.325155
2022-01-14 14:52:58,953 iteration 12 : loss : 0.416142, loss_ce: 0.303510
2022-01-14 14:53:00,326 iteration 13 : loss : 0.394473, loss_ce: 0.268060
2022-01-14 14:53:01,853 iteration 14 : loss : 0.387905, loss_ce: 0.254375
2022-01-14 14:53:03,266 iteration 15 : loss : 0.371173, loss_ce: 0.226376
2022-01-14 14:53:04,667 iteration 16 : loss : 0.365639, loss_ce: 0.217211
2022-01-14 14:53:06,030 iteration 17 : loss : 0.363378, loss_ce: 0.189932
  0%|                               | 1/400 [00:26<2:53:42, 26.12s/it]2022-01-14 14:53:07,505 iteration 18 : loss : 0.338512, loss_ce: 0.187801
2022-01-14 14:53:08,961 iteration 19 : loss : 0.329609, loss_ce: 0.153061
2022-01-14 14:53:10,499 iteration 20 : loss : 0.331993, loss_ce: 0.170545
2022-01-14 14:53:11,898 iteration 21 : loss : 0.339192, loss_ce: 0.157458
2022-01-14 14:53:13,222 iteration 22 : loss : 0.307187, loss_ce: 0.143420
2022-01-14 14:53:14,729 iteration 23 : loss : 0.317348, loss_ce: 0.146390
2022-01-14 14:53:16,212 iteration 24 : loss : 0.275264, loss_ce: 0.137948
2022-01-14 14:53:17,756 iteration 25 : loss : 0.325056, loss_ce: 0.179509
2022-01-14 14:53:19,155 iteration 26 : loss : 0.278795, loss_ce: 0.140228
2022-01-14 14:53:20,504 iteration 27 : loss : 0.293440, loss_ce: 0.141077
2022-01-14 14:53:21,829 iteration 28 : loss : 0.279832, loss_ce: 0.130467
2022-01-14 14:53:23,264 iteration 29 : loss : 0.323782, loss_ce: 0.156106
2022-01-14 14:53:24,622 iteration 30 : loss : 0.304509, loss_ce: 0.136549
2022-01-14 14:53:26,012 iteration 31 : loss : 0.249527, loss_ce: 0.099466
2022-01-14 14:53:27,398 iteration 32 : loss : 0.280173, loss_ce: 0.150443
2022-01-14 14:53:28,836 iteration 33 : loss : 0.315315, loss_ce: 0.153808
2022-01-14 14:53:30,356 iteration 34 : loss : 0.235154, loss_ce: 0.103108
  0%|▏                              | 2/400 [00:50<2:46:12, 25.06s/it]2022-01-14 14:53:31,852 iteration 35 : loss : 0.259021, loss_ce: 0.121323
2022-01-14 14:53:33,279 iteration 36 : loss : 0.281601, loss_ce: 0.097026
2022-01-14 14:53:34,739 iteration 37 : loss : 0.253855, loss_ce: 0.095159
2022-01-14 14:53:36,167 iteration 38 : loss : 0.256436, loss_ce: 0.099210
2022-01-14 14:53:37,480 iteration 39 : loss : 0.303592, loss_ce: 0.130918
2022-01-14 14:53:38,860 iteration 40 : loss : 0.322990, loss_ce: 0.149486
2022-01-14 14:53:40,154 iteration 41 : loss : 0.250054, loss_ce: 0.106905
2022-01-14 14:53:41,591 iteration 42 : loss : 0.293155, loss_ce: 0.133412
2022-01-14 14:53:43,000 iteration 43 : loss : 0.217458, loss_ce: 0.090480
2022-01-14 14:53:44,317 iteration 44 : loss : 0.267222, loss_ce: 0.134228
2022-01-14 14:53:45,840 iteration 45 : loss : 0.256944, loss_ce: 0.106983
2022-01-14 14:53:47,363 iteration 46 : loss : 0.262520, loss_ce: 0.117824
2022-01-14 14:53:48,918 iteration 47 : loss : 0.243989, loss_ce: 0.097713
2022-01-14 14:53:50,448 iteration 48 : loss : 0.224232, loss_ce: 0.106088
2022-01-14 14:53:52,037 iteration 49 : loss : 0.312435, loss_ce: 0.149654
2022-01-14 14:53:53,602 iteration 50 : loss : 0.239737, loss_ce: 0.101443
2022-01-14 14:53:55,170 iteration 51 : loss : 0.216327, loss_ce: 0.086238
  1%|▏                              | 3/400 [01:15<2:45:03, 24.95s/it]2022-01-14 14:53:56,621 iteration 52 : loss : 0.257751, loss_ce: 0.096847
2022-01-14 14:53:58,033 iteration 53 : loss : 0.228144, loss_ce: 0.102318
2022-01-14 14:53:59,558 iteration 54 : loss : 0.251167, loss_ce: 0.101262
2022-01-14 14:54:01,120 iteration 55 : loss : 0.302889, loss_ce: 0.119618
2022-01-14 14:54:02,631 iteration 56 : loss : 0.241954, loss_ce: 0.112022
2022-01-14 14:54:04,109 iteration 57 : loss : 0.254361, loss_ce: 0.122254
2022-01-14 14:54:05,576 iteration 58 : loss : 0.263321, loss_ce: 0.133233
2022-01-14 14:54:06,991 iteration 59 : loss : 0.226293, loss_ce: 0.098730
2022-01-14 14:54:08,478 iteration 60 : loss : 0.224294, loss_ce: 0.105744
2022-01-14 14:54:09,940 iteration 61 : loss : 0.232822, loss_ce: 0.097045
2022-01-14 14:54:11,530 iteration 62 : loss : 0.258618, loss_ce: 0.089625
2022-01-14 14:54:12,990 iteration 63 : loss : 0.255995, loss_ce: 0.116778
2022-01-14 14:54:14,555 iteration 64 : loss : 0.269020, loss_ce: 0.108224
2022-01-14 14:54:16,048 iteration 65 : loss : 0.229721, loss_ce: 0.089290
2022-01-14 14:54:17,616 iteration 66 : loss : 0.253013, loss_ce: 0.108126
2022-01-14 14:54:19,076 iteration 67 : loss : 0.226939, loss_ce: 0.100290
2022-01-14 14:54:20,515 iteration 68 : loss : 0.204922, loss_ce: 0.089065
  1%|▎                              | 4/400 [01:40<2:45:40, 25.10s/it]2022-01-14 14:54:22,130 iteration 69 : loss : 0.284327, loss_ce: 0.120915
2022-01-14 14:54:23,604 iteration 70 : loss : 0.265440, loss_ce: 0.101982
2022-01-14 14:54:25,094 iteration 71 : loss : 0.262555, loss_ce: 0.134936
2022-01-14 14:54:26,639 iteration 72 : loss : 0.238717, loss_ce: 0.107253
2022-01-14 14:54:28,169 iteration 73 : loss : 0.235611, loss_ce: 0.082788
2022-01-14 14:54:29,671 iteration 74 : loss : 0.200733, loss_ce: 0.078316
2022-01-14 14:54:31,114 iteration 75 : loss : 0.220584, loss_ce: 0.103410
2022-01-14 14:54:32,531 iteration 76 : loss : 0.239644, loss_ce: 0.109402
2022-01-14 14:54:34,091 iteration 77 : loss : 0.281784, loss_ce: 0.131235
2022-01-14 14:54:35,593 iteration 78 : loss : 0.236053, loss_ce: 0.087767
2022-01-14 14:54:37,099 iteration 79 : loss : 0.254046, loss_ce: 0.099615
2022-01-14 14:54:38,503 iteration 80 : loss : 0.241424, loss_ce: 0.085725
2022-01-14 14:54:40,040 iteration 81 : loss : 0.250143, loss_ce: 0.106247
2022-01-14 14:54:41,510 iteration 82 : loss : 0.273984, loss_ce: 0.085522
2022-01-14 14:54:42,979 iteration 83 : loss : 0.276582, loss_ce: 0.078929
2022-01-14 14:54:44,562 iteration 84 : loss : 0.277119, loss_ce: 0.121326
2022-01-14 14:54:44,562 Training Data Eval:
2022-01-14 14:54:52,001   Average segmentation loss on training set: 0.2330
2022-01-14 14:54:52,002 Validation Data Eval:
2022-01-14 14:54:54,796   Average segmentation loss on validation set: 0.3014
2022-01-14 14:55:00,600 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed100.pth
2022-01-14 14:55:01,940 iteration 85 : loss : 0.272137, loss_ce: 0.123726
  1%|▍                              | 5/400 [02:22<3:24:01, 30.99s/it]2022-01-14 14:55:03,429 iteration 86 : loss : 0.252981, loss_ce: 0.119489
2022-01-14 14:55:04,768 iteration 87 : loss : 0.285975, loss_ce: 0.121860
2022-01-14 14:55:06,074 iteration 88 : loss : 0.224571, loss_ce: 0.118475
2022-01-14 14:55:07,445 iteration 89 : loss : 0.264481, loss_ce: 0.103947
2022-01-14 14:55:08,788 iteration 90 : loss : 0.211963, loss_ce: 0.093204
2022-01-14 14:55:10,191 iteration 91 : loss : 0.198360, loss_ce: 0.087844
2022-01-14 14:55:11,608 iteration 92 : loss : 0.201565, loss_ce: 0.070317
2022-01-14 14:55:12,924 iteration 93 : loss : 0.199449, loss_ce: 0.062742
2022-01-14 14:55:14,397 iteration 94 : loss : 0.215711, loss_ce: 0.092118
2022-01-14 14:55:15,860 iteration 95 : loss : 0.251074, loss_ce: 0.116453
2022-01-14 14:55:17,394 iteration 96 : loss : 0.217097, loss_ce: 0.081923
2022-01-14 14:55:18,868 iteration 97 : loss : 0.217614, loss_ce: 0.082837
2022-01-14 14:55:20,378 iteration 98 : loss : 0.278238, loss_ce: 0.113873
2022-01-14 14:55:21,840 iteration 99 : loss : 0.247102, loss_ce: 0.098622
2022-01-14 14:55:23,358 iteration 100 : loss : 0.204642, loss_ce: 0.086457
2022-01-14 14:55:24,817 iteration 101 : loss : 0.186891, loss_ce: 0.078575
2022-01-14 14:55:26,262 iteration 102 : loss : 0.198485, loss_ce: 0.094133
  2%|▍                              | 6/400 [02:46<3:08:35, 28.72s/it]2022-01-14 14:55:27,791 iteration 103 : loss : 0.247331, loss_ce: 0.092740
2022-01-14 14:55:29,312 iteration 104 : loss : 0.192719, loss_ce: 0.076885
2022-01-14 14:55:30,863 iteration 105 : loss : 0.206993, loss_ce: 0.090070
2022-01-14 14:55:32,492 iteration 106 : loss : 0.207304, loss_ce: 0.083497
2022-01-14 14:55:34,038 iteration 107 : loss : 0.282699, loss_ce: 0.095764
2022-01-14 14:55:35,551 iteration 108 : loss : 0.209459, loss_ce: 0.069688
2022-01-14 14:55:36,984 iteration 109 : loss : 0.289231, loss_ce: 0.120624
2022-01-14 14:55:38,476 iteration 110 : loss : 0.232640, loss_ce: 0.097747
2022-01-14 14:55:40,088 iteration 111 : loss : 0.213305, loss_ce: 0.096634
2022-01-14 14:55:41,607 iteration 112 : loss : 0.222342, loss_ce: 0.090376
2022-01-14 14:55:43,038 iteration 113 : loss : 0.192400, loss_ce: 0.077343
2022-01-14 14:55:44,586 iteration 114 : loss : 0.207003, loss_ce: 0.079070
2022-01-14 14:55:46,089 iteration 115 : loss : 0.172502, loss_ce: 0.086530
2022-01-14 14:55:47,627 iteration 116 : loss : 0.237843, loss_ce: 0.123105
2022-01-14 14:55:49,104 iteration 117 : loss : 0.214145, loss_ce: 0.088636
2022-01-14 14:55:50,616 iteration 118 : loss : 0.259457, loss_ce: 0.125593
2022-01-14 14:55:52,147 iteration 119 : loss : 0.209365, loss_ce: 0.081353
  2%|▌                              | 7/400 [03:12<3:02:03, 27.80s/it]2022-01-14 14:55:53,801 iteration 120 : loss : 0.221797, loss_ce: 0.096000
2022-01-14 14:55:55,348 iteration 121 : loss : 0.286061, loss_ce: 0.122429
2022-01-14 14:55:56,800 iteration 122 : loss : 0.206332, loss_ce: 0.084979
2022-01-14 14:55:58,369 iteration 123 : loss : 0.238347, loss_ce: 0.109417
2022-01-14 14:55:59,925 iteration 124 : loss : 0.340810, loss_ce: 0.159684
2022-01-14 14:56:01,449 iteration 125 : loss : 0.232376, loss_ce: 0.123642
2022-01-14 14:56:03,029 iteration 126 : loss : 0.308242, loss_ce: 0.134411
2022-01-14 14:56:04,602 iteration 127 : loss : 0.225927, loss_ce: 0.107883
2022-01-14 14:56:06,168 iteration 128 : loss : 0.187316, loss_ce: 0.089822
2022-01-14 14:56:07,675 iteration 129 : loss : 0.260875, loss_ce: 0.108714
2022-01-14 14:56:09,248 iteration 130 : loss : 0.274149, loss_ce: 0.137981
2022-01-14 14:56:10,729 iteration 131 : loss : 0.263679, loss_ce: 0.125064
2022-01-14 14:56:12,188 iteration 132 : loss : 0.295198, loss_ce: 0.105944
2022-01-14 14:56:13,767 iteration 133 : loss : 0.257664, loss_ce: 0.090431
2022-01-14 14:56:15,263 iteration 134 : loss : 0.300520, loss_ce: 0.119212
2022-01-14 14:56:16,799 iteration 135 : loss : 0.230001, loss_ce: 0.100060
2022-01-14 14:56:18,320 iteration 136 : loss : 0.262097, loss_ce: 0.122117
  2%|▌                              | 8/400 [03:38<2:58:12, 27.28s/it]2022-01-14 14:56:19,806 iteration 137 : loss : 0.187759, loss_ce: 0.066464
2022-01-14 14:56:21,278 iteration 138 : loss : 0.274469, loss_ce: 0.145597
2022-01-14 14:56:22,874 iteration 139 : loss : 0.212913, loss_ce: 0.081189
2022-01-14 14:56:24,486 iteration 140 : loss : 0.293019, loss_ce: 0.115188
2022-01-14 14:56:26,013 iteration 141 : loss : 0.243776, loss_ce: 0.098263
2022-01-14 14:56:27,482 iteration 142 : loss : 0.210981, loss_ce: 0.087013
2022-01-14 14:56:28,950 iteration 143 : loss : 0.279340, loss_ce: 0.116532
2022-01-14 14:56:30,531 iteration 144 : loss : 0.261099, loss_ce: 0.094609
2022-01-14 14:56:32,236 iteration 145 : loss : 0.221361, loss_ce: 0.091607
2022-01-14 14:56:33,708 iteration 146 : loss : 0.231078, loss_ce: 0.085985
2022-01-14 14:56:35,227 iteration 147 : loss : 0.260399, loss_ce: 0.103683
2022-01-14 14:56:36,738 iteration 148 : loss : 0.253265, loss_ce: 0.115268
2022-01-14 14:56:38,241 iteration 149 : loss : 0.245906, loss_ce: 0.099248
2022-01-14 14:56:39,757 iteration 150 : loss : 0.306347, loss_ce: 0.155421
2022-01-14 14:56:41,287 iteration 151 : loss : 0.212305, loss_ce: 0.094990
2022-01-14 14:56:42,882 iteration 152 : loss : 0.211834, loss_ce: 0.097820
2022-01-14 14:56:44,458 iteration 153 : loss : 0.198949, loss_ce: 0.089961
  2%|▋                              | 9/400 [04:04<2:55:25, 26.92s/it]2022-01-14 14:56:45,990 iteration 154 : loss : 0.199325, loss_ce: 0.082113
2022-01-14 14:56:47,556 iteration 155 : loss : 0.250160, loss_ce: 0.108155
2022-01-14 14:56:49,104 iteration 156 : loss : 0.213940, loss_ce: 0.084102
2022-01-14 14:56:50,652 iteration 157 : loss : 0.257226, loss_ce: 0.097463
2022-01-14 14:56:52,181 iteration 158 : loss : 0.242374, loss_ce: 0.107331
2022-01-14 14:56:53,692 iteration 159 : loss : 0.243987, loss_ce: 0.097162
2022-01-14 14:56:55,186 iteration 160 : loss : 0.299779, loss_ce: 0.112015
2022-01-14 14:56:56,723 iteration 161 : loss : 0.234207, loss_ce: 0.104083
2022-01-14 14:56:58,331 iteration 162 : loss : 0.200985, loss_ce: 0.083496
2022-01-14 14:56:59,722 iteration 163 : loss : 0.190665, loss_ce: 0.076309
2022-01-14 14:57:01,327 iteration 164 : loss : 0.174947, loss_ce: 0.073854
2022-01-14 14:57:02,800 iteration 165 : loss : 0.191826, loss_ce: 0.070691
2022-01-14 14:57:04,393 iteration 166 : loss : 0.252035, loss_ce: 0.109308
2022-01-14 14:57:05,924 iteration 167 : loss : 0.247945, loss_ce: 0.112073
2022-01-14 14:57:07,490 iteration 168 : loss : 0.224262, loss_ce: 0.095595
2022-01-14 14:57:08,974 iteration 169 : loss : 0.200636, loss_ce: 0.085989
2022-01-14 14:57:08,975 Training Data Eval:
2022-01-14 14:57:16,460   Average segmentation loss on training set: 0.2016
2022-01-14 14:57:16,460 Validation Data Eval:
2022-01-14 14:57:19,025   Average segmentation loss on validation set: 0.2067
2022-01-14 14:57:25,004 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed100.pth
2022-01-14 14:57:26,396 iteration 170 : loss : 0.214235, loss_ce: 0.094380
  2%|▊                             | 10/400 [04:46<3:25:07, 31.56s/it]2022-01-14 14:57:27,892 iteration 171 : loss : 0.266825, loss_ce: 0.133637
2022-01-14 14:57:29,175 iteration 172 : loss : 0.288870, loss_ce: 0.107291
2022-01-14 14:57:30,501 iteration 173 : loss : 0.189640, loss_ce: 0.079750
2022-01-14 14:57:31,983 iteration 174 : loss : 0.257248, loss_ce: 0.106745
2022-01-14 14:57:33,398 iteration 175 : loss : 0.237062, loss_ce: 0.100445
2022-01-14 14:57:34,928 iteration 176 : loss : 0.221122, loss_ce: 0.079563
2022-01-14 14:57:36,333 iteration 177 : loss : 0.281070, loss_ce: 0.101311
2022-01-14 14:57:37,782 iteration 178 : loss : 0.225472, loss_ce: 0.073204
2022-01-14 14:57:39,253 iteration 179 : loss : 0.199612, loss_ce: 0.083812
2022-01-14 14:57:40,760 iteration 180 : loss : 0.194302, loss_ce: 0.066746
2022-01-14 14:57:42,323 iteration 181 : loss : 0.159102, loss_ce: 0.062403
2022-01-14 14:57:43,870 iteration 182 : loss : 0.181059, loss_ce: 0.072849
2022-01-14 14:57:45,453 iteration 183 : loss : 0.169288, loss_ce: 0.065116
2022-01-14 14:57:46,973 iteration 184 : loss : 0.191656, loss_ce: 0.081389
2022-01-14 14:57:48,461 iteration 185 : loss : 0.260678, loss_ce: 0.131754
2022-01-14 14:57:49,935 iteration 186 : loss : 0.175205, loss_ce: 0.075314
2022-01-14 14:57:51,384 iteration 187 : loss : 0.247751, loss_ce: 0.126693
  3%|▊                             | 11/400 [05:11<3:11:33, 29.55s/it]2022-01-14 14:57:53,009 iteration 188 : loss : 0.313270, loss_ce: 0.132233
2022-01-14 14:57:54,579 iteration 189 : loss : 0.213907, loss_ce: 0.107411
2022-01-14 14:57:56,204 iteration 190 : loss : 0.195503, loss_ce: 0.075207
2022-01-14 14:57:57,741 iteration 191 : loss : 0.253074, loss_ce: 0.120103
2022-01-14 14:57:59,172 iteration 192 : loss : 0.170132, loss_ce: 0.074947
2022-01-14 14:58:00,635 iteration 193 : loss : 0.293739, loss_ce: 0.131063
2022-01-14 14:58:02,077 iteration 194 : loss : 0.257597, loss_ce: 0.117464
2022-01-14 14:58:03,660 iteration 195 : loss : 0.149851, loss_ce: 0.052949
2022-01-14 14:58:05,227 iteration 196 : loss : 0.199880, loss_ce: 0.067388
2022-01-14 14:58:06,758 iteration 197 : loss : 0.187549, loss_ce: 0.075665
2022-01-14 14:58:08,328 iteration 198 : loss : 0.224170, loss_ce: 0.105870
2022-01-14 14:58:09,911 iteration 199 : loss : 0.182190, loss_ce: 0.085318
2022-01-14 14:58:11,391 iteration 200 : loss : 0.206390, loss_ce: 0.080750
2022-01-14 14:58:12,893 iteration 201 : loss : 0.248737, loss_ce: 0.105449
2022-01-14 14:58:14,265 iteration 202 : loss : 0.222050, loss_ce: 0.077989
2022-01-14 14:58:15,856 iteration 203 : loss : 0.152104, loss_ce: 0.065721
2022-01-14 14:58:17,355 iteration 204 : loss : 0.221422, loss_ce: 0.103819
  3%|▉                             | 12/400 [05:37<3:04:03, 28.46s/it]2022-01-14 14:58:19,015 iteration 205 : loss : 0.197885, loss_ce: 0.083178
2022-01-14 14:58:20,583 iteration 206 : loss : 0.325774, loss_ce: 0.139037
2022-01-14 14:58:22,188 iteration 207 : loss : 0.243395, loss_ce: 0.090286
2022-01-14 14:58:23,755 iteration 208 : loss : 0.180428, loss_ce: 0.088463
2022-01-14 14:58:25,305 iteration 209 : loss : 0.227314, loss_ce: 0.084787
2022-01-14 14:58:26,832 iteration 210 : loss : 0.202062, loss_ce: 0.095738
2022-01-14 14:58:28,375 iteration 211 : loss : 0.175062, loss_ce: 0.076894
2022-01-14 14:58:29,946 iteration 212 : loss : 0.175354, loss_ce: 0.072456
2022-01-14 14:58:31,521 iteration 213 : loss : 0.202693, loss_ce: 0.094310
2022-01-14 14:58:33,029 iteration 214 : loss : 0.238340, loss_ce: 0.100931
2022-01-14 14:58:34,491 iteration 215 : loss : 0.194043, loss_ce: 0.080109
2022-01-14 14:58:36,090 iteration 216 : loss : 0.176635, loss_ce: 0.065064
2022-01-14 14:58:37,723 iteration 217 : loss : 0.220269, loss_ce: 0.090773
2022-01-14 14:58:39,227 iteration 218 : loss : 0.200037, loss_ce: 0.087788
2022-01-14 14:58:40,716 iteration 219 : loss : 0.192733, loss_ce: 0.082802
2022-01-14 14:58:42,264 iteration 220 : loss : 0.177399, loss_ce: 0.072035
2022-01-14 14:58:43,791 iteration 221 : loss : 0.206584, loss_ce: 0.085524
  3%|▉                             | 13/400 [06:03<2:59:35, 27.84s/it]2022-01-14 14:58:45,351 iteration 222 : loss : 0.149904, loss_ce: 0.058693
2022-01-14 14:58:46,851 iteration 223 : loss : 0.247823, loss_ce: 0.112770
2022-01-14 14:58:48,343 iteration 224 : loss : 0.166213, loss_ce: 0.057905
2022-01-14 14:58:50,012 iteration 225 : loss : 0.138206, loss_ce: 0.060633
2022-01-14 14:58:51,611 iteration 226 : loss : 0.195716, loss_ce: 0.074818
2022-01-14 14:58:53,121 iteration 227 : loss : 0.156839, loss_ce: 0.062063
2022-01-14 14:58:54,631 iteration 228 : loss : 0.153813, loss_ce: 0.055091
2022-01-14 14:58:56,177 iteration 229 : loss : 0.209671, loss_ce: 0.075491
2022-01-14 14:58:57,643 iteration 230 : loss : 0.163512, loss_ce: 0.067266
2022-01-14 14:58:59,166 iteration 231 : loss : 0.163803, loss_ce: 0.064299
2022-01-14 14:59:00,689 iteration 232 : loss : 0.184620, loss_ce: 0.074075
2022-01-14 14:59:02,144 iteration 233 : loss : 0.178283, loss_ce: 0.084994
2022-01-14 14:59:03,668 iteration 234 : loss : 0.225686, loss_ce: 0.091992
2022-01-14 14:59:05,146 iteration 235 : loss : 0.173002, loss_ce: 0.068863
2022-01-14 14:59:06,655 iteration 236 : loss : 0.247558, loss_ce: 0.096841
2022-01-14 14:59:08,099 iteration 237 : loss : 0.259954, loss_ce: 0.140812
2022-01-14 14:59:09,631 iteration 238 : loss : 0.198106, loss_ce: 0.067639
  4%|█                             | 14/400 [06:29<2:55:15, 27.24s/it]2022-01-14 14:59:11,179 iteration 239 : loss : 0.190350, loss_ce: 0.072223
2022-01-14 14:59:12,793 iteration 240 : loss : 0.182465, loss_ce: 0.067354
2022-01-14 14:59:14,378 iteration 241 : loss : 0.171709, loss_ce: 0.073221
2022-01-14 14:59:15,866 iteration 242 : loss : 0.185782, loss_ce: 0.066762
2022-01-14 14:59:17,388 iteration 243 : loss : 0.143543, loss_ce: 0.053269
2022-01-14 14:59:18,883 iteration 244 : loss : 0.172037, loss_ce: 0.061044
2022-01-14 14:59:20,347 iteration 245 : loss : 0.201148, loss_ce: 0.069088
2022-01-14 14:59:21,842 iteration 246 : loss : 0.219556, loss_ce: 0.078817
2022-01-14 14:59:23,376 iteration 247 : loss : 0.182737, loss_ce: 0.086861
2022-01-14 14:59:24,929 iteration 248 : loss : 0.184990, loss_ce: 0.078901
2022-01-14 14:59:26,455 iteration 249 : loss : 0.164981, loss_ce: 0.069578
2022-01-14 14:59:27,947 iteration 250 : loss : 0.187046, loss_ce: 0.061282
2022-01-14 14:59:29,397 iteration 251 : loss : 0.158446, loss_ce: 0.070699
2022-01-14 14:59:31,007 iteration 252 : loss : 0.197157, loss_ce: 0.092051
2022-01-14 14:59:32,518 iteration 253 : loss : 0.136219, loss_ce: 0.049821
2022-01-14 14:59:34,018 iteration 254 : loss : 0.152962, loss_ce: 0.073559
2022-01-14 14:59:34,018 Training Data Eval:
2022-01-14 14:59:41,489   Average segmentation loss on training set: 0.3193
2022-01-14 14:59:41,490 Validation Data Eval:
2022-01-14 14:59:44,050   Average segmentation loss on validation set: 0.2866
2022-01-14 14:59:45,491 iteration 255 : loss : 0.170804, loss_ce: 0.079093
  4%|█▏                            | 15/400 [07:05<3:11:27, 29.84s/it]2022-01-14 14:59:46,978 iteration 256 : loss : 0.149497, loss_ce: 0.058431
2022-01-14 14:59:48,445 iteration 257 : loss : 0.156563, loss_ce: 0.068300
2022-01-14 14:59:49,998 iteration 258 : loss : 0.167095, loss_ce: 0.078413
2022-01-14 14:59:51,538 iteration 259 : loss : 0.205114, loss_ce: 0.095398
2022-01-14 14:59:53,041 iteration 260 : loss : 0.113041, loss_ce: 0.060232
2022-01-14 14:59:54,592 iteration 261 : loss : 0.179899, loss_ce: 0.072949
2022-01-14 14:59:56,181 iteration 262 : loss : 0.254721, loss_ce: 0.125122
2022-01-14 14:59:57,646 iteration 263 : loss : 0.139930, loss_ce: 0.058198
2022-01-14 14:59:59,209 iteration 264 : loss : 0.232126, loss_ce: 0.081227
2022-01-14 15:00:00,799 iteration 265 : loss : 0.230314, loss_ce: 0.116258
2022-01-14 15:00:02,333 iteration 266 : loss : 0.198129, loss_ce: 0.080534
2022-01-14 15:00:03,956 iteration 267 : loss : 0.140800, loss_ce: 0.044615
2022-01-14 15:00:05,495 iteration 268 : loss : 0.206850, loss_ce: 0.084588
2022-01-14 15:00:07,043 iteration 269 : loss : 0.248571, loss_ce: 0.111239
2022-01-14 15:00:08,563 iteration 270 : loss : 0.183103, loss_ce: 0.056740
2022-01-14 15:00:10,063 iteration 271 : loss : 0.142387, loss_ce: 0.058473
2022-01-14 15:00:11,533 iteration 272 : loss : 0.163070, loss_ce: 0.058773
  4%|█▏                            | 16/400 [07:31<3:03:39, 28.70s/it]2022-01-14 15:00:13,131 iteration 273 : loss : 0.152134, loss_ce: 0.062764
2022-01-14 15:00:14,644 iteration 274 : loss : 0.250282, loss_ce: 0.108123
2022-01-14 15:00:16,132 iteration 275 : loss : 0.222316, loss_ce: 0.060952
2022-01-14 15:00:17,607 iteration 276 : loss : 0.139507, loss_ce: 0.059492
2022-01-14 15:00:19,081 iteration 277 : loss : 0.155756, loss_ce: 0.058027
2022-01-14 15:00:20,581 iteration 278 : loss : 0.182300, loss_ce: 0.075890
2022-01-14 15:00:22,053 iteration 279 : loss : 0.194906, loss_ce: 0.078178
2022-01-14 15:00:23,555 iteration 280 : loss : 0.167583, loss_ce: 0.080413
2022-01-14 15:00:25,118 iteration 281 : loss : 0.157031, loss_ce: 0.073156
2022-01-14 15:00:26,657 iteration 282 : loss : 0.128416, loss_ce: 0.050017
2022-01-14 15:00:28,145 iteration 283 : loss : 0.131562, loss_ce: 0.053709
2022-01-14 15:00:29,670 iteration 284 : loss : 0.134860, loss_ce: 0.072939
2022-01-14 15:00:31,220 iteration 285 : loss : 0.144587, loss_ce: 0.047042
2022-01-14 15:00:32,619 iteration 286 : loss : 0.176232, loss_ce: 0.069232
2022-01-14 15:00:34,106 iteration 287 : loss : 0.152917, loss_ce: 0.058339
2022-01-14 15:00:35,656 iteration 288 : loss : 0.124142, loss_ce: 0.046735
2022-01-14 15:00:37,144 iteration 289 : loss : 0.129880, loss_ce: 0.045130
  4%|█▎                            | 17/400 [07:57<2:57:15, 27.77s/it]2022-01-14 15:00:38,730 iteration 290 : loss : 0.146537, loss_ce: 0.059478
2022-01-14 15:00:40,210 iteration 291 : loss : 0.143830, loss_ce: 0.049623
2022-01-14 15:00:41,660 iteration 292 : loss : 0.143701, loss_ce: 0.065495
2022-01-14 15:00:43,206 iteration 293 : loss : 0.132674, loss_ce: 0.049930
2022-01-14 15:00:44,718 iteration 294 : loss : 0.095281, loss_ce: 0.043869
2022-01-14 15:00:46,289 iteration 295 : loss : 0.139415, loss_ce: 0.060783
2022-01-14 15:00:47,854 iteration 296 : loss : 0.189146, loss_ce: 0.073091
2022-01-14 15:00:49,403 iteration 297 : loss : 0.156324, loss_ce: 0.071328
2022-01-14 15:00:50,888 iteration 298 : loss : 0.137576, loss_ce: 0.066092
2022-01-14 15:00:52,311 iteration 299 : loss : 0.168055, loss_ce: 0.065156
2022-01-14 15:00:53,787 iteration 300 : loss : 0.132367, loss_ce: 0.051777
2022-01-14 15:00:55,210 iteration 301 : loss : 0.163484, loss_ce: 0.060477
2022-01-14 15:00:56,785 iteration 302 : loss : 0.135959, loss_ce: 0.049696
2022-01-14 15:00:58,350 iteration 303 : loss : 0.120474, loss_ce: 0.035247
2022-01-14 15:00:59,917 iteration 304 : loss : 0.172777, loss_ce: 0.074080
2022-01-14 15:01:01,395 iteration 305 : loss : 0.138575, loss_ce: 0.053896
2022-01-14 15:01:02,885 iteration 306 : loss : 0.131129, loss_ce: 0.040313
  4%|█▎                            | 18/400 [08:22<2:52:55, 27.16s/it]2022-01-14 15:01:04,357 iteration 307 : loss : 0.221938, loss_ce: 0.091041
2022-01-14 15:01:05,778 iteration 308 : loss : 0.123133, loss_ce: 0.043960
2022-01-14 15:01:07,232 iteration 309 : loss : 0.159912, loss_ce: 0.074120
2022-01-14 15:01:08,751 iteration 310 : loss : 0.142383, loss_ce: 0.058910
2022-01-14 15:01:10,280 iteration 311 : loss : 0.122230, loss_ce: 0.049105
2022-01-14 15:01:11,829 iteration 312 : loss : 0.104166, loss_ce: 0.043057
2022-01-14 15:01:13,308 iteration 313 : loss : 0.134955, loss_ce: 0.056420
2022-01-14 15:01:14,828 iteration 314 : loss : 0.136129, loss_ce: 0.063604
2022-01-14 15:01:16,393 iteration 315 : loss : 0.143032, loss_ce: 0.056288
2022-01-14 15:01:17,903 iteration 316 : loss : 0.137303, loss_ce: 0.050797
2022-01-14 15:01:19,346 iteration 317 : loss : 0.150581, loss_ce: 0.053547
2022-01-14 15:01:20,831 iteration 318 : loss : 0.131160, loss_ce: 0.051265
2022-01-14 15:01:22,410 iteration 319 : loss : 0.129861, loss_ce: 0.055471
2022-01-14 15:01:23,886 iteration 320 : loss : 0.130442, loss_ce: 0.044678
2022-01-14 15:01:25,307 iteration 321 : loss : 0.113728, loss_ce: 0.059017
2022-01-14 15:01:26,820 iteration 322 : loss : 0.129039, loss_ce: 0.047881
2022-01-14 15:01:28,357 iteration 323 : loss : 0.131283, loss_ce: 0.051952
  5%|█▍                            | 19/400 [08:48<2:49:15, 26.65s/it]2022-01-14 15:01:29,822 iteration 324 : loss : 0.161349, loss_ce: 0.068696
2022-01-14 15:01:31,307 iteration 325 : loss : 0.129205, loss_ce: 0.045341
2022-01-14 15:01:32,804 iteration 326 : loss : 0.117027, loss_ce: 0.041915
2022-01-14 15:01:34,431 iteration 327 : loss : 0.149436, loss_ce: 0.055989
2022-01-14 15:01:35,980 iteration 328 : loss : 0.127485, loss_ce: 0.052319
2022-01-14 15:01:37,493 iteration 329 : loss : 0.125820, loss_ce: 0.046400
2022-01-14 15:01:38,908 iteration 330 : loss : 0.116148, loss_ce: 0.043749
2022-01-14 15:01:40,506 iteration 331 : loss : 0.107893, loss_ce: 0.039489
2022-01-14 15:01:42,046 iteration 332 : loss : 0.105392, loss_ce: 0.046064
2022-01-14 15:01:43,513 iteration 333 : loss : 0.098112, loss_ce: 0.037814
2022-01-14 15:01:45,049 iteration 334 : loss : 0.120757, loss_ce: 0.054274
2022-01-14 15:01:46,553 iteration 335 : loss : 0.160968, loss_ce: 0.056001
2022-01-14 15:01:48,101 iteration 336 : loss : 0.115541, loss_ce: 0.048021
2022-01-14 15:01:49,585 iteration 337 : loss : 0.125496, loss_ce: 0.051812
2022-01-14 15:01:50,997 iteration 338 : loss : 0.137938, loss_ce: 0.061715
2022-01-14 15:01:52,505 iteration 339 : loss : 0.104063, loss_ce: 0.036666
2022-01-14 15:01:52,506 Training Data Eval:
2022-01-14 15:01:59,970   Average segmentation loss on training set: 0.3234
2022-01-14 15:01:59,970 Validation Data Eval:
2022-01-14 15:02:02,535   Average segmentation loss on validation set: 0.3878
2022-01-14 15:02:04,015 iteration 340 : loss : 0.123975, loss_ce: 0.044338
  5%|█▌                            | 20/400 [09:24<3:05:54, 29.35s/it]2022-01-14 15:02:05,627 iteration 341 : loss : 0.114492, loss_ce: 0.047927
2022-01-14 15:02:07,239 iteration 342 : loss : 0.095527, loss_ce: 0.035463
2022-01-14 15:02:08,876 iteration 343 : loss : 0.139772, loss_ce: 0.076140
2022-01-14 15:02:10,373 iteration 344 : loss : 0.168588, loss_ce: 0.056087
2022-01-14 15:02:11,908 iteration 345 : loss : 0.133619, loss_ce: 0.053826
2022-01-14 15:02:13,485 iteration 346 : loss : 0.103961, loss_ce: 0.040979
2022-01-14 15:02:14,958 iteration 347 : loss : 0.101898, loss_ce: 0.043809
2022-01-14 15:02:16,588 iteration 348 : loss : 0.145531, loss_ce: 0.050125
2022-01-14 15:02:18,089 iteration 349 : loss : 0.114115, loss_ce: 0.045856
2022-01-14 15:02:19,518 iteration 350 : loss : 0.102528, loss_ce: 0.035111
2022-01-14 15:02:21,084 iteration 351 : loss : 0.124815, loss_ce: 0.036780
2022-01-14 15:02:22,595 iteration 352 : loss : 0.119733, loss_ce: 0.041454
2022-01-14 15:02:24,204 iteration 353 : loss : 0.120015, loss_ce: 0.039704
2022-01-14 15:02:25,717 iteration 354 : loss : 0.150154, loss_ce: 0.061834
2022-01-14 15:02:27,319 iteration 355 : loss : 0.143762, loss_ce: 0.058304
2022-01-14 15:02:28,785 iteration 356 : loss : 0.157997, loss_ce: 0.057510
2022-01-14 15:02:30,282 iteration 357 : loss : 0.181486, loss_ce: 0.081138
  5%|█▌                            | 21/400 [09:50<2:59:35, 28.43s/it]2022-01-14 15:02:31,933 iteration 358 : loss : 0.137407, loss_ce: 0.054496
2022-01-14 15:02:33,521 iteration 359 : loss : 0.098139, loss_ce: 0.046246
2022-01-14 15:02:35,064 iteration 360 : loss : 0.205236, loss_ce: 0.059150
2022-01-14 15:02:36,643 iteration 361 : loss : 0.157199, loss_ce: 0.053205
2022-01-14 15:02:38,047 iteration 362 : loss : 0.130817, loss_ce: 0.049587
2022-01-14 15:02:39,645 iteration 363 : loss : 0.160397, loss_ce: 0.080462
2022-01-14 15:02:41,191 iteration 364 : loss : 0.154446, loss_ce: 0.079492
2022-01-14 15:02:42,687 iteration 365 : loss : 0.098952, loss_ce: 0.035570
2022-01-14 15:02:44,176 iteration 366 : loss : 0.117113, loss_ce: 0.050118
2022-01-14 15:02:45,715 iteration 367 : loss : 0.124616, loss_ce: 0.055381
2022-01-14 15:02:47,167 iteration 368 : loss : 0.130982, loss_ce: 0.038458
2022-01-14 15:02:48,717 iteration 369 : loss : 0.114430, loss_ce: 0.050121
2022-01-14 15:02:50,162 iteration 370 : loss : 0.149125, loss_ce: 0.046862
2022-01-14 15:02:51,765 iteration 371 : loss : 0.125387, loss_ce: 0.064477
2022-01-14 15:02:53,333 iteration 372 : loss : 0.135244, loss_ce: 0.046417
2022-01-14 15:02:54,883 iteration 373 : loss : 0.119328, loss_ce: 0.040292
2022-01-14 15:02:56,387 iteration 374 : loss : 0.106772, loss_ce: 0.041216
  6%|█▋                            | 22/400 [10:16<2:54:42, 27.73s/it]2022-01-14 15:02:57,977 iteration 375 : loss : 0.118876, loss_ce: 0.050375
2022-01-14 15:02:59,502 iteration 376 : loss : 0.122444, loss_ce: 0.048337
2022-01-14 15:03:01,100 iteration 377 : loss : 0.171985, loss_ce: 0.054133
2022-01-14 15:03:02,652 iteration 378 : loss : 0.118648, loss_ce: 0.050647
2022-01-14 15:03:04,092 iteration 379 : loss : 0.136919, loss_ce: 0.050631
2022-01-14 15:03:05,627 iteration 380 : loss : 0.101424, loss_ce: 0.048677
2022-01-14 15:03:07,075 iteration 381 : loss : 0.092820, loss_ce: 0.034751
2022-01-14 15:03:08,690 iteration 382 : loss : 0.103004, loss_ce: 0.038977
2022-01-14 15:03:10,249 iteration 383 : loss : 0.124748, loss_ce: 0.048687
2022-01-14 15:03:11,762 iteration 384 : loss : 0.086659, loss_ce: 0.032808
2022-01-14 15:03:13,227 iteration 385 : loss : 0.109228, loss_ce: 0.045400
2022-01-14 15:03:14,797 iteration 386 : loss : 0.115209, loss_ce: 0.050004
2022-01-14 15:03:16,322 iteration 387 : loss : 0.113122, loss_ce: 0.039949
2022-01-14 15:03:17,911 iteration 388 : loss : 0.103296, loss_ce: 0.045883
2022-01-14 15:03:19,434 iteration 389 : loss : 0.120415, loss_ce: 0.040241
2022-01-14 15:03:20,993 iteration 390 : loss : 0.122995, loss_ce: 0.063393
2022-01-14 15:03:22,463 iteration 391 : loss : 0.109483, loss_ce: 0.034202
  6%|█▋                            | 23/400 [10:42<2:51:07, 27.23s/it]2022-01-14 15:03:24,147 iteration 392 : loss : 0.098297, loss_ce: 0.042201
2022-01-14 15:03:25,599 iteration 393 : loss : 0.133312, loss_ce: 0.057758
2022-01-14 15:03:27,137 iteration 394 : loss : 0.140473, loss_ce: 0.050783
2022-01-14 15:03:28,654 iteration 395 : loss : 0.121384, loss_ce: 0.053191
2022-01-14 15:03:30,247 iteration 396 : loss : 0.111509, loss_ce: 0.042212
2022-01-14 15:03:31,801 iteration 397 : loss : 0.100924, loss_ce: 0.038887
2022-01-14 15:03:33,335 iteration 398 : loss : 0.094199, loss_ce: 0.040597
2022-01-14 15:03:34,852 iteration 399 : loss : 0.066748, loss_ce: 0.022759
2022-01-14 15:03:36,443 iteration 400 : loss : 0.106000, loss_ce: 0.044229
2022-01-14 15:03:37,865 iteration 401 : loss : 0.121015, loss_ce: 0.035741
2022-01-14 15:03:39,442 iteration 402 : loss : 0.145352, loss_ce: 0.062000
2022-01-14 15:03:41,052 iteration 403 : loss : 0.093940, loss_ce: 0.037538
2022-01-14 15:03:42,566 iteration 404 : loss : 0.088707, loss_ce: 0.026951
2022-01-14 15:03:44,109 iteration 405 : loss : 0.125469, loss_ce: 0.040125
2022-01-14 15:03:45,603 iteration 406 : loss : 0.091907, loss_ce: 0.043916
2022-01-14 15:03:47,055 iteration 407 : loss : 0.090364, loss_ce: 0.034444
2022-01-14 15:03:48,515 iteration 408 : loss : 0.100057, loss_ce: 0.032445
  6%|█▊                            | 24/400 [11:08<2:48:26, 26.88s/it]2022-01-14 15:03:50,240 iteration 409 : loss : 0.090763, loss_ce: 0.032520
2022-01-14 15:03:51,734 iteration 410 : loss : 0.097750, loss_ce: 0.037009
2022-01-14 15:03:53,273 iteration 411 : loss : 0.100804, loss_ce: 0.036860
2022-01-14 15:03:54,790 iteration 412 : loss : 0.111746, loss_ce: 0.044634
2022-01-14 15:03:56,306 iteration 413 : loss : 0.114208, loss_ce: 0.046890
2022-01-14 15:03:57,842 iteration 414 : loss : 0.103266, loss_ce: 0.045617
2022-01-14 15:03:59,406 iteration 415 : loss : 0.115589, loss_ce: 0.061913
2022-01-14 15:04:00,791 iteration 416 : loss : 0.100606, loss_ce: 0.036991
2022-01-14 15:04:02,301 iteration 417 : loss : 0.145673, loss_ce: 0.046056
2022-01-14 15:04:03,836 iteration 418 : loss : 0.071519, loss_ce: 0.025678
2022-01-14 15:04:05,335 iteration 419 : loss : 0.157261, loss_ce: 0.055106
2022-01-14 15:04:06,861 iteration 420 : loss : 0.077589, loss_ce: 0.028239
2022-01-14 15:04:08,278 iteration 421 : loss : 0.109896, loss_ce: 0.030433
2022-01-14 15:04:09,837 iteration 422 : loss : 0.113638, loss_ce: 0.046524
2022-01-14 15:04:11,314 iteration 423 : loss : 0.096805, loss_ce: 0.034353
2022-01-14 15:04:12,809 iteration 424 : loss : 0.108230, loss_ce: 0.046951
2022-01-14 15:04:12,810 Training Data Eval:
2022-01-14 15:04:20,258   Average segmentation loss on training set: 0.1616
2022-01-14 15:04:20,259 Validation Data Eval:
2022-01-14 15:04:22,816   Average segmentation loss on validation set: 0.2466
2022-01-14 15:04:24,423 iteration 425 : loss : 0.145096, loss_ce: 0.056443
  6%|█▉                            | 25/400 [11:44<3:04:55, 29.59s/it]2022-01-14 15:04:26,030 iteration 426 : loss : 0.119771, loss_ce: 0.045333
2022-01-14 15:04:27,500 iteration 427 : loss : 0.128292, loss_ce: 0.057760
2022-01-14 15:04:29,109 iteration 428 : loss : 0.091977, loss_ce: 0.044409
2022-01-14 15:04:30,590 iteration 429 : loss : 0.119397, loss_ce: 0.047434
2022-01-14 15:04:32,044 iteration 430 : loss : 0.106773, loss_ce: 0.051968
2022-01-14 15:04:33,589 iteration 431 : loss : 0.092512, loss_ce: 0.044672
2022-01-14 15:04:35,126 iteration 432 : loss : 0.140828, loss_ce: 0.061291
2022-01-14 15:04:36,556 iteration 433 : loss : 0.119774, loss_ce: 0.050869
2022-01-14 15:04:38,027 iteration 434 : loss : 0.096502, loss_ce: 0.033850
2022-01-14 15:04:39,549 iteration 435 : loss : 0.100170, loss_ce: 0.037631
2022-01-14 15:04:41,116 iteration 436 : loss : 0.132437, loss_ce: 0.036300
2022-01-14 15:04:42,576 iteration 437 : loss : 0.117502, loss_ce: 0.048518
2022-01-14 15:04:44,063 iteration 438 : loss : 0.098871, loss_ce: 0.036847
2022-01-14 15:04:45,549 iteration 439 : loss : 0.110470, loss_ce: 0.046357
2022-01-14 15:04:47,209 iteration 440 : loss : 0.137647, loss_ce: 0.059681
2022-01-14 15:04:48,668 iteration 441 : loss : 0.079893, loss_ce: 0.034833
2022-01-14 15:04:50,118 iteration 442 : loss : 0.108198, loss_ce: 0.038415
  6%|█▉                            | 26/400 [12:10<2:57:09, 28.42s/it]2022-01-14 15:04:51,727 iteration 443 : loss : 0.072544, loss_ce: 0.029203
2022-01-14 15:04:53,179 iteration 444 : loss : 0.085218, loss_ce: 0.030236
2022-01-14 15:04:54,613 iteration 445 : loss : 0.090781, loss_ce: 0.035757
2022-01-14 15:04:56,097 iteration 446 : loss : 0.107862, loss_ce: 0.036072
2022-01-14 15:04:57,665 iteration 447 : loss : 0.090217, loss_ce: 0.033723
2022-01-14 15:04:59,088 iteration 448 : loss : 0.112010, loss_ce: 0.037644
2022-01-14 15:05:00,563 iteration 449 : loss : 0.105480, loss_ce: 0.033580
2022-01-14 15:05:02,007 iteration 450 : loss : 0.133745, loss_ce: 0.067780
2022-01-14 15:05:03,541 iteration 451 : loss : 0.136655, loss_ce: 0.054501
2022-01-14 15:05:05,056 iteration 452 : loss : 0.093440, loss_ce: 0.029680
2022-01-14 15:05:06,535 iteration 453 : loss : 0.117629, loss_ce: 0.054433
2022-01-14 15:05:08,155 iteration 454 : loss : 0.106283, loss_ce: 0.046223
2022-01-14 15:05:09,685 iteration 455 : loss : 0.105380, loss_ce: 0.045005
2022-01-14 15:05:11,157 iteration 456 : loss : 0.088374, loss_ce: 0.035570
2022-01-14 15:05:12,642 iteration 457 : loss : 0.099298, loss_ce: 0.051289
2022-01-14 15:05:14,096 iteration 458 : loss : 0.100497, loss_ce: 0.050872
2022-01-14 15:05:15,621 iteration 459 : loss : 0.126739, loss_ce: 0.060159
  7%|██                            | 27/400 [12:35<2:51:13, 27.54s/it]2022-01-14 15:05:17,115 iteration 460 : loss : 0.094190, loss_ce: 0.046379
2022-01-14 15:05:18,583 iteration 461 : loss : 0.086913, loss_ce: 0.037596
2022-01-14 15:05:20,149 iteration 462 : loss : 0.150973, loss_ce: 0.057555
2022-01-14 15:05:21,689 iteration 463 : loss : 0.099412, loss_ce: 0.033669
2022-01-14 15:05:23,372 iteration 464 : loss : 0.178097, loss_ce: 0.055545
2022-01-14 15:05:24,897 iteration 465 : loss : 0.123969, loss_ce: 0.052069
2022-01-14 15:05:26,368 iteration 466 : loss : 0.103233, loss_ce: 0.040466
2022-01-14 15:05:27,885 iteration 467 : loss : 0.109891, loss_ce: 0.040833
2022-01-14 15:05:29,370 iteration 468 : loss : 0.089032, loss_ce: 0.033683
2022-01-14 15:05:30,952 iteration 469 : loss : 0.108228, loss_ce: 0.048946
2022-01-14 15:05:32,477 iteration 470 : loss : 0.071864, loss_ce: 0.028036
2022-01-14 15:05:34,004 iteration 471 : loss : 0.164254, loss_ce: 0.086809
2022-01-14 15:05:35,562 iteration 472 : loss : 0.055172, loss_ce: 0.022610
2022-01-14 15:05:37,102 iteration 473 : loss : 0.091080, loss_ce: 0.042431
2022-01-14 15:05:38,576 iteration 474 : loss : 0.146191, loss_ce: 0.047944
2022-01-14 15:05:40,057 iteration 475 : loss : 0.125215, loss_ce: 0.042543
2022-01-14 15:05:41,673 iteration 476 : loss : 0.076628, loss_ce: 0.027899
  7%|██                            | 28/400 [13:01<2:47:59, 27.10s/it]2022-01-14 15:05:43,192 iteration 477 : loss : 0.066309, loss_ce: 0.027867
2022-01-14 15:05:44,629 iteration 478 : loss : 0.080710, loss_ce: 0.036700
2022-01-14 15:05:46,195 iteration 479 : loss : 0.097423, loss_ce: 0.034396
2022-01-14 15:05:47,712 iteration 480 : loss : 0.125265, loss_ce: 0.041282
2022-01-14 15:05:49,162 iteration 481 : loss : 0.096479, loss_ce: 0.030402
2022-01-14 15:05:50,758 iteration 482 : loss : 0.112839, loss_ce: 0.049706
2022-01-14 15:05:52,192 iteration 483 : loss : 0.137887, loss_ce: 0.066627
2022-01-14 15:05:53,699 iteration 484 : loss : 0.107406, loss_ce: 0.037925
2022-01-14 15:05:55,228 iteration 485 : loss : 0.099959, loss_ce: 0.043049
2022-01-14 15:05:56,818 iteration 486 : loss : 0.080656, loss_ce: 0.029479
2022-01-14 15:05:58,333 iteration 487 : loss : 0.138918, loss_ce: 0.046382
2022-01-14 15:05:59,741 iteration 488 : loss : 0.105375, loss_ce: 0.041516
2022-01-14 15:06:01,295 iteration 489 : loss : 0.106415, loss_ce: 0.047100
2022-01-14 15:06:02,817 iteration 490 : loss : 0.105568, loss_ce: 0.054429
2022-01-14 15:06:04,384 iteration 491 : loss : 0.152673, loss_ce: 0.054195
2022-01-14 15:06:05,860 iteration 492 : loss : 0.088008, loss_ce: 0.047488
2022-01-14 15:06:07,311 iteration 493 : loss : 0.084246, loss_ce: 0.036656
  7%|██▏                           | 29/400 [13:27<2:44:51, 26.66s/it]2022-01-14 15:06:08,869 iteration 494 : loss : 0.127456, loss_ce: 0.053793
2022-01-14 15:06:10,311 iteration 495 : loss : 0.124133, loss_ce: 0.046184
2022-01-14 15:06:11,812 iteration 496 : loss : 0.096074, loss_ce: 0.032242
2022-01-14 15:06:13,408 iteration 497 : loss : 0.088141, loss_ce: 0.040114
2022-01-14 15:06:15,009 iteration 498 : loss : 0.127449, loss_ce: 0.084433
2022-01-14 15:06:16,545 iteration 499 : loss : 0.112042, loss_ce: 0.037600
2022-01-14 15:06:18,192 iteration 500 : loss : 0.100756, loss_ce: 0.042786
2022-01-14 15:06:19,693 iteration 501 : loss : 0.105430, loss_ce: 0.038488
2022-01-14 15:06:21,154 iteration 502 : loss : 0.103841, loss_ce: 0.045048
2022-01-14 15:06:22,776 iteration 503 : loss : 0.115219, loss_ce: 0.032053
2022-01-14 15:06:24,418 iteration 504 : loss : 0.094243, loss_ce: 0.031335
2022-01-14 15:06:25,870 iteration 505 : loss : 0.090780, loss_ce: 0.033326
2022-01-14 15:06:27,407 iteration 506 : loss : 0.096497, loss_ce: 0.036852
2022-01-14 15:06:28,999 iteration 507 : loss : 0.072426, loss_ce: 0.028698
2022-01-14 15:06:30,498 iteration 508 : loss : 0.071446, loss_ce: 0.029821
2022-01-14 15:06:32,047 iteration 509 : loss : 0.091290, loss_ce: 0.039362
2022-01-14 15:06:32,047 Training Data Eval:
2022-01-14 15:06:39,555   Average segmentation loss on training set: 0.0801
2022-01-14 15:06:39,556 Validation Data Eval:
2022-01-14 15:06:42,120   Average segmentation loss on validation set: 0.1276
2022-01-14 15:06:48,070 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed100.pth
2022-01-14 15:06:49,383 iteration 510 : loss : 0.087678, loss_ce: 0.034246
  8%|██▎                           | 30/400 [14:09<3:12:54, 31.28s/it]2022-01-14 15:06:50,687 iteration 511 : loss : 0.064881, loss_ce: 0.029016
2022-01-14 15:06:52,275 iteration 512 : loss : 0.153396, loss_ce: 0.062968
2022-01-14 15:06:53,604 iteration 513 : loss : 0.117118, loss_ce: 0.062465
2022-01-14 15:06:55,049 iteration 514 : loss : 0.107843, loss_ce: 0.036996
2022-01-14 15:06:56,442 iteration 515 : loss : 0.064701, loss_ce: 0.028385
2022-01-14 15:06:57,749 iteration 516 : loss : 0.065943, loss_ce: 0.031172
2022-01-14 15:06:59,336 iteration 517 : loss : 0.092946, loss_ce: 0.033871
2022-01-14 15:07:00,790 iteration 518 : loss : 0.144853, loss_ce: 0.073141
2022-01-14 15:07:02,177 iteration 519 : loss : 0.081101, loss_ce: 0.028231
2022-01-14 15:07:03,589 iteration 520 : loss : 0.100881, loss_ce: 0.046093
2022-01-14 15:07:05,180 iteration 521 : loss : 0.178984, loss_ce: 0.038419
2022-01-14 15:07:06,672 iteration 522 : loss : 0.077172, loss_ce: 0.026323
2022-01-14 15:07:08,240 iteration 523 : loss : 0.077606, loss_ce: 0.032951
2022-01-14 15:07:09,628 iteration 524 : loss : 0.087058, loss_ce: 0.037435
2022-01-14 15:07:11,128 iteration 525 : loss : 0.080748, loss_ce: 0.033914
2022-01-14 15:07:12,676 iteration 526 : loss : 0.100777, loss_ce: 0.035233
2022-01-14 15:07:14,162 iteration 527 : loss : 0.103003, loss_ce: 0.041364
  8%|██▎                           | 31/400 [14:34<3:00:24, 29.33s/it]2022-01-14 15:07:15,783 iteration 528 : loss : 0.067336, loss_ce: 0.025634
2022-01-14 15:07:17,306 iteration 529 : loss : 0.101033, loss_ce: 0.060549
2022-01-14 15:07:18,765 iteration 530 : loss : 0.057940, loss_ce: 0.025688
2022-01-14 15:07:20,330 iteration 531 : loss : 0.158138, loss_ce: 0.060019
2022-01-14 15:07:21,791 iteration 532 : loss : 0.124207, loss_ce: 0.038893
2022-01-14 15:07:23,345 iteration 533 : loss : 0.062088, loss_ce: 0.028548
2022-01-14 15:07:24,909 iteration 534 : loss : 0.123960, loss_ce: 0.071448
2022-01-14 15:07:26,435 iteration 535 : loss : 0.096767, loss_ce: 0.038070
2022-01-14 15:07:27,888 iteration 536 : loss : 0.094963, loss_ce: 0.052804
2022-01-14 15:07:29,421 iteration 537 : loss : 0.104180, loss_ce: 0.048448
2022-01-14 15:07:30,896 iteration 538 : loss : 0.062138, loss_ce: 0.024024
2022-01-14 15:07:32,376 iteration 539 : loss : 0.124386, loss_ce: 0.041507
2022-01-14 15:07:33,838 iteration 540 : loss : 0.080119, loss_ce: 0.035182
2022-01-14 15:07:35,331 iteration 541 : loss : 0.088503, loss_ce: 0.042314
2022-01-14 15:07:36,775 iteration 542 : loss : 0.082643, loss_ce: 0.030722
2022-01-14 15:07:38,249 iteration 543 : loss : 0.128168, loss_ce: 0.038588
2022-01-14 15:07:39,738 iteration 544 : loss : 0.094504, loss_ce: 0.031625
  8%|██▍                           | 32/400 [14:59<2:53:00, 28.21s/it]2022-01-14 15:07:41,259 iteration 545 : loss : 0.118987, loss_ce: 0.047415
2022-01-14 15:07:42,766 iteration 546 : loss : 0.098554, loss_ce: 0.033675
2022-01-14 15:07:44,298 iteration 547 : loss : 0.101763, loss_ce: 0.039644
2022-01-14 15:07:45,725 iteration 548 : loss : 0.094127, loss_ce: 0.035116
2022-01-14 15:07:47,245 iteration 549 : loss : 0.110936, loss_ce: 0.046663
2022-01-14 15:07:48,883 iteration 550 : loss : 0.115117, loss_ce: 0.047441
2022-01-14 15:07:50,424 iteration 551 : loss : 0.091487, loss_ce: 0.029386
2022-01-14 15:07:51,946 iteration 552 : loss : 0.099019, loss_ce: 0.047113
2022-01-14 15:07:53,520 iteration 553 : loss : 0.095767, loss_ce: 0.041988
2022-01-14 15:07:54,981 iteration 554 : loss : 0.073932, loss_ce: 0.029574
2022-01-14 15:07:56,521 iteration 555 : loss : 0.078619, loss_ce: 0.036084
2022-01-14 15:07:58,126 iteration 556 : loss : 0.106026, loss_ce: 0.043935
2022-01-14 15:07:59,631 iteration 557 : loss : 0.099502, loss_ce: 0.047195
2022-01-14 15:08:01,123 iteration 558 : loss : 0.109444, loss_ce: 0.040579
2022-01-14 15:08:02,640 iteration 559 : loss : 0.098269, loss_ce: 0.041026
2022-01-14 15:08:04,174 iteration 560 : loss : 0.100886, loss_ce: 0.040951
2022-01-14 15:08:05,622 iteration 561 : loss : 0.115702, loss_ce: 0.031779
  8%|██▍                           | 33/400 [15:25<2:48:16, 27.51s/it]2022-01-14 15:08:07,159 iteration 562 : loss : 0.088268, loss_ce: 0.037296
2022-01-14 15:08:08,715 iteration 563 : loss : 0.096520, loss_ce: 0.043376
2022-01-14 15:08:10,299 iteration 564 : loss : 0.087551, loss_ce: 0.039919
2022-01-14 15:08:11,839 iteration 565 : loss : 0.087135, loss_ce: 0.040766
2022-01-14 15:08:13,281 iteration 566 : loss : 0.071863, loss_ce: 0.028064
2022-01-14 15:08:14,854 iteration 567 : loss : 0.103803, loss_ce: 0.037723
2022-01-14 15:08:16,339 iteration 568 : loss : 0.114452, loss_ce: 0.045042
2022-01-14 15:08:17,825 iteration 569 : loss : 0.075704, loss_ce: 0.028067
2022-01-14 15:08:19,431 iteration 570 : loss : 0.116940, loss_ce: 0.041342
2022-01-14 15:08:20,997 iteration 571 : loss : 0.080629, loss_ce: 0.029846
2022-01-14 15:08:22,527 iteration 572 : loss : 0.086509, loss_ce: 0.030879
2022-01-14 15:08:24,002 iteration 573 : loss : 0.073301, loss_ce: 0.030063
2022-01-14 15:08:25,507 iteration 574 : loss : 0.090085, loss_ce: 0.036887
2022-01-14 15:08:27,073 iteration 575 : loss : 0.098668, loss_ce: 0.037843
2022-01-14 15:08:28,612 iteration 576 : loss : 0.092189, loss_ce: 0.047725
2022-01-14 15:08:30,155 iteration 577 : loss : 0.119514, loss_ce: 0.036026
2022-01-14 15:08:31,680 iteration 578 : loss : 0.082191, loss_ce: 0.031047
  8%|██▌                           | 34/400 [15:51<2:45:08, 27.07s/it]2022-01-14 15:08:33,217 iteration 579 : loss : 0.060578, loss_ce: 0.019446
2022-01-14 15:08:34,694 iteration 580 : loss : 0.064780, loss_ce: 0.027345
2022-01-14 15:08:36,207 iteration 581 : loss : 0.081236, loss_ce: 0.033324
2022-01-14 15:08:37,737 iteration 582 : loss : 0.068353, loss_ce: 0.025139
2022-01-14 15:08:39,202 iteration 583 : loss : 0.093810, loss_ce: 0.043274
2022-01-14 15:08:40,604 iteration 584 : loss : 0.066575, loss_ce: 0.027672
2022-01-14 15:08:42,082 iteration 585 : loss : 0.064894, loss_ce: 0.022615
2022-01-14 15:08:43,633 iteration 586 : loss : 0.069518, loss_ce: 0.030759
2022-01-14 15:08:45,110 iteration 587 : loss : 0.062673, loss_ce: 0.024118
2022-01-14 15:08:46,665 iteration 588 : loss : 0.096823, loss_ce: 0.034558
2022-01-14 15:08:48,143 iteration 589 : loss : 0.065812, loss_ce: 0.026282
2022-01-14 15:08:49,617 iteration 590 : loss : 0.089231, loss_ce: 0.048417
2022-01-14 15:08:51,102 iteration 591 : loss : 0.064845, loss_ce: 0.026466
2022-01-14 15:08:52,607 iteration 592 : loss : 0.085130, loss_ce: 0.033675
2022-01-14 15:08:54,170 iteration 593 : loss : 0.066480, loss_ce: 0.027715
2022-01-14 15:08:55,757 iteration 594 : loss : 0.069509, loss_ce: 0.033365
2022-01-14 15:08:55,757 Training Data Eval:
2022-01-14 15:09:03,226   Average segmentation loss on training set: 0.1783
2022-01-14 15:09:03,227 Validation Data Eval:
2022-01-14 15:09:05,789   Average segmentation loss on validation set: 0.3381
2022-01-14 15:09:07,346 iteration 595 : loss : 0.084828, loss_ce: 0.029905
  9%|██▋                           | 35/400 [16:27<3:00:23, 29.65s/it]2022-01-14 15:09:08,853 iteration 596 : loss : 0.057147, loss_ce: 0.025130
2022-01-14 15:09:10,384 iteration 597 : loss : 0.083346, loss_ce: 0.036945
2022-01-14 15:09:11,931 iteration 598 : loss : 0.074732, loss_ce: 0.033517
2022-01-14 15:09:13,486 iteration 599 : loss : 0.058278, loss_ce: 0.022145
2022-01-14 15:09:14,922 iteration 600 : loss : 0.057430, loss_ce: 0.027391
2022-01-14 15:09:16,450 iteration 601 : loss : 0.065667, loss_ce: 0.023935
2022-01-14 15:09:18,004 iteration 602 : loss : 0.072397, loss_ce: 0.031532
2022-01-14 15:09:19,414 iteration 603 : loss : 0.081948, loss_ce: 0.030631
2022-01-14 15:09:20,919 iteration 604 : loss : 0.078609, loss_ce: 0.033490
2022-01-14 15:09:22,457 iteration 605 : loss : 0.069567, loss_ce: 0.028375
2022-01-14 15:09:23,949 iteration 606 : loss : 0.071958, loss_ce: 0.026285
2022-01-14 15:09:25,453 iteration 607 : loss : 0.081369, loss_ce: 0.027786
2022-01-14 15:09:27,077 iteration 608 : loss : 0.061582, loss_ce: 0.023193
2022-01-14 15:09:28,553 iteration 609 : loss : 0.062516, loss_ce: 0.025797
2022-01-14 15:09:30,108 iteration 610 : loss : 0.076179, loss_ce: 0.027384
2022-01-14 15:09:31,610 iteration 611 : loss : 0.104766, loss_ce: 0.036895
2022-01-14 15:09:33,122 iteration 612 : loss : 0.098171, loss_ce: 0.045362
  9%|██▋                           | 36/400 [16:53<2:52:48, 28.49s/it]2022-01-14 15:09:34,678 iteration 613 : loss : 0.073059, loss_ce: 0.035636
2022-01-14 15:09:36,312 iteration 614 : loss : 0.065105, loss_ce: 0.030651
2022-01-14 15:09:37,824 iteration 615 : loss : 0.066563, loss_ce: 0.026245
2022-01-14 15:09:39,257 iteration 616 : loss : 0.092404, loss_ce: 0.052377
2022-01-14 15:09:40,753 iteration 617 : loss : 0.081262, loss_ce: 0.034872
2022-01-14 15:09:42,219 iteration 618 : loss : 0.102505, loss_ce: 0.041066
2022-01-14 15:09:43,721 iteration 619 : loss : 0.112709, loss_ce: 0.042285
2022-01-14 15:09:45,346 iteration 620 : loss : 0.123663, loss_ce: 0.057175
2022-01-14 15:09:46,823 iteration 621 : loss : 0.093686, loss_ce: 0.041921
2022-01-14 15:09:48,337 iteration 622 : loss : 0.071300, loss_ce: 0.029581
2022-01-14 15:09:49,912 iteration 623 : loss : 0.078357, loss_ce: 0.023015
2022-01-14 15:09:51,400 iteration 624 : loss : 0.081440, loss_ce: 0.025142
2022-01-14 15:09:52,845 iteration 625 : loss : 0.079825, loss_ce: 0.029113
2022-01-14 15:09:54,296 iteration 626 : loss : 0.060247, loss_ce: 0.022809
2022-01-14 15:09:55,753 iteration 627 : loss : 0.068657, loss_ce: 0.022661
2022-01-14 15:09:57,260 iteration 628 : loss : 0.109876, loss_ce: 0.057173
2022-01-14 15:09:58,804 iteration 629 : loss : 0.076239, loss_ce: 0.028685
  9%|██▊                           | 37/400 [17:18<2:47:16, 27.65s/it]2022-01-14 15:10:00,337 iteration 630 : loss : 0.066727, loss_ce: 0.029027
2022-01-14 15:10:01,887 iteration 631 : loss : 0.104964, loss_ce: 0.059508
2022-01-14 15:10:03,413 iteration 632 : loss : 0.134267, loss_ce: 0.060239
2022-01-14 15:10:04,955 iteration 633 : loss : 0.074205, loss_ce: 0.030697
2022-01-14 15:10:06,518 iteration 634 : loss : 0.070478, loss_ce: 0.031560
2022-01-14 15:10:08,029 iteration 635 : loss : 0.107432, loss_ce: 0.036485
2022-01-14 15:10:09,655 iteration 636 : loss : 0.109118, loss_ce: 0.056433
2022-01-14 15:10:11,098 iteration 637 : loss : 0.073259, loss_ce: 0.027984
2022-01-14 15:10:12,591 iteration 638 : loss : 0.123100, loss_ce: 0.052862
2022-01-14 15:10:14,164 iteration 639 : loss : 0.085352, loss_ce: 0.036003
2022-01-14 15:10:15,628 iteration 640 : loss : 0.077460, loss_ce: 0.030473
2022-01-14 15:10:17,167 iteration 641 : loss : 0.067041, loss_ce: 0.027271
2022-01-14 15:10:18,718 iteration 642 : loss : 0.060636, loss_ce: 0.020989
2022-01-14 15:10:20,229 iteration 643 : loss : 0.076892, loss_ce: 0.029050
2022-01-14 15:10:21,745 iteration 644 : loss : 0.052383, loss_ce: 0.020147
2022-01-14 15:10:23,283 iteration 645 : loss : 0.115250, loss_ce: 0.043069
2022-01-14 15:10:24,789 iteration 646 : loss : 0.065374, loss_ce: 0.026957
 10%|██▊                           | 38/400 [17:44<2:43:48, 27.15s/it]2022-01-14 15:10:26,334 iteration 647 : loss : 0.092295, loss_ce: 0.028094
2022-01-14 15:10:27,778 iteration 648 : loss : 0.087072, loss_ce: 0.041126
2022-01-14 15:10:29,269 iteration 649 : loss : 0.087225, loss_ce: 0.040113
2022-01-14 15:10:30,858 iteration 650 : loss : 0.130652, loss_ce: 0.044126
2022-01-14 15:10:32,427 iteration 651 : loss : 0.056251, loss_ce: 0.020618
2022-01-14 15:10:33,907 iteration 652 : loss : 0.069750, loss_ce: 0.031779
2022-01-14 15:10:35,418 iteration 653 : loss : 0.078433, loss_ce: 0.039493
2022-01-14 15:10:36,922 iteration 654 : loss : 0.069129, loss_ce: 0.024676
2022-01-14 15:10:38,330 iteration 655 : loss : 0.072926, loss_ce: 0.024812
2022-01-14 15:10:39,911 iteration 656 : loss : 0.098196, loss_ce: 0.039012
2022-01-14 15:10:41,443 iteration 657 : loss : 0.087656, loss_ce: 0.029327
2022-01-14 15:10:42,951 iteration 658 : loss : 0.079843, loss_ce: 0.028045
2022-01-14 15:10:44,497 iteration 659 : loss : 0.074716, loss_ce: 0.024366
2022-01-14 15:10:46,009 iteration 660 : loss : 0.078677, loss_ce: 0.029315
2022-01-14 15:10:47,528 iteration 661 : loss : 0.069684, loss_ce: 0.032249
2022-01-14 15:10:49,096 iteration 662 : loss : 0.074590, loss_ce: 0.029741
2022-01-14 15:10:50,623 iteration 663 : loss : 0.088607, loss_ce: 0.040176
 10%|██▉                           | 39/400 [18:10<2:40:57, 26.75s/it]2022-01-14 15:10:52,119 iteration 664 : loss : 0.092061, loss_ce: 0.044133
2022-01-14 15:10:53,673 iteration 665 : loss : 0.074540, loss_ce: 0.023300
2022-01-14 15:10:55,225 iteration 666 : loss : 0.070306, loss_ce: 0.019998
2022-01-14 15:10:56,778 iteration 667 : loss : 0.074162, loss_ce: 0.029364
2022-01-14 15:10:58,248 iteration 668 : loss : 0.055573, loss_ce: 0.020644
2022-01-14 15:10:59,822 iteration 669 : loss : 0.079781, loss_ce: 0.036160
2022-01-14 15:11:01,425 iteration 670 : loss : 0.099234, loss_ce: 0.042854
2022-01-14 15:11:02,958 iteration 671 : loss : 0.101890, loss_ce: 0.043110
2022-01-14 15:11:04,367 iteration 672 : loss : 0.059219, loss_ce: 0.025737
2022-01-14 15:11:05,878 iteration 673 : loss : 0.096233, loss_ce: 0.038707
2022-01-14 15:11:07,528 iteration 674 : loss : 0.067497, loss_ce: 0.031290
2022-01-14 15:11:09,041 iteration 675 : loss : 0.098682, loss_ce: 0.036995
2022-01-14 15:11:10,537 iteration 676 : loss : 0.065756, loss_ce: 0.024992
2022-01-14 15:11:12,171 iteration 677 : loss : 0.062418, loss_ce: 0.030828
2022-01-14 15:11:13,700 iteration 678 : loss : 0.112085, loss_ce: 0.030773
2022-01-14 15:11:15,183 iteration 679 : loss : 0.078693, loss_ce: 0.033123
2022-01-14 15:11:15,184 Training Data Eval:
2022-01-14 15:11:22,666   Average segmentation loss on training set: 0.0608
2022-01-14 15:11:22,666 Validation Data Eval:
2022-01-14 15:11:25,233   Average segmentation loss on validation set: 0.1211
2022-01-14 15:11:31,118 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed100.pth
2022-01-14 15:11:32,523 iteration 680 : loss : 0.063825, loss_ce: 0.026588
 10%|███                           | 40/400 [18:52<3:07:47, 31.30s/it]2022-01-14 15:11:34,128 iteration 681 : loss : 0.100644, loss_ce: 0.036099
2022-01-14 15:11:35,520 iteration 682 : loss : 0.085537, loss_ce: 0.032308
2022-01-14 15:11:36,915 iteration 683 : loss : 0.064647, loss_ce: 0.019700
2022-01-14 15:11:38,453 iteration 684 : loss : 0.060492, loss_ce: 0.026606
2022-01-14 15:11:39,972 iteration 685 : loss : 0.065910, loss_ce: 0.025368
2022-01-14 15:11:41,464 iteration 686 : loss : 0.091464, loss_ce: 0.037406
2022-01-14 15:11:42,953 iteration 687 : loss : 0.049932, loss_ce: 0.022118
2022-01-14 15:11:44,464 iteration 688 : loss : 0.087506, loss_ce: 0.031216
2022-01-14 15:11:45,936 iteration 689 : loss : 0.075616, loss_ce: 0.035352
2022-01-14 15:11:47,339 iteration 690 : loss : 0.082985, loss_ce: 0.034600
2022-01-14 15:11:48,867 iteration 691 : loss : 0.100805, loss_ce: 0.035482
2022-01-14 15:11:50,343 iteration 692 : loss : 0.054014, loss_ce: 0.023640
2022-01-14 15:11:51,859 iteration 693 : loss : 0.054010, loss_ce: 0.021573
2022-01-14 15:11:53,397 iteration 694 : loss : 0.078626, loss_ce: 0.028899
2022-01-14 15:11:54,940 iteration 695 : loss : 0.096651, loss_ce: 0.035795
2022-01-14 15:11:56,447 iteration 696 : loss : 0.145066, loss_ce: 0.035080
2022-01-14 15:11:57,866 iteration 697 : loss : 0.056553, loss_ce: 0.023918
 10%|███                           | 41/400 [19:17<2:56:34, 29.51s/it]2022-01-14 15:11:59,439 iteration 698 : loss : 0.066211, loss_ce: 0.030975
2022-01-14 15:12:00,990 iteration 699 : loss : 0.082646, loss_ce: 0.034170
2022-01-14 15:12:02,470 iteration 700 : loss : 0.083504, loss_ce: 0.030523
2022-01-14 15:12:03,969 iteration 701 : loss : 0.078980, loss_ce: 0.026629
2022-01-14 15:12:05,556 iteration 702 : loss : 0.062258, loss_ce: 0.026101
2022-01-14 15:12:07,102 iteration 703 : loss : 0.116445, loss_ce: 0.036495
2022-01-14 15:12:08,744 iteration 704 : loss : 0.091085, loss_ce: 0.029746
2022-01-14 15:12:10,318 iteration 705 : loss : 0.066979, loss_ce: 0.033368
2022-01-14 15:12:11,887 iteration 706 : loss : 0.121763, loss_ce: 0.037177
2022-01-14 15:12:13,367 iteration 707 : loss : 0.077846, loss_ce: 0.033498
2022-01-14 15:12:14,911 iteration 708 : loss : 0.083211, loss_ce: 0.023729
2022-01-14 15:12:16,452 iteration 709 : loss : 0.080023, loss_ce: 0.030571
2022-01-14 15:12:17,909 iteration 710 : loss : 0.063446, loss_ce: 0.029339
2022-01-14 15:12:19,512 iteration 711 : loss : 0.058632, loss_ce: 0.025965
2022-01-14 15:12:21,023 iteration 712 : loss : 0.098366, loss_ce: 0.036830
2022-01-14 15:12:22,492 iteration 713 : loss : 0.050830, loss_ce: 0.021086
2022-01-14 15:12:23,953 iteration 714 : loss : 0.057663, loss_ce: 0.020314
 10%|███▏                          | 42/400 [19:44<2:49:57, 28.48s/it]2022-01-14 15:12:25,596 iteration 715 : loss : 0.079167, loss_ce: 0.040416
2022-01-14 15:12:27,080 iteration 716 : loss : 0.068021, loss_ce: 0.027746
2022-01-14 15:12:28,569 iteration 717 : loss : 0.100351, loss_ce: 0.035175
2022-01-14 15:12:30,084 iteration 718 : loss : 0.103168, loss_ce: 0.037750
2022-01-14 15:12:31,640 iteration 719 : loss : 0.079162, loss_ce: 0.030372
2022-01-14 15:12:33,122 iteration 720 : loss : 0.081724, loss_ce: 0.027387
2022-01-14 15:12:34,721 iteration 721 : loss : 0.075458, loss_ce: 0.026201
2022-01-14 15:12:36,261 iteration 722 : loss : 0.065632, loss_ce: 0.026549
2022-01-14 15:12:37,715 iteration 723 : loss : 0.059047, loss_ce: 0.023233
2022-01-14 15:12:39,327 iteration 724 : loss : 0.064538, loss_ce: 0.027926
2022-01-14 15:12:40,783 iteration 725 : loss : 0.064252, loss_ce: 0.025469
2022-01-14 15:12:42,321 iteration 726 : loss : 0.105528, loss_ce: 0.032711
2022-01-14 15:12:43,894 iteration 727 : loss : 0.075550, loss_ce: 0.023513
2022-01-14 15:12:45,631 iteration 728 : loss : 0.102859, loss_ce: 0.050218
2022-01-14 15:12:47,013 iteration 729 : loss : 0.047821, loss_ce: 0.019032
2022-01-14 15:12:48,518 iteration 730 : loss : 0.055307, loss_ce: 0.025501
2022-01-14 15:12:50,069 iteration 731 : loss : 0.090551, loss_ce: 0.036114
 11%|███▏                          | 43/400 [20:10<2:45:13, 27.77s/it]2022-01-14 15:12:51,731 iteration 732 : loss : 0.071220, loss_ce: 0.035623
2022-01-14 15:12:53,315 iteration 733 : loss : 0.116348, loss_ce: 0.060230
2022-01-14 15:12:54,779 iteration 734 : loss : 0.092845, loss_ce: 0.032759
2022-01-14 15:12:56,301 iteration 735 : loss : 0.062074, loss_ce: 0.027373
2022-01-14 15:12:57,821 iteration 736 : loss : 0.085236, loss_ce: 0.031663
2022-01-14 15:12:59,410 iteration 737 : loss : 0.072290, loss_ce: 0.026345
2022-01-14 15:13:00,955 iteration 738 : loss : 0.043393, loss_ce: 0.019777
2022-01-14 15:13:02,473 iteration 739 : loss : 0.088476, loss_ce: 0.033624
2022-01-14 15:13:03,993 iteration 740 : loss : 0.110342, loss_ce: 0.056329
2022-01-14 15:13:05,505 iteration 741 : loss : 0.064474, loss_ce: 0.028268
2022-01-14 15:13:07,103 iteration 742 : loss : 0.074177, loss_ce: 0.027024
2022-01-14 15:13:08,586 iteration 743 : loss : 0.076381, loss_ce: 0.026872
2022-01-14 15:13:10,099 iteration 744 : loss : 0.056997, loss_ce: 0.021776
2022-01-14 15:13:11,586 iteration 745 : loss : 0.051147, loss_ce: 0.021386
2022-01-14 15:13:13,085 iteration 746 : loss : 0.108149, loss_ce: 0.053587
2022-01-14 15:13:14,624 iteration 747 : loss : 0.090127, loss_ce: 0.026214
2022-01-14 15:13:16,070 iteration 748 : loss : 0.063951, loss_ce: 0.027138
 11%|███▎                          | 44/400 [20:36<2:41:38, 27.24s/it]2022-01-14 15:13:17,636 iteration 749 : loss : 0.067783, loss_ce: 0.029872
2022-01-14 15:13:19,191 iteration 750 : loss : 0.057646, loss_ce: 0.025184
2022-01-14 15:13:20,609 iteration 751 : loss : 0.058081, loss_ce: 0.024028
2022-01-14 15:13:22,153 iteration 752 : loss : 0.061800, loss_ce: 0.024929
2022-01-14 15:13:23,786 iteration 753 : loss : 0.086562, loss_ce: 0.035322
2022-01-14 15:13:25,261 iteration 754 : loss : 0.084980, loss_ce: 0.028876
2022-01-14 15:13:26,798 iteration 755 : loss : 0.055528, loss_ce: 0.020092
2022-01-14 15:13:28,247 iteration 756 : loss : 0.065521, loss_ce: 0.030791
2022-01-14 15:13:29,738 iteration 757 : loss : 0.077011, loss_ce: 0.026852
2022-01-14 15:13:31,282 iteration 758 : loss : 0.062899, loss_ce: 0.021295
2022-01-14 15:13:32,723 iteration 759 : loss : 0.056309, loss_ce: 0.021500
2022-01-14 15:13:34,267 iteration 760 : loss : 0.135126, loss_ce: 0.051518
2022-01-14 15:13:35,809 iteration 761 : loss : 0.057882, loss_ce: 0.019638
2022-01-14 15:13:37,341 iteration 762 : loss : 0.087316, loss_ce: 0.043320
2022-01-14 15:13:38,846 iteration 763 : loss : 0.066866, loss_ce: 0.028220
2022-01-14 15:13:40,304 iteration 764 : loss : 0.072691, loss_ce: 0.030699
2022-01-14 15:13:40,304 Training Data Eval:
2022-01-14 15:13:47,799   Average segmentation loss on training set: 0.0660
2022-01-14 15:13:47,800 Validation Data Eval:
2022-01-14 15:13:50,362   Average segmentation loss on validation set: 0.1310
2022-01-14 15:13:51,886 iteration 765 : loss : 0.076988, loss_ce: 0.036399
 11%|███▍                          | 45/400 [21:11<2:56:23, 29.81s/it]2022-01-14 15:13:53,418 iteration 766 : loss : 0.067840, loss_ce: 0.026640
2022-01-14 15:13:54,992 iteration 767 : loss : 0.109684, loss_ce: 0.044184
2022-01-14 15:13:56,425 iteration 768 : loss : 0.082031, loss_ce: 0.030354
2022-01-14 15:13:57,952 iteration 769 : loss : 0.168902, loss_ce: 0.032757
2022-01-14 15:13:59,397 iteration 770 : loss : 0.055898, loss_ce: 0.021452
2022-01-14 15:14:01,001 iteration 771 : loss : 0.074343, loss_ce: 0.029541
2022-01-14 15:14:02,571 iteration 772 : loss : 0.043774, loss_ce: 0.019650
2022-01-14 15:14:04,108 iteration 773 : loss : 0.054897, loss_ce: 0.019598
2022-01-14 15:14:05,604 iteration 774 : loss : 0.057436, loss_ce: 0.026788
2022-01-14 15:14:07,123 iteration 775 : loss : 0.076161, loss_ce: 0.028235
2022-01-14 15:14:08,558 iteration 776 : loss : 0.061952, loss_ce: 0.026752
2022-01-14 15:14:10,153 iteration 777 : loss : 0.060719, loss_ce: 0.023339
2022-01-14 15:14:11,671 iteration 778 : loss : 0.041518, loss_ce: 0.016441
2022-01-14 15:14:13,196 iteration 779 : loss : 0.062864, loss_ce: 0.033715
2022-01-14 15:14:14,657 iteration 780 : loss : 0.059713, loss_ce: 0.023560
2022-01-14 15:14:16,237 iteration 781 : loss : 0.066319, loss_ce: 0.029997
2022-01-14 15:14:17,768 iteration 782 : loss : 0.069117, loss_ce: 0.026930
 12%|███▍                          | 46/400 [21:37<2:48:55, 28.63s/it]2022-01-14 15:14:19,366 iteration 783 : loss : 0.067169, loss_ce: 0.028710
2022-01-14 15:14:20,866 iteration 784 : loss : 0.079239, loss_ce: 0.027327
2022-01-14 15:14:22,426 iteration 785 : loss : 0.059538, loss_ce: 0.025307
2022-01-14 15:14:23,940 iteration 786 : loss : 0.067309, loss_ce: 0.023428
2022-01-14 15:14:25,455 iteration 787 : loss : 0.058553, loss_ce: 0.024417
2022-01-14 15:14:27,008 iteration 788 : loss : 0.068574, loss_ce: 0.024473
2022-01-14 15:14:28,648 iteration 789 : loss : 0.093323, loss_ce: 0.055514
2022-01-14 15:14:30,247 iteration 790 : loss : 0.044993, loss_ce: 0.016386
2022-01-14 15:14:31,720 iteration 791 : loss : 0.063258, loss_ce: 0.024293
2022-01-14 15:14:33,250 iteration 792 : loss : 0.056758, loss_ce: 0.022729
2022-01-14 15:14:34,652 iteration 793 : loss : 0.092625, loss_ce: 0.033799
2022-01-14 15:14:36,148 iteration 794 : loss : 0.041055, loss_ce: 0.016653
2022-01-14 15:14:37,653 iteration 795 : loss : 0.065764, loss_ce: 0.025578
2022-01-14 15:14:39,153 iteration 796 : loss : 0.057172, loss_ce: 0.020495
2022-01-14 15:14:40,639 iteration 797 : loss : 0.068989, loss_ce: 0.031488
2022-01-14 15:14:42,139 iteration 798 : loss : 0.132056, loss_ce: 0.036200
2022-01-14 15:14:43,693 iteration 799 : loss : 0.048366, loss_ce: 0.020579
 12%|███▌                          | 47/400 [22:03<2:43:40, 27.82s/it]2022-01-14 15:14:45,274 iteration 800 : loss : 0.070956, loss_ce: 0.017492
2022-01-14 15:14:46,721 iteration 801 : loss : 0.050487, loss_ce: 0.018476
2022-01-14 15:14:48,242 iteration 802 : loss : 0.081526, loss_ce: 0.039764
2022-01-14 15:14:49,845 iteration 803 : loss : 0.119339, loss_ce: 0.080378
2022-01-14 15:14:51,280 iteration 804 : loss : 0.051437, loss_ce: 0.023159
2022-01-14 15:14:52,701 iteration 805 : loss : 0.182621, loss_ce: 0.045578
2022-01-14 15:14:54,224 iteration 806 : loss : 0.079593, loss_ce: 0.029305
2022-01-14 15:14:55,844 iteration 807 : loss : 0.064046, loss_ce: 0.027193
2022-01-14 15:14:57,441 iteration 808 : loss : 0.083362, loss_ce: 0.033199
2022-01-14 15:14:58,938 iteration 809 : loss : 0.130289, loss_ce: 0.043629
2022-01-14 15:15:00,503 iteration 810 : loss : 0.083749, loss_ce: 0.029014
2022-01-14 15:15:01,964 iteration 811 : loss : 0.036581, loss_ce: 0.015144
2022-01-14 15:15:03,557 iteration 812 : loss : 0.109091, loss_ce: 0.044884
2022-01-14 15:15:05,055 iteration 813 : loss : 0.065565, loss_ce: 0.027654
2022-01-14 15:15:06,570 iteration 814 : loss : 0.079067, loss_ce: 0.034020
2022-01-14 15:15:08,109 iteration 815 : loss : 0.053829, loss_ce: 0.018678
2022-01-14 15:15:09,492 iteration 816 : loss : 0.055678, loss_ce: 0.020771
 12%|███▌                          | 48/400 [22:29<2:39:39, 27.22s/it]2022-01-14 15:15:11,015 iteration 817 : loss : 0.055787, loss_ce: 0.022789
2022-01-14 15:15:12,577 iteration 818 : loss : 0.075974, loss_ce: 0.029211
2022-01-14 15:15:14,116 iteration 819 : loss : 0.060062, loss_ce: 0.024722
2022-01-14 15:15:15,737 iteration 820 : loss : 0.053853, loss_ce: 0.024138
2022-01-14 15:15:17,147 iteration 821 : loss : 0.084696, loss_ce: 0.032638
2022-01-14 15:15:18,701 iteration 822 : loss : 0.044697, loss_ce: 0.018156
2022-01-14 15:15:20,184 iteration 823 : loss : 0.068614, loss_ce: 0.026935
2022-01-14 15:15:21,652 iteration 824 : loss : 0.054701, loss_ce: 0.024669
2022-01-14 15:15:23,131 iteration 825 : loss : 0.066591, loss_ce: 0.019564
2022-01-14 15:15:24,662 iteration 826 : loss : 0.050968, loss_ce: 0.022103
2022-01-14 15:15:26,135 iteration 827 : loss : 0.086515, loss_ce: 0.024455
2022-01-14 15:15:27,717 iteration 828 : loss : 0.078457, loss_ce: 0.037401
2022-01-14 15:15:29,237 iteration 829 : loss : 0.113689, loss_ce: 0.043946
2022-01-14 15:15:30,843 iteration 830 : loss : 0.069518, loss_ce: 0.021759
2022-01-14 15:15:32,335 iteration 831 : loss : 0.059616, loss_ce: 0.024120
2022-01-14 15:15:33,831 iteration 832 : loss : 0.041544, loss_ce: 0.017483
2022-01-14 15:15:35,291 iteration 833 : loss : 0.064976, loss_ce: 0.031703
 12%|███▋                          | 49/400 [22:55<2:36:43, 26.79s/it]2022-01-14 15:15:36,805 iteration 834 : loss : 0.083983, loss_ce: 0.029433
2022-01-14 15:15:38,351 iteration 835 : loss : 0.066882, loss_ce: 0.028117
2022-01-14 15:15:39,901 iteration 836 : loss : 0.057654, loss_ce: 0.025587
2022-01-14 15:15:41,401 iteration 837 : loss : 0.065836, loss_ce: 0.027010
2022-01-14 15:15:42,860 iteration 838 : loss : 0.059238, loss_ce: 0.023964
2022-01-14 15:15:44,461 iteration 839 : loss : 0.063962, loss_ce: 0.024087
2022-01-14 15:15:45,971 iteration 840 : loss : 0.078388, loss_ce: 0.027494
2022-01-14 15:15:47,509 iteration 841 : loss : 0.072506, loss_ce: 0.043247
2022-01-14 15:15:49,177 iteration 842 : loss : 0.085503, loss_ce: 0.041911
2022-01-14 15:15:50,648 iteration 843 : loss : 0.042421, loss_ce: 0.015157
2022-01-14 15:15:52,181 iteration 844 : loss : 0.071435, loss_ce: 0.024993
2022-01-14 15:15:53,643 iteration 845 : loss : 0.061270, loss_ce: 0.024342
2022-01-14 15:15:55,144 iteration 846 : loss : 0.062918, loss_ce: 0.022259
2022-01-14 15:15:56,755 iteration 847 : loss : 0.078502, loss_ce: 0.028029
2022-01-14 15:15:58,180 iteration 848 : loss : 0.059971, loss_ce: 0.021397
2022-01-14 15:15:59,718 iteration 849 : loss : 0.072107, loss_ce: 0.027310
2022-01-14 15:15:59,718 Training Data Eval:
2022-01-14 15:16:07,187   Average segmentation loss on training set: 0.0533
2022-01-14 15:16:07,187 Validation Data Eval:
2022-01-14 15:16:09,742   Average segmentation loss on validation set: 0.1426
2022-01-14 15:16:11,328 iteration 850 : loss : 0.055691, loss_ce: 0.018457
 12%|███▊                          | 50/400 [23:31<2:52:26, 29.56s/it]2022-01-14 15:16:12,905 iteration 851 : loss : 0.053007, loss_ce: 0.026369
2022-01-14 15:16:14,472 iteration 852 : loss : 0.075470, loss_ce: 0.025569
2022-01-14 15:16:16,049 iteration 853 : loss : 0.088753, loss_ce: 0.036546
2022-01-14 15:16:17,512 iteration 854 : loss : 0.056374, loss_ce: 0.023424
2022-01-14 15:16:18,927 iteration 855 : loss : 0.048352, loss_ce: 0.020878
2022-01-14 15:16:20,384 iteration 856 : loss : 0.086328, loss_ce: 0.032912
2022-01-14 15:16:22,020 iteration 857 : loss : 0.050341, loss_ce: 0.022705
2022-01-14 15:16:23,519 iteration 858 : loss : 0.071361, loss_ce: 0.026032
2022-01-14 15:16:25,127 iteration 859 : loss : 0.063332, loss_ce: 0.023821
2022-01-14 15:16:26,668 iteration 860 : loss : 0.084779, loss_ce: 0.032695
2022-01-14 15:16:28,142 iteration 861 : loss : 0.072710, loss_ce: 0.027054
2022-01-14 15:16:29,661 iteration 862 : loss : 0.051744, loss_ce: 0.013312
2022-01-14 15:16:31,082 iteration 863 : loss : 0.074558, loss_ce: 0.036257
2022-01-14 15:16:32,562 iteration 864 : loss : 0.052177, loss_ce: 0.023789
2022-01-14 15:16:33,976 iteration 865 : loss : 0.056557, loss_ce: 0.027851
2022-01-14 15:16:35,438 iteration 866 : loss : 0.045458, loss_ce: 0.020288
2022-01-14 15:16:36,925 iteration 867 : loss : 0.070000, loss_ce: 0.031087
 13%|███▊                          | 51/400 [23:56<2:45:02, 28.37s/it]2022-01-14 15:16:38,500 iteration 868 : loss : 0.051684, loss_ce: 0.017546
2022-01-14 15:16:39,961 iteration 869 : loss : 0.063633, loss_ce: 0.028458
2022-01-14 15:16:41,515 iteration 870 : loss : 0.103706, loss_ce: 0.024635
2022-01-14 15:16:43,021 iteration 871 : loss : 0.078369, loss_ce: 0.031523
2022-01-14 15:16:44,445 iteration 872 : loss : 0.037758, loss_ce: 0.016523
2022-01-14 15:16:45,918 iteration 873 : loss : 0.035842, loss_ce: 0.013069
2022-01-14 15:16:47,454 iteration 874 : loss : 0.065389, loss_ce: 0.028547
2022-01-14 15:16:48,961 iteration 875 : loss : 0.061947, loss_ce: 0.029576
2022-01-14 15:16:50,447 iteration 876 : loss : 0.074385, loss_ce: 0.036038
2022-01-14 15:16:51,905 iteration 877 : loss : 0.053562, loss_ce: 0.017554
2022-01-14 15:16:53,403 iteration 878 : loss : 0.056310, loss_ce: 0.019705
2022-01-14 15:16:54,907 iteration 879 : loss : 0.060067, loss_ce: 0.020930
2022-01-14 15:16:56,345 iteration 880 : loss : 0.039302, loss_ce: 0.014232
2022-01-14 15:16:57,888 iteration 881 : loss : 0.060774, loss_ce: 0.023570
2022-01-14 15:16:59,361 iteration 882 : loss : 0.048040, loss_ce: 0.022914
2022-01-14 15:17:00,832 iteration 883 : loss : 0.079921, loss_ce: 0.024208
2022-01-14 15:17:02,473 iteration 884 : loss : 0.061466, loss_ce: 0.019093
 13%|███▉                          | 52/400 [24:22<2:39:38, 27.52s/it]2022-01-14 15:17:04,068 iteration 885 : loss : 0.080018, loss_ce: 0.035866
2022-01-14 15:17:05,553 iteration 886 : loss : 0.071090, loss_ce: 0.027903
2022-01-14 15:17:07,034 iteration 887 : loss : 0.060555, loss_ce: 0.025249
2022-01-14 15:17:08,566 iteration 888 : loss : 0.065470, loss_ce: 0.024678
2022-01-14 15:17:10,049 iteration 889 : loss : 0.063161, loss_ce: 0.021621
2022-01-14 15:17:11,631 iteration 890 : loss : 0.059630, loss_ce: 0.025674
2022-01-14 15:17:13,145 iteration 891 : loss : 0.076641, loss_ce: 0.037412
2022-01-14 15:17:14,667 iteration 892 : loss : 0.086554, loss_ce: 0.026199
2022-01-14 15:17:16,272 iteration 893 : loss : 0.072830, loss_ce: 0.032160
2022-01-14 15:17:17,760 iteration 894 : loss : 0.071975, loss_ce: 0.030221
2022-01-14 15:17:19,290 iteration 895 : loss : 0.065368, loss_ce: 0.024287
2022-01-14 15:17:20,865 iteration 896 : loss : 0.085636, loss_ce: 0.027707
2022-01-14 15:17:22,277 iteration 897 : loss : 0.045613, loss_ce: 0.018150
2022-01-14 15:17:23,894 iteration 898 : loss : 0.073322, loss_ce: 0.031056
2022-01-14 15:17:25,402 iteration 899 : loss : 0.058861, loss_ce: 0.021181
2022-01-14 15:17:26,946 iteration 900 : loss : 0.071504, loss_ce: 0.026494
2022-01-14 15:17:28,419 iteration 901 : loss : 0.067999, loss_ce: 0.037967
 13%|███▉                          | 53/400 [24:48<2:36:27, 27.05s/it]2022-01-14 15:17:29,959 iteration 902 : loss : 0.053925, loss_ce: 0.021935
2022-01-14 15:17:31,492 iteration 903 : loss : 0.052110, loss_ce: 0.017707
2022-01-14 15:17:32,978 iteration 904 : loss : 0.067349, loss_ce: 0.030196
2022-01-14 15:17:34,410 iteration 905 : loss : 0.093766, loss_ce: 0.024306
2022-01-14 15:17:35,880 iteration 906 : loss : 0.048984, loss_ce: 0.017940
2022-01-14 15:17:37,476 iteration 907 : loss : 0.041960, loss_ce: 0.020021
2022-01-14 15:17:38,962 iteration 908 : loss : 0.057629, loss_ce: 0.031496
2022-01-14 15:17:40,511 iteration 909 : loss : 0.058157, loss_ce: 0.027169
2022-01-14 15:17:41,991 iteration 910 : loss : 0.080188, loss_ce: 0.030711
2022-01-14 15:17:43,525 iteration 911 : loss : 0.061344, loss_ce: 0.022162
2022-01-14 15:17:44,938 iteration 912 : loss : 0.057276, loss_ce: 0.020988
2022-01-14 15:17:46,495 iteration 913 : loss : 0.063105, loss_ce: 0.025910
2022-01-14 15:17:47,976 iteration 914 : loss : 0.044636, loss_ce: 0.019387
2022-01-14 15:17:49,514 iteration 915 : loss : 0.068931, loss_ce: 0.033439
2022-01-14 15:17:51,005 iteration 916 : loss : 0.059612, loss_ce: 0.020598
2022-01-14 15:17:52,504 iteration 917 : loss : 0.058730, loss_ce: 0.019073
2022-01-14 15:17:53,991 iteration 918 : loss : 0.061113, loss_ce: 0.019761
 14%|████                          | 54/400 [25:14<2:33:26, 26.61s/it]2022-01-14 15:17:55,634 iteration 919 : loss : 0.053134, loss_ce: 0.022651
2022-01-14 15:17:57,072 iteration 920 : loss : 0.121355, loss_ce: 0.088438
2022-01-14 15:17:58,690 iteration 921 : loss : 0.040544, loss_ce: 0.017153
2022-01-14 15:18:00,078 iteration 922 : loss : 0.050689, loss_ce: 0.026067
2022-01-14 15:18:01,561 iteration 923 : loss : 0.053455, loss_ce: 0.020149
2022-01-14 15:18:03,048 iteration 924 : loss : 0.048604, loss_ce: 0.015848
2022-01-14 15:18:04,467 iteration 925 : loss : 0.047184, loss_ce: 0.016552
2022-01-14 15:18:05,902 iteration 926 : loss : 0.073448, loss_ce: 0.026623
2022-01-14 15:18:07,412 iteration 927 : loss : 0.054344, loss_ce: 0.021670
2022-01-14 15:18:08,865 iteration 928 : loss : 0.055263, loss_ce: 0.021651
2022-01-14 15:18:10,508 iteration 929 : loss : 0.058581, loss_ce: 0.027821
2022-01-14 15:18:12,024 iteration 930 : loss : 0.057044, loss_ce: 0.033143
2022-01-14 15:18:13,558 iteration 931 : loss : 0.055099, loss_ce: 0.021433
2022-01-14 15:18:15,088 iteration 932 : loss : 0.081087, loss_ce: 0.025920
2022-01-14 15:18:16,761 iteration 933 : loss : 0.096910, loss_ce: 0.030652
2022-01-14 15:18:18,253 iteration 934 : loss : 0.055006, loss_ce: 0.019933
2022-01-14 15:18:18,254 Training Data Eval:
2022-01-14 15:18:25,742   Average segmentation loss on training set: 0.0452
2022-01-14 15:18:25,742 Validation Data Eval:
2022-01-14 15:18:28,300   Average segmentation loss on validation set: 0.0720
2022-01-14 15:18:34,358 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed100.pth
2022-01-14 15:18:35,718 iteration 935 : loss : 0.045769, loss_ce: 0.015936
 14%|████▏                         | 55/400 [25:55<2:59:04, 31.14s/it]2022-01-14 15:18:37,146 iteration 936 : loss : 0.057779, loss_ce: 0.014782
2022-01-14 15:18:38,537 iteration 937 : loss : 0.053731, loss_ce: 0.020781
2022-01-14 15:18:39,974 iteration 938 : loss : 0.062209, loss_ce: 0.032925
2022-01-14 15:18:41,386 iteration 939 : loss : 0.065442, loss_ce: 0.029237
2022-01-14 15:18:42,776 iteration 940 : loss : 0.065746, loss_ce: 0.030383
2022-01-14 15:18:44,216 iteration 941 : loss : 0.083284, loss_ce: 0.024871
2022-01-14 15:18:45,596 iteration 942 : loss : 0.047408, loss_ce: 0.014360
2022-01-14 15:18:46,917 iteration 943 : loss : 0.094667, loss_ce: 0.031967
2022-01-14 15:18:48,285 iteration 944 : loss : 0.039578, loss_ce: 0.015557
2022-01-14 15:18:49,674 iteration 945 : loss : 0.071015, loss_ce: 0.038180
2022-01-14 15:18:51,188 iteration 946 : loss : 0.047268, loss_ce: 0.016836
2022-01-14 15:18:52,819 iteration 947 : loss : 0.063280, loss_ce: 0.027239
2022-01-14 15:18:54,334 iteration 948 : loss : 0.073506, loss_ce: 0.030030
2022-01-14 15:18:55,902 iteration 949 : loss : 0.069835, loss_ce: 0.028625
2022-01-14 15:18:57,490 iteration 950 : loss : 0.131613, loss_ce: 0.038847
2022-01-14 15:18:59,071 iteration 951 : loss : 0.059279, loss_ce: 0.025191
2022-01-14 15:19:00,518 iteration 952 : loss : 0.089075, loss_ce: 0.023611
 14%|████▏                         | 56/400 [26:20<2:47:39, 29.24s/it]2022-01-14 15:19:02,120 iteration 953 : loss : 0.058629, loss_ce: 0.021376
2022-01-14 15:19:03,708 iteration 954 : loss : 0.051159, loss_ce: 0.019717
2022-01-14 15:19:05,216 iteration 955 : loss : 0.050764, loss_ce: 0.020233
2022-01-14 15:19:06,712 iteration 956 : loss : 0.054990, loss_ce: 0.021899
2022-01-14 15:19:08,083 iteration 957 : loss : 0.074917, loss_ce: 0.024503
2022-01-14 15:19:09,566 iteration 958 : loss : 0.069608, loss_ce: 0.020315
2022-01-14 15:19:11,025 iteration 959 : loss : 0.061949, loss_ce: 0.029947
2022-01-14 15:19:12,465 iteration 960 : loss : 0.055663, loss_ce: 0.023538
2022-01-14 15:19:13,945 iteration 961 : loss : 0.067302, loss_ce: 0.022726
2022-01-14 15:19:15,413 iteration 962 : loss : 0.051358, loss_ce: 0.018565
2022-01-14 15:19:17,011 iteration 963 : loss : 0.051091, loss_ce: 0.018866
2022-01-14 15:19:18,557 iteration 964 : loss : 0.055815, loss_ce: 0.020432
2022-01-14 15:19:20,066 iteration 965 : loss : 0.048969, loss_ce: 0.019000
2022-01-14 15:19:21,665 iteration 966 : loss : 0.083437, loss_ce: 0.040681
2022-01-14 15:19:23,183 iteration 967 : loss : 0.104642, loss_ce: 0.044937
2022-01-14 15:19:24,700 iteration 968 : loss : 0.066267, loss_ce: 0.025159
2022-01-14 15:19:26,256 iteration 969 : loss : 0.048809, loss_ce: 0.019426
 14%|████▎                         | 57/400 [26:46<2:41:09, 28.19s/it]2022-01-14 15:19:27,825 iteration 970 : loss : 0.037361, loss_ce: 0.014314
2022-01-14 15:19:29,473 iteration 971 : loss : 0.087564, loss_ce: 0.031965
2022-01-14 15:19:30,935 iteration 972 : loss : 0.043486, loss_ce: 0.016064
2022-01-14 15:19:32,397 iteration 973 : loss : 0.054398, loss_ce: 0.020666
2022-01-14 15:19:33,907 iteration 974 : loss : 0.065214, loss_ce: 0.024444
2022-01-14 15:19:35,346 iteration 975 : loss : 0.066317, loss_ce: 0.022938
2022-01-14 15:19:36,855 iteration 976 : loss : 0.073261, loss_ce: 0.025035
2022-01-14 15:19:38,399 iteration 977 : loss : 0.076467, loss_ce: 0.030739
2022-01-14 15:19:39,950 iteration 978 : loss : 0.084779, loss_ce: 0.042639
2022-01-14 15:19:41,474 iteration 979 : loss : 0.066556, loss_ce: 0.033634
2022-01-14 15:19:42,930 iteration 980 : loss : 0.066138, loss_ce: 0.021238
2022-01-14 15:19:44,491 iteration 981 : loss : 0.072417, loss_ce: 0.024679
2022-01-14 15:19:45,938 iteration 982 : loss : 0.065248, loss_ce: 0.037418
2022-01-14 15:19:47,453 iteration 983 : loss : 0.072108, loss_ce: 0.032992
2022-01-14 15:19:48,957 iteration 984 : loss : 0.069683, loss_ce: 0.034243
2022-01-14 15:19:50,460 iteration 985 : loss : 0.085216, loss_ce: 0.030676
2022-01-14 15:19:51,950 iteration 986 : loss : 0.074386, loss_ce: 0.027594
 14%|████▎                         | 58/400 [27:12<2:36:24, 27.44s/it]2022-01-14 15:19:53,499 iteration 987 : loss : 0.051092, loss_ce: 0.021402
2022-01-14 15:19:55,100 iteration 988 : loss : 0.061193, loss_ce: 0.024579
2022-01-14 15:19:56,588 iteration 989 : loss : 0.063344, loss_ce: 0.022067
2022-01-14 15:19:58,184 iteration 990 : loss : 0.055105, loss_ce: 0.030917
2022-01-14 15:19:59,767 iteration 991 : loss : 0.078146, loss_ce: 0.037089
2022-01-14 15:20:01,199 iteration 992 : loss : 0.074849, loss_ce: 0.028727
2022-01-14 15:20:02,850 iteration 993 : loss : 0.047023, loss_ce: 0.020337
2022-01-14 15:20:04,392 iteration 994 : loss : 0.061323, loss_ce: 0.020213
2022-01-14 15:20:05,922 iteration 995 : loss : 0.051429, loss_ce: 0.018690
2022-01-14 15:20:07,416 iteration 996 : loss : 0.041612, loss_ce: 0.015152
2022-01-14 15:20:08,971 iteration 997 : loss : 0.093958, loss_ce: 0.049217
2022-01-14 15:20:10,495 iteration 998 : loss : 0.061770, loss_ce: 0.026242
2022-01-14 15:20:12,088 iteration 999 : loss : 0.057585, loss_ce: 0.024675
2022-01-14 15:20:13,600 iteration 1000 : loss : 0.064397, loss_ce: 0.027699
2022-01-14 15:20:15,149 iteration 1001 : loss : 0.066978, loss_ce: 0.024063
2022-01-14 15:20:16,634 iteration 1002 : loss : 0.037682, loss_ce: 0.012282
2022-01-14 15:20:18,111 iteration 1003 : loss : 0.069227, loss_ce: 0.030411
 15%|████▍                         | 59/400 [27:38<2:33:46, 27.06s/it]2022-01-14 15:20:19,644 iteration 1004 : loss : 0.073849, loss_ce: 0.028547
2022-01-14 15:20:21,249 iteration 1005 : loss : 0.096962, loss_ce: 0.036445
2022-01-14 15:20:22,758 iteration 1006 : loss : 0.065990, loss_ce: 0.035738
2022-01-14 15:20:24,305 iteration 1007 : loss : 0.053897, loss_ce: 0.022538
2022-01-14 15:20:25,852 iteration 1008 : loss : 0.071523, loss_ce: 0.024880
2022-01-14 15:20:27,401 iteration 1009 : loss : 0.064756, loss_ce: 0.022044
2022-01-14 15:20:28,876 iteration 1010 : loss : 0.049583, loss_ce: 0.019793
2022-01-14 15:20:30,364 iteration 1011 : loss : 0.038308, loss_ce: 0.015499
2022-01-14 15:20:31,977 iteration 1012 : loss : 0.084324, loss_ce: 0.024913
2022-01-14 15:20:33,471 iteration 1013 : loss : 0.064171, loss_ce: 0.021018
2022-01-14 15:20:35,033 iteration 1014 : loss : 0.043252, loss_ce: 0.015159
2022-01-14 15:20:36,523 iteration 1015 : loss : 0.063849, loss_ce: 0.026802
2022-01-14 15:20:37,961 iteration 1016 : loss : 0.056970, loss_ce: 0.030612
2022-01-14 15:20:39,623 iteration 1017 : loss : 0.073377, loss_ce: 0.022583
2022-01-14 15:20:41,224 iteration 1018 : loss : 0.052063, loss_ce: 0.020100
2022-01-14 15:20:42,810 iteration 1019 : loss : 0.071796, loss_ce: 0.028396
2022-01-14 15:20:42,810 Training Data Eval:
2022-01-14 15:20:50,284   Average segmentation loss on training set: 0.0555
2022-01-14 15:20:50,285 Validation Data Eval:
2022-01-14 15:20:52,866   Average segmentation loss on validation set: 0.1449
2022-01-14 15:20:54,477 iteration 1020 : loss : 0.060625, loss_ce: 0.021321
 15%|████▌                         | 60/400 [28:14<2:49:09, 29.85s/it]2022-01-14 15:20:56,138 iteration 1021 : loss : 0.069073, loss_ce: 0.026050
2022-01-14 15:20:57,667 iteration 1022 : loss : 0.053814, loss_ce: 0.019071
2022-01-14 15:20:59,136 iteration 1023 : loss : 0.094116, loss_ce: 0.036016
2022-01-14 15:21:00,690 iteration 1024 : loss : 0.046983, loss_ce: 0.023285
2022-01-14 15:21:02,227 iteration 1025 : loss : 0.077187, loss_ce: 0.032609
2022-01-14 15:21:03,779 iteration 1026 : loss : 0.070314, loss_ce: 0.026126
2022-01-14 15:21:05,294 iteration 1027 : loss : 0.058368, loss_ce: 0.030457
2022-01-14 15:21:06,741 iteration 1028 : loss : 0.074720, loss_ce: 0.020780
2022-01-14 15:21:08,286 iteration 1029 : loss : 0.059213, loss_ce: 0.017420
2022-01-14 15:21:09,866 iteration 1030 : loss : 0.052609, loss_ce: 0.017701
2022-01-14 15:21:11,465 iteration 1031 : loss : 0.083860, loss_ce: 0.039913
2022-01-14 15:21:12,907 iteration 1032 : loss : 0.043153, loss_ce: 0.015799
2022-01-14 15:21:14,480 iteration 1033 : loss : 0.051875, loss_ce: 0.020004
2022-01-14 15:21:16,088 iteration 1034 : loss : 0.052257, loss_ce: 0.030242
2022-01-14 15:21:17,651 iteration 1035 : loss : 0.091388, loss_ce: 0.030813
2022-01-14 15:21:19,260 iteration 1036 : loss : 0.085092, loss_ce: 0.032385
2022-01-14 15:21:20,656 iteration 1037 : loss : 0.040054, loss_ce: 0.017328
 15%|████▌                         | 61/400 [28:40<2:42:25, 28.75s/it]2022-01-14 15:21:22,157 iteration 1038 : loss : 0.058646, loss_ce: 0.025999
2022-01-14 15:21:23,688 iteration 1039 : loss : 0.070981, loss_ce: 0.026795
2022-01-14 15:21:25,128 iteration 1040 : loss : 0.059190, loss_ce: 0.019458
2022-01-14 15:21:26,737 iteration 1041 : loss : 0.069133, loss_ce: 0.025393
2022-01-14 15:21:28,350 iteration 1042 : loss : 0.085576, loss_ce: 0.036132
2022-01-14 15:21:29,809 iteration 1043 : loss : 0.046087, loss_ce: 0.016405
2022-01-14 15:21:31,304 iteration 1044 : loss : 0.057301, loss_ce: 0.022112
2022-01-14 15:21:32,784 iteration 1045 : loss : 0.050259, loss_ce: 0.027091
2022-01-14 15:21:34,312 iteration 1046 : loss : 0.059546, loss_ce: 0.023380
2022-01-14 15:21:35,887 iteration 1047 : loss : 0.072161, loss_ce: 0.034325
2022-01-14 15:21:37,408 iteration 1048 : loss : 0.072114, loss_ce: 0.028281
2022-01-14 15:21:38,841 iteration 1049 : loss : 0.049200, loss_ce: 0.020369
2022-01-14 15:21:40,311 iteration 1050 : loss : 0.047150, loss_ce: 0.018509
2022-01-14 15:21:41,841 iteration 1051 : loss : 0.046871, loss_ce: 0.018733
2022-01-14 15:21:43,331 iteration 1052 : loss : 0.070413, loss_ce: 0.029431
2022-01-14 15:21:44,960 iteration 1053 : loss : 0.046571, loss_ce: 0.019037
2022-01-14 15:21:46,418 iteration 1054 : loss : 0.057341, loss_ce: 0.022513
 16%|████▋                         | 62/400 [29:06<2:36:53, 27.85s/it]2022-01-14 15:21:47,940 iteration 1055 : loss : 0.051888, loss_ce: 0.019325
2022-01-14 15:21:49,406 iteration 1056 : loss : 0.083885, loss_ce: 0.035876
2022-01-14 15:21:50,967 iteration 1057 : loss : 0.088698, loss_ce: 0.020725
2022-01-14 15:21:52,410 iteration 1058 : loss : 0.044672, loss_ce: 0.019083
2022-01-14 15:21:54,007 iteration 1059 : loss : 0.064934, loss_ce: 0.028956
2022-01-14 15:21:55,512 iteration 1060 : loss : 0.048982, loss_ce: 0.021503
2022-01-14 15:21:57,073 iteration 1061 : loss : 0.059532, loss_ce: 0.023674
2022-01-14 15:21:58,576 iteration 1062 : loss : 0.048731, loss_ce: 0.017615
2022-01-14 15:22:00,166 iteration 1063 : loss : 0.054079, loss_ce: 0.017370
2022-01-14 15:22:01,632 iteration 1064 : loss : 0.046159, loss_ce: 0.021231
2022-01-14 15:22:03,054 iteration 1065 : loss : 0.055939, loss_ce: 0.020573
2022-01-14 15:22:04,555 iteration 1066 : loss : 0.042483, loss_ce: 0.021647
2022-01-14 15:22:06,214 iteration 1067 : loss : 0.073017, loss_ce: 0.026700
2022-01-14 15:22:07,786 iteration 1068 : loss : 0.090010, loss_ce: 0.035259
2022-01-14 15:22:09,210 iteration 1069 : loss : 0.074425, loss_ce: 0.034308
2022-01-14 15:22:10,853 iteration 1070 : loss : 0.047357, loss_ce: 0.017419
2022-01-14 15:22:12,362 iteration 1071 : loss : 0.052525, loss_ce: 0.019722
 16%|████▋                         | 63/400 [29:32<2:33:13, 27.28s/it]2022-01-14 15:22:13,887 iteration 1072 : loss : 0.047328, loss_ce: 0.020177
2022-01-14 15:22:15,493 iteration 1073 : loss : 0.063760, loss_ce: 0.022479
2022-01-14 15:22:17,001 iteration 1074 : loss : 0.040435, loss_ce: 0.016925
2022-01-14 15:22:18,539 iteration 1075 : loss : 0.046446, loss_ce: 0.019050
2022-01-14 15:22:20,022 iteration 1076 : loss : 0.081137, loss_ce: 0.031651
2022-01-14 15:22:21,570 iteration 1077 : loss : 0.097246, loss_ce: 0.028808
2022-01-14 15:22:23,001 iteration 1078 : loss : 0.073644, loss_ce: 0.028626
2022-01-14 15:22:24,500 iteration 1079 : loss : 0.068480, loss_ce: 0.029200
2022-01-14 15:22:26,047 iteration 1080 : loss : 0.066750, loss_ce: 0.025281
2022-01-14 15:22:27,608 iteration 1081 : loss : 0.055588, loss_ce: 0.019632
2022-01-14 15:22:29,120 iteration 1082 : loss : 0.063954, loss_ce: 0.024690
2022-01-14 15:22:30,650 iteration 1083 : loss : 0.062183, loss_ce: 0.021330
2022-01-14 15:22:32,243 iteration 1084 : loss : 0.118593, loss_ce: 0.038820
2022-01-14 15:22:33,738 iteration 1085 : loss : 0.054380, loss_ce: 0.019524
2022-01-14 15:22:35,269 iteration 1086 : loss : 0.049110, loss_ce: 0.017081
2022-01-14 15:22:36,721 iteration 1087 : loss : 0.049435, loss_ce: 0.022705
2022-01-14 15:22:38,233 iteration 1088 : loss : 0.059108, loss_ce: 0.031823
 16%|████▊                         | 64/400 [29:58<2:30:24, 26.86s/it]2022-01-14 15:22:39,680 iteration 1089 : loss : 0.049863, loss_ce: 0.021500
2022-01-14 15:22:41,216 iteration 1090 : loss : 0.049947, loss_ce: 0.017762
2022-01-14 15:22:42,750 iteration 1091 : loss : 0.074440, loss_ce: 0.039621
2022-01-14 15:22:44,264 iteration 1092 : loss : 0.076170, loss_ce: 0.023516
2022-01-14 15:22:45,767 iteration 1093 : loss : 0.078667, loss_ce: 0.023631
2022-01-14 15:22:47,397 iteration 1094 : loss : 0.154491, loss_ce: 0.041455
2022-01-14 15:22:48,848 iteration 1095 : loss : 0.046458, loss_ce: 0.015390
2022-01-14 15:22:50,305 iteration 1096 : loss : 0.044479, loss_ce: 0.019560
2022-01-14 15:22:51,762 iteration 1097 : loss : 0.047553, loss_ce: 0.016404
2022-01-14 15:22:53,339 iteration 1098 : loss : 0.053191, loss_ce: 0.023217
2022-01-14 15:22:54,856 iteration 1099 : loss : 0.046522, loss_ce: 0.015696
2022-01-14 15:22:56,438 iteration 1100 : loss : 0.065134, loss_ce: 0.028784
2022-01-14 15:22:57,994 iteration 1101 : loss : 0.069662, loss_ce: 0.029456
2022-01-14 15:22:59,500 iteration 1102 : loss : 0.068141, loss_ce: 0.026596
2022-01-14 15:23:01,041 iteration 1103 : loss : 0.038296, loss_ce: 0.016638
2022-01-14 15:23:02,541 iteration 1104 : loss : 0.083394, loss_ce: 0.035120
2022-01-14 15:23:02,541 Training Data Eval:
2022-01-14 15:23:10,006   Average segmentation loss on training set: 0.0690
2022-01-14 15:23:10,006 Validation Data Eval:
2022-01-14 15:23:12,565   Average segmentation loss on validation set: 0.1046
2022-01-14 15:23:14,101 iteration 1105 : loss : 0.048325, loss_ce: 0.019633
 16%|████▉                         | 65/400 [30:34<2:45:03, 29.56s/it]2022-01-14 15:23:15,720 iteration 1106 : loss : 0.059328, loss_ce: 0.022510
2022-01-14 15:23:17,224 iteration 1107 : loss : 0.058839, loss_ce: 0.022205
2022-01-14 15:23:18,714 iteration 1108 : loss : 0.071790, loss_ce: 0.022643
2022-01-14 15:23:20,329 iteration 1109 : loss : 0.069957, loss_ce: 0.023864
2022-01-14 15:23:21,818 iteration 1110 : loss : 0.048477, loss_ce: 0.022352
2022-01-14 15:23:23,410 iteration 1111 : loss : 0.098077, loss_ce: 0.028785
2022-01-14 15:23:24,863 iteration 1112 : loss : 0.043894, loss_ce: 0.018169
2022-01-14 15:23:26,379 iteration 1113 : loss : 0.075898, loss_ce: 0.029622
2022-01-14 15:23:27,938 iteration 1114 : loss : 0.061374, loss_ce: 0.020298
2022-01-14 15:23:29,469 iteration 1115 : loss : 0.037240, loss_ce: 0.013759
2022-01-14 15:23:30,868 iteration 1116 : loss : 0.070510, loss_ce: 0.032007
2022-01-14 15:23:32,327 iteration 1117 : loss : 0.060971, loss_ce: 0.022706
2022-01-14 15:23:33,864 iteration 1118 : loss : 0.057376, loss_ce: 0.025324
2022-01-14 15:23:35,388 iteration 1119 : loss : 0.047422, loss_ce: 0.020582
2022-01-14 15:23:36,926 iteration 1120 : loss : 0.052243, loss_ce: 0.015123
2022-01-14 15:23:38,414 iteration 1121 : loss : 0.051369, loss_ce: 0.023758
2022-01-14 15:23:39,851 iteration 1122 : loss : 0.052252, loss_ce: 0.016065
 16%|████▉                         | 66/400 [30:59<2:38:10, 28.42s/it]2022-01-14 15:23:41,498 iteration 1123 : loss : 0.042458, loss_ce: 0.014525
2022-01-14 15:23:43,007 iteration 1124 : loss : 0.034773, loss_ce: 0.015935
2022-01-14 15:23:44,461 iteration 1125 : loss : 0.056469, loss_ce: 0.015396
2022-01-14 15:23:45,947 iteration 1126 : loss : 0.062334, loss_ce: 0.020279
2022-01-14 15:23:47,429 iteration 1127 : loss : 0.051320, loss_ce: 0.019552
2022-01-14 15:23:49,030 iteration 1128 : loss : 0.044954, loss_ce: 0.022241
2022-01-14 15:23:50,618 iteration 1129 : loss : 0.062667, loss_ce: 0.026999
2022-01-14 15:23:52,041 iteration 1130 : loss : 0.053059, loss_ce: 0.021570
2022-01-14 15:23:53,584 iteration 1131 : loss : 0.079022, loss_ce: 0.033351
2022-01-14 15:23:55,177 iteration 1132 : loss : 0.046068, loss_ce: 0.018097
2022-01-14 15:23:56,747 iteration 1133 : loss : 0.049050, loss_ce: 0.020892
2022-01-14 15:23:58,314 iteration 1134 : loss : 0.061164, loss_ce: 0.018796
2022-01-14 15:23:59,771 iteration 1135 : loss : 0.056214, loss_ce: 0.020209
2022-01-14 15:24:01,256 iteration 1136 : loss : 0.038987, loss_ce: 0.017905
2022-01-14 15:24:02,733 iteration 1137 : loss : 0.056722, loss_ce: 0.026397
2022-01-14 15:24:04,260 iteration 1138 : loss : 0.063977, loss_ce: 0.023634
2022-01-14 15:24:05,723 iteration 1139 : loss : 0.067284, loss_ce: 0.026050
 17%|█████                         | 67/400 [31:25<2:33:28, 27.65s/it]2022-01-14 15:24:07,264 iteration 1140 : loss : 0.055079, loss_ce: 0.022140
2022-01-14 15:24:08,789 iteration 1141 : loss : 0.068166, loss_ce: 0.032024
2022-01-14 15:24:10,467 iteration 1142 : loss : 0.055198, loss_ce: 0.021803
2022-01-14 15:24:12,000 iteration 1143 : loss : 0.064013, loss_ce: 0.024346
2022-01-14 15:24:13,554 iteration 1144 : loss : 0.068748, loss_ce: 0.022315
2022-01-14 15:24:15,029 iteration 1145 : loss : 0.059737, loss_ce: 0.020770
2022-01-14 15:24:16,517 iteration 1146 : loss : 0.042969, loss_ce: 0.018343
2022-01-14 15:24:18,002 iteration 1147 : loss : 0.066744, loss_ce: 0.030209
2022-01-14 15:24:19,492 iteration 1148 : loss : 0.058479, loss_ce: 0.025867
2022-01-14 15:24:21,001 iteration 1149 : loss : 0.032278, loss_ce: 0.015051
2022-01-14 15:24:22,452 iteration 1150 : loss : 0.047986, loss_ce: 0.018519
2022-01-14 15:24:23,942 iteration 1151 : loss : 0.035464, loss_ce: 0.017180
2022-01-14 15:24:25,411 iteration 1152 : loss : 0.058597, loss_ce: 0.022626
2022-01-14 15:24:27,034 iteration 1153 : loss : 0.062435, loss_ce: 0.022659
2022-01-14 15:24:28,554 iteration 1154 : loss : 0.050097, loss_ce: 0.021078
2022-01-14 15:24:30,120 iteration 1155 : loss : 0.057586, loss_ce: 0.019509
2022-01-14 15:24:31,750 iteration 1156 : loss : 0.080780, loss_ce: 0.028935
 17%|█████                         | 68/400 [31:51<2:30:19, 27.17s/it]2022-01-14 15:24:33,343 iteration 1157 : loss : 0.066234, loss_ce: 0.024130
2022-01-14 15:24:34,831 iteration 1158 : loss : 0.043445, loss_ce: 0.015156
2022-01-14 15:24:36,246 iteration 1159 : loss : 0.038790, loss_ce: 0.014536
2022-01-14 15:24:37,712 iteration 1160 : loss : 0.064051, loss_ce: 0.030339
2022-01-14 15:24:39,233 iteration 1161 : loss : 0.040697, loss_ce: 0.016273
2022-01-14 15:24:40,782 iteration 1162 : loss : 0.049941, loss_ce: 0.020172
2022-01-14 15:24:42,296 iteration 1163 : loss : 0.049995, loss_ce: 0.023661
2022-01-14 15:24:43,882 iteration 1164 : loss : 0.071657, loss_ce: 0.029479
2022-01-14 15:24:45,288 iteration 1165 : loss : 0.039775, loss_ce: 0.018932
2022-01-14 15:24:46,732 iteration 1166 : loss : 0.059743, loss_ce: 0.021507
2022-01-14 15:24:48,258 iteration 1167 : loss : 0.046805, loss_ce: 0.021783
2022-01-14 15:24:49,827 iteration 1168 : loss : 0.105749, loss_ce: 0.028681
2022-01-14 15:24:51,266 iteration 1169 : loss : 0.066999, loss_ce: 0.019955
2022-01-14 15:24:52,806 iteration 1170 : loss : 0.058369, loss_ce: 0.017650
2022-01-14 15:24:54,496 iteration 1171 : loss : 0.118359, loss_ce: 0.028305
2022-01-14 15:24:55,905 iteration 1172 : loss : 0.046928, loss_ce: 0.018225
2022-01-14 15:24:57,326 iteration 1173 : loss : 0.049090, loss_ce: 0.020135
 17%|█████▏                        | 69/400 [32:17<2:27:14, 26.69s/it]2022-01-14 15:24:58,938 iteration 1174 : loss : 0.045163, loss_ce: 0.015384
2022-01-14 15:25:00,543 iteration 1175 : loss : 0.073221, loss_ce: 0.032324
2022-01-14 15:25:02,006 iteration 1176 : loss : 0.109389, loss_ce: 0.037989
2022-01-14 15:25:03,486 iteration 1177 : loss : 0.061859, loss_ce: 0.026941
2022-01-14 15:25:04,919 iteration 1178 : loss : 0.089585, loss_ce: 0.031988
2022-01-14 15:25:06,454 iteration 1179 : loss : 0.055127, loss_ce: 0.020856
2022-01-14 15:25:07,973 iteration 1180 : loss : 0.066765, loss_ce: 0.027557
2022-01-14 15:25:09,418 iteration 1181 : loss : 0.064368, loss_ce: 0.020789
2022-01-14 15:25:10,900 iteration 1182 : loss : 0.056703, loss_ce: 0.023041
2022-01-14 15:25:12,408 iteration 1183 : loss : 0.050921, loss_ce: 0.020672
2022-01-14 15:25:13,935 iteration 1184 : loss : 0.083672, loss_ce: 0.036884
2022-01-14 15:25:15,421 iteration 1185 : loss : 0.052330, loss_ce: 0.028838
2022-01-14 15:25:16,974 iteration 1186 : loss : 0.041090, loss_ce: 0.014167
2022-01-14 15:25:18,405 iteration 1187 : loss : 0.039222, loss_ce: 0.017437
2022-01-14 15:25:19,936 iteration 1188 : loss : 0.067752, loss_ce: 0.024506
2022-01-14 15:25:21,498 iteration 1189 : loss : 0.092960, loss_ce: 0.023540
2022-01-14 15:25:21,498 Training Data Eval:
2022-01-14 15:25:28,951   Average segmentation loss on training set: 0.1008
2022-01-14 15:25:28,952 Validation Data Eval:
2022-01-14 15:25:31,519   Average segmentation loss on validation set: 0.1120
2022-01-14 15:25:33,000 iteration 1190 : loss : 0.053700, loss_ce: 0.017812
 18%|█████▎                        | 70/400 [32:53<2:41:36, 29.38s/it]2022-01-14 15:25:34,540 iteration 1191 : loss : 0.050957, loss_ce: 0.020506
2022-01-14 15:25:36,023 iteration 1192 : loss : 0.076437, loss_ce: 0.043855
2022-01-14 15:25:37,450 iteration 1193 : loss : 0.047493, loss_ce: 0.016375
2022-01-14 15:25:38,972 iteration 1194 : loss : 0.048513, loss_ce: 0.015923
2022-01-14 15:25:40,502 iteration 1195 : loss : 0.049354, loss_ce: 0.020595
2022-01-14 15:25:42,056 iteration 1196 : loss : 0.043003, loss_ce: 0.019906
2022-01-14 15:25:43,581 iteration 1197 : loss : 0.068743, loss_ce: 0.022400
2022-01-14 15:25:45,003 iteration 1198 : loss : 0.033732, loss_ce: 0.011730
2022-01-14 15:25:46,477 iteration 1199 : loss : 0.070577, loss_ce: 0.031591
2022-01-14 15:25:47,923 iteration 1200 : loss : 0.048993, loss_ce: 0.016849
2022-01-14 15:25:49,386 iteration 1201 : loss : 0.045729, loss_ce: 0.015884
2022-01-14 15:25:50,960 iteration 1202 : loss : 0.050053, loss_ce: 0.018717
2022-01-14 15:25:52,542 iteration 1203 : loss : 0.061861, loss_ce: 0.025411
2022-01-14 15:25:53,960 iteration 1204 : loss : 0.054003, loss_ce: 0.015099
2022-01-14 15:25:55,549 iteration 1205 : loss : 0.056927, loss_ce: 0.025016
2022-01-14 15:25:57,007 iteration 1206 : loss : 0.062041, loss_ce: 0.021756
2022-01-14 15:25:58,560 iteration 1207 : loss : 0.041316, loss_ce: 0.019245
 18%|█████▎                        | 71/400 [33:18<2:34:49, 28.24s/it]2022-01-14 15:26:00,069 iteration 1208 : loss : 0.071002, loss_ce: 0.029271
2022-01-14 15:26:01,574 iteration 1209 : loss : 0.043314, loss_ce: 0.016430
2022-01-14 15:26:03,007 iteration 1210 : loss : 0.046714, loss_ce: 0.016756
2022-01-14 15:26:04,581 iteration 1211 : loss : 0.044935, loss_ce: 0.019946
2022-01-14 15:26:06,059 iteration 1212 : loss : 0.037192, loss_ce: 0.015645
2022-01-14 15:26:07,467 iteration 1213 : loss : 0.036615, loss_ce: 0.013036
2022-01-14 15:26:09,054 iteration 1214 : loss : 0.070230, loss_ce: 0.028139
2022-01-14 15:26:10,553 iteration 1215 : loss : 0.037274, loss_ce: 0.014388
2022-01-14 15:26:12,015 iteration 1216 : loss : 0.053531, loss_ce: 0.017919
2022-01-14 15:26:13,673 iteration 1217 : loss : 0.072036, loss_ce: 0.027338
2022-01-14 15:26:15,117 iteration 1218 : loss : 0.049096, loss_ce: 0.024949
2022-01-14 15:26:16,738 iteration 1219 : loss : 0.059600, loss_ce: 0.029848
2022-01-14 15:26:18,255 iteration 1220 : loss : 0.048907, loss_ce: 0.018194
2022-01-14 15:26:19,839 iteration 1221 : loss : 0.041582, loss_ce: 0.015228
2022-01-14 15:26:21,294 iteration 1222 : loss : 0.051832, loss_ce: 0.018509
2022-01-14 15:26:22,851 iteration 1223 : loss : 0.060120, loss_ce: 0.022752
2022-01-14 15:26:24,364 iteration 1224 : loss : 0.067075, loss_ce: 0.023658
 18%|█████▍                        | 72/400 [33:44<2:30:22, 27.51s/it]2022-01-14 15:26:25,890 iteration 1225 : loss : 0.057338, loss_ce: 0.016516
2022-01-14 15:26:27,378 iteration 1226 : loss : 0.037591, loss_ce: 0.013377
2022-01-14 15:26:28,842 iteration 1227 : loss : 0.048822, loss_ce: 0.018163
2022-01-14 15:26:30,319 iteration 1228 : loss : 0.101538, loss_ce: 0.041220
2022-01-14 15:26:31,976 iteration 1229 : loss : 0.048662, loss_ce: 0.022679
2022-01-14 15:26:33,510 iteration 1230 : loss : 0.056785, loss_ce: 0.022521
2022-01-14 15:26:35,036 iteration 1231 : loss : 0.035251, loss_ce: 0.012996
2022-01-14 15:26:36,514 iteration 1232 : loss : 0.047869, loss_ce: 0.019317
2022-01-14 15:26:38,083 iteration 1233 : loss : 0.042137, loss_ce: 0.015172
2022-01-14 15:26:39,719 iteration 1234 : loss : 0.091226, loss_ce: 0.033235
2022-01-14 15:26:41,140 iteration 1235 : loss : 0.070037, loss_ce: 0.027384
2022-01-14 15:26:42,690 iteration 1236 : loss : 0.066201, loss_ce: 0.031147
2022-01-14 15:26:44,191 iteration 1237 : loss : 0.066894, loss_ce: 0.020111
2022-01-14 15:26:45,623 iteration 1238 : loss : 0.058981, loss_ce: 0.021860
2022-01-14 15:26:47,157 iteration 1239 : loss : 0.044129, loss_ce: 0.017877
2022-01-14 15:26:48,777 iteration 1240 : loss : 0.068977, loss_ce: 0.022636
2022-01-14 15:26:50,264 iteration 1241 : loss : 0.038035, loss_ce: 0.015566
 18%|█████▍                        | 73/400 [34:10<2:27:17, 27.03s/it]2022-01-14 15:26:51,856 iteration 1242 : loss : 0.053843, loss_ce: 0.030219
2022-01-14 15:26:53,329 iteration 1243 : loss : 0.050212, loss_ce: 0.018861
2022-01-14 15:26:54,940 iteration 1244 : loss : 0.064587, loss_ce: 0.025978
2022-01-14 15:26:56,509 iteration 1245 : loss : 0.052234, loss_ce: 0.017882
2022-01-14 15:26:58,010 iteration 1246 : loss : 0.067010, loss_ce: 0.032127
2022-01-14 15:26:59,892 iteration 1247 : loss : 0.090411, loss_ce: 0.037688
2022-01-14 15:27:01,462 iteration 1248 : loss : 0.052034, loss_ce: 0.018897
2022-01-14 15:27:02,990 iteration 1249 : loss : 0.062016, loss_ce: 0.026794
2022-01-14 15:27:04,480 iteration 1250 : loss : 0.079772, loss_ce: 0.018614
2022-01-14 15:27:06,036 iteration 1251 : loss : 0.048796, loss_ce: 0.022122
2022-01-14 15:27:07,454 iteration 1252 : loss : 0.074289, loss_ce: 0.022494
2022-01-14 15:27:08,951 iteration 1253 : loss : 0.060290, loss_ce: 0.029241
2022-01-14 15:27:10,503 iteration 1254 : loss : 0.046456, loss_ce: 0.015681
2022-01-14 15:27:12,113 iteration 1255 : loss : 0.086004, loss_ce: 0.041502
2022-01-14 15:27:13,620 iteration 1256 : loss : 0.045963, loss_ce: 0.015798
2022-01-14 15:27:15,058 iteration 1257 : loss : 0.040063, loss_ce: 0.015068
2022-01-14 15:27:16,486 iteration 1258 : loss : 0.045371, loss_ce: 0.021090
 18%|█████▌                        | 74/400 [34:36<2:25:31, 26.78s/it]2022-01-14 15:27:17,970 iteration 1259 : loss : 0.044977, loss_ce: 0.016717
2022-01-14 15:27:19,596 iteration 1260 : loss : 0.044639, loss_ce: 0.020208
2022-01-14 15:27:21,085 iteration 1261 : loss : 0.071304, loss_ce: 0.026841
2022-01-14 15:27:22,505 iteration 1262 : loss : 0.047802, loss_ce: 0.017378
2022-01-14 15:27:24,026 iteration 1263 : loss : 0.051826, loss_ce: 0.021978
2022-01-14 15:27:25,571 iteration 1264 : loss : 0.048742, loss_ce: 0.020602
2022-01-14 15:27:27,079 iteration 1265 : loss : 0.044418, loss_ce: 0.016761
2022-01-14 15:27:28,542 iteration 1266 : loss : 0.036438, loss_ce: 0.015635
2022-01-14 15:27:30,010 iteration 1267 : loss : 0.074510, loss_ce: 0.031982
2022-01-14 15:27:31,462 iteration 1268 : loss : 0.041875, loss_ce: 0.018370
2022-01-14 15:27:32,920 iteration 1269 : loss : 0.058289, loss_ce: 0.026653
2022-01-14 15:27:34,468 iteration 1270 : loss : 0.032191, loss_ce: 0.013414
2022-01-14 15:27:36,046 iteration 1271 : loss : 0.056509, loss_ce: 0.025630
2022-01-14 15:27:37,455 iteration 1272 : loss : 0.041713, loss_ce: 0.012842
2022-01-14 15:27:38,909 iteration 1273 : loss : 0.053075, loss_ce: 0.014965
2022-01-14 15:27:40,432 iteration 1274 : loss : 0.056041, loss_ce: 0.022437
2022-01-14 15:27:40,432 Training Data Eval:
2022-01-14 15:27:47,879   Average segmentation loss on training set: 0.0326
2022-01-14 15:27:47,880 Validation Data Eval:
2022-01-14 15:27:50,436   Average segmentation loss on validation set: 0.0745
2022-01-14 15:27:51,918 iteration 1275 : loss : 0.046680, loss_ce: 0.018628
 19%|█████▋                        | 75/400 [35:11<2:39:08, 29.38s/it]2022-01-14 15:27:53,429 iteration 1276 : loss : 0.037494, loss_ce: 0.016420
2022-01-14 15:27:55,109 iteration 1277 : loss : 0.049971, loss_ce: 0.019630
2022-01-14 15:27:56,621 iteration 1278 : loss : 0.069509, loss_ce: 0.025018
2022-01-14 15:27:58,115 iteration 1279 : loss : 0.049866, loss_ce: 0.016988
2022-01-14 15:27:59,630 iteration 1280 : loss : 0.040112, loss_ce: 0.018951
2022-01-14 15:28:01,070 iteration 1281 : loss : 0.055517, loss_ce: 0.023189
2022-01-14 15:28:02,572 iteration 1282 : loss : 0.033836, loss_ce: 0.015069
2022-01-14 15:28:03,972 iteration 1283 : loss : 0.053486, loss_ce: 0.015727
2022-01-14 15:28:05,482 iteration 1284 : loss : 0.037418, loss_ce: 0.014057
2022-01-14 15:28:06,919 iteration 1285 : loss : 0.045299, loss_ce: 0.015093
2022-01-14 15:28:08,476 iteration 1286 : loss : 0.050782, loss_ce: 0.016304
2022-01-14 15:28:10,000 iteration 1287 : loss : 0.037100, loss_ce: 0.015547
2022-01-14 15:28:11,457 iteration 1288 : loss : 0.041266, loss_ce: 0.014914
2022-01-14 15:28:12,969 iteration 1289 : loss : 0.054594, loss_ce: 0.021370
2022-01-14 15:28:14,417 iteration 1290 : loss : 0.090794, loss_ce: 0.036710
2022-01-14 15:28:15,870 iteration 1291 : loss : 0.045835, loss_ce: 0.017916
2022-01-14 15:28:17,329 iteration 1292 : loss : 0.071281, loss_ce: 0.043961
 19%|█████▋                        | 76/400 [35:37<2:32:14, 28.19s/it]2022-01-14 15:28:18,996 iteration 1293 : loss : 0.070418, loss_ce: 0.033181
2022-01-14 15:28:20,405 iteration 1294 : loss : 0.034310, loss_ce: 0.013870
2022-01-14 15:28:21,962 iteration 1295 : loss : 0.052647, loss_ce: 0.016398
2022-01-14 15:28:23,475 iteration 1296 : loss : 0.065433, loss_ce: 0.019091
2022-01-14 15:28:24,847 iteration 1297 : loss : 0.034321, loss_ce: 0.014483
2022-01-14 15:28:26,418 iteration 1298 : loss : 0.056880, loss_ce: 0.022720
2022-01-14 15:28:27,876 iteration 1299 : loss : 0.042660, loss_ce: 0.017457
2022-01-14 15:28:29,502 iteration 1300 : loss : 0.084485, loss_ce: 0.034475
2022-01-14 15:28:31,066 iteration 1301 : loss : 0.056718, loss_ce: 0.020348
2022-01-14 15:28:32,482 iteration 1302 : loss : 0.051411, loss_ce: 0.018017
2022-01-14 15:28:34,030 iteration 1303 : loss : 0.044314, loss_ce: 0.013347
2022-01-14 15:28:35,521 iteration 1304 : loss : 0.042045, loss_ce: 0.018003
2022-01-14 15:28:37,138 iteration 1305 : loss : 0.058798, loss_ce: 0.019522
2022-01-14 15:28:38,705 iteration 1306 : loss : 0.046462, loss_ce: 0.018930
2022-01-14 15:28:40,156 iteration 1307 : loss : 0.049094, loss_ce: 0.016277
2022-01-14 15:28:41,654 iteration 1308 : loss : 0.053452, loss_ce: 0.024112
2022-01-14 15:28:43,119 iteration 1309 : loss : 0.041798, loss_ce: 0.016567
 19%|█████▊                        | 77/400 [36:03<2:27:52, 27.47s/it]2022-01-14 15:28:44,611 iteration 1310 : loss : 0.058771, loss_ce: 0.021325
2022-01-14 15:28:46,228 iteration 1311 : loss : 0.065646, loss_ce: 0.022048
2022-01-14 15:28:47,747 iteration 1312 : loss : 0.048810, loss_ce: 0.018216
2022-01-14 15:28:49,244 iteration 1313 : loss : 0.038629, loss_ce: 0.014877
2022-01-14 15:28:50,817 iteration 1314 : loss : 0.052610, loss_ce: 0.024949
2022-01-14 15:28:52,375 iteration 1315 : loss : 0.040196, loss_ce: 0.022291
2022-01-14 15:28:53,836 iteration 1316 : loss : 0.047851, loss_ce: 0.021329
2022-01-14 15:28:55,265 iteration 1317 : loss : 0.039542, loss_ce: 0.015235
2022-01-14 15:28:56,730 iteration 1318 : loss : 0.040569, loss_ce: 0.014427
2022-01-14 15:28:58,266 iteration 1319 : loss : 0.058666, loss_ce: 0.019505
2022-01-14 15:28:59,684 iteration 1320 : loss : 0.037574, loss_ce: 0.013934
2022-01-14 15:29:01,202 iteration 1321 : loss : 0.063969, loss_ce: 0.031837
2022-01-14 15:29:02,691 iteration 1322 : loss : 0.040177, loss_ce: 0.013848
2022-01-14 15:29:04,268 iteration 1323 : loss : 0.049233, loss_ce: 0.016287
2022-01-14 15:29:05,864 iteration 1324 : loss : 0.034972, loss_ce: 0.013801
2022-01-14 15:29:07,346 iteration 1325 : loss : 0.046368, loss_ce: 0.020143
2022-01-14 15:29:08,854 iteration 1326 : loss : 0.040439, loss_ce: 0.014720
 20%|█████▊                        | 78/400 [36:28<2:24:37, 26.95s/it]2022-01-14 15:29:10,378 iteration 1327 : loss : 0.033343, loss_ce: 0.013393
2022-01-14 15:29:11,903 iteration 1328 : loss : 0.038239, loss_ce: 0.014634
2022-01-14 15:29:13,414 iteration 1329 : loss : 0.048973, loss_ce: 0.018852
2022-01-14 15:29:14,983 iteration 1330 : loss : 0.036541, loss_ce: 0.011467
2022-01-14 15:29:16,490 iteration 1331 : loss : 0.046840, loss_ce: 0.018084
2022-01-14 15:29:17,962 iteration 1332 : loss : 0.047926, loss_ce: 0.018541
2022-01-14 15:29:19,421 iteration 1333 : loss : 0.045091, loss_ce: 0.017455
2022-01-14 15:29:20,949 iteration 1334 : loss : 0.047485, loss_ce: 0.022938
2022-01-14 15:29:22,492 iteration 1335 : loss : 0.043837, loss_ce: 0.018973
2022-01-14 15:29:23,958 iteration 1336 : loss : 0.041064, loss_ce: 0.019175
2022-01-14 15:29:25,540 iteration 1337 : loss : 0.056122, loss_ce: 0.022018
2022-01-14 15:29:27,003 iteration 1338 : loss : 0.033530, loss_ce: 0.014798
2022-01-14 15:29:28,462 iteration 1339 : loss : 0.064388, loss_ce: 0.026725
2022-01-14 15:29:29,936 iteration 1340 : loss : 0.029212, loss_ce: 0.011493
2022-01-14 15:29:31,444 iteration 1341 : loss : 0.048032, loss_ce: 0.018191
2022-01-14 15:29:33,051 iteration 1342 : loss : 0.050311, loss_ce: 0.017152
2022-01-14 15:29:34,457 iteration 1343 : loss : 0.040124, loss_ce: 0.012274
 20%|█████▉                        | 79/400 [36:54<2:22:00, 26.54s/it]2022-01-14 15:29:36,054 iteration 1344 : loss : 0.036412, loss_ce: 0.012414
2022-01-14 15:29:37,507 iteration 1345 : loss : 0.044235, loss_ce: 0.013142
2022-01-14 15:29:39,053 iteration 1346 : loss : 0.046992, loss_ce: 0.017409
2022-01-14 15:29:40,567 iteration 1347 : loss : 0.039720, loss_ce: 0.017361
2022-01-14 15:29:42,026 iteration 1348 : loss : 0.052428, loss_ce: 0.024072
2022-01-14 15:29:43,543 iteration 1349 : loss : 0.057383, loss_ce: 0.020942
2022-01-14 15:29:45,023 iteration 1350 : loss : 0.049672, loss_ce: 0.016320
2022-01-14 15:29:46,618 iteration 1351 : loss : 0.074534, loss_ce: 0.034836
2022-01-14 15:29:48,048 iteration 1352 : loss : 0.046488, loss_ce: 0.022403
2022-01-14 15:29:49,541 iteration 1353 : loss : 0.035944, loss_ce: 0.014891
2022-01-14 15:29:51,073 iteration 1354 : loss : 0.048268, loss_ce: 0.018377
2022-01-14 15:29:52,487 iteration 1355 : loss : 0.057540, loss_ce: 0.018857
2022-01-14 15:29:54,045 iteration 1356 : loss : 0.056297, loss_ce: 0.019531
2022-01-14 15:29:55,492 iteration 1357 : loss : 0.036155, loss_ce: 0.017141
2022-01-14 15:29:56,961 iteration 1358 : loss : 0.043405, loss_ce: 0.021350
2022-01-14 15:29:58,565 iteration 1359 : loss : 0.045789, loss_ce: 0.022967
2022-01-14 15:29:58,565 Training Data Eval:
2022-01-14 15:30:06,031   Average segmentation loss on training set: 0.0591
2022-01-14 15:30:06,032 Validation Data Eval:
2022-01-14 15:30:08,599   Average segmentation loss on validation set: 0.0888
2022-01-14 15:30:10,143 iteration 1360 : loss : 0.039413, loss_ce: 0.015427
 20%|██████                        | 80/400 [37:30<2:36:11, 29.29s/it]2022-01-14 15:30:11,764 iteration 1361 : loss : 0.061305, loss_ce: 0.018753
2022-01-14 15:30:13,234 iteration 1362 : loss : 0.059445, loss_ce: 0.018206
2022-01-14 15:30:14,741 iteration 1363 : loss : 0.030421, loss_ce: 0.011924
2022-01-14 15:30:16,168 iteration 1364 : loss : 0.051826, loss_ce: 0.024747
2022-01-14 15:30:17,642 iteration 1365 : loss : 0.047719, loss_ce: 0.014668
2022-01-14 15:30:19,240 iteration 1366 : loss : 0.055559, loss_ce: 0.018825
2022-01-14 15:30:20,756 iteration 1367 : loss : 0.059590, loss_ce: 0.031210
2022-01-14 15:30:22,450 iteration 1368 : loss : 0.046779, loss_ce: 0.018271
2022-01-14 15:30:23,930 iteration 1369 : loss : 0.043455, loss_ce: 0.017797
2022-01-14 15:30:25,383 iteration 1370 : loss : 0.055133, loss_ce: 0.024373
2022-01-14 15:30:26,861 iteration 1371 : loss : 0.040132, loss_ce: 0.015494
2022-01-14 15:30:28,543 iteration 1372 : loss : 0.059131, loss_ce: 0.021701
2022-01-14 15:30:30,018 iteration 1373 : loss : 0.043620, loss_ce: 0.019429
2022-01-14 15:30:31,483 iteration 1374 : loss : 0.046696, loss_ce: 0.018298
2022-01-14 15:30:32,927 iteration 1375 : loss : 0.034184, loss_ce: 0.014059
2022-01-14 15:30:34,408 iteration 1376 : loss : 0.032614, loss_ce: 0.010134
2022-01-14 15:30:35,991 iteration 1377 : loss : 0.047975, loss_ce: 0.024308
 20%|██████                        | 81/400 [37:56<2:30:13, 28.26s/it]2022-01-14 15:30:37,647 iteration 1378 : loss : 0.047653, loss_ce: 0.023244
2022-01-14 15:30:39,195 iteration 1379 : loss : 0.048104, loss_ce: 0.021802
2022-01-14 15:30:40,729 iteration 1380 : loss : 0.078119, loss_ce: 0.024481
2022-01-14 15:30:42,294 iteration 1381 : loss : 0.040744, loss_ce: 0.015688
2022-01-14 15:30:43,834 iteration 1382 : loss : 0.053883, loss_ce: 0.022123
2022-01-14 15:30:45,266 iteration 1383 : loss : 0.053113, loss_ce: 0.014826
2022-01-14 15:30:46,812 iteration 1384 : loss : 0.049870, loss_ce: 0.021952
2022-01-14 15:30:48,340 iteration 1385 : loss : 0.036670, loss_ce: 0.014763
2022-01-14 15:30:49,868 iteration 1386 : loss : 0.057693, loss_ce: 0.020810
2022-01-14 15:30:51,472 iteration 1387 : loss : 0.061589, loss_ce: 0.021273
2022-01-14 15:30:52,935 iteration 1388 : loss : 0.066655, loss_ce: 0.025851
2022-01-14 15:30:54,415 iteration 1389 : loss : 0.040449, loss_ce: 0.014675
2022-01-14 15:30:55,944 iteration 1390 : loss : 0.037530, loss_ce: 0.015858
2022-01-14 15:30:57,483 iteration 1391 : loss : 0.057221, loss_ce: 0.016909
2022-01-14 15:30:59,001 iteration 1392 : loss : 0.043043, loss_ce: 0.015800
2022-01-14 15:31:00,452 iteration 1393 : loss : 0.043626, loss_ce: 0.013940
2022-01-14 15:31:01,944 iteration 1394 : loss : 0.030621, loss_ce: 0.013716
 20%|██████▏                       | 82/400 [38:22<2:26:05, 27.57s/it]2022-01-14 15:31:03,498 iteration 1395 : loss : 0.037943, loss_ce: 0.013477
2022-01-14 15:31:04,977 iteration 1396 : loss : 0.046620, loss_ce: 0.018412
2022-01-14 15:31:06,528 iteration 1397 : loss : 0.050027, loss_ce: 0.016317
2022-01-14 15:31:08,155 iteration 1398 : loss : 0.035902, loss_ce: 0.015948
2022-01-14 15:31:09,726 iteration 1399 : loss : 0.049724, loss_ce: 0.023875
2022-01-14 15:31:11,219 iteration 1400 : loss : 0.053038, loss_ce: 0.022521
2022-01-14 15:31:12,682 iteration 1401 : loss : 0.052733, loss_ce: 0.018744
2022-01-14 15:31:14,107 iteration 1402 : loss : 0.035465, loss_ce: 0.013682
2022-01-14 15:31:15,701 iteration 1403 : loss : 0.061721, loss_ce: 0.021893
2022-01-14 15:31:17,266 iteration 1404 : loss : 0.049147, loss_ce: 0.019956
2022-01-14 15:31:18,780 iteration 1405 : loss : 0.043286, loss_ce: 0.018703
2022-01-14 15:31:20,314 iteration 1406 : loss : 0.042200, loss_ce: 0.013456
2022-01-14 15:31:21,758 iteration 1407 : loss : 0.042398, loss_ce: 0.020683
2022-01-14 15:31:23,242 iteration 1408 : loss : 0.063865, loss_ce: 0.020786
2022-01-14 15:31:24,861 iteration 1409 : loss : 0.082504, loss_ce: 0.026103
2022-01-14 15:31:26,416 iteration 1410 : loss : 0.040981, loss_ce: 0.013473
2022-01-14 15:31:27,897 iteration 1411 : loss : 0.040745, loss_ce: 0.017815
 21%|██████▏                       | 83/400 [38:47<2:23:03, 27.08s/it]2022-01-14 15:31:29,319 iteration 1412 : loss : 0.038926, loss_ce: 0.012391
2022-01-14 15:31:30,883 iteration 1413 : loss : 0.048075, loss_ce: 0.017523
2022-01-14 15:31:32,371 iteration 1414 : loss : 0.038298, loss_ce: 0.016660
2022-01-14 15:31:33,796 iteration 1415 : loss : 0.069546, loss_ce: 0.020822
2022-01-14 15:31:35,327 iteration 1416 : loss : 0.035918, loss_ce: 0.009668
2022-01-14 15:31:36,902 iteration 1417 : loss : 0.038152, loss_ce: 0.015476
2022-01-14 15:31:38,343 iteration 1418 : loss : 0.034233, loss_ce: 0.011306
2022-01-14 15:31:39,989 iteration 1419 : loss : 0.056319, loss_ce: 0.017616
2022-01-14 15:31:41,543 iteration 1420 : loss : 0.050831, loss_ce: 0.016470
2022-01-14 15:31:43,000 iteration 1421 : loss : 0.055798, loss_ce: 0.022906
2022-01-14 15:31:44,500 iteration 1422 : loss : 0.053690, loss_ce: 0.025157
2022-01-14 15:31:45,957 iteration 1423 : loss : 0.061818, loss_ce: 0.022200
2022-01-14 15:31:47,494 iteration 1424 : loss : 0.051681, loss_ce: 0.018844
2022-01-14 15:31:49,073 iteration 1425 : loss : 0.053259, loss_ce: 0.023871
2022-01-14 15:31:50,448 iteration 1426 : loss : 0.038236, loss_ce: 0.015003
2022-01-14 15:31:51,915 iteration 1427 : loss : 0.037568, loss_ce: 0.016458
2022-01-14 15:31:53,429 iteration 1428 : loss : 0.049964, loss_ce: 0.019312
 21%|██████▎                       | 84/400 [39:13<2:20:10, 26.62s/it]2022-01-14 15:31:55,063 iteration 1429 : loss : 0.059791, loss_ce: 0.026198
2022-01-14 15:31:56,512 iteration 1430 : loss : 0.062644, loss_ce: 0.019207
2022-01-14 15:31:58,010 iteration 1431 : loss : 0.036484, loss_ce: 0.014671
2022-01-14 15:31:59,525 iteration 1432 : loss : 0.044551, loss_ce: 0.017075
2022-01-14 15:32:01,136 iteration 1433 : loss : 0.060190, loss_ce: 0.022782
2022-01-14 15:32:02,699 iteration 1434 : loss : 0.056371, loss_ce: 0.025732
2022-01-14 15:32:04,093 iteration 1435 : loss : 0.044386, loss_ce: 0.012622
2022-01-14 15:32:05,651 iteration 1436 : loss : 0.043910, loss_ce: 0.019658
2022-01-14 15:32:07,077 iteration 1437 : loss : 0.079165, loss_ce: 0.017306
2022-01-14 15:32:08,484 iteration 1438 : loss : 0.034522, loss_ce: 0.016038
2022-01-14 15:32:09,982 iteration 1439 : loss : 0.034217, loss_ce: 0.010676
2022-01-14 15:32:11,586 iteration 1440 : loss : 0.044574, loss_ce: 0.021073
2022-01-14 15:32:13,054 iteration 1441 : loss : 0.029613, loss_ce: 0.011935
2022-01-14 15:32:14,484 iteration 1442 : loss : 0.050515, loss_ce: 0.019529
2022-01-14 15:32:16,025 iteration 1443 : loss : 0.041817, loss_ce: 0.015907
2022-01-14 15:32:17,602 iteration 1444 : loss : 0.050625, loss_ce: 0.024520
2022-01-14 15:32:17,602 Training Data Eval:
2022-01-14 15:32:25,045   Average segmentation loss on training set: 0.0343
2022-01-14 15:32:25,045 Validation Data Eval:
2022-01-14 15:32:27,604   Average segmentation loss on validation set: 0.0752
2022-01-14 15:32:29,140 iteration 1445 : loss : 0.049143, loss_ce: 0.016559
 21%|██████▍                       | 85/400 [39:49<2:34:03, 29.35s/it]2022-01-14 15:32:30,764 iteration 1446 : loss : 0.047331, loss_ce: 0.015762
2022-01-14 15:32:32,287 iteration 1447 : loss : 0.064764, loss_ce: 0.025395
2022-01-14 15:32:33,793 iteration 1448 : loss : 0.056518, loss_ce: 0.028649
2022-01-14 15:32:35,290 iteration 1449 : loss : 0.045231, loss_ce: 0.016398
2022-01-14 15:32:36,705 iteration 1450 : loss : 0.057880, loss_ce: 0.027057
2022-01-14 15:32:38,143 iteration 1451 : loss : 0.035978, loss_ce: 0.012169
2022-01-14 15:32:39,651 iteration 1452 : loss : 0.074818, loss_ce: 0.016857
2022-01-14 15:32:41,253 iteration 1453 : loss : 0.050205, loss_ce: 0.015668
2022-01-14 15:32:42,742 iteration 1454 : loss : 0.043239, loss_ce: 0.018458
2022-01-14 15:32:44,204 iteration 1455 : loss : 0.046516, loss_ce: 0.020777
2022-01-14 15:32:45,701 iteration 1456 : loss : 0.047446, loss_ce: 0.015921
2022-01-14 15:32:47,220 iteration 1457 : loss : 0.037949, loss_ce: 0.017682
2022-01-14 15:32:48,718 iteration 1458 : loss : 0.038100, loss_ce: 0.013377
2022-01-14 15:32:50,126 iteration 1459 : loss : 0.045169, loss_ce: 0.017575
2022-01-14 15:32:51,694 iteration 1460 : loss : 0.061677, loss_ce: 0.033149
2022-01-14 15:32:53,165 iteration 1461 : loss : 0.036139, loss_ce: 0.012797
2022-01-14 15:32:54,680 iteration 1462 : loss : 0.047529, loss_ce: 0.018591
 22%|██████▍                       | 86/400 [40:14<2:27:35, 28.20s/it]2022-01-14 15:32:56,218 iteration 1463 : loss : 0.038431, loss_ce: 0.016329
2022-01-14 15:32:57,769 iteration 1464 : loss : 0.044667, loss_ce: 0.015685
2022-01-14 15:32:59,343 iteration 1465 : loss : 0.060407, loss_ce: 0.027208
2022-01-14 15:33:00,827 iteration 1466 : loss : 0.042317, loss_ce: 0.015053
2022-01-14 15:33:02,338 iteration 1467 : loss : 0.051991, loss_ce: 0.021667
2022-01-14 15:33:03,856 iteration 1468 : loss : 0.062764, loss_ce: 0.022894
2022-01-14 15:33:05,353 iteration 1469 : loss : 0.026354, loss_ce: 0.011561
2022-01-14 15:33:06,855 iteration 1470 : loss : 0.035763, loss_ce: 0.012948
2022-01-14 15:33:08,270 iteration 1471 : loss : 0.035500, loss_ce: 0.011303
2022-01-14 15:33:09,771 iteration 1472 : loss : 0.039689, loss_ce: 0.012407
2022-01-14 15:33:11,349 iteration 1473 : loss : 0.043555, loss_ce: 0.021746
2022-01-14 15:33:12,791 iteration 1474 : loss : 0.041995, loss_ce: 0.018152
2022-01-14 15:33:14,313 iteration 1475 : loss : 0.046704, loss_ce: 0.014779
2022-01-14 15:33:15,873 iteration 1476 : loss : 0.061880, loss_ce: 0.032701
2022-01-14 15:33:17,371 iteration 1477 : loss : 0.040015, loss_ce: 0.012959
2022-01-14 15:33:18,928 iteration 1478 : loss : 0.039365, loss_ce: 0.013611
2022-01-14 15:33:20,451 iteration 1479 : loss : 0.064684, loss_ce: 0.029102
 22%|██████▌                       | 87/400 [40:40<2:23:19, 27.47s/it]2022-01-14 15:33:21,998 iteration 1480 : loss : 0.041422, loss_ce: 0.020762
2022-01-14 15:33:23,558 iteration 1481 : loss : 0.037607, loss_ce: 0.015532
2022-01-14 15:33:25,037 iteration 1482 : loss : 0.040799, loss_ce: 0.017438
2022-01-14 15:33:26,447 iteration 1483 : loss : 0.033908, loss_ce: 0.013595
2022-01-14 15:33:27,901 iteration 1484 : loss : 0.042876, loss_ce: 0.017618
2022-01-14 15:33:29,389 iteration 1485 : loss : 0.052257, loss_ce: 0.019655
2022-01-14 15:33:30,862 iteration 1486 : loss : 0.061704, loss_ce: 0.019572
2022-01-14 15:33:32,462 iteration 1487 : loss : 0.085634, loss_ce: 0.044664
2022-01-14 15:33:33,937 iteration 1488 : loss : 0.038063, loss_ce: 0.013044
2022-01-14 15:33:35,484 iteration 1489 : loss : 0.035328, loss_ce: 0.014839
2022-01-14 15:33:36,988 iteration 1490 : loss : 0.036734, loss_ce: 0.016916
2022-01-14 15:33:38,437 iteration 1491 : loss : 0.042138, loss_ce: 0.012939
2022-01-14 15:33:39,980 iteration 1492 : loss : 0.063036, loss_ce: 0.031184
2022-01-14 15:33:41,594 iteration 1493 : loss : 0.070753, loss_ce: 0.029083
2022-01-14 15:33:43,131 iteration 1494 : loss : 0.058773, loss_ce: 0.020030
2022-01-14 15:33:44,620 iteration 1495 : loss : 0.053029, loss_ce: 0.016710
2022-01-14 15:33:46,152 iteration 1496 : loss : 0.046514, loss_ce: 0.017737
 22%|██████▌                       | 88/400 [41:06<2:20:06, 26.94s/it]2022-01-14 15:33:47,655 iteration 1497 : loss : 0.031021, loss_ce: 0.012836
2022-01-14 15:33:49,024 iteration 1498 : loss : 0.033377, loss_ce: 0.015043
2022-01-14 15:33:50,459 iteration 1499 : loss : 0.044838, loss_ce: 0.018841
2022-01-14 15:33:52,117 iteration 1500 : loss : 0.067714, loss_ce: 0.024532
2022-01-14 15:33:53,559 iteration 1501 : loss : 0.034467, loss_ce: 0.011497
2022-01-14 15:33:55,068 iteration 1502 : loss : 0.072493, loss_ce: 0.022684
2022-01-14 15:33:56,666 iteration 1503 : loss : 0.045047, loss_ce: 0.017344
2022-01-14 15:33:58,140 iteration 1504 : loss : 0.051843, loss_ce: 0.022464
2022-01-14 15:33:59,618 iteration 1505 : loss : 0.035685, loss_ce: 0.015395
2022-01-14 15:34:01,204 iteration 1506 : loss : 0.040836, loss_ce: 0.014324
2022-01-14 15:34:02,680 iteration 1507 : loss : 0.042897, loss_ce: 0.019287
2022-01-14 15:34:04,189 iteration 1508 : loss : 0.128158, loss_ce: 0.025348
2022-01-14 15:34:05,665 iteration 1509 : loss : 0.036458, loss_ce: 0.015696
2022-01-14 15:34:07,158 iteration 1510 : loss : 0.047570, loss_ce: 0.014907
2022-01-14 15:34:08,796 iteration 1511 : loss : 0.089530, loss_ce: 0.056504
2022-01-14 15:34:10,327 iteration 1512 : loss : 0.044584, loss_ce: 0.017007
2022-01-14 15:34:11,827 iteration 1513 : loss : 0.046416, loss_ce: 0.018980
 22%|██████▋                       | 89/400 [41:31<2:17:40, 26.56s/it]2022-01-14 15:34:13,377 iteration 1514 : loss : 0.046381, loss_ce: 0.017465
2022-01-14 15:34:14,914 iteration 1515 : loss : 0.038927, loss_ce: 0.016286
2022-01-14 15:34:16,468 iteration 1516 : loss : 0.044932, loss_ce: 0.027370
2022-01-14 15:34:17,922 iteration 1517 : loss : 0.034183, loss_ce: 0.015877
2022-01-14 15:34:19,355 iteration 1518 : loss : 0.038844, loss_ce: 0.017536
2022-01-14 15:34:20,838 iteration 1519 : loss : 0.036994, loss_ce: 0.014981
2022-01-14 15:34:22,481 iteration 1520 : loss : 0.057143, loss_ce: 0.024267
2022-01-14 15:34:23,922 iteration 1521 : loss : 0.039388, loss_ce: 0.013376
2022-01-14 15:34:25,511 iteration 1522 : loss : 0.040646, loss_ce: 0.013904
2022-01-14 15:34:27,005 iteration 1523 : loss : 0.053027, loss_ce: 0.019867
2022-01-14 15:34:28,453 iteration 1524 : loss : 0.034630, loss_ce: 0.013874
2022-01-14 15:34:29,932 iteration 1525 : loss : 0.048256, loss_ce: 0.022109
2022-01-14 15:34:31,429 iteration 1526 : loss : 0.040173, loss_ce: 0.015523
2022-01-14 15:34:33,028 iteration 1527 : loss : 0.039968, loss_ce: 0.015771
2022-01-14 15:34:34,566 iteration 1528 : loss : 0.057938, loss_ce: 0.019792
2022-01-14 15:34:36,052 iteration 1529 : loss : 0.059201, loss_ce: 0.015306
2022-01-14 15:34:36,052 Training Data Eval:
2022-01-14 15:34:43,530   Average segmentation loss on training set: 0.0422
2022-01-14 15:34:43,530 Validation Data Eval:
2022-01-14 15:34:46,092   Average segmentation loss on validation set: 0.1566
2022-01-14 15:34:47,538 iteration 1530 : loss : 0.051184, loss_ce: 0.024290
 22%|██████▊                       | 90/400 [42:07<2:31:25, 29.31s/it]2022-01-14 15:34:49,124 iteration 1531 : loss : 0.053474, loss_ce: 0.022477
2022-01-14 15:34:50,687 iteration 1532 : loss : 0.058049, loss_ce: 0.024404
2022-01-14 15:34:52,158 iteration 1533 : loss : 0.036195, loss_ce: 0.013400
2022-01-14 15:34:53,635 iteration 1534 : loss : 0.031048, loss_ce: 0.014496
2022-01-14 15:34:55,095 iteration 1535 : loss : 0.035172, loss_ce: 0.015052
2022-01-14 15:34:56,634 iteration 1536 : loss : 0.063424, loss_ce: 0.018034
2022-01-14 15:34:58,108 iteration 1537 : loss : 0.034631, loss_ce: 0.018502
2022-01-14 15:34:59,486 iteration 1538 : loss : 0.073722, loss_ce: 0.021389
2022-01-14 15:35:00,921 iteration 1539 : loss : 0.036557, loss_ce: 0.015772
2022-01-14 15:35:02,419 iteration 1540 : loss : 0.035512, loss_ce: 0.016948
2022-01-14 15:35:03,988 iteration 1541 : loss : 0.043130, loss_ce: 0.017486
2022-01-14 15:35:05,624 iteration 1542 : loss : 0.032884, loss_ce: 0.013843
2022-01-14 15:35:07,120 iteration 1543 : loss : 0.048532, loss_ce: 0.012638
2022-01-14 15:35:08,639 iteration 1544 : loss : 0.038280, loss_ce: 0.016817
2022-01-14 15:35:10,057 iteration 1545 : loss : 0.045660, loss_ce: 0.016393
2022-01-14 15:35:11,529 iteration 1546 : loss : 0.043670, loss_ce: 0.013442
2022-01-14 15:35:13,065 iteration 1547 : loss : 0.043654, loss_ce: 0.017937
 23%|██████▊                       | 91/400 [42:33<2:25:05, 28.17s/it]2022-01-14 15:35:14,591 iteration 1548 : loss : 0.044379, loss_ce: 0.012855
2022-01-14 15:35:16,021 iteration 1549 : loss : 0.040997, loss_ce: 0.012055
2022-01-14 15:35:17,535 iteration 1550 : loss : 0.043283, loss_ce: 0.011820
2022-01-14 15:35:19,074 iteration 1551 : loss : 0.062991, loss_ce: 0.020386
2022-01-14 15:35:20,588 iteration 1552 : loss : 0.038905, loss_ce: 0.009455
2022-01-14 15:35:22,159 iteration 1553 : loss : 0.052267, loss_ce: 0.023938
2022-01-14 15:35:23,551 iteration 1554 : loss : 0.054023, loss_ce: 0.027440
2022-01-14 15:35:24,984 iteration 1555 : loss : 0.039411, loss_ce: 0.012194
2022-01-14 15:35:26,621 iteration 1556 : loss : 0.036515, loss_ce: 0.014501
2022-01-14 15:35:28,111 iteration 1557 : loss : 0.037863, loss_ce: 0.014652
2022-01-14 15:35:29,536 iteration 1558 : loss : 0.039417, loss_ce: 0.013863
2022-01-14 15:35:31,117 iteration 1559 : loss : 0.047418, loss_ce: 0.017700
2022-01-14 15:35:32,572 iteration 1560 : loss : 0.046060, loss_ce: 0.025004
2022-01-14 15:35:34,072 iteration 1561 : loss : 0.036398, loss_ce: 0.014396
2022-01-14 15:35:35,550 iteration 1562 : loss : 0.040764, loss_ce: 0.022090
2022-01-14 15:35:37,071 iteration 1563 : loss : 0.044250, loss_ce: 0.017647
2022-01-14 15:35:38,535 iteration 1564 : loss : 0.048450, loss_ce: 0.016507
 23%|██████▉                       | 92/400 [42:58<2:20:28, 27.36s/it]2022-01-14 15:35:40,074 iteration 1565 : loss : 0.031405, loss_ce: 0.014939
2022-01-14 15:35:41,620 iteration 1566 : loss : 0.057315, loss_ce: 0.016729
2022-01-14 15:35:43,137 iteration 1567 : loss : 0.038703, loss_ce: 0.016031
2022-01-14 15:35:44,793 iteration 1568 : loss : 0.046416, loss_ce: 0.016405
2022-01-14 15:35:46,297 iteration 1569 : loss : 0.046631, loss_ce: 0.021596
2022-01-14 15:35:47,833 iteration 1570 : loss : 0.041669, loss_ce: 0.017084
2022-01-14 15:35:49,322 iteration 1571 : loss : 0.042554, loss_ce: 0.014255
2022-01-14 15:35:50,917 iteration 1572 : loss : 0.049558, loss_ce: 0.016544
2022-01-14 15:35:52,336 iteration 1573 : loss : 0.044313, loss_ce: 0.023066
2022-01-14 15:35:53,908 iteration 1574 : loss : 0.039347, loss_ce: 0.015226
2022-01-14 15:35:55,518 iteration 1575 : loss : 0.055527, loss_ce: 0.026022
2022-01-14 15:35:57,076 iteration 1576 : loss : 0.042559, loss_ce: 0.020174
2022-01-14 15:35:58,465 iteration 1577 : loss : 0.033851, loss_ce: 0.011986
2022-01-14 15:35:59,954 iteration 1578 : loss : 0.031834, loss_ce: 0.010512
2022-01-14 15:36:01,540 iteration 1579 : loss : 0.062486, loss_ce: 0.022687
2022-01-14 15:36:03,058 iteration 1580 : loss : 0.061930, loss_ce: 0.022365
2022-01-14 15:36:04,693 iteration 1581 : loss : 0.035281, loss_ce: 0.015009
 23%|██████▉                       | 93/400 [43:24<2:18:09, 27.00s/it]2022-01-14 15:36:06,224 iteration 1582 : loss : 0.030365, loss_ce: 0.011773
2022-01-14 15:36:07,741 iteration 1583 : loss : 0.037629, loss_ce: 0.014896
2022-01-14 15:36:09,173 iteration 1584 : loss : 0.041244, loss_ce: 0.013394
2022-01-14 15:36:10,666 iteration 1585 : loss : 0.083240, loss_ce: 0.023746
2022-01-14 15:36:12,276 iteration 1586 : loss : 0.049540, loss_ce: 0.017298
2022-01-14 15:36:13,800 iteration 1587 : loss : 0.039075, loss_ce: 0.012153
2022-01-14 15:36:15,399 iteration 1588 : loss : 0.043108, loss_ce: 0.018305
2022-01-14 15:36:16,940 iteration 1589 : loss : 0.048506, loss_ce: 0.012324
2022-01-14 15:36:18,503 iteration 1590 : loss : 0.057454, loss_ce: 0.027037
2022-01-14 15:36:19,990 iteration 1591 : loss : 0.065262, loss_ce: 0.029619
2022-01-14 15:36:21,459 iteration 1592 : loss : 0.060246, loss_ce: 0.028386
2022-01-14 15:36:23,045 iteration 1593 : loss : 0.056457, loss_ce: 0.017642
2022-01-14 15:36:24,553 iteration 1594 : loss : 0.042143, loss_ce: 0.022827
2022-01-14 15:36:26,089 iteration 1595 : loss : 0.065014, loss_ce: 0.033881
2022-01-14 15:36:27,633 iteration 1596 : loss : 0.032993, loss_ce: 0.013098
2022-01-14 15:36:29,102 iteration 1597 : loss : 0.042834, loss_ce: 0.014340
2022-01-14 15:36:30,650 iteration 1598 : loss : 0.044148, loss_ce: 0.020012
 24%|███████                       | 94/400 [43:50<2:16:06, 26.69s/it]2022-01-14 15:36:32,224 iteration 1599 : loss : 0.027987, loss_ce: 0.011368
2022-01-14 15:36:33,721 iteration 1600 : loss : 0.045358, loss_ce: 0.016072
2022-01-14 15:36:35,213 iteration 1601 : loss : 0.050874, loss_ce: 0.016928
2022-01-14 15:36:36,671 iteration 1602 : loss : 0.043931, loss_ce: 0.018684
2022-01-14 15:36:38,274 iteration 1603 : loss : 0.052681, loss_ce: 0.021757
2022-01-14 15:36:39,768 iteration 1604 : loss : 0.062012, loss_ce: 0.028423
2022-01-14 15:36:41,339 iteration 1605 : loss : 0.033871, loss_ce: 0.012375
2022-01-14 15:36:42,913 iteration 1606 : loss : 0.041373, loss_ce: 0.013830
2022-01-14 15:36:44,411 iteration 1607 : loss : 0.049581, loss_ce: 0.019685
2022-01-14 15:36:45,968 iteration 1608 : loss : 0.034653, loss_ce: 0.011991
2022-01-14 15:36:47,521 iteration 1609 : loss : 0.037865, loss_ce: 0.013336
2022-01-14 15:36:49,024 iteration 1610 : loss : 0.054428, loss_ce: 0.021398
2022-01-14 15:36:50,569 iteration 1611 : loss : 0.051717, loss_ce: 0.019060
2022-01-14 15:36:52,044 iteration 1612 : loss : 0.043313, loss_ce: 0.018841
2022-01-14 15:36:53,576 iteration 1613 : loss : 0.047525, loss_ce: 0.017450
2022-01-14 15:36:55,102 iteration 1614 : loss : 0.045231, loss_ce: 0.016061
2022-01-14 15:36:55,103 Training Data Eval:
2022-01-14 15:37:02,549   Average segmentation loss on training set: 0.0332
2022-01-14 15:37:02,550 Validation Data Eval:
2022-01-14 15:37:05,108   Average segmentation loss on validation set: 0.0616
2022-01-14 15:37:10,936 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed100.pth
2022-01-14 15:37:12,380 iteration 1615 : loss : 0.041861, loss_ce: 0.018620
 24%|███████▏                      | 95/400 [44:32<2:38:36, 31.20s/it]2022-01-14 15:37:13,793 iteration 1616 : loss : 0.043903, loss_ce: 0.012227
2022-01-14 15:37:15,120 iteration 1617 : loss : 0.031330, loss_ce: 0.013747
2022-01-14 15:37:16,501 iteration 1618 : loss : 0.030368, loss_ce: 0.011230
2022-01-14 15:37:17,960 iteration 1619 : loss : 0.033349, loss_ce: 0.017388
2022-01-14 15:37:19,301 iteration 1620 : loss : 0.040204, loss_ce: 0.015590
2022-01-14 15:37:20,798 iteration 1621 : loss : 0.040625, loss_ce: 0.015880
2022-01-14 15:37:22,181 iteration 1622 : loss : 0.050418, loss_ce: 0.017407
2022-01-14 15:37:23,506 iteration 1623 : loss : 0.026996, loss_ce: 0.012261
2022-01-14 15:37:24,951 iteration 1624 : loss : 0.045593, loss_ce: 0.018155
2022-01-14 15:37:26,348 iteration 1625 : loss : 0.031584, loss_ce: 0.016301
2022-01-14 15:37:27,858 iteration 1626 : loss : 0.037558, loss_ce: 0.014608
2022-01-14 15:37:29,296 iteration 1627 : loss : 0.041823, loss_ce: 0.012598
2022-01-14 15:37:30,864 iteration 1628 : loss : 0.055067, loss_ce: 0.015655
2022-01-14 15:37:32,415 iteration 1629 : loss : 0.070707, loss_ce: 0.034557
2022-01-14 15:37:33,839 iteration 1630 : loss : 0.038595, loss_ce: 0.013411
2022-01-14 15:37:35,346 iteration 1631 : loss : 0.052682, loss_ce: 0.021924
2022-01-14 15:37:36,742 iteration 1632 : loss : 0.031605, loss_ce: 0.010843
 24%|███████▏                      | 96/400 [44:56<2:27:41, 29.15s/it]2022-01-14 15:37:38,348 iteration 1633 : loss : 0.038560, loss_ce: 0.014049
2022-01-14 15:37:39,895 iteration 1634 : loss : 0.044079, loss_ce: 0.019533
2022-01-14 15:37:41,381 iteration 1635 : loss : 0.040951, loss_ce: 0.017399
2022-01-14 15:37:42,788 iteration 1636 : loss : 0.032389, loss_ce: 0.013455
2022-01-14 15:37:44,372 iteration 1637 : loss : 0.046316, loss_ce: 0.016331
2022-01-14 15:37:45,927 iteration 1638 : loss : 0.043108, loss_ce: 0.014564
2022-01-14 15:37:47,507 iteration 1639 : loss : 0.037531, loss_ce: 0.014328
2022-01-14 15:37:49,006 iteration 1640 : loss : 0.052344, loss_ce: 0.023308
2022-01-14 15:37:50,565 iteration 1641 : loss : 0.039743, loss_ce: 0.017188
2022-01-14 15:37:52,209 iteration 1642 : loss : 0.051923, loss_ce: 0.014652
2022-01-14 15:37:53,746 iteration 1643 : loss : 0.025520, loss_ce: 0.010397
2022-01-14 15:37:55,268 iteration 1644 : loss : 0.062734, loss_ce: 0.025802
2022-01-14 15:37:56,688 iteration 1645 : loss : 0.035424, loss_ce: 0.010740
2022-01-14 15:37:58,182 iteration 1646 : loss : 0.038332, loss_ce: 0.017146
2022-01-14 15:37:59,781 iteration 1647 : loss : 0.048097, loss_ce: 0.028040
2022-01-14 15:38:01,275 iteration 1648 : loss : 0.041259, loss_ce: 0.018130
2022-01-14 15:38:02,855 iteration 1649 : loss : 0.071064, loss_ce: 0.022544
 24%|███████▎                      | 97/400 [45:22<2:22:35, 28.24s/it]2022-01-14 15:38:04,409 iteration 1650 : loss : 0.046595, loss_ce: 0.013898
2022-01-14 15:38:06,009 iteration 1651 : loss : 0.057502, loss_ce: 0.022478
2022-01-14 15:38:07,613 iteration 1652 : loss : 0.045682, loss_ce: 0.015162
2022-01-14 15:38:09,179 iteration 1653 : loss : 0.043822, loss_ce: 0.020663
2022-01-14 15:38:10,671 iteration 1654 : loss : 0.035965, loss_ce: 0.012135
2022-01-14 15:38:12,139 iteration 1655 : loss : 0.061128, loss_ce: 0.016972
2022-01-14 15:38:13,611 iteration 1656 : loss : 0.033971, loss_ce: 0.015157
2022-01-14 15:38:15,185 iteration 1657 : loss : 0.058412, loss_ce: 0.026445
2022-01-14 15:38:16,632 iteration 1658 : loss : 0.034737, loss_ce: 0.013118
2022-01-14 15:38:18,127 iteration 1659 : loss : 0.037376, loss_ce: 0.016186
2022-01-14 15:38:19,756 iteration 1660 : loss : 0.054064, loss_ce: 0.024997
2022-01-14 15:38:21,254 iteration 1661 : loss : 0.046818, loss_ce: 0.016672
2022-01-14 15:38:22,733 iteration 1662 : loss : 0.040691, loss_ce: 0.017121
2022-01-14 15:38:24,326 iteration 1663 : loss : 0.051845, loss_ce: 0.021436
2022-01-14 15:38:25,905 iteration 1664 : loss : 0.063095, loss_ce: 0.024325
2022-01-14 15:38:27,382 iteration 1665 : loss : 0.026155, loss_ce: 0.011292
2022-01-14 15:38:28,839 iteration 1666 : loss : 0.036162, loss_ce: 0.012334
 24%|███████▎                      | 98/400 [45:48<2:18:43, 27.56s/it]2022-01-14 15:38:30,391 iteration 1667 : loss : 0.031485, loss_ce: 0.012603
2022-01-14 15:38:31,954 iteration 1668 : loss : 0.048870, loss_ce: 0.019813
2022-01-14 15:38:33,454 iteration 1669 : loss : 0.037553, loss_ce: 0.016082
2022-01-14 15:38:34,969 iteration 1670 : loss : 0.032485, loss_ce: 0.010791
2022-01-14 15:38:36,531 iteration 1671 : loss : 0.039853, loss_ce: 0.015004
2022-01-14 15:38:38,017 iteration 1672 : loss : 0.044599, loss_ce: 0.016196
2022-01-14 15:38:39,481 iteration 1673 : loss : 0.032201, loss_ce: 0.012705
2022-01-14 15:38:41,057 iteration 1674 : loss : 0.033626, loss_ce: 0.014345
2022-01-14 15:38:42,542 iteration 1675 : loss : 0.032188, loss_ce: 0.011926
2022-01-14 15:38:44,112 iteration 1676 : loss : 0.035738, loss_ce: 0.015837
2022-01-14 15:38:45,691 iteration 1677 : loss : 0.036005, loss_ce: 0.014736
2022-01-14 15:38:47,240 iteration 1678 : loss : 0.056004, loss_ce: 0.014898
2022-01-14 15:38:48,811 iteration 1679 : loss : 0.031969, loss_ce: 0.009087
2022-01-14 15:38:50,363 iteration 1680 : loss : 0.039832, loss_ce: 0.022497
2022-01-14 15:38:51,891 iteration 1681 : loss : 0.049765, loss_ce: 0.014060
2022-01-14 15:38:53,341 iteration 1682 : loss : 0.047315, loss_ce: 0.023340
2022-01-14 15:38:54,875 iteration 1683 : loss : 0.051230, loss_ce: 0.022474
 25%|███████▍                      | 99/400 [46:14<2:15:58, 27.10s/it]2022-01-14 15:38:56,432 iteration 1684 : loss : 0.028740, loss_ce: 0.010066
2022-01-14 15:38:57,923 iteration 1685 : loss : 0.040222, loss_ce: 0.015132
2022-01-14 15:38:59,486 iteration 1686 : loss : 0.047482, loss_ce: 0.017363
2022-01-14 15:39:00,964 iteration 1687 : loss : 0.029982, loss_ce: 0.009516
2022-01-14 15:39:02,525 iteration 1688 : loss : 0.034537, loss_ce: 0.012293
2022-01-14 15:39:04,076 iteration 1689 : loss : 0.047979, loss_ce: 0.019756
2022-01-14 15:39:05,494 iteration 1690 : loss : 0.038128, loss_ce: 0.012379
2022-01-14 15:39:06,956 iteration 1691 : loss : 0.045390, loss_ce: 0.015554
2022-01-14 15:39:08,435 iteration 1692 : loss : 0.030769, loss_ce: 0.012957
2022-01-14 15:39:09,998 iteration 1693 : loss : 0.036308, loss_ce: 0.014486
2022-01-14 15:39:11,559 iteration 1694 : loss : 0.046626, loss_ce: 0.013949
2022-01-14 15:39:13,036 iteration 1695 : loss : 0.048897, loss_ce: 0.013155
2022-01-14 15:39:14,568 iteration 1696 : loss : 0.053316, loss_ce: 0.026687
2022-01-14 15:39:16,106 iteration 1697 : loss : 0.041703, loss_ce: 0.018808
2022-01-14 15:39:17,662 iteration 1698 : loss : 0.027092, loss_ce: 0.010173
2022-01-14 15:39:19,147 iteration 1699 : loss : 0.038507, loss_ce: 0.016537
2022-01-14 15:39:19,147 Training Data Eval:
2022-01-14 15:39:26,619   Average segmentation loss on training set: 0.0289
2022-01-14 15:39:26,620 Validation Data Eval:
2022-01-14 15:39:29,189   Average segmentation loss on validation set: 0.1316
2022-01-14 15:39:30,739 iteration 1700 : loss : 0.029606, loss_ce: 0.011223
 25%|███████▎                     | 100/400 [46:50<2:28:39, 29.73s/it]2022-01-14 15:39:32,273 iteration 1701 : loss : 0.029615, loss_ce: 0.012621
2022-01-14 15:39:33,789 iteration 1702 : loss : 0.040141, loss_ce: 0.015202
2022-01-14 15:39:35,358 iteration 1703 : loss : 0.044150, loss_ce: 0.018909
2022-01-14 15:39:36,864 iteration 1704 : loss : 0.037378, loss_ce: 0.016933
2022-01-14 15:39:38,409 iteration 1705 : loss : 0.046537, loss_ce: 0.017599
2022-01-14 15:39:39,984 iteration 1706 : loss : 0.045123, loss_ce: 0.018722
2022-01-14 15:39:41,478 iteration 1707 : loss : 0.040214, loss_ce: 0.017218
2022-01-14 15:39:42,964 iteration 1708 : loss : 0.060727, loss_ce: 0.016755
2022-01-14 15:39:44,490 iteration 1709 : loss : 0.038430, loss_ce: 0.016572
2022-01-14 15:39:46,059 iteration 1710 : loss : 0.059051, loss_ce: 0.019188
2022-01-14 15:39:47,556 iteration 1711 : loss : 0.033441, loss_ce: 0.011927
2022-01-14 15:39:49,001 iteration 1712 : loss : 0.029954, loss_ce: 0.013400
2022-01-14 15:39:50,525 iteration 1713 : loss : 0.043728, loss_ce: 0.012053
2022-01-14 15:39:52,092 iteration 1714 : loss : 0.073934, loss_ce: 0.018922
2022-01-14 15:39:53,661 iteration 1715 : loss : 0.038521, loss_ce: 0.015915
2022-01-14 15:39:55,085 iteration 1716 : loss : 0.045742, loss_ce: 0.014534
2022-01-14 15:39:56,657 iteration 1717 : loss : 0.044049, loss_ce: 0.013089
 25%|███████▎                     | 101/400 [47:16<2:22:27, 28.59s/it]2022-01-14 15:39:58,208 iteration 1718 : loss : 0.041502, loss_ce: 0.020353
2022-01-14 15:39:59,685 iteration 1719 : loss : 0.077292, loss_ce: 0.014011
2022-01-14 15:40:01,247 iteration 1720 : loss : 0.034923, loss_ce: 0.012120
2022-01-14 15:40:02,716 iteration 1721 : loss : 0.047087, loss_ce: 0.013639
2022-01-14 15:40:04,283 iteration 1722 : loss : 0.041721, loss_ce: 0.011956
2022-01-14 15:40:05,729 iteration 1723 : loss : 0.043781, loss_ce: 0.013752
2022-01-14 15:40:07,256 iteration 1724 : loss : 0.032293, loss_ce: 0.012036
2022-01-14 15:40:08,778 iteration 1725 : loss : 0.039727, loss_ce: 0.011904
2022-01-14 15:40:10,351 iteration 1726 : loss : 0.028892, loss_ce: 0.012082
2022-01-14 15:40:11,913 iteration 1727 : loss : 0.069000, loss_ce: 0.032177
2022-01-14 15:40:13,332 iteration 1728 : loss : 0.030391, loss_ce: 0.010835
2022-01-14 15:40:14,880 iteration 1729 : loss : 0.048513, loss_ce: 0.014962
2022-01-14 15:40:16,470 iteration 1730 : loss : 0.036380, loss_ce: 0.016817
2022-01-14 15:40:17,975 iteration 1731 : loss : 0.047757, loss_ce: 0.025953
2022-01-14 15:40:19,466 iteration 1732 : loss : 0.042072, loss_ce: 0.016882
2022-01-14 15:40:20,927 iteration 1733 : loss : 0.043607, loss_ce: 0.020050
2022-01-14 15:40:22,422 iteration 1734 : loss : 0.042033, loss_ce: 0.017496
 26%|███████▍                     | 102/400 [47:42<2:17:46, 27.74s/it]2022-01-14 15:40:24,104 iteration 1735 : loss : 0.079568, loss_ce: 0.034682
2022-01-14 15:40:25,577 iteration 1736 : loss : 0.048360, loss_ce: 0.019030
2022-01-14 15:40:27,168 iteration 1737 : loss : 0.049015, loss_ce: 0.019239
2022-01-14 15:40:28,704 iteration 1738 : loss : 0.037567, loss_ce: 0.018519
2022-01-14 15:40:30,153 iteration 1739 : loss : 0.029417, loss_ce: 0.011421
2022-01-14 15:40:31,746 iteration 1740 : loss : 0.031809, loss_ce: 0.013485
2022-01-14 15:40:33,298 iteration 1741 : loss : 0.030870, loss_ce: 0.010915
2022-01-14 15:40:34,847 iteration 1742 : loss : 0.048655, loss_ce: 0.019288
2022-01-14 15:40:36,265 iteration 1743 : loss : 0.047905, loss_ce: 0.015213
2022-01-14 15:40:37,836 iteration 1744 : loss : 0.080304, loss_ce: 0.033523
2022-01-14 15:40:39,381 iteration 1745 : loss : 0.051256, loss_ce: 0.020443
2022-01-14 15:40:40,876 iteration 1746 : loss : 0.049367, loss_ce: 0.023741
2022-01-14 15:40:42,346 iteration 1747 : loss : 0.038427, loss_ce: 0.015060
2022-01-14 15:40:43,875 iteration 1748 : loss : 0.036412, loss_ce: 0.012068
2022-01-14 15:40:45,290 iteration 1749 : loss : 0.034810, loss_ce: 0.011165
2022-01-14 15:40:46,844 iteration 1750 : loss : 0.085269, loss_ce: 0.018729
2022-01-14 15:40:48,499 iteration 1751 : loss : 0.047784, loss_ce: 0.016323
 26%|███████▍                     | 103/400 [48:08<2:14:51, 27.24s/it]2022-01-14 15:40:50,105 iteration 1752 : loss : 0.097238, loss_ce: 0.027448
2022-01-14 15:40:51,504 iteration 1753 : loss : 0.053635, loss_ce: 0.017515
2022-01-14 15:40:53,065 iteration 1754 : loss : 0.053219, loss_ce: 0.018706
2022-01-14 15:40:54,537 iteration 1755 : loss : 0.051191, loss_ce: 0.024952
2022-01-14 15:40:56,060 iteration 1756 : loss : 0.050805, loss_ce: 0.020001
2022-01-14 15:40:57,501 iteration 1757 : loss : 0.034419, loss_ce: 0.013339
2022-01-14 15:40:59,006 iteration 1758 : loss : 0.046575, loss_ce: 0.025827
2022-01-14 15:41:00,431 iteration 1759 : loss : 0.032574, loss_ce: 0.010150
2022-01-14 15:41:01,884 iteration 1760 : loss : 0.058011, loss_ce: 0.017576
2022-01-14 15:41:03,457 iteration 1761 : loss : 0.057630, loss_ce: 0.016470
2022-01-14 15:41:04,897 iteration 1762 : loss : 0.033386, loss_ce: 0.013678
2022-01-14 15:41:06,379 iteration 1763 : loss : 0.045864, loss_ce: 0.017029
2022-01-14 15:41:07,782 iteration 1764 : loss : 0.035143, loss_ce: 0.010569
2022-01-14 15:41:09,317 iteration 1765 : loss : 0.033766, loss_ce: 0.017557
2022-01-14 15:41:10,865 iteration 1766 : loss : 0.058339, loss_ce: 0.030492
2022-01-14 15:41:12,333 iteration 1767 : loss : 0.042026, loss_ce: 0.018962
2022-01-14 15:41:13,872 iteration 1768 : loss : 0.035000, loss_ce: 0.014000
 26%|███████▌                     | 104/400 [48:33<2:11:37, 26.68s/it]2022-01-14 15:41:15,423 iteration 1769 : loss : 0.040063, loss_ce: 0.016170
2022-01-14 15:41:16,918 iteration 1770 : loss : 0.034791, loss_ce: 0.014572
2022-01-14 15:41:18,341 iteration 1771 : loss : 0.049852, loss_ce: 0.019571
2022-01-14 15:41:19,775 iteration 1772 : loss : 0.038399, loss_ce: 0.021443
2022-01-14 15:41:21,322 iteration 1773 : loss : 0.063814, loss_ce: 0.017350
2022-01-14 15:41:22,848 iteration 1774 : loss : 0.030673, loss_ce: 0.009815
2022-01-14 15:41:24,401 iteration 1775 : loss : 0.054613, loss_ce: 0.023684
2022-01-14 15:41:25,882 iteration 1776 : loss : 0.034048, loss_ce: 0.015337
2022-01-14 15:41:27,344 iteration 1777 : loss : 0.032043, loss_ce: 0.011263
2022-01-14 15:41:28,760 iteration 1778 : loss : 0.035503, loss_ce: 0.012788
2022-01-14 15:41:30,297 iteration 1779 : loss : 0.047400, loss_ce: 0.015725
2022-01-14 15:41:31,837 iteration 1780 : loss : 0.069292, loss_ce: 0.035305
2022-01-14 15:41:33,287 iteration 1781 : loss : 0.038672, loss_ce: 0.015019
2022-01-14 15:41:34,865 iteration 1782 : loss : 0.038850, loss_ce: 0.014422
2022-01-14 15:41:36,382 iteration 1783 : loss : 0.034496, loss_ce: 0.012239
2022-01-14 15:41:37,872 iteration 1784 : loss : 0.043577, loss_ce: 0.018143
2022-01-14 15:41:37,873 Training Data Eval:
2022-01-14 15:41:45,365   Average segmentation loss on training set: 0.0574
2022-01-14 15:41:45,365 Validation Data Eval:
2022-01-14 15:41:47,931   Average segmentation loss on validation set: 0.2194
2022-01-14 15:41:49,488 iteration 1785 : loss : 0.035708, loss_ce: 0.013632
 26%|███████▌                     | 105/400 [49:09<2:24:21, 29.36s/it]2022-01-14 15:41:51,055 iteration 1786 : loss : 0.036008, loss_ce: 0.016821
2022-01-14 15:41:52,479 iteration 1787 : loss : 0.037636, loss_ce: 0.014800
2022-01-14 15:41:54,054 iteration 1788 : loss : 0.047246, loss_ce: 0.026014
2022-01-14 15:41:55,612 iteration 1789 : loss : 0.041874, loss_ce: 0.014826
2022-01-14 15:41:57,125 iteration 1790 : loss : 0.030673, loss_ce: 0.014838
2022-01-14 15:41:58,708 iteration 1791 : loss : 0.050460, loss_ce: 0.018513
2022-01-14 15:42:00,165 iteration 1792 : loss : 0.041659, loss_ce: 0.015446
2022-01-14 15:42:01,661 iteration 1793 : loss : 0.055559, loss_ce: 0.019995
2022-01-14 15:42:03,141 iteration 1794 : loss : 0.030244, loss_ce: 0.011179
2022-01-14 15:42:04,693 iteration 1795 : loss : 0.038525, loss_ce: 0.014701
2022-01-14 15:42:06,174 iteration 1796 : loss : 0.038448, loss_ce: 0.016955
2022-01-14 15:42:07,781 iteration 1797 : loss : 0.060242, loss_ce: 0.021612
2022-01-14 15:42:09,361 iteration 1798 : loss : 0.031161, loss_ce: 0.010994
2022-01-14 15:42:10,818 iteration 1799 : loss : 0.047745, loss_ce: 0.019544
2022-01-14 15:42:12,387 iteration 1800 : loss : 0.032901, loss_ce: 0.010904
2022-01-14 15:42:13,854 iteration 1801 : loss : 0.034551, loss_ce: 0.011846
2022-01-14 15:42:15,347 iteration 1802 : loss : 0.048422, loss_ce: 0.016009
 26%|███████▋                     | 106/400 [49:35<2:18:43, 28.31s/it]2022-01-14 15:42:16,979 iteration 1803 : loss : 0.037730, loss_ce: 0.013437
2022-01-14 15:42:18,550 iteration 1804 : loss : 0.039553, loss_ce: 0.010624
2022-01-14 15:42:20,023 iteration 1805 : loss : 0.032086, loss_ce: 0.009081
2022-01-14 15:42:21,507 iteration 1806 : loss : 0.044178, loss_ce: 0.020609
2022-01-14 15:42:22,983 iteration 1807 : loss : 0.054277, loss_ce: 0.018543
2022-01-14 15:42:24,497 iteration 1808 : loss : 0.027868, loss_ce: 0.011183
2022-01-14 15:42:25,990 iteration 1809 : loss : 0.032283, loss_ce: 0.013262
2022-01-14 15:42:27,385 iteration 1810 : loss : 0.026362, loss_ce: 0.010148
2022-01-14 15:42:28,944 iteration 1811 : loss : 0.029478, loss_ce: 0.013159
2022-01-14 15:42:30,521 iteration 1812 : loss : 0.038446, loss_ce: 0.013258
2022-01-14 15:42:32,157 iteration 1813 : loss : 0.038017, loss_ce: 0.013577
2022-01-14 15:42:33,694 iteration 1814 : loss : 0.034601, loss_ce: 0.016803
2022-01-14 15:42:35,114 iteration 1815 : loss : 0.040902, loss_ce: 0.012961
2022-01-14 15:42:36,543 iteration 1816 : loss : 0.032869, loss_ce: 0.012895
2022-01-14 15:42:38,149 iteration 1817 : loss : 0.050814, loss_ce: 0.021753
2022-01-14 15:42:39,679 iteration 1818 : loss : 0.054366, loss_ce: 0.021358
2022-01-14 15:42:41,203 iteration 1819 : loss : 0.034646, loss_ce: 0.014860
 27%|███████▊                     | 107/400 [50:01<2:14:39, 27.57s/it]2022-01-14 15:42:42,853 iteration 1820 : loss : 0.034389, loss_ce: 0.014926
2022-01-14 15:42:44,352 iteration 1821 : loss : 0.028747, loss_ce: 0.012684
2022-01-14 15:42:45,861 iteration 1822 : loss : 0.039563, loss_ce: 0.014373
2022-01-14 15:42:47,284 iteration 1823 : loss : 0.031972, loss_ce: 0.009987
2022-01-14 15:42:48,685 iteration 1824 : loss : 0.027319, loss_ce: 0.011192
2022-01-14 15:42:50,210 iteration 1825 : loss : 0.044377, loss_ce: 0.016840
2022-01-14 15:42:51,602 iteration 1826 : loss : 0.030754, loss_ce: 0.014833
2022-01-14 15:42:53,210 iteration 1827 : loss : 0.137509, loss_ce: 0.058402
2022-01-14 15:42:54,677 iteration 1828 : loss : 0.034968, loss_ce: 0.012895
2022-01-14 15:42:56,182 iteration 1829 : loss : 0.040449, loss_ce: 0.012539
2022-01-14 15:42:57,657 iteration 1830 : loss : 0.033137, loss_ce: 0.015032
2022-01-14 15:42:59,234 iteration 1831 : loss : 0.035284, loss_ce: 0.018090
2022-01-14 15:43:00,734 iteration 1832 : loss : 0.036631, loss_ce: 0.009920
2022-01-14 15:43:02,255 iteration 1833 : loss : 0.035593, loss_ce: 0.018324
2022-01-14 15:43:03,825 iteration 1834 : loss : 0.030985, loss_ce: 0.013228
2022-01-14 15:43:05,287 iteration 1835 : loss : 0.042434, loss_ce: 0.018867
2022-01-14 15:43:06,760 iteration 1836 : loss : 0.045144, loss_ce: 0.015315
 27%|███████▊                     | 108/400 [50:26<2:11:15, 26.97s/it]2022-01-14 15:43:08,355 iteration 1837 : loss : 0.025447, loss_ce: 0.009759
2022-01-14 15:43:09,974 iteration 1838 : loss : 0.042893, loss_ce: 0.018251
2022-01-14 15:43:11,478 iteration 1839 : loss : 0.042650, loss_ce: 0.015286
2022-01-14 15:43:12,897 iteration 1840 : loss : 0.033247, loss_ce: 0.014622
2022-01-14 15:43:14,431 iteration 1841 : loss : 0.066768, loss_ce: 0.030127
2022-01-14 15:43:16,036 iteration 1842 : loss : 0.052415, loss_ce: 0.018419
2022-01-14 15:43:17,479 iteration 1843 : loss : 0.030548, loss_ce: 0.013386
2022-01-14 15:43:19,011 iteration 1844 : loss : 0.037135, loss_ce: 0.015618
2022-01-14 15:43:20,419 iteration 1845 : loss : 0.036774, loss_ce: 0.014269
2022-01-14 15:43:22,033 iteration 1846 : loss : 0.037214, loss_ce: 0.015888
2022-01-14 15:43:23,604 iteration 1847 : loss : 0.043219, loss_ce: 0.016019
2022-01-14 15:43:25,112 iteration 1848 : loss : 0.046826, loss_ce: 0.019141
2022-01-14 15:43:26,514 iteration 1849 : loss : 0.024189, loss_ce: 0.010996
2022-01-14 15:43:28,033 iteration 1850 : loss : 0.056530, loss_ce: 0.015508
2022-01-14 15:43:29,581 iteration 1851 : loss : 0.038097, loss_ce: 0.015125
2022-01-14 15:43:31,078 iteration 1852 : loss : 0.034230, loss_ce: 0.013460
2022-01-14 15:43:32,604 iteration 1853 : loss : 0.043011, loss_ce: 0.009687
 27%|███████▉                     | 109/400 [50:52<2:09:10, 26.63s/it]2022-01-14 15:43:34,114 iteration 1854 : loss : 0.030005, loss_ce: 0.011902
2022-01-14 15:43:35,619 iteration 1855 : loss : 0.042489, loss_ce: 0.014284
2022-01-14 15:43:37,150 iteration 1856 : loss : 0.034305, loss_ce: 0.008343
2022-01-14 15:43:38,669 iteration 1857 : loss : 0.045492, loss_ce: 0.015605
2022-01-14 15:43:40,145 iteration 1858 : loss : 0.039562, loss_ce: 0.019625
2022-01-14 15:43:41,593 iteration 1859 : loss : 0.036640, loss_ce: 0.016763
2022-01-14 15:43:43,192 iteration 1860 : loss : 0.057038, loss_ce: 0.027235
2022-01-14 15:43:44,708 iteration 1861 : loss : 0.054799, loss_ce: 0.023312
2022-01-14 15:43:46,189 iteration 1862 : loss : 0.035298, loss_ce: 0.015808
2022-01-14 15:43:47,726 iteration 1863 : loss : 0.043330, loss_ce: 0.018334
2022-01-14 15:43:49,228 iteration 1864 : loss : 0.042697, loss_ce: 0.015162
2022-01-14 15:43:50,834 iteration 1865 : loss : 0.057127, loss_ce: 0.026044
2022-01-14 15:43:52,419 iteration 1866 : loss : 0.036736, loss_ce: 0.017072
2022-01-14 15:43:53,932 iteration 1867 : loss : 0.104091, loss_ce: 0.037071
2022-01-14 15:43:55,405 iteration 1868 : loss : 0.035351, loss_ce: 0.016717
2022-01-14 15:43:56,920 iteration 1869 : loss : 0.041871, loss_ce: 0.013268
2022-01-14 15:43:56,920 Training Data Eval:
2022-01-14 15:44:04,401   Average segmentation loss on training set: 0.0642
2022-01-14 15:44:04,402 Validation Data Eval:
2022-01-14 15:44:06,964   Average segmentation loss on validation set: 0.2344
2022-01-14 15:44:08,410 iteration 1870 : loss : 0.034998, loss_ce: 0.010201
 28%|███████▉                     | 110/400 [51:28<2:22:00, 29.38s/it]2022-01-14 15:44:09,931 iteration 1871 : loss : 0.041016, loss_ce: 0.018838
2022-01-14 15:44:11,416 iteration 1872 : loss : 0.042667, loss_ce: 0.016637
2022-01-14 15:44:12,918 iteration 1873 : loss : 0.048469, loss_ce: 0.023433
2022-01-14 15:44:14,475 iteration 1874 : loss : 0.043124, loss_ce: 0.019207
2022-01-14 15:44:16,089 iteration 1875 : loss : 0.041640, loss_ce: 0.023972
2022-01-14 15:44:17,671 iteration 1876 : loss : 0.050321, loss_ce: 0.014657
2022-01-14 15:44:19,233 iteration 1877 : loss : 0.037950, loss_ce: 0.012142
2022-01-14 15:44:20,674 iteration 1878 : loss : 0.036438, loss_ce: 0.011978
2022-01-14 15:44:22,136 iteration 1879 : loss : 0.040294, loss_ce: 0.018598
2022-01-14 15:44:23,612 iteration 1880 : loss : 0.033074, loss_ce: 0.010964
2022-01-14 15:44:25,098 iteration 1881 : loss : 0.029690, loss_ce: 0.010275
2022-01-14 15:44:26,587 iteration 1882 : loss : 0.034561, loss_ce: 0.010349
2022-01-14 15:44:28,044 iteration 1883 : loss : 0.031222, loss_ce: 0.011735
2022-01-14 15:44:29,577 iteration 1884 : loss : 0.029503, loss_ce: 0.011381
2022-01-14 15:44:31,022 iteration 1885 : loss : 0.028580, loss_ce: 0.010588
2022-01-14 15:44:32,531 iteration 1886 : loss : 0.035382, loss_ce: 0.016865
2022-01-14 15:44:34,018 iteration 1887 : loss : 0.037527, loss_ce: 0.014972
 28%|████████                     | 111/400 [51:54<2:16:04, 28.25s/it]2022-01-14 15:44:35,597 iteration 1888 : loss : 0.033782, loss_ce: 0.011418
2022-01-14 15:44:37,142 iteration 1889 : loss : 0.050991, loss_ce: 0.020190
2022-01-14 15:44:38,565 iteration 1890 : loss : 0.026854, loss_ce: 0.009868
2022-01-14 15:44:40,083 iteration 1891 : loss : 0.037115, loss_ce: 0.018846
2022-01-14 15:44:41,584 iteration 1892 : loss : 0.037826, loss_ce: 0.012080
2022-01-14 15:44:43,159 iteration 1893 : loss : 0.048520, loss_ce: 0.019698
2022-01-14 15:44:44,642 iteration 1894 : loss : 0.042811, loss_ce: 0.017340
2022-01-14 15:44:46,200 iteration 1895 : loss : 0.033598, loss_ce: 0.011152
2022-01-14 15:44:47,710 iteration 1896 : loss : 0.035679, loss_ce: 0.015097
2022-01-14 15:44:49,198 iteration 1897 : loss : 0.045074, loss_ce: 0.016168
2022-01-14 15:44:50,792 iteration 1898 : loss : 0.047151, loss_ce: 0.016506
2022-01-14 15:44:52,192 iteration 1899 : loss : 0.025606, loss_ce: 0.010134
2022-01-14 15:44:53,805 iteration 1900 : loss : 0.055470, loss_ce: 0.027687
2022-01-14 15:44:55,404 iteration 1901 : loss : 0.033092, loss_ce: 0.011575
2022-01-14 15:44:56,926 iteration 1902 : loss : 0.040966, loss_ce: 0.013678
2022-01-14 15:44:58,500 iteration 1903 : loss : 0.040267, loss_ce: 0.019459
2022-01-14 15:45:00,035 iteration 1904 : loss : 0.034599, loss_ce: 0.012640
 28%|████████                     | 112/400 [52:20<2:12:23, 27.58s/it]2022-01-14 15:45:01,617 iteration 1905 : loss : 0.042510, loss_ce: 0.017758
2022-01-14 15:45:03,146 iteration 1906 : loss : 0.036203, loss_ce: 0.010712
2022-01-14 15:45:04,651 iteration 1907 : loss : 0.029580, loss_ce: 0.012491
2022-01-14 15:45:06,305 iteration 1908 : loss : 0.028925, loss_ce: 0.009257
2022-01-14 15:45:07,855 iteration 1909 : loss : 0.031261, loss_ce: 0.011318
2022-01-14 15:45:09,398 iteration 1910 : loss : 0.057367, loss_ce: 0.011091
2022-01-14 15:45:10,979 iteration 1911 : loss : 0.032322, loss_ce: 0.010447
2022-01-14 15:45:12,390 iteration 1912 : loss : 0.031756, loss_ce: 0.010823
2022-01-14 15:45:13,917 iteration 1913 : loss : 0.040144, loss_ce: 0.016986
2022-01-14 15:45:15,411 iteration 1914 : loss : 0.030286, loss_ce: 0.013123
2022-01-14 15:45:16,961 iteration 1915 : loss : 0.021736, loss_ce: 0.009953
2022-01-14 15:45:18,466 iteration 1916 : loss : 0.048676, loss_ce: 0.019227
2022-01-14 15:45:19,942 iteration 1917 : loss : 0.040043, loss_ce: 0.017476
2022-01-14 15:45:21,499 iteration 1918 : loss : 0.028938, loss_ce: 0.009408
2022-01-14 15:45:22,966 iteration 1919 : loss : 0.048420, loss_ce: 0.020490
2022-01-14 15:45:24,437 iteration 1920 : loss : 0.037148, loss_ce: 0.017886
2022-01-14 15:45:26,081 iteration 1921 : loss : 0.045342, loss_ce: 0.019686
 28%|████████▏                    | 113/400 [52:46<2:09:43, 27.12s/it]2022-01-14 15:45:27,627 iteration 1922 : loss : 0.039181, loss_ce: 0.016596
2022-01-14 15:45:29,110 iteration 1923 : loss : 0.026632, loss_ce: 0.011878
2022-01-14 15:45:30,675 iteration 1924 : loss : 0.025856, loss_ce: 0.011399
2022-01-14 15:45:32,241 iteration 1925 : loss : 0.047051, loss_ce: 0.020205
2022-01-14 15:45:33,731 iteration 1926 : loss : 0.024940, loss_ce: 0.010110
2022-01-14 15:45:35,190 iteration 1927 : loss : 0.034539, loss_ce: 0.013914
2022-01-14 15:45:36,799 iteration 1928 : loss : 0.047418, loss_ce: 0.025342
2022-01-14 15:45:38,271 iteration 1929 : loss : 0.030232, loss_ce: 0.011086
2022-01-14 15:45:39,723 iteration 1930 : loss : 0.027033, loss_ce: 0.012536
2022-01-14 15:45:41,233 iteration 1931 : loss : 0.075038, loss_ce: 0.019797
2022-01-14 15:45:42,804 iteration 1932 : loss : 0.038271, loss_ce: 0.012230
2022-01-14 15:45:44,373 iteration 1933 : loss : 0.045242, loss_ce: 0.023771
2022-01-14 15:45:45,773 iteration 1934 : loss : 0.025989, loss_ce: 0.010194
2022-01-14 15:45:47,298 iteration 1935 : loss : 0.050276, loss_ce: 0.021181
2022-01-14 15:45:48,894 iteration 1936 : loss : 0.037129, loss_ce: 0.017285
2022-01-14 15:45:50,328 iteration 1937 : loss : 0.040117, loss_ce: 0.011762
2022-01-14 15:45:51,758 iteration 1938 : loss : 0.031032, loss_ce: 0.011609
 28%|████████▎                    | 114/400 [53:11<2:07:12, 26.69s/it]2022-01-14 15:45:53,254 iteration 1939 : loss : 0.025691, loss_ce: 0.008419
2022-01-14 15:45:54,871 iteration 1940 : loss : 0.045089, loss_ce: 0.018882
2022-01-14 15:45:56,470 iteration 1941 : loss : 0.039243, loss_ce: 0.018604
2022-01-14 15:45:57,993 iteration 1942 : loss : 0.036014, loss_ce: 0.011729
2022-01-14 15:45:59,452 iteration 1943 : loss : 0.042135, loss_ce: 0.016696
2022-01-14 15:46:00,970 iteration 1944 : loss : 0.025079, loss_ce: 0.009001
2022-01-14 15:46:02,484 iteration 1945 : loss : 0.042325, loss_ce: 0.014567
2022-01-14 15:46:04,007 iteration 1946 : loss : 0.036798, loss_ce: 0.013788
2022-01-14 15:46:05,538 iteration 1947 : loss : 0.037596, loss_ce: 0.016670
2022-01-14 15:46:07,048 iteration 1948 : loss : 0.061800, loss_ce: 0.018099
2022-01-14 15:46:08,524 iteration 1949 : loss : 0.035647, loss_ce: 0.013360
2022-01-14 15:46:10,000 iteration 1950 : loss : 0.028112, loss_ce: 0.011918
2022-01-14 15:46:11,618 iteration 1951 : loss : 0.041047, loss_ce: 0.015093
2022-01-14 15:46:13,181 iteration 1952 : loss : 0.034776, loss_ce: 0.011237
2022-01-14 15:46:14,760 iteration 1953 : loss : 0.042127, loss_ce: 0.020924
2022-01-14 15:46:16,258 iteration 1954 : loss : 0.022722, loss_ce: 0.009965
2022-01-14 15:46:16,258 Training Data Eval:
2022-01-14 15:46:23,718   Average segmentation loss on training set: 0.0278
2022-01-14 15:46:23,719 Validation Data Eval:
2022-01-14 15:46:26,280   Average segmentation loss on validation set: 0.1290
2022-01-14 15:46:27,844 iteration 1955 : loss : 0.047643, loss_ce: 0.014729
 29%|████████▎                    | 115/400 [53:47<2:20:09, 29.51s/it]2022-01-14 15:46:29,385 iteration 1956 : loss : 0.048145, loss_ce: 0.012038
2022-01-14 15:46:31,011 iteration 1957 : loss : 0.038464, loss_ce: 0.016014
2022-01-14 15:46:32,622 iteration 1958 : loss : 0.053028, loss_ce: 0.018746
2022-01-14 15:46:34,134 iteration 1959 : loss : 0.044083, loss_ce: 0.016396
2022-01-14 15:46:35,570 iteration 1960 : loss : 0.023816, loss_ce: 0.009076
2022-01-14 15:46:37,101 iteration 1961 : loss : 0.030704, loss_ce: 0.014203
2022-01-14 15:46:38,691 iteration 1962 : loss : 0.035039, loss_ce: 0.017178
2022-01-14 15:46:40,140 iteration 1963 : loss : 0.037060, loss_ce: 0.014258
2022-01-14 15:46:41,593 iteration 1964 : loss : 0.035134, loss_ce: 0.013218
2022-01-14 15:46:43,037 iteration 1965 : loss : 0.038420, loss_ce: 0.016584
2022-01-14 15:46:44,626 iteration 1966 : loss : 0.046069, loss_ce: 0.017640
2022-01-14 15:46:46,219 iteration 1967 : loss : 0.037034, loss_ce: 0.012771
2022-01-14 15:46:47,763 iteration 1968 : loss : 0.034283, loss_ce: 0.015587
2022-01-14 15:46:49,341 iteration 1969 : loss : 0.038823, loss_ce: 0.014392
2022-01-14 15:46:50,842 iteration 1970 : loss : 0.047660, loss_ce: 0.014471
2022-01-14 15:46:52,407 iteration 1971 : loss : 0.039069, loss_ce: 0.017659
2022-01-14 15:46:53,884 iteration 1972 : loss : 0.065570, loss_ce: 0.022126
 29%|████████▍                    | 116/400 [54:13<2:14:44, 28.47s/it]2022-01-14 15:46:55,310 iteration 1973 : loss : 0.027710, loss_ce: 0.011264
2022-01-14 15:46:56,845 iteration 1974 : loss : 0.032062, loss_ce: 0.012885
2022-01-14 15:46:58,354 iteration 1975 : loss : 0.039682, loss_ce: 0.012748
2022-01-14 15:46:59,969 iteration 1976 : loss : 0.045651, loss_ce: 0.019842
2022-01-14 15:47:01,504 iteration 1977 : loss : 0.043192, loss_ce: 0.013377
2022-01-14 15:47:02,931 iteration 1978 : loss : 0.026761, loss_ce: 0.011759
2022-01-14 15:47:04,355 iteration 1979 : loss : 0.031098, loss_ce: 0.011965
2022-01-14 15:47:05,909 iteration 1980 : loss : 0.063614, loss_ce: 0.031391
2022-01-14 15:47:07,391 iteration 1981 : loss : 0.041587, loss_ce: 0.014577
2022-01-14 15:47:08,770 iteration 1982 : loss : 0.049447, loss_ce: 0.016498
2022-01-14 15:47:10,373 iteration 1983 : loss : 0.042472, loss_ce: 0.021464
2022-01-14 15:47:11,779 iteration 1984 : loss : 0.032470, loss_ce: 0.008887
2022-01-14 15:47:13,285 iteration 1985 : loss : 0.021868, loss_ce: 0.008622
2022-01-14 15:47:14,811 iteration 1986 : loss : 0.036530, loss_ce: 0.018410
2022-01-14 15:47:16,350 iteration 1987 : loss : 0.029538, loss_ce: 0.012349
2022-01-14 15:47:17,809 iteration 1988 : loss : 0.036416, loss_ce: 0.011208
2022-01-14 15:47:19,309 iteration 1989 : loss : 0.032994, loss_ce: 0.015276
 29%|████████▍                    | 117/400 [54:39<2:09:58, 27.56s/it]2022-01-14 15:47:20,774 iteration 1990 : loss : 0.024318, loss_ce: 0.010424
2022-01-14 15:47:22,229 iteration 1991 : loss : 0.024445, loss_ce: 0.008802
2022-01-14 15:47:23,778 iteration 1992 : loss : 0.037911, loss_ce: 0.013577
2022-01-14 15:47:25,427 iteration 1993 : loss : 0.035762, loss_ce: 0.018423
2022-01-14 15:47:26,871 iteration 1994 : loss : 0.024214, loss_ce: 0.010560
2022-01-14 15:47:28,388 iteration 1995 : loss : 0.052171, loss_ce: 0.013307
2022-01-14 15:47:29,921 iteration 1996 : loss : 0.037006, loss_ce: 0.011995
2022-01-14 15:47:31,398 iteration 1997 : loss : 0.026264, loss_ce: 0.008536
2022-01-14 15:47:32,885 iteration 1998 : loss : 0.040615, loss_ce: 0.013393
2022-01-14 15:47:34,364 iteration 1999 : loss : 0.037620, loss_ce: 0.015366
2022-01-14 15:47:35,961 iteration 2000 : loss : 0.033307, loss_ce: 0.009556
2022-01-14 15:47:37,454 iteration 2001 : loss : 0.035531, loss_ce: 0.015895
2022-01-14 15:47:39,030 iteration 2002 : loss : 0.046929, loss_ce: 0.024702
2022-01-14 15:47:40,482 iteration 2003 : loss : 0.036707, loss_ce: 0.016506
2022-01-14 15:47:42,004 iteration 2004 : loss : 0.040232, loss_ce: 0.013401
2022-01-14 15:47:43,549 iteration 2005 : loss : 0.045242, loss_ce: 0.017796
2022-01-14 15:47:45,095 iteration 2006 : loss : 0.035761, loss_ce: 0.011949
 30%|████████▌                    | 118/400 [55:05<2:07:01, 27.02s/it]2022-01-14 15:47:46,670 iteration 2007 : loss : 0.033464, loss_ce: 0.014296
2022-01-14 15:47:48,131 iteration 2008 : loss : 0.038466, loss_ce: 0.014235
2022-01-14 15:47:49,586 iteration 2009 : loss : 0.054572, loss_ce: 0.015252
2022-01-14 15:47:51,020 iteration 2010 : loss : 0.037375, loss_ce: 0.013982
2022-01-14 15:47:52,523 iteration 2011 : loss : 0.040582, loss_ce: 0.016561
2022-01-14 15:47:54,036 iteration 2012 : loss : 0.048354, loss_ce: 0.017762
2022-01-14 15:47:55,573 iteration 2013 : loss : 0.031943, loss_ce: 0.014097
2022-01-14 15:47:57,135 iteration 2014 : loss : 0.028429, loss_ce: 0.010736
2022-01-14 15:47:58,573 iteration 2015 : loss : 0.031017, loss_ce: 0.011989
2022-01-14 15:48:00,057 iteration 2016 : loss : 0.042500, loss_ce: 0.014731
2022-01-14 15:48:01,450 iteration 2017 : loss : 0.026859, loss_ce: 0.010370
2022-01-14 15:48:02,974 iteration 2018 : loss : 0.049851, loss_ce: 0.019495
2022-01-14 15:48:04,457 iteration 2019 : loss : 0.027477, loss_ce: 0.011292
2022-01-14 15:48:05,975 iteration 2020 : loss : 0.062042, loss_ce: 0.026125
2022-01-14 15:48:07,488 iteration 2021 : loss : 0.035356, loss_ce: 0.014186
2022-01-14 15:48:09,062 iteration 2022 : loss : 0.036922, loss_ce: 0.015439
2022-01-14 15:48:10,542 iteration 2023 : loss : 0.039060, loss_ce: 0.012511
 30%|████████▋                    | 119/400 [55:30<2:04:20, 26.55s/it]2022-01-14 15:48:12,127 iteration 2024 : loss : 0.047459, loss_ce: 0.020122
2022-01-14 15:48:13,543 iteration 2025 : loss : 0.027822, loss_ce: 0.009473
2022-01-14 15:48:14,995 iteration 2026 : loss : 0.039472, loss_ce: 0.015071
2022-01-14 15:48:16,542 iteration 2027 : loss : 0.030364, loss_ce: 0.009867
2022-01-14 15:48:18,071 iteration 2028 : loss : 0.035906, loss_ce: 0.013311
2022-01-14 15:48:19,491 iteration 2029 : loss : 0.035111, loss_ce: 0.017443
2022-01-14 15:48:21,014 iteration 2030 : loss : 0.030382, loss_ce: 0.011610
2022-01-14 15:48:22,545 iteration 2031 : loss : 0.028502, loss_ce: 0.010656
2022-01-14 15:48:24,108 iteration 2032 : loss : 0.035309, loss_ce: 0.011871
2022-01-14 15:48:25,552 iteration 2033 : loss : 0.044703, loss_ce: 0.013308
2022-01-14 15:48:26,969 iteration 2034 : loss : 0.023310, loss_ce: 0.008474
2022-01-14 15:48:28,423 iteration 2035 : loss : 0.026284, loss_ce: 0.012017
2022-01-14 15:48:29,946 iteration 2036 : loss : 0.041433, loss_ce: 0.017914
2022-01-14 15:48:31,428 iteration 2037 : loss : 0.040326, loss_ce: 0.012379
2022-01-14 15:48:32,897 iteration 2038 : loss : 0.027881, loss_ce: 0.009999
2022-01-14 15:48:34,406 iteration 2039 : loss : 0.037416, loss_ce: 0.016295
2022-01-14 15:48:34,407 Training Data Eval:
2022-01-14 15:48:41,876   Average segmentation loss on training set: 0.0214
2022-01-14 15:48:41,876 Validation Data Eval:
2022-01-14 15:48:44,440   Average segmentation loss on validation set: 0.0772
2022-01-14 15:48:45,923 iteration 2040 : loss : 0.035509, loss_ce: 0.011518
 30%|████████▋                    | 120/400 [56:05<2:16:15, 29.20s/it]2022-01-14 15:48:47,471 iteration 2041 : loss : 0.031392, loss_ce: 0.012604
2022-01-14 15:48:48,971 iteration 2042 : loss : 0.027685, loss_ce: 0.011881
2022-01-14 15:48:50,467 iteration 2043 : loss : 0.027248, loss_ce: 0.011638
2022-01-14 15:48:52,049 iteration 2044 : loss : 0.029842, loss_ce: 0.012541
2022-01-14 15:48:53,635 iteration 2045 : loss : 0.032394, loss_ce: 0.011354
2022-01-14 15:48:55,176 iteration 2046 : loss : 0.042939, loss_ce: 0.018133
2022-01-14 15:48:56,689 iteration 2047 : loss : 0.025624, loss_ce: 0.008510
2022-01-14 15:48:58,113 iteration 2048 : loss : 0.030213, loss_ce: 0.010173
2022-01-14 15:48:59,606 iteration 2049 : loss : 0.025935, loss_ce: 0.009762
2022-01-14 15:49:01,134 iteration 2050 : loss : 0.044958, loss_ce: 0.013975
2022-01-14 15:49:02,688 iteration 2051 : loss : 0.032702, loss_ce: 0.012601
2022-01-14 15:49:04,134 iteration 2052 : loss : 0.030211, loss_ce: 0.015184
2022-01-14 15:49:05,603 iteration 2053 : loss : 0.033484, loss_ce: 0.009444
2022-01-14 15:49:07,097 iteration 2054 : loss : 0.036809, loss_ce: 0.011881
2022-01-14 15:49:08,645 iteration 2055 : loss : 0.074283, loss_ce: 0.038897
2022-01-14 15:49:10,149 iteration 2056 : loss : 0.031940, loss_ce: 0.013428
2022-01-14 15:49:11,719 iteration 2057 : loss : 0.026241, loss_ce: 0.011031
 30%|████████▊                    | 121/400 [56:31<2:11:02, 28.18s/it]2022-01-14 15:49:13,364 iteration 2058 : loss : 0.031015, loss_ce: 0.014960
2022-01-14 15:49:14,915 iteration 2059 : loss : 0.030375, loss_ce: 0.011091
2022-01-14 15:49:16,510 iteration 2060 : loss : 0.030797, loss_ce: 0.010382
2022-01-14 15:49:17,960 iteration 2061 : loss : 0.031541, loss_ce: 0.015330
2022-01-14 15:49:19,401 iteration 2062 : loss : 0.036298, loss_ce: 0.014525
2022-01-14 15:49:20,875 iteration 2063 : loss : 0.024529, loss_ce: 0.010658
2022-01-14 15:49:22,376 iteration 2064 : loss : 0.022577, loss_ce: 0.010436
2022-01-14 15:49:23,901 iteration 2065 : loss : 0.033745, loss_ce: 0.010420
2022-01-14 15:49:25,462 iteration 2066 : loss : 0.042460, loss_ce: 0.015592
2022-01-14 15:49:26,950 iteration 2067 : loss : 0.031903, loss_ce: 0.011973
2022-01-14 15:49:28,535 iteration 2068 : loss : 0.045859, loss_ce: 0.022724
2022-01-14 15:49:30,104 iteration 2069 : loss : 0.047110, loss_ce: 0.013072
2022-01-14 15:49:31,579 iteration 2070 : loss : 0.026820, loss_ce: 0.009699
2022-01-14 15:49:33,100 iteration 2071 : loss : 0.031983, loss_ce: 0.014227
2022-01-14 15:49:34,550 iteration 2072 : loss : 0.029588, loss_ce: 0.012390
2022-01-14 15:49:36,015 iteration 2073 : loss : 0.028303, loss_ce: 0.009071
2022-01-14 15:49:37,546 iteration 2074 : loss : 0.035964, loss_ce: 0.009944
 30%|████████▊                    | 122/400 [56:57<2:07:17, 27.47s/it]2022-01-14 15:49:39,105 iteration 2075 : loss : 0.029535, loss_ce: 0.010690
2022-01-14 15:49:40,698 iteration 2076 : loss : 0.033441, loss_ce: 0.011971
2022-01-14 15:49:42,210 iteration 2077 : loss : 0.036710, loss_ce: 0.014493
2022-01-14 15:49:43,647 iteration 2078 : loss : 0.028093, loss_ce: 0.012034
2022-01-14 15:49:45,153 iteration 2079 : loss : 0.027951, loss_ce: 0.009216
2022-01-14 15:49:46,696 iteration 2080 : loss : 0.025956, loss_ce: 0.008426
2022-01-14 15:49:48,222 iteration 2081 : loss : 0.032306, loss_ce: 0.014766
2022-01-14 15:49:49,745 iteration 2082 : loss : 0.033282, loss_ce: 0.013362
2022-01-14 15:49:51,238 iteration 2083 : loss : 0.024754, loss_ce: 0.008689
2022-01-14 15:49:52,712 iteration 2084 : loss : 0.031735, loss_ce: 0.011920
2022-01-14 15:49:54,176 iteration 2085 : loss : 0.030199, loss_ce: 0.013896
2022-01-14 15:49:55,688 iteration 2086 : loss : 0.023498, loss_ce: 0.010837
2022-01-14 15:49:57,137 iteration 2087 : loss : 0.045922, loss_ce: 0.012493
2022-01-14 15:49:58,757 iteration 2088 : loss : 0.033667, loss_ce: 0.015034
2022-01-14 15:50:00,234 iteration 2089 : loss : 0.027808, loss_ce: 0.010259
2022-01-14 15:50:01,792 iteration 2090 : loss : 0.031495, loss_ce: 0.010989
2022-01-14 15:50:03,303 iteration 2091 : loss : 0.030358, loss_ce: 0.011695
 31%|████████▉                    | 123/400 [57:23<2:04:26, 26.96s/it]2022-01-14 15:50:04,850 iteration 2092 : loss : 0.030004, loss_ce: 0.011514
2022-01-14 15:50:06,450 iteration 2093 : loss : 0.036763, loss_ce: 0.016180
2022-01-14 15:50:07,975 iteration 2094 : loss : 0.027040, loss_ce: 0.011083
2022-01-14 15:50:09,515 iteration 2095 : loss : 0.032331, loss_ce: 0.012172
2022-01-14 15:50:11,083 iteration 2096 : loss : 0.043570, loss_ce: 0.016613
2022-01-14 15:50:12,555 iteration 2097 : loss : 0.028025, loss_ce: 0.012797
2022-01-14 15:50:14,114 iteration 2098 : loss : 0.031374, loss_ce: 0.012122
2022-01-14 15:50:15,645 iteration 2099 : loss : 0.043198, loss_ce: 0.014861
2022-01-14 15:50:17,244 iteration 2100 : loss : 0.034620, loss_ce: 0.015307
2022-01-14 15:50:18,748 iteration 2101 : loss : 0.040221, loss_ce: 0.012980
2022-01-14 15:50:20,271 iteration 2102 : loss : 0.024522, loss_ce: 0.010659
2022-01-14 15:50:21,917 iteration 2103 : loss : 0.034436, loss_ce: 0.012804
2022-01-14 15:50:23,486 iteration 2104 : loss : 0.027349, loss_ce: 0.009323
2022-01-14 15:50:24,982 iteration 2105 : loss : 0.037580, loss_ce: 0.012228
2022-01-14 15:50:26,559 iteration 2106 : loss : 0.055787, loss_ce: 0.017503
2022-01-14 15:50:28,062 iteration 2107 : loss : 0.043109, loss_ce: 0.016403
2022-01-14 15:50:29,595 iteration 2108 : loss : 0.024238, loss_ce: 0.008378
 31%|████████▉                    | 124/400 [57:49<2:03:05, 26.76s/it]2022-01-14 15:50:31,146 iteration 2109 : loss : 0.034091, loss_ce: 0.012890
2022-01-14 15:50:32,644 iteration 2110 : loss : 0.030913, loss_ce: 0.009931
2022-01-14 15:50:34,281 iteration 2111 : loss : 0.034860, loss_ce: 0.011767
2022-01-14 15:50:35,941 iteration 2112 : loss : 0.030852, loss_ce: 0.011979
2022-01-14 15:50:37,380 iteration 2113 : loss : 0.031552, loss_ce: 0.012464
2022-01-14 15:50:38,877 iteration 2114 : loss : 0.043946, loss_ce: 0.015846
2022-01-14 15:50:40,254 iteration 2115 : loss : 0.036417, loss_ce: 0.012159
2022-01-14 15:50:41,839 iteration 2116 : loss : 0.024932, loss_ce: 0.008598
2022-01-14 15:50:43,432 iteration 2117 : loss : 0.033291, loss_ce: 0.010720
2022-01-14 15:50:44,936 iteration 2118 : loss : 0.046008, loss_ce: 0.022565
2022-01-14 15:50:46,482 iteration 2119 : loss : 0.028456, loss_ce: 0.010865
2022-01-14 15:50:47,992 iteration 2120 : loss : 0.040019, loss_ce: 0.015570
2022-01-14 15:50:49,584 iteration 2121 : loss : 0.033050, loss_ce: 0.011416
2022-01-14 15:50:51,034 iteration 2122 : loss : 0.029236, loss_ce: 0.012273
2022-01-14 15:50:52,532 iteration 2123 : loss : 0.039229, loss_ce: 0.020433
2022-01-14 15:50:54,101 iteration 2124 : loss : 0.028007, loss_ce: 0.009877
2022-01-14 15:50:54,102 Training Data Eval:
2022-01-14 15:51:01,549   Average segmentation loss on training set: 0.0216
2022-01-14 15:51:01,549 Validation Data Eval:
2022-01-14 15:51:04,117   Average segmentation loss on validation set: 0.0686
2022-01-14 15:51:05,632 iteration 2125 : loss : 0.025506, loss_ce: 0.008854
 31%|█████████                    | 125/400 [58:25<2:15:24, 29.54s/it]2022-01-14 15:51:07,171 iteration 2126 : loss : 0.024774, loss_ce: 0.008596
2022-01-14 15:51:08,768 iteration 2127 : loss : 0.029202, loss_ce: 0.011757
2022-01-14 15:51:10,228 iteration 2128 : loss : 0.022026, loss_ce: 0.011211
2022-01-14 15:51:11,743 iteration 2129 : loss : 0.033219, loss_ce: 0.012736
2022-01-14 15:51:13,190 iteration 2130 : loss : 0.029183, loss_ce: 0.009497
2022-01-14 15:51:14,790 iteration 2131 : loss : 0.045872, loss_ce: 0.019000
2022-01-14 15:51:16,398 iteration 2132 : loss : 0.033757, loss_ce: 0.013256
2022-01-14 15:51:17,937 iteration 2133 : loss : 0.035340, loss_ce: 0.014481
2022-01-14 15:51:19,486 iteration 2134 : loss : 0.049636, loss_ce: 0.014501
2022-01-14 15:51:21,013 iteration 2135 : loss : 0.032208, loss_ce: 0.010432
2022-01-14 15:51:22,530 iteration 2136 : loss : 0.032650, loss_ce: 0.012018
2022-01-14 15:51:24,063 iteration 2137 : loss : 0.057723, loss_ce: 0.016758
2022-01-14 15:51:25,533 iteration 2138 : loss : 0.029411, loss_ce: 0.009596
2022-01-14 15:51:26,968 iteration 2139 : loss : 0.035291, loss_ce: 0.016898
2022-01-14 15:51:28,458 iteration 2140 : loss : 0.034406, loss_ce: 0.011305
2022-01-14 15:51:29,979 iteration 2141 : loss : 0.037360, loss_ce: 0.014064
2022-01-14 15:51:31,493 iteration 2142 : loss : 0.050340, loss_ce: 0.022149
 32%|█████████▏                   | 126/400 [58:51<2:09:52, 28.44s/it]2022-01-14 15:51:33,096 iteration 2143 : loss : 0.032798, loss_ce: 0.008688
2022-01-14 15:51:34,596 iteration 2144 : loss : 0.044250, loss_ce: 0.012803
2022-01-14 15:51:36,022 iteration 2145 : loss : 0.023663, loss_ce: 0.011575
2022-01-14 15:51:37,685 iteration 2146 : loss : 0.042995, loss_ce: 0.014879
2022-01-14 15:51:39,236 iteration 2147 : loss : 0.024860, loss_ce: 0.009599
2022-01-14 15:51:40,750 iteration 2148 : loss : 0.026747, loss_ce: 0.010807
2022-01-14 15:51:42,260 iteration 2149 : loss : 0.040487, loss_ce: 0.016553
2022-01-14 15:51:43,843 iteration 2150 : loss : 0.046413, loss_ce: 0.016182
2022-01-14 15:51:45,381 iteration 2151 : loss : 0.041504, loss_ce: 0.016296
2022-01-14 15:51:46,811 iteration 2152 : loss : 0.025421, loss_ce: 0.011554
2022-01-14 15:51:48,317 iteration 2153 : loss : 0.034699, loss_ce: 0.008964
2022-01-14 15:51:49,773 iteration 2154 : loss : 0.029765, loss_ce: 0.013377
2022-01-14 15:51:51,232 iteration 2155 : loss : 0.033416, loss_ce: 0.013315
2022-01-14 15:51:52,771 iteration 2156 : loss : 0.047385, loss_ce: 0.017916
2022-01-14 15:51:54,320 iteration 2157 : loss : 0.039667, loss_ce: 0.018478
2022-01-14 15:51:55,801 iteration 2158 : loss : 0.029787, loss_ce: 0.011460
2022-01-14 15:51:57,368 iteration 2159 : loss : 0.049051, loss_ce: 0.017245
 32%|█████████▏                   | 127/400 [59:17<2:05:53, 27.67s/it]2022-01-14 15:51:58,828 iteration 2160 : loss : 0.024285, loss_ce: 0.008189
2022-01-14 15:52:00,350 iteration 2161 : loss : 0.024225, loss_ce: 0.009431
2022-01-14 15:52:01,875 iteration 2162 : loss : 0.030199, loss_ce: 0.012592
2022-01-14 15:52:03,282 iteration 2163 : loss : 0.033360, loss_ce: 0.010784
2022-01-14 15:52:04,815 iteration 2164 : loss : 0.036996, loss_ce: 0.017193
2022-01-14 15:52:06,310 iteration 2165 : loss : 0.033223, loss_ce: 0.010904
2022-01-14 15:52:07,862 iteration 2166 : loss : 0.039935, loss_ce: 0.020237
2022-01-14 15:52:09,362 iteration 2167 : loss : 0.025978, loss_ce: 0.012437
2022-01-14 15:52:10,857 iteration 2168 : loss : 0.028083, loss_ce: 0.011066
2022-01-14 15:52:12,393 iteration 2169 : loss : 0.026487, loss_ce: 0.009850
2022-01-14 15:52:13,880 iteration 2170 : loss : 0.029545, loss_ce: 0.009459
2022-01-14 15:52:15,377 iteration 2171 : loss : 0.019119, loss_ce: 0.006199
2022-01-14 15:52:16,779 iteration 2172 : loss : 0.027309, loss_ce: 0.012578
2022-01-14 15:52:18,292 iteration 2173 : loss : 0.030551, loss_ce: 0.012409
2022-01-14 15:52:19,856 iteration 2174 : loss : 0.043304, loss_ce: 0.018484
2022-01-14 15:52:21,291 iteration 2175 : loss : 0.038449, loss_ce: 0.011999
2022-01-14 15:52:22,738 iteration 2176 : loss : 0.036358, loss_ce: 0.019352
 32%|█████████▎                   | 128/400 [59:42<2:02:17, 26.98s/it]2022-01-14 15:52:24,337 iteration 2177 : loss : 0.039083, loss_ce: 0.012353
2022-01-14 15:52:25,770 iteration 2178 : loss : 0.024319, loss_ce: 0.010634
2022-01-14 15:52:27,280 iteration 2179 : loss : 0.023708, loss_ce: 0.009543
2022-01-14 15:52:28,792 iteration 2180 : loss : 0.025638, loss_ce: 0.007553
2022-01-14 15:52:30,267 iteration 2181 : loss : 0.033121, loss_ce: 0.010048
2022-01-14 15:52:31,741 iteration 2182 : loss : 0.028028, loss_ce: 0.009118
2022-01-14 15:52:33,194 iteration 2183 : loss : 0.037909, loss_ce: 0.009372
2022-01-14 15:52:34,644 iteration 2184 : loss : 0.030846, loss_ce: 0.014621
2022-01-14 15:52:36,067 iteration 2185 : loss : 0.026269, loss_ce: 0.010760
2022-01-14 15:52:37,683 iteration 2186 : loss : 0.050610, loss_ce: 0.020626
2022-01-14 15:52:39,097 iteration 2187 : loss : 0.023343, loss_ce: 0.011467
2022-01-14 15:52:40,612 iteration 2188 : loss : 0.028333, loss_ce: 0.010474
2022-01-14 15:52:42,047 iteration 2189 : loss : 0.030368, loss_ce: 0.012063
2022-01-14 15:52:43,613 iteration 2190 : loss : 0.030730, loss_ce: 0.010969
2022-01-14 15:52:45,035 iteration 2191 : loss : 0.028533, loss_ce: 0.011654
2022-01-14 15:52:46,534 iteration 2192 : loss : 0.035188, loss_ce: 0.013090
2022-01-14 15:52:48,115 iteration 2193 : loss : 0.031219, loss_ce: 0.011642
 32%|████████▋                  | 129/400 [1:00:08<1:59:41, 26.50s/it]2022-01-14 15:52:49,628 iteration 2194 : loss : 0.033801, loss_ce: 0.013764
2022-01-14 15:52:51,072 iteration 2195 : loss : 0.042723, loss_ce: 0.015787
2022-01-14 15:52:52,595 iteration 2196 : loss : 0.025584, loss_ce: 0.010661
2022-01-14 15:52:54,139 iteration 2197 : loss : 0.044771, loss_ce: 0.018848
2022-01-14 15:52:55,605 iteration 2198 : loss : 0.025844, loss_ce: 0.011955
2022-01-14 15:52:57,296 iteration 2199 : loss : 0.041823, loss_ce: 0.017089
2022-01-14 15:52:58,820 iteration 2200 : loss : 0.022689, loss_ce: 0.008416
2022-01-14 15:53:00,351 iteration 2201 : loss : 0.064385, loss_ce: 0.020493
2022-01-14 15:53:01,837 iteration 2202 : loss : 0.058100, loss_ce: 0.019666
2022-01-14 15:53:03,434 iteration 2203 : loss : 0.028980, loss_ce: 0.009031
2022-01-14 15:53:04,986 iteration 2204 : loss : 0.036755, loss_ce: 0.013254
2022-01-14 15:53:06,392 iteration 2205 : loss : 0.028785, loss_ce: 0.013042
2022-01-14 15:53:07,825 iteration 2206 : loss : 0.024460, loss_ce: 0.011149
2022-01-14 15:53:09,318 iteration 2207 : loss : 0.039944, loss_ce: 0.019986
2022-01-14 15:53:10,786 iteration 2208 : loss : 0.051981, loss_ce: 0.019157
2022-01-14 15:53:12,347 iteration 2209 : loss : 0.064428, loss_ce: 0.021876
2022-01-14 15:53:12,347 Training Data Eval:
2022-01-14 15:53:19,802   Average segmentation loss on training set: 0.0356
2022-01-14 15:53:19,803 Validation Data Eval:
2022-01-14 15:53:22,374   Average segmentation loss on validation set: 0.0739
2022-01-14 15:53:23,887 iteration 2210 : loss : 0.029807, loss_ce: 0.009782
 32%|████████▊                  | 130/400 [1:00:43<2:11:45, 29.28s/it]2022-01-14 15:53:25,468 iteration 2211 : loss : 0.037713, loss_ce: 0.018991
2022-01-14 15:53:26,909 iteration 2212 : loss : 0.029327, loss_ce: 0.009887
2022-01-14 15:53:28,360 iteration 2213 : loss : 0.027973, loss_ce: 0.011120
2022-01-14 15:53:29,891 iteration 2214 : loss : 0.043347, loss_ce: 0.017881
2022-01-14 15:53:31,362 iteration 2215 : loss : 0.027226, loss_ce: 0.010382
2022-01-14 15:53:32,838 iteration 2216 : loss : 0.032095, loss_ce: 0.014006
2022-01-14 15:53:34,259 iteration 2217 : loss : 0.033979, loss_ce: 0.015132
2022-01-14 15:53:35,823 iteration 2218 : loss : 0.031924, loss_ce: 0.011318
2022-01-14 15:53:37,270 iteration 2219 : loss : 0.027592, loss_ce: 0.010204
2022-01-14 15:53:38,782 iteration 2220 : loss : 0.028034, loss_ce: 0.013424
2022-01-14 15:53:40,376 iteration 2221 : loss : 0.038262, loss_ce: 0.016328
2022-01-14 15:53:41,830 iteration 2222 : loss : 0.046586, loss_ce: 0.014440
2022-01-14 15:53:43,453 iteration 2223 : loss : 0.044166, loss_ce: 0.015551
2022-01-14 15:53:44,914 iteration 2224 : loss : 0.050314, loss_ce: 0.014843
2022-01-14 15:53:46,403 iteration 2225 : loss : 0.029291, loss_ce: 0.012198
2022-01-14 15:53:48,052 iteration 2226 : loss : 0.052972, loss_ce: 0.024594
2022-01-14 15:53:49,610 iteration 2227 : loss : 0.034904, loss_ce: 0.010304
 33%|████████▊                  | 131/400 [1:01:09<2:06:29, 28.21s/it]2022-01-14 15:53:51,176 iteration 2228 : loss : 0.047729, loss_ce: 0.017494
2022-01-14 15:53:52,712 iteration 2229 : loss : 0.038045, loss_ce: 0.016249
2022-01-14 15:53:54,149 iteration 2230 : loss : 0.027349, loss_ce: 0.010942
2022-01-14 15:53:55,589 iteration 2231 : loss : 0.022802, loss_ce: 0.010266
2022-01-14 15:53:57,046 iteration 2232 : loss : 0.027098, loss_ce: 0.009321
2022-01-14 15:53:58,517 iteration 2233 : loss : 0.037150, loss_ce: 0.013107
2022-01-14 15:54:00,033 iteration 2234 : loss : 0.046467, loss_ce: 0.015114
2022-01-14 15:54:01,475 iteration 2235 : loss : 0.040638, loss_ce: 0.019690
2022-01-14 15:54:02,934 iteration 2236 : loss : 0.028166, loss_ce: 0.012466
2022-01-14 15:54:04,441 iteration 2237 : loss : 0.030761, loss_ce: 0.014145
2022-01-14 15:54:05,920 iteration 2238 : loss : 0.039337, loss_ce: 0.013605
2022-01-14 15:54:07,461 iteration 2239 : loss : 0.054041, loss_ce: 0.019003
2022-01-14 15:54:08,876 iteration 2240 : loss : 0.028015, loss_ce: 0.010549
2022-01-14 15:54:10,444 iteration 2241 : loss : 0.023903, loss_ce: 0.009644
2022-01-14 15:54:11,887 iteration 2242 : loss : 0.029048, loss_ce: 0.013498
2022-01-14 15:54:13,354 iteration 2243 : loss : 0.033082, loss_ce: 0.008598
2022-01-14 15:54:14,858 iteration 2244 : loss : 0.018690, loss_ce: 0.007272
 33%|████████▉                  | 132/400 [1:01:34<2:02:02, 27.32s/it]2022-01-14 15:54:16,316 iteration 2245 : loss : 0.021393, loss_ce: 0.008292
2022-01-14 15:54:17,836 iteration 2246 : loss : 0.038319, loss_ce: 0.014652
2022-01-14 15:54:19,360 iteration 2247 : loss : 0.036286, loss_ce: 0.014086
2022-01-14 15:54:20,748 iteration 2248 : loss : 0.018734, loss_ce: 0.007993
2022-01-14 15:54:22,336 iteration 2249 : loss : 0.029009, loss_ce: 0.013584
2022-01-14 15:54:23,997 iteration 2250 : loss : 0.040780, loss_ce: 0.016817
2022-01-14 15:54:25,393 iteration 2251 : loss : 0.035204, loss_ce: 0.013201
2022-01-14 15:54:26,935 iteration 2252 : loss : 0.034880, loss_ce: 0.014278
2022-01-14 15:54:28,366 iteration 2253 : loss : 0.042054, loss_ce: 0.012185
2022-01-14 15:54:29,920 iteration 2254 : loss : 0.043351, loss_ce: 0.017214
2022-01-14 15:54:31,478 iteration 2255 : loss : 0.032632, loss_ce: 0.014164
2022-01-14 15:54:33,080 iteration 2256 : loss : 0.034972, loss_ce: 0.012189
2022-01-14 15:54:34,576 iteration 2257 : loss : 0.034555, loss_ce: 0.011007
2022-01-14 15:54:36,077 iteration 2258 : loss : 0.033560, loss_ce: 0.013428
2022-01-14 15:54:37,607 iteration 2259 : loss : 0.031799, loss_ce: 0.010412
2022-01-14 15:54:39,134 iteration 2260 : loss : 0.044109, loss_ce: 0.016161
2022-01-14 15:54:40,581 iteration 2261 : loss : 0.043773, loss_ce: 0.011032
 33%|████████▉                  | 133/400 [1:02:00<1:59:27, 26.84s/it]2022-01-14 15:54:42,234 iteration 2262 : loss : 0.036429, loss_ce: 0.016589
2022-01-14 15:54:43,744 iteration 2263 : loss : 0.026563, loss_ce: 0.010365
2022-01-14 15:54:45,288 iteration 2264 : loss : 0.031102, loss_ce: 0.009177
2022-01-14 15:54:46,823 iteration 2265 : loss : 0.034714, loss_ce: 0.011852
2022-01-14 15:54:48,330 iteration 2266 : loss : 0.028906, loss_ce: 0.010117
2022-01-14 15:54:49,844 iteration 2267 : loss : 0.028728, loss_ce: 0.009470
2022-01-14 15:54:51,252 iteration 2268 : loss : 0.026522, loss_ce: 0.011196
2022-01-14 15:54:52,773 iteration 2269 : loss : 0.039056, loss_ce: 0.017184
2022-01-14 15:54:54,225 iteration 2270 : loss : 0.027445, loss_ce: 0.010130
2022-01-14 15:54:55,677 iteration 2271 : loss : 0.053650, loss_ce: 0.031882
2022-01-14 15:54:57,125 iteration 2272 : loss : 0.027179, loss_ce: 0.007216
2022-01-14 15:54:58,679 iteration 2273 : loss : 0.030854, loss_ce: 0.010234
2022-01-14 15:55:00,113 iteration 2274 : loss : 0.028853, loss_ce: 0.009014
2022-01-14 15:55:01,604 iteration 2275 : loss : 0.027352, loss_ce: 0.011406
2022-01-14 15:55:03,130 iteration 2276 : loss : 0.049187, loss_ce: 0.015101
2022-01-14 15:55:04,586 iteration 2277 : loss : 0.033110, loss_ce: 0.014224
2022-01-14 15:55:06,072 iteration 2278 : loss : 0.028765, loss_ce: 0.011763
 34%|█████████                  | 134/400 [1:02:26<1:57:13, 26.44s/it]2022-01-14 15:55:07,757 iteration 2279 : loss : 0.032569, loss_ce: 0.015698
2022-01-14 15:55:09,308 iteration 2280 : loss : 0.030177, loss_ce: 0.013340
2022-01-14 15:55:10,725 iteration 2281 : loss : 0.040324, loss_ce: 0.015002
2022-01-14 15:55:12,352 iteration 2282 : loss : 0.030584, loss_ce: 0.011536
2022-01-14 15:55:13,778 iteration 2283 : loss : 0.033587, loss_ce: 0.012329
2022-01-14 15:55:15,383 iteration 2284 : loss : 0.069277, loss_ce: 0.026323
2022-01-14 15:55:16,853 iteration 2285 : loss : 0.027434, loss_ce: 0.009143
2022-01-14 15:55:18,342 iteration 2286 : loss : 0.022400, loss_ce: 0.007480
2022-01-14 15:55:19,861 iteration 2287 : loss : 0.031519, loss_ce: 0.008245
2022-01-14 15:55:21,288 iteration 2288 : loss : 0.040472, loss_ce: 0.015177
2022-01-14 15:55:22,820 iteration 2289 : loss : 0.028756, loss_ce: 0.010824
2022-01-14 15:55:24,298 iteration 2290 : loss : 0.029441, loss_ce: 0.010164
2022-01-14 15:55:25,758 iteration 2291 : loss : 0.029531, loss_ce: 0.009997
2022-01-14 15:55:27,303 iteration 2292 : loss : 0.038552, loss_ce: 0.012634
2022-01-14 15:55:28,746 iteration 2293 : loss : 0.039302, loss_ce: 0.015089
2022-01-14 15:55:30,254 iteration 2294 : loss : 0.033522, loss_ce: 0.013952
2022-01-14 15:55:30,254 Training Data Eval:
2022-01-14 15:55:37,725   Average segmentation loss on training set: 0.0212
2022-01-14 15:55:37,726 Validation Data Eval:
2022-01-14 15:55:40,290   Average segmentation loss on validation set: 0.0649
2022-01-14 15:55:41,810 iteration 2295 : loss : 0.027542, loss_ce: 0.010108
 34%|█████████                  | 135/400 [1:03:01<2:09:05, 29.23s/it]2022-01-14 15:55:43,382 iteration 2296 : loss : 0.031453, loss_ce: 0.011671
2022-01-14 15:55:44,921 iteration 2297 : loss : 0.034293, loss_ce: 0.010244
2022-01-14 15:55:46,574 iteration 2298 : loss : 0.049621, loss_ce: 0.018171
2022-01-14 15:55:48,056 iteration 2299 : loss : 0.044333, loss_ce: 0.010253
2022-01-14 15:55:49,637 iteration 2300 : loss : 0.031812, loss_ce: 0.011959
2022-01-14 15:55:51,144 iteration 2301 : loss : 0.035774, loss_ce: 0.015759
2022-01-14 15:55:52,666 iteration 2302 : loss : 0.031078, loss_ce: 0.016096
2022-01-14 15:55:54,133 iteration 2303 : loss : 0.029274, loss_ce: 0.009035
2022-01-14 15:55:55,548 iteration 2304 : loss : 0.038568, loss_ce: 0.014681
2022-01-14 15:55:57,097 iteration 2305 : loss : 0.035178, loss_ce: 0.011639
2022-01-14 15:55:58,553 iteration 2306 : loss : 0.036849, loss_ce: 0.012262
2022-01-14 15:55:59,983 iteration 2307 : loss : 0.024570, loss_ce: 0.008516
2022-01-14 15:56:01,456 iteration 2308 : loss : 0.033428, loss_ce: 0.015112
2022-01-14 15:56:02,989 iteration 2309 : loss : 0.033138, loss_ce: 0.012736
2022-01-14 15:56:04,509 iteration 2310 : loss : 0.045787, loss_ce: 0.019813
2022-01-14 15:56:06,133 iteration 2311 : loss : 0.031693, loss_ce: 0.010592
2022-01-14 15:56:07,659 iteration 2312 : loss : 0.032358, loss_ce: 0.014877
 34%|█████████▏                 | 136/400 [1:03:27<2:04:08, 28.21s/it]2022-01-14 15:56:09,199 iteration 2313 : loss : 0.028212, loss_ce: 0.012527
2022-01-14 15:56:10,629 iteration 2314 : loss : 0.026122, loss_ce: 0.010399
2022-01-14 15:56:12,144 iteration 2315 : loss : 0.027149, loss_ce: 0.009255
2022-01-14 15:56:13,689 iteration 2316 : loss : 0.031704, loss_ce: 0.014557
2022-01-14 15:56:15,117 iteration 2317 : loss : 0.037136, loss_ce: 0.012774
2022-01-14 15:56:16,672 iteration 2318 : loss : 0.025290, loss_ce: 0.011001
2022-01-14 15:56:18,261 iteration 2319 : loss : 0.064036, loss_ce: 0.016201
2022-01-14 15:56:19,707 iteration 2320 : loss : 0.040335, loss_ce: 0.018449
2022-01-14 15:56:21,181 iteration 2321 : loss : 0.063228, loss_ce: 0.020175
2022-01-14 15:56:22,687 iteration 2322 : loss : 0.032943, loss_ce: 0.011531
2022-01-14 15:56:24,289 iteration 2323 : loss : 0.050192, loss_ce: 0.017140
2022-01-14 15:56:25,802 iteration 2324 : loss : 0.032838, loss_ce: 0.010033
2022-01-14 15:56:27,318 iteration 2325 : loss : 0.029824, loss_ce: 0.014053
2022-01-14 15:56:28,851 iteration 2326 : loss : 0.032541, loss_ce: 0.017661
2022-01-14 15:56:30,346 iteration 2327 : loss : 0.030515, loss_ce: 0.010471
2022-01-14 15:56:31,926 iteration 2328 : loss : 0.034489, loss_ce: 0.013992
2022-01-14 15:56:33,414 iteration 2329 : loss : 0.043281, loss_ce: 0.018893
 34%|█████████▏                 | 137/400 [1:03:53<2:00:25, 27.48s/it]2022-01-14 15:56:34,933 iteration 2330 : loss : 0.028433, loss_ce: 0.011628
2022-01-14 15:56:36,365 iteration 2331 : loss : 0.033043, loss_ce: 0.008685
2022-01-14 15:56:37,946 iteration 2332 : loss : 0.030294, loss_ce: 0.013114
2022-01-14 15:56:39,368 iteration 2333 : loss : 0.026994, loss_ce: 0.014642
2022-01-14 15:56:40,879 iteration 2334 : loss : 0.036904, loss_ce: 0.008524
2022-01-14 15:56:42,480 iteration 2335 : loss : 0.051217, loss_ce: 0.022810
2022-01-14 15:56:43,909 iteration 2336 : loss : 0.040615, loss_ce: 0.019651
2022-01-14 15:56:45,411 iteration 2337 : loss : 0.028257, loss_ce: 0.010186
2022-01-14 15:56:46,962 iteration 2338 : loss : 0.034980, loss_ce: 0.013796
2022-01-14 15:56:48,459 iteration 2339 : loss : 0.041766, loss_ce: 0.015888
2022-01-14 15:56:49,992 iteration 2340 : loss : 0.034775, loss_ce: 0.014537
2022-01-14 15:56:51,487 iteration 2341 : loss : 0.046306, loss_ce: 0.018319
2022-01-14 15:56:53,016 iteration 2342 : loss : 0.027112, loss_ce: 0.009778
2022-01-14 15:56:54,522 iteration 2343 : loss : 0.026349, loss_ce: 0.009519
2022-01-14 15:56:55,942 iteration 2344 : loss : 0.026953, loss_ce: 0.010062
2022-01-14 15:56:57,399 iteration 2345 : loss : 0.027492, loss_ce: 0.010902
2022-01-14 15:56:58,820 iteration 2346 : loss : 0.030669, loss_ce: 0.010662
 34%|█████████▎                 | 138/400 [1:04:18<1:57:15, 26.85s/it]2022-01-14 15:57:00,385 iteration 2347 : loss : 0.035070, loss_ce: 0.012710
2022-01-14 15:57:01,852 iteration 2348 : loss : 0.030958, loss_ce: 0.010726
2022-01-14 15:57:03,382 iteration 2349 : loss : 0.039631, loss_ce: 0.020458
2022-01-14 15:57:04,801 iteration 2350 : loss : 0.023666, loss_ce: 0.010372
2022-01-14 15:57:06,330 iteration 2351 : loss : 0.033786, loss_ce: 0.011571
2022-01-14 15:57:07,897 iteration 2352 : loss : 0.033424, loss_ce: 0.013586
2022-01-14 15:57:09,319 iteration 2353 : loss : 0.025650, loss_ce: 0.011014
2022-01-14 15:57:10,859 iteration 2354 : loss : 0.053110, loss_ce: 0.017061
2022-01-14 15:57:12,322 iteration 2355 : loss : 0.026160, loss_ce: 0.013159
2022-01-14 15:57:13,955 iteration 2356 : loss : 0.047579, loss_ce: 0.016167
2022-01-14 15:57:15,507 iteration 2357 : loss : 0.040227, loss_ce: 0.016302
2022-01-14 15:57:17,112 iteration 2358 : loss : 0.045053, loss_ce: 0.016506
2022-01-14 15:57:18,669 iteration 2359 : loss : 0.040954, loss_ce: 0.011909
2022-01-14 15:57:20,073 iteration 2360 : loss : 0.066281, loss_ce: 0.011554
2022-01-14 15:57:21,522 iteration 2361 : loss : 0.024629, loss_ce: 0.008516
2022-01-14 15:57:23,032 iteration 2362 : loss : 0.033762, loss_ce: 0.014320
2022-01-14 15:57:24,529 iteration 2363 : loss : 0.027811, loss_ce: 0.008520
 35%|█████████▍                 | 139/400 [1:04:44<1:55:19, 26.51s/it]2022-01-14 15:57:26,063 iteration 2364 : loss : 0.068891, loss_ce: 0.033140
2022-01-14 15:57:27,525 iteration 2365 : loss : 0.027216, loss_ce: 0.009425
2022-01-14 15:57:29,064 iteration 2366 : loss : 0.030443, loss_ce: 0.013144
2022-01-14 15:57:30,535 iteration 2367 : loss : 0.046489, loss_ce: 0.014331
2022-01-14 15:57:32,199 iteration 2368 : loss : 0.036400, loss_ce: 0.008850
2022-01-14 15:57:33,679 iteration 2369 : loss : 0.039422, loss_ce: 0.013770
2022-01-14 15:57:35,134 iteration 2370 : loss : 0.020213, loss_ce: 0.007103
2022-01-14 15:57:36,627 iteration 2371 : loss : 0.035747, loss_ce: 0.014607
2022-01-14 15:57:38,048 iteration 2372 : loss : 0.022482, loss_ce: 0.011075
2022-01-14 15:57:39,544 iteration 2373 : loss : 0.023953, loss_ce: 0.007942
2022-01-14 15:57:41,098 iteration 2374 : loss : 0.031190, loss_ce: 0.011302
2022-01-14 15:57:42,573 iteration 2375 : loss : 0.026472, loss_ce: 0.009276
2022-01-14 15:57:44,142 iteration 2376 : loss : 0.034292, loss_ce: 0.015084
2022-01-14 15:57:45,628 iteration 2377 : loss : 0.027331, loss_ce: 0.007155
2022-01-14 15:57:47,252 iteration 2378 : loss : 0.037027, loss_ce: 0.017950
2022-01-14 15:57:48,769 iteration 2379 : loss : 0.040758, loss_ce: 0.012685
2022-01-14 15:57:48,770 Training Data Eval:
2022-01-14 15:57:56,240   Average segmentation loss on training set: 0.0231
2022-01-14 15:57:56,241 Validation Data Eval:
2022-01-14 15:57:58,812   Average segmentation loss on validation set: 0.1129
2022-01-14 15:58:00,481 iteration 2380 : loss : 0.040173, loss_ce: 0.014057
 35%|█████████▍                 | 140/400 [1:05:20<2:07:08, 29.34s/it]2022-01-14 15:58:01,954 iteration 2381 : loss : 0.031922, loss_ce: 0.010187
2022-01-14 15:58:03,539 iteration 2382 : loss : 0.029855, loss_ce: 0.014106
2022-01-14 15:58:05,099 iteration 2383 : loss : 0.035623, loss_ce: 0.013594
2022-01-14 15:58:06,600 iteration 2384 : loss : 0.049044, loss_ce: 0.013966
2022-01-14 15:58:08,126 iteration 2385 : loss : 0.027076, loss_ce: 0.013486
2022-01-14 15:58:09,714 iteration 2386 : loss : 0.042432, loss_ce: 0.014629
2022-01-14 15:58:11,166 iteration 2387 : loss : 0.041759, loss_ce: 0.013630
2022-01-14 15:58:12,710 iteration 2388 : loss : 0.026899, loss_ce: 0.011263
2022-01-14 15:58:14,187 iteration 2389 : loss : 0.034777, loss_ce: 0.013106
2022-01-14 15:58:15,707 iteration 2390 : loss : 0.024624, loss_ce: 0.010426
2022-01-14 15:58:17,180 iteration 2391 : loss : 0.029336, loss_ce: 0.010916
2022-01-14 15:58:18,625 iteration 2392 : loss : 0.026916, loss_ce: 0.011169
2022-01-14 15:58:20,083 iteration 2393 : loss : 0.029079, loss_ce: 0.013698
2022-01-14 15:58:21,601 iteration 2394 : loss : 0.053239, loss_ce: 0.012166
2022-01-14 15:58:23,218 iteration 2395 : loss : 0.033452, loss_ce: 0.012397
2022-01-14 15:58:24,779 iteration 2396 : loss : 0.023236, loss_ce: 0.008425
2022-01-14 15:58:26,284 iteration 2397 : loss : 0.042782, loss_ce: 0.013745
 35%|█████████▌                 | 141/400 [1:05:46<2:02:05, 28.28s/it]2022-01-14 15:58:27,913 iteration 2398 : loss : 0.033149, loss_ce: 0.017587
2022-01-14 15:58:29,332 iteration 2399 : loss : 0.023371, loss_ce: 0.009126
2022-01-14 15:58:30,820 iteration 2400 : loss : 0.033090, loss_ce: 0.008738
2022-01-14 15:58:32,345 iteration 2401 : loss : 0.034741, loss_ce: 0.012857
2022-01-14 15:58:33,832 iteration 2402 : loss : 0.035264, loss_ce: 0.015111
2022-01-14 15:58:35,323 iteration 2403 : loss : 0.027880, loss_ce: 0.010112
2022-01-14 15:58:36,787 iteration 2404 : loss : 0.030799, loss_ce: 0.014361
2022-01-14 15:58:38,277 iteration 2405 : loss : 0.028154, loss_ce: 0.010896
2022-01-14 15:58:39,877 iteration 2406 : loss : 0.035834, loss_ce: 0.018534
2022-01-14 15:58:41,311 iteration 2407 : loss : 0.024653, loss_ce: 0.008401
2022-01-14 15:58:42,777 iteration 2408 : loss : 0.029127, loss_ce: 0.012579
2022-01-14 15:58:44,304 iteration 2409 : loss : 0.032665, loss_ce: 0.011262
2022-01-14 15:58:45,828 iteration 2410 : loss : 0.036191, loss_ce: 0.009474
2022-01-14 15:58:47,268 iteration 2411 : loss : 0.021925, loss_ce: 0.007176
2022-01-14 15:58:48,827 iteration 2412 : loss : 0.033035, loss_ce: 0.012273
2022-01-14 15:58:50,425 iteration 2413 : loss : 0.039466, loss_ce: 0.018132
2022-01-14 15:58:51,953 iteration 2414 : loss : 0.030745, loss_ce: 0.012408
 36%|█████████▌                 | 142/400 [1:06:12<1:58:14, 27.50s/it]2022-01-14 15:58:53,502 iteration 2415 : loss : 0.026947, loss_ce: 0.008417
2022-01-14 15:58:54,990 iteration 2416 : loss : 0.029775, loss_ce: 0.014143
2022-01-14 15:58:56,524 iteration 2417 : loss : 0.025828, loss_ce: 0.008194
2022-01-14 15:58:58,064 iteration 2418 : loss : 0.041495, loss_ce: 0.012871
2022-01-14 15:58:59,575 iteration 2419 : loss : 0.023290, loss_ce: 0.010930
2022-01-14 15:59:01,015 iteration 2420 : loss : 0.022589, loss_ce: 0.008144
2022-01-14 15:59:02,673 iteration 2421 : loss : 0.030576, loss_ce: 0.009065
2022-01-14 15:59:04,231 iteration 2422 : loss : 0.034811, loss_ce: 0.010236
2022-01-14 15:59:05,738 iteration 2423 : loss : 0.026907, loss_ce: 0.012041
2022-01-14 15:59:07,182 iteration 2424 : loss : 0.024920, loss_ce: 0.008373
2022-01-14 15:59:08,755 iteration 2425 : loss : 0.027033, loss_ce: 0.012970
2022-01-14 15:59:10,223 iteration 2426 : loss : 0.026552, loss_ce: 0.009478
2022-01-14 15:59:11,871 iteration 2427 : loss : 0.050355, loss_ce: 0.014716
2022-01-14 15:59:13,454 iteration 2428 : loss : 0.028675, loss_ce: 0.010652
2022-01-14 15:59:15,050 iteration 2429 : loss : 0.025100, loss_ce: 0.009444
2022-01-14 15:59:16,579 iteration 2430 : loss : 0.037317, loss_ce: 0.015162
2022-01-14 15:59:18,052 iteration 2431 : loss : 0.020337, loss_ce: 0.008930
 36%|█████████▋                 | 143/400 [1:06:38<1:55:59, 27.08s/it]2022-01-14 15:59:19,627 iteration 2432 : loss : 0.026794, loss_ce: 0.012138
2022-01-14 15:59:21,141 iteration 2433 : loss : 0.053454, loss_ce: 0.018111
2022-01-14 15:59:22,656 iteration 2434 : loss : 0.021204, loss_ce: 0.005697
2022-01-14 15:59:24,297 iteration 2435 : loss : 0.028853, loss_ce: 0.015044
2022-01-14 15:59:25,704 iteration 2436 : loss : 0.025080, loss_ce: 0.008726
2022-01-14 15:59:27,156 iteration 2437 : loss : 0.029832, loss_ce: 0.013381
2022-01-14 15:59:28,825 iteration 2438 : loss : 0.032678, loss_ce: 0.012905
2022-01-14 15:59:30,330 iteration 2439 : loss : 0.039116, loss_ce: 0.015330
2022-01-14 15:59:31,822 iteration 2440 : loss : 0.026022, loss_ce: 0.008345
2022-01-14 15:59:33,296 iteration 2441 : loss : 0.039232, loss_ce: 0.011762
2022-01-14 15:59:34,721 iteration 2442 : loss : 0.028899, loss_ce: 0.009727
2022-01-14 15:59:36,158 iteration 2443 : loss : 0.031705, loss_ce: 0.014907
2022-01-14 15:59:37,728 iteration 2444 : loss : 0.025101, loss_ce: 0.009079
2022-01-14 15:59:39,131 iteration 2445 : loss : 0.072433, loss_ce: 0.013755
2022-01-14 15:59:40,741 iteration 2446 : loss : 0.026742, loss_ce: 0.009107
2022-01-14 15:59:42,337 iteration 2447 : loss : 0.038827, loss_ce: 0.020917
2022-01-14 15:59:43,855 iteration 2448 : loss : 0.025981, loss_ce: 0.008923
 36%|█████████▋                 | 144/400 [1:07:03<1:53:54, 26.70s/it]2022-01-14 15:59:45,386 iteration 2449 : loss : 0.034971, loss_ce: 0.015004
2022-01-14 15:59:46,964 iteration 2450 : loss : 0.042168, loss_ce: 0.012424
2022-01-14 15:59:48,553 iteration 2451 : loss : 0.035361, loss_ce: 0.012639
2022-01-14 15:59:49,983 iteration 2452 : loss : 0.031575, loss_ce: 0.014330
2022-01-14 15:59:51,484 iteration 2453 : loss : 0.054927, loss_ce: 0.017662
2022-01-14 15:59:53,064 iteration 2454 : loss : 0.036668, loss_ce: 0.017970
2022-01-14 15:59:54,585 iteration 2455 : loss : 0.045872, loss_ce: 0.021233
2022-01-14 15:59:56,234 iteration 2456 : loss : 0.056698, loss_ce: 0.022783
2022-01-14 15:59:57,757 iteration 2457 : loss : 0.038097, loss_ce: 0.014680
2022-01-14 15:59:59,343 iteration 2458 : loss : 0.034568, loss_ce: 0.010133
2022-01-14 16:00:00,817 iteration 2459 : loss : 0.048060, loss_ce: 0.013891
2022-01-14 16:00:02,345 iteration 2460 : loss : 0.024396, loss_ce: 0.007209
2022-01-14 16:00:03,847 iteration 2461 : loss : 0.052426, loss_ce: 0.015721
2022-01-14 16:00:05,351 iteration 2462 : loss : 0.027060, loss_ce: 0.011428
2022-01-14 16:00:06,875 iteration 2463 : loss : 0.032288, loss_ce: 0.011048
2022-01-14 16:00:08,466 iteration 2464 : loss : 0.031437, loss_ce: 0.013712
2022-01-14 16:00:08,466 Training Data Eval:
2022-01-14 16:00:15,964   Average segmentation loss on training set: 0.0242
2022-01-14 16:00:15,964 Validation Data Eval:
2022-01-14 16:00:18,533   Average segmentation loss on validation set: 0.1456
2022-01-14 16:00:20,007 iteration 2465 : loss : 0.029592, loss_ce: 0.010320
 36%|█████████▊                 | 145/400 [1:07:40<2:05:30, 29.53s/it]2022-01-14 16:00:21,530 iteration 2466 : loss : 0.022569, loss_ce: 0.008813
2022-01-14 16:00:23,134 iteration 2467 : loss : 0.030732, loss_ce: 0.017106
2022-01-14 16:00:24,608 iteration 2468 : loss : 0.031018, loss_ce: 0.012946
2022-01-14 16:00:26,054 iteration 2469 : loss : 0.018387, loss_ce: 0.009220
2022-01-14 16:00:27,600 iteration 2470 : loss : 0.038176, loss_ce: 0.014568
2022-01-14 16:00:29,176 iteration 2471 : loss : 0.030275, loss_ce: 0.012508
2022-01-14 16:00:30,810 iteration 2472 : loss : 0.034323, loss_ce: 0.013379
2022-01-14 16:00:32,254 iteration 2473 : loss : 0.034904, loss_ce: 0.014480
2022-01-14 16:00:33,809 iteration 2474 : loss : 0.032029, loss_ce: 0.012105
2022-01-14 16:00:35,244 iteration 2475 : loss : 0.021776, loss_ce: 0.009135
2022-01-14 16:00:36,812 iteration 2476 : loss : 0.046928, loss_ce: 0.012508
2022-01-14 16:00:38,330 iteration 2477 : loss : 0.029589, loss_ce: 0.012032
2022-01-14 16:00:39,841 iteration 2478 : loss : 0.038171, loss_ce: 0.010175
2022-01-14 16:00:41,463 iteration 2479 : loss : 0.025173, loss_ce: 0.007436
2022-01-14 16:00:43,075 iteration 2480 : loss : 0.047160, loss_ce: 0.018385
2022-01-14 16:00:44,556 iteration 2481 : loss : 0.028243, loss_ce: 0.010502
2022-01-14 16:00:46,068 iteration 2482 : loss : 0.032038, loss_ce: 0.012355
 36%|█████████▊                 | 146/400 [1:08:06<2:00:36, 28.49s/it]2022-01-14 16:00:47,602 iteration 2483 : loss : 0.024737, loss_ce: 0.009964
2022-01-14 16:00:49,197 iteration 2484 : loss : 0.036070, loss_ce: 0.010643
2022-01-14 16:00:50,837 iteration 2485 : loss : 0.049925, loss_ce: 0.015369
2022-01-14 16:00:52,315 iteration 2486 : loss : 0.033322, loss_ce: 0.014654
2022-01-14 16:00:53,822 iteration 2487 : loss : 0.032702, loss_ce: 0.011237
2022-01-14 16:00:55,370 iteration 2488 : loss : 0.036359, loss_ce: 0.010914
2022-01-14 16:00:56,963 iteration 2489 : loss : 0.031153, loss_ce: 0.012503
2022-01-14 16:00:58,451 iteration 2490 : loss : 0.025613, loss_ce: 0.010749
2022-01-14 16:00:59,959 iteration 2491 : loss : 0.028365, loss_ce: 0.011365
2022-01-14 16:01:01,410 iteration 2492 : loss : 0.030509, loss_ce: 0.010860
2022-01-14 16:01:02,910 iteration 2493 : loss : 0.026950, loss_ce: 0.008321
2022-01-14 16:01:04,362 iteration 2494 : loss : 0.036054, loss_ce: 0.012795
2022-01-14 16:01:05,859 iteration 2495 : loss : 0.041928, loss_ce: 0.011992
2022-01-14 16:01:07,414 iteration 2496 : loss : 0.043229, loss_ce: 0.013127
2022-01-14 16:01:08,924 iteration 2497 : loss : 0.041556, loss_ce: 0.016889
2022-01-14 16:01:10,339 iteration 2498 : loss : 0.033681, loss_ce: 0.014023
2022-01-14 16:01:11,929 iteration 2499 : loss : 0.030730, loss_ce: 0.014747
 37%|█████████▉                 | 147/400 [1:08:31<1:56:47, 27.70s/it]2022-01-14 16:01:13,507 iteration 2500 : loss : 0.046916, loss_ce: 0.019452
2022-01-14 16:01:14,951 iteration 2501 : loss : 0.029590, loss_ce: 0.010005
2022-01-14 16:01:16,442 iteration 2502 : loss : 0.030873, loss_ce: 0.010889
2022-01-14 16:01:17,979 iteration 2503 : loss : 0.028522, loss_ce: 0.012794
2022-01-14 16:01:19,524 iteration 2504 : loss : 0.029602, loss_ce: 0.010388
2022-01-14 16:01:20,957 iteration 2505 : loss : 0.023544, loss_ce: 0.010282
2022-01-14 16:01:22,405 iteration 2506 : loss : 0.043387, loss_ce: 0.010645
2022-01-14 16:01:23,962 iteration 2507 : loss : 0.021455, loss_ce: 0.008198
2022-01-14 16:01:25,456 iteration 2508 : loss : 0.026019, loss_ce: 0.011304
2022-01-14 16:01:27,015 iteration 2509 : loss : 0.033964, loss_ce: 0.013650
2022-01-14 16:01:28,473 iteration 2510 : loss : 0.037701, loss_ce: 0.013310
2022-01-14 16:01:29,921 iteration 2511 : loss : 0.026258, loss_ce: 0.012977
2022-01-14 16:01:31,487 iteration 2512 : loss : 0.031447, loss_ce: 0.010850
2022-01-14 16:01:32,966 iteration 2513 : loss : 0.023153, loss_ce: 0.008444
2022-01-14 16:01:34,505 iteration 2514 : loss : 0.030319, loss_ce: 0.010119
2022-01-14 16:01:35,981 iteration 2515 : loss : 0.029075, loss_ce: 0.014942
2022-01-14 16:01:37,651 iteration 2516 : loss : 0.031406, loss_ce: 0.012105
 37%|█████████▉                 | 148/400 [1:08:57<1:53:51, 27.11s/it]2022-01-14 16:01:39,233 iteration 2517 : loss : 0.031857, loss_ce: 0.011261
2022-01-14 16:01:40,748 iteration 2518 : loss : 0.043243, loss_ce: 0.012104
2022-01-14 16:01:42,196 iteration 2519 : loss : 0.018808, loss_ce: 0.005786
2022-01-14 16:01:43,735 iteration 2520 : loss : 0.029218, loss_ce: 0.013981
2022-01-14 16:01:45,242 iteration 2521 : loss : 0.022280, loss_ce: 0.009460
2022-01-14 16:01:46,801 iteration 2522 : loss : 0.061638, loss_ce: 0.023095
2022-01-14 16:01:48,317 iteration 2523 : loss : 0.034917, loss_ce: 0.009635
2022-01-14 16:01:49,894 iteration 2524 : loss : 0.023884, loss_ce: 0.009247
2022-01-14 16:01:51,366 iteration 2525 : loss : 0.026211, loss_ce: 0.007627
2022-01-14 16:01:52,801 iteration 2526 : loss : 0.032544, loss_ce: 0.013012
2022-01-14 16:01:54,360 iteration 2527 : loss : 0.039002, loss_ce: 0.016970
2022-01-14 16:01:55,868 iteration 2528 : loss : 0.027827, loss_ce: 0.012701
2022-01-14 16:01:57,403 iteration 2529 : loss : 0.042029, loss_ce: 0.016944
2022-01-14 16:01:58,865 iteration 2530 : loss : 0.028632, loss_ce: 0.010437
2022-01-14 16:02:00,396 iteration 2531 : loss : 0.031928, loss_ce: 0.010134
2022-01-14 16:02:01,980 iteration 2532 : loss : 0.031522, loss_ce: 0.014809
2022-01-14 16:02:03,403 iteration 2533 : loss : 0.031953, loss_ce: 0.007831
 37%|██████████                 | 149/400 [1:09:23<1:51:41, 26.70s/it]2022-01-14 16:02:04,995 iteration 2534 : loss : 0.026730, loss_ce: 0.009986
2022-01-14 16:02:06,392 iteration 2535 : loss : 0.039894, loss_ce: 0.015491
2022-01-14 16:02:07,871 iteration 2536 : loss : 0.022436, loss_ce: 0.009204
2022-01-14 16:02:09,489 iteration 2537 : loss : 0.029936, loss_ce: 0.014782
2022-01-14 16:02:10,835 iteration 2538 : loss : 0.025970, loss_ce: 0.008462
2022-01-14 16:02:12,280 iteration 2539 : loss : 0.027582, loss_ce: 0.010691
2022-01-14 16:02:13,775 iteration 2540 : loss : 0.040392, loss_ce: 0.018599
2022-01-14 16:02:15,405 iteration 2541 : loss : 0.049668, loss_ce: 0.018294
2022-01-14 16:02:16,906 iteration 2542 : loss : 0.028721, loss_ce: 0.008470
2022-01-14 16:02:18,500 iteration 2543 : loss : 0.028178, loss_ce: 0.008477
2022-01-14 16:02:20,079 iteration 2544 : loss : 0.059955, loss_ce: 0.022485
2022-01-14 16:02:21,545 iteration 2545 : loss : 0.028901, loss_ce: 0.012979
2022-01-14 16:02:23,255 iteration 2546 : loss : 0.051832, loss_ce: 0.023545
2022-01-14 16:02:24,800 iteration 2547 : loss : 0.032466, loss_ce: 0.010830
2022-01-14 16:02:26,407 iteration 2548 : loss : 0.033072, loss_ce: 0.013487
2022-01-14 16:02:27,904 iteration 2549 : loss : 0.032140, loss_ce: 0.010814
2022-01-14 16:02:27,905 Training Data Eval:
2022-01-14 16:02:35,388   Average segmentation loss on training set: 0.0224
2022-01-14 16:02:35,388 Validation Data Eval:
2022-01-14 16:02:37,953   Average segmentation loss on validation set: 0.0620
2022-01-14 16:02:39,470 iteration 2550 : loss : 0.044155, loss_ce: 0.011870
 38%|██████████▏                | 150/400 [1:09:59<2:02:57, 29.51s/it]2022-01-14 16:02:41,056 iteration 2551 : loss : 0.030416, loss_ce: 0.011022
2022-01-14 16:02:42,606 iteration 2552 : loss : 0.030218, loss_ce: 0.012332
2022-01-14 16:02:44,153 iteration 2553 : loss : 0.032483, loss_ce: 0.011047
2022-01-14 16:02:45,661 iteration 2554 : loss : 0.036446, loss_ce: 0.012169
2022-01-14 16:02:47,146 iteration 2555 : loss : 0.028459, loss_ce: 0.011014
2022-01-14 16:02:48,639 iteration 2556 : loss : 0.028368, loss_ce: 0.012098
2022-01-14 16:02:50,124 iteration 2557 : loss : 0.038602, loss_ce: 0.017432
2022-01-14 16:02:51,593 iteration 2558 : loss : 0.029235, loss_ce: 0.009925
2022-01-14 16:02:53,044 iteration 2559 : loss : 0.028677, loss_ce: 0.014275
2022-01-14 16:02:54,656 iteration 2560 : loss : 0.030123, loss_ce: 0.011650
2022-01-14 16:02:56,191 iteration 2561 : loss : 0.039620, loss_ce: 0.013590
2022-01-14 16:02:57,739 iteration 2562 : loss : 0.022932, loss_ce: 0.009176
2022-01-14 16:02:59,186 iteration 2563 : loss : 0.027923, loss_ce: 0.012527
2022-01-14 16:03:00,625 iteration 2564 : loss : 0.020351, loss_ce: 0.008914
2022-01-14 16:03:02,132 iteration 2565 : loss : 0.019670, loss_ce: 0.007457
2022-01-14 16:03:03,553 iteration 2566 : loss : 0.022500, loss_ce: 0.008214
2022-01-14 16:03:05,021 iteration 2567 : loss : 0.045108, loss_ce: 0.011812
 38%|██████████▏                | 151/400 [1:10:25<1:57:32, 28.32s/it]2022-01-14 16:03:06,551 iteration 2568 : loss : 0.025405, loss_ce: 0.009928
2022-01-14 16:03:08,068 iteration 2569 : loss : 0.029554, loss_ce: 0.010085
2022-01-14 16:03:09,687 iteration 2570 : loss : 0.048572, loss_ce: 0.017174
2022-01-14 16:03:11,174 iteration 2571 : loss : 0.028965, loss_ce: 0.008414
2022-01-14 16:03:12,622 iteration 2572 : loss : 0.030046, loss_ce: 0.009712
2022-01-14 16:03:14,102 iteration 2573 : loss : 0.025982, loss_ce: 0.009916
2022-01-14 16:03:15,565 iteration 2574 : loss : 0.024093, loss_ce: 0.010164
2022-01-14 16:03:16,985 iteration 2575 : loss : 0.025208, loss_ce: 0.008827
2022-01-14 16:03:18,409 iteration 2576 : loss : 0.023912, loss_ce: 0.006985
2022-01-14 16:03:19,941 iteration 2577 : loss : 0.037748, loss_ce: 0.022203
2022-01-14 16:03:21,423 iteration 2578 : loss : 0.030287, loss_ce: 0.010724
2022-01-14 16:03:22,942 iteration 2579 : loss : 0.020799, loss_ce: 0.007883
2022-01-14 16:03:24,390 iteration 2580 : loss : 0.027448, loss_ce: 0.007992
2022-01-14 16:03:25,937 iteration 2581 : loss : 0.031768, loss_ce: 0.013124
2022-01-14 16:03:27,505 iteration 2582 : loss : 0.022899, loss_ce: 0.010768
2022-01-14 16:03:28,986 iteration 2583 : loss : 0.023209, loss_ce: 0.010242
2022-01-14 16:03:30,473 iteration 2584 : loss : 0.035264, loss_ce: 0.010912
 38%|██████████▎                | 152/400 [1:10:50<1:53:30, 27.46s/it]2022-01-14 16:03:32,051 iteration 2585 : loss : 0.033421, loss_ce: 0.014588
2022-01-14 16:03:33,723 iteration 2586 : loss : 0.034649, loss_ce: 0.011809
2022-01-14 16:03:35,317 iteration 2587 : loss : 0.049449, loss_ce: 0.013768
2022-01-14 16:03:36,810 iteration 2588 : loss : 0.036488, loss_ce: 0.013028
2022-01-14 16:03:38,245 iteration 2589 : loss : 0.036694, loss_ce: 0.010682
2022-01-14 16:03:39,791 iteration 2590 : loss : 0.032487, loss_ce: 0.011071
2022-01-14 16:03:41,294 iteration 2591 : loss : 0.022252, loss_ce: 0.009460
2022-01-14 16:03:42,726 iteration 2592 : loss : 0.029697, loss_ce: 0.015886
2022-01-14 16:03:44,114 iteration 2593 : loss : 0.033479, loss_ce: 0.018313
2022-01-14 16:03:45,614 iteration 2594 : loss : 0.031609, loss_ce: 0.013988
2022-01-14 16:03:47,067 iteration 2595 : loss : 0.020903, loss_ce: 0.007049
2022-01-14 16:03:48,559 iteration 2596 : loss : 0.028200, loss_ce: 0.008738
2022-01-14 16:03:50,080 iteration 2597 : loss : 0.026674, loss_ce: 0.010328
2022-01-14 16:03:51,618 iteration 2598 : loss : 0.028810, loss_ce: 0.012377
2022-01-14 16:03:53,119 iteration 2599 : loss : 0.026201, loss_ce: 0.010214
2022-01-14 16:03:54,556 iteration 2600 : loss : 0.028749, loss_ce: 0.012011
2022-01-14 16:03:56,011 iteration 2601 : loss : 0.026571, loss_ce: 0.010170
 38%|██████████▎                | 153/400 [1:11:16<1:50:40, 26.89s/it]2022-01-14 16:03:57,523 iteration 2602 : loss : 0.029156, loss_ce: 0.010292
2022-01-14 16:03:59,020 iteration 2603 : loss : 0.050271, loss_ce: 0.012580
2022-01-14 16:04:00,535 iteration 2604 : loss : 0.025600, loss_ce: 0.010040
2022-01-14 16:04:02,031 iteration 2605 : loss : 0.035005, loss_ce: 0.010504
2022-01-14 16:04:03,517 iteration 2606 : loss : 0.032090, loss_ce: 0.011335
2022-01-14 16:04:05,078 iteration 2607 : loss : 0.026332, loss_ce: 0.012759
2022-01-14 16:04:06,527 iteration 2608 : loss : 0.027123, loss_ce: 0.009928
2022-01-14 16:04:08,060 iteration 2609 : loss : 0.021633, loss_ce: 0.008362
2022-01-14 16:04:09,571 iteration 2610 : loss : 0.027072, loss_ce: 0.009326
2022-01-14 16:04:11,134 iteration 2611 : loss : 0.029190, loss_ce: 0.012404
2022-01-14 16:04:12,654 iteration 2612 : loss : 0.034642, loss_ce: 0.011568
2022-01-14 16:04:14,219 iteration 2613 : loss : 0.032340, loss_ce: 0.010979
2022-01-14 16:04:15,827 iteration 2614 : loss : 0.025041, loss_ce: 0.009907
2022-01-14 16:04:17,351 iteration 2615 : loss : 0.034858, loss_ce: 0.017690
2022-01-14 16:04:18,941 iteration 2616 : loss : 0.027788, loss_ce: 0.009522
2022-01-14 16:04:20,443 iteration 2617 : loss : 0.028165, loss_ce: 0.010384
2022-01-14 16:04:21,999 iteration 2618 : loss : 0.024593, loss_ce: 0.007094
 38%|██████████▍                | 154/400 [1:11:42<1:49:07, 26.62s/it]2022-01-14 16:04:23,745 iteration 2619 : loss : 0.033171, loss_ce: 0.012514
2022-01-14 16:04:25,301 iteration 2620 : loss : 0.023921, loss_ce: 0.008269
2022-01-14 16:04:26,716 iteration 2621 : loss : 0.025284, loss_ce: 0.009828
2022-01-14 16:04:28,248 iteration 2622 : loss : 0.039413, loss_ce: 0.016632
2022-01-14 16:04:29,696 iteration 2623 : loss : 0.030123, loss_ce: 0.011427
2022-01-14 16:04:31,263 iteration 2624 : loss : 0.045500, loss_ce: 0.017359
2022-01-14 16:04:32,810 iteration 2625 : loss : 0.039711, loss_ce: 0.015584
2022-01-14 16:04:34,320 iteration 2626 : loss : 0.022991, loss_ce: 0.008986
2022-01-14 16:04:35,751 iteration 2627 : loss : 0.023450, loss_ce: 0.012774
2022-01-14 16:04:37,216 iteration 2628 : loss : 0.023911, loss_ce: 0.009033
2022-01-14 16:04:38,643 iteration 2629 : loss : 0.031618, loss_ce: 0.008711
2022-01-14 16:04:40,233 iteration 2630 : loss : 0.103515, loss_ce: 0.020399
2022-01-14 16:04:41,660 iteration 2631 : loss : 0.035102, loss_ce: 0.017035
2022-01-14 16:04:43,119 iteration 2632 : loss : 0.031453, loss_ce: 0.009492
2022-01-14 16:04:44,624 iteration 2633 : loss : 0.021010, loss_ce: 0.007123
2022-01-14 16:04:46,103 iteration 2634 : loss : 0.023915, loss_ce: 0.007526
2022-01-14 16:04:46,103 Training Data Eval:
2022-01-14 16:04:53,609   Average segmentation loss on training set: 0.1278
2022-01-14 16:04:53,610 Validation Data Eval:
2022-01-14 16:04:56,176   Average segmentation loss on validation set: 0.3906
2022-01-14 16:04:57,656 iteration 2635 : loss : 0.040332, loss_ce: 0.017061
 39%|██████████▍                | 155/400 [1:12:17<1:59:45, 29.33s/it]2022-01-14 16:04:59,198 iteration 2636 : loss : 0.023013, loss_ce: 0.007013
2022-01-14 16:05:00,722 iteration 2637 : loss : 0.022571, loss_ce: 0.010256
2022-01-14 16:05:02,335 iteration 2638 : loss : 0.046013, loss_ce: 0.018750
2022-01-14 16:05:03,811 iteration 2639 : loss : 0.022841, loss_ce: 0.009181
2022-01-14 16:05:05,360 iteration 2640 : loss : 0.031575, loss_ce: 0.012172
2022-01-14 16:05:06,875 iteration 2641 : loss : 0.029070, loss_ce: 0.010753
2022-01-14 16:05:08,423 iteration 2642 : loss : 0.036856, loss_ce: 0.011478
2022-01-14 16:05:09,906 iteration 2643 : loss : 0.037350, loss_ce: 0.015185
2022-01-14 16:05:11,413 iteration 2644 : loss : 0.039205, loss_ce: 0.018089
2022-01-14 16:05:12,842 iteration 2645 : loss : 0.024867, loss_ce: 0.010921
2022-01-14 16:05:14,303 iteration 2646 : loss : 0.033228, loss_ce: 0.010194
2022-01-14 16:05:15,899 iteration 2647 : loss : 0.034374, loss_ce: 0.014070
2022-01-14 16:05:17,358 iteration 2648 : loss : 0.032974, loss_ce: 0.011664
2022-01-14 16:05:18,885 iteration 2649 : loss : 0.035981, loss_ce: 0.011876
2022-01-14 16:05:20,513 iteration 2650 : loss : 0.035684, loss_ce: 0.013055
2022-01-14 16:05:22,010 iteration 2651 : loss : 0.030832, loss_ce: 0.013055
2022-01-14 16:05:23,656 iteration 2652 : loss : 0.025541, loss_ce: 0.010292
 39%|██████████▌                | 156/400 [1:12:43<1:55:11, 28.33s/it]2022-01-14 16:05:25,247 iteration 2653 : loss : 0.035656, loss_ce: 0.013429
2022-01-14 16:05:26,689 iteration 2654 : loss : 0.019305, loss_ce: 0.007878
2022-01-14 16:05:28,170 iteration 2655 : loss : 0.025825, loss_ce: 0.010984
2022-01-14 16:05:29,656 iteration 2656 : loss : 0.027903, loss_ce: 0.014040
2022-01-14 16:05:31,192 iteration 2657 : loss : 0.029773, loss_ce: 0.013174
2022-01-14 16:05:32,767 iteration 2658 : loss : 0.036051, loss_ce: 0.011826
2022-01-14 16:05:34,334 iteration 2659 : loss : 0.028581, loss_ce: 0.010660
2022-01-14 16:05:35,959 iteration 2660 : loss : 0.033692, loss_ce: 0.015665
2022-01-14 16:05:37,362 iteration 2661 : loss : 0.027707, loss_ce: 0.008945
2022-01-14 16:05:38,950 iteration 2662 : loss : 0.024062, loss_ce: 0.008441
2022-01-14 16:05:40,474 iteration 2663 : loss : 0.029226, loss_ce: 0.011728
2022-01-14 16:05:41,890 iteration 2664 : loss : 0.031544, loss_ce: 0.010679
2022-01-14 16:05:43,377 iteration 2665 : loss : 0.016961, loss_ce: 0.007123
2022-01-14 16:05:45,006 iteration 2666 : loss : 0.031913, loss_ce: 0.010789
2022-01-14 16:05:46,445 iteration 2667 : loss : 0.031460, loss_ce: 0.011596
2022-01-14 16:05:48,001 iteration 2668 : loss : 0.028825, loss_ce: 0.010467
2022-01-14 16:05:49,501 iteration 2669 : loss : 0.024361, loss_ce: 0.006878
 39%|██████████▌                | 157/400 [1:13:09<1:51:43, 27.59s/it]2022-01-14 16:05:50,989 iteration 2670 : loss : 0.021712, loss_ce: 0.008904
2022-01-14 16:05:52,406 iteration 2671 : loss : 0.024023, loss_ce: 0.009807
2022-01-14 16:05:53,894 iteration 2672 : loss : 0.031942, loss_ce: 0.010068
2022-01-14 16:05:55,356 iteration 2673 : loss : 0.034699, loss_ce: 0.009419
2022-01-14 16:05:56,848 iteration 2674 : loss : 0.027792, loss_ce: 0.008900
2022-01-14 16:05:58,431 iteration 2675 : loss : 0.020638, loss_ce: 0.007107
2022-01-14 16:05:59,923 iteration 2676 : loss : 0.025603, loss_ce: 0.007394
2022-01-14 16:06:01,408 iteration 2677 : loss : 0.022082, loss_ce: 0.008543
2022-01-14 16:06:02,851 iteration 2678 : loss : 0.023499, loss_ce: 0.009891
2022-01-14 16:06:04,347 iteration 2679 : loss : 0.026598, loss_ce: 0.010195
2022-01-14 16:06:05,917 iteration 2680 : loss : 0.026265, loss_ce: 0.011981
2022-01-14 16:06:07,438 iteration 2681 : loss : 0.030282, loss_ce: 0.010086
2022-01-14 16:06:08,990 iteration 2682 : loss : 0.023492, loss_ce: 0.009035
2022-01-14 16:06:10,478 iteration 2683 : loss : 0.035195, loss_ce: 0.017039
2022-01-14 16:06:12,017 iteration 2684 : loss : 0.022341, loss_ce: 0.009749
2022-01-14 16:06:13,543 iteration 2685 : loss : 0.032811, loss_ce: 0.014108
2022-01-14 16:06:15,094 iteration 2686 : loss : 0.050653, loss_ce: 0.012573
 40%|██████████▋                | 158/400 [1:13:35<1:48:51, 26.99s/it]2022-01-14 16:06:16,577 iteration 2687 : loss : 0.028305, loss_ce: 0.011610
2022-01-14 16:06:18,054 iteration 2688 : loss : 0.023325, loss_ce: 0.008441
2022-01-14 16:06:19,503 iteration 2689 : loss : 0.026999, loss_ce: 0.009002
2022-01-14 16:06:21,082 iteration 2690 : loss : 0.046109, loss_ce: 0.012232
2022-01-14 16:06:22,513 iteration 2691 : loss : 0.018653, loss_ce: 0.007606
2022-01-14 16:06:23,977 iteration 2692 : loss : 0.026946, loss_ce: 0.009371
2022-01-14 16:06:25,385 iteration 2693 : loss : 0.020928, loss_ce: 0.008286
2022-01-14 16:06:26,915 iteration 2694 : loss : 0.036006, loss_ce: 0.018848
2022-01-14 16:06:28,420 iteration 2695 : loss : 0.041735, loss_ce: 0.022274
2022-01-14 16:06:29,894 iteration 2696 : loss : 0.035186, loss_ce: 0.019683
2022-01-14 16:06:31,337 iteration 2697 : loss : 0.031980, loss_ce: 0.015289
2022-01-14 16:06:32,782 iteration 2698 : loss : 0.029755, loss_ce: 0.008278
2022-01-14 16:06:34,252 iteration 2699 : loss : 0.024520, loss_ce: 0.010655
2022-01-14 16:06:35,733 iteration 2700 : loss : 0.024839, loss_ce: 0.008107
2022-01-14 16:06:37,409 iteration 2701 : loss : 0.025876, loss_ce: 0.007822
2022-01-14 16:06:38,967 iteration 2702 : loss : 0.028035, loss_ce: 0.014267
2022-01-14 16:06:40,516 iteration 2703 : loss : 0.034101, loss_ce: 0.012515
 40%|██████████▋                | 159/400 [1:14:00<1:46:30, 26.52s/it]2022-01-14 16:06:42,129 iteration 2704 : loss : 0.047322, loss_ce: 0.015575
2022-01-14 16:06:43,584 iteration 2705 : loss : 0.021478, loss_ce: 0.009345
2022-01-14 16:06:45,165 iteration 2706 : loss : 0.038589, loss_ce: 0.013141
2022-01-14 16:06:46,658 iteration 2707 : loss : 0.023264, loss_ce: 0.011968
2022-01-14 16:06:48,225 iteration 2708 : loss : 0.024140, loss_ce: 0.009805
2022-01-14 16:06:49,721 iteration 2709 : loss : 0.024818, loss_ce: 0.010155
2022-01-14 16:06:51,148 iteration 2710 : loss : 0.027264, loss_ce: 0.011566
2022-01-14 16:06:52,730 iteration 2711 : loss : 0.022448, loss_ce: 0.008028
2022-01-14 16:06:54,303 iteration 2712 : loss : 0.029932, loss_ce: 0.008928
2022-01-14 16:06:55,758 iteration 2713 : loss : 0.029320, loss_ce: 0.014049
2022-01-14 16:06:57,318 iteration 2714 : loss : 0.028177, loss_ce: 0.009662
2022-01-14 16:06:58,880 iteration 2715 : loss : 0.033862, loss_ce: 0.011665
2022-01-14 16:07:00,408 iteration 2716 : loss : 0.027467, loss_ce: 0.008260
2022-01-14 16:07:01,870 iteration 2717 : loss : 0.036941, loss_ce: 0.016821
2022-01-14 16:07:03,423 iteration 2718 : loss : 0.047325, loss_ce: 0.014135
2022-01-14 16:07:04,904 iteration 2719 : loss : 0.025808, loss_ce: 0.008626
2022-01-14 16:07:04,905 Training Data Eval:
2022-01-14 16:07:12,408   Average segmentation loss on training set: 0.0182
2022-01-14 16:07:12,409 Validation Data Eval:
2022-01-14 16:07:14,976   Average segmentation loss on validation set: 0.0724
2022-01-14 16:07:16,450 iteration 2720 : loss : 0.021414, loss_ce: 0.007024
 40%|██████████▊                | 160/400 [1:14:36<1:57:21, 29.34s/it]2022-01-14 16:07:18,056 iteration 2721 : loss : 0.024537, loss_ce: 0.009776
2022-01-14 16:07:19,596 iteration 2722 : loss : 0.027975, loss_ce: 0.010750
2022-01-14 16:07:21,139 iteration 2723 : loss : 0.021444, loss_ce: 0.008173
2022-01-14 16:07:22,681 iteration 2724 : loss : 0.030177, loss_ce: 0.012199
2022-01-14 16:07:24,173 iteration 2725 : loss : 0.026585, loss_ce: 0.008478
2022-01-14 16:07:25,845 iteration 2726 : loss : 0.037773, loss_ce: 0.013464
2022-01-14 16:07:27,431 iteration 2727 : loss : 0.032655, loss_ce: 0.012640
2022-01-14 16:07:28,943 iteration 2728 : loss : 0.025963, loss_ce: 0.010324
2022-01-14 16:07:30,465 iteration 2729 : loss : 0.025570, loss_ce: 0.010955
2022-01-14 16:07:31,880 iteration 2730 : loss : 0.022672, loss_ce: 0.008456
2022-01-14 16:07:33,367 iteration 2731 : loss : 0.026495, loss_ce: 0.008988
2022-01-14 16:07:34,937 iteration 2732 : loss : 0.032978, loss_ce: 0.013803
2022-01-14 16:07:36,449 iteration 2733 : loss : 0.024715, loss_ce: 0.008986
2022-01-14 16:07:37,962 iteration 2734 : loss : 0.025010, loss_ce: 0.007866
2022-01-14 16:07:39,585 iteration 2735 : loss : 0.046965, loss_ce: 0.014094
2022-01-14 16:07:41,049 iteration 2736 : loss : 0.022658, loss_ce: 0.009917
2022-01-14 16:07:42,588 iteration 2737 : loss : 0.029865, loss_ce: 0.011299
 40%|██████████▊                | 161/400 [1:15:02<1:53:02, 28.38s/it]2022-01-14 16:07:44,078 iteration 2738 : loss : 0.018742, loss_ce: 0.006845
2022-01-14 16:07:45,655 iteration 2739 : loss : 0.025889, loss_ce: 0.011301
2022-01-14 16:07:47,266 iteration 2740 : loss : 0.033876, loss_ce: 0.013052
2022-01-14 16:07:48,741 iteration 2741 : loss : 0.028802, loss_ce: 0.010986
2022-01-14 16:07:50,171 iteration 2742 : loss : 0.026933, loss_ce: 0.008056
2022-01-14 16:07:51,689 iteration 2743 : loss : 0.026110, loss_ce: 0.008240
2022-01-14 16:07:53,332 iteration 2744 : loss : 0.037646, loss_ce: 0.013415
2022-01-14 16:07:54,824 iteration 2745 : loss : 0.027786, loss_ce: 0.011201
2022-01-14 16:07:56,315 iteration 2746 : loss : 0.021621, loss_ce: 0.007679
2022-01-14 16:07:57,960 iteration 2747 : loss : 0.030933, loss_ce: 0.012375
2022-01-14 16:07:59,441 iteration 2748 : loss : 0.021017, loss_ce: 0.007916
2022-01-14 16:08:00,925 iteration 2749 : loss : 0.022584, loss_ce: 0.010303
2022-01-14 16:08:02,398 iteration 2750 : loss : 0.029111, loss_ce: 0.008461
2022-01-14 16:08:03,870 iteration 2751 : loss : 0.027829, loss_ce: 0.007118
2022-01-14 16:08:05,352 iteration 2752 : loss : 0.023114, loss_ce: 0.009826
2022-01-14 16:08:06,846 iteration 2753 : loss : 0.023674, loss_ce: 0.009973
2022-01-14 16:08:08,370 iteration 2754 : loss : 0.034283, loss_ce: 0.011340
 40%|██████████▉                | 162/400 [1:15:28<1:49:29, 27.60s/it]2022-01-14 16:08:09,925 iteration 2755 : loss : 0.034085, loss_ce: 0.011852
2022-01-14 16:08:11,430 iteration 2756 : loss : 0.031976, loss_ce: 0.012908
2022-01-14 16:08:12,882 iteration 2757 : loss : 0.034925, loss_ce: 0.011796
2022-01-14 16:08:14,393 iteration 2758 : loss : 0.023440, loss_ce: 0.008949
2022-01-14 16:08:15,946 iteration 2759 : loss : 0.021153, loss_ce: 0.007619
2022-01-14 16:08:17,522 iteration 2760 : loss : 0.049559, loss_ce: 0.011439
2022-01-14 16:08:19,036 iteration 2761 : loss : 0.029846, loss_ce: 0.010300
2022-01-14 16:08:20,519 iteration 2762 : loss : 0.032708, loss_ce: 0.014578
2022-01-14 16:08:22,049 iteration 2763 : loss : 0.022965, loss_ce: 0.008498
2022-01-14 16:08:23,485 iteration 2764 : loss : 0.023559, loss_ce: 0.010348
2022-01-14 16:08:24,983 iteration 2765 : loss : 0.032806, loss_ce: 0.013737
2022-01-14 16:08:26,553 iteration 2766 : loss : 0.025814, loss_ce: 0.009517
2022-01-14 16:08:27,967 iteration 2767 : loss : 0.026872, loss_ce: 0.008466
2022-01-14 16:08:29,616 iteration 2768 : loss : 0.024736, loss_ce: 0.009964
2022-01-14 16:08:31,092 iteration 2769 : loss : 0.023795, loss_ce: 0.007883
2022-01-14 16:08:32,557 iteration 2770 : loss : 0.025048, loss_ce: 0.012138
2022-01-14 16:08:34,045 iteration 2771 : loss : 0.022473, loss_ce: 0.011075
 41%|███████████                | 163/400 [1:15:54<1:46:45, 27.03s/it]2022-01-14 16:08:35,690 iteration 2772 : loss : 0.039065, loss_ce: 0.013071
2022-01-14 16:08:37,106 iteration 2773 : loss : 0.028737, loss_ce: 0.010587
2022-01-14 16:08:38,639 iteration 2774 : loss : 0.022325, loss_ce: 0.010005
2022-01-14 16:08:40,136 iteration 2775 : loss : 0.029514, loss_ce: 0.012862
2022-01-14 16:08:41,667 iteration 2776 : loss : 0.032659, loss_ce: 0.015086
2022-01-14 16:08:43,203 iteration 2777 : loss : 0.027574, loss_ce: 0.010616
2022-01-14 16:08:44,611 iteration 2778 : loss : 0.020910, loss_ce: 0.008866
2022-01-14 16:08:46,161 iteration 2779 : loss : 0.026570, loss_ce: 0.010771
2022-01-14 16:08:47,743 iteration 2780 : loss : 0.026946, loss_ce: 0.009557
2022-01-14 16:08:49,126 iteration 2781 : loss : 0.025401, loss_ce: 0.010001
2022-01-14 16:08:50,657 iteration 2782 : loss : 0.021879, loss_ce: 0.007921
2022-01-14 16:08:52,223 iteration 2783 : loss : 0.028014, loss_ce: 0.010189
2022-01-14 16:08:53,846 iteration 2784 : loss : 0.032894, loss_ce: 0.015029
2022-01-14 16:08:55,267 iteration 2785 : loss : 0.022679, loss_ce: 0.007717
2022-01-14 16:08:56,817 iteration 2786 : loss : 0.026056, loss_ce: 0.008877
2022-01-14 16:08:58,445 iteration 2787 : loss : 0.031102, loss_ce: 0.008500
2022-01-14 16:08:59,978 iteration 2788 : loss : 0.026179, loss_ce: 0.007528
 41%|███████████                | 164/400 [1:16:20<1:45:00, 26.69s/it]2022-01-14 16:09:01,546 iteration 2789 : loss : 0.020305, loss_ce: 0.009349
2022-01-14 16:09:03,019 iteration 2790 : loss : 0.026142, loss_ce: 0.006846
2022-01-14 16:09:04,551 iteration 2791 : loss : 0.020699, loss_ce: 0.006270
2022-01-14 16:09:06,132 iteration 2792 : loss : 0.042118, loss_ce: 0.008488
2022-01-14 16:09:07,652 iteration 2793 : loss : 0.031811, loss_ce: 0.014235
2022-01-14 16:09:09,210 iteration 2794 : loss : 0.019979, loss_ce: 0.007721
2022-01-14 16:09:10,821 iteration 2795 : loss : 0.026581, loss_ce: 0.010665
2022-01-14 16:09:12,413 iteration 2796 : loss : 0.031246, loss_ce: 0.009804
2022-01-14 16:09:13,951 iteration 2797 : loss : 0.032136, loss_ce: 0.012688
2022-01-14 16:09:15,537 iteration 2798 : loss : 0.027663, loss_ce: 0.008441
2022-01-14 16:09:17,098 iteration 2799 : loss : 0.024650, loss_ce: 0.008761
2022-01-14 16:09:18,610 iteration 2800 : loss : 0.019933, loss_ce: 0.009447
2022-01-14 16:09:20,121 iteration 2801 : loss : 0.022860, loss_ce: 0.010180
2022-01-14 16:09:21,586 iteration 2802 : loss : 0.017711, loss_ce: 0.006991
2022-01-14 16:09:23,241 iteration 2803 : loss : 0.052232, loss_ce: 0.018894
2022-01-14 16:09:24,736 iteration 2804 : loss : 0.034379, loss_ce: 0.012850
2022-01-14 16:09:24,736 Training Data Eval:
2022-01-14 16:09:32,209   Average segmentation loss on training set: 0.0218
2022-01-14 16:09:32,210 Validation Data Eval:
2022-01-14 16:09:34,781   Average segmentation loss on validation set: 0.0709
2022-01-14 16:09:36,270 iteration 2805 : loss : 0.034943, loss_ce: 0.010790
 41%|███████████▏               | 165/400 [1:16:56<1:55:49, 29.57s/it]2022-01-14 16:09:37,878 iteration 2806 : loss : 0.038135, loss_ce: 0.011758
2022-01-14 16:09:39,597 iteration 2807 : loss : 0.033968, loss_ce: 0.014802
2022-01-14 16:09:40,972 iteration 2808 : loss : 0.024345, loss_ce: 0.012253
2022-01-14 16:09:42,484 iteration 2809 : loss : 0.032860, loss_ce: 0.013984
2022-01-14 16:09:44,057 iteration 2810 : loss : 0.035065, loss_ce: 0.010135
2022-01-14 16:09:45,549 iteration 2811 : loss : 0.025935, loss_ce: 0.009638
2022-01-14 16:09:47,075 iteration 2812 : loss : 0.032195, loss_ce: 0.011298
2022-01-14 16:09:48,654 iteration 2813 : loss : 0.022919, loss_ce: 0.006901
2022-01-14 16:09:50,224 iteration 2814 : loss : 0.034746, loss_ce: 0.013064
2022-01-14 16:09:51,720 iteration 2815 : loss : 0.026677, loss_ce: 0.012908
2022-01-14 16:09:53,178 iteration 2816 : loss : 0.024858, loss_ce: 0.010983
2022-01-14 16:09:54,637 iteration 2817 : loss : 0.027871, loss_ce: 0.008909
2022-01-14 16:09:56,227 iteration 2818 : loss : 0.033787, loss_ce: 0.009248
2022-01-14 16:09:57,836 iteration 2819 : loss : 0.033395, loss_ce: 0.014949
2022-01-14 16:09:59,484 iteration 2820 : loss : 0.031263, loss_ce: 0.013119
2022-01-14 16:10:00,965 iteration 2821 : loss : 0.026298, loss_ce: 0.010994
2022-01-14 16:10:02,444 iteration 2822 : loss : 0.024689, loss_ce: 0.007604
 42%|███████████▏               | 166/400 [1:17:22<1:51:21, 28.55s/it]2022-01-14 16:10:04,091 iteration 2823 : loss : 0.031682, loss_ce: 0.011232
2022-01-14 16:10:05,537 iteration 2824 : loss : 0.017521, loss_ce: 0.006273
2022-01-14 16:10:07,094 iteration 2825 : loss : 0.035473, loss_ce: 0.017118
2022-01-14 16:10:08,562 iteration 2826 : loss : 0.019848, loss_ce: 0.008003
2022-01-14 16:10:10,075 iteration 2827 : loss : 0.035009, loss_ce: 0.017698
2022-01-14 16:10:11,613 iteration 2828 : loss : 0.026932, loss_ce: 0.011881
2022-01-14 16:10:13,258 iteration 2829 : loss : 0.033876, loss_ce: 0.011765
2022-01-14 16:10:14,699 iteration 2830 : loss : 0.022347, loss_ce: 0.009381
2022-01-14 16:10:16,203 iteration 2831 : loss : 0.027070, loss_ce: 0.011234
2022-01-14 16:10:17,777 iteration 2832 : loss : 0.034604, loss_ce: 0.010254
2022-01-14 16:10:19,372 iteration 2833 : loss : 0.031449, loss_ce: 0.011868
2022-01-14 16:10:20,869 iteration 2834 : loss : 0.044120, loss_ce: 0.013052
2022-01-14 16:10:22,403 iteration 2835 : loss : 0.052102, loss_ce: 0.012938
2022-01-14 16:10:23,951 iteration 2836 : loss : 0.032202, loss_ce: 0.014942
2022-01-14 16:10:25,463 iteration 2837 : loss : 0.030715, loss_ce: 0.007413
2022-01-14 16:10:26,920 iteration 2838 : loss : 0.018876, loss_ce: 0.005917
2022-01-14 16:10:28,489 iteration 2839 : loss : 0.049016, loss_ce: 0.018312
 42%|███████████▎               | 167/400 [1:17:48<1:47:57, 27.80s/it]2022-01-14 16:10:30,044 iteration 2840 : loss : 0.042045, loss_ce: 0.022186
2022-01-14 16:10:31,529 iteration 2841 : loss : 0.024099, loss_ce: 0.009031
2022-01-14 16:10:33,060 iteration 2842 : loss : 0.037720, loss_ce: 0.011692
2022-01-14 16:10:34,505 iteration 2843 : loss : 0.026965, loss_ce: 0.010035
2022-01-14 16:10:35,907 iteration 2844 : loss : 0.018993, loss_ce: 0.007688
2022-01-14 16:10:37,415 iteration 2845 : loss : 0.027097, loss_ce: 0.010779
2022-01-14 16:10:39,053 iteration 2846 : loss : 0.055166, loss_ce: 0.022228
2022-01-14 16:10:40,623 iteration 2847 : loss : 0.036403, loss_ce: 0.011906
2022-01-14 16:10:42,125 iteration 2848 : loss : 0.027455, loss_ce: 0.008995
2022-01-14 16:10:43,686 iteration 2849 : loss : 0.028803, loss_ce: 0.011029
2022-01-14 16:10:45,200 iteration 2850 : loss : 0.024384, loss_ce: 0.010921
2022-01-14 16:10:46,759 iteration 2851 : loss : 0.021279, loss_ce: 0.008500
2022-01-14 16:10:48,205 iteration 2852 : loss : 0.026453, loss_ce: 0.008308
2022-01-14 16:10:49,737 iteration 2853 : loss : 0.032644, loss_ce: 0.009648
2022-01-14 16:10:51,170 iteration 2854 : loss : 0.032629, loss_ce: 0.009032
2022-01-14 16:10:52,621 iteration 2855 : loss : 0.047218, loss_ce: 0.019319
2022-01-14 16:10:54,047 iteration 2856 : loss : 0.018996, loss_ce: 0.008913
 42%|███████████▎               | 168/400 [1:18:14<1:44:54, 27.13s/it]2022-01-14 16:10:55,625 iteration 2857 : loss : 0.029210, loss_ce: 0.013204
2022-01-14 16:10:57,290 iteration 2858 : loss : 0.046947, loss_ce: 0.014425
2022-01-14 16:10:58,838 iteration 2859 : loss : 0.025830, loss_ce: 0.009552
2022-01-14 16:11:00,383 iteration 2860 : loss : 0.024512, loss_ce: 0.009738
2022-01-14 16:11:01,922 iteration 2861 : loss : 0.023085, loss_ce: 0.007320
2022-01-14 16:11:03,451 iteration 2862 : loss : 0.039274, loss_ce: 0.010054
2022-01-14 16:11:04,907 iteration 2863 : loss : 0.027190, loss_ce: 0.009943
2022-01-14 16:11:06,424 iteration 2864 : loss : 0.033833, loss_ce: 0.014775
2022-01-14 16:11:07,947 iteration 2865 : loss : 0.030452, loss_ce: 0.012465
2022-01-14 16:11:09,473 iteration 2866 : loss : 0.022026, loss_ce: 0.007742
2022-01-14 16:11:11,108 iteration 2867 : loss : 0.027016, loss_ce: 0.007218
2022-01-14 16:11:12,657 iteration 2868 : loss : 0.037528, loss_ce: 0.013714
2022-01-14 16:11:14,219 iteration 2869 : loss : 0.034154, loss_ce: 0.012445
2022-01-14 16:11:15,839 iteration 2870 : loss : 0.033110, loss_ce: 0.011140
2022-01-14 16:11:17,277 iteration 2871 : loss : 0.031470, loss_ce: 0.015415
2022-01-14 16:11:18,732 iteration 2872 : loss : 0.030197, loss_ce: 0.013962
2022-01-14 16:11:20,204 iteration 2873 : loss : 0.025533, loss_ce: 0.010631
 42%|███████████▍               | 169/400 [1:18:40<1:43:19, 26.84s/it]2022-01-14 16:11:21,731 iteration 2874 : loss : 0.020313, loss_ce: 0.007446
2022-01-14 16:11:23,323 iteration 2875 : loss : 0.024087, loss_ce: 0.009342
2022-01-14 16:11:24,789 iteration 2876 : loss : 0.034522, loss_ce: 0.011133
2022-01-14 16:11:26,220 iteration 2877 : loss : 0.026278, loss_ce: 0.008590
2022-01-14 16:11:27,743 iteration 2878 : loss : 0.027408, loss_ce: 0.008490
2022-01-14 16:11:29,137 iteration 2879 : loss : 0.025882, loss_ce: 0.010534
2022-01-14 16:11:30,692 iteration 2880 : loss : 0.044734, loss_ce: 0.020123
2022-01-14 16:11:32,109 iteration 2881 : loss : 0.028140, loss_ce: 0.013027
2022-01-14 16:11:33,608 iteration 2882 : loss : 0.033527, loss_ce: 0.009953
2022-01-14 16:11:35,179 iteration 2883 : loss : 0.037473, loss_ce: 0.011203
2022-01-14 16:11:36,715 iteration 2884 : loss : 0.045748, loss_ce: 0.018172
2022-01-14 16:11:38,219 iteration 2885 : loss : 0.027423, loss_ce: 0.009408
2022-01-14 16:11:39,655 iteration 2886 : loss : 0.020668, loss_ce: 0.007050
2022-01-14 16:11:41,079 iteration 2887 : loss : 0.027588, loss_ce: 0.009571
2022-01-14 16:11:42,661 iteration 2888 : loss : 0.021325, loss_ce: 0.009329
2022-01-14 16:11:44,208 iteration 2889 : loss : 0.026887, loss_ce: 0.009381
2022-01-14 16:11:44,209 Training Data Eval:
2022-01-14 16:11:51,689   Average segmentation loss on training set: 0.0191
2022-01-14 16:11:51,690 Validation Data Eval:
2022-01-14 16:11:54,265   Average segmentation loss on validation set: 0.1032
2022-01-14 16:11:55,779 iteration 2890 : loss : 0.026650, loss_ce: 0.012618
 42%|███████████▍               | 170/400 [1:19:15<1:52:55, 29.46s/it]2022-01-14 16:11:57,339 iteration 2891 : loss : 0.028096, loss_ce: 0.011786
2022-01-14 16:11:58,850 iteration 2892 : loss : 0.034147, loss_ce: 0.012985
2022-01-14 16:12:00,250 iteration 2893 : loss : 0.023984, loss_ce: 0.009746
2022-01-14 16:12:01,696 iteration 2894 : loss : 0.019736, loss_ce: 0.006993
2022-01-14 16:12:03,155 iteration 2895 : loss : 0.025141, loss_ce: 0.009064
2022-01-14 16:12:04,651 iteration 2896 : loss : 0.035252, loss_ce: 0.011568
2022-01-14 16:12:06,326 iteration 2897 : loss : 0.066488, loss_ce: 0.015339
2022-01-14 16:12:07,856 iteration 2898 : loss : 0.028493, loss_ce: 0.009729
2022-01-14 16:12:09,409 iteration 2899 : loss : 0.032539, loss_ce: 0.013120
2022-01-14 16:12:11,034 iteration 2900 : loss : 0.049173, loss_ce: 0.020282
2022-01-14 16:12:12,573 iteration 2901 : loss : 0.034037, loss_ce: 0.011241
2022-01-14 16:12:14,052 iteration 2902 : loss : 0.036774, loss_ce: 0.023337
2022-01-14 16:12:15,572 iteration 2903 : loss : 0.027201, loss_ce: 0.008603
2022-01-14 16:12:17,076 iteration 2904 : loss : 0.026632, loss_ce: 0.012019
2022-01-14 16:12:18,633 iteration 2905 : loss : 0.033193, loss_ce: 0.014679
2022-01-14 16:12:20,092 iteration 2906 : loss : 0.027772, loss_ce: 0.011747
2022-01-14 16:12:21,649 iteration 2907 : loss : 0.020171, loss_ce: 0.007595
 43%|███████████▌               | 171/400 [1:19:41<1:48:18, 28.38s/it]2022-01-14 16:12:23,192 iteration 2908 : loss : 0.027282, loss_ce: 0.009824
2022-01-14 16:12:24,723 iteration 2909 : loss : 0.037451, loss_ce: 0.013214
2022-01-14 16:12:26,284 iteration 2910 : loss : 0.021744, loss_ce: 0.008308
2022-01-14 16:12:27,853 iteration 2911 : loss : 0.032988, loss_ce: 0.011628
2022-01-14 16:12:29,309 iteration 2912 : loss : 0.021681, loss_ce: 0.008176
2022-01-14 16:12:30,851 iteration 2913 : loss : 0.029865, loss_ce: 0.010096
2022-01-14 16:12:32,397 iteration 2914 : loss : 0.032900, loss_ce: 0.013205
2022-01-14 16:12:33,897 iteration 2915 : loss : 0.033692, loss_ce: 0.016929
2022-01-14 16:12:35,381 iteration 2916 : loss : 0.030718, loss_ce: 0.012422
2022-01-14 16:12:36,885 iteration 2917 : loss : 0.025190, loss_ce: 0.009295
2022-01-14 16:12:38,294 iteration 2918 : loss : 0.021994, loss_ce: 0.009790
2022-01-14 16:12:39,831 iteration 2919 : loss : 0.026748, loss_ce: 0.008849
2022-01-14 16:12:41,317 iteration 2920 : loss : 0.022695, loss_ce: 0.008508
2022-01-14 16:12:42,810 iteration 2921 : loss : 0.027306, loss_ce: 0.011534
2022-01-14 16:12:44,294 iteration 2922 : loss : 0.026925, loss_ce: 0.007915
2022-01-14 16:12:45,867 iteration 2923 : loss : 0.032584, loss_ce: 0.010833
2022-01-14 16:12:47,407 iteration 2924 : loss : 0.023897, loss_ce: 0.010337
 43%|███████████▌               | 172/400 [1:20:07<1:44:51, 27.60s/it]2022-01-14 16:12:48,970 iteration 2925 : loss : 0.031892, loss_ce: 0.014086
2022-01-14 16:12:50,394 iteration 2926 : loss : 0.019253, loss_ce: 0.006955
2022-01-14 16:12:51,877 iteration 2927 : loss : 0.018388, loss_ce: 0.005947
2022-01-14 16:12:53,400 iteration 2928 : loss : 0.043684, loss_ce: 0.022884
2022-01-14 16:12:54,851 iteration 2929 : loss : 0.028169, loss_ce: 0.007324
2022-01-14 16:12:56,287 iteration 2930 : loss : 0.021333, loss_ce: 0.009608
2022-01-14 16:12:57,769 iteration 2931 : loss : 0.082629, loss_ce: 0.012727
2022-01-14 16:12:59,323 iteration 2932 : loss : 0.028244, loss_ce: 0.010617
2022-01-14 16:13:00,850 iteration 2933 : loss : 0.046894, loss_ce: 0.021657
2022-01-14 16:13:02,444 iteration 2934 : loss : 0.036245, loss_ce: 0.017760
2022-01-14 16:13:03,907 iteration 2935 : loss : 0.073365, loss_ce: 0.029488
2022-01-14 16:13:05,383 iteration 2936 : loss : 0.050380, loss_ce: 0.023113
2022-01-14 16:13:06,887 iteration 2937 : loss : 0.037913, loss_ce: 0.018784
2022-01-14 16:13:08,404 iteration 2938 : loss : 0.047162, loss_ce: 0.018345
2022-01-14 16:13:09,794 iteration 2939 : loss : 0.049390, loss_ce: 0.012294
2022-01-14 16:13:11,261 iteration 2940 : loss : 0.039814, loss_ce: 0.020588
2022-01-14 16:13:12,721 iteration 2941 : loss : 0.046696, loss_ce: 0.018518
 43%|███████████▋               | 173/400 [1:20:32<1:41:48, 26.91s/it]2022-01-14 16:13:14,321 iteration 2942 : loss : 0.055865, loss_ce: 0.022323
2022-01-14 16:13:15,858 iteration 2943 : loss : 0.030624, loss_ce: 0.013839
2022-01-14 16:13:17,382 iteration 2944 : loss : 0.069936, loss_ce: 0.023258
2022-01-14 16:13:18,890 iteration 2945 : loss : 0.044788, loss_ce: 0.019604
2022-01-14 16:13:20,464 iteration 2946 : loss : 0.031900, loss_ce: 0.012862
2022-01-14 16:13:21,933 iteration 2947 : loss : 0.032438, loss_ce: 0.010800
2022-01-14 16:13:23,462 iteration 2948 : loss : 0.032595, loss_ce: 0.013110
2022-01-14 16:13:24,927 iteration 2949 : loss : 0.038633, loss_ce: 0.016593
2022-01-14 16:13:26,315 iteration 2950 : loss : 0.024575, loss_ce: 0.009632
2022-01-14 16:13:27,779 iteration 2951 : loss : 0.041294, loss_ce: 0.015190
2022-01-14 16:13:29,165 iteration 2952 : loss : 0.102952, loss_ce: 0.021094
2022-01-14 16:13:30,754 iteration 2953 : loss : 0.030120, loss_ce: 0.011242
2022-01-14 16:13:32,239 iteration 2954 : loss : 0.034599, loss_ce: 0.015986
2022-01-14 16:13:33,758 iteration 2955 : loss : 0.057849, loss_ce: 0.013340
2022-01-14 16:13:35,169 iteration 2956 : loss : 0.054193, loss_ce: 0.032185
2022-01-14 16:13:36,598 iteration 2957 : loss : 0.042081, loss_ce: 0.014114
2022-01-14 16:13:38,110 iteration 2958 : loss : 0.043153, loss_ce: 0.017161
 44%|███████████▋               | 174/400 [1:20:58<1:39:38, 26.45s/it]2022-01-14 16:13:39,709 iteration 2959 : loss : 0.028464, loss_ce: 0.012007
2022-01-14 16:13:41,175 iteration 2960 : loss : 0.048990, loss_ce: 0.023964
2022-01-14 16:13:42,705 iteration 2961 : loss : 0.037119, loss_ce: 0.018338
2022-01-14 16:13:44,215 iteration 2962 : loss : 0.030664, loss_ce: 0.014500
2022-01-14 16:13:45,674 iteration 2963 : loss : 0.037128, loss_ce: 0.017391
2022-01-14 16:13:47,146 iteration 2964 : loss : 0.057231, loss_ce: 0.023962
2022-01-14 16:13:48,553 iteration 2965 : loss : 0.044028, loss_ce: 0.016490
2022-01-14 16:13:49,941 iteration 2966 : loss : 0.034342, loss_ce: 0.013783
2022-01-14 16:13:51,475 iteration 2967 : loss : 0.032610, loss_ce: 0.015352
2022-01-14 16:13:53,063 iteration 2968 : loss : 0.054728, loss_ce: 0.013952
2022-01-14 16:13:54,566 iteration 2969 : loss : 0.022102, loss_ce: 0.010136
2022-01-14 16:13:56,027 iteration 2970 : loss : 0.028305, loss_ce: 0.010456
2022-01-14 16:13:57,444 iteration 2971 : loss : 0.030508, loss_ce: 0.012651
2022-01-14 16:13:58,950 iteration 2972 : loss : 0.041977, loss_ce: 0.015412
2022-01-14 16:14:00,375 iteration 2973 : loss : 0.042802, loss_ce: 0.016956
2022-01-14 16:14:01,883 iteration 2974 : loss : 0.028186, loss_ce: 0.008819
2022-01-14 16:14:01,883 Training Data Eval:
2022-01-14 16:14:09,265   Average segmentation loss on training set: 0.0395
2022-01-14 16:14:09,266 Validation Data Eval:
2022-01-14 16:14:11,814   Average segmentation loss on validation set: 0.1312
2022-01-14 16:14:13,306 iteration 2975 : loss : 0.033700, loss_ce: 0.009659
 44%|███████████▊               | 175/400 [1:21:33<1:49:02, 29.08s/it]2022-01-14 16:14:14,895 iteration 2976 : loss : 0.052187, loss_ce: 0.029995
2022-01-14 16:14:16,291 iteration 2977 : loss : 0.032407, loss_ce: 0.012565
2022-01-14 16:14:17,683 iteration 2978 : loss : 0.026343, loss_ce: 0.008466
2022-01-14 16:14:19,174 iteration 2979 : loss : 0.019588, loss_ce: 0.006794
2022-01-14 16:14:20,756 iteration 2980 : loss : 0.039616, loss_ce: 0.018399
2022-01-14 16:14:22,238 iteration 2981 : loss : 0.032368, loss_ce: 0.010956
2022-01-14 16:14:23,788 iteration 2982 : loss : 0.028192, loss_ce: 0.012131
2022-01-14 16:14:25,254 iteration 2983 : loss : 0.033887, loss_ce: 0.014478
2022-01-14 16:14:26,800 iteration 2984 : loss : 0.026894, loss_ce: 0.010581
2022-01-14 16:14:28,344 iteration 2985 : loss : 0.041696, loss_ce: 0.013163
2022-01-14 16:14:29,926 iteration 2986 : loss : 0.047179, loss_ce: 0.020419
2022-01-14 16:14:31,366 iteration 2987 : loss : 0.046182, loss_ce: 0.025380
2022-01-14 16:14:32,872 iteration 2988 : loss : 0.023865, loss_ce: 0.007407
2022-01-14 16:14:34,384 iteration 2989 : loss : 0.052464, loss_ce: 0.014358
2022-01-14 16:14:35,905 iteration 2990 : loss : 0.037471, loss_ce: 0.014867
2022-01-14 16:14:37,499 iteration 2991 : loss : 0.023361, loss_ce: 0.007891
2022-01-14 16:14:39,167 iteration 2992 : loss : 0.029010, loss_ce: 0.012354
 44%|███████████▉               | 176/400 [1:21:59<1:44:56, 28.11s/it]2022-01-14 16:14:40,603 iteration 2993 : loss : 0.029801, loss_ce: 0.008074
2022-01-14 16:14:42,097 iteration 2994 : loss : 0.032141, loss_ce: 0.012357
2022-01-14 16:14:43,673 iteration 2995 : loss : 0.041793, loss_ce: 0.020946
2022-01-14 16:14:45,178 iteration 2996 : loss : 0.025035, loss_ce: 0.008864
2022-01-14 16:14:46,674 iteration 2997 : loss : 0.023971, loss_ce: 0.008525
2022-01-14 16:14:48,173 iteration 2998 : loss : 0.022805, loss_ce: 0.007446
2022-01-14 16:14:49,747 iteration 2999 : loss : 0.041103, loss_ce: 0.014635
2022-01-14 16:14:51,260 iteration 3000 : loss : 0.035801, loss_ce: 0.011802
2022-01-14 16:14:52,819 iteration 3001 : loss : 0.023871, loss_ce: 0.009224
2022-01-14 16:14:54,223 iteration 3002 : loss : 0.032418, loss_ce: 0.012605
2022-01-14 16:14:55,783 iteration 3003 : loss : 0.030993, loss_ce: 0.011605
2022-01-14 16:14:57,193 iteration 3004 : loss : 0.024405, loss_ce: 0.009977
2022-01-14 16:14:58,715 iteration 3005 : loss : 0.032047, loss_ce: 0.011439
2022-01-14 16:15:00,229 iteration 3006 : loss : 0.036002, loss_ce: 0.013319
2022-01-14 16:15:01,689 iteration 3007 : loss : 0.021792, loss_ce: 0.008504
2022-01-14 16:15:03,312 iteration 3008 : loss : 0.024707, loss_ce: 0.010527
2022-01-14 16:15:04,791 iteration 3009 : loss : 0.026717, loss_ce: 0.014902
 44%|███████████▉               | 177/400 [1:22:24<1:41:42, 27.37s/it]2022-01-14 16:15:06,313 iteration 3010 : loss : 0.023956, loss_ce: 0.008669
2022-01-14 16:15:07,794 iteration 3011 : loss : 0.032829, loss_ce: 0.013017
2022-01-14 16:15:09,276 iteration 3012 : loss : 0.023714, loss_ce: 0.008182
2022-01-14 16:15:10,739 iteration 3013 : loss : 0.018547, loss_ce: 0.007486
2022-01-14 16:15:12,322 iteration 3014 : loss : 0.024215, loss_ce: 0.008979
2022-01-14 16:15:13,845 iteration 3015 : loss : 0.019619, loss_ce: 0.006683
2022-01-14 16:15:15,347 iteration 3016 : loss : 0.021326, loss_ce: 0.008076
2022-01-14 16:15:16,826 iteration 3017 : loss : 0.036214, loss_ce: 0.009747
2022-01-14 16:15:18,268 iteration 3018 : loss : 0.023138, loss_ce: 0.006107
2022-01-14 16:15:19,766 iteration 3019 : loss : 0.038207, loss_ce: 0.014580
2022-01-14 16:15:21,120 iteration 3020 : loss : 0.026646, loss_ce: 0.013323
2022-01-14 16:15:22,520 iteration 3021 : loss : 0.019835, loss_ce: 0.006681
2022-01-14 16:15:24,006 iteration 3022 : loss : 0.027261, loss_ce: 0.007531
2022-01-14 16:15:25,506 iteration 3023 : loss : 0.023651, loss_ce: 0.011894
2022-01-14 16:15:27,016 iteration 3024 : loss : 0.031688, loss_ce: 0.011732
2022-01-14 16:15:28,417 iteration 3025 : loss : 0.021915, loss_ce: 0.009003
2022-01-14 16:15:29,965 iteration 3026 : loss : 0.026864, loss_ce: 0.011471
 44%|████████████               | 178/400 [1:22:50<1:38:49, 26.71s/it]2022-01-14 16:15:31,499 iteration 3027 : loss : 0.024862, loss_ce: 0.011185
2022-01-14 16:15:32,982 iteration 3028 : loss : 0.033758, loss_ce: 0.013346
2022-01-14 16:15:34,474 iteration 3029 : loss : 0.025685, loss_ce: 0.011444
2022-01-14 16:15:36,057 iteration 3030 : loss : 0.032005, loss_ce: 0.011167
2022-01-14 16:15:37,448 iteration 3031 : loss : 0.022154, loss_ce: 0.008550
2022-01-14 16:15:38,932 iteration 3032 : loss : 0.027666, loss_ce: 0.009285
2022-01-14 16:15:40,456 iteration 3033 : loss : 0.037496, loss_ce: 0.016549
2022-01-14 16:15:41,922 iteration 3034 : loss : 0.021294, loss_ce: 0.007056
2022-01-14 16:15:43,506 iteration 3035 : loss : 0.043086, loss_ce: 0.012808
2022-01-14 16:15:45,042 iteration 3036 : loss : 0.022184, loss_ce: 0.009489
2022-01-14 16:15:46,585 iteration 3037 : loss : 0.017478, loss_ce: 0.006262
2022-01-14 16:15:48,018 iteration 3038 : loss : 0.021552, loss_ce: 0.005384
2022-01-14 16:15:49,716 iteration 3039 : loss : 0.035100, loss_ce: 0.013738
2022-01-14 16:15:51,144 iteration 3040 : loss : 0.024858, loss_ce: 0.010617
2022-01-14 16:15:52,597 iteration 3041 : loss : 0.027686, loss_ce: 0.011351
2022-01-14 16:15:54,028 iteration 3042 : loss : 0.027837, loss_ce: 0.012098
2022-01-14 16:15:55,657 iteration 3043 : loss : 0.023303, loss_ce: 0.009002
 45%|████████████               | 179/400 [1:23:15<1:37:15, 26.40s/it]2022-01-14 16:15:57,235 iteration 3044 : loss : 0.047269, loss_ce: 0.018932
2022-01-14 16:15:58,688 iteration 3045 : loss : 0.022332, loss_ce: 0.009548
2022-01-14 16:16:00,162 iteration 3046 : loss : 0.031713, loss_ce: 0.013408
2022-01-14 16:16:01,824 iteration 3047 : loss : 0.029524, loss_ce: 0.013143
2022-01-14 16:16:03,411 iteration 3048 : loss : 0.025597, loss_ce: 0.014011
2022-01-14 16:16:04,891 iteration 3049 : loss : 0.026975, loss_ce: 0.011178
2022-01-14 16:16:06,490 iteration 3050 : loss : 0.024158, loss_ce: 0.011216
2022-01-14 16:16:08,040 iteration 3051 : loss : 0.030866, loss_ce: 0.007328
2022-01-14 16:16:09,643 iteration 3052 : loss : 0.041984, loss_ce: 0.015269
2022-01-14 16:16:11,189 iteration 3053 : loss : 0.018987, loss_ce: 0.007877
2022-01-14 16:16:12,694 iteration 3054 : loss : 0.048185, loss_ce: 0.019687
2022-01-14 16:16:14,216 iteration 3055 : loss : 0.024069, loss_ce: 0.009274
2022-01-14 16:16:15,717 iteration 3056 : loss : 0.023345, loss_ce: 0.007903
2022-01-14 16:16:17,171 iteration 3057 : loss : 0.018767, loss_ce: 0.006290
2022-01-14 16:16:18,764 iteration 3058 : loss : 0.041738, loss_ce: 0.012640
2022-01-14 16:16:20,374 iteration 3059 : loss : 0.035702, loss_ce: 0.012586
2022-01-14 16:16:20,374 Training Data Eval:
2022-01-14 16:16:27,855   Average segmentation loss on training set: 0.0212
2022-01-14 16:16:27,856 Validation Data Eval:
2022-01-14 16:16:30,433   Average segmentation loss on validation set: 0.1020
2022-01-14 16:16:31,951 iteration 3060 : loss : 0.024638, loss_ce: 0.009219
 45%|████████████▏              | 180/400 [1:23:52<1:47:41, 29.37s/it]2022-01-14 16:16:33,459 iteration 3061 : loss : 0.030235, loss_ce: 0.010596
2022-01-14 16:16:35,007 iteration 3062 : loss : 0.023461, loss_ce: 0.007484
2022-01-14 16:16:36,492 iteration 3063 : loss : 0.031707, loss_ce: 0.009868
2022-01-14 16:16:38,069 iteration 3064 : loss : 0.036218, loss_ce: 0.020976
2022-01-14 16:16:39,551 iteration 3065 : loss : 0.037571, loss_ce: 0.009703
2022-01-14 16:16:41,020 iteration 3066 : loss : 0.023270, loss_ce: 0.006075
2022-01-14 16:16:42,536 iteration 3067 : loss : 0.026340, loss_ce: 0.011441
2022-01-14 16:16:44,124 iteration 3068 : loss : 0.019263, loss_ce: 0.006667
2022-01-14 16:16:45,714 iteration 3069 : loss : 0.044643, loss_ce: 0.010276
2022-01-14 16:16:47,152 iteration 3070 : loss : 0.026476, loss_ce: 0.009463
2022-01-14 16:16:48,742 iteration 3071 : loss : 0.025147, loss_ce: 0.009022
2022-01-14 16:16:50,274 iteration 3072 : loss : 0.022421, loss_ce: 0.007179
2022-01-14 16:16:51,732 iteration 3073 : loss : 0.028351, loss_ce: 0.010785
2022-01-14 16:16:53,349 iteration 3074 : loss : 0.038002, loss_ce: 0.017979
2022-01-14 16:16:54,903 iteration 3075 : loss : 0.022353, loss_ce: 0.008046
2022-01-14 16:16:56,354 iteration 3076 : loss : 0.033514, loss_ce: 0.015839
2022-01-14 16:16:57,963 iteration 3077 : loss : 0.060449, loss_ce: 0.027401
 45%|████████████▏              | 181/400 [1:24:18<1:43:31, 28.36s/it]2022-01-14 16:16:59,415 iteration 3078 : loss : 0.018409, loss_ce: 0.007409
2022-01-14 16:17:00,946 iteration 3079 : loss : 0.035711, loss_ce: 0.011729
2022-01-14 16:17:02,485 iteration 3080 : loss : 0.022121, loss_ce: 0.008332
2022-01-14 16:17:03,964 iteration 3081 : loss : 0.031054, loss_ce: 0.008994
2022-01-14 16:17:05,501 iteration 3082 : loss : 0.024611, loss_ce: 0.008911
2022-01-14 16:17:07,024 iteration 3083 : loss : 0.028661, loss_ce: 0.012245
2022-01-14 16:17:08,475 iteration 3084 : loss : 0.023429, loss_ce: 0.009585
2022-01-14 16:17:10,036 iteration 3085 : loss : 0.115382, loss_ce: 0.019702
2022-01-14 16:17:11,508 iteration 3086 : loss : 0.020259, loss_ce: 0.007697
2022-01-14 16:17:12,951 iteration 3087 : loss : 0.025555, loss_ce: 0.007161
2022-01-14 16:17:14,393 iteration 3088 : loss : 0.021982, loss_ce: 0.008315
2022-01-14 16:17:15,848 iteration 3089 : loss : 0.026207, loss_ce: 0.010061
2022-01-14 16:17:17,338 iteration 3090 : loss : 0.030529, loss_ce: 0.011825
2022-01-14 16:17:18,810 iteration 3091 : loss : 0.037790, loss_ce: 0.013571
2022-01-14 16:17:20,227 iteration 3092 : loss : 0.035062, loss_ce: 0.016190
2022-01-14 16:17:21,728 iteration 3093 : loss : 0.023857, loss_ce: 0.007918
2022-01-14 16:17:23,200 iteration 3094 : loss : 0.041361, loss_ce: 0.021983
 46%|████████████▎              | 182/400 [1:24:43<1:39:37, 27.42s/it]2022-01-14 16:17:24,806 iteration 3095 : loss : 0.021955, loss_ce: 0.007359
2022-01-14 16:17:26,292 iteration 3096 : loss : 0.026773, loss_ce: 0.010242
2022-01-14 16:17:27,764 iteration 3097 : loss : 0.034671, loss_ce: 0.012989
2022-01-14 16:17:29,212 iteration 3098 : loss : 0.022947, loss_ce: 0.007594
2022-01-14 16:17:30,798 iteration 3099 : loss : 0.033932, loss_ce: 0.010904
2022-01-14 16:17:32,229 iteration 3100 : loss : 0.026669, loss_ce: 0.008919
2022-01-14 16:17:33,752 iteration 3101 : loss : 0.023994, loss_ce: 0.010879
2022-01-14 16:17:35,292 iteration 3102 : loss : 0.025057, loss_ce: 0.009587
2022-01-14 16:17:36,771 iteration 3103 : loss : 0.021782, loss_ce: 0.006892
2022-01-14 16:17:38,284 iteration 3104 : loss : 0.023516, loss_ce: 0.008166
2022-01-14 16:17:39,745 iteration 3105 : loss : 0.022891, loss_ce: 0.008030
2022-01-14 16:17:41,404 iteration 3106 : loss : 0.038983, loss_ce: 0.017242
2022-01-14 16:17:42,877 iteration 3107 : loss : 0.033486, loss_ce: 0.013552
2022-01-14 16:17:44,294 iteration 3108 : loss : 0.023070, loss_ce: 0.007973
2022-01-14 16:17:45,872 iteration 3109 : loss : 0.031420, loss_ce: 0.016496
2022-01-14 16:17:47,434 iteration 3110 : loss : 0.030111, loss_ce: 0.013758
2022-01-14 16:17:48,914 iteration 3111 : loss : 0.027375, loss_ce: 0.008373
 46%|████████████▎              | 183/400 [1:25:08<1:37:19, 26.91s/it]2022-01-14 16:17:50,430 iteration 3112 : loss : 0.018957, loss_ce: 0.007432
2022-01-14 16:17:51,905 iteration 3113 : loss : 0.028852, loss_ce: 0.012548
2022-01-14 16:17:53,561 iteration 3114 : loss : 0.085629, loss_ce: 0.024217
2022-01-14 16:17:55,155 iteration 3115 : loss : 0.028701, loss_ce: 0.012092
2022-01-14 16:17:56,653 iteration 3116 : loss : 0.021553, loss_ce: 0.007831
2022-01-14 16:17:58,160 iteration 3117 : loss : 0.034442, loss_ce: 0.017404
2022-01-14 16:17:59,751 iteration 3118 : loss : 0.032074, loss_ce: 0.013230
2022-01-14 16:18:01,300 iteration 3119 : loss : 0.035368, loss_ce: 0.015188
2022-01-14 16:18:02,817 iteration 3120 : loss : 0.021458, loss_ce: 0.007138
2022-01-14 16:18:04,338 iteration 3121 : loss : 0.040389, loss_ce: 0.013438
2022-01-14 16:18:05,914 iteration 3122 : loss : 0.031891, loss_ce: 0.009008
2022-01-14 16:18:07,412 iteration 3123 : loss : 0.024792, loss_ce: 0.010304
2022-01-14 16:18:08,962 iteration 3124 : loss : 0.029086, loss_ce: 0.012343
2022-01-14 16:18:10,497 iteration 3125 : loss : 0.033555, loss_ce: 0.014311
2022-01-14 16:18:11,911 iteration 3126 : loss : 0.029846, loss_ce: 0.011210
2022-01-14 16:18:13,440 iteration 3127 : loss : 0.035854, loss_ce: 0.014440
2022-01-14 16:18:14,861 iteration 3128 : loss : 0.019468, loss_ce: 0.006822
 46%|████████████▍              | 184/400 [1:25:34<1:35:49, 26.62s/it]2022-01-14 16:18:16,455 iteration 3129 : loss : 0.026452, loss_ce: 0.009601
2022-01-14 16:18:17,968 iteration 3130 : loss : 0.022617, loss_ce: 0.007645
2022-01-14 16:18:19,536 iteration 3131 : loss : 0.041521, loss_ce: 0.016813
2022-01-14 16:18:21,011 iteration 3132 : loss : 0.020130, loss_ce: 0.007853
2022-01-14 16:18:22,460 iteration 3133 : loss : 0.023672, loss_ce: 0.008761
2022-01-14 16:18:23,979 iteration 3134 : loss : 0.028532, loss_ce: 0.012775
2022-01-14 16:18:25,505 iteration 3135 : loss : 0.033814, loss_ce: 0.013307
2022-01-14 16:18:27,082 iteration 3136 : loss : 0.045006, loss_ce: 0.021844
2022-01-14 16:18:28,599 iteration 3137 : loss : 0.030120, loss_ce: 0.012895
2022-01-14 16:18:30,145 iteration 3138 : loss : 0.028219, loss_ce: 0.012244
2022-01-14 16:18:31,722 iteration 3139 : loss : 0.029379, loss_ce: 0.010342
2022-01-14 16:18:33,278 iteration 3140 : loss : 0.032555, loss_ce: 0.012238
2022-01-14 16:18:34,840 iteration 3141 : loss : 0.025734, loss_ce: 0.008848
2022-01-14 16:18:36,327 iteration 3142 : loss : 0.027064, loss_ce: 0.009269
2022-01-14 16:18:37,872 iteration 3143 : loss : 0.021245, loss_ce: 0.008767
2022-01-14 16:18:39,468 iteration 3144 : loss : 0.031789, loss_ce: 0.014317
2022-01-14 16:18:39,469 Training Data Eval:
2022-01-14 16:18:46,954   Average segmentation loss on training set: 0.0190
2022-01-14 16:18:46,955 Validation Data Eval:
2022-01-14 16:18:49,524   Average segmentation loss on validation set: 0.1255
2022-01-14 16:18:50,922 iteration 3145 : loss : 0.022514, loss_ce: 0.007807
 46%|████████████▍              | 185/400 [1:26:10<1:45:32, 29.45s/it]2022-01-14 16:18:52,386 iteration 3146 : loss : 0.019067, loss_ce: 0.007313
2022-01-14 16:18:53,865 iteration 3147 : loss : 0.022842, loss_ce: 0.009975
2022-01-14 16:18:55,353 iteration 3148 : loss : 0.023127, loss_ce: 0.007434
2022-01-14 16:18:56,832 iteration 3149 : loss : 0.024126, loss_ce: 0.009187
2022-01-14 16:18:58,335 iteration 3150 : loss : 0.036893, loss_ce: 0.017115
2022-01-14 16:18:59,814 iteration 3151 : loss : 0.031761, loss_ce: 0.007949
2022-01-14 16:19:01,319 iteration 3152 : loss : 0.022610, loss_ce: 0.009010
2022-01-14 16:19:02,811 iteration 3153 : loss : 0.033526, loss_ce: 0.012067
2022-01-14 16:19:04,259 iteration 3154 : loss : 0.024935, loss_ce: 0.011752
2022-01-14 16:19:05,728 iteration 3155 : loss : 0.024022, loss_ce: 0.007418
2022-01-14 16:19:07,307 iteration 3156 : loss : 0.055831, loss_ce: 0.022593
2022-01-14 16:19:08,884 iteration 3157 : loss : 0.024855, loss_ce: 0.009309
2022-01-14 16:19:10,355 iteration 3158 : loss : 0.031057, loss_ce: 0.014284
2022-01-14 16:19:11,866 iteration 3159 : loss : 0.023750, loss_ce: 0.008925
2022-01-14 16:19:13,387 iteration 3160 : loss : 0.021156, loss_ce: 0.008351
2022-01-14 16:19:14,826 iteration 3161 : loss : 0.034164, loss_ce: 0.011445
2022-01-14 16:19:16,396 iteration 3162 : loss : 0.029131, loss_ce: 0.011639
 46%|████████████▌              | 186/400 [1:26:36<1:40:48, 28.26s/it]2022-01-14 16:19:18,030 iteration 3163 : loss : 0.032764, loss_ce: 0.014766
2022-01-14 16:19:19,567 iteration 3164 : loss : 0.020567, loss_ce: 0.007260
2022-01-14 16:19:21,076 iteration 3165 : loss : 0.020893, loss_ce: 0.007203
2022-01-14 16:19:22,627 iteration 3166 : loss : 0.034882, loss_ce: 0.010473
2022-01-14 16:19:24,094 iteration 3167 : loss : 0.018070, loss_ce: 0.007323
2022-01-14 16:19:25,781 iteration 3168 : loss : 0.027502, loss_ce: 0.012052
2022-01-14 16:19:27,416 iteration 3169 : loss : 0.037961, loss_ce: 0.019547
2022-01-14 16:19:28,911 iteration 3170 : loss : 0.025458, loss_ce: 0.010845
2022-01-14 16:19:30,349 iteration 3171 : loss : 0.017551, loss_ce: 0.007889
2022-01-14 16:19:31,872 iteration 3172 : loss : 0.022254, loss_ce: 0.007826
2022-01-14 16:19:33,432 iteration 3173 : loss : 0.023810, loss_ce: 0.008096
2022-01-14 16:19:34,925 iteration 3174 : loss : 0.030376, loss_ce: 0.013497
2022-01-14 16:19:36,556 iteration 3175 : loss : 0.037327, loss_ce: 0.009447
2022-01-14 16:19:38,059 iteration 3176 : loss : 0.029322, loss_ce: 0.009645
2022-01-14 16:19:39,631 iteration 3177 : loss : 0.043992, loss_ce: 0.014939
2022-01-14 16:19:41,047 iteration 3178 : loss : 0.023015, loss_ce: 0.007392
2022-01-14 16:19:42,551 iteration 3179 : loss : 0.043552, loss_ce: 0.012865
 47%|████████████▌              | 187/400 [1:27:02<1:38:04, 27.63s/it]2022-01-14 16:19:44,153 iteration 3180 : loss : 0.046190, loss_ce: 0.022116
2022-01-14 16:19:45,616 iteration 3181 : loss : 0.019717, loss_ce: 0.006746
2022-01-14 16:19:47,143 iteration 3182 : loss : 0.048711, loss_ce: 0.016675
2022-01-14 16:19:48,634 iteration 3183 : loss : 0.021419, loss_ce: 0.006484
2022-01-14 16:19:50,129 iteration 3184 : loss : 0.022429, loss_ce: 0.008256
2022-01-14 16:19:51,669 iteration 3185 : loss : 0.031709, loss_ce: 0.012964
2022-01-14 16:19:53,083 iteration 3186 : loss : 0.020132, loss_ce: 0.009930
2022-01-14 16:19:54,588 iteration 3187 : loss : 0.031758, loss_ce: 0.014643
2022-01-14 16:19:56,089 iteration 3188 : loss : 0.021238, loss_ce: 0.008665
2022-01-14 16:19:57,632 iteration 3189 : loss : 0.028487, loss_ce: 0.012171
2022-01-14 16:19:59,139 iteration 3190 : loss : 0.021109, loss_ce: 0.007554
2022-01-14 16:20:00,798 iteration 3191 : loss : 0.035164, loss_ce: 0.007902
2022-01-14 16:20:02,245 iteration 3192 : loss : 0.029210, loss_ce: 0.009704
2022-01-14 16:20:03,806 iteration 3193 : loss : 0.024297, loss_ce: 0.010928
2022-01-14 16:20:05,364 iteration 3194 : loss : 0.021659, loss_ce: 0.005920
2022-01-14 16:20:06,896 iteration 3195 : loss : 0.025040, loss_ce: 0.011477
2022-01-14 16:20:08,393 iteration 3196 : loss : 0.029957, loss_ce: 0.012553
 47%|████████████▋              | 188/400 [1:27:28<1:35:43, 27.09s/it]2022-01-14 16:20:09,844 iteration 3197 : loss : 0.019157, loss_ce: 0.007844
2022-01-14 16:20:11,346 iteration 3198 : loss : 0.023895, loss_ce: 0.008718
2022-01-14 16:20:12,864 iteration 3199 : loss : 0.023685, loss_ce: 0.010070
2022-01-14 16:20:14,488 iteration 3200 : loss : 0.020183, loss_ce: 0.008306
2022-01-14 16:20:16,055 iteration 3201 : loss : 0.036153, loss_ce: 0.009082
2022-01-14 16:20:17,545 iteration 3202 : loss : 0.027370, loss_ce: 0.008904
2022-01-14 16:20:19,165 iteration 3203 : loss : 0.024469, loss_ce: 0.009514
2022-01-14 16:20:20,673 iteration 3204 : loss : 0.019295, loss_ce: 0.005539
2022-01-14 16:20:22,274 iteration 3205 : loss : 0.027406, loss_ce: 0.007908
2022-01-14 16:20:23,772 iteration 3206 : loss : 0.017090, loss_ce: 0.006868
2022-01-14 16:20:25,374 iteration 3207 : loss : 0.025797, loss_ce: 0.011401
2022-01-14 16:20:26,809 iteration 3208 : loss : 0.020706, loss_ce: 0.005422
2022-01-14 16:20:28,275 iteration 3209 : loss : 0.024513, loss_ce: 0.012691
2022-01-14 16:20:29,677 iteration 3210 : loss : 0.028649, loss_ce: 0.014093
2022-01-14 16:20:31,206 iteration 3211 : loss : 0.024822, loss_ce: 0.007921
2022-01-14 16:20:32,656 iteration 3212 : loss : 0.018588, loss_ce: 0.007152
2022-01-14 16:20:34,169 iteration 3213 : loss : 0.026310, loss_ce: 0.007453
 47%|████████████▊              | 189/400 [1:27:54<1:33:53, 26.70s/it]2022-01-14 16:20:35,767 iteration 3214 : loss : 0.023369, loss_ce: 0.010740
2022-01-14 16:20:37,370 iteration 3215 : loss : 0.027936, loss_ce: 0.010264
2022-01-14 16:20:38,904 iteration 3216 : loss : 0.023665, loss_ce: 0.007909
2022-01-14 16:20:40,469 iteration 3217 : loss : 0.026451, loss_ce: 0.006208
2022-01-14 16:20:42,017 iteration 3218 : loss : 0.024717, loss_ce: 0.008752
2022-01-14 16:20:43,499 iteration 3219 : loss : 0.019451, loss_ce: 0.006741
2022-01-14 16:20:45,060 iteration 3220 : loss : 0.025231, loss_ce: 0.008589
2022-01-14 16:20:46,518 iteration 3221 : loss : 0.022807, loss_ce: 0.009247
2022-01-14 16:20:48,074 iteration 3222 : loss : 0.024027, loss_ce: 0.013349
2022-01-14 16:20:49,660 iteration 3223 : loss : 0.026674, loss_ce: 0.007127
2022-01-14 16:20:51,220 iteration 3224 : loss : 0.019911, loss_ce: 0.007242
2022-01-14 16:20:52,692 iteration 3225 : loss : 0.032263, loss_ce: 0.010996
2022-01-14 16:20:54,308 iteration 3226 : loss : 0.055564, loss_ce: 0.020104
2022-01-14 16:20:55,845 iteration 3227 : loss : 0.025130, loss_ce: 0.011376
2022-01-14 16:20:57,304 iteration 3228 : loss : 0.018151, loss_ce: 0.007944
2022-01-14 16:20:58,904 iteration 3229 : loss : 0.029947, loss_ce: 0.013237
2022-01-14 16:20:58,905 Training Data Eval:
2022-01-14 16:21:06,388   Average segmentation loss on training set: 0.0162
2022-01-14 16:21:06,389 Validation Data Eval:
2022-01-14 16:21:08,956   Average segmentation loss on validation set: 0.1024
2022-01-14 16:21:10,584 iteration 3230 : loss : 0.031308, loss_ce: 0.012706
 48%|████████████▊              | 190/400 [1:28:30<1:43:38, 29.61s/it]2022-01-14 16:21:12,101 iteration 3231 : loss : 0.026406, loss_ce: 0.009876
2022-01-14 16:21:13,617 iteration 3232 : loss : 0.020680, loss_ce: 0.009156
2022-01-14 16:21:15,102 iteration 3233 : loss : 0.024020, loss_ce: 0.007628
2022-01-14 16:21:16,555 iteration 3234 : loss : 0.023382, loss_ce: 0.008366
2022-01-14 16:21:18,007 iteration 3235 : loss : 0.018801, loss_ce: 0.005214
2022-01-14 16:21:19,558 iteration 3236 : loss : 0.018785, loss_ce: 0.008047
2022-01-14 16:21:21,102 iteration 3237 : loss : 0.020360, loss_ce: 0.008086
2022-01-14 16:21:22,611 iteration 3238 : loss : 0.034040, loss_ce: 0.007600
2022-01-14 16:21:24,085 iteration 3239 : loss : 0.019994, loss_ce: 0.007805
2022-01-14 16:21:25,624 iteration 3240 : loss : 0.025018, loss_ce: 0.008285
2022-01-14 16:21:27,171 iteration 3241 : loss : 0.023199, loss_ce: 0.008589
2022-01-14 16:21:28,836 iteration 3242 : loss : 0.022962, loss_ce: 0.010103
2022-01-14 16:21:30,304 iteration 3243 : loss : 0.022626, loss_ce: 0.011037
2022-01-14 16:21:31,840 iteration 3244 : loss : 0.028003, loss_ce: 0.008438
2022-01-14 16:21:33,376 iteration 3245 : loss : 0.022147, loss_ce: 0.009617
2022-01-14 16:21:34,974 iteration 3246 : loss : 0.036526, loss_ce: 0.017094
2022-01-14 16:21:36,496 iteration 3247 : loss : 0.025221, loss_ce: 0.007992
 48%|████████████▉              | 191/400 [1:28:56<1:39:17, 28.50s/it]2022-01-14 16:21:38,229 iteration 3248 : loss : 0.037463, loss_ce: 0.016181
2022-01-14 16:21:39,633 iteration 3249 : loss : 0.017734, loss_ce: 0.004734
2022-01-14 16:21:41,201 iteration 3250 : loss : 0.023672, loss_ce: 0.008591
2022-01-14 16:21:42,714 iteration 3251 : loss : 0.029121, loss_ce: 0.005854
2022-01-14 16:21:44,168 iteration 3252 : loss : 0.024213, loss_ce: 0.009141
2022-01-14 16:21:45,720 iteration 3253 : loss : 0.026232, loss_ce: 0.011759
2022-01-14 16:21:47,243 iteration 3254 : loss : 0.032543, loss_ce: 0.009097
2022-01-14 16:21:48,783 iteration 3255 : loss : 0.022440, loss_ce: 0.007767
2022-01-14 16:21:50,193 iteration 3256 : loss : 0.020710, loss_ce: 0.012200
2022-01-14 16:21:51,717 iteration 3257 : loss : 0.041697, loss_ce: 0.015499
2022-01-14 16:21:53,330 iteration 3258 : loss : 0.034843, loss_ce: 0.013937
2022-01-14 16:21:54,866 iteration 3259 : loss : 0.023484, loss_ce: 0.008677
2022-01-14 16:21:56,359 iteration 3260 : loss : 0.021288, loss_ce: 0.008288
2022-01-14 16:21:57,943 iteration 3261 : loss : 0.026833, loss_ce: 0.010433
2022-01-14 16:21:59,436 iteration 3262 : loss : 0.022960, loss_ce: 0.009763
2022-01-14 16:22:00,912 iteration 3263 : loss : 0.039334, loss_ce: 0.011798
2022-01-14 16:22:02,396 iteration 3264 : loss : 0.032063, loss_ce: 0.011623
 48%|████████████▉              | 192/400 [1:29:22<1:36:06, 27.72s/it]2022-01-14 16:22:03,839 iteration 3265 : loss : 0.015977, loss_ce: 0.006045
2022-01-14 16:22:05,380 iteration 3266 : loss : 0.021053, loss_ce: 0.009577
2022-01-14 16:22:06,847 iteration 3267 : loss : 0.021358, loss_ce: 0.009616
2022-01-14 16:22:08,508 iteration 3268 : loss : 0.034715, loss_ce: 0.015139
2022-01-14 16:22:09,943 iteration 3269 : loss : 0.023546, loss_ce: 0.008827
2022-01-14 16:22:11,350 iteration 3270 : loss : 0.026827, loss_ce: 0.011406
2022-01-14 16:22:12,928 iteration 3271 : loss : 0.028700, loss_ce: 0.012276
2022-01-14 16:22:14,413 iteration 3272 : loss : 0.020383, loss_ce: 0.007561
2022-01-14 16:22:15,891 iteration 3273 : loss : 0.024550, loss_ce: 0.009524
2022-01-14 16:22:17,418 iteration 3274 : loss : 0.020032, loss_ce: 0.006296
2022-01-14 16:22:18,873 iteration 3275 : loss : 0.017026, loss_ce: 0.007596
2022-01-14 16:22:20,386 iteration 3276 : loss : 0.019301, loss_ce: 0.006329
2022-01-14 16:22:21,963 iteration 3277 : loss : 0.021154, loss_ce: 0.007987
2022-01-14 16:22:23,433 iteration 3278 : loss : 0.020193, loss_ce: 0.007360
2022-01-14 16:22:24,994 iteration 3279 : loss : 0.037521, loss_ce: 0.018107
2022-01-14 16:22:26,505 iteration 3280 : loss : 0.030752, loss_ce: 0.015775
2022-01-14 16:22:28,013 iteration 3281 : loss : 0.023678, loss_ce: 0.006086
 48%|█████████████              | 193/400 [1:29:48<1:33:27, 27.09s/it]2022-01-14 16:22:29,529 iteration 3282 : loss : 0.019711, loss_ce: 0.008644
2022-01-14 16:22:31,118 iteration 3283 : loss : 0.030968, loss_ce: 0.010778
2022-01-14 16:22:32,566 iteration 3284 : loss : 0.019905, loss_ce: 0.009049
2022-01-14 16:22:33,950 iteration 3285 : loss : 0.018034, loss_ce: 0.006285
2022-01-14 16:22:35,534 iteration 3286 : loss : 0.027410, loss_ce: 0.007674
2022-01-14 16:22:37,077 iteration 3287 : loss : 0.032688, loss_ce: 0.013956
2022-01-14 16:22:38,583 iteration 3288 : loss : 0.025679, loss_ce: 0.008441
2022-01-14 16:22:40,131 iteration 3289 : loss : 0.024068, loss_ce: 0.007493
2022-01-14 16:22:41,580 iteration 3290 : loss : 0.020597, loss_ce: 0.006095
2022-01-14 16:22:43,155 iteration 3291 : loss : 0.031759, loss_ce: 0.009896
2022-01-14 16:22:44,613 iteration 3292 : loss : 0.031390, loss_ce: 0.014498
2022-01-14 16:22:46,036 iteration 3293 : loss : 0.017416, loss_ce: 0.006406
2022-01-14 16:22:47,511 iteration 3294 : loss : 0.021625, loss_ce: 0.008732
2022-01-14 16:22:49,002 iteration 3295 : loss : 0.019279, loss_ce: 0.007926
2022-01-14 16:22:50,521 iteration 3296 : loss : 0.026150, loss_ce: 0.008697
2022-01-14 16:22:52,028 iteration 3297 : loss : 0.034812, loss_ce: 0.013969
2022-01-14 16:22:53,439 iteration 3298 : loss : 0.021322, loss_ce: 0.008604
 48%|█████████████              | 194/400 [1:30:13<1:31:18, 26.59s/it]2022-01-14 16:22:54,931 iteration 3299 : loss : 0.015583, loss_ce: 0.006550
2022-01-14 16:22:56,407 iteration 3300 : loss : 0.021913, loss_ce: 0.008532
2022-01-14 16:22:57,956 iteration 3301 : loss : 0.027632, loss_ce: 0.008271
2022-01-14 16:22:59,377 iteration 3302 : loss : 0.021369, loss_ce: 0.007065
2022-01-14 16:23:00,999 iteration 3303 : loss : 0.025855, loss_ce: 0.008965
2022-01-14 16:23:02,533 iteration 3304 : loss : 0.021221, loss_ce: 0.009996
2022-01-14 16:23:04,069 iteration 3305 : loss : 0.030490, loss_ce: 0.009977
2022-01-14 16:23:05,523 iteration 3306 : loss : 0.015044, loss_ce: 0.005716
2022-01-14 16:23:07,143 iteration 3307 : loss : 0.024823, loss_ce: 0.008810
2022-01-14 16:23:08,717 iteration 3308 : loss : 0.023609, loss_ce: 0.008841
2022-01-14 16:23:10,237 iteration 3309 : loss : 0.017175, loss_ce: 0.006837
2022-01-14 16:23:11,822 iteration 3310 : loss : 0.029854, loss_ce: 0.008469
2022-01-14 16:23:13,317 iteration 3311 : loss : 0.020824, loss_ce: 0.006170
2022-01-14 16:23:14,756 iteration 3312 : loss : 0.016508, loss_ce: 0.007048
2022-01-14 16:23:16,342 iteration 3313 : loss : 0.044329, loss_ce: 0.018119
2022-01-14 16:23:17,714 iteration 3314 : loss : 0.019181, loss_ce: 0.008306
2022-01-14 16:23:17,714 Training Data Eval:
2022-01-14 16:23:25,214   Average segmentation loss on training set: 0.0150
2022-01-14 16:23:25,215 Validation Data Eval:
2022-01-14 16:23:27,785   Average segmentation loss on validation set: 0.0814
2022-01-14 16:23:29,275 iteration 3315 : loss : 0.020447, loss_ce: 0.008206
 49%|█████████████▏             | 195/400 [1:30:49<1:40:19, 29.36s/it]2022-01-14 16:23:30,804 iteration 3316 : loss : 0.026244, loss_ce: 0.006999
2022-01-14 16:23:32,323 iteration 3317 : loss : 0.024868, loss_ce: 0.009119
2022-01-14 16:23:33,857 iteration 3318 : loss : 0.023385, loss_ce: 0.009761
2022-01-14 16:23:35,299 iteration 3319 : loss : 0.018827, loss_ce: 0.007044
2022-01-14 16:23:36,903 iteration 3320 : loss : 0.035995, loss_ce: 0.012691
2022-01-14 16:23:38,326 iteration 3321 : loss : 0.017677, loss_ce: 0.008555
2022-01-14 16:23:39,730 iteration 3322 : loss : 0.021738, loss_ce: 0.006795
2022-01-14 16:23:41,270 iteration 3323 : loss : 0.024118, loss_ce: 0.011379
2022-01-14 16:23:42,780 iteration 3324 : loss : 0.026301, loss_ce: 0.008679
2022-01-14 16:23:44,375 iteration 3325 : loss : 0.027843, loss_ce: 0.010339
2022-01-14 16:23:45,879 iteration 3326 : loss : 0.025960, loss_ce: 0.009521
2022-01-14 16:23:47,547 iteration 3327 : loss : 0.031829, loss_ce: 0.009053
2022-01-14 16:23:49,006 iteration 3328 : loss : 0.020287, loss_ce: 0.009826
2022-01-14 16:23:50,460 iteration 3329 : loss : 0.019856, loss_ce: 0.007152
2022-01-14 16:23:52,015 iteration 3330 : loss : 0.024731, loss_ce: 0.012023
2022-01-14 16:23:53,451 iteration 3331 : loss : 0.016774, loss_ce: 0.007266
2022-01-14 16:23:54,863 iteration 3332 : loss : 0.017635, loss_ce: 0.005720
 49%|█████████████▏             | 196/400 [1:31:14<1:35:59, 28.23s/it]2022-01-14 16:23:56,391 iteration 3333 : loss : 0.036928, loss_ce: 0.016584
2022-01-14 16:23:57,933 iteration 3334 : loss : 0.020090, loss_ce: 0.009051
2022-01-14 16:23:59,478 iteration 3335 : loss : 0.022419, loss_ce: 0.009148
2022-01-14 16:24:00,926 iteration 3336 : loss : 0.021061, loss_ce: 0.007964
2022-01-14 16:24:02,376 iteration 3337 : loss : 0.023756, loss_ce: 0.008739
2022-01-14 16:24:03,916 iteration 3338 : loss : 0.020776, loss_ce: 0.007842
2022-01-14 16:24:05,501 iteration 3339 : loss : 0.033543, loss_ce: 0.011847
2022-01-14 16:24:07,036 iteration 3340 : loss : 0.049197, loss_ce: 0.016754
2022-01-14 16:24:08,504 iteration 3341 : loss : 0.022039, loss_ce: 0.009996
2022-01-14 16:24:09,945 iteration 3342 : loss : 0.024766, loss_ce: 0.012674
2022-01-14 16:24:11,416 iteration 3343 : loss : 0.028463, loss_ce: 0.011563
2022-01-14 16:24:12,978 iteration 3344 : loss : 0.023544, loss_ce: 0.006327
2022-01-14 16:24:14,588 iteration 3345 : loss : 0.026696, loss_ce: 0.012977
2022-01-14 16:24:16,079 iteration 3346 : loss : 0.031985, loss_ce: 0.011198
2022-01-14 16:24:17,550 iteration 3347 : loss : 0.020169, loss_ce: 0.006791
2022-01-14 16:24:19,186 iteration 3348 : loss : 0.020377, loss_ce: 0.008830
2022-01-14 16:24:20,654 iteration 3349 : loss : 0.030419, loss_ce: 0.007249
 49%|█████████████▎             | 197/400 [1:31:40<1:33:02, 27.50s/it]2022-01-14 16:24:22,190 iteration 3350 : loss : 0.019821, loss_ce: 0.009374
2022-01-14 16:24:23,738 iteration 3351 : loss : 0.019041, loss_ce: 0.007078
2022-01-14 16:24:25,197 iteration 3352 : loss : 0.041143, loss_ce: 0.011733
2022-01-14 16:24:26,712 iteration 3353 : loss : 0.021815, loss_ce: 0.006251
2022-01-14 16:24:28,168 iteration 3354 : loss : 0.017880, loss_ce: 0.005119
2022-01-14 16:24:29,721 iteration 3355 : loss : 0.020473, loss_ce: 0.007525
2022-01-14 16:24:31,190 iteration 3356 : loss : 0.025910, loss_ce: 0.010071
2022-01-14 16:24:32,634 iteration 3357 : loss : 0.019283, loss_ce: 0.007412
2022-01-14 16:24:34,149 iteration 3358 : loss : 0.019473, loss_ce: 0.006065
2022-01-14 16:24:35,636 iteration 3359 : loss : 0.022411, loss_ce: 0.010883
2022-01-14 16:24:37,182 iteration 3360 : loss : 0.018943, loss_ce: 0.006401
2022-01-14 16:24:38,681 iteration 3361 : loss : 0.021980, loss_ce: 0.007754
2022-01-14 16:24:40,153 iteration 3362 : loss : 0.025478, loss_ce: 0.009228
2022-01-14 16:24:41,565 iteration 3363 : loss : 0.023829, loss_ce: 0.007705
2022-01-14 16:24:43,153 iteration 3364 : loss : 0.027499, loss_ce: 0.009633
2022-01-14 16:24:44,637 iteration 3365 : loss : 0.017958, loss_ce: 0.007495
2022-01-14 16:24:46,140 iteration 3366 : loss : 0.019858, loss_ce: 0.007424
 50%|█████████████▎             | 198/400 [1:32:06<1:30:32, 26.90s/it]2022-01-14 16:24:47,793 iteration 3367 : loss : 0.031831, loss_ce: 0.012252
2022-01-14 16:24:49,276 iteration 3368 : loss : 0.022168, loss_ce: 0.010661
2022-01-14 16:24:50,795 iteration 3369 : loss : 0.024210, loss_ce: 0.009157
2022-01-14 16:24:52,219 iteration 3370 : loss : 0.025168, loss_ce: 0.005758
2022-01-14 16:24:53,715 iteration 3371 : loss : 0.022160, loss_ce: 0.008340
2022-01-14 16:24:55,285 iteration 3372 : loss : 0.025136, loss_ce: 0.006924
2022-01-14 16:24:56,821 iteration 3373 : loss : 0.025273, loss_ce: 0.010017
2022-01-14 16:24:58,404 iteration 3374 : loss : 0.021062, loss_ce: 0.009179
2022-01-14 16:25:00,034 iteration 3375 : loss : 0.035872, loss_ce: 0.013965
2022-01-14 16:25:01,470 iteration 3376 : loss : 0.016301, loss_ce: 0.005156
2022-01-14 16:25:03,018 iteration 3377 : loss : 0.022350, loss_ce: 0.009247
2022-01-14 16:25:04,469 iteration 3378 : loss : 0.019883, loss_ce: 0.005574
2022-01-14 16:25:06,005 iteration 3379 : loss : 0.021553, loss_ce: 0.007105
2022-01-14 16:25:07,455 iteration 3380 : loss : 0.019227, loss_ce: 0.006272
2022-01-14 16:25:08,970 iteration 3381 : loss : 0.020211, loss_ce: 0.009587
2022-01-14 16:25:10,504 iteration 3382 : loss : 0.023621, loss_ce: 0.007689
2022-01-14 16:25:11,986 iteration 3383 : loss : 0.027248, loss_ce: 0.012505
 50%|█████████████▍             | 199/400 [1:32:32<1:29:02, 26.58s/it]2022-01-14 16:25:13,539 iteration 3384 : loss : 0.020584, loss_ce: 0.008138
2022-01-14 16:25:15,068 iteration 3385 : loss : 0.022960, loss_ce: 0.008306
2022-01-14 16:25:16,540 iteration 3386 : loss : 0.018125, loss_ce: 0.005743
2022-01-14 16:25:18,003 iteration 3387 : loss : 0.022132, loss_ce: 0.006494
2022-01-14 16:25:19,537 iteration 3388 : loss : 0.022990, loss_ce: 0.008051
2022-01-14 16:25:20,959 iteration 3389 : loss : 0.021119, loss_ce: 0.006916
2022-01-14 16:25:22,477 iteration 3390 : loss : 0.021418, loss_ce: 0.009259
2022-01-14 16:25:24,122 iteration 3391 : loss : 0.029665, loss_ce: 0.016723
2022-01-14 16:25:25,685 iteration 3392 : loss : 0.022802, loss_ce: 0.010212
2022-01-14 16:25:27,131 iteration 3393 : loss : 0.021666, loss_ce: 0.009834
2022-01-14 16:25:28,611 iteration 3394 : loss : 0.023256, loss_ce: 0.007267
2022-01-14 16:25:30,125 iteration 3395 : loss : 0.018472, loss_ce: 0.007064
2022-01-14 16:25:31,617 iteration 3396 : loss : 0.023627, loss_ce: 0.007954
2022-01-14 16:25:33,034 iteration 3397 : loss : 0.021989, loss_ce: 0.008447
2022-01-14 16:25:34,685 iteration 3398 : loss : 0.027192, loss_ce: 0.008989
2022-01-14 16:25:36,180 iteration 3399 : loss : 0.025977, loss_ce: 0.011149
2022-01-14 16:25:36,180 Training Data Eval:
2022-01-14 16:25:43,669   Average segmentation loss on training set: 0.0185
2022-01-14 16:25:43,670 Validation Data Eval:
2022-01-14 16:25:46,245   Average segmentation loss on validation set: 0.0730
2022-01-14 16:25:47,828 iteration 3400 : loss : 0.025363, loss_ce: 0.006822
 50%|█████████████▌             | 200/400 [1:33:07<1:37:51, 29.36s/it]2022-01-14 16:25:49,487 iteration 3401 : loss : 0.035130, loss_ce: 0.015724
2022-01-14 16:25:51,052 iteration 3402 : loss : 0.034062, loss_ce: 0.012847
2022-01-14 16:25:52,688 iteration 3403 : loss : 0.032265, loss_ce: 0.012486
2022-01-14 16:25:54,130 iteration 3404 : loss : 0.020608, loss_ce: 0.006263
2022-01-14 16:25:55,627 iteration 3405 : loss : 0.023034, loss_ce: 0.005655
2022-01-14 16:25:57,053 iteration 3406 : loss : 0.019543, loss_ce: 0.008913
2022-01-14 16:25:58,502 iteration 3407 : loss : 0.021294, loss_ce: 0.007245
2022-01-14 16:26:00,009 iteration 3408 : loss : 0.017125, loss_ce: 0.005975
2022-01-14 16:26:01,538 iteration 3409 : loss : 0.041029, loss_ce: 0.008623
2022-01-14 16:26:03,039 iteration 3410 : loss : 0.021314, loss_ce: 0.007941
2022-01-14 16:26:04,592 iteration 3411 : loss : 0.026434, loss_ce: 0.007884
2022-01-14 16:26:06,170 iteration 3412 : loss : 0.023335, loss_ce: 0.010502
2022-01-14 16:26:07,825 iteration 3413 : loss : 0.026306, loss_ce: 0.012153
2022-01-14 16:26:09,396 iteration 3414 : loss : 0.037841, loss_ce: 0.011383
2022-01-14 16:26:10,779 iteration 3415 : loss : 0.021271, loss_ce: 0.008379
2022-01-14 16:26:12,312 iteration 3416 : loss : 0.037860, loss_ce: 0.018121
2022-01-14 16:26:13,807 iteration 3417 : loss : 0.020272, loss_ce: 0.009316
 50%|█████████████▌             | 201/400 [1:33:33<1:34:00, 28.35s/it]2022-01-14 16:26:15,462 iteration 3418 : loss : 0.036708, loss_ce: 0.011057
2022-01-14 16:26:16,960 iteration 3419 : loss : 0.029152, loss_ce: 0.013887
2022-01-14 16:26:18,432 iteration 3420 : loss : 0.021299, loss_ce: 0.010910
2022-01-14 16:26:19,945 iteration 3421 : loss : 0.032352, loss_ce: 0.008627
2022-01-14 16:26:21,477 iteration 3422 : loss : 0.039353, loss_ce: 0.012293
2022-01-14 16:26:23,056 iteration 3423 : loss : 0.026972, loss_ce: 0.013147
2022-01-14 16:26:24,488 iteration 3424 : loss : 0.019291, loss_ce: 0.006192
2022-01-14 16:26:26,029 iteration 3425 : loss : 0.025575, loss_ce: 0.011453
2022-01-14 16:26:27,522 iteration 3426 : loss : 0.027911, loss_ce: 0.008961
2022-01-14 16:26:29,166 iteration 3427 : loss : 0.035374, loss_ce: 0.011639
2022-01-14 16:26:30,685 iteration 3428 : loss : 0.022174, loss_ce: 0.008142
2022-01-14 16:26:32,201 iteration 3429 : loss : 0.025106, loss_ce: 0.013448
2022-01-14 16:26:33,757 iteration 3430 : loss : 0.019472, loss_ce: 0.006481
2022-01-14 16:26:35,362 iteration 3431 : loss : 0.035242, loss_ce: 0.013905
2022-01-14 16:26:36,838 iteration 3432 : loss : 0.022529, loss_ce: 0.007109
2022-01-14 16:26:38,334 iteration 3433 : loss : 0.037603, loss_ce: 0.010199
2022-01-14 16:26:39,804 iteration 3434 : loss : 0.021237, loss_ce: 0.005754
 50%|█████████████▋             | 202/400 [1:33:59<1:31:12, 27.64s/it]2022-01-14 16:26:41,312 iteration 3435 : loss : 0.028487, loss_ce: 0.012160
2022-01-14 16:26:42,795 iteration 3436 : loss : 0.028138, loss_ce: 0.009845
2022-01-14 16:26:44,276 iteration 3437 : loss : 0.019223, loss_ce: 0.006634
2022-01-14 16:26:45,738 iteration 3438 : loss : 0.025123, loss_ce: 0.012179
2022-01-14 16:26:47,330 iteration 3439 : loss : 0.021326, loss_ce: 0.008812
2022-01-14 16:26:48,904 iteration 3440 : loss : 0.029218, loss_ce: 0.009053
2022-01-14 16:26:50,293 iteration 3441 : loss : 0.017321, loss_ce: 0.008775
2022-01-14 16:26:51,788 iteration 3442 : loss : 0.014920, loss_ce: 0.004398
2022-01-14 16:26:53,367 iteration 3443 : loss : 0.021724, loss_ce: 0.008006
2022-01-14 16:26:54,848 iteration 3444 : loss : 0.018924, loss_ce: 0.006459
2022-01-14 16:26:56,406 iteration 3445 : loss : 0.020583, loss_ce: 0.007138
2022-01-14 16:26:57,897 iteration 3446 : loss : 0.020184, loss_ce: 0.006735
2022-01-14 16:26:59,395 iteration 3447 : loss : 0.022803, loss_ce: 0.012174
2022-01-14 16:27:00,812 iteration 3448 : loss : 0.020773, loss_ce: 0.006998
2022-01-14 16:27:02,321 iteration 3449 : loss : 0.036783, loss_ce: 0.010794
2022-01-14 16:27:03,879 iteration 3450 : loss : 0.026532, loss_ce: 0.009366
2022-01-14 16:27:05,329 iteration 3451 : loss : 0.017308, loss_ce: 0.007094
 51%|█████████████▋             | 203/400 [1:34:25<1:28:40, 27.01s/it]2022-01-14 16:27:06,886 iteration 3452 : loss : 0.016530, loss_ce: 0.005993
2022-01-14 16:27:08,473 iteration 3453 : loss : 0.035446, loss_ce: 0.013454
2022-01-14 16:27:10,058 iteration 3454 : loss : 0.039066, loss_ce: 0.013352
2022-01-14 16:27:11,608 iteration 3455 : loss : 0.028217, loss_ce: 0.011677
2022-01-14 16:27:13,157 iteration 3456 : loss : 0.026459, loss_ce: 0.008091
2022-01-14 16:27:14,674 iteration 3457 : loss : 0.029685, loss_ce: 0.010578
2022-01-14 16:27:16,212 iteration 3458 : loss : 0.019866, loss_ce: 0.009061
2022-01-14 16:27:17,819 iteration 3459 : loss : 0.030360, loss_ce: 0.014767
2022-01-14 16:27:19,365 iteration 3460 : loss : 0.022093, loss_ce: 0.007943
2022-01-14 16:27:20,893 iteration 3461 : loss : 0.022377, loss_ce: 0.009028
2022-01-14 16:27:22,312 iteration 3462 : loss : 0.018533, loss_ce: 0.006394
2022-01-14 16:27:23,711 iteration 3463 : loss : 0.014167, loss_ce: 0.004277
2022-01-14 16:27:25,187 iteration 3464 : loss : 0.019129, loss_ce: 0.007217
2022-01-14 16:27:26,665 iteration 3465 : loss : 0.024481, loss_ce: 0.007105
2022-01-14 16:27:28,218 iteration 3466 : loss : 0.019193, loss_ce: 0.007934
2022-01-14 16:27:29,805 iteration 3467 : loss : 0.034662, loss_ce: 0.013140
2022-01-14 16:27:31,442 iteration 3468 : loss : 0.049304, loss_ce: 0.015666
 51%|█████████████▊             | 204/400 [1:34:51<1:27:20, 26.74s/it]2022-01-14 16:27:32,947 iteration 3469 : loss : 0.022163, loss_ce: 0.008498
2022-01-14 16:27:34,631 iteration 3470 : loss : 0.026423, loss_ce: 0.008257
2022-01-14 16:27:36,144 iteration 3471 : loss : 0.023508, loss_ce: 0.008414
2022-01-14 16:27:37,715 iteration 3472 : loss : 0.020797, loss_ce: 0.008760
2022-01-14 16:27:39,286 iteration 3473 : loss : 0.023698, loss_ce: 0.011575
2022-01-14 16:27:40,806 iteration 3474 : loss : 0.025748, loss_ce: 0.009150
2022-01-14 16:27:42,396 iteration 3475 : loss : 0.028242, loss_ce: 0.011026
2022-01-14 16:27:43,921 iteration 3476 : loss : 0.027632, loss_ce: 0.010760
2022-01-14 16:27:45,512 iteration 3477 : loss : 0.034949, loss_ce: 0.010494
2022-01-14 16:27:47,015 iteration 3478 : loss : 0.022613, loss_ce: 0.006920
2022-01-14 16:27:48,483 iteration 3479 : loss : 0.029746, loss_ce: 0.011894
2022-01-14 16:27:49,950 iteration 3480 : loss : 0.017160, loss_ce: 0.006653
2022-01-14 16:27:51,474 iteration 3481 : loss : 0.023132, loss_ce: 0.012956
2022-01-14 16:27:52,901 iteration 3482 : loss : 0.020060, loss_ce: 0.006375
2022-01-14 16:27:54,487 iteration 3483 : loss : 0.023816, loss_ce: 0.008526
2022-01-14 16:27:56,018 iteration 3484 : loss : 0.024846, loss_ce: 0.006524
2022-01-14 16:27:56,018 Training Data Eval:
2022-01-14 16:28:03,541   Average segmentation loss on training set: 0.0145
2022-01-14 16:28:03,542 Validation Data Eval:
2022-01-14 16:28:06,115   Average segmentation loss on validation set: 0.0766
2022-01-14 16:28:07,610 iteration 3485 : loss : 0.018369, loss_ce: 0.006926
 51%|█████████████▊             | 205/400 [1:35:27<1:36:05, 29.57s/it]2022-01-14 16:28:09,119 iteration 3486 : loss : 0.020128, loss_ce: 0.007001
2022-01-14 16:28:10,592 iteration 3487 : loss : 0.020550, loss_ce: 0.008577
2022-01-14 16:28:12,149 iteration 3488 : loss : 0.027817, loss_ce: 0.015792
2022-01-14 16:28:13,610 iteration 3489 : loss : 0.027348, loss_ce: 0.008976
2022-01-14 16:28:15,224 iteration 3490 : loss : 0.026795, loss_ce: 0.013377
2022-01-14 16:28:16,782 iteration 3491 : loss : 0.028889, loss_ce: 0.013300
2022-01-14 16:28:18,194 iteration 3492 : loss : 0.017623, loss_ce: 0.005010
2022-01-14 16:28:19,815 iteration 3493 : loss : 0.032026, loss_ce: 0.007302
2022-01-14 16:28:21,363 iteration 3494 : loss : 0.022142, loss_ce: 0.011465
2022-01-14 16:28:22,772 iteration 3495 : loss : 0.015920, loss_ce: 0.006491
2022-01-14 16:28:24,330 iteration 3496 : loss : 0.029819, loss_ce: 0.008549
2022-01-14 16:28:25,919 iteration 3497 : loss : 0.027679, loss_ce: 0.010887
2022-01-14 16:28:27,444 iteration 3498 : loss : 0.021189, loss_ce: 0.008613
2022-01-14 16:28:29,042 iteration 3499 : loss : 0.043023, loss_ce: 0.011479
2022-01-14 16:28:30,538 iteration 3500 : loss : 0.022316, loss_ce: 0.006101
2022-01-14 16:28:32,082 iteration 3501 : loss : 0.021140, loss_ce: 0.007898
2022-01-14 16:28:33,601 iteration 3502 : loss : 0.025945, loss_ce: 0.008618
 52%|█████████████▉             | 206/400 [1:35:53<1:32:07, 28.49s/it]2022-01-14 16:28:35,088 iteration 3503 : loss : 0.019348, loss_ce: 0.009921
2022-01-14 16:28:36,650 iteration 3504 : loss : 0.023046, loss_ce: 0.007076
2022-01-14 16:28:38,153 iteration 3505 : loss : 0.027250, loss_ce: 0.013816
2022-01-14 16:28:39,733 iteration 3506 : loss : 0.035160, loss_ce: 0.012741
2022-01-14 16:28:41,204 iteration 3507 : loss : 0.020489, loss_ce: 0.009385
2022-01-14 16:28:42,620 iteration 3508 : loss : 0.025143, loss_ce: 0.007490
2022-01-14 16:28:44,099 iteration 3509 : loss : 0.022401, loss_ce: 0.009904
2022-01-14 16:28:45,709 iteration 3510 : loss : 0.037860, loss_ce: 0.014401
2022-01-14 16:28:47,221 iteration 3511 : loss : 0.025429, loss_ce: 0.010408
2022-01-14 16:28:48,757 iteration 3512 : loss : 0.032207, loss_ce: 0.011017
2022-01-14 16:28:50,234 iteration 3513 : loss : 0.024258, loss_ce: 0.007590
2022-01-14 16:28:51,687 iteration 3514 : loss : 0.015621, loss_ce: 0.006599
2022-01-14 16:28:53,174 iteration 3515 : loss : 0.018826, loss_ce: 0.006435
2022-01-14 16:28:54,703 iteration 3516 : loss : 0.019607, loss_ce: 0.007475
2022-01-14 16:28:56,233 iteration 3517 : loss : 0.021037, loss_ce: 0.008207
2022-01-14 16:28:57,654 iteration 3518 : loss : 0.016775, loss_ce: 0.007115
2022-01-14 16:28:59,101 iteration 3519 : loss : 0.023754, loss_ce: 0.007859
 52%|█████████████▉             | 207/400 [1:36:19<1:28:45, 27.60s/it]2022-01-14 16:29:00,635 iteration 3520 : loss : 0.019207, loss_ce: 0.006573
2022-01-14 16:29:02,180 iteration 3521 : loss : 0.025510, loss_ce: 0.010693
2022-01-14 16:29:03,713 iteration 3522 : loss : 0.023123, loss_ce: 0.008777
2022-01-14 16:29:05,341 iteration 3523 : loss : 0.027063, loss_ce: 0.009077
2022-01-14 16:29:06,809 iteration 3524 : loss : 0.024531, loss_ce: 0.007151
2022-01-14 16:29:08,376 iteration 3525 : loss : 0.037988, loss_ce: 0.015409
2022-01-14 16:29:09,901 iteration 3526 : loss : 0.020538, loss_ce: 0.009431
2022-01-14 16:29:11,450 iteration 3527 : loss : 0.020724, loss_ce: 0.006212
2022-01-14 16:29:12,920 iteration 3528 : loss : 0.018503, loss_ce: 0.008859
2022-01-14 16:29:14,472 iteration 3529 : loss : 0.030487, loss_ce: 0.010607
2022-01-14 16:29:16,009 iteration 3530 : loss : 0.023801, loss_ce: 0.008124
2022-01-14 16:29:17,537 iteration 3531 : loss : 0.021075, loss_ce: 0.008682
2022-01-14 16:29:19,015 iteration 3532 : loss : 0.015371, loss_ce: 0.005038
2022-01-14 16:29:20,456 iteration 3533 : loss : 0.020313, loss_ce: 0.010225
2022-01-14 16:29:21,972 iteration 3534 : loss : 0.025955, loss_ce: 0.014902
2022-01-14 16:29:23,407 iteration 3535 : loss : 0.025181, loss_ce: 0.010916
2022-01-14 16:29:24,855 iteration 3536 : loss : 0.020708, loss_ce: 0.006597
 52%|██████████████             | 208/400 [1:36:44<1:26:32, 27.04s/it]2022-01-14 16:29:26,342 iteration 3537 : loss : 0.019270, loss_ce: 0.007562
2022-01-14 16:29:27,891 iteration 3538 : loss : 0.029563, loss_ce: 0.009805
2022-01-14 16:29:29,473 iteration 3539 : loss : 0.019943, loss_ce: 0.009130
2022-01-14 16:29:30,929 iteration 3540 : loss : 0.023324, loss_ce: 0.006005
2022-01-14 16:29:32,479 iteration 3541 : loss : 0.020059, loss_ce: 0.009761
2022-01-14 16:29:33,956 iteration 3542 : loss : 0.024328, loss_ce: 0.006446
2022-01-14 16:29:35,484 iteration 3543 : loss : 0.022882, loss_ce: 0.011339
2022-01-14 16:29:37,039 iteration 3544 : loss : 0.021322, loss_ce: 0.008473
2022-01-14 16:29:38,498 iteration 3545 : loss : 0.020292, loss_ce: 0.007500
2022-01-14 16:29:39,911 iteration 3546 : loss : 0.021930, loss_ce: 0.010054
2022-01-14 16:29:41,452 iteration 3547 : loss : 0.033760, loss_ce: 0.010640
2022-01-14 16:29:43,023 iteration 3548 : loss : 0.023368, loss_ce: 0.007953
2022-01-14 16:29:44,548 iteration 3549 : loss : 0.027311, loss_ce: 0.010904
2022-01-14 16:29:45,995 iteration 3550 : loss : 0.017785, loss_ce: 0.005872
2022-01-14 16:29:47,601 iteration 3551 : loss : 0.024400, loss_ce: 0.006086
2022-01-14 16:29:49,150 iteration 3552 : loss : 0.026080, loss_ce: 0.010479
2022-01-14 16:29:50,721 iteration 3553 : loss : 0.030221, loss_ce: 0.009660
 52%|██████████████             | 209/400 [1:37:10<1:24:57, 26.69s/it]2022-01-14 16:29:52,250 iteration 3554 : loss : 0.017737, loss_ce: 0.006843
2022-01-14 16:29:53,825 iteration 3555 : loss : 0.023804, loss_ce: 0.009697
2022-01-14 16:29:55,315 iteration 3556 : loss : 0.033055, loss_ce: 0.011452
2022-01-14 16:29:56,795 iteration 3557 : loss : 0.017407, loss_ce: 0.007604
2022-01-14 16:29:58,224 iteration 3558 : loss : 0.017322, loss_ce: 0.005762
2022-01-14 16:29:59,774 iteration 3559 : loss : 0.021534, loss_ce: 0.007911
2022-01-14 16:30:01,322 iteration 3560 : loss : 0.024162, loss_ce: 0.006356
2022-01-14 16:30:02,886 iteration 3561 : loss : 0.018271, loss_ce: 0.008202
2022-01-14 16:30:04,424 iteration 3562 : loss : 0.023338, loss_ce: 0.008649
2022-01-14 16:30:05,925 iteration 3563 : loss : 0.015417, loss_ce: 0.005280
2022-01-14 16:30:07,488 iteration 3564 : loss : 0.019064, loss_ce: 0.006042
2022-01-14 16:30:08,923 iteration 3565 : loss : 0.019909, loss_ce: 0.007761
2022-01-14 16:30:10,308 iteration 3566 : loss : 0.017502, loss_ce: 0.006130
2022-01-14 16:30:11,740 iteration 3567 : loss : 0.024893, loss_ce: 0.007470
2022-01-14 16:30:13,292 iteration 3568 : loss : 0.024247, loss_ce: 0.007619
2022-01-14 16:30:14,757 iteration 3569 : loss : 0.018718, loss_ce: 0.007417
2022-01-14 16:30:14,758 Training Data Eval:
2022-01-14 16:30:22,292   Average segmentation loss on training set: 0.0134
2022-01-14 16:30:22,292 Validation Data Eval:
2022-01-14 16:30:24,867   Average segmentation loss on validation set: 0.0786
2022-01-14 16:30:26,373 iteration 3570 : loss : 0.017804, loss_ce: 0.005675
 52%|██████████████▏            | 210/400 [1:37:46<1:33:02, 29.38s/it]2022-01-14 16:30:27,947 iteration 3571 : loss : 0.024553, loss_ce: 0.009350
2022-01-14 16:30:29,528 iteration 3572 : loss : 0.032805, loss_ce: 0.011363
2022-01-14 16:30:31,066 iteration 3573 : loss : 0.026458, loss_ce: 0.009692
2022-01-14 16:30:32,526 iteration 3574 : loss : 0.020231, loss_ce: 0.010129
2022-01-14 16:30:33,993 iteration 3575 : loss : 0.019621, loss_ce: 0.007421
2022-01-14 16:30:35,485 iteration 3576 : loss : 0.026708, loss_ce: 0.009638
2022-01-14 16:30:37,041 iteration 3577 : loss : 0.020861, loss_ce: 0.009419
2022-01-14 16:30:38,520 iteration 3578 : loss : 0.022297, loss_ce: 0.009101
2022-01-14 16:30:40,085 iteration 3579 : loss : 0.017719, loss_ce: 0.006420
2022-01-14 16:30:41,632 iteration 3580 : loss : 0.022916, loss_ce: 0.010251
2022-01-14 16:30:43,191 iteration 3581 : loss : 0.018287, loss_ce: 0.006637
2022-01-14 16:30:44,727 iteration 3582 : loss : 0.025893, loss_ce: 0.008713
2022-01-14 16:30:46,215 iteration 3583 : loss : 0.032155, loss_ce: 0.008713
2022-01-14 16:30:47,642 iteration 3584 : loss : 0.018360, loss_ce: 0.006701
2022-01-14 16:30:49,151 iteration 3585 : loss : 0.014284, loss_ce: 0.005505
2022-01-14 16:30:50,602 iteration 3586 : loss : 0.013864, loss_ce: 0.004179
2022-01-14 16:30:52,118 iteration 3587 : loss : 0.018505, loss_ce: 0.008155
 53%|██████████████▏            | 211/400 [1:38:12<1:29:06, 28.29s/it]2022-01-14 16:30:53,714 iteration 3588 : loss : 0.019282, loss_ce: 0.007515
2022-01-14 16:30:55,316 iteration 3589 : loss : 0.028377, loss_ce: 0.006965
2022-01-14 16:30:56,832 iteration 3590 : loss : 0.017207, loss_ce: 0.004619
2022-01-14 16:30:58,294 iteration 3591 : loss : 0.016283, loss_ce: 0.005080
2022-01-14 16:30:59,820 iteration 3592 : loss : 0.017638, loss_ce: 0.007336
2022-01-14 16:31:01,359 iteration 3593 : loss : 0.023466, loss_ce: 0.011866
2022-01-14 16:31:02,886 iteration 3594 : loss : 0.020875, loss_ce: 0.006298
2022-01-14 16:31:04,385 iteration 3595 : loss : 0.034401, loss_ce: 0.014879
2022-01-14 16:31:05,837 iteration 3596 : loss : 0.020386, loss_ce: 0.008918
2022-01-14 16:31:07,341 iteration 3597 : loss : 0.016800, loss_ce: 0.006723
2022-01-14 16:31:08,905 iteration 3598 : loss : 0.027204, loss_ce: 0.011449
2022-01-14 16:31:10,435 iteration 3599 : loss : 0.022762, loss_ce: 0.008059
2022-01-14 16:31:11,881 iteration 3600 : loss : 0.018732, loss_ce: 0.010768
2022-01-14 16:31:13,384 iteration 3601 : loss : 0.017917, loss_ce: 0.006494
2022-01-14 16:31:14,959 iteration 3602 : loss : 0.032725, loss_ce: 0.012461
2022-01-14 16:31:16,431 iteration 3603 : loss : 0.021930, loss_ce: 0.010561
2022-01-14 16:31:17,924 iteration 3604 : loss : 0.031185, loss_ce: 0.007022
 53%|██████████████▎            | 212/400 [1:38:38<1:26:18, 27.54s/it]2022-01-14 16:31:19,598 iteration 3605 : loss : 0.046519, loss_ce: 0.017161
2022-01-14 16:31:21,026 iteration 3606 : loss : 0.025868, loss_ce: 0.006651
2022-01-14 16:31:22,424 iteration 3607 : loss : 0.012429, loss_ce: 0.004669
2022-01-14 16:31:24,003 iteration 3608 : loss : 0.033081, loss_ce: 0.010688
2022-01-14 16:31:25,568 iteration 3609 : loss : 0.056750, loss_ce: 0.025360
2022-01-14 16:31:26,997 iteration 3610 : loss : 0.013222, loss_ce: 0.005320
2022-01-14 16:31:28,497 iteration 3611 : loss : 0.022208, loss_ce: 0.008827
2022-01-14 16:31:29,981 iteration 3612 : loss : 0.017669, loss_ce: 0.007245
2022-01-14 16:31:31,513 iteration 3613 : loss : 0.023133, loss_ce: 0.009750
2022-01-14 16:31:32,953 iteration 3614 : loss : 0.020063, loss_ce: 0.007531
2022-01-14 16:31:34,432 iteration 3615 : loss : 0.024231, loss_ce: 0.008065
2022-01-14 16:31:35,909 iteration 3616 : loss : 0.018849, loss_ce: 0.009252
2022-01-14 16:31:37,434 iteration 3617 : loss : 0.018987, loss_ce: 0.008816
2022-01-14 16:31:38,991 iteration 3618 : loss : 0.023486, loss_ce: 0.008200
2022-01-14 16:31:40,489 iteration 3619 : loss : 0.019736, loss_ce: 0.006973
2022-01-14 16:31:42,003 iteration 3620 : loss : 0.023073, loss_ce: 0.007541
2022-01-14 16:31:43,509 iteration 3621 : loss : 0.017379, loss_ce: 0.008109
 53%|██████████████▍            | 213/400 [1:39:03<1:24:00, 26.95s/it]2022-01-14 16:31:45,085 iteration 3622 : loss : 0.025382, loss_ce: 0.008063
2022-01-14 16:31:46,619 iteration 3623 : loss : 0.033502, loss_ce: 0.013273
2022-01-14 16:31:48,128 iteration 3624 : loss : 0.017891, loss_ce: 0.007496
2022-01-14 16:31:49,542 iteration 3625 : loss : 0.016637, loss_ce: 0.006254
2022-01-14 16:31:51,095 iteration 3626 : loss : 0.028383, loss_ce: 0.009418
2022-01-14 16:31:52,646 iteration 3627 : loss : 0.030340, loss_ce: 0.013420
2022-01-14 16:31:54,176 iteration 3628 : loss : 0.030685, loss_ce: 0.010163
2022-01-14 16:31:55,773 iteration 3629 : loss : 0.022409, loss_ce: 0.010044
2022-01-14 16:31:57,282 iteration 3630 : loss : 0.022742, loss_ce: 0.010399
2022-01-14 16:31:58,840 iteration 3631 : loss : 0.018710, loss_ce: 0.006831
2022-01-14 16:32:00,395 iteration 3632 : loss : 0.027297, loss_ce: 0.014752
2022-01-14 16:32:01,936 iteration 3633 : loss : 0.022702, loss_ce: 0.008129
2022-01-14 16:32:03,384 iteration 3634 : loss : 0.017444, loss_ce: 0.005188
2022-01-14 16:32:04,998 iteration 3635 : loss : 0.022737, loss_ce: 0.010752
2022-01-14 16:32:06,415 iteration 3636 : loss : 0.018913, loss_ce: 0.009040
2022-01-14 16:32:07,961 iteration 3637 : loss : 0.019629, loss_ce: 0.007134
2022-01-14 16:32:09,476 iteration 3638 : loss : 0.026591, loss_ce: 0.008566
 54%|██████████████▍            | 214/400 [1:39:29<1:22:38, 26.66s/it]2022-01-14 16:32:11,040 iteration 3639 : loss : 0.031479, loss_ce: 0.011203
2022-01-14 16:32:12,583 iteration 3640 : loss : 0.022079, loss_ce: 0.005953
2022-01-14 16:32:14,129 iteration 3641 : loss : 0.022748, loss_ce: 0.008278
2022-01-14 16:32:15,618 iteration 3642 : loss : 0.023865, loss_ce: 0.010685
2022-01-14 16:32:17,129 iteration 3643 : loss : 0.019466, loss_ce: 0.006118
2022-01-14 16:32:18,655 iteration 3644 : loss : 0.023563, loss_ce: 0.009700
2022-01-14 16:32:20,229 iteration 3645 : loss : 0.031271, loss_ce: 0.008382
2022-01-14 16:32:21,798 iteration 3646 : loss : 0.022460, loss_ce: 0.009842
2022-01-14 16:32:23,284 iteration 3647 : loss : 0.019300, loss_ce: 0.008229
2022-01-14 16:32:24,820 iteration 3648 : loss : 0.023378, loss_ce: 0.009062
2022-01-14 16:32:26,212 iteration 3649 : loss : 0.019186, loss_ce: 0.007333
2022-01-14 16:32:27,736 iteration 3650 : loss : 0.017598, loss_ce: 0.007392
2022-01-14 16:32:29,200 iteration 3651 : loss : 0.018554, loss_ce: 0.006963
2022-01-14 16:32:30,645 iteration 3652 : loss : 0.029218, loss_ce: 0.012448
2022-01-14 16:32:32,232 iteration 3653 : loss : 0.025402, loss_ce: 0.011521
2022-01-14 16:32:33,735 iteration 3654 : loss : 0.019786, loss_ce: 0.007785
2022-01-14 16:32:33,736 Training Data Eval:
2022-01-14 16:32:41,251   Average segmentation loss on training set: 0.0142
2022-01-14 16:32:41,251 Validation Data Eval:
2022-01-14 16:32:43,826   Average segmentation loss on validation set: 0.0704
2022-01-14 16:32:45,521 iteration 3655 : loss : 0.032970, loss_ce: 0.011762
 54%|██████████████▌            | 215/400 [1:40:05<1:30:52, 29.47s/it]2022-01-14 16:32:47,092 iteration 3656 : loss : 0.018043, loss_ce: 0.005607
2022-01-14 16:32:48,636 iteration 3657 : loss : 0.018311, loss_ce: 0.007101
2022-01-14 16:32:50,162 iteration 3658 : loss : 0.032001, loss_ce: 0.012831
2022-01-14 16:32:51,604 iteration 3659 : loss : 0.030960, loss_ce: 0.009589
2022-01-14 16:32:53,204 iteration 3660 : loss : 0.033185, loss_ce: 0.013313
2022-01-14 16:32:54,676 iteration 3661 : loss : 0.021082, loss_ce: 0.008856
2022-01-14 16:32:56,121 iteration 3662 : loss : 0.020184, loss_ce: 0.010013
2022-01-14 16:32:57,595 iteration 3663 : loss : 0.019928, loss_ce: 0.007317
2022-01-14 16:32:59,143 iteration 3664 : loss : 0.031488, loss_ce: 0.008945
2022-01-14 16:33:00,782 iteration 3665 : loss : 0.028033, loss_ce: 0.007764
2022-01-14 16:33:02,341 iteration 3666 : loss : 0.021973, loss_ce: 0.009007
2022-01-14 16:33:03,819 iteration 3667 : loss : 0.019469, loss_ce: 0.007321
2022-01-14 16:33:05,308 iteration 3668 : loss : 0.030871, loss_ce: 0.011003
2022-01-14 16:33:06,848 iteration 3669 : loss : 0.039728, loss_ce: 0.012911
2022-01-14 16:33:08,280 iteration 3670 : loss : 0.023087, loss_ce: 0.012605
2022-01-14 16:33:09,801 iteration 3671 : loss : 0.037316, loss_ce: 0.010462
2022-01-14 16:33:11,279 iteration 3672 : loss : 0.026755, loss_ce: 0.007289
 54%|██████████████▌            | 216/400 [1:40:31<1:26:58, 28.36s/it]2022-01-14 16:33:12,804 iteration 3673 : loss : 0.020685, loss_ce: 0.008597
2022-01-14 16:33:14,399 iteration 3674 : loss : 0.020555, loss_ce: 0.009064
2022-01-14 16:33:16,004 iteration 3675 : loss : 0.026712, loss_ce: 0.010099
2022-01-14 16:33:17,577 iteration 3676 : loss : 0.022516, loss_ce: 0.006727
2022-01-14 16:33:19,106 iteration 3677 : loss : 0.021786, loss_ce: 0.009754
2022-01-14 16:33:20,731 iteration 3678 : loss : 0.040228, loss_ce: 0.011906
2022-01-14 16:33:22,159 iteration 3679 : loss : 0.017426, loss_ce: 0.006239
2022-01-14 16:33:23,630 iteration 3680 : loss : 0.019494, loss_ce: 0.007518
2022-01-14 16:33:25,144 iteration 3681 : loss : 0.021489, loss_ce: 0.007423
2022-01-14 16:33:26,538 iteration 3682 : loss : 0.017631, loss_ce: 0.005443
2022-01-14 16:33:28,034 iteration 3683 : loss : 0.020614, loss_ce: 0.009121
2022-01-14 16:33:29,476 iteration 3684 : loss : 0.027564, loss_ce: 0.011345
2022-01-14 16:33:30,944 iteration 3685 : loss : 0.021376, loss_ce: 0.007122
2022-01-14 16:33:32,524 iteration 3686 : loss : 0.021259, loss_ce: 0.008140
2022-01-14 16:33:34,094 iteration 3687 : loss : 0.026828, loss_ce: 0.009645
2022-01-14 16:33:35,618 iteration 3688 : loss : 0.021140, loss_ce: 0.008608
2022-01-14 16:33:37,161 iteration 3689 : loss : 0.029833, loss_ce: 0.008058
 54%|██████████████▋            | 217/400 [1:40:57<1:24:13, 27.62s/it]2022-01-14 16:33:38,855 iteration 3690 : loss : 0.030655, loss_ce: 0.014935
2022-01-14 16:33:40,351 iteration 3691 : loss : 0.031569, loss_ce: 0.008038
2022-01-14 16:33:41,881 iteration 3692 : loss : 0.038639, loss_ce: 0.012962
2022-01-14 16:33:43,333 iteration 3693 : loss : 0.017131, loss_ce: 0.004557
2022-01-14 16:33:44,855 iteration 3694 : loss : 0.022321, loss_ce: 0.007283
2022-01-14 16:33:46,398 iteration 3695 : loss : 0.021428, loss_ce: 0.007005
2022-01-14 16:33:47,855 iteration 3696 : loss : 0.015304, loss_ce: 0.006016
2022-01-14 16:33:49,340 iteration 3697 : loss : 0.017676, loss_ce: 0.006609
2022-01-14 16:33:50,941 iteration 3698 : loss : 0.040320, loss_ce: 0.011947
2022-01-14 16:33:52,466 iteration 3699 : loss : 0.020478, loss_ce: 0.009829
2022-01-14 16:33:53,940 iteration 3700 : loss : 0.019567, loss_ce: 0.006207
2022-01-14 16:33:55,378 iteration 3701 : loss : 0.023806, loss_ce: 0.012225
2022-01-14 16:33:56,916 iteration 3702 : loss : 0.034582, loss_ce: 0.011807
2022-01-14 16:33:58,434 iteration 3703 : loss : 0.017724, loss_ce: 0.006487
2022-01-14 16:33:59,969 iteration 3704 : loss : 0.029347, loss_ce: 0.009761
2022-01-14 16:34:01,512 iteration 3705 : loss : 0.029398, loss_ce: 0.015188
2022-01-14 16:34:02,952 iteration 3706 : loss : 0.020246, loss_ce: 0.006422
 55%|██████████████▋            | 218/400 [1:41:23<1:22:06, 27.07s/it]2022-01-14 16:34:04,515 iteration 3707 : loss : 0.055439, loss_ce: 0.011130
2022-01-14 16:34:06,115 iteration 3708 : loss : 0.033718, loss_ce: 0.010163
2022-01-14 16:34:07,610 iteration 3709 : loss : 0.018630, loss_ce: 0.005900
2022-01-14 16:34:09,026 iteration 3710 : loss : 0.022668, loss_ce: 0.008076
2022-01-14 16:34:10,707 iteration 3711 : loss : 0.025308, loss_ce: 0.009861
2022-01-14 16:34:12,149 iteration 3712 : loss : 0.023595, loss_ce: 0.008506
2022-01-14 16:34:13,577 iteration 3713 : loss : 0.016109, loss_ce: 0.006123
2022-01-14 16:34:15,141 iteration 3714 : loss : 0.029318, loss_ce: 0.011583
2022-01-14 16:34:16,601 iteration 3715 : loss : 0.020206, loss_ce: 0.007061
2022-01-14 16:34:18,140 iteration 3716 : loss : 0.026934, loss_ce: 0.010200
2022-01-14 16:34:19,656 iteration 3717 : loss : 0.022443, loss_ce: 0.009918
2022-01-14 16:34:21,216 iteration 3718 : loss : 0.027408, loss_ce: 0.010046
2022-01-14 16:34:22,834 iteration 3719 : loss : 0.044606, loss_ce: 0.013718
2022-01-14 16:34:24,429 iteration 3720 : loss : 0.028570, loss_ce: 0.009494
2022-01-14 16:34:25,944 iteration 3721 : loss : 0.023861, loss_ce: 0.009903
2022-01-14 16:34:27,516 iteration 3722 : loss : 0.022357, loss_ce: 0.006539
2022-01-14 16:34:29,003 iteration 3723 : loss : 0.022800, loss_ce: 0.010088
 55%|██████████████▊            | 219/400 [1:41:49<1:20:43, 26.76s/it]2022-01-14 16:34:30,579 iteration 3724 : loss : 0.024965, loss_ce: 0.014159
2022-01-14 16:34:32,146 iteration 3725 : loss : 0.021600, loss_ce: 0.008059
2022-01-14 16:34:33,655 iteration 3726 : loss : 0.019925, loss_ce: 0.008669
2022-01-14 16:34:35,139 iteration 3727 : loss : 0.018056, loss_ce: 0.006856
2022-01-14 16:34:36,537 iteration 3728 : loss : 0.019428, loss_ce: 0.009064
2022-01-14 16:34:38,122 iteration 3729 : loss : 0.032399, loss_ce: 0.009613
2022-01-14 16:34:39,566 iteration 3730 : loss : 0.018962, loss_ce: 0.007313
2022-01-14 16:34:41,165 iteration 3731 : loss : 0.021378, loss_ce: 0.008385
2022-01-14 16:34:42,686 iteration 3732 : loss : 0.021177, loss_ce: 0.010546
2022-01-14 16:34:44,121 iteration 3733 : loss : 0.018075, loss_ce: 0.005204
2022-01-14 16:34:45,654 iteration 3734 : loss : 0.024270, loss_ce: 0.008478
2022-01-14 16:34:47,230 iteration 3735 : loss : 0.025507, loss_ce: 0.008656
2022-01-14 16:34:48,768 iteration 3736 : loss : 0.022119, loss_ce: 0.009102
2022-01-14 16:34:50,335 iteration 3737 : loss : 0.027399, loss_ce: 0.012457
2022-01-14 16:34:51,816 iteration 3738 : loss : 0.031871, loss_ce: 0.009181
2022-01-14 16:34:53,343 iteration 3739 : loss : 0.029519, loss_ce: 0.009236
2022-01-14 16:34:53,343 Training Data Eval:
2022-01-14 16:35:00,835   Average segmentation loss on training set: 0.0136
2022-01-14 16:35:00,836 Validation Data Eval:
2022-01-14 16:35:03,402   Average segmentation loss on validation set: 0.0646
2022-01-14 16:35:04,867 iteration 3740 : loss : 0.022809, loss_ce: 0.007152
 55%|██████████████▊            | 220/400 [1:42:24<1:28:29, 29.49s/it]2022-01-14 16:35:06,459 iteration 3741 : loss : 0.027108, loss_ce: 0.012506
2022-01-14 16:35:07,978 iteration 3742 : loss : 0.017555, loss_ce: 0.006095
2022-01-14 16:35:09,475 iteration 3743 : loss : 0.018560, loss_ce: 0.005291
2022-01-14 16:35:11,023 iteration 3744 : loss : 0.016103, loss_ce: 0.005698
2022-01-14 16:35:12,662 iteration 3745 : loss : 0.030734, loss_ce: 0.016780
2022-01-14 16:35:14,137 iteration 3746 : loss : 0.019573, loss_ce: 0.004989
2022-01-14 16:35:15,675 iteration 3747 : loss : 0.028249, loss_ce: 0.013375
2022-01-14 16:35:17,225 iteration 3748 : loss : 0.038127, loss_ce: 0.012322
2022-01-14 16:35:18,732 iteration 3749 : loss : 0.021589, loss_ce: 0.006017
2022-01-14 16:35:20,373 iteration 3750 : loss : 0.033053, loss_ce: 0.011764
2022-01-14 16:35:21,888 iteration 3751 : loss : 0.025782, loss_ce: 0.012603
2022-01-14 16:35:23,364 iteration 3752 : loss : 0.019503, loss_ce: 0.006968
2022-01-14 16:35:24,885 iteration 3753 : loss : 0.048691, loss_ce: 0.021604
2022-01-14 16:35:26,313 iteration 3754 : loss : 0.015742, loss_ce: 0.007587
2022-01-14 16:35:27,852 iteration 3755 : loss : 0.022486, loss_ce: 0.008626
2022-01-14 16:35:29,355 iteration 3756 : loss : 0.020062, loss_ce: 0.007318
2022-01-14 16:35:30,865 iteration 3757 : loss : 0.021790, loss_ce: 0.008920
 55%|██████████████▉            | 221/400 [1:42:50<1:24:52, 28.45s/it]2022-01-14 16:35:32,479 iteration 3758 : loss : 0.025331, loss_ce: 0.010233
2022-01-14 16:35:34,034 iteration 3759 : loss : 0.021943, loss_ce: 0.008600
2022-01-14 16:35:35,575 iteration 3760 : loss : 0.039710, loss_ce: 0.017859
2022-01-14 16:35:37,106 iteration 3761 : loss : 0.018829, loss_ce: 0.008286
2022-01-14 16:35:38,682 iteration 3762 : loss : 0.027776, loss_ce: 0.010970
2022-01-14 16:35:40,236 iteration 3763 : loss : 0.035953, loss_ce: 0.018755
2022-01-14 16:35:41,726 iteration 3764 : loss : 0.041618, loss_ce: 0.009450
2022-01-14 16:35:43,191 iteration 3765 : loss : 0.026539, loss_ce: 0.010218
2022-01-14 16:35:44,641 iteration 3766 : loss : 0.016930, loss_ce: 0.004965
2022-01-14 16:35:46,142 iteration 3767 : loss : 0.021933, loss_ce: 0.007422
2022-01-14 16:35:47,760 iteration 3768 : loss : 0.021841, loss_ce: 0.008282
2022-01-14 16:35:49,263 iteration 3769 : loss : 0.023058, loss_ce: 0.008461
2022-01-14 16:35:50,819 iteration 3770 : loss : 0.019972, loss_ce: 0.010087
2022-01-14 16:35:52,380 iteration 3771 : loss : 0.019143, loss_ce: 0.008215
2022-01-14 16:35:53,950 iteration 3772 : loss : 0.023268, loss_ce: 0.006786
2022-01-14 16:35:55,461 iteration 3773 : loss : 0.022014, loss_ce: 0.006842
2022-01-14 16:35:56,998 iteration 3774 : loss : 0.029551, loss_ce: 0.014040
 56%|██████████████▉            | 222/400 [1:43:17<1:22:20, 27.75s/it]2022-01-14 16:35:58,613 iteration 3775 : loss : 0.028844, loss_ce: 0.012079
2022-01-14 16:36:00,097 iteration 3776 : loss : 0.017555, loss_ce: 0.006545
2022-01-14 16:36:01,582 iteration 3777 : loss : 0.019671, loss_ce: 0.006439
2022-01-14 16:36:03,174 iteration 3778 : loss : 0.028845, loss_ce: 0.010888
2022-01-14 16:36:04,642 iteration 3779 : loss : 0.020999, loss_ce: 0.007440
2022-01-14 16:36:06,186 iteration 3780 : loss : 0.025600, loss_ce: 0.011767
2022-01-14 16:36:07,737 iteration 3781 : loss : 0.020060, loss_ce: 0.007051
2022-01-14 16:36:09,302 iteration 3782 : loss : 0.033702, loss_ce: 0.013076
2022-01-14 16:36:10,921 iteration 3783 : loss : 0.021771, loss_ce: 0.010245
2022-01-14 16:36:12,365 iteration 3784 : loss : 0.024895, loss_ce: 0.007092
2022-01-14 16:36:13,857 iteration 3785 : loss : 0.034055, loss_ce: 0.009875
2022-01-14 16:36:15,364 iteration 3786 : loss : 0.027617, loss_ce: 0.011973
2022-01-14 16:36:16,794 iteration 3787 : loss : 0.020098, loss_ce: 0.008542
2022-01-14 16:36:18,317 iteration 3788 : loss : 0.030257, loss_ce: 0.012463
2022-01-14 16:36:19,879 iteration 3789 : loss : 0.021112, loss_ce: 0.008379
2022-01-14 16:36:21,396 iteration 3790 : loss : 0.022801, loss_ce: 0.009133
2022-01-14 16:36:22,961 iteration 3791 : loss : 0.025848, loss_ce: 0.009165
 56%|███████████████            | 223/400 [1:43:43<1:20:17, 27.22s/it]2022-01-14 16:36:24,480 iteration 3792 : loss : 0.026385, loss_ce: 0.009313
2022-01-14 16:36:25,895 iteration 3793 : loss : 0.014247, loss_ce: 0.003336
2022-01-14 16:36:27,402 iteration 3794 : loss : 0.018540, loss_ce: 0.007738
2022-01-14 16:36:28,878 iteration 3795 : loss : 0.025080, loss_ce: 0.007083
2022-01-14 16:36:30,425 iteration 3796 : loss : 0.017578, loss_ce: 0.005280
2022-01-14 16:36:31,969 iteration 3797 : loss : 0.019537, loss_ce: 0.006344
2022-01-14 16:36:33,440 iteration 3798 : loss : 0.016178, loss_ce: 0.005812
2022-01-14 16:36:35,052 iteration 3799 : loss : 0.027128, loss_ce: 0.010122
2022-01-14 16:36:36,708 iteration 3800 : loss : 0.039698, loss_ce: 0.018751
2022-01-14 16:36:38,295 iteration 3801 : loss : 0.031557, loss_ce: 0.009154
2022-01-14 16:36:39,864 iteration 3802 : loss : 0.030673, loss_ce: 0.010116
2022-01-14 16:36:41,363 iteration 3803 : loss : 0.021582, loss_ce: 0.007835
2022-01-14 16:36:42,865 iteration 3804 : loss : 0.021125, loss_ce: 0.007251
2022-01-14 16:36:44,409 iteration 3805 : loss : 0.022370, loss_ce: 0.009008
2022-01-14 16:36:45,832 iteration 3806 : loss : 0.017937, loss_ce: 0.007875
2022-01-14 16:36:47,353 iteration 3807 : loss : 0.020393, loss_ce: 0.006734
2022-01-14 16:36:48,857 iteration 3808 : loss : 0.024452, loss_ce: 0.010399
 56%|███████████████            | 224/400 [1:44:08<1:18:40, 26.82s/it]2022-01-14 16:36:50,434 iteration 3809 : loss : 0.020360, loss_ce: 0.008271
2022-01-14 16:36:52,019 iteration 3810 : loss : 0.021559, loss_ce: 0.006891
2022-01-14 16:36:53,498 iteration 3811 : loss : 0.016588, loss_ce: 0.005817
2022-01-14 16:36:55,051 iteration 3812 : loss : 0.037630, loss_ce: 0.016708
2022-01-14 16:36:56,486 iteration 3813 : loss : 0.017779, loss_ce: 0.007428
2022-01-14 16:36:58,071 iteration 3814 : loss : 0.021362, loss_ce: 0.010317
2022-01-14 16:36:59,698 iteration 3815 : loss : 0.021729, loss_ce: 0.007451
2022-01-14 16:37:01,162 iteration 3816 : loss : 0.014899, loss_ce: 0.005306
2022-01-14 16:37:02,538 iteration 3817 : loss : 0.015588, loss_ce: 0.005210
2022-01-14 16:37:04,032 iteration 3818 : loss : 0.018455, loss_ce: 0.005783
2022-01-14 16:37:05,600 iteration 3819 : loss : 0.033734, loss_ce: 0.013795
2022-01-14 16:37:07,024 iteration 3820 : loss : 0.014868, loss_ce: 0.006394
2022-01-14 16:37:08,610 iteration 3821 : loss : 0.019495, loss_ce: 0.008485
2022-01-14 16:37:10,093 iteration 3822 : loss : 0.032092, loss_ce: 0.008773
2022-01-14 16:37:11,576 iteration 3823 : loss : 0.025271, loss_ce: 0.008140
2022-01-14 16:37:13,129 iteration 3824 : loss : 0.023878, loss_ce: 0.009581
2022-01-14 16:37:13,129 Training Data Eval:
2022-01-14 16:37:20,635   Average segmentation loss on training set: 0.0140
2022-01-14 16:37:20,635 Validation Data Eval:
2022-01-14 16:37:23,201   Average segmentation loss on validation set: 0.0732
2022-01-14 16:37:24,630 iteration 3825 : loss : 0.027640, loss_ce: 0.009439
 56%|███████████████▏           | 225/400 [1:44:44<1:26:03, 29.51s/it]2022-01-14 16:37:26,290 iteration 3826 : loss : 0.025995, loss_ce: 0.011891
2022-01-14 16:37:27,920 iteration 3827 : loss : 0.024597, loss_ce: 0.011373
2022-01-14 16:37:29,390 iteration 3828 : loss : 0.017202, loss_ce: 0.008637
2022-01-14 16:37:30,869 iteration 3829 : loss : 0.015876, loss_ce: 0.006288
2022-01-14 16:37:32,467 iteration 3830 : loss : 0.025179, loss_ce: 0.008471
2022-01-14 16:37:34,052 iteration 3831 : loss : 0.023090, loss_ce: 0.009025
2022-01-14 16:37:35,592 iteration 3832 : loss : 0.022070, loss_ce: 0.009830
2022-01-14 16:37:37,126 iteration 3833 : loss : 0.042002, loss_ce: 0.015878
2022-01-14 16:37:38,585 iteration 3834 : loss : 0.020022, loss_ce: 0.006230
2022-01-14 16:37:40,109 iteration 3835 : loss : 0.031647, loss_ce: 0.008225
2022-01-14 16:37:41,552 iteration 3836 : loss : 0.019804, loss_ce: 0.010124
2022-01-14 16:37:42,962 iteration 3837 : loss : 0.018008, loss_ce: 0.007448
2022-01-14 16:37:44,528 iteration 3838 : loss : 0.018801, loss_ce: 0.007672
2022-01-14 16:37:45,999 iteration 3839 : loss : 0.019729, loss_ce: 0.005813
2022-01-14 16:37:47,532 iteration 3840 : loss : 0.019465, loss_ce: 0.009023
2022-01-14 16:37:48,946 iteration 3841 : loss : 0.017783, loss_ce: 0.007240
2022-01-14 16:37:50,479 iteration 3842 : loss : 0.059493, loss_ce: 0.009737
 56%|███████████████▎           | 226/400 [1:45:10<1:22:23, 28.41s/it]2022-01-14 16:37:52,010 iteration 3843 : loss : 0.020245, loss_ce: 0.006315
2022-01-14 16:37:53,560 iteration 3844 : loss : 0.025999, loss_ce: 0.010386
2022-01-14 16:37:54,968 iteration 3845 : loss : 0.022651, loss_ce: 0.008281
2022-01-14 16:37:56,474 iteration 3846 : loss : 0.027709, loss_ce: 0.010538
2022-01-14 16:37:58,111 iteration 3847 : loss : 0.045172, loss_ce: 0.017041
2022-01-14 16:37:59,595 iteration 3848 : loss : 0.026397, loss_ce: 0.009398
2022-01-14 16:38:01,061 iteration 3849 : loss : 0.017893, loss_ce: 0.006626
2022-01-14 16:38:02,637 iteration 3850 : loss : 0.033054, loss_ce: 0.009173
2022-01-14 16:38:04,219 iteration 3851 : loss : 0.035223, loss_ce: 0.009856
2022-01-14 16:38:05,770 iteration 3852 : loss : 0.033388, loss_ce: 0.012881
2022-01-14 16:38:07,289 iteration 3853 : loss : 0.019390, loss_ce: 0.007120
2022-01-14 16:38:08,722 iteration 3854 : loss : 0.015947, loss_ce: 0.005996
2022-01-14 16:38:10,218 iteration 3855 : loss : 0.021144, loss_ce: 0.005246
2022-01-14 16:38:11,863 iteration 3856 : loss : 0.028803, loss_ce: 0.012230
2022-01-14 16:38:13,329 iteration 3857 : loss : 0.031403, loss_ce: 0.009219
2022-01-14 16:38:14,826 iteration 3858 : loss : 0.020511, loss_ce: 0.008627
2022-01-14 16:38:16,303 iteration 3859 : loss : 0.021163, loss_ce: 0.008726
 57%|███████████████▎           | 227/400 [1:45:36<1:19:40, 27.63s/it]2022-01-14 16:38:17,814 iteration 3860 : loss : 0.017200, loss_ce: 0.007680
2022-01-14 16:38:19,274 iteration 3861 : loss : 0.021533, loss_ce: 0.008851
2022-01-14 16:38:20,724 iteration 3862 : loss : 0.023963, loss_ce: 0.006456
2022-01-14 16:38:22,227 iteration 3863 : loss : 0.022140, loss_ce: 0.009620
2022-01-14 16:38:23,664 iteration 3864 : loss : 0.017366, loss_ce: 0.006116
2022-01-14 16:38:25,189 iteration 3865 : loss : 0.016930, loss_ce: 0.006938
2022-01-14 16:38:26,674 iteration 3866 : loss : 0.021675, loss_ce: 0.010430
2022-01-14 16:38:28,239 iteration 3867 : loss : 0.023995, loss_ce: 0.009236
2022-01-14 16:38:29,677 iteration 3868 : loss : 0.019693, loss_ce: 0.008752
2022-01-14 16:38:31,292 iteration 3869 : loss : 0.024743, loss_ce: 0.005902
2022-01-14 16:38:32,760 iteration 3870 : loss : 0.024016, loss_ce: 0.008071
2022-01-14 16:38:34,317 iteration 3871 : loss : 0.019495, loss_ce: 0.006445
2022-01-14 16:38:35,789 iteration 3872 : loss : 0.018471, loss_ce: 0.006169
2022-01-14 16:38:37,283 iteration 3873 : loss : 0.019020, loss_ce: 0.005297
2022-01-14 16:38:38,839 iteration 3874 : loss : 0.024060, loss_ce: 0.008885
2022-01-14 16:38:40,373 iteration 3875 : loss : 0.017964, loss_ce: 0.005677
2022-01-14 16:38:41,976 iteration 3876 : loss : 0.021732, loss_ce: 0.008476
 57%|███████████████▍           | 228/400 [1:46:02<1:17:31, 27.05s/it]2022-01-14 16:38:43,492 iteration 3877 : loss : 0.015719, loss_ce: 0.006200
2022-01-14 16:38:45,051 iteration 3878 : loss : 0.023708, loss_ce: 0.009981
2022-01-14 16:38:46,616 iteration 3879 : loss : 0.018992, loss_ce: 0.009401
2022-01-14 16:38:48,106 iteration 3880 : loss : 0.017405, loss_ce: 0.006427
2022-01-14 16:38:49,624 iteration 3881 : loss : 0.024651, loss_ce: 0.007375
2022-01-14 16:38:51,169 iteration 3882 : loss : 0.016242, loss_ce: 0.007360
2022-01-14 16:38:52,678 iteration 3883 : loss : 0.019898, loss_ce: 0.007188
2022-01-14 16:38:54,227 iteration 3884 : loss : 0.020223, loss_ce: 0.008041
2022-01-14 16:38:55,695 iteration 3885 : loss : 0.017256, loss_ce: 0.005301
2022-01-14 16:38:57,244 iteration 3886 : loss : 0.022417, loss_ce: 0.009649
2022-01-14 16:38:58,752 iteration 3887 : loss : 0.023364, loss_ce: 0.009688
2022-01-14 16:39:00,323 iteration 3888 : loss : 0.021441, loss_ce: 0.011085
2022-01-14 16:39:01,794 iteration 3889 : loss : 0.022148, loss_ce: 0.006757
2022-01-14 16:39:03,289 iteration 3890 : loss : 0.016452, loss_ce: 0.005816
2022-01-14 16:39:04,840 iteration 3891 : loss : 0.043646, loss_ce: 0.019755
2022-01-14 16:39:06,378 iteration 3892 : loss : 0.022203, loss_ce: 0.007384
2022-01-14 16:39:07,835 iteration 3893 : loss : 0.024237, loss_ce: 0.006515
 57%|███████████████▍           | 229/400 [1:46:27<1:16:03, 26.69s/it]2022-01-14 16:39:09,414 iteration 3894 : loss : 0.023413, loss_ce: 0.009421
2022-01-14 16:39:10,976 iteration 3895 : loss : 0.018493, loss_ce: 0.008646
2022-01-14 16:39:12,438 iteration 3896 : loss : 0.014420, loss_ce: 0.005916
2022-01-14 16:39:14,018 iteration 3897 : loss : 0.016034, loss_ce: 0.005040
2022-01-14 16:39:15,542 iteration 3898 : loss : 0.027040, loss_ce: 0.006479
2022-01-14 16:39:17,050 iteration 3899 : loss : 0.015051, loss_ce: 0.005214
2022-01-14 16:39:18,648 iteration 3900 : loss : 0.016048, loss_ce: 0.006950
2022-01-14 16:39:20,054 iteration 3901 : loss : 0.016050, loss_ce: 0.007919
2022-01-14 16:39:21,571 iteration 3902 : loss : 0.014563, loss_ce: 0.005067
2022-01-14 16:39:23,045 iteration 3903 : loss : 0.016693, loss_ce: 0.005227
2022-01-14 16:39:24,566 iteration 3904 : loss : 0.018465, loss_ce: 0.007024
2022-01-14 16:39:26,060 iteration 3905 : loss : 0.028185, loss_ce: 0.015801
2022-01-14 16:39:27,555 iteration 3906 : loss : 0.021343, loss_ce: 0.006996
2022-01-14 16:39:29,067 iteration 3907 : loss : 0.020913, loss_ce: 0.006149
2022-01-14 16:39:30,469 iteration 3908 : loss : 0.022388, loss_ce: 0.007402
2022-01-14 16:39:31,885 iteration 3909 : loss : 0.023599, loss_ce: 0.009496
2022-01-14 16:39:31,885 Training Data Eval:
2022-01-14 16:39:39,415   Average segmentation loss on training set: 0.0152
2022-01-14 16:39:39,416 Validation Data Eval:
2022-01-14 16:39:41,992   Average segmentation loss on validation set: 0.0679
2022-01-14 16:39:43,503 iteration 3910 : loss : 0.022330, loss_ce: 0.009163
 57%|███████████████▌           | 230/400 [1:47:03<1:23:14, 29.38s/it]2022-01-14 16:39:44,971 iteration 3911 : loss : 0.016421, loss_ce: 0.007011
2022-01-14 16:39:46,466 iteration 3912 : loss : 0.026151, loss_ce: 0.008344
2022-01-14 16:39:48,037 iteration 3913 : loss : 0.025375, loss_ce: 0.011853
2022-01-14 16:39:49,442 iteration 3914 : loss : 0.014303, loss_ce: 0.006326
2022-01-14 16:39:50,995 iteration 3915 : loss : 0.026413, loss_ce: 0.008794
2022-01-14 16:39:52,539 iteration 3916 : loss : 0.018397, loss_ce: 0.007055
2022-01-14 16:39:54,085 iteration 3917 : loss : 0.018706, loss_ce: 0.006450
2022-01-14 16:39:55,582 iteration 3918 : loss : 0.018751, loss_ce: 0.006135
2022-01-14 16:39:57,115 iteration 3919 : loss : 0.019182, loss_ce: 0.005963
2022-01-14 16:39:58,676 iteration 3920 : loss : 0.023703, loss_ce: 0.005212
2022-01-14 16:40:00,209 iteration 3921 : loss : 0.016781, loss_ce: 0.005091
2022-01-14 16:40:01,756 iteration 3922 : loss : 0.032969, loss_ce: 0.008323
2022-01-14 16:40:03,357 iteration 3923 : loss : 0.031072, loss_ce: 0.012639
2022-01-14 16:40:04,833 iteration 3924 : loss : 0.018598, loss_ce: 0.006464
2022-01-14 16:40:06,246 iteration 3925 : loss : 0.017588, loss_ce: 0.007720
2022-01-14 16:40:07,907 iteration 3926 : loss : 0.022440, loss_ce: 0.009592
2022-01-14 16:40:09,425 iteration 3927 : loss : 0.029533, loss_ce: 0.013829
 58%|███████████████▌           | 231/400 [1:47:29<1:19:50, 28.34s/it]2022-01-14 16:40:10,956 iteration 3928 : loss : 0.022183, loss_ce: 0.009763
2022-01-14 16:40:12,450 iteration 3929 : loss : 0.021437, loss_ce: 0.012884
2022-01-14 16:40:13,940 iteration 3930 : loss : 0.018640, loss_ce: 0.005281
2022-01-14 16:40:15,377 iteration 3931 : loss : 0.018075, loss_ce: 0.003860
2022-01-14 16:40:16,922 iteration 3932 : loss : 0.020345, loss_ce: 0.006650
2022-01-14 16:40:18,407 iteration 3933 : loss : 0.021344, loss_ce: 0.009373
2022-01-14 16:40:19,965 iteration 3934 : loss : 0.026832, loss_ce: 0.010678
2022-01-14 16:40:21,462 iteration 3935 : loss : 0.033654, loss_ce: 0.012855
2022-01-14 16:40:22,903 iteration 3936 : loss : 0.016094, loss_ce: 0.004970
2022-01-14 16:40:24,452 iteration 3937 : loss : 0.024538, loss_ce: 0.007127
2022-01-14 16:40:25,948 iteration 3938 : loss : 0.022168, loss_ce: 0.006377
2022-01-14 16:40:27,490 iteration 3939 : loss : 0.036068, loss_ce: 0.007825
2022-01-14 16:40:28,964 iteration 3940 : loss : 0.018900, loss_ce: 0.008710
2022-01-14 16:40:30,447 iteration 3941 : loss : 0.016126, loss_ce: 0.004892
2022-01-14 16:40:31,923 iteration 3942 : loss : 0.022104, loss_ce: 0.010849
2022-01-14 16:40:33,407 iteration 3943 : loss : 0.021036, loss_ce: 0.007978
2022-01-14 16:40:34,891 iteration 3944 : loss : 0.045939, loss_ce: 0.016011
 58%|███████████████▋           | 232/400 [1:47:54<1:16:57, 27.48s/it]2022-01-14 16:40:36,521 iteration 3945 : loss : 0.018806, loss_ce: 0.005968
2022-01-14 16:40:38,037 iteration 3946 : loss : 0.019361, loss_ce: 0.007073
2022-01-14 16:40:39,482 iteration 3947 : loss : 0.018469, loss_ce: 0.007394
2022-01-14 16:40:40,987 iteration 3948 : loss : 0.027710, loss_ce: 0.012000
2022-01-14 16:40:42,543 iteration 3949 : loss : 0.027635, loss_ce: 0.007784
2022-01-14 16:40:44,018 iteration 3950 : loss : 0.015938, loss_ce: 0.007605
2022-01-14 16:40:45,470 iteration 3951 : loss : 0.019140, loss_ce: 0.004346
2022-01-14 16:40:47,140 iteration 3952 : loss : 0.026705, loss_ce: 0.011831
2022-01-14 16:40:48,664 iteration 3953 : loss : 0.018520, loss_ce: 0.007834
2022-01-14 16:40:50,128 iteration 3954 : loss : 0.016502, loss_ce: 0.006177
2022-01-14 16:40:51,670 iteration 3955 : loss : 0.020760, loss_ce: 0.008370
2022-01-14 16:40:53,216 iteration 3956 : loss : 0.026673, loss_ce: 0.013530
2022-01-14 16:40:54,796 iteration 3957 : loss : 0.041096, loss_ce: 0.014431
2022-01-14 16:40:56,365 iteration 3958 : loss : 0.027792, loss_ce: 0.013620
2022-01-14 16:40:57,760 iteration 3959 : loss : 0.017304, loss_ce: 0.004552
2022-01-14 16:40:59,302 iteration 3960 : loss : 0.020732, loss_ce: 0.007450
2022-01-14 16:41:00,787 iteration 3961 : loss : 0.019389, loss_ce: 0.005593
 58%|███████████████▋           | 233/400 [1:48:20<1:15:09, 27.01s/it]2022-01-14 16:41:02,397 iteration 3962 : loss : 0.028766, loss_ce: 0.012541
2022-01-14 16:41:03,989 iteration 3963 : loss : 0.027975, loss_ce: 0.011334
2022-01-14 16:41:05,426 iteration 3964 : loss : 0.015903, loss_ce: 0.004799
2022-01-14 16:41:06,984 iteration 3965 : loss : 0.019516, loss_ce: 0.008909
2022-01-14 16:41:08,598 iteration 3966 : loss : 0.023771, loss_ce: 0.010762
2022-01-14 16:41:10,111 iteration 3967 : loss : 0.026302, loss_ce: 0.005843
2022-01-14 16:41:11,611 iteration 3968 : loss : 0.015478, loss_ce: 0.005141
2022-01-14 16:41:13,065 iteration 3969 : loss : 0.021255, loss_ce: 0.007006
2022-01-14 16:41:14,558 iteration 3970 : loss : 0.027016, loss_ce: 0.006594
2022-01-14 16:41:16,037 iteration 3971 : loss : 0.018407, loss_ce: 0.005470
2022-01-14 16:41:17,553 iteration 3972 : loss : 0.024085, loss_ce: 0.008737
2022-01-14 16:41:19,123 iteration 3973 : loss : 0.027553, loss_ce: 0.012379
2022-01-14 16:41:20,694 iteration 3974 : loss : 0.024065, loss_ce: 0.010350
2022-01-14 16:41:22,182 iteration 3975 : loss : 0.030009, loss_ce: 0.007439
2022-01-14 16:41:23,658 iteration 3976 : loss : 0.017674, loss_ce: 0.006231
2022-01-14 16:41:25,200 iteration 3977 : loss : 0.021044, loss_ce: 0.009742
2022-01-14 16:41:26,687 iteration 3978 : loss : 0.019039, loss_ce: 0.008153
 58%|███████████████▊           | 234/400 [1:48:46<1:13:47, 26.67s/it]2022-01-14 16:41:28,326 iteration 3979 : loss : 0.022664, loss_ce: 0.009750
2022-01-14 16:41:29,761 iteration 3980 : loss : 0.020658, loss_ce: 0.007782
2022-01-14 16:41:31,274 iteration 3981 : loss : 0.028171, loss_ce: 0.007601
2022-01-14 16:41:32,790 iteration 3982 : loss : 0.021424, loss_ce: 0.008746
2022-01-14 16:41:34,317 iteration 3983 : loss : 0.030953, loss_ce: 0.007442
2022-01-14 16:41:35,856 iteration 3984 : loss : 0.024876, loss_ce: 0.010980
2022-01-14 16:41:37,413 iteration 3985 : loss : 0.032666, loss_ce: 0.008428
2022-01-14 16:41:38,990 iteration 3986 : loss : 0.031549, loss_ce: 0.013934
2022-01-14 16:41:40,463 iteration 3987 : loss : 0.020636, loss_ce: 0.008916
2022-01-14 16:41:41,951 iteration 3988 : loss : 0.021757, loss_ce: 0.007818
2022-01-14 16:41:43,478 iteration 3989 : loss : 0.024474, loss_ce: 0.009423
2022-01-14 16:41:44,998 iteration 3990 : loss : 0.021572, loss_ce: 0.010091
2022-01-14 16:41:46,540 iteration 3991 : loss : 0.036146, loss_ce: 0.018859
2022-01-14 16:41:48,085 iteration 3992 : loss : 0.020277, loss_ce: 0.007873
2022-01-14 16:41:49,568 iteration 3993 : loss : 0.020301, loss_ce: 0.007893
2022-01-14 16:41:51,152 iteration 3994 : loss : 0.017001, loss_ce: 0.005280
2022-01-14 16:41:51,153 Training Data Eval:
2022-01-14 16:41:58,680   Average segmentation loss on training set: 0.0136
2022-01-14 16:41:58,681 Validation Data Eval:
2022-01-14 16:42:01,260   Average segmentation loss on validation set: 0.0695
2022-01-14 16:42:02,879 iteration 3995 : loss : 0.030219, loss_ce: 0.009573
 59%|███████████████▊           | 235/400 [1:49:22<1:21:11, 29.53s/it]2022-01-14 16:42:04,436 iteration 3996 : loss : 0.021732, loss_ce: 0.010425
2022-01-14 16:42:05,888 iteration 3997 : loss : 0.022860, loss_ce: 0.009436
2022-01-14 16:42:07,337 iteration 3998 : loss : 0.019447, loss_ce: 0.005370
2022-01-14 16:42:08,921 iteration 3999 : loss : 0.032510, loss_ce: 0.009938
2022-01-14 16:42:10,460 iteration 4000 : loss : 0.017271, loss_ce: 0.007126
2022-01-14 16:42:11,989 iteration 4001 : loss : 0.019463, loss_ce: 0.010819
2022-01-14 16:42:13,383 iteration 4002 : loss : 0.017422, loss_ce: 0.006001
2022-01-14 16:42:14,968 iteration 4003 : loss : 0.020340, loss_ce: 0.006402
2022-01-14 16:42:16,520 iteration 4004 : loss : 0.023791, loss_ce: 0.009703
2022-01-14 16:42:18,050 iteration 4005 : loss : 0.016975, loss_ce: 0.006837
2022-01-14 16:42:19,491 iteration 4006 : loss : 0.019918, loss_ce: 0.007166
2022-01-14 16:42:21,035 iteration 4007 : loss : 0.022147, loss_ce: 0.007130
2022-01-14 16:42:22,514 iteration 4008 : loss : 0.015444, loss_ce: 0.006616
2022-01-14 16:42:24,027 iteration 4009 : loss : 0.014342, loss_ce: 0.004813
2022-01-14 16:42:25,555 iteration 4010 : loss : 0.019915, loss_ce: 0.009730
2022-01-14 16:42:27,007 iteration 4011 : loss : 0.022209, loss_ce: 0.007743
2022-01-14 16:42:28,555 iteration 4012 : loss : 0.019008, loss_ce: 0.007544
 59%|███████████████▉           | 236/400 [1:49:48<1:17:33, 28.37s/it]2022-01-14 16:42:29,972 iteration 4013 : loss : 0.013890, loss_ce: 0.006608
2022-01-14 16:42:31,588 iteration 4014 : loss : 0.025092, loss_ce: 0.011489
2022-01-14 16:42:33,018 iteration 4015 : loss : 0.015291, loss_ce: 0.006803
2022-01-14 16:42:34,571 iteration 4016 : loss : 0.018985, loss_ce: 0.006996
2022-01-14 16:42:36,082 iteration 4017 : loss : 0.026459, loss_ce: 0.007139
2022-01-14 16:42:37,502 iteration 4018 : loss : 0.022016, loss_ce: 0.007797
2022-01-14 16:42:39,030 iteration 4019 : loss : 0.019534, loss_ce: 0.005880
2022-01-14 16:42:40,490 iteration 4020 : loss : 0.015344, loss_ce: 0.004482
2022-01-14 16:42:42,048 iteration 4021 : loss : 0.024210, loss_ce: 0.007369
2022-01-14 16:42:43,639 iteration 4022 : loss : 0.031040, loss_ce: 0.009014
2022-01-14 16:42:45,073 iteration 4023 : loss : 0.015156, loss_ce: 0.006916
2022-01-14 16:42:46,621 iteration 4024 : loss : 0.026295, loss_ce: 0.009796
2022-01-14 16:42:48,138 iteration 4025 : loss : 0.021940, loss_ce: 0.007238
2022-01-14 16:42:49,692 iteration 4026 : loss : 0.026431, loss_ce: 0.007878
2022-01-14 16:42:51,112 iteration 4027 : loss : 0.018385, loss_ce: 0.005750
2022-01-14 16:42:52,776 iteration 4028 : loss : 0.021936, loss_ce: 0.010133
2022-01-14 16:42:54,410 iteration 4029 : loss : 0.023928, loss_ce: 0.009642
 59%|███████████████▉           | 237/400 [1:50:14<1:15:02, 27.62s/it]2022-01-14 16:42:55,940 iteration 4030 : loss : 0.013799, loss_ce: 0.005021
2022-01-14 16:42:57,425 iteration 4031 : loss : 0.023101, loss_ce: 0.012611
2022-01-14 16:42:58,851 iteration 4032 : loss : 0.015292, loss_ce: 0.004643
2022-01-14 16:43:00,301 iteration 4033 : loss : 0.016532, loss_ce: 0.006420
2022-01-14 16:43:01,879 iteration 4034 : loss : 0.018401, loss_ce: 0.007260
2022-01-14 16:43:03,391 iteration 4035 : loss : 0.037902, loss_ce: 0.012667
2022-01-14 16:43:04,894 iteration 4036 : loss : 0.018116, loss_ce: 0.008134
2022-01-14 16:43:06,375 iteration 4037 : loss : 0.017084, loss_ce: 0.008754
2022-01-14 16:43:07,906 iteration 4038 : loss : 0.019554, loss_ce: 0.008169
2022-01-14 16:43:09,458 iteration 4039 : loss : 0.025460, loss_ce: 0.007874
2022-01-14 16:43:10,917 iteration 4040 : loss : 0.023633, loss_ce: 0.006879
2022-01-14 16:43:12,483 iteration 4041 : loss : 0.018754, loss_ce: 0.007154
2022-01-14 16:43:14,048 iteration 4042 : loss : 0.027184, loss_ce: 0.009661
2022-01-14 16:43:15,567 iteration 4043 : loss : 0.017870, loss_ce: 0.007757
2022-01-14 16:43:17,066 iteration 4044 : loss : 0.023283, loss_ce: 0.010219
2022-01-14 16:43:18,600 iteration 4045 : loss : 0.023072, loss_ce: 0.006683
2022-01-14 16:43:20,190 iteration 4046 : loss : 0.022447, loss_ce: 0.007844
 60%|████████████████           | 238/400 [1:50:40<1:13:04, 27.06s/it]2022-01-14 16:43:21,774 iteration 4047 : loss : 0.017020, loss_ce: 0.006358
2022-01-14 16:43:23,254 iteration 4048 : loss : 0.023639, loss_ce: 0.007064
2022-01-14 16:43:24,764 iteration 4049 : loss : 0.017233, loss_ce: 0.004705
2022-01-14 16:43:26,215 iteration 4050 : loss : 0.018782, loss_ce: 0.006180
2022-01-14 16:43:27,674 iteration 4051 : loss : 0.018350, loss_ce: 0.008613
2022-01-14 16:43:29,135 iteration 4052 : loss : 0.015364, loss_ce: 0.005899
2022-01-14 16:43:30,647 iteration 4053 : loss : 0.027705, loss_ce: 0.006793
2022-01-14 16:43:32,206 iteration 4054 : loss : 0.019445, loss_ce: 0.008329
2022-01-14 16:43:33,705 iteration 4055 : loss : 0.015145, loss_ce: 0.006529
2022-01-14 16:43:35,237 iteration 4056 : loss : 0.017040, loss_ce: 0.007516
2022-01-14 16:43:36,694 iteration 4057 : loss : 0.019341, loss_ce: 0.005336
2022-01-14 16:43:38,158 iteration 4058 : loss : 0.015370, loss_ce: 0.005922
2022-01-14 16:43:39,707 iteration 4059 : loss : 0.021916, loss_ce: 0.008414
2022-01-14 16:43:41,190 iteration 4060 : loss : 0.018351, loss_ce: 0.007812
2022-01-14 16:43:42,590 iteration 4061 : loss : 0.019949, loss_ce: 0.009642
2022-01-14 16:43:44,059 iteration 4062 : loss : 0.014708, loss_ce: 0.006260
2022-01-14 16:43:45,612 iteration 4063 : loss : 0.017071, loss_ce: 0.005718
 60%|████████████████▏          | 239/400 [1:51:05<1:11:18, 26.57s/it]2022-01-14 16:43:47,131 iteration 4064 : loss : 0.016396, loss_ce: 0.006553
2022-01-14 16:43:48,582 iteration 4065 : loss : 0.017160, loss_ce: 0.004483
2022-01-14 16:43:50,056 iteration 4066 : loss : 0.017266, loss_ce: 0.006273
2022-01-14 16:43:51,570 iteration 4067 : loss : 0.023965, loss_ce: 0.008850
2022-01-14 16:43:53,113 iteration 4068 : loss : 0.032667, loss_ce: 0.013918
2022-01-14 16:43:54,632 iteration 4069 : loss : 0.029047, loss_ce: 0.014418
2022-01-14 16:43:56,089 iteration 4070 : loss : 0.018582, loss_ce: 0.005376
2022-01-14 16:43:57,596 iteration 4071 : loss : 0.017594, loss_ce: 0.006553
2022-01-14 16:43:59,131 iteration 4072 : loss : 0.017955, loss_ce: 0.006829
2022-01-14 16:44:00,633 iteration 4073 : loss : 0.024778, loss_ce: 0.009322
2022-01-14 16:44:02,142 iteration 4074 : loss : 0.021105, loss_ce: 0.008087
2022-01-14 16:44:03,747 iteration 4075 : loss : 0.021382, loss_ce: 0.006627
2022-01-14 16:44:05,307 iteration 4076 : loss : 0.013644, loss_ce: 0.005497
2022-01-14 16:44:06,927 iteration 4077 : loss : 0.021597, loss_ce: 0.009105
2022-01-14 16:44:08,530 iteration 4078 : loss : 0.018178, loss_ce: 0.006414
2022-01-14 16:44:10,002 iteration 4079 : loss : 0.018486, loss_ce: 0.007259
2022-01-14 16:44:10,002 Training Data Eval:
2022-01-14 16:44:17,506   Average segmentation loss on training set: 0.0125
2022-01-14 16:44:17,507 Validation Data Eval:
2022-01-14 16:44:20,086   Average segmentation loss on validation set: 0.0692
2022-01-14 16:44:21,681 iteration 4080 : loss : 0.023762, loss_ce: 0.008758
 60%|████████████████▏          | 240/400 [1:51:41<1:18:27, 29.42s/it]2022-01-14 16:44:23,200 iteration 4081 : loss : 0.014827, loss_ce: 0.006171
2022-01-14 16:44:24,702 iteration 4082 : loss : 0.023855, loss_ce: 0.008274
2022-01-14 16:44:26,209 iteration 4083 : loss : 0.015681, loss_ce: 0.006478
2022-01-14 16:44:27,770 iteration 4084 : loss : 0.026217, loss_ce: 0.007847
2022-01-14 16:44:29,358 iteration 4085 : loss : 0.022160, loss_ce: 0.006426
2022-01-14 16:44:30,959 iteration 4086 : loss : 0.022151, loss_ce: 0.011322
2022-01-14 16:44:32,433 iteration 4087 : loss : 0.026603, loss_ce: 0.007366
2022-01-14 16:44:33,935 iteration 4088 : loss : 0.018083, loss_ce: 0.007269
2022-01-14 16:44:35,467 iteration 4089 : loss : 0.022658, loss_ce: 0.008227
2022-01-14 16:44:37,018 iteration 4090 : loss : 0.015334, loss_ce: 0.006028
2022-01-14 16:44:38,473 iteration 4091 : loss : 0.017318, loss_ce: 0.005827
2022-01-14 16:44:39,976 iteration 4092 : loss : 0.013946, loss_ce: 0.005401
2022-01-14 16:44:41,465 iteration 4093 : loss : 0.016612, loss_ce: 0.007048
2022-01-14 16:44:42,936 iteration 4094 : loss : 0.012673, loss_ce: 0.004372
2022-01-14 16:44:44,434 iteration 4095 : loss : 0.019689, loss_ce: 0.007505
2022-01-14 16:44:45,936 iteration 4096 : loss : 0.021256, loss_ce: 0.008852
2022-01-14 16:44:47,451 iteration 4097 : loss : 0.019925, loss_ce: 0.009816
 60%|████████████████▎          | 241/400 [1:52:07<1:15:03, 28.32s/it]2022-01-14 16:44:49,039 iteration 4098 : loss : 0.019942, loss_ce: 0.007720
2022-01-14 16:44:50,515 iteration 4099 : loss : 0.036485, loss_ce: 0.007423
2022-01-14 16:44:51,955 iteration 4100 : loss : 0.015760, loss_ce: 0.006789
2022-01-14 16:44:53,417 iteration 4101 : loss : 0.014736, loss_ce: 0.005743
2022-01-14 16:44:54,931 iteration 4102 : loss : 0.042693, loss_ce: 0.015663
2022-01-14 16:44:56,399 iteration 4103 : loss : 0.017133, loss_ce: 0.006796
2022-01-14 16:44:57,847 iteration 4104 : loss : 0.016643, loss_ce: 0.007352
2022-01-14 16:44:59,398 iteration 4105 : loss : 0.019653, loss_ce: 0.007756
2022-01-14 16:45:00,909 iteration 4106 : loss : 0.026319, loss_ce: 0.005546
2022-01-14 16:45:02,533 iteration 4107 : loss : 0.021638, loss_ce: 0.011859
2022-01-14 16:45:04,052 iteration 4108 : loss : 0.022889, loss_ce: 0.008521
2022-01-14 16:45:05,492 iteration 4109 : loss : 0.014138, loss_ce: 0.003794
2022-01-14 16:45:06,992 iteration 4110 : loss : 0.020816, loss_ce: 0.009651
2022-01-14 16:45:08,566 iteration 4111 : loss : 0.021156, loss_ce: 0.007953
2022-01-14 16:45:10,048 iteration 4112 : loss : 0.025619, loss_ce: 0.008770
2022-01-14 16:45:11,574 iteration 4113 : loss : 0.022003, loss_ce: 0.008601
2022-01-14 16:45:13,166 iteration 4114 : loss : 0.021502, loss_ce: 0.007719
 60%|████████████████▎          | 242/400 [1:52:33<1:12:31, 27.54s/it]2022-01-14 16:45:14,670 iteration 4115 : loss : 0.018547, loss_ce: 0.004363
2022-01-14 16:45:16,104 iteration 4116 : loss : 0.017392, loss_ce: 0.007491
2022-01-14 16:45:17,775 iteration 4117 : loss : 0.022755, loss_ce: 0.006298
2022-01-14 16:45:19,421 iteration 4118 : loss : 0.022907, loss_ce: 0.009517
2022-01-14 16:45:20,999 iteration 4119 : loss : 0.018070, loss_ce: 0.007250
2022-01-14 16:45:22,502 iteration 4120 : loss : 0.030221, loss_ce: 0.005650
2022-01-14 16:45:24,028 iteration 4121 : loss : 0.016764, loss_ce: 0.007937
2022-01-14 16:45:25,493 iteration 4122 : loss : 0.021563, loss_ce: 0.006660
2022-01-14 16:45:27,080 iteration 4123 : loss : 0.021076, loss_ce: 0.007017
2022-01-14 16:45:28,514 iteration 4124 : loss : 0.019089, loss_ce: 0.006636
2022-01-14 16:45:30,111 iteration 4125 : loss : 0.024179, loss_ce: 0.006918
2022-01-14 16:45:31,640 iteration 4126 : loss : 0.018250, loss_ce: 0.007745
2022-01-14 16:45:33,202 iteration 4127 : loss : 0.017973, loss_ce: 0.007608
2022-01-14 16:45:34,670 iteration 4128 : loss : 0.023200, loss_ce: 0.011860
2022-01-14 16:45:36,212 iteration 4129 : loss : 0.023017, loss_ce: 0.009018
2022-01-14 16:45:37,724 iteration 4130 : loss : 0.016969, loss_ce: 0.009624
2022-01-14 16:45:39,138 iteration 4131 : loss : 0.013945, loss_ce: 0.003713
 61%|████████████████▍          | 243/400 [1:52:59<1:10:50, 27.07s/it]2022-01-14 16:45:40,746 iteration 4132 : loss : 0.025636, loss_ce: 0.010297
2022-01-14 16:45:42,304 iteration 4133 : loss : 0.027809, loss_ce: 0.011505
2022-01-14 16:45:43,726 iteration 4134 : loss : 0.023661, loss_ce: 0.008654
2022-01-14 16:45:45,301 iteration 4135 : loss : 0.018563, loss_ce: 0.007360
2022-01-14 16:45:46,811 iteration 4136 : loss : 0.019825, loss_ce: 0.009807
2022-01-14 16:45:48,281 iteration 4137 : loss : 0.022431, loss_ce: 0.010779
2022-01-14 16:45:49,726 iteration 4138 : loss : 0.020921, loss_ce: 0.009877
2022-01-14 16:45:51,298 iteration 4139 : loss : 0.033690, loss_ce: 0.009923
2022-01-14 16:45:52,879 iteration 4140 : loss : 0.029598, loss_ce: 0.010598
2022-01-14 16:45:54,362 iteration 4141 : loss : 0.021500, loss_ce: 0.004999
2022-01-14 16:45:55,890 iteration 4142 : loss : 0.031120, loss_ce: 0.008872
2022-01-14 16:45:57,469 iteration 4143 : loss : 0.024138, loss_ce: 0.006683
2022-01-14 16:45:58,949 iteration 4144 : loss : 0.018412, loss_ce: 0.007106
2022-01-14 16:46:00,444 iteration 4145 : loss : 0.015230, loss_ce: 0.004061
2022-01-14 16:46:01,935 iteration 4146 : loss : 0.018273, loss_ce: 0.005553
2022-01-14 16:46:03,451 iteration 4147 : loss : 0.020435, loss_ce: 0.007274
2022-01-14 16:46:04,865 iteration 4148 : loss : 0.015520, loss_ce: 0.005276
 61%|████████████████▍          | 244/400 [1:53:24<1:09:20, 26.67s/it]2022-01-14 16:46:06,549 iteration 4149 : loss : 0.041015, loss_ce: 0.017037
2022-01-14 16:46:07,982 iteration 4150 : loss : 0.017159, loss_ce: 0.004681
2022-01-14 16:46:09,530 iteration 4151 : loss : 0.018121, loss_ce: 0.008392
2022-01-14 16:46:10,925 iteration 4152 : loss : 0.018087, loss_ce: 0.006608
2022-01-14 16:46:12,494 iteration 4153 : loss : 0.035266, loss_ce: 0.009814
2022-01-14 16:46:14,037 iteration 4154 : loss : 0.029534, loss_ce: 0.013291
2022-01-14 16:46:15,617 iteration 4155 : loss : 0.027052, loss_ce: 0.011382
2022-01-14 16:46:17,021 iteration 4156 : loss : 0.013284, loss_ce: 0.005129
2022-01-14 16:46:18,565 iteration 4157 : loss : 0.021686, loss_ce: 0.007107
2022-01-14 16:46:20,092 iteration 4158 : loss : 0.020182, loss_ce: 0.007989
2022-01-14 16:46:21,617 iteration 4159 : loss : 0.015197, loss_ce: 0.005948
2022-01-14 16:46:23,161 iteration 4160 : loss : 0.019523, loss_ce: 0.008385
2022-01-14 16:46:24,638 iteration 4161 : loss : 0.015391, loss_ce: 0.005894
2022-01-14 16:46:26,105 iteration 4162 : loss : 0.016454, loss_ce: 0.006165
2022-01-14 16:46:27,654 iteration 4163 : loss : 0.027804, loss_ce: 0.008284
2022-01-14 16:46:29,198 iteration 4164 : loss : 0.016960, loss_ce: 0.007449
2022-01-14 16:46:29,198 Training Data Eval:
2022-01-14 16:46:36,715   Average segmentation loss on training set: 0.0129
2022-01-14 16:46:36,716 Validation Data Eval:
2022-01-14 16:46:39,297   Average segmentation loss on validation set: 0.0806
2022-01-14 16:46:40,839 iteration 4165 : loss : 0.020597, loss_ce: 0.007907
 61%|████████████████▌          | 245/400 [1:54:00<1:16:06, 29.46s/it]2022-01-14 16:46:42,328 iteration 4166 : loss : 0.016190, loss_ce: 0.006495
2022-01-14 16:46:43,880 iteration 4167 : loss : 0.031494, loss_ce: 0.008258
2022-01-14 16:46:45,450 iteration 4168 : loss : 0.017981, loss_ce: 0.007294
2022-01-14 16:46:46,984 iteration 4169 : loss : 0.022371, loss_ce: 0.008593
2022-01-14 16:46:48,525 iteration 4170 : loss : 0.022843, loss_ce: 0.008799
2022-01-14 16:46:49,990 iteration 4171 : loss : 0.017697, loss_ce: 0.007478
2022-01-14 16:46:51,490 iteration 4172 : loss : 0.019451, loss_ce: 0.007677
2022-01-14 16:46:52,918 iteration 4173 : loss : 0.016404, loss_ce: 0.005156
2022-01-14 16:46:54,466 iteration 4174 : loss : 0.023997, loss_ce: 0.008976
2022-01-14 16:46:55,968 iteration 4175 : loss : 0.016300, loss_ce: 0.004063
2022-01-14 16:46:57,515 iteration 4176 : loss : 0.024433, loss_ce: 0.008295
2022-01-14 16:46:58,950 iteration 4177 : loss : 0.019474, loss_ce: 0.009946
2022-01-14 16:47:00,430 iteration 4178 : loss : 0.016363, loss_ce: 0.006756
2022-01-14 16:47:01,989 iteration 4179 : loss : 0.030154, loss_ce: 0.009721
2022-01-14 16:47:03,600 iteration 4180 : loss : 0.020802, loss_ce: 0.007004
2022-01-14 16:47:05,133 iteration 4181 : loss : 0.018468, loss_ce: 0.007777
2022-01-14 16:47:06,716 iteration 4182 : loss : 0.024539, loss_ce: 0.009422
 62%|████████████████▌          | 246/400 [1:54:26<1:12:51, 28.38s/it]2022-01-14 16:47:08,261 iteration 4183 : loss : 0.027072, loss_ce: 0.007416
2022-01-14 16:47:09,721 iteration 4184 : loss : 0.018147, loss_ce: 0.006087
2022-01-14 16:47:11,313 iteration 4185 : loss : 0.030976, loss_ce: 0.010976
2022-01-14 16:47:12,804 iteration 4186 : loss : 0.018190, loss_ce: 0.006403
2022-01-14 16:47:14,228 iteration 4187 : loss : 0.017430, loss_ce: 0.006993
2022-01-14 16:47:15,709 iteration 4188 : loss : 0.018048, loss_ce: 0.007401
2022-01-14 16:47:17,167 iteration 4189 : loss : 0.017117, loss_ce: 0.006064
2022-01-14 16:47:18,754 iteration 4190 : loss : 0.027578, loss_ce: 0.013109
2022-01-14 16:47:20,314 iteration 4191 : loss : 0.015804, loss_ce: 0.003438
2022-01-14 16:47:21,743 iteration 4192 : loss : 0.015010, loss_ce: 0.007488
2022-01-14 16:47:23,177 iteration 4193 : loss : 0.019310, loss_ce: 0.005752
2022-01-14 16:47:24,660 iteration 4194 : loss : 0.020954, loss_ce: 0.007079
2022-01-14 16:47:26,131 iteration 4195 : loss : 0.016988, loss_ce: 0.007149
2022-01-14 16:47:27,579 iteration 4196 : loss : 0.015142, loss_ce: 0.005689
2022-01-14 16:47:29,044 iteration 4197 : loss : 0.016692, loss_ce: 0.006358
2022-01-14 16:47:30,504 iteration 4198 : loss : 0.021604, loss_ce: 0.003874
2022-01-14 16:47:32,077 iteration 4199 : loss : 0.021344, loss_ce: 0.008832
 62%|████████████████▋          | 247/400 [1:54:52<1:10:03, 27.48s/it]2022-01-14 16:47:33,621 iteration 4200 : loss : 0.016960, loss_ce: 0.005453
2022-01-14 16:47:35,166 iteration 4201 : loss : 0.045577, loss_ce: 0.019785
2022-01-14 16:47:36,757 iteration 4202 : loss : 0.016656, loss_ce: 0.006432
2022-01-14 16:47:38,310 iteration 4203 : loss : 0.021517, loss_ce: 0.007489
2022-01-14 16:47:39,897 iteration 4204 : loss : 0.019235, loss_ce: 0.007817
2022-01-14 16:47:41,236 iteration 4205 : loss : 0.013627, loss_ce: 0.004665
2022-01-14 16:47:42,698 iteration 4206 : loss : 0.016639, loss_ce: 0.005334
2022-01-14 16:47:44,182 iteration 4207 : loss : 0.013802, loss_ce: 0.006330
2022-01-14 16:47:45,788 iteration 4208 : loss : 0.023173, loss_ce: 0.007533
2022-01-14 16:47:47,275 iteration 4209 : loss : 0.017785, loss_ce: 0.005077
2022-01-14 16:47:48,766 iteration 4210 : loss : 0.014358, loss_ce: 0.004882
2022-01-14 16:47:50,327 iteration 4211 : loss : 0.015486, loss_ce: 0.005801
2022-01-14 16:47:51,801 iteration 4212 : loss : 0.013989, loss_ce: 0.005785
2022-01-14 16:47:53,370 iteration 4213 : loss : 0.022834, loss_ce: 0.008421
2022-01-14 16:47:54,942 iteration 4214 : loss : 0.022414, loss_ce: 0.010456
2022-01-14 16:47:56,487 iteration 4215 : loss : 0.031536, loss_ce: 0.006821
2022-01-14 16:47:57,998 iteration 4216 : loss : 0.028960, loss_ce: 0.010354
 62%|████████████████▋          | 248/400 [1:55:18<1:08:25, 27.01s/it]2022-01-14 16:47:59,611 iteration 4217 : loss : 0.038547, loss_ce: 0.010218
2022-01-14 16:48:01,244 iteration 4218 : loss : 0.023928, loss_ce: 0.012350
2022-01-14 16:48:02,747 iteration 4219 : loss : 0.025372, loss_ce: 0.009993
2022-01-14 16:48:04,241 iteration 4220 : loss : 0.021815, loss_ce: 0.007168
2022-01-14 16:48:05,780 iteration 4221 : loss : 0.026160, loss_ce: 0.009421
2022-01-14 16:48:07,356 iteration 4222 : loss : 0.017553, loss_ce: 0.007486
2022-01-14 16:48:09,024 iteration 4223 : loss : 0.037553, loss_ce: 0.009974
2022-01-14 16:48:10,509 iteration 4224 : loss : 0.018455, loss_ce: 0.005879
2022-01-14 16:48:12,104 iteration 4225 : loss : 0.027621, loss_ce: 0.013899
2022-01-14 16:48:13,691 iteration 4226 : loss : 0.026497, loss_ce: 0.009302
2022-01-14 16:48:15,154 iteration 4227 : loss : 0.027885, loss_ce: 0.008091
2022-01-14 16:48:16,718 iteration 4228 : loss : 0.022214, loss_ce: 0.010546
2022-01-14 16:48:18,178 iteration 4229 : loss : 0.019148, loss_ce: 0.006815
2022-01-14 16:48:19,724 iteration 4230 : loss : 0.021496, loss_ce: 0.007583
2022-01-14 16:48:21,301 iteration 4231 : loss : 0.015723, loss_ce: 0.005696
2022-01-14 16:48:22,860 iteration 4232 : loss : 0.028474, loss_ce: 0.012420
2022-01-14 16:48:24,313 iteration 4233 : loss : 0.020449, loss_ce: 0.007196
 62%|████████████████▊          | 249/400 [1:55:44<1:07:27, 26.80s/it]2022-01-14 16:48:25,889 iteration 4234 : loss : 0.023974, loss_ce: 0.009394
2022-01-14 16:48:27,336 iteration 4235 : loss : 0.016662, loss_ce: 0.005963
2022-01-14 16:48:28,891 iteration 4236 : loss : 0.023971, loss_ce: 0.012060
2022-01-14 16:48:30,412 iteration 4237 : loss : 0.018986, loss_ce: 0.008952
2022-01-14 16:48:32,037 iteration 4238 : loss : 0.041382, loss_ce: 0.011441
2022-01-14 16:48:33,468 iteration 4239 : loss : 0.017977, loss_ce: 0.005306
2022-01-14 16:48:35,072 iteration 4240 : loss : 0.019839, loss_ce: 0.006503
2022-01-14 16:48:36,571 iteration 4241 : loss : 0.016941, loss_ce: 0.005279
2022-01-14 16:48:38,046 iteration 4242 : loss : 0.026080, loss_ce: 0.009443
2022-01-14 16:48:39,569 iteration 4243 : loss : 0.022755, loss_ce: 0.009628
2022-01-14 16:48:41,107 iteration 4244 : loss : 0.022791, loss_ce: 0.008022
2022-01-14 16:48:42,649 iteration 4245 : loss : 0.025854, loss_ce: 0.005833
2022-01-14 16:48:44,154 iteration 4246 : loss : 0.020400, loss_ce: 0.010018
2022-01-14 16:48:45,605 iteration 4247 : loss : 0.018791, loss_ce: 0.004264
2022-01-14 16:48:47,187 iteration 4248 : loss : 0.022607, loss_ce: 0.008488
2022-01-14 16:48:48,690 iteration 4249 : loss : 0.019944, loss_ce: 0.008913
2022-01-14 16:48:48,690 Training Data Eval:
2022-01-14 16:48:56,173   Average segmentation loss on training set: 0.0153
2022-01-14 16:48:56,174 Validation Data Eval:
2022-01-14 16:48:58,749   Average segmentation loss on validation set: 0.0986
2022-01-14 16:49:00,318 iteration 4250 : loss : 0.020393, loss_ce: 0.006064
 62%|████████████████▉          | 250/400 [1:56:20<1:13:54, 29.56s/it]2022-01-14 16:49:01,942 iteration 4251 : loss : 0.022927, loss_ce: 0.010162
2022-01-14 16:49:03,546 iteration 4252 : loss : 0.020968, loss_ce: 0.008377
2022-01-14 16:49:05,115 iteration 4253 : loss : 0.022978, loss_ce: 0.008726
2022-01-14 16:49:06,746 iteration 4254 : loss : 0.019279, loss_ce: 0.007851
2022-01-14 16:49:08,144 iteration 4255 : loss : 0.014206, loss_ce: 0.005203
2022-01-14 16:49:09,654 iteration 4256 : loss : 0.018330, loss_ce: 0.004735
2022-01-14 16:49:11,268 iteration 4257 : loss : 0.021607, loss_ce: 0.008645
2022-01-14 16:49:12,756 iteration 4258 : loss : 0.015662, loss_ce: 0.005470
2022-01-14 16:49:14,273 iteration 4259 : loss : 0.019282, loss_ce: 0.006991
2022-01-14 16:49:15,807 iteration 4260 : loss : 0.020165, loss_ce: 0.006721
2022-01-14 16:49:17,330 iteration 4261 : loss : 0.015292, loss_ce: 0.005364
2022-01-14 16:49:19,004 iteration 4262 : loss : 0.017015, loss_ce: 0.007825
2022-01-14 16:49:20,512 iteration 4263 : loss : 0.018676, loss_ce: 0.009309
2022-01-14 16:49:21,944 iteration 4264 : loss : 0.024619, loss_ce: 0.007964
2022-01-14 16:49:23,421 iteration 4265 : loss : 0.022598, loss_ce: 0.008004
2022-01-14 16:49:24,914 iteration 4266 : loss : 0.021295, loss_ce: 0.008178
2022-01-14 16:49:26,422 iteration 4267 : loss : 0.019952, loss_ce: 0.009784
 63%|████████████████▉          | 251/400 [1:56:46<1:10:50, 28.52s/it]2022-01-14 16:49:28,003 iteration 4268 : loss : 0.021627, loss_ce: 0.008439
2022-01-14 16:49:29,435 iteration 4269 : loss : 0.017454, loss_ce: 0.005542
2022-01-14 16:49:30,913 iteration 4270 : loss : 0.026162, loss_ce: 0.004091
2022-01-14 16:49:32,394 iteration 4271 : loss : 0.017228, loss_ce: 0.007733
2022-01-14 16:49:33,939 iteration 4272 : loss : 0.018246, loss_ce: 0.006639
2022-01-14 16:49:35,488 iteration 4273 : loss : 0.023186, loss_ce: 0.011346
2022-01-14 16:49:37,018 iteration 4274 : loss : 0.026009, loss_ce: 0.011792
2022-01-14 16:49:38,381 iteration 4275 : loss : 0.015178, loss_ce: 0.006383
2022-01-14 16:49:39,863 iteration 4276 : loss : 0.023369, loss_ce: 0.008175
2022-01-14 16:49:41,338 iteration 4277 : loss : 0.014524, loss_ce: 0.006107
2022-01-14 16:49:42,833 iteration 4278 : loss : 0.021597, loss_ce: 0.005841
2022-01-14 16:49:44,275 iteration 4279 : loss : 0.012839, loss_ce: 0.003946
2022-01-14 16:49:45,719 iteration 4280 : loss : 0.016933, loss_ce: 0.004717
2022-01-14 16:49:47,336 iteration 4281 : loss : 0.017963, loss_ce: 0.007969
2022-01-14 16:49:48,839 iteration 4282 : loss : 0.018024, loss_ce: 0.007930
2022-01-14 16:49:50,238 iteration 4283 : loss : 0.015605, loss_ce: 0.006384
2022-01-14 16:49:51,701 iteration 4284 : loss : 0.018633, loss_ce: 0.008390
 63%|█████████████████          | 252/400 [1:57:11<1:07:57, 27.55s/it]2022-01-14 16:49:53,285 iteration 4285 : loss : 0.027298, loss_ce: 0.011448
2022-01-14 16:49:54,824 iteration 4286 : loss : 0.014191, loss_ce: 0.003998
2022-01-14 16:49:56,399 iteration 4287 : loss : 0.035537, loss_ce: 0.017906
2022-01-14 16:49:57,855 iteration 4288 : loss : 0.021564, loss_ce: 0.006337
2022-01-14 16:49:59,369 iteration 4289 : loss : 0.016795, loss_ce: 0.005528
2022-01-14 16:50:00,961 iteration 4290 : loss : 0.027075, loss_ce: 0.008853
2022-01-14 16:50:02,425 iteration 4291 : loss : 0.022832, loss_ce: 0.008308
2022-01-14 16:50:04,036 iteration 4292 : loss : 0.022743, loss_ce: 0.008187
2022-01-14 16:50:05,568 iteration 4293 : loss : 0.025919, loss_ce: 0.010652
2022-01-14 16:50:07,099 iteration 4294 : loss : 0.025466, loss_ce: 0.011274
2022-01-14 16:50:08,662 iteration 4295 : loss : 0.017215, loss_ce: 0.007490
2022-01-14 16:50:10,111 iteration 4296 : loss : 0.014322, loss_ce: 0.005784
2022-01-14 16:50:11,654 iteration 4297 : loss : 0.016144, loss_ce: 0.006128
2022-01-14 16:50:13,110 iteration 4298 : loss : 0.019988, loss_ce: 0.006268
2022-01-14 16:50:14,732 iteration 4299 : loss : 0.026565, loss_ce: 0.010662
2022-01-14 16:50:16,313 iteration 4300 : loss : 0.030170, loss_ce: 0.009019
2022-01-14 16:50:17,777 iteration 4301 : loss : 0.016866, loss_ce: 0.006361
 63%|█████████████████          | 253/400 [1:57:37<1:06:24, 27.11s/it]2022-01-14 16:50:19,332 iteration 4302 : loss : 0.019463, loss_ce: 0.008499
2022-01-14 16:50:20,871 iteration 4303 : loss : 0.018938, loss_ce: 0.006826
2022-01-14 16:50:22,295 iteration 4304 : loss : 0.017066, loss_ce: 0.006579
2022-01-14 16:50:23,843 iteration 4305 : loss : 0.027428, loss_ce: 0.008690
2022-01-14 16:50:25,293 iteration 4306 : loss : 0.021030, loss_ce: 0.007078
2022-01-14 16:50:26,805 iteration 4307 : loss : 0.018517, loss_ce: 0.006439
2022-01-14 16:50:28,372 iteration 4308 : loss : 0.030504, loss_ce: 0.009825
2022-01-14 16:50:29,854 iteration 4309 : loss : 0.020924, loss_ce: 0.006192
2022-01-14 16:50:31,389 iteration 4310 : loss : 0.017858, loss_ce: 0.008050
2022-01-14 16:50:32,915 iteration 4311 : loss : 0.017016, loss_ce: 0.007962
2022-01-14 16:50:34,586 iteration 4312 : loss : 0.023197, loss_ce: 0.008115
2022-01-14 16:50:36,093 iteration 4313 : loss : 0.022040, loss_ce: 0.007600
2022-01-14 16:50:37,542 iteration 4314 : loss : 0.034871, loss_ce: 0.010842
2022-01-14 16:50:39,003 iteration 4315 : loss : 0.014455, loss_ce: 0.005403
2022-01-14 16:50:40,556 iteration 4316 : loss : 0.019181, loss_ce: 0.006876
2022-01-14 16:50:42,011 iteration 4317 : loss : 0.023981, loss_ce: 0.008579
2022-01-14 16:50:43,499 iteration 4318 : loss : 0.017469, loss_ce: 0.008444
 64%|█████████████████▏         | 254/400 [1:58:03<1:04:57, 26.69s/it]2022-01-14 16:50:45,096 iteration 4319 : loss : 0.019576, loss_ce: 0.006676
2022-01-14 16:50:46,671 iteration 4320 : loss : 0.022143, loss_ce: 0.008842
2022-01-14 16:50:48,262 iteration 4321 : loss : 0.017955, loss_ce: 0.008068
2022-01-14 16:50:49,784 iteration 4322 : loss : 0.024539, loss_ce: 0.007360
2022-01-14 16:50:51,272 iteration 4323 : loss : 0.013290, loss_ce: 0.004118
2022-01-14 16:50:52,802 iteration 4324 : loss : 0.016690, loss_ce: 0.005723
2022-01-14 16:50:54,434 iteration 4325 : loss : 0.029190, loss_ce: 0.006573
2022-01-14 16:50:55,948 iteration 4326 : loss : 0.022150, loss_ce: 0.012511
2022-01-14 16:50:57,412 iteration 4327 : loss : 0.015697, loss_ce: 0.006012
2022-01-14 16:50:58,934 iteration 4328 : loss : 0.032306, loss_ce: 0.010809
2022-01-14 16:51:00,469 iteration 4329 : loss : 0.020121, loss_ce: 0.007000
2022-01-14 16:51:01,927 iteration 4330 : loss : 0.014486, loss_ce: 0.004868
2022-01-14 16:51:03,569 iteration 4331 : loss : 0.038569, loss_ce: 0.011261
2022-01-14 16:51:05,148 iteration 4332 : loss : 0.026486, loss_ce: 0.011134
2022-01-14 16:51:06,563 iteration 4333 : loss : 0.016025, loss_ce: 0.004735
2022-01-14 16:51:08,044 iteration 4334 : loss : 0.018026, loss_ce: 0.007106
2022-01-14 16:51:08,044 Training Data Eval:
2022-01-14 16:51:15,568   Average segmentation loss on training set: 0.0164
2022-01-14 16:51:15,569 Validation Data Eval:
2022-01-14 16:51:18,144   Average segmentation loss on validation set: 0.0810
2022-01-14 16:51:19,759 iteration 4335 : loss : 0.020481, loss_ce: 0.010877
 64%|█████████████████▏         | 255/400 [1:58:39<1:11:26, 29.56s/it]2022-01-14 16:51:21,327 iteration 4336 : loss : 0.018731, loss_ce: 0.006946
2022-01-14 16:51:22,863 iteration 4337 : loss : 0.029148, loss_ce: 0.010973
2022-01-14 16:51:24,482 iteration 4338 : loss : 0.016124, loss_ce: 0.005660
2022-01-14 16:51:25,981 iteration 4339 : loss : 0.028530, loss_ce: 0.008290
2022-01-14 16:51:27,523 iteration 4340 : loss : 0.018112, loss_ce: 0.007367
2022-01-14 16:51:29,084 iteration 4341 : loss : 0.055326, loss_ce: 0.036442
2022-01-14 16:51:30,586 iteration 4342 : loss : 0.026447, loss_ce: 0.008537
2022-01-14 16:51:32,139 iteration 4343 : loss : 0.025286, loss_ce: 0.007348
2022-01-14 16:51:33,616 iteration 4344 : loss : 0.017730, loss_ce: 0.006186
2022-01-14 16:51:35,132 iteration 4345 : loss : 0.024500, loss_ce: 0.006473
2022-01-14 16:51:36,601 iteration 4346 : loss : 0.015230, loss_ce: 0.006513
2022-01-14 16:51:38,176 iteration 4347 : loss : 0.022720, loss_ce: 0.007287
2022-01-14 16:51:39,732 iteration 4348 : loss : 0.017160, loss_ce: 0.008296
2022-01-14 16:51:41,278 iteration 4349 : loss : 0.022153, loss_ce: 0.006921
2022-01-14 16:51:42,741 iteration 4350 : loss : 0.018458, loss_ce: 0.008619
2022-01-14 16:51:44,173 iteration 4351 : loss : 0.015208, loss_ce: 0.006964
2022-01-14 16:51:45,622 iteration 4352 : loss : 0.015329, loss_ce: 0.006303
 64%|█████████████████▎         | 256/400 [1:59:05<1:08:17, 28.45s/it]2022-01-14 16:51:47,216 iteration 4353 : loss : 0.019143, loss_ce: 0.006709
2022-01-14 16:51:48,805 iteration 4354 : loss : 0.018054, loss_ce: 0.005765
2022-01-14 16:51:50,262 iteration 4355 : loss : 0.015693, loss_ce: 0.005251
2022-01-14 16:51:51,833 iteration 4356 : loss : 0.021662, loss_ce: 0.010728
2022-01-14 16:51:53,343 iteration 4357 : loss : 0.020253, loss_ce: 0.007999
2022-01-14 16:51:54,812 iteration 4358 : loss : 0.016277, loss_ce: 0.007110
2022-01-14 16:51:56,324 iteration 4359 : loss : 0.013494, loss_ce: 0.004780
2022-01-14 16:51:57,811 iteration 4360 : loss : 0.019950, loss_ce: 0.007882
2022-01-14 16:51:59,393 iteration 4361 : loss : 0.022105, loss_ce: 0.010004
2022-01-14 16:52:00,844 iteration 4362 : loss : 0.014743, loss_ce: 0.004776
2022-01-14 16:52:02,266 iteration 4363 : loss : 0.015936, loss_ce: 0.007528
2022-01-14 16:52:03,858 iteration 4364 : loss : 0.018572, loss_ce: 0.007097
2022-01-14 16:52:05,359 iteration 4365 : loss : 0.016852, loss_ce: 0.006928
2022-01-14 16:52:06,739 iteration 4366 : loss : 0.014367, loss_ce: 0.006050
2022-01-14 16:52:08,275 iteration 4367 : loss : 0.025476, loss_ce: 0.008753
2022-01-14 16:52:09,885 iteration 4368 : loss : 0.031216, loss_ce: 0.011986
2022-01-14 16:52:11,357 iteration 4369 : loss : 0.021335, loss_ce: 0.005927
 64%|█████████████████▎         | 257/400 [1:59:31<1:05:52, 27.64s/it]2022-01-14 16:52:12,897 iteration 4370 : loss : 0.039095, loss_ce: 0.009452
2022-01-14 16:52:14,403 iteration 4371 : loss : 0.020660, loss_ce: 0.010604
2022-01-14 16:52:15,819 iteration 4372 : loss : 0.015748, loss_ce: 0.006910
2022-01-14 16:52:17,372 iteration 4373 : loss : 0.015577, loss_ce: 0.004896
2022-01-14 16:52:18,859 iteration 4374 : loss : 0.016648, loss_ce: 0.007454
2022-01-14 16:52:20,269 iteration 4375 : loss : 0.015400, loss_ce: 0.006474
2022-01-14 16:52:21,729 iteration 4376 : loss : 0.018782, loss_ce: 0.006431
2022-01-14 16:52:23,363 iteration 4377 : loss : 0.021215, loss_ce: 0.006910
2022-01-14 16:52:24,892 iteration 4378 : loss : 0.019217, loss_ce: 0.007198
2022-01-14 16:52:26,517 iteration 4379 : loss : 0.031704, loss_ce: 0.014146
2022-01-14 16:52:28,053 iteration 4380 : loss : 0.019545, loss_ce: 0.007268
2022-01-14 16:52:29,589 iteration 4381 : loss : 0.026049, loss_ce: 0.010402
2022-01-14 16:52:31,105 iteration 4382 : loss : 0.020928, loss_ce: 0.007747
2022-01-14 16:52:32,620 iteration 4383 : loss : 0.019724, loss_ce: 0.005365
2022-01-14 16:52:34,158 iteration 4384 : loss : 0.023239, loss_ce: 0.008138
2022-01-14 16:52:35,569 iteration 4385 : loss : 0.015391, loss_ce: 0.006911
2022-01-14 16:52:37,081 iteration 4386 : loss : 0.029830, loss_ce: 0.011704
 64%|█████████████████▍         | 258/400 [1:59:57<1:04:03, 27.06s/it]2022-01-14 16:52:38,609 iteration 4387 : loss : 0.015452, loss_ce: 0.005880
2022-01-14 16:52:40,182 iteration 4388 : loss : 0.019206, loss_ce: 0.008316
2022-01-14 16:52:41,631 iteration 4389 : loss : 0.015696, loss_ce: 0.007716
2022-01-14 16:52:43,077 iteration 4390 : loss : 0.017627, loss_ce: 0.006114
2022-01-14 16:52:44,551 iteration 4391 : loss : 0.021038, loss_ce: 0.007846
2022-01-14 16:52:46,112 iteration 4392 : loss : 0.023335, loss_ce: 0.010673
2022-01-14 16:52:47,527 iteration 4393 : loss : 0.021171, loss_ce: 0.006985
2022-01-14 16:52:49,148 iteration 4394 : loss : 0.016183, loss_ce: 0.006669
2022-01-14 16:52:50,714 iteration 4395 : loss : 0.016274, loss_ce: 0.005651
2022-01-14 16:52:52,266 iteration 4396 : loss : 0.021174, loss_ce: 0.007141
2022-01-14 16:52:53,757 iteration 4397 : loss : 0.020879, loss_ce: 0.007813
2022-01-14 16:52:55,231 iteration 4398 : loss : 0.029873, loss_ce: 0.008854
2022-01-14 16:52:56,741 iteration 4399 : loss : 0.016276, loss_ce: 0.005745
2022-01-14 16:52:58,193 iteration 4400 : loss : 0.014868, loss_ce: 0.006204
2022-01-14 16:52:59,653 iteration 4401 : loss : 0.024532, loss_ce: 0.011072
2022-01-14 16:53:01,087 iteration 4402 : loss : 0.014276, loss_ce: 0.004438
2022-01-14 16:53:02,605 iteration 4403 : loss : 0.020963, loss_ce: 0.006083
 65%|█████████████████▍         | 259/400 [2:00:22<1:02:30, 26.60s/it]2022-01-14 16:53:04,157 iteration 4404 : loss : 0.012631, loss_ce: 0.005965
2022-01-14 16:53:05,715 iteration 4405 : loss : 0.023129, loss_ce: 0.007367
2022-01-14 16:53:07,240 iteration 4406 : loss : 0.018260, loss_ce: 0.007135
2022-01-14 16:53:08,654 iteration 4407 : loss : 0.016449, loss_ce: 0.006584
2022-01-14 16:53:10,064 iteration 4408 : loss : 0.022554, loss_ce: 0.005187
2022-01-14 16:53:11,592 iteration 4409 : loss : 0.013369, loss_ce: 0.005135
2022-01-14 16:53:13,114 iteration 4410 : loss : 0.024626, loss_ce: 0.009073
2022-01-14 16:53:14,729 iteration 4411 : loss : 0.022016, loss_ce: 0.010563
2022-01-14 16:53:16,154 iteration 4412 : loss : 0.019234, loss_ce: 0.007828
2022-01-14 16:53:17,747 iteration 4413 : loss : 0.018427, loss_ce: 0.005201
2022-01-14 16:53:19,129 iteration 4414 : loss : 0.014845, loss_ce: 0.005711
2022-01-14 16:53:20,644 iteration 4415 : loss : 0.020235, loss_ce: 0.009256
2022-01-14 16:53:22,126 iteration 4416 : loss : 0.020393, loss_ce: 0.005178
2022-01-14 16:53:23,613 iteration 4417 : loss : 0.019724, loss_ce: 0.006520
2022-01-14 16:53:25,123 iteration 4418 : loss : 0.019462, loss_ce: 0.008558
2022-01-14 16:53:26,661 iteration 4419 : loss : 0.016749, loss_ce: 0.005027
2022-01-14 16:53:26,662 Training Data Eval:
2022-01-14 16:53:34,148   Average segmentation loss on training set: 0.0110
2022-01-14 16:53:34,149 Validation Data Eval:
2022-01-14 16:53:36,719   Average segmentation loss on validation set: 0.0744
2022-01-14 16:53:38,185 iteration 4420 : loss : 0.011859, loss_ce: 0.004956
 65%|█████████████████▌         | 260/400 [2:00:58<1:08:21, 29.29s/it]2022-01-14 16:53:39,743 iteration 4421 : loss : 0.017144, loss_ce: 0.005922
2022-01-14 16:53:41,322 iteration 4422 : loss : 0.032388, loss_ce: 0.013491
2022-01-14 16:53:42,966 iteration 4423 : loss : 0.022441, loss_ce: 0.009571
2022-01-14 16:53:44,516 iteration 4424 : loss : 0.023987, loss_ce: 0.008007
2022-01-14 16:53:45,973 iteration 4425 : loss : 0.014766, loss_ce: 0.005221
2022-01-14 16:53:47,551 iteration 4426 : loss : 0.023454, loss_ce: 0.009325
2022-01-14 16:53:49,119 iteration 4427 : loss : 0.024716, loss_ce: 0.006618
2022-01-14 16:53:50,732 iteration 4428 : loss : 0.020846, loss_ce: 0.008121
2022-01-14 16:53:52,296 iteration 4429 : loss : 0.065021, loss_ce: 0.021504
2022-01-14 16:53:53,835 iteration 4430 : loss : 0.020576, loss_ce: 0.006592
2022-01-14 16:53:55,337 iteration 4431 : loss : 0.015604, loss_ce: 0.006491
2022-01-14 16:53:56,819 iteration 4432 : loss : 0.013534, loss_ce: 0.005020
2022-01-14 16:53:58,318 iteration 4433 : loss : 0.014891, loss_ce: 0.005535
2022-01-14 16:53:59,795 iteration 4434 : loss : 0.013782, loss_ce: 0.004875
2022-01-14 16:54:01,354 iteration 4435 : loss : 0.020835, loss_ce: 0.007428
2022-01-14 16:54:02,986 iteration 4436 : loss : 0.032082, loss_ce: 0.016420
2022-01-14 16:54:04,466 iteration 4437 : loss : 0.017808, loss_ce: 0.006929
 65%|█████████████████▌         | 261/400 [2:01:24<1:05:46, 28.39s/it]2022-01-14 16:54:06,083 iteration 4438 : loss : 0.022580, loss_ce: 0.007248
2022-01-14 16:54:07,525 iteration 4439 : loss : 0.025323, loss_ce: 0.008391
2022-01-14 16:54:09,079 iteration 4440 : loss : 0.024341, loss_ce: 0.008109
2022-01-14 16:54:10,646 iteration 4441 : loss : 0.017139, loss_ce: 0.007442
2022-01-14 16:54:12,087 iteration 4442 : loss : 0.013005, loss_ce: 0.005682
2022-01-14 16:54:13,641 iteration 4443 : loss : 0.017089, loss_ce: 0.007833
2022-01-14 16:54:15,097 iteration 4444 : loss : 0.017684, loss_ce: 0.006235
2022-01-14 16:54:16,639 iteration 4445 : loss : 0.021101, loss_ce: 0.007386
2022-01-14 16:54:18,214 iteration 4446 : loss : 0.014723, loss_ce: 0.005455
2022-01-14 16:54:19,738 iteration 4447 : loss : 0.020808, loss_ce: 0.007485
2022-01-14 16:54:21,235 iteration 4448 : loss : 0.030082, loss_ce: 0.008279
2022-01-14 16:54:22,762 iteration 4449 : loss : 0.020690, loss_ce: 0.009241
2022-01-14 16:54:24,363 iteration 4450 : loss : 0.019095, loss_ce: 0.006930
2022-01-14 16:54:25,786 iteration 4451 : loss : 0.023441, loss_ce: 0.006996
2022-01-14 16:54:27,286 iteration 4452 : loss : 0.016052, loss_ce: 0.006442
2022-01-14 16:54:28,923 iteration 4453 : loss : 0.023779, loss_ce: 0.010331
2022-01-14 16:54:30,467 iteration 4454 : loss : 0.024894, loss_ce: 0.014258
 66%|█████████████████▋         | 262/400 [2:01:50<1:03:39, 27.67s/it]2022-01-14 16:54:32,073 iteration 4455 : loss : 0.017122, loss_ce: 0.006492
2022-01-14 16:54:33,567 iteration 4456 : loss : 0.017953, loss_ce: 0.007475
2022-01-14 16:54:34,972 iteration 4457 : loss : 0.012890, loss_ce: 0.006018
2022-01-14 16:54:36,521 iteration 4458 : loss : 0.022408, loss_ce: 0.009187
2022-01-14 16:54:37,982 iteration 4459 : loss : 0.016304, loss_ce: 0.006374
2022-01-14 16:54:39,516 iteration 4460 : loss : 0.014068, loss_ce: 0.004876
2022-01-14 16:54:41,000 iteration 4461 : loss : 0.015508, loss_ce: 0.007064
2022-01-14 16:54:42,446 iteration 4462 : loss : 0.013595, loss_ce: 0.004916
2022-01-14 16:54:43,907 iteration 4463 : loss : 0.017552, loss_ce: 0.006619
2022-01-14 16:54:45,410 iteration 4464 : loss : 0.017472, loss_ce: 0.006892
2022-01-14 16:54:46,944 iteration 4465 : loss : 0.020964, loss_ce: 0.008682
2022-01-14 16:54:48,488 iteration 4466 : loss : 0.019540, loss_ce: 0.006087
2022-01-14 16:54:49,997 iteration 4467 : loss : 0.017285, loss_ce: 0.006603
2022-01-14 16:54:51,481 iteration 4468 : loss : 0.015136, loss_ce: 0.004683
2022-01-14 16:54:52,931 iteration 4469 : loss : 0.018036, loss_ce: 0.005746
2022-01-14 16:54:54,488 iteration 4470 : loss : 0.022589, loss_ce: 0.010038
2022-01-14 16:54:56,039 iteration 4471 : loss : 0.020040, loss_ce: 0.005923
 66%|█████████████████▊         | 263/400 [2:02:16<1:01:44, 27.04s/it]2022-01-14 16:54:57,529 iteration 4472 : loss : 0.015650, loss_ce: 0.006324
2022-01-14 16:54:59,027 iteration 4473 : loss : 0.015586, loss_ce: 0.006078
2022-01-14 16:55:00,573 iteration 4474 : loss : 0.016615, loss_ce: 0.006127
2022-01-14 16:55:02,029 iteration 4475 : loss : 0.014849, loss_ce: 0.006177
2022-01-14 16:55:03,432 iteration 4476 : loss : 0.012694, loss_ce: 0.004187
2022-01-14 16:55:04,971 iteration 4477 : loss : 0.017232, loss_ce: 0.006324
2022-01-14 16:55:06,460 iteration 4478 : loss : 0.021280, loss_ce: 0.007110
2022-01-14 16:55:07,947 iteration 4479 : loss : 0.027401, loss_ce: 0.005599
2022-01-14 16:55:09,413 iteration 4480 : loss : 0.015254, loss_ce: 0.006504
2022-01-14 16:55:10,886 iteration 4481 : loss : 0.012964, loss_ce: 0.005140
2022-01-14 16:55:12,475 iteration 4482 : loss : 0.021855, loss_ce: 0.007830
2022-01-14 16:55:14,100 iteration 4483 : loss : 0.035477, loss_ce: 0.014280
2022-01-14 16:55:15,692 iteration 4484 : loss : 0.029590, loss_ce: 0.010244
2022-01-14 16:55:17,149 iteration 4485 : loss : 0.014228, loss_ce: 0.004220
2022-01-14 16:55:18,783 iteration 4486 : loss : 0.022560, loss_ce: 0.009744
2022-01-14 16:55:20,248 iteration 4487 : loss : 0.017974, loss_ce: 0.009377
2022-01-14 16:55:21,767 iteration 4488 : loss : 0.022877, loss_ce: 0.010796
 66%|█████████████████▊         | 264/400 [2:02:41<1:00:24, 26.65s/it]2022-01-14 16:55:23,387 iteration 4489 : loss : 0.017911, loss_ce: 0.007047
2022-01-14 16:55:24,882 iteration 4490 : loss : 0.016067, loss_ce: 0.005516
2022-01-14 16:55:26,462 iteration 4491 : loss : 0.021966, loss_ce: 0.008580
2022-01-14 16:55:27,988 iteration 4492 : loss : 0.019160, loss_ce: 0.007088
2022-01-14 16:55:29,555 iteration 4493 : loss : 0.032875, loss_ce: 0.009707
2022-01-14 16:55:30,968 iteration 4494 : loss : 0.019569, loss_ce: 0.008179
2022-01-14 16:55:32,576 iteration 4495 : loss : 0.016922, loss_ce: 0.007629
2022-01-14 16:55:34,139 iteration 4496 : loss : 0.016066, loss_ce: 0.004902
2022-01-14 16:55:35,587 iteration 4497 : loss : 0.017976, loss_ce: 0.005272
2022-01-14 16:55:37,178 iteration 4498 : loss : 0.021317, loss_ce: 0.009611
2022-01-14 16:55:38,833 iteration 4499 : loss : 0.023825, loss_ce: 0.010126
2022-01-14 16:55:40,315 iteration 4500 : loss : 0.014041, loss_ce: 0.005919
2022-01-14 16:55:41,759 iteration 4501 : loss : 0.018975, loss_ce: 0.007081
2022-01-14 16:55:43,234 iteration 4502 : loss : 0.014340, loss_ce: 0.005500
2022-01-14 16:55:44,813 iteration 4503 : loss : 0.018892, loss_ce: 0.007394
2022-01-14 16:55:46,333 iteration 4504 : loss : 0.021945, loss_ce: 0.007800
2022-01-14 16:55:46,333 Training Data Eval:
2022-01-14 16:55:53,866   Average segmentation loss on training set: 0.0107
2022-01-14 16:55:53,867 Validation Data Eval:
2022-01-14 16:55:56,440   Average segmentation loss on validation set: 0.0753
2022-01-14 16:55:57,862 iteration 4505 : loss : 0.012785, loss_ce: 0.005080
 66%|█████████████████▉         | 265/400 [2:03:17<1:06:20, 29.48s/it]2022-01-14 16:55:59,495 iteration 4506 : loss : 0.020696, loss_ce: 0.006772
2022-01-14 16:56:00,975 iteration 4507 : loss : 0.011356, loss_ce: 0.003562
2022-01-14 16:56:02,579 iteration 4508 : loss : 0.022093, loss_ce: 0.007719
2022-01-14 16:56:04,107 iteration 4509 : loss : 0.024735, loss_ce: 0.007683
2022-01-14 16:56:05,632 iteration 4510 : loss : 0.012722, loss_ce: 0.004600
2022-01-14 16:56:07,100 iteration 4511 : loss : 0.018602, loss_ce: 0.007235
2022-01-14 16:56:08,605 iteration 4512 : loss : 0.011478, loss_ce: 0.004824
2022-01-14 16:56:10,160 iteration 4513 : loss : 0.014181, loss_ce: 0.006878
2022-01-14 16:56:11,586 iteration 4514 : loss : 0.014130, loss_ce: 0.005357
2022-01-14 16:56:13,085 iteration 4515 : loss : 0.022165, loss_ce: 0.007746
2022-01-14 16:56:14,724 iteration 4516 : loss : 0.024068, loss_ce: 0.009555
2022-01-14 16:56:16,219 iteration 4517 : loss : 0.016929, loss_ce: 0.005780
2022-01-14 16:56:17,760 iteration 4518 : loss : 0.016508, loss_ce: 0.005071
2022-01-14 16:56:19,258 iteration 4519 : loss : 0.018256, loss_ce: 0.008033
2022-01-14 16:56:20,725 iteration 4520 : loss : 0.015967, loss_ce: 0.005878
2022-01-14 16:56:22,275 iteration 4521 : loss : 0.021089, loss_ce: 0.007624
2022-01-14 16:56:23,707 iteration 4522 : loss : 0.013542, loss_ce: 0.006485
 66%|█████████████████▉         | 266/400 [2:03:43<1:03:24, 28.39s/it]2022-01-14 16:56:25,323 iteration 4523 : loss : 0.018294, loss_ce: 0.006305
2022-01-14 16:56:26,744 iteration 4524 : loss : 0.012038, loss_ce: 0.004648
2022-01-14 16:56:28,350 iteration 4525 : loss : 0.019439, loss_ce: 0.004619
2022-01-14 16:56:29,886 iteration 4526 : loss : 0.014131, loss_ce: 0.005876
2022-01-14 16:56:31,395 iteration 4527 : loss : 0.015339, loss_ce: 0.006482
2022-01-14 16:56:32,945 iteration 4528 : loss : 0.019515, loss_ce: 0.006319
2022-01-14 16:56:34,445 iteration 4529 : loss : 0.026258, loss_ce: 0.017305
2022-01-14 16:56:35,989 iteration 4530 : loss : 0.023053, loss_ce: 0.010474
2022-01-14 16:56:37,481 iteration 4531 : loss : 0.016655, loss_ce: 0.007404
2022-01-14 16:56:39,061 iteration 4532 : loss : 0.015232, loss_ce: 0.006464
2022-01-14 16:56:40,662 iteration 4533 : loss : 0.017661, loss_ce: 0.006405
2022-01-14 16:56:42,336 iteration 4534 : loss : 0.023957, loss_ce: 0.009379
2022-01-14 16:56:43,751 iteration 4535 : loss : 0.016996, loss_ce: 0.005498
2022-01-14 16:56:45,315 iteration 4536 : loss : 0.016216, loss_ce: 0.007366
2022-01-14 16:56:46,951 iteration 4537 : loss : 0.017299, loss_ce: 0.005567
2022-01-14 16:56:48,424 iteration 4538 : loss : 0.023062, loss_ce: 0.007197
2022-01-14 16:56:49,965 iteration 4539 : loss : 0.023817, loss_ce: 0.010096
 67%|██████████████████         | 267/400 [2:04:10<1:01:30, 27.75s/it]2022-01-14 16:56:51,613 iteration 4540 : loss : 0.020322, loss_ce: 0.005959
2022-01-14 16:56:53,016 iteration 4541 : loss : 0.017641, loss_ce: 0.006141
2022-01-14 16:56:54,542 iteration 4542 : loss : 0.022139, loss_ce: 0.004627
2022-01-14 16:56:55,951 iteration 4543 : loss : 0.014222, loss_ce: 0.005168
2022-01-14 16:56:57,529 iteration 4544 : loss : 0.021817, loss_ce: 0.008762
2022-01-14 16:56:59,134 iteration 4545 : loss : 0.027372, loss_ce: 0.011165
2022-01-14 16:57:00,647 iteration 4546 : loss : 0.025188, loss_ce: 0.009843
2022-01-14 16:57:02,185 iteration 4547 : loss : 0.013809, loss_ce: 0.006398
2022-01-14 16:57:03,693 iteration 4548 : loss : 0.022733, loss_ce: 0.009084
2022-01-14 16:57:05,285 iteration 4549 : loss : 0.026951, loss_ce: 0.008924
2022-01-14 16:57:06,865 iteration 4550 : loss : 0.035900, loss_ce: 0.010347
2022-01-14 16:57:08,437 iteration 4551 : loss : 0.017761, loss_ce: 0.004198
2022-01-14 16:57:09,847 iteration 4552 : loss : 0.013144, loss_ce: 0.005213
2022-01-14 16:57:11,324 iteration 4553 : loss : 0.019482, loss_ce: 0.007371
2022-01-14 16:57:12,814 iteration 4554 : loss : 0.019164, loss_ce: 0.007217
2022-01-14 16:57:14,447 iteration 4555 : loss : 0.024421, loss_ce: 0.008564
2022-01-14 16:57:15,930 iteration 4556 : loss : 0.017641, loss_ce: 0.008695
 67%|███████████████████▍         | 268/400 [2:04:36<59:52, 27.21s/it]2022-01-14 16:57:17,482 iteration 4557 : loss : 0.019441, loss_ce: 0.008123
2022-01-14 16:57:19,068 iteration 4558 : loss : 0.025976, loss_ce: 0.012661
2022-01-14 16:57:20,568 iteration 4559 : loss : 0.029055, loss_ce: 0.009249
2022-01-14 16:57:22,058 iteration 4560 : loss : 0.018341, loss_ce: 0.005439
2022-01-14 16:57:23,549 iteration 4561 : loss : 0.017361, loss_ce: 0.004772
2022-01-14 16:57:25,079 iteration 4562 : loss : 0.019086, loss_ce: 0.007778
2022-01-14 16:57:26,554 iteration 4563 : loss : 0.014285, loss_ce: 0.004958
2022-01-14 16:57:28,087 iteration 4564 : loss : 0.020898, loss_ce: 0.005961
2022-01-14 16:57:29,543 iteration 4565 : loss : 0.018714, loss_ce: 0.007401
2022-01-14 16:57:30,993 iteration 4566 : loss : 0.018508, loss_ce: 0.008170
2022-01-14 16:57:32,513 iteration 4567 : loss : 0.024268, loss_ce: 0.009931
2022-01-14 16:57:33,976 iteration 4568 : loss : 0.016225, loss_ce: 0.005086
2022-01-14 16:57:35,492 iteration 4569 : loss : 0.019281, loss_ce: 0.008496
2022-01-14 16:57:36,932 iteration 4570 : loss : 0.016485, loss_ce: 0.006887
2022-01-14 16:57:38,390 iteration 4571 : loss : 0.013895, loss_ce: 0.007469
2022-01-14 16:57:39,863 iteration 4572 : loss : 0.017823, loss_ce: 0.005056
2022-01-14 16:57:41,373 iteration 4573 : loss : 0.016878, loss_ce: 0.007340
 67%|███████████████████▌         | 269/400 [2:05:01<58:15, 26.69s/it]2022-01-14 16:57:42,934 iteration 4574 : loss : 0.021480, loss_ce: 0.005954
2022-01-14 16:57:44,380 iteration 4575 : loss : 0.014754, loss_ce: 0.005025
2022-01-14 16:57:45,898 iteration 4576 : loss : 0.013271, loss_ce: 0.006363
2022-01-14 16:57:47,482 iteration 4577 : loss : 0.015650, loss_ce: 0.005584
2022-01-14 16:57:49,008 iteration 4578 : loss : 0.017981, loss_ce: 0.007213
2022-01-14 16:57:50,488 iteration 4579 : loss : 0.017288, loss_ce: 0.009323
2022-01-14 16:57:51,991 iteration 4580 : loss : 0.016634, loss_ce: 0.006817
2022-01-14 16:57:53,570 iteration 4581 : loss : 0.017058, loss_ce: 0.005010
2022-01-14 16:57:55,062 iteration 4582 : loss : 0.019664, loss_ce: 0.009443
2022-01-14 16:57:56,589 iteration 4583 : loss : 0.016062, loss_ce: 0.005326
2022-01-14 16:57:58,079 iteration 4584 : loss : 0.025491, loss_ce: 0.009725
2022-01-14 16:57:59,619 iteration 4585 : loss : 0.021770, loss_ce: 0.006305
2022-01-14 16:58:01,087 iteration 4586 : loss : 0.013749, loss_ce: 0.005742
2022-01-14 16:58:02,707 iteration 4587 : loss : 0.019574, loss_ce: 0.006282
2022-01-14 16:58:04,196 iteration 4588 : loss : 0.037370, loss_ce: 0.009657
2022-01-14 16:58:05,739 iteration 4589 : loss : 0.016730, loss_ce: 0.006694
2022-01-14 16:58:05,740 Training Data Eval:
2022-01-14 16:58:13,248   Average segmentation loss on training set: 0.0127
2022-01-14 16:58:13,248 Validation Data Eval:
2022-01-14 16:58:15,826   Average segmentation loss on validation set: 0.0752
2022-01-14 16:58:17,456 iteration 4590 : loss : 0.034092, loss_ce: 0.010702
 68%|██████████████████▏        | 270/400 [2:05:37<1:03:55, 29.50s/it]2022-01-14 16:58:18,946 iteration 4591 : loss : 0.015315, loss_ce: 0.004025
2022-01-14 16:58:20,461 iteration 4592 : loss : 0.019030, loss_ce: 0.006143
2022-01-14 16:58:21,885 iteration 4593 : loss : 0.018587, loss_ce: 0.005458
2022-01-14 16:58:23,354 iteration 4594 : loss : 0.020294, loss_ce: 0.008032
2022-01-14 16:58:24,908 iteration 4595 : loss : 0.049917, loss_ce: 0.008922
2022-01-14 16:58:26,501 iteration 4596 : loss : 0.031641, loss_ce: 0.011732
2022-01-14 16:58:27,989 iteration 4597 : loss : 0.015862, loss_ce: 0.007026
2022-01-14 16:58:29,425 iteration 4598 : loss : 0.027875, loss_ce: 0.015542
2022-01-14 16:58:30,883 iteration 4599 : loss : 0.025226, loss_ce: 0.005962
2022-01-14 16:58:32,478 iteration 4600 : loss : 0.015848, loss_ce: 0.007271
2022-01-14 16:58:34,083 iteration 4601 : loss : 0.018658, loss_ce: 0.009103
2022-01-14 16:58:35,456 iteration 4602 : loss : 0.015919, loss_ce: 0.006000
2022-01-14 16:58:36,926 iteration 4603 : loss : 0.014897, loss_ce: 0.006659
2022-01-14 16:58:38,469 iteration 4604 : loss : 0.028688, loss_ce: 0.009285
2022-01-14 16:58:40,009 iteration 4605 : loss : 0.027438, loss_ce: 0.007128
2022-01-14 16:58:41,534 iteration 4606 : loss : 0.019279, loss_ce: 0.006097
2022-01-14 16:58:42,970 iteration 4607 : loss : 0.017765, loss_ce: 0.009058
 68%|██████████████████▎        | 271/400 [2:06:03<1:00:51, 28.31s/it]2022-01-14 16:58:44,600 iteration 4608 : loss : 0.025474, loss_ce: 0.008541
2022-01-14 16:58:46,180 iteration 4609 : loss : 0.023888, loss_ce: 0.011039
2022-01-14 16:58:47,725 iteration 4610 : loss : 0.036238, loss_ce: 0.009795
2022-01-14 16:58:49,205 iteration 4611 : loss : 0.017636, loss_ce: 0.008077
2022-01-14 16:58:50,636 iteration 4612 : loss : 0.014263, loss_ce: 0.004974
2022-01-14 16:58:52,211 iteration 4613 : loss : 0.021857, loss_ce: 0.010296
2022-01-14 16:58:53,752 iteration 4614 : loss : 0.018968, loss_ce: 0.006813
2022-01-14 16:58:55,295 iteration 4615 : loss : 0.025104, loss_ce: 0.009006
2022-01-14 16:58:56,922 iteration 4616 : loss : 0.023660, loss_ce: 0.008972
2022-01-14 16:58:58,370 iteration 4617 : loss : 0.018617, loss_ce: 0.007833
2022-01-14 16:58:59,942 iteration 4618 : loss : 0.023061, loss_ce: 0.008392
2022-01-14 16:59:01,500 iteration 4619 : loss : 0.021711, loss_ce: 0.007516
2022-01-14 16:59:03,052 iteration 4620 : loss : 0.024990, loss_ce: 0.009609
2022-01-14 16:59:04,681 iteration 4621 : loss : 0.022191, loss_ce: 0.008355
2022-01-14 16:59:06,195 iteration 4622 : loss : 0.019527, loss_ce: 0.006466
2022-01-14 16:59:07,683 iteration 4623 : loss : 0.022359, loss_ce: 0.007197
2022-01-14 16:59:09,166 iteration 4624 : loss : 0.017032, loss_ce: 0.006887
 68%|███████████████████▋         | 272/400 [2:06:29<59:02, 27.67s/it]2022-01-14 16:59:10,709 iteration 4625 : loss : 0.016691, loss_ce: 0.008029
2022-01-14 16:59:12,193 iteration 4626 : loss : 0.014351, loss_ce: 0.004645
2022-01-14 16:59:13,727 iteration 4627 : loss : 0.014296, loss_ce: 0.004440
2022-01-14 16:59:15,225 iteration 4628 : loss : 0.019113, loss_ce: 0.007293
2022-01-14 16:59:16,655 iteration 4629 : loss : 0.017750, loss_ce: 0.006943
2022-01-14 16:59:18,143 iteration 4630 : loss : 0.018951, loss_ce: 0.005692
2022-01-14 16:59:19,723 iteration 4631 : loss : 0.016172, loss_ce: 0.005468
2022-01-14 16:59:21,224 iteration 4632 : loss : 0.012812, loss_ce: 0.003989
2022-01-14 16:59:22,747 iteration 4633 : loss : 0.018687, loss_ce: 0.007130
2022-01-14 16:59:24,162 iteration 4634 : loss : 0.014159, loss_ce: 0.006187
2022-01-14 16:59:25,730 iteration 4635 : loss : 0.018456, loss_ce: 0.005601
2022-01-14 16:59:27,225 iteration 4636 : loss : 0.019544, loss_ce: 0.006807
2022-01-14 16:59:28,747 iteration 4637 : loss : 0.014312, loss_ce: 0.005014
2022-01-14 16:59:30,289 iteration 4638 : loss : 0.022881, loss_ce: 0.012021
2022-01-14 16:59:31,889 iteration 4639 : loss : 0.024633, loss_ce: 0.007400
2022-01-14 16:59:33,415 iteration 4640 : loss : 0.017552, loss_ce: 0.007240
2022-01-14 16:59:34,872 iteration 4641 : loss : 0.012204, loss_ce: 0.004985
 68%|███████████████████▊         | 273/400 [2:06:54<57:19, 27.08s/it]2022-01-14 16:59:36,514 iteration 4642 : loss : 0.022071, loss_ce: 0.006570
2022-01-14 16:59:38,064 iteration 4643 : loss : 0.038045, loss_ce: 0.015737
2022-01-14 16:59:39,608 iteration 4644 : loss : 0.015856, loss_ce: 0.006067
2022-01-14 16:59:41,274 iteration 4645 : loss : 0.028873, loss_ce: 0.014148
2022-01-14 16:59:42,719 iteration 4646 : loss : 0.013226, loss_ce: 0.005509
2022-01-14 16:59:44,214 iteration 4647 : loss : 0.016910, loss_ce: 0.007050
2022-01-14 16:59:45,627 iteration 4648 : loss : 0.013788, loss_ce: 0.005389
2022-01-14 16:59:47,182 iteration 4649 : loss : 0.020865, loss_ce: 0.008887
2022-01-14 16:59:48,677 iteration 4650 : loss : 0.021093, loss_ce: 0.007906
2022-01-14 16:59:50,166 iteration 4651 : loss : 0.020273, loss_ce: 0.007968
2022-01-14 16:59:51,693 iteration 4652 : loss : 0.017879, loss_ce: 0.007113
2022-01-14 16:59:53,221 iteration 4653 : loss : 0.017978, loss_ce: 0.006875
2022-01-14 16:59:54,746 iteration 4654 : loss : 0.017866, loss_ce: 0.008622
2022-01-14 16:59:56,278 iteration 4655 : loss : 0.019238, loss_ce: 0.007143
2022-01-14 16:59:57,926 iteration 4656 : loss : 0.030318, loss_ce: 0.007646
2022-01-14 16:59:59,432 iteration 4657 : loss : 0.046177, loss_ce: 0.004890
2022-01-14 17:00:00,905 iteration 4658 : loss : 0.018520, loss_ce: 0.004471
 68%|███████████████████▊         | 274/400 [2:07:20<56:12, 26.77s/it]2022-01-14 17:00:02,487 iteration 4659 : loss : 0.019504, loss_ce: 0.006876
2022-01-14 17:00:04,061 iteration 4660 : loss : 0.034868, loss_ce: 0.007731
2022-01-14 17:00:05,571 iteration 4661 : loss : 0.040427, loss_ce: 0.019050
2022-01-14 17:00:07,203 iteration 4662 : loss : 0.045334, loss_ce: 0.023304
2022-01-14 17:00:08,677 iteration 4663 : loss : 0.024019, loss_ce: 0.006862
2022-01-14 17:00:10,206 iteration 4664 : loss : 0.024154, loss_ce: 0.007456
2022-01-14 17:00:11,842 iteration 4665 : loss : 0.024894, loss_ce: 0.008554
2022-01-14 17:00:13,285 iteration 4666 : loss : 0.015754, loss_ce: 0.006104
2022-01-14 17:00:14,745 iteration 4667 : loss : 0.021497, loss_ce: 0.008593
2022-01-14 17:00:16,261 iteration 4668 : loss : 0.029513, loss_ce: 0.006395
2022-01-14 17:00:17,824 iteration 4669 : loss : 0.022037, loss_ce: 0.010005
2022-01-14 17:00:19,423 iteration 4670 : loss : 0.021425, loss_ce: 0.009906
2022-01-14 17:00:20,860 iteration 4671 : loss : 0.015344, loss_ce: 0.004851
2022-01-14 17:00:22,482 iteration 4672 : loss : 0.023545, loss_ce: 0.008545
2022-01-14 17:00:24,026 iteration 4673 : loss : 0.020262, loss_ce: 0.006545
2022-01-14 17:00:25,623 iteration 4674 : loss : 0.030386, loss_ce: 0.016356
2022-01-14 17:00:25,623 Training Data Eval:
2022-01-14 17:00:33,130   Average segmentation loss on training set: 0.0293
2022-01-14 17:00:33,131 Validation Data Eval:
2022-01-14 17:00:35,695   Average segmentation loss on validation set: 0.0941
2022-01-14 17:00:37,172 iteration 4675 : loss : 0.023843, loss_ce: 0.009226
 69%|██████████████████▌        | 275/400 [2:07:57<1:01:42, 29.62s/it]2022-01-14 17:00:38,799 iteration 4676 : loss : 0.022912, loss_ce: 0.008038
2022-01-14 17:00:40,286 iteration 4677 : loss : 0.021631, loss_ce: 0.008936
2022-01-14 17:00:41,768 iteration 4678 : loss : 0.031852, loss_ce: 0.009982
2022-01-14 17:00:43,286 iteration 4679 : loss : 0.018024, loss_ce: 0.009219
2022-01-14 17:00:44,784 iteration 4680 : loss : 0.017201, loss_ce: 0.006277
2022-01-14 17:00:46,312 iteration 4681 : loss : 0.022043, loss_ce: 0.007006
2022-01-14 17:00:47,748 iteration 4682 : loss : 0.020981, loss_ce: 0.004938
2022-01-14 17:00:49,245 iteration 4683 : loss : 0.022389, loss_ce: 0.009060
2022-01-14 17:00:50,821 iteration 4684 : loss : 0.025821, loss_ce: 0.011399
2022-01-14 17:00:52,350 iteration 4685 : loss : 0.018034, loss_ce: 0.007875
2022-01-14 17:00:53,740 iteration 4686 : loss : 0.016489, loss_ce: 0.005434
2022-01-14 17:00:55,327 iteration 4687 : loss : 0.017760, loss_ce: 0.007294
2022-01-14 17:00:56,886 iteration 4688 : loss : 0.017808, loss_ce: 0.005692
2022-01-14 17:00:58,458 iteration 4689 : loss : 0.027308, loss_ce: 0.012923
2022-01-14 17:00:59,934 iteration 4690 : loss : 0.018875, loss_ce: 0.005285
2022-01-14 17:01:01,439 iteration 4691 : loss : 0.017456, loss_ce: 0.006431
2022-01-14 17:01:02,948 iteration 4692 : loss : 0.016782, loss_ce: 0.006459
 69%|████████████████████         | 276/400 [2:08:23<58:49, 28.47s/it]2022-01-14 17:01:04,525 iteration 4693 : loss : 0.020919, loss_ce: 0.008520
2022-01-14 17:01:06,006 iteration 4694 : loss : 0.020370, loss_ce: 0.006787
2022-01-14 17:01:07,597 iteration 4695 : loss : 0.020171, loss_ce: 0.007538
2022-01-14 17:01:09,122 iteration 4696 : loss : 0.020873, loss_ce: 0.008736
2022-01-14 17:01:10,702 iteration 4697 : loss : 0.026642, loss_ce: 0.010962
2022-01-14 17:01:12,092 iteration 4698 : loss : 0.013422, loss_ce: 0.005166
2022-01-14 17:01:13,605 iteration 4699 : loss : 0.021821, loss_ce: 0.008146
2022-01-14 17:01:15,118 iteration 4700 : loss : 0.027997, loss_ce: 0.008908
2022-01-14 17:01:16,624 iteration 4701 : loss : 0.022312, loss_ce: 0.009481
2022-01-14 17:01:18,056 iteration 4702 : loss : 0.020045, loss_ce: 0.007298
2022-01-14 17:01:19,606 iteration 4703 : loss : 0.018302, loss_ce: 0.006178
2022-01-14 17:01:21,116 iteration 4704 : loss : 0.035042, loss_ce: 0.009708
2022-01-14 17:01:22,583 iteration 4705 : loss : 0.013664, loss_ce: 0.005132
2022-01-14 17:01:24,050 iteration 4706 : loss : 0.015507, loss_ce: 0.006807
2022-01-14 17:01:25,637 iteration 4707 : loss : 0.023588, loss_ce: 0.010222
2022-01-14 17:01:27,167 iteration 4708 : loss : 0.027332, loss_ce: 0.006096
2022-01-14 17:01:28,647 iteration 4709 : loss : 0.017092, loss_ce: 0.006157
 69%|████████████████████         | 277/400 [2:08:48<56:38, 27.63s/it]2022-01-14 17:01:30,259 iteration 4710 : loss : 0.033444, loss_ce: 0.009989
2022-01-14 17:01:31,714 iteration 4711 : loss : 0.023923, loss_ce: 0.011058
2022-01-14 17:01:33,223 iteration 4712 : loss : 0.016454, loss_ce: 0.006759
2022-01-14 17:01:34,710 iteration 4713 : loss : 0.014273, loss_ce: 0.005076
2022-01-14 17:01:36,203 iteration 4714 : loss : 0.013117, loss_ce: 0.005723
2022-01-14 17:01:37,836 iteration 4715 : loss : 0.025484, loss_ce: 0.008526
2022-01-14 17:01:39,326 iteration 4716 : loss : 0.013734, loss_ce: 0.005438
2022-01-14 17:01:40,845 iteration 4717 : loss : 0.025405, loss_ce: 0.008299
2022-01-14 17:01:42,343 iteration 4718 : loss : 0.014530, loss_ce: 0.005231
2022-01-14 17:01:43,844 iteration 4719 : loss : 0.012972, loss_ce: 0.004528
2022-01-14 17:01:45,405 iteration 4720 : loss : 0.020344, loss_ce: 0.007699
2022-01-14 17:01:46,903 iteration 4721 : loss : 0.015754, loss_ce: 0.004857
2022-01-14 17:01:48,408 iteration 4722 : loss : 0.022259, loss_ce: 0.008348
2022-01-14 17:01:49,941 iteration 4723 : loss : 0.025640, loss_ce: 0.006665
2022-01-14 17:01:51,367 iteration 4724 : loss : 0.018470, loss_ce: 0.009649
2022-01-14 17:01:52,856 iteration 4725 : loss : 0.020936, loss_ce: 0.007616
2022-01-14 17:01:54,303 iteration 4726 : loss : 0.017412, loss_ce: 0.005682
 70%|████████████████████▏        | 278/400 [2:09:14<54:59, 27.04s/it]2022-01-14 17:01:55,871 iteration 4727 : loss : 0.017617, loss_ce: 0.006311
2022-01-14 17:01:57,382 iteration 4728 : loss : 0.024705, loss_ce: 0.009950
2022-01-14 17:01:58,960 iteration 4729 : loss : 0.014634, loss_ce: 0.004464
2022-01-14 17:02:00,476 iteration 4730 : loss : 0.017922, loss_ce: 0.006292
2022-01-14 17:02:01,983 iteration 4731 : loss : 0.026104, loss_ce: 0.006564
2022-01-14 17:02:03,403 iteration 4732 : loss : 0.014792, loss_ce: 0.005914
2022-01-14 17:02:05,036 iteration 4733 : loss : 0.030418, loss_ce: 0.016024
2022-01-14 17:02:06,562 iteration 4734 : loss : 0.021080, loss_ce: 0.008716
2022-01-14 17:02:08,021 iteration 4735 : loss : 0.014591, loss_ce: 0.005929
2022-01-14 17:02:09,572 iteration 4736 : loss : 0.024772, loss_ce: 0.009478
2022-01-14 17:02:11,131 iteration 4737 : loss : 0.028100, loss_ce: 0.010424
2022-01-14 17:02:12,770 iteration 4738 : loss : 0.023203, loss_ce: 0.005236
2022-01-14 17:02:14,295 iteration 4739 : loss : 0.014478, loss_ce: 0.006057
2022-01-14 17:02:15,837 iteration 4740 : loss : 0.014168, loss_ce: 0.003674
2022-01-14 17:02:17,377 iteration 4741 : loss : 0.025885, loss_ce: 0.013354
2022-01-14 17:02:18,927 iteration 4742 : loss : 0.019673, loss_ce: 0.008788
2022-01-14 17:02:20,643 iteration 4743 : loss : 0.040556, loss_ce: 0.017764
 70%|████████████████████▏        | 279/400 [2:09:40<54:06, 26.83s/it]2022-01-14 17:02:22,230 iteration 4744 : loss : 0.017145, loss_ce: 0.005731
2022-01-14 17:02:23,768 iteration 4745 : loss : 0.023906, loss_ce: 0.012600
2022-01-14 17:02:25,251 iteration 4746 : loss : 0.025635, loss_ce: 0.010022
2022-01-14 17:02:26,683 iteration 4747 : loss : 0.014683, loss_ce: 0.007973
2022-01-14 17:02:28,291 iteration 4748 : loss : 0.019125, loss_ce: 0.008304
2022-01-14 17:02:29,702 iteration 4749 : loss : 0.015868, loss_ce: 0.006756
2022-01-14 17:02:31,272 iteration 4750 : loss : 0.020750, loss_ce: 0.006034
2022-01-14 17:02:32,819 iteration 4751 : loss : 0.016637, loss_ce: 0.006995
2022-01-14 17:02:34,358 iteration 4752 : loss : 0.023633, loss_ce: 0.006376
2022-01-14 17:02:35,876 iteration 4753 : loss : 0.013822, loss_ce: 0.004653
2022-01-14 17:02:37,404 iteration 4754 : loss : 0.017999, loss_ce: 0.008195
2022-01-14 17:02:39,007 iteration 4755 : loss : 0.031698, loss_ce: 0.008229
2022-01-14 17:02:40,559 iteration 4756 : loss : 0.017123, loss_ce: 0.004401
2022-01-14 17:02:42,060 iteration 4757 : loss : 0.022434, loss_ce: 0.011192
2022-01-14 17:02:43,649 iteration 4758 : loss : 0.020040, loss_ce: 0.007360
2022-01-14 17:02:45,190 iteration 4759 : loss : 0.022278, loss_ce: 0.013394
2022-01-14 17:02:45,191 Training Data Eval:
2022-01-14 17:02:52,659   Average segmentation loss on training set: 0.0122
2022-01-14 17:02:52,660 Validation Data Eval:
2022-01-14 17:02:55,236   Average segmentation loss on validation set: 0.0935
2022-01-14 17:02:56,800 iteration 4760 : loss : 0.018659, loss_ce: 0.005827
 70%|████████████████████▎        | 280/400 [2:10:16<59:15, 29.63s/it]2022-01-14 17:02:58,294 iteration 4761 : loss : 0.012431, loss_ce: 0.004186
2022-01-14 17:02:59,922 iteration 4762 : loss : 0.019830, loss_ce: 0.005978
2022-01-14 17:03:01,442 iteration 4763 : loss : 0.017374, loss_ce: 0.007318
2022-01-14 17:03:02,900 iteration 4764 : loss : 0.021341, loss_ce: 0.006617
2022-01-14 17:03:04,383 iteration 4765 : loss : 0.016682, loss_ce: 0.007433
2022-01-14 17:03:05,857 iteration 4766 : loss : 0.017782, loss_ce: 0.005296
2022-01-14 17:03:07,495 iteration 4767 : loss : 0.039757, loss_ce: 0.014675
2022-01-14 17:03:09,114 iteration 4768 : loss : 0.024662, loss_ce: 0.011460
2022-01-14 17:03:10,679 iteration 4769 : loss : 0.027093, loss_ce: 0.006522
2022-01-14 17:03:12,219 iteration 4770 : loss : 0.017895, loss_ce: 0.008166
2022-01-14 17:03:13,724 iteration 4771 : loss : 0.013935, loss_ce: 0.005721
2022-01-14 17:03:15,227 iteration 4772 : loss : 0.012302, loss_ce: 0.003587
2022-01-14 17:03:16,722 iteration 4773 : loss : 0.017820, loss_ce: 0.006988
2022-01-14 17:03:18,208 iteration 4774 : loss : 0.013605, loss_ce: 0.005501
2022-01-14 17:03:19,723 iteration 4775 : loss : 0.027615, loss_ce: 0.010572
2022-01-14 17:03:21,227 iteration 4776 : loss : 0.016774, loss_ce: 0.006296
2022-01-14 17:03:22,736 iteration 4777 : loss : 0.014455, loss_ce: 0.004605
 70%|████████████████████▎        | 281/400 [2:10:42<56:33, 28.52s/it]2022-01-14 17:03:24,328 iteration 4778 : loss : 0.025940, loss_ce: 0.009068
2022-01-14 17:03:25,797 iteration 4779 : loss : 0.015113, loss_ce: 0.005409
2022-01-14 17:03:27,260 iteration 4780 : loss : 0.022974, loss_ce: 0.005895
2022-01-14 17:03:28,738 iteration 4781 : loss : 0.015288, loss_ce: 0.007181
2022-01-14 17:03:30,308 iteration 4782 : loss : 0.022666, loss_ce: 0.006233
2022-01-14 17:03:31,730 iteration 4783 : loss : 0.016416, loss_ce: 0.004312
2022-01-14 17:03:33,310 iteration 4784 : loss : 0.015046, loss_ce: 0.005516
2022-01-14 17:03:34,899 iteration 4785 : loss : 0.022467, loss_ce: 0.010246
2022-01-14 17:03:36,399 iteration 4786 : loss : 0.016825, loss_ce: 0.006327
2022-01-14 17:03:37,930 iteration 4787 : loss : 0.019150, loss_ce: 0.004797
2022-01-14 17:03:39,435 iteration 4788 : loss : 0.015220, loss_ce: 0.006233
2022-01-14 17:03:40,953 iteration 4789 : loss : 0.017872, loss_ce: 0.006685
2022-01-14 17:03:42,435 iteration 4790 : loss : 0.018271, loss_ce: 0.008131
2022-01-14 17:03:43,978 iteration 4791 : loss : 0.013502, loss_ce: 0.004958
2022-01-14 17:03:45,505 iteration 4792 : loss : 0.021502, loss_ce: 0.009252
2022-01-14 17:03:47,039 iteration 4793 : loss : 0.026308, loss_ce: 0.010371
2022-01-14 17:03:48,584 iteration 4794 : loss : 0.040621, loss_ce: 0.008014
 70%|████████████████████▍        | 282/400 [2:11:08<54:30, 27.72s/it]2022-01-14 17:03:50,075 iteration 4795 : loss : 0.021057, loss_ce: 0.006667
2022-01-14 17:03:51,487 iteration 4796 : loss : 0.016675, loss_ce: 0.006478
2022-01-14 17:03:52,970 iteration 4797 : loss : 0.020197, loss_ce: 0.007002
2022-01-14 17:03:54,564 iteration 4798 : loss : 0.028770, loss_ce: 0.012413
2022-01-14 17:03:56,063 iteration 4799 : loss : 0.025038, loss_ce: 0.005779
2022-01-14 17:03:57,568 iteration 4800 : loss : 0.039353, loss_ce: 0.021252
2022-01-14 17:03:59,083 iteration 4801 : loss : 0.016252, loss_ce: 0.006931
2022-01-14 17:04:00,506 iteration 4802 : loss : 0.014565, loss_ce: 0.004284
2022-01-14 17:04:02,064 iteration 4803 : loss : 0.018254, loss_ce: 0.008873
2022-01-14 17:04:03,532 iteration 4804 : loss : 0.025594, loss_ce: 0.007822
2022-01-14 17:04:05,098 iteration 4805 : loss : 0.021923, loss_ce: 0.007122
2022-01-14 17:04:06,558 iteration 4806 : loss : 0.027581, loss_ce: 0.009090
2022-01-14 17:04:08,145 iteration 4807 : loss : 0.019676, loss_ce: 0.008484
2022-01-14 17:04:09,916 iteration 4808 : loss : 0.023033, loss_ce: 0.009339
2022-01-14 17:04:11,304 iteration 4809 : loss : 0.017289, loss_ce: 0.007035
2022-01-14 17:04:12,910 iteration 4810 : loss : 0.024815, loss_ce: 0.009012
2022-01-14 17:04:14,416 iteration 4811 : loss : 0.016261, loss_ce: 0.006500
 71%|████████████████████▌        | 283/400 [2:11:34<52:56, 27.15s/it]2022-01-14 17:04:15,949 iteration 4812 : loss : 0.020454, loss_ce: 0.007472
2022-01-14 17:04:17,476 iteration 4813 : loss : 0.017445, loss_ce: 0.006834
2022-01-14 17:04:18,936 iteration 4814 : loss : 0.016146, loss_ce: 0.008514
2022-01-14 17:04:20,441 iteration 4815 : loss : 0.017920, loss_ce: 0.006261
2022-01-14 17:04:21,901 iteration 4816 : loss : 0.017623, loss_ce: 0.006234
2022-01-14 17:04:23,282 iteration 4817 : loss : 0.014860, loss_ce: 0.005051
2022-01-14 17:04:24,834 iteration 4818 : loss : 0.033284, loss_ce: 0.014209
2022-01-14 17:04:26,373 iteration 4819 : loss : 0.018890, loss_ce: 0.006247
2022-01-14 17:04:27,975 iteration 4820 : loss : 0.015732, loss_ce: 0.006926
2022-01-14 17:04:29,452 iteration 4821 : loss : 0.019243, loss_ce: 0.009006
2022-01-14 17:04:30,981 iteration 4822 : loss : 0.021950, loss_ce: 0.006605
2022-01-14 17:04:32,462 iteration 4823 : loss : 0.021342, loss_ce: 0.008082
2022-01-14 17:04:34,019 iteration 4824 : loss : 0.017208, loss_ce: 0.005969
2022-01-14 17:04:35,519 iteration 4825 : loss : 0.015376, loss_ce: 0.005509
2022-01-14 17:04:36,997 iteration 4826 : loss : 0.021566, loss_ce: 0.006844
2022-01-14 17:04:38,616 iteration 4827 : loss : 0.016913, loss_ce: 0.005519
2022-01-14 17:04:40,194 iteration 4828 : loss : 0.020512, loss_ce: 0.008559
 71%|████████████████████▌        | 284/400 [2:12:00<51:42, 26.74s/it]2022-01-14 17:04:41,773 iteration 4829 : loss : 0.017121, loss_ce: 0.005907
2022-01-14 17:04:43,219 iteration 4830 : loss : 0.014341, loss_ce: 0.004218
2022-01-14 17:04:44,817 iteration 4831 : loss : 0.051882, loss_ce: 0.016363
2022-01-14 17:04:46,309 iteration 4832 : loss : 0.020727, loss_ce: 0.007863
2022-01-14 17:04:47,914 iteration 4833 : loss : 0.017828, loss_ce: 0.005365
2022-01-14 17:04:49,497 iteration 4834 : loss : 0.019381, loss_ce: 0.007540
2022-01-14 17:04:50,969 iteration 4835 : loss : 0.019686, loss_ce: 0.006937
2022-01-14 17:04:52,461 iteration 4836 : loss : 0.025477, loss_ce: 0.007914
2022-01-14 17:04:53,909 iteration 4837 : loss : 0.020681, loss_ce: 0.004445
2022-01-14 17:04:55,492 iteration 4838 : loss : 0.024365, loss_ce: 0.011859
2022-01-14 17:04:57,019 iteration 4839 : loss : 0.028822, loss_ce: 0.015186
2022-01-14 17:04:58,548 iteration 4840 : loss : 0.019903, loss_ce: 0.007848
2022-01-14 17:05:00,138 iteration 4841 : loss : 0.017200, loss_ce: 0.006878
2022-01-14 17:05:01,673 iteration 4842 : loss : 0.016573, loss_ce: 0.006079
2022-01-14 17:05:03,188 iteration 4843 : loss : 0.021199, loss_ce: 0.008782
2022-01-14 17:05:04,631 iteration 4844 : loss : 0.014420, loss_ce: 0.006610
2022-01-14 17:05:04,631 Training Data Eval:
2022-01-14 17:05:12,142   Average segmentation loss on training set: 0.0116
2022-01-14 17:05:12,142 Validation Data Eval:
2022-01-14 17:05:14,716   Average segmentation loss on validation set: 0.0629
2022-01-14 17:05:16,180 iteration 4845 : loss : 0.019060, loss_ce: 0.006462
 71%|████████████████████▋        | 285/400 [2:12:36<56:34, 29.52s/it]2022-01-14 17:05:17,780 iteration 4846 : loss : 0.017316, loss_ce: 0.006290
2022-01-14 17:05:19,293 iteration 4847 : loss : 0.022084, loss_ce: 0.007292
2022-01-14 17:05:20,968 iteration 4848 : loss : 0.020361, loss_ce: 0.008374
2022-01-14 17:05:22,472 iteration 4849 : loss : 0.024180, loss_ce: 0.011912
2022-01-14 17:05:23,991 iteration 4850 : loss : 0.050932, loss_ce: 0.011271
2022-01-14 17:05:25,547 iteration 4851 : loss : 0.016004, loss_ce: 0.007380
2022-01-14 17:05:27,032 iteration 4852 : loss : 0.017583, loss_ce: 0.007295
2022-01-14 17:05:28,511 iteration 4853 : loss : 0.017152, loss_ce: 0.005806
2022-01-14 17:05:29,926 iteration 4854 : loss : 0.016169, loss_ce: 0.006141
2022-01-14 17:05:31,448 iteration 4855 : loss : 0.019611, loss_ce: 0.007222
2022-01-14 17:05:32,996 iteration 4856 : loss : 0.016723, loss_ce: 0.006318
2022-01-14 17:05:34,575 iteration 4857 : loss : 0.019180, loss_ce: 0.009714
2022-01-14 17:05:36,101 iteration 4858 : loss : 0.021472, loss_ce: 0.007870
2022-01-14 17:05:37,554 iteration 4859 : loss : 0.013295, loss_ce: 0.005099
2022-01-14 17:05:39,043 iteration 4860 : loss : 0.015351, loss_ce: 0.004071
2022-01-14 17:05:40,463 iteration 4861 : loss : 0.029832, loss_ce: 0.007231
2022-01-14 17:05:42,051 iteration 4862 : loss : 0.027623, loss_ce: 0.009331
 72%|████████████████████▋        | 286/400 [2:13:02<53:59, 28.42s/it]2022-01-14 17:05:43,630 iteration 4863 : loss : 0.028088, loss_ce: 0.010891
2022-01-14 17:05:45,144 iteration 4864 : loss : 0.020458, loss_ce: 0.007425
2022-01-14 17:05:46,677 iteration 4865 : loss : 0.016782, loss_ce: 0.006265
2022-01-14 17:05:48,184 iteration 4866 : loss : 0.027520, loss_ce: 0.011431
2022-01-14 17:05:49,739 iteration 4867 : loss : 0.029033, loss_ce: 0.011299
2022-01-14 17:05:51,250 iteration 4868 : loss : 0.028670, loss_ce: 0.015004
2022-01-14 17:05:52,733 iteration 4869 : loss : 0.018245, loss_ce: 0.005323
2022-01-14 17:05:54,131 iteration 4870 : loss : 0.017529, loss_ce: 0.008150
2022-01-14 17:05:55,600 iteration 4871 : loss : 0.019543, loss_ce: 0.006083
2022-01-14 17:05:57,106 iteration 4872 : loss : 0.015023, loss_ce: 0.006571
2022-01-14 17:05:58,628 iteration 4873 : loss : 0.016802, loss_ce: 0.006393
2022-01-14 17:06:00,121 iteration 4874 : loss : 0.014142, loss_ce: 0.004785
2022-01-14 17:06:01,637 iteration 4875 : loss : 0.019048, loss_ce: 0.005619
2022-01-14 17:06:03,074 iteration 4876 : loss : 0.013898, loss_ce: 0.005966
2022-01-14 17:06:04,562 iteration 4877 : loss : 0.011916, loss_ce: 0.004370
2022-01-14 17:06:06,097 iteration 4878 : loss : 0.021815, loss_ce: 0.007756
2022-01-14 17:06:07,682 iteration 4879 : loss : 0.015677, loss_ce: 0.004423
 72%|████████████████████▊        | 287/400 [2:13:27<51:57, 27.58s/it]2022-01-14 17:06:09,261 iteration 4880 : loss : 0.015635, loss_ce: 0.004827
2022-01-14 17:06:10,681 iteration 4881 : loss : 0.013532, loss_ce: 0.004120
2022-01-14 17:06:12,121 iteration 4882 : loss : 0.013194, loss_ce: 0.003270
2022-01-14 17:06:13,670 iteration 4883 : loss : 0.022739, loss_ce: 0.009634
2022-01-14 17:06:15,113 iteration 4884 : loss : 0.024384, loss_ce: 0.011780
2022-01-14 17:06:16,612 iteration 4885 : loss : 0.018531, loss_ce: 0.005035
2022-01-14 17:06:18,168 iteration 4886 : loss : 0.013931, loss_ce: 0.004596
2022-01-14 17:06:19,617 iteration 4887 : loss : 0.022084, loss_ce: 0.008898
2022-01-14 17:06:21,133 iteration 4888 : loss : 0.022497, loss_ce: 0.005777
2022-01-14 17:06:22,634 iteration 4889 : loss : 0.014941, loss_ce: 0.006048
2022-01-14 17:06:24,154 iteration 4890 : loss : 0.017488, loss_ce: 0.006925
2022-01-14 17:06:25,660 iteration 4891 : loss : 0.023066, loss_ce: 0.010420
2022-01-14 17:06:27,202 iteration 4892 : loss : 0.016687, loss_ce: 0.007628
2022-01-14 17:06:28,895 iteration 4893 : loss : 0.021713, loss_ce: 0.007336
2022-01-14 17:06:30,390 iteration 4894 : loss : 0.017323, loss_ce: 0.007030
2022-01-14 17:06:31,900 iteration 4895 : loss : 0.014162, loss_ce: 0.006247
2022-01-14 17:06:33,389 iteration 4896 : loss : 0.013727, loss_ce: 0.004957
 72%|████████████████████▉        | 288/400 [2:13:53<50:26, 27.02s/it]2022-01-14 17:06:34,851 iteration 4897 : loss : 0.011734, loss_ce: 0.005245
2022-01-14 17:06:36,351 iteration 4898 : loss : 0.012214, loss_ce: 0.004249
2022-01-14 17:06:37,797 iteration 4899 : loss : 0.022664, loss_ce: 0.009285
2022-01-14 17:06:39,374 iteration 4900 : loss : 0.021731, loss_ce: 0.009191
2022-01-14 17:06:40,890 iteration 4901 : loss : 0.019611, loss_ce: 0.006464
2022-01-14 17:06:42,329 iteration 4902 : loss : 0.014890, loss_ce: 0.003058
2022-01-14 17:06:43,847 iteration 4903 : loss : 0.013661, loss_ce: 0.005558
2022-01-14 17:06:45,327 iteration 4904 : loss : 0.019097, loss_ce: 0.010110
2022-01-14 17:06:46,807 iteration 4905 : loss : 0.017662, loss_ce: 0.008018
2022-01-14 17:06:48,319 iteration 4906 : loss : 0.015527, loss_ce: 0.005398
2022-01-14 17:06:49,857 iteration 4907 : loss : 0.019431, loss_ce: 0.007363
2022-01-14 17:06:51,244 iteration 4908 : loss : 0.016123, loss_ce: 0.004484
2022-01-14 17:06:52,734 iteration 4909 : loss : 0.016082, loss_ce: 0.004902
2022-01-14 17:06:54,208 iteration 4910 : loss : 0.018934, loss_ce: 0.004626
2022-01-14 17:06:55,833 iteration 4911 : loss : 0.017355, loss_ce: 0.007282
2022-01-14 17:06:57,410 iteration 4912 : loss : 0.030433, loss_ce: 0.010545
2022-01-14 17:06:58,888 iteration 4913 : loss : 0.013870, loss_ce: 0.004437
 72%|████████████████████▉        | 289/400 [2:14:18<49:08, 26.56s/it]2022-01-14 17:07:00,351 iteration 4914 : loss : 0.013667, loss_ce: 0.004056
2022-01-14 17:07:01,860 iteration 4915 : loss : 0.018477, loss_ce: 0.007015
2022-01-14 17:07:03,424 iteration 4916 : loss : 0.027969, loss_ce: 0.009685
2022-01-14 17:07:04,928 iteration 4917 : loss : 0.013545, loss_ce: 0.004685
2022-01-14 17:07:06,389 iteration 4918 : loss : 0.019550, loss_ce: 0.010028
2022-01-14 17:07:07,842 iteration 4919 : loss : 0.017725, loss_ce: 0.006364
2022-01-14 17:07:09,375 iteration 4920 : loss : 0.017195, loss_ce: 0.008685
2022-01-14 17:07:10,860 iteration 4921 : loss : 0.030316, loss_ce: 0.009930
2022-01-14 17:07:12,382 iteration 4922 : loss : 0.017623, loss_ce: 0.003407
2022-01-14 17:07:13,885 iteration 4923 : loss : 0.020598, loss_ce: 0.007093
2022-01-14 17:07:15,396 iteration 4924 : loss : 0.021352, loss_ce: 0.008230
2022-01-14 17:07:17,054 iteration 4925 : loss : 0.033227, loss_ce: 0.016880
2022-01-14 17:07:18,532 iteration 4926 : loss : 0.020690, loss_ce: 0.007091
2022-01-14 17:07:20,093 iteration 4927 : loss : 0.019255, loss_ce: 0.008386
2022-01-14 17:07:21,671 iteration 4928 : loss : 0.019793, loss_ce: 0.009407
2022-01-14 17:07:23,246 iteration 4929 : loss : 0.030435, loss_ce: 0.010555
2022-01-14 17:07:23,247 Training Data Eval:
2022-01-14 17:07:30,736   Average segmentation loss on training set: 0.0111
2022-01-14 17:07:30,737 Validation Data Eval:
2022-01-14 17:07:33,310   Average segmentation loss on validation set: 0.0677
2022-01-14 17:07:34,861 iteration 4930 : loss : 0.013013, loss_ce: 0.005107
 72%|█████████████████████        | 290/400 [2:14:54<53:52, 29.39s/it]2022-01-14 17:07:36,463 iteration 4931 : loss : 0.016716, loss_ce: 0.007466
2022-01-14 17:07:37,907 iteration 4932 : loss : 0.014319, loss_ce: 0.005503
2022-01-14 17:07:39,357 iteration 4933 : loss : 0.018002, loss_ce: 0.006035
2022-01-14 17:07:40,928 iteration 4934 : loss : 0.017443, loss_ce: 0.007961
2022-01-14 17:07:42,466 iteration 4935 : loss : 0.025056, loss_ce: 0.007271
2022-01-14 17:07:43,972 iteration 4936 : loss : 0.016474, loss_ce: 0.007331
2022-01-14 17:07:45,514 iteration 4937 : loss : 0.018823, loss_ce: 0.006536
2022-01-14 17:07:47,030 iteration 4938 : loss : 0.017914, loss_ce: 0.006273
2022-01-14 17:07:48,622 iteration 4939 : loss : 0.020181, loss_ce: 0.007677
2022-01-14 17:07:50,083 iteration 4940 : loss : 0.029688, loss_ce: 0.007303
2022-01-14 17:07:51,618 iteration 4941 : loss : 0.017573, loss_ce: 0.006561
2022-01-14 17:07:53,179 iteration 4942 : loss : 0.016882, loss_ce: 0.006160
2022-01-14 17:07:54,650 iteration 4943 : loss : 0.014559, loss_ce: 0.004736
2022-01-14 17:07:56,150 iteration 4944 : loss : 0.020106, loss_ce: 0.008873
2022-01-14 17:07:57,771 iteration 4945 : loss : 0.022631, loss_ce: 0.005921
2022-01-14 17:07:59,398 iteration 4946 : loss : 0.034624, loss_ce: 0.013441
2022-01-14 17:08:00,999 iteration 4947 : loss : 0.028000, loss_ce: 0.010078
 73%|█████████████████████        | 291/400 [2:15:21<51:37, 28.41s/it]2022-01-14 17:08:02,638 iteration 4948 : loss : 0.016261, loss_ce: 0.005964
2022-01-14 17:08:04,126 iteration 4949 : loss : 0.012972, loss_ce: 0.004968
2022-01-14 17:08:05,589 iteration 4950 : loss : 0.016962, loss_ce: 0.006057
2022-01-14 17:08:07,091 iteration 4951 : loss : 0.024886, loss_ce: 0.008570
2022-01-14 17:08:08,514 iteration 4952 : loss : 0.019278, loss_ce: 0.008262
2022-01-14 17:08:10,097 iteration 4953 : loss : 0.017836, loss_ce: 0.007009
2022-01-14 17:08:11,566 iteration 4954 : loss : 0.024884, loss_ce: 0.011152
2022-01-14 17:08:13,046 iteration 4955 : loss : 0.014471, loss_ce: 0.005459
2022-01-14 17:08:14,535 iteration 4956 : loss : 0.022091, loss_ce: 0.006876
2022-01-14 17:08:16,039 iteration 4957 : loss : 0.013318, loss_ce: 0.005510
2022-01-14 17:08:17,594 iteration 4958 : loss : 0.021706, loss_ce: 0.009997
2022-01-14 17:08:19,017 iteration 4959 : loss : 0.013495, loss_ce: 0.004562
2022-01-14 17:08:20,520 iteration 4960 : loss : 0.017764, loss_ce: 0.006031
2022-01-14 17:08:21,981 iteration 4961 : loss : 0.015049, loss_ce: 0.005910
2022-01-14 17:08:23,530 iteration 4962 : loss : 0.018380, loss_ce: 0.008197
2022-01-14 17:08:24,974 iteration 4963 : loss : 0.015461, loss_ce: 0.006121
2022-01-14 17:08:26,605 iteration 4964 : loss : 0.018724, loss_ce: 0.006624
 73%|█████████████████████▏       | 292/400 [2:15:46<49:37, 27.57s/it]2022-01-14 17:08:28,219 iteration 4965 : loss : 0.021437, loss_ce: 0.006915
2022-01-14 17:08:29,837 iteration 4966 : loss : 0.020883, loss_ce: 0.005397
2022-01-14 17:08:31,241 iteration 4967 : loss : 0.011137, loss_ce: 0.004387
2022-01-14 17:08:32,734 iteration 4968 : loss : 0.015607, loss_ce: 0.005971
2022-01-14 17:08:34,216 iteration 4969 : loss : 0.016548, loss_ce: 0.003676
2022-01-14 17:08:35,675 iteration 4970 : loss : 0.009931, loss_ce: 0.003631
2022-01-14 17:08:37,229 iteration 4971 : loss : 0.016494, loss_ce: 0.006610
2022-01-14 17:08:38,823 iteration 4972 : loss : 0.017675, loss_ce: 0.005713
2022-01-14 17:08:40,305 iteration 4973 : loss : 0.015514, loss_ce: 0.005791
2022-01-14 17:08:41,761 iteration 4974 : loss : 0.016045, loss_ce: 0.006280
2022-01-14 17:08:43,240 iteration 4975 : loss : 0.022527, loss_ce: 0.007206
2022-01-14 17:08:44,720 iteration 4976 : loss : 0.023784, loss_ce: 0.009188
2022-01-14 17:08:46,353 iteration 4977 : loss : 0.018559, loss_ce: 0.009774
2022-01-14 17:08:47,825 iteration 4978 : loss : 0.036649, loss_ce: 0.011851
2022-01-14 17:08:49,332 iteration 4979 : loss : 0.021553, loss_ce: 0.013485
2022-01-14 17:08:50,744 iteration 4980 : loss : 0.010878, loss_ce: 0.003775
2022-01-14 17:08:52,244 iteration 4981 : loss : 0.016559, loss_ce: 0.005553
 73%|█████████████████████▏       | 293/400 [2:16:12<48:07, 26.99s/it]2022-01-14 17:08:53,815 iteration 4982 : loss : 0.019525, loss_ce: 0.008112
2022-01-14 17:08:55,294 iteration 4983 : loss : 0.014484, loss_ce: 0.004976
2022-01-14 17:08:56,862 iteration 4984 : loss : 0.019490, loss_ce: 0.007218
2022-01-14 17:08:58,396 iteration 4985 : loss : 0.015845, loss_ce: 0.005451
2022-01-14 17:08:59,959 iteration 4986 : loss : 0.025778, loss_ce: 0.010195
2022-01-14 17:09:01,434 iteration 4987 : loss : 0.017360, loss_ce: 0.007693
2022-01-14 17:09:02,943 iteration 4988 : loss : 0.026134, loss_ce: 0.010689
2022-01-14 17:09:04,446 iteration 4989 : loss : 0.018271, loss_ce: 0.006232
2022-01-14 17:09:06,038 iteration 4990 : loss : 0.016077, loss_ce: 0.006491
2022-01-14 17:09:07,536 iteration 4991 : loss : 0.022225, loss_ce: 0.005954
2022-01-14 17:09:09,033 iteration 4992 : loss : 0.016556, loss_ce: 0.007744
2022-01-14 17:09:10,591 iteration 4993 : loss : 0.019050, loss_ce: 0.008506
2022-01-14 17:09:12,241 iteration 4994 : loss : 0.022427, loss_ce: 0.005928
2022-01-14 17:09:13,720 iteration 4995 : loss : 0.026940, loss_ce: 0.009562
2022-01-14 17:09:15,225 iteration 4996 : loss : 0.018724, loss_ce: 0.006508
2022-01-14 17:09:16,853 iteration 4997 : loss : 0.022563, loss_ce: 0.009322
2022-01-14 17:09:18,283 iteration 4998 : loss : 0.018090, loss_ce: 0.006020
 74%|█████████████████████▎       | 294/400 [2:16:38<47:10, 26.71s/it]2022-01-14 17:09:19,873 iteration 4999 : loss : 0.017347, loss_ce: 0.006910
2022-01-14 17:09:21,323 iteration 5000 : loss : 0.013678, loss_ce: 0.004931
2022-01-14 17:09:22,819 iteration 5001 : loss : 0.024290, loss_ce: 0.008385
2022-01-14 17:09:24,389 iteration 5002 : loss : 0.025951, loss_ce: 0.010869
2022-01-14 17:09:25,901 iteration 5003 : loss : 0.022527, loss_ce: 0.006168
2022-01-14 17:09:27,476 iteration 5004 : loss : 0.029436, loss_ce: 0.009396
2022-01-14 17:09:28,950 iteration 5005 : loss : 0.015138, loss_ce: 0.005157
2022-01-14 17:09:30,519 iteration 5006 : loss : 0.017839, loss_ce: 0.004631
2022-01-14 17:09:32,002 iteration 5007 : loss : 0.013952, loss_ce: 0.005289
2022-01-14 17:09:33,429 iteration 5008 : loss : 0.014604, loss_ce: 0.005692
2022-01-14 17:09:34,919 iteration 5009 : loss : 0.024465, loss_ce: 0.007841
2022-01-14 17:09:36,530 iteration 5010 : loss : 0.035370, loss_ce: 0.014848
2022-01-14 17:09:38,051 iteration 5011 : loss : 0.017853, loss_ce: 0.009840
2022-01-14 17:09:39,656 iteration 5012 : loss : 0.016943, loss_ce: 0.006920
2022-01-14 17:09:41,312 iteration 5013 : loss : 0.020680, loss_ce: 0.007954
2022-01-14 17:09:42,705 iteration 5014 : loss : 0.013435, loss_ce: 0.004560
2022-01-14 17:09:42,706 Training Data Eval:
2022-01-14 17:09:50,193   Average segmentation loss on training set: 0.0115
2022-01-14 17:09:50,194 Validation Data Eval:
2022-01-14 17:09:52,777   Average segmentation loss on validation set: 0.0849
2022-01-14 17:09:54,288 iteration 5015 : loss : 0.013806, loss_ce: 0.002701
 74%|█████████████████████▍       | 295/400 [2:17:14<51:36, 29.49s/it]2022-01-14 17:09:55,793 iteration 5016 : loss : 0.022928, loss_ce: 0.009133
2022-01-14 17:09:57,316 iteration 5017 : loss : 0.013446, loss_ce: 0.003940
2022-01-14 17:09:58,980 iteration 5018 : loss : 0.017621, loss_ce: 0.005805
2022-01-14 17:10:00,465 iteration 5019 : loss : 0.014819, loss_ce: 0.004122
2022-01-14 17:10:02,038 iteration 5020 : loss : 0.013167, loss_ce: 0.005339
2022-01-14 17:10:03,612 iteration 5021 : loss : 0.023492, loss_ce: 0.009436
2022-01-14 17:10:05,184 iteration 5022 : loss : 0.025497, loss_ce: 0.013045
2022-01-14 17:10:06,724 iteration 5023 : loss : 0.015877, loss_ce: 0.006018
2022-01-14 17:10:08,214 iteration 5024 : loss : 0.011717, loss_ce: 0.004297
2022-01-14 17:10:09,682 iteration 5025 : loss : 0.012343, loss_ce: 0.004627
2022-01-14 17:10:11,185 iteration 5026 : loss : 0.018403, loss_ce: 0.007860
2022-01-14 17:10:12,721 iteration 5027 : loss : 0.015771, loss_ce: 0.004729
2022-01-14 17:10:14,291 iteration 5028 : loss : 0.025080, loss_ce: 0.008766
2022-01-14 17:10:15,780 iteration 5029 : loss : 0.013021, loss_ce: 0.004962
2022-01-14 17:10:17,349 iteration 5030 : loss : 0.021227, loss_ce: 0.006568
2022-01-14 17:10:18,945 iteration 5031 : loss : 0.023979, loss_ce: 0.011007
2022-01-14 17:10:20,505 iteration 5032 : loss : 0.024777, loss_ce: 0.007623
 74%|█████████████████████▍       | 296/400 [2:17:40<49:25, 28.51s/it]2022-01-14 17:10:22,074 iteration 5033 : loss : 0.018058, loss_ce: 0.009114
2022-01-14 17:10:23,589 iteration 5034 : loss : 0.019250, loss_ce: 0.005303
2022-01-14 17:10:25,086 iteration 5035 : loss : 0.020540, loss_ce: 0.006965
2022-01-14 17:10:26,532 iteration 5036 : loss : 0.012275, loss_ce: 0.004285
2022-01-14 17:10:28,051 iteration 5037 : loss : 0.013982, loss_ce: 0.005241
2022-01-14 17:10:29,722 iteration 5038 : loss : 0.030498, loss_ce: 0.013885
2022-01-14 17:10:31,180 iteration 5039 : loss : 0.013304, loss_ce: 0.004416
2022-01-14 17:10:32,757 iteration 5040 : loss : 0.022105, loss_ce: 0.009180
2022-01-14 17:10:34,277 iteration 5041 : loss : 0.016114, loss_ce: 0.005472
2022-01-14 17:10:35,800 iteration 5042 : loss : 0.012567, loss_ce: 0.005117
2022-01-14 17:10:37,298 iteration 5043 : loss : 0.018986, loss_ce: 0.006169
2022-01-14 17:10:38,802 iteration 5044 : loss : 0.015171, loss_ce: 0.005520
2022-01-14 17:10:40,231 iteration 5045 : loss : 0.011409, loss_ce: 0.003382
2022-01-14 17:10:41,766 iteration 5046 : loss : 0.025726, loss_ce: 0.007812
2022-01-14 17:10:43,258 iteration 5047 : loss : 0.016220, loss_ce: 0.006527
2022-01-14 17:10:44,694 iteration 5048 : loss : 0.013218, loss_ce: 0.004838
2022-01-14 17:10:46,273 iteration 5049 : loss : 0.020466, loss_ce: 0.009167
 74%|█████████████████████▌       | 297/400 [2:18:06<47:31, 27.69s/it]2022-01-14 17:10:47,826 iteration 5050 : loss : 0.017147, loss_ce: 0.004171
2022-01-14 17:10:49,257 iteration 5051 : loss : 0.013945, loss_ce: 0.005839
2022-01-14 17:10:50,803 iteration 5052 : loss : 0.016679, loss_ce: 0.007768
2022-01-14 17:10:52,259 iteration 5053 : loss : 0.015215, loss_ce: 0.005470
2022-01-14 17:10:53,797 iteration 5054 : loss : 0.016621, loss_ce: 0.009501
2022-01-14 17:10:55,292 iteration 5055 : loss : 0.013786, loss_ce: 0.004596
2022-01-14 17:10:56,771 iteration 5056 : loss : 0.016392, loss_ce: 0.006082
2022-01-14 17:10:58,260 iteration 5057 : loss : 0.013750, loss_ce: 0.005814
2022-01-14 17:10:59,750 iteration 5058 : loss : 0.018057, loss_ce: 0.005475
2022-01-14 17:11:01,261 iteration 5059 : loss : 0.015948, loss_ce: 0.007341
2022-01-14 17:11:02,793 iteration 5060 : loss : 0.037815, loss_ce: 0.009372
2022-01-14 17:11:04,331 iteration 5061 : loss : 0.015643, loss_ce: 0.007976
2022-01-14 17:11:05,919 iteration 5062 : loss : 0.014636, loss_ce: 0.005120
2022-01-14 17:11:07,403 iteration 5063 : loss : 0.014572, loss_ce: 0.005260
2022-01-14 17:11:08,918 iteration 5064 : loss : 0.018762, loss_ce: 0.004877
2022-01-14 17:11:10,528 iteration 5065 : loss : 0.029686, loss_ce: 0.011154
2022-01-14 17:11:11,917 iteration 5066 : loss : 0.015448, loss_ce: 0.006138
 74%|█████████████████████▌       | 298/400 [2:18:31<46:01, 27.07s/it]2022-01-14 17:11:13,596 iteration 5067 : loss : 0.033183, loss_ce: 0.010568
2022-01-14 17:11:15,097 iteration 5068 : loss : 0.019612, loss_ce: 0.007271
2022-01-14 17:11:16,562 iteration 5069 : loss : 0.026645, loss_ce: 0.009557
2022-01-14 17:11:18,098 iteration 5070 : loss : 0.017435, loss_ce: 0.008566
2022-01-14 17:11:19,706 iteration 5071 : loss : 0.019581, loss_ce: 0.008485
2022-01-14 17:11:21,261 iteration 5072 : loss : 0.012725, loss_ce: 0.003947
2022-01-14 17:11:22,820 iteration 5073 : loss : 0.022569, loss_ce: 0.005533
2022-01-14 17:11:24,372 iteration 5074 : loss : 0.018348, loss_ce: 0.007522
2022-01-14 17:11:25,791 iteration 5075 : loss : 0.015053, loss_ce: 0.006595
2022-01-14 17:11:27,217 iteration 5076 : loss : 0.017782, loss_ce: 0.006840
2022-01-14 17:11:28,798 iteration 5077 : loss : 0.035006, loss_ce: 0.013477
2022-01-14 17:11:30,321 iteration 5078 : loss : 0.018188, loss_ce: 0.006142
2022-01-14 17:11:31,803 iteration 5079 : loss : 0.010781, loss_ce: 0.003809
2022-01-14 17:11:33,334 iteration 5080 : loss : 0.016209, loss_ce: 0.005912
2022-01-14 17:11:34,858 iteration 5081 : loss : 0.043926, loss_ce: 0.020913
2022-01-14 17:11:36,298 iteration 5082 : loss : 0.017124, loss_ce: 0.004375
2022-01-14 17:11:37,771 iteration 5083 : loss : 0.021517, loss_ce: 0.008186
 75%|█████████████████████▋       | 299/400 [2:18:57<44:57, 26.71s/it]2022-01-14 17:11:39,327 iteration 5084 : loss : 0.017621, loss_ce: 0.008204
2022-01-14 17:11:40,977 iteration 5085 : loss : 0.019633, loss_ce: 0.006810
2022-01-14 17:11:42,402 iteration 5086 : loss : 0.012680, loss_ce: 0.003962
2022-01-14 17:11:43,906 iteration 5087 : loss : 0.029610, loss_ce: 0.010123
2022-01-14 17:11:45,327 iteration 5088 : loss : 0.010985, loss_ce: 0.005162
2022-01-14 17:11:46,840 iteration 5089 : loss : 0.016207, loss_ce: 0.006135
2022-01-14 17:11:48,409 iteration 5090 : loss : 0.018916, loss_ce: 0.008186
2022-01-14 17:11:49,929 iteration 5091 : loss : 0.044829, loss_ce: 0.020420
2022-01-14 17:11:51,436 iteration 5092 : loss : 0.016738, loss_ce: 0.003993
2022-01-14 17:11:52,968 iteration 5093 : loss : 0.021794, loss_ce: 0.007573
2022-01-14 17:11:54,492 iteration 5094 : loss : 0.014048, loss_ce: 0.004379
2022-01-14 17:11:56,009 iteration 5095 : loss : 0.016948, loss_ce: 0.008362
2022-01-14 17:11:57,614 iteration 5096 : loss : 0.022659, loss_ce: 0.007076
2022-01-14 17:11:59,140 iteration 5097 : loss : 0.020352, loss_ce: 0.008930
2022-01-14 17:12:00,681 iteration 5098 : loss : 0.015757, loss_ce: 0.006659
2022-01-14 17:12:02,222 iteration 5099 : loss : 0.023887, loss_ce: 0.009038
2022-01-14 17:12:02,223 Training Data Eval:
2022-01-14 17:12:09,748   Average segmentation loss on training set: 0.0110
2022-01-14 17:12:09,749 Validation Data Eval:
2022-01-14 17:12:12,320   Average segmentation loss on validation set: 0.0717
2022-01-14 17:12:13,799 iteration 5100 : loss : 0.016966, loss_ce: 0.005171
 75%|█████████████████████▊       | 300/400 [2:19:33<49:10, 29.51s/it]2022-01-14 17:12:15,406 iteration 5101 : loss : 0.019611, loss_ce: 0.005466
2022-01-14 17:12:17,008 iteration 5102 : loss : 0.016770, loss_ce: 0.008127
2022-01-14 17:12:18,491 iteration 5103 : loss : 0.016017, loss_ce: 0.005985
2022-01-14 17:12:20,028 iteration 5104 : loss : 0.018911, loss_ce: 0.005658
2022-01-14 17:12:21,553 iteration 5105 : loss : 0.017312, loss_ce: 0.005539
2022-01-14 17:12:23,100 iteration 5106 : loss : 0.020970, loss_ce: 0.008049
2022-01-14 17:12:24,654 iteration 5107 : loss : 0.019903, loss_ce: 0.007832
2022-01-14 17:12:26,190 iteration 5108 : loss : 0.016633, loss_ce: 0.007031
2022-01-14 17:12:27,667 iteration 5109 : loss : 0.014059, loss_ce: 0.005409
2022-01-14 17:12:29,046 iteration 5110 : loss : 0.012724, loss_ce: 0.004680
2022-01-14 17:12:30,584 iteration 5111 : loss : 0.015699, loss_ce: 0.004408
2022-01-14 17:12:32,019 iteration 5112 : loss : 0.012140, loss_ce: 0.004995
2022-01-14 17:12:33,645 iteration 5113 : loss : 0.017696, loss_ce: 0.006140
2022-01-14 17:12:35,109 iteration 5114 : loss : 0.013930, loss_ce: 0.005532
2022-01-14 17:12:36,587 iteration 5115 : loss : 0.016575, loss_ce: 0.006600
2022-01-14 17:12:38,089 iteration 5116 : loss : 0.025090, loss_ce: 0.013125
2022-01-14 17:12:39,638 iteration 5117 : loss : 0.017117, loss_ce: 0.006524
 75%|█████████████████████▊       | 301/400 [2:19:59<46:51, 28.40s/it]2022-01-14 17:12:41,210 iteration 5118 : loss : 0.014221, loss_ce: 0.005867
2022-01-14 17:12:42,708 iteration 5119 : loss : 0.031249, loss_ce: 0.009195
2022-01-14 17:12:44,299 iteration 5120 : loss : 0.012651, loss_ce: 0.003268
2022-01-14 17:12:45,741 iteration 5121 : loss : 0.015537, loss_ce: 0.006593
2022-01-14 17:12:47,237 iteration 5122 : loss : 0.023825, loss_ce: 0.006772
2022-01-14 17:12:48,759 iteration 5123 : loss : 0.015268, loss_ce: 0.007719
2022-01-14 17:12:50,221 iteration 5124 : loss : 0.025450, loss_ce: 0.007155
2022-01-14 17:12:51,727 iteration 5125 : loss : 0.015085, loss_ce: 0.005277
2022-01-14 17:12:53,205 iteration 5126 : loss : 0.012716, loss_ce: 0.004658
2022-01-14 17:12:54,746 iteration 5127 : loss : 0.020208, loss_ce: 0.008231
2022-01-14 17:12:56,369 iteration 5128 : loss : 0.022427, loss_ce: 0.007504
2022-01-14 17:12:57,950 iteration 5129 : loss : 0.023289, loss_ce: 0.007636
2022-01-14 17:12:59,389 iteration 5130 : loss : 0.013918, loss_ce: 0.005215
2022-01-14 17:13:00,941 iteration 5131 : loss : 0.013572, loss_ce: 0.003412
2022-01-14 17:13:02,465 iteration 5132 : loss : 0.016059, loss_ce: 0.007415
2022-01-14 17:13:03,949 iteration 5133 : loss : 0.013573, loss_ce: 0.005525
2022-01-14 17:13:05,370 iteration 5134 : loss : 0.010787, loss_ce: 0.003494
 76%|█████████████████████▉       | 302/400 [2:20:25<45:05, 27.61s/it]2022-01-14 17:13:06,949 iteration 5135 : loss : 0.015047, loss_ce: 0.004984
2022-01-14 17:13:08,542 iteration 5136 : loss : 0.021307, loss_ce: 0.008065
2022-01-14 17:13:10,137 iteration 5137 : loss : 0.049598, loss_ce: 0.018577
2022-01-14 17:13:11,716 iteration 5138 : loss : 0.043116, loss_ce: 0.025494
2022-01-14 17:13:13,161 iteration 5139 : loss : 0.009554, loss_ce: 0.003155
2022-01-14 17:13:14,721 iteration 5140 : loss : 0.026161, loss_ce: 0.011565
2022-01-14 17:13:16,185 iteration 5141 : loss : 0.016149, loss_ce: 0.007498
2022-01-14 17:13:17,838 iteration 5142 : loss : 0.018784, loss_ce: 0.007345
2022-01-14 17:13:19,269 iteration 5143 : loss : 0.013361, loss_ce: 0.005658
2022-01-14 17:13:20,718 iteration 5144 : loss : 0.012951, loss_ce: 0.005591
2022-01-14 17:13:22,256 iteration 5145 : loss : 0.019465, loss_ce: 0.007589
2022-01-14 17:13:23,910 iteration 5146 : loss : 0.029182, loss_ce: 0.008539
2022-01-14 17:13:25,431 iteration 5147 : loss : 0.012674, loss_ce: 0.006298
2022-01-14 17:13:26,977 iteration 5148 : loss : 0.018585, loss_ce: 0.006526
2022-01-14 17:13:28,458 iteration 5149 : loss : 0.014028, loss_ce: 0.004750
2022-01-14 17:13:29,944 iteration 5150 : loss : 0.015785, loss_ce: 0.006458
2022-01-14 17:13:31,378 iteration 5151 : loss : 0.011937, loss_ce: 0.004329
 76%|█████████████████████▉       | 303/400 [2:20:51<43:51, 27.12s/it]2022-01-14 17:13:32,987 iteration 5152 : loss : 0.024111, loss_ce: 0.008673
2022-01-14 17:13:34,439 iteration 5153 : loss : 0.011119, loss_ce: 0.005146
2022-01-14 17:13:36,005 iteration 5154 : loss : 0.022219, loss_ce: 0.007985
2022-01-14 17:13:37,454 iteration 5155 : loss : 0.011352, loss_ce: 0.003745
2022-01-14 17:13:38,956 iteration 5156 : loss : 0.018622, loss_ce: 0.007381
2022-01-14 17:13:40,532 iteration 5157 : loss : 0.015899, loss_ce: 0.006121
2022-01-14 17:13:42,067 iteration 5158 : loss : 0.020278, loss_ce: 0.009509
2022-01-14 17:13:43,632 iteration 5159 : loss : 0.024605, loss_ce: 0.007816
2022-01-14 17:13:45,210 iteration 5160 : loss : 0.017048, loss_ce: 0.007185
2022-01-14 17:13:46,798 iteration 5161 : loss : 0.018307, loss_ce: 0.008002
2022-01-14 17:13:48,250 iteration 5162 : loss : 0.014123, loss_ce: 0.003763
2022-01-14 17:13:49,754 iteration 5163 : loss : 0.019982, loss_ce: 0.006849
2022-01-14 17:13:51,185 iteration 5164 : loss : 0.014148, loss_ce: 0.007973
2022-01-14 17:13:52,688 iteration 5165 : loss : 0.017495, loss_ce: 0.006645
2022-01-14 17:13:54,193 iteration 5166 : loss : 0.012979, loss_ce: 0.005553
2022-01-14 17:13:55,652 iteration 5167 : loss : 0.015618, loss_ce: 0.006931
2022-01-14 17:13:57,223 iteration 5168 : loss : 0.020410, loss_ce: 0.007848
 76%|██████████████████████       | 304/400 [2:21:17<42:46, 26.74s/it]2022-01-14 17:13:58,757 iteration 5169 : loss : 0.015919, loss_ce: 0.006338
2022-01-14 17:14:00,261 iteration 5170 : loss : 0.019222, loss_ce: 0.010012
2022-01-14 17:14:01,754 iteration 5171 : loss : 0.022258, loss_ce: 0.004849
2022-01-14 17:14:03,317 iteration 5172 : loss : 0.013278, loss_ce: 0.004451
2022-01-14 17:14:04,815 iteration 5173 : loss : 0.031575, loss_ce: 0.015484
2022-01-14 17:14:06,367 iteration 5174 : loss : 0.019166, loss_ce: 0.007901
2022-01-14 17:14:07,958 iteration 5175 : loss : 0.028048, loss_ce: 0.009317
2022-01-14 17:14:09,453 iteration 5176 : loss : 0.015791, loss_ce: 0.005693
2022-01-14 17:14:11,083 iteration 5177 : loss : 0.035021, loss_ce: 0.015612
2022-01-14 17:14:12,564 iteration 5178 : loss : 0.017496, loss_ce: 0.003560
2022-01-14 17:14:14,141 iteration 5179 : loss : 0.015569, loss_ce: 0.006636
2022-01-14 17:14:15,655 iteration 5180 : loss : 0.015697, loss_ce: 0.006077
2022-01-14 17:14:17,251 iteration 5181 : loss : 0.016229, loss_ce: 0.006285
2022-01-14 17:14:18,798 iteration 5182 : loss : 0.018969, loss_ce: 0.006653
2022-01-14 17:14:20,361 iteration 5183 : loss : 0.020482, loss_ce: 0.005640
2022-01-14 17:14:21,979 iteration 5184 : loss : 0.016364, loss_ce: 0.008127
2022-01-14 17:14:21,980 Training Data Eval:
2022-01-14 17:14:29,482   Average segmentation loss on training set: 0.0103
2022-01-14 17:14:29,483 Validation Data Eval:
2022-01-14 17:14:32,049   Average segmentation loss on validation set: 0.0677
2022-01-14 17:14:33,562 iteration 5185 : loss : 0.016175, loss_ce: 0.006869
 76%|██████████████████████       | 305/400 [2:21:53<46:53, 29.62s/it]2022-01-14 17:14:35,151 iteration 5186 : loss : 0.016315, loss_ce: 0.007851
2022-01-14 17:14:36,763 iteration 5187 : loss : 0.016829, loss_ce: 0.007470
2022-01-14 17:14:38,207 iteration 5188 : loss : 0.017687, loss_ce: 0.004994
2022-01-14 17:14:39,738 iteration 5189 : loss : 0.014294, loss_ce: 0.005761
2022-01-14 17:14:41,199 iteration 5190 : loss : 0.014527, loss_ce: 0.006236
2022-01-14 17:14:42,662 iteration 5191 : loss : 0.017998, loss_ce: 0.006399
2022-01-14 17:14:44,274 iteration 5192 : loss : 0.015601, loss_ce: 0.007075
2022-01-14 17:14:45,825 iteration 5193 : loss : 0.020261, loss_ce: 0.009654
2022-01-14 17:14:47,327 iteration 5194 : loss : 0.016421, loss_ce: 0.006877
2022-01-14 17:14:48,872 iteration 5195 : loss : 0.019421, loss_ce: 0.005776
2022-01-14 17:14:50,546 iteration 5196 : loss : 0.028245, loss_ce: 0.007993
2022-01-14 17:14:51,954 iteration 5197 : loss : 0.013705, loss_ce: 0.004071
2022-01-14 17:14:53,539 iteration 5198 : loss : 0.024423, loss_ce: 0.009630
2022-01-14 17:14:55,095 iteration 5199 : loss : 0.018133, loss_ce: 0.006838
2022-01-14 17:14:56,629 iteration 5200 : loss : 0.013609, loss_ce: 0.004268
2022-01-14 17:14:58,135 iteration 5201 : loss : 0.012489, loss_ce: 0.003649
2022-01-14 17:14:59,627 iteration 5202 : loss : 0.016491, loss_ce: 0.006212
 76%|██████████████████████▏      | 306/400 [2:22:19<44:44, 28.55s/it]2022-01-14 17:15:01,075 iteration 5203 : loss : 0.014086, loss_ce: 0.003821
2022-01-14 17:15:02,624 iteration 5204 : loss : 0.015735, loss_ce: 0.006045
2022-01-14 17:15:04,139 iteration 5205 : loss : 0.015516, loss_ce: 0.005891
2022-01-14 17:15:05,565 iteration 5206 : loss : 0.011878, loss_ce: 0.004814
2022-01-14 17:15:07,083 iteration 5207 : loss : 0.012865, loss_ce: 0.004618
2022-01-14 17:15:08,681 iteration 5208 : loss : 0.018307, loss_ce: 0.006651
2022-01-14 17:15:10,248 iteration 5209 : loss : 0.018522, loss_ce: 0.007187
2022-01-14 17:15:11,758 iteration 5210 : loss : 0.013636, loss_ce: 0.004704
2022-01-14 17:15:13,205 iteration 5211 : loss : 0.014166, loss_ce: 0.003703
2022-01-14 17:15:14,749 iteration 5212 : loss : 0.019140, loss_ce: 0.005041
2022-01-14 17:15:16,283 iteration 5213 : loss : 0.028867, loss_ce: 0.008126
2022-01-14 17:15:17,775 iteration 5214 : loss : 0.021148, loss_ce: 0.011766
2022-01-14 17:15:19,261 iteration 5215 : loss : 0.021020, loss_ce: 0.007435
2022-01-14 17:15:20,757 iteration 5216 : loss : 0.013159, loss_ce: 0.005016
2022-01-14 17:15:22,197 iteration 5217 : loss : 0.012736, loss_ce: 0.004382
2022-01-14 17:15:23,704 iteration 5218 : loss : 0.016141, loss_ce: 0.005281
2022-01-14 17:15:25,237 iteration 5219 : loss : 0.016675, loss_ce: 0.007279
 77%|██████████████████████▎      | 307/400 [2:22:45<42:53, 27.67s/it]2022-01-14 17:15:26,911 iteration 5220 : loss : 0.022280, loss_ce: 0.008178
2022-01-14 17:15:28,380 iteration 5221 : loss : 0.013774, loss_ce: 0.005949
2022-01-14 17:15:29,783 iteration 5222 : loss : 0.013226, loss_ce: 0.003113
2022-01-14 17:15:31,292 iteration 5223 : loss : 0.015391, loss_ce: 0.006032
2022-01-14 17:15:32,854 iteration 5224 : loss : 0.027722, loss_ce: 0.012029
2022-01-14 17:15:34,272 iteration 5225 : loss : 0.013275, loss_ce: 0.003333
2022-01-14 17:15:35,929 iteration 5226 : loss : 0.022036, loss_ce: 0.008584
2022-01-14 17:15:37,321 iteration 5227 : loss : 0.011481, loss_ce: 0.004105
2022-01-14 17:15:38,762 iteration 5228 : loss : 0.010293, loss_ce: 0.004368
2022-01-14 17:15:40,257 iteration 5229 : loss : 0.021625, loss_ce: 0.008607
2022-01-14 17:15:41,796 iteration 5230 : loss : 0.022445, loss_ce: 0.011848
2022-01-14 17:15:43,357 iteration 5231 : loss : 0.028238, loss_ce: 0.008514
2022-01-14 17:15:44,830 iteration 5232 : loss : 0.016452, loss_ce: 0.007764
2022-01-14 17:15:46,362 iteration 5233 : loss : 0.021976, loss_ce: 0.008930
2022-01-14 17:15:47,774 iteration 5234 : loss : 0.011502, loss_ce: 0.004036
2022-01-14 17:15:49,386 iteration 5235 : loss : 0.030591, loss_ce: 0.013045
2022-01-14 17:15:50,914 iteration 5236 : loss : 0.026435, loss_ce: 0.011873
 77%|██████████████████████▎      | 308/400 [2:23:10<41:30, 27.07s/it]2022-01-14 17:15:52,507 iteration 5237 : loss : 0.017292, loss_ce: 0.006039
2022-01-14 17:15:54,026 iteration 5238 : loss : 0.015463, loss_ce: 0.006756
2022-01-14 17:15:55,578 iteration 5239 : loss : 0.012809, loss_ce: 0.003540
2022-01-14 17:15:57,205 iteration 5240 : loss : 0.015007, loss_ce: 0.004963
2022-01-14 17:15:58,759 iteration 5241 : loss : 0.018675, loss_ce: 0.007448
2022-01-14 17:16:00,331 iteration 5242 : loss : 0.022521, loss_ce: 0.009451
2022-01-14 17:16:01,884 iteration 5243 : loss : 0.019727, loss_ce: 0.006722
2022-01-14 17:16:03,451 iteration 5244 : loss : 0.018504, loss_ce: 0.006685
2022-01-14 17:16:04,963 iteration 5245 : loss : 0.017267, loss_ce: 0.005856
2022-01-14 17:16:06,371 iteration 5246 : loss : 0.010257, loss_ce: 0.004476
2022-01-14 17:16:07,876 iteration 5247 : loss : 0.014673, loss_ce: 0.004950
2022-01-14 17:16:09,460 iteration 5248 : loss : 0.014288, loss_ce: 0.005563
2022-01-14 17:16:10,946 iteration 5249 : loss : 0.018514, loss_ce: 0.006860
2022-01-14 17:16:12,444 iteration 5250 : loss : 0.016130, loss_ce: 0.006975
2022-01-14 17:16:14,033 iteration 5251 : loss : 0.015885, loss_ce: 0.005688
2022-01-14 17:16:15,521 iteration 5252 : loss : 0.022287, loss_ce: 0.006535
2022-01-14 17:16:17,073 iteration 5253 : loss : 0.012746, loss_ce: 0.004819
 77%|██████████████████████▍      | 309/400 [2:23:37<40:38, 26.80s/it]2022-01-14 17:16:18,526 iteration 5254 : loss : 0.012711, loss_ce: 0.004363
2022-01-14 17:16:20,104 iteration 5255 : loss : 0.014892, loss_ce: 0.004159
2022-01-14 17:16:21,619 iteration 5256 : loss : 0.013184, loss_ce: 0.005470
2022-01-14 17:16:23,231 iteration 5257 : loss : 0.032576, loss_ce: 0.009593
2022-01-14 17:16:24,691 iteration 5258 : loss : 0.019970, loss_ce: 0.008518
2022-01-14 17:16:26,230 iteration 5259 : loss : 0.017806, loss_ce: 0.004428
2022-01-14 17:16:27,719 iteration 5260 : loss : 0.015664, loss_ce: 0.006681
2022-01-14 17:16:29,216 iteration 5261 : loss : 0.013629, loss_ce: 0.005964
2022-01-14 17:16:30,690 iteration 5262 : loss : 0.009630, loss_ce: 0.004225
2022-01-14 17:16:32,201 iteration 5263 : loss : 0.020133, loss_ce: 0.007737
2022-01-14 17:16:33,697 iteration 5264 : loss : 0.018941, loss_ce: 0.007226
2022-01-14 17:16:35,107 iteration 5265 : loss : 0.012887, loss_ce: 0.004222
2022-01-14 17:16:36,647 iteration 5266 : loss : 0.017290, loss_ce: 0.007179
2022-01-14 17:16:38,123 iteration 5267 : loss : 0.017028, loss_ce: 0.006098
2022-01-14 17:16:39,758 iteration 5268 : loss : 0.024000, loss_ce: 0.011346
2022-01-14 17:16:41,347 iteration 5269 : loss : 0.020140, loss_ce: 0.008549
2022-01-14 17:16:41,348 Training Data Eval:
2022-01-14 17:16:48,824   Average segmentation loss on training set: 0.0095
2022-01-14 17:16:48,825 Validation Data Eval:
2022-01-14 17:16:51,400   Average segmentation loss on validation set: 0.0794
2022-01-14 17:16:52,981 iteration 5270 : loss : 0.025587, loss_ce: 0.008927
 78%|██████████████████████▍      | 310/400 [2:24:13<44:17, 29.53s/it]2022-01-14 17:16:54,592 iteration 5271 : loss : 0.018655, loss_ce: 0.008062
2022-01-14 17:16:56,122 iteration 5272 : loss : 0.023095, loss_ce: 0.009414
2022-01-14 17:16:57,645 iteration 5273 : loss : 0.016282, loss_ce: 0.007987
2022-01-14 17:16:59,127 iteration 5274 : loss : 0.013836, loss_ce: 0.004680
2022-01-14 17:17:00,682 iteration 5275 : loss : 0.018000, loss_ce: 0.005467
2022-01-14 17:17:02,251 iteration 5276 : loss : 0.014065, loss_ce: 0.004289
2022-01-14 17:17:03,657 iteration 5277 : loss : 0.017397, loss_ce: 0.005062
2022-01-14 17:17:05,329 iteration 5278 : loss : 0.023409, loss_ce: 0.010702
2022-01-14 17:17:06,841 iteration 5279 : loss : 0.016866, loss_ce: 0.004994
2022-01-14 17:17:08,418 iteration 5280 : loss : 0.014547, loss_ce: 0.005377
2022-01-14 17:17:09,914 iteration 5281 : loss : 0.017574, loss_ce: 0.008987
2022-01-14 17:17:11,444 iteration 5282 : loss : 0.017040, loss_ce: 0.005991
2022-01-14 17:17:12,968 iteration 5283 : loss : 0.015978, loss_ce: 0.004641
2022-01-14 17:17:14,523 iteration 5284 : loss : 0.012558, loss_ce: 0.005843
2022-01-14 17:17:16,044 iteration 5285 : loss : 0.015955, loss_ce: 0.007349
2022-01-14 17:17:17,605 iteration 5286 : loss : 0.013873, loss_ce: 0.004750
2022-01-14 17:17:19,222 iteration 5287 : loss : 0.019798, loss_ce: 0.008654
 78%|██████████████████████▌      | 311/400 [2:24:39<42:20, 28.54s/it]2022-01-14 17:17:20,693 iteration 5288 : loss : 0.015304, loss_ce: 0.005741
2022-01-14 17:17:22,198 iteration 5289 : loss : 0.015784, loss_ce: 0.005074
2022-01-14 17:17:23,807 iteration 5290 : loss : 0.019705, loss_ce: 0.008218
2022-01-14 17:17:25,395 iteration 5291 : loss : 0.017226, loss_ce: 0.006412
2022-01-14 17:17:26,969 iteration 5292 : loss : 0.011522, loss_ce: 0.004174
2022-01-14 17:17:28,464 iteration 5293 : loss : 0.015385, loss_ce: 0.004589
2022-01-14 17:17:30,051 iteration 5294 : loss : 0.021666, loss_ce: 0.008947
2022-01-14 17:17:31,541 iteration 5295 : loss : 0.011520, loss_ce: 0.004269
2022-01-14 17:17:33,081 iteration 5296 : loss : 0.017347, loss_ce: 0.005309
2022-01-14 17:17:34,644 iteration 5297 : loss : 0.017633, loss_ce: 0.005511
2022-01-14 17:17:36,106 iteration 5298 : loss : 0.012866, loss_ce: 0.005904
2022-01-14 17:17:37,684 iteration 5299 : loss : 0.017739, loss_ce: 0.007507
2022-01-14 17:17:39,116 iteration 5300 : loss : 0.013349, loss_ce: 0.004998
2022-01-14 17:17:40,639 iteration 5301 : loss : 0.018717, loss_ce: 0.006443
2022-01-14 17:17:42,123 iteration 5302 : loss : 0.013590, loss_ce: 0.006312
2022-01-14 17:17:43,536 iteration 5303 : loss : 0.011758, loss_ce: 0.004225
2022-01-14 17:17:45,111 iteration 5304 : loss : 0.017278, loss_ce: 0.006542
 78%|██████████████████████▌      | 312/400 [2:25:05<40:41, 27.75s/it]2022-01-14 17:17:46,696 iteration 5305 : loss : 0.017455, loss_ce: 0.006043
2022-01-14 17:17:48,215 iteration 5306 : loss : 0.033415, loss_ce: 0.011605
2022-01-14 17:17:49,723 iteration 5307 : loss : 0.013395, loss_ce: 0.005015
2022-01-14 17:17:51,258 iteration 5308 : loss : 0.013540, loss_ce: 0.005257
2022-01-14 17:17:52,764 iteration 5309 : loss : 0.015020, loss_ce: 0.006161
2022-01-14 17:17:54,290 iteration 5310 : loss : 0.014861, loss_ce: 0.006270
2022-01-14 17:17:55,812 iteration 5311 : loss : 0.016274, loss_ce: 0.006326
2022-01-14 17:17:57,302 iteration 5312 : loss : 0.013353, loss_ce: 0.003898
2022-01-14 17:17:58,854 iteration 5313 : loss : 0.019495, loss_ce: 0.005044
2022-01-14 17:18:00,333 iteration 5314 : loss : 0.013006, loss_ce: 0.005189
2022-01-14 17:18:01,877 iteration 5315 : loss : 0.018575, loss_ce: 0.007763
2022-01-14 17:18:03,250 iteration 5316 : loss : 0.010538, loss_ce: 0.004675
2022-01-14 17:18:04,790 iteration 5317 : loss : 0.014231, loss_ce: 0.005121
2022-01-14 17:18:06,338 iteration 5318 : loss : 0.015934, loss_ce: 0.005151
2022-01-14 17:18:07,906 iteration 5319 : loss : 0.020077, loss_ce: 0.006336
2022-01-14 17:18:09,440 iteration 5320 : loss : 0.019869, loss_ce: 0.008063
2022-01-14 17:18:10,868 iteration 5321 : loss : 0.021663, loss_ce: 0.006134
 78%|██████████████████████▋      | 313/400 [2:25:30<39:22, 27.15s/it]2022-01-14 17:18:12,488 iteration 5322 : loss : 0.017514, loss_ce: 0.007922
2022-01-14 17:18:14,078 iteration 5323 : loss : 0.033040, loss_ce: 0.008728
2022-01-14 17:18:15,692 iteration 5324 : loss : 0.015175, loss_ce: 0.006353
2022-01-14 17:18:17,227 iteration 5325 : loss : 0.015834, loss_ce: 0.005598
2022-01-14 17:18:18,836 iteration 5326 : loss : 0.021792, loss_ce: 0.006127
2022-01-14 17:18:20,398 iteration 5327 : loss : 0.020167, loss_ce: 0.007890
2022-01-14 17:18:21,896 iteration 5328 : loss : 0.014837, loss_ce: 0.005866
2022-01-14 17:18:23,429 iteration 5329 : loss : 0.014529, loss_ce: 0.004880
2022-01-14 17:18:24,943 iteration 5330 : loss : 0.020911, loss_ce: 0.008568
2022-01-14 17:18:26,407 iteration 5331 : loss : 0.011729, loss_ce: 0.004493
2022-01-14 17:18:28,155 iteration 5332 : loss : 0.026639, loss_ce: 0.011367
2022-01-14 17:18:29,612 iteration 5333 : loss : 0.017161, loss_ce: 0.005960
2022-01-14 17:18:30,993 iteration 5334 : loss : 0.018602, loss_ce: 0.005092
2022-01-14 17:18:32,486 iteration 5335 : loss : 0.013902, loss_ce: 0.003929
2022-01-14 17:18:33,984 iteration 5336 : loss : 0.014364, loss_ce: 0.005094
2022-01-14 17:18:35,509 iteration 5337 : loss : 0.017735, loss_ce: 0.007219
2022-01-14 17:18:37,052 iteration 5338 : loss : 0.018615, loss_ce: 0.007384
 78%|██████████████████████▊      | 314/400 [2:25:57<38:30, 26.86s/it]2022-01-14 17:18:38,602 iteration 5339 : loss : 0.016204, loss_ce: 0.006288
2022-01-14 17:18:40,076 iteration 5340 : loss : 0.013633, loss_ce: 0.005080
2022-01-14 17:18:41,649 iteration 5341 : loss : 0.037193, loss_ce: 0.013782
2022-01-14 17:18:43,219 iteration 5342 : loss : 0.016997, loss_ce: 0.005482
2022-01-14 17:18:44,789 iteration 5343 : loss : 0.017427, loss_ce: 0.006643
2022-01-14 17:18:46,260 iteration 5344 : loss : 0.012972, loss_ce: 0.005262
2022-01-14 17:18:47,786 iteration 5345 : loss : 0.014239, loss_ce: 0.005741
2022-01-14 17:18:49,262 iteration 5346 : loss : 0.017751, loss_ce: 0.006260
2022-01-14 17:18:50,818 iteration 5347 : loss : 0.012248, loss_ce: 0.004890
2022-01-14 17:18:52,273 iteration 5348 : loss : 0.014790, loss_ce: 0.005346
2022-01-14 17:18:53,714 iteration 5349 : loss : 0.014715, loss_ce: 0.005485
2022-01-14 17:18:55,219 iteration 5350 : loss : 0.016816, loss_ce: 0.004869
2022-01-14 17:18:56,661 iteration 5351 : loss : 0.013803, loss_ce: 0.004963
2022-01-14 17:18:58,274 iteration 5352 : loss : 0.019886, loss_ce: 0.007938
2022-01-14 17:18:59,789 iteration 5353 : loss : 0.017439, loss_ce: 0.007042
2022-01-14 17:19:01,225 iteration 5354 : loss : 0.015729, loss_ce: 0.006696
2022-01-14 17:19:01,225 Training Data Eval:
2022-01-14 17:19:08,731   Average segmentation loss on training set: 0.0104
2022-01-14 17:19:08,732 Validation Data Eval:
2022-01-14 17:19:11,302   Average segmentation loss on validation set: 0.0813
2022-01-14 17:19:12,826 iteration 5355 : loss : 0.020935, loss_ce: 0.008875
 79%|██████████████████████▊      | 315/400 [2:26:32<41:50, 29.53s/it]2022-01-14 17:19:14,428 iteration 5356 : loss : 0.032015, loss_ce: 0.013904
2022-01-14 17:19:15,909 iteration 5357 : loss : 0.009989, loss_ce: 0.003487
2022-01-14 17:19:17,372 iteration 5358 : loss : 0.016843, loss_ce: 0.007034
2022-01-14 17:19:18,843 iteration 5359 : loss : 0.013764, loss_ce: 0.004650
2022-01-14 17:19:20,428 iteration 5360 : loss : 0.017004, loss_ce: 0.006463
2022-01-14 17:19:21,913 iteration 5361 : loss : 0.016049, loss_ce: 0.007559
2022-01-14 17:19:23,480 iteration 5362 : loss : 0.016255, loss_ce: 0.006238
2022-01-14 17:19:25,153 iteration 5363 : loss : 0.020409, loss_ce: 0.008282
2022-01-14 17:19:26,685 iteration 5364 : loss : 0.022171, loss_ce: 0.005769
2022-01-14 17:19:28,213 iteration 5365 : loss : 0.021996, loss_ce: 0.006433
2022-01-14 17:19:29,704 iteration 5366 : loss : 0.016287, loss_ce: 0.005469
2022-01-14 17:19:31,124 iteration 5367 : loss : 0.013628, loss_ce: 0.004694
2022-01-14 17:19:32,782 iteration 5368 : loss : 0.018819, loss_ce: 0.007044
2022-01-14 17:19:34,260 iteration 5369 : loss : 0.010902, loss_ce: 0.004068
2022-01-14 17:19:35,722 iteration 5370 : loss : 0.016517, loss_ce: 0.007377
2022-01-14 17:19:37,206 iteration 5371 : loss : 0.013197, loss_ce: 0.003373
2022-01-14 17:19:38,629 iteration 5372 : loss : 0.011992, loss_ce: 0.004621
 79%|██████████████████████▉      | 316/400 [2:26:58<39:46, 28.42s/it]2022-01-14 17:19:40,179 iteration 5373 : loss : 0.014671, loss_ce: 0.005880
2022-01-14 17:19:41,622 iteration 5374 : loss : 0.014089, loss_ce: 0.003293
2022-01-14 17:19:43,130 iteration 5375 : loss : 0.013516, loss_ce: 0.004844
2022-01-14 17:19:44,660 iteration 5376 : loss : 0.017059, loss_ce: 0.007130
2022-01-14 17:19:46,176 iteration 5377 : loss : 0.019446, loss_ce: 0.004479
2022-01-14 17:19:47,688 iteration 5378 : loss : 0.019838, loss_ce: 0.005388
2022-01-14 17:19:49,178 iteration 5379 : loss : 0.017610, loss_ce: 0.006256
2022-01-14 17:19:50,594 iteration 5380 : loss : 0.013099, loss_ce: 0.005345
2022-01-14 17:19:52,198 iteration 5381 : loss : 0.014688, loss_ce: 0.005843
2022-01-14 17:19:53,700 iteration 5382 : loss : 0.025952, loss_ce: 0.016123
2022-01-14 17:19:55,204 iteration 5383 : loss : 0.016811, loss_ce: 0.007812
2022-01-14 17:19:56,706 iteration 5384 : loss : 0.013025, loss_ce: 0.006073
2022-01-14 17:19:58,241 iteration 5385 : loss : 0.016647, loss_ce: 0.006121
2022-01-14 17:19:59,732 iteration 5386 : loss : 0.017690, loss_ce: 0.006292
2022-01-14 17:20:01,354 iteration 5387 : loss : 0.016840, loss_ce: 0.006583
2022-01-14 17:20:02,884 iteration 5388 : loss : 0.012295, loss_ce: 0.003648
2022-01-14 17:20:04,458 iteration 5389 : loss : 0.024034, loss_ce: 0.011439
 79%|██████████████████████▉      | 317/400 [2:27:24<38:14, 27.64s/it]2022-01-14 17:20:05,974 iteration 5390 : loss : 0.011172, loss_ce: 0.003750
2022-01-14 17:20:07,573 iteration 5391 : loss : 0.023947, loss_ce: 0.009246
2022-01-14 17:20:09,065 iteration 5392 : loss : 0.015861, loss_ce: 0.004825
2022-01-14 17:20:10,546 iteration 5393 : loss : 0.012614, loss_ce: 0.004158
2022-01-14 17:20:12,015 iteration 5394 : loss : 0.011745, loss_ce: 0.003376
2022-01-14 17:20:13,531 iteration 5395 : loss : 0.016053, loss_ce: 0.005074
2022-01-14 17:20:14,973 iteration 5396 : loss : 0.014715, loss_ce: 0.005174
2022-01-14 17:20:16,542 iteration 5397 : loss : 0.017966, loss_ce: 0.007462
2022-01-14 17:20:18,215 iteration 5398 : loss : 0.022442, loss_ce: 0.006529
2022-01-14 17:20:19,751 iteration 5399 : loss : 0.017461, loss_ce: 0.005369
2022-01-14 17:20:21,236 iteration 5400 : loss : 0.015251, loss_ce: 0.006204
2022-01-14 17:20:22,818 iteration 5401 : loss : 0.017055, loss_ce: 0.009268
2022-01-14 17:20:24,315 iteration 5402 : loss : 0.022376, loss_ce: 0.012608
2022-01-14 17:20:25,821 iteration 5403 : loss : 0.014070, loss_ce: 0.005694
2022-01-14 17:20:27,358 iteration 5404 : loss : 0.013849, loss_ce: 0.007071
2022-01-14 17:20:29,024 iteration 5405 : loss : 0.019973, loss_ce: 0.006784
2022-01-14 17:20:30,522 iteration 5406 : loss : 0.011108, loss_ce: 0.004914
 80%|███████████████████████      | 318/400 [2:27:50<37:07, 27.16s/it]2022-01-14 17:20:32,050 iteration 5407 : loss : 0.015795, loss_ce: 0.006866
2022-01-14 17:20:33,542 iteration 5408 : loss : 0.017673, loss_ce: 0.006562
2022-01-14 17:20:34,957 iteration 5409 : loss : 0.011258, loss_ce: 0.003768
2022-01-14 17:20:36,468 iteration 5410 : loss : 0.016111, loss_ce: 0.005527
2022-01-14 17:20:37,962 iteration 5411 : loss : 0.014567, loss_ce: 0.005601
2022-01-14 17:20:39,490 iteration 5412 : loss : 0.016887, loss_ce: 0.006498
2022-01-14 17:20:40,994 iteration 5413 : loss : 0.013271, loss_ce: 0.005654
2022-01-14 17:20:42,523 iteration 5414 : loss : 0.012974, loss_ce: 0.005183
2022-01-14 17:20:44,114 iteration 5415 : loss : 0.017704, loss_ce: 0.006031
2022-01-14 17:20:45,564 iteration 5416 : loss : 0.012874, loss_ce: 0.004290
2022-01-14 17:20:47,092 iteration 5417 : loss : 0.013326, loss_ce: 0.004082
2022-01-14 17:20:48,660 iteration 5418 : loss : 0.016293, loss_ce: 0.007292
2022-01-14 17:20:50,089 iteration 5419 : loss : 0.013919, loss_ce: 0.005762
2022-01-14 17:20:51,499 iteration 5420 : loss : 0.012081, loss_ce: 0.004858
2022-01-14 17:20:53,071 iteration 5421 : loss : 0.036097, loss_ce: 0.013630
2022-01-14 17:20:54,634 iteration 5422 : loss : 0.043658, loss_ce: 0.012016
2022-01-14 17:20:56,219 iteration 5423 : loss : 0.016992, loss_ce: 0.007238
 80%|███████████████████████▏     | 319/400 [2:28:16<36:04, 26.73s/it]2022-01-14 17:20:57,760 iteration 5424 : loss : 0.014382, loss_ce: 0.004321
2022-01-14 17:20:59,221 iteration 5425 : loss : 0.023689, loss_ce: 0.005136
2022-01-14 17:21:00,789 iteration 5426 : loss : 0.017704, loss_ce: 0.008234
2022-01-14 17:21:02,217 iteration 5427 : loss : 0.013343, loss_ce: 0.003848
2022-01-14 17:21:03,741 iteration 5428 : loss : 0.010907, loss_ce: 0.003698
2022-01-14 17:21:05,239 iteration 5429 : loss : 0.020752, loss_ce: 0.007168
2022-01-14 17:21:06,879 iteration 5430 : loss : 0.020883, loss_ce: 0.006460
2022-01-14 17:21:08,381 iteration 5431 : loss : 0.016795, loss_ce: 0.006533
2022-01-14 17:21:09,901 iteration 5432 : loss : 0.029445, loss_ce: 0.011220
2022-01-14 17:21:11,481 iteration 5433 : loss : 0.017902, loss_ce: 0.007408
2022-01-14 17:21:12,982 iteration 5434 : loss : 0.020521, loss_ce: 0.007827
2022-01-14 17:21:14,641 iteration 5435 : loss : 0.017691, loss_ce: 0.008356
2022-01-14 17:21:16,119 iteration 5436 : loss : 0.013268, loss_ce: 0.005278
2022-01-14 17:21:17,474 iteration 5437 : loss : 0.011827, loss_ce: 0.004416
2022-01-14 17:21:19,112 iteration 5438 : loss : 0.020100, loss_ce: 0.007924
2022-01-14 17:21:20,579 iteration 5439 : loss : 0.011605, loss_ce: 0.004792
2022-01-14 17:21:20,580 Training Data Eval:
2022-01-14 17:21:28,094   Average segmentation loss on training set: 0.0099
2022-01-14 17:21:28,095 Validation Data Eval:
2022-01-14 17:21:30,673   Average segmentation loss on validation set: 0.0742
2022-01-14 17:21:32,239 iteration 5440 : loss : 0.024813, loss_ce: 0.006515
 80%|███████████████████████▏     | 320/400 [2:28:52<39:21, 29.51s/it]2022-01-14 17:21:33,683 iteration 5441 : loss : 0.014329, loss_ce: 0.004146
2022-01-14 17:21:35,229 iteration 5442 : loss : 0.018076, loss_ce: 0.006062
2022-01-14 17:21:36,788 iteration 5443 : loss : 0.010387, loss_ce: 0.003056
2022-01-14 17:21:38,325 iteration 5444 : loss : 0.012831, loss_ce: 0.004521
2022-01-14 17:21:39,930 iteration 5445 : loss : 0.031436, loss_ce: 0.012397
2022-01-14 17:21:41,427 iteration 5446 : loss : 0.015948, loss_ce: 0.004681
2022-01-14 17:21:42,899 iteration 5447 : loss : 0.015538, loss_ce: 0.006483
2022-01-14 17:21:44,400 iteration 5448 : loss : 0.020679, loss_ce: 0.006950
2022-01-14 17:21:45,904 iteration 5449 : loss : 0.016313, loss_ce: 0.005302
2022-01-14 17:21:47,515 iteration 5450 : loss : 0.020859, loss_ce: 0.010028
2022-01-14 17:21:49,051 iteration 5451 : loss : 0.015569, loss_ce: 0.006007
2022-01-14 17:21:50,579 iteration 5452 : loss : 0.014054, loss_ce: 0.005373
2022-01-14 17:21:52,086 iteration 5453 : loss : 0.018882, loss_ce: 0.006106
2022-01-14 17:21:53,492 iteration 5454 : loss : 0.009629, loss_ce: 0.004452
2022-01-14 17:21:55,178 iteration 5455 : loss : 0.028841, loss_ce: 0.010764
2022-01-14 17:21:56,723 iteration 5456 : loss : 0.015677, loss_ce: 0.006085
2022-01-14 17:21:58,257 iteration 5457 : loss : 0.014931, loss_ce: 0.005211
 80%|███████████████████████▎     | 321/400 [2:29:18<37:28, 28.47s/it]2022-01-14 17:21:59,798 iteration 5458 : loss : 0.014713, loss_ce: 0.005781
2022-01-14 17:22:01,287 iteration 5459 : loss : 0.011527, loss_ce: 0.004206
2022-01-14 17:22:02,839 iteration 5460 : loss : 0.017287, loss_ce: 0.007376
2022-01-14 17:22:04,433 iteration 5461 : loss : 0.015944, loss_ce: 0.006811
2022-01-14 17:22:05,963 iteration 5462 : loss : 0.030997, loss_ce: 0.010105
2022-01-14 17:22:07,469 iteration 5463 : loss : 0.014159, loss_ce: 0.005408
2022-01-14 17:22:08,946 iteration 5464 : loss : 0.015980, loss_ce: 0.006164
2022-01-14 17:22:10,407 iteration 5465 : loss : 0.016517, loss_ce: 0.005514
2022-01-14 17:22:12,046 iteration 5466 : loss : 0.014088, loss_ce: 0.005524
2022-01-14 17:22:13,569 iteration 5467 : loss : 0.013878, loss_ce: 0.006400
2022-01-14 17:22:15,102 iteration 5468 : loss : 0.016209, loss_ce: 0.007939
2022-01-14 17:22:16,543 iteration 5469 : loss : 0.010751, loss_ce: 0.003753
2022-01-14 17:22:18,099 iteration 5470 : loss : 0.017030, loss_ce: 0.006312
2022-01-14 17:22:19,607 iteration 5471 : loss : 0.014412, loss_ce: 0.005413
2022-01-14 17:22:21,234 iteration 5472 : loss : 0.013909, loss_ce: 0.004721
2022-01-14 17:22:22,767 iteration 5473 : loss : 0.039395, loss_ce: 0.012788
2022-01-14 17:22:24,338 iteration 5474 : loss : 0.022173, loss_ce: 0.009764
 80%|███████████████████████▎     | 322/400 [2:29:44<36:04, 27.75s/it]2022-01-14 17:22:25,908 iteration 5475 : loss : 0.012785, loss_ce: 0.003478
2022-01-14 17:22:27,413 iteration 5476 : loss : 0.017156, loss_ce: 0.005032
2022-01-14 17:22:28,909 iteration 5477 : loss : 0.013064, loss_ce: 0.005260
2022-01-14 17:22:30,427 iteration 5478 : loss : 0.014476, loss_ce: 0.006164
2022-01-14 17:22:32,058 iteration 5479 : loss : 0.019221, loss_ce: 0.009497
2022-01-14 17:22:33,657 iteration 5480 : loss : 0.017049, loss_ce: 0.006750
2022-01-14 17:22:35,194 iteration 5481 : loss : 0.014782, loss_ce: 0.004559
2022-01-14 17:22:36,712 iteration 5482 : loss : 0.011264, loss_ce: 0.003856
2022-01-14 17:22:38,262 iteration 5483 : loss : 0.017334, loss_ce: 0.007287
2022-01-14 17:22:39,740 iteration 5484 : loss : 0.015758, loss_ce: 0.006511
2022-01-14 17:22:41,120 iteration 5485 : loss : 0.012054, loss_ce: 0.004120
2022-01-14 17:22:42,740 iteration 5486 : loss : 0.028342, loss_ce: 0.011106
2022-01-14 17:22:44,396 iteration 5487 : loss : 0.017502, loss_ce: 0.007099
2022-01-14 17:22:45,925 iteration 5488 : loss : 0.018024, loss_ce: 0.006753
2022-01-14 17:22:47,471 iteration 5489 : loss : 0.014881, loss_ce: 0.005813
2022-01-14 17:22:48,971 iteration 5490 : loss : 0.021017, loss_ce: 0.007572
2022-01-14 17:22:50,460 iteration 5491 : loss : 0.013343, loss_ce: 0.005287
 81%|███████████████████████▍     | 323/400 [2:30:10<34:58, 27.26s/it]2022-01-14 17:22:52,038 iteration 5492 : loss : 0.016247, loss_ce: 0.006006
2022-01-14 17:22:53,518 iteration 5493 : loss : 0.014785, loss_ce: 0.006354
2022-01-14 17:22:54,988 iteration 5494 : loss : 0.015867, loss_ce: 0.004210
2022-01-14 17:22:56,585 iteration 5495 : loss : 0.055434, loss_ce: 0.012478
2022-01-14 17:22:58,073 iteration 5496 : loss : 0.011291, loss_ce: 0.003373
2022-01-14 17:22:59,612 iteration 5497 : loss : 0.013478, loss_ce: 0.004327
2022-01-14 17:23:01,160 iteration 5498 : loss : 0.024657, loss_ce: 0.014712
2022-01-14 17:23:02,671 iteration 5499 : loss : 0.019734, loss_ce: 0.008247
2022-01-14 17:23:04,196 iteration 5500 : loss : 0.028268, loss_ce: 0.010555
2022-01-14 17:23:05,830 iteration 5501 : loss : 0.018713, loss_ce: 0.007307
2022-01-14 17:23:07,399 iteration 5502 : loss : 0.018620, loss_ce: 0.007587
2022-01-14 17:23:08,895 iteration 5503 : loss : 0.016561, loss_ce: 0.004332
2022-01-14 17:23:10,426 iteration 5504 : loss : 0.018290, loss_ce: 0.008778
2022-01-14 17:23:11,951 iteration 5505 : loss : 0.015464, loss_ce: 0.006282
2022-01-14 17:23:13,429 iteration 5506 : loss : 0.015621, loss_ce: 0.005957
2022-01-14 17:23:14,933 iteration 5507 : loss : 0.023774, loss_ce: 0.008407
2022-01-14 17:23:16,447 iteration 5508 : loss : 0.015965, loss_ce: 0.006495
 81%|███████████████████████▍     | 324/400 [2:30:36<34:02, 26.88s/it]2022-01-14 17:23:17,968 iteration 5509 : loss : 0.015434, loss_ce: 0.005184
2022-01-14 17:23:19,612 iteration 5510 : loss : 0.022053, loss_ce: 0.006332
2022-01-14 17:23:21,111 iteration 5511 : loss : 0.018368, loss_ce: 0.009250
2022-01-14 17:23:22,721 iteration 5512 : loss : 0.013820, loss_ce: 0.002541
2022-01-14 17:23:24,170 iteration 5513 : loss : 0.017711, loss_ce: 0.005197
2022-01-14 17:23:25,762 iteration 5514 : loss : 0.015445, loss_ce: 0.005986
2022-01-14 17:23:27,356 iteration 5515 : loss : 0.023048, loss_ce: 0.006856
2022-01-14 17:23:28,779 iteration 5516 : loss : 0.011806, loss_ce: 0.004431
2022-01-14 17:23:30,348 iteration 5517 : loss : 0.020484, loss_ce: 0.006973
2022-01-14 17:23:31,809 iteration 5518 : loss : 0.016123, loss_ce: 0.006478
2022-01-14 17:23:33,298 iteration 5519 : loss : 0.025172, loss_ce: 0.008629
2022-01-14 17:23:34,843 iteration 5520 : loss : 0.025529, loss_ce: 0.009414
2022-01-14 17:23:36,529 iteration 5521 : loss : 0.013827, loss_ce: 0.004485
2022-01-14 17:23:37,948 iteration 5522 : loss : 0.012173, loss_ce: 0.005420
2022-01-14 17:23:39,502 iteration 5523 : loss : 0.015798, loss_ce: 0.006504
2022-01-14 17:23:41,048 iteration 5524 : loss : 0.018300, loss_ce: 0.008643
2022-01-14 17:23:41,048 Training Data Eval:
2022-01-14 17:23:48,600   Average segmentation loss on training set: 0.0095
2022-01-14 17:23:48,601 Validation Data Eval:
2022-01-14 17:23:51,177   Average segmentation loss on validation set: 0.0896
2022-01-14 17:23:52,807 iteration 5525 : loss : 0.028693, loss_ce: 0.011816
 81%|███████████████████████▌     | 325/400 [2:31:12<37:09, 29.73s/it]2022-01-14 17:23:54,470 iteration 5526 : loss : 0.018247, loss_ce: 0.007044
2022-01-14 17:23:55,982 iteration 5527 : loss : 0.028982, loss_ce: 0.014951
2022-01-14 17:23:57,553 iteration 5528 : loss : 0.018970, loss_ce: 0.006709
2022-01-14 17:23:59,050 iteration 5529 : loss : 0.017000, loss_ce: 0.006026
2022-01-14 17:24:00,501 iteration 5530 : loss : 0.011894, loss_ce: 0.003216
2022-01-14 17:24:02,006 iteration 5531 : loss : 0.012206, loss_ce: 0.004356
2022-01-14 17:24:03,432 iteration 5532 : loss : 0.025546, loss_ce: 0.008270
2022-01-14 17:24:04,995 iteration 5533 : loss : 0.015219, loss_ce: 0.006331
2022-01-14 17:24:06,541 iteration 5534 : loss : 0.018658, loss_ce: 0.006359
2022-01-14 17:24:08,126 iteration 5535 : loss : 0.016783, loss_ce: 0.006750
2022-01-14 17:24:09,621 iteration 5536 : loss : 0.015003, loss_ce: 0.004516
2022-01-14 17:24:11,148 iteration 5537 : loss : 0.015241, loss_ce: 0.004807
2022-01-14 17:24:12,622 iteration 5538 : loss : 0.014314, loss_ce: 0.007408
2022-01-14 17:24:14,149 iteration 5539 : loss : 0.015775, loss_ce: 0.006208
2022-01-14 17:24:15,704 iteration 5540 : loss : 0.014758, loss_ce: 0.005055
2022-01-14 17:24:17,142 iteration 5541 : loss : 0.019973, loss_ce: 0.008582
2022-01-14 17:24:18,643 iteration 5542 : loss : 0.016009, loss_ce: 0.006956
 82%|███████████████████████▋     | 326/400 [2:31:38<35:13, 28.56s/it]2022-01-14 17:24:20,284 iteration 5543 : loss : 0.025736, loss_ce: 0.010525
2022-01-14 17:24:21,993 iteration 5544 : loss : 0.019863, loss_ce: 0.005619
2022-01-14 17:24:23,600 iteration 5545 : loss : 0.019021, loss_ce: 0.007628
2022-01-14 17:24:25,012 iteration 5546 : loss : 0.009317, loss_ce: 0.004381
2022-01-14 17:24:26,590 iteration 5547 : loss : 0.012334, loss_ce: 0.005135
2022-01-14 17:24:28,044 iteration 5548 : loss : 0.013350, loss_ce: 0.004232
2022-01-14 17:24:29,547 iteration 5549 : loss : 0.012564, loss_ce: 0.004909
2022-01-14 17:24:31,097 iteration 5550 : loss : 0.018042, loss_ce: 0.006813
2022-01-14 17:24:32,642 iteration 5551 : loss : 0.012312, loss_ce: 0.002935
2022-01-14 17:24:34,294 iteration 5552 : loss : 0.020869, loss_ce: 0.006143
2022-01-14 17:24:35,851 iteration 5553 : loss : 0.018162, loss_ce: 0.006839
2022-01-14 17:24:37,481 iteration 5554 : loss : 0.019468, loss_ce: 0.004984
2022-01-14 17:24:39,071 iteration 5555 : loss : 0.033332, loss_ce: 0.015572
2022-01-14 17:24:40,642 iteration 5556 : loss : 0.020713, loss_ce: 0.008020
2022-01-14 17:24:42,186 iteration 5557 : loss : 0.013630, loss_ce: 0.003878
2022-01-14 17:24:43,741 iteration 5558 : loss : 0.018301, loss_ce: 0.006341
2022-01-14 17:24:45,207 iteration 5559 : loss : 0.013392, loss_ce: 0.004650
 82%|███████████████████████▋     | 327/400 [2:32:05<34:01, 27.96s/it]2022-01-14 17:24:46,763 iteration 5560 : loss : 0.035502, loss_ce: 0.012106
2022-01-14 17:24:48,376 iteration 5561 : loss : 0.019437, loss_ce: 0.005148
2022-01-14 17:24:49,931 iteration 5562 : loss : 0.014199, loss_ce: 0.003971
2022-01-14 17:24:51,528 iteration 5563 : loss : 0.020712, loss_ce: 0.007287
2022-01-14 17:24:52,943 iteration 5564 : loss : 0.019643, loss_ce: 0.006115
2022-01-14 17:24:54,525 iteration 5565 : loss : 0.023447, loss_ce: 0.005891
2022-01-14 17:24:56,023 iteration 5566 : loss : 0.013038, loss_ce: 0.004407
2022-01-14 17:24:57,605 iteration 5567 : loss : 0.013477, loss_ce: 0.006262
2022-01-14 17:24:59,164 iteration 5568 : loss : 0.017160, loss_ce: 0.007875
2022-01-14 17:25:00,706 iteration 5569 : loss : 0.019825, loss_ce: 0.007832
2022-01-14 17:25:02,257 iteration 5570 : loss : 0.015097, loss_ce: 0.006939
2022-01-14 17:25:03,767 iteration 5571 : loss : 0.024967, loss_ce: 0.008004
2022-01-14 17:25:05,186 iteration 5572 : loss : 0.010844, loss_ce: 0.003783
2022-01-14 17:25:06,743 iteration 5573 : loss : 0.015998, loss_ce: 0.006368
2022-01-14 17:25:08,192 iteration 5574 : loss : 0.012753, loss_ce: 0.004987
2022-01-14 17:25:09,623 iteration 5575 : loss : 0.011569, loss_ce: 0.004217
2022-01-14 17:25:11,028 iteration 5576 : loss : 0.015569, loss_ce: 0.004416
 82%|███████████████████████▊     | 328/400 [2:32:31<32:46, 27.32s/it]2022-01-14 17:25:12,638 iteration 5577 : loss : 0.018936, loss_ce: 0.006010
2022-01-14 17:25:14,137 iteration 5578 : loss : 0.012604, loss_ce: 0.003976
2022-01-14 17:25:15,785 iteration 5579 : loss : 0.014033, loss_ce: 0.003384
2022-01-14 17:25:17,365 iteration 5580 : loss : 0.016756, loss_ce: 0.005538
2022-01-14 17:25:18,898 iteration 5581 : loss : 0.025936, loss_ce: 0.015227
2022-01-14 17:25:20,429 iteration 5582 : loss : 0.017047, loss_ce: 0.006883
2022-01-14 17:25:21,856 iteration 5583 : loss : 0.010491, loss_ce: 0.002935
2022-01-14 17:25:23,347 iteration 5584 : loss : 0.021039, loss_ce: 0.007699
2022-01-14 17:25:24,801 iteration 5585 : loss : 0.011653, loss_ce: 0.003586
2022-01-14 17:25:26,262 iteration 5586 : loss : 0.010738, loss_ce: 0.004408
2022-01-14 17:25:27,862 iteration 5587 : loss : 0.016434, loss_ce: 0.006239
2022-01-14 17:25:29,397 iteration 5588 : loss : 0.014037, loss_ce: 0.005899
2022-01-14 17:25:30,974 iteration 5589 : loss : 0.016655, loss_ce: 0.006379
2022-01-14 17:25:32,436 iteration 5590 : loss : 0.013010, loss_ce: 0.005401
2022-01-14 17:25:33,991 iteration 5591 : loss : 0.017070, loss_ce: 0.005996
2022-01-14 17:25:35,513 iteration 5592 : loss : 0.020381, loss_ce: 0.008229
2022-01-14 17:25:36,926 iteration 5593 : loss : 0.011967, loss_ce: 0.005846
 82%|███████████████████████▊     | 329/400 [2:32:56<31:49, 26.89s/it]2022-01-14 17:25:38,442 iteration 5594 : loss : 0.011532, loss_ce: 0.003639
2022-01-14 17:25:39,869 iteration 5595 : loss : 0.009996, loss_ce: 0.003627
2022-01-14 17:25:41,455 iteration 5596 : loss : 0.023526, loss_ce: 0.006453
2022-01-14 17:25:42,994 iteration 5597 : loss : 0.013729, loss_ce: 0.006215
2022-01-14 17:25:44,665 iteration 5598 : loss : 0.019612, loss_ce: 0.009002
2022-01-14 17:25:46,291 iteration 5599 : loss : 0.027018, loss_ce: 0.009072
2022-01-14 17:25:47,734 iteration 5600 : loss : 0.011140, loss_ce: 0.004214
2022-01-14 17:25:49,274 iteration 5601 : loss : 0.016141, loss_ce: 0.005236
2022-01-14 17:25:50,764 iteration 5602 : loss : 0.015499, loss_ce: 0.004783
2022-01-14 17:25:52,266 iteration 5603 : loss : 0.019386, loss_ce: 0.008509
2022-01-14 17:25:53,786 iteration 5604 : loss : 0.022215, loss_ce: 0.008222
2022-01-14 17:25:55,248 iteration 5605 : loss : 0.015930, loss_ce: 0.006955
2022-01-14 17:25:56,817 iteration 5606 : loss : 0.037299, loss_ce: 0.011802
2022-01-14 17:25:58,315 iteration 5607 : loss : 0.014140, loss_ce: 0.005970
2022-01-14 17:25:59,881 iteration 5608 : loss : 0.014444, loss_ce: 0.007136
2022-01-14 17:26:01,376 iteration 5609 : loss : 0.013603, loss_ce: 0.004793
2022-01-14 17:26:01,376 Training Data Eval:
2022-01-14 17:26:08,911   Average segmentation loss on training set: 0.0089
2022-01-14 17:26:08,911 Validation Data Eval:
2022-01-14 17:26:11,498   Average segmentation loss on validation set: 0.0924
2022-01-14 17:26:13,056 iteration 5610 : loss : 0.019875, loss_ce: 0.007506
 82%|███████████████████████▉     | 330/400 [2:33:33<34:36, 29.66s/it]2022-01-14 17:26:14,543 iteration 5611 : loss : 0.009291, loss_ce: 0.003629
2022-01-14 17:26:16,133 iteration 5612 : loss : 0.022554, loss_ce: 0.007530
2022-01-14 17:26:17,612 iteration 5613 : loss : 0.015251, loss_ce: 0.003126
2022-01-14 17:26:19,155 iteration 5614 : loss : 0.016501, loss_ce: 0.005542
2022-01-14 17:26:20,720 iteration 5615 : loss : 0.019476, loss_ce: 0.009891
2022-01-14 17:26:22,255 iteration 5616 : loss : 0.012750, loss_ce: 0.003561
2022-01-14 17:26:23,921 iteration 5617 : loss : 0.040598, loss_ce: 0.011296
2022-01-14 17:26:25,464 iteration 5618 : loss : 0.014815, loss_ce: 0.005329
2022-01-14 17:26:26,993 iteration 5619 : loss : 0.016208, loss_ce: 0.008432
2022-01-14 17:26:28,460 iteration 5620 : loss : 0.013640, loss_ce: 0.005539
2022-01-14 17:26:29,919 iteration 5621 : loss : 0.014556, loss_ce: 0.005619
2022-01-14 17:26:31,326 iteration 5622 : loss : 0.012101, loss_ce: 0.005101
2022-01-14 17:26:32,893 iteration 5623 : loss : 0.012672, loss_ce: 0.004295
2022-01-14 17:26:34,425 iteration 5624 : loss : 0.013077, loss_ce: 0.004503
2022-01-14 17:26:35,946 iteration 5625 : loss : 0.017395, loss_ce: 0.008094
2022-01-14 17:26:37,494 iteration 5626 : loss : 0.018501, loss_ce: 0.007237
2022-01-14 17:26:38,983 iteration 5627 : loss : 0.014885, loss_ce: 0.006014
 83%|███████████████████████▉     | 331/400 [2:33:59<32:49, 28.54s/it]2022-01-14 17:26:40,564 iteration 5628 : loss : 0.012835, loss_ce: 0.005098
2022-01-14 17:26:42,083 iteration 5629 : loss : 0.016159, loss_ce: 0.006070
2022-01-14 17:26:43,600 iteration 5630 : loss : 0.011337, loss_ce: 0.004201
2022-01-14 17:26:45,186 iteration 5631 : loss : 0.017575, loss_ce: 0.008182
2022-01-14 17:26:46,790 iteration 5632 : loss : 0.017394, loss_ce: 0.006812
2022-01-14 17:26:48,202 iteration 5633 : loss : 0.013296, loss_ce: 0.003404
2022-01-14 17:26:49,781 iteration 5634 : loss : 0.032684, loss_ce: 0.009138
2022-01-14 17:26:51,274 iteration 5635 : loss : 0.012009, loss_ce: 0.004581
2022-01-14 17:26:52,681 iteration 5636 : loss : 0.018699, loss_ce: 0.004272
2022-01-14 17:26:54,287 iteration 5637 : loss : 0.014138, loss_ce: 0.006000
2022-01-14 17:26:55,808 iteration 5638 : loss : 0.013764, loss_ce: 0.006081
2022-01-14 17:26:57,344 iteration 5639 : loss : 0.017937, loss_ce: 0.005771
2022-01-14 17:26:58,883 iteration 5640 : loss : 0.015855, loss_ce: 0.005374
2022-01-14 17:27:00,379 iteration 5641 : loss : 0.017606, loss_ce: 0.005807
2022-01-14 17:27:02,062 iteration 5642 : loss : 0.015515, loss_ce: 0.006874
2022-01-14 17:27:03,480 iteration 5643 : loss : 0.014000, loss_ce: 0.006506
2022-01-14 17:27:05,016 iteration 5644 : loss : 0.016141, loss_ce: 0.006772
 83%|████████████████████████     | 332/400 [2:34:25<31:29, 27.79s/it]2022-01-14 17:27:06,495 iteration 5645 : loss : 0.013032, loss_ce: 0.003940
2022-01-14 17:27:07,967 iteration 5646 : loss : 0.016969, loss_ce: 0.005274
2022-01-14 17:27:09,421 iteration 5647 : loss : 0.009430, loss_ce: 0.003212
2022-01-14 17:27:10,977 iteration 5648 : loss : 0.012219, loss_ce: 0.005501
2022-01-14 17:27:12,432 iteration 5649 : loss : 0.014469, loss_ce: 0.004401
2022-01-14 17:27:14,026 iteration 5650 : loss : 0.013785, loss_ce: 0.005701
2022-01-14 17:27:15,514 iteration 5651 : loss : 0.013523, loss_ce: 0.006152
2022-01-14 17:27:17,050 iteration 5652 : loss : 0.013155, loss_ce: 0.003867
2022-01-14 17:27:18,597 iteration 5653 : loss : 0.015051, loss_ce: 0.004408
2022-01-14 17:27:20,102 iteration 5654 : loss : 0.013227, loss_ce: 0.005130
2022-01-14 17:27:21,516 iteration 5655 : loss : 0.012129, loss_ce: 0.005814
2022-01-14 17:27:23,137 iteration 5656 : loss : 0.021027, loss_ce: 0.006577
2022-01-14 17:27:24,723 iteration 5657 : loss : 0.022504, loss_ce: 0.008070
2022-01-14 17:27:26,268 iteration 5658 : loss : 0.018489, loss_ce: 0.008216
2022-01-14 17:27:27,720 iteration 5659 : loss : 0.014427, loss_ce: 0.005739
2022-01-14 17:27:29,247 iteration 5660 : loss : 0.017732, loss_ce: 0.005781
2022-01-14 17:27:30,783 iteration 5661 : loss : 0.014756, loss_ce: 0.006722
 83%|████████████████████████▏    | 333/400 [2:34:50<30:21, 27.18s/it]2022-01-14 17:27:32,317 iteration 5662 : loss : 0.014615, loss_ce: 0.004772
2022-01-14 17:27:33,786 iteration 5663 : loss : 0.012193, loss_ce: 0.003847
2022-01-14 17:27:35,310 iteration 5664 : loss : 0.014923, loss_ce: 0.006458
2022-01-14 17:27:36,764 iteration 5665 : loss : 0.010242, loss_ce: 0.003733
2022-01-14 17:27:38,291 iteration 5666 : loss : 0.015041, loss_ce: 0.003519
2022-01-14 17:27:39,839 iteration 5667 : loss : 0.013990, loss_ce: 0.004765
2022-01-14 17:27:41,375 iteration 5668 : loss : 0.015326, loss_ce: 0.005398
2022-01-14 17:27:42,818 iteration 5669 : loss : 0.011599, loss_ce: 0.004170
2022-01-14 17:27:44,289 iteration 5670 : loss : 0.015928, loss_ce: 0.004946
2022-01-14 17:27:45,782 iteration 5671 : loss : 0.013609, loss_ce: 0.005273
2022-01-14 17:27:47,436 iteration 5672 : loss : 0.027528, loss_ce: 0.011375
2022-01-14 17:27:48,965 iteration 5673 : loss : 0.013430, loss_ce: 0.004726
2022-01-14 17:27:50,506 iteration 5674 : loss : 0.012316, loss_ce: 0.003608
2022-01-14 17:27:51,973 iteration 5675 : loss : 0.010329, loss_ce: 0.004720
2022-01-14 17:27:53,532 iteration 5676 : loss : 0.015836, loss_ce: 0.006047
2022-01-14 17:27:55,012 iteration 5677 : loss : 0.016060, loss_ce: 0.003695
2022-01-14 17:27:56,619 iteration 5678 : loss : 0.014975, loss_ce: 0.005953
 84%|████████████████████████▏    | 334/400 [2:35:16<29:27, 26.78s/it]2022-01-14 17:27:58,182 iteration 5679 : loss : 0.018754, loss_ce: 0.009078
2022-01-14 17:27:59,644 iteration 5680 : loss : 0.023467, loss_ce: 0.009278
2022-01-14 17:28:01,163 iteration 5681 : loss : 0.016463, loss_ce: 0.008136
2022-01-14 17:28:02,658 iteration 5682 : loss : 0.013604, loss_ce: 0.005305
2022-01-14 17:28:04,229 iteration 5683 : loss : 0.019248, loss_ce: 0.007394
2022-01-14 17:28:05,830 iteration 5684 : loss : 0.016595, loss_ce: 0.005743
2022-01-14 17:28:07,386 iteration 5685 : loss : 0.010679, loss_ce: 0.002831
2022-01-14 17:28:08,874 iteration 5686 : loss : 0.018549, loss_ce: 0.006946
2022-01-14 17:28:10,349 iteration 5687 : loss : 0.012115, loss_ce: 0.003846
2022-01-14 17:28:11,868 iteration 5688 : loss : 0.018057, loss_ce: 0.005847
2022-01-14 17:28:13,351 iteration 5689 : loss : 0.013699, loss_ce: 0.005676
2022-01-14 17:28:14,909 iteration 5690 : loss : 0.013446, loss_ce: 0.006742
2022-01-14 17:28:16,360 iteration 5691 : loss : 0.011124, loss_ce: 0.002828
2022-01-14 17:28:17,864 iteration 5692 : loss : 0.011614, loss_ce: 0.003880
2022-01-14 17:28:19,381 iteration 5693 : loss : 0.016910, loss_ce: 0.007792
2022-01-14 17:28:20,960 iteration 5694 : loss : 0.016376, loss_ce: 0.006245
2022-01-14 17:28:20,960 Training Data Eval:
2022-01-14 17:28:28,459   Average segmentation loss on training set: 0.0077
2022-01-14 17:28:28,460 Validation Data Eval:
2022-01-14 17:28:31,029   Average segmentation loss on validation set: 0.0811
2022-01-14 17:28:32,506 iteration 5695 : loss : 0.026778, loss_ce: 0.008818
 84%|████████████████████████▎    | 335/400 [2:35:52<31:58, 29.51s/it]2022-01-14 17:28:34,086 iteration 5696 : loss : 0.013077, loss_ce: 0.004470
2022-01-14 17:28:35,686 iteration 5697 : loss : 0.016127, loss_ce: 0.005928
2022-01-14 17:28:37,208 iteration 5698 : loss : 0.013058, loss_ce: 0.005037
2022-01-14 17:28:38,813 iteration 5699 : loss : 0.015679, loss_ce: 0.006174
2022-01-14 17:28:40,282 iteration 5700 : loss : 0.013986, loss_ce: 0.005445
2022-01-14 17:28:41,764 iteration 5701 : loss : 0.015873, loss_ce: 0.007614
2022-01-14 17:28:43,337 iteration 5702 : loss : 0.009136, loss_ce: 0.002826
2022-01-14 17:28:44,843 iteration 5703 : loss : 0.011494, loss_ce: 0.005099
2022-01-14 17:28:46,399 iteration 5704 : loss : 0.015614, loss_ce: 0.006708
2022-01-14 17:28:47,946 iteration 5705 : loss : 0.012032, loss_ce: 0.004001
2022-01-14 17:28:49,412 iteration 5706 : loss : 0.014921, loss_ce: 0.002950
2022-01-14 17:28:51,063 iteration 5707 : loss : 0.017289, loss_ce: 0.006215
2022-01-14 17:28:52,569 iteration 5708 : loss : 0.014024, loss_ce: 0.006185
2022-01-14 17:28:54,087 iteration 5709 : loss : 0.013340, loss_ce: 0.005724
2022-01-14 17:28:55,707 iteration 5710 : loss : 0.015542, loss_ce: 0.005773
2022-01-14 17:28:57,193 iteration 5711 : loss : 0.021053, loss_ce: 0.011530
2022-01-14 17:28:58,712 iteration 5712 : loss : 0.014900, loss_ce: 0.006295
 84%|████████████████████████▎    | 336/400 [2:36:18<30:25, 28.52s/it]2022-01-14 17:29:00,206 iteration 5713 : loss : 0.013628, loss_ce: 0.004247
2022-01-14 17:29:01,676 iteration 5714 : loss : 0.013861, loss_ce: 0.005128
2022-01-14 17:29:03,195 iteration 5715 : loss : 0.009772, loss_ce: 0.003897
2022-01-14 17:29:04,746 iteration 5716 : loss : 0.013697, loss_ce: 0.006117
2022-01-14 17:29:06,328 iteration 5717 : loss : 0.014912, loss_ce: 0.005535
2022-01-14 17:29:07,756 iteration 5718 : loss : 0.017951, loss_ce: 0.005307
2022-01-14 17:29:09,312 iteration 5719 : loss : 0.013410, loss_ce: 0.005290
2022-01-14 17:29:10,802 iteration 5720 : loss : 0.014812, loss_ce: 0.006278
2022-01-14 17:29:12,196 iteration 5721 : loss : 0.011004, loss_ce: 0.002946
2022-01-14 17:29:13,711 iteration 5722 : loss : 0.015869, loss_ce: 0.005749
2022-01-14 17:29:15,265 iteration 5723 : loss : 0.014128, loss_ce: 0.005011
2022-01-14 17:29:16,680 iteration 5724 : loss : 0.009398, loss_ce: 0.003402
2022-01-14 17:29:18,242 iteration 5725 : loss : 0.013887, loss_ce: 0.006459
2022-01-14 17:29:19,700 iteration 5726 : loss : 0.012520, loss_ce: 0.005305
2022-01-14 17:29:21,200 iteration 5727 : loss : 0.017800, loss_ce: 0.005847
2022-01-14 17:29:22,688 iteration 5728 : loss : 0.012097, loss_ce: 0.005996
2022-01-14 17:29:24,258 iteration 5729 : loss : 0.014883, loss_ce: 0.005761
 84%|████████████████████████▍    | 337/400 [2:36:44<29:00, 27.63s/it]2022-01-14 17:29:25,866 iteration 5730 : loss : 0.017149, loss_ce: 0.004879
2022-01-14 17:29:27,423 iteration 5731 : loss : 0.011557, loss_ce: 0.004679
2022-01-14 17:29:28,903 iteration 5732 : loss : 0.016109, loss_ce: 0.004452
2022-01-14 17:29:30,356 iteration 5733 : loss : 0.012751, loss_ce: 0.003644
2022-01-14 17:29:31,860 iteration 5734 : loss : 0.017402, loss_ce: 0.005555
2022-01-14 17:29:33,373 iteration 5735 : loss : 0.014114, loss_ce: 0.006954
2022-01-14 17:29:34,875 iteration 5736 : loss : 0.015564, loss_ce: 0.008775
2022-01-14 17:29:36,394 iteration 5737 : loss : 0.021764, loss_ce: 0.008776
2022-01-14 17:29:37,897 iteration 5738 : loss : 0.016144, loss_ce: 0.009366
2022-01-14 17:29:39,352 iteration 5739 : loss : 0.011136, loss_ce: 0.004455
2022-01-14 17:29:40,886 iteration 5740 : loss : 0.016863, loss_ce: 0.006746
2022-01-14 17:29:42,435 iteration 5741 : loss : 0.017951, loss_ce: 0.008812
2022-01-14 17:29:43,976 iteration 5742 : loss : 0.015655, loss_ce: 0.005850
2022-01-14 17:29:45,437 iteration 5743 : loss : 0.010756, loss_ce: 0.004523
2022-01-14 17:29:47,038 iteration 5744 : loss : 0.013757, loss_ce: 0.005245
2022-01-14 17:29:48,541 iteration 5745 : loss : 0.012326, loss_ce: 0.003546
2022-01-14 17:29:49,963 iteration 5746 : loss : 0.013873, loss_ce: 0.003003
 84%|████████████████████████▌    | 338/400 [2:37:10<27:57, 27.05s/it]2022-01-14 17:29:51,551 iteration 5747 : loss : 0.011207, loss_ce: 0.003464
2022-01-14 17:29:53,112 iteration 5748 : loss : 0.015521, loss_ce: 0.004683
2022-01-14 17:29:54,704 iteration 5749 : loss : 0.020268, loss_ce: 0.009971
2022-01-14 17:29:56,322 iteration 5750 : loss : 0.015875, loss_ce: 0.004686
2022-01-14 17:29:57,753 iteration 5751 : loss : 0.011960, loss_ce: 0.004440
2022-01-14 17:29:59,312 iteration 5752 : loss : 0.019487, loss_ce: 0.006848
2022-01-14 17:30:00,812 iteration 5753 : loss : 0.016821, loss_ce: 0.006295
2022-01-14 17:30:02,254 iteration 5754 : loss : 0.011120, loss_ce: 0.003944
2022-01-14 17:30:03,770 iteration 5755 : loss : 0.016763, loss_ce: 0.009210
2022-01-14 17:30:05,265 iteration 5756 : loss : 0.011942, loss_ce: 0.003545
2022-01-14 17:30:06,734 iteration 5757 : loss : 0.012759, loss_ce: 0.006214
2022-01-14 17:30:08,212 iteration 5758 : loss : 0.021892, loss_ce: 0.005734
2022-01-14 17:30:09,751 iteration 5759 : loss : 0.013221, loss_ce: 0.006028
2022-01-14 17:30:11,356 iteration 5760 : loss : 0.024267, loss_ce: 0.009674
2022-01-14 17:30:12,766 iteration 5761 : loss : 0.010203, loss_ce: 0.003796
2022-01-14 17:30:14,517 iteration 5762 : loss : 0.016561, loss_ce: 0.007156
2022-01-14 17:30:16,069 iteration 5763 : loss : 0.013505, loss_ce: 0.005349
 85%|████████████████████████▌    | 339/400 [2:37:36<27:12, 26.77s/it]2022-01-14 17:30:17,664 iteration 5764 : loss : 0.013935, loss_ce: 0.005458
2022-01-14 17:30:19,195 iteration 5765 : loss : 0.025040, loss_ce: 0.006926
2022-01-14 17:30:20,686 iteration 5766 : loss : 0.013140, loss_ce: 0.005202
2022-01-14 17:30:22,210 iteration 5767 : loss : 0.012618, loss_ce: 0.004728
2022-01-14 17:30:23,845 iteration 5768 : loss : 0.024726, loss_ce: 0.008227
2022-01-14 17:30:25,372 iteration 5769 : loss : 0.011412, loss_ce: 0.004641
2022-01-14 17:30:26,869 iteration 5770 : loss : 0.014165, loss_ce: 0.005965
2022-01-14 17:30:28,387 iteration 5771 : loss : 0.014144, loss_ce: 0.006989
2022-01-14 17:30:29,948 iteration 5772 : loss : 0.018084, loss_ce: 0.006378
2022-01-14 17:30:31,571 iteration 5773 : loss : 0.014271, loss_ce: 0.005686
2022-01-14 17:30:33,162 iteration 5774 : loss : 0.018480, loss_ce: 0.007907
2022-01-14 17:30:34,823 iteration 5775 : loss : 0.014844, loss_ce: 0.004559
2022-01-14 17:30:36,289 iteration 5776 : loss : 0.012640, loss_ce: 0.004070
2022-01-14 17:30:37,763 iteration 5777 : loss : 0.018052, loss_ce: 0.006201
2022-01-14 17:30:39,305 iteration 5778 : loss : 0.015032, loss_ce: 0.004655
2022-01-14 17:30:40,810 iteration 5779 : loss : 0.013815, loss_ce: 0.005681
2022-01-14 17:30:40,811 Training Data Eval:
2022-01-14 17:30:48,304   Average segmentation loss on training set: 0.0079
2022-01-14 17:30:48,305 Validation Data Eval:
2022-01-14 17:30:50,877   Average segmentation loss on validation set: 0.0867
2022-01-14 17:30:52,437 iteration 5780 : loss : 0.012065, loss_ce: 0.004536
 85%|████████████████████████▋    | 340/400 [2:38:12<29:38, 29.65s/it]2022-01-14 17:30:54,154 iteration 5781 : loss : 0.019815, loss_ce: 0.006146
2022-01-14 17:30:55,570 iteration 5782 : loss : 0.009984, loss_ce: 0.004760
2022-01-14 17:30:57,019 iteration 5783 : loss : 0.014444, loss_ce: 0.005703
2022-01-14 17:30:58,495 iteration 5784 : loss : 0.011054, loss_ce: 0.003735
2022-01-14 17:30:59,917 iteration 5785 : loss : 0.011690, loss_ce: 0.004951
2022-01-14 17:31:01,463 iteration 5786 : loss : 0.030614, loss_ce: 0.006488
2022-01-14 17:31:02,944 iteration 5787 : loss : 0.019058, loss_ce: 0.006784
2022-01-14 17:31:04,329 iteration 5788 : loss : 0.011690, loss_ce: 0.004445
2022-01-14 17:31:05,767 iteration 5789 : loss : 0.010286, loss_ce: 0.003953
2022-01-14 17:31:07,315 iteration 5790 : loss : 0.009832, loss_ce: 0.003533
2022-01-14 17:31:08,793 iteration 5791 : loss : 0.014004, loss_ce: 0.006486
2022-01-14 17:31:10,217 iteration 5792 : loss : 0.012446, loss_ce: 0.004651
2022-01-14 17:31:11,767 iteration 5793 : loss : 0.015179, loss_ce: 0.004837
2022-01-14 17:31:13,342 iteration 5794 : loss : 0.015068, loss_ce: 0.006182
2022-01-14 17:31:14,787 iteration 5795 : loss : 0.009860, loss_ce: 0.004291
2022-01-14 17:31:16,291 iteration 5796 : loss : 0.015555, loss_ce: 0.007735
2022-01-14 17:31:17,822 iteration 5797 : loss : 0.015573, loss_ce: 0.005443
 85%|████████████████████████▋    | 341/400 [2:38:37<27:53, 28.37s/it]2022-01-14 17:31:19,482 iteration 5798 : loss : 0.018922, loss_ce: 0.004870
2022-01-14 17:31:20,983 iteration 5799 : loss : 0.017226, loss_ce: 0.004779
2022-01-14 17:31:22,483 iteration 5800 : loss : 0.013869, loss_ce: 0.003803
2022-01-14 17:31:23,890 iteration 5801 : loss : 0.009734, loss_ce: 0.003278
2022-01-14 17:31:25,466 iteration 5802 : loss : 0.014641, loss_ce: 0.007528
2022-01-14 17:31:26,877 iteration 5803 : loss : 0.010672, loss_ce: 0.003567
2022-01-14 17:31:28,505 iteration 5804 : loss : 0.029200, loss_ce: 0.011325
2022-01-14 17:31:29,987 iteration 5805 : loss : 0.016663, loss_ce: 0.007930
2022-01-14 17:31:31,481 iteration 5806 : loss : 0.013758, loss_ce: 0.005578
2022-01-14 17:31:32,968 iteration 5807 : loss : 0.011444, loss_ce: 0.003957
2022-01-14 17:31:34,440 iteration 5808 : loss : 0.017525, loss_ce: 0.007564
2022-01-14 17:31:36,094 iteration 5809 : loss : 0.019814, loss_ce: 0.005686
2022-01-14 17:31:37,521 iteration 5810 : loss : 0.017135, loss_ce: 0.004691
2022-01-14 17:31:39,050 iteration 5811 : loss : 0.012374, loss_ce: 0.005265
2022-01-14 17:31:40,582 iteration 5812 : loss : 0.018626, loss_ce: 0.007226
2022-01-14 17:31:42,058 iteration 5813 : loss : 0.016455, loss_ce: 0.005096
2022-01-14 17:31:43,569 iteration 5814 : loss : 0.016439, loss_ce: 0.006259
 86%|████████████████████████▊    | 342/400 [2:39:03<26:39, 27.58s/it]2022-01-14 17:31:45,211 iteration 5815 : loss : 0.018811, loss_ce: 0.008899
2022-01-14 17:31:46,625 iteration 5816 : loss : 0.013904, loss_ce: 0.004490
2022-01-14 17:31:48,124 iteration 5817 : loss : 0.015102, loss_ce: 0.004081
2022-01-14 17:31:49,573 iteration 5818 : loss : 0.013729, loss_ce: 0.004654
2022-01-14 17:31:51,156 iteration 5819 : loss : 0.014172, loss_ce: 0.005499
2022-01-14 17:31:52,652 iteration 5820 : loss : 0.011759, loss_ce: 0.005142
2022-01-14 17:31:54,143 iteration 5821 : loss : 0.017648, loss_ce: 0.006114
2022-01-14 17:31:55,690 iteration 5822 : loss : 0.023703, loss_ce: 0.007476
2022-01-14 17:31:57,206 iteration 5823 : loss : 0.012141, loss_ce: 0.004476
2022-01-14 17:31:58,726 iteration 5824 : loss : 0.012201, loss_ce: 0.004447
2022-01-14 17:32:00,211 iteration 5825 : loss : 0.018192, loss_ce: 0.007665
2022-01-14 17:32:01,655 iteration 5826 : loss : 0.017259, loss_ce: 0.005270
2022-01-14 17:32:03,081 iteration 5827 : loss : 0.015626, loss_ce: 0.004122
2022-01-14 17:32:04,469 iteration 5828 : loss : 0.009457, loss_ce: 0.003974
2022-01-14 17:32:05,940 iteration 5829 : loss : 0.011978, loss_ce: 0.004486
2022-01-14 17:32:07,407 iteration 5830 : loss : 0.017174, loss_ce: 0.007776
2022-01-14 17:32:08,923 iteration 5831 : loss : 0.013618, loss_ce: 0.005049
 86%|████████████████████████▊    | 343/400 [2:39:28<25:34, 26.91s/it]2022-01-14 17:32:10,494 iteration 5832 : loss : 0.016955, loss_ce: 0.006833
2022-01-14 17:32:11,918 iteration 5833 : loss : 0.009603, loss_ce: 0.003292
2022-01-14 17:32:13,458 iteration 5834 : loss : 0.020324, loss_ce: 0.008010
2022-01-14 17:32:15,050 iteration 5835 : loss : 0.035978, loss_ce: 0.012867
2022-01-14 17:32:16,488 iteration 5836 : loss : 0.019211, loss_ce: 0.007886
2022-01-14 17:32:18,024 iteration 5837 : loss : 0.015083, loss_ce: 0.006020
2022-01-14 17:32:19,564 iteration 5838 : loss : 0.019931, loss_ce: 0.005485
2022-01-14 17:32:20,953 iteration 5839 : loss : 0.013752, loss_ce: 0.004586
2022-01-14 17:32:22,590 iteration 5840 : loss : 0.015717, loss_ce: 0.006851
2022-01-14 17:32:24,032 iteration 5841 : loss : 0.009451, loss_ce: 0.003665
2022-01-14 17:32:25,565 iteration 5842 : loss : 0.020443, loss_ce: 0.008528
2022-01-14 17:32:27,124 iteration 5843 : loss : 0.018238, loss_ce: 0.005523
2022-01-14 17:32:28,625 iteration 5844 : loss : 0.028342, loss_ce: 0.007490
2022-01-14 17:32:30,133 iteration 5845 : loss : 0.024555, loss_ce: 0.007816
2022-01-14 17:32:31,615 iteration 5846 : loss : 0.014308, loss_ce: 0.006178
2022-01-14 17:32:33,070 iteration 5847 : loss : 0.010656, loss_ce: 0.003427
2022-01-14 17:32:34,453 iteration 5848 : loss : 0.012046, loss_ce: 0.003657
 86%|████████████████████████▉    | 344/400 [2:39:54<24:43, 26.50s/it]2022-01-14 17:32:35,922 iteration 5849 : loss : 0.017782, loss_ce: 0.005653
2022-01-14 17:32:37,520 iteration 5850 : loss : 0.017244, loss_ce: 0.004278
2022-01-14 17:32:38,992 iteration 5851 : loss : 0.011999, loss_ce: 0.004503
2022-01-14 17:32:40,484 iteration 5852 : loss : 0.013434, loss_ce: 0.004497
2022-01-14 17:32:41,918 iteration 5853 : loss : 0.018369, loss_ce: 0.004623
2022-01-14 17:32:43,410 iteration 5854 : loss : 0.020351, loss_ce: 0.007740
2022-01-14 17:32:44,905 iteration 5855 : loss : 0.025675, loss_ce: 0.008911
2022-01-14 17:32:46,348 iteration 5856 : loss : 0.011054, loss_ce: 0.004694
2022-01-14 17:32:47,902 iteration 5857 : loss : 0.020721, loss_ce: 0.009169
2022-01-14 17:32:49,375 iteration 5858 : loss : 0.024969, loss_ce: 0.009744
2022-01-14 17:32:50,892 iteration 5859 : loss : 0.019943, loss_ce: 0.010772
2022-01-14 17:32:52,426 iteration 5860 : loss : 0.012598, loss_ce: 0.004891
2022-01-14 17:32:53,970 iteration 5861 : loss : 0.019574, loss_ce: 0.008083
2022-01-14 17:32:55,466 iteration 5862 : loss : 0.011333, loss_ce: 0.004279
2022-01-14 17:32:56,976 iteration 5863 : loss : 0.015386, loss_ce: 0.005579
2022-01-14 17:32:58,506 iteration 5864 : loss : 0.015947, loss_ce: 0.005565
2022-01-14 17:32:58,507 Training Data Eval:
2022-01-14 17:33:05,996   Average segmentation loss on training set: 0.0087
2022-01-14 17:33:05,996 Validation Data Eval:
2022-01-14 17:33:08,567   Average segmentation loss on validation set: 0.0840
2022-01-14 17:33:10,023 iteration 5865 : loss : 0.011024, loss_ce: 0.003602
 86%|█████████████████████████    | 345/400 [2:40:30<26:47, 29.22s/it]2022-01-14 17:33:11,579 iteration 5866 : loss : 0.015062, loss_ce: 0.005126
2022-01-14 17:33:13,111 iteration 5867 : loss : 0.012426, loss_ce: 0.005066
2022-01-14 17:33:14,538 iteration 5868 : loss : 0.011732, loss_ce: 0.004425
2022-01-14 17:33:16,006 iteration 5869 : loss : 0.010072, loss_ce: 0.003443
2022-01-14 17:33:17,433 iteration 5870 : loss : 0.013136, loss_ce: 0.004883
2022-01-14 17:33:18,919 iteration 5871 : loss : 0.012004, loss_ce: 0.004745
2022-01-14 17:33:20,388 iteration 5872 : loss : 0.011425, loss_ce: 0.004776
2022-01-14 17:33:21,820 iteration 5873 : loss : 0.011523, loss_ce: 0.005107
2022-01-14 17:33:23,255 iteration 5874 : loss : 0.017712, loss_ce: 0.004098
2022-01-14 17:33:24,849 iteration 5875 : loss : 0.014236, loss_ce: 0.006167
2022-01-14 17:33:26,459 iteration 5876 : loss : 0.016250, loss_ce: 0.007225
2022-01-14 17:33:27,995 iteration 5877 : loss : 0.016696, loss_ce: 0.005581
2022-01-14 17:33:29,564 iteration 5878 : loss : 0.023402, loss_ce: 0.007378
2022-01-14 17:33:31,030 iteration 5879 : loss : 0.015572, loss_ce: 0.004712
2022-01-14 17:33:32,538 iteration 5880 : loss : 0.021485, loss_ce: 0.007657
2022-01-14 17:33:34,084 iteration 5881 : loss : 0.018227, loss_ce: 0.006262
2022-01-14 17:33:35,557 iteration 5882 : loss : 0.010976, loss_ce: 0.003657
 86%|█████████████████████████    | 346/400 [2:40:55<25:18, 28.11s/it]2022-01-14 17:33:37,221 iteration 5883 : loss : 0.016099, loss_ce: 0.005139
2022-01-14 17:33:38,681 iteration 5884 : loss : 0.017237, loss_ce: 0.006725
2022-01-14 17:33:40,254 iteration 5885 : loss : 0.020270, loss_ce: 0.005294
2022-01-14 17:33:41,717 iteration 5886 : loss : 0.008905, loss_ce: 0.002803
2022-01-14 17:33:43,188 iteration 5887 : loss : 0.020787, loss_ce: 0.006601
2022-01-14 17:33:44,586 iteration 5888 : loss : 0.011401, loss_ce: 0.004804
2022-01-14 17:33:46,070 iteration 5889 : loss : 0.012988, loss_ce: 0.005805
2022-01-14 17:33:47,628 iteration 5890 : loss : 0.014536, loss_ce: 0.006142
2022-01-14 17:33:49,152 iteration 5891 : loss : 0.017737, loss_ce: 0.005211
2022-01-14 17:33:50,730 iteration 5892 : loss : 0.013941, loss_ce: 0.006452
2022-01-14 17:33:52,151 iteration 5893 : loss : 0.012035, loss_ce: 0.003963
2022-01-14 17:33:53,625 iteration 5894 : loss : 0.021316, loss_ce: 0.005324
2022-01-14 17:33:55,191 iteration 5895 : loss : 0.022884, loss_ce: 0.009075
2022-01-14 17:33:56,567 iteration 5896 : loss : 0.011039, loss_ce: 0.003818
2022-01-14 17:33:58,081 iteration 5897 : loss : 0.014310, loss_ce: 0.006847
2022-01-14 17:33:59,652 iteration 5898 : loss : 0.015448, loss_ce: 0.006154
2022-01-14 17:34:01,120 iteration 5899 : loss : 0.016141, loss_ce: 0.005152
 87%|█████████████████████████▏   | 347/400 [2:41:21<24:09, 27.35s/it]2022-01-14 17:34:02,552 iteration 5900 : loss : 0.010379, loss_ce: 0.004169
2022-01-14 17:34:04,005 iteration 5901 : loss : 0.010595, loss_ce: 0.004364
2022-01-14 17:34:05,417 iteration 5902 : loss : 0.016963, loss_ce: 0.006584
2022-01-14 17:34:06,899 iteration 5903 : loss : 0.018189, loss_ce: 0.008294
2022-01-14 17:34:08,411 iteration 5904 : loss : 0.029559, loss_ce: 0.009315
2022-01-14 17:34:09,966 iteration 5905 : loss : 0.017697, loss_ce: 0.008749
2022-01-14 17:34:11,561 iteration 5906 : loss : 0.013830, loss_ce: 0.003500
2022-01-14 17:34:12,986 iteration 5907 : loss : 0.010176, loss_ce: 0.004376
2022-01-14 17:34:14,499 iteration 5908 : loss : 0.018195, loss_ce: 0.006396
2022-01-14 17:34:16,051 iteration 5909 : loss : 0.016915, loss_ce: 0.009125
2022-01-14 17:34:17,542 iteration 5910 : loss : 0.012147, loss_ce: 0.003979
2022-01-14 17:34:19,092 iteration 5911 : loss : 0.015597, loss_ce: 0.003832
2022-01-14 17:34:20,621 iteration 5912 : loss : 0.015474, loss_ce: 0.003533
2022-01-14 17:34:22,161 iteration 5913 : loss : 0.014072, loss_ce: 0.006153
2022-01-14 17:34:23,670 iteration 5914 : loss : 0.014286, loss_ce: 0.006365
2022-01-14 17:34:25,196 iteration 5915 : loss : 0.014810, loss_ce: 0.006695
2022-01-14 17:34:26,619 iteration 5916 : loss : 0.010725, loss_ce: 0.003835
 87%|█████████████████████████▏   | 348/400 [2:41:46<23:13, 26.79s/it]2022-01-14 17:34:28,117 iteration 5917 : loss : 0.013956, loss_ce: 0.006444
2022-01-14 17:34:29,683 iteration 5918 : loss : 0.020954, loss_ce: 0.010147
2022-01-14 17:34:31,270 iteration 5919 : loss : 0.015965, loss_ce: 0.006237
2022-01-14 17:34:32,866 iteration 5920 : loss : 0.017676, loss_ce: 0.006490
2022-01-14 17:34:34,344 iteration 5921 : loss : 0.015036, loss_ce: 0.005216
2022-01-14 17:34:35,903 iteration 5922 : loss : 0.015899, loss_ce: 0.007292
2022-01-14 17:34:37,426 iteration 5923 : loss : 0.015533, loss_ce: 0.007220
2022-01-14 17:34:38,844 iteration 5924 : loss : 0.010017, loss_ce: 0.003374
2022-01-14 17:34:40,352 iteration 5925 : loss : 0.013248, loss_ce: 0.004329
2022-01-14 17:34:41,945 iteration 5926 : loss : 0.013679, loss_ce: 0.003989
2022-01-14 17:34:43,395 iteration 5927 : loss : 0.009756, loss_ce: 0.004019
2022-01-14 17:34:44,990 iteration 5928 : loss : 0.010803, loss_ce: 0.004699
2022-01-14 17:34:46,529 iteration 5929 : loss : 0.017578, loss_ce: 0.007877
2022-01-14 17:34:48,088 iteration 5930 : loss : 0.018925, loss_ce: 0.007191
2022-01-14 17:34:49,535 iteration 5931 : loss : 0.013691, loss_ce: 0.005777
2022-01-14 17:34:51,041 iteration 5932 : loss : 0.011819, loss_ce: 0.004423
2022-01-14 17:34:52,643 iteration 5933 : loss : 0.016385, loss_ce: 0.004200
 87%|█████████████████████████▎   | 349/400 [2:42:12<22:34, 26.56s/it]2022-01-14 17:34:54,206 iteration 5934 : loss : 0.009352, loss_ce: 0.003104
2022-01-14 17:34:55,730 iteration 5935 : loss : 0.013898, loss_ce: 0.003828
2022-01-14 17:34:57,372 iteration 5936 : loss : 0.024570, loss_ce: 0.010024
2022-01-14 17:34:58,964 iteration 5937 : loss : 0.015897, loss_ce: 0.007427
2022-01-14 17:35:00,469 iteration 5938 : loss : 0.015006, loss_ce: 0.004888
2022-01-14 17:35:01,935 iteration 5939 : loss : 0.013935, loss_ce: 0.005468
2022-01-14 17:35:03,498 iteration 5940 : loss : 0.013997, loss_ce: 0.006184
2022-01-14 17:35:04,906 iteration 5941 : loss : 0.014296, loss_ce: 0.006995
2022-01-14 17:35:06,428 iteration 5942 : loss : 0.020067, loss_ce: 0.006913
2022-01-14 17:35:07,839 iteration 5943 : loss : 0.009822, loss_ce: 0.003475
2022-01-14 17:35:09,392 iteration 5944 : loss : 0.013687, loss_ce: 0.004643
2022-01-14 17:35:10,856 iteration 5945 : loss : 0.010933, loss_ce: 0.003494
2022-01-14 17:35:12,296 iteration 5946 : loss : 0.019459, loss_ce: 0.006592
2022-01-14 17:35:13,741 iteration 5947 : loss : 0.011187, loss_ce: 0.004402
2022-01-14 17:35:15,290 iteration 5948 : loss : 0.014738, loss_ce: 0.005967
2022-01-14 17:35:16,711 iteration 5949 : loss : 0.011562, loss_ce: 0.005277
2022-01-14 17:35:16,711 Training Data Eval:
2022-01-14 17:35:24,218   Average segmentation loss on training set: 0.0078
2022-01-14 17:35:24,218 Validation Data Eval:
2022-01-14 17:35:26,789   Average segmentation loss on validation set: 0.0765
2022-01-14 17:35:28,390 iteration 5950 : loss : 0.016288, loss_ce: 0.004578
 88%|█████████████████████████▍   | 350/400 [2:42:48<24:25, 29.32s/it]2022-01-14 17:35:29,894 iteration 5951 : loss : 0.010285, loss_ce: 0.002581
2022-01-14 17:35:31,420 iteration 5952 : loss : 0.011474, loss_ce: 0.005203
2022-01-14 17:35:32,929 iteration 5953 : loss : 0.016769, loss_ce: 0.006769
2022-01-14 17:35:34,573 iteration 5954 : loss : 0.031299, loss_ce: 0.009299
2022-01-14 17:35:36,075 iteration 5955 : loss : 0.012089, loss_ce: 0.004351
2022-01-14 17:35:37,669 iteration 5956 : loss : 0.014649, loss_ce: 0.005259
2022-01-14 17:35:39,151 iteration 5957 : loss : 0.015976, loss_ce: 0.004410
2022-01-14 17:35:40,621 iteration 5958 : loss : 0.011189, loss_ce: 0.004909
2022-01-14 17:35:42,150 iteration 5959 : loss : 0.010558, loss_ce: 0.003225
2022-01-14 17:35:43,631 iteration 5960 : loss : 0.008006, loss_ce: 0.002460
2022-01-14 17:35:45,150 iteration 5961 : loss : 0.013834, loss_ce: 0.005299
2022-01-14 17:35:46,712 iteration 5962 : loss : 0.014152, loss_ce: 0.005483
2022-01-14 17:35:48,128 iteration 5963 : loss : 0.012509, loss_ce: 0.005445
2022-01-14 17:35:49,850 iteration 5964 : loss : 0.034122, loss_ce: 0.015548
2022-01-14 17:35:51,290 iteration 5965 : loss : 0.012806, loss_ce: 0.004792
2022-01-14 17:35:52,853 iteration 5966 : loss : 0.020170, loss_ce: 0.008034
2022-01-14 17:35:54,295 iteration 5967 : loss : 0.017879, loss_ce: 0.005539
 88%|█████████████████████████▍   | 351/400 [2:43:14<23:06, 28.29s/it]2022-01-14 17:35:55,810 iteration 5968 : loss : 0.016496, loss_ce: 0.008155
2022-01-14 17:35:57,354 iteration 5969 : loss : 0.019368, loss_ce: 0.006361
2022-01-14 17:35:58,889 iteration 5970 : loss : 0.012222, loss_ce: 0.003896
2022-01-14 17:36:00,307 iteration 5971 : loss : 0.010918, loss_ce: 0.004290
2022-01-14 17:36:01,791 iteration 5972 : loss : 0.017565, loss_ce: 0.006283
2022-01-14 17:36:03,315 iteration 5973 : loss : 0.009946, loss_ce: 0.004206
2022-01-14 17:36:04,746 iteration 5974 : loss : 0.013166, loss_ce: 0.004611
2022-01-14 17:36:06,322 iteration 5975 : loss : 0.017372, loss_ce: 0.005619
2022-01-14 17:36:07,863 iteration 5976 : loss : 0.016803, loss_ce: 0.004215
2022-01-14 17:36:09,404 iteration 5977 : loss : 0.011290, loss_ce: 0.003591
2022-01-14 17:36:10,922 iteration 5978 : loss : 0.012286, loss_ce: 0.005012
2022-01-14 17:36:12,364 iteration 5979 : loss : 0.011821, loss_ce: 0.004655
2022-01-14 17:36:13,932 iteration 5980 : loss : 0.010028, loss_ce: 0.003820
2022-01-14 17:36:15,490 iteration 5981 : loss : 0.013909, loss_ce: 0.005496
2022-01-14 17:36:17,066 iteration 5982 : loss : 0.021824, loss_ce: 0.008393
2022-01-14 17:36:18,514 iteration 5983 : loss : 0.012387, loss_ce: 0.005974
2022-01-14 17:36:19,990 iteration 5984 : loss : 0.016084, loss_ce: 0.004619
 88%|█████████████████████████▌   | 352/400 [2:43:40<22:00, 27.52s/it]2022-01-14 17:36:21,668 iteration 5985 : loss : 0.024727, loss_ce: 0.011199
2022-01-14 17:36:23,099 iteration 5986 : loss : 0.011636, loss_ce: 0.004942
2022-01-14 17:36:24,671 iteration 5987 : loss : 0.081388, loss_ce: 0.014075
2022-01-14 17:36:26,273 iteration 5988 : loss : 0.015183, loss_ce: 0.007151
2022-01-14 17:36:27,741 iteration 5989 : loss : 0.015611, loss_ce: 0.005766
2022-01-14 17:36:29,301 iteration 5990 : loss : 0.023476, loss_ce: 0.017537
2022-01-14 17:36:30,715 iteration 5991 : loss : 0.012114, loss_ce: 0.004241
2022-01-14 17:36:32,271 iteration 5992 : loss : 0.014839, loss_ce: 0.004320
2022-01-14 17:36:33,695 iteration 5993 : loss : 0.010889, loss_ce: 0.003712
2022-01-14 17:36:35,203 iteration 5994 : loss : 0.019942, loss_ce: 0.006045
2022-01-14 17:36:36,723 iteration 5995 : loss : 0.022101, loss_ce: 0.008146
2022-01-14 17:36:38,289 iteration 5996 : loss : 0.017811, loss_ce: 0.006910
2022-01-14 17:36:39,881 iteration 5997 : loss : 0.016406, loss_ce: 0.007410
2022-01-14 17:36:41,324 iteration 5998 : loss : 0.011627, loss_ce: 0.004069
2022-01-14 17:36:42,896 iteration 5999 : loss : 0.026026, loss_ce: 0.007396
2022-01-14 17:36:44,437 iteration 6000 : loss : 0.020156, loss_ce: 0.008881
2022-01-14 17:36:45,979 iteration 6001 : loss : 0.043933, loss_ce: 0.016882
 88%|█████████████████████████▌   | 353/400 [2:44:06<21:11, 27.06s/it]2022-01-14 17:36:47,519 iteration 6002 : loss : 0.016830, loss_ce: 0.006740
2022-01-14 17:36:49,104 iteration 6003 : loss : 0.016097, loss_ce: 0.005629
2022-01-14 17:36:50,605 iteration 6004 : loss : 0.017533, loss_ce: 0.009604
2022-01-14 17:36:52,164 iteration 6005 : loss : 0.017073, loss_ce: 0.007226
2022-01-14 17:36:53,608 iteration 6006 : loss : 0.014972, loss_ce: 0.007358
2022-01-14 17:36:55,130 iteration 6007 : loss : 0.015999, loss_ce: 0.006264
2022-01-14 17:36:56,657 iteration 6008 : loss : 0.025684, loss_ce: 0.010986
2022-01-14 17:36:58,249 iteration 6009 : loss : 0.021373, loss_ce: 0.007153
2022-01-14 17:36:59,656 iteration 6010 : loss : 0.011793, loss_ce: 0.004804
2022-01-14 17:37:01,202 iteration 6011 : loss : 0.022970, loss_ce: 0.007616
2022-01-14 17:37:02,724 iteration 6012 : loss : 0.018739, loss_ce: 0.006549
2022-01-14 17:37:04,324 iteration 6013 : loss : 0.021681, loss_ce: 0.007910
2022-01-14 17:37:05,809 iteration 6014 : loss : 0.013875, loss_ce: 0.005803
2022-01-14 17:37:07,263 iteration 6015 : loss : 0.014740, loss_ce: 0.004950
2022-01-14 17:37:08,793 iteration 6016 : loss : 0.009426, loss_ce: 0.002680
2022-01-14 17:37:10,247 iteration 6017 : loss : 0.017028, loss_ce: 0.004504
2022-01-14 17:37:11,869 iteration 6018 : loss : 0.016589, loss_ce: 0.006256
 88%|█████████████████████████▋   | 354/400 [2:44:31<20:28, 26.71s/it]2022-01-14 17:37:13,443 iteration 6019 : loss : 0.013913, loss_ce: 0.005264
2022-01-14 17:37:14,947 iteration 6020 : loss : 0.014463, loss_ce: 0.005440
2022-01-14 17:37:16,433 iteration 6021 : loss : 0.011573, loss_ce: 0.003758
2022-01-14 17:37:17,963 iteration 6022 : loss : 0.012205, loss_ce: 0.004963
2022-01-14 17:37:19,395 iteration 6023 : loss : 0.010751, loss_ce: 0.003834
2022-01-14 17:37:20,991 iteration 6024 : loss : 0.026199, loss_ce: 0.008298
2022-01-14 17:37:22,563 iteration 6025 : loss : 0.024868, loss_ce: 0.009200
2022-01-14 17:37:24,124 iteration 6026 : loss : 0.016785, loss_ce: 0.005236
2022-01-14 17:37:25,592 iteration 6027 : loss : 0.015616, loss_ce: 0.006069
2022-01-14 17:37:27,056 iteration 6028 : loss : 0.013587, loss_ce: 0.005374
2022-01-14 17:37:28,614 iteration 6029 : loss : 0.017154, loss_ce: 0.007952
2022-01-14 17:37:30,059 iteration 6030 : loss : 0.013689, loss_ce: 0.004699
2022-01-14 17:37:31,705 iteration 6031 : loss : 0.022465, loss_ce: 0.005754
2022-01-14 17:37:33,252 iteration 6032 : loss : 0.020805, loss_ce: 0.007799
2022-01-14 17:37:34,779 iteration 6033 : loss : 0.017434, loss_ce: 0.007639
2022-01-14 17:37:36,339 iteration 6034 : loss : 0.014071, loss_ce: 0.004304
2022-01-14 17:37:36,340 Training Data Eval:
2022-01-14 17:37:43,822   Average segmentation loss on training set: 0.0082
2022-01-14 17:37:43,823 Validation Data Eval:
2022-01-14 17:37:46,392   Average segmentation loss on validation set: 0.0824
2022-01-14 17:37:47,852 iteration 6035 : loss : 0.012755, loss_ce: 0.003179
 89%|█████████████████████████▋   | 355/400 [2:45:07<22:07, 29.49s/it]2022-01-14 17:37:49,497 iteration 6036 : loss : 0.014509, loss_ce: 0.005078
2022-01-14 17:37:51,131 iteration 6037 : loss : 0.022160, loss_ce: 0.007405
2022-01-14 17:37:52,644 iteration 6038 : loss : 0.017196, loss_ce: 0.007124
2022-01-14 17:37:54,183 iteration 6039 : loss : 0.014560, loss_ce: 0.006171
2022-01-14 17:37:55,723 iteration 6040 : loss : 0.012799, loss_ce: 0.005587
2022-01-14 17:37:57,351 iteration 6041 : loss : 0.029032, loss_ce: 0.010480
2022-01-14 17:37:58,913 iteration 6042 : loss : 0.016575, loss_ce: 0.006364
2022-01-14 17:38:00,413 iteration 6043 : loss : 0.011223, loss_ce: 0.004887
2022-01-14 17:38:01,903 iteration 6044 : loss : 0.028144, loss_ce: 0.011006
2022-01-14 17:38:03,485 iteration 6045 : loss : 0.030974, loss_ce: 0.008706
2022-01-14 17:38:05,019 iteration 6046 : loss : 0.016243, loss_ce: 0.005091
2022-01-14 17:38:06,514 iteration 6047 : loss : 0.017681, loss_ce: 0.004760
2022-01-14 17:38:08,127 iteration 6048 : loss : 0.024209, loss_ce: 0.003485
2022-01-14 17:38:09,678 iteration 6049 : loss : 0.015301, loss_ce: 0.006983
2022-01-14 17:38:11,142 iteration 6050 : loss : 0.012299, loss_ce: 0.004962
2022-01-14 17:38:12,742 iteration 6051 : loss : 0.014275, loss_ce: 0.006692
2022-01-14 17:38:14,148 iteration 6052 : loss : 0.012228, loss_ce: 0.002952
 89%|█████████████████████████▊   | 356/400 [2:45:34<20:55, 28.53s/it]2022-01-14 17:38:15,678 iteration 6053 : loss : 0.013910, loss_ce: 0.006359
2022-01-14 17:38:17,267 iteration 6054 : loss : 0.020287, loss_ce: 0.007800
2022-01-14 17:38:18,740 iteration 6055 : loss : 0.013476, loss_ce: 0.004392
2022-01-14 17:38:20,227 iteration 6056 : loss : 0.011625, loss_ce: 0.004232
2022-01-14 17:38:21,686 iteration 6057 : loss : 0.013503, loss_ce: 0.004157
2022-01-14 17:38:23,278 iteration 6058 : loss : 0.012541, loss_ce: 0.005387
2022-01-14 17:38:24,723 iteration 6059 : loss : 0.010057, loss_ce: 0.003893
2022-01-14 17:38:26,276 iteration 6060 : loss : 0.013845, loss_ce: 0.006176
2022-01-14 17:38:27,726 iteration 6061 : loss : 0.014063, loss_ce: 0.006160
2022-01-14 17:38:29,355 iteration 6062 : loss : 0.014169, loss_ce: 0.006421
2022-01-14 17:38:30,978 iteration 6063 : loss : 0.025642, loss_ce: 0.007247
2022-01-14 17:38:32,505 iteration 6064 : loss : 0.021405, loss_ce: 0.005388
2022-01-14 17:38:34,073 iteration 6065 : loss : 0.015535, loss_ce: 0.007255
2022-01-14 17:38:35,579 iteration 6066 : loss : 0.012187, loss_ce: 0.004395
2022-01-14 17:38:37,032 iteration 6067 : loss : 0.021669, loss_ce: 0.004224
2022-01-14 17:38:38,669 iteration 6068 : loss : 0.023466, loss_ce: 0.007830
2022-01-14 17:38:40,127 iteration 6069 : loss : 0.053901, loss_ce: 0.005984
 89%|█████████████████████████▉   | 357/400 [2:46:00<19:53, 27.77s/it]2022-01-14 17:38:41,740 iteration 6070 : loss : 0.014663, loss_ce: 0.006802
2022-01-14 17:38:43,291 iteration 6071 : loss : 0.014203, loss_ce: 0.004019
2022-01-14 17:38:44,808 iteration 6072 : loss : 0.011292, loss_ce: 0.003452
2022-01-14 17:38:46,375 iteration 6073 : loss : 0.018909, loss_ce: 0.007221
2022-01-14 17:38:47,918 iteration 6074 : loss : 0.012058, loss_ce: 0.003799
2022-01-14 17:38:49,502 iteration 6075 : loss : 0.022849, loss_ce: 0.011198
2022-01-14 17:38:51,012 iteration 6076 : loss : 0.013421, loss_ce: 0.005563
2022-01-14 17:38:52,473 iteration 6077 : loss : 0.014640, loss_ce: 0.006923
2022-01-14 17:38:53,991 iteration 6078 : loss : 0.025995, loss_ce: 0.007653
2022-01-14 17:38:55,502 iteration 6079 : loss : 0.015621, loss_ce: 0.004093
2022-01-14 17:38:57,033 iteration 6080 : loss : 0.012578, loss_ce: 0.004064
2022-01-14 17:38:58,441 iteration 6081 : loss : 0.018386, loss_ce: 0.005892
2022-01-14 17:39:00,038 iteration 6082 : loss : 0.021831, loss_ce: 0.007642
2022-01-14 17:39:01,654 iteration 6083 : loss : 0.024588, loss_ce: 0.009856
2022-01-14 17:39:03,085 iteration 6084 : loss : 0.025005, loss_ce: 0.005794
2022-01-14 17:39:04,540 iteration 6085 : loss : 0.014069, loss_ce: 0.007145
2022-01-14 17:39:06,195 iteration 6086 : loss : 0.030430, loss_ce: 0.012173
 90%|█████████████████████████▉   | 358/400 [2:46:26<19:04, 27.25s/it]2022-01-14 17:39:07,754 iteration 6087 : loss : 0.032753, loss_ce: 0.009499
2022-01-14 17:39:09,257 iteration 6088 : loss : 0.012250, loss_ce: 0.003616
2022-01-14 17:39:10,833 iteration 6089 : loss : 0.018097, loss_ce: 0.008412
2022-01-14 17:39:12,307 iteration 6090 : loss : 0.012694, loss_ce: 0.003540
2022-01-14 17:39:13,759 iteration 6091 : loss : 0.014983, loss_ce: 0.004772
2022-01-14 17:39:15,347 iteration 6092 : loss : 0.018681, loss_ce: 0.006958
2022-01-14 17:39:16,979 iteration 6093 : loss : 0.014472, loss_ce: 0.006441
2022-01-14 17:39:18,547 iteration 6094 : loss : 0.016938, loss_ce: 0.008149
2022-01-14 17:39:19,962 iteration 6095 : loss : 0.014991, loss_ce: 0.003913
2022-01-14 17:39:21,552 iteration 6096 : loss : 0.017901, loss_ce: 0.004409
2022-01-14 17:39:23,021 iteration 6097 : loss : 0.012542, loss_ce: 0.006313
2022-01-14 17:39:24,537 iteration 6098 : loss : 0.015937, loss_ce: 0.008060
2022-01-14 17:39:26,042 iteration 6099 : loss : 0.016180, loss_ce: 0.007680
2022-01-14 17:39:27,551 iteration 6100 : loss : 0.015728, loss_ce: 0.005056
2022-01-14 17:39:29,147 iteration 6101 : loss : 0.022828, loss_ce: 0.009476
2022-01-14 17:39:30,575 iteration 6102 : loss : 0.013696, loss_ce: 0.005642
2022-01-14 17:39:32,120 iteration 6103 : loss : 0.020910, loss_ce: 0.007731
 90%|██████████████████████████   | 359/400 [2:46:52<18:21, 26.86s/it]2022-01-14 17:39:33,697 iteration 6104 : loss : 0.015109, loss_ce: 0.005889
2022-01-14 17:39:35,170 iteration 6105 : loss : 0.021756, loss_ce: 0.005320
2022-01-14 17:39:36,614 iteration 6106 : loss : 0.010188, loss_ce: 0.004198
2022-01-14 17:39:38,079 iteration 6107 : loss : 0.010599, loss_ce: 0.004083
2022-01-14 17:39:39,580 iteration 6108 : loss : 0.014528, loss_ce: 0.004452
2022-01-14 17:39:41,136 iteration 6109 : loss : 0.015784, loss_ce: 0.007121
2022-01-14 17:39:42,552 iteration 6110 : loss : 0.012198, loss_ce: 0.005613
2022-01-14 17:39:44,091 iteration 6111 : loss : 0.017902, loss_ce: 0.005786
2022-01-14 17:39:45,636 iteration 6112 : loss : 0.014162, loss_ce: 0.004168
2022-01-14 17:39:47,161 iteration 6113 : loss : 0.014770, loss_ce: 0.004798
2022-01-14 17:39:48,680 iteration 6114 : loss : 0.015268, loss_ce: 0.005740
2022-01-14 17:39:50,297 iteration 6115 : loss : 0.021779, loss_ce: 0.005635
2022-01-14 17:39:51,809 iteration 6116 : loss : 0.011308, loss_ce: 0.003586
2022-01-14 17:39:53,327 iteration 6117 : loss : 0.015933, loss_ce: 0.006031
2022-01-14 17:39:54,832 iteration 6118 : loss : 0.013859, loss_ce: 0.007078
2022-01-14 17:39:56,337 iteration 6119 : loss : 0.014691, loss_ce: 0.005917
2022-01-14 17:39:56,338 Training Data Eval:
2022-01-14 17:40:03,811   Average segmentation loss on training set: 0.0077
2022-01-14 17:40:03,812 Validation Data Eval:
2022-01-14 17:40:06,380   Average segmentation loss on validation set: 0.0701
2022-01-14 17:40:07,945 iteration 6120 : loss : 0.021242, loss_ce: 0.009439
 90%|██████████████████████████   | 360/400 [2:47:28<19:41, 29.55s/it]2022-01-14 17:40:09,553 iteration 6121 : loss : 0.011993, loss_ce: 0.003979
2022-01-14 17:40:11,104 iteration 6122 : loss : 0.012866, loss_ce: 0.005577
2022-01-14 17:40:12,614 iteration 6123 : loss : 0.013291, loss_ce: 0.004797
2022-01-14 17:40:14,193 iteration 6124 : loss : 0.020934, loss_ce: 0.007387
2022-01-14 17:40:15,719 iteration 6125 : loss : 0.012615, loss_ce: 0.003710
2022-01-14 17:40:17,365 iteration 6126 : loss : 0.017037, loss_ce: 0.005772
2022-01-14 17:40:19,021 iteration 6127 : loss : 0.018443, loss_ce: 0.008686
2022-01-14 17:40:20,515 iteration 6128 : loss : 0.011018, loss_ce: 0.003735
2022-01-14 17:40:21,960 iteration 6129 : loss : 0.013998, loss_ce: 0.004448
2022-01-14 17:40:23,513 iteration 6130 : loss : 0.016741, loss_ce: 0.007131
2022-01-14 17:40:24,979 iteration 6131 : loss : 0.018508, loss_ce: 0.005288
2022-01-14 17:40:26,561 iteration 6132 : loss : 0.014122, loss_ce: 0.004598
2022-01-14 17:40:28,132 iteration 6133 : loss : 0.014350, loss_ce: 0.005585
2022-01-14 17:40:29,638 iteration 6134 : loss : 0.015666, loss_ce: 0.006585
2022-01-14 17:40:31,073 iteration 6135 : loss : 0.012351, loss_ce: 0.005749
2022-01-14 17:40:32,549 iteration 6136 : loss : 0.011202, loss_ce: 0.003914
2022-01-14 17:40:33,997 iteration 6137 : loss : 0.014264, loss_ce: 0.004791
 90%|██████████████████████████▏  | 361/400 [2:47:54<18:31, 28.50s/it]2022-01-14 17:40:35,514 iteration 6138 : loss : 0.014381, loss_ce: 0.005336
2022-01-14 17:40:36,996 iteration 6139 : loss : 0.011129, loss_ce: 0.002742
2022-01-14 17:40:38,466 iteration 6140 : loss : 0.013275, loss_ce: 0.004673
2022-01-14 17:40:39,904 iteration 6141 : loss : 0.014222, loss_ce: 0.006514
2022-01-14 17:40:41,448 iteration 6142 : loss : 0.014793, loss_ce: 0.005928
2022-01-14 17:40:42,875 iteration 6143 : loss : 0.014494, loss_ce: 0.007052
2022-01-14 17:40:44,514 iteration 6144 : loss : 0.017816, loss_ce: 0.008001
2022-01-14 17:40:45,966 iteration 6145 : loss : 0.013303, loss_ce: 0.005378
2022-01-14 17:40:47,428 iteration 6146 : loss : 0.010873, loss_ce: 0.003504
2022-01-14 17:40:48,937 iteration 6147 : loss : 0.012278, loss_ce: 0.004595
2022-01-14 17:40:50,410 iteration 6148 : loss : 0.013466, loss_ce: 0.005746
2022-01-14 17:40:51,866 iteration 6149 : loss : 0.011579, loss_ce: 0.004252
2022-01-14 17:40:53,404 iteration 6150 : loss : 0.013889, loss_ce: 0.004986
2022-01-14 17:40:55,064 iteration 6151 : loss : 0.015245, loss_ce: 0.004724
2022-01-14 17:40:56,531 iteration 6152 : loss : 0.010867, loss_ce: 0.004417
2022-01-14 17:40:58,071 iteration 6153 : loss : 0.014244, loss_ce: 0.006209
2022-01-14 17:40:59,657 iteration 6154 : loss : 0.018926, loss_ce: 0.007054
 90%|██████████████████████████▏  | 362/400 [2:48:19<17:30, 27.65s/it]2022-01-14 17:41:01,276 iteration 6155 : loss : 0.016480, loss_ce: 0.006232
2022-01-14 17:41:02,744 iteration 6156 : loss : 0.010248, loss_ce: 0.004377
2022-01-14 17:41:04,239 iteration 6157 : loss : 0.010521, loss_ce: 0.003207
2022-01-14 17:41:05,772 iteration 6158 : loss : 0.011501, loss_ce: 0.004208
2022-01-14 17:41:07,226 iteration 6159 : loss : 0.018037, loss_ce: 0.007677
2022-01-14 17:41:08,740 iteration 6160 : loss : 0.011042, loss_ce: 0.004153
2022-01-14 17:41:10,250 iteration 6161 : loss : 0.010599, loss_ce: 0.002623
2022-01-14 17:41:11,819 iteration 6162 : loss : 0.018842, loss_ce: 0.003587
2022-01-14 17:41:13,336 iteration 6163 : loss : 0.013673, loss_ce: 0.006317
2022-01-14 17:41:14,909 iteration 6164 : loss : 0.012795, loss_ce: 0.005802
2022-01-14 17:41:16,423 iteration 6165 : loss : 0.012808, loss_ce: 0.004769
2022-01-14 17:41:17,977 iteration 6166 : loss : 0.010071, loss_ce: 0.004384
2022-01-14 17:41:19,451 iteration 6167 : loss : 0.017175, loss_ce: 0.006856
2022-01-14 17:41:20,996 iteration 6168 : loss : 0.016977, loss_ce: 0.006310
2022-01-14 17:41:22,515 iteration 6169 : loss : 0.014023, loss_ce: 0.004141
2022-01-14 17:41:24,003 iteration 6170 : loss : 0.013109, loss_ce: 0.004718
2022-01-14 17:41:25,467 iteration 6171 : loss : 0.011997, loss_ce: 0.004870
 91%|██████████████████████████▎  | 363/400 [2:48:45<16:42, 27.09s/it]2022-01-14 17:41:26,961 iteration 6172 : loss : 0.016526, loss_ce: 0.006579
2022-01-14 17:41:28,558 iteration 6173 : loss : 0.019391, loss_ce: 0.007128
2022-01-14 17:41:30,048 iteration 6174 : loss : 0.012652, loss_ce: 0.004691
2022-01-14 17:41:31,612 iteration 6175 : loss : 0.027296, loss_ce: 0.010636
2022-01-14 17:41:33,158 iteration 6176 : loss : 0.014730, loss_ce: 0.005402
2022-01-14 17:41:34,779 iteration 6177 : loss : 0.018557, loss_ce: 0.007472
2022-01-14 17:41:36,281 iteration 6178 : loss : 0.014067, loss_ce: 0.006119
2022-01-14 17:41:37,769 iteration 6179 : loss : 0.010831, loss_ce: 0.005019
2022-01-14 17:41:39,272 iteration 6180 : loss : 0.015929, loss_ce: 0.006481
2022-01-14 17:41:40,669 iteration 6181 : loss : 0.009117, loss_ce: 0.002941
2022-01-14 17:41:42,212 iteration 6182 : loss : 0.017835, loss_ce: 0.004949
2022-01-14 17:41:43,823 iteration 6183 : loss : 0.023901, loss_ce: 0.009556
2022-01-14 17:41:45,369 iteration 6184 : loss : 0.025673, loss_ce: 0.007805
2022-01-14 17:41:46,853 iteration 6185 : loss : 0.011830, loss_ce: 0.004112
2022-01-14 17:41:48,377 iteration 6186 : loss : 0.014485, loss_ce: 0.004752
2022-01-14 17:41:49,974 iteration 6187 : loss : 0.016959, loss_ce: 0.005607
2022-01-14 17:41:51,381 iteration 6188 : loss : 0.012356, loss_ce: 0.004094
 91%|██████████████████████████▍  | 364/400 [2:49:11<16:02, 26.74s/it]2022-01-14 17:41:52,863 iteration 6189 : loss : 0.010522, loss_ce: 0.003004
2022-01-14 17:41:54,269 iteration 6190 : loss : 0.012981, loss_ce: 0.004506
2022-01-14 17:41:55,909 iteration 6191 : loss : 0.022316, loss_ce: 0.007775
2022-01-14 17:41:57,437 iteration 6192 : loss : 0.011593, loss_ce: 0.004308
2022-01-14 17:41:58,834 iteration 6193 : loss : 0.008995, loss_ce: 0.003309
2022-01-14 17:42:00,355 iteration 6194 : loss : 0.013771, loss_ce: 0.004895
2022-01-14 17:42:01,916 iteration 6195 : loss : 0.013195, loss_ce: 0.005185
2022-01-14 17:42:03,480 iteration 6196 : loss : 0.013601, loss_ce: 0.005948
2022-01-14 17:42:04,972 iteration 6197 : loss : 0.013209, loss_ce: 0.007333
2022-01-14 17:42:06,477 iteration 6198 : loss : 0.013135, loss_ce: 0.004422
2022-01-14 17:42:07,975 iteration 6199 : loss : 0.017330, loss_ce: 0.004302
2022-01-14 17:42:09,375 iteration 6200 : loss : 0.010841, loss_ce: 0.005141
2022-01-14 17:42:10,896 iteration 6201 : loss : 0.019623, loss_ce: 0.006872
2022-01-14 17:42:12,351 iteration 6202 : loss : 0.012378, loss_ce: 0.005027
2022-01-14 17:42:13,835 iteration 6203 : loss : 0.012132, loss_ce: 0.002816
2022-01-14 17:42:15,374 iteration 6204 : loss : 0.012363, loss_ce: 0.005106
2022-01-14 17:42:15,374 Training Data Eval:
2022-01-14 17:42:22,840   Average segmentation loss on training set: 0.0075
2022-01-14 17:42:22,841 Validation Data Eval:
2022-01-14 17:42:25,410   Average segmentation loss on validation set: 0.0825
2022-01-14 17:42:26,941 iteration 6205 : loss : 0.020642, loss_ce: 0.006691
 91%|██████████████████████████▍  | 365/400 [2:49:47<17:08, 29.39s/it]2022-01-14 17:42:28,548 iteration 6206 : loss : 0.020665, loss_ce: 0.009300
2022-01-14 17:42:30,026 iteration 6207 : loss : 0.011549, loss_ce: 0.003441
2022-01-14 17:42:31,644 iteration 6208 : loss : 0.020310, loss_ce: 0.007514
2022-01-14 17:42:33,104 iteration 6209 : loss : 0.015931, loss_ce: 0.004186
2022-01-14 17:42:34,569 iteration 6210 : loss : 0.012832, loss_ce: 0.004657
2022-01-14 17:42:36,097 iteration 6211 : loss : 0.017243, loss_ce: 0.007485
2022-01-14 17:42:37,574 iteration 6212 : loss : 0.017053, loss_ce: 0.004913
2022-01-14 17:42:39,049 iteration 6213 : loss : 0.015887, loss_ce: 0.003740
2022-01-14 17:42:40,520 iteration 6214 : loss : 0.013454, loss_ce: 0.002816
2022-01-14 17:42:42,088 iteration 6215 : loss : 0.014444, loss_ce: 0.006843
2022-01-14 17:42:43,608 iteration 6216 : loss : 0.012712, loss_ce: 0.003995
2022-01-14 17:42:45,022 iteration 6217 : loss : 0.014094, loss_ce: 0.004133
2022-01-14 17:42:46,517 iteration 6218 : loss : 0.010755, loss_ce: 0.004648
2022-01-14 17:42:48,014 iteration 6219 : loss : 0.014042, loss_ce: 0.005343
2022-01-14 17:42:49,523 iteration 6220 : loss : 0.016748, loss_ce: 0.004428
2022-01-14 17:42:51,146 iteration 6221 : loss : 0.014400, loss_ce: 0.007204
2022-01-14 17:42:52,664 iteration 6222 : loss : 0.013332, loss_ce: 0.006531
 92%|██████████████████████████▌  | 366/400 [2:50:12<16:01, 28.29s/it]2022-01-14 17:42:54,231 iteration 6223 : loss : 0.020059, loss_ce: 0.004807
2022-01-14 17:42:55,710 iteration 6224 : loss : 0.014015, loss_ce: 0.004134
2022-01-14 17:42:57,208 iteration 6225 : loss : 0.013041, loss_ce: 0.004881
2022-01-14 17:42:58,818 iteration 6226 : loss : 0.014607, loss_ce: 0.006138
2022-01-14 17:43:00,328 iteration 6227 : loss : 0.011648, loss_ce: 0.002721
2022-01-14 17:43:01,861 iteration 6228 : loss : 0.015732, loss_ce: 0.007053
2022-01-14 17:43:03,318 iteration 6229 : loss : 0.010585, loss_ce: 0.004252
2022-01-14 17:43:04,833 iteration 6230 : loss : 0.013524, loss_ce: 0.005410
2022-01-14 17:43:06,362 iteration 6231 : loss : 0.012188, loss_ce: 0.005059
2022-01-14 17:43:07,902 iteration 6232 : loss : 0.018873, loss_ce: 0.007639
2022-01-14 17:43:09,367 iteration 6233 : loss : 0.013615, loss_ce: 0.006313
2022-01-14 17:43:10,904 iteration 6234 : loss : 0.017004, loss_ce: 0.005863
2022-01-14 17:43:12,500 iteration 6235 : loss : 0.030194, loss_ce: 0.007822
2022-01-14 17:43:13,906 iteration 6236 : loss : 0.009986, loss_ce: 0.003940
2022-01-14 17:43:15,384 iteration 6237 : loss : 0.019000, loss_ce: 0.007766
2022-01-14 17:43:16,815 iteration 6238 : loss : 0.008040, loss_ce: 0.002789
2022-01-14 17:43:18,300 iteration 6239 : loss : 0.009709, loss_ce: 0.004118
 92%|██████████████████████████▌  | 367/400 [2:50:38<15:07, 27.49s/it]2022-01-14 17:43:19,954 iteration 6240 : loss : 0.015299, loss_ce: 0.006414
2022-01-14 17:43:21,486 iteration 6241 : loss : 0.020169, loss_ce: 0.009334
2022-01-14 17:43:23,063 iteration 6242 : loss : 0.012378, loss_ce: 0.004762
2022-01-14 17:43:24,462 iteration 6243 : loss : 0.010135, loss_ce: 0.003797
2022-01-14 17:43:25,920 iteration 6244 : loss : 0.011343, loss_ce: 0.003487
2022-01-14 17:43:27,397 iteration 6245 : loss : 0.015052, loss_ce: 0.005466
2022-01-14 17:43:28,857 iteration 6246 : loss : 0.015005, loss_ce: 0.005896
2022-01-14 17:43:30,315 iteration 6247 : loss : 0.015503, loss_ce: 0.003783
2022-01-14 17:43:31,893 iteration 6248 : loss : 0.015787, loss_ce: 0.006975
2022-01-14 17:43:33,370 iteration 6249 : loss : 0.016732, loss_ce: 0.005752
2022-01-14 17:43:34,924 iteration 6250 : loss : 0.015079, loss_ce: 0.006306
2022-01-14 17:43:36,533 iteration 6251 : loss : 0.012686, loss_ce: 0.004711
2022-01-14 17:43:38,089 iteration 6252 : loss : 0.026114, loss_ce: 0.006698
2022-01-14 17:43:39,551 iteration 6253 : loss : 0.010538, loss_ce: 0.003082
2022-01-14 17:43:41,006 iteration 6254 : loss : 0.010774, loss_ce: 0.004372
2022-01-14 17:43:42,610 iteration 6255 : loss : 0.013021, loss_ce: 0.004357
2022-01-14 17:43:44,136 iteration 6256 : loss : 0.009566, loss_ce: 0.003473
 92%|██████████████████████████▋  | 368/400 [2:51:04<14:23, 26.99s/it]2022-01-14 17:43:45,707 iteration 6257 : loss : 0.011126, loss_ce: 0.003569
2022-01-14 17:43:47,125 iteration 6258 : loss : 0.010125, loss_ce: 0.003540
2022-01-14 17:43:48,699 iteration 6259 : loss : 0.013460, loss_ce: 0.005450
2022-01-14 17:43:50,363 iteration 6260 : loss : 0.034654, loss_ce: 0.008551
2022-01-14 17:43:51,919 iteration 6261 : loss : 0.014556, loss_ce: 0.006934
2022-01-14 17:43:53,487 iteration 6262 : loss : 0.010616, loss_ce: 0.003995
2022-01-14 17:43:54,929 iteration 6263 : loss : 0.010753, loss_ce: 0.003466
2022-01-14 17:43:56,399 iteration 6264 : loss : 0.014782, loss_ce: 0.006859
2022-01-14 17:43:57,921 iteration 6265 : loss : 0.012575, loss_ce: 0.005373
2022-01-14 17:43:59,399 iteration 6266 : loss : 0.010227, loss_ce: 0.003584
2022-01-14 17:44:01,089 iteration 6267 : loss : 0.021746, loss_ce: 0.009796
2022-01-14 17:44:02,577 iteration 6268 : loss : 0.012604, loss_ce: 0.004768
2022-01-14 17:44:04,058 iteration 6269 : loss : 0.011519, loss_ce: 0.004152
2022-01-14 17:44:05,563 iteration 6270 : loss : 0.014007, loss_ce: 0.006994
2022-01-14 17:44:07,118 iteration 6271 : loss : 0.019560, loss_ce: 0.009011
2022-01-14 17:44:08,569 iteration 6272 : loss : 0.014450, loss_ce: 0.004111
2022-01-14 17:44:10,192 iteration 6273 : loss : 0.035567, loss_ce: 0.013524
 92%|██████████████████████████▊  | 369/400 [2:51:30<13:48, 26.71s/it]2022-01-14 17:44:11,863 iteration 6274 : loss : 0.015674, loss_ce: 0.005921
2022-01-14 17:44:13,300 iteration 6275 : loss : 0.016153, loss_ce: 0.005995
2022-01-14 17:44:14,742 iteration 6276 : loss : 0.012874, loss_ce: 0.005125
2022-01-14 17:44:16,272 iteration 6277 : loss : 0.011721, loss_ce: 0.004611
2022-01-14 17:44:17,864 iteration 6278 : loss : 0.014198, loss_ce: 0.005421
2022-01-14 17:44:19,478 iteration 6279 : loss : 0.021369, loss_ce: 0.007146
2022-01-14 17:44:20,894 iteration 6280 : loss : 0.015158, loss_ce: 0.005106
2022-01-14 17:44:22,385 iteration 6281 : loss : 0.016089, loss_ce: 0.004796
2022-01-14 17:44:23,919 iteration 6282 : loss : 0.017639, loss_ce: 0.008521
2022-01-14 17:44:25,526 iteration 6283 : loss : 0.014629, loss_ce: 0.005940
2022-01-14 17:44:27,054 iteration 6284 : loss : 0.010087, loss_ce: 0.002934
2022-01-14 17:44:28,567 iteration 6285 : loss : 0.016237, loss_ce: 0.006783
2022-01-14 17:44:30,161 iteration 6286 : loss : 0.015888, loss_ce: 0.008005
2022-01-14 17:44:31,681 iteration 6287 : loss : 0.013446, loss_ce: 0.005036
2022-01-14 17:44:33,073 iteration 6288 : loss : 0.011111, loss_ce: 0.003938
2022-01-14 17:44:34,563 iteration 6289 : loss : 0.020563, loss_ce: 0.008528
2022-01-14 17:44:34,564 Training Data Eval:
2022-01-14 17:44:42,085   Average segmentation loss on training set: 0.0074
2022-01-14 17:44:42,085 Validation Data Eval:
2022-01-14 17:44:44,664   Average segmentation loss on validation set: 0.0776
2022-01-14 17:44:46,178 iteration 6290 : loss : 0.012767, loss_ce: 0.004729
 92%|██████████████████████████▊  | 370/400 [2:52:06<14:44, 29.49s/it]2022-01-14 17:44:47,729 iteration 6291 : loss : 0.015077, loss_ce: 0.004293
2022-01-14 17:44:49,149 iteration 6292 : loss : 0.011554, loss_ce: 0.003456
2022-01-14 17:44:50,624 iteration 6293 : loss : 0.014563, loss_ce: 0.003557
2022-01-14 17:44:52,211 iteration 6294 : loss : 0.019331, loss_ce: 0.005828
2022-01-14 17:44:53,737 iteration 6295 : loss : 0.013337, loss_ce: 0.004717
2022-01-14 17:44:55,154 iteration 6296 : loss : 0.010366, loss_ce: 0.004093
2022-01-14 17:44:56,729 iteration 6297 : loss : 0.021299, loss_ce: 0.008110
2022-01-14 17:44:58,238 iteration 6298 : loss : 0.013242, loss_ce: 0.006272
2022-01-14 17:44:59,747 iteration 6299 : loss : 0.016392, loss_ce: 0.006733
2022-01-14 17:45:01,338 iteration 6300 : loss : 0.012948, loss_ce: 0.003286
2022-01-14 17:45:02,828 iteration 6301 : loss : 0.012671, loss_ce: 0.006379
2022-01-14 17:45:04,414 iteration 6302 : loss : 0.017722, loss_ce: 0.007251
2022-01-14 17:45:05,911 iteration 6303 : loss : 0.010901, loss_ce: 0.004052
2022-01-14 17:45:07,439 iteration 6304 : loss : 0.013986, loss_ce: 0.005306
2022-01-14 17:45:08,901 iteration 6305 : loss : 0.010579, loss_ce: 0.003361
2022-01-14 17:45:10,410 iteration 6306 : loss : 0.019813, loss_ce: 0.012620
2022-01-14 17:45:11,914 iteration 6307 : loss : 0.012788, loss_ce: 0.004368
 93%|██████████████████████████▉  | 371/400 [2:52:31<13:42, 28.37s/it]2022-01-14 17:45:13,534 iteration 6308 : loss : 0.018607, loss_ce: 0.008560
2022-01-14 17:45:15,027 iteration 6309 : loss : 0.014902, loss_ce: 0.003755
2022-01-14 17:45:16,524 iteration 6310 : loss : 0.010006, loss_ce: 0.004001
2022-01-14 17:45:18,092 iteration 6311 : loss : 0.018883, loss_ce: 0.006322
2022-01-14 17:45:19,571 iteration 6312 : loss : 0.010287, loss_ce: 0.004518
2022-01-14 17:45:21,123 iteration 6313 : loss : 0.015809, loss_ce: 0.004364
2022-01-14 17:45:22,696 iteration 6314 : loss : 0.014829, loss_ce: 0.005665
2022-01-14 17:45:24,202 iteration 6315 : loss : 0.016175, loss_ce: 0.006794
2022-01-14 17:45:25,632 iteration 6316 : loss : 0.013001, loss_ce: 0.004299
2022-01-14 17:45:27,049 iteration 6317 : loss : 0.015240, loss_ce: 0.005713
2022-01-14 17:45:28,579 iteration 6318 : loss : 0.019153, loss_ce: 0.008791
2022-01-14 17:45:30,054 iteration 6319 : loss : 0.012894, loss_ce: 0.004246
2022-01-14 17:45:31,563 iteration 6320 : loss : 0.011767, loss_ce: 0.004943
2022-01-14 17:45:33,086 iteration 6321 : loss : 0.012180, loss_ce: 0.004101
2022-01-14 17:45:34,721 iteration 6322 : loss : 0.024187, loss_ce: 0.008897
2022-01-14 17:45:36,323 iteration 6323 : loss : 0.022903, loss_ce: 0.005835
2022-01-14 17:45:37,795 iteration 6324 : loss : 0.013521, loss_ce: 0.005614
 93%|██████████████████████████▉  | 372/400 [2:52:57<12:53, 27.62s/it]2022-01-14 17:45:39,281 iteration 6325 : loss : 0.012293, loss_ce: 0.006147
2022-01-14 17:45:40,689 iteration 6326 : loss : 0.008962, loss_ce: 0.003373
2022-01-14 17:45:42,298 iteration 6327 : loss : 0.012770, loss_ce: 0.004839
2022-01-14 17:45:43,784 iteration 6328 : loss : 0.009833, loss_ce: 0.003011
2022-01-14 17:45:45,202 iteration 6329 : loss : 0.012686, loss_ce: 0.003299
2022-01-14 17:45:46,738 iteration 6330 : loss : 0.010313, loss_ce: 0.003155
2022-01-14 17:45:48,508 iteration 6331 : loss : 0.017562, loss_ce: 0.007153
2022-01-14 17:45:49,964 iteration 6332 : loss : 0.012115, loss_ce: 0.004955
2022-01-14 17:45:51,502 iteration 6333 : loss : 0.011695, loss_ce: 0.003351
2022-01-14 17:45:52,973 iteration 6334 : loss : 0.015867, loss_ce: 0.007067
2022-01-14 17:45:54,597 iteration 6335 : loss : 0.015489, loss_ce: 0.006245
2022-01-14 17:45:56,045 iteration 6336 : loss : 0.007580, loss_ce: 0.002815
2022-01-14 17:45:57,594 iteration 6337 : loss : 0.023785, loss_ce: 0.009711
2022-01-14 17:45:59,210 iteration 6338 : loss : 0.028837, loss_ce: 0.007498
2022-01-14 17:46:00,674 iteration 6339 : loss : 0.014554, loss_ce: 0.006503
2022-01-14 17:46:02,147 iteration 6340 : loss : 0.011060, loss_ce: 0.005949
2022-01-14 17:46:03,684 iteration 6341 : loss : 0.010623, loss_ce: 0.003508
 93%|███████████████████████████  | 373/400 [2:53:23<12:11, 27.10s/it]2022-01-14 17:46:05,219 iteration 6342 : loss : 0.014608, loss_ce: 0.005679
2022-01-14 17:46:06,693 iteration 6343 : loss : 0.014436, loss_ce: 0.004221
2022-01-14 17:46:08,300 iteration 6344 : loss : 0.019773, loss_ce: 0.007828
2022-01-14 17:46:09,765 iteration 6345 : loss : 0.011367, loss_ce: 0.003313
2022-01-14 17:46:11,230 iteration 6346 : loss : 0.012287, loss_ce: 0.005002
2022-01-14 17:46:12,771 iteration 6347 : loss : 0.016345, loss_ce: 0.008378
2022-01-14 17:46:14,272 iteration 6348 : loss : 0.016225, loss_ce: 0.006255
2022-01-14 17:46:15,757 iteration 6349 : loss : 0.014729, loss_ce: 0.005058
2022-01-14 17:46:17,244 iteration 6350 : loss : 0.011615, loss_ce: 0.004085
2022-01-14 17:46:18,748 iteration 6351 : loss : 0.011964, loss_ce: 0.005198
2022-01-14 17:46:20,322 iteration 6352 : loss : 0.014371, loss_ce: 0.005338
2022-01-14 17:46:21,973 iteration 6353 : loss : 0.026628, loss_ce: 0.007861
2022-01-14 17:46:23,466 iteration 6354 : loss : 0.024909, loss_ce: 0.004863
2022-01-14 17:46:25,050 iteration 6355 : loss : 0.014264, loss_ce: 0.004659
2022-01-14 17:46:26,670 iteration 6356 : loss : 0.027120, loss_ce: 0.011342
2022-01-14 17:46:28,190 iteration 6357 : loss : 0.012661, loss_ce: 0.006560
2022-01-14 17:46:29,762 iteration 6358 : loss : 0.012487, loss_ce: 0.003606
 94%|███████████████████████████  | 374/400 [2:53:49<11:36, 26.80s/it]2022-01-14 17:46:31,302 iteration 6359 : loss : 0.012140, loss_ce: 0.004166
2022-01-14 17:46:32,680 iteration 6360 : loss : 0.008351, loss_ce: 0.002986
2022-01-14 17:46:34,311 iteration 6361 : loss : 0.011401, loss_ce: 0.003851
2022-01-14 17:46:35,857 iteration 6362 : loss : 0.012361, loss_ce: 0.004944
2022-01-14 17:46:37,477 iteration 6363 : loss : 0.022051, loss_ce: 0.006954
2022-01-14 17:46:39,015 iteration 6364 : loss : 0.010562, loss_ce: 0.002864
2022-01-14 17:46:40,489 iteration 6365 : loss : 0.016757, loss_ce: 0.006747
2022-01-14 17:46:41,995 iteration 6366 : loss : 0.011292, loss_ce: 0.003920
2022-01-14 17:46:43,594 iteration 6367 : loss : 0.015991, loss_ce: 0.008389
2022-01-14 17:46:45,125 iteration 6368 : loss : 0.020218, loss_ce: 0.005295
2022-01-14 17:46:46,652 iteration 6369 : loss : 0.017779, loss_ce: 0.004009
2022-01-14 17:46:48,207 iteration 6370 : loss : 0.013422, loss_ce: 0.006463
2022-01-14 17:46:49,642 iteration 6371 : loss : 0.010261, loss_ce: 0.004235
2022-01-14 17:46:51,173 iteration 6372 : loss : 0.019360, loss_ce: 0.009598
2022-01-14 17:46:52,631 iteration 6373 : loss : 0.011272, loss_ce: 0.005329
2022-01-14 17:46:54,074 iteration 6374 : loss : 0.008834, loss_ce: 0.003336
2022-01-14 17:46:54,074 Training Data Eval:
2022-01-14 17:47:01,581   Average segmentation loss on training set: 0.0072
2022-01-14 17:47:01,582 Validation Data Eval:
2022-01-14 17:47:04,150   Average segmentation loss on validation set: 0.0727
2022-01-14 17:47:05,740 iteration 6375 : loss : 0.011634, loss_ce: 0.005785
 94%|███████████████████████████▏ | 375/400 [2:54:25<12:18, 29.55s/it]2022-01-14 17:47:07,354 iteration 6376 : loss : 0.015839, loss_ce: 0.005896
2022-01-14 17:47:08,888 iteration 6377 : loss : 0.017393, loss_ce: 0.004336
2022-01-14 17:47:10,419 iteration 6378 : loss : 0.013327, loss_ce: 0.006437
2022-01-14 17:47:11,958 iteration 6379 : loss : 0.015437, loss_ce: 0.007169
2022-01-14 17:47:13,507 iteration 6380 : loss : 0.023684, loss_ce: 0.008948
2022-01-14 17:47:15,069 iteration 6381 : loss : 0.020449, loss_ce: 0.008155
2022-01-14 17:47:16,592 iteration 6382 : loss : 0.012869, loss_ce: 0.006572
2022-01-14 17:47:18,168 iteration 6383 : loss : 0.017094, loss_ce: 0.005811
2022-01-14 17:47:19,713 iteration 6384 : loss : 0.015242, loss_ce: 0.006203
2022-01-14 17:47:21,070 iteration 6385 : loss : 0.008946, loss_ce: 0.003410
2022-01-14 17:47:22,638 iteration 6386 : loss : 0.011204, loss_ce: 0.003497
2022-01-14 17:47:24,178 iteration 6387 : loss : 0.017472, loss_ce: 0.007934
2022-01-14 17:47:25,606 iteration 6388 : loss : 0.011160, loss_ce: 0.005206
2022-01-14 17:47:27,233 iteration 6389 : loss : 0.012068, loss_ce: 0.004628
2022-01-14 17:47:28,765 iteration 6390 : loss : 0.016465, loss_ce: 0.005010
2022-01-14 17:47:30,306 iteration 6391 : loss : 0.011791, loss_ce: 0.004712
2022-01-14 17:47:31,885 iteration 6392 : loss : 0.018136, loss_ce: 0.004912
 94%|███████████████████████████▎ | 376/400 [2:54:51<11:24, 28.53s/it]2022-01-14 17:47:33,382 iteration 6393 : loss : 0.011958, loss_ce: 0.006185
2022-01-14 17:47:34,877 iteration 6394 : loss : 0.008940, loss_ce: 0.003818
2022-01-14 17:47:36,372 iteration 6395 : loss : 0.009156, loss_ce: 0.002996
2022-01-14 17:47:37,929 iteration 6396 : loss : 0.016451, loss_ce: 0.006991
2022-01-14 17:47:39,509 iteration 6397 : loss : 0.016110, loss_ce: 0.004898
2022-01-14 17:47:41,079 iteration 6398 : loss : 0.012159, loss_ce: 0.004522
2022-01-14 17:47:42,509 iteration 6399 : loss : 0.014010, loss_ce: 0.004110
2022-01-14 17:47:43,960 iteration 6400 : loss : 0.010050, loss_ce: 0.003288
2022-01-14 17:47:45,409 iteration 6401 : loss : 0.009802, loss_ce: 0.003644
2022-01-14 17:47:46,958 iteration 6402 : loss : 0.014532, loss_ce: 0.006422
2022-01-14 17:47:48,417 iteration 6403 : loss : 0.011463, loss_ce: 0.004884
2022-01-14 17:47:49,857 iteration 6404 : loss : 0.010219, loss_ce: 0.004897
2022-01-14 17:47:51,506 iteration 6405 : loss : 0.023923, loss_ce: 0.008517
2022-01-14 17:47:52,914 iteration 6406 : loss : 0.008762, loss_ce: 0.003225
2022-01-14 17:47:54,447 iteration 6407 : loss : 0.018964, loss_ce: 0.007644
2022-01-14 17:47:55,991 iteration 6408 : loss : 0.012748, loss_ce: 0.004682
2022-01-14 17:47:57,451 iteration 6409 : loss : 0.008657, loss_ce: 0.002806
 94%|███████████████████████████▎ | 377/400 [2:55:17<10:35, 27.64s/it]2022-01-14 17:47:58,921 iteration 6410 : loss : 0.011139, loss_ce: 0.004415
2022-01-14 17:48:00,424 iteration 6411 : loss : 0.011704, loss_ce: 0.004511
2022-01-14 17:48:02,027 iteration 6412 : loss : 0.015000, loss_ce: 0.005584
2022-01-14 17:48:03,558 iteration 6413 : loss : 0.018347, loss_ce: 0.007197
2022-01-14 17:48:05,108 iteration 6414 : loss : 0.013123, loss_ce: 0.004974
2022-01-14 17:48:06,630 iteration 6415 : loss : 0.010710, loss_ce: 0.003158
2022-01-14 17:48:08,052 iteration 6416 : loss : 0.012583, loss_ce: 0.004908
2022-01-14 17:48:09,605 iteration 6417 : loss : 0.018554, loss_ce: 0.006307
2022-01-14 17:48:11,135 iteration 6418 : loss : 0.015783, loss_ce: 0.007007
2022-01-14 17:48:12,649 iteration 6419 : loss : 0.014715, loss_ce: 0.006370
2022-01-14 17:48:14,166 iteration 6420 : loss : 0.017367, loss_ce: 0.006941
2022-01-14 17:48:15,717 iteration 6421 : loss : 0.014107, loss_ce: 0.005472
2022-01-14 17:48:17,225 iteration 6422 : loss : 0.012784, loss_ce: 0.004807
2022-01-14 17:48:18,747 iteration 6423 : loss : 0.010110, loss_ce: 0.003770
2022-01-14 17:48:20,198 iteration 6424 : loss : 0.012056, loss_ce: 0.003922
2022-01-14 17:48:21,889 iteration 6425 : loss : 0.018482, loss_ce: 0.005897
2022-01-14 17:48:23,324 iteration 6426 : loss : 0.013388, loss_ce: 0.004275
 94%|███████████████████████████▍ | 378/400 [2:55:43<09:56, 27.11s/it]2022-01-14 17:48:24,912 iteration 6427 : loss : 0.014643, loss_ce: 0.005833
2022-01-14 17:48:26,431 iteration 6428 : loss : 0.030824, loss_ce: 0.008097
2022-01-14 17:48:27,922 iteration 6429 : loss : 0.010870, loss_ce: 0.004386
2022-01-14 17:48:29,523 iteration 6430 : loss : 0.015025, loss_ce: 0.007269
2022-01-14 17:48:31,016 iteration 6431 : loss : 0.012426, loss_ce: 0.003858
2022-01-14 17:48:32,557 iteration 6432 : loss : 0.015342, loss_ce: 0.005383
2022-01-14 17:48:34,075 iteration 6433 : loss : 0.012026, loss_ce: 0.003083
2022-01-14 17:48:35,582 iteration 6434 : loss : 0.017799, loss_ce: 0.007519
2022-01-14 17:48:36,973 iteration 6435 : loss : 0.008967, loss_ce: 0.002889
2022-01-14 17:48:38,413 iteration 6436 : loss : 0.011949, loss_ce: 0.007001
2022-01-14 17:48:39,840 iteration 6437 : loss : 0.010278, loss_ce: 0.003589
2022-01-14 17:48:41,283 iteration 6438 : loss : 0.009210, loss_ce: 0.004277
2022-01-14 17:48:42,881 iteration 6439 : loss : 0.022256, loss_ce: 0.007131
2022-01-14 17:48:44,411 iteration 6440 : loss : 0.012737, loss_ce: 0.004591
2022-01-14 17:48:45,949 iteration 6441 : loss : 0.010186, loss_ce: 0.004065
2022-01-14 17:48:47,435 iteration 6442 : loss : 0.009661, loss_ce: 0.004078
2022-01-14 17:48:48,898 iteration 6443 : loss : 0.011321, loss_ce: 0.003748
 95%|███████████████████████████▍ | 379/400 [2:56:08<09:19, 26.65s/it]2022-01-14 17:48:50,401 iteration 6444 : loss : 0.012257, loss_ce: 0.005239
2022-01-14 17:48:51,863 iteration 6445 : loss : 0.009892, loss_ce: 0.003850
2022-01-14 17:48:53,352 iteration 6446 : loss : 0.011883, loss_ce: 0.004066
2022-01-14 17:48:54,840 iteration 6447 : loss : 0.010554, loss_ce: 0.004309
2022-01-14 17:48:56,352 iteration 6448 : loss : 0.017780, loss_ce: 0.003904
2022-01-14 17:48:57,878 iteration 6449 : loss : 0.013668, loss_ce: 0.004152
2022-01-14 17:48:59,430 iteration 6450 : loss : 0.017393, loss_ce: 0.004613
2022-01-14 17:49:00,925 iteration 6451 : loss : 0.013481, loss_ce: 0.004459
2022-01-14 17:49:02,519 iteration 6452 : loss : 0.023293, loss_ce: 0.005401
2022-01-14 17:49:03,983 iteration 6453 : loss : 0.010296, loss_ce: 0.004087
2022-01-14 17:49:05,506 iteration 6454 : loss : 0.014050, loss_ce: 0.004045
2022-01-14 17:49:06,969 iteration 6455 : loss : 0.011382, loss_ce: 0.004539
2022-01-14 17:49:08,483 iteration 6456 : loss : 0.012588, loss_ce: 0.006283
2022-01-14 17:49:09,956 iteration 6457 : loss : 0.009449, loss_ce: 0.003869
2022-01-14 17:49:11,401 iteration 6458 : loss : 0.012734, loss_ce: 0.007183
2022-01-14 17:49:12,963 iteration 6459 : loss : 0.012233, loss_ce: 0.005006
2022-01-14 17:49:12,963 Training Data Eval:
2022-01-14 17:49:20,454   Average segmentation loss on training set: 0.0068
2022-01-14 17:49:20,454 Validation Data Eval:
2022-01-14 17:49:23,035   Average segmentation loss on validation set: 0.0716
2022-01-14 17:49:24,606 iteration 6460 : loss : 0.012170, loss_ce: 0.004143
 95%|███████████████████████████▌ | 380/400 [2:56:44<09:47, 29.37s/it]2022-01-14 17:49:26,147 iteration 6461 : loss : 0.010963, loss_ce: 0.003533
2022-01-14 17:49:27,672 iteration 6462 : loss : 0.011422, loss_ce: 0.004484
2022-01-14 17:49:29,126 iteration 6463 : loss : 0.013477, loss_ce: 0.006321
2022-01-14 17:49:30,608 iteration 6464 : loss : 0.011315, loss_ce: 0.004357
2022-01-14 17:49:32,116 iteration 6465 : loss : 0.009775, loss_ce: 0.003302
2022-01-14 17:49:33,630 iteration 6466 : loss : 0.014752, loss_ce: 0.005651
2022-01-14 17:49:35,155 iteration 6467 : loss : 0.012158, loss_ce: 0.005139
2022-01-14 17:49:36,583 iteration 6468 : loss : 0.008875, loss_ce: 0.002830
2022-01-14 17:49:38,115 iteration 6469 : loss : 0.019054, loss_ce: 0.005247
2022-01-14 17:49:39,665 iteration 6470 : loss : 0.012164, loss_ce: 0.004773
2022-01-14 17:49:41,208 iteration 6471 : loss : 0.017913, loss_ce: 0.008061
2022-01-14 17:49:42,665 iteration 6472 : loss : 0.015969, loss_ce: 0.006048
2022-01-14 17:49:44,216 iteration 6473 : loss : 0.012720, loss_ce: 0.004863
2022-01-14 17:49:45,765 iteration 6474 : loss : 0.012446, loss_ce: 0.005373
2022-01-14 17:49:47,332 iteration 6475 : loss : 0.020625, loss_ce: 0.006835
2022-01-14 17:49:48,867 iteration 6476 : loss : 0.011799, loss_ce: 0.003951
2022-01-14 17:49:50,361 iteration 6477 : loss : 0.014174, loss_ce: 0.006094
 95%|███████████████████████████▌ | 381/400 [2:57:10<08:57, 28.28s/it]2022-01-14 17:49:51,906 iteration 6478 : loss : 0.011705, loss_ce: 0.004534
2022-01-14 17:49:53,452 iteration 6479 : loss : 0.015566, loss_ce: 0.005392
2022-01-14 17:49:54,938 iteration 6480 : loss : 0.010281, loss_ce: 0.003369
2022-01-14 17:49:56,600 iteration 6481 : loss : 0.018761, loss_ce: 0.006348
2022-01-14 17:49:58,088 iteration 6482 : loss : 0.013270, loss_ce: 0.005750
2022-01-14 17:49:59,650 iteration 6483 : loss : 0.017496, loss_ce: 0.006745
2022-01-14 17:50:01,043 iteration 6484 : loss : 0.012716, loss_ce: 0.004494
2022-01-14 17:50:02,561 iteration 6485 : loss : 0.012799, loss_ce: 0.004429
2022-01-14 17:50:04,092 iteration 6486 : loss : 0.014956, loss_ce: 0.004947
2022-01-14 17:50:05,654 iteration 6487 : loss : 0.015343, loss_ce: 0.006068
2022-01-14 17:50:07,231 iteration 6488 : loss : 0.010134, loss_ce: 0.003598
2022-01-14 17:50:08,734 iteration 6489 : loss : 0.013495, loss_ce: 0.004277
2022-01-14 17:50:10,266 iteration 6490 : loss : 0.016132, loss_ce: 0.006354
2022-01-14 17:50:11,735 iteration 6491 : loss : 0.012286, loss_ce: 0.005835
2022-01-14 17:50:13,197 iteration 6492 : loss : 0.011168, loss_ce: 0.005598
2022-01-14 17:50:14,659 iteration 6493 : loss : 0.024869, loss_ce: 0.008636
2022-01-14 17:50:16,162 iteration 6494 : loss : 0.016607, loss_ce: 0.006002
 96%|███████████████████████████▋ | 382/400 [2:57:36<08:15, 27.54s/it]2022-01-14 17:50:17,614 iteration 6495 : loss : 0.011954, loss_ce: 0.005812
2022-01-14 17:50:19,135 iteration 6496 : loss : 0.014634, loss_ce: 0.005147
2022-01-14 17:50:20,688 iteration 6497 : loss : 0.010266, loss_ce: 0.005402
2022-01-14 17:50:22,154 iteration 6498 : loss : 0.014657, loss_ce: 0.003329
2022-01-14 17:50:23,609 iteration 6499 : loss : 0.025565, loss_ce: 0.004537
2022-01-14 17:50:25,222 iteration 6500 : loss : 0.028338, loss_ce: 0.008493
2022-01-14 17:50:26,794 iteration 6501 : loss : 0.016489, loss_ce: 0.008419
2022-01-14 17:50:28,313 iteration 6502 : loss : 0.016600, loss_ce: 0.005924
2022-01-14 17:50:29,831 iteration 6503 : loss : 0.014327, loss_ce: 0.005297
2022-01-14 17:50:31,403 iteration 6504 : loss : 0.017199, loss_ce: 0.008762
2022-01-14 17:50:32,827 iteration 6505 : loss : 0.009539, loss_ce: 0.003584
2022-01-14 17:50:34,327 iteration 6506 : loss : 0.017606, loss_ce: 0.004137
2022-01-14 17:50:35,813 iteration 6507 : loss : 0.011719, loss_ce: 0.004891
2022-01-14 17:50:37,247 iteration 6508 : loss : 0.012688, loss_ce: 0.004808
2022-01-14 17:50:38,739 iteration 6509 : loss : 0.010806, loss_ce: 0.003726
2022-01-14 17:50:40,108 iteration 6510 : loss : 0.008186, loss_ce: 0.003105
2022-01-14 17:50:41,643 iteration 6511 : loss : 0.014604, loss_ce: 0.006347
 96%|███████████████████████████▊ | 383/400 [2:58:01<07:37, 26.92s/it]2022-01-14 17:50:43,222 iteration 6512 : loss : 0.014847, loss_ce: 0.004992
2022-01-14 17:50:44,799 iteration 6513 : loss : 0.011333, loss_ce: 0.004161
2022-01-14 17:50:46,300 iteration 6514 : loss : 0.016357, loss_ce: 0.004959
2022-01-14 17:50:47,877 iteration 6515 : loss : 0.018458, loss_ce: 0.006310
2022-01-14 17:50:49,350 iteration 6516 : loss : 0.010807, loss_ce: 0.004139
2022-01-14 17:50:50,776 iteration 6517 : loss : 0.011585, loss_ce: 0.004902
2022-01-14 17:50:52,309 iteration 6518 : loss : 0.015700, loss_ce: 0.005448
2022-01-14 17:50:53,904 iteration 6519 : loss : 0.018191, loss_ce: 0.007105
2022-01-14 17:50:55,326 iteration 6520 : loss : 0.012180, loss_ce: 0.004779
2022-01-14 17:50:56,922 iteration 6521 : loss : 0.011803, loss_ce: 0.004651
2022-01-14 17:50:58,430 iteration 6522 : loss : 0.013449, loss_ce: 0.004490
2022-01-14 17:50:59,967 iteration 6523 : loss : 0.012663, loss_ce: 0.005192
2022-01-14 17:51:01,496 iteration 6524 : loss : 0.016426, loss_ce: 0.005515
2022-01-14 17:51:03,027 iteration 6525 : loss : 0.014679, loss_ce: 0.005076
2022-01-14 17:51:04,552 iteration 6526 : loss : 0.011608, loss_ce: 0.004253
2022-01-14 17:51:06,010 iteration 6527 : loss : 0.013293, loss_ce: 0.004576
2022-01-14 17:51:07,481 iteration 6528 : loss : 0.010891, loss_ce: 0.004081
 96%|███████████████████████████▊ | 384/400 [2:58:27<07:05, 26.60s/it]2022-01-14 17:51:09,197 iteration 6529 : loss : 0.017153, loss_ce: 0.007181
2022-01-14 17:51:10,680 iteration 6530 : loss : 0.015314, loss_ce: 0.007538
2022-01-14 17:51:12,311 iteration 6531 : loss : 0.015024, loss_ce: 0.005340
2022-01-14 17:51:13,836 iteration 6532 : loss : 0.018575, loss_ce: 0.007522
2022-01-14 17:51:15,437 iteration 6533 : loss : 0.028805, loss_ce: 0.005618
2022-01-14 17:51:17,118 iteration 6534 : loss : 0.018929, loss_ce: 0.004782
2022-01-14 17:51:18,517 iteration 6535 : loss : 0.014142, loss_ce: 0.002850
2022-01-14 17:51:20,024 iteration 6536 : loss : 0.015901, loss_ce: 0.005932
2022-01-14 17:51:21,578 iteration 6537 : loss : 0.012620, loss_ce: 0.005122
2022-01-14 17:51:23,125 iteration 6538 : loss : 0.013887, loss_ce: 0.006869
2022-01-14 17:51:24,705 iteration 6539 : loss : 0.018343, loss_ce: 0.006818
2022-01-14 17:51:26,196 iteration 6540 : loss : 0.012514, loss_ce: 0.005506
2022-01-14 17:51:27,715 iteration 6541 : loss : 0.010176, loss_ce: 0.004157
2022-01-14 17:51:29,279 iteration 6542 : loss : 0.021725, loss_ce: 0.010045
2022-01-14 17:51:30,835 iteration 6543 : loss : 0.021016, loss_ce: 0.008152
2022-01-14 17:51:32,267 iteration 6544 : loss : 0.009255, loss_ce: 0.002979
2022-01-14 17:51:32,267 Training Data Eval:
2022-01-14 17:51:39,764   Average segmentation loss on training set: 0.0069
2022-01-14 17:51:39,764 Validation Data Eval:
2022-01-14 17:51:42,327   Average segmentation loss on validation set: 0.0784
2022-01-14 17:51:43,723 iteration 6545 : loss : 0.007632, loss_ce: 0.001716
 96%|███████████████████████████▉ | 385/400 [2:59:03<07:22, 29.49s/it]2022-01-14 17:51:45,294 iteration 6546 : loss : 0.020270, loss_ce: 0.006072
2022-01-14 17:51:47,035 iteration 6547 : loss : 0.020578, loss_ce: 0.008509
2022-01-14 17:51:48,445 iteration 6548 : loss : 0.011910, loss_ce: 0.006950
2022-01-14 17:51:49,874 iteration 6549 : loss : 0.006764, loss_ce: 0.002342
2022-01-14 17:51:51,353 iteration 6550 : loss : 0.010742, loss_ce: 0.004022
2022-01-14 17:51:52,918 iteration 6551 : loss : 0.014023, loss_ce: 0.006118
2022-01-14 17:51:54,343 iteration 6552 : loss : 0.010938, loss_ce: 0.005008
2022-01-14 17:51:55,944 iteration 6553 : loss : 0.018855, loss_ce: 0.007438
2022-01-14 17:51:57,446 iteration 6554 : loss : 0.011729, loss_ce: 0.003193
2022-01-14 17:51:59,027 iteration 6555 : loss : 0.015063, loss_ce: 0.005269
2022-01-14 17:52:00,579 iteration 6556 : loss : 0.012967, loss_ce: 0.003373
2022-01-14 17:52:02,050 iteration 6557 : loss : 0.015469, loss_ce: 0.004588
2022-01-14 17:52:03,509 iteration 6558 : loss : 0.017205, loss_ce: 0.004956
2022-01-14 17:52:05,051 iteration 6559 : loss : 0.012666, loss_ce: 0.005243
2022-01-14 17:52:06,639 iteration 6560 : loss : 0.038584, loss_ce: 0.008086
2022-01-14 17:52:08,107 iteration 6561 : loss : 0.012754, loss_ce: 0.004727
2022-01-14 17:52:09,525 iteration 6562 : loss : 0.008084, loss_ce: 0.002538
 96%|███████████████████████████▉ | 386/400 [2:59:29<06:37, 28.39s/it]2022-01-14 17:52:11,038 iteration 6563 : loss : 0.010775, loss_ce: 0.004715
2022-01-14 17:52:12,498 iteration 6564 : loss : 0.014729, loss_ce: 0.003976
2022-01-14 17:52:13,932 iteration 6565 : loss : 0.008759, loss_ce: 0.002406
2022-01-14 17:52:15,397 iteration 6566 : loss : 0.009611, loss_ce: 0.003822
2022-01-14 17:52:16,922 iteration 6567 : loss : 0.013866, loss_ce: 0.005424
2022-01-14 17:52:18,444 iteration 6568 : loss : 0.027941, loss_ce: 0.009112
2022-01-14 17:52:20,082 iteration 6569 : loss : 0.014816, loss_ce: 0.004690
2022-01-14 17:52:21,582 iteration 6570 : loss : 0.013887, loss_ce: 0.003557
2022-01-14 17:52:23,252 iteration 6571 : loss : 0.019926, loss_ce: 0.009261
2022-01-14 17:52:24,680 iteration 6572 : loss : 0.009911, loss_ce: 0.004238
2022-01-14 17:52:26,246 iteration 6573 : loss : 0.020327, loss_ce: 0.006337
2022-01-14 17:52:27,703 iteration 6574 : loss : 0.009563, loss_ce: 0.002809
2022-01-14 17:52:29,290 iteration 6575 : loss : 0.025928, loss_ce: 0.008088
2022-01-14 17:52:30,811 iteration 6576 : loss : 0.011735, loss_ce: 0.004620
2022-01-14 17:52:32,284 iteration 6577 : loss : 0.012739, loss_ce: 0.004177
2022-01-14 17:52:33,805 iteration 6578 : loss : 0.009865, loss_ce: 0.003658
2022-01-14 17:52:35,298 iteration 6579 : loss : 0.014143, loss_ce: 0.005882
 97%|████████████████████████████ | 387/400 [2:59:55<05:58, 27.60s/it]2022-01-14 17:52:36,919 iteration 6580 : loss : 0.016431, loss_ce: 0.007408
2022-01-14 17:52:38,345 iteration 6581 : loss : 0.009545, loss_ce: 0.002864
2022-01-14 17:52:39,995 iteration 6582 : loss : 0.013168, loss_ce: 0.004088
2022-01-14 17:52:41,541 iteration 6583 : loss : 0.023217, loss_ce: 0.006978
2022-01-14 17:52:43,073 iteration 6584 : loss : 0.018130, loss_ce: 0.007352
2022-01-14 17:52:44,493 iteration 6585 : loss : 0.010275, loss_ce: 0.003149
2022-01-14 17:52:45,991 iteration 6586 : loss : 0.010468, loss_ce: 0.002097
2022-01-14 17:52:47,437 iteration 6587 : loss : 0.010689, loss_ce: 0.004862
2022-01-14 17:52:48,940 iteration 6588 : loss : 0.009332, loss_ce: 0.004272
2022-01-14 17:52:50,443 iteration 6589 : loss : 0.011150, loss_ce: 0.004572
2022-01-14 17:52:51,906 iteration 6590 : loss : 0.010548, loss_ce: 0.004664
2022-01-14 17:52:53,376 iteration 6591 : loss : 0.008907, loss_ce: 0.002953
2022-01-14 17:52:54,960 iteration 6592 : loss : 0.011641, loss_ce: 0.005658
2022-01-14 17:52:56,378 iteration 6593 : loss : 0.009342, loss_ce: 0.004811
2022-01-14 17:52:57,876 iteration 6594 : loss : 0.011739, loss_ce: 0.004528
2022-01-14 17:52:59,441 iteration 6595 : loss : 0.017227, loss_ce: 0.005436
2022-01-14 17:53:00,876 iteration 6596 : loss : 0.009197, loss_ce: 0.002514
 97%|████████████████████████████▏| 388/400 [3:00:20<05:23, 27.00s/it]2022-01-14 17:53:02,372 iteration 6597 : loss : 0.010569, loss_ce: 0.004850
2022-01-14 17:53:03,960 iteration 6598 : loss : 0.017067, loss_ce: 0.003204
2022-01-14 17:53:05,501 iteration 6599 : loss : 0.013705, loss_ce: 0.004898
2022-01-14 17:53:06,923 iteration 6600 : loss : 0.009339, loss_ce: 0.003585
2022-01-14 17:53:08,566 iteration 6601 : loss : 0.013244, loss_ce: 0.005116
2022-01-14 17:53:10,130 iteration 6602 : loss : 0.012362, loss_ce: 0.004552
2022-01-14 17:53:11,597 iteration 6603 : loss : 0.011954, loss_ce: 0.005281
2022-01-14 17:53:13,126 iteration 6604 : loss : 0.012967, loss_ce: 0.006134
2022-01-14 17:53:14,610 iteration 6605 : loss : 0.014682, loss_ce: 0.006148
2022-01-14 17:53:16,169 iteration 6606 : loss : 0.016198, loss_ce: 0.005524
2022-01-14 17:53:17,721 iteration 6607 : loss : 0.015196, loss_ce: 0.006060
2022-01-14 17:53:19,165 iteration 6608 : loss : 0.011634, loss_ce: 0.004987
2022-01-14 17:53:20,758 iteration 6609 : loss : 0.015881, loss_ce: 0.007745
2022-01-14 17:53:22,245 iteration 6610 : loss : 0.010618, loss_ce: 0.003981
2022-01-14 17:53:23,725 iteration 6611 : loss : 0.009743, loss_ce: 0.002993
2022-01-14 17:53:25,221 iteration 6612 : loss : 0.010482, loss_ce: 0.002734
2022-01-14 17:53:26,755 iteration 6613 : loss : 0.012723, loss_ce: 0.004537
 97%|████████████████████████████▏| 389/400 [3:00:46<04:53, 26.66s/it]2022-01-14 17:53:28,249 iteration 6614 : loss : 0.009131, loss_ce: 0.003287
2022-01-14 17:53:29,698 iteration 6615 : loss : 0.008154, loss_ce: 0.003022
2022-01-14 17:53:31,258 iteration 6616 : loss : 0.013346, loss_ce: 0.004506
2022-01-14 17:53:32,727 iteration 6617 : loss : 0.023295, loss_ce: 0.007054
2022-01-14 17:53:34,291 iteration 6618 : loss : 0.017281, loss_ce: 0.006554
2022-01-14 17:53:35,824 iteration 6619 : loss : 0.015698, loss_ce: 0.005759
2022-01-14 17:53:37,345 iteration 6620 : loss : 0.012025, loss_ce: 0.003752
2022-01-14 17:53:38,895 iteration 6621 : loss : 0.013265, loss_ce: 0.004503
2022-01-14 17:53:40,375 iteration 6622 : loss : 0.017243, loss_ce: 0.007598
2022-01-14 17:53:41,814 iteration 6623 : loss : 0.012186, loss_ce: 0.003972
2022-01-14 17:53:43,309 iteration 6624 : loss : 0.012058, loss_ce: 0.004730
2022-01-14 17:53:44,835 iteration 6625 : loss : 0.024984, loss_ce: 0.008091
2022-01-14 17:53:46,332 iteration 6626 : loss : 0.015937, loss_ce: 0.006926
2022-01-14 17:53:47,870 iteration 6627 : loss : 0.015930, loss_ce: 0.005744
2022-01-14 17:53:49,418 iteration 6628 : loss : 0.014089, loss_ce: 0.005764
2022-01-14 17:53:51,054 iteration 6629 : loss : 0.016507, loss_ce: 0.005096
2022-01-14 17:53:51,055 Training Data Eval:
2022-01-14 17:53:58,527   Average segmentation loss on training set: 0.0067
2022-01-14 17:53:58,527 Validation Data Eval:
2022-01-14 17:54:01,086   Average segmentation loss on validation set: 0.0825
2022-01-14 17:54:02,564 iteration 6630 : loss : 0.012578, loss_ce: 0.005175
 98%|████████████████████████████▎| 390/400 [3:01:22<04:54, 29.40s/it]2022-01-14 17:54:04,153 iteration 6631 : loss : 0.014684, loss_ce: 0.004556
2022-01-14 17:54:05,677 iteration 6632 : loss : 0.010359, loss_ce: 0.004945
2022-01-14 17:54:07,277 iteration 6633 : loss : 0.013705, loss_ce: 0.003675
2022-01-14 17:54:08,788 iteration 6634 : loss : 0.014329, loss_ce: 0.005503
2022-01-14 17:54:10,293 iteration 6635 : loss : 0.011891, loss_ce: 0.005034
2022-01-14 17:54:11,800 iteration 6636 : loss : 0.011717, loss_ce: 0.006408
2022-01-14 17:54:13,256 iteration 6637 : loss : 0.013648, loss_ce: 0.004764
2022-01-14 17:54:14,821 iteration 6638 : loss : 0.022937, loss_ce: 0.004758
2022-01-14 17:54:16,401 iteration 6639 : loss : 0.013581, loss_ce: 0.005294
2022-01-14 17:54:17,881 iteration 6640 : loss : 0.009330, loss_ce: 0.002851
2022-01-14 17:54:19,412 iteration 6641 : loss : 0.011423, loss_ce: 0.003392
2022-01-14 17:54:20,930 iteration 6642 : loss : 0.015365, loss_ce: 0.007112
2022-01-14 17:54:22,471 iteration 6643 : loss : 0.015902, loss_ce: 0.007085
2022-01-14 17:54:24,114 iteration 6644 : loss : 0.019920, loss_ce: 0.007610
2022-01-14 17:54:25,560 iteration 6645 : loss : 0.010141, loss_ce: 0.004104
2022-01-14 17:54:27,187 iteration 6646 : loss : 0.022675, loss_ce: 0.006799
2022-01-14 17:54:28,679 iteration 6647 : loss : 0.016264, loss_ce: 0.005702
 98%|████████████████████████████▎| 391/400 [3:01:48<04:15, 28.42s/it]2022-01-14 17:54:30,206 iteration 6648 : loss : 0.011827, loss_ce: 0.002880
2022-01-14 17:54:31,774 iteration 6649 : loss : 0.014416, loss_ce: 0.004748
2022-01-14 17:54:33,378 iteration 6650 : loss : 0.017425, loss_ce: 0.006472
2022-01-14 17:54:35,001 iteration 6651 : loss : 0.018979, loss_ce: 0.007887
2022-01-14 17:54:36,486 iteration 6652 : loss : 0.011628, loss_ce: 0.004922
2022-01-14 17:54:37,912 iteration 6653 : loss : 0.008680, loss_ce: 0.003444
2022-01-14 17:54:39,403 iteration 6654 : loss : 0.012709, loss_ce: 0.004461
2022-01-14 17:54:40,952 iteration 6655 : loss : 0.018599, loss_ce: 0.006621
2022-01-14 17:54:42,501 iteration 6656 : loss : 0.020006, loss_ce: 0.008523
2022-01-14 17:54:43,991 iteration 6657 : loss : 0.016918, loss_ce: 0.004292
2022-01-14 17:54:45,537 iteration 6658 : loss : 0.013528, loss_ce: 0.004609
2022-01-14 17:54:47,092 iteration 6659 : loss : 0.014755, loss_ce: 0.006999
2022-01-14 17:54:48,691 iteration 6660 : loss : 0.015139, loss_ce: 0.006257
2022-01-14 17:54:50,221 iteration 6661 : loss : 0.012145, loss_ce: 0.004437
2022-01-14 17:54:51,764 iteration 6662 : loss : 0.017434, loss_ce: 0.004040
2022-01-14 17:54:53,280 iteration 6663 : loss : 0.017854, loss_ce: 0.006466
2022-01-14 17:54:54,860 iteration 6664 : loss : 0.016135, loss_ce: 0.008599
 98%|████████████████████████████▍| 392/400 [3:02:14<03:41, 27.75s/it]2022-01-14 17:54:56,463 iteration 6665 : loss : 0.013667, loss_ce: 0.003911
2022-01-14 17:54:58,086 iteration 6666 : loss : 0.021589, loss_ce: 0.005323
2022-01-14 17:54:59,604 iteration 6667 : loss : 0.013539, loss_ce: 0.002256
2022-01-14 17:55:01,055 iteration 6668 : loss : 0.019650, loss_ce: 0.010697
2022-01-14 17:55:02,585 iteration 6669 : loss : 0.014045, loss_ce: 0.005465
2022-01-14 17:55:04,071 iteration 6670 : loss : 0.011992, loss_ce: 0.004914
2022-01-14 17:55:05,580 iteration 6671 : loss : 0.012083, loss_ce: 0.003887
2022-01-14 17:55:07,157 iteration 6672 : loss : 0.014220, loss_ce: 0.003879
2022-01-14 17:55:08,656 iteration 6673 : loss : 0.023299, loss_ce: 0.005958
2022-01-14 17:55:10,157 iteration 6674 : loss : 0.018909, loss_ce: 0.009893
2022-01-14 17:55:11,769 iteration 6675 : loss : 0.015665, loss_ce: 0.007398
2022-01-14 17:55:13,230 iteration 6676 : loss : 0.013688, loss_ce: 0.005495
2022-01-14 17:55:14,718 iteration 6677 : loss : 0.012443, loss_ce: 0.003832
2022-01-14 17:55:16,188 iteration 6678 : loss : 0.011238, loss_ce: 0.005263
2022-01-14 17:55:17,764 iteration 6679 : loss : 0.014186, loss_ce: 0.005714
2022-01-14 17:55:19,193 iteration 6680 : loss : 0.009172, loss_ce: 0.003154
2022-01-14 17:55:20,639 iteration 6681 : loss : 0.009852, loss_ce: 0.003351
 98%|████████████████████████████▍| 393/400 [3:02:40<03:10, 27.16s/it]2022-01-14 17:55:22,319 iteration 6682 : loss : 0.016367, loss_ce: 0.007783
2022-01-14 17:55:23,807 iteration 6683 : loss : 0.011011, loss_ce: 0.004284
2022-01-14 17:55:25,343 iteration 6684 : loss : 0.010151, loss_ce: 0.004339
2022-01-14 17:55:26,784 iteration 6685 : loss : 0.016436, loss_ce: 0.005662
2022-01-14 17:55:28,378 iteration 6686 : loss : 0.012601, loss_ce: 0.005054
2022-01-14 17:55:29,868 iteration 6687 : loss : 0.012268, loss_ce: 0.004327
2022-01-14 17:55:31,367 iteration 6688 : loss : 0.013717, loss_ce: 0.004796
2022-01-14 17:55:32,795 iteration 6689 : loss : 0.007249, loss_ce: 0.001962
2022-01-14 17:55:34,296 iteration 6690 : loss : 0.007605, loss_ce: 0.002170
2022-01-14 17:55:35,862 iteration 6691 : loss : 0.021281, loss_ce: 0.011659
2022-01-14 17:55:37,314 iteration 6692 : loss : 0.015123, loss_ce: 0.005532
2022-01-14 17:55:38,805 iteration 6693 : loss : 0.024160, loss_ce: 0.007193
2022-01-14 17:55:40,356 iteration 6694 : loss : 0.014482, loss_ce: 0.005289
2022-01-14 17:55:41,876 iteration 6695 : loss : 0.012042, loss_ce: 0.003879
2022-01-14 17:55:43,362 iteration 6696 : loss : 0.008919, loss_ce: 0.003493
2022-01-14 17:55:44,856 iteration 6697 : loss : 0.010165, loss_ce: 0.003760
2022-01-14 17:55:46,428 iteration 6698 : loss : 0.014289, loss_ce: 0.004378
 98%|████████████████████████████▌| 394/400 [3:03:06<02:40, 26.75s/it]2022-01-14 17:55:47,956 iteration 6699 : loss : 0.012761, loss_ce: 0.003871
2022-01-14 17:55:49,514 iteration 6700 : loss : 0.018464, loss_ce: 0.005884
2022-01-14 17:55:51,000 iteration 6701 : loss : 0.009433, loss_ce: 0.003030
2022-01-14 17:55:52,443 iteration 6702 : loss : 0.010203, loss_ce: 0.004991
2022-01-14 17:55:53,863 iteration 6703 : loss : 0.011568, loss_ce: 0.004116
2022-01-14 17:55:55,447 iteration 6704 : loss : 0.013803, loss_ce: 0.006865
2022-01-14 17:55:56,897 iteration 6705 : loss : 0.013314, loss_ce: 0.006221
2022-01-14 17:55:58,501 iteration 6706 : loss : 0.015632, loss_ce: 0.005237
2022-01-14 17:55:59,928 iteration 6707 : loss : 0.009586, loss_ce: 0.004039
2022-01-14 17:56:01,456 iteration 6708 : loss : 0.014022, loss_ce: 0.005461
2022-01-14 17:56:03,004 iteration 6709 : loss : 0.017214, loss_ce: 0.007160
2022-01-14 17:56:04,568 iteration 6710 : loss : 0.018908, loss_ce: 0.003512
2022-01-14 17:56:06,093 iteration 6711 : loss : 0.016814, loss_ce: 0.006342
2022-01-14 17:56:07,671 iteration 6712 : loss : 0.019789, loss_ce: 0.008319
2022-01-14 17:56:09,113 iteration 6713 : loss : 0.010465, loss_ce: 0.004618
2022-01-14 17:56:10,657 iteration 6714 : loss : 0.012133, loss_ce: 0.004132
2022-01-14 17:56:10,657 Training Data Eval:
2022-01-14 17:56:18,174   Average segmentation loss on training set: 0.0069
2022-01-14 17:56:18,175 Validation Data Eval:
2022-01-14 17:56:20,748   Average segmentation loss on validation set: 0.0699
2022-01-14 17:56:22,207 iteration 6715 : loss : 0.012516, loss_ce: 0.004698
 99%|████████████████████████████▋| 395/400 [3:03:42<02:27, 29.46s/it]2022-01-14 17:56:23,760 iteration 6716 : loss : 0.013651, loss_ce: 0.006277
2022-01-14 17:56:25,286 iteration 6717 : loss : 0.010073, loss_ce: 0.004085
2022-01-14 17:56:26,814 iteration 6718 : loss : 0.015487, loss_ce: 0.005955
2022-01-14 17:56:28,294 iteration 6719 : loss : 0.012367, loss_ce: 0.004713
2022-01-14 17:56:29,763 iteration 6720 : loss : 0.009707, loss_ce: 0.002943
2022-01-14 17:56:31,241 iteration 6721 : loss : 0.009219, loss_ce: 0.003018
2022-01-14 17:56:32,813 iteration 6722 : loss : 0.010594, loss_ce: 0.004300
2022-01-14 17:56:34,203 iteration 6723 : loss : 0.009640, loss_ce: 0.002914
2022-01-14 17:56:35,706 iteration 6724 : loss : 0.015494, loss_ce: 0.004678
2022-01-14 17:56:37,237 iteration 6725 : loss : 0.009878, loss_ce: 0.003178
2022-01-14 17:56:38,787 iteration 6726 : loss : 0.016736, loss_ce: 0.008060
2022-01-14 17:56:40,406 iteration 6727 : loss : 0.018055, loss_ce: 0.006487
2022-01-14 17:56:41,917 iteration 6728 : loss : 0.013192, loss_ce: 0.004626
2022-01-14 17:56:43,443 iteration 6729 : loss : 0.012351, loss_ce: 0.003894
2022-01-14 17:56:44,907 iteration 6730 : loss : 0.008718, loss_ce: 0.003065
2022-01-14 17:56:46,429 iteration 6731 : loss : 0.012787, loss_ce: 0.004666
2022-01-14 17:56:47,981 iteration 6732 : loss : 0.014711, loss_ce: 0.005564
 99%|████████████████████████████▋| 396/400 [3:04:08<01:53, 28.35s/it]2022-01-14 17:56:49,509 iteration 6733 : loss : 0.011903, loss_ce: 0.004179
2022-01-14 17:56:51,124 iteration 6734 : loss : 0.019047, loss_ce: 0.006794
2022-01-14 17:56:52,584 iteration 6735 : loss : 0.009020, loss_ce: 0.003724
2022-01-14 17:56:54,174 iteration 6736 : loss : 0.015091, loss_ce: 0.005581
2022-01-14 17:56:55,703 iteration 6737 : loss : 0.014587, loss_ce: 0.005278
2022-01-14 17:56:57,115 iteration 6738 : loss : 0.008946, loss_ce: 0.002512
2022-01-14 17:56:58,610 iteration 6739 : loss : 0.010975, loss_ce: 0.004096
2022-01-14 17:57:00,183 iteration 6740 : loss : 0.009638, loss_ce: 0.004203
2022-01-14 17:57:01,665 iteration 6741 : loss : 0.008946, loss_ce: 0.003050
2022-01-14 17:57:03,122 iteration 6742 : loss : 0.012530, loss_ce: 0.004762
2022-01-14 17:57:04,641 iteration 6743 : loss : 0.014445, loss_ce: 0.006489
2022-01-14 17:57:06,181 iteration 6744 : loss : 0.020731, loss_ce: 0.009438
2022-01-14 17:57:07,671 iteration 6745 : loss : 0.011347, loss_ce: 0.004081
2022-01-14 17:57:09,181 iteration 6746 : loss : 0.011098, loss_ce: 0.004842
2022-01-14 17:57:10,756 iteration 6747 : loss : 0.016359, loss_ce: 0.004487
2022-01-14 17:57:12,293 iteration 6748 : loss : 0.013753, loss_ce: 0.004439
2022-01-14 17:57:13,827 iteration 6749 : loss : 0.013090, loss_ce: 0.005041
 99%|████████████████████████████▊| 397/400 [3:04:33<01:22, 27.60s/it]2022-01-14 17:57:15,386 iteration 6750 : loss : 0.011884, loss_ce: 0.004113
2022-01-14 17:57:17,012 iteration 6751 : loss : 0.017449, loss_ce: 0.006412
2022-01-14 17:57:18,611 iteration 6752 : loss : 0.022765, loss_ce: 0.008920
2022-01-14 17:57:20,127 iteration 6753 : loss : 0.013298, loss_ce: 0.005340
2022-01-14 17:57:21,738 iteration 6754 : loss : 0.012854, loss_ce: 0.004915
2022-01-14 17:57:23,196 iteration 6755 : loss : 0.008896, loss_ce: 0.002078
2022-01-14 17:57:24,599 iteration 6756 : loss : 0.007941, loss_ce: 0.003568
2022-01-14 17:57:26,025 iteration 6757 : loss : 0.011303, loss_ce: 0.004541
2022-01-14 17:57:27,492 iteration 6758 : loss : 0.009730, loss_ce: 0.004613
2022-01-14 17:57:29,041 iteration 6759 : loss : 0.017532, loss_ce: 0.004698
2022-01-14 17:57:30,506 iteration 6760 : loss : 0.010024, loss_ce: 0.004081
2022-01-14 17:57:32,007 iteration 6761 : loss : 0.024899, loss_ce: 0.015575
2022-01-14 17:57:33,585 iteration 6762 : loss : 0.012717, loss_ce: 0.003731
2022-01-14 17:57:35,088 iteration 6763 : loss : 0.010262, loss_ce: 0.004753
2022-01-14 17:57:36,637 iteration 6764 : loss : 0.021727, loss_ce: 0.008580
2022-01-14 17:57:38,148 iteration 6765 : loss : 0.015710, loss_ce: 0.003929
2022-01-14 17:57:39,661 iteration 6766 : loss : 0.010495, loss_ce: 0.004543
100%|████████████████████████████▊| 398/400 [3:04:59<00:54, 27.07s/it]2022-01-14 17:57:41,283 iteration 6767 : loss : 0.022222, loss_ce: 0.010384
2022-01-14 17:57:42,742 iteration 6768 : loss : 0.012495, loss_ce: 0.003596
2022-01-14 17:57:44,200 iteration 6769 : loss : 0.009892, loss_ce: 0.003448
2022-01-14 17:57:45,734 iteration 6770 : loss : 0.014602, loss_ce: 0.004344
2022-01-14 17:57:47,217 iteration 6771 : loss : 0.013830, loss_ce: 0.006291
2022-01-14 17:57:48,770 iteration 6772 : loss : 0.013209, loss_ce: 0.005824
2022-01-14 17:57:50,232 iteration 6773 : loss : 0.009363, loss_ce: 0.003552
2022-01-14 17:57:51,724 iteration 6774 : loss : 0.015755, loss_ce: 0.004899
2022-01-14 17:57:53,186 iteration 6775 : loss : 0.012068, loss_ce: 0.002324
2022-01-14 17:57:54,684 iteration 6776 : loss : 0.012688, loss_ce: 0.004718
2022-01-14 17:57:56,199 iteration 6777 : loss : 0.013801, loss_ce: 0.005220
2022-01-14 17:57:57,629 iteration 6778 : loss : 0.010549, loss_ce: 0.004000
2022-01-14 17:57:59,144 iteration 6779 : loss : 0.011040, loss_ce: 0.004782
2022-01-14 17:58:00,690 iteration 6780 : loss : 0.012253, loss_ce: 0.004979
2022-01-14 17:58:02,199 iteration 6781 : loss : 0.012834, loss_ce: 0.004932
2022-01-14 17:58:03,649 iteration 6782 : loss : 0.012194, loss_ce: 0.004782
2022-01-14 17:58:05,217 iteration 6783 : loss : 0.014525, loss_ce: 0.004939
100%|████████████████████████████▉| 399/400 [3:05:25<00:26, 26.62s/it]2022-01-14 17:58:06,673 iteration 6784 : loss : 0.011988, loss_ce: 0.005643
2022-01-14 17:58:08,188 iteration 6785 : loss : 0.010387, loss_ce: 0.003030
2022-01-14 17:58:09,741 iteration 6786 : loss : 0.010803, loss_ce: 0.004101
2022-01-14 17:58:11,220 iteration 6787 : loss : 0.014362, loss_ce: 0.003602
2022-01-14 17:58:12,747 iteration 6788 : loss : 0.011174, loss_ce: 0.005206
2022-01-14 17:58:14,349 iteration 6789 : loss : 0.017339, loss_ce: 0.005094
2022-01-14 17:58:15,832 iteration 6790 : loss : 0.013626, loss_ce: 0.005674
2022-01-14 17:58:17,425 iteration 6791 : loss : 0.016674, loss_ce: 0.005340
2022-01-14 17:58:18,927 iteration 6792 : loss : 0.019149, loss_ce: 0.008464
2022-01-14 17:58:20,327 iteration 6793 : loss : 0.010515, loss_ce: 0.004178
2022-01-14 17:58:21,887 iteration 6794 : loss : 0.015295, loss_ce: 0.005472
2022-01-14 17:58:23,314 iteration 6795 : loss : 0.013059, loss_ce: 0.005929
2022-01-14 17:58:24,787 iteration 6796 : loss : 0.011735, loss_ce: 0.002880
2022-01-14 17:58:26,281 iteration 6797 : loss : 0.012869, loss_ce: 0.004362
2022-01-14 17:58:27,850 iteration 6798 : loss : 0.014720, loss_ce: 0.004584
2022-01-14 17:58:29,321 iteration 6799 : loss : 0.011935, loss_ce: 0.003729
2022-01-14 17:58:29,321 Training Data Eval:
2022-01-14 17:58:36,793   Average segmentation loss on training set: 0.0065
2022-01-14 17:58:36,793 Validation Data Eval:
2022-01-14 17:58:39,363   Average segmentation loss on validation set: 0.0766
2022-01-14 17:58:40,875 iteration 6800 : loss : 0.028280, loss_ce: 0.015692
100%|█████████████████████████████| 400/400 [3:06:00<00:00, 29.33s/it]100%|█████████████████████████████| 400/400 [3:06:00<00:00, 27.90s/it]
