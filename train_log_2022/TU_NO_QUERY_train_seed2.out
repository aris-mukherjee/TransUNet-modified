2022-01-08 09:53:45,217 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-08 09:53:45,218 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-08 09:53:45,218 ============================================================
2022-01-08 09:53:45,218 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-08 09:53:45,218 ============================================================
2022-01-08 09:53:45,218 Loading data...
2022-01-08 09:53:45,218 Reading NCI - RUNMC images...
2022-01-08 09:53:45,218 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-08 09:53:45,221 Already preprocessed this configuration. Loading now!
2022-01-08 09:53:45,247 Training Images: (256, 256, 286)
2022-01-08 09:53:45,247 Training Labels: (256, 256, 286)
2022-01-08 09:53:45,247 Validation Images: (256, 256, 98)
2022-01-08 09:53:45,247 Validation Labels: (256, 256, 98)
2022-01-08 09:53:45,247 ============================================================
2022-01-08 09:53:45,295 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-08 09:53:48,242 iteration 1 : loss : 0.924903, loss_ce: 1.122047
2022-01-08 09:53:49,670 iteration 2 : loss : 0.861915, loss_ce: 1.027042
2022-01-08 09:53:51,175 iteration 3 : loss : 0.800863, loss_ce: 0.934982
2022-01-08 09:53:52,651 iteration 4 : loss : 0.763451, loss_ce: 0.845210
2022-01-08 09:53:54,144 iteration 5 : loss : 0.725324, loss_ce: 0.766672
2022-01-08 09:53:55,703 iteration 6 : loss : 0.681188, loss_ce: 0.705260
2022-01-08 09:53:57,303 iteration 7 : loss : 0.634697, loss_ce: 0.645896
2022-01-08 09:53:58,957 iteration 8 : loss : 0.606253, loss_ce: 0.596880
2022-01-08 09:54:00,463 iteration 9 : loss : 0.593562, loss_ce: 0.545232
2022-01-08 09:54:01,987 iteration 10 : loss : 0.546879, loss_ce: 0.493920
2022-01-08 09:54:03,496 iteration 11 : loss : 0.527094, loss_ce: 0.445199
2022-01-08 09:54:05,044 iteration 12 : loss : 0.510007, loss_ce: 0.425444
2022-01-08 09:54:06,662 iteration 13 : loss : 0.471109, loss_ce: 0.398294
2022-01-08 09:54:08,166 iteration 14 : loss : 0.449490, loss_ce: 0.357226
2022-01-08 09:54:09,777 iteration 15 : loss : 0.428595, loss_ce: 0.325212
2022-01-08 09:54:11,316 iteration 16 : loss : 0.440633, loss_ce: 0.313936
2022-01-08 09:54:12,853 iteration 17 : loss : 0.424488, loss_ce: 0.308221
  0%|                               | 1/400 [00:27<3:03:53, 27.65s/it]2022-01-08 09:54:14,496 iteration 18 : loss : 0.385903, loss_ce: 0.251863
2022-01-08 09:54:16,086 iteration 19 : loss : 0.383963, loss_ce: 0.245439
2022-01-08 09:54:17,657 iteration 20 : loss : 0.362516, loss_ce: 0.230338
2022-01-08 09:54:19,299 iteration 21 : loss : 0.361264, loss_ce: 0.220927
2022-01-08 09:54:20,838 iteration 22 : loss : 0.356561, loss_ce: 0.213403
2022-01-08 09:54:22,414 iteration 23 : loss : 0.323774, loss_ce: 0.179509
2022-01-08 09:54:23,915 iteration 24 : loss : 0.347803, loss_ce: 0.203531
2022-01-08 09:54:25,377 iteration 25 : loss : 0.334234, loss_ce: 0.174877
2022-01-08 09:54:26,883 iteration 26 : loss : 0.340131, loss_ce: 0.171436
2022-01-08 09:54:28,449 iteration 27 : loss : 0.302984, loss_ce: 0.162278
2022-01-08 09:54:29,990 iteration 28 : loss : 0.322375, loss_ce: 0.159322
2022-01-08 09:54:31,686 iteration 29 : loss : 0.321991, loss_ce: 0.164389
2022-01-08 09:54:33,285 iteration 30 : loss : 0.302790, loss_ce: 0.143314
2022-01-08 09:54:34,801 iteration 31 : loss : 0.299184, loss_ce: 0.150465
2022-01-08 09:54:36,326 iteration 32 : loss : 0.299843, loss_ce: 0.143704
2022-01-08 09:54:37,959 iteration 33 : loss : 0.301904, loss_ce: 0.150625
2022-01-08 09:54:39,488 iteration 34 : loss : 0.297904, loss_ce: 0.124986
  0%|▏                              | 2/400 [00:54<2:59:17, 27.03s/it]2022-01-08 09:54:41,142 iteration 35 : loss : 0.292634, loss_ce: 0.144753
2022-01-08 09:54:42,715 iteration 36 : loss : 0.286218, loss_ce: 0.131919
2022-01-08 09:54:44,320 iteration 37 : loss : 0.284705, loss_ce: 0.140227
2022-01-08 09:54:45,987 iteration 38 : loss : 0.278829, loss_ce: 0.120273
2022-01-08 09:54:47,568 iteration 39 : loss : 0.318341, loss_ce: 0.129159
2022-01-08 09:54:49,186 iteration 40 : loss : 0.309980, loss_ce: 0.159806
2022-01-08 09:54:50,695 iteration 41 : loss : 0.286493, loss_ce: 0.113749
2022-01-08 09:54:52,394 iteration 42 : loss : 0.277862, loss_ce: 0.124034
2022-01-08 09:54:53,900 iteration 43 : loss : 0.293639, loss_ce: 0.103997
2022-01-08 09:54:55,490 iteration 44 : loss : 0.271817, loss_ce: 0.108644
2022-01-08 09:54:57,103 iteration 45 : loss : 0.317782, loss_ce: 0.124872
2022-01-08 09:54:58,578 iteration 46 : loss : 0.274883, loss_ce: 0.111215
2022-01-08 09:55:00,131 iteration 47 : loss : 0.296499, loss_ce: 0.105350
2022-01-08 09:55:01,723 iteration 48 : loss : 0.241865, loss_ce: 0.106089
2022-01-08 09:55:03,301 iteration 49 : loss : 0.285329, loss_ce: 0.104421
2022-01-08 09:55:04,914 iteration 50 : loss : 0.259048, loss_ce: 0.092946
2022-01-08 09:55:06,501 iteration 51 : loss : 0.272609, loss_ce: 0.123969
  1%|▏                              | 3/400 [01:21<2:58:47, 27.02s/it]2022-01-08 09:55:08,041 iteration 52 : loss : 0.280072, loss_ce: 0.122578
2022-01-08 09:55:09,513 iteration 53 : loss : 0.248827, loss_ce: 0.108665
2022-01-08 09:55:11,104 iteration 54 : loss : 0.217060, loss_ce: 0.093507
2022-01-08 09:55:12,677 iteration 55 : loss : 0.317522, loss_ce: 0.127684
2022-01-08 09:55:14,285 iteration 56 : loss : 0.276782, loss_ce: 0.108604
2022-01-08 09:55:15,881 iteration 57 : loss : 0.243255, loss_ce: 0.093675
2022-01-08 09:55:17,445 iteration 58 : loss : 0.267711, loss_ce: 0.117739
2022-01-08 09:55:18,996 iteration 59 : loss : 0.258071, loss_ce: 0.102293
2022-01-08 09:55:20,613 iteration 60 : loss : 0.257038, loss_ce: 0.100867
2022-01-08 09:55:22,261 iteration 61 : loss : 0.228813, loss_ce: 0.102128
2022-01-08 09:55:23,835 iteration 62 : loss : 0.253604, loss_ce: 0.106760
2022-01-08 09:55:25,330 iteration 63 : loss : 0.231649, loss_ce: 0.110852
2022-01-08 09:55:26,869 iteration 64 : loss : 0.255554, loss_ce: 0.134148
2022-01-08 09:55:28,445 iteration 65 : loss : 0.253807, loss_ce: 0.104844
2022-01-08 09:55:30,058 iteration 66 : loss : 0.263288, loss_ce: 0.117360
2022-01-08 09:55:31,567 iteration 67 : loss : 0.251388, loss_ce: 0.112389
2022-01-08 09:55:33,136 iteration 68 : loss : 0.280673, loss_ce: 0.110240
  1%|▎                              | 4/400 [01:47<2:57:19, 26.87s/it]2022-01-08 09:55:34,763 iteration 69 : loss : 0.236482, loss_ce: 0.084899
2022-01-08 09:55:36,477 iteration 70 : loss : 0.297761, loss_ce: 0.129057
2022-01-08 09:55:38,343 iteration 71 : loss : 0.218851, loss_ce: 0.087803
2022-01-08 09:55:40,358 iteration 72 : loss : 0.240252, loss_ce: 0.087798
2022-01-08 09:55:42,386 iteration 73 : loss : 0.219527, loss_ce: 0.105609
2022-01-08 09:55:44,511 iteration 74 : loss : 0.256757, loss_ce: 0.112349
2022-01-08 09:55:46,603 iteration 75 : loss : 0.232139, loss_ce: 0.116517
2022-01-08 09:55:48,845 iteration 76 : loss : 0.252148, loss_ce: 0.109136
2022-01-08 09:55:51,104 iteration 77 : loss : 0.233172, loss_ce: 0.091294
2022-01-08 09:55:53,294 iteration 78 : loss : 0.179397, loss_ce: 0.088562
2022-01-08 09:55:55,466 iteration 79 : loss : 0.194684, loss_ce: 0.075125
2022-01-08 09:55:57,759 iteration 80 : loss : 0.279402, loss_ce: 0.112920
2022-01-08 09:55:59,971 iteration 81 : loss : 0.211741, loss_ce: 0.083815
2022-01-08 09:56:02,224 iteration 82 : loss : 0.240983, loss_ce: 0.108602
2022-01-08 09:56:04,495 iteration 83 : loss : 0.212112, loss_ce: 0.082482
2022-01-08 09:56:06,687 iteration 84 : loss : 0.240572, loss_ce: 0.115369
2022-01-08 09:56:06,687 Training Data Eval:
2022-01-08 09:56:18,738   Average segmentation loss on training set: 0.2381
2022-01-08 09:56:18,738 Validation Data Eval:
2022-01-08 09:56:23,210   Average segmentation loss on validation set: 0.2096
2022-01-08 09:56:29,801 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed2.pth
2022-01-08 09:56:31,432 iteration 85 : loss : 0.189676, loss_ce: 0.080379
  1%|▍                              | 5/400 [02:46<4:11:28, 38.20s/it]2022-01-08 09:56:33,011 iteration 86 : loss : 0.306243, loss_ce: 0.120996
2022-01-08 09:56:34,495 iteration 87 : loss : 0.214333, loss_ce: 0.088377
2022-01-08 09:56:36,172 iteration 88 : loss : 0.217980, loss_ce: 0.082913
2022-01-08 09:56:38,081 iteration 89 : loss : 0.206765, loss_ce: 0.089800
2022-01-08 09:56:40,003 iteration 90 : loss : 0.205558, loss_ce: 0.086126
2022-01-08 09:56:42,058 iteration 91 : loss : 0.253406, loss_ce: 0.103729
2022-01-08 09:56:44,113 iteration 92 : loss : 0.193431, loss_ce: 0.078907
2022-01-08 09:56:46,276 iteration 93 : loss : 0.223622, loss_ce: 0.095436
2022-01-08 09:56:48,504 iteration 94 : loss : 0.238942, loss_ce: 0.118286
2022-01-08 09:56:50,702 iteration 95 : loss : 0.217743, loss_ce: 0.085712
2022-01-08 09:56:52,899 iteration 96 : loss : 0.206005, loss_ce: 0.075863
2022-01-08 09:56:55,073 iteration 97 : loss : 0.177717, loss_ce: 0.069983
2022-01-08 09:56:57,395 iteration 98 : loss : 0.235378, loss_ce: 0.095607
2022-01-08 09:56:59,785 iteration 99 : loss : 0.191527, loss_ce: 0.074348
2022-01-08 09:57:02,165 iteration 100 : loss : 0.215655, loss_ce: 0.081308
2022-01-08 09:57:04,310 iteration 101 : loss : 0.236374, loss_ce: 0.097096
2022-01-08 09:57:06,521 iteration 102 : loss : 0.208805, loss_ce: 0.074217
  2%|▍                              | 6/400 [03:21<4:03:57, 37.15s/it]2022-01-08 09:57:08,854 iteration 103 : loss : 0.219768, loss_ce: 0.086185
2022-01-08 09:57:11,269 iteration 104 : loss : 0.216709, loss_ce: 0.076133
2022-01-08 09:57:13,664 iteration 105 : loss : 0.199859, loss_ce: 0.081663
2022-01-08 09:57:16,035 iteration 106 : loss : 0.205621, loss_ce: 0.075501
2022-01-08 09:57:18,380 iteration 107 : loss : 0.179683, loss_ce: 0.070846
2022-01-08 09:57:20,633 iteration 108 : loss : 0.216852, loss_ce: 0.099461
2022-01-08 09:57:22,915 iteration 109 : loss : 0.164330, loss_ce: 0.062425
2022-01-08 09:57:25,344 iteration 110 : loss : 0.190249, loss_ce: 0.085331
2022-01-08 09:57:27,810 iteration 111 : loss : 0.166992, loss_ce: 0.062411
2022-01-08 09:57:30,092 iteration 112 : loss : 0.219669, loss_ce: 0.072633
2022-01-08 09:57:32,549 iteration 113 : loss : 0.173571, loss_ce: 0.061824
2022-01-08 09:57:34,853 iteration 114 : loss : 0.180431, loss_ce: 0.060278
2022-01-08 09:57:37,079 iteration 115 : loss : 0.192840, loss_ce: 0.068972
2022-01-08 09:57:39,472 iteration 116 : loss : 0.241266, loss_ce: 0.101519
2022-01-08 09:57:41,788 iteration 117 : loss : 0.171470, loss_ce: 0.066317
2022-01-08 09:57:44,256 iteration 118 : loss : 0.223240, loss_ce: 0.087575
2022-01-08 09:57:46,587 iteration 119 : loss : 0.257858, loss_ce: 0.118984
  2%|▌                              | 7/400 [04:01<4:09:33, 38.10s/it]2022-01-08 09:57:49,052 iteration 120 : loss : 0.246787, loss_ce: 0.120231
2022-01-08 09:57:51,371 iteration 121 : loss : 0.271536, loss_ce: 0.113786
2022-01-08 09:57:53,620 iteration 122 : loss : 0.211409, loss_ce: 0.086947
2022-01-08 09:57:55,913 iteration 123 : loss : 0.237692, loss_ce: 0.098359
2022-01-08 09:57:58,274 iteration 124 : loss : 0.219571, loss_ce: 0.078274
2022-01-08 09:58:00,559 iteration 125 : loss : 0.220323, loss_ce: 0.082055
2022-01-08 09:58:02,798 iteration 126 : loss : 0.171302, loss_ce: 0.068463
2022-01-08 09:58:05,095 iteration 127 : loss : 0.216021, loss_ce: 0.084586
2022-01-08 09:58:07,411 iteration 128 : loss : 0.234042, loss_ce: 0.090234
2022-01-08 09:58:09,738 iteration 129 : loss : 0.234631, loss_ce: 0.091196
2022-01-08 09:58:12,098 iteration 130 : loss : 0.189327, loss_ce: 0.080075
2022-01-08 09:58:14,451 iteration 131 : loss : 0.193328, loss_ce: 0.087526
2022-01-08 09:58:16,756 iteration 132 : loss : 0.213702, loss_ce: 0.087439
2022-01-08 09:58:19,018 iteration 133 : loss : 0.239737, loss_ce: 0.116528
2022-01-08 09:58:21,331 iteration 134 : loss : 0.158335, loss_ce: 0.057800
2022-01-08 09:58:23,671 iteration 135 : loss : 0.189914, loss_ce: 0.060485
2022-01-08 09:58:26,102 iteration 136 : loss : 0.167633, loss_ce: 0.066348
  2%|▌                              | 8/400 [04:40<4:11:51, 38.55s/it]2022-01-08 09:58:28,580 iteration 137 : loss : 0.201952, loss_ce: 0.065377
2022-01-08 09:58:30,856 iteration 138 : loss : 0.196955, loss_ce: 0.074306
2022-01-08 09:58:33,270 iteration 139 : loss : 0.202261, loss_ce: 0.055222
2022-01-08 09:58:35,682 iteration 140 : loss : 0.264479, loss_ce: 0.106629
2022-01-08 09:58:38,012 iteration 141 : loss : 0.212330, loss_ce: 0.077651
2022-01-08 09:58:40,403 iteration 142 : loss : 0.204884, loss_ce: 0.072713
2022-01-08 09:58:43,001 iteration 143 : loss : 0.219708, loss_ce: 0.079756
2022-01-08 09:58:45,366 iteration 144 : loss : 0.182495, loss_ce: 0.055697
2022-01-08 09:58:47,674 iteration 145 : loss : 0.198090, loss_ce: 0.095421
2022-01-08 09:58:49,975 iteration 146 : loss : 0.159972, loss_ce: 0.063183
2022-01-08 09:58:52,384 iteration 147 : loss : 0.226171, loss_ce: 0.097535
2022-01-08 09:58:54,838 iteration 148 : loss : 0.191012, loss_ce: 0.076681
2022-01-08 09:58:57,188 iteration 149 : loss : 0.189089, loss_ce: 0.071326
2022-01-08 09:58:59,626 iteration 150 : loss : 0.207119, loss_ce: 0.079563
2022-01-08 09:59:02,012 iteration 151 : loss : 0.169179, loss_ce: 0.080117
2022-01-08 09:59:04,268 iteration 152 : loss : 0.144832, loss_ce: 0.063622
2022-01-08 09:59:06,581 iteration 153 : loss : 0.159327, loss_ce: 0.065011
  2%|▋                              | 9/400 [05:21<4:15:08, 39.15s/it]2022-01-08 09:59:09,072 iteration 154 : loss : 0.204213, loss_ce: 0.083731
2022-01-08 09:59:11,393 iteration 155 : loss : 0.172356, loss_ce: 0.069759
2022-01-08 09:59:13,699 iteration 156 : loss : 0.182593, loss_ce: 0.067902
2022-01-08 09:59:15,987 iteration 157 : loss : 0.178663, loss_ce: 0.071214
2022-01-08 09:59:18,440 iteration 158 : loss : 0.193569, loss_ce: 0.076089
2022-01-08 09:59:20,920 iteration 159 : loss : 0.169170, loss_ce: 0.060681
2022-01-08 09:59:23,427 iteration 160 : loss : 0.197115, loss_ce: 0.069603
2022-01-08 09:59:25,897 iteration 161 : loss : 0.170146, loss_ce: 0.075019
2022-01-08 09:59:28,204 iteration 162 : loss : 0.215138, loss_ce: 0.071013
2022-01-08 09:59:30,464 iteration 163 : loss : 0.237474, loss_ce: 0.110217
2022-01-08 09:59:32,766 iteration 164 : loss : 0.200101, loss_ce: 0.063899
2022-01-08 09:59:35,064 iteration 165 : loss : 0.166662, loss_ce: 0.063019
2022-01-08 09:59:37,481 iteration 166 : loss : 0.250435, loss_ce: 0.144911
2022-01-08 09:59:39,979 iteration 167 : loss : 0.278493, loss_ce: 0.129370
2022-01-08 09:59:42,311 iteration 168 : loss : 0.214227, loss_ce: 0.078342
2022-01-08 09:59:44,687 iteration 169 : loss : 0.189700, loss_ce: 0.071288
2022-01-08 09:59:44,688 Training Data Eval:
2022-01-08 09:59:57,227   Average segmentation loss on training set: 1.6330
2022-01-08 09:59:57,228 Validation Data Eval:
2022-01-08 10:00:01,759   Average segmentation loss on validation set: 1.5029
2022-01-08 10:00:04,223 iteration 170 : loss : 0.187540, loss_ce: 0.079858
  2%|▊                             | 10/400 [06:18<4:51:33, 44.85s/it]2022-01-08 10:00:06,616 iteration 171 : loss : 0.142510, loss_ce: 0.059779
2022-01-08 10:00:08,864 iteration 172 : loss : 0.176812, loss_ce: 0.080621
2022-01-08 10:00:11,286 iteration 173 : loss : 0.195352, loss_ce: 0.076706
2022-01-08 10:00:13,584 iteration 174 : loss : 0.195586, loss_ce: 0.096859
2022-01-08 10:00:15,902 iteration 175 : loss : 0.209343, loss_ce: 0.073307
2022-01-08 10:00:18,279 iteration 176 : loss : 0.153952, loss_ce: 0.064770
2022-01-08 10:00:20,695 iteration 177 : loss : 0.146094, loss_ce: 0.054789
2022-01-08 10:00:23,047 iteration 178 : loss : 0.167857, loss_ce: 0.056974
2022-01-08 10:00:25,356 iteration 179 : loss : 0.169710, loss_ce: 0.057697
2022-01-08 10:00:27,810 iteration 180 : loss : 0.204586, loss_ce: 0.086443
2022-01-08 10:00:30,193 iteration 181 : loss : 0.162188, loss_ce: 0.065377
2022-01-08 10:00:32,498 iteration 182 : loss : 0.211052, loss_ce: 0.089748
2022-01-08 10:00:34,825 iteration 183 : loss : 0.184487, loss_ce: 0.057078
2022-01-08 10:00:37,296 iteration 184 : loss : 0.210036, loss_ce: 0.074656
2022-01-08 10:00:39,743 iteration 185 : loss : 0.185599, loss_ce: 0.087743
2022-01-08 10:00:42,074 iteration 186 : loss : 0.170869, loss_ce: 0.057577
2022-01-08 10:00:44,396 iteration 187 : loss : 0.162755, loss_ce: 0.063925
  3%|▊                             | 11/400 [06:59<4:41:31, 43.42s/it]2022-01-08 10:00:46,725 iteration 188 : loss : 0.154670, loss_ce: 0.061080
2022-01-08 10:00:49,209 iteration 189 : loss : 0.168963, loss_ce: 0.071639
2022-01-08 10:00:51,557 iteration 190 : loss : 0.196569, loss_ce: 0.080958
2022-01-08 10:00:53,880 iteration 191 : loss : 0.139917, loss_ce: 0.054016
2022-01-08 10:00:56,204 iteration 192 : loss : 0.165798, loss_ce: 0.054723
2022-01-08 10:00:58,442 iteration 193 : loss : 0.160258, loss_ce: 0.069966
2022-01-08 10:01:00,808 iteration 194 : loss : 0.171849, loss_ce: 0.073885
2022-01-08 10:01:03,202 iteration 195 : loss : 0.137799, loss_ce: 0.052282
2022-01-08 10:01:05,500 iteration 196 : loss : 0.145398, loss_ce: 0.067515
2022-01-08 10:01:07,929 iteration 197 : loss : 0.175808, loss_ce: 0.060792
2022-01-08 10:01:10,268 iteration 198 : loss : 0.178536, loss_ce: 0.061389
2022-01-08 10:01:12,587 iteration 199 : loss : 0.214023, loss_ce: 0.063141
2022-01-08 10:01:14,953 iteration 200 : loss : 0.186992, loss_ce: 0.082272
2022-01-08 10:01:17,364 iteration 201 : loss : 0.185190, loss_ce: 0.072585
2022-01-08 10:01:19,643 iteration 202 : loss : 0.128398, loss_ce: 0.053085
2022-01-08 10:01:22,062 iteration 203 : loss : 0.193400, loss_ce: 0.100544
2022-01-08 10:01:24,392 iteration 204 : loss : 0.132049, loss_ce: 0.056720
  3%|▉                             | 12/400 [07:39<4:34:04, 42.38s/it]2022-01-08 10:01:26,769 iteration 205 : loss : 0.199850, loss_ce: 0.087614
2022-01-08 10:01:29,181 iteration 206 : loss : 0.200281, loss_ce: 0.086090
2022-01-08 10:01:31,621 iteration 207 : loss : 0.156631, loss_ce: 0.071348
2022-01-08 10:01:34,106 iteration 208 : loss : 0.123992, loss_ce: 0.045792
2022-01-08 10:01:36,455 iteration 209 : loss : 0.133979, loss_ce: 0.050511
2022-01-08 10:01:38,776 iteration 210 : loss : 0.126727, loss_ce: 0.044431
2022-01-08 10:01:41,239 iteration 211 : loss : 0.153528, loss_ce: 0.056126
2022-01-08 10:01:43,562 iteration 212 : loss : 0.149952, loss_ce: 0.053009
2022-01-08 10:01:45,950 iteration 213 : loss : 0.136512, loss_ce: 0.062313
2022-01-08 10:01:48,281 iteration 214 : loss : 0.221830, loss_ce: 0.071069
2022-01-08 10:01:50,661 iteration 215 : loss : 0.175373, loss_ce: 0.081425
2022-01-08 10:01:53,090 iteration 216 : loss : 0.205554, loss_ce: 0.092792
2022-01-08 10:01:55,431 iteration 217 : loss : 0.153883, loss_ce: 0.065362
2022-01-08 10:01:57,775 iteration 218 : loss : 0.108900, loss_ce: 0.043290
2022-01-08 10:02:00,140 iteration 219 : loss : 0.119635, loss_ce: 0.043811
2022-01-08 10:02:02,420 iteration 220 : loss : 0.160025, loss_ce: 0.071220
2022-01-08 10:02:04,682 iteration 221 : loss : 0.126563, loss_ce: 0.058348
  3%|▉                             | 13/400 [08:19<4:29:16, 41.75s/it]2022-01-08 10:02:07,153 iteration 222 : loss : 0.193054, loss_ce: 0.080909
2022-01-08 10:02:09,553 iteration 223 : loss : 0.145301, loss_ce: 0.058522
2022-01-08 10:02:12,052 iteration 224 : loss : 0.162295, loss_ce: 0.071843
2022-01-08 10:02:14,477 iteration 225 : loss : 0.166479, loss_ce: 0.061711
2022-01-08 10:02:16,841 iteration 226 : loss : 0.260892, loss_ce: 0.109135
2022-01-08 10:02:19,230 iteration 227 : loss : 0.143617, loss_ce: 0.058508
2022-01-08 10:02:21,650 iteration 228 : loss : 0.187949, loss_ce: 0.073019
2022-01-08 10:02:24,045 iteration 229 : loss : 0.148915, loss_ce: 0.065356
2022-01-08 10:02:26,392 iteration 230 : loss : 0.193372, loss_ce: 0.082652
2022-01-08 10:02:28,710 iteration 231 : loss : 0.174304, loss_ce: 0.056985
2022-01-08 10:02:31,150 iteration 232 : loss : 0.133964, loss_ce: 0.071009
2022-01-08 10:02:33,553 iteration 233 : loss : 0.119896, loss_ce: 0.057884
2022-01-08 10:02:35,857 iteration 234 : loss : 0.150561, loss_ce: 0.045146
2022-01-08 10:02:38,198 iteration 235 : loss : 0.112969, loss_ce: 0.037933
2022-01-08 10:02:40,593 iteration 236 : loss : 0.164506, loss_ce: 0.063838
2022-01-08 10:02:42,975 iteration 237 : loss : 0.133097, loss_ce: 0.048834
2022-01-08 10:02:45,251 iteration 238 : loss : 0.153117, loss_ce: 0.072381
  4%|█                             | 14/400 [09:00<4:26:17, 41.39s/it]2022-01-08 10:02:47,630 iteration 239 : loss : 0.152416, loss_ce: 0.053885
2022-01-08 10:02:50,080 iteration 240 : loss : 0.166184, loss_ce: 0.085707
2022-01-08 10:02:52,421 iteration 241 : loss : 0.134933, loss_ce: 0.048629
2022-01-08 10:02:54,820 iteration 242 : loss : 0.176516, loss_ce: 0.078476
2022-01-08 10:02:57,164 iteration 243 : loss : 0.142088, loss_ce: 0.062850
2022-01-08 10:02:59,523 iteration 244 : loss : 0.159412, loss_ce: 0.070891
2022-01-08 10:03:01,727 iteration 245 : loss : 0.132233, loss_ce: 0.042908
2022-01-08 10:03:04,251 iteration 246 : loss : 0.145478, loss_ce: 0.051346
2022-01-08 10:03:06,585 iteration 247 : loss : 0.102612, loss_ce: 0.042980
2022-01-08 10:03:09,073 iteration 248 : loss : 0.118996, loss_ce: 0.046357
2022-01-08 10:03:11,551 iteration 249 : loss : 0.139565, loss_ce: 0.044324
2022-01-08 10:03:13,943 iteration 250 : loss : 0.156440, loss_ce: 0.071394
2022-01-08 10:03:16,348 iteration 251 : loss : 0.096555, loss_ce: 0.041608
2022-01-08 10:03:18,699 iteration 252 : loss : 0.119905, loss_ce: 0.060128
2022-01-08 10:03:20,943 iteration 253 : loss : 0.176135, loss_ce: 0.056575
2022-01-08 10:03:23,163 iteration 254 : loss : 0.146463, loss_ce: 0.059726
2022-01-08 10:03:23,163 Training Data Eval:
2022-01-08 10:03:36,098   Average segmentation loss on training set: 0.1175
2022-01-08 10:03:36,099 Validation Data Eval:
2022-01-08 10:03:40,577   Average segmentation loss on validation set: 0.1460
2022-01-08 10:03:46,352 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed2.pth
2022-01-08 10:03:47,971 iteration 255 : loss : 0.215557, loss_ce: 0.096351
  4%|█▏                            | 15/400 [10:02<5:06:50, 47.82s/it]2022-01-08 10:03:49,604 iteration 256 : loss : 0.137338, loss_ce: 0.051453
2022-01-08 10:03:51,235 iteration 257 : loss : 0.102351, loss_ce: 0.052139
2022-01-08 10:03:53,143 iteration 258 : loss : 0.153992, loss_ce: 0.049166
2022-01-08 10:03:55,107 iteration 259 : loss : 0.170690, loss_ce: 0.058440
2022-01-08 10:03:57,245 iteration 260 : loss : 0.140347, loss_ce: 0.063927
2022-01-08 10:03:59,405 iteration 261 : loss : 0.152022, loss_ce: 0.061651
2022-01-08 10:04:01,610 iteration 262 : loss : 0.143090, loss_ce: 0.081594
2022-01-08 10:04:03,840 iteration 263 : loss : 0.172488, loss_ce: 0.089679
2022-01-08 10:04:06,127 iteration 264 : loss : 0.149440, loss_ce: 0.057370
2022-01-08 10:04:08,543 iteration 265 : loss : 0.130803, loss_ce: 0.059372
2022-01-08 10:04:10,884 iteration 266 : loss : 0.161326, loss_ce: 0.052257
2022-01-08 10:04:13,207 iteration 267 : loss : 0.137619, loss_ce: 0.057251
2022-01-08 10:04:15,516 iteration 268 : loss : 0.119797, loss_ce: 0.053925
2022-01-08 10:04:18,020 iteration 269 : loss : 0.122004, loss_ce: 0.050141
2022-01-08 10:04:20,354 iteration 270 : loss : 0.158278, loss_ce: 0.056092
2022-01-08 10:04:22,748 iteration 271 : loss : 0.197901, loss_ce: 0.075349
2022-01-08 10:04:25,164 iteration 272 : loss : 0.162878, loss_ce: 0.066819
  4%|█▏                            | 16/400 [10:39<4:45:35, 44.62s/it]2022-01-08 10:04:27,489 iteration 273 : loss : 0.127513, loss_ce: 0.049716
2022-01-08 10:04:29,824 iteration 274 : loss : 0.152584, loss_ce: 0.056791
2022-01-08 10:04:32,140 iteration 275 : loss : 0.111927, loss_ce: 0.051030
2022-01-08 10:04:34,467 iteration 276 : loss : 0.136262, loss_ce: 0.062256
2022-01-08 10:04:36,925 iteration 277 : loss : 0.122360, loss_ce: 0.047210
2022-01-08 10:04:39,298 iteration 278 : loss : 0.224424, loss_ce: 0.070084
2022-01-08 10:04:41,690 iteration 279 : loss : 0.117786, loss_ce: 0.050995
2022-01-08 10:04:44,010 iteration 280 : loss : 0.101009, loss_ce: 0.049716
2022-01-08 10:04:46,416 iteration 281 : loss : 0.152966, loss_ce: 0.051892
2022-01-08 10:04:48,845 iteration 282 : loss : 0.136679, loss_ce: 0.063979
2022-01-08 10:04:51,270 iteration 283 : loss : 0.138336, loss_ce: 0.066136
2022-01-08 10:04:53,599 iteration 284 : loss : 0.101139, loss_ce: 0.040386
2022-01-08 10:04:56,137 iteration 285 : loss : 0.120915, loss_ce: 0.045966
2022-01-08 10:04:58,620 iteration 286 : loss : 0.106029, loss_ce: 0.039902
2022-01-08 10:05:00,998 iteration 287 : loss : 0.154942, loss_ce: 0.049423
2022-01-08 10:05:03,327 iteration 288 : loss : 0.124368, loss_ce: 0.053683
2022-01-08 10:05:05,652 iteration 289 : loss : 0.144286, loss_ce: 0.069347
  4%|█▎                            | 17/400 [11:20<4:36:54, 43.38s/it]2022-01-08 10:05:08,094 iteration 290 : loss : 0.112220, loss_ce: 0.047382
2022-01-08 10:05:10,512 iteration 291 : loss : 0.107774, loss_ce: 0.043444
2022-01-08 10:05:12,899 iteration 292 : loss : 0.083622, loss_ce: 0.035597
2022-01-08 10:05:15,396 iteration 293 : loss : 0.125259, loss_ce: 0.057703
2022-01-08 10:05:17,684 iteration 294 : loss : 0.092596, loss_ce: 0.041159
2022-01-08 10:05:20,061 iteration 295 : loss : 0.180240, loss_ce: 0.060263
2022-01-08 10:05:22,420 iteration 296 : loss : 0.113264, loss_ce: 0.048261
2022-01-08 10:05:24,825 iteration 297 : loss : 0.110974, loss_ce: 0.046326
2022-01-08 10:05:27,251 iteration 298 : loss : 0.111082, loss_ce: 0.042196
2022-01-08 10:05:29,663 iteration 299 : loss : 0.152323, loss_ce: 0.043098
2022-01-08 10:05:32,041 iteration 300 : loss : 0.135135, loss_ce: 0.049541
2022-01-08 10:05:34,411 iteration 301 : loss : 0.143378, loss_ce: 0.045447
2022-01-08 10:05:36,929 iteration 302 : loss : 0.178645, loss_ce: 0.097730
2022-01-08 10:05:39,342 iteration 303 : loss : 0.132095, loss_ce: 0.066688
2022-01-08 10:05:41,739 iteration 304 : loss : 0.092010, loss_ce: 0.035740
2022-01-08 10:05:44,114 iteration 305 : loss : 0.108408, loss_ce: 0.044897
2022-01-08 10:05:46,569 iteration 306 : loss : 0.144679, loss_ce: 0.057977
  4%|█▎                            | 18/400 [12:01<4:31:26, 42.64s/it]2022-01-08 10:05:49,060 iteration 307 : loss : 0.127553, loss_ce: 0.055107
2022-01-08 10:05:51,481 iteration 308 : loss : 0.144736, loss_ce: 0.045843
2022-01-08 10:05:53,867 iteration 309 : loss : 0.130472, loss_ce: 0.057623
2022-01-08 10:05:56,227 iteration 310 : loss : 0.102333, loss_ce: 0.036524
2022-01-08 10:05:58,657 iteration 311 : loss : 0.094215, loss_ce: 0.037914
2022-01-08 10:06:01,080 iteration 312 : loss : 0.182582, loss_ce: 0.053283
2022-01-08 10:06:03,550 iteration 313 : loss : 0.140905, loss_ce: 0.058560
2022-01-08 10:06:06,016 iteration 314 : loss : 0.120348, loss_ce: 0.045592
2022-01-08 10:06:08,401 iteration 315 : loss : 0.131748, loss_ce: 0.056320
2022-01-08 10:06:10,843 iteration 316 : loss : 0.109513, loss_ce: 0.048555
2022-01-08 10:06:13,239 iteration 317 : loss : 0.106449, loss_ce: 0.049972
2022-01-08 10:06:15,688 iteration 318 : loss : 0.122849, loss_ce: 0.056498
2022-01-08 10:06:18,079 iteration 319 : loss : 0.077177, loss_ce: 0.034296
2022-01-08 10:06:20,520 iteration 320 : loss : 0.122167, loss_ce: 0.044942
2022-01-08 10:06:22,937 iteration 321 : loss : 0.166146, loss_ce: 0.061304
2022-01-08 10:06:25,261 iteration 322 : loss : 0.113971, loss_ce: 0.055143
2022-01-08 10:06:27,655 iteration 323 : loss : 0.114290, loss_ce: 0.050431
  5%|█▍                            | 19/400 [12:42<4:27:47, 42.17s/it]2022-01-08 10:06:30,064 iteration 324 : loss : 0.094465, loss_ce: 0.038699
2022-01-08 10:06:32,437 iteration 325 : loss : 0.098774, loss_ce: 0.028247
2022-01-08 10:06:34,870 iteration 326 : loss : 0.159901, loss_ce: 0.065098
2022-01-08 10:06:37,265 iteration 327 : loss : 0.181543, loss_ce: 0.078013
2022-01-08 10:06:39,656 iteration 328 : loss : 0.078814, loss_ce: 0.025447
2022-01-08 10:06:42,100 iteration 329 : loss : 0.176054, loss_ce: 0.060206
2022-01-08 10:06:44,514 iteration 330 : loss : 0.122814, loss_ce: 0.058598
2022-01-08 10:06:46,959 iteration 331 : loss : 0.093589, loss_ce: 0.035921
2022-01-08 10:06:49,288 iteration 332 : loss : 0.073387, loss_ce: 0.034208
2022-01-08 10:06:51,677 iteration 333 : loss : 0.146828, loss_ce: 0.066086
2022-01-08 10:06:54,008 iteration 334 : loss : 0.103382, loss_ce: 0.046824
2022-01-08 10:06:56,424 iteration 335 : loss : 0.109832, loss_ce: 0.054731
2022-01-08 10:06:58,823 iteration 336 : loss : 0.125027, loss_ce: 0.057565
2022-01-08 10:07:01,328 iteration 337 : loss : 0.158346, loss_ce: 0.060359
2022-01-08 10:07:03,704 iteration 338 : loss : 0.096951, loss_ce: 0.039105
2022-01-08 10:07:06,081 iteration 339 : loss : 0.133069, loss_ce: 0.057933
2022-01-08 10:07:06,081 Training Data Eval:
2022-01-08 10:07:18,960   Average segmentation loss on training set: 0.3050
2022-01-08 10:07:18,960 Validation Data Eval:
2022-01-08 10:07:23,449   Average segmentation loss on validation set: 0.2431
2022-01-08 10:07:25,904 iteration 340 : loss : 0.167836, loss_ce: 0.091720
  5%|█▌                            | 20/400 [13:40<4:57:39, 47.00s/it]2022-01-08 10:07:28,302 iteration 341 : loss : 0.078000, loss_ce: 0.037769
2022-01-08 10:07:30,709 iteration 342 : loss : 0.100490, loss_ce: 0.046717
2022-01-08 10:07:33,104 iteration 343 : loss : 0.119761, loss_ce: 0.053043
2022-01-08 10:07:35,465 iteration 344 : loss : 0.089157, loss_ce: 0.039013
2022-01-08 10:07:37,860 iteration 345 : loss : 0.113589, loss_ce: 0.047691
2022-01-08 10:07:40,281 iteration 346 : loss : 0.087734, loss_ce: 0.034101
2022-01-08 10:07:42,687 iteration 347 : loss : 0.143817, loss_ce: 0.062571
2022-01-08 10:07:45,238 iteration 348 : loss : 0.078752, loss_ce: 0.032324
2022-01-08 10:07:47,641 iteration 349 : loss : 0.087598, loss_ce: 0.031540
2022-01-08 10:07:50,020 iteration 350 : loss : 0.107890, loss_ce: 0.050233
2022-01-08 10:07:52,403 iteration 351 : loss : 0.118176, loss_ce: 0.045378
2022-01-08 10:07:54,856 iteration 352 : loss : 0.107991, loss_ce: 0.060432
2022-01-08 10:07:57,240 iteration 353 : loss : 0.114639, loss_ce: 0.049270
2022-01-08 10:07:59,584 iteration 354 : loss : 0.166736, loss_ce: 0.063378
2022-01-08 10:08:02,005 iteration 355 : loss : 0.124770, loss_ce: 0.044332
2022-01-08 10:08:04,394 iteration 356 : loss : 0.117737, loss_ce: 0.044488
2022-01-08 10:08:06,858 iteration 357 : loss : 0.088284, loss_ce: 0.036945
  5%|█▌                            | 21/400 [14:21<4:45:24, 45.18s/it]2022-01-08 10:08:09,387 iteration 358 : loss : 0.155780, loss_ce: 0.078578
2022-01-08 10:08:11,763 iteration 359 : loss : 0.094521, loss_ce: 0.039385
2022-01-08 10:08:14,045 iteration 360 : loss : 0.086762, loss_ce: 0.031506
2022-01-08 10:08:16,435 iteration 361 : loss : 0.204998, loss_ce: 0.078832
2022-01-08 10:08:18,847 iteration 362 : loss : 0.113945, loss_ce: 0.063300
2022-01-08 10:08:21,195 iteration 363 : loss : 0.102301, loss_ce: 0.049502
2022-01-08 10:08:23,588 iteration 364 : loss : 0.215104, loss_ce: 0.080514
2022-01-08 10:08:25,911 iteration 365 : loss : 0.090805, loss_ce: 0.038503
2022-01-08 10:08:28,405 iteration 366 : loss : 0.113871, loss_ce: 0.036106
2022-01-08 10:08:30,793 iteration 367 : loss : 0.116666, loss_ce: 0.045325
2022-01-08 10:08:33,126 iteration 368 : loss : 0.119031, loss_ce: 0.043565
2022-01-08 10:08:35,397 iteration 369 : loss : 0.081949, loss_ce: 0.029929
2022-01-08 10:08:37,701 iteration 370 : loss : 0.145815, loss_ce: 0.066767
2022-01-08 10:08:40,080 iteration 371 : loss : 0.122735, loss_ce: 0.045147
2022-01-08 10:08:42,379 iteration 372 : loss : 0.097486, loss_ce: 0.038167
2022-01-08 10:08:44,709 iteration 373 : loss : 0.069019, loss_ce: 0.027337
2022-01-08 10:08:47,224 iteration 374 : loss : 0.093662, loss_ce: 0.041326
  6%|█▋                            | 22/400 [15:01<4:35:34, 43.74s/it]2022-01-08 10:08:49,656 iteration 375 : loss : 0.106258, loss_ce: 0.047995
2022-01-08 10:08:51,996 iteration 376 : loss : 0.153477, loss_ce: 0.043930
2022-01-08 10:08:54,361 iteration 377 : loss : 0.105331, loss_ce: 0.037783
2022-01-08 10:08:56,784 iteration 378 : loss : 0.106147, loss_ce: 0.036197
2022-01-08 10:08:59,187 iteration 379 : loss : 0.103782, loss_ce: 0.048535
2022-01-08 10:09:01,495 iteration 380 : loss : 0.107046, loss_ce: 0.053568
2022-01-08 10:09:03,924 iteration 381 : loss : 0.123436, loss_ce: 0.055771
2022-01-08 10:09:06,249 iteration 382 : loss : 0.092148, loss_ce: 0.039918
2022-01-08 10:09:08,728 iteration 383 : loss : 0.126767, loss_ce: 0.033969
2022-01-08 10:09:11,111 iteration 384 : loss : 0.099838, loss_ce: 0.040156
2022-01-08 10:09:13,500 iteration 385 : loss : 0.098564, loss_ce: 0.040263
2022-01-08 10:09:15,881 iteration 386 : loss : 0.088620, loss_ce: 0.030567
2022-01-08 10:09:18,206 iteration 387 : loss : 0.072373, loss_ce: 0.030081
2022-01-08 10:09:20,560 iteration 388 : loss : 0.111800, loss_ce: 0.056114
2022-01-08 10:09:22,895 iteration 389 : loss : 0.081675, loss_ce: 0.032778
2022-01-08 10:09:25,224 iteration 390 : loss : 0.111093, loss_ce: 0.057383
2022-01-08 10:09:27,565 iteration 391 : loss : 0.059061, loss_ce: 0.025024
  6%|█▋                            | 23/400 [15:42<4:28:27, 42.72s/it]2022-01-08 10:09:30,066 iteration 392 : loss : 0.096908, loss_ce: 0.044988
2022-01-08 10:09:32,359 iteration 393 : loss : 0.097505, loss_ce: 0.048410
2022-01-08 10:09:34,725 iteration 394 : loss : 0.104159, loss_ce: 0.039922
2022-01-08 10:09:37,097 iteration 395 : loss : 0.081337, loss_ce: 0.031186
2022-01-08 10:09:39,481 iteration 396 : loss : 0.095533, loss_ce: 0.035978
2022-01-08 10:09:41,949 iteration 397 : loss : 0.113183, loss_ce: 0.050794
2022-01-08 10:09:44,358 iteration 398 : loss : 0.085980, loss_ce: 0.031748
2022-01-08 10:09:46,744 iteration 399 : loss : 0.098152, loss_ce: 0.034541
2022-01-08 10:09:49,084 iteration 400 : loss : 0.078953, loss_ce: 0.032689
2022-01-08 10:09:51,485 iteration 401 : loss : 0.083917, loss_ce: 0.037725
2022-01-08 10:09:53,970 iteration 402 : loss : 0.091584, loss_ce: 0.043131
2022-01-08 10:09:56,428 iteration 403 : loss : 0.080076, loss_ce: 0.030896
2022-01-08 10:09:58,825 iteration 404 : loss : 0.083601, loss_ce: 0.032749
2022-01-08 10:10:01,189 iteration 405 : loss : 0.115650, loss_ce: 0.049468
2022-01-08 10:10:03,562 iteration 406 : loss : 0.096182, loss_ce: 0.041547
2022-01-08 10:10:06,067 iteration 407 : loss : 0.085441, loss_ce: 0.035978
2022-01-08 10:10:08,390 iteration 408 : loss : 0.077578, loss_ce: 0.034973
  6%|█▊                            | 24/400 [16:23<4:24:08, 42.15s/it]2022-01-08 10:10:10,838 iteration 409 : loss : 0.115672, loss_ce: 0.037686
2022-01-08 10:10:13,186 iteration 410 : loss : 0.105172, loss_ce: 0.042627
2022-01-08 10:10:15,577 iteration 411 : loss : 0.138218, loss_ce: 0.044438
2022-01-08 10:10:17,919 iteration 412 : loss : 0.091932, loss_ce: 0.039034
2022-01-08 10:10:20,294 iteration 413 : loss : 0.115766, loss_ce: 0.035854
2022-01-08 10:10:22,686 iteration 414 : loss : 0.097740, loss_ce: 0.037049
2022-01-08 10:10:25,133 iteration 415 : loss : 0.107911, loss_ce: 0.040172
2022-01-08 10:10:27,512 iteration 416 : loss : 0.115841, loss_ce: 0.048355
2022-01-08 10:10:29,923 iteration 417 : loss : 0.084369, loss_ce: 0.031724
2022-01-08 10:10:32,191 iteration 418 : loss : 0.087628, loss_ce: 0.053782
2022-01-08 10:10:34,551 iteration 419 : loss : 0.176954, loss_ce: 0.077629
2022-01-08 10:10:36,932 iteration 420 : loss : 0.073792, loss_ce: 0.030391
2022-01-08 10:10:39,389 iteration 421 : loss : 0.129991, loss_ce: 0.069944
2022-01-08 10:10:41,707 iteration 422 : loss : 0.142639, loss_ce: 0.055344
2022-01-08 10:10:44,022 iteration 423 : loss : 0.103289, loss_ce: 0.036005
2022-01-08 10:10:46,461 iteration 424 : loss : 0.102071, loss_ce: 0.036152
2022-01-08 10:10:46,461 Training Data Eval:
2022-01-08 10:10:59,209   Average segmentation loss on training set: 0.0906
2022-01-08 10:10:59,210 Validation Data Eval:
2022-01-08 10:11:03,732   Average segmentation loss on validation set: 0.1788
2022-01-08 10:11:06,210 iteration 425 : loss : 0.119713, loss_ce: 0.041508
  6%|█▉                            | 25/400 [17:20<4:52:48, 46.85s/it]2022-01-08 10:11:08,670 iteration 426 : loss : 0.070513, loss_ce: 0.033498
2022-01-08 10:11:11,067 iteration 427 : loss : 0.130059, loss_ce: 0.051179
2022-01-08 10:11:13,431 iteration 428 : loss : 0.131765, loss_ce: 0.061737
2022-01-08 10:11:15,771 iteration 429 : loss : 0.081676, loss_ce: 0.031790
2022-01-08 10:11:18,165 iteration 430 : loss : 0.102068, loss_ce: 0.039772
2022-01-08 10:11:20,485 iteration 431 : loss : 0.093107, loss_ce: 0.035798
2022-01-08 10:11:22,837 iteration 432 : loss : 0.059316, loss_ce: 0.026146
2022-01-08 10:11:25,197 iteration 433 : loss : 0.094599, loss_ce: 0.027756
2022-01-08 10:11:27,459 iteration 434 : loss : 0.085627, loss_ce: 0.030845
2022-01-08 10:11:29,730 iteration 435 : loss : 0.126457, loss_ce: 0.067248
2022-01-08 10:11:32,123 iteration 436 : loss : 0.140214, loss_ce: 0.046939
2022-01-08 10:11:34,577 iteration 437 : loss : 0.082020, loss_ce: 0.034488
2022-01-08 10:11:36,997 iteration 438 : loss : 0.124999, loss_ce: 0.068981
2022-01-08 10:11:39,342 iteration 439 : loss : 0.096247, loss_ce: 0.046548
2022-01-08 10:11:41,623 iteration 440 : loss : 0.088856, loss_ce: 0.039984
2022-01-08 10:11:43,938 iteration 441 : loss : 0.084609, loss_ce: 0.041546
2022-01-08 10:11:46,281 iteration 442 : loss : 0.175974, loss_ce: 0.066410
  6%|█▉                            | 26/400 [18:01<4:39:22, 44.82s/it]2022-01-08 10:11:48,765 iteration 443 : loss : 0.078853, loss_ce: 0.038859
2022-01-08 10:11:51,054 iteration 444 : loss : 0.112388, loss_ce: 0.039927
2022-01-08 10:11:53,461 iteration 445 : loss : 0.112062, loss_ce: 0.050484
2022-01-08 10:11:55,621 iteration 446 : loss : 0.129851, loss_ce: 0.043278
2022-01-08 10:11:57,946 iteration 447 : loss : 0.102021, loss_ce: 0.043132
2022-01-08 10:12:00,254 iteration 448 : loss : 0.096206, loss_ce: 0.045755
2022-01-08 10:12:02,583 iteration 449 : loss : 0.072893, loss_ce: 0.030756
2022-01-08 10:12:04,808 iteration 450 : loss : 0.076621, loss_ce: 0.036902
2022-01-08 10:12:07,142 iteration 451 : loss : 0.091724, loss_ce: 0.030766
2022-01-08 10:12:09,447 iteration 452 : loss : 0.088226, loss_ce: 0.036341
2022-01-08 10:12:11,741 iteration 453 : loss : 0.064390, loss_ce: 0.025414
2022-01-08 10:12:14,085 iteration 454 : loss : 0.191791, loss_ce: 0.067827
2022-01-08 10:12:16,407 iteration 455 : loss : 0.072764, loss_ce: 0.026260
2022-01-08 10:12:18,768 iteration 456 : loss : 0.103612, loss_ce: 0.037089
2022-01-08 10:12:21,162 iteration 457 : loss : 0.103312, loss_ce: 0.049828
2022-01-08 10:12:23,510 iteration 458 : loss : 0.147046, loss_ce: 0.078678
2022-01-08 10:12:25,866 iteration 459 : loss : 0.083977, loss_ce: 0.032830
  7%|██                            | 27/400 [18:40<4:28:51, 43.25s/it]2022-01-08 10:12:28,132 iteration 460 : loss : 0.104931, loss_ce: 0.034361
2022-01-08 10:12:30,536 iteration 461 : loss : 0.122118, loss_ce: 0.056755
2022-01-08 10:12:32,845 iteration 462 : loss : 0.141867, loss_ce: 0.034636
2022-01-08 10:12:35,141 iteration 463 : loss : 0.073893, loss_ce: 0.033457
2022-01-08 10:12:37,548 iteration 464 : loss : 0.064463, loss_ce: 0.028866
2022-01-08 10:12:39,868 iteration 465 : loss : 0.066937, loss_ce: 0.034655
2022-01-08 10:12:42,259 iteration 466 : loss : 0.105319, loss_ce: 0.043956
2022-01-08 10:12:44,653 iteration 467 : loss : 0.136371, loss_ce: 0.051244
2022-01-08 10:12:46,987 iteration 468 : loss : 0.114994, loss_ce: 0.043145
2022-01-08 10:12:49,241 iteration 469 : loss : 0.103916, loss_ce: 0.037175
2022-01-08 10:12:51,569 iteration 470 : loss : 0.107635, loss_ce: 0.050053
2022-01-08 10:12:53,827 iteration 471 : loss : 0.070135, loss_ce: 0.032852
2022-01-08 10:12:56,179 iteration 472 : loss : 0.127096, loss_ce: 0.048546
2022-01-08 10:12:58,501 iteration 473 : loss : 0.097345, loss_ce: 0.039517
2022-01-08 10:13:00,854 iteration 474 : loss : 0.101910, loss_ce: 0.040914
2022-01-08 10:13:03,140 iteration 475 : loss : 0.095140, loss_ce: 0.027111
2022-01-08 10:13:05,533 iteration 476 : loss : 0.095332, loss_ce: 0.048821
  7%|██                            | 28/400 [19:20<4:21:27, 42.17s/it]2022-01-08 10:13:07,915 iteration 477 : loss : 0.094849, loss_ce: 0.046048
2022-01-08 10:13:10,246 iteration 478 : loss : 0.104792, loss_ce: 0.040861
2022-01-08 10:13:12,570 iteration 479 : loss : 0.068427, loss_ce: 0.028286
2022-01-08 10:13:14,861 iteration 480 : loss : 0.085814, loss_ce: 0.038060
2022-01-08 10:13:17,266 iteration 481 : loss : 0.102150, loss_ce: 0.044905
2022-01-08 10:13:19,669 iteration 482 : loss : 0.078005, loss_ce: 0.029960
2022-01-08 10:13:22,037 iteration 483 : loss : 0.092367, loss_ce: 0.032964
2022-01-08 10:13:24,348 iteration 484 : loss : 0.071699, loss_ce: 0.026351
2022-01-08 10:13:26,640 iteration 485 : loss : 0.057454, loss_ce: 0.023187
2022-01-08 10:13:28,977 iteration 486 : loss : 0.218866, loss_ce: 0.058925
2022-01-08 10:13:31,319 iteration 487 : loss : 0.105817, loss_ce: 0.058031
2022-01-08 10:13:33,707 iteration 488 : loss : 0.127898, loss_ce: 0.051412
2022-01-08 10:13:35,990 iteration 489 : loss : 0.070793, loss_ce: 0.028762
2022-01-08 10:13:38,214 iteration 490 : loss : 0.089507, loss_ce: 0.035206
2022-01-08 10:13:40,520 iteration 491 : loss : 0.095107, loss_ce: 0.037025
2022-01-08 10:13:42,824 iteration 492 : loss : 0.099088, loss_ce: 0.039966
2022-01-08 10:13:45,192 iteration 493 : loss : 0.138307, loss_ce: 0.061313
  7%|██▏                           | 29/400 [19:59<4:16:05, 41.42s/it]2022-01-08 10:13:47,577 iteration 494 : loss : 0.095098, loss_ce: 0.042600
2022-01-08 10:13:49,925 iteration 495 : loss : 0.067730, loss_ce: 0.028045
2022-01-08 10:13:52,218 iteration 496 : loss : 0.078524, loss_ce: 0.033998
2022-01-08 10:13:54,562 iteration 497 : loss : 0.074177, loss_ce: 0.026555
2022-01-08 10:13:56,801 iteration 498 : loss : 0.108707, loss_ce: 0.037619
2022-01-08 10:13:59,126 iteration 499 : loss : 0.080356, loss_ce: 0.033360
2022-01-08 10:14:01,311 iteration 500 : loss : 0.076242, loss_ce: 0.031121
2022-01-08 10:14:03,709 iteration 501 : loss : 0.107104, loss_ce: 0.031926
2022-01-08 10:14:06,095 iteration 502 : loss : 0.080494, loss_ce: 0.029517
2022-01-08 10:14:08,477 iteration 503 : loss : 0.106941, loss_ce: 0.053521
2022-01-08 10:14:10,862 iteration 504 : loss : 0.074950, loss_ce: 0.028588
2022-01-08 10:14:13,165 iteration 505 : loss : 0.064679, loss_ce: 0.029933
2022-01-08 10:14:15,412 iteration 506 : loss : 0.090687, loss_ce: 0.044332
2022-01-08 10:14:17,684 iteration 507 : loss : 0.072848, loss_ce: 0.028682
2022-01-08 10:14:20,124 iteration 508 : loss : 0.081561, loss_ce: 0.026353
2022-01-08 10:14:22,523 iteration 509 : loss : 0.087308, loss_ce: 0.043473
2022-01-08 10:14:22,523 Training Data Eval:
2022-01-08 10:14:35,053   Average segmentation loss on training set: 0.0571
2022-01-08 10:14:35,053 Validation Data Eval:
2022-01-08 10:14:39,674   Average segmentation loss on validation set: 0.0847
2022-01-08 10:14:45,550 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed2.pth
2022-01-08 10:14:47,155 iteration 510 : loss : 0.059926, loss_ce: 0.025211
  8%|██▎                           | 30/400 [21:01<4:53:26, 47.58s/it]2022-01-08 10:14:48,744 iteration 511 : loss : 0.070672, loss_ce: 0.026461
2022-01-08 10:14:50,367 iteration 512 : loss : 0.091339, loss_ce: 0.039422
2022-01-08 10:14:52,158 iteration 513 : loss : 0.073947, loss_ce: 0.027487
2022-01-08 10:14:54,101 iteration 514 : loss : 0.082786, loss_ce: 0.035174
2022-01-08 10:14:56,100 iteration 515 : loss : 0.085174, loss_ce: 0.037515
2022-01-08 10:14:58,114 iteration 516 : loss : 0.053649, loss_ce: 0.017128
2022-01-08 10:15:00,385 iteration 517 : loss : 0.071068, loss_ce: 0.035877
2022-01-08 10:15:02,701 iteration 518 : loss : 0.133151, loss_ce: 0.051790
2022-01-08 10:15:05,010 iteration 519 : loss : 0.101511, loss_ce: 0.047821
2022-01-08 10:15:07,270 iteration 520 : loss : 0.078256, loss_ce: 0.034364
2022-01-08 10:15:09,596 iteration 521 : loss : 0.061803, loss_ce: 0.022398
2022-01-08 10:15:11,957 iteration 522 : loss : 0.085492, loss_ce: 0.033880
2022-01-08 10:15:14,252 iteration 523 : loss : 0.081006, loss_ce: 0.026402
2022-01-08 10:15:16,514 iteration 524 : loss : 0.074224, loss_ce: 0.034061
2022-01-08 10:15:18,769 iteration 525 : loss : 0.059405, loss_ce: 0.023555
2022-01-08 10:15:21,105 iteration 526 : loss : 0.076003, loss_ce: 0.026117
2022-01-08 10:15:23,438 iteration 527 : loss : 0.094992, loss_ce: 0.033108
  8%|██▎                           | 31/400 [21:38<4:31:48, 44.20s/it]2022-01-08 10:15:25,929 iteration 528 : loss : 0.077680, loss_ce: 0.032536
2022-01-08 10:15:28,437 iteration 529 : loss : 0.112596, loss_ce: 0.032350
2022-01-08 10:15:30,827 iteration 530 : loss : 0.052218, loss_ce: 0.021829
2022-01-08 10:15:33,249 iteration 531 : loss : 0.067250, loss_ce: 0.023997
2022-01-08 10:15:35,691 iteration 532 : loss : 0.085755, loss_ce: 0.037341
2022-01-08 10:15:38,284 iteration 533 : loss : 0.085087, loss_ce: 0.034970
2022-01-08 10:15:40,753 iteration 534 : loss : 0.057358, loss_ce: 0.022966
2022-01-08 10:15:43,201 iteration 535 : loss : 0.069432, loss_ce: 0.023736
2022-01-08 10:15:45,706 iteration 536 : loss : 0.067870, loss_ce: 0.034771
2022-01-08 10:15:48,090 iteration 537 : loss : 0.071053, loss_ce: 0.028964
2022-01-08 10:15:50,534 iteration 538 : loss : 0.083390, loss_ce: 0.042470
2022-01-08 10:15:53,118 iteration 539 : loss : 0.074417, loss_ce: 0.030935
2022-01-08 10:15:55,657 iteration 540 : loss : 0.092847, loss_ce: 0.046805
2022-01-08 10:15:58,268 iteration 541 : loss : 0.109929, loss_ce: 0.052356
2022-01-08 10:16:00,772 iteration 542 : loss : 0.107456, loss_ce: 0.042871
2022-01-08 10:16:03,371 iteration 543 : loss : 0.094606, loss_ce: 0.035947
2022-01-08 10:16:05,808 iteration 544 : loss : 0.168660, loss_ce: 0.047899
  8%|██▍                           | 32/400 [22:20<4:27:42, 43.65s/it]2022-01-08 10:16:08,400 iteration 545 : loss : 0.064219, loss_ce: 0.027928
2022-01-08 10:16:11,033 iteration 546 : loss : 0.069445, loss_ce: 0.030923
2022-01-08 10:16:13,517 iteration 547 : loss : 0.080735, loss_ce: 0.034064
2022-01-08 10:16:15,928 iteration 548 : loss : 0.145592, loss_ce: 0.053626
2022-01-08 10:16:18,490 iteration 549 : loss : 0.099254, loss_ce: 0.036748
2022-01-08 10:16:21,028 iteration 550 : loss : 0.101656, loss_ce: 0.036334
2022-01-08 10:16:23,453 iteration 551 : loss : 0.094850, loss_ce: 0.026258
2022-01-08 10:16:25,970 iteration 552 : loss : 0.135907, loss_ce: 0.066757
2022-01-08 10:16:28,552 iteration 553 : loss : 0.068698, loss_ce: 0.028040
2022-01-08 10:16:31,109 iteration 554 : loss : 0.106230, loss_ce: 0.043071
2022-01-08 10:16:33,679 iteration 555 : loss : 0.070955, loss_ce: 0.020906
2022-01-08 10:16:36,192 iteration 556 : loss : 0.084941, loss_ce: 0.038328
2022-01-08 10:16:38,696 iteration 557 : loss : 0.075301, loss_ce: 0.035867
2022-01-08 10:16:41,297 iteration 558 : loss : 0.070560, loss_ce: 0.029657
2022-01-08 10:16:43,819 iteration 559 : loss : 0.087381, loss_ce: 0.036634
2022-01-08 10:16:46,475 iteration 560 : loss : 0.079881, loss_ce: 0.036369
2022-01-08 10:16:48,967 iteration 561 : loss : 0.067172, loss_ce: 0.032582
  8%|██▍                           | 33/400 [23:03<4:26:04, 43.50s/it]2022-01-08 10:16:51,539 iteration 562 : loss : 0.101260, loss_ce: 0.040202
2022-01-08 10:16:54,159 iteration 563 : loss : 0.054256, loss_ce: 0.027578
2022-01-08 10:16:56,586 iteration 564 : loss : 0.071504, loss_ce: 0.035300
2022-01-08 10:16:59,168 iteration 565 : loss : 0.064380, loss_ce: 0.028636
2022-01-08 10:17:01,607 iteration 566 : loss : 0.100975, loss_ce: 0.030911
2022-01-08 10:17:04,114 iteration 567 : loss : 0.087785, loss_ce: 0.033076
2022-01-08 10:17:06,677 iteration 568 : loss : 0.097903, loss_ce: 0.025332
2022-01-08 10:17:09,268 iteration 569 : loss : 0.124519, loss_ce: 0.030754
2022-01-08 10:17:11,870 iteration 570 : loss : 0.070476, loss_ce: 0.025399
2022-01-08 10:17:14,498 iteration 571 : loss : 0.083168, loss_ce: 0.031558
2022-01-08 10:17:16,967 iteration 572 : loss : 0.084090, loss_ce: 0.033011
2022-01-08 10:17:19,384 iteration 573 : loss : 0.077881, loss_ce: 0.034219
2022-01-08 10:17:21,968 iteration 574 : loss : 0.090159, loss_ce: 0.033597
2022-01-08 10:17:24,719 iteration 575 : loss : 0.123440, loss_ce: 0.033188
2022-01-08 10:17:27,111 iteration 576 : loss : 0.074957, loss_ce: 0.039073
2022-01-08 10:17:29,732 iteration 577 : loss : 0.110363, loss_ce: 0.045141
2022-01-08 10:17:32,318 iteration 578 : loss : 0.070557, loss_ce: 0.031193
  8%|██▌                           | 34/400 [23:47<4:25:04, 43.45s/it]2022-01-08 10:17:34,782 iteration 579 : loss : 0.061400, loss_ce: 0.028614
2022-01-08 10:17:37,459 iteration 580 : loss : 0.075945, loss_ce: 0.024764
2022-01-08 10:17:39,997 iteration 581 : loss : 0.055722, loss_ce: 0.023427
2022-01-08 10:17:42,563 iteration 582 : loss : 0.068488, loss_ce: 0.029947
2022-01-08 10:17:45,222 iteration 583 : loss : 0.079157, loss_ce: 0.036312
2022-01-08 10:17:47,803 iteration 584 : loss : 0.119210, loss_ce: 0.060334
2022-01-08 10:17:50,295 iteration 585 : loss : 0.078429, loss_ce: 0.023933
2022-01-08 10:17:52,871 iteration 586 : loss : 0.065435, loss_ce: 0.023329
2022-01-08 10:17:55,474 iteration 587 : loss : 0.068448, loss_ce: 0.034928
2022-01-08 10:17:58,022 iteration 588 : loss : 0.082822, loss_ce: 0.029434
2022-01-08 10:18:00,627 iteration 589 : loss : 0.125333, loss_ce: 0.064779
2022-01-08 10:18:03,189 iteration 590 : loss : 0.086086, loss_ce: 0.028753
2022-01-08 10:18:05,768 iteration 591 : loss : 0.097787, loss_ce: 0.038326
2022-01-08 10:18:08,359 iteration 592 : loss : 0.078101, loss_ce: 0.039850
2022-01-08 10:18:10,912 iteration 593 : loss : 0.088671, loss_ce: 0.032429
2022-01-08 10:18:13,539 iteration 594 : loss : 0.088535, loss_ce: 0.030116
2022-01-08 10:18:13,540 Training Data Eval:
2022-01-08 10:18:27,400   Average segmentation loss on training set: 0.0830
2022-01-08 10:18:27,401 Validation Data Eval:
2022-01-08 10:18:32,212   Average segmentation loss on validation set: 0.1173
2022-01-08 10:18:34,741 iteration 595 : loss : 0.098324, loss_ce: 0.034560
  9%|██▋                           | 35/400 [24:49<4:58:56, 49.14s/it]2022-01-08 10:18:37,443 iteration 596 : loss : 0.084816, loss_ce: 0.036917
2022-01-08 10:18:39,928 iteration 597 : loss : 0.049428, loss_ce: 0.020349
2022-01-08 10:18:42,539 iteration 598 : loss : 0.068258, loss_ce: 0.024533
2022-01-08 10:18:45,233 iteration 599 : loss : 0.126768, loss_ce: 0.056000
2022-01-08 10:18:47,872 iteration 600 : loss : 0.064205, loss_ce: 0.023739
2022-01-08 10:18:50,463 iteration 601 : loss : 0.088199, loss_ce: 0.031863
2022-01-08 10:18:52,866 iteration 602 : loss : 0.077489, loss_ce: 0.036826
2022-01-08 10:18:55,464 iteration 603 : loss : 0.076310, loss_ce: 0.032294
2022-01-08 10:18:58,006 iteration 604 : loss : 0.107521, loss_ce: 0.030399
2022-01-08 10:19:00,492 iteration 605 : loss : 0.071226, loss_ce: 0.028503
2022-01-08 10:19:03,069 iteration 606 : loss : 0.051182, loss_ce: 0.020807
2022-01-08 10:19:05,688 iteration 607 : loss : 0.063171, loss_ce: 0.022079
2022-01-08 10:19:08,247 iteration 608 : loss : 0.045818, loss_ce: 0.023235
2022-01-08 10:19:10,737 iteration 609 : loss : 0.068919, loss_ce: 0.026317
2022-01-08 10:19:13,319 iteration 610 : loss : 0.103478, loss_ce: 0.048857
2022-01-08 10:19:15,929 iteration 611 : loss : 0.080517, loss_ce: 0.032709
2022-01-08 10:19:18,455 iteration 612 : loss : 0.059747, loss_ce: 0.023995
  9%|██▋                           | 36/400 [25:33<4:48:14, 47.51s/it]2022-01-08 10:19:21,255 iteration 613 : loss : 0.097236, loss_ce: 0.035942
2022-01-08 10:19:23,888 iteration 614 : loss : 0.070648, loss_ce: 0.027669
2022-01-08 10:19:26,427 iteration 615 : loss : 0.071654, loss_ce: 0.035560
2022-01-08 10:19:29,024 iteration 616 : loss : 0.106189, loss_ce: 0.037577
2022-01-08 10:19:31,717 iteration 617 : loss : 0.106356, loss_ce: 0.043319
2022-01-08 10:19:34,336 iteration 618 : loss : 0.045969, loss_ce: 0.022025
2022-01-08 10:19:36,845 iteration 619 : loss : 0.061186, loss_ce: 0.025809
2022-01-08 10:19:39,535 iteration 620 : loss : 0.050110, loss_ce: 0.026012
2022-01-08 10:19:42,107 iteration 621 : loss : 0.061887, loss_ce: 0.021580
2022-01-08 10:19:44,829 iteration 622 : loss : 0.073812, loss_ce: 0.030085
2022-01-08 10:19:47,488 iteration 623 : loss : 0.062512, loss_ce: 0.028095
2022-01-08 10:19:50,028 iteration 624 : loss : 0.067510, loss_ce: 0.028711
2022-01-08 10:19:52,615 iteration 625 : loss : 0.080379, loss_ce: 0.033011
2022-01-08 10:19:55,230 iteration 626 : loss : 0.074829, loss_ce: 0.031479
2022-01-08 10:19:57,808 iteration 627 : loss : 0.093817, loss_ce: 0.029144
2022-01-08 10:20:00,215 iteration 628 : loss : 0.087831, loss_ce: 0.029709
2022-01-08 10:20:02,845 iteration 629 : loss : 0.048439, loss_ce: 0.021032
  9%|██▊                           | 37/400 [26:17<4:41:47, 46.58s/it]2022-01-08 10:20:05,390 iteration 630 : loss : 0.062120, loss_ce: 0.027911
2022-01-08 10:20:08,150 iteration 631 : loss : 0.080112, loss_ce: 0.026786
2022-01-08 10:20:10,557 iteration 632 : loss : 0.054910, loss_ce: 0.020787
2022-01-08 10:20:13,161 iteration 633 : loss : 0.095532, loss_ce: 0.050268
2022-01-08 10:20:15,942 iteration 634 : loss : 0.055805, loss_ce: 0.024660
2022-01-08 10:20:18,515 iteration 635 : loss : 0.068438, loss_ce: 0.027731
2022-01-08 10:20:21,258 iteration 636 : loss : 0.097835, loss_ce: 0.028100
2022-01-08 10:20:23,882 iteration 637 : loss : 0.067286, loss_ce: 0.029942
2022-01-08 10:20:26,519 iteration 638 : loss : 0.042462, loss_ce: 0.019811
2022-01-08 10:20:29,036 iteration 639 : loss : 0.055298, loss_ce: 0.024686
2022-01-08 10:20:31,731 iteration 640 : loss : 0.085037, loss_ce: 0.028522
2022-01-08 10:20:34,327 iteration 641 : loss : 0.061020, loss_ce: 0.023723
2022-01-08 10:20:37,025 iteration 642 : loss : 0.062739, loss_ce: 0.024360
2022-01-08 10:20:39,688 iteration 643 : loss : 0.066493, loss_ce: 0.022535
2022-01-08 10:20:42,195 iteration 644 : loss : 0.070784, loss_ce: 0.022608
2022-01-08 10:20:44,638 iteration 645 : loss : 0.072672, loss_ce: 0.029698
2022-01-08 10:20:47,390 iteration 646 : loss : 0.060729, loss_ce: 0.025747
 10%|██▊                           | 38/400 [27:02<4:37:21, 45.97s/it]2022-01-08 10:20:49,908 iteration 647 : loss : 0.053533, loss_ce: 0.021703
2022-01-08 10:20:52,529 iteration 648 : loss : 0.100075, loss_ce: 0.040231
2022-01-08 10:20:55,127 iteration 649 : loss : 0.076500, loss_ce: 0.033092
2022-01-08 10:20:57,535 iteration 650 : loss : 0.063356, loss_ce: 0.032288
2022-01-08 10:21:00,129 iteration 651 : loss : 0.071739, loss_ce: 0.028447
2022-01-08 10:21:02,685 iteration 652 : loss : 0.077265, loss_ce: 0.023680
2022-01-08 10:21:05,216 iteration 653 : loss : 0.113566, loss_ce: 0.040253
2022-01-08 10:21:07,770 iteration 654 : loss : 0.079182, loss_ce: 0.028134
2022-01-08 10:21:10,411 iteration 655 : loss : 0.043917, loss_ce: 0.017242
2022-01-08 10:21:12,947 iteration 656 : loss : 0.057729, loss_ce: 0.024628
2022-01-08 10:21:15,520 iteration 657 : loss : 0.044624, loss_ce: 0.018905
2022-01-08 10:21:18,148 iteration 658 : loss : 0.124235, loss_ce: 0.046485
2022-01-08 10:21:20,876 iteration 659 : loss : 0.062229, loss_ce: 0.029290
2022-01-08 10:21:23,381 iteration 660 : loss : 0.065926, loss_ce: 0.022860
2022-01-08 10:21:25,925 iteration 661 : loss : 0.089651, loss_ce: 0.047883
2022-01-08 10:21:28,447 iteration 662 : loss : 0.057261, loss_ce: 0.030353
2022-01-08 10:21:30,926 iteration 663 : loss : 0.060848, loss_ce: 0.019103
 10%|██▉                           | 39/400 [27:45<4:32:13, 45.24s/it]2022-01-08 10:21:33,562 iteration 664 : loss : 0.063139, loss_ce: 0.031105
2022-01-08 10:21:36,238 iteration 665 : loss : 0.051269, loss_ce: 0.023700
2022-01-08 10:21:38,791 iteration 666 : loss : 0.061563, loss_ce: 0.024374
2022-01-08 10:21:41,314 iteration 667 : loss : 0.051470, loss_ce: 0.023432
2022-01-08 10:21:43,966 iteration 668 : loss : 0.065144, loss_ce: 0.025088
2022-01-08 10:21:46,493 iteration 669 : loss : 0.083758, loss_ce: 0.048360
2022-01-08 10:21:49,056 iteration 670 : loss : 0.061590, loss_ce: 0.026898
2022-01-08 10:21:51,681 iteration 671 : loss : 0.056629, loss_ce: 0.016934
2022-01-08 10:21:54,298 iteration 672 : loss : 0.066909, loss_ce: 0.025074
2022-01-08 10:21:56,844 iteration 673 : loss : 0.066261, loss_ce: 0.031847
2022-01-08 10:21:59,423 iteration 674 : loss : 0.057127, loss_ce: 0.023960
2022-01-08 10:22:02,020 iteration 675 : loss : 0.084598, loss_ce: 0.031984
2022-01-08 10:22:04,671 iteration 676 : loss : 0.078053, loss_ce: 0.023720
2022-01-08 10:22:07,160 iteration 677 : loss : 0.083706, loss_ce: 0.041126
2022-01-08 10:22:09,815 iteration 678 : loss : 0.061269, loss_ce: 0.021667
2022-01-08 10:22:12,428 iteration 679 : loss : 0.090575, loss_ce: 0.049701
2022-01-08 10:22:12,428 Training Data Eval:
2022-01-08 10:22:26,197   Average segmentation loss on training set: 0.1057
2022-01-08 10:22:26,197 Validation Data Eval:
2022-01-08 10:22:30,995   Average segmentation loss on validation set: 0.1427
2022-01-08 10:22:33,601 iteration 680 : loss : 0.144988, loss_ce: 0.034932
 10%|███                           | 40/400 [28:48<5:02:49, 50.47s/it]2022-01-08 10:22:36,252 iteration 681 : loss : 0.080723, loss_ce: 0.033598
2022-01-08 10:22:38,821 iteration 682 : loss : 0.058673, loss_ce: 0.019161
2022-01-08 10:22:41,413 iteration 683 : loss : 0.062643, loss_ce: 0.029298
2022-01-08 10:22:44,062 iteration 684 : loss : 0.071354, loss_ce: 0.029001
2022-01-08 10:22:46,699 iteration 685 : loss : 0.062173, loss_ce: 0.025044
2022-01-08 10:22:49,274 iteration 686 : loss : 0.070906, loss_ce: 0.021157
2022-01-08 10:22:51,843 iteration 687 : loss : 0.063394, loss_ce: 0.021739
2022-01-08 10:22:54,289 iteration 688 : loss : 0.069834, loss_ce: 0.028492
2022-01-08 10:22:56,783 iteration 689 : loss : 0.064839, loss_ce: 0.029186
2022-01-08 10:22:59,211 iteration 690 : loss : 0.093437, loss_ce: 0.049837
2022-01-08 10:23:01,884 iteration 691 : loss : 0.054714, loss_ce: 0.024479
2022-01-08 10:23:04,487 iteration 692 : loss : 0.074425, loss_ce: 0.026617
2022-01-08 10:23:07,151 iteration 693 : loss : 0.086159, loss_ce: 0.036998
2022-01-08 10:23:09,712 iteration 694 : loss : 0.058921, loss_ce: 0.023672
2022-01-08 10:23:12,116 iteration 695 : loss : 0.068408, loss_ce: 0.022079
2022-01-08 10:23:14,558 iteration 696 : loss : 0.069924, loss_ce: 0.029241
2022-01-08 10:23:17,167 iteration 697 : loss : 0.080855, loss_ce: 0.033226
 10%|███                           | 41/400 [29:31<4:49:34, 48.40s/it]2022-01-08 10:23:19,709 iteration 698 : loss : 0.108506, loss_ce: 0.038886
2022-01-08 10:23:22,289 iteration 699 : loss : 0.057987, loss_ce: 0.017326
2022-01-08 10:23:24,899 iteration 700 : loss : 0.087169, loss_ce: 0.034501
2022-01-08 10:23:27,414 iteration 701 : loss : 0.074956, loss_ce: 0.028159
2022-01-08 10:23:29,897 iteration 702 : loss : 0.076858, loss_ce: 0.027480
2022-01-08 10:23:32,490 iteration 703 : loss : 0.068731, loss_ce: 0.029675
2022-01-08 10:23:35,029 iteration 704 : loss : 0.079819, loss_ce: 0.025452
2022-01-08 10:23:37,446 iteration 705 : loss : 0.082678, loss_ce: 0.035346
2022-01-08 10:23:40,132 iteration 706 : loss : 0.051400, loss_ce: 0.023542
2022-01-08 10:23:42,719 iteration 707 : loss : 0.066678, loss_ce: 0.029746
2022-01-08 10:23:45,291 iteration 708 : loss : 0.074920, loss_ce: 0.032589
2022-01-08 10:23:47,916 iteration 709 : loss : 0.059264, loss_ce: 0.027589
2022-01-08 10:23:50,335 iteration 710 : loss : 0.078207, loss_ce: 0.027422
2022-01-08 10:23:52,861 iteration 711 : loss : 0.140082, loss_ce: 0.040979
2022-01-08 10:23:55,512 iteration 712 : loss : 0.057686, loss_ce: 0.030171
2022-01-08 10:23:57,972 iteration 713 : loss : 0.071241, loss_ce: 0.029563
2022-01-08 10:24:00,615 iteration 714 : loss : 0.049076, loss_ce: 0.021825
 10%|███▏                          | 42/400 [30:15<4:39:55, 46.91s/it]2022-01-08 10:24:03,269 iteration 715 : loss : 0.062112, loss_ce: 0.030401
2022-01-08 10:24:05,771 iteration 716 : loss : 0.105486, loss_ce: 0.028026
2022-01-08 10:24:08,230 iteration 717 : loss : 0.063277, loss_ce: 0.026457
2022-01-08 10:24:10,629 iteration 718 : loss : 0.062232, loss_ce: 0.023057
2022-01-08 10:24:13,242 iteration 719 : loss : 0.072534, loss_ce: 0.039455
2022-01-08 10:24:15,624 iteration 720 : loss : 0.051335, loss_ce: 0.022927
2022-01-08 10:24:18,348 iteration 721 : loss : 0.097147, loss_ce: 0.034596
2022-01-08 10:24:20,879 iteration 722 : loss : 0.048419, loss_ce: 0.022480
2022-01-08 10:24:23,302 iteration 723 : loss : 0.072491, loss_ce: 0.029451
2022-01-08 10:24:26,046 iteration 724 : loss : 0.096670, loss_ce: 0.041731
2022-01-08 10:24:28,667 iteration 725 : loss : 0.057017, loss_ce: 0.025343
2022-01-08 10:24:31,307 iteration 726 : loss : 0.093487, loss_ce: 0.054225
2022-01-08 10:24:33,723 iteration 727 : loss : 0.045545, loss_ce: 0.016663
2022-01-08 10:24:36,261 iteration 728 : loss : 0.072641, loss_ce: 0.020998
2022-01-08 10:24:38,718 iteration 729 : loss : 0.104669, loss_ce: 0.046784
2022-01-08 10:24:41,325 iteration 730 : loss : 0.068325, loss_ce: 0.024794
2022-01-08 10:24:43,959 iteration 731 : loss : 0.088842, loss_ce: 0.032172
 11%|███▏                          | 43/400 [30:58<4:32:45, 45.84s/it]2022-01-08 10:24:46,449 iteration 732 : loss : 0.061207, loss_ce: 0.024711
2022-01-08 10:24:48,862 iteration 733 : loss : 0.061341, loss_ce: 0.029260
2022-01-08 10:24:51,295 iteration 734 : loss : 0.105174, loss_ce: 0.048014
2022-01-08 10:24:53,893 iteration 735 : loss : 0.103772, loss_ce: 0.035046
2022-01-08 10:24:56,439 iteration 736 : loss : 0.055234, loss_ce: 0.022467
2022-01-08 10:24:58,976 iteration 737 : loss : 0.074267, loss_ce: 0.031876
2022-01-08 10:25:01,566 iteration 738 : loss : 0.066595, loss_ce: 0.025556
2022-01-08 10:25:04,009 iteration 739 : loss : 0.088589, loss_ce: 0.039930
2022-01-08 10:25:06,585 iteration 740 : loss : 0.061558, loss_ce: 0.018172
2022-01-08 10:25:09,158 iteration 741 : loss : 0.066610, loss_ce: 0.029768
2022-01-08 10:25:11,605 iteration 742 : loss : 0.075055, loss_ce: 0.028741
2022-01-08 10:25:14,169 iteration 743 : loss : 0.070811, loss_ce: 0.021238
2022-01-08 10:25:16,669 iteration 744 : loss : 0.056968, loss_ce: 0.026190
2022-01-08 10:25:19,248 iteration 745 : loss : 0.075635, loss_ce: 0.026959
2022-01-08 10:25:21,902 iteration 746 : loss : 0.133354, loss_ce: 0.046767
2022-01-08 10:25:24,435 iteration 747 : loss : 0.086804, loss_ce: 0.039421
2022-01-08 10:25:27,044 iteration 748 : loss : 0.075365, loss_ce: 0.027350
 11%|███▎                          | 44/400 [31:41<4:27:05, 45.01s/it]2022-01-08 10:25:29,481 iteration 749 : loss : 0.076829, loss_ce: 0.024580
2022-01-08 10:25:31,936 iteration 750 : loss : 0.049944, loss_ce: 0.016539
2022-01-08 10:25:34,422 iteration 751 : loss : 0.084118, loss_ce: 0.033627
2022-01-08 10:25:36,800 iteration 752 : loss : 0.074287, loss_ce: 0.030466
2022-01-08 10:25:39,440 iteration 753 : loss : 0.059149, loss_ce: 0.023390
2022-01-08 10:25:42,004 iteration 754 : loss : 0.039908, loss_ce: 0.013753
2022-01-08 10:25:44,572 iteration 755 : loss : 0.055766, loss_ce: 0.023581
2022-01-08 10:25:47,105 iteration 756 : loss : 0.062692, loss_ce: 0.028176
2022-01-08 10:25:49,502 iteration 757 : loss : 0.071020, loss_ce: 0.030883
2022-01-08 10:25:52,081 iteration 758 : loss : 0.079374, loss_ce: 0.031433
2022-01-08 10:25:54,700 iteration 759 : loss : 0.107470, loss_ce: 0.041454
2022-01-08 10:25:57,194 iteration 760 : loss : 0.074946, loss_ce: 0.027107
2022-01-08 10:25:59,816 iteration 761 : loss : 0.094641, loss_ce: 0.039386
2022-01-08 10:26:02,214 iteration 762 : loss : 0.056941, loss_ce: 0.023473
2022-01-08 10:26:04,775 iteration 763 : loss : 0.056769, loss_ce: 0.026333
2022-01-08 10:26:07,354 iteration 764 : loss : 0.064230, loss_ce: 0.024251
2022-01-08 10:26:07,354 Training Data Eval:
2022-01-08 10:26:20,967   Average segmentation loss on training set: 0.0613
2022-01-08 10:26:20,967 Validation Data Eval:
2022-01-08 10:26:25,734   Average segmentation loss on validation set: 0.1116
2022-01-08 10:26:28,264 iteration 765 : loss : 0.065466, loss_ce: 0.027357
 11%|███▍                          | 45/400 [32:43<4:55:06, 49.88s/it]2022-01-08 10:26:30,970 iteration 766 : loss : 0.066765, loss_ce: 0.025547
2022-01-08 10:26:33,512 iteration 767 : loss : 0.080647, loss_ce: 0.034121
2022-01-08 10:26:36,078 iteration 768 : loss : 0.075034, loss_ce: 0.031917
2022-01-08 10:26:38,648 iteration 769 : loss : 0.069750, loss_ce: 0.032298
2022-01-08 10:26:41,195 iteration 770 : loss : 0.068525, loss_ce: 0.037214
2022-01-08 10:26:43,827 iteration 771 : loss : 0.060781, loss_ce: 0.030766
2022-01-08 10:26:46,231 iteration 772 : loss : 0.065352, loss_ce: 0.027345
2022-01-08 10:26:48,621 iteration 773 : loss : 0.106458, loss_ce: 0.043131
2022-01-08 10:26:51,109 iteration 774 : loss : 0.062108, loss_ce: 0.027502
2022-01-08 10:26:53,493 iteration 775 : loss : 0.065695, loss_ce: 0.024976
2022-01-08 10:26:56,056 iteration 776 : loss : 0.131646, loss_ce: 0.042744
2022-01-08 10:26:58,625 iteration 777 : loss : 0.061329, loss_ce: 0.025883
2022-01-08 10:27:01,174 iteration 778 : loss : 0.063130, loss_ce: 0.021911
2022-01-08 10:27:03,558 iteration 779 : loss : 0.075083, loss_ce: 0.028307
2022-01-08 10:27:06,221 iteration 780 : loss : 0.091455, loss_ce: 0.028674
2022-01-08 10:27:08,840 iteration 781 : loss : 0.068128, loss_ce: 0.023702
2022-01-08 10:27:11,228 iteration 782 : loss : 0.068730, loss_ce: 0.029787
 12%|███▍                          | 46/400 [33:25<4:42:02, 47.80s/it]2022-01-08 10:27:13,812 iteration 783 : loss : 0.067379, loss_ce: 0.028234
2022-01-08 10:27:16,151 iteration 784 : loss : 0.043123, loss_ce: 0.017270
2022-01-08 10:27:18,686 iteration 785 : loss : 0.068302, loss_ce: 0.020413
2022-01-08 10:27:21,149 iteration 786 : loss : 0.057098, loss_ce: 0.020755
2022-01-08 10:27:23,630 iteration 787 : loss : 0.083774, loss_ce: 0.034370
2022-01-08 10:27:26,072 iteration 788 : loss : 0.106448, loss_ce: 0.048647
2022-01-08 10:27:28,510 iteration 789 : loss : 0.082201, loss_ce: 0.029466
2022-01-08 10:27:31,132 iteration 790 : loss : 0.053940, loss_ce: 0.022532
2022-01-08 10:27:33,493 iteration 791 : loss : 0.057999, loss_ce: 0.027840
2022-01-08 10:27:35,997 iteration 792 : loss : 0.072591, loss_ce: 0.030082
2022-01-08 10:27:38,559 iteration 793 : loss : 0.090949, loss_ce: 0.032731
2022-01-08 10:27:41,022 iteration 794 : loss : 0.065706, loss_ce: 0.030286
2022-01-08 10:27:43,518 iteration 795 : loss : 0.051203, loss_ce: 0.019403
2022-01-08 10:27:46,233 iteration 796 : loss : 0.067167, loss_ce: 0.030377
2022-01-08 10:27:48,625 iteration 797 : loss : 0.050970, loss_ce: 0.022610
2022-01-08 10:27:51,055 iteration 798 : loss : 0.059199, loss_ce: 0.024001
2022-01-08 10:27:53,516 iteration 799 : loss : 0.108013, loss_ce: 0.033608
 12%|███▌                          | 47/400 [34:08<4:31:30, 46.15s/it]2022-01-08 10:27:55,975 iteration 800 : loss : 0.080300, loss_ce: 0.041522
2022-01-08 10:27:58,432 iteration 801 : loss : 0.068885, loss_ce: 0.018737
2022-01-08 10:28:00,884 iteration 802 : loss : 0.074909, loss_ce: 0.037620
2022-01-08 10:28:03,261 iteration 803 : loss : 0.047234, loss_ce: 0.018185
2022-01-08 10:28:05,769 iteration 804 : loss : 0.071985, loss_ce: 0.024646
2022-01-08 10:28:08,198 iteration 805 : loss : 0.065707, loss_ce: 0.029996
2022-01-08 10:28:10,686 iteration 806 : loss : 0.058380, loss_ce: 0.023293
2022-01-08 10:28:13,073 iteration 807 : loss : 0.045823, loss_ce: 0.024210
2022-01-08 10:28:15,407 iteration 808 : loss : 0.103181, loss_ce: 0.036942
2022-01-08 10:28:17,820 iteration 809 : loss : 0.059876, loss_ce: 0.024566
2022-01-08 10:28:20,141 iteration 810 : loss : 0.051118, loss_ce: 0.016798
2022-01-08 10:28:22,537 iteration 811 : loss : 0.105287, loss_ce: 0.043347
2022-01-08 10:28:24,800 iteration 812 : loss : 0.069668, loss_ce: 0.029400
2022-01-08 10:28:27,104 iteration 813 : loss : 0.054376, loss_ce: 0.021940
2022-01-08 10:28:29,354 iteration 814 : loss : 0.131789, loss_ce: 0.031651
2022-01-08 10:28:31,452 iteration 815 : loss : 0.057514, loss_ce: 0.026401
2022-01-08 10:28:33,723 iteration 816 : loss : 0.088594, loss_ce: 0.033921
 12%|███▌                          | 48/400 [34:48<4:20:17, 44.37s/it]2022-01-08 10:28:35,937 iteration 817 : loss : 0.061641, loss_ce: 0.024132
2022-01-08 10:28:38,147 iteration 818 : loss : 0.062816, loss_ce: 0.029827
2022-01-08 10:28:40,497 iteration 819 : loss : 0.063106, loss_ce: 0.029591
2022-01-08 10:28:42,707 iteration 820 : loss : 0.102289, loss_ce: 0.039740
2022-01-08 10:28:44,884 iteration 821 : loss : 0.069555, loss_ce: 0.025862
2022-01-08 10:28:47,062 iteration 822 : loss : 0.068077, loss_ce: 0.029854
2022-01-08 10:28:49,310 iteration 823 : loss : 0.083042, loss_ce: 0.038021
2022-01-08 10:28:51,425 iteration 824 : loss : 0.050868, loss_ce: 0.017961
2022-01-08 10:28:53,558 iteration 825 : loss : 0.105835, loss_ce: 0.030693
2022-01-08 10:28:55,713 iteration 826 : loss : 0.061200, loss_ce: 0.021811
2022-01-08 10:28:57,930 iteration 827 : loss : 0.072662, loss_ce: 0.027795
2022-01-08 10:29:00,148 iteration 828 : loss : 0.071853, loss_ce: 0.028071
2022-01-08 10:29:02,447 iteration 829 : loss : 0.086619, loss_ce: 0.042417
2022-01-08 10:29:04,571 iteration 830 : loss : 0.084017, loss_ce: 0.037506
2022-01-08 10:29:06,806 iteration 831 : loss : 0.064576, loss_ce: 0.025975
2022-01-08 10:29:09,126 iteration 832 : loss : 0.063865, loss_ce: 0.019034
2022-01-08 10:29:11,379 iteration 833 : loss : 0.046816, loss_ce: 0.020446
 12%|███▋                          | 49/400 [35:26<4:07:44, 42.35s/it]2022-01-08 10:29:13,597 iteration 834 : loss : 0.064506, loss_ce: 0.023821
2022-01-08 10:29:15,742 iteration 835 : loss : 0.038277, loss_ce: 0.014589
2022-01-08 10:29:18,090 iteration 836 : loss : 0.064811, loss_ce: 0.022703
2022-01-08 10:29:20,272 iteration 837 : loss : 0.048039, loss_ce: 0.017546
2022-01-08 10:29:22,506 iteration 838 : loss : 0.055819, loss_ce: 0.024673
2022-01-08 10:29:24,572 iteration 839 : loss : 0.055361, loss_ce: 0.024065
2022-01-08 10:29:26,723 iteration 840 : loss : 0.037183, loss_ce: 0.017535
2022-01-08 10:29:28,880 iteration 841 : loss : 0.062627, loss_ce: 0.022039
2022-01-08 10:29:31,141 iteration 842 : loss : 0.079540, loss_ce: 0.028315
2022-01-08 10:29:33,252 iteration 843 : loss : 0.052874, loss_ce: 0.018362
2022-01-08 10:29:35,384 iteration 844 : loss : 0.041576, loss_ce: 0.015226
2022-01-08 10:29:37,487 iteration 845 : loss : 0.060207, loss_ce: 0.030093
2022-01-08 10:29:39,683 iteration 846 : loss : 0.043440, loss_ce: 0.020712
2022-01-08 10:29:42,046 iteration 847 : loss : 0.061955, loss_ce: 0.023167
2022-01-08 10:29:44,352 iteration 848 : loss : 0.046419, loss_ce: 0.018171
2022-01-08 10:29:46,538 iteration 849 : loss : 0.058230, loss_ce: 0.021456
2022-01-08 10:29:46,539 Training Data Eval:
2022-01-08 10:29:58,491   Average segmentation loss on training set: 0.0532
2022-01-08 10:29:58,491 Validation Data Eval:
2022-01-08 10:30:02,886   Average segmentation loss on validation set: 0.0987
2022-01-08 10:30:05,260 iteration 850 : loss : 0.081626, loss_ce: 0.040245
 12%|███▊                          | 50/400 [36:20<4:27:13, 45.81s/it]2022-01-08 10:30:07,652 iteration 851 : loss : 0.048495, loss_ce: 0.018822
2022-01-08 10:30:09,945 iteration 852 : loss : 0.073674, loss_ce: 0.028659
2022-01-08 10:30:12,198 iteration 853 : loss : 0.071737, loss_ce: 0.023248
2022-01-08 10:30:14,363 iteration 854 : loss : 0.052061, loss_ce: 0.027713
2022-01-08 10:30:16,567 iteration 855 : loss : 0.043331, loss_ce: 0.019981
2022-01-08 10:30:18,937 iteration 856 : loss : 0.057691, loss_ce: 0.026047
2022-01-08 10:30:21,254 iteration 857 : loss : 0.064972, loss_ce: 0.026006
2022-01-08 10:30:23,631 iteration 858 : loss : 0.040106, loss_ce: 0.015246
2022-01-08 10:30:25,758 iteration 859 : loss : 0.045894, loss_ce: 0.014804
2022-01-08 10:30:27,964 iteration 860 : loss : 0.047223, loss_ce: 0.016255
2022-01-08 10:30:30,252 iteration 861 : loss : 0.060827, loss_ce: 0.016730
2022-01-08 10:30:32,489 iteration 862 : loss : 0.068295, loss_ce: 0.030239
2022-01-08 10:30:34,657 iteration 863 : loss : 0.064412, loss_ce: 0.024462
2022-01-08 10:30:36,789 iteration 864 : loss : 0.059840, loss_ce: 0.025541
2022-01-08 10:30:38,913 iteration 865 : loss : 0.047419, loss_ce: 0.018470
2022-01-08 10:30:41,069 iteration 866 : loss : 0.057773, loss_ce: 0.025888
2022-01-08 10:30:43,310 iteration 867 : loss : 0.065598, loss_ce: 0.027292
 13%|███▊                          | 51/400 [36:58<4:12:56, 43.49s/it]2022-01-08 10:30:45,572 iteration 868 : loss : 0.045638, loss_ce: 0.020719
2022-01-08 10:30:47,793 iteration 869 : loss : 0.068442, loss_ce: 0.028054
2022-01-08 10:30:49,924 iteration 870 : loss : 0.051922, loss_ce: 0.024370
2022-01-08 10:30:52,155 iteration 871 : loss : 0.050139, loss_ce: 0.023057
2022-01-08 10:30:54,350 iteration 872 : loss : 0.064372, loss_ce: 0.028135
2022-01-08 10:30:56,635 iteration 873 : loss : 0.043151, loss_ce: 0.020803
2022-01-08 10:30:58,888 iteration 874 : loss : 0.047901, loss_ce: 0.019756
2022-01-08 10:31:01,122 iteration 875 : loss : 0.072813, loss_ce: 0.027629
2022-01-08 10:31:03,333 iteration 876 : loss : 0.055958, loss_ce: 0.021537
2022-01-08 10:31:05,625 iteration 877 : loss : 0.044836, loss_ce: 0.019580
2022-01-08 10:31:07,862 iteration 878 : loss : 0.089040, loss_ce: 0.021226
2022-01-08 10:31:10,202 iteration 879 : loss : 0.082750, loss_ce: 0.022869
2022-01-08 10:31:12,532 iteration 880 : loss : 0.053475, loss_ce: 0.025441
2022-01-08 10:31:14,936 iteration 881 : loss : 0.065239, loss_ce: 0.019354
2022-01-08 10:31:17,246 iteration 882 : loss : 0.091017, loss_ce: 0.036358
2022-01-08 10:31:19,509 iteration 883 : loss : 0.064888, loss_ce: 0.020466
2022-01-08 10:31:21,798 iteration 884 : loss : 0.070983, loss_ce: 0.028368
 13%|███▉                          | 52/400 [37:36<4:03:29, 41.98s/it]2022-01-08 10:31:24,077 iteration 885 : loss : 0.054340, loss_ce: 0.021565
2022-01-08 10:31:26,381 iteration 886 : loss : 0.076308, loss_ce: 0.040494
2022-01-08 10:31:28,660 iteration 887 : loss : 0.078458, loss_ce: 0.031599
2022-01-08 10:31:31,078 iteration 888 : loss : 0.071274, loss_ce: 0.028399
2022-01-08 10:31:33,398 iteration 889 : loss : 0.189308, loss_ce: 0.060914
2022-01-08 10:31:35,703 iteration 890 : loss : 0.049727, loss_ce: 0.022646
2022-01-08 10:31:38,056 iteration 891 : loss : 0.064234, loss_ce: 0.038827
2022-01-08 10:31:40,371 iteration 892 : loss : 0.053797, loss_ce: 0.021968
2022-01-08 10:31:42,669 iteration 893 : loss : 0.052029, loss_ce: 0.023077
2022-01-08 10:31:44,888 iteration 894 : loss : 0.069453, loss_ce: 0.021494
2022-01-08 10:31:47,124 iteration 895 : loss : 0.086710, loss_ce: 0.035297
2022-01-08 10:31:49,370 iteration 896 : loss : 0.047870, loss_ce: 0.020610
2022-01-08 10:31:51,821 iteration 897 : loss : 0.063947, loss_ce: 0.022226
2022-01-08 10:31:54,161 iteration 898 : loss : 0.093372, loss_ce: 0.036055
2022-01-08 10:31:56,513 iteration 899 : loss : 0.072297, loss_ce: 0.025837
2022-01-08 10:31:58,819 iteration 900 : loss : 0.068140, loss_ce: 0.024311
2022-01-08 10:32:01,291 iteration 901 : loss : 0.072325, loss_ce: 0.028323
 13%|███▉                          | 53/400 [38:16<3:58:30, 41.24s/it]2022-01-08 10:32:03,831 iteration 902 : loss : 0.077704, loss_ce: 0.037808
2022-01-08 10:32:06,206 iteration 903 : loss : 0.070041, loss_ce: 0.022146
2022-01-08 10:32:08,706 iteration 904 : loss : 0.076796, loss_ce: 0.036431
2022-01-08 10:32:11,086 iteration 905 : loss : 0.053828, loss_ce: 0.021635
2022-01-08 10:32:13,587 iteration 906 : loss : 0.059281, loss_ce: 0.025604
2022-01-08 10:32:15,961 iteration 907 : loss : 0.048305, loss_ce: 0.019327
2022-01-08 10:32:18,326 iteration 908 : loss : 0.053733, loss_ce: 0.028053
2022-01-08 10:32:20,842 iteration 909 : loss : 0.056608, loss_ce: 0.024187
2022-01-08 10:32:23,333 iteration 910 : loss : 0.048973, loss_ce: 0.020111
2022-01-08 10:32:25,894 iteration 911 : loss : 0.045011, loss_ce: 0.018844
2022-01-08 10:32:28,345 iteration 912 : loss : 0.063791, loss_ce: 0.027953
2022-01-08 10:32:30,818 iteration 913 : loss : 0.071162, loss_ce: 0.025266
2022-01-08 10:32:33,429 iteration 914 : loss : 0.050269, loss_ce: 0.020650
2022-01-08 10:32:35,987 iteration 915 : loss : 0.061786, loss_ce: 0.024078
2022-01-08 10:32:38,460 iteration 916 : loss : 0.097351, loss_ce: 0.030028
2022-01-08 10:32:41,013 iteration 917 : loss : 0.055838, loss_ce: 0.021698
2022-01-08 10:32:43,500 iteration 918 : loss : 0.109767, loss_ce: 0.026083
 14%|████                          | 54/400 [38:58<3:59:29, 41.53s/it]2022-01-08 10:32:45,869 iteration 919 : loss : 0.048149, loss_ce: 0.016201
2022-01-08 10:32:48,301 iteration 920 : loss : 0.044896, loss_ce: 0.020605
2022-01-08 10:32:50,677 iteration 921 : loss : 0.051028, loss_ce: 0.020508
2022-01-08 10:32:53,296 iteration 922 : loss : 0.049460, loss_ce: 0.018207
2022-01-08 10:32:55,625 iteration 923 : loss : 0.043185, loss_ce: 0.016317
2022-01-08 10:32:57,945 iteration 924 : loss : 0.078454, loss_ce: 0.026399
2022-01-08 10:33:00,212 iteration 925 : loss : 0.068764, loss_ce: 0.022944
2022-01-08 10:33:02,531 iteration 926 : loss : 0.055577, loss_ce: 0.019576
2022-01-08 10:33:04,766 iteration 927 : loss : 0.082728, loss_ce: 0.022188
2022-01-08 10:33:07,173 iteration 928 : loss : 0.082566, loss_ce: 0.037657
2022-01-08 10:33:09,474 iteration 929 : loss : 0.049134, loss_ce: 0.019848
2022-01-08 10:33:11,727 iteration 930 : loss : 0.057778, loss_ce: 0.025677
2022-01-08 10:33:14,041 iteration 931 : loss : 0.103582, loss_ce: 0.062146
2022-01-08 10:33:16,430 iteration 932 : loss : 0.052511, loss_ce: 0.026525
2022-01-08 10:33:18,854 iteration 933 : loss : 0.055726, loss_ce: 0.027425
2022-01-08 10:33:21,152 iteration 934 : loss : 0.045764, loss_ce: 0.016846
2022-01-08 10:33:21,153 Training Data Eval:
2022-01-08 10:33:33,652   Average segmentation loss on training set: 0.0750
2022-01-08 10:33:33,652 Validation Data Eval:
2022-01-08 10:33:38,013   Average segmentation loss on validation set: 0.0963
2022-01-08 10:33:40,393 iteration 935 : loss : 0.054535, loss_ce: 0.025851
 14%|████▏                         | 55/400 [39:55<4:25:16, 46.14s/it]2022-01-08 10:33:42,722 iteration 936 : loss : 0.050954, loss_ce: 0.023711
2022-01-08 10:33:44,891 iteration 937 : loss : 0.098532, loss_ce: 0.036894
2022-01-08 10:33:47,135 iteration 938 : loss : 0.046775, loss_ce: 0.023153
2022-01-08 10:33:49,409 iteration 939 : loss : 0.071098, loss_ce: 0.024566
2022-01-08 10:33:51,418 iteration 940 : loss : 0.054777, loss_ce: 0.021337
2022-01-08 10:33:53,447 iteration 941 : loss : 0.050503, loss_ce: 0.018050
2022-01-08 10:33:55,544 iteration 942 : loss : 0.066358, loss_ce: 0.027073
2022-01-08 10:33:57,704 iteration 943 : loss : 0.092601, loss_ce: 0.029342
2022-01-08 10:33:59,825 iteration 944 : loss : 0.084034, loss_ce: 0.028298
2022-01-08 10:34:02,066 iteration 945 : loss : 0.067106, loss_ce: 0.027691
2022-01-08 10:34:04,364 iteration 946 : loss : 0.049888, loss_ce: 0.020829
2022-01-08 10:34:06,732 iteration 947 : loss : 0.065528, loss_ce: 0.024361
2022-01-08 10:34:09,079 iteration 948 : loss : 0.076216, loss_ce: 0.029987
2022-01-08 10:34:11,348 iteration 949 : loss : 0.105949, loss_ce: 0.043239
2022-01-08 10:34:13,709 iteration 950 : loss : 0.066102, loss_ce: 0.025683
2022-01-08 10:34:15,945 iteration 951 : loss : 0.038125, loss_ce: 0.015637
2022-01-08 10:34:18,197 iteration 952 : loss : 0.057993, loss_ce: 0.021449
 14%|████▏                         | 56/400 [40:32<4:10:10, 43.64s/it]2022-01-08 10:34:20,409 iteration 953 : loss : 0.057528, loss_ce: 0.022406
2022-01-08 10:34:22,667 iteration 954 : loss : 0.051053, loss_ce: 0.019219
2022-01-08 10:34:25,104 iteration 955 : loss : 0.085422, loss_ce: 0.030950
2022-01-08 10:34:27,537 iteration 956 : loss : 0.047674, loss_ce: 0.015815
2022-01-08 10:34:29,976 iteration 957 : loss : 0.071843, loss_ce: 0.029934
2022-01-08 10:34:32,388 iteration 958 : loss : 0.057919, loss_ce: 0.022790
2022-01-08 10:34:34,769 iteration 959 : loss : 0.054760, loss_ce: 0.026924
2022-01-08 10:34:37,079 iteration 960 : loss : 0.069497, loss_ce: 0.027694
2022-01-08 10:34:39,388 iteration 961 : loss : 0.063306, loss_ce: 0.022832
2022-01-08 10:34:41,715 iteration 962 : loss : 0.083229, loss_ce: 0.022060
2022-01-08 10:34:43,978 iteration 963 : loss : 0.052812, loss_ce: 0.022170
2022-01-08 10:34:46,315 iteration 964 : loss : 0.046389, loss_ce: 0.014903
2022-01-08 10:34:48,641 iteration 965 : loss : 0.044576, loss_ce: 0.015901
2022-01-08 10:34:51,017 iteration 966 : loss : 0.073483, loss_ce: 0.023906
2022-01-08 10:34:53,328 iteration 967 : loss : 0.057172, loss_ce: 0.026380
2022-01-08 10:34:55,641 iteration 968 : loss : 0.054171, loss_ce: 0.020020
2022-01-08 10:34:57,956 iteration 969 : loss : 0.052402, loss_ce: 0.025310
 14%|████▎                         | 57/400 [41:12<4:02:47, 42.47s/it]2022-01-08 10:35:00,196 iteration 970 : loss : 0.050094, loss_ce: 0.024428
2022-01-08 10:35:02,567 iteration 971 : loss : 0.051197, loss_ce: 0.022348
2022-01-08 10:35:04,915 iteration 972 : loss : 0.055105, loss_ce: 0.019438
2022-01-08 10:35:07,278 iteration 973 : loss : 0.042170, loss_ce: 0.016195
2022-01-08 10:35:09,600 iteration 974 : loss : 0.065908, loss_ce: 0.026288
2022-01-08 10:35:11,926 iteration 975 : loss : 0.063330, loss_ce: 0.024108
2022-01-08 10:35:14,375 iteration 976 : loss : 0.056163, loss_ce: 0.024439
2022-01-08 10:35:16,728 iteration 977 : loss : 0.061388, loss_ce: 0.025902
2022-01-08 10:35:19,104 iteration 978 : loss : 0.048323, loss_ce: 0.017791
2022-01-08 10:35:21,392 iteration 979 : loss : 0.041733, loss_ce: 0.015855
2022-01-08 10:35:23,738 iteration 980 : loss : 0.052251, loss_ce: 0.018814
2022-01-08 10:35:26,054 iteration 981 : loss : 0.025948, loss_ce: 0.009460
2022-01-08 10:35:28,465 iteration 982 : loss : 0.077193, loss_ce: 0.023959
2022-01-08 10:35:30,852 iteration 983 : loss : 0.070628, loss_ce: 0.032094
2022-01-08 10:35:33,223 iteration 984 : loss : 0.042755, loss_ce: 0.018537
2022-01-08 10:35:35,527 iteration 985 : loss : 0.049916, loss_ce: 0.020199
2022-01-08 10:35:37,738 iteration 986 : loss : 0.083839, loss_ce: 0.034485
 14%|████▎                         | 58/400 [41:52<3:57:31, 41.67s/it]2022-01-08 10:35:40,057 iteration 987 : loss : 0.049916, loss_ce: 0.016498
2022-01-08 10:35:42,365 iteration 988 : loss : 0.055562, loss_ce: 0.019135
2022-01-08 10:35:44,590 iteration 989 : loss : 0.056011, loss_ce: 0.019966
2022-01-08 10:35:46,853 iteration 990 : loss : 0.056980, loss_ce: 0.019061
2022-01-08 10:35:49,126 iteration 991 : loss : 0.058000, loss_ce: 0.022141
2022-01-08 10:35:51,349 iteration 992 : loss : 0.045378, loss_ce: 0.018565
2022-01-08 10:35:53,622 iteration 993 : loss : 0.058681, loss_ce: 0.020606
2022-01-08 10:35:55,876 iteration 994 : loss : 0.047362, loss_ce: 0.017751
2022-01-08 10:35:58,263 iteration 995 : loss : 0.054779, loss_ce: 0.025565
2022-01-08 10:36:00,539 iteration 996 : loss : 0.047485, loss_ce: 0.024197
2022-01-08 10:36:02,842 iteration 997 : loss : 0.084051, loss_ce: 0.034707
2022-01-08 10:36:05,090 iteration 998 : loss : 0.040434, loss_ce: 0.015169
2022-01-08 10:36:07,289 iteration 999 : loss : 0.048273, loss_ce: 0.020250
2022-01-08 10:36:09,599 iteration 1000 : loss : 0.056946, loss_ce: 0.031281
2022-01-08 10:36:11,844 iteration 1001 : loss : 0.047875, loss_ce: 0.018664
2022-01-08 10:36:14,110 iteration 1002 : loss : 0.060463, loss_ce: 0.024049
2022-01-08 10:36:16,272 iteration 1003 : loss : 0.121115, loss_ce: 0.040277
 15%|████▍                         | 59/400 [42:31<3:51:26, 40.72s/it]2022-01-08 10:36:18,486 iteration 1004 : loss : 0.060684, loss_ce: 0.020786
2022-01-08 10:36:20,749 iteration 1005 : loss : 0.058307, loss_ce: 0.025498
2022-01-08 10:36:23,114 iteration 1006 : loss : 0.052867, loss_ce: 0.023670
2022-01-08 10:36:25,391 iteration 1007 : loss : 0.061296, loss_ce: 0.023335
2022-01-08 10:36:27,652 iteration 1008 : loss : 0.055521, loss_ce: 0.028887
2022-01-08 10:36:29,823 iteration 1009 : loss : 0.053314, loss_ce: 0.019265
2022-01-08 10:36:31,963 iteration 1010 : loss : 0.039902, loss_ce: 0.011376
2022-01-08 10:36:34,213 iteration 1011 : loss : 0.057650, loss_ce: 0.026686
2022-01-08 10:36:36,640 iteration 1012 : loss : 0.059878, loss_ce: 0.024087
2022-01-08 10:36:38,946 iteration 1013 : loss : 0.041823, loss_ce: 0.015349
2022-01-08 10:36:41,138 iteration 1014 : loss : 0.034295, loss_ce: 0.013422
2022-01-08 10:36:43,402 iteration 1015 : loss : 0.061297, loss_ce: 0.021438
2022-01-08 10:36:45,587 iteration 1016 : loss : 0.050187, loss_ce: 0.019078
2022-01-08 10:36:47,779 iteration 1017 : loss : 0.051987, loss_ce: 0.021145
2022-01-08 10:36:50,082 iteration 1018 : loss : 0.086507, loss_ce: 0.028472
2022-01-08 10:36:52,359 iteration 1019 : loss : 0.060027, loss_ce: 0.023626
2022-01-08 10:36:52,359 Training Data Eval:
2022-01-08 10:37:04,511   Average segmentation loss on training set: 0.0366
2022-01-08 10:37:04,512 Validation Data Eval:
2022-01-08 10:37:08,862   Average segmentation loss on validation set: 0.0736
2022-01-08 10:37:15,479 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed2.pth
2022-01-08 10:37:17,180 iteration 1020 : loss : 0.062774, loss_ce: 0.022988
 15%|████▌                         | 60/400 [43:31<4:25:06, 46.78s/it]2022-01-08 10:37:18,825 iteration 1021 : loss : 0.053891, loss_ce: 0.024631
2022-01-08 10:37:20,496 iteration 1022 : loss : 0.051738, loss_ce: 0.022107
2022-01-08 10:37:22,039 iteration 1023 : loss : 0.038627, loss_ce: 0.014059
2022-01-08 10:37:23,686 iteration 1024 : loss : 0.062720, loss_ce: 0.027751
2022-01-08 10:37:25,543 iteration 1025 : loss : 0.048185, loss_ce: 0.021574
2022-01-08 10:37:27,497 iteration 1026 : loss : 0.086264, loss_ce: 0.022993
2022-01-08 10:37:29,519 iteration 1027 : loss : 0.057939, loss_ce: 0.020072
2022-01-08 10:37:31,642 iteration 1028 : loss : 0.081378, loss_ce: 0.031329
2022-01-08 10:37:33,729 iteration 1029 : loss : 0.064722, loss_ce: 0.025141
2022-01-08 10:37:35,795 iteration 1030 : loss : 0.061417, loss_ce: 0.025495
2022-01-08 10:37:38,032 iteration 1031 : loss : 0.054237, loss_ce: 0.022786
2022-01-08 10:37:40,154 iteration 1032 : loss : 0.063362, loss_ce: 0.031072
2022-01-08 10:37:42,263 iteration 1033 : loss : 0.069519, loss_ce: 0.032290
2022-01-08 10:37:44,368 iteration 1034 : loss : 0.056429, loss_ce: 0.020893
2022-01-08 10:37:46,577 iteration 1035 : loss : 0.049610, loss_ce: 0.020711
2022-01-08 10:37:48,776 iteration 1036 : loss : 0.074369, loss_ce: 0.029217
2022-01-08 10:37:50,935 iteration 1037 : loss : 0.046629, loss_ce: 0.020926
 15%|████▌                         | 61/400 [44:05<4:02:14, 42.88s/it]2022-01-08 10:37:53,228 iteration 1038 : loss : 0.050208, loss_ce: 0.023725
2022-01-08 10:37:55,454 iteration 1039 : loss : 0.050808, loss_ce: 0.021789
2022-01-08 10:37:57,693 iteration 1040 : loss : 0.066067, loss_ce: 0.020350
2022-01-08 10:37:59,959 iteration 1041 : loss : 0.059832, loss_ce: 0.027007
2022-01-08 10:38:02,165 iteration 1042 : loss : 0.048798, loss_ce: 0.028647
2022-01-08 10:38:04,423 iteration 1043 : loss : 0.055595, loss_ce: 0.019120
2022-01-08 10:38:06,683 iteration 1044 : loss : 0.050027, loss_ce: 0.021545
2022-01-08 10:38:08,988 iteration 1045 : loss : 0.067843, loss_ce: 0.029498
2022-01-08 10:38:11,230 iteration 1046 : loss : 0.047182, loss_ce: 0.022433
2022-01-08 10:38:13,589 iteration 1047 : loss : 0.045636, loss_ce: 0.017148
2022-01-08 10:38:15,998 iteration 1048 : loss : 0.041008, loss_ce: 0.017248
2022-01-08 10:38:18,396 iteration 1049 : loss : 0.056589, loss_ce: 0.023068
2022-01-08 10:38:20,828 iteration 1050 : loss : 0.108455, loss_ce: 0.020736
2022-01-08 10:38:23,190 iteration 1051 : loss : 0.054927, loss_ce: 0.025242
2022-01-08 10:38:25,733 iteration 1052 : loss : 0.051837, loss_ce: 0.015554
2022-01-08 10:38:28,167 iteration 1053 : loss : 0.065263, loss_ce: 0.017118
2022-01-08 10:38:30,556 iteration 1054 : loss : 0.053966, loss_ce: 0.019499
 16%|████▋                         | 62/400 [44:45<3:56:01, 41.90s/it]2022-01-08 10:38:33,176 iteration 1055 : loss : 0.043944, loss_ce: 0.015093
2022-01-08 10:38:35,530 iteration 1056 : loss : 0.044856, loss_ce: 0.019620
2022-01-08 10:38:37,962 iteration 1057 : loss : 0.078677, loss_ce: 0.028109
2022-01-08 10:38:40,414 iteration 1058 : loss : 0.079448, loss_ce: 0.025175
2022-01-08 10:38:42,831 iteration 1059 : loss : 0.065743, loss_ce: 0.027670
2022-01-08 10:38:45,196 iteration 1060 : loss : 0.038296, loss_ce: 0.012470
2022-01-08 10:38:47,717 iteration 1061 : loss : 0.053604, loss_ce: 0.026916
2022-01-08 10:38:50,149 iteration 1062 : loss : 0.093428, loss_ce: 0.036027
2022-01-08 10:38:52,714 iteration 1063 : loss : 0.065739, loss_ce: 0.029443
2022-01-08 10:38:55,216 iteration 1064 : loss : 0.137421, loss_ce: 0.067749
2022-01-08 10:38:57,732 iteration 1065 : loss : 0.064101, loss_ce: 0.037087
2022-01-08 10:39:00,179 iteration 1066 : loss : 0.048373, loss_ce: 0.018073
2022-01-08 10:39:02,629 iteration 1067 : loss : 0.046055, loss_ce: 0.019295
2022-01-08 10:39:05,234 iteration 1068 : loss : 0.048551, loss_ce: 0.020190
2022-01-08 10:39:07,651 iteration 1069 : loss : 0.051229, loss_ce: 0.024493
2022-01-08 10:39:10,071 iteration 1070 : loss : 0.094118, loss_ce: 0.030830
2022-01-08 10:39:12,361 iteration 1071 : loss : 0.052229, loss_ce: 0.024229
 16%|████▋                         | 63/400 [45:27<3:55:09, 41.87s/it]2022-01-08 10:39:14,820 iteration 1072 : loss : 0.077182, loss_ce: 0.025480
2022-01-08 10:39:17,194 iteration 1073 : loss : 0.059032, loss_ce: 0.024412
2022-01-08 10:39:19,511 iteration 1074 : loss : 0.057792, loss_ce: 0.021233
2022-01-08 10:39:21,780 iteration 1075 : loss : 0.095941, loss_ce: 0.033684
2022-01-08 10:39:23,954 iteration 1076 : loss : 0.051707, loss_ce: 0.019464
2022-01-08 10:39:26,228 iteration 1077 : loss : 0.074945, loss_ce: 0.024450
2022-01-08 10:39:28,414 iteration 1078 : loss : 0.058813, loss_ce: 0.025273
2022-01-08 10:39:30,654 iteration 1079 : loss : 0.053149, loss_ce: 0.022075
2022-01-08 10:39:32,828 iteration 1080 : loss : 0.031871, loss_ce: 0.011437
2022-01-08 10:39:35,119 iteration 1081 : loss : 0.043986, loss_ce: 0.022934
2022-01-08 10:39:37,488 iteration 1082 : loss : 0.054744, loss_ce: 0.024643
2022-01-08 10:39:39,850 iteration 1083 : loss : 0.045249, loss_ce: 0.017341
2022-01-08 10:39:42,229 iteration 1084 : loss : 0.060706, loss_ce: 0.018091
2022-01-08 10:39:44,603 iteration 1085 : loss : 0.048322, loss_ce: 0.020129
2022-01-08 10:39:46,977 iteration 1086 : loss : 0.051215, loss_ce: 0.023229
2022-01-08 10:39:49,363 iteration 1087 : loss : 0.040796, loss_ce: 0.016322
2022-01-08 10:39:51,640 iteration 1088 : loss : 0.047738, loss_ce: 0.019548
 16%|████▊                         | 64/400 [46:06<3:50:06, 41.09s/it]2022-01-08 10:39:53,930 iteration 1089 : loss : 0.073271, loss_ce: 0.026980
2022-01-08 10:39:56,254 iteration 1090 : loss : 0.055831, loss_ce: 0.018246
2022-01-08 10:39:58,568 iteration 1091 : loss : 0.040967, loss_ce: 0.019592
2022-01-08 10:40:00,810 iteration 1092 : loss : 0.051314, loss_ce: 0.022002
2022-01-08 10:40:03,142 iteration 1093 : loss : 0.056846, loss_ce: 0.024580
2022-01-08 10:40:05,519 iteration 1094 : loss : 0.054229, loss_ce: 0.025872
2022-01-08 10:40:07,828 iteration 1095 : loss : 0.061175, loss_ce: 0.019964
2022-01-08 10:40:10,195 iteration 1096 : loss : 0.035631, loss_ce: 0.015227
2022-01-08 10:40:12,550 iteration 1097 : loss : 0.067379, loss_ce: 0.019746
2022-01-08 10:40:14,955 iteration 1098 : loss : 0.050887, loss_ce: 0.023681
2022-01-08 10:40:17,326 iteration 1099 : loss : 0.044587, loss_ce: 0.018292
2022-01-08 10:40:19,605 iteration 1100 : loss : 0.054422, loss_ce: 0.021520
2022-01-08 10:40:21,839 iteration 1101 : loss : 0.051469, loss_ce: 0.018871
2022-01-08 10:40:24,158 iteration 1102 : loss : 0.069391, loss_ce: 0.020085
2022-01-08 10:40:26,465 iteration 1103 : loss : 0.054754, loss_ce: 0.021197
2022-01-08 10:40:28,740 iteration 1104 : loss : 0.049124, loss_ce: 0.018627
2022-01-08 10:40:28,740 Training Data Eval:
2022-01-08 10:40:41,538   Average segmentation loss on training set: 0.0363
2022-01-08 10:40:41,538 Validation Data Eval:
2022-01-08 10:40:45,878   Average segmentation loss on validation set: 0.0881
2022-01-08 10:40:48,276 iteration 1105 : loss : 0.044092, loss_ce: 0.019375
 16%|████▉                         | 65/400 [47:03<4:15:27, 45.75s/it]2022-01-08 10:40:50,715 iteration 1106 : loss : 0.055948, loss_ce: 0.021479
2022-01-08 10:40:53,120 iteration 1107 : loss : 0.048593, loss_ce: 0.025239
2022-01-08 10:40:55,333 iteration 1108 : loss : 0.041039, loss_ce: 0.014245
2022-01-08 10:40:57,618 iteration 1109 : loss : 0.074565, loss_ce: 0.028716
2022-01-08 10:41:00,061 iteration 1110 : loss : 0.047715, loss_ce: 0.018928
2022-01-08 10:41:02,453 iteration 1111 : loss : 0.042083, loss_ce: 0.017441
2022-01-08 10:41:04,785 iteration 1112 : loss : 0.043689, loss_ce: 0.016979
2022-01-08 10:41:07,081 iteration 1113 : loss : 0.055227, loss_ce: 0.019027
2022-01-08 10:41:09,389 iteration 1114 : loss : 0.071428, loss_ce: 0.023760
2022-01-08 10:41:11,682 iteration 1115 : loss : 0.050191, loss_ce: 0.016708
2022-01-08 10:41:14,049 iteration 1116 : loss : 0.069299, loss_ce: 0.029528
2022-01-08 10:41:16,448 iteration 1117 : loss : 0.042201, loss_ce: 0.016748
2022-01-08 10:41:18,714 iteration 1118 : loss : 0.038920, loss_ce: 0.016211
2022-01-08 10:41:21,037 iteration 1119 : loss : 0.036448, loss_ce: 0.013713
2022-01-08 10:41:23,426 iteration 1120 : loss : 0.060387, loss_ce: 0.019689
2022-01-08 10:41:25,762 iteration 1121 : loss : 0.042631, loss_ce: 0.013211
2022-01-08 10:41:28,084 iteration 1122 : loss : 0.035171, loss_ce: 0.015044
 16%|████▉                         | 66/400 [47:42<4:04:48, 43.98s/it]2022-01-08 10:41:30,516 iteration 1123 : loss : 0.057089, loss_ce: 0.026357
2022-01-08 10:41:32,859 iteration 1124 : loss : 0.037742, loss_ce: 0.017308
2022-01-08 10:41:35,275 iteration 1125 : loss : 0.057548, loss_ce: 0.021402
2022-01-08 10:41:37,744 iteration 1126 : loss : 0.067888, loss_ce: 0.030794
2022-01-08 10:41:40,107 iteration 1127 : loss : 0.049025, loss_ce: 0.019168
2022-01-08 10:41:42,502 iteration 1128 : loss : 0.054690, loss_ce: 0.015481
2022-01-08 10:41:44,826 iteration 1129 : loss : 0.030482, loss_ce: 0.010595
2022-01-08 10:41:47,292 iteration 1130 : loss : 0.052380, loss_ce: 0.025427
2022-01-08 10:41:49,758 iteration 1131 : loss : 0.090884, loss_ce: 0.024553
2022-01-08 10:41:52,116 iteration 1132 : loss : 0.058530, loss_ce: 0.023332
2022-01-08 10:41:54,410 iteration 1133 : loss : 0.061348, loss_ce: 0.023908
2022-01-08 10:41:56,735 iteration 1134 : loss : 0.069901, loss_ce: 0.030246
2022-01-08 10:41:59,041 iteration 1135 : loss : 0.043534, loss_ce: 0.013886
2022-01-08 10:42:01,439 iteration 1136 : loss : 0.046040, loss_ce: 0.017738
2022-01-08 10:42:03,851 iteration 1137 : loss : 0.046258, loss_ce: 0.015511
2022-01-08 10:42:06,287 iteration 1138 : loss : 0.041183, loss_ce: 0.018075
2022-01-08 10:42:08,653 iteration 1139 : loss : 0.085099, loss_ce: 0.036219
 17%|█████                         | 67/400 [48:23<3:58:23, 42.95s/it]2022-01-08 10:42:10,977 iteration 1140 : loss : 0.040360, loss_ce: 0.015339
2022-01-08 10:42:13,341 iteration 1141 : loss : 0.060552, loss_ce: 0.024897
2022-01-08 10:42:15,688 iteration 1142 : loss : 0.036173, loss_ce: 0.014174
2022-01-08 10:42:18,159 iteration 1143 : loss : 0.092717, loss_ce: 0.029559
2022-01-08 10:42:20,560 iteration 1144 : loss : 0.055107, loss_ce: 0.020523
2022-01-08 10:42:22,834 iteration 1145 : loss : 0.051515, loss_ce: 0.016761
2022-01-08 10:42:25,262 iteration 1146 : loss : 0.053147, loss_ce: 0.024574
2022-01-08 10:42:27,565 iteration 1147 : loss : 0.042538, loss_ce: 0.016253
2022-01-08 10:42:29,895 iteration 1148 : loss : 0.043664, loss_ce: 0.016862
2022-01-08 10:42:32,212 iteration 1149 : loss : 0.052609, loss_ce: 0.024513
2022-01-08 10:42:34,542 iteration 1150 : loss : 0.051507, loss_ce: 0.022796
2022-01-08 10:42:36,957 iteration 1151 : loss : 0.043274, loss_ce: 0.012136
2022-01-08 10:42:39,404 iteration 1152 : loss : 0.107114, loss_ce: 0.021322
2022-01-08 10:42:41,763 iteration 1153 : loss : 0.035948, loss_ce: 0.012893
2022-01-08 10:42:44,032 iteration 1154 : loss : 0.061672, loss_ce: 0.028573
2022-01-08 10:42:46,528 iteration 1155 : loss : 0.063526, loss_ce: 0.021944
2022-01-08 10:42:48,885 iteration 1156 : loss : 0.079599, loss_ce: 0.023409
 17%|█████                         | 68/400 [49:03<3:53:08, 42.13s/it]2022-01-08 10:42:51,187 iteration 1157 : loss : 0.040705, loss_ce: 0.015445
2022-01-08 10:42:53,504 iteration 1158 : loss : 0.049970, loss_ce: 0.015756
2022-01-08 10:42:55,796 iteration 1159 : loss : 0.051220, loss_ce: 0.019344
2022-01-08 10:42:58,104 iteration 1160 : loss : 0.057467, loss_ce: 0.027941
2022-01-08 10:43:00,506 iteration 1161 : loss : 0.056237, loss_ce: 0.019027
2022-01-08 10:43:02,924 iteration 1162 : loss : 0.067523, loss_ce: 0.019053
2022-01-08 10:43:05,407 iteration 1163 : loss : 0.099279, loss_ce: 0.030611
2022-01-08 10:43:07,826 iteration 1164 : loss : 0.056050, loss_ce: 0.022375
2022-01-08 10:43:10,136 iteration 1165 : loss : 0.065253, loss_ce: 0.030177
2022-01-08 10:43:12,439 iteration 1166 : loss : 0.049334, loss_ce: 0.022778
2022-01-08 10:43:14,819 iteration 1167 : loss : 0.055173, loss_ce: 0.023933
2022-01-08 10:43:17,059 iteration 1168 : loss : 0.055834, loss_ce: 0.023959
2022-01-08 10:43:19,399 iteration 1169 : loss : 0.061508, loss_ce: 0.020149
2022-01-08 10:43:21,781 iteration 1170 : loss : 0.044104, loss_ce: 0.015514
2022-01-08 10:43:24,236 iteration 1171 : loss : 0.042077, loss_ce: 0.017038
2022-01-08 10:43:26,615 iteration 1172 : loss : 0.052048, loss_ce: 0.021343
2022-01-08 10:43:28,938 iteration 1173 : loss : 0.068829, loss_ce: 0.048582
 17%|█████▏                        | 69/400 [49:43<3:49:00, 41.51s/it]2022-01-08 10:43:31,309 iteration 1174 : loss : 0.044888, loss_ce: 0.014384
2022-01-08 10:43:33,675 iteration 1175 : loss : 0.047049, loss_ce: 0.018725
2022-01-08 10:43:36,019 iteration 1176 : loss : 0.079050, loss_ce: 0.037044
2022-01-08 10:43:38,420 iteration 1177 : loss : 0.053459, loss_ce: 0.022333
2022-01-08 10:43:40,823 iteration 1178 : loss : 0.072905, loss_ce: 0.032625
2022-01-08 10:43:43,124 iteration 1179 : loss : 0.036009, loss_ce: 0.016175
2022-01-08 10:43:45,557 iteration 1180 : loss : 0.048300, loss_ce: 0.017527
2022-01-08 10:43:47,909 iteration 1181 : loss : 0.034342, loss_ce: 0.015206
2022-01-08 10:43:50,339 iteration 1182 : loss : 0.053873, loss_ce: 0.023052
2022-01-08 10:43:52,636 iteration 1183 : loss : 0.043506, loss_ce: 0.017864
2022-01-08 10:43:54,838 iteration 1184 : loss : 0.036345, loss_ce: 0.016611
2022-01-08 10:43:57,171 iteration 1185 : loss : 0.070342, loss_ce: 0.025888
2022-01-08 10:43:59,483 iteration 1186 : loss : 0.051711, loss_ce: 0.019191
2022-01-08 10:44:01,886 iteration 1187 : loss : 0.046539, loss_ce: 0.016949
2022-01-08 10:44:04,260 iteration 1188 : loss : 0.035707, loss_ce: 0.012072
2022-01-08 10:44:06,614 iteration 1189 : loss : 0.039856, loss_ce: 0.014112
2022-01-08 10:44:06,615 Training Data Eval:
2022-01-08 10:44:19,254   Average segmentation loss on training set: 0.1187
2022-01-08 10:44:19,255 Validation Data Eval:
2022-01-08 10:44:23,888   Average segmentation loss on validation set: 0.3156
2022-01-08 10:44:26,325 iteration 1190 : loss : 0.042158, loss_ce: 0.016747
 18%|█████▎                        | 70/400 [50:41<4:14:29, 46.27s/it]2022-01-08 10:44:28,737 iteration 1191 : loss : 0.046099, loss_ce: 0.023934
2022-01-08 10:44:31,013 iteration 1192 : loss : 0.040520, loss_ce: 0.016776
2022-01-08 10:44:33,358 iteration 1193 : loss : 0.048048, loss_ce: 0.013539
2022-01-08 10:44:35,633 iteration 1194 : loss : 0.056026, loss_ce: 0.018539
2022-01-08 10:44:38,073 iteration 1195 : loss : 0.049317, loss_ce: 0.015639
2022-01-08 10:44:40,365 iteration 1196 : loss : 0.046534, loss_ce: 0.014931
2022-01-08 10:44:42,739 iteration 1197 : loss : 0.053050, loss_ce: 0.028829
2022-01-08 10:44:45,042 iteration 1198 : loss : 0.058641, loss_ce: 0.036577
2022-01-08 10:44:47,325 iteration 1199 : loss : 0.050372, loss_ce: 0.019475
2022-01-08 10:44:49,685 iteration 1200 : loss : 0.051994, loss_ce: 0.018995
2022-01-08 10:44:52,074 iteration 1201 : loss : 0.031463, loss_ce: 0.013731
2022-01-08 10:44:54,424 iteration 1202 : loss : 0.035596, loss_ce: 0.015369
2022-01-08 10:44:56,761 iteration 1203 : loss : 0.045559, loss_ce: 0.015789
2022-01-08 10:44:59,075 iteration 1204 : loss : 0.037822, loss_ce: 0.016545
2022-01-08 10:45:01,444 iteration 1205 : loss : 0.045904, loss_ce: 0.025739
2022-01-08 10:45:03,892 iteration 1206 : loss : 0.079092, loss_ce: 0.021618
2022-01-08 10:45:06,206 iteration 1207 : loss : 0.048527, loss_ce: 0.015434
 18%|█████▎                        | 71/400 [51:20<4:03:12, 44.35s/it]2022-01-08 10:45:08,555 iteration 1208 : loss : 0.040686, loss_ce: 0.020533
2022-01-08 10:45:10,955 iteration 1209 : loss : 0.059612, loss_ce: 0.018647
2022-01-08 10:45:13,218 iteration 1210 : loss : 0.039270, loss_ce: 0.011463
2022-01-08 10:45:15,690 iteration 1211 : loss : 0.056539, loss_ce: 0.018886
2022-01-08 10:45:18,030 iteration 1212 : loss : 0.033749, loss_ce: 0.014237
2022-01-08 10:45:20,399 iteration 1213 : loss : 0.074306, loss_ce: 0.019586
2022-01-08 10:45:23,042 iteration 1214 : loss : 0.044589, loss_ce: 0.019649
2022-01-08 10:45:25,475 iteration 1215 : loss : 0.053188, loss_ce: 0.023325
2022-01-08 10:45:27,817 iteration 1216 : loss : 0.040535, loss_ce: 0.015519
2022-01-08 10:45:30,194 iteration 1217 : loss : 0.041942, loss_ce: 0.018025
2022-01-08 10:45:32,665 iteration 1218 : loss : 0.031139, loss_ce: 0.014597
2022-01-08 10:45:35,171 iteration 1219 : loss : 0.065971, loss_ce: 0.022189
2022-01-08 10:45:37,618 iteration 1220 : loss : 0.051005, loss_ce: 0.018425
2022-01-08 10:45:40,148 iteration 1221 : loss : 0.042258, loss_ce: 0.018283
2022-01-08 10:45:42,747 iteration 1222 : loss : 0.058262, loss_ce: 0.021622
2022-01-08 10:45:45,128 iteration 1223 : loss : 0.035129, loss_ce: 0.014723
2022-01-08 10:45:47,500 iteration 1224 : loss : 0.046977, loss_ce: 0.019385
 18%|█████▍                        | 72/400 [52:02<3:57:26, 43.44s/it]2022-01-08 10:45:49,907 iteration 1225 : loss : 0.060839, loss_ce: 0.021620
2022-01-08 10:45:52,327 iteration 1226 : loss : 0.046439, loss_ce: 0.018066
2022-01-08 10:45:54,702 iteration 1227 : loss : 0.039376, loss_ce: 0.012376
2022-01-08 10:45:57,205 iteration 1228 : loss : 0.072130, loss_ce: 0.022907
2022-01-08 10:45:59,784 iteration 1229 : loss : 0.045642, loss_ce: 0.018791
2022-01-08 10:46:02,229 iteration 1230 : loss : 0.039995, loss_ce: 0.015959
2022-01-08 10:46:04,587 iteration 1231 : loss : 0.067046, loss_ce: 0.022280
2022-01-08 10:46:07,015 iteration 1232 : loss : 0.037709, loss_ce: 0.015418
2022-01-08 10:46:09,612 iteration 1233 : loss : 0.049188, loss_ce: 0.019790
2022-01-08 10:46:12,109 iteration 1234 : loss : 0.057917, loss_ce: 0.023071
2022-01-08 10:46:14,506 iteration 1235 : loss : 0.052060, loss_ce: 0.024277
2022-01-08 10:46:17,074 iteration 1236 : loss : 0.035135, loss_ce: 0.012738
2022-01-08 10:46:19,575 iteration 1237 : loss : 0.036521, loss_ce: 0.012058
2022-01-08 10:46:21,959 iteration 1238 : loss : 0.049994, loss_ce: 0.021502
2022-01-08 10:46:24,391 iteration 1239 : loss : 0.045043, loss_ce: 0.015113
2022-01-08 10:46:26,676 iteration 1240 : loss : 0.030248, loss_ce: 0.011403
2022-01-08 10:46:29,106 iteration 1241 : loss : 0.036973, loss_ce: 0.016192
 18%|█████▍                        | 73/400 [52:43<3:53:44, 42.89s/it]2022-01-08 10:46:31,364 iteration 1242 : loss : 0.037348, loss_ce: 0.014758
2022-01-08 10:46:33,595 iteration 1243 : loss : 0.030762, loss_ce: 0.013732
2022-01-08 10:46:35,927 iteration 1244 : loss : 0.045491, loss_ce: 0.016433
2022-01-08 10:46:38,292 iteration 1245 : loss : 0.041137, loss_ce: 0.016873
2022-01-08 10:46:40,643 iteration 1246 : loss : 0.059505, loss_ce: 0.022931
2022-01-08 10:46:42,957 iteration 1247 : loss : 0.058590, loss_ce: 0.018867
2022-01-08 10:46:45,296 iteration 1248 : loss : 0.037982, loss_ce: 0.013206
2022-01-08 10:46:47,623 iteration 1249 : loss : 0.039649, loss_ce: 0.013613
2022-01-08 10:46:49,957 iteration 1250 : loss : 0.048558, loss_ce: 0.016963
2022-01-08 10:46:52,381 iteration 1251 : loss : 0.033514, loss_ce: 0.013563
2022-01-08 10:46:54,768 iteration 1252 : loss : 0.055932, loss_ce: 0.013439
2022-01-08 10:46:57,198 iteration 1253 : loss : 0.038686, loss_ce: 0.015698
2022-01-08 10:46:59,566 iteration 1254 : loss : 0.052683, loss_ce: 0.026089
2022-01-08 10:47:01,913 iteration 1255 : loss : 0.035291, loss_ce: 0.014599
2022-01-08 10:47:04,237 iteration 1256 : loss : 0.066540, loss_ce: 0.021700
2022-01-08 10:47:06,543 iteration 1257 : loss : 0.041161, loss_ce: 0.018109
2022-01-08 10:47:08,948 iteration 1258 : loss : 0.047389, loss_ce: 0.020915
 18%|█████▌                        | 74/400 [53:23<3:48:04, 41.98s/it]2022-01-08 10:47:11,403 iteration 1259 : loss : 0.049183, loss_ce: 0.017162
2022-01-08 10:47:13,812 iteration 1260 : loss : 0.043985, loss_ce: 0.012532
2022-01-08 10:47:16,188 iteration 1261 : loss : 0.041685, loss_ce: 0.017330
2022-01-08 10:47:18,461 iteration 1262 : loss : 0.028939, loss_ce: 0.012625
2022-01-08 10:47:20,824 iteration 1263 : loss : 0.040590, loss_ce: 0.015561
2022-01-08 10:47:23,048 iteration 1264 : loss : 0.041904, loss_ce: 0.019504
2022-01-08 10:47:25,377 iteration 1265 : loss : 0.040388, loss_ce: 0.015189
2022-01-08 10:47:27,648 iteration 1266 : loss : 0.036967, loss_ce: 0.016714
2022-01-08 10:47:30,106 iteration 1267 : loss : 0.041790, loss_ce: 0.016265
2022-01-08 10:47:32,401 iteration 1268 : loss : 0.107453, loss_ce: 0.031041
2022-01-08 10:47:34,779 iteration 1269 : loss : 0.050202, loss_ce: 0.016856
2022-01-08 10:47:37,138 iteration 1270 : loss : 0.045885, loss_ce: 0.015954
2022-01-08 10:47:39,486 iteration 1271 : loss : 0.032475, loss_ce: 0.012177
2022-01-08 10:47:41,861 iteration 1272 : loss : 0.057668, loss_ce: 0.025316
2022-01-08 10:47:44,294 iteration 1273 : loss : 0.051294, loss_ce: 0.026352
2022-01-08 10:47:46,693 iteration 1274 : loss : 0.040565, loss_ce: 0.013634
2022-01-08 10:47:46,693 Training Data Eval:
2022-01-08 10:47:59,606   Average segmentation loss on training set: 0.0520
2022-01-08 10:47:59,607 Validation Data Eval:
2022-01-08 10:48:04,148   Average segmentation loss on validation set: 0.1769
2022-01-08 10:48:06,547 iteration 1275 : loss : 0.048461, loss_ce: 0.013848
 19%|█████▋                        | 75/400 [54:21<4:12:46, 46.67s/it]2022-01-08 10:48:09,096 iteration 1276 : loss : 0.065188, loss_ce: 0.016714
2022-01-08 10:48:11,398 iteration 1277 : loss : 0.037824, loss_ce: 0.015197
2022-01-08 10:48:13,694 iteration 1278 : loss : 0.039463, loss_ce: 0.018126
2022-01-08 10:48:15,945 iteration 1279 : loss : 0.046705, loss_ce: 0.024352
2022-01-08 10:48:18,228 iteration 1280 : loss : 0.046706, loss_ce: 0.022370
2022-01-08 10:48:20,581 iteration 1281 : loss : 0.055375, loss_ce: 0.024363
2022-01-08 10:48:22,828 iteration 1282 : loss : 0.059708, loss_ce: 0.031442
2022-01-08 10:48:25,061 iteration 1283 : loss : 0.042902, loss_ce: 0.017247
2022-01-08 10:48:27,406 iteration 1284 : loss : 0.054107, loss_ce: 0.021840
2022-01-08 10:48:29,969 iteration 1285 : loss : 0.062973, loss_ce: 0.021378
2022-01-08 10:48:32,314 iteration 1286 : loss : 0.044258, loss_ce: 0.015507
2022-01-08 10:48:34,579 iteration 1287 : loss : 0.051997, loss_ce: 0.017499
2022-01-08 10:48:36,978 iteration 1288 : loss : 0.044095, loss_ce: 0.016438
2022-01-08 10:48:39,393 iteration 1289 : loss : 0.055705, loss_ce: 0.021949
2022-01-08 10:48:41,718 iteration 1290 : loss : 0.056399, loss_ce: 0.018432
2022-01-08 10:48:44,108 iteration 1291 : loss : 0.038256, loss_ce: 0.013061
2022-01-08 10:48:46,408 iteration 1292 : loss : 0.030259, loss_ce: 0.012053
 19%|█████▋                        | 76/400 [55:01<4:00:55, 44.62s/it]2022-01-08 10:48:48,842 iteration 1293 : loss : 0.041373, loss_ce: 0.019258
2022-01-08 10:48:51,188 iteration 1294 : loss : 0.039619, loss_ce: 0.016998
2022-01-08 10:48:53,540 iteration 1295 : loss : 0.037616, loss_ce: 0.015383
2022-01-08 10:48:55,838 iteration 1296 : loss : 0.039197, loss_ce: 0.013298
2022-01-08 10:48:58,159 iteration 1297 : loss : 0.044780, loss_ce: 0.018068
2022-01-08 10:49:00,482 iteration 1298 : loss : 0.030252, loss_ce: 0.012758
2022-01-08 10:49:02,768 iteration 1299 : loss : 0.046154, loss_ce: 0.015556
2022-01-08 10:49:05,108 iteration 1300 : loss : 0.044190, loss_ce: 0.010973
2022-01-08 10:49:07,485 iteration 1301 : loss : 0.050274, loss_ce: 0.024074
2022-01-08 10:49:09,952 iteration 1302 : loss : 0.061676, loss_ce: 0.020249
2022-01-08 10:49:12,299 iteration 1303 : loss : 0.043844, loss_ce: 0.018004
2022-01-08 10:49:14,728 iteration 1304 : loss : 0.055835, loss_ce: 0.016130
2022-01-08 10:49:17,080 iteration 1305 : loss : 0.036425, loss_ce: 0.015578
2022-01-08 10:49:19,402 iteration 1306 : loss : 0.063521, loss_ce: 0.025252
2022-01-08 10:49:21,693 iteration 1307 : loss : 0.044818, loss_ce: 0.017806
2022-01-08 10:49:23,899 iteration 1308 : loss : 0.052383, loss_ce: 0.029105
2022-01-08 10:49:26,158 iteration 1309 : loss : 0.041589, loss_ce: 0.017746
 19%|█████▊                        | 77/400 [55:40<3:52:19, 43.16s/it]2022-01-08 10:49:28,580 iteration 1310 : loss : 0.039478, loss_ce: 0.016086
2022-01-08 10:49:30,941 iteration 1311 : loss : 0.042365, loss_ce: 0.014962
2022-01-08 10:49:33,233 iteration 1312 : loss : 0.048842, loss_ce: 0.024707
2022-01-08 10:49:35,420 iteration 1313 : loss : 0.033268, loss_ce: 0.014321
2022-01-08 10:49:37,638 iteration 1314 : loss : 0.033699, loss_ce: 0.014192
2022-01-08 10:49:39,891 iteration 1315 : loss : 0.048469, loss_ce: 0.022682
2022-01-08 10:49:42,116 iteration 1316 : loss : 0.043509, loss_ce: 0.018891
2022-01-08 10:49:44,448 iteration 1317 : loss : 0.040032, loss_ce: 0.019753
2022-01-08 10:49:46,820 iteration 1318 : loss : 0.051153, loss_ce: 0.019971
2022-01-08 10:49:49,143 iteration 1319 : loss : 0.043085, loss_ce: 0.013811
2022-01-08 10:49:51,447 iteration 1320 : loss : 0.042117, loss_ce: 0.015456
2022-01-08 10:49:53,789 iteration 1321 : loss : 0.050613, loss_ce: 0.019354
2022-01-08 10:49:56,153 iteration 1322 : loss : 0.054126, loss_ce: 0.020167
2022-01-08 10:49:58,373 iteration 1323 : loss : 0.035816, loss_ce: 0.013962
2022-01-08 10:50:00,603 iteration 1324 : loss : 0.044602, loss_ce: 0.014586
2022-01-08 10:50:02,903 iteration 1325 : loss : 0.053476, loss_ce: 0.018053
2022-01-08 10:50:05,117 iteration 1326 : loss : 0.048193, loss_ce: 0.017167
 20%|█████▊                        | 78/400 [56:19<3:44:53, 41.90s/it]2022-01-08 10:50:07,517 iteration 1327 : loss : 0.047284, loss_ce: 0.024456
2022-01-08 10:50:10,021 iteration 1328 : loss : 0.051863, loss_ce: 0.017119
2022-01-08 10:50:12,377 iteration 1329 : loss : 0.045432, loss_ce: 0.021660
2022-01-08 10:50:14,711 iteration 1330 : loss : 0.051117, loss_ce: 0.019335
2022-01-08 10:50:17,019 iteration 1331 : loss : 0.040559, loss_ce: 0.012796
2022-01-08 10:50:19,352 iteration 1332 : loss : 0.028859, loss_ce: 0.011825
2022-01-08 10:50:21,662 iteration 1333 : loss : 0.062541, loss_ce: 0.012973
2022-01-08 10:50:24,025 iteration 1334 : loss : 0.034270, loss_ce: 0.013140
2022-01-08 10:50:26,461 iteration 1335 : loss : 0.043607, loss_ce: 0.013607
2022-01-08 10:50:28,742 iteration 1336 : loss : 0.040661, loss_ce: 0.016864
2022-01-08 10:50:31,115 iteration 1337 : loss : 0.043822, loss_ce: 0.020119
2022-01-08 10:50:33,422 iteration 1338 : loss : 0.048070, loss_ce: 0.018254
2022-01-08 10:50:35,685 iteration 1339 : loss : 0.047047, loss_ce: 0.018940
2022-01-08 10:50:37,926 iteration 1340 : loss : 0.033955, loss_ce: 0.011373
2022-01-08 10:50:40,217 iteration 1341 : loss : 0.047425, loss_ce: 0.018197
2022-01-08 10:50:42,465 iteration 1342 : loss : 0.046942, loss_ce: 0.013911
2022-01-08 10:50:44,798 iteration 1343 : loss : 0.035677, loss_ce: 0.013010
 20%|█████▉                        | 79/400 [56:59<3:40:36, 41.24s/it]2022-01-08 10:50:47,156 iteration 1344 : loss : 0.033464, loss_ce: 0.013446
2022-01-08 10:50:49,496 iteration 1345 : loss : 0.036639, loss_ce: 0.016549
2022-01-08 10:50:51,743 iteration 1346 : loss : 0.038092, loss_ce: 0.014399
2022-01-08 10:50:54,069 iteration 1347 : loss : 0.084939, loss_ce: 0.019118
2022-01-08 10:50:56,362 iteration 1348 : loss : 0.038829, loss_ce: 0.015213
2022-01-08 10:50:58,668 iteration 1349 : loss : 0.052516, loss_ce: 0.021907
2022-01-08 10:51:01,002 iteration 1350 : loss : 0.058836, loss_ce: 0.023990
2022-01-08 10:51:03,262 iteration 1351 : loss : 0.050186, loss_ce: 0.019630
2022-01-08 10:51:05,698 iteration 1352 : loss : 0.038086, loss_ce: 0.015062
2022-01-08 10:51:08,053 iteration 1353 : loss : 0.042673, loss_ce: 0.018780
2022-01-08 10:51:10,430 iteration 1354 : loss : 0.031484, loss_ce: 0.013087
2022-01-08 10:51:12,668 iteration 1355 : loss : 0.065405, loss_ce: 0.018827
2022-01-08 10:51:14,934 iteration 1356 : loss : 0.055200, loss_ce: 0.018629
2022-01-08 10:51:17,127 iteration 1357 : loss : 0.042618, loss_ce: 0.026600
2022-01-08 10:51:19,472 iteration 1358 : loss : 0.038514, loss_ce: 0.011747
2022-01-08 10:51:21,716 iteration 1359 : loss : 0.060913, loss_ce: 0.039514
2022-01-08 10:51:21,717 Training Data Eval:
2022-01-08 10:51:34,410   Average segmentation loss on training set: 0.1028
2022-01-08 10:51:34,411 Validation Data Eval:
2022-01-08 10:51:39,009   Average segmentation loss on validation set: 0.2601
2022-01-08 10:51:41,412 iteration 1360 : loss : 0.045327, loss_ce: 0.015715
 20%|██████                        | 80/400 [57:56<4:04:31, 45.85s/it]2022-01-08 10:51:43,875 iteration 1361 : loss : 0.067210, loss_ce: 0.019779
2022-01-08 10:51:46,198 iteration 1362 : loss : 0.046506, loss_ce: 0.020839
2022-01-08 10:51:48,580 iteration 1363 : loss : 0.046423, loss_ce: 0.017392
2022-01-08 10:51:50,995 iteration 1364 : loss : 0.054152, loss_ce: 0.016733
2022-01-08 10:51:53,347 iteration 1365 : loss : 0.041677, loss_ce: 0.016972
2022-01-08 10:51:55,590 iteration 1366 : loss : 0.040452, loss_ce: 0.016992
2022-01-08 10:51:57,936 iteration 1367 : loss : 0.035275, loss_ce: 0.015859
2022-01-08 10:52:00,284 iteration 1368 : loss : 0.055836, loss_ce: 0.026866
2022-01-08 10:52:02,695 iteration 1369 : loss : 0.051361, loss_ce: 0.015215
2022-01-08 10:52:05,092 iteration 1370 : loss : 0.055588, loss_ce: 0.016421
2022-01-08 10:52:07,383 iteration 1371 : loss : 0.032483, loss_ce: 0.013278
2022-01-08 10:52:09,786 iteration 1372 : loss : 0.078113, loss_ce: 0.024181
2022-01-08 10:52:12,184 iteration 1373 : loss : 0.055119, loss_ce: 0.031970
2022-01-08 10:52:14,441 iteration 1374 : loss : 0.040906, loss_ce: 0.013875
2022-01-08 10:52:16,762 iteration 1375 : loss : 0.040114, loss_ce: 0.013346
2022-01-08 10:52:19,085 iteration 1376 : loss : 0.032271, loss_ce: 0.012908
2022-01-08 10:52:21,508 iteration 1377 : loss : 0.065613, loss_ce: 0.024145
 20%|██████                        | 81/400 [58:36<3:54:35, 44.12s/it]2022-01-08 10:52:24,010 iteration 1378 : loss : 0.044120, loss_ce: 0.021102
2022-01-08 10:52:26,378 iteration 1379 : loss : 0.052140, loss_ce: 0.012356
2022-01-08 10:52:28,684 iteration 1380 : loss : 0.033677, loss_ce: 0.014523
2022-01-08 10:52:31,011 iteration 1381 : loss : 0.039924, loss_ce: 0.016371
2022-01-08 10:52:33,263 iteration 1382 : loss : 0.032403, loss_ce: 0.013088
2022-01-08 10:52:35,592 iteration 1383 : loss : 0.062036, loss_ce: 0.019369
2022-01-08 10:52:37,985 iteration 1384 : loss : 0.067800, loss_ce: 0.030050
2022-01-08 10:52:40,243 iteration 1385 : loss : 0.031524, loss_ce: 0.011464
2022-01-08 10:52:42,767 iteration 1386 : loss : 0.042538, loss_ce: 0.018557
2022-01-08 10:52:45,124 iteration 1387 : loss : 0.076892, loss_ce: 0.022414
2022-01-08 10:52:47,524 iteration 1388 : loss : 0.051886, loss_ce: 0.015714
2022-01-08 10:52:49,830 iteration 1389 : loss : 0.057497, loss_ce: 0.030462
2022-01-08 10:52:52,081 iteration 1390 : loss : 0.036944, loss_ce: 0.017179
2022-01-08 10:52:54,460 iteration 1391 : loss : 0.063760, loss_ce: 0.018427
2022-01-08 10:52:56,927 iteration 1392 : loss : 0.065694, loss_ce: 0.035041
2022-01-08 10:52:59,362 iteration 1393 : loss : 0.092601, loss_ce: 0.027079
2022-01-08 10:53:01,771 iteration 1394 : loss : 0.036023, loss_ce: 0.010184
 20%|██████▏                       | 82/400 [59:16<3:47:42, 42.96s/it]2022-01-08 10:53:04,203 iteration 1395 : loss : 0.048972, loss_ce: 0.027427
2022-01-08 10:53:06,715 iteration 1396 : loss : 0.040759, loss_ce: 0.018688
2022-01-08 10:53:09,158 iteration 1397 : loss : 0.036805, loss_ce: 0.015336
2022-01-08 10:53:11,377 iteration 1398 : loss : 0.029118, loss_ce: 0.011836
2022-01-08 10:53:13,657 iteration 1399 : loss : 0.034028, loss_ce: 0.014304
2022-01-08 10:53:16,028 iteration 1400 : loss : 0.078227, loss_ce: 0.032581
2022-01-08 10:53:18,358 iteration 1401 : loss : 0.042759, loss_ce: 0.015766
2022-01-08 10:53:20,692 iteration 1402 : loss : 0.050899, loss_ce: 0.019923
2022-01-08 10:53:23,000 iteration 1403 : loss : 0.059138, loss_ce: 0.017763
2022-01-08 10:53:25,471 iteration 1404 : loss : 0.039538, loss_ce: 0.016803
2022-01-08 10:53:27,743 iteration 1405 : loss : 0.028873, loss_ce: 0.011164
2022-01-08 10:53:30,118 iteration 1406 : loss : 0.040721, loss_ce: 0.013944
2022-01-08 10:53:32,419 iteration 1407 : loss : 0.044030, loss_ce: 0.018070
2022-01-08 10:53:34,779 iteration 1408 : loss : 0.053608, loss_ce: 0.028122
2022-01-08 10:53:37,212 iteration 1409 : loss : 0.081679, loss_ce: 0.025000
2022-01-08 10:53:39,460 iteration 1410 : loss : 0.053463, loss_ce: 0.019654
2022-01-08 10:53:41,780 iteration 1411 : loss : 0.029541, loss_ce: 0.011344
 21%|██████▏                       | 83/400 [59:56<3:42:18, 42.08s/it]2022-01-08 10:53:44,258 iteration 1412 : loss : 0.037774, loss_ce: 0.017638
2022-01-08 10:53:46,608 iteration 1413 : loss : 0.036503, loss_ce: 0.013430
2022-01-08 10:53:49,022 iteration 1414 : loss : 0.033193, loss_ce: 0.014900
2022-01-08 10:53:51,304 iteration 1415 : loss : 0.038528, loss_ce: 0.014885
2022-01-08 10:53:53,627 iteration 1416 : loss : 0.042789, loss_ce: 0.014384
2022-01-08 10:53:56,067 iteration 1417 : loss : 0.072435, loss_ce: 0.027198
2022-01-08 10:53:58,455 iteration 1418 : loss : 0.045412, loss_ce: 0.013840
2022-01-08 10:54:00,747 iteration 1419 : loss : 0.039161, loss_ce: 0.017444
2022-01-08 10:54:03,124 iteration 1420 : loss : 0.042001, loss_ce: 0.011194
2022-01-08 10:54:05,501 iteration 1421 : loss : 0.058363, loss_ce: 0.032965
2022-01-08 10:54:07,901 iteration 1422 : loss : 0.041727, loss_ce: 0.018670
2022-01-08 10:54:10,207 iteration 1423 : loss : 0.039306, loss_ce: 0.012110
2022-01-08 10:54:12,480 iteration 1424 : loss : 0.027216, loss_ce: 0.010695
2022-01-08 10:54:14,877 iteration 1425 : loss : 0.054106, loss_ce: 0.016901
2022-01-08 10:54:17,234 iteration 1426 : loss : 0.050762, loss_ce: 0.026574
2022-01-08 10:54:19,680 iteration 1427 : loss : 0.077763, loss_ce: 0.015655
2022-01-08 10:54:22,191 iteration 1428 : loss : 0.065504, loss_ce: 0.023225
 21%|█████▉                      | 84/400 [1:00:36<3:38:58, 41.58s/it]2022-01-08 10:54:24,587 iteration 1429 : loss : 0.057396, loss_ce: 0.027194
2022-01-08 10:54:26,846 iteration 1430 : loss : 0.033182, loss_ce: 0.012576
2022-01-08 10:54:29,182 iteration 1431 : loss : 0.041420, loss_ce: 0.014285
2022-01-08 10:54:31,560 iteration 1432 : loss : 0.040623, loss_ce: 0.016013
2022-01-08 10:54:33,838 iteration 1433 : loss : 0.031834, loss_ce: 0.013886
2022-01-08 10:54:36,202 iteration 1434 : loss : 0.040563, loss_ce: 0.016447
2022-01-08 10:54:38,628 iteration 1435 : loss : 0.071012, loss_ce: 0.024954
2022-01-08 10:54:41,028 iteration 1436 : loss : 0.044459, loss_ce: 0.021802
2022-01-08 10:54:43,383 iteration 1437 : loss : 0.037146, loss_ce: 0.016357
2022-01-08 10:54:45,888 iteration 1438 : loss : 0.049936, loss_ce: 0.019697
2022-01-08 10:54:48,323 iteration 1439 : loss : 0.066344, loss_ce: 0.025880
2022-01-08 10:54:50,730 iteration 1440 : loss : 0.042039, loss_ce: 0.013259
2022-01-08 10:54:53,134 iteration 1441 : loss : 0.039051, loss_ce: 0.015166
2022-01-08 10:54:55,533 iteration 1442 : loss : 0.042236, loss_ce: 0.012540
2022-01-08 10:54:57,971 iteration 1443 : loss : 0.045337, loss_ce: 0.016800
2022-01-08 10:55:00,339 iteration 1444 : loss : 0.046177, loss_ce: 0.011410
2022-01-08 10:55:00,340 Training Data Eval:
2022-01-08 10:55:13,151   Average segmentation loss on training set: 0.0303
2022-01-08 10:55:13,152 Validation Data Eval:
2022-01-08 10:55:17,817   Average segmentation loss on validation set: 0.0922
2022-01-08 10:55:20,341 iteration 1445 : loss : 0.051848, loss_ce: 0.021009
 21%|█████▉                      | 85/400 [1:01:35<4:04:22, 46.55s/it]2022-01-08 10:55:22,737 iteration 1446 : loss : 0.031680, loss_ce: 0.011204
2022-01-08 10:55:25,038 iteration 1447 : loss : 0.028963, loss_ce: 0.012822
2022-01-08 10:55:27,395 iteration 1448 : loss : 0.047107, loss_ce: 0.012954
2022-01-08 10:55:29,797 iteration 1449 : loss : 0.045336, loss_ce: 0.014633
2022-01-08 10:55:32,191 iteration 1450 : loss : 0.040829, loss_ce: 0.014559
2022-01-08 10:55:34,794 iteration 1451 : loss : 0.038655, loss_ce: 0.011726
2022-01-08 10:55:37,204 iteration 1452 : loss : 0.053093, loss_ce: 0.028580
2022-01-08 10:55:39,604 iteration 1453 : loss : 0.042461, loss_ce: 0.018740
2022-01-08 10:55:41,947 iteration 1454 : loss : 0.068134, loss_ce: 0.030621
2022-01-08 10:55:44,362 iteration 1455 : loss : 0.055289, loss_ce: 0.022154
2022-01-08 10:55:46,686 iteration 1456 : loss : 0.042233, loss_ce: 0.011955
2022-01-08 10:55:49,131 iteration 1457 : loss : 0.048352, loss_ce: 0.018635
2022-01-08 10:55:51,509 iteration 1458 : loss : 0.029122, loss_ce: 0.011573
2022-01-08 10:55:53,787 iteration 1459 : loss : 0.030894, loss_ce: 0.010264
2022-01-08 10:55:56,101 iteration 1460 : loss : 0.041078, loss_ce: 0.015906
2022-01-08 10:55:58,439 iteration 1461 : loss : 0.046116, loss_ce: 0.017042
2022-01-08 10:56:00,868 iteration 1462 : loss : 0.038743, loss_ce: 0.015667
 22%|██████                      | 86/400 [1:02:15<3:54:09, 44.74s/it]2022-01-08 10:56:03,433 iteration 1463 : loss : 0.109750, loss_ce: 0.031636
2022-01-08 10:56:05,813 iteration 1464 : loss : 0.046169, loss_ce: 0.023352
2022-01-08 10:56:08,291 iteration 1465 : loss : 0.049774, loss_ce: 0.014648
2022-01-08 10:56:10,596 iteration 1466 : loss : 0.036909, loss_ce: 0.013662
2022-01-08 10:56:12,953 iteration 1467 : loss : 0.037063, loss_ce: 0.014740
2022-01-08 10:56:15,351 iteration 1468 : loss : 0.036300, loss_ce: 0.017294
2022-01-08 10:56:17,756 iteration 1469 : loss : 0.052447, loss_ce: 0.021131
2022-01-08 10:56:20,171 iteration 1470 : loss : 0.096558, loss_ce: 0.021752
2022-01-08 10:56:22,567 iteration 1471 : loss : 0.037293, loss_ce: 0.016296
2022-01-08 10:56:25,032 iteration 1472 : loss : 0.056712, loss_ce: 0.021216
2022-01-08 10:56:27,489 iteration 1473 : loss : 0.041522, loss_ce: 0.019395
2022-01-08 10:56:29,939 iteration 1474 : loss : 0.051450, loss_ce: 0.016540
2022-01-08 10:56:32,297 iteration 1475 : loss : 0.045094, loss_ce: 0.018956
2022-01-08 10:56:34,697 iteration 1476 : loss : 0.041991, loss_ce: 0.016492
2022-01-08 10:56:37,200 iteration 1477 : loss : 0.058652, loss_ce: 0.024298
2022-01-08 10:56:39,563 iteration 1478 : loss : 0.067390, loss_ce: 0.022328
2022-01-08 10:56:41,942 iteration 1479 : loss : 0.057182, loss_ce: 0.020215
 22%|██████                      | 87/400 [1:02:56<3:47:41, 43.65s/it]2022-01-08 10:56:44,280 iteration 1480 : loss : 0.032195, loss_ce: 0.011591
2022-01-08 10:56:46,946 iteration 1481 : loss : 0.047663, loss_ce: 0.019539
2022-01-08 10:56:49,353 iteration 1482 : loss : 0.040790, loss_ce: 0.015654
2022-01-08 10:56:51,860 iteration 1483 : loss : 0.039960, loss_ce: 0.015130
2022-01-08 10:56:54,304 iteration 1484 : loss : 0.048336, loss_ce: 0.015472
2022-01-08 10:56:56,784 iteration 1485 : loss : 0.027760, loss_ce: 0.013123
2022-01-08 10:56:59,239 iteration 1486 : loss : 0.038672, loss_ce: 0.014262
2022-01-08 10:57:01,721 iteration 1487 : loss : 0.028982, loss_ce: 0.010721
2022-01-08 10:57:04,151 iteration 1488 : loss : 0.035232, loss_ce: 0.015282
2022-01-08 10:57:06,553 iteration 1489 : loss : 0.045060, loss_ce: 0.020883
2022-01-08 10:57:08,984 iteration 1490 : loss : 0.042619, loss_ce: 0.015939
2022-01-08 10:57:11,289 iteration 1491 : loss : 0.046331, loss_ce: 0.013790
2022-01-08 10:57:13,707 iteration 1492 : loss : 0.043724, loss_ce: 0.018812
2022-01-08 10:57:16,147 iteration 1493 : loss : 0.036360, loss_ce: 0.016460
2022-01-08 10:57:18,561 iteration 1494 : loss : 0.049961, loss_ce: 0.014462
2022-01-08 10:57:20,964 iteration 1495 : loss : 0.034447, loss_ce: 0.009165
2022-01-08 10:57:23,580 iteration 1496 : loss : 0.060735, loss_ce: 0.027141
 22%|██████▏                     | 88/400 [1:03:38<3:43:48, 43.04s/it]2022-01-08 10:57:25,951 iteration 1497 : loss : 0.037124, loss_ce: 0.015475
2022-01-08 10:57:28,278 iteration 1498 : loss : 0.057357, loss_ce: 0.023351
2022-01-08 10:57:30,570 iteration 1499 : loss : 0.044845, loss_ce: 0.016747
2022-01-08 10:57:32,966 iteration 1500 : loss : 0.031723, loss_ce: 0.013615
2022-01-08 10:57:35,364 iteration 1501 : loss : 0.036521, loss_ce: 0.015974
2022-01-08 10:57:37,781 iteration 1502 : loss : 0.089053, loss_ce: 0.022702
2022-01-08 10:57:40,180 iteration 1503 : loss : 0.079111, loss_ce: 0.022252
2022-01-08 10:57:42,410 iteration 1504 : loss : 0.034712, loss_ce: 0.014197
2022-01-08 10:57:44,713 iteration 1505 : loss : 0.070752, loss_ce: 0.027941
2022-01-08 10:57:47,108 iteration 1506 : loss : 0.050012, loss_ce: 0.021750
2022-01-08 10:57:49,496 iteration 1507 : loss : 0.043813, loss_ce: 0.011372
2022-01-08 10:57:51,878 iteration 1508 : loss : 0.064752, loss_ce: 0.032232
2022-01-08 10:57:54,275 iteration 1509 : loss : 0.045213, loss_ce: 0.017514
2022-01-08 10:57:56,756 iteration 1510 : loss : 0.048766, loss_ce: 0.016151
2022-01-08 10:57:59,138 iteration 1511 : loss : 0.049160, loss_ce: 0.021280
2022-01-08 10:58:01,412 iteration 1512 : loss : 0.058074, loss_ce: 0.016553
2022-01-08 10:58:03,810 iteration 1513 : loss : 0.057916, loss_ce: 0.024202
 22%|██████▏                     | 89/400 [1:04:18<3:38:43, 42.20s/it]2022-01-08 10:58:06,229 iteration 1514 : loss : 0.037373, loss_ce: 0.013810
2022-01-08 10:58:08,549 iteration 1515 : loss : 0.046781, loss_ce: 0.020709
2022-01-08 10:58:10,924 iteration 1516 : loss : 0.061964, loss_ce: 0.021119
2022-01-08 10:58:13,411 iteration 1517 : loss : 0.032158, loss_ce: 0.012006
2022-01-08 10:58:15,909 iteration 1518 : loss : 0.033095, loss_ce: 0.012072
2022-01-08 10:58:18,357 iteration 1519 : loss : 0.046373, loss_ce: 0.016976
2022-01-08 10:58:20,715 iteration 1520 : loss : 0.051321, loss_ce: 0.020150
2022-01-08 10:58:22,985 iteration 1521 : loss : 0.058499, loss_ce: 0.015983
2022-01-08 10:58:25,286 iteration 1522 : loss : 0.034927, loss_ce: 0.013374
2022-01-08 10:58:27,649 iteration 1523 : loss : 0.043664, loss_ce: 0.014267
2022-01-08 10:58:30,035 iteration 1524 : loss : 0.037239, loss_ce: 0.013865
2022-01-08 10:58:32,351 iteration 1525 : loss : 0.046215, loss_ce: 0.020049
2022-01-08 10:58:34,772 iteration 1526 : loss : 0.043932, loss_ce: 0.020553
2022-01-08 10:58:37,131 iteration 1527 : loss : 0.037679, loss_ce: 0.018413
2022-01-08 10:58:39,439 iteration 1528 : loss : 0.039372, loss_ce: 0.018644
2022-01-08 10:58:41,859 iteration 1529 : loss : 0.040790, loss_ce: 0.015909
2022-01-08 10:58:41,859 Training Data Eval:
2022-01-08 10:58:54,626   Average segmentation loss on training set: 0.0343
2022-01-08 10:58:54,626 Validation Data Eval:
2022-01-08 10:58:59,139   Average segmentation loss on validation set: 0.0780
2022-01-08 10:59:01,588 iteration 1530 : loss : 0.050222, loss_ce: 0.023463
 22%|██████▎                     | 90/400 [1:05:16<4:02:09, 46.87s/it]2022-01-08 10:59:04,023 iteration 1531 : loss : 0.047280, loss_ce: 0.016452
2022-01-08 10:59:06,380 iteration 1532 : loss : 0.043151, loss_ce: 0.016467
2022-01-08 10:59:08,702 iteration 1533 : loss : 0.034628, loss_ce: 0.011204
2022-01-08 10:59:11,033 iteration 1534 : loss : 0.049604, loss_ce: 0.023267
2022-01-08 10:59:13,348 iteration 1535 : loss : 0.036993, loss_ce: 0.015204
2022-01-08 10:59:15,665 iteration 1536 : loss : 0.044719, loss_ce: 0.020998
2022-01-08 10:59:18,014 iteration 1537 : loss : 0.050765, loss_ce: 0.015780
2022-01-08 10:59:20,402 iteration 1538 : loss : 0.034997, loss_ce: 0.013222
2022-01-08 10:59:22,703 iteration 1539 : loss : 0.032473, loss_ce: 0.013868
2022-01-08 10:59:24,960 iteration 1540 : loss : 0.038650, loss_ce: 0.017312
2022-01-08 10:59:27,225 iteration 1541 : loss : 0.027914, loss_ce: 0.012446
2022-01-08 10:59:29,618 iteration 1542 : loss : 0.030473, loss_ce: 0.014107
2022-01-08 10:59:31,996 iteration 1543 : loss : 0.053294, loss_ce: 0.015128
2022-01-08 10:59:34,293 iteration 1544 : loss : 0.032419, loss_ce: 0.013503
2022-01-08 10:59:36,764 iteration 1545 : loss : 0.051353, loss_ce: 0.019179
2022-01-08 10:59:39,094 iteration 1546 : loss : 0.072528, loss_ce: 0.019371
2022-01-08 10:59:41,558 iteration 1547 : loss : 0.034627, loss_ce: 0.012632
 23%|██████▎                     | 91/400 [1:05:56<3:50:43, 44.80s/it]2022-01-08 10:59:43,943 iteration 1548 : loss : 0.036120, loss_ce: 0.015263
2022-01-08 10:59:46,266 iteration 1549 : loss : 0.031211, loss_ce: 0.012421
2022-01-08 10:59:48,603 iteration 1550 : loss : 0.047723, loss_ce: 0.018814
2022-01-08 10:59:50,956 iteration 1551 : loss : 0.032522, loss_ce: 0.011149
2022-01-08 10:59:53,349 iteration 1552 : loss : 0.035506, loss_ce: 0.011522
2022-01-08 10:59:55,783 iteration 1553 : loss : 0.065100, loss_ce: 0.025446
2022-01-08 10:59:58,163 iteration 1554 : loss : 0.034776, loss_ce: 0.013164
2022-01-08 11:00:00,501 iteration 1555 : loss : 0.037567, loss_ce: 0.015119
2022-01-08 11:00:02,892 iteration 1556 : loss : 0.027372, loss_ce: 0.009442
2022-01-08 11:00:05,211 iteration 1557 : loss : 0.043844, loss_ce: 0.016260
2022-01-08 11:00:07,509 iteration 1558 : loss : 0.043976, loss_ce: 0.018381
2022-01-08 11:00:09,823 iteration 1559 : loss : 0.042471, loss_ce: 0.015028
2022-01-08 11:00:12,152 iteration 1560 : loss : 0.029906, loss_ce: 0.014763
2022-01-08 11:00:14,525 iteration 1561 : loss : 0.046234, loss_ce: 0.015976
2022-01-08 11:00:16,858 iteration 1562 : loss : 0.056510, loss_ce: 0.013817
2022-01-08 11:00:19,290 iteration 1563 : loss : 0.038415, loss_ce: 0.016445
2022-01-08 11:00:21,779 iteration 1564 : loss : 0.033927, loss_ce: 0.012435
 23%|██████▍                     | 92/400 [1:06:36<3:42:55, 43.43s/it]2022-01-08 11:00:24,223 iteration 1565 : loss : 0.039703, loss_ce: 0.019466
2022-01-08 11:00:26,600 iteration 1566 : loss : 0.038044, loss_ce: 0.013382
2022-01-08 11:00:28,997 iteration 1567 : loss : 0.032118, loss_ce: 0.009264
2022-01-08 11:00:31,457 iteration 1568 : loss : 0.077706, loss_ce: 0.022747
2022-01-08 11:00:33,863 iteration 1569 : loss : 0.035339, loss_ce: 0.014742
2022-01-08 11:00:36,211 iteration 1570 : loss : 0.025380, loss_ce: 0.010955
2022-01-08 11:00:38,468 iteration 1571 : loss : 0.061781, loss_ce: 0.012442
2022-01-08 11:00:40,755 iteration 1572 : loss : 0.042209, loss_ce: 0.015136
2022-01-08 11:00:43,032 iteration 1573 : loss : 0.045455, loss_ce: 0.023496
2022-01-08 11:00:45,293 iteration 1574 : loss : 0.025765, loss_ce: 0.010792
2022-01-08 11:00:47,569 iteration 1575 : loss : 0.035363, loss_ce: 0.014360
2022-01-08 11:00:49,892 iteration 1576 : loss : 0.052697, loss_ce: 0.026198
2022-01-08 11:00:52,211 iteration 1577 : loss : 0.029960, loss_ce: 0.012680
2022-01-08 11:00:54,529 iteration 1578 : loss : 0.049240, loss_ce: 0.015565
2022-01-08 11:00:56,986 iteration 1579 : loss : 0.037179, loss_ce: 0.014065
2022-01-08 11:00:59,286 iteration 1580 : loss : 0.041775, loss_ce: 0.016118
2022-01-08 11:01:01,586 iteration 1581 : loss : 0.040887, loss_ce: 0.015118
 23%|██████▌                     | 93/400 [1:07:16<3:36:37, 42.34s/it]2022-01-08 11:01:03,987 iteration 1582 : loss : 0.054510, loss_ce: 0.024994
2022-01-08 11:01:06,237 iteration 1583 : loss : 0.055262, loss_ce: 0.016392
2022-01-08 11:01:08,469 iteration 1584 : loss : 0.030467, loss_ce: 0.015115
2022-01-08 11:01:10,666 iteration 1585 : loss : 0.035114, loss_ce: 0.011755
2022-01-08 11:01:12,912 iteration 1586 : loss : 0.043670, loss_ce: 0.016540
2022-01-08 11:01:15,114 iteration 1587 : loss : 0.027338, loss_ce: 0.011378
2022-01-08 11:01:17,474 iteration 1588 : loss : 0.041669, loss_ce: 0.020317
2022-01-08 11:01:19,878 iteration 1589 : loss : 0.036537, loss_ce: 0.014708
2022-01-08 11:01:22,348 iteration 1590 : loss : 0.049404, loss_ce: 0.015369
2022-01-08 11:01:24,624 iteration 1591 : loss : 0.029940, loss_ce: 0.010612
2022-01-08 11:01:27,062 iteration 1592 : loss : 0.048745, loss_ce: 0.015264
2022-01-08 11:01:29,460 iteration 1593 : loss : 0.045759, loss_ce: 0.017901
2022-01-08 11:01:31,766 iteration 1594 : loss : 0.044416, loss_ce: 0.015555
2022-01-08 11:01:33,996 iteration 1595 : loss : 0.029489, loss_ce: 0.009311
2022-01-08 11:01:36,281 iteration 1596 : loss : 0.042392, loss_ce: 0.020859
2022-01-08 11:01:38,613 iteration 1597 : loss : 0.055138, loss_ce: 0.024899
2022-01-08 11:01:40,928 iteration 1598 : loss : 0.031918, loss_ce: 0.011746
 24%|██████▌                     | 94/400 [1:07:55<3:31:21, 41.44s/it]2022-01-08 11:01:43,194 iteration 1599 : loss : 0.029185, loss_ce: 0.011212
2022-01-08 11:01:45,435 iteration 1600 : loss : 0.039963, loss_ce: 0.014589
2022-01-08 11:01:47,750 iteration 1601 : loss : 0.034841, loss_ce: 0.013225
2022-01-08 11:01:50,093 iteration 1602 : loss : 0.051335, loss_ce: 0.022153
2022-01-08 11:01:52,404 iteration 1603 : loss : 0.048535, loss_ce: 0.018828
2022-01-08 11:01:54,699 iteration 1604 : loss : 0.032991, loss_ce: 0.012341
2022-01-08 11:01:57,137 iteration 1605 : loss : 0.045539, loss_ce: 0.017265
2022-01-08 11:01:59,407 iteration 1606 : loss : 0.056368, loss_ce: 0.030683
2022-01-08 11:02:01,647 iteration 1607 : loss : 0.028080, loss_ce: 0.010742
2022-01-08 11:02:03,975 iteration 1608 : loss : 0.055160, loss_ce: 0.021836
2022-01-08 11:02:06,219 iteration 1609 : loss : 0.065451, loss_ce: 0.030030
2022-01-08 11:02:08,532 iteration 1610 : loss : 0.030538, loss_ce: 0.010897
2022-01-08 11:02:10,908 iteration 1611 : loss : 0.042766, loss_ce: 0.014792
2022-01-08 11:02:13,215 iteration 1612 : loss : 0.029672, loss_ce: 0.013145
2022-01-08 11:02:15,458 iteration 1613 : loss : 0.037583, loss_ce: 0.016614
2022-01-08 11:02:17,867 iteration 1614 : loss : 0.041248, loss_ce: 0.013213
2022-01-08 11:02:17,868 Training Data Eval:
2022-01-08 11:02:30,428   Average segmentation loss on training set: 0.0270
2022-01-08 11:02:30,428 Validation Data Eval:
2022-01-08 11:02:34,775   Average segmentation loss on validation set: 0.0802
2022-01-08 11:02:37,145 iteration 1615 : loss : 0.037115, loss_ce: 0.014174
 24%|██████▋                     | 95/400 [1:08:51<3:53:12, 45.88s/it]2022-01-08 11:02:39,495 iteration 1616 : loss : 0.035610, loss_ce: 0.013150
2022-01-08 11:02:41,736 iteration 1617 : loss : 0.063884, loss_ce: 0.021732
2022-01-08 11:02:43,964 iteration 1618 : loss : 0.043416, loss_ce: 0.017077
2022-01-08 11:02:46,240 iteration 1619 : loss : 0.025275, loss_ce: 0.008167
2022-01-08 11:02:48,539 iteration 1620 : loss : 0.026836, loss_ce: 0.007534
2022-01-08 11:02:50,855 iteration 1621 : loss : 0.051338, loss_ce: 0.032249
2022-01-08 11:02:53,222 iteration 1622 : loss : 0.058173, loss_ce: 0.016654
2022-01-08 11:02:55,462 iteration 1623 : loss : 0.036352, loss_ce: 0.015181
2022-01-08 11:02:57,766 iteration 1624 : loss : 0.031970, loss_ce: 0.011284
2022-01-08 11:02:59,998 iteration 1625 : loss : 0.029295, loss_ce: 0.011314
2022-01-08 11:03:02,208 iteration 1626 : loss : 0.028964, loss_ce: 0.012656
2022-01-08 11:03:04,472 iteration 1627 : loss : 0.044867, loss_ce: 0.014253
2022-01-08 11:03:06,893 iteration 1628 : loss : 0.034386, loss_ce: 0.015484
2022-01-08 11:03:09,198 iteration 1629 : loss : 0.034574, loss_ce: 0.012280
2022-01-08 11:03:11,480 iteration 1630 : loss : 0.034593, loss_ce: 0.012928
2022-01-08 11:03:13,937 iteration 1631 : loss : 0.037283, loss_ce: 0.015115
2022-01-08 11:03:16,337 iteration 1632 : loss : 0.045639, loss_ce: 0.016708
 24%|██████▋                     | 96/400 [1:09:31<3:42:14, 43.86s/it]2022-01-08 11:03:18,776 iteration 1633 : loss : 0.038841, loss_ce: 0.018193
2022-01-08 11:03:21,117 iteration 1634 : loss : 0.056878, loss_ce: 0.018915
2022-01-08 11:03:23,350 iteration 1635 : loss : 0.026121, loss_ce: 0.011681
2022-01-08 11:03:25,661 iteration 1636 : loss : 0.037821, loss_ce: 0.018178
2022-01-08 11:03:27,941 iteration 1637 : loss : 0.045679, loss_ce: 0.016738
2022-01-08 11:03:30,139 iteration 1638 : loss : 0.042635, loss_ce: 0.018035
2022-01-08 11:03:32,386 iteration 1639 : loss : 0.068265, loss_ce: 0.016726
2022-01-08 11:03:34,623 iteration 1640 : loss : 0.056866, loss_ce: 0.014787
2022-01-08 11:03:36,843 iteration 1641 : loss : 0.032753, loss_ce: 0.014500
2022-01-08 11:03:39,121 iteration 1642 : loss : 0.030148, loss_ce: 0.012373
2022-01-08 11:03:41,381 iteration 1643 : loss : 0.029851, loss_ce: 0.008181
2022-01-08 11:03:43,580 iteration 1644 : loss : 0.038346, loss_ce: 0.014432
2022-01-08 11:03:45,888 iteration 1645 : loss : 0.041738, loss_ce: 0.014050
2022-01-08 11:03:48,222 iteration 1646 : loss : 0.041151, loss_ce: 0.016746
2022-01-08 11:03:50,494 iteration 1647 : loss : 0.042335, loss_ce: 0.014438
2022-01-08 11:03:52,852 iteration 1648 : loss : 0.045617, loss_ce: 0.020716
2022-01-08 11:03:55,096 iteration 1649 : loss : 0.040891, loss_ce: 0.018262
 24%|██████▊                     | 97/400 [1:10:09<3:33:48, 42.34s/it]2022-01-08 11:03:57,397 iteration 1650 : loss : 0.030111, loss_ce: 0.013459
2022-01-08 11:03:59,675 iteration 1651 : loss : 0.070172, loss_ce: 0.022216
2022-01-08 11:04:01,822 iteration 1652 : loss : 0.055447, loss_ce: 0.016882
2022-01-08 11:04:04,023 iteration 1653 : loss : 0.031613, loss_ce: 0.011510
2022-01-08 11:04:06,399 iteration 1654 : loss : 0.086158, loss_ce: 0.022885
2022-01-08 11:04:08,804 iteration 1655 : loss : 0.043448, loss_ce: 0.015711
2022-01-08 11:04:11,044 iteration 1656 : loss : 0.039332, loss_ce: 0.015269
2022-01-08 11:04:13,371 iteration 1657 : loss : 0.054170, loss_ce: 0.015903
2022-01-08 11:04:15,689 iteration 1658 : loss : 0.046815, loss_ce: 0.025256
2022-01-08 11:04:18,054 iteration 1659 : loss : 0.026487, loss_ce: 0.008822
2022-01-08 11:04:20,551 iteration 1660 : loss : 0.047041, loss_ce: 0.017019
2022-01-08 11:04:22,944 iteration 1661 : loss : 0.037615, loss_ce: 0.009918
2022-01-08 11:04:25,177 iteration 1662 : loss : 0.031717, loss_ce: 0.011512
2022-01-08 11:04:27,313 iteration 1663 : loss : 0.028994, loss_ce: 0.014751
2022-01-08 11:04:29,573 iteration 1664 : loss : 0.056106, loss_ce: 0.020626
2022-01-08 11:04:31,793 iteration 1665 : loss : 0.040181, loss_ce: 0.013539
2022-01-08 11:04:34,079 iteration 1666 : loss : 0.044034, loss_ce: 0.017625
 24%|██████▊                     | 98/400 [1:10:48<3:28:01, 41.33s/it]2022-01-08 11:04:36,415 iteration 1667 : loss : 0.047204, loss_ce: 0.015332
2022-01-08 11:04:38,646 iteration 1668 : loss : 0.048509, loss_ce: 0.018163
2022-01-08 11:04:40,957 iteration 1669 : loss : 0.032523, loss_ce: 0.012193
2022-01-08 11:04:43,320 iteration 1670 : loss : 0.038946, loss_ce: 0.017974
2022-01-08 11:04:45,674 iteration 1671 : loss : 0.032388, loss_ce: 0.011738
2022-01-08 11:04:48,089 iteration 1672 : loss : 0.035970, loss_ce: 0.013555
2022-01-08 11:04:50,380 iteration 1673 : loss : 0.040765, loss_ce: 0.016146
2022-01-08 11:04:52,684 iteration 1674 : loss : 0.038783, loss_ce: 0.019208
2022-01-08 11:04:54,965 iteration 1675 : loss : 0.035643, loss_ce: 0.009341
2022-01-08 11:04:57,313 iteration 1676 : loss : 0.045963, loss_ce: 0.016084
2022-01-08 11:04:59,746 iteration 1677 : loss : 0.057005, loss_ce: 0.028759
2022-01-08 11:05:02,019 iteration 1678 : loss : 0.031008, loss_ce: 0.012842
2022-01-08 11:05:04,325 iteration 1679 : loss : 0.028990, loss_ce: 0.008303
2022-01-08 11:05:06,628 iteration 1680 : loss : 0.033420, loss_ce: 0.015507
2022-01-08 11:05:09,043 iteration 1681 : loss : 0.035690, loss_ce: 0.019822
2022-01-08 11:05:11,447 iteration 1682 : loss : 0.036894, loss_ce: 0.014456
2022-01-08 11:05:13,720 iteration 1683 : loss : 0.032563, loss_ce: 0.011594
 25%|██████▉                     | 99/400 [1:11:28<3:24:47, 40.82s/it]2022-01-08 11:05:16,284 iteration 1684 : loss : 0.034513, loss_ce: 0.011895
2022-01-08 11:05:18,667 iteration 1685 : loss : 0.061860, loss_ce: 0.019454
2022-01-08 11:05:20,954 iteration 1686 : loss : 0.030707, loss_ce: 0.011749
2022-01-08 11:05:23,142 iteration 1687 : loss : 0.029754, loss_ce: 0.014419
2022-01-08 11:05:25,453 iteration 1688 : loss : 0.031656, loss_ce: 0.012528
2022-01-08 11:05:27,727 iteration 1689 : loss : 0.039439, loss_ce: 0.015590
2022-01-08 11:05:30,122 iteration 1690 : loss : 0.042312, loss_ce: 0.018794
2022-01-08 11:05:32,339 iteration 1691 : loss : 0.082346, loss_ce: 0.019805
2022-01-08 11:05:34,644 iteration 1692 : loss : 0.051635, loss_ce: 0.016584
2022-01-08 11:05:36,906 iteration 1693 : loss : 0.028824, loss_ce: 0.011657
2022-01-08 11:05:39,343 iteration 1694 : loss : 0.026414, loss_ce: 0.011240
2022-01-08 11:05:41,731 iteration 1695 : loss : 0.040850, loss_ce: 0.015770
2022-01-08 11:05:44,198 iteration 1696 : loss : 0.052541, loss_ce: 0.016140
2022-01-08 11:05:46,568 iteration 1697 : loss : 0.034477, loss_ce: 0.012825
2022-01-08 11:05:48,964 iteration 1698 : loss : 0.041549, loss_ce: 0.017908
2022-01-08 11:05:51,230 iteration 1699 : loss : 0.038219, loss_ce: 0.018889
2022-01-08 11:05:51,231 Training Data Eval:
2022-01-08 11:06:03,966   Average segmentation loss on training set: 0.0333
2022-01-08 11:06:03,966 Validation Data Eval:
2022-01-08 11:06:08,472   Average segmentation loss on validation set: 0.1445
2022-01-08 11:06:10,831 iteration 1700 : loss : 0.037301, loss_ce: 0.011986
 25%|██████▊                    | 100/400 [1:12:25<3:48:33, 45.71s/it]2022-01-08 11:06:13,285 iteration 1701 : loss : 0.032374, loss_ce: 0.013988
2022-01-08 11:06:15,680 iteration 1702 : loss : 0.033994, loss_ce: 0.013583
2022-01-08 11:06:18,105 iteration 1703 : loss : 0.038056, loss_ce: 0.016731
2022-01-08 11:06:20,496 iteration 1704 : loss : 0.038420, loss_ce: 0.014876
2022-01-08 11:06:22,802 iteration 1705 : loss : 0.034824, loss_ce: 0.012136
2022-01-08 11:06:25,193 iteration 1706 : loss : 0.050007, loss_ce: 0.013623
2022-01-08 11:06:27,495 iteration 1707 : loss : 0.035874, loss_ce: 0.015282
2022-01-08 11:06:29,901 iteration 1708 : loss : 0.030275, loss_ce: 0.011454
2022-01-08 11:06:32,414 iteration 1709 : loss : 0.042223, loss_ce: 0.018384
2022-01-08 11:06:34,803 iteration 1710 : loss : 0.034767, loss_ce: 0.015918
2022-01-08 11:06:37,200 iteration 1711 : loss : 0.054045, loss_ce: 0.019461
2022-01-08 11:06:39,561 iteration 1712 : loss : 0.048902, loss_ce: 0.013875
2022-01-08 11:06:41,849 iteration 1713 : loss : 0.051245, loss_ce: 0.016362
2022-01-08 11:06:44,218 iteration 1714 : loss : 0.027812, loss_ce: 0.010864
2022-01-08 11:06:46,579 iteration 1715 : loss : 0.052443, loss_ce: 0.019982
2022-01-08 11:06:48,967 iteration 1716 : loss : 0.054281, loss_ce: 0.018583
2022-01-08 11:06:51,367 iteration 1717 : loss : 0.030515, loss_ce: 0.012152
 25%|██████▊                    | 101/400 [1:13:06<3:40:02, 44.16s/it]2022-01-08 11:06:53,847 iteration 1718 : loss : 0.031342, loss_ce: 0.011396
2022-01-08 11:06:56,301 iteration 1719 : loss : 0.034942, loss_ce: 0.008469
2022-01-08 11:06:58,739 iteration 1720 : loss : 0.039163, loss_ce: 0.013838
2022-01-08 11:07:01,176 iteration 1721 : loss : 0.038522, loss_ce: 0.016723
2022-01-08 11:07:03,630 iteration 1722 : loss : 0.034301, loss_ce: 0.013842
2022-01-08 11:07:05,982 iteration 1723 : loss : 0.026806, loss_ce: 0.011302
2022-01-08 11:07:08,318 iteration 1724 : loss : 0.030354, loss_ce: 0.014474
2022-01-08 11:07:10,676 iteration 1725 : loss : 0.036295, loss_ce: 0.016194
2022-01-08 11:07:13,136 iteration 1726 : loss : 0.032252, loss_ce: 0.011734
2022-01-08 11:07:15,467 iteration 1727 : loss : 0.040111, loss_ce: 0.013363
2022-01-08 11:07:17,910 iteration 1728 : loss : 0.040354, loss_ce: 0.017122
2022-01-08 11:07:20,262 iteration 1729 : loss : 0.038591, loss_ce: 0.013111
2022-01-08 11:07:22,674 iteration 1730 : loss : 0.045299, loss_ce: 0.017378
2022-01-08 11:07:24,978 iteration 1731 : loss : 0.035233, loss_ce: 0.014783
2022-01-08 11:07:27,372 iteration 1732 : loss : 0.031939, loss_ce: 0.014061
2022-01-08 11:07:29,782 iteration 1733 : loss : 0.039336, loss_ce: 0.012672
2022-01-08 11:07:32,170 iteration 1734 : loss : 0.044915, loss_ce: 0.012198
 26%|██████▉                    | 102/400 [1:13:46<3:34:18, 43.15s/it]2022-01-08 11:07:34,659 iteration 1735 : loss : 0.030440, loss_ce: 0.009304
2022-01-08 11:07:37,022 iteration 1736 : loss : 0.038744, loss_ce: 0.014229
2022-01-08 11:07:39,414 iteration 1737 : loss : 0.042859, loss_ce: 0.017310
2022-01-08 11:07:41,798 iteration 1738 : loss : 0.050042, loss_ce: 0.017889
2022-01-08 11:07:44,172 iteration 1739 : loss : 0.054573, loss_ce: 0.027354
2022-01-08 11:07:46,583 iteration 1740 : loss : 0.044251, loss_ce: 0.009888
2022-01-08 11:07:49,062 iteration 1741 : loss : 0.030995, loss_ce: 0.009508
2022-01-08 11:07:51,500 iteration 1742 : loss : 0.046885, loss_ce: 0.016824
2022-01-08 11:07:54,073 iteration 1743 : loss : 0.043914, loss_ce: 0.024887
2022-01-08 11:07:56,452 iteration 1744 : loss : 0.044813, loss_ce: 0.017198
2022-01-08 11:07:58,888 iteration 1745 : loss : 0.036117, loss_ce: 0.013819
2022-01-08 11:08:01,257 iteration 1746 : loss : 0.038427, loss_ce: 0.013229
2022-01-08 11:08:03,629 iteration 1747 : loss : 0.034562, loss_ce: 0.012309
2022-01-08 11:08:05,975 iteration 1748 : loss : 0.026153, loss_ce: 0.012740
2022-01-08 11:08:08,376 iteration 1749 : loss : 0.037606, loss_ce: 0.015281
2022-01-08 11:08:10,676 iteration 1750 : loss : 0.034187, loss_ce: 0.016932
2022-01-08 11:08:12,937 iteration 1751 : loss : 0.038621, loss_ce: 0.013381
 26%|██████▉                    | 103/400 [1:14:27<3:30:04, 42.44s/it]2022-01-08 11:08:15,409 iteration 1752 : loss : 0.025110, loss_ce: 0.010682
2022-01-08 11:08:18,058 iteration 1753 : loss : 0.032274, loss_ce: 0.014269
2022-01-08 11:08:20,472 iteration 1754 : loss : 0.032250, loss_ce: 0.015461
2022-01-08 11:08:22,816 iteration 1755 : loss : 0.052858, loss_ce: 0.016876
2022-01-08 11:08:25,314 iteration 1756 : loss : 0.070053, loss_ce: 0.040136
2022-01-08 11:08:27,710 iteration 1757 : loss : 0.044190, loss_ce: 0.011919
2022-01-08 11:08:30,086 iteration 1758 : loss : 0.039314, loss_ce: 0.015711
2022-01-08 11:08:32,449 iteration 1759 : loss : 0.043294, loss_ce: 0.012776
2022-01-08 11:08:34,863 iteration 1760 : loss : 0.051483, loss_ce: 0.019460
2022-01-08 11:08:37,147 iteration 1761 : loss : 0.026058, loss_ce: 0.011740
2022-01-08 11:08:39,529 iteration 1762 : loss : 0.066755, loss_ce: 0.025872
2022-01-08 11:08:41,842 iteration 1763 : loss : 0.039603, loss_ce: 0.012401
2022-01-08 11:08:44,216 iteration 1764 : loss : 0.073155, loss_ce: 0.020653
2022-01-08 11:08:46,759 iteration 1765 : loss : 0.038713, loss_ce: 0.011835
2022-01-08 11:08:49,096 iteration 1766 : loss : 0.031426, loss_ce: 0.013548
2022-01-08 11:08:51,456 iteration 1767 : loss : 0.046011, loss_ce: 0.021311
2022-01-08 11:08:53,932 iteration 1768 : loss : 0.049122, loss_ce: 0.018039
 26%|███████                    | 104/400 [1:15:08<3:27:12, 42.00s/it]2022-01-08 11:08:56,362 iteration 1769 : loss : 0.037108, loss_ce: 0.011914
2022-01-08 11:08:58,824 iteration 1770 : loss : 0.060682, loss_ce: 0.031430
2022-01-08 11:09:01,209 iteration 1771 : loss : 0.037795, loss_ce: 0.014727
2022-01-08 11:09:03,498 iteration 1772 : loss : 0.039662, loss_ce: 0.011890
2022-01-08 11:09:05,768 iteration 1773 : loss : 0.035355, loss_ce: 0.012210
2022-01-08 11:09:08,092 iteration 1774 : loss : 0.036766, loss_ce: 0.015854
2022-01-08 11:09:10,567 iteration 1775 : loss : 0.043858, loss_ce: 0.019057
2022-01-08 11:09:12,974 iteration 1776 : loss : 0.062805, loss_ce: 0.018677
2022-01-08 11:09:15,333 iteration 1777 : loss : 0.047353, loss_ce: 0.017541
2022-01-08 11:09:17,776 iteration 1778 : loss : 0.064697, loss_ce: 0.020416
2022-01-08 11:09:20,176 iteration 1779 : loss : 0.041740, loss_ce: 0.021243
2022-01-08 11:09:22,582 iteration 1780 : loss : 0.038962, loss_ce: 0.014120
2022-01-08 11:09:24,990 iteration 1781 : loss : 0.033614, loss_ce: 0.016090
2022-01-08 11:09:27,393 iteration 1782 : loss : 0.040909, loss_ce: 0.015648
2022-01-08 11:09:29,703 iteration 1783 : loss : 0.044996, loss_ce: 0.027724
2022-01-08 11:09:32,149 iteration 1784 : loss : 0.029933, loss_ce: 0.012628
2022-01-08 11:09:32,149 Training Data Eval:
2022-01-08 11:09:44,986   Average segmentation loss on training set: 0.0289
2022-01-08 11:09:44,987 Validation Data Eval:
2022-01-08 11:09:49,482   Average segmentation loss on validation set: 0.0982
2022-01-08 11:09:51,955 iteration 1785 : loss : 0.044746, loss_ce: 0.017172
 26%|███████                    | 105/400 [1:16:06<3:50:08, 46.81s/it]2022-01-08 11:09:54,522 iteration 1786 : loss : 0.037165, loss_ce: 0.017662
2022-01-08 11:09:56,924 iteration 1787 : loss : 0.040459, loss_ce: 0.014918
2022-01-08 11:09:59,207 iteration 1788 : loss : 0.054170, loss_ce: 0.027742
2022-01-08 11:10:01,533 iteration 1789 : loss : 0.037725, loss_ce: 0.013336
2022-01-08 11:10:03,951 iteration 1790 : loss : 0.031563, loss_ce: 0.014149
2022-01-08 11:10:06,270 iteration 1791 : loss : 0.025796, loss_ce: 0.011768
2022-01-08 11:10:08,658 iteration 1792 : loss : 0.043723, loss_ce: 0.014237
2022-01-08 11:10:11,081 iteration 1793 : loss : 0.033536, loss_ce: 0.015065
2022-01-08 11:10:13,596 iteration 1794 : loss : 0.049841, loss_ce: 0.025277
2022-01-08 11:10:15,996 iteration 1795 : loss : 0.041427, loss_ce: 0.018884
2022-01-08 11:10:18,312 iteration 1796 : loss : 0.031905, loss_ce: 0.010442
2022-01-08 11:10:20,697 iteration 1797 : loss : 0.029733, loss_ce: 0.013481
2022-01-08 11:10:23,054 iteration 1798 : loss : 0.041099, loss_ce: 0.015433
2022-01-08 11:10:25,538 iteration 1799 : loss : 0.037615, loss_ce: 0.014839
2022-01-08 11:10:27,977 iteration 1800 : loss : 0.054291, loss_ce: 0.027080
2022-01-08 11:10:30,422 iteration 1801 : loss : 0.031453, loss_ce: 0.012739
2022-01-08 11:10:32,802 iteration 1802 : loss : 0.065862, loss_ce: 0.019770
 26%|███████▏                   | 106/400 [1:16:47<3:40:36, 45.02s/it]2022-01-08 11:10:35,278 iteration 1803 : loss : 0.036528, loss_ce: 0.013439
2022-01-08 11:10:37,629 iteration 1804 : loss : 0.033217, loss_ce: 0.007743
2022-01-08 11:10:39,969 iteration 1805 : loss : 0.033057, loss_ce: 0.016640
2022-01-08 11:10:42,324 iteration 1806 : loss : 0.038352, loss_ce: 0.014129
2022-01-08 11:10:44,816 iteration 1807 : loss : 0.039878, loss_ce: 0.013109
2022-01-08 11:10:47,260 iteration 1808 : loss : 0.037571, loss_ce: 0.015685
2022-01-08 11:10:49,681 iteration 1809 : loss : 0.038915, loss_ce: 0.015904
2022-01-08 11:10:52,294 iteration 1810 : loss : 0.030049, loss_ce: 0.011820
2022-01-08 11:10:54,776 iteration 1811 : loss : 0.031137, loss_ce: 0.011579
2022-01-08 11:10:57,306 iteration 1812 : loss : 0.035574, loss_ce: 0.017924
2022-01-08 11:10:59,765 iteration 1813 : loss : 0.055860, loss_ce: 0.016656
2022-01-08 11:11:02,218 iteration 1814 : loss : 0.042529, loss_ce: 0.015069
2022-01-08 11:11:04,811 iteration 1815 : loss : 0.026939, loss_ce: 0.012756
2022-01-08 11:11:07,303 iteration 1816 : loss : 0.049450, loss_ce: 0.017947
2022-01-08 11:11:09,703 iteration 1817 : loss : 0.032836, loss_ce: 0.009963
2022-01-08 11:11:12,378 iteration 1818 : loss : 0.030768, loss_ce: 0.016117
2022-01-08 11:11:14,775 iteration 1819 : loss : 0.025817, loss_ce: 0.009371
 27%|███████▏                   | 107/400 [1:17:29<3:35:22, 44.10s/it]2022-01-08 11:11:17,283 iteration 1820 : loss : 0.057335, loss_ce: 0.015849
2022-01-08 11:11:19,618 iteration 1821 : loss : 0.031158, loss_ce: 0.010997
2022-01-08 11:11:22,071 iteration 1822 : loss : 0.032990, loss_ce: 0.015301
2022-01-08 11:11:24,508 iteration 1823 : loss : 0.045082, loss_ce: 0.019021
2022-01-08 11:11:26,924 iteration 1824 : loss : 0.027822, loss_ce: 0.009501
2022-01-08 11:11:29,319 iteration 1825 : loss : 0.034792, loss_ce: 0.011735
2022-01-08 11:11:31,593 iteration 1826 : loss : 0.046943, loss_ce: 0.020037
2022-01-08 11:11:33,816 iteration 1827 : loss : 0.044194, loss_ce: 0.013321
2022-01-08 11:11:36,137 iteration 1828 : loss : 0.036633, loss_ce: 0.017304
2022-01-08 11:11:38,557 iteration 1829 : loss : 0.042218, loss_ce: 0.012932
2022-01-08 11:11:40,952 iteration 1830 : loss : 0.027702, loss_ce: 0.011101
2022-01-08 11:11:43,352 iteration 1831 : loss : 0.032969, loss_ce: 0.012988
2022-01-08 11:11:45,719 iteration 1832 : loss : 0.026154, loss_ce: 0.009916
2022-01-08 11:11:48,088 iteration 1833 : loss : 0.037358, loss_ce: 0.023181
2022-01-08 11:11:50,569 iteration 1834 : loss : 0.044841, loss_ce: 0.015117
2022-01-08 11:11:52,930 iteration 1835 : loss : 0.037723, loss_ce: 0.012968
2022-01-08 11:11:55,268 iteration 1836 : loss : 0.038454, loss_ce: 0.014290
 27%|███████▎                   | 108/400 [1:18:10<3:29:23, 43.03s/it]2022-01-08 11:11:57,631 iteration 1837 : loss : 0.048562, loss_ce: 0.007790
2022-01-08 11:12:00,003 iteration 1838 : loss : 0.038314, loss_ce: 0.016260
2022-01-08 11:12:02,237 iteration 1839 : loss : 0.028748, loss_ce: 0.012917
2022-01-08 11:12:04,585 iteration 1840 : loss : 0.046922, loss_ce: 0.011987
2022-01-08 11:12:07,019 iteration 1841 : loss : 0.034115, loss_ce: 0.011553
2022-01-08 11:12:09,465 iteration 1842 : loss : 0.032604, loss_ce: 0.013399
2022-01-08 11:12:11,860 iteration 1843 : loss : 0.043769, loss_ce: 0.019947
2022-01-08 11:12:14,260 iteration 1844 : loss : 0.037482, loss_ce: 0.014558
2022-01-08 11:12:16,679 iteration 1845 : loss : 0.032747, loss_ce: 0.014157
2022-01-08 11:12:19,052 iteration 1846 : loss : 0.049575, loss_ce: 0.014094
2022-01-08 11:12:21,350 iteration 1847 : loss : 0.024784, loss_ce: 0.009175
2022-01-08 11:12:23,885 iteration 1848 : loss : 0.032935, loss_ce: 0.013008
2022-01-08 11:12:26,286 iteration 1849 : loss : 0.047423, loss_ce: 0.015400
2022-01-08 11:12:28,690 iteration 1850 : loss : 0.034731, loss_ce: 0.012994
2022-01-08 11:12:31,138 iteration 1851 : loss : 0.031031, loss_ce: 0.014212
2022-01-08 11:12:33,469 iteration 1852 : loss : 0.030457, loss_ce: 0.017608
2022-01-08 11:12:35,852 iteration 1853 : loss : 0.032968, loss_ce: 0.015460
 27%|███████▎                   | 109/400 [1:18:50<3:25:06, 42.29s/it]2022-01-08 11:12:38,191 iteration 1854 : loss : 0.041404, loss_ce: 0.014547
2022-01-08 11:12:40,488 iteration 1855 : loss : 0.040822, loss_ce: 0.016281
2022-01-08 11:12:42,762 iteration 1856 : loss : 0.037712, loss_ce: 0.015784
2022-01-08 11:12:45,096 iteration 1857 : loss : 0.025603, loss_ce: 0.011213
2022-01-08 11:12:47,617 iteration 1858 : loss : 0.027489, loss_ce: 0.013524
2022-01-08 11:12:50,042 iteration 1859 : loss : 0.048114, loss_ce: 0.018329
2022-01-08 11:12:52,441 iteration 1860 : loss : 0.051247, loss_ce: 0.021181
2022-01-08 11:12:54,798 iteration 1861 : loss : 0.028440, loss_ce: 0.013178
2022-01-08 11:12:57,206 iteration 1862 : loss : 0.028453, loss_ce: 0.013569
2022-01-08 11:12:59,573 iteration 1863 : loss : 0.037030, loss_ce: 0.012408
2022-01-08 11:13:01,974 iteration 1864 : loss : 0.027523, loss_ce: 0.009414
2022-01-08 11:13:04,409 iteration 1865 : loss : 0.040094, loss_ce: 0.012762
2022-01-08 11:13:06,798 iteration 1866 : loss : 0.029024, loss_ce: 0.010814
2022-01-08 11:13:09,050 iteration 1867 : loss : 0.023860, loss_ce: 0.007676
2022-01-08 11:13:11,393 iteration 1868 : loss : 0.032325, loss_ce: 0.010330
2022-01-08 11:13:13,702 iteration 1869 : loss : 0.032552, loss_ce: 0.015550
2022-01-08 11:13:13,702 Training Data Eval:
2022-01-08 11:13:26,499   Average segmentation loss on training set: 0.0306
2022-01-08 11:13:26,499 Validation Data Eval:
2022-01-08 11:13:30,880   Average segmentation loss on validation set: 0.1425
2022-01-08 11:13:33,316 iteration 1870 : loss : 0.042799, loss_ce: 0.015500
 28%|███████▍                   | 110/400 [1:19:48<3:46:24, 46.84s/it]2022-01-08 11:13:35,823 iteration 1871 : loss : 0.059427, loss_ce: 0.017236
2022-01-08 11:13:38,264 iteration 1872 : loss : 0.028776, loss_ce: 0.010058
2022-01-08 11:13:40,652 iteration 1873 : loss : 0.027811, loss_ce: 0.009205
2022-01-08 11:13:43,020 iteration 1874 : loss : 0.049721, loss_ce: 0.014814
2022-01-08 11:13:45,365 iteration 1875 : loss : 0.028117, loss_ce: 0.011627
2022-01-08 11:13:47,694 iteration 1876 : loss : 0.023930, loss_ce: 0.010874
2022-01-08 11:13:50,084 iteration 1877 : loss : 0.025997, loss_ce: 0.008627
2022-01-08 11:13:52,414 iteration 1878 : loss : 0.049028, loss_ce: 0.025809
2022-01-08 11:13:54,759 iteration 1879 : loss : 0.035449, loss_ce: 0.011765
2022-01-08 11:13:57,057 iteration 1880 : loss : 0.035098, loss_ce: 0.014951
2022-01-08 11:13:59,362 iteration 1881 : loss : 0.034725, loss_ce: 0.016414
2022-01-08 11:14:01,765 iteration 1882 : loss : 0.042372, loss_ce: 0.015223
2022-01-08 11:14:04,212 iteration 1883 : loss : 0.025567, loss_ce: 0.009204
2022-01-08 11:14:06,566 iteration 1884 : loss : 0.029837, loss_ce: 0.011639
2022-01-08 11:14:08,946 iteration 1885 : loss : 0.021586, loss_ce: 0.008441
2022-01-08 11:14:11,354 iteration 1886 : loss : 0.040421, loss_ce: 0.014712
2022-01-08 11:14:13,679 iteration 1887 : loss : 0.048847, loss_ce: 0.020311
 28%|███████▍                   | 111/400 [1:20:28<3:36:15, 44.90s/it]2022-01-08 11:14:16,197 iteration 1888 : loss : 0.044631, loss_ce: 0.014807
2022-01-08 11:14:18,538 iteration 1889 : loss : 0.041159, loss_ce: 0.011759
2022-01-08 11:14:20,860 iteration 1890 : loss : 0.034728, loss_ce: 0.015572
2022-01-08 11:14:23,296 iteration 1891 : loss : 0.026742, loss_ce: 0.009281
2022-01-08 11:14:25,704 iteration 1892 : loss : 0.028761, loss_ce: 0.013712
2022-01-08 11:14:28,114 iteration 1893 : loss : 0.026477, loss_ce: 0.007234
2022-01-08 11:14:30,490 iteration 1894 : loss : 0.045522, loss_ce: 0.020287
2022-01-08 11:14:32,775 iteration 1895 : loss : 0.025202, loss_ce: 0.010307
2022-01-08 11:14:35,192 iteration 1896 : loss : 0.034378, loss_ce: 0.013363
2022-01-08 11:14:37,551 iteration 1897 : loss : 0.034672, loss_ce: 0.011216
2022-01-08 11:14:39,962 iteration 1898 : loss : 0.048206, loss_ce: 0.023234
2022-01-08 11:14:42,320 iteration 1899 : loss : 0.040160, loss_ce: 0.013039
2022-01-08 11:14:44,821 iteration 1900 : loss : 0.035710, loss_ce: 0.015110
2022-01-08 11:14:47,139 iteration 1901 : loss : 0.027719, loss_ce: 0.009207
2022-01-08 11:14:49,474 iteration 1902 : loss : 0.034039, loss_ce: 0.013929
2022-01-08 11:14:51,854 iteration 1903 : loss : 0.037509, loss_ce: 0.015630
2022-01-08 11:14:54,329 iteration 1904 : loss : 0.031854, loss_ce: 0.013450
 28%|███████▌                   | 112/400 [1:21:09<3:29:24, 43.63s/it]2022-01-08 11:14:56,661 iteration 1905 : loss : 0.029010, loss_ce: 0.013364
2022-01-08 11:14:59,122 iteration 1906 : loss : 0.029773, loss_ce: 0.010407
2022-01-08 11:15:01,550 iteration 1907 : loss : 0.041202, loss_ce: 0.014824
2022-01-08 11:15:03,966 iteration 1908 : loss : 0.054252, loss_ce: 0.022643
2022-01-08 11:15:06,134 iteration 1909 : loss : 0.023901, loss_ce: 0.009967
2022-01-08 11:15:08,473 iteration 1910 : loss : 0.034959, loss_ce: 0.013266
2022-01-08 11:15:10,805 iteration 1911 : loss : 0.035182, loss_ce: 0.013049
2022-01-08 11:15:13,278 iteration 1912 : loss : 0.035651, loss_ce: 0.012855
2022-01-08 11:15:15,610 iteration 1913 : loss : 0.043995, loss_ce: 0.016359
2022-01-08 11:15:17,970 iteration 1914 : loss : 0.037099, loss_ce: 0.013619
2022-01-08 11:15:20,327 iteration 1915 : loss : 0.034873, loss_ce: 0.013872
2022-01-08 11:15:22,700 iteration 1916 : loss : 0.033766, loss_ce: 0.012061
2022-01-08 11:15:25,038 iteration 1917 : loss : 0.029173, loss_ce: 0.011966
2022-01-08 11:15:27,435 iteration 1918 : loss : 0.041304, loss_ce: 0.017445
2022-01-08 11:15:29,922 iteration 1919 : loss : 0.035718, loss_ce: 0.011812
2022-01-08 11:15:32,271 iteration 1920 : loss : 0.031628, loss_ce: 0.013488
2022-01-08 11:15:34,731 iteration 1921 : loss : 0.035379, loss_ce: 0.012016
 28%|███████▋                   | 113/400 [1:21:49<3:24:02, 42.66s/it]2022-01-08 11:15:37,127 iteration 1922 : loss : 0.051131, loss_ce: 0.022026
2022-01-08 11:15:39,309 iteration 1923 : loss : 0.025719, loss_ce: 0.009795
2022-01-08 11:15:41,657 iteration 1924 : loss : 0.044601, loss_ce: 0.014862
2022-01-08 11:15:43,906 iteration 1925 : loss : 0.035454, loss_ce: 0.010738
2022-01-08 11:15:46,191 iteration 1926 : loss : 0.025479, loss_ce: 0.009772
2022-01-08 11:15:48,491 iteration 1927 : loss : 0.032807, loss_ce: 0.015104
2022-01-08 11:15:50,756 iteration 1928 : loss : 0.044175, loss_ce: 0.014728
2022-01-08 11:15:53,214 iteration 1929 : loss : 0.053520, loss_ce: 0.025992
2022-01-08 11:15:55,512 iteration 1930 : loss : 0.030326, loss_ce: 0.012734
2022-01-08 11:15:57,927 iteration 1931 : loss : 0.041114, loss_ce: 0.013040
2022-01-08 11:16:00,271 iteration 1932 : loss : 0.052639, loss_ce: 0.014482
2022-01-08 11:16:02,658 iteration 1933 : loss : 0.038518, loss_ce: 0.013830
2022-01-08 11:16:05,048 iteration 1934 : loss : 0.042158, loss_ce: 0.012011
2022-01-08 11:16:07,465 iteration 1935 : loss : 0.023839, loss_ce: 0.009963
2022-01-08 11:16:09,770 iteration 1936 : loss : 0.027317, loss_ce: 0.010421
2022-01-08 11:16:12,133 iteration 1937 : loss : 0.034286, loss_ce: 0.012734
2022-01-08 11:16:14,507 iteration 1938 : loss : 0.039240, loss_ce: 0.017918
 28%|███████▋                   | 114/400 [1:22:29<3:19:12, 41.79s/it]2022-01-08 11:16:16,865 iteration 1939 : loss : 0.029231, loss_ce: 0.012169
2022-01-08 11:16:19,032 iteration 1940 : loss : 0.038763, loss_ce: 0.020561
2022-01-08 11:16:21,265 iteration 1941 : loss : 0.023986, loss_ce: 0.009188
2022-01-08 11:16:23,589 iteration 1942 : loss : 0.027159, loss_ce: 0.009385
2022-01-08 11:16:25,899 iteration 1943 : loss : 0.028388, loss_ce: 0.010005
2022-01-08 11:16:28,298 iteration 1944 : loss : 0.031454, loss_ce: 0.011557
2022-01-08 11:16:30,696 iteration 1945 : loss : 0.042456, loss_ce: 0.015293
2022-01-08 11:16:33,025 iteration 1946 : loss : 0.036824, loss_ce: 0.009654
2022-01-08 11:16:35,396 iteration 1947 : loss : 0.030808, loss_ce: 0.007197
2022-01-08 11:16:37,771 iteration 1948 : loss : 0.048616, loss_ce: 0.023644
2022-01-08 11:16:40,211 iteration 1949 : loss : 0.033088, loss_ce: 0.009664
2022-01-08 11:16:42,639 iteration 1950 : loss : 0.044318, loss_ce: 0.014768
2022-01-08 11:16:45,042 iteration 1951 : loss : 0.028269, loss_ce: 0.011291
2022-01-08 11:16:47,377 iteration 1952 : loss : 0.029970, loss_ce: 0.013298
2022-01-08 11:16:49,685 iteration 1953 : loss : 0.036565, loss_ce: 0.020571
2022-01-08 11:16:52,013 iteration 1954 : loss : 0.026139, loss_ce: 0.010813
2022-01-08 11:16:52,013 Training Data Eval:
2022-01-08 11:17:04,511   Average segmentation loss on training set: 0.0271
2022-01-08 11:17:04,512 Validation Data Eval:
2022-01-08 11:17:08,958   Average segmentation loss on validation set: 0.0707
2022-01-08 11:17:14,749 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed2.pth
2022-01-08 11:17:16,411 iteration 1955 : loss : 0.032145, loss_ce: 0.013835
 29%|███████▊                   | 115/400 [1:23:31<3:47:11, 47.83s/it]2022-01-08 11:17:18,061 iteration 1956 : loss : 0.038994, loss_ce: 0.014133
2022-01-08 11:17:19,789 iteration 1957 : loss : 0.033535, loss_ce: 0.018640
2022-01-08 11:17:21,581 iteration 1958 : loss : 0.065438, loss_ce: 0.014795
2022-01-08 11:17:23,504 iteration 1959 : loss : 0.037490, loss_ce: 0.011241
2022-01-08 11:17:25,450 iteration 1960 : loss : 0.024917, loss_ce: 0.009143
2022-01-08 11:17:27,436 iteration 1961 : loss : 0.027070, loss_ce: 0.009641
2022-01-08 11:17:29,630 iteration 1962 : loss : 0.028701, loss_ce: 0.011679
2022-01-08 11:17:31,766 iteration 1963 : loss : 0.024730, loss_ce: 0.009068
2022-01-08 11:17:33,986 iteration 1964 : loss : 0.037233, loss_ce: 0.010852
2022-01-08 11:17:36,082 iteration 1965 : loss : 0.027948, loss_ce: 0.012827
2022-01-08 11:17:38,291 iteration 1966 : loss : 0.039465, loss_ce: 0.014315
2022-01-08 11:17:40,568 iteration 1967 : loss : 0.031390, loss_ce: 0.012416
2022-01-08 11:17:42,958 iteration 1968 : loss : 0.050048, loss_ce: 0.023368
2022-01-08 11:17:45,227 iteration 1969 : loss : 0.047798, loss_ce: 0.017767
2022-01-08 11:17:47,413 iteration 1970 : loss : 0.029922, loss_ce: 0.011576
2022-01-08 11:17:49,809 iteration 1971 : loss : 0.030952, loss_ce: 0.010334
2022-01-08 11:17:52,205 iteration 1972 : loss : 0.047390, loss_ce: 0.013619
 29%|███████▊                   | 116/400 [1:24:06<3:29:17, 44.22s/it]2022-01-08 11:17:54,690 iteration 1973 : loss : 0.026357, loss_ce: 0.011007
2022-01-08 11:17:57,081 iteration 1974 : loss : 0.041996, loss_ce: 0.018303
2022-01-08 11:17:59,499 iteration 1975 : loss : 0.036574, loss_ce: 0.012834
2022-01-08 11:18:01,780 iteration 1976 : loss : 0.036830, loss_ce: 0.018371
2022-01-08 11:18:04,192 iteration 1977 : loss : 0.032586, loss_ce: 0.012740
2022-01-08 11:18:06,537 iteration 1978 : loss : 0.031300, loss_ce: 0.011955
2022-01-08 11:18:08,707 iteration 1979 : loss : 0.029115, loss_ce: 0.011961
2022-01-08 11:18:10,930 iteration 1980 : loss : 0.031725, loss_ce: 0.010764
2022-01-08 11:18:13,221 iteration 1981 : loss : 0.025063, loss_ce: 0.010578
2022-01-08 11:18:15,663 iteration 1982 : loss : 0.030199, loss_ce: 0.011725
2022-01-08 11:18:17,944 iteration 1983 : loss : 0.035769, loss_ce: 0.013001
2022-01-08 11:18:20,308 iteration 1984 : loss : 0.046608, loss_ce: 0.017955
2022-01-08 11:18:22,689 iteration 1985 : loss : 0.041832, loss_ce: 0.015927
2022-01-08 11:18:25,169 iteration 1986 : loss : 0.052965, loss_ce: 0.018506
2022-01-08 11:18:27,527 iteration 1987 : loss : 0.026672, loss_ce: 0.009320
2022-01-08 11:18:29,833 iteration 1988 : loss : 0.025307, loss_ce: 0.010536
2022-01-08 11:18:32,236 iteration 1989 : loss : 0.044787, loss_ce: 0.014078
 29%|███████▉                   | 117/400 [1:24:46<3:22:37, 42.96s/it]2022-01-08 11:18:34,678 iteration 1990 : loss : 0.034535, loss_ce: 0.008986
2022-01-08 11:18:36,991 iteration 1991 : loss : 0.027270, loss_ce: 0.010622
2022-01-08 11:18:39,364 iteration 1992 : loss : 0.032586, loss_ce: 0.011384
2022-01-08 11:18:41,644 iteration 1993 : loss : 0.033793, loss_ce: 0.012284
2022-01-08 11:18:43,899 iteration 1994 : loss : 0.061816, loss_ce: 0.029931
2022-01-08 11:18:46,096 iteration 1995 : loss : 0.031227, loss_ce: 0.012201
2022-01-08 11:18:48,453 iteration 1996 : loss : 0.024070, loss_ce: 0.010367
2022-01-08 11:18:50,788 iteration 1997 : loss : 0.027692, loss_ce: 0.011589
2022-01-08 11:18:53,160 iteration 1998 : loss : 0.029829, loss_ce: 0.012465
2022-01-08 11:18:55,549 iteration 1999 : loss : 0.033830, loss_ce: 0.013566
2022-01-08 11:18:57,931 iteration 2000 : loss : 0.036128, loss_ce: 0.016834
2022-01-08 11:19:00,300 iteration 2001 : loss : 0.039737, loss_ce: 0.014561
2022-01-08 11:19:02,740 iteration 2002 : loss : 0.032097, loss_ce: 0.013787
2022-01-08 11:19:05,159 iteration 2003 : loss : 0.036430, loss_ce: 0.011908
2022-01-08 11:19:07,579 iteration 2004 : loss : 0.030829, loss_ce: 0.014198
2022-01-08 11:19:09,908 iteration 2005 : loss : 0.031066, loss_ce: 0.013880
2022-01-08 11:19:12,294 iteration 2006 : loss : 0.028395, loss_ce: 0.009566
 30%|███████▉                   | 118/400 [1:25:27<3:17:48, 42.09s/it]2022-01-08 11:19:14,817 iteration 2007 : loss : 0.053610, loss_ce: 0.018564
2022-01-08 11:19:17,163 iteration 2008 : loss : 0.028455, loss_ce: 0.011712
2022-01-08 11:19:19,541 iteration 2009 : loss : 0.029899, loss_ce: 0.013442
2022-01-08 11:19:21,912 iteration 2010 : loss : 0.030141, loss_ce: 0.011404
2022-01-08 11:19:24,234 iteration 2011 : loss : 0.046786, loss_ce: 0.014767
2022-01-08 11:19:26,610 iteration 2012 : loss : 0.022140, loss_ce: 0.008169
2022-01-08 11:19:28,985 iteration 2013 : loss : 0.033643, loss_ce: 0.018394
2022-01-08 11:19:31,435 iteration 2014 : loss : 0.024535, loss_ce: 0.010241
2022-01-08 11:19:33,861 iteration 2015 : loss : 0.040499, loss_ce: 0.013431
2022-01-08 11:19:36,317 iteration 2016 : loss : 0.041634, loss_ce: 0.016927
2022-01-08 11:19:38,729 iteration 2017 : loss : 0.039179, loss_ce: 0.012845
2022-01-08 11:19:41,052 iteration 2018 : loss : 0.029064, loss_ce: 0.009618
2022-01-08 11:19:43,440 iteration 2019 : loss : 0.026370, loss_ce: 0.009403
2022-01-08 11:19:45,790 iteration 2020 : loss : 0.034519, loss_ce: 0.011491
2022-01-08 11:19:48,091 iteration 2021 : loss : 0.027536, loss_ce: 0.011073
2022-01-08 11:19:50,509 iteration 2022 : loss : 0.023660, loss_ce: 0.007795
2022-01-08 11:19:52,860 iteration 2023 : loss : 0.030672, loss_ce: 0.009900
 30%|████████                   | 119/400 [1:26:07<3:14:58, 41.63s/it]2022-01-08 11:19:55,206 iteration 2024 : loss : 0.046360, loss_ce: 0.023196
2022-01-08 11:19:57,557 iteration 2025 : loss : 0.073550, loss_ce: 0.027364
2022-01-08 11:19:59,871 iteration 2026 : loss : 0.029269, loss_ce: 0.010579
2022-01-08 11:20:02,173 iteration 2027 : loss : 0.036773, loss_ce: 0.011250
2022-01-08 11:20:04,515 iteration 2028 : loss : 0.025959, loss_ce: 0.011006
2022-01-08 11:20:06,862 iteration 2029 : loss : 0.039906, loss_ce: 0.012351
2022-01-08 11:20:09,214 iteration 2030 : loss : 0.023677, loss_ce: 0.008094
2022-01-08 11:20:11,575 iteration 2031 : loss : 0.039892, loss_ce: 0.014071
2022-01-08 11:20:14,116 iteration 2032 : loss : 0.031573, loss_ce: 0.014400
2022-01-08 11:20:16,429 iteration 2033 : loss : 0.023584, loss_ce: 0.009712
2022-01-08 11:20:18,755 iteration 2034 : loss : 0.031377, loss_ce: 0.010550
2022-01-08 11:20:21,103 iteration 2035 : loss : 0.044577, loss_ce: 0.017861
2022-01-08 11:20:23,342 iteration 2036 : loss : 0.036794, loss_ce: 0.015377
2022-01-08 11:20:25,575 iteration 2037 : loss : 0.043728, loss_ce: 0.018662
2022-01-08 11:20:28,057 iteration 2038 : loss : 0.054172, loss_ce: 0.014940
2022-01-08 11:20:30,398 iteration 2039 : loss : 0.034700, loss_ce: 0.011882
2022-01-08 11:20:30,399 Training Data Eval:
2022-01-08 11:20:42,774   Average segmentation loss on training set: 0.0237
2022-01-08 11:20:42,774 Validation Data Eval:
2022-01-08 11:20:47,370   Average segmentation loss on validation set: 0.0977
2022-01-08 11:20:49,885 iteration 2040 : loss : 0.036961, loss_ce: 0.015405
 30%|████████                   | 120/400 [1:27:04<3:35:50, 46.25s/it]2022-01-08 11:20:52,312 iteration 2041 : loss : 0.026614, loss_ce: 0.011593
2022-01-08 11:20:54,642 iteration 2042 : loss : 0.030228, loss_ce: 0.011245
2022-01-08 11:20:57,024 iteration 2043 : loss : 0.043725, loss_ce: 0.014623
2022-01-08 11:20:59,353 iteration 2044 : loss : 0.033088, loss_ce: 0.015195
2022-01-08 11:21:01,846 iteration 2045 : loss : 0.062055, loss_ce: 0.032534
2022-01-08 11:21:04,192 iteration 2046 : loss : 0.048710, loss_ce: 0.011158
2022-01-08 11:21:06,465 iteration 2047 : loss : 0.027367, loss_ce: 0.010568
2022-01-08 11:21:08,666 iteration 2048 : loss : 0.028125, loss_ce: 0.010354
2022-01-08 11:21:11,014 iteration 2049 : loss : 0.038860, loss_ce: 0.019358
2022-01-08 11:21:13,431 iteration 2050 : loss : 0.028641, loss_ce: 0.007458
2022-01-08 11:21:15,755 iteration 2051 : loss : 0.030011, loss_ce: 0.012773
2022-01-08 11:21:18,232 iteration 2052 : loss : 0.040839, loss_ce: 0.015477
2022-01-08 11:21:20,634 iteration 2053 : loss : 0.032028, loss_ce: 0.013624
2022-01-08 11:21:23,084 iteration 2054 : loss : 0.037249, loss_ce: 0.017866
2022-01-08 11:21:25,500 iteration 2055 : loss : 0.040503, loss_ce: 0.013632
2022-01-08 11:21:27,884 iteration 2056 : loss : 0.024385, loss_ce: 0.008463
2022-01-08 11:21:30,242 iteration 2057 : loss : 0.030191, loss_ce: 0.012962
 30%|████████▏                  | 121/400 [1:27:44<3:26:50, 44.48s/it]2022-01-08 11:21:32,680 iteration 2058 : loss : 0.027229, loss_ce: 0.012573
2022-01-08 11:21:35,149 iteration 2059 : loss : 0.035449, loss_ce: 0.014865
2022-01-08 11:21:37,617 iteration 2060 : loss : 0.028593, loss_ce: 0.010242
2022-01-08 11:21:39,998 iteration 2061 : loss : 0.032138, loss_ce: 0.017263
2022-01-08 11:21:42,362 iteration 2062 : loss : 0.049316, loss_ce: 0.017106
2022-01-08 11:21:44,873 iteration 2063 : loss : 0.036452, loss_ce: 0.013111
2022-01-08 11:21:47,197 iteration 2064 : loss : 0.040658, loss_ce: 0.015596
2022-01-08 11:21:49,581 iteration 2065 : loss : 0.051151, loss_ce: 0.019138
2022-01-08 11:21:52,034 iteration 2066 : loss : 0.030348, loss_ce: 0.012678
2022-01-08 11:21:54,458 iteration 2067 : loss : 0.042382, loss_ce: 0.014442
2022-01-08 11:21:56,753 iteration 2068 : loss : 0.025131, loss_ce: 0.009111
2022-01-08 11:21:59,084 iteration 2069 : loss : 0.046332, loss_ce: 0.021263
2022-01-08 11:22:01,523 iteration 2070 : loss : 0.040834, loss_ce: 0.016505
2022-01-08 11:22:03,946 iteration 2071 : loss : 0.028489, loss_ce: 0.011062
2022-01-08 11:22:06,369 iteration 2072 : loss : 0.037892, loss_ce: 0.016672
2022-01-08 11:22:08,830 iteration 2073 : loss : 0.038543, loss_ce: 0.015856
2022-01-08 11:22:11,307 iteration 2074 : loss : 0.031084, loss_ce: 0.008845
 30%|████████▏                  | 122/400 [1:28:26<3:21:20, 43.45s/it]2022-01-08 11:22:13,725 iteration 2075 : loss : 0.027735, loss_ce: 0.013273
2022-01-08 11:22:16,113 iteration 2076 : loss : 0.038116, loss_ce: 0.017201
2022-01-08 11:22:18,412 iteration 2077 : loss : 0.032902, loss_ce: 0.014737
2022-01-08 11:22:20,766 iteration 2078 : loss : 0.042358, loss_ce: 0.015902
2022-01-08 11:22:23,037 iteration 2079 : loss : 0.037480, loss_ce: 0.012648
2022-01-08 11:22:25,309 iteration 2080 : loss : 0.036328, loss_ce: 0.014008
2022-01-08 11:22:27,817 iteration 2081 : loss : 0.026438, loss_ce: 0.009156
2022-01-08 11:22:30,222 iteration 2082 : loss : 0.033200, loss_ce: 0.010216
2022-01-08 11:22:32,545 iteration 2083 : loss : 0.030451, loss_ce: 0.010104
2022-01-08 11:22:34,776 iteration 2084 : loss : 0.035415, loss_ce: 0.017294
2022-01-08 11:22:37,199 iteration 2085 : loss : 0.060851, loss_ce: 0.009926
2022-01-08 11:22:39,678 iteration 2086 : loss : 0.024375, loss_ce: 0.007635
2022-01-08 11:22:41,916 iteration 2087 : loss : 0.030525, loss_ce: 0.009811
2022-01-08 11:22:44,200 iteration 2088 : loss : 0.032249, loss_ce: 0.013007
2022-01-08 11:22:46,616 iteration 2089 : loss : 0.023612, loss_ce: 0.009130
2022-01-08 11:22:49,016 iteration 2090 : loss : 0.030311, loss_ce: 0.014027
2022-01-08 11:22:51,467 iteration 2091 : loss : 0.065516, loss_ce: 0.027223
 31%|████████▎                  | 123/400 [1:29:06<3:16:04, 42.47s/it]2022-01-08 11:22:53,801 iteration 2092 : loss : 0.032176, loss_ce: 0.010401
2022-01-08 11:22:56,053 iteration 2093 : loss : 0.023376, loss_ce: 0.009565
2022-01-08 11:22:58,368 iteration 2094 : loss : 0.035550, loss_ce: 0.012609
2022-01-08 11:23:00,825 iteration 2095 : loss : 0.052914, loss_ce: 0.023585
2022-01-08 11:23:03,048 iteration 2096 : loss : 0.029540, loss_ce: 0.012182
2022-01-08 11:23:05,377 iteration 2097 : loss : 0.063080, loss_ce: 0.020149
2022-01-08 11:23:07,612 iteration 2098 : loss : 0.031346, loss_ce: 0.012105
2022-01-08 11:23:09,854 iteration 2099 : loss : 0.028529, loss_ce: 0.011789
2022-01-08 11:23:12,154 iteration 2100 : loss : 0.030635, loss_ce: 0.011333
2022-01-08 11:23:14,407 iteration 2101 : loss : 0.028236, loss_ce: 0.009742
2022-01-08 11:23:16,790 iteration 2102 : loss : 0.033157, loss_ce: 0.013534
2022-01-08 11:23:19,060 iteration 2103 : loss : 0.036982, loss_ce: 0.018469
2022-01-08 11:23:21,386 iteration 2104 : loss : 0.028054, loss_ce: 0.010306
2022-01-08 11:23:23,839 iteration 2105 : loss : 0.047108, loss_ce: 0.022841
2022-01-08 11:23:26,231 iteration 2106 : loss : 0.033164, loss_ce: 0.011649
2022-01-08 11:23:28,522 iteration 2107 : loss : 0.032682, loss_ce: 0.010855
2022-01-08 11:23:30,743 iteration 2108 : loss : 0.030667, loss_ce: 0.011839
 31%|████████▎                  | 124/400 [1:29:45<3:10:57, 41.51s/it]2022-01-08 11:23:33,059 iteration 2109 : loss : 0.049890, loss_ce: 0.015940
2022-01-08 11:23:35,263 iteration 2110 : loss : 0.056657, loss_ce: 0.020568
2022-01-08 11:23:37,512 iteration 2111 : loss : 0.024952, loss_ce: 0.008393
2022-01-08 11:23:39,812 iteration 2112 : loss : 0.042525, loss_ce: 0.016246
2022-01-08 11:23:42,096 iteration 2113 : loss : 0.040771, loss_ce: 0.013437
2022-01-08 11:23:44,439 iteration 2114 : loss : 0.029768, loss_ce: 0.009568
2022-01-08 11:23:46,782 iteration 2115 : loss : 0.027618, loss_ce: 0.008758
2022-01-08 11:23:49,154 iteration 2116 : loss : 0.029414, loss_ce: 0.009096
2022-01-08 11:23:51,621 iteration 2117 : loss : 0.034375, loss_ce: 0.010259
2022-01-08 11:23:54,023 iteration 2118 : loss : 0.034581, loss_ce: 0.013332
2022-01-08 11:23:56,492 iteration 2119 : loss : 0.055510, loss_ce: 0.021515
2022-01-08 11:23:58,840 iteration 2120 : loss : 0.030850, loss_ce: 0.018641
2022-01-08 11:24:01,259 iteration 2121 : loss : 0.045398, loss_ce: 0.019952
2022-01-08 11:24:03,637 iteration 2122 : loss : 0.037718, loss_ce: 0.018469
2022-01-08 11:24:05,926 iteration 2123 : loss : 0.047225, loss_ce: 0.016195
2022-01-08 11:24:08,379 iteration 2124 : loss : 0.033290, loss_ce: 0.013312
2022-01-08 11:24:08,379 Training Data Eval:
2022-01-08 11:24:20,936   Average segmentation loss on training set: 0.0257
2022-01-08 11:24:20,937 Validation Data Eval:
2022-01-08 11:24:25,554   Average segmentation loss on validation set: 0.0643
2022-01-08 11:24:31,534 Found new lowest validation loss at iteration 2124! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed2.pth
2022-01-08 11:24:33,118 iteration 2125 : loss : 0.022086, loss_ce: 0.010916
 31%|████████▍                  | 125/400 [1:30:47<3:38:57, 47.77s/it]2022-01-08 11:24:34,852 iteration 2126 : loss : 0.071317, loss_ce: 0.021442
2022-01-08 11:24:36,428 iteration 2127 : loss : 0.023076, loss_ce: 0.009601
2022-01-08 11:24:38,177 iteration 2128 : loss : 0.022015, loss_ce: 0.009456
2022-01-08 11:24:40,234 iteration 2129 : loss : 0.043819, loss_ce: 0.016176
2022-01-08 11:24:42,321 iteration 2130 : loss : 0.032956, loss_ce: 0.012068
2022-01-08 11:24:44,331 iteration 2131 : loss : 0.024167, loss_ce: 0.008639
2022-01-08 11:24:46,475 iteration 2132 : loss : 0.028097, loss_ce: 0.007948
2022-01-08 11:24:48,625 iteration 2133 : loss : 0.031410, loss_ce: 0.013328
2022-01-08 11:24:50,915 iteration 2134 : loss : 0.041880, loss_ce: 0.013050
2022-01-08 11:24:53,051 iteration 2135 : loss : 0.026397, loss_ce: 0.008021
2022-01-08 11:24:55,292 iteration 2136 : loss : 0.045739, loss_ce: 0.019617
2022-01-08 11:24:57,493 iteration 2137 : loss : 0.030273, loss_ce: 0.013723
2022-01-08 11:24:59,882 iteration 2138 : loss : 0.038426, loss_ce: 0.011686
2022-01-08 11:25:02,127 iteration 2139 : loss : 0.034813, loss_ce: 0.017686
2022-01-08 11:25:04,477 iteration 2140 : loss : 0.034039, loss_ce: 0.018945
2022-01-08 11:25:06,838 iteration 2141 : loss : 0.030143, loss_ce: 0.010136
2022-01-08 11:25:09,177 iteration 2142 : loss : 0.067387, loss_ce: 0.023210
 32%|████████▌                  | 126/400 [1:31:23<3:22:06, 44.26s/it]2022-01-08 11:25:11,624 iteration 2143 : loss : 0.035650, loss_ce: 0.018483
2022-01-08 11:25:14,031 iteration 2144 : loss : 0.025685, loss_ce: 0.010482
2022-01-08 11:25:16,433 iteration 2145 : loss : 0.030538, loss_ce: 0.011729
2022-01-08 11:25:18,819 iteration 2146 : loss : 0.034381, loss_ce: 0.013944
2022-01-08 11:25:21,148 iteration 2147 : loss : 0.026104, loss_ce: 0.009236
2022-01-08 11:25:23,478 iteration 2148 : loss : 0.025122, loss_ce: 0.009571
2022-01-08 11:25:25,837 iteration 2149 : loss : 0.032791, loss_ce: 0.010754
2022-01-08 11:25:28,063 iteration 2150 : loss : 0.025687, loss_ce: 0.010014
2022-01-08 11:25:30,372 iteration 2151 : loss : 0.040104, loss_ce: 0.015492
2022-01-08 11:25:32,660 iteration 2152 : loss : 0.027246, loss_ce: 0.012835
2022-01-08 11:25:34,962 iteration 2153 : loss : 0.031296, loss_ce: 0.009014
2022-01-08 11:25:37,269 iteration 2154 : loss : 0.025092, loss_ce: 0.009372
2022-01-08 11:25:39,641 iteration 2155 : loss : 0.029150, loss_ce: 0.014139
2022-01-08 11:25:41,883 iteration 2156 : loss : 0.025407, loss_ce: 0.010181
2022-01-08 11:25:44,294 iteration 2157 : loss : 0.039026, loss_ce: 0.016313
2022-01-08 11:25:46,660 iteration 2158 : loss : 0.032055, loss_ce: 0.010848
2022-01-08 11:25:49,028 iteration 2159 : loss : 0.034199, loss_ce: 0.013271
 32%|████████▌                  | 127/400 [1:32:03<3:15:19, 42.93s/it]2022-01-08 11:25:51,409 iteration 2160 : loss : 0.036353, loss_ce: 0.012605
2022-01-08 11:25:53,806 iteration 2161 : loss : 0.051739, loss_ce: 0.025349
2022-01-08 11:25:56,092 iteration 2162 : loss : 0.030159, loss_ce: 0.011445
2022-01-08 11:25:58,268 iteration 2163 : loss : 0.041397, loss_ce: 0.013990
2022-01-08 11:26:00,623 iteration 2164 : loss : 0.037835, loss_ce: 0.013421
2022-01-08 11:26:02,916 iteration 2165 : loss : 0.026731, loss_ce: 0.011052
2022-01-08 11:26:05,214 iteration 2166 : loss : 0.036734, loss_ce: 0.010515
2022-01-08 11:26:07,566 iteration 2167 : loss : 0.024572, loss_ce: 0.008010
2022-01-08 11:26:10,065 iteration 2168 : loss : 0.027540, loss_ce: 0.010578
2022-01-08 11:26:12,449 iteration 2169 : loss : 0.030488, loss_ce: 0.011129
2022-01-08 11:26:14,705 iteration 2170 : loss : 0.054791, loss_ce: 0.026867
2022-01-08 11:26:17,078 iteration 2171 : loss : 0.044189, loss_ce: 0.014115
2022-01-08 11:26:19,494 iteration 2172 : loss : 0.033304, loss_ce: 0.010469
2022-01-08 11:26:21,740 iteration 2173 : loss : 0.033560, loss_ce: 0.010411
2022-01-08 11:26:24,047 iteration 2174 : loss : 0.023647, loss_ce: 0.011607
2022-01-08 11:26:26,450 iteration 2175 : loss : 0.033973, loss_ce: 0.014352
2022-01-08 11:26:28,909 iteration 2176 : loss : 0.033527, loss_ce: 0.014176
 32%|████████▋                  | 128/400 [1:32:43<3:10:29, 42.02s/it]2022-01-08 11:26:31,266 iteration 2177 : loss : 0.032858, loss_ce: 0.010350
2022-01-08 11:26:33,517 iteration 2178 : loss : 0.044943, loss_ce: 0.019778
2022-01-08 11:26:35,664 iteration 2179 : loss : 0.032268, loss_ce: 0.014876
2022-01-08 11:26:37,843 iteration 2180 : loss : 0.024350, loss_ce: 0.008730
2022-01-08 11:26:40,115 iteration 2181 : loss : 0.028763, loss_ce: 0.013392
2022-01-08 11:26:42,401 iteration 2182 : loss : 0.039402, loss_ce: 0.010168
2022-01-08 11:26:44,652 iteration 2183 : loss : 0.030532, loss_ce: 0.013427
2022-01-08 11:26:47,109 iteration 2184 : loss : 0.038588, loss_ce: 0.013365
2022-01-08 11:26:49,415 iteration 2185 : loss : 0.042430, loss_ce: 0.014783
2022-01-08 11:26:51,692 iteration 2186 : loss : 0.033496, loss_ce: 0.011039
2022-01-08 11:26:54,034 iteration 2187 : loss : 0.021475, loss_ce: 0.008557
2022-01-08 11:26:56,382 iteration 2188 : loss : 0.041779, loss_ce: 0.010133
2022-01-08 11:26:58,850 iteration 2189 : loss : 0.049609, loss_ce: 0.018129
2022-01-08 11:27:01,278 iteration 2190 : loss : 0.034301, loss_ce: 0.011730
2022-01-08 11:27:03,656 iteration 2191 : loss : 0.043277, loss_ce: 0.015020
2022-01-08 11:27:05,935 iteration 2192 : loss : 0.028954, loss_ce: 0.008510
2022-01-08 11:27:08,285 iteration 2193 : loss : 0.040964, loss_ce: 0.014555
 32%|████████▋                  | 129/400 [1:33:23<3:06:12, 41.23s/it]2022-01-08 11:27:10,746 iteration 2194 : loss : 0.058992, loss_ce: 0.029914
2022-01-08 11:27:13,027 iteration 2195 : loss : 0.039182, loss_ce: 0.012477
2022-01-08 11:27:15,316 iteration 2196 : loss : 0.032447, loss_ce: 0.011924
2022-01-08 11:27:17,581 iteration 2197 : loss : 0.028894, loss_ce: 0.013746
2022-01-08 11:27:19,837 iteration 2198 : loss : 0.033675, loss_ce: 0.014866
2022-01-08 11:27:22,110 iteration 2199 : loss : 0.035697, loss_ce: 0.016055
2022-01-08 11:27:24,469 iteration 2200 : loss : 0.047503, loss_ce: 0.016174
2022-01-08 11:27:26,899 iteration 2201 : loss : 0.026677, loss_ce: 0.010133
2022-01-08 11:27:29,336 iteration 2202 : loss : 0.082686, loss_ce: 0.021532
2022-01-08 11:27:31,697 iteration 2203 : loss : 0.044096, loss_ce: 0.023451
2022-01-08 11:27:33,964 iteration 2204 : loss : 0.033336, loss_ce: 0.015054
2022-01-08 11:27:36,243 iteration 2205 : loss : 0.028132, loss_ce: 0.011811
2022-01-08 11:27:38,547 iteration 2206 : loss : 0.050400, loss_ce: 0.019771
2022-01-08 11:27:40,965 iteration 2207 : loss : 0.046509, loss_ce: 0.016704
2022-01-08 11:27:43,409 iteration 2208 : loss : 0.042913, loss_ce: 0.013176
2022-01-08 11:27:45,735 iteration 2209 : loss : 0.039283, loss_ce: 0.014199
2022-01-08 11:27:45,735 Training Data Eval:
2022-01-08 11:27:58,485   Average segmentation loss on training set: 0.0352
2022-01-08 11:27:58,486 Validation Data Eval:
2022-01-08 11:28:02,989   Average segmentation loss on validation set: 0.1919
2022-01-08 11:28:05,376 iteration 2210 : loss : 0.037618, loss_ce: 0.013831
 32%|████████▊                  | 130/400 [1:34:20<3:26:56, 45.99s/it]2022-01-08 11:28:07,803 iteration 2211 : loss : 0.062842, loss_ce: 0.019946
2022-01-08 11:28:10,258 iteration 2212 : loss : 0.030003, loss_ce: 0.012559
2022-01-08 11:28:12,692 iteration 2213 : loss : 0.038562, loss_ce: 0.015845
2022-01-08 11:28:15,181 iteration 2214 : loss : 0.044705, loss_ce: 0.018878
2022-01-08 11:28:17,621 iteration 2215 : loss : 0.053618, loss_ce: 0.024876
2022-01-08 11:28:19,867 iteration 2216 : loss : 0.031368, loss_ce: 0.010315
2022-01-08 11:28:22,233 iteration 2217 : loss : 0.059658, loss_ce: 0.025340
2022-01-08 11:28:24,529 iteration 2218 : loss : 0.036531, loss_ce: 0.014480
2022-01-08 11:28:26,854 iteration 2219 : loss : 0.040070, loss_ce: 0.013588
2022-01-08 11:28:29,183 iteration 2220 : loss : 0.045554, loss_ce: 0.017387
2022-01-08 11:28:31,558 iteration 2221 : loss : 0.023639, loss_ce: 0.008106
2022-01-08 11:28:33,938 iteration 2222 : loss : 0.045108, loss_ce: 0.018069
2022-01-08 11:28:36,228 iteration 2223 : loss : 0.037413, loss_ce: 0.011642
2022-01-08 11:28:38,649 iteration 2224 : loss : 0.065708, loss_ce: 0.032118
2022-01-08 11:28:41,172 iteration 2225 : loss : 0.021697, loss_ce: 0.007695
2022-01-08 11:28:43,628 iteration 2226 : loss : 0.042673, loss_ce: 0.017325
2022-01-08 11:28:45,904 iteration 2227 : loss : 0.033118, loss_ce: 0.012372
 33%|████████▊                  | 131/400 [1:35:00<3:18:49, 44.35s/it]2022-01-08 11:28:48,276 iteration 2228 : loss : 0.027045, loss_ce: 0.012065
2022-01-08 11:28:50,531 iteration 2229 : loss : 0.032531, loss_ce: 0.012708
2022-01-08 11:28:52,795 iteration 2230 : loss : 0.032151, loss_ce: 0.009970
2022-01-08 11:28:54,930 iteration 2231 : loss : 0.018852, loss_ce: 0.007547
2022-01-08 11:28:57,177 iteration 2232 : loss : 0.037410, loss_ce: 0.014555
2022-01-08 11:28:59,396 iteration 2233 : loss : 0.044591, loss_ce: 0.017609
2022-01-08 11:29:01,647 iteration 2234 : loss : 0.032860, loss_ce: 0.011901
2022-01-08 11:29:03,902 iteration 2235 : loss : 0.046653, loss_ce: 0.010790
2022-01-08 11:29:06,298 iteration 2236 : loss : 0.047615, loss_ce: 0.022179
2022-01-08 11:29:08,552 iteration 2237 : loss : 0.036379, loss_ce: 0.016555
2022-01-08 11:29:10,790 iteration 2238 : loss : 0.037896, loss_ce: 0.020448
2022-01-08 11:29:13,057 iteration 2239 : loss : 0.032832, loss_ce: 0.010377
2022-01-08 11:29:15,403 iteration 2240 : loss : 0.032983, loss_ce: 0.011608
2022-01-08 11:29:17,744 iteration 2241 : loss : 0.038681, loss_ce: 0.011806
2022-01-08 11:29:20,081 iteration 2242 : loss : 0.026809, loss_ce: 0.009895
2022-01-08 11:29:22,494 iteration 2243 : loss : 0.041761, loss_ce: 0.011249
2022-01-08 11:29:24,924 iteration 2244 : loss : 0.035704, loss_ce: 0.014523
 33%|████████▉                  | 132/400 [1:35:39<3:10:56, 42.75s/it]2022-01-08 11:29:27,409 iteration 2245 : loss : 0.052966, loss_ce: 0.017485
2022-01-08 11:29:29,601 iteration 2246 : loss : 0.025315, loss_ce: 0.009911
2022-01-08 11:29:31,923 iteration 2247 : loss : 0.048607, loss_ce: 0.013117
2022-01-08 11:29:34,180 iteration 2248 : loss : 0.037119, loss_ce: 0.015061
2022-01-08 11:29:36,402 iteration 2249 : loss : 0.053883, loss_ce: 0.018798
2022-01-08 11:29:38,598 iteration 2250 : loss : 0.041727, loss_ce: 0.017432
2022-01-08 11:29:40,825 iteration 2251 : loss : 0.033942, loss_ce: 0.011797
2022-01-08 11:29:43,229 iteration 2252 : loss : 0.075354, loss_ce: 0.027390
2022-01-08 11:29:45,557 iteration 2253 : loss : 0.029142, loss_ce: 0.011448
2022-01-08 11:29:47,827 iteration 2254 : loss : 0.033235, loss_ce: 0.013819
2022-01-08 11:29:50,104 iteration 2255 : loss : 0.036968, loss_ce: 0.012470
2022-01-08 11:29:52,426 iteration 2256 : loss : 0.027245, loss_ce: 0.010667
2022-01-08 11:29:54,685 iteration 2257 : loss : 0.028309, loss_ce: 0.010144
2022-01-08 11:29:56,940 iteration 2258 : loss : 0.023929, loss_ce: 0.010418
2022-01-08 11:29:59,339 iteration 2259 : loss : 0.031883, loss_ce: 0.011034
2022-01-08 11:30:01,673 iteration 2260 : loss : 0.038774, loss_ce: 0.015719
2022-01-08 11:30:04,086 iteration 2261 : loss : 0.032213, loss_ce: 0.013393
 33%|████████▉                  | 133/400 [1:36:18<3:05:26, 41.67s/it]2022-01-08 11:30:06,476 iteration 2262 : loss : 0.031400, loss_ce: 0.013107
2022-01-08 11:30:08,755 iteration 2263 : loss : 0.025088, loss_ce: 0.010150
2022-01-08 11:30:11,108 iteration 2264 : loss : 0.041832, loss_ce: 0.018164
2022-01-08 11:30:13,496 iteration 2265 : loss : 0.023433, loss_ce: 0.008086
2022-01-08 11:30:15,831 iteration 2266 : loss : 0.024121, loss_ce: 0.006925
2022-01-08 11:30:18,102 iteration 2267 : loss : 0.021506, loss_ce: 0.008214
2022-01-08 11:30:20,429 iteration 2268 : loss : 0.029811, loss_ce: 0.011997
2022-01-08 11:30:22,783 iteration 2269 : loss : 0.031417, loss_ce: 0.015630
2022-01-08 11:30:25,134 iteration 2270 : loss : 0.020125, loss_ce: 0.007112
2022-01-08 11:30:27,459 iteration 2271 : loss : 0.045859, loss_ce: 0.015837
2022-01-08 11:30:29,826 iteration 2272 : loss : 0.055151, loss_ce: 0.024417
2022-01-08 11:30:32,187 iteration 2273 : loss : 0.034828, loss_ce: 0.014488
2022-01-08 11:30:34,611 iteration 2274 : loss : 0.030202, loss_ce: 0.012209
2022-01-08 11:30:36,972 iteration 2275 : loss : 0.037816, loss_ce: 0.014388
2022-01-08 11:30:39,323 iteration 2276 : loss : 0.037478, loss_ce: 0.017244
2022-01-08 11:30:41,776 iteration 2277 : loss : 0.031928, loss_ce: 0.010744
2022-01-08 11:30:44,197 iteration 2278 : loss : 0.053877, loss_ce: 0.021834
 34%|█████████                  | 134/400 [1:36:58<3:02:40, 41.20s/it]2022-01-08 11:30:46,506 iteration 2279 : loss : 0.021605, loss_ce: 0.007680
2022-01-08 11:30:48,968 iteration 2280 : loss : 0.031030, loss_ce: 0.014314
2022-01-08 11:30:51,379 iteration 2281 : loss : 0.042770, loss_ce: 0.012311
2022-01-08 11:30:53,739 iteration 2282 : loss : 0.034310, loss_ce: 0.011293
2022-01-08 11:30:56,120 iteration 2283 : loss : 0.036548, loss_ce: 0.008951
2022-01-08 11:30:58,347 iteration 2284 : loss : 0.031655, loss_ce: 0.016460
2022-01-08 11:31:00,697 iteration 2285 : loss : 0.034845, loss_ce: 0.016791
2022-01-08 11:31:03,044 iteration 2286 : loss : 0.042504, loss_ce: 0.019957
2022-01-08 11:31:05,431 iteration 2287 : loss : 0.022870, loss_ce: 0.006387
2022-01-08 11:31:07,793 iteration 2288 : loss : 0.043874, loss_ce: 0.012266
2022-01-08 11:31:10,201 iteration 2289 : loss : 0.029618, loss_ce: 0.012161
2022-01-08 11:31:12,577 iteration 2290 : loss : 0.043276, loss_ce: 0.016612
2022-01-08 11:31:15,070 iteration 2291 : loss : 0.032303, loss_ce: 0.012739
2022-01-08 11:31:17,469 iteration 2292 : loss : 0.037111, loss_ce: 0.013898
2022-01-08 11:31:19,826 iteration 2293 : loss : 0.047867, loss_ce: 0.017812
2022-01-08 11:31:22,189 iteration 2294 : loss : 0.030044, loss_ce: 0.015104
2022-01-08 11:31:22,189 Training Data Eval:
2022-01-08 11:31:35,118   Average segmentation loss on training set: 0.0315
2022-01-08 11:31:35,118 Validation Data Eval:
2022-01-08 11:31:39,734   Average segmentation loss on validation set: 0.0841
2022-01-08 11:31:42,148 iteration 2295 : loss : 0.044637, loss_ce: 0.015862
 34%|█████████                  | 135/400 [1:37:56<3:24:10, 46.23s/it]2022-01-08 11:31:44,525 iteration 2296 : loss : 0.026613, loss_ce: 0.010756
2022-01-08 11:31:46,912 iteration 2297 : loss : 0.024570, loss_ce: 0.008986
2022-01-08 11:31:49,205 iteration 2298 : loss : 0.036704, loss_ce: 0.012161
2022-01-08 11:31:51,627 iteration 2299 : loss : 0.050203, loss_ce: 0.013351
2022-01-08 11:31:53,910 iteration 2300 : loss : 0.045787, loss_ce: 0.020619
2022-01-08 11:31:56,263 iteration 2301 : loss : 0.029179, loss_ce: 0.011335
2022-01-08 11:31:58,655 iteration 2302 : loss : 0.034653, loss_ce: 0.012557
2022-01-08 11:32:01,085 iteration 2303 : loss : 0.038573, loss_ce: 0.012249
2022-01-08 11:32:03,542 iteration 2304 : loss : 0.035147, loss_ce: 0.013529
2022-01-08 11:32:05,916 iteration 2305 : loss : 0.032481, loss_ce: 0.015614
2022-01-08 11:32:08,232 iteration 2306 : loss : 0.030342, loss_ce: 0.011032
2022-01-08 11:32:10,642 iteration 2307 : loss : 0.032638, loss_ce: 0.015119
2022-01-08 11:32:12,946 iteration 2308 : loss : 0.028901, loss_ce: 0.011155
2022-01-08 11:32:15,445 iteration 2309 : loss : 0.041984, loss_ce: 0.018543
2022-01-08 11:32:17,894 iteration 2310 : loss : 0.039737, loss_ce: 0.019546
2022-01-08 11:32:20,213 iteration 2311 : loss : 0.037703, loss_ce: 0.012879
2022-01-08 11:32:22,540 iteration 2312 : loss : 0.023600, loss_ce: 0.008458
 34%|█████████▏                 | 136/400 [1:38:37<3:15:41, 44.48s/it]2022-01-08 11:32:25,001 iteration 2313 : loss : 0.033513, loss_ce: 0.011384
2022-01-08 11:32:27,413 iteration 2314 : loss : 0.031384, loss_ce: 0.009751
2022-01-08 11:32:29,852 iteration 2315 : loss : 0.030039, loss_ce: 0.008564
2022-01-08 11:32:32,193 iteration 2316 : loss : 0.029459, loss_ce: 0.010601
2022-01-08 11:32:34,654 iteration 2317 : loss : 0.032741, loss_ce: 0.008796
2022-01-08 11:32:37,115 iteration 2318 : loss : 0.040629, loss_ce: 0.021107
2022-01-08 11:32:39,547 iteration 2319 : loss : 0.037217, loss_ce: 0.014285
2022-01-08 11:32:41,949 iteration 2320 : loss : 0.029911, loss_ce: 0.014326
2022-01-08 11:32:44,214 iteration 2321 : loss : 0.032186, loss_ce: 0.009548
2022-01-08 11:32:46,592 iteration 2322 : loss : 0.035524, loss_ce: 0.016505
2022-01-08 11:32:48,924 iteration 2323 : loss : 0.032510, loss_ce: 0.014933
2022-01-08 11:32:51,299 iteration 2324 : loss : 0.035478, loss_ce: 0.013642
2022-01-08 11:32:53,810 iteration 2325 : loss : 0.031005, loss_ce: 0.012659
2022-01-08 11:32:56,209 iteration 2326 : loss : 0.032948, loss_ce: 0.015306
2022-01-08 11:32:58,560 iteration 2327 : loss : 0.027934, loss_ce: 0.010719
2022-01-08 11:33:01,026 iteration 2328 : loss : 0.039330, loss_ce: 0.021890
2022-01-08 11:33:03,392 iteration 2329 : loss : 0.020340, loss_ce: 0.008312
 34%|█████████▏                 | 137/400 [1:39:18<3:10:11, 43.39s/it]2022-01-08 11:33:05,850 iteration 2330 : loss : 0.021077, loss_ce: 0.008261
2022-01-08 11:33:08,223 iteration 2331 : loss : 0.032678, loss_ce: 0.015226
2022-01-08 11:33:10,628 iteration 2332 : loss : 0.056755, loss_ce: 0.024240
2022-01-08 11:33:12,957 iteration 2333 : loss : 0.027221, loss_ce: 0.012653
2022-01-08 11:33:15,261 iteration 2334 : loss : 0.029673, loss_ce: 0.012617
2022-01-08 11:33:17,591 iteration 2335 : loss : 0.032739, loss_ce: 0.009763
2022-01-08 11:33:19,956 iteration 2336 : loss : 0.056318, loss_ce: 0.012043
2022-01-08 11:33:22,583 iteration 2337 : loss : 0.033076, loss_ce: 0.014394
2022-01-08 11:33:24,989 iteration 2338 : loss : 0.024045, loss_ce: 0.007876
2022-01-08 11:33:27,366 iteration 2339 : loss : 0.041740, loss_ce: 0.013764
2022-01-08 11:33:29,779 iteration 2340 : loss : 0.035703, loss_ce: 0.015364
2022-01-08 11:33:32,036 iteration 2341 : loss : 0.024445, loss_ce: 0.005992
2022-01-08 11:33:34,483 iteration 2342 : loss : 0.032029, loss_ce: 0.013058
2022-01-08 11:33:36,944 iteration 2343 : loss : 0.044884, loss_ce: 0.016308
2022-01-08 11:33:39,425 iteration 2344 : loss : 0.039075, loss_ce: 0.015921
2022-01-08 11:33:41,880 iteration 2345 : loss : 0.033267, loss_ce: 0.010707
2022-01-08 11:33:44,233 iteration 2346 : loss : 0.050520, loss_ce: 0.024726
 34%|█████████▎                 | 138/400 [1:39:58<3:06:06, 42.62s/it]2022-01-08 11:33:46,544 iteration 2347 : loss : 0.032187, loss_ce: 0.010737
2022-01-08 11:33:48,888 iteration 2348 : loss : 0.033039, loss_ce: 0.011629
2022-01-08 11:33:51,298 iteration 2349 : loss : 0.027107, loss_ce: 0.010997
2022-01-08 11:33:53,594 iteration 2350 : loss : 0.034272, loss_ce: 0.011650
2022-01-08 11:33:55,974 iteration 2351 : loss : 0.095445, loss_ce: 0.020271
2022-01-08 11:33:58,370 iteration 2352 : loss : 0.027968, loss_ce: 0.009921
2022-01-08 11:34:00,734 iteration 2353 : loss : 0.035745, loss_ce: 0.014935
2022-01-08 11:34:03,046 iteration 2354 : loss : 0.035911, loss_ce: 0.014403
2022-01-08 11:34:05,329 iteration 2355 : loss : 0.022600, loss_ce: 0.008276
2022-01-08 11:34:07,742 iteration 2356 : loss : 0.026993, loss_ce: 0.009092
2022-01-08 11:34:10,128 iteration 2357 : loss : 0.038547, loss_ce: 0.012031
2022-01-08 11:34:12,524 iteration 2358 : loss : 0.035793, loss_ce: 0.015472
2022-01-08 11:34:14,968 iteration 2359 : loss : 0.035542, loss_ce: 0.016030
2022-01-08 11:34:17,490 iteration 2360 : loss : 0.034498, loss_ce: 0.013273
2022-01-08 11:34:19,916 iteration 2361 : loss : 0.038191, loss_ce: 0.013980
2022-01-08 11:34:22,364 iteration 2362 : loss : 0.081359, loss_ce: 0.042238
2022-01-08 11:34:24,725 iteration 2363 : loss : 0.026673, loss_ce: 0.011762
 35%|█████████▍                 | 139/400 [1:40:39<3:02:37, 41.98s/it]2022-01-08 11:34:27,080 iteration 2364 : loss : 0.058741, loss_ce: 0.012220
2022-01-08 11:34:29,403 iteration 2365 : loss : 0.042309, loss_ce: 0.010882
2022-01-08 11:34:31,842 iteration 2366 : loss : 0.032734, loss_ce: 0.013932
2022-01-08 11:34:34,190 iteration 2367 : loss : 0.043135, loss_ce: 0.020070
2022-01-08 11:34:36,581 iteration 2368 : loss : 0.029216, loss_ce: 0.011277
2022-01-08 11:34:38,992 iteration 2369 : loss : 0.048017, loss_ce: 0.019666
2022-01-08 11:34:41,251 iteration 2370 : loss : 0.040469, loss_ce: 0.015004
2022-01-08 11:34:43,613 iteration 2371 : loss : 0.031898, loss_ce: 0.013008
2022-01-08 11:34:46,143 iteration 2372 : loss : 0.031604, loss_ce: 0.011603
2022-01-08 11:34:48,520 iteration 2373 : loss : 0.025045, loss_ce: 0.010019
2022-01-08 11:34:50,842 iteration 2374 : loss : 0.025967, loss_ce: 0.009667
2022-01-08 11:34:53,181 iteration 2375 : loss : 0.045570, loss_ce: 0.012148
2022-01-08 11:34:55,492 iteration 2376 : loss : 0.031388, loss_ce: 0.011482
2022-01-08 11:34:58,002 iteration 2377 : loss : 0.023926, loss_ce: 0.007618
2022-01-08 11:35:00,381 iteration 2378 : loss : 0.022099, loss_ce: 0.008209
2022-01-08 11:35:02,706 iteration 2379 : loss : 0.055400, loss_ce: 0.032859
2022-01-08 11:35:02,707 Training Data Eval:
2022-01-08 11:35:15,636   Average segmentation loss on training set: 0.0247
2022-01-08 11:35:15,637 Validation Data Eval:
2022-01-08 11:35:19,978   Average segmentation loss on validation set: 0.0848
2022-01-08 11:35:22,348 iteration 2380 : loss : 0.027311, loss_ce: 0.012869
 35%|█████████▍                 | 140/400 [1:41:37<3:22:16, 46.68s/it]2022-01-08 11:35:24,807 iteration 2381 : loss : 0.054654, loss_ce: 0.016479
2022-01-08 11:35:27,165 iteration 2382 : loss : 0.027063, loss_ce: 0.009531
2022-01-08 11:35:29,502 iteration 2383 : loss : 0.033594, loss_ce: 0.011678
2022-01-08 11:35:31,827 iteration 2384 : loss : 0.027527, loss_ce: 0.008944
2022-01-08 11:35:34,281 iteration 2385 : loss : 0.029203, loss_ce: 0.010152
2022-01-08 11:35:36,751 iteration 2386 : loss : 0.039671, loss_ce: 0.011261
2022-01-08 11:35:39,186 iteration 2387 : loss : 0.022809, loss_ce: 0.008529
2022-01-08 11:35:41,587 iteration 2388 : loss : 0.030504, loss_ce: 0.014642
2022-01-08 11:35:43,938 iteration 2389 : loss : 0.024376, loss_ce: 0.008478
2022-01-08 11:35:46,294 iteration 2390 : loss : 0.023841, loss_ce: 0.009602
2022-01-08 11:35:48,643 iteration 2391 : loss : 0.029891, loss_ce: 0.011518
2022-01-08 11:35:51,169 iteration 2392 : loss : 0.055269, loss_ce: 0.012226
2022-01-08 11:35:53,598 iteration 2393 : loss : 0.034353, loss_ce: 0.014114
2022-01-08 11:35:55,997 iteration 2394 : loss : 0.038155, loss_ce: 0.014374
2022-01-08 11:35:58,483 iteration 2395 : loss : 0.065394, loss_ce: 0.028701
2022-01-08 11:36:00,989 iteration 2396 : loss : 0.028907, loss_ce: 0.012764
2022-01-08 11:36:03,453 iteration 2397 : loss : 0.030026, loss_ce: 0.015078
 35%|█████████▌                 | 141/400 [1:42:18<3:14:17, 45.01s/it]2022-01-08 11:36:05,786 iteration 2398 : loss : 0.023924, loss_ce: 0.012042
2022-01-08 11:36:08,131 iteration 2399 : loss : 0.033526, loss_ce: 0.015257
2022-01-08 11:36:10,362 iteration 2400 : loss : 0.037202, loss_ce: 0.016441
2022-01-08 11:36:12,800 iteration 2401 : loss : 0.046707, loss_ce: 0.014940
2022-01-08 11:36:15,079 iteration 2402 : loss : 0.048630, loss_ce: 0.018115
2022-01-08 11:36:17,372 iteration 2403 : loss : 0.031212, loss_ce: 0.012124
2022-01-08 11:36:19,671 iteration 2404 : loss : 0.026138, loss_ce: 0.008392
2022-01-08 11:36:21,994 iteration 2405 : loss : 0.041378, loss_ce: 0.014784
2022-01-08 11:36:24,243 iteration 2406 : loss : 0.038387, loss_ce: 0.016510
2022-01-08 11:36:26,651 iteration 2407 : loss : 0.026606, loss_ce: 0.009069
2022-01-08 11:36:29,105 iteration 2408 : loss : 0.043468, loss_ce: 0.014943
2022-01-08 11:36:31,385 iteration 2409 : loss : 0.026983, loss_ce: 0.010812
2022-01-08 11:36:33,735 iteration 2410 : loss : 0.039443, loss_ce: 0.014865
2022-01-08 11:36:36,169 iteration 2411 : loss : 0.025211, loss_ce: 0.009994
2022-01-08 11:36:38,554 iteration 2412 : loss : 0.030871, loss_ce: 0.011467
2022-01-08 11:36:40,920 iteration 2413 : loss : 0.030333, loss_ce: 0.012568
2022-01-08 11:36:43,310 iteration 2414 : loss : 0.024493, loss_ce: 0.009946
 36%|█████████▌                 | 142/400 [1:42:58<3:06:53, 43.46s/it]2022-01-08 11:36:45,830 iteration 2415 : loss : 0.031232, loss_ce: 0.009627
2022-01-08 11:36:48,176 iteration 2416 : loss : 0.027955, loss_ce: 0.011721
2022-01-08 11:36:50,556 iteration 2417 : loss : 0.031951, loss_ce: 0.015662
2022-01-08 11:36:52,921 iteration 2418 : loss : 0.035238, loss_ce: 0.010360
2022-01-08 11:36:55,311 iteration 2419 : loss : 0.045867, loss_ce: 0.015125
2022-01-08 11:36:57,684 iteration 2420 : loss : 0.036539, loss_ce: 0.019550
2022-01-08 11:36:59,959 iteration 2421 : loss : 0.028191, loss_ce: 0.012752
2022-01-08 11:37:02,352 iteration 2422 : loss : 0.035079, loss_ce: 0.015419
2022-01-08 11:37:04,660 iteration 2423 : loss : 0.028209, loss_ce: 0.012513
2022-01-08 11:37:07,087 iteration 2424 : loss : 0.029728, loss_ce: 0.010957
2022-01-08 11:37:09,503 iteration 2425 : loss : 0.025334, loss_ce: 0.007870
2022-01-08 11:37:11,839 iteration 2426 : loss : 0.032635, loss_ce: 0.011198
2022-01-08 11:37:14,087 iteration 2427 : loss : 0.034352, loss_ce: 0.013872
2022-01-08 11:37:16,428 iteration 2428 : loss : 0.031201, loss_ce: 0.010066
2022-01-08 11:37:18,774 iteration 2429 : loss : 0.054126, loss_ce: 0.014712
2022-01-08 11:37:21,195 iteration 2430 : loss : 0.031283, loss_ce: 0.013426
2022-01-08 11:37:23,607 iteration 2431 : loss : 0.027228, loss_ce: 0.008142
 36%|█████████▋                 | 143/400 [1:43:38<3:02:05, 42.51s/it]2022-01-08 11:37:25,971 iteration 2432 : loss : 0.028234, loss_ce: 0.009562
2022-01-08 11:37:28,300 iteration 2433 : loss : 0.023554, loss_ce: 0.010047
2022-01-08 11:37:30,678 iteration 2434 : loss : 0.041042, loss_ce: 0.016655
2022-01-08 11:37:33,002 iteration 2435 : loss : 0.025622, loss_ce: 0.011327
2022-01-08 11:37:35,443 iteration 2436 : loss : 0.027781, loss_ce: 0.010842
2022-01-08 11:37:37,746 iteration 2437 : loss : 0.025408, loss_ce: 0.009751
2022-01-08 11:37:39,984 iteration 2438 : loss : 0.036851, loss_ce: 0.019091
2022-01-08 11:37:42,284 iteration 2439 : loss : 0.033096, loss_ce: 0.012535
2022-01-08 11:37:44,623 iteration 2440 : loss : 0.033604, loss_ce: 0.012453
2022-01-08 11:37:47,001 iteration 2441 : loss : 0.052128, loss_ce: 0.016925
2022-01-08 11:37:49,335 iteration 2442 : loss : 0.026783, loss_ce: 0.009044
2022-01-08 11:37:51,612 iteration 2443 : loss : 0.035986, loss_ce: 0.012404
2022-01-08 11:37:54,121 iteration 2444 : loss : 0.045222, loss_ce: 0.019472
2022-01-08 11:37:56,622 iteration 2445 : loss : 0.042595, loss_ce: 0.020674
2022-01-08 11:37:58,942 iteration 2446 : loss : 0.032791, loss_ce: 0.013728
2022-01-08 11:38:01,274 iteration 2447 : loss : 0.039169, loss_ce: 0.015591
2022-01-08 11:38:03,493 iteration 2448 : loss : 0.052404, loss_ce: 0.025577
 36%|█████████▋                 | 144/400 [1:44:18<2:58:02, 41.73s/it]2022-01-08 11:38:05,858 iteration 2449 : loss : 0.021829, loss_ce: 0.007310
2022-01-08 11:38:08,095 iteration 2450 : loss : 0.038380, loss_ce: 0.014214
2022-01-08 11:38:10,426 iteration 2451 : loss : 0.022191, loss_ce: 0.007877
2022-01-08 11:38:12,816 iteration 2452 : loss : 0.029881, loss_ce: 0.013328
2022-01-08 11:38:15,197 iteration 2453 : loss : 0.029127, loss_ce: 0.013701
2022-01-08 11:38:17,735 iteration 2454 : loss : 0.035436, loss_ce: 0.013283
2022-01-08 11:38:20,210 iteration 2455 : loss : 0.050668, loss_ce: 0.017086
2022-01-08 11:38:22,531 iteration 2456 : loss : 0.027473, loss_ce: 0.012463
2022-01-08 11:38:24,771 iteration 2457 : loss : 0.031486, loss_ce: 0.015987
2022-01-08 11:38:27,083 iteration 2458 : loss : 0.032328, loss_ce: 0.010387
2022-01-08 11:38:29,451 iteration 2459 : loss : 0.027076, loss_ce: 0.009290
2022-01-08 11:38:31,850 iteration 2460 : loss : 0.046097, loss_ce: 0.012703
2022-01-08 11:38:34,181 iteration 2461 : loss : 0.049412, loss_ce: 0.012568
2022-01-08 11:38:36,533 iteration 2462 : loss : 0.031499, loss_ce: 0.013282
2022-01-08 11:38:38,807 iteration 2463 : loss : 0.027450, loss_ce: 0.010681
2022-01-08 11:38:41,099 iteration 2464 : loss : 0.037811, loss_ce: 0.023905
2022-01-08 11:38:41,099 Training Data Eval:
2022-01-08 11:38:53,682   Average segmentation loss on training set: 0.0218
2022-01-08 11:38:53,683 Validation Data Eval:
2022-01-08 11:38:58,167   Average segmentation loss on validation set: 0.1167
2022-01-08 11:39:00,612 iteration 2465 : loss : 0.027005, loss_ce: 0.011877
 36%|█████████▊                 | 145/400 [1:45:15<3:16:56, 46.34s/it]2022-01-08 11:39:03,092 iteration 2466 : loss : 0.047534, loss_ce: 0.018404
2022-01-08 11:39:05,442 iteration 2467 : loss : 0.023073, loss_ce: 0.008672
2022-01-08 11:39:07,930 iteration 2468 : loss : 0.037860, loss_ce: 0.014888
2022-01-08 11:39:10,326 iteration 2469 : loss : 0.024800, loss_ce: 0.010773
2022-01-08 11:39:12,744 iteration 2470 : loss : 0.032418, loss_ce: 0.012799
2022-01-08 11:39:15,065 iteration 2471 : loss : 0.039580, loss_ce: 0.018859
2022-01-08 11:39:17,349 iteration 2472 : loss : 0.034090, loss_ce: 0.014572
2022-01-08 11:39:19,584 iteration 2473 : loss : 0.038041, loss_ce: 0.016614
2022-01-08 11:39:21,806 iteration 2474 : loss : 0.028957, loss_ce: 0.011433
2022-01-08 11:39:24,188 iteration 2475 : loss : 0.039342, loss_ce: 0.021255
2022-01-08 11:39:26,502 iteration 2476 : loss : 0.063811, loss_ce: 0.022489
2022-01-08 11:39:28,906 iteration 2477 : loss : 0.041197, loss_ce: 0.014296
2022-01-08 11:39:31,274 iteration 2478 : loss : 0.031938, loss_ce: 0.009838
2022-01-08 11:39:33,665 iteration 2479 : loss : 0.029731, loss_ce: 0.008519
2022-01-08 11:39:35,951 iteration 2480 : loss : 0.024891, loss_ce: 0.008842
2022-01-08 11:39:38,303 iteration 2481 : loss : 0.023818, loss_ce: 0.009219
2022-01-08 11:39:40,797 iteration 2482 : loss : 0.063205, loss_ce: 0.023490
 36%|█████████▊                 | 146/400 [1:45:55<3:08:20, 44.49s/it]2022-01-08 11:39:43,128 iteration 2483 : loss : 0.058027, loss_ce: 0.022163
2022-01-08 11:39:45,488 iteration 2484 : loss : 0.072150, loss_ce: 0.014541
2022-01-08 11:39:47,970 iteration 2485 : loss : 0.038956, loss_ce: 0.013636
2022-01-08 11:39:50,368 iteration 2486 : loss : 0.029064, loss_ce: 0.011991
2022-01-08 11:39:52,674 iteration 2487 : loss : 0.025564, loss_ce: 0.010324
2022-01-08 11:39:55,084 iteration 2488 : loss : 0.029807, loss_ce: 0.015022
2022-01-08 11:39:57,370 iteration 2489 : loss : 0.041301, loss_ce: 0.016750
2022-01-08 11:39:59,634 iteration 2490 : loss : 0.035429, loss_ce: 0.017072
2022-01-08 11:40:01,872 iteration 2491 : loss : 0.038276, loss_ce: 0.011095
2022-01-08 11:40:04,216 iteration 2492 : loss : 0.053639, loss_ce: 0.020159
2022-01-08 11:40:06,550 iteration 2493 : loss : 0.025382, loss_ce: 0.009347
2022-01-08 11:40:08,897 iteration 2494 : loss : 0.035492, loss_ce: 0.012675
2022-01-08 11:40:11,265 iteration 2495 : loss : 0.027058, loss_ce: 0.010948
2022-01-08 11:40:13,449 iteration 2496 : loss : 0.023630, loss_ce: 0.008264
2022-01-08 11:40:15,740 iteration 2497 : loss : 0.025847, loss_ce: 0.008649
2022-01-08 11:40:18,273 iteration 2498 : loss : 0.059890, loss_ce: 0.029263
2022-01-08 11:40:20,836 iteration 2499 : loss : 0.037324, loss_ce: 0.019191
 37%|█████████▉                 | 147/400 [1:46:35<3:01:59, 43.16s/it]2022-01-08 11:40:23,302 iteration 2500 : loss : 0.032348, loss_ce: 0.010961
2022-01-08 11:40:25,669 iteration 2501 : loss : 0.024212, loss_ce: 0.009331
2022-01-08 11:40:27,998 iteration 2502 : loss : 0.041284, loss_ce: 0.022504
2022-01-08 11:40:30,330 iteration 2503 : loss : 0.023304, loss_ce: 0.011415
2022-01-08 11:40:32,659 iteration 2504 : loss : 0.035488, loss_ce: 0.012844
2022-01-08 11:40:34,986 iteration 2505 : loss : 0.031266, loss_ce: 0.010428
2022-01-08 11:40:37,363 iteration 2506 : loss : 0.026226, loss_ce: 0.010836
2022-01-08 11:40:39,702 iteration 2507 : loss : 0.019018, loss_ce: 0.006333
2022-01-08 11:40:41,971 iteration 2508 : loss : 0.024986, loss_ce: 0.010341
2022-01-08 11:40:44,323 iteration 2509 : loss : 0.027458, loss_ce: 0.012862
2022-01-08 11:40:46,604 iteration 2510 : loss : 0.047771, loss_ce: 0.015463
2022-01-08 11:40:48,882 iteration 2511 : loss : 0.027015, loss_ce: 0.012037
2022-01-08 11:40:51,213 iteration 2512 : loss : 0.030320, loss_ce: 0.012842
2022-01-08 11:40:53,587 iteration 2513 : loss : 0.031743, loss_ce: 0.011552
2022-01-08 11:40:55,954 iteration 2514 : loss : 0.030382, loss_ce: 0.011321
2022-01-08 11:40:58,308 iteration 2515 : loss : 0.026209, loss_ce: 0.007326
2022-01-08 11:41:00,612 iteration 2516 : loss : 0.029942, loss_ce: 0.012140
 37%|█████████▉                 | 148/400 [1:47:15<2:56:59, 42.14s/it]2022-01-08 11:41:02,968 iteration 2517 : loss : 0.025897, loss_ce: 0.008525
2022-01-08 11:41:05,381 iteration 2518 : loss : 0.032091, loss_ce: 0.012410
2022-01-08 11:41:07,775 iteration 2519 : loss : 0.024910, loss_ce: 0.009341
2022-01-08 11:41:10,163 iteration 2520 : loss : 0.022730, loss_ce: 0.007074
2022-01-08 11:41:12,560 iteration 2521 : loss : 0.024232, loss_ce: 0.011816
2022-01-08 11:41:14,973 iteration 2522 : loss : 0.024566, loss_ce: 0.009270
2022-01-08 11:41:17,277 iteration 2523 : loss : 0.026294, loss_ce: 0.006230
2022-01-08 11:41:19,690 iteration 2524 : loss : 0.023341, loss_ce: 0.010874
2022-01-08 11:41:21,952 iteration 2525 : loss : 0.027072, loss_ce: 0.012020
2022-01-08 11:41:24,254 iteration 2526 : loss : 0.026794, loss_ce: 0.010295
2022-01-08 11:41:26,636 iteration 2527 : loss : 0.027631, loss_ce: 0.008884
2022-01-08 11:41:28,900 iteration 2528 : loss : 0.028397, loss_ce: 0.011321
2022-01-08 11:41:31,214 iteration 2529 : loss : 0.025956, loss_ce: 0.010644
2022-01-08 11:41:33,470 iteration 2530 : loss : 0.021913, loss_ce: 0.005787
2022-01-08 11:41:35,825 iteration 2531 : loss : 0.027198, loss_ce: 0.009976
2022-01-08 11:41:38,218 iteration 2532 : loss : 0.033211, loss_ce: 0.011845
2022-01-08 11:41:40,567 iteration 2533 : loss : 0.029793, loss_ce: 0.016203
 37%|██████████                 | 149/400 [1:47:55<2:53:33, 41.49s/it]2022-01-08 11:41:42,895 iteration 2534 : loss : 0.019726, loss_ce: 0.008555
2022-01-08 11:41:45,336 iteration 2535 : loss : 0.023436, loss_ce: 0.006661
2022-01-08 11:41:47,718 iteration 2536 : loss : 0.032776, loss_ce: 0.014486
2022-01-08 11:41:50,026 iteration 2537 : loss : 0.036530, loss_ce: 0.012795
2022-01-08 11:41:52,307 iteration 2538 : loss : 0.072347, loss_ce: 0.027328
2022-01-08 11:41:54,658 iteration 2539 : loss : 0.022159, loss_ce: 0.008812
2022-01-08 11:41:57,068 iteration 2540 : loss : 0.031955, loss_ce: 0.013051
2022-01-08 11:41:59,546 iteration 2541 : loss : 0.049282, loss_ce: 0.012985
2022-01-08 11:42:01,815 iteration 2542 : loss : 0.026713, loss_ce: 0.009745
2022-01-08 11:42:04,119 iteration 2543 : loss : 0.025456, loss_ce: 0.009010
2022-01-08 11:42:06,532 iteration 2544 : loss : 0.031877, loss_ce: 0.013474
2022-01-08 11:42:08,849 iteration 2545 : loss : 0.042196, loss_ce: 0.022017
2022-01-08 11:42:11,120 iteration 2546 : loss : 0.030001, loss_ce: 0.010991
2022-01-08 11:42:13,415 iteration 2547 : loss : 0.047797, loss_ce: 0.011803
2022-01-08 11:42:15,698 iteration 2548 : loss : 0.027054, loss_ce: 0.010575
2022-01-08 11:42:18,055 iteration 2549 : loss : 0.045515, loss_ce: 0.013106
2022-01-08 11:42:18,055 Training Data Eval:
2022-01-08 11:42:30,486   Average segmentation loss on training set: 0.0229
2022-01-08 11:42:30,486 Validation Data Eval:
2022-01-08 11:42:34,968   Average segmentation loss on validation set: 0.0948
2022-01-08 11:42:37,323 iteration 2550 : loss : 0.034145, loss_ce: 0.018279
 38%|██████████▏                | 150/400 [1:48:52<3:11:56, 46.07s/it]2022-01-08 11:42:39,659 iteration 2551 : loss : 0.022758, loss_ce: 0.007892
2022-01-08 11:42:42,076 iteration 2552 : loss : 0.022035, loss_ce: 0.008660
2022-01-08 11:42:44,499 iteration 2553 : loss : 0.031714, loss_ce: 0.012671
2022-01-08 11:42:46,909 iteration 2554 : loss : 0.056573, loss_ce: 0.014463
2022-01-08 11:42:49,231 iteration 2555 : loss : 0.028549, loss_ce: 0.008377
2022-01-08 11:42:51,473 iteration 2556 : loss : 0.023062, loss_ce: 0.010527
2022-01-08 11:42:53,813 iteration 2557 : loss : 0.036803, loss_ce: 0.014771
2022-01-08 11:42:56,202 iteration 2558 : loss : 0.026619, loss_ce: 0.011303
2022-01-08 11:42:58,500 iteration 2559 : loss : 0.043510, loss_ce: 0.011267
2022-01-08 11:43:00,787 iteration 2560 : loss : 0.031705, loss_ce: 0.012454
2022-01-08 11:43:03,017 iteration 2561 : loss : 0.027210, loss_ce: 0.010765
2022-01-08 11:43:05,206 iteration 2562 : loss : 0.026361, loss_ce: 0.013867
2022-01-08 11:43:07,446 iteration 2563 : loss : 0.031449, loss_ce: 0.010388
2022-01-08 11:43:09,778 iteration 2564 : loss : 0.027337, loss_ce: 0.012563
2022-01-08 11:43:12,190 iteration 2565 : loss : 0.035832, loss_ce: 0.011166
2022-01-08 11:43:14,506 iteration 2566 : loss : 0.022500, loss_ce: 0.009966
2022-01-08 11:43:16,894 iteration 2567 : loss : 0.036267, loss_ce: 0.015779
 38%|██████████▏                | 151/400 [1:49:31<3:03:06, 44.12s/it]2022-01-08 11:43:19,340 iteration 2568 : loss : 0.024550, loss_ce: 0.012230
2022-01-08 11:43:21,728 iteration 2569 : loss : 0.027133, loss_ce: 0.010867
2022-01-08 11:43:24,041 iteration 2570 : loss : 0.038608, loss_ce: 0.010635
2022-01-08 11:43:26,375 iteration 2571 : loss : 0.048846, loss_ce: 0.018832
2022-01-08 11:43:28,760 iteration 2572 : loss : 0.026602, loss_ce: 0.008562
2022-01-08 11:43:31,111 iteration 2573 : loss : 0.039927, loss_ce: 0.018512
2022-01-08 11:43:33,461 iteration 2574 : loss : 0.033827, loss_ce: 0.010146
2022-01-08 11:43:35,856 iteration 2575 : loss : 0.032512, loss_ce: 0.011518
2022-01-08 11:43:38,306 iteration 2576 : loss : 0.033142, loss_ce: 0.016324
2022-01-08 11:43:40,599 iteration 2577 : loss : 0.029970, loss_ce: 0.010155
2022-01-08 11:43:43,157 iteration 2578 : loss : 0.029799, loss_ce: 0.015773
2022-01-08 11:43:45,542 iteration 2579 : loss : 0.028480, loss_ce: 0.009753
2022-01-08 11:43:47,919 iteration 2580 : loss : 0.027360, loss_ce: 0.008197
2022-01-08 11:43:50,307 iteration 2581 : loss : 0.033784, loss_ce: 0.011437
2022-01-08 11:43:52,543 iteration 2582 : loss : 0.027509, loss_ce: 0.011792
2022-01-08 11:43:54,867 iteration 2583 : loss : 0.020382, loss_ce: 0.006442
2022-01-08 11:43:57,094 iteration 2584 : loss : 0.026355, loss_ce: 0.011642
 38%|██████████▎                | 152/400 [1:50:11<2:57:29, 42.94s/it]2022-01-08 11:43:59,407 iteration 2585 : loss : 0.029241, loss_ce: 0.012792
2022-01-08 11:44:01,750 iteration 2586 : loss : 0.038715, loss_ce: 0.016255
2022-01-08 11:44:04,102 iteration 2587 : loss : 0.023003, loss_ce: 0.007050
2022-01-08 11:44:06,463 iteration 2588 : loss : 0.024318, loss_ce: 0.010202
2022-01-08 11:44:08,807 iteration 2589 : loss : 0.022980, loss_ce: 0.009448
2022-01-08 11:44:11,232 iteration 2590 : loss : 0.026412, loss_ce: 0.009555
2022-01-08 11:44:13,576 iteration 2591 : loss : 0.024924, loss_ce: 0.010742
2022-01-08 11:44:15,923 iteration 2592 : loss : 0.024404, loss_ce: 0.009600
2022-01-08 11:44:18,276 iteration 2593 : loss : 0.026490, loss_ce: 0.008412
2022-01-08 11:44:20,691 iteration 2594 : loss : 0.030858, loss_ce: 0.011727
2022-01-08 11:44:23,112 iteration 2595 : loss : 0.047909, loss_ce: 0.014279
2022-01-08 11:44:25,461 iteration 2596 : loss : 0.023004, loss_ce: 0.007258
2022-01-08 11:44:27,849 iteration 2597 : loss : 0.051493, loss_ce: 0.018417
2022-01-08 11:44:30,156 iteration 2598 : loss : 0.025433, loss_ce: 0.012215
2022-01-08 11:44:32,457 iteration 2599 : loss : 0.023428, loss_ce: 0.010407
2022-01-08 11:44:34,740 iteration 2600 : loss : 0.034161, loss_ce: 0.014420
2022-01-08 11:44:37,139 iteration 2601 : loss : 0.032482, loss_ce: 0.015149
 38%|██████████▎                | 153/400 [1:50:51<2:53:12, 42.08s/it]2022-01-08 11:44:39,530 iteration 2602 : loss : 0.023986, loss_ce: 0.007409
2022-01-08 11:44:41,929 iteration 2603 : loss : 0.035085, loss_ce: 0.011674
2022-01-08 11:44:44,283 iteration 2604 : loss : 0.026105, loss_ce: 0.011926
2022-01-08 11:44:46,691 iteration 2605 : loss : 0.020209, loss_ce: 0.005843
2022-01-08 11:44:49,190 iteration 2606 : loss : 0.046029, loss_ce: 0.014193
2022-01-08 11:44:51,529 iteration 2607 : loss : 0.027213, loss_ce: 0.009148
2022-01-08 11:44:53,826 iteration 2608 : loss : 0.020496, loss_ce: 0.009685
2022-01-08 11:44:56,191 iteration 2609 : loss : 0.036306, loss_ce: 0.012790
2022-01-08 11:44:58,605 iteration 2610 : loss : 0.030824, loss_ce: 0.011535
2022-01-08 11:45:01,033 iteration 2611 : loss : 0.032225, loss_ce: 0.011426
2022-01-08 11:45:03,427 iteration 2612 : loss : 0.029889, loss_ce: 0.013780
2022-01-08 11:45:05,802 iteration 2613 : loss : 0.026007, loss_ce: 0.011318
2022-01-08 11:45:08,244 iteration 2614 : loss : 0.025823, loss_ce: 0.008796
2022-01-08 11:45:10,588 iteration 2615 : loss : 0.042102, loss_ce: 0.014002
2022-01-08 11:45:12,973 iteration 2616 : loss : 0.030866, loss_ce: 0.018478
2022-01-08 11:45:15,303 iteration 2617 : loss : 0.024768, loss_ce: 0.009459
2022-01-08 11:45:17,641 iteration 2618 : loss : 0.020353, loss_ce: 0.009056
 38%|██████████▍                | 154/400 [1:51:32<2:50:33, 41.60s/it]2022-01-08 11:45:19,990 iteration 2619 : loss : 0.032823, loss_ce: 0.011109
2022-01-08 11:45:22,289 iteration 2620 : loss : 0.021221, loss_ce: 0.010141
2022-01-08 11:45:24,750 iteration 2621 : loss : 0.036898, loss_ce: 0.014012
2022-01-08 11:45:27,114 iteration 2622 : loss : 0.049344, loss_ce: 0.013533
2022-01-08 11:45:29,652 iteration 2623 : loss : 0.032732, loss_ce: 0.012731
2022-01-08 11:45:32,020 iteration 2624 : loss : 0.022721, loss_ce: 0.007472
2022-01-08 11:45:34,391 iteration 2625 : loss : 0.043151, loss_ce: 0.007759
2022-01-08 11:45:36,984 iteration 2626 : loss : 0.037174, loss_ce: 0.014036
2022-01-08 11:45:39,506 iteration 2627 : loss : 0.033054, loss_ce: 0.011517
2022-01-08 11:45:41,796 iteration 2628 : loss : 0.034355, loss_ce: 0.017207
2022-01-08 11:45:44,209 iteration 2629 : loss : 0.034336, loss_ce: 0.014764
2022-01-08 11:45:46,617 iteration 2630 : loss : 0.032258, loss_ce: 0.012932
2022-01-08 11:45:49,004 iteration 2631 : loss : 0.030971, loss_ce: 0.013670
2022-01-08 11:45:51,313 iteration 2632 : loss : 0.022007, loss_ce: 0.008407
2022-01-08 11:45:53,700 iteration 2633 : loss : 0.038596, loss_ce: 0.021972
2022-01-08 11:45:56,068 iteration 2634 : loss : 0.031076, loss_ce: 0.011478
2022-01-08 11:45:56,068 Training Data Eval:
2022-01-08 11:46:08,674   Average segmentation loss on training set: 0.0222
2022-01-08 11:46:08,675 Validation Data Eval:
2022-01-08 11:46:13,159   Average segmentation loss on validation set: 0.0645
2022-01-08 11:46:15,609 iteration 2635 : loss : 0.029645, loss_ce: 0.011939
 39%|██████████▍                | 155/400 [1:52:30<3:09:55, 46.51s/it]2022-01-08 11:46:18,048 iteration 2636 : loss : 0.033765, loss_ce: 0.015674
2022-01-08 11:46:20,511 iteration 2637 : loss : 0.033361, loss_ce: 0.013492
2022-01-08 11:46:22,933 iteration 2638 : loss : 0.033246, loss_ce: 0.012120
2022-01-08 11:46:25,293 iteration 2639 : loss : 0.021505, loss_ce: 0.010242
2022-01-08 11:46:27,688 iteration 2640 : loss : 0.027957, loss_ce: 0.009642
2022-01-08 11:46:30,091 iteration 2641 : loss : 0.037061, loss_ce: 0.016738
2022-01-08 11:46:32,436 iteration 2642 : loss : 0.026044, loss_ce: 0.009609
2022-01-08 11:46:34,930 iteration 2643 : loss : 0.030413, loss_ce: 0.011446
2022-01-08 11:46:37,324 iteration 2644 : loss : 0.027376, loss_ce: 0.009819
2022-01-08 11:46:39,657 iteration 2645 : loss : 0.022502, loss_ce: 0.007814
2022-01-08 11:46:42,088 iteration 2646 : loss : 0.034950, loss_ce: 0.010812
2022-01-08 11:46:44,408 iteration 2647 : loss : 0.042018, loss_ce: 0.017484
2022-01-08 11:46:46,635 iteration 2648 : loss : 0.033739, loss_ce: 0.013438
2022-01-08 11:46:49,063 iteration 2649 : loss : 0.035428, loss_ce: 0.014672
2022-01-08 11:46:51,516 iteration 2650 : loss : 0.027003, loss_ce: 0.008149
2022-01-08 11:46:53,933 iteration 2651 : loss : 0.027310, loss_ce: 0.010960
2022-01-08 11:46:56,345 iteration 2652 : loss : 0.023999, loss_ce: 0.009123
 39%|██████████▌                | 156/400 [1:53:11<3:02:06, 44.78s/it]2022-01-08 11:46:58,845 iteration 2653 : loss : 0.022003, loss_ce: 0.009916
2022-01-08 11:47:01,189 iteration 2654 : loss : 0.035901, loss_ce: 0.013458
2022-01-08 11:47:03,673 iteration 2655 : loss : 0.028015, loss_ce: 0.013091
2022-01-08 11:47:06,013 iteration 2656 : loss : 0.048766, loss_ce: 0.014796
2022-01-08 11:47:08,382 iteration 2657 : loss : 0.039417, loss_ce: 0.017540
2022-01-08 11:47:10,644 iteration 2658 : loss : 0.021160, loss_ce: 0.009914
2022-01-08 11:47:13,046 iteration 2659 : loss : 0.035635, loss_ce: 0.010469
2022-01-08 11:47:15,526 iteration 2660 : loss : 0.025843, loss_ce: 0.008302
2022-01-08 11:47:17,899 iteration 2661 : loss : 0.026266, loss_ce: 0.009294
2022-01-08 11:47:20,276 iteration 2662 : loss : 0.039377, loss_ce: 0.017549
2022-01-08 11:47:22,597 iteration 2663 : loss : 0.038198, loss_ce: 0.010460
2022-01-08 11:47:25,041 iteration 2664 : loss : 0.036288, loss_ce: 0.016174
2022-01-08 11:47:27,305 iteration 2665 : loss : 0.032342, loss_ce: 0.011851
2022-01-08 11:47:29,495 iteration 2666 : loss : 0.018779, loss_ce: 0.006379
2022-01-08 11:47:31,838 iteration 2667 : loss : 0.032233, loss_ce: 0.011164
2022-01-08 11:47:34,187 iteration 2668 : loss : 0.031130, loss_ce: 0.012651
2022-01-08 11:47:36,493 iteration 2669 : loss : 0.028329, loss_ce: 0.010530
 39%|██████████▌                | 157/400 [1:53:51<2:55:43, 43.39s/it]2022-01-08 11:47:38,932 iteration 2670 : loss : 0.042592, loss_ce: 0.019256
2022-01-08 11:47:41,290 iteration 2671 : loss : 0.053902, loss_ce: 0.018857
2022-01-08 11:47:43,527 iteration 2672 : loss : 0.023982, loss_ce: 0.009696
2022-01-08 11:47:45,760 iteration 2673 : loss : 0.022096, loss_ce: 0.010687
2022-01-08 11:47:48,048 iteration 2674 : loss : 0.034842, loss_ce: 0.016248
2022-01-08 11:47:50,354 iteration 2675 : loss : 0.020445, loss_ce: 0.008643
2022-01-08 11:47:52,813 iteration 2676 : loss : 0.048605, loss_ce: 0.012287
2022-01-08 11:47:55,155 iteration 2677 : loss : 0.036899, loss_ce: 0.014136
2022-01-08 11:47:57,496 iteration 2678 : loss : 0.029764, loss_ce: 0.012219
2022-01-08 11:47:59,927 iteration 2679 : loss : 0.032177, loss_ce: 0.010668
2022-01-08 11:48:02,281 iteration 2680 : loss : 0.025233, loss_ce: 0.009548
2022-01-08 11:48:04,681 iteration 2681 : loss : 0.027029, loss_ce: 0.008224
2022-01-08 11:48:07,102 iteration 2682 : loss : 0.027782, loss_ce: 0.009929
2022-01-08 11:48:09,472 iteration 2683 : loss : 0.040612, loss_ce: 0.012784
2022-01-08 11:48:11,769 iteration 2684 : loss : 0.033370, loss_ce: 0.016205
2022-01-08 11:48:14,120 iteration 2685 : loss : 0.029235, loss_ce: 0.012680
2022-01-08 11:48:16,353 iteration 2686 : loss : 0.038193, loss_ce: 0.016748
 40%|██████████▋                | 158/400 [1:54:31<2:50:43, 42.33s/it]2022-01-08 11:48:18,616 iteration 2687 : loss : 0.034556, loss_ce: 0.008914
2022-01-08 11:48:20,996 iteration 2688 : loss : 0.043425, loss_ce: 0.015436
2022-01-08 11:48:23,281 iteration 2689 : loss : 0.022932, loss_ce: 0.008691
2022-01-08 11:48:25,813 iteration 2690 : loss : 0.027265, loss_ce: 0.011924
2022-01-08 11:48:28,136 iteration 2691 : loss : 0.019952, loss_ce: 0.008094
2022-01-08 11:48:30,508 iteration 2692 : loss : 0.030007, loss_ce: 0.009091
2022-01-08 11:48:32,904 iteration 2693 : loss : 0.039178, loss_ce: 0.012375
2022-01-08 11:48:35,288 iteration 2694 : loss : 0.032796, loss_ce: 0.011466
2022-01-08 11:48:37,680 iteration 2695 : loss : 0.022501, loss_ce: 0.008938
2022-01-08 11:48:40,136 iteration 2696 : loss : 0.024852, loss_ce: 0.010742
2022-01-08 11:48:42,522 iteration 2697 : loss : 0.023102, loss_ce: 0.010038
2022-01-08 11:48:44,806 iteration 2698 : loss : 0.020776, loss_ce: 0.009179
2022-01-08 11:48:47,193 iteration 2699 : loss : 0.032660, loss_ce: 0.012441
2022-01-08 11:48:49,588 iteration 2700 : loss : 0.031932, loss_ce: 0.014700
2022-01-08 11:48:51,874 iteration 2701 : loss : 0.038087, loss_ce: 0.014954
2022-01-08 11:48:54,141 iteration 2702 : loss : 0.065677, loss_ce: 0.010430
2022-01-08 11:48:56,393 iteration 2703 : loss : 0.027135, loss_ce: 0.010617
 40%|██████████▋                | 159/400 [1:55:11<2:47:15, 41.64s/it]2022-01-08 11:48:58,758 iteration 2704 : loss : 0.029444, loss_ce: 0.011409
2022-01-08 11:49:00,916 iteration 2705 : loss : 0.039763, loss_ce: 0.009965
2022-01-08 11:49:03,110 iteration 2706 : loss : 0.026862, loss_ce: 0.014009
2022-01-08 11:49:05,515 iteration 2707 : loss : 0.029814, loss_ce: 0.008677
2022-01-08 11:49:07,997 iteration 2708 : loss : 0.018661, loss_ce: 0.007519
2022-01-08 11:49:10,372 iteration 2709 : loss : 0.024568, loss_ce: 0.007469
2022-01-08 11:49:12,666 iteration 2710 : loss : 0.022281, loss_ce: 0.008039
2022-01-08 11:49:15,105 iteration 2711 : loss : 0.039760, loss_ce: 0.013618
2022-01-08 11:49:17,360 iteration 2712 : loss : 0.021840, loss_ce: 0.009329
2022-01-08 11:49:19,767 iteration 2713 : loss : 0.037851, loss_ce: 0.012006
2022-01-08 11:49:22,218 iteration 2714 : loss : 0.023806, loss_ce: 0.007993
2022-01-08 11:49:24,650 iteration 2715 : loss : 0.026835, loss_ce: 0.014086
2022-01-08 11:49:27,195 iteration 2716 : loss : 0.033742, loss_ce: 0.012495
2022-01-08 11:49:29,578 iteration 2717 : loss : 0.021130, loss_ce: 0.009982
2022-01-08 11:49:31,914 iteration 2718 : loss : 0.025824, loss_ce: 0.010173
2022-01-08 11:49:34,277 iteration 2719 : loss : 0.044555, loss_ce: 0.013344
2022-01-08 11:49:34,277 Training Data Eval:
2022-01-08 11:49:46,637   Average segmentation loss on training set: 0.0206
2022-01-08 11:49:46,638 Validation Data Eval:
2022-01-08 11:49:51,121   Average segmentation loss on validation set: 0.0787
2022-01-08 11:49:53,515 iteration 2720 : loss : 0.023948, loss_ce: 0.009935
 40%|██████████▊                | 160/400 [1:56:08<3:05:09, 46.29s/it]2022-01-08 11:49:55,971 iteration 2721 : loss : 0.026700, loss_ce: 0.009692
2022-01-08 11:49:58,370 iteration 2722 : loss : 0.031493, loss_ce: 0.014227
2022-01-08 11:50:00,751 iteration 2723 : loss : 0.027377, loss_ce: 0.009396
2022-01-08 11:50:03,002 iteration 2724 : loss : 0.030745, loss_ce: 0.011129
2022-01-08 11:50:05,307 iteration 2725 : loss : 0.024511, loss_ce: 0.008646
2022-01-08 11:50:07,641 iteration 2726 : loss : 0.026673, loss_ce: 0.009168
2022-01-08 11:50:09,907 iteration 2727 : loss : 0.018371, loss_ce: 0.005728
2022-01-08 11:50:12,347 iteration 2728 : loss : 0.028688, loss_ce: 0.014392
2022-01-08 11:50:14,729 iteration 2729 : loss : 0.049035, loss_ce: 0.017829
2022-01-08 11:50:17,179 iteration 2730 : loss : 0.024831, loss_ce: 0.009804
2022-01-08 11:50:19,588 iteration 2731 : loss : 0.053455, loss_ce: 0.022526
2022-01-08 11:50:21,989 iteration 2732 : loss : 0.036835, loss_ce: 0.014842
2022-01-08 11:50:24,329 iteration 2733 : loss : 0.041866, loss_ce: 0.016514
2022-01-08 11:50:26,688 iteration 2734 : loss : 0.039066, loss_ce: 0.013638
2022-01-08 11:50:28,990 iteration 2735 : loss : 0.022215, loss_ce: 0.008844
2022-01-08 11:50:31,353 iteration 2736 : loss : 0.026493, loss_ce: 0.012917
2022-01-08 11:50:33,678 iteration 2737 : loss : 0.025050, loss_ce: 0.009124
 40%|██████████▊                | 161/400 [1:56:48<2:57:03, 44.45s/it]2022-01-08 11:50:36,068 iteration 2738 : loss : 0.023376, loss_ce: 0.010331
2022-01-08 11:50:38,345 iteration 2739 : loss : 0.029329, loss_ce: 0.015280
2022-01-08 11:50:40,718 iteration 2740 : loss : 0.030057, loss_ce: 0.011626
2022-01-08 11:50:43,119 iteration 2741 : loss : 0.021617, loss_ce: 0.006574
2022-01-08 11:50:45,433 iteration 2742 : loss : 0.028989, loss_ce: 0.011614
2022-01-08 11:50:47,808 iteration 2743 : loss : 0.041492, loss_ce: 0.024163
2022-01-08 11:50:50,176 iteration 2744 : loss : 0.026003, loss_ce: 0.010133
2022-01-08 11:50:52,529 iteration 2745 : loss : 0.023176, loss_ce: 0.008858
2022-01-08 11:50:54,973 iteration 2746 : loss : 0.027609, loss_ce: 0.008642
2022-01-08 11:50:57,354 iteration 2747 : loss : 0.025166, loss_ce: 0.008015
2022-01-08 11:50:59,723 iteration 2748 : loss : 0.031534, loss_ce: 0.010677
2022-01-08 11:51:02,012 iteration 2749 : loss : 0.021974, loss_ce: 0.009427
2022-01-08 11:51:04,376 iteration 2750 : loss : 0.033785, loss_ce: 0.009735
2022-01-08 11:51:06,642 iteration 2751 : loss : 0.018820, loss_ce: 0.008168
2022-01-08 11:51:08,894 iteration 2752 : loss : 0.024119, loss_ce: 0.006335
2022-01-08 11:51:11,231 iteration 2753 : loss : 0.030957, loss_ce: 0.012397
2022-01-08 11:51:13,527 iteration 2754 : loss : 0.020876, loss_ce: 0.009361
 40%|██████████▉                | 162/400 [1:57:28<2:50:49, 43.07s/it]2022-01-08 11:51:15,819 iteration 2755 : loss : 0.024762, loss_ce: 0.010213
2022-01-08 11:51:18,043 iteration 2756 : loss : 0.039379, loss_ce: 0.021951
2022-01-08 11:51:20,252 iteration 2757 : loss : 0.022052, loss_ce: 0.007630
2022-01-08 11:51:22,611 iteration 2758 : loss : 0.042158, loss_ce: 0.013640
2022-01-08 11:51:24,909 iteration 2759 : loss : 0.024071, loss_ce: 0.007644
2022-01-08 11:51:27,219 iteration 2760 : loss : 0.031699, loss_ce: 0.010612
2022-01-08 11:51:29,471 iteration 2761 : loss : 0.027968, loss_ce: 0.011010
2022-01-08 11:51:31,696 iteration 2762 : loss : 0.018296, loss_ce: 0.006858
2022-01-08 11:51:34,013 iteration 2763 : loss : 0.040418, loss_ce: 0.011801
2022-01-08 11:51:36,379 iteration 2764 : loss : 0.020793, loss_ce: 0.008193
2022-01-08 11:51:38,684 iteration 2765 : loss : 0.029025, loss_ce: 0.011240
2022-01-08 11:51:41,000 iteration 2766 : loss : 0.027019, loss_ce: 0.013422
2022-01-08 11:51:43,323 iteration 2767 : loss : 0.024446, loss_ce: 0.008770
2022-01-08 11:51:45,577 iteration 2768 : loss : 0.019945, loss_ce: 0.005538
2022-01-08 11:51:47,843 iteration 2769 : loss : 0.023705, loss_ce: 0.009843
2022-01-08 11:51:50,107 iteration 2770 : loss : 0.031073, loss_ce: 0.013851
2022-01-08 11:51:52,326 iteration 2771 : loss : 0.020344, loss_ce: 0.006367
 41%|███████████                | 163/400 [1:58:07<2:45:03, 41.79s/it]2022-01-08 11:51:54,610 iteration 2772 : loss : 0.022779, loss_ce: 0.009523
2022-01-08 11:51:56,848 iteration 2773 : loss : 0.025768, loss_ce: 0.009961
2022-01-08 11:51:59,040 iteration 2774 : loss : 0.032766, loss_ce: 0.008559
2022-01-08 11:52:01,323 iteration 2775 : loss : 0.021516, loss_ce: 0.007829
2022-01-08 11:52:03,692 iteration 2776 : loss : 0.021516, loss_ce: 0.007402
2022-01-08 11:52:06,063 iteration 2777 : loss : 0.017529, loss_ce: 0.006590
2022-01-08 11:52:08,457 iteration 2778 : loss : 0.032456, loss_ce: 0.014385
2022-01-08 11:52:10,867 iteration 2779 : loss : 0.028826, loss_ce: 0.009863
2022-01-08 11:52:13,108 iteration 2780 : loss : 0.021008, loss_ce: 0.006763
2022-01-08 11:52:15,448 iteration 2781 : loss : 0.046464, loss_ce: 0.014183
2022-01-08 11:52:17,775 iteration 2782 : loss : 0.022252, loss_ce: 0.007962
2022-01-08 11:52:20,076 iteration 2783 : loss : 0.038694, loss_ce: 0.017219
2022-01-08 11:52:22,529 iteration 2784 : loss : 0.035462, loss_ce: 0.012023
2022-01-08 11:52:24,972 iteration 2785 : loss : 0.036047, loss_ce: 0.011228
2022-01-08 11:52:27,438 iteration 2786 : loss : 0.025292, loss_ce: 0.010111
2022-01-08 11:52:29,845 iteration 2787 : loss : 0.018820, loss_ce: 0.008282
2022-01-08 11:52:32,069 iteration 2788 : loss : 0.022406, loss_ce: 0.011714
 41%|███████████                | 164/400 [1:58:46<2:41:57, 41.18s/it]2022-01-08 11:52:34,286 iteration 2789 : loss : 0.024749, loss_ce: 0.009672
2022-01-08 11:52:36,547 iteration 2790 : loss : 0.025894, loss_ce: 0.007858
2022-01-08 11:52:38,908 iteration 2791 : loss : 0.022436, loss_ce: 0.009224
2022-01-08 11:52:41,301 iteration 2792 : loss : 0.035034, loss_ce: 0.011828
2022-01-08 11:52:43,529 iteration 2793 : loss : 0.024884, loss_ce: 0.009885
2022-01-08 11:52:45,882 iteration 2794 : loss : 0.025679, loss_ce: 0.009101
2022-01-08 11:52:48,134 iteration 2795 : loss : 0.025945, loss_ce: 0.008318
2022-01-08 11:52:50,471 iteration 2796 : loss : 0.025330, loss_ce: 0.009140
2022-01-08 11:52:52,857 iteration 2797 : loss : 0.019806, loss_ce: 0.007698
2022-01-08 11:52:55,235 iteration 2798 : loss : 0.039537, loss_ce: 0.020798
2022-01-08 11:52:57,579 iteration 2799 : loss : 0.018098, loss_ce: 0.007780
2022-01-08 11:52:59,872 iteration 2800 : loss : 0.032679, loss_ce: 0.011050
2022-01-08 11:53:02,184 iteration 2801 : loss : 0.017827, loss_ce: 0.005955
2022-01-08 11:53:04,546 iteration 2802 : loss : 0.029453, loss_ce: 0.008464
2022-01-08 11:53:06,883 iteration 2803 : loss : 0.045888, loss_ce: 0.026237
2022-01-08 11:53:09,138 iteration 2804 : loss : 0.025266, loss_ce: 0.008872
2022-01-08 11:53:09,138 Training Data Eval:
2022-01-08 11:53:21,777   Average segmentation loss on training set: 0.0181
2022-01-08 11:53:21,777 Validation Data Eval:
2022-01-08 11:53:26,416   Average segmentation loss on validation set: 0.0665
2022-01-08 11:53:28,789 iteration 2805 : loss : 0.025367, loss_ce: 0.010660
 41%|███████████▏               | 165/400 [1:59:43<2:59:32, 45.84s/it]2022-01-08 11:53:31,300 iteration 2806 : loss : 0.027197, loss_ce: 0.011341
2022-01-08 11:53:33,563 iteration 2807 : loss : 0.021427, loss_ce: 0.007302
2022-01-08 11:53:35,901 iteration 2808 : loss : 0.022554, loss_ce: 0.009302
2022-01-08 11:53:38,341 iteration 2809 : loss : 0.017653, loss_ce: 0.005956
2022-01-08 11:53:40,698 iteration 2810 : loss : 0.028899, loss_ce: 0.012735
2022-01-08 11:53:43,070 iteration 2811 : loss : 0.033361, loss_ce: 0.012979
2022-01-08 11:53:45,396 iteration 2812 : loss : 0.023594, loss_ce: 0.009241
2022-01-08 11:53:47,560 iteration 2813 : loss : 0.020896, loss_ce: 0.008415
2022-01-08 11:53:49,788 iteration 2814 : loss : 0.023469, loss_ce: 0.011953
2022-01-08 11:53:52,095 iteration 2815 : loss : 0.024206, loss_ce: 0.009524
2022-01-08 11:53:54,373 iteration 2816 : loss : 0.027480, loss_ce: 0.009225
2022-01-08 11:53:56,707 iteration 2817 : loss : 0.037021, loss_ce: 0.017379
2022-01-08 11:53:59,155 iteration 2818 : loss : 0.032964, loss_ce: 0.011376
2022-01-08 11:54:01,507 iteration 2819 : loss : 0.023651, loss_ce: 0.009974
2022-01-08 11:54:03,774 iteration 2820 : loss : 0.022664, loss_ce: 0.008255
2022-01-08 11:54:06,132 iteration 2821 : loss : 0.016586, loss_ce: 0.006291
2022-01-08 11:54:08,459 iteration 2822 : loss : 0.063136, loss_ce: 0.012250
 42%|███████████▏               | 166/400 [2:00:23<2:51:32, 43.99s/it]2022-01-08 11:54:10,810 iteration 2823 : loss : 0.026568, loss_ce: 0.010975
2022-01-08 11:54:13,118 iteration 2824 : loss : 0.042422, loss_ce: 0.012346
2022-01-08 11:54:15,467 iteration 2825 : loss : 0.054276, loss_ce: 0.020629
2022-01-08 11:54:17,844 iteration 2826 : loss : 0.021791, loss_ce: 0.008380
2022-01-08 11:54:20,242 iteration 2827 : loss : 0.040340, loss_ce: 0.018358
2022-01-08 11:54:22,493 iteration 2828 : loss : 0.023129, loss_ce: 0.009424
2022-01-08 11:54:24,838 iteration 2829 : loss : 0.036205, loss_ce: 0.011087
2022-01-08 11:54:27,258 iteration 2830 : loss : 0.026225, loss_ce: 0.012122
2022-01-08 11:54:29,634 iteration 2831 : loss : 0.041709, loss_ce: 0.012258
2022-01-08 11:54:31,940 iteration 2832 : loss : 0.026046, loss_ce: 0.010588
2022-01-08 11:54:34,355 iteration 2833 : loss : 0.028289, loss_ce: 0.010922
2022-01-08 11:54:36,668 iteration 2834 : loss : 0.024857, loss_ce: 0.010278
2022-01-08 11:54:39,069 iteration 2835 : loss : 0.032342, loss_ce: 0.013880
2022-01-08 11:54:41,389 iteration 2836 : loss : 0.045759, loss_ce: 0.022818
2022-01-08 11:54:43,716 iteration 2837 : loss : 0.025254, loss_ce: 0.009075
2022-01-08 11:54:46,042 iteration 2838 : loss : 0.025196, loss_ce: 0.008546
2022-01-08 11:54:48,289 iteration 2839 : loss : 0.022789, loss_ce: 0.009792
 42%|███████████▎               | 167/400 [2:01:03<2:45:58, 42.74s/it]2022-01-08 11:54:50,733 iteration 2840 : loss : 0.032277, loss_ce: 0.011420
2022-01-08 11:54:53,083 iteration 2841 : loss : 0.021621, loss_ce: 0.009889
2022-01-08 11:54:55,376 iteration 2842 : loss : 0.020702, loss_ce: 0.007263
2022-01-08 11:54:57,749 iteration 2843 : loss : 0.024487, loss_ce: 0.007731
2022-01-08 11:55:00,209 iteration 2844 : loss : 0.038937, loss_ce: 0.016673
2022-01-08 11:55:02,649 iteration 2845 : loss : 0.027109, loss_ce: 0.008956
2022-01-08 11:55:04,923 iteration 2846 : loss : 0.023906, loss_ce: 0.007728
2022-01-08 11:55:07,185 iteration 2847 : loss : 0.044681, loss_ce: 0.020345
2022-01-08 11:55:09,450 iteration 2848 : loss : 0.039171, loss_ce: 0.023111
2022-01-08 11:55:11,578 iteration 2849 : loss : 0.025946, loss_ce: 0.008456
2022-01-08 11:55:13,790 iteration 2850 : loss : 0.024540, loss_ce: 0.008441
2022-01-08 11:55:15,998 iteration 2851 : loss : 0.034541, loss_ce: 0.014631
2022-01-08 11:55:18,228 iteration 2852 : loss : 0.037769, loss_ce: 0.016205
2022-01-08 11:55:20,455 iteration 2853 : loss : 0.022961, loss_ce: 0.009371
2022-01-08 11:55:22,747 iteration 2854 : loss : 0.028102, loss_ce: 0.013201
2022-01-08 11:55:25,036 iteration 2855 : loss : 0.031601, loss_ce: 0.012223
2022-01-08 11:55:27,360 iteration 2856 : loss : 0.030581, loss_ce: 0.009778
 42%|███████████▎               | 168/400 [2:01:42<2:40:59, 41.64s/it]2022-01-08 11:55:29,716 iteration 2857 : loss : 0.052352, loss_ce: 0.015386
2022-01-08 11:55:31,975 iteration 2858 : loss : 0.030692, loss_ce: 0.009167
2022-01-08 11:55:34,265 iteration 2859 : loss : 0.021488, loss_ce: 0.006950
2022-01-08 11:55:36,633 iteration 2860 : loss : 0.038142, loss_ce: 0.016293
2022-01-08 11:55:38,973 iteration 2861 : loss : 0.020428, loss_ce: 0.008123
2022-01-08 11:55:41,364 iteration 2862 : loss : 0.028699, loss_ce: 0.010516
2022-01-08 11:55:43,819 iteration 2863 : loss : 0.037748, loss_ce: 0.013775
2022-01-08 11:55:46,178 iteration 2864 : loss : 0.034749, loss_ce: 0.015597
2022-01-08 11:55:48,396 iteration 2865 : loss : 0.024091, loss_ce: 0.009050
2022-01-08 11:55:50,633 iteration 2866 : loss : 0.019751, loss_ce: 0.005732
2022-01-08 11:55:52,900 iteration 2867 : loss : 0.031498, loss_ce: 0.011572
2022-01-08 11:55:55,181 iteration 2868 : loss : 0.024498, loss_ce: 0.010174
2022-01-08 11:55:57,433 iteration 2869 : loss : 0.020386, loss_ce: 0.008623
2022-01-08 11:55:59,660 iteration 2870 : loss : 0.038654, loss_ce: 0.018040
2022-01-08 11:56:01,736 iteration 2871 : loss : 0.020705, loss_ce: 0.008969
2022-01-08 11:56:03,957 iteration 2872 : loss : 0.048706, loss_ce: 0.021459
2022-01-08 11:56:06,233 iteration 2873 : loss : 0.030735, loss_ce: 0.012325
 42%|███████████▍               | 169/400 [2:02:21<2:37:08, 40.81s/it]2022-01-08 11:56:08,561 iteration 2874 : loss : 0.040838, loss_ce: 0.011369
2022-01-08 11:56:10,737 iteration 2875 : loss : 0.019945, loss_ce: 0.007734
2022-01-08 11:56:13,010 iteration 2876 : loss : 0.020799, loss_ce: 0.008565
2022-01-08 11:56:15,382 iteration 2877 : loss : 0.025783, loss_ce: 0.008369
2022-01-08 11:56:17,795 iteration 2878 : loss : 0.031522, loss_ce: 0.011090
2022-01-08 11:56:20,049 iteration 2879 : loss : 0.023863, loss_ce: 0.011535
2022-01-08 11:56:22,374 iteration 2880 : loss : 0.030679, loss_ce: 0.012371
2022-01-08 11:56:24,615 iteration 2881 : loss : 0.031262, loss_ce: 0.014828
2022-01-08 11:56:26,989 iteration 2882 : loss : 0.042076, loss_ce: 0.013663
2022-01-08 11:56:29,291 iteration 2883 : loss : 0.049069, loss_ce: 0.026492
2022-01-08 11:56:31,525 iteration 2884 : loss : 0.036657, loss_ce: 0.010951
2022-01-08 11:56:33,687 iteration 2885 : loss : 0.033950, loss_ce: 0.016789
2022-01-08 11:56:35,822 iteration 2886 : loss : 0.022870, loss_ce: 0.006506
2022-01-08 11:56:37,941 iteration 2887 : loss : 0.022498, loss_ce: 0.008204
2022-01-08 11:56:40,219 iteration 2888 : loss : 0.024581, loss_ce: 0.008740
2022-01-08 11:56:42,460 iteration 2889 : loss : 0.030450, loss_ce: 0.011491
2022-01-08 11:56:42,460 Training Data Eval:
2022-01-08 11:56:55,167   Average segmentation loss on training set: 0.0173
2022-01-08 11:56:55,168 Validation Data Eval:
2022-01-08 11:56:59,647   Average segmentation loss on validation set: 0.0863
2022-01-08 11:57:02,074 iteration 2890 : loss : 0.031519, loss_ce: 0.012952
 42%|███████████▍               | 170/400 [2:03:16<2:53:43, 45.32s/it]2022-01-08 11:57:04,500 iteration 2891 : loss : 0.033838, loss_ce: 0.017092
2022-01-08 11:57:06,737 iteration 2892 : loss : 0.023929, loss_ce: 0.010301
2022-01-08 11:57:08,998 iteration 2893 : loss : 0.028132, loss_ce: 0.008594
2022-01-08 11:57:11,364 iteration 2894 : loss : 0.018000, loss_ce: 0.007157
2022-01-08 11:57:13,716 iteration 2895 : loss : 0.033236, loss_ce: 0.011384
2022-01-08 11:57:16,016 iteration 2896 : loss : 0.023919, loss_ce: 0.008662
2022-01-08 11:57:18,396 iteration 2897 : loss : 0.026577, loss_ce: 0.012034
2022-01-08 11:57:20,778 iteration 2898 : loss : 0.024394, loss_ce: 0.013345
2022-01-08 11:57:23,129 iteration 2899 : loss : 0.035273, loss_ce: 0.013904
2022-01-08 11:57:25,390 iteration 2900 : loss : 0.022418, loss_ce: 0.007532
2022-01-08 11:57:27,859 iteration 2901 : loss : 0.020892, loss_ce: 0.007018
2022-01-08 11:57:30,173 iteration 2902 : loss : 0.020118, loss_ce: 0.006402
2022-01-08 11:57:32,705 iteration 2903 : loss : 0.024837, loss_ce: 0.010989
2022-01-08 11:57:35,155 iteration 2904 : loss : 0.040685, loss_ce: 0.012446
2022-01-08 11:57:37,497 iteration 2905 : loss : 0.030550, loss_ce: 0.010072
2022-01-08 11:57:39,945 iteration 2906 : loss : 0.032214, loss_ce: 0.011924
2022-01-08 11:57:42,330 iteration 2907 : loss : 0.031386, loss_ce: 0.011807
 43%|███████████▌               | 171/400 [2:03:57<2:47:10, 43.80s/it]2022-01-08 11:57:44,741 iteration 2908 : loss : 0.022218, loss_ce: 0.008324
2022-01-08 11:57:47,023 iteration 2909 : loss : 0.023450, loss_ce: 0.005646
2022-01-08 11:57:49,570 iteration 2910 : loss : 0.052069, loss_ce: 0.017230
2022-01-08 11:57:51,993 iteration 2911 : loss : 0.039801, loss_ce: 0.017659
2022-01-08 11:57:54,331 iteration 2912 : loss : 0.022013, loss_ce: 0.007315
2022-01-08 11:57:56,628 iteration 2913 : loss : 0.021107, loss_ce: 0.008421
2022-01-08 11:57:58,956 iteration 2914 : loss : 0.022187, loss_ce: 0.009448
2022-01-08 11:58:01,398 iteration 2915 : loss : 0.024943, loss_ce: 0.008462
2022-01-08 11:58:03,700 iteration 2916 : loss : 0.024209, loss_ce: 0.012452
2022-01-08 11:58:06,148 iteration 2917 : loss : 0.036157, loss_ce: 0.013898
2022-01-08 11:58:08,596 iteration 2918 : loss : 0.054199, loss_ce: 0.023984
2022-01-08 11:58:11,001 iteration 2919 : loss : 0.038608, loss_ce: 0.017756
2022-01-08 11:58:13,380 iteration 2920 : loss : 0.044557, loss_ce: 0.013139
2022-01-08 11:58:15,788 iteration 2921 : loss : 0.027727, loss_ce: 0.007974
2022-01-08 11:58:18,154 iteration 2922 : loss : 0.026588, loss_ce: 0.010177
2022-01-08 11:58:20,582 iteration 2923 : loss : 0.033446, loss_ce: 0.016456
2022-01-08 11:58:22,978 iteration 2924 : loss : 0.020884, loss_ce: 0.006523
 43%|███████████▌               | 172/400 [2:04:37<2:42:51, 42.86s/it]2022-01-08 11:58:25,493 iteration 2925 : loss : 0.054002, loss_ce: 0.021862
2022-01-08 11:58:27,849 iteration 2926 : loss : 0.027970, loss_ce: 0.009181
2022-01-08 11:58:30,224 iteration 2927 : loss : 0.041199, loss_ce: 0.019827
2022-01-08 11:58:32,661 iteration 2928 : loss : 0.054813, loss_ce: 0.015324
2022-01-08 11:58:35,062 iteration 2929 : loss : 0.019347, loss_ce: 0.006358
2022-01-08 11:58:37,457 iteration 2930 : loss : 0.039568, loss_ce: 0.017007
2022-01-08 11:58:39,772 iteration 2931 : loss : 0.033376, loss_ce: 0.012611
2022-01-08 11:58:42,307 iteration 2932 : loss : 0.028694, loss_ce: 0.011237
2022-01-08 11:58:44,674 iteration 2933 : loss : 0.035290, loss_ce: 0.015768
2022-01-08 11:58:47,152 iteration 2934 : loss : 0.025433, loss_ce: 0.010914
2022-01-08 11:58:49,557 iteration 2935 : loss : 0.044234, loss_ce: 0.012032
2022-01-08 11:58:51,949 iteration 2936 : loss : 0.028060, loss_ce: 0.012427
2022-01-08 11:58:54,413 iteration 2937 : loss : 0.020618, loss_ce: 0.008826
2022-01-08 11:58:56,796 iteration 2938 : loss : 0.019927, loss_ce: 0.007490
2022-01-08 11:58:59,148 iteration 2939 : loss : 0.024817, loss_ce: 0.010228
2022-01-08 11:59:01,536 iteration 2940 : loss : 0.025304, loss_ce: 0.008302
2022-01-08 11:59:03,852 iteration 2941 : loss : 0.029251, loss_ce: 0.008854
 43%|███████████▋               | 173/400 [2:05:18<2:39:53, 42.26s/it]2022-01-08 11:59:06,325 iteration 2942 : loss : 0.026294, loss_ce: 0.009193
2022-01-08 11:59:08,690 iteration 2943 : loss : 0.021209, loss_ce: 0.008400
2022-01-08 11:59:11,102 iteration 2944 : loss : 0.029304, loss_ce: 0.010323
2022-01-08 11:59:13,567 iteration 2945 : loss : 0.033787, loss_ce: 0.015396
2022-01-08 11:59:15,945 iteration 2946 : loss : 0.023161, loss_ce: 0.009126
2022-01-08 11:59:18,314 iteration 2947 : loss : 0.016461, loss_ce: 0.005681
2022-01-08 11:59:20,698 iteration 2948 : loss : 0.031639, loss_ce: 0.011065
2022-01-08 11:59:23,068 iteration 2949 : loss : 0.020804, loss_ce: 0.007901
2022-01-08 11:59:25,357 iteration 2950 : loss : 0.029104, loss_ce: 0.011965
2022-01-08 11:59:27,572 iteration 2951 : loss : 0.022545, loss_ce: 0.008065
2022-01-08 11:59:29,956 iteration 2952 : loss : 0.034588, loss_ce: 0.007782
2022-01-08 11:59:32,405 iteration 2953 : loss : 0.033925, loss_ce: 0.014266
2022-01-08 11:59:34,822 iteration 2954 : loss : 0.032422, loss_ce: 0.011559
2022-01-08 11:59:37,105 iteration 2955 : loss : 0.023261, loss_ce: 0.011133
2022-01-08 11:59:39,466 iteration 2956 : loss : 0.020554, loss_ce: 0.009327
2022-01-08 11:59:41,880 iteration 2957 : loss : 0.035829, loss_ce: 0.008148
2022-01-08 11:59:44,290 iteration 2958 : loss : 0.037033, loss_ce: 0.014510
 44%|███████████▋               | 174/400 [2:05:59<2:37:07, 41.71s/it]2022-01-08 11:59:46,788 iteration 2959 : loss : 0.020598, loss_ce: 0.009486
2022-01-08 11:59:49,180 iteration 2960 : loss : 0.025329, loss_ce: 0.009408
2022-01-08 11:59:51,624 iteration 2961 : loss : 0.024244, loss_ce: 0.010277
2022-01-08 11:59:53,931 iteration 2962 : loss : 0.021838, loss_ce: 0.007466
2022-01-08 11:59:56,453 iteration 2963 : loss : 0.030190, loss_ce: 0.011845
2022-01-08 11:59:58,895 iteration 2964 : loss : 0.030607, loss_ce: 0.010170
2022-01-08 12:00:01,323 iteration 2965 : loss : 0.020354, loss_ce: 0.008975
2022-01-08 12:00:03,783 iteration 2966 : loss : 0.020506, loss_ce: 0.006342
2022-01-08 12:00:06,251 iteration 2967 : loss : 0.066429, loss_ce: 0.021757
2022-01-08 12:00:08,683 iteration 2968 : loss : 0.031949, loss_ce: 0.010854
2022-01-08 12:00:11,053 iteration 2969 : loss : 0.020727, loss_ce: 0.005811
2022-01-08 12:00:13,429 iteration 2970 : loss : 0.023296, loss_ce: 0.008481
2022-01-08 12:00:15,890 iteration 2971 : loss : 0.031884, loss_ce: 0.013053
2022-01-08 12:00:18,498 iteration 2972 : loss : 0.019171, loss_ce: 0.006917
2022-01-08 12:00:20,881 iteration 2973 : loss : 0.028691, loss_ce: 0.012022
2022-01-08 12:00:23,297 iteration 2974 : loss : 0.047046, loss_ce: 0.025116
2022-01-08 12:00:23,298 Training Data Eval:
2022-01-08 12:00:36,095   Average segmentation loss on training set: 0.0180
2022-01-08 12:00:36,096 Validation Data Eval:
2022-01-08 12:00:40,575   Average segmentation loss on validation set: 0.0656
2022-01-08 12:00:42,934 iteration 2975 : loss : 0.029235, loss_ce: 0.010836
 44%|███████████▊               | 175/400 [2:06:57<2:55:28, 46.79s/it]2022-01-08 12:00:45,413 iteration 2976 : loss : 0.025358, loss_ce: 0.010281
2022-01-08 12:00:47,857 iteration 2977 : loss : 0.025647, loss_ce: 0.009123
2022-01-08 12:00:50,175 iteration 2978 : loss : 0.028440, loss_ce: 0.010312
2022-01-08 12:00:52,548 iteration 2979 : loss : 0.038140, loss_ce: 0.009612
2022-01-08 12:00:54,939 iteration 2980 : loss : 0.036042, loss_ce: 0.014088
2022-01-08 12:00:57,294 iteration 2981 : loss : 0.019975, loss_ce: 0.008899
2022-01-08 12:00:59,706 iteration 2982 : loss : 0.028585, loss_ce: 0.011403
2022-01-08 12:01:02,132 iteration 2983 : loss : 0.030609, loss_ce: 0.006800
2022-01-08 12:01:04,511 iteration 2984 : loss : 0.041173, loss_ce: 0.024839
2022-01-08 12:01:06,865 iteration 2985 : loss : 0.021412, loss_ce: 0.009717
2022-01-08 12:01:09,192 iteration 2986 : loss : 0.035861, loss_ce: 0.015314
2022-01-08 12:01:11,586 iteration 2987 : loss : 0.025399, loss_ce: 0.008994
2022-01-08 12:01:13,974 iteration 2988 : loss : 0.029014, loss_ce: 0.010996
2022-01-08 12:01:16,330 iteration 2989 : loss : 0.021933, loss_ce: 0.007887
2022-01-08 12:01:18,724 iteration 2990 : loss : 0.027738, loss_ce: 0.012939
2022-01-08 12:01:21,143 iteration 2991 : loss : 0.027717, loss_ce: 0.008370
2022-01-08 12:01:23,548 iteration 2992 : loss : 0.029453, loss_ce: 0.012675
 44%|███████████▉               | 176/400 [2:07:38<2:47:46, 44.94s/it]2022-01-08 12:01:25,946 iteration 2993 : loss : 0.031505, loss_ce: 0.014042
2022-01-08 12:01:28,298 iteration 2994 : loss : 0.020531, loss_ce: 0.007828
2022-01-08 12:01:30,738 iteration 2995 : loss : 0.040938, loss_ce: 0.015924
2022-01-08 12:01:33,084 iteration 2996 : loss : 0.023991, loss_ce: 0.008011
2022-01-08 12:01:35,432 iteration 2997 : loss : 0.022470, loss_ce: 0.008169
2022-01-08 12:01:37,779 iteration 2998 : loss : 0.022649, loss_ce: 0.010801
2022-01-08 12:01:40,156 iteration 2999 : loss : 0.033511, loss_ce: 0.012649
2022-01-08 12:01:42,535 iteration 3000 : loss : 0.029584, loss_ce: 0.012145
2022-01-08 12:01:45,002 iteration 3001 : loss : 0.030147, loss_ce: 0.013012
2022-01-08 12:01:47,446 iteration 3002 : loss : 0.031520, loss_ce: 0.013005
2022-01-08 12:01:49,797 iteration 3003 : loss : 0.021063, loss_ce: 0.008857
2022-01-08 12:01:52,177 iteration 3004 : loss : 0.026909, loss_ce: 0.012692
2022-01-08 12:01:54,515 iteration 3005 : loss : 0.025626, loss_ce: 0.010795
2022-01-08 12:01:56,891 iteration 3006 : loss : 0.024994, loss_ce: 0.010112
2022-01-08 12:01:59,468 iteration 3007 : loss : 0.026570, loss_ce: 0.009496
2022-01-08 12:02:01,864 iteration 3008 : loss : 0.026099, loss_ce: 0.009210
2022-01-08 12:02:04,188 iteration 3009 : loss : 0.025578, loss_ce: 0.006415
 44%|███████████▉               | 177/400 [2:08:18<2:42:13, 43.65s/it]2022-01-08 12:02:06,642 iteration 3010 : loss : 0.045199, loss_ce: 0.014790
2022-01-08 12:02:08,991 iteration 3011 : loss : 0.045470, loss_ce: 0.014086
2022-01-08 12:02:11,335 iteration 3012 : loss : 0.034538, loss_ce: 0.011945
2022-01-08 12:02:13,751 iteration 3013 : loss : 0.022653, loss_ce: 0.008066
2022-01-08 12:02:16,051 iteration 3014 : loss : 0.037886, loss_ce: 0.016602
2022-01-08 12:02:18,355 iteration 3015 : loss : 0.023328, loss_ce: 0.006841
2022-01-08 12:02:20,540 iteration 3016 : loss : 0.019156, loss_ce: 0.006070
2022-01-08 12:02:22,833 iteration 3017 : loss : 0.038496, loss_ce: 0.020276
2022-01-08 12:02:25,158 iteration 3018 : loss : 0.028340, loss_ce: 0.014195
2022-01-08 12:02:27,545 iteration 3019 : loss : 0.044030, loss_ce: 0.020730
2022-01-08 12:02:29,786 iteration 3020 : loss : 0.043849, loss_ce: 0.013514
2022-01-08 12:02:32,022 iteration 3021 : loss : 0.024426, loss_ce: 0.010606
2022-01-08 12:02:34,222 iteration 3022 : loss : 0.020461, loss_ce: 0.009630
2022-01-08 12:02:36,534 iteration 3023 : loss : 0.020869, loss_ce: 0.007887
2022-01-08 12:02:38,846 iteration 3024 : loss : 0.028158, loss_ce: 0.011289
2022-01-08 12:02:41,213 iteration 3025 : loss : 0.023099, loss_ce: 0.009305
2022-01-08 12:02:43,555 iteration 3026 : loss : 0.030030, loss_ce: 0.008485
 44%|████████████               | 178/400 [2:08:58<2:36:44, 42.36s/it]2022-01-08 12:02:45,990 iteration 3027 : loss : 0.029441, loss_ce: 0.013476
2022-01-08 12:02:48,419 iteration 3028 : loss : 0.038025, loss_ce: 0.013696
2022-01-08 12:02:50,809 iteration 3029 : loss : 0.016911, loss_ce: 0.005752
2022-01-08 12:02:53,230 iteration 3030 : loss : 0.031240, loss_ce: 0.010085
2022-01-08 12:02:55,641 iteration 3031 : loss : 0.041766, loss_ce: 0.011968
2022-01-08 12:02:58,056 iteration 3032 : loss : 0.022308, loss_ce: 0.009451
2022-01-08 12:03:00,389 iteration 3033 : loss : 0.033216, loss_ce: 0.009739
2022-01-08 12:03:02,773 iteration 3034 : loss : 0.021639, loss_ce: 0.005762
2022-01-08 12:03:05,158 iteration 3035 : loss : 0.024580, loss_ce: 0.010064
2022-01-08 12:03:07,582 iteration 3036 : loss : 0.028982, loss_ce: 0.012529
2022-01-08 12:03:09,910 iteration 3037 : loss : 0.029784, loss_ce: 0.012256
2022-01-08 12:03:12,254 iteration 3038 : loss : 0.026980, loss_ce: 0.012245
2022-01-08 12:03:14,585 iteration 3039 : loss : 0.036480, loss_ce: 0.014091
2022-01-08 12:03:17,044 iteration 3040 : loss : 0.027639, loss_ce: 0.008051
2022-01-08 12:03:19,353 iteration 3041 : loss : 0.018721, loss_ce: 0.006823
2022-01-08 12:03:21,687 iteration 3042 : loss : 0.023226, loss_ce: 0.010946
2022-01-08 12:03:24,103 iteration 3043 : loss : 0.022536, loss_ce: 0.008947
 45%|████████████               | 179/400 [2:09:38<2:34:02, 41.82s/it]2022-01-08 12:03:26,573 iteration 3044 : loss : 0.021050, loss_ce: 0.008569
2022-01-08 12:03:28,838 iteration 3045 : loss : 0.030644, loss_ce: 0.009781
2022-01-08 12:03:31,194 iteration 3046 : loss : 0.022812, loss_ce: 0.009185
2022-01-08 12:03:33,547 iteration 3047 : loss : 0.023656, loss_ce: 0.008486
2022-01-08 12:03:35,876 iteration 3048 : loss : 0.026880, loss_ce: 0.009244
2022-01-08 12:03:38,301 iteration 3049 : loss : 0.031632, loss_ce: 0.009821
2022-01-08 12:03:40,652 iteration 3050 : loss : 0.031217, loss_ce: 0.006388
2022-01-08 12:03:42,974 iteration 3051 : loss : 0.024785, loss_ce: 0.009029
2022-01-08 12:03:45,228 iteration 3052 : loss : 0.032116, loss_ce: 0.014051
2022-01-08 12:03:47,334 iteration 3053 : loss : 0.017230, loss_ce: 0.005946
2022-01-08 12:03:49,424 iteration 3054 : loss : 0.027387, loss_ce: 0.011904
2022-01-08 12:03:51,580 iteration 3055 : loss : 0.030704, loss_ce: 0.012862
2022-01-08 12:03:53,818 iteration 3056 : loss : 0.019976, loss_ce: 0.006382
2022-01-08 12:03:56,280 iteration 3057 : loss : 0.032947, loss_ce: 0.012970
2022-01-08 12:03:58,551 iteration 3058 : loss : 0.021529, loss_ce: 0.006659
2022-01-08 12:04:00,862 iteration 3059 : loss : 0.027718, loss_ce: 0.017043
2022-01-08 12:04:00,862 Training Data Eval:
2022-01-08 12:04:13,430   Average segmentation loss on training set: 0.0165
2022-01-08 12:04:13,431 Validation Data Eval:
2022-01-08 12:04:17,809   Average segmentation loss on validation set: 0.0663
2022-01-08 12:04:20,223 iteration 3060 : loss : 0.027913, loss_ce: 0.010937
 45%|████████████▏              | 180/400 [2:10:34<2:49:03, 46.11s/it]2022-01-08 12:04:22,675 iteration 3061 : loss : 0.020286, loss_ce: 0.005391
2022-01-08 12:04:25,116 iteration 3062 : loss : 0.031636, loss_ce: 0.013015
2022-01-08 12:04:27,476 iteration 3063 : loss : 0.022040, loss_ce: 0.009215
2022-01-08 12:04:29,766 iteration 3064 : loss : 0.031468, loss_ce: 0.016558
2022-01-08 12:04:32,063 iteration 3065 : loss : 0.030523, loss_ce: 0.009043
2022-01-08 12:04:34,310 iteration 3066 : loss : 0.021194, loss_ce: 0.006764
2022-01-08 12:04:36,664 iteration 3067 : loss : 0.022702, loss_ce: 0.009393
2022-01-08 12:04:38,972 iteration 3068 : loss : 0.024056, loss_ce: 0.009808
2022-01-08 12:04:41,194 iteration 3069 : loss : 0.012172, loss_ce: 0.004686
2022-01-08 12:04:43,541 iteration 3070 : loss : 0.042206, loss_ce: 0.015254
2022-01-08 12:04:45,969 iteration 3071 : loss : 0.032654, loss_ce: 0.010812
2022-01-08 12:04:48,291 iteration 3072 : loss : 0.018262, loss_ce: 0.007253
2022-01-08 12:04:50,651 iteration 3073 : loss : 0.027382, loss_ce: 0.008658
2022-01-08 12:04:52,995 iteration 3074 : loss : 0.027026, loss_ce: 0.011140
2022-01-08 12:04:55,363 iteration 3075 : loss : 0.050944, loss_ce: 0.018727
2022-01-08 12:04:57,577 iteration 3076 : loss : 0.022852, loss_ce: 0.007785
2022-01-08 12:04:59,913 iteration 3077 : loss : 0.051372, loss_ce: 0.017711
 45%|████████████▏              | 181/400 [2:11:14<2:41:16, 44.18s/it]2022-01-08 12:05:02,269 iteration 3078 : loss : 0.059790, loss_ce: 0.007920
2022-01-08 12:05:04,547 iteration 3079 : loss : 0.023805, loss_ce: 0.007093
2022-01-08 12:05:06,881 iteration 3080 : loss : 0.025128, loss_ce: 0.007245
2022-01-08 12:05:09,186 iteration 3081 : loss : 0.031225, loss_ce: 0.011530
2022-01-08 12:05:11,449 iteration 3082 : loss : 0.041662, loss_ce: 0.012646
2022-01-08 12:05:13,680 iteration 3083 : loss : 0.050679, loss_ce: 0.014867
2022-01-08 12:05:15,951 iteration 3084 : loss : 0.039801, loss_ce: 0.014953
2022-01-08 12:05:18,172 iteration 3085 : loss : 0.025936, loss_ce: 0.010472
2022-01-08 12:05:20,469 iteration 3086 : loss : 0.024586, loss_ce: 0.012053
2022-01-08 12:05:22,896 iteration 3087 : loss : 0.028486, loss_ce: 0.011461
2022-01-08 12:05:25,311 iteration 3088 : loss : 0.031752, loss_ce: 0.013741
2022-01-08 12:05:27,730 iteration 3089 : loss : 0.044527, loss_ce: 0.014938
2022-01-08 12:05:29,966 iteration 3090 : loss : 0.027524, loss_ce: 0.010841
2022-01-08 12:05:32,353 iteration 3091 : loss : 0.034402, loss_ce: 0.013296
2022-01-08 12:05:34,611 iteration 3092 : loss : 0.033283, loss_ce: 0.017261
2022-01-08 12:05:36,843 iteration 3093 : loss : 0.023909, loss_ce: 0.009876
2022-01-08 12:05:39,098 iteration 3094 : loss : 0.047489, loss_ce: 0.010925
 46%|████████████▎              | 182/400 [2:11:53<2:35:05, 42.68s/it]2022-01-08 12:05:41,488 iteration 3095 : loss : 0.024720, loss_ce: 0.010264
2022-01-08 12:05:43,879 iteration 3096 : loss : 0.025130, loss_ce: 0.008442
2022-01-08 12:05:46,244 iteration 3097 : loss : 0.029631, loss_ce: 0.012947
2022-01-08 12:05:48,628 iteration 3098 : loss : 0.028172, loss_ce: 0.008432
2022-01-08 12:05:50,988 iteration 3099 : loss : 0.031489, loss_ce: 0.017589
2022-01-08 12:05:53,305 iteration 3100 : loss : 0.020431, loss_ce: 0.006672
2022-01-08 12:05:55,636 iteration 3101 : loss : 0.018221, loss_ce: 0.006840
2022-01-08 12:05:57,939 iteration 3102 : loss : 0.022468, loss_ce: 0.008370
2022-01-08 12:06:00,357 iteration 3103 : loss : 0.034391, loss_ce: 0.017121
2022-01-08 12:06:02,732 iteration 3104 : loss : 0.048790, loss_ce: 0.016219
2022-01-08 12:06:05,128 iteration 3105 : loss : 0.022755, loss_ce: 0.008663
2022-01-08 12:06:07,495 iteration 3106 : loss : 0.023297, loss_ce: 0.009216
2022-01-08 12:06:09,922 iteration 3107 : loss : 0.026080, loss_ce: 0.011213
2022-01-08 12:06:12,342 iteration 3108 : loss : 0.029181, loss_ce: 0.010824
2022-01-08 12:06:14,695 iteration 3109 : loss : 0.021998, loss_ce: 0.009769
2022-01-08 12:06:17,047 iteration 3110 : loss : 0.026552, loss_ce: 0.010002
2022-01-08 12:06:19,381 iteration 3111 : loss : 0.033079, loss_ce: 0.008827
 46%|████████████▎              | 183/400 [2:12:34<2:31:46, 41.97s/it]2022-01-08 12:06:21,785 iteration 3112 : loss : 0.024577, loss_ce: 0.009433
2022-01-08 12:06:24,239 iteration 3113 : loss : 0.025463, loss_ce: 0.009406
2022-01-08 12:06:26,584 iteration 3114 : loss : 0.021563, loss_ce: 0.009925
2022-01-08 12:06:29,004 iteration 3115 : loss : 0.030940, loss_ce: 0.011716
2022-01-08 12:06:31,282 iteration 3116 : loss : 0.022165, loss_ce: 0.009025
2022-01-08 12:06:33,628 iteration 3117 : loss : 0.029491, loss_ce: 0.006410
2022-01-08 12:06:35,906 iteration 3118 : loss : 0.020022, loss_ce: 0.008676
2022-01-08 12:06:38,222 iteration 3119 : loss : 0.020139, loss_ce: 0.008661
2022-01-08 12:06:40,417 iteration 3120 : loss : 0.021200, loss_ce: 0.006272
2022-01-08 12:06:42,652 iteration 3121 : loss : 0.040359, loss_ce: 0.011445
2022-01-08 12:06:44,857 iteration 3122 : loss : 0.029927, loss_ce: 0.013675
2022-01-08 12:06:47,160 iteration 3123 : loss : 0.043828, loss_ce: 0.014758
2022-01-08 12:06:49,386 iteration 3124 : loss : 0.020108, loss_ce: 0.007360
2022-01-08 12:06:51,665 iteration 3125 : loss : 0.014841, loss_ce: 0.006161
2022-01-08 12:06:54,047 iteration 3126 : loss : 0.023165, loss_ce: 0.009787
2022-01-08 12:06:56,412 iteration 3127 : loss : 0.021849, loss_ce: 0.009230
2022-01-08 12:06:58,846 iteration 3128 : loss : 0.035942, loss_ce: 0.008090
 46%|████████████▍              | 184/400 [2:13:13<2:28:21, 41.21s/it]2022-01-08 12:07:01,247 iteration 3129 : loss : 0.022910, loss_ce: 0.007606
2022-01-08 12:07:03,528 iteration 3130 : loss : 0.022339, loss_ce: 0.008426
2022-01-08 12:07:05,864 iteration 3131 : loss : 0.032301, loss_ce: 0.015409
2022-01-08 12:07:08,138 iteration 3132 : loss : 0.035444, loss_ce: 0.011793
2022-01-08 12:07:10,333 iteration 3133 : loss : 0.019927, loss_ce: 0.008332
2022-01-08 12:07:12,714 iteration 3134 : loss : 0.023534, loss_ce: 0.010088
2022-01-08 12:07:15,012 iteration 3135 : loss : 0.034577, loss_ce: 0.007920
2022-01-08 12:07:17,178 iteration 3136 : loss : 0.025400, loss_ce: 0.013716
2022-01-08 12:07:19,439 iteration 3137 : loss : 0.020343, loss_ce: 0.008654
2022-01-08 12:07:21,761 iteration 3138 : loss : 0.021087, loss_ce: 0.008364
2022-01-08 12:07:24,200 iteration 3139 : loss : 0.030929, loss_ce: 0.009006
2022-01-08 12:07:26,491 iteration 3140 : loss : 0.035506, loss_ce: 0.014079
2022-01-08 12:07:28,828 iteration 3141 : loss : 0.029334, loss_ce: 0.012437
2022-01-08 12:07:31,066 iteration 3142 : loss : 0.021900, loss_ce: 0.008943
2022-01-08 12:07:33,373 iteration 3143 : loss : 0.041094, loss_ce: 0.011173
2022-01-08 12:07:35,782 iteration 3144 : loss : 0.041271, loss_ce: 0.008385
2022-01-08 12:07:35,782 Training Data Eval:
2022-01-08 12:07:48,440   Average segmentation loss on training set: 0.0206
2022-01-08 12:07:48,440 Validation Data Eval:
2022-01-08 12:07:52,780   Average segmentation loss on validation set: 0.0602
2022-01-08 12:07:58,630 Found new lowest validation loss at iteration 3144! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed2.pth
2022-01-08 12:08:00,170 iteration 3145 : loss : 0.020601, loss_ce: 0.009416
 46%|████████████▍              | 185/400 [2:14:14<2:49:18, 47.25s/it]2022-01-08 12:08:01,883 iteration 3146 : loss : 0.024609, loss_ce: 0.010478
2022-01-08 12:08:03,538 iteration 3147 : loss : 0.041242, loss_ce: 0.015599
2022-01-08 12:08:05,131 iteration 3148 : loss : 0.019739, loss_ce: 0.007601
2022-01-08 12:08:06,887 iteration 3149 : loss : 0.028436, loss_ce: 0.008207
2022-01-08 12:08:08,793 iteration 3150 : loss : 0.026519, loss_ce: 0.007200
2022-01-08 12:08:10,728 iteration 3151 : loss : 0.019186, loss_ce: 0.008179
2022-01-08 12:08:12,875 iteration 3152 : loss : 0.025498, loss_ce: 0.011762
2022-01-08 12:08:15,020 iteration 3153 : loss : 0.019278, loss_ce: 0.008535
2022-01-08 12:08:17,140 iteration 3154 : loss : 0.025402, loss_ce: 0.007058
2022-01-08 12:08:19,242 iteration 3155 : loss : 0.020575, loss_ce: 0.006713
2022-01-08 12:08:21,368 iteration 3156 : loss : 0.022441, loss_ce: 0.008667
2022-01-08 12:08:23,490 iteration 3157 : loss : 0.030904, loss_ce: 0.009242
2022-01-08 12:08:25,845 iteration 3158 : loss : 0.024996, loss_ce: 0.009154
2022-01-08 12:08:28,105 iteration 3159 : loss : 0.023532, loss_ce: 0.010132
2022-01-08 12:08:30,330 iteration 3160 : loss : 0.020683, loss_ce: 0.008965
2022-01-08 12:08:32,781 iteration 3161 : loss : 0.030594, loss_ce: 0.010219
2022-01-08 12:08:35,198 iteration 3162 : loss : 0.028692, loss_ce: 0.012356
 46%|████████████▌              | 186/400 [2:14:49<2:35:25, 43.58s/it]2022-01-08 12:08:37,472 iteration 3163 : loss : 0.024713, loss_ce: 0.006774
2022-01-08 12:08:39,729 iteration 3164 : loss : 0.029051, loss_ce: 0.008082
2022-01-08 12:08:41,997 iteration 3165 : loss : 0.014854, loss_ce: 0.006100
2022-01-08 12:08:44,266 iteration 3166 : loss : 0.024635, loss_ce: 0.011340
2022-01-08 12:08:46,550 iteration 3167 : loss : 0.036054, loss_ce: 0.010914
2022-01-08 12:08:48,753 iteration 3168 : loss : 0.018195, loss_ce: 0.008630
2022-01-08 12:08:51,012 iteration 3169 : loss : 0.017901, loss_ce: 0.006119
2022-01-08 12:08:53,360 iteration 3170 : loss : 0.023885, loss_ce: 0.010463
2022-01-08 12:08:55,762 iteration 3171 : loss : 0.029306, loss_ce: 0.008280
2022-01-08 12:08:58,074 iteration 3172 : loss : 0.023084, loss_ce: 0.009695
2022-01-08 12:09:00,492 iteration 3173 : loss : 0.024290, loss_ce: 0.008420
2022-01-08 12:09:02,851 iteration 3174 : loss : 0.025849, loss_ce: 0.007348
2022-01-08 12:09:05,072 iteration 3175 : loss : 0.023961, loss_ce: 0.008683
2022-01-08 12:09:07,353 iteration 3176 : loss : 0.020825, loss_ce: 0.010093
2022-01-08 12:09:09,612 iteration 3177 : loss : 0.021593, loss_ce: 0.009223
2022-01-08 12:09:11,846 iteration 3178 : loss : 0.024522, loss_ce: 0.006374
2022-01-08 12:09:14,105 iteration 3179 : loss : 0.028704, loss_ce: 0.007414
 47%|████████████▌              | 187/400 [2:15:28<2:29:43, 42.18s/it]2022-01-08 12:09:16,438 iteration 3180 : loss : 0.017618, loss_ce: 0.007389
2022-01-08 12:09:18,678 iteration 3181 : loss : 0.035760, loss_ce: 0.014727
2022-01-08 12:09:20,997 iteration 3182 : loss : 0.024033, loss_ce: 0.009038
2022-01-08 12:09:23,356 iteration 3183 : loss : 0.020558, loss_ce: 0.008643
2022-01-08 12:09:25,525 iteration 3184 : loss : 0.017332, loss_ce: 0.007176
2022-01-08 12:09:27,693 iteration 3185 : loss : 0.028830, loss_ce: 0.011008
2022-01-08 12:09:29,903 iteration 3186 : loss : 0.022044, loss_ce: 0.010097
2022-01-08 12:09:32,071 iteration 3187 : loss : 0.024929, loss_ce: 0.008047
2022-01-08 12:09:34,322 iteration 3188 : loss : 0.025029, loss_ce: 0.007824
2022-01-08 12:09:36,528 iteration 3189 : loss : 0.017161, loss_ce: 0.007837
2022-01-08 12:09:38,874 iteration 3190 : loss : 0.030770, loss_ce: 0.011314
2022-01-08 12:09:41,166 iteration 3191 : loss : 0.025040, loss_ce: 0.007504
2022-01-08 12:09:43,427 iteration 3192 : loss : 0.016192, loss_ce: 0.006773
2022-01-08 12:09:45,751 iteration 3193 : loss : 0.022298, loss_ce: 0.009235
2022-01-08 12:09:48,066 iteration 3194 : loss : 0.020967, loss_ce: 0.006872
2022-01-08 12:09:50,432 iteration 3195 : loss : 0.022814, loss_ce: 0.006396
2022-01-08 12:09:52,826 iteration 3196 : loss : 0.019511, loss_ce: 0.005317
 47%|████████████▋              | 188/400 [2:16:07<2:25:22, 41.14s/it]2022-01-08 12:09:55,216 iteration 3197 : loss : 0.020703, loss_ce: 0.006326
2022-01-08 12:09:57,568 iteration 3198 : loss : 0.026519, loss_ce: 0.010393
2022-01-08 12:09:59,918 iteration 3199 : loss : 0.018747, loss_ce: 0.006995
2022-01-08 12:10:02,259 iteration 3200 : loss : 0.019617, loss_ce: 0.008381
2022-01-08 12:10:04,828 iteration 3201 : loss : 0.029326, loss_ce: 0.009038
2022-01-08 12:10:07,241 iteration 3202 : loss : 0.034574, loss_ce: 0.016214
2022-01-08 12:10:09,537 iteration 3203 : loss : 0.028998, loss_ce: 0.005978
2022-01-08 12:10:11,924 iteration 3204 : loss : 0.020184, loss_ce: 0.009733
2022-01-08 12:10:14,330 iteration 3205 : loss : 0.021713, loss_ce: 0.007534
2022-01-08 12:10:16,696 iteration 3206 : loss : 0.027633, loss_ce: 0.010288
2022-01-08 12:10:19,060 iteration 3207 : loss : 0.017247, loss_ce: 0.005549
2022-01-08 12:10:21,399 iteration 3208 : loss : 0.028815, loss_ce: 0.008550
2022-01-08 12:10:23,885 iteration 3209 : loss : 0.020627, loss_ce: 0.007870
2022-01-08 12:10:26,300 iteration 3210 : loss : 0.031836, loss_ce: 0.010552
2022-01-08 12:10:28,717 iteration 3211 : loss : 0.025737, loss_ce: 0.012993
2022-01-08 12:10:31,104 iteration 3212 : loss : 0.022380, loss_ce: 0.009565
2022-01-08 12:10:33,417 iteration 3213 : loss : 0.020264, loss_ce: 0.009497
 47%|████████████▊              | 189/400 [2:16:48<2:24:05, 40.98s/it]2022-01-08 12:10:35,782 iteration 3214 : loss : 0.023749, loss_ce: 0.009799
2022-01-08 12:10:38,199 iteration 3215 : loss : 0.019319, loss_ce: 0.008474
2022-01-08 12:10:40,566 iteration 3216 : loss : 0.022460, loss_ce: 0.008923
2022-01-08 12:10:42,991 iteration 3217 : loss : 0.052311, loss_ce: 0.022625
2022-01-08 12:10:45,368 iteration 3218 : loss : 0.020253, loss_ce: 0.008452
2022-01-08 12:10:47,723 iteration 3219 : loss : 0.019578, loss_ce: 0.006133
2022-01-08 12:10:50,314 iteration 3220 : loss : 0.033571, loss_ce: 0.014956
2022-01-08 12:10:52,725 iteration 3221 : loss : 0.022916, loss_ce: 0.007704
2022-01-08 12:10:55,056 iteration 3222 : loss : 0.018001, loss_ce: 0.006228
2022-01-08 12:10:57,411 iteration 3223 : loss : 0.038638, loss_ce: 0.010394
2022-01-08 12:10:59,657 iteration 3224 : loss : 0.018279, loss_ce: 0.006654
2022-01-08 12:11:01,879 iteration 3225 : loss : 0.024203, loss_ce: 0.008459
2022-01-08 12:11:04,145 iteration 3226 : loss : 0.022921, loss_ce: 0.009732
2022-01-08 12:11:06,504 iteration 3227 : loss : 0.026323, loss_ce: 0.009771
2022-01-08 12:11:08,880 iteration 3228 : loss : 0.032160, loss_ce: 0.015746
2022-01-08 12:11:11,195 iteration 3229 : loss : 0.016066, loss_ce: 0.005225
2022-01-08 12:11:11,196 Training Data Eval:
2022-01-08 12:11:24,079   Average segmentation loss on training set: 0.0158
2022-01-08 12:11:24,079 Validation Data Eval:
2022-01-08 12:11:28,562   Average segmentation loss on validation set: 0.1069
2022-01-08 12:11:30,948 iteration 3230 : loss : 0.021372, loss_ce: 0.010986
 48%|████████████▊              | 190/400 [2:17:45<2:40:48, 45.95s/it]2022-01-08 12:11:33,284 iteration 3231 : loss : 0.018362, loss_ce: 0.006968
2022-01-08 12:11:35,628 iteration 3232 : loss : 0.018151, loss_ce: 0.006935
2022-01-08 12:11:38,108 iteration 3233 : loss : 0.026506, loss_ce: 0.006589
2022-01-08 12:11:40,459 iteration 3234 : loss : 0.017753, loss_ce: 0.006858
2022-01-08 12:11:42,874 iteration 3235 : loss : 0.024599, loss_ce: 0.009382
2022-01-08 12:11:45,284 iteration 3236 : loss : 0.019104, loss_ce: 0.009729
2022-01-08 12:11:47,669 iteration 3237 : loss : 0.018423, loss_ce: 0.006982
2022-01-08 12:11:50,041 iteration 3238 : loss : 0.021690, loss_ce: 0.008538
2022-01-08 12:11:52,295 iteration 3239 : loss : 0.020351, loss_ce: 0.008454
2022-01-08 12:11:54,693 iteration 3240 : loss : 0.022521, loss_ce: 0.008595
2022-01-08 12:11:57,146 iteration 3241 : loss : 0.035067, loss_ce: 0.012621
2022-01-08 12:11:59,521 iteration 3242 : loss : 0.018144, loss_ce: 0.007037
2022-01-08 12:12:01,956 iteration 3243 : loss : 0.019694, loss_ce: 0.008416
2022-01-08 12:12:04,329 iteration 3244 : loss : 0.025253, loss_ce: 0.008720
2022-01-08 12:12:06,753 iteration 3245 : loss : 0.025231, loss_ce: 0.008599
2022-01-08 12:12:09,170 iteration 3246 : loss : 0.026052, loss_ce: 0.008615
2022-01-08 12:12:11,603 iteration 3247 : loss : 0.028568, loss_ce: 0.011058
 48%|████████████▉              | 191/400 [2:18:26<2:34:31, 44.36s/it]2022-01-08 12:12:14,064 iteration 3248 : loss : 0.031532, loss_ce: 0.008776
2022-01-08 12:12:16,535 iteration 3249 : loss : 0.018878, loss_ce: 0.006294
2022-01-08 12:12:18,927 iteration 3250 : loss : 0.025509, loss_ce: 0.008776
2022-01-08 12:12:21,324 iteration 3251 : loss : 0.033779, loss_ce: 0.013426
2022-01-08 12:12:23,572 iteration 3252 : loss : 0.016799, loss_ce: 0.007894
2022-01-08 12:12:25,851 iteration 3253 : loss : 0.039982, loss_ce: 0.015516
2022-01-08 12:12:28,348 iteration 3254 : loss : 0.027528, loss_ce: 0.013083
2022-01-08 12:12:30,742 iteration 3255 : loss : 0.018668, loss_ce: 0.007254
2022-01-08 12:12:33,078 iteration 3256 : loss : 0.019565, loss_ce: 0.007674
2022-01-08 12:12:35,376 iteration 3257 : loss : 0.031359, loss_ce: 0.012474
2022-01-08 12:12:37,629 iteration 3258 : loss : 0.019380, loss_ce: 0.004987
2022-01-08 12:12:40,091 iteration 3259 : loss : 0.028612, loss_ce: 0.010733
2022-01-08 12:12:42,531 iteration 3260 : loss : 0.025230, loss_ce: 0.010146
2022-01-08 12:12:44,918 iteration 3261 : loss : 0.023892, loss_ce: 0.009358
2022-01-08 12:12:47,381 iteration 3262 : loss : 0.038831, loss_ce: 0.015579
2022-01-08 12:12:49,669 iteration 3263 : loss : 0.023066, loss_ce: 0.008047
2022-01-08 12:12:52,102 iteration 3264 : loss : 0.026524, loss_ce: 0.008745
 48%|████████████▉              | 192/400 [2:19:06<2:29:44, 43.20s/it]2022-01-08 12:12:54,479 iteration 3265 : loss : 0.021377, loss_ce: 0.008615
2022-01-08 12:12:56,880 iteration 3266 : loss : 0.022677, loss_ce: 0.007996
2022-01-08 12:12:59,246 iteration 3267 : loss : 0.017958, loss_ce: 0.005915
2022-01-08 12:13:01,604 iteration 3268 : loss : 0.024405, loss_ce: 0.009349
2022-01-08 12:13:04,108 iteration 3269 : loss : 0.020788, loss_ce: 0.010037
2022-01-08 12:13:06,525 iteration 3270 : loss : 0.027046, loss_ce: 0.009942
2022-01-08 12:13:08,987 iteration 3271 : loss : 0.020164, loss_ce: 0.006120
2022-01-08 12:13:11,451 iteration 3272 : loss : 0.033631, loss_ce: 0.011919
2022-01-08 12:13:13,789 iteration 3273 : loss : 0.024983, loss_ce: 0.011641
2022-01-08 12:13:16,039 iteration 3274 : loss : 0.022586, loss_ce: 0.007397
2022-01-08 12:13:18,362 iteration 3275 : loss : 0.023113, loss_ce: 0.007866
2022-01-08 12:13:20,738 iteration 3276 : loss : 0.018485, loss_ce: 0.005379
2022-01-08 12:13:23,111 iteration 3277 : loss : 0.018126, loss_ce: 0.006391
2022-01-08 12:13:25,547 iteration 3278 : loss : 0.020028, loss_ce: 0.007577
2022-01-08 12:13:27,964 iteration 3279 : loss : 0.023832, loss_ce: 0.013506
2022-01-08 12:13:30,403 iteration 3280 : loss : 0.030313, loss_ce: 0.012040
2022-01-08 12:13:32,720 iteration 3281 : loss : 0.017993, loss_ce: 0.005424
 48%|█████████████              | 193/400 [2:19:47<2:26:21, 42.42s/it]2022-01-08 12:13:35,382 iteration 3282 : loss : 0.024835, loss_ce: 0.006378
2022-01-08 12:13:37,807 iteration 3283 : loss : 0.021336, loss_ce: 0.007728
2022-01-08 12:13:40,149 iteration 3284 : loss : 0.026833, loss_ce: 0.012900
2022-01-08 12:13:42,551 iteration 3285 : loss : 0.042834, loss_ce: 0.012638
2022-01-08 12:13:44,928 iteration 3286 : loss : 0.036843, loss_ce: 0.011275
2022-01-08 12:13:47,301 iteration 3287 : loss : 0.027071, loss_ce: 0.011319
2022-01-08 12:13:49,528 iteration 3288 : loss : 0.023875, loss_ce: 0.009433
2022-01-08 12:13:51,973 iteration 3289 : loss : 0.028166, loss_ce: 0.013701
2022-01-08 12:13:54,331 iteration 3290 : loss : 0.027365, loss_ce: 0.008404
2022-01-08 12:13:56,701 iteration 3291 : loss : 0.030563, loss_ce: 0.015141
2022-01-08 12:13:59,075 iteration 3292 : loss : 0.021749, loss_ce: 0.007458
2022-01-08 12:14:01,407 iteration 3293 : loss : 0.027731, loss_ce: 0.006384
2022-01-08 12:14:03,801 iteration 3294 : loss : 0.037858, loss_ce: 0.018860
2022-01-08 12:14:06,243 iteration 3295 : loss : 0.021763, loss_ce: 0.009325
2022-01-08 12:14:08,643 iteration 3296 : loss : 0.024572, loss_ce: 0.008231
2022-01-08 12:14:11,217 iteration 3297 : loss : 0.020988, loss_ce: 0.007714
2022-01-08 12:14:13,704 iteration 3298 : loss : 0.022424, loss_ce: 0.009399
 48%|█████████████              | 194/400 [2:20:28<2:24:11, 42.00s/it]2022-01-08 12:14:16,105 iteration 3299 : loss : 0.019199, loss_ce: 0.004729
2022-01-08 12:14:18,530 iteration 3300 : loss : 0.021605, loss_ce: 0.006787
2022-01-08 12:14:20,849 iteration 3301 : loss : 0.018660, loss_ce: 0.008039
2022-01-08 12:14:23,236 iteration 3302 : loss : 0.027724, loss_ce: 0.008634
2022-01-08 12:14:25,684 iteration 3303 : loss : 0.019328, loss_ce: 0.008716
2022-01-08 12:14:28,023 iteration 3304 : loss : 0.022185, loss_ce: 0.008215
2022-01-08 12:14:30,432 iteration 3305 : loss : 0.020736, loss_ce: 0.007137
2022-01-08 12:14:32,807 iteration 3306 : loss : 0.034312, loss_ce: 0.008835
2022-01-08 12:14:35,324 iteration 3307 : loss : 0.029739, loss_ce: 0.013090
2022-01-08 12:14:37,778 iteration 3308 : loss : 0.031228, loss_ce: 0.012407
2022-01-08 12:14:40,158 iteration 3309 : loss : 0.020415, loss_ce: 0.009233
2022-01-08 12:14:42,465 iteration 3310 : loss : 0.017750, loss_ce: 0.009063
2022-01-08 12:14:44,887 iteration 3311 : loss : 0.034180, loss_ce: 0.013542
2022-01-08 12:14:47,265 iteration 3312 : loss : 0.024624, loss_ce: 0.006342
2022-01-08 12:14:49,686 iteration 3313 : loss : 0.025391, loss_ce: 0.009818
2022-01-08 12:14:52,084 iteration 3314 : loss : 0.028121, loss_ce: 0.008773
2022-01-08 12:14:52,084 Training Data Eval:
2022-01-08 12:15:05,020   Average segmentation loss on training set: 0.0154
2022-01-08 12:15:05,020 Validation Data Eval:
2022-01-08 12:15:09,413   Average segmentation loss on validation set: 0.0819
2022-01-08 12:15:11,771 iteration 3315 : loss : 0.019384, loss_ce: 0.007336
 49%|█████████████▏             | 195/400 [2:21:26<2:39:57, 46.82s/it]2022-01-08 12:15:14,122 iteration 3316 : loss : 0.019080, loss_ce: 0.008001
2022-01-08 12:15:16,427 iteration 3317 : loss : 0.019884, loss_ce: 0.009397
2022-01-08 12:15:18,678 iteration 3318 : loss : 0.027634, loss_ce: 0.011815
2022-01-08 12:15:20,937 iteration 3319 : loss : 0.019154, loss_ce: 0.006583
2022-01-08 12:15:23,337 iteration 3320 : loss : 0.030179, loss_ce: 0.011918
2022-01-08 12:15:25,720 iteration 3321 : loss : 0.019264, loss_ce: 0.006278
2022-01-08 12:15:28,128 iteration 3322 : loss : 0.040704, loss_ce: 0.014161
2022-01-08 12:15:30,457 iteration 3323 : loss : 0.018253, loss_ce: 0.005571
2022-01-08 12:15:32,806 iteration 3324 : loss : 0.022882, loss_ce: 0.009819
2022-01-08 12:15:35,181 iteration 3325 : loss : 0.027022, loss_ce: 0.010006
2022-01-08 12:15:37,481 iteration 3326 : loss : 0.022796, loss_ce: 0.008682
2022-01-08 12:15:39,815 iteration 3327 : loss : 0.019054, loss_ce: 0.005573
2022-01-08 12:15:42,167 iteration 3328 : loss : 0.022146, loss_ce: 0.007924
2022-01-08 12:15:44,641 iteration 3329 : loss : 0.034136, loss_ce: 0.013607
2022-01-08 12:15:47,030 iteration 3330 : loss : 0.023602, loss_ce: 0.012532
2022-01-08 12:15:49,361 iteration 3331 : loss : 0.021919, loss_ce: 0.010551
2022-01-08 12:15:51,772 iteration 3332 : loss : 0.032980, loss_ce: 0.009704
 49%|█████████████▏             | 196/400 [2:22:06<2:32:12, 44.77s/it]2022-01-08 12:15:54,232 iteration 3333 : loss : 0.025610, loss_ce: 0.008851
2022-01-08 12:15:56,682 iteration 3334 : loss : 0.030934, loss_ce: 0.014687
2022-01-08 12:15:59,143 iteration 3335 : loss : 0.029781, loss_ce: 0.012654
2022-01-08 12:16:01,515 iteration 3336 : loss : 0.031114, loss_ce: 0.009494
2022-01-08 12:16:03,920 iteration 3337 : loss : 0.029565, loss_ce: 0.010141
2022-01-08 12:16:06,378 iteration 3338 : loss : 0.028374, loss_ce: 0.011987
2022-01-08 12:16:08,712 iteration 3339 : loss : 0.023660, loss_ce: 0.010571
2022-01-08 12:16:11,051 iteration 3340 : loss : 0.036815, loss_ce: 0.009821
2022-01-08 12:16:13,419 iteration 3341 : loss : 0.026526, loss_ce: 0.010009
2022-01-08 12:16:15,770 iteration 3342 : loss : 0.020395, loss_ce: 0.009466
2022-01-08 12:16:18,193 iteration 3343 : loss : 0.025014, loss_ce: 0.011516
2022-01-08 12:16:20,626 iteration 3344 : loss : 0.026730, loss_ce: 0.009196
2022-01-08 12:16:23,031 iteration 3345 : loss : 0.026054, loss_ce: 0.011993
2022-01-08 12:16:25,413 iteration 3346 : loss : 0.025614, loss_ce: 0.012928
2022-01-08 12:16:27,797 iteration 3347 : loss : 0.020247, loss_ce: 0.007874
2022-01-08 12:16:30,213 iteration 3348 : loss : 0.020509, loss_ce: 0.007205
2022-01-08 12:16:32,685 iteration 3349 : loss : 0.053556, loss_ce: 0.018543
 49%|█████████████▎             | 197/400 [2:22:47<2:27:34, 43.62s/it]2022-01-08 12:16:35,137 iteration 3350 : loss : 0.029479, loss_ce: 0.010911
2022-01-08 12:16:37,489 iteration 3351 : loss : 0.033288, loss_ce: 0.011022
2022-01-08 12:16:39,764 iteration 3352 : loss : 0.039338, loss_ce: 0.017423
2022-01-08 12:16:42,063 iteration 3353 : loss : 0.021820, loss_ce: 0.007461
2022-01-08 12:16:44,228 iteration 3354 : loss : 0.023477, loss_ce: 0.010184
2022-01-08 12:16:46,554 iteration 3355 : loss : 0.031174, loss_ce: 0.013178
2022-01-08 12:16:48,826 iteration 3356 : loss : 0.028967, loss_ce: 0.010082
2022-01-08 12:16:51,084 iteration 3357 : loss : 0.027932, loss_ce: 0.007519
2022-01-08 12:16:53,430 iteration 3358 : loss : 0.018542, loss_ce: 0.007464
2022-01-08 12:16:55,739 iteration 3359 : loss : 0.019283, loss_ce: 0.006622
2022-01-08 12:16:58,057 iteration 3360 : loss : 0.026976, loss_ce: 0.009602
2022-01-08 12:17:00,389 iteration 3361 : loss : 0.027016, loss_ce: 0.009801
2022-01-08 12:17:02,822 iteration 3362 : loss : 0.024181, loss_ce: 0.008167
2022-01-08 12:17:05,272 iteration 3363 : loss : 0.032134, loss_ce: 0.009280
2022-01-08 12:17:07,585 iteration 3364 : loss : 0.021597, loss_ce: 0.009515
2022-01-08 12:17:09,987 iteration 3365 : loss : 0.025973, loss_ce: 0.010821
2022-01-08 12:17:12,288 iteration 3366 : loss : 0.017939, loss_ce: 0.007266
 50%|█████████████▎             | 198/400 [2:23:27<2:22:46, 42.41s/it]2022-01-08 12:17:14,700 iteration 3367 : loss : 0.021741, loss_ce: 0.008343
2022-01-08 12:17:17,217 iteration 3368 : loss : 0.015141, loss_ce: 0.006749
2022-01-08 12:17:19,559 iteration 3369 : loss : 0.019561, loss_ce: 0.006415
2022-01-08 12:17:21,963 iteration 3370 : loss : 0.027065, loss_ce: 0.013184
2022-01-08 12:17:24,334 iteration 3371 : loss : 0.028178, loss_ce: 0.010078
2022-01-08 12:17:26,814 iteration 3372 : loss : 0.018475, loss_ce: 0.007873
2022-01-08 12:17:29,208 iteration 3373 : loss : 0.022350, loss_ce: 0.007199
2022-01-08 12:17:31,473 iteration 3374 : loss : 0.018552, loss_ce: 0.006499
2022-01-08 12:17:33,852 iteration 3375 : loss : 0.055135, loss_ce: 0.022101
2022-01-08 12:17:36,202 iteration 3376 : loss : 0.024943, loss_ce: 0.007253
2022-01-08 12:17:38,479 iteration 3377 : loss : 0.014897, loss_ce: 0.005646
2022-01-08 12:17:40,887 iteration 3378 : loss : 0.035343, loss_ce: 0.008207
2022-01-08 12:17:43,313 iteration 3379 : loss : 0.034060, loss_ce: 0.015899
2022-01-08 12:17:45,720 iteration 3380 : loss : 0.024613, loss_ce: 0.007676
2022-01-08 12:17:48,145 iteration 3381 : loss : 0.034384, loss_ce: 0.012541
2022-01-08 12:17:50,587 iteration 3382 : loss : 0.021669, loss_ce: 0.008411
2022-01-08 12:17:52,952 iteration 3383 : loss : 0.017300, loss_ce: 0.006242
 50%|█████████████▍             | 199/400 [2:24:07<2:20:18, 41.88s/it]2022-01-08 12:17:55,438 iteration 3384 : loss : 0.027617, loss_ce: 0.008610
2022-01-08 12:17:58,026 iteration 3385 : loss : 0.026892, loss_ce: 0.011316
2022-01-08 12:18:00,362 iteration 3386 : loss : 0.019279, loss_ce: 0.005682
2022-01-08 12:18:02,742 iteration 3387 : loss : 0.023917, loss_ce: 0.009108
2022-01-08 12:18:05,064 iteration 3388 : loss : 0.025934, loss_ce: 0.011891
2022-01-08 12:18:07,250 iteration 3389 : loss : 0.023414, loss_ce: 0.009136
2022-01-08 12:18:09,438 iteration 3390 : loss : 0.014655, loss_ce: 0.006015
2022-01-08 12:18:11,850 iteration 3391 : loss : 0.026588, loss_ce: 0.009323
2022-01-08 12:18:14,236 iteration 3392 : loss : 0.026118, loss_ce: 0.008910
2022-01-08 12:18:16,602 iteration 3393 : loss : 0.019730, loss_ce: 0.007374
2022-01-08 12:18:19,020 iteration 3394 : loss : 0.017039, loss_ce: 0.006566
2022-01-08 12:18:21,366 iteration 3395 : loss : 0.017901, loss_ce: 0.007352
2022-01-08 12:18:23,762 iteration 3396 : loss : 0.030244, loss_ce: 0.008292
2022-01-08 12:18:26,075 iteration 3397 : loss : 0.020450, loss_ce: 0.008320
2022-01-08 12:18:28,357 iteration 3398 : loss : 0.028636, loss_ce: 0.010696
2022-01-08 12:18:30,623 iteration 3399 : loss : 0.038220, loss_ce: 0.013373
2022-01-08 12:18:30,623 Training Data Eval:
2022-01-08 12:18:43,485   Average segmentation loss on training set: 0.0183
2022-01-08 12:18:43,486 Validation Data Eval:
2022-01-08 12:18:47,862   Average segmentation loss on validation set: 0.0957
2022-01-08 12:18:50,192 iteration 3400 : loss : 0.020349, loss_ce: 0.006894
 50%|█████████████▌             | 200/400 [2:25:04<2:34:58, 46.49s/it]2022-01-08 12:18:52,644 iteration 3401 : loss : 0.022724, loss_ce: 0.012044
2022-01-08 12:18:54,924 iteration 3402 : loss : 0.017310, loss_ce: 0.006349
2022-01-08 12:18:57,360 iteration 3403 : loss : 0.026639, loss_ce: 0.009686
2022-01-08 12:18:59,773 iteration 3404 : loss : 0.021440, loss_ce: 0.007702
2022-01-08 12:19:02,272 iteration 3405 : loss : 0.028298, loss_ce: 0.011503
2022-01-08 12:19:04,728 iteration 3406 : loss : 0.022641, loss_ce: 0.008656
2022-01-08 12:19:07,064 iteration 3407 : loss : 0.020424, loss_ce: 0.007942
2022-01-08 12:19:09,371 iteration 3408 : loss : 0.021568, loss_ce: 0.007589
2022-01-08 12:19:11,751 iteration 3409 : loss : 0.016651, loss_ce: 0.005385
2022-01-08 12:19:14,085 iteration 3410 : loss : 0.020480, loss_ce: 0.009369
2022-01-08 12:19:16,480 iteration 3411 : loss : 0.024924, loss_ce: 0.010060
2022-01-08 12:19:18,871 iteration 3412 : loss : 0.029559, loss_ce: 0.013237
2022-01-08 12:19:21,267 iteration 3413 : loss : 0.019291, loss_ce: 0.005320
2022-01-08 12:19:23,668 iteration 3414 : loss : 0.023953, loss_ce: 0.009554
2022-01-08 12:19:25,982 iteration 3415 : loss : 0.018990, loss_ce: 0.008657
2022-01-08 12:19:28,366 iteration 3416 : loss : 0.017718, loss_ce: 0.005781
2022-01-08 12:19:30,659 iteration 3417 : loss : 0.024806, loss_ce: 0.008464
 50%|█████████████▌             | 201/400 [2:25:45<2:28:11, 44.68s/it]2022-01-08 12:19:32,798 iteration 3418 : loss : 0.014371, loss_ce: 0.004615
2022-01-08 12:19:34,909 iteration 3419 : loss : 0.017998, loss_ce: 0.007984
2022-01-08 12:19:37,068 iteration 3420 : loss : 0.020495, loss_ce: 0.006756
2022-01-08 12:19:39,273 iteration 3421 : loss : 0.015999, loss_ce: 0.006199
2022-01-08 12:19:41,575 iteration 3422 : loss : 0.020331, loss_ce: 0.006584
2022-01-08 12:19:43,932 iteration 3423 : loss : 0.023708, loss_ce: 0.012097
2022-01-08 12:19:46,224 iteration 3424 : loss : 0.021218, loss_ce: 0.008639
2022-01-08 12:19:48,598 iteration 3425 : loss : 0.022813, loss_ce: 0.008456
2022-01-08 12:19:50,889 iteration 3426 : loss : 0.024184, loss_ce: 0.008746
2022-01-08 12:19:53,271 iteration 3427 : loss : 0.022193, loss_ce: 0.006568
2022-01-08 12:19:55,640 iteration 3428 : loss : 0.021449, loss_ce: 0.008524
2022-01-08 12:19:57,892 iteration 3429 : loss : 0.018352, loss_ce: 0.005653
2022-01-08 12:20:00,205 iteration 3430 : loss : 0.018593, loss_ce: 0.006981
2022-01-08 12:20:02,568 iteration 3431 : loss : 0.026640, loss_ce: 0.010832
2022-01-08 12:20:04,989 iteration 3432 : loss : 0.026623, loss_ce: 0.011095
2022-01-08 12:20:07,390 iteration 3433 : loss : 0.024382, loss_ce: 0.007828
2022-01-08 12:20:09,695 iteration 3434 : loss : 0.024335, loss_ce: 0.007216
 50%|█████████████▋             | 202/400 [2:26:24<2:21:51, 42.99s/it]2022-01-08 12:20:11,987 iteration 3435 : loss : 0.018015, loss_ce: 0.006583
2022-01-08 12:20:14,344 iteration 3436 : loss : 0.027884, loss_ce: 0.011273
2022-01-08 12:20:16,699 iteration 3437 : loss : 0.025804, loss_ce: 0.010287
2022-01-08 12:20:19,079 iteration 3438 : loss : 0.046311, loss_ce: 0.017633
2022-01-08 12:20:21,294 iteration 3439 : loss : 0.019660, loss_ce: 0.006876
2022-01-08 12:20:23,672 iteration 3440 : loss : 0.022782, loss_ce: 0.009170
2022-01-08 12:20:26,033 iteration 3441 : loss : 0.023932, loss_ce: 0.007553
2022-01-08 12:20:28,394 iteration 3442 : loss : 0.017773, loss_ce: 0.007318
2022-01-08 12:20:30,769 iteration 3443 : loss : 0.023141, loss_ce: 0.009006
2022-01-08 12:20:33,043 iteration 3444 : loss : 0.044208, loss_ce: 0.013709
2022-01-08 12:20:35,297 iteration 3445 : loss : 0.034840, loss_ce: 0.015728
2022-01-08 12:20:37,590 iteration 3446 : loss : 0.022770, loss_ce: 0.010664
2022-01-08 12:20:39,909 iteration 3447 : loss : 0.032395, loss_ce: 0.010285
2022-01-08 12:20:42,194 iteration 3448 : loss : 0.033493, loss_ce: 0.013413
2022-01-08 12:20:44,446 iteration 3449 : loss : 0.020616, loss_ce: 0.008496
2022-01-08 12:20:46,688 iteration 3450 : loss : 0.017577, loss_ce: 0.006186
2022-01-08 12:20:49,027 iteration 3451 : loss : 0.019426, loss_ce: 0.012569
 51%|█████████████▋             | 203/400 [2:27:03<2:17:33, 41.90s/it]2022-01-08 12:20:51,411 iteration 3452 : loss : 0.014538, loss_ce: 0.006543
2022-01-08 12:20:53,803 iteration 3453 : loss : 0.022266, loss_ce: 0.008731
2022-01-08 12:20:56,165 iteration 3454 : loss : 0.030144, loss_ce: 0.012955
2022-01-08 12:20:58,421 iteration 3455 : loss : 0.024441, loss_ce: 0.009867
2022-01-08 12:21:00,695 iteration 3456 : loss : 0.029545, loss_ce: 0.007547
2022-01-08 12:21:02,858 iteration 3457 : loss : 0.019342, loss_ce: 0.008268
2022-01-08 12:21:05,013 iteration 3458 : loss : 0.037472, loss_ce: 0.009583
2022-01-08 12:21:07,314 iteration 3459 : loss : 0.021405, loss_ce: 0.009611
2022-01-08 12:21:09,473 iteration 3460 : loss : 0.016335, loss_ce: 0.006629
2022-01-08 12:21:11,719 iteration 3461 : loss : 0.014485, loss_ce: 0.004771
2022-01-08 12:21:13,942 iteration 3462 : loss : 0.016405, loss_ce: 0.007589
2022-01-08 12:21:16,341 iteration 3463 : loss : 0.020085, loss_ce: 0.009429
2022-01-08 12:21:18,655 iteration 3464 : loss : 0.025991, loss_ce: 0.008796
2022-01-08 12:21:20,913 iteration 3465 : loss : 0.019102, loss_ce: 0.007034
2022-01-08 12:21:23,348 iteration 3466 : loss : 0.023671, loss_ce: 0.009017
2022-01-08 12:21:25,656 iteration 3467 : loss : 0.015098, loss_ce: 0.005714
2022-01-08 12:21:28,054 iteration 3468 : loss : 0.019364, loss_ce: 0.005532
 51%|█████████████▊             | 204/400 [2:27:42<2:14:02, 41.03s/it]2022-01-08 12:21:30,473 iteration 3469 : loss : 0.018861, loss_ce: 0.007436
2022-01-08 12:21:32,760 iteration 3470 : loss : 0.028389, loss_ce: 0.010335
2022-01-08 12:21:35,168 iteration 3471 : loss : 0.028675, loss_ce: 0.012002
2022-01-08 12:21:37,511 iteration 3472 : loss : 0.028746, loss_ce: 0.009940
2022-01-08 12:21:39,683 iteration 3473 : loss : 0.016112, loss_ce: 0.008170
2022-01-08 12:21:41,986 iteration 3474 : loss : 0.026367, loss_ce: 0.010438
2022-01-08 12:21:44,334 iteration 3475 : loss : 0.028580, loss_ce: 0.012996
2022-01-08 12:21:46,595 iteration 3476 : loss : 0.021178, loss_ce: 0.006379
2022-01-08 12:21:48,840 iteration 3477 : loss : 0.022779, loss_ce: 0.006900
2022-01-08 12:21:51,110 iteration 3478 : loss : 0.016525, loss_ce: 0.006314
2022-01-08 12:21:53,383 iteration 3479 : loss : 0.020171, loss_ce: 0.008154
2022-01-08 12:21:55,623 iteration 3480 : loss : 0.015268, loss_ce: 0.007193
2022-01-08 12:21:57,866 iteration 3481 : loss : 0.028711, loss_ce: 0.010590
2022-01-08 12:22:00,225 iteration 3482 : loss : 0.021137, loss_ce: 0.007243
2022-01-08 12:22:02,590 iteration 3483 : loss : 0.020597, loss_ce: 0.008589
2022-01-08 12:22:04,926 iteration 3484 : loss : 0.019798, loss_ce: 0.006157
2022-01-08 12:22:04,926 Training Data Eval:
2022-01-08 12:22:17,359   Average segmentation loss on training set: 0.0131
2022-01-08 12:22:17,359 Validation Data Eval:
2022-01-08 12:22:21,696   Average segmentation loss on validation set: 0.0856
2022-01-08 12:22:24,094 iteration 3485 : loss : 0.015549, loss_ce: 0.005695
 51%|█████████████▊             | 205/400 [2:28:38<2:27:59, 45.53s/it]2022-01-08 12:22:26,518 iteration 3486 : loss : 0.019985, loss_ce: 0.005071
2022-01-08 12:22:28,859 iteration 3487 : loss : 0.018638, loss_ce: 0.007990
2022-01-08 12:22:31,155 iteration 3488 : loss : 0.028090, loss_ce: 0.008600
2022-01-08 12:22:33,329 iteration 3489 : loss : 0.023657, loss_ce: 0.012279
2022-01-08 12:22:35,594 iteration 3490 : loss : 0.026021, loss_ce: 0.010118
2022-01-08 12:22:38,043 iteration 3491 : loss : 0.027485, loss_ce: 0.012419
2022-01-08 12:22:40,318 iteration 3492 : loss : 0.017493, loss_ce: 0.005112
2022-01-08 12:22:42,526 iteration 3493 : loss : 0.039117, loss_ce: 0.014287
2022-01-08 12:22:44,765 iteration 3494 : loss : 0.021132, loss_ce: 0.008359
2022-01-08 12:22:47,024 iteration 3495 : loss : 0.016273, loss_ce: 0.005331
2022-01-08 12:22:49,363 iteration 3496 : loss : 0.021317, loss_ce: 0.007869
2022-01-08 12:22:51,589 iteration 3497 : loss : 0.024964, loss_ce: 0.010307
2022-01-08 12:22:53,937 iteration 3498 : loss : 0.025064, loss_ce: 0.009393
2022-01-08 12:22:56,194 iteration 3499 : loss : 0.018468, loss_ce: 0.010168
2022-01-08 12:22:58,505 iteration 3500 : loss : 0.025405, loss_ce: 0.010708
2022-01-08 12:23:00,908 iteration 3501 : loss : 0.023725, loss_ce: 0.009372
2022-01-08 12:23:03,254 iteration 3502 : loss : 0.018875, loss_ce: 0.009751
 52%|█████████████▉             | 206/400 [2:29:18<2:21:02, 43.62s/it]2022-01-08 12:23:05,728 iteration 3503 : loss : 0.032667, loss_ce: 0.009905
2022-01-08 12:23:08,074 iteration 3504 : loss : 0.017867, loss_ce: 0.007495
2022-01-08 12:23:10,463 iteration 3505 : loss : 0.016419, loss_ce: 0.007204
2022-01-08 12:23:12,922 iteration 3506 : loss : 0.018695, loss_ce: 0.006326
2022-01-08 12:23:15,257 iteration 3507 : loss : 0.017471, loss_ce: 0.006682
2022-01-08 12:23:17,668 iteration 3508 : loss : 0.022948, loss_ce: 0.005344
2022-01-08 12:23:20,053 iteration 3509 : loss : 0.024124, loss_ce: 0.008622
2022-01-08 12:23:22,328 iteration 3510 : loss : 0.021216, loss_ce: 0.008792
2022-01-08 12:23:24,870 iteration 3511 : loss : 0.038709, loss_ce: 0.018713
2022-01-08 12:23:27,199 iteration 3512 : loss : 0.019265, loss_ce: 0.008330
2022-01-08 12:23:29,557 iteration 3513 : loss : 0.019047, loss_ce: 0.008503
2022-01-08 12:23:31,960 iteration 3514 : loss : 0.018474, loss_ce: 0.008772
2022-01-08 12:23:34,332 iteration 3515 : loss : 0.022829, loss_ce: 0.010562
2022-01-08 12:23:36,635 iteration 3516 : loss : 0.015932, loss_ce: 0.007358
2022-01-08 12:23:38,901 iteration 3517 : loss : 0.020173, loss_ce: 0.009644
2022-01-08 12:23:41,455 iteration 3518 : loss : 0.036881, loss_ce: 0.012359
2022-01-08 12:23:43,894 iteration 3519 : loss : 0.024080, loss_ce: 0.010081
 52%|█████████████▉             | 207/400 [2:29:58<2:17:25, 42.72s/it]2022-01-08 12:23:46,219 iteration 3520 : loss : 0.022291, loss_ce: 0.010091
2022-01-08 12:23:48,461 iteration 3521 : loss : 0.020679, loss_ce: 0.005015
2022-01-08 12:23:50,640 iteration 3522 : loss : 0.019374, loss_ce: 0.005721
2022-01-08 12:23:52,971 iteration 3523 : loss : 0.030696, loss_ce: 0.017095
2022-01-08 12:23:55,394 iteration 3524 : loss : 0.028202, loss_ce: 0.012905
2022-01-08 12:23:57,684 iteration 3525 : loss : 0.023151, loss_ce: 0.006735
2022-01-08 12:24:00,025 iteration 3526 : loss : 0.021600, loss_ce: 0.011538
2022-01-08 12:24:02,432 iteration 3527 : loss : 0.025735, loss_ce: 0.010431
2022-01-08 12:24:04,771 iteration 3528 : loss : 0.037099, loss_ce: 0.008171
2022-01-08 12:24:07,123 iteration 3529 : loss : 0.031704, loss_ce: 0.012711
2022-01-08 12:24:09,485 iteration 3530 : loss : 0.020800, loss_ce: 0.007852
2022-01-08 12:24:11,866 iteration 3531 : loss : 0.023425, loss_ce: 0.008274
2022-01-08 12:24:14,411 iteration 3532 : loss : 0.018781, loss_ce: 0.007762
2022-01-08 12:24:16,836 iteration 3533 : loss : 0.023668, loss_ce: 0.009351
2022-01-08 12:24:19,119 iteration 3534 : loss : 0.025619, loss_ce: 0.011383
2022-01-08 12:24:21,496 iteration 3535 : loss : 0.035304, loss_ce: 0.015359
2022-01-08 12:24:23,853 iteration 3536 : loss : 0.023133, loss_ce: 0.009083
 52%|██████████████             | 208/400 [2:30:38<2:14:03, 41.89s/it]2022-01-08 12:24:26,279 iteration 3537 : loss : 0.026799, loss_ce: 0.012351
2022-01-08 12:24:28,550 iteration 3538 : loss : 0.019422, loss_ce: 0.007103
2022-01-08 12:24:30,905 iteration 3539 : loss : 0.021812, loss_ce: 0.007031
2022-01-08 12:24:33,323 iteration 3540 : loss : 0.036750, loss_ce: 0.020071
2022-01-08 12:24:35,767 iteration 3541 : loss : 0.023684, loss_ce: 0.009803
2022-01-08 12:24:38,347 iteration 3542 : loss : 0.022889, loss_ce: 0.008760
2022-01-08 12:24:40,814 iteration 3543 : loss : 0.022661, loss_ce: 0.009166
2022-01-08 12:24:43,186 iteration 3544 : loss : 0.047609, loss_ce: 0.010980
2022-01-08 12:24:45,748 iteration 3545 : loss : 0.026937, loss_ce: 0.008678
2022-01-08 12:24:48,184 iteration 3546 : loss : 0.023357, loss_ce: 0.007901
2022-01-08 12:24:50,567 iteration 3547 : loss : 0.025180, loss_ce: 0.010554
2022-01-08 12:24:52,886 iteration 3548 : loss : 0.013309, loss_ce: 0.003896
2022-01-08 12:24:55,333 iteration 3549 : loss : 0.037347, loss_ce: 0.017337
2022-01-08 12:24:57,815 iteration 3550 : loss : 0.025670, loss_ce: 0.009765
2022-01-08 12:25:00,211 iteration 3551 : loss : 0.024336, loss_ce: 0.009543
2022-01-08 12:25:02,505 iteration 3552 : loss : 0.031544, loss_ce: 0.017276
2022-01-08 12:25:04,766 iteration 3553 : loss : 0.018594, loss_ce: 0.006805
 52%|██████████████             | 209/400 [2:31:19<2:12:26, 41.61s/it]2022-01-08 12:25:07,079 iteration 3554 : loss : 0.021961, loss_ce: 0.008549
2022-01-08 12:25:09,362 iteration 3555 : loss : 0.025808, loss_ce: 0.012038
2022-01-08 12:25:11,650 iteration 3556 : loss : 0.026119, loss_ce: 0.012772
2022-01-08 12:25:14,000 iteration 3557 : loss : 0.025849, loss_ce: 0.011191
2022-01-08 12:25:16,303 iteration 3558 : loss : 0.024659, loss_ce: 0.008519
2022-01-08 12:25:18,701 iteration 3559 : loss : 0.029147, loss_ce: 0.008720
2022-01-08 12:25:21,048 iteration 3560 : loss : 0.027603, loss_ce: 0.011484
2022-01-08 12:25:23,270 iteration 3561 : loss : 0.014634, loss_ce: 0.007066
2022-01-08 12:25:25,605 iteration 3562 : loss : 0.041742, loss_ce: 0.016364
2022-01-08 12:25:28,032 iteration 3563 : loss : 0.021512, loss_ce: 0.007688
2022-01-08 12:25:30,475 iteration 3564 : loss : 0.040266, loss_ce: 0.012211
2022-01-08 12:25:32,942 iteration 3565 : loss : 0.036842, loss_ce: 0.010229
2022-01-08 12:25:35,283 iteration 3566 : loss : 0.023465, loss_ce: 0.009123
2022-01-08 12:25:37,914 iteration 3567 : loss : 0.029768, loss_ce: 0.013905
2022-01-08 12:25:40,322 iteration 3568 : loss : 0.031439, loss_ce: 0.015194
2022-01-08 12:25:42,633 iteration 3569 : loss : 0.026465, loss_ce: 0.009513
2022-01-08 12:25:42,633 Training Data Eval:
2022-01-08 12:25:55,486   Average segmentation loss on training set: 0.0161
2022-01-08 12:25:55,486 Validation Data Eval:
2022-01-08 12:26:00,111   Average segmentation loss on validation set: 0.0826
2022-01-08 12:26:02,530 iteration 3570 : loss : 0.041299, loss_ce: 0.012790
 52%|██████████████▏            | 210/400 [2:32:17<2:27:06, 46.45s/it]2022-01-08 12:26:04,939 iteration 3571 : loss : 0.031802, loss_ce: 0.016244
2022-01-08 12:26:07,321 iteration 3572 : loss : 0.024831, loss_ce: 0.008854
2022-01-08 12:26:09,717 iteration 3573 : loss : 0.030049, loss_ce: 0.009898
2022-01-08 12:26:12,141 iteration 3574 : loss : 0.021411, loss_ce: 0.006400
2022-01-08 12:26:14,506 iteration 3575 : loss : 0.021451, loss_ce: 0.007730
2022-01-08 12:26:16,964 iteration 3576 : loss : 0.020917, loss_ce: 0.005609
2022-01-08 12:26:19,343 iteration 3577 : loss : 0.022199, loss_ce: 0.009606
2022-01-08 12:26:21,785 iteration 3578 : loss : 0.026390, loss_ce: 0.010249
2022-01-08 12:26:24,183 iteration 3579 : loss : 0.024654, loss_ce: 0.010314
2022-01-08 12:26:26,515 iteration 3580 : loss : 0.026624, loss_ce: 0.011510
2022-01-08 12:26:28,927 iteration 3581 : loss : 0.032438, loss_ce: 0.017680
2022-01-08 12:26:31,333 iteration 3582 : loss : 0.024371, loss_ce: 0.008987
2022-01-08 12:26:33,712 iteration 3583 : loss : 0.028876, loss_ce: 0.009156
2022-01-08 12:26:35,988 iteration 3584 : loss : 0.023741, loss_ce: 0.007745
2022-01-08 12:26:38,265 iteration 3585 : loss : 0.022130, loss_ce: 0.007706
2022-01-08 12:26:40,656 iteration 3586 : loss : 0.030116, loss_ce: 0.013910
2022-01-08 12:26:43,061 iteration 3587 : loss : 0.016213, loss_ce: 0.006942
 53%|██████████████▏            | 211/400 [2:32:57<2:20:43, 44.67s/it]2022-01-08 12:26:45,513 iteration 3588 : loss : 0.023114, loss_ce: 0.009291
2022-01-08 12:26:47,826 iteration 3589 : loss : 0.018569, loss_ce: 0.005816
2022-01-08 12:26:50,132 iteration 3590 : loss : 0.021094, loss_ce: 0.008248
2022-01-08 12:26:52,514 iteration 3591 : loss : 0.020897, loss_ce: 0.007464
2022-01-08 12:26:55,077 iteration 3592 : loss : 0.030501, loss_ce: 0.011383
2022-01-08 12:26:57,449 iteration 3593 : loss : 0.030378, loss_ce: 0.010733
2022-01-08 12:26:59,899 iteration 3594 : loss : 0.020076, loss_ce: 0.008081
2022-01-08 12:27:02,313 iteration 3595 : loss : 0.032853, loss_ce: 0.012469
2022-01-08 12:27:04,726 iteration 3596 : loss : 0.015512, loss_ce: 0.005503
2022-01-08 12:27:07,162 iteration 3597 : loss : 0.030129, loss_ce: 0.012296
2022-01-08 12:27:09,558 iteration 3598 : loss : 0.013647, loss_ce: 0.005498
2022-01-08 12:27:11,945 iteration 3599 : loss : 0.020797, loss_ce: 0.006308
2022-01-08 12:27:14,233 iteration 3600 : loss : 0.016924, loss_ce: 0.006891
2022-01-08 12:27:16,647 iteration 3601 : loss : 0.022222, loss_ce: 0.009979
2022-01-08 12:27:19,102 iteration 3602 : loss : 0.019034, loss_ce: 0.006413
2022-01-08 12:27:21,532 iteration 3603 : loss : 0.021435, loss_ce: 0.010872
2022-01-08 12:27:23,853 iteration 3604 : loss : 0.017721, loss_ce: 0.006946
 53%|██████████████▎            | 212/400 [2:33:38<2:16:19, 43.51s/it]2022-01-08 12:27:26,280 iteration 3605 : loss : 0.027833, loss_ce: 0.010106
2022-01-08 12:27:28,693 iteration 3606 : loss : 0.022388, loss_ce: 0.011108
2022-01-08 12:27:31,104 iteration 3607 : loss : 0.023353, loss_ce: 0.008509
2022-01-08 12:27:33,490 iteration 3608 : loss : 0.016806, loss_ce: 0.006216
2022-01-08 12:27:35,869 iteration 3609 : loss : 0.016712, loss_ce: 0.007512
2022-01-08 12:27:38,263 iteration 3610 : loss : 0.016581, loss_ce: 0.006307
2022-01-08 12:27:40,609 iteration 3611 : loss : 0.021065, loss_ce: 0.005742
2022-01-08 12:27:42,930 iteration 3612 : loss : 0.016636, loss_ce: 0.005886
2022-01-08 12:27:45,407 iteration 3613 : loss : 0.032014, loss_ce: 0.011787
2022-01-08 12:27:47,808 iteration 3614 : loss : 0.016991, loss_ce: 0.006435
2022-01-08 12:27:50,168 iteration 3615 : loss : 0.016598, loss_ce: 0.005978
2022-01-08 12:27:52,682 iteration 3616 : loss : 0.030665, loss_ce: 0.011058
2022-01-08 12:27:55,099 iteration 3617 : loss : 0.019939, loss_ce: 0.008344
2022-01-08 12:27:57,436 iteration 3618 : loss : 0.026001, loss_ce: 0.011097
2022-01-08 12:27:59,786 iteration 3619 : loss : 0.023689, loss_ce: 0.007143
2022-01-08 12:28:02,133 iteration 3620 : loss : 0.019272, loss_ce: 0.006072
2022-01-08 12:28:04,550 iteration 3621 : loss : 0.021278, loss_ce: 0.008162
 53%|██████████████▍            | 213/400 [2:34:19<2:12:58, 42.67s/it]2022-01-08 12:28:06,958 iteration 3622 : loss : 0.019502, loss_ce: 0.008967
2022-01-08 12:28:09,327 iteration 3623 : loss : 0.016830, loss_ce: 0.003895
2022-01-08 12:28:11,676 iteration 3624 : loss : 0.015665, loss_ce: 0.006608
2022-01-08 12:28:13,932 iteration 3625 : loss : 0.017685, loss_ce: 0.006455
2022-01-08 12:28:16,250 iteration 3626 : loss : 0.018985, loss_ce: 0.009088
2022-01-08 12:28:18,518 iteration 3627 : loss : 0.017459, loss_ce: 0.006291
2022-01-08 12:28:20,871 iteration 3628 : loss : 0.030923, loss_ce: 0.008825
2022-01-08 12:28:23,364 iteration 3629 : loss : 0.019843, loss_ce: 0.008560
2022-01-08 12:28:25,833 iteration 3630 : loss : 0.019585, loss_ce: 0.006984
2022-01-08 12:28:28,217 iteration 3631 : loss : 0.027058, loss_ce: 0.007803
2022-01-08 12:28:30,735 iteration 3632 : loss : 0.023272, loss_ce: 0.007317
2022-01-08 12:28:33,114 iteration 3633 : loss : 0.016266, loss_ce: 0.006439
2022-01-08 12:28:35,470 iteration 3634 : loss : 0.017750, loss_ce: 0.007243
2022-01-08 12:28:37,915 iteration 3635 : loss : 0.033680, loss_ce: 0.015064
2022-01-08 12:28:40,233 iteration 3636 : loss : 0.026933, loss_ce: 0.007618
2022-01-08 12:28:42,471 iteration 3637 : loss : 0.028764, loss_ce: 0.009746
2022-01-08 12:28:44,711 iteration 3638 : loss : 0.016488, loss_ce: 0.006978
 54%|██████████████▍            | 214/400 [2:34:59<2:09:56, 41.92s/it]2022-01-08 12:28:46,968 iteration 3639 : loss : 0.018312, loss_ce: 0.007458
2022-01-08 12:28:49,261 iteration 3640 : loss : 0.020005, loss_ce: 0.007723
2022-01-08 12:28:51,571 iteration 3641 : loss : 0.017756, loss_ce: 0.005532
2022-01-08 12:28:54,084 iteration 3642 : loss : 0.027988, loss_ce: 0.008376
2022-01-08 12:28:56,437 iteration 3643 : loss : 0.016765, loss_ce: 0.006996
2022-01-08 12:28:58,762 iteration 3644 : loss : 0.014148, loss_ce: 0.005657
2022-01-08 12:29:01,092 iteration 3645 : loss : 0.020095, loss_ce: 0.006467
2022-01-08 12:29:03,505 iteration 3646 : loss : 0.019801, loss_ce: 0.007523
2022-01-08 12:29:05,847 iteration 3647 : loss : 0.023979, loss_ce: 0.006088
2022-01-08 12:29:08,172 iteration 3648 : loss : 0.031455, loss_ce: 0.013408
2022-01-08 12:29:10,446 iteration 3649 : loss : 0.016150, loss_ce: 0.004541
2022-01-08 12:29:12,764 iteration 3650 : loss : 0.021142, loss_ce: 0.009654
2022-01-08 12:29:15,069 iteration 3651 : loss : 0.019910, loss_ce: 0.007429
2022-01-08 12:29:17,463 iteration 3652 : loss : 0.054168, loss_ce: 0.021225
2022-01-08 12:29:19,795 iteration 3653 : loss : 0.020230, loss_ce: 0.011091
2022-01-08 12:29:22,062 iteration 3654 : loss : 0.016425, loss_ce: 0.008054
2022-01-08 12:29:22,062 Training Data Eval:
2022-01-08 12:29:34,414   Average segmentation loss on training set: 0.0134
2022-01-08 12:29:34,415 Validation Data Eval:
2022-01-08 12:29:38,774   Average segmentation loss on validation set: 0.0955
2022-01-08 12:29:41,260 iteration 3655 : loss : 0.017480, loss_ce: 0.006694
 54%|██████████████▌            | 215/400 [2:35:56<2:22:46, 46.31s/it]2022-01-08 12:29:43,739 iteration 3656 : loss : 0.017198, loss_ce: 0.006578
2022-01-08 12:29:46,030 iteration 3657 : loss : 0.017498, loss_ce: 0.008609
2022-01-08 12:29:48,352 iteration 3658 : loss : 0.022477, loss_ce: 0.010162
2022-01-08 12:29:50,728 iteration 3659 : loss : 0.024839, loss_ce: 0.009381
2022-01-08 12:29:53,119 iteration 3660 : loss : 0.021082, loss_ce: 0.004990
2022-01-08 12:29:55,468 iteration 3661 : loss : 0.015056, loss_ce: 0.006281
2022-01-08 12:29:57,811 iteration 3662 : loss : 0.021560, loss_ce: 0.007404
2022-01-08 12:30:00,077 iteration 3663 : loss : 0.021183, loss_ce: 0.006895
2022-01-08 12:30:02,397 iteration 3664 : loss : 0.016439, loss_ce: 0.005738
2022-01-08 12:30:04,772 iteration 3665 : loss : 0.025231, loss_ce: 0.013152
2022-01-08 12:30:07,121 iteration 3666 : loss : 0.021576, loss_ce: 0.006948
2022-01-08 12:30:09,442 iteration 3667 : loss : 0.021251, loss_ce: 0.009053
2022-01-08 12:30:11,700 iteration 3668 : loss : 0.015322, loss_ce: 0.002866
2022-01-08 12:30:14,103 iteration 3669 : loss : 0.019209, loss_ce: 0.008338
2022-01-08 12:30:16,380 iteration 3670 : loss : 0.014790, loss_ce: 0.005272
2022-01-08 12:30:18,796 iteration 3671 : loss : 0.016114, loss_ce: 0.007425
2022-01-08 12:30:21,320 iteration 3672 : loss : 0.044668, loss_ce: 0.013135
 54%|██████████████▌            | 216/400 [2:36:36<2:16:15, 44.43s/it]2022-01-08 12:30:23,694 iteration 3673 : loss : 0.020180, loss_ce: 0.008373
2022-01-08 12:30:26,058 iteration 3674 : loss : 0.021523, loss_ce: 0.005899
2022-01-08 12:30:28,505 iteration 3675 : loss : 0.019512, loss_ce: 0.007288
2022-01-08 12:30:30,849 iteration 3676 : loss : 0.015575, loss_ce: 0.006116
2022-01-08 12:30:33,209 iteration 3677 : loss : 0.023056, loss_ce: 0.006659
2022-01-08 12:30:35,569 iteration 3678 : loss : 0.021503, loss_ce: 0.006597
2022-01-08 12:30:37,963 iteration 3679 : loss : 0.020823, loss_ce: 0.008184
2022-01-08 12:30:40,384 iteration 3680 : loss : 0.028486, loss_ce: 0.011107
2022-01-08 12:30:42,714 iteration 3681 : loss : 0.019868, loss_ce: 0.008708
2022-01-08 12:30:44,916 iteration 3682 : loss : 0.016738, loss_ce: 0.006307
2022-01-08 12:30:47,081 iteration 3683 : loss : 0.018518, loss_ce: 0.007325
2022-01-08 12:30:49,415 iteration 3684 : loss : 0.014879, loss_ce: 0.005575
2022-01-08 12:30:51,670 iteration 3685 : loss : 0.024147, loss_ce: 0.007255
2022-01-08 12:30:53,930 iteration 3686 : loss : 0.020224, loss_ce: 0.007859
2022-01-08 12:30:56,117 iteration 3687 : loss : 0.015002, loss_ce: 0.005081
2022-01-08 12:30:58,412 iteration 3688 : loss : 0.023664, loss_ce: 0.012492
2022-01-08 12:31:00,810 iteration 3689 : loss : 0.021413, loss_ce: 0.006128
 54%|██████████████▋            | 217/400 [2:37:15<2:10:59, 42.95s/it]2022-01-08 12:31:03,243 iteration 3690 : loss : 0.020541, loss_ce: 0.005587
2022-01-08 12:31:05,583 iteration 3691 : loss : 0.027659, loss_ce: 0.007496
2022-01-08 12:31:07,931 iteration 3692 : loss : 0.020851, loss_ce: 0.010079
2022-01-08 12:31:10,166 iteration 3693 : loss : 0.020233, loss_ce: 0.010315
2022-01-08 12:31:12,506 iteration 3694 : loss : 0.020798, loss_ce: 0.009559
2022-01-08 12:31:14,937 iteration 3695 : loss : 0.017875, loss_ce: 0.009081
2022-01-08 12:31:17,292 iteration 3696 : loss : 0.029904, loss_ce: 0.010040
2022-01-08 12:31:19,662 iteration 3697 : loss : 0.022814, loss_ce: 0.007044
2022-01-08 12:31:21,995 iteration 3698 : loss : 0.020322, loss_ce: 0.008920
2022-01-08 12:31:24,247 iteration 3699 : loss : 0.016193, loss_ce: 0.006558
2022-01-08 12:31:26,596 iteration 3700 : loss : 0.018847, loss_ce: 0.005944
2022-01-08 12:31:28,879 iteration 3701 : loss : 0.016209, loss_ce: 0.007484
2022-01-08 12:31:31,225 iteration 3702 : loss : 0.015557, loss_ce: 0.005240
2022-01-08 12:31:33,635 iteration 3703 : loss : 0.016648, loss_ce: 0.007478
2022-01-08 12:31:35,952 iteration 3704 : loss : 0.015000, loss_ce: 0.005745
2022-01-08 12:31:38,400 iteration 3705 : loss : 0.028294, loss_ce: 0.010719
2022-01-08 12:31:40,765 iteration 3706 : loss : 0.014891, loss_ce: 0.004222
 55%|██████████████▋            | 218/400 [2:37:55<2:07:33, 42.05s/it]2022-01-08 12:31:43,224 iteration 3707 : loss : 0.016752, loss_ce: 0.007529
2022-01-08 12:31:45,600 iteration 3708 : loss : 0.022507, loss_ce: 0.007373
2022-01-08 12:31:48,079 iteration 3709 : loss : 0.026610, loss_ce: 0.007918
2022-01-08 12:31:50,415 iteration 3710 : loss : 0.022705, loss_ce: 0.008891
2022-01-08 12:31:52,666 iteration 3711 : loss : 0.014985, loss_ce: 0.005160
2022-01-08 12:31:54,852 iteration 3712 : loss : 0.015059, loss_ce: 0.006856
2022-01-08 12:31:57,156 iteration 3713 : loss : 0.018821, loss_ce: 0.006622
2022-01-08 12:31:59,712 iteration 3714 : loss : 0.023818, loss_ce: 0.008762
2022-01-08 12:32:02,077 iteration 3715 : loss : 0.017608, loss_ce: 0.007654
2022-01-08 12:32:04,366 iteration 3716 : loss : 0.020833, loss_ce: 0.010930
2022-01-08 12:32:06,662 iteration 3717 : loss : 0.019258, loss_ce: 0.007077
2022-01-08 12:32:08,879 iteration 3718 : loss : 0.016234, loss_ce: 0.005921
2022-01-08 12:32:11,224 iteration 3719 : loss : 0.020254, loss_ce: 0.007697
2022-01-08 12:32:13,571 iteration 3720 : loss : 0.019370, loss_ce: 0.005431
2022-01-08 12:32:15,835 iteration 3721 : loss : 0.015514, loss_ce: 0.005762
2022-01-08 12:32:18,066 iteration 3722 : loss : 0.019152, loss_ce: 0.008630
2022-01-08 12:32:20,423 iteration 3723 : loss : 0.031838, loss_ce: 0.008032
 55%|██████████████▊            | 219/400 [2:38:35<2:04:41, 41.33s/it]2022-01-08 12:32:22,827 iteration 3724 : loss : 0.021836, loss_ce: 0.007739
2022-01-08 12:32:25,074 iteration 3725 : loss : 0.035639, loss_ce: 0.016024
2022-01-08 12:32:27,386 iteration 3726 : loss : 0.016170, loss_ce: 0.006017
2022-01-08 12:32:29,586 iteration 3727 : loss : 0.014571, loss_ce: 0.004511
2022-01-08 12:32:31,926 iteration 3728 : loss : 0.026785, loss_ce: 0.013382
2022-01-08 12:32:34,313 iteration 3729 : loss : 0.033307, loss_ce: 0.010807
2022-01-08 12:32:36,583 iteration 3730 : loss : 0.026586, loss_ce: 0.008165
2022-01-08 12:32:38,859 iteration 3731 : loss : 0.017644, loss_ce: 0.006245
2022-01-08 12:32:41,239 iteration 3732 : loss : 0.021425, loss_ce: 0.009607
2022-01-08 12:32:43,566 iteration 3733 : loss : 0.025751, loss_ce: 0.007331
2022-01-08 12:32:45,947 iteration 3734 : loss : 0.027296, loss_ce: 0.009872
2022-01-08 12:32:48,386 iteration 3735 : loss : 0.026610, loss_ce: 0.012656
2022-01-08 12:32:50,812 iteration 3736 : loss : 0.022836, loss_ce: 0.008213
2022-01-08 12:32:53,132 iteration 3737 : loss : 0.037702, loss_ce: 0.017956
2022-01-08 12:32:55,532 iteration 3738 : loss : 0.020757, loss_ce: 0.008097
2022-01-08 12:32:57,864 iteration 3739 : loss : 0.018587, loss_ce: 0.006486
2022-01-08 12:32:57,865 Training Data Eval:
2022-01-08 12:33:10,633   Average segmentation loss on training set: 0.0143
2022-01-08 12:33:10,633 Validation Data Eval:
2022-01-08 12:33:15,114   Average segmentation loss on validation set: 0.0730
2022-01-08 12:33:17,544 iteration 3740 : loss : 0.021989, loss_ce: 0.006911
 55%|██████████████▊            | 220/400 [2:39:32<2:18:12, 46.07s/it]2022-01-08 12:33:19,901 iteration 3741 : loss : 0.023728, loss_ce: 0.011575
2022-01-08 12:33:22,167 iteration 3742 : loss : 0.022365, loss_ce: 0.010201
2022-01-08 12:33:24,475 iteration 3743 : loss : 0.018960, loss_ce: 0.006461
2022-01-08 12:33:26,871 iteration 3744 : loss : 0.021923, loss_ce: 0.008940
2022-01-08 12:33:29,198 iteration 3745 : loss : 0.016075, loss_ce: 0.006027
2022-01-08 12:33:31,536 iteration 3746 : loss : 0.015949, loss_ce: 0.006094
2022-01-08 12:33:33,791 iteration 3747 : loss : 0.039083, loss_ce: 0.007717
2022-01-08 12:33:36,014 iteration 3748 : loss : 0.034171, loss_ce: 0.019999
2022-01-08 12:33:38,286 iteration 3749 : loss : 0.019929, loss_ce: 0.009184
2022-01-08 12:33:40,639 iteration 3750 : loss : 0.024703, loss_ce: 0.009761
2022-01-08 12:33:42,957 iteration 3751 : loss : 0.022249, loss_ce: 0.006054
2022-01-08 12:33:45,239 iteration 3752 : loss : 0.016824, loss_ce: 0.006968
2022-01-08 12:33:47,501 iteration 3753 : loss : 0.023375, loss_ce: 0.006898
2022-01-08 12:33:49,842 iteration 3754 : loss : 0.016083, loss_ce: 0.005763
2022-01-08 12:33:52,173 iteration 3755 : loss : 0.017721, loss_ce: 0.007846
2022-01-08 12:33:54,502 iteration 3756 : loss : 0.029906, loss_ce: 0.009573
2022-01-08 12:33:56,777 iteration 3757 : loss : 0.022831, loss_ce: 0.007182
 55%|██████████████▉            | 221/400 [2:40:11<2:11:19, 44.02s/it]2022-01-08 12:33:59,178 iteration 3758 : loss : 0.031728, loss_ce: 0.013330
2022-01-08 12:34:01,554 iteration 3759 : loss : 0.018327, loss_ce: 0.006864
2022-01-08 12:34:03,793 iteration 3760 : loss : 0.018691, loss_ce: 0.006558
2022-01-08 12:34:06,145 iteration 3761 : loss : 0.023257, loss_ce: 0.009748
2022-01-08 12:34:08,454 iteration 3762 : loss : 0.024182, loss_ce: 0.009196
2022-01-08 12:34:10,887 iteration 3763 : loss : 0.034288, loss_ce: 0.013404
2022-01-08 12:34:13,227 iteration 3764 : loss : 0.025274, loss_ce: 0.008905
2022-01-08 12:34:15,561 iteration 3765 : loss : 0.016559, loss_ce: 0.006465
2022-01-08 12:34:17,864 iteration 3766 : loss : 0.020034, loss_ce: 0.007605
2022-01-08 12:34:20,286 iteration 3767 : loss : 0.024858, loss_ce: 0.008385
2022-01-08 12:34:22,634 iteration 3768 : loss : 0.017911, loss_ce: 0.007705
2022-01-08 12:34:24,886 iteration 3769 : loss : 0.019356, loss_ce: 0.008368
2022-01-08 12:34:27,127 iteration 3770 : loss : 0.021225, loss_ce: 0.006878
2022-01-08 12:34:29,621 iteration 3771 : loss : 0.016480, loss_ce: 0.005851
2022-01-08 12:34:31,980 iteration 3772 : loss : 0.023171, loss_ce: 0.007066
2022-01-08 12:34:34,240 iteration 3773 : loss : 0.014863, loss_ce: 0.005185
2022-01-08 12:34:36,493 iteration 3774 : loss : 0.017805, loss_ce: 0.007230
 56%|██████████████▉            | 222/400 [2:40:51<2:06:45, 42.73s/it]2022-01-08 12:34:38,800 iteration 3775 : loss : 0.018606, loss_ce: 0.005526
2022-01-08 12:34:41,116 iteration 3776 : loss : 0.029931, loss_ce: 0.012773
2022-01-08 12:34:43,527 iteration 3777 : loss : 0.022544, loss_ce: 0.006864
2022-01-08 12:34:45,823 iteration 3778 : loss : 0.013752, loss_ce: 0.006558
2022-01-08 12:34:48,172 iteration 3779 : loss : 0.019951, loss_ce: 0.007570
2022-01-08 12:34:50,441 iteration 3780 : loss : 0.019155, loss_ce: 0.009087
2022-01-08 12:34:52,775 iteration 3781 : loss : 0.019667, loss_ce: 0.007436
2022-01-08 12:34:55,097 iteration 3782 : loss : 0.018251, loss_ce: 0.006271
2022-01-08 12:34:57,394 iteration 3783 : loss : 0.014424, loss_ce: 0.003936
2022-01-08 12:34:59,739 iteration 3784 : loss : 0.022591, loss_ce: 0.010185
2022-01-08 12:35:01,991 iteration 3785 : loss : 0.017274, loss_ce: 0.006436
2022-01-08 12:35:04,295 iteration 3786 : loss : 0.026026, loss_ce: 0.010624
2022-01-08 12:35:06,658 iteration 3787 : loss : 0.053028, loss_ce: 0.022475
2022-01-08 12:35:08,953 iteration 3788 : loss : 0.027603, loss_ce: 0.011180
2022-01-08 12:35:11,171 iteration 3789 : loss : 0.019368, loss_ce: 0.005035
2022-01-08 12:35:13,454 iteration 3790 : loss : 0.017746, loss_ce: 0.006437
2022-01-08 12:35:15,735 iteration 3791 : loss : 0.024058, loss_ce: 0.009381
 56%|███████████████            | 223/400 [2:41:30<2:02:57, 41.68s/it]2022-01-08 12:35:18,124 iteration 3792 : loss : 0.017904, loss_ce: 0.007669
2022-01-08 12:35:20,434 iteration 3793 : loss : 0.015878, loss_ce: 0.006136
2022-01-08 12:35:22,798 iteration 3794 : loss : 0.018142, loss_ce: 0.007006
2022-01-08 12:35:25,201 iteration 3795 : loss : 0.025964, loss_ce: 0.010254
2022-01-08 12:35:27,472 iteration 3796 : loss : 0.024191, loss_ce: 0.006610
2022-01-08 12:35:29,791 iteration 3797 : loss : 0.019774, loss_ce: 0.006306
2022-01-08 12:35:32,230 iteration 3798 : loss : 0.026899, loss_ce: 0.011971
2022-01-08 12:35:34,498 iteration 3799 : loss : 0.017448, loss_ce: 0.008943
2022-01-08 12:35:36,985 iteration 3800 : loss : 0.021528, loss_ce: 0.006995
2022-01-08 12:35:39,345 iteration 3801 : loss : 0.016056, loss_ce: 0.005369
2022-01-08 12:35:41,691 iteration 3802 : loss : 0.016459, loss_ce: 0.004197
2022-01-08 12:35:43,985 iteration 3803 : loss : 0.016674, loss_ce: 0.005739
2022-01-08 12:35:46,223 iteration 3804 : loss : 0.018986, loss_ce: 0.007893
2022-01-08 12:35:48,542 iteration 3805 : loss : 0.015173, loss_ce: 0.006192
2022-01-08 12:35:50,883 iteration 3806 : loss : 0.021867, loss_ce: 0.006130
2022-01-08 12:35:53,206 iteration 3807 : loss : 0.019904, loss_ce: 0.008459
2022-01-08 12:35:55,601 iteration 3808 : loss : 0.019521, loss_ce: 0.007166
 56%|███████████████            | 224/400 [2:42:10<2:00:40, 41.14s/it]2022-01-08 12:35:58,011 iteration 3809 : loss : 0.019549, loss_ce: 0.008062
2022-01-08 12:36:00,346 iteration 3810 : loss : 0.020009, loss_ce: 0.008448
2022-01-08 12:36:02,722 iteration 3811 : loss : 0.020542, loss_ce: 0.006711
2022-01-08 12:36:04,987 iteration 3812 : loss : 0.018103, loss_ce: 0.006373
2022-01-08 12:36:07,337 iteration 3813 : loss : 0.033646, loss_ce: 0.011050
2022-01-08 12:36:09,545 iteration 3814 : loss : 0.013782, loss_ce: 0.004649
2022-01-08 12:36:11,907 iteration 3815 : loss : 0.034584, loss_ce: 0.013106
2022-01-08 12:36:14,311 iteration 3816 : loss : 0.022837, loss_ce: 0.008438
2022-01-08 12:36:16,611 iteration 3817 : loss : 0.017928, loss_ce: 0.008050
2022-01-08 12:36:19,017 iteration 3818 : loss : 0.020945, loss_ce: 0.009009
2022-01-08 12:36:21,315 iteration 3819 : loss : 0.018329, loss_ce: 0.008284
2022-01-08 12:36:23,726 iteration 3820 : loss : 0.023319, loss_ce: 0.009866
2022-01-08 12:36:26,054 iteration 3821 : loss : 0.035055, loss_ce: 0.018295
2022-01-08 12:36:28,294 iteration 3822 : loss : 0.018756, loss_ce: 0.008267
2022-01-08 12:36:30,538 iteration 3823 : loss : 0.021627, loss_ce: 0.007714
2022-01-08 12:36:32,850 iteration 3824 : loss : 0.021702, loss_ce: 0.008053
2022-01-08 12:36:32,850 Training Data Eval:
2022-01-08 12:36:45,506   Average segmentation loss on training set: 0.0159
2022-01-08 12:36:45,507 Validation Data Eval:
2022-01-08 12:36:49,859   Average segmentation loss on validation set: 0.0636
2022-01-08 12:36:52,199 iteration 3825 : loss : 0.020843, loss_ce: 0.007610
 56%|███████████████▏           | 225/400 [2:43:06<2:13:30, 45.77s/it]2022-01-08 12:36:54,511 iteration 3826 : loss : 0.016598, loss_ce: 0.006740
2022-01-08 12:36:56,960 iteration 3827 : loss : 0.027295, loss_ce: 0.009417
2022-01-08 12:36:59,392 iteration 3828 : loss : 0.018215, loss_ce: 0.007320
2022-01-08 12:37:01,721 iteration 3829 : loss : 0.021634, loss_ce: 0.009725
2022-01-08 12:37:04,158 iteration 3830 : loss : 0.045031, loss_ce: 0.024689
2022-01-08 12:37:06,588 iteration 3831 : loss : 0.061404, loss_ce: 0.022966
2022-01-08 12:37:08,804 iteration 3832 : loss : 0.015074, loss_ce: 0.005072
2022-01-08 12:37:11,170 iteration 3833 : loss : 0.018429, loss_ce: 0.006506
2022-01-08 12:37:13,560 iteration 3834 : loss : 0.015966, loss_ce: 0.007550
2022-01-08 12:37:16,108 iteration 3835 : loss : 0.023264, loss_ce: 0.011453
2022-01-08 12:37:18,553 iteration 3836 : loss : 0.017717, loss_ce: 0.006387
2022-01-08 12:37:20,851 iteration 3837 : loss : 0.020108, loss_ce: 0.008147
2022-01-08 12:37:23,359 iteration 3838 : loss : 0.019060, loss_ce: 0.006225
2022-01-08 12:37:25,919 iteration 3839 : loss : 0.027914, loss_ce: 0.011631
2022-01-08 12:37:28,233 iteration 3840 : loss : 0.021555, loss_ce: 0.005979
2022-01-08 12:37:30,567 iteration 3841 : loss : 0.018704, loss_ce: 0.006327
2022-01-08 12:37:32,861 iteration 3842 : loss : 0.022064, loss_ce: 0.005439
 56%|███████████████▎           | 226/400 [2:43:47<2:08:17, 44.24s/it]2022-01-08 12:37:35,158 iteration 3843 : loss : 0.021593, loss_ce: 0.008045
2022-01-08 12:37:37,380 iteration 3844 : loss : 0.021386, loss_ce: 0.009456
2022-01-08 12:37:39,726 iteration 3845 : loss : 0.031792, loss_ce: 0.010358
2022-01-08 12:37:42,052 iteration 3846 : loss : 0.017211, loss_ce: 0.004987
2022-01-08 12:37:44,476 iteration 3847 : loss : 0.016797, loss_ce: 0.006226
2022-01-08 12:37:46,758 iteration 3848 : loss : 0.018216, loss_ce: 0.007238
2022-01-08 12:37:49,034 iteration 3849 : loss : 0.017643, loss_ce: 0.006621
2022-01-08 12:37:51,440 iteration 3850 : loss : 0.029499, loss_ce: 0.007793
2022-01-08 12:37:53,777 iteration 3851 : loss : 0.038582, loss_ce: 0.021718
2022-01-08 12:37:56,038 iteration 3852 : loss : 0.021671, loss_ce: 0.007259
2022-01-08 12:37:58,380 iteration 3853 : loss : 0.016966, loss_ce: 0.008734
2022-01-08 12:38:00,809 iteration 3854 : loss : 0.039024, loss_ce: 0.018300
2022-01-08 12:38:03,234 iteration 3855 : loss : 0.016710, loss_ce: 0.006307
2022-01-08 12:38:05,632 iteration 3856 : loss : 0.030693, loss_ce: 0.013100
2022-01-08 12:38:08,012 iteration 3857 : loss : 0.018074, loss_ce: 0.007481
2022-01-08 12:38:10,399 iteration 3858 : loss : 0.019224, loss_ce: 0.006809
2022-01-08 12:38:12,937 iteration 3859 : loss : 0.025583, loss_ce: 0.006975
 57%|███████████████▎           | 227/400 [2:44:27<2:03:57, 42.99s/it]2022-01-08 12:38:15,382 iteration 3860 : loss : 0.017166, loss_ce: 0.007532
2022-01-08 12:38:17,734 iteration 3861 : loss : 0.026567, loss_ce: 0.013838
2022-01-08 12:38:19,964 iteration 3862 : loss : 0.017161, loss_ce: 0.008009
2022-01-08 12:38:22,368 iteration 3863 : loss : 0.021470, loss_ce: 0.010773
2022-01-08 12:38:24,941 iteration 3864 : loss : 0.018728, loss_ce: 0.006862
2022-01-08 12:38:27,443 iteration 3865 : loss : 0.028242, loss_ce: 0.012622
2022-01-08 12:38:29,863 iteration 3866 : loss : 0.028091, loss_ce: 0.012238
2022-01-08 12:38:32,127 iteration 3867 : loss : 0.014679, loss_ce: 0.005556
2022-01-08 12:38:34,544 iteration 3868 : loss : 0.016828, loss_ce: 0.007064
2022-01-08 12:38:36,926 iteration 3869 : loss : 0.020457, loss_ce: 0.007418
2022-01-08 12:38:39,341 iteration 3870 : loss : 0.020277, loss_ce: 0.006596
2022-01-08 12:38:41,815 iteration 3871 : loss : 0.024276, loss_ce: 0.006544
2022-01-08 12:38:44,170 iteration 3872 : loss : 0.019721, loss_ce: 0.008687
2022-01-08 12:38:46,503 iteration 3873 : loss : 0.021996, loss_ce: 0.008311
2022-01-08 12:38:48,902 iteration 3874 : loss : 0.015726, loss_ce: 0.005752
2022-01-08 12:38:51,232 iteration 3875 : loss : 0.021168, loss_ce: 0.007370
2022-01-08 12:38:53,496 iteration 3876 : loss : 0.024358, loss_ce: 0.005024
 57%|███████████████▍           | 228/400 [2:45:08<2:01:08, 42.26s/it]2022-01-08 12:38:56,030 iteration 3877 : loss : 0.014850, loss_ce: 0.005438
2022-01-08 12:38:58,450 iteration 3878 : loss : 0.026678, loss_ce: 0.012475
2022-01-08 12:39:00,828 iteration 3879 : loss : 0.021281, loss_ce: 0.009436
2022-01-08 12:39:03,207 iteration 3880 : loss : 0.018473, loss_ce: 0.008481
2022-01-08 12:39:05,515 iteration 3881 : loss : 0.018359, loss_ce: 0.009165
2022-01-08 12:39:07,934 iteration 3882 : loss : 0.026371, loss_ce: 0.008523
2022-01-08 12:39:10,370 iteration 3883 : loss : 0.022620, loss_ce: 0.009968
2022-01-08 12:39:12,747 iteration 3884 : loss : 0.026777, loss_ce: 0.004270
2022-01-08 12:39:15,087 iteration 3885 : loss : 0.016365, loss_ce: 0.005332
2022-01-08 12:39:17,488 iteration 3886 : loss : 0.022792, loss_ce: 0.008424
2022-01-08 12:39:19,928 iteration 3887 : loss : 0.022175, loss_ce: 0.008397
2022-01-08 12:39:22,278 iteration 3888 : loss : 0.021632, loss_ce: 0.007579
2022-01-08 12:39:24,680 iteration 3889 : loss : 0.021925, loss_ce: 0.009435
2022-01-08 12:39:27,007 iteration 3890 : loss : 0.019987, loss_ce: 0.006793
2022-01-08 12:39:29,481 iteration 3891 : loss : 0.012006, loss_ce: 0.004555
2022-01-08 12:39:31,878 iteration 3892 : loss : 0.029700, loss_ce: 0.008261
2022-01-08 12:39:34,290 iteration 3893 : loss : 0.027644, loss_ce: 0.015450
 57%|███████████████▍           | 229/400 [2:45:49<1:59:11, 41.82s/it]2022-01-08 12:39:36,631 iteration 3894 : loss : 0.016401, loss_ce: 0.007332
2022-01-08 12:39:38,945 iteration 3895 : loss : 0.023927, loss_ce: 0.010958
2022-01-08 12:39:41,311 iteration 3896 : loss : 0.022845, loss_ce: 0.006058
2022-01-08 12:39:43,790 iteration 3897 : loss : 0.025120, loss_ce: 0.010661
2022-01-08 12:39:46,185 iteration 3898 : loss : 0.018413, loss_ce: 0.006133
2022-01-08 12:39:48,614 iteration 3899 : loss : 0.022889, loss_ce: 0.009865
2022-01-08 12:39:51,117 iteration 3900 : loss : 0.027998, loss_ce: 0.010135
2022-01-08 12:39:53,436 iteration 3901 : loss : 0.016289, loss_ce: 0.005207
2022-01-08 12:39:55,766 iteration 3902 : loss : 0.012817, loss_ce: 0.004778
2022-01-08 12:39:58,119 iteration 3903 : loss : 0.016023, loss_ce: 0.005798
2022-01-08 12:40:00,564 iteration 3904 : loss : 0.026898, loss_ce: 0.009163
2022-01-08 12:40:02,948 iteration 3905 : loss : 0.021762, loss_ce: 0.009589
2022-01-08 12:40:05,348 iteration 3906 : loss : 0.018161, loss_ce: 0.008156
2022-01-08 12:40:07,933 iteration 3907 : loss : 0.023979, loss_ce: 0.006888
2022-01-08 12:40:10,396 iteration 3908 : loss : 0.029225, loss_ce: 0.010292
2022-01-08 12:40:12,738 iteration 3909 : loss : 0.016634, loss_ce: 0.006840
2022-01-08 12:40:12,738 Training Data Eval:
2022-01-08 12:40:25,401   Average segmentation loss on training set: 0.0122
2022-01-08 12:40:25,402 Validation Data Eval:
2022-01-08 12:40:29,923   Average segmentation loss on validation set: 0.0696
2022-01-08 12:40:32,266 iteration 3910 : loss : 0.015459, loss_ce: 0.004771
 57%|███████████████▌           | 230/400 [2:46:47<2:12:13, 46.67s/it]2022-01-08 12:40:34,654 iteration 3911 : loss : 0.015142, loss_ce: 0.004891
2022-01-08 12:40:37,244 iteration 3912 : loss : 0.025588, loss_ce: 0.012173
2022-01-08 12:40:39,576 iteration 3913 : loss : 0.018465, loss_ce: 0.005529
2022-01-08 12:40:42,010 iteration 3914 : loss : 0.017795, loss_ce: 0.006130
2022-01-08 12:40:44,332 iteration 3915 : loss : 0.033188, loss_ce: 0.011726
2022-01-08 12:40:46,732 iteration 3916 : loss : 0.026137, loss_ce: 0.009863
2022-01-08 12:40:49,153 iteration 3917 : loss : 0.057186, loss_ce: 0.012970
2022-01-08 12:40:51,558 iteration 3918 : loss : 0.026674, loss_ce: 0.011894
2022-01-08 12:40:53,882 iteration 3919 : loss : 0.021136, loss_ce: 0.007241
2022-01-08 12:40:56,215 iteration 3920 : loss : 0.019148, loss_ce: 0.008975
2022-01-08 12:40:58,608 iteration 3921 : loss : 0.034161, loss_ce: 0.009863
2022-01-08 12:41:00,991 iteration 3922 : loss : 0.013136, loss_ce: 0.004998
2022-01-08 12:41:03,354 iteration 3923 : loss : 0.018292, loss_ce: 0.007081
2022-01-08 12:41:05,822 iteration 3924 : loss : 0.027009, loss_ce: 0.011487
2022-01-08 12:41:08,322 iteration 3925 : loss : 0.028089, loss_ce: 0.011170
2022-01-08 12:41:10,711 iteration 3926 : loss : 0.020797, loss_ce: 0.008170
2022-01-08 12:41:13,075 iteration 3927 : loss : 0.021861, loss_ce: 0.008384
 58%|███████████████▌           | 231/400 [2:47:27<2:06:30, 44.91s/it]2022-01-08 12:41:15,477 iteration 3928 : loss : 0.023857, loss_ce: 0.011109
2022-01-08 12:41:17,902 iteration 3929 : loss : 0.024979, loss_ce: 0.010344
2022-01-08 12:41:20,345 iteration 3930 : loss : 0.038325, loss_ce: 0.013345
2022-01-08 12:41:22,714 iteration 3931 : loss : 0.020120, loss_ce: 0.009917
2022-01-08 12:41:25,059 iteration 3932 : loss : 0.021582, loss_ce: 0.006210
2022-01-08 12:41:27,404 iteration 3933 : loss : 0.030215, loss_ce: 0.007390
2022-01-08 12:41:29,828 iteration 3934 : loss : 0.021110, loss_ce: 0.006557
2022-01-08 12:41:32,292 iteration 3935 : loss : 0.022654, loss_ce: 0.007179
2022-01-08 12:41:34,668 iteration 3936 : loss : 0.022024, loss_ce: 0.009211
2022-01-08 12:41:37,003 iteration 3937 : loss : 0.018993, loss_ce: 0.005349
2022-01-08 12:41:39,310 iteration 3938 : loss : 0.020425, loss_ce: 0.009471
2022-01-08 12:41:41,667 iteration 3939 : loss : 0.027024, loss_ce: 0.009002
2022-01-08 12:41:43,919 iteration 3940 : loss : 0.025243, loss_ce: 0.006310
2022-01-08 12:41:46,212 iteration 3941 : loss : 0.022259, loss_ce: 0.010524
2022-01-08 12:41:48,512 iteration 3942 : loss : 0.031627, loss_ce: 0.012512
2022-01-08 12:41:50,893 iteration 3943 : loss : 0.024983, loss_ce: 0.012256
2022-01-08 12:41:53,185 iteration 3944 : loss : 0.018170, loss_ce: 0.005819
 58%|███████████████▋           | 232/400 [2:48:07<2:01:42, 43.47s/it]2022-01-08 12:41:55,598 iteration 3945 : loss : 0.014151, loss_ce: 0.006178
2022-01-08 12:41:57,925 iteration 3946 : loss : 0.014034, loss_ce: 0.005161
2022-01-08 12:42:00,355 iteration 3947 : loss : 0.018787, loss_ce: 0.006828
2022-01-08 12:42:02,713 iteration 3948 : loss : 0.020701, loss_ce: 0.008905
2022-01-08 12:42:05,067 iteration 3949 : loss : 0.023239, loss_ce: 0.011990
2022-01-08 12:42:07,441 iteration 3950 : loss : 0.019466, loss_ce: 0.007063
2022-01-08 12:42:09,795 iteration 3951 : loss : 0.022819, loss_ce: 0.009000
2022-01-08 12:42:12,203 iteration 3952 : loss : 0.015292, loss_ce: 0.006033
2022-01-08 12:42:14,574 iteration 3953 : loss : 0.019147, loss_ce: 0.005663
2022-01-08 12:42:16,921 iteration 3954 : loss : 0.024349, loss_ce: 0.008814
2022-01-08 12:42:19,359 iteration 3955 : loss : 0.021223, loss_ce: 0.007223
2022-01-08 12:42:21,716 iteration 3956 : loss : 0.020193, loss_ce: 0.008206
2022-01-08 12:42:24,148 iteration 3957 : loss : 0.019239, loss_ce: 0.008194
2022-01-08 12:42:26,618 iteration 3958 : loss : 0.018738, loss_ce: 0.008004
2022-01-08 12:42:28,929 iteration 3959 : loss : 0.017660, loss_ce: 0.005397
2022-01-08 12:42:31,219 iteration 3960 : loss : 0.020618, loss_ce: 0.004506
2022-01-08 12:42:33,646 iteration 3961 : loss : 0.019178, loss_ce: 0.007779
 58%|███████████████▋           | 233/400 [2:48:48<1:58:28, 42.57s/it]2022-01-08 12:42:36,131 iteration 3962 : loss : 0.032343, loss_ce: 0.011748
2022-01-08 12:42:38,658 iteration 3963 : loss : 0.019846, loss_ce: 0.008401
2022-01-08 12:42:41,098 iteration 3964 : loss : 0.032413, loss_ce: 0.013061
2022-01-08 12:42:43,493 iteration 3965 : loss : 0.026468, loss_ce: 0.007152
2022-01-08 12:42:45,740 iteration 3966 : loss : 0.019362, loss_ce: 0.006252
2022-01-08 12:42:48,066 iteration 3967 : loss : 0.020661, loss_ce: 0.005529
2022-01-08 12:42:50,492 iteration 3968 : loss : 0.022051, loss_ce: 0.008118
2022-01-08 12:42:52,824 iteration 3969 : loss : 0.025107, loss_ce: 0.009998
2022-01-08 12:42:55,182 iteration 3970 : loss : 0.022810, loss_ce: 0.011455
2022-01-08 12:42:57,525 iteration 3971 : loss : 0.019839, loss_ce: 0.005723
2022-01-08 12:42:59,904 iteration 3972 : loss : 0.019174, loss_ce: 0.006985
2022-01-08 12:43:02,313 iteration 3973 : loss : 0.025656, loss_ce: 0.008855
2022-01-08 12:43:04,781 iteration 3974 : loss : 0.021132, loss_ce: 0.008892
2022-01-08 12:43:07,249 iteration 3975 : loss : 0.014959, loss_ce: 0.005315
2022-01-08 12:43:09,663 iteration 3976 : loss : 0.021407, loss_ce: 0.010242
2022-01-08 12:43:11,993 iteration 3977 : loss : 0.017852, loss_ce: 0.006745
2022-01-08 12:43:14,328 iteration 3978 : loss : 0.019506, loss_ce: 0.008133
 58%|███████████████▊           | 234/400 [2:49:29<1:56:12, 42.01s/it]2022-01-08 12:43:16,791 iteration 3979 : loss : 0.032741, loss_ce: 0.010016
2022-01-08 12:43:19,239 iteration 3980 : loss : 0.024101, loss_ce: 0.010274
2022-01-08 12:43:21,597 iteration 3981 : loss : 0.019175, loss_ce: 0.007291
2022-01-08 12:43:24,127 iteration 3982 : loss : 0.021255, loss_ce: 0.007839
2022-01-08 12:43:26,495 iteration 3983 : loss : 0.017107, loss_ce: 0.004978
2022-01-08 12:43:28,895 iteration 3984 : loss : 0.020495, loss_ce: 0.007678
2022-01-08 12:43:31,208 iteration 3985 : loss : 0.028142, loss_ce: 0.008524
2022-01-08 12:43:33,444 iteration 3986 : loss : 0.015648, loss_ce: 0.006337
2022-01-08 12:43:35,795 iteration 3987 : loss : 0.014815, loss_ce: 0.006373
2022-01-08 12:43:38,276 iteration 3988 : loss : 0.039324, loss_ce: 0.019048
2022-01-08 12:43:40,671 iteration 3989 : loss : 0.022506, loss_ce: 0.008457
2022-01-08 12:43:43,016 iteration 3990 : loss : 0.014571, loss_ce: 0.005013
2022-01-08 12:43:45,370 iteration 3991 : loss : 0.025315, loss_ce: 0.009193
2022-01-08 12:43:47,785 iteration 3992 : loss : 0.038096, loss_ce: 0.009746
2022-01-08 12:43:50,157 iteration 3993 : loss : 0.021964, loss_ce: 0.010722
2022-01-08 12:43:52,538 iteration 3994 : loss : 0.017437, loss_ce: 0.008126
2022-01-08 12:43:52,538 Training Data Eval:
2022-01-08 12:44:05,133   Average segmentation loss on training set: 0.0126
2022-01-08 12:44:05,134 Validation Data Eval:
2022-01-08 12:44:09,617   Average segmentation loss on validation set: 0.0875
2022-01-08 12:44:12,005 iteration 3995 : loss : 0.023101, loss_ce: 0.006706
 59%|███████████████▊           | 235/400 [2:50:26<2:08:25, 46.70s/it]2022-01-08 12:44:14,471 iteration 3996 : loss : 0.027198, loss_ce: 0.014825
2022-01-08 12:44:16,830 iteration 3997 : loss : 0.018072, loss_ce: 0.005987
2022-01-08 12:44:19,145 iteration 3998 : loss : 0.022474, loss_ce: 0.008208
2022-01-08 12:44:21,528 iteration 3999 : loss : 0.021910, loss_ce: 0.007542
2022-01-08 12:44:23,933 iteration 4000 : loss : 0.019972, loss_ce: 0.007498
2022-01-08 12:44:26,427 iteration 4001 : loss : 0.022853, loss_ce: 0.006296
2022-01-08 12:44:28,838 iteration 4002 : loss : 0.019993, loss_ce: 0.010904
2022-01-08 12:44:31,220 iteration 4003 : loss : 0.020825, loss_ce: 0.008852
2022-01-08 12:44:33,559 iteration 4004 : loss : 0.024378, loss_ce: 0.009149
2022-01-08 12:44:35,986 iteration 4005 : loss : 0.022212, loss_ce: 0.010594
2022-01-08 12:44:38,457 iteration 4006 : loss : 0.029060, loss_ce: 0.008916
2022-01-08 12:44:40,838 iteration 4007 : loss : 0.026828, loss_ce: 0.010344
2022-01-08 12:44:43,242 iteration 4008 : loss : 0.023953, loss_ce: 0.006804
2022-01-08 12:44:45,595 iteration 4009 : loss : 0.018819, loss_ce: 0.007262
2022-01-08 12:44:47,910 iteration 4010 : loss : 0.012197, loss_ce: 0.004561
2022-01-08 12:44:50,309 iteration 4011 : loss : 0.029813, loss_ce: 0.009574
2022-01-08 12:44:52,678 iteration 4012 : loss : 0.019352, loss_ce: 0.008776
 59%|███████████████▉           | 236/400 [2:51:07<2:02:42, 44.89s/it]2022-01-08 12:44:55,025 iteration 4013 : loss : 0.022620, loss_ce: 0.005939
2022-01-08 12:44:57,447 iteration 4014 : loss : 0.027970, loss_ce: 0.009592
2022-01-08 12:44:59,782 iteration 4015 : loss : 0.020755, loss_ce: 0.009925
2022-01-08 12:45:02,215 iteration 4016 : loss : 0.019779, loss_ce: 0.006873
2022-01-08 12:45:04,630 iteration 4017 : loss : 0.045606, loss_ce: 0.018640
2022-01-08 12:45:07,101 iteration 4018 : loss : 0.023731, loss_ce: 0.008391
2022-01-08 12:45:09,490 iteration 4019 : loss : 0.022528, loss_ce: 0.009423
2022-01-08 12:45:11,797 iteration 4020 : loss : 0.017502, loss_ce: 0.005991
2022-01-08 12:45:14,189 iteration 4021 : loss : 0.031091, loss_ce: 0.010469
2022-01-08 12:45:16,542 iteration 4022 : loss : 0.025798, loss_ce: 0.009508
2022-01-08 12:45:18,947 iteration 4023 : loss : 0.019899, loss_ce: 0.009529
2022-01-08 12:45:21,279 iteration 4024 : loss : 0.027433, loss_ce: 0.008958
2022-01-08 12:45:23,684 iteration 4025 : loss : 0.021881, loss_ce: 0.008435
2022-01-08 12:45:26,213 iteration 4026 : loss : 0.015312, loss_ce: 0.006488
2022-01-08 12:45:28,615 iteration 4027 : loss : 0.016293, loss_ce: 0.006248
2022-01-08 12:45:30,960 iteration 4028 : loss : 0.018206, loss_ce: 0.004397
2022-01-08 12:45:33,270 iteration 4029 : loss : 0.019149, loss_ce: 0.007284
 59%|███████████████▉           | 237/400 [2:51:48<1:58:26, 43.60s/it]2022-01-08 12:45:35,603 iteration 4030 : loss : 0.025654, loss_ce: 0.009875
2022-01-08 12:45:37,894 iteration 4031 : loss : 0.017430, loss_ce: 0.006345
2022-01-08 12:45:40,285 iteration 4032 : loss : 0.015664, loss_ce: 0.005002
2022-01-08 12:45:42,774 iteration 4033 : loss : 0.026534, loss_ce: 0.010469
2022-01-08 12:45:45,104 iteration 4034 : loss : 0.022308, loss_ce: 0.007501
2022-01-08 12:45:47,523 iteration 4035 : loss : 0.017379, loss_ce: 0.005725
2022-01-08 12:45:49,937 iteration 4036 : loss : 0.017045, loss_ce: 0.006258
2022-01-08 12:45:52,355 iteration 4037 : loss : 0.025543, loss_ce: 0.008631
2022-01-08 12:45:54,667 iteration 4038 : loss : 0.017872, loss_ce: 0.009948
2022-01-08 12:45:56,903 iteration 4039 : loss : 0.017489, loss_ce: 0.008553
2022-01-08 12:45:59,224 iteration 4040 : loss : 0.024873, loss_ce: 0.005575
2022-01-08 12:46:01,648 iteration 4041 : loss : 0.025462, loss_ce: 0.013202
2022-01-08 12:46:03,837 iteration 4042 : loss : 0.017051, loss_ce: 0.007050
2022-01-08 12:46:06,076 iteration 4043 : loss : 0.018980, loss_ce: 0.008653
2022-01-08 12:46:08,317 iteration 4044 : loss : 0.018667, loss_ce: 0.007504
2022-01-08 12:46:10,639 iteration 4045 : loss : 0.020739, loss_ce: 0.007775
2022-01-08 12:46:13,027 iteration 4046 : loss : 0.018193, loss_ce: 0.006444
 60%|████████████████           | 238/400 [2:52:27<1:54:37, 42.45s/it]2022-01-08 12:46:15,343 iteration 4047 : loss : 0.016634, loss_ce: 0.007095
2022-01-08 12:46:17,719 iteration 4048 : loss : 0.014671, loss_ce: 0.004220
2022-01-08 12:46:20,115 iteration 4049 : loss : 0.023303, loss_ce: 0.008631
2022-01-08 12:46:22,482 iteration 4050 : loss : 0.018425, loss_ce: 0.004545
2022-01-08 12:46:24,885 iteration 4051 : loss : 0.012656, loss_ce: 0.004115
2022-01-08 12:46:27,191 iteration 4052 : loss : 0.016359, loss_ce: 0.004473
2022-01-08 12:46:29,590 iteration 4053 : loss : 0.019281, loss_ce: 0.010257
2022-01-08 12:46:31,932 iteration 4054 : loss : 0.020864, loss_ce: 0.008490
2022-01-08 12:46:34,387 iteration 4055 : loss : 0.016837, loss_ce: 0.005421
2022-01-08 12:46:36,843 iteration 4056 : loss : 0.020314, loss_ce: 0.006078
2022-01-08 12:46:39,271 iteration 4057 : loss : 0.026673, loss_ce: 0.012043
2022-01-08 12:46:41,509 iteration 4058 : loss : 0.017934, loss_ce: 0.009210
2022-01-08 12:46:43,867 iteration 4059 : loss : 0.033420, loss_ce: 0.016391
2022-01-08 12:46:46,231 iteration 4060 : loss : 0.017438, loss_ce: 0.006662
2022-01-08 12:46:48,547 iteration 4061 : loss : 0.020408, loss_ce: 0.006362
2022-01-08 12:46:50,878 iteration 4062 : loss : 0.024970, loss_ce: 0.010926
2022-01-08 12:46:53,341 iteration 4063 : loss : 0.037178, loss_ce: 0.010703
 60%|████████████████▏          | 239/400 [2:53:08<1:52:11, 41.81s/it]2022-01-08 12:46:55,746 iteration 4064 : loss : 0.017961, loss_ce: 0.006026
2022-01-08 12:46:58,045 iteration 4065 : loss : 0.018784, loss_ce: 0.007942
2022-01-08 12:47:00,374 iteration 4066 : loss : 0.028599, loss_ce: 0.008774
2022-01-08 12:47:02,704 iteration 4067 : loss : 0.027829, loss_ce: 0.005961
2022-01-08 12:47:05,145 iteration 4068 : loss : 0.023384, loss_ce: 0.009667
2022-01-08 12:47:07,566 iteration 4069 : loss : 0.021367, loss_ce: 0.006885
2022-01-08 12:47:09,933 iteration 4070 : loss : 0.020781, loss_ce: 0.010901
2022-01-08 12:47:12,186 iteration 4071 : loss : 0.016987, loss_ce: 0.006662
2022-01-08 12:47:14,538 iteration 4072 : loss : 0.018717, loss_ce: 0.007942
2022-01-08 12:47:17,031 iteration 4073 : loss : 0.031151, loss_ce: 0.015188
2022-01-08 12:47:19,377 iteration 4074 : loss : 0.020888, loss_ce: 0.008102
2022-01-08 12:47:21,751 iteration 4075 : loss : 0.025008, loss_ce: 0.009751
2022-01-08 12:47:24,087 iteration 4076 : loss : 0.017096, loss_ce: 0.006031
2022-01-08 12:47:26,507 iteration 4077 : loss : 0.016587, loss_ce: 0.007421
2022-01-08 12:47:28,983 iteration 4078 : loss : 0.026725, loss_ce: 0.007562
2022-01-08 12:47:31,310 iteration 4079 : loss : 0.017779, loss_ce: 0.005957
2022-01-08 12:47:31,310 Training Data Eval:
2022-01-08 12:47:43,955   Average segmentation loss on training set: 0.0122
2022-01-08 12:47:43,956 Validation Data Eval:
2022-01-08 12:47:48,303   Average segmentation loss on validation set: 0.0670
2022-01-08 12:47:50,704 iteration 4080 : loss : 0.023299, loss_ce: 0.007513
 60%|████████████████▏          | 240/400 [2:54:05<2:03:56, 46.48s/it]2022-01-08 12:47:53,137 iteration 4081 : loss : 0.019324, loss_ce: 0.009760
2022-01-08 12:47:55,525 iteration 4082 : loss : 0.023169, loss_ce: 0.008332
2022-01-08 12:47:57,859 iteration 4083 : loss : 0.017522, loss_ce: 0.007192
2022-01-08 12:48:00,206 iteration 4084 : loss : 0.014898, loss_ce: 0.005105
2022-01-08 12:48:02,677 iteration 4085 : loss : 0.028061, loss_ce: 0.007143
2022-01-08 12:48:05,046 iteration 4086 : loss : 0.014917, loss_ce: 0.005441
2022-01-08 12:48:07,368 iteration 4087 : loss : 0.024895, loss_ce: 0.007482
2022-01-08 12:48:09,805 iteration 4088 : loss : 0.018733, loss_ce: 0.009124
2022-01-08 12:48:12,215 iteration 4089 : loss : 0.027748, loss_ce: 0.010379
2022-01-08 12:48:14,512 iteration 4090 : loss : 0.023451, loss_ce: 0.011864
2022-01-08 12:48:16,822 iteration 4091 : loss : 0.030488, loss_ce: 0.010269
2022-01-08 12:48:18,994 iteration 4092 : loss : 0.023686, loss_ce: 0.006571
2022-01-08 12:48:21,232 iteration 4093 : loss : 0.016161, loss_ce: 0.006883
2022-01-08 12:48:23,562 iteration 4094 : loss : 0.025233, loss_ce: 0.008811
2022-01-08 12:48:25,843 iteration 4095 : loss : 0.027920, loss_ce: 0.008013
2022-01-08 12:48:28,270 iteration 4096 : loss : 0.021040, loss_ce: 0.008833
2022-01-08 12:48:30,674 iteration 4097 : loss : 0.018579, loss_ce: 0.007321
 60%|████████████████▎          | 241/400 [2:54:45<1:57:59, 44.52s/it]2022-01-08 12:48:33,034 iteration 4098 : loss : 0.017146, loss_ce: 0.006158
2022-01-08 12:48:35,388 iteration 4099 : loss : 0.022547, loss_ce: 0.008441
2022-01-08 12:48:37,673 iteration 4100 : loss : 0.018520, loss_ce: 0.006890
2022-01-08 12:48:40,169 iteration 4101 : loss : 0.016326, loss_ce: 0.007457
2022-01-08 12:48:42,642 iteration 4102 : loss : 0.025764, loss_ce: 0.009325
2022-01-08 12:48:44,908 iteration 4103 : loss : 0.017424, loss_ce: 0.007701
2022-01-08 12:48:47,224 iteration 4104 : loss : 0.024491, loss_ce: 0.008887
2022-01-08 12:48:49,533 iteration 4105 : loss : 0.020448, loss_ce: 0.006723
2022-01-08 12:48:51,940 iteration 4106 : loss : 0.030683, loss_ce: 0.010233
2022-01-08 12:48:54,277 iteration 4107 : loss : 0.020691, loss_ce: 0.007878
2022-01-08 12:48:56,616 iteration 4108 : loss : 0.019658, loss_ce: 0.007688
2022-01-08 12:48:58,985 iteration 4109 : loss : 0.031567, loss_ce: 0.007889
2022-01-08 12:49:01,342 iteration 4110 : loss : 0.015300, loss_ce: 0.004927
2022-01-08 12:49:03,700 iteration 4111 : loss : 0.020124, loss_ce: 0.005700
2022-01-08 12:49:06,041 iteration 4112 : loss : 0.013425, loss_ce: 0.005347
2022-01-08 12:49:08,489 iteration 4113 : loss : 0.027360, loss_ce: 0.010598
2022-01-08 12:49:10,888 iteration 4114 : loss : 0.027796, loss_ce: 0.013206
 60%|████████████████▎          | 242/400 [2:55:25<1:53:50, 43.23s/it]2022-01-08 12:49:13,247 iteration 4115 : loss : 0.020257, loss_ce: 0.005108
2022-01-08 12:49:15,582 iteration 4116 : loss : 0.016851, loss_ce: 0.007390
2022-01-08 12:49:17,912 iteration 4117 : loss : 0.017830, loss_ce: 0.009984
2022-01-08 12:49:20,311 iteration 4118 : loss : 0.029093, loss_ce: 0.008768
2022-01-08 12:49:22,668 iteration 4119 : loss : 0.014601, loss_ce: 0.005357
2022-01-08 12:49:25,141 iteration 4120 : loss : 0.017935, loss_ce: 0.005332
2022-01-08 12:49:27,413 iteration 4121 : loss : 0.023097, loss_ce: 0.008640
2022-01-08 12:49:29,833 iteration 4122 : loss : 0.017916, loss_ce: 0.005640
2022-01-08 12:49:32,383 iteration 4123 : loss : 0.018811, loss_ce: 0.007089
2022-01-08 12:49:34,738 iteration 4124 : loss : 0.014397, loss_ce: 0.005586
2022-01-08 12:49:37,116 iteration 4125 : loss : 0.030062, loss_ce: 0.009732
2022-01-08 12:49:39,524 iteration 4126 : loss : 0.020126, loss_ce: 0.007856
2022-01-08 12:49:41,870 iteration 4127 : loss : 0.018620, loss_ce: 0.008498
2022-01-08 12:49:44,160 iteration 4128 : loss : 0.018882, loss_ce: 0.008068
2022-01-08 12:49:46,579 iteration 4129 : loss : 0.020516, loss_ce: 0.005515
2022-01-08 12:49:48,925 iteration 4130 : loss : 0.022097, loss_ce: 0.006689
2022-01-08 12:49:51,320 iteration 4131 : loss : 0.015972, loss_ce: 0.006366
 61%|████████████████▍          | 243/400 [2:56:06<1:50:55, 42.39s/it]2022-01-08 12:49:53,816 iteration 4132 : loss : 0.020648, loss_ce: 0.006712
2022-01-08 12:49:56,082 iteration 4133 : loss : 0.019870, loss_ce: 0.009300
2022-01-08 12:49:58,503 iteration 4134 : loss : 0.013630, loss_ce: 0.005683
2022-01-08 12:50:00,864 iteration 4135 : loss : 0.028950, loss_ce: 0.009571
2022-01-08 12:50:03,193 iteration 4136 : loss : 0.015966, loss_ce: 0.004451
2022-01-08 12:50:05,602 iteration 4137 : loss : 0.018339, loss_ce: 0.008805
2022-01-08 12:50:08,021 iteration 4138 : loss : 0.018588, loss_ce: 0.010080
2022-01-08 12:50:10,482 iteration 4139 : loss : 0.021347, loss_ce: 0.005448
2022-01-08 12:50:12,944 iteration 4140 : loss : 0.021918, loss_ce: 0.008058
2022-01-08 12:50:15,371 iteration 4141 : loss : 0.018140, loss_ce: 0.004518
2022-01-08 12:50:17,768 iteration 4142 : loss : 0.015734, loss_ce: 0.006734
2022-01-08 12:50:20,114 iteration 4143 : loss : 0.016717, loss_ce: 0.005889
2022-01-08 12:50:22,526 iteration 4144 : loss : 0.018694, loss_ce: 0.005494
2022-01-08 12:50:24,921 iteration 4145 : loss : 0.025166, loss_ce: 0.009829
2022-01-08 12:50:27,197 iteration 4146 : loss : 0.015521, loss_ce: 0.003927
2022-01-08 12:50:29,468 iteration 4147 : loss : 0.017087, loss_ce: 0.007070
2022-01-08 12:50:31,867 iteration 4148 : loss : 0.016627, loss_ce: 0.006156
 61%|████████████████▍          | 244/400 [2:56:46<1:48:46, 41.84s/it]2022-01-08 12:50:34,308 iteration 4149 : loss : 0.017330, loss_ce: 0.006845
2022-01-08 12:50:36,654 iteration 4150 : loss : 0.016462, loss_ce: 0.005446
2022-01-08 12:50:39,040 iteration 4151 : loss : 0.018654, loss_ce: 0.008934
2022-01-08 12:50:41,516 iteration 4152 : loss : 0.017119, loss_ce: 0.007158
2022-01-08 12:50:43,941 iteration 4153 : loss : 0.029067, loss_ce: 0.014151
2022-01-08 12:50:46,255 iteration 4154 : loss : 0.014310, loss_ce: 0.005749
2022-01-08 12:50:48,613 iteration 4155 : loss : 0.014056, loss_ce: 0.006616
2022-01-08 12:50:51,043 iteration 4156 : loss : 0.020784, loss_ce: 0.007524
2022-01-08 12:50:53,438 iteration 4157 : loss : 0.016254, loss_ce: 0.005710
2022-01-08 12:50:55,876 iteration 4158 : loss : 0.013311, loss_ce: 0.005341
2022-01-08 12:50:58,345 iteration 4159 : loss : 0.015512, loss_ce: 0.006620
2022-01-08 12:51:00,753 iteration 4160 : loss : 0.018290, loss_ce: 0.006999
2022-01-08 12:51:03,055 iteration 4161 : loss : 0.028622, loss_ce: 0.007513
2022-01-08 12:51:05,568 iteration 4162 : loss : 0.032303, loss_ce: 0.012322
2022-01-08 12:51:08,038 iteration 4163 : loss : 0.027616, loss_ce: 0.010254
2022-01-08 12:51:10,436 iteration 4164 : loss : 0.016333, loss_ce: 0.004603
2022-01-08 12:51:10,436 Training Data Eval:
2022-01-08 12:51:23,209   Average segmentation loss on training set: 0.0164
2022-01-08 12:51:23,209 Validation Data Eval:
2022-01-08 12:51:27,760   Average segmentation loss on validation set: 0.0717
2022-01-08 12:51:30,222 iteration 4165 : loss : 0.018664, loss_ce: 0.005784
 61%|████████████████▌          | 245/400 [2:57:44<2:00:53, 46.79s/it]2022-01-08 12:51:32,650 iteration 4166 : loss : 0.024550, loss_ce: 0.007366
2022-01-08 12:51:34,965 iteration 4167 : loss : 0.014476, loss_ce: 0.005957
2022-01-08 12:51:37,427 iteration 4168 : loss : 0.015387, loss_ce: 0.004268
2022-01-08 12:51:39,760 iteration 4169 : loss : 0.020398, loss_ce: 0.008317
2022-01-08 12:51:42,233 iteration 4170 : loss : 0.025982, loss_ce: 0.008958
2022-01-08 12:51:44,711 iteration 4171 : loss : 0.019183, loss_ce: 0.007203
2022-01-08 12:51:47,058 iteration 4172 : loss : 0.015291, loss_ce: 0.003438
2022-01-08 12:51:49,454 iteration 4173 : loss : 0.027517, loss_ce: 0.008873
2022-01-08 12:51:51,870 iteration 4174 : loss : 0.021642, loss_ce: 0.010353
2022-01-08 12:51:54,294 iteration 4175 : loss : 0.023800, loss_ce: 0.008721
2022-01-08 12:51:56,739 iteration 4176 : loss : 0.022731, loss_ce: 0.010061
2022-01-08 12:51:59,149 iteration 4177 : loss : 0.026504, loss_ce: 0.009035
2022-01-08 12:52:01,493 iteration 4178 : loss : 0.018611, loss_ce: 0.007167
2022-01-08 12:52:03,977 iteration 4179 : loss : 0.021142, loss_ce: 0.007760
2022-01-08 12:52:06,449 iteration 4180 : loss : 0.026129, loss_ce: 0.009094
2022-01-08 12:52:08,773 iteration 4181 : loss : 0.024553, loss_ce: 0.007084
2022-01-08 12:52:11,379 iteration 4182 : loss : 0.018384, loss_ce: 0.008487
 62%|████████████████▌          | 246/400 [2:58:26<1:55:45, 45.10s/it]2022-01-08 12:52:13,873 iteration 4183 : loss : 0.021594, loss_ce: 0.007746
2022-01-08 12:52:16,286 iteration 4184 : loss : 0.026890, loss_ce: 0.011124
2022-01-08 12:52:18,675 iteration 4185 : loss : 0.020899, loss_ce: 0.006737
2022-01-08 12:52:21,118 iteration 4186 : loss : 0.015832, loss_ce: 0.006443
2022-01-08 12:52:23,570 iteration 4187 : loss : 0.024384, loss_ce: 0.008313
2022-01-08 12:52:25,913 iteration 4188 : loss : 0.017793, loss_ce: 0.008316
2022-01-08 12:52:28,157 iteration 4189 : loss : 0.017206, loss_ce: 0.004515
2022-01-08 12:52:30,363 iteration 4190 : loss : 0.026568, loss_ce: 0.011053
2022-01-08 12:52:32,580 iteration 4191 : loss : 0.022492, loss_ce: 0.006711
2022-01-08 12:52:34,959 iteration 4192 : loss : 0.022046, loss_ce: 0.006161
2022-01-08 12:52:37,280 iteration 4193 : loss : 0.020281, loss_ce: 0.006941
2022-01-08 12:52:39,649 iteration 4194 : loss : 0.017004, loss_ce: 0.006737
2022-01-08 12:52:42,020 iteration 4195 : loss : 0.028121, loss_ce: 0.010183
2022-01-08 12:52:44,267 iteration 4196 : loss : 0.016170, loss_ce: 0.008295
2022-01-08 12:52:46,706 iteration 4197 : loss : 0.018209, loss_ce: 0.004982
2022-01-08 12:52:49,077 iteration 4198 : loss : 0.021046, loss_ce: 0.007501
2022-01-08 12:52:51,393 iteration 4199 : loss : 0.017244, loss_ce: 0.006209
 62%|████████████████▋          | 247/400 [2:59:06<1:51:06, 43.57s/it]2022-01-08 12:52:53,762 iteration 4200 : loss : 0.017973, loss_ce: 0.005634
2022-01-08 12:52:56,142 iteration 4201 : loss : 0.020555, loss_ce: 0.008510
2022-01-08 12:52:58,415 iteration 4202 : loss : 0.014325, loss_ce: 0.006663
2022-01-08 12:53:00,783 iteration 4203 : loss : 0.018052, loss_ce: 0.007305
2022-01-08 12:53:03,162 iteration 4204 : loss : 0.019362, loss_ce: 0.006725
2022-01-08 12:53:05,564 iteration 4205 : loss : 0.016539, loss_ce: 0.005869
2022-01-08 12:53:07,940 iteration 4206 : loss : 0.016280, loss_ce: 0.005378
2022-01-08 12:53:10,475 iteration 4207 : loss : 0.013740, loss_ce: 0.006154
2022-01-08 12:53:12,864 iteration 4208 : loss : 0.018342, loss_ce: 0.006667
2022-01-08 12:53:15,305 iteration 4209 : loss : 0.027490, loss_ce: 0.005743
2022-01-08 12:53:17,700 iteration 4210 : loss : 0.018278, loss_ce: 0.006729
2022-01-08 12:53:20,026 iteration 4211 : loss : 0.012409, loss_ce: 0.004924
2022-01-08 12:53:22,395 iteration 4212 : loss : 0.016232, loss_ce: 0.006256
2022-01-08 12:53:24,779 iteration 4213 : loss : 0.034983, loss_ce: 0.017177
2022-01-08 12:53:27,255 iteration 4214 : loss : 0.024468, loss_ce: 0.007939
2022-01-08 12:53:29,768 iteration 4215 : loss : 0.015077, loss_ce: 0.005223
2022-01-08 12:53:32,232 iteration 4216 : loss : 0.031080, loss_ce: 0.010250
 62%|████████████████▋          | 248/400 [2:59:46<1:48:19, 42.76s/it]2022-01-08 12:53:34,708 iteration 4217 : loss : 0.017539, loss_ce: 0.007310
2022-01-08 12:53:36,889 iteration 4218 : loss : 0.014845, loss_ce: 0.007733
2022-01-08 12:53:39,252 iteration 4219 : loss : 0.019246, loss_ce: 0.007611
2022-01-08 12:53:41,712 iteration 4220 : loss : 0.027569, loss_ce: 0.011167
2022-01-08 12:53:44,055 iteration 4221 : loss : 0.016713, loss_ce: 0.004553
2022-01-08 12:53:46,470 iteration 4222 : loss : 0.022404, loss_ce: 0.008522
2022-01-08 12:53:48,874 iteration 4223 : loss : 0.016988, loss_ce: 0.005908
2022-01-08 12:53:51,292 iteration 4224 : loss : 0.016784, loss_ce: 0.005097
2022-01-08 12:53:53,695 iteration 4225 : loss : 0.029629, loss_ce: 0.009392
2022-01-08 12:53:56,047 iteration 4226 : loss : 0.018535, loss_ce: 0.005061
2022-01-08 12:53:58,488 iteration 4227 : loss : 0.032956, loss_ce: 0.011636
2022-01-08 12:54:00,878 iteration 4228 : loss : 0.024510, loss_ce: 0.009015
2022-01-08 12:54:03,280 iteration 4229 : loss : 0.015931, loss_ce: 0.006043
2022-01-08 12:54:05,685 iteration 4230 : loss : 0.023410, loss_ce: 0.011540
2022-01-08 12:54:08,041 iteration 4231 : loss : 0.020633, loss_ce: 0.006591
2022-01-08 12:54:10,373 iteration 4232 : loss : 0.017778, loss_ce: 0.007005
2022-01-08 12:54:12,754 iteration 4233 : loss : 0.018661, loss_ce: 0.008823
 62%|████████████████▊          | 249/400 [3:00:27<1:45:54, 42.08s/it]2022-01-08 12:54:15,208 iteration 4234 : loss : 0.029047, loss_ce: 0.016345
2022-01-08 12:54:17,657 iteration 4235 : loss : 0.016518, loss_ce: 0.004744
2022-01-08 12:54:20,047 iteration 4236 : loss : 0.015998, loss_ce: 0.006493
2022-01-08 12:54:22,375 iteration 4237 : loss : 0.018092, loss_ce: 0.006856
2022-01-08 12:54:24,699 iteration 4238 : loss : 0.015332, loss_ce: 0.004462
2022-01-08 12:54:27,029 iteration 4239 : loss : 0.018515, loss_ce: 0.007175
2022-01-08 12:54:29,456 iteration 4240 : loss : 0.034690, loss_ce: 0.016568
2022-01-08 12:54:31,759 iteration 4241 : loss : 0.019167, loss_ce: 0.007732
2022-01-08 12:54:34,226 iteration 4242 : loss : 0.015955, loss_ce: 0.005906
2022-01-08 12:54:36,655 iteration 4243 : loss : 0.021686, loss_ce: 0.007728
2022-01-08 12:54:38,945 iteration 4244 : loss : 0.016262, loss_ce: 0.004803
2022-01-08 12:54:41,221 iteration 4245 : loss : 0.019710, loss_ce: 0.006910
2022-01-08 12:54:43,454 iteration 4246 : loss : 0.017749, loss_ce: 0.005915
2022-01-08 12:54:45,729 iteration 4247 : loss : 0.022062, loss_ce: 0.006569
2022-01-08 12:54:47,901 iteration 4248 : loss : 0.015663, loss_ce: 0.006351
2022-01-08 12:54:50,173 iteration 4249 : loss : 0.022396, loss_ce: 0.009831
2022-01-08 12:54:50,173 Training Data Eval:
2022-01-08 12:55:02,914   Average segmentation loss on training set: 0.0118
2022-01-08 12:55:02,914 Validation Data Eval:
2022-01-08 12:55:07,401   Average segmentation loss on validation set: 0.0673
2022-01-08 12:55:09,830 iteration 4250 : loss : 0.015075, loss_ce: 0.005685
 62%|████████████████▉          | 250/400 [3:01:24<1:56:26, 46.58s/it]2022-01-08 12:55:12,280 iteration 4251 : loss : 0.016171, loss_ce: 0.006381
2022-01-08 12:55:14,671 iteration 4252 : loss : 0.017897, loss_ce: 0.004368
2022-01-08 12:55:17,093 iteration 4253 : loss : 0.020662, loss_ce: 0.011010
2022-01-08 12:55:19,509 iteration 4254 : loss : 0.018851, loss_ce: 0.007221
2022-01-08 12:55:21,877 iteration 4255 : loss : 0.029123, loss_ce: 0.008028
2022-01-08 12:55:24,374 iteration 4256 : loss : 0.043269, loss_ce: 0.017624
2022-01-08 12:55:26,794 iteration 4257 : loss : 0.021583, loss_ce: 0.010724
2022-01-08 12:55:29,211 iteration 4258 : loss : 0.019948, loss_ce: 0.009437
2022-01-08 12:55:31,444 iteration 4259 : loss : 0.016073, loss_ce: 0.005950
2022-01-08 12:55:33,836 iteration 4260 : loss : 0.019461, loss_ce: 0.006422
2022-01-08 12:55:36,107 iteration 4261 : loss : 0.014381, loss_ce: 0.004857
2022-01-08 12:55:38,438 iteration 4262 : loss : 0.015921, loss_ce: 0.006796
2022-01-08 12:55:40,873 iteration 4263 : loss : 0.019204, loss_ce: 0.007614
2022-01-08 12:55:43,293 iteration 4264 : loss : 0.017924, loss_ce: 0.007822
2022-01-08 12:55:45,584 iteration 4265 : loss : 0.014654, loss_ce: 0.006313
2022-01-08 12:55:47,945 iteration 4266 : loss : 0.019080, loss_ce: 0.005594
2022-01-08 12:55:50,351 iteration 4267 : loss : 0.022223, loss_ce: 0.008661
 63%|████████████████▉          | 251/400 [3:02:05<1:51:09, 44.76s/it]2022-01-08 12:55:52,714 iteration 4268 : loss : 0.021083, loss_ce: 0.008867
2022-01-08 12:55:55,068 iteration 4269 : loss : 0.013916, loss_ce: 0.003871
2022-01-08 12:55:57,395 iteration 4270 : loss : 0.026864, loss_ce: 0.007602
2022-01-08 12:55:59,749 iteration 4271 : loss : 0.015164, loss_ce: 0.005541
2022-01-08 12:56:02,115 iteration 4272 : loss : 0.016160, loss_ce: 0.006465
2022-01-08 12:56:04,582 iteration 4273 : loss : 0.015771, loss_ce: 0.006928
2022-01-08 12:56:06,991 iteration 4274 : loss : 0.018083, loss_ce: 0.007926
2022-01-08 12:56:09,346 iteration 4275 : loss : 0.019050, loss_ce: 0.007353
2022-01-08 12:56:11,665 iteration 4276 : loss : 0.017580, loss_ce: 0.006305
2022-01-08 12:56:14,064 iteration 4277 : loss : 0.021545, loss_ce: 0.011257
2022-01-08 12:56:16,424 iteration 4278 : loss : 0.018765, loss_ce: 0.005013
2022-01-08 12:56:18,768 iteration 4279 : loss : 0.014841, loss_ce: 0.006270
2022-01-08 12:56:21,162 iteration 4280 : loss : 0.028796, loss_ce: 0.008621
2022-01-08 12:56:23,510 iteration 4281 : loss : 0.020090, loss_ce: 0.008025
2022-01-08 12:56:25,848 iteration 4282 : loss : 0.047175, loss_ce: 0.014792
2022-01-08 12:56:28,339 iteration 4283 : loss : 0.018249, loss_ce: 0.009875
2022-01-08 12:56:30,799 iteration 4284 : loss : 0.021233, loss_ce: 0.009133
 63%|█████████████████          | 252/400 [3:02:45<1:47:13, 43.47s/it]2022-01-08 12:56:33,201 iteration 4285 : loss : 0.019291, loss_ce: 0.010248
2022-01-08 12:56:35,532 iteration 4286 : loss : 0.018774, loss_ce: 0.007011
2022-01-08 12:56:37,909 iteration 4287 : loss : 0.035400, loss_ce: 0.014682
2022-01-08 12:56:40,410 iteration 4288 : loss : 0.013796, loss_ce: 0.004233
2022-01-08 12:56:42,767 iteration 4289 : loss : 0.014572, loss_ce: 0.006251
2022-01-08 12:56:45,098 iteration 4290 : loss : 0.015184, loss_ce: 0.005469
2022-01-08 12:56:47,467 iteration 4291 : loss : 0.020178, loss_ce: 0.008659
2022-01-08 12:56:49,807 iteration 4292 : loss : 0.023552, loss_ce: 0.011487
2022-01-08 12:56:52,057 iteration 4293 : loss : 0.017804, loss_ce: 0.006532
2022-01-08 12:56:54,381 iteration 4294 : loss : 0.016826, loss_ce: 0.007667
2022-01-08 12:56:56,849 iteration 4295 : loss : 0.024086, loss_ce: 0.008855
2022-01-08 12:56:59,157 iteration 4296 : loss : 0.016578, loss_ce: 0.006348
2022-01-08 12:57:01,411 iteration 4297 : loss : 0.015048, loss_ce: 0.004533
2022-01-08 12:57:03,751 iteration 4298 : loss : 0.020977, loss_ce: 0.007978
2022-01-08 12:57:06,248 iteration 4299 : loss : 0.038122, loss_ce: 0.011613
2022-01-08 12:57:08,715 iteration 4300 : loss : 0.055380, loss_ce: 0.016976
2022-01-08 12:57:11,077 iteration 4301 : loss : 0.024452, loss_ce: 0.008965
 63%|█████████████████          | 253/400 [3:03:25<1:44:08, 42.51s/it]2022-01-08 12:57:13,461 iteration 4302 : loss : 0.021185, loss_ce: 0.007958
2022-01-08 12:57:15,860 iteration 4303 : loss : 0.018485, loss_ce: 0.009664
2022-01-08 12:57:18,247 iteration 4304 : loss : 0.018302, loss_ce: 0.007445
2022-01-08 12:57:20,613 iteration 4305 : loss : 0.022442, loss_ce: 0.006605
2022-01-08 12:57:23,198 iteration 4306 : loss : 0.017196, loss_ce: 0.005525
2022-01-08 12:57:25,649 iteration 4307 : loss : 0.030379, loss_ce: 0.010611
2022-01-08 12:57:27,972 iteration 4308 : loss : 0.017361, loss_ce: 0.006287
2022-01-08 12:57:30,272 iteration 4309 : loss : 0.019909, loss_ce: 0.006814
2022-01-08 12:57:32,463 iteration 4310 : loss : 0.017971, loss_ce: 0.006352
2022-01-08 12:57:34,876 iteration 4311 : loss : 0.038374, loss_ce: 0.015111
2022-01-08 12:57:37,203 iteration 4312 : loss : 0.027768, loss_ce: 0.015970
2022-01-08 12:57:39,593 iteration 4313 : loss : 0.024457, loss_ce: 0.011346
2022-01-08 12:57:41,936 iteration 4314 : loss : 0.020921, loss_ce: 0.006912
2022-01-08 12:57:44,260 iteration 4315 : loss : 0.015303, loss_ce: 0.005825
2022-01-08 12:57:46,776 iteration 4316 : loss : 0.021035, loss_ce: 0.008264
2022-01-08 12:57:49,164 iteration 4317 : loss : 0.016067, loss_ce: 0.006860
2022-01-08 12:57:51,562 iteration 4318 : loss : 0.022989, loss_ce: 0.008417
 64%|█████████████████▏         | 254/400 [3:04:06<1:41:58, 41.91s/it]2022-01-08 12:57:53,911 iteration 4319 : loss : 0.019563, loss_ce: 0.007506
2022-01-08 12:57:56,379 iteration 4320 : loss : 0.023635, loss_ce: 0.010405
2022-01-08 12:57:58,887 iteration 4321 : loss : 0.023718, loss_ce: 0.011537
2022-01-08 12:58:01,225 iteration 4322 : loss : 0.024123, loss_ce: 0.009611
2022-01-08 12:58:03,491 iteration 4323 : loss : 0.024971, loss_ce: 0.008252
2022-01-08 12:58:05,798 iteration 4324 : loss : 0.014327, loss_ce: 0.006082
2022-01-08 12:58:08,101 iteration 4325 : loss : 0.017078, loss_ce: 0.005600
2022-01-08 12:58:10,475 iteration 4326 : loss : 0.023502, loss_ce: 0.007672
2022-01-08 12:58:12,937 iteration 4327 : loss : 0.023754, loss_ce: 0.010754
2022-01-08 12:58:15,322 iteration 4328 : loss : 0.016799, loss_ce: 0.007410
2022-01-08 12:58:17,675 iteration 4329 : loss : 0.017543, loss_ce: 0.006912
2022-01-08 12:58:19,974 iteration 4330 : loss : 0.016248, loss_ce: 0.007301
2022-01-08 12:58:22,465 iteration 4331 : loss : 0.016563, loss_ce: 0.006564
2022-01-08 12:58:24,842 iteration 4332 : loss : 0.015793, loss_ce: 0.005749
2022-01-08 12:58:27,156 iteration 4333 : loss : 0.014465, loss_ce: 0.005955
2022-01-08 12:58:29,561 iteration 4334 : loss : 0.013645, loss_ce: 0.004765
2022-01-08 12:58:29,561 Training Data Eval:
2022-01-08 12:58:42,308   Average segmentation loss on training set: 0.0108
2022-01-08 12:58:42,309 Validation Data Eval:
2022-01-08 12:58:46,817   Average segmentation loss on validation set: 0.0634
2022-01-08 12:58:49,227 iteration 4335 : loss : 0.031192, loss_ce: 0.007101
 64%|█████████████████▏         | 255/400 [3:05:03<1:52:41, 46.63s/it]2022-01-08 12:58:51,627 iteration 4336 : loss : 0.015746, loss_ce: 0.006375
2022-01-08 12:58:54,067 iteration 4337 : loss : 0.018401, loss_ce: 0.007530
2022-01-08 12:58:56,436 iteration 4338 : loss : 0.024141, loss_ce: 0.008828
2022-01-08 12:58:58,726 iteration 4339 : loss : 0.019012, loss_ce: 0.004586
2022-01-08 12:59:01,058 iteration 4340 : loss : 0.033166, loss_ce: 0.005320
2022-01-08 12:59:03,383 iteration 4341 : loss : 0.017279, loss_ce: 0.006753
2022-01-08 12:59:05,687 iteration 4342 : loss : 0.019017, loss_ce: 0.007250
2022-01-08 12:59:08,136 iteration 4343 : loss : 0.035870, loss_ce: 0.010491
2022-01-08 12:59:10,439 iteration 4344 : loss : 0.018979, loss_ce: 0.006988
2022-01-08 12:59:12,795 iteration 4345 : loss : 0.016788, loss_ce: 0.006727
2022-01-08 12:59:15,247 iteration 4346 : loss : 0.012941, loss_ce: 0.004327
2022-01-08 12:59:17,688 iteration 4347 : loss : 0.034663, loss_ce: 0.009889
2022-01-08 12:59:20,089 iteration 4348 : loss : 0.018471, loss_ce: 0.007739
2022-01-08 12:59:22,400 iteration 4349 : loss : 0.015991, loss_ce: 0.006475
2022-01-08 12:59:24,669 iteration 4350 : loss : 0.016802, loss_ce: 0.005323
2022-01-08 12:59:27,045 iteration 4351 : loss : 0.027686, loss_ce: 0.012358
2022-01-08 12:59:29,500 iteration 4352 : loss : 0.021710, loss_ce: 0.008439
 64%|█████████████████▎         | 256/400 [3:05:44<1:47:20, 44.72s/it]2022-01-08 12:59:31,885 iteration 4353 : loss : 0.015400, loss_ce: 0.005709
2022-01-08 12:59:34,293 iteration 4354 : loss : 0.019808, loss_ce: 0.005148
2022-01-08 12:59:36,694 iteration 4355 : loss : 0.017338, loss_ce: 0.005650
2022-01-08 12:59:39,041 iteration 4356 : loss : 0.023697, loss_ce: 0.008286
2022-01-08 12:59:41,495 iteration 4357 : loss : 0.021989, loss_ce: 0.008461
2022-01-08 12:59:43,809 iteration 4358 : loss : 0.019528, loss_ce: 0.007736
2022-01-08 12:59:46,146 iteration 4359 : loss : 0.020102, loss_ce: 0.005884
2022-01-08 12:59:48,469 iteration 4360 : loss : 0.015830, loss_ce: 0.006389
2022-01-08 12:59:50,914 iteration 4361 : loss : 0.033966, loss_ce: 0.012868
2022-01-08 12:59:53,273 iteration 4362 : loss : 0.016686, loss_ce: 0.005303
2022-01-08 12:59:55,686 iteration 4363 : loss : 0.017355, loss_ce: 0.006558
2022-01-08 12:59:58,024 iteration 4364 : loss : 0.015413, loss_ce: 0.006574
2022-01-08 13:00:00,489 iteration 4365 : loss : 0.019970, loss_ce: 0.007335
2022-01-08 13:00:02,824 iteration 4366 : loss : 0.015681, loss_ce: 0.006136
2022-01-08 13:00:05,097 iteration 4367 : loss : 0.016868, loss_ce: 0.007134
2022-01-08 13:00:07,378 iteration 4368 : loss : 0.011424, loss_ce: 0.004114
2022-01-08 13:00:09,801 iteration 4369 : loss : 0.031955, loss_ce: 0.015680
 64%|█████████████████▎         | 257/400 [3:06:24<1:43:25, 43.39s/it]2022-01-08 13:00:12,206 iteration 4370 : loss : 0.017117, loss_ce: 0.006209
2022-01-08 13:00:14,753 iteration 4371 : loss : 0.026423, loss_ce: 0.011454
2022-01-08 13:00:17,113 iteration 4372 : loss : 0.027693, loss_ce: 0.007200
2022-01-08 13:00:19,460 iteration 4373 : loss : 0.031067, loss_ce: 0.012638
2022-01-08 13:00:21,890 iteration 4374 : loss : 0.014572, loss_ce: 0.005531
2022-01-08 13:00:24,279 iteration 4375 : loss : 0.014003, loss_ce: 0.005824
2022-01-08 13:00:26,657 iteration 4376 : loss : 0.021686, loss_ce: 0.008245
2022-01-08 13:00:28,999 iteration 4377 : loss : 0.018788, loss_ce: 0.006987
2022-01-08 13:00:31,358 iteration 4378 : loss : 0.016334, loss_ce: 0.007362
2022-01-08 13:00:33,707 iteration 4379 : loss : 0.019593, loss_ce: 0.007578
2022-01-08 13:00:36,047 iteration 4380 : loss : 0.016994, loss_ce: 0.006109
2022-01-08 13:00:38,348 iteration 4381 : loss : 0.039851, loss_ce: 0.011072
2022-01-08 13:00:40,812 iteration 4382 : loss : 0.037152, loss_ce: 0.012409
2022-01-08 13:00:43,203 iteration 4383 : loss : 0.017689, loss_ce: 0.006124
2022-01-08 13:00:45,640 iteration 4384 : loss : 0.019406, loss_ce: 0.006487
2022-01-08 13:00:48,093 iteration 4385 : loss : 0.021962, loss_ce: 0.010377
2022-01-08 13:00:50,492 iteration 4386 : loss : 0.017106, loss_ce: 0.004507
 64%|█████████████████▍         | 258/400 [3:07:05<1:40:47, 42.59s/it]2022-01-08 13:00:52,988 iteration 4387 : loss : 0.024694, loss_ce: 0.006242
2022-01-08 13:00:55,373 iteration 4388 : loss : 0.022306, loss_ce: 0.010869
2022-01-08 13:00:57,777 iteration 4389 : loss : 0.019635, loss_ce: 0.008514
2022-01-08 13:01:00,119 iteration 4390 : loss : 0.018436, loss_ce: 0.008116
2022-01-08 13:01:02,417 iteration 4391 : loss : 0.025810, loss_ce: 0.008941
2022-01-08 13:01:04,601 iteration 4392 : loss : 0.015278, loss_ce: 0.006186
2022-01-08 13:01:06,856 iteration 4393 : loss : 0.018331, loss_ce: 0.007568
2022-01-08 13:01:09,075 iteration 4394 : loss : 0.015462, loss_ce: 0.005554
2022-01-08 13:01:11,463 iteration 4395 : loss : 0.013481, loss_ce: 0.005912
2022-01-08 13:01:13,766 iteration 4396 : loss : 0.031109, loss_ce: 0.013969
2022-01-08 13:01:15,991 iteration 4397 : loss : 0.013055, loss_ce: 0.004153
2022-01-08 13:01:18,265 iteration 4398 : loss : 0.023771, loss_ce: 0.008318
2022-01-08 13:01:20,541 iteration 4399 : loss : 0.018697, loss_ce: 0.005239
2022-01-08 13:01:22,790 iteration 4400 : loss : 0.016566, loss_ce: 0.004831
2022-01-08 13:01:25,246 iteration 4401 : loss : 0.020106, loss_ce: 0.010760
2022-01-08 13:01:27,592 iteration 4402 : loss : 0.022375, loss_ce: 0.006171
2022-01-08 13:01:29,985 iteration 4403 : loss : 0.020850, loss_ce: 0.006020
 65%|█████████████████▍         | 259/400 [3:07:44<1:37:54, 41.66s/it]2022-01-08 13:01:32,398 iteration 4404 : loss : 0.023924, loss_ce: 0.010774
2022-01-08 13:01:34,657 iteration 4405 : loss : 0.019388, loss_ce: 0.006798
2022-01-08 13:01:36,945 iteration 4406 : loss : 0.015793, loss_ce: 0.006489
2022-01-08 13:01:39,344 iteration 4407 : loss : 0.026542, loss_ce: 0.006099
2022-01-08 13:01:41,655 iteration 4408 : loss : 0.019850, loss_ce: 0.010302
2022-01-08 13:01:43,928 iteration 4409 : loss : 0.018967, loss_ce: 0.006741
2022-01-08 13:01:46,359 iteration 4410 : loss : 0.030788, loss_ce: 0.011819
2022-01-08 13:01:48,730 iteration 4411 : loss : 0.028203, loss_ce: 0.009061
2022-01-08 13:01:51,095 iteration 4412 : loss : 0.016414, loss_ce: 0.005598
2022-01-08 13:01:53,450 iteration 4413 : loss : 0.015528, loss_ce: 0.006690
2022-01-08 13:01:55,737 iteration 4414 : loss : 0.021714, loss_ce: 0.006487
2022-01-08 13:01:58,023 iteration 4415 : loss : 0.015741, loss_ce: 0.007227
2022-01-08 13:02:00,359 iteration 4416 : loss : 0.021540, loss_ce: 0.008516
2022-01-08 13:02:02,964 iteration 4417 : loss : 0.018571, loss_ce: 0.008298
2022-01-08 13:02:05,364 iteration 4418 : loss : 0.016206, loss_ce: 0.006351
2022-01-08 13:02:07,876 iteration 4419 : loss : 0.015700, loss_ce: 0.005461
2022-01-08 13:02:07,877 Training Data Eval:
2022-01-08 13:02:20,579   Average segmentation loss on training set: 0.0128
2022-01-08 13:02:20,580 Validation Data Eval:
2022-01-08 13:02:24,958   Average segmentation loss on validation set: 0.0776
2022-01-08 13:02:27,502 iteration 4420 : loss : 0.015249, loss_ce: 0.004359
 65%|█████████████████▌         | 260/400 [3:08:42<1:48:18, 46.42s/it]2022-01-08 13:02:29,942 iteration 4421 : loss : 0.023507, loss_ce: 0.006786
2022-01-08 13:02:32,223 iteration 4422 : loss : 0.017067, loss_ce: 0.005430
2022-01-08 13:02:34,540 iteration 4423 : loss : 0.017018, loss_ce: 0.005552
2022-01-08 13:02:36,961 iteration 4424 : loss : 0.020393, loss_ce: 0.008093
2022-01-08 13:02:39,310 iteration 4425 : loss : 0.032090, loss_ce: 0.017093
2022-01-08 13:02:41,676 iteration 4426 : loss : 0.026746, loss_ce: 0.006510
2022-01-08 13:02:44,039 iteration 4427 : loss : 0.024488, loss_ce: 0.011530
2022-01-08 13:02:46,437 iteration 4428 : loss : 0.020762, loss_ce: 0.008674
2022-01-08 13:02:48,711 iteration 4429 : loss : 0.017249, loss_ce: 0.007035
2022-01-08 13:02:51,288 iteration 4430 : loss : 0.043255, loss_ce: 0.021347
2022-01-08 13:02:53,720 iteration 4431 : loss : 0.028671, loss_ce: 0.010049
2022-01-08 13:02:56,085 iteration 4432 : loss : 0.026321, loss_ce: 0.010240
2022-01-08 13:02:58,380 iteration 4433 : loss : 0.024982, loss_ce: 0.007244
2022-01-08 13:03:00,745 iteration 4434 : loss : 0.020715, loss_ce: 0.008102
2022-01-08 13:03:03,035 iteration 4435 : loss : 0.015463, loss_ce: 0.005169
2022-01-08 13:03:05,329 iteration 4436 : loss : 0.017345, loss_ce: 0.008589
2022-01-08 13:03:07,692 iteration 4437 : loss : 0.015238, loss_ce: 0.005176
 65%|█████████████████▌         | 261/400 [3:09:22<1:43:12, 44.55s/it]2022-01-08 13:03:10,148 iteration 4438 : loss : 0.022214, loss_ce: 0.007744
2022-01-08 13:03:12,403 iteration 4439 : loss : 0.017084, loss_ce: 0.007580
2022-01-08 13:03:14,812 iteration 4440 : loss : 0.021110, loss_ce: 0.011198
2022-01-08 13:03:17,235 iteration 4441 : loss : 0.020216, loss_ce: 0.007560
2022-01-08 13:03:19,682 iteration 4442 : loss : 0.021405, loss_ce: 0.007860
2022-01-08 13:03:22,112 iteration 4443 : loss : 0.020764, loss_ce: 0.008260
2022-01-08 13:03:24,445 iteration 4444 : loss : 0.018726, loss_ce: 0.007565
2022-01-08 13:03:26,807 iteration 4445 : loss : 0.019667, loss_ce: 0.006796
2022-01-08 13:03:29,407 iteration 4446 : loss : 0.032046, loss_ce: 0.006103
2022-01-08 13:03:31,881 iteration 4447 : loss : 0.018888, loss_ce: 0.006118
2022-01-08 13:03:34,212 iteration 4448 : loss : 0.024973, loss_ce: 0.009297
2022-01-08 13:03:36,674 iteration 4449 : loss : 0.020429, loss_ce: 0.008957
2022-01-08 13:03:39,039 iteration 4450 : loss : 0.020777, loss_ce: 0.013458
2022-01-08 13:03:41,500 iteration 4451 : loss : 0.015062, loss_ce: 0.005313
2022-01-08 13:03:43,872 iteration 4452 : loss : 0.022744, loss_ce: 0.007394
2022-01-08 13:03:46,200 iteration 4453 : loss : 0.016065, loss_ce: 0.006353
2022-01-08 13:03:48,741 iteration 4454 : loss : 0.016630, loss_ce: 0.006385
 66%|█████████████████▋         | 262/400 [3:10:03<1:40:02, 43.49s/it]2022-01-08 13:03:51,184 iteration 4455 : loss : 0.020007, loss_ce: 0.006854
2022-01-08 13:03:53,491 iteration 4456 : loss : 0.016595, loss_ce: 0.005750
2022-01-08 13:03:55,836 iteration 4457 : loss : 0.017876, loss_ce: 0.007371
2022-01-08 13:03:58,142 iteration 4458 : loss : 0.016308, loss_ce: 0.006615
2022-01-08 13:04:00,521 iteration 4459 : loss : 0.026223, loss_ce: 0.008164
2022-01-08 13:04:03,002 iteration 4460 : loss : 0.013873, loss_ce: 0.005363
2022-01-08 13:04:05,396 iteration 4461 : loss : 0.018816, loss_ce: 0.008232
2022-01-08 13:04:07,855 iteration 4462 : loss : 0.021597, loss_ce: 0.007216
2022-01-08 13:04:10,138 iteration 4463 : loss : 0.014758, loss_ce: 0.005269
2022-01-08 13:04:12,497 iteration 4464 : loss : 0.013026, loss_ce: 0.005584
2022-01-08 13:04:14,981 iteration 4465 : loss : 0.051897, loss_ce: 0.009938
2022-01-08 13:04:17,328 iteration 4466 : loss : 0.013505, loss_ce: 0.004948
2022-01-08 13:04:19,749 iteration 4467 : loss : 0.026499, loss_ce: 0.011159
2022-01-08 13:04:22,271 iteration 4468 : loss : 0.020379, loss_ce: 0.007041
2022-01-08 13:04:24,639 iteration 4469 : loss : 0.013793, loss_ce: 0.003848
2022-01-08 13:04:26,998 iteration 4470 : loss : 0.029600, loss_ce: 0.016185
2022-01-08 13:04:29,558 iteration 4471 : loss : 0.029698, loss_ce: 0.008335
 66%|█████████████████▊         | 263/400 [3:10:44<1:37:29, 42.69s/it]2022-01-08 13:04:32,020 iteration 4472 : loss : 0.018593, loss_ce: 0.008071
2022-01-08 13:04:34,432 iteration 4473 : loss : 0.020856, loss_ce: 0.009089
2022-01-08 13:04:36,834 iteration 4474 : loss : 0.022729, loss_ce: 0.011054
2022-01-08 13:04:39,087 iteration 4475 : loss : 0.019165, loss_ce: 0.009498
2022-01-08 13:04:41,365 iteration 4476 : loss : 0.029893, loss_ce: 0.011022
2022-01-08 13:04:43,719 iteration 4477 : loss : 0.023962, loss_ce: 0.011360
2022-01-08 13:04:46,197 iteration 4478 : loss : 0.026264, loss_ce: 0.012430
2022-01-08 13:04:48,528 iteration 4479 : loss : 0.019908, loss_ce: 0.009228
2022-01-08 13:04:51,033 iteration 4480 : loss : 0.015210, loss_ce: 0.006077
2022-01-08 13:04:53,473 iteration 4481 : loss : 0.024900, loss_ce: 0.006235
2022-01-08 13:04:55,801 iteration 4482 : loss : 0.015541, loss_ce: 0.005056
2022-01-08 13:04:58,171 iteration 4483 : loss : 0.019009, loss_ce: 0.004988
2022-01-08 13:05:00,611 iteration 4484 : loss : 0.043527, loss_ce: 0.012969
2022-01-08 13:05:03,056 iteration 4485 : loss : 0.023639, loss_ce: 0.011314
2022-01-08 13:05:05,515 iteration 4486 : loss : 0.021599, loss_ce: 0.008178
2022-01-08 13:05:07,868 iteration 4487 : loss : 0.016853, loss_ce: 0.004621
2022-01-08 13:05:10,284 iteration 4488 : loss : 0.021008, loss_ce: 0.008071
 66%|█████████████████▊         | 264/400 [3:11:25<1:35:26, 42.10s/it]2022-01-08 13:05:12,769 iteration 4489 : loss : 0.022832, loss_ce: 0.009600
2022-01-08 13:05:15,021 iteration 4490 : loss : 0.017660, loss_ce: 0.010381
2022-01-08 13:05:17,363 iteration 4491 : loss : 0.030736, loss_ce: 0.012794
2022-01-08 13:05:19,747 iteration 4492 : loss : 0.018070, loss_ce: 0.008270
2022-01-08 13:05:22,068 iteration 4493 : loss : 0.020862, loss_ce: 0.007650
2022-01-08 13:05:24,352 iteration 4494 : loss : 0.029894, loss_ce: 0.012513
2022-01-08 13:05:26,640 iteration 4495 : loss : 0.045093, loss_ce: 0.016087
2022-01-08 13:05:28,925 iteration 4496 : loss : 0.014529, loss_ce: 0.006808
2022-01-08 13:05:31,313 iteration 4497 : loss : 0.021301, loss_ce: 0.009219
2022-01-08 13:05:33,669 iteration 4498 : loss : 0.025501, loss_ce: 0.008713
2022-01-08 13:05:36,064 iteration 4499 : loss : 0.030868, loss_ce: 0.012518
2022-01-08 13:05:38,456 iteration 4500 : loss : 0.013133, loss_ce: 0.004451
2022-01-08 13:05:40,830 iteration 4501 : loss : 0.017965, loss_ce: 0.006125
2022-01-08 13:05:43,177 iteration 4502 : loss : 0.018283, loss_ce: 0.005273
2022-01-08 13:05:45,547 iteration 4503 : loss : 0.024010, loss_ce: 0.010789
2022-01-08 13:05:47,902 iteration 4504 : loss : 0.020484, loss_ce: 0.008519
2022-01-08 13:05:47,902 Training Data Eval:
2022-01-08 13:06:00,676   Average segmentation loss on training set: 0.0152
2022-01-08 13:06:00,677 Validation Data Eval:
2022-01-08 13:06:05,163   Average segmentation loss on validation set: 0.1013
2022-01-08 13:06:07,574 iteration 4505 : loss : 0.018176, loss_ce: 0.007319
 66%|█████████████████▉         | 265/400 [3:12:22<1:44:59, 46.66s/it]2022-01-08 13:06:09,984 iteration 4506 : loss : 0.022411, loss_ce: 0.008984
2022-01-08 13:06:12,420 iteration 4507 : loss : 0.017107, loss_ce: 0.007881
2022-01-08 13:06:14,791 iteration 4508 : loss : 0.017685, loss_ce: 0.007081
2022-01-08 13:06:17,164 iteration 4509 : loss : 0.020522, loss_ce: 0.004552
2022-01-08 13:06:19,578 iteration 4510 : loss : 0.021308, loss_ce: 0.006248
2022-01-08 13:06:21,957 iteration 4511 : loss : 0.028592, loss_ce: 0.008473
2022-01-08 13:06:24,392 iteration 4512 : loss : 0.016555, loss_ce: 0.008019
2022-01-08 13:06:26,816 iteration 4513 : loss : 0.026985, loss_ce: 0.014450
2022-01-08 13:06:29,125 iteration 4514 : loss : 0.018061, loss_ce: 0.005068
2022-01-08 13:06:31,556 iteration 4515 : loss : 0.020700, loss_ce: 0.007475
2022-01-08 13:06:33,967 iteration 4516 : loss : 0.013028, loss_ce: 0.005429
2022-01-08 13:06:36,331 iteration 4517 : loss : 0.014739, loss_ce: 0.006057
2022-01-08 13:06:38,730 iteration 4518 : loss : 0.019941, loss_ce: 0.006378
2022-01-08 13:06:41,061 iteration 4519 : loss : 0.016671, loss_ce: 0.005527
2022-01-08 13:06:43,474 iteration 4520 : loss : 0.031465, loss_ce: 0.013355
2022-01-08 13:06:45,826 iteration 4521 : loss : 0.019452, loss_ce: 0.007789
2022-01-08 13:06:48,293 iteration 4522 : loss : 0.022295, loss_ce: 0.008251
 66%|█████████████████▉         | 266/400 [3:13:03<1:40:13, 44.88s/it]2022-01-08 13:06:50,802 iteration 4523 : loss : 0.029334, loss_ce: 0.017932
2022-01-08 13:06:53,208 iteration 4524 : loss : 0.019342, loss_ce: 0.007163
2022-01-08 13:06:55,540 iteration 4525 : loss : 0.015173, loss_ce: 0.007064
2022-01-08 13:06:57,909 iteration 4526 : loss : 0.018470, loss_ce: 0.005694
2022-01-08 13:07:00,290 iteration 4527 : loss : 0.013187, loss_ce: 0.005615
2022-01-08 13:07:02,676 iteration 4528 : loss : 0.014428, loss_ce: 0.005778
2022-01-08 13:07:05,019 iteration 4529 : loss : 0.016133, loss_ce: 0.005997
2022-01-08 13:07:07,525 iteration 4530 : loss : 0.017909, loss_ce: 0.007116
2022-01-08 13:07:10,001 iteration 4531 : loss : 0.022883, loss_ce: 0.007356
2022-01-08 13:07:12,265 iteration 4532 : loss : 0.012485, loss_ce: 0.004509
2022-01-08 13:07:14,707 iteration 4533 : loss : 0.025474, loss_ce: 0.008871
2022-01-08 13:07:16,982 iteration 4534 : loss : 0.013965, loss_ce: 0.006361
2022-01-08 13:07:19,380 iteration 4535 : loss : 0.023955, loss_ce: 0.010677
2022-01-08 13:07:21,777 iteration 4536 : loss : 0.020565, loss_ce: 0.005926
2022-01-08 13:07:24,051 iteration 4537 : loss : 0.027766, loss_ce: 0.007551
2022-01-08 13:07:26,387 iteration 4538 : loss : 0.014070, loss_ce: 0.005570
2022-01-08 13:07:28,658 iteration 4539 : loss : 0.014048, loss_ce: 0.004864
 67%|██████████████████         | 267/400 [3:13:43<1:36:28, 43.52s/it]2022-01-08 13:07:31,019 iteration 4540 : loss : 0.014293, loss_ce: 0.006024
2022-01-08 13:07:33,363 iteration 4541 : loss : 0.016057, loss_ce: 0.006228
2022-01-08 13:07:35,771 iteration 4542 : loss : 0.019051, loss_ce: 0.005321
2022-01-08 13:07:38,303 iteration 4543 : loss : 0.021646, loss_ce: 0.007633
2022-01-08 13:07:40,584 iteration 4544 : loss : 0.016840, loss_ce: 0.007734
2022-01-08 13:07:42,841 iteration 4545 : loss : 0.012045, loss_ce: 0.004516
2022-01-08 13:07:45,285 iteration 4546 : loss : 0.025361, loss_ce: 0.009198
2022-01-08 13:07:47,758 iteration 4547 : loss : 0.018461, loss_ce: 0.006522
2022-01-08 13:07:50,106 iteration 4548 : loss : 0.017750, loss_ce: 0.007634
2022-01-08 13:07:52,431 iteration 4549 : loss : 0.018883, loss_ce: 0.004940
2022-01-08 13:07:54,894 iteration 4550 : loss : 0.016591, loss_ce: 0.005353
2022-01-08 13:07:57,271 iteration 4551 : loss : 0.023183, loss_ce: 0.007193
2022-01-08 13:07:59,531 iteration 4552 : loss : 0.017561, loss_ce: 0.005318
2022-01-08 13:08:01,847 iteration 4553 : loss : 0.019929, loss_ce: 0.007290
2022-01-08 13:08:04,449 iteration 4554 : loss : 0.035085, loss_ce: 0.009779
2022-01-08 13:08:06,815 iteration 4555 : loss : 0.020890, loss_ce: 0.007263
2022-01-08 13:08:09,154 iteration 4556 : loss : 0.020028, loss_ce: 0.008433
 67%|██████████████████         | 268/400 [3:14:23<1:33:44, 42.61s/it]2022-01-08 13:08:11,568 iteration 4557 : loss : 0.012309, loss_ce: 0.005890
2022-01-08 13:08:13,998 iteration 4558 : loss : 0.020788, loss_ce: 0.009718
2022-01-08 13:08:16,377 iteration 4559 : loss : 0.019387, loss_ce: 0.006028
2022-01-08 13:08:18,905 iteration 4560 : loss : 0.021246, loss_ce: 0.006141
2022-01-08 13:08:21,332 iteration 4561 : loss : 0.028065, loss_ce: 0.007082
2022-01-08 13:08:23,632 iteration 4562 : loss : 0.020686, loss_ce: 0.005999
2022-01-08 13:08:25,955 iteration 4563 : loss : 0.015787, loss_ce: 0.006795
2022-01-08 13:08:28,392 iteration 4564 : loss : 0.026264, loss_ce: 0.010422
2022-01-08 13:08:30,847 iteration 4565 : loss : 0.022991, loss_ce: 0.007670
2022-01-08 13:08:33,314 iteration 4566 : loss : 0.026053, loss_ce: 0.011088
2022-01-08 13:08:35,817 iteration 4567 : loss : 0.017997, loss_ce: 0.006891
2022-01-08 13:08:38,189 iteration 4568 : loss : 0.018687, loss_ce: 0.005890
2022-01-08 13:08:40,555 iteration 4569 : loss : 0.034385, loss_ce: 0.007895
2022-01-08 13:08:42,920 iteration 4570 : loss : 0.028075, loss_ce: 0.012630
2022-01-08 13:08:45,243 iteration 4571 : loss : 0.020540, loss_ce: 0.008185
2022-01-08 13:08:47,514 iteration 4572 : loss : 0.016334, loss_ce: 0.005978
2022-01-08 13:08:49,946 iteration 4573 : loss : 0.023640, loss_ce: 0.011518
 67%|██████████████████▏        | 269/400 [3:15:04<1:31:51, 42.07s/it]2022-01-08 13:08:52,506 iteration 4574 : loss : 0.016152, loss_ce: 0.006842
2022-01-08 13:08:54,943 iteration 4575 : loss : 0.021020, loss_ce: 0.006220
2022-01-08 13:08:57,373 iteration 4576 : loss : 0.027229, loss_ce: 0.010004
2022-01-08 13:08:59,738 iteration 4577 : loss : 0.019423, loss_ce: 0.006143
2022-01-08 13:09:01,973 iteration 4578 : loss : 0.020910, loss_ce: 0.008308
2022-01-08 13:09:04,394 iteration 4579 : loss : 0.016431, loss_ce: 0.006336
2022-01-08 13:09:06,744 iteration 4580 : loss : 0.021056, loss_ce: 0.010127
2022-01-08 13:09:09,059 iteration 4581 : loss : 0.019528, loss_ce: 0.007893
2022-01-08 13:09:11,388 iteration 4582 : loss : 0.015974, loss_ce: 0.006889
2022-01-08 13:09:13,886 iteration 4583 : loss : 0.040397, loss_ce: 0.008849
2022-01-08 13:09:16,305 iteration 4584 : loss : 0.026609, loss_ce: 0.006981
2022-01-08 13:09:18,807 iteration 4585 : loss : 0.013046, loss_ce: 0.004217
2022-01-08 13:09:21,207 iteration 4586 : loss : 0.013399, loss_ce: 0.005870
2022-01-08 13:09:23,499 iteration 4587 : loss : 0.018299, loss_ce: 0.006929
2022-01-08 13:09:25,772 iteration 4588 : loss : 0.020241, loss_ce: 0.007753
2022-01-08 13:09:27,959 iteration 4589 : loss : 0.017756, loss_ce: 0.007886
2022-01-08 13:09:27,959 Training Data Eval:
2022-01-08 13:09:40,065   Average segmentation loss on training set: 0.0110
2022-01-08 13:09:40,066 Validation Data Eval:
2022-01-08 13:09:44,545   Average segmentation loss on validation set: 0.0716
2022-01-08 13:09:46,970 iteration 4590 : loss : 0.020036, loss_ce: 0.010048
 68%|██████████████████▏        | 270/400 [3:16:01<1:40:52, 46.56s/it]2022-01-08 13:09:49,539 iteration 4591 : loss : 0.024175, loss_ce: 0.009035
2022-01-08 13:09:51,920 iteration 4592 : loss : 0.016879, loss_ce: 0.007543
2022-01-08 13:09:54,219 iteration 4593 : loss : 0.022953, loss_ce: 0.007898
2022-01-08 13:09:56,492 iteration 4594 : loss : 0.021207, loss_ce: 0.007782
2022-01-08 13:09:58,750 iteration 4595 : loss : 0.013822, loss_ce: 0.005551
2022-01-08 13:10:01,160 iteration 4596 : loss : 0.021772, loss_ce: 0.009881
2022-01-08 13:10:03,401 iteration 4597 : loss : 0.029940, loss_ce: 0.007344
2022-01-08 13:10:05,691 iteration 4598 : loss : 0.016818, loss_ce: 0.004809
2022-01-08 13:10:08,073 iteration 4599 : loss : 0.020611, loss_ce: 0.009534
2022-01-08 13:10:10,424 iteration 4600 : loss : 0.018265, loss_ce: 0.006685
2022-01-08 13:10:12,726 iteration 4601 : loss : 0.020124, loss_ce: 0.009512
2022-01-08 13:10:15,095 iteration 4602 : loss : 0.020539, loss_ce: 0.007854
2022-01-08 13:10:17,470 iteration 4603 : loss : 0.021461, loss_ce: 0.006784
2022-01-08 13:10:19,732 iteration 4604 : loss : 0.015116, loss_ce: 0.005194
2022-01-08 13:10:22,034 iteration 4605 : loss : 0.017370, loss_ce: 0.004821
2022-01-08 13:10:24,418 iteration 4606 : loss : 0.015723, loss_ce: 0.005079
2022-01-08 13:10:26,806 iteration 4607 : loss : 0.025466, loss_ce: 0.009649
 68%|██████████████████▎        | 271/400 [3:16:41<1:35:45, 44.54s/it]2022-01-08 13:10:29,238 iteration 4608 : loss : 0.014484, loss_ce: 0.004767
2022-01-08 13:10:31,564 iteration 4609 : loss : 0.016670, loss_ce: 0.005530
2022-01-08 13:10:33,889 iteration 4610 : loss : 0.021680, loss_ce: 0.005207
2022-01-08 13:10:36,197 iteration 4611 : loss : 0.022854, loss_ce: 0.009742
2022-01-08 13:10:38,496 iteration 4612 : loss : 0.020006, loss_ce: 0.008329
2022-01-08 13:10:40,854 iteration 4613 : loss : 0.016888, loss_ce: 0.005784
2022-01-08 13:10:43,179 iteration 4614 : loss : 0.015151, loss_ce: 0.004523
2022-01-08 13:10:45,693 iteration 4615 : loss : 0.029490, loss_ce: 0.012505
2022-01-08 13:10:47,988 iteration 4616 : loss : 0.016463, loss_ce: 0.007411
2022-01-08 13:10:50,384 iteration 4617 : loss : 0.020875, loss_ce: 0.008411
2022-01-08 13:10:52,741 iteration 4618 : loss : 0.011319, loss_ce: 0.004314
2022-01-08 13:10:55,074 iteration 4619 : loss : 0.021888, loss_ce: 0.008412
2022-01-08 13:10:57,419 iteration 4620 : loss : 0.012994, loss_ce: 0.004884
2022-01-08 13:10:59,745 iteration 4621 : loss : 0.015910, loss_ce: 0.005629
2022-01-08 13:11:02,151 iteration 4622 : loss : 0.017170, loss_ce: 0.006603
2022-01-08 13:11:04,470 iteration 4623 : loss : 0.012948, loss_ce: 0.005202
2022-01-08 13:11:06,794 iteration 4624 : loss : 0.020450, loss_ce: 0.006327
 68%|██████████████████▎        | 272/400 [3:17:21<1:32:06, 43.17s/it]2022-01-08 13:11:09,267 iteration 4625 : loss : 0.018252, loss_ce: 0.005796
2022-01-08 13:11:11,596 iteration 4626 : loss : 0.028384, loss_ce: 0.008830
2022-01-08 13:11:13,886 iteration 4627 : loss : 0.024148, loss_ce: 0.012077
2022-01-08 13:11:16,187 iteration 4628 : loss : 0.017579, loss_ce: 0.005600
2022-01-08 13:11:18,519 iteration 4629 : loss : 0.023061, loss_ce: 0.003916
2022-01-08 13:11:20,914 iteration 4630 : loss : 0.016804, loss_ce: 0.009775
2022-01-08 13:11:23,219 iteration 4631 : loss : 0.020127, loss_ce: 0.007374
2022-01-08 13:11:25,561 iteration 4632 : loss : 0.017441, loss_ce: 0.005602
2022-01-08 13:11:27,976 iteration 4633 : loss : 0.016995, loss_ce: 0.006458
2022-01-08 13:11:30,477 iteration 4634 : loss : 0.020241, loss_ce: 0.009153
2022-01-08 13:11:32,775 iteration 4635 : loss : 0.012365, loss_ce: 0.004263
2022-01-08 13:11:35,077 iteration 4636 : loss : 0.011862, loss_ce: 0.004460
2022-01-08 13:11:37,376 iteration 4637 : loss : 0.022247, loss_ce: 0.007948
2022-01-08 13:11:39,670 iteration 4638 : loss : 0.019484, loss_ce: 0.011238
2022-01-08 13:11:41,995 iteration 4639 : loss : 0.017761, loss_ce: 0.006093
2022-01-08 13:11:44,335 iteration 4640 : loss : 0.022482, loss_ce: 0.009394
2022-01-08 13:11:46,688 iteration 4641 : loss : 0.020959, loss_ce: 0.007284
 68%|██████████████████▍        | 273/400 [3:18:01<1:29:18, 42.19s/it]2022-01-08 13:11:49,037 iteration 4642 : loss : 0.021320, loss_ce: 0.008194
2022-01-08 13:11:51,348 iteration 4643 : loss : 0.019133, loss_ce: 0.007838
2022-01-08 13:11:53,745 iteration 4644 : loss : 0.023908, loss_ce: 0.009285
2022-01-08 13:11:56,025 iteration 4645 : loss : 0.017301, loss_ce: 0.006501
2022-01-08 13:11:58,338 iteration 4646 : loss : 0.015954, loss_ce: 0.006406
2022-01-08 13:12:00,761 iteration 4647 : loss : 0.016286, loss_ce: 0.006795
2022-01-08 13:12:03,098 iteration 4648 : loss : 0.017391, loss_ce: 0.006999
2022-01-08 13:12:05,544 iteration 4649 : loss : 0.020698, loss_ce: 0.007727
2022-01-08 13:12:07,772 iteration 4650 : loss : 0.014013, loss_ce: 0.005599
2022-01-08 13:12:10,093 iteration 4651 : loss : 0.021711, loss_ce: 0.008515
2022-01-08 13:12:12,395 iteration 4652 : loss : 0.017512, loss_ce: 0.006176
2022-01-08 13:12:14,733 iteration 4653 : loss : 0.016176, loss_ce: 0.005996
2022-01-08 13:12:17,050 iteration 4654 : loss : 0.013528, loss_ce: 0.003868
2022-01-08 13:12:19,399 iteration 4655 : loss : 0.018084, loss_ce: 0.005710
2022-01-08 13:12:21,675 iteration 4656 : loss : 0.020216, loss_ce: 0.006123
2022-01-08 13:12:23,983 iteration 4657 : loss : 0.015937, loss_ce: 0.006801
2022-01-08 13:12:26,269 iteration 4658 : loss : 0.011011, loss_ce: 0.004247
 68%|██████████████████▍        | 274/400 [3:18:41<1:26:57, 41.41s/it]2022-01-08 13:12:28,680 iteration 4659 : loss : 0.021872, loss_ce: 0.009130
2022-01-08 13:12:30,951 iteration 4660 : loss : 0.013022, loss_ce: 0.005116
2022-01-08 13:12:33,299 iteration 4661 : loss : 0.018165, loss_ce: 0.007693
2022-01-08 13:12:35,784 iteration 4662 : loss : 0.011181, loss_ce: 0.005412
2022-01-08 13:12:38,243 iteration 4663 : loss : 0.017910, loss_ce: 0.006777
2022-01-08 13:12:40,580 iteration 4664 : loss : 0.014042, loss_ce: 0.004810
2022-01-08 13:12:42,821 iteration 4665 : loss : 0.018907, loss_ce: 0.008473
2022-01-08 13:12:45,081 iteration 4666 : loss : 0.015376, loss_ce: 0.006633
2022-01-08 13:12:47,325 iteration 4667 : loss : 0.027155, loss_ce: 0.008588
2022-01-08 13:12:49,550 iteration 4668 : loss : 0.012706, loss_ce: 0.005267
2022-01-08 13:12:51,884 iteration 4669 : loss : 0.017930, loss_ce: 0.006420
2022-01-08 13:12:54,270 iteration 4670 : loss : 0.026405, loss_ce: 0.006822
2022-01-08 13:12:56,624 iteration 4671 : loss : 0.013042, loss_ce: 0.004775
2022-01-08 13:12:59,028 iteration 4672 : loss : 0.011375, loss_ce: 0.003966
2022-01-08 13:13:01,355 iteration 4673 : loss : 0.012582, loss_ce: 0.004135
2022-01-08 13:13:03,735 iteration 4674 : loss : 0.014379, loss_ce: 0.003395
2022-01-08 13:13:03,735 Training Data Eval:
2022-01-08 13:13:16,220   Average segmentation loss on training set: 0.0101
2022-01-08 13:13:16,221 Validation Data Eval:
2022-01-08 13:13:20,557   Average segmentation loss on validation set: 0.0887
2022-01-08 13:13:22,910 iteration 4675 : loss : 0.012631, loss_ce: 0.004715
 69%|██████████████████▌        | 275/400 [3:19:37<1:35:47, 45.98s/it]2022-01-08 13:13:25,357 iteration 4676 : loss : 0.011980, loss_ce: 0.005008
2022-01-08 13:13:27,649 iteration 4677 : loss : 0.013387, loss_ce: 0.005684
2022-01-08 13:13:29,982 iteration 4678 : loss : 0.020846, loss_ce: 0.006862
2022-01-08 13:13:32,340 iteration 4679 : loss : 0.015861, loss_ce: 0.005966
2022-01-08 13:13:34,587 iteration 4680 : loss : 0.015473, loss_ce: 0.005753
2022-01-08 13:13:36,917 iteration 4681 : loss : 0.017633, loss_ce: 0.007825
2022-01-08 13:13:39,174 iteration 4682 : loss : 0.018041, loss_ce: 0.006911
2022-01-08 13:13:41,387 iteration 4683 : loss : 0.014477, loss_ce: 0.004599
2022-01-08 13:13:43,677 iteration 4684 : loss : 0.033948, loss_ce: 0.014693
2022-01-08 13:13:46,014 iteration 4685 : loss : 0.013807, loss_ce: 0.005840
2022-01-08 13:13:48,188 iteration 4686 : loss : 0.021463, loss_ce: 0.007088
2022-01-08 13:13:50,562 iteration 4687 : loss : 0.019636, loss_ce: 0.006023
2022-01-08 13:13:52,875 iteration 4688 : loss : 0.011141, loss_ce: 0.004813
2022-01-08 13:13:55,239 iteration 4689 : loss : 0.030996, loss_ce: 0.011881
2022-01-08 13:13:57,492 iteration 4690 : loss : 0.016530, loss_ce: 0.006880
2022-01-08 13:13:59,860 iteration 4691 : loss : 0.021605, loss_ce: 0.005225
2022-01-08 13:14:02,350 iteration 4692 : loss : 0.019727, loss_ce: 0.006403
 69%|██████████████████▋        | 276/400 [3:20:17<1:30:58, 44.02s/it]2022-01-08 13:14:04,715 iteration 4693 : loss : 0.013790, loss_ce: 0.005111
2022-01-08 13:14:07,171 iteration 4694 : loss : 0.017804, loss_ce: 0.004990
2022-01-08 13:14:09,582 iteration 4695 : loss : 0.019520, loss_ce: 0.006883
2022-01-08 13:14:12,024 iteration 4696 : loss : 0.023269, loss_ce: 0.007482
2022-01-08 13:14:14,355 iteration 4697 : loss : 0.017612, loss_ce: 0.007195
2022-01-08 13:14:16,753 iteration 4698 : loss : 0.015966, loss_ce: 0.006146
2022-01-08 13:14:19,113 iteration 4699 : loss : 0.015434, loss_ce: 0.004644
2022-01-08 13:14:21,416 iteration 4700 : loss : 0.017625, loss_ce: 0.006688
2022-01-08 13:14:23,696 iteration 4701 : loss : 0.014676, loss_ce: 0.004042
2022-01-08 13:14:26,091 iteration 4702 : loss : 0.019539, loss_ce: 0.006348
2022-01-08 13:14:28,367 iteration 4703 : loss : 0.031952, loss_ce: 0.017808
2022-01-08 13:14:30,689 iteration 4704 : loss : 0.021418, loss_ce: 0.005715
2022-01-08 13:14:33,087 iteration 4705 : loss : 0.028175, loss_ce: 0.008923
2022-01-08 13:14:35,347 iteration 4706 : loss : 0.020898, loss_ce: 0.007403
2022-01-08 13:14:37,699 iteration 4707 : loss : 0.018111, loss_ce: 0.005496
2022-01-08 13:14:40,036 iteration 4708 : loss : 0.019960, loss_ce: 0.008747
2022-01-08 13:14:42,307 iteration 4709 : loss : 0.020503, loss_ce: 0.007693
 69%|██████████████████▋        | 277/400 [3:20:57<1:27:43, 42.79s/it]2022-01-08 13:14:44,824 iteration 4710 : loss : 0.016238, loss_ce: 0.006613
2022-01-08 13:14:47,179 iteration 4711 : loss : 0.014065, loss_ce: 0.005300
2022-01-08 13:14:49,458 iteration 4712 : loss : 0.014860, loss_ce: 0.004798
2022-01-08 13:14:51,831 iteration 4713 : loss : 0.031513, loss_ce: 0.012124
2022-01-08 13:14:54,126 iteration 4714 : loss : 0.011610, loss_ce: 0.003581
2022-01-08 13:14:56,527 iteration 4715 : loss : 0.018365, loss_ce: 0.008926
2022-01-08 13:14:58,938 iteration 4716 : loss : 0.020647, loss_ce: 0.007771
2022-01-08 13:15:01,264 iteration 4717 : loss : 0.016813, loss_ce: 0.005576
2022-01-08 13:15:03,584 iteration 4718 : loss : 0.019905, loss_ce: 0.008221
2022-01-08 13:15:05,999 iteration 4719 : loss : 0.015550, loss_ce: 0.006247
2022-01-08 13:15:08,368 iteration 4720 : loss : 0.014168, loss_ce: 0.006827
2022-01-08 13:15:10,694 iteration 4721 : loss : 0.020737, loss_ce: 0.007733
2022-01-08 13:15:13,096 iteration 4722 : loss : 0.017987, loss_ce: 0.007330
2022-01-08 13:15:15,529 iteration 4723 : loss : 0.026736, loss_ce: 0.008614
2022-01-08 13:15:18,138 iteration 4724 : loss : 0.019221, loss_ce: 0.010687
2022-01-08 13:15:20,669 iteration 4725 : loss : 0.025288, loss_ce: 0.007762
2022-01-08 13:15:23,088 iteration 4726 : loss : 0.016663, loss_ce: 0.004666
 70%|██████████████████▊        | 278/400 [3:21:37<1:25:47, 42.20s/it]2022-01-08 13:15:25,457 iteration 4727 : loss : 0.017082, loss_ce: 0.006685
2022-01-08 13:15:27,811 iteration 4728 : loss : 0.015054, loss_ce: 0.005311
2022-01-08 13:15:30,190 iteration 4729 : loss : 0.015134, loss_ce: 0.004373
2022-01-08 13:15:32,560 iteration 4730 : loss : 0.027268, loss_ce: 0.011525
2022-01-08 13:15:34,960 iteration 4731 : loss : 0.023644, loss_ce: 0.006210
2022-01-08 13:15:37,424 iteration 4732 : loss : 0.015426, loss_ce: 0.006454
2022-01-08 13:15:39,746 iteration 4733 : loss : 0.014180, loss_ce: 0.004982
2022-01-08 13:15:42,098 iteration 4734 : loss : 0.015768, loss_ce: 0.005469
2022-01-08 13:15:44,542 iteration 4735 : loss : 0.023391, loss_ce: 0.010684
2022-01-08 13:15:46,876 iteration 4736 : loss : 0.015354, loss_ce: 0.005770
2022-01-08 13:15:49,299 iteration 4737 : loss : 0.019040, loss_ce: 0.006387
2022-01-08 13:15:51,781 iteration 4738 : loss : 0.040541, loss_ce: 0.006722
2022-01-08 13:15:54,143 iteration 4739 : loss : 0.014909, loss_ce: 0.005911
2022-01-08 13:15:56,529 iteration 4740 : loss : 0.015332, loss_ce: 0.006299
2022-01-08 13:15:58,988 iteration 4741 : loss : 0.018113, loss_ce: 0.010137
2022-01-08 13:16:01,309 iteration 4742 : loss : 0.015952, loss_ce: 0.005381
2022-01-08 13:16:03,692 iteration 4743 : loss : 0.015411, loss_ce: 0.004380
 70%|██████████████████▊        | 279/400 [3:22:18<1:24:07, 41.72s/it]2022-01-08 13:16:06,134 iteration 4744 : loss : 0.025097, loss_ce: 0.011144
2022-01-08 13:16:08,556 iteration 4745 : loss : 0.021365, loss_ce: 0.009595
2022-01-08 13:16:10,920 iteration 4746 : loss : 0.023980, loss_ce: 0.009104
2022-01-08 13:16:13,344 iteration 4747 : loss : 0.019582, loss_ce: 0.009966
2022-01-08 13:16:15,987 iteration 4748 : loss : 0.020400, loss_ce: 0.007919
2022-01-08 13:16:18,430 iteration 4749 : loss : 0.017142, loss_ce: 0.005824
2022-01-08 13:16:20,767 iteration 4750 : loss : 0.019197, loss_ce: 0.007369
2022-01-08 13:16:23,008 iteration 4751 : loss : 0.017841, loss_ce: 0.006508
2022-01-08 13:16:25,415 iteration 4752 : loss : 0.021320, loss_ce: 0.005123
2022-01-08 13:16:27,828 iteration 4753 : loss : 0.020096, loss_ce: 0.009416
2022-01-08 13:16:30,191 iteration 4754 : loss : 0.023021, loss_ce: 0.006352
2022-01-08 13:16:32,580 iteration 4755 : loss : 0.016843, loss_ce: 0.005654
2022-01-08 13:16:35,127 iteration 4756 : loss : 0.017795, loss_ce: 0.007454
2022-01-08 13:16:37,521 iteration 4757 : loss : 0.014227, loss_ce: 0.005944
2022-01-08 13:16:39,921 iteration 4758 : loss : 0.019481, loss_ce: 0.006418
2022-01-08 13:16:42,132 iteration 4759 : loss : 0.012472, loss_ce: 0.004813
2022-01-08 13:16:42,132 Training Data Eval:
2022-01-08 13:16:54,879   Average segmentation loss on training set: 0.0107
2022-01-08 13:16:54,879 Validation Data Eval:
2022-01-08 13:16:59,354   Average segmentation loss on validation set: 0.0723
2022-01-08 13:17:01,756 iteration 4760 : loss : 0.019800, loss_ce: 0.005956
 70%|██████████████████▉        | 280/400 [3:23:16<1:33:14, 46.62s/it]2022-01-08 13:17:04,181 iteration 4761 : loss : 0.016467, loss_ce: 0.008555
2022-01-08 13:17:06,553 iteration 4762 : loss : 0.016966, loss_ce: 0.005288
2022-01-08 13:17:08,880 iteration 4763 : loss : 0.018360, loss_ce: 0.005964
2022-01-08 13:17:11,269 iteration 4764 : loss : 0.018923, loss_ce: 0.006179
2022-01-08 13:17:13,734 iteration 4765 : loss : 0.014627, loss_ce: 0.005259
2022-01-08 13:17:16,211 iteration 4766 : loss : 0.021828, loss_ce: 0.005327
2022-01-08 13:17:18,679 iteration 4767 : loss : 0.022225, loss_ce: 0.011581
2022-01-08 13:17:20,996 iteration 4768 : loss : 0.020881, loss_ce: 0.008661
2022-01-08 13:17:23,238 iteration 4769 : loss : 0.014560, loss_ce: 0.005162
2022-01-08 13:17:25,617 iteration 4770 : loss : 0.019190, loss_ce: 0.009118
2022-01-08 13:17:28,028 iteration 4771 : loss : 0.023636, loss_ce: 0.008047
2022-01-08 13:17:30,539 iteration 4772 : loss : 0.015365, loss_ce: 0.006068
2022-01-08 13:17:32,846 iteration 4773 : loss : 0.012464, loss_ce: 0.005147
2022-01-08 13:17:35,225 iteration 4774 : loss : 0.019712, loss_ce: 0.006708
2022-01-08 13:17:37,499 iteration 4775 : loss : 0.015107, loss_ce: 0.005533
2022-01-08 13:17:40,016 iteration 4776 : loss : 0.018014, loss_ce: 0.005999
2022-01-08 13:17:42,413 iteration 4777 : loss : 0.013161, loss_ce: 0.003979
 70%|██████████████████▉        | 281/400 [3:23:57<1:28:54, 44.83s/it]2022-01-08 13:17:44,828 iteration 4778 : loss : 0.017315, loss_ce: 0.007483
2022-01-08 13:17:47,092 iteration 4779 : loss : 0.013390, loss_ce: 0.005785
2022-01-08 13:17:49,397 iteration 4780 : loss : 0.015386, loss_ce: 0.006280
2022-01-08 13:17:51,763 iteration 4781 : loss : 0.019109, loss_ce: 0.006772
2022-01-08 13:17:54,154 iteration 4782 : loss : 0.017328, loss_ce: 0.006004
2022-01-08 13:17:56,406 iteration 4783 : loss : 0.017444, loss_ce: 0.007795
2022-01-08 13:17:58,727 iteration 4784 : loss : 0.019567, loss_ce: 0.005944
2022-01-08 13:18:01,034 iteration 4785 : loss : 0.015167, loss_ce: 0.005164
2022-01-08 13:18:03,393 iteration 4786 : loss : 0.014229, loss_ce: 0.005474
2022-01-08 13:18:05,726 iteration 4787 : loss : 0.021471, loss_ce: 0.007032
2022-01-08 13:18:08,118 iteration 4788 : loss : 0.022619, loss_ce: 0.006374
2022-01-08 13:18:10,355 iteration 4789 : loss : 0.013235, loss_ce: 0.004780
2022-01-08 13:18:12,782 iteration 4790 : loss : 0.011762, loss_ce: 0.004424
2022-01-08 13:18:15,180 iteration 4791 : loss : 0.026225, loss_ce: 0.013121
2022-01-08 13:18:17,556 iteration 4792 : loss : 0.014929, loss_ce: 0.005328
2022-01-08 13:18:19,982 iteration 4793 : loss : 0.030982, loss_ce: 0.010315
2022-01-08 13:18:22,376 iteration 4794 : loss : 0.014195, loss_ce: 0.003771
 70%|███████████████████        | 282/400 [3:24:37<1:25:17, 43.37s/it]2022-01-08 13:18:24,855 iteration 4795 : loss : 0.023471, loss_ce: 0.007849
2022-01-08 13:18:27,255 iteration 4796 : loss : 0.013301, loss_ce: 0.003471
2022-01-08 13:18:29,620 iteration 4797 : loss : 0.012892, loss_ce: 0.004792
2022-01-08 13:18:31,960 iteration 4798 : loss : 0.020272, loss_ce: 0.008681
2022-01-08 13:18:34,313 iteration 4799 : loss : 0.020378, loss_ce: 0.004533
2022-01-08 13:18:36,678 iteration 4800 : loss : 0.017057, loss_ce: 0.006074
2022-01-08 13:18:39,106 iteration 4801 : loss : 0.015213, loss_ce: 0.006677
2022-01-08 13:18:41,572 iteration 4802 : loss : 0.015953, loss_ce: 0.006030
2022-01-08 13:18:43,956 iteration 4803 : loss : 0.012798, loss_ce: 0.004609
2022-01-08 13:18:46,367 iteration 4804 : loss : 0.013384, loss_ce: 0.004757
2022-01-08 13:18:48,994 iteration 4805 : loss : 0.021270, loss_ce: 0.008636
2022-01-08 13:18:51,415 iteration 4806 : loss : 0.020927, loss_ce: 0.004292
2022-01-08 13:18:53,760 iteration 4807 : loss : 0.013536, loss_ce: 0.004006
2022-01-08 13:18:56,205 iteration 4808 : loss : 0.017648, loss_ce: 0.006629
2022-01-08 13:18:58,494 iteration 4809 : loss : 0.013157, loss_ce: 0.006299
2022-01-08 13:19:00,790 iteration 4810 : loss : 0.016905, loss_ce: 0.006126
2022-01-08 13:19:03,215 iteration 4811 : loss : 0.025638, loss_ce: 0.009430
 71%|███████████████████        | 283/400 [3:25:17<1:23:05, 42.61s/it]2022-01-08 13:19:05,655 iteration 4812 : loss : 0.016687, loss_ce: 0.005213
2022-01-08 13:19:07,967 iteration 4813 : loss : 0.013485, loss_ce: 0.005960
2022-01-08 13:19:10,523 iteration 4814 : loss : 0.027152, loss_ce: 0.010701
2022-01-08 13:19:12,918 iteration 4815 : loss : 0.015562, loss_ce: 0.005581
2022-01-08 13:19:15,252 iteration 4816 : loss : 0.013748, loss_ce: 0.005261
2022-01-08 13:19:17,652 iteration 4817 : loss : 0.011666, loss_ce: 0.004565
2022-01-08 13:19:20,047 iteration 4818 : loss : 0.017619, loss_ce: 0.005857
2022-01-08 13:19:22,410 iteration 4819 : loss : 0.022310, loss_ce: 0.006766
2022-01-08 13:19:24,744 iteration 4820 : loss : 0.021660, loss_ce: 0.009247
2022-01-08 13:19:27,123 iteration 4821 : loss : 0.016000, loss_ce: 0.005924
2022-01-08 13:19:29,733 iteration 4822 : loss : 0.019324, loss_ce: 0.008277
2022-01-08 13:19:32,133 iteration 4823 : loss : 0.029867, loss_ce: 0.007996
2022-01-08 13:19:34,524 iteration 4824 : loss : 0.017940, loss_ce: 0.004856
2022-01-08 13:19:36,933 iteration 4825 : loss : 0.019545, loss_ce: 0.009811
2022-01-08 13:19:39,434 iteration 4826 : loss : 0.022790, loss_ce: 0.010154
2022-01-08 13:19:41,814 iteration 4827 : loss : 0.020190, loss_ce: 0.010613
2022-01-08 13:19:44,213 iteration 4828 : loss : 0.013890, loss_ce: 0.005024
 71%|███████████████████▏       | 284/400 [3:25:58<1:21:26, 42.12s/it]2022-01-08 13:19:46,650 iteration 4829 : loss : 0.012432, loss_ce: 0.006061
2022-01-08 13:19:49,032 iteration 4830 : loss : 0.018992, loss_ce: 0.008394
2022-01-08 13:19:51,359 iteration 4831 : loss : 0.019636, loss_ce: 0.010639
2022-01-08 13:19:53,609 iteration 4832 : loss : 0.013943, loss_ce: 0.005048
2022-01-08 13:19:55,749 iteration 4833 : loss : 0.016677, loss_ce: 0.008163
2022-01-08 13:19:57,977 iteration 4834 : loss : 0.015158, loss_ce: 0.005322
2022-01-08 13:20:00,116 iteration 4835 : loss : 0.020458, loss_ce: 0.008280
2022-01-08 13:20:02,334 iteration 4836 : loss : 0.018606, loss_ce: 0.005447
2022-01-08 13:20:04,687 iteration 4837 : loss : 0.018705, loss_ce: 0.005599
2022-01-08 13:20:07,003 iteration 4838 : loss : 0.025373, loss_ce: 0.011645
2022-01-08 13:20:09,170 iteration 4839 : loss : 0.013810, loss_ce: 0.005488
2022-01-08 13:20:11,526 iteration 4840 : loss : 0.015630, loss_ce: 0.005525
2022-01-08 13:20:13,930 iteration 4841 : loss : 0.013808, loss_ce: 0.005000
2022-01-08 13:20:16,300 iteration 4842 : loss : 0.019726, loss_ce: 0.007931
2022-01-08 13:20:18,589 iteration 4843 : loss : 0.014422, loss_ce: 0.004559
2022-01-08 13:20:20,965 iteration 4844 : loss : 0.016588, loss_ce: 0.005014
2022-01-08 13:20:20,966 Training Data Eval:
2022-01-08 13:20:33,457   Average segmentation loss on training set: 0.0106
2022-01-08 13:20:33,457 Validation Data Eval:
2022-01-08 13:20:37,941   Average segmentation loss on validation set: 0.0646
2022-01-08 13:20:40,332 iteration 4845 : loss : 0.015387, loss_ce: 0.005639
 71%|███████████████████▏       | 285/400 [3:26:55<1:28:47, 46.33s/it]2022-01-08 13:20:42,766 iteration 4846 : loss : 0.023377, loss_ce: 0.011952
2022-01-08 13:20:45,043 iteration 4847 : loss : 0.016478, loss_ce: 0.006628
2022-01-08 13:20:47,439 iteration 4848 : loss : 0.024576, loss_ce: 0.011348
2022-01-08 13:20:49,750 iteration 4849 : loss : 0.015069, loss_ce: 0.005412
2022-01-08 13:20:52,015 iteration 4850 : loss : 0.012430, loss_ce: 0.005673
2022-01-08 13:20:54,499 iteration 4851 : loss : 0.022601, loss_ce: 0.006762
2022-01-08 13:20:56,834 iteration 4852 : loss : 0.017817, loss_ce: 0.008693
2022-01-08 13:20:59,195 iteration 4853 : loss : 0.024734, loss_ce: 0.005256
2022-01-08 13:21:01,705 iteration 4854 : loss : 0.024517, loss_ce: 0.007343
2022-01-08 13:21:04,111 iteration 4855 : loss : 0.020863, loss_ce: 0.007248
2022-01-08 13:21:06,432 iteration 4856 : loss : 0.012964, loss_ce: 0.003953
2022-01-08 13:21:08,801 iteration 4857 : loss : 0.017532, loss_ce: 0.009722
2022-01-08 13:21:11,136 iteration 4858 : loss : 0.021460, loss_ce: 0.008991
2022-01-08 13:21:13,397 iteration 4859 : loss : 0.016667, loss_ce: 0.007985
2022-01-08 13:21:15,686 iteration 4860 : loss : 0.021287, loss_ce: 0.007449
2022-01-08 13:21:17,958 iteration 4861 : loss : 0.016646, loss_ce: 0.007106
2022-01-08 13:21:20,274 iteration 4862 : loss : 0.011709, loss_ce: 0.004587
 72%|███████████████████▎       | 286/400 [3:27:35<1:24:22, 44.41s/it]2022-01-08 13:21:22,608 iteration 4863 : loss : 0.013755, loss_ce: 0.004510
2022-01-08 13:21:24,943 iteration 4864 : loss : 0.019377, loss_ce: 0.006622
2022-01-08 13:21:27,300 iteration 4865 : loss : 0.025143, loss_ce: 0.006252
2022-01-08 13:21:29,583 iteration 4866 : loss : 0.015791, loss_ce: 0.006161
2022-01-08 13:21:31,892 iteration 4867 : loss : 0.016209, loss_ce: 0.006305
2022-01-08 13:21:34,135 iteration 4868 : loss : 0.018820, loss_ce: 0.008367
2022-01-08 13:21:36,480 iteration 4869 : loss : 0.019281, loss_ce: 0.007835
2022-01-08 13:21:38,867 iteration 4870 : loss : 0.022521, loss_ce: 0.007403
2022-01-08 13:21:41,197 iteration 4871 : loss : 0.014566, loss_ce: 0.005474
2022-01-08 13:21:43,460 iteration 4872 : loss : 0.019592, loss_ce: 0.007482
2022-01-08 13:21:45,755 iteration 4873 : loss : 0.015603, loss_ce: 0.005091
2022-01-08 13:21:48,089 iteration 4874 : loss : 0.012168, loss_ce: 0.005373
2022-01-08 13:21:50,478 iteration 4875 : loss : 0.013580, loss_ce: 0.004216
2022-01-08 13:21:52,772 iteration 4876 : loss : 0.017255, loss_ce: 0.005631
2022-01-08 13:21:55,219 iteration 4877 : loss : 0.019145, loss_ce: 0.007382
2022-01-08 13:21:57,548 iteration 4878 : loss : 0.017933, loss_ce: 0.005952
2022-01-08 13:21:59,959 iteration 4879 : loss : 0.017994, loss_ce: 0.007860
 72%|███████████████████▎       | 287/400 [3:28:14<1:20:58, 42.99s/it]2022-01-08 13:22:02,383 iteration 4880 : loss : 0.020089, loss_ce: 0.011676
2022-01-08 13:22:04,624 iteration 4881 : loss : 0.023566, loss_ce: 0.007078
2022-01-08 13:22:06,949 iteration 4882 : loss : 0.016735, loss_ce: 0.004088
2022-01-08 13:22:09,374 iteration 4883 : loss : 0.017595, loss_ce: 0.005252
2022-01-08 13:22:11,732 iteration 4884 : loss : 0.011343, loss_ce: 0.005850
2022-01-08 13:22:14,147 iteration 4885 : loss : 0.029197, loss_ce: 0.008533
2022-01-08 13:22:16,465 iteration 4886 : loss : 0.015801, loss_ce: 0.005784
2022-01-08 13:22:18,759 iteration 4887 : loss : 0.018450, loss_ce: 0.006259
2022-01-08 13:22:20,985 iteration 4888 : loss : 0.020745, loss_ce: 0.006619
2022-01-08 13:22:23,310 iteration 4889 : loss : 0.016916, loss_ce: 0.006560
2022-01-08 13:22:25,662 iteration 4890 : loss : 0.018566, loss_ce: 0.006255
2022-01-08 13:22:27,981 iteration 4891 : loss : 0.022816, loss_ce: 0.013392
2022-01-08 13:22:30,188 iteration 4892 : loss : 0.014522, loss_ce: 0.005811
2022-01-08 13:22:32,488 iteration 4893 : loss : 0.011994, loss_ce: 0.005553
2022-01-08 13:22:34,824 iteration 4894 : loss : 0.015751, loss_ce: 0.003246
2022-01-08 13:22:37,176 iteration 4895 : loss : 0.015278, loss_ce: 0.005998
2022-01-08 13:22:39,570 iteration 4896 : loss : 0.022691, loss_ce: 0.008842
 72%|███████████████████▍       | 288/400 [3:28:54<1:18:21, 41.97s/it]2022-01-08 13:22:41,948 iteration 4897 : loss : 0.014253, loss_ce: 0.004944
2022-01-08 13:22:44,239 iteration 4898 : loss : 0.023090, loss_ce: 0.010039
2022-01-08 13:22:46,487 iteration 4899 : loss : 0.014302, loss_ce: 0.005838
2022-01-08 13:22:48,920 iteration 4900 : loss : 0.029611, loss_ce: 0.010182
2022-01-08 13:22:51,187 iteration 4901 : loss : 0.013395, loss_ce: 0.003302
2022-01-08 13:22:53,635 iteration 4902 : loss : 0.028495, loss_ce: 0.011271
2022-01-08 13:22:56,026 iteration 4903 : loss : 0.031024, loss_ce: 0.014465
2022-01-08 13:22:58,445 iteration 4904 : loss : 0.024708, loss_ce: 0.012055
2022-01-08 13:23:00,743 iteration 4905 : loss : 0.019894, loss_ce: 0.006380
2022-01-08 13:23:03,063 iteration 4906 : loss : 0.022622, loss_ce: 0.007943
2022-01-08 13:23:05,284 iteration 4907 : loss : 0.013090, loss_ce: 0.005171
2022-01-08 13:23:07,581 iteration 4908 : loss : 0.015633, loss_ce: 0.006188
2022-01-08 13:23:09,956 iteration 4909 : loss : 0.013430, loss_ce: 0.004569
2022-01-08 13:23:12,259 iteration 4910 : loss : 0.013459, loss_ce: 0.004739
2022-01-08 13:23:14,509 iteration 4911 : loss : 0.016307, loss_ce: 0.004281
2022-01-08 13:23:16,787 iteration 4912 : loss : 0.017382, loss_ce: 0.006370
2022-01-08 13:23:19,086 iteration 4913 : loss : 0.016147, loss_ce: 0.004626
 72%|███████████████████▌       | 289/400 [3:29:33<1:16:17, 41.24s/it]2022-01-08 13:23:21,449 iteration 4914 : loss : 0.015109, loss_ce: 0.006464
2022-01-08 13:23:23,786 iteration 4915 : loss : 0.014809, loss_ce: 0.006495
2022-01-08 13:23:26,208 iteration 4916 : loss : 0.026757, loss_ce: 0.007089
2022-01-08 13:23:28,550 iteration 4917 : loss : 0.013652, loss_ce: 0.004511
2022-01-08 13:23:30,893 iteration 4918 : loss : 0.018097, loss_ce: 0.008055
2022-01-08 13:23:33,190 iteration 4919 : loss : 0.014293, loss_ce: 0.006036
2022-01-08 13:23:35,588 iteration 4920 : loss : 0.028203, loss_ce: 0.009482
2022-01-08 13:23:37,830 iteration 4921 : loss : 0.016137, loss_ce: 0.006010
2022-01-08 13:23:40,176 iteration 4922 : loss : 0.014702, loss_ce: 0.005506
2022-01-08 13:23:42,540 iteration 4923 : loss : 0.019463, loss_ce: 0.007453
2022-01-08 13:23:44,910 iteration 4924 : loss : 0.016974, loss_ce: 0.007485
2022-01-08 13:23:47,193 iteration 4925 : loss : 0.016104, loss_ce: 0.006825
2022-01-08 13:23:49,444 iteration 4926 : loss : 0.013215, loss_ce: 0.006238
2022-01-08 13:23:51,807 iteration 4927 : loss : 0.012270, loss_ce: 0.004404
2022-01-08 13:23:54,211 iteration 4928 : loss : 0.019619, loss_ce: 0.008483
2022-01-08 13:23:56,537 iteration 4929 : loss : 0.015657, loss_ce: 0.004177
2022-01-08 13:23:56,537 Training Data Eval:
2022-01-08 13:24:09,157   Average segmentation loss on training set: 0.0092
2022-01-08 13:24:09,158 Validation Data Eval:
2022-01-08 13:24:13,540   Average segmentation loss on validation set: 0.0762
2022-01-08 13:24:15,961 iteration 4930 : loss : 0.015549, loss_ce: 0.004501
 72%|███████████████████▌       | 290/400 [3:30:30<1:24:12, 45.93s/it]2022-01-08 13:24:18,407 iteration 4931 : loss : 0.016757, loss_ce: 0.007643
2022-01-08 13:24:20,787 iteration 4932 : loss : 0.016978, loss_ce: 0.005066
2022-01-08 13:24:23,044 iteration 4933 : loss : 0.016715, loss_ce: 0.006613
2022-01-08 13:24:25,462 iteration 4934 : loss : 0.013756, loss_ce: 0.004477
2022-01-08 13:24:27,957 iteration 4935 : loss : 0.010039, loss_ce: 0.002360
2022-01-08 13:24:30,361 iteration 4936 : loss : 0.012619, loss_ce: 0.004338
2022-01-08 13:24:32,673 iteration 4937 : loss : 0.015963, loss_ce: 0.006501
2022-01-08 13:24:34,994 iteration 4938 : loss : 0.013142, loss_ce: 0.005209
2022-01-08 13:24:37,409 iteration 4939 : loss : 0.020583, loss_ce: 0.010229
2022-01-08 13:24:39,808 iteration 4940 : loss : 0.013394, loss_ce: 0.005161
2022-01-08 13:24:42,220 iteration 4941 : loss : 0.016599, loss_ce: 0.007055
2022-01-08 13:24:44,745 iteration 4942 : loss : 0.017129, loss_ce: 0.007478
2022-01-08 13:24:47,022 iteration 4943 : loss : 0.014343, loss_ce: 0.005863
2022-01-08 13:24:49,327 iteration 4944 : loss : 0.015916, loss_ce: 0.007641
2022-01-08 13:24:51,692 iteration 4945 : loss : 0.013356, loss_ce: 0.004763
2022-01-08 13:24:54,038 iteration 4946 : loss : 0.013114, loss_ce: 0.004680
2022-01-08 13:24:56,428 iteration 4947 : loss : 0.025314, loss_ce: 0.008927
 73%|███████████████████▋       | 291/400 [3:31:11<1:20:27, 44.29s/it]2022-01-08 13:24:58,874 iteration 4948 : loss : 0.016864, loss_ce: 0.005294
2022-01-08 13:25:01,375 iteration 4949 : loss : 0.016803, loss_ce: 0.007730
2022-01-08 13:25:03,756 iteration 4950 : loss : 0.019866, loss_ce: 0.009544
2022-01-08 13:25:06,320 iteration 4951 : loss : 0.018022, loss_ce: 0.007020
2022-01-08 13:25:08,737 iteration 4952 : loss : 0.017628, loss_ce: 0.006009
2022-01-08 13:25:11,173 iteration 4953 : loss : 0.031098, loss_ce: 0.010522
2022-01-08 13:25:13,428 iteration 4954 : loss : 0.015883, loss_ce: 0.006126
2022-01-08 13:25:15,803 iteration 4955 : loss : 0.013960, loss_ce: 0.006502
2022-01-08 13:25:18,230 iteration 4956 : loss : 0.013554, loss_ce: 0.004030
2022-01-08 13:25:20,626 iteration 4957 : loss : 0.015261, loss_ce: 0.006483
2022-01-08 13:25:23,148 iteration 4958 : loss : 0.024321, loss_ce: 0.011349
2022-01-08 13:25:25,665 iteration 4959 : loss : 0.023990, loss_ce: 0.009987
2022-01-08 13:25:28,182 iteration 4960 : loss : 0.016695, loss_ce: 0.006716
2022-01-08 13:25:30,514 iteration 4961 : loss : 0.016938, loss_ce: 0.004163
2022-01-08 13:25:32,837 iteration 4962 : loss : 0.013546, loss_ce: 0.005746
2022-01-08 13:25:35,192 iteration 4963 : loss : 0.015877, loss_ce: 0.005258
2022-01-08 13:25:37,570 iteration 4964 : loss : 0.011582, loss_ce: 0.003654
 73%|███████████████████▋       | 292/400 [3:31:52<1:18:01, 43.35s/it]2022-01-08 13:25:39,927 iteration 4965 : loss : 0.018876, loss_ce: 0.005529
2022-01-08 13:25:42,225 iteration 4966 : loss : 0.015345, loss_ce: 0.006093
2022-01-08 13:25:44,585 iteration 4967 : loss : 0.029829, loss_ce: 0.007701
2022-01-08 13:25:46,958 iteration 4968 : loss : 0.023319, loss_ce: 0.006010
2022-01-08 13:25:49,390 iteration 4969 : loss : 0.029648, loss_ce: 0.009564
2022-01-08 13:25:51,799 iteration 4970 : loss : 0.021354, loss_ce: 0.012984
2022-01-08 13:25:54,164 iteration 4971 : loss : 0.017476, loss_ce: 0.006845
2022-01-08 13:25:56,470 iteration 4972 : loss : 0.021399, loss_ce: 0.007588
2022-01-08 13:25:58,858 iteration 4973 : loss : 0.013166, loss_ce: 0.004055
2022-01-08 13:26:01,228 iteration 4974 : loss : 0.016826, loss_ce: 0.009207
2022-01-08 13:26:03,606 iteration 4975 : loss : 0.016935, loss_ce: 0.005330
2022-01-08 13:26:05,878 iteration 4976 : loss : 0.015091, loss_ce: 0.005338
2022-01-08 13:26:08,280 iteration 4977 : loss : 0.014428, loss_ce: 0.006273
2022-01-08 13:26:10,710 iteration 4978 : loss : 0.031635, loss_ce: 0.012656
2022-01-08 13:26:13,050 iteration 4979 : loss : 0.015386, loss_ce: 0.005668
2022-01-08 13:26:15,318 iteration 4980 : loss : 0.011537, loss_ce: 0.003950
2022-01-08 13:26:17,820 iteration 4981 : loss : 0.019482, loss_ce: 0.006633
 73%|███████████████████▊       | 293/400 [3:32:32<1:15:38, 42.42s/it]2022-01-08 13:26:20,249 iteration 4982 : loss : 0.022589, loss_ce: 0.005092
2022-01-08 13:26:22,515 iteration 4983 : loss : 0.012308, loss_ce: 0.003812
2022-01-08 13:26:24,907 iteration 4984 : loss : 0.024917, loss_ce: 0.005709
2022-01-08 13:26:27,309 iteration 4985 : loss : 0.009605, loss_ce: 0.003416
2022-01-08 13:26:29,712 iteration 4986 : loss : 0.022815, loss_ce: 0.006491
2022-01-08 13:26:32,091 iteration 4987 : loss : 0.014118, loss_ce: 0.006722
2022-01-08 13:26:34,656 iteration 4988 : loss : 0.017135, loss_ce: 0.008558
2022-01-08 13:26:37,039 iteration 4989 : loss : 0.015192, loss_ce: 0.006334
2022-01-08 13:26:39,419 iteration 4990 : loss : 0.014177, loss_ce: 0.005882
2022-01-08 13:26:41,772 iteration 4991 : loss : 0.018990, loss_ce: 0.007416
2022-01-08 13:26:44,107 iteration 4992 : loss : 0.017514, loss_ce: 0.006117
2022-01-08 13:26:46,461 iteration 4993 : loss : 0.016068, loss_ce: 0.006841
2022-01-08 13:26:48,951 iteration 4994 : loss : 0.021481, loss_ce: 0.009472
2022-01-08 13:26:51,370 iteration 4995 : loss : 0.020213, loss_ce: 0.009057
2022-01-08 13:26:53,708 iteration 4996 : loss : 0.015175, loss_ce: 0.004439
2022-01-08 13:26:56,134 iteration 4997 : loss : 0.015251, loss_ce: 0.005413
2022-01-08 13:26:58,672 iteration 4998 : loss : 0.016711, loss_ce: 0.006124
 74%|███████████████████▊       | 294/400 [3:33:13<1:14:06, 41.95s/it]2022-01-08 13:27:01,122 iteration 4999 : loss : 0.015758, loss_ce: 0.006302
2022-01-08 13:27:03,503 iteration 5000 : loss : 0.013272, loss_ce: 0.004159
2022-01-08 13:27:05,917 iteration 5001 : loss : 0.018330, loss_ce: 0.005110
2022-01-08 13:27:08,302 iteration 5002 : loss : 0.015429, loss_ce: 0.004466
2022-01-08 13:27:10,753 iteration 5003 : loss : 0.017389, loss_ce: 0.007923
2022-01-08 13:27:13,091 iteration 5004 : loss : 0.012761, loss_ce: 0.005417
2022-01-08 13:27:15,496 iteration 5005 : loss : 0.014617, loss_ce: 0.005519
2022-01-08 13:27:17,907 iteration 5006 : loss : 0.013669, loss_ce: 0.005089
2022-01-08 13:27:20,399 iteration 5007 : loss : 0.019049, loss_ce: 0.004619
2022-01-08 13:27:22,763 iteration 5008 : loss : 0.015402, loss_ce: 0.004519
2022-01-08 13:27:25,088 iteration 5009 : loss : 0.014747, loss_ce: 0.007654
2022-01-08 13:27:27,484 iteration 5010 : loss : 0.015648, loss_ce: 0.006712
2022-01-08 13:27:29,985 iteration 5011 : loss : 0.012273, loss_ce: 0.004681
2022-01-08 13:27:32,403 iteration 5012 : loss : 0.017400, loss_ce: 0.004770
2022-01-08 13:27:34,835 iteration 5013 : loss : 0.023673, loss_ce: 0.010482
2022-01-08 13:27:37,132 iteration 5014 : loss : 0.014152, loss_ce: 0.005340
2022-01-08 13:27:37,132 Training Data Eval:
2022-01-08 13:27:49,901   Average segmentation loss on training set: 0.0094
2022-01-08 13:27:49,902 Validation Data Eval:
2022-01-08 13:27:54,398   Average segmentation loss on validation set: 0.0767
2022-01-08 13:27:56,842 iteration 5015 : loss : 0.018814, loss_ce: 0.006204
 74%|███████████████████▉       | 295/400 [3:34:11<1:21:55, 46.81s/it]2022-01-08 13:27:59,279 iteration 5016 : loss : 0.014045, loss_ce: 0.005661
2022-01-08 13:28:01,583 iteration 5017 : loss : 0.010931, loss_ce: 0.004105
2022-01-08 13:28:04,083 iteration 5018 : loss : 0.016311, loss_ce: 0.007095
2022-01-08 13:28:06,352 iteration 5019 : loss : 0.012989, loss_ce: 0.004719
2022-01-08 13:28:08,667 iteration 5020 : loss : 0.023448, loss_ce: 0.007045
2022-01-08 13:28:11,046 iteration 5021 : loss : 0.018339, loss_ce: 0.006566
2022-01-08 13:28:13,325 iteration 5022 : loss : 0.014644, loss_ce: 0.004493
2022-01-08 13:28:15,647 iteration 5023 : loss : 0.020436, loss_ce: 0.009610
2022-01-08 13:28:18,122 iteration 5024 : loss : 0.019923, loss_ce: 0.008457
2022-01-08 13:28:20,518 iteration 5025 : loss : 0.018349, loss_ce: 0.006246
2022-01-08 13:28:22,924 iteration 5026 : loss : 0.020980, loss_ce: 0.006898
2022-01-08 13:28:25,154 iteration 5027 : loss : 0.013524, loss_ce: 0.004967
2022-01-08 13:28:27,380 iteration 5028 : loss : 0.012044, loss_ce: 0.004910
2022-01-08 13:28:29,776 iteration 5029 : loss : 0.024392, loss_ce: 0.010055
2022-01-08 13:28:32,200 iteration 5030 : loss : 0.014126, loss_ce: 0.006371
2022-01-08 13:28:34,629 iteration 5031 : loss : 0.024635, loss_ce: 0.007594
2022-01-08 13:28:36,964 iteration 5032 : loss : 0.013169, loss_ce: 0.005301
 74%|███████████████████▉       | 296/400 [3:34:51<1:17:39, 44.81s/it]2022-01-08 13:28:39,419 iteration 5033 : loss : 0.017223, loss_ce: 0.006251
2022-01-08 13:28:41,858 iteration 5034 : loss : 0.018864, loss_ce: 0.007163
2022-01-08 13:28:44,258 iteration 5035 : loss : 0.019365, loss_ce: 0.006898
2022-01-08 13:28:46,547 iteration 5036 : loss : 0.015841, loss_ce: 0.006170
2022-01-08 13:28:48,827 iteration 5037 : loss : 0.020160, loss_ce: 0.006453
2022-01-08 13:28:51,213 iteration 5038 : loss : 0.014590, loss_ce: 0.004245
2022-01-08 13:28:53,606 iteration 5039 : loss : 0.017397, loss_ce: 0.006209
2022-01-08 13:28:56,028 iteration 5040 : loss : 0.012166, loss_ce: 0.004429
2022-01-08 13:28:58,471 iteration 5041 : loss : 0.017945, loss_ce: 0.006781
2022-01-08 13:29:00,943 iteration 5042 : loss : 0.022897, loss_ce: 0.007870
2022-01-08 13:29:03,254 iteration 5043 : loss : 0.024053, loss_ce: 0.007516
2022-01-08 13:29:05,664 iteration 5044 : loss : 0.016547, loss_ce: 0.005274
2022-01-08 13:29:07,982 iteration 5045 : loss : 0.019447, loss_ce: 0.008381
2022-01-08 13:29:10,291 iteration 5046 : loss : 0.023282, loss_ce: 0.005852
2022-01-08 13:29:12,792 iteration 5047 : loss : 0.010576, loss_ce: 0.002868
2022-01-08 13:29:15,124 iteration 5048 : loss : 0.012141, loss_ce: 0.006254
2022-01-08 13:29:17,431 iteration 5049 : loss : 0.011026, loss_ce: 0.004470
 74%|████████████████████       | 297/400 [3:35:32<1:14:40, 43.50s/it]2022-01-08 13:29:19,873 iteration 5050 : loss : 0.014578, loss_ce: 0.004316
2022-01-08 13:29:22,312 iteration 5051 : loss : 0.033093, loss_ce: 0.010857
2022-01-08 13:29:24,734 iteration 5052 : loss : 0.018814, loss_ce: 0.006456
2022-01-08 13:29:27,205 iteration 5053 : loss : 0.032415, loss_ce: 0.009188
2022-01-08 13:29:29,602 iteration 5054 : loss : 0.019958, loss_ce: 0.004168
2022-01-08 13:29:31,987 iteration 5055 : loss : 0.018083, loss_ce: 0.006215
2022-01-08 13:29:34,364 iteration 5056 : loss : 0.019070, loss_ce: 0.008642
2022-01-08 13:29:36,868 iteration 5057 : loss : 0.032489, loss_ce: 0.014773
2022-01-08 13:29:39,307 iteration 5058 : loss : 0.020826, loss_ce: 0.007197
2022-01-08 13:29:41,589 iteration 5059 : loss : 0.017470, loss_ce: 0.006712
2022-01-08 13:29:43,980 iteration 5060 : loss : 0.016679, loss_ce: 0.007546
2022-01-08 13:29:46,360 iteration 5061 : loss : 0.019573, loss_ce: 0.006873
2022-01-08 13:29:48,814 iteration 5062 : loss : 0.022205, loss_ce: 0.007690
2022-01-08 13:29:51,185 iteration 5063 : loss : 0.030478, loss_ce: 0.011483
2022-01-08 13:29:53,504 iteration 5064 : loss : 0.020648, loss_ce: 0.008287
2022-01-08 13:29:55,903 iteration 5065 : loss : 0.013170, loss_ce: 0.006339
2022-01-08 13:29:58,408 iteration 5066 : loss : 0.014883, loss_ce: 0.005526
 74%|████████████████████       | 298/400 [3:36:13<1:12:39, 42.74s/it]2022-01-08 13:30:00,746 iteration 5067 : loss : 0.019378, loss_ce: 0.006354
2022-01-08 13:30:03,147 iteration 5068 : loss : 0.018187, loss_ce: 0.004504
2022-01-08 13:30:05,569 iteration 5069 : loss : 0.017733, loss_ce: 0.008668
2022-01-08 13:30:07,847 iteration 5070 : loss : 0.020211, loss_ce: 0.006064
2022-01-08 13:30:10,301 iteration 5071 : loss : 0.021161, loss_ce: 0.008875
2022-01-08 13:30:12,604 iteration 5072 : loss : 0.012317, loss_ce: 0.004643
2022-01-08 13:30:14,967 iteration 5073 : loss : 0.020289, loss_ce: 0.007958
2022-01-08 13:30:17,216 iteration 5074 : loss : 0.013014, loss_ce: 0.005492
2022-01-08 13:30:19,477 iteration 5075 : loss : 0.015729, loss_ce: 0.005943
2022-01-08 13:30:21,791 iteration 5076 : loss : 0.016623, loss_ce: 0.002914
2022-01-08 13:30:24,153 iteration 5077 : loss : 0.020305, loss_ce: 0.006470
2022-01-08 13:30:26,488 iteration 5078 : loss : 0.016777, loss_ce: 0.007862
2022-01-08 13:30:28,774 iteration 5079 : loss : 0.013550, loss_ce: 0.005231
2022-01-08 13:30:31,124 iteration 5080 : loss : 0.015829, loss_ce: 0.005884
2022-01-08 13:30:33,697 iteration 5081 : loss : 0.024175, loss_ce: 0.008019
2022-01-08 13:30:36,059 iteration 5082 : loss : 0.013795, loss_ce: 0.004713
2022-01-08 13:30:38,375 iteration 5083 : loss : 0.017814, loss_ce: 0.004108
 75%|████████████████████▏      | 299/400 [3:36:53<1:10:33, 41.91s/it]2022-01-08 13:30:40,768 iteration 5084 : loss : 0.013305, loss_ce: 0.006375
2022-01-08 13:30:43,170 iteration 5085 : loss : 0.019628, loss_ce: 0.006644
2022-01-08 13:30:45,530 iteration 5086 : loss : 0.015590, loss_ce: 0.004953
2022-01-08 13:30:47,894 iteration 5087 : loss : 0.016528, loss_ce: 0.007285
2022-01-08 13:30:50,420 iteration 5088 : loss : 0.017956, loss_ce: 0.007332
2022-01-08 13:30:52,830 iteration 5089 : loss : 0.013507, loss_ce: 0.003725
2022-01-08 13:30:55,352 iteration 5090 : loss : 0.016467, loss_ce: 0.003371
2022-01-08 13:30:57,794 iteration 5091 : loss : 0.018583, loss_ce: 0.006246
2022-01-08 13:31:00,174 iteration 5092 : loss : 0.016565, loss_ce: 0.006204
2022-01-08 13:31:02,493 iteration 5093 : loss : 0.017130, loss_ce: 0.004864
2022-01-08 13:31:04,912 iteration 5094 : loss : 0.019821, loss_ce: 0.007692
2022-01-08 13:31:07,314 iteration 5095 : loss : 0.013889, loss_ce: 0.005419
2022-01-08 13:31:09,723 iteration 5096 : loss : 0.017533, loss_ce: 0.007080
2022-01-08 13:31:12,029 iteration 5097 : loss : 0.015976, loss_ce: 0.007496
2022-01-08 13:31:14,494 iteration 5098 : loss : 0.031219, loss_ce: 0.012798
2022-01-08 13:31:16,834 iteration 5099 : loss : 0.024844, loss_ce: 0.011089
2022-01-08 13:31:16,835 Training Data Eval:
2022-01-08 13:31:29,626   Average segmentation loss on training set: 0.0094
2022-01-08 13:31:29,626 Validation Data Eval:
2022-01-08 13:31:33,966   Average segmentation loss on validation set: 0.0654
2022-01-08 13:31:36,436 iteration 5100 : loss : 0.025535, loss_ce: 0.007225
 75%|████████████████████▎      | 300/400 [3:37:51<1:17:55, 46.76s/it]2022-01-08 13:31:38,925 iteration 5101 : loss : 0.021169, loss_ce: 0.008954
2022-01-08 13:31:41,261 iteration 5102 : loss : 0.014154, loss_ce: 0.005254
2022-01-08 13:31:43,649 iteration 5103 : loss : 0.014386, loss_ce: 0.007588
2022-01-08 13:31:46,103 iteration 5104 : loss : 0.014791, loss_ce: 0.004210
2022-01-08 13:31:48,397 iteration 5105 : loss : 0.016434, loss_ce: 0.006530
2022-01-08 13:31:50,823 iteration 5106 : loss : 0.014880, loss_ce: 0.005634
2022-01-08 13:31:53,272 iteration 5107 : loss : 0.021615, loss_ce: 0.007235
2022-01-08 13:31:55,595 iteration 5108 : loss : 0.014858, loss_ce: 0.006299
2022-01-08 13:31:57,904 iteration 5109 : loss : 0.018343, loss_ce: 0.007328
2022-01-08 13:32:00,239 iteration 5110 : loss : 0.011337, loss_ce: 0.003358
2022-01-08 13:32:02,643 iteration 5111 : loss : 0.020136, loss_ce: 0.006407
2022-01-08 13:32:05,073 iteration 5112 : loss : 0.026667, loss_ce: 0.009465
2022-01-08 13:32:07,435 iteration 5113 : loss : 0.017051, loss_ce: 0.005121
2022-01-08 13:32:09,922 iteration 5114 : loss : 0.019337, loss_ce: 0.007930
2022-01-08 13:32:12,276 iteration 5115 : loss : 0.023149, loss_ce: 0.007761
2022-01-08 13:32:14,575 iteration 5116 : loss : 0.014520, loss_ce: 0.005738
2022-01-08 13:32:16,921 iteration 5117 : loss : 0.017738, loss_ce: 0.007097
 75%|████████████████████▎      | 301/400 [3:38:31<1:14:02, 44.88s/it]2022-01-08 13:32:19,383 iteration 5118 : loss : 0.019181, loss_ce: 0.005044
2022-01-08 13:32:21,724 iteration 5119 : loss : 0.014377, loss_ce: 0.006566
2022-01-08 13:32:24,046 iteration 5120 : loss : 0.012301, loss_ce: 0.004752
2022-01-08 13:32:26,504 iteration 5121 : loss : 0.016991, loss_ce: 0.004467
2022-01-08 13:32:28,942 iteration 5122 : loss : 0.020640, loss_ce: 0.010412
2022-01-08 13:32:31,408 iteration 5123 : loss : 0.029084, loss_ce: 0.009378
2022-01-08 13:32:33,715 iteration 5124 : loss : 0.011810, loss_ce: 0.005481
2022-01-08 13:32:36,049 iteration 5125 : loss : 0.019051, loss_ce: 0.007438
2022-01-08 13:32:38,457 iteration 5126 : loss : 0.017435, loss_ce: 0.006566
2022-01-08 13:32:40,873 iteration 5127 : loss : 0.019244, loss_ce: 0.008554
2022-01-08 13:32:43,212 iteration 5128 : loss : 0.017371, loss_ce: 0.006201
2022-01-08 13:32:45,543 iteration 5129 : loss : 0.017564, loss_ce: 0.007662
2022-01-08 13:32:47,892 iteration 5130 : loss : 0.013773, loss_ce: 0.005653
2022-01-08 13:32:50,285 iteration 5131 : loss : 0.012560, loss_ce: 0.004836
2022-01-08 13:32:52,688 iteration 5132 : loss : 0.016324, loss_ce: 0.006062
2022-01-08 13:32:55,180 iteration 5133 : loss : 0.028211, loss_ce: 0.010552
2022-01-08 13:32:57,560 iteration 5134 : loss : 0.020788, loss_ce: 0.005000
 76%|████████████████████▍      | 302/400 [3:39:12<1:11:13, 43.60s/it]2022-01-08 13:32:59,977 iteration 5135 : loss : 0.013303, loss_ce: 0.006743
2022-01-08 13:33:02,275 iteration 5136 : loss : 0.012495, loss_ce: 0.003738
2022-01-08 13:33:04,565 iteration 5137 : loss : 0.013177, loss_ce: 0.004555
2022-01-08 13:33:06,949 iteration 5138 : loss : 0.013921, loss_ce: 0.005963
2022-01-08 13:33:09,402 iteration 5139 : loss : 0.016585, loss_ce: 0.006565
2022-01-08 13:33:11,748 iteration 5140 : loss : 0.038988, loss_ce: 0.014316
2022-01-08 13:33:14,075 iteration 5141 : loss : 0.025953, loss_ce: 0.009401
2022-01-08 13:33:16,410 iteration 5142 : loss : 0.016465, loss_ce: 0.005165
2022-01-08 13:33:18,727 iteration 5143 : loss : 0.011929, loss_ce: 0.005683
2022-01-08 13:33:21,205 iteration 5144 : loss : 0.013157, loss_ce: 0.005598
2022-01-08 13:33:23,673 iteration 5145 : loss : 0.011162, loss_ce: 0.003258
2022-01-08 13:33:26,135 iteration 5146 : loss : 0.014628, loss_ce: 0.004938
2022-01-08 13:33:28,445 iteration 5147 : loss : 0.015589, loss_ce: 0.003511
2022-01-08 13:33:30,854 iteration 5148 : loss : 0.015384, loss_ce: 0.005389
2022-01-08 13:33:33,250 iteration 5149 : loss : 0.016578, loss_ce: 0.005947
2022-01-08 13:33:35,611 iteration 5150 : loss : 0.018272, loss_ce: 0.008330
2022-01-08 13:33:37,942 iteration 5151 : loss : 0.017039, loss_ce: 0.008982
 76%|████████████████████▍      | 303/400 [3:39:52<1:08:56, 42.64s/it]2022-01-08 13:33:40,267 iteration 5152 : loss : 0.015290, loss_ce: 0.006706
2022-01-08 13:33:42,753 iteration 5153 : loss : 0.017650, loss_ce: 0.007185
2022-01-08 13:33:45,092 iteration 5154 : loss : 0.012407, loss_ce: 0.004045
2022-01-08 13:33:47,410 iteration 5155 : loss : 0.014296, loss_ce: 0.005891
2022-01-08 13:33:49,744 iteration 5156 : loss : 0.022338, loss_ce: 0.005437
2022-01-08 13:33:52,064 iteration 5157 : loss : 0.010748, loss_ce: 0.004537
2022-01-08 13:33:54,373 iteration 5158 : loss : 0.016104, loss_ce: 0.005660
2022-01-08 13:33:56,772 iteration 5159 : loss : 0.014591, loss_ce: 0.005461
2022-01-08 13:33:59,111 iteration 5160 : loss : 0.020289, loss_ce: 0.008208
2022-01-08 13:34:01,481 iteration 5161 : loss : 0.018083, loss_ce: 0.006445
2022-01-08 13:34:03,967 iteration 5162 : loss : 0.017271, loss_ce: 0.004792
2022-01-08 13:34:06,345 iteration 5163 : loss : 0.018878, loss_ce: 0.010655
2022-01-08 13:34:08,603 iteration 5164 : loss : 0.013762, loss_ce: 0.005081
2022-01-08 13:34:11,024 iteration 5165 : loss : 0.018015, loss_ce: 0.007203
2022-01-08 13:34:13,347 iteration 5166 : loss : 0.016749, loss_ce: 0.006371
2022-01-08 13:34:15,655 iteration 5167 : loss : 0.020965, loss_ce: 0.005890
2022-01-08 13:34:17,942 iteration 5168 : loss : 0.010879, loss_ce: 0.004911
 76%|████████████████████▌      | 304/400 [3:40:32<1:06:57, 41.85s/it]2022-01-08 13:34:20,345 iteration 5169 : loss : 0.014463, loss_ce: 0.003705
2022-01-08 13:34:22,697 iteration 5170 : loss : 0.012233, loss_ce: 0.006159
2022-01-08 13:34:25,037 iteration 5171 : loss : 0.029300, loss_ce: 0.009298
2022-01-08 13:34:27,439 iteration 5172 : loss : 0.018296, loss_ce: 0.006903
2022-01-08 13:34:29,896 iteration 5173 : loss : 0.018497, loss_ce: 0.007126
2022-01-08 13:34:32,427 iteration 5174 : loss : 0.009807, loss_ce: 0.002785
2022-01-08 13:34:34,848 iteration 5175 : loss : 0.016222, loss_ce: 0.004929
2022-01-08 13:34:37,239 iteration 5176 : loss : 0.014105, loss_ce: 0.004673
2022-01-08 13:34:39,600 iteration 5177 : loss : 0.014623, loss_ce: 0.006674
2022-01-08 13:34:41,967 iteration 5178 : loss : 0.013784, loss_ce: 0.006281
2022-01-08 13:34:44,256 iteration 5179 : loss : 0.016813, loss_ce: 0.007899
2022-01-08 13:34:46,527 iteration 5180 : loss : 0.013629, loss_ce: 0.006250
2022-01-08 13:34:48,818 iteration 5181 : loss : 0.016483, loss_ce: 0.005977
2022-01-08 13:34:51,256 iteration 5182 : loss : 0.016124, loss_ce: 0.007086
2022-01-08 13:34:53,613 iteration 5183 : loss : 0.012961, loss_ce: 0.004368
2022-01-08 13:34:56,008 iteration 5184 : loss : 0.013590, loss_ce: 0.006014
2022-01-08 13:34:56,009 Training Data Eval:
2022-01-08 13:35:08,792   Average segmentation loss on training set: 0.0089
2022-01-08 13:35:08,792 Validation Data Eval:
2022-01-08 13:35:13,281   Average segmentation loss on validation set: 0.0657
2022-01-08 13:35:15,668 iteration 5185 : loss : 0.011855, loss_ce: 0.004590
 76%|████████████████████▌      | 305/400 [3:41:30<1:13:47, 46.61s/it]2022-01-08 13:35:18,104 iteration 5186 : loss : 0.035081, loss_ce: 0.012414
2022-01-08 13:35:20,458 iteration 5187 : loss : 0.011061, loss_ce: 0.004683
2022-01-08 13:35:22,831 iteration 5188 : loss : 0.012157, loss_ce: 0.003787
2022-01-08 13:35:25,184 iteration 5189 : loss : 0.025219, loss_ce: 0.007811
2022-01-08 13:35:27,626 iteration 5190 : loss : 0.021516, loss_ce: 0.007319
2022-01-08 13:35:29,901 iteration 5191 : loss : 0.021448, loss_ce: 0.007912
2022-01-08 13:35:32,238 iteration 5192 : loss : 0.019137, loss_ce: 0.008238
2022-01-08 13:35:34,533 iteration 5193 : loss : 0.018825, loss_ce: 0.010383
2022-01-08 13:35:36,884 iteration 5194 : loss : 0.018076, loss_ce: 0.005559
2022-01-08 13:35:39,197 iteration 5195 : loss : 0.014784, loss_ce: 0.004327
2022-01-08 13:35:41,682 iteration 5196 : loss : 0.022085, loss_ce: 0.006844
2022-01-08 13:35:44,008 iteration 5197 : loss : 0.014368, loss_ce: 0.004456
2022-01-08 13:35:46,259 iteration 5198 : loss : 0.014222, loss_ce: 0.008270
2022-01-08 13:35:48,644 iteration 5199 : loss : 0.014274, loss_ce: 0.005268
2022-01-08 13:35:50,911 iteration 5200 : loss : 0.014353, loss_ce: 0.006276
2022-01-08 13:35:53,165 iteration 5201 : loss : 0.013530, loss_ce: 0.005985
2022-01-08 13:35:55,506 iteration 5202 : loss : 0.016958, loss_ce: 0.007349
 76%|████████████████████▋      | 306/400 [3:42:10<1:09:50, 44.58s/it]2022-01-08 13:35:57,911 iteration 5203 : loss : 0.019685, loss_ce: 0.008273
2022-01-08 13:36:00,332 iteration 5204 : loss : 0.015824, loss_ce: 0.007106
2022-01-08 13:36:02,759 iteration 5205 : loss : 0.020763, loss_ce: 0.006336
2022-01-08 13:36:05,235 iteration 5206 : loss : 0.027059, loss_ce: 0.009060
2022-01-08 13:36:07,674 iteration 5207 : loss : 0.033734, loss_ce: 0.009797
2022-01-08 13:36:10,100 iteration 5208 : loss : 0.010289, loss_ce: 0.004242
2022-01-08 13:36:12,514 iteration 5209 : loss : 0.015244, loss_ce: 0.006206
2022-01-08 13:36:14,901 iteration 5210 : loss : 0.018197, loss_ce: 0.008533
2022-01-08 13:36:17,215 iteration 5211 : loss : 0.019348, loss_ce: 0.006896
2022-01-08 13:36:19,593 iteration 5212 : loss : 0.017750, loss_ce: 0.005518
2022-01-08 13:36:22,037 iteration 5213 : loss : 0.021165, loss_ce: 0.008952
2022-01-08 13:36:24,440 iteration 5214 : loss : 0.015656, loss_ce: 0.008058
2022-01-08 13:36:26,725 iteration 5215 : loss : 0.017801, loss_ce: 0.006994
2022-01-08 13:36:28,982 iteration 5216 : loss : 0.015469, loss_ce: 0.004699
2022-01-08 13:36:31,304 iteration 5217 : loss : 0.018679, loss_ce: 0.008092
2022-01-08 13:36:33,564 iteration 5218 : loss : 0.012352, loss_ce: 0.004375
2022-01-08 13:36:35,911 iteration 5219 : loss : 0.020316, loss_ce: 0.006941
 77%|████████████████████▋      | 307/400 [3:42:50<1:07:09, 43.33s/it]2022-01-08 13:36:38,217 iteration 5220 : loss : 0.011596, loss_ce: 0.005022
2022-01-08 13:36:40,528 iteration 5221 : loss : 0.015397, loss_ce: 0.004117
2022-01-08 13:36:42,899 iteration 5222 : loss : 0.027298, loss_ce: 0.007713
2022-01-08 13:36:45,261 iteration 5223 : loss : 0.016009, loss_ce: 0.009832
2022-01-08 13:36:47,729 iteration 5224 : loss : 0.021825, loss_ce: 0.006042
2022-01-08 13:36:50,095 iteration 5225 : loss : 0.011720, loss_ce: 0.004739
2022-01-08 13:36:52,497 iteration 5226 : loss : 0.013773, loss_ce: 0.005780
2022-01-08 13:36:54,827 iteration 5227 : loss : 0.025033, loss_ce: 0.007607
2022-01-08 13:36:57,167 iteration 5228 : loss : 0.009699, loss_ce: 0.003123
2022-01-08 13:36:59,598 iteration 5229 : loss : 0.025004, loss_ce: 0.010955
2022-01-08 13:37:02,029 iteration 5230 : loss : 0.011331, loss_ce: 0.003958
2022-01-08 13:37:04,422 iteration 5231 : loss : 0.014820, loss_ce: 0.004576
2022-01-08 13:37:06,860 iteration 5232 : loss : 0.030801, loss_ce: 0.010380
2022-01-08 13:37:09,350 iteration 5233 : loss : 0.012946, loss_ce: 0.005453
2022-01-08 13:37:11,772 iteration 5234 : loss : 0.015722, loss_ce: 0.006370
2022-01-08 13:37:14,183 iteration 5235 : loss : 0.018194, loss_ce: 0.008653
2022-01-08 13:37:16,566 iteration 5236 : loss : 0.020041, loss_ce: 0.008438
 77%|████████████████████▊      | 308/400 [3:43:31<1:05:12, 42.53s/it]2022-01-08 13:37:18,831 iteration 5237 : loss : 0.011404, loss_ce: 0.005363
2022-01-08 13:37:21,366 iteration 5238 : loss : 0.013209, loss_ce: 0.005358
2022-01-08 13:37:23,715 iteration 5239 : loss : 0.014622, loss_ce: 0.005185
2022-01-08 13:37:26,158 iteration 5240 : loss : 0.026411, loss_ce: 0.005595
2022-01-08 13:37:28,759 iteration 5241 : loss : 0.024512, loss_ce: 0.009094
2022-01-08 13:37:31,266 iteration 5242 : loss : 0.025542, loss_ce: 0.010397
2022-01-08 13:37:33,716 iteration 5243 : loss : 0.025261, loss_ce: 0.011628
2022-01-08 13:37:36,087 iteration 5244 : loss : 0.013263, loss_ce: 0.004551
2022-01-08 13:37:38,524 iteration 5245 : loss : 0.020903, loss_ce: 0.006217
2022-01-08 13:37:40,875 iteration 5246 : loss : 0.022764, loss_ce: 0.007717
2022-01-08 13:37:43,278 iteration 5247 : loss : 0.019254, loss_ce: 0.007161
2022-01-08 13:37:45,702 iteration 5248 : loss : 0.019230, loss_ce: 0.008787
2022-01-08 13:37:48,203 iteration 5249 : loss : 0.012588, loss_ce: 0.004499
2022-01-08 13:37:50,596 iteration 5250 : loss : 0.017412, loss_ce: 0.007125
2022-01-08 13:37:53,043 iteration 5251 : loss : 0.015305, loss_ce: 0.006656
2022-01-08 13:37:55,414 iteration 5252 : loss : 0.012870, loss_ce: 0.006385
2022-01-08 13:37:57,734 iteration 5253 : loss : 0.012190, loss_ce: 0.004435
 77%|████████████████████▊      | 309/400 [3:44:12<1:03:52, 42.12s/it]2022-01-08 13:38:00,032 iteration 5254 : loss : 0.013585, loss_ce: 0.006141
2022-01-08 13:38:02,429 iteration 5255 : loss : 0.015827, loss_ce: 0.004122
2022-01-08 13:38:04,767 iteration 5256 : loss : 0.035966, loss_ce: 0.012795
2022-01-08 13:38:07,122 iteration 5257 : loss : 0.014765, loss_ce: 0.005162
2022-01-08 13:38:09,471 iteration 5258 : loss : 0.013041, loss_ce: 0.005211
2022-01-08 13:38:11,827 iteration 5259 : loss : 0.018741, loss_ce: 0.006895
2022-01-08 13:38:14,300 iteration 5260 : loss : 0.017065, loss_ce: 0.005819
2022-01-08 13:38:16,635 iteration 5261 : loss : 0.020039, loss_ce: 0.011864
2022-01-08 13:38:18,922 iteration 5262 : loss : 0.014857, loss_ce: 0.006061
2022-01-08 13:38:21,359 iteration 5263 : loss : 0.031160, loss_ce: 0.015451
2022-01-08 13:38:23,739 iteration 5264 : loss : 0.026416, loss_ce: 0.014892
2022-01-08 13:38:26,324 iteration 5265 : loss : 0.021475, loss_ce: 0.010503
2022-01-08 13:38:28,710 iteration 5266 : loss : 0.017177, loss_ce: 0.006861
2022-01-08 13:38:31,158 iteration 5267 : loss : 0.018704, loss_ce: 0.008223
2022-01-08 13:38:33,340 iteration 5268 : loss : 0.011359, loss_ce: 0.002743
2022-01-08 13:38:35,609 iteration 5269 : loss : 0.013200, loss_ce: 0.004764
2022-01-08 13:38:35,609 Training Data Eval:
2022-01-08 13:38:48,542   Average segmentation loss on training set: 0.0090
2022-01-08 13:38:48,543 Validation Data Eval:
2022-01-08 13:38:53,058   Average segmentation loss on validation set: 0.0703
2022-01-08 13:38:55,423 iteration 5270 : loss : 0.026735, loss_ce: 0.003682
 78%|████████████████████▉      | 310/400 [3:45:10<1:10:11, 46.79s/it]2022-01-08 13:38:57,981 iteration 5271 : loss : 0.019779, loss_ce: 0.006862
2022-01-08 13:39:00,459 iteration 5272 : loss : 0.024175, loss_ce: 0.009102
2022-01-08 13:39:03,000 iteration 5273 : loss : 0.016780, loss_ce: 0.008031
2022-01-08 13:39:05,410 iteration 5274 : loss : 0.017293, loss_ce: 0.006783
2022-01-08 13:39:07,767 iteration 5275 : loss : 0.012848, loss_ce: 0.005332
2022-01-08 13:39:10,086 iteration 5276 : loss : 0.015103, loss_ce: 0.004948
2022-01-08 13:39:12,547 iteration 5277 : loss : 0.021073, loss_ce: 0.009034
2022-01-08 13:39:14,825 iteration 5278 : loss : 0.022902, loss_ce: 0.005460
2022-01-08 13:39:17,186 iteration 5279 : loss : 0.024491, loss_ce: 0.009074
2022-01-08 13:39:19,514 iteration 5280 : loss : 0.013330, loss_ce: 0.004144
2022-01-08 13:39:22,094 iteration 5281 : loss : 0.011234, loss_ce: 0.005043
2022-01-08 13:39:24,441 iteration 5282 : loss : 0.013671, loss_ce: 0.005424
2022-01-08 13:39:26,795 iteration 5283 : loss : 0.014050, loss_ce: 0.005697
2022-01-08 13:39:29,211 iteration 5284 : loss : 0.013300, loss_ce: 0.004896
2022-01-08 13:39:31,574 iteration 5285 : loss : 0.014671, loss_ce: 0.004727
2022-01-08 13:39:33,954 iteration 5286 : loss : 0.014606, loss_ce: 0.007058
2022-01-08 13:39:36,391 iteration 5287 : loss : 0.016686, loss_ce: 0.008169
 78%|████████████████████▉      | 311/400 [3:45:51<1:06:49, 45.05s/it]2022-01-08 13:39:38,816 iteration 5288 : loss : 0.014510, loss_ce: 0.006301
2022-01-08 13:39:41,158 iteration 5289 : loss : 0.013613, loss_ce: 0.005388
2022-01-08 13:39:43,578 iteration 5290 : loss : 0.020550, loss_ce: 0.006555
2022-01-08 13:39:45,841 iteration 5291 : loss : 0.014699, loss_ce: 0.006350
2022-01-08 13:39:48,135 iteration 5292 : loss : 0.022805, loss_ce: 0.004861
2022-01-08 13:39:50,498 iteration 5293 : loss : 0.018749, loss_ce: 0.006309
2022-01-08 13:39:52,921 iteration 5294 : loss : 0.024708, loss_ce: 0.007796
2022-01-08 13:39:55,235 iteration 5295 : loss : 0.021290, loss_ce: 0.005663
2022-01-08 13:39:57,471 iteration 5296 : loss : 0.014151, loss_ce: 0.004121
2022-01-08 13:39:59,813 iteration 5297 : loss : 0.016638, loss_ce: 0.005013
2022-01-08 13:40:02,114 iteration 5298 : loss : 0.017730, loss_ce: 0.008382
2022-01-08 13:40:04,385 iteration 5299 : loss : 0.018585, loss_ce: 0.004013
2022-01-08 13:40:06,716 iteration 5300 : loss : 0.013657, loss_ce: 0.005558
2022-01-08 13:40:09,072 iteration 5301 : loss : 0.021987, loss_ce: 0.006616
2022-01-08 13:40:11,432 iteration 5302 : loss : 0.017396, loss_ce: 0.006988
2022-01-08 13:40:13,734 iteration 5303 : loss : 0.013228, loss_ce: 0.005866
2022-01-08 13:40:16,054 iteration 5304 : loss : 0.020487, loss_ce: 0.011726
 78%|█████████████████████      | 312/400 [3:46:30<1:03:41, 43.43s/it]2022-01-08 13:40:18,381 iteration 5305 : loss : 0.008536, loss_ce: 0.003048
2022-01-08 13:40:20,722 iteration 5306 : loss : 0.015936, loss_ce: 0.006975
2022-01-08 13:40:23,003 iteration 5307 : loss : 0.019735, loss_ce: 0.007025
2022-01-08 13:40:25,338 iteration 5308 : loss : 0.012556, loss_ce: 0.004332
2022-01-08 13:40:27,778 iteration 5309 : loss : 0.017817, loss_ce: 0.009680
2022-01-08 13:40:30,289 iteration 5310 : loss : 0.017051, loss_ce: 0.005802
2022-01-08 13:40:32,695 iteration 5311 : loss : 0.016614, loss_ce: 0.005284
2022-01-08 13:40:35,101 iteration 5312 : loss : 0.025494, loss_ce: 0.009456
2022-01-08 13:40:37,594 iteration 5313 : loss : 0.014975, loss_ce: 0.007389
2022-01-08 13:40:40,007 iteration 5314 : loss : 0.019117, loss_ce: 0.006116
2022-01-08 13:40:42,353 iteration 5315 : loss : 0.015189, loss_ce: 0.005415
2022-01-08 13:40:44,739 iteration 5316 : loss : 0.014620, loss_ce: 0.004479
2022-01-08 13:40:47,092 iteration 5317 : loss : 0.011541, loss_ce: 0.003565
2022-01-08 13:40:49,442 iteration 5318 : loss : 0.017173, loss_ce: 0.006205
2022-01-08 13:40:51,750 iteration 5319 : loss : 0.026640, loss_ce: 0.010270
2022-01-08 13:40:54,066 iteration 5320 : loss : 0.013058, loss_ce: 0.004370
2022-01-08 13:40:56,413 iteration 5321 : loss : 0.018444, loss_ce: 0.007071
 78%|█████████████████████▏     | 313/400 [3:47:11<1:01:37, 42.51s/it]2022-01-08 13:40:58,770 iteration 5322 : loss : 0.014183, loss_ce: 0.005648
2022-01-08 13:41:01,190 iteration 5323 : loss : 0.023915, loss_ce: 0.007531
2022-01-08 13:41:03,517 iteration 5324 : loss : 0.015198, loss_ce: 0.005154
2022-01-08 13:41:05,935 iteration 5325 : loss : 0.015936, loss_ce: 0.005950
2022-01-08 13:41:08,333 iteration 5326 : loss : 0.017733, loss_ce: 0.006079
2022-01-08 13:41:10,662 iteration 5327 : loss : 0.021518, loss_ce: 0.007682
2022-01-08 13:41:13,006 iteration 5328 : loss : 0.011738, loss_ce: 0.004387
2022-01-08 13:41:15,302 iteration 5329 : loss : 0.023662, loss_ce: 0.018357
2022-01-08 13:41:17,697 iteration 5330 : loss : 0.013672, loss_ce: 0.004609
2022-01-08 13:41:19,980 iteration 5331 : loss : 0.013082, loss_ce: 0.004813
2022-01-08 13:41:22,320 iteration 5332 : loss : 0.018893, loss_ce: 0.007381
2022-01-08 13:41:24,661 iteration 5333 : loss : 0.019735, loss_ce: 0.006532
2022-01-08 13:41:26,974 iteration 5334 : loss : 0.013407, loss_ce: 0.003813
2022-01-08 13:41:29,349 iteration 5335 : loss : 0.019127, loss_ce: 0.006361
2022-01-08 13:41:31,682 iteration 5336 : loss : 0.025934, loss_ce: 0.008686
2022-01-08 13:41:33,976 iteration 5337 : loss : 0.014629, loss_ce: 0.005602
2022-01-08 13:41:36,209 iteration 5338 : loss : 0.011820, loss_ce: 0.004460
 78%|██████████████████████▊      | 314/400 [3:47:50<59:45, 41.69s/it]2022-01-08 13:41:38,652 iteration 5339 : loss : 0.015190, loss_ce: 0.004806
2022-01-08 13:41:41,045 iteration 5340 : loss : 0.013776, loss_ce: 0.009069
2022-01-08 13:41:43,370 iteration 5341 : loss : 0.013678, loss_ce: 0.005226
2022-01-08 13:41:45,746 iteration 5342 : loss : 0.033960, loss_ce: 0.009607
2022-01-08 13:41:48,024 iteration 5343 : loss : 0.019130, loss_ce: 0.006869
2022-01-08 13:41:50,442 iteration 5344 : loss : 0.016078, loss_ce: 0.007980
2022-01-08 13:41:52,763 iteration 5345 : loss : 0.015563, loss_ce: 0.004404
2022-01-08 13:41:55,087 iteration 5346 : loss : 0.019735, loss_ce: 0.006990
2022-01-08 13:41:57,532 iteration 5347 : loss : 0.014616, loss_ce: 0.006233
2022-01-08 13:41:59,949 iteration 5348 : loss : 0.016899, loss_ce: 0.007118
2022-01-08 13:42:02,370 iteration 5349 : loss : 0.020127, loss_ce: 0.009298
2022-01-08 13:42:04,696 iteration 5350 : loss : 0.010402, loss_ce: 0.003874
2022-01-08 13:42:07,137 iteration 5351 : loss : 0.027586, loss_ce: 0.005121
2022-01-08 13:42:09,501 iteration 5352 : loss : 0.015251, loss_ce: 0.005293
2022-01-08 13:42:11,898 iteration 5353 : loss : 0.018899, loss_ce: 0.007956
2022-01-08 13:42:14,161 iteration 5354 : loss : 0.012998, loss_ce: 0.005161
2022-01-08 13:42:14,161 Training Data Eval:
2022-01-08 13:42:26,753   Average segmentation loss on training set: 0.0107
2022-01-08 13:42:26,753 Validation Data Eval:
2022-01-08 13:42:31,122   Average segmentation loss on validation set: 0.0914
2022-01-08 13:42:33,468 iteration 5355 : loss : 0.017508, loss_ce: 0.008252
 79%|█████████████████████▎     | 315/400 [3:48:48<1:05:40, 46.36s/it]2022-01-08 13:42:35,921 iteration 5356 : loss : 0.032012, loss_ce: 0.014943
2022-01-08 13:42:38,208 iteration 5357 : loss : 0.012130, loss_ce: 0.003685
2022-01-08 13:42:40,485 iteration 5358 : loss : 0.012841, loss_ce: 0.003445
2022-01-08 13:42:42,720 iteration 5359 : loss : 0.031188, loss_ce: 0.020095
2022-01-08 13:42:44,978 iteration 5360 : loss : 0.013260, loss_ce: 0.004516
2022-01-08 13:42:47,289 iteration 5361 : loss : 0.020535, loss_ce: 0.006066
2022-01-08 13:42:49,555 iteration 5362 : loss : 0.022970, loss_ce: 0.014762
2022-01-08 13:42:51,816 iteration 5363 : loss : 0.013957, loss_ce: 0.005826
2022-01-08 13:42:54,035 iteration 5364 : loss : 0.016763, loss_ce: 0.002844
2022-01-08 13:42:56,413 iteration 5365 : loss : 0.014736, loss_ce: 0.004730
2022-01-08 13:42:58,652 iteration 5366 : loss : 0.018365, loss_ce: 0.006072
2022-01-08 13:43:00,988 iteration 5367 : loss : 0.019929, loss_ce: 0.005518
2022-01-08 13:43:03,437 iteration 5368 : loss : 0.021115, loss_ce: 0.007953
2022-01-08 13:43:05,827 iteration 5369 : loss : 0.014998, loss_ce: 0.006351
2022-01-08 13:43:08,150 iteration 5370 : loss : 0.019589, loss_ce: 0.005725
2022-01-08 13:43:10,513 iteration 5371 : loss : 0.014822, loss_ce: 0.004109
2022-01-08 13:43:12,783 iteration 5372 : loss : 0.017508, loss_ce: 0.007911
 79%|█████████████████████▎     | 316/400 [3:49:27<1:01:57, 44.26s/it]2022-01-08 13:43:15,142 iteration 5373 : loss : 0.011338, loss_ce: 0.005120
2022-01-08 13:43:17,555 iteration 5374 : loss : 0.018161, loss_ce: 0.005224
2022-01-08 13:43:19,930 iteration 5375 : loss : 0.012812, loss_ce: 0.004650
2022-01-08 13:43:22,246 iteration 5376 : loss : 0.013398, loss_ce: 0.004314
2022-01-08 13:43:24,517 iteration 5377 : loss : 0.014778, loss_ce: 0.002178
2022-01-08 13:43:26,815 iteration 5378 : loss : 0.010700, loss_ce: 0.004097
2022-01-08 13:43:29,271 iteration 5379 : loss : 0.017723, loss_ce: 0.005095
2022-01-08 13:43:31,644 iteration 5380 : loss : 0.014311, loss_ce: 0.005789
2022-01-08 13:43:33,985 iteration 5381 : loss : 0.015254, loss_ce: 0.007135
2022-01-08 13:43:36,352 iteration 5382 : loss : 0.017928, loss_ce: 0.005005
2022-01-08 13:43:38,734 iteration 5383 : loss : 0.017175, loss_ce: 0.007126
2022-01-08 13:43:41,054 iteration 5384 : loss : 0.013743, loss_ce: 0.006096
2022-01-08 13:43:43,428 iteration 5385 : loss : 0.014884, loss_ce: 0.006336
2022-01-08 13:43:45,809 iteration 5386 : loss : 0.016596, loss_ce: 0.006260
2022-01-08 13:43:48,085 iteration 5387 : loss : 0.021210, loss_ce: 0.008338
2022-01-08 13:43:50,415 iteration 5388 : loss : 0.013942, loss_ce: 0.005480
2022-01-08 13:43:52,761 iteration 5389 : loss : 0.012658, loss_ce: 0.004254
 79%|██████████████████████▉      | 317/400 [3:50:07<59:26, 42.97s/it]2022-01-08 13:43:55,167 iteration 5390 : loss : 0.016820, loss_ce: 0.004398
2022-01-08 13:43:57,354 iteration 5391 : loss : 0.017048, loss_ce: 0.006318
2022-01-08 13:43:59,699 iteration 5392 : loss : 0.018780, loss_ce: 0.007788
2022-01-08 13:44:02,077 iteration 5393 : loss : 0.036948, loss_ce: 0.009948
2022-01-08 13:44:04,379 iteration 5394 : loss : 0.013289, loss_ce: 0.005378
2022-01-08 13:44:06,747 iteration 5395 : loss : 0.012655, loss_ce: 0.005684
2022-01-08 13:44:09,180 iteration 5396 : loss : 0.024958, loss_ce: 0.007124
2022-01-08 13:44:11,600 iteration 5397 : loss : 0.018421, loss_ce: 0.006765
2022-01-08 13:44:13,898 iteration 5398 : loss : 0.010736, loss_ce: 0.005244
2022-01-08 13:44:16,242 iteration 5399 : loss : 0.011038, loss_ce: 0.004797
2022-01-08 13:44:18,652 iteration 5400 : loss : 0.020010, loss_ce: 0.005552
2022-01-08 13:44:21,010 iteration 5401 : loss : 0.013625, loss_ce: 0.004271
2022-01-08 13:44:23,317 iteration 5402 : loss : 0.014430, loss_ce: 0.005161
2022-01-08 13:44:25,780 iteration 5403 : loss : 0.028765, loss_ce: 0.008992
2022-01-08 13:44:28,121 iteration 5404 : loss : 0.013665, loss_ce: 0.006477
2022-01-08 13:44:30,435 iteration 5405 : loss : 0.012282, loss_ce: 0.004006
2022-01-08 13:44:32,752 iteration 5406 : loss : 0.015295, loss_ce: 0.003332
 80%|███████████████████████      | 318/400 [3:50:47<57:30, 42.08s/it]2022-01-08 13:44:35,222 iteration 5407 : loss : 0.016938, loss_ce: 0.005001
2022-01-08 13:44:37,491 iteration 5408 : loss : 0.014637, loss_ce: 0.003835
2022-01-08 13:44:39,712 iteration 5409 : loss : 0.011987, loss_ce: 0.005501
2022-01-08 13:44:41,961 iteration 5410 : loss : 0.012249, loss_ce: 0.003890
2022-01-08 13:44:44,248 iteration 5411 : loss : 0.012635, loss_ce: 0.004166
2022-01-08 13:44:46,582 iteration 5412 : loss : 0.019259, loss_ce: 0.009384
2022-01-08 13:44:48,829 iteration 5413 : loss : 0.014033, loss_ce: 0.005542
2022-01-08 13:44:51,270 iteration 5414 : loss : 0.020193, loss_ce: 0.007054
2022-01-08 13:44:53,607 iteration 5415 : loss : 0.014369, loss_ce: 0.004721
2022-01-08 13:44:56,036 iteration 5416 : loss : 0.014605, loss_ce: 0.005882
2022-01-08 13:44:58,311 iteration 5417 : loss : 0.014002, loss_ce: 0.005199
2022-01-08 13:45:00,608 iteration 5418 : loss : 0.013192, loss_ce: 0.004024
2022-01-08 13:45:02,907 iteration 5419 : loss : 0.012567, loss_ce: 0.005389
2022-01-08 13:45:05,229 iteration 5420 : loss : 0.011776, loss_ce: 0.005016
2022-01-08 13:45:07,592 iteration 5421 : loss : 0.017037, loss_ce: 0.005626
2022-01-08 13:45:09,945 iteration 5422 : loss : 0.017917, loss_ce: 0.005762
2022-01-08 13:45:12,334 iteration 5423 : loss : 0.022791, loss_ce: 0.006552
 80%|███████████████████████▏     | 319/400 [3:51:27<55:47, 41.32s/it]2022-01-08 13:45:14,666 iteration 5424 : loss : 0.016619, loss_ce: 0.005932
2022-01-08 13:45:16,958 iteration 5425 : loss : 0.018362, loss_ce: 0.007648
2022-01-08 13:45:19,366 iteration 5426 : loss : 0.018420, loss_ce: 0.006265
2022-01-08 13:45:21,788 iteration 5427 : loss : 0.020616, loss_ce: 0.007836
2022-01-08 13:45:24,088 iteration 5428 : loss : 0.020679, loss_ce: 0.007569
2022-01-08 13:45:26,363 iteration 5429 : loss : 0.013399, loss_ce: 0.004734
2022-01-08 13:45:28,690 iteration 5430 : loss : 0.017067, loss_ce: 0.006776
2022-01-08 13:45:31,111 iteration 5431 : loss : 0.019655, loss_ce: 0.006353
2022-01-08 13:45:33,453 iteration 5432 : loss : 0.019623, loss_ce: 0.006286
2022-01-08 13:45:35,878 iteration 5433 : loss : 0.020495, loss_ce: 0.007750
2022-01-08 13:45:38,208 iteration 5434 : loss : 0.022247, loss_ce: 0.007392
2022-01-08 13:45:40,514 iteration 5435 : loss : 0.013289, loss_ce: 0.005355
2022-01-08 13:45:42,897 iteration 5436 : loss : 0.016360, loss_ce: 0.007227
2022-01-08 13:45:45,247 iteration 5437 : loss : 0.016278, loss_ce: 0.003625
2022-01-08 13:45:47,608 iteration 5438 : loss : 0.016490, loss_ce: 0.007126
2022-01-08 13:45:49,982 iteration 5439 : loss : 0.031384, loss_ce: 0.010294
2022-01-08 13:45:49,983 Training Data Eval:
2022-01-08 13:46:02,438   Average segmentation loss on training set: 0.0089
2022-01-08 13:46:02,438 Validation Data Eval:
2022-01-08 13:46:06,966   Average segmentation loss on validation set: 0.0853
2022-01-08 13:46:09,380 iteration 5440 : loss : 0.014728, loss_ce: 0.005538
 80%|█████████████████████▌     | 320/400 [3:52:24<1:01:23, 46.05s/it]2022-01-08 13:46:11,714 iteration 5441 : loss : 0.012291, loss_ce: 0.005244
2022-01-08 13:46:14,108 iteration 5442 : loss : 0.032380, loss_ce: 0.014609
2022-01-08 13:46:16,528 iteration 5443 : loss : 0.017971, loss_ce: 0.007073
2022-01-08 13:46:18,822 iteration 5444 : loss : 0.013019, loss_ce: 0.005782
2022-01-08 13:46:21,155 iteration 5445 : loss : 0.017101, loss_ce: 0.006415
2022-01-08 13:46:23,520 iteration 5446 : loss : 0.019919, loss_ce: 0.007647
2022-01-08 13:46:25,848 iteration 5447 : loss : 0.013067, loss_ce: 0.002205
2022-01-08 13:46:28,250 iteration 5448 : loss : 0.018628, loss_ce: 0.006054
2022-01-08 13:46:30,570 iteration 5449 : loss : 0.014482, loss_ce: 0.003832
2022-01-08 13:46:32,830 iteration 5450 : loss : 0.019460, loss_ce: 0.006293
2022-01-08 13:46:35,081 iteration 5451 : loss : 0.011450, loss_ce: 0.003105
2022-01-08 13:46:37,345 iteration 5452 : loss : 0.010985, loss_ce: 0.004184
2022-01-08 13:46:39,603 iteration 5453 : loss : 0.023682, loss_ce: 0.010150
2022-01-08 13:46:41,879 iteration 5454 : loss : 0.018738, loss_ce: 0.009057
2022-01-08 13:46:44,103 iteration 5455 : loss : 0.023644, loss_ce: 0.014390
2022-01-08 13:46:46,395 iteration 5456 : loss : 0.013985, loss_ce: 0.003945
2022-01-08 13:46:48,604 iteration 5457 : loss : 0.013346, loss_ce: 0.005112
 80%|███████████████████████▎     | 321/400 [3:53:03<57:55, 44.00s/it]2022-01-08 13:46:50,942 iteration 5458 : loss : 0.018430, loss_ce: 0.005869
2022-01-08 13:46:53,132 iteration 5459 : loss : 0.013075, loss_ce: 0.004687
2022-01-08 13:46:55,346 iteration 5460 : loss : 0.018237, loss_ce: 0.007114
2022-01-08 13:46:57,641 iteration 5461 : loss : 0.013875, loss_ce: 0.004849
2022-01-08 13:46:59,982 iteration 5462 : loss : 0.013036, loss_ce: 0.004883
2022-01-08 13:47:02,329 iteration 5463 : loss : 0.009773, loss_ce: 0.002985
2022-01-08 13:47:04,754 iteration 5464 : loss : 0.018802, loss_ce: 0.006720
2022-01-08 13:47:07,084 iteration 5465 : loss : 0.014131, loss_ce: 0.004992
2022-01-08 13:47:09,419 iteration 5466 : loss : 0.012662, loss_ce: 0.004824
2022-01-08 13:47:11,842 iteration 5467 : loss : 0.015073, loss_ce: 0.005194
2022-01-08 13:47:14,143 iteration 5468 : loss : 0.014772, loss_ce: 0.006681
2022-01-08 13:47:16,389 iteration 5469 : loss : 0.017252, loss_ce: 0.006846
2022-01-08 13:47:18,627 iteration 5470 : loss : 0.012258, loss_ce: 0.005699
2022-01-08 13:47:21,019 iteration 5471 : loss : 0.013535, loss_ce: 0.006174
2022-01-08 13:47:23,439 iteration 5472 : loss : 0.017861, loss_ce: 0.007855
2022-01-08 13:47:25,710 iteration 5473 : loss : 0.012489, loss_ce: 0.003464
2022-01-08 13:47:27,990 iteration 5474 : loss : 0.015478, loss_ce: 0.004848
 80%|███████████████████████▎     | 322/400 [3:53:42<55:23, 42.61s/it]2022-01-08 13:47:30,236 iteration 5475 : loss : 0.014123, loss_ce: 0.005676
2022-01-08 13:47:32,461 iteration 5476 : loss : 0.011754, loss_ce: 0.005100
2022-01-08 13:47:34,824 iteration 5477 : loss : 0.011416, loss_ce: 0.004244
2022-01-08 13:47:37,307 iteration 5478 : loss : 0.018104, loss_ce: 0.007673
2022-01-08 13:47:39,666 iteration 5479 : loss : 0.017004, loss_ce: 0.004766
2022-01-08 13:47:42,060 iteration 5480 : loss : 0.014929, loss_ce: 0.003793
2022-01-08 13:47:44,466 iteration 5481 : loss : 0.017202, loss_ce: 0.006563
2022-01-08 13:47:46,833 iteration 5482 : loss : 0.013851, loss_ce: 0.004734
2022-01-08 13:47:49,158 iteration 5483 : loss : 0.015036, loss_ce: 0.005226
2022-01-08 13:47:51,614 iteration 5484 : loss : 0.016611, loss_ce: 0.006934
2022-01-08 13:47:53,968 iteration 5485 : loss : 0.012084, loss_ce: 0.005590
2022-01-08 13:47:56,441 iteration 5486 : loss : 0.014267, loss_ce: 0.004801
2022-01-08 13:47:58,679 iteration 5487 : loss : 0.012220, loss_ce: 0.006745
2022-01-08 13:48:01,010 iteration 5488 : loss : 0.020640, loss_ce: 0.005937
2022-01-08 13:48:03,375 iteration 5489 : loss : 0.015807, loss_ce: 0.003631
2022-01-08 13:48:05,803 iteration 5490 : loss : 0.012693, loss_ce: 0.004521
2022-01-08 13:48:08,145 iteration 5491 : loss : 0.012087, loss_ce: 0.004013
 81%|███████████████████████▍     | 323/400 [3:54:22<53:44, 41.87s/it]2022-01-08 13:48:10,561 iteration 5492 : loss : 0.015464, loss_ce: 0.006339
2022-01-08 13:48:12,877 iteration 5493 : loss : 0.012193, loss_ce: 0.004078
2022-01-08 13:48:15,245 iteration 5494 : loss : 0.014011, loss_ce: 0.006898
2022-01-08 13:48:17,696 iteration 5495 : loss : 0.024743, loss_ce: 0.004707
2022-01-08 13:48:20,109 iteration 5496 : loss : 0.010829, loss_ce: 0.003247
2022-01-08 13:48:22,535 iteration 5497 : loss : 0.015430, loss_ce: 0.006862
2022-01-08 13:48:24,949 iteration 5498 : loss : 0.015026, loss_ce: 0.005965
2022-01-08 13:48:27,310 iteration 5499 : loss : 0.014660, loss_ce: 0.003906
2022-01-08 13:48:29,683 iteration 5500 : loss : 0.012220, loss_ce: 0.003867
2022-01-08 13:48:32,042 iteration 5501 : loss : 0.010519, loss_ce: 0.003593
2022-01-08 13:48:34,425 iteration 5502 : loss : 0.014848, loss_ce: 0.008746
2022-01-08 13:48:36,937 iteration 5503 : loss : 0.026424, loss_ce: 0.007856
2022-01-08 13:48:39,215 iteration 5504 : loss : 0.017341, loss_ce: 0.007272
2022-01-08 13:48:41,464 iteration 5505 : loss : 0.011953, loss_ce: 0.004267
2022-01-08 13:48:43,837 iteration 5506 : loss : 0.013762, loss_ce: 0.005107
2022-01-08 13:48:46,277 iteration 5507 : loss : 0.018521, loss_ce: 0.007833
2022-01-08 13:48:48,701 iteration 5508 : loss : 0.025579, loss_ce: 0.010377
 81%|███████████████████████▍     | 324/400 [3:55:03<52:32, 41.48s/it]2022-01-08 13:48:51,062 iteration 5509 : loss : 0.018695, loss_ce: 0.009185
2022-01-08 13:48:53,334 iteration 5510 : loss : 0.011742, loss_ce: 0.004227
2022-01-08 13:48:55,733 iteration 5511 : loss : 0.022339, loss_ce: 0.008104
2022-01-08 13:48:58,086 iteration 5512 : loss : 0.014079, loss_ce: 0.006292
2022-01-08 13:49:00,428 iteration 5513 : loss : 0.014067, loss_ce: 0.006994
2022-01-08 13:49:02,800 iteration 5514 : loss : 0.020554, loss_ce: 0.009033
2022-01-08 13:49:05,098 iteration 5515 : loss : 0.014422, loss_ce: 0.005783
2022-01-08 13:49:07,544 iteration 5516 : loss : 0.011201, loss_ce: 0.005508
2022-01-08 13:49:09,951 iteration 5517 : loss : 0.021296, loss_ce: 0.006552
2022-01-08 13:49:12,216 iteration 5518 : loss : 0.011711, loss_ce: 0.003797
2022-01-08 13:49:14,657 iteration 5519 : loss : 0.020539, loss_ce: 0.005934
2022-01-08 13:49:17,000 iteration 5520 : loss : 0.024548, loss_ce: 0.003242
2022-01-08 13:49:19,465 iteration 5521 : loss : 0.014123, loss_ce: 0.004593
2022-01-08 13:49:21,843 iteration 5522 : loss : 0.015348, loss_ce: 0.006013
2022-01-08 13:49:24,276 iteration 5523 : loss : 0.019039, loss_ce: 0.007503
2022-01-08 13:49:26,715 iteration 5524 : loss : 0.018616, loss_ce: 0.006363
2022-01-08 13:49:26,715 Training Data Eval:
2022-01-08 13:49:39,595   Average segmentation loss on training set: 0.0105
2022-01-08 13:49:39,595 Validation Data Eval:
2022-01-08 13:49:44,076   Average segmentation loss on validation set: 0.1026
2022-01-08 13:49:46,550 iteration 5525 : loss : 0.031825, loss_ce: 0.018039
 81%|███████████████████████▌     | 325/400 [3:56:01<57:59, 46.39s/it]2022-01-08 13:49:48,902 iteration 5526 : loss : 0.022013, loss_ce: 0.006466
2022-01-08 13:49:51,232 iteration 5527 : loss : 0.012602, loss_ce: 0.005425
2022-01-08 13:49:53,692 iteration 5528 : loss : 0.018890, loss_ce: 0.007241
2022-01-08 13:49:56,005 iteration 5529 : loss : 0.014953, loss_ce: 0.004941
2022-01-08 13:49:58,271 iteration 5530 : loss : 0.012818, loss_ce: 0.005044
2022-01-08 13:50:00,589 iteration 5531 : loss : 0.010207, loss_ce: 0.003142
2022-01-08 13:50:02,908 iteration 5532 : loss : 0.018842, loss_ce: 0.006732
2022-01-08 13:50:05,365 iteration 5533 : loss : 0.015347, loss_ce: 0.007007
2022-01-08 13:50:07,704 iteration 5534 : loss : 0.011627, loss_ce: 0.004509
2022-01-08 13:50:10,046 iteration 5535 : loss : 0.018393, loss_ce: 0.006637
2022-01-08 13:50:12,511 iteration 5536 : loss : 0.014647, loss_ce: 0.004630
2022-01-08 13:50:14,929 iteration 5537 : loss : 0.017575, loss_ce: 0.007316
2022-01-08 13:50:17,329 iteration 5538 : loss : 0.016367, loss_ce: 0.004726
2022-01-08 13:50:19,708 iteration 5539 : loss : 0.015678, loss_ce: 0.005932
2022-01-08 13:50:22,082 iteration 5540 : loss : 0.016006, loss_ce: 0.006116
2022-01-08 13:50:24,543 iteration 5541 : loss : 0.029012, loss_ce: 0.011196
2022-01-08 13:50:26,878 iteration 5542 : loss : 0.014639, loss_ce: 0.005867
 82%|███████████████████████▋     | 326/400 [3:56:41<54:58, 44.57s/it]2022-01-08 13:50:29,311 iteration 5543 : loss : 0.014558, loss_ce: 0.006484
2022-01-08 13:50:31,688 iteration 5544 : loss : 0.013253, loss_ce: 0.004800
2022-01-08 13:50:34,146 iteration 5545 : loss : 0.013869, loss_ce: 0.006598
2022-01-08 13:50:36,601 iteration 5546 : loss : 0.024625, loss_ce: 0.006178
2022-01-08 13:50:39,049 iteration 5547 : loss : 0.015072, loss_ce: 0.005623
2022-01-08 13:50:41,608 iteration 5548 : loss : 0.025319, loss_ce: 0.004961
2022-01-08 13:50:44,021 iteration 5549 : loss : 0.012400, loss_ce: 0.003388
2022-01-08 13:50:46,413 iteration 5550 : loss : 0.014433, loss_ce: 0.004736
2022-01-08 13:50:48,725 iteration 5551 : loss : 0.018269, loss_ce: 0.008629
2022-01-08 13:50:51,221 iteration 5552 : loss : 0.010466, loss_ce: 0.003658
2022-01-08 13:50:53,640 iteration 5553 : loss : 0.016167, loss_ce: 0.006555
2022-01-08 13:50:56,060 iteration 5554 : loss : 0.015709, loss_ce: 0.006583
2022-01-08 13:50:58,561 iteration 5555 : loss : 0.014417, loss_ce: 0.006286
2022-01-08 13:51:01,019 iteration 5556 : loss : 0.019448, loss_ce: 0.006832
2022-01-08 13:51:03,407 iteration 5557 : loss : 0.012082, loss_ce: 0.005500
2022-01-08 13:51:05,739 iteration 5558 : loss : 0.022189, loss_ce: 0.007523
2022-01-08 13:51:08,055 iteration 5559 : loss : 0.019791, loss_ce: 0.005794
 82%|███████████████████████▋     | 327/400 [3:57:22<52:59, 43.56s/it]2022-01-08 13:51:10,482 iteration 5560 : loss : 0.014257, loss_ce: 0.004884
2022-01-08 13:51:12,830 iteration 5561 : loss : 0.013732, loss_ce: 0.004573
2022-01-08 13:51:15,247 iteration 5562 : loss : 0.012414, loss_ce: 0.005529
2022-01-08 13:51:17,672 iteration 5563 : loss : 0.014392, loss_ce: 0.006408
2022-01-08 13:51:20,109 iteration 5564 : loss : 0.015622, loss_ce: 0.007302
2022-01-08 13:51:22,584 iteration 5565 : loss : 0.022435, loss_ce: 0.008578
2022-01-08 13:51:25,023 iteration 5566 : loss : 0.017298, loss_ce: 0.007605
2022-01-08 13:51:27,453 iteration 5567 : loss : 0.014977, loss_ce: 0.007381
2022-01-08 13:51:29,860 iteration 5568 : loss : 0.019835, loss_ce: 0.006641
2022-01-08 13:51:32,240 iteration 5569 : loss : 0.015925, loss_ce: 0.005910
2022-01-08 13:51:34,684 iteration 5570 : loss : 0.010809, loss_ce: 0.002967
2022-01-08 13:51:37,027 iteration 5571 : loss : 0.009892, loss_ce: 0.003637
2022-01-08 13:51:39,392 iteration 5572 : loss : 0.013538, loss_ce: 0.004235
2022-01-08 13:51:41,842 iteration 5573 : loss : 0.009259, loss_ce: 0.002700
2022-01-08 13:51:44,240 iteration 5574 : loss : 0.013026, loss_ce: 0.003948
2022-01-08 13:51:46,680 iteration 5575 : loss : 0.016830, loss_ce: 0.004771
2022-01-08 13:51:49,231 iteration 5576 : loss : 0.018387, loss_ce: 0.006104
 82%|███████████████████████▊     | 328/400 [3:58:03<51:24, 42.84s/it]2022-01-08 13:51:51,869 iteration 5577 : loss : 0.018055, loss_ce: 0.008743
2022-01-08 13:51:54,295 iteration 5578 : loss : 0.019699, loss_ce: 0.006061
2022-01-08 13:51:56,718 iteration 5579 : loss : 0.022846, loss_ce: 0.011167
2022-01-08 13:51:58,996 iteration 5580 : loss : 0.015901, loss_ce: 0.005991
2022-01-08 13:52:01,248 iteration 5581 : loss : 0.010479, loss_ce: 0.004059
2022-01-08 13:52:03,637 iteration 5582 : loss : 0.011123, loss_ce: 0.003162
2022-01-08 13:52:05,954 iteration 5583 : loss : 0.008805, loss_ce: 0.003223
2022-01-08 13:52:08,423 iteration 5584 : loss : 0.019613, loss_ce: 0.008327
2022-01-08 13:52:10,788 iteration 5585 : loss : 0.013755, loss_ce: 0.003914
2022-01-08 13:52:13,239 iteration 5586 : loss : 0.024756, loss_ce: 0.006978
2022-01-08 13:52:15,626 iteration 5587 : loss : 0.013476, loss_ce: 0.005344
2022-01-08 13:52:18,077 iteration 5588 : loss : 0.012731, loss_ce: 0.004782
2022-01-08 13:52:20,459 iteration 5589 : loss : 0.009710, loss_ce: 0.002806
2022-01-08 13:52:22,789 iteration 5590 : loss : 0.011024, loss_ce: 0.002600
2022-01-08 13:52:25,110 iteration 5591 : loss : 0.014236, loss_ce: 0.006716
2022-01-08 13:52:27,602 iteration 5592 : loss : 0.019366, loss_ce: 0.006889
2022-01-08 13:52:30,004 iteration 5593 : loss : 0.016464, loss_ce: 0.007220
 82%|███████████████████████▊     | 329/400 [3:58:44<49:57, 42.22s/it]2022-01-08 13:52:32,486 iteration 5594 : loss : 0.014994, loss_ce: 0.004154
2022-01-08 13:52:34,905 iteration 5595 : loss : 0.014835, loss_ce: 0.006314
2022-01-08 13:52:37,341 iteration 5596 : loss : 0.015069, loss_ce: 0.005641
2022-01-08 13:52:39,783 iteration 5597 : loss : 0.012281, loss_ce: 0.004587
2022-01-08 13:52:42,069 iteration 5598 : loss : 0.009640, loss_ce: 0.004066
2022-01-08 13:52:44,386 iteration 5599 : loss : 0.017327, loss_ce: 0.007288
2022-01-08 13:52:46,787 iteration 5600 : loss : 0.010912, loss_ce: 0.004421
2022-01-08 13:52:49,128 iteration 5601 : loss : 0.010163, loss_ce: 0.003765
2022-01-08 13:52:51,677 iteration 5602 : loss : 0.012980, loss_ce: 0.005762
2022-01-08 13:52:54,032 iteration 5603 : loss : 0.009803, loss_ce: 0.003941
2022-01-08 13:52:56,391 iteration 5604 : loss : 0.026786, loss_ce: 0.008514
2022-01-08 13:52:58,722 iteration 5605 : loss : 0.018604, loss_ce: 0.008445
2022-01-08 13:53:01,001 iteration 5606 : loss : 0.014888, loss_ce: 0.005429
2022-01-08 13:53:03,318 iteration 5607 : loss : 0.014672, loss_ce: 0.004810
2022-01-08 13:53:05,675 iteration 5608 : loss : 0.013518, loss_ce: 0.003862
2022-01-08 13:53:08,062 iteration 5609 : loss : 0.011332, loss_ce: 0.004919
2022-01-08 13:53:08,062 Training Data Eval:
2022-01-08 13:53:20,754   Average segmentation loss on training set: 0.0087
2022-01-08 13:53:20,754 Validation Data Eval:
2022-01-08 13:53:25,089   Average segmentation loss on validation set: 0.0793
2022-01-08 13:53:27,412 iteration 5610 : loss : 0.014241, loss_ce: 0.004773
 82%|███████████████████████▉     | 330/400 [3:59:42<54:34, 46.77s/it]2022-01-08 13:53:29,758 iteration 5611 : loss : 0.024107, loss_ce: 0.008634
2022-01-08 13:53:32,181 iteration 5612 : loss : 0.025022, loss_ce: 0.004951
2022-01-08 13:53:34,563 iteration 5613 : loss : 0.013347, loss_ce: 0.005152
2022-01-08 13:53:36,870 iteration 5614 : loss : 0.012929, loss_ce: 0.004923
2022-01-08 13:53:39,115 iteration 5615 : loss : 0.009443, loss_ce: 0.003942
2022-01-08 13:53:41,454 iteration 5616 : loss : 0.017891, loss_ce: 0.008098
2022-01-08 13:53:43,812 iteration 5617 : loss : 0.011858, loss_ce: 0.004157
2022-01-08 13:53:46,144 iteration 5618 : loss : 0.012855, loss_ce: 0.005052
2022-01-08 13:53:48,473 iteration 5619 : loss : 0.028299, loss_ce: 0.008093
2022-01-08 13:53:50,884 iteration 5620 : loss : 0.011899, loss_ce: 0.004486
2022-01-08 13:53:53,115 iteration 5621 : loss : 0.013887, loss_ce: 0.004879
2022-01-08 13:53:55,477 iteration 5622 : loss : 0.016787, loss_ce: 0.006671
2022-01-08 13:53:57,909 iteration 5623 : loss : 0.028015, loss_ce: 0.009731
2022-01-08 13:54:00,149 iteration 5624 : loss : 0.017468, loss_ce: 0.004562
2022-01-08 13:54:02,366 iteration 5625 : loss : 0.014973, loss_ce: 0.007315
2022-01-08 13:54:04,711 iteration 5626 : loss : 0.015873, loss_ce: 0.003991
2022-01-08 13:54:07,119 iteration 5627 : loss : 0.013312, loss_ce: 0.005164
 83%|███████████████████████▉     | 331/400 [4:00:21<51:21, 44.66s/it]2022-01-08 13:54:09,564 iteration 5628 : loss : 0.016264, loss_ce: 0.007646
2022-01-08 13:54:11,853 iteration 5629 : loss : 0.010858, loss_ce: 0.004310
2022-01-08 13:54:14,272 iteration 5630 : loss : 0.020628, loss_ce: 0.009580
2022-01-08 13:54:16,597 iteration 5631 : loss : 0.014853, loss_ce: 0.005909
2022-01-08 13:54:18,986 iteration 5632 : loss : 0.015387, loss_ce: 0.006892
2022-01-08 13:54:21,350 iteration 5633 : loss : 0.025322, loss_ce: 0.007592
2022-01-08 13:54:23,676 iteration 5634 : loss : 0.011231, loss_ce: 0.004392
2022-01-08 13:54:26,012 iteration 5635 : loss : 0.017210, loss_ce: 0.007928
2022-01-08 13:54:28,417 iteration 5636 : loss : 0.019632, loss_ce: 0.005556
2022-01-08 13:54:30,686 iteration 5637 : loss : 0.014884, loss_ce: 0.004531
2022-01-08 13:54:32,964 iteration 5638 : loss : 0.014767, loss_ce: 0.006111
2022-01-08 13:54:35,270 iteration 5639 : loss : 0.014787, loss_ce: 0.005431
2022-01-08 13:54:37,675 iteration 5640 : loss : 0.016198, loss_ce: 0.006950
2022-01-08 13:54:39,954 iteration 5641 : loss : 0.012139, loss_ce: 0.003460
2022-01-08 13:54:42,166 iteration 5642 : loss : 0.015006, loss_ce: 0.006065
2022-01-08 13:54:44,429 iteration 5643 : loss : 0.014645, loss_ce: 0.005141
2022-01-08 13:54:46,653 iteration 5644 : loss : 0.011224, loss_ce: 0.004624
 83%|████████████████████████     | 332/400 [4:01:01<48:52, 43.12s/it]2022-01-08 13:54:48,934 iteration 5645 : loss : 0.015878, loss_ce: 0.005453
2022-01-08 13:54:51,283 iteration 5646 : loss : 0.015079, loss_ce: 0.004145
2022-01-08 13:54:53,704 iteration 5647 : loss : 0.013644, loss_ce: 0.004276
2022-01-08 13:54:56,065 iteration 5648 : loss : 0.016537, loss_ce: 0.004993
2022-01-08 13:54:58,326 iteration 5649 : loss : 0.013559, loss_ce: 0.005199
2022-01-08 13:55:00,643 iteration 5650 : loss : 0.015374, loss_ce: 0.004428
2022-01-08 13:55:03,007 iteration 5651 : loss : 0.012168, loss_ce: 0.005924
2022-01-08 13:55:05,334 iteration 5652 : loss : 0.015750, loss_ce: 0.006226
2022-01-08 13:55:07,650 iteration 5653 : loss : 0.013242, loss_ce: 0.004673
2022-01-08 13:55:10,038 iteration 5654 : loss : 0.015661, loss_ce: 0.006574
2022-01-08 13:55:12,349 iteration 5655 : loss : 0.023733, loss_ce: 0.007469
2022-01-08 13:55:14,790 iteration 5656 : loss : 0.017970, loss_ce: 0.007953
2022-01-08 13:55:17,152 iteration 5657 : loss : 0.017406, loss_ce: 0.008871
2022-01-08 13:55:19,596 iteration 5658 : loss : 0.027511, loss_ce: 0.008621
2022-01-08 13:55:21,981 iteration 5659 : loss : 0.029341, loss_ce: 0.012395
2022-01-08 13:55:24,182 iteration 5660 : loss : 0.009891, loss_ce: 0.003705
2022-01-08 13:55:26,564 iteration 5661 : loss : 0.018451, loss_ce: 0.007050
 83%|████████████████████████▏    | 333/400 [4:01:41<47:04, 42.16s/it]2022-01-08 13:55:28,923 iteration 5662 : loss : 0.013452, loss_ce: 0.005757
2022-01-08 13:55:31,352 iteration 5663 : loss : 0.013369, loss_ce: 0.005847
2022-01-08 13:55:33,757 iteration 5664 : loss : 0.017775, loss_ce: 0.006361
2022-01-08 13:55:35,997 iteration 5665 : loss : 0.010924, loss_ce: 0.002365
2022-01-08 13:55:38,353 iteration 5666 : loss : 0.012548, loss_ce: 0.004295
2022-01-08 13:55:40,675 iteration 5667 : loss : 0.013682, loss_ce: 0.004212
2022-01-08 13:55:43,005 iteration 5668 : loss : 0.016902, loss_ce: 0.006054
2022-01-08 13:55:45,369 iteration 5669 : loss : 0.016164, loss_ce: 0.007797
2022-01-08 13:55:47,672 iteration 5670 : loss : 0.016983, loss_ce: 0.005887
2022-01-08 13:55:50,035 iteration 5671 : loss : 0.019722, loss_ce: 0.005473
2022-01-08 13:55:52,292 iteration 5672 : loss : 0.013387, loss_ce: 0.003518
2022-01-08 13:55:54,614 iteration 5673 : loss : 0.017381, loss_ce: 0.009064
2022-01-08 13:55:56,966 iteration 5674 : loss : 0.017124, loss_ce: 0.005760
2022-01-08 13:55:59,454 iteration 5675 : loss : 0.024328, loss_ce: 0.009999
2022-01-08 13:56:01,812 iteration 5676 : loss : 0.016118, loss_ce: 0.008368
2022-01-08 13:56:04,157 iteration 5677 : loss : 0.020255, loss_ce: 0.007930
2022-01-08 13:56:06,478 iteration 5678 : loss : 0.017035, loss_ce: 0.007228
 84%|████████████████████████▏    | 334/400 [4:02:21<45:37, 41.48s/it]2022-01-08 13:56:08,831 iteration 5679 : loss : 0.015011, loss_ce: 0.005072
2022-01-08 13:56:11,209 iteration 5680 : loss : 0.012636, loss_ce: 0.005657
2022-01-08 13:56:13,630 iteration 5681 : loss : 0.024540, loss_ce: 0.006829
2022-01-08 13:56:15,898 iteration 5682 : loss : 0.011173, loss_ce: 0.003758
2022-01-08 13:56:18,125 iteration 5683 : loss : 0.009414, loss_ce: 0.004095
2022-01-08 13:56:20,574 iteration 5684 : loss : 0.012512, loss_ce: 0.006230
2022-01-08 13:56:22,941 iteration 5685 : loss : 0.016716, loss_ce: 0.005273
2022-01-08 13:56:25,217 iteration 5686 : loss : 0.014846, loss_ce: 0.005233
2022-01-08 13:56:27,557 iteration 5687 : loss : 0.013195, loss_ce: 0.003982
2022-01-08 13:56:29,963 iteration 5688 : loss : 0.021331, loss_ce: 0.008103
2022-01-08 13:56:32,356 iteration 5689 : loss : 0.012860, loss_ce: 0.005394
2022-01-08 13:56:34,677 iteration 5690 : loss : 0.011106, loss_ce: 0.003595
2022-01-08 13:56:37,039 iteration 5691 : loss : 0.011480, loss_ce: 0.005232
2022-01-08 13:56:39,364 iteration 5692 : loss : 0.009194, loss_ce: 0.002639
2022-01-08 13:56:41,655 iteration 5693 : loss : 0.010775, loss_ce: 0.004542
2022-01-08 13:56:44,087 iteration 5694 : loss : 0.015303, loss_ce: 0.006117
2022-01-08 13:56:44,087 Training Data Eval:
2022-01-08 13:56:56,644   Average segmentation loss on training set: 0.0077
2022-01-08 13:56:56,645 Validation Data Eval:
2022-01-08 13:57:01,120   Average segmentation loss on validation set: 0.0779
2022-01-08 13:57:03,524 iteration 5695 : loss : 0.016385, loss_ce: 0.006228
 84%|████████████████████████▎    | 335/400 [4:03:18<49:59, 46.15s/it]2022-01-08 13:57:05,955 iteration 5696 : loss : 0.016235, loss_ce: 0.005202
2022-01-08 13:57:08,288 iteration 5697 : loss : 0.010500, loss_ce: 0.002961
2022-01-08 13:57:10,650 iteration 5698 : loss : 0.020211, loss_ce: 0.007437
2022-01-08 13:57:13,051 iteration 5699 : loss : 0.013219, loss_ce: 0.003456
2022-01-08 13:57:15,380 iteration 5700 : loss : 0.011597, loss_ce: 0.005011
2022-01-08 13:57:17,789 iteration 5701 : loss : 0.025911, loss_ce: 0.004522
2022-01-08 13:57:20,092 iteration 5702 : loss : 0.013674, loss_ce: 0.005361
2022-01-08 13:57:22,509 iteration 5703 : loss : 0.012418, loss_ce: 0.005713
2022-01-08 13:57:24,794 iteration 5704 : loss : 0.014645, loss_ce: 0.007494
2022-01-08 13:57:27,081 iteration 5705 : loss : 0.012407, loss_ce: 0.005178
2022-01-08 13:57:29,378 iteration 5706 : loss : 0.012349, loss_ce: 0.004813
2022-01-08 13:57:31,699 iteration 5707 : loss : 0.020885, loss_ce: 0.005291
2022-01-08 13:57:33,906 iteration 5708 : loss : 0.014939, loss_ce: 0.007709
2022-01-08 13:57:36,070 iteration 5709 : loss : 0.014734, loss_ce: 0.005007
2022-01-08 13:57:38,339 iteration 5710 : loss : 0.013386, loss_ce: 0.006389
2022-01-08 13:57:40,619 iteration 5711 : loss : 0.013856, loss_ce: 0.006246
2022-01-08 13:57:42,918 iteration 5712 : loss : 0.014897, loss_ce: 0.006476
 84%|████████████████████████▎    | 336/400 [4:03:57<47:04, 44.13s/it]2022-01-08 13:57:45,222 iteration 5713 : loss : 0.011599, loss_ce: 0.005246
2022-01-08 13:57:47,490 iteration 5714 : loss : 0.015922, loss_ce: 0.006276
2022-01-08 13:57:49,728 iteration 5715 : loss : 0.012583, loss_ce: 0.004751
2022-01-08 13:57:52,105 iteration 5716 : loss : 0.014893, loss_ce: 0.005653
2022-01-08 13:57:54,351 iteration 5717 : loss : 0.010293, loss_ce: 0.004361
2022-01-08 13:57:56,743 iteration 5718 : loss : 0.016075, loss_ce: 0.007052
2022-01-08 13:57:59,158 iteration 5719 : loss : 0.017915, loss_ce: 0.005059
2022-01-08 13:58:01,496 iteration 5720 : loss : 0.021821, loss_ce: 0.009564
2022-01-08 13:58:03,719 iteration 5721 : loss : 0.013734, loss_ce: 0.003877
2022-01-08 13:58:06,028 iteration 5722 : loss : 0.014753, loss_ce: 0.005327
2022-01-08 13:58:08,449 iteration 5723 : loss : 0.022580, loss_ce: 0.007959
2022-01-08 13:58:10,819 iteration 5724 : loss : 0.014308, loss_ce: 0.005688
2022-01-08 13:58:13,174 iteration 5725 : loss : 0.013051, loss_ce: 0.005306
2022-01-08 13:58:15,553 iteration 5726 : loss : 0.009195, loss_ce: 0.003538
2022-01-08 13:58:17,832 iteration 5727 : loss : 0.016870, loss_ce: 0.008436
2022-01-08 13:58:20,097 iteration 5728 : loss : 0.013553, loss_ce: 0.004207
2022-01-08 13:58:22,398 iteration 5729 : loss : 0.014170, loss_ce: 0.003979
 84%|████████████████████████▍    | 337/400 [4:04:37<44:51, 42.73s/it]2022-01-08 13:58:24,908 iteration 5730 : loss : 0.021121, loss_ce: 0.007680
2022-01-08 13:58:27,282 iteration 5731 : loss : 0.018987, loss_ce: 0.006544
2022-01-08 13:58:29,625 iteration 5732 : loss : 0.019930, loss_ce: 0.004280
2022-01-08 13:58:31,881 iteration 5733 : loss : 0.018089, loss_ce: 0.007211
2022-01-08 13:58:34,059 iteration 5734 : loss : 0.010088, loss_ce: 0.003734
2022-01-08 13:58:36,364 iteration 5735 : loss : 0.018039, loss_ce: 0.005974
2022-01-08 13:58:38,662 iteration 5736 : loss : 0.014957, loss_ce: 0.006065
2022-01-08 13:58:40,924 iteration 5737 : loss : 0.013128, loss_ce: 0.005694
2022-01-08 13:58:43,173 iteration 5738 : loss : 0.013233, loss_ce: 0.005555
2022-01-08 13:58:45,542 iteration 5739 : loss : 0.012158, loss_ce: 0.003726
2022-01-08 13:58:47,879 iteration 5740 : loss : 0.019113, loss_ce: 0.008132
2022-01-08 13:58:50,217 iteration 5741 : loss : 0.015208, loss_ce: 0.006577
2022-01-08 13:58:52,609 iteration 5742 : loss : 0.021396, loss_ce: 0.003899
2022-01-08 13:58:54,981 iteration 5743 : loss : 0.019830, loss_ce: 0.006078
2022-01-08 13:58:57,315 iteration 5744 : loss : 0.013509, loss_ce: 0.005930
2022-01-08 13:58:59,675 iteration 5745 : loss : 0.010531, loss_ce: 0.003469
2022-01-08 13:59:02,008 iteration 5746 : loss : 0.014288, loss_ce: 0.006682
 84%|████████████████████████▌    | 338/400 [4:05:16<43:11, 41.80s/it]2022-01-08 13:59:04,440 iteration 5747 : loss : 0.015932, loss_ce: 0.005847
2022-01-08 13:59:06,705 iteration 5748 : loss : 0.014231, loss_ce: 0.005314
2022-01-08 13:59:09,069 iteration 5749 : loss : 0.018710, loss_ce: 0.008727
2022-01-08 13:59:11,429 iteration 5750 : loss : 0.016818, loss_ce: 0.004128
2022-01-08 13:59:13,764 iteration 5751 : loss : 0.023489, loss_ce: 0.009593
2022-01-08 13:59:16,083 iteration 5752 : loss : 0.015102, loss_ce: 0.005632
2022-01-08 13:59:18,471 iteration 5753 : loss : 0.014257, loss_ce: 0.006030
2022-01-08 13:59:20,801 iteration 5754 : loss : 0.020473, loss_ce: 0.006095
2022-01-08 13:59:23,196 iteration 5755 : loss : 0.016921, loss_ce: 0.004951
2022-01-08 13:59:25,504 iteration 5756 : loss : 0.014282, loss_ce: 0.006877
2022-01-08 13:59:27,815 iteration 5757 : loss : 0.016559, loss_ce: 0.005659
2022-01-08 13:59:30,045 iteration 5758 : loss : 0.012154, loss_ce: 0.004476
2022-01-08 13:59:32,462 iteration 5759 : loss : 0.012232, loss_ce: 0.003520
2022-01-08 13:59:34,830 iteration 5760 : loss : 0.011806, loss_ce: 0.004358
2022-01-08 13:59:37,156 iteration 5761 : loss : 0.018444, loss_ce: 0.005854
2022-01-08 13:59:39,505 iteration 5762 : loss : 0.024153, loss_ce: 0.009067
2022-01-08 13:59:41,830 iteration 5763 : loss : 0.014018, loss_ce: 0.005816
 85%|████████████████████████▌    | 339/400 [4:05:56<41:53, 41.20s/it]2022-01-08 13:59:44,165 iteration 5764 : loss : 0.013721, loss_ce: 0.006596
2022-01-08 13:59:46,448 iteration 5765 : loss : 0.026815, loss_ce: 0.010512
2022-01-08 13:59:48,729 iteration 5766 : loss : 0.012863, loss_ce: 0.004611
2022-01-08 13:59:51,106 iteration 5767 : loss : 0.016019, loss_ce: 0.006785
2022-01-08 13:59:53,464 iteration 5768 : loss : 0.023626, loss_ce: 0.006739
2022-01-08 13:59:55,791 iteration 5769 : loss : 0.012875, loss_ce: 0.003527
2022-01-08 13:59:58,101 iteration 5770 : loss : 0.016313, loss_ce: 0.006305
2022-01-08 14:00:00,316 iteration 5771 : loss : 0.009565, loss_ce: 0.003951
2022-01-08 14:00:02,598 iteration 5772 : loss : 0.016251, loss_ce: 0.005599
2022-01-08 14:00:04,828 iteration 5773 : loss : 0.011363, loss_ce: 0.004064
2022-01-08 14:00:07,125 iteration 5774 : loss : 0.012604, loss_ce: 0.004728
2022-01-08 14:00:09,488 iteration 5775 : loss : 0.017475, loss_ce: 0.006470
2022-01-08 14:00:11,694 iteration 5776 : loss : 0.011503, loss_ce: 0.004519
2022-01-08 14:00:14,013 iteration 5777 : loss : 0.010541, loss_ce: 0.003620
2022-01-08 14:00:16,345 iteration 5778 : loss : 0.011356, loss_ce: 0.003919
2022-01-08 14:00:18,656 iteration 5779 : loss : 0.009623, loss_ce: 0.004317
2022-01-08 14:00:18,657 Training Data Eval:
2022-01-08 14:00:30,842   Average segmentation loss on training set: 0.0075
2022-01-08 14:00:30,842 Validation Data Eval:
2022-01-08 14:00:35,325   Average segmentation loss on validation set: 0.0667
2022-01-08 14:00:37,725 iteration 5780 : loss : 0.011605, loss_ce: 0.004611
 85%|████████████████████████▋    | 340/400 [4:06:52<45:36, 45.62s/it]2022-01-08 14:00:40,143 iteration 5781 : loss : 0.018354, loss_ce: 0.006947
2022-01-08 14:00:42,430 iteration 5782 : loss : 0.009561, loss_ce: 0.003404
2022-01-08 14:00:44,756 iteration 5783 : loss : 0.016229, loss_ce: 0.005067
2022-01-08 14:00:47,093 iteration 5784 : loss : 0.014249, loss_ce: 0.004033
2022-01-08 14:00:49,413 iteration 5785 : loss : 0.010713, loss_ce: 0.005030
2022-01-08 14:00:51,862 iteration 5786 : loss : 0.011419, loss_ce: 0.004563
2022-01-08 14:00:54,252 iteration 5787 : loss : 0.013556, loss_ce: 0.004519
2022-01-08 14:00:56,645 iteration 5788 : loss : 0.013448, loss_ce: 0.005432
2022-01-08 14:00:58,989 iteration 5789 : loss : 0.013883, loss_ce: 0.004050
2022-01-08 14:01:01,317 iteration 5790 : loss : 0.015992, loss_ce: 0.008011
2022-01-08 14:01:03,746 iteration 5791 : loss : 0.013472, loss_ce: 0.005321
2022-01-08 14:01:06,166 iteration 5792 : loss : 0.021626, loss_ce: 0.006624
2022-01-08 14:01:08,404 iteration 5793 : loss : 0.012278, loss_ce: 0.004684
2022-01-08 14:01:10,719 iteration 5794 : loss : 0.014137, loss_ce: 0.004558
2022-01-08 14:01:13,103 iteration 5795 : loss : 0.014217, loss_ce: 0.006204
2022-01-08 14:01:15,462 iteration 5796 : loss : 0.015267, loss_ce: 0.007106
2022-01-08 14:01:17,869 iteration 5797 : loss : 0.018444, loss_ce: 0.005781
 85%|████████████████████████▋    | 341/400 [4:07:32<43:14, 43.97s/it]2022-01-08 14:01:20,259 iteration 5798 : loss : 0.014519, loss_ce: 0.004448
2022-01-08 14:01:22,631 iteration 5799 : loss : 0.018414, loss_ce: 0.006771
2022-01-08 14:01:24,892 iteration 5800 : loss : 0.008249, loss_ce: 0.003279
2022-01-08 14:01:27,243 iteration 5801 : loss : 0.014294, loss_ce: 0.006595
2022-01-08 14:01:29,700 iteration 5802 : loss : 0.012306, loss_ce: 0.005180
2022-01-08 14:01:32,109 iteration 5803 : loss : 0.014916, loss_ce: 0.004692
2022-01-08 14:01:34,404 iteration 5804 : loss : 0.016406, loss_ce: 0.005420
2022-01-08 14:01:36,693 iteration 5805 : loss : 0.012191, loss_ce: 0.004213
2022-01-08 14:01:39,036 iteration 5806 : loss : 0.010620, loss_ce: 0.004876
2022-01-08 14:01:41,437 iteration 5807 : loss : 0.020768, loss_ce: 0.007709
2022-01-08 14:01:43,839 iteration 5808 : loss : 0.029242, loss_ce: 0.010102
2022-01-08 14:01:46,232 iteration 5809 : loss : 0.014489, loss_ce: 0.005161
2022-01-08 14:01:48,649 iteration 5810 : loss : 0.018372, loss_ce: 0.004999
2022-01-08 14:01:51,002 iteration 5811 : loss : 0.017262, loss_ce: 0.007638
2022-01-08 14:01:53,290 iteration 5812 : loss : 0.012915, loss_ce: 0.005685
2022-01-08 14:01:55,617 iteration 5813 : loss : 0.013941, loss_ce: 0.004470
2022-01-08 14:01:57,977 iteration 5814 : loss : 0.020117, loss_ce: 0.006630
 86%|████████████████████████▊    | 342/400 [4:08:12<41:23, 42.82s/it]2022-01-08 14:02:00,473 iteration 5815 : loss : 0.020638, loss_ce: 0.008810
2022-01-08 14:02:02,782 iteration 5816 : loss : 0.013563, loss_ce: 0.004833
2022-01-08 14:02:05,433 iteration 5817 : loss : 0.019076, loss_ce: 0.008671
2022-01-08 14:02:07,850 iteration 5818 : loss : 0.017226, loss_ce: 0.007222
2022-01-08 14:02:10,138 iteration 5819 : loss : 0.014145, loss_ce: 0.004321
2022-01-08 14:02:12,444 iteration 5820 : loss : 0.023474, loss_ce: 0.008855
2022-01-08 14:02:14,765 iteration 5821 : loss : 0.013176, loss_ce: 0.004626
2022-01-08 14:02:17,140 iteration 5822 : loss : 0.017675, loss_ce: 0.005648
2022-01-08 14:02:19,349 iteration 5823 : loss : 0.011611, loss_ce: 0.005395
2022-01-08 14:02:21,844 iteration 5824 : loss : 0.021651, loss_ce: 0.004306
2022-01-08 14:02:24,268 iteration 5825 : loss : 0.011647, loss_ce: 0.004377
2022-01-08 14:02:26,668 iteration 5826 : loss : 0.013134, loss_ce: 0.005887
2022-01-08 14:02:28,965 iteration 5827 : loss : 0.012617, loss_ce: 0.004887
2022-01-08 14:02:31,410 iteration 5828 : loss : 0.042617, loss_ce: 0.007072
2022-01-08 14:02:33,783 iteration 5829 : loss : 0.014850, loss_ce: 0.005003
2022-01-08 14:02:36,110 iteration 5830 : loss : 0.022404, loss_ce: 0.009740
2022-01-08 14:02:38,562 iteration 5831 : loss : 0.019992, loss_ce: 0.007479
 86%|████████████████████████▊    | 343/400 [4:08:53<40:02, 42.15s/it]2022-01-08 14:02:41,209 iteration 5832 : loss : 0.022103, loss_ce: 0.010401
2022-01-08 14:02:43,672 iteration 5833 : loss : 0.020633, loss_ce: 0.007409
2022-01-08 14:02:45,976 iteration 5834 : loss : 0.019067, loss_ce: 0.009317
2022-01-08 14:02:48,306 iteration 5835 : loss : 0.017881, loss_ce: 0.007311
2022-01-08 14:02:50,592 iteration 5836 : loss : 0.019202, loss_ce: 0.006319
2022-01-08 14:02:52,953 iteration 5837 : loss : 0.017371, loss_ce: 0.006425
2022-01-08 14:02:55,206 iteration 5838 : loss : 0.017521, loss_ce: 0.004932
2022-01-08 14:02:57,452 iteration 5839 : loss : 0.022310, loss_ce: 0.010147
2022-01-08 14:02:59,798 iteration 5840 : loss : 0.011973, loss_ce: 0.004318
2022-01-08 14:03:02,217 iteration 5841 : loss : 0.015569, loss_ce: 0.004992
2022-01-08 14:03:04,563 iteration 5842 : loss : 0.016020, loss_ce: 0.005036
2022-01-08 14:03:06,919 iteration 5843 : loss : 0.011719, loss_ce: 0.004452
2022-01-08 14:03:09,300 iteration 5844 : loss : 0.016866, loss_ce: 0.006514
2022-01-08 14:03:11,581 iteration 5845 : loss : 0.012608, loss_ce: 0.004885
2022-01-08 14:03:13,822 iteration 5846 : loss : 0.010439, loss_ce: 0.004398
2022-01-08 14:03:16,029 iteration 5847 : loss : 0.014060, loss_ce: 0.005070
2022-01-08 14:03:18,246 iteration 5848 : loss : 0.012575, loss_ce: 0.004486
 86%|████████████████████████▉    | 344/400 [4:09:33<38:38, 41.41s/it]2022-01-08 14:03:20,518 iteration 5849 : loss : 0.017531, loss_ce: 0.004923
2022-01-08 14:03:22,865 iteration 5850 : loss : 0.015051, loss_ce: 0.006656
2022-01-08 14:03:25,215 iteration 5851 : loss : 0.013411, loss_ce: 0.003109
2022-01-08 14:03:27,544 iteration 5852 : loss : 0.020059, loss_ce: 0.009563
2022-01-08 14:03:29,949 iteration 5853 : loss : 0.018577, loss_ce: 0.006593
2022-01-08 14:03:32,373 iteration 5854 : loss : 0.015128, loss_ce: 0.005637
2022-01-08 14:03:34,671 iteration 5855 : loss : 0.013442, loss_ce: 0.005856
2022-01-08 14:03:36,994 iteration 5856 : loss : 0.016446, loss_ce: 0.006726
2022-01-08 14:03:39,443 iteration 5857 : loss : 0.013621, loss_ce: 0.005125
2022-01-08 14:03:41,865 iteration 5858 : loss : 0.014760, loss_ce: 0.004323
2022-01-08 14:03:44,377 iteration 5859 : loss : 0.014174, loss_ce: 0.005172
2022-01-08 14:03:46,773 iteration 5860 : loss : 0.013750, loss_ce: 0.004873
2022-01-08 14:03:49,086 iteration 5861 : loss : 0.017025, loss_ce: 0.007134
2022-01-08 14:03:51,408 iteration 5862 : loss : 0.013879, loss_ce: 0.005584
2022-01-08 14:03:53,728 iteration 5863 : loss : 0.023715, loss_ce: 0.006951
2022-01-08 14:03:56,114 iteration 5864 : loss : 0.016217, loss_ce: 0.007569
2022-01-08 14:03:56,114 Training Data Eval:
2022-01-08 14:04:09,037   Average segmentation loss on training set: 0.0082
2022-01-08 14:04:09,038 Validation Data Eval:
2022-01-08 14:04:13,659   Average segmentation loss on validation set: 0.0786
2022-01-08 14:04:16,114 iteration 5865 : loss : 0.022110, loss_ce: 0.006125
 86%|█████████████████████████    | 345/400 [4:10:30<42:28, 46.34s/it]2022-01-08 14:04:18,459 iteration 5866 : loss : 0.012209, loss_ce: 0.003057
2022-01-08 14:04:20,729 iteration 5867 : loss : 0.012638, loss_ce: 0.004934
2022-01-08 14:04:23,065 iteration 5868 : loss : 0.017346, loss_ce: 0.006856
2022-01-08 14:04:25,454 iteration 5869 : loss : 0.013475, loss_ce: 0.004216
2022-01-08 14:04:27,919 iteration 5870 : loss : 0.018055, loss_ce: 0.007154
2022-01-08 14:04:30,309 iteration 5871 : loss : 0.016330, loss_ce: 0.005520
2022-01-08 14:04:32,692 iteration 5872 : loss : 0.014853, loss_ce: 0.005225
2022-01-08 14:04:35,089 iteration 5873 : loss : 0.024036, loss_ce: 0.015127
2022-01-08 14:04:37,484 iteration 5874 : loss : 0.019539, loss_ce: 0.006105
2022-01-08 14:04:39,884 iteration 5875 : loss : 0.009691, loss_ce: 0.004561
2022-01-08 14:04:42,361 iteration 5876 : loss : 0.013985, loss_ce: 0.006347
2022-01-08 14:04:44,733 iteration 5877 : loss : 0.022101, loss_ce: 0.009183
2022-01-08 14:04:47,140 iteration 5878 : loss : 0.013245, loss_ce: 0.004429
2022-01-08 14:04:49,509 iteration 5879 : loss : 0.016762, loss_ce: 0.006748
2022-01-08 14:04:51,831 iteration 5880 : loss : 0.016386, loss_ce: 0.004510
2022-01-08 14:04:54,212 iteration 5881 : loss : 0.012372, loss_ce: 0.005241
2022-01-08 14:04:56,597 iteration 5882 : loss : 0.014021, loss_ce: 0.005508
 86%|█████████████████████████    | 346/400 [4:11:11<40:07, 44.58s/it]2022-01-08 14:04:58,997 iteration 5883 : loss : 0.012637, loss_ce: 0.003721
2022-01-08 14:05:01,396 iteration 5884 : loss : 0.010306, loss_ce: 0.003584
2022-01-08 14:05:03,834 iteration 5885 : loss : 0.013685, loss_ce: 0.003597
2022-01-08 14:05:06,167 iteration 5886 : loss : 0.013781, loss_ce: 0.004116
2022-01-08 14:05:08,549 iteration 5887 : loss : 0.013370, loss_ce: 0.004943
2022-01-08 14:05:10,930 iteration 5888 : loss : 0.009536, loss_ce: 0.003918
2022-01-08 14:05:13,376 iteration 5889 : loss : 0.011929, loss_ce: 0.003865
2022-01-08 14:05:15,702 iteration 5890 : loss : 0.013105, loss_ce: 0.005414
2022-01-08 14:05:18,186 iteration 5891 : loss : 0.027750, loss_ce: 0.008987
2022-01-08 14:05:20,579 iteration 5892 : loss : 0.025905, loss_ce: 0.009620
2022-01-08 14:05:22,894 iteration 5893 : loss : 0.013874, loss_ce: 0.005982
2022-01-08 14:05:25,128 iteration 5894 : loss : 0.014124, loss_ce: 0.006231
2022-01-08 14:05:27,384 iteration 5895 : loss : 0.009156, loss_ce: 0.003532
2022-01-08 14:05:29,880 iteration 5896 : loss : 0.016524, loss_ce: 0.006689
2022-01-08 14:05:32,331 iteration 5897 : loss : 0.013247, loss_ce: 0.005605
2022-01-08 14:05:34,697 iteration 5898 : loss : 0.017645, loss_ce: 0.006092
2022-01-08 14:05:37,076 iteration 5899 : loss : 0.018302, loss_ce: 0.008211
 87%|█████████████████████████▏   | 347/400 [4:11:51<38:17, 43.35s/it]2022-01-08 14:05:39,435 iteration 5900 : loss : 0.012422, loss_ce: 0.004368
2022-01-08 14:05:41,946 iteration 5901 : loss : 0.014393, loss_ce: 0.005604
2022-01-08 14:05:44,374 iteration 5902 : loss : 0.017199, loss_ce: 0.007845
2022-01-08 14:05:46,688 iteration 5903 : loss : 0.015615, loss_ce: 0.005300
2022-01-08 14:05:49,117 iteration 5904 : loss : 0.014041, loss_ce: 0.006349
2022-01-08 14:05:51,434 iteration 5905 : loss : 0.012645, loss_ce: 0.004697
2022-01-08 14:05:53,811 iteration 5906 : loss : 0.013217, loss_ce: 0.005600
2022-01-08 14:05:56,200 iteration 5907 : loss : 0.015392, loss_ce: 0.004818
2022-01-08 14:05:58,613 iteration 5908 : loss : 0.016176, loss_ce: 0.005740
2022-01-08 14:06:00,986 iteration 5909 : loss : 0.010163, loss_ce: 0.003962
2022-01-08 14:06:03,335 iteration 5910 : loss : 0.014833, loss_ce: 0.006135
2022-01-08 14:06:05,661 iteration 5911 : loss : 0.012857, loss_ce: 0.005059
2022-01-08 14:06:08,165 iteration 5912 : loss : 0.036055, loss_ce: 0.005504
2022-01-08 14:06:10,536 iteration 5913 : loss : 0.014436, loss_ce: 0.004943
2022-01-08 14:06:12,963 iteration 5914 : loss : 0.016899, loss_ce: 0.007120
2022-01-08 14:06:15,262 iteration 5915 : loss : 0.024920, loss_ce: 0.010204
2022-01-08 14:06:17,528 iteration 5916 : loss : 0.014755, loss_ce: 0.005827
 87%|█████████████████████████▏   | 348/400 [4:12:32<36:48, 42.48s/it]2022-01-08 14:06:19,937 iteration 5917 : loss : 0.018062, loss_ce: 0.003990
2022-01-08 14:06:22,336 iteration 5918 : loss : 0.019738, loss_ce: 0.009072
2022-01-08 14:06:24,636 iteration 5919 : loss : 0.011405, loss_ce: 0.006472
2022-01-08 14:06:27,084 iteration 5920 : loss : 0.023465, loss_ce: 0.011378
2022-01-08 14:06:29,413 iteration 5921 : loss : 0.012627, loss_ce: 0.003557
2022-01-08 14:06:31,911 iteration 5922 : loss : 0.013671, loss_ce: 0.006216
2022-01-08 14:06:34,329 iteration 5923 : loss : 0.019117, loss_ce: 0.005247
2022-01-08 14:06:36,693 iteration 5924 : loss : 0.012241, loss_ce: 0.004863
2022-01-08 14:06:39,049 iteration 5925 : loss : 0.013371, loss_ce: 0.004505
2022-01-08 14:06:41,498 iteration 5926 : loss : 0.013759, loss_ce: 0.005162
2022-01-08 14:06:43,980 iteration 5927 : loss : 0.016534, loss_ce: 0.006663
2022-01-08 14:06:46,271 iteration 5928 : loss : 0.011995, loss_ce: 0.005071
2022-01-08 14:06:48,675 iteration 5929 : loss : 0.019961, loss_ce: 0.005128
2022-01-08 14:06:51,106 iteration 5930 : loss : 0.016218, loss_ce: 0.005534
2022-01-08 14:06:53,501 iteration 5931 : loss : 0.012736, loss_ce: 0.005669
2022-01-08 14:06:55,858 iteration 5932 : loss : 0.014102, loss_ce: 0.005469
2022-01-08 14:06:58,227 iteration 5933 : loss : 0.010016, loss_ce: 0.004002
 87%|█████████████████████████▎   | 349/400 [4:13:12<35:39, 41.95s/it]2022-01-08 14:07:00,626 iteration 5934 : loss : 0.009934, loss_ce: 0.003293
2022-01-08 14:07:03,003 iteration 5935 : loss : 0.015361, loss_ce: 0.007185
2022-01-08 14:07:05,401 iteration 5936 : loss : 0.019068, loss_ce: 0.007899
2022-01-08 14:07:07,802 iteration 5937 : loss : 0.015510, loss_ce: 0.006514
2022-01-08 14:07:10,160 iteration 5938 : loss : 0.012059, loss_ce: 0.005416
2022-01-08 14:07:12,642 iteration 5939 : loss : 0.031901, loss_ce: 0.010259
2022-01-08 14:07:14,993 iteration 5940 : loss : 0.009323, loss_ce: 0.003361
2022-01-08 14:07:17,420 iteration 5941 : loss : 0.014575, loss_ce: 0.004957
2022-01-08 14:07:19,842 iteration 5942 : loss : 0.014597, loss_ce: 0.005655
2022-01-08 14:07:22,262 iteration 5943 : loss : 0.015170, loss_ce: 0.005774
2022-01-08 14:07:24,623 iteration 5944 : loss : 0.015009, loss_ce: 0.005817
2022-01-08 14:07:27,113 iteration 5945 : loss : 0.017561, loss_ce: 0.005793
2022-01-08 14:07:29,462 iteration 5946 : loss : 0.010499, loss_ce: 0.004000
2022-01-08 14:07:32,092 iteration 5947 : loss : 0.035451, loss_ce: 0.011367
2022-01-08 14:07:34,546 iteration 5948 : loss : 0.027804, loss_ce: 0.010208
2022-01-08 14:07:36,886 iteration 5949 : loss : 0.018174, loss_ce: 0.004595
2022-01-08 14:07:36,887 Training Data Eval:
2022-01-08 14:07:49,641   Average segmentation loss on training set: 0.0075
2022-01-08 14:07:49,641 Validation Data Eval:
2022-01-08 14:07:54,135   Average segmentation loss on validation set: 0.0821
2022-01-08 14:07:56,483 iteration 5950 : loss : 0.009656, loss_ce: 0.003056
 88%|█████████████████████████▍   | 350/400 [4:14:11<39:02, 46.84s/it]2022-01-08 14:07:58,850 iteration 5951 : loss : 0.012423, loss_ce: 0.004136
2022-01-08 14:08:01,374 iteration 5952 : loss : 0.014467, loss_ce: 0.006168
2022-01-08 14:08:03,858 iteration 5953 : loss : 0.018384, loss_ce: 0.008823
2022-01-08 14:08:06,232 iteration 5954 : loss : 0.015067, loss_ce: 0.003999
2022-01-08 14:08:08,709 iteration 5955 : loss : 0.025933, loss_ce: 0.008910
2022-01-08 14:08:11,032 iteration 5956 : loss : 0.027151, loss_ce: 0.006076
2022-01-08 14:08:13,370 iteration 5957 : loss : 0.016977, loss_ce: 0.006802
2022-01-08 14:08:15,705 iteration 5958 : loss : 0.015726, loss_ce: 0.006742
2022-01-08 14:08:18,146 iteration 5959 : loss : 0.015718, loss_ce: 0.003577
2022-01-08 14:08:20,569 iteration 5960 : loss : 0.013896, loss_ce: 0.003487
2022-01-08 14:08:22,990 iteration 5961 : loss : 0.018839, loss_ce: 0.011190
2022-01-08 14:08:25,385 iteration 5962 : loss : 0.012747, loss_ce: 0.004608
2022-01-08 14:08:27,703 iteration 5963 : loss : 0.015147, loss_ce: 0.005696
2022-01-08 14:08:30,170 iteration 5964 : loss : 0.020385, loss_ce: 0.008092
2022-01-08 14:08:32,576 iteration 5965 : loss : 0.010967, loss_ce: 0.004928
2022-01-08 14:08:34,883 iteration 5966 : loss : 0.011090, loss_ce: 0.003859
2022-01-08 14:08:37,266 iteration 5967 : loss : 0.020159, loss_ce: 0.006868
 88%|█████████████████████████▍   | 351/400 [4:14:52<36:45, 45.02s/it]2022-01-08 14:08:39,673 iteration 5968 : loss : 0.013330, loss_ce: 0.004551
2022-01-08 14:08:42,013 iteration 5969 : loss : 0.014190, loss_ce: 0.006876
2022-01-08 14:08:44,412 iteration 5970 : loss : 0.018935, loss_ce: 0.007412
2022-01-08 14:08:46,770 iteration 5971 : loss : 0.009308, loss_ce: 0.004029
2022-01-08 14:08:49,137 iteration 5972 : loss : 0.012572, loss_ce: 0.003541
2022-01-08 14:08:51,452 iteration 5973 : loss : 0.011576, loss_ce: 0.005090
2022-01-08 14:08:53,735 iteration 5974 : loss : 0.026443, loss_ce: 0.007929
2022-01-08 14:08:55,990 iteration 5975 : loss : 0.016885, loss_ce: 0.011098
2022-01-08 14:08:58,333 iteration 5976 : loss : 0.017567, loss_ce: 0.005795
2022-01-08 14:09:00,671 iteration 5977 : loss : 0.012336, loss_ce: 0.004186
2022-01-08 14:09:03,029 iteration 5978 : loss : 0.016085, loss_ce: 0.004645
2022-01-08 14:09:05,387 iteration 5979 : loss : 0.012634, loss_ce: 0.003864
2022-01-08 14:09:07,788 iteration 5980 : loss : 0.016566, loss_ce: 0.003601
2022-01-08 14:09:10,112 iteration 5981 : loss : 0.028930, loss_ce: 0.011127
2022-01-08 14:09:12,360 iteration 5982 : loss : 0.016224, loss_ce: 0.007415
2022-01-08 14:09:14,670 iteration 5983 : loss : 0.018512, loss_ce: 0.004387
2022-01-08 14:09:17,128 iteration 5984 : loss : 0.012614, loss_ce: 0.003910
 88%|█████████████████████████▌   | 352/400 [4:15:31<34:46, 43.48s/it]2022-01-08 14:09:19,526 iteration 5985 : loss : 0.028622, loss_ce: 0.011562
2022-01-08 14:09:21,682 iteration 5986 : loss : 0.010449, loss_ce: 0.005440
2022-01-08 14:09:23,954 iteration 5987 : loss : 0.022975, loss_ce: 0.004830
2022-01-08 14:09:26,197 iteration 5988 : loss : 0.011297, loss_ce: 0.004545
2022-01-08 14:09:28,611 iteration 5989 : loss : 0.010289, loss_ce: 0.003584
2022-01-08 14:09:30,979 iteration 5990 : loss : 0.020592, loss_ce: 0.006140
2022-01-08 14:09:33,432 iteration 5991 : loss : 0.014627, loss_ce: 0.003855
2022-01-08 14:09:35,799 iteration 5992 : loss : 0.018319, loss_ce: 0.004364
2022-01-08 14:09:38,126 iteration 5993 : loss : 0.013904, loss_ce: 0.005319
2022-01-08 14:09:40,359 iteration 5994 : loss : 0.009589, loss_ce: 0.004244
2022-01-08 14:09:42,815 iteration 5995 : loss : 0.013744, loss_ce: 0.004868
2022-01-08 14:09:45,226 iteration 5996 : loss : 0.010428, loss_ce: 0.005408
2022-01-08 14:09:47,522 iteration 5997 : loss : 0.013852, loss_ce: 0.004129
2022-01-08 14:09:49,970 iteration 5998 : loss : 0.019088, loss_ce: 0.006307
2022-01-08 14:09:52,264 iteration 5999 : loss : 0.013965, loss_ce: 0.004384
2022-01-08 14:09:54,676 iteration 6000 : loss : 0.020350, loss_ce: 0.007370
2022-01-08 14:09:56,900 iteration 6001 : loss : 0.010520, loss_ce: 0.003892
 88%|█████████████████████████▌   | 353/400 [4:16:11<33:10, 42.36s/it]2022-01-08 14:09:59,258 iteration 6002 : loss : 0.016909, loss_ce: 0.006146
2022-01-08 14:10:01,576 iteration 6003 : loss : 0.011115, loss_ce: 0.004875
2022-01-08 14:10:03,828 iteration 6004 : loss : 0.013434, loss_ce: 0.004683
2022-01-08 14:10:06,093 iteration 6005 : loss : 0.013274, loss_ce: 0.005148
2022-01-08 14:10:08,486 iteration 6006 : loss : 0.024434, loss_ce: 0.011921
2022-01-08 14:10:10,747 iteration 6007 : loss : 0.012404, loss_ce: 0.004730
2022-01-08 14:10:13,042 iteration 6008 : loss : 0.021463, loss_ce: 0.006988
2022-01-08 14:10:15,423 iteration 6009 : loss : 0.017303, loss_ce: 0.005183
2022-01-08 14:10:17,671 iteration 6010 : loss : 0.015730, loss_ce: 0.003537
2022-01-08 14:10:19,995 iteration 6011 : loss : 0.017102, loss_ce: 0.006220
2022-01-08 14:10:22,351 iteration 6012 : loss : 0.015430, loss_ce: 0.006754
2022-01-08 14:10:24,631 iteration 6013 : loss : 0.014516, loss_ce: 0.005167
2022-01-08 14:10:26,856 iteration 6014 : loss : 0.012174, loss_ce: 0.004586
2022-01-08 14:10:29,142 iteration 6015 : loss : 0.010377, loss_ce: 0.005166
2022-01-08 14:10:31,524 iteration 6016 : loss : 0.021422, loss_ce: 0.006906
2022-01-08 14:10:33,901 iteration 6017 : loss : 0.011460, loss_ce: 0.004132
2022-01-08 14:10:36,156 iteration 6018 : loss : 0.012512, loss_ce: 0.004956
 88%|█████████████████████████▋   | 354/400 [4:16:50<31:45, 41.43s/it]2022-01-08 14:10:38,503 iteration 6019 : loss : 0.014848, loss_ce: 0.005459
2022-01-08 14:10:40,819 iteration 6020 : loss : 0.016676, loss_ce: 0.006250
2022-01-08 14:10:43,027 iteration 6021 : loss : 0.008692, loss_ce: 0.003191
2022-01-08 14:10:45,346 iteration 6022 : loss : 0.011784, loss_ce: 0.004422
2022-01-08 14:10:47,663 iteration 6023 : loss : 0.014708, loss_ce: 0.007612
2022-01-08 14:10:50,053 iteration 6024 : loss : 0.012188, loss_ce: 0.004596
2022-01-08 14:10:52,398 iteration 6025 : loss : 0.011885, loss_ce: 0.002466
2022-01-08 14:10:54,750 iteration 6026 : loss : 0.021132, loss_ce: 0.007441
2022-01-08 14:10:57,108 iteration 6027 : loss : 0.013722, loss_ce: 0.006178
2022-01-08 14:10:59,407 iteration 6028 : loss : 0.010744, loss_ce: 0.005137
2022-01-08 14:11:01,788 iteration 6029 : loss : 0.019271, loss_ce: 0.009682
2022-01-08 14:11:04,166 iteration 6030 : loss : 0.027073, loss_ce: 0.013116
2022-01-08 14:11:06,508 iteration 6031 : loss : 0.017855, loss_ce: 0.005196
2022-01-08 14:11:08,869 iteration 6032 : loss : 0.019511, loss_ce: 0.005732
2022-01-08 14:11:11,237 iteration 6033 : loss : 0.018115, loss_ce: 0.006732
2022-01-08 14:11:13,564 iteration 6034 : loss : 0.009859, loss_ce: 0.003823
2022-01-08 14:11:13,564 Training Data Eval:
2022-01-08 14:11:26,290   Average segmentation loss on training set: 0.0077
2022-01-08 14:11:26,290 Validation Data Eval:
2022-01-08 14:11:30,759   Average segmentation loss on validation set: 0.0599
2022-01-08 14:11:36,606 Found new lowest validation loss at iteration 6034! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed2.pth
2022-01-08 14:11:38,164 iteration 6035 : loss : 0.013270, loss_ce: 0.005611
 89%|█████████████████████████▋   | 355/400 [4:17:52<35:42, 47.61s/it]2022-01-08 14:11:39,797 iteration 6036 : loss : 0.009880, loss_ce: 0.004536
2022-01-08 14:11:41,322 iteration 6037 : loss : 0.009253, loss_ce: 0.003737
2022-01-08 14:11:42,943 iteration 6038 : loss : 0.014694, loss_ce: 0.005892
2022-01-08 14:11:44,665 iteration 6039 : loss : 0.010046, loss_ce: 0.003330
2022-01-08 14:11:46,575 iteration 6040 : loss : 0.014265, loss_ce: 0.004122
2022-01-08 14:11:48,591 iteration 6041 : loss : 0.018357, loss_ce: 0.007307
2022-01-08 14:11:50,612 iteration 6042 : loss : 0.016596, loss_ce: 0.003733
2022-01-08 14:11:52,654 iteration 6043 : loss : 0.008992, loss_ce: 0.002542
2022-01-08 14:11:54,779 iteration 6044 : loss : 0.016329, loss_ce: 0.004330
2022-01-08 14:11:56,898 iteration 6045 : loss : 0.012064, loss_ce: 0.004995
2022-01-08 14:11:59,106 iteration 6046 : loss : 0.013212, loss_ce: 0.005360
2022-01-08 14:12:01,357 iteration 6047 : loss : 0.010225, loss_ce: 0.003920
2022-01-08 14:12:03,730 iteration 6048 : loss : 0.013948, loss_ce: 0.006443
2022-01-08 14:12:06,009 iteration 6049 : loss : 0.011975, loss_ce: 0.005743
2022-01-08 14:12:08,313 iteration 6050 : loss : 0.011816, loss_ce: 0.003776
2022-01-08 14:12:10,675 iteration 6051 : loss : 0.011905, loss_ce: 0.004013
2022-01-08 14:12:12,933 iteration 6052 : loss : 0.012988, loss_ce: 0.005515
 89%|█████████████████████████▊   | 356/400 [4:18:27<32:05, 43.75s/it]2022-01-08 14:12:15,300 iteration 6053 : loss : 0.014282, loss_ce: 0.005975
2022-01-08 14:12:17,562 iteration 6054 : loss : 0.010552, loss_ce: 0.005313
2022-01-08 14:12:19,918 iteration 6055 : loss : 0.013167, loss_ce: 0.004729
2022-01-08 14:12:22,273 iteration 6056 : loss : 0.011918, loss_ce: 0.004279
2022-01-08 14:12:24,560 iteration 6057 : loss : 0.012928, loss_ce: 0.004278
2022-01-08 14:12:26,858 iteration 6058 : loss : 0.018150, loss_ce: 0.005816
2022-01-08 14:12:29,152 iteration 6059 : loss : 0.013712, loss_ce: 0.006263
2022-01-08 14:12:31,599 iteration 6060 : loss : 0.025748, loss_ce: 0.009051
2022-01-08 14:12:33,931 iteration 6061 : loss : 0.014450, loss_ce: 0.005764
2022-01-08 14:12:36,306 iteration 6062 : loss : 0.013448, loss_ce: 0.004583
2022-01-08 14:12:38,536 iteration 6063 : loss : 0.023146, loss_ce: 0.007894
2022-01-08 14:12:40,957 iteration 6064 : loss : 0.020509, loss_ce: 0.008080
2022-01-08 14:12:43,238 iteration 6065 : loss : 0.010608, loss_ce: 0.004704
2022-01-08 14:12:45,610 iteration 6066 : loss : 0.007838, loss_ce: 0.002277
2022-01-08 14:12:47,969 iteration 6067 : loss : 0.010549, loss_ce: 0.004272
2022-01-08 14:12:50,388 iteration 6068 : loss : 0.012025, loss_ce: 0.003853
2022-01-08 14:12:52,780 iteration 6069 : loss : 0.016134, loss_ce: 0.006767
 89%|█████████████████████████▉   | 357/400 [4:19:07<30:31, 42.58s/it]2022-01-08 14:12:55,203 iteration 6070 : loss : 0.008398, loss_ce: 0.004398
2022-01-08 14:12:57,482 iteration 6071 : loss : 0.010782, loss_ce: 0.003445
2022-01-08 14:12:59,698 iteration 6072 : loss : 0.011594, loss_ce: 0.006024
2022-01-08 14:13:01,923 iteration 6073 : loss : 0.012227, loss_ce: 0.003985
2022-01-08 14:13:04,217 iteration 6074 : loss : 0.013843, loss_ce: 0.005731
2022-01-08 14:13:06,445 iteration 6075 : loss : 0.009725, loss_ce: 0.004337
2022-01-08 14:13:08,741 iteration 6076 : loss : 0.013284, loss_ce: 0.003027
2022-01-08 14:13:11,053 iteration 6077 : loss : 0.015975, loss_ce: 0.005711
2022-01-08 14:13:13,450 iteration 6078 : loss : 0.016230, loss_ce: 0.005689
2022-01-08 14:13:15,883 iteration 6079 : loss : 0.017765, loss_ce: 0.006805
2022-01-08 14:13:18,194 iteration 6080 : loss : 0.013148, loss_ce: 0.004811
2022-01-08 14:13:20,503 iteration 6081 : loss : 0.023205, loss_ce: 0.009149
2022-01-08 14:13:22,710 iteration 6082 : loss : 0.012605, loss_ce: 0.003680
2022-01-08 14:13:24,968 iteration 6083 : loss : 0.011929, loss_ce: 0.003185
2022-01-08 14:13:27,343 iteration 6084 : loss : 0.017901, loss_ce: 0.004390
2022-01-08 14:13:29,673 iteration 6085 : loss : 0.014442, loss_ce: 0.004994
2022-01-08 14:13:32,090 iteration 6086 : loss : 0.010132, loss_ce: 0.003245
 90%|█████████████████████████▉   | 358/400 [4:19:46<29:07, 41.60s/it]2022-01-08 14:13:34,454 iteration 6087 : loss : 0.012810, loss_ce: 0.004196
2022-01-08 14:13:36,868 iteration 6088 : loss : 0.011764, loss_ce: 0.004635
2022-01-08 14:13:39,186 iteration 6089 : loss : 0.014743, loss_ce: 0.004192
2022-01-08 14:13:41,448 iteration 6090 : loss : 0.010908, loss_ce: 0.004620
2022-01-08 14:13:43,793 iteration 6091 : loss : 0.010459, loss_ce: 0.003437
2022-01-08 14:13:46,146 iteration 6092 : loss : 0.012006, loss_ce: 0.003405
2022-01-08 14:13:48,480 iteration 6093 : loss : 0.012101, loss_ce: 0.005184
2022-01-08 14:13:50,773 iteration 6094 : loss : 0.017304, loss_ce: 0.005970
2022-01-08 14:13:53,108 iteration 6095 : loss : 0.015574, loss_ce: 0.005192
2022-01-08 14:13:55,581 iteration 6096 : loss : 0.012608, loss_ce: 0.003716
2022-01-08 14:13:57,974 iteration 6097 : loss : 0.009369, loss_ce: 0.003674
2022-01-08 14:14:00,363 iteration 6098 : loss : 0.016745, loss_ce: 0.007058
2022-01-08 14:14:02,663 iteration 6099 : loss : 0.010689, loss_ce: 0.004396
2022-01-08 14:14:04,915 iteration 6100 : loss : 0.013037, loss_ce: 0.006674
2022-01-08 14:14:07,198 iteration 6101 : loss : 0.014465, loss_ce: 0.005684
2022-01-08 14:14:09,545 iteration 6102 : loss : 0.014518, loss_ce: 0.007550
2022-01-08 14:14:11,893 iteration 6103 : loss : 0.017192, loss_ce: 0.007091
 90%|██████████████████████████   | 359/400 [4:20:26<28:03, 41.06s/it]2022-01-08 14:14:14,267 iteration 6104 : loss : 0.018871, loss_ce: 0.009435
2022-01-08 14:14:16,711 iteration 6105 : loss : 0.012022, loss_ce: 0.006031
2022-01-08 14:14:19,032 iteration 6106 : loss : 0.016107, loss_ce: 0.006842
2022-01-08 14:14:21,306 iteration 6107 : loss : 0.017227, loss_ce: 0.007962
2022-01-08 14:14:23,494 iteration 6108 : loss : 0.012452, loss_ce: 0.005306
2022-01-08 14:14:25,672 iteration 6109 : loss : 0.018094, loss_ce: 0.003988
2022-01-08 14:14:27,871 iteration 6110 : loss : 0.011689, loss_ce: 0.004974
2022-01-08 14:14:30,103 iteration 6111 : loss : 0.012934, loss_ce: 0.004799
2022-01-08 14:14:32,316 iteration 6112 : loss : 0.017702, loss_ce: 0.005472
2022-01-08 14:14:34,564 iteration 6113 : loss : 0.013551, loss_ce: 0.005861
2022-01-08 14:14:36,791 iteration 6114 : loss : 0.013349, loss_ce: 0.003865
2022-01-08 14:14:39,030 iteration 6115 : loss : 0.012388, loss_ce: 0.004367
2022-01-08 14:14:41,241 iteration 6116 : loss : 0.026597, loss_ce: 0.008754
2022-01-08 14:14:43,418 iteration 6117 : loss : 0.012277, loss_ce: 0.005245
2022-01-08 14:14:45,667 iteration 6118 : loss : 0.009726, loss_ce: 0.003024
2022-01-08 14:14:48,115 iteration 6119 : loss : 0.019482, loss_ce: 0.009381
2022-01-08 14:14:48,115 Training Data Eval:
2022-01-08 14:15:00,621   Average segmentation loss on training set: 0.0072
2022-01-08 14:15:00,621 Validation Data Eval:
2022-01-08 14:15:04,951   Average segmentation loss on validation set: 0.0843
2022-01-08 14:15:07,351 iteration 6120 : loss : 0.012185, loss_ce: 0.003735
 90%|██████████████████████████   | 360/400 [4:21:22<30:15, 45.38s/it]2022-01-08 14:15:09,765 iteration 6121 : loss : 0.013425, loss_ce: 0.003800
2022-01-08 14:15:12,060 iteration 6122 : loss : 0.012054, loss_ce: 0.005160
2022-01-08 14:15:14,340 iteration 6123 : loss : 0.016042, loss_ce: 0.006827
2022-01-08 14:15:16,573 iteration 6124 : loss : 0.010760, loss_ce: 0.003975
2022-01-08 14:15:18,824 iteration 6125 : loss : 0.020044, loss_ce: 0.007521
2022-01-08 14:15:21,119 iteration 6126 : loss : 0.010883, loss_ce: 0.005364
2022-01-08 14:15:23,443 iteration 6127 : loss : 0.010016, loss_ce: 0.003257
2022-01-08 14:15:25,747 iteration 6128 : loss : 0.010925, loss_ce: 0.003597
2022-01-08 14:15:28,216 iteration 6129 : loss : 0.011667, loss_ce: 0.004357
2022-01-08 14:15:30,566 iteration 6130 : loss : 0.014654, loss_ce: 0.004641
2022-01-08 14:15:32,963 iteration 6131 : loss : 0.017049, loss_ce: 0.009495
2022-01-08 14:15:35,283 iteration 6132 : loss : 0.035826, loss_ce: 0.025788
2022-01-08 14:15:37,580 iteration 6133 : loss : 0.016891, loss_ce: 0.005129
2022-01-08 14:15:39,913 iteration 6134 : loss : 0.014513, loss_ce: 0.004929
2022-01-08 14:15:42,362 iteration 6135 : loss : 0.027564, loss_ce: 0.010988
2022-01-08 14:15:44,738 iteration 6136 : loss : 0.012688, loss_ce: 0.003293
2022-01-08 14:15:47,041 iteration 6137 : loss : 0.013706, loss_ce: 0.005498
 90%|██████████████████████████▏  | 361/400 [4:22:01<28:23, 43.67s/it]2022-01-08 14:15:49,399 iteration 6138 : loss : 0.015084, loss_ce: 0.005281
2022-01-08 14:15:51,691 iteration 6139 : loss : 0.012366, loss_ce: 0.004967
2022-01-08 14:15:54,105 iteration 6140 : loss : 0.014984, loss_ce: 0.007758
2022-01-08 14:15:56,430 iteration 6141 : loss : 0.011612, loss_ce: 0.005001
2022-01-08 14:15:58,711 iteration 6142 : loss : 0.008316, loss_ce: 0.003440
2022-01-08 14:16:01,066 iteration 6143 : loss : 0.014394, loss_ce: 0.003855
2022-01-08 14:16:03,389 iteration 6144 : loss : 0.016425, loss_ce: 0.006668
2022-01-08 14:16:05,610 iteration 6145 : loss : 0.011575, loss_ce: 0.005080
2022-01-08 14:16:08,025 iteration 6146 : loss : 0.015183, loss_ce: 0.004151
2022-01-08 14:16:10,469 iteration 6147 : loss : 0.010980, loss_ce: 0.004377
2022-01-08 14:16:12,892 iteration 6148 : loss : 0.013217, loss_ce: 0.004845
2022-01-08 14:16:15,344 iteration 6149 : loss : 0.012750, loss_ce: 0.005075
2022-01-08 14:16:17,769 iteration 6150 : loss : 0.026661, loss_ce: 0.008395
2022-01-08 14:16:20,139 iteration 6151 : loss : 0.017382, loss_ce: 0.004348
2022-01-08 14:16:22,478 iteration 6152 : loss : 0.012137, loss_ce: 0.004996
2022-01-08 14:16:24,812 iteration 6153 : loss : 0.012777, loss_ce: 0.004480
2022-01-08 14:16:27,263 iteration 6154 : loss : 0.017630, loss_ce: 0.007265
 90%|██████████████████████████▏  | 362/400 [4:22:42<27:00, 42.64s/it]2022-01-08 14:16:29,748 iteration 6155 : loss : 0.018955, loss_ce: 0.006138
2022-01-08 14:16:32,117 iteration 6156 : loss : 0.020247, loss_ce: 0.007358
2022-01-08 14:16:34,546 iteration 6157 : loss : 0.014407, loss_ce: 0.006202
2022-01-08 14:16:36,969 iteration 6158 : loss : 0.015943, loss_ce: 0.004199
2022-01-08 14:16:39,289 iteration 6159 : loss : 0.010253, loss_ce: 0.003339
2022-01-08 14:16:41,685 iteration 6160 : loss : 0.010180, loss_ce: 0.003687
2022-01-08 14:16:44,074 iteration 6161 : loss : 0.015358, loss_ce: 0.004573
2022-01-08 14:16:46,483 iteration 6162 : loss : 0.023144, loss_ce: 0.006639
2022-01-08 14:16:48,873 iteration 6163 : loss : 0.019792, loss_ce: 0.008950
2022-01-08 14:16:51,221 iteration 6164 : loss : 0.010910, loss_ce: 0.002895
2022-01-08 14:16:53,663 iteration 6165 : loss : 0.017912, loss_ce: 0.006021
2022-01-08 14:16:55,965 iteration 6166 : loss : 0.012575, loss_ce: 0.004738
2022-01-08 14:16:58,399 iteration 6167 : loss : 0.014580, loss_ce: 0.006910
2022-01-08 14:17:00,830 iteration 6168 : loss : 0.022072, loss_ce: 0.008880
2022-01-08 14:17:03,199 iteration 6169 : loss : 0.016218, loss_ce: 0.004384
2022-01-08 14:17:05,562 iteration 6170 : loss : 0.011555, loss_ce: 0.005869
2022-01-08 14:17:07,912 iteration 6171 : loss : 0.014774, loss_ce: 0.006659
 91%|██████████████████████████▎  | 363/400 [4:23:22<25:55, 42.04s/it]2022-01-08 14:17:10,267 iteration 6172 : loss : 0.015221, loss_ce: 0.005353
2022-01-08 14:17:12,601 iteration 6173 : loss : 0.025224, loss_ce: 0.006789
2022-01-08 14:17:14,938 iteration 6174 : loss : 0.010913, loss_ce: 0.004368
2022-01-08 14:17:17,388 iteration 6175 : loss : 0.013106, loss_ce: 0.003874
2022-01-08 14:17:19,768 iteration 6176 : loss : 0.013357, loss_ce: 0.004703
2022-01-08 14:17:22,103 iteration 6177 : loss : 0.009759, loss_ce: 0.004433
2022-01-08 14:17:24,420 iteration 6178 : loss : 0.013610, loss_ce: 0.004721
2022-01-08 14:17:26,725 iteration 6179 : loss : 0.017831, loss_ce: 0.005790
2022-01-08 14:17:29,130 iteration 6180 : loss : 0.013774, loss_ce: 0.006136
2022-01-08 14:17:31,639 iteration 6181 : loss : 0.009690, loss_ce: 0.002981
2022-01-08 14:17:34,024 iteration 6182 : loss : 0.010215, loss_ce: 0.002650
2022-01-08 14:17:36,430 iteration 6183 : loss : 0.018153, loss_ce: 0.007370
2022-01-08 14:17:38,834 iteration 6184 : loss : 0.011147, loss_ce: 0.004927
2022-01-08 14:17:41,282 iteration 6185 : loss : 0.020595, loss_ce: 0.006042
2022-01-08 14:17:43,572 iteration 6186 : loss : 0.010338, loss_ce: 0.003857
2022-01-08 14:17:45,895 iteration 6187 : loss : 0.014409, loss_ce: 0.006839
2022-01-08 14:17:48,310 iteration 6188 : loss : 0.016173, loss_ce: 0.007315
 91%|██████████████████████████▍  | 364/400 [4:24:03<24:55, 41.55s/it]2022-01-08 14:17:50,741 iteration 6189 : loss : 0.017146, loss_ce: 0.004145
2022-01-08 14:17:53,283 iteration 6190 : loss : 0.016104, loss_ce: 0.004443
2022-01-08 14:17:55,672 iteration 6191 : loss : 0.011968, loss_ce: 0.005752
2022-01-08 14:17:58,018 iteration 6192 : loss : 0.010484, loss_ce: 0.004194
2022-01-08 14:18:00,386 iteration 6193 : loss : 0.014706, loss_ce: 0.004772
2022-01-08 14:18:02,700 iteration 6194 : loss : 0.012272, loss_ce: 0.004585
2022-01-08 14:18:05,160 iteration 6195 : loss : 0.015753, loss_ce: 0.005249
2022-01-08 14:18:07,493 iteration 6196 : loss : 0.021317, loss_ce: 0.007281
2022-01-08 14:18:09,817 iteration 6197 : loss : 0.013012, loss_ce: 0.007779
2022-01-08 14:18:12,326 iteration 6198 : loss : 0.028675, loss_ce: 0.007785
2022-01-08 14:18:14,757 iteration 6199 : loss : 0.023325, loss_ce: 0.009706
2022-01-08 14:18:17,152 iteration 6200 : loss : 0.011105, loss_ce: 0.004765
2022-01-08 14:18:19,502 iteration 6201 : loss : 0.013974, loss_ce: 0.005476
2022-01-08 14:18:21,785 iteration 6202 : loss : 0.010212, loss_ce: 0.003563
2022-01-08 14:18:24,323 iteration 6203 : loss : 0.018982, loss_ce: 0.007583
2022-01-08 14:18:26,614 iteration 6204 : loss : 0.011629, loss_ce: 0.005349
2022-01-08 14:18:26,615 Training Data Eval:
2022-01-08 14:18:39,258   Average segmentation loss on training set: 0.0071
2022-01-08 14:18:39,259 Validation Data Eval:
2022-01-08 14:18:43,878   Average segmentation loss on validation set: 0.0663
2022-01-08 14:18:46,324 iteration 6205 : loss : 0.019897, loss_ce: 0.006957
 91%|██████████████████████████▍  | 365/400 [4:25:01<27:07, 46.49s/it]2022-01-08 14:18:48,792 iteration 6206 : loss : 0.023169, loss_ce: 0.009549
2022-01-08 14:18:51,121 iteration 6207 : loss : 0.012038, loss_ce: 0.004773
2022-01-08 14:18:53,414 iteration 6208 : loss : 0.020929, loss_ce: 0.007282
2022-01-08 14:18:55,756 iteration 6209 : loss : 0.013482, loss_ce: 0.005051
2022-01-08 14:18:58,074 iteration 6210 : loss : 0.030986, loss_ce: 0.017093
2022-01-08 14:19:00,478 iteration 6211 : loss : 0.014871, loss_ce: 0.007647
2022-01-08 14:19:02,885 iteration 6212 : loss : 0.011468, loss_ce: 0.004438
2022-01-08 14:19:05,246 iteration 6213 : loss : 0.010073, loss_ce: 0.003563
2022-01-08 14:19:07,684 iteration 6214 : loss : 0.013371, loss_ce: 0.004655
2022-01-08 14:19:10,022 iteration 6215 : loss : 0.018777, loss_ce: 0.005829
2022-01-08 14:19:12,548 iteration 6216 : loss : 0.016671, loss_ce: 0.005013
2022-01-08 14:19:14,965 iteration 6217 : loss : 0.017386, loss_ce: 0.007584
2022-01-08 14:19:17,253 iteration 6218 : loss : 0.011548, loss_ce: 0.004289
2022-01-08 14:19:19,578 iteration 6219 : loss : 0.017550, loss_ce: 0.006362
2022-01-08 14:19:21,846 iteration 6220 : loss : 0.011045, loss_ce: 0.002853
2022-01-08 14:19:24,292 iteration 6221 : loss : 0.012540, loss_ce: 0.004025
2022-01-08 14:19:26,684 iteration 6222 : loss : 0.010067, loss_ce: 0.004471
 92%|██████████████████████████▌  | 366/400 [4:25:41<25:18, 44.65s/it]2022-01-08 14:19:29,142 iteration 6223 : loss : 0.015509, loss_ce: 0.006274
2022-01-08 14:19:31,596 iteration 6224 : loss : 0.015338, loss_ce: 0.006792
2022-01-08 14:19:34,143 iteration 6225 : loss : 0.010983, loss_ce: 0.005211
2022-01-08 14:19:36,515 iteration 6226 : loss : 0.014290, loss_ce: 0.005061
2022-01-08 14:19:38,938 iteration 6227 : loss : 0.010473, loss_ce: 0.003413
2022-01-08 14:19:41,314 iteration 6228 : loss : 0.027679, loss_ce: 0.010244
2022-01-08 14:19:43,716 iteration 6229 : loss : 0.014598, loss_ce: 0.004232
2022-01-08 14:19:46,117 iteration 6230 : loss : 0.047741, loss_ce: 0.007639
2022-01-08 14:19:48,395 iteration 6231 : loss : 0.012112, loss_ce: 0.005343
2022-01-08 14:19:50,737 iteration 6232 : loss : 0.014056, loss_ce: 0.005475
2022-01-08 14:19:53,153 iteration 6233 : loss : 0.023704, loss_ce: 0.008308
2022-01-08 14:19:55,523 iteration 6234 : loss : 0.015692, loss_ce: 0.006620
2022-01-08 14:19:57,911 iteration 6235 : loss : 0.015334, loss_ce: 0.004568
2022-01-08 14:20:00,348 iteration 6236 : loss : 0.019036, loss_ce: 0.006791
2022-01-08 14:20:02,758 iteration 6237 : loss : 0.015413, loss_ce: 0.005195
2022-01-08 14:20:05,110 iteration 6238 : loss : 0.012645, loss_ce: 0.004865
2022-01-08 14:20:07,429 iteration 6239 : loss : 0.023098, loss_ce: 0.009568
 92%|██████████████████████████▌  | 367/400 [4:26:22<23:54, 43.48s/it]2022-01-08 14:20:09,660 iteration 6240 : loss : 0.013470, loss_ce: 0.004900
2022-01-08 14:20:11,861 iteration 6241 : loss : 0.010489, loss_ce: 0.004407
2022-01-08 14:20:14,262 iteration 6242 : loss : 0.014621, loss_ce: 0.006425
2022-01-08 14:20:16,654 iteration 6243 : loss : 0.014983, loss_ce: 0.005277
2022-01-08 14:20:19,110 iteration 6244 : loss : 0.017215, loss_ce: 0.006145
2022-01-08 14:20:21,559 iteration 6245 : loss : 0.010319, loss_ce: 0.004653
2022-01-08 14:20:23,925 iteration 6246 : loss : 0.011028, loss_ce: 0.004250
2022-01-08 14:20:26,422 iteration 6247 : loss : 0.016085, loss_ce: 0.005420
2022-01-08 14:20:28,845 iteration 6248 : loss : 0.028559, loss_ce: 0.006727
2022-01-08 14:20:31,182 iteration 6249 : loss : 0.012101, loss_ce: 0.004014
2022-01-08 14:20:33,412 iteration 6250 : loss : 0.013854, loss_ce: 0.002978
2022-01-08 14:20:35,928 iteration 6251 : loss : 0.019338, loss_ce: 0.011290
2022-01-08 14:20:38,277 iteration 6252 : loss : 0.010437, loss_ce: 0.003547
2022-01-08 14:20:40,752 iteration 6253 : loss : 0.014596, loss_ce: 0.005666
2022-01-08 14:20:43,083 iteration 6254 : loss : 0.008049, loss_ce: 0.003392
2022-01-08 14:20:45,622 iteration 6255 : loss : 0.028581, loss_ce: 0.011981
2022-01-08 14:20:47,915 iteration 6256 : loss : 0.012544, loss_ce: 0.005026
 92%|██████████████████████████▋  | 368/400 [4:27:02<22:42, 42.58s/it]2022-01-08 14:20:50,313 iteration 6257 : loss : 0.012821, loss_ce: 0.005660
2022-01-08 14:20:52,594 iteration 6258 : loss : 0.010100, loss_ce: 0.004835
2022-01-08 14:20:55,020 iteration 6259 : loss : 0.016037, loss_ce: 0.007824
2022-01-08 14:20:57,404 iteration 6260 : loss : 0.022744, loss_ce: 0.005938
2022-01-08 14:20:59,778 iteration 6261 : loss : 0.010527, loss_ce: 0.004464
2022-01-08 14:21:02,232 iteration 6262 : loss : 0.014352, loss_ce: 0.005932
2022-01-08 14:21:04,665 iteration 6263 : loss : 0.017193, loss_ce: 0.004435
2022-01-08 14:21:07,036 iteration 6264 : loss : 0.011531, loss_ce: 0.005351
2022-01-08 14:21:09,434 iteration 6265 : loss : 0.011410, loss_ce: 0.004673
2022-01-08 14:21:11,851 iteration 6266 : loss : 0.011801, loss_ce: 0.004802
2022-01-08 14:21:14,266 iteration 6267 : loss : 0.014467, loss_ce: 0.005332
2022-01-08 14:21:16,644 iteration 6268 : loss : 0.016119, loss_ce: 0.006072
2022-01-08 14:21:19,021 iteration 6269 : loss : 0.018141, loss_ce: 0.007414
2022-01-08 14:21:21,424 iteration 6270 : loss : 0.014214, loss_ce: 0.004126
2022-01-08 14:21:23,838 iteration 6271 : loss : 0.014724, loss_ce: 0.003491
2022-01-08 14:21:26,240 iteration 6272 : loss : 0.009834, loss_ce: 0.002803
2022-01-08 14:21:28,608 iteration 6273 : loss : 0.008353, loss_ce: 0.003196
 92%|██████████████████████████▊  | 369/400 [4:27:43<21:42, 42.01s/it]2022-01-08 14:21:31,015 iteration 6274 : loss : 0.011973, loss_ce: 0.003648
2022-01-08 14:21:33,364 iteration 6275 : loss : 0.012622, loss_ce: 0.005281
2022-01-08 14:21:35,729 iteration 6276 : loss : 0.015328, loss_ce: 0.005203
2022-01-08 14:21:38,165 iteration 6277 : loss : 0.015733, loss_ce: 0.004120
2022-01-08 14:21:40,551 iteration 6278 : loss : 0.015170, loss_ce: 0.005954
2022-01-08 14:21:42,990 iteration 6279 : loss : 0.019190, loss_ce: 0.006044
2022-01-08 14:21:45,389 iteration 6280 : loss : 0.017750, loss_ce: 0.008347
2022-01-08 14:21:47,716 iteration 6281 : loss : 0.012051, loss_ce: 0.003824
2022-01-08 14:21:50,023 iteration 6282 : loss : 0.011455, loss_ce: 0.004668
2022-01-08 14:21:52,457 iteration 6283 : loss : 0.021689, loss_ce: 0.005964
2022-01-08 14:21:54,942 iteration 6284 : loss : 0.011607, loss_ce: 0.005392
2022-01-08 14:21:57,329 iteration 6285 : loss : 0.015754, loss_ce: 0.006016
2022-01-08 14:21:59,703 iteration 6286 : loss : 0.012488, loss_ce: 0.006525
2022-01-08 14:22:02,131 iteration 6287 : loss : 0.010637, loss_ce: 0.003639
2022-01-08 14:22:04,516 iteration 6288 : loss : 0.032220, loss_ce: 0.011851
2022-01-08 14:22:06,908 iteration 6289 : loss : 0.013772, loss_ce: 0.004454
2022-01-08 14:22:06,908 Training Data Eval:
2022-01-08 14:22:19,683   Average segmentation loss on training set: 0.0069
2022-01-08 14:22:19,683 Validation Data Eval:
2022-01-08 14:22:24,171   Average segmentation loss on validation set: 0.0738
2022-01-08 14:22:26,544 iteration 6290 : loss : 0.012155, loss_ce: 0.004371
 92%|██████████████████████████▊  | 370/400 [4:28:41<23:23, 46.79s/it]2022-01-08 14:22:28,941 iteration 6291 : loss : 0.010445, loss_ce: 0.002260
2022-01-08 14:22:31,388 iteration 6292 : loss : 0.011960, loss_ce: 0.004396
2022-01-08 14:22:33,869 iteration 6293 : loss : 0.013782, loss_ce: 0.005217
2022-01-08 14:22:36,278 iteration 6294 : loss : 0.016063, loss_ce: 0.007707
2022-01-08 14:22:38,605 iteration 6295 : loss : 0.015822, loss_ce: 0.005771
2022-01-08 14:22:40,850 iteration 6296 : loss : 0.012529, loss_ce: 0.005318
2022-01-08 14:22:43,153 iteration 6297 : loss : 0.011373, loss_ce: 0.002906
2022-01-08 14:22:45,442 iteration 6298 : loss : 0.012297, loss_ce: 0.004144
2022-01-08 14:22:47,840 iteration 6299 : loss : 0.012920, loss_ce: 0.005073
2022-01-08 14:22:50,211 iteration 6300 : loss : 0.016323, loss_ce: 0.006130
2022-01-08 14:22:52,593 iteration 6301 : loss : 0.016568, loss_ce: 0.007845
2022-01-08 14:22:54,915 iteration 6302 : loss : 0.010741, loss_ce: 0.004291
2022-01-08 14:22:57,286 iteration 6303 : loss : 0.013055, loss_ce: 0.005611
2022-01-08 14:22:59,627 iteration 6304 : loss : 0.011133, loss_ce: 0.004475
2022-01-08 14:23:01,933 iteration 6305 : loss : 0.013274, loss_ce: 0.007494
2022-01-08 14:23:04,255 iteration 6306 : loss : 0.011365, loss_ce: 0.003892
2022-01-08 14:23:06,714 iteration 6307 : loss : 0.014363, loss_ce: 0.005123
 93%|██████████████████████████▉  | 371/400 [4:29:21<21:39, 44.81s/it]2022-01-08 14:23:09,114 iteration 6308 : loss : 0.012405, loss_ce: 0.004632
2022-01-08 14:23:11,450 iteration 6309 : loss : 0.018314, loss_ce: 0.005549
2022-01-08 14:23:13,779 iteration 6310 : loss : 0.014534, loss_ce: 0.006505
2022-01-08 14:23:16,227 iteration 6311 : loss : 0.012551, loss_ce: 0.003301
2022-01-08 14:23:18,669 iteration 6312 : loss : 0.015829, loss_ce: 0.006343
2022-01-08 14:23:21,038 iteration 6313 : loss : 0.010078, loss_ce: 0.002857
2022-01-08 14:23:23,409 iteration 6314 : loss : 0.033867, loss_ce: 0.010718
2022-01-08 14:23:25,774 iteration 6315 : loss : 0.014287, loss_ce: 0.004916
2022-01-08 14:23:28,255 iteration 6316 : loss : 0.011738, loss_ce: 0.005566
2022-01-08 14:23:30,678 iteration 6317 : loss : 0.009891, loss_ce: 0.003632
2022-01-08 14:23:33,046 iteration 6318 : loss : 0.011806, loss_ce: 0.004642
2022-01-08 14:23:35,372 iteration 6319 : loss : 0.015017, loss_ce: 0.004581
2022-01-08 14:23:37,687 iteration 6320 : loss : 0.013026, loss_ce: 0.005234
2022-01-08 14:23:40,101 iteration 6321 : loss : 0.018137, loss_ce: 0.008049
2022-01-08 14:23:42,561 iteration 6322 : loss : 0.016864, loss_ce: 0.006437
2022-01-08 14:23:44,778 iteration 6323 : loss : 0.009361, loss_ce: 0.004259
2022-01-08 14:23:47,174 iteration 6324 : loss : 0.013950, loss_ce: 0.003700
 93%|██████████████████████████▉  | 372/400 [4:30:01<20:18, 43.50s/it]2022-01-08 14:23:49,550 iteration 6325 : loss : 0.012036, loss_ce: 0.004163
2022-01-08 14:23:51,819 iteration 6326 : loss : 0.011544, loss_ce: 0.005825
2022-01-08 14:23:54,139 iteration 6327 : loss : 0.009099, loss_ce: 0.003301
2022-01-08 14:23:56,633 iteration 6328 : loss : 0.012548, loss_ce: 0.005294
2022-01-08 14:23:59,102 iteration 6329 : loss : 0.012274, loss_ce: 0.004102
2022-01-08 14:24:01,441 iteration 6330 : loss : 0.015304, loss_ce: 0.006604
2022-01-08 14:24:03,853 iteration 6331 : loss : 0.014192, loss_ce: 0.006827
2022-01-08 14:24:06,187 iteration 6332 : loss : 0.014417, loss_ce: 0.004718
2022-01-08 14:24:08,547 iteration 6333 : loss : 0.012874, loss_ce: 0.005437
2022-01-08 14:24:10,879 iteration 6334 : loss : 0.012043, loss_ce: 0.006691
2022-01-08 14:24:13,419 iteration 6335 : loss : 0.018868, loss_ce: 0.008560
2022-01-08 14:24:15,792 iteration 6336 : loss : 0.012339, loss_ce: 0.004037
2022-01-08 14:24:18,096 iteration 6337 : loss : 0.011581, loss_ce: 0.004507
2022-01-08 14:24:20,487 iteration 6338 : loss : 0.014837, loss_ce: 0.004670
2022-01-08 14:24:22,843 iteration 6339 : loss : 0.013676, loss_ce: 0.005350
2022-01-08 14:24:25,205 iteration 6340 : loss : 0.012972, loss_ce: 0.006046
2022-01-08 14:24:27,819 iteration 6341 : loss : 0.017994, loss_ce: 0.004531
 93%|███████████████████████████  | 373/400 [4:30:42<19:11, 42.64s/it]2022-01-08 14:24:30,370 iteration 6342 : loss : 0.013677, loss_ce: 0.005299
2022-01-08 14:24:32,741 iteration 6343 : loss : 0.014133, loss_ce: 0.004127
2022-01-08 14:24:35,095 iteration 6344 : loss : 0.017971, loss_ce: 0.008142
2022-01-08 14:24:37,412 iteration 6345 : loss : 0.016465, loss_ce: 0.007790
2022-01-08 14:24:39,712 iteration 6346 : loss : 0.010446, loss_ce: 0.002845
2022-01-08 14:24:42,056 iteration 6347 : loss : 0.016966, loss_ce: 0.007413
2022-01-08 14:24:44,496 iteration 6348 : loss : 0.017576, loss_ce: 0.005965
2022-01-08 14:24:46,812 iteration 6349 : loss : 0.010331, loss_ce: 0.004164
2022-01-08 14:24:49,245 iteration 6350 : loss : 0.010408, loss_ce: 0.002761
2022-01-08 14:24:51,691 iteration 6351 : loss : 0.010791, loss_ce: 0.003696
2022-01-08 14:24:54,124 iteration 6352 : loss : 0.009766, loss_ce: 0.003926
2022-01-08 14:24:56,520 iteration 6353 : loss : 0.013955, loss_ce: 0.005920
2022-01-08 14:24:58,949 iteration 6354 : loss : 0.014104, loss_ce: 0.005175
2022-01-08 14:25:01,292 iteration 6355 : loss : 0.011497, loss_ce: 0.005367
2022-01-08 14:25:03,652 iteration 6356 : loss : 0.015673, loss_ce: 0.008041
2022-01-08 14:25:05,943 iteration 6357 : loss : 0.017635, loss_ce: 0.006449
2022-01-08 14:25:08,391 iteration 6358 : loss : 0.014030, loss_ce: 0.005238
 94%|███████████████████████████  | 374/400 [4:31:23<18:12, 42.02s/it]2022-01-08 14:25:10,798 iteration 6359 : loss : 0.012823, loss_ce: 0.004351
2022-01-08 14:25:13,383 iteration 6360 : loss : 0.018722, loss_ce: 0.005122
2022-01-08 14:25:15,781 iteration 6361 : loss : 0.014800, loss_ce: 0.003703
2022-01-08 14:25:18,112 iteration 6362 : loss : 0.013856, loss_ce: 0.006051
2022-01-08 14:25:20,480 iteration 6363 : loss : 0.020898, loss_ce: 0.008426
2022-01-08 14:25:22,696 iteration 6364 : loss : 0.008160, loss_ce: 0.003173
2022-01-08 14:25:24,974 iteration 6365 : loss : 0.012055, loss_ce: 0.004694
2022-01-08 14:25:27,386 iteration 6366 : loss : 0.015695, loss_ce: 0.005615
2022-01-08 14:25:29,800 iteration 6367 : loss : 0.013433, loss_ce: 0.006434
2022-01-08 14:25:32,157 iteration 6368 : loss : 0.014115, loss_ce: 0.004847
2022-01-08 14:25:34,595 iteration 6369 : loss : 0.018551, loss_ce: 0.009722
2022-01-08 14:25:36,978 iteration 6370 : loss : 0.019920, loss_ce: 0.005267
2022-01-08 14:25:39,288 iteration 6371 : loss : 0.015974, loss_ce: 0.005957
2022-01-08 14:25:41,565 iteration 6372 : loss : 0.014219, loss_ce: 0.007486
2022-01-08 14:25:43,734 iteration 6373 : loss : 0.008464, loss_ce: 0.002186
2022-01-08 14:25:45,953 iteration 6374 : loss : 0.009404, loss_ce: 0.003776
2022-01-08 14:25:45,953 Training Data Eval:
2022-01-08 14:25:58,331   Average segmentation loss on training set: 0.0067
2022-01-08 14:25:58,331 Validation Data Eval:
2022-01-08 14:26:02,982   Average segmentation loss on validation set: 0.0659
2022-01-08 14:26:05,347 iteration 6375 : loss : 0.012241, loss_ce: 0.004315
 94%|███████████████████████████▏ | 375/400 [4:32:20<19:22, 46.50s/it]2022-01-08 14:26:07,842 iteration 6376 : loss : 0.018221, loss_ce: 0.007043
2022-01-08 14:26:10,075 iteration 6377 : loss : 0.015450, loss_ce: 0.006026
2022-01-08 14:26:12,329 iteration 6378 : loss : 0.012933, loss_ce: 0.004378
2022-01-08 14:26:14,661 iteration 6379 : loss : 0.023296, loss_ce: 0.005465
2022-01-08 14:26:16,873 iteration 6380 : loss : 0.009184, loss_ce: 0.004106
2022-01-08 14:26:19,193 iteration 6381 : loss : 0.011662, loss_ce: 0.004429
2022-01-08 14:26:21,661 iteration 6382 : loss : 0.019373, loss_ce: 0.008162
2022-01-08 14:26:24,087 iteration 6383 : loss : 0.011214, loss_ce: 0.004351
2022-01-08 14:26:26,484 iteration 6384 : loss : 0.011915, loss_ce: 0.005080
2022-01-08 14:26:28,910 iteration 6385 : loss : 0.017870, loss_ce: 0.008071
2022-01-08 14:26:31,289 iteration 6386 : loss : 0.013346, loss_ce: 0.004956
2022-01-08 14:26:33,708 iteration 6387 : loss : 0.019936, loss_ce: 0.008891
2022-01-08 14:26:35,930 iteration 6388 : loss : 0.010250, loss_ce: 0.003880
2022-01-08 14:26:38,077 iteration 6389 : loss : 0.009468, loss_ce: 0.002831
2022-01-08 14:26:40,385 iteration 6390 : loss : 0.011383, loss_ce: 0.004409
2022-01-08 14:26:42,860 iteration 6391 : loss : 0.021645, loss_ce: 0.005301
2022-01-08 14:26:45,214 iteration 6392 : loss : 0.008283, loss_ce: 0.003559
 94%|███████████████████████████▎ | 376/400 [4:32:59<17:48, 44.51s/it]2022-01-08 14:26:47,631 iteration 6393 : loss : 0.009766, loss_ce: 0.002903
2022-01-08 14:26:49,968 iteration 6394 : loss : 0.013401, loss_ce: 0.004115
2022-01-08 14:26:52,356 iteration 6395 : loss : 0.009844, loss_ce: 0.004475
2022-01-08 14:26:54,829 iteration 6396 : loss : 0.013981, loss_ce: 0.005836
2022-01-08 14:26:57,208 iteration 6397 : loss : 0.019943, loss_ce: 0.009684
2022-01-08 14:26:59,525 iteration 6398 : loss : 0.010293, loss_ce: 0.003108
2022-01-08 14:27:01,894 iteration 6399 : loss : 0.014053, loss_ce: 0.004567
2022-01-08 14:27:04,284 iteration 6400 : loss : 0.011273, loss_ce: 0.005092
2022-01-08 14:27:06,553 iteration 6401 : loss : 0.010064, loss_ce: 0.003961
2022-01-08 14:27:08,821 iteration 6402 : loss : 0.017402, loss_ce: 0.006774
2022-01-08 14:27:11,194 iteration 6403 : loss : 0.015759, loss_ce: 0.006341
2022-01-08 14:27:13,525 iteration 6404 : loss : 0.011779, loss_ce: 0.003434
2022-01-08 14:27:15,790 iteration 6405 : loss : 0.014129, loss_ce: 0.005240
2022-01-08 14:27:18,244 iteration 6406 : loss : 0.019909, loss_ce: 0.013399
2022-01-08 14:27:20,447 iteration 6407 : loss : 0.010461, loss_ce: 0.003151
2022-01-08 14:27:22,913 iteration 6408 : loss : 0.015228, loss_ce: 0.004546
2022-01-08 14:27:25,263 iteration 6409 : loss : 0.013132, loss_ce: 0.004980
 94%|███████████████████████████▎ | 377/400 [4:33:40<16:32, 43.17s/it]2022-01-08 14:27:27,690 iteration 6410 : loss : 0.018379, loss_ce: 0.006970
2022-01-08 14:27:29,953 iteration 6411 : loss : 0.013971, loss_ce: 0.005410
2022-01-08 14:27:32,273 iteration 6412 : loss : 0.015475, loss_ce: 0.007717
2022-01-08 14:27:34,569 iteration 6413 : loss : 0.008759, loss_ce: 0.002742
2022-01-08 14:27:36,826 iteration 6414 : loss : 0.017754, loss_ce: 0.006626
2022-01-08 14:27:39,037 iteration 6415 : loss : 0.013260, loss_ce: 0.004224
2022-01-08 14:27:41,407 iteration 6416 : loss : 0.020972, loss_ce: 0.005356
2022-01-08 14:27:43,739 iteration 6417 : loss : 0.014570, loss_ce: 0.006875
2022-01-08 14:27:46,070 iteration 6418 : loss : 0.011533, loss_ce: 0.004412
2022-01-08 14:27:48,334 iteration 6419 : loss : 0.012495, loss_ce: 0.003855
2022-01-08 14:27:50,684 iteration 6420 : loss : 0.014428, loss_ce: 0.004242
2022-01-08 14:27:53,041 iteration 6421 : loss : 0.011909, loss_ce: 0.004537
2022-01-08 14:27:55,293 iteration 6422 : loss : 0.012282, loss_ce: 0.004724
2022-01-08 14:27:57,720 iteration 6423 : loss : 0.019249, loss_ce: 0.005936
2022-01-08 14:28:00,160 iteration 6424 : loss : 0.015155, loss_ce: 0.007146
2022-01-08 14:28:02,503 iteration 6425 : loss : 0.012911, loss_ce: 0.004898
2022-01-08 14:28:04,910 iteration 6426 : loss : 0.017876, loss_ce: 0.007765
 94%|███████████████████████████▍ | 378/400 [4:34:19<15:26, 42.11s/it]2022-01-08 14:28:07,282 iteration 6427 : loss : 0.013406, loss_ce: 0.005225
2022-01-08 14:28:09,542 iteration 6428 : loss : 0.010729, loss_ce: 0.005048
2022-01-08 14:28:11,848 iteration 6429 : loss : 0.016075, loss_ce: 0.005110
2022-01-08 14:28:14,100 iteration 6430 : loss : 0.010048, loss_ce: 0.002723
2022-01-08 14:28:16,423 iteration 6431 : loss : 0.013366, loss_ce: 0.004476
2022-01-08 14:28:18,730 iteration 6432 : loss : 0.011530, loss_ce: 0.004349
2022-01-08 14:28:21,041 iteration 6433 : loss : 0.013693, loss_ce: 0.004880
2022-01-08 14:28:23,217 iteration 6434 : loss : 0.008025, loss_ce: 0.002874
2022-01-08 14:28:25,512 iteration 6435 : loss : 0.012047, loss_ce: 0.005553
2022-01-08 14:28:27,774 iteration 6436 : loss : 0.012044, loss_ce: 0.004923
2022-01-08 14:28:30,089 iteration 6437 : loss : 0.018222, loss_ce: 0.004613
2022-01-08 14:28:32,383 iteration 6438 : loss : 0.014159, loss_ce: 0.005720
2022-01-08 14:28:34,703 iteration 6439 : loss : 0.012830, loss_ce: 0.004719
2022-01-08 14:28:37,044 iteration 6440 : loss : 0.016901, loss_ce: 0.007181
2022-01-08 14:28:39,360 iteration 6441 : loss : 0.013178, loss_ce: 0.003713
2022-01-08 14:28:41,706 iteration 6442 : loss : 0.014134, loss_ce: 0.006224
2022-01-08 14:28:44,021 iteration 6443 : loss : 0.014075, loss_ce: 0.005253
 95%|███████████████████████████▍ | 379/400 [4:34:58<14:25, 41.21s/it]2022-01-08 14:28:46,389 iteration 6444 : loss : 0.014964, loss_ce: 0.006872
2022-01-08 14:28:48,757 iteration 6445 : loss : 0.013864, loss_ce: 0.005164
2022-01-08 14:28:51,000 iteration 6446 : loss : 0.011716, loss_ce: 0.002901
2022-01-08 14:28:53,230 iteration 6447 : loss : 0.014094, loss_ce: 0.007385
2022-01-08 14:28:55,585 iteration 6448 : loss : 0.010349, loss_ce: 0.004443
2022-01-08 14:28:57,967 iteration 6449 : loss : 0.013345, loss_ce: 0.004493
2022-01-08 14:29:00,331 iteration 6450 : loss : 0.010655, loss_ce: 0.004660
2022-01-08 14:29:02,713 iteration 6451 : loss : 0.010851, loss_ce: 0.004159
2022-01-08 14:29:05,126 iteration 6452 : loss : 0.011995, loss_ce: 0.005220
2022-01-08 14:29:07,447 iteration 6453 : loss : 0.013524, loss_ce: 0.005848
2022-01-08 14:29:09,856 iteration 6454 : loss : 0.010962, loss_ce: 0.003964
2022-01-08 14:29:12,219 iteration 6455 : loss : 0.012222, loss_ce: 0.004207
2022-01-08 14:29:14,636 iteration 6456 : loss : 0.020819, loss_ce: 0.009791
2022-01-08 14:29:16,995 iteration 6457 : loss : 0.011716, loss_ce: 0.003588
2022-01-08 14:29:19,279 iteration 6458 : loss : 0.011003, loss_ce: 0.003485
2022-01-08 14:29:21,569 iteration 6459 : loss : 0.010412, loss_ce: 0.003542
2022-01-08 14:29:21,569 Training Data Eval:
2022-01-08 14:29:34,345   Average segmentation loss on training set: 0.0065
2022-01-08 14:29:34,346 Validation Data Eval:
2022-01-08 14:29:38,682   Average segmentation loss on validation set: 0.0738
2022-01-08 14:29:41,101 iteration 6460 : loss : 0.017744, loss_ce: 0.005288
 95%|███████████████████████████▌ | 380/400 [4:35:55<15:19, 45.97s/it]2022-01-08 14:29:43,546 iteration 6461 : loss : 0.022772, loss_ce: 0.006666
2022-01-08 14:29:45,908 iteration 6462 : loss : 0.011836, loss_ce: 0.003931
2022-01-08 14:29:48,207 iteration 6463 : loss : 0.008300, loss_ce: 0.002300
2022-01-08 14:29:50,530 iteration 6464 : loss : 0.010414, loss_ce: 0.003670
2022-01-08 14:29:52,890 iteration 6465 : loss : 0.018658, loss_ce: 0.005663
2022-01-08 14:29:55,313 iteration 6466 : loss : 0.013187, loss_ce: 0.005119
2022-01-08 14:29:57,871 iteration 6467 : loss : 0.013499, loss_ce: 0.006571
2022-01-08 14:30:00,336 iteration 6468 : loss : 0.013256, loss_ce: 0.006394
2022-01-08 14:30:02,686 iteration 6469 : loss : 0.011960, loss_ce: 0.005715
2022-01-08 14:30:04,968 iteration 6470 : loss : 0.021873, loss_ce: 0.006375
2022-01-08 14:30:07,291 iteration 6471 : loss : 0.020240, loss_ce: 0.006907
2022-01-08 14:30:09,596 iteration 6472 : loss : 0.013294, loss_ce: 0.003630
2022-01-08 14:30:12,006 iteration 6473 : loss : 0.011863, loss_ce: 0.005867
2022-01-08 14:30:14,451 iteration 6474 : loss : 0.017653, loss_ce: 0.009127
2022-01-08 14:30:16,772 iteration 6475 : loss : 0.009120, loss_ce: 0.003132
2022-01-08 14:30:19,123 iteration 6476 : loss : 0.010689, loss_ce: 0.003995
2022-01-08 14:30:21,434 iteration 6477 : loss : 0.010415, loss_ce: 0.004072
 95%|███████████████████████████▌ | 381/400 [4:36:36<14:01, 44.28s/it]2022-01-08 14:30:23,863 iteration 6478 : loss : 0.011923, loss_ce: 0.004668
2022-01-08 14:30:26,324 iteration 6479 : loss : 0.015362, loss_ce: 0.007570
2022-01-08 14:30:28,712 iteration 6480 : loss : 0.017390, loss_ce: 0.004151
2022-01-08 14:30:31,084 iteration 6481 : loss : 0.013501, loss_ce: 0.005534
2022-01-08 14:30:33,439 iteration 6482 : loss : 0.016343, loss_ce: 0.006246
2022-01-08 14:30:35,860 iteration 6483 : loss : 0.014444, loss_ce: 0.005145
2022-01-08 14:30:38,235 iteration 6484 : loss : 0.013426, loss_ce: 0.003903
2022-01-08 14:30:40,610 iteration 6485 : loss : 0.021435, loss_ce: 0.009095
2022-01-08 14:30:43,091 iteration 6486 : loss : 0.013340, loss_ce: 0.004323
2022-01-08 14:30:45,530 iteration 6487 : loss : 0.015936, loss_ce: 0.004705
2022-01-08 14:30:47,848 iteration 6488 : loss : 0.009147, loss_ce: 0.003851
2022-01-08 14:30:50,264 iteration 6489 : loss : 0.019529, loss_ce: 0.003884
2022-01-08 14:30:52,629 iteration 6490 : loss : 0.009610, loss_ce: 0.003686
2022-01-08 14:30:55,036 iteration 6491 : loss : 0.016333, loss_ce: 0.005278
2022-01-08 14:30:57,429 iteration 6492 : loss : 0.010209, loss_ce: 0.003704
2022-01-08 14:30:59,862 iteration 6493 : loss : 0.016594, loss_ce: 0.004575
2022-01-08 14:31:02,293 iteration 6494 : loss : 0.015321, loss_ce: 0.006334
 96%|███████████████████████████▋ | 382/400 [4:37:17<12:58, 43.25s/it]2022-01-08 14:31:04,736 iteration 6495 : loss : 0.010824, loss_ce: 0.003174
2022-01-08 14:31:07,072 iteration 6496 : loss : 0.013271, loss_ce: 0.006509
2022-01-08 14:31:09,488 iteration 6497 : loss : 0.009992, loss_ce: 0.003566
2022-01-08 14:31:11,803 iteration 6498 : loss : 0.015290, loss_ce: 0.007316
2022-01-08 14:31:14,179 iteration 6499 : loss : 0.030220, loss_ce: 0.011076
2022-01-08 14:31:16,530 iteration 6500 : loss : 0.015223, loss_ce: 0.005947
2022-01-08 14:31:18,833 iteration 6501 : loss : 0.012940, loss_ce: 0.003353
2022-01-08 14:31:21,182 iteration 6502 : loss : 0.014748, loss_ce: 0.005450
2022-01-08 14:31:23,680 iteration 6503 : loss : 0.020466, loss_ce: 0.007545
2022-01-08 14:31:26,053 iteration 6504 : loss : 0.013675, loss_ce: 0.007721
2022-01-08 14:31:28,374 iteration 6505 : loss : 0.011245, loss_ce: 0.003177
2022-01-08 14:31:30,686 iteration 6506 : loss : 0.010560, loss_ce: 0.003109
2022-01-08 14:31:33,073 iteration 6507 : loss : 0.018887, loss_ce: 0.006602
2022-01-08 14:31:35,497 iteration 6508 : loss : 0.011273, loss_ce: 0.003683
2022-01-08 14:31:37,885 iteration 6509 : loss : 0.010664, loss_ce: 0.004415
2022-01-08 14:31:40,276 iteration 6510 : loss : 0.013356, loss_ce: 0.004546
2022-01-08 14:31:42,750 iteration 6511 : loss : 0.015853, loss_ce: 0.007364
 96%|███████████████████████████▊ | 383/400 [4:37:57<12:01, 42.41s/it]2022-01-08 14:31:45,182 iteration 6512 : loss : 0.011651, loss_ce: 0.004700
2022-01-08 14:31:47,566 iteration 6513 : loss : 0.014308, loss_ce: 0.005170
2022-01-08 14:31:49,941 iteration 6514 : loss : 0.011370, loss_ce: 0.002996
2022-01-08 14:31:52,327 iteration 6515 : loss : 0.013065, loss_ce: 0.003703
2022-01-08 14:31:54,701 iteration 6516 : loss : 0.012379, loss_ce: 0.003663
2022-01-08 14:31:57,171 iteration 6517 : loss : 0.013573, loss_ce: 0.005871
2022-01-08 14:31:59,578 iteration 6518 : loss : 0.013303, loss_ce: 0.005632
2022-01-08 14:32:02,045 iteration 6519 : loss : 0.013412, loss_ce: 0.003953
2022-01-08 14:32:04,445 iteration 6520 : loss : 0.010723, loss_ce: 0.004563
2022-01-08 14:32:06,877 iteration 6521 : loss : 0.011537, loss_ce: 0.004930
2022-01-08 14:32:09,215 iteration 6522 : loss : 0.012345, loss_ce: 0.004921
2022-01-08 14:32:11,467 iteration 6523 : loss : 0.011420, loss_ce: 0.003685
2022-01-08 14:32:13,809 iteration 6524 : loss : 0.016938, loss_ce: 0.005774
2022-01-08 14:32:16,154 iteration 6525 : loss : 0.010897, loss_ce: 0.003545
2022-01-08 14:32:18,561 iteration 6526 : loss : 0.011161, loss_ce: 0.004226
2022-01-08 14:32:20,978 iteration 6527 : loss : 0.012535, loss_ce: 0.004245
2022-01-08 14:32:23,436 iteration 6528 : loss : 0.012815, loss_ce: 0.005099
 96%|███████████████████████████▊ | 384/400 [4:38:38<11:10, 41.89s/it]2022-01-08 14:32:25,816 iteration 6529 : loss : 0.010539, loss_ce: 0.003916
2022-01-08 14:32:28,213 iteration 6530 : loss : 0.014789, loss_ce: 0.009946
2022-01-08 14:32:30,608 iteration 6531 : loss : 0.021915, loss_ce: 0.003949
2022-01-08 14:32:33,000 iteration 6532 : loss : 0.009400, loss_ce: 0.002836
2022-01-08 14:32:35,391 iteration 6533 : loss : 0.013271, loss_ce: 0.005927
2022-01-08 14:32:37,815 iteration 6534 : loss : 0.015233, loss_ce: 0.004311
2022-01-08 14:32:40,206 iteration 6535 : loss : 0.012174, loss_ce: 0.004599
2022-01-08 14:32:42,628 iteration 6536 : loss : 0.013155, loss_ce: 0.004881
2022-01-08 14:32:45,137 iteration 6537 : loss : 0.023486, loss_ce: 0.007786
2022-01-08 14:32:47,507 iteration 6538 : loss : 0.010960, loss_ce: 0.003784
2022-01-08 14:32:49,995 iteration 6539 : loss : 0.016563, loss_ce: 0.006398
2022-01-08 14:32:52,289 iteration 6540 : loss : 0.012530, loss_ce: 0.005522
2022-01-08 14:32:54,632 iteration 6541 : loss : 0.009940, loss_ce: 0.003836
2022-01-08 14:32:57,027 iteration 6542 : loss : 0.014948, loss_ce: 0.005690
2022-01-08 14:32:59,455 iteration 6543 : loss : 0.013057, loss_ce: 0.005405
2022-01-08 14:33:01,967 iteration 6544 : loss : 0.014071, loss_ce: 0.005249
2022-01-08 14:33:01,967 Training Data Eval:
2022-01-08 14:33:14,797   Average segmentation loss on training set: 0.0066
2022-01-08 14:33:14,797 Validation Data Eval:
2022-01-08 14:33:19,281   Average segmentation loss on validation set: 0.0725
2022-01-08 14:33:21,761 iteration 6545 : loss : 0.010406, loss_ce: 0.002761
 96%|███████████████████████████▉ | 385/400 [4:39:36<11:42, 46.83s/it]2022-01-08 14:33:24,230 iteration 6546 : loss : 0.017599, loss_ce: 0.006558
2022-01-08 14:33:26,571 iteration 6547 : loss : 0.009771, loss_ce: 0.002155
2022-01-08 14:33:29,002 iteration 6548 : loss : 0.020015, loss_ce: 0.005507
2022-01-08 14:33:31,452 iteration 6549 : loss : 0.020825, loss_ce: 0.005795
2022-01-08 14:33:33,840 iteration 6550 : loss : 0.013218, loss_ce: 0.006191
2022-01-08 14:33:36,286 iteration 6551 : loss : 0.015099, loss_ce: 0.006527
2022-01-08 14:33:38,723 iteration 6552 : loss : 0.013235, loss_ce: 0.004899
2022-01-08 14:33:41,271 iteration 6553 : loss : 0.014044, loss_ce: 0.005032
2022-01-08 14:33:43,776 iteration 6554 : loss : 0.022773, loss_ce: 0.008643
2022-01-08 14:33:46,138 iteration 6555 : loss : 0.014235, loss_ce: 0.005528
2022-01-08 14:33:48,519 iteration 6556 : loss : 0.016161, loss_ce: 0.005491
2022-01-08 14:33:50,833 iteration 6557 : loss : 0.008415, loss_ce: 0.003058
2022-01-08 14:33:53,222 iteration 6558 : loss : 0.024143, loss_ce: 0.008078
2022-01-08 14:33:55,498 iteration 6559 : loss : 0.008678, loss_ce: 0.003063
2022-01-08 14:33:57,786 iteration 6560 : loss : 0.009261, loss_ce: 0.004125
2022-01-08 14:34:00,197 iteration 6561 : loss : 0.015074, loss_ce: 0.004702
2022-01-08 14:34:02,569 iteration 6562 : loss : 0.015512, loss_ce: 0.006892
 96%|███████████████████████████▉ | 386/400 [4:40:17<10:30, 45.02s/it]2022-01-08 14:34:05,004 iteration 6563 : loss : 0.014743, loss_ce: 0.006683
2022-01-08 14:34:07,361 iteration 6564 : loss : 0.017464, loss_ce: 0.006425
2022-01-08 14:34:09,664 iteration 6565 : loss : 0.018145, loss_ce: 0.004566
2022-01-08 14:34:12,121 iteration 6566 : loss : 0.018072, loss_ce: 0.006252
2022-01-08 14:34:14,466 iteration 6567 : loss : 0.017681, loss_ce: 0.004797
2022-01-08 14:34:16,963 iteration 6568 : loss : 0.009262, loss_ce: 0.003278
2022-01-08 14:34:19,383 iteration 6569 : loss : 0.019183, loss_ce: 0.005475
2022-01-08 14:34:21,878 iteration 6570 : loss : 0.026819, loss_ce: 0.011489
2022-01-08 14:34:24,225 iteration 6571 : loss : 0.009336, loss_ce: 0.003923
2022-01-08 14:34:26,549 iteration 6572 : loss : 0.011691, loss_ce: 0.004136
2022-01-08 14:34:28,873 iteration 6573 : loss : 0.012123, loss_ce: 0.003995
2022-01-08 14:34:31,293 iteration 6574 : loss : 0.014726, loss_ce: 0.005632
2022-01-08 14:34:33,657 iteration 6575 : loss : 0.008200, loss_ce: 0.003374
2022-01-08 14:34:36,194 iteration 6576 : loss : 0.018257, loss_ce: 0.007414
2022-01-08 14:34:38,624 iteration 6577 : loss : 0.016181, loss_ce: 0.005167
2022-01-08 14:34:41,111 iteration 6578 : loss : 0.012573, loss_ce: 0.006269
2022-01-08 14:34:43,524 iteration 6579 : loss : 0.016685, loss_ce: 0.004251
 97%|████████████████████████████ | 387/400 [4:40:58<09:29, 43.80s/it]2022-01-08 14:34:45,988 iteration 6580 : loss : 0.013306, loss_ce: 0.004902
2022-01-08 14:34:48,422 iteration 6581 : loss : 0.016460, loss_ce: 0.004774
2022-01-08 14:34:50,853 iteration 6582 : loss : 0.016106, loss_ce: 0.008013
2022-01-08 14:34:53,206 iteration 6583 : loss : 0.008606, loss_ce: 0.003057
2022-01-08 14:34:55,566 iteration 6584 : loss : 0.013994, loss_ce: 0.005435
2022-01-08 14:34:57,882 iteration 6585 : loss : 0.011268, loss_ce: 0.004094
2022-01-08 14:35:00,245 iteration 6586 : loss : 0.012652, loss_ce: 0.005053
2022-01-08 14:35:02,493 iteration 6587 : loss : 0.012171, loss_ce: 0.004700
2022-01-08 14:35:04,899 iteration 6588 : loss : 0.014222, loss_ce: 0.005095
2022-01-08 14:35:07,330 iteration 6589 : loss : 0.013855, loss_ce: 0.004519
2022-01-08 14:35:09,720 iteration 6590 : loss : 0.011931, loss_ce: 0.004735
2022-01-08 14:35:12,059 iteration 6591 : loss : 0.012323, loss_ce: 0.005136
2022-01-08 14:35:14,409 iteration 6592 : loss : 0.010701, loss_ce: 0.003306
2022-01-08 14:35:16,852 iteration 6593 : loss : 0.013449, loss_ce: 0.005901
2022-01-08 14:35:19,344 iteration 6594 : loss : 0.010169, loss_ce: 0.003720
2022-01-08 14:35:21,699 iteration 6595 : loss : 0.012670, loss_ce: 0.004048
2022-01-08 14:35:24,031 iteration 6596 : loss : 0.007288, loss_ce: 0.002801
 97%|████████████████████████████▏| 388/400 [4:41:38<08:33, 42.82s/it]2022-01-08 14:35:26,505 iteration 6597 : loss : 0.013218, loss_ce: 0.006969
2022-01-08 14:35:28,901 iteration 6598 : loss : 0.021107, loss_ce: 0.005397
2022-01-08 14:35:31,204 iteration 6599 : loss : 0.011062, loss_ce: 0.004282
2022-01-08 14:35:33,637 iteration 6600 : loss : 0.012916, loss_ce: 0.004200
2022-01-08 14:35:36,005 iteration 6601 : loss : 0.012899, loss_ce: 0.005567
2022-01-08 14:35:38,454 iteration 6602 : loss : 0.008031, loss_ce: 0.002806
2022-01-08 14:35:40,874 iteration 6603 : loss : 0.021561, loss_ce: 0.007854
2022-01-08 14:35:43,346 iteration 6604 : loss : 0.013899, loss_ce: 0.005511
2022-01-08 14:35:45,766 iteration 6605 : loss : 0.014722, loss_ce: 0.005641
2022-01-08 14:35:48,099 iteration 6606 : loss : 0.012237, loss_ce: 0.006419
2022-01-08 14:35:50,423 iteration 6607 : loss : 0.025647, loss_ce: 0.006605
2022-01-08 14:35:52,810 iteration 6608 : loss : 0.014898, loss_ce: 0.005371
2022-01-08 14:35:55,235 iteration 6609 : loss : 0.011640, loss_ce: 0.004530
2022-01-08 14:35:57,758 iteration 6610 : loss : 0.013730, loss_ce: 0.003660
2022-01-08 14:36:00,080 iteration 6611 : loss : 0.010677, loss_ce: 0.004715
2022-01-08 14:36:02,427 iteration 6612 : loss : 0.012231, loss_ce: 0.004534
2022-01-08 14:36:04,993 iteration 6613 : loss : 0.019075, loss_ce: 0.004731
 97%|████████████████████████████▏| 389/400 [4:42:19<07:44, 42.26s/it]2022-01-08 14:36:07,367 iteration 6614 : loss : 0.008580, loss_ce: 0.003265
2022-01-08 14:36:09,726 iteration 6615 : loss : 0.018884, loss_ce: 0.007326
2022-01-08 14:36:12,045 iteration 6616 : loss : 0.011767, loss_ce: 0.004529
2022-01-08 14:36:14,336 iteration 6617 : loss : 0.010716, loss_ce: 0.002028
2022-01-08 14:36:16,685 iteration 6618 : loss : 0.011644, loss_ce: 0.003731
2022-01-08 14:36:19,067 iteration 6619 : loss : 0.011835, loss_ce: 0.004134
2022-01-08 14:36:21,465 iteration 6620 : loss : 0.014341, loss_ce: 0.004894
2022-01-08 14:36:23,804 iteration 6621 : loss : 0.011331, loss_ce: 0.004897
2022-01-08 14:36:26,084 iteration 6622 : loss : 0.008941, loss_ce: 0.002823
2022-01-08 14:36:28,543 iteration 6623 : loss : 0.013071, loss_ce: 0.006418
2022-01-08 14:36:30,888 iteration 6624 : loss : 0.010433, loss_ce: 0.003790
2022-01-08 14:36:33,240 iteration 6625 : loss : 0.008412, loss_ce: 0.003345
2022-01-08 14:36:35,615 iteration 6626 : loss : 0.012847, loss_ce: 0.004935
2022-01-08 14:36:37,991 iteration 6627 : loss : 0.008503, loss_ce: 0.002890
2022-01-08 14:36:40,445 iteration 6628 : loss : 0.011473, loss_ce: 0.004009
2022-01-08 14:36:42,775 iteration 6629 : loss : 0.009728, loss_ce: 0.003960
2022-01-08 14:36:42,775 Training Data Eval:
2022-01-08 14:36:55,331   Average segmentation loss on training set: 0.0064
2022-01-08 14:36:55,331 Validation Data Eval:
2022-01-08 14:36:59,822   Average segmentation loss on validation set: 0.0754
2022-01-08 14:37:02,253 iteration 6630 : loss : 0.012291, loss_ce: 0.004843
 98%|████████████████████████████▎| 390/400 [4:43:17<07:47, 46.76s/it]2022-01-08 14:37:04,725 iteration 6631 : loss : 0.008839, loss_ce: 0.003496
2022-01-08 14:37:07,128 iteration 6632 : loss : 0.020074, loss_ce: 0.004309
2022-01-08 14:37:09,451 iteration 6633 : loss : 0.012721, loss_ce: 0.006103
2022-01-08 14:37:11,781 iteration 6634 : loss : 0.012781, loss_ce: 0.005142
2022-01-08 14:37:14,157 iteration 6635 : loss : 0.008369, loss_ce: 0.003298
2022-01-08 14:37:16,486 iteration 6636 : loss : 0.010078, loss_ce: 0.005063
2022-01-08 14:37:18,926 iteration 6637 : loss : 0.014753, loss_ce: 0.004562
2022-01-08 14:37:21,321 iteration 6638 : loss : 0.008410, loss_ce: 0.002439
2022-01-08 14:37:23,736 iteration 6639 : loss : 0.013063, loss_ce: 0.004084
2022-01-08 14:37:26,190 iteration 6640 : loss : 0.015131, loss_ce: 0.005221
2022-01-08 14:37:28,756 iteration 6641 : loss : 0.012416, loss_ce: 0.005328
2022-01-08 14:37:31,141 iteration 6642 : loss : 0.011475, loss_ce: 0.003551
2022-01-08 14:37:33,521 iteration 6643 : loss : 0.014995, loss_ce: 0.006754
2022-01-08 14:37:35,916 iteration 6644 : loss : 0.014958, loss_ce: 0.006669
2022-01-08 14:37:38,274 iteration 6645 : loss : 0.016759, loss_ce: 0.007234
2022-01-08 14:37:40,707 iteration 6646 : loss : 0.024297, loss_ce: 0.010551
2022-01-08 14:37:43,130 iteration 6647 : loss : 0.015372, loss_ce: 0.003204
 98%|████████████████████████████▎| 391/400 [4:43:57<06:44, 44.99s/it]2022-01-08 14:37:45,560 iteration 6648 : loss : 0.014947, loss_ce: 0.005567
2022-01-08 14:37:47,962 iteration 6649 : loss : 0.014780, loss_ce: 0.004068
2022-01-08 14:37:50,325 iteration 6650 : loss : 0.010569, loss_ce: 0.003956
2022-01-08 14:37:52,683 iteration 6651 : loss : 0.011681, loss_ce: 0.004897
2022-01-08 14:37:55,025 iteration 6652 : loss : 0.014443, loss_ce: 0.005245
2022-01-08 14:37:57,433 iteration 6653 : loss : 0.018623, loss_ce: 0.005637
2022-01-08 14:37:59,866 iteration 6654 : loss : 0.020309, loss_ce: 0.006579
2022-01-08 14:38:02,403 iteration 6655 : loss : 0.013358, loss_ce: 0.006853
2022-01-08 14:38:04,868 iteration 6656 : loss : 0.014731, loss_ce: 0.005861
2022-01-08 14:38:07,233 iteration 6657 : loss : 0.015111, loss_ce: 0.004680
2022-01-08 14:38:09,587 iteration 6658 : loss : 0.028992, loss_ce: 0.012298
2022-01-08 14:38:11,987 iteration 6659 : loss : 0.021302, loss_ce: 0.006099
2022-01-08 14:38:14,283 iteration 6660 : loss : 0.010372, loss_ce: 0.004434
2022-01-08 14:38:16,649 iteration 6661 : loss : 0.009902, loss_ce: 0.003828
2022-01-08 14:38:19,068 iteration 6662 : loss : 0.013377, loss_ce: 0.004525
2022-01-08 14:38:21,387 iteration 6663 : loss : 0.011012, loss_ce: 0.004475
2022-01-08 14:38:23,772 iteration 6664 : loss : 0.008889, loss_ce: 0.004129
 98%|████████████████████████████▍| 392/400 [4:44:38<05:49, 43.69s/it]2022-01-08 14:38:26,187 iteration 6665 : loss : 0.020974, loss_ce: 0.007985
2022-01-08 14:38:28,549 iteration 6666 : loss : 0.010149, loss_ce: 0.003163
2022-01-08 14:38:30,854 iteration 6667 : loss : 0.013977, loss_ce: 0.005449
2022-01-08 14:38:33,259 iteration 6668 : loss : 0.019097, loss_ce: 0.010886
2022-01-08 14:38:35,615 iteration 6669 : loss : 0.013938, loss_ce: 0.004936
2022-01-08 14:38:37,990 iteration 6670 : loss : 0.007909, loss_ce: 0.003196
2022-01-08 14:38:40,319 iteration 6671 : loss : 0.015444, loss_ce: 0.005983
2022-01-08 14:38:42,782 iteration 6672 : loss : 0.009287, loss_ce: 0.002469
2022-01-08 14:38:45,204 iteration 6673 : loss : 0.015305, loss_ce: 0.005930
2022-01-08 14:38:47,554 iteration 6674 : loss : 0.013976, loss_ce: 0.005444
2022-01-08 14:38:49,943 iteration 6675 : loss : 0.019329, loss_ce: 0.007330
2022-01-08 14:38:52,210 iteration 6676 : loss : 0.009055, loss_ce: 0.002932
2022-01-08 14:38:54,610 iteration 6677 : loss : 0.013735, loss_ce: 0.003008
2022-01-08 14:38:56,906 iteration 6678 : loss : 0.008018, loss_ce: 0.003535
2022-01-08 14:38:59,405 iteration 6679 : loss : 0.016747, loss_ce: 0.007585
2022-01-08 14:39:01,829 iteration 6680 : loss : 0.019136, loss_ce: 0.006591
2022-01-08 14:39:04,265 iteration 6681 : loss : 0.010109, loss_ce: 0.004190
 98%|████████████████████████████▍| 393/400 [4:45:19<04:59, 42.73s/it]2022-01-08 14:39:06,712 iteration 6682 : loss : 0.015423, loss_ce: 0.008189
2022-01-08 14:39:09,202 iteration 6683 : loss : 0.012506, loss_ce: 0.004811
2022-01-08 14:39:11,497 iteration 6684 : loss : 0.009815, loss_ce: 0.003075
2022-01-08 14:39:13,850 iteration 6685 : loss : 0.018070, loss_ce: 0.007117
2022-01-08 14:39:16,204 iteration 6686 : loss : 0.012482, loss_ce: 0.006163
2022-01-08 14:39:18,594 iteration 6687 : loss : 0.014972, loss_ce: 0.003491
2022-01-08 14:39:21,072 iteration 6688 : loss : 0.015660, loss_ce: 0.006861
2022-01-08 14:39:23,434 iteration 6689 : loss : 0.009630, loss_ce: 0.003357
2022-01-08 14:39:25,720 iteration 6690 : loss : 0.013616, loss_ce: 0.005431
2022-01-08 14:39:28,142 iteration 6691 : loss : 0.016929, loss_ce: 0.006167
2022-01-08 14:39:30,509 iteration 6692 : loss : 0.019679, loss_ce: 0.005784
2022-01-08 14:39:32,834 iteration 6693 : loss : 0.013890, loss_ce: 0.005200
2022-01-08 14:39:35,145 iteration 6694 : loss : 0.012409, loss_ce: 0.004798
2022-01-08 14:39:37,464 iteration 6695 : loss : 0.014483, loss_ce: 0.006195
2022-01-08 14:39:39,666 iteration 6696 : loss : 0.012609, loss_ce: 0.006088
2022-01-08 14:39:42,073 iteration 6697 : loss : 0.012800, loss_ce: 0.004550
2022-01-08 14:39:44,432 iteration 6698 : loss : 0.011712, loss_ce: 0.003875
 98%|████████████████████████████▌| 394/400 [4:45:59<04:11, 41.96s/it]2022-01-08 14:39:46,758 iteration 6699 : loss : 0.011651, loss_ce: 0.006297
2022-01-08 14:39:49,111 iteration 6700 : loss : 0.018789, loss_ce: 0.007560
2022-01-08 14:39:51,452 iteration 6701 : loss : 0.013011, loss_ce: 0.005930
2022-01-08 14:39:53,727 iteration 6702 : loss : 0.021768, loss_ce: 0.006689
2022-01-08 14:39:55,952 iteration 6703 : loss : 0.011878, loss_ce: 0.003430
2022-01-08 14:39:58,252 iteration 6704 : loss : 0.013802, loss_ce: 0.004126
2022-01-08 14:40:00,532 iteration 6705 : loss : 0.015760, loss_ce: 0.005420
2022-01-08 14:40:02,760 iteration 6706 : loss : 0.008415, loss_ce: 0.004072
2022-01-08 14:40:05,027 iteration 6707 : loss : 0.012266, loss_ce: 0.003552
2022-01-08 14:40:07,292 iteration 6708 : loss : 0.011211, loss_ce: 0.003717
2022-01-08 14:40:09,689 iteration 6709 : loss : 0.009916, loss_ce: 0.003203
2022-01-08 14:40:12,027 iteration 6710 : loss : 0.017397, loss_ce: 0.006127
2022-01-08 14:40:14,404 iteration 6711 : loss : 0.013356, loss_ce: 0.002320
2022-01-08 14:40:16,771 iteration 6712 : loss : 0.018403, loss_ce: 0.008370
2022-01-08 14:40:19,119 iteration 6713 : loss : 0.013682, loss_ce: 0.004686
2022-01-08 14:40:21,405 iteration 6714 : loss : 0.012387, loss_ce: 0.005507
2022-01-08 14:40:21,405 Training Data Eval:
2022-01-08 14:40:33,974   Average segmentation loss on training set: 0.0061
2022-01-08 14:40:33,974 Validation Data Eval:
2022-01-08 14:40:38,464   Average segmentation loss on validation set: 0.0782
2022-01-08 14:40:40,892 iteration 6715 : loss : 0.010599, loss_ce: 0.003630
 99%|████████████████████████████▋| 395/400 [4:46:55<03:51, 46.31s/it]2022-01-08 14:40:43,237 iteration 6716 : loss : 0.007415, loss_ce: 0.002618
2022-01-08 14:40:45,576 iteration 6717 : loss : 0.017831, loss_ce: 0.007209
2022-01-08 14:40:47,969 iteration 6718 : loss : 0.010668, loss_ce: 0.003558
2022-01-08 14:40:50,370 iteration 6719 : loss : 0.010133, loss_ce: 0.003230
2022-01-08 14:40:52,752 iteration 6720 : loss : 0.009765, loss_ce: 0.003379
2022-01-08 14:40:55,093 iteration 6721 : loss : 0.015266, loss_ce: 0.005126
2022-01-08 14:40:57,405 iteration 6722 : loss : 0.015126, loss_ce: 0.005312
2022-01-08 14:40:59,724 iteration 6723 : loss : 0.016036, loss_ce: 0.005486
2022-01-08 14:41:02,007 iteration 6724 : loss : 0.014406, loss_ce: 0.006903
2022-01-08 14:41:04,464 iteration 6725 : loss : 0.011173, loss_ce: 0.004885
2022-01-08 14:41:06,853 iteration 6726 : loss : 0.014178, loss_ce: 0.004300
2022-01-08 14:41:09,180 iteration 6727 : loss : 0.014489, loss_ce: 0.005679
2022-01-08 14:41:11,467 iteration 6728 : loss : 0.011908, loss_ce: 0.005239
2022-01-08 14:41:13,673 iteration 6729 : loss : 0.009780, loss_ce: 0.003184
2022-01-08 14:41:15,990 iteration 6730 : loss : 0.014197, loss_ce: 0.004851
2022-01-08 14:41:18,260 iteration 6731 : loss : 0.012431, loss_ce: 0.005448
2022-01-08 14:41:20,541 iteration 6732 : loss : 0.011183, loss_ce: 0.005377
 99%|████████████████████████████▋| 396/400 [4:47:35<02:57, 44.31s/it]2022-01-08 14:41:22,987 iteration 6733 : loss : 0.016478, loss_ce: 0.008718
2022-01-08 14:41:25,422 iteration 6734 : loss : 0.006224, loss_ce: 0.001921
2022-01-08 14:41:27,805 iteration 6735 : loss : 0.011661, loss_ce: 0.005754
2022-01-08 14:41:30,148 iteration 6736 : loss : 0.010802, loss_ce: 0.003110
2022-01-08 14:41:32,398 iteration 6737 : loss : 0.009723, loss_ce: 0.004648
2022-01-08 14:41:34,650 iteration 6738 : loss : 0.008809, loss_ce: 0.002927
2022-01-08 14:41:36,970 iteration 6739 : loss : 0.013723, loss_ce: 0.005527
2022-01-08 14:41:39,271 iteration 6740 : loss : 0.014066, loss_ce: 0.004731
2022-01-08 14:41:41,443 iteration 6741 : loss : 0.010710, loss_ce: 0.004822
2022-01-08 14:41:43,752 iteration 6742 : loss : 0.013811, loss_ce: 0.005981
2022-01-08 14:41:46,050 iteration 6743 : loss : 0.014819, loss_ce: 0.004616
2022-01-08 14:41:48,429 iteration 6744 : loss : 0.014011, loss_ce: 0.006582
2022-01-08 14:41:50,668 iteration 6745 : loss : 0.014144, loss_ce: 0.004142
2022-01-08 14:41:53,068 iteration 6746 : loss : 0.013344, loss_ce: 0.005332
2022-01-08 14:41:55,449 iteration 6747 : loss : 0.015315, loss_ce: 0.005347
2022-01-08 14:41:57,880 iteration 6748 : loss : 0.023325, loss_ce: 0.009240
2022-01-08 14:42:00,254 iteration 6749 : loss : 0.021403, loss_ce: 0.007521
 99%|████████████████████████████▊| 397/400 [4:48:15<02:08, 42.93s/it]2022-01-08 14:42:02,576 iteration 6750 : loss : 0.012227, loss_ce: 0.004769
2022-01-08 14:42:04,988 iteration 6751 : loss : 0.020577, loss_ce: 0.009894
2022-01-08 14:42:07,369 iteration 6752 : loss : 0.014934, loss_ce: 0.007375
2022-01-08 14:42:09,675 iteration 6753 : loss : 0.011597, loss_ce: 0.004739
2022-01-08 14:42:11,975 iteration 6754 : loss : 0.019466, loss_ce: 0.004699
2022-01-08 14:42:14,269 iteration 6755 : loss : 0.006810, loss_ce: 0.002057
2022-01-08 14:42:16,558 iteration 6756 : loss : 0.010244, loss_ce: 0.004006
2022-01-08 14:42:18,909 iteration 6757 : loss : 0.013568, loss_ce: 0.006295
2022-01-08 14:42:21,165 iteration 6758 : loss : 0.008227, loss_ce: 0.003608
2022-01-08 14:42:23,437 iteration 6759 : loss : 0.013380, loss_ce: 0.005269
2022-01-08 14:42:25,732 iteration 6760 : loss : 0.015149, loss_ce: 0.007314
2022-01-08 14:42:28,107 iteration 6761 : loss : 0.012306, loss_ce: 0.005140
2022-01-08 14:42:30,295 iteration 6762 : loss : 0.007868, loss_ce: 0.002794
2022-01-08 14:42:32,564 iteration 6763 : loss : 0.012480, loss_ce: 0.003635
2022-01-08 14:42:35,031 iteration 6764 : loss : 0.010877, loss_ce: 0.003975
2022-01-08 14:42:37,400 iteration 6765 : loss : 0.009924, loss_ce: 0.003320
2022-01-08 14:42:39,754 iteration 6766 : loss : 0.014630, loss_ce: 0.005304
100%|████████████████████████████▊| 398/400 [4:48:54<01:23, 41.90s/it]2022-01-08 14:42:42,272 iteration 6767 : loss : 0.013498, loss_ce: 0.004643
2022-01-08 14:42:44,514 iteration 6768 : loss : 0.011300, loss_ce: 0.005342
2022-01-08 14:42:46,820 iteration 6769 : loss : 0.014727, loss_ce: 0.004979
2022-01-08 14:42:49,146 iteration 6770 : loss : 0.009361, loss_ce: 0.003542
2022-01-08 14:42:51,549 iteration 6771 : loss : 0.012155, loss_ce: 0.003834
2022-01-08 14:42:54,208 iteration 6772 : loss : 0.019896, loss_ce: 0.006133
2022-01-08 14:42:56,609 iteration 6773 : loss : 0.011054, loss_ce: 0.004544
2022-01-08 14:42:58,931 iteration 6774 : loss : 0.013147, loss_ce: 0.005767
2022-01-08 14:43:01,339 iteration 6775 : loss : 0.012353, loss_ce: 0.005167
2022-01-08 14:43:03,746 iteration 6776 : loss : 0.020430, loss_ce: 0.007743
2022-01-08 14:43:06,110 iteration 6777 : loss : 0.010702, loss_ce: 0.004134
2022-01-08 14:43:08,451 iteration 6778 : loss : 0.017011, loss_ce: 0.004769
2022-01-08 14:43:10,834 iteration 6779 : loss : 0.010790, loss_ce: 0.003440
2022-01-08 14:43:13,163 iteration 6780 : loss : 0.008432, loss_ce: 0.002810
2022-01-08 14:43:15,486 iteration 6781 : loss : 0.009434, loss_ce: 0.004338
2022-01-08 14:43:18,032 iteration 6782 : loss : 0.008506, loss_ce: 0.003564
2022-01-08 14:43:20,442 iteration 6783 : loss : 0.009078, loss_ce: 0.003667
100%|████████████████████████████▉| 399/400 [4:49:35<00:41, 41.54s/it]2022-01-08 14:43:22,939 iteration 6784 : loss : 0.020388, loss_ce: 0.007296
2022-01-08 14:43:25,189 iteration 6785 : loss : 0.012253, loss_ce: 0.005549
2022-01-08 14:43:27,505 iteration 6786 : loss : 0.009977, loss_ce: 0.004666
2022-01-08 14:43:29,871 iteration 6787 : loss : 0.013544, loss_ce: 0.004626
2022-01-08 14:43:32,180 iteration 6788 : loss : 0.014381, loss_ce: 0.003340
2022-01-08 14:43:34,541 iteration 6789 : loss : 0.008606, loss_ce: 0.003455
2022-01-08 14:43:36,908 iteration 6790 : loss : 0.011764, loss_ce: 0.003852
2022-01-08 14:43:39,347 iteration 6791 : loss : 0.015668, loss_ce: 0.004782
2022-01-08 14:43:41,771 iteration 6792 : loss : 0.016069, loss_ce: 0.007196
2022-01-08 14:43:44,131 iteration 6793 : loss : 0.014814, loss_ce: 0.004642
2022-01-08 14:43:46,505 iteration 6794 : loss : 0.010701, loss_ce: 0.004002
2022-01-08 14:43:48,804 iteration 6795 : loss : 0.009343, loss_ce: 0.003425
2022-01-08 14:43:51,218 iteration 6796 : loss : 0.012733, loss_ce: 0.004825
2022-01-08 14:43:53,592 iteration 6797 : loss : 0.013384, loss_ce: 0.004760
2022-01-08 14:43:55,908 iteration 6798 : loss : 0.010319, loss_ce: 0.003749
2022-01-08 14:43:58,349 iteration 6799 : loss : 0.017276, loss_ce: 0.008309
2022-01-08 14:43:58,349 Training Data Eval:
2022-01-08 14:44:11,352   Average segmentation loss on training set: 0.0062
2022-01-08 14:44:11,353 Validation Data Eval:
2022-01-08 14:44:15,859   Average segmentation loss on validation set: 0.0722
2022-01-08 14:44:18,235 iteration 6800 : loss : 0.016267, loss_ce: 0.007564
100%|█████████████████████████████| 400/400 [4:50:32<00:00, 46.41s/it]100%|█████████████████████████████| 400/400 [4:50:32<00:00, 43.58s/it]
