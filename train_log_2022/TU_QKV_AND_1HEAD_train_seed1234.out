2022-01-15 23:39:06,899 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:06,900 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:06,900 ============================================================
2022-01-15 23:39:06,900 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-15 23:39:06,900 ============================================================
2022-01-15 23:39:06,900 Loading data...
2022-01-15 23:39:06,900 Reading NCI - RUNMC images...
2022-01-15 23:39:06,900 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-15 23:39:06,902 Already preprocessed this configuration. Loading now!
2022-01-15 23:39:06,929 Training Images: (256, 256, 286)
2022-01-15 23:39:06,929 Training Labels: (256, 256, 286)
2022-01-15 23:39:06,929 Validation Images: (256, 256, 98)
2022-01-15 23:39:06,929 Validation Labels: (256, 256, 98)
2022-01-15 23:39:06,929 ============================================================
2022-01-15 23:39:06,965 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-15 23:39:10,245 iteration 1 : loss : 0.823425, loss_ce: 0.938253
2022-01-15 23:39:11,154 iteration 2 : loss : 0.765807, loss_ce: 0.850409
2022-01-15 23:39:12,179 iteration 3 : loss : 0.712738, loss_ce: 0.759347
2022-01-15 23:39:13,144 iteration 4 : loss : 0.668530, loss_ce: 0.681706
2022-01-15 23:39:14,067 iteration 5 : loss : 0.620942, loss_ce: 0.617245
2022-01-15 23:39:15,001 iteration 6 : loss : 0.593545, loss_ce: 0.557172
2022-01-15 23:39:15,996 iteration 7 : loss : 0.556813, loss_ce: 0.510271
2022-01-15 23:39:16,938 iteration 8 : loss : 0.533706, loss_ce: 0.445513
2022-01-15 23:39:17,898 iteration 9 : loss : 0.495340, loss_ce: 0.441755
2022-01-15 23:39:18,892 iteration 10 : loss : 0.481197, loss_ce: 0.367089
2022-01-15 23:39:19,948 iteration 11 : loss : 0.452977, loss_ce: 0.355740
2022-01-15 23:39:20,875 iteration 12 : loss : 0.433902, loss_ce: 0.318237
2022-01-15 23:39:21,791 iteration 13 : loss : 0.425704, loss_ce: 0.295139
2022-01-15 23:39:22,672 iteration 14 : loss : 0.391483, loss_ce: 0.270203
2022-01-15 23:39:23,628 iteration 15 : loss : 0.395356, loss_ce: 0.263307
2022-01-15 23:39:24,563 iteration 16 : loss : 0.405297, loss_ce: 0.257213
2022-01-15 23:39:25,494 iteration 17 : loss : 0.359174, loss_ce: 0.225701
  0%|                               | 1/400 [00:18<2:03:51, 18.62s/it]2022-01-15 23:39:26,560 iteration 18 : loss : 0.379154, loss_ce: 0.205770
2022-01-15 23:39:27,422 iteration 19 : loss : 0.327694, loss_ce: 0.184078
2022-01-15 23:39:28,435 iteration 20 : loss : 0.314255, loss_ce: 0.168530
2022-01-15 23:39:29,344 iteration 21 : loss : 0.341340, loss_ce: 0.157403
2022-01-15 23:39:30,277 iteration 22 : loss : 0.337247, loss_ce: 0.178628
2022-01-15 23:39:31,300 iteration 23 : loss : 0.311739, loss_ce: 0.142344
2022-01-15 23:39:32,238 iteration 24 : loss : 0.286260, loss_ce: 0.148185
2022-01-15 23:39:33,257 iteration 25 : loss : 0.363673, loss_ce: 0.212397
2022-01-15 23:39:34,194 iteration 26 : loss : 0.295071, loss_ce: 0.146302
2022-01-15 23:39:35,065 iteration 27 : loss : 0.279890, loss_ce: 0.146925
2022-01-15 23:39:35,947 iteration 28 : loss : 0.282496, loss_ce: 0.139565
2022-01-15 23:39:36,937 iteration 29 : loss : 0.282441, loss_ce: 0.135534
2022-01-15 23:39:37,911 iteration 30 : loss : 0.290403, loss_ce: 0.133927
2022-01-15 23:39:38,778 iteration 31 : loss : 0.276651, loss_ce: 0.126869
2022-01-15 23:39:39,784 iteration 32 : loss : 0.290186, loss_ce: 0.149788
2022-01-15 23:39:41,696 iteration 33 : loss : 0.279354, loss_ce: 0.148047
2022-01-15 23:39:42,679 iteration 34 : loss : 0.294875, loss_ce: 0.160697
  0%|▏                              | 2/400 [00:35<1:57:49, 17.76s/it]2022-01-15 23:39:43,726 iteration 35 : loss : 0.271276, loss_ce: 0.125803
2022-01-15 23:39:44,730 iteration 36 : loss : 0.289256, loss_ce: 0.154432
2022-01-15 23:39:45,746 iteration 37 : loss : 0.302517, loss_ce: 0.143636
2022-01-15 23:39:46,667 iteration 38 : loss : 0.259188, loss_ce: 0.129759
2022-01-15 23:39:47,594 iteration 39 : loss : 0.234210, loss_ce: 0.112587
2022-01-15 23:39:48,605 iteration 40 : loss : 0.291847, loss_ce: 0.141753
2022-01-15 23:39:49,605 iteration 41 : loss : 0.313944, loss_ce: 0.152420
2022-01-15 23:39:50,582 iteration 42 : loss : 0.255269, loss_ce: 0.117586
2022-01-15 23:39:51,461 iteration 43 : loss : 0.245420, loss_ce: 0.108061
2022-01-15 23:39:52,496 iteration 44 : loss : 0.210916, loss_ce: 0.093411
2022-01-15 23:39:53,454 iteration 45 : loss : 0.225395, loss_ce: 0.101950
2022-01-15 23:39:54,425 iteration 46 : loss : 0.251470, loss_ce: 0.100593
2022-01-15 23:39:55,434 iteration 47 : loss : 0.209425, loss_ce: 0.084481
2022-01-15 23:39:56,412 iteration 48 : loss : 0.201559, loss_ce: 0.084859
2022-01-15 23:39:57,438 iteration 49 : loss : 0.276912, loss_ce: 0.126725
2022-01-15 23:39:58,350 iteration 50 : loss : 0.329162, loss_ce: 0.143918
2022-01-15 23:39:59,240 iteration 51 : loss : 0.267242, loss_ce: 0.119765
  1%|▏                              | 3/400 [00:52<1:53:53, 17.21s/it]2022-01-15 23:40:00,316 iteration 52 : loss : 0.268768, loss_ce: 0.124796
2022-01-15 23:40:01,306 iteration 53 : loss : 0.238105, loss_ce: 0.104886
2022-01-15 23:40:02,270 iteration 54 : loss : 0.235219, loss_ce: 0.102331
2022-01-15 23:40:03,244 iteration 55 : loss : 0.289381, loss_ce: 0.147896
2022-01-15 23:40:04,197 iteration 56 : loss : 0.250826, loss_ce: 0.110849
2022-01-15 23:40:05,175 iteration 57 : loss : 0.236102, loss_ce: 0.097166
2022-01-15 23:40:06,154 iteration 58 : loss : 0.276679, loss_ce: 0.117614
2022-01-15 23:40:07,099 iteration 59 : loss : 0.195108, loss_ce: 0.079948
2022-01-15 23:40:08,081 iteration 60 : loss : 0.198296, loss_ce: 0.071874
2022-01-15 23:40:09,048 iteration 61 : loss : 0.284611, loss_ce: 0.126224
2022-01-15 23:40:10,003 iteration 62 : loss : 0.327211, loss_ce: 0.122819
2022-01-15 23:40:10,876 iteration 63 : loss : 0.265620, loss_ce: 0.128203
2022-01-15 23:40:11,814 iteration 64 : loss : 0.344100, loss_ce: 0.157034
2022-01-15 23:40:12,701 iteration 65 : loss : 0.260436, loss_ce: 0.101561
2022-01-15 23:40:13,632 iteration 66 : loss : 0.210350, loss_ce: 0.092687
2022-01-15 23:40:14,654 iteration 67 : loss : 0.240967, loss_ce: 0.085800
2022-01-15 23:40:15,608 iteration 68 : loss : 0.237283, loss_ce: 0.099358
  1%|▎                              | 4/400 [01:08<1:51:22, 16.88s/it]2022-01-15 23:40:16,647 iteration 69 : loss : 0.216221, loss_ce: 0.083887
2022-01-15 23:40:17,692 iteration 70 : loss : 0.219838, loss_ce: 0.083322
2022-01-15 23:40:18,613 iteration 71 : loss : 0.219705, loss_ce: 0.089066
2022-01-15 23:40:19,581 iteration 72 : loss : 0.221832, loss_ce: 0.086069
2022-01-15 23:40:20,486 iteration 73 : loss : 0.216233, loss_ce: 0.093122
2022-01-15 23:40:21,361 iteration 74 : loss : 0.205314, loss_ce: 0.080160
2022-01-15 23:40:22,275 iteration 75 : loss : 0.204818, loss_ce: 0.079587
2022-01-15 23:40:23,177 iteration 76 : loss : 0.189613, loss_ce: 0.071980
2022-01-15 23:40:23,995 iteration 77 : loss : 0.219662, loss_ce: 0.090746
2022-01-15 23:40:24,931 iteration 78 : loss : 0.233200, loss_ce: 0.097475
2022-01-15 23:40:25,832 iteration 79 : loss : 0.256650, loss_ce: 0.089202
2022-01-15 23:40:26,718 iteration 80 : loss : 0.209394, loss_ce: 0.089770
2022-01-15 23:40:27,593 iteration 81 : loss : 0.210459, loss_ce: 0.087034
2022-01-15 23:40:28,499 iteration 82 : loss : 0.196186, loss_ce: 0.075627
2022-01-15 23:40:29,399 iteration 83 : loss : 0.214652, loss_ce: 0.076728
2022-01-15 23:40:30,402 iteration 84 : loss : 0.210124, loss_ce: 0.094895
2022-01-15 23:40:30,402 Training Data Eval:
2022-01-15 23:40:34,921   Average segmentation loss on training set: 1.3383
2022-01-15 23:40:34,922 Validation Data Eval:
2022-01-15 23:40:36,647   Average segmentation loss on validation set: 1.3148
2022-01-15 23:40:37,549 iteration 85 : loss : 0.219354, loss_ce: 0.081251
  1%|▍                              | 5/400 [01:30<2:03:06, 18.70s/it]2022-01-15 23:40:38,562 iteration 86 : loss : 0.302612, loss_ce: 0.108371
2022-01-15 23:40:39,649 iteration 87 : loss : 0.190206, loss_ce: 0.075034
2022-01-15 23:40:40,539 iteration 88 : loss : 0.203415, loss_ce: 0.080912
2022-01-15 23:40:41,512 iteration 89 : loss : 0.239663, loss_ce: 0.103455
2022-01-15 23:40:42,477 iteration 90 : loss : 0.205350, loss_ce: 0.080141
2022-01-15 23:40:43,512 iteration 91 : loss : 0.207671, loss_ce: 0.090971
2022-01-15 23:40:44,386 iteration 92 : loss : 0.199558, loss_ce: 0.078019
2022-01-15 23:40:45,313 iteration 93 : loss : 0.236184, loss_ce: 0.090983
2022-01-15 23:40:46,245 iteration 94 : loss : 0.218826, loss_ce: 0.086121
2022-01-15 23:40:47,325 iteration 95 : loss : 0.219149, loss_ce: 0.086507
2022-01-15 23:40:48,241 iteration 96 : loss : 0.188039, loss_ce: 0.074952
2022-01-15 23:40:49,165 iteration 97 : loss : 0.217497, loss_ce: 0.083566
2022-01-15 23:40:50,102 iteration 98 : loss : 0.215639, loss_ce: 0.087470
2022-01-15 23:40:51,129 iteration 99 : loss : 0.198219, loss_ce: 0.078419
2022-01-15 23:40:52,098 iteration 100 : loss : 0.204044, loss_ce: 0.075080
2022-01-15 23:40:53,042 iteration 101 : loss : 0.149587, loss_ce: 0.054939
2022-01-15 23:40:53,915 iteration 102 : loss : 0.192078, loss_ce: 0.073526
  2%|▍                              | 6/400 [01:47<1:57:37, 17.91s/it]2022-01-15 23:40:55,032 iteration 103 : loss : 0.189569, loss_ce: 0.073571
2022-01-15 23:40:56,070 iteration 104 : loss : 0.195034, loss_ce: 0.076714
2022-01-15 23:40:57,158 iteration 105 : loss : 0.218883, loss_ce: 0.084882
2022-01-15 23:40:58,066 iteration 106 : loss : 0.206711, loss_ce: 0.070097
2022-01-15 23:40:59,183 iteration 107 : loss : 0.223975, loss_ce: 0.098760
2022-01-15 23:41:00,065 iteration 108 : loss : 0.238807, loss_ce: 0.089964
2022-01-15 23:41:00,990 iteration 109 : loss : 0.173720, loss_ce: 0.067837
2022-01-15 23:41:01,851 iteration 110 : loss : 0.194078, loss_ce: 0.075782
2022-01-15 23:41:02,821 iteration 111 : loss : 0.224257, loss_ce: 0.098171
2022-01-15 23:41:03,692 iteration 112 : loss : 0.188785, loss_ce: 0.070017
2022-01-15 23:41:04,641 iteration 113 : loss : 0.237212, loss_ce: 0.121531
2022-01-15 23:41:05,548 iteration 114 : loss : 0.238000, loss_ce: 0.079742
2022-01-15 23:41:06,479 iteration 115 : loss : 0.200507, loss_ce: 0.077519
2022-01-15 23:41:07,475 iteration 116 : loss : 0.218398, loss_ce: 0.088124
2022-01-15 23:41:08,466 iteration 117 : loss : 0.213649, loss_ce: 0.093876
2022-01-15 23:41:09,413 iteration 118 : loss : 0.215699, loss_ce: 0.082081
2022-01-15 23:41:10,382 iteration 119 : loss : 0.200174, loss_ce: 0.066266
  2%|▌                              | 7/400 [02:03<1:54:14, 17.44s/it]2022-01-15 23:41:11,347 iteration 120 : loss : 0.242288, loss_ce: 0.102197
2022-01-15 23:41:12,222 iteration 121 : loss : 0.335813, loss_ce: 0.172612
2022-01-15 23:41:13,227 iteration 122 : loss : 0.247977, loss_ce: 0.110131
2022-01-15 23:41:14,190 iteration 123 : loss : 0.221082, loss_ce: 0.097796
2022-01-15 23:41:15,124 iteration 124 : loss : 0.246271, loss_ce: 0.105428
2022-01-15 23:41:16,013 iteration 125 : loss : 0.237326, loss_ce: 0.113866
2022-01-15 23:41:16,972 iteration 126 : loss : 0.237530, loss_ce: 0.082731
2022-01-15 23:41:17,857 iteration 127 : loss : 0.217281, loss_ce: 0.092874
2022-01-15 23:41:18,766 iteration 128 : loss : 0.201690, loss_ce: 0.077522
2022-01-15 23:41:19,760 iteration 129 : loss : 0.210289, loss_ce: 0.070082
2022-01-15 23:41:20,689 iteration 130 : loss : 0.200012, loss_ce: 0.066945
2022-01-15 23:41:21,721 iteration 131 : loss : 0.235965, loss_ce: 0.097383
2022-01-15 23:41:22,783 iteration 132 : loss : 0.206608, loss_ce: 0.056970
2022-01-15 23:41:23,698 iteration 133 : loss : 0.194341, loss_ce: 0.066102
2022-01-15 23:41:24,722 iteration 134 : loss : 0.201974, loss_ce: 0.078118
2022-01-15 23:41:25,763 iteration 135 : loss : 0.237369, loss_ce: 0.101766
2022-01-15 23:41:26,702 iteration 136 : loss : 0.169909, loss_ce: 0.066613
  2%|▌                              | 8/400 [02:19<1:51:34, 17.08s/it]2022-01-15 23:41:27,782 iteration 137 : loss : 0.233163, loss_ce: 0.082944
2022-01-15 23:41:28,697 iteration 138 : loss : 0.229465, loss_ce: 0.110135
2022-01-15 23:41:29,679 iteration 139 : loss : 0.232032, loss_ce: 0.099092
2022-01-15 23:41:30,627 iteration 140 : loss : 0.222082, loss_ce: 0.081992
2022-01-15 23:41:31,627 iteration 141 : loss : 0.201000, loss_ce: 0.094195
2022-01-15 23:41:32,640 iteration 142 : loss : 0.201081, loss_ce: 0.081184
2022-01-15 23:41:33,680 iteration 143 : loss : 0.225355, loss_ce: 0.092270
2022-01-15 23:41:34,690 iteration 144 : loss : 0.189809, loss_ce: 0.067088
2022-01-15 23:41:35,632 iteration 145 : loss : 0.224607, loss_ce: 0.080467
2022-01-15 23:41:36,621 iteration 146 : loss : 0.162191, loss_ce: 0.061409
2022-01-15 23:41:37,621 iteration 147 : loss : 0.176298, loss_ce: 0.061150
2022-01-15 23:41:38,480 iteration 148 : loss : 0.176044, loss_ce: 0.062858
2022-01-15 23:41:39,410 iteration 149 : loss : 0.218221, loss_ce: 0.085867
2022-01-15 23:41:40,318 iteration 150 : loss : 0.204148, loss_ce: 0.064571
2022-01-15 23:41:41,231 iteration 151 : loss : 0.248746, loss_ce: 0.110137
2022-01-15 23:41:42,150 iteration 152 : loss : 0.213903, loss_ce: 0.068090
2022-01-15 23:41:43,125 iteration 153 : loss : 0.251062, loss_ce: 0.106578
  2%|▋                              | 9/400 [02:36<1:49:58, 16.88s/it]2022-01-15 23:41:44,075 iteration 154 : loss : 0.245444, loss_ce: 0.101137
2022-01-15 23:41:45,033 iteration 155 : loss : 0.193201, loss_ce: 0.066587
2022-01-15 23:41:46,077 iteration 156 : loss : 0.195062, loss_ce: 0.072588
2022-01-15 23:41:47,047 iteration 157 : loss : 0.240082, loss_ce: 0.084103
2022-01-15 23:41:48,137 iteration 158 : loss : 0.183393, loss_ce: 0.071998
2022-01-15 23:41:48,964 iteration 159 : loss : 0.164594, loss_ce: 0.053263
2022-01-15 23:41:50,000 iteration 160 : loss : 0.177897, loss_ce: 0.050834
2022-01-15 23:41:51,025 iteration 161 : loss : 0.205229, loss_ce: 0.060471
2022-01-15 23:41:52,053 iteration 162 : loss : 0.214156, loss_ce: 0.084731
2022-01-15 23:41:53,006 iteration 163 : loss : 0.210355, loss_ce: 0.071438
2022-01-15 23:41:53,984 iteration 164 : loss : 0.191876, loss_ce: 0.060944
2022-01-15 23:41:54,924 iteration 165 : loss : 0.191461, loss_ce: 0.072898
2022-01-15 23:41:55,844 iteration 166 : loss : 0.188646, loss_ce: 0.066746
2022-01-15 23:41:56,787 iteration 167 : loss : 0.189537, loss_ce: 0.066240
2022-01-15 23:41:57,775 iteration 168 : loss : 0.205751, loss_ce: 0.087197
2022-01-15 23:41:58,725 iteration 169 : loss : 0.221011, loss_ce: 0.099744
2022-01-15 23:41:58,726 Training Data Eval:
2022-01-15 23:42:03,251   Average segmentation loss on training set: 0.4299
2022-01-15 23:42:03,251 Validation Data Eval:
2022-01-15 23:42:04,742   Average segmentation loss on validation set: 0.5033
2022-01-15 23:42:05,586 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-15 23:42:06,585 iteration 170 : loss : 0.164253, loss_ce: 0.060161
  2%|▊                             | 10/400 [02:59<2:02:53, 18.91s/it]2022-01-15 23:42:07,614 iteration 171 : loss : 0.201946, loss_ce: 0.072274
2022-01-15 23:42:08,602 iteration 172 : loss : 0.184968, loss_ce: 0.072355
2022-01-15 23:42:09,608 iteration 173 : loss : 0.177073, loss_ce: 0.071844
2022-01-15 23:42:10,517 iteration 174 : loss : 0.187799, loss_ce: 0.077833
2022-01-15 23:42:11,407 iteration 175 : loss : 0.220563, loss_ce: 0.086435
2022-01-15 23:42:12,385 iteration 176 : loss : 0.174019, loss_ce: 0.070308
2022-01-15 23:42:13,325 iteration 177 : loss : 0.195204, loss_ce: 0.066351
2022-01-15 23:42:14,272 iteration 178 : loss : 0.156346, loss_ce: 0.061154
2022-01-15 23:42:15,213 iteration 179 : loss : 0.205893, loss_ce: 0.076832
2022-01-15 23:42:16,133 iteration 180 : loss : 0.212102, loss_ce: 0.071482
2022-01-15 23:42:17,110 iteration 181 : loss : 0.169802, loss_ce: 0.060978
2022-01-15 23:42:18,020 iteration 182 : loss : 0.163338, loss_ce: 0.054455
2022-01-15 23:42:18,913 iteration 183 : loss : 0.191898, loss_ce: 0.059741
2022-01-15 23:42:19,760 iteration 184 : loss : 0.194185, loss_ce: 0.060988
2022-01-15 23:42:20,741 iteration 185 : loss : 0.185186, loss_ce: 0.057134
2022-01-15 23:42:21,729 iteration 186 : loss : 0.231924, loss_ce: 0.091611
2022-01-15 23:42:22,751 iteration 187 : loss : 0.179424, loss_ce: 0.066307
  3%|▊                             | 11/400 [03:15<1:57:07, 18.07s/it]2022-01-15 23:42:23,794 iteration 188 : loss : 0.209397, loss_ce: 0.071733
2022-01-15 23:42:24,770 iteration 189 : loss : 0.170405, loss_ce: 0.060506
2022-01-15 23:42:25,749 iteration 190 : loss : 0.178526, loss_ce: 0.058437
2022-01-15 23:42:26,681 iteration 191 : loss : 0.183237, loss_ce: 0.059837
2022-01-15 23:42:27,555 iteration 192 : loss : 0.167820, loss_ce: 0.060358
2022-01-15 23:42:28,570 iteration 193 : loss : 0.182092, loss_ce: 0.066661
2022-01-15 23:42:29,501 iteration 194 : loss : 0.206094, loss_ce: 0.058244
2022-01-15 23:42:30,410 iteration 195 : loss : 0.171299, loss_ce: 0.058584
2022-01-15 23:42:31,271 iteration 196 : loss : 0.191883, loss_ce: 0.061209
2022-01-15 23:42:32,230 iteration 197 : loss : 0.174796, loss_ce: 0.057295
2022-01-15 23:42:33,220 iteration 198 : loss : 0.195902, loss_ce: 0.076183
2022-01-15 23:42:34,125 iteration 199 : loss : 0.192311, loss_ce: 0.063708
2022-01-15 23:42:35,079 iteration 200 : loss : 0.194350, loss_ce: 0.077891
2022-01-15 23:42:36,046 iteration 201 : loss : 0.152375, loss_ce: 0.053730
2022-01-15 23:42:37,037 iteration 202 : loss : 0.180360, loss_ce: 0.070973
2022-01-15 23:42:37,941 iteration 203 : loss : 0.172554, loss_ce: 0.063778
2022-01-15 23:42:38,993 iteration 204 : loss : 0.215468, loss_ce: 0.079654
  3%|▉                             | 12/400 [03:32<1:53:14, 17.51s/it]2022-01-15 23:42:39,960 iteration 205 : loss : 0.168931, loss_ce: 0.061273
2022-01-15 23:42:40,904 iteration 206 : loss : 0.171837, loss_ce: 0.049789
2022-01-15 23:42:41,871 iteration 207 : loss : 0.171924, loss_ce: 0.063268
2022-01-15 23:42:42,796 iteration 208 : loss : 0.199335, loss_ce: 0.061527
2022-01-15 23:42:43,829 iteration 209 : loss : 0.250684, loss_ce: 0.117544
2022-01-15 23:42:44,678 iteration 210 : loss : 0.189623, loss_ce: 0.058835
2022-01-15 23:42:45,666 iteration 211 : loss : 0.222134, loss_ce: 0.094248
2022-01-15 23:42:46,631 iteration 212 : loss : 0.200686, loss_ce: 0.068941
2022-01-15 23:42:47,704 iteration 213 : loss : 0.170535, loss_ce: 0.065839
2022-01-15 23:42:48,659 iteration 214 : loss : 0.174516, loss_ce: 0.049434
2022-01-15 23:42:49,616 iteration 215 : loss : 0.208771, loss_ce: 0.076434
2022-01-15 23:42:50,747 iteration 216 : loss : 0.160545, loss_ce: 0.054591
2022-01-15 23:42:51,808 iteration 217 : loss : 0.168627, loss_ce: 0.058229
2022-01-15 23:42:52,786 iteration 218 : loss : 0.176807, loss_ce: 0.072884
2022-01-15 23:42:53,633 iteration 219 : loss : 0.173108, loss_ce: 0.068628
2022-01-15 23:42:54,614 iteration 220 : loss : 0.163303, loss_ce: 0.064293
2022-01-15 23:42:55,574 iteration 221 : loss : 0.211172, loss_ce: 0.072091
  3%|▉                             | 13/400 [03:48<1:51:08, 17.23s/it]2022-01-15 23:42:56,607 iteration 222 : loss : 0.180103, loss_ce: 0.068697
2022-01-15 23:42:57,616 iteration 223 : loss : 0.152495, loss_ce: 0.054968
2022-01-15 23:42:58,570 iteration 224 : loss : 0.259255, loss_ce: 0.131379
2022-01-15 23:42:59,628 iteration 225 : loss : 0.288172, loss_ce: 0.088798
2022-01-15 23:43:00,580 iteration 226 : loss : 0.178224, loss_ce: 0.058907
2022-01-15 23:43:01,584 iteration 227 : loss : 0.232562, loss_ce: 0.100753
2022-01-15 23:43:02,536 iteration 228 : loss : 0.193407, loss_ce: 0.075659
2022-01-15 23:43:03,433 iteration 229 : loss : 0.182661, loss_ce: 0.060496
2022-01-15 23:43:04,400 iteration 230 : loss : 0.168029, loss_ce: 0.060030
2022-01-15 23:43:05,408 iteration 231 : loss : 0.217613, loss_ce: 0.078024
2022-01-15 23:43:06,407 iteration 232 : loss : 0.157666, loss_ce: 0.059776
2022-01-15 23:43:07,314 iteration 233 : loss : 0.165409, loss_ce: 0.057635
2022-01-15 23:43:08,345 iteration 234 : loss : 0.206277, loss_ce: 0.080925
2022-01-15 23:43:09,281 iteration 235 : loss : 0.173052, loss_ce: 0.066389
2022-01-15 23:43:10,271 iteration 236 : loss : 0.172275, loss_ce: 0.062694
2022-01-15 23:43:11,204 iteration 237 : loss : 0.161516, loss_ce: 0.060391
2022-01-15 23:43:12,157 iteration 238 : loss : 0.147849, loss_ce: 0.057199
  4%|█                             | 14/400 [04:05<1:49:35, 17.04s/it]2022-01-15 23:43:13,112 iteration 239 : loss : 0.184701, loss_ce: 0.057036
2022-01-15 23:43:14,102 iteration 240 : loss : 0.158250, loss_ce: 0.067672
2022-01-15 23:43:15,101 iteration 241 : loss : 0.188916, loss_ce: 0.064329
2022-01-15 23:43:16,080 iteration 242 : loss : 0.205695, loss_ce: 0.101786
2022-01-15 23:43:17,205 iteration 243 : loss : 0.192260, loss_ce: 0.077297
2022-01-15 23:43:18,106 iteration 244 : loss : 0.219645, loss_ce: 0.060113
2022-01-15 23:43:19,082 iteration 245 : loss : 0.183022, loss_ce: 0.078998
2022-01-15 23:43:20,098 iteration 246 : loss : 0.197099, loss_ce: 0.083289
2022-01-15 23:43:21,040 iteration 247 : loss : 0.225698, loss_ce: 0.075390
2022-01-15 23:43:21,983 iteration 248 : loss : 0.192551, loss_ce: 0.065276
2022-01-15 23:43:22,907 iteration 249 : loss : 0.177856, loss_ce: 0.087165
2022-01-15 23:43:23,853 iteration 250 : loss : 0.191926, loss_ce: 0.071599
2022-01-15 23:43:24,735 iteration 251 : loss : 0.179210, loss_ce: 0.059954
2022-01-15 23:43:25,678 iteration 252 : loss : 0.143271, loss_ce: 0.056914
2022-01-15 23:43:26,656 iteration 253 : loss : 0.203432, loss_ce: 0.075117
2022-01-15 23:43:27,707 iteration 254 : loss : 0.236060, loss_ce: 0.071502
2022-01-15 23:43:27,707 Training Data Eval:
2022-01-15 23:43:32,234   Average segmentation loss on training set: 0.1793
2022-01-15 23:43:32,234 Validation Data Eval:
2022-01-15 23:43:33,719   Average segmentation loss on validation set: 0.2058
2022-01-15 23:43:34,563 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-15 23:43:35,477 iteration 255 : loss : 0.186971, loss_ce: 0.072908
  4%|█▏                            | 15/400 [04:28<2:01:29, 18.93s/it]2022-01-15 23:43:36,526 iteration 256 : loss : 0.188391, loss_ce: 0.074093
2022-01-15 23:43:37,549 iteration 257 : loss : 0.179479, loss_ce: 0.065218
2022-01-15 23:43:38,620 iteration 258 : loss : 0.169147, loss_ce: 0.063039
2022-01-15 23:43:39,491 iteration 259 : loss : 0.143547, loss_ce: 0.056539
2022-01-15 23:43:40,517 iteration 260 : loss : 0.167404, loss_ce: 0.064648
2022-01-15 23:43:41,501 iteration 261 : loss : 0.202870, loss_ce: 0.062936
2022-01-15 23:43:42,579 iteration 262 : loss : 0.182700, loss_ce: 0.070584
2022-01-15 23:43:43,549 iteration 263 : loss : 0.165806, loss_ce: 0.065126
2022-01-15 23:43:44,553 iteration 264 : loss : 0.194889, loss_ce: 0.083613
2022-01-15 23:43:45,476 iteration 265 : loss : 0.142448, loss_ce: 0.051836
2022-01-15 23:43:46,471 iteration 266 : loss : 0.157755, loss_ce: 0.062082
2022-01-15 23:43:47,422 iteration 267 : loss : 0.197345, loss_ce: 0.060447
2022-01-15 23:43:48,395 iteration 268 : loss : 0.186205, loss_ce: 0.080240
2022-01-15 23:43:49,583 iteration 269 : loss : 0.195556, loss_ce: 0.060714
2022-01-15 23:43:50,669 iteration 270 : loss : 0.163638, loss_ce: 0.056407
2022-01-15 23:43:51,494 iteration 271 : loss : 0.184210, loss_ce: 0.055659
2022-01-15 23:43:52,458 iteration 272 : loss : 0.183827, loss_ce: 0.080044
  4%|█▏                            | 16/400 [04:45<1:57:24, 18.35s/it]2022-01-15 23:43:53,432 iteration 273 : loss : 0.173730, loss_ce: 0.057766
2022-01-15 23:43:54,325 iteration 274 : loss : 0.142903, loss_ce: 0.048439
2022-01-15 23:43:55,223 iteration 275 : loss : 0.137591, loss_ce: 0.050954
2022-01-15 23:43:56,192 iteration 276 : loss : 0.142102, loss_ce: 0.061931
2022-01-15 23:43:57,182 iteration 277 : loss : 0.141630, loss_ce: 0.052302
2022-01-15 23:43:58,002 iteration 278 : loss : 0.190827, loss_ce: 0.063752
2022-01-15 23:43:58,898 iteration 279 : loss : 0.199751, loss_ce: 0.071684
2022-01-15 23:43:59,783 iteration 280 : loss : 0.169542, loss_ce: 0.066416
2022-01-15 23:44:00,739 iteration 281 : loss : 0.157745, loss_ce: 0.063139
2022-01-15 23:44:01,672 iteration 282 : loss : 0.219585, loss_ce: 0.081529
2022-01-15 23:44:02,578 iteration 283 : loss : 0.196263, loss_ce: 0.082627
2022-01-15 23:44:03,602 iteration 284 : loss : 0.187339, loss_ce: 0.074224
2022-01-15 23:44:04,494 iteration 285 : loss : 0.183339, loss_ce: 0.061011
2022-01-15 23:44:05,402 iteration 286 : loss : 0.144997, loss_ce: 0.060995
2022-01-15 23:44:06,444 iteration 287 : loss : 0.168653, loss_ce: 0.068938
2022-01-15 23:44:07,462 iteration 288 : loss : 0.186699, loss_ce: 0.073199
2022-01-15 23:44:08,391 iteration 289 : loss : 0.175463, loss_ce: 0.060984
  4%|█▎                            | 17/400 [05:01<1:52:27, 17.62s/it]2022-01-15 23:44:09,418 iteration 290 : loss : 0.166968, loss_ce: 0.060783
2022-01-15 23:44:10,329 iteration 291 : loss : 0.151926, loss_ce: 0.050654
2022-01-15 23:44:11,249 iteration 292 : loss : 0.135483, loss_ce: 0.052913
2022-01-15 23:44:12,175 iteration 293 : loss : 0.189090, loss_ce: 0.073174
2022-01-15 23:44:13,135 iteration 294 : loss : 0.187105, loss_ce: 0.070775
2022-01-15 23:44:14,204 iteration 295 : loss : 0.181426, loss_ce: 0.057564
2022-01-15 23:44:15,123 iteration 296 : loss : 0.179459, loss_ce: 0.066589
2022-01-15 23:44:16,081 iteration 297 : loss : 0.179185, loss_ce: 0.061297
2022-01-15 23:44:16,995 iteration 298 : loss : 0.112394, loss_ce: 0.034920
2022-01-15 23:44:17,944 iteration 299 : loss : 0.159897, loss_ce: 0.053399
2022-01-15 23:44:18,897 iteration 300 : loss : 0.190984, loss_ce: 0.062946
2022-01-15 23:44:19,857 iteration 301 : loss : 0.186226, loss_ce: 0.091540
2022-01-15 23:44:20,882 iteration 302 : loss : 0.138812, loss_ce: 0.051641
2022-01-15 23:44:21,883 iteration 303 : loss : 0.176496, loss_ce: 0.072185
2022-01-15 23:44:22,859 iteration 304 : loss : 0.183304, loss_ce: 0.076897
2022-01-15 23:44:23,877 iteration 305 : loss : 0.169242, loss_ce: 0.069205
2022-01-15 23:44:24,888 iteration 306 : loss : 0.127915, loss_ce: 0.057821
  4%|█▎                            | 18/400 [05:17<1:50:02, 17.28s/it]2022-01-15 23:44:25,928 iteration 307 : loss : 0.158431, loss_ce: 0.060018
2022-01-15 23:44:26,846 iteration 308 : loss : 0.148846, loss_ce: 0.066293
2022-01-15 23:44:27,827 iteration 309 : loss : 0.221608, loss_ce: 0.080340
2022-01-15 23:44:28,836 iteration 310 : loss : 0.187056, loss_ce: 0.079122
2022-01-15 23:44:29,747 iteration 311 : loss : 0.203291, loss_ce: 0.061625
2022-01-15 23:44:30,697 iteration 312 : loss : 0.168121, loss_ce: 0.075944
2022-01-15 23:44:31,662 iteration 313 : loss : 0.197261, loss_ce: 0.092757
2022-01-15 23:44:32,540 iteration 314 : loss : 0.136293, loss_ce: 0.063327
2022-01-15 23:44:33,479 iteration 315 : loss : 0.201700, loss_ce: 0.080354
2022-01-15 23:44:34,451 iteration 316 : loss : 0.188242, loss_ce: 0.064653
2022-01-15 23:44:35,409 iteration 317 : loss : 0.190823, loss_ce: 0.069561
2022-01-15 23:44:36,384 iteration 318 : loss : 0.145070, loss_ce: 0.061832
2022-01-15 23:44:37,274 iteration 319 : loss : 0.140042, loss_ce: 0.053672
2022-01-15 23:44:38,313 iteration 320 : loss : 0.147766, loss_ce: 0.054874
2022-01-15 23:44:39,313 iteration 321 : loss : 0.159354, loss_ce: 0.055746
2022-01-15 23:44:40,267 iteration 322 : loss : 0.200763, loss_ce: 0.077565
2022-01-15 23:44:41,290 iteration 323 : loss : 0.189746, loss_ce: 0.053458
  5%|█▍                            | 19/400 [05:34<1:48:03, 17.02s/it]2022-01-15 23:44:42,300 iteration 324 : loss : 0.174475, loss_ce: 0.057377
2022-01-15 23:44:43,257 iteration 325 : loss : 0.201051, loss_ce: 0.061594
2022-01-15 23:44:44,249 iteration 326 : loss : 0.129263, loss_ce: 0.056864
2022-01-15 23:44:45,320 iteration 327 : loss : 0.180669, loss_ce: 0.062784
2022-01-15 23:44:46,273 iteration 328 : loss : 0.194314, loss_ce: 0.082325
2022-01-15 23:44:47,270 iteration 329 : loss : 0.172724, loss_ce: 0.080332
2022-01-15 23:44:48,285 iteration 330 : loss : 0.153116, loss_ce: 0.063023
2022-01-15 23:44:49,191 iteration 331 : loss : 0.149859, loss_ce: 0.064455
2022-01-15 23:44:50,132 iteration 332 : loss : 0.133514, loss_ce: 0.047639
2022-01-15 23:44:51,117 iteration 333 : loss : 0.128300, loss_ce: 0.057201
2022-01-15 23:44:52,088 iteration 334 : loss : 0.159862, loss_ce: 0.058472
2022-01-15 23:44:53,023 iteration 335 : loss : 0.191588, loss_ce: 0.060637
2022-01-15 23:44:54,039 iteration 336 : loss : 0.122363, loss_ce: 0.043027
2022-01-15 23:44:54,994 iteration 337 : loss : 0.155518, loss_ce: 0.047876
2022-01-15 23:44:55,901 iteration 338 : loss : 0.180507, loss_ce: 0.084290
2022-01-15 23:44:56,819 iteration 339 : loss : 0.180865, loss_ce: 0.059551
2022-01-15 23:44:56,819 Training Data Eval:
2022-01-15 23:45:01,354   Average segmentation loss on training set: 0.4290
2022-01-15 23:45:01,355 Validation Data Eval:
2022-01-15 23:45:02,851   Average segmentation loss on validation set: 0.4977
2022-01-15 23:45:03,862 iteration 340 : loss : 0.163164, loss_ce: 0.069083
  5%|█▌                            | 20/400 [05:56<1:58:19, 18.68s/it]2022-01-15 23:45:04,936 iteration 341 : loss : 0.167555, loss_ce: 0.067363
2022-01-15 23:45:05,929 iteration 342 : loss : 0.136658, loss_ce: 0.040289
2022-01-15 23:45:06,890 iteration 343 : loss : 0.182127, loss_ce: 0.067103
2022-01-15 23:45:07,899 iteration 344 : loss : 0.193193, loss_ce: 0.081876
2022-01-15 23:45:08,850 iteration 345 : loss : 0.127664, loss_ce: 0.037708
2022-01-15 23:45:09,886 iteration 346 : loss : 0.182783, loss_ce: 0.064333
2022-01-15 23:45:10,791 iteration 347 : loss : 0.173628, loss_ce: 0.077564
2022-01-15 23:45:11,782 iteration 348 : loss : 0.183853, loss_ce: 0.065325
2022-01-15 23:45:12,896 iteration 349 : loss : 0.161655, loss_ce: 0.084348
2022-01-15 23:45:13,852 iteration 350 : loss : 0.152347, loss_ce: 0.064121
2022-01-15 23:45:14,883 iteration 351 : loss : 0.137766, loss_ce: 0.064877
2022-01-15 23:45:15,881 iteration 352 : loss : 0.173300, loss_ce: 0.075287
2022-01-15 23:45:16,790 iteration 353 : loss : 0.164132, loss_ce: 0.067301
2022-01-15 23:45:17,760 iteration 354 : loss : 0.192833, loss_ce: 0.068108
2022-01-15 23:45:18,780 iteration 355 : loss : 0.154257, loss_ce: 0.062878
2022-01-15 23:45:19,880 iteration 356 : loss : 0.150011, loss_ce: 0.058900
2022-01-15 23:45:20,767 iteration 357 : loss : 0.130588, loss_ce: 0.049587
  5%|█▌                            | 21/400 [06:13<1:54:38, 18.15s/it]2022-01-15 23:45:21,823 iteration 358 : loss : 0.158581, loss_ce: 0.062745
2022-01-15 23:45:22,865 iteration 359 : loss : 0.170424, loss_ce: 0.062351
2022-01-15 23:45:23,762 iteration 360 : loss : 0.132785, loss_ce: 0.045027
2022-01-15 23:45:24,766 iteration 361 : loss : 0.149866, loss_ce: 0.049051
2022-01-15 23:45:25,822 iteration 362 : loss : 0.141454, loss_ce: 0.041075
2022-01-15 23:45:26,872 iteration 363 : loss : 0.193401, loss_ce: 0.068602
2022-01-15 23:45:27,862 iteration 364 : loss : 0.168289, loss_ce: 0.052108
2022-01-15 23:45:28,717 iteration 365 : loss : 0.177447, loss_ce: 0.073988
2022-01-15 23:45:29,717 iteration 366 : loss : 0.195942, loss_ce: 0.089421
2022-01-15 23:45:30,602 iteration 367 : loss : 0.158001, loss_ce: 0.061346
2022-01-15 23:45:31,613 iteration 368 : loss : 0.178349, loss_ce: 0.060812
2022-01-15 23:45:32,664 iteration 369 : loss : 0.197361, loss_ce: 0.069305
2022-01-15 23:45:33,700 iteration 370 : loss : 0.131158, loss_ce: 0.063310
2022-01-15 23:45:34,682 iteration 371 : loss : 0.209635, loss_ce: 0.066240
2022-01-15 23:45:35,673 iteration 372 : loss : 0.218868, loss_ce: 0.101686
2022-01-15 23:45:36,579 iteration 373 : loss : 0.175011, loss_ce: 0.063338
2022-01-15 23:45:37,519 iteration 374 : loss : 0.160733, loss_ce: 0.056790
  6%|█▋                            | 22/400 [06:30<1:51:43, 17.73s/it]2022-01-15 23:45:38,609 iteration 375 : loss : 0.247800, loss_ce: 0.105338
2022-01-15 23:45:39,517 iteration 376 : loss : 0.113619, loss_ce: 0.034962
2022-01-15 23:45:40,466 iteration 377 : loss : 0.159133, loss_ce: 0.048704
2022-01-15 23:45:41,510 iteration 378 : loss : 0.178995, loss_ce: 0.074068
2022-01-15 23:45:42,382 iteration 379 : loss : 0.126909, loss_ce: 0.050502
2022-01-15 23:45:43,374 iteration 380 : loss : 0.170875, loss_ce: 0.063559
2022-01-15 23:45:44,327 iteration 381 : loss : 0.138804, loss_ce: 0.047756
2022-01-15 23:45:45,201 iteration 382 : loss : 0.173381, loss_ce: 0.079090
2022-01-15 23:45:46,160 iteration 383 : loss : 0.204487, loss_ce: 0.080982
2022-01-15 23:45:47,142 iteration 384 : loss : 0.163997, loss_ce: 0.072349
2022-01-15 23:45:48,104 iteration 385 : loss : 0.129676, loss_ce: 0.057376
2022-01-15 23:45:49,069 iteration 386 : loss : 0.195351, loss_ce: 0.069981
2022-01-15 23:45:50,052 iteration 387 : loss : 0.192247, loss_ce: 0.057171
2022-01-15 23:45:51,052 iteration 388 : loss : 0.157268, loss_ce: 0.053286
2022-01-15 23:45:52,044 iteration 389 : loss : 0.243051, loss_ce: 0.121445
2022-01-15 23:45:52,991 iteration 390 : loss : 0.139316, loss_ce: 0.049899
2022-01-15 23:45:53,931 iteration 391 : loss : 0.206114, loss_ce: 0.105930
  6%|█▋                            | 23/400 [06:47<1:48:53, 17.33s/it]2022-01-15 23:45:54,978 iteration 392 : loss : 0.177713, loss_ce: 0.090120
2022-01-15 23:45:55,895 iteration 393 : loss : 0.141421, loss_ce: 0.050142
2022-01-15 23:45:56,911 iteration 394 : loss : 0.147730, loss_ce: 0.048998
2022-01-15 23:45:57,901 iteration 395 : loss : 0.146502, loss_ce: 0.057310
2022-01-15 23:45:58,830 iteration 396 : loss : 0.144709, loss_ce: 0.050574
2022-01-15 23:45:59,793 iteration 397 : loss : 0.146147, loss_ce: 0.059009
2022-01-15 23:46:00,774 iteration 398 : loss : 0.124840, loss_ce: 0.048220
2022-01-15 23:46:01,620 iteration 399 : loss : 0.162710, loss_ce: 0.059323
2022-01-15 23:46:02,592 iteration 400 : loss : 0.135816, loss_ce: 0.044055
2022-01-15 23:46:03,619 iteration 401 : loss : 0.141690, loss_ce: 0.054570
2022-01-15 23:46:04,555 iteration 402 : loss : 0.104961, loss_ce: 0.044523
2022-01-15 23:46:05,492 iteration 403 : loss : 0.105514, loss_ce: 0.040771
2022-01-15 23:46:06,488 iteration 404 : loss : 0.146991, loss_ce: 0.055874
2022-01-15 23:46:07,534 iteration 405 : loss : 0.142214, loss_ce: 0.057186
2022-01-15 23:46:08,467 iteration 406 : loss : 0.136236, loss_ce: 0.052552
2022-01-15 23:46:09,358 iteration 407 : loss : 0.135177, loss_ce: 0.047722
2022-01-15 23:46:10,303 iteration 408 : loss : 0.188470, loss_ce: 0.066947
  6%|█▊                            | 24/400 [07:03<1:46:50, 17.05s/it]2022-01-15 23:46:11,357 iteration 409 : loss : 0.113393, loss_ce: 0.049724
2022-01-15 23:46:12,348 iteration 410 : loss : 0.166264, loss_ce: 0.063756
2022-01-15 23:46:13,304 iteration 411 : loss : 0.201742, loss_ce: 0.052929
2022-01-15 23:46:14,155 iteration 412 : loss : 0.130858, loss_ce: 0.048452
2022-01-15 23:46:15,114 iteration 413 : loss : 0.117441, loss_ce: 0.039638
2022-01-15 23:46:16,009 iteration 414 : loss : 0.189555, loss_ce: 0.101762
2022-01-15 23:46:16,842 iteration 415 : loss : 0.141032, loss_ce: 0.054819
2022-01-15 23:46:17,778 iteration 416 : loss : 0.142912, loss_ce: 0.070652
2022-01-15 23:46:18,680 iteration 417 : loss : 0.206805, loss_ce: 0.083376
2022-01-15 23:46:19,704 iteration 418 : loss : 0.131486, loss_ce: 0.053297
2022-01-15 23:46:20,627 iteration 419 : loss : 0.160393, loss_ce: 0.086568
2022-01-15 23:46:21,601 iteration 420 : loss : 0.124554, loss_ce: 0.047221
2022-01-15 23:46:22,500 iteration 421 : loss : 0.174573, loss_ce: 0.071864
2022-01-15 23:46:23,395 iteration 422 : loss : 0.186785, loss_ce: 0.076556
2022-01-15 23:46:24,305 iteration 423 : loss : 0.165064, loss_ce: 0.050775
2022-01-15 23:46:25,268 iteration 424 : loss : 0.162735, loss_ce: 0.064025
2022-01-15 23:46:25,268 Training Data Eval:
2022-01-15 23:46:29,800   Average segmentation loss on training set: 0.1305
2022-01-15 23:46:29,801 Validation Data Eval:
2022-01-15 23:46:31,288   Average segmentation loss on validation set: 0.1536
2022-01-15 23:46:32,141 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-15 23:46:33,074 iteration 425 : loss : 0.129321, loss_ce: 0.049977
  6%|█▉                            | 25/400 [07:26<1:57:16, 18.76s/it]2022-01-15 23:46:34,035 iteration 426 : loss : 0.145848, loss_ce: 0.044991
2022-01-15 23:46:35,031 iteration 427 : loss : 0.115275, loss_ce: 0.041989
2022-01-15 23:46:35,993 iteration 428 : loss : 0.143976, loss_ce: 0.050763
2022-01-15 23:46:36,893 iteration 429 : loss : 0.197314, loss_ce: 0.097373
2022-01-15 23:46:37,782 iteration 430 : loss : 0.141841, loss_ce: 0.048730
2022-01-15 23:46:38,700 iteration 431 : loss : 0.209424, loss_ce: 0.067709
2022-01-15 23:46:39,683 iteration 432 : loss : 0.104139, loss_ce: 0.041042
2022-01-15 23:46:40,708 iteration 433 : loss : 0.131530, loss_ce: 0.052997
2022-01-15 23:46:41,670 iteration 434 : loss : 0.136389, loss_ce: 0.054191
2022-01-15 23:46:42,557 iteration 435 : loss : 0.128976, loss_ce: 0.053160
2022-01-15 23:46:43,488 iteration 436 : loss : 0.124541, loss_ce: 0.051585
2022-01-15 23:46:44,427 iteration 437 : loss : 0.159245, loss_ce: 0.075682
2022-01-15 23:46:45,308 iteration 438 : loss : 0.135907, loss_ce: 0.047014
2022-01-15 23:46:46,268 iteration 439 : loss : 0.156604, loss_ce: 0.049611
2022-01-15 23:46:47,199 iteration 440 : loss : 0.153441, loss_ce: 0.047499
2022-01-15 23:46:48,197 iteration 441 : loss : 0.152734, loss_ce: 0.053209
2022-01-15 23:46:49,173 iteration 442 : loss : 0.130121, loss_ce: 0.058968
  6%|█▉                            | 26/400 [07:42<1:51:59, 17.97s/it]2022-01-15 23:46:50,164 iteration 443 : loss : 0.141409, loss_ce: 0.067545
2022-01-15 23:46:51,058 iteration 444 : loss : 0.110731, loss_ce: 0.040283
2022-01-15 23:46:51,995 iteration 445 : loss : 0.173755, loss_ce: 0.062053
2022-01-15 23:46:53,085 iteration 446 : loss : 0.172410, loss_ce: 0.071721
2022-01-15 23:46:54,113 iteration 447 : loss : 0.129749, loss_ce: 0.069649
2022-01-15 23:46:55,123 iteration 448 : loss : 0.235610, loss_ce: 0.071134
2022-01-15 23:46:56,083 iteration 449 : loss : 0.140909, loss_ce: 0.060384
2022-01-15 23:46:57,020 iteration 450 : loss : 0.137693, loss_ce: 0.053157
2022-01-15 23:46:58,061 iteration 451 : loss : 0.131823, loss_ce: 0.058528
2022-01-15 23:46:59,054 iteration 452 : loss : 0.107238, loss_ce: 0.045013
2022-01-15 23:47:00,039 iteration 453 : loss : 0.166917, loss_ce: 0.069424
2022-01-15 23:47:01,027 iteration 454 : loss : 0.156664, loss_ce: 0.052687
2022-01-15 23:47:02,050 iteration 455 : loss : 0.124378, loss_ce: 0.044593
2022-01-15 23:47:03,028 iteration 456 : loss : 0.134530, loss_ce: 0.041235
2022-01-15 23:47:03,999 iteration 457 : loss : 0.166389, loss_ce: 0.059930
2022-01-15 23:47:05,046 iteration 458 : loss : 0.163481, loss_ce: 0.081007
2022-01-15 23:47:05,936 iteration 459 : loss : 0.119493, loss_ce: 0.041997
  7%|██                            | 27/400 [07:59<1:49:25, 17.60s/it]2022-01-15 23:47:06,980 iteration 460 : loss : 0.182935, loss_ce: 0.097505
2022-01-15 23:47:07,999 iteration 461 : loss : 0.134416, loss_ce: 0.063873
2022-01-15 23:47:08,945 iteration 462 : loss : 0.128044, loss_ce: 0.051089
2022-01-15 23:47:09,982 iteration 463 : loss : 0.094976, loss_ce: 0.037652
2022-01-15 23:47:10,952 iteration 464 : loss : 0.105739, loss_ce: 0.040048
2022-01-15 23:47:11,861 iteration 465 : loss : 0.117765, loss_ce: 0.034235
2022-01-15 23:47:12,814 iteration 466 : loss : 0.123188, loss_ce: 0.034384
2022-01-15 23:47:13,747 iteration 467 : loss : 0.173782, loss_ce: 0.054473
2022-01-15 23:47:14,820 iteration 468 : loss : 0.138504, loss_ce: 0.054484
2022-01-15 23:47:15,756 iteration 469 : loss : 0.112404, loss_ce: 0.032396
2022-01-15 23:47:16,713 iteration 470 : loss : 0.127275, loss_ce: 0.046131
2022-01-15 23:47:17,667 iteration 471 : loss : 0.139507, loss_ce: 0.045826
2022-01-15 23:47:18,682 iteration 472 : loss : 0.178765, loss_ce: 0.073936
2022-01-15 23:47:19,802 iteration 473 : loss : 0.146254, loss_ce: 0.055613
2022-01-15 23:47:20,867 iteration 474 : loss : 0.216433, loss_ce: 0.097461
2022-01-15 23:47:21,809 iteration 475 : loss : 0.111430, loss_ce: 0.043147
2022-01-15 23:47:22,833 iteration 476 : loss : 0.158451, loss_ce: 0.076230
  7%|██                            | 28/400 [08:15<1:47:49, 17.39s/it]2022-01-15 23:47:23,861 iteration 477 : loss : 0.156905, loss_ce: 0.052882
2022-01-15 23:47:24,875 iteration 478 : loss : 0.104805, loss_ce: 0.034376
2022-01-15 23:47:25,829 iteration 479 : loss : 0.169807, loss_ce: 0.065227
2022-01-15 23:47:26,812 iteration 480 : loss : 0.140159, loss_ce: 0.060618
2022-01-15 23:47:27,684 iteration 481 : loss : 0.166308, loss_ce: 0.065100
2022-01-15 23:47:28,666 iteration 482 : loss : 0.182252, loss_ce: 0.055244
2022-01-15 23:47:29,653 iteration 483 : loss : 0.186456, loss_ce: 0.065813
2022-01-15 23:47:30,661 iteration 484 : loss : 0.187391, loss_ce: 0.078299
2022-01-15 23:47:31,606 iteration 485 : loss : 0.152912, loss_ce: 0.062589
2022-01-15 23:47:32,535 iteration 486 : loss : 0.187900, loss_ce: 0.059217
2022-01-15 23:47:33,559 iteration 487 : loss : 0.133440, loss_ce: 0.054415
2022-01-15 23:47:34,457 iteration 488 : loss : 0.128941, loss_ce: 0.055746
2022-01-15 23:47:35,419 iteration 489 : loss : 0.128243, loss_ce: 0.051716
2022-01-15 23:47:36,265 iteration 490 : loss : 0.179799, loss_ce: 0.070879
2022-01-15 23:47:37,231 iteration 491 : loss : 0.141707, loss_ce: 0.063340
2022-01-15 23:47:38,171 iteration 492 : loss : 0.130235, loss_ce: 0.066104
2022-01-15 23:47:39,159 iteration 493 : loss : 0.145703, loss_ce: 0.068969
  7%|██▏                           | 29/400 [08:32<1:45:33, 17.07s/it]2022-01-15 23:47:40,215 iteration 494 : loss : 0.151870, loss_ce: 0.071124
2022-01-15 23:47:41,218 iteration 495 : loss : 0.140980, loss_ce: 0.052181
2022-01-15 23:47:42,165 iteration 496 : loss : 0.157408, loss_ce: 0.069131
2022-01-15 23:47:43,153 iteration 497 : loss : 0.156524, loss_ce: 0.062914
2022-01-15 23:47:44,185 iteration 498 : loss : 0.144306, loss_ce: 0.061920
2022-01-15 23:47:45,074 iteration 499 : loss : 0.105938, loss_ce: 0.043391
2022-01-15 23:47:45,978 iteration 500 : loss : 0.180699, loss_ce: 0.067672
2022-01-15 23:47:46,880 iteration 501 : loss : 0.165620, loss_ce: 0.071756
2022-01-15 23:47:47,907 iteration 502 : loss : 0.111730, loss_ce: 0.044349
2022-01-15 23:47:48,829 iteration 503 : loss : 0.171202, loss_ce: 0.050491
2022-01-15 23:47:49,817 iteration 504 : loss : 0.120414, loss_ce: 0.040255
2022-01-15 23:47:50,730 iteration 505 : loss : 0.111287, loss_ce: 0.042608
2022-01-15 23:47:51,788 iteration 506 : loss : 0.122489, loss_ce: 0.046712
2022-01-15 23:47:52,759 iteration 507 : loss : 0.185155, loss_ce: 0.069844
2022-01-15 23:47:53,728 iteration 508 : loss : 0.169267, loss_ce: 0.067545
2022-01-15 23:47:54,741 iteration 509 : loss : 0.151634, loss_ce: 0.048722
2022-01-15 23:47:54,741 Training Data Eval:
2022-01-15 23:47:59,271   Average segmentation loss on training set: 0.1373
2022-01-15 23:47:59,271 Validation Data Eval:
2022-01-15 23:48:00,759   Average segmentation loss on validation set: 0.1724
2022-01-15 23:48:01,762 iteration 510 : loss : 0.128701, loss_ce: 0.049878
  8%|██▎                           | 30/400 [08:54<1:55:29, 18.73s/it]2022-01-15 23:48:02,804 iteration 511 : loss : 0.195639, loss_ce: 0.105378
2022-01-15 23:48:03,715 iteration 512 : loss : 0.208107, loss_ce: 0.103869
2022-01-15 23:48:04,640 iteration 513 : loss : 0.112788, loss_ce: 0.037143
2022-01-15 23:48:05,593 iteration 514 : loss : 0.132582, loss_ce: 0.059420
2022-01-15 23:48:06,522 iteration 515 : loss : 0.122916, loss_ce: 0.045021
2022-01-15 23:48:07,505 iteration 516 : loss : 0.107324, loss_ce: 0.036780
2022-01-15 23:48:08,524 iteration 517 : loss : 0.172323, loss_ce: 0.072380
2022-01-15 23:48:09,426 iteration 518 : loss : 0.165342, loss_ce: 0.053779
2022-01-15 23:48:10,386 iteration 519 : loss : 0.149546, loss_ce: 0.059661
2022-01-15 23:48:11,285 iteration 520 : loss : 0.120944, loss_ce: 0.043545
2022-01-15 23:48:12,239 iteration 521 : loss : 0.118032, loss_ce: 0.040822
2022-01-15 23:48:13,238 iteration 522 : loss : 0.110637, loss_ce: 0.038795
2022-01-15 23:48:14,280 iteration 523 : loss : 0.109096, loss_ce: 0.044858
2022-01-15 23:48:15,348 iteration 524 : loss : 0.109223, loss_ce: 0.038583
2022-01-15 23:48:16,306 iteration 525 : loss : 0.165212, loss_ce: 0.068985
2022-01-15 23:48:17,255 iteration 526 : loss : 0.149149, loss_ce: 0.064028
2022-01-15 23:48:18,214 iteration 527 : loss : 0.119080, loss_ce: 0.046715
  8%|██▎                           | 31/400 [09:11<1:50:59, 18.05s/it]2022-01-15 23:48:19,203 iteration 528 : loss : 0.130812, loss_ce: 0.054407
2022-01-15 23:48:20,169 iteration 529 : loss : 0.139414, loss_ce: 0.043691
2022-01-15 23:48:21,083 iteration 530 : loss : 0.173523, loss_ce: 0.064835
2022-01-15 23:48:21,982 iteration 531 : loss : 0.128961, loss_ce: 0.038778
2022-01-15 23:48:22,898 iteration 532 : loss : 0.117146, loss_ce: 0.051754
2022-01-15 23:48:23,960 iteration 533 : loss : 0.080685, loss_ce: 0.026696
2022-01-15 23:48:24,859 iteration 534 : loss : 0.101763, loss_ce: 0.044602
2022-01-15 23:48:25,868 iteration 535 : loss : 0.097320, loss_ce: 0.036168
2022-01-15 23:48:26,908 iteration 536 : loss : 0.182239, loss_ce: 0.077307
2022-01-15 23:48:27,969 iteration 537 : loss : 0.146526, loss_ce: 0.042535
2022-01-15 23:48:28,954 iteration 538 : loss : 0.123545, loss_ce: 0.054391
2022-01-15 23:48:29,896 iteration 539 : loss : 0.134563, loss_ce: 0.054208
2022-01-15 23:48:30,876 iteration 540 : loss : 0.103611, loss_ce: 0.035132
2022-01-15 23:48:31,813 iteration 541 : loss : 0.105799, loss_ce: 0.042118
2022-01-15 23:48:32,768 iteration 542 : loss : 0.135220, loss_ce: 0.053503
2022-01-15 23:48:33,671 iteration 543 : loss : 0.102549, loss_ce: 0.041037
2022-01-15 23:48:34,607 iteration 544 : loss : 0.114259, loss_ce: 0.039148
  8%|██▍                           | 32/400 [09:27<1:47:38, 17.55s/it]2022-01-15 23:48:35,648 iteration 545 : loss : 0.082475, loss_ce: 0.037992
2022-01-15 23:48:36,605 iteration 546 : loss : 0.096635, loss_ce: 0.034971
2022-01-15 23:48:37,558 iteration 547 : loss : 0.127070, loss_ce: 0.055983
2022-01-15 23:48:38,503 iteration 548 : loss : 0.204711, loss_ce: 0.077636
2022-01-15 23:48:39,489 iteration 549 : loss : 0.102896, loss_ce: 0.044148
2022-01-15 23:48:40,413 iteration 550 : loss : 0.133940, loss_ce: 0.053691
2022-01-15 23:48:41,359 iteration 551 : loss : 0.117806, loss_ce: 0.051521
2022-01-15 23:48:42,283 iteration 552 : loss : 0.110809, loss_ce: 0.041833
2022-01-15 23:48:43,275 iteration 553 : loss : 0.136457, loss_ce: 0.047852
2022-01-15 23:48:44,194 iteration 554 : loss : 0.107248, loss_ce: 0.049172
2022-01-15 23:48:45,142 iteration 555 : loss : 0.159908, loss_ce: 0.040360
2022-01-15 23:48:46,148 iteration 556 : loss : 0.122094, loss_ce: 0.052857
2022-01-15 23:48:47,020 iteration 557 : loss : 0.156802, loss_ce: 0.047718
2022-01-15 23:48:48,017 iteration 558 : loss : 0.125492, loss_ce: 0.041238
2022-01-15 23:48:48,964 iteration 559 : loss : 0.155193, loss_ce: 0.064828
2022-01-15 23:48:49,938 iteration 560 : loss : 0.091013, loss_ce: 0.025931
2022-01-15 23:48:50,942 iteration 561 : loss : 0.181729, loss_ce: 0.092659
  8%|██▍                           | 33/400 [09:44<1:45:08, 17.19s/it]2022-01-15 23:48:52,091 iteration 562 : loss : 0.165789, loss_ce: 0.073145
2022-01-15 23:48:52,945 iteration 563 : loss : 0.124227, loss_ce: 0.051254
2022-01-15 23:48:53,930 iteration 564 : loss : 0.140503, loss_ce: 0.073334
2022-01-15 23:48:54,912 iteration 565 : loss : 0.094188, loss_ce: 0.041997
2022-01-15 23:48:55,931 iteration 566 : loss : 0.114293, loss_ce: 0.049804
2022-01-15 23:48:56,861 iteration 567 : loss : 0.137146, loss_ce: 0.047695
2022-01-15 23:48:57,783 iteration 568 : loss : 0.203571, loss_ce: 0.064891
2022-01-15 23:48:58,732 iteration 569 : loss : 0.126863, loss_ce: 0.051330
2022-01-15 23:48:59,729 iteration 570 : loss : 0.090464, loss_ce: 0.040607
2022-01-15 23:49:00,662 iteration 571 : loss : 0.234837, loss_ce: 0.100287
2022-01-15 23:49:01,639 iteration 572 : loss : 0.113726, loss_ce: 0.038180
2022-01-15 23:49:02,560 iteration 573 : loss : 0.134578, loss_ce: 0.055812
2022-01-15 23:49:03,517 iteration 574 : loss : 0.163397, loss_ce: 0.050243
2022-01-15 23:49:04,545 iteration 575 : loss : 0.141044, loss_ce: 0.038191
2022-01-15 23:49:05,553 iteration 576 : loss : 0.126238, loss_ce: 0.055741
2022-01-15 23:49:06,513 iteration 577 : loss : 0.099449, loss_ce: 0.035931
2022-01-15 23:49:07,421 iteration 578 : loss : 0.132822, loss_ce: 0.045685
  8%|██▌                           | 34/400 [10:00<1:43:32, 16.97s/it]2022-01-15 23:49:08,628 iteration 579 : loss : 0.163956, loss_ce: 0.071279
2022-01-15 23:49:09,608 iteration 580 : loss : 0.121192, loss_ce: 0.050864
2022-01-15 23:49:10,628 iteration 581 : loss : 0.166513, loss_ce: 0.058694
2022-01-15 23:49:11,575 iteration 582 : loss : 0.112342, loss_ce: 0.045635
2022-01-15 23:49:12,544 iteration 583 : loss : 0.229885, loss_ce: 0.075908
2022-01-15 23:49:13,470 iteration 584 : loss : 0.089807, loss_ce: 0.038828
2022-01-15 23:49:14,483 iteration 585 : loss : 0.086146, loss_ce: 0.031771
2022-01-15 23:49:15,395 iteration 586 : loss : 0.154110, loss_ce: 0.060245
2022-01-15 23:49:16,305 iteration 587 : loss : 0.113119, loss_ce: 0.049043
2022-01-15 23:49:17,286 iteration 588 : loss : 0.119926, loss_ce: 0.042897
2022-01-15 23:49:18,231 iteration 589 : loss : 0.117686, loss_ce: 0.038619
2022-01-15 23:49:19,188 iteration 590 : loss : 0.106003, loss_ce: 0.036693
2022-01-15 23:49:20,149 iteration 591 : loss : 0.117549, loss_ce: 0.040431
2022-01-15 23:49:21,110 iteration 592 : loss : 0.118616, loss_ce: 0.044672
2022-01-15 23:49:22,110 iteration 593 : loss : 0.087671, loss_ce: 0.031897
2022-01-15 23:49:23,088 iteration 594 : loss : 0.114354, loss_ce: 0.050009
2022-01-15 23:49:23,088 Training Data Eval:
2022-01-15 23:49:27,618   Average segmentation loss on training set: 0.1327
2022-01-15 23:49:27,618 Validation Data Eval:
2022-01-15 23:49:29,115   Average segmentation loss on validation set: 0.2403
2022-01-15 23:49:30,143 iteration 595 : loss : 0.146249, loss_ce: 0.072636
  9%|██▋                           | 35/400 [10:23<1:53:44, 18.70s/it]2022-01-15 23:49:31,169 iteration 596 : loss : 0.100512, loss_ce: 0.041951
2022-01-15 23:49:32,090 iteration 597 : loss : 0.158334, loss_ce: 0.053360
2022-01-15 23:49:33,012 iteration 598 : loss : 0.094525, loss_ce: 0.035843
2022-01-15 23:49:33,947 iteration 599 : loss : 0.129036, loss_ce: 0.050106
2022-01-15 23:49:34,883 iteration 600 : loss : 0.139514, loss_ce: 0.063242
2022-01-15 23:49:35,850 iteration 601 : loss : 0.124243, loss_ce: 0.047138
2022-01-15 23:49:36,835 iteration 602 : loss : 0.105709, loss_ce: 0.042080
2022-01-15 23:49:37,722 iteration 603 : loss : 0.110157, loss_ce: 0.036588
2022-01-15 23:49:38,623 iteration 604 : loss : 0.106070, loss_ce: 0.040517
2022-01-15 23:49:39,511 iteration 605 : loss : 0.121131, loss_ce: 0.044212
2022-01-15 23:49:40,619 iteration 606 : loss : 0.104464, loss_ce: 0.044565
2022-01-15 23:49:41,567 iteration 607 : loss : 0.152754, loss_ce: 0.060046
2022-01-15 23:49:42,520 iteration 608 : loss : 0.146900, loss_ce: 0.067951
2022-01-15 23:49:43,386 iteration 609 : loss : 0.089045, loss_ce: 0.033926
2022-01-15 23:49:44,386 iteration 610 : loss : 0.100599, loss_ce: 0.042132
2022-01-15 23:49:45,452 iteration 611 : loss : 0.145279, loss_ce: 0.062850
2022-01-15 23:49:46,436 iteration 612 : loss : 0.096339, loss_ce: 0.033730
  9%|██▋                           | 36/400 [10:39<1:49:04, 17.98s/it]2022-01-15 23:49:47,492 iteration 613 : loss : 0.104720, loss_ce: 0.038593
2022-01-15 23:49:48,410 iteration 614 : loss : 0.108336, loss_ce: 0.036673
2022-01-15 23:49:49,316 iteration 615 : loss : 0.137272, loss_ce: 0.060526
2022-01-15 23:49:50,356 iteration 616 : loss : 0.113174, loss_ce: 0.050162
2022-01-15 23:49:51,270 iteration 617 : loss : 0.120496, loss_ce: 0.055466
2022-01-15 23:49:52,241 iteration 618 : loss : 0.122769, loss_ce: 0.037725
2022-01-15 23:49:53,210 iteration 619 : loss : 0.218590, loss_ce: 0.086179
2022-01-15 23:49:54,277 iteration 620 : loss : 0.155397, loss_ce: 0.047843
2022-01-15 23:49:55,245 iteration 621 : loss : 0.090613, loss_ce: 0.031559
2022-01-15 23:49:56,345 iteration 622 : loss : 0.117241, loss_ce: 0.042284
2022-01-15 23:49:57,422 iteration 623 : loss : 0.125440, loss_ce: 0.059812
2022-01-15 23:49:58,372 iteration 624 : loss : 0.112039, loss_ce: 0.037212
2022-01-15 23:49:59,282 iteration 625 : loss : 0.106206, loss_ce: 0.044284
2022-01-15 23:50:00,295 iteration 626 : loss : 0.105131, loss_ce: 0.044050
2022-01-15 23:50:01,320 iteration 627 : loss : 0.153240, loss_ce: 0.060792
2022-01-15 23:50:02,395 iteration 628 : loss : 0.127413, loss_ce: 0.048111
2022-01-15 23:50:03,346 iteration 629 : loss : 0.090193, loss_ce: 0.036276
  9%|██▊                           | 37/400 [10:56<1:46:49, 17.66s/it]2022-01-15 23:50:04,411 iteration 630 : loss : 0.105282, loss_ce: 0.045112
2022-01-15 23:50:05,346 iteration 631 : loss : 0.080385, loss_ce: 0.033697
2022-01-15 23:50:06,281 iteration 632 : loss : 0.127376, loss_ce: 0.048066
2022-01-15 23:50:07,325 iteration 633 : loss : 0.103292, loss_ce: 0.048462
2022-01-15 23:50:08,296 iteration 634 : loss : 0.195700, loss_ce: 0.077555
2022-01-15 23:50:09,367 iteration 635 : loss : 0.128103, loss_ce: 0.057074
2022-01-15 23:50:10,359 iteration 636 : loss : 0.121849, loss_ce: 0.049485
2022-01-15 23:50:11,251 iteration 637 : loss : 0.120646, loss_ce: 0.056662
2022-01-15 23:50:12,302 iteration 638 : loss : 0.186949, loss_ce: 0.058160
2022-01-15 23:50:13,224 iteration 639 : loss : 0.110843, loss_ce: 0.049488
2022-01-15 23:50:14,118 iteration 640 : loss : 0.146650, loss_ce: 0.042720
2022-01-15 23:50:15,012 iteration 641 : loss : 0.119607, loss_ce: 0.048184
2022-01-15 23:50:15,920 iteration 642 : loss : 0.111778, loss_ce: 0.029530
2022-01-15 23:50:16,860 iteration 643 : loss : 0.157238, loss_ce: 0.057947
2022-01-15 23:50:17,812 iteration 644 : loss : 0.123628, loss_ce: 0.053222
2022-01-15 23:50:18,720 iteration 645 : loss : 0.119355, loss_ce: 0.035910
2022-01-15 23:50:19,746 iteration 646 : loss : 0.099587, loss_ce: 0.038184
 10%|██▊                           | 38/400 [11:12<1:44:14, 17.28s/it]2022-01-15 23:50:20,749 iteration 647 : loss : 0.124850, loss_ce: 0.048778
2022-01-15 23:50:21,713 iteration 648 : loss : 0.103841, loss_ce: 0.044326
2022-01-15 23:50:22,707 iteration 649 : loss : 0.101596, loss_ce: 0.043520
2022-01-15 23:50:23,750 iteration 650 : loss : 0.155965, loss_ce: 0.060352
2022-01-15 23:50:24,709 iteration 651 : loss : 0.096855, loss_ce: 0.039525
2022-01-15 23:50:25,555 iteration 652 : loss : 0.077917, loss_ce: 0.029324
2022-01-15 23:50:26,591 iteration 653 : loss : 0.110501, loss_ce: 0.047074
2022-01-15 23:50:27,497 iteration 654 : loss : 0.125564, loss_ce: 0.050551
2022-01-15 23:50:28,451 iteration 655 : loss : 0.183987, loss_ce: 0.053688
2022-01-15 23:50:29,422 iteration 656 : loss : 0.119571, loss_ce: 0.041933
2022-01-15 23:50:30,465 iteration 657 : loss : 0.070151, loss_ce: 0.025116
2022-01-15 23:50:31,453 iteration 658 : loss : 0.107289, loss_ce: 0.033053
2022-01-15 23:50:32,449 iteration 659 : loss : 0.106406, loss_ce: 0.038589
2022-01-15 23:50:33,380 iteration 660 : loss : 0.104449, loss_ce: 0.040886
2022-01-15 23:50:34,369 iteration 661 : loss : 0.121862, loss_ce: 0.045994
2022-01-15 23:50:35,444 iteration 662 : loss : 0.165489, loss_ce: 0.042148
2022-01-15 23:50:36,417 iteration 663 : loss : 0.114701, loss_ce: 0.050601
 10%|██▉                           | 39/400 [11:29<1:42:50, 17.09s/it]2022-01-15 23:50:37,469 iteration 664 : loss : 0.104086, loss_ce: 0.047047
2022-01-15 23:50:38,348 iteration 665 : loss : 0.088673, loss_ce: 0.041734
2022-01-15 23:50:39,296 iteration 666 : loss : 0.068456, loss_ce: 0.024284
2022-01-15 23:50:40,293 iteration 667 : loss : 0.073420, loss_ce: 0.032447
2022-01-15 23:50:41,265 iteration 668 : loss : 0.125430, loss_ce: 0.047078
2022-01-15 23:50:42,199 iteration 669 : loss : 0.106808, loss_ce: 0.034492
2022-01-15 23:50:43,296 iteration 670 : loss : 0.125351, loss_ce: 0.050454
2022-01-15 23:50:44,238 iteration 671 : loss : 0.123099, loss_ce: 0.040141
2022-01-15 23:50:45,278 iteration 672 : loss : 0.090221, loss_ce: 0.034138
2022-01-15 23:50:46,291 iteration 673 : loss : 0.093147, loss_ce: 0.037582
2022-01-15 23:50:47,286 iteration 674 : loss : 0.091186, loss_ce: 0.041005
2022-01-15 23:50:48,308 iteration 675 : loss : 0.126977, loss_ce: 0.059951
2022-01-15 23:50:49,263 iteration 676 : loss : 0.126896, loss_ce: 0.046495
2022-01-15 23:50:50,235 iteration 677 : loss : 0.080542, loss_ce: 0.036881
2022-01-15 23:50:51,237 iteration 678 : loss : 0.116023, loss_ce: 0.042428
2022-01-15 23:50:52,212 iteration 679 : loss : 0.114251, loss_ce: 0.052948
2022-01-15 23:50:52,212 Training Data Eval:
2022-01-15 23:50:56,751   Average segmentation loss on training set: 0.1339
2022-01-15 23:50:56,751 Validation Data Eval:
2022-01-15 23:50:58,240   Average segmentation loss on validation set: 0.2020
2022-01-15 23:50:59,200 iteration 680 : loss : 0.096043, loss_ce: 0.036339
 10%|███                           | 40/400 [11:52<1:52:49, 18.80s/it]2022-01-15 23:51:00,248 iteration 681 : loss : 0.078914, loss_ce: 0.028236
2022-01-15 23:51:01,126 iteration 682 : loss : 0.152327, loss_ce: 0.045851
2022-01-15 23:51:02,086 iteration 683 : loss : 0.099358, loss_ce: 0.044309
2022-01-15 23:51:03,003 iteration 684 : loss : 0.083015, loss_ce: 0.029074
2022-01-15 23:51:04,033 iteration 685 : loss : 0.091960, loss_ce: 0.035331
2022-01-15 23:51:04,993 iteration 686 : loss : 0.159933, loss_ce: 0.056687
2022-01-15 23:51:05,951 iteration 687 : loss : 0.107957, loss_ce: 0.048450
2022-01-15 23:51:06,884 iteration 688 : loss : 0.100813, loss_ce: 0.033392
2022-01-15 23:51:07,868 iteration 689 : loss : 0.088922, loss_ce: 0.045138
2022-01-15 23:51:08,822 iteration 690 : loss : 0.086159, loss_ce: 0.031958
2022-01-15 23:51:09,796 iteration 691 : loss : 0.112154, loss_ce: 0.043793
2022-01-15 23:51:10,823 iteration 692 : loss : 0.086782, loss_ce: 0.031770
2022-01-15 23:51:11,718 iteration 693 : loss : 0.093361, loss_ce: 0.041365
2022-01-15 23:51:12,686 iteration 694 : loss : 0.094392, loss_ce: 0.038163
2022-01-15 23:51:13,603 iteration 695 : loss : 0.129791, loss_ce: 0.058136
2022-01-15 23:51:14,631 iteration 696 : loss : 0.084635, loss_ce: 0.033474
2022-01-15 23:51:15,593 iteration 697 : loss : 0.092191, loss_ce: 0.035579
 10%|███                           | 41/400 [12:08<1:48:12, 18.08s/it]2022-01-15 23:51:16,583 iteration 698 : loss : 0.140900, loss_ce: 0.035455
2022-01-15 23:51:17,588 iteration 699 : loss : 0.104311, loss_ce: 0.044838
2022-01-15 23:51:18,523 iteration 700 : loss : 0.106131, loss_ce: 0.048004
2022-01-15 23:51:19,455 iteration 701 : loss : 0.145768, loss_ce: 0.071686
2022-01-15 23:51:20,455 iteration 702 : loss : 0.141136, loss_ce: 0.045034
2022-01-15 23:51:21,516 iteration 703 : loss : 0.074634, loss_ce: 0.031905
2022-01-15 23:51:22,413 iteration 704 : loss : 0.079541, loss_ce: 0.030674
2022-01-15 23:51:23,367 iteration 705 : loss : 0.089502, loss_ce: 0.033306
2022-01-15 23:51:24,343 iteration 706 : loss : 0.096575, loss_ce: 0.032807
2022-01-15 23:51:25,232 iteration 707 : loss : 0.101586, loss_ce: 0.047635
2022-01-15 23:51:26,187 iteration 708 : loss : 0.087703, loss_ce: 0.031701
2022-01-15 23:51:27,141 iteration 709 : loss : 0.132636, loss_ce: 0.053301
2022-01-15 23:51:28,135 iteration 710 : loss : 0.115118, loss_ce: 0.044953
2022-01-15 23:51:29,124 iteration 711 : loss : 0.115999, loss_ce: 0.049357
2022-01-15 23:51:30,182 iteration 712 : loss : 0.117592, loss_ce: 0.042717
2022-01-15 23:51:31,135 iteration 713 : loss : 0.082552, loss_ce: 0.032394
2022-01-15 23:51:32,170 iteration 714 : loss : 0.133045, loss_ce: 0.044002
 10%|███▏                          | 42/400 [12:25<1:45:12, 17.63s/it]2022-01-15 23:51:33,248 iteration 715 : loss : 0.089397, loss_ce: 0.029221
2022-01-15 23:51:34,266 iteration 716 : loss : 0.073441, loss_ce: 0.032468
2022-01-15 23:51:35,227 iteration 717 : loss : 0.089865, loss_ce: 0.028340
2022-01-15 23:51:36,210 iteration 718 : loss : 0.105461, loss_ce: 0.046937
2022-01-15 23:51:37,249 iteration 719 : loss : 0.095624, loss_ce: 0.034225
2022-01-15 23:51:38,219 iteration 720 : loss : 0.096813, loss_ce: 0.035989
2022-01-15 23:51:39,182 iteration 721 : loss : 0.108675, loss_ce: 0.036612
2022-01-15 23:51:40,131 iteration 722 : loss : 0.111625, loss_ce: 0.042169
2022-01-15 23:51:41,139 iteration 723 : loss : 0.104826, loss_ce: 0.050024
2022-01-15 23:51:42,074 iteration 724 : loss : 0.131467, loss_ce: 0.054420
2022-01-15 23:51:43,104 iteration 725 : loss : 0.087328, loss_ce: 0.032234
2022-01-15 23:51:44,060 iteration 726 : loss : 0.114979, loss_ce: 0.045754
2022-01-15 23:51:44,945 iteration 727 : loss : 0.109032, loss_ce: 0.043311
2022-01-15 23:51:45,941 iteration 728 : loss : 0.090149, loss_ce: 0.037874
2022-01-15 23:51:46,954 iteration 729 : loss : 0.079150, loss_ce: 0.036090
2022-01-15 23:51:47,935 iteration 730 : loss : 0.091531, loss_ce: 0.037432
2022-01-15 23:51:48,801 iteration 731 : loss : 0.060808, loss_ce: 0.019721
 11%|███▏                          | 43/400 [12:41<1:43:07, 17.33s/it]2022-01-15 23:51:49,758 iteration 732 : loss : 0.104170, loss_ce: 0.039629
2022-01-15 23:51:50,634 iteration 733 : loss : 0.107316, loss_ce: 0.052076
2022-01-15 23:51:51,639 iteration 734 : loss : 0.112100, loss_ce: 0.037202
2022-01-15 23:51:52,578 iteration 735 : loss : 0.103519, loss_ce: 0.037978
2022-01-15 23:51:53,498 iteration 736 : loss : 0.097495, loss_ce: 0.037728
2022-01-15 23:51:54,584 iteration 737 : loss : 0.110107, loss_ce: 0.040351
2022-01-15 23:51:55,451 iteration 738 : loss : 0.102091, loss_ce: 0.052826
2022-01-15 23:51:56,450 iteration 739 : loss : 0.110363, loss_ce: 0.036137
2022-01-15 23:51:57,390 iteration 740 : loss : 0.084417, loss_ce: 0.036137
2022-01-15 23:51:58,309 iteration 741 : loss : 0.102577, loss_ce: 0.040076
2022-01-15 23:51:59,179 iteration 742 : loss : 0.113438, loss_ce: 0.058695
2022-01-15 23:52:00,144 iteration 743 : loss : 0.091131, loss_ce: 0.035247
2022-01-15 23:52:01,135 iteration 744 : loss : 0.085154, loss_ce: 0.030898
2022-01-15 23:52:02,051 iteration 745 : loss : 0.133468, loss_ce: 0.027567
2022-01-15 23:52:02,976 iteration 746 : loss : 0.090309, loss_ce: 0.034556
2022-01-15 23:52:03,891 iteration 747 : loss : 0.102184, loss_ce: 0.040625
2022-01-15 23:52:04,797 iteration 748 : loss : 0.077614, loss_ce: 0.031692
 11%|███▎                          | 44/400 [12:57<1:40:27, 16.93s/it]2022-01-15 23:52:05,756 iteration 749 : loss : 0.228106, loss_ce: 0.050669
2022-01-15 23:52:06,686 iteration 750 : loss : 0.069754, loss_ce: 0.024987
2022-01-15 23:52:07,658 iteration 751 : loss : 0.080157, loss_ce: 0.025961
2022-01-15 23:52:08,590 iteration 752 : loss : 0.104641, loss_ce: 0.047309
2022-01-15 23:52:09,489 iteration 753 : loss : 0.112640, loss_ce: 0.045349
2022-01-15 23:52:10,397 iteration 754 : loss : 0.131515, loss_ce: 0.044146
2022-01-15 23:52:11,252 iteration 755 : loss : 0.132637, loss_ce: 0.064563
2022-01-15 23:52:12,119 iteration 756 : loss : 0.083776, loss_ce: 0.028103
2022-01-15 23:52:13,058 iteration 757 : loss : 0.096896, loss_ce: 0.045121
2022-01-15 23:52:14,105 iteration 758 : loss : 0.105589, loss_ce: 0.043601
2022-01-15 23:52:15,211 iteration 759 : loss : 0.119753, loss_ce: 0.046192
2022-01-15 23:52:16,144 iteration 760 : loss : 0.106729, loss_ce: 0.053702
2022-01-15 23:52:17,133 iteration 761 : loss : 0.099302, loss_ce: 0.040606
2022-01-15 23:52:18,140 iteration 762 : loss : 0.130838, loss_ce: 0.047381
2022-01-15 23:52:19,152 iteration 763 : loss : 0.098346, loss_ce: 0.044546
2022-01-15 23:52:20,077 iteration 764 : loss : 0.110945, loss_ce: 0.045096
2022-01-15 23:52:20,077 Training Data Eval:
2022-01-15 23:52:24,615   Average segmentation loss on training set: 0.1338
2022-01-15 23:52:24,616 Validation Data Eval:
2022-01-15 23:52:26,105   Average segmentation loss on validation set: 0.1403
2022-01-15 23:52:26,947 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-15 23:52:28,085 iteration 765 : loss : 0.127642, loss_ce: 0.052975
 11%|███▍                          | 45/400 [13:21<1:51:27, 18.84s/it]2022-01-15 23:52:29,171 iteration 766 : loss : 0.124345, loss_ce: 0.059748
2022-01-15 23:52:30,170 iteration 767 : loss : 0.107182, loss_ce: 0.045696
2022-01-15 23:52:31,156 iteration 768 : loss : 0.122122, loss_ce: 0.038424
2022-01-15 23:52:32,161 iteration 769 : loss : 0.090516, loss_ce: 0.036126
2022-01-15 23:52:33,035 iteration 770 : loss : 0.087580, loss_ce: 0.034289
2022-01-15 23:52:34,004 iteration 771 : loss : 0.137166, loss_ce: 0.040244
2022-01-15 23:52:34,978 iteration 772 : loss : 0.069839, loss_ce: 0.026284
2022-01-15 23:52:35,970 iteration 773 : loss : 0.113831, loss_ce: 0.028016
2022-01-15 23:52:37,052 iteration 774 : loss : 0.118966, loss_ce: 0.050422
2022-01-15 23:52:37,987 iteration 775 : loss : 0.125003, loss_ce: 0.062692
2022-01-15 23:52:38,896 iteration 776 : loss : 0.081233, loss_ce: 0.031699
2022-01-15 23:52:40,050 iteration 777 : loss : 0.106215, loss_ce: 0.044715
2022-01-15 23:52:40,933 iteration 778 : loss : 0.125997, loss_ce: 0.043560
2022-01-15 23:52:41,956 iteration 779 : loss : 0.086363, loss_ce: 0.036002
2022-01-15 23:52:42,982 iteration 780 : loss : 0.078041, loss_ce: 0.027874
2022-01-15 23:52:43,912 iteration 781 : loss : 0.089610, loss_ce: 0.041474
2022-01-15 23:52:44,781 iteration 782 : loss : 0.092120, loss_ce: 0.044552
 12%|███▍                          | 46/400 [13:37<1:47:20, 18.19s/it]2022-01-15 23:52:45,786 iteration 783 : loss : 0.131240, loss_ce: 0.066723
2022-01-15 23:52:46,704 iteration 784 : loss : 0.122196, loss_ce: 0.042211
2022-01-15 23:52:47,670 iteration 785 : loss : 0.100112, loss_ce: 0.045520
2022-01-15 23:52:48,599 iteration 786 : loss : 0.143046, loss_ce: 0.048722
2022-01-15 23:52:49,543 iteration 787 : loss : 0.101963, loss_ce: 0.041212
2022-01-15 23:52:50,564 iteration 788 : loss : 0.089460, loss_ce: 0.038499
2022-01-15 23:52:51,429 iteration 789 : loss : 0.104962, loss_ce: 0.034569
2022-01-15 23:52:52,439 iteration 790 : loss : 0.116484, loss_ce: 0.036001
2022-01-15 23:52:53,387 iteration 791 : loss : 0.085073, loss_ce: 0.031656
2022-01-15 23:52:54,275 iteration 792 : loss : 0.087854, loss_ce: 0.037690
2022-01-15 23:52:55,300 iteration 793 : loss : 0.108734, loss_ce: 0.055793
2022-01-15 23:52:56,156 iteration 794 : loss : 0.076274, loss_ce: 0.030774
2022-01-15 23:52:57,043 iteration 795 : loss : 0.089964, loss_ce: 0.034478
2022-01-15 23:52:57,932 iteration 796 : loss : 0.105057, loss_ce: 0.052991
2022-01-15 23:52:58,926 iteration 797 : loss : 0.152210, loss_ce: 0.059022
2022-01-15 23:52:59,859 iteration 798 : loss : 0.106069, loss_ce: 0.031905
2022-01-15 23:53:00,730 iteration 799 : loss : 0.075992, loss_ce: 0.033471
 12%|███▌                          | 47/400 [13:53<1:43:05, 17.52s/it]2022-01-15 23:53:01,865 iteration 800 : loss : 0.108130, loss_ce: 0.035355
2022-01-15 23:53:02,845 iteration 801 : loss : 0.083960, loss_ce: 0.036857
2022-01-15 23:53:03,800 iteration 802 : loss : 0.104821, loss_ce: 0.033972
2022-01-15 23:53:04,771 iteration 803 : loss : 0.079551, loss_ce: 0.043022
2022-01-15 23:53:05,821 iteration 804 : loss : 0.135304, loss_ce: 0.061173
2022-01-15 23:53:06,946 iteration 805 : loss : 0.081735, loss_ce: 0.028949
2022-01-15 23:53:07,881 iteration 806 : loss : 0.095431, loss_ce: 0.044117
2022-01-15 23:53:08,779 iteration 807 : loss : 0.085775, loss_ce: 0.031792
2022-01-15 23:53:09,815 iteration 808 : loss : 0.097715, loss_ce: 0.046503
2022-01-15 23:53:10,780 iteration 809 : loss : 0.092343, loss_ce: 0.035748
2022-01-15 23:53:11,698 iteration 810 : loss : 0.142275, loss_ce: 0.052492
2022-01-15 23:53:12,582 iteration 811 : loss : 0.116572, loss_ce: 0.060164
2022-01-15 23:53:13,500 iteration 812 : loss : 0.096190, loss_ce: 0.041403
2022-01-15 23:53:14,450 iteration 813 : loss : 0.145219, loss_ce: 0.048042
2022-01-15 23:53:15,529 iteration 814 : loss : 0.121506, loss_ce: 0.041891
2022-01-15 23:53:16,557 iteration 815 : loss : 0.111702, loss_ce: 0.045811
2022-01-15 23:53:17,531 iteration 816 : loss : 0.073401, loss_ce: 0.028936
 12%|███▌                          | 48/400 [14:10<1:41:31, 17.30s/it]2022-01-15 23:53:18,538 iteration 817 : loss : 0.104559, loss_ce: 0.042771
2022-01-15 23:53:19,431 iteration 818 : loss : 0.104512, loss_ce: 0.039161
2022-01-15 23:53:20,385 iteration 819 : loss : 0.091290, loss_ce: 0.028123
2022-01-15 23:53:21,262 iteration 820 : loss : 0.085339, loss_ce: 0.034750
2022-01-15 23:53:22,279 iteration 821 : loss : 0.086675, loss_ce: 0.032421
2022-01-15 23:53:23,275 iteration 822 : loss : 0.112656, loss_ce: 0.043432
2022-01-15 23:53:24,171 iteration 823 : loss : 0.061590, loss_ce: 0.024716
2022-01-15 23:53:25,063 iteration 824 : loss : 0.097849, loss_ce: 0.044731
2022-01-15 23:53:26,005 iteration 825 : loss : 0.085213, loss_ce: 0.032705
2022-01-15 23:53:26,935 iteration 826 : loss : 0.130509, loss_ce: 0.041713
2022-01-15 23:53:27,875 iteration 827 : loss : 0.137850, loss_ce: 0.049824
2022-01-15 23:53:28,818 iteration 828 : loss : 0.079116, loss_ce: 0.027744
2022-01-15 23:53:29,789 iteration 829 : loss : 0.111631, loss_ce: 0.042474
2022-01-15 23:53:30,803 iteration 830 : loss : 0.097248, loss_ce: 0.034442
2022-01-15 23:53:31,756 iteration 831 : loss : 0.113416, loss_ce: 0.047264
2022-01-15 23:53:32,687 iteration 832 : loss : 0.062344, loss_ce: 0.021758
2022-01-15 23:53:33,697 iteration 833 : loss : 0.104512, loss_ce: 0.049944
 12%|███▋                          | 49/400 [14:26<1:39:13, 16.96s/it]2022-01-15 23:53:34,709 iteration 834 : loss : 0.086850, loss_ce: 0.035246
2022-01-15 23:53:35,558 iteration 835 : loss : 0.113859, loss_ce: 0.034002
2022-01-15 23:53:36,519 iteration 836 : loss : 0.073251, loss_ce: 0.030909
2022-01-15 23:53:37,408 iteration 837 : loss : 0.082031, loss_ce: 0.044145
2022-01-15 23:53:38,274 iteration 838 : loss : 0.095879, loss_ce: 0.041091
2022-01-15 23:53:39,247 iteration 839 : loss : 0.108388, loss_ce: 0.046847
2022-01-15 23:53:40,179 iteration 840 : loss : 0.100825, loss_ce: 0.034298
2022-01-15 23:53:41,073 iteration 841 : loss : 0.100609, loss_ce: 0.041360
2022-01-15 23:53:42,004 iteration 842 : loss : 0.078961, loss_ce: 0.032479
2022-01-15 23:53:43,054 iteration 843 : loss : 0.096936, loss_ce: 0.030908
2022-01-15 23:53:43,987 iteration 844 : loss : 0.109526, loss_ce: 0.035188
2022-01-15 23:53:44,966 iteration 845 : loss : 0.104777, loss_ce: 0.040357
2022-01-15 23:53:46,052 iteration 846 : loss : 0.086375, loss_ce: 0.039375
2022-01-15 23:53:47,022 iteration 847 : loss : 0.092835, loss_ce: 0.037166
2022-01-15 23:53:47,872 iteration 848 : loss : 0.090170, loss_ce: 0.036360
2022-01-15 23:53:48,835 iteration 849 : loss : 0.095892, loss_ce: 0.037385
2022-01-15 23:53:48,835 Training Data Eval:
2022-01-15 23:53:53,359   Average segmentation loss on training set: 0.3179
2022-01-15 23:53:53,359 Validation Data Eval:
2022-01-15 23:53:54,840   Average segmentation loss on validation set: 0.4551
2022-01-15 23:53:55,832 iteration 850 : loss : 0.116350, loss_ce: 0.045085
 12%|███▊                          | 50/400 [14:48<1:48:00, 18.52s/it]2022-01-15 23:53:56,872 iteration 851 : loss : 0.072479, loss_ce: 0.030597
2022-01-15 23:53:57,801 iteration 852 : loss : 0.069129, loss_ce: 0.029280
2022-01-15 23:53:58,839 iteration 853 : loss : 0.112817, loss_ce: 0.048315
2022-01-15 23:53:59,824 iteration 854 : loss : 0.083521, loss_ce: 0.028308
2022-01-15 23:54:00,798 iteration 855 : loss : 0.068383, loss_ce: 0.030458
2022-01-15 23:54:01,794 iteration 856 : loss : 0.068376, loss_ce: 0.025785
2022-01-15 23:54:02,714 iteration 857 : loss : 0.074443, loss_ce: 0.031384
2022-01-15 23:54:03,564 iteration 858 : loss : 0.074585, loss_ce: 0.038323
2022-01-15 23:54:04,493 iteration 859 : loss : 0.077530, loss_ce: 0.029058
2022-01-15 23:54:05,379 iteration 860 : loss : 0.107753, loss_ce: 0.033369
2022-01-15 23:54:06,399 iteration 861 : loss : 0.101935, loss_ce: 0.040483
2022-01-15 23:54:07,268 iteration 862 : loss : 0.095167, loss_ce: 0.032410
2022-01-15 23:54:08,299 iteration 863 : loss : 0.113869, loss_ce: 0.048885
2022-01-15 23:54:09,289 iteration 864 : loss : 0.085742, loss_ce: 0.036167
2022-01-15 23:54:10,155 iteration 865 : loss : 0.092034, loss_ce: 0.036490
2022-01-15 23:54:11,172 iteration 866 : loss : 0.103520, loss_ce: 0.047966
2022-01-15 23:54:12,057 iteration 867 : loss : 0.053108, loss_ce: 0.018683
 13%|███▊                          | 51/400 [15:05<1:43:41, 17.83s/it]2022-01-15 23:54:13,111 iteration 868 : loss : 0.121843, loss_ce: 0.039784
2022-01-15 23:54:14,061 iteration 869 : loss : 0.091143, loss_ce: 0.041686
2022-01-15 23:54:14,911 iteration 870 : loss : 0.072044, loss_ce: 0.026365
2022-01-15 23:54:15,802 iteration 871 : loss : 0.077896, loss_ce: 0.031233
2022-01-15 23:54:16,713 iteration 872 : loss : 0.064476, loss_ce: 0.030426
2022-01-15 23:54:17,742 iteration 873 : loss : 0.078993, loss_ce: 0.025847
2022-01-15 23:54:18,600 iteration 874 : loss : 0.067028, loss_ce: 0.029177
2022-01-15 23:54:19,704 iteration 875 : loss : 0.120394, loss_ce: 0.038947
2022-01-15 23:54:20,660 iteration 876 : loss : 0.047077, loss_ce: 0.020235
2022-01-15 23:54:21,496 iteration 877 : loss : 0.051331, loss_ce: 0.019014
2022-01-15 23:54:22,491 iteration 878 : loss : 0.076823, loss_ce: 0.032997
2022-01-15 23:54:23,409 iteration 879 : loss : 0.093487, loss_ce: 0.037496
2022-01-15 23:54:24,387 iteration 880 : loss : 0.107005, loss_ce: 0.045884
2022-01-15 23:54:25,302 iteration 881 : loss : 0.109336, loss_ce: 0.053536
2022-01-15 23:54:26,292 iteration 882 : loss : 0.092145, loss_ce: 0.033233
2022-01-15 23:54:27,240 iteration 883 : loss : 0.086860, loss_ce: 0.032504
2022-01-15 23:54:28,294 iteration 884 : loss : 0.097110, loss_ce: 0.045113
 13%|███▉                          | 52/400 [15:21<1:40:38, 17.35s/it]2022-01-15 23:54:29,349 iteration 885 : loss : 0.095863, loss_ce: 0.041493
2022-01-15 23:54:30,338 iteration 886 : loss : 0.068381, loss_ce: 0.026598
2022-01-15 23:54:31,336 iteration 887 : loss : 0.118767, loss_ce: 0.055133
2022-01-15 23:54:32,292 iteration 888 : loss : 0.076504, loss_ce: 0.030910
2022-01-15 23:54:33,318 iteration 889 : loss : 0.080647, loss_ce: 0.027138
2022-01-15 23:54:34,395 iteration 890 : loss : 0.078770, loss_ce: 0.030676
2022-01-15 23:54:35,365 iteration 891 : loss : 0.062576, loss_ce: 0.022431
2022-01-15 23:54:36,324 iteration 892 : loss : 0.069301, loss_ce: 0.032906
2022-01-15 23:54:37,259 iteration 893 : loss : 0.078843, loss_ce: 0.029106
2022-01-15 23:54:38,332 iteration 894 : loss : 0.084294, loss_ce: 0.028780
2022-01-15 23:54:39,250 iteration 895 : loss : 0.129152, loss_ce: 0.032158
2022-01-15 23:54:40,275 iteration 896 : loss : 0.105262, loss_ce: 0.040294
2022-01-15 23:54:41,330 iteration 897 : loss : 0.105221, loss_ce: 0.046541
2022-01-15 23:54:42,264 iteration 898 : loss : 0.083199, loss_ce: 0.039228
2022-01-15 23:54:43,202 iteration 899 : loss : 0.077593, loss_ce: 0.034628
2022-01-15 23:54:44,094 iteration 900 : loss : 0.072183, loss_ce: 0.030387
2022-01-15 23:54:45,013 iteration 901 : loss : 0.102898, loss_ce: 0.034485
 13%|███▉                          | 53/400 [15:38<1:39:14, 17.16s/it]2022-01-15 23:54:46,063 iteration 902 : loss : 0.082067, loss_ce: 0.033666
2022-01-15 23:54:47,122 iteration 903 : loss : 0.067692, loss_ce: 0.025605
2022-01-15 23:54:48,119 iteration 904 : loss : 0.101455, loss_ce: 0.031027
2022-01-15 23:54:49,096 iteration 905 : loss : 0.081454, loss_ce: 0.029875
2022-01-15 23:54:50,047 iteration 906 : loss : 0.070567, loss_ce: 0.031393
2022-01-15 23:54:51,067 iteration 907 : loss : 0.095199, loss_ce: 0.026406
2022-01-15 23:54:51,915 iteration 908 : loss : 0.083542, loss_ce: 0.037336
2022-01-15 23:54:52,894 iteration 909 : loss : 0.102987, loss_ce: 0.040038
2022-01-15 23:54:53,769 iteration 910 : loss : 0.109745, loss_ce: 0.041834
2022-01-15 23:54:54,715 iteration 911 : loss : 0.077535, loss_ce: 0.033468
2022-01-15 23:54:55,650 iteration 912 : loss : 0.068676, loss_ce: 0.026989
2022-01-15 23:54:56,573 iteration 913 : loss : 0.082220, loss_ce: 0.026239
2022-01-15 23:54:57,512 iteration 914 : loss : 0.110813, loss_ce: 0.052753
2022-01-15 23:54:58,416 iteration 915 : loss : 0.136243, loss_ce: 0.040648
2022-01-15 23:54:59,330 iteration 916 : loss : 0.056845, loss_ce: 0.022833
2022-01-15 23:55:00,307 iteration 917 : loss : 0.109509, loss_ce: 0.041860
2022-01-15 23:55:01,304 iteration 918 : loss : 0.098333, loss_ce: 0.042132
 14%|████                          | 54/400 [15:54<1:37:26, 16.90s/it]2022-01-15 23:55:02,368 iteration 919 : loss : 0.065333, loss_ce: 0.030907
2022-01-15 23:55:03,346 iteration 920 : loss : 0.063341, loss_ce: 0.027582
2022-01-15 23:55:04,357 iteration 921 : loss : 0.109526, loss_ce: 0.041989
2022-01-15 23:55:05,377 iteration 922 : loss : 0.093558, loss_ce: 0.045057
2022-01-15 23:55:06,305 iteration 923 : loss : 0.062660, loss_ce: 0.028023
2022-01-15 23:55:07,317 iteration 924 : loss : 0.116141, loss_ce: 0.035748
2022-01-15 23:55:08,234 iteration 925 : loss : 0.060741, loss_ce: 0.020815
2022-01-15 23:55:09,246 iteration 926 : loss : 0.077368, loss_ce: 0.031477
2022-01-15 23:55:10,120 iteration 927 : loss : 0.108503, loss_ce: 0.034925
2022-01-15 23:55:11,066 iteration 928 : loss : 0.069897, loss_ce: 0.029163
2022-01-15 23:55:12,076 iteration 929 : loss : 0.112844, loss_ce: 0.041470
2022-01-15 23:55:13,053 iteration 930 : loss : 0.081246, loss_ce: 0.031634
2022-01-15 23:55:14,027 iteration 931 : loss : 0.134684, loss_ce: 0.030018
2022-01-15 23:55:14,989 iteration 932 : loss : 0.087428, loss_ce: 0.029863
2022-01-15 23:55:15,911 iteration 933 : loss : 0.106772, loss_ce: 0.044231
2022-01-15 23:55:16,860 iteration 934 : loss : 0.063489, loss_ce: 0.029225
2022-01-15 23:55:16,860 Training Data Eval:
2022-01-15 23:55:21,390   Average segmentation loss on training set: 0.2147
2022-01-15 23:55:21,390 Validation Data Eval:
2022-01-15 23:55:22,873   Average segmentation loss on validation set: 0.3842
2022-01-15 23:55:23,927 iteration 935 : loss : 0.133067, loss_ce: 0.040156
 14%|████▏                         | 55/400 [16:17<1:47:01, 18.61s/it]2022-01-15 23:55:24,913 iteration 936 : loss : 0.071399, loss_ce: 0.024660
2022-01-15 23:55:25,885 iteration 937 : loss : 0.070447, loss_ce: 0.025554
2022-01-15 23:55:26,890 iteration 938 : loss : 0.098875, loss_ce: 0.030981
2022-01-15 23:55:27,796 iteration 939 : loss : 0.085585, loss_ce: 0.033545
2022-01-15 23:55:28,771 iteration 940 : loss : 0.097069, loss_ce: 0.039421
2022-01-15 23:55:29,844 iteration 941 : loss : 0.110891, loss_ce: 0.047266
2022-01-15 23:55:30,758 iteration 942 : loss : 0.064126, loss_ce: 0.025129
2022-01-15 23:55:31,689 iteration 943 : loss : 0.070679, loss_ce: 0.031787
2022-01-15 23:55:32,588 iteration 944 : loss : 0.079360, loss_ce: 0.033584
2022-01-15 23:55:33,504 iteration 945 : loss : 0.078153, loss_ce: 0.031353
2022-01-15 23:55:34,420 iteration 946 : loss : 0.061805, loss_ce: 0.026440
2022-01-15 23:55:35,320 iteration 947 : loss : 0.108775, loss_ce: 0.036017
2022-01-15 23:55:36,218 iteration 948 : loss : 0.082953, loss_ce: 0.032290
2022-01-15 23:55:37,155 iteration 949 : loss : 0.078638, loss_ce: 0.029732
2022-01-15 23:55:38,076 iteration 950 : loss : 0.092741, loss_ce: 0.039823
2022-01-15 23:55:39,069 iteration 951 : loss : 0.084820, loss_ce: 0.049096
2022-01-15 23:55:39,964 iteration 952 : loss : 0.075668, loss_ce: 0.031764
 14%|████▏                         | 56/400 [16:33<1:42:17, 17.84s/it]2022-01-15 23:55:41,001 iteration 953 : loss : 0.071347, loss_ce: 0.024011
2022-01-15 23:55:42,005 iteration 954 : loss : 0.059627, loss_ce: 0.023979
2022-01-15 23:55:42,877 iteration 955 : loss : 0.048282, loss_ce: 0.021266
2022-01-15 23:55:43,867 iteration 956 : loss : 0.076823, loss_ce: 0.028912
2022-01-15 23:55:44,840 iteration 957 : loss : 0.083900, loss_ce: 0.029217
2022-01-15 23:55:45,820 iteration 958 : loss : 0.075576, loss_ce: 0.023890
2022-01-15 23:55:46,880 iteration 959 : loss : 0.109990, loss_ce: 0.046559
2022-01-15 23:55:48,007 iteration 960 : loss : 0.099136, loss_ce: 0.047892
2022-01-15 23:55:48,928 iteration 961 : loss : 0.137315, loss_ce: 0.034645
2022-01-15 23:55:49,810 iteration 962 : loss : 0.083934, loss_ce: 0.024233
2022-01-15 23:55:50,846 iteration 963 : loss : 0.101872, loss_ce: 0.038011
2022-01-15 23:55:51,843 iteration 964 : loss : 0.085232, loss_ce: 0.047782
2022-01-15 23:55:52,772 iteration 965 : loss : 0.064979, loss_ce: 0.029564
2022-01-15 23:55:53,730 iteration 966 : loss : 0.066705, loss_ce: 0.026646
2022-01-15 23:55:54,708 iteration 967 : loss : 0.059204, loss_ce: 0.024836
2022-01-15 23:55:55,613 iteration 968 : loss : 0.118022, loss_ce: 0.043260
2022-01-15 23:55:56,596 iteration 969 : loss : 0.061826, loss_ce: 0.026197
 14%|████▎                         | 57/400 [16:49<1:39:55, 17.48s/it]2022-01-15 23:55:57,590 iteration 970 : loss : 0.082517, loss_ce: 0.038908
2022-01-15 23:55:58,575 iteration 971 : loss : 0.107377, loss_ce: 0.032330
2022-01-15 23:55:59,463 iteration 972 : loss : 0.067686, loss_ce: 0.029562
2022-01-15 23:56:00,441 iteration 973 : loss : 0.069292, loss_ce: 0.023464
2022-01-15 23:56:01,331 iteration 974 : loss : 0.074881, loss_ce: 0.029954
2022-01-15 23:56:02,336 iteration 975 : loss : 0.095474, loss_ce: 0.026582
2022-01-15 23:56:03,264 iteration 976 : loss : 0.073064, loss_ce: 0.027344
2022-01-15 23:56:04,205 iteration 977 : loss : 0.056870, loss_ce: 0.020810
2022-01-15 23:56:05,180 iteration 978 : loss : 0.049526, loss_ce: 0.016978
2022-01-15 23:56:06,105 iteration 979 : loss : 0.113904, loss_ce: 0.062150
2022-01-15 23:56:07,033 iteration 980 : loss : 0.060536, loss_ce: 0.019798
2022-01-15 23:56:08,092 iteration 981 : loss : 0.090579, loss_ce: 0.043003
2022-01-15 23:56:09,016 iteration 982 : loss : 0.081081, loss_ce: 0.040789
2022-01-15 23:56:10,023 iteration 983 : loss : 0.132524, loss_ce: 0.036827
2022-01-15 23:56:10,888 iteration 984 : loss : 0.082093, loss_ce: 0.040196
2022-01-15 23:56:11,844 iteration 985 : loss : 0.061758, loss_ce: 0.021380
2022-01-15 23:56:12,855 iteration 986 : loss : 0.104863, loss_ce: 0.041747
 14%|████▎                         | 58/400 [17:05<1:37:33, 17.12s/it]2022-01-15 23:56:13,949 iteration 987 : loss : 0.070095, loss_ce: 0.031144
2022-01-15 23:56:14,940 iteration 988 : loss : 0.082739, loss_ce: 0.034827
2022-01-15 23:56:15,910 iteration 989 : loss : 0.069258, loss_ce: 0.029662
2022-01-15 23:56:16,865 iteration 990 : loss : 0.074430, loss_ce: 0.032639
2022-01-15 23:56:17,808 iteration 991 : loss : 0.059582, loss_ce: 0.025362
2022-01-15 23:56:18,853 iteration 992 : loss : 0.069989, loss_ce: 0.033104
2022-01-15 23:56:19,843 iteration 993 : loss : 0.064209, loss_ce: 0.022976
2022-01-15 23:56:20,930 iteration 994 : loss : 0.081567, loss_ce: 0.032996
2022-01-15 23:56:21,904 iteration 995 : loss : 0.095562, loss_ce: 0.027682
2022-01-15 23:56:22,935 iteration 996 : loss : 0.047553, loss_ce: 0.019328
2022-01-15 23:56:23,963 iteration 997 : loss : 0.112586, loss_ce: 0.043677
2022-01-15 23:56:24,869 iteration 998 : loss : 0.083081, loss_ce: 0.026735
2022-01-15 23:56:25,881 iteration 999 : loss : 0.099562, loss_ce: 0.038637
2022-01-15 23:56:26,798 iteration 1000 : loss : 0.089792, loss_ce: 0.028009
2022-01-15 23:56:27,726 iteration 1001 : loss : 0.130383, loss_ce: 0.035693
2022-01-15 23:56:28,792 iteration 1002 : loss : 0.099804, loss_ce: 0.043009
2022-01-15 23:56:29,840 iteration 1003 : loss : 0.090394, loss_ce: 0.034878
 15%|████▍                         | 59/400 [17:22<1:37:02, 17.08s/it]2022-01-15 23:56:30,873 iteration 1004 : loss : 0.107351, loss_ce: 0.043584
2022-01-15 23:56:31,819 iteration 1005 : loss : 0.078313, loss_ce: 0.032596
2022-01-15 23:56:32,876 iteration 1006 : loss : 0.095532, loss_ce: 0.036477
2022-01-15 23:56:33,791 iteration 1007 : loss : 0.072491, loss_ce: 0.037429
2022-01-15 23:56:34,693 iteration 1008 : loss : 0.141436, loss_ce: 0.055567
2022-01-15 23:56:35,602 iteration 1009 : loss : 0.123116, loss_ce: 0.042679
2022-01-15 23:56:36,516 iteration 1010 : loss : 0.088730, loss_ce: 0.036304
2022-01-15 23:56:37,535 iteration 1011 : loss : 0.077510, loss_ce: 0.033959
2022-01-15 23:56:38,478 iteration 1012 : loss : 0.061917, loss_ce: 0.023706
2022-01-15 23:56:39,370 iteration 1013 : loss : 0.056882, loss_ce: 0.019310
2022-01-15 23:56:40,339 iteration 1014 : loss : 0.102633, loss_ce: 0.043295
2022-01-15 23:56:41,220 iteration 1015 : loss : 0.071832, loss_ce: 0.026763
2022-01-15 23:56:42,191 iteration 1016 : loss : 0.096296, loss_ce: 0.041867
2022-01-15 23:56:43,044 iteration 1017 : loss : 0.057680, loss_ce: 0.020662
2022-01-15 23:56:43,894 iteration 1018 : loss : 0.072191, loss_ce: 0.033968
2022-01-15 23:56:44,829 iteration 1019 : loss : 0.072852, loss_ce: 0.028541
2022-01-15 23:56:44,829 Training Data Eval:
2022-01-15 23:56:49,356   Average segmentation loss on training set: 0.0564
2022-01-15 23:56:49,357 Validation Data Eval:
2022-01-15 23:56:50,837   Average segmentation loss on validation set: 0.1142
2022-01-15 23:56:51,702 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-15 23:56:52,592 iteration 1020 : loss : 0.060473, loss_ce: 0.020439
 15%|████▌                         | 60/400 [17:45<1:46:24, 18.78s/it]2022-01-15 23:56:53,695 iteration 1021 : loss : 0.130856, loss_ce: 0.031108
2022-01-15 23:56:54,633 iteration 1022 : loss : 0.076742, loss_ce: 0.031740
2022-01-15 23:56:55,584 iteration 1023 : loss : 0.127517, loss_ce: 0.034171
2022-01-15 23:56:56,605 iteration 1024 : loss : 0.048569, loss_ce: 0.019009
2022-01-15 23:56:57,610 iteration 1025 : loss : 0.069241, loss_ce: 0.028173
2022-01-15 23:56:58,464 iteration 1026 : loss : 0.065569, loss_ce: 0.025902
2022-01-15 23:56:59,467 iteration 1027 : loss : 0.073624, loss_ce: 0.022280
2022-01-15 23:57:00,461 iteration 1028 : loss : 0.105458, loss_ce: 0.047340
2022-01-15 23:57:01,396 iteration 1029 : loss : 0.067522, loss_ce: 0.026165
2022-01-15 23:57:02,352 iteration 1030 : loss : 0.091399, loss_ce: 0.038301
2022-01-15 23:57:03,371 iteration 1031 : loss : 0.084576, loss_ce: 0.033016
2022-01-15 23:57:04,361 iteration 1032 : loss : 0.083389, loss_ce: 0.040009
2022-01-15 23:57:05,299 iteration 1033 : loss : 0.084570, loss_ce: 0.029763
2022-01-15 23:57:06,328 iteration 1034 : loss : 0.088834, loss_ce: 0.035447
2022-01-15 23:57:07,301 iteration 1035 : loss : 0.066054, loss_ce: 0.028292
2022-01-15 23:57:08,315 iteration 1036 : loss : 0.072114, loss_ce: 0.029201
2022-01-15 23:57:09,230 iteration 1037 : loss : 0.078593, loss_ce: 0.028569
 15%|████▌                         | 61/400 [18:02<1:42:27, 18.13s/it]2022-01-15 23:57:10,272 iteration 1038 : loss : 0.060273, loss_ce: 0.022931
2022-01-15 23:57:11,232 iteration 1039 : loss : 0.067239, loss_ce: 0.032190
2022-01-15 23:57:12,236 iteration 1040 : loss : 0.106756, loss_ce: 0.051634
2022-01-15 23:57:13,218 iteration 1041 : loss : 0.078044, loss_ce: 0.032952
2022-01-15 23:57:14,205 iteration 1042 : loss : 0.059751, loss_ce: 0.024499
2022-01-15 23:57:15,172 iteration 1043 : loss : 0.108218, loss_ce: 0.031896
2022-01-15 23:57:16,164 iteration 1044 : loss : 0.059407, loss_ce: 0.021907
2022-01-15 23:57:17,023 iteration 1045 : loss : 0.060569, loss_ce: 0.026668
2022-01-15 23:57:17,922 iteration 1046 : loss : 0.093637, loss_ce: 0.027829
2022-01-15 23:57:18,929 iteration 1047 : loss : 0.096775, loss_ce: 0.035669
2022-01-15 23:57:19,889 iteration 1048 : loss : 0.089202, loss_ce: 0.025726
2022-01-15 23:57:20,854 iteration 1049 : loss : 0.095790, loss_ce: 0.032076
2022-01-15 23:57:21,869 iteration 1050 : loss : 0.082633, loss_ce: 0.027751
2022-01-15 23:57:22,822 iteration 1051 : loss : 0.090412, loss_ce: 0.037436
2022-01-15 23:57:23,778 iteration 1052 : loss : 0.085819, loss_ce: 0.031118
2022-01-15 23:57:24,654 iteration 1053 : loss : 0.081975, loss_ce: 0.025438
2022-01-15 23:57:25,685 iteration 1054 : loss : 0.081381, loss_ce: 0.039164
 16%|████▋                         | 62/400 [18:18<1:39:20, 17.63s/it]2022-01-15 23:57:26,712 iteration 1055 : loss : 0.089243, loss_ce: 0.025812
2022-01-15 23:57:27,639 iteration 1056 : loss : 0.070693, loss_ce: 0.034524
2022-01-15 23:57:28,572 iteration 1057 : loss : 0.110174, loss_ce: 0.054119
2022-01-15 23:57:29,517 iteration 1058 : loss : 0.084649, loss_ce: 0.040739
2022-01-15 23:57:30,374 iteration 1059 : loss : 0.091770, loss_ce: 0.038818
2022-01-15 23:57:31,314 iteration 1060 : loss : 0.051607, loss_ce: 0.019824
2022-01-15 23:57:32,302 iteration 1061 : loss : 0.074620, loss_ce: 0.034278
2022-01-15 23:57:33,280 iteration 1062 : loss : 0.071490, loss_ce: 0.028634
2022-01-15 23:57:34,316 iteration 1063 : loss : 0.131676, loss_ce: 0.050680
2022-01-15 23:57:35,267 iteration 1064 : loss : 0.117442, loss_ce: 0.034987
2022-01-15 23:57:36,153 iteration 1065 : loss : 0.067216, loss_ce: 0.028033
2022-01-15 23:57:37,153 iteration 1066 : loss : 0.067206, loss_ce: 0.027850
2022-01-15 23:57:38,091 iteration 1067 : loss : 0.166207, loss_ce: 0.051502
2022-01-15 23:57:39,107 iteration 1068 : loss : 0.083119, loss_ce: 0.039341
2022-01-15 23:57:40,097 iteration 1069 : loss : 0.116949, loss_ce: 0.046972
2022-01-15 23:57:41,051 iteration 1070 : loss : 0.054437, loss_ce: 0.022264
2022-01-15 23:57:41,987 iteration 1071 : loss : 0.089219, loss_ce: 0.038607
 16%|████▋                         | 63/400 [18:35<1:36:47, 17.23s/it]2022-01-15 23:57:43,124 iteration 1072 : loss : 0.057766, loss_ce: 0.019937
2022-01-15 23:57:44,061 iteration 1073 : loss : 0.095561, loss_ce: 0.020818
2022-01-15 23:57:44,997 iteration 1074 : loss : 0.088337, loss_ce: 0.037991
2022-01-15 23:57:45,985 iteration 1075 : loss : 0.074631, loss_ce: 0.027673
2022-01-15 23:57:46,879 iteration 1076 : loss : 0.050052, loss_ce: 0.017896
2022-01-15 23:57:47,815 iteration 1077 : loss : 0.064131, loss_ce: 0.021912
2022-01-15 23:57:48,840 iteration 1078 : loss : 0.140924, loss_ce: 0.077829
2022-01-15 23:57:49,753 iteration 1079 : loss : 0.055210, loss_ce: 0.020508
2022-01-15 23:57:50,651 iteration 1080 : loss : 0.058828, loss_ce: 0.025639
2022-01-15 23:57:51,637 iteration 1081 : loss : 0.076387, loss_ce: 0.027025
2022-01-15 23:57:52,619 iteration 1082 : loss : 0.075031, loss_ce: 0.038987
2022-01-15 23:57:53,633 iteration 1083 : loss : 0.101733, loss_ce: 0.046874
2022-01-15 23:57:54,565 iteration 1084 : loss : 0.082719, loss_ce: 0.041315
2022-01-15 23:57:55,603 iteration 1085 : loss : 0.072883, loss_ce: 0.026899
2022-01-15 23:57:56,536 iteration 1086 : loss : 0.072520, loss_ce: 0.030437
2022-01-15 23:57:57,489 iteration 1087 : loss : 0.077654, loss_ce: 0.033905
2022-01-15 23:57:58,510 iteration 1088 : loss : 0.071087, loss_ce: 0.030287
 16%|████▊                         | 64/400 [18:51<1:35:19, 17.02s/it]2022-01-15 23:57:59,504 iteration 1089 : loss : 0.080277, loss_ce: 0.036504
2022-01-15 23:58:00,436 iteration 1090 : loss : 0.065449, loss_ce: 0.030458
2022-01-15 23:58:01,391 iteration 1091 : loss : 0.079485, loss_ce: 0.038289
2022-01-15 23:58:02,349 iteration 1092 : loss : 0.066459, loss_ce: 0.029661
2022-01-15 23:58:03,327 iteration 1093 : loss : 0.099045, loss_ce: 0.037437
2022-01-15 23:58:04,359 iteration 1094 : loss : 0.074336, loss_ce: 0.034815
2022-01-15 23:58:05,268 iteration 1095 : loss : 0.055580, loss_ce: 0.022537
2022-01-15 23:58:06,334 iteration 1096 : loss : 0.058166, loss_ce: 0.024166
2022-01-15 23:58:07,317 iteration 1097 : loss : 0.086326, loss_ce: 0.033708
2022-01-15 23:58:08,232 iteration 1098 : loss : 0.049999, loss_ce: 0.022421
2022-01-15 23:58:09,216 iteration 1099 : loss : 0.083286, loss_ce: 0.023699
2022-01-15 23:58:10,265 iteration 1100 : loss : 0.065083, loss_ce: 0.022613
2022-01-15 23:58:11,214 iteration 1101 : loss : 0.072797, loss_ce: 0.027798
2022-01-15 23:58:12,260 iteration 1102 : loss : 0.112927, loss_ce: 0.038739
2022-01-15 23:58:13,199 iteration 1103 : loss : 0.089250, loss_ce: 0.029263
2022-01-15 23:58:14,132 iteration 1104 : loss : 0.103871, loss_ce: 0.040023
2022-01-15 23:58:14,132 Training Data Eval:
2022-01-15 23:58:18,666   Average segmentation loss on training set: 0.1121
2022-01-15 23:58:18,667 Validation Data Eval:
2022-01-15 23:58:20,157   Average segmentation loss on validation set: 0.2543
2022-01-15 23:58:21,171 iteration 1105 : loss : 0.067998, loss_ce: 0.020711
 16%|████▉                         | 65/400 [19:14<1:44:28, 18.71s/it]2022-01-15 23:58:22,111 iteration 1106 : loss : 0.088721, loss_ce: 0.030338
2022-01-15 23:58:23,038 iteration 1107 : loss : 0.099141, loss_ce: 0.048206
2022-01-15 23:58:23,998 iteration 1108 : loss : 0.113803, loss_ce: 0.029816
2022-01-15 23:58:24,888 iteration 1109 : loss : 0.055470, loss_ce: 0.022847
2022-01-15 23:58:25,855 iteration 1110 : loss : 0.081009, loss_ce: 0.033667
2022-01-15 23:58:26,785 iteration 1111 : loss : 0.074394, loss_ce: 0.032407
2022-01-15 23:58:27,718 iteration 1112 : loss : 0.064228, loss_ce: 0.026417
2022-01-15 23:58:28,634 iteration 1113 : loss : 0.081135, loss_ce: 0.028517
2022-01-15 23:58:29,649 iteration 1114 : loss : 0.077456, loss_ce: 0.036760
2022-01-15 23:58:30,744 iteration 1115 : loss : 0.059213, loss_ce: 0.026145
2022-01-15 23:58:31,758 iteration 1116 : loss : 0.096640, loss_ce: 0.030416
2022-01-15 23:58:32,852 iteration 1117 : loss : 0.054431, loss_ce: 0.019647
2022-01-15 23:58:33,865 iteration 1118 : loss : 0.086315, loss_ce: 0.028284
2022-01-15 23:58:34,791 iteration 1119 : loss : 0.055786, loss_ce: 0.024085
2022-01-15 23:58:35,705 iteration 1120 : loss : 0.075151, loss_ce: 0.022530
2022-01-15 23:58:36,680 iteration 1121 : loss : 0.082939, loss_ce: 0.022144
2022-01-15 23:58:37,642 iteration 1122 : loss : 0.090415, loss_ce: 0.038382
 16%|████▉                         | 66/400 [19:30<1:40:24, 18.04s/it]2022-01-15 23:58:38,614 iteration 1123 : loss : 0.101278, loss_ce: 0.031768
2022-01-15 23:58:39,608 iteration 1124 : loss : 0.072992, loss_ce: 0.033268
2022-01-15 23:58:40,564 iteration 1125 : loss : 0.050106, loss_ce: 0.014929
2022-01-15 23:58:41,501 iteration 1126 : loss : 0.082985, loss_ce: 0.031288
2022-01-15 23:58:42,428 iteration 1127 : loss : 0.118621, loss_ce: 0.043726
2022-01-15 23:58:43,447 iteration 1128 : loss : 0.106308, loss_ce: 0.049490
2022-01-15 23:58:44,473 iteration 1129 : loss : 0.111623, loss_ce: 0.047566
2022-01-15 23:58:45,413 iteration 1130 : loss : 0.070950, loss_ce: 0.031025
2022-01-15 23:58:46,350 iteration 1131 : loss : 0.061431, loss_ce: 0.026303
2022-01-15 23:58:47,349 iteration 1132 : loss : 0.065979, loss_ce: 0.029384
2022-01-15 23:58:48,232 iteration 1133 : loss : 0.041423, loss_ce: 0.019429
2022-01-15 23:58:49,187 iteration 1134 : loss : 0.098353, loss_ce: 0.034508
2022-01-15 23:58:50,101 iteration 1135 : loss : 0.080500, loss_ce: 0.031427
2022-01-15 23:58:51,045 iteration 1136 : loss : 0.053352, loss_ce: 0.019778
2022-01-15 23:58:51,963 iteration 1137 : loss : 0.104413, loss_ce: 0.045135
2022-01-15 23:58:52,966 iteration 1138 : loss : 0.068573, loss_ce: 0.029497
2022-01-15 23:58:53,938 iteration 1139 : loss : 0.089683, loss_ce: 0.029348
 17%|█████                         | 67/400 [19:47<1:37:13, 17.52s/it]2022-01-15 23:58:54,961 iteration 1140 : loss : 0.087860, loss_ce: 0.033910
2022-01-15 23:58:55,872 iteration 1141 : loss : 0.054388, loss_ce: 0.021281
2022-01-15 23:58:56,892 iteration 1142 : loss : 0.076880, loss_ce: 0.032669
2022-01-15 23:58:57,843 iteration 1143 : loss : 0.072913, loss_ce: 0.028524
2022-01-15 23:58:58,834 iteration 1144 : loss : 0.104893, loss_ce: 0.054718
2022-01-15 23:58:59,734 iteration 1145 : loss : 0.051411, loss_ce: 0.020193
2022-01-15 23:59:00,705 iteration 1146 : loss : 0.104212, loss_ce: 0.047336
2022-01-15 23:59:01,568 iteration 1147 : loss : 0.067334, loss_ce: 0.025336
2022-01-15 23:59:02,577 iteration 1148 : loss : 0.072956, loss_ce: 0.026829
2022-01-15 23:59:03,474 iteration 1149 : loss : 0.064091, loss_ce: 0.030626
2022-01-15 23:59:04,437 iteration 1150 : loss : 0.053824, loss_ce: 0.021715
2022-01-15 23:59:05,426 iteration 1151 : loss : 0.064085, loss_ce: 0.020222
2022-01-15 23:59:06,522 iteration 1152 : loss : 0.092340, loss_ce: 0.036619
2022-01-15 23:59:07,382 iteration 1153 : loss : 0.058011, loss_ce: 0.023386
2022-01-15 23:59:08,380 iteration 1154 : loss : 0.089414, loss_ce: 0.032902
2022-01-15 23:59:09,325 iteration 1155 : loss : 0.065245, loss_ce: 0.023911
2022-01-15 23:59:10,337 iteration 1156 : loss : 0.085389, loss_ce: 0.043274
 17%|█████                         | 68/400 [20:03<1:35:03, 17.18s/it]2022-01-15 23:59:11,335 iteration 1157 : loss : 0.101070, loss_ce: 0.030139
2022-01-15 23:59:12,308 iteration 1158 : loss : 0.060804, loss_ce: 0.022571
2022-01-15 23:59:13,350 iteration 1159 : loss : 0.046125, loss_ce: 0.015267
2022-01-15 23:59:14,437 iteration 1160 : loss : 0.108193, loss_ce: 0.040403
2022-01-15 23:59:15,467 iteration 1161 : loss : 0.053633, loss_ce: 0.023256
2022-01-15 23:59:16,459 iteration 1162 : loss : 0.051511, loss_ce: 0.019020
2022-01-15 23:59:17,393 iteration 1163 : loss : 0.068932, loss_ce: 0.033107
2022-01-15 23:59:18,341 iteration 1164 : loss : 0.089868, loss_ce: 0.034788
2022-01-15 23:59:19,292 iteration 1165 : loss : 0.070637, loss_ce: 0.030714
2022-01-15 23:59:20,330 iteration 1166 : loss : 0.063919, loss_ce: 0.022779
2022-01-15 23:59:21,249 iteration 1167 : loss : 0.066946, loss_ce: 0.031364
2022-01-15 23:59:22,183 iteration 1168 : loss : 0.067021, loss_ce: 0.028260
2022-01-15 23:59:23,102 iteration 1169 : loss : 0.057917, loss_ce: 0.023102
2022-01-15 23:59:24,024 iteration 1170 : loss : 0.072142, loss_ce: 0.027122
2022-01-15 23:59:24,997 iteration 1171 : loss : 0.064616, loss_ce: 0.020813
2022-01-15 23:59:25,963 iteration 1172 : loss : 0.060913, loss_ce: 0.025972
2022-01-15 23:59:26,952 iteration 1173 : loss : 0.090087, loss_ce: 0.030733
 17%|█████▏                        | 69/400 [20:20<1:33:49, 17.01s/it]2022-01-15 23:59:27,941 iteration 1174 : loss : 0.085413, loss_ce: 0.027669
2022-01-15 23:59:28,900 iteration 1175 : loss : 0.069544, loss_ce: 0.029639
2022-01-15 23:59:29,848 iteration 1176 : loss : 0.083267, loss_ce: 0.036337
2022-01-15 23:59:30,763 iteration 1177 : loss : 0.059369, loss_ce: 0.022981
2022-01-15 23:59:31,753 iteration 1178 : loss : 0.059637, loss_ce: 0.020897
2022-01-15 23:59:32,797 iteration 1179 : loss : 0.070939, loss_ce: 0.028892
2022-01-15 23:59:33,719 iteration 1180 : loss : 0.060801, loss_ce: 0.023733
2022-01-15 23:59:34,668 iteration 1181 : loss : 0.070737, loss_ce: 0.027781
2022-01-15 23:59:35,635 iteration 1182 : loss : 0.078487, loss_ce: 0.027848
2022-01-15 23:59:36,536 iteration 1183 : loss : 0.059646, loss_ce: 0.020651
2022-01-15 23:59:37,447 iteration 1184 : loss : 0.062852, loss_ce: 0.028777
2022-01-15 23:59:38,447 iteration 1185 : loss : 0.062508, loss_ce: 0.022872
2022-01-15 23:59:39,366 iteration 1186 : loss : 0.073152, loss_ce: 0.032162
2022-01-15 23:59:40,394 iteration 1187 : loss : 0.049494, loss_ce: 0.015680
2022-01-15 23:59:41,306 iteration 1188 : loss : 0.068777, loss_ce: 0.025959
2022-01-15 23:59:42,347 iteration 1189 : loss : 0.079710, loss_ce: 0.034329
2022-01-15 23:59:42,347 Training Data Eval:
2022-01-15 23:59:46,888   Average segmentation loss on training set: 0.0468
2022-01-15 23:59:46,889 Validation Data Eval:
2022-01-15 23:59:48,390   Average segmentation loss on validation set: 0.1029
2022-01-15 23:59:49,255 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-15 23:59:50,212 iteration 1190 : loss : 0.061636, loss_ce: 0.027701
 18%|█████▎                        | 70/400 [20:43<1:43:53, 18.89s/it]2022-01-15 23:59:51,308 iteration 1191 : loss : 0.068780, loss_ce: 0.030237
2022-01-15 23:59:52,213 iteration 1192 : loss : 0.049462, loss_ce: 0.023209
2022-01-15 23:59:53,253 iteration 1193 : loss : 0.095739, loss_ce: 0.033099
2022-01-15 23:59:54,192 iteration 1194 : loss : 0.053244, loss_ce: 0.017645
2022-01-15 23:59:55,088 iteration 1195 : loss : 0.056460, loss_ce: 0.024102
2022-01-15 23:59:55,987 iteration 1196 : loss : 0.052597, loss_ce: 0.022061
2022-01-15 23:59:56,846 iteration 1197 : loss : 0.055124, loss_ce: 0.020629
2022-01-15 23:59:57,842 iteration 1198 : loss : 0.052341, loss_ce: 0.023055
2022-01-15 23:59:58,795 iteration 1199 : loss : 0.058997, loss_ce: 0.023155
2022-01-15 23:59:59,724 iteration 1200 : loss : 0.070850, loss_ce: 0.022767
2022-01-16 00:00:00,613 iteration 1201 : loss : 0.055025, loss_ce: 0.023476
2022-01-16 00:00:01,590 iteration 1202 : loss : 0.058891, loss_ce: 0.021775
2022-01-16 00:00:02,560 iteration 1203 : loss : 0.064567, loss_ce: 0.022668
2022-01-16 00:00:03,512 iteration 1204 : loss : 0.073246, loss_ce: 0.025191
2022-01-16 00:00:04,497 iteration 1205 : loss : 0.091009, loss_ce: 0.039369
2022-01-16 00:00:05,468 iteration 1206 : loss : 0.058794, loss_ce: 0.022515
2022-01-16 00:00:06,485 iteration 1207 : loss : 0.057901, loss_ce: 0.019985
 18%|█████▎                        | 71/400 [20:59<1:39:16, 18.10s/it]2022-01-16 00:00:07,544 iteration 1208 : loss : 0.063918, loss_ce: 0.031267
2022-01-16 00:00:08,509 iteration 1209 : loss : 0.049865, loss_ce: 0.018396
2022-01-16 00:00:09,474 iteration 1210 : loss : 0.052030, loss_ce: 0.019921
2022-01-16 00:00:10,374 iteration 1211 : loss : 0.042760, loss_ce: 0.017300
2022-01-16 00:00:11,250 iteration 1212 : loss : 0.079358, loss_ce: 0.021558
2022-01-16 00:00:12,334 iteration 1213 : loss : 0.070228, loss_ce: 0.028092
2022-01-16 00:00:13,285 iteration 1214 : loss : 0.057275, loss_ce: 0.021507
2022-01-16 00:00:14,246 iteration 1215 : loss : 0.087726, loss_ce: 0.037887
2022-01-16 00:00:15,335 iteration 1216 : loss : 0.053820, loss_ce: 0.019312
2022-01-16 00:00:16,298 iteration 1217 : loss : 0.043086, loss_ce: 0.014688
2022-01-16 00:00:17,207 iteration 1218 : loss : 0.046832, loss_ce: 0.016614
2022-01-16 00:00:18,082 iteration 1219 : loss : 0.053975, loss_ce: 0.017305
2022-01-16 00:00:19,017 iteration 1220 : loss : 0.055200, loss_ce: 0.019400
2022-01-16 00:00:19,921 iteration 1221 : loss : 0.065779, loss_ce: 0.026407
2022-01-16 00:00:20,942 iteration 1222 : loss : 0.070672, loss_ce: 0.025974
2022-01-16 00:00:21,870 iteration 1223 : loss : 0.055989, loss_ce: 0.023245
2022-01-16 00:00:22,868 iteration 1224 : loss : 0.121150, loss_ce: 0.051555
 18%|█████▍                        | 72/400 [21:15<1:36:08, 17.59s/it]2022-01-16 00:00:23,853 iteration 1225 : loss : 0.050385, loss_ce: 0.019018
2022-01-16 00:00:24,845 iteration 1226 : loss : 0.083104, loss_ce: 0.037790
2022-01-16 00:00:25,742 iteration 1227 : loss : 0.058067, loss_ce: 0.023921
2022-01-16 00:00:26,681 iteration 1228 : loss : 0.062089, loss_ce: 0.023934
2022-01-16 00:00:27,554 iteration 1229 : loss : 0.075114, loss_ce: 0.023847
2022-01-16 00:00:28,453 iteration 1230 : loss : 0.076985, loss_ce: 0.034550
2022-01-16 00:00:29,439 iteration 1231 : loss : 0.057226, loss_ce: 0.027706
2022-01-16 00:00:30,341 iteration 1232 : loss : 0.080639, loss_ce: 0.037441
2022-01-16 00:00:31,254 iteration 1233 : loss : 0.050402, loss_ce: 0.021982
2022-01-16 00:00:32,241 iteration 1234 : loss : 0.058138, loss_ce: 0.025672
2022-01-16 00:00:33,223 iteration 1235 : loss : 0.078079, loss_ce: 0.024331
2022-01-16 00:00:34,123 iteration 1236 : loss : 0.065991, loss_ce: 0.024300
2022-01-16 00:00:34,974 iteration 1237 : loss : 0.091405, loss_ce: 0.035009
2022-01-16 00:00:35,977 iteration 1238 : loss : 0.055141, loss_ce: 0.021411
2022-01-16 00:00:36,867 iteration 1239 : loss : 0.062005, loss_ce: 0.029609
2022-01-16 00:00:37,768 iteration 1240 : loss : 0.055040, loss_ce: 0.023996
2022-01-16 00:00:38,665 iteration 1241 : loss : 0.066377, loss_ce: 0.031395
 18%|█████▍                        | 73/400 [21:31<1:32:54, 17.05s/it]2022-01-16 00:00:39,699 iteration 1242 : loss : 0.091596, loss_ce: 0.054202
2022-01-16 00:00:40,605 iteration 1243 : loss : 0.103351, loss_ce: 0.042924
2022-01-16 00:00:41,521 iteration 1244 : loss : 0.062638, loss_ce: 0.026511
2022-01-16 00:00:42,489 iteration 1245 : loss : 0.085421, loss_ce: 0.029991
2022-01-16 00:00:43,447 iteration 1246 : loss : 0.055986, loss_ce: 0.019155
2022-01-16 00:00:44,358 iteration 1247 : loss : 0.055610, loss_ce: 0.020188
2022-01-16 00:00:45,331 iteration 1248 : loss : 0.062190, loss_ce: 0.021763
2022-01-16 00:00:46,233 iteration 1249 : loss : 0.052083, loss_ce: 0.017258
2022-01-16 00:00:47,290 iteration 1250 : loss : 0.055447, loss_ce: 0.020716
2022-01-16 00:00:48,379 iteration 1251 : loss : 0.079458, loss_ce: 0.039185
2022-01-16 00:00:49,364 iteration 1252 : loss : 0.054977, loss_ce: 0.022155
2022-01-16 00:00:50,228 iteration 1253 : loss : 0.047615, loss_ce: 0.017554
2022-01-16 00:00:51,180 iteration 1254 : loss : 0.073446, loss_ce: 0.036681
2022-01-16 00:00:52,142 iteration 1255 : loss : 0.061255, loss_ce: 0.024564
2022-01-16 00:00:53,075 iteration 1256 : loss : 0.063495, loss_ce: 0.027073
2022-01-16 00:00:54,025 iteration 1257 : loss : 0.081746, loss_ce: 0.024350
2022-01-16 00:00:54,994 iteration 1258 : loss : 0.059447, loss_ce: 0.026477
 18%|█████▌                        | 74/400 [21:48<1:31:26, 16.83s/it]2022-01-16 00:00:55,950 iteration 1259 : loss : 0.056972, loss_ce: 0.025930
2022-01-16 00:00:56,953 iteration 1260 : loss : 0.048775, loss_ce: 0.022430
2022-01-16 00:00:57,878 iteration 1261 : loss : 0.060454, loss_ce: 0.021243
2022-01-16 00:00:58,917 iteration 1262 : loss : 0.059348, loss_ce: 0.025470
2022-01-16 00:00:59,986 iteration 1263 : loss : 0.100630, loss_ce: 0.040701
2022-01-16 00:01:00,913 iteration 1264 : loss : 0.059090, loss_ce: 0.025352
2022-01-16 00:01:01,930 iteration 1265 : loss : 0.054675, loss_ce: 0.028302
2022-01-16 00:01:02,943 iteration 1266 : loss : 0.065059, loss_ce: 0.024860
2022-01-16 00:01:03,924 iteration 1267 : loss : 0.063487, loss_ce: 0.025335
2022-01-16 00:01:04,842 iteration 1268 : loss : 0.086817, loss_ce: 0.040040
2022-01-16 00:01:05,879 iteration 1269 : loss : 0.108864, loss_ce: 0.030443
2022-01-16 00:01:06,876 iteration 1270 : loss : 0.067646, loss_ce: 0.031265
2022-01-16 00:01:07,824 iteration 1271 : loss : 0.064685, loss_ce: 0.028510
2022-01-16 00:01:08,687 iteration 1272 : loss : 0.062407, loss_ce: 0.021562
2022-01-16 00:01:09,609 iteration 1273 : loss : 0.072574, loss_ce: 0.022745
2022-01-16 00:01:10,559 iteration 1274 : loss : 0.071243, loss_ce: 0.020433
2022-01-16 00:01:10,559 Training Data Eval:
2022-01-16 00:01:15,088   Average segmentation loss on training set: 0.0714
2022-01-16 00:01:15,088 Validation Data Eval:
2022-01-16 00:01:16,583   Average segmentation loss on validation set: 0.2107
2022-01-16 00:01:17,516 iteration 1275 : loss : 0.062711, loss_ce: 0.022662
 19%|█████▋                        | 75/400 [22:10<1:40:25, 18.54s/it]2022-01-16 00:01:18,437 iteration 1276 : loss : 0.065292, loss_ce: 0.026932
2022-01-16 00:01:19,506 iteration 1277 : loss : 0.057671, loss_ce: 0.023215
2022-01-16 00:01:20,414 iteration 1278 : loss : 0.044977, loss_ce: 0.016667
2022-01-16 00:01:21,465 iteration 1279 : loss : 0.061877, loss_ce: 0.022064
2022-01-16 00:01:22,443 iteration 1280 : loss : 0.073298, loss_ce: 0.035068
2022-01-16 00:01:23,411 iteration 1281 : loss : 0.057988, loss_ce: 0.026404
2022-01-16 00:01:24,304 iteration 1282 : loss : 0.035402, loss_ce: 0.016258
2022-01-16 00:01:25,315 iteration 1283 : loss : 0.086679, loss_ce: 0.031000
2022-01-16 00:01:26,215 iteration 1284 : loss : 0.062029, loss_ce: 0.022273
2022-01-16 00:01:27,241 iteration 1285 : loss : 0.056072, loss_ce: 0.019165
2022-01-16 00:01:28,298 iteration 1286 : loss : 0.156737, loss_ce: 0.049244
2022-01-16 00:01:29,228 iteration 1287 : loss : 0.051245, loss_ce: 0.024742
2022-01-16 00:01:30,139 iteration 1288 : loss : 0.061251, loss_ce: 0.028431
2022-01-16 00:01:31,093 iteration 1289 : loss : 0.045812, loss_ce: 0.018084
2022-01-16 00:01:32,092 iteration 1290 : loss : 0.094391, loss_ce: 0.027355
2022-01-16 00:01:33,099 iteration 1291 : loss : 0.081800, loss_ce: 0.034515
2022-01-16 00:01:34,121 iteration 1292 : loss : 0.071338, loss_ce: 0.028627
 19%|█████▋                        | 76/400 [22:27<1:36:58, 17.96s/it]2022-01-16 00:01:35,173 iteration 1293 : loss : 0.050780, loss_ce: 0.016165
2022-01-16 00:01:36,163 iteration 1294 : loss : 0.077044, loss_ce: 0.026719
2022-01-16 00:01:37,206 iteration 1295 : loss : 0.115106, loss_ce: 0.033765
2022-01-16 00:01:38,194 iteration 1296 : loss : 0.091445, loss_ce: 0.031913
2022-01-16 00:01:39,107 iteration 1297 : loss : 0.054342, loss_ce: 0.027560
2022-01-16 00:01:39,990 iteration 1298 : loss : 0.044037, loss_ce: 0.017215
2022-01-16 00:01:40,955 iteration 1299 : loss : 0.069702, loss_ce: 0.030875
2022-01-16 00:01:41,901 iteration 1300 : loss : 0.071856, loss_ce: 0.023157
2022-01-16 00:01:42,889 iteration 1301 : loss : 0.042130, loss_ce: 0.015939
2022-01-16 00:01:43,812 iteration 1302 : loss : 0.062316, loss_ce: 0.025884
2022-01-16 00:01:44,743 iteration 1303 : loss : 0.059084, loss_ce: 0.024995
2022-01-16 00:01:45,710 iteration 1304 : loss : 0.059996, loss_ce: 0.023502
2022-01-16 00:01:46,661 iteration 1305 : loss : 0.065679, loss_ce: 0.026921
2022-01-16 00:01:47,662 iteration 1306 : loss : 0.080005, loss_ce: 0.026451
2022-01-16 00:01:48,661 iteration 1307 : loss : 0.073059, loss_ce: 0.039166
2022-01-16 00:01:49,632 iteration 1308 : loss : 0.075067, loss_ce: 0.020863
2022-01-16 00:01:50,518 iteration 1309 : loss : 0.063750, loss_ce: 0.022303
 19%|█████▊                        | 77/400 [22:43<1:34:10, 17.49s/it]2022-01-16 00:01:51,617 iteration 1310 : loss : 0.064111, loss_ce: 0.024779
2022-01-16 00:01:52,545 iteration 1311 : loss : 0.068783, loss_ce: 0.030659
2022-01-16 00:01:53,458 iteration 1312 : loss : 0.049168, loss_ce: 0.020179
2022-01-16 00:01:54,380 iteration 1313 : loss : 0.070707, loss_ce: 0.023893
2022-01-16 00:01:55,335 iteration 1314 : loss : 0.066033, loss_ce: 0.027956
2022-01-16 00:01:56,321 iteration 1315 : loss : 0.066786, loss_ce: 0.022754
2022-01-16 00:01:57,403 iteration 1316 : loss : 0.071673, loss_ce: 0.029345
2022-01-16 00:01:58,350 iteration 1317 : loss : 0.067423, loss_ce: 0.036703
2022-01-16 00:01:59,402 iteration 1318 : loss : 0.154411, loss_ce: 0.035948
2022-01-16 00:02:00,405 iteration 1319 : loss : 0.050167, loss_ce: 0.022735
2022-01-16 00:02:01,343 iteration 1320 : loss : 0.049274, loss_ce: 0.021410
2022-01-16 00:02:02,323 iteration 1321 : loss : 0.094744, loss_ce: 0.025785
2022-01-16 00:02:03,218 iteration 1322 : loss : 0.064915, loss_ce: 0.030774
2022-01-16 00:02:04,162 iteration 1323 : loss : 0.086670, loss_ce: 0.029277
2022-01-16 00:02:05,146 iteration 1324 : loss : 0.073115, loss_ce: 0.027460
2022-01-16 00:02:06,169 iteration 1325 : loss : 0.074043, loss_ce: 0.025898
2022-01-16 00:02:07,022 iteration 1326 : loss : 0.067095, loss_ce: 0.026369
 20%|█████▊                        | 78/400 [23:00<1:32:16, 17.19s/it]2022-01-16 00:02:08,006 iteration 1327 : loss : 0.063771, loss_ce: 0.019962
2022-01-16 00:02:08,993 iteration 1328 : loss : 0.080399, loss_ce: 0.038781
2022-01-16 00:02:09,942 iteration 1329 : loss : 0.045910, loss_ce: 0.018287
2022-01-16 00:02:10,860 iteration 1330 : loss : 0.099936, loss_ce: 0.027315
2022-01-16 00:02:11,742 iteration 1331 : loss : 0.057701, loss_ce: 0.027794
2022-01-16 00:02:12,640 iteration 1332 : loss : 0.057985, loss_ce: 0.017107
2022-01-16 00:02:13,573 iteration 1333 : loss : 0.051601, loss_ce: 0.015536
2022-01-16 00:02:14,528 iteration 1334 : loss : 0.074943, loss_ce: 0.027490
2022-01-16 00:02:15,446 iteration 1335 : loss : 0.052155, loss_ce: 0.014991
2022-01-16 00:02:16,366 iteration 1336 : loss : 0.056660, loss_ce: 0.022299
2022-01-16 00:02:17,384 iteration 1337 : loss : 0.073725, loss_ce: 0.031148
2022-01-16 00:02:18,382 iteration 1338 : loss : 0.047387, loss_ce: 0.016663
2022-01-16 00:02:19,368 iteration 1339 : loss : 0.056288, loss_ce: 0.026937
2022-01-16 00:02:20,356 iteration 1340 : loss : 0.061344, loss_ce: 0.025434
2022-01-16 00:02:21,324 iteration 1341 : loss : 0.090958, loss_ce: 0.038673
2022-01-16 00:02:22,267 iteration 1342 : loss : 0.083415, loss_ce: 0.033163
2022-01-16 00:02:23,155 iteration 1343 : loss : 0.056902, loss_ce: 0.020390
 20%|█████▉                        | 79/400 [23:16<1:30:17, 16.88s/it]2022-01-16 00:02:24,172 iteration 1344 : loss : 0.063906, loss_ce: 0.025414
2022-01-16 00:02:25,208 iteration 1345 : loss : 0.085970, loss_ce: 0.031285
2022-01-16 00:02:26,140 iteration 1346 : loss : 0.080036, loss_ce: 0.037585
2022-01-16 00:02:27,170 iteration 1347 : loss : 0.053344, loss_ce: 0.024432
2022-01-16 00:02:28,240 iteration 1348 : loss : 0.076487, loss_ce: 0.027436
2022-01-16 00:02:29,208 iteration 1349 : loss : 0.057272, loss_ce: 0.021334
2022-01-16 00:02:30,163 iteration 1350 : loss : 0.067954, loss_ce: 0.028360
2022-01-16 00:02:31,115 iteration 1351 : loss : 0.061301, loss_ce: 0.027043
2022-01-16 00:02:32,132 iteration 1352 : loss : 0.058633, loss_ce: 0.026562
2022-01-16 00:02:33,120 iteration 1353 : loss : 0.064903, loss_ce: 0.022772
2022-01-16 00:02:34,128 iteration 1354 : loss : 0.068022, loss_ce: 0.022043
2022-01-16 00:02:35,204 iteration 1355 : loss : 0.228226, loss_ce: 0.062262
2022-01-16 00:02:36,189 iteration 1356 : loss : 0.067300, loss_ce: 0.030904
2022-01-16 00:02:37,187 iteration 1357 : loss : 0.044896, loss_ce: 0.018404
2022-01-16 00:02:38,209 iteration 1358 : loss : 0.075591, loss_ce: 0.030636
2022-01-16 00:02:39,168 iteration 1359 : loss : 0.066798, loss_ce: 0.027441
2022-01-16 00:02:39,169 Training Data Eval:
2022-01-16 00:02:43,704   Average segmentation loss on training set: 0.0647
2022-01-16 00:02:43,705 Validation Data Eval:
2022-01-16 00:02:45,188   Average segmentation loss on validation set: 0.1536
2022-01-16 00:02:46,206 iteration 1360 : loss : 0.060969, loss_ce: 0.018465
 20%|██████                        | 80/400 [23:39<1:39:53, 18.73s/it]2022-01-16 00:02:47,335 iteration 1361 : loss : 0.088873, loss_ce: 0.044183
2022-01-16 00:02:48,305 iteration 1362 : loss : 0.062835, loss_ce: 0.021989
2022-01-16 00:02:49,449 iteration 1363 : loss : 0.100793, loss_ce: 0.041916
2022-01-16 00:02:50,276 iteration 1364 : loss : 0.073659, loss_ce: 0.019015
2022-01-16 00:02:51,313 iteration 1365 : loss : 0.054551, loss_ce: 0.023247
2022-01-16 00:02:52,301 iteration 1366 : loss : 0.077741, loss_ce: 0.027585
2022-01-16 00:02:53,284 iteration 1367 : loss : 0.062261, loss_ce: 0.024216
2022-01-16 00:02:54,256 iteration 1368 : loss : 0.049917, loss_ce: 0.024150
2022-01-16 00:02:55,187 iteration 1369 : loss : 0.064941, loss_ce: 0.022763
2022-01-16 00:02:56,190 iteration 1370 : loss : 0.068295, loss_ce: 0.032994
2022-01-16 00:02:57,122 iteration 1371 : loss : 0.050545, loss_ce: 0.016904
2022-01-16 00:02:58,041 iteration 1372 : loss : 0.060910, loss_ce: 0.023112
2022-01-16 00:02:58,953 iteration 1373 : loss : 0.063762, loss_ce: 0.023134
2022-01-16 00:02:59,924 iteration 1374 : loss : 0.069153, loss_ce: 0.022117
2022-01-16 00:03:00,906 iteration 1375 : loss : 0.071749, loss_ce: 0.032657
2022-01-16 00:03:01,875 iteration 1376 : loss : 0.077620, loss_ce: 0.024115
2022-01-16 00:03:02,818 iteration 1377 : loss : 0.038172, loss_ce: 0.014695
 20%|██████                        | 81/400 [23:55<1:36:12, 18.10s/it]2022-01-16 00:03:03,768 iteration 1378 : loss : 0.083603, loss_ce: 0.033274
2022-01-16 00:03:04,775 iteration 1379 : loss : 0.053359, loss_ce: 0.019848
2022-01-16 00:03:05,743 iteration 1380 : loss : 0.059923, loss_ce: 0.027102
2022-01-16 00:03:06,799 iteration 1381 : loss : 0.054454, loss_ce: 0.022400
2022-01-16 00:03:07,678 iteration 1382 : loss : 0.055248, loss_ce: 0.022140
2022-01-16 00:03:08,717 iteration 1383 : loss : 0.052089, loss_ce: 0.017422
2022-01-16 00:03:09,691 iteration 1384 : loss : 0.063284, loss_ce: 0.023048
2022-01-16 00:03:10,580 iteration 1385 : loss : 0.079510, loss_ce: 0.033456
2022-01-16 00:03:11,503 iteration 1386 : loss : 0.053602, loss_ce: 0.019868
2022-01-16 00:03:12,440 iteration 1387 : loss : 0.066444, loss_ce: 0.023038
2022-01-16 00:03:13,401 iteration 1388 : loss : 0.064924, loss_ce: 0.019188
2022-01-16 00:03:14,354 iteration 1389 : loss : 0.058678, loss_ce: 0.023325
2022-01-16 00:03:15,369 iteration 1390 : loss : 0.041405, loss_ce: 0.016205
2022-01-16 00:03:16,406 iteration 1391 : loss : 0.072410, loss_ce: 0.025351
2022-01-16 00:03:17,414 iteration 1392 : loss : 0.069921, loss_ce: 0.034698
2022-01-16 00:03:18,344 iteration 1393 : loss : 0.060490, loss_ce: 0.021701
2022-01-16 00:03:19,371 iteration 1394 : loss : 0.044929, loss_ce: 0.020538
 20%|██████▏                       | 82/400 [24:12<1:33:26, 17.63s/it]2022-01-16 00:03:20,375 iteration 1395 : loss : 0.070307, loss_ce: 0.026842
2022-01-16 00:03:21,310 iteration 1396 : loss : 0.039660, loss_ce: 0.018265
2022-01-16 00:03:22,331 iteration 1397 : loss : 0.057542, loss_ce: 0.022077
2022-01-16 00:03:23,369 iteration 1398 : loss : 0.065441, loss_ce: 0.028610
2022-01-16 00:03:24,242 iteration 1399 : loss : 0.053104, loss_ce: 0.022849
2022-01-16 00:03:25,109 iteration 1400 : loss : 0.060295, loss_ce: 0.019457
2022-01-16 00:03:26,127 iteration 1401 : loss : 0.059884, loss_ce: 0.021526
2022-01-16 00:03:27,104 iteration 1402 : loss : 0.068586, loss_ce: 0.024901
2022-01-16 00:03:28,004 iteration 1403 : loss : 0.042361, loss_ce: 0.016070
2022-01-16 00:03:28,904 iteration 1404 : loss : 0.031136, loss_ce: 0.014081
2022-01-16 00:03:29,851 iteration 1405 : loss : 0.051435, loss_ce: 0.017169
2022-01-16 00:03:30,815 iteration 1406 : loss : 0.064937, loss_ce: 0.023559
2022-01-16 00:03:31,822 iteration 1407 : loss : 0.038362, loss_ce: 0.014804
2022-01-16 00:03:32,776 iteration 1408 : loss : 0.067073, loss_ce: 0.023700
2022-01-16 00:03:33,739 iteration 1409 : loss : 0.072389, loss_ce: 0.023116
2022-01-16 00:03:34,777 iteration 1410 : loss : 0.045843, loss_ce: 0.016459
2022-01-16 00:03:35,709 iteration 1411 : loss : 0.059452, loss_ce: 0.024290
 21%|██████▏                       | 83/400 [24:28<1:31:06, 17.24s/it]2022-01-16 00:03:36,701 iteration 1412 : loss : 0.070089, loss_ce: 0.026322
2022-01-16 00:03:37,733 iteration 1413 : loss : 0.078543, loss_ce: 0.023765
2022-01-16 00:03:38,675 iteration 1414 : loss : 0.052658, loss_ce: 0.021457
2022-01-16 00:03:39,688 iteration 1415 : loss : 0.051609, loss_ce: 0.013699
2022-01-16 00:03:40,628 iteration 1416 : loss : 0.057148, loss_ce: 0.026848
2022-01-16 00:03:41,554 iteration 1417 : loss : 0.064994, loss_ce: 0.021450
2022-01-16 00:03:42,473 iteration 1418 : loss : 0.069012, loss_ce: 0.032512
2022-01-16 00:03:43,362 iteration 1419 : loss : 0.047985, loss_ce: 0.018733
2022-01-16 00:03:44,368 iteration 1420 : loss : 0.069708, loss_ce: 0.024576
2022-01-16 00:03:45,420 iteration 1421 : loss : 0.085599, loss_ce: 0.032051
2022-01-16 00:03:46,413 iteration 1422 : loss : 0.057002, loss_ce: 0.018777
2022-01-16 00:03:47,302 iteration 1423 : loss : 0.060330, loss_ce: 0.025061
2022-01-16 00:03:48,292 iteration 1424 : loss : 0.073017, loss_ce: 0.029528
2022-01-16 00:03:49,271 iteration 1425 : loss : 0.045932, loss_ce: 0.020356
2022-01-16 00:03:50,179 iteration 1426 : loss : 0.054999, loss_ce: 0.025094
2022-01-16 00:03:51,128 iteration 1427 : loss : 0.068877, loss_ce: 0.025091
2022-01-16 00:03:51,974 iteration 1428 : loss : 0.075016, loss_ce: 0.025649
 21%|██████▎                       | 84/400 [24:45<1:29:16, 16.95s/it]2022-01-16 00:03:53,074 iteration 1429 : loss : 0.058498, loss_ce: 0.026165
2022-01-16 00:03:53,986 iteration 1430 : loss : 0.149145, loss_ce: 0.033971
2022-01-16 00:03:54,938 iteration 1431 : loss : 0.062184, loss_ce: 0.031465
2022-01-16 00:03:55,915 iteration 1432 : loss : 0.059059, loss_ce: 0.025680
2022-01-16 00:03:56,935 iteration 1433 : loss : 0.059650, loss_ce: 0.018940
2022-01-16 00:03:57,868 iteration 1434 : loss : 0.056590, loss_ce: 0.025526
2022-01-16 00:03:58,853 iteration 1435 : loss : 0.068715, loss_ce: 0.023950
2022-01-16 00:03:59,852 iteration 1436 : loss : 0.062904, loss_ce: 0.027615
2022-01-16 00:04:00,861 iteration 1437 : loss : 0.062670, loss_ce: 0.020749
2022-01-16 00:04:01,834 iteration 1438 : loss : 0.058663, loss_ce: 0.026866
2022-01-16 00:04:02,855 iteration 1439 : loss : 0.050994, loss_ce: 0.020752
2022-01-16 00:04:03,856 iteration 1440 : loss : 0.046051, loss_ce: 0.021284
2022-01-16 00:04:04,804 iteration 1441 : loss : 0.046280, loss_ce: 0.021595
2022-01-16 00:04:05,775 iteration 1442 : loss : 0.062383, loss_ce: 0.029459
2022-01-16 00:04:06,768 iteration 1443 : loss : 0.077016, loss_ce: 0.033592
2022-01-16 00:04:07,736 iteration 1444 : loss : 0.143492, loss_ce: 0.046475
2022-01-16 00:04:07,736 Training Data Eval:
2022-01-16 00:04:12,253   Average segmentation loss on training set: 0.0414
2022-01-16 00:04:12,253 Validation Data Eval:
2022-01-16 00:04:13,724   Average segmentation loss on validation set: 0.1438
2022-01-16 00:04:14,679 iteration 1445 : loss : 0.055389, loss_ce: 0.019305
 21%|██████▍                       | 85/400 [25:07<1:38:02, 18.67s/it]2022-01-16 00:04:15,794 iteration 1446 : loss : 0.046734, loss_ce: 0.015618
2022-01-16 00:04:16,738 iteration 1447 : loss : 0.074184, loss_ce: 0.021976
2022-01-16 00:04:17,632 iteration 1448 : loss : 0.071296, loss_ce: 0.038573
2022-01-16 00:04:18,623 iteration 1449 : loss : 0.048815, loss_ce: 0.016529
2022-01-16 00:04:19,699 iteration 1450 : loss : 0.054081, loss_ce: 0.026141
2022-01-16 00:04:20,782 iteration 1451 : loss : 0.061169, loss_ce: 0.022929
2022-01-16 00:04:21,712 iteration 1452 : loss : 0.071409, loss_ce: 0.020143
2022-01-16 00:04:22,645 iteration 1453 : loss : 0.072319, loss_ce: 0.028694
2022-01-16 00:04:23,635 iteration 1454 : loss : 0.082609, loss_ce: 0.031637
2022-01-16 00:04:24,559 iteration 1455 : loss : 0.046804, loss_ce: 0.020503
2022-01-16 00:04:25,610 iteration 1456 : loss : 0.088363, loss_ce: 0.021024
2022-01-16 00:04:26,570 iteration 1457 : loss : 0.052535, loss_ce: 0.022503
2022-01-16 00:04:27,517 iteration 1458 : loss : 0.054093, loss_ce: 0.018220
2022-01-16 00:04:28,430 iteration 1459 : loss : 0.062075, loss_ce: 0.014599
2022-01-16 00:04:29,465 iteration 1460 : loss : 0.088215, loss_ce: 0.035159
2022-01-16 00:04:30,433 iteration 1461 : loss : 0.064953, loss_ce: 0.028012
2022-01-16 00:04:31,449 iteration 1462 : loss : 0.044945, loss_ce: 0.018774
 22%|██████▍                       | 86/400 [25:24<1:34:45, 18.11s/it]2022-01-16 00:04:32,468 iteration 1463 : loss : 0.053269, loss_ce: 0.024456
2022-01-16 00:04:33,401 iteration 1464 : loss : 0.046859, loss_ce: 0.019167
2022-01-16 00:04:34,393 iteration 1465 : loss : 0.071472, loss_ce: 0.018197
2022-01-16 00:04:35,389 iteration 1466 : loss : 0.043086, loss_ce: 0.017408
2022-01-16 00:04:36,360 iteration 1467 : loss : 0.066787, loss_ce: 0.028535
2022-01-16 00:04:37,302 iteration 1468 : loss : 0.049507, loss_ce: 0.022637
2022-01-16 00:04:38,262 iteration 1469 : loss : 0.054349, loss_ce: 0.019668
2022-01-16 00:04:39,260 iteration 1470 : loss : 0.075897, loss_ce: 0.026446
2022-01-16 00:04:40,246 iteration 1471 : loss : 0.064891, loss_ce: 0.035945
2022-01-16 00:04:41,099 iteration 1472 : loss : 0.044952, loss_ce: 0.015851
2022-01-16 00:04:42,151 iteration 1473 : loss : 0.071125, loss_ce: 0.025544
2022-01-16 00:04:43,170 iteration 1474 : loss : 0.063932, loss_ce: 0.022703
2022-01-16 00:04:44,129 iteration 1475 : loss : 0.047754, loss_ce: 0.020796
2022-01-16 00:04:45,185 iteration 1476 : loss : 0.087095, loss_ce: 0.029974
2022-01-16 00:04:46,201 iteration 1477 : loss : 0.064530, loss_ce: 0.023809
2022-01-16 00:04:47,252 iteration 1478 : loss : 0.064606, loss_ce: 0.023050
2022-01-16 00:04:48,168 iteration 1479 : loss : 0.056396, loss_ce: 0.021815
 22%|██████▌                       | 87/400 [25:41<1:32:17, 17.69s/it]2022-01-16 00:04:49,198 iteration 1480 : loss : 0.059320, loss_ce: 0.020125
2022-01-16 00:04:50,135 iteration 1481 : loss : 0.046015, loss_ce: 0.017980
2022-01-16 00:04:51,092 iteration 1482 : loss : 0.060684, loss_ce: 0.024712
2022-01-16 00:04:52,139 iteration 1483 : loss : 0.048830, loss_ce: 0.019184
2022-01-16 00:04:53,253 iteration 1484 : loss : 0.076416, loss_ce: 0.025997
2022-01-16 00:04:54,289 iteration 1485 : loss : 0.056746, loss_ce: 0.026211
2022-01-16 00:04:55,235 iteration 1486 : loss : 0.073930, loss_ce: 0.032280
2022-01-16 00:04:56,202 iteration 1487 : loss : 0.057155, loss_ce: 0.026433
2022-01-16 00:04:57,187 iteration 1488 : loss : 0.041088, loss_ce: 0.016919
2022-01-16 00:04:58,178 iteration 1489 : loss : 0.033842, loss_ce: 0.013813
2022-01-16 00:04:59,189 iteration 1490 : loss : 0.069713, loss_ce: 0.027748
2022-01-16 00:05:00,239 iteration 1491 : loss : 0.055991, loss_ce: 0.023590
2022-01-16 00:05:01,163 iteration 1492 : loss : 0.037471, loss_ce: 0.015154
2022-01-16 00:05:02,177 iteration 1493 : loss : 0.062544, loss_ce: 0.021099
2022-01-16 00:05:03,116 iteration 1494 : loss : 0.066096, loss_ce: 0.024399
2022-01-16 00:05:04,054 iteration 1495 : loss : 0.053610, loss_ce: 0.021978
2022-01-16 00:05:05,025 iteration 1496 : loss : 0.078830, loss_ce: 0.022866
 22%|██████▌                       | 88/400 [25:58<1:30:40, 17.44s/it]2022-01-16 00:05:06,001 iteration 1497 : loss : 0.059246, loss_ce: 0.026982
2022-01-16 00:05:06,929 iteration 1498 : loss : 0.055963, loss_ce: 0.016966
2022-01-16 00:05:07,932 iteration 1499 : loss : 0.061698, loss_ce: 0.029100
2022-01-16 00:05:08,820 iteration 1500 : loss : 0.060772, loss_ce: 0.019347
2022-01-16 00:05:09,761 iteration 1501 : loss : 0.068049, loss_ce: 0.022685
2022-01-16 00:05:10,758 iteration 1502 : loss : 0.060072, loss_ce: 0.021219
2022-01-16 00:05:11,702 iteration 1503 : loss : 0.034173, loss_ce: 0.014220
2022-01-16 00:05:12,642 iteration 1504 : loss : 0.047308, loss_ce: 0.014655
2022-01-16 00:05:13,538 iteration 1505 : loss : 0.043876, loss_ce: 0.014925
2022-01-16 00:05:14,488 iteration 1506 : loss : 0.047745, loss_ce: 0.017495
2022-01-16 00:05:15,442 iteration 1507 : loss : 0.070563, loss_ce: 0.021905
2022-01-16 00:05:16,362 iteration 1508 : loss : 0.078230, loss_ce: 0.037586
2022-01-16 00:05:17,307 iteration 1509 : loss : 0.074760, loss_ce: 0.024304
2022-01-16 00:05:18,213 iteration 1510 : loss : 0.037412, loss_ce: 0.014153
2022-01-16 00:05:19,186 iteration 1511 : loss : 0.054438, loss_ce: 0.022562
2022-01-16 00:05:20,099 iteration 1512 : loss : 0.047978, loss_ce: 0.018761
2022-01-16 00:05:21,076 iteration 1513 : loss : 0.041144, loss_ce: 0.018180
 22%|██████▋                       | 89/400 [26:14<1:28:13, 17.02s/it]2022-01-16 00:05:22,068 iteration 1514 : loss : 0.054988, loss_ce: 0.021012
2022-01-16 00:05:23,027 iteration 1515 : loss : 0.058214, loss_ce: 0.022165
2022-01-16 00:05:24,007 iteration 1516 : loss : 0.060381, loss_ce: 0.024652
2022-01-16 00:05:24,952 iteration 1517 : loss : 0.039756, loss_ce: 0.016547
2022-01-16 00:05:25,943 iteration 1518 : loss : 0.055862, loss_ce: 0.015043
2022-01-16 00:05:26,874 iteration 1519 : loss : 0.049027, loss_ce: 0.017563
2022-01-16 00:05:27,801 iteration 1520 : loss : 0.045417, loss_ce: 0.013760
2022-01-16 00:05:28,732 iteration 1521 : loss : 0.055149, loss_ce: 0.018469
2022-01-16 00:05:29,805 iteration 1522 : loss : 0.062064, loss_ce: 0.020084
2022-01-16 00:05:30,711 iteration 1523 : loss : 0.066476, loss_ce: 0.036086
2022-01-16 00:05:31,695 iteration 1524 : loss : 0.074781, loss_ce: 0.026942
2022-01-16 00:05:32,622 iteration 1525 : loss : 0.043985, loss_ce: 0.017660
2022-01-16 00:05:33,648 iteration 1526 : loss : 0.048644, loss_ce: 0.018557
2022-01-16 00:05:34,677 iteration 1527 : loss : 0.067288, loss_ce: 0.031137
2022-01-16 00:05:35,682 iteration 1528 : loss : 0.063851, loss_ce: 0.024535
2022-01-16 00:05:36,605 iteration 1529 : loss : 0.058397, loss_ce: 0.022867
2022-01-16 00:05:36,605 Training Data Eval:
2022-01-16 00:05:41,138   Average segmentation loss on training set: 0.0415
2022-01-16 00:05:41,138 Validation Data Eval:
2022-01-16 00:05:42,619   Average segmentation loss on validation set: 0.0932
2022-01-16 00:05:43,477 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-16 00:05:44,419 iteration 1530 : loss : 0.065139, loss_ce: 0.028787
 22%|██████▊                       | 90/400 [26:37<1:37:45, 18.92s/it]2022-01-16 00:05:45,571 iteration 1531 : loss : 0.054115, loss_ce: 0.019459
2022-01-16 00:05:46,580 iteration 1532 : loss : 0.055319, loss_ce: 0.020062
2022-01-16 00:05:47,501 iteration 1533 : loss : 0.038775, loss_ce: 0.017244
2022-01-16 00:05:48,521 iteration 1534 : loss : 0.066216, loss_ce: 0.025616
2022-01-16 00:05:49,465 iteration 1535 : loss : 0.043308, loss_ce: 0.017020
2022-01-16 00:05:50,385 iteration 1536 : loss : 0.065188, loss_ce: 0.031291
2022-01-16 00:05:51,299 iteration 1537 : loss : 0.051834, loss_ce: 0.016579
2022-01-16 00:05:52,197 iteration 1538 : loss : 0.129625, loss_ce: 0.028315
2022-01-16 00:05:53,144 iteration 1539 : loss : 0.052728, loss_ce: 0.020842
2022-01-16 00:05:54,101 iteration 1540 : loss : 0.078210, loss_ce: 0.035454
2022-01-16 00:05:54,958 iteration 1541 : loss : 0.054771, loss_ce: 0.017914
2022-01-16 00:05:55,918 iteration 1542 : loss : 0.064157, loss_ce: 0.028837
2022-01-16 00:05:56,844 iteration 1543 : loss : 0.052814, loss_ce: 0.015792
2022-01-16 00:05:57,729 iteration 1544 : loss : 0.058102, loss_ce: 0.021310
2022-01-16 00:05:58,668 iteration 1545 : loss : 0.063239, loss_ce: 0.026400
2022-01-16 00:05:59,603 iteration 1546 : loss : 0.051786, loss_ce: 0.022007
2022-01-16 00:06:00,530 iteration 1547 : loss : 0.072656, loss_ce: 0.029618
 23%|██████▊                       | 91/400 [26:53<1:33:05, 18.08s/it]2022-01-16 00:06:01,542 iteration 1548 : loss : 0.053350, loss_ce: 0.022277
2022-01-16 00:06:02,435 iteration 1549 : loss : 0.043324, loss_ce: 0.019196
2022-01-16 00:06:03,492 iteration 1550 : loss : 0.063518, loss_ce: 0.029449
2022-01-16 00:06:04,443 iteration 1551 : loss : 0.054324, loss_ce: 0.022560
2022-01-16 00:06:05,406 iteration 1552 : loss : 0.047472, loss_ce: 0.020343
2022-01-16 00:06:06,263 iteration 1553 : loss : 0.040596, loss_ce: 0.023455
2022-01-16 00:06:07,161 iteration 1554 : loss : 0.060074, loss_ce: 0.023000
2022-01-16 00:06:08,176 iteration 1555 : loss : 0.053162, loss_ce: 0.019243
2022-01-16 00:06:09,268 iteration 1556 : loss : 0.068585, loss_ce: 0.023977
2022-01-16 00:06:10,300 iteration 1557 : loss : 0.121335, loss_ce: 0.027124
2022-01-16 00:06:11,266 iteration 1558 : loss : 0.070350, loss_ce: 0.017959
2022-01-16 00:06:12,338 iteration 1559 : loss : 0.055597, loss_ce: 0.022560
2022-01-16 00:06:13,274 iteration 1560 : loss : 0.061060, loss_ce: 0.017980
2022-01-16 00:06:14,213 iteration 1561 : loss : 0.066602, loss_ce: 0.024328
2022-01-16 00:06:15,185 iteration 1562 : loss : 0.050832, loss_ce: 0.020458
2022-01-16 00:06:16,128 iteration 1563 : loss : 0.070290, loss_ce: 0.039716
2022-01-16 00:06:17,090 iteration 1564 : loss : 0.063115, loss_ce: 0.022133
 23%|██████▉                       | 92/400 [27:10<1:30:27, 17.62s/it]2022-01-16 00:06:18,140 iteration 1565 : loss : 0.042747, loss_ce: 0.016043
2022-01-16 00:06:19,081 iteration 1566 : loss : 0.062098, loss_ce: 0.025960
2022-01-16 00:06:20,078 iteration 1567 : loss : 0.084269, loss_ce: 0.022818
2022-01-16 00:06:21,152 iteration 1568 : loss : 0.078634, loss_ce: 0.034193
2022-01-16 00:06:22,085 iteration 1569 : loss : 0.059277, loss_ce: 0.025292
2022-01-16 00:06:23,062 iteration 1570 : loss : 0.050548, loss_ce: 0.021775
2022-01-16 00:06:24,006 iteration 1571 : loss : 0.042364, loss_ce: 0.018523
2022-01-16 00:06:24,958 iteration 1572 : loss : 0.064095, loss_ce: 0.028665
2022-01-16 00:06:25,925 iteration 1573 : loss : 0.064039, loss_ce: 0.020981
2022-01-16 00:06:26,896 iteration 1574 : loss : 0.042866, loss_ce: 0.020033
2022-01-16 00:06:27,885 iteration 1575 : loss : 0.058047, loss_ce: 0.024560
2022-01-16 00:06:28,826 iteration 1576 : loss : 0.044305, loss_ce: 0.014739
2022-01-16 00:06:29,732 iteration 1577 : loss : 0.072662, loss_ce: 0.021198
2022-01-16 00:06:30,586 iteration 1578 : loss : 0.042526, loss_ce: 0.017515
2022-01-16 00:06:31,529 iteration 1579 : loss : 0.041038, loss_ce: 0.014614
2022-01-16 00:06:32,507 iteration 1580 : loss : 0.052016, loss_ce: 0.014736
2022-01-16 00:06:33,484 iteration 1581 : loss : 0.040420, loss_ce: 0.015635
 23%|██████▉                       | 93/400 [27:26<1:28:17, 17.25s/it]2022-01-16 00:06:34,547 iteration 1582 : loss : 0.046980, loss_ce: 0.019869
2022-01-16 00:06:35,513 iteration 1583 : loss : 0.043206, loss_ce: 0.014049
2022-01-16 00:06:36,420 iteration 1584 : loss : 0.046138, loss_ce: 0.014827
2022-01-16 00:06:37,358 iteration 1585 : loss : 0.043280, loss_ce: 0.018126
2022-01-16 00:06:38,229 iteration 1586 : loss : 0.046931, loss_ce: 0.019612
2022-01-16 00:06:39,151 iteration 1587 : loss : 0.050223, loss_ce: 0.017351
2022-01-16 00:06:40,080 iteration 1588 : loss : 0.037027, loss_ce: 0.011022
2022-01-16 00:06:41,033 iteration 1589 : loss : 0.043454, loss_ce: 0.017570
2022-01-16 00:06:42,075 iteration 1590 : loss : 0.048668, loss_ce: 0.014854
2022-01-16 00:06:43,009 iteration 1591 : loss : 0.053590, loss_ce: 0.029433
2022-01-16 00:06:43,865 iteration 1592 : loss : 0.037530, loss_ce: 0.016407
2022-01-16 00:06:44,825 iteration 1593 : loss : 0.065063, loss_ce: 0.026218
2022-01-16 00:06:45,760 iteration 1594 : loss : 0.056989, loss_ce: 0.019227
2022-01-16 00:06:46,652 iteration 1595 : loss : 0.044869, loss_ce: 0.022529
2022-01-16 00:06:47,516 iteration 1596 : loss : 0.067685, loss_ce: 0.025359
2022-01-16 00:06:48,479 iteration 1597 : loss : 0.080376, loss_ce: 0.022063
2022-01-16 00:06:49,470 iteration 1598 : loss : 0.064804, loss_ce: 0.023462
 24%|███████                       | 94/400 [27:42<1:26:03, 16.87s/it]2022-01-16 00:06:50,532 iteration 1599 : loss : 0.053950, loss_ce: 0.024962
2022-01-16 00:06:51,465 iteration 1600 : loss : 0.043699, loss_ce: 0.020224
2022-01-16 00:06:52,458 iteration 1601 : loss : 0.054546, loss_ce: 0.020588
2022-01-16 00:06:53,430 iteration 1602 : loss : 0.080738, loss_ce: 0.022772
2022-01-16 00:06:54,371 iteration 1603 : loss : 0.054072, loss_ce: 0.022627
2022-01-16 00:06:55,299 iteration 1604 : loss : 0.060187, loss_ce: 0.015257
2022-01-16 00:06:56,235 iteration 1605 : loss : 0.094107, loss_ce: 0.039001
2022-01-16 00:06:57,197 iteration 1606 : loss : 0.046102, loss_ce: 0.019370
2022-01-16 00:06:58,141 iteration 1607 : loss : 0.056556, loss_ce: 0.020890
2022-01-16 00:06:59,183 iteration 1608 : loss : 0.077778, loss_ce: 0.032939
2022-01-16 00:07:00,117 iteration 1609 : loss : 0.040731, loss_ce: 0.015240
2022-01-16 00:07:01,172 iteration 1610 : loss : 0.061975, loss_ce: 0.022054
2022-01-16 00:07:02,222 iteration 1611 : loss : 0.051384, loss_ce: 0.025925
2022-01-16 00:07:03,285 iteration 1612 : loss : 0.039352, loss_ce: 0.016222
2022-01-16 00:07:04,251 iteration 1613 : loss : 0.056419, loss_ce: 0.018756
2022-01-16 00:07:05,279 iteration 1614 : loss : 0.057185, loss_ce: 0.025901
2022-01-16 00:07:05,279 Training Data Eval:
2022-01-16 00:07:09,798   Average segmentation loss on training set: 0.0857
2022-01-16 00:07:09,799 Validation Data Eval:
2022-01-16 00:07:11,283   Average segmentation loss on validation set: 0.1124
2022-01-16 00:07:12,289 iteration 1615 : loss : 0.085704, loss_ce: 0.031865
 24%|███████▏                      | 95/400 [28:05<1:34:50, 18.66s/it]2022-01-16 00:07:13,325 iteration 1616 : loss : 0.058177, loss_ce: 0.023996
2022-01-16 00:07:14,265 iteration 1617 : loss : 0.060366, loss_ce: 0.029162
2022-01-16 00:07:15,163 iteration 1618 : loss : 0.062325, loss_ce: 0.027075
2022-01-16 00:07:16,112 iteration 1619 : loss : 0.063715, loss_ce: 0.037391
2022-01-16 00:07:17,195 iteration 1620 : loss : 0.067279, loss_ce: 0.021782
2022-01-16 00:07:18,280 iteration 1621 : loss : 0.046337, loss_ce: 0.015150
2022-01-16 00:07:19,238 iteration 1622 : loss : 0.057093, loss_ce: 0.022163
2022-01-16 00:07:20,147 iteration 1623 : loss : 0.058540, loss_ce: 0.019576
2022-01-16 00:07:21,126 iteration 1624 : loss : 0.050498, loss_ce: 0.016922
2022-01-16 00:07:22,010 iteration 1625 : loss : 0.043209, loss_ce: 0.013962
2022-01-16 00:07:22,941 iteration 1626 : loss : 0.037794, loss_ce: 0.016216
2022-01-16 00:07:24,027 iteration 1627 : loss : 0.062032, loss_ce: 0.026670
2022-01-16 00:07:25,089 iteration 1628 : loss : 0.056487, loss_ce: 0.023130
2022-01-16 00:07:26,019 iteration 1629 : loss : 0.035379, loss_ce: 0.012405
2022-01-16 00:07:26,929 iteration 1630 : loss : 0.032061, loss_ce: 0.012043
2022-01-16 00:07:27,840 iteration 1631 : loss : 0.064692, loss_ce: 0.020149
2022-01-16 00:07:28,765 iteration 1632 : loss : 0.054268, loss_ce: 0.022018
 24%|███████▏                      | 96/400 [28:21<1:31:12, 18.00s/it]2022-01-16 00:07:29,790 iteration 1633 : loss : 0.057642, loss_ce: 0.018295
2022-01-16 00:07:30,767 iteration 1634 : loss : 0.057711, loss_ce: 0.022624
2022-01-16 00:07:31,692 iteration 1635 : loss : 0.076381, loss_ce: 0.025868
2022-01-16 00:07:32,568 iteration 1636 : loss : 0.050189, loss_ce: 0.022559
2022-01-16 00:07:33,545 iteration 1637 : loss : 0.061473, loss_ce: 0.020260
2022-01-16 00:07:34,499 iteration 1638 : loss : 0.054848, loss_ce: 0.024852
2022-01-16 00:07:35,519 iteration 1639 : loss : 0.043793, loss_ce: 0.019766
2022-01-16 00:07:36,441 iteration 1640 : loss : 0.066973, loss_ce: 0.023309
2022-01-16 00:07:37,482 iteration 1641 : loss : 0.050837, loss_ce: 0.020872
2022-01-16 00:07:38,389 iteration 1642 : loss : 0.053498, loss_ce: 0.018571
2022-01-16 00:07:39,273 iteration 1643 : loss : 0.056828, loss_ce: 0.019741
2022-01-16 00:07:40,287 iteration 1644 : loss : 0.052331, loss_ce: 0.021073
2022-01-16 00:07:41,344 iteration 1645 : loss : 0.058215, loss_ce: 0.025521
2022-01-16 00:07:42,260 iteration 1646 : loss : 0.059249, loss_ce: 0.021088
2022-01-16 00:07:43,193 iteration 1647 : loss : 0.099969, loss_ce: 0.031086
2022-01-16 00:07:44,057 iteration 1648 : loss : 0.043028, loss_ce: 0.017869
2022-01-16 00:07:44,940 iteration 1649 : loss : 0.050232, loss_ce: 0.021366
 24%|███████▎                      | 97/400 [28:38<1:28:09, 17.46s/it]2022-01-16 00:07:46,088 iteration 1650 : loss : 0.047851, loss_ce: 0.021603
2022-01-16 00:07:47,027 iteration 1651 : loss : 0.061988, loss_ce: 0.018649
2022-01-16 00:07:47,994 iteration 1652 : loss : 0.072102, loss_ce: 0.021057
2022-01-16 00:07:48,918 iteration 1653 : loss : 0.052252, loss_ce: 0.017011
2022-01-16 00:07:49,854 iteration 1654 : loss : 0.047828, loss_ce: 0.016297
2022-01-16 00:07:50,757 iteration 1655 : loss : 0.057593, loss_ce: 0.021119
2022-01-16 00:07:51,761 iteration 1656 : loss : 0.072645, loss_ce: 0.035263
2022-01-16 00:07:52,702 iteration 1657 : loss : 0.050374, loss_ce: 0.021848
2022-01-16 00:07:53,717 iteration 1658 : loss : 0.075348, loss_ce: 0.042215
2022-01-16 00:07:54,765 iteration 1659 : loss : 0.053680, loss_ce: 0.022428
2022-01-16 00:07:55,739 iteration 1660 : loss : 0.040287, loss_ce: 0.015771
2022-01-16 00:07:56,638 iteration 1661 : loss : 0.069664, loss_ce: 0.024022
2022-01-16 00:07:57,639 iteration 1662 : loss : 0.050722, loss_ce: 0.022364
2022-01-16 00:07:58,665 iteration 1663 : loss : 0.048283, loss_ce: 0.019970
2022-01-16 00:07:59,629 iteration 1664 : loss : 0.092404, loss_ce: 0.034416
2022-01-16 00:08:00,570 iteration 1665 : loss : 0.050630, loss_ce: 0.022791
2022-01-16 00:08:01,548 iteration 1666 : loss : 0.065209, loss_ce: 0.022469
 24%|███████▎                      | 98/400 [28:54<1:26:33, 17.20s/it]2022-01-16 00:08:02,510 iteration 1667 : loss : 0.047717, loss_ce: 0.023301
2022-01-16 00:08:03,549 iteration 1668 : loss : 0.065369, loss_ce: 0.020163
2022-01-16 00:08:04,548 iteration 1669 : loss : 0.052476, loss_ce: 0.017758
2022-01-16 00:08:05,425 iteration 1670 : loss : 0.045169, loss_ce: 0.014227
2022-01-16 00:08:06,321 iteration 1671 : loss : 0.045574, loss_ce: 0.021663
2022-01-16 00:08:07,344 iteration 1672 : loss : 0.065949, loss_ce: 0.024877
2022-01-16 00:08:08,345 iteration 1673 : loss : 0.046964, loss_ce: 0.014362
2022-01-16 00:08:09,410 iteration 1674 : loss : 0.069341, loss_ce: 0.026268
2022-01-16 00:08:10,342 iteration 1675 : loss : 0.068205, loss_ce: 0.020564
2022-01-16 00:08:11,367 iteration 1676 : loss : 0.065802, loss_ce: 0.027558
2022-01-16 00:08:12,351 iteration 1677 : loss : 0.072954, loss_ce: 0.024516
2022-01-16 00:08:13,356 iteration 1678 : loss : 0.058253, loss_ce: 0.031277
2022-01-16 00:08:14,298 iteration 1679 : loss : 0.095303, loss_ce: 0.051984
2022-01-16 00:08:15,290 iteration 1680 : loss : 0.053796, loss_ce: 0.026798
2022-01-16 00:08:16,234 iteration 1681 : loss : 0.051179, loss_ce: 0.020733
2022-01-16 00:08:17,194 iteration 1682 : loss : 0.066504, loss_ce: 0.028804
2022-01-16 00:08:18,117 iteration 1683 : loss : 0.054708, loss_ce: 0.025282
 25%|███████▍                      | 99/400 [29:11<1:25:20, 17.01s/it]2022-01-16 00:08:19,171 iteration 1684 : loss : 0.066655, loss_ce: 0.023741
2022-01-16 00:08:20,091 iteration 1685 : loss : 0.046053, loss_ce: 0.022457
2022-01-16 00:08:20,971 iteration 1686 : loss : 0.048404, loss_ce: 0.020122
2022-01-16 00:08:21,892 iteration 1687 : loss : 0.046963, loss_ce: 0.020245
2022-01-16 00:08:22,855 iteration 1688 : loss : 0.058270, loss_ce: 0.028915
2022-01-16 00:08:23,762 iteration 1689 : loss : 0.042560, loss_ce: 0.015745
2022-01-16 00:08:24,747 iteration 1690 : loss : 0.091935, loss_ce: 0.034513
2022-01-16 00:08:25,685 iteration 1691 : loss : 0.042607, loss_ce: 0.016730
2022-01-16 00:08:26,694 iteration 1692 : loss : 0.092088, loss_ce: 0.036186
2022-01-16 00:08:27,722 iteration 1693 : loss : 0.043907, loss_ce: 0.019876
2022-01-16 00:08:28,713 iteration 1694 : loss : 0.052125, loss_ce: 0.020810
2022-01-16 00:08:29,584 iteration 1695 : loss : 0.041275, loss_ce: 0.013544
2022-01-16 00:08:30,524 iteration 1696 : loss : 0.056188, loss_ce: 0.019044
2022-01-16 00:08:31,528 iteration 1697 : loss : 0.068940, loss_ce: 0.019729
2022-01-16 00:08:32,466 iteration 1698 : loss : 0.036045, loss_ce: 0.011423
2022-01-16 00:08:33,306 iteration 1699 : loss : 0.049590, loss_ce: 0.023410
2022-01-16 00:08:33,307 Training Data Eval:
2022-01-16 00:08:37,840   Average segmentation loss on training set: 0.0934
2022-01-16 00:08:37,840 Validation Data Eval:
2022-01-16 00:08:39,328   Average segmentation loss on validation set: 0.3022
2022-01-16 00:08:40,295 iteration 1700 : loss : 0.048632, loss_ce: 0.014282
 25%|███████▎                     | 100/400 [29:33<1:32:47, 18.56s/it]2022-01-16 00:08:41,353 iteration 1701 : loss : 0.070319, loss_ce: 0.037629
2022-01-16 00:08:42,327 iteration 1702 : loss : 0.054987, loss_ce: 0.023510
2022-01-16 00:08:43,225 iteration 1703 : loss : 0.048476, loss_ce: 0.019676
2022-01-16 00:08:44,258 iteration 1704 : loss : 0.037043, loss_ce: 0.014618
2022-01-16 00:08:45,219 iteration 1705 : loss : 0.049180, loss_ce: 0.021833
2022-01-16 00:08:46,198 iteration 1706 : loss : 0.045838, loss_ce: 0.021145
2022-01-16 00:08:47,151 iteration 1707 : loss : 0.053482, loss_ce: 0.019873
2022-01-16 00:08:48,145 iteration 1708 : loss : 0.041662, loss_ce: 0.012642
2022-01-16 00:08:49,030 iteration 1709 : loss : 0.045872, loss_ce: 0.020051
2022-01-16 00:08:49,895 iteration 1710 : loss : 0.037261, loss_ce: 0.015089
2022-01-16 00:08:50,856 iteration 1711 : loss : 0.053125, loss_ce: 0.017822
2022-01-16 00:08:51,756 iteration 1712 : loss : 0.047839, loss_ce: 0.016064
2022-01-16 00:08:52,644 iteration 1713 : loss : 0.049640, loss_ce: 0.017925
2022-01-16 00:08:53,687 iteration 1714 : loss : 0.079788, loss_ce: 0.024299
2022-01-16 00:08:54,682 iteration 1715 : loss : 0.071495, loss_ce: 0.020366
2022-01-16 00:08:55,727 iteration 1716 : loss : 0.066163, loss_ce: 0.022506
2022-01-16 00:08:56,686 iteration 1717 : loss : 0.054148, loss_ce: 0.020125
 25%|███████▎                     | 101/400 [29:49<1:29:15, 17.91s/it]2022-01-16 00:08:57,675 iteration 1718 : loss : 0.057915, loss_ce: 0.019217
2022-01-16 00:08:58,653 iteration 1719 : loss : 0.064564, loss_ce: 0.025319
2022-01-16 00:08:59,510 iteration 1720 : loss : 0.037117, loss_ce: 0.012365
2022-01-16 00:09:00,454 iteration 1721 : loss : 0.053402, loss_ce: 0.024395
2022-01-16 00:09:01,463 iteration 1722 : loss : 0.044474, loss_ce: 0.014583
2022-01-16 00:09:02,416 iteration 1723 : loss : 0.079990, loss_ce: 0.036309
2022-01-16 00:09:03,412 iteration 1724 : loss : 0.044678, loss_ce: 0.015441
2022-01-16 00:09:04,502 iteration 1725 : loss : 0.079529, loss_ce: 0.025851
2022-01-16 00:09:05,545 iteration 1726 : loss : 0.068445, loss_ce: 0.018629
2022-01-16 00:09:06,514 iteration 1727 : loss : 0.048198, loss_ce: 0.022856
2022-01-16 00:09:07,459 iteration 1728 : loss : 0.056903, loss_ce: 0.018958
2022-01-16 00:09:08,409 iteration 1729 : loss : 0.039518, loss_ce: 0.017647
2022-01-16 00:09:09,387 iteration 1730 : loss : 0.051122, loss_ce: 0.021743
2022-01-16 00:09:10,425 iteration 1731 : loss : 0.063934, loss_ce: 0.022971
2022-01-16 00:09:11,392 iteration 1732 : loss : 0.044192, loss_ce: 0.020655
2022-01-16 00:09:12,441 iteration 1733 : loss : 0.078363, loss_ce: 0.033954
2022-01-16 00:09:13,353 iteration 1734 : loss : 0.047031, loss_ce: 0.015688
 26%|███████▍                     | 102/400 [30:06<1:27:05, 17.54s/it]2022-01-16 00:09:14,331 iteration 1735 : loss : 0.077892, loss_ce: 0.027677
2022-01-16 00:09:15,273 iteration 1736 : loss : 0.046835, loss_ce: 0.019470
2022-01-16 00:09:16,231 iteration 1737 : loss : 0.056789, loss_ce: 0.020175
2022-01-16 00:09:17,154 iteration 1738 : loss : 0.057756, loss_ce: 0.020911
2022-01-16 00:09:18,214 iteration 1739 : loss : 0.056783, loss_ce: 0.023960
2022-01-16 00:09:19,221 iteration 1740 : loss : 0.056180, loss_ce: 0.019958
2022-01-16 00:09:20,169 iteration 1741 : loss : 0.046542, loss_ce: 0.018330
2022-01-16 00:09:21,248 iteration 1742 : loss : 0.048638, loss_ce: 0.022272
2022-01-16 00:09:22,193 iteration 1743 : loss : 0.058021, loss_ce: 0.019188
2022-01-16 00:09:23,183 iteration 1744 : loss : 0.042211, loss_ce: 0.016135
2022-01-16 00:09:24,306 iteration 1745 : loss : 0.058083, loss_ce: 0.027443
2022-01-16 00:09:25,259 iteration 1746 : loss : 0.039113, loss_ce: 0.013557
2022-01-16 00:09:26,195 iteration 1747 : loss : 0.046908, loss_ce: 0.020383
2022-01-16 00:09:27,161 iteration 1748 : loss : 0.037464, loss_ce: 0.014337
2022-01-16 00:09:28,119 iteration 1749 : loss : 0.043906, loss_ce: 0.015511
2022-01-16 00:09:29,024 iteration 1750 : loss : 0.040105, loss_ce: 0.017220
2022-01-16 00:09:30,087 iteration 1751 : loss : 0.054661, loss_ce: 0.019333
 26%|███████▍                     | 103/400 [30:23<1:25:36, 17.29s/it]2022-01-16 00:09:31,076 iteration 1752 : loss : 0.034787, loss_ce: 0.012952
2022-01-16 00:09:31,992 iteration 1753 : loss : 0.060061, loss_ce: 0.029273
2022-01-16 00:09:32,927 iteration 1754 : loss : 0.044125, loss_ce: 0.016260
2022-01-16 00:09:33,879 iteration 1755 : loss : 0.038020, loss_ce: 0.014983
2022-01-16 00:09:34,854 iteration 1756 : loss : 0.047168, loss_ce: 0.021216
2022-01-16 00:09:35,886 iteration 1757 : loss : 0.051097, loss_ce: 0.025885
2022-01-16 00:09:36,890 iteration 1758 : loss : 0.058300, loss_ce: 0.021883
2022-01-16 00:09:37,770 iteration 1759 : loss : 0.076498, loss_ce: 0.026165
2022-01-16 00:09:38,712 iteration 1760 : loss : 0.046842, loss_ce: 0.018118
2022-01-16 00:09:39,621 iteration 1761 : loss : 0.039288, loss_ce: 0.014277
2022-01-16 00:09:40,570 iteration 1762 : loss : 0.049790, loss_ce: 0.020175
2022-01-16 00:09:41,442 iteration 1763 : loss : 0.048153, loss_ce: 0.020878
2022-01-16 00:09:42,502 iteration 1764 : loss : 0.035364, loss_ce: 0.011440
2022-01-16 00:09:43,469 iteration 1765 : loss : 0.043921, loss_ce: 0.015959
2022-01-16 00:09:44,491 iteration 1766 : loss : 0.046210, loss_ce: 0.020246
2022-01-16 00:09:45,477 iteration 1767 : loss : 0.051414, loss_ce: 0.022887
2022-01-16 00:09:46,428 iteration 1768 : loss : 0.074664, loss_ce: 0.026124
 26%|███████▌                     | 104/400 [30:39<1:23:55, 17.01s/it]2022-01-16 00:09:47,493 iteration 1769 : loss : 0.043991, loss_ce: 0.016767
2022-01-16 00:09:48,443 iteration 1770 : loss : 0.040503, loss_ce: 0.014749
2022-01-16 00:09:49,355 iteration 1771 : loss : 0.045442, loss_ce: 0.017848
2022-01-16 00:09:50,377 iteration 1772 : loss : 0.068374, loss_ce: 0.038588
2022-01-16 00:09:51,358 iteration 1773 : loss : 0.074770, loss_ce: 0.034226
2022-01-16 00:09:52,284 iteration 1774 : loss : 0.053300, loss_ce: 0.019091
2022-01-16 00:09:53,219 iteration 1775 : loss : 0.044636, loss_ce: 0.016162
2022-01-16 00:09:54,139 iteration 1776 : loss : 0.047752, loss_ce: 0.016518
2022-01-16 00:09:55,042 iteration 1777 : loss : 0.042773, loss_ce: 0.016619
2022-01-16 00:09:56,045 iteration 1778 : loss : 0.041163, loss_ce: 0.018640
2022-01-16 00:09:57,005 iteration 1779 : loss : 0.041510, loss_ce: 0.019024
2022-01-16 00:09:57,995 iteration 1780 : loss : 0.085098, loss_ce: 0.025511
2022-01-16 00:09:58,984 iteration 1781 : loss : 0.052214, loss_ce: 0.021323
2022-01-16 00:09:59,864 iteration 1782 : loss : 0.076624, loss_ce: 0.020275
2022-01-16 00:10:00,779 iteration 1783 : loss : 0.048520, loss_ce: 0.022802
2022-01-16 00:10:01,762 iteration 1784 : loss : 0.062996, loss_ce: 0.032283
2022-01-16 00:10:01,762 Training Data Eval:
2022-01-16 00:10:06,289   Average segmentation loss on training set: 0.0408
2022-01-16 00:10:06,289 Validation Data Eval:
2022-01-16 00:10:07,766   Average segmentation loss on validation set: 0.1515
2022-01-16 00:10:08,714 iteration 1785 : loss : 0.040891, loss_ce: 0.020370
 26%|███████▌                     | 105/400 [31:01<1:31:24, 18.59s/it]2022-01-16 00:10:09,774 iteration 1786 : loss : 0.053001, loss_ce: 0.017941
2022-01-16 00:10:10,674 iteration 1787 : loss : 0.073179, loss_ce: 0.017931
2022-01-16 00:10:11,643 iteration 1788 : loss : 0.047486, loss_ce: 0.016878
2022-01-16 00:10:12,613 iteration 1789 : loss : 0.047237, loss_ce: 0.023142
2022-01-16 00:10:13,731 iteration 1790 : loss : 0.038850, loss_ce: 0.015537
2022-01-16 00:10:14,716 iteration 1791 : loss : 0.050754, loss_ce: 0.021414
2022-01-16 00:10:15,703 iteration 1792 : loss : 0.036872, loss_ce: 0.014143
2022-01-16 00:10:16,704 iteration 1793 : loss : 0.084566, loss_ce: 0.033828
2022-01-16 00:10:17,655 iteration 1794 : loss : 0.066331, loss_ce: 0.038633
2022-01-16 00:10:18,507 iteration 1795 : loss : 0.046896, loss_ce: 0.018736
2022-01-16 00:10:19,546 iteration 1796 : loss : 0.053252, loss_ce: 0.022842
2022-01-16 00:10:20,457 iteration 1797 : loss : 0.045140, loss_ce: 0.019190
2022-01-16 00:10:21,422 iteration 1798 : loss : 0.045828, loss_ce: 0.016864
2022-01-16 00:10:22,457 iteration 1799 : loss : 0.052922, loss_ce: 0.019669
2022-01-16 00:10:23,358 iteration 1800 : loss : 0.054027, loss_ce: 0.017045
2022-01-16 00:10:24,316 iteration 1801 : loss : 0.101956, loss_ce: 0.029828
2022-01-16 00:10:25,331 iteration 1802 : loss : 0.050776, loss_ce: 0.018871
 26%|███████▋                     | 106/400 [31:18<1:28:11, 18.00s/it]2022-01-16 00:10:26,403 iteration 1803 : loss : 0.058305, loss_ce: 0.022628
2022-01-16 00:10:27,293 iteration 1804 : loss : 0.056267, loss_ce: 0.020238
2022-01-16 00:10:28,385 iteration 1805 : loss : 0.053137, loss_ce: 0.018288
2022-01-16 00:10:29,441 iteration 1806 : loss : 0.071387, loss_ce: 0.038143
2022-01-16 00:10:30,398 iteration 1807 : loss : 0.046809, loss_ce: 0.019945
2022-01-16 00:10:31,409 iteration 1808 : loss : 0.046518, loss_ce: 0.018734
2022-01-16 00:10:32,350 iteration 1809 : loss : 0.051992, loss_ce: 0.022209
2022-01-16 00:10:33,345 iteration 1810 : loss : 0.064070, loss_ce: 0.031368
2022-01-16 00:10:34,284 iteration 1811 : loss : 0.059355, loss_ce: 0.020607
2022-01-16 00:10:35,218 iteration 1812 : loss : 0.052286, loss_ce: 0.017325
2022-01-16 00:10:36,181 iteration 1813 : loss : 0.043762, loss_ce: 0.020455
2022-01-16 00:10:37,117 iteration 1814 : loss : 0.063246, loss_ce: 0.023668
2022-01-16 00:10:38,162 iteration 1815 : loss : 0.067445, loss_ce: 0.024381
2022-01-16 00:10:39,140 iteration 1816 : loss : 0.040936, loss_ce: 0.016062
2022-01-16 00:10:40,181 iteration 1817 : loss : 0.072488, loss_ce: 0.027292
2022-01-16 00:10:41,086 iteration 1818 : loss : 0.036032, loss_ce: 0.012315
2022-01-16 00:10:42,102 iteration 1819 : loss : 0.073798, loss_ce: 0.031461
 27%|███████▊                     | 107/400 [31:35<1:26:06, 17.63s/it]2022-01-16 00:10:43,016 iteration 1820 : loss : 0.041745, loss_ce: 0.017301
2022-01-16 00:10:44,097 iteration 1821 : loss : 0.055814, loss_ce: 0.019464
2022-01-16 00:10:45,115 iteration 1822 : loss : 0.068720, loss_ce: 0.032586
2022-01-16 00:10:46,164 iteration 1823 : loss : 0.045652, loss_ce: 0.018171
2022-01-16 00:10:47,165 iteration 1824 : loss : 0.064263, loss_ce: 0.017976
2022-01-16 00:10:48,080 iteration 1825 : loss : 0.051796, loss_ce: 0.020181
2022-01-16 00:10:49,117 iteration 1826 : loss : 0.058819, loss_ce: 0.020499
2022-01-16 00:10:50,030 iteration 1827 : loss : 0.037498, loss_ce: 0.013358
2022-01-16 00:10:51,002 iteration 1828 : loss : 0.039790, loss_ce: 0.014113
2022-01-16 00:10:51,925 iteration 1829 : loss : 0.057420, loss_ce: 0.026345
2022-01-16 00:10:52,982 iteration 1830 : loss : 0.055503, loss_ce: 0.020650
2022-01-16 00:10:53,965 iteration 1831 : loss : 0.047256, loss_ce: 0.019477
2022-01-16 00:10:54,901 iteration 1832 : loss : 0.057039, loss_ce: 0.024027
2022-01-16 00:10:55,801 iteration 1833 : loss : 0.044251, loss_ce: 0.019154
2022-01-16 00:10:56,755 iteration 1834 : loss : 0.050606, loss_ce: 0.020043
2022-01-16 00:10:57,719 iteration 1835 : loss : 0.039609, loss_ce: 0.016395
2022-01-16 00:10:58,641 iteration 1836 : loss : 0.073840, loss_ce: 0.023607
 27%|███████▊                     | 108/400 [31:51<1:24:12, 17.30s/it]2022-01-16 00:10:59,708 iteration 1837 : loss : 0.043723, loss_ce: 0.016082
2022-01-16 00:11:00,584 iteration 1838 : loss : 0.041489, loss_ce: 0.017740
2022-01-16 00:11:01,497 iteration 1839 : loss : 0.055017, loss_ce: 0.021598
2022-01-16 00:11:02,475 iteration 1840 : loss : 0.044879, loss_ce: 0.020300
2022-01-16 00:11:03,369 iteration 1841 : loss : 0.045980, loss_ce: 0.016766
2022-01-16 00:11:04,306 iteration 1842 : loss : 0.031701, loss_ce: 0.009619
2022-01-16 00:11:05,289 iteration 1843 : loss : 0.057495, loss_ce: 0.028345
2022-01-16 00:11:06,234 iteration 1844 : loss : 0.050059, loss_ce: 0.017937
2022-01-16 00:11:07,162 iteration 1845 : loss : 0.028659, loss_ce: 0.008833
2022-01-16 00:11:08,202 iteration 1846 : loss : 0.043602, loss_ce: 0.019223
2022-01-16 00:11:09,119 iteration 1847 : loss : 0.039075, loss_ce: 0.013982
2022-01-16 00:11:10,065 iteration 1848 : loss : 0.058288, loss_ce: 0.024144
2022-01-16 00:11:10,986 iteration 1849 : loss : 0.056277, loss_ce: 0.024739
2022-01-16 00:11:12,081 iteration 1850 : loss : 0.071294, loss_ce: 0.029376
2022-01-16 00:11:13,043 iteration 1851 : loss : 0.071103, loss_ce: 0.022308
2022-01-16 00:11:14,020 iteration 1852 : loss : 0.042907, loss_ce: 0.017065
2022-01-16 00:11:14,945 iteration 1853 : loss : 0.038125, loss_ce: 0.016350
 27%|███████▉                     | 109/400 [32:08<1:22:28, 17.01s/it]2022-01-16 00:11:15,941 iteration 1854 : loss : 0.042376, loss_ce: 0.015970
2022-01-16 00:11:16,955 iteration 1855 : loss : 0.047156, loss_ce: 0.018928
2022-01-16 00:11:17,976 iteration 1856 : loss : 0.052162, loss_ce: 0.017153
2022-01-16 00:11:19,011 iteration 1857 : loss : 0.043440, loss_ce: 0.017585
2022-01-16 00:11:19,992 iteration 1858 : loss : 0.044397, loss_ce: 0.017833
2022-01-16 00:11:20,977 iteration 1859 : loss : 0.047553, loss_ce: 0.019098
2022-01-16 00:11:21,895 iteration 1860 : loss : 0.050847, loss_ce: 0.016242
2022-01-16 00:11:22,921 iteration 1861 : loss : 0.037482, loss_ce: 0.013092
2022-01-16 00:11:23,829 iteration 1862 : loss : 0.039319, loss_ce: 0.017390
2022-01-16 00:11:24,789 iteration 1863 : loss : 0.056194, loss_ce: 0.022227
2022-01-16 00:11:25,788 iteration 1864 : loss : 0.083409, loss_ce: 0.018237
2022-01-16 00:11:26,649 iteration 1865 : loss : 0.039356, loss_ce: 0.017483
2022-01-16 00:11:27,683 iteration 1866 : loss : 0.036379, loss_ce: 0.017031
2022-01-16 00:11:28,647 iteration 1867 : loss : 0.035722, loss_ce: 0.016361
2022-01-16 00:11:29,568 iteration 1868 : loss : 0.048340, loss_ce: 0.022163
2022-01-16 00:11:30,482 iteration 1869 : loss : 0.078617, loss_ce: 0.026662
2022-01-16 00:11:30,482 Training Data Eval:
2022-01-16 00:11:35,027   Average segmentation loss on training set: 0.0449
2022-01-16 00:11:35,027 Validation Data Eval:
2022-01-16 00:11:36,522   Average segmentation loss on validation set: 0.0967
2022-01-16 00:11:37,519 iteration 1870 : loss : 0.047752, loss_ce: 0.017083
 28%|███████▉                     | 110/400 [32:30<1:30:16, 18.68s/it]2022-01-16 00:11:38,597 iteration 1871 : loss : 0.047239, loss_ce: 0.018329
2022-01-16 00:11:39,674 iteration 1872 : loss : 0.088705, loss_ce: 0.020974
2022-01-16 00:11:40,578 iteration 1873 : loss : 0.056883, loss_ce: 0.021893
2022-01-16 00:11:41,615 iteration 1874 : loss : 0.060314, loss_ce: 0.031580
2022-01-16 00:11:42,481 iteration 1875 : loss : 0.064708, loss_ce: 0.022860
2022-01-16 00:11:43,524 iteration 1876 : loss : 0.040934, loss_ce: 0.012351
2022-01-16 00:11:44,536 iteration 1877 : loss : 0.084760, loss_ce: 0.033180
2022-01-16 00:11:45,473 iteration 1878 : loss : 0.067927, loss_ce: 0.023363
2022-01-16 00:11:46,396 iteration 1879 : loss : 0.056531, loss_ce: 0.017700
2022-01-16 00:11:47,313 iteration 1880 : loss : 0.070710, loss_ce: 0.030534
2022-01-16 00:11:48,271 iteration 1881 : loss : 0.052916, loss_ce: 0.017465
2022-01-16 00:11:49,176 iteration 1882 : loss : 0.051418, loss_ce: 0.019289
2022-01-16 00:11:50,046 iteration 1883 : loss : 0.062619, loss_ce: 0.021571
2022-01-16 00:11:51,046 iteration 1884 : loss : 0.054474, loss_ce: 0.020696
2022-01-16 00:11:51,910 iteration 1885 : loss : 0.036139, loss_ce: 0.014300
2022-01-16 00:11:52,957 iteration 1886 : loss : 0.041936, loss_ce: 0.017876
2022-01-16 00:11:53,997 iteration 1887 : loss : 0.053401, loss_ce: 0.024968
 28%|████████                     | 111/400 [32:47<1:26:46, 18.01s/it]2022-01-16 00:11:55,006 iteration 1888 : loss : 0.052011, loss_ce: 0.021813
2022-01-16 00:11:56,033 iteration 1889 : loss : 0.066638, loss_ce: 0.024325
2022-01-16 00:11:57,036 iteration 1890 : loss : 0.056773, loss_ce: 0.019381
2022-01-16 00:11:58,054 iteration 1891 : loss : 0.054367, loss_ce: 0.018963
2022-01-16 00:11:59,032 iteration 1892 : loss : 0.038069, loss_ce: 0.016859
2022-01-16 00:12:00,019 iteration 1893 : loss : 0.050547, loss_ce: 0.026668
2022-01-16 00:12:00,972 iteration 1894 : loss : 0.054954, loss_ce: 0.026513
2022-01-16 00:12:01,916 iteration 1895 : loss : 0.043409, loss_ce: 0.015222
2022-01-16 00:12:03,016 iteration 1896 : loss : 0.080180, loss_ce: 0.043120
2022-01-16 00:12:03,961 iteration 1897 : loss : 0.064129, loss_ce: 0.019176
2022-01-16 00:12:04,989 iteration 1898 : loss : 0.044309, loss_ce: 0.017729
2022-01-16 00:12:05,947 iteration 1899 : loss : 0.061459, loss_ce: 0.028150
2022-01-16 00:12:06,823 iteration 1900 : loss : 0.037551, loss_ce: 0.015387
2022-01-16 00:12:07,779 iteration 1901 : loss : 0.043491, loss_ce: 0.015551
2022-01-16 00:12:08,772 iteration 1902 : loss : 0.044991, loss_ce: 0.019157
2022-01-16 00:12:09,791 iteration 1903 : loss : 0.056069, loss_ce: 0.018282
2022-01-16 00:12:10,868 iteration 1904 : loss : 0.047939, loss_ce: 0.017887
 28%|████████                     | 112/400 [33:03<1:24:48, 17.67s/it]2022-01-16 00:12:11,832 iteration 1905 : loss : 0.044616, loss_ce: 0.017207
2022-01-16 00:12:12,862 iteration 1906 : loss : 0.049872, loss_ce: 0.020447
2022-01-16 00:12:13,950 iteration 1907 : loss : 0.045024, loss_ce: 0.016522
2022-01-16 00:12:14,963 iteration 1908 : loss : 0.060712, loss_ce: 0.023564
2022-01-16 00:12:16,003 iteration 1909 : loss : 0.044762, loss_ce: 0.022571
2022-01-16 00:12:17,026 iteration 1910 : loss : 0.038721, loss_ce: 0.018657
2022-01-16 00:12:18,127 iteration 1911 : loss : 0.038239, loss_ce: 0.012679
2022-01-16 00:12:19,148 iteration 1912 : loss : 0.049853, loss_ce: 0.012493
2022-01-16 00:12:20,108 iteration 1913 : loss : 0.039770, loss_ce: 0.015297
2022-01-16 00:12:21,031 iteration 1914 : loss : 0.039253, loss_ce: 0.018351
2022-01-16 00:12:22,000 iteration 1915 : loss : 0.049844, loss_ce: 0.015886
2022-01-16 00:12:22,966 iteration 1916 : loss : 0.040227, loss_ce: 0.015743
2022-01-16 00:12:23,965 iteration 1917 : loss : 0.054982, loss_ce: 0.022886
2022-01-16 00:12:24,884 iteration 1918 : loss : 0.052170, loss_ce: 0.019832
2022-01-16 00:12:25,832 iteration 1919 : loss : 0.042742, loss_ce: 0.019462
2022-01-16 00:12:26,786 iteration 1920 : loss : 0.044061, loss_ce: 0.015471
2022-01-16 00:12:27,792 iteration 1921 : loss : 0.047016, loss_ce: 0.016961
 28%|████████▏                    | 113/400 [33:20<1:23:27, 17.45s/it]2022-01-16 00:12:28,764 iteration 1922 : loss : 0.045980, loss_ce: 0.018725
2022-01-16 00:12:29,645 iteration 1923 : loss : 0.030167, loss_ce: 0.013315
2022-01-16 00:12:30,633 iteration 1924 : loss : 0.063725, loss_ce: 0.030978
2022-01-16 00:12:31,539 iteration 1925 : loss : 0.047670, loss_ce: 0.020246
2022-01-16 00:12:32,462 iteration 1926 : loss : 0.034793, loss_ce: 0.014049
2022-01-16 00:12:33,470 iteration 1927 : loss : 0.061146, loss_ce: 0.026761
2022-01-16 00:12:34,487 iteration 1928 : loss : 0.032060, loss_ce: 0.011607
2022-01-16 00:12:35,420 iteration 1929 : loss : 0.044641, loss_ce: 0.019855
2022-01-16 00:12:36,378 iteration 1930 : loss : 0.064145, loss_ce: 0.026496
2022-01-16 00:12:37,309 iteration 1931 : loss : 0.044943, loss_ce: 0.013123
2022-01-16 00:12:38,267 iteration 1932 : loss : 0.047686, loss_ce: 0.015264
2022-01-16 00:12:39,225 iteration 1933 : loss : 0.044477, loss_ce: 0.015822
2022-01-16 00:12:40,052 iteration 1934 : loss : 0.033541, loss_ce: 0.014685
2022-01-16 00:12:40,982 iteration 1935 : loss : 0.040696, loss_ce: 0.019328
2022-01-16 00:12:41,989 iteration 1936 : loss : 0.039677, loss_ce: 0.014150
2022-01-16 00:12:42,982 iteration 1937 : loss : 0.036249, loss_ce: 0.014580
2022-01-16 00:12:43,982 iteration 1938 : loss : 0.052348, loss_ce: 0.018540
 28%|████████▎                    | 114/400 [33:37<1:21:22, 17.07s/it]2022-01-16 00:12:44,935 iteration 1939 : loss : 0.037546, loss_ce: 0.016657
2022-01-16 00:12:45,864 iteration 1940 : loss : 0.029023, loss_ce: 0.011041
2022-01-16 00:12:46,880 iteration 1941 : loss : 0.052320, loss_ce: 0.026520
2022-01-16 00:12:47,839 iteration 1942 : loss : 0.045685, loss_ce: 0.014570
2022-01-16 00:12:48,715 iteration 1943 : loss : 0.037830, loss_ce: 0.013343
2022-01-16 00:12:49,637 iteration 1944 : loss : 0.037355, loss_ce: 0.014465
2022-01-16 00:12:50,572 iteration 1945 : loss : 0.043850, loss_ce: 0.022240
2022-01-16 00:12:51,514 iteration 1946 : loss : 0.046045, loss_ce: 0.016107
2022-01-16 00:12:52,447 iteration 1947 : loss : 0.049286, loss_ce: 0.016727
2022-01-16 00:12:53,372 iteration 1948 : loss : 0.036114, loss_ce: 0.014998
2022-01-16 00:12:54,246 iteration 1949 : loss : 0.038441, loss_ce: 0.019074
2022-01-16 00:12:55,243 iteration 1950 : loss : 0.049267, loss_ce: 0.018298
2022-01-16 00:12:56,312 iteration 1951 : loss : 0.059289, loss_ce: 0.023994
2022-01-16 00:12:57,213 iteration 1952 : loss : 0.048823, loss_ce: 0.014841
2022-01-16 00:12:58,190 iteration 1953 : loss : 0.047873, loss_ce: 0.023526
2022-01-16 00:12:59,229 iteration 1954 : loss : 0.051849, loss_ce: 0.016813
2022-01-16 00:12:59,230 Training Data Eval:
2022-01-16 00:13:03,767   Average segmentation loss on training set: 0.0352
2022-01-16 00:13:03,767 Validation Data Eval:
2022-01-16 00:13:05,253   Average segmentation loss on validation set: 0.1167
2022-01-16 00:13:06,182 iteration 1955 : loss : 0.037562, loss_ce: 0.014875
 29%|████████▎                    | 115/400 [33:59<1:28:24, 18.61s/it]2022-01-16 00:13:07,253 iteration 1956 : loss : 0.051485, loss_ce: 0.021710
2022-01-16 00:13:08,153 iteration 1957 : loss : 0.034607, loss_ce: 0.014431
2022-01-16 00:13:09,079 iteration 1958 : loss : 0.047576, loss_ce: 0.022505
2022-01-16 00:13:10,123 iteration 1959 : loss : 0.071305, loss_ce: 0.017687
2022-01-16 00:13:11,054 iteration 1960 : loss : 0.042517, loss_ce: 0.013704
2022-01-16 00:13:12,013 iteration 1961 : loss : 0.052209, loss_ce: 0.021600
2022-01-16 00:13:12,957 iteration 1962 : loss : 0.037581, loss_ce: 0.014584
2022-01-16 00:13:13,930 iteration 1963 : loss : 0.050822, loss_ce: 0.021546
2022-01-16 00:13:14,867 iteration 1964 : loss : 0.040644, loss_ce: 0.010925
2022-01-16 00:13:15,781 iteration 1965 : loss : 0.047770, loss_ce: 0.021674
2022-01-16 00:13:16,686 iteration 1966 : loss : 0.043979, loss_ce: 0.020544
2022-01-16 00:13:17,583 iteration 1967 : loss : 0.060548, loss_ce: 0.021931
2022-01-16 00:13:18,463 iteration 1968 : loss : 0.055706, loss_ce: 0.027108
2022-01-16 00:13:19,452 iteration 1969 : loss : 0.036463, loss_ce: 0.014443
2022-01-16 00:13:20,560 iteration 1970 : loss : 0.039520, loss_ce: 0.014811
2022-01-16 00:13:21,419 iteration 1971 : loss : 0.036722, loss_ce: 0.012041
2022-01-16 00:13:22,499 iteration 1972 : loss : 0.055822, loss_ce: 0.021905
 29%|████████▍                    | 116/400 [34:15<1:24:50, 17.92s/it]2022-01-16 00:13:23,434 iteration 1973 : loss : 0.033182, loss_ce: 0.012956
2022-01-16 00:13:24,314 iteration 1974 : loss : 0.039619, loss_ce: 0.017591
2022-01-16 00:13:25,353 iteration 1975 : loss : 0.048065, loss_ce: 0.017945
2022-01-16 00:13:26,218 iteration 1976 : loss : 0.044626, loss_ce: 0.016843
2022-01-16 00:13:27,266 iteration 1977 : loss : 0.056191, loss_ce: 0.027078
2022-01-16 00:13:28,184 iteration 1978 : loss : 0.037331, loss_ce: 0.016813
2022-01-16 00:13:29,117 iteration 1979 : loss : 0.044898, loss_ce: 0.022306
2022-01-16 00:13:30,117 iteration 1980 : loss : 0.053355, loss_ce: 0.018400
2022-01-16 00:13:31,021 iteration 1981 : loss : 0.041509, loss_ce: 0.015238
2022-01-16 00:13:32,039 iteration 1982 : loss : 0.048249, loss_ce: 0.019068
2022-01-16 00:13:33,090 iteration 1983 : loss : 0.052433, loss_ce: 0.020207
2022-01-16 00:13:34,009 iteration 1984 : loss : 0.046650, loss_ce: 0.015181
2022-01-16 00:13:34,934 iteration 1985 : loss : 0.038569, loss_ce: 0.014973
2022-01-16 00:13:35,848 iteration 1986 : loss : 0.032824, loss_ce: 0.011681
2022-01-16 00:13:36,753 iteration 1987 : loss : 0.025757, loss_ce: 0.009766
2022-01-16 00:13:37,804 iteration 1988 : loss : 0.043171, loss_ce: 0.017086
2022-01-16 00:13:38,762 iteration 1989 : loss : 0.044491, loss_ce: 0.019302
 29%|████████▍                    | 117/400 [34:31<1:22:09, 17.42s/it]2022-01-16 00:13:39,775 iteration 1990 : loss : 0.056245, loss_ce: 0.025548
2022-01-16 00:13:40,638 iteration 1991 : loss : 0.039130, loss_ce: 0.017232
2022-01-16 00:13:41,632 iteration 1992 : loss : 0.047088, loss_ce: 0.021653
2022-01-16 00:13:42,571 iteration 1993 : loss : 0.053882, loss_ce: 0.014609
2022-01-16 00:13:43,561 iteration 1994 : loss : 0.037892, loss_ce: 0.015742
2022-01-16 00:13:44,511 iteration 1995 : loss : 0.041490, loss_ce: 0.014389
2022-01-16 00:13:45,481 iteration 1996 : loss : 0.051046, loss_ce: 0.024161
2022-01-16 00:13:46,451 iteration 1997 : loss : 0.041333, loss_ce: 0.018574
2022-01-16 00:13:47,444 iteration 1998 : loss : 0.050917, loss_ce: 0.020316
2022-01-16 00:13:48,427 iteration 1999 : loss : 0.045691, loss_ce: 0.018032
2022-01-16 00:13:49,522 iteration 2000 : loss : 0.063562, loss_ce: 0.017023
2022-01-16 00:13:50,488 iteration 2001 : loss : 0.040007, loss_ce: 0.016180
2022-01-16 00:13:51,367 iteration 2002 : loss : 0.042327, loss_ce: 0.017082
2022-01-16 00:13:52,183 iteration 2003 : loss : 0.028832, loss_ce: 0.013379
2022-01-16 00:13:53,090 iteration 2004 : loss : 0.095071, loss_ce: 0.022172
2022-01-16 00:13:54,086 iteration 2005 : loss : 0.028719, loss_ce: 0.009224
2022-01-16 00:13:55,071 iteration 2006 : loss : 0.047041, loss_ce: 0.015778
 30%|████████▌                    | 118/400 [34:48<1:20:18, 17.09s/it]2022-01-16 00:13:56,156 iteration 2007 : loss : 0.049402, loss_ce: 0.018938
2022-01-16 00:13:57,250 iteration 2008 : loss : 0.038380, loss_ce: 0.013327
2022-01-16 00:13:58,211 iteration 2009 : loss : 0.045990, loss_ce: 0.019575
2022-01-16 00:13:59,168 iteration 2010 : loss : 0.047235, loss_ce: 0.018894
2022-01-16 00:14:00,224 iteration 2011 : loss : 0.048746, loss_ce: 0.020102
2022-01-16 00:14:01,193 iteration 2012 : loss : 0.035063, loss_ce: 0.016696
2022-01-16 00:14:02,071 iteration 2013 : loss : 0.043004, loss_ce: 0.018722
2022-01-16 00:14:02,998 iteration 2014 : loss : 0.043824, loss_ce: 0.014370
2022-01-16 00:14:03,999 iteration 2015 : loss : 0.032998, loss_ce: 0.013371
2022-01-16 00:14:04,943 iteration 2016 : loss : 0.062602, loss_ce: 0.022276
2022-01-16 00:14:05,950 iteration 2017 : loss : 0.033677, loss_ce: 0.009544
2022-01-16 00:14:07,027 iteration 2018 : loss : 0.054227, loss_ce: 0.023079
2022-01-16 00:14:07,972 iteration 2019 : loss : 0.050410, loss_ce: 0.017993
2022-01-16 00:14:08,894 iteration 2020 : loss : 0.029712, loss_ce: 0.010545
2022-01-16 00:14:09,880 iteration 2021 : loss : 0.047130, loss_ce: 0.015733
2022-01-16 00:14:10,876 iteration 2022 : loss : 0.038608, loss_ce: 0.017337
2022-01-16 00:14:11,910 iteration 2023 : loss : 0.045228, loss_ce: 0.016983
 30%|████████▋                    | 119/400 [35:04<1:19:40, 17.01s/it]2022-01-16 00:14:12,877 iteration 2024 : loss : 0.036163, loss_ce: 0.010538
2022-01-16 00:14:13,862 iteration 2025 : loss : 0.041839, loss_ce: 0.019925
2022-01-16 00:14:14,885 iteration 2026 : loss : 0.041650, loss_ce: 0.017146
2022-01-16 00:14:15,827 iteration 2027 : loss : 0.032767, loss_ce: 0.010202
2022-01-16 00:14:16,732 iteration 2028 : loss : 0.040691, loss_ce: 0.021617
2022-01-16 00:14:17,664 iteration 2029 : loss : 0.034942, loss_ce: 0.014839
2022-01-16 00:14:18,576 iteration 2030 : loss : 0.035759, loss_ce: 0.013665
2022-01-16 00:14:19,535 iteration 2031 : loss : 0.042490, loss_ce: 0.015931
2022-01-16 00:14:20,591 iteration 2032 : loss : 0.053349, loss_ce: 0.023371
2022-01-16 00:14:21,685 iteration 2033 : loss : 0.043671, loss_ce: 0.018913
2022-01-16 00:14:22,608 iteration 2034 : loss : 0.032700, loss_ce: 0.013639
2022-01-16 00:14:23,574 iteration 2035 : loss : 0.048396, loss_ce: 0.019814
2022-01-16 00:14:24,589 iteration 2036 : loss : 0.040047, loss_ce: 0.017937
2022-01-16 00:14:25,550 iteration 2037 : loss : 0.078546, loss_ce: 0.022180
2022-01-16 00:14:26,564 iteration 2038 : loss : 0.052325, loss_ce: 0.019958
2022-01-16 00:14:27,629 iteration 2039 : loss : 0.048566, loss_ce: 0.018207
2022-01-16 00:14:27,629 Training Data Eval:
2022-01-16 00:14:32,164   Average segmentation loss on training set: 0.0302
2022-01-16 00:14:32,164 Validation Data Eval:
2022-01-16 00:14:33,648   Average segmentation loss on validation set: 0.0955
2022-01-16 00:14:34,685 iteration 2040 : loss : 0.051308, loss_ce: 0.021172
 30%|████████▋                    | 120/400 [35:27<1:27:28, 18.75s/it]2022-01-16 00:14:35,765 iteration 2041 : loss : 0.077691, loss_ce: 0.027421
2022-01-16 00:14:36,700 iteration 2042 : loss : 0.056413, loss_ce: 0.021419
2022-01-16 00:14:37,635 iteration 2043 : loss : 0.033456, loss_ce: 0.012777
2022-01-16 00:14:38,586 iteration 2044 : loss : 0.049573, loss_ce: 0.019202
2022-01-16 00:14:39,508 iteration 2045 : loss : 0.035485, loss_ce: 0.011102
2022-01-16 00:14:40,478 iteration 2046 : loss : 0.042457, loss_ce: 0.021256
2022-01-16 00:14:41,407 iteration 2047 : loss : 0.057823, loss_ce: 0.023621
2022-01-16 00:14:42,375 iteration 2048 : loss : 0.047318, loss_ce: 0.015971
2022-01-16 00:14:43,303 iteration 2049 : loss : 0.074873, loss_ce: 0.021478
2022-01-16 00:14:44,282 iteration 2050 : loss : 0.056984, loss_ce: 0.021829
2022-01-16 00:14:45,261 iteration 2051 : loss : 0.047369, loss_ce: 0.022257
2022-01-16 00:14:46,160 iteration 2052 : loss : 0.062552, loss_ce: 0.024105
2022-01-16 00:14:47,124 iteration 2053 : loss : 0.064121, loss_ce: 0.019338
2022-01-16 00:14:48,058 iteration 2054 : loss : 0.044960, loss_ce: 0.017932
2022-01-16 00:14:48,997 iteration 2055 : loss : 0.083447, loss_ce: 0.024502
2022-01-16 00:14:49,998 iteration 2056 : loss : 0.052942, loss_ce: 0.022034
2022-01-16 00:14:50,902 iteration 2057 : loss : 0.046299, loss_ce: 0.019840
 30%|████████▊                    | 121/400 [35:43<1:23:36, 17.98s/it]2022-01-16 00:14:51,926 iteration 2058 : loss : 0.044120, loss_ce: 0.019927
2022-01-16 00:14:52,952 iteration 2059 : loss : 0.063657, loss_ce: 0.026686
2022-01-16 00:14:53,818 iteration 2060 : loss : 0.062496, loss_ce: 0.026882
2022-01-16 00:14:54,810 iteration 2061 : loss : 0.065600, loss_ce: 0.029130
2022-01-16 00:14:55,748 iteration 2062 : loss : 0.047952, loss_ce: 0.018689
2022-01-16 00:14:56,694 iteration 2063 : loss : 0.078488, loss_ce: 0.016794
2022-01-16 00:14:57,594 iteration 2064 : loss : 0.028160, loss_ce: 0.010152
2022-01-16 00:14:58,524 iteration 2065 : loss : 0.082838, loss_ce: 0.026640
2022-01-16 00:14:59,475 iteration 2066 : loss : 0.050695, loss_ce: 0.017545
2022-01-16 00:15:00,466 iteration 2067 : loss : 0.038341, loss_ce: 0.014620
2022-01-16 00:15:01,495 iteration 2068 : loss : 0.049216, loss_ce: 0.021245
2022-01-16 00:15:02,429 iteration 2069 : loss : 0.038242, loss_ce: 0.010344
2022-01-16 00:15:03,452 iteration 2070 : loss : 0.053709, loss_ce: 0.023102
2022-01-16 00:15:04,486 iteration 2071 : loss : 0.051400, loss_ce: 0.019235
2022-01-16 00:15:05,465 iteration 2072 : loss : 0.052370, loss_ce: 0.023311
2022-01-16 00:15:06,490 iteration 2073 : loss : 0.055483, loss_ce: 0.018796
2022-01-16 00:15:07,493 iteration 2074 : loss : 0.049582, loss_ce: 0.025369
 30%|████████▊                    | 122/400 [36:00<1:21:24, 17.57s/it]2022-01-16 00:15:08,490 iteration 2075 : loss : 0.042451, loss_ce: 0.014930
2022-01-16 00:15:09,463 iteration 2076 : loss : 0.047793, loss_ce: 0.015363
2022-01-16 00:15:10,459 iteration 2077 : loss : 0.042087, loss_ce: 0.018028
2022-01-16 00:15:11,564 iteration 2078 : loss : 0.054063, loss_ce: 0.018588
2022-01-16 00:15:12,501 iteration 2079 : loss : 0.052502, loss_ce: 0.017207
2022-01-16 00:15:13,525 iteration 2080 : loss : 0.054525, loss_ce: 0.019416
2022-01-16 00:15:14,390 iteration 2081 : loss : 0.039351, loss_ce: 0.014350
2022-01-16 00:15:15,232 iteration 2082 : loss : 0.028287, loss_ce: 0.009990
2022-01-16 00:15:16,170 iteration 2083 : loss : 0.049567, loss_ce: 0.025850
2022-01-16 00:15:17,108 iteration 2084 : loss : 0.058536, loss_ce: 0.028305
2022-01-16 00:15:18,012 iteration 2085 : loss : 0.034447, loss_ce: 0.008737
2022-01-16 00:15:18,960 iteration 2086 : loss : 0.054063, loss_ce: 0.021118
2022-01-16 00:15:19,879 iteration 2087 : loss : 0.049667, loss_ce: 0.017649
2022-01-16 00:15:20,908 iteration 2088 : loss : 0.033470, loss_ce: 0.013000
2022-01-16 00:15:21,914 iteration 2089 : loss : 0.038416, loss_ce: 0.016799
2022-01-16 00:15:22,798 iteration 2090 : loss : 0.041590, loss_ce: 0.017051
2022-01-16 00:15:23,797 iteration 2091 : loss : 0.041966, loss_ce: 0.016985
 31%|████████▉                    | 123/400 [36:16<1:19:20, 17.19s/it]2022-01-16 00:15:24,737 iteration 2092 : loss : 0.029160, loss_ce: 0.012685
2022-01-16 00:15:25,668 iteration 2093 : loss : 0.057669, loss_ce: 0.023760
2022-01-16 00:15:26,623 iteration 2094 : loss : 0.045207, loss_ce: 0.013870
2022-01-16 00:15:27,515 iteration 2095 : loss : 0.031056, loss_ce: 0.012978
2022-01-16 00:15:28,566 iteration 2096 : loss : 0.042711, loss_ce: 0.020208
2022-01-16 00:15:29,549 iteration 2097 : loss : 0.069959, loss_ce: 0.021454
2022-01-16 00:15:30,517 iteration 2098 : loss : 0.055874, loss_ce: 0.021503
2022-01-16 00:15:31,498 iteration 2099 : loss : 0.035354, loss_ce: 0.011301
2022-01-16 00:15:32,501 iteration 2100 : loss : 0.059514, loss_ce: 0.034466
2022-01-16 00:15:33,485 iteration 2101 : loss : 0.043235, loss_ce: 0.014012
2022-01-16 00:15:34,497 iteration 2102 : loss : 0.057933, loss_ce: 0.027007
2022-01-16 00:15:35,372 iteration 2103 : loss : 0.045609, loss_ce: 0.020365
2022-01-16 00:15:36,269 iteration 2104 : loss : 0.066310, loss_ce: 0.018519
2022-01-16 00:15:37,328 iteration 2105 : loss : 0.046279, loss_ce: 0.014743
2022-01-16 00:15:38,253 iteration 2106 : loss : 0.028449, loss_ce: 0.012548
2022-01-16 00:15:39,304 iteration 2107 : loss : 0.034011, loss_ce: 0.013294
2022-01-16 00:15:40,288 iteration 2108 : loss : 0.056290, loss_ce: 0.021481
 31%|████████▉                    | 124/400 [36:33<1:18:06, 16.98s/it]2022-01-16 00:15:41,307 iteration 2109 : loss : 0.054356, loss_ce: 0.023207
2022-01-16 00:15:42,310 iteration 2110 : loss : 0.042634, loss_ce: 0.015463
2022-01-16 00:15:43,373 iteration 2111 : loss : 0.058758, loss_ce: 0.017778
2022-01-16 00:15:44,355 iteration 2112 : loss : 0.075790, loss_ce: 0.029393
2022-01-16 00:15:45,281 iteration 2113 : loss : 0.044388, loss_ce: 0.022621
2022-01-16 00:15:46,278 iteration 2114 : loss : 0.039341, loss_ce: 0.019066
2022-01-16 00:15:47,270 iteration 2115 : loss : 0.035758, loss_ce: 0.012936
2022-01-16 00:15:48,256 iteration 2116 : loss : 0.038596, loss_ce: 0.013994
2022-01-16 00:15:49,232 iteration 2117 : loss : 0.038957, loss_ce: 0.013462
2022-01-16 00:15:50,245 iteration 2118 : loss : 0.063339, loss_ce: 0.019534
2022-01-16 00:15:51,260 iteration 2119 : loss : 0.074500, loss_ce: 0.026423
2022-01-16 00:15:52,235 iteration 2120 : loss : 0.049594, loss_ce: 0.014315
2022-01-16 00:15:53,092 iteration 2121 : loss : 0.044324, loss_ce: 0.015628
2022-01-16 00:15:54,028 iteration 2122 : loss : 0.032229, loss_ce: 0.010294
2022-01-16 00:15:55,055 iteration 2123 : loss : 0.050563, loss_ce: 0.022980
2022-01-16 00:15:56,106 iteration 2124 : loss : 0.050570, loss_ce: 0.020350
2022-01-16 00:15:56,106 Training Data Eval:
2022-01-16 00:16:00,644   Average segmentation loss on training set: 0.0392
2022-01-16 00:16:00,645 Validation Data Eval:
2022-01-16 00:16:02,129   Average segmentation loss on validation set: 0.1314
2022-01-16 00:16:03,107 iteration 2125 : loss : 0.068518, loss_ce: 0.037398
 31%|█████████                    | 125/400 [36:56<1:25:51, 18.73s/it]2022-01-16 00:16:04,185 iteration 2126 : loss : 0.051455, loss_ce: 0.018815
2022-01-16 00:16:05,182 iteration 2127 : loss : 0.046481, loss_ce: 0.020552
2022-01-16 00:16:06,169 iteration 2128 : loss : 0.045133, loss_ce: 0.015182
2022-01-16 00:16:07,095 iteration 2129 : loss : 0.051725, loss_ce: 0.018980
2022-01-16 00:16:08,102 iteration 2130 : loss : 0.072747, loss_ce: 0.026079
2022-01-16 00:16:09,043 iteration 2131 : loss : 0.055913, loss_ce: 0.018804
2022-01-16 00:16:10,005 iteration 2132 : loss : 0.044258, loss_ce: 0.015602
2022-01-16 00:16:11,044 iteration 2133 : loss : 0.065416, loss_ce: 0.020796
2022-01-16 00:16:11,931 iteration 2134 : loss : 0.039134, loss_ce: 0.020214
2022-01-16 00:16:12,893 iteration 2135 : loss : 0.042718, loss_ce: 0.015003
2022-01-16 00:16:13,839 iteration 2136 : loss : 0.039992, loss_ce: 0.016946
2022-01-16 00:16:14,797 iteration 2137 : loss : 0.050918, loss_ce: 0.022037
2022-01-16 00:16:15,712 iteration 2138 : loss : 0.054400, loss_ce: 0.021681
2022-01-16 00:16:16,714 iteration 2139 : loss : 0.038131, loss_ce: 0.018392
2022-01-16 00:16:17,674 iteration 2140 : loss : 0.054986, loss_ce: 0.024985
2022-01-16 00:16:18,704 iteration 2141 : loss : 0.080448, loss_ce: 0.021528
2022-01-16 00:16:19,626 iteration 2142 : loss : 0.042652, loss_ce: 0.013959
 32%|█████████▏                   | 126/400 [37:12<1:22:30, 18.07s/it]2022-01-16 00:16:20,571 iteration 2143 : loss : 0.041411, loss_ce: 0.016276
2022-01-16 00:16:21,550 iteration 2144 : loss : 0.052073, loss_ce: 0.015889
2022-01-16 00:16:22,542 iteration 2145 : loss : 0.056619, loss_ce: 0.018944
2022-01-16 00:16:23,441 iteration 2146 : loss : 0.028066, loss_ce: 0.012089
2022-01-16 00:16:24,416 iteration 2147 : loss : 0.063986, loss_ce: 0.021200
2022-01-16 00:16:25,351 iteration 2148 : loss : 0.041184, loss_ce: 0.014495
2022-01-16 00:16:26,315 iteration 2149 : loss : 0.043688, loss_ce: 0.017074
2022-01-16 00:16:27,245 iteration 2150 : loss : 0.041234, loss_ce: 0.015599
2022-01-16 00:16:28,279 iteration 2151 : loss : 0.045328, loss_ce: 0.018179
2022-01-16 00:16:29,195 iteration 2152 : loss : 0.035584, loss_ce: 0.013909
2022-01-16 00:16:30,095 iteration 2153 : loss : 0.031339, loss_ce: 0.011896
2022-01-16 00:16:31,200 iteration 2154 : loss : 0.069156, loss_ce: 0.023185
2022-01-16 00:16:32,163 iteration 2155 : loss : 0.042744, loss_ce: 0.014814
2022-01-16 00:16:33,071 iteration 2156 : loss : 0.046666, loss_ce: 0.019494
2022-01-16 00:16:34,191 iteration 2157 : loss : 0.073342, loss_ce: 0.022850
2022-01-16 00:16:35,262 iteration 2158 : loss : 0.056843, loss_ce: 0.026140
2022-01-16 00:16:36,252 iteration 2159 : loss : 0.067977, loss_ce: 0.020584
 32%|█████████▏                   | 127/400 [37:29<1:20:13, 17.63s/it]2022-01-16 00:16:37,226 iteration 2160 : loss : 0.037385, loss_ce: 0.014937
2022-01-16 00:16:38,120 iteration 2161 : loss : 0.035139, loss_ce: 0.011319
2022-01-16 00:16:39,058 iteration 2162 : loss : 0.046717, loss_ce: 0.016956
2022-01-16 00:16:39,980 iteration 2163 : loss : 0.036182, loss_ce: 0.013684
2022-01-16 00:16:40,984 iteration 2164 : loss : 0.041179, loss_ce: 0.019891
2022-01-16 00:16:41,962 iteration 2165 : loss : 0.051465, loss_ce: 0.017302
2022-01-16 00:16:42,867 iteration 2166 : loss : 0.044645, loss_ce: 0.019489
2022-01-16 00:16:43,739 iteration 2167 : loss : 0.035684, loss_ce: 0.014953
2022-01-16 00:16:44,664 iteration 2168 : loss : 0.032848, loss_ce: 0.013135
2022-01-16 00:16:45,648 iteration 2169 : loss : 0.044187, loss_ce: 0.016378
2022-01-16 00:16:46,489 iteration 2170 : loss : 0.036196, loss_ce: 0.012129
2022-01-16 00:16:47,412 iteration 2171 : loss : 0.046920, loss_ce: 0.018762
2022-01-16 00:16:48,326 iteration 2172 : loss : 0.049594, loss_ce: 0.017472
2022-01-16 00:16:49,231 iteration 2173 : loss : 0.041303, loss_ce: 0.011497
2022-01-16 00:16:50,187 iteration 2174 : loss : 0.049217, loss_ce: 0.018729
2022-01-16 00:16:51,235 iteration 2175 : loss : 0.026333, loss_ce: 0.010204
2022-01-16 00:16:52,075 iteration 2176 : loss : 0.034512, loss_ce: 0.017251
 32%|█████████▎                   | 128/400 [37:45<1:17:29, 17.09s/it]2022-01-16 00:16:53,016 iteration 2177 : loss : 0.052089, loss_ce: 0.026972
2022-01-16 00:16:53,967 iteration 2178 : loss : 0.032097, loss_ce: 0.009555
2022-01-16 00:16:55,002 iteration 2179 : loss : 0.038683, loss_ce: 0.013118
2022-01-16 00:16:56,005 iteration 2180 : loss : 0.044841, loss_ce: 0.018942
2022-01-16 00:16:56,889 iteration 2181 : loss : 0.036928, loss_ce: 0.013433
2022-01-16 00:16:57,844 iteration 2182 : loss : 0.047589, loss_ce: 0.016603
2022-01-16 00:16:58,816 iteration 2183 : loss : 0.049457, loss_ce: 0.018543
2022-01-16 00:16:59,711 iteration 2184 : loss : 0.046763, loss_ce: 0.023229
2022-01-16 00:17:00,611 iteration 2185 : loss : 0.040300, loss_ce: 0.013670
2022-01-16 00:17:01,651 iteration 2186 : loss : 0.035016, loss_ce: 0.012197
2022-01-16 00:17:02,710 iteration 2187 : loss : 0.042395, loss_ce: 0.015222
2022-01-16 00:17:03,840 iteration 2188 : loss : 0.058656, loss_ce: 0.034443
2022-01-16 00:17:04,956 iteration 2189 : loss : 0.045531, loss_ce: 0.014336
2022-01-16 00:17:05,928 iteration 2190 : loss : 0.038639, loss_ce: 0.017792
2022-01-16 00:17:06,920 iteration 2191 : loss : 0.032048, loss_ce: 0.012266
2022-01-16 00:17:07,845 iteration 2192 : loss : 0.035818, loss_ce: 0.013895
2022-01-16 00:17:08,823 iteration 2193 : loss : 0.032953, loss_ce: 0.011750
 32%|█████████▎                   | 129/400 [38:01<1:16:44, 16.99s/it]2022-01-16 00:17:09,888 iteration 2194 : loss : 0.036223, loss_ce: 0.014868
2022-01-16 00:17:10,879 iteration 2195 : loss : 0.047604, loss_ce: 0.023878
2022-01-16 00:17:11,905 iteration 2196 : loss : 0.030688, loss_ce: 0.013083
2022-01-16 00:17:12,967 iteration 2197 : loss : 0.033127, loss_ce: 0.011842
2022-01-16 00:17:13,931 iteration 2198 : loss : 0.051692, loss_ce: 0.017259
2022-01-16 00:17:14,907 iteration 2199 : loss : 0.049313, loss_ce: 0.023454
2022-01-16 00:17:15,962 iteration 2200 : loss : 0.071585, loss_ce: 0.015313
2022-01-16 00:17:16,862 iteration 2201 : loss : 0.033281, loss_ce: 0.011933
2022-01-16 00:17:17,944 iteration 2202 : loss : 0.041787, loss_ce: 0.017271
2022-01-16 00:17:18,942 iteration 2203 : loss : 0.043325, loss_ce: 0.013933
2022-01-16 00:17:19,833 iteration 2204 : loss : 0.036683, loss_ce: 0.010587
2022-01-16 00:17:20,810 iteration 2205 : loss : 0.057878, loss_ce: 0.026682
2022-01-16 00:17:21,869 iteration 2206 : loss : 0.053699, loss_ce: 0.021512
2022-01-16 00:17:22,866 iteration 2207 : loss : 0.045270, loss_ce: 0.014031
2022-01-16 00:17:23,899 iteration 2208 : loss : 0.056630, loss_ce: 0.017155
2022-01-16 00:17:24,867 iteration 2209 : loss : 0.049974, loss_ce: 0.017598
2022-01-16 00:17:24,867 Training Data Eval:
2022-01-16 00:17:29,396   Average segmentation loss on training set: 0.0373
2022-01-16 00:17:29,396 Validation Data Eval:
2022-01-16 00:17:30,888   Average segmentation loss on validation set: 0.0709
2022-01-16 00:17:31,745 Found new lowest validation loss at iteration 2209! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-16 00:17:32,740 iteration 2210 : loss : 0.054095, loss_ce: 0.025170
 32%|█████████▍                   | 130/400 [38:25<1:25:48, 19.07s/it]2022-01-16 00:17:33,769 iteration 2211 : loss : 0.041155, loss_ce: 0.011134
2022-01-16 00:17:34,681 iteration 2212 : loss : 0.065397, loss_ce: 0.029461
2022-01-16 00:17:35,646 iteration 2213 : loss : 0.072221, loss_ce: 0.015132
2022-01-16 00:17:36,520 iteration 2214 : loss : 0.042238, loss_ce: 0.015226
2022-01-16 00:17:37,390 iteration 2215 : loss : 0.030840, loss_ce: 0.011057
2022-01-16 00:17:38,310 iteration 2216 : loss : 0.040142, loss_ce: 0.018313
2022-01-16 00:17:39,208 iteration 2217 : loss : 0.048823, loss_ce: 0.025336
2022-01-16 00:17:40,134 iteration 2218 : loss : 0.030377, loss_ce: 0.010390
2022-01-16 00:17:41,119 iteration 2219 : loss : 0.034593, loss_ce: 0.015299
2022-01-16 00:17:42,167 iteration 2220 : loss : 0.087665, loss_ce: 0.049927
2022-01-16 00:17:43,208 iteration 2221 : loss : 0.043769, loss_ce: 0.013206
2022-01-16 00:17:44,077 iteration 2222 : loss : 0.048528, loss_ce: 0.017344
2022-01-16 00:17:44,972 iteration 2223 : loss : 0.051870, loss_ce: 0.019607
2022-01-16 00:17:46,007 iteration 2224 : loss : 0.055934, loss_ce: 0.023466
2022-01-16 00:17:46,994 iteration 2225 : loss : 0.048565, loss_ce: 0.017484
2022-01-16 00:17:48,031 iteration 2226 : loss : 0.041463, loss_ce: 0.018203
2022-01-16 00:17:49,040 iteration 2227 : loss : 0.051874, loss_ce: 0.017197
 33%|█████████▍                   | 131/400 [38:42<1:21:45, 18.24s/it]2022-01-16 00:17:50,146 iteration 2228 : loss : 0.048168, loss_ce: 0.019774
2022-01-16 00:17:51,128 iteration 2229 : loss : 0.040066, loss_ce: 0.016097
2022-01-16 00:17:52,251 iteration 2230 : loss : 0.050755, loss_ce: 0.022454
2022-01-16 00:17:53,209 iteration 2231 : loss : 0.051918, loss_ce: 0.027076
2022-01-16 00:17:54,153 iteration 2232 : loss : 0.044725, loss_ce: 0.019826
2022-01-16 00:17:55,328 iteration 2233 : loss : 0.127138, loss_ce: 0.045296
2022-01-16 00:17:56,332 iteration 2234 : loss : 0.056392, loss_ce: 0.018161
2022-01-16 00:17:57,305 iteration 2235 : loss : 0.053158, loss_ce: 0.020710
2022-01-16 00:17:58,253 iteration 2236 : loss : 0.032106, loss_ce: 0.012625
2022-01-16 00:17:59,232 iteration 2237 : loss : 0.041053, loss_ce: 0.017744
2022-01-16 00:18:00,137 iteration 2238 : loss : 0.041380, loss_ce: 0.011172
2022-01-16 00:18:01,075 iteration 2239 : loss : 0.036436, loss_ce: 0.011562
2022-01-16 00:18:01,945 iteration 2240 : loss : 0.053673, loss_ce: 0.015597
2022-01-16 00:18:02,896 iteration 2241 : loss : 0.033515, loss_ce: 0.011115
2022-01-16 00:18:03,924 iteration 2242 : loss : 0.055295, loss_ce: 0.018683
2022-01-16 00:18:04,926 iteration 2243 : loss : 0.068790, loss_ce: 0.033417
2022-01-16 00:18:05,870 iteration 2244 : loss : 0.026829, loss_ce: 0.009194
 33%|█████████▌                   | 132/400 [38:58<1:19:34, 17.82s/it]2022-01-16 00:18:06,885 iteration 2245 : loss : 0.036580, loss_ce: 0.012484
2022-01-16 00:18:07,745 iteration 2246 : loss : 0.043530, loss_ce: 0.012752
2022-01-16 00:18:08,713 iteration 2247 : loss : 0.041148, loss_ce: 0.017213
2022-01-16 00:18:09,750 iteration 2248 : loss : 0.066159, loss_ce: 0.029915
2022-01-16 00:18:10,709 iteration 2249 : loss : 0.029634, loss_ce: 0.012571
2022-01-16 00:18:11,677 iteration 2250 : loss : 0.035086, loss_ce: 0.011451
2022-01-16 00:18:12,674 iteration 2251 : loss : 0.042338, loss_ce: 0.019345
2022-01-16 00:18:13,640 iteration 2252 : loss : 0.047525, loss_ce: 0.016666
2022-01-16 00:18:14,713 iteration 2253 : loss : 0.049340, loss_ce: 0.017430
2022-01-16 00:18:15,740 iteration 2254 : loss : 0.030274, loss_ce: 0.011229
2022-01-16 00:18:16,711 iteration 2255 : loss : 0.035783, loss_ce: 0.011977
2022-01-16 00:18:17,657 iteration 2256 : loss : 0.033812, loss_ce: 0.012994
2022-01-16 00:18:18,567 iteration 2257 : loss : 0.054809, loss_ce: 0.017928
2022-01-16 00:18:19,467 iteration 2258 : loss : 0.064609, loss_ce: 0.024502
2022-01-16 00:18:20,492 iteration 2259 : loss : 0.038471, loss_ce: 0.014990
2022-01-16 00:18:21,375 iteration 2260 : loss : 0.035572, loss_ce: 0.013685
2022-01-16 00:18:22,358 iteration 2261 : loss : 0.048888, loss_ce: 0.021397
 33%|█████████▋                   | 133/400 [39:15<1:17:30, 17.42s/it]2022-01-16 00:18:23,325 iteration 2262 : loss : 0.038799, loss_ce: 0.021683
2022-01-16 00:18:24,362 iteration 2263 : loss : 0.078157, loss_ce: 0.027507
2022-01-16 00:18:25,428 iteration 2264 : loss : 0.035490, loss_ce: 0.010376
2022-01-16 00:18:26,422 iteration 2265 : loss : 0.032061, loss_ce: 0.012111
2022-01-16 00:18:27,355 iteration 2266 : loss : 0.044123, loss_ce: 0.016543
2022-01-16 00:18:28,293 iteration 2267 : loss : 0.032101, loss_ce: 0.010839
2022-01-16 00:18:29,253 iteration 2268 : loss : 0.039843, loss_ce: 0.015366
2022-01-16 00:18:30,170 iteration 2269 : loss : 0.040499, loss_ce: 0.022726
2022-01-16 00:18:31,124 iteration 2270 : loss : 0.044291, loss_ce: 0.014734
2022-01-16 00:18:32,047 iteration 2271 : loss : 0.038822, loss_ce: 0.014561
2022-01-16 00:18:32,994 iteration 2272 : loss : 0.046396, loss_ce: 0.022104
2022-01-16 00:18:33,981 iteration 2273 : loss : 0.031170, loss_ce: 0.010118
2022-01-16 00:18:34,961 iteration 2274 : loss : 0.038387, loss_ce: 0.011778
2022-01-16 00:18:35,988 iteration 2275 : loss : 0.061885, loss_ce: 0.023271
2022-01-16 00:18:36,890 iteration 2276 : loss : 0.030581, loss_ce: 0.011772
2022-01-16 00:18:37,859 iteration 2277 : loss : 0.042287, loss_ce: 0.013907
2022-01-16 00:18:38,766 iteration 2278 : loss : 0.028436, loss_ce: 0.010503
 34%|█████████▋                   | 134/400 [39:31<1:15:51, 17.11s/it]2022-01-16 00:18:39,717 iteration 2279 : loss : 0.055740, loss_ce: 0.021751
2022-01-16 00:18:40,682 iteration 2280 : loss : 0.033869, loss_ce: 0.015821
2022-01-16 00:18:41,636 iteration 2281 : loss : 0.063608, loss_ce: 0.015847
2022-01-16 00:18:42,628 iteration 2282 : loss : 0.032753, loss_ce: 0.013132
2022-01-16 00:18:43,673 iteration 2283 : loss : 0.037212, loss_ce: 0.015840
2022-01-16 00:18:44,608 iteration 2284 : loss : 0.039448, loss_ce: 0.016085
2022-01-16 00:18:45,548 iteration 2285 : loss : 0.025673, loss_ce: 0.008948
2022-01-16 00:18:46,491 iteration 2286 : loss : 0.031530, loss_ce: 0.010571
2022-01-16 00:18:47,432 iteration 2287 : loss : 0.037769, loss_ce: 0.015668
2022-01-16 00:18:48,432 iteration 2288 : loss : 0.027905, loss_ce: 0.010157
2022-01-16 00:18:49,340 iteration 2289 : loss : 0.031523, loss_ce: 0.007692
2022-01-16 00:18:50,359 iteration 2290 : loss : 0.035708, loss_ce: 0.018621
2022-01-16 00:18:51,310 iteration 2291 : loss : 0.030240, loss_ce: 0.011662
2022-01-16 00:18:52,250 iteration 2292 : loss : 0.037800, loss_ce: 0.016458
2022-01-16 00:18:53,120 iteration 2293 : loss : 0.043256, loss_ce: 0.023549
2022-01-16 00:18:54,114 iteration 2294 : loss : 0.061450, loss_ce: 0.021540
2022-01-16 00:18:54,115 Training Data Eval:
2022-01-16 00:18:58,659   Average segmentation loss on training set: 0.0338
2022-01-16 00:18:58,659 Validation Data Eval:
2022-01-16 00:19:00,153   Average segmentation loss on validation set: 0.2223
2022-01-16 00:19:01,195 iteration 2295 : loss : 0.037328, loss_ce: 0.016099
 34%|█████████▊                   | 135/400 [39:54<1:22:37, 18.71s/it]2022-01-16 00:19:02,128 iteration 2296 : loss : 0.027887, loss_ce: 0.010926
2022-01-16 00:19:03,066 iteration 2297 : loss : 0.027365, loss_ce: 0.012084
2022-01-16 00:19:04,010 iteration 2298 : loss : 0.028143, loss_ce: 0.011992
2022-01-16 00:19:05,048 iteration 2299 : loss : 0.057336, loss_ce: 0.027295
2022-01-16 00:19:05,967 iteration 2300 : loss : 0.040508, loss_ce: 0.015776
2022-01-16 00:19:07,011 iteration 2301 : loss : 0.031340, loss_ce: 0.008685
2022-01-16 00:19:08,020 iteration 2302 : loss : 0.065216, loss_ce: 0.022509
2022-01-16 00:19:09,002 iteration 2303 : loss : 0.033786, loss_ce: 0.011347
2022-01-16 00:19:10,057 iteration 2304 : loss : 0.048062, loss_ce: 0.017935
2022-01-16 00:19:11,060 iteration 2305 : loss : 0.046112, loss_ce: 0.019312
2022-01-16 00:19:12,133 iteration 2306 : loss : 0.049542, loss_ce: 0.022443
2022-01-16 00:19:13,084 iteration 2307 : loss : 0.046739, loss_ce: 0.015105
2022-01-16 00:19:13,996 iteration 2308 : loss : 0.034810, loss_ce: 0.011956
2022-01-16 00:19:14,928 iteration 2309 : loss : 0.038982, loss_ce: 0.018126
2022-01-16 00:19:15,964 iteration 2310 : loss : 0.031833, loss_ce: 0.013011
2022-01-16 00:19:16,842 iteration 2311 : loss : 0.039764, loss_ce: 0.014884
2022-01-16 00:19:17,816 iteration 2312 : loss : 0.058064, loss_ce: 0.020380
 34%|█████████▊                   | 136/400 [40:10<1:19:32, 18.08s/it]2022-01-16 00:19:18,880 iteration 2313 : loss : 0.040730, loss_ce: 0.014082
2022-01-16 00:19:19,729 iteration 2314 : loss : 0.032843, loss_ce: 0.010500
2022-01-16 00:19:20,633 iteration 2315 : loss : 0.034186, loss_ce: 0.013537
2022-01-16 00:19:21,686 iteration 2316 : loss : 0.034188, loss_ce: 0.015155
2022-01-16 00:19:22,572 iteration 2317 : loss : 0.032619, loss_ce: 0.011850
2022-01-16 00:19:23,502 iteration 2318 : loss : 0.040147, loss_ce: 0.018771
2022-01-16 00:19:24,457 iteration 2319 : loss : 0.055537, loss_ce: 0.020176
2022-01-16 00:19:25,504 iteration 2320 : loss : 0.040289, loss_ce: 0.015840
2022-01-16 00:19:26,458 iteration 2321 : loss : 0.038884, loss_ce: 0.015285
2022-01-16 00:19:27,429 iteration 2322 : loss : 0.041060, loss_ce: 0.017458
2022-01-16 00:19:28,291 iteration 2323 : loss : 0.038240, loss_ce: 0.016413
2022-01-16 00:19:29,225 iteration 2324 : loss : 0.030437, loss_ce: 0.013511
2022-01-16 00:19:30,049 iteration 2325 : loss : 0.031996, loss_ce: 0.014189
2022-01-16 00:19:30,981 iteration 2326 : loss : 0.049233, loss_ce: 0.010508
2022-01-16 00:19:31,894 iteration 2327 : loss : 0.043853, loss_ce: 0.016478
2022-01-16 00:19:32,846 iteration 2328 : loss : 0.041453, loss_ce: 0.016814
2022-01-16 00:19:33,740 iteration 2329 : loss : 0.032724, loss_ce: 0.014034
 34%|█████████▉                   | 137/400 [40:26<1:16:26, 17.44s/it]2022-01-16 00:19:34,779 iteration 2330 : loss : 0.035533, loss_ce: 0.013240
2022-01-16 00:19:35,681 iteration 2331 : loss : 0.026982, loss_ce: 0.010484
2022-01-16 00:19:36,726 iteration 2332 : loss : 0.030262, loss_ce: 0.010749
2022-01-16 00:19:37,681 iteration 2333 : loss : 0.033923, loss_ce: 0.014951
2022-01-16 00:19:38,779 iteration 2334 : loss : 0.028979, loss_ce: 0.011554
2022-01-16 00:19:39,861 iteration 2335 : loss : 0.050415, loss_ce: 0.020498
2022-01-16 00:19:40,905 iteration 2336 : loss : 0.033545, loss_ce: 0.015927
2022-01-16 00:19:41,874 iteration 2337 : loss : 0.044693, loss_ce: 0.015520
2022-01-16 00:19:42,876 iteration 2338 : loss : 0.048277, loss_ce: 0.018829
2022-01-16 00:19:43,868 iteration 2339 : loss : 0.045716, loss_ce: 0.018922
2022-01-16 00:19:44,765 iteration 2340 : loss : 0.028600, loss_ce: 0.010983
2022-01-16 00:19:45,743 iteration 2341 : loss : 0.034804, loss_ce: 0.014247
2022-01-16 00:19:46,734 iteration 2342 : loss : 0.032616, loss_ce: 0.013938
2022-01-16 00:19:47,837 iteration 2343 : loss : 0.031786, loss_ce: 0.011757
2022-01-16 00:19:48,751 iteration 2344 : loss : 0.100776, loss_ce: 0.032145
2022-01-16 00:19:49,676 iteration 2345 : loss : 0.057669, loss_ce: 0.030975
2022-01-16 00:19:50,625 iteration 2346 : loss : 0.050218, loss_ce: 0.018504
 34%|██████████                   | 138/400 [40:43<1:15:25, 17.27s/it]2022-01-16 00:19:51,756 iteration 2347 : loss : 0.059656, loss_ce: 0.026011
2022-01-16 00:19:52,741 iteration 2348 : loss : 0.031051, loss_ce: 0.011134
2022-01-16 00:19:53,674 iteration 2349 : loss : 0.044303, loss_ce: 0.013594
2022-01-16 00:19:54,621 iteration 2350 : loss : 0.058052, loss_ce: 0.016785
2022-01-16 00:19:55,668 iteration 2351 : loss : 0.040009, loss_ce: 0.017002
2022-01-16 00:19:56,580 iteration 2352 : loss : 0.033426, loss_ce: 0.015975
2022-01-16 00:19:57,504 iteration 2353 : loss : 0.034177, loss_ce: 0.014637
2022-01-16 00:19:58,408 iteration 2354 : loss : 0.027175, loss_ce: 0.012358
2022-01-16 00:19:59,328 iteration 2355 : loss : 0.050766, loss_ce: 0.019500
2022-01-16 00:20:00,345 iteration 2356 : loss : 0.043641, loss_ce: 0.016896
2022-01-16 00:20:01,317 iteration 2357 : loss : 0.054919, loss_ce: 0.016000
2022-01-16 00:20:02,296 iteration 2358 : loss : 0.039057, loss_ce: 0.015582
2022-01-16 00:20:03,226 iteration 2359 : loss : 0.037547, loss_ce: 0.012171
2022-01-16 00:20:04,130 iteration 2360 : loss : 0.046353, loss_ce: 0.013989
2022-01-16 00:20:05,082 iteration 2361 : loss : 0.032456, loss_ce: 0.011337
2022-01-16 00:20:06,176 iteration 2362 : loss : 0.043819, loss_ce: 0.016521
2022-01-16 00:20:07,146 iteration 2363 : loss : 0.034102, loss_ce: 0.015098
 35%|██████████                   | 139/400 [41:00<1:14:09, 17.05s/it]2022-01-16 00:20:08,262 iteration 2364 : loss : 0.035098, loss_ce: 0.011685
2022-01-16 00:20:09,328 iteration 2365 : loss : 0.044556, loss_ce: 0.016183
2022-01-16 00:20:10,345 iteration 2366 : loss : 0.053915, loss_ce: 0.019315
2022-01-16 00:20:11,246 iteration 2367 : loss : 0.033724, loss_ce: 0.008269
2022-01-16 00:20:12,150 iteration 2368 : loss : 0.029322, loss_ce: 0.011959
2022-01-16 00:20:13,120 iteration 2369 : loss : 0.045340, loss_ce: 0.014014
2022-01-16 00:20:14,066 iteration 2370 : loss : 0.053509, loss_ce: 0.022712
2022-01-16 00:20:15,063 iteration 2371 : loss : 0.029081, loss_ce: 0.011851
2022-01-16 00:20:15,977 iteration 2372 : loss : 0.046135, loss_ce: 0.015224
2022-01-16 00:20:16,920 iteration 2373 : loss : 0.043476, loss_ce: 0.016130
2022-01-16 00:20:17,818 iteration 2374 : loss : 0.034142, loss_ce: 0.013398
2022-01-16 00:20:18,732 iteration 2375 : loss : 0.026516, loss_ce: 0.009451
2022-01-16 00:20:19,711 iteration 2376 : loss : 0.047739, loss_ce: 0.023172
2022-01-16 00:20:20,681 iteration 2377 : loss : 0.031202, loss_ce: 0.014382
2022-01-16 00:20:21,651 iteration 2378 : loss : 0.027298, loss_ce: 0.010542
2022-01-16 00:20:22,654 iteration 2379 : loss : 0.036450, loss_ce: 0.013961
2022-01-16 00:20:22,654 Training Data Eval:
2022-01-16 00:20:27,202   Average segmentation loss on training set: 0.0246
2022-01-16 00:20:27,202 Validation Data Eval:
2022-01-16 00:20:28,692   Average segmentation loss on validation set: 0.0777
2022-01-16 00:20:29,604 iteration 2380 : loss : 0.026890, loss_ce: 0.012211
 35%|██████████▏                  | 140/400 [41:22<1:20:52, 18.67s/it]2022-01-16 00:20:30,564 iteration 2381 : loss : 0.033013, loss_ce: 0.012043
2022-01-16 00:20:31,557 iteration 2382 : loss : 0.051983, loss_ce: 0.016830
2022-01-16 00:20:32,465 iteration 2383 : loss : 0.026721, loss_ce: 0.008783
2022-01-16 00:20:33,480 iteration 2384 : loss : 0.037172, loss_ce: 0.013697
2022-01-16 00:20:34,513 iteration 2385 : loss : 0.050762, loss_ce: 0.019353
2022-01-16 00:20:35,468 iteration 2386 : loss : 0.031404, loss_ce: 0.009338
2022-01-16 00:20:36,394 iteration 2387 : loss : 0.042791, loss_ce: 0.014387
2022-01-16 00:20:37,347 iteration 2388 : loss : 0.049888, loss_ce: 0.022462
2022-01-16 00:20:38,238 iteration 2389 : loss : 0.019426, loss_ce: 0.006126
2022-01-16 00:20:39,224 iteration 2390 : loss : 0.031832, loss_ce: 0.016145
2022-01-16 00:20:40,176 iteration 2391 : loss : 0.041964, loss_ce: 0.024547
2022-01-16 00:20:41,173 iteration 2392 : loss : 0.034425, loss_ce: 0.012416
2022-01-16 00:20:42,169 iteration 2393 : loss : 0.057409, loss_ce: 0.017356
2022-01-16 00:20:43,040 iteration 2394 : loss : 0.032449, loss_ce: 0.010707
2022-01-16 00:20:44,069 iteration 2395 : loss : 0.029676, loss_ce: 0.012742
2022-01-16 00:20:44,988 iteration 2396 : loss : 0.026647, loss_ce: 0.012003
2022-01-16 00:20:45,984 iteration 2397 : loss : 0.028440, loss_ce: 0.010620
 35%|██████████▏                  | 141/400 [41:39<1:17:37, 17.98s/it]2022-01-16 00:20:47,005 iteration 2398 : loss : 0.043951, loss_ce: 0.016242
2022-01-16 00:20:47,932 iteration 2399 : loss : 0.060247, loss_ce: 0.018754
2022-01-16 00:20:48,960 iteration 2400 : loss : 0.032345, loss_ce: 0.014546
2022-01-16 00:20:49,924 iteration 2401 : loss : 0.032323, loss_ce: 0.010275
2022-01-16 00:20:50,941 iteration 2402 : loss : 0.038003, loss_ce: 0.018355
2022-01-16 00:20:51,864 iteration 2403 : loss : 0.038382, loss_ce: 0.016684
2022-01-16 00:20:52,761 iteration 2404 : loss : 0.047687, loss_ce: 0.018519
2022-01-16 00:20:53,625 iteration 2405 : loss : 0.044493, loss_ce: 0.015771
2022-01-16 00:20:54,729 iteration 2406 : loss : 0.040410, loss_ce: 0.011467
2022-01-16 00:20:55,619 iteration 2407 : loss : 0.035826, loss_ce: 0.017306
2022-01-16 00:20:56,511 iteration 2408 : loss : 0.022328, loss_ce: 0.009525
2022-01-16 00:20:57,524 iteration 2409 : loss : 0.031641, loss_ce: 0.010871
2022-01-16 00:20:58,547 iteration 2410 : loss : 0.046481, loss_ce: 0.018755
2022-01-16 00:20:59,542 iteration 2411 : loss : 0.048905, loss_ce: 0.014157
2022-01-16 00:21:00,453 iteration 2412 : loss : 0.026644, loss_ce: 0.011210
2022-01-16 00:21:01,490 iteration 2413 : loss : 0.060882, loss_ce: 0.025858
2022-01-16 00:21:02,459 iteration 2414 : loss : 0.030728, loss_ce: 0.012332
 36%|██████████▎                  | 142/400 [41:55<1:15:22, 17.53s/it]2022-01-16 00:21:03,499 iteration 2415 : loss : 0.043319, loss_ce: 0.015046
2022-01-16 00:21:04,435 iteration 2416 : loss : 0.028730, loss_ce: 0.009666
2022-01-16 00:21:05,390 iteration 2417 : loss : 0.023569, loss_ce: 0.007831
2022-01-16 00:21:06,446 iteration 2418 : loss : 0.037088, loss_ce: 0.013193
2022-01-16 00:21:07,421 iteration 2419 : loss : 0.042203, loss_ce: 0.020083
2022-01-16 00:21:08,501 iteration 2420 : loss : 0.048840, loss_ce: 0.025439
2022-01-16 00:21:09,555 iteration 2421 : loss : 0.058105, loss_ce: 0.018347
2022-01-16 00:21:10,586 iteration 2422 : loss : 0.049446, loss_ce: 0.019691
2022-01-16 00:21:11,551 iteration 2423 : loss : 0.036890, loss_ce: 0.012789
2022-01-16 00:21:12,498 iteration 2424 : loss : 0.028112, loss_ce: 0.011966
2022-01-16 00:21:13,580 iteration 2425 : loss : 0.035208, loss_ce: 0.011683
2022-01-16 00:21:14,524 iteration 2426 : loss : 0.036512, loss_ce: 0.011454
2022-01-16 00:21:15,383 iteration 2427 : loss : 0.035194, loss_ce: 0.014375
2022-01-16 00:21:16,300 iteration 2428 : loss : 0.032201, loss_ce: 0.008916
2022-01-16 00:21:17,217 iteration 2429 : loss : 0.036447, loss_ce: 0.014138
2022-01-16 00:21:18,133 iteration 2430 : loss : 0.020604, loss_ce: 0.007533
2022-01-16 00:21:19,086 iteration 2431 : loss : 0.039420, loss_ce: 0.020724
 36%|██████████▎                  | 143/400 [42:12<1:13:55, 17.26s/it]2022-01-16 00:21:20,056 iteration 2432 : loss : 0.034434, loss_ce: 0.010366
2022-01-16 00:21:20,998 iteration 2433 : loss : 0.033768, loss_ce: 0.012960
2022-01-16 00:21:21,955 iteration 2434 : loss : 0.037776, loss_ce: 0.012283
2022-01-16 00:21:23,010 iteration 2435 : loss : 0.045479, loss_ce: 0.023654
2022-01-16 00:21:23,876 iteration 2436 : loss : 0.030188, loss_ce: 0.011868
2022-01-16 00:21:24,880 iteration 2437 : loss : 0.029826, loss_ce: 0.009821
2022-01-16 00:21:25,902 iteration 2438 : loss : 0.038384, loss_ce: 0.013396
2022-01-16 00:21:26,913 iteration 2439 : loss : 0.026533, loss_ce: 0.009011
2022-01-16 00:21:27,935 iteration 2440 : loss : 0.051767, loss_ce: 0.020046
2022-01-16 00:21:28,882 iteration 2441 : loss : 0.031911, loss_ce: 0.010748
2022-01-16 00:21:29,820 iteration 2442 : loss : 0.033700, loss_ce: 0.013662
2022-01-16 00:21:30,702 iteration 2443 : loss : 0.032341, loss_ce: 0.012864
2022-01-16 00:21:31,655 iteration 2444 : loss : 0.035158, loss_ce: 0.014471
2022-01-16 00:21:32,627 iteration 2445 : loss : 0.037718, loss_ce: 0.015063
2022-01-16 00:21:33,684 iteration 2446 : loss : 0.027323, loss_ce: 0.012134
2022-01-16 00:21:34,576 iteration 2447 : loss : 0.031814, loss_ce: 0.011677
2022-01-16 00:21:35,587 iteration 2448 : loss : 0.033569, loss_ce: 0.013026
 36%|██████████▍                  | 144/400 [42:28<1:12:39, 17.03s/it]2022-01-16 00:21:36,530 iteration 2449 : loss : 0.045637, loss_ce: 0.017607
2022-01-16 00:21:37,417 iteration 2450 : loss : 0.026056, loss_ce: 0.013168
2022-01-16 00:21:38,342 iteration 2451 : loss : 0.036817, loss_ce: 0.010921
2022-01-16 00:21:39,244 iteration 2452 : loss : 0.034175, loss_ce: 0.011674
2022-01-16 00:21:40,209 iteration 2453 : loss : 0.047474, loss_ce: 0.016773
2022-01-16 00:21:41,137 iteration 2454 : loss : 0.033329, loss_ce: 0.012250
2022-01-16 00:21:42,040 iteration 2455 : loss : 0.039843, loss_ce: 0.020302
2022-01-16 00:21:42,924 iteration 2456 : loss : 0.033041, loss_ce: 0.014390
2022-01-16 00:21:43,851 iteration 2457 : loss : 0.030092, loss_ce: 0.011509
2022-01-16 00:21:44,744 iteration 2458 : loss : 0.031746, loss_ce: 0.012087
2022-01-16 00:21:45,591 iteration 2459 : loss : 0.025206, loss_ce: 0.009812
2022-01-16 00:21:46,507 iteration 2460 : loss : 0.038846, loss_ce: 0.012450
2022-01-16 00:21:47,534 iteration 2461 : loss : 0.041793, loss_ce: 0.014725
2022-01-16 00:21:48,517 iteration 2462 : loss : 0.047135, loss_ce: 0.017234
2022-01-16 00:21:49,449 iteration 2463 : loss : 0.032244, loss_ce: 0.013415
2022-01-16 00:21:50,430 iteration 2464 : loss : 0.029638, loss_ce: 0.010512
2022-01-16 00:21:50,430 Training Data Eval:
2022-01-16 00:21:54,973   Average segmentation loss on training set: 0.0416
2022-01-16 00:21:54,974 Validation Data Eval:
2022-01-16 00:21:56,466   Average segmentation loss on validation set: 0.2503
2022-01-16 00:21:57,398 iteration 2465 : loss : 0.044897, loss_ce: 0.019268
 36%|██████████▌                  | 145/400 [42:50<1:18:28, 18.47s/it]2022-01-16 00:21:58,481 iteration 2466 : loss : 0.047698, loss_ce: 0.017067
2022-01-16 00:21:59,526 iteration 2467 : loss : 0.036600, loss_ce: 0.015318
2022-01-16 00:22:00,456 iteration 2468 : loss : 0.031698, loss_ce: 0.011964
2022-01-16 00:22:01,353 iteration 2469 : loss : 0.028876, loss_ce: 0.011389
2022-01-16 00:22:02,293 iteration 2470 : loss : 0.055153, loss_ce: 0.020206
2022-01-16 00:22:03,342 iteration 2471 : loss : 0.066937, loss_ce: 0.022381
2022-01-16 00:22:04,258 iteration 2472 : loss : 0.046241, loss_ce: 0.016944
2022-01-16 00:22:05,273 iteration 2473 : loss : 0.042265, loss_ce: 0.018358
2022-01-16 00:22:06,192 iteration 2474 : loss : 0.039810, loss_ce: 0.015395
2022-01-16 00:22:07,150 iteration 2475 : loss : 0.033550, loss_ce: 0.014103
2022-01-16 00:22:08,047 iteration 2476 : loss : 0.036441, loss_ce: 0.018190
2022-01-16 00:22:09,094 iteration 2477 : loss : 0.040025, loss_ce: 0.015750
2022-01-16 00:22:10,085 iteration 2478 : loss : 0.038665, loss_ce: 0.014948
2022-01-16 00:22:10,945 iteration 2479 : loss : 0.038856, loss_ce: 0.012841
2022-01-16 00:22:11,909 iteration 2480 : loss : 0.033941, loss_ce: 0.012259
2022-01-16 00:22:12,928 iteration 2481 : loss : 0.031731, loss_ce: 0.011393
2022-01-16 00:22:13,851 iteration 2482 : loss : 0.031689, loss_ce: 0.013739
 36%|██████████▌                  | 146/400 [43:06<1:15:36, 17.86s/it]2022-01-16 00:22:14,959 iteration 2483 : loss : 0.043291, loss_ce: 0.017811
2022-01-16 00:22:15,949 iteration 2484 : loss : 0.042275, loss_ce: 0.010184
2022-01-16 00:22:16,864 iteration 2485 : loss : 0.030820, loss_ce: 0.014191
2022-01-16 00:22:17,811 iteration 2486 : loss : 0.030419, loss_ce: 0.012710
2022-01-16 00:22:18,744 iteration 2487 : loss : 0.032442, loss_ce: 0.011420
2022-01-16 00:22:19,762 iteration 2488 : loss : 0.029691, loss_ce: 0.012120
2022-01-16 00:22:20,704 iteration 2489 : loss : 0.031339, loss_ce: 0.012712
2022-01-16 00:22:21,715 iteration 2490 : loss : 0.030712, loss_ce: 0.012742
2022-01-16 00:22:22,763 iteration 2491 : loss : 0.029190, loss_ce: 0.012003
2022-01-16 00:22:23,620 iteration 2492 : loss : 0.026816, loss_ce: 0.010336
2022-01-16 00:22:24,592 iteration 2493 : loss : 0.035570, loss_ce: 0.014907
2022-01-16 00:22:25,531 iteration 2494 : loss : 0.062659, loss_ce: 0.019439
2022-01-16 00:22:26,457 iteration 2495 : loss : 0.030818, loss_ce: 0.013479
2022-01-16 00:22:27,611 iteration 2496 : loss : 0.041116, loss_ce: 0.011920
2022-01-16 00:22:28,620 iteration 2497 : loss : 0.048182, loss_ce: 0.017154
2022-01-16 00:22:29,640 iteration 2498 : loss : 0.049341, loss_ce: 0.021917
2022-01-16 00:22:30,532 iteration 2499 : loss : 0.031054, loss_ce: 0.007868
 37%|██████████▋                  | 147/400 [43:23<1:13:49, 17.51s/it]2022-01-16 00:22:31,535 iteration 2500 : loss : 0.040252, loss_ce: 0.015842
2022-01-16 00:22:32,478 iteration 2501 : loss : 0.032477, loss_ce: 0.009578
2022-01-16 00:22:33,512 iteration 2502 : loss : 0.045978, loss_ce: 0.019036
2022-01-16 00:22:34,406 iteration 2503 : loss : 0.031251, loss_ce: 0.012087
2022-01-16 00:22:35,322 iteration 2504 : loss : 0.036072, loss_ce: 0.013229
2022-01-16 00:22:36,320 iteration 2505 : loss : 0.050511, loss_ce: 0.021558
2022-01-16 00:22:37,269 iteration 2506 : loss : 0.038668, loss_ce: 0.012163
2022-01-16 00:22:38,166 iteration 2507 : loss : 0.030080, loss_ce: 0.014482
2022-01-16 00:22:39,094 iteration 2508 : loss : 0.033386, loss_ce: 0.011468
2022-01-16 00:22:40,025 iteration 2509 : loss : 0.035445, loss_ce: 0.012204
2022-01-16 00:22:40,938 iteration 2510 : loss : 0.027046, loss_ce: 0.011582
2022-01-16 00:22:41,908 iteration 2511 : loss : 0.031916, loss_ce: 0.013833
2022-01-16 00:22:42,891 iteration 2512 : loss : 0.037143, loss_ce: 0.014044
2022-01-16 00:22:43,913 iteration 2513 : loss : 0.033357, loss_ce: 0.011190
2022-01-16 00:22:44,878 iteration 2514 : loss : 0.040433, loss_ce: 0.012670
2022-01-16 00:22:45,824 iteration 2515 : loss : 0.028109, loss_ce: 0.013082
2022-01-16 00:22:46,751 iteration 2516 : loss : 0.031312, loss_ce: 0.014671
 37%|██████████▋                  | 148/400 [43:39<1:11:54, 17.12s/it]2022-01-16 00:22:47,744 iteration 2517 : loss : 0.035045, loss_ce: 0.014112
2022-01-16 00:22:48,702 iteration 2518 : loss : 0.037629, loss_ce: 0.011702
2022-01-16 00:22:49,682 iteration 2519 : loss : 0.035703, loss_ce: 0.012845
2022-01-16 00:22:50,630 iteration 2520 : loss : 0.047070, loss_ce: 0.019422
2022-01-16 00:22:51,566 iteration 2521 : loss : 0.026961, loss_ce: 0.009630
2022-01-16 00:22:52,531 iteration 2522 : loss : 0.039753, loss_ce: 0.021509
2022-01-16 00:22:53,542 iteration 2523 : loss : 0.041370, loss_ce: 0.012361
2022-01-16 00:22:54,477 iteration 2524 : loss : 0.037754, loss_ce: 0.017023
2022-01-16 00:22:55,444 iteration 2525 : loss : 0.028328, loss_ce: 0.011932
2022-01-16 00:22:56,432 iteration 2526 : loss : 0.049228, loss_ce: 0.017505
2022-01-16 00:22:57,395 iteration 2527 : loss : 0.030505, loss_ce: 0.012080
2022-01-16 00:22:58,376 iteration 2528 : loss : 0.035654, loss_ce: 0.013614
2022-01-16 00:22:59,343 iteration 2529 : loss : 0.043005, loss_ce: 0.014856
2022-01-16 00:23:00,314 iteration 2530 : loss : 0.028490, loss_ce: 0.013327
2022-01-16 00:23:01,361 iteration 2531 : loss : 0.050763, loss_ce: 0.019749
2022-01-16 00:23:02,315 iteration 2532 : loss : 0.052550, loss_ce: 0.017085
2022-01-16 00:23:03,294 iteration 2533 : loss : 0.043300, loss_ce: 0.013375
 37%|██████████▊                  | 149/400 [43:56<1:10:52, 16.94s/it]2022-01-16 00:23:04,235 iteration 2534 : loss : 0.039169, loss_ce: 0.018318
2022-01-16 00:23:05,274 iteration 2535 : loss : 0.069830, loss_ce: 0.023860
2022-01-16 00:23:06,191 iteration 2536 : loss : 0.036744, loss_ce: 0.016365
2022-01-16 00:23:07,115 iteration 2537 : loss : 0.038703, loss_ce: 0.017115
2022-01-16 00:23:07,960 iteration 2538 : loss : 0.027182, loss_ce: 0.011778
2022-01-16 00:23:08,942 iteration 2539 : loss : 0.032598, loss_ce: 0.012327
2022-01-16 00:23:09,848 iteration 2540 : loss : 0.024782, loss_ce: 0.007809
2022-01-16 00:23:10,775 iteration 2541 : loss : 0.040724, loss_ce: 0.019091
2022-01-16 00:23:11,657 iteration 2542 : loss : 0.022126, loss_ce: 0.007268
2022-01-16 00:23:12,544 iteration 2543 : loss : 0.041138, loss_ce: 0.012950
2022-01-16 00:23:13,495 iteration 2544 : loss : 0.031829, loss_ce: 0.011253
2022-01-16 00:23:14,573 iteration 2545 : loss : 0.027483, loss_ce: 0.010464
2022-01-16 00:23:15,668 iteration 2546 : loss : 0.036729, loss_ce: 0.015700
2022-01-16 00:23:16,561 iteration 2547 : loss : 0.023467, loss_ce: 0.011179
2022-01-16 00:23:17,547 iteration 2548 : loss : 0.028421, loss_ce: 0.013408
2022-01-16 00:23:18,514 iteration 2549 : loss : 0.057509, loss_ce: 0.018309
2022-01-16 00:23:18,514 Training Data Eval:
2022-01-16 00:23:23,037   Average segmentation loss on training set: 0.0263
2022-01-16 00:23:23,037 Validation Data Eval:
2022-01-16 00:23:24,519   Average segmentation loss on validation set: 0.0675
2022-01-16 00:23:25,367 Found new lowest validation loss at iteration 2549! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-16 00:23:26,281 iteration 2550 : loss : 0.046282, loss_ce: 0.018134
 38%|██████████▉                  | 150/400 [44:19<1:18:10, 18.76s/it]2022-01-16 00:23:27,277 iteration 2551 : loss : 0.026789, loss_ce: 0.012792
2022-01-16 00:23:28,293 iteration 2552 : loss : 0.026529, loss_ce: 0.011282
2022-01-16 00:23:29,170 iteration 2553 : loss : 0.021528, loss_ce: 0.006893
2022-01-16 00:23:30,126 iteration 2554 : loss : 0.025161, loss_ce: 0.009286
2022-01-16 00:23:31,056 iteration 2555 : loss : 0.043751, loss_ce: 0.010805
2022-01-16 00:23:32,065 iteration 2556 : loss : 0.045728, loss_ce: 0.025033
2022-01-16 00:23:33,004 iteration 2557 : loss : 0.037913, loss_ce: 0.018150
2022-01-16 00:23:33,967 iteration 2558 : loss : 0.042377, loss_ce: 0.024557
2022-01-16 00:23:35,018 iteration 2559 : loss : 0.034361, loss_ce: 0.013136
2022-01-16 00:23:35,969 iteration 2560 : loss : 0.034042, loss_ce: 0.017585
2022-01-16 00:23:37,022 iteration 2561 : loss : 0.041199, loss_ce: 0.014420
2022-01-16 00:23:38,003 iteration 2562 : loss : 0.048123, loss_ce: 0.018164
2022-01-16 00:23:38,993 iteration 2563 : loss : 0.039891, loss_ce: 0.017429
2022-01-16 00:23:39,902 iteration 2564 : loss : 0.030063, loss_ce: 0.013243
2022-01-16 00:23:40,816 iteration 2565 : loss : 0.033403, loss_ce: 0.013003
2022-01-16 00:23:41,747 iteration 2566 : loss : 0.034915, loss_ce: 0.013478
2022-01-16 00:23:42,713 iteration 2567 : loss : 0.063830, loss_ce: 0.021391
 38%|██████████▉                  | 151/400 [44:35<1:14:56, 18.06s/it]2022-01-16 00:23:43,752 iteration 2568 : loss : 0.039111, loss_ce: 0.018424
2022-01-16 00:23:44,686 iteration 2569 : loss : 0.028784, loss_ce: 0.013512
2022-01-16 00:23:45,620 iteration 2570 : loss : 0.055948, loss_ce: 0.020039
2022-01-16 00:23:46,556 iteration 2571 : loss : 0.025503, loss_ce: 0.010307
2022-01-16 00:23:47,442 iteration 2572 : loss : 0.042194, loss_ce: 0.011230
2022-01-16 00:23:48,332 iteration 2573 : loss : 0.029570, loss_ce: 0.012008
2022-01-16 00:23:49,252 iteration 2574 : loss : 0.040303, loss_ce: 0.015402
2022-01-16 00:23:50,328 iteration 2575 : loss : 0.059442, loss_ce: 0.024437
2022-01-16 00:23:51,303 iteration 2576 : loss : 0.035591, loss_ce: 0.013345
2022-01-16 00:23:52,264 iteration 2577 : loss : 0.044621, loss_ce: 0.016820
2022-01-16 00:23:53,233 iteration 2578 : loss : 0.040098, loss_ce: 0.012869
2022-01-16 00:23:54,128 iteration 2579 : loss : 0.045465, loss_ce: 0.011387
2022-01-16 00:23:55,146 iteration 2580 : loss : 0.056200, loss_ce: 0.012987
2022-01-16 00:23:56,149 iteration 2581 : loss : 0.038120, loss_ce: 0.015448
2022-01-16 00:23:57,189 iteration 2582 : loss : 0.031507, loss_ce: 0.011018
2022-01-16 00:23:58,139 iteration 2583 : loss : 0.029197, loss_ce: 0.010596
2022-01-16 00:23:58,996 iteration 2584 : loss : 0.031350, loss_ce: 0.011244
 38%|███████████                  | 152/400 [44:52<1:12:27, 17.53s/it]2022-01-16 00:24:00,015 iteration 2585 : loss : 0.028620, loss_ce: 0.008191
2022-01-16 00:24:00,978 iteration 2586 : loss : 0.032663, loss_ce: 0.014091
2022-01-16 00:24:01,864 iteration 2587 : loss : 0.031178, loss_ce: 0.010777
2022-01-16 00:24:02,790 iteration 2588 : loss : 0.037352, loss_ce: 0.017133
2022-01-16 00:24:03,787 iteration 2589 : loss : 0.038161, loss_ce: 0.012174
2022-01-16 00:24:04,798 iteration 2590 : loss : 0.032906, loss_ce: 0.012257
2022-01-16 00:24:05,714 iteration 2591 : loss : 0.032259, loss_ce: 0.010275
2022-01-16 00:24:06,632 iteration 2592 : loss : 0.041569, loss_ce: 0.014156
2022-01-16 00:24:07,560 iteration 2593 : loss : 0.033927, loss_ce: 0.014719
2022-01-16 00:24:08,654 iteration 2594 : loss : 0.050580, loss_ce: 0.021699
2022-01-16 00:24:09,650 iteration 2595 : loss : 0.034675, loss_ce: 0.013369
2022-01-16 00:24:10,565 iteration 2596 : loss : 0.028648, loss_ce: 0.013039
2022-01-16 00:24:11,459 iteration 2597 : loss : 0.032894, loss_ce: 0.012659
2022-01-16 00:24:12,384 iteration 2598 : loss : 0.031676, loss_ce: 0.012690
2022-01-16 00:24:13,323 iteration 2599 : loss : 0.035377, loss_ce: 0.008554
2022-01-16 00:24:14,259 iteration 2600 : loss : 0.033087, loss_ce: 0.011950
2022-01-16 00:24:15,149 iteration 2601 : loss : 0.033296, loss_ce: 0.013179
 38%|███████████                  | 153/400 [45:08<1:10:27, 17.12s/it]2022-01-16 00:24:16,194 iteration 2602 : loss : 0.030342, loss_ce: 0.011835
2022-01-16 00:24:17,065 iteration 2603 : loss : 0.021742, loss_ce: 0.008332
2022-01-16 00:24:17,993 iteration 2604 : loss : 0.030015, loss_ce: 0.010820
2022-01-16 00:24:19,084 iteration 2605 : loss : 0.028002, loss_ce: 0.009133
2022-01-16 00:24:20,038 iteration 2606 : loss : 0.035605, loss_ce: 0.015552
2022-01-16 00:24:20,998 iteration 2607 : loss : 0.038966, loss_ce: 0.019559
2022-01-16 00:24:21,891 iteration 2608 : loss : 0.033232, loss_ce: 0.016034
2022-01-16 00:24:22,796 iteration 2609 : loss : 0.033843, loss_ce: 0.010245
2022-01-16 00:24:23,878 iteration 2610 : loss : 0.035876, loss_ce: 0.015344
2022-01-16 00:24:24,798 iteration 2611 : loss : 0.038292, loss_ce: 0.012117
2022-01-16 00:24:25,647 iteration 2612 : loss : 0.027504, loss_ce: 0.012631
2022-01-16 00:24:26,566 iteration 2613 : loss : 0.043008, loss_ce: 0.015187
2022-01-16 00:24:27,574 iteration 2614 : loss : 0.049077, loss_ce: 0.017074
2022-01-16 00:24:28,489 iteration 2615 : loss : 0.034419, loss_ce: 0.013397
2022-01-16 00:24:29,409 iteration 2616 : loss : 0.037160, loss_ce: 0.015825
2022-01-16 00:24:30,444 iteration 2617 : loss : 0.051425, loss_ce: 0.016515
2022-01-16 00:24:31,419 iteration 2618 : loss : 0.040861, loss_ce: 0.019560
 38%|███████████▏                 | 154/400 [45:24<1:09:08, 16.86s/it]2022-01-16 00:24:32,494 iteration 2619 : loss : 0.055843, loss_ce: 0.016784
2022-01-16 00:24:33,419 iteration 2620 : loss : 0.038676, loss_ce: 0.014083
2022-01-16 00:24:34,398 iteration 2621 : loss : 0.030597, loss_ce: 0.009516
2022-01-16 00:24:35,378 iteration 2622 : loss : 0.039012, loss_ce: 0.020877
2022-01-16 00:24:36,372 iteration 2623 : loss : 0.078460, loss_ce: 0.039743
2022-01-16 00:24:37,275 iteration 2624 : loss : 0.053605, loss_ce: 0.019541
2022-01-16 00:24:38,203 iteration 2625 : loss : 0.026601, loss_ce: 0.010993
2022-01-16 00:24:39,227 iteration 2626 : loss : 0.059934, loss_ce: 0.023823
2022-01-16 00:24:40,206 iteration 2627 : loss : 0.078849, loss_ce: 0.027861
2022-01-16 00:24:41,112 iteration 2628 : loss : 0.037037, loss_ce: 0.013635
2022-01-16 00:24:42,132 iteration 2629 : loss : 0.052203, loss_ce: 0.021215
2022-01-16 00:24:43,023 iteration 2630 : loss : 0.037033, loss_ce: 0.011230
2022-01-16 00:24:43,997 iteration 2631 : loss : 0.044085, loss_ce: 0.022378
2022-01-16 00:24:44,981 iteration 2632 : loss : 0.037550, loss_ce: 0.013864
2022-01-16 00:24:45,898 iteration 2633 : loss : 0.032487, loss_ce: 0.015142
2022-01-16 00:24:46,868 iteration 2634 : loss : 0.041328, loss_ce: 0.014795
2022-01-16 00:24:46,869 Training Data Eval:
2022-01-16 00:24:51,400   Average segmentation loss on training set: 0.0336
2022-01-16 00:24:51,400 Validation Data Eval:
2022-01-16 00:24:52,887   Average segmentation loss on validation set: 0.1299
2022-01-16 00:24:53,916 iteration 2635 : loss : 0.050272, loss_ce: 0.023255
 39%|███████████▏                 | 155/400 [45:47<1:15:44, 18.55s/it]2022-01-16 00:24:54,884 iteration 2636 : loss : 0.028898, loss_ce: 0.009191
2022-01-16 00:24:55,978 iteration 2637 : loss : 0.050233, loss_ce: 0.017950
2022-01-16 00:24:56,945 iteration 2638 : loss : 0.037951, loss_ce: 0.016797
2022-01-16 00:24:57,775 iteration 2639 : loss : 0.030264, loss_ce: 0.010853
2022-01-16 00:24:58,671 iteration 2640 : loss : 0.034958, loss_ce: 0.013678
2022-01-16 00:24:59,719 iteration 2641 : loss : 0.041497, loss_ce: 0.016355
2022-01-16 00:25:00,733 iteration 2642 : loss : 0.071838, loss_ce: 0.024155
2022-01-16 00:25:01,739 iteration 2643 : loss : 0.041312, loss_ce: 0.012629
2022-01-16 00:25:02,655 iteration 2644 : loss : 0.041217, loss_ce: 0.013691
2022-01-16 00:25:03,572 iteration 2645 : loss : 0.030820, loss_ce: 0.015298
2022-01-16 00:25:04,499 iteration 2646 : loss : 0.048985, loss_ce: 0.014374
2022-01-16 00:25:05,504 iteration 2647 : loss : 0.056170, loss_ce: 0.022725
2022-01-16 00:25:06,370 iteration 2648 : loss : 0.025743, loss_ce: 0.011624
2022-01-16 00:25:07,365 iteration 2649 : loss : 0.050605, loss_ce: 0.022312
2022-01-16 00:25:08,354 iteration 2650 : loss : 0.037543, loss_ce: 0.016917
2022-01-16 00:25:09,277 iteration 2651 : loss : 0.048857, loss_ce: 0.016507
2022-01-16 00:25:10,232 iteration 2652 : loss : 0.034209, loss_ce: 0.017791
 39%|███████████▎                 | 156/400 [46:03<1:12:43, 17.88s/it]2022-01-16 00:25:11,352 iteration 2653 : loss : 0.037318, loss_ce: 0.014269
2022-01-16 00:25:12,305 iteration 2654 : loss : 0.027914, loss_ce: 0.009931
2022-01-16 00:25:13,193 iteration 2655 : loss : 0.025478, loss_ce: 0.009326
2022-01-16 00:25:14,064 iteration 2656 : loss : 0.027121, loss_ce: 0.012159
2022-01-16 00:25:14,954 iteration 2657 : loss : 0.029072, loss_ce: 0.010499
2022-01-16 00:25:15,862 iteration 2658 : loss : 0.036418, loss_ce: 0.014982
2022-01-16 00:25:16,946 iteration 2659 : loss : 0.038984, loss_ce: 0.017454
2022-01-16 00:25:17,898 iteration 2660 : loss : 0.034838, loss_ce: 0.011384
2022-01-16 00:25:18,756 iteration 2661 : loss : 0.033408, loss_ce: 0.013487
2022-01-16 00:25:19,757 iteration 2662 : loss : 0.040323, loss_ce: 0.014986
2022-01-16 00:25:20,655 iteration 2663 : loss : 0.038838, loss_ce: 0.015403
2022-01-16 00:25:21,667 iteration 2664 : loss : 0.028556, loss_ce: 0.010144
2022-01-16 00:25:22,597 iteration 2665 : loss : 0.036662, loss_ce: 0.013117
2022-01-16 00:25:23,557 iteration 2666 : loss : 0.037583, loss_ce: 0.011392
2022-01-16 00:25:24,548 iteration 2667 : loss : 0.030820, loss_ce: 0.012404
2022-01-16 00:25:25,527 iteration 2668 : loss : 0.061835, loss_ce: 0.024224
2022-01-16 00:25:26,535 iteration 2669 : loss : 0.047702, loss_ce: 0.017527
 39%|███████████▍                 | 157/400 [46:19<1:10:30, 17.41s/it]2022-01-16 00:25:27,573 iteration 2670 : loss : 0.068519, loss_ce: 0.018091
2022-01-16 00:25:28,548 iteration 2671 : loss : 0.045213, loss_ce: 0.015626
2022-01-16 00:25:29,535 iteration 2672 : loss : 0.031295, loss_ce: 0.011802
2022-01-16 00:25:30,549 iteration 2673 : loss : 0.048949, loss_ce: 0.019349
2022-01-16 00:25:31,464 iteration 2674 : loss : 0.043168, loss_ce: 0.022729
2022-01-16 00:25:32,477 iteration 2675 : loss : 0.043688, loss_ce: 0.016178
2022-01-16 00:25:33,454 iteration 2676 : loss : 0.036444, loss_ce: 0.011061
2022-01-16 00:25:34,344 iteration 2677 : loss : 0.026110, loss_ce: 0.012013
2022-01-16 00:25:35,258 iteration 2678 : loss : 0.031907, loss_ce: 0.010348
2022-01-16 00:25:36,237 iteration 2679 : loss : 0.036721, loss_ce: 0.018430
2022-01-16 00:25:37,252 iteration 2680 : loss : 0.033691, loss_ce: 0.014447
2022-01-16 00:25:38,193 iteration 2681 : loss : 0.033454, loss_ce: 0.016093
2022-01-16 00:25:39,078 iteration 2682 : loss : 0.026491, loss_ce: 0.011127
2022-01-16 00:25:40,044 iteration 2683 : loss : 0.032358, loss_ce: 0.016170
2022-01-16 00:25:40,988 iteration 2684 : loss : 0.047151, loss_ce: 0.015296
2022-01-16 00:25:41,945 iteration 2685 : loss : 0.030841, loss_ce: 0.014057
2022-01-16 00:25:42,887 iteration 2686 : loss : 0.027732, loss_ce: 0.010470
 40%|███████████▍                 | 158/400 [46:35<1:08:56, 17.09s/it]2022-01-16 00:25:43,872 iteration 2687 : loss : 0.020561, loss_ce: 0.008855
2022-01-16 00:25:44,801 iteration 2688 : loss : 0.040040, loss_ce: 0.014338
2022-01-16 00:25:45,634 iteration 2689 : loss : 0.025780, loss_ce: 0.009558
2022-01-16 00:25:46,560 iteration 2690 : loss : 0.029153, loss_ce: 0.012284
2022-01-16 00:25:47,524 iteration 2691 : loss : 0.027306, loss_ce: 0.009121
2022-01-16 00:25:48,458 iteration 2692 : loss : 0.033418, loss_ce: 0.011217
2022-01-16 00:25:49,364 iteration 2693 : loss : 0.034442, loss_ce: 0.013260
2022-01-16 00:25:50,211 iteration 2694 : loss : 0.031206, loss_ce: 0.011171
2022-01-16 00:25:51,206 iteration 2695 : loss : 0.051975, loss_ce: 0.019594
2022-01-16 00:25:52,266 iteration 2696 : loss : 0.044638, loss_ce: 0.017784
2022-01-16 00:25:53,286 iteration 2697 : loss : 0.028493, loss_ce: 0.014412
2022-01-16 00:25:54,178 iteration 2698 : loss : 0.024131, loss_ce: 0.009640
2022-01-16 00:25:55,082 iteration 2699 : loss : 0.026547, loss_ce: 0.009067
2022-01-16 00:25:55,988 iteration 2700 : loss : 0.035182, loss_ce: 0.010378
2022-01-16 00:25:56,944 iteration 2701 : loss : 0.030708, loss_ce: 0.014099
2022-01-16 00:25:57,930 iteration 2702 : loss : 0.039225, loss_ce: 0.010088
2022-01-16 00:25:58,925 iteration 2703 : loss : 0.035133, loss_ce: 0.012436
 40%|███████████▌                 | 159/400 [46:52<1:07:22, 16.78s/it]2022-01-16 00:25:59,878 iteration 2704 : loss : 0.028032, loss_ce: 0.008947
2022-01-16 00:26:00,767 iteration 2705 : loss : 0.037796, loss_ce: 0.016544
2022-01-16 00:26:01,753 iteration 2706 : loss : 0.050272, loss_ce: 0.024945
2022-01-16 00:26:02,696 iteration 2707 : loss : 0.030176, loss_ce: 0.011148
2022-01-16 00:26:03,624 iteration 2708 : loss : 0.043344, loss_ce: 0.013176
2022-01-16 00:26:04,647 iteration 2709 : loss : 0.031229, loss_ce: 0.009305
2022-01-16 00:26:05,652 iteration 2710 : loss : 0.037113, loss_ce: 0.016852
2022-01-16 00:26:06,573 iteration 2711 : loss : 0.025183, loss_ce: 0.008652
2022-01-16 00:26:07,504 iteration 2712 : loss : 0.038952, loss_ce: 0.014956
2022-01-16 00:26:08,465 iteration 2713 : loss : 0.030497, loss_ce: 0.010826
2022-01-16 00:26:09,422 iteration 2714 : loss : 0.040968, loss_ce: 0.015600
2022-01-16 00:26:10,357 iteration 2715 : loss : 0.027030, loss_ce: 0.014811
2022-01-16 00:26:11,289 iteration 2716 : loss : 0.047113, loss_ce: 0.013123
2022-01-16 00:26:12,172 iteration 2717 : loss : 0.032657, loss_ce: 0.012963
2022-01-16 00:26:13,155 iteration 2718 : loss : 0.034021, loss_ce: 0.012015
2022-01-16 00:26:14,067 iteration 2719 : loss : 0.022857, loss_ce: 0.010058
2022-01-16 00:26:14,067 Training Data Eval:
2022-01-16 00:26:18,607   Average segmentation loss on training set: 0.0218
2022-01-16 00:26:18,607 Validation Data Eval:
2022-01-16 00:26:20,096   Average segmentation loss on validation set: 0.0767
2022-01-16 00:26:21,027 iteration 2720 : loss : 0.028240, loss_ce: 0.012128
 40%|███████████▌                 | 160/400 [47:14<1:13:28, 18.37s/it]2022-01-16 00:26:22,047 iteration 2721 : loss : 0.031179, loss_ce: 0.010697
2022-01-16 00:26:23,031 iteration 2722 : loss : 0.030051, loss_ce: 0.014669
2022-01-16 00:26:24,068 iteration 2723 : loss : 0.046003, loss_ce: 0.022584
2022-01-16 00:26:24,959 iteration 2724 : loss : 0.036996, loss_ce: 0.013113
2022-01-16 00:26:25,884 iteration 2725 : loss : 0.046652, loss_ce: 0.020153
2022-01-16 00:26:26,912 iteration 2726 : loss : 0.032500, loss_ce: 0.012116
2022-01-16 00:26:27,859 iteration 2727 : loss : 0.034926, loss_ce: 0.013559
2022-01-16 00:26:28,860 iteration 2728 : loss : 0.031868, loss_ce: 0.013862
2022-01-16 00:26:29,847 iteration 2729 : loss : 0.032564, loss_ce: 0.015341
2022-01-16 00:26:30,875 iteration 2730 : loss : 0.038283, loss_ce: 0.014283
2022-01-16 00:26:31,816 iteration 2731 : loss : 0.030971, loss_ce: 0.011700
2022-01-16 00:26:32,663 iteration 2732 : loss : 0.024573, loss_ce: 0.009503
2022-01-16 00:26:33,603 iteration 2733 : loss : 0.025373, loss_ce: 0.011913
2022-01-16 00:26:34,565 iteration 2734 : loss : 0.048335, loss_ce: 0.012529
2022-01-16 00:26:35,526 iteration 2735 : loss : 0.050397, loss_ce: 0.024747
2022-01-16 00:26:36,457 iteration 2736 : loss : 0.028459, loss_ce: 0.008504
2022-01-16 00:26:37,383 iteration 2737 : loss : 0.048281, loss_ce: 0.013603
 40%|███████████▋                 | 161/400 [47:30<1:10:46, 17.77s/it]2022-01-16 00:26:38,442 iteration 2738 : loss : 0.050314, loss_ce: 0.025851
2022-01-16 00:26:39,336 iteration 2739 : loss : 0.039108, loss_ce: 0.010578
2022-01-16 00:26:40,376 iteration 2740 : loss : 0.044111, loss_ce: 0.021793
2022-01-16 00:26:41,321 iteration 2741 : loss : 0.037294, loss_ce: 0.016552
2022-01-16 00:26:42,278 iteration 2742 : loss : 0.043305, loss_ce: 0.019147
2022-01-16 00:26:43,163 iteration 2743 : loss : 0.036193, loss_ce: 0.012948
2022-01-16 00:26:44,106 iteration 2744 : loss : 0.027659, loss_ce: 0.009758
2022-01-16 00:26:45,007 iteration 2745 : loss : 0.028235, loss_ce: 0.008941
2022-01-16 00:26:46,063 iteration 2746 : loss : 0.068063, loss_ce: 0.020238
2022-01-16 00:26:46,981 iteration 2747 : loss : 0.036194, loss_ce: 0.014012
2022-01-16 00:26:47,975 iteration 2748 : loss : 0.030776, loss_ce: 0.008212
2022-01-16 00:26:49,007 iteration 2749 : loss : 0.037243, loss_ce: 0.013668
2022-01-16 00:26:49,941 iteration 2750 : loss : 0.035362, loss_ce: 0.013387
2022-01-16 00:26:50,888 iteration 2751 : loss : 0.055744, loss_ce: 0.015484
2022-01-16 00:26:51,954 iteration 2752 : loss : 0.046360, loss_ce: 0.017155
2022-01-16 00:26:53,028 iteration 2753 : loss : 0.033444, loss_ce: 0.014376
2022-01-16 00:26:53,996 iteration 2754 : loss : 0.033226, loss_ce: 0.016235
 40%|███████████▋                 | 162/400 [47:47<1:09:05, 17.42s/it]2022-01-16 00:26:54,866 iteration 2755 : loss : 0.030279, loss_ce: 0.009494
2022-01-16 00:26:55,833 iteration 2756 : loss : 0.036082, loss_ce: 0.013803
2022-01-16 00:26:56,782 iteration 2757 : loss : 0.028557, loss_ce: 0.012535
2022-01-16 00:26:57,729 iteration 2758 : loss : 0.032582, loss_ce: 0.012658
2022-01-16 00:26:58,674 iteration 2759 : loss : 0.046575, loss_ce: 0.019833
2022-01-16 00:26:59,625 iteration 2760 : loss : 0.027035, loss_ce: 0.012689
2022-01-16 00:27:00,620 iteration 2761 : loss : 0.032328, loss_ce: 0.011137
2022-01-16 00:27:01,564 iteration 2762 : loss : 0.027458, loss_ce: 0.011477
2022-01-16 00:27:02,551 iteration 2763 : loss : 0.056133, loss_ce: 0.019132
2022-01-16 00:27:03,434 iteration 2764 : loss : 0.022232, loss_ce: 0.008170
2022-01-16 00:27:04,500 iteration 2765 : loss : 0.029136, loss_ce: 0.009735
2022-01-16 00:27:05,370 iteration 2766 : loss : 0.034715, loss_ce: 0.012256
2022-01-16 00:27:06,336 iteration 2767 : loss : 0.030756, loss_ce: 0.012307
2022-01-16 00:27:07,264 iteration 2768 : loss : 0.036275, loss_ce: 0.011987
2022-01-16 00:27:08,142 iteration 2769 : loss : 0.027130, loss_ce: 0.012004
2022-01-16 00:27:09,054 iteration 2770 : loss : 0.034881, loss_ce: 0.016166
2022-01-16 00:27:09,997 iteration 2771 : loss : 0.027573, loss_ce: 0.011860
 41%|███████████▊                 | 163/400 [48:03<1:07:07, 16.99s/it]2022-01-16 00:27:10,930 iteration 2772 : loss : 0.029202, loss_ce: 0.010277
2022-01-16 00:27:11,889 iteration 2773 : loss : 0.026622, loss_ce: 0.011175
2022-01-16 00:27:12,847 iteration 2774 : loss : 0.036143, loss_ce: 0.009398
2022-01-16 00:27:13,817 iteration 2775 : loss : 0.040510, loss_ce: 0.017614
2022-01-16 00:27:14,748 iteration 2776 : loss : 0.033575, loss_ce: 0.011669
2022-01-16 00:27:15,762 iteration 2777 : loss : 0.022998, loss_ce: 0.008477
2022-01-16 00:27:16,665 iteration 2778 : loss : 0.041192, loss_ce: 0.015373
2022-01-16 00:27:17,574 iteration 2779 : loss : 0.027827, loss_ce: 0.010775
2022-01-16 00:27:18,508 iteration 2780 : loss : 0.025823, loss_ce: 0.012724
2022-01-16 00:27:19,585 iteration 2781 : loss : 0.035829, loss_ce: 0.012468
2022-01-16 00:27:20,617 iteration 2782 : loss : 0.033047, loss_ce: 0.014744
2022-01-16 00:27:21,556 iteration 2783 : loss : 0.024907, loss_ce: 0.007369
2022-01-16 00:27:22,387 iteration 2784 : loss : 0.031435, loss_ce: 0.008735
2022-01-16 00:27:23,273 iteration 2785 : loss : 0.027876, loss_ce: 0.012471
2022-01-16 00:27:24,154 iteration 2786 : loss : 0.026971, loss_ce: 0.010984
2022-01-16 00:27:25,060 iteration 2787 : loss : 0.027998, loss_ce: 0.010738
2022-01-16 00:27:26,152 iteration 2788 : loss : 0.041657, loss_ce: 0.016144
 41%|███████████▉                 | 164/400 [48:19<1:05:51, 16.74s/it]2022-01-16 00:27:27,188 iteration 2789 : loss : 0.027190, loss_ce: 0.008274
2022-01-16 00:27:28,237 iteration 2790 : loss : 0.042471, loss_ce: 0.018232
2022-01-16 00:27:29,119 iteration 2791 : loss : 0.023349, loss_ce: 0.007220
2022-01-16 00:27:30,049 iteration 2792 : loss : 0.031560, loss_ce: 0.012465
2022-01-16 00:27:30,997 iteration 2793 : loss : 0.034356, loss_ce: 0.011343
2022-01-16 00:27:32,011 iteration 2794 : loss : 0.033628, loss_ce: 0.016589
2022-01-16 00:27:32,955 iteration 2795 : loss : 0.035509, loss_ce: 0.014887
2022-01-16 00:27:33,870 iteration 2796 : loss : 0.033207, loss_ce: 0.010964
2022-01-16 00:27:34,866 iteration 2797 : loss : 0.034968, loss_ce: 0.016063
2022-01-16 00:27:35,844 iteration 2798 : loss : 0.037450, loss_ce: 0.010930
2022-01-16 00:27:36,895 iteration 2799 : loss : 0.034309, loss_ce: 0.011992
2022-01-16 00:27:37,869 iteration 2800 : loss : 0.037627, loss_ce: 0.018402
2022-01-16 00:27:38,725 iteration 2801 : loss : 0.034700, loss_ce: 0.009362
2022-01-16 00:27:39,623 iteration 2802 : loss : 0.023583, loss_ce: 0.008814
2022-01-16 00:27:40,586 iteration 2803 : loss : 0.030856, loss_ce: 0.011848
2022-01-16 00:27:41,440 iteration 2804 : loss : 0.034522, loss_ce: 0.015147
2022-01-16 00:27:41,440 Training Data Eval:
2022-01-16 00:27:45,968   Average segmentation loss on training set: 0.0248
2022-01-16 00:27:45,968 Validation Data Eval:
2022-01-16 00:27:47,453   Average segmentation loss on validation set: 0.1235
2022-01-16 00:27:48,501 iteration 2805 : loss : 0.033041, loss_ce: 0.012394
 41%|███████████▉                 | 165/400 [48:41<1:12:10, 18.43s/it]2022-01-16 00:27:49,601 iteration 2806 : loss : 0.062108, loss_ce: 0.030431
2022-01-16 00:27:50,649 iteration 2807 : loss : 0.043991, loss_ce: 0.014559
2022-01-16 00:27:51,656 iteration 2808 : loss : 0.046040, loss_ce: 0.014065
2022-01-16 00:27:52,637 iteration 2809 : loss : 0.029828, loss_ce: 0.011746
2022-01-16 00:27:53,509 iteration 2810 : loss : 0.063514, loss_ce: 0.024201
2022-01-16 00:27:54,509 iteration 2811 : loss : 0.025375, loss_ce: 0.011725
2022-01-16 00:27:55,390 iteration 2812 : loss : 0.019846, loss_ce: 0.008387
2022-01-16 00:27:56,418 iteration 2813 : loss : 0.039837, loss_ce: 0.017177
2022-01-16 00:27:57,390 iteration 2814 : loss : 0.034720, loss_ce: 0.012380
2022-01-16 00:27:58,340 iteration 2815 : loss : 0.033410, loss_ce: 0.015451
2022-01-16 00:27:59,287 iteration 2816 : loss : 0.035394, loss_ce: 0.012888
2022-01-16 00:28:00,335 iteration 2817 : loss : 0.129267, loss_ce: 0.039140
2022-01-16 00:28:01,352 iteration 2818 : loss : 0.046649, loss_ce: 0.019167
2022-01-16 00:28:02,286 iteration 2819 : loss : 0.037352, loss_ce: 0.016695
2022-01-16 00:28:03,351 iteration 2820 : loss : 0.068592, loss_ce: 0.026999
2022-01-16 00:28:04,386 iteration 2821 : loss : 0.035960, loss_ce: 0.013093
2022-01-16 00:28:05,384 iteration 2822 : loss : 0.046794, loss_ce: 0.017772
 42%|████████████                 | 166/400 [48:58<1:10:03, 17.96s/it]2022-01-16 00:28:06,517 iteration 2823 : loss : 0.045373, loss_ce: 0.020847
2022-01-16 00:28:07,440 iteration 2824 : loss : 0.032117, loss_ce: 0.016139
2022-01-16 00:28:08,414 iteration 2825 : loss : 0.048560, loss_ce: 0.022940
2022-01-16 00:28:09,486 iteration 2826 : loss : 0.052598, loss_ce: 0.020269
2022-01-16 00:28:10,578 iteration 2827 : loss : 0.061154, loss_ce: 0.021509
2022-01-16 00:28:11,569 iteration 2828 : loss : 0.029193, loss_ce: 0.009949
2022-01-16 00:28:12,527 iteration 2829 : loss : 0.036144, loss_ce: 0.016402
2022-01-16 00:28:13,468 iteration 2830 : loss : 0.040286, loss_ce: 0.017052
2022-01-16 00:28:14,319 iteration 2831 : loss : 0.028968, loss_ce: 0.012612
2022-01-16 00:28:15,417 iteration 2832 : loss : 0.044873, loss_ce: 0.018532
2022-01-16 00:28:16,358 iteration 2833 : loss : 0.035627, loss_ce: 0.012694
2022-01-16 00:28:17,382 iteration 2834 : loss : 0.037029, loss_ce: 0.011921
2022-01-16 00:28:18,375 iteration 2835 : loss : 0.049869, loss_ce: 0.015912
2022-01-16 00:28:19,336 iteration 2836 : loss : 0.036675, loss_ce: 0.012754
2022-01-16 00:28:20,362 iteration 2837 : loss : 0.039948, loss_ce: 0.016956
2022-01-16 00:28:21,253 iteration 2838 : loss : 0.026425, loss_ce: 0.011922
2022-01-16 00:28:22,276 iteration 2839 : loss : 0.032349, loss_ce: 0.012393
 42%|████████████                 | 167/400 [49:15<1:08:29, 17.64s/it]2022-01-16 00:28:23,362 iteration 2840 : loss : 0.038857, loss_ce: 0.013559
2022-01-16 00:28:24,307 iteration 2841 : loss : 0.026709, loss_ce: 0.008553
2022-01-16 00:28:25,252 iteration 2842 : loss : 0.031935, loss_ce: 0.010550
2022-01-16 00:28:26,261 iteration 2843 : loss : 0.037539, loss_ce: 0.011938
2022-01-16 00:28:27,239 iteration 2844 : loss : 0.042818, loss_ce: 0.017480
2022-01-16 00:28:28,190 iteration 2845 : loss : 0.035073, loss_ce: 0.011705
2022-01-16 00:28:29,154 iteration 2846 : loss : 0.027219, loss_ce: 0.009895
2022-01-16 00:28:29,976 iteration 2847 : loss : 0.022199, loss_ce: 0.011592
2022-01-16 00:28:30,945 iteration 2848 : loss : 0.036908, loss_ce: 0.012381
2022-01-16 00:28:31,965 iteration 2849 : loss : 0.037435, loss_ce: 0.014302
2022-01-16 00:28:32,967 iteration 2850 : loss : 0.049957, loss_ce: 0.017818
2022-01-16 00:28:33,984 iteration 2851 : loss : 0.031798, loss_ce: 0.011155
2022-01-16 00:28:34,969 iteration 2852 : loss : 0.041047, loss_ce: 0.011248
2022-01-16 00:28:35,999 iteration 2853 : loss : 0.026631, loss_ce: 0.009184
2022-01-16 00:28:36,996 iteration 2854 : loss : 0.027726, loss_ce: 0.010266
2022-01-16 00:28:37,918 iteration 2855 : loss : 0.028921, loss_ce: 0.014455
2022-01-16 00:28:38,917 iteration 2856 : loss : 0.042831, loss_ce: 0.020999
 42%|████████████▏                | 168/400 [49:32<1:07:03, 17.34s/it]2022-01-16 00:28:39,841 iteration 2857 : loss : 0.024674, loss_ce: 0.008975
2022-01-16 00:28:40,809 iteration 2858 : loss : 0.033181, loss_ce: 0.014936
2022-01-16 00:28:41,735 iteration 2859 : loss : 0.021802, loss_ce: 0.009539
2022-01-16 00:28:42,733 iteration 2860 : loss : 0.040672, loss_ce: 0.012922
2022-01-16 00:28:43,593 iteration 2861 : loss : 0.031608, loss_ce: 0.013373
2022-01-16 00:28:44,650 iteration 2862 : loss : 0.074590, loss_ce: 0.022443
2022-01-16 00:28:45,556 iteration 2863 : loss : 0.050868, loss_ce: 0.014807
2022-01-16 00:28:46,544 iteration 2864 : loss : 0.024696, loss_ce: 0.009493
2022-01-16 00:28:47,548 iteration 2865 : loss : 0.038478, loss_ce: 0.016788
2022-01-16 00:28:48,483 iteration 2866 : loss : 0.029428, loss_ce: 0.011025
2022-01-16 00:28:49,561 iteration 2867 : loss : 0.032475, loss_ce: 0.014182
2022-01-16 00:28:50,475 iteration 2868 : loss : 0.029450, loss_ce: 0.010497
2022-01-16 00:28:51,526 iteration 2869 : loss : 0.044862, loss_ce: 0.015476
2022-01-16 00:28:52,518 iteration 2870 : loss : 0.028349, loss_ce: 0.010484
2022-01-16 00:28:53,443 iteration 2871 : loss : 0.031486, loss_ce: 0.012270
2022-01-16 00:28:54,313 iteration 2872 : loss : 0.031084, loss_ce: 0.011279
2022-01-16 00:28:55,325 iteration 2873 : loss : 0.057659, loss_ce: 0.014927
 42%|████████████▎                | 169/400 [49:48<1:05:41, 17.06s/it]2022-01-16 00:28:56,392 iteration 2874 : loss : 0.032656, loss_ce: 0.009973
2022-01-16 00:28:57,373 iteration 2875 : loss : 0.026641, loss_ce: 0.011019
2022-01-16 00:28:58,342 iteration 2876 : loss : 0.036325, loss_ce: 0.015694
2022-01-16 00:28:59,370 iteration 2877 : loss : 0.057285, loss_ce: 0.014399
2022-01-16 00:29:00,335 iteration 2878 : loss : 0.030040, loss_ce: 0.013633
2022-01-16 00:29:01,354 iteration 2879 : loss : 0.033343, loss_ce: 0.011309
2022-01-16 00:29:02,384 iteration 2880 : loss : 0.030536, loss_ce: 0.010495
2022-01-16 00:29:03,360 iteration 2881 : loss : 0.026841, loss_ce: 0.011071
2022-01-16 00:29:04,390 iteration 2882 : loss : 0.029585, loss_ce: 0.013816
2022-01-16 00:29:05,316 iteration 2883 : loss : 0.039827, loss_ce: 0.015624
2022-01-16 00:29:06,258 iteration 2884 : loss : 0.029110, loss_ce: 0.012628
2022-01-16 00:29:07,246 iteration 2885 : loss : 0.035894, loss_ce: 0.016251
2022-01-16 00:29:08,113 iteration 2886 : loss : 0.045465, loss_ce: 0.015486
2022-01-16 00:29:09,153 iteration 2887 : loss : 0.038188, loss_ce: 0.017957
2022-01-16 00:29:10,128 iteration 2888 : loss : 0.058708, loss_ce: 0.014523
2022-01-16 00:29:11,209 iteration 2889 : loss : 0.027622, loss_ce: 0.009324
2022-01-16 00:29:11,209 Training Data Eval:
2022-01-16 00:29:15,734   Average segmentation loss on training set: 0.0292
2022-01-16 00:29:15,734 Validation Data Eval:
2022-01-16 00:29:17,209   Average segmentation loss on validation set: 0.2081
2022-01-16 00:29:18,222 iteration 2890 : loss : 0.024939, loss_ce: 0.007626
 42%|████████████▎                | 170/400 [50:11<1:12:06, 18.81s/it]2022-01-16 00:29:19,282 iteration 2891 : loss : 0.055026, loss_ce: 0.022586
2022-01-16 00:29:20,335 iteration 2892 : loss : 0.038404, loss_ce: 0.010458
2022-01-16 00:29:21,248 iteration 2893 : loss : 0.028306, loss_ce: 0.009279
2022-01-16 00:29:22,298 iteration 2894 : loss : 0.043314, loss_ce: 0.011955
2022-01-16 00:29:23,326 iteration 2895 : loss : 0.057997, loss_ce: 0.029656
2022-01-16 00:29:24,256 iteration 2896 : loss : 0.025005, loss_ce: 0.008376
2022-01-16 00:29:25,227 iteration 2897 : loss : 0.047897, loss_ce: 0.020850
2022-01-16 00:29:26,130 iteration 2898 : loss : 0.031579, loss_ce: 0.012737
2022-01-16 00:29:27,122 iteration 2899 : loss : 0.048164, loss_ce: 0.017317
2022-01-16 00:29:28,075 iteration 2900 : loss : 0.029059, loss_ce: 0.010511
2022-01-16 00:29:29,048 iteration 2901 : loss : 0.032130, loss_ce: 0.009579
2022-01-16 00:29:29,930 iteration 2902 : loss : 0.043398, loss_ce: 0.016998
2022-01-16 00:29:30,846 iteration 2903 : loss : 0.028529, loss_ce: 0.013909
2022-01-16 00:29:31,751 iteration 2904 : loss : 0.031586, loss_ce: 0.012543
2022-01-16 00:29:32,629 iteration 2905 : loss : 0.028549, loss_ce: 0.013108
2022-01-16 00:29:33,628 iteration 2906 : loss : 0.037219, loss_ce: 0.018447
2022-01-16 00:29:34,544 iteration 2907 : loss : 0.034677, loss_ce: 0.012825
 43%|████████████▍                | 171/400 [50:27<1:08:57, 18.07s/it]2022-01-16 00:29:35,602 iteration 2908 : loss : 0.056244, loss_ce: 0.028571
2022-01-16 00:29:36,627 iteration 2909 : loss : 0.033675, loss_ce: 0.016939
2022-01-16 00:29:37,600 iteration 2910 : loss : 0.039618, loss_ce: 0.016044
2022-01-16 00:29:38,615 iteration 2911 : loss : 0.033709, loss_ce: 0.010022
2022-01-16 00:29:39,546 iteration 2912 : loss : 0.027581, loss_ce: 0.009907
2022-01-16 00:29:40,580 iteration 2913 : loss : 0.029493, loss_ce: 0.013165
2022-01-16 00:29:41,517 iteration 2914 : loss : 0.040294, loss_ce: 0.014640
2022-01-16 00:29:42,459 iteration 2915 : loss : 0.026537, loss_ce: 0.010749
2022-01-16 00:29:43,438 iteration 2916 : loss : 0.024989, loss_ce: 0.009860
2022-01-16 00:29:44,323 iteration 2917 : loss : 0.037276, loss_ce: 0.016688
2022-01-16 00:29:45,240 iteration 2918 : loss : 0.028674, loss_ce: 0.007888
2022-01-16 00:29:46,194 iteration 2919 : loss : 0.029228, loss_ce: 0.008996
2022-01-16 00:29:47,175 iteration 2920 : loss : 0.030803, loss_ce: 0.011284
2022-01-16 00:29:48,124 iteration 2921 : loss : 0.031367, loss_ce: 0.014463
2022-01-16 00:29:49,003 iteration 2922 : loss : 0.027498, loss_ce: 0.009857
2022-01-16 00:29:49,924 iteration 2923 : loss : 0.029782, loss_ce: 0.009686
2022-01-16 00:29:50,881 iteration 2924 : loss : 0.037684, loss_ce: 0.014379
 43%|████████████▍                | 172/400 [50:43<1:06:40, 17.55s/it]2022-01-16 00:29:51,789 iteration 2925 : loss : 0.023977, loss_ce: 0.011706
2022-01-16 00:29:52,835 iteration 2926 : loss : 0.035243, loss_ce: 0.014695
2022-01-16 00:29:53,789 iteration 2927 : loss : 0.031364, loss_ce: 0.012499
2022-01-16 00:29:54,616 iteration 2928 : loss : 0.028514, loss_ce: 0.009144
2022-01-16 00:29:55,541 iteration 2929 : loss : 0.028416, loss_ce: 0.013715
2022-01-16 00:29:56,581 iteration 2930 : loss : 0.036837, loss_ce: 0.017095
2022-01-16 00:29:57,510 iteration 2931 : loss : 0.027340, loss_ce: 0.010130
2022-01-16 00:29:58,409 iteration 2932 : loss : 0.028472, loss_ce: 0.009966
2022-01-16 00:29:59,448 iteration 2933 : loss : 0.037286, loss_ce: 0.011975
2022-01-16 00:30:00,397 iteration 2934 : loss : 0.036558, loss_ce: 0.014773
2022-01-16 00:30:01,363 iteration 2935 : loss : 0.027486, loss_ce: 0.008588
2022-01-16 00:30:02,311 iteration 2936 : loss : 0.020734, loss_ce: 0.006243
2022-01-16 00:30:03,297 iteration 2937 : loss : 0.027647, loss_ce: 0.013545
2022-01-16 00:30:04,316 iteration 2938 : loss : 0.049208, loss_ce: 0.017283
2022-01-16 00:30:05,324 iteration 2939 : loss : 0.026563, loss_ce: 0.008856
2022-01-16 00:30:06,396 iteration 2940 : loss : 0.037559, loss_ce: 0.016772
2022-01-16 00:30:07,298 iteration 2941 : loss : 0.023189, loss_ce: 0.007085
 43%|████████████▌                | 173/400 [51:00<1:05:06, 17.21s/it]2022-01-16 00:30:08,261 iteration 2942 : loss : 0.020290, loss_ce: 0.006300
2022-01-16 00:30:09,250 iteration 2943 : loss : 0.038332, loss_ce: 0.010929
2022-01-16 00:30:10,163 iteration 2944 : loss : 0.027332, loss_ce: 0.013634
2022-01-16 00:30:11,126 iteration 2945 : loss : 0.025614, loss_ce: 0.007501
2022-01-16 00:30:11,969 iteration 2946 : loss : 0.023249, loss_ce: 0.009629
2022-01-16 00:30:12,886 iteration 2947 : loss : 0.025893, loss_ce: 0.010222
2022-01-16 00:30:13,798 iteration 2948 : loss : 0.026195, loss_ce: 0.007094
2022-01-16 00:30:14,832 iteration 2949 : loss : 0.036686, loss_ce: 0.013885
2022-01-16 00:30:15,809 iteration 2950 : loss : 0.028182, loss_ce: 0.013291
2022-01-16 00:30:16,808 iteration 2951 : loss : 0.028311, loss_ce: 0.011909
2022-01-16 00:30:17,799 iteration 2952 : loss : 0.021657, loss_ce: 0.007225
2022-01-16 00:30:18,827 iteration 2953 : loss : 0.043219, loss_ce: 0.022067
2022-01-16 00:30:19,904 iteration 2954 : loss : 0.060972, loss_ce: 0.016569
2022-01-16 00:30:20,823 iteration 2955 : loss : 0.025129, loss_ce: 0.010842
2022-01-16 00:30:21,756 iteration 2956 : loss : 0.028876, loss_ce: 0.011564
2022-01-16 00:30:22,653 iteration 2957 : loss : 0.034057, loss_ce: 0.013712
2022-01-16 00:30:23,618 iteration 2958 : loss : 0.036174, loss_ce: 0.018873
 44%|████████████▌                | 174/400 [51:16<1:03:48, 16.94s/it]2022-01-16 00:30:24,625 iteration 2959 : loss : 0.023545, loss_ce: 0.008539
2022-01-16 00:30:25,560 iteration 2960 : loss : 0.028168, loss_ce: 0.011988
2022-01-16 00:30:26,531 iteration 2961 : loss : 0.034435, loss_ce: 0.012991
2022-01-16 00:30:27,658 iteration 2962 : loss : 0.034023, loss_ce: 0.012880
2022-01-16 00:30:28,639 iteration 2963 : loss : 0.040106, loss_ce: 0.013614
2022-01-16 00:30:29,497 iteration 2964 : loss : 0.025613, loss_ce: 0.008107
2022-01-16 00:30:30,465 iteration 2965 : loss : 0.030318, loss_ce: 0.016621
2022-01-16 00:30:31,468 iteration 2966 : loss : 0.033493, loss_ce: 0.011079
2022-01-16 00:30:32,410 iteration 2967 : loss : 0.039913, loss_ce: 0.013816
2022-01-16 00:30:33,378 iteration 2968 : loss : 0.028480, loss_ce: 0.010960
2022-01-16 00:30:34,311 iteration 2969 : loss : 0.029668, loss_ce: 0.012622
2022-01-16 00:30:35,281 iteration 2970 : loss : 0.036970, loss_ce: 0.014551
2022-01-16 00:30:36,217 iteration 2971 : loss : 0.021950, loss_ce: 0.007579
2022-01-16 00:30:37,164 iteration 2972 : loss : 0.037468, loss_ce: 0.015004
2022-01-16 00:30:38,060 iteration 2973 : loss : 0.026581, loss_ce: 0.006437
2022-01-16 00:30:39,082 iteration 2974 : loss : 0.043568, loss_ce: 0.013100
2022-01-16 00:30:39,082 Training Data Eval:
2022-01-16 00:30:43,609   Average segmentation loss on training set: 0.0223
2022-01-16 00:30:43,609 Validation Data Eval:
2022-01-16 00:30:45,102   Average segmentation loss on validation set: 0.1473
2022-01-16 00:30:46,025 iteration 2975 : loss : 0.023078, loss_ce: 0.008742
 44%|████████████▋                | 175/400 [51:39<1:09:40, 18.58s/it]2022-01-16 00:30:46,951 iteration 2976 : loss : 0.021892, loss_ce: 0.008593
2022-01-16 00:30:47,944 iteration 2977 : loss : 0.024208, loss_ce: 0.011075
2022-01-16 00:30:48,916 iteration 2978 : loss : 0.028747, loss_ce: 0.008526
2022-01-16 00:30:49,930 iteration 2979 : loss : 0.035930, loss_ce: 0.012691
2022-01-16 00:30:50,929 iteration 2980 : loss : 0.036534, loss_ce: 0.009962
2022-01-16 00:30:52,003 iteration 2981 : loss : 0.049302, loss_ce: 0.021902
2022-01-16 00:30:52,967 iteration 2982 : loss : 0.019631, loss_ce: 0.007295
2022-01-16 00:30:53,941 iteration 2983 : loss : 0.034695, loss_ce: 0.013857
2022-01-16 00:30:54,915 iteration 2984 : loss : 0.037091, loss_ce: 0.012575
2022-01-16 00:30:55,914 iteration 2985 : loss : 0.036233, loss_ce: 0.012397
2022-01-16 00:30:56,806 iteration 2986 : loss : 0.034043, loss_ce: 0.017226
2022-01-16 00:30:57,774 iteration 2987 : loss : 0.039338, loss_ce: 0.013049
2022-01-16 00:30:58,791 iteration 2988 : loss : 0.026117, loss_ce: 0.009414
2022-01-16 00:30:59,794 iteration 2989 : loss : 0.037898, loss_ce: 0.013782
2022-01-16 00:31:00,689 iteration 2990 : loss : 0.019919, loss_ce: 0.008515
2022-01-16 00:31:01,644 iteration 2991 : loss : 0.024662, loss_ce: 0.009761
2022-01-16 00:31:02,683 iteration 2992 : loss : 0.030010, loss_ce: 0.012826
 44%|████████████▊                | 176/400 [51:55<1:07:12, 18.00s/it]2022-01-16 00:31:03,646 iteration 2993 : loss : 0.026596, loss_ce: 0.012645
2022-01-16 00:31:04,622 iteration 2994 : loss : 0.052728, loss_ce: 0.012554
2022-01-16 00:31:05,556 iteration 2995 : loss : 0.022968, loss_ce: 0.008009
2022-01-16 00:31:06,501 iteration 2996 : loss : 0.023392, loss_ce: 0.012411
2022-01-16 00:31:07,452 iteration 2997 : loss : 0.049626, loss_ce: 0.017797
2022-01-16 00:31:08,422 iteration 2998 : loss : 0.031131, loss_ce: 0.015039
2022-01-16 00:31:09,445 iteration 2999 : loss : 0.047934, loss_ce: 0.010383
2022-01-16 00:31:10,493 iteration 3000 : loss : 0.040249, loss_ce: 0.016719
2022-01-16 00:31:11,535 iteration 3001 : loss : 0.042620, loss_ce: 0.011641
2022-01-16 00:31:12,435 iteration 3002 : loss : 0.029378, loss_ce: 0.011714
2022-01-16 00:31:13,366 iteration 3003 : loss : 0.028811, loss_ce: 0.010449
2022-01-16 00:31:14,302 iteration 3004 : loss : 0.028861, loss_ce: 0.012210
2022-01-16 00:31:15,267 iteration 3005 : loss : 0.034988, loss_ce: 0.015534
2022-01-16 00:31:16,267 iteration 3006 : loss : 0.025329, loss_ce: 0.009681
2022-01-16 00:31:17,255 iteration 3007 : loss : 0.033730, loss_ce: 0.014295
2022-01-16 00:31:18,249 iteration 3008 : loss : 0.037787, loss_ce: 0.012475
2022-01-16 00:31:19,125 iteration 3009 : loss : 0.031375, loss_ce: 0.014018
 44%|████████████▊                | 177/400 [52:12<1:05:10, 17.53s/it]2022-01-16 00:31:20,279 iteration 3010 : loss : 0.039392, loss_ce: 0.013488
2022-01-16 00:31:21,285 iteration 3011 : loss : 0.030396, loss_ce: 0.013781
2022-01-16 00:31:22,192 iteration 3012 : loss : 0.021750, loss_ce: 0.008892
2022-01-16 00:31:23,080 iteration 3013 : loss : 0.039098, loss_ce: 0.013311
2022-01-16 00:31:24,046 iteration 3014 : loss : 0.026781, loss_ce: 0.009085
2022-01-16 00:31:24,991 iteration 3015 : loss : 0.051583, loss_ce: 0.012327
2022-01-16 00:31:25,935 iteration 3016 : loss : 0.045228, loss_ce: 0.021677
2022-01-16 00:31:26,860 iteration 3017 : loss : 0.029476, loss_ce: 0.015133
2022-01-16 00:31:27,780 iteration 3018 : loss : 0.022735, loss_ce: 0.009656
2022-01-16 00:31:28,659 iteration 3019 : loss : 0.035758, loss_ce: 0.014602
2022-01-16 00:31:29,645 iteration 3020 : loss : 0.045652, loss_ce: 0.016666
2022-01-16 00:31:30,613 iteration 3021 : loss : 0.017887, loss_ce: 0.005994
2022-01-16 00:31:31,544 iteration 3022 : loss : 0.025349, loss_ce: 0.009220
2022-01-16 00:31:32,509 iteration 3023 : loss : 0.035692, loss_ce: 0.014953
2022-01-16 00:31:33,562 iteration 3024 : loss : 0.030942, loss_ce: 0.011775
2022-01-16 00:31:34,586 iteration 3025 : loss : 0.052235, loss_ce: 0.024327
2022-01-16 00:31:35,494 iteration 3026 : loss : 0.027748, loss_ce: 0.011066
 44%|████████████▉                | 178/400 [52:28<1:03:34, 17.18s/it]2022-01-16 00:31:36,575 iteration 3027 : loss : 0.034994, loss_ce: 0.012687
2022-01-16 00:31:37,485 iteration 3028 : loss : 0.032260, loss_ce: 0.011559
2022-01-16 00:31:38,461 iteration 3029 : loss : 0.027159, loss_ce: 0.010848
2022-01-16 00:31:39,381 iteration 3030 : loss : 0.023578, loss_ce: 0.010010
2022-01-16 00:31:40,344 iteration 3031 : loss : 0.032126, loss_ce: 0.012657
2022-01-16 00:31:41,257 iteration 3032 : loss : 0.028949, loss_ce: 0.009553
2022-01-16 00:31:42,245 iteration 3033 : loss : 0.042115, loss_ce: 0.013116
2022-01-16 00:31:43,259 iteration 3034 : loss : 0.027137, loss_ce: 0.009391
2022-01-16 00:31:44,236 iteration 3035 : loss : 0.028494, loss_ce: 0.012500
2022-01-16 00:31:45,174 iteration 3036 : loss : 0.032955, loss_ce: 0.016255
2022-01-16 00:31:46,126 iteration 3037 : loss : 0.037984, loss_ce: 0.013933
2022-01-16 00:31:47,118 iteration 3038 : loss : 0.038737, loss_ce: 0.015101
2022-01-16 00:31:48,002 iteration 3039 : loss : 0.030124, loss_ce: 0.009657
2022-01-16 00:31:48,971 iteration 3040 : loss : 0.038745, loss_ce: 0.009785
2022-01-16 00:31:49,975 iteration 3041 : loss : 0.036793, loss_ce: 0.017746
2022-01-16 00:31:50,927 iteration 3042 : loss : 0.027694, loss_ce: 0.012332
2022-01-16 00:31:52,083 iteration 3043 : loss : 0.040935, loss_ce: 0.012399
 45%|████████████▉                | 179/400 [52:45<1:02:38, 17.01s/it]2022-01-16 00:31:53,126 iteration 3044 : loss : 0.030642, loss_ce: 0.011603
2022-01-16 00:31:54,024 iteration 3045 : loss : 0.031261, loss_ce: 0.010956
2022-01-16 00:31:54,955 iteration 3046 : loss : 0.023017, loss_ce: 0.007512
2022-01-16 00:31:56,032 iteration 3047 : loss : 0.064829, loss_ce: 0.038115
2022-01-16 00:31:56,946 iteration 3048 : loss : 0.027570, loss_ce: 0.009187
2022-01-16 00:31:57,910 iteration 3049 : loss : 0.032197, loss_ce: 0.012905
2022-01-16 00:31:58,903 iteration 3050 : loss : 0.032362, loss_ce: 0.014009
2022-01-16 00:31:59,874 iteration 3051 : loss : 0.029568, loss_ce: 0.008177
2022-01-16 00:32:00,814 iteration 3052 : loss : 0.031703, loss_ce: 0.010750
2022-01-16 00:32:01,866 iteration 3053 : loss : 0.027010, loss_ce: 0.012229
2022-01-16 00:32:02,774 iteration 3054 : loss : 0.035642, loss_ce: 0.011402
2022-01-16 00:32:03,763 iteration 3055 : loss : 0.034929, loss_ce: 0.013525
2022-01-16 00:32:04,691 iteration 3056 : loss : 0.024963, loss_ce: 0.010590
2022-01-16 00:32:05,585 iteration 3057 : loss : 0.023551, loss_ce: 0.008912
2022-01-16 00:32:06,565 iteration 3058 : loss : 0.023527, loss_ce: 0.009447
2022-01-16 00:32:07,566 iteration 3059 : loss : 0.029379, loss_ce: 0.009847
2022-01-16 00:32:07,566 Training Data Eval:
2022-01-16 00:32:12,096   Average segmentation loss on training set: 0.0200
2022-01-16 00:32:12,097 Validation Data Eval:
2022-01-16 00:32:13,591   Average segmentation loss on validation set: 0.0811
2022-01-16 00:32:14,503 iteration 3060 : loss : 0.025721, loss_ce: 0.012396
 45%|█████████████                | 180/400 [53:07<1:08:19, 18.63s/it]2022-01-16 00:32:15,430 iteration 3061 : loss : 0.025174, loss_ce: 0.009696
2022-01-16 00:32:16,382 iteration 3062 : loss : 0.039131, loss_ce: 0.015453
2022-01-16 00:32:17,377 iteration 3063 : loss : 0.027382, loss_ce: 0.010722
2022-01-16 00:32:18,376 iteration 3064 : loss : 0.026807, loss_ce: 0.011785
2022-01-16 00:32:19,225 iteration 3065 : loss : 0.022416, loss_ce: 0.007277
2022-01-16 00:32:20,141 iteration 3066 : loss : 0.027516, loss_ce: 0.012917
2022-01-16 00:32:21,124 iteration 3067 : loss : 0.033848, loss_ce: 0.014362
2022-01-16 00:32:22,094 iteration 3068 : loss : 0.037129, loss_ce: 0.012615
2022-01-16 00:32:23,053 iteration 3069 : loss : 0.032178, loss_ce: 0.009171
2022-01-16 00:32:24,016 iteration 3070 : loss : 0.020845, loss_ce: 0.008576
2022-01-16 00:32:24,910 iteration 3071 : loss : 0.024884, loss_ce: 0.010156
2022-01-16 00:32:25,803 iteration 3072 : loss : 0.024477, loss_ce: 0.009556
2022-01-16 00:32:26,736 iteration 3073 : loss : 0.029101, loss_ce: 0.009979
2022-01-16 00:32:27,770 iteration 3074 : loss : 0.038040, loss_ce: 0.013854
2022-01-16 00:32:28,766 iteration 3075 : loss : 0.028657, loss_ce: 0.009916
2022-01-16 00:32:29,800 iteration 3076 : loss : 0.034734, loss_ce: 0.011643
2022-01-16 00:32:30,703 iteration 3077 : loss : 0.031019, loss_ce: 0.011624
 45%|█████████████                | 181/400 [53:23<1:05:19, 17.90s/it]2022-01-16 00:32:31,656 iteration 3078 : loss : 0.028000, loss_ce: 0.011409
2022-01-16 00:32:32,736 iteration 3079 : loss : 0.026248, loss_ce: 0.008741
2022-01-16 00:32:33,635 iteration 3080 : loss : 0.031138, loss_ce: 0.009004
2022-01-16 00:32:34,623 iteration 3081 : loss : 0.030039, loss_ce: 0.009485
2022-01-16 00:32:35,562 iteration 3082 : loss : 0.042068, loss_ce: 0.010406
2022-01-16 00:32:36,576 iteration 3083 : loss : 0.037434, loss_ce: 0.014935
2022-01-16 00:32:37,401 iteration 3084 : loss : 0.024521, loss_ce: 0.010187
2022-01-16 00:32:38,380 iteration 3085 : loss : 0.029712, loss_ce: 0.013228
2022-01-16 00:32:39,444 iteration 3086 : loss : 0.025387, loss_ce: 0.012214
2022-01-16 00:32:40,377 iteration 3087 : loss : 0.032476, loss_ce: 0.013579
2022-01-16 00:32:41,346 iteration 3088 : loss : 0.020629, loss_ce: 0.006146
2022-01-16 00:32:42,404 iteration 3089 : loss : 0.038536, loss_ce: 0.010960
2022-01-16 00:32:43,279 iteration 3090 : loss : 0.027018, loss_ce: 0.011737
2022-01-16 00:32:44,231 iteration 3091 : loss : 0.038193, loss_ce: 0.017710
2022-01-16 00:32:45,344 iteration 3092 : loss : 0.040518, loss_ce: 0.016450
2022-01-16 00:32:46,266 iteration 3093 : loss : 0.028074, loss_ce: 0.011530
2022-01-16 00:32:47,233 iteration 3094 : loss : 0.029830, loss_ce: 0.013351
 46%|█████████████▏               | 182/400 [53:40<1:03:33, 17.49s/it]2022-01-16 00:32:48,245 iteration 3095 : loss : 0.040426, loss_ce: 0.015018
2022-01-16 00:32:49,217 iteration 3096 : loss : 0.026359, loss_ce: 0.013098
2022-01-16 00:32:50,157 iteration 3097 : loss : 0.034723, loss_ce: 0.013989
2022-01-16 00:32:51,069 iteration 3098 : loss : 0.022648, loss_ce: 0.009334
2022-01-16 00:32:52,018 iteration 3099 : loss : 0.026283, loss_ce: 0.009274
2022-01-16 00:32:52,913 iteration 3100 : loss : 0.025865, loss_ce: 0.008695
2022-01-16 00:32:53,918 iteration 3101 : loss : 0.034138, loss_ce: 0.012005
2022-01-16 00:32:54,875 iteration 3102 : loss : 0.027964, loss_ce: 0.010226
2022-01-16 00:32:55,850 iteration 3103 : loss : 0.036055, loss_ce: 0.014080
2022-01-16 00:32:56,762 iteration 3104 : loss : 0.022855, loss_ce: 0.009674
2022-01-16 00:32:57,639 iteration 3105 : loss : 0.023319, loss_ce: 0.010794
2022-01-16 00:32:58,578 iteration 3106 : loss : 0.028183, loss_ce: 0.012127
2022-01-16 00:32:59,502 iteration 3107 : loss : 0.021666, loss_ce: 0.005634
2022-01-16 00:33:00,475 iteration 3108 : loss : 0.034182, loss_ce: 0.010750
2022-01-16 00:33:01,467 iteration 3109 : loss : 0.035974, loss_ce: 0.013317
2022-01-16 00:33:02,462 iteration 3110 : loss : 0.030918, loss_ce: 0.014833
2022-01-16 00:33:03,432 iteration 3111 : loss : 0.030971, loss_ce: 0.012296
 46%|█████████████▎               | 183/400 [53:56<1:01:51, 17.10s/it]2022-01-16 00:33:04,472 iteration 3112 : loss : 0.027953, loss_ce: 0.010211
2022-01-16 00:33:05,384 iteration 3113 : loss : 0.031703, loss_ce: 0.013887
2022-01-16 00:33:06,392 iteration 3114 : loss : 0.029638, loss_ce: 0.010276
2022-01-16 00:33:07,362 iteration 3115 : loss : 0.033450, loss_ce: 0.012754
2022-01-16 00:33:08,306 iteration 3116 : loss : 0.025314, loss_ce: 0.011566
2022-01-16 00:33:09,335 iteration 3117 : loss : 0.027282, loss_ce: 0.010712
2022-01-16 00:33:10,271 iteration 3118 : loss : 0.030681, loss_ce: 0.011865
2022-01-16 00:33:11,337 iteration 3119 : loss : 0.041231, loss_ce: 0.013270
2022-01-16 00:33:12,240 iteration 3120 : loss : 0.026335, loss_ce: 0.010370
2022-01-16 00:33:13,269 iteration 3121 : loss : 0.027008, loss_ce: 0.011786
2022-01-16 00:33:14,207 iteration 3122 : loss : 0.032299, loss_ce: 0.009173
2022-01-16 00:33:15,226 iteration 3123 : loss : 0.030686, loss_ce: 0.012334
2022-01-16 00:33:16,102 iteration 3124 : loss : 0.026919, loss_ce: 0.009705
2022-01-16 00:33:17,050 iteration 3125 : loss : 0.041929, loss_ce: 0.013647
2022-01-16 00:33:18,070 iteration 3126 : loss : 0.030735, loss_ce: 0.015878
2022-01-16 00:33:19,105 iteration 3127 : loss : 0.033775, loss_ce: 0.012134
2022-01-16 00:33:20,133 iteration 3128 : loss : 0.031770, loss_ce: 0.011012
 46%|█████████████▎               | 184/400 [54:13<1:01:08, 16.98s/it]2022-01-16 00:33:21,117 iteration 3129 : loss : 0.030373, loss_ce: 0.010973
2022-01-16 00:33:22,181 iteration 3130 : loss : 0.038933, loss_ce: 0.016306
2022-01-16 00:33:23,124 iteration 3131 : loss : 0.030640, loss_ce: 0.010510
2022-01-16 00:33:24,079 iteration 3132 : loss : 0.026749, loss_ce: 0.007508
2022-01-16 00:33:25,043 iteration 3133 : loss : 0.040388, loss_ce: 0.014505
2022-01-16 00:33:25,968 iteration 3134 : loss : 0.023816, loss_ce: 0.011048
2022-01-16 00:33:26,918 iteration 3135 : loss : 0.034403, loss_ce: 0.016518
2022-01-16 00:33:27,849 iteration 3136 : loss : 0.031043, loss_ce: 0.013594
2022-01-16 00:33:28,929 iteration 3137 : loss : 0.027865, loss_ce: 0.011827
2022-01-16 00:33:29,962 iteration 3138 : loss : 0.038897, loss_ce: 0.016140
2022-01-16 00:33:30,853 iteration 3139 : loss : 0.024526, loss_ce: 0.008441
2022-01-16 00:33:31,745 iteration 3140 : loss : 0.030673, loss_ce: 0.012079
2022-01-16 00:33:32,717 iteration 3141 : loss : 0.032340, loss_ce: 0.014576
2022-01-16 00:33:33,648 iteration 3142 : loss : 0.039162, loss_ce: 0.013596
2022-01-16 00:33:34,651 iteration 3143 : loss : 0.041221, loss_ce: 0.013572
2022-01-16 00:33:35,593 iteration 3144 : loss : 0.025729, loss_ce: 0.009729
2022-01-16 00:33:35,593 Training Data Eval:
2022-01-16 00:33:40,123   Average segmentation loss on training set: 0.0188
2022-01-16 00:33:40,123 Validation Data Eval:
2022-01-16 00:33:41,608   Average segmentation loss on validation set: 0.1340
2022-01-16 00:33:42,513 iteration 3145 : loss : 0.021432, loss_ce: 0.008273
 46%|█████████████▍               | 185/400 [54:35<1:06:39, 18.60s/it]2022-01-16 00:33:43,691 iteration 3146 : loss : 0.048777, loss_ce: 0.017869
2022-01-16 00:33:44,700 iteration 3147 : loss : 0.043610, loss_ce: 0.022026
2022-01-16 00:33:45,596 iteration 3148 : loss : 0.023286, loss_ce: 0.008503
2022-01-16 00:33:46,602 iteration 3149 : loss : 0.045175, loss_ce: 0.012607
2022-01-16 00:33:47,602 iteration 3150 : loss : 0.026907, loss_ce: 0.007775
2022-01-16 00:33:48,601 iteration 3151 : loss : 0.031168, loss_ce: 0.011051
2022-01-16 00:33:49,595 iteration 3152 : loss : 0.036978, loss_ce: 0.012328
2022-01-16 00:33:50,569 iteration 3153 : loss : 0.045226, loss_ce: 0.021994
2022-01-16 00:33:51,612 iteration 3154 : loss : 0.033498, loss_ce: 0.011245
2022-01-16 00:33:52,621 iteration 3155 : loss : 0.027066, loss_ce: 0.009540
2022-01-16 00:33:53,517 iteration 3156 : loss : 0.029971, loss_ce: 0.010167
2022-01-16 00:33:54,494 iteration 3157 : loss : 0.028391, loss_ce: 0.011832
2022-01-16 00:33:55,403 iteration 3158 : loss : 0.040145, loss_ce: 0.012747
2022-01-16 00:33:56,394 iteration 3159 : loss : 0.029273, loss_ce: 0.014023
2022-01-16 00:33:57,390 iteration 3160 : loss : 0.025778, loss_ce: 0.010562
2022-01-16 00:33:58,435 iteration 3161 : loss : 0.021659, loss_ce: 0.008275
2022-01-16 00:33:59,405 iteration 3162 : loss : 0.027858, loss_ce: 0.009346
 46%|█████████████▍               | 186/400 [54:52<1:04:31, 18.09s/it]2022-01-16 00:34:00,379 iteration 3163 : loss : 0.029714, loss_ce: 0.009840
2022-01-16 00:34:01,453 iteration 3164 : loss : 0.039764, loss_ce: 0.015788
2022-01-16 00:34:02,475 iteration 3165 : loss : 0.031562, loss_ce: 0.011844
2022-01-16 00:34:03,398 iteration 3166 : loss : 0.029866, loss_ce: 0.010880
2022-01-16 00:34:04,416 iteration 3167 : loss : 0.029298, loss_ce: 0.010307
2022-01-16 00:34:05,381 iteration 3168 : loss : 0.034481, loss_ce: 0.015991
2022-01-16 00:34:06,374 iteration 3169 : loss : 0.027499, loss_ce: 0.012133
2022-01-16 00:34:07,345 iteration 3170 : loss : 0.031013, loss_ce: 0.013306
2022-01-16 00:34:08,182 iteration 3171 : loss : 0.023553, loss_ce: 0.006695
2022-01-16 00:34:09,099 iteration 3172 : loss : 0.023282, loss_ce: 0.009040
2022-01-16 00:34:10,062 iteration 3173 : loss : 0.032344, loss_ce: 0.011481
2022-01-16 00:34:10,987 iteration 3174 : loss : 0.028258, loss_ce: 0.011748
2022-01-16 00:34:11,882 iteration 3175 : loss : 0.060471, loss_ce: 0.017406
2022-01-16 00:34:12,931 iteration 3176 : loss : 0.054334, loss_ce: 0.024544
2022-01-16 00:34:13,896 iteration 3177 : loss : 0.034012, loss_ce: 0.011849
2022-01-16 00:34:14,954 iteration 3178 : loss : 0.023988, loss_ce: 0.006674
2022-01-16 00:34:15,922 iteration 3179 : loss : 0.025715, loss_ce: 0.012363
 47%|█████████████▌               | 187/400 [55:09<1:02:32, 17.62s/it]2022-01-16 00:34:16,965 iteration 3180 : loss : 0.078956, loss_ce: 0.030345
2022-01-16 00:34:17,895 iteration 3181 : loss : 0.030239, loss_ce: 0.011453
2022-01-16 00:34:18,797 iteration 3182 : loss : 0.029371, loss_ce: 0.014452
2022-01-16 00:34:19,820 iteration 3183 : loss : 0.042548, loss_ce: 0.017096
2022-01-16 00:34:20,783 iteration 3184 : loss : 0.029322, loss_ce: 0.010415
2022-01-16 00:34:21,754 iteration 3185 : loss : 0.035137, loss_ce: 0.010751
2022-01-16 00:34:22,759 iteration 3186 : loss : 0.027636, loss_ce: 0.011317
2022-01-16 00:34:23,773 iteration 3187 : loss : 0.031584, loss_ce: 0.013137
2022-01-16 00:34:24,796 iteration 3188 : loss : 0.029641, loss_ce: 0.011873
2022-01-16 00:34:25,751 iteration 3189 : loss : 0.026678, loss_ce: 0.009680
2022-01-16 00:34:26,824 iteration 3190 : loss : 0.031266, loss_ce: 0.011641
2022-01-16 00:34:27,848 iteration 3191 : loss : 0.031699, loss_ce: 0.010772
2022-01-16 00:34:28,743 iteration 3192 : loss : 0.050811, loss_ce: 0.010248
2022-01-16 00:34:29,706 iteration 3193 : loss : 0.049490, loss_ce: 0.020519
2022-01-16 00:34:30,806 iteration 3194 : loss : 0.042491, loss_ce: 0.018027
2022-01-16 00:34:31,786 iteration 3195 : loss : 0.032780, loss_ce: 0.013212
2022-01-16 00:34:32,750 iteration 3196 : loss : 0.035113, loss_ce: 0.016043
 47%|█████████████▋               | 188/400 [55:25<1:01:24, 17.38s/it]2022-01-16 00:34:33,757 iteration 3197 : loss : 0.024776, loss_ce: 0.010028
2022-01-16 00:34:34,767 iteration 3198 : loss : 0.034062, loss_ce: 0.017280
2022-01-16 00:34:35,766 iteration 3199 : loss : 0.025150, loss_ce: 0.006772
2022-01-16 00:34:36,787 iteration 3200 : loss : 0.054069, loss_ce: 0.017758
2022-01-16 00:34:37,800 iteration 3201 : loss : 0.029484, loss_ce: 0.011405
2022-01-16 00:34:38,819 iteration 3202 : loss : 0.044103, loss_ce: 0.013615
2022-01-16 00:34:39,703 iteration 3203 : loss : 0.026967, loss_ce: 0.012481
2022-01-16 00:34:40,574 iteration 3204 : loss : 0.026262, loss_ce: 0.011226
2022-01-16 00:34:41,445 iteration 3205 : loss : 0.032575, loss_ce: 0.010269
2022-01-16 00:34:42,275 iteration 3206 : loss : 0.024840, loss_ce: 0.007423
2022-01-16 00:34:43,269 iteration 3207 : loss : 0.042869, loss_ce: 0.016868
2022-01-16 00:34:44,224 iteration 3208 : loss : 0.031740, loss_ce: 0.012512
2022-01-16 00:34:45,153 iteration 3209 : loss : 0.028868, loss_ce: 0.010053
2022-01-16 00:34:46,139 iteration 3210 : loss : 0.023456, loss_ce: 0.010929
2022-01-16 00:34:47,029 iteration 3211 : loss : 0.025848, loss_ce: 0.007661
2022-01-16 00:34:48,073 iteration 3212 : loss : 0.036151, loss_ce: 0.017814
2022-01-16 00:34:49,128 iteration 3213 : loss : 0.040586, loss_ce: 0.012826
 47%|█████████████▋               | 189/400 [55:42<1:00:03, 17.08s/it]2022-01-16 00:34:50,098 iteration 3214 : loss : 0.020072, loss_ce: 0.008546
2022-01-16 00:34:51,059 iteration 3215 : loss : 0.024704, loss_ce: 0.010782
2022-01-16 00:34:52,019 iteration 3216 : loss : 0.038995, loss_ce: 0.014705
2022-01-16 00:34:53,013 iteration 3217 : loss : 0.029552, loss_ce: 0.011764
2022-01-16 00:34:53,982 iteration 3218 : loss : 0.043001, loss_ce: 0.015117
2022-01-16 00:34:54,930 iteration 3219 : loss : 0.028425, loss_ce: 0.010358
2022-01-16 00:34:55,836 iteration 3220 : loss : 0.025468, loss_ce: 0.011625
2022-01-16 00:34:56,900 iteration 3221 : loss : 0.064836, loss_ce: 0.029642
2022-01-16 00:34:57,828 iteration 3222 : loss : 0.033122, loss_ce: 0.009221
2022-01-16 00:34:58,814 iteration 3223 : loss : 0.031812, loss_ce: 0.009656
2022-01-16 00:34:59,877 iteration 3224 : loss : 0.049841, loss_ce: 0.015233
2022-01-16 00:35:00,839 iteration 3225 : loss : 0.034665, loss_ce: 0.015807
2022-01-16 00:35:01,795 iteration 3226 : loss : 0.030840, loss_ce: 0.014289
2022-01-16 00:35:02,776 iteration 3227 : loss : 0.027024, loss_ce: 0.011369
2022-01-16 00:35:03,706 iteration 3228 : loss : 0.040688, loss_ce: 0.012394
2022-01-16 00:35:04,600 iteration 3229 : loss : 0.033117, loss_ce: 0.009495
2022-01-16 00:35:04,600 Training Data Eval:
2022-01-16 00:35:09,131   Average segmentation loss on training set: 0.0216
2022-01-16 00:35:09,132 Validation Data Eval:
2022-01-16 00:35:10,616   Average segmentation loss on validation set: 0.0739
2022-01-16 00:35:11,496 iteration 3230 : loss : 0.029180, loss_ce: 0.011237
 48%|█████████████▊               | 190/400 [56:04<1:05:19, 18.67s/it]2022-01-16 00:35:12,474 iteration 3231 : loss : 0.060760, loss_ce: 0.018744
2022-01-16 00:35:13,409 iteration 3232 : loss : 0.027201, loss_ce: 0.008187
2022-01-16 00:35:14,376 iteration 3233 : loss : 0.029539, loss_ce: 0.013751
2022-01-16 00:35:15,365 iteration 3234 : loss : 0.018701, loss_ce: 0.005613
2022-01-16 00:35:16,342 iteration 3235 : loss : 0.045765, loss_ce: 0.012854
2022-01-16 00:35:17,234 iteration 3236 : loss : 0.022300, loss_ce: 0.009954
2022-01-16 00:35:18,302 iteration 3237 : loss : 0.034482, loss_ce: 0.014894
2022-01-16 00:35:19,276 iteration 3238 : loss : 0.027471, loss_ce: 0.013206
2022-01-16 00:35:20,240 iteration 3239 : loss : 0.022499, loss_ce: 0.008437
2022-01-16 00:35:21,138 iteration 3240 : loss : 0.029682, loss_ce: 0.007619
2022-01-16 00:35:22,015 iteration 3241 : loss : 0.028816, loss_ce: 0.007066
2022-01-16 00:35:22,983 iteration 3242 : loss : 0.027368, loss_ce: 0.010395
2022-01-16 00:35:23,871 iteration 3243 : loss : 0.030250, loss_ce: 0.011291
2022-01-16 00:35:24,854 iteration 3244 : loss : 0.032618, loss_ce: 0.013389
2022-01-16 00:35:25,769 iteration 3245 : loss : 0.021339, loss_ce: 0.009820
2022-01-16 00:35:26,795 iteration 3246 : loss : 0.032194, loss_ce: 0.015970
2022-01-16 00:35:27,710 iteration 3247 : loss : 0.030365, loss_ce: 0.013609
 48%|█████████████▊               | 191/400 [56:20<1:02:27, 17.93s/it]2022-01-16 00:35:28,678 iteration 3248 : loss : 0.025392, loss_ce: 0.009157
2022-01-16 00:35:29,581 iteration 3249 : loss : 0.023317, loss_ce: 0.008565
2022-01-16 00:35:30,510 iteration 3250 : loss : 0.027974, loss_ce: 0.009433
2022-01-16 00:35:31,449 iteration 3251 : loss : 0.023934, loss_ce: 0.010140
2022-01-16 00:35:32,413 iteration 3252 : loss : 0.022307, loss_ce: 0.008492
2022-01-16 00:35:33,352 iteration 3253 : loss : 0.023849, loss_ce: 0.009922
2022-01-16 00:35:34,282 iteration 3254 : loss : 0.029434, loss_ce: 0.010703
2022-01-16 00:35:35,138 iteration 3255 : loss : 0.027731, loss_ce: 0.010848
2022-01-16 00:35:36,075 iteration 3256 : loss : 0.020883, loss_ce: 0.007382
2022-01-16 00:35:36,977 iteration 3257 : loss : 0.020230, loss_ce: 0.008110
2022-01-16 00:35:37,934 iteration 3258 : loss : 0.022126, loss_ce: 0.009738
2022-01-16 00:35:38,824 iteration 3259 : loss : 0.029697, loss_ce: 0.011392
2022-01-16 00:35:39,788 iteration 3260 : loss : 0.023645, loss_ce: 0.009276
2022-01-16 00:35:40,705 iteration 3261 : loss : 0.052927, loss_ce: 0.014762
2022-01-16 00:35:41,700 iteration 3262 : loss : 0.030964, loss_ce: 0.011538
2022-01-16 00:35:42,778 iteration 3263 : loss : 0.026193, loss_ce: 0.007769
2022-01-16 00:35:43,742 iteration 3264 : loss : 0.027748, loss_ce: 0.012580
 48%|█████████████▉               | 192/400 [56:36<1:00:11, 17.36s/it]2022-01-16 00:35:44,703 iteration 3265 : loss : 0.021777, loss_ce: 0.008562
2022-01-16 00:35:45,713 iteration 3266 : loss : 0.034497, loss_ce: 0.015407
2022-01-16 00:35:46,692 iteration 3267 : loss : 0.033966, loss_ce: 0.012640
2022-01-16 00:35:47,602 iteration 3268 : loss : 0.028360, loss_ce: 0.011400
2022-01-16 00:35:48,619 iteration 3269 : loss : 0.033253, loss_ce: 0.015521
2022-01-16 00:35:49,665 iteration 3270 : loss : 0.035044, loss_ce: 0.011939
2022-01-16 00:35:50,685 iteration 3271 : loss : 0.025894, loss_ce: 0.008440
2022-01-16 00:35:51,707 iteration 3272 : loss : 0.028443, loss_ce: 0.013848
2022-01-16 00:35:52,601 iteration 3273 : loss : 0.028800, loss_ce: 0.008881
2022-01-16 00:35:53,543 iteration 3274 : loss : 0.021279, loss_ce: 0.010325
2022-01-16 00:35:54,568 iteration 3275 : loss : 0.028731, loss_ce: 0.007924
2022-01-16 00:35:55,499 iteration 3276 : loss : 0.026399, loss_ce: 0.010580
2022-01-16 00:35:56,487 iteration 3277 : loss : 0.026182, loss_ce: 0.012680
2022-01-16 00:35:57,447 iteration 3278 : loss : 0.029658, loss_ce: 0.009943
2022-01-16 00:35:58,361 iteration 3279 : loss : 0.023997, loss_ce: 0.008780
2022-01-16 00:35:59,303 iteration 3280 : loss : 0.026260, loss_ce: 0.008661
2022-01-16 00:36:00,194 iteration 3281 : loss : 0.024667, loss_ce: 0.006918
 48%|██████████████▉                | 193/400 [56:53<58:56, 17.09s/it]2022-01-16 00:36:01,238 iteration 3282 : loss : 0.030441, loss_ce: 0.011912
2022-01-16 00:36:02,192 iteration 3283 : loss : 0.019758, loss_ce: 0.006296
2022-01-16 00:36:03,142 iteration 3284 : loss : 0.032949, loss_ce: 0.015164
2022-01-16 00:36:04,081 iteration 3285 : loss : 0.035242, loss_ce: 0.015930
2022-01-16 00:36:05,018 iteration 3286 : loss : 0.019715, loss_ce: 0.007118
2022-01-16 00:36:05,986 iteration 3287 : loss : 0.024509, loss_ce: 0.010565
2022-01-16 00:36:06,881 iteration 3288 : loss : 0.030620, loss_ce: 0.016458
2022-01-16 00:36:07,791 iteration 3289 : loss : 0.031756, loss_ce: 0.009305
2022-01-16 00:36:08,803 iteration 3290 : loss : 0.028356, loss_ce: 0.007964
2022-01-16 00:36:09,822 iteration 3291 : loss : 0.024917, loss_ce: 0.009623
2022-01-16 00:36:10,794 iteration 3292 : loss : 0.045010, loss_ce: 0.011979
2022-01-16 00:36:11,745 iteration 3293 : loss : 0.023017, loss_ce: 0.010232
2022-01-16 00:36:12,664 iteration 3294 : loss : 0.023446, loss_ce: 0.010104
2022-01-16 00:36:13,712 iteration 3295 : loss : 0.037925, loss_ce: 0.015886
2022-01-16 00:36:14,697 iteration 3296 : loss : 0.047320, loss_ce: 0.014858
2022-01-16 00:36:15,576 iteration 3297 : loss : 0.020643, loss_ce: 0.009542
2022-01-16 00:36:16,579 iteration 3298 : loss : 0.025606, loss_ce: 0.010279
 48%|███████████████                | 194/400 [57:09<57:56, 16.88s/it]2022-01-16 00:36:17,518 iteration 3299 : loss : 0.021586, loss_ce: 0.009766
2022-01-16 00:36:18,435 iteration 3300 : loss : 0.045483, loss_ce: 0.015238
2022-01-16 00:36:19,450 iteration 3301 : loss : 0.028317, loss_ce: 0.013072
2022-01-16 00:36:20,401 iteration 3302 : loss : 0.024230, loss_ce: 0.009637
2022-01-16 00:36:21,331 iteration 3303 : loss : 0.023073, loss_ce: 0.009082
2022-01-16 00:36:22,289 iteration 3304 : loss : 0.025397, loss_ce: 0.008914
2022-01-16 00:36:23,271 iteration 3305 : loss : 0.026592, loss_ce: 0.009506
2022-01-16 00:36:24,284 iteration 3306 : loss : 0.031722, loss_ce: 0.012721
2022-01-16 00:36:25,209 iteration 3307 : loss : 0.024785, loss_ce: 0.009951
2022-01-16 00:36:26,170 iteration 3308 : loss : 0.031458, loss_ce: 0.013295
2022-01-16 00:36:27,116 iteration 3309 : loss : 0.035438, loss_ce: 0.008281
2022-01-16 00:36:28,150 iteration 3310 : loss : 0.050056, loss_ce: 0.016099
2022-01-16 00:36:29,211 iteration 3311 : loss : 0.025054, loss_ce: 0.009239
2022-01-16 00:36:30,111 iteration 3312 : loss : 0.025990, loss_ce: 0.008971
2022-01-16 00:36:31,026 iteration 3313 : loss : 0.019289, loss_ce: 0.006730
2022-01-16 00:36:32,052 iteration 3314 : loss : 0.036730, loss_ce: 0.012713
2022-01-16 00:36:32,052 Training Data Eval:
2022-01-16 00:36:36,589   Average segmentation loss on training set: 0.0200
2022-01-16 00:36:36,589 Validation Data Eval:
2022-01-16 00:36:38,092   Average segmentation loss on validation set: 0.0889
2022-01-16 00:36:38,989 iteration 3315 : loss : 0.020219, loss_ce: 0.009179
 49%|██████████████▏              | 195/400 [57:32<1:03:19, 18.54s/it]2022-01-16 00:36:39,951 iteration 3316 : loss : 0.017945, loss_ce: 0.006855
2022-01-16 00:36:40,874 iteration 3317 : loss : 0.029665, loss_ce: 0.011431
2022-01-16 00:36:41,934 iteration 3318 : loss : 0.026689, loss_ce: 0.011099
2022-01-16 00:36:42,857 iteration 3319 : loss : 0.022552, loss_ce: 0.007865
2022-01-16 00:36:43,794 iteration 3320 : loss : 0.028754, loss_ce: 0.009163
2022-01-16 00:36:44,756 iteration 3321 : loss : 0.021868, loss_ce: 0.006398
2022-01-16 00:36:45,715 iteration 3322 : loss : 0.031227, loss_ce: 0.012966
2022-01-16 00:36:46,611 iteration 3323 : loss : 0.021986, loss_ce: 0.007848
2022-01-16 00:36:47,653 iteration 3324 : loss : 0.054229, loss_ce: 0.032198
2022-01-16 00:36:48,556 iteration 3325 : loss : 0.029513, loss_ce: 0.009042
2022-01-16 00:36:49,539 iteration 3326 : loss : 0.024329, loss_ce: 0.008622
2022-01-16 00:36:50,606 iteration 3327 : loss : 0.039933, loss_ce: 0.013316
2022-01-16 00:36:51,565 iteration 3328 : loss : 0.027730, loss_ce: 0.011316
2022-01-16 00:36:52,485 iteration 3329 : loss : 0.022914, loss_ce: 0.010316
2022-01-16 00:36:53,428 iteration 3330 : loss : 0.035331, loss_ce: 0.011625
2022-01-16 00:36:54,401 iteration 3331 : loss : 0.022245, loss_ce: 0.008278
2022-01-16 00:36:55,259 iteration 3332 : loss : 0.021826, loss_ce: 0.010053
 49%|██████████████▏              | 196/400 [57:48<1:00:43, 17.86s/it]2022-01-16 00:36:56,251 iteration 3333 : loss : 0.025132, loss_ce: 0.009869
2022-01-16 00:36:57,218 iteration 3334 : loss : 0.017769, loss_ce: 0.008047
2022-01-16 00:36:58,087 iteration 3335 : loss : 0.017477, loss_ce: 0.007546
2022-01-16 00:36:59,036 iteration 3336 : loss : 0.035764, loss_ce: 0.012578
2022-01-16 00:37:00,042 iteration 3337 : loss : 0.029660, loss_ce: 0.012767
2022-01-16 00:37:01,106 iteration 3338 : loss : 0.032022, loss_ce: 0.017955
2022-01-16 00:37:02,054 iteration 3339 : loss : 0.034736, loss_ce: 0.010483
2022-01-16 00:37:02,981 iteration 3340 : loss : 0.020226, loss_ce: 0.007425
2022-01-16 00:37:03,923 iteration 3341 : loss : 0.019706, loss_ce: 0.007546
2022-01-16 00:37:04,926 iteration 3342 : loss : 0.039861, loss_ce: 0.020116
2022-01-16 00:37:05,907 iteration 3343 : loss : 0.031825, loss_ce: 0.010578
2022-01-16 00:37:06,881 iteration 3344 : loss : 0.027520, loss_ce: 0.010213
2022-01-16 00:37:07,815 iteration 3345 : loss : 0.023069, loss_ce: 0.007959
2022-01-16 00:37:08,778 iteration 3346 : loss : 0.020674, loss_ce: 0.009481
2022-01-16 00:37:09,771 iteration 3347 : loss : 0.040971, loss_ce: 0.011997
2022-01-16 00:37:10,826 iteration 3348 : loss : 0.034504, loss_ce: 0.010805
2022-01-16 00:37:11,808 iteration 3349 : loss : 0.028228, loss_ce: 0.010821
 49%|███████████████▎               | 197/400 [58:04<59:05, 17.46s/it]2022-01-16 00:37:12,784 iteration 3350 : loss : 0.022864, loss_ce: 0.008898
2022-01-16 00:37:13,688 iteration 3351 : loss : 0.023524, loss_ce: 0.008736
2022-01-16 00:37:14,619 iteration 3352 : loss : 0.025564, loss_ce: 0.011349
2022-01-16 00:37:15,602 iteration 3353 : loss : 0.027486, loss_ce: 0.011703
2022-01-16 00:37:16,580 iteration 3354 : loss : 0.039173, loss_ce: 0.016684
2022-01-16 00:37:17,618 iteration 3355 : loss : 0.028693, loss_ce: 0.014575
2022-01-16 00:37:18,623 iteration 3356 : loss : 0.026006, loss_ce: 0.007570
2022-01-16 00:37:19,638 iteration 3357 : loss : 0.025386, loss_ce: 0.008588
2022-01-16 00:37:20,673 iteration 3358 : loss : 0.029023, loss_ce: 0.011218
2022-01-16 00:37:21,665 iteration 3359 : loss : 0.020151, loss_ce: 0.007833
2022-01-16 00:37:22,729 iteration 3360 : loss : 0.034369, loss_ce: 0.015024
2022-01-16 00:37:23,634 iteration 3361 : loss : 0.031150, loss_ce: 0.008792
2022-01-16 00:37:24,548 iteration 3362 : loss : 0.026803, loss_ce: 0.010147
2022-01-16 00:37:25,454 iteration 3363 : loss : 0.023545, loss_ce: 0.010457
2022-01-16 00:37:26,433 iteration 3364 : loss : 0.032882, loss_ce: 0.012126
2022-01-16 00:37:27,337 iteration 3365 : loss : 0.022671, loss_ce: 0.012053
2022-01-16 00:37:28,283 iteration 3366 : loss : 0.037909, loss_ce: 0.013523
 50%|███████████████▎               | 198/400 [58:21<57:48, 17.17s/it]2022-01-16 00:37:29,302 iteration 3367 : loss : 0.030333, loss_ce: 0.008758
2022-01-16 00:37:30,244 iteration 3368 : loss : 0.036774, loss_ce: 0.019566
2022-01-16 00:37:31,226 iteration 3369 : loss : 0.027885, loss_ce: 0.009983
2022-01-16 00:37:32,212 iteration 3370 : loss : 0.025362, loss_ce: 0.012554
2022-01-16 00:37:33,074 iteration 3371 : loss : 0.017028, loss_ce: 0.006586
2022-01-16 00:37:34,011 iteration 3372 : loss : 0.023240, loss_ce: 0.011331
2022-01-16 00:37:34,957 iteration 3373 : loss : 0.022218, loss_ce: 0.010670
2022-01-16 00:37:35,851 iteration 3374 : loss : 0.021147, loss_ce: 0.009557
2022-01-16 00:37:36,752 iteration 3375 : loss : 0.024379, loss_ce: 0.011477
2022-01-16 00:37:37,668 iteration 3376 : loss : 0.028250, loss_ce: 0.011167
2022-01-16 00:37:38,664 iteration 3377 : loss : 0.032386, loss_ce: 0.009964
2022-01-16 00:37:39,610 iteration 3378 : loss : 0.028877, loss_ce: 0.009644
2022-01-16 00:37:40,472 iteration 3379 : loss : 0.018046, loss_ce: 0.007981
2022-01-16 00:37:41,490 iteration 3380 : loss : 0.042930, loss_ce: 0.016556
2022-01-16 00:37:42,370 iteration 3381 : loss : 0.056759, loss_ce: 0.011888
2022-01-16 00:37:43,324 iteration 3382 : loss : 0.031630, loss_ce: 0.012065
2022-01-16 00:37:44,262 iteration 3383 : loss : 0.027173, loss_ce: 0.010658
 50%|███████████████▍               | 199/400 [58:37<56:19, 16.81s/it]2022-01-16 00:37:45,221 iteration 3384 : loss : 0.030693, loss_ce: 0.010940
2022-01-16 00:37:46,223 iteration 3385 : loss : 0.032005, loss_ce: 0.013327
2022-01-16 00:37:47,238 iteration 3386 : loss : 0.034737, loss_ce: 0.016857
2022-01-16 00:37:48,233 iteration 3387 : loss : 0.027342, loss_ce: 0.009838
2022-01-16 00:37:49,123 iteration 3388 : loss : 0.026394, loss_ce: 0.009422
2022-01-16 00:37:50,108 iteration 3389 : loss : 0.030460, loss_ce: 0.011917
2022-01-16 00:37:50,989 iteration 3390 : loss : 0.035826, loss_ce: 0.008738
2022-01-16 00:37:52,053 iteration 3391 : loss : 0.035232, loss_ce: 0.011358
2022-01-16 00:37:53,048 iteration 3392 : loss : 0.026447, loss_ce: 0.009785
2022-01-16 00:37:54,035 iteration 3393 : loss : 0.037321, loss_ce: 0.015043
2022-01-16 00:37:54,894 iteration 3394 : loss : 0.025693, loss_ce: 0.008701
2022-01-16 00:37:55,964 iteration 3395 : loss : 0.036777, loss_ce: 0.013824
2022-01-16 00:37:56,946 iteration 3396 : loss : 0.060627, loss_ce: 0.023896
2022-01-16 00:37:57,877 iteration 3397 : loss : 0.026418, loss_ce: 0.010346
2022-01-16 00:37:58,873 iteration 3398 : loss : 0.024951, loss_ce: 0.008725
2022-01-16 00:37:59,844 iteration 3399 : loss : 0.028990, loss_ce: 0.011438
2022-01-16 00:37:59,845 Training Data Eval:
2022-01-16 00:38:04,383   Average segmentation loss on training set: 0.0198
2022-01-16 00:38:04,383 Validation Data Eval:
2022-01-16 00:38:05,868   Average segmentation loss on validation set: 0.0664
2022-01-16 00:38:06,745 Found new lowest validation loss at iteration 3399! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-16 00:38:07,702 iteration 3400 : loss : 0.025246, loss_ce: 0.008747
 50%|██████████████▌              | 200/400 [59:00<1:02:40, 18.80s/it]2022-01-16 00:38:08,872 iteration 3401 : loss : 0.030078, loss_ce: 0.012679
2022-01-16 00:38:09,891 iteration 3402 : loss : 0.033486, loss_ce: 0.011380
2022-01-16 00:38:10,817 iteration 3403 : loss : 0.025150, loss_ce: 0.012169
2022-01-16 00:38:11,746 iteration 3404 : loss : 0.020329, loss_ce: 0.006964
2022-01-16 00:38:12,677 iteration 3405 : loss : 0.029917, loss_ce: 0.011359
2022-01-16 00:38:13,692 iteration 3406 : loss : 0.039300, loss_ce: 0.013528
2022-01-16 00:38:14,664 iteration 3407 : loss : 0.032762, loss_ce: 0.013342
2022-01-16 00:38:15,647 iteration 3408 : loss : 0.029635, loss_ce: 0.011712
2022-01-16 00:38:16,642 iteration 3409 : loss : 0.027925, loss_ce: 0.012076
2022-01-16 00:38:17,625 iteration 3410 : loss : 0.028373, loss_ce: 0.009902
2022-01-16 00:38:18,647 iteration 3411 : loss : 0.028007, loss_ce: 0.012581
2022-01-16 00:38:19,547 iteration 3412 : loss : 0.032291, loss_ce: 0.010430
2022-01-16 00:38:20,426 iteration 3413 : loss : 0.018228, loss_ce: 0.007926
2022-01-16 00:38:21,406 iteration 3414 : loss : 0.041850, loss_ce: 0.010151
2022-01-16 00:38:22,417 iteration 3415 : loss : 0.023758, loss_ce: 0.008806
2022-01-16 00:38:23,426 iteration 3416 : loss : 0.023053, loss_ce: 0.007159
2022-01-16 00:38:24,486 iteration 3417 : loss : 0.037754, loss_ce: 0.013691
 50%|██████████████▌              | 201/400 [59:17<1:00:20, 18.19s/it]2022-01-16 00:38:25,526 iteration 3418 : loss : 0.024984, loss_ce: 0.012165
2022-01-16 00:38:26,526 iteration 3419 : loss : 0.033562, loss_ce: 0.012813
2022-01-16 00:38:27,596 iteration 3420 : loss : 0.038014, loss_ce: 0.010624
2022-01-16 00:38:28,588 iteration 3421 : loss : 0.027681, loss_ce: 0.010251
2022-01-16 00:38:29,492 iteration 3422 : loss : 0.023182, loss_ce: 0.007537
2022-01-16 00:38:30,451 iteration 3423 : loss : 0.021860, loss_ce: 0.008662
2022-01-16 00:38:31,412 iteration 3424 : loss : 0.022346, loss_ce: 0.009722
2022-01-16 00:38:32,317 iteration 3425 : loss : 0.032033, loss_ce: 0.018280
2022-01-16 00:38:33,283 iteration 3426 : loss : 0.028709, loss_ce: 0.009813
2022-01-16 00:38:34,265 iteration 3427 : loss : 0.029605, loss_ce: 0.010100
2022-01-16 00:38:35,249 iteration 3428 : loss : 0.059590, loss_ce: 0.022808
2022-01-16 00:38:36,266 iteration 3429 : loss : 0.025553, loss_ce: 0.009999
2022-01-16 00:38:37,288 iteration 3430 : loss : 0.030330, loss_ce: 0.011873
2022-01-16 00:38:38,165 iteration 3431 : loss : 0.025043, loss_ce: 0.010378
2022-01-16 00:38:39,084 iteration 3432 : loss : 0.035192, loss_ce: 0.012523
2022-01-16 00:38:40,001 iteration 3433 : loss : 0.024745, loss_ce: 0.008880
2022-01-16 00:38:41,010 iteration 3434 : loss : 0.060027, loss_ce: 0.017748
 50%|███████████████▋               | 202/400 [59:34<58:23, 17.69s/it]2022-01-16 00:38:41,940 iteration 3435 : loss : 0.024832, loss_ce: 0.007747
2022-01-16 00:38:42,861 iteration 3436 : loss : 0.036678, loss_ce: 0.020877
2022-01-16 00:38:43,933 iteration 3437 : loss : 0.030621, loss_ce: 0.014994
2022-01-16 00:38:44,973 iteration 3438 : loss : 0.027109, loss_ce: 0.013369
2022-01-16 00:38:45,994 iteration 3439 : loss : 0.041321, loss_ce: 0.016027
2022-01-16 00:38:46,922 iteration 3440 : loss : 0.021475, loss_ce: 0.008434
2022-01-16 00:38:47,877 iteration 3441 : loss : 0.027977, loss_ce: 0.010914
2022-01-16 00:38:48,963 iteration 3442 : loss : 0.036563, loss_ce: 0.013742
2022-01-16 00:38:49,978 iteration 3443 : loss : 0.036999, loss_ce: 0.012763
2022-01-16 00:38:50,993 iteration 3444 : loss : 0.027640, loss_ce: 0.012892
2022-01-16 00:38:51,963 iteration 3445 : loss : 0.042298, loss_ce: 0.013847
2022-01-16 00:38:52,921 iteration 3446 : loss : 0.024066, loss_ce: 0.009581
2022-01-16 00:38:53,865 iteration 3447 : loss : 0.027859, loss_ce: 0.009627
2022-01-16 00:38:54,885 iteration 3448 : loss : 0.032401, loss_ce: 0.008683
2022-01-16 00:38:55,876 iteration 3449 : loss : 0.032474, loss_ce: 0.013559
2022-01-16 00:38:56,841 iteration 3450 : loss : 0.034672, loss_ce: 0.015351
2022-01-16 00:38:57,900 iteration 3451 : loss : 0.024979, loss_ce: 0.010062
 51%|███████████████▋               | 203/400 [59:50<57:17, 17.45s/it]2022-01-16 00:38:58,922 iteration 3452 : loss : 0.022361, loss_ce: 0.008520
2022-01-16 00:38:59,867 iteration 3453 : loss : 0.026527, loss_ce: 0.010572
2022-01-16 00:39:00,784 iteration 3454 : loss : 0.024338, loss_ce: 0.008686
2022-01-16 00:39:01,826 iteration 3455 : loss : 0.030042, loss_ce: 0.013157
2022-01-16 00:39:02,741 iteration 3456 : loss : 0.023684, loss_ce: 0.006789
2022-01-16 00:39:03,815 iteration 3457 : loss : 0.026076, loss_ce: 0.009289
2022-01-16 00:39:04,826 iteration 3458 : loss : 0.033080, loss_ce: 0.012300
2022-01-16 00:39:05,790 iteration 3459 : loss : 0.024794, loss_ce: 0.009858
2022-01-16 00:39:06,738 iteration 3460 : loss : 0.023339, loss_ce: 0.010159
2022-01-16 00:39:07,696 iteration 3461 : loss : 0.022238, loss_ce: 0.007596
2022-01-16 00:39:08,633 iteration 3462 : loss : 0.030430, loss_ce: 0.013642
2022-01-16 00:39:09,636 iteration 3463 : loss : 0.025349, loss_ce: 0.008884
2022-01-16 00:39:10,536 iteration 3464 : loss : 0.021485, loss_ce: 0.007943
2022-01-16 00:39:11,549 iteration 3465 : loss : 0.031624, loss_ce: 0.009513
2022-01-16 00:39:12,532 iteration 3466 : loss : 0.019737, loss_ce: 0.006195
2022-01-16 00:39:13,499 iteration 3467 : loss : 0.034856, loss_ce: 0.018068
2022-01-16 00:39:14,450 iteration 3468 : loss : 0.022995, loss_ce: 0.009490
 51%|██████████████▊              | 204/400 [1:00:07<56:07, 17.18s/it]2022-01-16 00:39:15,431 iteration 3469 : loss : 0.023371, loss_ce: 0.006228
2022-01-16 00:39:16,452 iteration 3470 : loss : 0.032692, loss_ce: 0.009787
2022-01-16 00:39:17,333 iteration 3471 : loss : 0.022787, loss_ce: 0.009292
2022-01-16 00:39:18,319 iteration 3472 : loss : 0.025100, loss_ce: 0.011121
2022-01-16 00:39:19,412 iteration 3473 : loss : 0.031189, loss_ce: 0.010182
2022-01-16 00:39:20,370 iteration 3474 : loss : 0.027373, loss_ce: 0.008240
2022-01-16 00:39:21,409 iteration 3475 : loss : 0.036294, loss_ce: 0.011594
2022-01-16 00:39:22,331 iteration 3476 : loss : 0.028305, loss_ce: 0.008369
2022-01-16 00:39:23,327 iteration 3477 : loss : 0.033750, loss_ce: 0.009597
2022-01-16 00:39:24,289 iteration 3478 : loss : 0.022254, loss_ce: 0.008552
2022-01-16 00:39:25,210 iteration 3479 : loss : 0.023440, loss_ce: 0.009410
2022-01-16 00:39:26,075 iteration 3480 : loss : 0.020749, loss_ce: 0.008028
2022-01-16 00:39:27,018 iteration 3481 : loss : 0.029390, loss_ce: 0.011457
2022-01-16 00:39:27,973 iteration 3482 : loss : 0.028321, loss_ce: 0.010389
2022-01-16 00:39:29,002 iteration 3483 : loss : 0.027262, loss_ce: 0.012408
2022-01-16 00:39:29,866 iteration 3484 : loss : 0.021959, loss_ce: 0.008635
2022-01-16 00:39:29,866 Training Data Eval:
2022-01-16 00:39:34,405   Average segmentation loss on training set: 0.0175
2022-01-16 00:39:34,405 Validation Data Eval:
2022-01-16 00:39:35,901   Average segmentation loss on validation set: 0.0829
2022-01-16 00:39:36,954 iteration 3485 : loss : 0.041359, loss_ce: 0.019172
 51%|█████████████▊             | 205/400 [1:00:30<1:01:02, 18.78s/it]2022-01-16 00:39:37,969 iteration 3486 : loss : 0.026809, loss_ce: 0.010967
2022-01-16 00:39:38,866 iteration 3487 : loss : 0.020988, loss_ce: 0.008747
2022-01-16 00:39:39,798 iteration 3488 : loss : 0.027910, loss_ce: 0.010522
2022-01-16 00:39:40,742 iteration 3489 : loss : 0.046389, loss_ce: 0.017245
2022-01-16 00:39:41,722 iteration 3490 : loss : 0.034965, loss_ce: 0.013562
2022-01-16 00:39:42,747 iteration 3491 : loss : 0.031494, loss_ce: 0.013473
2022-01-16 00:39:43,635 iteration 3492 : loss : 0.030230, loss_ce: 0.011074
2022-01-16 00:39:44,712 iteration 3493 : loss : 0.025649, loss_ce: 0.010130
2022-01-16 00:39:45,708 iteration 3494 : loss : 0.028629, loss_ce: 0.007980
2022-01-16 00:39:46,660 iteration 3495 : loss : 0.024620, loss_ce: 0.007625
2022-01-16 00:39:47,657 iteration 3496 : loss : 0.029264, loss_ce: 0.011864
2022-01-16 00:39:48,649 iteration 3497 : loss : 0.032142, loss_ce: 0.012690
2022-01-16 00:39:49,736 iteration 3498 : loss : 0.040458, loss_ce: 0.016744
2022-01-16 00:39:50,662 iteration 3499 : loss : 0.023925, loss_ce: 0.009135
2022-01-16 00:39:51,534 iteration 3500 : loss : 0.017793, loss_ce: 0.005780
2022-01-16 00:39:52,442 iteration 3501 : loss : 0.031298, loss_ce: 0.009708
2022-01-16 00:39:53,419 iteration 3502 : loss : 0.022164, loss_ce: 0.008454
 52%|██████████████▉              | 206/400 [1:00:46<58:28, 18.08s/it]2022-01-16 00:39:54,462 iteration 3503 : loss : 0.026028, loss_ce: 0.010401
2022-01-16 00:39:55,391 iteration 3504 : loss : 0.021628, loss_ce: 0.006479
2022-01-16 00:39:56,240 iteration 3505 : loss : 0.019838, loss_ce: 0.009785
2022-01-16 00:39:57,220 iteration 3506 : loss : 0.038884, loss_ce: 0.012614
2022-01-16 00:39:58,157 iteration 3507 : loss : 0.033060, loss_ce: 0.009084
2022-01-16 00:39:59,240 iteration 3508 : loss : 0.032853, loss_ce: 0.014724
2022-01-16 00:40:00,224 iteration 3509 : loss : 0.022268, loss_ce: 0.008339
2022-01-16 00:40:01,128 iteration 3510 : loss : 0.028581, loss_ce: 0.011795
2022-01-16 00:40:02,021 iteration 3511 : loss : 0.020746, loss_ce: 0.009388
2022-01-16 00:40:03,052 iteration 3512 : loss : 0.035639, loss_ce: 0.010103
2022-01-16 00:40:04,017 iteration 3513 : loss : 0.023549, loss_ce: 0.006637
2022-01-16 00:40:05,109 iteration 3514 : loss : 0.034223, loss_ce: 0.016860
2022-01-16 00:40:06,052 iteration 3515 : loss : 0.036227, loss_ce: 0.011134
2022-01-16 00:40:06,980 iteration 3516 : loss : 0.019654, loss_ce: 0.008493
2022-01-16 00:40:07,916 iteration 3517 : loss : 0.032627, loss_ce: 0.010993
2022-01-16 00:40:08,856 iteration 3518 : loss : 0.030234, loss_ce: 0.015879
2022-01-16 00:40:09,834 iteration 3519 : loss : 0.030564, loss_ce: 0.010430
 52%|███████████████              | 207/400 [1:01:02<56:33, 17.58s/it]2022-01-16 00:40:10,871 iteration 3520 : loss : 0.032842, loss_ce: 0.012318
2022-01-16 00:40:11,795 iteration 3521 : loss : 0.037574, loss_ce: 0.016670
2022-01-16 00:40:12,679 iteration 3522 : loss : 0.024122, loss_ce: 0.011239
2022-01-16 00:40:13,617 iteration 3523 : loss : 0.020734, loss_ce: 0.007613
2022-01-16 00:40:14,614 iteration 3524 : loss : 0.028990, loss_ce: 0.009863
2022-01-16 00:40:15,683 iteration 3525 : loss : 0.021430, loss_ce: 0.008738
2022-01-16 00:40:16,665 iteration 3526 : loss : 0.029151, loss_ce: 0.011328
2022-01-16 00:40:17,672 iteration 3527 : loss : 0.053320, loss_ce: 0.017971
2022-01-16 00:40:18,777 iteration 3528 : loss : 0.050061, loss_ce: 0.020050
2022-01-16 00:40:19,779 iteration 3529 : loss : 0.026742, loss_ce: 0.006848
2022-01-16 00:40:20,775 iteration 3530 : loss : 0.025825, loss_ce: 0.009583
2022-01-16 00:40:21,683 iteration 3531 : loss : 0.028342, loss_ce: 0.007615
2022-01-16 00:40:22,728 iteration 3532 : loss : 0.032675, loss_ce: 0.014217
2022-01-16 00:40:23,671 iteration 3533 : loss : 0.027331, loss_ce: 0.009148
2022-01-16 00:40:24,659 iteration 3534 : loss : 0.029884, loss_ce: 0.011168
2022-01-16 00:40:25,707 iteration 3535 : loss : 0.034444, loss_ce: 0.012976
2022-01-16 00:40:26,712 iteration 3536 : loss : 0.039227, loss_ce: 0.019730
 52%|███████████████              | 208/400 [1:01:19<55:34, 17.37s/it]2022-01-16 00:40:27,645 iteration 3537 : loss : 0.022856, loss_ce: 0.008936
2022-01-16 00:40:28,529 iteration 3538 : loss : 0.032851, loss_ce: 0.013586
2022-01-16 00:40:29,432 iteration 3539 : loss : 0.019793, loss_ce: 0.008487
2022-01-16 00:40:30,267 iteration 3540 : loss : 0.027160, loss_ce: 0.007418
2022-01-16 00:40:31,310 iteration 3541 : loss : 0.028463, loss_ce: 0.010351
2022-01-16 00:40:32,271 iteration 3542 : loss : 0.030464, loss_ce: 0.013014
2022-01-16 00:40:33,358 iteration 3543 : loss : 0.038725, loss_ce: 0.011923
2022-01-16 00:40:34,234 iteration 3544 : loss : 0.020671, loss_ce: 0.007833
2022-01-16 00:40:35,183 iteration 3545 : loss : 0.021229, loss_ce: 0.008944
2022-01-16 00:40:36,063 iteration 3546 : loss : 0.023975, loss_ce: 0.008655
2022-01-16 00:40:37,021 iteration 3547 : loss : 0.028867, loss_ce: 0.014822
2022-01-16 00:40:37,920 iteration 3548 : loss : 0.029031, loss_ce: 0.009608
2022-01-16 00:40:38,883 iteration 3549 : loss : 0.025052, loss_ce: 0.009801
2022-01-16 00:40:39,882 iteration 3550 : loss : 0.025605, loss_ce: 0.010784
2022-01-16 00:40:40,911 iteration 3551 : loss : 0.035632, loss_ce: 0.011128
2022-01-16 00:40:41,940 iteration 3552 : loss : 0.070667, loss_ce: 0.023871
2022-01-16 00:40:42,977 iteration 3553 : loss : 0.037803, loss_ce: 0.016879
 52%|███████████████▏             | 209/400 [1:01:36<54:14, 17.04s/it]2022-01-16 00:40:44,018 iteration 3554 : loss : 0.027482, loss_ce: 0.011898
2022-01-16 00:40:44,952 iteration 3555 : loss : 0.025094, loss_ce: 0.008185
2022-01-16 00:40:45,887 iteration 3556 : loss : 0.024515, loss_ce: 0.011039
2022-01-16 00:40:46,940 iteration 3557 : loss : 0.036797, loss_ce: 0.010880
2022-01-16 00:40:47,842 iteration 3558 : loss : 0.040696, loss_ce: 0.010631
2022-01-16 00:40:48,780 iteration 3559 : loss : 0.023103, loss_ce: 0.007595
2022-01-16 00:40:49,616 iteration 3560 : loss : 0.026290, loss_ce: 0.013302
2022-01-16 00:40:50,651 iteration 3561 : loss : 0.028670, loss_ce: 0.009784
2022-01-16 00:40:51,570 iteration 3562 : loss : 0.022649, loss_ce: 0.008145
2022-01-16 00:40:52,563 iteration 3563 : loss : 0.028160, loss_ce: 0.010389
2022-01-16 00:40:53,528 iteration 3564 : loss : 0.033340, loss_ce: 0.012215
2022-01-16 00:40:54,614 iteration 3565 : loss : 0.035823, loss_ce: 0.012674
2022-01-16 00:40:55,588 iteration 3566 : loss : 0.032999, loss_ce: 0.013039
2022-01-16 00:40:56,642 iteration 3567 : loss : 0.044950, loss_ce: 0.020524
2022-01-16 00:40:57,677 iteration 3568 : loss : 0.028841, loss_ce: 0.011161
2022-01-16 00:40:58,702 iteration 3569 : loss : 0.038546, loss_ce: 0.008991
2022-01-16 00:40:58,702 Training Data Eval:
2022-01-16 00:41:03,239   Average segmentation loss on training set: 0.0192
2022-01-16 00:41:03,239 Validation Data Eval:
2022-01-16 00:41:04,735   Average segmentation loss on validation set: 0.0813
2022-01-16 00:41:05,717 iteration 3570 : loss : 0.029290, loss_ce: 0.010508
 52%|███████████████▏             | 210/400 [1:01:58<59:22, 18.75s/it]2022-01-16 00:41:06,734 iteration 3571 : loss : 0.048668, loss_ce: 0.020145
2022-01-16 00:41:07,703 iteration 3572 : loss : 0.033728, loss_ce: 0.010304
2022-01-16 00:41:08,663 iteration 3573 : loss : 0.039283, loss_ce: 0.015113
2022-01-16 00:41:09,591 iteration 3574 : loss : 0.029610, loss_ce: 0.011351
2022-01-16 00:41:10,525 iteration 3575 : loss : 0.028143, loss_ce: 0.011045
2022-01-16 00:41:11,503 iteration 3576 : loss : 0.037644, loss_ce: 0.014391
2022-01-16 00:41:12,525 iteration 3577 : loss : 0.024976, loss_ce: 0.012098
2022-01-16 00:41:13,542 iteration 3578 : loss : 0.034272, loss_ce: 0.012836
2022-01-16 00:41:14,477 iteration 3579 : loss : 0.023090, loss_ce: 0.009021
2022-01-16 00:41:15,468 iteration 3580 : loss : 0.021907, loss_ce: 0.006970
2022-01-16 00:41:16,384 iteration 3581 : loss : 0.029380, loss_ce: 0.006023
2022-01-16 00:41:17,332 iteration 3582 : loss : 0.022432, loss_ce: 0.008969
2022-01-16 00:41:18,331 iteration 3583 : loss : 0.033861, loss_ce: 0.013270
2022-01-16 00:41:19,250 iteration 3584 : loss : 0.042442, loss_ce: 0.019789
2022-01-16 00:41:20,196 iteration 3585 : loss : 0.020936, loss_ce: 0.007849
2022-01-16 00:41:21,088 iteration 3586 : loss : 0.024952, loss_ce: 0.009595
2022-01-16 00:41:22,036 iteration 3587 : loss : 0.030329, loss_ce: 0.013970
 53%|███████████████▎             | 211/400 [1:02:15<56:45, 18.02s/it]2022-01-16 00:41:22,958 iteration 3588 : loss : 0.022364, loss_ce: 0.008021
2022-01-16 00:41:23,952 iteration 3589 : loss : 0.036134, loss_ce: 0.013024
2022-01-16 00:41:24,911 iteration 3590 : loss : 0.032909, loss_ce: 0.013424
2022-01-16 00:41:25,850 iteration 3591 : loss : 0.025915, loss_ce: 0.008221
2022-01-16 00:41:26,874 iteration 3592 : loss : 0.025123, loss_ce: 0.010172
2022-01-16 00:41:27,850 iteration 3593 : loss : 0.029994, loss_ce: 0.009106
2022-01-16 00:41:28,829 iteration 3594 : loss : 0.020767, loss_ce: 0.005905
2022-01-16 00:41:29,935 iteration 3595 : loss : 0.067536, loss_ce: 0.015210
2022-01-16 00:41:30,820 iteration 3596 : loss : 0.026614, loss_ce: 0.010787
2022-01-16 00:41:31,865 iteration 3597 : loss : 0.031347, loss_ce: 0.012007
2022-01-16 00:41:32,824 iteration 3598 : loss : 0.037301, loss_ce: 0.018070
2022-01-16 00:41:33,798 iteration 3599 : loss : 0.049879, loss_ce: 0.026925
2022-01-16 00:41:34,742 iteration 3600 : loss : 0.033795, loss_ce: 0.017008
2022-01-16 00:41:35,701 iteration 3601 : loss : 0.038221, loss_ce: 0.017041
2022-01-16 00:41:36,632 iteration 3602 : loss : 0.035315, loss_ce: 0.015265
2022-01-16 00:41:37,540 iteration 3603 : loss : 0.024346, loss_ce: 0.008657
2022-01-16 00:41:38,438 iteration 3604 : loss : 0.021958, loss_ce: 0.008440
 53%|███████████████▎             | 212/400 [1:02:31<54:57, 17.54s/it]2022-01-16 00:41:39,443 iteration 3605 : loss : 0.031375, loss_ce: 0.011937
2022-01-16 00:41:40,395 iteration 3606 : loss : 0.032595, loss_ce: 0.011837
2022-01-16 00:41:41,280 iteration 3607 : loss : 0.027999, loss_ce: 0.010586
2022-01-16 00:41:42,165 iteration 3608 : loss : 0.030648, loss_ce: 0.014447
2022-01-16 00:41:43,148 iteration 3609 : loss : 0.034821, loss_ce: 0.012704
2022-01-16 00:41:44,061 iteration 3610 : loss : 0.027311, loss_ce: 0.013185
2022-01-16 00:41:45,051 iteration 3611 : loss : 0.029083, loss_ce: 0.014244
2022-01-16 00:41:46,064 iteration 3612 : loss : 0.030547, loss_ce: 0.011478
2022-01-16 00:41:47,033 iteration 3613 : loss : 0.030241, loss_ce: 0.011745
2022-01-16 00:41:48,039 iteration 3614 : loss : 0.023255, loss_ce: 0.007379
2022-01-16 00:41:48,967 iteration 3615 : loss : 0.040746, loss_ce: 0.013497
2022-01-16 00:41:50,002 iteration 3616 : loss : 0.028780, loss_ce: 0.008558
2022-01-16 00:41:50,942 iteration 3617 : loss : 0.028884, loss_ce: 0.010792
2022-01-16 00:41:51,889 iteration 3618 : loss : 0.030539, loss_ce: 0.014158
2022-01-16 00:41:52,829 iteration 3619 : loss : 0.028220, loss_ce: 0.011937
2022-01-16 00:41:53,824 iteration 3620 : loss : 0.028989, loss_ce: 0.012552
2022-01-16 00:41:54,767 iteration 3621 : loss : 0.030566, loss_ce: 0.012649
 53%|███████████████▍             | 213/400 [1:02:47<53:31, 17.17s/it]2022-01-16 00:41:55,855 iteration 3622 : loss : 0.035193, loss_ce: 0.012006
2022-01-16 00:41:56,815 iteration 3623 : loss : 0.025038, loss_ce: 0.009656
2022-01-16 00:41:57,857 iteration 3624 : loss : 0.026356, loss_ce: 0.009233
2022-01-16 00:41:58,890 iteration 3625 : loss : 0.035418, loss_ce: 0.015890
2022-01-16 00:41:59,848 iteration 3626 : loss : 0.026981, loss_ce: 0.009535
2022-01-16 00:42:00,849 iteration 3627 : loss : 0.026027, loss_ce: 0.013252
2022-01-16 00:42:01,828 iteration 3628 : loss : 0.020249, loss_ce: 0.006198
2022-01-16 00:42:02,874 iteration 3629 : loss : 0.026881, loss_ce: 0.012066
2022-01-16 00:42:03,836 iteration 3630 : loss : 0.024765, loss_ce: 0.009477
2022-01-16 00:42:04,726 iteration 3631 : loss : 0.019428, loss_ce: 0.007340
2022-01-16 00:42:05,613 iteration 3632 : loss : 0.021149, loss_ce: 0.009261
2022-01-16 00:42:06,631 iteration 3633 : loss : 0.034976, loss_ce: 0.013798
2022-01-16 00:42:07,579 iteration 3634 : loss : 0.026235, loss_ce: 0.009829
2022-01-16 00:42:08,484 iteration 3635 : loss : 0.023606, loss_ce: 0.008544
2022-01-16 00:42:09,393 iteration 3636 : loss : 0.023374, loss_ce: 0.009884
2022-01-16 00:42:10,417 iteration 3637 : loss : 0.042241, loss_ce: 0.014627
2022-01-16 00:42:11,311 iteration 3638 : loss : 0.025375, loss_ce: 0.008408
 54%|███████████████▌             | 214/400 [1:03:04<52:39, 16.98s/it]2022-01-16 00:42:12,306 iteration 3639 : loss : 0.026081, loss_ce: 0.012079
2022-01-16 00:42:13,315 iteration 3640 : loss : 0.022561, loss_ce: 0.008176
2022-01-16 00:42:14,279 iteration 3641 : loss : 0.023473, loss_ce: 0.006922
2022-01-16 00:42:15,283 iteration 3642 : loss : 0.028184, loss_ce: 0.012258
2022-01-16 00:42:16,237 iteration 3643 : loss : 0.030822, loss_ce: 0.013890
2022-01-16 00:42:17,177 iteration 3644 : loss : 0.026092, loss_ce: 0.013022
2022-01-16 00:42:18,092 iteration 3645 : loss : 0.022237, loss_ce: 0.008502
2022-01-16 00:42:19,056 iteration 3646 : loss : 0.025020, loss_ce: 0.008422
2022-01-16 00:42:20,059 iteration 3647 : loss : 0.023972, loss_ce: 0.009346
2022-01-16 00:42:21,142 iteration 3648 : loss : 0.039108, loss_ce: 0.014900
2022-01-16 00:42:22,128 iteration 3649 : loss : 0.033672, loss_ce: 0.010509
2022-01-16 00:42:23,086 iteration 3650 : loss : 0.039062, loss_ce: 0.010471
2022-01-16 00:42:24,068 iteration 3651 : loss : 0.033013, loss_ce: 0.011289
2022-01-16 00:42:24,994 iteration 3652 : loss : 0.022616, loss_ce: 0.009231
2022-01-16 00:42:26,023 iteration 3653 : loss : 0.038067, loss_ce: 0.008771
2022-01-16 00:42:26,994 iteration 3654 : loss : 0.020070, loss_ce: 0.006478
2022-01-16 00:42:26,994 Training Data Eval:
2022-01-16 00:42:31,533   Average segmentation loss on training set: 0.0178
2022-01-16 00:42:31,533 Validation Data Eval:
2022-01-16 00:42:33,019   Average segmentation loss on validation set: 0.1389
2022-01-16 00:42:33,866 iteration 3655 : loss : 0.024321, loss_ce: 0.008323
 54%|███████████████▌             | 215/400 [1:03:26<57:31, 18.66s/it]2022-01-16 00:42:34,948 iteration 3656 : loss : 0.040495, loss_ce: 0.010800
2022-01-16 00:42:35,875 iteration 3657 : loss : 0.026452, loss_ce: 0.012552
2022-01-16 00:42:36,834 iteration 3658 : loss : 0.024370, loss_ce: 0.010475
2022-01-16 00:42:37,834 iteration 3659 : loss : 0.031221, loss_ce: 0.009567
2022-01-16 00:42:38,902 iteration 3660 : loss : 0.048262, loss_ce: 0.018645
2022-01-16 00:42:39,982 iteration 3661 : loss : 0.033951, loss_ce: 0.015506
2022-01-16 00:42:40,854 iteration 3662 : loss : 0.022485, loss_ce: 0.007933
2022-01-16 00:42:41,774 iteration 3663 : loss : 0.018640, loss_ce: 0.005751
2022-01-16 00:42:42,709 iteration 3664 : loss : 0.028686, loss_ce: 0.007779
2022-01-16 00:42:43,656 iteration 3665 : loss : 0.022723, loss_ce: 0.009504
2022-01-16 00:42:44,740 iteration 3666 : loss : 0.042638, loss_ce: 0.020537
2022-01-16 00:42:45,754 iteration 3667 : loss : 0.032774, loss_ce: 0.013300
2022-01-16 00:42:46,771 iteration 3668 : loss : 0.021396, loss_ce: 0.008338
2022-01-16 00:42:47,750 iteration 3669 : loss : 0.030474, loss_ce: 0.013530
2022-01-16 00:42:48,684 iteration 3670 : loss : 0.036353, loss_ce: 0.010664
2022-01-16 00:42:49,692 iteration 3671 : loss : 0.029055, loss_ce: 0.012848
2022-01-16 00:42:50,602 iteration 3672 : loss : 0.036045, loss_ce: 0.015005
 54%|███████████████▋             | 216/400 [1:03:43<55:26, 18.08s/it]2022-01-16 00:42:51,606 iteration 3673 : loss : 0.028110, loss_ce: 0.013565
2022-01-16 00:42:52,572 iteration 3674 : loss : 0.026140, loss_ce: 0.011080
2022-01-16 00:42:53,514 iteration 3675 : loss : 0.022206, loss_ce: 0.010934
2022-01-16 00:42:54,450 iteration 3676 : loss : 0.026511, loss_ce: 0.008912
2022-01-16 00:42:55,393 iteration 3677 : loss : 0.024916, loss_ce: 0.012037
2022-01-16 00:42:56,439 iteration 3678 : loss : 0.045459, loss_ce: 0.016533
2022-01-16 00:42:57,384 iteration 3679 : loss : 0.024644, loss_ce: 0.009675
2022-01-16 00:42:58,319 iteration 3680 : loss : 0.035376, loss_ce: 0.010650
2022-01-16 00:42:59,327 iteration 3681 : loss : 0.030014, loss_ce: 0.011373
2022-01-16 00:43:00,260 iteration 3682 : loss : 0.029560, loss_ce: 0.011911
2022-01-16 00:43:01,270 iteration 3683 : loss : 0.069976, loss_ce: 0.013909
2022-01-16 00:43:02,195 iteration 3684 : loss : 0.015133, loss_ce: 0.004636
2022-01-16 00:43:03,131 iteration 3685 : loss : 0.040729, loss_ce: 0.016077
2022-01-16 00:43:04,113 iteration 3686 : loss : 0.044977, loss_ce: 0.017710
2022-01-16 00:43:05,079 iteration 3687 : loss : 0.033135, loss_ce: 0.011624
2022-01-16 00:43:06,027 iteration 3688 : loss : 0.041303, loss_ce: 0.020721
2022-01-16 00:43:06,907 iteration 3689 : loss : 0.026514, loss_ce: 0.009436
 54%|███████████████▋             | 217/400 [1:04:00<53:31, 17.55s/it]2022-01-16 00:43:07,883 iteration 3690 : loss : 0.029918, loss_ce: 0.007198
2022-01-16 00:43:08,929 iteration 3691 : loss : 0.048763, loss_ce: 0.011905
2022-01-16 00:43:09,892 iteration 3692 : loss : 0.030034, loss_ce: 0.012482
2022-01-16 00:43:10,933 iteration 3693 : loss : 0.035116, loss_ce: 0.013212
2022-01-16 00:43:11,903 iteration 3694 : loss : 0.023356, loss_ce: 0.010196
2022-01-16 00:43:12,809 iteration 3695 : loss : 0.026001, loss_ce: 0.010548
2022-01-16 00:43:13,822 iteration 3696 : loss : 0.029006, loss_ce: 0.014082
2022-01-16 00:43:14,769 iteration 3697 : loss : 0.022959, loss_ce: 0.007827
2022-01-16 00:43:15,730 iteration 3698 : loss : 0.032060, loss_ce: 0.011451
2022-01-16 00:43:16,760 iteration 3699 : loss : 0.052336, loss_ce: 0.019746
2022-01-16 00:43:17,722 iteration 3700 : loss : 0.030937, loss_ce: 0.013463
2022-01-16 00:43:18,651 iteration 3701 : loss : 0.024698, loss_ce: 0.010321
2022-01-16 00:43:19,574 iteration 3702 : loss : 0.030277, loss_ce: 0.011712
2022-01-16 00:43:20,653 iteration 3703 : loss : 0.029560, loss_ce: 0.012283
2022-01-16 00:43:21,572 iteration 3704 : loss : 0.023730, loss_ce: 0.007562
2022-01-16 00:43:22,478 iteration 3705 : loss : 0.024224, loss_ce: 0.008440
2022-01-16 00:43:23,374 iteration 3706 : loss : 0.028955, loss_ce: 0.007405
 55%|███████████████▊             | 218/400 [1:04:16<52:13, 17.22s/it]2022-01-16 00:43:24,376 iteration 3707 : loss : 0.037230, loss_ce: 0.012162
2022-01-16 00:43:25,339 iteration 3708 : loss : 0.025952, loss_ce: 0.010291
2022-01-16 00:43:26,301 iteration 3709 : loss : 0.023323, loss_ce: 0.007531
2022-01-16 00:43:27,311 iteration 3710 : loss : 0.029517, loss_ce: 0.009913
2022-01-16 00:43:28,246 iteration 3711 : loss : 0.022013, loss_ce: 0.008204
2022-01-16 00:43:29,231 iteration 3712 : loss : 0.027019, loss_ce: 0.007671
2022-01-16 00:43:30,138 iteration 3713 : loss : 0.034233, loss_ce: 0.014988
2022-01-16 00:43:31,056 iteration 3714 : loss : 0.023976, loss_ce: 0.008402
2022-01-16 00:43:32,023 iteration 3715 : loss : 0.027921, loss_ce: 0.011200
2022-01-16 00:43:32,938 iteration 3716 : loss : 0.034220, loss_ce: 0.011229
2022-01-16 00:43:33,908 iteration 3717 : loss : 0.034607, loss_ce: 0.014996
2022-01-16 00:43:34,927 iteration 3718 : loss : 0.023263, loss_ce: 0.010151
2022-01-16 00:43:35,828 iteration 3719 : loss : 0.021915, loss_ce: 0.006016
2022-01-16 00:43:36,805 iteration 3720 : loss : 0.025557, loss_ce: 0.012703
2022-01-16 00:43:37,769 iteration 3721 : loss : 0.022004, loss_ce: 0.008507
2022-01-16 00:43:38,716 iteration 3722 : loss : 0.020082, loss_ce: 0.007657
2022-01-16 00:43:39,636 iteration 3723 : loss : 0.038880, loss_ce: 0.011063
 55%|███████████████▉             | 219/400 [1:04:32<51:05, 16.93s/it]2022-01-16 00:43:40,576 iteration 3724 : loss : 0.020896, loss_ce: 0.010493
2022-01-16 00:43:41,480 iteration 3725 : loss : 0.023030, loss_ce: 0.010285
2022-01-16 00:43:42,502 iteration 3726 : loss : 0.026952, loss_ce: 0.013457
2022-01-16 00:43:43,468 iteration 3727 : loss : 0.026574, loss_ce: 0.011973
2022-01-16 00:43:44,446 iteration 3728 : loss : 0.035673, loss_ce: 0.011277
2022-01-16 00:43:45,355 iteration 3729 : loss : 0.034452, loss_ce: 0.008987
2022-01-16 00:43:46,297 iteration 3730 : loss : 0.025070, loss_ce: 0.010841
2022-01-16 00:43:47,227 iteration 3731 : loss : 0.024018, loss_ce: 0.007787
2022-01-16 00:43:48,214 iteration 3732 : loss : 0.032467, loss_ce: 0.011318
2022-01-16 00:43:49,118 iteration 3733 : loss : 0.026114, loss_ce: 0.009674
2022-01-16 00:43:50,083 iteration 3734 : loss : 0.029017, loss_ce: 0.013535
2022-01-16 00:43:51,044 iteration 3735 : loss : 0.029953, loss_ce: 0.008955
2022-01-16 00:43:52,061 iteration 3736 : loss : 0.058114, loss_ce: 0.033304
2022-01-16 00:43:52,978 iteration 3737 : loss : 0.023543, loss_ce: 0.007777
2022-01-16 00:43:53,928 iteration 3738 : loss : 0.022516, loss_ce: 0.007372
2022-01-16 00:43:54,832 iteration 3739 : loss : 0.020871, loss_ce: 0.008478
2022-01-16 00:43:54,832 Training Data Eval:
2022-01-16 00:43:59,371   Average segmentation loss on training set: 0.0178
2022-01-16 00:43:59,372 Validation Data Eval:
2022-01-16 00:44:00,867   Average segmentation loss on validation set: 0.0975
2022-01-16 00:44:01,986 iteration 3740 : loss : 0.035859, loss_ce: 0.017396
 55%|███████████████▉             | 220/400 [1:04:55<55:40, 18.56s/it]2022-01-16 00:44:03,143 iteration 3741 : loss : 0.035210, loss_ce: 0.010215
2022-01-16 00:44:04,090 iteration 3742 : loss : 0.033464, loss_ce: 0.017423
2022-01-16 00:44:05,048 iteration 3743 : loss : 0.023889, loss_ce: 0.009221
2022-01-16 00:44:06,058 iteration 3744 : loss : 0.032652, loss_ce: 0.012111
2022-01-16 00:44:07,093 iteration 3745 : loss : 0.028059, loss_ce: 0.008886
2022-01-16 00:44:08,132 iteration 3746 : loss : 0.041659, loss_ce: 0.015751
2022-01-16 00:44:09,078 iteration 3747 : loss : 0.027226, loss_ce: 0.009279
2022-01-16 00:44:10,009 iteration 3748 : loss : 0.025634, loss_ce: 0.014599
2022-01-16 00:44:11,025 iteration 3749 : loss : 0.023034, loss_ce: 0.008255
2022-01-16 00:44:12,067 iteration 3750 : loss : 0.045120, loss_ce: 0.013673
2022-01-16 00:44:13,060 iteration 3751 : loss : 0.034878, loss_ce: 0.011646
2022-01-16 00:44:14,000 iteration 3752 : loss : 0.034586, loss_ce: 0.008973
2022-01-16 00:44:14,909 iteration 3753 : loss : 0.039385, loss_ce: 0.014173
2022-01-16 00:44:15,873 iteration 3754 : loss : 0.019560, loss_ce: 0.006716
2022-01-16 00:44:16,889 iteration 3755 : loss : 0.025325, loss_ce: 0.011213
2022-01-16 00:44:17,772 iteration 3756 : loss : 0.024609, loss_ce: 0.010463
2022-01-16 00:44:18,678 iteration 3757 : loss : 0.022169, loss_ce: 0.009867
 55%|████████████████             | 221/400 [1:05:11<53:42, 18.00s/it]2022-01-16 00:44:19,781 iteration 3758 : loss : 0.023030, loss_ce: 0.008384
2022-01-16 00:44:20,694 iteration 3759 : loss : 0.022716, loss_ce: 0.007402
2022-01-16 00:44:21,630 iteration 3760 : loss : 0.022703, loss_ce: 0.009345
2022-01-16 00:44:22,637 iteration 3761 : loss : 0.025122, loss_ce: 0.010004
2022-01-16 00:44:23,665 iteration 3762 : loss : 0.030376, loss_ce: 0.017597
2022-01-16 00:44:24,732 iteration 3763 : loss : 0.028944, loss_ce: 0.010494
2022-01-16 00:44:25,684 iteration 3764 : loss : 0.033015, loss_ce: 0.012100
2022-01-16 00:44:26,587 iteration 3765 : loss : 0.021593, loss_ce: 0.009210
2022-01-16 00:44:27,605 iteration 3766 : loss : 0.046078, loss_ce: 0.011679
2022-01-16 00:44:28,561 iteration 3767 : loss : 0.018521, loss_ce: 0.006533
2022-01-16 00:44:29,476 iteration 3768 : loss : 0.039508, loss_ce: 0.014699
2022-01-16 00:44:30,395 iteration 3769 : loss : 0.023558, loss_ce: 0.010648
2022-01-16 00:44:31,387 iteration 3770 : loss : 0.028556, loss_ce: 0.006657
2022-01-16 00:44:32,484 iteration 3771 : loss : 0.033957, loss_ce: 0.011677
2022-01-16 00:44:33,518 iteration 3772 : loss : 0.031178, loss_ce: 0.009128
2022-01-16 00:44:34,502 iteration 3773 : loss : 0.018439, loss_ce: 0.007068
2022-01-16 00:44:35,543 iteration 3774 : loss : 0.037354, loss_ce: 0.019566
 56%|████████████████             | 222/400 [1:05:28<52:23, 17.66s/it]2022-01-16 00:44:36,545 iteration 3775 : loss : 0.026902, loss_ce: 0.010004
2022-01-16 00:44:37,418 iteration 3776 : loss : 0.027403, loss_ce: 0.011291
2022-01-16 00:44:38,356 iteration 3777 : loss : 0.022858, loss_ce: 0.005849
2022-01-16 00:44:39,269 iteration 3778 : loss : 0.019892, loss_ce: 0.007521
2022-01-16 00:44:40,185 iteration 3779 : loss : 0.023415, loss_ce: 0.010863
2022-01-16 00:44:41,160 iteration 3780 : loss : 0.034190, loss_ce: 0.011255
2022-01-16 00:44:42,132 iteration 3781 : loss : 0.030480, loss_ce: 0.013357
2022-01-16 00:44:43,118 iteration 3782 : loss : 0.065065, loss_ce: 0.012531
2022-01-16 00:44:44,103 iteration 3783 : loss : 0.036653, loss_ce: 0.018095
2022-01-16 00:44:45,097 iteration 3784 : loss : 0.020617, loss_ce: 0.009474
2022-01-16 00:44:46,024 iteration 3785 : loss : 0.020255, loss_ce: 0.009316
2022-01-16 00:44:46,947 iteration 3786 : loss : 0.020250, loss_ce: 0.007335
2022-01-16 00:44:47,860 iteration 3787 : loss : 0.024319, loss_ce: 0.007767
2022-01-16 00:44:48,890 iteration 3788 : loss : 0.029208, loss_ce: 0.007306
2022-01-16 00:44:49,845 iteration 3789 : loss : 0.025598, loss_ce: 0.006534
2022-01-16 00:44:50,844 iteration 3790 : loss : 0.032377, loss_ce: 0.011765
2022-01-16 00:44:51,836 iteration 3791 : loss : 0.024171, loss_ce: 0.009291
 56%|████████████████▏            | 223/400 [1:05:44<50:53, 17.25s/it]2022-01-16 00:44:52,820 iteration 3792 : loss : 0.019285, loss_ce: 0.006672
2022-01-16 00:44:53,834 iteration 3793 : loss : 0.023339, loss_ce: 0.007363
2022-01-16 00:44:54,824 iteration 3794 : loss : 0.029734, loss_ce: 0.012525
2022-01-16 00:44:55,785 iteration 3795 : loss : 0.020465, loss_ce: 0.006123
2022-01-16 00:44:56,642 iteration 3796 : loss : 0.018205, loss_ce: 0.005962
2022-01-16 00:44:57,569 iteration 3797 : loss : 0.019038, loss_ce: 0.006854
2022-01-16 00:44:58,450 iteration 3798 : loss : 0.020707, loss_ce: 0.007372
2022-01-16 00:44:59,383 iteration 3799 : loss : 0.025291, loss_ce: 0.009312
2022-01-16 00:45:00,320 iteration 3800 : loss : 0.016437, loss_ce: 0.005087
2022-01-16 00:45:01,256 iteration 3801 : loss : 0.050822, loss_ce: 0.009274
2022-01-16 00:45:02,174 iteration 3802 : loss : 0.023443, loss_ce: 0.011014
2022-01-16 00:45:03,121 iteration 3803 : loss : 0.019147, loss_ce: 0.006102
2022-01-16 00:45:04,073 iteration 3804 : loss : 0.032001, loss_ce: 0.011578
2022-01-16 00:45:04,996 iteration 3805 : loss : 0.026501, loss_ce: 0.010094
2022-01-16 00:45:05,915 iteration 3806 : loss : 0.022725, loss_ce: 0.010569
2022-01-16 00:45:06,906 iteration 3807 : loss : 0.024256, loss_ce: 0.009493
2022-01-16 00:45:07,873 iteration 3808 : loss : 0.028800, loss_ce: 0.010896
 56%|████████████████▏            | 224/400 [1:06:00<49:31, 16.88s/it]2022-01-16 00:45:08,821 iteration 3809 : loss : 0.017509, loss_ce: 0.006071
2022-01-16 00:45:09,750 iteration 3810 : loss : 0.020920, loss_ce: 0.007990
2022-01-16 00:45:10,697 iteration 3811 : loss : 0.023608, loss_ce: 0.006851
2022-01-16 00:45:11,663 iteration 3812 : loss : 0.022871, loss_ce: 0.011134
2022-01-16 00:45:12,602 iteration 3813 : loss : 0.022009, loss_ce: 0.010517
2022-01-16 00:45:13,581 iteration 3814 : loss : 0.023549, loss_ce: 0.008498
2022-01-16 00:45:14,540 iteration 3815 : loss : 0.019618, loss_ce: 0.007776
2022-01-16 00:45:15,513 iteration 3816 : loss : 0.029770, loss_ce: 0.010657
2022-01-16 00:45:16,418 iteration 3817 : loss : 0.032653, loss_ce: 0.012619
2022-01-16 00:45:17,409 iteration 3818 : loss : 0.018739, loss_ce: 0.008370
2022-01-16 00:45:18,418 iteration 3819 : loss : 0.021914, loss_ce: 0.009464
2022-01-16 00:45:19,404 iteration 3820 : loss : 0.026681, loss_ce: 0.010106
2022-01-16 00:45:20,395 iteration 3821 : loss : 0.032009, loss_ce: 0.012286
2022-01-16 00:45:21,315 iteration 3822 : loss : 0.025056, loss_ce: 0.007572
2022-01-16 00:45:22,361 iteration 3823 : loss : 0.024580, loss_ce: 0.007079
2022-01-16 00:45:23,335 iteration 3824 : loss : 0.032889, loss_ce: 0.010132
2022-01-16 00:45:23,335 Training Data Eval:
2022-01-16 00:45:27,863   Average segmentation loss on training set: 0.0171
2022-01-16 00:45:27,863 Validation Data Eval:
2022-01-16 00:45:29,357   Average segmentation loss on validation set: 0.1014
2022-01-16 00:45:30,388 iteration 3825 : loss : 0.027611, loss_ce: 0.010144
 56%|████████████████▎            | 225/400 [1:06:23<54:09, 18.57s/it]2022-01-16 00:45:31,427 iteration 3826 : loss : 0.023861, loss_ce: 0.011392
2022-01-16 00:45:32,336 iteration 3827 : loss : 0.023238, loss_ce: 0.007739
2022-01-16 00:45:33,309 iteration 3828 : loss : 0.023153, loss_ce: 0.008120
2022-01-16 00:45:34,273 iteration 3829 : loss : 0.021055, loss_ce: 0.006305
2022-01-16 00:45:35,193 iteration 3830 : loss : 0.017495, loss_ce: 0.005974
2022-01-16 00:45:36,097 iteration 3831 : loss : 0.019670, loss_ce: 0.007098
2022-01-16 00:45:36,994 iteration 3832 : loss : 0.022830, loss_ce: 0.005565
2022-01-16 00:45:37,943 iteration 3833 : loss : 0.019203, loss_ce: 0.008724
2022-01-16 00:45:38,937 iteration 3834 : loss : 0.029555, loss_ce: 0.012868
2022-01-16 00:45:39,914 iteration 3835 : loss : 0.022533, loss_ce: 0.007374
2022-01-16 00:45:40,874 iteration 3836 : loss : 0.023194, loss_ce: 0.008913
2022-01-16 00:45:41,863 iteration 3837 : loss : 0.027925, loss_ce: 0.011071
2022-01-16 00:45:42,921 iteration 3838 : loss : 0.023189, loss_ce: 0.008637
2022-01-16 00:45:43,872 iteration 3839 : loss : 0.020840, loss_ce: 0.008869
2022-01-16 00:45:44,843 iteration 3840 : loss : 0.027113, loss_ce: 0.007611
2022-01-16 00:45:45,764 iteration 3841 : loss : 0.019635, loss_ce: 0.007763
2022-01-16 00:45:46,753 iteration 3842 : loss : 0.034488, loss_ce: 0.015761
 56%|████████████████▍            | 226/400 [1:06:39<51:56, 17.91s/it]2022-01-16 00:45:47,731 iteration 3843 : loss : 0.024423, loss_ce: 0.009978
2022-01-16 00:45:48,734 iteration 3844 : loss : 0.025656, loss_ce: 0.008343
2022-01-16 00:45:49,723 iteration 3845 : loss : 0.018586, loss_ce: 0.008463
2022-01-16 00:45:50,639 iteration 3846 : loss : 0.022765, loss_ce: 0.007921
2022-01-16 00:45:51,576 iteration 3847 : loss : 0.020471, loss_ce: 0.008241
2022-01-16 00:45:52,588 iteration 3848 : loss : 0.025768, loss_ce: 0.012213
2022-01-16 00:45:53,660 iteration 3849 : loss : 0.024514, loss_ce: 0.010803
2022-01-16 00:45:54,716 iteration 3850 : loss : 0.044557, loss_ce: 0.011816
2022-01-16 00:45:55,690 iteration 3851 : loss : 0.018690, loss_ce: 0.008331
2022-01-16 00:45:56,675 iteration 3852 : loss : 0.019603, loss_ce: 0.006020
2022-01-16 00:45:57,589 iteration 3853 : loss : 0.018423, loss_ce: 0.005502
2022-01-16 00:45:58,580 iteration 3854 : loss : 0.028622, loss_ce: 0.009615
2022-01-16 00:45:59,692 iteration 3855 : loss : 0.026616, loss_ce: 0.010942
2022-01-16 00:46:00,521 iteration 3856 : loss : 0.020329, loss_ce: 0.009268
2022-01-16 00:46:01,463 iteration 3857 : loss : 0.029222, loss_ce: 0.013696
2022-01-16 00:46:02,319 iteration 3858 : loss : 0.021782, loss_ce: 0.009091
2022-01-16 00:46:03,266 iteration 3859 : loss : 0.024731, loss_ce: 0.010668
 57%|████████████████▍            | 227/400 [1:06:56<50:25, 17.49s/it]2022-01-16 00:46:04,278 iteration 3860 : loss : 0.019532, loss_ce: 0.007688
2022-01-16 00:46:05,319 iteration 3861 : loss : 0.038981, loss_ce: 0.017683
2022-01-16 00:46:06,315 iteration 3862 : loss : 0.021862, loss_ce: 0.007774
2022-01-16 00:46:07,295 iteration 3863 : loss : 0.035952, loss_ce: 0.014367
2022-01-16 00:46:08,304 iteration 3864 : loss : 0.025967, loss_ce: 0.009220
2022-01-16 00:46:09,264 iteration 3865 : loss : 0.042097, loss_ce: 0.013968
2022-01-16 00:46:10,352 iteration 3866 : loss : 0.025537, loss_ce: 0.008338
2022-01-16 00:46:11,306 iteration 3867 : loss : 0.028838, loss_ce: 0.009840
2022-01-16 00:46:12,329 iteration 3868 : loss : 0.038256, loss_ce: 0.011215
2022-01-16 00:46:13,327 iteration 3869 : loss : 0.037678, loss_ce: 0.017238
2022-01-16 00:46:14,350 iteration 3870 : loss : 0.026249, loss_ce: 0.009353
2022-01-16 00:46:15,351 iteration 3871 : loss : 0.025401, loss_ce: 0.006136
2022-01-16 00:46:16,276 iteration 3872 : loss : 0.031739, loss_ce: 0.011446
2022-01-16 00:46:17,198 iteration 3873 : loss : 0.028198, loss_ce: 0.015289
2022-01-16 00:46:18,186 iteration 3874 : loss : 0.042101, loss_ce: 0.016137
2022-01-16 00:46:19,172 iteration 3875 : loss : 0.034667, loss_ce: 0.014963
2022-01-16 00:46:20,161 iteration 3876 : loss : 0.031929, loss_ce: 0.010389
 57%|████████████████▌            | 228/400 [1:07:13<49:38, 17.32s/it]2022-01-16 00:46:21,157 iteration 3877 : loss : 0.024211, loss_ce: 0.009763
2022-01-16 00:46:22,154 iteration 3878 : loss : 0.024282, loss_ce: 0.009123
2022-01-16 00:46:23,084 iteration 3879 : loss : 0.022641, loss_ce: 0.008576
2022-01-16 00:46:24,080 iteration 3880 : loss : 0.025566, loss_ce: 0.011839
2022-01-16 00:46:25,009 iteration 3881 : loss : 0.026494, loss_ce: 0.012335
2022-01-16 00:46:26,070 iteration 3882 : loss : 0.046145, loss_ce: 0.010930
2022-01-16 00:46:27,097 iteration 3883 : loss : 0.042305, loss_ce: 0.015980
2022-01-16 00:46:28,085 iteration 3884 : loss : 0.024730, loss_ce: 0.009465
2022-01-16 00:46:29,103 iteration 3885 : loss : 0.053693, loss_ce: 0.010801
2022-01-16 00:46:30,121 iteration 3886 : loss : 0.026066, loss_ce: 0.009929
2022-01-16 00:46:31,029 iteration 3887 : loss : 0.021108, loss_ce: 0.007613
2022-01-16 00:46:32,039 iteration 3888 : loss : 0.028228, loss_ce: 0.013949
2022-01-16 00:46:33,019 iteration 3889 : loss : 0.025133, loss_ce: 0.010007
2022-01-16 00:46:34,106 iteration 3890 : loss : 0.036653, loss_ce: 0.011128
2022-01-16 00:46:35,044 iteration 3891 : loss : 0.039867, loss_ce: 0.019229
2022-01-16 00:46:36,020 iteration 3892 : loss : 0.027869, loss_ce: 0.013051
2022-01-16 00:46:37,029 iteration 3893 : loss : 0.030255, loss_ce: 0.011839
 57%|████████████████▌            | 229/400 [1:07:30<48:57, 17.18s/it]2022-01-16 00:46:38,045 iteration 3894 : loss : 0.021834, loss_ce: 0.006490
2022-01-16 00:46:38,966 iteration 3895 : loss : 0.024018, loss_ce: 0.009050
2022-01-16 00:46:39,933 iteration 3896 : loss : 0.042592, loss_ce: 0.021112
2022-01-16 00:46:40,947 iteration 3897 : loss : 0.030955, loss_ce: 0.013675
2022-01-16 00:46:41,952 iteration 3898 : loss : 0.029158, loss_ce: 0.008473
2022-01-16 00:46:42,845 iteration 3899 : loss : 0.027251, loss_ce: 0.009686
2022-01-16 00:46:43,772 iteration 3900 : loss : 0.024540, loss_ce: 0.010181
2022-01-16 00:46:44,678 iteration 3901 : loss : 0.021059, loss_ce: 0.008915
2022-01-16 00:46:45,596 iteration 3902 : loss : 0.023143, loss_ce: 0.008741
2022-01-16 00:46:46,472 iteration 3903 : loss : 0.024464, loss_ce: 0.006712
2022-01-16 00:46:47,408 iteration 3904 : loss : 0.029573, loss_ce: 0.009775
2022-01-16 00:46:48,351 iteration 3905 : loss : 0.031880, loss_ce: 0.008871
2022-01-16 00:46:49,211 iteration 3906 : loss : 0.018535, loss_ce: 0.007908
2022-01-16 00:46:50,059 iteration 3907 : loss : 0.016484, loss_ce: 0.005881
2022-01-16 00:46:50,934 iteration 3908 : loss : 0.024442, loss_ce: 0.008756
2022-01-16 00:46:51,877 iteration 3909 : loss : 0.028319, loss_ce: 0.014986
2022-01-16 00:46:51,877 Training Data Eval:
2022-01-16 00:46:56,418   Average segmentation loss on training set: 0.0160
2022-01-16 00:46:56,418 Validation Data Eval:
2022-01-16 00:46:57,908   Average segmentation loss on validation set: 0.0848
2022-01-16 00:46:58,933 iteration 3910 : loss : 0.021918, loss_ce: 0.007520
 57%|████████████████▋            | 230/400 [1:07:52<52:41, 18.60s/it]2022-01-16 00:46:59,900 iteration 3911 : loss : 0.021124, loss_ce: 0.010150
2022-01-16 00:47:00,887 iteration 3912 : loss : 0.028944, loss_ce: 0.012323
2022-01-16 00:47:01,838 iteration 3913 : loss : 0.020011, loss_ce: 0.007917
2022-01-16 00:47:02,780 iteration 3914 : loss : 0.018429, loss_ce: 0.008337
2022-01-16 00:47:03,722 iteration 3915 : loss : 0.025938, loss_ce: 0.010913
2022-01-16 00:47:04,628 iteration 3916 : loss : 0.021682, loss_ce: 0.007576
2022-01-16 00:47:05,619 iteration 3917 : loss : 0.025755, loss_ce: 0.009134
2022-01-16 00:47:06,605 iteration 3918 : loss : 0.033914, loss_ce: 0.012254
2022-01-16 00:47:07,703 iteration 3919 : loss : 0.030314, loss_ce: 0.009361
2022-01-16 00:47:08,615 iteration 3920 : loss : 0.023775, loss_ce: 0.009088
2022-01-16 00:47:09,563 iteration 3921 : loss : 0.022251, loss_ce: 0.008521
2022-01-16 00:47:10,564 iteration 3922 : loss : 0.026114, loss_ce: 0.010059
2022-01-16 00:47:11,492 iteration 3923 : loss : 0.019288, loss_ce: 0.009706
2022-01-16 00:47:12,392 iteration 3924 : loss : 0.025985, loss_ce: 0.006353
2022-01-16 00:47:13,431 iteration 3925 : loss : 0.041397, loss_ce: 0.016372
2022-01-16 00:47:14,445 iteration 3926 : loss : 0.020065, loss_ce: 0.007767
2022-01-16 00:47:15,397 iteration 3927 : loss : 0.033491, loss_ce: 0.013464
 58%|████████████████▋            | 231/400 [1:08:08<50:35, 17.96s/it]2022-01-16 00:47:16,478 iteration 3928 : loss : 0.041515, loss_ce: 0.016797
2022-01-16 00:47:17,445 iteration 3929 : loss : 0.019932, loss_ce: 0.009226
2022-01-16 00:47:18,471 iteration 3930 : loss : 0.022312, loss_ce: 0.009663
2022-01-16 00:47:19,482 iteration 3931 : loss : 0.021836, loss_ce: 0.008406
2022-01-16 00:47:20,486 iteration 3932 : loss : 0.029986, loss_ce: 0.009034
2022-01-16 00:47:21,540 iteration 3933 : loss : 0.022952, loss_ce: 0.008514
2022-01-16 00:47:22,536 iteration 3934 : loss : 0.018583, loss_ce: 0.007853
2022-01-16 00:47:23,415 iteration 3935 : loss : 0.020960, loss_ce: 0.008691
2022-01-16 00:47:24,519 iteration 3936 : loss : 0.020851, loss_ce: 0.007920
2022-01-16 00:47:25,435 iteration 3937 : loss : 0.032589, loss_ce: 0.014892
2022-01-16 00:47:26,450 iteration 3938 : loss : 0.060205, loss_ce: 0.012387
2022-01-16 00:47:27,327 iteration 3939 : loss : 0.041088, loss_ce: 0.012350
2022-01-16 00:47:28,255 iteration 3940 : loss : 0.020857, loss_ce: 0.007599
2022-01-16 00:47:29,205 iteration 3941 : loss : 0.022440, loss_ce: 0.008303
2022-01-16 00:47:30,220 iteration 3942 : loss : 0.042749, loss_ce: 0.020457
2022-01-16 00:47:31,139 iteration 3943 : loss : 0.024656, loss_ce: 0.005656
2022-01-16 00:47:32,167 iteration 3944 : loss : 0.034020, loss_ce: 0.013199
 58%|████████████████▊            | 232/400 [1:08:25<49:16, 17.60s/it]2022-01-16 00:47:33,213 iteration 3945 : loss : 0.024690, loss_ce: 0.011151
2022-01-16 00:47:34,074 iteration 3946 : loss : 0.021623, loss_ce: 0.010795
2022-01-16 00:47:35,015 iteration 3947 : loss : 0.018572, loss_ce: 0.005447
2022-01-16 00:47:36,115 iteration 3948 : loss : 0.029018, loss_ce: 0.010184
2022-01-16 00:47:37,122 iteration 3949 : loss : 0.034745, loss_ce: 0.013383
2022-01-16 00:47:38,164 iteration 3950 : loss : 0.026362, loss_ce: 0.007734
2022-01-16 00:47:39,063 iteration 3951 : loss : 0.021534, loss_ce: 0.009363
2022-01-16 00:47:40,077 iteration 3952 : loss : 0.020382, loss_ce: 0.007162
2022-01-16 00:47:41,106 iteration 3953 : loss : 0.038146, loss_ce: 0.011559
2022-01-16 00:47:42,060 iteration 3954 : loss : 0.024906, loss_ce: 0.008393
2022-01-16 00:47:43,006 iteration 3955 : loss : 0.015849, loss_ce: 0.005387
2022-01-16 00:47:44,102 iteration 3956 : loss : 0.029973, loss_ce: 0.011017
2022-01-16 00:47:45,022 iteration 3957 : loss : 0.023741, loss_ce: 0.010379
2022-01-16 00:47:45,955 iteration 3958 : loss : 0.022850, loss_ce: 0.008550
2022-01-16 00:47:47,005 iteration 3959 : loss : 0.033513, loss_ce: 0.008266
2022-01-16 00:47:47,942 iteration 3960 : loss : 0.023648, loss_ce: 0.011122
2022-01-16 00:47:48,892 iteration 3961 : loss : 0.028437, loss_ce: 0.010522
 58%|████████████████▉            | 233/400 [1:08:41<48:15, 17.34s/it]2022-01-16 00:47:49,947 iteration 3962 : loss : 0.022647, loss_ce: 0.008313
2022-01-16 00:47:50,907 iteration 3963 : loss : 0.041858, loss_ce: 0.018584
2022-01-16 00:47:51,971 iteration 3964 : loss : 0.024875, loss_ce: 0.010829
2022-01-16 00:47:52,882 iteration 3965 : loss : 0.020581, loss_ce: 0.005891
2022-01-16 00:47:53,895 iteration 3966 : loss : 0.031207, loss_ce: 0.012052
2022-01-16 00:47:54,866 iteration 3967 : loss : 0.026088, loss_ce: 0.009392
2022-01-16 00:47:55,720 iteration 3968 : loss : 0.025347, loss_ce: 0.008358
2022-01-16 00:47:56,696 iteration 3969 : loss : 0.035638, loss_ce: 0.015330
2022-01-16 00:47:57,639 iteration 3970 : loss : 0.024419, loss_ce: 0.007570
2022-01-16 00:47:58,481 iteration 3971 : loss : 0.018257, loss_ce: 0.007225
2022-01-16 00:47:59,470 iteration 3972 : loss : 0.028249, loss_ce: 0.006443
2022-01-16 00:48:00,369 iteration 3973 : loss : 0.026222, loss_ce: 0.014019
2022-01-16 00:48:01,226 iteration 3974 : loss : 0.019344, loss_ce: 0.005961
2022-01-16 00:48:02,200 iteration 3975 : loss : 0.022946, loss_ce: 0.008146
2022-01-16 00:48:03,231 iteration 3976 : loss : 0.035997, loss_ce: 0.014009
2022-01-16 00:48:04,259 iteration 3977 : loss : 0.021540, loss_ce: 0.009416
2022-01-16 00:48:05,310 iteration 3978 : loss : 0.034844, loss_ce: 0.012603
 58%|████████████████▉            | 234/400 [1:08:58<47:12, 17.06s/it]2022-01-16 00:48:06,335 iteration 3979 : loss : 0.021864, loss_ce: 0.007713
2022-01-16 00:48:07,336 iteration 3980 : loss : 0.032966, loss_ce: 0.009863
2022-01-16 00:48:08,278 iteration 3981 : loss : 0.029133, loss_ce: 0.011692
2022-01-16 00:48:09,124 iteration 3982 : loss : 0.019790, loss_ce: 0.007137
2022-01-16 00:48:09,991 iteration 3983 : loss : 0.020160, loss_ce: 0.008967
2022-01-16 00:48:10,906 iteration 3984 : loss : 0.021862, loss_ce: 0.009344
2022-01-16 00:48:11,881 iteration 3985 : loss : 0.032167, loss_ce: 0.017296
2022-01-16 00:48:12,934 iteration 3986 : loss : 0.022572, loss_ce: 0.008973
2022-01-16 00:48:13,928 iteration 3987 : loss : 0.029889, loss_ce: 0.011228
2022-01-16 00:48:14,887 iteration 3988 : loss : 0.024780, loss_ce: 0.011308
2022-01-16 00:48:15,816 iteration 3989 : loss : 0.043954, loss_ce: 0.009817
2022-01-16 00:48:16,742 iteration 3990 : loss : 0.029152, loss_ce: 0.009294
2022-01-16 00:48:17,765 iteration 3991 : loss : 0.029576, loss_ce: 0.006717
2022-01-16 00:48:18,744 iteration 3992 : loss : 0.039662, loss_ce: 0.013455
2022-01-16 00:48:19,761 iteration 3993 : loss : 0.023695, loss_ce: 0.008361
2022-01-16 00:48:20,699 iteration 3994 : loss : 0.024680, loss_ce: 0.012072
2022-01-16 00:48:20,699 Training Data Eval:
2022-01-16 00:48:25,240   Average segmentation loss on training set: 0.0156
2022-01-16 00:48:25,241 Validation Data Eval:
2022-01-16 00:48:26,734   Average segmentation loss on validation set: 0.0975
2022-01-16 00:48:27,625 iteration 3995 : loss : 0.021378, loss_ce: 0.009061
 59%|█████████████████            | 235/400 [1:09:20<51:15, 18.64s/it]2022-01-16 00:48:28,714 iteration 3996 : loss : 0.022416, loss_ce: 0.006627
2022-01-16 00:48:29,607 iteration 3997 : loss : 0.023619, loss_ce: 0.007023
2022-01-16 00:48:30,585 iteration 3998 : loss : 0.027081, loss_ce: 0.015338
2022-01-16 00:48:31,524 iteration 3999 : loss : 0.019004, loss_ce: 0.004696
2022-01-16 00:48:32,539 iteration 4000 : loss : 0.021314, loss_ce: 0.010653
2022-01-16 00:48:33,420 iteration 4001 : loss : 0.017148, loss_ce: 0.006655
2022-01-16 00:48:34,382 iteration 4002 : loss : 0.020329, loss_ce: 0.008367
2022-01-16 00:48:35,352 iteration 4003 : loss : 0.018864, loss_ce: 0.008099
2022-01-16 00:48:36,353 iteration 4004 : loss : 0.035684, loss_ce: 0.007779
2022-01-16 00:48:37,319 iteration 4005 : loss : 0.026974, loss_ce: 0.013275
2022-01-16 00:48:38,217 iteration 4006 : loss : 0.022925, loss_ce: 0.010024
2022-01-16 00:48:39,226 iteration 4007 : loss : 0.033838, loss_ce: 0.009744
2022-01-16 00:48:40,140 iteration 4008 : loss : 0.020090, loss_ce: 0.008301
2022-01-16 00:48:41,090 iteration 4009 : loss : 0.024529, loss_ce: 0.011448
2022-01-16 00:48:42,114 iteration 4010 : loss : 0.027775, loss_ce: 0.011480
2022-01-16 00:48:43,020 iteration 4011 : loss : 0.022699, loss_ce: 0.006533
2022-01-16 00:48:44,060 iteration 4012 : loss : 0.027825, loss_ce: 0.013677
 59%|█████████████████            | 236/400 [1:09:37<49:08, 17.98s/it]2022-01-16 00:48:45,171 iteration 4013 : loss : 0.035844, loss_ce: 0.011680
2022-01-16 00:48:46,074 iteration 4014 : loss : 0.020346, loss_ce: 0.006543
2022-01-16 00:48:47,085 iteration 4015 : loss : 0.031879, loss_ce: 0.012848
2022-01-16 00:48:48,088 iteration 4016 : loss : 0.017968, loss_ce: 0.006149
2022-01-16 00:48:49,109 iteration 4017 : loss : 0.026732, loss_ce: 0.008215
2022-01-16 00:48:50,024 iteration 4018 : loss : 0.020461, loss_ce: 0.006681
2022-01-16 00:48:50,976 iteration 4019 : loss : 0.021213, loss_ce: 0.010802
2022-01-16 00:48:51,877 iteration 4020 : loss : 0.022718, loss_ce: 0.012384
2022-01-16 00:48:52,800 iteration 4021 : loss : 0.018386, loss_ce: 0.007260
2022-01-16 00:48:53,789 iteration 4022 : loss : 0.028639, loss_ce: 0.014045
2022-01-16 00:48:54,745 iteration 4023 : loss : 0.017943, loss_ce: 0.006195
2022-01-16 00:48:55,629 iteration 4024 : loss : 0.019117, loss_ce: 0.006467
2022-01-16 00:48:56,542 iteration 4025 : loss : 0.021134, loss_ce: 0.007337
2022-01-16 00:48:57,531 iteration 4026 : loss : 0.019459, loss_ce: 0.008462
2022-01-16 00:48:58,517 iteration 4027 : loss : 0.025884, loss_ce: 0.009175
2022-01-16 00:48:59,535 iteration 4028 : loss : 0.032166, loss_ce: 0.011834
2022-01-16 00:49:00,442 iteration 4029 : loss : 0.029147, loss_ce: 0.013983
 59%|█████████████████▏           | 237/400 [1:09:53<47:32, 17.50s/it]2022-01-16 00:49:01,535 iteration 4030 : loss : 0.024836, loss_ce: 0.009805
2022-01-16 00:49:02,520 iteration 4031 : loss : 0.028243, loss_ce: 0.009903
2022-01-16 00:49:03,475 iteration 4032 : loss : 0.030870, loss_ce: 0.014491
2022-01-16 00:49:04,429 iteration 4033 : loss : 0.026984, loss_ce: 0.009148
2022-01-16 00:49:05,314 iteration 4034 : loss : 0.022943, loss_ce: 0.007779
2022-01-16 00:49:06,244 iteration 4035 : loss : 0.018033, loss_ce: 0.005357
2022-01-16 00:49:07,236 iteration 4036 : loss : 0.032340, loss_ce: 0.014369
2022-01-16 00:49:08,140 iteration 4037 : loss : 0.018766, loss_ce: 0.008772
2022-01-16 00:49:09,165 iteration 4038 : loss : 0.024259, loss_ce: 0.008547
2022-01-16 00:49:10,219 iteration 4039 : loss : 0.029178, loss_ce: 0.011057
2022-01-16 00:49:11,275 iteration 4040 : loss : 0.025796, loss_ce: 0.010776
2022-01-16 00:49:12,301 iteration 4041 : loss : 0.039492, loss_ce: 0.014018
2022-01-16 00:49:13,229 iteration 4042 : loss : 0.036075, loss_ce: 0.014623
2022-01-16 00:49:14,206 iteration 4043 : loss : 0.183492, loss_ce: 0.009555
2022-01-16 00:49:15,130 iteration 4044 : loss : 0.032972, loss_ce: 0.012842
2022-01-16 00:49:16,077 iteration 4045 : loss : 0.021303, loss_ce: 0.010254
2022-01-16 00:49:17,092 iteration 4046 : loss : 0.022363, loss_ce: 0.010389
 60%|█████████████████▎           | 238/400 [1:10:10<46:33, 17.24s/it]2022-01-16 00:49:18,212 iteration 4047 : loss : 0.022439, loss_ce: 0.010533
2022-01-16 00:49:19,227 iteration 4048 : loss : 0.031853, loss_ce: 0.012237
2022-01-16 00:49:20,154 iteration 4049 : loss : 0.022187, loss_ce: 0.009092
2022-01-16 00:49:21,148 iteration 4050 : loss : 0.030088, loss_ce: 0.011199
2022-01-16 00:49:22,225 iteration 4051 : loss : 0.100930, loss_ce: 0.020677
2022-01-16 00:49:23,118 iteration 4052 : loss : 0.023264, loss_ce: 0.007738
2022-01-16 00:49:23,979 iteration 4053 : loss : 0.021281, loss_ce: 0.007131
2022-01-16 00:49:24,879 iteration 4054 : loss : 0.036009, loss_ce: 0.008874
2022-01-16 00:49:25,816 iteration 4055 : loss : 0.023375, loss_ce: 0.009711
2022-01-16 00:49:26,789 iteration 4056 : loss : 0.064388, loss_ce: 0.035488
2022-01-16 00:49:27,694 iteration 4057 : loss : 0.029328, loss_ce: 0.005965
2022-01-16 00:49:28,635 iteration 4058 : loss : 0.019596, loss_ce: 0.006448
2022-01-16 00:49:29,702 iteration 4059 : loss : 0.041197, loss_ce: 0.016668
2022-01-16 00:49:30,676 iteration 4060 : loss : 0.025569, loss_ce: 0.011631
2022-01-16 00:49:31,637 iteration 4061 : loss : 0.041137, loss_ce: 0.018478
2022-01-16 00:49:32,634 iteration 4062 : loss : 0.050147, loss_ce: 0.020029
2022-01-16 00:49:33,612 iteration 4063 : loss : 0.050245, loss_ce: 0.015570
 60%|█████████████████▎           | 239/400 [1:10:26<45:40, 17.02s/it]2022-01-16 00:49:34,609 iteration 4064 : loss : 0.030870, loss_ce: 0.007608
2022-01-16 00:49:35,536 iteration 4065 : loss : 0.023547, loss_ce: 0.009220
2022-01-16 00:49:36,571 iteration 4066 : loss : 0.045838, loss_ce: 0.017943
2022-01-16 00:49:37,496 iteration 4067 : loss : 0.027072, loss_ce: 0.010804
2022-01-16 00:49:38,453 iteration 4068 : loss : 0.028887, loss_ce: 0.011370
2022-01-16 00:49:39,445 iteration 4069 : loss : 0.025199, loss_ce: 0.010154
2022-01-16 00:49:40,430 iteration 4070 : loss : 0.028468, loss_ce: 0.011285
2022-01-16 00:49:41,458 iteration 4071 : loss : 0.035725, loss_ce: 0.013072
2022-01-16 00:49:42,411 iteration 4072 : loss : 0.021002, loss_ce: 0.006686
2022-01-16 00:49:43,329 iteration 4073 : loss : 0.022010, loss_ce: 0.007884
2022-01-16 00:49:44,297 iteration 4074 : loss : 0.024737, loss_ce: 0.011651
2022-01-16 00:49:45,305 iteration 4075 : loss : 0.022315, loss_ce: 0.007612
2022-01-16 00:49:46,215 iteration 4076 : loss : 0.041003, loss_ce: 0.015767
2022-01-16 00:49:47,163 iteration 4077 : loss : 0.022898, loss_ce: 0.009049
2022-01-16 00:49:48,182 iteration 4078 : loss : 0.030762, loss_ce: 0.010407
2022-01-16 00:49:49,179 iteration 4079 : loss : 0.031110, loss_ce: 0.013671
2022-01-16 00:49:49,180 Training Data Eval:
2022-01-16 00:49:53,717   Average segmentation loss on training set: 0.0179
2022-01-16 00:49:53,717 Validation Data Eval:
2022-01-16 00:49:55,210   Average segmentation loss on validation set: 0.0678
2022-01-16 00:49:56,221 iteration 4080 : loss : 0.031285, loss_ce: 0.013629
 60%|█████████████████▍           | 240/400 [1:10:49<49:52, 18.71s/it]2022-01-16 00:49:57,279 iteration 4081 : loss : 0.026567, loss_ce: 0.010021
2022-01-16 00:49:58,248 iteration 4082 : loss : 0.018949, loss_ce: 0.007585
2022-01-16 00:49:59,150 iteration 4083 : loss : 0.020017, loss_ce: 0.008405
2022-01-16 00:50:00,104 iteration 4084 : loss : 0.023230, loss_ce: 0.007421
2022-01-16 00:50:01,009 iteration 4085 : loss : 0.029794, loss_ce: 0.009813
2022-01-16 00:50:02,102 iteration 4086 : loss : 0.044195, loss_ce: 0.016653
2022-01-16 00:50:03,085 iteration 4087 : loss : 0.046642, loss_ce: 0.008832
2022-01-16 00:50:03,971 iteration 4088 : loss : 0.019569, loss_ce: 0.008916
2022-01-16 00:50:04,924 iteration 4089 : loss : 0.032154, loss_ce: 0.011014
2022-01-16 00:50:05,781 iteration 4090 : loss : 0.022472, loss_ce: 0.007206
2022-01-16 00:50:06,723 iteration 4091 : loss : 0.030897, loss_ce: 0.012921
2022-01-16 00:50:07,695 iteration 4092 : loss : 0.017779, loss_ce: 0.005868
2022-01-16 00:50:08,671 iteration 4093 : loss : 0.039864, loss_ce: 0.015317
2022-01-16 00:50:09,599 iteration 4094 : loss : 0.025675, loss_ce: 0.009375
2022-01-16 00:50:10,572 iteration 4095 : loss : 0.044987, loss_ce: 0.023456
2022-01-16 00:50:11,492 iteration 4096 : loss : 0.020781, loss_ce: 0.010914
2022-01-16 00:50:12,428 iteration 4097 : loss : 0.029803, loss_ce: 0.010780
 60%|█████████████████▍           | 241/400 [1:11:05<47:34, 17.95s/it]2022-01-16 00:50:13,426 iteration 4098 : loss : 0.024597, loss_ce: 0.009424
2022-01-16 00:50:14,343 iteration 4099 : loss : 0.032411, loss_ce: 0.009259
2022-01-16 00:50:15,305 iteration 4100 : loss : 0.019656, loss_ce: 0.006787
2022-01-16 00:50:16,314 iteration 4101 : loss : 0.031803, loss_ce: 0.009899
2022-01-16 00:50:17,320 iteration 4102 : loss : 0.029584, loss_ce: 0.012866
2022-01-16 00:50:18,304 iteration 4103 : loss : 0.029288, loss_ce: 0.012924
2022-01-16 00:50:19,269 iteration 4104 : loss : 0.025958, loss_ce: 0.011660
2022-01-16 00:50:20,244 iteration 4105 : loss : 0.022498, loss_ce: 0.009834
2022-01-16 00:50:21,185 iteration 4106 : loss : 0.025693, loss_ce: 0.010343
2022-01-16 00:50:22,120 iteration 4107 : loss : 0.020084, loss_ce: 0.007277
2022-01-16 00:50:23,077 iteration 4108 : loss : 0.024692, loss_ce: 0.009571
2022-01-16 00:50:23,971 iteration 4109 : loss : 0.020453, loss_ce: 0.006831
2022-01-16 00:50:24,965 iteration 4110 : loss : 0.025203, loss_ce: 0.008853
2022-01-16 00:50:26,086 iteration 4111 : loss : 0.037573, loss_ce: 0.017999
2022-01-16 00:50:27,009 iteration 4112 : loss : 0.025069, loss_ce: 0.008013
2022-01-16 00:50:28,013 iteration 4113 : loss : 0.029378, loss_ce: 0.008710
2022-01-16 00:50:28,963 iteration 4114 : loss : 0.017749, loss_ce: 0.007315
 60%|█████████████████▌           | 242/400 [1:11:22<46:08, 17.53s/it]2022-01-16 00:50:29,930 iteration 4115 : loss : 0.024937, loss_ce: 0.012129
2022-01-16 00:50:30,947 iteration 4116 : loss : 0.022227, loss_ce: 0.007803
2022-01-16 00:50:31,840 iteration 4117 : loss : 0.017651, loss_ce: 0.006418
2022-01-16 00:50:32,867 iteration 4118 : loss : 0.027085, loss_ce: 0.011762
2022-01-16 00:50:33,958 iteration 4119 : loss : 0.037004, loss_ce: 0.010895
2022-01-16 00:50:34,947 iteration 4120 : loss : 0.040563, loss_ce: 0.012238
2022-01-16 00:50:35,862 iteration 4121 : loss : 0.019839, loss_ce: 0.006547
2022-01-16 00:50:36,809 iteration 4122 : loss : 0.038760, loss_ce: 0.011658
2022-01-16 00:50:37,706 iteration 4123 : loss : 0.012919, loss_ce: 0.005416
2022-01-16 00:50:38,705 iteration 4124 : loss : 0.025624, loss_ce: 0.013243
2022-01-16 00:50:39,690 iteration 4125 : loss : 0.037639, loss_ce: 0.016323
2022-01-16 00:50:40,661 iteration 4126 : loss : 0.022814, loss_ce: 0.009086
2022-01-16 00:50:41,573 iteration 4127 : loss : 0.014536, loss_ce: 0.006907
2022-01-16 00:50:42,646 iteration 4128 : loss : 0.044923, loss_ce: 0.011490
2022-01-16 00:50:43,539 iteration 4129 : loss : 0.023658, loss_ce: 0.004785
2022-01-16 00:50:44,422 iteration 4130 : loss : 0.017727, loss_ce: 0.005331
2022-01-16 00:50:45,355 iteration 4131 : loss : 0.018286, loss_ce: 0.008240
 61%|█████████████████▌           | 243/400 [1:11:38<44:58, 17.19s/it]2022-01-16 00:50:46,428 iteration 4132 : loss : 0.030275, loss_ce: 0.009370
2022-01-16 00:50:47,408 iteration 4133 : loss : 0.020446, loss_ce: 0.006509
2022-01-16 00:50:48,408 iteration 4134 : loss : 0.030586, loss_ce: 0.013238
2022-01-16 00:50:49,284 iteration 4135 : loss : 0.025556, loss_ce: 0.010776
2022-01-16 00:50:50,232 iteration 4136 : loss : 0.026458, loss_ce: 0.012119
2022-01-16 00:50:51,112 iteration 4137 : loss : 0.019056, loss_ce: 0.007029
2022-01-16 00:50:52,098 iteration 4138 : loss : 0.020794, loss_ce: 0.009317
2022-01-16 00:50:53,089 iteration 4139 : loss : 0.021130, loss_ce: 0.009148
2022-01-16 00:50:54,066 iteration 4140 : loss : 0.016705, loss_ce: 0.007458
2022-01-16 00:50:55,047 iteration 4141 : loss : 0.023876, loss_ce: 0.009491
2022-01-16 00:50:56,091 iteration 4142 : loss : 0.033420, loss_ce: 0.013365
2022-01-16 00:50:56,950 iteration 4143 : loss : 0.059017, loss_ce: 0.016346
2022-01-16 00:50:57,830 iteration 4144 : loss : 0.022148, loss_ce: 0.005963
2022-01-16 00:50:58,837 iteration 4145 : loss : 0.019132, loss_ce: 0.007481
2022-01-16 00:50:59,757 iteration 4146 : loss : 0.020098, loss_ce: 0.008749
2022-01-16 00:51:00,725 iteration 4147 : loss : 0.022020, loss_ce: 0.007807
2022-01-16 00:51:01,647 iteration 4148 : loss : 0.030739, loss_ce: 0.010979
 61%|█████████████████▋           | 244/400 [1:11:54<43:59, 16.92s/it]2022-01-16 00:51:02,580 iteration 4149 : loss : 0.022198, loss_ce: 0.007952
2022-01-16 00:51:03,551 iteration 4150 : loss : 0.020384, loss_ce: 0.006300
2022-01-16 00:51:04,560 iteration 4151 : loss : 0.041690, loss_ce: 0.019547
2022-01-16 00:51:05,525 iteration 4152 : loss : 0.029606, loss_ce: 0.011872
2022-01-16 00:51:06,400 iteration 4153 : loss : 0.017318, loss_ce: 0.006422
2022-01-16 00:51:07,370 iteration 4154 : loss : 0.017935, loss_ce: 0.007062
2022-01-16 00:51:08,310 iteration 4155 : loss : 0.021387, loss_ce: 0.006522
2022-01-16 00:51:09,200 iteration 4156 : loss : 0.016262, loss_ce: 0.006262
2022-01-16 00:51:10,211 iteration 4157 : loss : 0.043266, loss_ce: 0.027918
2022-01-16 00:51:11,129 iteration 4158 : loss : 0.020038, loss_ce: 0.007385
2022-01-16 00:51:12,059 iteration 4159 : loss : 0.019562, loss_ce: 0.007849
2022-01-16 00:51:13,131 iteration 4160 : loss : 0.033443, loss_ce: 0.011773
2022-01-16 00:51:14,181 iteration 4161 : loss : 0.027680, loss_ce: 0.007752
2022-01-16 00:51:15,227 iteration 4162 : loss : 0.030551, loss_ce: 0.011133
2022-01-16 00:51:16,249 iteration 4163 : loss : 0.031103, loss_ce: 0.013793
2022-01-16 00:51:17,215 iteration 4164 : loss : 0.022681, loss_ce: 0.008632
2022-01-16 00:51:17,215 Training Data Eval:
2022-01-16 00:51:21,753   Average segmentation loss on training set: 0.0160
2022-01-16 00:51:21,753 Validation Data Eval:
2022-01-16 00:51:23,239   Average segmentation loss on validation set: 0.0693
2022-01-16 00:51:24,226 iteration 4165 : loss : 0.035775, loss_ce: 0.011647
 61%|█████████████████▊           | 245/400 [1:12:17<48:05, 18.62s/it]2022-01-16 00:51:25,234 iteration 4166 : loss : 0.024037, loss_ce: 0.009669
2022-01-16 00:51:26,108 iteration 4167 : loss : 0.029095, loss_ce: 0.008525
2022-01-16 00:51:27,011 iteration 4168 : loss : 0.017265, loss_ce: 0.007152
2022-01-16 00:51:27,915 iteration 4169 : loss : 0.019181, loss_ce: 0.009163
2022-01-16 00:51:28,988 iteration 4170 : loss : 0.025492, loss_ce: 0.011195
2022-01-16 00:51:29,867 iteration 4171 : loss : 0.017748, loss_ce: 0.005801
2022-01-16 00:51:30,813 iteration 4172 : loss : 0.019330, loss_ce: 0.008856
2022-01-16 00:51:31,805 iteration 4173 : loss : 0.021366, loss_ce: 0.006055
2022-01-16 00:51:32,734 iteration 4174 : loss : 0.025307, loss_ce: 0.006785
2022-01-16 00:51:33,628 iteration 4175 : loss : 0.019461, loss_ce: 0.008665
2022-01-16 00:51:34,559 iteration 4176 : loss : 0.021313, loss_ce: 0.008836
2022-01-16 00:51:35,558 iteration 4177 : loss : 0.019960, loss_ce: 0.005720
2022-01-16 00:51:36,460 iteration 4178 : loss : 0.032050, loss_ce: 0.012851
2022-01-16 00:51:37,390 iteration 4179 : loss : 0.021501, loss_ce: 0.009257
2022-01-16 00:51:38,310 iteration 4180 : loss : 0.017626, loss_ce: 0.005597
2022-01-16 00:51:39,246 iteration 4181 : loss : 0.018936, loss_ce: 0.007583
2022-01-16 00:51:40,193 iteration 4182 : loss : 0.023206, loss_ce: 0.005606
 62%|█████████████████▊           | 246/400 [1:12:33<45:44, 17.82s/it]2022-01-16 00:51:41,226 iteration 4183 : loss : 0.019348, loss_ce: 0.006495
2022-01-16 00:51:42,220 iteration 4184 : loss : 0.020197, loss_ce: 0.008342
2022-01-16 00:51:43,180 iteration 4185 : loss : 0.020695, loss_ce: 0.009480
2022-01-16 00:51:44,113 iteration 4186 : loss : 0.018265, loss_ce: 0.004736
2022-01-16 00:51:45,114 iteration 4187 : loss : 0.036811, loss_ce: 0.013040
2022-01-16 00:51:46,029 iteration 4188 : loss : 0.031541, loss_ce: 0.011820
2022-01-16 00:51:47,104 iteration 4189 : loss : 0.021624, loss_ce: 0.009357
2022-01-16 00:51:48,123 iteration 4190 : loss : 0.024958, loss_ce: 0.011134
2022-01-16 00:51:49,155 iteration 4191 : loss : 0.028528, loss_ce: 0.011682
2022-01-16 00:51:50,014 iteration 4192 : loss : 0.015131, loss_ce: 0.004842
2022-01-16 00:51:50,993 iteration 4193 : loss : 0.035208, loss_ce: 0.016686
2022-01-16 00:51:51,998 iteration 4194 : loss : 0.019001, loss_ce: 0.006618
2022-01-16 00:51:52,935 iteration 4195 : loss : 0.021186, loss_ce: 0.006418
2022-01-16 00:51:53,924 iteration 4196 : loss : 0.020098, loss_ce: 0.008194
2022-01-16 00:51:54,866 iteration 4197 : loss : 0.035860, loss_ce: 0.010842
2022-01-16 00:51:55,810 iteration 4198 : loss : 0.022046, loss_ce: 0.009175
2022-01-16 00:51:56,699 iteration 4199 : loss : 0.018457, loss_ce: 0.007089
 62%|█████████████████▉           | 247/400 [1:12:49<44:26, 17.43s/it]2022-01-16 00:51:57,709 iteration 4200 : loss : 0.026142, loss_ce: 0.013471
2022-01-16 00:51:58,698 iteration 4201 : loss : 0.023982, loss_ce: 0.010272
2022-01-16 00:51:59,681 iteration 4202 : loss : 0.020563, loss_ce: 0.009187
2022-01-16 00:52:00,745 iteration 4203 : loss : 0.028852, loss_ce: 0.013057
2022-01-16 00:52:01,686 iteration 4204 : loss : 0.021713, loss_ce: 0.008789
2022-01-16 00:52:02,632 iteration 4205 : loss : 0.021093, loss_ce: 0.009685
2022-01-16 00:52:03,719 iteration 4206 : loss : 0.030631, loss_ce: 0.011941
2022-01-16 00:52:04,728 iteration 4207 : loss : 0.024838, loss_ce: 0.009501
2022-01-16 00:52:05,595 iteration 4208 : loss : 0.015275, loss_ce: 0.005825
2022-01-16 00:52:06,517 iteration 4209 : loss : 0.032985, loss_ce: 0.015252
2022-01-16 00:52:07,442 iteration 4210 : loss : 0.023009, loss_ce: 0.009586
2022-01-16 00:52:08,419 iteration 4211 : loss : 0.019458, loss_ce: 0.008142
2022-01-16 00:52:09,434 iteration 4212 : loss : 0.024073, loss_ce: 0.008667
2022-01-16 00:52:10,354 iteration 4213 : loss : 0.021824, loss_ce: 0.006432
2022-01-16 00:52:11,353 iteration 4214 : loss : 0.023907, loss_ce: 0.007301
2022-01-16 00:52:12,299 iteration 4215 : loss : 0.019573, loss_ce: 0.007439
2022-01-16 00:52:13,238 iteration 4216 : loss : 0.020798, loss_ce: 0.007300
 62%|█████████████████▉           | 248/400 [1:13:06<43:28, 17.16s/it]2022-01-16 00:52:14,305 iteration 4217 : loss : 0.028020, loss_ce: 0.010575
2022-01-16 00:52:15,245 iteration 4218 : loss : 0.020724, loss_ce: 0.007207
2022-01-16 00:52:16,160 iteration 4219 : loss : 0.016466, loss_ce: 0.005970
2022-01-16 00:52:17,012 iteration 4220 : loss : 0.019446, loss_ce: 0.005050
2022-01-16 00:52:18,068 iteration 4221 : loss : 0.023991, loss_ce: 0.010819
2022-01-16 00:52:19,125 iteration 4222 : loss : 0.034376, loss_ce: 0.011413
2022-01-16 00:52:20,053 iteration 4223 : loss : 0.018348, loss_ce: 0.006111
2022-01-16 00:52:21,075 iteration 4224 : loss : 0.037530, loss_ce: 0.011403
2022-01-16 00:52:22,056 iteration 4225 : loss : 0.021121, loss_ce: 0.005810
2022-01-16 00:52:23,069 iteration 4226 : loss : 0.018994, loss_ce: 0.008143
2022-01-16 00:52:24,053 iteration 4227 : loss : 0.019083, loss_ce: 0.007007
2022-01-16 00:52:24,963 iteration 4228 : loss : 0.023682, loss_ce: 0.011625
2022-01-16 00:52:25,911 iteration 4229 : loss : 0.031342, loss_ce: 0.014445
2022-01-16 00:52:26,850 iteration 4230 : loss : 0.030259, loss_ce: 0.017162
2022-01-16 00:52:27,854 iteration 4231 : loss : 0.019895, loss_ce: 0.008383
2022-01-16 00:52:28,857 iteration 4232 : loss : 0.023046, loss_ce: 0.007295
2022-01-16 00:52:29,808 iteration 4233 : loss : 0.032843, loss_ce: 0.018230
 62%|██████████████████           | 249/400 [1:13:22<42:44, 16.98s/it]2022-01-16 00:52:30,731 iteration 4234 : loss : 0.035264, loss_ce: 0.006971
2022-01-16 00:52:31,619 iteration 4235 : loss : 0.015632, loss_ce: 0.005791
2022-01-16 00:52:32,606 iteration 4236 : loss : 0.022582, loss_ce: 0.009138
2022-01-16 00:52:33,512 iteration 4237 : loss : 0.021549, loss_ce: 0.009208
2022-01-16 00:52:34,460 iteration 4238 : loss : 0.024454, loss_ce: 0.012073
2022-01-16 00:52:35,562 iteration 4239 : loss : 0.033019, loss_ce: 0.014356
2022-01-16 00:52:36,535 iteration 4240 : loss : 0.028723, loss_ce: 0.010497
2022-01-16 00:52:37,398 iteration 4241 : loss : 0.017206, loss_ce: 0.008015
2022-01-16 00:52:38,355 iteration 4242 : loss : 0.029140, loss_ce: 0.009619
2022-01-16 00:52:39,285 iteration 4243 : loss : 0.026493, loss_ce: 0.011009
2022-01-16 00:52:40,158 iteration 4244 : loss : 0.016461, loss_ce: 0.007537
2022-01-16 00:52:41,165 iteration 4245 : loss : 0.021661, loss_ce: 0.009276
2022-01-16 00:52:42,211 iteration 4246 : loss : 0.027180, loss_ce: 0.008017
2022-01-16 00:52:43,208 iteration 4247 : loss : 0.021582, loss_ce: 0.009184
2022-01-16 00:52:44,105 iteration 4248 : loss : 0.031814, loss_ce: 0.014395
2022-01-16 00:52:45,128 iteration 4249 : loss : 0.050250, loss_ce: 0.017364
2022-01-16 00:52:45,129 Training Data Eval:
2022-01-16 00:52:49,667   Average segmentation loss on training set: 0.0137
2022-01-16 00:52:49,667 Validation Data Eval:
2022-01-16 00:52:51,153   Average segmentation loss on validation set: 0.0851
2022-01-16 00:52:52,092 iteration 4250 : loss : 0.027808, loss_ce: 0.011951
 62%|██████████████████▏          | 250/400 [1:13:45<46:25, 18.57s/it]2022-01-16 00:52:53,172 iteration 4251 : loss : 0.023892, loss_ce: 0.006481
2022-01-16 00:52:54,183 iteration 4252 : loss : 0.025678, loss_ce: 0.012477
2022-01-16 00:52:55,140 iteration 4253 : loss : 0.026362, loss_ce: 0.010088
2022-01-16 00:52:56,148 iteration 4254 : loss : 0.019021, loss_ce: 0.007780
2022-01-16 00:52:57,164 iteration 4255 : loss : 0.028270, loss_ce: 0.013211
2022-01-16 00:52:58,024 iteration 4256 : loss : 0.022036, loss_ce: 0.009559
2022-01-16 00:52:58,976 iteration 4257 : loss : 0.037071, loss_ce: 0.012664
2022-01-16 00:52:59,855 iteration 4258 : loss : 0.040934, loss_ce: 0.014456
2022-01-16 00:53:00,834 iteration 4259 : loss : 0.030691, loss_ce: 0.013638
2022-01-16 00:53:01,816 iteration 4260 : loss : 0.028081, loss_ce: 0.008893
2022-01-16 00:53:02,803 iteration 4261 : loss : 0.031437, loss_ce: 0.014868
2022-01-16 00:53:03,714 iteration 4262 : loss : 0.021980, loss_ce: 0.009484
2022-01-16 00:53:04,699 iteration 4263 : loss : 0.030110, loss_ce: 0.012466
2022-01-16 00:53:05,720 iteration 4264 : loss : 0.032547, loss_ce: 0.014209
2022-01-16 00:53:06,673 iteration 4265 : loss : 0.037096, loss_ce: 0.011580
2022-01-16 00:53:07,662 iteration 4266 : loss : 0.026077, loss_ce: 0.008088
2022-01-16 00:53:08,676 iteration 4267 : loss : 0.019800, loss_ce: 0.007212
 63%|██████████████████▏          | 251/400 [1:14:01<44:38, 17.98s/it]2022-01-16 00:53:09,707 iteration 4268 : loss : 0.021512, loss_ce: 0.005287
2022-01-16 00:53:10,650 iteration 4269 : loss : 0.031132, loss_ce: 0.009373
2022-01-16 00:53:11,567 iteration 4270 : loss : 0.026338, loss_ce: 0.014952
2022-01-16 00:53:12,438 iteration 4271 : loss : 0.022932, loss_ce: 0.008307
2022-01-16 00:53:13,380 iteration 4272 : loss : 0.026201, loss_ce: 0.013034
2022-01-16 00:53:14,261 iteration 4273 : loss : 0.019194, loss_ce: 0.007789
2022-01-16 00:53:15,311 iteration 4274 : loss : 0.024547, loss_ce: 0.012663
2022-01-16 00:53:16,240 iteration 4275 : loss : 0.016449, loss_ce: 0.005592
2022-01-16 00:53:17,249 iteration 4276 : loss : 0.022482, loss_ce: 0.006026
2022-01-16 00:53:18,262 iteration 4277 : loss : 0.025891, loss_ce: 0.007818
2022-01-16 00:53:19,272 iteration 4278 : loss : 0.028703, loss_ce: 0.009392
2022-01-16 00:53:20,215 iteration 4279 : loss : 0.025672, loss_ce: 0.013153
2022-01-16 00:53:21,190 iteration 4280 : loss : 0.026160, loss_ce: 0.008585
2022-01-16 00:53:22,155 iteration 4281 : loss : 0.036773, loss_ce: 0.014923
2022-01-16 00:53:23,037 iteration 4282 : loss : 0.020690, loss_ce: 0.007733
2022-01-16 00:53:23,978 iteration 4283 : loss : 0.030766, loss_ce: 0.009140
2022-01-16 00:53:24,894 iteration 4284 : loss : 0.020574, loss_ce: 0.008925
 63%|██████████████████▎          | 252/400 [1:14:17<43:02, 17.45s/it]2022-01-16 00:53:25,840 iteration 4285 : loss : 0.027720, loss_ce: 0.008633
2022-01-16 00:53:26,843 iteration 4286 : loss : 0.023037, loss_ce: 0.009071
2022-01-16 00:53:27,749 iteration 4287 : loss : 0.027533, loss_ce: 0.013658
2022-01-16 00:53:28,655 iteration 4288 : loss : 0.026276, loss_ce: 0.013404
2022-01-16 00:53:29,614 iteration 4289 : loss : 0.023168, loss_ce: 0.008842
2022-01-16 00:53:30,557 iteration 4290 : loss : 0.031654, loss_ce: 0.009676
2022-01-16 00:53:31,538 iteration 4291 : loss : 0.025880, loss_ce: 0.009771
2022-01-16 00:53:32,514 iteration 4292 : loss : 0.022058, loss_ce: 0.010517
2022-01-16 00:53:33,473 iteration 4293 : loss : 0.023888, loss_ce: 0.007383
2022-01-16 00:53:34,399 iteration 4294 : loss : 0.015593, loss_ce: 0.004135
2022-01-16 00:53:35,466 iteration 4295 : loss : 0.021499, loss_ce: 0.007332
2022-01-16 00:53:36,431 iteration 4296 : loss : 0.015804, loss_ce: 0.004392
2022-01-16 00:53:37,418 iteration 4297 : loss : 0.021737, loss_ce: 0.007818
2022-01-16 00:53:38,342 iteration 4298 : loss : 0.026310, loss_ce: 0.014332
2022-01-16 00:53:39,348 iteration 4299 : loss : 0.020485, loss_ce: 0.009566
2022-01-16 00:53:40,390 iteration 4300 : loss : 0.029929, loss_ce: 0.012469
2022-01-16 00:53:41,422 iteration 4301 : loss : 0.019825, loss_ce: 0.009256
 63%|██████████████████▎          | 253/400 [1:14:34<42:04, 17.18s/it]2022-01-16 00:53:42,493 iteration 4302 : loss : 0.026288, loss_ce: 0.011059
2022-01-16 00:53:43,523 iteration 4303 : loss : 0.031003, loss_ce: 0.006860
2022-01-16 00:53:44,442 iteration 4304 : loss : 0.018645, loss_ce: 0.007213
2022-01-16 00:53:45,370 iteration 4305 : loss : 0.025656, loss_ce: 0.009183
2022-01-16 00:53:46,305 iteration 4306 : loss : 0.018300, loss_ce: 0.005888
2022-01-16 00:53:47,197 iteration 4307 : loss : 0.017256, loss_ce: 0.007646
2022-01-16 00:53:48,184 iteration 4308 : loss : 0.020070, loss_ce: 0.007452
2022-01-16 00:53:49,211 iteration 4309 : loss : 0.028744, loss_ce: 0.010293
2022-01-16 00:53:50,174 iteration 4310 : loss : 0.016840, loss_ce: 0.007076
2022-01-16 00:53:51,092 iteration 4311 : loss : 0.022743, loss_ce: 0.009015
2022-01-16 00:53:51,993 iteration 4312 : loss : 0.018879, loss_ce: 0.008013
2022-01-16 00:53:52,909 iteration 4313 : loss : 0.018611, loss_ce: 0.008850
2022-01-16 00:53:53,825 iteration 4314 : loss : 0.022707, loss_ce: 0.007743
2022-01-16 00:53:54,817 iteration 4315 : loss : 0.019278, loss_ce: 0.006609
2022-01-16 00:53:55,731 iteration 4316 : loss : 0.023115, loss_ce: 0.007242
2022-01-16 00:53:56,742 iteration 4317 : loss : 0.024121, loss_ce: 0.008957
2022-01-16 00:53:57,639 iteration 4318 : loss : 0.018890, loss_ce: 0.007228
 64%|██████████████████▍          | 254/400 [1:14:50<41:04, 16.88s/it]2022-01-16 00:53:58,703 iteration 4319 : loss : 0.022372, loss_ce: 0.007920
2022-01-16 00:53:59,702 iteration 4320 : loss : 0.027868, loss_ce: 0.010802
2022-01-16 00:54:00,549 iteration 4321 : loss : 0.019130, loss_ce: 0.005664
2022-01-16 00:54:01,501 iteration 4322 : loss : 0.019258, loss_ce: 0.006234
2022-01-16 00:54:02,397 iteration 4323 : loss : 0.017522, loss_ce: 0.008303
2022-01-16 00:54:03,470 iteration 4324 : loss : 0.025896, loss_ce: 0.011166
2022-01-16 00:54:04,430 iteration 4325 : loss : 0.021626, loss_ce: 0.009283
2022-01-16 00:54:05,358 iteration 4326 : loss : 0.020421, loss_ce: 0.009691
2022-01-16 00:54:06,348 iteration 4327 : loss : 0.030228, loss_ce: 0.007444
2022-01-16 00:54:07,266 iteration 4328 : loss : 0.029106, loss_ce: 0.011281
2022-01-16 00:54:08,290 iteration 4329 : loss : 0.035141, loss_ce: 0.010671
2022-01-16 00:54:09,285 iteration 4330 : loss : 0.021833, loss_ce: 0.010194
2022-01-16 00:54:10,337 iteration 4331 : loss : 0.045679, loss_ce: 0.012071
2022-01-16 00:54:11,343 iteration 4332 : loss : 0.033450, loss_ce: 0.011322
2022-01-16 00:54:12,383 iteration 4333 : loss : 0.039470, loss_ce: 0.017768
2022-01-16 00:54:13,354 iteration 4334 : loss : 0.022500, loss_ce: 0.012515
2022-01-16 00:54:13,354 Training Data Eval:
2022-01-16 00:54:17,884   Average segmentation loss on training set: 0.0144
2022-01-16 00:54:17,884 Validation Data Eval:
2022-01-16 00:54:19,371   Average segmentation loss on validation set: 0.0705
2022-01-16 00:54:20,369 iteration 4335 : loss : 0.065732, loss_ce: 0.017609
 64%|██████████████████▍          | 255/400 [1:15:13<45:02, 18.64s/it]2022-01-16 00:54:21,265 iteration 4336 : loss : 0.016807, loss_ce: 0.008212
2022-01-16 00:54:22,304 iteration 4337 : loss : 0.029819, loss_ce: 0.013694
2022-01-16 00:54:23,258 iteration 4338 : loss : 0.019953, loss_ce: 0.008509
2022-01-16 00:54:24,160 iteration 4339 : loss : 0.017025, loss_ce: 0.006079
2022-01-16 00:54:25,154 iteration 4340 : loss : 0.019084, loss_ce: 0.008006
2022-01-16 00:54:26,047 iteration 4341 : loss : 0.018504, loss_ce: 0.005914
2022-01-16 00:54:27,049 iteration 4342 : loss : 0.030928, loss_ce: 0.008539
2022-01-16 00:54:28,048 iteration 4343 : loss : 0.023404, loss_ce: 0.006823
2022-01-16 00:54:29,039 iteration 4344 : loss : 0.023457, loss_ce: 0.010892
2022-01-16 00:54:30,097 iteration 4345 : loss : 0.028328, loss_ce: 0.011501
2022-01-16 00:54:30,981 iteration 4346 : loss : 0.033438, loss_ce: 0.009464
2022-01-16 00:54:31,936 iteration 4347 : loss : 0.018756, loss_ce: 0.008487
2022-01-16 00:54:32,835 iteration 4348 : loss : 0.018581, loss_ce: 0.008981
2022-01-16 00:54:33,688 iteration 4349 : loss : 0.020354, loss_ce: 0.005503
2022-01-16 00:54:34,540 iteration 4350 : loss : 0.019761, loss_ce: 0.008152
2022-01-16 00:54:35,511 iteration 4351 : loss : 0.025203, loss_ce: 0.007585
2022-01-16 00:54:36,463 iteration 4352 : loss : 0.026994, loss_ce: 0.010702
 64%|██████████████████▌          | 256/400 [1:15:29<42:54, 17.88s/it]2022-01-16 00:54:37,428 iteration 4353 : loss : 0.017985, loss_ce: 0.005744
2022-01-16 00:54:38,471 iteration 4354 : loss : 0.026188, loss_ce: 0.012577
2022-01-16 00:54:39,477 iteration 4355 : loss : 0.022773, loss_ce: 0.010027
2022-01-16 00:54:40,529 iteration 4356 : loss : 0.020728, loss_ce: 0.005449
2022-01-16 00:54:41,537 iteration 4357 : loss : 0.020510, loss_ce: 0.009752
2022-01-16 00:54:42,572 iteration 4358 : loss : 0.031373, loss_ce: 0.011314
2022-01-16 00:54:43,562 iteration 4359 : loss : 0.022108, loss_ce: 0.007802
2022-01-16 00:54:44,512 iteration 4360 : loss : 0.031390, loss_ce: 0.015900
2022-01-16 00:54:45,530 iteration 4361 : loss : 0.023808, loss_ce: 0.008324
2022-01-16 00:54:46,490 iteration 4362 : loss : 0.019973, loss_ce: 0.008408
2022-01-16 00:54:47,444 iteration 4363 : loss : 0.016782, loss_ce: 0.007079
2022-01-16 00:54:48,435 iteration 4364 : loss : 0.024790, loss_ce: 0.011786
2022-01-16 00:54:49,502 iteration 4365 : loss : 0.026816, loss_ce: 0.013315
2022-01-16 00:54:50,406 iteration 4366 : loss : 0.020917, loss_ce: 0.005780
2022-01-16 00:54:51,253 iteration 4367 : loss : 0.020109, loss_ce: 0.008732
2022-01-16 00:54:52,132 iteration 4368 : loss : 0.022641, loss_ce: 0.007403
2022-01-16 00:54:53,101 iteration 4369 : loss : 0.018955, loss_ce: 0.006882
 64%|██████████████████▋          | 257/400 [1:15:46<41:43, 17.50s/it]2022-01-16 00:54:54,135 iteration 4370 : loss : 0.018226, loss_ce: 0.006278
2022-01-16 00:54:55,118 iteration 4371 : loss : 0.023810, loss_ce: 0.011814
2022-01-16 00:54:56,112 iteration 4372 : loss : 0.020771, loss_ce: 0.008956
2022-01-16 00:54:57,100 iteration 4373 : loss : 0.027846, loss_ce: 0.017161
2022-01-16 00:54:58,106 iteration 4374 : loss : 0.019074, loss_ce: 0.006608
2022-01-16 00:54:59,107 iteration 4375 : loss : 0.021172, loss_ce: 0.009613
2022-01-16 00:55:00,039 iteration 4376 : loss : 0.024079, loss_ce: 0.009049
2022-01-16 00:55:00,975 iteration 4377 : loss : 0.022756, loss_ce: 0.006716
2022-01-16 00:55:01,860 iteration 4378 : loss : 0.018035, loss_ce: 0.006556
2022-01-16 00:55:02,753 iteration 4379 : loss : 0.020189, loss_ce: 0.007010
2022-01-16 00:55:03,620 iteration 4380 : loss : 0.021397, loss_ce: 0.007372
2022-01-16 00:55:04,608 iteration 4381 : loss : 0.031470, loss_ce: 0.009773
2022-01-16 00:55:05,561 iteration 4382 : loss : 0.044009, loss_ce: 0.008887
2022-01-16 00:55:06,487 iteration 4383 : loss : 0.020204, loss_ce: 0.005736
2022-01-16 00:55:07,513 iteration 4384 : loss : 0.020726, loss_ce: 0.008415
2022-01-16 00:55:08,530 iteration 4385 : loss : 0.035737, loss_ce: 0.013992
2022-01-16 00:55:09,444 iteration 4386 : loss : 0.020447, loss_ce: 0.009336
 64%|██████████████████▋          | 258/400 [1:16:02<40:36, 17.16s/it]2022-01-16 00:55:10,396 iteration 4387 : loss : 0.043721, loss_ce: 0.012599
2022-01-16 00:55:11,354 iteration 4388 : loss : 0.036169, loss_ce: 0.014013
2022-01-16 00:55:12,318 iteration 4389 : loss : 0.043756, loss_ce: 0.014800
2022-01-16 00:55:13,214 iteration 4390 : loss : 0.019487, loss_ce: 0.005942
2022-01-16 00:55:14,186 iteration 4391 : loss : 0.025581, loss_ce: 0.008799
2022-01-16 00:55:15,135 iteration 4392 : loss : 0.024849, loss_ce: 0.007184
2022-01-16 00:55:16,171 iteration 4393 : loss : 0.038555, loss_ce: 0.020712
2022-01-16 00:55:17,171 iteration 4394 : loss : 0.024409, loss_ce: 0.009158
2022-01-16 00:55:18,243 iteration 4395 : loss : 0.036297, loss_ce: 0.012147
2022-01-16 00:55:19,171 iteration 4396 : loss : 0.029306, loss_ce: 0.009171
2022-01-16 00:55:20,247 iteration 4397 : loss : 0.030911, loss_ce: 0.014341
2022-01-16 00:55:21,154 iteration 4398 : loss : 0.020366, loss_ce: 0.008427
2022-01-16 00:55:22,167 iteration 4399 : loss : 0.026336, loss_ce: 0.009043
2022-01-16 00:55:23,145 iteration 4400 : loss : 0.041811, loss_ce: 0.012636
2022-01-16 00:55:24,265 iteration 4401 : loss : 0.035688, loss_ce: 0.014114
2022-01-16 00:55:25,246 iteration 4402 : loss : 0.037834, loss_ce: 0.013122
2022-01-16 00:55:26,234 iteration 4403 : loss : 0.025374, loss_ce: 0.008890
 65%|██████████████████▊          | 259/400 [1:16:19<40:03, 17.05s/it]2022-01-16 00:55:27,226 iteration 4404 : loss : 0.022185, loss_ce: 0.009902
2022-01-16 00:55:28,233 iteration 4405 : loss : 0.018764, loss_ce: 0.008075
2022-01-16 00:55:29,226 iteration 4406 : loss : 0.025480, loss_ce: 0.011053
2022-01-16 00:55:30,260 iteration 4407 : loss : 0.027355, loss_ce: 0.009979
2022-01-16 00:55:31,203 iteration 4408 : loss : 0.022398, loss_ce: 0.009149
2022-01-16 00:55:32,202 iteration 4409 : loss : 0.044298, loss_ce: 0.016099
2022-01-16 00:55:33,335 iteration 4410 : loss : 0.048980, loss_ce: 0.017237
2022-01-16 00:55:34,357 iteration 4411 : loss : 0.026028, loss_ce: 0.010647
2022-01-16 00:55:35,326 iteration 4412 : loss : 0.023749, loss_ce: 0.008805
2022-01-16 00:55:36,318 iteration 4413 : loss : 0.019085, loss_ce: 0.005921
2022-01-16 00:55:37,217 iteration 4414 : loss : 0.029543, loss_ce: 0.008437
2022-01-16 00:55:38,222 iteration 4415 : loss : 0.020323, loss_ce: 0.006866
2022-01-16 00:55:39,254 iteration 4416 : loss : 0.028696, loss_ce: 0.009836
2022-01-16 00:55:40,216 iteration 4417 : loss : 0.019801, loss_ce: 0.005762
2022-01-16 00:55:41,203 iteration 4418 : loss : 0.020497, loss_ce: 0.009140
2022-01-16 00:55:42,233 iteration 4419 : loss : 0.020340, loss_ce: 0.006282
2022-01-16 00:55:42,234 Training Data Eval:
2022-01-16 00:55:46,762   Average segmentation loss on training set: 0.0229
2022-01-16 00:55:46,762 Validation Data Eval:
2022-01-16 00:55:48,251   Average segmentation loss on validation set: 0.2126
2022-01-16 00:55:49,143 iteration 4420 : loss : 0.016354, loss_ce: 0.006954
 65%|██████████████████▊          | 260/400 [1:16:42<43:52, 18.81s/it]2022-01-16 00:55:50,137 iteration 4421 : loss : 0.021165, loss_ce: 0.008377
2022-01-16 00:55:51,119 iteration 4422 : loss : 0.030783, loss_ce: 0.014728
2022-01-16 00:55:52,144 iteration 4423 : loss : 0.027829, loss_ce: 0.012077
2022-01-16 00:55:53,042 iteration 4424 : loss : 0.016286, loss_ce: 0.005368
2022-01-16 00:55:53,932 iteration 4425 : loss : 0.019188, loss_ce: 0.006336
2022-01-16 00:55:54,955 iteration 4426 : loss : 0.024886, loss_ce: 0.012199
2022-01-16 00:55:55,853 iteration 4427 : loss : 0.017359, loss_ce: 0.007633
2022-01-16 00:55:56,705 iteration 4428 : loss : 0.017001, loss_ce: 0.008074
2022-01-16 00:55:57,578 iteration 4429 : loss : 0.022122, loss_ce: 0.007237
2022-01-16 00:55:58,456 iteration 4430 : loss : 0.016554, loss_ce: 0.007113
2022-01-16 00:55:59,424 iteration 4431 : loss : 0.026645, loss_ce: 0.012303
2022-01-16 00:56:00,431 iteration 4432 : loss : 0.026969, loss_ce: 0.011347
2022-01-16 00:56:01,360 iteration 4433 : loss : 0.033860, loss_ce: 0.010544
2022-01-16 00:56:02,247 iteration 4434 : loss : 0.023519, loss_ce: 0.012903
2022-01-16 00:56:03,199 iteration 4435 : loss : 0.026552, loss_ce: 0.006288
2022-01-16 00:56:04,145 iteration 4436 : loss : 0.018392, loss_ce: 0.007380
2022-01-16 00:56:05,164 iteration 4437 : loss : 0.024509, loss_ce: 0.009272
 65%|██████████████████▉          | 261/400 [1:16:58<41:37, 17.97s/it]2022-01-16 00:56:06,251 iteration 4438 : loss : 0.033666, loss_ce: 0.007786
2022-01-16 00:56:07,244 iteration 4439 : loss : 0.018619, loss_ce: 0.006357
2022-01-16 00:56:08,220 iteration 4440 : loss : 0.018950, loss_ce: 0.006606
2022-01-16 00:56:09,307 iteration 4441 : loss : 0.033867, loss_ce: 0.011255
2022-01-16 00:56:10,337 iteration 4442 : loss : 0.024502, loss_ce: 0.011795
2022-01-16 00:56:11,329 iteration 4443 : loss : 0.049282, loss_ce: 0.018054
2022-01-16 00:56:12,214 iteration 4444 : loss : 0.023130, loss_ce: 0.007399
2022-01-16 00:56:13,152 iteration 4445 : loss : 0.030111, loss_ce: 0.012732
2022-01-16 00:56:14,142 iteration 4446 : loss : 0.022463, loss_ce: 0.009633
2022-01-16 00:56:15,075 iteration 4447 : loss : 0.017228, loss_ce: 0.005937
2022-01-16 00:56:16,064 iteration 4448 : loss : 0.027440, loss_ce: 0.010054
2022-01-16 00:56:17,033 iteration 4449 : loss : 0.023441, loss_ce: 0.010750
2022-01-16 00:56:18,063 iteration 4450 : loss : 0.029850, loss_ce: 0.009337
2022-01-16 00:56:18,989 iteration 4451 : loss : 0.023155, loss_ce: 0.009777
2022-01-16 00:56:19,966 iteration 4452 : loss : 0.016963, loss_ce: 0.007638
2022-01-16 00:56:20,895 iteration 4453 : loss : 0.019645, loss_ce: 0.007019
2022-01-16 00:56:21,824 iteration 4454 : loss : 0.018007, loss_ce: 0.007760
 66%|██████████████████▉          | 262/400 [1:17:14<40:25, 17.58s/it]2022-01-16 00:56:22,869 iteration 4455 : loss : 0.027943, loss_ce: 0.008171
2022-01-16 00:56:23,735 iteration 4456 : loss : 0.016681, loss_ce: 0.006322
2022-01-16 00:56:24,716 iteration 4457 : loss : 0.023281, loss_ce: 0.010833
2022-01-16 00:56:25,784 iteration 4458 : loss : 0.039931, loss_ce: 0.018734
2022-01-16 00:56:26,937 iteration 4459 : loss : 0.022689, loss_ce: 0.010525
2022-01-16 00:56:27,861 iteration 4460 : loss : 0.025570, loss_ce: 0.010438
2022-01-16 00:56:28,830 iteration 4461 : loss : 0.024630, loss_ce: 0.007636
2022-01-16 00:56:29,845 iteration 4462 : loss : 0.021770, loss_ce: 0.009431
2022-01-16 00:56:30,794 iteration 4463 : loss : 0.025966, loss_ce: 0.010012
2022-01-16 00:56:31,727 iteration 4464 : loss : 0.020464, loss_ce: 0.006611
2022-01-16 00:56:32,598 iteration 4465 : loss : 0.026193, loss_ce: 0.006152
2022-01-16 00:56:33,497 iteration 4466 : loss : 0.019103, loss_ce: 0.005557
2022-01-16 00:56:34,456 iteration 4467 : loss : 0.034579, loss_ce: 0.017140
2022-01-16 00:56:35,452 iteration 4468 : loss : 0.028357, loss_ce: 0.012376
2022-01-16 00:56:36,495 iteration 4469 : loss : 0.042759, loss_ce: 0.025083
2022-01-16 00:56:37,517 iteration 4470 : loss : 0.031079, loss_ce: 0.012031
2022-01-16 00:56:38,569 iteration 4471 : loss : 0.033884, loss_ce: 0.010019
 66%|███████████████████          | 263/400 [1:17:31<39:33, 17.32s/it]2022-01-16 00:56:39,553 iteration 4472 : loss : 0.016599, loss_ce: 0.007288
2022-01-16 00:56:40,465 iteration 4473 : loss : 0.021601, loss_ce: 0.008826
2022-01-16 00:56:41,435 iteration 4474 : loss : 0.024152, loss_ce: 0.012315
2022-01-16 00:56:42,387 iteration 4475 : loss : 0.024172, loss_ce: 0.006708
2022-01-16 00:56:43,305 iteration 4476 : loss : 0.020629, loss_ce: 0.006459
2022-01-16 00:56:44,241 iteration 4477 : loss : 0.018786, loss_ce: 0.009299
2022-01-16 00:56:45,329 iteration 4478 : loss : 0.023376, loss_ce: 0.010907
2022-01-16 00:56:46,293 iteration 4479 : loss : 0.067176, loss_ce: 0.021081
2022-01-16 00:56:47,273 iteration 4480 : loss : 0.025599, loss_ce: 0.009467
2022-01-16 00:56:48,186 iteration 4481 : loss : 0.021719, loss_ce: 0.008333
2022-01-16 00:56:49,083 iteration 4482 : loss : 0.017860, loss_ce: 0.005369
2022-01-16 00:56:50,003 iteration 4483 : loss : 0.025968, loss_ce: 0.007734
2022-01-16 00:56:50,968 iteration 4484 : loss : 0.013205, loss_ce: 0.004266
2022-01-16 00:56:51,848 iteration 4485 : loss : 0.020565, loss_ce: 0.008174
2022-01-16 00:56:52,869 iteration 4486 : loss : 0.019365, loss_ce: 0.006832
2022-01-16 00:56:53,860 iteration 4487 : loss : 0.022853, loss_ce: 0.010667
2022-01-16 00:56:54,764 iteration 4488 : loss : 0.021605, loss_ce: 0.008272
 66%|███████████████████▏         | 264/400 [1:17:47<38:30, 16.99s/it]2022-01-16 00:56:55,828 iteration 4489 : loss : 0.019879, loss_ce: 0.008135
2022-01-16 00:56:56,779 iteration 4490 : loss : 0.029271, loss_ce: 0.014806
2022-01-16 00:56:57,849 iteration 4491 : loss : 0.051947, loss_ce: 0.023878
2022-01-16 00:56:58,779 iteration 4492 : loss : 0.027334, loss_ce: 0.006748
2022-01-16 00:56:59,835 iteration 4493 : loss : 0.025958, loss_ce: 0.015888
2022-01-16 00:57:00,755 iteration 4494 : loss : 0.021786, loss_ce: 0.007636
2022-01-16 00:57:01,727 iteration 4495 : loss : 0.036976, loss_ce: 0.008593
2022-01-16 00:57:02,712 iteration 4496 : loss : 0.021146, loss_ce: 0.006004
2022-01-16 00:57:03,559 iteration 4497 : loss : 0.021823, loss_ce: 0.009897
2022-01-16 00:57:04,515 iteration 4498 : loss : 0.020036, loss_ce: 0.006012
2022-01-16 00:57:05,439 iteration 4499 : loss : 0.016612, loss_ce: 0.006580
2022-01-16 00:57:06,395 iteration 4500 : loss : 0.022040, loss_ce: 0.007611
2022-01-16 00:57:07,323 iteration 4501 : loss : 0.020570, loss_ce: 0.008971
2022-01-16 00:57:08,255 iteration 4502 : loss : 0.030341, loss_ce: 0.010864
2022-01-16 00:57:09,303 iteration 4503 : loss : 0.049060, loss_ce: 0.018067
2022-01-16 00:57:10,162 iteration 4504 : loss : 0.018357, loss_ce: 0.007487
2022-01-16 00:57:10,162 Training Data Eval:
2022-01-16 00:57:14,698   Average segmentation loss on training set: 0.0139
2022-01-16 00:57:14,698 Validation Data Eval:
2022-01-16 00:57:16,197   Average segmentation loss on validation set: 0.0754
2022-01-16 00:57:17,153 iteration 4505 : loss : 0.020703, loss_ce: 0.007463
 66%|███████████████████▏         | 265/400 [1:18:10<41:52, 18.61s/it]2022-01-16 00:57:18,214 iteration 4506 : loss : 0.018344, loss_ce: 0.006240
2022-01-16 00:57:19,253 iteration 4507 : loss : 0.026270, loss_ce: 0.010956
2022-01-16 00:57:20,223 iteration 4508 : loss : 0.019353, loss_ce: 0.006039
2022-01-16 00:57:21,110 iteration 4509 : loss : 0.019937, loss_ce: 0.007128
2022-01-16 00:57:22,070 iteration 4510 : loss : 0.017923, loss_ce: 0.006266
2022-01-16 00:57:23,135 iteration 4511 : loss : 0.029007, loss_ce: 0.010743
2022-01-16 00:57:23,993 iteration 4512 : loss : 0.019369, loss_ce: 0.007108
2022-01-16 00:57:24,921 iteration 4513 : loss : 0.017868, loss_ce: 0.006080
2022-01-16 00:57:25,840 iteration 4514 : loss : 0.024626, loss_ce: 0.010667
2022-01-16 00:57:26,782 iteration 4515 : loss : 0.015984, loss_ce: 0.005993
2022-01-16 00:57:27,748 iteration 4516 : loss : 0.019795, loss_ce: 0.008301
2022-01-16 00:57:28,744 iteration 4517 : loss : 0.031165, loss_ce: 0.012221
2022-01-16 00:57:29,674 iteration 4518 : loss : 0.020115, loss_ce: 0.008165
2022-01-16 00:57:30,552 iteration 4519 : loss : 0.028140, loss_ce: 0.009679
2022-01-16 00:57:31,511 iteration 4520 : loss : 0.029163, loss_ce: 0.007542
2022-01-16 00:57:32,483 iteration 4521 : loss : 0.023831, loss_ce: 0.009730
2022-01-16 00:57:33,501 iteration 4522 : loss : 0.029238, loss_ce: 0.012023
 66%|███████████████████▎         | 266/400 [1:18:26<40:02, 17.93s/it]2022-01-16 00:57:34,604 iteration 4523 : loss : 0.026599, loss_ce: 0.012255
2022-01-16 00:57:35,586 iteration 4524 : loss : 0.019547, loss_ce: 0.007206
2022-01-16 00:57:36,581 iteration 4525 : loss : 0.024901, loss_ce: 0.012148
2022-01-16 00:57:37,534 iteration 4526 : loss : 0.040743, loss_ce: 0.015852
2022-01-16 00:57:38,406 iteration 4527 : loss : 0.021259, loss_ce: 0.007412
2022-01-16 00:57:39,318 iteration 4528 : loss : 0.019456, loss_ce: 0.006467
2022-01-16 00:57:40,297 iteration 4529 : loss : 0.031083, loss_ce: 0.012776
2022-01-16 00:57:41,216 iteration 4530 : loss : 0.023951, loss_ce: 0.006450
2022-01-16 00:57:42,173 iteration 4531 : loss : 0.023179, loss_ce: 0.007883
2022-01-16 00:57:43,157 iteration 4532 : loss : 0.015128, loss_ce: 0.004869
2022-01-16 00:57:44,088 iteration 4533 : loss : 0.028889, loss_ce: 0.013643
2022-01-16 00:57:45,028 iteration 4534 : loss : 0.023985, loss_ce: 0.006656
2022-01-16 00:57:46,020 iteration 4535 : loss : 0.025093, loss_ce: 0.008568
2022-01-16 00:57:46,997 iteration 4536 : loss : 0.021816, loss_ce: 0.008798
2022-01-16 00:57:47,962 iteration 4537 : loss : 0.024241, loss_ce: 0.009835
2022-01-16 00:57:48,921 iteration 4538 : loss : 0.021400, loss_ce: 0.007275
2022-01-16 00:57:49,870 iteration 4539 : loss : 0.020956, loss_ce: 0.008290
 67%|███████████████████▎         | 267/400 [1:18:42<38:42, 17.46s/it]2022-01-16 00:57:50,858 iteration 4540 : loss : 0.017516, loss_ce: 0.006446
2022-01-16 00:57:51,849 iteration 4541 : loss : 0.021674, loss_ce: 0.009119
2022-01-16 00:57:52,751 iteration 4542 : loss : 0.039388, loss_ce: 0.014706
2022-01-16 00:57:53,680 iteration 4543 : loss : 0.025905, loss_ce: 0.009165
2022-01-16 00:57:54,587 iteration 4544 : loss : 0.023633, loss_ce: 0.008809
2022-01-16 00:57:55,620 iteration 4545 : loss : 0.025542, loss_ce: 0.011202
2022-01-16 00:57:56,704 iteration 4546 : loss : 0.067352, loss_ce: 0.040558
2022-01-16 00:57:57,767 iteration 4547 : loss : 0.027605, loss_ce: 0.010461
2022-01-16 00:57:58,661 iteration 4548 : loss : 0.018675, loss_ce: 0.006627
2022-01-16 00:57:59,560 iteration 4549 : loss : 0.028348, loss_ce: 0.008100
2022-01-16 00:58:00,527 iteration 4550 : loss : 0.027702, loss_ce: 0.010187
2022-01-16 00:58:01,519 iteration 4551 : loss : 0.029700, loss_ce: 0.011961
2022-01-16 00:58:02,577 iteration 4552 : loss : 0.061210, loss_ce: 0.022451
2022-01-16 00:58:03,563 iteration 4553 : loss : 0.026313, loss_ce: 0.010168
2022-01-16 00:58:04,472 iteration 4554 : loss : 0.023431, loss_ce: 0.009750
2022-01-16 00:58:05,419 iteration 4555 : loss : 0.021099, loss_ce: 0.009221
2022-01-16 00:58:06,360 iteration 4556 : loss : 0.028957, loss_ce: 0.008681
 67%|███████████████████▍         | 268/400 [1:18:59<37:46, 17.17s/it]2022-01-16 00:58:07,345 iteration 4557 : loss : 0.026024, loss_ce: 0.011928
2022-01-16 00:58:08,340 iteration 4558 : loss : 0.031758, loss_ce: 0.013335
2022-01-16 00:58:09,376 iteration 4559 : loss : 0.028494, loss_ce: 0.011106
2022-01-16 00:58:10,374 iteration 4560 : loss : 0.023583, loss_ce: 0.013911
2022-01-16 00:58:11,292 iteration 4561 : loss : 0.017332, loss_ce: 0.006159
2022-01-16 00:58:12,266 iteration 4562 : loss : 0.025858, loss_ce: 0.010934
2022-01-16 00:58:13,203 iteration 4563 : loss : 0.022685, loss_ce: 0.008139
2022-01-16 00:58:14,128 iteration 4564 : loss : 0.019439, loss_ce: 0.007900
2022-01-16 00:58:15,070 iteration 4565 : loss : 0.027396, loss_ce: 0.012910
2022-01-16 00:58:16,039 iteration 4566 : loss : 0.021963, loss_ce: 0.009024
2022-01-16 00:58:16,993 iteration 4567 : loss : 0.021172, loss_ce: 0.008302
2022-01-16 00:58:17,861 iteration 4568 : loss : 0.021494, loss_ce: 0.007315
2022-01-16 00:58:18,753 iteration 4569 : loss : 0.020264, loss_ce: 0.008805
2022-01-16 00:58:19,660 iteration 4570 : loss : 0.021161, loss_ce: 0.007344
2022-01-16 00:58:20,657 iteration 4571 : loss : 0.028369, loss_ce: 0.012509
2022-01-16 00:58:21,649 iteration 4572 : loss : 0.024961, loss_ce: 0.009398
2022-01-16 00:58:22,662 iteration 4573 : loss : 0.028199, loss_ce: 0.009086
 67%|███████████████████▌         | 269/400 [1:19:15<36:54, 16.91s/it]2022-01-16 00:58:23,617 iteration 4574 : loss : 0.018414, loss_ce: 0.005779
2022-01-16 00:58:24,596 iteration 4575 : loss : 0.023427, loss_ce: 0.006841
2022-01-16 00:58:25,469 iteration 4576 : loss : 0.021269, loss_ce: 0.008919
2022-01-16 00:58:26,366 iteration 4577 : loss : 0.019133, loss_ce: 0.008869
2022-01-16 00:58:27,314 iteration 4578 : loss : 0.018748, loss_ce: 0.007186
2022-01-16 00:58:28,217 iteration 4579 : loss : 0.022470, loss_ce: 0.011392
2022-01-16 00:58:29,145 iteration 4580 : loss : 0.022987, loss_ce: 0.009043
2022-01-16 00:58:30,093 iteration 4581 : loss : 0.022369, loss_ce: 0.010008
2022-01-16 00:58:31,055 iteration 4582 : loss : 0.025530, loss_ce: 0.009706
2022-01-16 00:58:31,995 iteration 4583 : loss : 0.021986, loss_ce: 0.007899
2022-01-16 00:58:32,924 iteration 4584 : loss : 0.015277, loss_ce: 0.005445
2022-01-16 00:58:33,900 iteration 4585 : loss : 0.026272, loss_ce: 0.008910
2022-01-16 00:58:34,791 iteration 4586 : loss : 0.020484, loss_ce: 0.008076
2022-01-16 00:58:35,702 iteration 4587 : loss : 0.024402, loss_ce: 0.007552
2022-01-16 00:58:36,621 iteration 4588 : loss : 0.021100, loss_ce: 0.007193
2022-01-16 00:58:37,586 iteration 4589 : loss : 0.022359, loss_ce: 0.006921
2022-01-16 00:58:37,586 Training Data Eval:
2022-01-16 00:58:42,125   Average segmentation loss on training set: 0.0146
2022-01-16 00:58:42,125 Validation Data Eval:
2022-01-16 00:58:43,617   Average segmentation loss on validation set: 0.1044
2022-01-16 00:58:44,547 iteration 4590 : loss : 0.023264, loss_ce: 0.011169
 68%|███████████████████▌         | 270/400 [1:19:37<39:52, 18.40s/it]2022-01-16 00:58:45,566 iteration 4591 : loss : 0.034013, loss_ce: 0.010191
2022-01-16 00:58:46,580 iteration 4592 : loss : 0.023481, loss_ce: 0.007223
2022-01-16 00:58:47,564 iteration 4593 : loss : 0.033494, loss_ce: 0.018659
2022-01-16 00:58:48,596 iteration 4594 : loss : 0.051021, loss_ce: 0.012546
2022-01-16 00:58:49,548 iteration 4595 : loss : 0.019040, loss_ce: 0.006763
2022-01-16 00:58:50,472 iteration 4596 : loss : 0.019643, loss_ce: 0.006611
2022-01-16 00:58:51,443 iteration 4597 : loss : 0.015989, loss_ce: 0.007149
2022-01-16 00:58:52,469 iteration 4598 : loss : 0.036330, loss_ce: 0.014830
2022-01-16 00:58:53,474 iteration 4599 : loss : 0.020352, loss_ce: 0.009749
2022-01-16 00:58:54,411 iteration 4600 : loss : 0.032395, loss_ce: 0.009649
2022-01-16 00:58:55,400 iteration 4601 : loss : 0.021433, loss_ce: 0.009768
2022-01-16 00:58:56,467 iteration 4602 : loss : 0.025493, loss_ce: 0.007759
2022-01-16 00:58:57,447 iteration 4603 : loss : 0.028999, loss_ce: 0.010528
2022-01-16 00:58:58,453 iteration 4604 : loss : 0.025723, loss_ce: 0.012784
2022-01-16 00:58:59,476 iteration 4605 : loss : 0.089255, loss_ce: 0.023163
2022-01-16 00:59:00,492 iteration 4606 : loss : 0.020669, loss_ce: 0.008378
2022-01-16 00:59:01,507 iteration 4607 : loss : 0.025182, loss_ce: 0.014790
 68%|███████████████████▋         | 271/400 [1:19:54<38:38, 17.97s/it]2022-01-16 00:59:02,480 iteration 4608 : loss : 0.017811, loss_ce: 0.006502
2022-01-16 00:59:03,454 iteration 4609 : loss : 0.033043, loss_ce: 0.014073
2022-01-16 00:59:04,358 iteration 4610 : loss : 0.021456, loss_ce: 0.006831
2022-01-16 00:59:05,256 iteration 4611 : loss : 0.023856, loss_ce: 0.008605
2022-01-16 00:59:06,132 iteration 4612 : loss : 0.018458, loss_ce: 0.005493
2022-01-16 00:59:07,094 iteration 4613 : loss : 0.019159, loss_ce: 0.006617
2022-01-16 00:59:08,054 iteration 4614 : loss : 0.019092, loss_ce: 0.009544
2022-01-16 00:59:09,061 iteration 4615 : loss : 0.023611, loss_ce: 0.009942
2022-01-16 00:59:10,149 iteration 4616 : loss : 0.020516, loss_ce: 0.008563
2022-01-16 00:59:11,136 iteration 4617 : loss : 0.022080, loss_ce: 0.010345
2022-01-16 00:59:12,041 iteration 4618 : loss : 0.018156, loss_ce: 0.005451
2022-01-16 00:59:12,955 iteration 4619 : loss : 0.013699, loss_ce: 0.005865
2022-01-16 00:59:13,977 iteration 4620 : loss : 0.021356, loss_ce: 0.006247
2022-01-16 00:59:14,926 iteration 4621 : loss : 0.021119, loss_ce: 0.010031
2022-01-16 00:59:15,885 iteration 4622 : loss : 0.035587, loss_ce: 0.013507
2022-01-16 00:59:16,835 iteration 4623 : loss : 0.020545, loss_ce: 0.007186
2022-01-16 00:59:17,809 iteration 4624 : loss : 0.019643, loss_ce: 0.008908
 68%|███████████████████▋         | 272/400 [1:20:10<37:15, 17.47s/it]2022-01-16 00:59:18,877 iteration 4625 : loss : 0.020363, loss_ce: 0.008113
2022-01-16 00:59:19,908 iteration 4626 : loss : 0.019424, loss_ce: 0.008160
2022-01-16 00:59:20,985 iteration 4627 : loss : 0.021677, loss_ce: 0.008480
2022-01-16 00:59:21,924 iteration 4628 : loss : 0.021358, loss_ce: 0.007973
2022-01-16 00:59:22,811 iteration 4629 : loss : 0.018239, loss_ce: 0.005741
2022-01-16 00:59:23,760 iteration 4630 : loss : 0.018834, loss_ce: 0.007313
2022-01-16 00:59:24,727 iteration 4631 : loss : 0.023029, loss_ce: 0.007905
2022-01-16 00:59:25,686 iteration 4632 : loss : 0.022105, loss_ce: 0.006909
2022-01-16 00:59:26,624 iteration 4633 : loss : 0.019246, loss_ce: 0.005980
2022-01-16 00:59:27,541 iteration 4634 : loss : 0.018538, loss_ce: 0.009028
2022-01-16 00:59:28,408 iteration 4635 : loss : 0.013232, loss_ce: 0.005579
2022-01-16 00:59:29,453 iteration 4636 : loss : 0.029948, loss_ce: 0.011444
2022-01-16 00:59:30,381 iteration 4637 : loss : 0.029078, loss_ce: 0.007227
2022-01-16 00:59:31,466 iteration 4638 : loss : 0.029733, loss_ce: 0.012824
2022-01-16 00:59:32,478 iteration 4639 : loss : 0.029911, loss_ce: 0.010706
2022-01-16 00:59:33,577 iteration 4640 : loss : 0.027496, loss_ce: 0.009418
2022-01-16 00:59:34,589 iteration 4641 : loss : 0.022488, loss_ce: 0.008285
 68%|███████████████████▊         | 273/400 [1:20:27<36:32, 17.26s/it]2022-01-16 00:59:35,604 iteration 4642 : loss : 0.033665, loss_ce: 0.010449
2022-01-16 00:59:36,561 iteration 4643 : loss : 0.020870, loss_ce: 0.007380
2022-01-16 00:59:37,584 iteration 4644 : loss : 0.026135, loss_ce: 0.008182
2022-01-16 00:59:38,621 iteration 4645 : loss : 0.025517, loss_ce: 0.011468
2022-01-16 00:59:39,614 iteration 4646 : loss : 0.034491, loss_ce: 0.007672
2022-01-16 00:59:40,494 iteration 4647 : loss : 0.017478, loss_ce: 0.005777
2022-01-16 00:59:41,427 iteration 4648 : loss : 0.020038, loss_ce: 0.007504
2022-01-16 00:59:42,398 iteration 4649 : loss : 0.020044, loss_ce: 0.008337
2022-01-16 00:59:43,426 iteration 4650 : loss : 0.051724, loss_ce: 0.012651
2022-01-16 00:59:44,329 iteration 4651 : loss : 0.017781, loss_ce: 0.007360
2022-01-16 00:59:45,380 iteration 4652 : loss : 0.027174, loss_ce: 0.011451
2022-01-16 00:59:46,321 iteration 4653 : loss : 0.023925, loss_ce: 0.009635
2022-01-16 00:59:47,265 iteration 4654 : loss : 0.018377, loss_ce: 0.005181
2022-01-16 00:59:48,299 iteration 4655 : loss : 0.026944, loss_ce: 0.010034
2022-01-16 00:59:49,358 iteration 4656 : loss : 0.021294, loss_ce: 0.008880
2022-01-16 00:59:50,372 iteration 4657 : loss : 0.027860, loss_ce: 0.012145
2022-01-16 00:59:51,383 iteration 4658 : loss : 0.027368, loss_ce: 0.009230
 68%|███████████████████▊         | 274/400 [1:20:44<35:57, 17.12s/it]2022-01-16 00:59:52,449 iteration 4659 : loss : 0.021403, loss_ce: 0.009259
2022-01-16 00:59:53,480 iteration 4660 : loss : 0.026363, loss_ce: 0.011940
2022-01-16 00:59:54,482 iteration 4661 : loss : 0.030629, loss_ce: 0.011510
2022-01-16 00:59:55,399 iteration 4662 : loss : 0.015364, loss_ce: 0.005935
2022-01-16 00:59:56,396 iteration 4663 : loss : 0.029402, loss_ce: 0.011114
2022-01-16 00:59:57,338 iteration 4664 : loss : 0.015334, loss_ce: 0.005864
2022-01-16 00:59:58,289 iteration 4665 : loss : 0.018991, loss_ce: 0.006397
2022-01-16 00:59:59,138 iteration 4666 : loss : 0.016131, loss_ce: 0.005458
2022-01-16 01:00:00,052 iteration 4667 : loss : 0.015771, loss_ce: 0.005865
2022-01-16 01:00:01,154 iteration 4668 : loss : 0.029175, loss_ce: 0.015106
2022-01-16 01:00:02,067 iteration 4669 : loss : 0.016526, loss_ce: 0.007301
2022-01-16 01:00:02,990 iteration 4670 : loss : 0.022460, loss_ce: 0.009122
2022-01-16 01:00:03,898 iteration 4671 : loss : 0.027266, loss_ce: 0.009089
2022-01-16 01:00:04,963 iteration 4672 : loss : 0.030915, loss_ce: 0.011408
2022-01-16 01:00:05,989 iteration 4673 : loss : 0.019461, loss_ce: 0.008661
2022-01-16 01:00:06,876 iteration 4674 : loss : 0.016801, loss_ce: 0.004829
2022-01-16 01:00:06,876 Training Data Eval:
2022-01-16 01:00:11,416   Average segmentation loss on training set: 0.0135
2022-01-16 01:00:11,417 Validation Data Eval:
2022-01-16 01:00:12,912   Average segmentation loss on validation set: 0.0660
2022-01-16 01:00:13,790 Found new lowest validation loss at iteration 4674! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_AND_1HEAD_best_val_loss_seed1234.pth
2022-01-16 01:00:14,814 iteration 4675 : loss : 0.019287, loss_ce: 0.008084
 69%|███████████████████▉         | 275/400 [1:21:07<39:37, 19.02s/it]2022-01-16 01:00:15,950 iteration 4676 : loss : 0.026222, loss_ce: 0.007928
2022-01-16 01:00:16,906 iteration 4677 : loss : 0.023422, loss_ce: 0.007647
2022-01-16 01:00:17,895 iteration 4678 : loss : 0.021814, loss_ce: 0.006573
2022-01-16 01:00:18,943 iteration 4679 : loss : 0.053498, loss_ce: 0.013642
2022-01-16 01:00:19,904 iteration 4680 : loss : 0.015953, loss_ce: 0.006186
2022-01-16 01:00:20,853 iteration 4681 : loss : 0.028486, loss_ce: 0.008632
2022-01-16 01:00:21,784 iteration 4682 : loss : 0.019115, loss_ce: 0.006879
2022-01-16 01:00:22,636 iteration 4683 : loss : 0.022507, loss_ce: 0.005386
2022-01-16 01:00:23,656 iteration 4684 : loss : 0.029188, loss_ce: 0.013328
2022-01-16 01:00:24,651 iteration 4685 : loss : 0.040386, loss_ce: 0.014692
2022-01-16 01:00:25,609 iteration 4686 : loss : 0.022246, loss_ce: 0.006604
2022-01-16 01:00:26,543 iteration 4687 : loss : 0.020244, loss_ce: 0.009046
2022-01-16 01:00:27,415 iteration 4688 : loss : 0.016232, loss_ce: 0.007299
2022-01-16 01:00:28,298 iteration 4689 : loss : 0.012334, loss_ce: 0.005277
2022-01-16 01:00:29,202 iteration 4690 : loss : 0.020829, loss_ce: 0.007650
2022-01-16 01:00:30,202 iteration 4691 : loss : 0.053635, loss_ce: 0.031579
2022-01-16 01:00:31,141 iteration 4692 : loss : 0.022692, loss_ce: 0.006675
 69%|████████████████████         | 276/400 [1:21:24<37:37, 18.21s/it]2022-01-16 01:00:32,241 iteration 4693 : loss : 0.026708, loss_ce: 0.009488
2022-01-16 01:00:33,233 iteration 4694 : loss : 0.030747, loss_ce: 0.010574
2022-01-16 01:00:34,037 iteration 4695 : loss : 0.016156, loss_ce: 0.005630
2022-01-16 01:00:35,073 iteration 4696 : loss : 0.026448, loss_ce: 0.010123
2022-01-16 01:00:36,000 iteration 4697 : loss : 0.021953, loss_ce: 0.007891
2022-01-16 01:00:36,965 iteration 4698 : loss : 0.026008, loss_ce: 0.012126
2022-01-16 01:00:37,994 iteration 4699 : loss : 0.020174, loss_ce: 0.008932
2022-01-16 01:00:38,903 iteration 4700 : loss : 0.020761, loss_ce: 0.009418
2022-01-16 01:00:39,969 iteration 4701 : loss : 0.023047, loss_ce: 0.009579
2022-01-16 01:00:40,906 iteration 4702 : loss : 0.022151, loss_ce: 0.010909
2022-01-16 01:00:41,819 iteration 4703 : loss : 0.029583, loss_ce: 0.008359
2022-01-16 01:00:42,771 iteration 4704 : loss : 0.019574, loss_ce: 0.006722
2022-01-16 01:00:43,584 iteration 4705 : loss : 0.014219, loss_ce: 0.006217
2022-01-16 01:00:44,537 iteration 4706 : loss : 0.025539, loss_ce: 0.006837
2022-01-16 01:00:45,552 iteration 4707 : loss : 0.019398, loss_ce: 0.008824
2022-01-16 01:00:46,582 iteration 4708 : loss : 0.028131, loss_ce: 0.011402
2022-01-16 01:00:47,584 iteration 4709 : loss : 0.030512, loss_ce: 0.011393
 69%|████████████████████         | 277/400 [1:21:40<36:14, 17.68s/it]2022-01-16 01:00:48,643 iteration 4710 : loss : 0.043505, loss_ce: 0.010331
2022-01-16 01:00:49,769 iteration 4711 : loss : 0.023668, loss_ce: 0.010026
2022-01-16 01:00:50,715 iteration 4712 : loss : 0.022131, loss_ce: 0.009397
2022-01-16 01:00:51,668 iteration 4713 : loss : 0.023037, loss_ce: 0.009790
2022-01-16 01:00:52,648 iteration 4714 : loss : 0.020663, loss_ce: 0.007124
2022-01-16 01:00:53,684 iteration 4715 : loss : 0.026891, loss_ce: 0.013173
2022-01-16 01:00:54,673 iteration 4716 : loss : 0.020872, loss_ce: 0.008218
2022-01-16 01:00:55,630 iteration 4717 : loss : 0.022748, loss_ce: 0.008953
2022-01-16 01:00:56,522 iteration 4718 : loss : 0.016635, loss_ce: 0.005730
2022-01-16 01:00:57,413 iteration 4719 : loss : 0.019055, loss_ce: 0.008946
2022-01-16 01:00:58,324 iteration 4720 : loss : 0.017952, loss_ce: 0.007025
2022-01-16 01:00:59,264 iteration 4721 : loss : 0.017201, loss_ce: 0.006700
2022-01-16 01:01:00,282 iteration 4722 : loss : 0.032504, loss_ce: 0.012412
2022-01-16 01:01:01,239 iteration 4723 : loss : 0.014648, loss_ce: 0.005556
2022-01-16 01:01:02,123 iteration 4724 : loss : 0.017515, loss_ce: 0.006925
2022-01-16 01:01:03,002 iteration 4725 : loss : 0.019549, loss_ce: 0.007687
2022-01-16 01:01:03,956 iteration 4726 : loss : 0.020056, loss_ce: 0.008064
 70%|████████████████████▏        | 278/400 [1:21:57<35:09, 17.29s/it]2022-01-16 01:01:05,048 iteration 4727 : loss : 0.019506, loss_ce: 0.006670
2022-01-16 01:01:05,947 iteration 4728 : loss : 0.015880, loss_ce: 0.006243
2022-01-16 01:01:06,858 iteration 4729 : loss : 0.018432, loss_ce: 0.007013
2022-01-16 01:01:07,768 iteration 4730 : loss : 0.016262, loss_ce: 0.006265
2022-01-16 01:01:08,785 iteration 4731 : loss : 0.024982, loss_ce: 0.010923
2022-01-16 01:01:09,760 iteration 4732 : loss : 0.028252, loss_ce: 0.010067
2022-01-16 01:01:10,725 iteration 4733 : loss : 0.015064, loss_ce: 0.006349
2022-01-16 01:01:11,660 iteration 4734 : loss : 0.018688, loss_ce: 0.006984
2022-01-16 01:01:12,716 iteration 4735 : loss : 0.032973, loss_ce: 0.012569
2022-01-16 01:01:13,602 iteration 4736 : loss : 0.029290, loss_ce: 0.011707
2022-01-16 01:01:14,644 iteration 4737 : loss : 0.021440, loss_ce: 0.009322
2022-01-16 01:01:15,599 iteration 4738 : loss : 0.018704, loss_ce: 0.007387
2022-01-16 01:01:16,553 iteration 4739 : loss : 0.021226, loss_ce: 0.008167
2022-01-16 01:01:17,567 iteration 4740 : loss : 0.025198, loss_ce: 0.011788
2022-01-16 01:01:18,502 iteration 4741 : loss : 0.018378, loss_ce: 0.005989
2022-01-16 01:01:19,447 iteration 4742 : loss : 0.037242, loss_ce: 0.020732
2022-01-16 01:01:20,492 iteration 4743 : loss : 0.028831, loss_ce: 0.009845
 70%|████████████████████▏        | 279/400 [1:22:13<34:24, 17.06s/it]2022-01-16 01:01:21,579 iteration 4744 : loss : 0.029387, loss_ce: 0.009803
2022-01-16 01:01:22,549 iteration 4745 : loss : 0.029049, loss_ce: 0.008689
2022-01-16 01:01:23,468 iteration 4746 : loss : 0.017324, loss_ce: 0.008888
2022-01-16 01:01:24,401 iteration 4747 : loss : 0.021954, loss_ce: 0.007454
2022-01-16 01:01:25,373 iteration 4748 : loss : 0.022080, loss_ce: 0.008354
2022-01-16 01:01:26,350 iteration 4749 : loss : 0.023745, loss_ce: 0.008348
2022-01-16 01:01:27,367 iteration 4750 : loss : 0.027274, loss_ce: 0.011131
2022-01-16 01:01:28,303 iteration 4751 : loss : 0.023841, loss_ce: 0.009292
2022-01-16 01:01:29,293 iteration 4752 : loss : 0.020515, loss_ce: 0.007087
2022-01-16 01:01:30,308 iteration 4753 : loss : 0.025234, loss_ce: 0.007855
2022-01-16 01:01:31,291 iteration 4754 : loss : 0.016155, loss_ce: 0.005409
2022-01-16 01:01:32,374 iteration 4755 : loss : 0.026559, loss_ce: 0.009370
2022-01-16 01:01:33,305 iteration 4756 : loss : 0.018777, loss_ce: 0.009260
2022-01-16 01:01:34,252 iteration 4757 : loss : 0.027689, loss_ce: 0.010707
2022-01-16 01:01:35,173 iteration 4758 : loss : 0.019854, loss_ce: 0.005984
2022-01-16 01:01:36,132 iteration 4759 : loss : 0.015151, loss_ce: 0.005431
2022-01-16 01:01:36,132 Training Data Eval:
2022-01-16 01:01:40,669   Average segmentation loss on training set: 0.0137
2022-01-16 01:01:40,669 Validation Data Eval:
2022-01-16 01:01:42,151   Average segmentation loss on validation set: 0.0740
2022-01-16 01:01:43,071 iteration 4760 : loss : 0.018647, loss_ce: 0.007787
 70%|████████████████████▎        | 280/400 [1:22:36<37:26, 18.72s/it]2022-01-16 01:01:44,072 iteration 4761 : loss : 0.018305, loss_ce: 0.005839
2022-01-16 01:01:45,064 iteration 4762 : loss : 0.020212, loss_ce: 0.007202
2022-01-16 01:01:45,962 iteration 4763 : loss : 0.017067, loss_ce: 0.006531
2022-01-16 01:01:46,963 iteration 4764 : loss : 0.026247, loss_ce: 0.009104
2022-01-16 01:01:47,900 iteration 4765 : loss : 0.020425, loss_ce: 0.008547
2022-01-16 01:01:48,935 iteration 4766 : loss : 0.020152, loss_ce: 0.007406
2022-01-16 01:01:49,926 iteration 4767 : loss : 0.019931, loss_ce: 0.007826
2022-01-16 01:01:50,840 iteration 4768 : loss : 0.018407, loss_ce: 0.006147
2022-01-16 01:01:51,841 iteration 4769 : loss : 0.021972, loss_ce: 0.008664
2022-01-16 01:01:52,851 iteration 4770 : loss : 0.020141, loss_ce: 0.006745
2022-01-16 01:01:53,741 iteration 4771 : loss : 0.016830, loss_ce: 0.005286
2022-01-16 01:01:54,754 iteration 4772 : loss : 0.025153, loss_ce: 0.010895
2022-01-16 01:01:55,750 iteration 4773 : loss : 0.021249, loss_ce: 0.007884
2022-01-16 01:01:56,738 iteration 4774 : loss : 0.016382, loss_ce: 0.006469
2022-01-16 01:01:57,657 iteration 4775 : loss : 0.026306, loss_ce: 0.008227
2022-01-16 01:01:58,611 iteration 4776 : loss : 0.020547, loss_ce: 0.011250
2022-01-16 01:01:59,726 iteration 4777 : loss : 0.023201, loss_ce: 0.011790
 70%|████████████████████▎        | 281/400 [1:22:52<35:53, 18.10s/it]2022-01-16 01:02:00,668 iteration 4778 : loss : 0.013738, loss_ce: 0.003709
2022-01-16 01:02:01,608 iteration 4779 : loss : 0.040602, loss_ce: 0.014304
2022-01-16 01:02:02,484 iteration 4780 : loss : 0.013728, loss_ce: 0.004819
2022-01-16 01:02:03,409 iteration 4781 : loss : 0.020868, loss_ce: 0.006279
2022-01-16 01:02:04,424 iteration 4782 : loss : 0.024642, loss_ce: 0.011037
2022-01-16 01:02:05,385 iteration 4783 : loss : 0.019786, loss_ce: 0.008472
2022-01-16 01:02:06,273 iteration 4784 : loss : 0.017167, loss_ce: 0.007891
2022-01-16 01:02:07,312 iteration 4785 : loss : 0.022451, loss_ce: 0.008082
2022-01-16 01:02:08,301 iteration 4786 : loss : 0.017679, loss_ce: 0.005559
2022-01-16 01:02:09,295 iteration 4787 : loss : 0.019511, loss_ce: 0.006045
2022-01-16 01:02:10,295 iteration 4788 : loss : 0.022042, loss_ce: 0.007818
2022-01-16 01:02:11,187 iteration 4789 : loss : 0.021456, loss_ce: 0.009990
2022-01-16 01:02:12,253 iteration 4790 : loss : 0.026690, loss_ce: 0.009148
2022-01-16 01:02:13,191 iteration 4791 : loss : 0.023314, loss_ce: 0.011100
2022-01-16 01:02:14,208 iteration 4792 : loss : 0.054724, loss_ce: 0.018242
2022-01-16 01:02:15,122 iteration 4793 : loss : 0.023947, loss_ce: 0.011236
2022-01-16 01:02:15,986 iteration 4794 : loss : 0.033149, loss_ce: 0.008757
 70%|████████████████████▍        | 282/400 [1:23:09<34:30, 17.54s/it]2022-01-16 01:02:17,033 iteration 4795 : loss : 0.020528, loss_ce: 0.007062
2022-01-16 01:02:18,015 iteration 4796 : loss : 0.020250, loss_ce: 0.006206
2022-01-16 01:02:19,006 iteration 4797 : loss : 0.038651, loss_ce: 0.016949
2022-01-16 01:02:20,051 iteration 4798 : loss : 0.027468, loss_ce: 0.009304
2022-01-16 01:02:21,017 iteration 4799 : loss : 0.017964, loss_ce: 0.005265
2022-01-16 01:02:21,986 iteration 4800 : loss : 0.022509, loss_ce: 0.006312
2022-01-16 01:02:23,044 iteration 4801 : loss : 0.021742, loss_ce: 0.008736
2022-01-16 01:02:23,927 iteration 4802 : loss : 0.016880, loss_ce: 0.007268
2022-01-16 01:02:24,860 iteration 4803 : loss : 0.021184, loss_ce: 0.009450
2022-01-16 01:02:25,902 iteration 4804 : loss : 0.038399, loss_ce: 0.008754
2022-01-16 01:02:26,928 iteration 4805 : loss : 0.026779, loss_ce: 0.009463
2022-01-16 01:02:27,964 iteration 4806 : loss : 0.029839, loss_ce: 0.012737
2022-01-16 01:02:28,854 iteration 4807 : loss : 0.024549, loss_ce: 0.010637
2022-01-16 01:02:29,735 iteration 4808 : loss : 0.016834, loss_ce: 0.007404
2022-01-16 01:02:30,710 iteration 4809 : loss : 0.025224, loss_ce: 0.012397
2022-01-16 01:02:31,664 iteration 4810 : loss : 0.024774, loss_ce: 0.006460
2022-01-16 01:02:32,641 iteration 4811 : loss : 0.018236, loss_ce: 0.006707
 71%|████████████████████▌        | 283/400 [1:23:25<33:41, 17.28s/it]2022-01-16 01:02:33,597 iteration 4812 : loss : 0.023397, loss_ce: 0.009111
2022-01-16 01:02:34,574 iteration 4813 : loss : 0.024924, loss_ce: 0.006388
2022-01-16 01:02:35,587 iteration 4814 : loss : 0.031185, loss_ce: 0.008095
2022-01-16 01:02:36,477 iteration 4815 : loss : 0.019835, loss_ce: 0.008387
2022-01-16 01:02:37,561 iteration 4816 : loss : 0.020623, loss_ce: 0.008271
2022-01-16 01:02:38,507 iteration 4817 : loss : 0.022419, loss_ce: 0.008618
2022-01-16 01:02:39,446 iteration 4818 : loss : 0.019055, loss_ce: 0.007051
2022-01-16 01:02:40,305 iteration 4819 : loss : 0.020004, loss_ce: 0.007950
2022-01-16 01:02:41,225 iteration 4820 : loss : 0.019909, loss_ce: 0.007097
2022-01-16 01:02:42,286 iteration 4821 : loss : 0.035588, loss_ce: 0.014595
2022-01-16 01:02:43,331 iteration 4822 : loss : 0.021947, loss_ce: 0.007516
2022-01-16 01:02:44,287 iteration 4823 : loss : 0.024201, loss_ce: 0.010701
2022-01-16 01:02:45,279 iteration 4824 : loss : 0.020080, loss_ce: 0.007413
2022-01-16 01:02:46,214 iteration 4825 : loss : 0.022868, loss_ce: 0.008606
2022-01-16 01:02:47,143 iteration 4826 : loss : 0.017298, loss_ce: 0.005181
2022-01-16 01:02:48,077 iteration 4827 : loss : 0.015626, loss_ce: 0.006207
2022-01-16 01:02:48,995 iteration 4828 : loss : 0.018880, loss_ce: 0.007903
 71%|████████████████████▌        | 284/400 [1:23:42<32:52, 17.00s/it]2022-01-16 01:02:49,958 iteration 4829 : loss : 0.019686, loss_ce: 0.006404
2022-01-16 01:02:50,954 iteration 4830 : loss : 0.019179, loss_ce: 0.009143
2022-01-16 01:02:51,929 iteration 4831 : loss : 0.018014, loss_ce: 0.007341
2022-01-16 01:02:52,882 iteration 4832 : loss : 0.023843, loss_ce: 0.007545
2022-01-16 01:02:53,889 iteration 4833 : loss : 0.025227, loss_ce: 0.009180
2022-01-16 01:02:54,779 iteration 4834 : loss : 0.016016, loss_ce: 0.005536
2022-01-16 01:02:55,863 iteration 4835 : loss : 0.027292, loss_ce: 0.014547
2022-01-16 01:02:56,832 iteration 4836 : loss : 0.032428, loss_ce: 0.008960
2022-01-16 01:02:57,846 iteration 4837 : loss : 0.019938, loss_ce: 0.005709
2022-01-16 01:02:58,778 iteration 4838 : loss : 0.014919, loss_ce: 0.004688
2022-01-16 01:02:59,774 iteration 4839 : loss : 0.021728, loss_ce: 0.008097
2022-01-16 01:03:00,740 iteration 4840 : loss : 0.025568, loss_ce: 0.012752
2022-01-16 01:03:01,625 iteration 4841 : loss : 0.013522, loss_ce: 0.004366
2022-01-16 01:03:02,592 iteration 4842 : loss : 0.016723, loss_ce: 0.005720
2022-01-16 01:03:03,656 iteration 4843 : loss : 0.024292, loss_ce: 0.007560
2022-01-16 01:03:04,615 iteration 4844 : loss : 0.024331, loss_ce: 0.008153
2022-01-16 01:03:04,615 Training Data Eval:
2022-01-16 01:03:09,149   Average segmentation loss on training set: 0.0120
2022-01-16 01:03:09,149 Validation Data Eval:
2022-01-16 01:03:10,642   Average segmentation loss on validation set: 0.0732
2022-01-16 01:03:11,646 iteration 4845 : loss : 0.021287, loss_ce: 0.009488
 71%|████████████████████▋        | 285/400 [1:24:04<35:50, 18.70s/it]2022-01-16 01:03:12,628 iteration 4846 : loss : 0.020036, loss_ce: 0.007753
2022-01-16 01:03:13,547 iteration 4847 : loss : 0.017605, loss_ce: 0.006039
2022-01-16 01:03:14,557 iteration 4848 : loss : 0.022019, loss_ce: 0.009972
2022-01-16 01:03:15,548 iteration 4849 : loss : 0.018490, loss_ce: 0.005048
2022-01-16 01:03:16,472 iteration 4850 : loss : 0.024228, loss_ce: 0.007130
2022-01-16 01:03:17,558 iteration 4851 : loss : 0.015314, loss_ce: 0.005969
2022-01-16 01:03:18,503 iteration 4852 : loss : 0.016942, loss_ce: 0.005585
2022-01-16 01:03:19,478 iteration 4853 : loss : 0.017886, loss_ce: 0.007426
2022-01-16 01:03:20,453 iteration 4854 : loss : 0.016616, loss_ce: 0.006536
2022-01-16 01:03:21,381 iteration 4855 : loss : 0.027943, loss_ce: 0.007397
2022-01-16 01:03:22,450 iteration 4856 : loss : 0.038736, loss_ce: 0.020852
2022-01-16 01:03:23,379 iteration 4857 : loss : 0.016626, loss_ce: 0.006045
2022-01-16 01:03:24,430 iteration 4858 : loss : 0.018933, loss_ce: 0.006691
2022-01-16 01:03:25,327 iteration 4859 : loss : 0.012475, loss_ce: 0.005155
2022-01-16 01:03:26,335 iteration 4860 : loss : 0.028421, loss_ce: 0.013071
2022-01-16 01:03:27,265 iteration 4861 : loss : 0.022137, loss_ce: 0.007429
2022-01-16 01:03:28,275 iteration 4862 : loss : 0.022302, loss_ce: 0.011255
 72%|████████████████████▋        | 286/400 [1:24:21<34:20, 18.07s/it]2022-01-16 01:03:29,386 iteration 4863 : loss : 0.025579, loss_ce: 0.006615
2022-01-16 01:03:30,346 iteration 4864 : loss : 0.021724, loss_ce: 0.009669
2022-01-16 01:03:31,281 iteration 4865 : loss : 0.017505, loss_ce: 0.008548
2022-01-16 01:03:32,319 iteration 4866 : loss : 0.020066, loss_ce: 0.006963
2022-01-16 01:03:33,295 iteration 4867 : loss : 0.016165, loss_ce: 0.005739
2022-01-16 01:03:34,151 iteration 4868 : loss : 0.022722, loss_ce: 0.009415
2022-01-16 01:03:35,221 iteration 4869 : loss : 0.024029, loss_ce: 0.010498
2022-01-16 01:03:36,175 iteration 4870 : loss : 0.013329, loss_ce: 0.004713
2022-01-16 01:03:37,250 iteration 4871 : loss : 0.025583, loss_ce: 0.009320
2022-01-16 01:03:38,136 iteration 4872 : loss : 0.015389, loss_ce: 0.004652
2022-01-16 01:03:39,205 iteration 4873 : loss : 0.017215, loss_ce: 0.006327
2022-01-16 01:03:40,199 iteration 4874 : loss : 0.025391, loss_ce: 0.007815
2022-01-16 01:03:41,151 iteration 4875 : loss : 0.028925, loss_ce: 0.014934
2022-01-16 01:03:42,018 iteration 4876 : loss : 0.020943, loss_ce: 0.006501
2022-01-16 01:03:43,035 iteration 4877 : loss : 0.033934, loss_ce: 0.017208
2022-01-16 01:03:44,084 iteration 4878 : loss : 0.028976, loss_ce: 0.008683
2022-01-16 01:03:45,049 iteration 4879 : loss : 0.020527, loss_ce: 0.007031
 72%|████████████████████▊        | 287/400 [1:24:38<33:18, 17.69s/it]2022-01-16 01:03:46,049 iteration 4880 : loss : 0.020050, loss_ce: 0.008106
2022-01-16 01:03:46,950 iteration 4881 : loss : 0.016736, loss_ce: 0.007254
2022-01-16 01:03:47,809 iteration 4882 : loss : 0.019138, loss_ce: 0.008404
2022-01-16 01:03:48,789 iteration 4883 : loss : 0.023261, loss_ce: 0.010443
2022-01-16 01:03:49,792 iteration 4884 : loss : 0.023205, loss_ce: 0.006962
2022-01-16 01:03:50,632 iteration 4885 : loss : 0.014963, loss_ce: 0.005771
2022-01-16 01:03:51,580 iteration 4886 : loss : 0.024462, loss_ce: 0.006273
2022-01-16 01:03:52,468 iteration 4887 : loss : 0.013924, loss_ce: 0.004261
2022-01-16 01:03:53,451 iteration 4888 : loss : 0.057928, loss_ce: 0.019884
2022-01-16 01:03:54,413 iteration 4889 : loss : 0.022090, loss_ce: 0.010925
2022-01-16 01:03:55,320 iteration 4890 : loss : 0.016454, loss_ce: 0.008470
2022-01-16 01:03:56,150 iteration 4891 : loss : 0.014010, loss_ce: 0.005248
2022-01-16 01:03:57,149 iteration 4892 : loss : 0.016978, loss_ce: 0.007098
2022-01-16 01:03:58,104 iteration 4893 : loss : 0.023640, loss_ce: 0.010016
2022-01-16 01:03:59,043 iteration 4894 : loss : 0.020397, loss_ce: 0.010304
2022-01-16 01:03:59,973 iteration 4895 : loss : 0.081386, loss_ce: 0.027877
2022-01-16 01:04:00,878 iteration 4896 : loss : 0.024238, loss_ce: 0.007734
 72%|████████████████████▉        | 288/400 [1:24:53<31:58, 17.13s/it]2022-01-16 01:04:01,862 iteration 4897 : loss : 0.019272, loss_ce: 0.007617
2022-01-16 01:04:02,884 iteration 4898 : loss : 0.023007, loss_ce: 0.010577
2022-01-16 01:04:03,845 iteration 4899 : loss : 0.015987, loss_ce: 0.004525
2022-01-16 01:04:04,752 iteration 4900 : loss : 0.021209, loss_ce: 0.008952
2022-01-16 01:04:05,679 iteration 4901 : loss : 0.028169, loss_ce: 0.008394
2022-01-16 01:04:06,602 iteration 4902 : loss : 0.020575, loss_ce: 0.008564
2022-01-16 01:04:07,580 iteration 4903 : loss : 0.030007, loss_ce: 0.017961
2022-01-16 01:04:08,419 iteration 4904 : loss : 0.025002, loss_ce: 0.009766
2022-01-16 01:04:09,322 iteration 4905 : loss : 0.032438, loss_ce: 0.009787
2022-01-16 01:04:10,299 iteration 4906 : loss : 0.030164, loss_ce: 0.012403
2022-01-16 01:04:11,199 iteration 4907 : loss : 0.023431, loss_ce: 0.008789
2022-01-16 01:04:12,230 iteration 4908 : loss : 0.035639, loss_ce: 0.018070
2022-01-16 01:04:13,219 iteration 4909 : loss : 0.045559, loss_ce: 0.027946
2022-01-16 01:04:14,123 iteration 4910 : loss : 0.024134, loss_ce: 0.012067
2022-01-16 01:04:15,047 iteration 4911 : loss : 0.018995, loss_ce: 0.007934
2022-01-16 01:04:16,003 iteration 4912 : loss : 0.023146, loss_ce: 0.011117
2022-01-16 01:04:16,950 iteration 4913 : loss : 0.030194, loss_ce: 0.012277
 72%|████████████████████▉        | 289/400 [1:25:10<31:05, 16.81s/it]2022-01-16 01:04:18,009 iteration 4914 : loss : 0.040575, loss_ce: 0.018969
2022-01-16 01:04:18,923 iteration 4915 : loss : 0.025317, loss_ce: 0.010072
2022-01-16 01:04:19,848 iteration 4916 : loss : 0.021106, loss_ce: 0.006785
2022-01-16 01:04:20,798 iteration 4917 : loss : 0.020990, loss_ce: 0.006351
2022-01-16 01:04:21,780 iteration 4918 : loss : 0.023563, loss_ce: 0.008488
2022-01-16 01:04:22,906 iteration 4919 : loss : 0.030778, loss_ce: 0.013191
2022-01-16 01:04:23,853 iteration 4920 : loss : 0.022085, loss_ce: 0.008828
2022-01-16 01:04:24,759 iteration 4921 : loss : 0.017627, loss_ce: 0.008776
2022-01-16 01:04:25,639 iteration 4922 : loss : 0.018057, loss_ce: 0.004791
2022-01-16 01:04:26,643 iteration 4923 : loss : 0.024873, loss_ce: 0.009641
2022-01-16 01:04:27,679 iteration 4924 : loss : 0.032915, loss_ce: 0.016796
2022-01-16 01:04:28,671 iteration 4925 : loss : 0.022000, loss_ce: 0.007762
2022-01-16 01:04:29,684 iteration 4926 : loss : 0.022300, loss_ce: 0.011349
2022-01-16 01:04:30,626 iteration 4927 : loss : 0.015951, loss_ce: 0.005101
2022-01-16 01:04:31,652 iteration 4928 : loss : 0.040420, loss_ce: 0.012581
2022-01-16 01:04:32,706 iteration 4929 : loss : 0.022908, loss_ce: 0.010011
2022-01-16 01:04:32,707 Training Data Eval:
2022-01-16 01:04:37,253   Average segmentation loss on training set: 0.0136
2022-01-16 01:04:37,254 Validation Data Eval:
2022-01-16 01:04:38,752   Average segmentation loss on validation set: 0.1162
2022-01-16 01:04:39,714 iteration 4930 : loss : 0.021939, loss_ce: 0.006477
 72%|█████████████████████        | 290/400 [1:25:32<34:05, 18.60s/it]2022-01-16 01:04:40,710 iteration 4931 : loss : 0.024032, loss_ce: 0.012238
2022-01-16 01:04:41,697 iteration 4932 : loss : 0.026944, loss_ce: 0.014149
2022-01-16 01:04:42,587 iteration 4933 : loss : 0.021008, loss_ce: 0.011040
2022-01-16 01:04:43,615 iteration 4934 : loss : 0.034769, loss_ce: 0.010458
2022-01-16 01:04:44,575 iteration 4935 : loss : 0.027635, loss_ce: 0.008111
2022-01-16 01:04:45,558 iteration 4936 : loss : 0.020693, loss_ce: 0.007683
2022-01-16 01:04:46,527 iteration 4937 : loss : 0.018984, loss_ce: 0.007900
2022-01-16 01:04:47,552 iteration 4938 : loss : 0.033372, loss_ce: 0.011694
2022-01-16 01:04:48,568 iteration 4939 : loss : 0.026403, loss_ce: 0.010857
2022-01-16 01:04:49,506 iteration 4940 : loss : 0.020235, loss_ce: 0.008322
2022-01-16 01:04:50,485 iteration 4941 : loss : 0.021116, loss_ce: 0.009457
2022-01-16 01:04:51,468 iteration 4942 : loss : 0.023923, loss_ce: 0.008616
2022-01-16 01:04:52,539 iteration 4943 : loss : 0.041843, loss_ce: 0.009221
2022-01-16 01:04:53,506 iteration 4944 : loss : 0.019380, loss_ce: 0.006709
2022-01-16 01:04:54,519 iteration 4945 : loss : 0.035238, loss_ce: 0.014188
2022-01-16 01:04:55,555 iteration 4946 : loss : 0.028856, loss_ce: 0.008422
2022-01-16 01:04:56,499 iteration 4947 : loss : 0.026839, loss_ce: 0.010367
 73%|█████████████████████        | 291/400 [1:25:49<32:47, 18.05s/it]2022-01-16 01:04:57,551 iteration 4948 : loss : 0.019136, loss_ce: 0.007013
2022-01-16 01:04:58,492 iteration 4949 : loss : 0.023761, loss_ce: 0.009390
2022-01-16 01:04:59,504 iteration 4950 : loss : 0.026020, loss_ce: 0.011346
2022-01-16 01:05:00,503 iteration 4951 : loss : 0.019814, loss_ce: 0.006125
2022-01-16 01:05:01,490 iteration 4952 : loss : 0.022657, loss_ce: 0.013695
2022-01-16 01:05:02,502 iteration 4953 : loss : 0.021554, loss_ce: 0.008999
2022-01-16 01:05:03,439 iteration 4954 : loss : 0.018516, loss_ce: 0.006371
2022-01-16 01:05:04,328 iteration 4955 : loss : 0.024463, loss_ce: 0.006606
2022-01-16 01:05:05,278 iteration 4956 : loss : 0.024839, loss_ce: 0.006429
2022-01-16 01:05:06,137 iteration 4957 : loss : 0.018022, loss_ce: 0.007302
2022-01-16 01:05:07,106 iteration 4958 : loss : 0.022842, loss_ce: 0.011293
2022-01-16 01:05:08,074 iteration 4959 : loss : 0.048355, loss_ce: 0.031924
2022-01-16 01:05:08,956 iteration 4960 : loss : 0.016499, loss_ce: 0.006404
2022-01-16 01:05:09,924 iteration 4961 : loss : 0.019012, loss_ce: 0.007601
2022-01-16 01:05:10,817 iteration 4962 : loss : 0.020321, loss_ce: 0.005335
2022-01-16 01:05:11,748 iteration 4963 : loss : 0.019688, loss_ce: 0.007460
2022-01-16 01:05:12,762 iteration 4964 : loss : 0.020710, loss_ce: 0.007546
 73%|█████████████████████▏       | 292/400 [1:26:05<31:31, 17.52s/it]2022-01-16 01:05:13,860 iteration 4965 : loss : 0.030435, loss_ce: 0.011978
2022-01-16 01:05:14,890 iteration 4966 : loss : 0.020831, loss_ce: 0.008356
2022-01-16 01:05:15,869 iteration 4967 : loss : 0.017880, loss_ce: 0.007065
2022-01-16 01:05:16,869 iteration 4968 : loss : 0.016367, loss_ce: 0.007503
2022-01-16 01:05:17,963 iteration 4969 : loss : 0.034406, loss_ce: 0.011265
2022-01-16 01:05:18,878 iteration 4970 : loss : 0.016038, loss_ce: 0.006528
2022-01-16 01:05:19,814 iteration 4971 : loss : 0.016742, loss_ce: 0.009200
2022-01-16 01:05:20,819 iteration 4972 : loss : 0.024739, loss_ce: 0.010534
2022-01-16 01:05:21,789 iteration 4973 : loss : 0.030251, loss_ce: 0.011683
2022-01-16 01:05:22,896 iteration 4974 : loss : 0.022141, loss_ce: 0.007503
2022-01-16 01:05:23,851 iteration 4975 : loss : 0.017401, loss_ce: 0.005192
2022-01-16 01:05:24,748 iteration 4976 : loss : 0.015318, loss_ce: 0.005645
2022-01-16 01:05:25,743 iteration 4977 : loss : 0.024353, loss_ce: 0.005533
2022-01-16 01:05:26,688 iteration 4978 : loss : 0.019037, loss_ce: 0.005258
2022-01-16 01:05:27,647 iteration 4979 : loss : 0.019202, loss_ce: 0.007311
2022-01-16 01:05:28,618 iteration 4980 : loss : 0.020580, loss_ce: 0.005809
2022-01-16 01:05:29,576 iteration 4981 : loss : 0.022576, loss_ce: 0.007160
 73%|█████████████████████▏       | 293/400 [1:26:22<30:51, 17.31s/it]2022-01-16 01:05:30,580 iteration 4982 : loss : 0.017334, loss_ce: 0.007810
2022-01-16 01:05:31,515 iteration 4983 : loss : 0.017873, loss_ce: 0.007200
2022-01-16 01:05:32,586 iteration 4984 : loss : 0.022475, loss_ce: 0.009287
2022-01-16 01:05:33,472 iteration 4985 : loss : 0.019527, loss_ce: 0.005802
2022-01-16 01:05:34,523 iteration 4986 : loss : 0.020716, loss_ce: 0.008669
2022-01-16 01:05:35,432 iteration 4987 : loss : 0.017973, loss_ce: 0.005171
2022-01-16 01:05:36,413 iteration 4988 : loss : 0.027851, loss_ce: 0.009005
2022-01-16 01:05:37,438 iteration 4989 : loss : 0.026739, loss_ce: 0.009300
2022-01-16 01:05:38,493 iteration 4990 : loss : 0.017655, loss_ce: 0.007978
2022-01-16 01:05:39,475 iteration 4991 : loss : 0.024214, loss_ce: 0.006876
2022-01-16 01:05:40,341 iteration 4992 : loss : 0.014777, loss_ce: 0.007018
2022-01-16 01:05:41,279 iteration 4993 : loss : 0.022263, loss_ce: 0.007569
2022-01-16 01:05:42,183 iteration 4994 : loss : 0.023229, loss_ce: 0.007190
2022-01-16 01:05:43,102 iteration 4995 : loss : 0.019090, loss_ce: 0.008521
2022-01-16 01:05:44,127 iteration 4996 : loss : 0.024458, loss_ce: 0.006582
2022-01-16 01:05:45,007 iteration 4997 : loss : 0.016941, loss_ce: 0.004809
2022-01-16 01:05:45,902 iteration 4998 : loss : 0.020337, loss_ce: 0.007545
 74%|█████████████████████▎       | 294/400 [1:26:39<30:03, 17.01s/it]2022-01-16 01:05:46,889 iteration 4999 : loss : 0.018359, loss_ce: 0.006495
2022-01-16 01:05:47,825 iteration 5000 : loss : 0.018311, loss_ce: 0.006741
2022-01-16 01:05:48,770 iteration 5001 : loss : 0.022714, loss_ce: 0.009158
2022-01-16 01:05:49,704 iteration 5002 : loss : 0.016420, loss_ce: 0.005652
2022-01-16 01:05:50,691 iteration 5003 : loss : 0.047261, loss_ce: 0.010420
2022-01-16 01:05:51,642 iteration 5004 : loss : 0.022614, loss_ce: 0.007889
2022-01-16 01:05:52,597 iteration 5005 : loss : 0.018571, loss_ce: 0.007801
2022-01-16 01:05:53,621 iteration 5006 : loss : 0.020302, loss_ce: 0.008396
2022-01-16 01:05:54,625 iteration 5007 : loss : 0.024918, loss_ce: 0.011235
2022-01-16 01:05:55,636 iteration 5008 : loss : 0.024833, loss_ce: 0.009964
2022-01-16 01:05:56,646 iteration 5009 : loss : 0.021698, loss_ce: 0.005346
2022-01-16 01:05:57,641 iteration 5010 : loss : 0.023330, loss_ce: 0.008675
2022-01-16 01:05:58,583 iteration 5011 : loss : 0.017949, loss_ce: 0.008219
2022-01-16 01:05:59,563 iteration 5012 : loss : 0.020185, loss_ce: 0.007794
2022-01-16 01:06:00,458 iteration 5013 : loss : 0.021158, loss_ce: 0.007725
2022-01-16 01:06:01,409 iteration 5014 : loss : 0.028644, loss_ce: 0.009876
2022-01-16 01:06:01,409 Training Data Eval:
2022-01-16 01:06:05,944   Average segmentation loss on training set: 0.0122
2022-01-16 01:06:05,944 Validation Data Eval:
2022-01-16 01:06:07,440   Average segmentation loss on validation set: 0.1227
2022-01-16 01:06:08,392 iteration 5015 : loss : 0.020687, loss_ce: 0.006520
 74%|█████████████████████▍       | 295/400 [1:27:01<32:38, 18.65s/it]2022-01-16 01:06:09,403 iteration 5016 : loss : 0.022055, loss_ce: 0.011387
2022-01-16 01:06:10,336 iteration 5017 : loss : 0.018985, loss_ce: 0.007550
2022-01-16 01:06:11,286 iteration 5018 : loss : 0.024516, loss_ce: 0.011789
2022-01-16 01:06:12,268 iteration 5019 : loss : 0.016331, loss_ce: 0.005446
2022-01-16 01:06:13,257 iteration 5020 : loss : 0.024297, loss_ce: 0.008904
2022-01-16 01:06:14,272 iteration 5021 : loss : 0.016409, loss_ce: 0.007928
2022-01-16 01:06:15,176 iteration 5022 : loss : 0.014266, loss_ce: 0.005001
2022-01-16 01:06:16,138 iteration 5023 : loss : 0.023492, loss_ce: 0.006989
2022-01-16 01:06:17,211 iteration 5024 : loss : 0.031683, loss_ce: 0.007051
2022-01-16 01:06:18,249 iteration 5025 : loss : 0.021268, loss_ce: 0.004188
2022-01-16 01:06:19,222 iteration 5026 : loss : 0.020114, loss_ce: 0.007227
2022-01-16 01:06:20,147 iteration 5027 : loss : 0.019329, loss_ce: 0.008291
2022-01-16 01:06:21,084 iteration 5028 : loss : 0.018601, loss_ce: 0.006809
2022-01-16 01:06:22,138 iteration 5029 : loss : 0.028533, loss_ce: 0.006735
2022-01-16 01:06:23,099 iteration 5030 : loss : 0.021389, loss_ce: 0.011892
2022-01-16 01:06:24,134 iteration 5031 : loss : 0.034356, loss_ce: 0.018775
2022-01-16 01:06:25,102 iteration 5032 : loss : 0.022681, loss_ce: 0.010777
 74%|█████████████████████▍       | 296/400 [1:27:18<31:19, 18.07s/it]2022-01-16 01:06:26,261 iteration 5033 : loss : 0.027834, loss_ce: 0.009104
2022-01-16 01:06:27,205 iteration 5034 : loss : 0.019663, loss_ce: 0.006692
2022-01-16 01:06:28,132 iteration 5035 : loss : 0.017172, loss_ce: 0.007018
2022-01-16 01:06:29,072 iteration 5036 : loss : 0.027212, loss_ce: 0.010673
2022-01-16 01:06:30,043 iteration 5037 : loss : 0.020294, loss_ce: 0.008072
2022-01-16 01:06:30,974 iteration 5038 : loss : 0.023712, loss_ce: 0.006685
2022-01-16 01:06:32,028 iteration 5039 : loss : 0.017432, loss_ce: 0.008235
2022-01-16 01:06:33,002 iteration 5040 : loss : 0.019804, loss_ce: 0.006735
2022-01-16 01:06:34,043 iteration 5041 : loss : 0.020822, loss_ce: 0.007461
2022-01-16 01:06:34,964 iteration 5042 : loss : 0.021521, loss_ce: 0.008985
2022-01-16 01:06:35,926 iteration 5043 : loss : 0.019729, loss_ce: 0.008786
2022-01-16 01:06:36,894 iteration 5044 : loss : 0.023461, loss_ce: 0.011215
2022-01-16 01:06:37,916 iteration 5045 : loss : 0.026776, loss_ce: 0.011575
2022-01-16 01:06:38,901 iteration 5046 : loss : 0.030250, loss_ce: 0.009075
2022-01-16 01:06:39,850 iteration 5047 : loss : 0.026823, loss_ce: 0.006849
2022-01-16 01:06:40,787 iteration 5048 : loss : 0.017508, loss_ce: 0.007508
2022-01-16 01:06:41,722 iteration 5049 : loss : 0.020917, loss_ce: 0.009558
 74%|█████████████████████▌       | 297/400 [1:27:34<30:16, 17.64s/it]2022-01-16 01:06:42,759 iteration 5050 : loss : 0.023287, loss_ce: 0.006751
2022-01-16 01:06:43,709 iteration 5051 : loss : 0.026480, loss_ce: 0.009802
2022-01-16 01:06:44,667 iteration 5052 : loss : 0.019293, loss_ce: 0.008863
2022-01-16 01:06:45,605 iteration 5053 : loss : 0.016006, loss_ce: 0.006477
2022-01-16 01:06:46,570 iteration 5054 : loss : 0.016468, loss_ce: 0.004785
2022-01-16 01:06:47,508 iteration 5055 : loss : 0.018281, loss_ce: 0.006347
2022-01-16 01:06:48,438 iteration 5056 : loss : 0.024509, loss_ce: 0.005944
2022-01-16 01:06:49,453 iteration 5057 : loss : 0.019908, loss_ce: 0.011073
2022-01-16 01:06:50,486 iteration 5058 : loss : 0.023596, loss_ce: 0.009367
2022-01-16 01:06:51,320 iteration 5059 : loss : 0.015140, loss_ce: 0.003992
2022-01-16 01:06:52,283 iteration 5060 : loss : 0.020779, loss_ce: 0.006210
2022-01-16 01:06:53,279 iteration 5061 : loss : 0.016436, loss_ce: 0.006549
2022-01-16 01:06:54,265 iteration 5062 : loss : 0.027389, loss_ce: 0.008294
2022-01-16 01:06:55,296 iteration 5063 : loss : 0.024441, loss_ce: 0.009949
2022-01-16 01:06:56,219 iteration 5064 : loss : 0.017008, loss_ce: 0.007189
2022-01-16 01:06:57,146 iteration 5065 : loss : 0.021565, loss_ce: 0.008046
2022-01-16 01:06:58,107 iteration 5066 : loss : 0.018411, loss_ce: 0.010204
 74%|█████████████████████▌       | 298/400 [1:27:51<29:20, 17.26s/it]2022-01-16 01:06:59,237 iteration 5067 : loss : 0.033051, loss_ce: 0.013315
2022-01-16 01:07:00,232 iteration 5068 : loss : 0.021942, loss_ce: 0.011454
2022-01-16 01:07:01,217 iteration 5069 : loss : 0.024174, loss_ce: 0.009117
2022-01-16 01:07:02,170 iteration 5070 : loss : 0.017403, loss_ce: 0.004802
2022-01-16 01:07:03,205 iteration 5071 : loss : 0.019438, loss_ce: 0.007444
2022-01-16 01:07:04,041 iteration 5072 : loss : 0.014844, loss_ce: 0.005183
2022-01-16 01:07:04,991 iteration 5073 : loss : 0.018305, loss_ce: 0.009556
2022-01-16 01:07:05,996 iteration 5074 : loss : 0.018944, loss_ce: 0.005755
2022-01-16 01:07:06,963 iteration 5075 : loss : 0.022010, loss_ce: 0.008027
2022-01-16 01:07:07,990 iteration 5076 : loss : 0.020283, loss_ce: 0.009535
2022-01-16 01:07:08,925 iteration 5077 : loss : 0.019605, loss_ce: 0.007079
2022-01-16 01:07:09,899 iteration 5078 : loss : 0.015366, loss_ce: 0.004210
2022-01-16 01:07:10,836 iteration 5079 : loss : 0.017850, loss_ce: 0.007360
2022-01-16 01:07:11,806 iteration 5080 : loss : 0.019740, loss_ce: 0.007186
2022-01-16 01:07:12,807 iteration 5081 : loss : 0.026156, loss_ce: 0.014052
2022-01-16 01:07:13,836 iteration 5082 : loss : 0.031534, loss_ce: 0.015020
2022-01-16 01:07:14,828 iteration 5083 : loss : 0.018306, loss_ce: 0.005550
 75%|█████████████████████▋       | 299/400 [1:28:07<28:47, 17.10s/it]2022-01-16 01:07:15,830 iteration 5084 : loss : 0.017692, loss_ce: 0.005783
2022-01-16 01:07:16,795 iteration 5085 : loss : 0.034123, loss_ce: 0.012638
2022-01-16 01:07:17,721 iteration 5086 : loss : 0.015504, loss_ce: 0.005974
2022-01-16 01:07:18,741 iteration 5087 : loss : 0.029025, loss_ce: 0.012449
2022-01-16 01:07:19,728 iteration 5088 : loss : 0.021335, loss_ce: 0.008295
2022-01-16 01:07:20,643 iteration 5089 : loss : 0.016436, loss_ce: 0.005502
2022-01-16 01:07:21,575 iteration 5090 : loss : 0.017717, loss_ce: 0.006240
2022-01-16 01:07:22,646 iteration 5091 : loss : 0.032970, loss_ce: 0.015942
2022-01-16 01:07:23,617 iteration 5092 : loss : 0.017823, loss_ce: 0.010482
2022-01-16 01:07:24,543 iteration 5093 : loss : 0.017665, loss_ce: 0.008428
2022-01-16 01:07:25,437 iteration 5094 : loss : 0.014765, loss_ce: 0.005536
2022-01-16 01:07:26,451 iteration 5095 : loss : 0.033536, loss_ce: 0.015350
2022-01-16 01:07:27,365 iteration 5096 : loss : 0.014927, loss_ce: 0.006064
2022-01-16 01:07:28,285 iteration 5097 : loss : 0.016033, loss_ce: 0.007027
2022-01-16 01:07:29,266 iteration 5098 : loss : 0.020205, loss_ce: 0.006489
2022-01-16 01:07:30,217 iteration 5099 : loss : 0.020445, loss_ce: 0.007088
2022-01-16 01:07:30,217 Training Data Eval:
2022-01-16 01:07:34,759   Average segmentation loss on training set: 0.0122
2022-01-16 01:07:34,760 Validation Data Eval:
2022-01-16 01:07:36,246   Average segmentation loss on validation set: 0.0692
2022-01-16 01:07:37,197 iteration 5100 : loss : 0.013498, loss_ce: 0.006217
 75%|█████████████████████▊       | 300/400 [1:28:30<31:08, 18.68s/it]2022-01-16 01:07:38,239 iteration 5101 : loss : 0.017678, loss_ce: 0.007366
2022-01-16 01:07:39,163 iteration 5102 : loss : 0.014441, loss_ce: 0.005997
2022-01-16 01:07:40,113 iteration 5103 : loss : 0.019619, loss_ce: 0.008152
2022-01-16 01:07:41,154 iteration 5104 : loss : 0.021843, loss_ce: 0.008370
2022-01-16 01:07:42,055 iteration 5105 : loss : 0.017343, loss_ce: 0.005794
2022-01-16 01:07:43,095 iteration 5106 : loss : 0.017992, loss_ce: 0.006752
2022-01-16 01:07:44,002 iteration 5107 : loss : 0.016190, loss_ce: 0.006186
2022-01-16 01:07:44,995 iteration 5108 : loss : 0.026346, loss_ce: 0.010875
2022-01-16 01:07:45,963 iteration 5109 : loss : 0.020598, loss_ce: 0.006674
2022-01-16 01:07:46,917 iteration 5110 : loss : 0.038670, loss_ce: 0.027458
2022-01-16 01:07:47,911 iteration 5111 : loss : 0.018341, loss_ce: 0.006214
2022-01-16 01:07:48,815 iteration 5112 : loss : 0.027418, loss_ce: 0.007164
2022-01-16 01:07:49,842 iteration 5113 : loss : 0.063021, loss_ce: 0.012704
2022-01-16 01:07:50,788 iteration 5114 : loss : 0.019464, loss_ce: 0.010109
2022-01-16 01:07:51,703 iteration 5115 : loss : 0.019445, loss_ce: 0.005606
2022-01-16 01:07:52,629 iteration 5116 : loss : 0.015503, loss_ce: 0.006370
2022-01-16 01:07:53,656 iteration 5117 : loss : 0.024764, loss_ce: 0.011422
 75%|█████████████████████▊       | 301/400 [1:28:46<29:43, 18.02s/it]2022-01-16 01:07:54,696 iteration 5118 : loss : 0.012911, loss_ce: 0.005170
2022-01-16 01:07:55,676 iteration 5119 : loss : 0.026702, loss_ce: 0.008336
2022-01-16 01:07:56,600 iteration 5120 : loss : 0.023981, loss_ce: 0.006600
2022-01-16 01:07:57,560 iteration 5121 : loss : 0.022738, loss_ce: 0.011773
2022-01-16 01:07:58,476 iteration 5122 : loss : 0.035019, loss_ce: 0.014597
2022-01-16 01:07:59,422 iteration 5123 : loss : 0.024559, loss_ce: 0.006345
2022-01-16 01:08:00,410 iteration 5124 : loss : 0.019708, loss_ce: 0.007799
2022-01-16 01:08:01,271 iteration 5125 : loss : 0.018971, loss_ce: 0.009481
2022-01-16 01:08:02,169 iteration 5126 : loss : 0.026150, loss_ce: 0.009638
2022-01-16 01:08:03,170 iteration 5127 : loss : 0.024536, loss_ce: 0.008438
2022-01-16 01:08:04,096 iteration 5128 : loss : 0.014993, loss_ce: 0.005952
2022-01-16 01:08:05,083 iteration 5129 : loss : 0.019683, loss_ce: 0.006602
2022-01-16 01:08:06,047 iteration 5130 : loss : 0.027607, loss_ce: 0.009097
2022-01-16 01:08:06,917 iteration 5131 : loss : 0.012622, loss_ce: 0.004876
2022-01-16 01:08:07,865 iteration 5132 : loss : 0.019325, loss_ce: 0.008414
2022-01-16 01:08:08,780 iteration 5133 : loss : 0.023826, loss_ce: 0.006925
2022-01-16 01:08:09,678 iteration 5134 : loss : 0.018553, loss_ce: 0.007364
 76%|█████████████████████▉       | 302/400 [1:29:02<28:26, 17.42s/it]2022-01-16 01:08:10,857 iteration 5135 : loss : 0.039571, loss_ce: 0.017795
2022-01-16 01:08:11,812 iteration 5136 : loss : 0.019087, loss_ce: 0.006190
2022-01-16 01:08:12,827 iteration 5137 : loss : 0.017085, loss_ce: 0.005841
2022-01-16 01:08:13,742 iteration 5138 : loss : 0.022405, loss_ce: 0.009228
2022-01-16 01:08:14,701 iteration 5139 : loss : 0.017032, loss_ce: 0.006611
2022-01-16 01:08:15,761 iteration 5140 : loss : 0.016329, loss_ce: 0.007357
2022-01-16 01:08:16,682 iteration 5141 : loss : 0.019820, loss_ce: 0.006861
2022-01-16 01:08:17,651 iteration 5142 : loss : 0.025795, loss_ce: 0.008911
2022-01-16 01:08:18,523 iteration 5143 : loss : 0.016461, loss_ce: 0.006396
2022-01-16 01:08:19,511 iteration 5144 : loss : 0.019010, loss_ce: 0.010268
2022-01-16 01:08:20,380 iteration 5145 : loss : 0.013515, loss_ce: 0.004262
2022-01-16 01:08:21,412 iteration 5146 : loss : 0.025318, loss_ce: 0.010938
2022-01-16 01:08:22,448 iteration 5147 : loss : 0.026303, loss_ce: 0.008963
2022-01-16 01:08:23,385 iteration 5148 : loss : 0.023077, loss_ce: 0.010779
2022-01-16 01:08:24,320 iteration 5149 : loss : 0.023004, loss_ce: 0.006753
2022-01-16 01:08:25,254 iteration 5150 : loss : 0.017456, loss_ce: 0.007264
2022-01-16 01:08:26,218 iteration 5151 : loss : 0.040028, loss_ce: 0.007094
 76%|█████████████████████▉       | 303/400 [1:29:19<27:43, 17.15s/it]2022-01-16 01:08:27,188 iteration 5152 : loss : 0.019230, loss_ce: 0.004218
2022-01-16 01:08:28,042 iteration 5153 : loss : 0.013717, loss_ce: 0.005249
2022-01-16 01:08:29,074 iteration 5154 : loss : 0.021698, loss_ce: 0.009377
2022-01-16 01:08:29,969 iteration 5155 : loss : 0.013317, loss_ce: 0.004531
2022-01-16 01:08:30,903 iteration 5156 : loss : 0.027536, loss_ce: 0.012887
2022-01-16 01:08:31,786 iteration 5157 : loss : 0.016085, loss_ce: 0.004740
2022-01-16 01:08:32,714 iteration 5158 : loss : 0.018511, loss_ce: 0.005980
2022-01-16 01:08:33,729 iteration 5159 : loss : 0.023171, loss_ce: 0.007111
2022-01-16 01:08:34,621 iteration 5160 : loss : 0.019668, loss_ce: 0.006810
2022-01-16 01:08:35,562 iteration 5161 : loss : 0.015716, loss_ce: 0.006234
2022-01-16 01:08:36,449 iteration 5162 : loss : 0.019196, loss_ce: 0.010244
2022-01-16 01:08:37,416 iteration 5163 : loss : 0.017954, loss_ce: 0.007385
2022-01-16 01:08:38,391 iteration 5164 : loss : 0.019452, loss_ce: 0.008867
2022-01-16 01:08:39,275 iteration 5165 : loss : 0.017187, loss_ce: 0.005336
2022-01-16 01:08:40,223 iteration 5166 : loss : 0.016458, loss_ce: 0.006868
2022-01-16 01:08:41,191 iteration 5167 : loss : 0.031945, loss_ce: 0.009903
2022-01-16 01:08:42,206 iteration 5168 : loss : 0.017775, loss_ce: 0.005763
 76%|██████████████████████       | 304/400 [1:29:35<26:53, 16.80s/it]2022-01-16 01:08:43,351 iteration 5169 : loss : 0.025807, loss_ce: 0.011351
2022-01-16 01:08:44,251 iteration 5170 : loss : 0.018334, loss_ce: 0.005222
2022-01-16 01:08:45,278 iteration 5171 : loss : 0.016430, loss_ce: 0.007048
2022-01-16 01:08:46,155 iteration 5172 : loss : 0.017583, loss_ce: 0.005156
2022-01-16 01:08:46,969 iteration 5173 : loss : 0.014240, loss_ce: 0.005977
2022-01-16 01:08:48,001 iteration 5174 : loss : 0.025387, loss_ce: 0.009203
2022-01-16 01:08:48,912 iteration 5175 : loss : 0.020224, loss_ce: 0.009642
2022-01-16 01:08:50,007 iteration 5176 : loss : 0.022079, loss_ce: 0.007742
2022-01-16 01:08:50,917 iteration 5177 : loss : 0.016856, loss_ce: 0.006457
2022-01-16 01:08:51,854 iteration 5178 : loss : 0.016147, loss_ce: 0.004924
2022-01-16 01:08:52,869 iteration 5179 : loss : 0.018382, loss_ce: 0.005844
2022-01-16 01:08:53,825 iteration 5180 : loss : 0.017915, loss_ce: 0.006882
2022-01-16 01:08:54,729 iteration 5181 : loss : 0.018467, loss_ce: 0.005436
2022-01-16 01:08:55,682 iteration 5182 : loss : 0.018277, loss_ce: 0.006725
2022-01-16 01:08:56,608 iteration 5183 : loss : 0.019848, loss_ce: 0.008512
2022-01-16 01:08:57,519 iteration 5184 : loss : 0.029861, loss_ce: 0.009896
2022-01-16 01:08:57,519 Training Data Eval:
2022-01-16 01:09:02,059   Average segmentation loss on training set: 0.0122
2022-01-16 01:09:02,059 Validation Data Eval:
2022-01-16 01:09:03,547   Average segmentation loss on validation set: 0.0821
2022-01-16 01:09:04,485 iteration 5185 : loss : 0.020376, loss_ce: 0.007375
 76%|██████████████████████       | 305/400 [1:29:57<29:12, 18.45s/it]2022-01-16 01:09:05,522 iteration 5186 : loss : 0.018820, loss_ce: 0.008837
2022-01-16 01:09:06,414 iteration 5187 : loss : 0.018646, loss_ce: 0.006826
2022-01-16 01:09:07,319 iteration 5188 : loss : 0.015087, loss_ce: 0.005934
2022-01-16 01:09:08,231 iteration 5189 : loss : 0.018151, loss_ce: 0.007435
2022-01-16 01:09:09,124 iteration 5190 : loss : 0.024790, loss_ce: 0.012630
2022-01-16 01:09:10,129 iteration 5191 : loss : 0.020216, loss_ce: 0.006510
2022-01-16 01:09:11,113 iteration 5192 : loss : 0.016159, loss_ce: 0.004918
2022-01-16 01:09:12,009 iteration 5193 : loss : 0.012357, loss_ce: 0.004129
2022-01-16 01:09:12,995 iteration 5194 : loss : 0.023372, loss_ce: 0.009554
2022-01-16 01:09:13,913 iteration 5195 : loss : 0.016299, loss_ce: 0.005406
2022-01-16 01:09:14,757 iteration 5196 : loss : 0.013290, loss_ce: 0.003431
2022-01-16 01:09:15,640 iteration 5197 : loss : 0.014581, loss_ce: 0.004787
2022-01-16 01:09:16,547 iteration 5198 : loss : 0.017610, loss_ce: 0.009265
2022-01-16 01:09:17,525 iteration 5199 : loss : 0.014252, loss_ce: 0.004789
2022-01-16 01:09:18,471 iteration 5200 : loss : 0.026671, loss_ce: 0.008802
2022-01-16 01:09:19,434 iteration 5201 : loss : 0.019595, loss_ce: 0.006199
2022-01-16 01:09:20,474 iteration 5202 : loss : 0.022914, loss_ce: 0.012750
 76%|██████████████████████▏      | 306/400 [1:30:13<27:44, 17.71s/it]2022-01-16 01:09:21,456 iteration 5203 : loss : 0.013961, loss_ce: 0.005126
2022-01-16 01:09:22,381 iteration 5204 : loss : 0.022614, loss_ce: 0.008507
2022-01-16 01:09:23,475 iteration 5205 : loss : 0.023982, loss_ce: 0.008381
2022-01-16 01:09:24,424 iteration 5206 : loss : 0.016672, loss_ce: 0.005965
2022-01-16 01:09:25,384 iteration 5207 : loss : 0.021272, loss_ce: 0.011016
2022-01-16 01:09:26,421 iteration 5208 : loss : 0.019066, loss_ce: 0.007863
2022-01-16 01:09:27,321 iteration 5209 : loss : 0.014322, loss_ce: 0.005865
2022-01-16 01:09:28,320 iteration 5210 : loss : 0.023115, loss_ce: 0.009919
2022-01-16 01:09:29,294 iteration 5211 : loss : 0.017898, loss_ce: 0.007545
2022-01-16 01:09:30,248 iteration 5212 : loss : 0.017919, loss_ce: 0.006680
2022-01-16 01:09:31,088 iteration 5213 : loss : 0.014251, loss_ce: 0.005360
2022-01-16 01:09:32,142 iteration 5214 : loss : 0.030238, loss_ce: 0.014543
2022-01-16 01:09:33,127 iteration 5215 : loss : 0.019248, loss_ce: 0.006515
2022-01-16 01:09:34,142 iteration 5216 : loss : 0.022871, loss_ce: 0.007471
2022-01-16 01:09:35,189 iteration 5217 : loss : 0.016815, loss_ce: 0.005038
2022-01-16 01:09:36,103 iteration 5218 : loss : 0.023030, loss_ce: 0.003698
2022-01-16 01:09:37,163 iteration 5219 : loss : 0.019300, loss_ce: 0.006040
 77%|██████████████████████▎      | 307/400 [1:30:30<26:58, 17.40s/it]2022-01-16 01:09:38,166 iteration 5220 : loss : 0.021522, loss_ce: 0.006230
2022-01-16 01:09:39,109 iteration 5221 : loss : 0.032453, loss_ce: 0.012921
2022-01-16 01:09:40,005 iteration 5222 : loss : 0.016085, loss_ce: 0.005860
2022-01-16 01:09:41,007 iteration 5223 : loss : 0.028034, loss_ce: 0.011337
2022-01-16 01:09:41,947 iteration 5224 : loss : 0.021788, loss_ce: 0.008178
2022-01-16 01:09:42,964 iteration 5225 : loss : 0.017744, loss_ce: 0.005959
2022-01-16 01:09:43,905 iteration 5226 : loss : 0.021253, loss_ce: 0.008377
2022-01-16 01:09:44,957 iteration 5227 : loss : 0.026025, loss_ce: 0.009356
2022-01-16 01:09:45,878 iteration 5228 : loss : 0.017412, loss_ce: 0.005220
2022-01-16 01:09:46,964 iteration 5229 : loss : 0.021331, loss_ce: 0.008785
2022-01-16 01:09:47,805 iteration 5230 : loss : 0.012821, loss_ce: 0.005707
2022-01-16 01:09:48,784 iteration 5231 : loss : 0.021920, loss_ce: 0.010643
2022-01-16 01:09:49,751 iteration 5232 : loss : 0.020998, loss_ce: 0.006481
2022-01-16 01:09:50,751 iteration 5233 : loss : 0.019870, loss_ce: 0.006949
2022-01-16 01:09:51,678 iteration 5234 : loss : 0.014446, loss_ce: 0.006035
2022-01-16 01:09:52,645 iteration 5235 : loss : 0.020244, loss_ce: 0.007033
2022-01-16 01:09:53,654 iteration 5236 : loss : 0.020331, loss_ce: 0.006883
 77%|██████████████████████▎      | 308/400 [1:30:46<26:15, 17.13s/it]2022-01-16 01:09:54,542 iteration 5237 : loss : 0.013470, loss_ce: 0.005632
2022-01-16 01:09:55,533 iteration 5238 : loss : 0.015176, loss_ce: 0.006214
2022-01-16 01:09:56,509 iteration 5239 : loss : 0.020197, loss_ce: 0.006253
2022-01-16 01:09:57,513 iteration 5240 : loss : 0.173077, loss_ce: 0.004292
2022-01-16 01:09:58,434 iteration 5241 : loss : 0.015430, loss_ce: 0.006221
2022-01-16 01:09:59,391 iteration 5242 : loss : 0.018265, loss_ce: 0.008146
2022-01-16 01:10:00,439 iteration 5243 : loss : 0.022480, loss_ce: 0.007357
2022-01-16 01:10:01,442 iteration 5244 : loss : 0.015047, loss_ce: 0.005970
2022-01-16 01:10:02,413 iteration 5245 : loss : 0.027524, loss_ce: 0.014081
2022-01-16 01:10:03,403 iteration 5246 : loss : 0.030771, loss_ce: 0.008159
2022-01-16 01:10:04,278 iteration 5247 : loss : 0.014125, loss_ce: 0.005584
2022-01-16 01:10:05,279 iteration 5248 : loss : 0.017236, loss_ce: 0.006061
2022-01-16 01:10:06,334 iteration 5249 : loss : 0.019534, loss_ce: 0.006261
2022-01-16 01:10:07,329 iteration 5250 : loss : 0.020416, loss_ce: 0.009693
2022-01-16 01:10:08,203 iteration 5251 : loss : 0.013562, loss_ce: 0.004524
2022-01-16 01:10:09,168 iteration 5252 : loss : 0.017058, loss_ce: 0.006918
2022-01-16 01:10:10,164 iteration 5253 : loss : 0.039717, loss_ce: 0.010592
 77%|██████████████████████▍      | 309/400 [1:31:03<25:41, 16.94s/it]2022-01-16 01:10:11,184 iteration 5254 : loss : 0.013764, loss_ce: 0.005138
2022-01-16 01:10:12,138 iteration 5255 : loss : 0.030994, loss_ce: 0.018218
2022-01-16 01:10:13,051 iteration 5256 : loss : 0.015000, loss_ce: 0.006270
2022-01-16 01:10:14,013 iteration 5257 : loss : 0.021278, loss_ce: 0.008197
2022-01-16 01:10:15,016 iteration 5258 : loss : 0.017323, loss_ce: 0.004638
2022-01-16 01:10:15,917 iteration 5259 : loss : 0.024258, loss_ce: 0.006475
2022-01-16 01:10:16,892 iteration 5260 : loss : 0.013987, loss_ce: 0.005222
2022-01-16 01:10:17,874 iteration 5261 : loss : 0.023445, loss_ce: 0.011289
2022-01-16 01:10:18,840 iteration 5262 : loss : 0.012502, loss_ce: 0.004855
2022-01-16 01:10:19,813 iteration 5263 : loss : 0.017721, loss_ce: 0.008749
2022-01-16 01:10:20,714 iteration 5264 : loss : 0.012981, loss_ce: 0.005403
2022-01-16 01:10:21,718 iteration 5265 : loss : 0.021249, loss_ce: 0.008296
2022-01-16 01:10:22,770 iteration 5266 : loss : 0.018217, loss_ce: 0.005755
2022-01-16 01:10:23,729 iteration 5267 : loss : 0.026390, loss_ce: 0.007380
2022-01-16 01:10:24,708 iteration 5268 : loss : 0.025107, loss_ce: 0.008183
2022-01-16 01:10:25,794 iteration 5269 : loss : 0.037669, loss_ce: 0.011950
2022-01-16 01:10:25,794 Training Data Eval:
2022-01-16 01:10:30,337   Average segmentation loss on training set: 0.0107
2022-01-16 01:10:30,337 Validation Data Eval:
2022-01-16 01:10:31,833   Average segmentation loss on validation set: 0.0816
2022-01-16 01:10:32,783 iteration 5270 : loss : 0.016319, loss_ce: 0.006836
 78%|██████████████████████▍      | 310/400 [1:31:25<27:57, 18.64s/it]2022-01-16 01:10:33,767 iteration 5271 : loss : 0.016038, loss_ce: 0.005805
2022-01-16 01:10:34,750 iteration 5272 : loss : 0.024271, loss_ce: 0.012210
2022-01-16 01:10:35,673 iteration 5273 : loss : 0.016461, loss_ce: 0.004179
2022-01-16 01:10:36,608 iteration 5274 : loss : 0.018128, loss_ce: 0.007230
2022-01-16 01:10:37,481 iteration 5275 : loss : 0.014317, loss_ce: 0.006257
2022-01-16 01:10:38,461 iteration 5276 : loss : 0.018803, loss_ce: 0.007850
2022-01-16 01:10:39,418 iteration 5277 : loss : 0.020440, loss_ce: 0.008088
2022-01-16 01:10:40,281 iteration 5278 : loss : 0.015720, loss_ce: 0.006015
2022-01-16 01:10:41,232 iteration 5279 : loss : 0.014484, loss_ce: 0.006495
2022-01-16 01:10:42,332 iteration 5280 : loss : 0.020651, loss_ce: 0.007721
2022-01-16 01:10:43,272 iteration 5281 : loss : 0.020651, loss_ce: 0.006845
2022-01-16 01:10:44,152 iteration 5282 : loss : 0.012994, loss_ce: 0.003998
2022-01-16 01:10:45,115 iteration 5283 : loss : 0.025197, loss_ce: 0.008317
2022-01-16 01:10:46,094 iteration 5284 : loss : 0.025454, loss_ce: 0.007553
2022-01-16 01:10:47,046 iteration 5285 : loss : 0.025362, loss_ce: 0.010838
2022-01-16 01:10:47,911 iteration 5286 : loss : 0.013443, loss_ce: 0.005466
2022-01-16 01:10:48,847 iteration 5287 : loss : 0.017911, loss_ce: 0.003978
 78%|██████████████████████▌      | 311/400 [1:31:41<26:30, 17.87s/it]2022-01-16 01:10:49,910 iteration 5288 : loss : 0.019309, loss_ce: 0.008562
2022-01-16 01:10:50,910 iteration 5289 : loss : 0.022083, loss_ce: 0.007769
2022-01-16 01:10:51,856 iteration 5290 : loss : 0.019495, loss_ce: 0.004337
2022-01-16 01:10:52,787 iteration 5291 : loss : 0.023348, loss_ce: 0.007647
2022-01-16 01:10:53,787 iteration 5292 : loss : 0.020689, loss_ce: 0.007326
2022-01-16 01:10:54,764 iteration 5293 : loss : 0.017396, loss_ce: 0.006932
2022-01-16 01:10:55,771 iteration 5294 : loss : 0.017906, loss_ce: 0.006117
2022-01-16 01:10:56,835 iteration 5295 : loss : 0.034451, loss_ce: 0.013705
2022-01-16 01:10:57,843 iteration 5296 : loss : 0.026355, loss_ce: 0.006263
2022-01-16 01:10:58,853 iteration 5297 : loss : 0.015661, loss_ce: 0.004660
2022-01-16 01:10:59,865 iteration 5298 : loss : 0.023139, loss_ce: 0.009569
2022-01-16 01:11:00,868 iteration 5299 : loss : 0.019919, loss_ce: 0.007215
2022-01-16 01:11:01,897 iteration 5300 : loss : 0.017361, loss_ce: 0.005728
2022-01-16 01:11:02,788 iteration 5301 : loss : 0.016594, loss_ce: 0.005981
2022-01-16 01:11:03,686 iteration 5302 : loss : 0.014794, loss_ce: 0.007212
2022-01-16 01:11:04,589 iteration 5303 : loss : 0.014608, loss_ce: 0.005626
2022-01-16 01:11:05,468 iteration 5304 : loss : 0.017006, loss_ce: 0.005943
 78%|██████████████████████▌      | 312/400 [1:31:58<25:39, 17.50s/it]2022-01-16 01:11:06,513 iteration 5305 : loss : 0.028992, loss_ce: 0.012264
2022-01-16 01:11:07,586 iteration 5306 : loss : 0.023511, loss_ce: 0.009717
2022-01-16 01:11:08,683 iteration 5307 : loss : 0.019973, loss_ce: 0.007018
2022-01-16 01:11:09,726 iteration 5308 : loss : 0.026590, loss_ce: 0.007843
2022-01-16 01:11:10,762 iteration 5309 : loss : 0.022857, loss_ce: 0.006769
2022-01-16 01:11:11,700 iteration 5310 : loss : 0.015688, loss_ce: 0.007379
2022-01-16 01:11:12,615 iteration 5311 : loss : 0.021804, loss_ce: 0.006740
2022-01-16 01:11:13,645 iteration 5312 : loss : 0.018642, loss_ce: 0.008701
2022-01-16 01:11:14,727 iteration 5313 : loss : 0.024068, loss_ce: 0.006673
2022-01-16 01:11:15,708 iteration 5314 : loss : 0.020047, loss_ce: 0.006273
2022-01-16 01:11:16,741 iteration 5315 : loss : 0.028680, loss_ce: 0.007076
2022-01-16 01:11:17,764 iteration 5316 : loss : 0.019263, loss_ce: 0.008461
2022-01-16 01:11:18,721 iteration 5317 : loss : 0.019578, loss_ce: 0.008151
2022-01-16 01:11:19,646 iteration 5318 : loss : 0.015109, loss_ce: 0.005915
2022-01-16 01:11:20,675 iteration 5319 : loss : 0.023780, loss_ce: 0.009516
2022-01-16 01:11:21,688 iteration 5320 : loss : 0.020521, loss_ce: 0.008725
2022-01-16 01:11:22,726 iteration 5321 : loss : 0.033373, loss_ce: 0.014409
 78%|██████████████████████▋      | 313/400 [1:32:15<25:15, 17.42s/it]2022-01-16 01:11:23,668 iteration 5322 : loss : 0.027353, loss_ce: 0.011501
2022-01-16 01:11:24,651 iteration 5323 : loss : 0.026834, loss_ce: 0.011705
2022-01-16 01:11:25,542 iteration 5324 : loss : 0.020814, loss_ce: 0.006386
2022-01-16 01:11:26,462 iteration 5325 : loss : 0.017547, loss_ce: 0.004272
2022-01-16 01:11:27,464 iteration 5326 : loss : 0.021104, loss_ce: 0.007594
2022-01-16 01:11:28,386 iteration 5327 : loss : 0.016315, loss_ce: 0.005726
2022-01-16 01:11:29,322 iteration 5328 : loss : 0.023934, loss_ce: 0.012475
2022-01-16 01:11:30,337 iteration 5329 : loss : 0.025691, loss_ce: 0.009348
2022-01-16 01:11:31,327 iteration 5330 : loss : 0.018439, loss_ce: 0.007045
2022-01-16 01:11:32,287 iteration 5331 : loss : 0.016592, loss_ce: 0.005460
2022-01-16 01:11:33,261 iteration 5332 : loss : 0.024077, loss_ce: 0.008320
2022-01-16 01:11:34,266 iteration 5333 : loss : 0.016423, loss_ce: 0.007986
2022-01-16 01:11:35,250 iteration 5334 : loss : 0.062337, loss_ce: 0.031198
2022-01-16 01:11:36,256 iteration 5335 : loss : 0.026899, loss_ce: 0.008734
2022-01-16 01:11:37,232 iteration 5336 : loss : 0.019051, loss_ce: 0.007480
2022-01-16 01:11:38,155 iteration 5337 : loss : 0.014725, loss_ce: 0.006010
2022-01-16 01:11:39,082 iteration 5338 : loss : 0.016357, loss_ce: 0.006904
 78%|██████████████████████▊      | 314/400 [1:32:32<24:30, 17.10s/it]2022-01-16 01:11:40,280 iteration 5339 : loss : 0.023542, loss_ce: 0.009649
2022-01-16 01:11:41,306 iteration 5340 : loss : 0.026174, loss_ce: 0.013509
2022-01-16 01:11:42,302 iteration 5341 : loss : 0.020760, loss_ce: 0.004805
2022-01-16 01:11:43,283 iteration 5342 : loss : 0.016861, loss_ce: 0.008625
2022-01-16 01:11:44,215 iteration 5343 : loss : 0.013576, loss_ce: 0.004182
2022-01-16 01:11:45,206 iteration 5344 : loss : 0.019538, loss_ce: 0.006727
2022-01-16 01:11:46,165 iteration 5345 : loss : 0.016449, loss_ce: 0.005621
2022-01-16 01:11:47,175 iteration 5346 : loss : 0.025285, loss_ce: 0.008524
2022-01-16 01:11:48,192 iteration 5347 : loss : 0.018009, loss_ce: 0.005068
2022-01-16 01:11:49,221 iteration 5348 : loss : 0.017098, loss_ce: 0.004645
2022-01-16 01:11:50,204 iteration 5349 : loss : 0.022969, loss_ce: 0.008995
2022-01-16 01:11:51,095 iteration 5350 : loss : 0.012768, loss_ce: 0.004727
2022-01-16 01:11:51,993 iteration 5351 : loss : 0.021707, loss_ce: 0.008538
2022-01-16 01:11:53,005 iteration 5352 : loss : 0.020877, loss_ce: 0.008238
2022-01-16 01:11:54,022 iteration 5353 : loss : 0.012543, loss_ce: 0.004754
2022-01-16 01:11:54,955 iteration 5354 : loss : 0.016288, loss_ce: 0.007697
2022-01-16 01:11:54,955 Training Data Eval:
2022-01-16 01:11:59,489   Average segmentation loss on training set: 0.0117
2022-01-16 01:11:59,489 Validation Data Eval:
2022-01-16 01:12:00,985   Average segmentation loss on validation set: 0.0998
2022-01-16 01:12:01,878 iteration 5355 : loss : 0.017787, loss_ce: 0.006701
 79%|██████████████████████▊      | 315/400 [1:32:54<26:39, 18.81s/it]2022-01-16 01:12:02,916 iteration 5356 : loss : 0.018117, loss_ce: 0.008203
2022-01-16 01:12:03,804 iteration 5357 : loss : 0.017659, loss_ce: 0.003810
2022-01-16 01:12:04,914 iteration 5358 : loss : 0.033181, loss_ce: 0.015094
2022-01-16 01:12:05,802 iteration 5359 : loss : 0.014187, loss_ce: 0.005434
2022-01-16 01:12:06,784 iteration 5360 : loss : 0.018726, loss_ce: 0.008172
2022-01-16 01:12:07,764 iteration 5361 : loss : 0.019951, loss_ce: 0.007202
2022-01-16 01:12:08,767 iteration 5362 : loss : 0.022591, loss_ce: 0.006378
2022-01-16 01:12:09,739 iteration 5363 : loss : 0.023864, loss_ce: 0.010861
2022-01-16 01:12:10,713 iteration 5364 : loss : 0.036630, loss_ce: 0.008247
2022-01-16 01:12:11,659 iteration 5365 : loss : 0.019303, loss_ce: 0.008619
2022-01-16 01:12:12,643 iteration 5366 : loss : 0.015648, loss_ce: 0.006035
2022-01-16 01:12:13,655 iteration 5367 : loss : 0.021275, loss_ce: 0.009262
2022-01-16 01:12:14,597 iteration 5368 : loss : 0.016454, loss_ce: 0.008001
2022-01-16 01:12:15,581 iteration 5369 : loss : 0.015638, loss_ce: 0.005553
2022-01-16 01:12:16,528 iteration 5370 : loss : 0.012869, loss_ce: 0.004908
2022-01-16 01:12:17,506 iteration 5371 : loss : 0.019867, loss_ce: 0.008363
2022-01-16 01:12:18,437 iteration 5372 : loss : 0.026215, loss_ce: 0.008453
 79%|██████████████████████▉      | 316/400 [1:33:11<25:23, 18.14s/it]2022-01-16 01:12:19,471 iteration 5373 : loss : 0.015777, loss_ce: 0.007715
2022-01-16 01:12:20,393 iteration 5374 : loss : 0.017134, loss_ce: 0.007203
2022-01-16 01:12:21,389 iteration 5375 : loss : 0.013526, loss_ce: 0.004424
2022-01-16 01:12:22,329 iteration 5376 : loss : 0.015168, loss_ce: 0.005363
2022-01-16 01:12:23,254 iteration 5377 : loss : 0.014253, loss_ce: 0.004114
2022-01-16 01:12:24,222 iteration 5378 : loss : 0.017398, loss_ce: 0.006128
2022-01-16 01:12:25,111 iteration 5379 : loss : 0.015563, loss_ce: 0.005685
2022-01-16 01:12:26,076 iteration 5380 : loss : 0.016113, loss_ce: 0.006799
2022-01-16 01:12:27,008 iteration 5381 : loss : 0.016065, loss_ce: 0.006953
2022-01-16 01:12:27,992 iteration 5382 : loss : 0.015469, loss_ce: 0.004257
2022-01-16 01:12:29,046 iteration 5383 : loss : 0.022847, loss_ce: 0.010901
2022-01-16 01:12:30,190 iteration 5384 : loss : 0.016767, loss_ce: 0.006128
2022-01-16 01:12:31,128 iteration 5385 : loss : 0.022058, loss_ce: 0.010296
2022-01-16 01:12:32,003 iteration 5386 : loss : 0.013764, loss_ce: 0.004786
2022-01-16 01:12:32,932 iteration 5387 : loss : 0.020184, loss_ce: 0.008476
2022-01-16 01:12:33,944 iteration 5388 : loss : 0.022982, loss_ce: 0.007200
2022-01-16 01:12:35,033 iteration 5389 : loss : 0.028067, loss_ce: 0.010807
 79%|██████████████████████▉      | 317/400 [1:33:28<24:27, 17.68s/it]2022-01-16 01:12:36,039 iteration 5390 : loss : 0.021359, loss_ce: 0.007132
2022-01-16 01:12:37,053 iteration 5391 : loss : 0.018668, loss_ce: 0.006749
2022-01-16 01:12:38,080 iteration 5392 : loss : 0.018029, loss_ce: 0.008779
2022-01-16 01:12:39,051 iteration 5393 : loss : 0.024984, loss_ce: 0.009012
2022-01-16 01:12:39,983 iteration 5394 : loss : 0.019878, loss_ce: 0.008799
2022-01-16 01:12:40,977 iteration 5395 : loss : 0.019164, loss_ce: 0.006046
2022-01-16 01:12:41,890 iteration 5396 : loss : 0.026878, loss_ce: 0.015200
2022-01-16 01:12:42,919 iteration 5397 : loss : 0.021371, loss_ce: 0.007146
2022-01-16 01:12:43,900 iteration 5398 : loss : 0.017047, loss_ce: 0.006028
2022-01-16 01:12:44,789 iteration 5399 : loss : 0.016957, loss_ce: 0.005033
2022-01-16 01:12:45,852 iteration 5400 : loss : 0.033210, loss_ce: 0.009481
2022-01-16 01:12:46,855 iteration 5401 : loss : 0.020587, loss_ce: 0.009528
2022-01-16 01:12:47,830 iteration 5402 : loss : 0.017409, loss_ce: 0.006217
2022-01-16 01:12:48,761 iteration 5403 : loss : 0.024619, loss_ce: 0.010123
2022-01-16 01:12:49,672 iteration 5404 : loss : 0.014961, loss_ce: 0.004188
2022-01-16 01:12:50,604 iteration 5405 : loss : 0.018787, loss_ce: 0.007662
2022-01-16 01:12:51,614 iteration 5406 : loss : 0.020108, loss_ce: 0.005506
 80%|███████████████████████      | 318/400 [1:33:44<23:42, 17.34s/it]2022-01-16 01:12:52,681 iteration 5407 : loss : 0.024491, loss_ce: 0.009627
2022-01-16 01:12:53,643 iteration 5408 : loss : 0.029706, loss_ce: 0.009525
2022-01-16 01:12:54,696 iteration 5409 : loss : 0.018657, loss_ce: 0.008115
2022-01-16 01:12:55,624 iteration 5410 : loss : 0.021088, loss_ce: 0.008419
2022-01-16 01:12:56,582 iteration 5411 : loss : 0.016893, loss_ce: 0.006448
2022-01-16 01:12:57,554 iteration 5412 : loss : 0.021027, loss_ce: 0.009860
2022-01-16 01:12:58,490 iteration 5413 : loss : 0.018892, loss_ce: 0.009487
2022-01-16 01:12:59,468 iteration 5414 : loss : 0.018397, loss_ce: 0.007401
2022-01-16 01:13:00,530 iteration 5415 : loss : 0.026516, loss_ce: 0.009810
2022-01-16 01:13:01,428 iteration 5416 : loss : 0.015630, loss_ce: 0.005084
2022-01-16 01:13:02,428 iteration 5417 : loss : 0.019357, loss_ce: 0.006180
2022-01-16 01:13:03,371 iteration 5418 : loss : 0.022867, loss_ce: 0.008608
2022-01-16 01:13:04,367 iteration 5419 : loss : 0.029925, loss_ce: 0.007311
2022-01-16 01:13:05,403 iteration 5420 : loss : 0.017319, loss_ce: 0.006107
2022-01-16 01:13:06,393 iteration 5421 : loss : 0.026008, loss_ce: 0.012277
2022-01-16 01:13:07,228 iteration 5422 : loss : 0.013341, loss_ce: 0.005445
2022-01-16 01:13:08,226 iteration 5423 : loss : 0.027938, loss_ce: 0.005648
 80%|███████████████████████▏     | 319/400 [1:34:01<23:07, 17.12s/it]2022-01-16 01:13:09,324 iteration 5424 : loss : 0.016073, loss_ce: 0.005481
2022-01-16 01:13:10,244 iteration 5425 : loss : 0.016584, loss_ce: 0.004515
2022-01-16 01:13:11,195 iteration 5426 : loss : 0.022960, loss_ce: 0.007876
2022-01-16 01:13:12,060 iteration 5427 : loss : 0.018122, loss_ce: 0.006803
2022-01-16 01:13:12,984 iteration 5428 : loss : 0.015533, loss_ce: 0.006125
2022-01-16 01:13:13,963 iteration 5429 : loss : 0.014501, loss_ce: 0.005354
2022-01-16 01:13:14,930 iteration 5430 : loss : 0.023748, loss_ce: 0.009899
2022-01-16 01:13:15,822 iteration 5431 : loss : 0.018486, loss_ce: 0.006342
2022-01-16 01:13:16,859 iteration 5432 : loss : 0.016576, loss_ce: 0.007549
2022-01-16 01:13:17,884 iteration 5433 : loss : 0.029721, loss_ce: 0.013916
2022-01-16 01:13:18,791 iteration 5434 : loss : 0.016464, loss_ce: 0.006597
2022-01-16 01:13:19,829 iteration 5435 : loss : 0.024057, loss_ce: 0.008969
2022-01-16 01:13:20,823 iteration 5436 : loss : 0.015974, loss_ce: 0.005989
2022-01-16 01:13:21,835 iteration 5437 : loss : 0.028130, loss_ce: 0.007457
2022-01-16 01:13:22,856 iteration 5438 : loss : 0.017210, loss_ce: 0.007707
2022-01-16 01:13:23,800 iteration 5439 : loss : 0.015842, loss_ce: 0.006944
2022-01-16 01:13:23,800 Training Data Eval:
2022-01-16 01:13:28,340   Average segmentation loss on training set: 0.0114
2022-01-16 01:13:28,340 Validation Data Eval:
2022-01-16 01:13:29,826   Average segmentation loss on validation set: 0.0741
2022-01-16 01:13:30,718 iteration 5440 : loss : 0.018429, loss_ce: 0.005920
 80%|███████████████████████▏     | 320/400 [1:34:23<24:58, 18.74s/it]2022-01-16 01:13:31,713 iteration 5441 : loss : 0.015089, loss_ce: 0.004931
2022-01-16 01:13:32,613 iteration 5442 : loss : 0.019423, loss_ce: 0.006775
2022-01-16 01:13:33,557 iteration 5443 : loss : 0.028892, loss_ce: 0.010498
2022-01-16 01:13:34,427 iteration 5444 : loss : 0.016374, loss_ce: 0.005133
2022-01-16 01:13:35,397 iteration 5445 : loss : 0.018806, loss_ce: 0.006735
2022-01-16 01:13:36,309 iteration 5446 : loss : 0.017038, loss_ce: 0.008044
2022-01-16 01:13:37,357 iteration 5447 : loss : 0.024153, loss_ce: 0.008229
2022-01-16 01:13:38,262 iteration 5448 : loss : 0.015327, loss_ce: 0.006792
2022-01-16 01:13:39,231 iteration 5449 : loss : 0.020721, loss_ce: 0.010953
2022-01-16 01:13:40,184 iteration 5450 : loss : 0.019887, loss_ce: 0.008201
2022-01-16 01:13:41,071 iteration 5451 : loss : 0.015808, loss_ce: 0.005176
2022-01-16 01:13:42,037 iteration 5452 : loss : 0.018676, loss_ce: 0.007010
2022-01-16 01:13:42,943 iteration 5453 : loss : 0.013824, loss_ce: 0.005459
2022-01-16 01:13:43,960 iteration 5454 : loss : 0.018602, loss_ce: 0.009780
2022-01-16 01:13:44,948 iteration 5455 : loss : 0.031134, loss_ce: 0.010812
2022-01-16 01:13:45,916 iteration 5456 : loss : 0.014383, loss_ce: 0.003341
2022-01-16 01:13:46,826 iteration 5457 : loss : 0.013326, loss_ce: 0.004126
 80%|███████████████████████▎     | 321/400 [1:34:39<23:38, 17.95s/it]2022-01-16 01:13:47,832 iteration 5458 : loss : 0.020636, loss_ce: 0.006764
2022-01-16 01:13:48,724 iteration 5459 : loss : 0.017113, loss_ce: 0.007683
2022-01-16 01:13:49,681 iteration 5460 : loss : 0.014033, loss_ce: 0.005498
2022-01-16 01:13:50,626 iteration 5461 : loss : 0.024098, loss_ce: 0.008298
2022-01-16 01:13:51,562 iteration 5462 : loss : 0.016850, loss_ce: 0.006287
2022-01-16 01:13:52,533 iteration 5463 : loss : 0.022942, loss_ce: 0.006555
2022-01-16 01:13:53,502 iteration 5464 : loss : 0.021288, loss_ce: 0.009463
2022-01-16 01:13:54,533 iteration 5465 : loss : 0.023941, loss_ce: 0.009007
2022-01-16 01:13:55,558 iteration 5466 : loss : 0.017075, loss_ce: 0.006580
2022-01-16 01:13:56,545 iteration 5467 : loss : 0.032219, loss_ce: 0.013816
2022-01-16 01:13:57,531 iteration 5468 : loss : 0.019834, loss_ce: 0.008824
2022-01-16 01:13:58,414 iteration 5469 : loss : 0.019386, loss_ce: 0.006516
2022-01-16 01:13:59,352 iteration 5470 : loss : 0.010460, loss_ce: 0.003594
2022-01-16 01:14:00,292 iteration 5471 : loss : 0.021949, loss_ce: 0.005361
2022-01-16 01:14:01,281 iteration 5472 : loss : 0.023830, loss_ce: 0.009433
2022-01-16 01:14:02,180 iteration 5473 : loss : 0.013642, loss_ce: 0.004873
2022-01-16 01:14:03,080 iteration 5474 : loss : 0.014175, loss_ce: 0.004536
 80%|███████████████████████▎     | 322/400 [1:34:56<22:40, 17.44s/it]2022-01-16 01:14:04,122 iteration 5475 : loss : 0.019045, loss_ce: 0.005567
2022-01-16 01:14:05,143 iteration 5476 : loss : 0.019106, loss_ce: 0.009070
2022-01-16 01:14:06,103 iteration 5477 : loss : 0.042480, loss_ce: 0.007220
2022-01-16 01:14:06,976 iteration 5478 : loss : 0.015496, loss_ce: 0.005063
2022-01-16 01:14:07,922 iteration 5479 : loss : 0.015806, loss_ce: 0.006462
2022-01-16 01:14:08,865 iteration 5480 : loss : 0.019835, loss_ce: 0.006817
2022-01-16 01:14:09,778 iteration 5481 : loss : 0.019998, loss_ce: 0.006756
2022-01-16 01:14:10,836 iteration 5482 : loss : 0.027858, loss_ce: 0.008237
2022-01-16 01:14:11,705 iteration 5483 : loss : 0.015696, loss_ce: 0.006211
2022-01-16 01:14:12,672 iteration 5484 : loss : 0.034561, loss_ce: 0.011346
2022-01-16 01:14:13,625 iteration 5485 : loss : 0.021842, loss_ce: 0.009047
2022-01-16 01:14:14,573 iteration 5486 : loss : 0.020127, loss_ce: 0.009881
2022-01-16 01:14:15,541 iteration 5487 : loss : 0.020633, loss_ce: 0.006932
2022-01-16 01:14:16,452 iteration 5488 : loss : 0.014991, loss_ce: 0.006753
2022-01-16 01:14:17,358 iteration 5489 : loss : 0.020060, loss_ce: 0.010202
2022-01-16 01:14:18,396 iteration 5490 : loss : 0.039553, loss_ce: 0.016279
2022-01-16 01:14:19,319 iteration 5491 : loss : 0.014951, loss_ce: 0.004540
 81%|███████████████████████▍     | 323/400 [1:35:12<21:55, 17.08s/it]2022-01-16 01:14:20,241 iteration 5492 : loss : 0.023349, loss_ce: 0.008405
2022-01-16 01:14:21,225 iteration 5493 : loss : 0.038623, loss_ce: 0.012061
2022-01-16 01:14:22,136 iteration 5494 : loss : 0.020004, loss_ce: 0.006227
2022-01-16 01:14:23,099 iteration 5495 : loss : 0.017509, loss_ce: 0.005988
2022-01-16 01:14:24,070 iteration 5496 : loss : 0.018038, loss_ce: 0.005688
2022-01-16 01:14:25,044 iteration 5497 : loss : 0.015011, loss_ce: 0.005887
2022-01-16 01:14:26,058 iteration 5498 : loss : 0.026184, loss_ce: 0.009116
2022-01-16 01:14:27,050 iteration 5499 : loss : 0.020353, loss_ce: 0.012351
2022-01-16 01:14:27,938 iteration 5500 : loss : 0.018386, loss_ce: 0.008062
2022-01-16 01:14:28,904 iteration 5501 : loss : 0.020820, loss_ce: 0.008444
2022-01-16 01:14:29,813 iteration 5502 : loss : 0.011645, loss_ce: 0.004927
2022-01-16 01:14:30,756 iteration 5503 : loss : 0.017799, loss_ce: 0.004628
2022-01-16 01:14:31,666 iteration 5504 : loss : 0.016035, loss_ce: 0.006089
2022-01-16 01:14:32,618 iteration 5505 : loss : 0.017157, loss_ce: 0.006502
2022-01-16 01:14:33,606 iteration 5506 : loss : 0.013527, loss_ce: 0.004947
2022-01-16 01:14:34,545 iteration 5507 : loss : 0.022975, loss_ce: 0.010185
2022-01-16 01:14:35,513 iteration 5508 : loss : 0.018090, loss_ce: 0.005909
 81%|███████████████████████▍     | 324/400 [1:35:28<21:18, 16.82s/it]2022-01-16 01:14:36,541 iteration 5509 : loss : 0.020624, loss_ce: 0.005732
2022-01-16 01:14:37,597 iteration 5510 : loss : 0.018133, loss_ce: 0.007043
2022-01-16 01:14:38,533 iteration 5511 : loss : 0.015549, loss_ce: 0.005907
2022-01-16 01:14:39,548 iteration 5512 : loss : 0.020969, loss_ce: 0.008411
2022-01-16 01:14:40,480 iteration 5513 : loss : 0.013693, loss_ce: 0.005897
2022-01-16 01:14:41,362 iteration 5514 : loss : 0.012428, loss_ce: 0.004097
2022-01-16 01:14:42,384 iteration 5515 : loss : 0.033059, loss_ce: 0.007121
2022-01-16 01:14:43,318 iteration 5516 : loss : 0.015099, loss_ce: 0.005933
2022-01-16 01:14:44,282 iteration 5517 : loss : 0.017526, loss_ce: 0.007369
2022-01-16 01:14:45,241 iteration 5518 : loss : 0.021903, loss_ce: 0.007259
2022-01-16 01:14:46,225 iteration 5519 : loss : 0.018641, loss_ce: 0.006852
2022-01-16 01:14:47,183 iteration 5520 : loss : 0.017074, loss_ce: 0.006694
2022-01-16 01:14:48,161 iteration 5521 : loss : 0.017095, loss_ce: 0.006169
2022-01-16 01:14:49,120 iteration 5522 : loss : 0.024661, loss_ce: 0.008625
2022-01-16 01:14:50,046 iteration 5523 : loss : 0.016825, loss_ce: 0.005103
2022-01-16 01:14:50,977 iteration 5524 : loss : 0.020350, loss_ce: 0.008172
2022-01-16 01:14:50,977 Training Data Eval:
2022-01-16 01:14:55,513   Average segmentation loss on training set: 0.0109
2022-01-16 01:14:55,513 Validation Data Eval:
2022-01-16 01:14:57,006   Average segmentation loss on validation set: 0.0916
2022-01-16 01:14:57,963 iteration 5525 : loss : 0.021368, loss_ce: 0.011694
 81%|███████████████████████▌     | 325/400 [1:35:51<23:07, 18.51s/it]2022-01-16 01:14:59,044 iteration 5526 : loss : 0.034489, loss_ce: 0.011317
2022-01-16 01:15:00,019 iteration 5527 : loss : 0.018310, loss_ce: 0.007998
2022-01-16 01:15:00,973 iteration 5528 : loss : 0.019606, loss_ce: 0.007740
2022-01-16 01:15:01,967 iteration 5529 : loss : 0.021292, loss_ce: 0.009750
2022-01-16 01:15:02,865 iteration 5530 : loss : 0.014168, loss_ce: 0.006172
2022-01-16 01:15:03,805 iteration 5531 : loss : 0.019402, loss_ce: 0.008195
2022-01-16 01:15:04,716 iteration 5532 : loss : 0.012334, loss_ce: 0.005277
2022-01-16 01:15:05,738 iteration 5533 : loss : 0.016953, loss_ce: 0.004038
2022-01-16 01:15:06,689 iteration 5534 : loss : 0.013665, loss_ce: 0.005131
2022-01-16 01:15:07,713 iteration 5535 : loss : 0.017168, loss_ce: 0.006909
2022-01-16 01:15:08,776 iteration 5536 : loss : 0.020110, loss_ce: 0.009036
2022-01-16 01:15:09,779 iteration 5537 : loss : 0.016312, loss_ce: 0.005299
2022-01-16 01:15:10,753 iteration 5538 : loss : 0.021538, loss_ce: 0.008767
2022-01-16 01:15:11,823 iteration 5539 : loss : 0.020576, loss_ce: 0.004277
2022-01-16 01:15:12,750 iteration 5540 : loss : 0.021577, loss_ce: 0.009354
2022-01-16 01:15:13,722 iteration 5541 : loss : 0.018168, loss_ce: 0.005571
2022-01-16 01:15:14,655 iteration 5542 : loss : 0.013321, loss_ce: 0.004997
 82%|███████████████████████▋     | 326/400 [1:36:07<22:09, 17.96s/it]2022-01-16 01:15:15,711 iteration 5543 : loss : 0.018989, loss_ce: 0.006301
2022-01-16 01:15:16,680 iteration 5544 : loss : 0.014373, loss_ce: 0.006334
2022-01-16 01:15:17,612 iteration 5545 : loss : 0.020055, loss_ce: 0.008705
2022-01-16 01:15:18,519 iteration 5546 : loss : 0.018356, loss_ce: 0.006275
2022-01-16 01:15:19,475 iteration 5547 : loss : 0.015955, loss_ce: 0.005781
2022-01-16 01:15:20,493 iteration 5548 : loss : 0.029661, loss_ce: 0.009571
2022-01-16 01:15:21,384 iteration 5549 : loss : 0.017143, loss_ce: 0.007648
2022-01-16 01:15:22,317 iteration 5550 : loss : 0.018700, loss_ce: 0.006679
2022-01-16 01:15:23,276 iteration 5551 : loss : 0.013618, loss_ce: 0.005784
2022-01-16 01:15:24,167 iteration 5552 : loss : 0.012841, loss_ce: 0.005164
2022-01-16 01:15:25,141 iteration 5553 : loss : 0.032381, loss_ce: 0.013659
2022-01-16 01:15:26,152 iteration 5554 : loss : 0.014590, loss_ce: 0.004736
2022-01-16 01:15:27,160 iteration 5555 : loss : 0.019007, loss_ce: 0.005391
2022-01-16 01:15:28,041 iteration 5556 : loss : 0.017924, loss_ce: 0.007092
2022-01-16 01:15:29,062 iteration 5557 : loss : 0.024325, loss_ce: 0.006535
2022-01-16 01:15:30,033 iteration 5558 : loss : 0.016303, loss_ce: 0.005881
2022-01-16 01:15:30,891 iteration 5559 : loss : 0.012621, loss_ce: 0.005230
 82%|███████████████████████▋     | 327/400 [1:36:23<21:13, 17.44s/it]2022-01-16 01:15:32,104 iteration 5560 : loss : 0.039264, loss_ce: 0.016220
2022-01-16 01:15:33,047 iteration 5561 : loss : 0.019653, loss_ce: 0.006672
2022-01-16 01:15:33,995 iteration 5562 : loss : 0.022284, loss_ce: 0.007128
2022-01-16 01:15:34,943 iteration 5563 : loss : 0.014163, loss_ce: 0.006204
2022-01-16 01:15:36,007 iteration 5564 : loss : 0.020464, loss_ce: 0.006537
2022-01-16 01:15:36,980 iteration 5565 : loss : 0.018405, loss_ce: 0.007168
2022-01-16 01:15:37,994 iteration 5566 : loss : 0.014676, loss_ce: 0.006054
2022-01-16 01:15:39,065 iteration 5567 : loss : 0.019198, loss_ce: 0.009173
2022-01-16 01:15:40,029 iteration 5568 : loss : 0.021863, loss_ce: 0.007068
2022-01-16 01:15:41,044 iteration 5569 : loss : 0.018058, loss_ce: 0.008042
2022-01-16 01:15:42,031 iteration 5570 : loss : 0.017854, loss_ce: 0.006654
2022-01-16 01:15:43,045 iteration 5571 : loss : 0.020893, loss_ce: 0.009397
2022-01-16 01:15:44,012 iteration 5572 : loss : 0.012613, loss_ce: 0.004426
2022-01-16 01:15:44,961 iteration 5573 : loss : 0.014879, loss_ce: 0.004832
2022-01-16 01:15:46,040 iteration 5574 : loss : 0.024570, loss_ce: 0.008037
2022-01-16 01:15:46,885 iteration 5575 : loss : 0.011862, loss_ce: 0.005179
2022-01-16 01:15:47,711 iteration 5576 : loss : 0.014874, loss_ce: 0.004536
 82%|███████████████████████▊     | 328/400 [1:36:40<20:42, 17.25s/it]2022-01-16 01:15:48,723 iteration 5577 : loss : 0.014636, loss_ce: 0.004883
2022-01-16 01:15:49,644 iteration 5578 : loss : 0.023907, loss_ce: 0.006070
2022-01-16 01:15:50,592 iteration 5579 : loss : 0.014728, loss_ce: 0.004285
2022-01-16 01:15:51,598 iteration 5580 : loss : 0.013762, loss_ce: 0.004804
2022-01-16 01:15:52,535 iteration 5581 : loss : 0.022057, loss_ce: 0.009501
2022-01-16 01:15:53,540 iteration 5582 : loss : 0.020680, loss_ce: 0.005939
2022-01-16 01:15:54,478 iteration 5583 : loss : 0.032035, loss_ce: 0.008087
2022-01-16 01:15:55,537 iteration 5584 : loss : 0.024297, loss_ce: 0.009516
2022-01-16 01:15:56,477 iteration 5585 : loss : 0.019005, loss_ce: 0.006790
2022-01-16 01:15:57,434 iteration 5586 : loss : 0.016603, loss_ce: 0.007348
2022-01-16 01:15:58,394 iteration 5587 : loss : 0.019225, loss_ce: 0.008485
2022-01-16 01:15:59,439 iteration 5588 : loss : 0.023498, loss_ce: 0.008249
2022-01-16 01:16:00,459 iteration 5589 : loss : 0.022809, loss_ce: 0.008807
2022-01-16 01:16:01,431 iteration 5590 : loss : 0.021361, loss_ce: 0.009570
2022-01-16 01:16:02,397 iteration 5591 : loss : 0.017493, loss_ce: 0.008681
2022-01-16 01:16:03,345 iteration 5592 : loss : 0.016151, loss_ce: 0.004945
2022-01-16 01:16:04,287 iteration 5593 : loss : 0.015065, loss_ce: 0.008905
 82%|███████████████████████▊     | 329/400 [1:36:57<20:10, 17.05s/it]2022-01-16 01:16:05,344 iteration 5594 : loss : 0.013388, loss_ce: 0.004497
2022-01-16 01:16:06,277 iteration 5595 : loss : 0.016218, loss_ce: 0.007321
2022-01-16 01:16:07,211 iteration 5596 : loss : 0.012558, loss_ce: 0.003635
2022-01-16 01:16:08,196 iteration 5597 : loss : 0.016285, loss_ce: 0.005080
2022-01-16 01:16:09,242 iteration 5598 : loss : 0.016617, loss_ce: 0.006969
2022-01-16 01:16:10,255 iteration 5599 : loss : 0.015634, loss_ce: 0.005691
2022-01-16 01:16:11,264 iteration 5600 : loss : 0.014839, loss_ce: 0.005926
2022-01-16 01:16:12,273 iteration 5601 : loss : 0.020136, loss_ce: 0.006146
2022-01-16 01:16:13,195 iteration 5602 : loss : 0.019746, loss_ce: 0.005110
2022-01-16 01:16:14,216 iteration 5603 : loss : 0.023305, loss_ce: 0.011088
2022-01-16 01:16:15,145 iteration 5604 : loss : 0.017013, loss_ce: 0.007952
2022-01-16 01:16:16,076 iteration 5605 : loss : 0.016567, loss_ce: 0.006357
2022-01-16 01:16:17,115 iteration 5606 : loss : 0.017729, loss_ce: 0.006209
2022-01-16 01:16:18,082 iteration 5607 : loss : 0.020832, loss_ce: 0.007357
2022-01-16 01:16:19,182 iteration 5608 : loss : 0.036610, loss_ce: 0.019165
2022-01-16 01:16:20,113 iteration 5609 : loss : 0.016969, loss_ce: 0.006823
2022-01-16 01:16:20,113 Training Data Eval:
2022-01-16 01:16:24,651   Average segmentation loss on training set: 0.0102
2022-01-16 01:16:24,651 Validation Data Eval:
2022-01-16 01:16:26,135   Average segmentation loss on validation set: 0.0858
2022-01-16 01:16:27,120 iteration 5610 : loss : 0.021994, loss_ce: 0.008509
 82%|███████████████████████▉     | 330/400 [1:37:20<21:54, 18.78s/it]2022-01-16 01:16:28,191 iteration 5611 : loss : 0.015586, loss_ce: 0.006659
2022-01-16 01:16:29,161 iteration 5612 : loss : 0.017634, loss_ce: 0.005504
2022-01-16 01:16:30,113 iteration 5613 : loss : 0.015959, loss_ce: 0.005992
2022-01-16 01:16:31,063 iteration 5614 : loss : 0.018305, loss_ce: 0.006289
2022-01-16 01:16:32,052 iteration 5615 : loss : 0.019440, loss_ce: 0.007774
2022-01-16 01:16:33,063 iteration 5616 : loss : 0.019421, loss_ce: 0.007824
2022-01-16 01:16:34,031 iteration 5617 : loss : 0.013568, loss_ce: 0.005077
2022-01-16 01:16:34,935 iteration 5618 : loss : 0.016475, loss_ce: 0.007279
2022-01-16 01:16:35,942 iteration 5619 : loss : 0.027428, loss_ce: 0.010388
2022-01-16 01:16:36,964 iteration 5620 : loss : 0.018026, loss_ce: 0.005237
2022-01-16 01:16:37,891 iteration 5621 : loss : 0.018691, loss_ce: 0.006620
2022-01-16 01:16:38,948 iteration 5622 : loss : 0.018512, loss_ce: 0.007597
2022-01-16 01:16:39,867 iteration 5623 : loss : 0.024254, loss_ce: 0.007069
2022-01-16 01:16:40,853 iteration 5624 : loss : 0.018295, loss_ce: 0.008345
2022-01-16 01:16:41,855 iteration 5625 : loss : 0.029379, loss_ce: 0.012368
2022-01-16 01:16:42,818 iteration 5626 : loss : 0.017288, loss_ce: 0.006765
2022-01-16 01:16:43,775 iteration 5627 : loss : 0.019450, loss_ce: 0.006633
 83%|███████████████████████▉     | 331/400 [1:37:36<20:52, 18.15s/it]2022-01-16 01:16:44,690 iteration 5628 : loss : 0.014778, loss_ce: 0.005256
2022-01-16 01:16:45,678 iteration 5629 : loss : 0.026691, loss_ce: 0.012324
2022-01-16 01:16:46,639 iteration 5630 : loss : 0.016569, loss_ce: 0.006834
2022-01-16 01:16:47,718 iteration 5631 : loss : 0.022925, loss_ce: 0.010767
2022-01-16 01:16:48,593 iteration 5632 : loss : 0.017792, loss_ce: 0.007939
2022-01-16 01:16:49,608 iteration 5633 : loss : 0.023543, loss_ce: 0.009015
2022-01-16 01:16:50,523 iteration 5634 : loss : 0.017350, loss_ce: 0.006344
2022-01-16 01:16:51,514 iteration 5635 : loss : 0.020949, loss_ce: 0.005792
2022-01-16 01:16:52,414 iteration 5636 : loss : 0.013153, loss_ce: 0.005813
2022-01-16 01:16:53,393 iteration 5637 : loss : 0.016428, loss_ce: 0.006709
2022-01-16 01:16:54,232 iteration 5638 : loss : 0.016269, loss_ce: 0.004908
2022-01-16 01:16:55,129 iteration 5639 : loss : 0.021297, loss_ce: 0.006260
2022-01-16 01:16:56,065 iteration 5640 : loss : 0.013582, loss_ce: 0.006692
2022-01-16 01:16:57,061 iteration 5641 : loss : 0.013640, loss_ce: 0.007220
2022-01-16 01:16:57,994 iteration 5642 : loss : 0.031841, loss_ce: 0.005845
2022-01-16 01:16:59,005 iteration 5643 : loss : 0.014727, loss_ce: 0.004218
2022-01-16 01:16:59,998 iteration 5644 : loss : 0.019635, loss_ce: 0.007341
 83%|████████████████████████     | 332/400 [1:37:53<19:54, 17.57s/it]2022-01-16 01:17:01,143 iteration 5645 : loss : 0.026482, loss_ce: 0.012988
2022-01-16 01:17:02,070 iteration 5646 : loss : 0.021402, loss_ce: 0.006868
2022-01-16 01:17:03,030 iteration 5647 : loss : 0.018299, loss_ce: 0.008266
2022-01-16 01:17:04,039 iteration 5648 : loss : 0.022961, loss_ce: 0.007020
2022-01-16 01:17:05,052 iteration 5649 : loss : 0.016666, loss_ce: 0.007316
2022-01-16 01:17:06,031 iteration 5650 : loss : 0.019789, loss_ce: 0.008061
2022-01-16 01:17:06,988 iteration 5651 : loss : 0.017519, loss_ce: 0.008001
2022-01-16 01:17:07,865 iteration 5652 : loss : 0.013243, loss_ce: 0.004759
2022-01-16 01:17:08,802 iteration 5653 : loss : 0.015609, loss_ce: 0.005737
2022-01-16 01:17:09,699 iteration 5654 : loss : 0.014824, loss_ce: 0.004294
2022-01-16 01:17:10,682 iteration 5655 : loss : 0.034502, loss_ce: 0.012885
2022-01-16 01:17:11,636 iteration 5656 : loss : 0.015912, loss_ce: 0.005427
2022-01-16 01:17:12,594 iteration 5657 : loss : 0.020860, loss_ce: 0.008835
2022-01-16 01:17:13,553 iteration 5658 : loss : 0.021097, loss_ce: 0.009613
2022-01-16 01:17:14,484 iteration 5659 : loss : 0.016527, loss_ce: 0.004414
2022-01-16 01:17:15,376 iteration 5660 : loss : 0.016715, loss_ce: 0.006767
2022-01-16 01:17:16,434 iteration 5661 : loss : 0.018532, loss_ce: 0.006158
 83%|████████████████████████▏    | 333/400 [1:38:09<19:14, 17.23s/it]2022-01-16 01:17:17,455 iteration 5662 : loss : 0.024274, loss_ce: 0.006488
2022-01-16 01:17:18,416 iteration 5663 : loss : 0.022581, loss_ce: 0.011209
2022-01-16 01:17:19,403 iteration 5664 : loss : 0.021699, loss_ce: 0.006323
2022-01-16 01:17:20,269 iteration 5665 : loss : 0.018164, loss_ce: 0.006372
2022-01-16 01:17:21,253 iteration 5666 : loss : 0.016234, loss_ce: 0.005508
2022-01-16 01:17:22,263 iteration 5667 : loss : 0.022395, loss_ce: 0.008437
2022-01-16 01:17:23,220 iteration 5668 : loss : 0.022160, loss_ce: 0.010295
2022-01-16 01:17:24,232 iteration 5669 : loss : 0.018164, loss_ce: 0.009208
2022-01-16 01:17:25,217 iteration 5670 : loss : 0.014120, loss_ce: 0.004849
2022-01-16 01:17:26,199 iteration 5671 : loss : 0.016652, loss_ce: 0.006240
2022-01-16 01:17:27,157 iteration 5672 : loss : 0.018327, loss_ce: 0.004950
2022-01-16 01:17:28,079 iteration 5673 : loss : 0.017841, loss_ce: 0.005879
2022-01-16 01:17:29,121 iteration 5674 : loss : 0.017175, loss_ce: 0.009101
2022-01-16 01:17:30,052 iteration 5675 : loss : 0.016550, loss_ce: 0.006860
2022-01-16 01:17:31,080 iteration 5676 : loss : 0.020271, loss_ce: 0.007027
2022-01-16 01:17:32,094 iteration 5677 : loss : 0.017563, loss_ce: 0.009455
2022-01-16 01:17:33,077 iteration 5678 : loss : 0.027334, loss_ce: 0.007987
 84%|████████████████████████▏    | 334/400 [1:38:26<18:45, 17.05s/it]2022-01-16 01:17:34,114 iteration 5679 : loss : 0.024542, loss_ce: 0.010993
2022-01-16 01:17:34,965 iteration 5680 : loss : 0.013503, loss_ce: 0.003326
2022-01-16 01:17:35,976 iteration 5681 : loss : 0.021268, loss_ce: 0.006464
2022-01-16 01:17:36,988 iteration 5682 : loss : 0.018219, loss_ce: 0.007416
2022-01-16 01:17:37,918 iteration 5683 : loss : 0.012964, loss_ce: 0.004410
2022-01-16 01:17:38,837 iteration 5684 : loss : 0.013379, loss_ce: 0.007111
2022-01-16 01:17:39,820 iteration 5685 : loss : 0.017230, loss_ce: 0.007789
2022-01-16 01:17:40,756 iteration 5686 : loss : 0.015585, loss_ce: 0.006272
2022-01-16 01:17:41,711 iteration 5687 : loss : 0.013286, loss_ce: 0.005295
2022-01-16 01:17:42,774 iteration 5688 : loss : 0.018060, loss_ce: 0.006800
2022-01-16 01:17:43,746 iteration 5689 : loss : 0.022934, loss_ce: 0.006680
2022-01-16 01:17:44,730 iteration 5690 : loss : 0.015494, loss_ce: 0.006347
2022-01-16 01:17:45,733 iteration 5691 : loss : 0.020039, loss_ce: 0.010447
2022-01-16 01:17:46,728 iteration 5692 : loss : 0.018105, loss_ce: 0.007672
2022-01-16 01:17:47,698 iteration 5693 : loss : 0.021714, loss_ce: 0.005947
2022-01-16 01:17:48,641 iteration 5694 : loss : 0.016590, loss_ce: 0.007949
2022-01-16 01:17:48,642 Training Data Eval:
2022-01-16 01:17:53,173   Average segmentation loss on training set: 0.0099
2022-01-16 01:17:53,173 Validation Data Eval:
2022-01-16 01:17:54,661   Average segmentation loss on validation set: 0.0787
2022-01-16 01:17:55,559 iteration 5695 : loss : 0.013647, loss_ce: 0.004746
 84%|████████████████████████▎    | 335/400 [1:38:48<20:14, 18.68s/it]2022-01-16 01:17:56,525 iteration 5696 : loss : 0.013083, loss_ce: 0.006572
2022-01-16 01:17:57,422 iteration 5697 : loss : 0.014469, loss_ce: 0.006439
2022-01-16 01:17:58,435 iteration 5698 : loss : 0.022594, loss_ce: 0.008618
2022-01-16 01:17:59,313 iteration 5699 : loss : 0.013534, loss_ce: 0.005938
2022-01-16 01:18:00,245 iteration 5700 : loss : 0.013633, loss_ce: 0.004637
2022-01-16 01:18:01,136 iteration 5701 : loss : 0.015772, loss_ce: 0.007048
2022-01-16 01:18:02,201 iteration 5702 : loss : 0.029620, loss_ce: 0.012753
2022-01-16 01:18:03,195 iteration 5703 : loss : 0.019668, loss_ce: 0.008214
2022-01-16 01:18:04,171 iteration 5704 : loss : 0.019878, loss_ce: 0.007279
2022-01-16 01:18:05,158 iteration 5705 : loss : 0.019485, loss_ce: 0.005663
2022-01-16 01:18:06,025 iteration 5706 : loss : 0.013701, loss_ce: 0.005244
2022-01-16 01:18:06,958 iteration 5707 : loss : 0.016470, loss_ce: 0.005382
2022-01-16 01:18:07,860 iteration 5708 : loss : 0.019283, loss_ce: 0.006535
2022-01-16 01:18:08,823 iteration 5709 : loss : 0.024643, loss_ce: 0.007815
2022-01-16 01:18:09,776 iteration 5710 : loss : 0.017799, loss_ce: 0.005858
2022-01-16 01:18:10,657 iteration 5711 : loss : 0.014325, loss_ce: 0.004574
2022-01-16 01:18:11,629 iteration 5712 : loss : 0.018562, loss_ce: 0.007943
 84%|████████████████████████▎    | 336/400 [1:39:04<19:05, 17.90s/it]2022-01-16 01:18:12,701 iteration 5713 : loss : 0.020571, loss_ce: 0.006612
2022-01-16 01:18:13,709 iteration 5714 : loss : 0.017397, loss_ce: 0.006539
2022-01-16 01:18:14,738 iteration 5715 : loss : 0.013868, loss_ce: 0.005451
2022-01-16 01:18:15,672 iteration 5716 : loss : 0.015726, loss_ce: 0.006720
2022-01-16 01:18:16,731 iteration 5717 : loss : 0.023751, loss_ce: 0.010272
2022-01-16 01:18:17,636 iteration 5718 : loss : 0.017883, loss_ce: 0.005860
2022-01-16 01:18:18,538 iteration 5719 : loss : 0.014756, loss_ce: 0.005863
2022-01-16 01:18:19,551 iteration 5720 : loss : 0.018110, loss_ce: 0.007139
2022-01-16 01:18:20,527 iteration 5721 : loss : 0.024581, loss_ce: 0.013121
2022-01-16 01:18:21,482 iteration 5722 : loss : 0.015780, loss_ce: 0.006805
2022-01-16 01:18:22,456 iteration 5723 : loss : 0.016192, loss_ce: 0.005499
2022-01-16 01:18:23,464 iteration 5724 : loss : 0.015260, loss_ce: 0.005005
2022-01-16 01:18:24,434 iteration 5725 : loss : 0.024714, loss_ce: 0.009238
2022-01-16 01:18:25,340 iteration 5726 : loss : 0.022761, loss_ce: 0.005051
2022-01-16 01:18:26,316 iteration 5727 : loss : 0.017651, loss_ce: 0.005315
2022-01-16 01:18:27,251 iteration 5728 : loss : 0.022746, loss_ce: 0.007246
2022-01-16 01:18:28,284 iteration 5729 : loss : 0.019695, loss_ce: 0.008066
 84%|████████████████████████▍    | 337/400 [1:39:21<18:24, 17.53s/it]2022-01-16 01:18:29,257 iteration 5730 : loss : 0.015998, loss_ce: 0.007602
2022-01-16 01:18:30,271 iteration 5731 : loss : 0.018120, loss_ce: 0.008442
2022-01-16 01:18:31,181 iteration 5732 : loss : 0.014320, loss_ce: 0.005435
2022-01-16 01:18:32,207 iteration 5733 : loss : 0.028732, loss_ce: 0.007558
2022-01-16 01:18:33,223 iteration 5734 : loss : 0.021878, loss_ce: 0.009951
2022-01-16 01:18:34,154 iteration 5735 : loss : 0.020078, loss_ce: 0.006800
2022-01-16 01:18:35,078 iteration 5736 : loss : 0.023659, loss_ce: 0.009569
2022-01-16 01:18:36,117 iteration 5737 : loss : 0.026665, loss_ce: 0.009043
2022-01-16 01:18:37,040 iteration 5738 : loss : 0.014053, loss_ce: 0.004808
2022-01-16 01:18:37,958 iteration 5739 : loss : 0.014701, loss_ce: 0.005712
2022-01-16 01:18:38,908 iteration 5740 : loss : 0.025539, loss_ce: 0.009637
2022-01-16 01:18:39,865 iteration 5741 : loss : 0.021697, loss_ce: 0.009168
2022-01-16 01:18:40,844 iteration 5742 : loss : 0.018568, loss_ce: 0.003768
2022-01-16 01:18:41,835 iteration 5743 : loss : 0.013947, loss_ce: 0.006059
2022-01-16 01:18:42,857 iteration 5744 : loss : 0.021422, loss_ce: 0.009781
2022-01-16 01:18:43,883 iteration 5745 : loss : 0.016648, loss_ce: 0.006712
2022-01-16 01:18:44,803 iteration 5746 : loss : 0.019821, loss_ce: 0.005101
 84%|████████████████████████▌    | 338/400 [1:39:37<17:47, 17.22s/it]2022-01-16 01:18:45,832 iteration 5747 : loss : 0.017428, loss_ce: 0.006417
2022-01-16 01:18:46,814 iteration 5748 : loss : 0.019620, loss_ce: 0.007061
2022-01-16 01:18:47,778 iteration 5749 : loss : 0.019509, loss_ce: 0.008481
2022-01-16 01:18:48,740 iteration 5750 : loss : 0.018724, loss_ce: 0.006511
2022-01-16 01:18:49,635 iteration 5751 : loss : 0.016678, loss_ce: 0.005583
2022-01-16 01:18:50,567 iteration 5752 : loss : 0.016577, loss_ce: 0.004787
2022-01-16 01:18:51,575 iteration 5753 : loss : 0.013869, loss_ce: 0.005134
2022-01-16 01:18:52,599 iteration 5754 : loss : 0.018686, loss_ce: 0.006248
2022-01-16 01:18:53,562 iteration 5755 : loss : 0.012200, loss_ce: 0.004508
2022-01-16 01:18:54,489 iteration 5756 : loss : 0.014614, loss_ce: 0.004874
2022-01-16 01:18:55,328 iteration 5757 : loss : 0.014951, loss_ce: 0.005956
2022-01-16 01:18:56,344 iteration 5758 : loss : 0.023491, loss_ce: 0.009751
2022-01-16 01:18:57,360 iteration 5759 : loss : 0.013596, loss_ce: 0.005062
2022-01-16 01:18:58,421 iteration 5760 : loss : 0.019596, loss_ce: 0.009703
2022-01-16 01:18:59,499 iteration 5761 : loss : 0.032506, loss_ce: 0.014865
2022-01-16 01:19:00,404 iteration 5762 : loss : 0.012656, loss_ce: 0.005336
2022-01-16 01:19:01,415 iteration 5763 : loss : 0.012604, loss_ce: 0.004956
 85%|████████████████████████▌    | 339/400 [1:39:54<17:19, 17.04s/it]2022-01-16 01:19:02,452 iteration 5764 : loss : 0.015897, loss_ce: 0.005285
2022-01-16 01:19:03,488 iteration 5765 : loss : 0.039995, loss_ce: 0.009543
2022-01-16 01:19:04,479 iteration 5766 : loss : 0.025422, loss_ce: 0.013708
2022-01-16 01:19:05,442 iteration 5767 : loss : 0.014811, loss_ce: 0.007502
2022-01-16 01:19:06,521 iteration 5768 : loss : 0.015348, loss_ce: 0.005629
2022-01-16 01:19:07,543 iteration 5769 : loss : 0.020892, loss_ce: 0.006867
2022-01-16 01:19:08,464 iteration 5770 : loss : 0.013539, loss_ce: 0.004912
2022-01-16 01:19:09,453 iteration 5771 : loss : 0.028072, loss_ce: 0.010512
2022-01-16 01:19:10,410 iteration 5772 : loss : 0.021011, loss_ce: 0.006913
2022-01-16 01:19:11,293 iteration 5773 : loss : 0.013187, loss_ce: 0.004618
2022-01-16 01:19:12,161 iteration 5774 : loss : 0.016608, loss_ce: 0.004444
2022-01-16 01:19:13,137 iteration 5775 : loss : 0.014107, loss_ce: 0.005561
2022-01-16 01:19:14,182 iteration 5776 : loss : 0.025135, loss_ce: 0.012621
2022-01-16 01:19:15,051 iteration 5777 : loss : 0.017781, loss_ce: 0.007844
2022-01-16 01:19:15,981 iteration 5778 : loss : 0.020858, loss_ce: 0.007565
2022-01-16 01:19:16,924 iteration 5779 : loss : 0.011610, loss_ce: 0.003929
2022-01-16 01:19:16,924 Training Data Eval:
2022-01-16 01:19:21,463   Average segmentation loss on training set: 0.0100
2022-01-16 01:19:21,463 Validation Data Eval:
2022-01-16 01:19:22,951   Average segmentation loss on validation set: 0.0766
2022-01-16 01:19:23,891 iteration 5780 : loss : 0.037272, loss_ce: 0.011309
 85%|████████████████████████▋    | 340/400 [1:40:16<18:40, 18.67s/it]2022-01-16 01:19:24,876 iteration 5781 : loss : 0.025002, loss_ce: 0.008660
2022-01-16 01:19:25,903 iteration 5782 : loss : 0.023729, loss_ce: 0.009053
2022-01-16 01:19:26,861 iteration 5783 : loss : 0.018246, loss_ce: 0.006597
2022-01-16 01:19:27,848 iteration 5784 : loss : 0.017287, loss_ce: 0.008688
2022-01-16 01:19:28,761 iteration 5785 : loss : 0.012333, loss_ce: 0.004294
2022-01-16 01:19:29,684 iteration 5786 : loss : 0.016573, loss_ce: 0.007011
2022-01-16 01:19:30,602 iteration 5787 : loss : 0.015240, loss_ce: 0.005700
2022-01-16 01:19:31,705 iteration 5788 : loss : 0.017327, loss_ce: 0.006673
2022-01-16 01:19:32,686 iteration 5789 : loss : 0.018641, loss_ce: 0.008188
2022-01-16 01:19:33,656 iteration 5790 : loss : 0.015468, loss_ce: 0.004983
2022-01-16 01:19:34,569 iteration 5791 : loss : 0.015347, loss_ce: 0.005463
2022-01-16 01:19:35,564 iteration 5792 : loss : 0.020922, loss_ce: 0.006896
2022-01-16 01:19:36,655 iteration 5793 : loss : 0.017862, loss_ce: 0.006666
2022-01-16 01:19:37,641 iteration 5794 : loss : 0.017002, loss_ce: 0.006568
2022-01-16 01:19:38,599 iteration 5795 : loss : 0.015552, loss_ce: 0.005245
2022-01-16 01:19:39,508 iteration 5796 : loss : 0.014074, loss_ce: 0.003820
2022-01-16 01:19:40,496 iteration 5797 : loss : 0.022075, loss_ce: 0.008844
 85%|████████████████████████▋    | 341/400 [1:40:33<17:44, 18.05s/it]2022-01-16 01:19:41,564 iteration 5798 : loss : 0.019579, loss_ce: 0.008208
2022-01-16 01:19:42,545 iteration 5799 : loss : 0.015746, loss_ce: 0.005883
2022-01-16 01:19:43,500 iteration 5800 : loss : 0.012863, loss_ce: 0.005331
2022-01-16 01:19:44,453 iteration 5801 : loss : 0.017382, loss_ce: 0.005527
2022-01-16 01:19:45,343 iteration 5802 : loss : 0.017704, loss_ce: 0.006191
2022-01-16 01:19:46,266 iteration 5803 : loss : 0.013407, loss_ce: 0.005950
2022-01-16 01:19:47,225 iteration 5804 : loss : 0.018131, loss_ce: 0.006458
2022-01-16 01:19:48,284 iteration 5805 : loss : 0.015652, loss_ce: 0.005048
2022-01-16 01:19:49,231 iteration 5806 : loss : 0.019897, loss_ce: 0.005509
2022-01-16 01:19:50,275 iteration 5807 : loss : 0.017588, loss_ce: 0.006604
2022-01-16 01:19:51,267 iteration 5808 : loss : 0.020111, loss_ce: 0.009244
2022-01-16 01:19:52,165 iteration 5809 : loss : 0.010281, loss_ce: 0.002552
2022-01-16 01:19:53,082 iteration 5810 : loss : 0.015718, loss_ce: 0.005176
2022-01-16 01:19:53,963 iteration 5811 : loss : 0.011151, loss_ce: 0.003212
2022-01-16 01:19:54,922 iteration 5812 : loss : 0.016324, loss_ce: 0.005577
2022-01-16 01:19:55,805 iteration 5813 : loss : 0.015744, loss_ce: 0.007456
2022-01-16 01:19:56,796 iteration 5814 : loss : 0.016168, loss_ce: 0.006789
 86%|████████████████████████▊    | 342/400 [1:40:49<16:56, 17.53s/it]2022-01-16 01:19:57,751 iteration 5815 : loss : 0.012837, loss_ce: 0.004315
2022-01-16 01:19:58,684 iteration 5816 : loss : 0.012602, loss_ce: 0.005560
2022-01-16 01:19:59,603 iteration 5817 : loss : 0.013084, loss_ce: 0.004854
2022-01-16 01:20:00,455 iteration 5818 : loss : 0.015290, loss_ce: 0.006121
2022-01-16 01:20:01,470 iteration 5819 : loss : 0.019696, loss_ce: 0.006211
2022-01-16 01:20:02,517 iteration 5820 : loss : 0.017726, loss_ce: 0.008041
2022-01-16 01:20:03,400 iteration 5821 : loss : 0.014295, loss_ce: 0.005017
2022-01-16 01:20:04,312 iteration 5822 : loss : 0.012774, loss_ce: 0.005714
2022-01-16 01:20:05,379 iteration 5823 : loss : 0.020491, loss_ce: 0.008354
2022-01-16 01:20:06,338 iteration 5824 : loss : 0.015471, loss_ce: 0.004768
2022-01-16 01:20:07,343 iteration 5825 : loss : 0.025424, loss_ce: 0.008566
2022-01-16 01:20:08,349 iteration 5826 : loss : 0.018030, loss_ce: 0.004192
2022-01-16 01:20:09,311 iteration 5827 : loss : 0.030679, loss_ce: 0.012081
2022-01-16 01:20:10,382 iteration 5828 : loss : 0.021267, loss_ce: 0.008144
2022-01-16 01:20:11,339 iteration 5829 : loss : 0.014794, loss_ce: 0.006163
2022-01-16 01:20:12,259 iteration 5830 : loss : 0.023589, loss_ce: 0.008888
2022-01-16 01:20:13,198 iteration 5831 : loss : 0.016126, loss_ce: 0.005661
 86%|████████████████████████▊    | 343/400 [1:41:06<16:19, 17.19s/it]2022-01-16 01:20:14,219 iteration 5832 : loss : 0.012953, loss_ce: 0.003846
2022-01-16 01:20:15,220 iteration 5833 : loss : 0.020330, loss_ce: 0.008526
2022-01-16 01:20:16,115 iteration 5834 : loss : 0.014754, loss_ce: 0.005192
2022-01-16 01:20:17,020 iteration 5835 : loss : 0.017290, loss_ce: 0.005406
2022-01-16 01:20:18,028 iteration 5836 : loss : 0.022742, loss_ce: 0.012527
2022-01-16 01:20:18,984 iteration 5837 : loss : 0.016934, loss_ce: 0.003769
2022-01-16 01:20:19,842 iteration 5838 : loss : 0.011767, loss_ce: 0.003484
2022-01-16 01:20:20,785 iteration 5839 : loss : 0.015982, loss_ce: 0.005294
2022-01-16 01:20:21,788 iteration 5840 : loss : 0.024410, loss_ce: 0.009818
2022-01-16 01:20:22,717 iteration 5841 : loss : 0.016367, loss_ce: 0.007231
2022-01-16 01:20:23,650 iteration 5842 : loss : 0.010294, loss_ce: 0.004015
2022-01-16 01:20:24,569 iteration 5843 : loss : 0.018320, loss_ce: 0.007823
2022-01-16 01:20:25,671 iteration 5844 : loss : 0.027284, loss_ce: 0.007853
2022-01-16 01:20:26,627 iteration 5845 : loss : 0.025224, loss_ce: 0.012799
2022-01-16 01:20:27,602 iteration 5846 : loss : 0.019065, loss_ce: 0.009096
2022-01-16 01:20:28,584 iteration 5847 : loss : 0.018039, loss_ce: 0.007049
2022-01-16 01:20:29,540 iteration 5848 : loss : 0.018075, loss_ce: 0.006539
 86%|████████████████████████▉    | 344/400 [1:41:22<15:48, 16.94s/it]2022-01-16 01:20:30,568 iteration 5849 : loss : 0.017619, loss_ce: 0.007326
2022-01-16 01:20:31,459 iteration 5850 : loss : 0.013628, loss_ce: 0.005329
2022-01-16 01:20:32,417 iteration 5851 : loss : 0.017818, loss_ce: 0.007576
2022-01-16 01:20:33,348 iteration 5852 : loss : 0.013849, loss_ce: 0.005169
2022-01-16 01:20:34,212 iteration 5853 : loss : 0.014057, loss_ce: 0.004611
2022-01-16 01:20:35,137 iteration 5854 : loss : 0.019455, loss_ce: 0.006374
2022-01-16 01:20:36,172 iteration 5855 : loss : 0.020542, loss_ce: 0.008999
2022-01-16 01:20:37,136 iteration 5856 : loss : 0.015044, loss_ce: 0.006734
2022-01-16 01:20:38,113 iteration 5857 : loss : 0.013745, loss_ce: 0.005111
2022-01-16 01:20:38,986 iteration 5858 : loss : 0.013427, loss_ce: 0.004890
2022-01-16 01:20:39,993 iteration 5859 : loss : 0.018764, loss_ce: 0.007306
2022-01-16 01:20:40,999 iteration 5860 : loss : 0.018344, loss_ce: 0.005641
2022-01-16 01:20:41,934 iteration 5861 : loss : 0.016694, loss_ce: 0.005118
2022-01-16 01:20:42,916 iteration 5862 : loss : 0.015610, loss_ce: 0.007193
2022-01-16 01:20:43,774 iteration 5863 : loss : 0.010524, loss_ce: 0.003370
2022-01-16 01:20:44,734 iteration 5864 : loss : 0.024463, loss_ce: 0.006855
2022-01-16 01:20:44,734 Training Data Eval:
2022-01-16 01:20:49,274   Average segmentation loss on training set: 0.0094
2022-01-16 01:20:49,275 Validation Data Eval:
2022-01-16 01:20:50,763   Average segmentation loss on validation set: 0.0845
2022-01-16 01:20:51,646 iteration 5865 : loss : 0.016340, loss_ce: 0.005138
 86%|█████████████████████████    | 345/400 [1:41:44<16:56, 18.49s/it]2022-01-16 01:20:52,755 iteration 5866 : loss : 0.015667, loss_ce: 0.006585
2022-01-16 01:20:53,771 iteration 5867 : loss : 0.022580, loss_ce: 0.006606
2022-01-16 01:20:54,772 iteration 5868 : loss : 0.024386, loss_ce: 0.009736
2022-01-16 01:20:55,647 iteration 5869 : loss : 0.018366, loss_ce: 0.007326
2022-01-16 01:20:56,698 iteration 5870 : loss : 0.025775, loss_ce: 0.007888
2022-01-16 01:20:57,692 iteration 5871 : loss : 0.016268, loss_ce: 0.005299
2022-01-16 01:20:58,694 iteration 5872 : loss : 0.030670, loss_ce: 0.010830
2022-01-16 01:20:59,792 iteration 5873 : loss : 0.027896, loss_ce: 0.009365
2022-01-16 01:21:00,711 iteration 5874 : loss : 0.014677, loss_ce: 0.004703
2022-01-16 01:21:01,651 iteration 5875 : loss : 0.015193, loss_ce: 0.007124
2022-01-16 01:21:02,614 iteration 5876 : loss : 0.015534, loss_ce: 0.005570
2022-01-16 01:21:03,574 iteration 5877 : loss : 0.019014, loss_ce: 0.007160
2022-01-16 01:21:04,567 iteration 5878 : loss : 0.015393, loss_ce: 0.006318
2022-01-16 01:21:05,484 iteration 5879 : loss : 0.016988, loss_ce: 0.007320
2022-01-16 01:21:06,552 iteration 5880 : loss : 0.029777, loss_ce: 0.007886
2022-01-16 01:21:07,453 iteration 5881 : loss : 0.013230, loss_ce: 0.004929
2022-01-16 01:21:08,390 iteration 5882 : loss : 0.016183, loss_ce: 0.007706
 86%|█████████████████████████    | 346/400 [1:42:01<16:10, 17.96s/it]2022-01-16 01:21:09,383 iteration 5883 : loss : 0.013433, loss_ce: 0.004548
2022-01-16 01:21:10,308 iteration 5884 : loss : 0.013285, loss_ce: 0.005594
2022-01-16 01:21:11,407 iteration 5885 : loss : 0.025196, loss_ce: 0.009432
2022-01-16 01:21:12,304 iteration 5886 : loss : 0.014115, loss_ce: 0.004222
2022-01-16 01:21:13,236 iteration 5887 : loss : 0.013771, loss_ce: 0.005668
2022-01-16 01:21:14,289 iteration 5888 : loss : 0.020070, loss_ce: 0.007216
2022-01-16 01:21:15,343 iteration 5889 : loss : 0.020398, loss_ce: 0.009606
2022-01-16 01:21:16,331 iteration 5890 : loss : 0.011831, loss_ce: 0.003794
2022-01-16 01:21:17,362 iteration 5891 : loss : 0.025922, loss_ce: 0.008745
2022-01-16 01:21:18,441 iteration 5892 : loss : 0.021701, loss_ce: 0.009254
2022-01-16 01:21:19,370 iteration 5893 : loss : 0.013058, loss_ce: 0.004210
2022-01-16 01:21:20,427 iteration 5894 : loss : 0.015736, loss_ce: 0.006634
2022-01-16 01:21:21,422 iteration 5895 : loss : 0.019252, loss_ce: 0.007032
2022-01-16 01:21:22,376 iteration 5896 : loss : 0.019853, loss_ce: 0.009781
2022-01-16 01:21:23,416 iteration 5897 : loss : 0.032647, loss_ce: 0.012356
2022-01-16 01:21:24,432 iteration 5898 : loss : 0.017154, loss_ce: 0.006875
2022-01-16 01:21:25,367 iteration 5899 : loss : 0.014904, loss_ce: 0.005482
 87%|█████████████████████████▏   | 347/400 [1:42:18<15:36, 17.67s/it]2022-01-16 01:21:26,417 iteration 5900 : loss : 0.015113, loss_ce: 0.005226
2022-01-16 01:21:27,473 iteration 5901 : loss : 0.014719, loss_ce: 0.005085
2022-01-16 01:21:28,442 iteration 5902 : loss : 0.016086, loss_ce: 0.006079
2022-01-16 01:21:29,479 iteration 5903 : loss : 0.015489, loss_ce: 0.007200
2022-01-16 01:21:30,431 iteration 5904 : loss : 0.016520, loss_ce: 0.006447
2022-01-16 01:21:31,454 iteration 5905 : loss : 0.027412, loss_ce: 0.006448
2022-01-16 01:21:32,364 iteration 5906 : loss : 0.017311, loss_ce: 0.006724
2022-01-16 01:21:33,363 iteration 5907 : loss : 0.010499, loss_ce: 0.003422
2022-01-16 01:21:34,342 iteration 5908 : loss : 0.011281, loss_ce: 0.003419
2022-01-16 01:21:35,202 iteration 5909 : loss : 0.016393, loss_ce: 0.004755
2022-01-16 01:21:36,174 iteration 5910 : loss : 0.020681, loss_ce: 0.006504
2022-01-16 01:21:37,187 iteration 5911 : loss : 0.022926, loss_ce: 0.008556
2022-01-16 01:21:38,082 iteration 5912 : loss : 0.014496, loss_ce: 0.004664
2022-01-16 01:21:39,016 iteration 5913 : loss : 0.016577, loss_ce: 0.007918
2022-01-16 01:21:39,986 iteration 5914 : loss : 0.018081, loss_ce: 0.007202
2022-01-16 01:21:40,857 iteration 5915 : loss : 0.016847, loss_ce: 0.006385
2022-01-16 01:21:41,871 iteration 5916 : loss : 0.028638, loss_ce: 0.011825
 87%|█████████████████████████▏   | 348/400 [1:42:34<15:00, 17.32s/it]2022-01-16 01:21:42,862 iteration 5917 : loss : 0.016846, loss_ce: 0.006282
2022-01-16 01:21:43,750 iteration 5918 : loss : 0.015556, loss_ce: 0.006023
2022-01-16 01:21:44,753 iteration 5919 : loss : 0.023207, loss_ce: 0.009982
2022-01-16 01:21:45,774 iteration 5920 : loss : 0.028944, loss_ce: 0.015054
2022-01-16 01:21:46,897 iteration 5921 : loss : 0.020782, loss_ce: 0.007309
2022-01-16 01:21:47,844 iteration 5922 : loss : 0.014288, loss_ce: 0.003662
2022-01-16 01:21:48,826 iteration 5923 : loss : 0.018861, loss_ce: 0.005646
2022-01-16 01:21:49,907 iteration 5924 : loss : 0.021385, loss_ce: 0.005267
2022-01-16 01:21:50,885 iteration 5925 : loss : 0.020142, loss_ce: 0.007429
2022-01-16 01:21:51,850 iteration 5926 : loss : 0.018143, loss_ce: 0.008133
2022-01-16 01:21:52,834 iteration 5927 : loss : 0.019731, loss_ce: 0.008720
2022-01-16 01:21:53,728 iteration 5928 : loss : 0.017262, loss_ce: 0.005049
2022-01-16 01:21:54,625 iteration 5929 : loss : 0.014986, loss_ce: 0.007163
2022-01-16 01:21:55,523 iteration 5930 : loss : 0.018614, loss_ce: 0.008197
2022-01-16 01:21:56,494 iteration 5931 : loss : 0.026203, loss_ce: 0.006370
2022-01-16 01:21:57,508 iteration 5932 : loss : 0.019278, loss_ce: 0.007410
2022-01-16 01:21:58,456 iteration 5933 : loss : 0.015661, loss_ce: 0.005671
 87%|█████████████████████████▎   | 349/400 [1:42:51<14:31, 17.09s/it]2022-01-16 01:21:59,434 iteration 5934 : loss : 0.013425, loss_ce: 0.004374
2022-01-16 01:22:00,544 iteration 5935 : loss : 0.021603, loss_ce: 0.008127
2022-01-16 01:22:01,510 iteration 5936 : loss : 0.013711, loss_ce: 0.005670
2022-01-16 01:22:02,438 iteration 5937 : loss : 0.016330, loss_ce: 0.005589
2022-01-16 01:22:03,314 iteration 5938 : loss : 0.009841, loss_ce: 0.003729
2022-01-16 01:22:04,314 iteration 5939 : loss : 0.015634, loss_ce: 0.006768
2022-01-16 01:22:05,212 iteration 5940 : loss : 0.012730, loss_ce: 0.005267
2022-01-16 01:22:06,125 iteration 5941 : loss : 0.018179, loss_ce: 0.007792
2022-01-16 01:22:07,050 iteration 5942 : loss : 0.016466, loss_ce: 0.007373
2022-01-16 01:22:08,015 iteration 5943 : loss : 0.017157, loss_ce: 0.004498
2022-01-16 01:22:08,985 iteration 5944 : loss : 0.016076, loss_ce: 0.008203
2022-01-16 01:22:09,910 iteration 5945 : loss : 0.016635, loss_ce: 0.003683
2022-01-16 01:22:10,977 iteration 5946 : loss : 0.028906, loss_ce: 0.011610
2022-01-16 01:22:11,977 iteration 5947 : loss : 0.035270, loss_ce: 0.014144
2022-01-16 01:22:12,909 iteration 5948 : loss : 0.018114, loss_ce: 0.006434
2022-01-16 01:22:13,952 iteration 5949 : loss : 0.019612, loss_ce: 0.006784
2022-01-16 01:22:13,952 Training Data Eval:
2022-01-16 01:22:18,485   Average segmentation loss on training set: 0.0095
2022-01-16 01:22:18,485 Validation Data Eval:
2022-01-16 01:22:19,978   Average segmentation loss on validation set: 0.0729
2022-01-16 01:22:20,949 iteration 5950 : loss : 0.022588, loss_ce: 0.007784
 88%|█████████████████████████▍   | 350/400 [1:43:14<15:35, 18.72s/it]2022-01-16 01:22:21,914 iteration 5951 : loss : 0.013123, loss_ce: 0.004591
2022-01-16 01:22:22,873 iteration 5952 : loss : 0.015509, loss_ce: 0.005738
2022-01-16 01:22:23,837 iteration 5953 : loss : 0.020096, loss_ce: 0.009304
2022-01-16 01:22:24,759 iteration 5954 : loss : 0.015516, loss_ce: 0.005711
2022-01-16 01:22:25,711 iteration 5955 : loss : 0.014090, loss_ce: 0.004509
2022-01-16 01:22:26,701 iteration 5956 : loss : 0.026390, loss_ce: 0.013561
2022-01-16 01:22:27,677 iteration 5957 : loss : 0.011967, loss_ce: 0.004659
2022-01-16 01:22:28,588 iteration 5958 : loss : 0.023461, loss_ce: 0.009306
2022-01-16 01:22:29,535 iteration 5959 : loss : 0.019079, loss_ce: 0.007277
2022-01-16 01:22:30,440 iteration 5960 : loss : 0.017151, loss_ce: 0.005097
2022-01-16 01:22:31,338 iteration 5961 : loss : 0.019382, loss_ce: 0.004513
2022-01-16 01:22:32,280 iteration 5962 : loss : 0.021052, loss_ce: 0.004354
2022-01-16 01:22:33,273 iteration 5963 : loss : 0.016997, loss_ce: 0.006958
2022-01-16 01:22:34,200 iteration 5964 : loss : 0.012604, loss_ce: 0.005276
2022-01-16 01:22:35,087 iteration 5965 : loss : 0.014236, loss_ce: 0.006296
2022-01-16 01:22:36,097 iteration 5966 : loss : 0.016357, loss_ce: 0.004424
2022-01-16 01:22:37,073 iteration 5967 : loss : 0.017831, loss_ce: 0.007798
 88%|█████████████████████████▍   | 351/400 [1:43:30<14:38, 17.94s/it]2022-01-16 01:22:38,179 iteration 5968 : loss : 0.023785, loss_ce: 0.010422
2022-01-16 01:22:39,112 iteration 5969 : loss : 0.017587, loss_ce: 0.007169
2022-01-16 01:22:40,107 iteration 5970 : loss : 0.016783, loss_ce: 0.006793
2022-01-16 01:22:40,989 iteration 5971 : loss : 0.013005, loss_ce: 0.004062
2022-01-16 01:22:41,846 iteration 5972 : loss : 0.012935, loss_ce: 0.004156
2022-01-16 01:22:42,805 iteration 5973 : loss : 0.014330, loss_ce: 0.006528
2022-01-16 01:22:43,872 iteration 5974 : loss : 0.023960, loss_ce: 0.010335
2022-01-16 01:22:44,778 iteration 5975 : loss : 0.017339, loss_ce: 0.005475
2022-01-16 01:22:45,702 iteration 5976 : loss : 0.015591, loss_ce: 0.004666
2022-01-16 01:22:46,605 iteration 5977 : loss : 0.016738, loss_ce: 0.004781
2022-01-16 01:22:47,495 iteration 5978 : loss : 0.015011, loss_ce: 0.006329
2022-01-16 01:22:48,442 iteration 5979 : loss : 0.014474, loss_ce: 0.007823
2022-01-16 01:22:49,438 iteration 5980 : loss : 0.014934, loss_ce: 0.005385
2022-01-16 01:22:50,355 iteration 5981 : loss : 0.023237, loss_ce: 0.009127
2022-01-16 01:22:51,307 iteration 5982 : loss : 0.017163, loss_ce: 0.007089
2022-01-16 01:22:52,329 iteration 5983 : loss : 0.018011, loss_ce: 0.005969
2022-01-16 01:22:53,250 iteration 5984 : loss : 0.016634, loss_ce: 0.005953
 88%|█████████████████████████▌   | 352/400 [1:43:46<13:55, 17.41s/it]2022-01-16 01:22:54,281 iteration 5985 : loss : 0.015728, loss_ce: 0.004508
2022-01-16 01:22:55,139 iteration 5986 : loss : 0.012572, loss_ce: 0.003941
2022-01-16 01:22:56,118 iteration 5987 : loss : 0.014828, loss_ce: 0.006543
2022-01-16 01:22:57,131 iteration 5988 : loss : 0.025192, loss_ce: 0.009856
2022-01-16 01:22:58,101 iteration 5989 : loss : 0.014032, loss_ce: 0.004953
2022-01-16 01:22:59,030 iteration 5990 : loss : 0.013473, loss_ce: 0.004688
2022-01-16 01:23:00,009 iteration 5991 : loss : 0.018337, loss_ce: 0.006180
2022-01-16 01:23:00,982 iteration 5992 : loss : 0.017150, loss_ce: 0.005936
2022-01-16 01:23:01,930 iteration 5993 : loss : 0.011707, loss_ce: 0.004778
2022-01-16 01:23:02,940 iteration 5994 : loss : 0.017663, loss_ce: 0.007421
2022-01-16 01:23:03,886 iteration 5995 : loss : 0.013669, loss_ce: 0.006101
2022-01-16 01:23:04,790 iteration 5996 : loss : 0.012793, loss_ce: 0.003842
2022-01-16 01:23:05,770 iteration 5997 : loss : 0.020046, loss_ce: 0.007020
2022-01-16 01:23:06,815 iteration 5998 : loss : 0.016932, loss_ce: 0.005747
2022-01-16 01:23:07,888 iteration 5999 : loss : 0.014887, loss_ce: 0.005047
2022-01-16 01:23:08,868 iteration 6000 : loss : 0.017537, loss_ce: 0.007415
2022-01-16 01:23:09,740 iteration 6001 : loss : 0.017472, loss_ce: 0.008274
 88%|█████████████████████████▌   | 353/400 [1:44:02<13:25, 17.13s/it]2022-01-16 01:23:10,779 iteration 6002 : loss : 0.019177, loss_ce: 0.007185
2022-01-16 01:23:11,697 iteration 6003 : loss : 0.013280, loss_ce: 0.004961
2022-01-16 01:23:12,707 iteration 6004 : loss : 0.017921, loss_ce: 0.007942
2022-01-16 01:23:13,704 iteration 6005 : loss : 0.024664, loss_ce: 0.009241
2022-01-16 01:23:14,783 iteration 6006 : loss : 0.026689, loss_ce: 0.009895
2022-01-16 01:23:15,774 iteration 6007 : loss : 0.011422, loss_ce: 0.004248
2022-01-16 01:23:16,749 iteration 6008 : loss : 0.017513, loss_ce: 0.006383
2022-01-16 01:23:17,621 iteration 6009 : loss : 0.013203, loss_ce: 0.006271
2022-01-16 01:23:18,514 iteration 6010 : loss : 0.013833, loss_ce: 0.005541
2022-01-16 01:23:19,508 iteration 6011 : loss : 0.027146, loss_ce: 0.010398
2022-01-16 01:23:20,536 iteration 6012 : loss : 0.015561, loss_ce: 0.004049
2022-01-16 01:23:21,541 iteration 6013 : loss : 0.018805, loss_ce: 0.007111
2022-01-16 01:23:22,534 iteration 6014 : loss : 0.018035, loss_ce: 0.005187
2022-01-16 01:23:23,458 iteration 6015 : loss : 0.012954, loss_ce: 0.005574
2022-01-16 01:23:24,417 iteration 6016 : loss : 0.017407, loss_ce: 0.005900
2022-01-16 01:23:25,373 iteration 6017 : loss : 0.014703, loss_ce: 0.006408
2022-01-16 01:23:26,357 iteration 6018 : loss : 0.015617, loss_ce: 0.005932
 88%|█████████████████████████▋   | 354/400 [1:44:19<13:00, 16.98s/it]2022-01-16 01:23:27,391 iteration 6019 : loss : 0.020700, loss_ce: 0.010768
2022-01-16 01:23:28,333 iteration 6020 : loss : 0.012465, loss_ce: 0.006090
2022-01-16 01:23:29,313 iteration 6021 : loss : 0.025669, loss_ce: 0.005980
2022-01-16 01:23:30,209 iteration 6022 : loss : 0.013060, loss_ce: 0.005492
2022-01-16 01:23:31,207 iteration 6023 : loss : 0.018409, loss_ce: 0.007714
2022-01-16 01:23:32,139 iteration 6024 : loss : 0.020487, loss_ce: 0.007008
2022-01-16 01:23:33,062 iteration 6025 : loss : 0.015643, loss_ce: 0.007165
2022-01-16 01:23:34,038 iteration 6026 : loss : 0.015730, loss_ce: 0.005515
2022-01-16 01:23:35,011 iteration 6027 : loss : 0.022516, loss_ce: 0.007725
2022-01-16 01:23:36,008 iteration 6028 : loss : 0.021150, loss_ce: 0.007579
2022-01-16 01:23:36,945 iteration 6029 : loss : 0.020350, loss_ce: 0.005691
2022-01-16 01:23:37,827 iteration 6030 : loss : 0.013722, loss_ce: 0.006411
2022-01-16 01:23:38,806 iteration 6031 : loss : 0.013922, loss_ce: 0.006502
2022-01-16 01:23:39,708 iteration 6032 : loss : 0.018802, loss_ce: 0.006034
2022-01-16 01:23:40,716 iteration 6033 : loss : 0.027304, loss_ce: 0.011828
2022-01-16 01:23:41,680 iteration 6034 : loss : 0.012555, loss_ce: 0.004882
2022-01-16 01:23:41,680 Training Data Eval:
2022-01-16 01:23:46,225   Average segmentation loss on training set: 0.0093
2022-01-16 01:23:46,226 Validation Data Eval:
2022-01-16 01:23:47,710   Average segmentation loss on validation set: 0.0910
2022-01-16 01:23:48,536 iteration 6035 : loss : 0.011115, loss_ce: 0.004208
 89%|█████████████████████████▋   | 355/400 [1:44:41<13:54, 18.54s/it]2022-01-16 01:23:49,661 iteration 6036 : loss : 0.028545, loss_ce: 0.008910
2022-01-16 01:23:50,670 iteration 6037 : loss : 0.018777, loss_ce: 0.005821
2022-01-16 01:23:51,609 iteration 6038 : loss : 0.018461, loss_ce: 0.007469
2022-01-16 01:23:52,530 iteration 6039 : loss : 0.014099, loss_ce: 0.004364
2022-01-16 01:23:53,493 iteration 6040 : loss : 0.016944, loss_ce: 0.006354
2022-01-16 01:23:54,406 iteration 6041 : loss : 0.015944, loss_ce: 0.005567
2022-01-16 01:23:55,381 iteration 6042 : loss : 0.013566, loss_ce: 0.006105
2022-01-16 01:23:56,281 iteration 6043 : loss : 0.014093, loss_ce: 0.006967
2022-01-16 01:23:57,163 iteration 6044 : loss : 0.011761, loss_ce: 0.004976
2022-01-16 01:23:58,197 iteration 6045 : loss : 0.022751, loss_ce: 0.008663
2022-01-16 01:23:59,087 iteration 6046 : loss : 0.019308, loss_ce: 0.009231
2022-01-16 01:23:59,976 iteration 6047 : loss : 0.012338, loss_ce: 0.005454
2022-01-16 01:24:01,002 iteration 6048 : loss : 0.022581, loss_ce: 0.007214
2022-01-16 01:24:01,885 iteration 6049 : loss : 0.012934, loss_ce: 0.004765
2022-01-16 01:24:02,762 iteration 6050 : loss : 0.019153, loss_ce: 0.004877
2022-01-16 01:24:03,634 iteration 6051 : loss : 0.011907, loss_ce: 0.005033
2022-01-16 01:24:04,609 iteration 6052 : loss : 0.013584, loss_ce: 0.005153
 89%|█████████████████████████▊   | 356/400 [1:44:57<13:03, 17.80s/it]2022-01-16 01:24:05,593 iteration 6053 : loss : 0.014042, loss_ce: 0.004160
2022-01-16 01:24:06,507 iteration 6054 : loss : 0.012293, loss_ce: 0.004160
2022-01-16 01:24:07,482 iteration 6055 : loss : 0.016526, loss_ce: 0.007015
2022-01-16 01:24:08,414 iteration 6056 : loss : 0.016671, loss_ce: 0.005928
2022-01-16 01:24:09,277 iteration 6057 : loss : 0.015764, loss_ce: 0.006133
2022-01-16 01:24:10,166 iteration 6058 : loss : 0.012899, loss_ce: 0.006886
2022-01-16 01:24:11,182 iteration 6059 : loss : 0.026806, loss_ce: 0.009963
2022-01-16 01:24:12,148 iteration 6060 : loss : 0.019093, loss_ce: 0.005746
2022-01-16 01:24:13,043 iteration 6061 : loss : 0.018592, loss_ce: 0.010481
2022-01-16 01:24:14,135 iteration 6062 : loss : 0.021135, loss_ce: 0.007510
2022-01-16 01:24:15,036 iteration 6063 : loss : 0.014057, loss_ce: 0.006302
2022-01-16 01:24:15,951 iteration 6064 : loss : 0.011460, loss_ce: 0.003552
2022-01-16 01:24:16,934 iteration 6065 : loss : 0.024541, loss_ce: 0.009909
2022-01-16 01:24:17,813 iteration 6066 : loss : 0.015461, loss_ce: 0.006243
2022-01-16 01:24:18,786 iteration 6067 : loss : 0.026213, loss_ce: 0.010134
2022-01-16 01:24:19,740 iteration 6068 : loss : 0.019076, loss_ce: 0.003039
2022-01-16 01:24:20,782 iteration 6069 : loss : 0.025473, loss_ce: 0.014480
 89%|█████████████████████████▉   | 357/400 [1:45:13<12:24, 17.31s/it]2022-01-16 01:24:21,818 iteration 6070 : loss : 0.019556, loss_ce: 0.007990
2022-01-16 01:24:22,782 iteration 6071 : loss : 0.018504, loss_ce: 0.007324
2022-01-16 01:24:23,726 iteration 6072 : loss : 0.013539, loss_ce: 0.004457
2022-01-16 01:24:24,686 iteration 6073 : loss : 0.017204, loss_ce: 0.004742
2022-01-16 01:24:25,544 iteration 6074 : loss : 0.013808, loss_ce: 0.006680
2022-01-16 01:24:26,535 iteration 6075 : loss : 0.014909, loss_ce: 0.006112
2022-01-16 01:24:27,495 iteration 6076 : loss : 0.014100, loss_ce: 0.005881
2022-01-16 01:24:28,326 iteration 6077 : loss : 0.011985, loss_ce: 0.004360
2022-01-16 01:24:29,258 iteration 6078 : loss : 0.014545, loss_ce: 0.007331
2022-01-16 01:24:30,285 iteration 6079 : loss : 0.013935, loss_ce: 0.005786
2022-01-16 01:24:31,164 iteration 6080 : loss : 0.012349, loss_ce: 0.004341
2022-01-16 01:24:32,198 iteration 6081 : loss : 0.019843, loss_ce: 0.006964
2022-01-16 01:24:33,143 iteration 6082 : loss : 0.019894, loss_ce: 0.006380
2022-01-16 01:24:34,142 iteration 6083 : loss : 0.015080, loss_ce: 0.004426
2022-01-16 01:24:35,047 iteration 6084 : loss : 0.015444, loss_ce: 0.004312
2022-01-16 01:24:35,946 iteration 6085 : loss : 0.013755, loss_ce: 0.005177
2022-01-16 01:24:37,074 iteration 6086 : loss : 0.022510, loss_ce: 0.005369
 90%|█████████████████████████▉   | 358/400 [1:45:30<11:54, 17.01s/it]2022-01-16 01:24:38,031 iteration 6087 : loss : 0.016572, loss_ce: 0.006489
2022-01-16 01:24:38,992 iteration 6088 : loss : 0.019652, loss_ce: 0.007649
2022-01-16 01:24:39,927 iteration 6089 : loss : 0.017724, loss_ce: 0.008862
2022-01-16 01:24:40,867 iteration 6090 : loss : 0.025132, loss_ce: 0.006171
2022-01-16 01:24:41,810 iteration 6091 : loss : 0.011752, loss_ce: 0.005386
2022-01-16 01:24:42,770 iteration 6092 : loss : 0.014533, loss_ce: 0.005501
2022-01-16 01:24:43,638 iteration 6093 : loss : 0.014031, loss_ce: 0.004893
2022-01-16 01:24:44,529 iteration 6094 : loss : 0.016953, loss_ce: 0.005017
2022-01-16 01:24:45,504 iteration 6095 : loss : 0.015470, loss_ce: 0.006293
2022-01-16 01:24:46,487 iteration 6096 : loss : 0.016045, loss_ce: 0.004819
2022-01-16 01:24:47,362 iteration 6097 : loss : 0.013370, loss_ce: 0.006019
2022-01-16 01:24:48,314 iteration 6098 : loss : 0.018746, loss_ce: 0.007500
2022-01-16 01:24:49,310 iteration 6099 : loss : 0.027631, loss_ce: 0.006599
2022-01-16 01:24:50,348 iteration 6100 : loss : 0.017183, loss_ce: 0.005582
2022-01-16 01:24:51,355 iteration 6101 : loss : 0.012510, loss_ce: 0.004554
2022-01-16 01:24:52,265 iteration 6102 : loss : 0.013025, loss_ce: 0.003877
2022-01-16 01:24:53,096 iteration 6103 : loss : 0.009843, loss_ce: 0.003595
 90%|██████████████████████████   | 359/400 [1:45:46<11:25, 16.71s/it]2022-01-16 01:24:54,164 iteration 6104 : loss : 0.024221, loss_ce: 0.007874
2022-01-16 01:24:55,061 iteration 6105 : loss : 0.015126, loss_ce: 0.006171
2022-01-16 01:24:55,915 iteration 6106 : loss : 0.012412, loss_ce: 0.004269
2022-01-16 01:24:56,803 iteration 6107 : loss : 0.013033, loss_ce: 0.003753
2022-01-16 01:24:57,802 iteration 6108 : loss : 0.014499, loss_ce: 0.004283
2022-01-16 01:24:58,720 iteration 6109 : loss : 0.017158, loss_ce: 0.006199
2022-01-16 01:24:59,684 iteration 6110 : loss : 0.013911, loss_ce: 0.006105
2022-01-16 01:25:00,697 iteration 6111 : loss : 0.029490, loss_ce: 0.012534
2022-01-16 01:25:01,689 iteration 6112 : loss : 0.014220, loss_ce: 0.004966
2022-01-16 01:25:02,716 iteration 6113 : loss : 0.018134, loss_ce: 0.006064
2022-01-16 01:25:03,650 iteration 6114 : loss : 0.020025, loss_ce: 0.008982
2022-01-16 01:25:04,693 iteration 6115 : loss : 0.023928, loss_ce: 0.008570
2022-01-16 01:25:05,683 iteration 6116 : loss : 0.014194, loss_ce: 0.006367
2022-01-16 01:25:06,598 iteration 6117 : loss : 0.021547, loss_ce: 0.008860
2022-01-16 01:25:07,590 iteration 6118 : loss : 0.017790, loss_ce: 0.008164
2022-01-16 01:25:08,527 iteration 6119 : loss : 0.017077, loss_ce: 0.005400
2022-01-16 01:25:08,528 Training Data Eval:
2022-01-16 01:25:13,068   Average segmentation loss on training set: 0.0092
2022-01-16 01:25:13,068 Validation Data Eval:
2022-01-16 01:25:14,556   Average segmentation loss on validation set: 0.0753
2022-01-16 01:25:15,489 iteration 6120 : loss : 0.012780, loss_ce: 0.005338
 90%|██████████████████████████   | 360/400 [1:46:08<12:16, 18.42s/it]2022-01-16 01:25:16,522 iteration 6121 : loss : 0.021464, loss_ce: 0.009339
2022-01-16 01:25:17,528 iteration 6122 : loss : 0.019867, loss_ce: 0.007891
2022-01-16 01:25:18,572 iteration 6123 : loss : 0.017228, loss_ce: 0.006937
2022-01-16 01:25:19,544 iteration 6124 : loss : 0.015780, loss_ce: 0.004650
2022-01-16 01:25:20,603 iteration 6125 : loss : 0.026549, loss_ce: 0.008373
2022-01-16 01:25:21,550 iteration 6126 : loss : 0.024160, loss_ce: 0.005760
2022-01-16 01:25:22,480 iteration 6127 : loss : 0.021452, loss_ce: 0.008141
2022-01-16 01:25:23,514 iteration 6128 : loss : 0.016538, loss_ce: 0.005653
2022-01-16 01:25:24,478 iteration 6129 : loss : 0.027993, loss_ce: 0.008683
2022-01-16 01:25:25,528 iteration 6130 : loss : 0.020281, loss_ce: 0.007527
2022-01-16 01:25:26,508 iteration 6131 : loss : 0.023300, loss_ce: 0.011730
2022-01-16 01:25:27,483 iteration 6132 : loss : 0.026884, loss_ce: 0.007427
2022-01-16 01:25:28,396 iteration 6133 : loss : 0.014982, loss_ce: 0.007691
2022-01-16 01:25:29,269 iteration 6134 : loss : 0.010101, loss_ce: 0.004205
2022-01-16 01:25:30,147 iteration 6135 : loss : 0.011294, loss_ce: 0.004234
2022-01-16 01:25:31,116 iteration 6136 : loss : 0.015418, loss_ce: 0.005100
2022-01-16 01:25:32,046 iteration 6137 : loss : 0.013785, loss_ce: 0.005194
 90%|██████████████████████████▏  | 361/400 [1:46:25<11:36, 17.86s/it]2022-01-16 01:25:33,011 iteration 6138 : loss : 0.012456, loss_ce: 0.004135
2022-01-16 01:25:34,003 iteration 6139 : loss : 0.013980, loss_ce: 0.005692
2022-01-16 01:25:34,947 iteration 6140 : loss : 0.011858, loss_ce: 0.004322
2022-01-16 01:25:35,935 iteration 6141 : loss : 0.015102, loss_ce: 0.006087
2022-01-16 01:25:37,058 iteration 6142 : loss : 0.022814, loss_ce: 0.009684
2022-01-16 01:25:37,947 iteration 6143 : loss : 0.014036, loss_ce: 0.006461
2022-01-16 01:25:38,922 iteration 6144 : loss : 0.012266, loss_ce: 0.005029
2022-01-16 01:25:39,899 iteration 6145 : loss : 0.017556, loss_ce: 0.006292
2022-01-16 01:25:40,849 iteration 6146 : loss : 0.015991, loss_ce: 0.006976
2022-01-16 01:25:41,795 iteration 6147 : loss : 0.011924, loss_ce: 0.003126
2022-01-16 01:25:42,695 iteration 6148 : loss : 0.009302, loss_ce: 0.002949
2022-01-16 01:25:43,590 iteration 6149 : loss : 0.018809, loss_ce: 0.006809
2022-01-16 01:25:44,510 iteration 6150 : loss : 0.019956, loss_ce: 0.005888
2022-01-16 01:25:45,452 iteration 6151 : loss : 0.015843, loss_ce: 0.003631
2022-01-16 01:25:46,351 iteration 6152 : loss : 0.024199, loss_ce: 0.010982
2022-01-16 01:25:47,368 iteration 6153 : loss : 0.019781, loss_ce: 0.008214
2022-01-16 01:25:48,422 iteration 6154 : loss : 0.019654, loss_ce: 0.007868
 90%|██████████████████████████▏  | 362/400 [1:46:41<11:01, 17.41s/it]2022-01-16 01:25:49,406 iteration 6155 : loss : 0.016283, loss_ce: 0.006801
2022-01-16 01:25:50,349 iteration 6156 : loss : 0.011555, loss_ce: 0.005052
2022-01-16 01:25:51,350 iteration 6157 : loss : 0.014718, loss_ce: 0.004762
2022-01-16 01:25:52,271 iteration 6158 : loss : 0.015312, loss_ce: 0.004884
2022-01-16 01:25:53,127 iteration 6159 : loss : 0.011962, loss_ce: 0.004545
2022-01-16 01:25:54,287 iteration 6160 : loss : 0.020343, loss_ce: 0.009490
2022-01-16 01:25:55,159 iteration 6161 : loss : 0.022476, loss_ce: 0.006939
2022-01-16 01:25:56,135 iteration 6162 : loss : 0.011940, loss_ce: 0.004281
2022-01-16 01:25:57,083 iteration 6163 : loss : 0.012846, loss_ce: 0.004760
2022-01-16 01:25:57,996 iteration 6164 : loss : 0.014881, loss_ce: 0.004301
2022-01-16 01:25:58,963 iteration 6165 : loss : 0.015522, loss_ce: 0.005893
2022-01-16 01:25:59,958 iteration 6166 : loss : 0.021259, loss_ce: 0.009875
2022-01-16 01:26:00,823 iteration 6167 : loss : 0.011340, loss_ce: 0.003555
2022-01-16 01:26:01,891 iteration 6168 : loss : 0.024950, loss_ce: 0.007855
2022-01-16 01:26:02,833 iteration 6169 : loss : 0.013120, loss_ce: 0.005252
2022-01-16 01:26:03,824 iteration 6170 : loss : 0.015787, loss_ce: 0.006394
2022-01-16 01:26:04,777 iteration 6171 : loss : 0.017577, loss_ce: 0.004757
 91%|██████████████████████████▎  | 363/400 [1:46:57<10:32, 17.10s/it]2022-01-16 01:26:05,788 iteration 6172 : loss : 0.016217, loss_ce: 0.005135
2022-01-16 01:26:06,637 iteration 6173 : loss : 0.012389, loss_ce: 0.004205
2022-01-16 01:26:07,561 iteration 6174 : loss : 0.014587, loss_ce: 0.007724
2022-01-16 01:26:08,437 iteration 6175 : loss : 0.010393, loss_ce: 0.002827
2022-01-16 01:26:09,410 iteration 6176 : loss : 0.014439, loss_ce: 0.007123
2022-01-16 01:26:10,474 iteration 6177 : loss : 0.022922, loss_ce: 0.010389
2022-01-16 01:26:11,496 iteration 6178 : loss : 0.019021, loss_ce: 0.006983
2022-01-16 01:26:12,495 iteration 6179 : loss : 0.019118, loss_ce: 0.005724
2022-01-16 01:26:13,488 iteration 6180 : loss : 0.022636, loss_ce: 0.004481
2022-01-16 01:26:14,411 iteration 6181 : loss : 0.014694, loss_ce: 0.005847
2022-01-16 01:26:15,385 iteration 6182 : loss : 0.012616, loss_ce: 0.004757
2022-01-16 01:26:16,292 iteration 6183 : loss : 0.016690, loss_ce: 0.006057
2022-01-16 01:26:17,191 iteration 6184 : loss : 0.013169, loss_ce: 0.005280
2022-01-16 01:26:18,194 iteration 6185 : loss : 0.019838, loss_ce: 0.005733
2022-01-16 01:26:19,080 iteration 6186 : loss : 0.011987, loss_ce: 0.004587
2022-01-16 01:26:19,979 iteration 6187 : loss : 0.014352, loss_ce: 0.004529
2022-01-16 01:26:20,876 iteration 6188 : loss : 0.018908, loss_ce: 0.008227
 91%|██████████████████████████▍  | 364/400 [1:47:13<10:04, 16.80s/it]2022-01-16 01:26:21,983 iteration 6189 : loss : 0.023194, loss_ce: 0.010538
2022-01-16 01:26:22,948 iteration 6190 : loss : 0.022301, loss_ce: 0.010602
2022-01-16 01:26:23,983 iteration 6191 : loss : 0.018827, loss_ce: 0.005581
2022-01-16 01:26:24,982 iteration 6192 : loss : 0.014834, loss_ce: 0.004679
2022-01-16 01:26:25,898 iteration 6193 : loss : 0.011493, loss_ce: 0.003669
2022-01-16 01:26:26,900 iteration 6194 : loss : 0.014782, loss_ce: 0.005665
2022-01-16 01:26:27,932 iteration 6195 : loss : 0.015105, loss_ce: 0.004711
2022-01-16 01:26:28,842 iteration 6196 : loss : 0.017175, loss_ce: 0.005214
2022-01-16 01:26:29,900 iteration 6197 : loss : 0.020532, loss_ce: 0.006447
2022-01-16 01:26:30,959 iteration 6198 : loss : 0.020743, loss_ce: 0.009188
2022-01-16 01:26:31,879 iteration 6199 : loss : 0.013081, loss_ce: 0.004930
2022-01-16 01:26:32,871 iteration 6200 : loss : 0.022965, loss_ce: 0.012385
2022-01-16 01:26:33,837 iteration 6201 : loss : 0.019272, loss_ce: 0.007193
2022-01-16 01:26:34,779 iteration 6202 : loss : 0.012163, loss_ce: 0.003968
2022-01-16 01:26:35,709 iteration 6203 : loss : 0.023776, loss_ce: 0.006103
2022-01-16 01:26:36,715 iteration 6204 : loss : 0.024067, loss_ce: 0.011530
2022-01-16 01:26:36,715 Training Data Eval:
2022-01-16 01:26:41,255   Average segmentation loss on training set: 0.0087
2022-01-16 01:26:41,255 Validation Data Eval:
2022-01-16 01:26:42,744   Average segmentation loss on validation set: 0.0686
2022-01-16 01:26:43,804 iteration 6205 : loss : 0.022189, loss_ce: 0.011620
 91%|██████████████████████████▍  | 365/400 [1:47:36<10:52, 18.63s/it]2022-01-16 01:26:44,844 iteration 6206 : loss : 0.015145, loss_ce: 0.006965
2022-01-16 01:26:45,810 iteration 6207 : loss : 0.018990, loss_ce: 0.010806
2022-01-16 01:26:46,797 iteration 6208 : loss : 0.016142, loss_ce: 0.006003
2022-01-16 01:26:47,779 iteration 6209 : loss : 0.021700, loss_ce: 0.007415
2022-01-16 01:26:48,710 iteration 6210 : loss : 0.020434, loss_ce: 0.007782
2022-01-16 01:26:49,600 iteration 6211 : loss : 0.011774, loss_ce: 0.004041
2022-01-16 01:26:50,529 iteration 6212 : loss : 0.017801, loss_ce: 0.005878
2022-01-16 01:26:51,483 iteration 6213 : loss : 0.011439, loss_ce: 0.004402
2022-01-16 01:26:52,414 iteration 6214 : loss : 0.012031, loss_ce: 0.004422
2022-01-16 01:26:53,431 iteration 6215 : loss : 0.019598, loss_ce: 0.006555
2022-01-16 01:26:54,374 iteration 6216 : loss : 0.015097, loss_ce: 0.005535
2022-01-16 01:26:55,252 iteration 6217 : loss : 0.017563, loss_ce: 0.006464
2022-01-16 01:26:56,211 iteration 6218 : loss : 0.016838, loss_ce: 0.006555
2022-01-16 01:26:57,151 iteration 6219 : loss : 0.013901, loss_ce: 0.004836
2022-01-16 01:26:58,063 iteration 6220 : loss : 0.012702, loss_ce: 0.003075
2022-01-16 01:26:59,035 iteration 6221 : loss : 0.015448, loss_ce: 0.004383
2022-01-16 01:26:59,938 iteration 6222 : loss : 0.010520, loss_ce: 0.004942
 92%|██████████████████████████▌  | 366/400 [1:47:53<10:08, 17.89s/it]2022-01-16 01:27:00,991 iteration 6223 : loss : 0.016641, loss_ce: 0.007390
2022-01-16 01:27:01,932 iteration 6224 : loss : 0.016771, loss_ce: 0.006749
2022-01-16 01:27:02,897 iteration 6225 : loss : 0.027127, loss_ce: 0.009742
2022-01-16 01:27:03,808 iteration 6226 : loss : 0.012997, loss_ce: 0.004469
2022-01-16 01:27:04,696 iteration 6227 : loss : 0.013929, loss_ce: 0.005434
2022-01-16 01:27:05,654 iteration 6228 : loss : 0.015962, loss_ce: 0.005725
2022-01-16 01:27:06,618 iteration 6229 : loss : 0.010912, loss_ce: 0.004933
2022-01-16 01:27:07,610 iteration 6230 : loss : 0.018900, loss_ce: 0.006854
2022-01-16 01:27:08,618 iteration 6231 : loss : 0.016504, loss_ce: 0.006301
2022-01-16 01:27:09,597 iteration 6232 : loss : 0.015279, loss_ce: 0.005607
2022-01-16 01:27:10,546 iteration 6233 : loss : 0.014096, loss_ce: 0.006373
2022-01-16 01:27:11,476 iteration 6234 : loss : 0.016601, loss_ce: 0.003417
2022-01-16 01:27:12,381 iteration 6235 : loss : 0.017077, loss_ce: 0.010019
2022-01-16 01:27:13,334 iteration 6236 : loss : 0.012675, loss_ce: 0.005901
2022-01-16 01:27:14,311 iteration 6237 : loss : 0.024966, loss_ce: 0.016340
2022-01-16 01:27:15,341 iteration 6238 : loss : 0.017157, loss_ce: 0.005009
2022-01-16 01:27:16,306 iteration 6239 : loss : 0.015621, loss_ce: 0.004737
 92%|██████████████████████████▌  | 367/400 [1:48:09<09:35, 17.43s/it]2022-01-16 01:27:17,310 iteration 6240 : loss : 0.011526, loss_ce: 0.003756
2022-01-16 01:27:18,215 iteration 6241 : loss : 0.011625, loss_ce: 0.005440
2022-01-16 01:27:19,252 iteration 6242 : loss : 0.026355, loss_ce: 0.010401
2022-01-16 01:27:20,196 iteration 6243 : loss : 0.012519, loss_ce: 0.004940
2022-01-16 01:27:21,244 iteration 6244 : loss : 0.014641, loss_ce: 0.006105
2022-01-16 01:27:22,193 iteration 6245 : loss : 0.015701, loss_ce: 0.005768
2022-01-16 01:27:23,120 iteration 6246 : loss : 0.013012, loss_ce: 0.005677
2022-01-16 01:27:24,099 iteration 6247 : loss : 0.016376, loss_ce: 0.004007
2022-01-16 01:27:25,034 iteration 6248 : loss : 0.015321, loss_ce: 0.006593
2022-01-16 01:27:25,972 iteration 6249 : loss : 0.014171, loss_ce: 0.004209
2022-01-16 01:27:26,962 iteration 6250 : loss : 0.013407, loss_ce: 0.004706
2022-01-16 01:27:28,019 iteration 6251 : loss : 0.019429, loss_ce: 0.007459
2022-01-16 01:27:28,930 iteration 6252 : loss : 0.015772, loss_ce: 0.007750
2022-01-16 01:27:29,937 iteration 6253 : loss : 0.015912, loss_ce: 0.005418
2022-01-16 01:27:30,867 iteration 6254 : loss : 0.015887, loss_ce: 0.007178
2022-01-16 01:27:31,837 iteration 6255 : loss : 0.019870, loss_ce: 0.007522
2022-01-16 01:27:32,877 iteration 6256 : loss : 0.019596, loss_ce: 0.008847
 92%|██████████████████████████▋  | 368/400 [1:48:25<09:09, 17.17s/it]2022-01-16 01:27:33,948 iteration 6257 : loss : 0.017648, loss_ce: 0.006748
2022-01-16 01:27:34,964 iteration 6258 : loss : 0.018402, loss_ce: 0.006440
2022-01-16 01:27:36,003 iteration 6259 : loss : 0.016200, loss_ce: 0.006411
2022-01-16 01:27:36,946 iteration 6260 : loss : 0.018188, loss_ce: 0.007550
2022-01-16 01:27:37,885 iteration 6261 : loss : 0.021064, loss_ce: 0.008572
2022-01-16 01:27:38,863 iteration 6262 : loss : 0.018516, loss_ce: 0.004725
2022-01-16 01:27:39,839 iteration 6263 : loss : 0.017057, loss_ce: 0.003924
2022-01-16 01:27:40,820 iteration 6264 : loss : 0.015938, loss_ce: 0.005613
2022-01-16 01:27:41,802 iteration 6265 : loss : 0.015547, loss_ce: 0.005982
2022-01-16 01:27:42,733 iteration 6266 : loss : 0.017749, loss_ce: 0.009295
2022-01-16 01:27:43,647 iteration 6267 : loss : 0.014115, loss_ce: 0.006453
2022-01-16 01:27:44,603 iteration 6268 : loss : 0.016184, loss_ce: 0.006441
2022-01-16 01:27:45,412 iteration 6269 : loss : 0.010237, loss_ce: 0.003603
2022-01-16 01:27:46,344 iteration 6270 : loss : 0.013797, loss_ce: 0.006566
2022-01-16 01:27:47,282 iteration 6271 : loss : 0.013192, loss_ce: 0.003689
2022-01-16 01:27:48,283 iteration 6272 : loss : 0.020834, loss_ce: 0.008043
2022-01-16 01:27:49,271 iteration 6273 : loss : 0.013562, loss_ce: 0.005142
 92%|██████████████████████████▊  | 369/400 [1:48:42<08:45, 16.94s/it]2022-01-16 01:27:50,433 iteration 6274 : loss : 0.022026, loss_ce: 0.007428
2022-01-16 01:27:51,420 iteration 6275 : loss : 0.022957, loss_ce: 0.009469
2022-01-16 01:27:52,397 iteration 6276 : loss : 0.022813, loss_ce: 0.009395
2022-01-16 01:27:53,315 iteration 6277 : loss : 0.019898, loss_ce: 0.005316
2022-01-16 01:27:54,284 iteration 6278 : loss : 0.021241, loss_ce: 0.007124
2022-01-16 01:27:55,228 iteration 6279 : loss : 0.019306, loss_ce: 0.008065
2022-01-16 01:27:56,150 iteration 6280 : loss : 0.023401, loss_ce: 0.007825
2022-01-16 01:27:57,236 iteration 6281 : loss : 0.024742, loss_ce: 0.005860
2022-01-16 01:27:58,183 iteration 6282 : loss : 0.013005, loss_ce: 0.005155
2022-01-16 01:27:59,102 iteration 6283 : loss : 0.014744, loss_ce: 0.006371
2022-01-16 01:28:00,061 iteration 6284 : loss : 0.016811, loss_ce: 0.007612
2022-01-16 01:28:01,070 iteration 6285 : loss : 0.018716, loss_ce: 0.005975
2022-01-16 01:28:01,999 iteration 6286 : loss : 0.013404, loss_ce: 0.004374
2022-01-16 01:28:02,921 iteration 6287 : loss : 0.015334, loss_ce: 0.004033
2022-01-16 01:28:03,785 iteration 6288 : loss : 0.011238, loss_ce: 0.003870
2022-01-16 01:28:04,754 iteration 6289 : loss : 0.014245, loss_ce: 0.006323
2022-01-16 01:28:04,754 Training Data Eval:
2022-01-16 01:28:09,293   Average segmentation loss on training set: 0.0086
2022-01-16 01:28:09,293 Validation Data Eval:
2022-01-16 01:28:10,786   Average segmentation loss on validation set: 0.0850
2022-01-16 01:28:11,781 iteration 6290 : loss : 0.025794, loss_ce: 0.012218
 92%|██████████████████████████▊  | 370/400 [1:49:04<09:18, 18.61s/it]2022-01-16 01:28:12,792 iteration 6291 : loss : 0.010529, loss_ce: 0.004181
2022-01-16 01:28:13,748 iteration 6292 : loss : 0.017424, loss_ce: 0.007098
2022-01-16 01:28:14,739 iteration 6293 : loss : 0.024432, loss_ce: 0.011439
2022-01-16 01:28:15,742 iteration 6294 : loss : 0.019112, loss_ce: 0.005424
2022-01-16 01:28:16,698 iteration 6295 : loss : 0.016944, loss_ce: 0.007667
2022-01-16 01:28:17,734 iteration 6296 : loss : 0.018718, loss_ce: 0.006491
2022-01-16 01:28:18,710 iteration 6297 : loss : 0.023524, loss_ce: 0.008875
2022-01-16 01:28:19,718 iteration 6298 : loss : 0.028980, loss_ce: 0.010002
2022-01-16 01:28:20,668 iteration 6299 : loss : 0.015578, loss_ce: 0.005573
2022-01-16 01:28:21,595 iteration 6300 : loss : 0.016271, loss_ce: 0.005345
2022-01-16 01:28:22,517 iteration 6301 : loss : 0.015069, loss_ce: 0.009484
2022-01-16 01:28:23,491 iteration 6302 : loss : 0.027408, loss_ce: 0.012304
2022-01-16 01:28:24,349 iteration 6303 : loss : 0.013166, loss_ce: 0.002977
2022-01-16 01:28:25,223 iteration 6304 : loss : 0.014852, loss_ce: 0.003852
2022-01-16 01:28:26,199 iteration 6305 : loss : 0.016242, loss_ce: 0.006883
2022-01-16 01:28:27,128 iteration 6306 : loss : 0.033809, loss_ce: 0.006502
2022-01-16 01:28:28,072 iteration 6307 : loss : 0.012110, loss_ce: 0.005576
 93%|██████████████████████████▉  | 371/400 [1:49:21<08:39, 17.91s/it]2022-01-16 01:28:29,038 iteration 6308 : loss : 0.014567, loss_ce: 0.003196
2022-01-16 01:28:30,006 iteration 6309 : loss : 0.021783, loss_ce: 0.008752
2022-01-16 01:28:30,945 iteration 6310 : loss : 0.017311, loss_ce: 0.008368
2022-01-16 01:28:31,916 iteration 6311 : loss : 0.011224, loss_ce: 0.004729
2022-01-16 01:28:32,898 iteration 6312 : loss : 0.026855, loss_ce: 0.010455
2022-01-16 01:28:33,930 iteration 6313 : loss : 0.021396, loss_ce: 0.009434
2022-01-16 01:28:34,878 iteration 6314 : loss : 0.014012, loss_ce: 0.004994
2022-01-16 01:28:35,791 iteration 6315 : loss : 0.013337, loss_ce: 0.004732
2022-01-16 01:28:36,738 iteration 6316 : loss : 0.016917, loss_ce: 0.005922
2022-01-16 01:28:37,675 iteration 6317 : loss : 0.013153, loss_ce: 0.003601
2022-01-16 01:28:38,695 iteration 6318 : loss : 0.021307, loss_ce: 0.008813
2022-01-16 01:28:39,672 iteration 6319 : loss : 0.012126, loss_ce: 0.004811
2022-01-16 01:28:40,610 iteration 6320 : loss : 0.033565, loss_ce: 0.010051
2022-01-16 01:28:41,621 iteration 6321 : loss : 0.022294, loss_ce: 0.010854
2022-01-16 01:28:42,643 iteration 6322 : loss : 0.018882, loss_ce: 0.009864
2022-01-16 01:28:43,761 iteration 6323 : loss : 0.017033, loss_ce: 0.005180
2022-01-16 01:28:44,811 iteration 6324 : loss : 0.022380, loss_ce: 0.010772
 93%|██████████████████████████▉  | 372/400 [1:49:37<08:11, 17.56s/it]2022-01-16 01:28:45,874 iteration 6325 : loss : 0.020133, loss_ce: 0.005962
2022-01-16 01:28:46,803 iteration 6326 : loss : 0.016013, loss_ce: 0.007756
2022-01-16 01:28:47,753 iteration 6327 : loss : 0.015183, loss_ce: 0.005308
2022-01-16 01:28:48,774 iteration 6328 : loss : 0.011812, loss_ce: 0.005574
2022-01-16 01:28:49,661 iteration 6329 : loss : 0.014294, loss_ce: 0.007052
2022-01-16 01:28:50,602 iteration 6330 : loss : 0.015272, loss_ce: 0.005959
2022-01-16 01:28:51,623 iteration 6331 : loss : 0.016387, loss_ce: 0.006825
2022-01-16 01:28:52,618 iteration 6332 : loss : 0.013095, loss_ce: 0.003703
2022-01-16 01:28:53,579 iteration 6333 : loss : 0.011668, loss_ce: 0.005470
2022-01-16 01:28:54,534 iteration 6334 : loss : 0.033129, loss_ce: 0.007600
2022-01-16 01:28:55,589 iteration 6335 : loss : 0.013954, loss_ce: 0.005308
2022-01-16 01:28:56,516 iteration 6336 : loss : 0.014146, loss_ce: 0.005659
2022-01-16 01:28:57,502 iteration 6337 : loss : 0.018469, loss_ce: 0.005720
2022-01-16 01:28:58,469 iteration 6338 : loss : 0.019742, loss_ce: 0.006287
2022-01-16 01:28:59,424 iteration 6339 : loss : 0.014978, loss_ce: 0.005363
2022-01-16 01:29:00,382 iteration 6340 : loss : 0.016988, loss_ce: 0.008111
2022-01-16 01:29:01,252 iteration 6341 : loss : 0.010754, loss_ce: 0.003763
 93%|███████████████████████████  | 373/400 [1:49:54<07:45, 17.22s/it]2022-01-16 01:29:02,323 iteration 6342 : loss : 0.016260, loss_ce: 0.004605
2022-01-16 01:29:03,261 iteration 6343 : loss : 0.012858, loss_ce: 0.004927
2022-01-16 01:29:04,195 iteration 6344 : loss : 0.015794, loss_ce: 0.004619
2022-01-16 01:29:05,119 iteration 6345 : loss : 0.023173, loss_ce: 0.003002
2022-01-16 01:29:06,091 iteration 6346 : loss : 0.024743, loss_ce: 0.007692
2022-01-16 01:29:07,052 iteration 6347 : loss : 0.016308, loss_ce: 0.006291
2022-01-16 01:29:07,907 iteration 6348 : loss : 0.009804, loss_ce: 0.004119
2022-01-16 01:29:08,873 iteration 6349 : loss : 0.017979, loss_ce: 0.007813
2022-01-16 01:29:09,956 iteration 6350 : loss : 0.021527, loss_ce: 0.007301
2022-01-16 01:29:10,979 iteration 6351 : loss : 0.014907, loss_ce: 0.006306
2022-01-16 01:29:11,940 iteration 6352 : loss : 0.020855, loss_ce: 0.007205
2022-01-16 01:29:12,909 iteration 6353 : loss : 0.016490, loss_ce: 0.006593
2022-01-16 01:29:13,863 iteration 6354 : loss : 0.016597, loss_ce: 0.007377
2022-01-16 01:29:14,797 iteration 6355 : loss : 0.021043, loss_ce: 0.008036
2022-01-16 01:29:15,821 iteration 6356 : loss : 0.018961, loss_ce: 0.005133
2022-01-16 01:29:16,746 iteration 6357 : loss : 0.018159, loss_ce: 0.006662
2022-01-16 01:29:17,823 iteration 6358 : loss : 0.024262, loss_ce: 0.010004
 94%|███████████████████████████  | 374/400 [1:50:10<07:22, 17.03s/it]2022-01-16 01:29:18,914 iteration 6359 : loss : 0.026422, loss_ce: 0.005997
2022-01-16 01:29:19,820 iteration 6360 : loss : 0.015413, loss_ce: 0.006148
2022-01-16 01:29:20,810 iteration 6361 : loss : 0.013921, loss_ce: 0.004444
2022-01-16 01:29:21,808 iteration 6362 : loss : 0.016851, loss_ce: 0.007330
2022-01-16 01:29:22,833 iteration 6363 : loss : 0.018042, loss_ce: 0.006975
2022-01-16 01:29:23,754 iteration 6364 : loss : 0.012540, loss_ce: 0.003336
2022-01-16 01:29:24,728 iteration 6365 : loss : 0.014627, loss_ce: 0.007536
2022-01-16 01:29:25,793 iteration 6366 : loss : 0.015429, loss_ce: 0.005899
2022-01-16 01:29:26,884 iteration 6367 : loss : 0.017937, loss_ce: 0.006399
2022-01-16 01:29:27,903 iteration 6368 : loss : 0.020439, loss_ce: 0.007650
2022-01-16 01:29:28,872 iteration 6369 : loss : 0.011000, loss_ce: 0.004596
2022-01-16 01:29:29,846 iteration 6370 : loss : 0.019286, loss_ce: 0.007327
2022-01-16 01:29:30,923 iteration 6371 : loss : 0.022499, loss_ce: 0.008019
2022-01-16 01:29:31,843 iteration 6372 : loss : 0.010381, loss_ce: 0.004307
2022-01-16 01:29:32,754 iteration 6373 : loss : 0.012653, loss_ce: 0.004733
2022-01-16 01:29:33,724 iteration 6374 : loss : 0.018196, loss_ce: 0.007202
2022-01-16 01:29:33,724 Training Data Eval:
2022-01-16 01:29:38,257   Average segmentation loss on training set: 0.0085
2022-01-16 01:29:38,257 Validation Data Eval:
2022-01-16 01:29:39,741   Average segmentation loss on validation set: 0.0786
2022-01-16 01:29:40,709 iteration 6375 : loss : 0.024247, loss_ce: 0.007970
 94%|███████████████████████████▏ | 375/400 [1:50:33<07:49, 18.78s/it]2022-01-16 01:29:41,769 iteration 6376 : loss : 0.019569, loss_ce: 0.005858
2022-01-16 01:29:42,746 iteration 6377 : loss : 0.013658, loss_ce: 0.004919
2022-01-16 01:29:43,601 iteration 6378 : loss : 0.011337, loss_ce: 0.004844
2022-01-16 01:29:44,547 iteration 6379 : loss : 0.015826, loss_ce: 0.004374
2022-01-16 01:29:45,468 iteration 6380 : loss : 0.013949, loss_ce: 0.005009
2022-01-16 01:29:46,380 iteration 6381 : loss : 0.010990, loss_ce: 0.003413
2022-01-16 01:29:47,233 iteration 6382 : loss : 0.012134, loss_ce: 0.004199
2022-01-16 01:29:48,231 iteration 6383 : loss : 0.016266, loss_ce: 0.005996
2022-01-16 01:29:49,149 iteration 6384 : loss : 0.012731, loss_ce: 0.004781
2022-01-16 01:29:50,134 iteration 6385 : loss : 0.027839, loss_ce: 0.008148
2022-01-16 01:29:51,147 iteration 6386 : loss : 0.014541, loss_ce: 0.004765
2022-01-16 01:29:52,212 iteration 6387 : loss : 0.021482, loss_ce: 0.008874
2022-01-16 01:29:53,212 iteration 6388 : loss : 0.015068, loss_ce: 0.006709
2022-01-16 01:29:54,045 iteration 6389 : loss : 0.012034, loss_ce: 0.004202
2022-01-16 01:29:54,999 iteration 6390 : loss : 0.016518, loss_ce: 0.007676
2022-01-16 01:29:55,904 iteration 6391 : loss : 0.013796, loss_ce: 0.007997
2022-01-16 01:29:56,931 iteration 6392 : loss : 0.017815, loss_ce: 0.004918
 94%|███████████████████████████▎ | 376/400 [1:50:50<07:12, 18.02s/it]2022-01-16 01:29:57,945 iteration 6393 : loss : 0.016748, loss_ce: 0.006253
2022-01-16 01:29:58,959 iteration 6394 : loss : 0.018166, loss_ce: 0.006679
2022-01-16 01:29:59,902 iteration 6395 : loss : 0.013060, loss_ce: 0.004344
2022-01-16 01:30:00,853 iteration 6396 : loss : 0.012048, loss_ce: 0.004038
2022-01-16 01:30:01,830 iteration 6397 : loss : 0.020350, loss_ce: 0.009664
2022-01-16 01:30:02,823 iteration 6398 : loss : 0.016878, loss_ce: 0.006549
2022-01-16 01:30:03,782 iteration 6399 : loss : 0.019931, loss_ce: 0.006489
2022-01-16 01:30:04,726 iteration 6400 : loss : 0.012027, loss_ce: 0.005140
2022-01-16 01:30:05,714 iteration 6401 : loss : 0.013743, loss_ce: 0.005358
2022-01-16 01:30:06,653 iteration 6402 : loss : 0.022163, loss_ce: 0.012550
2022-01-16 01:30:07,699 iteration 6403 : loss : 0.027488, loss_ce: 0.013566
2022-01-16 01:30:08,635 iteration 6404 : loss : 0.012519, loss_ce: 0.005339
2022-01-16 01:30:09,557 iteration 6405 : loss : 0.020909, loss_ce: 0.005938
2022-01-16 01:30:10,680 iteration 6406 : loss : 0.025702, loss_ce: 0.006350
2022-01-16 01:30:11,675 iteration 6407 : loss : 0.024356, loss_ce: 0.006324
2022-01-16 01:30:12,523 iteration 6408 : loss : 0.011567, loss_ce: 0.003853
2022-01-16 01:30:13,464 iteration 6409 : loss : 0.017279, loss_ce: 0.007810
 94%|███████████████████████████▎ | 377/400 [1:51:06<06:44, 17.57s/it]2022-01-16 01:30:14,443 iteration 6410 : loss : 0.013121, loss_ce: 0.004465
2022-01-16 01:30:15,428 iteration 6411 : loss : 0.019318, loss_ce: 0.007515
2022-01-16 01:30:16,414 iteration 6412 : loss : 0.013330, loss_ce: 0.004767
2022-01-16 01:30:17,351 iteration 6413 : loss : 0.014765, loss_ce: 0.006254
2022-01-16 01:30:18,273 iteration 6414 : loss : 0.012138, loss_ce: 0.004810
2022-01-16 01:30:19,171 iteration 6415 : loss : 0.012109, loss_ce: 0.004315
2022-01-16 01:30:20,133 iteration 6416 : loss : 0.014773, loss_ce: 0.005390
2022-01-16 01:30:21,020 iteration 6417 : loss : 0.012597, loss_ce: 0.004629
2022-01-16 01:30:21,942 iteration 6418 : loss : 0.012483, loss_ce: 0.005526
2022-01-16 01:30:22,998 iteration 6419 : loss : 0.019146, loss_ce: 0.008218
2022-01-16 01:30:24,035 iteration 6420 : loss : 0.019843, loss_ce: 0.004758
2022-01-16 01:30:25,036 iteration 6421 : loss : 0.014377, loss_ce: 0.005496
2022-01-16 01:30:26,003 iteration 6422 : loss : 0.017104, loss_ce: 0.004831
2022-01-16 01:30:27,003 iteration 6423 : loss : 0.014298, loss_ce: 0.005470
2022-01-16 01:30:28,073 iteration 6424 : loss : 0.021780, loss_ce: 0.011118
2022-01-16 01:30:29,021 iteration 6425 : loss : 0.013429, loss_ce: 0.003928
2022-01-16 01:30:30,065 iteration 6426 : loss : 0.020971, loss_ce: 0.006396
 94%|███████████████████████████▍ | 378/400 [1:51:23<06:20, 17.28s/it]2022-01-16 01:30:31,129 iteration 6427 : loss : 0.014885, loss_ce: 0.004950
2022-01-16 01:30:32,101 iteration 6428 : loss : 0.020133, loss_ce: 0.006224
2022-01-16 01:30:33,073 iteration 6429 : loss : 0.021962, loss_ce: 0.006528
2022-01-16 01:30:34,089 iteration 6430 : loss : 0.017608, loss_ce: 0.007210
2022-01-16 01:30:34,980 iteration 6431 : loss : 0.021129, loss_ce: 0.006813
2022-01-16 01:30:35,954 iteration 6432 : loss : 0.013017, loss_ce: 0.005183
2022-01-16 01:30:36,914 iteration 6433 : loss : 0.011854, loss_ce: 0.003740
2022-01-16 01:30:37,835 iteration 6434 : loss : 0.014806, loss_ce: 0.006058
2022-01-16 01:30:38,781 iteration 6435 : loss : 0.013928, loss_ce: 0.005367
2022-01-16 01:30:39,715 iteration 6436 : loss : 0.013215, loss_ce: 0.005242
2022-01-16 01:30:40,678 iteration 6437 : loss : 0.012904, loss_ce: 0.004334
2022-01-16 01:30:41,680 iteration 6438 : loss : 0.018368, loss_ce: 0.005330
2022-01-16 01:30:42,590 iteration 6439 : loss : 0.012931, loss_ce: 0.006282
2022-01-16 01:30:43,591 iteration 6440 : loss : 0.017964, loss_ce: 0.008413
2022-01-16 01:30:44,484 iteration 6441 : loss : 0.011595, loss_ce: 0.004934
2022-01-16 01:30:45,450 iteration 6442 : loss : 0.013981, loss_ce: 0.004231
2022-01-16 01:30:46,322 iteration 6443 : loss : 0.010760, loss_ce: 0.003451
 95%|███████████████████████████▍ | 379/400 [1:51:39<05:56, 16.98s/it]2022-01-16 01:30:47,355 iteration 6444 : loss : 0.018772, loss_ce: 0.008447
2022-01-16 01:30:48,311 iteration 6445 : loss : 0.014169, loss_ce: 0.005216
2022-01-16 01:30:49,281 iteration 6446 : loss : 0.018201, loss_ce: 0.008174
2022-01-16 01:30:50,268 iteration 6447 : loss : 0.045901, loss_ce: 0.006355
2022-01-16 01:30:51,271 iteration 6448 : loss : 0.019572, loss_ce: 0.006769
2022-01-16 01:30:52,205 iteration 6449 : loss : 0.016032, loss_ce: 0.003883
2022-01-16 01:30:53,112 iteration 6450 : loss : 0.017670, loss_ce: 0.008001
2022-01-16 01:30:54,075 iteration 6451 : loss : 0.013765, loss_ce: 0.004561
2022-01-16 01:30:55,113 iteration 6452 : loss : 0.025411, loss_ce: 0.009621
2022-01-16 01:30:56,048 iteration 6453 : loss : 0.016209, loss_ce: 0.006571
2022-01-16 01:30:56,939 iteration 6454 : loss : 0.015931, loss_ce: 0.005816
2022-01-16 01:30:57,940 iteration 6455 : loss : 0.016627, loss_ce: 0.008083
2022-01-16 01:30:58,891 iteration 6456 : loss : 0.016522, loss_ce: 0.005713
2022-01-16 01:30:59,871 iteration 6457 : loss : 0.020836, loss_ce: 0.007570
2022-01-16 01:31:00,770 iteration 6458 : loss : 0.015230, loss_ce: 0.005764
2022-01-16 01:31:01,707 iteration 6459 : loss : 0.011270, loss_ce: 0.002982
2022-01-16 01:31:01,707 Training Data Eval:
2022-01-16 01:31:06,245   Average segmentation loss on training set: 0.0083
2022-01-16 01:31:06,245 Validation Data Eval:
2022-01-16 01:31:07,723   Average segmentation loss on validation set: 0.0855
2022-01-16 01:31:08,722 iteration 6460 : loss : 0.018130, loss_ce: 0.008766
 95%|███████████████████████████▌ | 380/400 [1:52:01<06:12, 18.60s/it]2022-01-16 01:31:09,809 iteration 6461 : loss : 0.022770, loss_ce: 0.007282
2022-01-16 01:31:10,739 iteration 6462 : loss : 0.010632, loss_ce: 0.004293
2022-01-16 01:31:11,759 iteration 6463 : loss : 0.026541, loss_ce: 0.012120
2022-01-16 01:31:12,722 iteration 6464 : loss : 0.019630, loss_ce: 0.006835
2022-01-16 01:31:13,726 iteration 6465 : loss : 0.020584, loss_ce: 0.007807
2022-01-16 01:31:14,630 iteration 6466 : loss : 0.013378, loss_ce: 0.004269
2022-01-16 01:31:15,561 iteration 6467 : loss : 0.013610, loss_ce: 0.004967
2022-01-16 01:31:16,588 iteration 6468 : loss : 0.016936, loss_ce: 0.006429
2022-01-16 01:31:17,529 iteration 6469 : loss : 0.013110, loss_ce: 0.005451
2022-01-16 01:31:18,447 iteration 6470 : loss : 0.013566, loss_ce: 0.004220
2022-01-16 01:31:19,407 iteration 6471 : loss : 0.015664, loss_ce: 0.006007
2022-01-16 01:31:20,374 iteration 6472 : loss : 0.026950, loss_ce: 0.007814
2022-01-16 01:31:21,292 iteration 6473 : loss : 0.013944, loss_ce: 0.004641
2022-01-16 01:31:22,320 iteration 6474 : loss : 0.011264, loss_ce: 0.005249
2022-01-16 01:31:23,309 iteration 6475 : loss : 0.020678, loss_ce: 0.010751
2022-01-16 01:31:24,147 iteration 6476 : loss : 0.011913, loss_ce: 0.004574
2022-01-16 01:31:25,207 iteration 6477 : loss : 0.018297, loss_ce: 0.007154
 95%|███████████████████████████▌ | 381/400 [1:52:18<05:41, 17.96s/it]2022-01-16 01:31:26,291 iteration 6478 : loss : 0.019460, loss_ce: 0.005992
2022-01-16 01:31:27,229 iteration 6479 : loss : 0.020064, loss_ce: 0.006199
2022-01-16 01:31:28,172 iteration 6480 : loss : 0.017044, loss_ce: 0.007877
2022-01-16 01:31:29,162 iteration 6481 : loss : 0.015131, loss_ce: 0.006470
2022-01-16 01:31:30,043 iteration 6482 : loss : 0.012117, loss_ce: 0.004039
2022-01-16 01:31:31,036 iteration 6483 : loss : 0.020730, loss_ce: 0.005449
2022-01-16 01:31:31,947 iteration 6484 : loss : 0.015348, loss_ce: 0.005696
2022-01-16 01:31:32,894 iteration 6485 : loss : 0.023188, loss_ce: 0.009362
2022-01-16 01:31:33,907 iteration 6486 : loss : 0.013818, loss_ce: 0.004466
2022-01-16 01:31:34,980 iteration 6487 : loss : 0.026615, loss_ce: 0.012304
2022-01-16 01:31:35,981 iteration 6488 : loss : 0.016240, loss_ce: 0.006150
2022-01-16 01:31:36,900 iteration 6489 : loss : 0.011972, loss_ce: 0.006032
2022-01-16 01:31:37,877 iteration 6490 : loss : 0.014870, loss_ce: 0.003775
2022-01-16 01:31:38,811 iteration 6491 : loss : 0.018583, loss_ce: 0.009294
2022-01-16 01:31:39,861 iteration 6492 : loss : 0.015411, loss_ce: 0.005638
2022-01-16 01:31:40,847 iteration 6493 : loss : 0.018619, loss_ce: 0.006759
2022-01-16 01:31:41,695 iteration 6494 : loss : 0.009131, loss_ce: 0.003509
 96%|███████████████████████████▋ | 382/400 [1:52:34<05:15, 17.52s/it]2022-01-16 01:31:42,680 iteration 6495 : loss : 0.014700, loss_ce: 0.005775
2022-01-16 01:31:43,641 iteration 6496 : loss : 0.026258, loss_ce: 0.006826
2022-01-16 01:31:44,639 iteration 6497 : loss : 0.011767, loss_ce: 0.004177
2022-01-16 01:31:45,640 iteration 6498 : loss : 0.018845, loss_ce: 0.006704
2022-01-16 01:31:46,638 iteration 6499 : loss : 0.017606, loss_ce: 0.008174
2022-01-16 01:31:47,582 iteration 6500 : loss : 0.012602, loss_ce: 0.004639
2022-01-16 01:31:48,563 iteration 6501 : loss : 0.015937, loss_ce: 0.005932
2022-01-16 01:31:49,583 iteration 6502 : loss : 0.016085, loss_ce: 0.008964
2022-01-16 01:31:50,510 iteration 6503 : loss : 0.009538, loss_ce: 0.002368
2022-01-16 01:31:51,409 iteration 6504 : loss : 0.011835, loss_ce: 0.004080
2022-01-16 01:31:52,226 iteration 6505 : loss : 0.011402, loss_ce: 0.005295
2022-01-16 01:31:53,159 iteration 6506 : loss : 0.017697, loss_ce: 0.004536
2022-01-16 01:31:54,192 iteration 6507 : loss : 0.021547, loss_ce: 0.011735
2022-01-16 01:31:55,189 iteration 6508 : loss : 0.014771, loss_ce: 0.005542
2022-01-16 01:31:56,165 iteration 6509 : loss : 0.015411, loss_ce: 0.006286
2022-01-16 01:31:57,143 iteration 6510 : loss : 0.017235, loss_ce: 0.006624
2022-01-16 01:31:58,018 iteration 6511 : loss : 0.012037, loss_ce: 0.004300
 96%|███████████████████████████▊ | 383/400 [1:52:51<04:51, 17.17s/it]2022-01-16 01:31:59,006 iteration 6512 : loss : 0.013983, loss_ce: 0.004682
2022-01-16 01:31:59,968 iteration 6513 : loss : 0.020025, loss_ce: 0.006773
2022-01-16 01:32:01,040 iteration 6514 : loss : 0.012433, loss_ce: 0.003578
2022-01-16 01:32:02,067 iteration 6515 : loss : 0.020409, loss_ce: 0.007307
2022-01-16 01:32:03,063 iteration 6516 : loss : 0.016742, loss_ce: 0.008209
2022-01-16 01:32:04,015 iteration 6517 : loss : 0.015008, loss_ce: 0.003408
2022-01-16 01:32:04,979 iteration 6518 : loss : 0.011600, loss_ce: 0.003955
2022-01-16 01:32:05,931 iteration 6519 : loss : 0.019337, loss_ce: 0.006631
2022-01-16 01:32:06,942 iteration 6520 : loss : 0.017190, loss_ce: 0.005821
2022-01-16 01:32:07,860 iteration 6521 : loss : 0.017775, loss_ce: 0.007839
2022-01-16 01:32:08,833 iteration 6522 : loss : 0.011732, loss_ce: 0.004616
2022-01-16 01:32:09,714 iteration 6523 : loss : 0.010337, loss_ce: 0.004131
2022-01-16 01:32:10,726 iteration 6524 : loss : 0.017452, loss_ce: 0.007993
2022-01-16 01:32:11,700 iteration 6525 : loss : 0.021117, loss_ce: 0.008673
2022-01-16 01:32:12,660 iteration 6526 : loss : 0.016608, loss_ce: 0.006903
2022-01-16 01:32:13,542 iteration 6527 : loss : 0.012183, loss_ce: 0.005335
2022-01-16 01:32:14,450 iteration 6528 : loss : 0.012662, loss_ce: 0.003798
 96%|███████████████████████████▊ | 384/400 [1:53:07<04:31, 16.94s/it]2022-01-16 01:32:15,518 iteration 6529 : loss : 0.020477, loss_ce: 0.006371
2022-01-16 01:32:16,502 iteration 6530 : loss : 0.012566, loss_ce: 0.003997
2022-01-16 01:32:17,392 iteration 6531 : loss : 0.013091, loss_ce: 0.003809
2022-01-16 01:32:18,380 iteration 6532 : loss : 0.014358, loss_ce: 0.005471
2022-01-16 01:32:19,257 iteration 6533 : loss : 0.008889, loss_ce: 0.003358
2022-01-16 01:32:20,222 iteration 6534 : loss : 0.017072, loss_ce: 0.007815
2022-01-16 01:32:21,196 iteration 6535 : loss : 0.021239, loss_ce: 0.008542
2022-01-16 01:32:22,186 iteration 6536 : loss : 0.012571, loss_ce: 0.004043
2022-01-16 01:32:23,165 iteration 6537 : loss : 0.016175, loss_ce: 0.005319
2022-01-16 01:32:24,154 iteration 6538 : loss : 0.021654, loss_ce: 0.006279
2022-01-16 01:32:25,163 iteration 6539 : loss : 0.018648, loss_ce: 0.008018
2022-01-16 01:32:26,033 iteration 6540 : loss : 0.011223, loss_ce: 0.004765
2022-01-16 01:32:26,948 iteration 6541 : loss : 0.018669, loss_ce: 0.011215
2022-01-16 01:32:28,003 iteration 6542 : loss : 0.011673, loss_ce: 0.003704
2022-01-16 01:32:28,927 iteration 6543 : loss : 0.012532, loss_ce: 0.004642
2022-01-16 01:32:29,926 iteration 6544 : loss : 0.016291, loss_ce: 0.006420
2022-01-16 01:32:29,926 Training Data Eval:
2022-01-16 01:32:34,467   Average segmentation loss on training set: 0.0080
2022-01-16 01:32:34,467 Validation Data Eval:
2022-01-16 01:32:35,967   Average segmentation loss on validation set: 0.0931
2022-01-16 01:32:37,010 iteration 6545 : loss : 0.015505, loss_ce: 0.006197
 96%|███████████████████████████▉ | 385/400 [1:53:30<04:39, 18.63s/it]2022-01-16 01:32:38,188 iteration 6546 : loss : 0.015107, loss_ce: 0.006113
2022-01-16 01:32:39,144 iteration 6547 : loss : 0.014439, loss_ce: 0.006542
2022-01-16 01:32:40,141 iteration 6548 : loss : 0.014704, loss_ce: 0.005486
2022-01-16 01:32:41,064 iteration 6549 : loss : 0.016059, loss_ce: 0.005832
2022-01-16 01:32:42,068 iteration 6550 : loss : 0.014524, loss_ce: 0.004970
2022-01-16 01:32:43,104 iteration 6551 : loss : 0.021907, loss_ce: 0.009146
2022-01-16 01:32:44,184 iteration 6552 : loss : 0.018791, loss_ce: 0.007479
2022-01-16 01:32:45,290 iteration 6553 : loss : 0.023549, loss_ce: 0.008475
2022-01-16 01:32:46,285 iteration 6554 : loss : 0.022073, loss_ce: 0.008896
2022-01-16 01:32:47,256 iteration 6555 : loss : 0.013137, loss_ce: 0.005945
2022-01-16 01:32:48,220 iteration 6556 : loss : 0.015178, loss_ce: 0.004171
2022-01-16 01:32:49,071 iteration 6557 : loss : 0.008978, loss_ce: 0.003690
2022-01-16 01:32:50,019 iteration 6558 : loss : 0.016872, loss_ce: 0.005869
2022-01-16 01:32:50,889 iteration 6559 : loss : 0.011541, loss_ce: 0.004227
2022-01-16 01:32:51,842 iteration 6560 : loss : 0.014497, loss_ce: 0.007280
2022-01-16 01:32:52,845 iteration 6561 : loss : 0.013705, loss_ce: 0.003985
2022-01-16 01:32:53,756 iteration 6562 : loss : 0.012942, loss_ce: 0.004714
 96%|███████████████████████████▉ | 386/400 [1:53:46<04:12, 18.07s/it]2022-01-16 01:32:54,924 iteration 6563 : loss : 0.024331, loss_ce: 0.011877
2022-01-16 01:32:55,864 iteration 6564 : loss : 0.014392, loss_ce: 0.006042
2022-01-16 01:32:56,767 iteration 6565 : loss : 0.017524, loss_ce: 0.004278
2022-01-16 01:32:57,657 iteration 6566 : loss : 0.011941, loss_ce: 0.004786
2022-01-16 01:32:58,525 iteration 6567 : loss : 0.012268, loss_ce: 0.004838
2022-01-16 01:32:59,451 iteration 6568 : loss : 0.013988, loss_ce: 0.006295
2022-01-16 01:33:00,408 iteration 6569 : loss : 0.015866, loss_ce: 0.006005
2022-01-16 01:33:01,309 iteration 6570 : loss : 0.010069, loss_ce: 0.004625
2022-01-16 01:33:02,244 iteration 6571 : loss : 0.014302, loss_ce: 0.004415
2022-01-16 01:33:03,113 iteration 6572 : loss : 0.011248, loss_ce: 0.004857
2022-01-16 01:33:04,139 iteration 6573 : loss : 0.022932, loss_ce: 0.007923
2022-01-16 01:33:05,175 iteration 6574 : loss : 0.012033, loss_ce: 0.004451
2022-01-16 01:33:06,225 iteration 6575 : loss : 0.028523, loss_ce: 0.011104
2022-01-16 01:33:07,143 iteration 6576 : loss : 0.012469, loss_ce: 0.005459
2022-01-16 01:33:08,125 iteration 6577 : loss : 0.022771, loss_ce: 0.006003
2022-01-16 01:33:09,030 iteration 6578 : loss : 0.012479, loss_ce: 0.004897
2022-01-16 01:33:09,997 iteration 6579 : loss : 0.016808, loss_ce: 0.005971
 97%|████████████████████████████ | 387/400 [1:54:03<03:47, 17.52s/it]2022-01-16 01:33:11,035 iteration 6580 : loss : 0.018197, loss_ce: 0.005171
2022-01-16 01:33:11,969 iteration 6581 : loss : 0.016196, loss_ce: 0.004800
2022-01-16 01:33:13,001 iteration 6582 : loss : 0.017232, loss_ce: 0.006591
2022-01-16 01:33:13,968 iteration 6583 : loss : 0.014695, loss_ce: 0.006248
2022-01-16 01:33:14,951 iteration 6584 : loss : 0.017758, loss_ce: 0.007249
2022-01-16 01:33:15,972 iteration 6585 : loss : 0.022415, loss_ce: 0.008142
2022-01-16 01:33:16,964 iteration 6586 : loss : 0.018042, loss_ce: 0.005241
2022-01-16 01:33:17,914 iteration 6587 : loss : 0.011444, loss_ce: 0.004768
2022-01-16 01:33:18,890 iteration 6588 : loss : 0.017219, loss_ce: 0.007141
2022-01-16 01:33:19,781 iteration 6589 : loss : 0.012743, loss_ce: 0.005288
2022-01-16 01:33:20,807 iteration 6590 : loss : 0.018985, loss_ce: 0.008056
2022-01-16 01:33:21,833 iteration 6591 : loss : 0.015751, loss_ce: 0.006354
2022-01-16 01:33:22,757 iteration 6592 : loss : 0.011466, loss_ce: 0.004526
2022-01-16 01:33:23,798 iteration 6593 : loss : 0.029444, loss_ce: 0.007033
2022-01-16 01:33:24,747 iteration 6594 : loss : 0.017918, loss_ce: 0.010172
2022-01-16 01:33:25,683 iteration 6595 : loss : 0.023430, loss_ce: 0.007334
2022-01-16 01:33:26,704 iteration 6596 : loss : 0.023143, loss_ce: 0.007225
 97%|████████████████████████████▏| 388/400 [1:54:19<03:27, 17.28s/it]2022-01-16 01:33:27,728 iteration 6597 : loss : 0.019332, loss_ce: 0.008458
2022-01-16 01:33:28,632 iteration 6598 : loss : 0.016552, loss_ce: 0.004674
2022-01-16 01:33:29,609 iteration 6599 : loss : 0.013233, loss_ce: 0.005343
2022-01-16 01:33:30,443 iteration 6600 : loss : 0.009969, loss_ce: 0.004112
2022-01-16 01:33:31,383 iteration 6601 : loss : 0.015550, loss_ce: 0.005669
2022-01-16 01:33:32,292 iteration 6602 : loss : 0.012120, loss_ce: 0.004191
2022-01-16 01:33:33,241 iteration 6603 : loss : 0.017285, loss_ce: 0.006232
2022-01-16 01:33:34,108 iteration 6604 : loss : 0.009631, loss_ce: 0.004079
2022-01-16 01:33:35,067 iteration 6605 : loss : 0.012436, loss_ce: 0.004266
2022-01-16 01:33:36,057 iteration 6606 : loss : 0.018424, loss_ce: 0.008787
2022-01-16 01:33:37,048 iteration 6607 : loss : 0.019132, loss_ce: 0.008365
2022-01-16 01:33:38,036 iteration 6608 : loss : 0.012047, loss_ce: 0.005190
2022-01-16 01:33:38,943 iteration 6609 : loss : 0.013317, loss_ce: 0.004807
2022-01-16 01:33:39,867 iteration 6610 : loss : 0.014150, loss_ce: 0.006153
2022-01-16 01:33:40,788 iteration 6611 : loss : 0.011336, loss_ce: 0.002672
2022-01-16 01:33:41,789 iteration 6612 : loss : 0.021211, loss_ce: 0.008581
2022-01-16 01:33:42,624 iteration 6613 : loss : 0.012192, loss_ce: 0.004646
 97%|████████████████████████████▏| 389/400 [1:54:35<03:05, 16.87s/it]2022-01-16 01:33:43,646 iteration 6614 : loss : 0.016211, loss_ce: 0.006417
2022-01-16 01:33:44,619 iteration 6615 : loss : 0.014469, loss_ce: 0.006625
2022-01-16 01:33:45,564 iteration 6616 : loss : 0.015391, loss_ce: 0.004392
2022-01-16 01:33:46,667 iteration 6617 : loss : 0.017540, loss_ce: 0.005843
2022-01-16 01:33:47,652 iteration 6618 : loss : 0.021019, loss_ce: 0.005992
2022-01-16 01:33:48,713 iteration 6619 : loss : 0.017589, loss_ce: 0.006711
2022-01-16 01:33:49,726 iteration 6620 : loss : 0.019037, loss_ce: 0.008314
2022-01-16 01:33:50,670 iteration 6621 : loss : 0.022826, loss_ce: 0.006944
2022-01-16 01:33:51,609 iteration 6622 : loss : 0.016092, loss_ce: 0.007770
2022-01-16 01:33:52,558 iteration 6623 : loss : 0.019533, loss_ce: 0.007242
2022-01-16 01:33:53,558 iteration 6624 : loss : 0.018517, loss_ce: 0.007503
2022-01-16 01:33:54,586 iteration 6625 : loss : 0.015532, loss_ce: 0.006125
2022-01-16 01:33:55,542 iteration 6626 : loss : 0.018307, loss_ce: 0.005110
2022-01-16 01:33:56,408 iteration 6627 : loss : 0.013746, loss_ce: 0.004250
2022-01-16 01:33:57,355 iteration 6628 : loss : 0.012255, loss_ce: 0.005740
2022-01-16 01:33:58,294 iteration 6629 : loss : 0.012094, loss_ce: 0.005696
2022-01-16 01:33:58,294 Training Data Eval:
2022-01-16 01:34:02,827   Average segmentation loss on training set: 0.0080
2022-01-16 01:34:02,827 Validation Data Eval:
2022-01-16 01:34:04,318   Average segmentation loss on validation set: 0.0883
2022-01-16 01:34:05,317 iteration 6630 : loss : 0.016011, loss_ce: 0.005372
 98%|████████████████████████████▎| 390/400 [1:54:58<03:06, 18.62s/it]2022-01-16 01:34:06,425 iteration 6631 : loss : 0.019024, loss_ce: 0.006577
2022-01-16 01:34:07,395 iteration 6632 : loss : 0.017365, loss_ce: 0.006867
2022-01-16 01:34:08,361 iteration 6633 : loss : 0.024658, loss_ce: 0.005880
2022-01-16 01:34:09,179 iteration 6634 : loss : 0.010399, loss_ce: 0.003281
2022-01-16 01:34:10,078 iteration 6635 : loss : 0.021117, loss_ce: 0.005997
2022-01-16 01:34:11,093 iteration 6636 : loss : 0.020589, loss_ce: 0.008637
2022-01-16 01:34:12,078 iteration 6637 : loss : 0.011216, loss_ce: 0.005144
2022-01-16 01:34:13,087 iteration 6638 : loss : 0.018180, loss_ce: 0.006664
2022-01-16 01:34:14,134 iteration 6639 : loss : 0.019152, loss_ce: 0.006149
2022-01-16 01:34:15,079 iteration 6640 : loss : 0.017274, loss_ce: 0.005633
2022-01-16 01:34:15,998 iteration 6641 : loss : 0.014547, loss_ce: 0.007663
2022-01-16 01:34:17,038 iteration 6642 : loss : 0.012135, loss_ce: 0.005042
2022-01-16 01:34:18,024 iteration 6643 : loss : 0.015675, loss_ce: 0.007843
2022-01-16 01:34:18,991 iteration 6644 : loss : 0.016508, loss_ce: 0.005084
2022-01-16 01:34:19,883 iteration 6645 : loss : 0.010070, loss_ce: 0.004584
2022-01-16 01:34:20,814 iteration 6646 : loss : 0.013347, loss_ce: 0.005348
2022-01-16 01:34:21,666 iteration 6647 : loss : 0.011475, loss_ce: 0.003691
 98%|████████████████████████████▎| 391/400 [1:55:14<02:41, 17.93s/it]2022-01-16 01:34:22,638 iteration 6648 : loss : 0.019049, loss_ce: 0.006376
2022-01-16 01:34:23,659 iteration 6649 : loss : 0.018054, loss_ce: 0.006937
2022-01-16 01:34:24,546 iteration 6650 : loss : 0.013618, loss_ce: 0.004952
2022-01-16 01:34:25,454 iteration 6651 : loss : 0.016776, loss_ce: 0.005080
2022-01-16 01:34:26,492 iteration 6652 : loss : 0.023746, loss_ce: 0.008205
2022-01-16 01:34:27,515 iteration 6653 : loss : 0.013731, loss_ce: 0.005906
2022-01-16 01:34:28,434 iteration 6654 : loss : 0.011767, loss_ce: 0.004129
2022-01-16 01:34:29,413 iteration 6655 : loss : 0.020770, loss_ce: 0.008211
2022-01-16 01:34:30,406 iteration 6656 : loss : 0.012248, loss_ce: 0.004586
2022-01-16 01:34:31,469 iteration 6657 : loss : 0.017720, loss_ce: 0.006787
2022-01-16 01:34:32,454 iteration 6658 : loss : 0.028845, loss_ce: 0.010498
2022-01-16 01:34:33,466 iteration 6659 : loss : 0.025688, loss_ce: 0.008867
2022-01-16 01:34:34,383 iteration 6660 : loss : 0.012367, loss_ce: 0.004226
2022-01-16 01:34:35,254 iteration 6661 : loss : 0.009800, loss_ce: 0.003571
2022-01-16 01:34:36,228 iteration 6662 : loss : 0.012910, loss_ce: 0.004701
2022-01-16 01:34:37,249 iteration 6663 : loss : 0.021278, loss_ce: 0.007690
2022-01-16 01:34:38,197 iteration 6664 : loss : 0.020138, loss_ce: 0.005915
 98%|████████████████████████████▍| 392/400 [1:55:31<02:20, 17.52s/it]2022-01-16 01:34:39,244 iteration 6665 : loss : 0.014468, loss_ce: 0.005063
2022-01-16 01:34:40,228 iteration 6666 : loss : 0.017161, loss_ce: 0.006315
2022-01-16 01:34:41,149 iteration 6667 : loss : 0.016331, loss_ce: 0.005847
2022-01-16 01:34:41,990 iteration 6668 : loss : 0.009347, loss_ce: 0.003855
2022-01-16 01:34:42,962 iteration 6669 : loss : 0.018142, loss_ce: 0.005630
2022-01-16 01:34:43,856 iteration 6670 : loss : 0.013794, loss_ce: 0.004710
2022-01-16 01:34:44,895 iteration 6671 : loss : 0.011917, loss_ce: 0.005154
2022-01-16 01:34:45,853 iteration 6672 : loss : 0.015488, loss_ce: 0.007546
2022-01-16 01:34:46,899 iteration 6673 : loss : 0.019938, loss_ce: 0.010968
2022-01-16 01:34:47,928 iteration 6674 : loss : 0.022965, loss_ce: 0.008655
2022-01-16 01:34:48,859 iteration 6675 : loss : 0.026194, loss_ce: 0.011926
2022-01-16 01:34:49,738 iteration 6676 : loss : 0.013013, loss_ce: 0.004566
2022-01-16 01:34:50,718 iteration 6677 : loss : 0.011473, loss_ce: 0.002826
2022-01-16 01:34:51,778 iteration 6678 : loss : 0.015297, loss_ce: 0.006677
2022-01-16 01:34:52,766 iteration 6679 : loss : 0.018665, loss_ce: 0.007945
2022-01-16 01:34:53,708 iteration 6680 : loss : 0.022040, loss_ce: 0.010372
2022-01-16 01:34:54,612 iteration 6681 : loss : 0.013662, loss_ce: 0.004559
 98%|████████████████████████████▍| 393/400 [1:55:47<02:00, 17.19s/it]2022-01-16 01:34:55,633 iteration 6682 : loss : 0.015505, loss_ce: 0.004790
2022-01-16 01:34:56,639 iteration 6683 : loss : 0.017542, loss_ce: 0.005801
2022-01-16 01:34:57,624 iteration 6684 : loss : 0.039994, loss_ce: 0.004594
2022-01-16 01:34:58,562 iteration 6685 : loss : 0.012959, loss_ce: 0.005311
2022-01-16 01:34:59,541 iteration 6686 : loss : 0.012892, loss_ce: 0.004290
2022-01-16 01:35:00,512 iteration 6687 : loss : 0.015994, loss_ce: 0.006430
2022-01-16 01:35:01,485 iteration 6688 : loss : 0.017147, loss_ce: 0.005537
2022-01-16 01:35:02,410 iteration 6689 : loss : 0.013546, loss_ce: 0.005723
2022-01-16 01:35:03,444 iteration 6690 : loss : 0.015483, loss_ce: 0.005610
2022-01-16 01:35:04,340 iteration 6691 : loss : 0.010930, loss_ce: 0.003776
2022-01-16 01:35:05,238 iteration 6692 : loss : 0.010709, loss_ce: 0.005162
2022-01-16 01:35:06,212 iteration 6693 : loss : 0.017586, loss_ce: 0.007390
2022-01-16 01:35:07,092 iteration 6694 : loss : 0.009883, loss_ce: 0.004248
2022-01-16 01:35:08,017 iteration 6695 : loss : 0.012215, loss_ce: 0.003205
2022-01-16 01:35:08,960 iteration 6696 : loss : 0.013468, loss_ce: 0.006804
2022-01-16 01:35:09,918 iteration 6697 : loss : 0.017042, loss_ce: 0.006119
2022-01-16 01:35:10,784 iteration 6698 : loss : 0.015431, loss_ce: 0.005241
 98%|████████████████████████████▌| 394/400 [1:56:03<01:41, 16.88s/it]2022-01-16 01:35:11,820 iteration 6699 : loss : 0.014409, loss_ce: 0.004227
2022-01-16 01:35:12,839 iteration 6700 : loss : 0.017248, loss_ce: 0.007655
2022-01-16 01:35:13,885 iteration 6701 : loss : 0.027339, loss_ce: 0.008604
2022-01-16 01:35:14,807 iteration 6702 : loss : 0.012650, loss_ce: 0.004105
2022-01-16 01:35:15,871 iteration 6703 : loss : 0.018442, loss_ce: 0.006009
2022-01-16 01:35:16,842 iteration 6704 : loss : 0.017321, loss_ce: 0.007946
2022-01-16 01:35:17,738 iteration 6705 : loss : 0.014056, loss_ce: 0.004872
2022-01-16 01:35:18,661 iteration 6706 : loss : 0.017529, loss_ce: 0.006244
2022-01-16 01:35:19,610 iteration 6707 : loss : 0.013243, loss_ce: 0.004657
2022-01-16 01:35:20,475 iteration 6708 : loss : 0.010635, loss_ce: 0.003118
2022-01-16 01:35:21,374 iteration 6709 : loss : 0.013700, loss_ce: 0.003674
2022-01-16 01:35:22,344 iteration 6710 : loss : 0.014023, loss_ce: 0.005439
2022-01-16 01:35:23,293 iteration 6711 : loss : 0.013625, loss_ce: 0.005899
2022-01-16 01:35:24,294 iteration 6712 : loss : 0.013997, loss_ce: 0.005236
2022-01-16 01:35:25,219 iteration 6713 : loss : 0.012772, loss_ce: 0.004210
2022-01-16 01:35:26,161 iteration 6714 : loss : 0.013432, loss_ce: 0.005781
2022-01-16 01:35:26,162 Training Data Eval:
2022-01-16 01:35:30,730   Average segmentation loss on training set: 0.0081
2022-01-16 01:35:30,731 Validation Data Eval:
2022-01-16 01:35:32,228   Average segmentation loss on validation set: 0.0868
2022-01-16 01:35:33,139 iteration 6715 : loss : 0.009367, loss_ce: 0.002722
 99%|████████████████████████████▋| 395/400 [1:56:26<01:32, 18.52s/it]2022-01-16 01:35:34,070 iteration 6716 : loss : 0.011940, loss_ce: 0.003927
2022-01-16 01:35:35,058 iteration 6717 : loss : 0.018123, loss_ce: 0.005689
2022-01-16 01:35:36,086 iteration 6718 : loss : 0.030712, loss_ce: 0.017873
2022-01-16 01:35:37,095 iteration 6719 : loss : 0.020348, loss_ce: 0.007194
2022-01-16 01:35:38,085 iteration 6720 : loss : 0.021915, loss_ce: 0.004219
2022-01-16 01:35:39,081 iteration 6721 : loss : 0.014071, loss_ce: 0.005716
2022-01-16 01:35:40,020 iteration 6722 : loss : 0.015734, loss_ce: 0.007224
2022-01-16 01:35:40,989 iteration 6723 : loss : 0.017534, loss_ce: 0.006614
2022-01-16 01:35:41,890 iteration 6724 : loss : 0.012907, loss_ce: 0.005812
2022-01-16 01:35:42,836 iteration 6725 : loss : 0.010399, loss_ce: 0.003461
2022-01-16 01:35:43,703 iteration 6726 : loss : 0.011449, loss_ce: 0.004207
2022-01-16 01:35:44,765 iteration 6727 : loss : 0.023438, loss_ce: 0.008928
2022-01-16 01:35:45,677 iteration 6728 : loss : 0.015670, loss_ce: 0.006097
2022-01-16 01:35:46,686 iteration 6729 : loss : 0.015128, loss_ce: 0.005166
2022-01-16 01:35:47,757 iteration 6730 : loss : 0.018484, loss_ce: 0.007664
2022-01-16 01:35:48,769 iteration 6731 : loss : 0.018681, loss_ce: 0.006425
2022-01-16 01:35:49,731 iteration 6732 : loss : 0.015738, loss_ce: 0.008552
 99%|████████████████████████████▋| 396/400 [1:56:42<01:11, 17.94s/it]2022-01-16 01:35:50,695 iteration 6733 : loss : 0.012839, loss_ce: 0.006218
2022-01-16 01:35:51,639 iteration 6734 : loss : 0.016048, loss_ce: 0.004019
2022-01-16 01:35:52,632 iteration 6735 : loss : 0.015447, loss_ce: 0.005335
2022-01-16 01:35:53,571 iteration 6736 : loss : 0.013532, loss_ce: 0.006834
2022-01-16 01:35:54,465 iteration 6737 : loss : 0.012544, loss_ce: 0.006178
2022-01-16 01:35:55,348 iteration 6738 : loss : 0.012919, loss_ce: 0.004093
2022-01-16 01:35:56,305 iteration 6739 : loss : 0.012041, loss_ce: 0.005448
2022-01-16 01:35:57,298 iteration 6740 : loss : 0.025613, loss_ce: 0.009719
2022-01-16 01:35:58,273 iteration 6741 : loss : 0.018538, loss_ce: 0.007322
2022-01-16 01:35:59,204 iteration 6742 : loss : 0.012936, loss_ce: 0.005934
2022-01-16 01:36:00,094 iteration 6743 : loss : 0.012668, loss_ce: 0.002956
2022-01-16 01:36:01,097 iteration 6744 : loss : 0.015356, loss_ce: 0.006523
2022-01-16 01:36:02,047 iteration 6745 : loss : 0.013666, loss_ce: 0.006627
2022-01-16 01:36:02,935 iteration 6746 : loss : 0.008612, loss_ce: 0.002481
2022-01-16 01:36:03,842 iteration 6747 : loss : 0.014626, loss_ce: 0.005176
2022-01-16 01:36:04,819 iteration 6748 : loss : 0.012643, loss_ce: 0.005298
2022-01-16 01:36:05,757 iteration 6749 : loss : 0.016061, loss_ce: 0.005221
 99%|████████████████████████████▊| 397/400 [1:56:58<00:52, 17.37s/it]2022-01-16 01:36:06,771 iteration 6750 : loss : 0.010091, loss_ce: 0.004442
2022-01-16 01:36:07,796 iteration 6751 : loss : 0.011701, loss_ce: 0.004558
2022-01-16 01:36:08,673 iteration 6752 : loss : 0.012737, loss_ce: 0.003881
2022-01-16 01:36:09,631 iteration 6753 : loss : 0.015256, loss_ce: 0.006341
2022-01-16 01:36:10,616 iteration 6754 : loss : 0.016538, loss_ce: 0.006136
2022-01-16 01:36:11,533 iteration 6755 : loss : 0.013197, loss_ce: 0.004327
2022-01-16 01:36:12,451 iteration 6756 : loss : 0.013579, loss_ce: 0.006095
2022-01-16 01:36:13,486 iteration 6757 : loss : 0.018202, loss_ce: 0.005703
2022-01-16 01:36:14,416 iteration 6758 : loss : 0.016761, loss_ce: 0.007558
2022-01-16 01:36:15,395 iteration 6759 : loss : 0.011314, loss_ce: 0.004849
2022-01-16 01:36:16,435 iteration 6760 : loss : 0.021024, loss_ce: 0.003990
2022-01-16 01:36:17,397 iteration 6761 : loss : 0.014007, loss_ce: 0.005316
2022-01-16 01:36:18,330 iteration 6762 : loss : 0.018384, loss_ce: 0.006207
2022-01-16 01:36:19,347 iteration 6763 : loss : 0.016210, loss_ce: 0.006669
2022-01-16 01:36:20,271 iteration 6764 : loss : 0.013592, loss_ce: 0.006041
2022-01-16 01:36:21,297 iteration 6765 : loss : 0.016573, loss_ce: 0.006359
2022-01-16 01:36:22,224 iteration 6766 : loss : 0.010714, loss_ce: 0.004766
100%|████████████████████████████▊| 398/400 [1:57:15<00:34, 17.09s/it]2022-01-16 01:36:23,238 iteration 6767 : loss : 0.016832, loss_ce: 0.005147
2022-01-16 01:36:24,291 iteration 6768 : loss : 0.014934, loss_ce: 0.005113
2022-01-16 01:36:25,272 iteration 6769 : loss : 0.013090, loss_ce: 0.005988
2022-01-16 01:36:26,209 iteration 6770 : loss : 0.014616, loss_ce: 0.007283
2022-01-16 01:36:27,277 iteration 6771 : loss : 0.023306, loss_ce: 0.005002
2022-01-16 01:36:28,206 iteration 6772 : loss : 0.012063, loss_ce: 0.004394
2022-01-16 01:36:29,035 iteration 6773 : loss : 0.011020, loss_ce: 0.003470
2022-01-16 01:36:30,029 iteration 6774 : loss : 0.021439, loss_ce: 0.005969
2022-01-16 01:36:31,023 iteration 6775 : loss : 0.017425, loss_ce: 0.005260
2022-01-16 01:36:31,975 iteration 6776 : loss : 0.014585, loss_ce: 0.004532
2022-01-16 01:36:33,022 iteration 6777 : loss : 0.023729, loss_ce: 0.013219
2022-01-16 01:36:33,967 iteration 6778 : loss : 0.011526, loss_ce: 0.003738
2022-01-16 01:36:35,021 iteration 6779 : loss : 0.015338, loss_ce: 0.006116
2022-01-16 01:36:36,000 iteration 6780 : loss : 0.012742, loss_ce: 0.005360
2022-01-16 01:36:37,011 iteration 6781 : loss : 0.014387, loss_ce: 0.006052
2022-01-16 01:36:38,028 iteration 6782 : loss : 0.013188, loss_ce: 0.005036
2022-01-16 01:36:38,964 iteration 6783 : loss : 0.013756, loss_ce: 0.004551
100%|████████████████████████████▉| 399/400 [1:57:32<00:16, 16.99s/it]2022-01-16 01:36:40,135 iteration 6784 : loss : 0.029982, loss_ce: 0.009411
2022-01-16 01:36:41,135 iteration 6785 : loss : 0.017494, loss_ce: 0.006088
2022-01-16 01:36:42,050 iteration 6786 : loss : 0.012830, loss_ce: 0.006344
2022-01-16 01:36:42,977 iteration 6787 : loss : 0.012817, loss_ce: 0.004675
2022-01-16 01:36:43,958 iteration 6788 : loss : 0.015378, loss_ce: 0.006105
2022-01-16 01:36:44,928 iteration 6789 : loss : 0.017629, loss_ce: 0.005111
2022-01-16 01:36:45,872 iteration 6790 : loss : 0.011151, loss_ce: 0.004611
2022-01-16 01:36:46,861 iteration 6791 : loss : 0.017978, loss_ce: 0.007932
2022-01-16 01:36:47,775 iteration 6792 : loss : 0.013401, loss_ce: 0.006161
2022-01-16 01:36:48,815 iteration 6793 : loss : 0.033878, loss_ce: 0.012536
2022-01-16 01:36:49,783 iteration 6794 : loss : 0.020668, loss_ce: 0.007269
2022-01-16 01:36:50,788 iteration 6795 : loss : 0.014842, loss_ce: 0.006363
2022-01-16 01:36:51,812 iteration 6796 : loss : 0.023065, loss_ce: 0.014777
2022-01-16 01:36:52,684 iteration 6797 : loss : 0.011409, loss_ce: 0.003610
2022-01-16 01:36:53,685 iteration 6798 : loss : 0.014905, loss_ce: 0.004693
2022-01-16 01:36:54,754 iteration 6799 : loss : 0.019747, loss_ce: 0.008654
2022-01-16 01:36:54,754 Training Data Eval:
2022-01-16 01:36:59,405   Average segmentation loss on training set: 0.0078
2022-01-16 01:36:59,405 Validation Data Eval:
2022-01-16 01:37:00,943   Average segmentation loss on validation set: 0.0843
2022-01-16 01:37:01,867 iteration 6800 : loss : 0.010703, loss_ce: 0.002711
100%|█████████████████████████████| 400/400 [1:57:54<00:00, 18.77s/it]100%|█████████████████████████████| 400/400 [1:57:54<00:00, 17.69s/it]
