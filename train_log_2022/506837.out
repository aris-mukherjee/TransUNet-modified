2022-01-14 11:34:34,105 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:34:34,106 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:34:34,106 ============================================================
2022-01-14 11:34:34,106 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:34:34,106 ============================================================
2022-01-14 11:34:34,106 Loading data...
2022-01-14 11:34:34,106 Reading NCI - RUNMC images...
2022-01-14 11:34:34,106 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-14 11:34:34,107 Already preprocessed this configuration. Loading now!
2022-01-14 11:34:34,123 Training Images: (256, 256, 286)
2022-01-14 11:34:34,123 Training Labels: (256, 256, 286)
2022-01-14 11:34:34,123 Validation Images: (256, 256, 98)
2022-01-14 11:34:34,123 Validation Labels: (256, 256, 98)
2022-01-14 11:34:34,123 ============================================================
2022-01-14 11:34:34,160 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-14 11:34:36,808 iteration 1 : loss : 1.132674, loss_ce: 1.473716
2022-01-14 11:34:37,687 iteration 2 : loss : 1.052549, loss_ce: 1.351070
2022-01-14 11:34:38,651 iteration 3 : loss : 0.959295, loss_ce: 1.199588
2022-01-14 11:34:39,557 iteration 4 : loss : 0.940510, loss_ce: 1.135244
2022-01-14 11:34:40,391 iteration 5 : loss : 0.906061, loss_ce: 1.062730
2022-01-14 11:34:41,276 iteration 6 : loss : 0.866918, loss_ce: 1.005084
2022-01-14 11:34:42,195 iteration 7 : loss : 0.830985, loss_ce: 0.950411
2022-01-14 11:34:43,174 iteration 8 : loss : 0.796609, loss_ce: 0.891186
2022-01-14 11:34:44,020 iteration 9 : loss : 0.771766, loss_ce: 0.833159
2022-01-14 11:34:44,869 iteration 10 : loss : 0.725243, loss_ce: 0.772543
2022-01-14 11:34:45,704 iteration 11 : loss : 0.698281, loss_ce: 0.716101
2022-01-14 11:34:46,593 iteration 12 : loss : 0.663199, loss_ce: 0.674192
2022-01-14 11:34:47,533 iteration 13 : loss : 0.618048, loss_ce: 0.627614
2022-01-14 11:34:48,368 iteration 14 : loss : 0.591350, loss_ce: 0.576818
2022-01-14 11:34:49,301 iteration 15 : loss : 0.574151, loss_ce: 0.536600
2022-01-14 11:34:50,175 iteration 16 : loss : 0.557464, loss_ce: 0.503726
2022-01-14 11:34:51,039 iteration 17 : loss : 0.512219, loss_ce: 0.469488
  0%|                               | 1/400 [00:16<1:52:42, 16.95s/it]2022-01-14 11:34:51,974 iteration 18 : loss : 0.500020, loss_ce: 0.418407
2022-01-14 11:34:52,875 iteration 19 : loss : 0.475043, loss_ce: 0.392455
2022-01-14 11:34:53,760 iteration 20 : loss : 0.443673, loss_ce: 0.362272
2022-01-14 11:34:54,721 iteration 21 : loss : 0.437424, loss_ce: 0.338133
2022-01-14 11:34:55,594 iteration 22 : loss : 0.413604, loss_ce: 0.313094
2022-01-14 11:34:56,494 iteration 23 : loss : 0.383236, loss_ce: 0.273172
2022-01-14 11:34:57,328 iteration 24 : loss : 0.383940, loss_ce: 0.278417
2022-01-14 11:34:58,124 iteration 25 : loss : 0.384773, loss_ce: 0.251389
2022-01-14 11:34:58,962 iteration 26 : loss : 0.377730, loss_ce: 0.235344
2022-01-14 11:34:59,852 iteration 27 : loss : 0.328396, loss_ce: 0.215555
2022-01-14 11:35:00,725 iteration 28 : loss : 0.341491, loss_ce: 0.203516
2022-01-14 11:35:01,736 iteration 29 : loss : 0.327044, loss_ce: 0.200466
2022-01-14 11:35:02,670 iteration 30 : loss : 0.329776, loss_ce: 0.185052
2022-01-14 11:35:03,515 iteration 31 : loss : 0.292754, loss_ce: 0.173149
2022-01-14 11:35:04,381 iteration 32 : loss : 0.311504, loss_ce: 0.177058
2022-01-14 11:35:05,335 iteration 33 : loss : 0.287950, loss_ce: 0.172099
2022-01-14 11:35:06,197 iteration 34 : loss : 0.283218, loss_ce: 0.147918
  0%|▏                              | 2/400 [00:32<1:45:21, 15.88s/it]2022-01-14 11:35:07,181 iteration 35 : loss : 0.262745, loss_ce: 0.158380
2022-01-14 11:35:08,078 iteration 36 : loss : 0.290804, loss_ce: 0.162733
2022-01-14 11:35:09,011 iteration 37 : loss : 0.275591, loss_ce: 0.163097
2022-01-14 11:35:10,004 iteration 38 : loss : 0.255164, loss_ce: 0.132513
2022-01-14 11:35:10,907 iteration 39 : loss : 0.349314, loss_ce: 0.157592
2022-01-14 11:35:11,840 iteration 40 : loss : 0.266345, loss_ce: 0.154716
2022-01-14 11:35:12,684 iteration 41 : loss : 0.263462, loss_ce: 0.121194
2022-01-14 11:35:13,696 iteration 42 : loss : 0.260459, loss_ce: 0.135157
2022-01-14 11:35:14,539 iteration 43 : loss : 0.285996, loss_ce: 0.119340
2022-01-14 11:35:15,457 iteration 44 : loss : 0.244987, loss_ce: 0.116189
2022-01-14 11:35:16,397 iteration 45 : loss : 0.355898, loss_ce: 0.162262
2022-01-14 11:35:17,211 iteration 46 : loss : 0.245196, loss_ce: 0.111438
2022-01-14 11:35:18,088 iteration 47 : loss : 0.300978, loss_ce: 0.126438
2022-01-14 11:35:19,007 iteration 48 : loss : 0.209472, loss_ce: 0.106280
2022-01-14 11:35:19,913 iteration 49 : loss : 0.294076, loss_ce: 0.125416
2022-01-14 11:35:20,858 iteration 50 : loss : 0.237158, loss_ce: 0.096933
2022-01-14 11:35:21,769 iteration 51 : loss : 0.249902, loss_ce: 0.128216
  1%|▏                              | 3/400 [00:47<1:44:09, 15.74s/it]2022-01-14 11:35:22,645 iteration 52 : loss : 0.276877, loss_ce: 0.130953
2022-01-14 11:35:23,461 iteration 53 : loss : 0.255480, loss_ce: 0.122256
2022-01-14 11:35:24,382 iteration 54 : loss : 0.186089, loss_ce: 0.093713
2022-01-14 11:35:26,857 iteration 55 : loss : 0.332784, loss_ce: 0.144450
2022-01-14 11:35:27,788 iteration 56 : loss : 0.260579, loss_ce: 0.121886
2022-01-14 11:35:28,715 iteration 57 : loss : 0.230849, loss_ce: 0.096337
2022-01-14 11:35:29,626 iteration 58 : loss : 0.260220, loss_ce: 0.129620
2022-01-14 11:35:30,514 iteration 59 : loss : 0.240157, loss_ce: 0.100122
2022-01-14 11:35:31,514 iteration 60 : loss : 0.288488, loss_ce: 0.128455
2022-01-14 11:35:32,486 iteration 61 : loss : 0.265546, loss_ce: 0.117137
2022-01-14 11:35:33,388 iteration 62 : loss : 0.283283, loss_ce: 0.114985
2022-01-14 11:35:34,218 iteration 63 : loss : 0.226229, loss_ce: 0.112118
2022-01-14 11:35:35,141 iteration 64 : loss : 0.298145, loss_ce: 0.162728
2022-01-14 11:35:36,021 iteration 65 : loss : 0.292245, loss_ce: 0.126095
2022-01-14 11:35:36,960 iteration 66 : loss : 0.248135, loss_ce: 0.119078
2022-01-14 11:35:37,813 iteration 67 : loss : 0.306672, loss_ce: 0.164320
2022-01-14 11:35:38,698 iteration 68 : loss : 0.280982, loss_ce: 0.127218
  1%|▎                              | 4/400 [01:04<1:47:00, 16.21s/it]2022-01-14 11:35:39,654 iteration 69 : loss : 0.252980, loss_ce: 0.109109
2022-01-14 11:35:40,575 iteration 70 : loss : 0.307177, loss_ce: 0.145978
2022-01-14 11:35:41,427 iteration 71 : loss : 0.229792, loss_ce: 0.097554
2022-01-14 11:35:42,375 iteration 72 : loss : 0.258220, loss_ce: 0.103681
2022-01-14 11:35:43,264 iteration 73 : loss : 0.248565, loss_ce: 0.116308
2022-01-14 11:35:44,233 iteration 74 : loss : 0.255312, loss_ce: 0.109281
2022-01-14 11:35:45,141 iteration 75 : loss : 0.263517, loss_ce: 0.141751
2022-01-14 11:35:46,095 iteration 76 : loss : 0.235887, loss_ce: 0.107514
2022-01-14 11:35:47,071 iteration 77 : loss : 0.230745, loss_ce: 0.097045
2022-01-14 11:35:48,022 iteration 78 : loss : 0.206330, loss_ce: 0.111533
2022-01-14 11:35:48,879 iteration 79 : loss : 0.196708, loss_ce: 0.081972
2022-01-14 11:35:49,831 iteration 80 : loss : 0.299823, loss_ce: 0.123412
2022-01-14 11:35:50,723 iteration 81 : loss : 0.241457, loss_ce: 0.106851
2022-01-14 11:35:51,620 iteration 82 : loss : 0.262074, loss_ce: 0.137543
2022-01-14 11:35:52,576 iteration 83 : loss : 0.232270, loss_ce: 0.103532
2022-01-14 11:35:53,444 iteration 84 : loss : 0.253895, loss_ce: 0.126965
2022-01-14 11:35:53,444 Training Data Eval:
2022-01-14 11:35:57,705   Average segmentation loss on training set: 0.7556
2022-01-14 11:35:57,705 Validation Data Eval:
