2021-12-10 10:21:23,386 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_no_da_r3/i2i2l/
2021-12-10 10:21:23,386 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_no_da_r3/i2i2l/
2021-12-10 10:21:23,386 ============================================================
2021-12-10 10:21:23,386 EXPERIMENT NAME: trRUNMC_cv1_no_da_r3/i2i2l/
2021-12-10 10:21:23,387 ============================================================
2021-12-10 10:21:23,387 Loading data...
2021-12-10 10:21:23,387 Reading NCI - RUNMC images...
2021-12-10 10:21:23,387 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-10 10:21:23,388 Already preprocessed this configuration. Loading now!
2021-12-10 10:21:23,419 Training Images: (256, 256, 286)
2021-12-10 10:21:23,419 Training Labels: (256, 256, 286)
2021-12-10 10:21:23,419 Validation Images: (256, 256, 98)
2021-12-10 10:21:23,419 Validation Labels: (256, 256, 98)
2021-12-10 10:21:23,419 ============================================================
2021-12-10 10:21:23,454 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-10 10:21:25,939 iteration 1 : loss : 0.901086, loss_ce: 1.071506
2021-12-10 10:21:27,275 iteration 2 : loss : 0.846292, loss_ce: 0.986390
2021-12-10 10:21:28,609 iteration 3 : loss : 0.788706, loss_ce: 0.889212
2021-12-10 10:21:29,941 iteration 4 : loss : 0.740232, loss_ce: 0.802984
2021-12-10 10:21:31,281 iteration 5 : loss : 0.683188, loss_ce: 0.723329
2021-12-10 10:21:32,619 iteration 6 : loss : 0.643362, loss_ce: 0.651648
2021-12-10 10:21:33,961 iteration 7 : loss : 0.599637, loss_ce: 0.598988
2021-12-10 10:21:35,309 iteration 8 : loss : 0.576502, loss_ce: 0.534331
2021-12-10 10:21:36,658 iteration 9 : loss : 0.538157, loss_ce: 0.529084
2021-12-10 10:21:38,005 iteration 10 : loss : 0.536951, loss_ce: 0.467295
2021-12-10 10:21:39,353 iteration 11 : loss : 0.473814, loss_ce: 0.426640
2021-12-10 10:21:40,708 iteration 12 : loss : 0.462092, loss_ce: 0.389283
2021-12-10 10:21:42,061 iteration 13 : loss : 0.447596, loss_ce: 0.359166
2021-12-10 10:21:43,418 iteration 14 : loss : 0.434517, loss_ce: 0.334567
2021-12-10 10:21:44,775 iteration 15 : loss : 0.386801, loss_ce: 0.295434
2021-12-10 10:21:46,132 iteration 16 : loss : 0.402020, loss_ce: 0.288660
2021-12-10 10:21:47,494 iteration 17 : loss : 0.363267, loss_ce: 0.264333
  0%|                               | 1/400 [00:24<2:40:25, 24.13s/it]2021-12-10 10:21:48,936 iteration 18 : loss : 0.339664, loss_ce: 0.239792
2021-12-10 10:21:50,294 iteration 19 : loss : 0.323976, loss_ce: 0.204943
2021-12-10 10:21:51,651 iteration 20 : loss : 0.345229, loss_ce: 0.209125
2021-12-10 10:21:53,011 iteration 21 : loss : 0.313485, loss_ce: 0.185003
2021-12-10 10:21:54,363 iteration 22 : loss : 0.300885, loss_ce: 0.192643
2021-12-10 10:21:55,728 iteration 23 : loss : 0.293346, loss_ce: 0.174154
2021-12-10 10:21:57,091 iteration 24 : loss : 0.307078, loss_ce: 0.185202
2021-12-10 10:21:58,459 iteration 25 : loss : 0.280331, loss_ce: 0.153610
2021-12-10 10:21:59,826 iteration 26 : loss : 0.263471, loss_ce: 0.153607
2021-12-10 10:22:01,197 iteration 27 : loss : 0.286660, loss_ce: 0.157151
2021-12-10 10:22:02,560 iteration 28 : loss : 0.264470, loss_ce: 0.128277
2021-12-10 10:22:03,927 iteration 29 : loss : 0.282955, loss_ce: 0.145900
2021-12-10 10:22:05,291 iteration 30 : loss : 0.238853, loss_ce: 0.128039
2021-12-10 10:22:06,658 iteration 31 : loss : 0.247087, loss_ce: 0.122140
2021-12-10 10:22:08,022 iteration 32 : loss : 0.269803, loss_ce: 0.140936
2021-12-10 10:22:09,385 iteration 33 : loss : 0.235147, loss_ce: 0.112374
2021-12-10 10:22:10,754 iteration 34 : loss : 0.212700, loss_ce: 0.102432
  0%|▏                              | 2/400 [00:47<2:36:35, 23.61s/it]2021-12-10 10:22:12,193 iteration 35 : loss : 0.248190, loss_ce: 0.113486
2021-12-10 10:22:13,563 iteration 36 : loss : 0.261228, loss_ce: 0.111987
2021-12-10 10:22:14,931 iteration 37 : loss : 0.206016, loss_ce: 0.091364
2021-12-10 10:22:16,301 iteration 38 : loss : 0.251596, loss_ce: 0.118285
2021-12-10 10:22:17,670 iteration 39 : loss : 0.241933, loss_ce: 0.098975
2021-12-10 10:22:19,037 iteration 40 : loss : 0.199366, loss_ce: 0.090992
2021-12-10 10:22:20,406 iteration 41 : loss : 0.273223, loss_ce: 0.127916
2021-12-10 10:22:21,776 iteration 42 : loss : 0.231690, loss_ce: 0.110174
2021-12-10 10:22:23,146 iteration 43 : loss : 0.244940, loss_ce: 0.105950
2021-12-10 10:22:24,516 iteration 44 : loss : 0.221519, loss_ce: 0.092556
2021-12-10 10:22:25,890 iteration 45 : loss : 0.215960, loss_ce: 0.091025
2021-12-10 10:22:27,255 iteration 46 : loss : 0.236558, loss_ce: 0.101785
2021-12-10 10:22:28,627 iteration 47 : loss : 0.197121, loss_ce: 0.085396
2021-12-10 10:22:29,998 iteration 48 : loss : 0.206624, loss_ce: 0.082702
2021-12-10 10:22:31,370 iteration 49 : loss : 0.183921, loss_ce: 0.073254
2021-12-10 10:22:32,739 iteration 50 : loss : 0.198021, loss_ce: 0.096773
2021-12-10 10:22:34,110 iteration 51 : loss : 0.223948, loss_ce: 0.106419
  1%|▏                              | 3/400 [01:10<2:35:28, 23.50s/it]2021-12-10 10:22:35,561 iteration 52 : loss : 0.203610, loss_ce: 0.094251
2021-12-10 10:22:36,927 iteration 53 : loss : 0.209514, loss_ce: 0.097115
2021-12-10 10:22:38,299 iteration 54 : loss : 0.215573, loss_ce: 0.084723
2021-12-10 10:22:39,674 iteration 55 : loss : 0.171558, loss_ce: 0.069128
2021-12-10 10:22:41,045 iteration 56 : loss : 0.218803, loss_ce: 0.082324
2021-12-10 10:22:42,414 iteration 57 : loss : 0.252440, loss_ce: 0.085034
2021-12-10 10:22:43,790 iteration 58 : loss : 0.250641, loss_ce: 0.095100
2021-12-10 10:22:45,168 iteration 59 : loss : 0.226658, loss_ce: 0.085986
2021-12-10 10:22:46,546 iteration 60 : loss : 0.221665, loss_ce: 0.091468
2021-12-10 10:22:47,920 iteration 61 : loss : 0.185136, loss_ce: 0.078306
2021-12-10 10:22:49,297 iteration 62 : loss : 0.213868, loss_ce: 0.091436
2021-12-10 10:22:50,668 iteration 63 : loss : 0.222725, loss_ce: 0.109030
2021-12-10 10:22:52,040 iteration 64 : loss : 0.268725, loss_ce: 0.114884
2021-12-10 10:22:53,415 iteration 65 : loss : 0.178767, loss_ce: 0.081331
2021-12-10 10:22:54,791 iteration 66 : loss : 0.242084, loss_ce: 0.085332
2021-12-10 10:22:56,159 iteration 67 : loss : 0.238602, loss_ce: 0.093482
2021-12-10 10:22:57,532 iteration 68 : loss : 0.243903, loss_ce: 0.091131
  1%|▎                              | 4/400 [01:34<2:34:52, 23.47s/it]2021-12-10 10:22:58,983 iteration 69 : loss : 0.213003, loss_ce: 0.080203
2021-12-10 10:23:00,355 iteration 70 : loss : 0.232314, loss_ce: 0.090454
2021-12-10 10:23:01,729 iteration 71 : loss : 0.207205, loss_ce: 0.086996
2021-12-10 10:23:03,103 iteration 72 : loss : 0.193065, loss_ce: 0.079820
2021-12-10 10:23:04,474 iteration 73 : loss : 0.218191, loss_ce: 0.090835
2021-12-10 10:23:05,843 iteration 74 : loss : 0.205017, loss_ce: 0.085492
2021-12-10 10:23:07,221 iteration 75 : loss : 0.222975, loss_ce: 0.089384
2021-12-10 10:23:08,601 iteration 76 : loss : 0.197401, loss_ce: 0.075772
2021-12-10 10:23:10,032 iteration 77 : loss : 0.173032, loss_ce: 0.070433
2021-12-10 10:23:11,498 iteration 78 : loss : 0.215741, loss_ce: 0.073011
2021-12-10 10:23:12,967 iteration 79 : loss : 0.207118, loss_ce: 0.071758
2021-12-10 10:23:14,449 iteration 80 : loss : 0.199057, loss_ce: 0.070289
2021-12-10 10:23:15,922 iteration 81 : loss : 0.175021, loss_ce: 0.067823
2021-12-10 10:23:17,395 iteration 82 : loss : 0.215104, loss_ce: 0.067130
2021-12-10 10:23:18,886 iteration 83 : loss : 0.219921, loss_ce: 0.098894
2021-12-10 10:23:20,379 iteration 84 : loss : 0.176537, loss_ce: 0.068540
2021-12-10 10:23:20,379 Training Data Eval:
2021-12-10 10:23:28,683   Average segmentation loss on training set: 0.1941
2021-12-10 10:23:28,684 Validation Data Eval:
2021-12-10 10:23:31,610   Average segmentation loss on validation set: 0.2049
2021-12-10 10:23:37,454 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:23:38,857 iteration 85 : loss : 0.186977, loss_ce: 0.071471
  1%|▍                              | 5/400 [02:15<3:16:53, 29.91s/it]2021-12-10 10:23:40,305 iteration 86 : loss : 0.181833, loss_ce: 0.069541
2021-12-10 10:23:41,673 iteration 87 : loss : 0.172912, loss_ce: 0.076640
2021-12-10 10:23:43,042 iteration 88 : loss : 0.192852, loss_ce: 0.077402
2021-12-10 10:23:44,418 iteration 89 : loss : 0.185388, loss_ce: 0.078721
2021-12-10 10:23:45,794 iteration 90 : loss : 0.234887, loss_ce: 0.100834
2021-12-10 10:23:47,167 iteration 91 : loss : 0.182250, loss_ce: 0.078420
2021-12-10 10:23:48,541 iteration 92 : loss : 0.222286, loss_ce: 0.076237
2021-12-10 10:23:49,916 iteration 93 : loss : 0.194176, loss_ce: 0.063324
2021-12-10 10:23:51,318 iteration 94 : loss : 0.187200, loss_ce: 0.064142
2021-12-10 10:23:52,788 iteration 95 : loss : 0.172672, loss_ce: 0.060736
2021-12-10 10:23:54,284 iteration 96 : loss : 0.201783, loss_ce: 0.078500
2021-12-10 10:23:55,793 iteration 97 : loss : 0.194736, loss_ce: 0.071392
2021-12-10 10:23:57,306 iteration 98 : loss : 0.199454, loss_ce: 0.070484
2021-12-10 10:23:58,802 iteration 99 : loss : 0.216000, loss_ce: 0.084625
2021-12-10 10:24:00,299 iteration 100 : loss : 0.200936, loss_ce: 0.086709
2021-12-10 10:24:01,779 iteration 101 : loss : 0.221063, loss_ce: 0.080117
2021-12-10 10:24:03,243 iteration 102 : loss : 0.245519, loss_ce: 0.117980
  2%|▍                              | 6/400 [02:39<3:04:03, 28.03s/it]2021-12-10 10:24:04,748 iteration 103 : loss : 0.196535, loss_ce: 0.079369
2021-12-10 10:24:06,163 iteration 104 : loss : 0.205633, loss_ce: 0.076642
2021-12-10 10:24:07,566 iteration 105 : loss : 0.186683, loss_ce: 0.079613
2021-12-10 10:24:08,960 iteration 106 : loss : 0.171694, loss_ce: 0.066999
2021-12-10 10:24:10,349 iteration 107 : loss : 0.208831, loss_ce: 0.076823
2021-12-10 10:24:11,741 iteration 108 : loss : 0.168431, loss_ce: 0.071997
2021-12-10 10:24:13,148 iteration 109 : loss : 0.180429, loss_ce: 0.060621
2021-12-10 10:24:14,568 iteration 110 : loss : 0.207947, loss_ce: 0.073199
2021-12-10 10:24:15,995 iteration 111 : loss : 0.189379, loss_ce: 0.069146
2021-12-10 10:24:17,408 iteration 112 : loss : 0.187361, loss_ce: 0.068163
2021-12-10 10:24:18,803 iteration 113 : loss : 0.176675, loss_ce: 0.056534
2021-12-10 10:24:20,188 iteration 114 : loss : 0.273380, loss_ce: 0.130494
2021-12-10 10:24:21,569 iteration 115 : loss : 0.176059, loss_ce: 0.059807
2021-12-10 10:24:22,945 iteration 116 : loss : 0.227362, loss_ce: 0.085835
2021-12-10 10:24:24,336 iteration 117 : loss : 0.170288, loss_ce: 0.053425
2021-12-10 10:24:25,730 iteration 118 : loss : 0.168244, loss_ce: 0.066449
2021-12-10 10:24:27,119 iteration 119 : loss : 0.205987, loss_ce: 0.074154
  2%|▌                              | 7/400 [03:03<2:54:40, 26.67s/it]