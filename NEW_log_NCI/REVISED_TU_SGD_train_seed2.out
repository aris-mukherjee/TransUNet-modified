2021-12-14 01:18:54,742 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-14 01:18:54,743 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-14 01:18:54,743 ============================================================
2021-12-14 01:18:54,743 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-14 01:18:54,743 ============================================================
2021-12-14 01:18:54,743 Loading data...
2021-12-14 01:18:54,743 Reading NCI - RUNMC images...
2021-12-14 01:18:54,743 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-14 01:18:54,744 Already preprocessed this configuration. Loading now!
2021-12-14 01:18:54,769 Training Images: (256, 256, 286)
2021-12-14 01:18:54,769 Training Labels: (256, 256, 286)
2021-12-14 01:18:54,769 Validation Images: (256, 256, 98)
2021-12-14 01:18:54,769 Validation Labels: (256, 256, 98)
2021-12-14 01:18:54,770 ============================================================
2021-12-14 01:18:54,813 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-14 01:18:57,489 iteration 1 : loss : 0.926682, loss_ce: 1.121993
2021-12-14 01:18:58,978 iteration 2 : loss : 0.917354, loss_ce: 1.117194
2021-12-14 01:19:00,597 iteration 3 : loss : 0.909831, loss_ce: 1.104165
2021-12-14 01:19:02,130 iteration 4 : loss : 0.908692, loss_ce: 1.077561
2021-12-14 01:19:03,574 iteration 5 : loss : 0.900479, loss_ce: 1.052654
2021-12-14 01:19:05,074 iteration 6 : loss : 0.878426, loss_ce: 1.022417
2021-12-14 01:19:06,625 iteration 7 : loss : 0.855228, loss_ce: 0.987773
2021-12-14 01:19:08,256 iteration 8 : loss : 0.832259, loss_ce: 0.949911
2021-12-14 01:19:09,713 iteration 9 : loss : 0.815867, loss_ce: 0.907222
2021-12-14 01:19:11,165 iteration 10 : loss : 0.787840, loss_ce: 0.872546
2021-12-14 01:19:12,606 iteration 11 : loss : 0.770573, loss_ce: 0.831774
2021-12-14 01:19:14,112 iteration 12 : loss : 0.737770, loss_ce: 0.794338
2021-12-14 01:19:15,694 iteration 13 : loss : 0.707112, loss_ce: 0.763847
2021-12-14 01:19:17,148 iteration 14 : loss : 0.688668, loss_ce: 0.719252
2021-12-14 01:19:18,722 iteration 15 : loss : 0.670192, loss_ce: 0.678688
2021-12-14 01:19:20,220 iteration 16 : loss : 0.651016, loss_ce: 0.647549
2021-12-14 01:19:21,692 iteration 17 : loss : 0.623243, loss_ce: 0.624754
  0%|                               | 1/400 [00:26<2:59:18, 26.96s/it]2021-12-14 01:19:23,238 iteration 18 : loss : 0.614583, loss_ce: 0.577693
2021-12-14 01:19:24,760 iteration 19 : loss : 0.589553, loss_ce: 0.548059
2021-12-14 01:19:26,266 iteration 20 : loss : 0.571027, loss_ce: 0.524412
2021-12-14 01:19:27,875 iteration 21 : loss : 0.559808, loss_ce: 0.502803
2021-12-14 01:19:29,369 iteration 22 : loss : 0.540840, loss_ce: 0.477236
2021-12-14 01:19:30,899 iteration 23 : loss : 0.525271, loss_ce: 0.443002
2021-12-14 01:19:32,331 iteration 24 : loss : 0.512953, loss_ce: 0.441460
2021-12-14 01:19:33,734 iteration 25 : loss : 0.505226, loss_ce: 0.409183
2021-12-14 01:19:35,171 iteration 26 : loss : 0.499063, loss_ce: 0.392015
2021-12-14 01:19:36,692 iteration 27 : loss : 0.479094, loss_ce: 0.380444
2021-12-14 01:19:38,170 iteration 28 : loss : 0.471892, loss_ce: 0.355021
2021-12-14 01:19:39,846 iteration 29 : loss : 0.464671, loss_ce: 0.354574
2021-12-14 01:19:41,413 iteration 30 : loss : 0.452940, loss_ce: 0.331209
2021-12-14 01:19:42,854 iteration 31 : loss : 0.448896, loss_ce: 0.336631
2021-12-14 01:19:44,333 iteration 32 : loss : 0.437928, loss_ce: 0.313444
2021-12-14 01:19:45,935 iteration 33 : loss : 0.449907, loss_ce: 0.326196
2021-12-14 01:19:47,401 iteration 34 : loss : 0.431892, loss_ce: 0.280232
  0%|▏                              | 2/400 [00:52<2:53:50, 26.21s/it]2021-12-14 01:19:49,038 iteration 35 : loss : 0.425446, loss_ce: 0.304878
2021-12-14 01:19:50,561 iteration 36 : loss : 0.417256, loss_ce: 0.284227
2021-12-14 01:19:52,129 iteration 37 : loss : 0.418394, loss_ce: 0.294009
2021-12-14 01:19:53,779 iteration 38 : loss : 0.402954, loss_ce: 0.253676
2021-12-14 01:19:55,309 iteration 39 : loss : 0.414969, loss_ce: 0.246090
2021-12-14 01:19:56,887 iteration 40 : loss : 0.411255, loss_ce: 0.283109
2021-12-14 01:19:58,336 iteration 41 : loss : 0.402922, loss_ce: 0.239200
2021-12-14 01:20:00,024 iteration 42 : loss : 0.398365, loss_ce: 0.252904
2021-12-14 01:20:01,486 iteration 43 : loss : 0.396630, loss_ce: 0.215956
2021-12-14 01:20:03,026 iteration 44 : loss : 0.391910, loss_ce: 0.228714
2021-12-14 01:20:04,596 iteration 45 : loss : 0.393391, loss_ce: 0.218919
2021-12-14 01:20:05,991 iteration 46 : loss : 0.378867, loss_ce: 0.217107
2021-12-14 01:20:07,502 iteration 47 : loss : 0.386436, loss_ce: 0.197281
2021-12-14 01:20:09,063 iteration 48 : loss : 0.372639, loss_ce: 0.225528
2021-12-14 01:20:10,599 iteration 49 : loss : 0.377829, loss_ce: 0.196300
2021-12-14 01:20:12,189 iteration 50 : loss : 0.374319, loss_ce: 0.193410
2021-12-14 01:20:13,735 iteration 51 : loss : 0.382282, loss_ce: 0.229355
  1%|▏                              | 3/400 [01:18<2:53:47, 26.27s/it]2021-12-14 01:20:15,200 iteration 52 : loss : 0.377493, loss_ce: 0.215167
2021-12-14 01:20:16,603 iteration 53 : loss : 0.372467, loss_ce: 0.213604
2021-12-14 01:20:18,151 iteration 54 : loss : 0.359835, loss_ce: 0.201730
2021-12-14 01:20:19,672 iteration 55 : loss : 0.382010, loss_ce: 0.194179
2021-12-14 01:20:21,237 iteration 56 : loss : 0.361491, loss_ce: 0.178125
2021-12-14 01:20:22,817 iteration 57 : loss : 0.356953, loss_ce: 0.173777
2021-12-14 01:20:24,349 iteration 58 : loss : 0.380460, loss_ce: 0.212428
2021-12-14 01:20:25,847 iteration 59 : loss : 0.354123, loss_ce: 0.178183
2021-12-14 01:20:27,475 iteration 60 : loss : 0.366788, loss_ce: 0.180190
2021-12-14 01:20:29,113 iteration 61 : loss : 0.352932, loss_ce: 0.189800
2021-12-14 01:20:30,636 iteration 62 : loss : 0.358341, loss_ce: 0.182449
2021-12-14 01:20:32,060 iteration 63 : loss : 0.350281, loss_ce: 0.196595
2021-12-14 01:20:33,561 iteration 64 : loss : 0.369545, loss_ce: 0.213347
2021-12-14 01:20:35,052 iteration 65 : loss : 0.356492, loss_ce: 0.165290
2021-12-14 01:20:36,616 iteration 66 : loss : 0.350265, loss_ce: 0.174520
2021-12-14 01:20:38,080 iteration 67 : loss : 0.348680, loss_ce: 0.185263
2021-12-14 01:20:39,577 iteration 68 : loss : 0.355316, loss_ce: 0.163744
  1%|▎                              | 4/400 [01:44<2:52:15, 26.10s/it]2021-12-14 01:20:41,150 iteration 69 : loss : 0.350833, loss_ce: 0.152866
2021-12-14 01:20:42,692 iteration 70 : loss : 0.366943, loss_ce: 0.193991
2021-12-14 01:20:44,154 iteration 71 : loss : 0.338487, loss_ce: 0.171468
2021-12-14 01:20:45,728 iteration 72 : loss : 0.346455, loss_ce: 0.167359
2021-12-14 01:20:47,233 iteration 73 : loss : 0.344431, loss_ce: 0.183602
2021-12-14 01:20:48,865 iteration 74 : loss : 0.340376, loss_ce: 0.173759
2021-12-14 01:20:50,400 iteration 75 : loss : 0.356335, loss_ce: 0.201642
2021-12-14 01:20:51,987 iteration 76 : loss : 0.357770, loss_ce: 0.180769
2021-12-14 01:20:53,607 iteration 77 : loss : 0.336027, loss_ce: 0.154490
2021-12-14 01:20:55,197 iteration 78 : loss : 0.330603, loss_ce: 0.182303
2021-12-14 01:20:56,665 iteration 79 : loss : 0.327322, loss_ce: 0.152481
2021-12-14 01:20:58,248 iteration 80 : loss : 0.363097, loss_ce: 0.156223
2021-12-14 01:20:59,748 iteration 81 : loss : 0.325442, loss_ce: 0.150161
2021-12-14 01:21:01,273 iteration 82 : loss : 0.345941, loss_ce: 0.177918
2021-12-14 01:21:02,867 iteration 83 : loss : 0.326704, loss_ce: 0.146429
2021-12-14 01:21:04,345 iteration 84 : loss : 0.340431, loss_ce: 0.168166
2021-12-14 01:21:04,345 Training Data Eval:
2021-12-14 01:21:11,769   Average segmentation loss on training set: 0.3403
2021-12-14 01:21:11,770 Validation Data Eval:
2021-12-14 01:21:14,336   Average segmentation loss on validation set: 0.3486
2021-12-14 01:21:19,214 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 01:21:20,800 iteration 85 : loss : 0.319442, loss_ce: 0.163159
  1%|▍                              | 5/400 [02:26<3:27:43, 31.55s/it]2021-12-14 01:21:22,357 iteration 86 : loss : 0.329059, loss_ce: 0.140686
2021-12-14 01:21:23,745 iteration 87 : loss : 0.324765, loss_ce: 0.154871
2021-12-14 01:21:25,204 iteration 88 : loss : 0.316233, loss_ce: 0.139951
2021-12-14 01:21:26,795 iteration 89 : loss : 0.313716, loss_ce: 0.153547
2021-12-14 01:21:28,242 iteration 90 : loss : 0.316262, loss_ce: 0.158180
2021-12-14 01:21:29,772 iteration 91 : loss : 0.338942, loss_ce: 0.155472
2021-12-14 01:21:31,266 iteration 92 : loss : 0.308480, loss_ce: 0.148902
2021-12-14 01:21:32,867 iteration 93 : loss : 0.314117, loss_ce: 0.146087
2021-12-14 01:21:34,457 iteration 94 : loss : 0.326068, loss_ce: 0.170853
2021-12-14 01:21:35,956 iteration 95 : loss : 0.313439, loss_ce: 0.135979
2021-12-14 01:21:37,404 iteration 96 : loss : 0.303973, loss_ce: 0.130786
2021-12-14 01:21:38,832 iteration 97 : loss : 0.298562, loss_ce: 0.132698
2021-12-14 01:21:40,322 iteration 98 : loss : 0.322216, loss_ce: 0.147715
2021-12-14 01:21:42,003 iteration 99 : loss : 0.308527, loss_ce: 0.144790
2021-12-14 01:21:43,699 iteration 100 : loss : 0.307879, loss_ce: 0.142653
2021-12-14 01:21:45,169 iteration 101 : loss : 0.351632, loss_ce: 0.167828
2021-12-14 01:21:46,672 iteration 102 : loss : 0.305656, loss_ce: 0.133190
  2%|▍                              | 6/400 [02:51<3:14:32, 29.63s/it]2021-12-14 01:21:48,271 iteration 103 : loss : 0.306744, loss_ce: 0.139345
2021-12-14 01:21:49,839 iteration 104 : loss : 0.318042, loss_ce: 0.134211
2021-12-14 01:21:51,372 iteration 105 : loss : 0.301307, loss_ce: 0.140871
2021-12-14 01:21:52,920 iteration 106 : loss : 0.292688, loss_ce: 0.127814
2021-12-14 01:21:54,557 iteration 107 : loss : 0.302908, loss_ce: 0.139377
2021-12-14 01:21:56,058 iteration 108 : loss : 0.314550, loss_ce: 0.157808
2021-12-14 01:21:57,595 iteration 109 : loss : 0.291536, loss_ce: 0.130306
2021-12-14 01:21:59,172 iteration 110 : loss : 0.311127, loss_ce: 0.147597
2021-12-14 01:22:00,937 iteration 111 : loss : 0.298384, loss_ce: 0.125540
2021-12-14 01:22:02,419 iteration 112 : loss : 0.313535, loss_ce: 0.122404
2021-12-14 01:22:04,079 iteration 113 : loss : 0.285141, loss_ce: 0.121016
2021-12-14 01:22:05,622 iteration 114 : loss : 0.284146, loss_ce: 0.118631
2021-12-14 01:22:07,055 iteration 115 : loss : 0.280351, loss_ce: 0.120901
2021-12-14 01:22:08,580 iteration 116 : loss : 0.306840, loss_ce: 0.138763
2021-12-14 01:22:10,067 iteration 117 : loss : 0.279261, loss_ce: 0.123088
2021-12-14 01:22:11,676 iteration 118 : loss : 0.293971, loss_ce: 0.127338
2021-12-14 01:22:13,157 iteration 119 : loss : 0.310632, loss_ce: 0.144820
  2%|▌                              | 7/400 [03:18<3:07:18, 28.60s/it]2021-12-14 01:22:14,815 iteration 120 : loss : 0.326151, loss_ce: 0.161978
2021-12-14 01:22:16,404 iteration 121 : loss : 0.301323, loss_ce: 0.124914
2021-12-14 01:22:17,802 iteration 122 : loss : 0.271940, loss_ce: 0.115568
2021-12-14 01:22:19,333 iteration 123 : loss : 0.295568, loss_ce: 0.133496
2021-12-14 01:22:20,827 iteration 124 : loss : 0.282074, loss_ce: 0.119261
2021-12-14 01:22:22,355 iteration 125 : loss : 0.291008, loss_ce: 0.120061
2021-12-14 01:22:23,839 iteration 126 : loss : 0.266650, loss_ce: 0.119610
2021-12-14 01:22:25,368 iteration 127 : loss : 0.307839, loss_ce: 0.149703
2021-12-14 01:22:26,851 iteration 128 : loss : 0.278689, loss_ce: 0.114111
2021-12-14 01:22:28,451 iteration 129 : loss : 0.310088, loss_ce: 0.129125
2021-12-14 01:22:29,825 iteration 130 : loss : 0.273735, loss_ce: 0.123188
2021-12-14 01:22:31,318 iteration 131 : loss : 0.294751, loss_ce: 0.143238
2021-12-14 01:22:32,850 iteration 132 : loss : 0.292832, loss_ce: 0.121359
2021-12-14 01:22:34,375 iteration 133 : loss : 0.334017, loss_ce: 0.171417
2021-12-14 01:22:35,871 iteration 134 : loss : 0.276922, loss_ce: 0.115533
2021-12-14 01:22:37,360 iteration 135 : loss : 0.251425, loss_ce: 0.094961
2021-12-14 01:22:38,973 iteration 136 : loss : 0.271067, loss_ce: 0.118009
  2%|▌                              | 8/400 [03:44<3:01:02, 27.71s/it]2021-12-14 01:22:40,655 iteration 137 : loss : 0.277797, loss_ce: 0.107691
2021-12-14 01:22:42,093 iteration 138 : loss : 0.269061, loss_ce: 0.113418
2021-12-14 01:22:43,698 iteration 139 : loss : 0.272347, loss_ce: 0.091405
2021-12-14 01:22:45,208 iteration 140 : loss : 0.299319, loss_ce: 0.128872
2021-12-14 01:22:46,669 iteration 141 : loss : 0.301257, loss_ce: 0.124776
2021-12-14 01:22:48,164 iteration 142 : loss : 0.269572, loss_ce: 0.116264
2021-12-14 01:22:49,687 iteration 143 : loss : 0.305177, loss_ce: 0.120610
2021-12-14 01:22:51,172 iteration 144 : loss : 0.258032, loss_ce: 0.090795
2021-12-14 01:22:52,703 iteration 145 : loss : 0.290906, loss_ce: 0.141671
2021-12-14 01:22:54,292 iteration 146 : loss : 0.253789, loss_ce: 0.105061
2021-12-14 01:22:55,812 iteration 147 : loss : 0.298505, loss_ce: 0.143256
2021-12-14 01:22:57,458 iteration 148 : loss : 0.269769, loss_ce: 0.114662
2021-12-14 01:22:59,090 iteration 149 : loss : 0.287799, loss_ce: 0.115273
2021-12-14 01:23:00,728 iteration 150 : loss : 0.264192, loss_ce: 0.113513
2021-12-14 01:23:02,194 iteration 151 : loss : 0.279996, loss_ce: 0.142062
2021-12-14 01:23:03,593 iteration 152 : loss : 0.247348, loss_ce: 0.111361
2021-12-14 01:23:05,091 iteration 153 : loss : 0.264666, loss_ce: 0.107016
  2%|▋                              | 9/400 [04:10<2:57:18, 27.21s/it]2021-12-14 01:23:06,715 iteration 154 : loss : 0.288831, loss_ce: 0.128686
2021-12-14 01:23:08,219 iteration 155 : loss : 0.275682, loss_ce: 0.126503
2021-12-14 01:23:09,687 iteration 156 : loss : 0.271258, loss_ce: 0.120313
2021-12-14 01:23:11,161 iteration 157 : loss : 0.267762, loss_ce: 0.112685
2021-12-14 01:23:12,758 iteration 158 : loss : 0.273507, loss_ce: 0.114760
2021-12-14 01:23:14,355 iteration 159 : loss : 0.268424, loss_ce: 0.111655
2021-12-14 01:23:15,850 iteration 160 : loss : 0.247839, loss_ce: 0.099875
2021-12-14 01:23:17,483 iteration 161 : loss : 0.266427, loss_ce: 0.118368
2021-12-14 01:23:19,008 iteration 162 : loss : 0.274179, loss_ce: 0.101535
2021-12-14 01:23:20,564 iteration 163 : loss : 0.277922, loss_ce: 0.127547
2021-12-14 01:23:22,075 iteration 164 : loss : 0.275632, loss_ce: 0.101866
2021-12-14 01:23:23,501 iteration 165 : loss : 0.252903, loss_ce: 0.106539
2021-12-14 01:23:25,064 iteration 166 : loss : 0.285608, loss_ce: 0.146743
2021-12-14 01:23:26,748 iteration 167 : loss : 0.308422, loss_ce: 0.133022
2021-12-14 01:23:28,249 iteration 168 : loss : 0.267990, loss_ce: 0.098901
2021-12-14 01:23:29,792 iteration 169 : loss : 0.266829, loss_ce: 0.108532
2021-12-14 01:23:29,793 Training Data Eval:
2021-12-14 01:23:37,225   Average segmentation loss on training set: 0.2628
2021-12-14 01:23:37,226 Validation Data Eval:
2021-12-14 01:23:39,793   Average segmentation loss on validation set: 0.2662
2021-12-14 01:23:45,720 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 01:23:47,378 iteration 170 : loss : 0.241977, loss_ce: 0.105647
  2%|▊                             | 10/400 [04:52<3:27:07, 31.87s/it]2021-12-14 01:23:49,035 iteration 171 : loss : 0.243021, loss_ce: 0.103807
2021-12-14 01:23:50,496 iteration 172 : loss : 0.255469, loss_ce: 0.114794
2021-12-14 01:23:52,097 iteration 173 : loss : 0.246220, loss_ce: 0.095152
2021-12-14 01:23:53,523 iteration 174 : loss : 0.273569, loss_ce: 0.131815
2021-12-14 01:23:55,012 iteration 175 : loss : 0.249209, loss_ce: 0.090858
2021-12-14 01:23:56,497 iteration 176 : loss : 0.254318, loss_ce: 0.107155
2021-12-14 01:23:58,065 iteration 177 : loss : 0.251079, loss_ce: 0.102172
2021-12-14 01:23:59,576 iteration 178 : loss : 0.241892, loss_ce: 0.098700
2021-12-14 01:24:01,001 iteration 179 : loss : 0.238385, loss_ce: 0.090414
2021-12-14 01:24:02,637 iteration 180 : loss : 0.261440, loss_ce: 0.107257
2021-12-14 01:24:04,204 iteration 181 : loss : 0.240756, loss_ce: 0.102383
2021-12-14 01:24:05,712 iteration 182 : loss : 0.243838, loss_ce: 0.102175
2021-12-14 01:24:07,274 iteration 183 : loss : 0.242766, loss_ce: 0.090387
2021-12-14 01:24:09,004 iteration 184 : loss : 0.256000, loss_ce: 0.092231
2021-12-14 01:24:10,699 iteration 185 : loss : 0.242912, loss_ce: 0.104535
2021-12-14 01:24:12,204 iteration 186 : loss : 0.255137, loss_ce: 0.092376
2021-12-14 01:24:13,756 iteration 187 : loss : 0.241977, loss_ce: 0.098029
  3%|▊                             | 11/400 [05:18<3:15:42, 30.19s/it]2021-12-14 01:24:15,287 iteration 188 : loss : 0.244477, loss_ce: 0.104307
2021-12-14 01:24:16,934 iteration 189 : loss : 0.250279, loss_ce: 0.107441
2021-12-14 01:24:18,505 iteration 190 : loss : 0.264232, loss_ce: 0.117156
2021-12-14 01:24:20,060 iteration 191 : loss : 0.226409, loss_ce: 0.090307
2021-12-14 01:24:21,590 iteration 192 : loss : 0.249588, loss_ce: 0.089951
2021-12-14 01:24:23,032 iteration 193 : loss : 0.238280, loss_ce: 0.098669
2021-12-14 01:24:24,624 iteration 194 : loss : 0.242767, loss_ce: 0.100202
2021-12-14 01:24:26,202 iteration 195 : loss : 0.244256, loss_ce: 0.095475
2021-12-14 01:24:27,696 iteration 196 : loss : 0.224742, loss_ce: 0.100170
2021-12-14 01:24:29,269 iteration 197 : loss : 0.230561, loss_ce: 0.088548
2021-12-14 01:24:30,824 iteration 198 : loss : 0.238284, loss_ce: 0.080762
2021-12-14 01:24:32,221 iteration 199 : loss : 0.251840, loss_ce: 0.094101
2021-12-14 01:24:33,722 iteration 200 : loss : 0.271596, loss_ce: 0.129033
2021-12-14 01:24:35,404 iteration 201 : loss : 0.228703, loss_ce: 0.095915
2021-12-14 01:24:36,884 iteration 202 : loss : 0.228369, loss_ce: 0.090703
2021-12-14 01:24:38,342 iteration 203 : loss : 0.254090, loss_ce: 0.125231
2021-12-14 01:24:39,757 iteration 204 : loss : 0.230391, loss_ce: 0.094399
  3%|▉                             | 12/400 [05:45<3:06:59, 28.92s/it]2021-12-14 01:24:41,246 iteration 205 : loss : 0.239577, loss_ce: 0.091465
2021-12-14 01:24:42,790 iteration 206 : loss : 0.257380, loss_ce: 0.111007
2021-12-14 01:24:44,466 iteration 207 : loss : 0.231538, loss_ce: 0.098348
2021-12-14 01:24:46,120 iteration 208 : loss : 0.220996, loss_ce: 0.088993
2021-12-14 01:24:47,575 iteration 209 : loss : 0.211795, loss_ce: 0.083295
2021-12-14 01:24:49,012 iteration 210 : loss : 0.214824, loss_ce: 0.087160
2021-12-14 01:24:50,517 iteration 211 : loss : 0.219158, loss_ce: 0.089746
2021-12-14 01:24:51,909 iteration 212 : loss : 0.223671, loss_ce: 0.086063
2021-12-14 01:24:53,490 iteration 213 : loss : 0.215814, loss_ce: 0.095008
2021-12-14 01:24:55,034 iteration 214 : loss : 0.245698, loss_ce: 0.086417
2021-12-14 01:24:56,468 iteration 215 : loss : 0.210109, loss_ce: 0.081167
2021-12-14 01:24:58,053 iteration 216 : loss : 0.249359, loss_ce: 0.099593
2021-12-14 01:24:59,529 iteration 217 : loss : 0.196694, loss_ce: 0.084361
2021-12-14 01:25:01,009 iteration 218 : loss : 0.218922, loss_ce: 0.088029
2021-12-14 01:25:02,498 iteration 219 : loss : 0.227499, loss_ce: 0.077841
2021-12-14 01:25:03,936 iteration 220 : loss : 0.221164, loss_ce: 0.099226
2021-12-14 01:25:05,420 iteration 221 : loss : 0.217769, loss_ce: 0.097166
  3%|▉                             | 13/400 [06:10<3:00:09, 27.93s/it]2021-12-14 01:25:07,180 iteration 222 : loss : 0.229630, loss_ce: 0.088845
2021-12-14 01:25:08,783 iteration 223 : loss : 0.221702, loss_ce: 0.082180
2021-12-14 01:25:10,178 iteration 224 : loss : 0.220953, loss_ce: 0.089986
2021-12-14 01:25:11,759 iteration 225 : loss : 0.222806, loss_ce: 0.086182
2021-12-14 01:25:13,320 iteration 226 : loss : 0.239439, loss_ce: 0.087047
2021-12-14 01:25:14,894 iteration 227 : loss : 0.217529, loss_ce: 0.092387
2021-12-14 01:25:16,454 iteration 228 : loss : 0.222658, loss_ce: 0.083285
2021-12-14 01:25:17,990 iteration 229 : loss : 0.195763, loss_ce: 0.085877
2021-12-14 01:25:19,505 iteration 230 : loss : 0.253639, loss_ce: 0.103365
2021-12-14 01:25:21,001 iteration 231 : loss : 0.217608, loss_ce: 0.078035
2021-12-14 01:25:22,631 iteration 232 : loss : 0.209606, loss_ce: 0.095072
2021-12-14 01:25:24,232 iteration 233 : loss : 0.223715, loss_ce: 0.102701
2021-12-14 01:25:25,807 iteration 234 : loss : 0.207113, loss_ce: 0.069167
2021-12-14 01:25:27,324 iteration 235 : loss : 0.202185, loss_ce: 0.078349
2021-12-14 01:25:28,823 iteration 236 : loss : 0.246207, loss_ce: 0.101061
2021-12-14 01:25:30,297 iteration 237 : loss : 0.186294, loss_ce: 0.074924
2021-12-14 01:25:31,685 iteration 238 : loss : 0.204905, loss_ce: 0.087221
  4%|█                             | 14/400 [06:36<2:56:25, 27.42s/it]2021-12-14 01:25:33,211 iteration 239 : loss : 0.200124, loss_ce: 0.073806
2021-12-14 01:25:34,804 iteration 240 : loss : 0.217396, loss_ce: 0.106746
2021-12-14 01:25:36,262 iteration 241 : loss : 0.238673, loss_ce: 0.080787
2021-12-14 01:25:37,862 iteration 242 : loss : 0.195033, loss_ce: 0.075972
2021-12-14 01:25:39,479 iteration 243 : loss : 0.215833, loss_ce: 0.097813
2021-12-14 01:25:41,059 iteration 244 : loss : 0.202458, loss_ce: 0.090492
2021-12-14 01:25:42,482 iteration 245 : loss : 0.208651, loss_ce: 0.075847
2021-12-14 01:25:44,023 iteration 246 : loss : 0.199645, loss_ce: 0.075304
2021-12-14 01:25:45,462 iteration 247 : loss : 0.190082, loss_ce: 0.082019
2021-12-14 01:25:46,862 iteration 248 : loss : 0.188224, loss_ce: 0.067671
2021-12-14 01:25:48,512 iteration 249 : loss : 0.208089, loss_ce: 0.075281
2021-12-14 01:25:50,102 iteration 250 : loss : 0.208046, loss_ce: 0.089913
2021-12-14 01:25:51,603 iteration 251 : loss : 0.197655, loss_ce: 0.076125
2021-12-14 01:25:53,124 iteration 252 : loss : 0.202148, loss_ce: 0.096145
2021-12-14 01:25:54,586 iteration 253 : loss : 0.184470, loss_ce: 0.068879
2021-12-14 01:25:56,028 iteration 254 : loss : 0.177396, loss_ce: 0.069122
2021-12-14 01:25:56,028 Training Data Eval:
2021-12-14 01:26:03,464   Average segmentation loss on training set: 0.2194
2021-12-14 01:26:03,465 Validation Data Eval:
2021-12-14 01:26:06,027   Average segmentation loss on validation set: 0.2028
2021-12-14 01:26:12,308 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 01:26:13,852 iteration 255 : loss : 0.256876, loss_ce: 0.092781
  4%|█▏                            | 15/400 [07:19<3:24:28, 31.87s/it]2021-12-14 01:26:15,411 iteration 256 : loss : 0.184904, loss_ce: 0.069239
2021-12-14 01:26:16,886 iteration 257 : loss : 0.193976, loss_ce: 0.087125
2021-12-14 01:26:18,568 iteration 258 : loss : 0.215836, loss_ce: 0.078452
2021-12-14 01:26:20,005 iteration 259 : loss : 0.212665, loss_ce: 0.082701
2021-12-14 01:26:21,558 iteration 260 : loss : 0.204807, loss_ce: 0.089574
2021-12-14 01:26:23,117 iteration 261 : loss : 0.195290, loss_ce: 0.082104
2021-12-14 01:26:24,685 iteration 262 : loss : 0.238190, loss_ce: 0.114468
2021-12-14 01:26:26,136 iteration 263 : loss : 0.234429, loss_ce: 0.104368
2021-12-14 01:26:27,578 iteration 264 : loss : 0.210173, loss_ce: 0.077207
2021-12-14 01:26:29,162 iteration 265 : loss : 0.201779, loss_ce: 0.089031
2021-12-14 01:26:30,712 iteration 266 : loss : 0.213243, loss_ce: 0.068833
2021-12-14 01:26:32,196 iteration 267 : loss : 0.196738, loss_ce: 0.083859
2021-12-14 01:26:33,710 iteration 268 : loss : 0.176586, loss_ce: 0.077241
2021-12-14 01:26:35,200 iteration 269 : loss : 0.181244, loss_ce: 0.074349
2021-12-14 01:26:36,600 iteration 270 : loss : 0.215026, loss_ce: 0.076453
2021-12-14 01:26:38,127 iteration 271 : loss : 0.238819, loss_ce: 0.088490
2021-12-14 01:26:39,751 iteration 272 : loss : 0.222610, loss_ce: 0.090387
  4%|█▏                            | 16/400 [07:45<3:12:28, 30.08s/it]2021-12-14 01:26:41,320 iteration 273 : loss : 0.204830, loss_ce: 0.081964
2021-12-14 01:26:42,858 iteration 274 : loss : 0.227718, loss_ce: 0.093944
2021-12-14 01:26:44,397 iteration 275 : loss : 0.195264, loss_ce: 0.087153
2021-12-14 01:26:45,837 iteration 276 : loss : 0.206430, loss_ce: 0.087105
2021-12-14 01:26:47,441 iteration 277 : loss : 0.181912, loss_ce: 0.069206
2021-12-14 01:26:48,864 iteration 278 : loss : 0.244232, loss_ce: 0.088285
2021-12-14 01:26:50,382 iteration 279 : loss : 0.183832, loss_ce: 0.072060
2021-12-14 01:26:51,777 iteration 280 : loss : 0.187357, loss_ce: 0.079807
2021-12-14 01:26:53,297 iteration 281 : loss : 0.186774, loss_ce: 0.068614
2021-12-14 01:26:54,888 iteration 282 : loss : 0.204692, loss_ce: 0.088326
2021-12-14 01:26:56,419 iteration 283 : loss : 0.202348, loss_ce: 0.090540
2021-12-14 01:26:57,864 iteration 284 : loss : 0.162230, loss_ce: 0.062820
2021-12-14 01:26:59,390 iteration 285 : loss : 0.185620, loss_ce: 0.069115
2021-12-14 01:27:00,955 iteration 286 : loss : 0.181502, loss_ce: 0.065604
2021-12-14 01:27:02,404 iteration 287 : loss : 0.190250, loss_ce: 0.066638
2021-12-14 01:27:03,894 iteration 288 : loss : 0.169603, loss_ce: 0.065186
2021-12-14 01:27:05,393 iteration 289 : loss : 0.192185, loss_ce: 0.077557
  4%|█▎                            | 17/400 [08:10<3:03:28, 28.74s/it]2021-12-14 01:27:06,986 iteration 290 : loss : 0.176407, loss_ce: 0.065882
2021-12-14 01:27:08,495 iteration 291 : loss : 0.177273, loss_ce: 0.068657
2021-12-14 01:27:10,012 iteration 292 : loss : 0.159723, loss_ce: 0.063172
2021-12-14 01:27:11,717 iteration 293 : loss : 0.211719, loss_ce: 0.088086
2021-12-14 01:27:13,187 iteration 294 : loss : 0.185791, loss_ce: 0.069538
2021-12-14 01:27:14,645 iteration 295 : loss : 0.198822, loss_ce: 0.070871
2021-12-14 01:27:16,134 iteration 296 : loss : 0.190321, loss_ce: 0.070102
2021-12-14 01:27:17,728 iteration 297 : loss : 0.202274, loss_ce: 0.081908
2021-12-14 01:27:19,183 iteration 298 : loss : 0.188641, loss_ce: 0.066475
2021-12-14 01:27:20,733 iteration 299 : loss : 0.213888, loss_ce: 0.069770
2021-12-14 01:27:22,210 iteration 300 : loss : 0.184405, loss_ce: 0.070392
2021-12-14 01:27:23,722 iteration 301 : loss : 0.196095, loss_ce: 0.073066
2021-12-14 01:27:25,366 iteration 302 : loss : 0.226657, loss_ce: 0.107811
2021-12-14 01:27:26,931 iteration 303 : loss : 0.194243, loss_ce: 0.079646
2021-12-14 01:27:28,429 iteration 304 : loss : 0.196551, loss_ce: 0.074706
2021-12-14 01:27:29,949 iteration 305 : loss : 0.164374, loss_ce: 0.063507
2021-12-14 01:27:31,456 iteration 306 : loss : 0.196823, loss_ce: 0.074199
  4%|█▎                            | 18/400 [08:36<2:57:49, 27.93s/it]2021-12-14 01:27:32,994 iteration 307 : loss : 0.179392, loss_ce: 0.064411
2021-12-14 01:27:34,570 iteration 308 : loss : 0.199794, loss_ce: 0.072841
2021-12-14 01:27:36,088 iteration 309 : loss : 0.201560, loss_ce: 0.087755
2021-12-14 01:27:37,568 iteration 310 : loss : 0.177307, loss_ce: 0.061853
2021-12-14 01:27:39,029 iteration 311 : loss : 0.192143, loss_ce: 0.078038
2021-12-14 01:27:40,551 iteration 312 : loss : 0.228481, loss_ce: 0.063630
2021-12-14 01:27:42,131 iteration 313 : loss : 0.180013, loss_ce: 0.067162
2021-12-14 01:27:43,528 iteration 314 : loss : 0.176479, loss_ce: 0.067593
2021-12-14 01:27:45,010 iteration 315 : loss : 0.189761, loss_ce: 0.082482
2021-12-14 01:27:46,612 iteration 316 : loss : 0.190097, loss_ce: 0.075388
2021-12-14 01:27:48,227 iteration 317 : loss : 0.195329, loss_ce: 0.084198
2021-12-14 01:27:49,739 iteration 318 : loss : 0.215533, loss_ce: 0.093132
2021-12-14 01:27:51,266 iteration 319 : loss : 0.164164, loss_ce: 0.063509
2021-12-14 01:27:52,794 iteration 320 : loss : 0.157365, loss_ce: 0.055218
2021-12-14 01:27:54,264 iteration 321 : loss : 0.185979, loss_ce: 0.067328
2021-12-14 01:27:55,718 iteration 322 : loss : 0.170090, loss_ce: 0.066022
2021-12-14 01:27:57,197 iteration 323 : loss : 0.185493, loss_ce: 0.072715
  5%|█▍                            | 19/400 [09:02<2:53:12, 27.28s/it]2021-12-14 01:27:58,772 iteration 324 : loss : 0.166444, loss_ce: 0.056734
2021-12-14 01:28:00,240 iteration 325 : loss : 0.194240, loss_ce: 0.052348
2021-12-14 01:28:01,698 iteration 326 : loss : 0.227103, loss_ce: 0.076575
2021-12-14 01:28:03,127 iteration 327 : loss : 0.209394, loss_ce: 0.083466
2021-12-14 01:28:04,645 iteration 328 : loss : 0.189020, loss_ce: 0.060505
2021-12-14 01:28:06,231 iteration 329 : loss : 0.196211, loss_ce: 0.069159
2021-12-14 01:28:07,709 iteration 330 : loss : 0.184841, loss_ce: 0.077846
2021-12-14 01:28:09,217 iteration 331 : loss : 0.213418, loss_ce: 0.082103
2021-12-14 01:28:10,610 iteration 332 : loss : 0.165610, loss_ce: 0.063834
2021-12-14 01:28:12,177 iteration 333 : loss : 0.182190, loss_ce: 0.075443
2021-12-14 01:28:13,698 iteration 334 : loss : 0.182325, loss_ce: 0.072982
2021-12-14 01:28:15,305 iteration 335 : loss : 0.182345, loss_ce: 0.083287
2021-12-14 01:28:16,813 iteration 336 : loss : 0.185768, loss_ce: 0.081068
2021-12-14 01:28:18,283 iteration 337 : loss : 0.204750, loss_ce: 0.078386
2021-12-14 01:28:19,790 iteration 338 : loss : 0.168909, loss_ce: 0.069979
2021-12-14 01:28:21,260 iteration 339 : loss : 0.196777, loss_ce: 0.081393
2021-12-14 01:28:21,260 Training Data Eval:
2021-12-14 01:28:28,710   Average segmentation loss on training set: 0.2830
2021-12-14 01:28:28,711 Validation Data Eval:
2021-12-14 01:28:31,273   Average segmentation loss on validation set: 0.2493
2021-12-14 01:28:32,842 iteration 340 : loss : 0.187846, loss_ce: 0.087244
  5%|█▌                            | 20/400 [09:38<3:08:40, 29.79s/it]2021-12-14 01:28:34,390 iteration 341 : loss : 0.150330, loss_ce: 0.061970
2021-12-14 01:28:36,000 iteration 342 : loss : 0.174224, loss_ce: 0.072338
2021-12-14 01:28:37,555 iteration 343 : loss : 0.194640, loss_ce: 0.075991
2021-12-14 01:28:39,043 iteration 344 : loss : 0.152703, loss_ce: 0.061814
2021-12-14 01:28:40,523 iteration 345 : loss : 0.166290, loss_ce: 0.065413
2021-12-14 01:28:42,101 iteration 346 : loss : 0.166296, loss_ce: 0.055683
2021-12-14 01:28:43,681 iteration 347 : loss : 0.208678, loss_ce: 0.086324
2021-12-14 01:28:45,166 iteration 348 : loss : 0.167561, loss_ce: 0.058759
2021-12-14 01:28:46,673 iteration 349 : loss : 0.209662, loss_ce: 0.077147
2021-12-14 01:28:48,220 iteration 350 : loss : 0.184364, loss_ce: 0.073118
2021-12-14 01:28:49,711 iteration 351 : loss : 0.181018, loss_ce: 0.062043
2021-12-14 01:28:51,354 iteration 352 : loss : 0.178230, loss_ce: 0.075416
2021-12-14 01:28:52,996 iteration 353 : loss : 0.178155, loss_ce: 0.068394
2021-12-14 01:28:54,493 iteration 354 : loss : 0.158518, loss_ce: 0.055570
2021-12-14 01:28:56,054 iteration 355 : loss : 0.159575, loss_ce: 0.049646
2021-12-14 01:28:57,598 iteration 356 : loss : 0.163784, loss_ce: 0.056979
2021-12-14 01:28:59,153 iteration 357 : loss : 0.163005, loss_ce: 0.057116
  5%|█▌                            | 21/400 [10:04<3:01:34, 28.74s/it]2021-12-14 01:29:00,869 iteration 358 : loss : 0.188007, loss_ce: 0.079987
2021-12-14 01:29:02,488 iteration 359 : loss : 0.160637, loss_ce: 0.058335
2021-12-14 01:29:03,979 iteration 360 : loss : 0.155571, loss_ce: 0.053470
2021-12-14 01:29:05,543 iteration 361 : loss : 0.170150, loss_ce: 0.060492
2021-12-14 01:29:07,095 iteration 362 : loss : 0.180915, loss_ce: 0.082944
2021-12-14 01:29:08,524 iteration 363 : loss : 0.187898, loss_ce: 0.081566
2021-12-14 01:29:10,079 iteration 364 : loss : 0.211022, loss_ce: 0.068638
2021-12-14 01:29:11,538 iteration 365 : loss : 0.162933, loss_ce: 0.059443
2021-12-14 01:29:13,030 iteration 366 : loss : 0.167126, loss_ce: 0.047614
2021-12-14 01:29:14,564 iteration 367 : loss : 0.186501, loss_ce: 0.065935
2021-12-14 01:29:16,070 iteration 368 : loss : 0.196739, loss_ce: 0.073892
2021-12-14 01:29:17,528 iteration 369 : loss : 0.165876, loss_ce: 0.057416
2021-12-14 01:29:19,039 iteration 370 : loss : 0.187815, loss_ce: 0.074560
2021-12-14 01:29:20,573 iteration 371 : loss : 0.164120, loss_ce: 0.055931
2021-12-14 01:29:22,020 iteration 372 : loss : 0.156637, loss_ce: 0.056681
2021-12-14 01:29:23,515 iteration 373 : loss : 0.146507, loss_ce: 0.048250
2021-12-14 01:29:25,105 iteration 374 : loss : 0.162412, loss_ce: 0.063684
  6%|█▋                            | 22/400 [10:30<2:55:48, 27.91s/it]2021-12-14 01:29:26,682 iteration 375 : loss : 0.175338, loss_ce: 0.069167
2021-12-14 01:29:28,177 iteration 376 : loss : 0.177536, loss_ce: 0.052245
2021-12-14 01:29:29,704 iteration 377 : loss : 0.159239, loss_ce: 0.053272
2021-12-14 01:29:31,326 iteration 378 : loss : 0.169718, loss_ce: 0.055468
2021-12-14 01:29:32,863 iteration 379 : loss : 0.156858, loss_ce: 0.056835
2021-12-14 01:29:34,332 iteration 380 : loss : 0.188316, loss_ce: 0.081782
2021-12-14 01:29:35,875 iteration 381 : loss : 0.157392, loss_ce: 0.056246
2021-12-14 01:29:37,314 iteration 382 : loss : 0.149568, loss_ce: 0.059166
2021-12-14 01:29:38,843 iteration 383 : loss : 0.162759, loss_ce: 0.041923
2021-12-14 01:29:40,352 iteration 384 : loss : 0.153275, loss_ce: 0.053190
2021-12-14 01:29:41,840 iteration 385 : loss : 0.164169, loss_ce: 0.063230
2021-12-14 01:29:43,357 iteration 386 : loss : 0.171112, loss_ce: 0.053279
2021-12-14 01:29:44,814 iteration 387 : loss : 0.153661, loss_ce: 0.052312
2021-12-14 01:29:46,375 iteration 388 : loss : 0.185269, loss_ce: 0.069229
2021-12-14 01:29:47,869 iteration 389 : loss : 0.166776, loss_ce: 0.052351
2021-12-14 01:29:49,386 iteration 390 : loss : 0.185258, loss_ce: 0.074053
2021-12-14 01:29:50,939 iteration 391 : loss : 0.143824, loss_ce: 0.051090
  6%|█▋                            | 23/400 [10:56<2:51:26, 27.28s/it]2021-12-14 01:29:52,597 iteration 392 : loss : 0.178276, loss_ce: 0.069079
2021-12-14 01:29:54,042 iteration 393 : loss : 0.156220, loss_ce: 0.061045
2021-12-14 01:29:55,552 iteration 394 : loss : 0.170029, loss_ce: 0.051891
2021-12-14 01:29:57,015 iteration 395 : loss : 0.159960, loss_ce: 0.051036
2021-12-14 01:29:58,528 iteration 396 : loss : 0.164195, loss_ce: 0.054751
2021-12-14 01:30:00,136 iteration 397 : loss : 0.168297, loss_ce: 0.063973
2021-12-14 01:30:01,639 iteration 398 : loss : 0.160675, loss_ce: 0.054245
2021-12-14 01:30:03,192 iteration 399 : loss : 0.172182, loss_ce: 0.062188
2021-12-14 01:30:04,681 iteration 400 : loss : 0.155525, loss_ce: 0.054124
2021-12-14 01:30:06,209 iteration 401 : loss : 0.139402, loss_ce: 0.051514
2021-12-14 01:30:07,863 iteration 402 : loss : 0.156463, loss_ce: 0.054632
2021-12-14 01:30:09,444 iteration 403 : loss : 0.149387, loss_ce: 0.052167
2021-12-14 01:30:10,925 iteration 404 : loss : 0.134908, loss_ce: 0.045018
2021-12-14 01:30:12,422 iteration 405 : loss : 0.158217, loss_ce: 0.061786
2021-12-14 01:30:14,005 iteration 406 : loss : 0.166750, loss_ce: 0.058555
2021-12-14 01:30:15,585 iteration 407 : loss : 0.139409, loss_ce: 0.046777
2021-12-14 01:30:16,986 iteration 408 : loss : 0.142581, loss_ce: 0.051792
  6%|█▊                            | 24/400 [11:22<2:48:40, 26.92s/it]2021-12-14 01:30:18,668 iteration 409 : loss : 0.153090, loss_ce: 0.044011
2021-12-14 01:30:20,239 iteration 410 : loss : 0.153078, loss_ce: 0.051028
2021-12-14 01:30:21,788 iteration 411 : loss : 0.171018, loss_ce: 0.055777
2021-12-14 01:30:23,279 iteration 412 : loss : 0.156418, loss_ce: 0.057638
2021-12-14 01:30:24,804 iteration 413 : loss : 0.146889, loss_ce: 0.044931
2021-12-14 01:30:26,257 iteration 414 : loss : 0.143017, loss_ce: 0.048182
2021-12-14 01:30:27,844 iteration 415 : loss : 0.187810, loss_ce: 0.072363
2021-12-14 01:30:29,354 iteration 416 : loss : 0.155218, loss_ce: 0.058822
2021-12-14 01:30:30,913 iteration 417 : loss : 0.149066, loss_ce: 0.047130
2021-12-14 01:30:32,334 iteration 418 : loss : 0.161055, loss_ce: 0.074524
2021-12-14 01:30:33,830 iteration 419 : loss : 0.166161, loss_ce: 0.051636
2021-12-14 01:30:35,350 iteration 420 : loss : 0.134622, loss_ce: 0.048430
2021-12-14 01:30:36,956 iteration 421 : loss : 0.198468, loss_ce: 0.087308
2021-12-14 01:30:38,441 iteration 422 : loss : 0.143091, loss_ce: 0.047626
2021-12-14 01:30:39,954 iteration 423 : loss : 0.156819, loss_ce: 0.054424
2021-12-14 01:30:41,523 iteration 424 : loss : 0.169529, loss_ce: 0.058436
2021-12-14 01:30:41,523 Training Data Eval:
2021-12-14 01:30:48,962   Average segmentation loss on training set: 0.1414
2021-12-14 01:30:48,962 Validation Data Eval:
2021-12-14 01:30:51,536   Average segmentation loss on validation set: 0.1504
2021-12-14 01:30:57,531 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 01:30:59,149 iteration 425 : loss : 0.161836, loss_ce: 0.057243
  6%|█▉                            | 25/400 [12:04<3:16:48, 31.49s/it]2021-12-14 01:31:00,799 iteration 426 : loss : 0.145129, loss_ce: 0.046865
2021-12-14 01:31:02,333 iteration 427 : loss : 0.164378, loss_ce: 0.052808
2021-12-14 01:31:03,909 iteration 428 : loss : 0.155731, loss_ce: 0.054557
2021-12-14 01:31:05,388 iteration 429 : loss : 0.134492, loss_ce: 0.040147
2021-12-14 01:31:06,921 iteration 430 : loss : 0.152969, loss_ce: 0.052030
2021-12-14 01:31:08,362 iteration 431 : loss : 0.184873, loss_ce: 0.061703
2021-12-14 01:31:09,838 iteration 432 : loss : 0.137585, loss_ce: 0.046517
2021-12-14 01:31:11,362 iteration 433 : loss : 0.144565, loss_ce: 0.043759
2021-12-14 01:31:12,852 iteration 434 : loss : 0.143401, loss_ce: 0.046815
2021-12-14 01:31:14,355 iteration 435 : loss : 0.169634, loss_ce: 0.073852
2021-12-14 01:31:15,919 iteration 436 : loss : 0.158349, loss_ce: 0.052486
2021-12-14 01:31:17,441 iteration 437 : loss : 0.150040, loss_ce: 0.050290
2021-12-14 01:31:18,952 iteration 438 : loss : 0.178854, loss_ce: 0.081455
2021-12-14 01:31:20,459 iteration 439 : loss : 0.154201, loss_ce: 0.059775
2021-12-14 01:31:21,908 iteration 440 : loss : 0.142169, loss_ce: 0.047724
2021-12-14 01:31:23,410 iteration 441 : loss : 0.161696, loss_ce: 0.063473
2021-12-14 01:31:24,884 iteration 442 : loss : 0.191536, loss_ce: 0.057553
  6%|█▉                            | 26/400 [12:30<3:05:29, 29.76s/it]2021-12-14 01:31:26,453 iteration 443 : loss : 0.153627, loss_ce: 0.064290
2021-12-14 01:31:27,951 iteration 444 : loss : 0.163613, loss_ce: 0.052747
2021-12-14 01:31:29,715 iteration 445 : loss : 0.178325, loss_ce: 0.065446
2021-12-14 01:31:31,166 iteration 446 : loss : 0.186429, loss_ce: 0.057787
2021-12-14 01:31:32,790 iteration 447 : loss : 0.163129, loss_ce: 0.059968
2021-12-14 01:31:34,355 iteration 448 : loss : 0.152911, loss_ce: 0.057284
2021-12-14 01:31:35,853 iteration 449 : loss : 0.155885, loss_ce: 0.049794
2021-12-14 01:31:37,258 iteration 450 : loss : 0.163903, loss_ce: 0.061845
2021-12-14 01:31:38,758 iteration 451 : loss : 0.155217, loss_ce: 0.048414
2021-12-14 01:31:40,309 iteration 452 : loss : 0.139679, loss_ce: 0.048559
2021-12-14 01:31:41,833 iteration 453 : loss : 0.144048, loss_ce: 0.041724
2021-12-14 01:31:43,397 iteration 454 : loss : 0.193533, loss_ce: 0.074229
2021-12-14 01:31:45,018 iteration 455 : loss : 0.149814, loss_ce: 0.043623
2021-12-14 01:31:46,504 iteration 456 : loss : 0.178863, loss_ce: 0.052899
2021-12-14 01:31:47,986 iteration 457 : loss : 0.163644, loss_ce: 0.061320
2021-12-14 01:31:49,507 iteration 458 : loss : 0.184642, loss_ce: 0.071429
2021-12-14 01:31:51,048 iteration 459 : loss : 0.144607, loss_ce: 0.048045
  7%|██                            | 27/400 [12:56<2:58:19, 28.68s/it]2021-12-14 01:31:52,513 iteration 460 : loss : 0.156549, loss_ce: 0.046669
2021-12-14 01:31:54,053 iteration 461 : loss : 0.153462, loss_ce: 0.050803
2021-12-14 01:31:55,573 iteration 462 : loss : 0.138401, loss_ce: 0.035562
2021-12-14 01:31:56,988 iteration 463 : loss : 0.153683, loss_ce: 0.056879
2021-12-14 01:31:58,581 iteration 464 : loss : 0.143993, loss_ce: 0.050460
2021-12-14 01:32:00,074 iteration 465 : loss : 0.147918, loss_ce: 0.061098
2021-12-14 01:32:01,659 iteration 466 : loss : 0.139226, loss_ce: 0.047643
2021-12-14 01:32:03,127 iteration 467 : loss : 0.150601, loss_ce: 0.049034
2021-12-14 01:32:04,628 iteration 468 : loss : 0.146045, loss_ce: 0.047921
2021-12-14 01:32:06,086 iteration 469 : loss : 0.185501, loss_ce: 0.065419
2021-12-14 01:32:07,702 iteration 470 : loss : 0.178354, loss_ce: 0.068411
2021-12-14 01:32:09,159 iteration 471 : loss : 0.151766, loss_ce: 0.053836
2021-12-14 01:32:10,745 iteration 472 : loss : 0.159590, loss_ce: 0.053910
2021-12-14 01:32:12,323 iteration 473 : loss : 0.147871, loss_ce: 0.049917
2021-12-14 01:32:13,917 iteration 474 : loss : 0.142605, loss_ce: 0.044264
2021-12-14 01:32:15,441 iteration 475 : loss : 0.165196, loss_ce: 0.044063
2021-12-14 01:32:17,009 iteration 476 : loss : 0.142426, loss_ce: 0.057583
  7%|██                            | 28/400 [13:22<2:52:46, 27.87s/it]2021-12-14 01:32:18,583 iteration 477 : loss : 0.140115, loss_ce: 0.050113
2021-12-14 01:32:20,148 iteration 478 : loss : 0.150183, loss_ce: 0.049463
2021-12-14 01:32:21,584 iteration 479 : loss : 0.162000, loss_ce: 0.057660
2021-12-14 01:32:22,988 iteration 480 : loss : 0.160030, loss_ce: 0.057471
2021-12-14 01:32:24,474 iteration 481 : loss : 0.153900, loss_ce: 0.055267
2021-12-14 01:32:26,047 iteration 482 : loss : 0.140458, loss_ce: 0.042724
2021-12-14 01:32:27,592 iteration 483 : loss : 0.133320, loss_ce: 0.038630
2021-12-14 01:32:29,130 iteration 484 : loss : 0.176203, loss_ce: 0.063653
2021-12-14 01:32:30,554 iteration 485 : loss : 0.124428, loss_ce: 0.037501
2021-12-14 01:32:32,063 iteration 486 : loss : 0.194389, loss_ce: 0.053633
2021-12-14 01:32:33,643 iteration 487 : loss : 0.163310, loss_ce: 0.066004
2021-12-14 01:32:35,293 iteration 488 : loss : 0.171738, loss_ce: 0.063457
2021-12-14 01:32:36,871 iteration 489 : loss : 0.127602, loss_ce: 0.037425
2021-12-14 01:32:38,341 iteration 490 : loss : 0.140788, loss_ce: 0.047267
2021-12-14 01:32:39,947 iteration 491 : loss : 0.149250, loss_ce: 0.049985
2021-12-14 01:32:41,409 iteration 492 : loss : 0.165680, loss_ce: 0.061420
2021-12-14 01:32:42,914 iteration 493 : loss : 0.169548, loss_ce: 0.060655
  7%|██▏                           | 29/400 [13:48<2:48:39, 27.27s/it]2021-12-14 01:32:44,444 iteration 494 : loss : 0.148054, loss_ce: 0.045503
2021-12-14 01:32:45,956 iteration 495 : loss : 0.126069, loss_ce: 0.041590
2021-12-14 01:32:47,367 iteration 496 : loss : 0.135793, loss_ce: 0.048424
2021-12-14 01:32:48,974 iteration 497 : loss : 0.152705, loss_ce: 0.047728
2021-12-14 01:32:50,498 iteration 498 : loss : 0.153005, loss_ce: 0.052727
2021-12-14 01:32:52,123 iteration 499 : loss : 0.168517, loss_ce: 0.062243
2021-12-14 01:32:53,531 iteration 500 : loss : 0.148293, loss_ce: 0.051556
2021-12-14 01:32:55,061 iteration 501 : loss : 0.129829, loss_ce: 0.037435
2021-12-14 01:32:56,532 iteration 502 : loss : 0.154784, loss_ce: 0.046766
2021-12-14 01:32:58,036 iteration 503 : loss : 0.148440, loss_ce: 0.059114
2021-12-14 01:32:59,676 iteration 504 : loss : 0.131543, loss_ce: 0.040986
2021-12-14 01:33:01,313 iteration 505 : loss : 0.145151, loss_ce: 0.052187
2021-12-14 01:33:02,845 iteration 506 : loss : 0.159877, loss_ce: 0.067799
2021-12-14 01:33:04,343 iteration 507 : loss : 0.137024, loss_ce: 0.042898
2021-12-14 01:33:05,927 iteration 508 : loss : 0.135241, loss_ce: 0.038559
2021-12-14 01:33:07,513 iteration 509 : loss : 0.139598, loss_ce: 0.049646
2021-12-14 01:33:07,513 Training Data Eval:
2021-12-14 01:33:14,938   Average segmentation loss on training set: 0.1432
2021-12-14 01:33:14,938 Validation Data Eval:
2021-12-14 01:33:17,512   Average segmentation loss on validation set: 0.1479
2021-12-14 01:33:23,518 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 01:33:25,038 iteration 510 : loss : 0.134549, loss_ce: 0.042834
  8%|██▎                           | 30/400 [14:30<3:15:42, 31.74s/it]2021-12-14 01:33:26,571 iteration 511 : loss : 0.146357, loss_ce: 0.043091
2021-12-14 01:33:28,067 iteration 512 : loss : 0.172256, loss_ce: 0.063721
2021-12-14 01:33:29,589 iteration 513 : loss : 0.146595, loss_ce: 0.047891
2021-12-14 01:33:31,140 iteration 514 : loss : 0.160359, loss_ce: 0.057046
2021-12-14 01:33:32,557 iteration 515 : loss : 0.154170, loss_ce: 0.055660
2021-12-14 01:33:33,938 iteration 516 : loss : 0.134718, loss_ce: 0.038135
2021-12-14 01:33:35,555 iteration 517 : loss : 0.156186, loss_ce: 0.062624
2021-12-14 01:33:37,192 iteration 518 : loss : 0.187253, loss_ce: 0.058846
2021-12-14 01:33:38,805 iteration 519 : loss : 0.154590, loss_ce: 0.060423
2021-12-14 01:33:40,346 iteration 520 : loss : 0.135402, loss_ce: 0.047311
2021-12-14 01:33:41,782 iteration 521 : loss : 0.125227, loss_ce: 0.035318
2021-12-14 01:33:43,351 iteration 522 : loss : 0.138985, loss_ce: 0.042859
2021-12-14 01:33:44,851 iteration 523 : loss : 0.151616, loss_ce: 0.043886
2021-12-14 01:33:46,349 iteration 524 : loss : 0.152310, loss_ce: 0.058341
2021-12-14 01:33:47,846 iteration 525 : loss : 0.136057, loss_ce: 0.047490
2021-12-14 01:33:49,409 iteration 526 : loss : 0.132299, loss_ce: 0.041265
2021-12-14 01:33:50,965 iteration 527 : loss : 0.163979, loss_ce: 0.052325
  8%|██▎                           | 31/400 [14:56<3:04:27, 29.99s/it]2021-12-14 01:33:52,522 iteration 528 : loss : 0.140740, loss_ce: 0.047996
2021-12-14 01:33:54,193 iteration 529 : loss : 0.180657, loss_ce: 0.048183
2021-12-14 01:33:55,664 iteration 530 : loss : 0.126417, loss_ce: 0.037269
2021-12-14 01:33:57,117 iteration 531 : loss : 0.139974, loss_ce: 0.042918
2021-12-14 01:33:58,660 iteration 532 : loss : 0.140052, loss_ce: 0.046726
2021-12-14 01:34:00,170 iteration 533 : loss : 0.129485, loss_ce: 0.039603
2021-12-14 01:34:01,665 iteration 534 : loss : 0.137258, loss_ce: 0.043573
2021-12-14 01:34:03,238 iteration 535 : loss : 0.133382, loss_ce: 0.039675
2021-12-14 01:34:04,775 iteration 536 : loss : 0.148280, loss_ce: 0.055737
2021-12-14 01:34:06,268 iteration 537 : loss : 0.135486, loss_ce: 0.040772
2021-12-14 01:34:07,809 iteration 538 : loss : 0.153487, loss_ce: 0.061191
2021-12-14 01:34:09,238 iteration 539 : loss : 0.129206, loss_ce: 0.040801
2021-12-14 01:34:10,914 iteration 540 : loss : 0.166914, loss_ce: 0.067435
2021-12-14 01:34:12,572 iteration 541 : loss : 0.147857, loss_ce: 0.056817
2021-12-14 01:34:14,018 iteration 542 : loss : 0.189085, loss_ce: 0.063113
2021-12-14 01:34:15,543 iteration 543 : loss : 0.143393, loss_ce: 0.051680
2021-12-14 01:34:17,044 iteration 544 : loss : 0.194914, loss_ce: 0.052742
  8%|██▍                           | 32/400 [15:22<2:56:45, 28.82s/it]2021-12-14 01:34:18,710 iteration 545 : loss : 0.131162, loss_ce: 0.043222
2021-12-14 01:34:20,333 iteration 546 : loss : 0.122364, loss_ce: 0.041806
2021-12-14 01:34:21,935 iteration 547 : loss : 0.148003, loss_ce: 0.046838
2021-12-14 01:34:23,380 iteration 548 : loss : 0.204127, loss_ce: 0.064463
2021-12-14 01:34:24,825 iteration 549 : loss : 0.138117, loss_ce: 0.045156
2021-12-14 01:34:26,292 iteration 550 : loss : 0.158420, loss_ce: 0.052265
2021-12-14 01:34:27,743 iteration 551 : loss : 0.134086, loss_ce: 0.033061
2021-12-14 01:34:29,318 iteration 552 : loss : 0.156758, loss_ce: 0.050550
2021-12-14 01:34:30,861 iteration 553 : loss : 0.139321, loss_ce: 0.045149
2021-12-14 01:34:32,398 iteration 554 : loss : 0.169727, loss_ce: 0.050070
2021-12-14 01:34:33,977 iteration 555 : loss : 0.123812, loss_ce: 0.032571
2021-12-14 01:34:35,601 iteration 556 : loss : 0.140792, loss_ce: 0.049910
2021-12-14 01:34:37,078 iteration 557 : loss : 0.160985, loss_ce: 0.066630
2021-12-14 01:34:38,510 iteration 558 : loss : 0.135874, loss_ce: 0.045676
2021-12-14 01:34:39,995 iteration 559 : loss : 0.138244, loss_ce: 0.043446
2021-12-14 01:34:41,580 iteration 560 : loss : 0.143173, loss_ce: 0.049999
2021-12-14 01:34:43,155 iteration 561 : loss : 0.135173, loss_ce: 0.050477
  8%|██▍                           | 33/400 [15:48<2:51:17, 28.00s/it]2021-12-14 01:34:44,782 iteration 562 : loss : 0.164847, loss_ce: 0.046762
2021-12-14 01:34:46,240 iteration 563 : loss : 0.118417, loss_ce: 0.041269
2021-12-14 01:34:47,704 iteration 564 : loss : 0.144678, loss_ce: 0.058157
2021-12-14 01:34:49,265 iteration 565 : loss : 0.138829, loss_ce: 0.048960
2021-12-14 01:34:50,807 iteration 566 : loss : 0.134308, loss_ce: 0.039661
2021-12-14 01:34:52,360 iteration 567 : loss : 0.148223, loss_ce: 0.048479
2021-12-14 01:34:53,917 iteration 568 : loss : 0.149082, loss_ce: 0.037659
2021-12-14 01:34:55,554 iteration 569 : loss : 0.179058, loss_ce: 0.046691
2021-12-14 01:34:57,101 iteration 570 : loss : 0.144588, loss_ce: 0.045594
2021-12-14 01:34:58,675 iteration 571 : loss : 0.128670, loss_ce: 0.044856
2021-12-14 01:35:00,285 iteration 572 : loss : 0.149348, loss_ce: 0.051384
2021-12-14 01:35:01,783 iteration 573 : loss : 0.144966, loss_ce: 0.050754
2021-12-14 01:35:03,421 iteration 574 : loss : 0.142809, loss_ce: 0.041417
2021-12-14 01:35:04,926 iteration 575 : loss : 0.149886, loss_ce: 0.044546
2021-12-14 01:35:06,378 iteration 576 : loss : 0.141464, loss_ce: 0.055967
2021-12-14 01:35:08,055 iteration 577 : loss : 0.156200, loss_ce: 0.058940
2021-12-14 01:35:09,627 iteration 578 : loss : 0.127636, loss_ce: 0.040059
  8%|██▌                           | 34/400 [16:14<2:48:00, 27.54s/it]2021-12-14 01:35:11,119 iteration 579 : loss : 0.122601, loss_ce: 0.039524
2021-12-14 01:35:12,703 iteration 580 : loss : 0.132464, loss_ce: 0.040830
2021-12-14 01:35:14,402 iteration 581 : loss : 0.122015, loss_ce: 0.035878
2021-12-14 01:35:15,848 iteration 582 : loss : 0.130748, loss_ce: 0.042887
2021-12-14 01:35:17,381 iteration 583 : loss : 0.142528, loss_ce: 0.053113
2021-12-14 01:35:18,962 iteration 584 : loss : 0.134061, loss_ce: 0.045473
2021-12-14 01:35:20,456 iteration 585 : loss : 0.150505, loss_ce: 0.041005
2021-12-14 01:35:22,023 iteration 586 : loss : 0.151152, loss_ce: 0.048215
2021-12-14 01:35:23,568 iteration 587 : loss : 0.132372, loss_ce: 0.046259
2021-12-14 01:35:25,045 iteration 588 : loss : 0.138901, loss_ce: 0.039745
2021-12-14 01:35:26,646 iteration 589 : loss : 0.164957, loss_ce: 0.058888
2021-12-14 01:35:28,150 iteration 590 : loss : 0.147667, loss_ce: 0.041622
2021-12-14 01:35:29,668 iteration 591 : loss : 0.155354, loss_ce: 0.051493
2021-12-14 01:35:31,220 iteration 592 : loss : 0.122295, loss_ce: 0.041245
2021-12-14 01:35:32,664 iteration 593 : loss : 0.137732, loss_ce: 0.043712
2021-12-14 01:35:34,252 iteration 594 : loss : 0.130601, loss_ce: 0.039853
2021-12-14 01:35:34,252 Training Data Eval:
2021-12-14 01:35:41,674   Average segmentation loss on training set: 0.1316
2021-12-14 01:35:41,674 Validation Data Eval:
2021-12-14 01:35:44,233   Average segmentation loss on validation set: 0.1506
2021-12-14 01:35:45,768 iteration 595 : loss : 0.158770, loss_ce: 0.051433
  9%|██▋                           | 35/400 [16:51<3:03:15, 30.12s/it]2021-12-14 01:35:47,455 iteration 596 : loss : 0.133503, loss_ce: 0.045686
2021-12-14 01:35:48,972 iteration 597 : loss : 0.127711, loss_ce: 0.041734
2021-12-14 01:35:50,484 iteration 598 : loss : 0.129886, loss_ce: 0.037444
2021-12-14 01:35:52,042 iteration 599 : loss : 0.150196, loss_ce: 0.039970
2021-12-14 01:35:53,637 iteration 600 : loss : 0.141073, loss_ce: 0.042558
2021-12-14 01:35:55,228 iteration 601 : loss : 0.141443, loss_ce: 0.043813
2021-12-14 01:35:56,629 iteration 602 : loss : 0.127484, loss_ce: 0.042411
2021-12-14 01:35:58,140 iteration 603 : loss : 0.118736, loss_ce: 0.035764
2021-12-14 01:35:59,616 iteration 604 : loss : 0.164783, loss_ce: 0.043754
2021-12-14 01:36:01,267 iteration 605 : loss : 0.143599, loss_ce: 0.046264
2021-12-14 01:36:02,729 iteration 606 : loss : 0.126310, loss_ce: 0.040318
2021-12-14 01:36:04,194 iteration 607 : loss : 0.113043, loss_ce: 0.032786
2021-12-14 01:36:05,660 iteration 608 : loss : 0.122509, loss_ce: 0.040563
2021-12-14 01:36:07,108 iteration 609 : loss : 0.138355, loss_ce: 0.041016
2021-12-14 01:36:08,757 iteration 610 : loss : 0.178962, loss_ce: 0.073191
2021-12-14 01:36:10,272 iteration 611 : loss : 0.125560, loss_ce: 0.042714
2021-12-14 01:36:11,697 iteration 612 : loss : 0.133525, loss_ce: 0.041731
  9%|██▋                           | 36/400 [17:16<2:55:06, 28.86s/it]2021-12-14 01:36:13,263 iteration 613 : loss : 0.126405, loss_ce: 0.035617
2021-12-14 01:36:14,860 iteration 614 : loss : 0.124936, loss_ce: 0.041577
2021-12-14 01:36:16,396 iteration 615 : loss : 0.139021, loss_ce: 0.050546
2021-12-14 01:36:17,882 iteration 616 : loss : 0.159838, loss_ce: 0.043816
2021-12-14 01:36:19,448 iteration 617 : loss : 0.157231, loss_ce: 0.046778
2021-12-14 01:36:21,064 iteration 618 : loss : 0.123183, loss_ce: 0.043020
2021-12-14 01:36:22,618 iteration 619 : loss : 0.134953, loss_ce: 0.040134
2021-12-14 01:36:24,190 iteration 620 : loss : 0.144850, loss_ce: 0.050622
2021-12-14 01:36:25,595 iteration 621 : loss : 0.130947, loss_ce: 0.038112
2021-12-14 01:36:27,209 iteration 622 : loss : 0.130212, loss_ce: 0.040346
2021-12-14 01:36:28,807 iteration 623 : loss : 0.154901, loss_ce: 0.051239
2021-12-14 01:36:30,242 iteration 624 : loss : 0.137449, loss_ce: 0.050547
2021-12-14 01:36:31,931 iteration 625 : loss : 0.137224, loss_ce: 0.043161
2021-12-14 01:36:33,441 iteration 626 : loss : 0.145354, loss_ce: 0.046861
2021-12-14 01:36:34,871 iteration 627 : loss : 0.148324, loss_ce: 0.043040
2021-12-14 01:36:36,270 iteration 628 : loss : 0.166853, loss_ce: 0.050770
2021-12-14 01:36:37,817 iteration 629 : loss : 0.122226, loss_ce: 0.038450
  9%|██▊                           | 37/400 [17:43<2:49:38, 28.04s/it]2021-12-14 01:36:39,264 iteration 630 : loss : 0.124865, loss_ce: 0.043020
2021-12-14 01:36:40,777 iteration 631 : loss : 0.157182, loss_ce: 0.054637
2021-12-14 01:36:42,219 iteration 632 : loss : 0.119346, loss_ce: 0.035439
2021-12-14 01:36:43,775 iteration 633 : loss : 0.143985, loss_ce: 0.053719
2021-12-14 01:36:45,304 iteration 634 : loss : 0.121516, loss_ce: 0.038043
2021-12-14 01:36:46,862 iteration 635 : loss : 0.134605, loss_ce: 0.042675
2021-12-14 01:36:48,359 iteration 636 : loss : 0.161708, loss_ce: 0.044571
2021-12-14 01:36:49,820 iteration 637 : loss : 0.130156, loss_ce: 0.042359
2021-12-14 01:36:51,297 iteration 638 : loss : 0.116931, loss_ce: 0.038984
2021-12-14 01:36:52,884 iteration 639 : loss : 0.131894, loss_ce: 0.048646
2021-12-14 01:36:54,479 iteration 640 : loss : 0.128309, loss_ce: 0.032909
2021-12-14 01:36:55,927 iteration 641 : loss : 0.120740, loss_ce: 0.036174
2021-12-14 01:36:57,460 iteration 642 : loss : 0.139478, loss_ce: 0.041032
2021-12-14 01:36:58,945 iteration 643 : loss : 0.127995, loss_ce: 0.036444
2021-12-14 01:37:00,454 iteration 644 : loss : 0.139325, loss_ce: 0.036107
2021-12-14 01:37:01,920 iteration 645 : loss : 0.150569, loss_ce: 0.049024
2021-12-14 01:37:03,486 iteration 646 : loss : 0.130249, loss_ce: 0.039742
 10%|██▊                           | 38/400 [18:08<2:44:54, 27.33s/it]2021-12-14 01:37:05,024 iteration 647 : loss : 0.127269, loss_ce: 0.041408
2021-12-14 01:37:06,606 iteration 648 : loss : 0.162556, loss_ce: 0.057876
2021-12-14 01:37:08,159 iteration 649 : loss : 0.123202, loss_ce: 0.038596
2021-12-14 01:37:09,582 iteration 650 : loss : 0.124773, loss_ce: 0.043197
2021-12-14 01:37:11,102 iteration 651 : loss : 0.149557, loss_ce: 0.043754
2021-12-14 01:37:12,546 iteration 652 : loss : 0.140800, loss_ce: 0.040914
2021-12-14 01:37:14,080 iteration 653 : loss : 0.162049, loss_ce: 0.043230
2021-12-14 01:37:15,682 iteration 654 : loss : 0.156514, loss_ce: 0.046061
2021-12-14 01:37:17,245 iteration 655 : loss : 0.111918, loss_ce: 0.032585
2021-12-14 01:37:18,684 iteration 656 : loss : 0.123317, loss_ce: 0.038457
2021-12-14 01:37:20,205 iteration 657 : loss : 0.122919, loss_ce: 0.041549
2021-12-14 01:37:21,787 iteration 658 : loss : 0.218207, loss_ce: 0.064356
2021-12-14 01:37:23,380 iteration 659 : loss : 0.128786, loss_ce: 0.043561
2021-12-14 01:37:24,927 iteration 660 : loss : 0.153945, loss_ce: 0.048072
2021-12-14 01:37:26,450 iteration 661 : loss : 0.128208, loss_ce: 0.045630
2021-12-14 01:37:27,913 iteration 662 : loss : 0.122008, loss_ce: 0.044842
2021-12-14 01:37:29,431 iteration 663 : loss : 0.140455, loss_ce: 0.039389
 10%|██▉                           | 39/400 [18:34<2:41:57, 26.92s/it]2021-12-14 01:37:30,963 iteration 664 : loss : 0.133915, loss_ce: 0.049446
2021-12-14 01:37:32,463 iteration 665 : loss : 0.131958, loss_ce: 0.046190
2021-12-14 01:37:33,995 iteration 666 : loss : 0.123865, loss_ce: 0.037887
2021-12-14 01:37:35,447 iteration 667 : loss : 0.133299, loss_ce: 0.044201
2021-12-14 01:37:37,038 iteration 668 : loss : 0.130911, loss_ce: 0.042088
2021-12-14 01:37:38,505 iteration 669 : loss : 0.146412, loss_ce: 0.051186
2021-12-14 01:37:39,979 iteration 670 : loss : 0.122462, loss_ce: 0.041112
2021-12-14 01:37:41,557 iteration 671 : loss : 0.121475, loss_ce: 0.031833
2021-12-14 01:37:43,145 iteration 672 : loss : 0.130463, loss_ce: 0.038359
2021-12-14 01:37:44,589 iteration 673 : loss : 0.126023, loss_ce: 0.046305
2021-12-14 01:37:46,131 iteration 674 : loss : 0.161027, loss_ce: 0.053041
2021-12-14 01:37:47,698 iteration 675 : loss : 0.132232, loss_ce: 0.039966
2021-12-14 01:37:49,192 iteration 676 : loss : 0.127479, loss_ce: 0.032133
2021-12-14 01:37:50,730 iteration 677 : loss : 0.140603, loss_ce: 0.052025
2021-12-14 01:37:52,236 iteration 678 : loss : 0.134638, loss_ce: 0.041718
2021-12-14 01:37:53,686 iteration 679 : loss : 0.142505, loss_ce: 0.053624
2021-12-14 01:37:53,687 Training Data Eval:
2021-12-14 01:38:01,114   Average segmentation loss on training set: 0.1130
2021-12-14 01:38:01,114 Validation Data Eval:
2021-12-14 01:38:03,685   Average segmentation loss on validation set: 0.1349
2021-12-14 01:38:09,806 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 01:38:11,362 iteration 680 : loss : 0.160561, loss_ce: 0.030575
 10%|███                           | 40/400 [19:16<3:08:30, 31.42s/it]2021-12-14 01:38:13,027 iteration 681 : loss : 0.132164, loss_ce: 0.047668
2021-12-14 01:38:14,493 iteration 682 : loss : 0.122806, loss_ce: 0.032087
2021-12-14 01:38:16,033 iteration 683 : loss : 0.121027, loss_ce: 0.039733
2021-12-14 01:38:17,582 iteration 684 : loss : 0.137201, loss_ce: 0.043999
2021-12-14 01:38:19,188 iteration 685 : loss : 0.122415, loss_ce: 0.037024
2021-12-14 01:38:20,586 iteration 686 : loss : 0.127512, loss_ce: 0.036487
2021-12-14 01:38:22,051 iteration 687 : loss : 0.112655, loss_ce: 0.032241
2021-12-14 01:38:23,654 iteration 688 : loss : 0.143483, loss_ce: 0.050677
2021-12-14 01:38:25,186 iteration 689 : loss : 0.121248, loss_ce: 0.038688
2021-12-14 01:38:26,642 iteration 690 : loss : 0.155784, loss_ce: 0.061482
2021-12-14 01:38:28,268 iteration 691 : loss : 0.134807, loss_ce: 0.045823
2021-12-14 01:38:29,877 iteration 692 : loss : 0.134138, loss_ce: 0.034400
2021-12-14 01:38:31,465 iteration 693 : loss : 0.134233, loss_ce: 0.039976
2021-12-14 01:38:32,991 iteration 694 : loss : 0.123030, loss_ce: 0.035266
2021-12-14 01:38:34,510 iteration 695 : loss : 0.122531, loss_ce: 0.031403
2021-12-14 01:38:36,019 iteration 696 : loss : 0.128285, loss_ce: 0.037772
2021-12-14 01:38:37,549 iteration 697 : loss : 0.143169, loss_ce: 0.041766
 10%|███                           | 41/400 [19:42<2:58:36, 29.85s/it]2021-12-14 01:38:39,098 iteration 698 : loss : 0.137443, loss_ce: 0.043359
2021-12-14 01:38:40,630 iteration 699 : loss : 0.120646, loss_ce: 0.031919
2021-12-14 01:38:42,152 iteration 700 : loss : 0.121640, loss_ce: 0.038383
2021-12-14 01:38:43,632 iteration 701 : loss : 0.140721, loss_ce: 0.045822
2021-12-14 01:38:45,198 iteration 702 : loss : 0.122074, loss_ce: 0.031768
2021-12-14 01:38:46,709 iteration 703 : loss : 0.128919, loss_ce: 0.042134
2021-12-14 01:38:48,200 iteration 704 : loss : 0.154918, loss_ce: 0.040009
2021-12-14 01:38:49,659 iteration 705 : loss : 0.144914, loss_ce: 0.052795
2021-12-14 01:38:51,234 iteration 706 : loss : 0.130784, loss_ce: 0.042021
2021-12-14 01:38:52,791 iteration 707 : loss : 0.142155, loss_ce: 0.051122
2021-12-14 01:38:54,332 iteration 708 : loss : 0.136285, loss_ce: 0.042249
2021-12-14 01:38:55,893 iteration 709 : loss : 0.120888, loss_ce: 0.038287
2021-12-14 01:38:57,414 iteration 710 : loss : 0.125084, loss_ce: 0.036736
2021-12-14 01:38:58,993 iteration 711 : loss : 0.165594, loss_ce: 0.050367
2021-12-14 01:39:00,603 iteration 712 : loss : 0.138085, loss_ce: 0.053796
2021-12-14 01:39:02,080 iteration 713 : loss : 0.122218, loss_ce: 0.041389
2021-12-14 01:39:03,602 iteration 714 : loss : 0.119624, loss_ce: 0.040435
 10%|███▏                          | 42/400 [20:08<2:51:17, 28.71s/it]2021-12-14 01:39:05,159 iteration 715 : loss : 0.130444, loss_ce: 0.046880
2021-12-14 01:39:06,668 iteration 716 : loss : 0.154798, loss_ce: 0.046225
2021-12-14 01:39:08,169 iteration 717 : loss : 0.120915, loss_ce: 0.036237
2021-12-14 01:39:09,553 iteration 718 : loss : 0.122690, loss_ce: 0.036339
2021-12-14 01:39:11,058 iteration 719 : loss : 0.146497, loss_ce: 0.055919
2021-12-14 01:39:12,469 iteration 720 : loss : 0.125001, loss_ce: 0.039674
2021-12-14 01:39:14,145 iteration 721 : loss : 0.142376, loss_ce: 0.040301
2021-12-14 01:39:15,664 iteration 722 : loss : 0.118476, loss_ce: 0.038687
2021-12-14 01:39:17,207 iteration 723 : loss : 0.133375, loss_ce: 0.038054
2021-12-14 01:39:18,839 iteration 724 : loss : 0.127266, loss_ce: 0.042938
2021-12-14 01:39:20,304 iteration 725 : loss : 0.122325, loss_ce: 0.036482
2021-12-14 01:39:21,862 iteration 726 : loss : 0.148394, loss_ce: 0.055899
2021-12-14 01:39:23,332 iteration 727 : loss : 0.113100, loss_ce: 0.034356
2021-12-14 01:39:24,823 iteration 728 : loss : 0.123041, loss_ce: 0.031858
2021-12-14 01:39:26,317 iteration 729 : loss : 0.137968, loss_ce: 0.049449
2021-12-14 01:39:27,854 iteration 730 : loss : 0.131560, loss_ce: 0.037433
2021-12-14 01:39:29,327 iteration 731 : loss : 0.155498, loss_ce: 0.048474
 11%|███▏                          | 43/400 [20:34<2:45:30, 27.82s/it]2021-12-14 01:39:30,965 iteration 732 : loss : 0.122229, loss_ce: 0.039722
2021-12-14 01:39:32,525 iteration 733 : loss : 0.137432, loss_ce: 0.048542
2021-12-14 01:39:34,065 iteration 734 : loss : 0.175774, loss_ce: 0.065852
2021-12-14 01:39:35,620 iteration 735 : loss : 0.131011, loss_ce: 0.038429
2021-12-14 01:39:37,175 iteration 736 : loss : 0.117259, loss_ce: 0.037416
2021-12-14 01:39:38,615 iteration 737 : loss : 0.120882, loss_ce: 0.036469
2021-12-14 01:39:40,213 iteration 738 : loss : 0.163875, loss_ce: 0.060972
2021-12-14 01:39:41,777 iteration 739 : loss : 0.138209, loss_ce: 0.054425
2021-12-14 01:39:43,298 iteration 740 : loss : 0.117047, loss_ce: 0.033139
2021-12-14 01:39:44,857 iteration 741 : loss : 0.124220, loss_ce: 0.036396
2021-12-14 01:39:46,434 iteration 742 : loss : 0.126738, loss_ce: 0.037911
2021-12-14 01:39:47,949 iteration 743 : loss : 0.124417, loss_ce: 0.032410
2021-12-14 01:39:49,496 iteration 744 : loss : 0.116753, loss_ce: 0.036713
2021-12-14 01:39:51,012 iteration 745 : loss : 0.145490, loss_ce: 0.046652
2021-12-14 01:39:52,505 iteration 746 : loss : 0.168349, loss_ce: 0.045204
2021-12-14 01:39:54,003 iteration 747 : loss : 0.127262, loss_ce: 0.047367
2021-12-14 01:39:55,535 iteration 748 : loss : 0.144691, loss_ce: 0.041833
 11%|███▎                          | 44/400 [21:00<2:42:08, 27.33s/it]2021-12-14 01:39:57,080 iteration 749 : loss : 0.139540, loss_ce: 0.040496
2021-12-14 01:39:58,595 iteration 750 : loss : 0.124370, loss_ce: 0.032074
2021-12-14 01:40:00,179 iteration 751 : loss : 0.118809, loss_ce: 0.035212
2021-12-14 01:40:01,682 iteration 752 : loss : 0.151352, loss_ce: 0.050538
2021-12-14 01:40:03,246 iteration 753 : loss : 0.119149, loss_ce: 0.037257
2021-12-14 01:40:04,754 iteration 754 : loss : 0.109210, loss_ce: 0.027269
2021-12-14 01:40:06,279 iteration 755 : loss : 0.113358, loss_ce: 0.031917
2021-12-14 01:40:07,684 iteration 756 : loss : 0.115869, loss_ce: 0.034870
2021-12-14 01:40:09,120 iteration 757 : loss : 0.133613, loss_ce: 0.043537
2021-12-14 01:40:10,637 iteration 758 : loss : 0.127604, loss_ce: 0.034513
2021-12-14 01:40:12,214 iteration 759 : loss : 0.151702, loss_ce: 0.045500
2021-12-14 01:40:13,764 iteration 760 : loss : 0.128181, loss_ce: 0.037776
2021-12-14 01:40:15,337 iteration 761 : loss : 0.126639, loss_ce: 0.033822
2021-12-14 01:40:16,746 iteration 762 : loss : 0.116391, loss_ce: 0.039181
2021-12-14 01:40:18,263 iteration 763 : loss : 0.118673, loss_ce: 0.041616
2021-12-14 01:40:19,683 iteration 764 : loss : 0.111719, loss_ce: 0.032912
2021-12-14 01:40:19,683 Training Data Eval:
2021-12-14 01:40:27,112   Average segmentation loss on training set: 0.1455
2021-12-14 01:40:27,112 Validation Data Eval:
2021-12-14 01:40:29,683   Average segmentation loss on validation set: 0.1500
2021-12-14 01:40:31,091 iteration 765 : loss : 0.111195, loss_ce: 0.035026
 11%|███▍                          | 45/400 [21:36<2:56:18, 29.80s/it]2021-12-14 01:40:32,774 iteration 766 : loss : 0.119337, loss_ce: 0.034549
2021-12-14 01:40:34,470 iteration 767 : loss : 0.135788, loss_ce: 0.044214
2021-12-14 01:40:36,023 iteration 768 : loss : 0.130153, loss_ce: 0.043098
2021-12-14 01:40:37,602 iteration 769 : loss : 0.134807, loss_ce: 0.045810
2021-12-14 01:40:39,239 iteration 770 : loss : 0.129910, loss_ce: 0.047433
2021-12-14 01:40:40,776 iteration 771 : loss : 0.130323, loss_ce: 0.049555
2021-12-14 01:40:42,211 iteration 772 : loss : 0.125573, loss_ce: 0.040733
2021-12-14 01:40:43,717 iteration 773 : loss : 0.160366, loss_ce: 0.049458
2021-12-14 01:40:45,327 iteration 774 : loss : 0.166099, loss_ce: 0.063393
2021-12-14 01:40:46,753 iteration 775 : loss : 0.128999, loss_ce: 0.041726
2021-12-14 01:40:48,238 iteration 776 : loss : 0.147468, loss_ce: 0.033487
2021-12-14 01:40:49,920 iteration 777 : loss : 0.114202, loss_ce: 0.036707
2021-12-14 01:40:51,441 iteration 778 : loss : 0.127017, loss_ce: 0.033517
2021-12-14 01:40:52,941 iteration 779 : loss : 0.133894, loss_ce: 0.040626
2021-12-14 01:40:54,596 iteration 780 : loss : 0.160407, loss_ce: 0.056389
2021-12-14 01:40:56,194 iteration 781 : loss : 0.129664, loss_ce: 0.034345
2021-12-14 01:40:57,672 iteration 782 : loss : 0.137042, loss_ce: 0.038616
 12%|███▍                          | 46/400 [22:02<2:50:07, 28.83s/it]2021-12-14 01:40:59,246 iteration 783 : loss : 0.122188, loss_ce: 0.036212
2021-12-14 01:41:00,721 iteration 784 : loss : 0.111643, loss_ce: 0.028199
2021-12-14 01:41:02,317 iteration 785 : loss : 0.126097, loss_ce: 0.034806
2021-12-14 01:41:03,812 iteration 786 : loss : 0.127722, loss_ce: 0.040210
2021-12-14 01:41:05,395 iteration 787 : loss : 0.143344, loss_ce: 0.053077
2021-12-14 01:41:06,869 iteration 788 : loss : 0.141513, loss_ce: 0.051602
2021-12-14 01:41:08,444 iteration 789 : loss : 0.143012, loss_ce: 0.045410
2021-12-14 01:41:10,041 iteration 790 : loss : 0.114818, loss_ce: 0.034279
2021-12-14 01:41:11,482 iteration 791 : loss : 0.120822, loss_ce: 0.043413
2021-12-14 01:41:13,089 iteration 792 : loss : 0.120388, loss_ce: 0.037599
2021-12-14 01:41:14,643 iteration 793 : loss : 0.130762, loss_ce: 0.039876
2021-12-14 01:41:16,224 iteration 794 : loss : 0.110029, loss_ce: 0.032172
2021-12-14 01:41:17,795 iteration 795 : loss : 0.127575, loss_ce: 0.040730
2021-12-14 01:41:19,427 iteration 796 : loss : 0.124677, loss_ce: 0.041171
2021-12-14 01:41:20,933 iteration 797 : loss : 0.114432, loss_ce: 0.037347
2021-12-14 01:41:22,439 iteration 798 : loss : 0.121294, loss_ce: 0.037912
2021-12-14 01:41:24,118 iteration 799 : loss : 0.136408, loss_ce: 0.035677
 12%|███▌                          | 47/400 [22:29<2:45:25, 28.12s/it]2021-12-14 01:41:25,726 iteration 800 : loss : 0.151085, loss_ce: 0.056690
2021-12-14 01:41:27,219 iteration 801 : loss : 0.134779, loss_ce: 0.034203
2021-12-14 01:41:28,808 iteration 802 : loss : 0.130731, loss_ce: 0.051134
2021-12-14 01:41:30,238 iteration 803 : loss : 0.110000, loss_ce: 0.032447
2021-12-14 01:41:31,859 iteration 804 : loss : 0.141913, loss_ce: 0.037154
2021-12-14 01:41:33,355 iteration 805 : loss : 0.124763, loss_ce: 0.036124
2021-12-14 01:41:34,784 iteration 806 : loss : 0.133885, loss_ce: 0.041813
2021-12-14 01:41:36,290 iteration 807 : loss : 0.116674, loss_ce: 0.040656
2021-12-14 01:41:37,803 iteration 808 : loss : 0.131198, loss_ce: 0.030497
2021-12-14 01:41:39,403 iteration 809 : loss : 0.121562, loss_ce: 0.036482
2021-12-14 01:41:40,877 iteration 810 : loss : 0.108334, loss_ce: 0.026580
2021-12-14 01:41:42,418 iteration 811 : loss : 0.151241, loss_ce: 0.052794
2021-12-14 01:41:43,879 iteration 812 : loss : 0.127850, loss_ce: 0.044352
2021-12-14 01:41:45,491 iteration 813 : loss : 0.114635, loss_ce: 0.036269
2021-12-14 01:41:47,136 iteration 814 : loss : 0.156234, loss_ce: 0.031605
2021-12-14 01:41:48,493 iteration 815 : loss : 0.110502, loss_ce: 0.038457
2021-12-14 01:41:50,099 iteration 816 : loss : 0.135318, loss_ce: 0.045528
 12%|███▌                          | 48/400 [22:55<2:41:11, 27.48s/it]2021-12-14 01:41:51,618 iteration 817 : loss : 0.128345, loss_ce: 0.039604
2021-12-14 01:41:53,105 iteration 818 : loss : 0.124941, loss_ce: 0.043350
2021-12-14 01:41:54,800 iteration 819 : loss : 0.133787, loss_ce: 0.046701
2021-12-14 01:41:56,420 iteration 820 : loss : 0.127724, loss_ce: 0.038330
2021-12-14 01:41:57,995 iteration 821 : loss : 0.134475, loss_ce: 0.042404
2021-12-14 01:41:59,510 iteration 822 : loss : 0.118863, loss_ce: 0.039271
2021-12-14 01:42:01,080 iteration 823 : loss : 0.112679, loss_ce: 0.030146
2021-12-14 01:42:02,529 iteration 824 : loss : 0.118451, loss_ce: 0.030308
2021-12-14 01:42:04,038 iteration 825 : loss : 0.148342, loss_ce: 0.036883
2021-12-14 01:42:05,467 iteration 826 : loss : 0.120011, loss_ce: 0.034992
2021-12-14 01:42:06,985 iteration 827 : loss : 0.124004, loss_ce: 0.032844
2021-12-14 01:42:08,399 iteration 828 : loss : 0.124236, loss_ce: 0.037812
2021-12-14 01:42:10,001 iteration 829 : loss : 0.130078, loss_ce: 0.045284
2021-12-14 01:42:11,498 iteration 830 : loss : 0.126968, loss_ce: 0.043007
2021-12-14 01:42:13,069 iteration 831 : loss : 0.134093, loss_ce: 0.043873
2021-12-14 01:42:14,596 iteration 832 : loss : 0.139298, loss_ce: 0.038542
2021-12-14 01:42:16,134 iteration 833 : loss : 0.117614, loss_ce: 0.035452
 12%|███▋                          | 49/400 [23:21<2:38:11, 27.04s/it]2021-12-14 01:42:17,615 iteration 834 : loss : 0.121585, loss_ce: 0.036875
2021-12-14 01:42:19,019 iteration 835 : loss : 0.102394, loss_ce: 0.027326
2021-12-14 01:42:20,616 iteration 836 : loss : 0.117176, loss_ce: 0.031320
2021-12-14 01:42:22,099 iteration 837 : loss : 0.106931, loss_ce: 0.029620
2021-12-14 01:42:23,659 iteration 838 : loss : 0.127614, loss_ce: 0.042536
2021-12-14 01:42:25,069 iteration 839 : loss : 0.115803, loss_ce: 0.033565
2021-12-14 01:42:26,492 iteration 840 : loss : 0.118038, loss_ce: 0.036266
2021-12-14 01:42:27,933 iteration 841 : loss : 0.120907, loss_ce: 0.034525
2021-12-14 01:42:29,556 iteration 842 : loss : 0.142396, loss_ce: 0.041110
2021-12-14 01:42:31,015 iteration 843 : loss : 0.117180, loss_ce: 0.030620
2021-12-14 01:42:32,618 iteration 844 : loss : 0.117479, loss_ce: 0.033713
2021-12-14 01:42:34,101 iteration 845 : loss : 0.123497, loss_ce: 0.044216
2021-12-14 01:42:35,591 iteration 846 : loss : 0.122504, loss_ce: 0.040139
2021-12-14 01:42:37,215 iteration 847 : loss : 0.124920, loss_ce: 0.038643
2021-12-14 01:42:38,717 iteration 848 : loss : 0.108625, loss_ce: 0.031602
2021-12-14 01:42:40,196 iteration 849 : loss : 0.116787, loss_ce: 0.034473
2021-12-14 01:42:40,196 Training Data Eval:
2021-12-14 01:42:47,632   Average segmentation loss on training set: 0.1263
2021-12-14 01:42:47,633 Validation Data Eval:
2021-12-14 01:42:50,198   Average segmentation loss on validation set: 0.1398
2021-12-14 01:42:51,642 iteration 850 : loss : 0.129681, loss_ce: 0.050203
 12%|███▊                          | 50/400 [23:56<2:52:34, 29.58s/it]2021-12-14 01:42:53,208 iteration 851 : loss : 0.119956, loss_ce: 0.038974
2021-12-14 01:42:54,704 iteration 852 : loss : 0.130895, loss_ce: 0.037719
2021-12-14 01:42:56,242 iteration 853 : loss : 0.118106, loss_ce: 0.028421
2021-12-14 01:42:57,781 iteration 854 : loss : 0.114850, loss_ce: 0.037191
2021-12-14 01:42:59,259 iteration 855 : loss : 0.127511, loss_ce: 0.046047
2021-12-14 01:43:00,825 iteration 856 : loss : 0.125168, loss_ce: 0.043773
2021-12-14 01:43:02,300 iteration 857 : loss : 0.133646, loss_ce: 0.042343
2021-12-14 01:43:03,917 iteration 858 : loss : 0.102409, loss_ce: 0.029382
2021-12-14 01:43:05,261 iteration 859 : loss : 0.106624, loss_ce: 0.026347
2021-12-14 01:43:06,764 iteration 860 : loss : 0.111235, loss_ce: 0.031843
2021-12-14 01:43:08,262 iteration 861 : loss : 0.131353, loss_ce: 0.034490
2021-12-14 01:43:09,782 iteration 862 : loss : 0.132810, loss_ce: 0.049838
2021-12-14 01:43:11,298 iteration 863 : loss : 0.145600, loss_ce: 0.048383
2021-12-14 01:43:12,789 iteration 864 : loss : 0.112436, loss_ce: 0.035200
2021-12-14 01:43:14,313 iteration 865 : loss : 0.124201, loss_ce: 0.035980
2021-12-14 01:43:15,772 iteration 866 : loss : 0.113819, loss_ce: 0.036937
2021-12-14 01:43:17,327 iteration 867 : loss : 0.117339, loss_ce: 0.036423
 13%|███▊                          | 51/400 [24:22<2:45:17, 28.42s/it]2021-12-14 01:43:18,895 iteration 868 : loss : 0.121400, loss_ce: 0.036224
2021-12-14 01:43:20,457 iteration 869 : loss : 0.119796, loss_ce: 0.039648
2021-12-14 01:43:21,867 iteration 870 : loss : 0.114869, loss_ce: 0.036335
2021-12-14 01:43:23,343 iteration 871 : loss : 0.125222, loss_ce: 0.044771
2021-12-14 01:43:24,800 iteration 872 : loss : 0.118839, loss_ce: 0.039500
2021-12-14 01:43:26,348 iteration 873 : loss : 0.128331, loss_ce: 0.043922
2021-12-14 01:43:27,850 iteration 874 : loss : 0.114829, loss_ce: 0.035361
2021-12-14 01:43:29,368 iteration 875 : loss : 0.122839, loss_ce: 0.031191
2021-12-14 01:43:30,895 iteration 876 : loss : 0.106077, loss_ce: 0.028264
2021-12-14 01:43:32,503 iteration 877 : loss : 0.117686, loss_ce: 0.035274
2021-12-14 01:43:33,968 iteration 878 : loss : 0.134323, loss_ce: 0.030655
2021-12-14 01:43:35,466 iteration 879 : loss : 0.121180, loss_ce: 0.027720
2021-12-14 01:43:36,930 iteration 880 : loss : 0.114374, loss_ce: 0.041713
2021-12-14 01:43:38,515 iteration 881 : loss : 0.118560, loss_ce: 0.029905
2021-12-14 01:43:40,064 iteration 882 : loss : 0.130737, loss_ce: 0.040249
2021-12-14 01:43:41,535 iteration 883 : loss : 0.107423, loss_ce: 0.026722
2021-12-14 01:43:43,095 iteration 884 : loss : 0.127934, loss_ce: 0.041907
 13%|███▉                          | 52/400 [24:48<2:40:11, 27.62s/it]2021-12-14 01:43:44,685 iteration 885 : loss : 0.117934, loss_ce: 0.036013
2021-12-14 01:43:46,201 iteration 886 : loss : 0.131410, loss_ce: 0.046265
2021-12-14 01:43:47,732 iteration 887 : loss : 0.117580, loss_ce: 0.034288
2021-12-14 01:43:49,266 iteration 888 : loss : 0.122235, loss_ce: 0.036712
2021-12-14 01:43:50,788 iteration 889 : loss : 0.152108, loss_ce: 0.032380
2021-12-14 01:43:52,270 iteration 890 : loss : 0.119358, loss_ce: 0.036058
2021-12-14 01:43:53,793 iteration 891 : loss : 0.116259, loss_ce: 0.047888
2021-12-14 01:43:55,310 iteration 892 : loss : 0.105922, loss_ce: 0.032437
2021-12-14 01:43:56,812 iteration 893 : loss : 0.111300, loss_ce: 0.036498
2021-12-14 01:43:58,305 iteration 894 : loss : 0.112633, loss_ce: 0.028802
2021-12-14 01:43:59,787 iteration 895 : loss : 0.125373, loss_ce: 0.031284
2021-12-14 01:44:01,250 iteration 896 : loss : 0.114851, loss_ce: 0.035214
2021-12-14 01:44:02,960 iteration 897 : loss : 0.152680, loss_ce: 0.044036
2021-12-14 01:44:04,440 iteration 898 : loss : 0.126029, loss_ce: 0.037917
2021-12-14 01:44:06,015 iteration 899 : loss : 0.109173, loss_ce: 0.031108
2021-12-14 01:44:07,578 iteration 900 : loss : 0.110896, loss_ce: 0.027437
2021-12-14 01:44:09,065 iteration 901 : loss : 0.115322, loss_ce: 0.033867
 13%|███▉                          | 53/400 [25:14<2:36:53, 27.13s/it]2021-12-14 01:44:10,731 iteration 902 : loss : 0.115481, loss_ce: 0.039853
2021-12-14 01:44:12,287 iteration 903 : loss : 0.132417, loss_ce: 0.036487
2021-12-14 01:44:13,800 iteration 904 : loss : 0.126931, loss_ce: 0.042303
2021-12-14 01:44:15,296 iteration 905 : loss : 0.116022, loss_ce: 0.039068
2021-12-14 01:44:16,918 iteration 906 : loss : 0.125294, loss_ce: 0.039961
2021-12-14 01:44:18,376 iteration 907 : loss : 0.115108, loss_ce: 0.036959
2021-12-14 01:44:19,871 iteration 908 : loss : 0.113582, loss_ce: 0.042895
2021-12-14 01:44:21,423 iteration 909 : loss : 0.110271, loss_ce: 0.033833
2021-12-14 01:44:23,046 iteration 910 : loss : 0.122873, loss_ce: 0.040049
2021-12-14 01:44:24,565 iteration 911 : loss : 0.112948, loss_ce: 0.032079
2021-12-14 01:44:26,130 iteration 912 : loss : 0.111843, loss_ce: 0.033670
2021-12-14 01:44:27,641 iteration 913 : loss : 0.138145, loss_ce: 0.036882
2021-12-14 01:44:29,061 iteration 914 : loss : 0.122174, loss_ce: 0.036921
2021-12-14 01:44:30,601 iteration 915 : loss : 0.135163, loss_ce: 0.042239
2021-12-14 01:44:32,211 iteration 916 : loss : 0.143300, loss_ce: 0.037771
2021-12-14 01:44:33,751 iteration 917 : loss : 0.120722, loss_ce: 0.039053
2021-12-14 01:44:35,383 iteration 918 : loss : 0.123440, loss_ce: 0.033903
 14%|████                          | 54/400 [25:40<2:35:01, 26.88s/it]2021-12-14 01:44:36,940 iteration 919 : loss : 0.123317, loss_ce: 0.034640
2021-12-14 01:44:38,545 iteration 920 : loss : 0.112089, loss_ce: 0.035904
2021-12-14 01:44:39,996 iteration 921 : loss : 0.107161, loss_ce: 0.030822
2021-12-14 01:44:41,554 iteration 922 : loss : 0.116971, loss_ce: 0.027904
2021-12-14 01:44:42,978 iteration 923 : loss : 0.100656, loss_ce: 0.027366
2021-12-14 01:44:44,523 iteration 924 : loss : 0.136104, loss_ce: 0.034117
2021-12-14 01:44:46,091 iteration 925 : loss : 0.118117, loss_ce: 0.027818
2021-12-14 01:44:47,636 iteration 926 : loss : 0.113704, loss_ce: 0.028239
2021-12-14 01:44:49,061 iteration 927 : loss : 0.128977, loss_ce: 0.033509
2021-12-14 01:44:50,655 iteration 928 : loss : 0.126043, loss_ce: 0.041329
2021-12-14 01:44:52,168 iteration 929 : loss : 0.105690, loss_ce: 0.030290
2021-12-14 01:44:53,597 iteration 930 : loss : 0.110711, loss_ce: 0.032124
2021-12-14 01:44:55,060 iteration 931 : loss : 0.127268, loss_ce: 0.049912
2021-12-14 01:44:56,584 iteration 932 : loss : 0.106844, loss_ce: 0.037386
2021-12-14 01:44:58,148 iteration 933 : loss : 0.125046, loss_ce: 0.045730
2021-12-14 01:44:59,607 iteration 934 : loss : 0.118092, loss_ce: 0.032266
2021-12-14 01:44:59,607 Training Data Eval:
2021-12-14 01:45:07,056   Average segmentation loss on training set: 0.1329
2021-12-14 01:45:07,057 Validation Data Eval:
2021-12-14 01:45:09,636   Average segmentation loss on validation set: 0.1401
2021-12-14 01:45:11,180 iteration 935 : loss : 0.120829, loss_ce: 0.037738
 14%|████▏                         | 55/400 [26:16<2:49:56, 29.56s/it]2021-12-14 01:45:12,766 iteration 936 : loss : 0.121796, loss_ce: 0.039780
2021-12-14 01:45:14,254 iteration 937 : loss : 0.130587, loss_ce: 0.041131
2021-12-14 01:45:15,796 iteration 938 : loss : 0.109255, loss_ce: 0.031603
2021-12-14 01:45:17,441 iteration 939 : loss : 0.112525, loss_ce: 0.026151
2021-12-14 01:45:18,889 iteration 940 : loss : 0.128526, loss_ce: 0.040679
2021-12-14 01:45:20,370 iteration 941 : loss : 0.137336, loss_ce: 0.043972
2021-12-14 01:45:21,877 iteration 942 : loss : 0.117032, loss_ce: 0.041550
2021-12-14 01:45:23,428 iteration 943 : loss : 0.138586, loss_ce: 0.036183
2021-12-14 01:45:24,935 iteration 944 : loss : 0.138473, loss_ce: 0.041659
2021-12-14 01:45:26,482 iteration 945 : loss : 0.123633, loss_ce: 0.041762
2021-12-14 01:45:27,982 iteration 946 : loss : 0.114439, loss_ce: 0.036186
2021-12-14 01:45:29,507 iteration 947 : loss : 0.101691, loss_ce: 0.026229
2021-12-14 01:45:31,121 iteration 948 : loss : 0.116529, loss_ce: 0.036519
2021-12-14 01:45:32,724 iteration 949 : loss : 0.127839, loss_ce: 0.041175
2021-12-14 01:45:34,350 iteration 950 : loss : 0.137469, loss_ce: 0.043272
2021-12-14 01:45:35,849 iteration 951 : loss : 0.123684, loss_ce: 0.038830
2021-12-14 01:45:37,418 iteration 952 : loss : 0.124078, loss_ce: 0.033150
 14%|████▏                         | 56/400 [26:42<2:43:45, 28.56s/it]2021-12-14 01:45:38,948 iteration 953 : loss : 0.145319, loss_ce: 0.046596
2021-12-14 01:45:40,431 iteration 954 : loss : 0.110498, loss_ce: 0.031686
2021-12-14 01:45:41,985 iteration 955 : loss : 0.120284, loss_ce: 0.033339
2021-12-14 01:45:43,538 iteration 956 : loss : 0.096601, loss_ce: 0.024494
2021-12-14 01:45:45,059 iteration 957 : loss : 0.132302, loss_ce: 0.044021
2021-12-14 01:45:46,625 iteration 958 : loss : 0.122586, loss_ce: 0.035064
2021-12-14 01:45:48,217 iteration 959 : loss : 0.126058, loss_ce: 0.043745
2021-12-14 01:45:49,776 iteration 960 : loss : 0.120510, loss_ce: 0.040151
2021-12-14 01:45:51,336 iteration 961 : loss : 0.120718, loss_ce: 0.034231
2021-12-14 01:45:52,907 iteration 962 : loss : 0.132492, loss_ce: 0.034226
2021-12-14 01:45:54,357 iteration 963 : loss : 0.111577, loss_ce: 0.037146
2021-12-14 01:45:55,912 iteration 964 : loss : 0.114748, loss_ce: 0.028531
2021-12-14 01:45:57,395 iteration 965 : loss : 0.101239, loss_ce: 0.027709
2021-12-14 01:45:59,031 iteration 966 : loss : 0.119524, loss_ce: 0.031698
2021-12-14 01:46:00,576 iteration 967 : loss : 0.118359, loss_ce: 0.041517
2021-12-14 01:46:01,991 iteration 968 : loss : 0.110603, loss_ce: 0.031820
2021-12-14 01:46:03,525 iteration 969 : loss : 0.110546, loss_ce: 0.037836
 14%|████▎                         | 57/400 [27:08<2:39:02, 27.82s/it]2021-12-14 01:46:05,033 iteration 970 : loss : 0.122681, loss_ce: 0.043176
2021-12-14 01:46:06,577 iteration 971 : loss : 0.122439, loss_ce: 0.041758
2021-12-14 01:46:08,083 iteration 972 : loss : 0.111859, loss_ce: 0.031550
2021-12-14 01:46:09,624 iteration 973 : loss : 0.103871, loss_ce: 0.031414
2021-12-14 01:46:11,139 iteration 974 : loss : 0.114843, loss_ce: 0.035522
2021-12-14 01:46:12,591 iteration 975 : loss : 0.119304, loss_ce: 0.031481
2021-12-14 01:46:14,203 iteration 976 : loss : 0.115384, loss_ce: 0.038530
2021-12-14 01:46:15,704 iteration 977 : loss : 0.112897, loss_ce: 0.033489
2021-12-14 01:46:17,243 iteration 978 : loss : 0.109708, loss_ce: 0.031876
2021-12-14 01:46:18,732 iteration 979 : loss : 0.108873, loss_ce: 0.033690
2021-12-14 01:46:20,234 iteration 980 : loss : 0.115540, loss_ce: 0.035526
2021-12-14 01:46:21,699 iteration 981 : loss : 0.094188, loss_ce: 0.022989
2021-12-14 01:46:23,249 iteration 982 : loss : 0.132569, loss_ce: 0.035822
2021-12-14 01:46:24,867 iteration 983 : loss : 0.131892, loss_ce: 0.041003
2021-12-14 01:46:26,466 iteration 984 : loss : 0.116120, loss_ce: 0.037415
2021-12-14 01:46:28,018 iteration 985 : loss : 0.118663, loss_ce: 0.038760
2021-12-14 01:46:29,493 iteration 986 : loss : 0.103437, loss_ce: 0.025261
 14%|████▎                         | 58/400 [27:34<2:35:25, 27.27s/it]2021-12-14 01:46:30,967 iteration 987 : loss : 0.112449, loss_ce: 0.031221
2021-12-14 01:46:32,467 iteration 988 : loss : 0.106523, loss_ce: 0.029222
2021-12-14 01:46:33,962 iteration 989 : loss : 0.104633, loss_ce: 0.030024
2021-12-14 01:46:35,466 iteration 990 : loss : 0.115447, loss_ce: 0.030828
2021-12-14 01:46:36,964 iteration 991 : loss : 0.133771, loss_ce: 0.041878
2021-12-14 01:46:38,429 iteration 992 : loss : 0.103372, loss_ce: 0.029686
2021-12-14 01:46:39,852 iteration 993 : loss : 0.103984, loss_ce: 0.027656
2021-12-14 01:46:41,202 iteration 994 : loss : 0.103686, loss_ce: 0.027338
2021-12-14 01:46:42,793 iteration 995 : loss : 0.110313, loss_ce: 0.035545
2021-12-14 01:46:44,357 iteration 996 : loss : 0.109982, loss_ce: 0.035754
2021-12-14 01:46:45,955 iteration 997 : loss : 0.136625, loss_ce: 0.041769
2021-12-14 01:46:47,503 iteration 998 : loss : 0.116227, loss_ce: 0.033326
2021-12-14 01:46:48,961 iteration 999 : loss : 0.108027, loss_ce: 0.031864
2021-12-14 01:46:50,567 iteration 1000 : loss : 0.113109, loss_ce: 0.042000
2021-12-14 01:46:52,053 iteration 1001 : loss : 0.105626, loss_ce: 0.028731
2021-12-14 01:46:53,636 iteration 1002 : loss : 0.134103, loss_ce: 0.041656
2021-12-14 01:46:55,070 iteration 1003 : loss : 0.163581, loss_ce: 0.034713
 15%|████▍                         | 59/400 [28:00<2:32:05, 26.76s/it]2021-12-14 01:46:56,653 iteration 1004 : loss : 0.112275, loss_ce: 0.028504
2021-12-14 01:46:58,150 iteration 1005 : loss : 0.117153, loss_ce: 0.044714
2021-12-14 01:46:59,782 iteration 1006 : loss : 0.114348, loss_ce: 0.038385
2021-12-14 01:47:01,377 iteration 1007 : loss : 0.127912, loss_ce: 0.043431
2021-12-14 01:47:02,988 iteration 1008 : loss : 0.133065, loss_ce: 0.054613
2021-12-14 01:47:04,467 iteration 1009 : loss : 0.108381, loss_ce: 0.033162
2021-12-14 01:47:05,888 iteration 1010 : loss : 0.098505, loss_ce: 0.023617
2021-12-14 01:47:07,382 iteration 1011 : loss : 0.123258, loss_ce: 0.037878
2021-12-14 01:47:08,954 iteration 1012 : loss : 0.116632, loss_ce: 0.037970
2021-12-14 01:47:10,466 iteration 1013 : loss : 0.112593, loss_ce: 0.032043
2021-12-14 01:47:11,961 iteration 1014 : loss : 0.100738, loss_ce: 0.026992
2021-12-14 01:47:13,650 iteration 1015 : loss : 0.132575, loss_ce: 0.038943
2021-12-14 01:47:15,152 iteration 1016 : loss : 0.113288, loss_ce: 0.032848
2021-12-14 01:47:16,625 iteration 1017 : loss : 0.124160, loss_ce: 0.037871
2021-12-14 01:47:18,241 iteration 1018 : loss : 0.120729, loss_ce: 0.032499
2021-12-14 01:47:19,810 iteration 1019 : loss : 0.117300, loss_ce: 0.035074
2021-12-14 01:47:19,810 Training Data Eval:
2021-12-14 01:47:27,242   Average segmentation loss on training set: 0.1004
2021-12-14 01:47:27,243 Validation Data Eval:
2021-12-14 01:47:29,818   Average segmentation loss on validation set: 0.1190
2021-12-14 01:47:35,691 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 01:47:37,334 iteration 1020 : loss : 0.122493, loss_ce: 0.036757
 15%|████▌                         | 60/400 [28:42<2:58:00, 31.41s/it]2021-12-14 01:47:38,883 iteration 1021 : loss : 0.110526, loss_ce: 0.031469
2021-12-14 01:47:40,511 iteration 1022 : loss : 0.121493, loss_ce: 0.042667
2021-12-14 01:47:41,979 iteration 1023 : loss : 0.101417, loss_ce: 0.027864
2021-12-14 01:47:43,473 iteration 1024 : loss : 0.102067, loss_ce: 0.030979
2021-12-14 01:47:45,043 iteration 1025 : loss : 0.115601, loss_ce: 0.036038
2021-12-14 01:47:46,583 iteration 1026 : loss : 0.118786, loss_ce: 0.024099
2021-12-14 01:47:48,085 iteration 1027 : loss : 0.100615, loss_ce: 0.024499
2021-12-14 01:47:49,709 iteration 1028 : loss : 0.129435, loss_ce: 0.036282
2021-12-14 01:47:51,283 iteration 1029 : loss : 0.122344, loss_ce: 0.032424
2021-12-14 01:47:52,816 iteration 1030 : loss : 0.126396, loss_ce: 0.041780
2021-12-14 01:47:54,483 iteration 1031 : loss : 0.116840, loss_ce: 0.039347
2021-12-14 01:47:56,027 iteration 1032 : loss : 0.124775, loss_ce: 0.046644
2021-12-14 01:47:57,520 iteration 1033 : loss : 0.125253, loss_ce: 0.047512
2021-12-14 01:47:58,984 iteration 1034 : loss : 0.119511, loss_ce: 0.039871
2021-12-14 01:48:00,577 iteration 1035 : loss : 0.116470, loss_ce: 0.038106
2021-12-14 01:48:02,181 iteration 1036 : loss : 0.113002, loss_ce: 0.033525
2021-12-14 01:48:03,605 iteration 1037 : loss : 0.093222, loss_ce: 0.026994
 15%|████▌                         | 61/400 [29:08<2:48:46, 29.87s/it]2021-12-14 01:48:05,140 iteration 1038 : loss : 0.107206, loss_ce: 0.031455
2021-12-14 01:48:06,638 iteration 1039 : loss : 0.114320, loss_ce: 0.037786
2021-12-14 01:48:08,124 iteration 1040 : loss : 0.130457, loss_ce: 0.037614
2021-12-14 01:48:09,634 iteration 1041 : loss : 0.113217, loss_ce: 0.037424
2021-12-14 01:48:11,123 iteration 1042 : loss : 0.108258, loss_ce: 0.040242
2021-12-14 01:48:12,628 iteration 1043 : loss : 0.104936, loss_ce: 0.030990
2021-12-14 01:48:14,223 iteration 1044 : loss : 0.104227, loss_ce: 0.033454
2021-12-14 01:48:15,765 iteration 1045 : loss : 0.125819, loss_ce: 0.040121
2021-12-14 01:48:17,232 iteration 1046 : loss : 0.108793, loss_ce: 0.035398
2021-12-14 01:48:18,597 iteration 1047 : loss : 0.100367, loss_ce: 0.027444
2021-12-14 01:48:20,123 iteration 1048 : loss : 0.105630, loss_ce: 0.033545
2021-12-14 01:48:21,703 iteration 1049 : loss : 0.118677, loss_ce: 0.037228
2021-12-14 01:48:23,203 iteration 1050 : loss : 0.137284, loss_ce: 0.027380
2021-12-14 01:48:24,696 iteration 1051 : loss : 0.103550, loss_ce: 0.032582
2021-12-14 01:48:26,276 iteration 1052 : loss : 0.121437, loss_ce: 0.031645
2021-12-14 01:48:27,844 iteration 1053 : loss : 0.118605, loss_ce: 0.026771
2021-12-14 01:48:29,373 iteration 1054 : loss : 0.104594, loss_ce: 0.027708
 16%|████▋                         | 62/400 [29:34<2:41:20, 28.64s/it]2021-12-14 01:48:30,947 iteration 1055 : loss : 0.097026, loss_ce: 0.019756
2021-12-14 01:48:32,367 iteration 1056 : loss : 0.103008, loss_ce: 0.031693
2021-12-14 01:48:33,919 iteration 1057 : loss : 0.174417, loss_ce: 0.062611
2021-12-14 01:48:35,447 iteration 1058 : loss : 0.122465, loss_ce: 0.032842
2021-12-14 01:48:36,980 iteration 1059 : loss : 0.128945, loss_ce: 0.041849
2021-12-14 01:48:38,413 iteration 1060 : loss : 0.112922, loss_ce: 0.028029
2021-12-14 01:48:40,068 iteration 1061 : loss : 0.107112, loss_ce: 0.037686
2021-12-14 01:48:41,619 iteration 1062 : loss : 0.124918, loss_ce: 0.030318
2021-12-14 01:48:43,324 iteration 1063 : loss : 0.115332, loss_ce: 0.038135
2021-12-14 01:48:44,883 iteration 1064 : loss : 0.133443, loss_ce: 0.035608
2021-12-14 01:48:46,521 iteration 1065 : loss : 0.120127, loss_ce: 0.041573
2021-12-14 01:48:47,993 iteration 1066 : loss : 0.102403, loss_ce: 0.028107
2021-12-14 01:48:49,475 iteration 1067 : loss : 0.103530, loss_ce: 0.031957
2021-12-14 01:48:51,057 iteration 1068 : loss : 0.111859, loss_ce: 0.036491
2021-12-14 01:48:52,607 iteration 1069 : loss : 0.105283, loss_ce: 0.034464
2021-12-14 01:48:54,270 iteration 1070 : loss : 0.130155, loss_ce: 0.031886
2021-12-14 01:48:55,809 iteration 1071 : loss : 0.108513, loss_ce: 0.038653
 16%|████▋                         | 63/400 [30:01<2:37:09, 27.98s/it]2021-12-14 01:48:57,526 iteration 1072 : loss : 0.113419, loss_ce: 0.028090
2021-12-14 01:48:59,084 iteration 1073 : loss : 0.130631, loss_ce: 0.042815
2021-12-14 01:49:00,649 iteration 1074 : loss : 0.112276, loss_ce: 0.030155
2021-12-14 01:49:02,215 iteration 1075 : loss : 0.134548, loss_ce: 0.029048
2021-12-14 01:49:03,711 iteration 1076 : loss : 0.103971, loss_ce: 0.030651
2021-12-14 01:49:05,336 iteration 1077 : loss : 0.112299, loss_ce: 0.025943
2021-12-14 01:49:06,823 iteration 1078 : loss : 0.115249, loss_ce: 0.041956
2021-12-14 01:49:08,438 iteration 1079 : loss : 0.130167, loss_ce: 0.041071
2021-12-14 01:49:09,868 iteration 1080 : loss : 0.097450, loss_ce: 0.024546
2021-12-14 01:49:11,369 iteration 1081 : loss : 0.108109, loss_ce: 0.037908
2021-12-14 01:49:12,945 iteration 1082 : loss : 0.111590, loss_ce: 0.038068
2021-12-14 01:49:14,427 iteration 1083 : loss : 0.102381, loss_ce: 0.028084
2021-12-14 01:49:15,933 iteration 1084 : loss : 0.108591, loss_ce: 0.028190
2021-12-14 01:49:17,471 iteration 1085 : loss : 0.104762, loss_ce: 0.034311
2021-12-14 01:49:18,983 iteration 1086 : loss : 0.117765, loss_ce: 0.041879
2021-12-14 01:49:20,605 iteration 1087 : loss : 0.102717, loss_ce: 0.029615
2021-12-14 01:49:22,118 iteration 1088 : loss : 0.102261, loss_ce: 0.030470
 16%|████▊                         | 64/400 [30:27<2:33:51, 27.47s/it]2021-12-14 01:49:23,661 iteration 1089 : loss : 0.131569, loss_ce: 0.040374
2021-12-14 01:49:25,170 iteration 1090 : loss : 0.111113, loss_ce: 0.025704
2021-12-14 01:49:26,764 iteration 1091 : loss : 0.114584, loss_ce: 0.039535
2021-12-14 01:49:28,296 iteration 1092 : loss : 0.106504, loss_ce: 0.033790
2021-12-14 01:49:29,831 iteration 1093 : loss : 0.111377, loss_ce: 0.029733
2021-12-14 01:49:31,392 iteration 1094 : loss : 0.107205, loss_ce: 0.034001
2021-12-14 01:49:32,955 iteration 1095 : loss : 0.114997, loss_ce: 0.025621
2021-12-14 01:49:34,487 iteration 1096 : loss : 0.094786, loss_ce: 0.029481
2021-12-14 01:49:35,962 iteration 1097 : loss : 0.120201, loss_ce: 0.028547
2021-12-14 01:49:37,430 iteration 1098 : loss : 0.098661, loss_ce: 0.034361
2021-12-14 01:49:38,978 iteration 1099 : loss : 0.107678, loss_ce: 0.031599
2021-12-14 01:49:40,473 iteration 1100 : loss : 0.096681, loss_ce: 0.030726
2021-12-14 01:49:41,966 iteration 1101 : loss : 0.100828, loss_ce: 0.028044
2021-12-14 01:49:43,579 iteration 1102 : loss : 0.107154, loss_ce: 0.027839
2021-12-14 01:49:45,080 iteration 1103 : loss : 0.108578, loss_ce: 0.030867
2021-12-14 01:49:46,540 iteration 1104 : loss : 0.109502, loss_ce: 0.033525
2021-12-14 01:49:46,540 Training Data Eval:
2021-12-14 01:49:53,977   Average segmentation loss on training set: 0.0970
2021-12-14 01:49:53,977 Validation Data Eval:
2021-12-14 01:49:56,541   Average segmentation loss on validation set: 0.1205
2021-12-14 01:49:58,066 iteration 1105 : loss : 0.110039, loss_ce: 0.034888
 16%|████▉                         | 65/400 [31:03<2:47:36, 30.02s/it]2021-12-14 01:49:59,674 iteration 1106 : loss : 0.103533, loss_ce: 0.025853
2021-12-14 01:50:01,279 iteration 1107 : loss : 0.105073, loss_ce: 0.036464
2021-12-14 01:50:02,744 iteration 1108 : loss : 0.094882, loss_ce: 0.024171
2021-12-14 01:50:04,191 iteration 1109 : loss : 0.137332, loss_ce: 0.052545
2021-12-14 01:50:05,702 iteration 1110 : loss : 0.101736, loss_ce: 0.030591
2021-12-14 01:50:07,222 iteration 1111 : loss : 0.095892, loss_ce: 0.027577
2021-12-14 01:50:08,764 iteration 1112 : loss : 0.106526, loss_ce: 0.035794
2021-12-14 01:50:10,259 iteration 1113 : loss : 0.111750, loss_ce: 0.032286
2021-12-14 01:50:11,698 iteration 1114 : loss : 0.110997, loss_ce: 0.029268
2021-12-14 01:50:13,092 iteration 1115 : loss : 0.101877, loss_ce: 0.025392
2021-12-14 01:50:14,704 iteration 1116 : loss : 0.116553, loss_ce: 0.037240
2021-12-14 01:50:16,340 iteration 1117 : loss : 0.116899, loss_ce: 0.033509
2021-12-14 01:50:17,807 iteration 1118 : loss : 0.105728, loss_ce: 0.029961
2021-12-14 01:50:19,272 iteration 1119 : loss : 0.088421, loss_ce: 0.023655
2021-12-14 01:50:20,744 iteration 1120 : loss : 0.115312, loss_ce: 0.031148
2021-12-14 01:50:22,199 iteration 1121 : loss : 0.094106, loss_ce: 0.021055
2021-12-14 01:50:23,644 iteration 1122 : loss : 0.110640, loss_ce: 0.035078
 16%|████▉                         | 66/400 [31:28<2:39:42, 28.69s/it]2021-12-14 01:50:25,227 iteration 1123 : loss : 0.100841, loss_ce: 0.031232
2021-12-14 01:50:26,700 iteration 1124 : loss : 0.098897, loss_ce: 0.029203
2021-12-14 01:50:28,286 iteration 1125 : loss : 0.124648, loss_ce: 0.042326
2021-12-14 01:50:29,968 iteration 1126 : loss : 0.117476, loss_ce: 0.037230
2021-12-14 01:50:31,552 iteration 1127 : loss : 0.131824, loss_ce: 0.038144
2021-12-14 01:50:33,105 iteration 1128 : loss : 0.124611, loss_ce: 0.031046
2021-12-14 01:50:34,611 iteration 1129 : loss : 0.115225, loss_ce: 0.031768
2021-12-14 01:50:36,199 iteration 1130 : loss : 0.111662, loss_ce: 0.043567
2021-12-14 01:50:37,837 iteration 1131 : loss : 0.135445, loss_ce: 0.028330
2021-12-14 01:50:39,398 iteration 1132 : loss : 0.129954, loss_ce: 0.039822
2021-12-14 01:50:40,947 iteration 1133 : loss : 0.115395, loss_ce: 0.033447
2021-12-14 01:50:42,480 iteration 1134 : loss : 0.118523, loss_ce: 0.040091
2021-12-14 01:50:43,952 iteration 1135 : loss : 0.097034, loss_ce: 0.023747
2021-12-14 01:50:45,475 iteration 1136 : loss : 0.108476, loss_ce: 0.034542
2021-12-14 01:50:46,964 iteration 1137 : loss : 0.122645, loss_ce: 0.035668
2021-12-14 01:50:48,616 iteration 1138 : loss : 0.108943, loss_ce: 0.033936
2021-12-14 01:50:50,235 iteration 1139 : loss : 0.110252, loss_ce: 0.033608
 17%|█████                         | 67/400 [31:55<2:35:43, 28.06s/it]2021-12-14 01:50:51,784 iteration 1140 : loss : 0.104287, loss_ce: 0.031868
2021-12-14 01:50:53,319 iteration 1141 : loss : 0.102666, loss_ce: 0.033391
2021-12-14 01:50:54,785 iteration 1142 : loss : 0.098974, loss_ce: 0.030631
2021-12-14 01:50:56,323 iteration 1143 : loss : 0.129792, loss_ce: 0.033965
2021-12-14 01:50:57,904 iteration 1144 : loss : 0.110711, loss_ce: 0.034067
2021-12-14 01:50:59,431 iteration 1145 : loss : 0.094403, loss_ce: 0.023127
2021-12-14 01:51:00,989 iteration 1146 : loss : 0.110286, loss_ce: 0.037368
2021-12-14 01:51:02,421 iteration 1147 : loss : 0.087689, loss_ce: 0.022854
2021-12-14 01:51:03,937 iteration 1148 : loss : 0.106148, loss_ce: 0.030209
2021-12-14 01:51:05,521 iteration 1149 : loss : 0.106027, loss_ce: 0.034113
2021-12-14 01:51:07,046 iteration 1150 : loss : 0.098347, loss_ce: 0.030975
2021-12-14 01:51:08,580 iteration 1151 : loss : 0.098703, loss_ce: 0.023794
2021-12-14 01:51:10,153 iteration 1152 : loss : 0.135495, loss_ce: 0.022121
2021-12-14 01:51:11,697 iteration 1153 : loss : 0.095920, loss_ce: 0.024161
2021-12-14 01:51:13,123 iteration 1154 : loss : 0.097501, loss_ce: 0.035484
2021-12-14 01:51:14,755 iteration 1155 : loss : 0.127266, loss_ce: 0.037468
2021-12-14 01:51:16,328 iteration 1156 : loss : 0.131266, loss_ce: 0.034272
 17%|█████                         | 68/400 [32:21<2:31:59, 27.47s/it]2021-12-14 01:51:17,854 iteration 1157 : loss : 0.103895, loss_ce: 0.031828
2021-12-14 01:51:19,520 iteration 1158 : loss : 0.116232, loss_ce: 0.026929
2021-12-14 01:51:21,124 iteration 1159 : loss : 0.118415, loss_ce: 0.033559
2021-12-14 01:51:22,551 iteration 1160 : loss : 0.106436, loss_ce: 0.036287
2021-12-14 01:51:24,059 iteration 1161 : loss : 0.105392, loss_ce: 0.028546
2021-12-14 01:51:25,576 iteration 1162 : loss : 0.115254, loss_ce: 0.024460
2021-12-14 01:51:27,244 iteration 1163 : loss : 0.114868, loss_ce: 0.029847
2021-12-14 01:51:28,800 iteration 1164 : loss : 0.111342, loss_ce: 0.032888
2021-12-14 01:51:30,244 iteration 1165 : loss : 0.111277, loss_ce: 0.040364
2021-12-14 01:51:31,752 iteration 1166 : loss : 0.102945, loss_ce: 0.035609
2021-12-14 01:51:33,300 iteration 1167 : loss : 0.136856, loss_ce: 0.052373
2021-12-14 01:51:34,721 iteration 1168 : loss : 0.097293, loss_ce: 0.027416
2021-12-14 01:51:36,257 iteration 1169 : loss : 0.110796, loss_ce: 0.028029
2021-12-14 01:51:37,800 iteration 1170 : loss : 0.104871, loss_ce: 0.028881
2021-12-14 01:51:39,241 iteration 1171 : loss : 0.104162, loss_ce: 0.025931
2021-12-14 01:51:40,746 iteration 1172 : loss : 0.101568, loss_ce: 0.031605
2021-12-14 01:51:42,298 iteration 1173 : loss : 0.108217, loss_ce: 0.041897
 17%|█████▏                        | 69/400 [32:47<2:29:03, 27.02s/it]2021-12-14 01:51:43,908 iteration 1174 : loss : 0.101840, loss_ce: 0.024497
2021-12-14 01:51:45,399 iteration 1175 : loss : 0.109098, loss_ce: 0.036351
2021-12-14 01:51:46,993 iteration 1176 : loss : 0.116994, loss_ce: 0.043143
2021-12-14 01:51:48,644 iteration 1177 : loss : 0.121542, loss_ce: 0.039480
2021-12-14 01:51:50,193 iteration 1178 : loss : 0.114501, loss_ce: 0.038877
2021-12-14 01:51:51,611 iteration 1179 : loss : 0.097601, loss_ce: 0.031053
2021-12-14 01:51:53,193 iteration 1180 : loss : 0.105665, loss_ce: 0.026604
2021-12-14 01:51:54,612 iteration 1181 : loss : 0.103362, loss_ce: 0.029636
2021-12-14 01:51:56,251 iteration 1182 : loss : 0.116320, loss_ce: 0.034138
2021-12-14 01:51:57,766 iteration 1183 : loss : 0.100748, loss_ce: 0.030377
2021-12-14 01:51:59,199 iteration 1184 : loss : 0.097849, loss_ce: 0.029511
2021-12-14 01:52:00,768 iteration 1185 : loss : 0.103281, loss_ce: 0.027673
2021-12-14 01:52:02,229 iteration 1186 : loss : 0.103721, loss_ce: 0.028454
2021-12-14 01:52:03,770 iteration 1187 : loss : 0.095850, loss_ce: 0.026829
2021-12-14 01:52:05,211 iteration 1188 : loss : 0.094486, loss_ce: 0.025409
2021-12-14 01:52:06,735 iteration 1189 : loss : 0.104378, loss_ce: 0.031722
2021-12-14 01:52:06,736 Training Data Eval:
2021-12-14 01:52:14,166   Average segmentation loss on training set: 0.0998
2021-12-14 01:52:14,167 Validation Data Eval:
2021-12-14 01:52:16,725   Average segmentation loss on validation set: 0.1203
2021-12-14 01:52:18,263 iteration 1190 : loss : 0.103236, loss_ce: 0.033212
 18%|█████▎                        | 70/400 [33:23<2:43:21, 29.70s/it]2021-12-14 01:52:19,804 iteration 1191 : loss : 0.091540, loss_ce: 0.027025
2021-12-14 01:52:21,261 iteration 1192 : loss : 0.102269, loss_ce: 0.032510
2021-12-14 01:52:22,779 iteration 1193 : loss : 0.111077, loss_ce: 0.027288
2021-12-14 01:52:24,258 iteration 1194 : loss : 0.108992, loss_ce: 0.035332
2021-12-14 01:52:25,830 iteration 1195 : loss : 0.108510, loss_ce: 0.029674
2021-12-14 01:52:27,252 iteration 1196 : loss : 0.099981, loss_ce: 0.027005
2021-12-14 01:52:28,807 iteration 1197 : loss : 0.102724, loss_ce: 0.035377
2021-12-14 01:52:30,366 iteration 1198 : loss : 0.105225, loss_ce: 0.041040
2021-12-14 01:52:31,900 iteration 1199 : loss : 0.106311, loss_ce: 0.026969
2021-12-14 01:52:33,471 iteration 1200 : loss : 0.124272, loss_ce: 0.034690
2021-12-14 01:52:34,982 iteration 1201 : loss : 0.092493, loss_ce: 0.027668
2021-12-14 01:52:36,555 iteration 1202 : loss : 0.096835, loss_ce: 0.033874
2021-12-14 01:52:38,066 iteration 1203 : loss : 0.097779, loss_ce: 0.025424
2021-12-14 01:52:39,568 iteration 1204 : loss : 0.113998, loss_ce: 0.036653
2021-12-14 01:52:41,133 iteration 1205 : loss : 0.119043, loss_ce: 0.046917
2021-12-14 01:52:42,721 iteration 1206 : loss : 0.124758, loss_ce: 0.031049
2021-12-14 01:52:44,191 iteration 1207 : loss : 0.100787, loss_ce: 0.025414
 18%|█████▎                        | 71/400 [33:49<2:36:40, 28.57s/it]2021-12-14 01:52:45,691 iteration 1208 : loss : 0.104930, loss_ce: 0.035361
2021-12-14 01:52:47,209 iteration 1209 : loss : 0.098605, loss_ce: 0.026732
2021-12-14 01:52:48,638 iteration 1210 : loss : 0.096448, loss_ce: 0.021086
2021-12-14 01:52:50,195 iteration 1211 : loss : 0.123066, loss_ce: 0.036534
2021-12-14 01:52:51,658 iteration 1212 : loss : 0.095904, loss_ce: 0.028520
2021-12-14 01:52:53,184 iteration 1213 : loss : 0.126816, loss_ce: 0.026801
2021-12-14 01:52:54,723 iteration 1214 : loss : 0.100444, loss_ce: 0.030377
2021-12-14 01:52:56,233 iteration 1215 : loss : 0.101549, loss_ce: 0.034842
2021-12-14 01:52:57,720 iteration 1216 : loss : 0.091855, loss_ce: 0.026660
2021-12-14 01:52:59,296 iteration 1217 : loss : 0.105204, loss_ce: 0.035688
2021-12-14 01:53:00,687 iteration 1218 : loss : 0.090447, loss_ce: 0.030456
2021-12-14 01:53:02,262 iteration 1219 : loss : 0.107952, loss_ce: 0.031830
2021-12-14 01:53:03,758 iteration 1220 : loss : 0.107439, loss_ce: 0.030535
2021-12-14 01:53:05,416 iteration 1221 : loss : 0.134572, loss_ce: 0.048697
2021-12-14 01:53:06,990 iteration 1222 : loss : 0.101653, loss_ce: 0.024259
2021-12-14 01:53:08,484 iteration 1223 : loss : 0.108071, loss_ce: 0.035788
2021-12-14 01:53:10,050 iteration 1224 : loss : 0.100302, loss_ce: 0.035564
 18%|█████▍                        | 72/400 [34:15<2:31:43, 27.76s/it]2021-12-14 01:53:11,670 iteration 1225 : loss : 0.096340, loss_ce: 0.027636
2021-12-14 01:53:13,206 iteration 1226 : loss : 0.118638, loss_ce: 0.037425
2021-12-14 01:53:14,690 iteration 1227 : loss : 0.086311, loss_ce: 0.021288
2021-12-14 01:53:16,343 iteration 1228 : loss : 0.110935, loss_ce: 0.026722
2021-12-14 01:53:17,947 iteration 1229 : loss : 0.114439, loss_ce: 0.037630
2021-12-14 01:53:19,522 iteration 1230 : loss : 0.100989, loss_ce: 0.031383
2021-12-14 01:53:21,031 iteration 1231 : loss : 0.133150, loss_ce: 0.039527
2021-12-14 01:53:22,619 iteration 1232 : loss : 0.098911, loss_ce: 0.028018
2021-12-14 01:53:24,294 iteration 1233 : loss : 0.122853, loss_ce: 0.043796
2021-12-14 01:53:25,846 iteration 1234 : loss : 0.109571, loss_ce: 0.035824
2021-12-14 01:53:27,345 iteration 1235 : loss : 0.117467, loss_ce: 0.045639
2021-12-14 01:53:28,811 iteration 1236 : loss : 0.094407, loss_ce: 0.023709
2021-12-14 01:53:30,232 iteration 1237 : loss : 0.099865, loss_ce: 0.027556
2021-12-14 01:53:31,805 iteration 1238 : loss : 0.112324, loss_ce: 0.035045
2021-12-14 01:53:33,371 iteration 1239 : loss : 0.098896, loss_ce: 0.026872
2021-12-14 01:53:34,785 iteration 1240 : loss : 0.111224, loss_ce: 0.032069
2021-12-14 01:53:36,431 iteration 1241 : loss : 0.095327, loss_ce: 0.028662
 18%|█████▍                        | 73/400 [34:41<2:29:02, 27.35s/it]2021-12-14 01:53:37,917 iteration 1242 : loss : 0.093477, loss_ce: 0.027366
2021-12-14 01:53:39,341 iteration 1243 : loss : 0.082369, loss_ce: 0.023001
2021-12-14 01:53:40,780 iteration 1244 : loss : 0.096688, loss_ce: 0.029404
2021-12-14 01:53:42,276 iteration 1245 : loss : 0.107712, loss_ce: 0.034544
2021-12-14 01:53:43,788 iteration 1246 : loss : 0.109267, loss_ce: 0.034806
2021-12-14 01:53:45,354 iteration 1247 : loss : 0.104624, loss_ce: 0.026674
2021-12-14 01:53:46,827 iteration 1248 : loss : 0.087560, loss_ce: 0.023895
2021-12-14 01:53:48,351 iteration 1249 : loss : 0.104473, loss_ce: 0.026961
2021-12-14 01:53:49,817 iteration 1250 : loss : 0.109925, loss_ce: 0.032846
2021-12-14 01:53:51,367 iteration 1251 : loss : 0.095980, loss_ce: 0.029682
2021-12-14 01:53:52,909 iteration 1252 : loss : 0.132461, loss_ce: 0.030078
2021-12-14 01:53:54,449 iteration 1253 : loss : 0.103550, loss_ce: 0.031312
2021-12-14 01:53:55,943 iteration 1254 : loss : 0.121066, loss_ce: 0.044098
2021-12-14 01:53:57,538 iteration 1255 : loss : 0.101752, loss_ce: 0.031997
2021-12-14 01:53:59,139 iteration 1256 : loss : 0.102276, loss_ce: 0.027369
2021-12-14 01:54:00,653 iteration 1257 : loss : 0.095300, loss_ce: 0.030232
2021-12-14 01:54:02,286 iteration 1258 : loss : 0.107703, loss_ce: 0.038768
 18%|█████▌                        | 74/400 [35:07<2:26:08, 26.90s/it]2021-12-14 01:54:03,875 iteration 1259 : loss : 0.097487, loss_ce: 0.026969
2021-12-14 01:54:05,441 iteration 1260 : loss : 0.107666, loss_ce: 0.029193
2021-12-14 01:54:06,982 iteration 1261 : loss : 0.094224, loss_ce: 0.025951
2021-12-14 01:54:08,458 iteration 1262 : loss : 0.089449, loss_ce: 0.028043
2021-12-14 01:54:10,064 iteration 1263 : loss : 0.095376, loss_ce: 0.023328
2021-12-14 01:54:11,500 iteration 1264 : loss : 0.094303, loss_ce: 0.031898
2021-12-14 01:54:12,952 iteration 1265 : loss : 0.097875, loss_ce: 0.027926
2021-12-14 01:54:14,399 iteration 1266 : loss : 0.095440, loss_ce: 0.028832
2021-12-14 01:54:16,009 iteration 1267 : loss : 0.100172, loss_ce: 0.028381
2021-12-14 01:54:17,508 iteration 1268 : loss : 0.138722, loss_ce: 0.026419
2021-12-14 01:54:19,085 iteration 1269 : loss : 0.107911, loss_ce: 0.030411
2021-12-14 01:54:20,529 iteration 1270 : loss : 0.100199, loss_ce: 0.024659
2021-12-14 01:54:22,025 iteration 1271 : loss : 0.102073, loss_ce: 0.032829
2021-12-14 01:54:23,517 iteration 1272 : loss : 0.110618, loss_ce: 0.035817
2021-12-14 01:54:25,107 iteration 1273 : loss : 0.099222, loss_ce: 0.032348
2021-12-14 01:54:26,636 iteration 1274 : loss : 0.102106, loss_ce: 0.030178
2021-12-14 01:54:26,636 Training Data Eval:
2021-12-14 01:54:34,057   Average segmentation loss on training set: 0.0917
2021-12-14 01:54:34,058 Validation Data Eval:
2021-12-14 01:54:36,621   Average segmentation loss on validation set: 0.1140
2021-12-14 01:54:42,355 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 01:54:43,915 iteration 1275 : loss : 0.106526, loss_ce: 0.027808
 19%|█████▋                        | 75/400 [35:49<2:49:38, 31.32s/it]2021-12-14 01:54:45,611 iteration 1276 : loss : 0.108022, loss_ce: 0.022186
2021-12-14 01:54:47,070 iteration 1277 : loss : 0.086139, loss_ce: 0.023118
2021-12-14 01:54:48,643 iteration 1278 : loss : 0.099595, loss_ce: 0.032717
2021-12-14 01:54:50,026 iteration 1279 : loss : 0.094317, loss_ce: 0.032093
2021-12-14 01:54:51,418 iteration 1280 : loss : 0.106104, loss_ce: 0.036088
2021-12-14 01:54:53,012 iteration 1281 : loss : 0.106059, loss_ce: 0.034651
2021-12-14 01:54:54,455 iteration 1282 : loss : 0.125187, loss_ce: 0.054054
2021-12-14 01:54:55,923 iteration 1283 : loss : 0.096239, loss_ce: 0.027368
2021-12-14 01:54:57,440 iteration 1284 : loss : 0.103044, loss_ce: 0.032774
2021-12-14 01:54:59,157 iteration 1285 : loss : 0.124905, loss_ce: 0.031937
2021-12-14 01:55:00,726 iteration 1286 : loss : 0.099232, loss_ce: 0.024694
2021-12-14 01:55:02,205 iteration 1287 : loss : 0.096606, loss_ce: 0.027700
2021-12-14 01:55:03,773 iteration 1288 : loss : 0.098090, loss_ce: 0.028777
2021-12-14 01:55:05,399 iteration 1289 : loss : 0.108499, loss_ce: 0.031803
2021-12-14 01:55:06,868 iteration 1290 : loss : 0.109216, loss_ce: 0.028164
2021-12-14 01:55:08,401 iteration 1291 : loss : 0.091567, loss_ce: 0.023678
2021-12-14 01:55:09,846 iteration 1292 : loss : 0.094598, loss_ce: 0.026513
 19%|█████▋                        | 76/400 [36:15<2:40:22, 29.70s/it]2021-12-14 01:55:11,407 iteration 1293 : loss : 0.111588, loss_ce: 0.041977
2021-12-14 01:55:12,863 iteration 1294 : loss : 0.094939, loss_ce: 0.027979
2021-12-14 01:55:14,363 iteration 1295 : loss : 0.085473, loss_ce: 0.024540
2021-12-14 01:55:15,865 iteration 1296 : loss : 0.087031, loss_ce: 0.024056
2021-12-14 01:55:17,361 iteration 1297 : loss : 0.099384, loss_ce: 0.028113
2021-12-14 01:55:18,889 iteration 1298 : loss : 0.098858, loss_ce: 0.032148
2021-12-14 01:55:20,340 iteration 1299 : loss : 0.098918, loss_ce: 0.027850
2021-12-14 01:55:21,928 iteration 1300 : loss : 0.120062, loss_ce: 0.025411
2021-12-14 01:55:23,483 iteration 1301 : loss : 0.102993, loss_ce: 0.033201
2021-12-14 01:55:25,089 iteration 1302 : loss : 0.103714, loss_ce: 0.023774
2021-12-14 01:55:26,559 iteration 1303 : loss : 0.101729, loss_ce: 0.031145
2021-12-14 01:55:28,125 iteration 1304 : loss : 0.119465, loss_ce: 0.025912
2021-12-14 01:55:29,655 iteration 1305 : loss : 0.091582, loss_ce: 0.030254
2021-12-14 01:55:31,250 iteration 1306 : loss : 0.095002, loss_ce: 0.022315
2021-12-14 01:55:32,850 iteration 1307 : loss : 0.105314, loss_ce: 0.030007
2021-12-14 01:55:34,386 iteration 1308 : loss : 0.107320, loss_ce: 0.040460
2021-12-14 01:55:35,914 iteration 1309 : loss : 0.095101, loss_ce: 0.021014
 19%|█████▊                        | 77/400 [36:41<2:33:59, 28.61s/it]2021-12-14 01:55:37,497 iteration 1310 : loss : 0.116316, loss_ce: 0.039618
2021-12-14 01:55:39,111 iteration 1311 : loss : 0.091838, loss_ce: 0.023497
2021-12-14 01:55:40,623 iteration 1312 : loss : 0.101660, loss_ce: 0.036242
2021-12-14 01:55:42,055 iteration 1313 : loss : 0.094549, loss_ce: 0.026196
2021-12-14 01:55:43,582 iteration 1314 : loss : 0.085674, loss_ce: 0.025358
2021-12-14 01:55:45,113 iteration 1315 : loss : 0.095926, loss_ce: 0.026081
2021-12-14 01:55:46,605 iteration 1316 : loss : 0.096447, loss_ce: 0.028393
2021-12-14 01:55:48,187 iteration 1317 : loss : 0.093605, loss_ce: 0.029312
2021-12-14 01:55:49,759 iteration 1318 : loss : 0.102378, loss_ce: 0.033593
2021-12-14 01:55:51,254 iteration 1319 : loss : 0.093671, loss_ce: 0.024397
2021-12-14 01:55:52,750 iteration 1320 : loss : 0.094414, loss_ce: 0.024924
2021-12-14 01:55:54,278 iteration 1321 : loss : 0.111613, loss_ce: 0.034617
2021-12-14 01:55:55,929 iteration 1322 : loss : 0.098571, loss_ce: 0.027754
2021-12-14 01:55:57,499 iteration 1323 : loss : 0.087848, loss_ce: 0.023683
2021-12-14 01:55:59,063 iteration 1324 : loss : 0.131364, loss_ce: 0.037764
2021-12-14 01:56:00,655 iteration 1325 : loss : 0.096334, loss_ce: 0.026531
2021-12-14 01:56:02,101 iteration 1326 : loss : 0.101988, loss_ce: 0.028315
 20%|█████▊                        | 78/400 [37:07<2:29:39, 27.89s/it]2021-12-14 01:56:03,708 iteration 1327 : loss : 0.106496, loss_ce: 0.039851
2021-12-14 01:56:05,373 iteration 1328 : loss : 0.104318, loss_ce: 0.028742
2021-12-14 01:56:06,817 iteration 1329 : loss : 0.098157, loss_ce: 0.034441
2021-12-14 01:56:08,326 iteration 1330 : loss : 0.105338, loss_ce: 0.029613
2021-12-14 01:56:09,835 iteration 1331 : loss : 0.086867, loss_ce: 0.021216
2021-12-14 01:56:11,328 iteration 1332 : loss : 0.093586, loss_ce: 0.028941
2021-12-14 01:56:12,888 iteration 1333 : loss : 0.112338, loss_ce: 0.022843
2021-12-14 01:56:14,395 iteration 1334 : loss : 0.085427, loss_ce: 0.022967
2021-12-14 01:56:16,065 iteration 1335 : loss : 0.093145, loss_ce: 0.023852
2021-12-14 01:56:17,645 iteration 1336 : loss : 0.108642, loss_ce: 0.033148
2021-12-14 01:56:19,253 iteration 1337 : loss : 0.107121, loss_ce: 0.035707
2021-12-14 01:56:20,877 iteration 1338 : loss : 0.110927, loss_ce: 0.034956
2021-12-14 01:56:22,456 iteration 1339 : loss : 0.097484, loss_ce: 0.030377
2021-12-14 01:56:23,929 iteration 1340 : loss : 0.092897, loss_ce: 0.024016
2021-12-14 01:56:25,438 iteration 1341 : loss : 0.097627, loss_ce: 0.032350
2021-12-14 01:56:26,952 iteration 1342 : loss : 0.108950, loss_ce: 0.029171
2021-12-14 01:56:28,442 iteration 1343 : loss : 0.094672, loss_ce: 0.026639
 20%|█████▉                        | 79/400 [37:33<2:26:41, 27.42s/it]2021-12-14 01:56:29,985 iteration 1344 : loss : 0.090166, loss_ce: 0.024452
2021-12-14 01:56:31,448 iteration 1345 : loss : 0.092412, loss_ce: 0.031054
2021-12-14 01:56:32,918 iteration 1346 : loss : 0.098747, loss_ce: 0.025571
2021-12-14 01:56:34,536 iteration 1347 : loss : 0.132140, loss_ce: 0.026904
2021-12-14 01:56:36,169 iteration 1348 : loss : 0.099583, loss_ce: 0.029428
2021-12-14 01:56:37,710 iteration 1349 : loss : 0.113929, loss_ce: 0.039533
2021-12-14 01:56:39,299 iteration 1350 : loss : 0.131349, loss_ce: 0.051076
2021-12-14 01:56:40,769 iteration 1351 : loss : 0.092837, loss_ce: 0.024681
2021-12-14 01:56:42,397 iteration 1352 : loss : 0.087576, loss_ce: 0.023991
2021-12-14 01:56:43,832 iteration 1353 : loss : 0.107348, loss_ce: 0.038039
2021-12-14 01:56:45,390 iteration 1354 : loss : 0.083970, loss_ce: 0.023519
2021-12-14 01:56:46,836 iteration 1355 : loss : 0.108926, loss_ce: 0.025716
2021-12-14 01:56:48,399 iteration 1356 : loss : 0.105361, loss_ce: 0.030878
2021-12-14 01:56:49,854 iteration 1357 : loss : 0.117953, loss_ce: 0.054268
2021-12-14 01:56:51,370 iteration 1358 : loss : 0.090854, loss_ce: 0.023252
2021-12-14 01:56:52,807 iteration 1359 : loss : 0.102392, loss_ce: 0.038695
2021-12-14 01:56:52,807 Training Data Eval:
2021-12-14 01:57:00,256   Average segmentation loss on training set: 0.0937
2021-12-14 01:57:00,256 Validation Data Eval:
2021-12-14 01:57:02,815   Average segmentation loss on validation set: 0.1164
2021-12-14 01:57:04,315 iteration 1360 : loss : 0.109189, loss_ce: 0.027406
 20%|██████                        | 80/400 [38:09<2:39:45, 29.95s/it]2021-12-14 01:57:05,941 iteration 1361 : loss : 0.124955, loss_ce: 0.036980
2021-12-14 01:57:07,476 iteration 1362 : loss : 0.101501, loss_ce: 0.034288
2021-12-14 01:57:09,040 iteration 1363 : loss : 0.093246, loss_ce: 0.025955
2021-12-14 01:57:10,648 iteration 1364 : loss : 0.100119, loss_ce: 0.027699
2021-12-14 01:57:12,298 iteration 1365 : loss : 0.120612, loss_ce: 0.042276
2021-12-14 01:57:13,825 iteration 1366 : loss : 0.098021, loss_ce: 0.032969
2021-12-14 01:57:15,302 iteration 1367 : loss : 0.108100, loss_ce: 0.036857
2021-12-14 01:57:16,834 iteration 1368 : loss : 0.117139, loss_ce: 0.040257
2021-12-14 01:57:18,314 iteration 1369 : loss : 0.098931, loss_ce: 0.024137
2021-12-14 01:57:19,854 iteration 1370 : loss : 0.106608, loss_ce: 0.030913
2021-12-14 01:57:21,306 iteration 1371 : loss : 0.092842, loss_ce: 0.026717
2021-12-14 01:57:22,849 iteration 1372 : loss : 0.122911, loss_ce: 0.033765
2021-12-14 01:57:24,495 iteration 1373 : loss : 0.108259, loss_ce: 0.043547
2021-12-14 01:57:26,006 iteration 1374 : loss : 0.111686, loss_ce: 0.028065
2021-12-14 01:57:27,607 iteration 1375 : loss : 0.098537, loss_ce: 0.026449
2021-12-14 01:57:29,025 iteration 1376 : loss : 0.116664, loss_ce: 0.036552
2021-12-14 01:57:30,600 iteration 1377 : loss : 0.111007, loss_ce: 0.032961
 20%|██████                        | 81/400 [38:35<2:33:25, 28.86s/it]2021-12-14 01:57:32,298 iteration 1378 : loss : 0.099108, loss_ce: 0.035543
2021-12-14 01:57:33,928 iteration 1379 : loss : 0.116099, loss_ce: 0.028896
2021-12-14 01:57:35,448 iteration 1380 : loss : 0.093518, loss_ce: 0.030546
2021-12-14 01:57:37,001 iteration 1381 : loss : 0.102023, loss_ce: 0.033963
2021-12-14 01:57:38,518 iteration 1382 : loss : 0.102445, loss_ce: 0.031194
2021-12-14 01:57:40,030 iteration 1383 : loss : 0.096597, loss_ce: 0.021574
2021-12-14 01:57:41,675 iteration 1384 : loss : 0.117037, loss_ce: 0.042014
2021-12-14 01:57:43,104 iteration 1385 : loss : 0.082279, loss_ce: 0.021495
2021-12-14 01:57:44,760 iteration 1386 : loss : 0.107498, loss_ce: 0.037871
2021-12-14 01:57:46,239 iteration 1387 : loss : 0.112103, loss_ce: 0.029695
2021-12-14 01:57:47,820 iteration 1388 : loss : 0.128969, loss_ce: 0.024499
2021-12-14 01:57:49,385 iteration 1389 : loss : 0.106438, loss_ce: 0.039836
2021-12-14 01:57:50,821 iteration 1390 : loss : 0.098222, loss_ce: 0.032890
2021-12-14 01:57:52,357 iteration 1391 : loss : 0.113888, loss_ce: 0.029168
2021-12-14 01:57:53,867 iteration 1392 : loss : 0.121563, loss_ce: 0.047654
2021-12-14 01:57:55,409 iteration 1393 : loss : 0.113283, loss_ce: 0.028655
2021-12-14 01:57:56,922 iteration 1394 : loss : 0.101944, loss_ce: 0.024468
 20%|██████▏                       | 82/400 [39:02<2:28:54, 28.10s/it]2021-12-14 01:57:58,572 iteration 1395 : loss : 0.114232, loss_ce: 0.040638
2021-12-14 01:58:00,009 iteration 1396 : loss : 0.120410, loss_ce: 0.044012
2021-12-14 01:58:01,598 iteration 1397 : loss : 0.105499, loss_ce: 0.031916
2021-12-14 01:58:03,009 iteration 1398 : loss : 0.086985, loss_ce: 0.024616
2021-12-14 01:58:04,565 iteration 1399 : loss : 0.095818, loss_ce: 0.030377
2021-12-14 01:58:06,191 iteration 1400 : loss : 0.126024, loss_ce: 0.036250
2021-12-14 01:58:07,664 iteration 1401 : loss : 0.084368, loss_ce: 0.019420
2021-12-14 01:58:09,284 iteration 1402 : loss : 0.108797, loss_ce: 0.031265
2021-12-14 01:58:10,837 iteration 1403 : loss : 0.106040, loss_ce: 0.024929
2021-12-14 01:58:12,487 iteration 1404 : loss : 0.110940, loss_ce: 0.033070
2021-12-14 01:58:13,810 iteration 1405 : loss : 0.084327, loss_ce: 0.022392
2021-12-14 01:58:15,369 iteration 1406 : loss : 0.107331, loss_ce: 0.028835
2021-12-14 01:58:16,875 iteration 1407 : loss : 0.102790, loss_ce: 0.032710
2021-12-14 01:58:18,313 iteration 1408 : loss : 0.100240, loss_ce: 0.030750
2021-12-14 01:58:19,935 iteration 1409 : loss : 0.107858, loss_ce: 0.023057
2021-12-14 01:58:21,413 iteration 1410 : loss : 0.101156, loss_ce: 0.031458
2021-12-14 01:58:22,824 iteration 1411 : loss : 0.090698, loss_ce: 0.025964
 21%|██████▏                       | 83/400 [39:28<2:24:57, 27.44s/it]2021-12-14 01:58:24,428 iteration 1412 : loss : 0.098854, loss_ce: 0.033225
2021-12-14 01:58:25,858 iteration 1413 : loss : 0.101548, loss_ce: 0.029408
2021-12-14 01:58:27,427 iteration 1414 : loss : 0.096165, loss_ce: 0.030077
2021-12-14 01:58:28,861 iteration 1415 : loss : 0.095382, loss_ce: 0.027894
2021-12-14 01:58:30,367 iteration 1416 : loss : 0.093588, loss_ce: 0.027886
2021-12-14 01:58:31,914 iteration 1417 : loss : 0.108037, loss_ce: 0.028787
2021-12-14 01:58:33,431 iteration 1418 : loss : 0.088007, loss_ce: 0.022351
2021-12-14 01:58:34,842 iteration 1419 : loss : 0.091813, loss_ce: 0.028099
2021-12-14 01:58:36,342 iteration 1420 : loss : 0.091357, loss_ce: 0.019743
2021-12-14 01:58:37,836 iteration 1421 : loss : 0.113921, loss_ce: 0.046638
2021-12-14 01:58:39,367 iteration 1422 : loss : 0.101619, loss_ce: 0.030883
2021-12-14 01:58:40,830 iteration 1423 : loss : 0.096085, loss_ce: 0.024374
2021-12-14 01:58:42,234 iteration 1424 : loss : 0.082669, loss_ce: 0.024214
2021-12-14 01:58:43,763 iteration 1425 : loss : 0.098933, loss_ce: 0.023753
2021-12-14 01:58:45,311 iteration 1426 : loss : 0.107712, loss_ce: 0.044150
2021-12-14 01:58:46,832 iteration 1427 : loss : 0.106754, loss_ce: 0.022685
2021-12-14 01:58:48,482 iteration 1428 : loss : 0.114488, loss_ce: 0.034388
 21%|██████▎                       | 84/400 [39:53<2:21:41, 26.90s/it]2021-12-14 01:58:50,108 iteration 1429 : loss : 0.106866, loss_ce: 0.037818
2021-12-14 01:58:51,610 iteration 1430 : loss : 0.095817, loss_ce: 0.027705
2021-12-14 01:58:53,056 iteration 1431 : loss : 0.099092, loss_ce: 0.027198
2021-12-14 01:58:54,582 iteration 1432 : loss : 0.093008, loss_ce: 0.029142
2021-12-14 01:58:55,999 iteration 1433 : loss : 0.092550, loss_ce: 0.028656
2021-12-14 01:58:57,648 iteration 1434 : loss : 0.093984, loss_ce: 0.031164
2021-12-14 01:58:59,239 iteration 1435 : loss : 0.097033, loss_ce: 0.026267
2021-12-14 01:59:00,831 iteration 1436 : loss : 0.119433, loss_ce: 0.044503
2021-12-14 01:59:02,342 iteration 1437 : loss : 0.086570, loss_ce: 0.028119
2021-12-14 01:59:03,844 iteration 1438 : loss : 0.087093, loss_ce: 0.025198
2021-12-14 01:59:05,383 iteration 1439 : loss : 0.126342, loss_ce: 0.037044
2021-12-14 01:59:06,825 iteration 1440 : loss : 0.094979, loss_ce: 0.023884
2021-12-14 01:59:08,368 iteration 1441 : loss : 0.100167, loss_ce: 0.030694
2021-12-14 01:59:09,892 iteration 1442 : loss : 0.104235, loss_ce: 0.027741
2021-12-14 01:59:11,489 iteration 1443 : loss : 0.096233, loss_ce: 0.027794
2021-12-14 01:59:12,995 iteration 1444 : loss : 0.099708, loss_ce: 0.020203
2021-12-14 01:59:12,995 Training Data Eval:
2021-12-14 01:59:20,421   Average segmentation loss on training set: 0.0908
2021-12-14 01:59:20,422 Validation Data Eval:
2021-12-14 01:59:22,979   Average segmentation loss on validation set: 0.1179
2021-12-14 01:59:24,550 iteration 1445 : loss : 0.089524, loss_ce: 0.031200
 21%|██████▍                       | 85/400 [40:29<2:35:41, 29.66s/it]2021-12-14 01:59:26,028 iteration 1446 : loss : 0.097887, loss_ce: 0.027097
2021-12-14 01:59:27,435 iteration 1447 : loss : 0.083428, loss_ce: 0.022025
2021-12-14 01:59:29,031 iteration 1448 : loss : 0.084776, loss_ce: 0.019630
2021-12-14 01:59:30,601 iteration 1449 : loss : 0.103468, loss_ce: 0.028453
2021-12-14 01:59:32,081 iteration 1450 : loss : 0.095812, loss_ce: 0.028213
2021-12-14 01:59:33,636 iteration 1451 : loss : 0.092013, loss_ce: 0.021612
2021-12-14 01:59:35,151 iteration 1452 : loss : 0.118426, loss_ce: 0.053105
2021-12-14 01:59:36,701 iteration 1453 : loss : 0.100463, loss_ce: 0.033678
2021-12-14 01:59:38,218 iteration 1454 : loss : 0.086704, loss_ce: 0.021079
2021-12-14 01:59:39,761 iteration 1455 : loss : 0.104245, loss_ce: 0.028126
2021-12-14 01:59:41,227 iteration 1456 : loss : 0.088353, loss_ce: 0.021153
2021-12-14 01:59:42,822 iteration 1457 : loss : 0.087437, loss_ce: 0.026689
2021-12-14 01:59:44,416 iteration 1458 : loss : 0.091231, loss_ce: 0.026827
2021-12-14 01:59:45,932 iteration 1459 : loss : 0.083887, loss_ce: 0.020213
2021-12-14 01:59:47,416 iteration 1460 : loss : 0.097339, loss_ce: 0.027414
2021-12-14 01:59:48,849 iteration 1461 : loss : 0.103630, loss_ce: 0.032529
2021-12-14 01:59:50,465 iteration 1462 : loss : 0.096555, loss_ce: 0.031934
 22%|██████▍                       | 86/400 [40:55<2:29:18, 28.53s/it]2021-12-14 01:59:52,189 iteration 1463 : loss : 0.138110, loss_ce: 0.034494
2021-12-14 01:59:53,645 iteration 1464 : loss : 0.102943, loss_ce: 0.039038
2021-12-14 01:59:55,324 iteration 1465 : loss : 0.093012, loss_ce: 0.024795
2021-12-14 01:59:56,867 iteration 1466 : loss : 0.089693, loss_ce: 0.024720
2021-12-14 01:59:58,339 iteration 1467 : loss : 0.092534, loss_ce: 0.026428
2021-12-14 01:59:59,872 iteration 1468 : loss : 0.101703, loss_ce: 0.034614
2021-12-14 02:00:01,406 iteration 1469 : loss : 0.119418, loss_ce: 0.034589
2021-12-14 02:00:02,855 iteration 1470 : loss : 0.107587, loss_ce: 0.021502
2021-12-14 02:00:04,363 iteration 1471 : loss : 0.086792, loss_ce: 0.025891
2021-12-14 02:00:05,918 iteration 1472 : loss : 0.105342, loss_ce: 0.032331
2021-12-14 02:00:07,386 iteration 1473 : loss : 0.087469, loss_ce: 0.029001
2021-12-14 02:00:08,965 iteration 1474 : loss : 0.107574, loss_ce: 0.027876
2021-12-14 02:00:10,446 iteration 1475 : loss : 0.091987, loss_ce: 0.031714
2021-12-14 02:00:11,932 iteration 1476 : loss : 0.088693, loss_ce: 0.027507
2021-12-14 02:00:13,549 iteration 1477 : loss : 0.102463, loss_ce: 0.032762
2021-12-14 02:00:15,019 iteration 1478 : loss : 0.120290, loss_ce: 0.029650
2021-12-14 02:00:16,538 iteration 1479 : loss : 0.100333, loss_ce: 0.027127
 22%|██████▌                       | 87/400 [41:21<2:25:00, 27.80s/it]2021-12-14 02:00:17,962 iteration 1480 : loss : 0.078382, loss_ce: 0.020797
2021-12-14 02:00:19,593 iteration 1481 : loss : 0.094397, loss_ce: 0.029384
2021-12-14 02:00:21,102 iteration 1482 : loss : 0.090204, loss_ce: 0.026289
2021-12-14 02:00:22,701 iteration 1483 : loss : 0.098580, loss_ce: 0.031388
2021-12-14 02:00:24,258 iteration 1484 : loss : 0.099758, loss_ce: 0.023288
2021-12-14 02:00:25,832 iteration 1485 : loss : 0.089970, loss_ce: 0.031099
2021-12-14 02:00:27,340 iteration 1486 : loss : 0.090529, loss_ce: 0.022501
2021-12-14 02:00:28,854 iteration 1487 : loss : 0.090543, loss_ce: 0.024397
2021-12-14 02:00:30,305 iteration 1488 : loss : 0.091872, loss_ce: 0.029381
2021-12-14 02:00:31,782 iteration 1489 : loss : 0.120730, loss_ce: 0.042130
2021-12-14 02:00:33,351 iteration 1490 : loss : 0.111530, loss_ce: 0.032240
2021-12-14 02:00:34,738 iteration 1491 : loss : 0.104111, loss_ce: 0.027455
2021-12-14 02:00:36,172 iteration 1492 : loss : 0.098469, loss_ce: 0.031569
2021-12-14 02:00:37,736 iteration 1493 : loss : 0.090511, loss_ce: 0.029257
2021-12-14 02:00:39,226 iteration 1494 : loss : 0.093122, loss_ce: 0.024741
2021-12-14 02:00:40,654 iteration 1495 : loss : 0.091023, loss_ce: 0.020721
2021-12-14 02:00:42,219 iteration 1496 : loss : 0.091863, loss_ce: 0.030478
 22%|██████▌                       | 88/400 [41:47<2:21:14, 27.16s/it]2021-12-14 02:00:43,703 iteration 1497 : loss : 0.082080, loss_ce: 0.023772
2021-12-14 02:00:45,265 iteration 1498 : loss : 0.108515, loss_ce: 0.031928
2021-12-14 02:00:46,702 iteration 1499 : loss : 0.101805, loss_ce: 0.028212
2021-12-14 02:00:48,239 iteration 1500 : loss : 0.100120, loss_ce: 0.035708
2021-12-14 02:00:49,732 iteration 1501 : loss : 0.087698, loss_ce: 0.028525
2021-12-14 02:00:51,338 iteration 1502 : loss : 0.105249, loss_ce: 0.022063
2021-12-14 02:00:53,017 iteration 1503 : loss : 0.130747, loss_ce: 0.034881
2021-12-14 02:00:54,511 iteration 1504 : loss : 0.082989, loss_ce: 0.025381
2021-12-14 02:00:56,077 iteration 1505 : loss : 0.091979, loss_ce: 0.029823
2021-12-14 02:00:57,621 iteration 1506 : loss : 0.088388, loss_ce: 0.026453
2021-12-14 02:00:59,183 iteration 1507 : loss : 0.105696, loss_ce: 0.022916
2021-12-14 02:01:00,729 iteration 1508 : loss : 0.100063, loss_ce: 0.032470
2021-12-14 02:01:02,256 iteration 1509 : loss : 0.091943, loss_ce: 0.026761
2021-12-14 02:01:03,883 iteration 1510 : loss : 0.089634, loss_ce: 0.022057
2021-12-14 02:01:05,503 iteration 1511 : loss : 0.102423, loss_ce: 0.031555
2021-12-14 02:01:07,041 iteration 1512 : loss : 0.085266, loss_ce: 0.018483
2021-12-14 02:01:08,582 iteration 1513 : loss : 0.090964, loss_ce: 0.025248
 22%|██████▋                       | 89/400 [42:13<2:19:32, 26.92s/it]2021-12-14 02:01:10,237 iteration 1514 : loss : 0.098991, loss_ce: 0.025391
2021-12-14 02:01:11,686 iteration 1515 : loss : 0.094417, loss_ce: 0.030327
2021-12-14 02:01:13,219 iteration 1516 : loss : 0.097499, loss_ce: 0.028264
2021-12-14 02:01:14,627 iteration 1517 : loss : 0.087478, loss_ce: 0.025146
2021-12-14 02:01:16,194 iteration 1518 : loss : 0.084326, loss_ce: 0.021855
2021-12-14 02:01:17,814 iteration 1519 : loss : 0.098155, loss_ce: 0.025539
2021-12-14 02:01:19,410 iteration 1520 : loss : 0.092434, loss_ce: 0.025747
2021-12-14 02:01:20,938 iteration 1521 : loss : 0.099849, loss_ce: 0.022561
2021-12-14 02:01:22,411 iteration 1522 : loss : 0.088323, loss_ce: 0.024935
2021-12-14 02:01:23,904 iteration 1523 : loss : 0.088364, loss_ce: 0.022358
2021-12-14 02:01:25,436 iteration 1524 : loss : 0.088928, loss_ce: 0.026409
2021-12-14 02:01:26,868 iteration 1525 : loss : 0.099685, loss_ce: 0.030912
2021-12-14 02:01:28,421 iteration 1526 : loss : 0.110559, loss_ce: 0.035637
2021-12-14 02:01:29,992 iteration 1527 : loss : 0.099579, loss_ce: 0.035042
2021-12-14 02:01:31,455 iteration 1528 : loss : 0.102643, loss_ce: 0.032782
2021-12-14 02:01:32,908 iteration 1529 : loss : 0.093045, loss_ce: 0.026311
2021-12-14 02:01:32,909 Training Data Eval:
2021-12-14 02:01:40,321   Average segmentation loss on training set: 0.0839
2021-12-14 02:01:40,322 Validation Data Eval:
2021-12-14 02:01:42,890   Average segmentation loss on validation set: 0.1090
2021-12-14 02:01:48,910 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 02:01:50,496 iteration 1530 : loss : 0.116629, loss_ce: 0.039361
 22%|██████▊                       | 90/400 [42:55<2:42:20, 31.42s/it]2021-12-14 02:01:52,102 iteration 1531 : loss : 0.097672, loss_ce: 0.030235
2021-12-14 02:01:53,619 iteration 1532 : loss : 0.099247, loss_ce: 0.028349
2021-12-14 02:01:55,069 iteration 1533 : loss : 0.084354, loss_ce: 0.023098
2021-12-14 02:01:56,556 iteration 1534 : loss : 0.091450, loss_ce: 0.031580
2021-12-14 02:01:58,143 iteration 1535 : loss : 0.091055, loss_ce: 0.025601
2021-12-14 02:01:59,733 iteration 1536 : loss : 0.104682, loss_ce: 0.039218
2021-12-14 02:02:01,242 iteration 1537 : loss : 0.089291, loss_ce: 0.023051
2021-12-14 02:02:02,806 iteration 1538 : loss : 0.098959, loss_ce: 0.028749
2021-12-14 02:02:04,337 iteration 1539 : loss : 0.083141, loss_ce: 0.027414
2021-12-14 02:02:05,855 iteration 1540 : loss : 0.107223, loss_ce: 0.036310
2021-12-14 02:02:07,314 iteration 1541 : loss : 0.079471, loss_ce: 0.023272
2021-12-14 02:02:08,757 iteration 1542 : loss : 0.080179, loss_ce: 0.025456
2021-12-14 02:02:10,243 iteration 1543 : loss : 0.104260, loss_ce: 0.027839
2021-12-14 02:02:11,658 iteration 1544 : loss : 0.093082, loss_ce: 0.028049
2021-12-14 02:02:13,315 iteration 1545 : loss : 0.093116, loss_ce: 0.026810
2021-12-14 02:02:14,769 iteration 1546 : loss : 0.104195, loss_ce: 0.022217
2021-12-14 02:02:16,445 iteration 1547 : loss : 0.089702, loss_ce: 0.024897
 23%|██████▊                       | 91/400 [43:21<2:33:21, 29.78s/it]2021-12-14 02:02:18,069 iteration 1548 : loss : 0.102937, loss_ce: 0.036318
2021-12-14 02:02:19,465 iteration 1549 : loss : 0.081611, loss_ce: 0.023095
2021-12-14 02:02:20,937 iteration 1550 : loss : 0.089427, loss_ce: 0.026154
2021-12-14 02:02:22,306 iteration 1551 : loss : 0.084278, loss_ce: 0.023378
2021-12-14 02:02:23,840 iteration 1552 : loss : 0.096397, loss_ce: 0.026434
2021-12-14 02:02:25,425 iteration 1553 : loss : 0.104787, loss_ce: 0.031485
2021-12-14 02:02:26,990 iteration 1554 : loss : 0.094777, loss_ce: 0.028798
2021-12-14 02:02:28,477 iteration 1555 : loss : 0.095854, loss_ce: 0.032260
2021-12-14 02:02:30,040 iteration 1556 : loss : 0.083335, loss_ce: 0.019362
2021-12-14 02:02:31,528 iteration 1557 : loss : 0.099404, loss_ce: 0.028224
2021-12-14 02:02:33,031 iteration 1558 : loss : 0.089424, loss_ce: 0.028652
2021-12-14 02:02:34,555 iteration 1559 : loss : 0.096051, loss_ce: 0.026548
2021-12-14 02:02:36,017 iteration 1560 : loss : 0.085344, loss_ce: 0.029757
2021-12-14 02:02:37,572 iteration 1561 : loss : 0.082781, loss_ce: 0.020693
2021-12-14 02:02:39,029 iteration 1562 : loss : 0.101858, loss_ce: 0.020772
2021-12-14 02:02:40,631 iteration 1563 : loss : 0.085821, loss_ce: 0.025748
2021-12-14 02:02:42,210 iteration 1564 : loss : 0.088701, loss_ce: 0.025995
 23%|██████▉                       | 92/400 [43:47<2:26:40, 28.57s/it]2021-12-14 02:02:43,748 iteration 1565 : loss : 0.101893, loss_ce: 0.035469
2021-12-14 02:02:45,247 iteration 1566 : loss : 0.088468, loss_ce: 0.026273
2021-12-14 02:02:46,819 iteration 1567 : loss : 0.080928, loss_ce: 0.020362
2021-12-14 02:02:48,307 iteration 1568 : loss : 0.087468, loss_ce: 0.022340
2021-12-14 02:02:49,888 iteration 1569 : loss : 0.089677, loss_ce: 0.026996
2021-12-14 02:02:51,412 iteration 1570 : loss : 0.083682, loss_ce: 0.024872
2021-12-14 02:02:52,891 iteration 1571 : loss : 0.096876, loss_ce: 0.016867
2021-12-14 02:02:54,475 iteration 1572 : loss : 0.104596, loss_ce: 0.026232
2021-12-14 02:02:56,004 iteration 1573 : loss : 0.107817, loss_ce: 0.037060
2021-12-14 02:02:57,453 iteration 1574 : loss : 0.076703, loss_ce: 0.022498
2021-12-14 02:02:58,833 iteration 1575 : loss : 0.088061, loss_ce: 0.026257
2021-12-14 02:03:00,319 iteration 1576 : loss : 0.087673, loss_ce: 0.029894
2021-12-14 02:03:01,818 iteration 1577 : loss : 0.082557, loss_ce: 0.024382
2021-12-14 02:03:03,341 iteration 1578 : loss : 0.100241, loss_ce: 0.025313
2021-12-14 02:03:04,882 iteration 1579 : loss : 0.081284, loss_ce: 0.023856
2021-12-14 02:03:06,332 iteration 1580 : loss : 0.096658, loss_ce: 0.029949
2021-12-14 02:03:07,838 iteration 1581 : loss : 0.086534, loss_ce: 0.022265
 23%|██████▉                       | 93/400 [44:13<2:21:41, 27.69s/it]2021-12-14 02:03:09,495 iteration 1582 : loss : 0.088052, loss_ce: 0.022491
2021-12-14 02:03:11,005 iteration 1583 : loss : 0.096576, loss_ce: 0.022377
2021-12-14 02:03:12,556 iteration 1584 : loss : 0.092216, loss_ce: 0.032091
2021-12-14 02:03:14,065 iteration 1585 : loss : 0.086312, loss_ce: 0.023009
2021-12-14 02:03:15,559 iteration 1586 : loss : 0.092076, loss_ce: 0.026757
2021-12-14 02:03:16,943 iteration 1587 : loss : 0.079606, loss_ce: 0.024848
2021-12-14 02:03:18,495 iteration 1588 : loss : 0.088011, loss_ce: 0.028414
2021-12-14 02:03:20,001 iteration 1589 : loss : 0.080859, loss_ce: 0.024944
2021-12-14 02:03:21,680 iteration 1590 : loss : 0.129068, loss_ce: 0.040196
2021-12-14 02:03:23,142 iteration 1591 : loss : 0.079815, loss_ce: 0.019190
2021-12-14 02:03:24,650 iteration 1592 : loss : 0.090503, loss_ce: 0.024306
2021-12-14 02:03:26,313 iteration 1593 : loss : 0.098894, loss_ce: 0.030692
2021-12-14 02:03:27,926 iteration 1594 : loss : 0.092547, loss_ce: 0.024341
2021-12-14 02:03:29,428 iteration 1595 : loss : 0.075762, loss_ce: 0.017859
2021-12-14 02:03:30,950 iteration 1596 : loss : 0.098526, loss_ce: 0.034241
2021-12-14 02:03:32,467 iteration 1597 : loss : 0.111950, loss_ce: 0.039613
2021-12-14 02:03:34,010 iteration 1598 : loss : 0.097802, loss_ce: 0.028258
 24%|███████                       | 94/400 [44:39<2:18:53, 27.23s/it]2021-12-14 02:03:35,545 iteration 1599 : loss : 0.084302, loss_ce: 0.024499
2021-12-14 02:03:37,059 iteration 1600 : loss : 0.096685, loss_ce: 0.025422
2021-12-14 02:03:38,659 iteration 1601 : loss : 0.097387, loss_ce: 0.027948
2021-12-14 02:03:40,349 iteration 1602 : loss : 0.106492, loss_ce: 0.032212
2021-12-14 02:03:41,857 iteration 1603 : loss : 0.084882, loss_ce: 0.023827
2021-12-14 02:03:43,321 iteration 1604 : loss : 0.084518, loss_ce: 0.024220
2021-12-14 02:03:44,886 iteration 1605 : loss : 0.095413, loss_ce: 0.026904
2021-12-14 02:03:46,379 iteration 1606 : loss : 0.087352, loss_ce: 0.029724
2021-12-14 02:03:47,847 iteration 1607 : loss : 0.088907, loss_ce: 0.027012
2021-12-14 02:03:49,457 iteration 1608 : loss : 0.088797, loss_ce: 0.023654
2021-12-14 02:03:50,968 iteration 1609 : loss : 0.111315, loss_ce: 0.045710
2021-12-14 02:03:52,494 iteration 1610 : loss : 0.082031, loss_ce: 0.023727
2021-12-14 02:03:54,135 iteration 1611 : loss : 0.128728, loss_ce: 0.037028
2021-12-14 02:03:55,650 iteration 1612 : loss : 0.080997, loss_ce: 0.027358
2021-12-14 02:03:56,984 iteration 1613 : loss : 0.096912, loss_ce: 0.033389
2021-12-14 02:03:58,529 iteration 1614 : loss : 0.100820, loss_ce: 0.025539
2021-12-14 02:03:58,530 Training Data Eval:
2021-12-14 02:04:05,953   Average segmentation loss on training set: 0.0869
2021-12-14 02:04:05,953 Validation Data Eval:
2021-12-14 02:04:08,519   Average segmentation loss on validation set: 0.1068
2021-12-14 02:04:14,392 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 02:04:15,957 iteration 1615 : loss : 0.086434, loss_ce: 0.026610
 24%|███████▏                      | 95/400 [45:21<2:40:52, 31.65s/it]2021-12-14 02:04:17,575 iteration 1616 : loss : 0.103976, loss_ce: 0.031083
2021-12-14 02:04:19,115 iteration 1617 : loss : 0.095738, loss_ce: 0.023540
2021-12-14 02:04:20,531 iteration 1618 : loss : 0.085907, loss_ce: 0.024994
2021-12-14 02:04:21,967 iteration 1619 : loss : 0.079983, loss_ce: 0.021789
2021-12-14 02:04:23,353 iteration 1620 : loss : 0.082042, loss_ce: 0.019642
2021-12-14 02:04:24,879 iteration 1621 : loss : 0.100740, loss_ce: 0.040103
2021-12-14 02:04:26,563 iteration 1622 : loss : 0.101971, loss_ce: 0.025181
2021-12-14 02:04:28,077 iteration 1623 : loss : 0.090140, loss_ce: 0.026365
2021-12-14 02:04:29,554 iteration 1624 : loss : 0.087181, loss_ce: 0.024920
2021-12-14 02:04:31,042 iteration 1625 : loss : 0.082816, loss_ce: 0.023135
2021-12-14 02:04:32,520 iteration 1626 : loss : 0.084862, loss_ce: 0.027962
2021-12-14 02:04:34,009 iteration 1627 : loss : 0.085689, loss_ce: 0.022185
2021-12-14 02:04:35,615 iteration 1628 : loss : 0.098828, loss_ce: 0.032959
2021-12-14 02:04:37,127 iteration 1629 : loss : 0.082847, loss_ce: 0.024951
2021-12-14 02:04:38,559 iteration 1630 : loss : 0.085322, loss_ce: 0.024720
2021-12-14 02:04:40,233 iteration 1631 : loss : 0.090049, loss_ce: 0.029009
2021-12-14 02:04:41,847 iteration 1632 : loss : 0.090442, loss_ce: 0.024598
 24%|███████▏                      | 96/400 [45:47<2:31:35, 29.92s/it]2021-12-14 02:04:43,506 iteration 1633 : loss : 0.081635, loss_ce: 0.021482
2021-12-14 02:04:45,065 iteration 1634 : loss : 0.112681, loss_ce: 0.029544
2021-12-14 02:04:46,575 iteration 1635 : loss : 0.091216, loss_ce: 0.033036
2021-12-14 02:04:48,186 iteration 1636 : loss : 0.098140, loss_ce: 0.035894
2021-12-14 02:04:49,728 iteration 1637 : loss : 0.092428, loss_ce: 0.024579
2021-12-14 02:04:51,213 iteration 1638 : loss : 0.090374, loss_ce: 0.028915
2021-12-14 02:04:52,886 iteration 1639 : loss : 0.097533, loss_ce: 0.019600
2021-12-14 02:04:54,454 iteration 1640 : loss : 0.098244, loss_ce: 0.023280
2021-12-14 02:04:55,883 iteration 1641 : loss : 0.080372, loss_ce: 0.027689
2021-12-14 02:04:57,370 iteration 1642 : loss : 0.089318, loss_ce: 0.026184
2021-12-14 02:04:58,914 iteration 1643 : loss : 0.084754, loss_ce: 0.019172
2021-12-14 02:05:00,388 iteration 1644 : loss : 0.093235, loss_ce: 0.026420
2021-12-14 02:05:01,885 iteration 1645 : loss : 0.091231, loss_ce: 0.024762
2021-12-14 02:05:03,373 iteration 1646 : loss : 0.099967, loss_ce: 0.025736
2021-12-14 02:05:04,846 iteration 1647 : loss : 0.103073, loss_ce: 0.027983
2021-12-14 02:05:06,386 iteration 1648 : loss : 0.094357, loss_ce: 0.031885
2021-12-14 02:05:07,835 iteration 1649 : loss : 0.090219, loss_ce: 0.029384
 24%|███████▎                      | 97/400 [46:13<2:25:08, 28.74s/it]2021-12-14 02:05:09,437 iteration 1650 : loss : 0.084213, loss_ce: 0.028984
2021-12-14 02:05:11,120 iteration 1651 : loss : 0.097062, loss_ce: 0.025848
2021-12-14 02:05:12,573 iteration 1652 : loss : 0.094285, loss_ce: 0.023758
2021-12-14 02:05:14,001 iteration 1653 : loss : 0.083632, loss_ce: 0.020424
2021-12-14 02:05:15,561 iteration 1654 : loss : 0.128808, loss_ce: 0.026815
2021-12-14 02:05:17,166 iteration 1655 : loss : 0.097465, loss_ce: 0.026854
2021-12-14 02:05:18,672 iteration 1656 : loss : 0.084417, loss_ce: 0.024130
2021-12-14 02:05:20,319 iteration 1657 : loss : 0.116110, loss_ce: 0.029444
2021-12-14 02:05:21,904 iteration 1658 : loss : 0.111677, loss_ce: 0.043640
2021-12-14 02:05:23,407 iteration 1659 : loss : 0.075880, loss_ce: 0.017438
2021-12-14 02:05:25,072 iteration 1660 : loss : 0.087944, loss_ce: 0.027398
2021-12-14 02:05:26,695 iteration 1661 : loss : 0.089868, loss_ce: 0.021947
2021-12-14 02:05:28,219 iteration 1662 : loss : 0.095157, loss_ce: 0.028947
2021-12-14 02:05:29,588 iteration 1663 : loss : 0.079453, loss_ce: 0.028544
2021-12-14 02:05:31,203 iteration 1664 : loss : 0.101789, loss_ce: 0.032866
2021-12-14 02:05:32,775 iteration 1665 : loss : 0.093539, loss_ce: 0.026439
2021-12-14 02:05:34,408 iteration 1666 : loss : 0.096804, loss_ce: 0.032506
 24%|███████▎                      | 98/400 [46:39<2:21:24, 28.09s/it]2021-12-14 02:05:36,054 iteration 1667 : loss : 0.112977, loss_ce: 0.027454
2021-12-14 02:05:37,582 iteration 1668 : loss : 0.091109, loss_ce: 0.021515
2021-12-14 02:05:39,036 iteration 1669 : loss : 0.080189, loss_ce: 0.022736
2021-12-14 02:05:40,583 iteration 1670 : loss : 0.092554, loss_ce: 0.030978
2021-12-14 02:05:42,094 iteration 1671 : loss : 0.081001, loss_ce: 0.021268
2021-12-14 02:05:43,692 iteration 1672 : loss : 0.082170, loss_ce: 0.023528
2021-12-14 02:05:45,251 iteration 1673 : loss : 0.087076, loss_ce: 0.028383
2021-12-14 02:05:46,881 iteration 1674 : loss : 0.119690, loss_ce: 0.046584
2021-12-14 02:05:48,360 iteration 1675 : loss : 0.093142, loss_ce: 0.022707
2021-12-14 02:05:49,856 iteration 1676 : loss : 0.111197, loss_ce: 0.031897
2021-12-14 02:05:51,500 iteration 1677 : loss : 0.106523, loss_ce: 0.041725
2021-12-14 02:05:52,877 iteration 1678 : loss : 0.084576, loss_ce: 0.026915
2021-12-14 02:05:54,348 iteration 1679 : loss : 0.086854, loss_ce: 0.018953
2021-12-14 02:05:55,915 iteration 1680 : loss : 0.087828, loss_ce: 0.029429
2021-12-14 02:05:57,481 iteration 1681 : loss : 0.097723, loss_ce: 0.039927
2021-12-14 02:05:59,033 iteration 1682 : loss : 0.086755, loss_ce: 0.022462
2021-12-14 02:06:00,479 iteration 1683 : loss : 0.080223, loss_ce: 0.020881
 25%|███████▍                      | 99/400 [47:05<2:17:53, 27.49s/it]2021-12-14 02:06:02,113 iteration 1684 : loss : 0.090637, loss_ce: 0.025482
2021-12-14 02:06:03,639 iteration 1685 : loss : 0.094260, loss_ce: 0.024607
2021-12-14 02:06:05,141 iteration 1686 : loss : 0.079853, loss_ce: 0.023287
2021-12-14 02:06:06,570 iteration 1687 : loss : 0.094654, loss_ce: 0.030254
2021-12-14 02:06:08,272 iteration 1688 : loss : 0.086810, loss_ce: 0.025745
2021-12-14 02:06:09,805 iteration 1689 : loss : 0.104658, loss_ce: 0.032939
2021-12-14 02:06:11,384 iteration 1690 : loss : 0.083350, loss_ce: 0.028486
2021-12-14 02:06:12,815 iteration 1691 : loss : 0.122709, loss_ce: 0.025082
2021-12-14 02:06:14,406 iteration 1692 : loss : 0.126201, loss_ce: 0.033958
2021-12-14 02:06:15,759 iteration 1693 : loss : 0.082219, loss_ce: 0.024687
2021-12-14 02:06:17,321 iteration 1694 : loss : 0.082012, loss_ce: 0.021862
2021-12-14 02:06:18,941 iteration 1695 : loss : 0.085093, loss_ce: 0.026084
2021-12-14 02:06:20,548 iteration 1696 : loss : 0.096504, loss_ce: 0.025151
2021-12-14 02:06:22,063 iteration 1697 : loss : 0.083452, loss_ce: 0.023425
2021-12-14 02:06:23,659 iteration 1698 : loss : 0.093284, loss_ce: 0.027073
2021-12-14 02:06:25,188 iteration 1699 : loss : 0.090549, loss_ce: 0.032338
2021-12-14 02:06:25,189 Training Data Eval:
2021-12-14 02:06:32,624   Average segmentation loss on training set: 0.0759
2021-12-14 02:06:32,624 Validation Data Eval:
2021-12-14 02:06:35,182   Average segmentation loss on validation set: 0.1087
2021-12-14 02:06:36,660 iteration 1700 : loss : 0.081030, loss_ce: 0.018065
 25%|███████▎                     | 100/400 [47:41<2:30:28, 30.09s/it]2021-12-14 02:06:38,270 iteration 1701 : loss : 0.084106, loss_ce: 0.026410
2021-12-14 02:06:39,756 iteration 1702 : loss : 0.089443, loss_ce: 0.027195
2021-12-14 02:06:41,369 iteration 1703 : loss : 0.090010, loss_ce: 0.029949
2021-12-14 02:06:42,961 iteration 1704 : loss : 0.083796, loss_ce: 0.026815
2021-12-14 02:06:44,466 iteration 1705 : loss : 0.093093, loss_ce: 0.024784
2021-12-14 02:06:46,046 iteration 1706 : loss : 0.094549, loss_ce: 0.021373
2021-12-14 02:06:47,539 iteration 1707 : loss : 0.105086, loss_ce: 0.035585
2021-12-14 02:06:49,045 iteration 1708 : loss : 0.091086, loss_ce: 0.027454
2021-12-14 02:06:50,772 iteration 1709 : loss : 0.085612, loss_ce: 0.026027
2021-12-14 02:06:52,236 iteration 1710 : loss : 0.086945, loss_ce: 0.028496
2021-12-14 02:06:53,783 iteration 1711 : loss : 0.099808, loss_ce: 0.030753
2021-12-14 02:06:55,322 iteration 1712 : loss : 0.091771, loss_ce: 0.022609
2021-12-14 02:06:56,854 iteration 1713 : loss : 0.086437, loss_ce: 0.022782
2021-12-14 02:06:58,337 iteration 1714 : loss : 0.095565, loss_ce: 0.031794
2021-12-14 02:06:59,941 iteration 1715 : loss : 0.108480, loss_ce: 0.032401
2021-12-14 02:07:01,446 iteration 1716 : loss : 0.115324, loss_ce: 0.027564
2021-12-14 02:07:02,989 iteration 1717 : loss : 0.090835, loss_ce: 0.030871
 25%|███████▎                     | 101/400 [48:08<2:24:20, 28.97s/it]2021-12-14 02:07:04,620 iteration 1718 : loss : 0.091713, loss_ce: 0.024748
2021-12-14 02:07:06,252 iteration 1719 : loss : 0.078991, loss_ce: 0.017810
2021-12-14 02:07:07,833 iteration 1720 : loss : 0.086022, loss_ce: 0.025479
2021-12-14 02:07:09,373 iteration 1721 : loss : 0.095483, loss_ce: 0.033920
2021-12-14 02:07:10,849 iteration 1722 : loss : 0.078463, loss_ce: 0.020755
2021-12-14 02:07:12,334 iteration 1723 : loss : 0.083382, loss_ce: 0.025205
2021-12-14 02:07:13,758 iteration 1724 : loss : 0.082602, loss_ce: 0.026623
2021-12-14 02:07:15,204 iteration 1725 : loss : 0.088019, loss_ce: 0.030628
2021-12-14 02:07:16,874 iteration 1726 : loss : 0.094047, loss_ce: 0.024951
2021-12-14 02:07:18,462 iteration 1727 : loss : 0.084443, loss_ce: 0.024219
2021-12-14 02:07:20,121 iteration 1728 : loss : 0.105419, loss_ce: 0.037372
2021-12-14 02:07:21,599 iteration 1729 : loss : 0.080303, loss_ce: 0.022430
2021-12-14 02:07:23,141 iteration 1730 : loss : 0.082220, loss_ce: 0.024905
2021-12-14 02:07:24,606 iteration 1731 : loss : 0.084087, loss_ce: 0.026725
2021-12-14 02:07:26,138 iteration 1732 : loss : 0.093513, loss_ce: 0.032314
2021-12-14 02:07:27,675 iteration 1733 : loss : 0.083362, loss_ce: 0.020677
2021-12-14 02:07:29,160 iteration 1734 : loss : 0.099104, loss_ce: 0.023524
 26%|███████▍                     | 102/400 [48:34<2:19:39, 28.12s/it]2021-12-14 02:07:30,829 iteration 1735 : loss : 0.076941, loss_ce: 0.017377
2021-12-14 02:07:32,357 iteration 1736 : loss : 0.086765, loss_ce: 0.025649
2021-12-14 02:07:33,905 iteration 1737 : loss : 0.098388, loss_ce: 0.033017
2021-12-14 02:07:35,421 iteration 1738 : loss : 0.085771, loss_ce: 0.023667
2021-12-14 02:07:36,930 iteration 1739 : loss : 0.120350, loss_ce: 0.049969
2021-12-14 02:07:38,438 iteration 1740 : loss : 0.089200, loss_ce: 0.021381
2021-12-14 02:07:40,063 iteration 1741 : loss : 0.090520, loss_ce: 0.024897
2021-12-14 02:07:41,601 iteration 1742 : loss : 0.096854, loss_ce: 0.026845
2021-12-14 02:07:43,114 iteration 1743 : loss : 0.096100, loss_ce: 0.039656
2021-12-14 02:07:44,563 iteration 1744 : loss : 0.093618, loss_ce: 0.025356
2021-12-14 02:07:46,161 iteration 1745 : loss : 0.094749, loss_ce: 0.029592
2021-12-14 02:07:47,652 iteration 1746 : loss : 0.092894, loss_ce: 0.024570
2021-12-14 02:07:49,152 iteration 1747 : loss : 0.091699, loss_ce: 0.026544
2021-12-14 02:07:50,609 iteration 1748 : loss : 0.079347, loss_ce: 0.027810
2021-12-14 02:07:52,158 iteration 1749 : loss : 0.088177, loss_ce: 0.027946
2021-12-14 02:07:53,614 iteration 1750 : loss : 0.084537, loss_ce: 0.030854
2021-12-14 02:07:55,074 iteration 1751 : loss : 0.088425, loss_ce: 0.027057
 26%|███████▍                     | 103/400 [49:00<2:15:55, 27.46s/it]2021-12-14 02:07:56,639 iteration 1752 : loss : 0.080660, loss_ce: 0.026031
2021-12-14 02:07:58,278 iteration 1753 : loss : 0.109928, loss_ce: 0.041939
2021-12-14 02:07:59,820 iteration 1754 : loss : 0.085093, loss_ce: 0.029599
2021-12-14 02:08:01,358 iteration 1755 : loss : 0.098188, loss_ce: 0.025139
2021-12-14 02:08:02,951 iteration 1756 : loss : 0.146771, loss_ce: 0.076858
2021-12-14 02:08:04,490 iteration 1757 : loss : 0.109857, loss_ce: 0.022180
2021-12-14 02:08:06,035 iteration 1758 : loss : 0.088789, loss_ce: 0.025166
2021-12-14 02:08:07,535 iteration 1759 : loss : 0.093798, loss_ce: 0.024083
2021-12-14 02:08:09,126 iteration 1760 : loss : 0.089428, loss_ce: 0.031011
2021-12-14 02:08:10,570 iteration 1761 : loss : 0.079086, loss_ce: 0.021657
2021-12-14 02:08:12,166 iteration 1762 : loss : 0.128479, loss_ce: 0.047042
2021-12-14 02:08:13,645 iteration 1763 : loss : 0.087469, loss_ce: 0.023453
2021-12-14 02:08:15,221 iteration 1764 : loss : 0.120861, loss_ce: 0.020501
2021-12-14 02:08:16,795 iteration 1765 : loss : 0.109552, loss_ce: 0.026935
2021-12-14 02:08:18,254 iteration 1766 : loss : 0.079257, loss_ce: 0.025935
2021-12-14 02:08:19,785 iteration 1767 : loss : 0.090354, loss_ce: 0.029150
2021-12-14 02:08:21,397 iteration 1768 : loss : 0.089280, loss_ce: 0.026005
 26%|███████▌                     | 104/400 [49:26<2:13:48, 27.12s/it]2021-12-14 02:08:22,962 iteration 1769 : loss : 0.090928, loss_ce: 0.024091
2021-12-14 02:08:24,722 iteration 1770 : loss : 0.106635, loss_ce: 0.034370
2021-12-14 02:08:26,249 iteration 1771 : loss : 0.093753, loss_ce: 0.026425
2021-12-14 02:08:27,748 iteration 1772 : loss : 0.078585, loss_ce: 0.017451
2021-12-14 02:08:29,165 iteration 1773 : loss : 0.080549, loss_ce: 0.020582
2021-12-14 02:08:30,686 iteration 1774 : loss : 0.075710, loss_ce: 0.021638
2021-12-14 02:08:32,295 iteration 1775 : loss : 0.116450, loss_ce: 0.043095
2021-12-14 02:08:33,802 iteration 1776 : loss : 0.092133, loss_ce: 0.020395
2021-12-14 02:08:35,284 iteration 1777 : loss : 0.091446, loss_ce: 0.027950
2021-12-14 02:08:36,785 iteration 1778 : loss : 0.107864, loss_ce: 0.029819
2021-12-14 02:08:38,321 iteration 1779 : loss : 0.082660, loss_ce: 0.022311
2021-12-14 02:08:39,795 iteration 1780 : loss : 0.086006, loss_ce: 0.025609
2021-12-14 02:08:41,293 iteration 1781 : loss : 0.096871, loss_ce: 0.038182
2021-12-14 02:08:42,854 iteration 1782 : loss : 0.098574, loss_ce: 0.027143
2021-12-14 02:08:44,299 iteration 1783 : loss : 0.083679, loss_ce: 0.029384
2021-12-14 02:08:45,934 iteration 1784 : loss : 0.084036, loss_ce: 0.024160
2021-12-14 02:08:45,934 Training Data Eval:
2021-12-14 02:08:53,363   Average segmentation loss on training set: 0.0771
2021-12-14 02:08:53,363 Validation Data Eval:
2021-12-14 02:08:55,928   Average segmentation loss on validation set: 0.1014
2021-12-14 02:09:01,940 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 02:09:03,506 iteration 1785 : loss : 0.095506, loss_ce: 0.026665
 26%|███████▌                     | 105/400 [50:08<2:35:26, 31.62s/it]2021-12-14 02:09:05,240 iteration 1786 : loss : 0.103523, loss_ce: 0.040684
2021-12-14 02:09:06,889 iteration 1787 : loss : 0.090170, loss_ce: 0.028349
2021-12-14 02:09:08,458 iteration 1788 : loss : 0.099308, loss_ce: 0.032334
2021-12-14 02:09:09,977 iteration 1789 : loss : 0.084404, loss_ce: 0.021590
2021-12-14 02:09:11,478 iteration 1790 : loss : 0.081942, loss_ce: 0.030048
2021-12-14 02:09:12,919 iteration 1791 : loss : 0.075812, loss_ce: 0.024533
2021-12-14 02:09:14,474 iteration 1792 : loss : 0.109744, loss_ce: 0.028032
2021-12-14 02:09:16,048 iteration 1793 : loss : 0.085792, loss_ce: 0.028937
2021-12-14 02:09:17,535 iteration 1794 : loss : 0.088577, loss_ce: 0.031934
2021-12-14 02:09:19,097 iteration 1795 : loss : 0.092515, loss_ce: 0.026724
2021-12-14 02:09:20,619 iteration 1796 : loss : 0.083443, loss_ce: 0.024275
2021-12-14 02:09:22,259 iteration 1797 : loss : 0.087984, loss_ce: 0.027090
2021-12-14 02:09:23,803 iteration 1798 : loss : 0.089262, loss_ce: 0.025625
2021-12-14 02:09:25,373 iteration 1799 : loss : 0.106667, loss_ce: 0.028777
2021-12-14 02:09:26,922 iteration 1800 : loss : 0.092326, loss_ce: 0.029733
2021-12-14 02:09:28,491 iteration 1801 : loss : 0.082381, loss_ce: 0.023825
2021-12-14 02:09:29,927 iteration 1802 : loss : 0.099024, loss_ce: 0.022119
 26%|███████▋                     | 106/400 [50:35<2:27:17, 30.06s/it]2021-12-14 02:09:31,550 iteration 1803 : loss : 0.089901, loss_ce: 0.023643
2021-12-14 02:09:33,046 iteration 1804 : loss : 0.089461, loss_ce: 0.018259
2021-12-14 02:09:34,495 iteration 1805 : loss : 0.077088, loss_ce: 0.025505
2021-12-14 02:09:35,969 iteration 1806 : loss : 0.089654, loss_ce: 0.024195
2021-12-14 02:09:37,496 iteration 1807 : loss : 0.083691, loss_ce: 0.023754
2021-12-14 02:09:39,034 iteration 1808 : loss : 0.089844, loss_ce: 0.028336
2021-12-14 02:09:40,564 iteration 1809 : loss : 0.088284, loss_ce: 0.029896
2021-12-14 02:09:42,097 iteration 1810 : loss : 0.087690, loss_ce: 0.026298
2021-12-14 02:09:43,670 iteration 1811 : loss : 0.094173, loss_ce: 0.025867
2021-12-14 02:09:45,298 iteration 1812 : loss : 0.098113, loss_ce: 0.032562
2021-12-14 02:09:46,880 iteration 1813 : loss : 0.119842, loss_ce: 0.031833
2021-12-14 02:09:48,521 iteration 1814 : loss : 0.103679, loss_ce: 0.032658
2021-12-14 02:09:50,074 iteration 1815 : loss : 0.086675, loss_ce: 0.030737
2021-12-14 02:09:51,684 iteration 1816 : loss : 0.092398, loss_ce: 0.025559
2021-12-14 02:09:53,219 iteration 1817 : loss : 0.080262, loss_ce: 0.019199
2021-12-14 02:09:54,866 iteration 1818 : loss : 0.087142, loss_ce: 0.035323
2021-12-14 02:09:56,361 iteration 1819 : loss : 0.076879, loss_ce: 0.021658
 27%|███████▊                     | 107/400 [51:01<2:21:27, 28.97s/it]2021-12-14 02:09:58,012 iteration 1820 : loss : 0.108102, loss_ce: 0.029644
2021-12-14 02:09:59,492 iteration 1821 : loss : 0.093624, loss_ce: 0.022732
2021-12-14 02:10:00,962 iteration 1822 : loss : 0.083420, loss_ce: 0.030774
2021-12-14 02:10:02,538 iteration 1823 : loss : 0.097155, loss_ce: 0.031415
2021-12-14 02:10:04,054 iteration 1824 : loss : 0.087456, loss_ce: 0.022320
2021-12-14 02:10:05,590 iteration 1825 : loss : 0.083744, loss_ce: 0.022711
2021-12-14 02:10:07,006 iteration 1826 : loss : 0.097178, loss_ce: 0.031794
2021-12-14 02:10:08,475 iteration 1827 : loss : 0.093339, loss_ce: 0.021498
2021-12-14 02:10:10,055 iteration 1828 : loss : 0.080148, loss_ce: 0.026057
2021-12-14 02:10:11,618 iteration 1829 : loss : 0.100831, loss_ce: 0.025267
2021-12-14 02:10:13,136 iteration 1830 : loss : 0.077787, loss_ce: 0.022464
2021-12-14 02:10:14,641 iteration 1831 : loss : 0.084370, loss_ce: 0.029059
2021-12-14 02:10:16,146 iteration 1832 : loss : 0.078108, loss_ce: 0.022009
2021-12-14 02:10:17,631 iteration 1833 : loss : 0.077480, loss_ce: 0.029455
2021-12-14 02:10:19,250 iteration 1834 : loss : 0.086019, loss_ce: 0.025513
2021-12-14 02:10:20,663 iteration 1835 : loss : 0.083750, loss_ce: 0.023147
2021-12-14 02:10:22,130 iteration 1836 : loss : 0.087892, loss_ce: 0.029600
 27%|███████▊                     | 108/400 [51:27<2:16:20, 28.01s/it]2021-12-14 02:10:23,636 iteration 1837 : loss : 0.099887, loss_ce: 0.019563
2021-12-14 02:10:25,245 iteration 1838 : loss : 0.088638, loss_ce: 0.029993
2021-12-14 02:10:26,679 iteration 1839 : loss : 0.077214, loss_ce: 0.023832
2021-12-14 02:10:28,211 iteration 1840 : loss : 0.091620, loss_ce: 0.021645
2021-12-14 02:10:29,742 iteration 1841 : loss : 0.090240, loss_ce: 0.021305
2021-12-14 02:10:31,376 iteration 1842 : loss : 0.094301, loss_ce: 0.029673
2021-12-14 02:10:32,878 iteration 1843 : loss : 0.080624, loss_ce: 0.025968
2021-12-14 02:10:34,399 iteration 1844 : loss : 0.086883, loss_ce: 0.027430
2021-12-14 02:10:35,912 iteration 1845 : loss : 0.078462, loss_ce: 0.022056
2021-12-14 02:10:37,441 iteration 1846 : loss : 0.080689, loss_ce: 0.019973
2021-12-14 02:10:38,847 iteration 1847 : loss : 0.071625, loss_ce: 0.019458
2021-12-14 02:10:40,372 iteration 1848 : loss : 0.082565, loss_ce: 0.023575
2021-12-14 02:10:41,902 iteration 1849 : loss : 0.081362, loss_ce: 0.021898
2021-12-14 02:10:43,432 iteration 1850 : loss : 0.089423, loss_ce: 0.026466
2021-12-14 02:10:45,011 iteration 1851 : loss : 0.092041, loss_ce: 0.028653
2021-12-14 02:10:46,410 iteration 1852 : loss : 0.077225, loss_ce: 0.026447
2021-12-14 02:10:47,983 iteration 1853 : loss : 0.093785, loss_ce: 0.029775
 27%|███████▉                     | 109/400 [51:53<2:12:42, 27.36s/it]2021-12-14 02:10:49,603 iteration 1854 : loss : 0.086063, loss_ce: 0.020915
2021-12-14 02:10:51,204 iteration 1855 : loss : 0.092827, loss_ce: 0.026845
2021-12-14 02:10:52,602 iteration 1856 : loss : 0.082895, loss_ce: 0.028039
2021-12-14 02:10:54,003 iteration 1857 : loss : 0.080263, loss_ce: 0.026180
2021-12-14 02:10:55,445 iteration 1858 : loss : 0.080347, loss_ce: 0.027465
2021-12-14 02:10:56,986 iteration 1859 : loss : 0.084932, loss_ce: 0.027611
2021-12-14 02:10:58,558 iteration 1860 : loss : 0.095819, loss_ce: 0.026407
2021-12-14 02:11:00,091 iteration 1861 : loss : 0.088174, loss_ce: 0.034880
2021-12-14 02:11:01,643 iteration 1862 : loss : 0.075025, loss_ce: 0.025217
2021-12-14 02:11:03,221 iteration 1863 : loss : 0.101556, loss_ce: 0.032036
2021-12-14 02:11:04,777 iteration 1864 : loss : 0.078437, loss_ce: 0.021780
2021-12-14 02:11:06,322 iteration 1865 : loss : 0.093757, loss_ce: 0.025234
2021-12-14 02:11:07,847 iteration 1866 : loss : 0.073777, loss_ce: 0.020109
2021-12-14 02:11:09,239 iteration 1867 : loss : 0.074012, loss_ce: 0.017845
2021-12-14 02:11:10,712 iteration 1868 : loss : 0.078744, loss_ce: 0.022224
2021-12-14 02:11:12,178 iteration 1869 : loss : 0.078252, loss_ce: 0.027499
2021-12-14 02:11:12,178 Training Data Eval:
2021-12-14 02:11:19,613   Average segmentation loss on training set: 0.0711
2021-12-14 02:11:19,614 Validation Data Eval:
2021-12-14 02:11:22,187   Average segmentation loss on validation set: 0.1056
2021-12-14 02:11:23,731 iteration 1870 : loss : 0.091669, loss_ce: 0.028712
 28%|███████▉                     | 110/400 [52:28<2:24:25, 29.88s/it]2021-12-14 02:11:25,372 iteration 1871 : loss : 0.094052, loss_ce: 0.021808
2021-12-14 02:11:26,950 iteration 1872 : loss : 0.080484, loss_ce: 0.021609
2021-12-14 02:11:28,548 iteration 1873 : loss : 0.086192, loss_ce: 0.021768
2021-12-14 02:11:30,118 iteration 1874 : loss : 0.086982, loss_ce: 0.024222
2021-12-14 02:11:31,546 iteration 1875 : loss : 0.071185, loss_ce: 0.021359
2021-12-14 02:11:32,945 iteration 1876 : loss : 0.076482, loss_ce: 0.026052
2021-12-14 02:11:34,514 iteration 1877 : loss : 0.080599, loss_ce: 0.020430
2021-12-14 02:11:36,055 iteration 1878 : loss : 0.105658, loss_ce: 0.042413
2021-12-14 02:11:37,585 iteration 1879 : loss : 0.076489, loss_ce: 0.017970
2021-12-14 02:11:39,152 iteration 1880 : loss : 0.094546, loss_ce: 0.033411
2021-12-14 02:11:40,684 iteration 1881 : loss : 0.115472, loss_ce: 0.044403
2021-12-14 02:11:42,291 iteration 1882 : loss : 0.109150, loss_ce: 0.030816
2021-12-14 02:11:43,841 iteration 1883 : loss : 0.069911, loss_ce: 0.018473
2021-12-14 02:11:45,316 iteration 1884 : loss : 0.088342, loss_ce: 0.026105
2021-12-14 02:11:46,735 iteration 1885 : loss : 0.069223, loss_ce: 0.020094
2021-12-14 02:11:48,276 iteration 1886 : loss : 0.088939, loss_ce: 0.026677
2021-12-14 02:11:49,834 iteration 1887 : loss : 0.106922, loss_ce: 0.036402
 28%|████████                     | 111/400 [52:55<2:18:26, 28.74s/it]2021-12-14 02:11:51,565 iteration 1888 : loss : 0.087834, loss_ce: 0.021951
2021-12-14 02:11:53,008 iteration 1889 : loss : 0.092334, loss_ce: 0.024820
2021-12-14 02:11:54,451 iteration 1890 : loss : 0.083826, loss_ce: 0.028288
2021-12-14 02:11:55,895 iteration 1891 : loss : 0.077903, loss_ce: 0.021938
2021-12-14 02:11:57,379 iteration 1892 : loss : 0.077667, loss_ce: 0.027127
2021-12-14 02:11:58,927 iteration 1893 : loss : 0.086271, loss_ce: 0.021083
2021-12-14 02:12:00,442 iteration 1894 : loss : 0.087036, loss_ce: 0.028755
2021-12-14 02:12:01,871 iteration 1895 : loss : 0.073877, loss_ce: 0.020103
2021-12-14 02:12:03,478 iteration 1896 : loss : 0.087239, loss_ce: 0.028539
2021-12-14 02:12:05,051 iteration 1897 : loss : 0.095221, loss_ce: 0.026303
2021-12-14 02:12:06,696 iteration 1898 : loss : 0.081426, loss_ce: 0.026909
2021-12-14 02:12:08,223 iteration 1899 : loss : 0.088885, loss_ce: 0.023394
2021-12-14 02:12:09,677 iteration 1900 : loss : 0.105563, loss_ce: 0.036788
2021-12-14 02:12:11,113 iteration 1901 : loss : 0.084769, loss_ce: 0.022428
2021-12-14 02:12:12,614 iteration 1902 : loss : 0.082654, loss_ce: 0.026092
2021-12-14 02:12:14,182 iteration 1903 : loss : 0.091541, loss_ce: 0.028919
2021-12-14 02:12:15,788 iteration 1904 : loss : 0.087223, loss_ce: 0.026799
 28%|████████                     | 112/400 [53:21<2:13:58, 27.91s/it]2021-12-14 02:12:17,289 iteration 1905 : loss : 0.084551, loss_ce: 0.028987
2021-12-14 02:12:18,846 iteration 1906 : loss : 0.075181, loss_ce: 0.017853
2021-12-14 02:12:20,427 iteration 1907 : loss : 0.081198, loss_ce: 0.025199
2021-12-14 02:12:22,153 iteration 1908 : loss : 0.093670, loss_ce: 0.029846
2021-12-14 02:12:23,576 iteration 1909 : loss : 0.072649, loss_ce: 0.021153
2021-12-14 02:12:25,073 iteration 1910 : loss : 0.083145, loss_ce: 0.024570
2021-12-14 02:12:26,657 iteration 1911 : loss : 0.075871, loss_ce: 0.023397
2021-12-14 02:12:28,336 iteration 1912 : loss : 0.087449, loss_ce: 0.025840
2021-12-14 02:12:29,905 iteration 1913 : loss : 0.093151, loss_ce: 0.025817
2021-12-14 02:12:31,547 iteration 1914 : loss : 0.093497, loss_ce: 0.031553
2021-12-14 02:12:33,087 iteration 1915 : loss : 0.073176, loss_ce: 0.017847
2021-12-14 02:12:34,594 iteration 1916 : loss : 0.088914, loss_ce: 0.024324
2021-12-14 02:12:36,098 iteration 1917 : loss : 0.077963, loss_ce: 0.025093
2021-12-14 02:12:37,675 iteration 1918 : loss : 0.091167, loss_ce: 0.034668
2021-12-14 02:12:39,151 iteration 1919 : loss : 0.082791, loss_ce: 0.019287
2021-12-14 02:12:40,568 iteration 1920 : loss : 0.085285, loss_ce: 0.028429
2021-12-14 02:12:42,189 iteration 1921 : loss : 0.098733, loss_ce: 0.031631
 28%|████████▏                    | 113/400 [53:47<2:11:19, 27.45s/it]2021-12-14 02:12:43,866 iteration 1922 : loss : 0.092632, loss_ce: 0.032748
2021-12-14 02:12:45,347 iteration 1923 : loss : 0.074164, loss_ce: 0.020861
2021-12-14 02:12:46,948 iteration 1924 : loss : 0.106536, loss_ce: 0.028323
2021-12-14 02:12:48,391 iteration 1925 : loss : 0.102561, loss_ce: 0.023155
2021-12-14 02:12:50,004 iteration 1926 : loss : 0.095086, loss_ce: 0.029631
2021-12-14 02:12:51,639 iteration 1927 : loss : 0.080548, loss_ce: 0.027412
2021-12-14 02:12:53,096 iteration 1928 : loss : 0.088778, loss_ce: 0.022129
2021-12-14 02:12:54,819 iteration 1929 : loss : 0.096826, loss_ce: 0.032907
2021-12-14 02:12:56,361 iteration 1930 : loss : 0.086018, loss_ce: 0.030180
2021-12-14 02:12:57,993 iteration 1931 : loss : 0.082204, loss_ce: 0.021725
2021-12-14 02:12:59,548 iteration 1932 : loss : 0.094840, loss_ce: 0.022252
2021-12-14 02:13:01,119 iteration 1933 : loss : 0.082199, loss_ce: 0.022891
2021-12-14 02:13:02,650 iteration 1934 : loss : 0.100194, loss_ce: 0.028157
2021-12-14 02:13:04,199 iteration 1935 : loss : 0.077596, loss_ce: 0.024223
2021-12-14 02:13:05,699 iteration 1936 : loss : 0.081111, loss_ce: 0.024082
2021-12-14 02:13:07,166 iteration 1937 : loss : 0.078556, loss_ce: 0.021785
2021-12-14 02:13:08,735 iteration 1938 : loss : 0.084820, loss_ce: 0.025466
 28%|████████▎                    | 114/400 [54:13<2:09:34, 27.18s/it]2021-12-14 02:13:10,355 iteration 1939 : loss : 0.090242, loss_ce: 0.031126
2021-12-14 02:13:11,806 iteration 1940 : loss : 0.080965, loss_ce: 0.028762
2021-12-14 02:13:13,338 iteration 1941 : loss : 0.080738, loss_ce: 0.025249
2021-12-14 02:13:14,894 iteration 1942 : loss : 0.078242, loss_ce: 0.020361
2021-12-14 02:13:16,392 iteration 1943 : loss : 0.090814, loss_ce: 0.024519
2021-12-14 02:13:17,946 iteration 1944 : loss : 0.083641, loss_ce: 0.023386
2021-12-14 02:13:19,494 iteration 1945 : loss : 0.098764, loss_ce: 0.031607
2021-12-14 02:13:20,977 iteration 1946 : loss : 0.083542, loss_ce: 0.018535
2021-12-14 02:13:22,483 iteration 1947 : loss : 0.082053, loss_ce: 0.018006
2021-12-14 02:13:24,043 iteration 1948 : loss : 0.087605, loss_ce: 0.029018
2021-12-14 02:13:25,532 iteration 1949 : loss : 0.074479, loss_ce: 0.020057
2021-12-14 02:13:27,100 iteration 1950 : loss : 0.096427, loss_ce: 0.027829
2021-12-14 02:13:28,657 iteration 1951 : loss : 0.080276, loss_ce: 0.023187
2021-12-14 02:13:30,205 iteration 1952 : loss : 0.082079, loss_ce: 0.025801
2021-12-14 02:13:31,625 iteration 1953 : loss : 0.096001, loss_ce: 0.042561
2021-12-14 02:13:33,172 iteration 1954 : loss : 0.071671, loss_ce: 0.019935
2021-12-14 02:13:33,172 Training Data Eval:
2021-12-14 02:13:40,603   Average segmentation loss on training set: 0.0785
2021-12-14 02:13:40,604 Validation Data Eval:
2021-12-14 02:13:43,167   Average segmentation loss on validation set: 0.1041
2021-12-14 02:13:44,736 iteration 1955 : loss : 0.081556, loss_ce: 0.026268
 29%|████████▎                    | 115/400 [54:49<2:21:41, 29.83s/it]2021-12-14 02:13:46,296 iteration 1956 : loss : 0.097259, loss_ce: 0.031692
2021-12-14 02:13:47,879 iteration 1957 : loss : 0.104693, loss_ce: 0.036579
2021-12-14 02:13:49,402 iteration 1958 : loss : 0.106666, loss_ce: 0.021143
2021-12-14 02:13:50,919 iteration 1959 : loss : 0.095633, loss_ce: 0.021875
2021-12-14 02:13:52,317 iteration 1960 : loss : 0.077198, loss_ce: 0.022284
2021-12-14 02:13:53,681 iteration 1961 : loss : 0.073606, loss_ce: 0.021492
2021-12-14 02:13:55,261 iteration 1962 : loss : 0.079188, loss_ce: 0.025111
2021-12-14 02:13:56,709 iteration 1963 : loss : 0.077204, loss_ce: 0.021641
2021-12-14 02:13:58,284 iteration 1964 : loss : 0.086341, loss_ce: 0.020475
2021-12-14 02:13:59,682 iteration 1965 : loss : 0.075925, loss_ce: 0.025138
2021-12-14 02:14:01,190 iteration 1966 : loss : 0.081660, loss_ce: 0.023819
2021-12-14 02:14:02,866 iteration 1967 : loss : 0.086586, loss_ce: 0.025815
2021-12-14 02:14:04,611 iteration 1968 : loss : 0.113333, loss_ce: 0.038860
2021-12-14 02:14:06,196 iteration 1969 : loss : 0.093380, loss_ce: 0.031027
2021-12-14 02:14:07,625 iteration 1970 : loss : 0.073832, loss_ce: 0.023227
2021-12-14 02:14:09,159 iteration 1971 : loss : 0.083921, loss_ce: 0.024243
2021-12-14 02:14:10,694 iteration 1972 : loss : 0.082379, loss_ce: 0.019680
 29%|████████▍                    | 116/400 [55:15<2:15:42, 28.67s/it]2021-12-14 02:14:12,219 iteration 1973 : loss : 0.080224, loss_ce: 0.024533
2021-12-14 02:14:13,683 iteration 1974 : loss : 0.076372, loss_ce: 0.022489
2021-12-14 02:14:15,242 iteration 1975 : loss : 0.081440, loss_ce: 0.025254
2021-12-14 02:14:16,720 iteration 1976 : loss : 0.082689, loss_ce: 0.024642
2021-12-14 02:14:18,312 iteration 1977 : loss : 0.079538, loss_ce: 0.023367
2021-12-14 02:14:19,940 iteration 1978 : loss : 0.103205, loss_ce: 0.032328
2021-12-14 02:14:21,383 iteration 1979 : loss : 0.076623, loss_ce: 0.024711
2021-12-14 02:14:22,829 iteration 1980 : loss : 0.081815, loss_ce: 0.023547
2021-12-14 02:14:24,319 iteration 1981 : loss : 0.085308, loss_ce: 0.029133
2021-12-14 02:14:25,910 iteration 1982 : loss : 0.089761, loss_ce: 0.024592
2021-12-14 02:14:27,338 iteration 1983 : loss : 0.085954, loss_ce: 0.023795
2021-12-14 02:14:28,925 iteration 1984 : loss : 0.096960, loss_ce: 0.032855
2021-12-14 02:14:30,426 iteration 1985 : loss : 0.094253, loss_ce: 0.026381
2021-12-14 02:14:32,009 iteration 1986 : loss : 0.101910, loss_ce: 0.028272
2021-12-14 02:14:33,500 iteration 1987 : loss : 0.078750, loss_ce: 0.023406
2021-12-14 02:14:34,915 iteration 1988 : loss : 0.082524, loss_ce: 0.028406
2021-12-14 02:14:36,426 iteration 1989 : loss : 0.087610, loss_ce: 0.024842
 29%|████████▍                    | 117/400 [55:41<2:11:03, 27.79s/it]2021-12-14 02:14:38,044 iteration 1990 : loss : 0.099611, loss_ce: 0.025147
2021-12-14 02:14:39,478 iteration 1991 : loss : 0.070261, loss_ce: 0.020484
2021-12-14 02:14:41,027 iteration 1992 : loss : 0.080723, loss_ce: 0.023547
2021-12-14 02:14:42,580 iteration 1993 : loss : 0.088074, loss_ce: 0.025796
2021-12-14 02:14:44,180 iteration 1994 : loss : 0.078105, loss_ce: 0.024270
2021-12-14 02:14:45,666 iteration 1995 : loss : 0.070826, loss_ce: 0.021156
2021-12-14 02:14:47,231 iteration 1996 : loss : 0.078233, loss_ce: 0.024031
2021-12-14 02:14:48,686 iteration 1997 : loss : 0.075680, loss_ce: 0.022654
2021-12-14 02:14:50,215 iteration 1998 : loss : 0.093353, loss_ce: 0.028748
2021-12-14 02:14:51,772 iteration 1999 : loss : 0.082006, loss_ce: 0.023638
2021-12-14 02:14:53,285 iteration 2000 : loss : 0.094915, loss_ce: 0.034922
2021-12-14 02:14:54,745 iteration 2001 : loss : 0.108418, loss_ce: 0.029580
2021-12-14 02:14:56,335 iteration 2002 : loss : 0.072443, loss_ce: 0.020690
2021-12-14 02:14:57,784 iteration 2003 : loss : 0.087830, loss_ce: 0.020886
2021-12-14 02:14:59,340 iteration 2004 : loss : 0.086373, loss_ce: 0.029383
2021-12-14 02:15:00,802 iteration 2005 : loss : 0.090496, loss_ce: 0.033222
2021-12-14 02:15:02,303 iteration 2006 : loss : 0.081254, loss_ce: 0.022432
 30%|████████▌                    | 118/400 [56:07<2:07:53, 27.21s/it]2021-12-14 02:15:03,986 iteration 2007 : loss : 0.083896, loss_ce: 0.024462
2021-12-14 02:15:05,570 iteration 2008 : loss : 0.072521, loss_ce: 0.023769
2021-12-14 02:15:07,030 iteration 2009 : loss : 0.080254, loss_ce: 0.026464
2021-12-14 02:15:08,551 iteration 2010 : loss : 0.088804, loss_ce: 0.031092
2021-12-14 02:15:09,987 iteration 2011 : loss : 0.089882, loss_ce: 0.022652
2021-12-14 02:15:11,393 iteration 2012 : loss : 0.072139, loss_ce: 0.021481
2021-12-14 02:15:12,846 iteration 2013 : loss : 0.081040, loss_ce: 0.029635
2021-12-14 02:15:14,388 iteration 2014 : loss : 0.073507, loss_ce: 0.023230
2021-12-14 02:15:15,972 iteration 2015 : loss : 0.088641, loss_ce: 0.023529
2021-12-14 02:15:17,584 iteration 2016 : loss : 0.083749, loss_ce: 0.026129
2021-12-14 02:15:19,129 iteration 2017 : loss : 0.083840, loss_ce: 0.024105
2021-12-14 02:15:20,546 iteration 2018 : loss : 0.074685, loss_ce: 0.018795
2021-12-14 02:15:22,081 iteration 2019 : loss : 0.083275, loss_ce: 0.027513
2021-12-14 02:15:23,578 iteration 2020 : loss : 0.095306, loss_ce: 0.025783
2021-12-14 02:15:25,072 iteration 2021 : loss : 0.073293, loss_ce: 0.018822
2021-12-14 02:15:26,602 iteration 2022 : loss : 0.082379, loss_ce: 0.019173
2021-12-14 02:15:28,143 iteration 2023 : loss : 0.076292, loss_ce: 0.020798
 30%|████████▋                    | 119/400 [56:33<2:05:30, 26.80s/it]2021-12-14 02:15:29,757 iteration 2024 : loss : 0.097472, loss_ce: 0.033200
2021-12-14 02:15:31,496 iteration 2025 : loss : 0.103925, loss_ce: 0.031528
2021-12-14 02:15:32,988 iteration 2026 : loss : 0.085456, loss_ce: 0.020332
2021-12-14 02:15:34,548 iteration 2027 : loss : 0.075369, loss_ce: 0.019904
2021-12-14 02:15:35,929 iteration 2028 : loss : 0.079605, loss_ce: 0.026004
2021-12-14 02:15:37,363 iteration 2029 : loss : 0.085345, loss_ce: 0.020697
2021-12-14 02:15:38,899 iteration 2030 : loss : 0.076613, loss_ce: 0.019916
2021-12-14 02:15:40,437 iteration 2031 : loss : 0.081273, loss_ce: 0.022585
2021-12-14 02:15:41,962 iteration 2032 : loss : 0.086171, loss_ce: 0.028746
2021-12-14 02:15:43,349 iteration 2033 : loss : 0.067426, loss_ce: 0.020365
2021-12-14 02:15:44,806 iteration 2034 : loss : 0.089109, loss_ce: 0.024750
2021-12-14 02:15:46,368 iteration 2035 : loss : 0.089608, loss_ce: 0.027572
2021-12-14 02:15:47,869 iteration 2036 : loss : 0.078254, loss_ce: 0.026156
2021-12-14 02:15:49,315 iteration 2037 : loss : 0.080688, loss_ce: 0.024667
2021-12-14 02:15:50,952 iteration 2038 : loss : 0.110570, loss_ce: 0.029080
2021-12-14 02:15:52,530 iteration 2039 : loss : 0.074125, loss_ce: 0.019101
2021-12-14 02:15:52,530 Training Data Eval:
2021-12-14 02:15:59,959   Average segmentation loss on training set: 0.0692
2021-12-14 02:15:59,959 Validation Data Eval:
2021-12-14 02:16:02,517   Average segmentation loss on validation set: 0.1014
2021-12-14 02:16:04,103 iteration 2040 : loss : 0.082448, loss_ce: 0.030046
 30%|████████▋                    | 120/400 [57:09<2:17:54, 29.55s/it]2021-12-14 02:16:05,634 iteration 2041 : loss : 0.072780, loss_ce: 0.022044
2021-12-14 02:16:07,190 iteration 2042 : loss : 0.084306, loss_ce: 0.025780
2021-12-14 02:16:08,712 iteration 2043 : loss : 0.076635, loss_ce: 0.020840
2021-12-14 02:16:10,201 iteration 2044 : loss : 0.073444, loss_ce: 0.026064
2021-12-14 02:16:11,854 iteration 2045 : loss : 0.088426, loss_ce: 0.028117
2021-12-14 02:16:13,400 iteration 2046 : loss : 0.082266, loss_ce: 0.016528
2021-12-14 02:16:14,872 iteration 2047 : loss : 0.079825, loss_ce: 0.025392
2021-12-14 02:16:16,302 iteration 2048 : loss : 0.076554, loss_ce: 0.024133
2021-12-14 02:16:17,904 iteration 2049 : loss : 0.100165, loss_ce: 0.035921
2021-12-14 02:16:19,475 iteration 2050 : loss : 0.085186, loss_ce: 0.020923
2021-12-14 02:16:20,953 iteration 2051 : loss : 0.086099, loss_ce: 0.030062
2021-12-14 02:16:22,552 iteration 2052 : loss : 0.081892, loss_ce: 0.023253
2021-12-14 02:16:24,105 iteration 2053 : loss : 0.078263, loss_ce: 0.022965
2021-12-14 02:16:25,613 iteration 2054 : loss : 0.090309, loss_ce: 0.026856
2021-12-14 02:16:27,156 iteration 2055 : loss : 0.098871, loss_ce: 0.034129
2021-12-14 02:16:28,653 iteration 2056 : loss : 0.074324, loss_ce: 0.021824
2021-12-14 02:16:30,123 iteration 2057 : loss : 0.068581, loss_ce: 0.020262
 30%|████████▊                    | 121/400 [57:35<2:12:27, 28.49s/it]2021-12-14 02:16:31,669 iteration 2058 : loss : 0.088332, loss_ce: 0.030504
2021-12-14 02:16:33,252 iteration 2059 : loss : 0.087947, loss_ce: 0.023671
2021-12-14 02:16:34,892 iteration 2060 : loss : 0.086247, loss_ce: 0.025947
2021-12-14 02:16:36,401 iteration 2061 : loss : 0.074606, loss_ce: 0.025261
2021-12-14 02:16:37,840 iteration 2062 : loss : 0.093111, loss_ce: 0.028604
2021-12-14 02:16:39,594 iteration 2063 : loss : 0.095549, loss_ce: 0.030120
2021-12-14 02:16:41,125 iteration 2064 : loss : 0.078531, loss_ce: 0.022514
2021-12-14 02:16:42,729 iteration 2065 : loss : 0.107325, loss_ce: 0.031937
2021-12-14 02:16:44,232 iteration 2066 : loss : 0.077717, loss_ce: 0.023425
2021-12-14 02:16:45,817 iteration 2067 : loss : 0.104403, loss_ce: 0.033978
2021-12-14 02:16:47,276 iteration 2068 : loss : 0.069110, loss_ce: 0.019230
2021-12-14 02:16:48,802 iteration 2069 : loss : 0.093430, loss_ce: 0.030955
2021-12-14 02:16:50,394 iteration 2070 : loss : 0.081090, loss_ce: 0.027441
2021-12-14 02:16:51,850 iteration 2071 : loss : 0.065207, loss_ce: 0.018348
2021-12-14 02:16:53,302 iteration 2072 : loss : 0.080750, loss_ce: 0.027384
2021-12-14 02:16:54,881 iteration 2073 : loss : 0.082219, loss_ce: 0.024387
2021-12-14 02:16:56,314 iteration 2074 : loss : 0.078379, loss_ce: 0.018651
 30%|████████▊                    | 122/400 [58:01<2:08:47, 27.80s/it]2021-12-14 02:16:57,872 iteration 2075 : loss : 0.079537, loss_ce: 0.028734
2021-12-14 02:16:59,451 iteration 2076 : loss : 0.077383, loss_ce: 0.025545
2021-12-14 02:17:01,027 iteration 2077 : loss : 0.079125, loss_ce: 0.025611
2021-12-14 02:17:02,618 iteration 2078 : loss : 0.081371, loss_ce: 0.021875
2021-12-14 02:17:04,194 iteration 2079 : loss : 0.092067, loss_ce: 0.027405
2021-12-14 02:17:05,681 iteration 2080 : loss : 0.085671, loss_ce: 0.018603
2021-12-14 02:17:07,111 iteration 2081 : loss : 0.071117, loss_ce: 0.019457
2021-12-14 02:17:08,626 iteration 2082 : loss : 0.094489, loss_ce: 0.021934
2021-12-14 02:17:10,117 iteration 2083 : loss : 0.116867, loss_ce: 0.037436
2021-12-14 02:17:11,563 iteration 2084 : loss : 0.073222, loss_ce: 0.026738
2021-12-14 02:17:13,115 iteration 2085 : loss : 0.105433, loss_ce: 0.016880
2021-12-14 02:17:14,763 iteration 2086 : loss : 0.076731, loss_ce: 0.023250
2021-12-14 02:17:16,196 iteration 2087 : loss : 0.074889, loss_ce: 0.020994
2021-12-14 02:17:17,698 iteration 2088 : loss : 0.074657, loss_ce: 0.023142
2021-12-14 02:17:19,242 iteration 2089 : loss : 0.073587, loss_ce: 0.020513
2021-12-14 02:17:20,756 iteration 2090 : loss : 0.076638, loss_ce: 0.026847
2021-12-14 02:17:22,396 iteration 2091 : loss : 0.093066, loss_ce: 0.029488
 31%|████████▉                    | 123/400 [58:27<2:05:58, 27.29s/it]2021-12-14 02:17:23,959 iteration 2092 : loss : 0.085272, loss_ce: 0.022672
2021-12-14 02:17:25,397 iteration 2093 : loss : 0.070539, loss_ce: 0.021013
2021-12-14 02:17:26,963 iteration 2094 : loss : 0.076271, loss_ce: 0.021105
2021-12-14 02:17:28,717 iteration 2095 : loss : 0.082898, loss_ce: 0.024044
2021-12-14 02:17:30,220 iteration 2096 : loss : 0.071133, loss_ce: 0.021777
2021-12-14 02:17:31,722 iteration 2097 : loss : 0.106862, loss_ce: 0.028210
2021-12-14 02:17:33,153 iteration 2098 : loss : 0.072939, loss_ce: 0.020826
2021-12-14 02:17:34,639 iteration 2099 : loss : 0.068465, loss_ce: 0.020299
2021-12-14 02:17:36,221 iteration 2100 : loss : 0.086614, loss_ce: 0.027523
2021-12-14 02:17:37,608 iteration 2101 : loss : 0.073800, loss_ce: 0.017268
2021-12-14 02:17:39,162 iteration 2102 : loss : 0.079464, loss_ce: 0.027029
2021-12-14 02:17:40,611 iteration 2103 : loss : 0.082128, loss_ce: 0.031048
2021-12-14 02:17:42,013 iteration 2104 : loss : 0.074190, loss_ce: 0.020083
2021-12-14 02:17:43,540 iteration 2105 : loss : 0.088472, loss_ce: 0.030023
2021-12-14 02:17:45,076 iteration 2106 : loss : 0.079751, loss_ce: 0.022849
2021-12-14 02:17:46,536 iteration 2107 : loss : 0.080104, loss_ce: 0.022972
2021-12-14 02:17:47,967 iteration 2108 : loss : 0.078866, loss_ce: 0.025030
 31%|████████▉                    | 124/400 [58:53<2:03:09, 26.77s/it]2021-12-14 02:17:49,537 iteration 2109 : loss : 0.100653, loss_ce: 0.025182
2021-12-14 02:17:51,084 iteration 2110 : loss : 0.083535, loss_ce: 0.025711
2021-12-14 02:17:52,679 iteration 2111 : loss : 0.073016, loss_ce: 0.020285
2021-12-14 02:17:54,335 iteration 2112 : loss : 0.078104, loss_ce: 0.023471
2021-12-14 02:17:55,925 iteration 2113 : loss : 0.076684, loss_ce: 0.018865
2021-12-14 02:17:57,498 iteration 2114 : loss : 0.091183, loss_ce: 0.022551
2021-12-14 02:17:58,955 iteration 2115 : loss : 0.073088, loss_ce: 0.017601
2021-12-14 02:18:00,415 iteration 2116 : loss : 0.078177, loss_ce: 0.020736
2021-12-14 02:18:02,064 iteration 2117 : loss : 0.081825, loss_ce: 0.019605
2021-12-14 02:18:03,608 iteration 2118 : loss : 0.076898, loss_ce: 0.023724
2021-12-14 02:18:05,294 iteration 2119 : loss : 0.108316, loss_ce: 0.031833
2021-12-14 02:18:06,893 iteration 2120 : loss : 0.074039, loss_ce: 0.027486
2021-12-14 02:18:08,507 iteration 2121 : loss : 0.087751, loss_ce: 0.031127
2021-12-14 02:18:10,112 iteration 2122 : loss : 0.118327, loss_ce: 0.047527
2021-12-14 02:18:11,554 iteration 2123 : loss : 0.090463, loss_ce: 0.023621
2021-12-14 02:18:13,161 iteration 2124 : loss : 0.085800, loss_ce: 0.028470
2021-12-14 02:18:13,161 Training Data Eval:
2021-12-14 02:18:20,583   Average segmentation loss on training set: 0.0717
2021-12-14 02:18:20,583 Validation Data Eval:
2021-12-14 02:18:23,153   Average segmentation loss on validation set: 0.0960
2021-12-14 02:18:29,073 Found new lowest validation loss at iteration 2124! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 02:18:30,570 iteration 2125 : loss : 0.075876, loss_ce: 0.026095
 31%|█████████                    | 125/400 [59:35<2:24:28, 31.52s/it]2021-12-14 02:18:32,211 iteration 2126 : loss : 0.096748, loss_ce: 0.025376
2021-12-14 02:18:33,643 iteration 2127 : loss : 0.072126, loss_ce: 0.023563
2021-12-14 02:18:35,064 iteration 2128 : loss : 0.067246, loss_ce: 0.020976
2021-12-14 02:18:36,669 iteration 2129 : loss : 0.080734, loss_ce: 0.026609
2021-12-14 02:18:38,179 iteration 2130 : loss : 0.088330, loss_ce: 0.028497
2021-12-14 02:18:39,636 iteration 2131 : loss : 0.077570, loss_ce: 0.023068
2021-12-14 02:18:41,179 iteration 2132 : loss : 0.080568, loss_ce: 0.019941
2021-12-14 02:18:42,694 iteration 2133 : loss : 0.097374, loss_ce: 0.034483
2021-12-14 02:18:44,321 iteration 2134 : loss : 0.090767, loss_ce: 0.026127
2021-12-14 02:18:45,748 iteration 2135 : loss : 0.081437, loss_ce: 0.020232
2021-12-14 02:18:47,335 iteration 2136 : loss : 0.101568, loss_ce: 0.034261
2021-12-14 02:18:48,850 iteration 2137 : loss : 0.073315, loss_ce: 0.021957
2021-12-14 02:18:50,489 iteration 2138 : loss : 0.100649, loss_ce: 0.028151
2021-12-14 02:18:51,968 iteration 2139 : loss : 0.071962, loss_ce: 0.024894
2021-12-14 02:18:53,551 iteration 2140 : loss : 0.094015, loss_ce: 0.039027
2021-12-14 02:18:55,128 iteration 2141 : loss : 0.081390, loss_ce: 0.023825
2021-12-14 02:18:56,704 iteration 2142 : loss : 0.095200, loss_ce: 0.025379
 32%|████████▌                  | 126/400 [1:00:01<2:16:34, 29.91s/it]2021-12-14 02:18:58,291 iteration 2143 : loss : 0.090839, loss_ce: 0.035733
2021-12-14 02:18:59,841 iteration 2144 : loss : 0.074687, loss_ce: 0.022477
2021-12-14 02:19:01,363 iteration 2145 : loss : 0.075984, loss_ce: 0.021746
2021-12-14 02:19:02,841 iteration 2146 : loss : 0.078252, loss_ce: 0.022350
2021-12-14 02:19:04,276 iteration 2147 : loss : 0.074528, loss_ce: 0.020765
2021-12-14 02:19:05,788 iteration 2148 : loss : 0.069358, loss_ce: 0.019817
2021-12-14 02:19:07,392 iteration 2149 : loss : 0.084633, loss_ce: 0.022214
2021-12-14 02:19:08,869 iteration 2150 : loss : 0.072427, loss_ce: 0.020488
2021-12-14 02:19:10,377 iteration 2151 : loss : 0.081309, loss_ce: 0.023556
2021-12-14 02:19:11,838 iteration 2152 : loss : 0.073924, loss_ce: 0.026720
2021-12-14 02:19:13,335 iteration 2153 : loss : 0.078425, loss_ce: 0.018069
2021-12-14 02:19:14,845 iteration 2154 : loss : 0.071797, loss_ce: 0.018061
2021-12-14 02:19:16,407 iteration 2155 : loss : 0.086316, loss_ce: 0.031536
2021-12-14 02:19:17,841 iteration 2156 : loss : 0.073279, loss_ce: 0.020260
2021-12-14 02:19:19,477 iteration 2157 : loss : 0.083464, loss_ce: 0.026658
2021-12-14 02:19:21,088 iteration 2158 : loss : 0.073783, loss_ce: 0.018801
2021-12-14 02:19:22,671 iteration 2159 : loss : 0.080355, loss_ce: 0.022862
 32%|████████▌                  | 127/400 [1:00:27<2:10:39, 28.72s/it]2021-12-14 02:19:24,254 iteration 2160 : loss : 0.078392, loss_ce: 0.022484
2021-12-14 02:19:25,885 iteration 2161 : loss : 0.103275, loss_ce: 0.037795
2021-12-14 02:19:27,508 iteration 2162 : loss : 0.080879, loss_ce: 0.022944
2021-12-14 02:19:28,959 iteration 2163 : loss : 0.086513, loss_ce: 0.024991
2021-12-14 02:19:30,541 iteration 2164 : loss : 0.088402, loss_ce: 0.026658
2021-12-14 02:19:32,110 iteration 2165 : loss : 0.081357, loss_ce: 0.027085
2021-12-14 02:19:33,674 iteration 2166 : loss : 0.083617, loss_ce: 0.020104
2021-12-14 02:19:35,310 iteration 2167 : loss : 0.062657, loss_ce: 0.015035
2021-12-14 02:19:36,853 iteration 2168 : loss : 0.087825, loss_ce: 0.028344
2021-12-14 02:19:38,386 iteration 2169 : loss : 0.068114, loss_ce: 0.018445
2021-12-14 02:19:39,847 iteration 2170 : loss : 0.084653, loss_ce: 0.030684
2021-12-14 02:19:41,440 iteration 2171 : loss : 0.081208, loss_ce: 0.021807
2021-12-14 02:19:43,108 iteration 2172 : loss : 0.075563, loss_ce: 0.017698
2021-12-14 02:19:44,574 iteration 2173 : loss : 0.072136, loss_ce: 0.020037
2021-12-14 02:19:45,983 iteration 2174 : loss : 0.076922, loss_ce: 0.028197
2021-12-14 02:19:47,432 iteration 2175 : loss : 0.064992, loss_ce: 0.017932
2021-12-14 02:19:49,085 iteration 2176 : loss : 0.082940, loss_ce: 0.025813
 32%|████████▋                  | 128/400 [1:00:54<2:07:05, 28.03s/it]2021-12-14 02:19:50,709 iteration 2177 : loss : 0.075397, loss_ce: 0.020396
2021-12-14 02:19:52,335 iteration 2178 : loss : 0.073478, loss_ce: 0.022799
2021-12-14 02:19:53,850 iteration 2179 : loss : 0.076522, loss_ce: 0.027935
2021-12-14 02:19:55,351 iteration 2180 : loss : 0.077254, loss_ce: 0.023420
2021-12-14 02:19:56,923 iteration 2181 : loss : 0.084200, loss_ce: 0.029821
2021-12-14 02:19:58,432 iteration 2182 : loss : 0.074408, loss_ce: 0.015911
2021-12-14 02:19:59,856 iteration 2183 : loss : 0.079388, loss_ce: 0.027231
2021-12-14 02:20:01,467 iteration 2184 : loss : 0.071437, loss_ce: 0.016278
2021-12-14 02:20:02,929 iteration 2185 : loss : 0.074853, loss_ce: 0.020878
2021-12-14 02:20:04,419 iteration 2186 : loss : 0.082123, loss_ce: 0.021674
2021-12-14 02:20:05,932 iteration 2187 : loss : 0.062364, loss_ce: 0.017099
2021-12-14 02:20:07,397 iteration 2188 : loss : 0.082377, loss_ce: 0.021189
2021-12-14 02:20:09,010 iteration 2189 : loss : 0.083476, loss_ce: 0.027902
2021-12-14 02:20:10,521 iteration 2190 : loss : 0.088258, loss_ce: 0.025216
2021-12-14 02:20:12,080 iteration 2191 : loss : 0.100788, loss_ce: 0.028244
2021-12-14 02:20:13,566 iteration 2192 : loss : 0.069926, loss_ce: 0.017384
2021-12-14 02:20:15,090 iteration 2193 : loss : 0.087256, loss_ce: 0.028282
 32%|████████▋                  | 129/400 [1:01:20<2:03:51, 27.42s/it]2021-12-14 02:20:16,738 iteration 2194 : loss : 0.081479, loss_ce: 0.031878
2021-12-14 02:20:18,231 iteration 2195 : loss : 0.098878, loss_ce: 0.023416
2021-12-14 02:20:19,745 iteration 2196 : loss : 0.074999, loss_ce: 0.021037
2021-12-14 02:20:21,308 iteration 2197 : loss : 0.081504, loss_ce: 0.031435
2021-12-14 02:20:22,858 iteration 2198 : loss : 0.072624, loss_ce: 0.023266
2021-12-14 02:20:24,391 iteration 2199 : loss : 0.078031, loss_ce: 0.025475
2021-12-14 02:20:25,892 iteration 2200 : loss : 0.083476, loss_ce: 0.022121
2021-12-14 02:20:27,360 iteration 2201 : loss : 0.072344, loss_ce: 0.022176
2021-12-14 02:20:28,943 iteration 2202 : loss : 0.107534, loss_ce: 0.020966
2021-12-14 02:20:30,550 iteration 2203 : loss : 0.089092, loss_ce: 0.036580
2021-12-14 02:20:32,037 iteration 2204 : loss : 0.075794, loss_ce: 0.027276
2021-12-14 02:20:33,447 iteration 2205 : loss : 0.069319, loss_ce: 0.021923
2021-12-14 02:20:34,863 iteration 2206 : loss : 0.077501, loss_ce: 0.016946
2021-12-14 02:20:36,311 iteration 2207 : loss : 0.081996, loss_ce: 0.022428
2021-12-14 02:20:37,854 iteration 2208 : loss : 0.070853, loss_ce: 0.017257
2021-12-14 02:20:39,351 iteration 2209 : loss : 0.069391, loss_ce: 0.019518
2021-12-14 02:20:39,351 Training Data Eval:
2021-12-14 02:20:46,776   Average segmentation loss on training set: 0.0628
2021-12-14 02:20:46,776 Validation Data Eval:
2021-12-14 02:20:49,334   Average segmentation loss on validation set: 0.1023
2021-12-14 02:20:50,855 iteration 2210 : loss : 0.079047, loss_ce: 0.021208
 32%|████████▊                  | 130/400 [1:01:56<2:14:40, 29.93s/it]2021-12-14 02:20:52,471 iteration 2211 : loss : 0.081948, loss_ce: 0.022213
2021-12-14 02:20:54,039 iteration 2212 : loss : 0.072501, loss_ce: 0.024121
2021-12-14 02:20:55,617 iteration 2213 : loss : 0.081058, loss_ce: 0.025229
2021-12-14 02:20:57,165 iteration 2214 : loss : 0.072980, loss_ce: 0.018241
2021-12-14 02:20:58,756 iteration 2215 : loss : 0.082127, loss_ce: 0.028250
2021-12-14 02:21:00,196 iteration 2216 : loss : 0.077758, loss_ce: 0.018531
2021-12-14 02:21:01,794 iteration 2217 : loss : 0.079061, loss_ce: 0.024916
2021-12-14 02:21:03,250 iteration 2218 : loss : 0.094234, loss_ce: 0.027486
2021-12-14 02:21:04,844 iteration 2219 : loss : 0.069666, loss_ce: 0.018941
2021-12-14 02:21:06,239 iteration 2220 : loss : 0.090904, loss_ce: 0.020079
2021-12-14 02:21:07,703 iteration 2221 : loss : 0.076283, loss_ce: 0.021438
2021-12-14 02:21:09,298 iteration 2222 : loss : 0.079328, loss_ce: 0.027898
2021-12-14 02:21:10,844 iteration 2223 : loss : 0.086904, loss_ce: 0.024343
2021-12-14 02:21:12,464 iteration 2224 : loss : 0.083012, loss_ce: 0.032410
2021-12-14 02:21:13,901 iteration 2225 : loss : 0.067205, loss_ce: 0.019831
2021-12-14 02:21:15,530 iteration 2226 : loss : 0.078956, loss_ce: 0.026901
2021-12-14 02:21:17,030 iteration 2227 : loss : 0.087824, loss_ce: 0.026207
 33%|████████▊                  | 131/400 [1:02:22<2:09:06, 28.80s/it]2021-12-14 02:21:18,686 iteration 2228 : loss : 0.073497, loss_ce: 0.026273
2021-12-14 02:21:20,220 iteration 2229 : loss : 0.078419, loss_ce: 0.023295
2021-12-14 02:21:21,814 iteration 2230 : loss : 0.083623, loss_ce: 0.025561
2021-12-14 02:21:23,204 iteration 2231 : loss : 0.063759, loss_ce: 0.018021
2021-12-14 02:21:24,664 iteration 2232 : loss : 0.080151, loss_ce: 0.026326
2021-12-14 02:21:26,147 iteration 2233 : loss : 0.090348, loss_ce: 0.029148
2021-12-14 02:21:27,637 iteration 2234 : loss : 0.086414, loss_ce: 0.024613
2021-12-14 02:21:29,122 iteration 2235 : loss : 0.101669, loss_ce: 0.016491
2021-12-14 02:21:30,821 iteration 2236 : loss : 0.107864, loss_ce: 0.032670
2021-12-14 02:21:32,352 iteration 2237 : loss : 0.075143, loss_ce: 0.024512
2021-12-14 02:21:33,886 iteration 2238 : loss : 0.083016, loss_ce: 0.032536
2021-12-14 02:21:35,418 iteration 2239 : loss : 0.078409, loss_ce: 0.022859
2021-12-14 02:21:36,993 iteration 2240 : loss : 0.076956, loss_ce: 0.022194
2021-12-14 02:21:38,591 iteration 2241 : loss : 0.075483, loss_ce: 0.018531
2021-12-14 02:21:40,199 iteration 2242 : loss : 0.073468, loss_ce: 0.023200
2021-12-14 02:21:41,869 iteration 2243 : loss : 0.086005, loss_ce: 0.021700
2021-12-14 02:21:43,385 iteration 2244 : loss : 0.075884, loss_ce: 0.026772
 33%|████████▉                  | 132/400 [1:02:48<2:05:21, 28.06s/it]2021-12-14 02:21:45,097 iteration 2245 : loss : 0.082861, loss_ce: 0.025791
2021-12-14 02:21:46,609 iteration 2246 : loss : 0.065372, loss_ce: 0.018118
2021-12-14 02:21:48,280 iteration 2247 : loss : 0.113228, loss_ce: 0.028341
2021-12-14 02:21:49,867 iteration 2248 : loss : 0.076051, loss_ce: 0.023334
2021-12-14 02:21:51,408 iteration 2249 : loss : 0.072791, loss_ce: 0.019425
2021-12-14 02:21:52,924 iteration 2250 : loss : 0.090597, loss_ce: 0.027449
2021-12-14 02:21:54,354 iteration 2251 : loss : 0.079380, loss_ce: 0.023454
2021-12-14 02:21:56,020 iteration 2252 : loss : 0.087770, loss_ce: 0.021690
2021-12-14 02:21:57,657 iteration 2253 : loss : 0.083303, loss_ce: 0.028338
2021-12-14 02:21:59,171 iteration 2254 : loss : 0.077662, loss_ce: 0.026594
2021-12-14 02:22:00,645 iteration 2255 : loss : 0.075098, loss_ce: 0.019407
2021-12-14 02:22:02,197 iteration 2256 : loss : 0.080771, loss_ce: 0.025424
2021-12-14 02:22:03,706 iteration 2257 : loss : 0.078136, loss_ce: 0.025503
2021-12-14 02:22:05,142 iteration 2258 : loss : 0.067814, loss_ce: 0.021179
2021-12-14 02:22:06,766 iteration 2259 : loss : 0.064116, loss_ce: 0.017929
2021-12-14 02:22:08,251 iteration 2260 : loss : 0.077731, loss_ce: 0.021879
2021-12-14 02:22:09,821 iteration 2261 : loss : 0.082898, loss_ce: 0.025921
 33%|████████▉                  | 133/400 [1:03:15<2:02:42, 27.57s/it]2021-12-14 02:22:11,436 iteration 2262 : loss : 0.094356, loss_ce: 0.030917
2021-12-14 02:22:12,971 iteration 2263 : loss : 0.075162, loss_ce: 0.024533
2021-12-14 02:22:14,562 iteration 2264 : loss : 0.090073, loss_ce: 0.028185
2021-12-14 02:22:16,086 iteration 2265 : loss : 0.064175, loss_ce: 0.016979
2021-12-14 02:22:17,600 iteration 2266 : loss : 0.074302, loss_ce: 0.016891
2021-12-14 02:22:19,017 iteration 2267 : loss : 0.062281, loss_ce: 0.018249
2021-12-14 02:22:20,516 iteration 2268 : loss : 0.071809, loss_ce: 0.024658
2021-12-14 02:22:21,980 iteration 2269 : loss : 0.076659, loss_ce: 0.027195
2021-12-14 02:22:23,414 iteration 2270 : loss : 0.061321, loss_ce: 0.016231
2021-12-14 02:22:24,919 iteration 2271 : loss : 0.100803, loss_ce: 0.031625
2021-12-14 02:22:26,519 iteration 2272 : loss : 0.073501, loss_ce: 0.020382
2021-12-14 02:22:28,113 iteration 2273 : loss : 0.072566, loss_ce: 0.018267
2021-12-14 02:22:29,629 iteration 2274 : loss : 0.083131, loss_ce: 0.027421
2021-12-14 02:22:31,134 iteration 2275 : loss : 0.080772, loss_ce: 0.020833
2021-12-14 02:22:32,581 iteration 2276 : loss : 0.074568, loss_ce: 0.025233
2021-12-14 02:22:34,071 iteration 2277 : loss : 0.065526, loss_ce: 0.013995
2021-12-14 02:22:35,614 iteration 2278 : loss : 0.076501, loss_ce: 0.021458
 34%|█████████                  | 134/400 [1:03:40<1:59:53, 27.04s/it]2021-12-14 02:22:37,104 iteration 2279 : loss : 0.068651, loss_ce: 0.020100
2021-12-14 02:22:38,532 iteration 2280 : loss : 0.080039, loss_ce: 0.027717
2021-12-14 02:22:40,051 iteration 2281 : loss : 0.093816, loss_ce: 0.026555
2021-12-14 02:22:41,482 iteration 2282 : loss : 0.088925, loss_ce: 0.027254
2021-12-14 02:22:43,015 iteration 2283 : loss : 0.100199, loss_ce: 0.026027
2021-12-14 02:22:44,427 iteration 2284 : loss : 0.077342, loss_ce: 0.025372
2021-12-14 02:22:45,994 iteration 2285 : loss : 0.076741, loss_ce: 0.026000
2021-12-14 02:22:47,486 iteration 2286 : loss : 0.098492, loss_ce: 0.035897
2021-12-14 02:22:48,987 iteration 2287 : loss : 0.065741, loss_ce: 0.013272
2021-12-14 02:22:50,500 iteration 2288 : loss : 0.082674, loss_ce: 0.020699
2021-12-14 02:22:52,048 iteration 2289 : loss : 0.091182, loss_ce: 0.026722
2021-12-14 02:22:53,575 iteration 2290 : loss : 0.089903, loss_ce: 0.026388
2021-12-14 02:22:55,229 iteration 2291 : loss : 0.087555, loss_ce: 0.031224
2021-12-14 02:22:56,800 iteration 2292 : loss : 0.069621, loss_ce: 0.020200
2021-12-14 02:22:58,340 iteration 2293 : loss : 0.078063, loss_ce: 0.024078
2021-12-14 02:22:59,821 iteration 2294 : loss : 0.077683, loss_ce: 0.031303
2021-12-14 02:22:59,822 Training Data Eval:
2021-12-14 02:23:07,264   Average segmentation loss on training set: 0.0705
2021-12-14 02:23:07,264 Validation Data Eval:
2021-12-14 02:23:09,834   Average segmentation loss on validation set: 0.0963
2021-12-14 02:23:11,361 iteration 2295 : loss : 0.077598, loss_ce: 0.019651
 34%|█████████                  | 135/400 [1:04:16<2:10:57, 29.65s/it]2021-12-14 02:23:12,858 iteration 2296 : loss : 0.073731, loss_ce: 0.023902
2021-12-14 02:23:14,444 iteration 2297 : loss : 0.071389, loss_ce: 0.019802
2021-12-14 02:23:15,985 iteration 2298 : loss : 0.072757, loss_ce: 0.021025
2021-12-14 02:23:17,571 iteration 2299 : loss : 0.084464, loss_ce: 0.022787
2021-12-14 02:23:19,062 iteration 2300 : loss : 0.072423, loss_ce: 0.023377
2021-12-14 02:23:20,593 iteration 2301 : loss : 0.069839, loss_ce: 0.021651
2021-12-14 02:23:22,177 iteration 2302 : loss : 0.081980, loss_ce: 0.024313
2021-12-14 02:23:23,737 iteration 2303 : loss : 0.087945, loss_ce: 0.023176
2021-12-14 02:23:25,288 iteration 2304 : loss : 0.086856, loss_ce: 0.029707
2021-12-14 02:23:26,797 iteration 2305 : loss : 0.073668, loss_ce: 0.023799
2021-12-14 02:23:28,297 iteration 2306 : loss : 0.072633, loss_ce: 0.022156
2021-12-14 02:23:29,902 iteration 2307 : loss : 0.075958, loss_ce: 0.021631
2021-12-14 02:23:31,364 iteration 2308 : loss : 0.077273, loss_ce: 0.024689
2021-12-14 02:23:32,959 iteration 2309 : loss : 0.087430, loss_ce: 0.028457
2021-12-14 02:23:34,521 iteration 2310 : loss : 0.092187, loss_ce: 0.032223
2021-12-14 02:23:35,995 iteration 2311 : loss : 0.078476, loss_ce: 0.021366
2021-12-14 02:23:37,430 iteration 2312 : loss : 0.068861, loss_ce: 0.019017
 34%|█████████▏                 | 136/400 [1:04:42<2:05:44, 28.58s/it]2021-12-14 02:23:38,998 iteration 2313 : loss : 0.078473, loss_ce: 0.021933
2021-12-14 02:23:40,542 iteration 2314 : loss : 0.077112, loss_ce: 0.019599
2021-12-14 02:23:42,179 iteration 2315 : loss : 0.071694, loss_ce: 0.015919
2021-12-14 02:23:43,611 iteration 2316 : loss : 0.072528, loss_ce: 0.022579
2021-12-14 02:23:45,216 iteration 2317 : loss : 0.081193, loss_ce: 0.021619
2021-12-14 02:23:46,766 iteration 2318 : loss : 0.071598, loss_ce: 0.022272
2021-12-14 02:23:48,305 iteration 2319 : loss : 0.072661, loss_ce: 0.022590
2021-12-14 02:23:49,921 iteration 2320 : loss : 0.067725, loss_ce: 0.022899
2021-12-14 02:23:51,372 iteration 2321 : loss : 0.092836, loss_ce: 0.025553
2021-12-14 02:23:52,882 iteration 2322 : loss : 0.085558, loss_ce: 0.028798
2021-12-14 02:23:54,389 iteration 2323 : loss : 0.078917, loss_ce: 0.027758
2021-12-14 02:23:55,933 iteration 2324 : loss : 0.069200, loss_ce: 0.016047
2021-12-14 02:23:57,416 iteration 2325 : loss : 0.081390, loss_ce: 0.027437
2021-12-14 02:23:58,965 iteration 2326 : loss : 0.077335, loss_ce: 0.029069
2021-12-14 02:24:00,469 iteration 2327 : loss : 0.072941, loss_ce: 0.021024
2021-12-14 02:24:02,037 iteration 2328 : loss : 0.087184, loss_ce: 0.033077
2021-12-14 02:24:03,528 iteration 2329 : loss : 0.065988, loss_ce: 0.020051
 34%|█████████▏                 | 137/400 [1:05:08<2:02:00, 27.83s/it]2021-12-14 02:24:05,082 iteration 2330 : loss : 0.068137, loss_ce: 0.019644
2021-12-14 02:24:06,588 iteration 2331 : loss : 0.083006, loss_ce: 0.029435
2021-12-14 02:24:08,172 iteration 2332 : loss : 0.090985, loss_ce: 0.030664
2021-12-14 02:24:09,792 iteration 2333 : loss : 0.079419, loss_ce: 0.029754
2021-12-14 02:24:11,289 iteration 2334 : loss : 0.068575, loss_ce: 0.021788
2021-12-14 02:24:12,785 iteration 2335 : loss : 0.082125, loss_ce: 0.020850
2021-12-14 02:24:14,366 iteration 2336 : loss : 0.103701, loss_ce: 0.024665
2021-12-14 02:24:15,944 iteration 2337 : loss : 0.075240, loss_ce: 0.025224
2021-12-14 02:24:17,439 iteration 2338 : loss : 0.071997, loss_ce: 0.021663
2021-12-14 02:24:18,996 iteration 2339 : loss : 0.075003, loss_ce: 0.021889
2021-12-14 02:24:20,600 iteration 2340 : loss : 0.087866, loss_ce: 0.034540
2021-12-14 02:24:22,033 iteration 2341 : loss : 0.070182, loss_ce: 0.015316
2021-12-14 02:24:23,556 iteration 2342 : loss : 0.071840, loss_ce: 0.021883
2021-12-14 02:24:25,166 iteration 2343 : loss : 0.087623, loss_ce: 0.027653
2021-12-14 02:24:26,745 iteration 2344 : loss : 0.076051, loss_ce: 0.023778
2021-12-14 02:24:28,349 iteration 2345 : loss : 0.067045, loss_ce: 0.016610
2021-12-14 02:24:29,881 iteration 2346 : loss : 0.067460, loss_ce: 0.021958
 34%|█████████▎                 | 138/400 [1:05:35<1:59:36, 27.39s/it]2021-12-14 02:24:31,473 iteration 2347 : loss : 0.076024, loss_ce: 0.019906
2021-12-14 02:24:32,984 iteration 2348 : loss : 0.070625, loss_ce: 0.020541
2021-12-14 02:24:34,589 iteration 2349 : loss : 0.072854, loss_ce: 0.022486
2021-12-14 02:24:36,088 iteration 2350 : loss : 0.069652, loss_ce: 0.019695
2021-12-14 02:24:37,638 iteration 2351 : loss : 0.102290, loss_ce: 0.015079
2021-12-14 02:24:39,185 iteration 2352 : loss : 0.081247, loss_ce: 0.021445
2021-12-14 02:24:40,778 iteration 2353 : loss : 0.076892, loss_ce: 0.024095
2021-12-14 02:24:42,393 iteration 2354 : loss : 0.085820, loss_ce: 0.024736
2021-12-14 02:24:43,824 iteration 2355 : loss : 0.073159, loss_ce: 0.021934
2021-12-14 02:24:45,360 iteration 2356 : loss : 0.062562, loss_ce: 0.017797
2021-12-14 02:24:46,869 iteration 2357 : loss : 0.071255, loss_ce: 0.019876
2021-12-14 02:24:48,422 iteration 2358 : loss : 0.078053, loss_ce: 0.029309
2021-12-14 02:24:50,118 iteration 2359 : loss : 0.077037, loss_ce: 0.023428
2021-12-14 02:24:51,616 iteration 2360 : loss : 0.072893, loss_ce: 0.024103
2021-12-14 02:24:53,194 iteration 2361 : loss : 0.071774, loss_ce: 0.019521
2021-12-14 02:24:54,858 iteration 2362 : loss : 0.086868, loss_ce: 0.031217
2021-12-14 02:24:56,308 iteration 2363 : loss : 0.064618, loss_ce: 0.021373
 35%|█████████▍                 | 139/400 [1:06:01<1:57:53, 27.10s/it]2021-12-14 02:24:57,801 iteration 2364 : loss : 0.103858, loss_ce: 0.019573
2021-12-14 02:24:59,269 iteration 2365 : loss : 0.078895, loss_ce: 0.015826
2021-12-14 02:25:00,825 iteration 2366 : loss : 0.084982, loss_ce: 0.028158
2021-12-14 02:25:02,333 iteration 2367 : loss : 0.078274, loss_ce: 0.029288
2021-12-14 02:25:03,815 iteration 2368 : loss : 0.070510, loss_ce: 0.020204
2021-12-14 02:25:05,356 iteration 2369 : loss : 0.078924, loss_ce: 0.024359
2021-12-14 02:25:06,783 iteration 2370 : loss : 0.094622, loss_ce: 0.029925
2021-12-14 02:25:08,367 iteration 2371 : loss : 0.076378, loss_ce: 0.024022
2021-12-14 02:25:09,875 iteration 2372 : loss : 0.073703, loss_ce: 0.024887
2021-12-14 02:25:11,332 iteration 2373 : loss : 0.071796, loss_ce: 0.021734
2021-12-14 02:25:12,813 iteration 2374 : loss : 0.066661, loss_ce: 0.020169
2021-12-14 02:25:14,372 iteration 2375 : loss : 0.085559, loss_ce: 0.020726
2021-12-14 02:25:15,947 iteration 2376 : loss : 0.083282, loss_ce: 0.023634
2021-12-14 02:25:17,453 iteration 2377 : loss : 0.069400, loss_ce: 0.019857
2021-12-14 02:25:18,959 iteration 2378 : loss : 0.061132, loss_ce: 0.016993
2021-12-14 02:25:20,493 iteration 2379 : loss : 0.088184, loss_ce: 0.035666
2021-12-14 02:25:20,493 Training Data Eval:
2021-12-14 02:25:27,912   Average segmentation loss on training set: 0.0663
2021-12-14 02:25:27,912 Validation Data Eval:
2021-12-14 02:25:30,476   Average segmentation loss on validation set: 0.0973
2021-12-14 02:25:31,925 iteration 2380 : loss : 0.066174, loss_ce: 0.024006
 35%|█████████▍                 | 140/400 [1:06:37<2:08:30, 29.66s/it]2021-12-14 02:25:33,625 iteration 2381 : loss : 0.075134, loss_ce: 0.018889
2021-12-14 02:25:35,182 iteration 2382 : loss : 0.094188, loss_ce: 0.029776
2021-12-14 02:25:36,705 iteration 2383 : loss : 0.081870, loss_ce: 0.028743
2021-12-14 02:25:38,161 iteration 2384 : loss : 0.071096, loss_ce: 0.019677
2021-12-14 02:25:39,687 iteration 2385 : loss : 0.080146, loss_ce: 0.023656
2021-12-14 02:25:41,288 iteration 2386 : loss : 0.076514, loss_ce: 0.017270
2021-12-14 02:25:42,885 iteration 2387 : loss : 0.073530, loss_ce: 0.023203
2021-12-14 02:25:44,445 iteration 2388 : loss : 0.074724, loss_ce: 0.027235
2021-12-14 02:25:45,976 iteration 2389 : loss : 0.074976, loss_ce: 0.022291
2021-12-14 02:25:47,448 iteration 2390 : loss : 0.066285, loss_ce: 0.018795
2021-12-14 02:25:48,876 iteration 2391 : loss : 0.072957, loss_ce: 0.021764
2021-12-14 02:25:50,576 iteration 2392 : loss : 0.092251, loss_ce: 0.019344
2021-12-14 02:25:52,187 iteration 2393 : loss : 0.077223, loss_ce: 0.022670
2021-12-14 02:25:53,724 iteration 2394 : loss : 0.081910, loss_ce: 0.025674
2021-12-14 02:25:55,340 iteration 2395 : loss : 0.079153, loss_ce: 0.026480
2021-12-14 02:25:56,796 iteration 2396 : loss : 0.077364, loss_ce: 0.027525
2021-12-14 02:25:58,406 iteration 2397 : loss : 0.071844, loss_ce: 0.028303
 35%|█████████▌                 | 141/400 [1:07:03<2:03:54, 28.71s/it]2021-12-14 02:25:59,965 iteration 2398 : loss : 0.067351, loss_ce: 0.023507
2021-12-14 02:26:01,611 iteration 2399 : loss : 0.072852, loss_ce: 0.023805
2021-12-14 02:26:03,114 iteration 2400 : loss : 0.078267, loss_ce: 0.024224
2021-12-14 02:26:04,820 iteration 2401 : loss : 0.085252, loss_ce: 0.024401
2021-12-14 02:26:06,348 iteration 2402 : loss : 0.084830, loss_ce: 0.025580
2021-12-14 02:26:07,839 iteration 2403 : loss : 0.070418, loss_ce: 0.020366
2021-12-14 02:26:09,318 iteration 2404 : loss : 0.076568, loss_ce: 0.021748
2021-12-14 02:26:10,912 iteration 2405 : loss : 0.075874, loss_ce: 0.022557
2021-12-14 02:26:12,351 iteration 2406 : loss : 0.098368, loss_ce: 0.038769
2021-12-14 02:26:13,843 iteration 2407 : loss : 0.078633, loss_ce: 0.023781
2021-12-14 02:26:15,568 iteration 2408 : loss : 0.081552, loss_ce: 0.023064
2021-12-14 02:26:17,040 iteration 2409 : loss : 0.065251, loss_ce: 0.018405
2021-12-14 02:26:18,522 iteration 2410 : loss : 0.067212, loss_ce: 0.020044
2021-12-14 02:26:19,995 iteration 2411 : loss : 0.072967, loss_ce: 0.023056
2021-12-14 02:26:21,484 iteration 2412 : loss : 0.070628, loss_ce: 0.020367
2021-12-14 02:26:22,949 iteration 2413 : loss : 0.072488, loss_ce: 0.021942
2021-12-14 02:26:24,383 iteration 2414 : loss : 0.066374, loss_ce: 0.021985
 36%|█████████▌                 | 142/400 [1:07:29<1:59:53, 27.88s/it]2021-12-14 02:26:26,024 iteration 2415 : loss : 0.070846, loss_ce: 0.019320
2021-12-14 02:26:27,517 iteration 2416 : loss : 0.077944, loss_ce: 0.024493
2021-12-14 02:26:29,039 iteration 2417 : loss : 0.079387, loss_ce: 0.029375
2021-12-14 02:26:30,493 iteration 2418 : loss : 0.074058, loss_ce: 0.018603
2021-12-14 02:26:32,008 iteration 2419 : loss : 0.082012, loss_ce: 0.023281
2021-12-14 02:26:33,620 iteration 2420 : loss : 0.072077, loss_ce: 0.021820
2021-12-14 02:26:35,126 iteration 2421 : loss : 0.068792, loss_ce: 0.023366
2021-12-14 02:26:36,641 iteration 2422 : loss : 0.075730, loss_ce: 0.025641
2021-12-14 02:26:38,059 iteration 2423 : loss : 0.072943, loss_ce: 0.025414
2021-12-14 02:26:39,577 iteration 2424 : loss : 0.072402, loss_ce: 0.023171
2021-12-14 02:26:41,141 iteration 2425 : loss : 0.065723, loss_ce: 0.015516
2021-12-14 02:26:42,641 iteration 2426 : loss : 0.082399, loss_ce: 0.022580
2021-12-14 02:26:44,083 iteration 2427 : loss : 0.065906, loss_ce: 0.020749
2021-12-14 02:26:45,572 iteration 2428 : loss : 0.068950, loss_ce: 0.017588
2021-12-14 02:26:47,033 iteration 2429 : loss : 0.071974, loss_ce: 0.019295
2021-12-14 02:26:48,547 iteration 2430 : loss : 0.069744, loss_ce: 0.023044
2021-12-14 02:26:50,092 iteration 2431 : loss : 0.067229, loss_ce: 0.017599
 36%|█████████▋                 | 143/400 [1:07:55<1:56:39, 27.23s/it]2021-12-14 02:26:51,584 iteration 2432 : loss : 0.069404, loss_ce: 0.017684
2021-12-14 02:26:53,077 iteration 2433 : loss : 0.063543, loss_ce: 0.020677
2021-12-14 02:26:54,627 iteration 2434 : loss : 0.082361, loss_ce: 0.024944
2021-12-14 02:26:56,134 iteration 2435 : loss : 0.064677, loss_ce: 0.020211
2021-12-14 02:26:57,736 iteration 2436 : loss : 0.073256, loss_ce: 0.022426
2021-12-14 02:26:59,265 iteration 2437 : loss : 0.071900, loss_ce: 0.020541
2021-12-14 02:27:00,702 iteration 2438 : loss : 0.064477, loss_ce: 0.018088
2021-12-14 02:27:02,210 iteration 2439 : loss : 0.069072, loss_ce: 0.020154
2021-12-14 02:27:03,732 iteration 2440 : loss : 0.078206, loss_ce: 0.024682
2021-12-14 02:27:05,393 iteration 2441 : loss : 0.096993, loss_ce: 0.025106
2021-12-14 02:27:06,957 iteration 2442 : loss : 0.063950, loss_ce: 0.016045
2021-12-14 02:27:08,532 iteration 2443 : loss : 0.066981, loss_ce: 0.020513
2021-12-14 02:27:10,103 iteration 2444 : loss : 0.083636, loss_ce: 0.024373
2021-12-14 02:27:11,768 iteration 2445 : loss : 0.063029, loss_ce: 0.016867
2021-12-14 02:27:13,259 iteration 2446 : loss : 0.067830, loss_ce: 0.020794
2021-12-14 02:27:14,851 iteration 2447 : loss : 0.078916, loss_ce: 0.023709
2021-12-14 02:27:16,307 iteration 2448 : loss : 0.079421, loss_ce: 0.034159
 36%|█████████▋                 | 144/400 [1:08:21<1:54:53, 26.93s/it]2021-12-14 02:27:17,889 iteration 2449 : loss : 0.065446, loss_ce: 0.014223
2021-12-14 02:27:19,336 iteration 2450 : loss : 0.069807, loss_ce: 0.019396
2021-12-14 02:27:20,773 iteration 2451 : loss : 0.064474, loss_ce: 0.018008
2021-12-14 02:27:22,256 iteration 2452 : loss : 0.076010, loss_ce: 0.025966
2021-12-14 02:27:23,747 iteration 2453 : loss : 0.068817, loss_ce: 0.024481
2021-12-14 02:27:25,217 iteration 2454 : loss : 0.075296, loss_ce: 0.022131
2021-12-14 02:27:26,841 iteration 2455 : loss : 0.080762, loss_ce: 0.020852
2021-12-14 02:27:28,378 iteration 2456 : loss : 0.065158, loss_ce: 0.022135
2021-12-14 02:27:29,845 iteration 2457 : loss : 0.092229, loss_ce: 0.027991
2021-12-14 02:27:31,407 iteration 2458 : loss : 0.084990, loss_ce: 0.021943
2021-12-14 02:27:32,914 iteration 2459 : loss : 0.070248, loss_ce: 0.019144
2021-12-14 02:27:34,496 iteration 2460 : loss : 0.082175, loss_ce: 0.019612
2021-12-14 02:27:36,048 iteration 2461 : loss : 0.074016, loss_ce: 0.017321
2021-12-14 02:27:37,702 iteration 2462 : loss : 0.075513, loss_ce: 0.027095
2021-12-14 02:27:39,189 iteration 2463 : loss : 0.084693, loss_ce: 0.025562
2021-12-14 02:27:40,719 iteration 2464 : loss : 0.073989, loss_ce: 0.031236
2021-12-14 02:27:40,719 Training Data Eval:
2021-12-14 02:27:48,169   Average segmentation loss on training set: 0.0598
2021-12-14 02:27:48,169 Validation Data Eval:
2021-12-14 02:27:50,733   Average segmentation loss on validation set: 0.1058
2021-12-14 02:27:52,271 iteration 2465 : loss : 0.072022, loss_ce: 0.024104
 36%|█████████▊                 | 145/400 [1:08:57<2:05:56, 29.63s/it]2021-12-14 02:27:53,890 iteration 2466 : loss : 0.070549, loss_ce: 0.021900
2021-12-14 02:27:55,364 iteration 2467 : loss : 0.061153, loss_ce: 0.017032
2021-12-14 02:27:56,976 iteration 2468 : loss : 0.076243, loss_ce: 0.023848
2021-12-14 02:27:58,433 iteration 2469 : loss : 0.068409, loss_ce: 0.021810
2021-12-14 02:27:59,996 iteration 2470 : loss : 0.085645, loss_ce: 0.026816
2021-12-14 02:28:01,534 iteration 2471 : loss : 0.075065, loss_ce: 0.028589
2021-12-14 02:28:03,093 iteration 2472 : loss : 0.066857, loss_ce: 0.018531
2021-12-14 02:28:04,607 iteration 2473 : loss : 0.076246, loss_ce: 0.021963
2021-12-14 02:28:05,989 iteration 2474 : loss : 0.070690, loss_ce: 0.025132
2021-12-14 02:28:07,543 iteration 2475 : loss : 0.080773, loss_ce: 0.037493
2021-12-14 02:28:09,097 iteration 2476 : loss : 0.087215, loss_ce: 0.022452
2021-12-14 02:28:10,609 iteration 2477 : loss : 0.074058, loss_ce: 0.017995
2021-12-14 02:28:12,093 iteration 2478 : loss : 0.070836, loss_ce: 0.019305
2021-12-14 02:28:13,683 iteration 2479 : loss : 0.072391, loss_ce: 0.019128
2021-12-14 02:28:15,183 iteration 2480 : loss : 0.071046, loss_ce: 0.017330
2021-12-14 02:28:16,642 iteration 2481 : loss : 0.074628, loss_ce: 0.024282
2021-12-14 02:28:18,296 iteration 2482 : loss : 0.122157, loss_ce: 0.037939
 36%|█████████▊                 | 146/400 [1:09:23<2:00:52, 28.55s/it]2021-12-14 02:28:19,842 iteration 2483 : loss : 0.076364, loss_ce: 0.025705
2021-12-14 02:28:21,384 iteration 2484 : loss : 0.103101, loss_ce: 0.019822
2021-12-14 02:28:22,922 iteration 2485 : loss : 0.091124, loss_ce: 0.025145
2021-12-14 02:28:24,457 iteration 2486 : loss : 0.080223, loss_ce: 0.028548
2021-12-14 02:28:25,912 iteration 2487 : loss : 0.074547, loss_ce: 0.026591
2021-12-14 02:28:27,501 iteration 2488 : loss : 0.072695, loss_ce: 0.027728
2021-12-14 02:28:29,072 iteration 2489 : loss : 0.073980, loss_ce: 0.024156
2021-12-14 02:28:30,695 iteration 2490 : loss : 0.081287, loss_ce: 0.028949
2021-12-14 02:28:32,241 iteration 2491 : loss : 0.076076, loss_ce: 0.018606
2021-12-14 02:28:33,799 iteration 2492 : loss : 0.086696, loss_ce: 0.027039
2021-12-14 02:28:35,257 iteration 2493 : loss : 0.069986, loss_ce: 0.020002
2021-12-14 02:28:36,790 iteration 2494 : loss : 0.072565, loss_ce: 0.020953
2021-12-14 02:28:38,412 iteration 2495 : loss : 0.065082, loss_ce: 0.021999
2021-12-14 02:28:39,782 iteration 2496 : loss : 0.058565, loss_ce: 0.017517
2021-12-14 02:28:41,235 iteration 2497 : loss : 0.069290, loss_ce: 0.018045
2021-12-14 02:28:42,923 iteration 2498 : loss : 0.094592, loss_ce: 0.027264
2021-12-14 02:28:44,443 iteration 2499 : loss : 0.077625, loss_ce: 0.029216
 37%|█████████▉                 | 147/400 [1:09:49<1:57:22, 27.84s/it]2021-12-14 02:28:46,054 iteration 2500 : loss : 0.066042, loss_ce: 0.018082
2021-12-14 02:28:47,633 iteration 2501 : loss : 0.079876, loss_ce: 0.029329
2021-12-14 02:28:49,185 iteration 2502 : loss : 0.077505, loss_ce: 0.028448
2021-12-14 02:28:50,677 iteration 2503 : loss : 0.069477, loss_ce: 0.023043
2021-12-14 02:28:52,234 iteration 2504 : loss : 0.072696, loss_ce: 0.021537
2021-12-14 02:28:53,769 iteration 2505 : loss : 0.079261, loss_ce: 0.023630
2021-12-14 02:28:55,303 iteration 2506 : loss : 0.065608, loss_ce: 0.022295
2021-12-14 02:28:56,751 iteration 2507 : loss : 0.068485, loss_ce: 0.020441
2021-12-14 02:28:58,164 iteration 2508 : loss : 0.071906, loss_ce: 0.023595
2021-12-14 02:28:59,646 iteration 2509 : loss : 0.066369, loss_ce: 0.022051
2021-12-14 02:29:01,078 iteration 2510 : loss : 0.079789, loss_ce: 0.019068
2021-12-14 02:29:02,581 iteration 2511 : loss : 0.070936, loss_ce: 0.023273
2021-12-14 02:29:04,060 iteration 2512 : loss : 0.070240, loss_ce: 0.021743
2021-12-14 02:29:05,561 iteration 2513 : loss : 0.078552, loss_ce: 0.023714
2021-12-14 02:29:07,092 iteration 2514 : loss : 0.079188, loss_ce: 0.024684
2021-12-14 02:29:08,581 iteration 2515 : loss : 0.068185, loss_ce: 0.016811
2021-12-14 02:29:10,022 iteration 2516 : loss : 0.073329, loss_ce: 0.023497
 37%|█████████▉                 | 148/400 [1:10:15<1:54:03, 27.16s/it]2021-12-14 02:29:11,567 iteration 2517 : loss : 0.070348, loss_ce: 0.019193
2021-12-14 02:29:13,223 iteration 2518 : loss : 0.092580, loss_ce: 0.030656
2021-12-14 02:29:14,728 iteration 2519 : loss : 0.072080, loss_ce: 0.020061
2021-12-14 02:29:16,229 iteration 2520 : loss : 0.063429, loss_ce: 0.017662
2021-12-14 02:29:17,804 iteration 2521 : loss : 0.073062, loss_ce: 0.026172
2021-12-14 02:29:19,241 iteration 2522 : loss : 0.064888, loss_ce: 0.019687
2021-12-14 02:29:20,602 iteration 2523 : loss : 0.072722, loss_ce: 0.015284
2021-12-14 02:29:22,169 iteration 2524 : loss : 0.067187, loss_ce: 0.023716
2021-12-14 02:29:23,639 iteration 2525 : loss : 0.068574, loss_ce: 0.023738
2021-12-14 02:29:25,089 iteration 2526 : loss : 0.069344, loss_ce: 0.016519
2021-12-14 02:29:26,660 iteration 2527 : loss : 0.071011, loss_ce: 0.019604
2021-12-14 02:29:28,131 iteration 2528 : loss : 0.075043, loss_ce: 0.022576
2021-12-14 02:29:29,665 iteration 2529 : loss : 0.069477, loss_ce: 0.020545
2021-12-14 02:29:31,172 iteration 2530 : loss : 0.070644, loss_ce: 0.017022
2021-12-14 02:29:32,664 iteration 2531 : loss : 0.077677, loss_ce: 0.022143
2021-12-14 02:29:34,213 iteration 2532 : loss : 0.078724, loss_ce: 0.024023
2021-12-14 02:29:35,729 iteration 2533 : loss : 0.078815, loss_ce: 0.036146
 37%|██████████                 | 149/400 [1:10:40<1:51:47, 26.72s/it]2021-12-14 02:29:37,232 iteration 2534 : loss : 0.069675, loss_ce: 0.023015
2021-12-14 02:29:38,787 iteration 2535 : loss : 0.065012, loss_ce: 0.015432
2021-12-14 02:29:40,362 iteration 2536 : loss : 0.068176, loss_ce: 0.023495
2021-12-14 02:29:41,944 iteration 2537 : loss : 0.088123, loss_ce: 0.025519
2021-12-14 02:29:43,566 iteration 2538 : loss : 0.078862, loss_ce: 0.022197
2021-12-14 02:29:45,012 iteration 2539 : loss : 0.064978, loss_ce: 0.019009
2021-12-14 02:29:46,508 iteration 2540 : loss : 0.076910, loss_ce: 0.024943
2021-12-14 02:29:48,184 iteration 2541 : loss : 0.084066, loss_ce: 0.020932
2021-12-14 02:29:49,634 iteration 2542 : loss : 0.068864, loss_ce: 0.020933
2021-12-14 02:29:51,143 iteration 2543 : loss : 0.070453, loss_ce: 0.019541
2021-12-14 02:29:52,743 iteration 2544 : loss : 0.082331, loss_ce: 0.026219
2021-12-14 02:29:54,317 iteration 2545 : loss : 0.071552, loss_ce: 0.027164
2021-12-14 02:29:55,764 iteration 2546 : loss : 0.069262, loss_ce: 0.020537
2021-12-14 02:29:57,285 iteration 2547 : loss : 0.086859, loss_ce: 0.016308
2021-12-14 02:29:58,798 iteration 2548 : loss : 0.077758, loss_ce: 0.023686
2021-12-14 02:30:00,390 iteration 2549 : loss : 0.085638, loss_ce: 0.024273
2021-12-14 02:30:00,390 Training Data Eval:
2021-12-14 02:30:07,838   Average segmentation loss on training set: 0.0602
2021-12-14 02:30:07,838 Validation Data Eval:
2021-12-14 02:30:10,400   Average segmentation loss on validation set: 0.0947
2021-12-14 02:30:16,446 Found new lowest validation loss at iteration 2549! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 02:30:17,945 iteration 2550 : loss : 0.070470, loss_ce: 0.028993
 38%|██████████▏                | 150/400 [1:11:23<2:10:41, 31.37s/it]2021-12-14 02:30:19,462 iteration 2551 : loss : 0.077486, loss_ce: 0.023974
2021-12-14 02:30:20,981 iteration 2552 : loss : 0.065771, loss_ce: 0.019856
2021-12-14 02:30:22,585 iteration 2553 : loss : 0.076726, loss_ce: 0.023002
2021-12-14 02:30:24,167 iteration 2554 : loss : 0.097659, loss_ce: 0.020777
2021-12-14 02:30:25,655 iteration 2555 : loss : 0.067328, loss_ce: 0.016129
2021-12-14 02:30:27,084 iteration 2556 : loss : 0.068897, loss_ce: 0.023079
2021-12-14 02:30:28,653 iteration 2557 : loss : 0.085955, loss_ce: 0.029252
2021-12-14 02:30:30,223 iteration 2558 : loss : 0.072434, loss_ce: 0.025973
2021-12-14 02:30:31,820 iteration 2559 : loss : 0.094611, loss_ce: 0.017610
2021-12-14 02:30:33,407 iteration 2560 : loss : 0.064354, loss_ce: 0.017554
2021-12-14 02:30:34,904 iteration 2561 : loss : 0.074064, loss_ce: 0.024933
2021-12-14 02:30:36,349 iteration 2562 : loss : 0.072856, loss_ce: 0.027857
2021-12-14 02:30:37,844 iteration 2563 : loss : 0.069104, loss_ce: 0.018155
2021-12-14 02:30:39,352 iteration 2564 : loss : 0.076261, loss_ce: 0.026328
2021-12-14 02:30:40,859 iteration 2565 : loss : 0.068414, loss_ce: 0.015960
2021-12-14 02:30:42,346 iteration 2566 : loss : 0.070616, loss_ce: 0.028039
2021-12-14 02:30:43,988 iteration 2567 : loss : 0.074308, loss_ce: 0.023392
 38%|██████████▏                | 151/400 [1:11:49<2:03:34, 29.78s/it]2021-12-14 02:30:45,563 iteration 2568 : loss : 0.063607, loss_ce: 0.020930
2021-12-14 02:30:47,081 iteration 2569 : loss : 0.062892, loss_ce: 0.018630
2021-12-14 02:30:48,562 iteration 2570 : loss : 0.083723, loss_ce: 0.018874
2021-12-14 02:30:50,087 iteration 2571 : loss : 0.075112, loss_ce: 0.022304
2021-12-14 02:30:51,504 iteration 2572 : loss : 0.070368, loss_ce: 0.018367
2021-12-14 02:30:52,964 iteration 2573 : loss : 0.062955, loss_ce: 0.019007
2021-12-14 02:30:54,461 iteration 2574 : loss : 0.089292, loss_ce: 0.025039
2021-12-14 02:30:56,005 iteration 2575 : loss : 0.072290, loss_ce: 0.021515
2021-12-14 02:30:57,651 iteration 2576 : loss : 0.068253, loss_ce: 0.023062
2021-12-14 02:30:59,150 iteration 2577 : loss : 0.071810, loss_ce: 0.021464
2021-12-14 02:31:00,709 iteration 2578 : loss : 0.074134, loss_ce: 0.028998
2021-12-14 02:31:02,187 iteration 2579 : loss : 0.073566, loss_ce: 0.019639
2021-12-14 02:31:03,746 iteration 2580 : loss : 0.064407, loss_ce: 0.016177
2021-12-14 02:31:05,428 iteration 2581 : loss : 0.074831, loss_ce: 0.022453
2021-12-14 02:31:06,812 iteration 2582 : loss : 0.071915, loss_ce: 0.023490
2021-12-14 02:31:08,377 iteration 2583 : loss : 0.064226, loss_ce: 0.018150
2021-12-14 02:31:09,852 iteration 2584 : loss : 0.064606, loss_ce: 0.018930
 38%|██████████▎                | 152/400 [1:12:15<1:58:12, 28.60s/it]2021-12-14 02:31:11,507 iteration 2585 : loss : 0.080439, loss_ce: 0.027351
2021-12-14 02:31:13,016 iteration 2586 : loss : 0.082074, loss_ce: 0.026900
2021-12-14 02:31:14,463 iteration 2587 : loss : 0.069957, loss_ce: 0.020761
2021-12-14 02:31:15,955 iteration 2588 : loss : 0.069908, loss_ce: 0.024165
2021-12-14 02:31:17,369 iteration 2589 : loss : 0.064924, loss_ce: 0.018669
2021-12-14 02:31:18,931 iteration 2590 : loss : 0.066819, loss_ce: 0.017665
2021-12-14 02:31:20,442 iteration 2591 : loss : 0.067694, loss_ce: 0.023952
2021-12-14 02:31:21,939 iteration 2592 : loss : 0.069532, loss_ce: 0.021122
2021-12-14 02:31:23,400 iteration 2593 : loss : 0.075047, loss_ce: 0.024076
2021-12-14 02:31:24,955 iteration 2594 : loss : 0.067905, loss_ce: 0.020440
2021-12-14 02:31:26,619 iteration 2595 : loss : 0.084022, loss_ce: 0.023157
2021-12-14 02:31:28,042 iteration 2596 : loss : 0.062917, loss_ce: 0.016200
2021-12-14 02:31:29,557 iteration 2597 : loss : 0.092054, loss_ce: 0.026919
2021-12-14 02:31:31,037 iteration 2598 : loss : 0.068355, loss_ce: 0.023899
2021-12-14 02:31:32,599 iteration 2599 : loss : 0.062508, loss_ce: 0.022157
2021-12-14 02:31:34,104 iteration 2600 : loss : 0.081333, loss_ce: 0.024941
2021-12-14 02:31:35,635 iteration 2601 : loss : 0.065210, loss_ce: 0.018059
 38%|██████████▎                | 153/400 [1:12:40<1:54:15, 27.76s/it]2021-12-14 02:31:37,254 iteration 2602 : loss : 0.071332, loss_ce: 0.019200
2021-12-14 02:31:38,871 iteration 2603 : loss : 0.066136, loss_ce: 0.015446
2021-12-14 02:31:40,424 iteration 2604 : loss : 0.074221, loss_ce: 0.028031
2021-12-14 02:31:41,796 iteration 2605 : loss : 0.056801, loss_ce: 0.013487
2021-12-14 02:31:43,492 iteration 2606 : loss : 0.093020, loss_ce: 0.027791
2021-12-14 02:31:45,056 iteration 2607 : loss : 0.078239, loss_ce: 0.024531
2021-12-14 02:31:46,575 iteration 2608 : loss : 0.075975, loss_ce: 0.026714
2021-12-14 02:31:48,257 iteration 2609 : loss : 0.085952, loss_ce: 0.023993
2021-12-14 02:31:49,858 iteration 2610 : loss : 0.076041, loss_ce: 0.022917
2021-12-14 02:31:51,431 iteration 2611 : loss : 0.069481, loss_ce: 0.022555
2021-12-14 02:31:53,018 iteration 2612 : loss : 0.072703, loss_ce: 0.026273
2021-12-14 02:31:54,479 iteration 2613 : loss : 0.065599, loss_ce: 0.019728
2021-12-14 02:31:56,076 iteration 2614 : loss : 0.080861, loss_ce: 0.022541
2021-12-14 02:31:57,544 iteration 2615 : loss : 0.078391, loss_ce: 0.025430
2021-12-14 02:31:59,119 iteration 2616 : loss : 0.075967, loss_ce: 0.029642
2021-12-14 02:32:00,629 iteration 2617 : loss : 0.073517, loss_ce: 0.020170
2021-12-14 02:32:02,082 iteration 2618 : loss : 0.064033, loss_ce: 0.019502
 38%|██████████▍                | 154/400 [1:13:07<1:52:11, 27.36s/it]2021-12-14 02:32:03,616 iteration 2619 : loss : 0.074226, loss_ce: 0.019539
2021-12-14 02:32:05,107 iteration 2620 : loss : 0.065205, loss_ce: 0.021788
2021-12-14 02:32:06,689 iteration 2621 : loss : 0.075347, loss_ce: 0.023855
2021-12-14 02:32:08,186 iteration 2622 : loss : 0.075213, loss_ce: 0.017498
2021-12-14 02:32:09,735 iteration 2623 : loss : 0.075872, loss_ce: 0.027562
2021-12-14 02:32:11,206 iteration 2624 : loss : 0.060592, loss_ce: 0.016091
2021-12-14 02:32:12,740 iteration 2625 : loss : 0.110271, loss_ce: 0.017459
2021-12-14 02:32:14,286 iteration 2626 : loss : 0.070915, loss_ce: 0.023723
2021-12-14 02:32:16,006 iteration 2627 : loss : 0.065940, loss_ce: 0.020359
2021-12-14 02:32:17,448 iteration 2628 : loss : 0.066836, loss_ce: 0.021511
2021-12-14 02:32:19,033 iteration 2629 : loss : 0.076906, loss_ce: 0.028741
2021-12-14 02:32:20,585 iteration 2630 : loss : 0.066345, loss_ce: 0.021076
2021-12-14 02:32:22,120 iteration 2631 : loss : 0.066901, loss_ce: 0.022309
2021-12-14 02:32:23,633 iteration 2632 : loss : 0.061703, loss_ce: 0.016840
2021-12-14 02:32:25,189 iteration 2633 : loss : 0.084689, loss_ce: 0.035663
2021-12-14 02:32:26,733 iteration 2634 : loss : 0.065572, loss_ce: 0.016397
2021-12-14 02:32:26,734 Training Data Eval:
2021-12-14 02:32:34,170   Average segmentation loss on training set: 0.0573
2021-12-14 02:32:34,170 Validation Data Eval:
2021-12-14 02:32:36,740   Average segmentation loss on validation set: 0.1029
2021-12-14 02:32:38,251 iteration 2635 : loss : 0.064505, loss_ce: 0.019504
 39%|██████████▍                | 155/400 [1:13:43<2:02:30, 30.00s/it]2021-12-14 02:32:39,848 iteration 2636 : loss : 0.069972, loss_ce: 0.022652
2021-12-14 02:32:41,467 iteration 2637 : loss : 0.070486, loss_ce: 0.023089
2021-12-14 02:32:42,961 iteration 2638 : loss : 0.078005, loss_ce: 0.020598
2021-12-14 02:32:44,410 iteration 2639 : loss : 0.061487, loss_ce: 0.022363
2021-12-14 02:32:45,897 iteration 2640 : loss : 0.074953, loss_ce: 0.021391
2021-12-14 02:32:47,389 iteration 2641 : loss : 0.073629, loss_ce: 0.028157
2021-12-14 02:32:48,853 iteration 2642 : loss : 0.065934, loss_ce: 0.019183
2021-12-14 02:32:50,515 iteration 2643 : loss : 0.064597, loss_ce: 0.018145
2021-12-14 02:32:52,011 iteration 2644 : loss : 0.064246, loss_ce: 0.019678
2021-12-14 02:32:53,463 iteration 2645 : loss : 0.071015, loss_ce: 0.020679
2021-12-14 02:32:55,200 iteration 2646 : loss : 0.064768, loss_ce: 0.017098
2021-12-14 02:32:56,798 iteration 2647 : loss : 0.102296, loss_ce: 0.034300
2021-12-14 02:32:58,308 iteration 2648 : loss : 0.069750, loss_ce: 0.021039
2021-12-14 02:32:59,859 iteration 2649 : loss : 0.077729, loss_ce: 0.025370
2021-12-14 02:33:01,459 iteration 2650 : loss : 0.074021, loss_ce: 0.020784
2021-12-14 02:33:03,024 iteration 2651 : loss : 0.070466, loss_ce: 0.024927
2021-12-14 02:33:04,505 iteration 2652 : loss : 0.063426, loss_ce: 0.018080
 39%|██████████▌                | 156/400 [1:14:09<1:57:26, 28.88s/it]2021-12-14 02:33:06,140 iteration 2653 : loss : 0.068474, loss_ce: 0.024585
2021-12-14 02:33:07,687 iteration 2654 : loss : 0.075008, loss_ce: 0.020256
2021-12-14 02:33:09,362 iteration 2655 : loss : 0.073580, loss_ce: 0.027106
2021-12-14 02:33:10,876 iteration 2656 : loss : 0.073614, loss_ce: 0.018725
2021-12-14 02:33:12,396 iteration 2657 : loss : 0.068617, loss_ce: 0.021385
2021-12-14 02:33:13,758 iteration 2658 : loss : 0.061030, loss_ce: 0.019783
2021-12-14 02:33:15,194 iteration 2659 : loss : 0.085430, loss_ce: 0.017514
2021-12-14 02:33:16,786 iteration 2660 : loss : 0.068864, loss_ce: 0.018508
2021-12-14 02:33:18,276 iteration 2661 : loss : 0.064733, loss_ce: 0.021541
2021-12-14 02:33:19,768 iteration 2662 : loss : 0.067806, loss_ce: 0.025326
2021-12-14 02:33:21,246 iteration 2663 : loss : 0.075575, loss_ce: 0.020388
2021-12-14 02:33:22,882 iteration 2664 : loss : 0.077133, loss_ce: 0.026299
2021-12-14 02:33:24,413 iteration 2665 : loss : 0.072726, loss_ce: 0.021856
2021-12-14 02:33:25,881 iteration 2666 : loss : 0.064948, loss_ce: 0.016741
2021-12-14 02:33:27,476 iteration 2667 : loss : 0.072863, loss_ce: 0.021472
2021-12-14 02:33:28,952 iteration 2668 : loss : 0.077131, loss_ce: 0.020399
2021-12-14 02:33:30,423 iteration 2669 : loss : 0.073539, loss_ce: 0.023259
 39%|██████████▌                | 157/400 [1:14:35<1:53:21, 27.99s/it]2021-12-14 02:33:32,037 iteration 2670 : loss : 0.075155, loss_ce: 0.026991
2021-12-14 02:33:33,710 iteration 2671 : loss : 0.080359, loss_ce: 0.023635
2021-12-14 02:33:35,277 iteration 2672 : loss : 0.064265, loss_ce: 0.018959
2021-12-14 02:33:36,730 iteration 2673 : loss : 0.071279, loss_ce: 0.027859
2021-12-14 02:33:38,299 iteration 2674 : loss : 0.075463, loss_ce: 0.025294
2021-12-14 02:33:39,670 iteration 2675 : loss : 0.062034, loss_ce: 0.018767
2021-12-14 02:33:41,323 iteration 2676 : loss : 0.066115, loss_ce: 0.013792
2021-12-14 02:33:42,887 iteration 2677 : loss : 0.076522, loss_ce: 0.024270
2021-12-14 02:33:44,405 iteration 2678 : loss : 0.067890, loss_ce: 0.024030
2021-12-14 02:33:45,951 iteration 2679 : loss : 0.079250, loss_ce: 0.023761
2021-12-14 02:33:47,456 iteration 2680 : loss : 0.068292, loss_ce: 0.023166
2021-12-14 02:33:49,000 iteration 2681 : loss : 0.070224, loss_ce: 0.019770
2021-12-14 02:33:50,535 iteration 2682 : loss : 0.072641, loss_ce: 0.020718
2021-12-14 02:33:52,039 iteration 2683 : loss : 0.103246, loss_ce: 0.020827
2021-12-14 02:33:53,494 iteration 2684 : loss : 0.068442, loss_ce: 0.025071
2021-12-14 02:33:55,041 iteration 2685 : loss : 0.065514, loss_ce: 0.022713
2021-12-14 02:33:56,494 iteration 2686 : loss : 0.071241, loss_ce: 0.025587
 40%|██████████▋                | 158/400 [1:15:01<1:50:34, 27.42s/it]2021-12-14 02:33:57,952 iteration 2687 : loss : 0.077740, loss_ce: 0.019447
2021-12-14 02:33:59,471 iteration 2688 : loss : 0.075217, loss_ce: 0.019823
2021-12-14 02:34:00,954 iteration 2689 : loss : 0.070658, loss_ce: 0.022967
2021-12-14 02:34:02,595 iteration 2690 : loss : 0.093258, loss_ce: 0.035484
2021-12-14 02:34:04,032 iteration 2691 : loss : 0.063473, loss_ce: 0.019442
2021-12-14 02:34:05,487 iteration 2692 : loss : 0.066305, loss_ce: 0.017139
2021-12-14 02:34:07,004 iteration 2693 : loss : 0.070285, loss_ce: 0.021212
2021-12-14 02:34:08,614 iteration 2694 : loss : 0.077712, loss_ce: 0.022454
2021-12-14 02:34:10,103 iteration 2695 : loss : 0.064256, loss_ce: 0.021271
2021-12-14 02:34:11,638 iteration 2696 : loss : 0.071181, loss_ce: 0.024764
2021-12-14 02:34:13,070 iteration 2697 : loss : 0.059114, loss_ce: 0.018275
2021-12-14 02:34:14,405 iteration 2698 : loss : 0.059078, loss_ce: 0.019632
2021-12-14 02:34:15,929 iteration 2699 : loss : 0.069344, loss_ce: 0.021143
2021-12-14 02:34:17,515 iteration 2700 : loss : 0.086273, loss_ce: 0.030174
2021-12-14 02:34:19,038 iteration 2701 : loss : 0.079544, loss_ce: 0.026979
2021-12-14 02:34:20,626 iteration 2702 : loss : 0.089487, loss_ce: 0.016033
2021-12-14 02:34:22,149 iteration 2703 : loss : 0.075681, loss_ce: 0.021767
 40%|██████████▋                | 159/400 [1:15:27<1:48:00, 26.89s/it]2021-12-14 02:34:23,883 iteration 2704 : loss : 0.074086, loss_ce: 0.023580
2021-12-14 02:34:25,343 iteration 2705 : loss : 0.073414, loss_ce: 0.019539
2021-12-14 02:34:26,798 iteration 2706 : loss : 0.076123, loss_ce: 0.029810
2021-12-14 02:34:28,402 iteration 2707 : loss : 0.068627, loss_ce: 0.016793
2021-12-14 02:34:29,809 iteration 2708 : loss : 0.055466, loss_ce: 0.016711
2021-12-14 02:34:31,336 iteration 2709 : loss : 0.072025, loss_ce: 0.018563
2021-12-14 02:34:32,767 iteration 2710 : loss : 0.063967, loss_ce: 0.019395
2021-12-14 02:34:34,407 iteration 2711 : loss : 0.085915, loss_ce: 0.025397
2021-12-14 02:34:35,847 iteration 2712 : loss : 0.057153, loss_ce: 0.016768
2021-12-14 02:34:37,511 iteration 2713 : loss : 0.088126, loss_ce: 0.028363
2021-12-14 02:34:38,945 iteration 2714 : loss : 0.062915, loss_ce: 0.016930
2021-12-14 02:34:40,481 iteration 2715 : loss : 0.087305, loss_ce: 0.035216
2021-12-14 02:34:41,958 iteration 2716 : loss : 0.074275, loss_ce: 0.022754
2021-12-14 02:34:43,380 iteration 2717 : loss : 0.067979, loss_ce: 0.025483
2021-12-14 02:34:44,833 iteration 2718 : loss : 0.067215, loss_ce: 0.018392
2021-12-14 02:34:46,435 iteration 2719 : loss : 0.086352, loss_ce: 0.021493
2021-12-14 02:34:46,435 Training Data Eval:
2021-12-14 02:34:53,869   Average segmentation loss on training set: 0.0572
2021-12-14 02:34:53,869 Validation Data Eval:
2021-12-14 02:34:56,426   Average segmentation loss on validation set: 0.0973
2021-12-14 02:34:57,845 iteration 2720 : loss : 0.063028, loss_ce: 0.021152
 40%|██████████▊                | 160/400 [1:16:03<1:58:07, 29.53s/it]2021-12-14 02:34:59,447 iteration 2721 : loss : 0.073811, loss_ce: 0.025648
2021-12-14 02:35:01,012 iteration 2722 : loss : 0.079825, loss_ce: 0.026652
2021-12-14 02:35:02,568 iteration 2723 : loss : 0.068103, loss_ce: 0.020624
2021-12-14 02:35:04,003 iteration 2724 : loss : 0.064942, loss_ce: 0.018009
2021-12-14 02:35:05,390 iteration 2725 : loss : 0.061421, loss_ce: 0.016781
2021-12-14 02:35:06,856 iteration 2726 : loss : 0.080765, loss_ce: 0.025064
2021-12-14 02:35:08,265 iteration 2727 : loss : 0.057098, loss_ce: 0.014880
2021-12-14 02:35:09,939 iteration 2728 : loss : 0.076353, loss_ce: 0.026223
2021-12-14 02:35:11,460 iteration 2729 : loss : 0.075039, loss_ce: 0.022638
2021-12-14 02:35:13,023 iteration 2730 : loss : 0.059777, loss_ce: 0.019583
2021-12-14 02:35:14,581 iteration 2731 : loss : 0.062987, loss_ce: 0.021731
2021-12-14 02:35:16,233 iteration 2732 : loss : 0.078785, loss_ce: 0.020653
2021-12-14 02:35:17,782 iteration 2733 : loss : 0.078564, loss_ce: 0.022406
2021-12-14 02:35:19,329 iteration 2734 : loss : 0.061792, loss_ce: 0.014290
2021-12-14 02:35:20,735 iteration 2735 : loss : 0.063343, loss_ce: 0.020536
2021-12-14 02:35:22,325 iteration 2736 : loss : 0.083214, loss_ce: 0.035055
2021-12-14 02:35:23,826 iteration 2737 : loss : 0.071792, loss_ce: 0.020524
 40%|██████████▊                | 161/400 [1:16:29<1:53:21, 28.46s/it]2021-12-14 02:35:25,372 iteration 2738 : loss : 0.067772, loss_ce: 0.024415
2021-12-14 02:35:26,866 iteration 2739 : loss : 0.071013, loss_ce: 0.028155
2021-12-14 02:35:28,398 iteration 2740 : loss : 0.067619, loss_ce: 0.021220
2021-12-14 02:35:29,944 iteration 2741 : loss : 0.063154, loss_ce: 0.017037
2021-12-14 02:35:31,362 iteration 2742 : loss : 0.065403, loss_ce: 0.020875
2021-12-14 02:35:32,878 iteration 2743 : loss : 0.082553, loss_ce: 0.030355
2021-12-14 02:35:34,415 iteration 2744 : loss : 0.060906, loss_ce: 0.018956
2021-12-14 02:35:35,940 iteration 2745 : loss : 0.067470, loss_ce: 0.020723
2021-12-14 02:35:37,382 iteration 2746 : loss : 0.075331, loss_ce: 0.017059
2021-12-14 02:35:38,900 iteration 2747 : loss : 0.061933, loss_ce: 0.016779
2021-12-14 02:35:40,453 iteration 2748 : loss : 0.078279, loss_ce: 0.025741
2021-12-14 02:35:41,886 iteration 2749 : loss : 0.068527, loss_ce: 0.024639
2021-12-14 02:35:43,439 iteration 2750 : loss : 0.067987, loss_ce: 0.017998
2021-12-14 02:35:44,907 iteration 2751 : loss : 0.058592, loss_ce: 0.017699
2021-12-14 02:35:46,320 iteration 2752 : loss : 0.063742, loss_ce: 0.013445
2021-12-14 02:35:47,942 iteration 2753 : loss : 0.079601, loss_ce: 0.027041
2021-12-14 02:35:49,512 iteration 2754 : loss : 0.057527, loss_ce: 0.018402
 40%|██████████▉                | 162/400 [1:16:54<1:49:36, 27.63s/it]2021-12-14 02:35:51,083 iteration 2755 : loss : 0.073994, loss_ce: 0.022702
2021-12-14 02:35:52,623 iteration 2756 : loss : 0.080457, loss_ce: 0.034329
2021-12-14 02:35:54,142 iteration 2757 : loss : 0.068396, loss_ce: 0.020234
2021-12-14 02:35:55,733 iteration 2758 : loss : 0.100343, loss_ce: 0.029622
2021-12-14 02:35:57,258 iteration 2759 : loss : 0.073822, loss_ce: 0.019895
2021-12-14 02:35:58,785 iteration 2760 : loss : 0.067541, loss_ce: 0.020847
2021-12-14 02:36:00,188 iteration 2761 : loss : 0.076969, loss_ce: 0.022916
2021-12-14 02:36:01,626 iteration 2762 : loss : 0.057026, loss_ce: 0.016694
2021-12-14 02:36:03,206 iteration 2763 : loss : 0.081688, loss_ce: 0.022937
2021-12-14 02:36:04,721 iteration 2764 : loss : 0.070853, loss_ce: 0.021230
2021-12-14 02:36:06,241 iteration 2765 : loss : 0.072465, loss_ce: 0.023575
2021-12-14 02:36:07,724 iteration 2766 : loss : 0.064452, loss_ce: 0.021298
2021-12-14 02:36:09,264 iteration 2767 : loss : 0.075324, loss_ce: 0.024017
2021-12-14 02:36:10,724 iteration 2768 : loss : 0.058886, loss_ce: 0.013358
2021-12-14 02:36:12,242 iteration 2769 : loss : 0.058718, loss_ce: 0.019262
2021-12-14 02:36:13,761 iteration 2770 : loss : 0.076612, loss_ce: 0.032580
2021-12-14 02:36:15,239 iteration 2771 : loss : 0.071145, loss_ce: 0.019265
 41%|███████████                | 163/400 [1:17:20<1:46:53, 27.06s/it]2021-12-14 02:36:16,869 iteration 2772 : loss : 0.073609, loss_ce: 0.024373
2021-12-14 02:36:18,304 iteration 2773 : loss : 0.061930, loss_ce: 0.020376
2021-12-14 02:36:19,723 iteration 2774 : loss : 0.081748, loss_ce: 0.017762
2021-12-14 02:36:21,207 iteration 2775 : loss : 0.070545, loss_ce: 0.021387
2021-12-14 02:36:22,661 iteration 2776 : loss : 0.061281, loss_ce: 0.017787
2021-12-14 02:36:24,157 iteration 2777 : loss : 0.053390, loss_ce: 0.013887
2021-12-14 02:36:25,754 iteration 2778 : loss : 0.074947, loss_ce: 0.024574
2021-12-14 02:36:27,419 iteration 2779 : loss : 0.066306, loss_ce: 0.019274
2021-12-14 02:36:28,868 iteration 2780 : loss : 0.051198, loss_ce: 0.013845
2021-12-14 02:36:30,444 iteration 2781 : loss : 0.091527, loss_ce: 0.027054
2021-12-14 02:36:31,934 iteration 2782 : loss : 0.065828, loss_ce: 0.019136
2021-12-14 02:36:33,391 iteration 2783 : loss : 0.074492, loss_ce: 0.028984
2021-12-14 02:36:35,046 iteration 2784 : loss : 0.074355, loss_ce: 0.020701
2021-12-14 02:36:36,652 iteration 2785 : loss : 0.073499, loss_ce: 0.019523
2021-12-14 02:36:38,205 iteration 2786 : loss : 0.063552, loss_ce: 0.020715
2021-12-14 02:36:39,790 iteration 2787 : loss : 0.067887, loss_ce: 0.023158
2021-12-14 02:36:41,265 iteration 2788 : loss : 0.065042, loss_ce: 0.026087
 41%|███████████                | 164/400 [1:17:46<1:45:12, 26.75s/it]2021-12-14 02:36:42,785 iteration 2789 : loss : 0.066334, loss_ce: 0.020523
2021-12-14 02:36:44,333 iteration 2790 : loss : 0.068436, loss_ce: 0.017117
2021-12-14 02:36:45,799 iteration 2791 : loss : 0.068648, loss_ce: 0.024826
2021-12-14 02:36:47,396 iteration 2792 : loss : 0.079818, loss_ce: 0.023787
2021-12-14 02:36:48,848 iteration 2793 : loss : 0.067859, loss_ce: 0.022101
2021-12-14 02:36:50,406 iteration 2794 : loss : 0.057928, loss_ce: 0.015810
2021-12-14 02:36:51,863 iteration 2795 : loss : 0.058402, loss_ce: 0.014708
2021-12-14 02:36:53,421 iteration 2796 : loss : 0.062209, loss_ce: 0.018125
2021-12-14 02:36:54,977 iteration 2797 : loss : 0.068306, loss_ce: 0.022250
2021-12-14 02:36:56,571 iteration 2798 : loss : 0.072535, loss_ce: 0.029569
2021-12-14 02:36:58,026 iteration 2799 : loss : 0.060070, loss_ce: 0.020080
2021-12-14 02:36:59,469 iteration 2800 : loss : 0.078411, loss_ce: 0.021897
2021-12-14 02:37:00,889 iteration 2801 : loss : 0.067004, loss_ce: 0.017041
2021-12-14 02:37:02,474 iteration 2802 : loss : 0.077684, loss_ce: 0.019718
2021-12-14 02:37:03,976 iteration 2803 : loss : 0.069008, loss_ce: 0.024086
2021-12-14 02:37:05,450 iteration 2804 : loss : 0.063733, loss_ce: 0.017551
2021-12-14 02:37:05,451 Training Data Eval:
2021-12-14 02:37:12,885   Average segmentation loss on training set: 0.0551
2021-12-14 02:37:12,886 Validation Data Eval:
2021-12-14 02:37:15,445   Average segmentation loss on validation set: 0.0909
2021-12-14 02:37:21,309 Found new lowest validation loss at iteration 2804! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 02:37:22,792 iteration 2805 : loss : 0.065624, loss_ce: 0.023062
 41%|███████████▏               | 165/400 [1:18:28<2:02:07, 31.18s/it]2021-12-14 02:37:24,499 iteration 2806 : loss : 0.074085, loss_ce: 0.026848
2021-12-14 02:37:25,909 iteration 2807 : loss : 0.078329, loss_ce: 0.024698
2021-12-14 02:37:27,350 iteration 2808 : loss : 0.065358, loss_ce: 0.021704
2021-12-14 02:37:28,897 iteration 2809 : loss : 0.059854, loss_ce: 0.016259
2021-12-14 02:37:30,386 iteration 2810 : loss : 0.069920, loss_ce: 0.024000
2021-12-14 02:37:32,014 iteration 2811 : loss : 0.065250, loss_ce: 0.018007
2021-12-14 02:37:33,659 iteration 2812 : loss : 0.064045, loss_ce: 0.016757
2021-12-14 02:37:35,059 iteration 2813 : loss : 0.057802, loss_ce: 0.016798
2021-12-14 02:37:36,598 iteration 2814 : loss : 0.076430, loss_ce: 0.030555
2021-12-14 02:37:38,173 iteration 2815 : loss : 0.069094, loss_ce: 0.022405
2021-12-14 02:37:39,662 iteration 2816 : loss : 0.059797, loss_ce: 0.015997
2021-12-14 02:37:41,145 iteration 2817 : loss : 0.078197, loss_ce: 0.028379
2021-12-14 02:37:42,782 iteration 2818 : loss : 0.070940, loss_ce: 0.020751
2021-12-14 02:37:44,386 iteration 2819 : loss : 0.064697, loss_ce: 0.022226
2021-12-14 02:37:45,870 iteration 2820 : loss : 0.059366, loss_ce: 0.017084
2021-12-14 02:37:47,396 iteration 2821 : loss : 0.056224, loss_ce: 0.017633
2021-12-14 02:37:48,979 iteration 2822 : loss : 0.093580, loss_ce: 0.017427
 42%|███████████▏               | 166/400 [1:18:54<1:55:45, 29.68s/it]2021-12-14 02:37:50,588 iteration 2823 : loss : 0.066369, loss_ce: 0.017452
2021-12-14 02:37:52,142 iteration 2824 : loss : 0.071807, loss_ce: 0.017480
2021-12-14 02:37:53,681 iteration 2825 : loss : 0.087151, loss_ce: 0.024588
2021-12-14 02:37:55,145 iteration 2826 : loss : 0.071115, loss_ce: 0.019709
2021-12-14 02:37:56,712 iteration 2827 : loss : 0.057961, loss_ce: 0.016705
2021-12-14 02:37:58,188 iteration 2828 : loss : 0.087090, loss_ce: 0.030411
2021-12-14 02:37:59,689 iteration 2829 : loss : 0.072705, loss_ce: 0.017531
2021-12-14 02:38:01,237 iteration 2830 : loss : 0.061944, loss_ce: 0.020740
2021-12-14 02:38:02,720 iteration 2831 : loss : 0.071724, loss_ce: 0.018824
2021-12-14 02:38:04,156 iteration 2832 : loss : 0.060924, loss_ce: 0.020528
2021-12-14 02:38:05,776 iteration 2833 : loss : 0.055224, loss_ce: 0.018201
2021-12-14 02:38:07,302 iteration 2834 : loss : 0.062929, loss_ce: 0.019589
2021-12-14 02:38:08,848 iteration 2835 : loss : 0.091992, loss_ce: 0.029808
2021-12-14 02:38:10,412 iteration 2836 : loss : 0.069351, loss_ce: 0.021980
2021-12-14 02:38:11,993 iteration 2837 : loss : 0.064805, loss_ce: 0.018829
2021-12-14 02:38:13,556 iteration 2838 : loss : 0.062711, loss_ce: 0.018337
2021-12-14 02:38:14,986 iteration 2839 : loss : 0.067038, loss_ce: 0.021068
 42%|███████████▎               | 167/400 [1:19:20<1:50:59, 28.58s/it]2021-12-14 02:38:16,567 iteration 2840 : loss : 0.064281, loss_ce: 0.018723
2021-12-14 02:38:18,018 iteration 2841 : loss : 0.058796, loss_ce: 0.019757
2021-12-14 02:38:19,430 iteration 2842 : loss : 0.057059, loss_ce: 0.016961
2021-12-14 02:38:20,923 iteration 2843 : loss : 0.074781, loss_ce: 0.017042
2021-12-14 02:38:22,490 iteration 2844 : loss : 0.064583, loss_ce: 0.022950
2021-12-14 02:38:24,089 iteration 2845 : loss : 0.068376, loss_ce: 0.019966
2021-12-14 02:38:25,598 iteration 2846 : loss : 0.059616, loss_ce: 0.015960
2021-12-14 02:38:27,151 iteration 2847 : loss : 0.071001, loss_ce: 0.023336
2021-12-14 02:38:28,784 iteration 2848 : loss : 0.074463, loss_ce: 0.027603
2021-12-14 02:38:30,265 iteration 2849 : loss : 0.065487, loss_ce: 0.018194
2021-12-14 02:38:31,734 iteration 2850 : loss : 0.058891, loss_ce: 0.014654
2021-12-14 02:38:33,263 iteration 2851 : loss : 0.062605, loss_ce: 0.019869
2021-12-14 02:38:34,791 iteration 2852 : loss : 0.078226, loss_ce: 0.023213
2021-12-14 02:38:36,261 iteration 2853 : loss : 0.072154, loss_ce: 0.026157
2021-12-14 02:38:37,855 iteration 2854 : loss : 0.077823, loss_ce: 0.029556
2021-12-14 02:38:39,361 iteration 2855 : loss : 0.071105, loss_ce: 0.023049
2021-12-14 02:38:40,956 iteration 2856 : loss : 0.072926, loss_ce: 0.023690
 42%|███████████▎               | 168/400 [1:19:46<1:47:29, 27.80s/it]2021-12-14 02:38:42,643 iteration 2857 : loss : 0.075001, loss_ce: 0.015318
2021-12-14 02:38:44,205 iteration 2858 : loss : 0.066223, loss_ce: 0.017647
2021-12-14 02:38:45,648 iteration 2859 : loss : 0.062676, loss_ce: 0.017401
2021-12-14 02:38:47,242 iteration 2860 : loss : 0.082172, loss_ce: 0.028716
2021-12-14 02:38:48,721 iteration 2861 : loss : 0.062573, loss_ce: 0.015849
2021-12-14 02:38:50,280 iteration 2862 : loss : 0.062876, loss_ce: 0.018326
2021-12-14 02:38:51,877 iteration 2863 : loss : 0.075263, loss_ce: 0.023234
2021-12-14 02:38:53,407 iteration 2864 : loss : 0.069199, loss_ce: 0.021602
2021-12-14 02:38:54,845 iteration 2865 : loss : 0.060253, loss_ce: 0.017667
2021-12-14 02:38:56,330 iteration 2866 : loss : 0.061355, loss_ce: 0.015232
2021-12-14 02:38:57,921 iteration 2867 : loss : 0.080315, loss_ce: 0.026880
2021-12-14 02:38:59,492 iteration 2868 : loss : 0.062952, loss_ce: 0.019624
2021-12-14 02:39:00,959 iteration 2869 : loss : 0.060336, loss_ce: 0.020129
2021-12-14 02:39:02,483 iteration 2870 : loss : 0.078905, loss_ce: 0.030555
2021-12-14 02:39:03,887 iteration 2871 : loss : 0.057304, loss_ce: 0.020024
2021-12-14 02:39:05,401 iteration 2872 : loss : 0.062796, loss_ce: 0.017164
2021-12-14 02:39:06,968 iteration 2873 : loss : 0.072779, loss_ce: 0.026667
 42%|███████████▍               | 169/400 [1:20:12<1:44:58, 27.26s/it]2021-12-14 02:39:08,499 iteration 2874 : loss : 0.072722, loss_ce: 0.016672
2021-12-14 02:39:09,907 iteration 2875 : loss : 0.056601, loss_ce: 0.017642
2021-12-14 02:39:11,375 iteration 2876 : loss : 0.065393, loss_ce: 0.021770
2021-12-14 02:39:12,906 iteration 2877 : loss : 0.064814, loss_ce: 0.018439
2021-12-14 02:39:14,458 iteration 2878 : loss : 0.073779, loss_ce: 0.022582
2021-12-14 02:39:15,898 iteration 2879 : loss : 0.063304, loss_ce: 0.023257
2021-12-14 02:39:17,490 iteration 2880 : loss : 0.080140, loss_ce: 0.027528
2021-12-14 02:39:18,982 iteration 2881 : loss : 0.069594, loss_ce: 0.023292
2021-12-14 02:39:20,625 iteration 2882 : loss : 0.078853, loss_ce: 0.017006
2021-12-14 02:39:22,248 iteration 2883 : loss : 0.070837, loss_ce: 0.025103
2021-12-14 02:39:23,867 iteration 2884 : loss : 0.078844, loss_ce: 0.019980
2021-12-14 02:39:25,402 iteration 2885 : loss : 0.059678, loss_ce: 0.020996
2021-12-14 02:39:26,876 iteration 2886 : loss : 0.072911, loss_ce: 0.015719
2021-12-14 02:39:28,374 iteration 2887 : loss : 0.062489, loss_ce: 0.018837
2021-12-14 02:39:30,007 iteration 2888 : loss : 0.062001, loss_ce: 0.016048
2021-12-14 02:39:31,550 iteration 2889 : loss : 0.078716, loss_ce: 0.024234
2021-12-14 02:39:31,550 Training Data Eval:
2021-12-14 02:39:38,976   Average segmentation loss on training set: 0.0592
2021-12-14 02:39:38,977 Validation Data Eval:
2021-12-14 02:39:41,532   Average segmentation loss on validation set: 0.1048
2021-12-14 02:39:43,098 iteration 2890 : loss : 0.074127, loss_ce: 0.023583
 42%|███████████▍               | 170/400 [1:20:48<1:54:41, 29.92s/it]2021-12-14 02:39:44,756 iteration 2891 : loss : 0.090376, loss_ce: 0.039649
2021-12-14 02:39:46,202 iteration 2892 : loss : 0.063649, loss_ce: 0.022267
2021-12-14 02:39:47,681 iteration 2893 : loss : 0.062261, loss_ce: 0.016582
2021-12-14 02:39:49,225 iteration 2894 : loss : 0.054495, loss_ce: 0.016716
2021-12-14 02:39:50,716 iteration 2895 : loss : 0.059089, loss_ce: 0.016409
2021-12-14 02:39:52,163 iteration 2896 : loss : 0.058442, loss_ce: 0.017048
2021-12-14 02:39:53,659 iteration 2897 : loss : 0.067698, loss_ce: 0.022715
2021-12-14 02:39:55,178 iteration 2898 : loss : 0.080604, loss_ce: 0.034373
2021-12-14 02:39:56,764 iteration 2899 : loss : 0.069201, loss_ce: 0.019172
2021-12-14 02:39:58,206 iteration 2900 : loss : 0.061804, loss_ce: 0.015524
2021-12-14 02:39:59,846 iteration 2901 : loss : 0.062678, loss_ce: 0.015640
2021-12-14 02:40:01,230 iteration 2902 : loss : 0.062440, loss_ce: 0.015315
2021-12-14 02:40:02,789 iteration 2903 : loss : 0.071111, loss_ce: 0.023716
2021-12-14 02:40:04,378 iteration 2904 : loss : 0.110151, loss_ce: 0.029249
2021-12-14 02:40:05,886 iteration 2905 : loss : 0.060627, loss_ce: 0.016407
2021-12-14 02:40:07,482 iteration 2906 : loss : 0.065054, loss_ce: 0.020283
2021-12-14 02:40:08,958 iteration 2907 : loss : 0.056432, loss_ce: 0.018375
 43%|███████████▌               | 171/400 [1:21:14<1:49:33, 28.70s/it]2021-12-14 02:40:10,533 iteration 2908 : loss : 0.070747, loss_ce: 0.021748
2021-12-14 02:40:11,961 iteration 2909 : loss : 0.068919, loss_ce: 0.014424
2021-12-14 02:40:13,514 iteration 2910 : loss : 0.064095, loss_ce: 0.017622
2021-12-14 02:40:15,034 iteration 2911 : loss : 0.073779, loss_ce: 0.027818
2021-12-14 02:40:16,547 iteration 2912 : loss : 0.069595, loss_ce: 0.021766
2021-12-14 02:40:18,125 iteration 2913 : loss : 0.069439, loss_ce: 0.021256
2021-12-14 02:40:19,663 iteration 2914 : loss : 0.070109, loss_ce: 0.024250
2021-12-14 02:40:21,266 iteration 2915 : loss : 0.066866, loss_ce: 0.020165
2021-12-14 02:40:22,709 iteration 2916 : loss : 0.063050, loss_ce: 0.025706
2021-12-14 02:40:24,303 iteration 2917 : loss : 0.071873, loss_ce: 0.024907
2021-12-14 02:40:25,852 iteration 2918 : loss : 0.067230, loss_ce: 0.019632
2021-12-14 02:40:27,414 iteration 2919 : loss : 0.070859, loss_ce: 0.027848
2021-12-14 02:40:28,973 iteration 2920 : loss : 0.071156, loss_ce: 0.015283
2021-12-14 02:40:30,594 iteration 2921 : loss : 0.073704, loss_ce: 0.019089
2021-12-14 02:40:32,096 iteration 2922 : loss : 0.065517, loss_ce: 0.022202
2021-12-14 02:40:33,663 iteration 2923 : loss : 0.067624, loss_ce: 0.021904
2021-12-14 02:40:35,166 iteration 2924 : loss : 0.058627, loss_ce: 0.016338
 43%|███████████▌               | 172/400 [1:21:40<1:46:14, 27.96s/it]2021-12-14 02:40:36,858 iteration 2925 : loss : 0.076748, loss_ce: 0.026260
2021-12-14 02:40:38,345 iteration 2926 : loss : 0.065519, loss_ce: 0.017704
2021-12-14 02:40:39,947 iteration 2927 : loss : 0.066080, loss_ce: 0.023828
2021-12-14 02:40:41,629 iteration 2928 : loss : 0.065067, loss_ce: 0.015406
2021-12-14 02:40:43,126 iteration 2929 : loss : 0.058664, loss_ce: 0.016009
2021-12-14 02:40:44,609 iteration 2930 : loss : 0.068067, loss_ce: 0.021928
2021-12-14 02:40:46,032 iteration 2931 : loss : 0.067634, loss_ce: 0.022501
2021-12-14 02:40:47,647 iteration 2932 : loss : 0.058454, loss_ce: 0.017862
2021-12-14 02:40:49,151 iteration 2933 : loss : 0.080805, loss_ce: 0.024163
2021-12-14 02:40:50,737 iteration 2934 : loss : 0.066731, loss_ce: 0.023175
2021-12-14 02:40:52,275 iteration 2935 : loss : 0.065074, loss_ce: 0.016160
2021-12-14 02:40:53,892 iteration 2936 : loss : 0.074128, loss_ce: 0.026245
2021-12-14 02:40:55,401 iteration 2937 : loss : 0.057951, loss_ce: 0.018072
2021-12-14 02:40:56,923 iteration 2938 : loss : 0.060560, loss_ce: 0.018519
2021-12-14 02:40:58,416 iteration 2939 : loss : 0.068770, loss_ce: 0.023351
2021-12-14 02:40:59,993 iteration 2940 : loss : 0.065187, loss_ce: 0.016994
2021-12-14 02:41:01,499 iteration 2941 : loss : 0.062163, loss_ce: 0.016785
 43%|███████████▋               | 173/400 [1:22:06<1:43:55, 27.47s/it]2021-12-14 02:41:03,101 iteration 2942 : loss : 0.067011, loss_ce: 0.020241
2021-12-14 02:41:04,518 iteration 2943 : loss : 0.060431, loss_ce: 0.019233
2021-12-14 02:41:05,957 iteration 2944 : loss : 0.058673, loss_ce: 0.015515
2021-12-14 02:41:07,544 iteration 2945 : loss : 0.077057, loss_ce: 0.030081
2021-12-14 02:41:09,001 iteration 2946 : loss : 0.055309, loss_ce: 0.018090
2021-12-14 02:41:10,467 iteration 2947 : loss : 0.055434, loss_ce: 0.014544
2021-12-14 02:41:11,973 iteration 2948 : loss : 0.068535, loss_ce: 0.019820
2021-12-14 02:41:13,533 iteration 2949 : loss : 0.060386, loss_ce: 0.017652
2021-12-14 02:41:15,050 iteration 2950 : loss : 0.064307, loss_ce: 0.022250
2021-12-14 02:41:16,498 iteration 2951 : loss : 0.068363, loss_ce: 0.021580
2021-12-14 02:41:18,013 iteration 2952 : loss : 0.073076, loss_ce: 0.016876
2021-12-14 02:41:19,537 iteration 2953 : loss : 0.069770, loss_ce: 0.024547
2021-12-14 02:41:21,114 iteration 2954 : loss : 0.073491, loss_ce: 0.020472
2021-12-14 02:41:22,569 iteration 2955 : loss : 0.061835, loss_ce: 0.022228
2021-12-14 02:41:24,105 iteration 2956 : loss : 0.054893, loss_ce: 0.018689
2021-12-14 02:41:25,619 iteration 2957 : loss : 0.070788, loss_ce: 0.015416
2021-12-14 02:41:27,133 iteration 2958 : loss : 0.081902, loss_ce: 0.021877
 44%|███████████▋               | 174/400 [1:22:32<1:41:23, 26.92s/it]2021-12-14 02:41:28,817 iteration 2959 : loss : 0.061772, loss_ce: 0.023394
2021-12-14 02:41:30,363 iteration 2960 : loss : 0.065681, loss_ce: 0.019225
2021-12-14 02:41:31,954 iteration 2961 : loss : 0.059599, loss_ce: 0.021597
2021-12-14 02:41:33,414 iteration 2962 : loss : 0.060351, loss_ce: 0.015591
2021-12-14 02:41:34,920 iteration 2963 : loss : 0.080811, loss_ce: 0.023441
2021-12-14 02:41:36,519 iteration 2964 : loss : 0.073757, loss_ce: 0.024481
2021-12-14 02:41:38,059 iteration 2965 : loss : 0.066966, loss_ce: 0.023927
2021-12-14 02:41:39,552 iteration 2966 : loss : 0.078177, loss_ce: 0.023744
2021-12-14 02:41:41,173 iteration 2967 : loss : 0.068981, loss_ce: 0.020455
2021-12-14 02:41:42,708 iteration 2968 : loss : 0.074146, loss_ce: 0.022033
2021-12-14 02:41:44,163 iteration 2969 : loss : 0.066800, loss_ce: 0.016789
2021-12-14 02:41:45,640 iteration 2970 : loss : 0.064760, loss_ce: 0.021211
2021-12-14 02:41:47,193 iteration 2971 : loss : 0.075285, loss_ce: 0.024938
2021-12-14 02:41:48,752 iteration 2972 : loss : 0.066821, loss_ce: 0.019640
2021-12-14 02:41:50,266 iteration 2973 : loss : 0.070933, loss_ce: 0.023047
2021-12-14 02:41:51,932 iteration 2974 : loss : 0.096628, loss_ce: 0.032628
2021-12-14 02:41:51,932 Training Data Eval:
2021-12-14 02:41:59,355   Average segmentation loss on training set: 0.0547
2021-12-14 02:41:59,356 Validation Data Eval:
2021-12-14 02:42:01,920   Average segmentation loss on validation set: 0.0950
2021-12-14 02:42:03,398 iteration 2975 : loss : 0.075366, loss_ce: 0.019621
 44%|███████████▊               | 175/400 [1:23:08<1:51:28, 29.72s/it]2021-12-14 02:42:05,019 iteration 2976 : loss : 0.075000, loss_ce: 0.025098
2021-12-14 02:42:06,718 iteration 2977 : loss : 0.077295, loss_ce: 0.023354
2021-12-14 02:42:08,266 iteration 2978 : loss : 0.073720, loss_ce: 0.024793
2021-12-14 02:42:09,892 iteration 2979 : loss : 0.093403, loss_ce: 0.022312
2021-12-14 02:42:11,609 iteration 2980 : loss : 0.074480, loss_ce: 0.025958
2021-12-14 02:42:13,139 iteration 2981 : loss : 0.056270, loss_ce: 0.019528
2021-12-14 02:42:14,669 iteration 2982 : loss : 0.068473, loss_ce: 0.020249
2021-12-14 02:42:16,244 iteration 2983 : loss : 0.059892, loss_ce: 0.011498
2021-12-14 02:42:17,786 iteration 2984 : loss : 0.070994, loss_ce: 0.025080
2021-12-14 02:42:19,330 iteration 2985 : loss : 0.083083, loss_ce: 0.030679
2021-12-14 02:42:20,841 iteration 2986 : loss : 0.068426, loss_ce: 0.021671
2021-12-14 02:42:22,322 iteration 2987 : loss : 0.064466, loss_ce: 0.018695
2021-12-14 02:42:23,884 iteration 2988 : loss : 0.062246, loss_ce: 0.018707
2021-12-14 02:42:25,363 iteration 2989 : loss : 0.060476, loss_ce: 0.018956
2021-12-14 02:42:26,904 iteration 2990 : loss : 0.067562, loss_ce: 0.025798
2021-12-14 02:42:28,365 iteration 2991 : loss : 0.059936, loss_ce: 0.013939
2021-12-14 02:42:29,919 iteration 2992 : loss : 0.067199, loss_ce: 0.025311
 44%|███████████▉               | 176/400 [1:23:35<1:47:22, 28.76s/it]2021-12-14 02:42:31,526 iteration 2993 : loss : 0.055597, loss_ce: 0.017858
2021-12-14 02:42:33,041 iteration 2994 : loss : 0.061757, loss_ce: 0.019655
2021-12-14 02:42:34,627 iteration 2995 : loss : 0.079509, loss_ce: 0.028568
2021-12-14 02:42:36,093 iteration 2996 : loss : 0.067545, loss_ce: 0.019206
2021-12-14 02:42:37,611 iteration 2997 : loss : 0.062114, loss_ce: 0.016379
2021-12-14 02:42:39,172 iteration 2998 : loss : 0.059785, loss_ce: 0.022383
2021-12-14 02:42:40,687 iteration 2999 : loss : 0.067849, loss_ce: 0.020000
2021-12-14 02:42:42,191 iteration 3000 : loss : 0.066234, loss_ce: 0.020883
2021-12-14 02:42:43,830 iteration 3001 : loss : 0.070614, loss_ce: 0.024944
2021-12-14 02:42:45,413 iteration 3002 : loss : 0.070865, loss_ce: 0.021815
2021-12-14 02:42:46,851 iteration 3003 : loss : 0.057339, loss_ce: 0.017448
2021-12-14 02:42:48,364 iteration 3004 : loss : 0.061430, loss_ce: 0.022929
2021-12-14 02:42:49,845 iteration 3005 : loss : 0.057452, loss_ce: 0.019583
2021-12-14 02:42:51,343 iteration 3006 : loss : 0.069594, loss_ce: 0.020900
2021-12-14 02:42:52,882 iteration 3007 : loss : 0.060675, loss_ce: 0.016187
2021-12-14 02:42:54,332 iteration 3008 : loss : 0.059414, loss_ce: 0.017742
2021-12-14 02:42:55,794 iteration 3009 : loss : 0.066337, loss_ce: 0.014912
 44%|███████████▉               | 177/400 [1:24:01<1:43:39, 27.89s/it]2021-12-14 02:42:57,466 iteration 3010 : loss : 0.081284, loss_ce: 0.023145
2021-12-14 02:42:58,956 iteration 3011 : loss : 0.072542, loss_ce: 0.016951
2021-12-14 02:43:00,425 iteration 3012 : loss : 0.066306, loss_ce: 0.019970
2021-12-14 02:43:02,050 iteration 3013 : loss : 0.068263, loss_ce: 0.019116
2021-12-14 02:43:03,612 iteration 3014 : loss : 0.077865, loss_ce: 0.026627
2021-12-14 02:43:05,169 iteration 3015 : loss : 0.059789, loss_ce: 0.014942
2021-12-14 02:43:06,593 iteration 3016 : loss : 0.061877, loss_ce: 0.017082
2021-12-14 02:43:08,183 iteration 3017 : loss : 0.076959, loss_ce: 0.032391
2021-12-14 02:43:09,815 iteration 3018 : loss : 0.060626, loss_ce: 0.023621
2021-12-14 02:43:11,539 iteration 3019 : loss : 0.082365, loss_ce: 0.027627
2021-12-14 02:43:13,027 iteration 3020 : loss : 0.065850, loss_ce: 0.017718
2021-12-14 02:43:14,534 iteration 3021 : loss : 0.058983, loss_ce: 0.016681
2021-12-14 02:43:15,957 iteration 3022 : loss : 0.058542, loss_ce: 0.021340
2021-12-14 02:43:17,429 iteration 3023 : loss : 0.057507, loss_ce: 0.016303
2021-12-14 02:43:18,946 iteration 3024 : loss : 0.071408, loss_ce: 0.024875
2021-12-14 02:43:20,477 iteration 3025 : loss : 0.065849, loss_ce: 0.020918
2021-12-14 02:43:21,939 iteration 3026 : loss : 0.065597, loss_ce: 0.017480
 44%|████████████               | 178/400 [1:24:27<1:41:15, 27.37s/it]2021-12-14 02:43:23,503 iteration 3027 : loss : 0.066301, loss_ce: 0.024460
2021-12-14 02:43:25,153 iteration 3028 : loss : 0.062178, loss_ce: 0.017515
2021-12-14 02:43:26,639 iteration 3029 : loss : 0.052133, loss_ce: 0.011757
2021-12-14 02:43:28,257 iteration 3030 : loss : 0.062099, loss_ce: 0.016777
2021-12-14 02:43:29,873 iteration 3031 : loss : 0.078075, loss_ce: 0.020082
2021-12-14 02:43:31,486 iteration 3032 : loss : 0.061552, loss_ce: 0.019315
2021-12-14 02:43:33,038 iteration 3033 : loss : 0.075344, loss_ce: 0.022832
2021-12-14 02:43:34,528 iteration 3034 : loss : 0.056488, loss_ce: 0.014419
2021-12-14 02:43:35,967 iteration 3035 : loss : 0.060282, loss_ce: 0.019155
2021-12-14 02:43:37,546 iteration 3036 : loss : 0.063293, loss_ce: 0.022748
2021-12-14 02:43:39,003 iteration 3037 : loss : 0.060617, loss_ce: 0.021758
2021-12-14 02:43:40,425 iteration 3038 : loss : 0.059416, loss_ce: 0.021316
2021-12-14 02:43:41,870 iteration 3039 : loss : 0.062840, loss_ce: 0.020985
2021-12-14 02:43:43,493 iteration 3040 : loss : 0.076367, loss_ce: 0.018038
2021-12-14 02:43:44,880 iteration 3041 : loss : 0.058842, loss_ce: 0.017854
2021-12-14 02:43:46,329 iteration 3042 : loss : 0.057226, loss_ce: 0.020286
2021-12-14 02:43:47,782 iteration 3043 : loss : 0.061949, loss_ce: 0.020048
 45%|████████████               | 179/400 [1:24:53<1:39:07, 26.91s/it]2021-12-14 02:43:49,391 iteration 3044 : loss : 0.060129, loss_ce: 0.016862
2021-12-14 02:43:50,797 iteration 3045 : loss : 0.061743, loss_ce: 0.016350
2021-12-14 02:43:52,435 iteration 3046 : loss : 0.075063, loss_ce: 0.026812
2021-12-14 02:43:54,098 iteration 3047 : loss : 0.056457, loss_ce: 0.015842
2021-12-14 02:43:55,666 iteration 3048 : loss : 0.069350, loss_ce: 0.020949
2021-12-14 02:43:57,226 iteration 3049 : loss : 0.059733, loss_ce: 0.017436
2021-12-14 02:43:58,807 iteration 3050 : loss : 0.079576, loss_ce: 0.016276
2021-12-14 02:44:00,456 iteration 3051 : loss : 0.061650, loss_ce: 0.016621
2021-12-14 02:44:02,027 iteration 3052 : loss : 0.069432, loss_ce: 0.026888
2021-12-14 02:44:03,448 iteration 3053 : loss : 0.056408, loss_ce: 0.016168
2021-12-14 02:44:04,939 iteration 3054 : loss : 0.066325, loss_ce: 0.022762
2021-12-14 02:44:06,373 iteration 3055 : loss : 0.082435, loss_ce: 0.024375
2021-12-14 02:44:07,791 iteration 3056 : loss : 0.056672, loss_ce: 0.014252
2021-12-14 02:44:09,477 iteration 3057 : loss : 0.080010, loss_ce: 0.027827
2021-12-14 02:44:10,945 iteration 3058 : loss : 0.062530, loss_ce: 0.017236
2021-12-14 02:44:12,405 iteration 3059 : loss : 0.062768, loss_ce: 0.026105
2021-12-14 02:44:12,405 Training Data Eval:
2021-12-14 02:44:19,855   Average segmentation loss on training set: 0.0521
2021-12-14 02:44:19,855 Validation Data Eval:
2021-12-14 02:44:22,422   Average segmentation loss on validation set: 0.0959
2021-12-14 02:44:24,000 iteration 3060 : loss : 0.072749, loss_ce: 0.025691
 45%|████████████▏              | 180/400 [1:25:29<1:48:54, 29.70s/it]2021-12-14 02:44:25,592 iteration 3061 : loss : 0.062388, loss_ce: 0.015162
2021-12-14 02:44:27,159 iteration 3062 : loss : 0.078146, loss_ce: 0.029018
2021-12-14 02:44:28,654 iteration 3063 : loss : 0.057185, loss_ce: 0.018979
2021-12-14 02:44:30,184 iteration 3064 : loss : 0.068380, loss_ce: 0.027357
2021-12-14 02:44:31,762 iteration 3065 : loss : 0.061915, loss_ce: 0.015254
2021-12-14 02:44:33,231 iteration 3066 : loss : 0.059764, loss_ce: 0.014387
2021-12-14 02:44:34,852 iteration 3067 : loss : 0.067557, loss_ce: 0.023537
2021-12-14 02:44:36,496 iteration 3068 : loss : 0.069939, loss_ce: 0.024503
2021-12-14 02:44:37,949 iteration 3069 : loss : 0.047904, loss_ce: 0.012504
2021-12-14 02:44:39,486 iteration 3070 : loss : 0.068020, loss_ce: 0.018374
2021-12-14 02:44:41,199 iteration 3071 : loss : 0.076296, loss_ce: 0.022983
2021-12-14 02:44:42,706 iteration 3072 : loss : 0.060669, loss_ce: 0.021688
2021-12-14 02:44:44,214 iteration 3073 : loss : 0.064988, loss_ce: 0.017818
2021-12-14 02:44:45,715 iteration 3074 : loss : 0.068834, loss_ce: 0.023735
2021-12-14 02:44:47,262 iteration 3075 : loss : 0.066159, loss_ce: 0.018947
2021-12-14 02:44:48,716 iteration 3076 : loss : 0.053927, loss_ce: 0.015437
2021-12-14 02:44:50,339 iteration 3077 : loss : 0.086564, loss_ce: 0.023833
 45%|████████████▏              | 181/400 [1:25:55<1:44:43, 28.69s/it]2021-12-14 02:44:51,995 iteration 3078 : loss : 0.104426, loss_ce: 0.016111
2021-12-14 02:44:53,500 iteration 3079 : loss : 0.067583, loss_ce: 0.019636
2021-12-14 02:44:55,005 iteration 3080 : loss : 0.067859, loss_ce: 0.020107
2021-12-14 02:44:56,537 iteration 3081 : loss : 0.060148, loss_ce: 0.019299
2021-12-14 02:44:58,066 iteration 3082 : loss : 0.067689, loss_ce: 0.021437
2021-12-14 02:44:59,582 iteration 3083 : loss : 0.080311, loss_ce: 0.022307
2021-12-14 02:45:01,139 iteration 3084 : loss : 0.077244, loss_ce: 0.028033
2021-12-14 02:45:02,590 iteration 3085 : loss : 0.060733, loss_ce: 0.019816
2021-12-14 02:45:04,090 iteration 3086 : loss : 0.072719, loss_ce: 0.025044
2021-12-14 02:45:05,666 iteration 3087 : loss : 0.061562, loss_ce: 0.020773
2021-12-14 02:45:07,196 iteration 3088 : loss : 0.070964, loss_ce: 0.025989
2021-12-14 02:45:08,831 iteration 3089 : loss : 0.091120, loss_ce: 0.029836
2021-12-14 02:45:10,272 iteration 3090 : loss : 0.067502, loss_ce: 0.020954
2021-12-14 02:45:11,840 iteration 3091 : loss : 0.063897, loss_ce: 0.023082
2021-12-14 02:45:13,314 iteration 3092 : loss : 0.064083, loss_ce: 0.022389
2021-12-14 02:45:14,765 iteration 3093 : loss : 0.057669, loss_ce: 0.018122
2021-12-14 02:45:16,268 iteration 3094 : loss : 0.097555, loss_ce: 0.024881
 46%|████████████▎              | 182/400 [1:26:21<1:41:15, 27.87s/it]2021-12-14 02:45:17,890 iteration 3095 : loss : 0.057707, loss_ce: 0.018759
2021-12-14 02:45:19,420 iteration 3096 : loss : 0.060102, loss_ce: 0.018574
2021-12-14 02:45:20,957 iteration 3097 : loss : 0.063530, loss_ce: 0.023407
2021-12-14 02:45:22,526 iteration 3098 : loss : 0.076918, loss_ce: 0.020456
2021-12-14 02:45:24,104 iteration 3099 : loss : 0.073588, loss_ce: 0.026654
2021-12-14 02:45:25,632 iteration 3100 : loss : 0.065589, loss_ce: 0.019927
2021-12-14 02:45:27,117 iteration 3101 : loss : 0.052599, loss_ce: 0.014652
2021-12-14 02:45:28,523 iteration 3102 : loss : 0.060251, loss_ce: 0.019148
2021-12-14 02:45:30,105 iteration 3103 : loss : 0.073180, loss_ce: 0.025045
2021-12-14 02:45:31,591 iteration 3104 : loss : 0.068969, loss_ce: 0.019222
2021-12-14 02:45:33,183 iteration 3105 : loss : 0.061738, loss_ce: 0.019611
2021-12-14 02:45:34,712 iteration 3106 : loss : 0.055269, loss_ce: 0.016400
2021-12-14 02:45:36,329 iteration 3107 : loss : 0.059800, loss_ce: 0.017268
2021-12-14 02:45:37,889 iteration 3108 : loss : 0.072621, loss_ce: 0.022332
2021-12-14 02:45:39,331 iteration 3109 : loss : 0.067523, loss_ce: 0.023481
2021-12-14 02:45:40,810 iteration 3110 : loss : 0.062697, loss_ce: 0.018881
2021-12-14 02:45:42,331 iteration 3111 : loss : 0.078947, loss_ce: 0.016464
 46%|████████████▎              | 183/400 [1:26:47<1:38:50, 27.33s/it]2021-12-14 02:45:43,849 iteration 3112 : loss : 0.055782, loss_ce: 0.017266
2021-12-14 02:45:45,402 iteration 3113 : loss : 0.061761, loss_ce: 0.018561
2021-12-14 02:45:46,861 iteration 3114 : loss : 0.068072, loss_ce: 0.026648
2021-12-14 02:45:48,420 iteration 3115 : loss : 0.057876, loss_ce: 0.016306
2021-12-14 02:45:49,857 iteration 3116 : loss : 0.059904, loss_ce: 0.020387
2021-12-14 02:45:51,473 iteration 3117 : loss : 0.081570, loss_ce: 0.015663
2021-12-14 02:45:53,004 iteration 3118 : loss : 0.060073, loss_ce: 0.022548
2021-12-14 02:45:54,549 iteration 3119 : loss : 0.057364, loss_ce: 0.019510
2021-12-14 02:45:55,988 iteration 3120 : loss : 0.067128, loss_ce: 0.019453
2021-12-14 02:45:57,537 iteration 3121 : loss : 0.102096, loss_ce: 0.027726
2021-12-14 02:45:59,047 iteration 3122 : loss : 0.057412, loss_ce: 0.021329
2021-12-14 02:46:00,776 iteration 3123 : loss : 0.079580, loss_ce: 0.023616
2021-12-14 02:46:02,266 iteration 3124 : loss : 0.058472, loss_ce: 0.016579
2021-12-14 02:46:03,725 iteration 3125 : loss : 0.052994, loss_ce: 0.016985
2021-12-14 02:46:05,205 iteration 3126 : loss : 0.064470, loss_ce: 0.020524
2021-12-14 02:46:06,693 iteration 3127 : loss : 0.058098, loss_ce: 0.019422
2021-12-14 02:46:08,184 iteration 3128 : loss : 0.091370, loss_ce: 0.020282
 46%|████████████▍              | 184/400 [1:27:13<1:36:47, 26.88s/it]2021-12-14 02:46:09,726 iteration 3129 : loss : 0.081518, loss_ce: 0.023388
2021-12-14 02:46:11,212 iteration 3130 : loss : 0.058105, loss_ce: 0.016276
2021-12-14 02:46:12,788 iteration 3131 : loss : 0.073090, loss_ce: 0.027922
2021-12-14 02:46:14,325 iteration 3132 : loss : 0.084569, loss_ce: 0.024817
2021-12-14 02:46:15,794 iteration 3133 : loss : 0.060113, loss_ce: 0.020129
2021-12-14 02:46:17,365 iteration 3134 : loss : 0.060799, loss_ce: 0.018569
2021-12-14 02:46:18,929 iteration 3135 : loss : 0.073543, loss_ce: 0.013969
2021-12-14 02:46:20,370 iteration 3136 : loss : 0.059812, loss_ce: 0.021893
2021-12-14 02:46:21,836 iteration 3137 : loss : 0.053038, loss_ce: 0.018001
2021-12-14 02:46:23,317 iteration 3138 : loss : 0.060737, loss_ce: 0.019093
2021-12-14 02:46:25,003 iteration 3139 : loss : 0.071960, loss_ce: 0.018408
2021-12-14 02:46:26,592 iteration 3140 : loss : 0.058062, loss_ce: 0.017276
2021-12-14 02:46:28,103 iteration 3141 : loss : 0.064855, loss_ce: 0.023972
2021-12-14 02:46:29,534 iteration 3142 : loss : 0.055916, loss_ce: 0.015885
2021-12-14 02:46:31,081 iteration 3143 : loss : 0.076036, loss_ce: 0.019215
2021-12-14 02:46:32,688 iteration 3144 : loss : 0.065894, loss_ce: 0.013050
2021-12-14 02:46:32,688 Training Data Eval:
2021-12-14 02:46:40,131   Average segmentation loss on training set: 0.0540
2021-12-14 02:46:40,132 Validation Data Eval:
2021-12-14 02:46:42,696   Average segmentation loss on validation set: 0.0875
2021-12-14 02:46:48,760 Found new lowest validation loss at iteration 3144! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 02:46:50,211 iteration 3145 : loss : 0.058141, loss_ce: 0.019014
 46%|████████████▍              | 185/400 [1:27:55<1:52:36, 31.43s/it]2021-12-14 02:46:51,910 iteration 3146 : loss : 0.067738, loss_ce: 0.020428
2021-12-14 02:46:53,520 iteration 3147 : loss : 0.075395, loss_ce: 0.026303
2021-12-14 02:46:54,959 iteration 3148 : loss : 0.057228, loss_ce: 0.016970
2021-12-14 02:46:56,480 iteration 3149 : loss : 0.067578, loss_ce: 0.016862
2021-12-14 02:46:58,016 iteration 3150 : loss : 0.081219, loss_ce: 0.019688
2021-12-14 02:46:59,430 iteration 3151 : loss : 0.057074, loss_ce: 0.020684
2021-12-14 02:47:00,999 iteration 3152 : loss : 0.060101, loss_ce: 0.022412
2021-12-14 02:47:02,503 iteration 3153 : loss : 0.058936, loss_ce: 0.022025
2021-12-14 02:47:04,039 iteration 3154 : loss : 0.061112, loss_ce: 0.013831
2021-12-14 02:47:05,581 iteration 3155 : loss : 0.054568, loss_ce: 0.015631
2021-12-14 02:47:07,139 iteration 3156 : loss : 0.057231, loss_ce: 0.017102
2021-12-14 02:47:08,566 iteration 3157 : loss : 0.062760, loss_ce: 0.016339
2021-12-14 02:47:10,171 iteration 3158 : loss : 0.060074, loss_ce: 0.018849
2021-12-14 02:47:11,688 iteration 3159 : loss : 0.064519, loss_ce: 0.023806
2021-12-14 02:47:13,198 iteration 3160 : loss : 0.062519, loss_ce: 0.021845
2021-12-14 02:47:14,829 iteration 3161 : loss : 0.072986, loss_ce: 0.023895
2021-12-14 02:47:16,483 iteration 3162 : loss : 0.058697, loss_ce: 0.020717
 46%|████████████▌              | 186/400 [1:28:21<1:46:34, 29.88s/it]2021-12-14 02:47:18,007 iteration 3163 : loss : 0.057511, loss_ce: 0.013786
2021-12-14 02:47:19,477 iteration 3164 : loss : 0.062172, loss_ce: 0.016889
2021-12-14 02:47:20,962 iteration 3165 : loss : 0.048683, loss_ce: 0.015225
2021-12-14 02:47:22,488 iteration 3166 : loss : 0.073061, loss_ce: 0.027308
2021-12-14 02:47:24,029 iteration 3167 : loss : 0.101930, loss_ce: 0.033980
2021-12-14 02:47:25,479 iteration 3168 : loss : 0.055410, loss_ce: 0.019598
2021-12-14 02:47:26,999 iteration 3169 : loss : 0.058030, loss_ce: 0.014692
2021-12-14 02:47:28,575 iteration 3170 : loss : 0.061666, loss_ce: 0.022605
2021-12-14 02:47:30,190 iteration 3171 : loss : 0.065740, loss_ce: 0.017309
2021-12-14 02:47:31,759 iteration 3172 : loss : 0.072383, loss_ce: 0.025389
2021-12-14 02:47:33,320 iteration 3173 : loss : 0.070829, loss_ce: 0.024587
2021-12-14 02:47:34,919 iteration 3174 : loss : 0.069038, loss_ce: 0.021740
2021-12-14 02:47:36,444 iteration 3175 : loss : 0.060788, loss_ce: 0.019696
2021-12-14 02:47:38,005 iteration 3176 : loss : 0.062693, loss_ce: 0.024369
2021-12-14 02:47:39,470 iteration 3177 : loss : 0.060714, loss_ce: 0.022555
2021-12-14 02:47:41,007 iteration 3178 : loss : 0.071691, loss_ce: 0.019422
2021-12-14 02:47:42,575 iteration 3179 : loss : 0.079584, loss_ce: 0.019503
 47%|████████████▌              | 187/400 [1:28:47<1:42:02, 28.75s/it]2021-12-14 02:47:44,243 iteration 3180 : loss : 0.058496, loss_ce: 0.019377
2021-12-14 02:47:45,778 iteration 3181 : loss : 0.060973, loss_ce: 0.020444
2021-12-14 02:47:47,376 iteration 3182 : loss : 0.059585, loss_ce: 0.017095
2021-12-14 02:47:48,965 iteration 3183 : loss : 0.062427, loss_ce: 0.022923
2021-12-14 02:47:50,381 iteration 3184 : loss : 0.053909, loss_ce: 0.018970
2021-12-14 02:47:51,824 iteration 3185 : loss : 0.058960, loss_ce: 0.020539
2021-12-14 02:47:53,297 iteration 3186 : loss : 0.061280, loss_ce: 0.023971
2021-12-14 02:47:54,738 iteration 3187 : loss : 0.053998, loss_ce: 0.015298
2021-12-14 02:47:56,239 iteration 3188 : loss : 0.058568, loss_ce: 0.015056
2021-12-14 02:47:57,677 iteration 3189 : loss : 0.054587, loss_ce: 0.019854
2021-12-14 02:47:59,270 iteration 3190 : loss : 0.092166, loss_ce: 0.027595
2021-12-14 02:48:00,823 iteration 3191 : loss : 0.062267, loss_ce: 0.015928
2021-12-14 02:48:02,341 iteration 3192 : loss : 0.053649, loss_ce: 0.016700
2021-12-14 02:48:03,799 iteration 3193 : loss : 0.056419, loss_ce: 0.019453
2021-12-14 02:48:05,223 iteration 3194 : loss : 0.061186, loss_ce: 0.017318
2021-12-14 02:48:06,722 iteration 3195 : loss : 0.063714, loss_ce: 0.015273
2021-12-14 02:48:08,296 iteration 3196 : loss : 0.070645, loss_ce: 0.016679
 47%|████████████▋              | 188/400 [1:29:13<1:38:21, 27.83s/it]2021-12-14 02:48:09,845 iteration 3197 : loss : 0.061393, loss_ce: 0.016294
2021-12-14 02:48:11,310 iteration 3198 : loss : 0.074151, loss_ce: 0.021732
2021-12-14 02:48:12,744 iteration 3199 : loss : 0.057033, loss_ce: 0.018548
2021-12-14 02:48:14,217 iteration 3200 : loss : 0.061620, loss_ce: 0.020172
2021-12-14 02:48:15,772 iteration 3201 : loss : 0.081802, loss_ce: 0.023913
2021-12-14 02:48:17,322 iteration 3202 : loss : 0.060176, loss_ce: 0.020208
2021-12-14 02:48:18,739 iteration 3203 : loss : 0.092881, loss_ce: 0.019925
2021-12-14 02:48:20,271 iteration 3204 : loss : 0.061214, loss_ce: 0.023457
2021-12-14 02:48:21,819 iteration 3205 : loss : 0.056894, loss_ce: 0.015497
2021-12-14 02:48:23,277 iteration 3206 : loss : 0.065036, loss_ce: 0.021087
2021-12-14 02:48:24,730 iteration 3207 : loss : 0.061313, loss_ce: 0.015652
2021-12-14 02:48:26,192 iteration 3208 : loss : 0.060419, loss_ce: 0.017580
2021-12-14 02:48:27,749 iteration 3209 : loss : 0.051032, loss_ce: 0.015796
2021-12-14 02:48:29,278 iteration 3210 : loss : 0.069691, loss_ce: 0.020190
2021-12-14 02:48:30,856 iteration 3211 : loss : 0.061308, loss_ce: 0.022761
2021-12-14 02:48:32,427 iteration 3212 : loss : 0.063127, loss_ce: 0.023623
2021-12-14 02:48:33,935 iteration 3213 : loss : 0.065270, loss_ce: 0.025611
 47%|████████████▊              | 189/400 [1:29:39<1:35:34, 27.18s/it]2021-12-14 02:48:35,496 iteration 3214 : loss : 0.056740, loss_ce: 0.018583
2021-12-14 02:48:36,962 iteration 3215 : loss : 0.055981, loss_ce: 0.018892
2021-12-14 02:48:38,452 iteration 3216 : loss : 0.067509, loss_ce: 0.022301
2021-12-14 02:48:40,014 iteration 3217 : loss : 0.068328, loss_ce: 0.015363
2021-12-14 02:48:41,463 iteration 3218 : loss : 0.061379, loss_ce: 0.021177
2021-12-14 02:48:42,935 iteration 3219 : loss : 0.054861, loss_ce: 0.014751
2021-12-14 02:48:44,476 iteration 3220 : loss : 0.071584, loss_ce: 0.028830
2021-12-14 02:48:46,029 iteration 3221 : loss : 0.071154, loss_ce: 0.020895
2021-12-14 02:48:47,475 iteration 3222 : loss : 0.052996, loss_ce: 0.014735
2021-12-14 02:48:49,017 iteration 3223 : loss : 0.090661, loss_ce: 0.021268
2021-12-14 02:48:50,518 iteration 3224 : loss : 0.052357, loss_ce: 0.014769
2021-12-14 02:48:51,941 iteration 3225 : loss : 0.057400, loss_ce: 0.017598
2021-12-14 02:48:53,445 iteration 3226 : loss : 0.056424, loss_ce: 0.019333
2021-12-14 02:48:54,964 iteration 3227 : loss : 0.067101, loss_ce: 0.021413
2021-12-14 02:48:56,465 iteration 3228 : loss : 0.067500, loss_ce: 0.023663
2021-12-14 02:48:58,010 iteration 3229 : loss : 0.054777, loss_ce: 0.014297
2021-12-14 02:48:58,010 Training Data Eval:
2021-12-14 02:49:05,434   Average segmentation loss on training set: 0.0499
2021-12-14 02:49:05,435 Validation Data Eval:
2021-12-14 02:49:07,996   Average segmentation loss on validation set: 0.1053
2021-12-14 02:49:09,481 iteration 3230 : loss : 0.071399, loss_ce: 0.029550
 48%|████████████▊              | 190/400 [1:30:14<1:43:54, 29.69s/it]2021-12-14 02:49:10,927 iteration 3231 : loss : 0.056719, loss_ce: 0.016559
2021-12-14 02:49:12,463 iteration 3232 : loss : 0.058395, loss_ce: 0.020643
2021-12-14 02:49:13,988 iteration 3233 : loss : 0.068122, loss_ce: 0.017958
2021-12-14 02:49:15,468 iteration 3234 : loss : 0.059318, loss_ce: 0.018372
2021-12-14 02:49:16,998 iteration 3235 : loss : 0.055258, loss_ce: 0.018084
2021-12-14 02:49:18,360 iteration 3236 : loss : 0.062883, loss_ce: 0.025392
2021-12-14 02:49:19,839 iteration 3237 : loss : 0.050615, loss_ce: 0.015765
2021-12-14 02:49:21,339 iteration 3238 : loss : 0.060194, loss_ce: 0.019124
2021-12-14 02:49:22,745 iteration 3239 : loss : 0.057296, loss_ce: 0.019450
2021-12-14 02:49:24,315 iteration 3240 : loss : 0.074216, loss_ce: 0.023897
2021-12-14 02:49:25,943 iteration 3241 : loss : 0.076550, loss_ce: 0.023466
2021-12-14 02:49:27,469 iteration 3242 : loss : 0.056269, loss_ce: 0.016055
2021-12-14 02:49:29,041 iteration 3243 : loss : 0.064029, loss_ce: 0.021522
2021-12-14 02:49:30,500 iteration 3244 : loss : 0.064025, loss_ce: 0.018038
2021-12-14 02:49:32,039 iteration 3245 : loss : 0.069326, loss_ce: 0.019678
2021-12-14 02:49:33,592 iteration 3246 : loss : 0.067115, loss_ce: 0.019647
2021-12-14 02:49:35,253 iteration 3247 : loss : 0.070861, loss_ce: 0.021832
 48%|████████████▉              | 191/400 [1:30:40<1:39:19, 28.51s/it]2021-12-14 02:49:36,908 iteration 3248 : loss : 0.080779, loss_ce: 0.019585
2021-12-14 02:49:38,475 iteration 3249 : loss : 0.055629, loss_ce: 0.016013
2021-12-14 02:49:40,002 iteration 3250 : loss : 0.067273, loss_ce: 0.017864
2021-12-14 02:49:41,545 iteration 3251 : loss : 0.056516, loss_ce: 0.015647
2021-12-14 02:49:42,931 iteration 3252 : loss : 0.055895, loss_ce: 0.020838
2021-12-14 02:49:44,423 iteration 3253 : loss : 0.072209, loss_ce: 0.018783
2021-12-14 02:49:45,994 iteration 3254 : loss : 0.070283, loss_ce: 0.027693
2021-12-14 02:49:47,534 iteration 3255 : loss : 0.064733, loss_ce: 0.019992
2021-12-14 02:49:49,095 iteration 3256 : loss : 0.063060, loss_ce: 0.020443
2021-12-14 02:49:50,627 iteration 3257 : loss : 0.062832, loss_ce: 0.018927
2021-12-14 02:49:52,085 iteration 3258 : loss : 0.055383, loss_ce: 0.013283
2021-12-14 02:49:53,606 iteration 3259 : loss : 0.058113, loss_ce: 0.016840
2021-12-14 02:49:55,154 iteration 3260 : loss : 0.062639, loss_ce: 0.021059
2021-12-14 02:49:56,666 iteration 3261 : loss : 0.058764, loss_ce: 0.017592
2021-12-14 02:49:58,304 iteration 3262 : loss : 0.066918, loss_ce: 0.021079
2021-12-14 02:49:59,786 iteration 3263 : loss : 0.064787, loss_ce: 0.019607
2021-12-14 02:50:01,396 iteration 3264 : loss : 0.077786, loss_ce: 0.025121
 48%|████████████▉              | 192/400 [1:31:06<1:36:22, 27.80s/it]2021-12-14 02:50:02,931 iteration 3265 : loss : 0.067580, loss_ce: 0.021022
2021-12-14 02:50:04,486 iteration 3266 : loss : 0.050592, loss_ce: 0.013254
2021-12-14 02:50:06,013 iteration 3267 : loss : 0.055170, loss_ce: 0.014444
2021-12-14 02:50:07,549 iteration 3268 : loss : 0.074555, loss_ce: 0.022759
2021-12-14 02:50:09,014 iteration 3269 : loss : 0.057882, loss_ce: 0.023651
2021-12-14 02:50:10,515 iteration 3270 : loss : 0.057952, loss_ce: 0.018115
2021-12-14 02:50:11,918 iteration 3271 : loss : 0.062819, loss_ce: 0.017370
2021-12-14 02:50:13,532 iteration 3272 : loss : 0.063276, loss_ce: 0.021209
2021-12-14 02:50:15,031 iteration 3273 : loss : 0.061022, loss_ce: 0.021011
2021-12-14 02:50:16,441 iteration 3274 : loss : 0.077348, loss_ce: 0.024655
2021-12-14 02:50:17,929 iteration 3275 : loss : 0.065796, loss_ce: 0.017914
2021-12-14 02:50:19,418 iteration 3276 : loss : 0.057747, loss_ce: 0.013806
2021-12-14 02:50:20,843 iteration 3277 : loss : 0.067891, loss_ce: 0.017683
2021-12-14 02:50:22,340 iteration 3278 : loss : 0.053251, loss_ce: 0.016245
2021-12-14 02:50:23,729 iteration 3279 : loss : 0.067325, loss_ce: 0.030811
2021-12-14 02:50:25,315 iteration 3280 : loss : 0.074361, loss_ce: 0.025395
2021-12-14 02:50:26,820 iteration 3281 : loss : 0.054713, loss_ce: 0.013805
 48%|█████████████              | 193/400 [1:31:32<1:33:27, 27.09s/it]2021-12-14 02:50:28,452 iteration 3282 : loss : 0.058250, loss_ce: 0.011954
2021-12-14 02:50:30,015 iteration 3283 : loss : 0.061395, loss_ce: 0.017642
2021-12-14 02:50:31,550 iteration 3284 : loss : 0.057338, loss_ce: 0.019505
2021-12-14 02:50:33,109 iteration 3285 : loss : 0.070792, loss_ce: 0.021098
2021-12-14 02:50:34,642 iteration 3286 : loss : 0.055559, loss_ce: 0.014364
2021-12-14 02:50:36,248 iteration 3287 : loss : 0.078862, loss_ce: 0.029513
2021-12-14 02:50:37,689 iteration 3288 : loss : 0.058775, loss_ce: 0.020481
2021-12-14 02:50:39,355 iteration 3289 : loss : 0.054879, loss_ce: 0.015995
2021-12-14 02:50:40,971 iteration 3290 : loss : 0.061316, loss_ce: 0.015757
2021-12-14 02:50:42,565 iteration 3291 : loss : 0.068259, loss_ce: 0.025313
2021-12-14 02:50:44,088 iteration 3292 : loss : 0.063960, loss_ce: 0.017356
2021-12-14 02:50:45,594 iteration 3293 : loss : 0.070240, loss_ce: 0.017780
2021-12-14 02:50:47,234 iteration 3294 : loss : 0.069104, loss_ce: 0.025127
2021-12-14 02:50:48,806 iteration 3295 : loss : 0.062258, loss_ce: 0.024137
2021-12-14 02:50:50,254 iteration 3296 : loss : 0.054919, loss_ce: 0.017197
2021-12-14 02:50:51,739 iteration 3297 : loss : 0.057108, loss_ce: 0.017906
2021-12-14 02:50:53,372 iteration 3298 : loss : 0.054588, loss_ce: 0.018802
 48%|█████████████              | 194/400 [1:31:58<1:32:26, 26.93s/it]2021-12-14 02:50:54,833 iteration 3299 : loss : 0.054685, loss_ce: 0.012642
2021-12-14 02:50:56,408 iteration 3300 : loss : 0.064003, loss_ce: 0.018126
2021-12-14 02:50:57,943 iteration 3301 : loss : 0.067720, loss_ce: 0.026841
2021-12-14 02:50:59,416 iteration 3302 : loss : 0.058393, loss_ce: 0.015748
2021-12-14 02:51:01,017 iteration 3303 : loss : 0.062583, loss_ce: 0.023240
2021-12-14 02:51:02,592 iteration 3304 : loss : 0.053612, loss_ce: 0.017472
2021-12-14 02:51:04,084 iteration 3305 : loss : 0.056024, loss_ce: 0.015520
2021-12-14 02:51:05,593 iteration 3306 : loss : 0.062418, loss_ce: 0.016126
2021-12-14 02:51:07,285 iteration 3307 : loss : 0.080187, loss_ce: 0.029610
2021-12-14 02:51:08,907 iteration 3308 : loss : 0.077723, loss_ce: 0.027478
2021-12-14 02:51:10,495 iteration 3309 : loss : 0.054392, loss_ce: 0.017389
2021-12-14 02:51:11,960 iteration 3310 : loss : 0.058943, loss_ce: 0.025189
2021-12-14 02:51:13,614 iteration 3311 : loss : 0.067662, loss_ce: 0.018250
2021-12-14 02:51:15,134 iteration 3312 : loss : 0.062399, loss_ce: 0.013669
2021-12-14 02:51:16,744 iteration 3313 : loss : 0.076135, loss_ce: 0.028560
2021-12-14 02:51:18,267 iteration 3314 : loss : 0.063765, loss_ce: 0.016404
2021-12-14 02:51:18,267 Training Data Eval:
2021-12-14 02:51:25,729   Average segmentation loss on training set: 0.0485
2021-12-14 02:51:25,730 Validation Data Eval:
2021-12-14 02:51:28,293   Average segmentation loss on validation set: 0.0879
2021-12-14 02:51:29,739 iteration 3315 : loss : 0.053400, loss_ce: 0.016530
 49%|█████████████▏             | 195/400 [1:32:34<1:41:41, 29.76s/it]2021-12-14 02:51:31,261 iteration 3316 : loss : 0.052648, loss_ce: 0.016502
2021-12-14 02:51:32,785 iteration 3317 : loss : 0.067381, loss_ce: 0.023540
2021-12-14 02:51:34,284 iteration 3318 : loss : 0.066342, loss_ce: 0.025627
2021-12-14 02:51:35,728 iteration 3319 : loss : 0.064398, loss_ce: 0.020479
2021-12-14 02:51:37,366 iteration 3320 : loss : 0.092262, loss_ce: 0.033393
2021-12-14 02:51:38,845 iteration 3321 : loss : 0.063519, loss_ce: 0.018685
2021-12-14 02:51:40,436 iteration 3322 : loss : 0.064406, loss_ce: 0.016072
2021-12-14 02:51:41,884 iteration 3323 : loss : 0.056744, loss_ce: 0.015876
2021-12-14 02:51:43,390 iteration 3324 : loss : 0.072544, loss_ce: 0.028044
2021-12-14 02:51:44,950 iteration 3325 : loss : 0.062772, loss_ce: 0.019261
2021-12-14 02:51:46,413 iteration 3326 : loss : 0.072027, loss_ce: 0.024676
2021-12-14 02:51:47,924 iteration 3327 : loss : 0.052170, loss_ce: 0.013158
2021-12-14 02:51:49,536 iteration 3328 : loss : 0.060161, loss_ce: 0.018139
2021-12-14 02:51:51,063 iteration 3329 : loss : 0.071483, loss_ce: 0.024408
2021-12-14 02:51:52,538 iteration 3330 : loss : 0.056530, loss_ce: 0.022603
2021-12-14 02:51:53,952 iteration 3331 : loss : 0.061533, loss_ce: 0.022009
2021-12-14 02:51:55,504 iteration 3332 : loss : 0.060400, loss_ce: 0.014734
 49%|█████████████▏             | 196/400 [1:33:00<1:37:06, 28.56s/it]2021-12-14 02:51:57,124 iteration 3333 : loss : 0.065787, loss_ce: 0.020352
2021-12-14 02:51:58,677 iteration 3334 : loss : 0.073917, loss_ce: 0.033546
2021-12-14 02:52:00,321 iteration 3335 : loss : 0.069078, loss_ce: 0.025805
2021-12-14 02:52:01,856 iteration 3336 : loss : 0.076907, loss_ce: 0.021040
2021-12-14 02:52:03,441 iteration 3337 : loss : 0.099237, loss_ce: 0.037696
2021-12-14 02:52:05,120 iteration 3338 : loss : 0.073524, loss_ce: 0.027824
2021-12-14 02:52:06,570 iteration 3339 : loss : 0.061108, loss_ce: 0.020464
2021-12-14 02:52:08,000 iteration 3340 : loss : 0.061341, loss_ce: 0.014176
2021-12-14 02:52:09,509 iteration 3341 : loss : 0.064926, loss_ce: 0.020497
2021-12-14 02:52:10,996 iteration 3342 : loss : 0.054874, loss_ce: 0.019141
2021-12-14 02:52:12,563 iteration 3343 : loss : 0.053766, loss_ce: 0.019852
2021-12-14 02:52:14,084 iteration 3344 : loss : 0.065677, loss_ce: 0.020495
2021-12-14 02:52:15,630 iteration 3345 : loss : 0.065298, loss_ce: 0.022647
2021-12-14 02:52:17,093 iteration 3346 : loss : 0.057030, loss_ce: 0.021394
2021-12-14 02:52:18,570 iteration 3347 : loss : 0.060530, loss_ce: 0.017697
2021-12-14 02:52:19,987 iteration 3348 : loss : 0.068491, loss_ce: 0.021117
2021-12-14 02:52:21,571 iteration 3349 : loss : 0.075142, loss_ce: 0.019775
 49%|█████████████▎             | 197/400 [1:33:26<1:34:06, 27.81s/it]2021-12-14 02:52:23,161 iteration 3350 : loss : 0.062745, loss_ce: 0.019858
2021-12-14 02:52:24,744 iteration 3351 : loss : 0.068153, loss_ce: 0.020713
2021-12-14 02:52:26,321 iteration 3352 : loss : 0.084956, loss_ce: 0.032908
2021-12-14 02:52:27,945 iteration 3353 : loss : 0.064764, loss_ce: 0.016696
2021-12-14 02:52:29,430 iteration 3354 : loss : 0.064132, loss_ce: 0.024689
2021-12-14 02:52:31,039 iteration 3355 : loss : 0.070721, loss_ce: 0.025047
2021-12-14 02:52:32,636 iteration 3356 : loss : 0.064905, loss_ce: 0.020057
2021-12-14 02:52:34,144 iteration 3357 : loss : 0.062547, loss_ce: 0.015100
2021-12-14 02:52:35,731 iteration 3358 : loss : 0.057248, loss_ce: 0.019682
2021-12-14 02:52:37,148 iteration 3359 : loss : 0.049971, loss_ce: 0.014145
2021-12-14 02:52:38,625 iteration 3360 : loss : 0.067544, loss_ce: 0.020640
2021-12-14 02:52:40,138 iteration 3361 : loss : 0.061522, loss_ce: 0.020334
2021-12-14 02:52:41,653 iteration 3362 : loss : 0.063690, loss_ce: 0.018628
2021-12-14 02:52:43,266 iteration 3363 : loss : 0.061560, loss_ce: 0.015480
2021-12-14 02:52:44,710 iteration 3364 : loss : 0.067145, loss_ce: 0.022273
2021-12-14 02:52:46,271 iteration 3365 : loss : 0.065737, loss_ce: 0.021368
2021-12-14 02:52:47,689 iteration 3366 : loss : 0.054393, loss_ce: 0.017812
 50%|█████████████▎             | 198/400 [1:33:52<1:31:55, 27.30s/it]2021-12-14 02:52:49,264 iteration 3367 : loss : 0.052258, loss_ce: 0.015829
2021-12-14 02:52:50,747 iteration 3368 : loss : 0.053448, loss_ce: 0.019186
2021-12-14 02:52:52,171 iteration 3369 : loss : 0.058178, loss_ce: 0.015550
2021-12-14 02:52:53,750 iteration 3370 : loss : 0.060058, loss_ce: 0.022729
2021-12-14 02:52:55,423 iteration 3371 : loss : 0.069347, loss_ce: 0.022060
2021-12-14 02:52:56,897 iteration 3372 : loss : 0.052518, loss_ce: 0.016879
2021-12-14 02:52:58,425 iteration 3373 : loss : 0.062314, loss_ce: 0.018555
2021-12-14 02:52:59,863 iteration 3374 : loss : 0.052101, loss_ce: 0.013841
2021-12-14 02:53:01,321 iteration 3375 : loss : 0.065989, loss_ce: 0.022294
2021-12-14 02:53:02,850 iteration 3376 : loss : 0.065639, loss_ce: 0.016154
2021-12-14 02:53:04,230 iteration 3377 : loss : 0.049439, loss_ce: 0.017013
2021-12-14 02:53:05,778 iteration 3378 : loss : 0.068393, loss_ce: 0.014982
2021-12-14 02:53:07,438 iteration 3379 : loss : 0.083554, loss_ce: 0.028987
2021-12-14 02:53:09,029 iteration 3380 : loss : 0.068574, loss_ce: 0.019346
2021-12-14 02:53:10,609 iteration 3381 : loss : 0.082333, loss_ce: 0.025233
2021-12-14 02:53:12,159 iteration 3382 : loss : 0.057358, loss_ce: 0.019612
2021-12-14 02:53:13,639 iteration 3383 : loss : 0.055095, loss_ce: 0.016712
 50%|█████████████▍             | 199/400 [1:34:18<1:30:06, 26.90s/it]2021-12-14 02:53:15,291 iteration 3384 : loss : 0.065544, loss_ce: 0.019416
2021-12-14 02:53:16,855 iteration 3385 : loss : 0.058089, loss_ce: 0.018551
2021-12-14 02:53:18,319 iteration 3386 : loss : 0.053204, loss_ce: 0.013621
2021-12-14 02:53:19,931 iteration 3387 : loss : 0.062577, loss_ce: 0.020465
2021-12-14 02:53:21,479 iteration 3388 : loss : 0.063232, loss_ce: 0.023379
2021-12-14 02:53:22,973 iteration 3389 : loss : 0.050416, loss_ce: 0.016629
2021-12-14 02:53:24,338 iteration 3390 : loss : 0.049981, loss_ce: 0.014956
2021-12-14 02:53:25,895 iteration 3391 : loss : 0.061416, loss_ce: 0.020826
2021-12-14 02:53:27,452 iteration 3392 : loss : 0.067282, loss_ce: 0.017125
2021-12-14 02:53:28,999 iteration 3393 : loss : 0.057882, loss_ce: 0.018926
2021-12-14 02:53:30,569 iteration 3394 : loss : 0.048253, loss_ce: 0.013521
2021-12-14 02:53:31,999 iteration 3395 : loss : 0.052548, loss_ce: 0.017607
2021-12-14 02:53:33,588 iteration 3396 : loss : 0.057294, loss_ce: 0.013605
2021-12-14 02:53:35,153 iteration 3397 : loss : 0.061018, loss_ce: 0.018422
2021-12-14 02:53:36,715 iteration 3398 : loss : 0.056028, loss_ce: 0.019499
2021-12-14 02:53:38,218 iteration 3399 : loss : 0.058840, loss_ce: 0.017666
2021-12-14 02:53:38,218 Training Data Eval:
2021-12-14 02:53:45,661   Average segmentation loss on training set: 0.0488
2021-12-14 02:53:45,662 Validation Data Eval:
2021-12-14 02:53:48,224   Average segmentation loss on validation set: 0.0947
2021-12-14 02:53:49,638 iteration 3400 : loss : 0.060711, loss_ce: 0.016814
 50%|█████████████▌             | 200/400 [1:34:54<1:38:45, 29.63s/it]2021-12-14 02:53:51,221 iteration 3401 : loss : 0.072916, loss_ce: 0.028397
2021-12-14 02:53:52,652 iteration 3402 : loss : 0.055748, loss_ce: 0.017778
2021-12-14 02:53:54,290 iteration 3403 : loss : 0.066563, loss_ce: 0.019013
2021-12-14 02:53:55,884 iteration 3404 : loss : 0.060742, loss_ce: 0.019206
2021-12-14 02:53:57,326 iteration 3405 : loss : 0.066460, loss_ce: 0.015776
2021-12-14 02:53:58,946 iteration 3406 : loss : 0.060604, loss_ce: 0.019644
2021-12-14 02:54:00,449 iteration 3407 : loss : 0.062855, loss_ce: 0.019733
2021-12-14 02:54:01,861 iteration 3408 : loss : 0.065366, loss_ce: 0.019619
2021-12-14 02:54:03,376 iteration 3409 : loss : 0.058600, loss_ce: 0.018446
2021-12-14 02:54:04,941 iteration 3410 : loss : 0.056940, loss_ce: 0.016170
2021-12-14 02:54:06,522 iteration 3411 : loss : 0.064968, loss_ce: 0.020655
2021-12-14 02:54:08,084 iteration 3412 : loss : 0.060836, loss_ce: 0.020806
2021-12-14 02:54:09,626 iteration 3413 : loss : 0.053840, loss_ce: 0.011888
2021-12-14 02:54:11,246 iteration 3414 : loss : 0.067471, loss_ce: 0.022468
2021-12-14 02:54:12,783 iteration 3415 : loss : 0.053068, loss_ce: 0.017495
2021-12-14 02:54:14,414 iteration 3416 : loss : 0.055064, loss_ce: 0.014881
2021-12-14 02:54:16,037 iteration 3417 : loss : 0.065843, loss_ce: 0.018160
 50%|█████████████▌             | 201/400 [1:35:21<1:35:02, 28.66s/it]2021-12-14 02:54:17,543 iteration 3418 : loss : 0.046193, loss_ce: 0.012296
2021-12-14 02:54:18,936 iteration 3419 : loss : 0.051696, loss_ce: 0.017554
2021-12-14 02:54:20,401 iteration 3420 : loss : 0.054587, loss_ce: 0.017131
2021-12-14 02:54:21,838 iteration 3421 : loss : 0.053425, loss_ce: 0.017397
2021-12-14 02:54:23,257 iteration 3422 : loss : 0.055729, loss_ce: 0.016709
2021-12-14 02:54:24,807 iteration 3423 : loss : 0.068079, loss_ce: 0.028471
2021-12-14 02:54:26,345 iteration 3424 : loss : 0.068595, loss_ce: 0.020716
2021-12-14 02:54:27,893 iteration 3425 : loss : 0.055192, loss_ce: 0.017641
2021-12-14 02:54:29,284 iteration 3426 : loss : 0.056064, loss_ce: 0.016830
2021-12-14 02:54:30,813 iteration 3427 : loss : 0.064999, loss_ce: 0.015409
2021-12-14 02:54:32,357 iteration 3428 : loss : 0.057149, loss_ce: 0.020333
2021-12-14 02:54:33,821 iteration 3429 : loss : 0.060207, loss_ce: 0.017680
2021-12-14 02:54:35,385 iteration 3430 : loss : 0.058946, loss_ce: 0.018613
2021-12-14 02:54:36,927 iteration 3431 : loss : 0.070713, loss_ce: 0.021862
2021-12-14 02:54:38,538 iteration 3432 : loss : 0.072621, loss_ce: 0.024787
2021-12-14 02:54:40,157 iteration 3433 : loss : 0.070399, loss_ce: 0.020316
2021-12-14 02:54:41,691 iteration 3434 : loss : 0.069197, loss_ce: 0.017623
 50%|█████████████▋             | 202/400 [1:35:46<1:31:35, 27.76s/it]2021-12-14 02:54:43,254 iteration 3435 : loss : 0.058136, loss_ce: 0.015943
2021-12-14 02:54:44,847 iteration 3436 : loss : 0.077730, loss_ce: 0.027168
2021-12-14 02:54:46,469 iteration 3437 : loss : 0.065426, loss_ce: 0.018932
2021-12-14 02:54:48,091 iteration 3438 : loss : 0.065372, loss_ce: 0.021725
2021-12-14 02:54:49,550 iteration 3439 : loss : 0.064731, loss_ce: 0.020732
2021-12-14 02:54:51,103 iteration 3440 : loss : 0.053038, loss_ce: 0.015935
2021-12-14 02:54:52,588 iteration 3441 : loss : 0.062524, loss_ce: 0.018121
2021-12-14 02:54:54,130 iteration 3442 : loss : 0.068110, loss_ce: 0.022524
2021-12-14 02:54:55,789 iteration 3443 : loss : 0.061829, loss_ce: 0.020365
2021-12-14 02:54:57,269 iteration 3444 : loss : 0.064683, loss_ce: 0.016675
2021-12-14 02:54:58,828 iteration 3445 : loss : 0.061356, loss_ce: 0.021430
2021-12-14 02:55:00,419 iteration 3446 : loss : 0.058563, loss_ce: 0.022064
2021-12-14 02:55:02,001 iteration 3447 : loss : 0.076154, loss_ce: 0.020083
2021-12-14 02:55:03,445 iteration 3448 : loss : 0.059622, loss_ce: 0.017981
2021-12-14 02:55:04,909 iteration 3449 : loss : 0.056202, loss_ce: 0.019469
2021-12-14 02:55:06,401 iteration 3450 : loss : 0.059193, loss_ce: 0.015545
2021-12-14 02:55:07,884 iteration 3451 : loss : 0.055343, loss_ce: 0.024686
 51%|█████████████▋             | 203/400 [1:36:13<1:29:36, 27.29s/it]2021-12-14 02:55:09,354 iteration 3452 : loss : 0.054672, loss_ce: 0.017304
2021-12-14 02:55:10,942 iteration 3453 : loss : 0.064819, loss_ce: 0.021629
2021-12-14 02:55:12,665 iteration 3454 : loss : 0.081960, loss_ce: 0.028569
2021-12-14 02:55:14,173 iteration 3455 : loss : 0.061301, loss_ce: 0.021414
2021-12-14 02:55:15,727 iteration 3456 : loss : 0.085602, loss_ce: 0.017736
2021-12-14 02:55:17,181 iteration 3457 : loss : 0.063044, loss_ce: 0.022607
2021-12-14 02:55:18,605 iteration 3458 : loss : 0.062780, loss_ce: 0.015344
2021-12-14 02:55:20,204 iteration 3459 : loss : 0.061198, loss_ce: 0.022532
2021-12-14 02:55:21,653 iteration 3460 : loss : 0.055082, loss_ce: 0.018508
2021-12-14 02:55:23,099 iteration 3461 : loss : 0.056002, loss_ce: 0.016336
2021-12-14 02:55:24,469 iteration 3462 : loss : 0.050765, loss_ce: 0.017993
2021-12-14 02:55:26,026 iteration 3463 : loss : 0.056018, loss_ce: 0.018750
2021-12-14 02:55:27,565 iteration 3464 : loss : 0.063390, loss_ce: 0.018225
2021-12-14 02:55:29,029 iteration 3465 : loss : 0.055001, loss_ce: 0.016648
2021-12-14 02:55:30,652 iteration 3466 : loss : 0.068898, loss_ce: 0.024417
2021-12-14 02:55:32,072 iteration 3467 : loss : 0.048634, loss_ce: 0.013624
2021-12-14 02:55:33,559 iteration 3468 : loss : 0.056687, loss_ce: 0.014399
 51%|█████████████▊             | 204/400 [1:36:38<1:27:33, 26.80s/it]2021-12-14 02:55:35,105 iteration 3469 : loss : 0.048669, loss_ce: 0.013172
2021-12-14 02:55:36,600 iteration 3470 : loss : 0.070565, loss_ce: 0.021506
2021-12-14 02:55:38,202 iteration 3471 : loss : 0.059068, loss_ce: 0.018462
2021-12-14 02:55:39,848 iteration 3472 : loss : 0.062898, loss_ce: 0.020524
2021-12-14 02:55:41,307 iteration 3473 : loss : 0.051316, loss_ce: 0.017855
2021-12-14 02:55:42,900 iteration 3474 : loss : 0.066824, loss_ce: 0.019689
2021-12-14 02:55:44,432 iteration 3475 : loss : 0.051721, loss_ce: 0.017762
2021-12-14 02:55:45,912 iteration 3476 : loss : 0.058358, loss_ce: 0.014810
2021-12-14 02:55:47,400 iteration 3477 : loss : 0.053511, loss_ce: 0.015469
2021-12-14 02:55:48,928 iteration 3478 : loss : 0.058957, loss_ce: 0.022210
2021-12-14 02:55:50,429 iteration 3479 : loss : 0.058881, loss_ce: 0.020330
2021-12-14 02:55:51,874 iteration 3480 : loss : 0.055753, loss_ce: 0.022996
2021-12-14 02:55:53,351 iteration 3481 : loss : 0.070548, loss_ce: 0.017847
2021-12-14 02:55:54,855 iteration 3482 : loss : 0.059138, loss_ce: 0.018496
2021-12-14 02:55:56,455 iteration 3483 : loss : 0.065605, loss_ce: 0.024410
2021-12-14 02:55:58,006 iteration 3484 : loss : 0.068865, loss_ce: 0.016621
2021-12-14 02:55:58,007 Training Data Eval:
2021-12-14 02:56:05,454   Average segmentation loss on training set: 0.0488
2021-12-14 02:56:05,455 Validation Data Eval:
2021-12-14 02:56:08,020   Average segmentation loss on validation set: 0.0954
2021-12-14 02:56:09,518 iteration 3485 : loss : 0.057549, loss_ce: 0.019394
 51%|█████████████▊             | 205/400 [1:37:14<1:36:02, 29.55s/it]2021-12-14 02:56:11,110 iteration 3486 : loss : 0.064361, loss_ce: 0.015593
2021-12-14 02:56:12,616 iteration 3487 : loss : 0.067537, loss_ce: 0.023206
2021-12-14 02:56:14,134 iteration 3488 : loss : 0.055944, loss_ce: 0.014284
2021-12-14 02:56:15,501 iteration 3489 : loss : 0.058567, loss_ce: 0.021366
2021-12-14 02:56:17,068 iteration 3490 : loss : 0.062980, loss_ce: 0.017755
2021-12-14 02:56:18,734 iteration 3491 : loss : 0.064747, loss_ce: 0.025254
2021-12-14 02:56:20,287 iteration 3492 : loss : 0.074392, loss_ce: 0.016412
2021-12-14 02:56:21,769 iteration 3493 : loss : 0.068364, loss_ce: 0.020937
2021-12-14 02:56:23,299 iteration 3494 : loss : 0.064746, loss_ce: 0.020181
2021-12-14 02:56:24,874 iteration 3495 : loss : 0.058426, loss_ce: 0.017505
2021-12-14 02:56:26,541 iteration 3496 : loss : 0.068232, loss_ce: 0.020180
2021-12-14 02:56:28,051 iteration 3497 : loss : 0.066076, loss_ce: 0.023136
2021-12-14 02:56:29,629 iteration 3498 : loss : 0.055705, loss_ce: 0.020017
2021-12-14 02:56:31,116 iteration 3499 : loss : 0.052145, loss_ce: 0.019762
2021-12-14 02:56:32,629 iteration 3500 : loss : 0.059785, loss_ce: 0.018410
2021-12-14 02:56:34,273 iteration 3501 : loss : 0.054176, loss_ce: 0.017239
2021-12-14 02:56:35,793 iteration 3502 : loss : 0.059332, loss_ce: 0.024148
 52%|█████████████▉             | 206/400 [1:37:41<1:32:21, 28.57s/it]2021-12-14 02:56:37,409 iteration 3503 : loss : 0.084156, loss_ce: 0.020526
2021-12-14 02:56:38,924 iteration 3504 : loss : 0.049640, loss_ce: 0.013205
2021-12-14 02:56:40,447 iteration 3505 : loss : 0.051192, loss_ce: 0.017558
2021-12-14 02:56:42,052 iteration 3506 : loss : 0.066198, loss_ce: 0.020181
2021-12-14 02:56:43,501 iteration 3507 : loss : 0.055722, loss_ce: 0.017637
2021-12-14 02:56:44,998 iteration 3508 : loss : 0.052884, loss_ce: 0.012172
2021-12-14 02:56:46,579 iteration 3509 : loss : 0.057911, loss_ce: 0.018483
2021-12-14 02:56:48,096 iteration 3510 : loss : 0.057865, loss_ce: 0.019825
2021-12-14 02:56:49,872 iteration 3511 : loss : 0.072311, loss_ce: 0.027007
2021-12-14 02:56:51,320 iteration 3512 : loss : 0.053684, loss_ce: 0.016589
2021-12-14 02:56:52,732 iteration 3513 : loss : 0.056606, loss_ce: 0.019713
2021-12-14 02:56:54,236 iteration 3514 : loss : 0.055946, loss_ce: 0.018504
2021-12-14 02:56:55,729 iteration 3515 : loss : 0.068108, loss_ce: 0.028216
2021-12-14 02:56:57,212 iteration 3516 : loss : 0.057219, loss_ce: 0.020839
2021-12-14 02:56:58,723 iteration 3517 : loss : 0.055551, loss_ce: 0.021756
2021-12-14 02:57:00,338 iteration 3518 : loss : 0.065908, loss_ce: 0.016801
2021-12-14 02:57:01,916 iteration 3519 : loss : 0.070526, loss_ce: 0.024963
 52%|█████████████▉             | 207/400 [1:38:07<1:29:32, 27.84s/it]2021-12-14 02:57:03,422 iteration 3520 : loss : 0.054376, loss_ce: 0.014791
2021-12-14 02:57:04,916 iteration 3521 : loss : 0.059650, loss_ce: 0.014106
2021-12-14 02:57:06,354 iteration 3522 : loss : 0.059326, loss_ce: 0.014212
2021-12-14 02:57:07,912 iteration 3523 : loss : 0.059808, loss_ce: 0.023810
2021-12-14 02:57:09,542 iteration 3524 : loss : 0.057407, loss_ce: 0.018026
2021-12-14 02:57:11,009 iteration 3525 : loss : 0.064149, loss_ce: 0.016990
2021-12-14 02:57:12,551 iteration 3526 : loss : 0.055060, loss_ce: 0.021881
2021-12-14 02:57:14,196 iteration 3527 : loss : 0.062568, loss_ce: 0.020837
2021-12-14 02:57:15,698 iteration 3528 : loss : 0.090691, loss_ce: 0.017498
2021-12-14 02:57:17,200 iteration 3529 : loss : 0.057493, loss_ce: 0.017076
2021-12-14 02:57:18,711 iteration 3530 : loss : 0.054965, loss_ce: 0.016527
2021-12-14 02:57:20,228 iteration 3531 : loss : 0.054642, loss_ce: 0.016834
2021-12-14 02:57:21,764 iteration 3532 : loss : 0.053175, loss_ce: 0.018997
2021-12-14 02:57:23,324 iteration 3533 : loss : 0.054945, loss_ce: 0.019775
2021-12-14 02:57:24,776 iteration 3534 : loss : 0.055972, loss_ce: 0.016265
2021-12-14 02:57:26,323 iteration 3535 : loss : 0.055334, loss_ce: 0.019082
2021-12-14 02:57:27,842 iteration 3536 : loss : 0.058776, loss_ce: 0.020702
 52%|██████████████             | 208/400 [1:38:33<1:27:13, 27.26s/it]2021-12-14 02:57:29,552 iteration 3537 : loss : 0.077998, loss_ce: 0.032748
2021-12-14 02:57:31,037 iteration 3538 : loss : 0.056797, loss_ce: 0.017906
2021-12-14 02:57:32,521 iteration 3539 : loss : 0.053447, loss_ce: 0.012904
2021-12-14 02:57:34,076 iteration 3540 : loss : 0.061290, loss_ce: 0.021717
2021-12-14 02:57:35,664 iteration 3541 : loss : 0.057463, loss_ce: 0.018189
2021-12-14 02:57:37,237 iteration 3542 : loss : 0.062310, loss_ce: 0.020561
2021-12-14 02:57:38,850 iteration 3543 : loss : 0.058499, loss_ce: 0.019079
2021-12-14 02:57:40,437 iteration 3544 : loss : 0.080254, loss_ce: 0.015079
2021-12-14 02:57:42,057 iteration 3545 : loss : 0.062917, loss_ce: 0.019097
2021-12-14 02:57:43,671 iteration 3546 : loss : 0.070515, loss_ce: 0.020835
2021-12-14 02:57:45,289 iteration 3547 : loss : 0.061670, loss_ce: 0.020186
2021-12-14 02:57:46,764 iteration 3548 : loss : 0.044504, loss_ce: 0.010234
2021-12-14 02:57:48,422 iteration 3549 : loss : 0.060340, loss_ce: 0.022962
2021-12-14 02:57:49,942 iteration 3550 : loss : 0.052045, loss_ce: 0.014287
2021-12-14 02:57:51,408 iteration 3551 : loss : 0.064025, loss_ce: 0.021383
2021-12-14 02:57:52,865 iteration 3552 : loss : 0.067538, loss_ce: 0.027377
2021-12-14 02:57:54,355 iteration 3553 : loss : 0.053003, loss_ce: 0.015394
 52%|██████████████             | 209/400 [1:38:59<1:26:04, 27.04s/it]2021-12-14 02:57:55,925 iteration 3554 : loss : 0.062104, loss_ce: 0.019966
2021-12-14 02:57:57,432 iteration 3555 : loss : 0.067385, loss_ce: 0.025096
2021-12-14 02:57:59,051 iteration 3556 : loss : 0.061484, loss_ce: 0.023217
2021-12-14 02:58:00,701 iteration 3557 : loss : 0.057148, loss_ce: 0.020525
2021-12-14 02:58:02,207 iteration 3558 : loss : 0.050194, loss_ce: 0.013918
2021-12-14 02:58:03,736 iteration 3559 : loss : 0.068518, loss_ce: 0.015170
2021-12-14 02:58:05,248 iteration 3560 : loss : 0.063389, loss_ce: 0.025063
2021-12-14 02:58:06,663 iteration 3561 : loss : 0.053255, loss_ce: 0.021846
2021-12-14 02:58:08,190 iteration 3562 : loss : 0.066361, loss_ce: 0.025894
2021-12-14 02:58:09,722 iteration 3563 : loss : 0.069274, loss_ce: 0.023721
2021-12-14 02:58:11,317 iteration 3564 : loss : 0.082253, loss_ce: 0.020283
2021-12-14 02:58:12,771 iteration 3565 : loss : 0.064977, loss_ce: 0.013477
2021-12-14 02:58:14,218 iteration 3566 : loss : 0.052402, loss_ce: 0.017236
2021-12-14 02:58:15,846 iteration 3567 : loss : 0.073063, loss_ce: 0.032381
2021-12-14 02:58:17,360 iteration 3568 : loss : 0.059431, loss_ce: 0.017143
2021-12-14 02:58:18,817 iteration 3569 : loss : 0.056274, loss_ce: 0.017662
2021-12-14 02:58:18,817 Training Data Eval:
2021-12-14 02:58:26,266   Average segmentation loss on training set: 0.0478
2021-12-14 02:58:26,267 Validation Data Eval:
2021-12-14 02:58:28,828   Average segmentation loss on validation set: 0.0962
2021-12-14 02:58:30,389 iteration 3570 : loss : 0.067867, loss_ce: 0.019183
 52%|██████████████▏            | 210/400 [1:39:35<1:34:09, 29.74s/it]2021-12-14 02:58:31,992 iteration 3571 : loss : 0.058102, loss_ce: 0.021779
2021-12-14 02:58:33,443 iteration 3572 : loss : 0.054346, loss_ce: 0.015380
2021-12-14 02:58:34,985 iteration 3573 : loss : 0.073554, loss_ce: 0.022726
2021-12-14 02:58:36,500 iteration 3574 : loss : 0.062205, loss_ce: 0.016262
2021-12-14 02:58:37,941 iteration 3575 : loss : 0.050531, loss_ce: 0.013753
2021-12-14 02:58:39,525 iteration 3576 : loss : 0.064469, loss_ce: 0.015987
2021-12-14 02:58:41,070 iteration 3577 : loss : 0.062373, loss_ce: 0.019235
2021-12-14 02:58:42,464 iteration 3578 : loss : 0.061970, loss_ce: 0.017022
2021-12-14 02:58:43,936 iteration 3579 : loss : 0.064069, loss_ce: 0.021400
2021-12-14 02:58:45,391 iteration 3580 : loss : 0.059130, loss_ce: 0.020038
2021-12-14 02:58:46,830 iteration 3581 : loss : 0.067388, loss_ce: 0.032111
2021-12-14 02:58:48,333 iteration 3582 : loss : 0.056675, loss_ce: 0.017649
2021-12-14 02:58:49,884 iteration 3583 : loss : 0.057385, loss_ce: 0.016873
2021-12-14 02:58:51,425 iteration 3584 : loss : 0.061295, loss_ce: 0.017738
2021-12-14 02:58:52,871 iteration 3585 : loss : 0.061481, loss_ce: 0.017491
2021-12-14 02:58:54,473 iteration 3586 : loss : 0.063621, loss_ce: 0.024621
2021-12-14 02:58:55,974 iteration 3587 : loss : 0.050116, loss_ce: 0.016152
 53%|██████████████▏            | 211/400 [1:40:01<1:29:45, 28.49s/it]2021-12-14 02:58:57,649 iteration 3588 : loss : 0.048153, loss_ce: 0.015078
2021-12-14 02:58:59,077 iteration 3589 : loss : 0.060059, loss_ce: 0.018650
2021-12-14 02:59:00,550 iteration 3590 : loss : 0.051017, loss_ce: 0.016469
2021-12-14 02:59:02,067 iteration 3591 : loss : 0.056825, loss_ce: 0.017105
2021-12-14 02:59:03,815 iteration 3592 : loss : 0.066658, loss_ce: 0.022520
2021-12-14 02:59:05,320 iteration 3593 : loss : 0.074092, loss_ce: 0.021461
2021-12-14 02:59:06,814 iteration 3594 : loss : 0.056515, loss_ce: 0.018397
2021-12-14 02:59:08,373 iteration 3595 : loss : 0.087443, loss_ce: 0.027158
2021-12-14 02:59:09,886 iteration 3596 : loss : 0.057258, loss_ce: 0.019753
2021-12-14 02:59:11,465 iteration 3597 : loss : 0.083344, loss_ce: 0.025868
2021-12-14 02:59:12,906 iteration 3598 : loss : 0.048589, loss_ce: 0.016326
2021-12-14 02:59:14,486 iteration 3599 : loss : 0.053830, loss_ce: 0.014721
2021-12-14 02:59:15,859 iteration 3600 : loss : 0.052974, loss_ce: 0.017355
2021-12-14 02:59:17,374 iteration 3601 : loss : 0.053521, loss_ce: 0.016297
2021-12-14 02:59:18,822 iteration 3602 : loss : 0.056433, loss_ce: 0.016672
2021-12-14 02:59:20,352 iteration 3603 : loss : 0.053391, loss_ce: 0.019654
2021-12-14 02:59:21,775 iteration 3604 : loss : 0.052592, loss_ce: 0.019264
 53%|██████████████▎            | 212/400 [1:40:27<1:26:45, 27.69s/it]2021-12-14 02:59:23,383 iteration 3605 : loss : 0.054527, loss_ce: 0.015386
2021-12-14 02:59:24,862 iteration 3606 : loss : 0.071201, loss_ce: 0.031434
2021-12-14 02:59:26,414 iteration 3607 : loss : 0.073003, loss_ce: 0.021848
2021-12-14 02:59:27,914 iteration 3608 : loss : 0.048469, loss_ce: 0.014907
2021-12-14 02:59:29,398 iteration 3609 : loss : 0.052029, loss_ce: 0.018966
2021-12-14 02:59:30,915 iteration 3610 : loss : 0.051532, loss_ce: 0.017240
2021-12-14 02:59:32,333 iteration 3611 : loss : 0.053714, loss_ce: 0.011305
2021-12-14 02:59:33,780 iteration 3612 : loss : 0.048777, loss_ce: 0.013023
2021-12-14 02:59:35,414 iteration 3613 : loss : 0.068080, loss_ce: 0.023538
2021-12-14 02:59:36,854 iteration 3614 : loss : 0.052908, loss_ce: 0.016001
2021-12-14 02:59:38,233 iteration 3615 : loss : 0.051777, loss_ce: 0.015711
2021-12-14 02:59:39,757 iteration 3616 : loss : 0.056266, loss_ce: 0.018853
2021-12-14 02:59:41,319 iteration 3617 : loss : 0.061624, loss_ce: 0.020616
2021-12-14 02:59:42,853 iteration 3618 : loss : 0.054815, loss_ce: 0.016281
2021-12-14 02:59:44,377 iteration 3619 : loss : 0.058822, loss_ce: 0.014899
2021-12-14 02:59:45,830 iteration 3620 : loss : 0.059160, loss_ce: 0.015971
2021-12-14 02:59:47,362 iteration 3621 : loss : 0.072437, loss_ce: 0.022388
 53%|██████████████▍            | 213/400 [1:40:52<1:24:18, 27.05s/it]2021-12-14 02:59:48,947 iteration 3622 : loss : 0.053769, loss_ce: 0.018677
2021-12-14 02:59:50,542 iteration 3623 : loss : 0.058338, loss_ce: 0.011851
2021-12-14 02:59:52,062 iteration 3624 : loss : 0.047433, loss_ce: 0.015739
2021-12-14 02:59:53,552 iteration 3625 : loss : 0.049455, loss_ce: 0.014305
2021-12-14 02:59:55,003 iteration 3626 : loss : 0.065054, loss_ce: 0.024213
2021-12-14 02:59:56,430 iteration 3627 : loss : 0.056102, loss_ce: 0.018252
2021-12-14 02:59:58,011 iteration 3628 : loss : 0.081088, loss_ce: 0.020258
2021-12-14 02:59:59,734 iteration 3629 : loss : 0.061425, loss_ce: 0.020224
2021-12-14 03:00:01,131 iteration 3630 : loss : 0.051316, loss_ce: 0.015883
2021-12-14 03:00:02,639 iteration 3631 : loss : 0.055973, loss_ce: 0.014823
2021-12-14 03:00:04,310 iteration 3632 : loss : 0.071057, loss_ce: 0.022487
2021-12-14 03:00:05,826 iteration 3633 : loss : 0.054879, loss_ce: 0.016812
2021-12-14 03:00:07,314 iteration 3634 : loss : 0.053049, loss_ce: 0.017190
2021-12-14 03:00:08,940 iteration 3635 : loss : 0.066414, loss_ce: 0.023712
2021-12-14 03:00:10,535 iteration 3636 : loss : 0.057778, loss_ce: 0.014470
2021-12-14 03:00:12,058 iteration 3637 : loss : 0.068297, loss_ce: 0.019084
2021-12-14 03:00:13,570 iteration 3638 : loss : 0.054560, loss_ce: 0.018461
 54%|██████████████▍            | 214/400 [1:41:18<1:23:04, 26.80s/it]2021-12-14 03:00:15,071 iteration 3639 : loss : 0.056303, loss_ce: 0.018206
2021-12-14 03:00:16,512 iteration 3640 : loss : 0.056278, loss_ce: 0.017913
2021-12-14 03:00:17,942 iteration 3641 : loss : 0.054088, loss_ce: 0.016207
2021-12-14 03:00:19,456 iteration 3642 : loss : 0.062982, loss_ce: 0.018993
2021-12-14 03:00:20,891 iteration 3643 : loss : 0.056214, loss_ce: 0.017090
2021-12-14 03:00:22,344 iteration 3644 : loss : 0.048251, loss_ce: 0.015192
2021-12-14 03:00:23,843 iteration 3645 : loss : 0.053589, loss_ce: 0.014860
2021-12-14 03:00:25,366 iteration 3646 : loss : 0.052483, loss_ce: 0.014767
2021-12-14 03:00:26,899 iteration 3647 : loss : 0.055697, loss_ce: 0.012398
2021-12-14 03:00:28,438 iteration 3648 : loss : 0.069440, loss_ce: 0.025412
2021-12-14 03:00:29,932 iteration 3649 : loss : 0.052045, loss_ce: 0.012629
2021-12-14 03:00:31,467 iteration 3650 : loss : 0.055230, loss_ce: 0.020672
2021-12-14 03:00:33,044 iteration 3651 : loss : 0.053005, loss_ce: 0.015707
2021-12-14 03:00:34,724 iteration 3652 : loss : 0.085905, loss_ce: 0.025746
2021-12-14 03:00:36,187 iteration 3653 : loss : 0.057119, loss_ce: 0.024802
2021-12-14 03:00:37,618 iteration 3654 : loss : 0.050016, loss_ce: 0.019082
2021-12-14 03:00:37,618 Training Data Eval:
2021-12-14 03:00:45,061   Average segmentation loss on training set: 0.0452
2021-12-14 03:00:45,061 Validation Data Eval:
2021-12-14 03:00:47,644   Average segmentation loss on validation set: 0.0926
2021-12-14 03:00:49,176 iteration 3655 : loss : 0.057629, loss_ce: 0.020553
 54%|██████████████▌            | 215/400 [1:41:54<1:30:47, 29.44s/it]2021-12-14 03:00:50,809 iteration 3656 : loss : 0.060399, loss_ce: 0.015441
2021-12-14 03:00:52,267 iteration 3657 : loss : 0.054466, loss_ce: 0.022238
2021-12-14 03:00:53,837 iteration 3658 : loss : 0.062867, loss_ce: 0.024461
2021-12-14 03:00:55,493 iteration 3659 : loss : 0.079460, loss_ce: 0.021779
2021-12-14 03:00:57,027 iteration 3660 : loss : 0.073900, loss_ce: 0.014954
2021-12-14 03:00:58,468 iteration 3661 : loss : 0.052186, loss_ce: 0.017051
2021-12-14 03:00:59,979 iteration 3662 : loss : 0.058352, loss_ce: 0.018616
2021-12-14 03:01:01,465 iteration 3663 : loss : 0.061110, loss_ce: 0.016874
2021-12-14 03:01:03,030 iteration 3664 : loss : 0.045079, loss_ce: 0.013283
2021-12-14 03:01:04,525 iteration 3665 : loss : 0.053329, loss_ce: 0.020161
2021-12-14 03:01:06,028 iteration 3666 : loss : 0.056826, loss_ce: 0.016626
2021-12-14 03:01:07,518 iteration 3667 : loss : 0.064942, loss_ce: 0.025378
2021-12-14 03:01:08,906 iteration 3668 : loss : 0.051209, loss_ce: 0.010197
2021-12-14 03:01:10,479 iteration 3669 : loss : 0.053493, loss_ce: 0.016033
2021-12-14 03:01:11,927 iteration 3670 : loss : 0.052710, loss_ce: 0.016600
2021-12-14 03:01:13,413 iteration 3671 : loss : 0.051223, loss_ce: 0.019684
2021-12-14 03:01:15,109 iteration 3672 : loss : 0.079783, loss_ce: 0.019406
 54%|██████████████▌            | 216/400 [1:42:20<1:27:03, 28.39s/it]2021-12-14 03:01:16,718 iteration 3673 : loss : 0.061833, loss_ce: 0.022675
2021-12-14 03:01:18,313 iteration 3674 : loss : 0.057762, loss_ce: 0.013304
2021-12-14 03:01:19,974 iteration 3675 : loss : 0.058322, loss_ce: 0.016401
2021-12-14 03:01:21,403 iteration 3676 : loss : 0.051449, loss_ce: 0.016591
2021-12-14 03:01:22,924 iteration 3677 : loss : 0.059397, loss_ce: 0.015336
2021-12-14 03:01:24,541 iteration 3678 : loss : 0.077668, loss_ce: 0.023305
2021-12-14 03:01:26,046 iteration 3679 : loss : 0.054814, loss_ce: 0.016653
2021-12-14 03:01:27,576 iteration 3680 : loss : 0.064441, loss_ce: 0.021536
2021-12-14 03:01:29,078 iteration 3681 : loss : 0.062075, loss_ce: 0.021419
2021-12-14 03:01:30,479 iteration 3682 : loss : 0.051521, loss_ce: 0.017418
2021-12-14 03:01:31,866 iteration 3683 : loss : 0.049322, loss_ce: 0.014163
2021-12-14 03:01:33,464 iteration 3684 : loss : 0.052495, loss_ce: 0.018446
2021-12-14 03:01:34,927 iteration 3685 : loss : 0.048323, loss_ce: 0.013788
2021-12-14 03:01:36,457 iteration 3686 : loss : 0.057089, loss_ce: 0.019108
2021-12-14 03:01:37,923 iteration 3687 : loss : 0.057521, loss_ce: 0.015337
2021-12-14 03:01:39,434 iteration 3688 : loss : 0.055387, loss_ce: 0.023065
2021-12-14 03:01:40,982 iteration 3689 : loss : 0.061614, loss_ce: 0.015439
 54%|██████████████▋            | 217/400 [1:42:46<1:24:16, 27.63s/it]2021-12-14 03:01:42,557 iteration 3690 : loss : 0.070224, loss_ce: 0.015549
2021-12-14 03:01:44,118 iteration 3691 : loss : 0.060524, loss_ce: 0.013218
2021-12-14 03:01:45,655 iteration 3692 : loss : 0.058982, loss_ce: 0.024005
2021-12-14 03:01:47,085 iteration 3693 : loss : 0.048604, loss_ce: 0.015455
2021-12-14 03:01:48,587 iteration 3694 : loss : 0.061005, loss_ce: 0.022980
2021-12-14 03:01:50,115 iteration 3695 : loss : 0.058467, loss_ce: 0.025541
2021-12-14 03:01:51,607 iteration 3696 : loss : 0.074872, loss_ce: 0.025966
2021-12-14 03:01:53,147 iteration 3697 : loss : 0.066861, loss_ce: 0.018844
2021-12-14 03:01:54,776 iteration 3698 : loss : 0.078883, loss_ce: 0.027183
2021-12-14 03:01:56,234 iteration 3699 : loss : 0.050774, loss_ce: 0.017093
2021-12-14 03:01:57,766 iteration 3700 : loss : 0.057905, loss_ce: 0.014462
2021-12-14 03:01:59,152 iteration 3701 : loss : 0.053995, loss_ce: 0.019486
2021-12-14 03:02:00,682 iteration 3702 : loss : 0.049683, loss_ce: 0.015100
2021-12-14 03:02:02,210 iteration 3703 : loss : 0.058466, loss_ce: 0.022498
2021-12-14 03:02:03,595 iteration 3704 : loss : 0.051557, loss_ce: 0.015410
2021-12-14 03:02:05,195 iteration 3705 : loss : 0.078953, loss_ce: 0.030115
2021-12-14 03:02:06,596 iteration 3706 : loss : 0.046020, loss_ce: 0.011485
 55%|██████████████▋            | 218/400 [1:43:11<1:21:58, 27.03s/it]2021-12-14 03:02:08,177 iteration 3707 : loss : 0.086169, loss_ce: 0.031246
2021-12-14 03:02:09,588 iteration 3708 : loss : 0.057576, loss_ce: 0.016701
2021-12-14 03:02:11,241 iteration 3709 : loss : 0.069271, loss_ce: 0.016976
2021-12-14 03:02:12,754 iteration 3710 : loss : 0.063935, loss_ce: 0.018023
2021-12-14 03:02:14,219 iteration 3711 : loss : 0.050208, loss_ce: 0.014945
2021-12-14 03:02:15,648 iteration 3712 : loss : 0.051661, loss_ce: 0.019229
2021-12-14 03:02:17,282 iteration 3713 : loss : 0.062391, loss_ce: 0.021900
2021-12-14 03:02:18,795 iteration 3714 : loss : 0.057318, loss_ce: 0.019072
2021-12-14 03:02:20,266 iteration 3715 : loss : 0.052395, loss_ce: 0.017949
2021-12-14 03:02:21,771 iteration 3716 : loss : 0.062541, loss_ce: 0.023711
2021-12-14 03:02:23,343 iteration 3717 : loss : 0.053279, loss_ce: 0.016389
2021-12-14 03:02:24,820 iteration 3718 : loss : 0.060078, loss_ce: 0.020011
2021-12-14 03:02:26,318 iteration 3719 : loss : 0.056418, loss_ce: 0.018952
2021-12-14 03:02:27,963 iteration 3720 : loss : 0.055657, loss_ce: 0.015736
2021-12-14 03:02:29,431 iteration 3721 : loss : 0.055563, loss_ce: 0.018205
2021-12-14 03:02:30,908 iteration 3722 : loss : 0.070897, loss_ce: 0.025995
2021-12-14 03:02:32,486 iteration 3723 : loss : 0.067586, loss_ce: 0.015217
 55%|██████████████▊            | 219/400 [1:43:37<1:20:30, 26.69s/it]2021-12-14 03:02:34,142 iteration 3724 : loss : 0.061945, loss_ce: 0.019416
2021-12-14 03:02:35,660 iteration 3725 : loss : 0.089022, loss_ce: 0.031888
2021-12-14 03:02:37,336 iteration 3726 : loss : 0.053116, loss_ce: 0.014331
2021-12-14 03:02:38,794 iteration 3727 : loss : 0.049978, loss_ce: 0.014455
2021-12-14 03:02:40,300 iteration 3728 : loss : 0.059849, loss_ce: 0.025402
2021-12-14 03:02:41,892 iteration 3729 : loss : 0.063114, loss_ce: 0.018144
2021-12-14 03:02:43,370 iteration 3730 : loss : 0.060940, loss_ce: 0.015744
2021-12-14 03:02:44,810 iteration 3731 : loss : 0.056235, loss_ce: 0.017335
2021-12-14 03:02:46,330 iteration 3732 : loss : 0.056109, loss_ce: 0.017226
2021-12-14 03:02:47,813 iteration 3733 : loss : 0.053979, loss_ce: 0.013889
2021-12-14 03:02:49,341 iteration 3734 : loss : 0.058400, loss_ce: 0.020381
2021-12-14 03:02:50,902 iteration 3735 : loss : 0.066402, loss_ce: 0.026126
2021-12-14 03:02:52,471 iteration 3736 : loss : 0.077739, loss_ce: 0.017707
2021-12-14 03:02:53,997 iteration 3737 : loss : 0.059917, loss_ce: 0.018386
2021-12-14 03:02:55,508 iteration 3738 : loss : 0.058073, loss_ce: 0.019456
2021-12-14 03:02:57,019 iteration 3739 : loss : 0.055558, loss_ce: 0.015451
2021-12-14 03:02:57,019 Training Data Eval:
2021-12-14 03:03:04,431   Average segmentation loss on training set: 0.0448
2021-12-14 03:03:04,432 Validation Data Eval:
2021-12-14 03:03:06,997   Average segmentation loss on validation set: 0.0951
2021-12-14 03:03:08,573 iteration 3740 : loss : 0.052077, loss_ce: 0.014320
 55%|██████████████▊            | 220/400 [1:44:13<1:28:31, 29.51s/it]2021-12-14 03:03:10,179 iteration 3741 : loss : 0.054542, loss_ce: 0.018497
2021-12-14 03:03:11,636 iteration 3742 : loss : 0.060057, loss_ce: 0.022579
2021-12-14 03:03:13,121 iteration 3743 : loss : 0.058108, loss_ce: 0.015999
2021-12-14 03:03:14,648 iteration 3744 : loss : 0.057903, loss_ce: 0.019618
2021-12-14 03:03:16,087 iteration 3745 : loss : 0.052063, loss_ce: 0.017755
2021-12-14 03:03:17,653 iteration 3746 : loss : 0.054756, loss_ce: 0.017246
2021-12-14 03:03:19,222 iteration 3747 : loss : 0.067316, loss_ce: 0.011109
2021-12-14 03:03:20,759 iteration 3748 : loss : 0.069037, loss_ce: 0.025142
2021-12-14 03:03:22,261 iteration 3749 : loss : 0.057528, loss_ce: 0.019663
2021-12-14 03:03:23,800 iteration 3750 : loss : 0.064131, loss_ce: 0.023042
2021-12-14 03:03:25,353 iteration 3751 : loss : 0.061982, loss_ce: 0.013951
2021-12-14 03:03:26,866 iteration 3752 : loss : 0.056668, loss_ce: 0.020526
2021-12-14 03:03:28,308 iteration 3753 : loss : 0.061374, loss_ce: 0.014858
2021-12-14 03:03:29,740 iteration 3754 : loss : 0.052824, loss_ce: 0.013529
2021-12-14 03:03:31,201 iteration 3755 : loss : 0.053527, loss_ce: 0.018753
2021-12-14 03:03:32,697 iteration 3756 : loss : 0.060232, loss_ce: 0.018370
2021-12-14 03:03:34,225 iteration 3757 : loss : 0.060786, loss_ce: 0.018144
 55%|██████████████▉            | 221/400 [1:44:39<1:24:34, 28.35s/it]2021-12-14 03:03:35,842 iteration 3758 : loss : 0.072383, loss_ce: 0.026077
2021-12-14 03:03:37,352 iteration 3759 : loss : 0.049854, loss_ce: 0.015696
2021-12-14 03:03:38,746 iteration 3760 : loss : 0.052406, loss_ce: 0.014330
2021-12-14 03:03:40,336 iteration 3761 : loss : 0.067162, loss_ce: 0.022051
2021-12-14 03:03:41,841 iteration 3762 : loss : 0.055396, loss_ce: 0.015870
2021-12-14 03:03:43,421 iteration 3763 : loss : 0.064883, loss_ce: 0.019833
2021-12-14 03:03:45,009 iteration 3764 : loss : 0.060421, loss_ce: 0.019647
2021-12-14 03:03:46,526 iteration 3765 : loss : 0.054557, loss_ce: 0.018154
2021-12-14 03:03:48,020 iteration 3766 : loss : 0.056476, loss_ce: 0.016627
2021-12-14 03:03:49,631 iteration 3767 : loss : 0.065477, loss_ce: 0.017315
2021-12-14 03:03:51,173 iteration 3768 : loss : 0.061027, loss_ce: 0.024387
2021-12-14 03:03:52,650 iteration 3769 : loss : 0.054719, loss_ce: 0.018892
2021-12-14 03:03:54,090 iteration 3770 : loss : 0.050141, loss_ce: 0.014168
2021-12-14 03:03:55,553 iteration 3771 : loss : 0.042947, loss_ce: 0.012764
2021-12-14 03:03:57,058 iteration 3772 : loss : 0.056205, loss_ce: 0.015425
2021-12-14 03:03:58,477 iteration 3773 : loss : 0.050100, loss_ce: 0.015171
2021-12-14 03:03:59,922 iteration 3774 : loss : 0.053229, loss_ce: 0.017338
 56%|██████████████▉            | 222/400 [1:45:05<1:21:44, 27.55s/it]2021-12-14 03:04:01,446 iteration 3775 : loss : 0.062950, loss_ce: 0.013767
2021-12-14 03:04:03,004 iteration 3776 : loss : 0.075900, loss_ce: 0.027107
2021-12-14 03:04:04,671 iteration 3777 : loss : 0.063266, loss_ce: 0.018576
2021-12-14 03:04:06,149 iteration 3778 : loss : 0.049170, loss_ce: 0.018765
2021-12-14 03:04:07,709 iteration 3779 : loss : 0.049697, loss_ce: 0.014897
2021-12-14 03:04:09,183 iteration 3780 : loss : 0.052325, loss_ce: 0.019697
2021-12-14 03:04:10,707 iteration 3781 : loss : 0.062384, loss_ce: 0.019408
2021-12-14 03:04:12,251 iteration 3782 : loss : 0.065590, loss_ce: 0.021790
2021-12-14 03:04:13,815 iteration 3783 : loss : 0.051277, loss_ce: 0.010784
2021-12-14 03:04:15,399 iteration 3784 : loss : 0.067852, loss_ce: 0.026321
2021-12-14 03:04:16,872 iteration 3785 : loss : 0.052733, loss_ce: 0.015369
2021-12-14 03:04:18,403 iteration 3786 : loss : 0.054531, loss_ce: 0.014348
2021-12-14 03:04:19,994 iteration 3787 : loss : 0.068924, loss_ce: 0.022940
2021-12-14 03:04:21,611 iteration 3788 : loss : 0.072744, loss_ce: 0.020975
2021-12-14 03:04:23,092 iteration 3789 : loss : 0.060460, loss_ce: 0.016018
2021-12-14 03:04:24,641 iteration 3790 : loss : 0.067683, loss_ce: 0.024701
2021-12-14 03:04:26,039 iteration 3791 : loss : 0.050102, loss_ce: 0.017062
 56%|███████████████            | 223/400 [1:45:31<1:20:00, 27.12s/it]2021-12-14 03:04:27,611 iteration 3792 : loss : 0.049803, loss_ce: 0.017682
2021-12-14 03:04:29,135 iteration 3793 : loss : 0.051701, loss_ce: 0.017347
2021-12-14 03:04:30,569 iteration 3794 : loss : 0.050003, loss_ce: 0.015527
2021-12-14 03:04:32,244 iteration 3795 : loss : 0.068865, loss_ce: 0.022899
2021-12-14 03:04:33,822 iteration 3796 : loss : 0.059254, loss_ce: 0.014259
2021-12-14 03:04:35,313 iteration 3797 : loss : 0.051989, loss_ce: 0.014365
2021-12-14 03:04:36,951 iteration 3798 : loss : 0.053805, loss_ce: 0.018117
2021-12-14 03:04:38,421 iteration 3799 : loss : 0.061354, loss_ce: 0.026398
2021-12-14 03:04:39,992 iteration 3800 : loss : 0.056528, loss_ce: 0.015779
2021-12-14 03:04:41,435 iteration 3801 : loss : 0.049238, loss_ce: 0.014821
2021-12-14 03:04:42,956 iteration 3802 : loss : 0.058279, loss_ce: 0.016216
2021-12-14 03:04:44,462 iteration 3803 : loss : 0.050383, loss_ce: 0.015541
2021-12-14 03:04:45,843 iteration 3804 : loss : 0.051027, loss_ce: 0.014409
2021-12-14 03:04:47,389 iteration 3805 : loss : 0.055474, loss_ce: 0.020353
2021-12-14 03:04:48,855 iteration 3806 : loss : 0.055170, loss_ce: 0.014072
2021-12-14 03:04:50,337 iteration 3807 : loss : 0.059294, loss_ce: 0.020274
2021-12-14 03:04:51,858 iteration 3808 : loss : 0.057493, loss_ce: 0.018279
 56%|███████████████            | 224/400 [1:45:57<1:18:24, 26.73s/it]2021-12-14 03:04:53,426 iteration 3809 : loss : 0.051954, loss_ce: 0.017441
2021-12-14 03:04:54,929 iteration 3810 : loss : 0.051708, loss_ce: 0.016564
2021-12-14 03:04:56,590 iteration 3811 : loss : 0.054033, loss_ce: 0.014830
2021-12-14 03:04:58,060 iteration 3812 : loss : 0.056519, loss_ce: 0.017629
2021-12-14 03:04:59,595 iteration 3813 : loss : 0.071333, loss_ce: 0.016015
2021-12-14 03:05:01,014 iteration 3814 : loss : 0.052136, loss_ce: 0.015309
2021-12-14 03:05:02,602 iteration 3815 : loss : 0.071679, loss_ce: 0.019965
2021-12-14 03:05:04,264 iteration 3816 : loss : 0.055638, loss_ce: 0.016157
2021-12-14 03:05:05,802 iteration 3817 : loss : 0.065722, loss_ce: 0.028626
2021-12-14 03:05:07,471 iteration 3818 : loss : 0.062250, loss_ce: 0.022711
2021-12-14 03:05:08,916 iteration 3819 : loss : 0.059350, loss_ce: 0.023082
2021-12-14 03:05:10,487 iteration 3820 : loss : 0.070996, loss_ce: 0.026235
2021-12-14 03:05:12,000 iteration 3821 : loss : 0.055717, loss_ce: 0.021457
2021-12-14 03:05:13,383 iteration 3822 : loss : 0.049207, loss_ce: 0.016406
2021-12-14 03:05:14,825 iteration 3823 : loss : 0.053168, loss_ce: 0.016725
2021-12-14 03:05:16,304 iteration 3824 : loss : 0.058646, loss_ce: 0.017050
2021-12-14 03:05:16,304 Training Data Eval:
2021-12-14 03:05:23,734   Average segmentation loss on training set: 0.0465
2021-12-14 03:05:23,734 Validation Data Eval:
2021-12-14 03:05:26,307   Average segmentation loss on validation set: 0.0882
2021-12-14 03:05:27,762 iteration 3825 : loss : 0.058036, loss_ce: 0.019159
 56%|███████████████▏           | 225/400 [1:46:33<1:25:59, 29.48s/it]2021-12-14 03:05:29,193 iteration 3826 : loss : 0.054003, loss_ce: 0.017386
2021-12-14 03:05:30,714 iteration 3827 : loss : 0.063770, loss_ce: 0.019653
2021-12-14 03:05:32,263 iteration 3828 : loss : 0.051861, loss_ce: 0.016536
2021-12-14 03:05:33,765 iteration 3829 : loss : 0.060204, loss_ce: 0.023941
2021-12-14 03:05:35,277 iteration 3830 : loss : 0.071842, loss_ce: 0.025028
2021-12-14 03:05:36,882 iteration 3831 : loss : 0.087794, loss_ce: 0.026148
2021-12-14 03:05:38,286 iteration 3832 : loss : 0.046089, loss_ce: 0.013858
2021-12-14 03:05:39,803 iteration 3833 : loss : 0.056099, loss_ce: 0.017497
2021-12-14 03:05:41,280 iteration 3834 : loss : 0.048628, loss_ce: 0.018957
2021-12-14 03:05:42,858 iteration 3835 : loss : 0.055093, loss_ce: 0.020862
2021-12-14 03:05:44,468 iteration 3836 : loss : 0.050891, loss_ce: 0.014740
2021-12-14 03:05:45,877 iteration 3837 : loss : 0.053219, loss_ce: 0.018058
2021-12-14 03:05:47,331 iteration 3838 : loss : 0.058221, loss_ce: 0.016701
2021-12-14 03:05:48,788 iteration 3839 : loss : 0.059299, loss_ce: 0.017497
2021-12-14 03:05:50,182 iteration 3840 : loss : 0.063365, loss_ce: 0.018344
2021-12-14 03:05:51,638 iteration 3841 : loss : 0.061341, loss_ce: 0.017200
2021-12-14 03:05:53,109 iteration 3842 : loss : 0.051443, loss_ce: 0.010628
 56%|███████████████▎           | 226/400 [1:46:58<1:21:54, 28.24s/it]2021-12-14 03:05:54,715 iteration 3843 : loss : 0.050908, loss_ce: 0.016983
2021-12-14 03:05:56,235 iteration 3844 : loss : 0.058979, loss_ce: 0.021839
2021-12-14 03:05:57,704 iteration 3845 : loss : 0.053302, loss_ce: 0.016197
2021-12-14 03:05:59,190 iteration 3846 : loss : 0.060574, loss_ce: 0.015310
2021-12-14 03:06:00,753 iteration 3847 : loss : 0.049197, loss_ce: 0.013796
2021-12-14 03:06:02,232 iteration 3848 : loss : 0.053529, loss_ce: 0.019139
2021-12-14 03:06:03,651 iteration 3849 : loss : 0.047536, loss_ce: 0.014491
2021-12-14 03:06:05,199 iteration 3850 : loss : 0.069506, loss_ce: 0.014932
2021-12-14 03:06:06,767 iteration 3851 : loss : 0.067195, loss_ce: 0.031629
2021-12-14 03:06:08,256 iteration 3852 : loss : 0.064787, loss_ce: 0.021739
2021-12-14 03:06:09,703 iteration 3853 : loss : 0.056244, loss_ce: 0.023999
2021-12-14 03:06:11,285 iteration 3854 : loss : 0.056787, loss_ce: 0.019904
2021-12-14 03:06:12,791 iteration 3855 : loss : 0.065070, loss_ce: 0.023547
2021-12-14 03:06:14,327 iteration 3856 : loss : 0.054445, loss_ce: 0.016913
2021-12-14 03:06:15,795 iteration 3857 : loss : 0.054469, loss_ce: 0.018615
2021-12-14 03:06:17,359 iteration 3858 : loss : 0.054517, loss_ce: 0.017771
2021-12-14 03:06:18,904 iteration 3859 : loss : 0.058264, loss_ce: 0.013313
 57%|███████████████▎           | 227/400 [1:47:24<1:19:19, 27.51s/it]2021-12-14 03:06:20,482 iteration 3860 : loss : 0.053925, loss_ce: 0.019415
2021-12-14 03:06:22,084 iteration 3861 : loss : 0.062866, loss_ce: 0.024906
2021-12-14 03:06:23,512 iteration 3862 : loss : 0.068627, loss_ce: 0.026237
2021-12-14 03:06:25,068 iteration 3863 : loss : 0.053624, loss_ce: 0.021459
2021-12-14 03:06:26,655 iteration 3864 : loss : 0.062691, loss_ce: 0.018866
2021-12-14 03:06:28,356 iteration 3865 : loss : 0.064746, loss_ce: 0.020752
2021-12-14 03:06:30,052 iteration 3866 : loss : 0.067369, loss_ce: 0.021333
2021-12-14 03:06:31,539 iteration 3867 : loss : 0.050017, loss_ce: 0.015435
2021-12-14 03:06:33,109 iteration 3868 : loss : 0.056663, loss_ce: 0.018480
2021-12-14 03:06:34,692 iteration 3869 : loss : 0.063234, loss_ce: 0.021976
2021-12-14 03:06:36,302 iteration 3870 : loss : 0.054501, loss_ce: 0.014408
2021-12-14 03:06:37,819 iteration 3871 : loss : 0.061111, loss_ce: 0.016657
2021-12-14 03:06:39,315 iteration 3872 : loss : 0.053542, loss_ce: 0.018674
2021-12-14 03:06:40,823 iteration 3873 : loss : 0.063163, loss_ce: 0.018628
2021-12-14 03:06:42,410 iteration 3874 : loss : 0.049143, loss_ce: 0.015338
2021-12-14 03:06:43,966 iteration 3875 : loss : 0.052546, loss_ce: 0.015650
2021-12-14 03:06:45,465 iteration 3876 : loss : 0.061789, loss_ce: 0.012765
 57%|███████████████▍           | 228/400 [1:47:50<1:18:02, 27.23s/it]2021-12-14 03:06:47,013 iteration 3877 : loss : 0.052662, loss_ce: 0.017547
2021-12-14 03:06:48,601 iteration 3878 : loss : 0.048248, loss_ce: 0.016640
2021-12-14 03:06:50,143 iteration 3879 : loss : 0.068062, loss_ce: 0.025322
2021-12-14 03:06:51,667 iteration 3880 : loss : 0.046574, loss_ce: 0.015406
2021-12-14 03:06:53,131 iteration 3881 : loss : 0.057836, loss_ce: 0.024672
2021-12-14 03:06:54,727 iteration 3882 : loss : 0.084698, loss_ce: 0.026911
2021-12-14 03:06:56,292 iteration 3883 : loss : 0.064316, loss_ce: 0.023873
2021-12-14 03:06:57,772 iteration 3884 : loss : 0.063659, loss_ce: 0.011518
2021-12-14 03:06:59,212 iteration 3885 : loss : 0.052538, loss_ce: 0.015282
2021-12-14 03:07:00,672 iteration 3886 : loss : 0.056237, loss_ce: 0.017374
2021-12-14 03:07:02,276 iteration 3887 : loss : 0.065628, loss_ce: 0.022358
2021-12-14 03:07:03,817 iteration 3888 : loss : 0.052528, loss_ce: 0.014627
2021-12-14 03:07:05,338 iteration 3889 : loss : 0.058955, loss_ce: 0.022341
2021-12-14 03:07:06,733 iteration 3890 : loss : 0.053208, loss_ce: 0.017329
2021-12-14 03:07:08,284 iteration 3891 : loss : 0.044936, loss_ce: 0.012473
2021-12-14 03:07:09,804 iteration 3892 : loss : 0.069117, loss_ce: 0.014759
2021-12-14 03:07:11,442 iteration 3893 : loss : 0.068959, loss_ce: 0.030449
 57%|███████████████▍           | 229/400 [1:48:16<1:16:31, 26.85s/it]2021-12-14 03:07:12,950 iteration 3894 : loss : 0.049463, loss_ce: 0.018689
2021-12-14 03:07:14,542 iteration 3895 : loss : 0.054798, loss_ce: 0.017010
2021-12-14 03:07:16,032 iteration 3896 : loss : 0.057600, loss_ce: 0.014789
2021-12-14 03:07:17,566 iteration 3897 : loss : 0.063591, loss_ce: 0.024516
2021-12-14 03:07:19,048 iteration 3898 : loss : 0.050223, loss_ce: 0.014884
2021-12-14 03:07:20,597 iteration 3899 : loss : 0.053299, loss_ce: 0.017136
2021-12-14 03:07:22,220 iteration 3900 : loss : 0.067400, loss_ce: 0.020460
2021-12-14 03:07:23,675 iteration 3901 : loss : 0.058132, loss_ce: 0.017440
2021-12-14 03:07:25,145 iteration 3902 : loss : 0.047639, loss_ce: 0.015935
2021-12-14 03:07:26,648 iteration 3903 : loss : 0.050478, loss_ce: 0.016592
2021-12-14 03:07:28,284 iteration 3904 : loss : 0.067356, loss_ce: 0.020762
2021-12-14 03:07:29,811 iteration 3905 : loss : 0.054581, loss_ce: 0.019870
2021-12-14 03:07:31,272 iteration 3906 : loss : 0.055549, loss_ce: 0.021321
2021-12-14 03:07:32,806 iteration 3907 : loss : 0.074515, loss_ce: 0.018776
2021-12-14 03:07:34,454 iteration 3908 : loss : 0.059065, loss_ce: 0.017758
2021-12-14 03:07:36,027 iteration 3909 : loss : 0.061910, loss_ce: 0.021845
2021-12-14 03:07:36,028 Training Data Eval:
2021-12-14 03:07:43,465   Average segmentation loss on training set: 0.0462
2021-12-14 03:07:43,465 Validation Data Eval:
2021-12-14 03:07:46,034   Average segmentation loss on validation set: 0.0877
2021-12-14 03:07:47,442 iteration 3910 : loss : 0.048180, loss_ce: 0.013107
 57%|███████████████▌           | 230/400 [1:48:52<1:23:51, 29.60s/it]2021-12-14 03:07:48,979 iteration 3911 : loss : 0.049919, loss_ce: 0.014098
2021-12-14 03:07:50,570 iteration 3912 : loss : 0.058011, loss_ce: 0.019278
2021-12-14 03:07:51,980 iteration 3913 : loss : 0.053652, loss_ce: 0.015121
2021-12-14 03:07:53,378 iteration 3914 : loss : 0.050342, loss_ce: 0.015439
2021-12-14 03:07:54,770 iteration 3915 : loss : 0.051594, loss_ce: 0.014931
2021-12-14 03:07:56,343 iteration 3916 : loss : 0.050057, loss_ce: 0.014827
2021-12-14 03:07:57,938 iteration 3917 : loss : 0.070534, loss_ce: 0.014744
2021-12-14 03:07:59,530 iteration 3918 : loss : 0.061214, loss_ce: 0.023847
2021-12-14 03:08:01,047 iteration 3919 : loss : 0.055262, loss_ce: 0.017722
2021-12-14 03:08:02,590 iteration 3920 : loss : 0.060694, loss_ce: 0.025002
2021-12-14 03:08:04,133 iteration 3921 : loss : 0.075772, loss_ce: 0.019604
2021-12-14 03:08:05,596 iteration 3922 : loss : 0.042919, loss_ce: 0.012679
2021-12-14 03:08:07,089 iteration 3923 : loss : 0.051850, loss_ce: 0.017193
2021-12-14 03:08:08,597 iteration 3924 : loss : 0.065186, loss_ce: 0.022491
2021-12-14 03:08:10,300 iteration 3925 : loss : 0.073992, loss_ce: 0.025486
2021-12-14 03:08:11,834 iteration 3926 : loss : 0.061301, loss_ce: 0.017271
2021-12-14 03:08:13,367 iteration 3927 : loss : 0.056546, loss_ce: 0.019305
 58%|███████████████▌           | 231/400 [1:49:18<1:20:15, 28.50s/it]2021-12-14 03:08:14,972 iteration 3928 : loss : 0.054093, loss_ce: 0.019493
2021-12-14 03:08:16,602 iteration 3929 : loss : 0.058680, loss_ce: 0.021569
2021-12-14 03:08:18,319 iteration 3930 : loss : 0.068447, loss_ce: 0.020264
2021-12-14 03:08:19,871 iteration 3931 : loss : 0.054823, loss_ce: 0.020338
2021-12-14 03:08:21,465 iteration 3932 : loss : 0.055802, loss_ce: 0.012714
2021-12-14 03:08:22,949 iteration 3933 : loss : 0.072995, loss_ce: 0.019512
2021-12-14 03:08:24,461 iteration 3934 : loss : 0.052284, loss_ce: 0.014849
2021-12-14 03:08:26,048 iteration 3935 : loss : 0.059612, loss_ce: 0.019027
2021-12-14 03:08:27,551 iteration 3936 : loss : 0.054943, loss_ce: 0.018617
2021-12-14 03:08:29,055 iteration 3937 : loss : 0.056115, loss_ce: 0.014415
2021-12-14 03:08:30,529 iteration 3938 : loss : 0.051746, loss_ce: 0.016943
2021-12-14 03:08:32,165 iteration 3939 : loss : 0.068473, loss_ce: 0.022838
2021-12-14 03:08:33,646 iteration 3940 : loss : 0.051579, loss_ce: 0.012500
2021-12-14 03:08:35,150 iteration 3941 : loss : 0.055061, loss_ce: 0.021571
2021-12-14 03:08:36,649 iteration 3942 : loss : 0.055594, loss_ce: 0.021529
2021-12-14 03:08:38,221 iteration 3943 : loss : 0.065643, loss_ce: 0.026978
2021-12-14 03:08:39,756 iteration 3944 : loss : 0.054375, loss_ce: 0.015085
 58%|███████████████▋           | 232/400 [1:49:44<1:18:00, 27.86s/it]2021-12-14 03:08:41,318 iteration 3945 : loss : 0.051148, loss_ce: 0.017584
2021-12-14 03:08:42,721 iteration 3946 : loss : 0.045349, loss_ce: 0.014025
2021-12-14 03:08:44,228 iteration 3947 : loss : 0.049349, loss_ce: 0.014526
2021-12-14 03:08:45,718 iteration 3948 : loss : 0.056667, loss_ce: 0.020239
2021-12-14 03:08:47,247 iteration 3949 : loss : 0.054846, loss_ce: 0.021821
2021-12-14 03:08:48,760 iteration 3950 : loss : 0.047959, loss_ce: 0.014980
2021-12-14 03:08:50,325 iteration 3951 : loss : 0.062198, loss_ce: 0.022490
2021-12-14 03:08:51,839 iteration 3952 : loss : 0.056623, loss_ce: 0.022418
2021-12-14 03:08:53,351 iteration 3953 : loss : 0.048740, loss_ce: 0.012876
2021-12-14 03:08:54,916 iteration 3954 : loss : 0.055325, loss_ce: 0.017156
2021-12-14 03:08:56,464 iteration 3955 : loss : 0.057982, loss_ce: 0.017232
2021-12-14 03:08:57,948 iteration 3956 : loss : 0.058868, loss_ce: 0.020869
2021-12-14 03:08:59,430 iteration 3957 : loss : 0.054616, loss_ce: 0.019825
2021-12-14 03:09:01,059 iteration 3958 : loss : 0.054068, loss_ce: 0.017708
2021-12-14 03:09:02,550 iteration 3959 : loss : 0.047834, loss_ce: 0.012647
2021-12-14 03:09:04,071 iteration 3960 : loss : 0.068438, loss_ce: 0.014319
2021-12-14 03:09:05,637 iteration 3961 : loss : 0.049967, loss_ce: 0.015095
 58%|███████████████▋           | 233/400 [1:50:10<1:15:53, 27.27s/it]2021-12-14 03:09:07,412 iteration 3962 : loss : 0.075078, loss_ce: 0.025873
2021-12-14 03:09:08,866 iteration 3963 : loss : 0.053203, loss_ce: 0.018976
2021-12-14 03:09:10,434 iteration 3964 : loss : 0.072784, loss_ce: 0.028072
2021-12-14 03:09:12,060 iteration 3965 : loss : 0.062688, loss_ce: 0.016102
2021-12-14 03:09:13,545 iteration 3966 : loss : 0.051362, loss_ce: 0.015946
2021-12-14 03:09:15,029 iteration 3967 : loss : 0.059109, loss_ce: 0.016109
2021-12-14 03:09:16,641 iteration 3968 : loss : 0.056011, loss_ce: 0.017505
2021-12-14 03:09:18,240 iteration 3969 : loss : 0.057352, loss_ce: 0.019796
2021-12-14 03:09:19,890 iteration 3970 : loss : 0.061089, loss_ce: 0.024985
2021-12-14 03:09:21,372 iteration 3971 : loss : 0.051002, loss_ce: 0.013947
2021-12-14 03:09:22,844 iteration 3972 : loss : 0.053516, loss_ce: 0.017177
2021-12-14 03:09:24,392 iteration 3973 : loss : 0.062569, loss_ce: 0.019724
2021-12-14 03:09:26,037 iteration 3974 : loss : 0.059647, loss_ce: 0.023336
2021-12-14 03:09:27,647 iteration 3975 : loss : 0.062604, loss_ce: 0.018223
2021-12-14 03:09:29,295 iteration 3976 : loss : 0.057173, loss_ce: 0.020831
2021-12-14 03:09:30,815 iteration 3977 : loss : 0.052274, loss_ce: 0.017101
2021-12-14 03:09:32,331 iteration 3978 : loss : 0.053302, loss_ce: 0.019726
 58%|███████████████▊           | 234/400 [1:50:37<1:14:57, 27.09s/it]2021-12-14 03:09:33,911 iteration 3979 : loss : 0.061159, loss_ce: 0.019604
2021-12-14 03:09:35,469 iteration 3980 : loss : 0.049724, loss_ce: 0.017482
2021-12-14 03:09:36,946 iteration 3981 : loss : 0.056252, loss_ce: 0.017889
2021-12-14 03:09:38,664 iteration 3982 : loss : 0.050732, loss_ce: 0.013449
2021-12-14 03:09:40,173 iteration 3983 : loss : 0.052243, loss_ce: 0.011645
2021-12-14 03:09:41,752 iteration 3984 : loss : 0.050314, loss_ce: 0.016830
2021-12-14 03:09:43,297 iteration 3985 : loss : 0.054724, loss_ce: 0.016210
2021-12-14 03:09:44,765 iteration 3986 : loss : 0.055726, loss_ce: 0.019647
2021-12-14 03:09:46,241 iteration 3987 : loss : 0.046750, loss_ce: 0.017120
2021-12-14 03:09:47,851 iteration 3988 : loss : 0.065462, loss_ce: 0.025291
2021-12-14 03:09:49,397 iteration 3989 : loss : 0.060602, loss_ce: 0.020810
2021-12-14 03:09:50,889 iteration 3990 : loss : 0.047621, loss_ce: 0.013532
2021-12-14 03:09:52,407 iteration 3991 : loss : 0.058425, loss_ce: 0.019784
2021-12-14 03:09:54,111 iteration 3992 : loss : 0.070514, loss_ce: 0.018281
2021-12-14 03:09:55,635 iteration 3993 : loss : 0.060720, loss_ce: 0.023622
2021-12-14 03:09:57,140 iteration 3994 : loss : 0.052785, loss_ce: 0.017435
2021-12-14 03:09:57,140 Training Data Eval:
2021-12-14 03:10:04,562   Average segmentation loss on training set: 0.0438
2021-12-14 03:10:04,562 Validation Data Eval:
2021-12-14 03:10:07,120   Average segmentation loss on validation set: 0.0894
2021-12-14 03:10:08,618 iteration 3995 : loss : 0.059421, loss_ce: 0.014892
 59%|███████████████▊           | 235/400 [1:51:13<1:22:05, 29.85s/it]2021-12-14 03:10:10,290 iteration 3996 : loss : 0.064557, loss_ce: 0.027277
2021-12-14 03:10:11,857 iteration 3997 : loss : 0.059373, loss_ce: 0.019792
2021-12-14 03:10:13,370 iteration 3998 : loss : 0.060330, loss_ce: 0.019732
2021-12-14 03:10:14,962 iteration 3999 : loss : 0.049342, loss_ce: 0.013384
2021-12-14 03:10:16,502 iteration 4000 : loss : 0.052568, loss_ce: 0.015697
2021-12-14 03:10:18,176 iteration 4001 : loss : 0.064270, loss_ce: 0.018340
2021-12-14 03:10:19,705 iteration 4002 : loss : 0.055170, loss_ce: 0.020877
2021-12-14 03:10:21,229 iteration 4003 : loss : 0.049257, loss_ce: 0.013860
2021-12-14 03:10:22,734 iteration 4004 : loss : 0.055761, loss_ce: 0.016800
2021-12-14 03:10:24,266 iteration 4005 : loss : 0.064890, loss_ce: 0.020905
2021-12-14 03:10:25,947 iteration 4006 : loss : 0.059484, loss_ce: 0.015707
2021-12-14 03:10:27,447 iteration 4007 : loss : 0.053241, loss_ce: 0.015707
2021-12-14 03:10:28,973 iteration 4008 : loss : 0.056215, loss_ce: 0.014810
2021-12-14 03:10:30,489 iteration 4009 : loss : 0.047418, loss_ce: 0.014789
2021-12-14 03:10:31,919 iteration 4010 : loss : 0.043631, loss_ce: 0.013407
2021-12-14 03:10:33,485 iteration 4011 : loss : 0.073942, loss_ce: 0.018779
2021-12-14 03:10:35,062 iteration 4012 : loss : 0.065618, loss_ce: 0.025384
 59%|███████████████▉           | 236/400 [1:51:40<1:18:48, 28.83s/it]2021-12-14 03:10:36,639 iteration 4013 : loss : 0.061147, loss_ce: 0.013824
2021-12-14 03:10:38,237 iteration 4014 : loss : 0.078596, loss_ce: 0.020563
2021-12-14 03:10:39,718 iteration 4015 : loss : 0.057172, loss_ce: 0.023840
2021-12-14 03:10:41,299 iteration 4016 : loss : 0.059168, loss_ce: 0.017423
2021-12-14 03:10:42,779 iteration 4017 : loss : 0.057317, loss_ce: 0.018296
2021-12-14 03:10:44,409 iteration 4018 : loss : 0.068077, loss_ce: 0.019821
2021-12-14 03:10:46,012 iteration 4019 : loss : 0.072081, loss_ce: 0.030477
2021-12-14 03:10:47,519 iteration 4020 : loss : 0.046322, loss_ce: 0.012721
2021-12-14 03:10:49,051 iteration 4021 : loss : 0.055937, loss_ce: 0.015951
2021-12-14 03:10:50,569 iteration 4022 : loss : 0.070065, loss_ce: 0.018188
2021-12-14 03:10:52,116 iteration 4023 : loss : 0.063551, loss_ce: 0.024064
2021-12-14 03:10:53,681 iteration 4024 : loss : 0.065690, loss_ce: 0.020645
2021-12-14 03:10:55,171 iteration 4025 : loss : 0.052516, loss_ce: 0.017993
2021-12-14 03:10:56,662 iteration 4026 : loss : 0.046972, loss_ce: 0.015937
2021-12-14 03:10:58,166 iteration 4027 : loss : 0.057432, loss_ce: 0.018649
2021-12-14 03:10:59,684 iteration 4028 : loss : 0.050712, loss_ce: 0.013196
2021-12-14 03:11:01,236 iteration 4029 : loss : 0.052145, loss_ce: 0.018623
 59%|███████████████▉           | 237/400 [1:52:06<1:16:08, 28.03s/it]2021-12-14 03:11:02,845 iteration 4030 : loss : 0.060782, loss_ce: 0.020592
2021-12-14 03:11:04,362 iteration 4031 : loss : 0.049788, loss_ce: 0.015236
2021-12-14 03:11:05,960 iteration 4032 : loss : 0.052010, loss_ce: 0.015313
2021-12-14 03:11:07,601 iteration 4033 : loss : 0.065990, loss_ce: 0.017942
2021-12-14 03:11:09,101 iteration 4034 : loss : 0.060918, loss_ce: 0.017921
2021-12-14 03:11:10,650 iteration 4035 : loss : 0.050109, loss_ce: 0.015467
2021-12-14 03:11:12,167 iteration 4036 : loss : 0.044959, loss_ce: 0.012256
2021-12-14 03:11:13,744 iteration 4037 : loss : 0.062852, loss_ce: 0.017882
2021-12-14 03:11:15,275 iteration 4038 : loss : 0.058232, loss_ce: 0.027453
2021-12-14 03:11:16,665 iteration 4039 : loss : 0.052062, loss_ce: 0.018258
2021-12-14 03:11:18,178 iteration 4040 : loss : 0.106516, loss_ce: 0.020990
2021-12-14 03:11:19,881 iteration 4041 : loss : 0.070109, loss_ce: 0.029325
2021-12-14 03:11:21,317 iteration 4042 : loss : 0.051547, loss_ce: 0.018812
2021-12-14 03:11:22,866 iteration 4043 : loss : 0.045773, loss_ce: 0.013099
2021-12-14 03:11:24,403 iteration 4044 : loss : 0.058454, loss_ce: 0.020537
2021-12-14 03:11:25,895 iteration 4045 : loss : 0.060469, loss_ce: 0.019194
2021-12-14 03:11:27,470 iteration 4046 : loss : 0.050804, loss_ce: 0.014318
 60%|████████████████           | 238/400 [1:52:32<1:14:13, 27.49s/it]2021-12-14 03:11:28,978 iteration 4047 : loss : 0.048070, loss_ce: 0.017226
2021-12-14 03:11:30,495 iteration 4048 : loss : 0.048072, loss_ce: 0.011326
2021-12-14 03:11:32,117 iteration 4049 : loss : 0.064852, loss_ce: 0.020005
2021-12-14 03:11:33,665 iteration 4050 : loss : 0.057007, loss_ce: 0.014827
2021-12-14 03:11:35,209 iteration 4051 : loss : 0.051487, loss_ce: 0.016527
2021-12-14 03:11:36,721 iteration 4052 : loss : 0.048622, loss_ce: 0.014293
2021-12-14 03:11:38,210 iteration 4053 : loss : 0.058058, loss_ce: 0.022729
2021-12-14 03:11:39,675 iteration 4054 : loss : 0.051947, loss_ce: 0.018024
2021-12-14 03:11:41,332 iteration 4055 : loss : 0.053655, loss_ce: 0.014674
2021-12-14 03:11:42,919 iteration 4056 : loss : 0.060213, loss_ce: 0.014795
2021-12-14 03:11:44,523 iteration 4057 : loss : 0.073692, loss_ce: 0.027162
2021-12-14 03:11:45,941 iteration 4058 : loss : 0.054901, loss_ce: 0.019213
2021-12-14 03:11:47,539 iteration 4059 : loss : 0.056426, loss_ce: 0.021317
2021-12-14 03:11:49,104 iteration 4060 : loss : 0.052499, loss_ce: 0.017326
2021-12-14 03:11:50,607 iteration 4061 : loss : 0.073885, loss_ce: 0.015124
2021-12-14 03:11:52,096 iteration 4062 : loss : 0.066500, loss_ce: 0.025289
2021-12-14 03:11:53,774 iteration 4063 : loss : 0.110894, loss_ce: 0.030659
 60%|████████████████▏          | 239/400 [1:52:59<1:12:49, 27.14s/it]2021-12-14 03:11:55,354 iteration 4064 : loss : 0.061560, loss_ce: 0.018354
2021-12-14 03:11:56,876 iteration 4065 : loss : 0.069186, loss_ce: 0.021898
2021-12-14 03:11:58,291 iteration 4066 : loss : 0.051122, loss_ce: 0.014617
2021-12-14 03:11:59,737 iteration 4067 : loss : 0.068072, loss_ce: 0.013854
2021-12-14 03:12:01,277 iteration 4068 : loss : 0.058835, loss_ce: 0.019377
2021-12-14 03:12:02,868 iteration 4069 : loss : 0.071688, loss_ce: 0.021344
2021-12-14 03:12:04,425 iteration 4070 : loss : 0.055679, loss_ce: 0.022587
2021-12-14 03:12:05,861 iteration 4071 : loss : 0.059151, loss_ce: 0.021072
2021-12-14 03:12:07,388 iteration 4072 : loss : 0.051452, loss_ce: 0.017921
2021-12-14 03:12:08,933 iteration 4073 : loss : 0.062126, loss_ce: 0.026412
2021-12-14 03:12:10,388 iteration 4074 : loss : 0.055002, loss_ce: 0.017717
2021-12-14 03:12:11,977 iteration 4075 : loss : 0.055067, loss_ce: 0.017722
2021-12-14 03:12:13,526 iteration 4076 : loss : 0.053391, loss_ce: 0.015795
2021-12-14 03:12:15,088 iteration 4077 : loss : 0.051228, loss_ce: 0.019965
2021-12-14 03:12:16,703 iteration 4078 : loss : 0.061356, loss_ce: 0.015608
2021-12-14 03:12:18,252 iteration 4079 : loss : 0.048054, loss_ce: 0.015790
2021-12-14 03:12:18,253 Training Data Eval:
2021-12-14 03:12:25,659   Average segmentation loss on training set: 0.0438
2021-12-14 03:12:25,660 Validation Data Eval:
2021-12-14 03:12:28,235   Average segmentation loss on validation set: 0.0941
2021-12-14 03:12:29,763 iteration 4080 : loss : 0.056067, loss_ce: 0.014291
 60%|████████████████▏          | 240/400 [1:53:34<1:19:26, 29.79s/it]2021-12-14 03:12:31,329 iteration 4081 : loss : 0.053891, loss_ce: 0.022761
2021-12-14 03:12:32,963 iteration 4082 : loss : 0.060114, loss_ce: 0.018257
2021-12-14 03:12:34,406 iteration 4083 : loss : 0.058613, loss_ce: 0.021473
2021-12-14 03:12:35,876 iteration 4084 : loss : 0.053854, loss_ce: 0.016019
2021-12-14 03:12:37,403 iteration 4085 : loss : 0.065868, loss_ce: 0.015100
2021-12-14 03:12:38,897 iteration 4086 : loss : 0.050567, loss_ce: 0.015086
2021-12-14 03:12:40,407 iteration 4087 : loss : 0.053339, loss_ce: 0.015172
2021-12-14 03:12:41,951 iteration 4088 : loss : 0.048725, loss_ce: 0.016975
2021-12-14 03:12:43,525 iteration 4089 : loss : 0.059040, loss_ce: 0.019214
2021-12-14 03:12:45,059 iteration 4090 : loss : 0.052376, loss_ce: 0.019795
2021-12-14 03:12:46,641 iteration 4091 : loss : 0.060023, loss_ce: 0.018166
2021-12-14 03:12:48,097 iteration 4092 : loss : 0.051805, loss_ce: 0.012715
2021-12-14 03:12:49,593 iteration 4093 : loss : 0.046342, loss_ce: 0.015917
2021-12-14 03:12:51,201 iteration 4094 : loss : 0.049541, loss_ce: 0.013711
2021-12-14 03:12:52,729 iteration 4095 : loss : 0.051089, loss_ce: 0.012505
2021-12-14 03:12:54,314 iteration 4096 : loss : 0.057291, loss_ce: 0.021540
2021-12-14 03:12:55,922 iteration 4097 : loss : 0.055537, loss_ce: 0.018448
 60%|████████████████▎          | 241/400 [1:54:01<1:16:03, 28.70s/it]2021-12-14 03:12:57,513 iteration 4098 : loss : 0.051640, loss_ce: 0.018086
2021-12-14 03:12:59,034 iteration 4099 : loss : 0.056333, loss_ce: 0.016214
2021-12-14 03:13:00,517 iteration 4100 : loss : 0.066484, loss_ce: 0.019697
2021-12-14 03:13:02,082 iteration 4101 : loss : 0.049002, loss_ce: 0.017653
2021-12-14 03:13:03,700 iteration 4102 : loss : 0.056923, loss_ce: 0.017375
2021-12-14 03:13:05,116 iteration 4103 : loss : 0.048206, loss_ce: 0.016593
2021-12-14 03:13:06,677 iteration 4104 : loss : 0.076900, loss_ce: 0.025529
2021-12-14 03:13:08,253 iteration 4105 : loss : 0.052088, loss_ce: 0.015723
2021-12-14 03:13:09,907 iteration 4106 : loss : 0.054724, loss_ce: 0.015897
2021-12-14 03:13:11,483 iteration 4107 : loss : 0.055519, loss_ce: 0.018690
2021-12-14 03:13:13,078 iteration 4108 : loss : 0.054332, loss_ce: 0.018433
2021-12-14 03:13:14,629 iteration 4109 : loss : 0.065622, loss_ce: 0.016007
2021-12-14 03:13:16,218 iteration 4110 : loss : 0.057338, loss_ce: 0.015689
2021-12-14 03:13:17,777 iteration 4111 : loss : 0.049264, loss_ce: 0.012798
2021-12-14 03:13:19,182 iteration 4112 : loss : 0.049090, loss_ce: 0.016565
2021-12-14 03:13:20,784 iteration 4113 : loss : 0.072851, loss_ce: 0.022191
2021-12-14 03:13:22,325 iteration 4114 : loss : 0.056999, loss_ce: 0.020530
 60%|████████████████▎          | 242/400 [1:54:27<1:13:46, 28.02s/it]2021-12-14 03:13:23,912 iteration 4115 : loss : 0.059013, loss_ce: 0.013250
2021-12-14 03:13:25,394 iteration 4116 : loss : 0.049911, loss_ce: 0.017201
2021-12-14 03:13:26,840 iteration 4117 : loss : 0.056303, loss_ce: 0.023442
2021-12-14 03:13:28,352 iteration 4118 : loss : 0.050157, loss_ce: 0.012841
2021-12-14 03:13:29,751 iteration 4119 : loss : 0.044351, loss_ce: 0.013931
2021-12-14 03:13:31,412 iteration 4120 : loss : 0.051637, loss_ce: 0.013874
2021-12-14 03:13:32,934 iteration 4121 : loss : 0.055297, loss_ce: 0.017265
2021-12-14 03:13:34,509 iteration 4122 : loss : 0.049750, loss_ce: 0.012632
2021-12-14 03:13:36,071 iteration 4123 : loss : 0.056374, loss_ce: 0.020635
2021-12-14 03:13:37,490 iteration 4124 : loss : 0.047852, loss_ce: 0.015312
2021-12-14 03:13:39,047 iteration 4125 : loss : 0.062832, loss_ce: 0.019383
2021-12-14 03:13:40,740 iteration 4126 : loss : 0.053806, loss_ce: 0.019075
2021-12-14 03:13:42,344 iteration 4127 : loss : 0.062319, loss_ce: 0.025382
2021-12-14 03:13:43,822 iteration 4128 : loss : 0.051243, loss_ce: 0.020030
2021-12-14 03:13:45,517 iteration 4129 : loss : 0.057182, loss_ce: 0.012364
2021-12-14 03:13:47,122 iteration 4130 : loss : 0.053994, loss_ce: 0.014601
2021-12-14 03:13:48,640 iteration 4131 : loss : 0.051353, loss_ce: 0.017368
 61%|████████████████▍          | 243/400 [1:54:53<1:11:57, 27.50s/it]2021-12-14 03:13:50,273 iteration 4132 : loss : 0.060883, loss_ce: 0.014628
2021-12-14 03:13:51,752 iteration 4133 : loss : 0.052820, loss_ce: 0.020962
2021-12-14 03:13:53,346 iteration 4134 : loss : 0.053507, loss_ce: 0.021986
2021-12-14 03:13:54,872 iteration 4135 : loss : 0.068228, loss_ce: 0.020620
2021-12-14 03:13:56,394 iteration 4136 : loss : 0.047429, loss_ce: 0.012258
2021-12-14 03:13:57,958 iteration 4137 : loss : 0.053649, loss_ce: 0.022174
2021-12-14 03:13:59,526 iteration 4138 : loss : 0.047518, loss_ce: 0.018359
2021-12-14 03:14:01,083 iteration 4139 : loss : 0.088092, loss_ce: 0.020375
2021-12-14 03:14:02,683 iteration 4140 : loss : 0.061585, loss_ce: 0.020630
2021-12-14 03:14:04,217 iteration 4141 : loss : 0.051742, loss_ce: 0.012364
2021-12-14 03:14:05,701 iteration 4142 : loss : 0.051242, loss_ce: 0.017698
2021-12-14 03:14:07,178 iteration 4143 : loss : 0.048546, loss_ce: 0.014840
2021-12-14 03:14:08,732 iteration 4144 : loss : 0.057940, loss_ce: 0.016766
2021-12-14 03:14:10,240 iteration 4145 : loss : 0.063769, loss_ce: 0.021576
2021-12-14 03:14:11,621 iteration 4146 : loss : 0.055249, loss_ce: 0.014271
2021-12-14 03:14:13,119 iteration 4147 : loss : 0.060172, loss_ce: 0.017535
2021-12-14 03:14:14,640 iteration 4148 : loss : 0.058447, loss_ce: 0.018528
 61%|████████████████▍          | 244/400 [1:55:19<1:10:20, 27.05s/it]2021-12-14 03:14:16,228 iteration 4149 : loss : 0.061819, loss_ce: 0.021399
2021-12-14 03:14:17,727 iteration 4150 : loss : 0.047945, loss_ce: 0.014555
2021-12-14 03:14:19,239 iteration 4151 : loss : 0.053735, loss_ce: 0.019927
2021-12-14 03:14:20,870 iteration 4152 : loss : 0.053304, loss_ce: 0.018828
2021-12-14 03:14:22,436 iteration 4153 : loss : 0.054174, loss_ce: 0.020635
2021-12-14 03:14:23,888 iteration 4154 : loss : 0.051743, loss_ce: 0.016277
2021-12-14 03:14:25,349 iteration 4155 : loss : 0.051495, loss_ce: 0.019101
2021-12-14 03:14:26,876 iteration 4156 : loss : 0.062886, loss_ce: 0.019058
2021-12-14 03:14:28,412 iteration 4157 : loss : 0.050452, loss_ce: 0.015898
2021-12-14 03:14:29,919 iteration 4158 : loss : 0.047425, loss_ce: 0.014657
2021-12-14 03:14:31,509 iteration 4159 : loss : 0.044165, loss_ce: 0.014827
2021-12-14 03:14:33,054 iteration 4160 : loss : 0.059761, loss_ce: 0.018892
2021-12-14 03:14:34,545 iteration 4161 : loss : 0.049933, loss_ce: 0.012314
2021-12-14 03:14:36,104 iteration 4162 : loss : 0.057246, loss_ce: 0.017713
2021-12-14 03:14:37,645 iteration 4163 : loss : 0.062347, loss_ce: 0.020042
2021-12-14 03:14:39,158 iteration 4164 : loss : 0.048863, loss_ce: 0.013157
2021-12-14 03:14:39,158 Training Data Eval:
2021-12-14 03:14:46,598   Average segmentation loss on training set: 0.0426
2021-12-14 03:14:46,598 Validation Data Eval:
2021-12-14 03:14:49,171   Average segmentation loss on validation set: 0.0898
2021-12-14 03:14:50,726 iteration 4165 : loss : 0.048649, loss_ce: 0.011938
 61%|████████████████▌          | 245/400 [1:55:55<1:16:53, 29.76s/it]2021-12-14 03:14:52,275 iteration 4166 : loss : 0.060484, loss_ce: 0.015690
2021-12-14 03:14:53,772 iteration 4167 : loss : 0.048118, loss_ce: 0.016361
2021-12-14 03:14:55,186 iteration 4168 : loss : 0.049341, loss_ce: 0.013092
2021-12-14 03:14:56,645 iteration 4169 : loss : 0.049751, loss_ce: 0.016808
2021-12-14 03:14:58,288 iteration 4170 : loss : 0.058963, loss_ce: 0.018963
2021-12-14 03:14:59,938 iteration 4171 : loss : 0.050087, loss_ce: 0.016352
2021-12-14 03:15:01,380 iteration 4172 : loss : 0.051485, loss_ce: 0.011278
2021-12-14 03:15:02,905 iteration 4173 : loss : 0.069633, loss_ce: 0.021082
2021-12-14 03:15:04,431 iteration 4174 : loss : 0.052444, loss_ce: 0.018905
2021-12-14 03:15:06,023 iteration 4175 : loss : 0.054117, loss_ce: 0.016599
2021-12-14 03:15:07,574 iteration 4176 : loss : 0.055213, loss_ce: 0.018381
2021-12-14 03:15:09,126 iteration 4177 : loss : 0.055267, loss_ce: 0.016978
2021-12-14 03:15:10,646 iteration 4178 : loss : 0.054277, loss_ce: 0.018842
2021-12-14 03:15:12,273 iteration 4179 : loss : 0.062395, loss_ce: 0.023622
2021-12-14 03:15:13,799 iteration 4180 : loss : 0.068115, loss_ce: 0.019404
2021-12-14 03:15:15,197 iteration 4181 : loss : 0.059734, loss_ce: 0.015110
2021-12-14 03:15:16,775 iteration 4182 : loss : 0.052892, loss_ce: 0.018266
 62%|████████████████▌          | 246/400 [1:56:22<1:13:31, 28.65s/it]2021-12-14 03:15:18,372 iteration 4183 : loss : 0.065565, loss_ce: 0.020408
2021-12-14 03:15:19,916 iteration 4184 : loss : 0.054580, loss_ce: 0.018959
2021-12-14 03:15:21,444 iteration 4185 : loss : 0.056501, loss_ce: 0.017441
2021-12-14 03:15:22,937 iteration 4186 : loss : 0.047224, loss_ce: 0.013065
2021-12-14 03:15:24,548 iteration 4187 : loss : 0.059792, loss_ce: 0.019673
2021-12-14 03:15:26,141 iteration 4188 : loss : 0.050240, loss_ce: 0.020233
2021-12-14 03:15:27,690 iteration 4189 : loss : 0.048495, loss_ce: 0.013297
2021-12-14 03:15:29,300 iteration 4190 : loss : 0.072458, loss_ce: 0.023708
2021-12-14 03:15:30,797 iteration 4191 : loss : 0.056853, loss_ce: 0.016592
2021-12-14 03:15:32,342 iteration 4192 : loss : 0.048928, loss_ce: 0.011995
2021-12-14 03:15:33,873 iteration 4193 : loss : 0.047307, loss_ce: 0.013973
2021-12-14 03:15:35,436 iteration 4194 : loss : 0.056087, loss_ce: 0.019441
2021-12-14 03:15:37,157 iteration 4195 : loss : 0.066576, loss_ce: 0.017896
2021-12-14 03:15:38,643 iteration 4196 : loss : 0.049020, loss_ce: 0.020563
2021-12-14 03:15:40,266 iteration 4197 : loss : 0.048593, loss_ce: 0.013105
2021-12-14 03:15:41,820 iteration 4198 : loss : 0.056467, loss_ce: 0.018623
2021-12-14 03:15:43,252 iteration 4199 : loss : 0.054845, loss_ce: 0.016535
 62%|████████████████▋          | 247/400 [1:56:48<1:11:23, 28.00s/it]2021-12-14 03:15:44,784 iteration 4200 : loss : 0.058678, loss_ce: 0.017734
2021-12-14 03:15:46,366 iteration 4201 : loss : 0.056289, loss_ce: 0.020412
2021-12-14 03:15:47,803 iteration 4202 : loss : 0.047246, loss_ce: 0.018659
2021-12-14 03:15:49,275 iteration 4203 : loss : 0.053577, loss_ce: 0.019405
2021-12-14 03:15:50,785 iteration 4204 : loss : 0.049225, loss_ce: 0.016733
2021-12-14 03:15:52,268 iteration 4205 : loss : 0.047804, loss_ce: 0.014445
2021-12-14 03:15:53,673 iteration 4206 : loss : 0.050753, loss_ce: 0.012706
2021-12-14 03:15:55,128 iteration 4207 : loss : 0.052660, loss_ce: 0.018855
2021-12-14 03:15:56,617 iteration 4208 : loss : 0.058100, loss_ce: 0.018734
2021-12-14 03:15:58,260 iteration 4209 : loss : 0.072390, loss_ce: 0.018016
2021-12-14 03:15:59,858 iteration 4210 : loss : 0.052259, loss_ce: 0.017392
2021-12-14 03:16:01,206 iteration 4211 : loss : 0.044690, loss_ce: 0.014196
2021-12-14 03:16:02,722 iteration 4212 : loss : 0.056030, loss_ce: 0.020663
2021-12-14 03:16:04,229 iteration 4213 : loss : 0.062541, loss_ce: 0.021787
2021-12-14 03:16:05,816 iteration 4214 : loss : 0.064065, loss_ce: 0.017306
2021-12-14 03:16:07,303 iteration 4215 : loss : 0.050503, loss_ce: 0.015277
2021-12-14 03:16:08,947 iteration 4216 : loss : 0.056689, loss_ce: 0.015327
 62%|████████████████▋          | 248/400 [1:57:14<1:09:10, 27.30s/it]2021-12-14 03:16:10,632 iteration 4217 : loss : 0.050533, loss_ce: 0.018442
2021-12-14 03:16:12,050 iteration 4218 : loss : 0.046761, loss_ce: 0.018392
2021-12-14 03:16:13,510 iteration 4219 : loss : 0.052510, loss_ce: 0.018213
2021-12-14 03:16:15,181 iteration 4220 : loss : 0.064218, loss_ce: 0.019315
2021-12-14 03:16:16,734 iteration 4221 : loss : 0.052242, loss_ce: 0.013863
2021-12-14 03:16:18,310 iteration 4222 : loss : 0.054397, loss_ce: 0.018188
2021-12-14 03:16:19,877 iteration 4223 : loss : 0.056886, loss_ce: 0.018445
2021-12-14 03:16:21,387 iteration 4224 : loss : 0.053277, loss_ce: 0.014701
2021-12-14 03:16:22,866 iteration 4225 : loss : 0.064285, loss_ce: 0.019130
2021-12-14 03:16:24,367 iteration 4226 : loss : 0.057505, loss_ce: 0.014332
2021-12-14 03:16:26,030 iteration 4227 : loss : 0.069133, loss_ce: 0.024902
2021-12-14 03:16:27,540 iteration 4228 : loss : 0.053443, loss_ce: 0.017504
2021-12-14 03:16:29,123 iteration 4229 : loss : 0.052870, loss_ce: 0.018682
2021-12-14 03:16:30,685 iteration 4230 : loss : 0.058852, loss_ce: 0.025027
2021-12-14 03:16:32,170 iteration 4231 : loss : 0.056690, loss_ce: 0.015485
2021-12-14 03:16:33,651 iteration 4232 : loss : 0.052349, loss_ce: 0.017720
2021-12-14 03:16:35,171 iteration 4233 : loss : 0.057996, loss_ce: 0.021693
 62%|████████████████▊          | 249/400 [1:57:40<1:07:53, 26.98s/it]2021-12-14 03:16:36,837 iteration 4234 : loss : 0.061083, loss_ce: 0.024015
2021-12-14 03:16:38,339 iteration 4235 : loss : 0.054490, loss_ce: 0.013685
2021-12-14 03:16:39,769 iteration 4236 : loss : 0.048883, loss_ce: 0.015256
2021-12-14 03:16:41,234 iteration 4237 : loss : 0.049678, loss_ce: 0.016474
2021-12-14 03:16:42,719 iteration 4238 : loss : 0.053602, loss_ce: 0.016231
2021-12-14 03:16:44,285 iteration 4239 : loss : 0.057949, loss_ce: 0.018362
2021-12-14 03:16:45,838 iteration 4240 : loss : 0.071037, loss_ce: 0.023992
2021-12-14 03:16:47,363 iteration 4241 : loss : 0.059043, loss_ce: 0.022213
2021-12-14 03:16:48,728 iteration 4242 : loss : 0.043962, loss_ce: 0.014828
2021-12-14 03:16:50,271 iteration 4243 : loss : 0.054550, loss_ce: 0.016956
2021-12-14 03:16:51,736 iteration 4244 : loss : 0.052458, loss_ce: 0.015511
2021-12-14 03:16:53,221 iteration 4245 : loss : 0.046953, loss_ce: 0.013884
2021-12-14 03:16:54,693 iteration 4246 : loss : 0.051335, loss_ce: 0.015548
2021-12-14 03:16:56,201 iteration 4247 : loss : 0.049947, loss_ce: 0.012898
2021-12-14 03:16:57,599 iteration 4248 : loss : 0.050297, loss_ce: 0.017567
2021-12-14 03:16:59,198 iteration 4249 : loss : 0.051535, loss_ce: 0.017607
2021-12-14 03:16:59,199 Training Data Eval:
2021-12-14 03:17:06,623   Average segmentation loss on training set: 0.0430
2021-12-14 03:17:06,623 Validation Data Eval:
2021-12-14 03:17:09,187   Average segmentation loss on validation set: 0.0966
2021-12-14 03:17:10,717 iteration 4250 : loss : 0.064633, loss_ce: 0.020226
 62%|████████████████▉          | 250/400 [1:58:15<1:13:52, 29.55s/it]2021-12-14 03:17:12,303 iteration 4251 : loss : 0.056801, loss_ce: 0.018383
2021-12-14 03:17:13,826 iteration 4252 : loss : 0.049074, loss_ce: 0.011776
2021-12-14 03:17:15,404 iteration 4253 : loss : 0.049700, loss_ce: 0.018953
2021-12-14 03:17:16,953 iteration 4254 : loss : 0.049996, loss_ce: 0.015945
2021-12-14 03:17:18,496 iteration 4255 : loss : 0.074313, loss_ce: 0.019309
2021-12-14 03:17:19,981 iteration 4256 : loss : 0.057105, loss_ce: 0.018328
2021-12-14 03:17:21,508 iteration 4257 : loss : 0.056141, loss_ce: 0.020836
2021-12-14 03:17:23,120 iteration 4258 : loss : 0.055273, loss_ce: 0.021483
2021-12-14 03:17:24,507 iteration 4259 : loss : 0.045158, loss_ce: 0.012155
2021-12-14 03:17:26,066 iteration 4260 : loss : 0.058839, loss_ce: 0.016947
2021-12-14 03:17:27,498 iteration 4261 : loss : 0.043680, loss_ce: 0.011991
2021-12-14 03:17:28,985 iteration 4262 : loss : 0.049706, loss_ce: 0.017749
2021-12-14 03:17:30,562 iteration 4263 : loss : 0.059938, loss_ce: 0.020151
2021-12-14 03:17:32,063 iteration 4264 : loss : 0.058869, loss_ce: 0.023404
2021-12-14 03:17:33,419 iteration 4265 : loss : 0.050480, loss_ce: 0.017147
2021-12-14 03:17:34,966 iteration 4266 : loss : 0.052765, loss_ce: 0.014338
2021-12-14 03:17:36,530 iteration 4267 : loss : 0.051586, loss_ce: 0.016804
 63%|████████████████▉          | 251/400 [1:58:41<1:10:35, 28.43s/it]2021-12-14 03:17:38,016 iteration 4268 : loss : 0.055074, loss_ce: 0.017886
2021-12-14 03:17:39,454 iteration 4269 : loss : 0.049074, loss_ce: 0.011280
2021-12-14 03:17:40,944 iteration 4270 : loss : 0.060866, loss_ce: 0.014893
2021-12-14 03:17:42,427 iteration 4271 : loss : 0.065014, loss_ce: 0.022112
2021-12-14 03:17:43,922 iteration 4272 : loss : 0.051879, loss_ce: 0.019390
2021-12-14 03:17:45,396 iteration 4273 : loss : 0.048808, loss_ce: 0.017202
2021-12-14 03:17:46,906 iteration 4274 : loss : 0.048454, loss_ce: 0.017065
2021-12-14 03:17:48,390 iteration 4275 : loss : 0.049385, loss_ce: 0.016567
2021-12-14 03:17:49,867 iteration 4276 : loss : 0.047950, loss_ce: 0.014904
2021-12-14 03:17:51,378 iteration 4277 : loss : 0.053578, loss_ce: 0.019272
2021-12-14 03:17:52,863 iteration 4278 : loss : 0.058441, loss_ce: 0.014335
2021-12-14 03:17:54,317 iteration 4279 : loss : 0.046050, loss_ce: 0.015399
2021-12-14 03:17:55,842 iteration 4280 : loss : 0.067157, loss_ce: 0.018687
2021-12-14 03:17:57,356 iteration 4281 : loss : 0.057015, loss_ce: 0.020534
2021-12-14 03:17:58,906 iteration 4282 : loss : 0.081733, loss_ce: 0.024651
2021-12-14 03:18:00,525 iteration 4283 : loss : 0.049383, loss_ce: 0.017203
2021-12-14 03:18:02,149 iteration 4284 : loss : 0.054036, loss_ce: 0.016739
 63%|█████████████████          | 252/400 [1:59:07<1:08:03, 27.59s/it]2021-12-14 03:18:03,646 iteration 4285 : loss : 0.047195, loss_ce: 0.018585
2021-12-14 03:18:05,128 iteration 4286 : loss : 0.047091, loss_ce: 0.014691
2021-12-14 03:18:06,649 iteration 4287 : loss : 0.066621, loss_ce: 0.023677
2021-12-14 03:18:08,093 iteration 4288 : loss : 0.047972, loss_ce: 0.012484
2021-12-14 03:18:09,545 iteration 4289 : loss : 0.049151, loss_ce: 0.018097
2021-12-14 03:18:11,053 iteration 4290 : loss : 0.053978, loss_ce: 0.016783
2021-12-14 03:18:12,667 iteration 4291 : loss : 0.051360, loss_ce: 0.017967
2021-12-14 03:18:14,246 iteration 4292 : loss : 0.058893, loss_ce: 0.022728
2021-12-14 03:18:15,632 iteration 4293 : loss : 0.047282, loss_ce: 0.014198
2021-12-14 03:18:17,090 iteration 4294 : loss : 0.049869, loss_ce: 0.019813
2021-12-14 03:18:18,776 iteration 4295 : loss : 0.059649, loss_ce: 0.021554
2021-12-14 03:18:20,259 iteration 4296 : loss : 0.047050, loss_ce: 0.014202
2021-12-14 03:18:21,722 iteration 4297 : loss : 0.049551, loss_ce: 0.013389
2021-12-14 03:18:23,322 iteration 4298 : loss : 0.050030, loss_ce: 0.013993
2021-12-14 03:18:24,883 iteration 4299 : loss : 0.052200, loss_ce: 0.012222
2021-12-14 03:18:26,535 iteration 4300 : loss : 0.066961, loss_ce: 0.020604
2021-12-14 03:18:28,056 iteration 4301 : loss : 0.062162, loss_ce: 0.019864
 63%|█████████████████          | 253/400 [1:59:33<1:06:21, 27.08s/it]2021-12-14 03:18:29,724 iteration 4302 : loss : 0.055702, loss_ce: 0.018259
2021-12-14 03:18:31,143 iteration 4303 : loss : 0.056906, loss_ce: 0.024792
2021-12-14 03:18:32,661 iteration 4304 : loss : 0.049936, loss_ce: 0.017488
2021-12-14 03:18:34,191 iteration 4305 : loss : 0.057561, loss_ce: 0.015322
2021-12-14 03:18:35,712 iteration 4306 : loss : 0.050547, loss_ce: 0.015238
2021-12-14 03:18:37,334 iteration 4307 : loss : 0.060965, loss_ce: 0.015461
2021-12-14 03:18:38,836 iteration 4308 : loss : 0.046535, loss_ce: 0.015158
2021-12-14 03:18:40,419 iteration 4309 : loss : 0.057324, loss_ce: 0.015489
2021-12-14 03:18:41,866 iteration 4310 : loss : 0.046696, loss_ce: 0.012672
2021-12-14 03:18:43,512 iteration 4311 : loss : 0.066156, loss_ce: 0.021635
2021-12-14 03:18:44,997 iteration 4312 : loss : 0.049285, loss_ce: 0.018745
2021-12-14 03:18:46,585 iteration 4313 : loss : 0.049801, loss_ce: 0.017223
2021-12-14 03:18:48,121 iteration 4314 : loss : 0.056609, loss_ce: 0.013730
2021-12-14 03:18:49,602 iteration 4315 : loss : 0.047285, loss_ce: 0.014477
2021-12-14 03:18:51,101 iteration 4316 : loss : 0.055101, loss_ce: 0.018674
2021-12-14 03:18:52,633 iteration 4317 : loss : 0.044520, loss_ce: 0.013592
2021-12-14 03:18:54,286 iteration 4318 : loss : 0.049368, loss_ce: 0.016512
 64%|█████████████████▏         | 254/400 [1:59:59<1:05:16, 26.83s/it]2021-12-14 03:18:55,836 iteration 4319 : loss : 0.051469, loss_ce: 0.015971
2021-12-14 03:18:57,221 iteration 4320 : loss : 0.048637, loss_ce: 0.016464
2021-12-14 03:18:58,925 iteration 4321 : loss : 0.062443, loss_ce: 0.023578
2021-12-14 03:19:00,445 iteration 4322 : loss : 0.053669, loss_ce: 0.017425
2021-12-14 03:19:01,954 iteration 4323 : loss : 0.058429, loss_ce: 0.018652
2021-12-14 03:19:03,434 iteration 4324 : loss : 0.043434, loss_ce: 0.015104
2021-12-14 03:19:04,908 iteration 4325 : loss : 0.076352, loss_ce: 0.021129
2021-12-14 03:19:06,473 iteration 4326 : loss : 0.053207, loss_ce: 0.014009
2021-12-14 03:19:08,101 iteration 4327 : loss : 0.045569, loss_ce: 0.015246
2021-12-14 03:19:09,685 iteration 4328 : loss : 0.050142, loss_ce: 0.019436
2021-12-14 03:19:11,181 iteration 4329 : loss : 0.049557, loss_ce: 0.015599
2021-12-14 03:19:12,616 iteration 4330 : loss : 0.052132, loss_ce: 0.019116
2021-12-14 03:19:14,100 iteration 4331 : loss : 0.052195, loss_ce: 0.018626
2021-12-14 03:19:15,547 iteration 4332 : loss : 0.044972, loss_ce: 0.013386
2021-12-14 03:19:16,932 iteration 4333 : loss : 0.043865, loss_ce: 0.015208
2021-12-14 03:19:18,465 iteration 4334 : loss : 0.057164, loss_ce: 0.014992
2021-12-14 03:19:18,465 Training Data Eval:
2021-12-14 03:19:25,887   Average segmentation loss on training set: 0.0419
2021-12-14 03:19:25,887 Validation Data Eval:
2021-12-14 03:19:28,450   Average segmentation loss on validation set: 0.0898
2021-12-14 03:19:29,989 iteration 4335 : loss : 0.082760, loss_ce: 0.020517
 64%|█████████████████▏         | 255/400 [2:00:35<1:11:15, 29.49s/it]2021-12-14 03:19:31,458 iteration 4336 : loss : 0.046517, loss_ce: 0.015367
2021-12-14 03:19:33,013 iteration 4337 : loss : 0.051309, loss_ce: 0.017876
2021-12-14 03:19:34,553 iteration 4338 : loss : 0.049732, loss_ce: 0.016965
2021-12-14 03:19:35,956 iteration 4339 : loss : 0.059451, loss_ce: 0.015418
2021-12-14 03:19:37,495 iteration 4340 : loss : 0.056281, loss_ce: 0.010468
2021-12-14 03:19:38,998 iteration 4341 : loss : 0.051401, loss_ce: 0.016701
2021-12-14 03:19:40,475 iteration 4342 : loss : 0.045612, loss_ce: 0.014421
2021-12-14 03:19:42,092 iteration 4343 : loss : 0.075309, loss_ce: 0.022903
2021-12-14 03:19:43,567 iteration 4344 : loss : 0.053957, loss_ce: 0.017839
2021-12-14 03:19:45,019 iteration 4345 : loss : 0.046581, loss_ce: 0.017854
2021-12-14 03:19:46,396 iteration 4346 : loss : 0.042806, loss_ce: 0.011924
2021-12-14 03:19:47,993 iteration 4347 : loss : 0.055398, loss_ce: 0.015240
2021-12-14 03:19:49,559 iteration 4348 : loss : 0.052076, loss_ce: 0.019801
2021-12-14 03:19:50,988 iteration 4349 : loss : 0.057674, loss_ce: 0.019690
2021-12-14 03:19:52,419 iteration 4350 : loss : 0.044237, loss_ce: 0.012143
2021-12-14 03:19:54,013 iteration 4351 : loss : 0.052379, loss_ce: 0.018566
2021-12-14 03:19:55,568 iteration 4352 : loss : 0.061430, loss_ce: 0.020642
 64%|█████████████████▎         | 256/400 [2:01:00<1:07:57, 28.32s/it]2021-12-14 03:19:57,078 iteration 4353 : loss : 0.046502, loss_ce: 0.012276
2021-12-14 03:19:58,688 iteration 4354 : loss : 0.052243, loss_ce: 0.014235
2021-12-14 03:20:00,232 iteration 4355 : loss : 0.057703, loss_ce: 0.018547
2021-12-14 03:20:01,695 iteration 4356 : loss : 0.056345, loss_ce: 0.017065
2021-12-14 03:20:03,318 iteration 4357 : loss : 0.062799, loss_ce: 0.020676
2021-12-14 03:20:04,805 iteration 4358 : loss : 0.049979, loss_ce: 0.016597
2021-12-14 03:20:06,352 iteration 4359 : loss : 0.053908, loss_ce: 0.013401
2021-12-14 03:20:07,776 iteration 4360 : loss : 0.051095, loss_ce: 0.017630
2021-12-14 03:20:09,363 iteration 4361 : loss : 0.064704, loss_ce: 0.020738
2021-12-14 03:20:10,789 iteration 4362 : loss : 0.054596, loss_ce: 0.015076
2021-12-14 03:20:12,342 iteration 4363 : loss : 0.059300, loss_ce: 0.017753
2021-12-14 03:20:13,867 iteration 4364 : loss : 0.054064, loss_ce: 0.020349
2021-12-14 03:20:15,450 iteration 4365 : loss : 0.060899, loss_ce: 0.022428
2021-12-14 03:20:16,913 iteration 4366 : loss : 0.061334, loss_ce: 0.019528
2021-12-14 03:20:18,340 iteration 4367 : loss : 0.050890, loss_ce: 0.019952
2021-12-14 03:20:19,820 iteration 4368 : loss : 0.045296, loss_ce: 0.014310
2021-12-14 03:20:21,387 iteration 4369 : loss : 0.057721, loss_ce: 0.017523
 64%|█████████████████▎         | 257/400 [2:01:26<1:05:42, 27.57s/it]2021-12-14 03:20:22,897 iteration 4370 : loss : 0.051432, loss_ce: 0.017134
2021-12-14 03:20:24,642 iteration 4371 : loss : 0.061868, loss_ce: 0.018223
2021-12-14 03:20:26,222 iteration 4372 : loss : 0.063464, loss_ce: 0.017763
2021-12-14 03:20:27,796 iteration 4373 : loss : 0.067854, loss_ce: 0.020783
2021-12-14 03:20:29,279 iteration 4374 : loss : 0.054558, loss_ce: 0.019202
2021-12-14 03:20:30,818 iteration 4375 : loss : 0.045370, loss_ce: 0.013925
2021-12-14 03:20:32,359 iteration 4376 : loss : 0.052917, loss_ce: 0.015886
2021-12-14 03:20:33,817 iteration 4377 : loss : 0.048846, loss_ce: 0.014831
2021-12-14 03:20:35,390 iteration 4378 : loss : 0.055712, loss_ce: 0.021705
2021-12-14 03:20:36,871 iteration 4379 : loss : 0.058696, loss_ce: 0.018232
2021-12-14 03:20:38,382 iteration 4380 : loss : 0.054167, loss_ce: 0.019174
2021-12-14 03:20:39,929 iteration 4381 : loss : 0.073836, loss_ce: 0.018309
2021-12-14 03:20:41,590 iteration 4382 : loss : 0.068551, loss_ce: 0.021165
2021-12-14 03:20:43,116 iteration 4383 : loss : 0.061616, loss_ce: 0.019435
2021-12-14 03:20:44,696 iteration 4384 : loss : 0.049664, loss_ce: 0.014648
2021-12-14 03:20:46,304 iteration 4385 : loss : 0.056567, loss_ce: 0.021598
2021-12-14 03:20:47,806 iteration 4386 : loss : 0.048617, loss_ce: 0.011995
 64%|█████████████████▍         | 258/400 [2:01:53<1:04:25, 27.22s/it]2021-12-14 03:20:49,484 iteration 4387 : loss : 0.081347, loss_ce: 0.019992
2021-12-14 03:20:51,029 iteration 4388 : loss : 0.054544, loss_ce: 0.019188
2021-12-14 03:20:52,584 iteration 4389 : loss : 0.052154, loss_ce: 0.019867
2021-12-14 03:20:54,153 iteration 4390 : loss : 0.058844, loss_ce: 0.022754
2021-12-14 03:20:55,781 iteration 4391 : loss : 0.061039, loss_ce: 0.020363
2021-12-14 03:20:57,341 iteration 4392 : loss : 0.073616, loss_ce: 0.029546
2021-12-14 03:20:59,007 iteration 4393 : loss : 0.067231, loss_ce: 0.027858
2021-12-14 03:21:00,435 iteration 4394 : loss : 0.049540, loss_ce: 0.015195
2021-12-14 03:21:01,951 iteration 4395 : loss : 0.050900, loss_ce: 0.018935
2021-12-14 03:21:03,497 iteration 4396 : loss : 0.057198, loss_ce: 0.018892
2021-12-14 03:21:04,942 iteration 4397 : loss : 0.047984, loss_ce: 0.012786
2021-12-14 03:21:06,458 iteration 4398 : loss : 0.048373, loss_ce: 0.015634
2021-12-14 03:21:07,981 iteration 4399 : loss : 0.056036, loss_ce: 0.014660
2021-12-14 03:21:09,444 iteration 4400 : loss : 0.060700, loss_ce: 0.016858
2021-12-14 03:21:11,014 iteration 4401 : loss : 0.050506, loss_ce: 0.020480
2021-12-14 03:21:12,426 iteration 4402 : loss : 0.049915, loss_ce: 0.013294
2021-12-14 03:21:13,956 iteration 4403 : loss : 0.053674, loss_ce: 0.015569
 65%|█████████████████▍         | 259/400 [2:02:19<1:03:13, 26.90s/it]2021-12-14 03:21:15,631 iteration 4404 : loss : 0.080044, loss_ce: 0.032353
2021-12-14 03:21:17,157 iteration 4405 : loss : 0.056072, loss_ce: 0.018515
2021-12-14 03:21:18,720 iteration 4406 : loss : 0.058681, loss_ce: 0.020042
2021-12-14 03:21:20,316 iteration 4407 : loss : 0.060433, loss_ce: 0.015778
2021-12-14 03:21:21,782 iteration 4408 : loss : 0.050560, loss_ce: 0.019783
2021-12-14 03:21:23,227 iteration 4409 : loss : 0.054815, loss_ce: 0.017446
2021-12-14 03:21:24,876 iteration 4410 : loss : 0.072247, loss_ce: 0.019876
2021-12-14 03:21:26,414 iteration 4411 : loss : 0.051217, loss_ce: 0.015692
2021-12-14 03:21:27,942 iteration 4412 : loss : 0.048207, loss_ce: 0.013079
2021-12-14 03:21:29,490 iteration 4413 : loss : 0.047182, loss_ce: 0.017754
2021-12-14 03:21:30,969 iteration 4414 : loss : 0.056303, loss_ce: 0.014789
2021-12-14 03:21:32,409 iteration 4415 : loss : 0.047628, loss_ce: 0.016032
2021-12-14 03:21:33,959 iteration 4416 : loss : 0.060657, loss_ce: 0.017302
2021-12-14 03:21:35,508 iteration 4417 : loss : 0.055015, loss_ce: 0.019786
2021-12-14 03:21:37,041 iteration 4418 : loss : 0.047281, loss_ce: 0.016243
2021-12-14 03:21:38,542 iteration 4419 : loss : 0.042812, loss_ce: 0.012472
2021-12-14 03:21:38,542 Training Data Eval:
2021-12-14 03:21:45,982   Average segmentation loss on training set: 0.0409
2021-12-14 03:21:45,982 Validation Data Eval:
2021-12-14 03:21:48,551   Average segmentation loss on validation set: 0.0897
2021-12-14 03:21:50,031 iteration 4420 : loss : 0.047529, loss_ce: 0.011597
 65%|█████████████████▌         | 260/400 [2:02:55<1:09:11, 29.65s/it]2021-12-14 03:21:51,614 iteration 4421 : loss : 0.061107, loss_ce: 0.018484
2021-12-14 03:21:53,110 iteration 4422 : loss : 0.048546, loss_ce: 0.015198
2021-12-14 03:21:54,592 iteration 4423 : loss : 0.048567, loss_ce: 0.014996
2021-12-14 03:21:56,153 iteration 4424 : loss : 0.055514, loss_ce: 0.018830
2021-12-14 03:21:57,652 iteration 4425 : loss : 0.058913, loss_ce: 0.015853
2021-12-14 03:21:59,142 iteration 4426 : loss : 0.046321, loss_ce: 0.011661
2021-12-14 03:22:00,676 iteration 4427 : loss : 0.052911, loss_ce: 0.018208
2021-12-14 03:22:02,230 iteration 4428 : loss : 0.065295, loss_ce: 0.023280
2021-12-14 03:22:03,616 iteration 4429 : loss : 0.049432, loss_ce: 0.016945
2021-12-14 03:22:05,146 iteration 4430 : loss : 0.064311, loss_ce: 0.024897
2021-12-14 03:22:06,714 iteration 4431 : loss : 0.056827, loss_ce: 0.016067
2021-12-14 03:22:08,316 iteration 4432 : loss : 0.053827, loss_ce: 0.018953
2021-12-14 03:22:09,877 iteration 4433 : loss : 0.050293, loss_ce: 0.013234
2021-12-14 03:22:11,449 iteration 4434 : loss : 0.059275, loss_ce: 0.024053
2021-12-14 03:22:12,907 iteration 4435 : loss : 0.049529, loss_ce: 0.013279
2021-12-14 03:22:14,404 iteration 4436 : loss : 0.058799, loss_ce: 0.027835
2021-12-14 03:22:15,899 iteration 4437 : loss : 0.048338, loss_ce: 0.015400
 65%|█████████████████▌         | 261/400 [2:03:21<1:06:04, 28.52s/it]2021-12-14 03:22:17,587 iteration 4438 : loss : 0.055418, loss_ce: 0.018773
2021-12-14 03:22:19,007 iteration 4439 : loss : 0.046347, loss_ce: 0.017820
2021-12-14 03:22:20,616 iteration 4440 : loss : 0.055772, loss_ce: 0.021980
2021-12-14 03:22:22,145 iteration 4441 : loss : 0.058834, loss_ce: 0.019760
2021-12-14 03:22:23,797 iteration 4442 : loss : 0.053028, loss_ce: 0.018381
2021-12-14 03:22:25,432 iteration 4443 : loss : 0.050657, loss_ce: 0.015898
2021-12-14 03:22:26,992 iteration 4444 : loss : 0.051486, loss_ce: 0.016202
2021-12-14 03:22:28,468 iteration 4445 : loss : 0.056452, loss_ce: 0.017328
2021-12-14 03:22:30,070 iteration 4446 : loss : 0.072255, loss_ce: 0.013633
2021-12-14 03:22:31,716 iteration 4447 : loss : 0.055646, loss_ce: 0.016030
2021-12-14 03:22:33,221 iteration 4448 : loss : 0.053943, loss_ce: 0.015715
2021-12-14 03:22:34,863 iteration 4449 : loss : 0.056977, loss_ce: 0.021497
2021-12-14 03:22:36,380 iteration 4450 : loss : 0.054289, loss_ce: 0.019451
2021-12-14 03:22:37,955 iteration 4451 : loss : 0.045828, loss_ce: 0.013842
2021-12-14 03:22:39,425 iteration 4452 : loss : 0.075972, loss_ce: 0.022789
2021-12-14 03:22:40,877 iteration 4453 : loss : 0.044724, loss_ce: 0.013479
2021-12-14 03:22:42,376 iteration 4454 : loss : 0.052869, loss_ce: 0.017358
 66%|█████████████████▋         | 262/400 [2:03:47<1:04:10, 27.90s/it]2021-12-14 03:22:43,924 iteration 4455 : loss : 0.065039, loss_ce: 0.020836
2021-12-14 03:22:45,339 iteration 4456 : loss : 0.052595, loss_ce: 0.015312
2021-12-14 03:22:46,838 iteration 4457 : loss : 0.049891, loss_ce: 0.016481
2021-12-14 03:22:48,313 iteration 4458 : loss : 0.047636, loss_ce: 0.014854
2021-12-14 03:22:49,868 iteration 4459 : loss : 0.077353, loss_ce: 0.020231
2021-12-14 03:22:51,331 iteration 4460 : loss : 0.043545, loss_ce: 0.014452
2021-12-14 03:22:52,815 iteration 4461 : loss : 0.054834, loss_ce: 0.019575
2021-12-14 03:22:54,433 iteration 4462 : loss : 0.055372, loss_ce: 0.016831
2021-12-14 03:22:55,872 iteration 4463 : loss : 0.045720, loss_ce: 0.013606
2021-12-14 03:22:57,354 iteration 4464 : loss : 0.043081, loss_ce: 0.016611
2021-12-14 03:22:59,023 iteration 4465 : loss : 0.061888, loss_ce: 0.011140
2021-12-14 03:23:00,438 iteration 4466 : loss : 0.050054, loss_ce: 0.017190
2021-12-14 03:23:01,969 iteration 4467 : loss : 0.060639, loss_ce: 0.023731
2021-12-14 03:23:03,480 iteration 4468 : loss : 0.056017, loss_ce: 0.015980
2021-12-14 03:23:04,990 iteration 4469 : loss : 0.049019, loss_ce: 0.011805
2021-12-14 03:23:06,488 iteration 4470 : loss : 0.062031, loss_ce: 0.022370
2021-12-14 03:23:08,070 iteration 4471 : loss : 0.064204, loss_ce: 0.014939
 66%|█████████████████▊         | 263/400 [2:04:13<1:02:11, 27.24s/it]2021-12-14 03:23:09,587 iteration 4472 : loss : 0.050989, loss_ce: 0.018659
2021-12-14 03:23:11,146 iteration 4473 : loss : 0.053783, loss_ce: 0.018220
2021-12-14 03:23:12,790 iteration 4474 : loss : 0.061070, loss_ce: 0.022448
2021-12-14 03:23:14,356 iteration 4475 : loss : 0.047519, loss_ce: 0.016265
2021-12-14 03:23:15,851 iteration 4476 : loss : 0.050947, loss_ce: 0.015395
2021-12-14 03:23:17,341 iteration 4477 : loss : 0.060532, loss_ce: 0.020432
2021-12-14 03:23:18,976 iteration 4478 : loss : 0.056637, loss_ce: 0.023273
2021-12-14 03:23:20,473 iteration 4479 : loss : 0.049696, loss_ce: 0.019968
2021-12-14 03:23:21,899 iteration 4480 : loss : 0.050544, loss_ce: 0.016861
2021-12-14 03:23:23,483 iteration 4481 : loss : 0.060229, loss_ce: 0.014784
2021-12-14 03:23:25,000 iteration 4482 : loss : 0.046968, loss_ce: 0.013245
2021-12-14 03:23:26,458 iteration 4483 : loss : 0.052362, loss_ce: 0.013401
2021-12-14 03:23:28,069 iteration 4484 : loss : 0.057379, loss_ce: 0.017531
2021-12-14 03:23:29,668 iteration 4485 : loss : 0.067736, loss_ce: 0.026673
2021-12-14 03:23:31,279 iteration 4486 : loss : 0.051461, loss_ce: 0.014479
2021-12-14 03:23:32,751 iteration 4487 : loss : 0.057157, loss_ce: 0.012556
2021-12-14 03:23:34,235 iteration 4488 : loss : 0.061086, loss_ce: 0.020882
 66%|█████████████████▊         | 264/400 [2:04:39<1:01:00, 26.92s/it]2021-12-14 03:23:35,867 iteration 4489 : loss : 0.056689, loss_ce: 0.020265
2021-12-14 03:23:37,323 iteration 4490 : loss : 0.045306, loss_ce: 0.018693
2021-12-14 03:23:38,892 iteration 4491 : loss : 0.052737, loss_ce: 0.016384
2021-12-14 03:23:40,530 iteration 4492 : loss : 0.050726, loss_ce: 0.019578
2021-12-14 03:23:42,025 iteration 4493 : loss : 0.061234, loss_ce: 0.020581
2021-12-14 03:23:43,541 iteration 4494 : loss : 0.051194, loss_ce: 0.014762
2021-12-14 03:23:45,069 iteration 4495 : loss : 0.069769, loss_ce: 0.022274
2021-12-14 03:23:46,541 iteration 4496 : loss : 0.044863, loss_ce: 0.017825
2021-12-14 03:23:48,146 iteration 4497 : loss : 0.063833, loss_ce: 0.022822
2021-12-14 03:23:49,668 iteration 4498 : loss : 0.056070, loss_ce: 0.012862
2021-12-14 03:23:51,226 iteration 4499 : loss : 0.061830, loss_ce: 0.018616
2021-12-14 03:23:52,660 iteration 4500 : loss : 0.045871, loss_ce: 0.013168
2021-12-14 03:23:54,128 iteration 4501 : loss : 0.048742, loss_ce: 0.012830
2021-12-14 03:23:55,599 iteration 4502 : loss : 0.053559, loss_ce: 0.015023
2021-12-14 03:23:57,222 iteration 4503 : loss : 0.052116, loss_ce: 0.017409
2021-12-14 03:23:58,737 iteration 4504 : loss : 0.049785, loss_ce: 0.016261
2021-12-14 03:23:58,737 Training Data Eval:
2021-12-14 03:24:06,165   Average segmentation loss on training set: 0.0413
2021-12-14 03:24:06,165 Validation Data Eval:
2021-12-14 03:24:08,740   Average segmentation loss on validation set: 0.0857
2021-12-14 03:24:14,637 Found new lowest validation loss at iteration 4504! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 03:24:16,218 iteration 4505 : loss : 0.047565, loss_ce: 0.017009
 66%|█████████████████▉         | 265/400 [2:05:21<1:10:44, 31.44s/it]2021-12-14 03:24:17,752 iteration 4506 : loss : 0.057371, loss_ce: 0.020815
2021-12-14 03:24:19,296 iteration 4507 : loss : 0.043740, loss_ce: 0.016268
2021-12-14 03:24:20,770 iteration 4508 : loss : 0.047141, loss_ce: 0.013206
2021-12-14 03:24:22,235 iteration 4509 : loss : 0.061276, loss_ce: 0.013462
2021-12-14 03:24:23,844 iteration 4510 : loss : 0.052365, loss_ce: 0.016192
2021-12-14 03:24:25,343 iteration 4511 : loss : 0.051484, loss_ce: 0.012998
2021-12-14 03:24:26,950 iteration 4512 : loss : 0.055129, loss_ce: 0.020471
2021-12-14 03:24:28,592 iteration 4513 : loss : 0.065119, loss_ce: 0.019553
2021-12-14 03:24:30,007 iteration 4514 : loss : 0.055024, loss_ce: 0.015515
2021-12-14 03:24:31,489 iteration 4515 : loss : 0.049411, loss_ce: 0.013483
2021-12-14 03:24:32,913 iteration 4516 : loss : 0.046468, loss_ce: 0.016015
2021-12-14 03:24:34,376 iteration 4517 : loss : 0.046952, loss_ce: 0.015510
2021-12-14 03:24:35,923 iteration 4518 : loss : 0.046036, loss_ce: 0.013493
2021-12-14 03:24:37,318 iteration 4519 : loss : 0.048360, loss_ce: 0.014677
2021-12-14 03:24:38,875 iteration 4520 : loss : 0.056460, loss_ce: 0.019602
2021-12-14 03:24:40,346 iteration 4521 : loss : 0.051224, loss_ce: 0.017474
2021-12-14 03:24:41,860 iteration 4522 : loss : 0.052909, loss_ce: 0.016188
 66%|█████████████████▉         | 266/400 [2:05:47<1:06:20, 29.70s/it]2021-12-14 03:24:43,554 iteration 4523 : loss : 0.044564, loss_ce: 0.014947
2021-12-14 03:24:45,033 iteration 4524 : loss : 0.046425, loss_ce: 0.014536
2021-12-14 03:24:46,445 iteration 4525 : loss : 0.045081, loss_ce: 0.016967
2021-12-14 03:24:47,915 iteration 4526 : loss : 0.052607, loss_ce: 0.013683
2021-12-14 03:24:49,383 iteration 4527 : loss : 0.062456, loss_ce: 0.019244
2021-12-14 03:24:50,899 iteration 4528 : loss : 0.047984, loss_ce: 0.016278
2021-12-14 03:24:52,311 iteration 4529 : loss : 0.049329, loss_ce: 0.015095
2021-12-14 03:24:53,830 iteration 4530 : loss : 0.058808, loss_ce: 0.020266
2021-12-14 03:24:55,493 iteration 4531 : loss : 0.071990, loss_ce: 0.023185
2021-12-14 03:24:56,900 iteration 4532 : loss : 0.043019, loss_ce: 0.013998
2021-12-14 03:24:58,597 iteration 4533 : loss : 0.077868, loss_ce: 0.026183
2021-12-14 03:25:00,078 iteration 4534 : loss : 0.050569, loss_ce: 0.017828
2021-12-14 03:25:01,642 iteration 4535 : loss : 0.053940, loss_ce: 0.020807
2021-12-14 03:25:03,175 iteration 4536 : loss : 0.049360, loss_ce: 0.013578
2021-12-14 03:25:04,649 iteration 4537 : loss : 0.050377, loss_ce: 0.011773
2021-12-14 03:25:06,156 iteration 4538 : loss : 0.050917, loss_ce: 0.017613
2021-12-14 03:25:07,534 iteration 4539 : loss : 0.043630, loss_ce: 0.012978
 67%|██████████████████         | 267/400 [2:06:12<1:03:09, 28.49s/it]2021-12-14 03:25:09,050 iteration 4540 : loss : 0.047287, loss_ce: 0.017535
2021-12-14 03:25:10,567 iteration 4541 : loss : 0.052732, loss_ce: 0.018711
2021-12-14 03:25:12,080 iteration 4542 : loss : 0.053684, loss_ce: 0.015177
2021-12-14 03:25:13,793 iteration 4543 : loss : 0.059156, loss_ce: 0.019519
2021-12-14 03:25:15,248 iteration 4544 : loss : 0.056411, loss_ce: 0.019840
2021-12-14 03:25:16,701 iteration 4545 : loss : 0.041723, loss_ce: 0.013505
2021-12-14 03:25:18,187 iteration 4546 : loss : 0.051901, loss_ce: 0.015360
2021-12-14 03:25:19,716 iteration 4547 : loss : 0.050961, loss_ce: 0.015765
2021-12-14 03:25:21,211 iteration 4548 : loss : 0.049226, loss_ce: 0.020047
2021-12-14 03:25:22,616 iteration 4549 : loss : 0.055343, loss_ce: 0.013443
2021-12-14 03:25:24,230 iteration 4550 : loss : 0.060472, loss_ce: 0.015682
2021-12-14 03:25:25,857 iteration 4551 : loss : 0.057419, loss_ce: 0.017347
2021-12-14 03:25:27,376 iteration 4552 : loss : 0.050313, loss_ce: 0.013736
2021-12-14 03:25:28,853 iteration 4553 : loss : 0.049932, loss_ce: 0.014561
2021-12-14 03:25:30,423 iteration 4554 : loss : 0.072607, loss_ce: 0.020164
2021-12-14 03:25:31,873 iteration 4555 : loss : 0.065501, loss_ce: 0.020801
2021-12-14 03:25:33,379 iteration 4556 : loss : 0.047237, loss_ce: 0.016668
 67%|██████████████████         | 268/400 [2:06:38<1:00:55, 27.69s/it]2021-12-14 03:25:34,928 iteration 4557 : loss : 0.044323, loss_ce: 0.017483
2021-12-14 03:25:36,460 iteration 4558 : loss : 0.057394, loss_ce: 0.021864
2021-12-14 03:25:38,032 iteration 4559 : loss : 0.046637, loss_ce: 0.011940
2021-12-14 03:25:39,548 iteration 4560 : loss : 0.066695, loss_ce: 0.018062
2021-12-14 03:25:41,113 iteration 4561 : loss : 0.055698, loss_ce: 0.014018
2021-12-14 03:25:42,589 iteration 4562 : loss : 0.054199, loss_ce: 0.013016
2021-12-14 03:25:44,141 iteration 4563 : loss : 0.044374, loss_ce: 0.015337
2021-12-14 03:25:45,707 iteration 4564 : loss : 0.056781, loss_ce: 0.019134
2021-12-14 03:25:47,337 iteration 4565 : loss : 0.054778, loss_ce: 0.017730
2021-12-14 03:25:48,939 iteration 4566 : loss : 0.057156, loss_ce: 0.023092
2021-12-14 03:25:50,445 iteration 4567 : loss : 0.054888, loss_ce: 0.017623
2021-12-14 03:25:51,949 iteration 4568 : loss : 0.045773, loss_ce: 0.012432
2021-12-14 03:25:53,584 iteration 4569 : loss : 0.089369, loss_ce: 0.013926
2021-12-14 03:25:55,248 iteration 4570 : loss : 0.064919, loss_ce: 0.024405
2021-12-14 03:25:56,755 iteration 4571 : loss : 0.061280, loss_ce: 0.022219
2021-12-14 03:25:58,204 iteration 4572 : loss : 0.048363, loss_ce: 0.015369
2021-12-14 03:25:59,773 iteration 4573 : loss : 0.056574, loss_ce: 0.021932
 67%|███████████████████▌         | 269/400 [2:07:05<59:37, 27.31s/it]2021-12-14 03:26:01,253 iteration 4574 : loss : 0.050915, loss_ce: 0.017445
2021-12-14 03:26:02,837 iteration 4575 : loss : 0.050700, loss_ce: 0.013321
2021-12-14 03:26:04,546 iteration 4576 : loss : 0.049527, loss_ce: 0.015711
2021-12-14 03:26:06,097 iteration 4577 : loss : 0.052148, loss_ce: 0.013932
2021-12-14 03:26:07,515 iteration 4578 : loss : 0.048688, loss_ce: 0.016569
2021-12-14 03:26:09,107 iteration 4579 : loss : 0.044143, loss_ce: 0.013029
2021-12-14 03:26:10,671 iteration 4580 : loss : 0.051436, loss_ce: 0.018733
2021-12-14 03:26:12,198 iteration 4581 : loss : 0.055893, loss_ce: 0.017595
2021-12-14 03:26:13,711 iteration 4582 : loss : 0.050472, loss_ce: 0.017887
2021-12-14 03:26:15,357 iteration 4583 : loss : 0.069443, loss_ce: 0.014374
2021-12-14 03:26:16,876 iteration 4584 : loss : 0.063091, loss_ce: 0.015802
2021-12-14 03:26:18,331 iteration 4585 : loss : 0.050452, loss_ce: 0.015173
2021-12-14 03:26:19,831 iteration 4586 : loss : 0.047943, loss_ce: 0.018485
2021-12-14 03:26:21,362 iteration 4587 : loss : 0.046711, loss_ce: 0.015344
2021-12-14 03:26:22,978 iteration 4588 : loss : 0.057779, loss_ce: 0.020840
2021-12-14 03:26:24,498 iteration 4589 : loss : 0.055541, loss_ce: 0.021141
2021-12-14 03:26:24,498 Training Data Eval:
2021-12-14 03:26:31,947   Average segmentation loss on training set: 0.0399
2021-12-14 03:26:31,948 Validation Data Eval:
2021-12-14 03:26:34,512   Average segmentation loss on validation set: 0.0870
2021-12-14 03:26:36,093 iteration 4590 : loss : 0.056089, loss_ce: 0.025307
 68%|██████████████████▏        | 270/400 [2:07:41<1:05:01, 30.01s/it]2021-12-14 03:26:37,857 iteration 4591 : loss : 0.060306, loss_ce: 0.017386
2021-12-14 03:26:39,384 iteration 4592 : loss : 0.054886, loss_ce: 0.018816
2021-12-14 03:26:40,914 iteration 4593 : loss : 0.060677, loss_ce: 0.018895
2021-12-14 03:26:42,458 iteration 4594 : loss : 0.057694, loss_ce: 0.016759
2021-12-14 03:26:43,978 iteration 4595 : loss : 0.046002, loss_ce: 0.015641
2021-12-14 03:26:45,628 iteration 4596 : loss : 0.047305, loss_ce: 0.015704
2021-12-14 03:26:47,073 iteration 4597 : loss : 0.059423, loss_ce: 0.018023
2021-12-14 03:26:48,476 iteration 4598 : loss : 0.042830, loss_ce: 0.011003
2021-12-14 03:26:49,950 iteration 4599 : loss : 0.050741, loss_ce: 0.017704
2021-12-14 03:26:51,486 iteration 4600 : loss : 0.044423, loss_ce: 0.014220
2021-12-14 03:26:53,046 iteration 4601 : loss : 0.051959, loss_ce: 0.021963
2021-12-14 03:26:54,666 iteration 4602 : loss : 0.059701, loss_ce: 0.019328
2021-12-14 03:26:56,302 iteration 4603 : loss : 0.050744, loss_ce: 0.014987
2021-12-14 03:26:57,764 iteration 4604 : loss : 0.051653, loss_ce: 0.016000
2021-12-14 03:26:59,299 iteration 4605 : loss : 0.044499, loss_ce: 0.011874
2021-12-14 03:27:00,788 iteration 4606 : loss : 0.056796, loss_ce: 0.018549
2021-12-14 03:27:02,271 iteration 4607 : loss : 0.059828, loss_ce: 0.020181
 68%|██████████████████▎        | 271/400 [2:08:07<1:02:02, 28.86s/it]2021-12-14 03:27:03,908 iteration 4608 : loss : 0.042987, loss_ce: 0.013275
2021-12-14 03:27:05,473 iteration 4609 : loss : 0.046992, loss_ce: 0.013412
2021-12-14 03:27:07,016 iteration 4610 : loss : 0.057457, loss_ce: 0.013599
2021-12-14 03:27:08,610 iteration 4611 : loss : 0.056527, loss_ce: 0.020226
2021-12-14 03:27:10,174 iteration 4612 : loss : 0.053275, loss_ce: 0.019467
2021-12-14 03:27:11,710 iteration 4613 : loss : 0.050913, loss_ce: 0.014755
2021-12-14 03:27:13,245 iteration 4614 : loss : 0.049401, loss_ce: 0.014725
2021-12-14 03:27:14,934 iteration 4615 : loss : 0.069191, loss_ce: 0.023804
2021-12-14 03:27:16,384 iteration 4616 : loss : 0.054309, loss_ce: 0.018946
2021-12-14 03:27:17,938 iteration 4617 : loss : 0.053025, loss_ce: 0.016341
2021-12-14 03:27:19,424 iteration 4618 : loss : 0.039355, loss_ce: 0.011875
2021-12-14 03:27:20,986 iteration 4619 : loss : 0.058918, loss_ce: 0.018442
2021-12-14 03:27:22,476 iteration 4620 : loss : 0.057596, loss_ce: 0.021624
2021-12-14 03:27:23,965 iteration 4621 : loss : 0.050054, loss_ce: 0.014966
2021-12-14 03:27:25,527 iteration 4622 : loss : 0.052020, loss_ce: 0.016545
2021-12-14 03:27:27,062 iteration 4623 : loss : 0.044271, loss_ce: 0.015731
2021-12-14 03:27:28,542 iteration 4624 : loss : 0.051471, loss_ce: 0.014512
 68%|███████████████████▋         | 272/400 [2:08:33<59:54, 28.08s/it]2021-12-14 03:27:30,226 iteration 4625 : loss : 0.052129, loss_ce: 0.014893
2021-12-14 03:27:31,808 iteration 4626 : loss : 0.059337, loss_ce: 0.017648
2021-12-14 03:27:33,314 iteration 4627 : loss : 0.047736, loss_ce: 0.018098
2021-12-14 03:27:34,825 iteration 4628 : loss : 0.052367, loss_ce: 0.016315
2021-12-14 03:27:36,274 iteration 4629 : loss : 0.075660, loss_ce: 0.012365
2021-12-14 03:27:37,815 iteration 4630 : loss : 0.051649, loss_ce: 0.022689
2021-12-14 03:27:39,301 iteration 4631 : loss : 0.057260, loss_ce: 0.019394
2021-12-14 03:27:40,844 iteration 4632 : loss : 0.047662, loss_ce: 0.013352
2021-12-14 03:27:42,397 iteration 4633 : loss : 0.047774, loss_ce: 0.014064
2021-12-14 03:27:44,026 iteration 4634 : loss : 0.056087, loss_ce: 0.020274
2021-12-14 03:27:45,387 iteration 4635 : loss : 0.041284, loss_ce: 0.011825
2021-12-14 03:27:46,807 iteration 4636 : loss : 0.041124, loss_ce: 0.013035
2021-12-14 03:27:48,312 iteration 4637 : loss : 0.051167, loss_ce: 0.014596
2021-12-14 03:27:49,822 iteration 4638 : loss : 0.051575, loss_ce: 0.018829
2021-12-14 03:27:51,392 iteration 4639 : loss : 0.048851, loss_ce: 0.014025
2021-12-14 03:27:52,971 iteration 4640 : loss : 0.057420, loss_ce: 0.020753
2021-12-14 03:27:54,497 iteration 4641 : loss : 0.065735, loss_ce: 0.018743
 68%|███████████████████▊         | 273/400 [2:08:59<58:05, 27.45s/it]2021-12-14 03:27:56,072 iteration 4642 : loss : 0.063106, loss_ce: 0.019300
2021-12-14 03:27:57,597 iteration 4643 : loss : 0.057206, loss_ce: 0.019788
2021-12-14 03:27:59,140 iteration 4644 : loss : 0.062553, loss_ce: 0.026387
2021-12-14 03:28:00,627 iteration 4645 : loss : 0.050113, loss_ce: 0.014173
2021-12-14 03:28:02,140 iteration 4646 : loss : 0.051733, loss_ce: 0.020633
2021-12-14 03:28:03,672 iteration 4647 : loss : 0.049275, loss_ce: 0.017465
2021-12-14 03:28:05,140 iteration 4648 : loss : 0.043737, loss_ce: 0.015212
2021-12-14 03:28:06,831 iteration 4649 : loss : 0.058138, loss_ce: 0.020536
2021-12-14 03:28:08,201 iteration 4650 : loss : 0.045773, loss_ce: 0.015407
2021-12-14 03:28:09,734 iteration 4651 : loss : 0.048391, loss_ce: 0.015169
2021-12-14 03:28:11,249 iteration 4652 : loss : 0.052857, loss_ce: 0.017155
2021-12-14 03:28:12,667 iteration 4653 : loss : 0.043085, loss_ce: 0.014421
2021-12-14 03:28:14,098 iteration 4654 : loss : 0.050521, loss_ce: 0.013317
2021-12-14 03:28:15,687 iteration 4655 : loss : 0.059930, loss_ce: 0.017123
2021-12-14 03:28:17,199 iteration 4656 : loss : 0.052150, loss_ce: 0.014522
2021-12-14 03:28:18,732 iteration 4657 : loss : 0.054073, loss_ce: 0.017981
2021-12-14 03:28:20,235 iteration 4658 : loss : 0.046939, loss_ce: 0.014660
 68%|███████████████████▊         | 274/400 [2:09:25<56:33, 26.93s/it]2021-12-14 03:28:21,834 iteration 4659 : loss : 0.049323, loss_ce: 0.016236
2021-12-14 03:28:23,320 iteration 4660 : loss : 0.049589, loss_ce: 0.016784
2021-12-14 03:28:24,907 iteration 4661 : loss : 0.048616, loss_ce: 0.017525
2021-12-14 03:28:26,292 iteration 4662 : loss : 0.043866, loss_ce: 0.015590
2021-12-14 03:28:27,930 iteration 4663 : loss : 0.048687, loss_ce: 0.016491
2021-12-14 03:28:29,449 iteration 4664 : loss : 0.049686, loss_ce: 0.014306
2021-12-14 03:28:30,952 iteration 4665 : loss : 0.055170, loss_ce: 0.018423
2021-12-14 03:28:32,556 iteration 4666 : loss : 0.054934, loss_ce: 0.019963
2021-12-14 03:28:34,159 iteration 4667 : loss : 0.053438, loss_ce: 0.015118
2021-12-14 03:28:35,659 iteration 4668 : loss : 0.041824, loss_ce: 0.013706
2021-12-14 03:28:37,248 iteration 4669 : loss : 0.054750, loss_ce: 0.018438
2021-12-14 03:28:38,793 iteration 4670 : loss : 0.060480, loss_ce: 0.015245
2021-12-14 03:28:40,278 iteration 4671 : loss : 0.047571, loss_ce: 0.014695
2021-12-14 03:28:41,742 iteration 4672 : loss : 0.043487, loss_ce: 0.014105
2021-12-14 03:28:43,147 iteration 4673 : loss : 0.043272, loss_ce: 0.013296
2021-12-14 03:28:44,693 iteration 4674 : loss : 0.061385, loss_ce: 0.013540
2021-12-14 03:28:44,693 Training Data Eval:
2021-12-14 03:28:52,126   Average segmentation loss on training set: 0.0395
2021-12-14 03:28:52,126 Validation Data Eval:
2021-12-14 03:28:54,692   Average segmentation loss on validation set: 0.0882
2021-12-14 03:28:56,113 iteration 4675 : loss : 0.044883, loss_ce: 0.014680
 69%|██████████████████▌        | 275/400 [2:10:01<1:01:41, 29.62s/it]2021-12-14 03:28:57,694 iteration 4676 : loss : 0.046104, loss_ce: 0.014618
2021-12-14 03:28:59,150 iteration 4677 : loss : 0.043377, loss_ce: 0.015447
2021-12-14 03:29:00,720 iteration 4678 : loss : 0.053342, loss_ce: 0.015076
2021-12-14 03:29:02,358 iteration 4679 : loss : 0.059868, loss_ce: 0.021578
2021-12-14 03:29:03,784 iteration 4680 : loss : 0.061294, loss_ce: 0.020213
2021-12-14 03:29:05,282 iteration 4681 : loss : 0.056416, loss_ce: 0.020837
2021-12-14 03:29:06,777 iteration 4682 : loss : 0.050300, loss_ce: 0.017227
2021-12-14 03:29:08,244 iteration 4683 : loss : 0.048239, loss_ce: 0.014040
2021-12-14 03:29:09,756 iteration 4684 : loss : 0.056153, loss_ce: 0.018786
2021-12-14 03:29:11,318 iteration 4685 : loss : 0.041500, loss_ce: 0.013047
2021-12-14 03:29:12,768 iteration 4686 : loss : 0.054438, loss_ce: 0.017298
2021-12-14 03:29:14,277 iteration 4687 : loss : 0.058465, loss_ce: 0.015085
2021-12-14 03:29:15,667 iteration 4688 : loss : 0.040321, loss_ce: 0.014771
2021-12-14 03:29:17,218 iteration 4689 : loss : 0.049950, loss_ce: 0.015649
2021-12-14 03:29:18,614 iteration 4690 : loss : 0.044604, loss_ce: 0.013019
2021-12-14 03:29:20,113 iteration 4691 : loss : 0.052958, loss_ce: 0.013279
2021-12-14 03:29:21,780 iteration 4692 : loss : 0.069193, loss_ce: 0.025463
 69%|████████████████████         | 276/400 [2:10:27<58:45, 28.43s/it]2021-12-14 03:29:23,342 iteration 4693 : loss : 0.055880, loss_ce: 0.020564
2021-12-14 03:29:24,831 iteration 4694 : loss : 0.046797, loss_ce: 0.013630
2021-12-14 03:29:26,373 iteration 4695 : loss : 0.051281, loss_ce: 0.016703
2021-12-14 03:29:27,924 iteration 4696 : loss : 0.048224, loss_ce: 0.016388
2021-12-14 03:29:29,382 iteration 4697 : loss : 0.050067, loss_ce: 0.017002
2021-12-14 03:29:30,845 iteration 4698 : loss : 0.054133, loss_ce: 0.016869
2021-12-14 03:29:32,335 iteration 4699 : loss : 0.048138, loss_ce: 0.012393
2021-12-14 03:29:33,856 iteration 4700 : loss : 0.045182, loss_ce: 0.016131
2021-12-14 03:29:35,335 iteration 4701 : loss : 0.048661, loss_ce: 0.013978
2021-12-14 03:29:36,910 iteration 4702 : loss : 0.058043, loss_ce: 0.016930
2021-12-14 03:29:38,448 iteration 4703 : loss : 0.068202, loss_ce: 0.029842
2021-12-14 03:29:39,992 iteration 4704 : loss : 0.048084, loss_ce: 0.010632
2021-12-14 03:29:41,535 iteration 4705 : loss : 0.065528, loss_ce: 0.014913
2021-12-14 03:29:42,943 iteration 4706 : loss : 0.042176, loss_ce: 0.013630
2021-12-14 03:29:44,430 iteration 4707 : loss : 0.050372, loss_ce: 0.013155
2021-12-14 03:29:45,926 iteration 4708 : loss : 0.051214, loss_ce: 0.019549
2021-12-14 03:29:47,408 iteration 4709 : loss : 0.064636, loss_ce: 0.024127
 69%|████████████████████         | 277/400 [2:10:52<56:33, 27.59s/it]2021-12-14 03:29:48,923 iteration 4710 : loss : 0.048145, loss_ce: 0.015726
2021-12-14 03:29:50,355 iteration 4711 : loss : 0.042456, loss_ce: 0.011345
2021-12-14 03:29:51,756 iteration 4712 : loss : 0.049775, loss_ce: 0.014086
2021-12-14 03:29:53,274 iteration 4713 : loss : 0.045908, loss_ce: 0.012589
2021-12-14 03:29:54,682 iteration 4714 : loss : 0.043163, loss_ce: 0.012537
2021-12-14 03:29:56,209 iteration 4715 : loss : 0.066969, loss_ce: 0.029656
2021-12-14 03:29:57,791 iteration 4716 : loss : 0.060526, loss_ce: 0.021781
2021-12-14 03:29:59,284 iteration 4717 : loss : 0.054027, loss_ce: 0.015902
2021-12-14 03:30:00,815 iteration 4718 : loss : 0.047689, loss_ce: 0.016459
2021-12-14 03:30:02,299 iteration 4719 : loss : 0.042565, loss_ce: 0.013417
2021-12-14 03:30:03,816 iteration 4720 : loss : 0.053908, loss_ce: 0.021631
2021-12-14 03:30:05,298 iteration 4721 : loss : 0.057292, loss_ce: 0.017616
2021-12-14 03:30:06,894 iteration 4722 : loss : 0.057625, loss_ce: 0.020722
2021-12-14 03:30:08,529 iteration 4723 : loss : 0.051617, loss_ce: 0.013963
2021-12-14 03:30:10,185 iteration 4724 : loss : 0.057000, loss_ce: 0.025770
2021-12-14 03:30:11,639 iteration 4725 : loss : 0.060835, loss_ce: 0.020836
2021-12-14 03:30:13,207 iteration 4726 : loss : 0.053691, loss_ce: 0.014306
 70%|████████████████████▏        | 278/400 [2:11:18<55:00, 27.06s/it]2021-12-14 03:30:14,815 iteration 4727 : loss : 0.055873, loss_ce: 0.015867
2021-12-14 03:30:16,373 iteration 4728 : loss : 0.047900, loss_ce: 0.015420
2021-12-14 03:30:17,842 iteration 4729 : loss : 0.051630, loss_ce: 0.013605
2021-12-14 03:30:19,373 iteration 4730 : loss : 0.050909, loss_ce: 0.016820
2021-12-14 03:30:20,899 iteration 4731 : loss : 0.055495, loss_ce: 0.015535
2021-12-14 03:30:22,433 iteration 4732 : loss : 0.048245, loss_ce: 0.016728
2021-12-14 03:30:23,870 iteration 4733 : loss : 0.046885, loss_ce: 0.012800
2021-12-14 03:30:25,306 iteration 4734 : loss : 0.043279, loss_ce: 0.013696
2021-12-14 03:30:26,909 iteration 4735 : loss : 0.068797, loss_ce: 0.029756
2021-12-14 03:30:28,446 iteration 4736 : loss : 0.044862, loss_ce: 0.015818
2021-12-14 03:30:30,082 iteration 4737 : loss : 0.064024, loss_ce: 0.017576
2021-12-14 03:30:31,698 iteration 4738 : loss : 0.081507, loss_ce: 0.012785
2021-12-14 03:30:33,227 iteration 4739 : loss : 0.047914, loss_ce: 0.016328
2021-12-14 03:30:34,650 iteration 4740 : loss : 0.046140, loss_ce: 0.016954
2021-12-14 03:30:36,148 iteration 4741 : loss : 0.059382, loss_ce: 0.029530
2021-12-14 03:30:37,547 iteration 4742 : loss : 0.043399, loss_ce: 0.013445
2021-12-14 03:30:39,064 iteration 4743 : loss : 0.042236, loss_ce: 0.012274
 70%|████████████████████▏        | 279/400 [2:11:44<53:50, 26.69s/it]2021-12-14 03:30:40,652 iteration 4744 : loss : 0.061781, loss_ce: 0.023500
2021-12-14 03:30:42,200 iteration 4745 : loss : 0.044307, loss_ce: 0.015341
2021-12-14 03:30:43,696 iteration 4746 : loss : 0.056362, loss_ce: 0.019417
2021-12-14 03:30:45,266 iteration 4747 : loss : 0.048432, loss_ce: 0.014456
2021-12-14 03:30:46,921 iteration 4748 : loss : 0.060071, loss_ce: 0.020678
2021-12-14 03:30:48,529 iteration 4749 : loss : 0.052147, loss_ce: 0.014870
2021-12-14 03:30:50,038 iteration 4750 : loss : 0.046540, loss_ce: 0.014839
2021-12-14 03:30:51,475 iteration 4751 : loss : 0.054296, loss_ce: 0.017399
2021-12-14 03:30:53,002 iteration 4752 : loss : 0.052698, loss_ce: 0.012516
2021-12-14 03:30:54,567 iteration 4753 : loss : 0.045663, loss_ce: 0.016816
2021-12-14 03:30:56,099 iteration 4754 : loss : 0.058863, loss_ce: 0.013961
2021-12-14 03:30:57,657 iteration 4755 : loss : 0.049072, loss_ce: 0.016251
2021-12-14 03:30:59,186 iteration 4756 : loss : 0.052748, loss_ce: 0.019898
2021-12-14 03:31:00,710 iteration 4757 : loss : 0.048290, loss_ce: 0.016245
2021-12-14 03:31:02,358 iteration 4758 : loss : 0.054353, loss_ce: 0.016630
2021-12-14 03:31:03,810 iteration 4759 : loss : 0.044186, loss_ce: 0.013891
2021-12-14 03:31:03,810 Training Data Eval:
2021-12-14 03:31:11,259   Average segmentation loss on training set: 0.0394
2021-12-14 03:31:11,259 Validation Data Eval:
2021-12-14 03:31:13,836   Average segmentation loss on validation set: 0.0911
2021-12-14 03:31:15,346 iteration 4760 : loss : 0.051923, loss_ce: 0.012963
 70%|████████████████████▎        | 280/400 [2:12:20<59:08, 29.57s/it]2021-12-14 03:31:16,943 iteration 4761 : loss : 0.045650, loss_ce: 0.017173
2021-12-14 03:31:18,519 iteration 4762 : loss : 0.054352, loss_ce: 0.014310
2021-12-14 03:31:20,057 iteration 4763 : loss : 0.050452, loss_ce: 0.014744
2021-12-14 03:31:21,669 iteration 4764 : loss : 0.049044, loss_ce: 0.013174
2021-12-14 03:31:23,267 iteration 4765 : loss : 0.049975, loss_ce: 0.016601
2021-12-14 03:31:24,940 iteration 4766 : loss : 0.060454, loss_ce: 0.012929
2021-12-14 03:31:26,623 iteration 4767 : loss : 0.056588, loss_ce: 0.022920
2021-12-14 03:31:28,195 iteration 4768 : loss : 0.057228, loss_ce: 0.022072
2021-12-14 03:31:29,629 iteration 4769 : loss : 0.043821, loss_ce: 0.013162
2021-12-14 03:31:31,212 iteration 4770 : loss : 0.051637, loss_ce: 0.021425
2021-12-14 03:31:32,713 iteration 4771 : loss : 0.070401, loss_ce: 0.024271
2021-12-14 03:31:34,183 iteration 4772 : loss : 0.045386, loss_ce: 0.014215
2021-12-14 03:31:35,613 iteration 4773 : loss : 0.043180, loss_ce: 0.014734
2021-12-14 03:31:37,196 iteration 4774 : loss : 0.078790, loss_ce: 0.025175
2021-12-14 03:31:38,620 iteration 4775 : loss : 0.049641, loss_ce: 0.016052
2021-12-14 03:31:40,138 iteration 4776 : loss : 0.064254, loss_ce: 0.020900
2021-12-14 03:31:41,635 iteration 4777 : loss : 0.045765, loss_ce: 0.012515
 70%|████████████████████▎        | 281/400 [2:12:46<56:41, 28.58s/it]2021-12-14 03:31:43,225 iteration 4778 : loss : 0.051799, loss_ce: 0.020130
2021-12-14 03:31:44,693 iteration 4779 : loss : 0.042084, loss_ce: 0.015955
2021-12-14 03:31:46,171 iteration 4780 : loss : 0.046630, loss_ce: 0.015964
2021-12-14 03:31:47,730 iteration 4781 : loss : 0.056058, loss_ce: 0.017834
2021-12-14 03:31:49,302 iteration 4782 : loss : 0.062951, loss_ce: 0.021178
2021-12-14 03:31:50,817 iteration 4783 : loss : 0.054043, loss_ce: 0.017006
2021-12-14 03:31:52,421 iteration 4784 : loss : 0.056574, loss_ce: 0.016048
2021-12-14 03:31:53,938 iteration 4785 : loss : 0.048640, loss_ce: 0.015321
2021-12-14 03:31:55,444 iteration 4786 : loss : 0.043703, loss_ce: 0.014471
2021-12-14 03:31:56,945 iteration 4787 : loss : 0.072789, loss_ce: 0.021049
2021-12-14 03:31:58,492 iteration 4788 : loss : 0.060992, loss_ce: 0.015270
2021-12-14 03:31:59,880 iteration 4789 : loss : 0.043077, loss_ce: 0.013838
2021-12-14 03:32:01,253 iteration 4790 : loss : 0.043079, loss_ce: 0.013396
2021-12-14 03:32:02,806 iteration 4791 : loss : 0.081393, loss_ce: 0.032997
2021-12-14 03:32:04,331 iteration 4792 : loss : 0.050676, loss_ce: 0.018054
2021-12-14 03:32:05,939 iteration 4793 : loss : 0.049670, loss_ce: 0.013752
2021-12-14 03:32:07,430 iteration 4794 : loss : 0.045925, loss_ce: 0.011305
 70%|████████████████████▍        | 282/400 [2:13:12<54:34, 27.75s/it]2021-12-14 03:32:09,051 iteration 4795 : loss : 0.053144, loss_ce: 0.017051
2021-12-14 03:32:10,609 iteration 4796 : loss : 0.048925, loss_ce: 0.012186
2021-12-14 03:32:12,148 iteration 4797 : loss : 0.046700, loss_ce: 0.014586
2021-12-14 03:32:13,707 iteration 4798 : loss : 0.047565, loss_ce: 0.015990
2021-12-14 03:32:15,187 iteration 4799 : loss : 0.048419, loss_ce: 0.011004
2021-12-14 03:32:16,759 iteration 4800 : loss : 0.051650, loss_ce: 0.015958
2021-12-14 03:32:18,244 iteration 4801 : loss : 0.045452, loss_ce: 0.016478
2021-12-14 03:32:19,830 iteration 4802 : loss : 0.048531, loss_ce: 0.016537
2021-12-14 03:32:21,343 iteration 4803 : loss : 0.044234, loss_ce: 0.013557
2021-12-14 03:32:22,897 iteration 4804 : loss : 0.050186, loss_ce: 0.016789
2021-12-14 03:32:24,524 iteration 4805 : loss : 0.060267, loss_ce: 0.021772
2021-12-14 03:32:26,115 iteration 4806 : loss : 0.076507, loss_ce: 0.016068
2021-12-14 03:32:27,565 iteration 4807 : loss : 0.045785, loss_ce: 0.011803
2021-12-14 03:32:29,151 iteration 4808 : loss : 0.045975, loss_ce: 0.014571
2021-12-14 03:32:30,606 iteration 4809 : loss : 0.049972, loss_ce: 0.019632
2021-12-14 03:32:32,127 iteration 4810 : loss : 0.052499, loss_ce: 0.016328
2021-12-14 03:32:33,699 iteration 4811 : loss : 0.055017, loss_ce: 0.017249
 71%|████████████████████▌        | 283/400 [2:13:38<53:15, 27.31s/it]2021-12-14 03:32:35,284 iteration 4812 : loss : 0.051532, loss_ce: 0.012779
2021-12-14 03:32:36,767 iteration 4813 : loss : 0.044466, loss_ce: 0.015267
2021-12-14 03:32:38,460 iteration 4814 : loss : 0.065016, loss_ce: 0.024309
2021-12-14 03:32:39,977 iteration 4815 : loss : 0.044185, loss_ce: 0.014309
2021-12-14 03:32:41,439 iteration 4816 : loss : 0.050468, loss_ce: 0.015875
2021-12-14 03:32:42,881 iteration 4817 : loss : 0.042965, loss_ce: 0.014733
2021-12-14 03:32:44,351 iteration 4818 : loss : 0.047776, loss_ce: 0.014867
2021-12-14 03:32:45,898 iteration 4819 : loss : 0.044468, loss_ce: 0.012330
2021-12-14 03:32:47,362 iteration 4820 : loss : 0.055395, loss_ce: 0.020714
2021-12-14 03:32:48,873 iteration 4821 : loss : 0.045451, loss_ce: 0.012754
2021-12-14 03:32:50,457 iteration 4822 : loss : 0.051428, loss_ce: 0.014959
2021-12-14 03:32:51,994 iteration 4823 : loss : 0.060108, loss_ce: 0.014242
2021-12-14 03:32:53,487 iteration 4824 : loss : 0.041873, loss_ce: 0.010847
2021-12-14 03:32:55,078 iteration 4825 : loss : 0.045457, loss_ce: 0.017346
2021-12-14 03:32:56,819 iteration 4826 : loss : 0.057905, loss_ce: 0.021826
2021-12-14 03:32:58,306 iteration 4827 : loss : 0.052781, loss_ce: 0.023300
2021-12-14 03:32:59,770 iteration 4828 : loss : 0.041818, loss_ce: 0.012722
 71%|████████████████████▌        | 284/400 [2:14:05<52:04, 26.93s/it]2021-12-14 03:33:01,308 iteration 4829 : loss : 0.042507, loss_ce: 0.015561
2021-12-14 03:33:02,891 iteration 4830 : loss : 0.060564, loss_ce: 0.024816
2021-12-14 03:33:04,451 iteration 4831 : loss : 0.054137, loss_ce: 0.025533
2021-12-14 03:33:06,020 iteration 4832 : loss : 0.044847, loss_ce: 0.014036
2021-12-14 03:33:07,534 iteration 4833 : loss : 0.053376, loss_ce: 0.021268
2021-12-14 03:33:09,165 iteration 4834 : loss : 0.050483, loss_ce: 0.016056
2021-12-14 03:33:10,679 iteration 4835 : loss : 0.051399, loss_ce: 0.018487
2021-12-14 03:33:12,156 iteration 4836 : loss : 0.045565, loss_ce: 0.010679
2021-12-14 03:33:13,690 iteration 4837 : loss : 0.045457, loss_ce: 0.012571
2021-12-14 03:33:15,247 iteration 4838 : loss : 0.053627, loss_ce: 0.018144
2021-12-14 03:33:16,634 iteration 4839 : loss : 0.047917, loss_ce: 0.014688
2021-12-14 03:33:18,113 iteration 4840 : loss : 0.055588, loss_ce: 0.016846
2021-12-14 03:33:19,683 iteration 4841 : loss : 0.052496, loss_ce: 0.016965
2021-12-14 03:33:21,235 iteration 4842 : loss : 0.057022, loss_ce: 0.019929
2021-12-14 03:33:22,726 iteration 4843 : loss : 0.048037, loss_ce: 0.015383
2021-12-14 03:33:24,324 iteration 4844 : loss : 0.048139, loss_ce: 0.013103
2021-12-14 03:33:24,324 Training Data Eval:
2021-12-14 03:33:31,805   Average segmentation loss on training set: 0.0392
2021-12-14 03:33:31,806 Validation Data Eval:
2021-12-14 03:33:34,379   Average segmentation loss on validation set: 0.0864
2021-12-14 03:33:35,861 iteration 4845 : loss : 0.043317, loss_ce: 0.012860
 71%|████████████████████▋        | 285/400 [2:14:41<56:53, 29.68s/it]2021-12-14 03:33:37,450 iteration 4846 : loss : 0.050404, loss_ce: 0.017131
2021-12-14 03:33:38,900 iteration 4847 : loss : 0.042807, loss_ce: 0.011903
2021-12-14 03:33:40,561 iteration 4848 : loss : 0.052124, loss_ce: 0.020122
2021-12-14 03:33:42,086 iteration 4849 : loss : 0.050755, loss_ce: 0.017348
2021-12-14 03:33:43,514 iteration 4850 : loss : 0.043308, loss_ce: 0.015862
2021-12-14 03:33:45,188 iteration 4851 : loss : 0.062056, loss_ce: 0.017027
2021-12-14 03:33:46,705 iteration 4852 : loss : 0.062198, loss_ce: 0.025418
2021-12-14 03:33:48,254 iteration 4853 : loss : 0.065647, loss_ce: 0.015991
2021-12-14 03:33:49,974 iteration 4854 : loss : 0.048113, loss_ce: 0.015352
2021-12-14 03:33:51,526 iteration 4855 : loss : 0.054884, loss_ce: 0.017091
2021-12-14 03:33:52,967 iteration 4856 : loss : 0.049616, loss_ce: 0.015186
2021-12-14 03:33:54,548 iteration 4857 : loss : 0.046965, loss_ce: 0.018382
2021-12-14 03:33:56,104 iteration 4858 : loss : 0.053980, loss_ce: 0.018398
2021-12-14 03:33:57,635 iteration 4859 : loss : 0.045107, loss_ce: 0.016392
2021-12-14 03:33:59,202 iteration 4860 : loss : 0.071884, loss_ce: 0.024128
2021-12-14 03:34:00,713 iteration 4861 : loss : 0.048025, loss_ce: 0.016903
2021-12-14 03:34:02,163 iteration 4862 : loss : 0.044818, loss_ce: 0.014435
 72%|████████████████████▋        | 286/400 [2:15:07<54:27, 28.67s/it]2021-12-14 03:34:03,668 iteration 4863 : loss : 0.044244, loss_ce: 0.012396
2021-12-14 03:34:05,244 iteration 4864 : loss : 0.055336, loss_ce: 0.019443
2021-12-14 03:34:06,890 iteration 4865 : loss : 0.061518, loss_ce: 0.015363
2021-12-14 03:34:08,393 iteration 4866 : loss : 0.044228, loss_ce: 0.014503
2021-12-14 03:34:09,934 iteration 4867 : loss : 0.055109, loss_ce: 0.019057
2021-12-14 03:34:11,398 iteration 4868 : loss : 0.052023, loss_ce: 0.021571
2021-12-14 03:34:12,874 iteration 4869 : loss : 0.049077, loss_ce: 0.017716
2021-12-14 03:34:14,519 iteration 4870 : loss : 0.053659, loss_ce: 0.016415
2021-12-14 03:34:16,064 iteration 4871 : loss : 0.042383, loss_ce: 0.014051
2021-12-14 03:34:17,501 iteration 4872 : loss : 0.056281, loss_ce: 0.019360
2021-12-14 03:34:18,916 iteration 4873 : loss : 0.047666, loss_ce: 0.014309
2021-12-14 03:34:20,308 iteration 4874 : loss : 0.044126, loss_ce: 0.015227
2021-12-14 03:34:21,813 iteration 4875 : loss : 0.039081, loss_ce: 0.010537
2021-12-14 03:34:23,247 iteration 4876 : loss : 0.047278, loss_ce: 0.013693
2021-12-14 03:34:24,893 iteration 4877 : loss : 0.053374, loss_ce: 0.020172
2021-12-14 03:34:26,395 iteration 4878 : loss : 0.045796, loss_ce: 0.012629
2021-12-14 03:34:27,907 iteration 4879 : loss : 0.052899, loss_ce: 0.018415
 72%|████████████████████▊        | 287/400 [2:15:33<52:20, 27.79s/it]2021-12-14 03:34:29,601 iteration 4880 : loss : 0.064353, loss_ce: 0.032567
2021-12-14 03:34:31,084 iteration 4881 : loss : 0.080606, loss_ce: 0.024667
2021-12-14 03:34:32,593 iteration 4882 : loss : 0.043430, loss_ce: 0.010027
2021-12-14 03:34:34,132 iteration 4883 : loss : 0.048758, loss_ce: 0.012832
2021-12-14 03:34:35,660 iteration 4884 : loss : 0.045045, loss_ce: 0.019259
2021-12-14 03:34:37,359 iteration 4885 : loss : 0.054030, loss_ce: 0.013591
2021-12-14 03:34:38,948 iteration 4886 : loss : 0.053785, loss_ce: 0.014767
2021-12-14 03:34:40,568 iteration 4887 : loss : 0.053133, loss_ce: 0.016654
2021-12-14 03:34:42,068 iteration 4888 : loss : 0.064750, loss_ce: 0.017303
2021-12-14 03:34:43,561 iteration 4889 : loss : 0.046425, loss_ce: 0.016192
2021-12-14 03:34:45,166 iteration 4890 : loss : 0.054111, loss_ce: 0.016123
2021-12-14 03:34:46,773 iteration 4891 : loss : 0.054636, loss_ce: 0.025088
2021-12-14 03:34:48,211 iteration 4892 : loss : 0.052346, loss_ce: 0.020475
2021-12-14 03:34:49,678 iteration 4893 : loss : 0.045508, loss_ce: 0.018288
2021-12-14 03:34:51,181 iteration 4894 : loss : 0.055231, loss_ce: 0.013292
2021-12-14 03:34:52,642 iteration 4895 : loss : 0.045321, loss_ce: 0.015308
2021-12-14 03:34:54,165 iteration 4896 : loss : 0.064733, loss_ce: 0.020157
 72%|████████████████████▉        | 288/400 [2:15:59<51:00, 27.33s/it]2021-12-14 03:34:55,715 iteration 4897 : loss : 0.066708, loss_ce: 0.019764
2021-12-14 03:34:57,286 iteration 4898 : loss : 0.074981, loss_ce: 0.020634
2021-12-14 03:34:58,631 iteration 4899 : loss : 0.047379, loss_ce: 0.016652
2021-12-14 03:35:00,266 iteration 4900 : loss : 0.048510, loss_ce: 0.014551
2021-12-14 03:35:01,763 iteration 4901 : loss : 0.044788, loss_ce: 0.010226
2021-12-14 03:35:03,364 iteration 4902 : loss : 0.058793, loss_ce: 0.020391
2021-12-14 03:35:05,017 iteration 4903 : loss : 0.058840, loss_ce: 0.020476
2021-12-14 03:35:06,639 iteration 4904 : loss : 0.063194, loss_ce: 0.027319
2021-12-14 03:35:08,210 iteration 4905 : loss : 0.065298, loss_ce: 0.018586
2021-12-14 03:35:09,771 iteration 4906 : loss : 0.056681, loss_ce: 0.018802
2021-12-14 03:35:11,173 iteration 4907 : loss : 0.044218, loss_ce: 0.014480
2021-12-14 03:35:12,630 iteration 4908 : loss : 0.049400, loss_ce: 0.017653
2021-12-14 03:35:14,143 iteration 4909 : loss : 0.043095, loss_ce: 0.012834
2021-12-14 03:35:15,657 iteration 4910 : loss : 0.050423, loss_ce: 0.017038
2021-12-14 03:35:17,109 iteration 4911 : loss : 0.046721, loss_ce: 0.014204
2021-12-14 03:35:18,686 iteration 4912 : loss : 0.061606, loss_ce: 0.017135
2021-12-14 03:35:20,221 iteration 4913 : loss : 0.052019, loss_ce: 0.015780
 72%|████████████████████▉        | 289/400 [2:16:25<49:51, 26.95s/it]2021-12-14 03:35:21,731 iteration 4914 : loss : 0.047488, loss_ce: 0.015145
2021-12-14 03:35:23,266 iteration 4915 : loss : 0.048780, loss_ce: 0.017764
2021-12-14 03:35:24,848 iteration 4916 : loss : 0.059248, loss_ce: 0.016383
2021-12-14 03:35:26,362 iteration 4917 : loss : 0.041097, loss_ce: 0.011542
2021-12-14 03:35:27,887 iteration 4918 : loss : 0.049135, loss_ce: 0.017649
2021-12-14 03:35:29,403 iteration 4919 : loss : 0.042876, loss_ce: 0.014023
2021-12-14 03:35:31,011 iteration 4920 : loss : 0.057414, loss_ce: 0.019958
2021-12-14 03:35:32,445 iteration 4921 : loss : 0.050547, loss_ce: 0.015874
2021-12-14 03:35:34,021 iteration 4922 : loss : 0.046524, loss_ce: 0.013556
2021-12-14 03:35:35,541 iteration 4923 : loss : 0.050961, loss_ce: 0.017797
2021-12-14 03:35:37,086 iteration 4924 : loss : 0.053211, loss_ce: 0.018734
2021-12-14 03:35:38,583 iteration 4925 : loss : 0.054912, loss_ce: 0.017658
2021-12-14 03:35:39,961 iteration 4926 : loss : 0.045416, loss_ce: 0.017055
2021-12-14 03:35:41,492 iteration 4927 : loss : 0.044706, loss_ce: 0.013109
2021-12-14 03:35:43,055 iteration 4928 : loss : 0.042267, loss_ce: 0.014899
2021-12-14 03:35:44,512 iteration 4929 : loss : 0.056681, loss_ce: 0.016033
2021-12-14 03:35:44,512 Training Data Eval:
2021-12-14 03:35:51,946   Average segmentation loss on training set: 0.0397
2021-12-14 03:35:51,947 Validation Data Eval:
2021-12-14 03:35:54,509   Average segmentation loss on validation set: 0.0862
2021-12-14 03:35:56,047 iteration 4930 : loss : 0.056557, loss_ce: 0.015602
 72%|█████████████████████        | 290/400 [2:17:01<54:17, 29.62s/it]2021-12-14 03:35:57,681 iteration 4931 : loss : 0.055066, loss_ce: 0.022852
2021-12-14 03:35:59,242 iteration 4932 : loss : 0.051576, loss_ce: 0.012680
2021-12-14 03:36:00,678 iteration 4933 : loss : 0.051221, loss_ce: 0.018294
2021-12-14 03:36:02,209 iteration 4934 : loss : 0.044356, loss_ce: 0.011489
2021-12-14 03:36:03,705 iteration 4935 : loss : 0.047229, loss_ce: 0.011476
2021-12-14 03:36:05,260 iteration 4936 : loss : 0.046994, loss_ce: 0.013737
2021-12-14 03:36:06,731 iteration 4937 : loss : 0.045215, loss_ce: 0.012627
2021-12-14 03:36:08,178 iteration 4938 : loss : 0.049678, loss_ce: 0.018012
2021-12-14 03:36:09,824 iteration 4939 : loss : 0.070700, loss_ce: 0.024451
2021-12-14 03:36:11,287 iteration 4940 : loss : 0.047375, loss_ce: 0.016285
2021-12-14 03:36:12,816 iteration 4941 : loss : 0.054775, loss_ce: 0.020788
2021-12-14 03:36:14,577 iteration 4942 : loss : 0.053799, loss_ce: 0.018154
2021-12-14 03:36:16,063 iteration 4943 : loss : 0.051646, loss_ce: 0.016414
2021-12-14 03:36:17,544 iteration 4944 : loss : 0.047509, loss_ce: 0.019785
2021-12-14 03:36:19,053 iteration 4945 : loss : 0.041654, loss_ce: 0.012928
2021-12-14 03:36:20,473 iteration 4946 : loss : 0.050594, loss_ce: 0.016074
2021-12-14 03:36:22,073 iteration 4947 : loss : 0.060507, loss_ce: 0.017849
 73%|█████████████████████        | 291/400 [2:17:27<51:50, 28.53s/it]2021-12-14 03:36:23,700 iteration 4948 : loss : 0.049692, loss_ce: 0.014530
2021-12-14 03:36:25,364 iteration 4949 : loss : 0.054061, loss_ce: 0.019860
2021-12-14 03:36:26,814 iteration 4950 : loss : 0.046476, loss_ce: 0.019320
2021-12-14 03:36:28,333 iteration 4951 : loss : 0.061083, loss_ce: 0.021501
2021-12-14 03:36:29,850 iteration 4952 : loss : 0.055308, loss_ce: 0.016923
2021-12-14 03:36:31,463 iteration 4953 : loss : 0.045029, loss_ce: 0.011575
2021-12-14 03:36:32,870 iteration 4954 : loss : 0.056660, loss_ce: 0.015048
2021-12-14 03:36:34,322 iteration 4955 : loss : 0.044170, loss_ce: 0.016694
2021-12-14 03:36:35,882 iteration 4956 : loss : 0.053978, loss_ce: 0.014844
2021-12-14 03:36:37,404 iteration 4957 : loss : 0.050158, loss_ce: 0.016058
2021-12-14 03:36:39,126 iteration 4958 : loss : 0.053454, loss_ce: 0.020080
2021-12-14 03:36:40,760 iteration 4959 : loss : 0.053513, loss_ce: 0.018506
2021-12-14 03:36:42,451 iteration 4960 : loss : 0.053166, loss_ce: 0.019826
2021-12-14 03:36:43,962 iteration 4961 : loss : 0.058316, loss_ce: 0.014796
2021-12-14 03:36:45,502 iteration 4962 : loss : 0.050639, loss_ce: 0.019706
2021-12-14 03:36:47,081 iteration 4963 : loss : 0.050257, loss_ce: 0.016202
2021-12-14 03:36:48,653 iteration 4964 : loss : 0.042929, loss_ce: 0.011720
 73%|█████████████████████▏       | 292/400 [2:17:53<50:18, 27.95s/it]2021-12-14 03:36:50,198 iteration 4965 : loss : 0.050869, loss_ce: 0.014491
2021-12-14 03:36:51,739 iteration 4966 : loss : 0.047102, loss_ce: 0.015455
2021-12-14 03:36:53,280 iteration 4967 : loss : 0.052729, loss_ce: 0.013188
2021-12-14 03:36:54,788 iteration 4968 : loss : 0.076245, loss_ce: 0.015959
2021-12-14 03:36:56,331 iteration 4969 : loss : 0.047407, loss_ce: 0.015914
2021-12-14 03:36:57,920 iteration 4970 : loss : 0.059823, loss_ce: 0.025246
2021-12-14 03:36:59,418 iteration 4971 : loss : 0.049563, loss_ce: 0.015255
2021-12-14 03:37:00,865 iteration 4972 : loss : 0.049432, loss_ce: 0.013451
2021-12-14 03:37:02,353 iteration 4973 : loss : 0.041825, loss_ce: 0.012182
2021-12-14 03:37:03,906 iteration 4974 : loss : 0.052344, loss_ce: 0.023770
2021-12-14 03:37:05,533 iteration 4975 : loss : 0.041430, loss_ce: 0.012998
2021-12-14 03:37:07,011 iteration 4976 : loss : 0.041130, loss_ce: 0.012781
2021-12-14 03:37:08,529 iteration 4977 : loss : 0.044327, loss_ce: 0.015176
2021-12-14 03:37:10,058 iteration 4978 : loss : 0.056752, loss_ce: 0.019941
2021-12-14 03:37:11,521 iteration 4979 : loss : 0.039711, loss_ce: 0.010981
2021-12-14 03:37:12,948 iteration 4980 : loss : 0.040425, loss_ce: 0.011683
2021-12-14 03:37:14,452 iteration 4981 : loss : 0.050369, loss_ce: 0.017150
 73%|█████████████████████▏       | 293/400 [2:18:19<48:41, 27.30s/it]2021-12-14 03:37:16,055 iteration 4982 : loss : 0.053844, loss_ce: 0.011303
2021-12-14 03:37:17,480 iteration 4983 : loss : 0.046755, loss_ce: 0.013441
2021-12-14 03:37:19,024 iteration 4984 : loss : 0.048807, loss_ce: 0.011464
2021-12-14 03:37:20,440 iteration 4985 : loss : 0.043163, loss_ce: 0.013645
2021-12-14 03:37:21,894 iteration 4986 : loss : 0.046810, loss_ce: 0.014074
2021-12-14 03:37:23,435 iteration 4987 : loss : 0.045926, loss_ce: 0.018375
2021-12-14 03:37:24,973 iteration 4988 : loss : 0.051957, loss_ce: 0.021102
2021-12-14 03:37:26,453 iteration 4989 : loss : 0.059524, loss_ce: 0.022454
2021-12-14 03:37:28,007 iteration 4990 : loss : 0.049306, loss_ce: 0.018566
2021-12-14 03:37:29,493 iteration 4991 : loss : 0.055611, loss_ce: 0.016916
2021-12-14 03:37:31,017 iteration 4992 : loss : 0.055594, loss_ce: 0.015469
2021-12-14 03:37:32,534 iteration 4993 : loss : 0.054878, loss_ce: 0.019836
2021-12-14 03:37:34,246 iteration 4994 : loss : 0.052661, loss_ce: 0.017318
2021-12-14 03:37:35,844 iteration 4995 : loss : 0.056450, loss_ce: 0.022283
2021-12-14 03:37:37,321 iteration 4996 : loss : 0.047775, loss_ce: 0.012619
2021-12-14 03:37:38,866 iteration 4997 : loss : 0.048465, loss_ce: 0.014626
2021-12-14 03:37:40,410 iteration 4998 : loss : 0.047738, loss_ce: 0.014483
 74%|█████████████████████▎       | 294/400 [2:18:45<47:31, 26.90s/it]2021-12-14 03:37:41,997 iteration 4999 : loss : 0.045177, loss_ce: 0.015564
2021-12-14 03:37:43,424 iteration 5000 : loss : 0.045595, loss_ce: 0.013516
2021-12-14 03:37:45,003 iteration 5001 : loss : 0.050737, loss_ce: 0.013659
2021-12-14 03:37:46,634 iteration 5002 : loss : 0.056994, loss_ce: 0.016858
2021-12-14 03:37:48,302 iteration 5003 : loss : 0.054390, loss_ce: 0.021107
2021-12-14 03:37:49,821 iteration 5004 : loss : 0.043077, loss_ce: 0.015414
2021-12-14 03:37:51,379 iteration 5005 : loss : 0.048607, loss_ce: 0.017188
2021-12-14 03:37:52,834 iteration 5006 : loss : 0.046524, loss_ce: 0.014918
2021-12-14 03:37:54,384 iteration 5007 : loss : 0.052270, loss_ce: 0.012987
2021-12-14 03:37:55,841 iteration 5008 : loss : 0.051700, loss_ce: 0.013967
2021-12-14 03:37:57,285 iteration 5009 : loss : 0.044095, loss_ce: 0.018173
2021-12-14 03:37:58,853 iteration 5010 : loss : 0.046237, loss_ce: 0.017636
2021-12-14 03:38:00,302 iteration 5011 : loss : 0.047773, loss_ce: 0.017160
2021-12-14 03:38:01,788 iteration 5012 : loss : 0.055757, loss_ce: 0.013624
2021-12-14 03:38:03,424 iteration 5013 : loss : 0.048534, loss_ce: 0.017576
2021-12-14 03:38:04,844 iteration 5014 : loss : 0.050438, loss_ce: 0.015904
2021-12-14 03:38:04,844 Training Data Eval:
2021-12-14 03:38:12,291   Average segmentation loss on training set: 0.0375
2021-12-14 03:38:12,291 Validation Data Eval:
2021-12-14 03:38:14,859   Average segmentation loss on validation set: 0.0911
2021-12-14 03:38:16,350 iteration 5015 : loss : 0.056560, loss_ce: 0.018410
 74%|█████████████████████▍       | 295/400 [2:19:21<51:49, 29.61s/it]2021-12-14 03:38:17,962 iteration 5016 : loss : 0.053695, loss_ce: 0.020011
2021-12-14 03:38:19,363 iteration 5017 : loss : 0.042877, loss_ce: 0.013280
2021-12-14 03:38:21,006 iteration 5018 : loss : 0.045469, loss_ce: 0.016977
2021-12-14 03:38:22,439 iteration 5019 : loss : 0.047281, loss_ce: 0.014911
2021-12-14 03:38:24,032 iteration 5020 : loss : 0.062664, loss_ce: 0.018371
2021-12-14 03:38:25,549 iteration 5021 : loss : 0.069050, loss_ce: 0.023664
2021-12-14 03:38:27,055 iteration 5022 : loss : 0.055086, loss_ce: 0.018342
2021-12-14 03:38:28,561 iteration 5023 : loss : 0.058861, loss_ce: 0.025776
2021-12-14 03:38:30,167 iteration 5024 : loss : 0.052007, loss_ce: 0.017095
2021-12-14 03:38:31,698 iteration 5025 : loss : 0.051208, loss_ce: 0.016265
2021-12-14 03:38:33,299 iteration 5026 : loss : 0.052949, loss_ce: 0.014504
2021-12-14 03:38:34,757 iteration 5027 : loss : 0.041567, loss_ce: 0.013024
2021-12-14 03:38:36,186 iteration 5028 : loss : 0.043479, loss_ce: 0.015606
2021-12-14 03:38:37,786 iteration 5029 : loss : 0.056986, loss_ce: 0.019907
2021-12-14 03:38:39,266 iteration 5030 : loss : 0.040726, loss_ce: 0.013197
2021-12-14 03:38:40,852 iteration 5031 : loss : 0.077209, loss_ce: 0.023465
2021-12-14 03:38:42,268 iteration 5032 : loss : 0.048373, loss_ce: 0.014904
 74%|█████████████████████▍       | 296/400 [2:19:47<49:24, 28.50s/it]2021-12-14 03:38:43,762 iteration 5033 : loss : 0.055279, loss_ce: 0.018168
2021-12-14 03:38:45,208 iteration 5034 : loss : 0.057283, loss_ce: 0.016090
2021-12-14 03:38:46,712 iteration 5035 : loss : 0.049716, loss_ce: 0.014709
2021-12-14 03:38:48,158 iteration 5036 : loss : 0.058839, loss_ce: 0.021059
2021-12-14 03:38:49,651 iteration 5037 : loss : 0.047108, loss_ce: 0.014305
2021-12-14 03:38:51,123 iteration 5038 : loss : 0.045208, loss_ce: 0.012596
2021-12-14 03:38:52,659 iteration 5039 : loss : 0.049001, loss_ce: 0.016760
2021-12-14 03:38:54,232 iteration 5040 : loss : 0.051949, loss_ce: 0.016177
2021-12-14 03:38:55,741 iteration 5041 : loss : 0.059079, loss_ce: 0.020697
2021-12-14 03:38:57,390 iteration 5042 : loss : 0.052341, loss_ce: 0.017262
2021-12-14 03:38:58,778 iteration 5043 : loss : 0.039982, loss_ce: 0.011858
2021-12-14 03:39:00,345 iteration 5044 : loss : 0.042691, loss_ce: 0.012222
2021-12-14 03:39:01,890 iteration 5045 : loss : 0.059753, loss_ce: 0.023798
2021-12-14 03:39:03,422 iteration 5046 : loss : 0.054075, loss_ce: 0.012893
2021-12-14 03:39:04,863 iteration 5047 : loss : 0.037602, loss_ce: 0.009616
2021-12-14 03:39:06,275 iteration 5048 : loss : 0.041496, loss_ce: 0.015298
2021-12-14 03:39:07,673 iteration 5049 : loss : 0.044288, loss_ce: 0.016754
 74%|█████████████████████▌       | 297/400 [2:20:12<47:20, 27.57s/it]2021-12-14 03:39:09,289 iteration 5050 : loss : 0.052619, loss_ce: 0.014691
2021-12-14 03:39:10,893 iteration 5051 : loss : 0.054814, loss_ce: 0.017115
2021-12-14 03:39:12,529 iteration 5052 : loss : 0.056109, loss_ce: 0.020384
2021-12-14 03:39:14,146 iteration 5053 : loss : 0.053649, loss_ce: 0.016114
2021-12-14 03:39:15,637 iteration 5054 : loss : 0.047066, loss_ce: 0.010682
2021-12-14 03:39:17,179 iteration 5055 : loss : 0.046498, loss_ce: 0.014874
2021-12-14 03:39:18,720 iteration 5056 : loss : 0.061650, loss_ce: 0.022785
2021-12-14 03:39:20,361 iteration 5057 : loss : 0.066350, loss_ce: 0.024422
2021-12-14 03:39:22,006 iteration 5058 : loss : 0.057435, loss_ce: 0.018787
2021-12-14 03:39:23,517 iteration 5059 : loss : 0.050605, loss_ce: 0.017255
2021-12-14 03:39:25,101 iteration 5060 : loss : 0.048981, loss_ce: 0.017692
2021-12-14 03:39:26,711 iteration 5061 : loss : 0.056702, loss_ce: 0.017668
2021-12-14 03:39:28,388 iteration 5062 : loss : 0.052224, loss_ce: 0.015362
2021-12-14 03:39:30,032 iteration 5063 : loss : 0.054048, loss_ce: 0.019102
2021-12-14 03:39:31,534 iteration 5064 : loss : 0.048850, loss_ce: 0.015587
2021-12-14 03:39:33,140 iteration 5065 : loss : 0.046709, loss_ce: 0.019592
2021-12-14 03:39:34,601 iteration 5066 : loss : 0.044693, loss_ce: 0.015519
 74%|█████████████████████▌       | 298/400 [2:20:39<46:32, 27.38s/it]2021-12-14 03:39:36,020 iteration 5067 : loss : 0.047079, loss_ce: 0.014757
2021-12-14 03:39:37,589 iteration 5068 : loss : 0.044708, loss_ce: 0.012172
2021-12-14 03:39:39,142 iteration 5069 : loss : 0.045518, loss_ce: 0.017499
2021-12-14 03:39:40,586 iteration 5070 : loss : 0.049384, loss_ce: 0.015874
2021-12-14 03:39:42,148 iteration 5071 : loss : 0.051540, loss_ce: 0.019642
2021-12-14 03:39:43,577 iteration 5072 : loss : 0.042293, loss_ce: 0.014334
2021-12-14 03:39:45,188 iteration 5073 : loss : 0.048060, loss_ce: 0.016763
2021-12-14 03:39:46,668 iteration 5074 : loss : 0.041984, loss_ce: 0.014737
2021-12-14 03:39:48,151 iteration 5075 : loss : 0.054358, loss_ce: 0.019481
2021-12-14 03:39:49,712 iteration 5076 : loss : 0.070970, loss_ce: 0.013388
2021-12-14 03:39:51,247 iteration 5077 : loss : 0.054383, loss_ce: 0.016040
2021-12-14 03:39:52,693 iteration 5078 : loss : 0.054101, loss_ce: 0.023086
2021-12-14 03:39:54,134 iteration 5079 : loss : 0.047740, loss_ce: 0.015672
2021-12-14 03:39:55,602 iteration 5080 : loss : 0.044736, loss_ce: 0.015093
2021-12-14 03:39:57,154 iteration 5081 : loss : 0.054228, loss_ce: 0.014271
2021-12-14 03:39:58,643 iteration 5082 : loss : 0.042099, loss_ce: 0.013142
2021-12-14 03:40:00,188 iteration 5083 : loss : 0.072102, loss_ce: 0.011296
 75%|█████████████████████▋       | 299/400 [2:21:05<45:11, 26.84s/it]2021-12-14 03:40:01,811 iteration 5084 : loss : 0.047312, loss_ce: 0.018293
2021-12-14 03:40:03,449 iteration 5085 : loss : 0.061578, loss_ce: 0.019718
2021-12-14 03:40:05,025 iteration 5086 : loss : 0.046811, loss_ce: 0.013769
2021-12-14 03:40:06,484 iteration 5087 : loss : 0.053917, loss_ce: 0.019809
2021-12-14 03:40:07,930 iteration 5088 : loss : 0.055329, loss_ce: 0.020593
2021-12-14 03:40:09,486 iteration 5089 : loss : 0.053897, loss_ce: 0.015185
2021-12-14 03:40:11,011 iteration 5090 : loss : 0.045331, loss_ce: 0.009045
2021-12-14 03:40:12,615 iteration 5091 : loss : 0.048201, loss_ce: 0.014404
2021-12-14 03:40:14,161 iteration 5092 : loss : 0.051925, loss_ce: 0.016007
2021-12-14 03:40:15,614 iteration 5093 : loss : 0.041717, loss_ce: 0.010955
2021-12-14 03:40:17,193 iteration 5094 : loss : 0.047560, loss_ce: 0.015367
2021-12-14 03:40:18,634 iteration 5095 : loss : 0.044516, loss_ce: 0.014947
2021-12-14 03:40:20,130 iteration 5096 : loss : 0.050331, loss_ce: 0.019174
2021-12-14 03:40:21,564 iteration 5097 : loss : 0.063731, loss_ce: 0.026340
2021-12-14 03:40:23,173 iteration 5098 : loss : 0.050530, loss_ce: 0.014223
2021-12-14 03:40:24,722 iteration 5099 : loss : 0.052374, loss_ce: 0.016312
2021-12-14 03:40:24,722 Training Data Eval:
2021-12-14 03:40:32,152   Average segmentation loss on training set: 0.0372
2021-12-14 03:40:32,152 Validation Data Eval:
2021-12-14 03:40:34,721   Average segmentation loss on validation set: 0.0855
2021-12-14 03:40:40,779 Found new lowest validation loss at iteration 5099! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 03:40:42,409 iteration 5100 : loss : 0.058927, loss_ce: 0.014208
 75%|█████████████████████▊       | 300/400 [2:21:47<52:25, 31.46s/it]2021-12-14 03:40:44,104 iteration 5101 : loss : 0.050091, loss_ce: 0.017010
2021-12-14 03:40:45,612 iteration 5102 : loss : 0.049612, loss_ce: 0.015956
2021-12-14 03:40:47,152 iteration 5103 : loss : 0.048786, loss_ce: 0.021570
2021-12-14 03:40:48,760 iteration 5104 : loss : 0.052754, loss_ce: 0.013917
2021-12-14 03:40:50,242 iteration 5105 : loss : 0.053355, loss_ce: 0.016180
2021-12-14 03:40:51,720 iteration 5106 : loss : 0.043961, loss_ce: 0.014000
2021-12-14 03:40:53,330 iteration 5107 : loss : 0.077989, loss_ce: 0.026539
2021-12-14 03:40:54,878 iteration 5108 : loss : 0.053733, loss_ce: 0.021795
2021-12-14 03:40:56,406 iteration 5109 : loss : 0.056344, loss_ce: 0.019178
2021-12-14 03:40:57,873 iteration 5110 : loss : 0.043274, loss_ce: 0.011435
2021-12-14 03:40:59,425 iteration 5111 : loss : 0.050189, loss_ce: 0.015247
2021-12-14 03:41:01,076 iteration 5112 : loss : 0.051633, loss_ce: 0.015730
2021-12-14 03:41:02,628 iteration 5113 : loss : 0.051458, loss_ce: 0.014911
2021-12-14 03:41:04,266 iteration 5114 : loss : 0.049645, loss_ce: 0.015153
2021-12-14 03:41:05,787 iteration 5115 : loss : 0.054575, loss_ce: 0.016906
2021-12-14 03:41:07,270 iteration 5116 : loss : 0.044028, loss_ce: 0.015358
2021-12-14 03:41:08,836 iteration 5117 : loss : 0.052431, loss_ce: 0.019294
 75%|█████████████████████▊       | 301/400 [2:22:14<49:25, 29.95s/it]2021-12-14 03:41:10,466 iteration 5118 : loss : 0.055913, loss_ce: 0.014436
2021-12-14 03:41:11,965 iteration 5119 : loss : 0.046084, loss_ce: 0.017838
2021-12-14 03:41:13,412 iteration 5120 : loss : 0.042216, loss_ce: 0.014805
2021-12-14 03:41:15,009 iteration 5121 : loss : 0.048803, loss_ce: 0.012254
2021-12-14 03:41:16,655 iteration 5122 : loss : 0.047679, loss_ce: 0.017309
2021-12-14 03:41:18,282 iteration 5123 : loss : 0.066245, loss_ce: 0.018634
2021-12-14 03:41:19,733 iteration 5124 : loss : 0.042056, loss_ce: 0.016520
2021-12-14 03:41:21,181 iteration 5125 : loss : 0.045761, loss_ce: 0.013696
2021-12-14 03:41:22,711 iteration 5126 : loss : 0.053030, loss_ce: 0.017529
2021-12-14 03:41:24,219 iteration 5127 : loss : 0.050392, loss_ce: 0.019263
2021-12-14 03:41:25,687 iteration 5128 : loss : 0.057397, loss_ce: 0.014346
2021-12-14 03:41:27,240 iteration 5129 : loss : 0.053752, loss_ce: 0.020743
2021-12-14 03:41:28,750 iteration 5130 : loss : 0.047015, loss_ce: 0.016733
2021-12-14 03:41:30,293 iteration 5131 : loss : 0.047238, loss_ce: 0.016367
2021-12-14 03:41:31,803 iteration 5132 : loss : 0.049127, loss_ce: 0.016573
2021-12-14 03:41:33,409 iteration 5133 : loss : 0.060504, loss_ce: 0.020611
2021-12-14 03:41:34,929 iteration 5134 : loss : 0.053546, loss_ce: 0.013746
 76%|█████████████████████▉       | 302/400 [2:22:40<47:01, 28.79s/it]2021-12-14 03:41:36,482 iteration 5135 : loss : 0.060705, loss_ce: 0.028254
2021-12-14 03:41:38,002 iteration 5136 : loss : 0.047131, loss_ce: 0.013908
2021-12-14 03:41:39,443 iteration 5137 : loss : 0.048331, loss_ce: 0.015466
2021-12-14 03:41:41,012 iteration 5138 : loss : 0.046484, loss_ce: 0.016769
2021-12-14 03:41:42,661 iteration 5139 : loss : 0.049165, loss_ce: 0.016248
2021-12-14 03:41:44,286 iteration 5140 : loss : 0.061529, loss_ce: 0.021080
2021-12-14 03:41:45,738 iteration 5141 : loss : 0.049666, loss_ce: 0.014960
2021-12-14 03:41:47,287 iteration 5142 : loss : 0.045303, loss_ce: 0.013282
2021-12-14 03:41:48,796 iteration 5143 : loss : 0.044893, loss_ce: 0.019056
2021-12-14 03:41:50,429 iteration 5144 : loss : 0.043794, loss_ce: 0.014811
2021-12-14 03:41:52,139 iteration 5145 : loss : 0.040640, loss_ce: 0.010432
2021-12-14 03:41:53,722 iteration 5146 : loss : 0.049266, loss_ce: 0.015809
2021-12-14 03:41:55,167 iteration 5147 : loss : 0.052313, loss_ce: 0.011943
2021-12-14 03:41:56,686 iteration 5148 : loss : 0.049998, loss_ce: 0.014246
2021-12-14 03:41:58,189 iteration 5149 : loss : 0.060677, loss_ce: 0.021392
2021-12-14 03:41:59,678 iteration 5150 : loss : 0.058876, loss_ce: 0.023403
2021-12-14 03:42:01,259 iteration 5151 : loss : 0.056980, loss_ce: 0.020907
 76%|█████████████████████▉       | 303/400 [2:23:06<45:21, 28.05s/it]2021-12-14 03:42:02,819 iteration 5152 : loss : 0.064692, loss_ce: 0.025956
2021-12-14 03:42:04,354 iteration 5153 : loss : 0.047988, loss_ce: 0.015487
2021-12-14 03:42:05,783 iteration 5154 : loss : 0.047792, loss_ce: 0.015503
2021-12-14 03:42:07,243 iteration 5155 : loss : 0.041257, loss_ce: 0.013425
2021-12-14 03:42:08,753 iteration 5156 : loss : 0.045504, loss_ce: 0.010760
2021-12-14 03:42:10,190 iteration 5157 : loss : 0.039416, loss_ce: 0.012126
2021-12-14 03:42:11,667 iteration 5158 : loss : 0.046693, loss_ce: 0.016622
2021-12-14 03:42:13,208 iteration 5159 : loss : 0.044191, loss_ce: 0.014378
2021-12-14 03:42:14,735 iteration 5160 : loss : 0.047544, loss_ce: 0.016962
2021-12-14 03:42:16,290 iteration 5161 : loss : 0.045094, loss_ce: 0.014639
2021-12-14 03:42:17,919 iteration 5162 : loss : 0.048359, loss_ce: 0.011877
2021-12-14 03:42:19,477 iteration 5163 : loss : 0.054320, loss_ce: 0.022821
2021-12-14 03:42:20,932 iteration 5164 : loss : 0.047385, loss_ce: 0.014326
2021-12-14 03:42:22,559 iteration 5165 : loss : 0.048962, loss_ce: 0.015235
2021-12-14 03:42:24,108 iteration 5166 : loss : 0.051547, loss_ce: 0.016379
2021-12-14 03:42:25,684 iteration 5167 : loss : 0.052044, loss_ce: 0.014602
2021-12-14 03:42:27,086 iteration 5168 : loss : 0.049404, loss_ce: 0.018521
 76%|██████████████████████       | 304/400 [2:23:32<43:49, 27.39s/it]2021-12-14 03:42:28,744 iteration 5169 : loss : 0.046395, loss_ce: 0.012082
2021-12-14 03:42:30,245 iteration 5170 : loss : 0.051978, loss_ce: 0.021949
2021-12-14 03:42:31,764 iteration 5171 : loss : 0.059277, loss_ce: 0.017960
2021-12-14 03:42:33,309 iteration 5172 : loss : 0.051934, loss_ce: 0.015038
2021-12-14 03:42:34,948 iteration 5173 : loss : 0.052033, loss_ce: 0.019383
2021-12-14 03:42:36,487 iteration 5174 : loss : 0.037274, loss_ce: 0.009588
2021-12-14 03:42:38,058 iteration 5175 : loss : 0.044422, loss_ce: 0.013161
2021-12-14 03:42:39,699 iteration 5176 : loss : 0.044890, loss_ce: 0.014071
2021-12-14 03:42:41,245 iteration 5177 : loss : 0.045693, loss_ce: 0.013423
2021-12-14 03:42:42,792 iteration 5178 : loss : 0.044065, loss_ce: 0.015207
2021-12-14 03:42:44,277 iteration 5179 : loss : 0.047720, loss_ce: 0.018310
2021-12-14 03:42:45,710 iteration 5180 : loss : 0.043965, loss_ce: 0.015478
2021-12-14 03:42:47,189 iteration 5181 : loss : 0.053101, loss_ce: 0.015851
2021-12-14 03:42:48,676 iteration 5182 : loss : 0.047973, loss_ce: 0.017701
2021-12-14 03:42:50,167 iteration 5183 : loss : 0.045270, loss_ce: 0.012747
2021-12-14 03:42:51,624 iteration 5184 : loss : 0.048633, loss_ce: 0.019194
2021-12-14 03:42:51,624 Training Data Eval:
2021-12-14 03:42:59,076   Average segmentation loss on training set: 0.0372
2021-12-14 03:42:59,076 Validation Data Eval:
2021-12-14 03:43:01,649   Average segmentation loss on validation set: 0.0865
2021-12-14 03:43:03,131 iteration 5185 : loss : 0.043379, loss_ce: 0.014871
 76%|██████████████████████       | 305/400 [2:24:08<47:28, 29.98s/it]2021-12-14 03:43:04,778 iteration 5186 : loss : 0.055998, loss_ce: 0.014485
2021-12-14 03:43:06,211 iteration 5187 : loss : 0.048188, loss_ce: 0.016839
2021-12-14 03:43:07,720 iteration 5188 : loss : 0.043944, loss_ce: 0.012071
2021-12-14 03:43:09,265 iteration 5189 : loss : 0.077112, loss_ce: 0.020361
2021-12-14 03:43:10,915 iteration 5190 : loss : 0.050608, loss_ce: 0.013697
2021-12-14 03:43:12,406 iteration 5191 : loss : 0.050048, loss_ce: 0.016484
2021-12-14 03:43:13,922 iteration 5192 : loss : 0.051092, loss_ce: 0.018554
2021-12-14 03:43:15,510 iteration 5193 : loss : 0.047176, loss_ce: 0.016702
2021-12-14 03:43:17,072 iteration 5194 : loss : 0.045900, loss_ce: 0.012102
2021-12-14 03:43:18,578 iteration 5195 : loss : 0.054340, loss_ce: 0.012769
2021-12-14 03:43:20,239 iteration 5196 : loss : 0.057944, loss_ce: 0.016661
2021-12-14 03:43:21,759 iteration 5197 : loss : 0.047097, loss_ce: 0.012097
2021-12-14 03:43:23,215 iteration 5198 : loss : 0.044376, loss_ce: 0.019494
2021-12-14 03:43:24,884 iteration 5199 : loss : 0.047579, loss_ce: 0.015853
2021-12-14 03:43:26,309 iteration 5200 : loss : 0.046842, loss_ce: 0.018433
2021-12-14 03:43:27,746 iteration 5201 : loss : 0.043340, loss_ce: 0.015524
2021-12-14 03:43:29,229 iteration 5202 : loss : 0.049276, loss_ce: 0.015832
 76%|██████████████████████▏      | 306/400 [2:24:34<45:09, 28.82s/it]2021-12-14 03:43:30,783 iteration 5203 : loss : 0.051294, loss_ce: 0.019829
2021-12-14 03:43:32,396 iteration 5204 : loss : 0.050049, loss_ce: 0.018591
2021-12-14 03:43:33,969 iteration 5205 : loss : 0.057750, loss_ce: 0.014856
2021-12-14 03:43:35,673 iteration 5206 : loss : 0.051230, loss_ce: 0.017628
2021-12-14 03:43:37,284 iteration 5207 : loss : 0.062719, loss_ce: 0.012744
2021-12-14 03:43:38,839 iteration 5208 : loss : 0.040100, loss_ce: 0.013365
2021-12-14 03:43:40,433 iteration 5209 : loss : 0.055676, loss_ce: 0.018706
2021-12-14 03:43:42,025 iteration 5210 : loss : 0.051648, loss_ce: 0.020877
2021-12-14 03:43:43,548 iteration 5211 : loss : 0.045325, loss_ce: 0.013849
2021-12-14 03:43:45,144 iteration 5212 : loss : 0.052780, loss_ce: 0.014386
2021-12-14 03:43:46,641 iteration 5213 : loss : 0.050395, loss_ce: 0.015965
2021-12-14 03:43:48,165 iteration 5214 : loss : 0.044272, loss_ce: 0.016968
2021-12-14 03:43:49,578 iteration 5215 : loss : 0.042012, loss_ce: 0.012056
2021-12-14 03:43:51,052 iteration 5216 : loss : 0.047337, loss_ce: 0.013066
2021-12-14 03:43:52,657 iteration 5217 : loss : 0.057647, loss_ce: 0.021123
2021-12-14 03:43:54,105 iteration 5218 : loss : 0.040470, loss_ce: 0.011663
2021-12-14 03:43:55,631 iteration 5219 : loss : 0.041432, loss_ce: 0.013887
 77%|██████████████████████▎      | 307/400 [2:25:00<43:32, 28.09s/it]2021-12-14 03:43:57,096 iteration 5220 : loss : 0.040147, loss_ce: 0.014176
2021-12-14 03:43:58,520 iteration 5221 : loss : 0.051458, loss_ce: 0.012453
2021-12-14 03:44:00,102 iteration 5222 : loss : 0.053778, loss_ce: 0.013835
2021-12-14 03:44:01,604 iteration 5223 : loss : 0.047930, loss_ce: 0.018330
2021-12-14 03:44:03,227 iteration 5224 : loss : 0.062399, loss_ce: 0.014131
2021-12-14 03:44:04,720 iteration 5225 : loss : 0.041850, loss_ce: 0.015599
2021-12-14 03:44:06,264 iteration 5226 : loss : 0.043007, loss_ce: 0.014721
2021-12-14 03:44:07,804 iteration 5227 : loss : 0.067863, loss_ce: 0.018413
2021-12-14 03:44:09,217 iteration 5228 : loss : 0.046477, loss_ce: 0.013761
2021-12-14 03:44:10,782 iteration 5229 : loss : 0.050873, loss_ce: 0.017733
2021-12-14 03:44:12,220 iteration 5230 : loss : 0.041341, loss_ce: 0.010897
2021-12-14 03:44:13,753 iteration 5231 : loss : 0.045948, loss_ce: 0.012886
2021-12-14 03:44:15,405 iteration 5232 : loss : 0.057790, loss_ce: 0.018698
2021-12-14 03:44:16,774 iteration 5233 : loss : 0.045182, loss_ce: 0.016429
2021-12-14 03:44:18,268 iteration 5234 : loss : 0.048824, loss_ce: 0.016744
2021-12-14 03:44:19,846 iteration 5235 : loss : 0.058473, loss_ce: 0.022626
2021-12-14 03:44:21,486 iteration 5236 : loss : 0.065445, loss_ce: 0.024319
 77%|██████████████████████▎      | 308/400 [2:25:26<42:02, 27.42s/it]2021-12-14 03:44:22,969 iteration 5237 : loss : 0.040837, loss_ce: 0.015769
2021-12-14 03:44:24,477 iteration 5238 : loss : 0.045216, loss_ce: 0.015930
2021-12-14 03:44:25,973 iteration 5239 : loss : 0.045683, loss_ce: 0.014073
2021-12-14 03:44:27,578 iteration 5240 : loss : 0.062504, loss_ce: 0.010985
2021-12-14 03:44:29,130 iteration 5241 : loss : 0.057350, loss_ce: 0.016926
2021-12-14 03:44:30,786 iteration 5242 : loss : 0.044774, loss_ce: 0.016776
2021-12-14 03:44:32,356 iteration 5243 : loss : 0.057655, loss_ce: 0.022438
2021-12-14 03:44:33,876 iteration 5244 : loss : 0.042929, loss_ce: 0.012166
2021-12-14 03:44:35,492 iteration 5245 : loss : 0.051897, loss_ce: 0.015015
2021-12-14 03:44:37,038 iteration 5246 : loss : 0.063785, loss_ce: 0.018810
2021-12-14 03:44:38,539 iteration 5247 : loss : 0.051585, loss_ce: 0.015425
2021-12-14 03:44:40,153 iteration 5248 : loss : 0.046232, loss_ce: 0.019176
2021-12-14 03:44:41,662 iteration 5249 : loss : 0.045441, loss_ce: 0.013758
2021-12-14 03:44:43,194 iteration 5250 : loss : 0.044394, loss_ce: 0.013662
2021-12-14 03:44:44,792 iteration 5251 : loss : 0.055160, loss_ce: 0.018719
2021-12-14 03:44:46,299 iteration 5252 : loss : 0.043609, loss_ce: 0.017968
2021-12-14 03:44:47,782 iteration 5253 : loss : 0.046392, loss_ce: 0.014234
 77%|██████████████████████▍      | 309/400 [2:25:53<41:04, 27.08s/it]2021-12-14 03:44:49,349 iteration 5254 : loss : 0.049095, loss_ce: 0.018833
2021-12-14 03:44:50,946 iteration 5255 : loss : 0.049914, loss_ce: 0.013167
2021-12-14 03:44:52,479 iteration 5256 : loss : 0.051116, loss_ce: 0.019332
2021-12-14 03:44:54,034 iteration 5257 : loss : 0.047289, loss_ce: 0.015498
2021-12-14 03:44:55,457 iteration 5258 : loss : 0.042797, loss_ce: 0.015132
2021-12-14 03:44:56,946 iteration 5259 : loss : 0.061371, loss_ce: 0.017174
2021-12-14 03:44:58,576 iteration 5260 : loss : 0.044939, loss_ce: 0.013209
2021-12-14 03:45:00,089 iteration 5261 : loss : 0.045349, loss_ce: 0.015415
2021-12-14 03:45:01,577 iteration 5262 : loss : 0.051183, loss_ce: 0.017629
2021-12-14 03:45:03,163 iteration 5263 : loss : 0.053239, loss_ce: 0.018890
2021-12-14 03:45:04,727 iteration 5264 : loss : 0.052563, loss_ce: 0.018492
2021-12-14 03:45:06,310 iteration 5265 : loss : 0.050082, loss_ce: 0.016782
2021-12-14 03:45:07,802 iteration 5266 : loss : 0.047567, loss_ce: 0.014202
2021-12-14 03:45:09,428 iteration 5267 : loss : 0.061388, loss_ce: 0.022066
2021-12-14 03:45:10,776 iteration 5268 : loss : 0.046882, loss_ce: 0.010157
2021-12-14 03:45:12,159 iteration 5269 : loss : 0.042492, loss_ce: 0.013566
2021-12-14 03:45:12,159 Training Data Eval:
2021-12-14 03:45:19,605   Average segmentation loss on training set: 0.0369
2021-12-14 03:45:19,605 Validation Data Eval:
2021-12-14 03:45:22,175   Average segmentation loss on validation set: 0.0837
2021-12-14 03:45:26,939 Found new lowest validation loss at iteration 5269! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 03:45:28,434 iteration 5270 : loss : 0.084150, loss_ce: 0.012016
 78%|██████████████████████▍      | 310/400 [2:26:33<46:43, 31.15s/it]2021-12-14 03:45:30,149 iteration 5271 : loss : 0.049139, loss_ce: 0.013777
2021-12-14 03:45:31,794 iteration 5272 : loss : 0.050510, loss_ce: 0.017551
2021-12-14 03:45:33,360 iteration 5273 : loss : 0.053578, loss_ce: 0.020456
2021-12-14 03:45:34,884 iteration 5274 : loss : 0.049973, loss_ce: 0.017544
2021-12-14 03:45:36,362 iteration 5275 : loss : 0.043990, loss_ce: 0.014904
2021-12-14 03:45:37,832 iteration 5276 : loss : 0.053085, loss_ce: 0.014733
2021-12-14 03:45:39,485 iteration 5277 : loss : 0.058452, loss_ce: 0.023189
2021-12-14 03:45:40,985 iteration 5278 : loss : 0.055924, loss_ce: 0.011831
2021-12-14 03:45:42,566 iteration 5279 : loss : 0.052896, loss_ce: 0.017417
2021-12-14 03:45:44,017 iteration 5280 : loss : 0.048391, loss_ce: 0.012936
2021-12-14 03:45:45,489 iteration 5281 : loss : 0.045802, loss_ce: 0.017516
2021-12-14 03:45:46,959 iteration 5282 : loss : 0.051278, loss_ce: 0.018014
2021-12-14 03:45:48,429 iteration 5283 : loss : 0.059594, loss_ce: 0.020163
2021-12-14 03:45:49,954 iteration 5284 : loss : 0.044394, loss_ce: 0.013052
2021-12-14 03:45:51,438 iteration 5285 : loss : 0.046313, loss_ce: 0.014768
2021-12-14 03:45:52,893 iteration 5286 : loss : 0.050480, loss_ce: 0.020221
2021-12-14 03:45:54,451 iteration 5287 : loss : 0.042032, loss_ce: 0.012327
 78%|██████████████████████▌      | 311/400 [2:26:59<43:55, 29.62s/it]2021-12-14 03:45:56,040 iteration 5288 : loss : 0.050066, loss_ce: 0.020186
2021-12-14 03:45:57,494 iteration 5289 : loss : 0.053659, loss_ce: 0.017768
2021-12-14 03:45:59,202 iteration 5290 : loss : 0.053441, loss_ce: 0.014518
2021-12-14 03:46:00,727 iteration 5291 : loss : 0.045836, loss_ce: 0.015057
2021-12-14 03:46:02,285 iteration 5292 : loss : 0.042111, loss_ce: 0.009290
2021-12-14 03:46:03,736 iteration 5293 : loss : 0.054703, loss_ce: 0.017413
2021-12-14 03:46:05,322 iteration 5294 : loss : 0.059662, loss_ce: 0.017615
2021-12-14 03:46:06,849 iteration 5295 : loss : 0.050084, loss_ce: 0.013194
2021-12-14 03:46:08,280 iteration 5296 : loss : 0.061754, loss_ce: 0.015075
2021-12-14 03:46:09,775 iteration 5297 : loss : 0.064356, loss_ce: 0.016982
2021-12-14 03:46:11,240 iteration 5298 : loss : 0.056593, loss_ce: 0.024711
2021-12-14 03:46:12,708 iteration 5299 : loss : 0.060926, loss_ce: 0.012862
2021-12-14 03:46:14,174 iteration 5300 : loss : 0.040299, loss_ce: 0.013716
2021-12-14 03:46:15,665 iteration 5301 : loss : 0.044327, loss_ce: 0.009900
2021-12-14 03:46:17,270 iteration 5302 : loss : 0.051552, loss_ce: 0.017899
2021-12-14 03:46:18,834 iteration 5303 : loss : 0.043732, loss_ce: 0.017656
2021-12-14 03:46:20,342 iteration 5304 : loss : 0.057042, loss_ce: 0.022809
 78%|██████████████████████▌      | 312/400 [2:27:25<41:47, 28.49s/it]2021-12-14 03:46:21,829 iteration 5305 : loss : 0.042565, loss_ce: 0.013162
2021-12-14 03:46:23,409 iteration 5306 : loss : 0.050388, loss_ce: 0.017330
2021-12-14 03:46:24,967 iteration 5307 : loss : 0.054829, loss_ce: 0.018104
2021-12-14 03:46:26,447 iteration 5308 : loss : 0.042529, loss_ce: 0.011269
2021-12-14 03:46:27,986 iteration 5309 : loss : 0.054920, loss_ce: 0.024844
2021-12-14 03:46:29,665 iteration 5310 : loss : 0.057838, loss_ce: 0.016677
2021-12-14 03:46:31,180 iteration 5311 : loss : 0.052525, loss_ce: 0.015671
2021-12-14 03:46:32,802 iteration 5312 : loss : 0.054306, loss_ce: 0.017760
2021-12-14 03:46:34,290 iteration 5313 : loss : 0.050185, loss_ce: 0.022815
2021-12-14 03:46:35,805 iteration 5314 : loss : 0.044155, loss_ce: 0.011706
2021-12-14 03:46:37,273 iteration 5315 : loss : 0.047561, loss_ce: 0.014878
2021-12-14 03:46:38,773 iteration 5316 : loss : 0.044228, loss_ce: 0.012038
2021-12-14 03:46:40,255 iteration 5317 : loss : 0.045397, loss_ce: 0.013373
2021-12-14 03:46:41,820 iteration 5318 : loss : 0.044785, loss_ce: 0.015530
2021-12-14 03:46:43,317 iteration 5319 : loss : 0.056114, loss_ce: 0.016791
2021-12-14 03:46:44,776 iteration 5320 : loss : 0.041661, loss_ce: 0.012859
2021-12-14 03:46:46,247 iteration 5321 : loss : 0.050510, loss_ce: 0.016794
 78%|██████████████████████▋      | 313/400 [2:27:51<40:11, 27.72s/it]2021-12-14 03:46:47,743 iteration 5322 : loss : 0.051314, loss_ce: 0.015207
2021-12-14 03:46:49,303 iteration 5323 : loss : 0.052451, loss_ce: 0.013328
2021-12-14 03:46:50,797 iteration 5324 : loss : 0.053701, loss_ce: 0.016254
2021-12-14 03:46:52,380 iteration 5325 : loss : 0.042856, loss_ce: 0.014692
2021-12-14 03:46:53,940 iteration 5326 : loss : 0.048867, loss_ce: 0.015213
2021-12-14 03:46:55,463 iteration 5327 : loss : 0.042150, loss_ce: 0.014472
2021-12-14 03:46:57,026 iteration 5328 : loss : 0.041249, loss_ce: 0.011725
2021-12-14 03:46:58,587 iteration 5329 : loss : 0.060772, loss_ce: 0.028383
2021-12-14 03:47:00,179 iteration 5330 : loss : 0.045156, loss_ce: 0.013937
2021-12-14 03:47:01,621 iteration 5331 : loss : 0.049061, loss_ce: 0.015233
2021-12-14 03:47:03,084 iteration 5332 : loss : 0.048986, loss_ce: 0.017487
2021-12-14 03:47:04,585 iteration 5333 : loss : 0.049301, loss_ce: 0.013851
2021-12-14 03:47:06,063 iteration 5334 : loss : 0.042009, loss_ce: 0.012233
2021-12-14 03:47:07,715 iteration 5335 : loss : 0.054503, loss_ce: 0.016606
2021-12-14 03:47:09,241 iteration 5336 : loss : 0.053882, loss_ce: 0.016110
2021-12-14 03:47:10,757 iteration 5337 : loss : 0.045338, loss_ce: 0.013845
2021-12-14 03:47:12,164 iteration 5338 : loss : 0.045517, loss_ce: 0.012947
 78%|██████████████████████▊      | 314/400 [2:28:17<38:57, 27.18s/it]2021-12-14 03:47:13,719 iteration 5339 : loss : 0.039414, loss_ce: 0.011599
2021-12-14 03:47:15,235 iteration 5340 : loss : 0.045947, loss_ce: 0.021078
2021-12-14 03:47:16,787 iteration 5341 : loss : 0.048738, loss_ce: 0.017473
2021-12-14 03:47:18,360 iteration 5342 : loss : 0.055038, loss_ce: 0.015205
2021-12-14 03:47:19,833 iteration 5343 : loss : 0.054237, loss_ce: 0.016756
2021-12-14 03:47:21,317 iteration 5344 : loss : 0.052761, loss_ce: 0.022393
2021-12-14 03:47:22,755 iteration 5345 : loss : 0.041061, loss_ce: 0.011084
2021-12-14 03:47:24,237 iteration 5346 : loss : 0.055162, loss_ce: 0.016015
2021-12-14 03:47:25,872 iteration 5347 : loss : 0.047199, loss_ce: 0.016300
2021-12-14 03:47:27,428 iteration 5348 : loss : 0.053646, loss_ce: 0.020522
2021-12-14 03:47:28,945 iteration 5349 : loss : 0.048088, loss_ce: 0.019801
2021-12-14 03:47:30,373 iteration 5350 : loss : 0.040188, loss_ce: 0.012550
2021-12-14 03:47:31,958 iteration 5351 : loss : 0.052234, loss_ce: 0.009178
2021-12-14 03:47:33,490 iteration 5352 : loss : 0.041284, loss_ce: 0.013077
2021-12-14 03:47:35,125 iteration 5353 : loss : 0.058087, loss_ce: 0.021536
2021-12-14 03:47:36,602 iteration 5354 : loss : 0.042767, loss_ce: 0.014549
2021-12-14 03:47:36,603 Training Data Eval:
2021-12-14 03:47:44,033   Average segmentation loss on training set: 0.0366
2021-12-14 03:47:44,033 Validation Data Eval:
2021-12-14 03:47:46,589   Average segmentation loss on validation set: 0.0838
2021-12-14 03:47:48,017 iteration 5355 : loss : 0.046850, loss_ce: 0.015796
 79%|██████████████████████▊      | 315/400 [2:28:53<42:11, 29.78s/it]2021-12-14 03:47:49,657 iteration 5356 : loss : 0.074401, loss_ce: 0.027754
2021-12-14 03:47:51,067 iteration 5357 : loss : 0.039427, loss_ce: 0.010423
2021-12-14 03:47:52,578 iteration 5358 : loss : 0.044029, loss_ce: 0.010365
2021-12-14 03:47:54,036 iteration 5359 : loss : 0.057625, loss_ce: 0.027373
2021-12-14 03:47:55,539 iteration 5360 : loss : 0.047010, loss_ce: 0.016364
2021-12-14 03:47:57,154 iteration 5361 : loss : 0.057568, loss_ce: 0.015072
2021-12-14 03:47:58,722 iteration 5362 : loss : 0.060298, loss_ce: 0.031436
2021-12-14 03:48:00,247 iteration 5363 : loss : 0.050102, loss_ce: 0.017504
2021-12-14 03:48:01,643 iteration 5364 : loss : 0.054031, loss_ce: 0.009488
2021-12-14 03:48:03,220 iteration 5365 : loss : 0.042507, loss_ce: 0.012354
2021-12-14 03:48:04,645 iteration 5366 : loss : 0.048604, loss_ce: 0.014035
2021-12-14 03:48:06,206 iteration 5367 : loss : 0.052547, loss_ce: 0.011131
2021-12-14 03:48:07,852 iteration 5368 : loss : 0.048365, loss_ce: 0.015798
2021-12-14 03:48:09,389 iteration 5369 : loss : 0.067137, loss_ce: 0.028824
2021-12-14 03:48:10,927 iteration 5370 : loss : 0.050993, loss_ce: 0.014157
2021-12-14 03:48:12,568 iteration 5371 : loss : 0.044844, loss_ce: 0.011253
2021-12-14 03:48:14,072 iteration 5372 : loss : 0.048790, loss_ce: 0.018377
 79%|██████████████████████▉      | 316/400 [2:29:19<40:07, 28.66s/it]2021-12-14 03:48:15,533 iteration 5373 : loss : 0.040579, loss_ce: 0.016021
2021-12-14 03:48:17,081 iteration 5374 : loss : 0.049211, loss_ce: 0.013322
2021-12-14 03:48:18,549 iteration 5375 : loss : 0.041192, loss_ce: 0.011670
2021-12-14 03:48:19,979 iteration 5376 : loss : 0.043617, loss_ce: 0.012886
2021-12-14 03:48:21,347 iteration 5377 : loss : 0.056690, loss_ce: 0.008714
2021-12-14 03:48:22,724 iteration 5378 : loss : 0.040080, loss_ce: 0.012349
2021-12-14 03:48:24,261 iteration 5379 : loss : 0.047259, loss_ce: 0.011980
2021-12-14 03:48:25,725 iteration 5380 : loss : 0.046079, loss_ce: 0.016044
2021-12-14 03:48:27,251 iteration 5381 : loss : 0.048814, loss_ce: 0.017253
2021-12-14 03:48:28,818 iteration 5382 : loss : 0.049377, loss_ce: 0.013269
2021-12-14 03:48:30,397 iteration 5383 : loss : 0.047942, loss_ce: 0.018194
2021-12-14 03:48:31,907 iteration 5384 : loss : 0.070771, loss_ce: 0.029732
2021-12-14 03:48:33,424 iteration 5385 : loss : 0.057093, loss_ce: 0.022109
2021-12-14 03:48:34,998 iteration 5386 : loss : 0.043370, loss_ce: 0.014092
2021-12-14 03:48:36,520 iteration 5387 : loss : 0.046657, loss_ce: 0.016456
2021-12-14 03:48:37,932 iteration 5388 : loss : 0.044402, loss_ce: 0.014836
2021-12-14 03:48:39,419 iteration 5389 : loss : 0.051461, loss_ce: 0.015844
 79%|██████████████████████▉      | 317/400 [2:29:44<38:16, 27.66s/it]2021-12-14 03:48:41,092 iteration 5390 : loss : 0.045592, loss_ce: 0.011599
2021-12-14 03:48:42,486 iteration 5391 : loss : 0.053489, loss_ce: 0.016235
2021-12-14 03:48:44,037 iteration 5392 : loss : 0.042957, loss_ce: 0.015292
2021-12-14 03:48:45,595 iteration 5393 : loss : 0.057447, loss_ce: 0.016332
2021-12-14 03:48:47,101 iteration 5394 : loss : 0.042545, loss_ce: 0.015283
2021-12-14 03:48:48,545 iteration 5395 : loss : 0.044506, loss_ce: 0.018099
2021-12-14 03:48:50,118 iteration 5396 : loss : 0.066030, loss_ce: 0.018515
2021-12-14 03:48:51,636 iteration 5397 : loss : 0.066000, loss_ce: 0.024026
2021-12-14 03:48:53,015 iteration 5398 : loss : 0.041188, loss_ce: 0.016952
2021-12-14 03:48:54,484 iteration 5399 : loss : 0.039962, loss_ce: 0.015143
2021-12-14 03:48:56,093 iteration 5400 : loss : 0.062930, loss_ce: 0.017708
2021-12-14 03:48:57,672 iteration 5401 : loss : 0.050803, loss_ce: 0.013753
2021-12-14 03:48:59,184 iteration 5402 : loss : 0.045868, loss_ce: 0.015572
2021-12-14 03:49:00,749 iteration 5403 : loss : 0.053659, loss_ce: 0.013584
2021-12-14 03:49:02,214 iteration 5404 : loss : 0.050914, loss_ce: 0.020252
2021-12-14 03:49:03,649 iteration 5405 : loss : 0.045640, loss_ce: 0.014861
2021-12-14 03:49:05,034 iteration 5406 : loss : 0.046195, loss_ce: 0.010095
 80%|███████████████████████      | 318/400 [2:30:10<36:58, 27.06s/it]2021-12-14 03:49:06,697 iteration 5407 : loss : 0.090196, loss_ce: 0.022989
2021-12-14 03:49:08,187 iteration 5408 : loss : 0.053440, loss_ce: 0.015532
2021-12-14 03:49:09,637 iteration 5409 : loss : 0.041708, loss_ce: 0.016291
2021-12-14 03:49:11,093 iteration 5410 : loss : 0.045439, loss_ce: 0.012794
2021-12-14 03:49:12,644 iteration 5411 : loss : 0.045709, loss_ce: 0.015066
2021-12-14 03:49:14,224 iteration 5412 : loss : 0.057324, loss_ce: 0.023118
2021-12-14 03:49:15,674 iteration 5413 : loss : 0.044469, loss_ce: 0.014120
2021-12-14 03:49:17,256 iteration 5414 : loss : 0.050684, loss_ce: 0.015755
2021-12-14 03:49:18,758 iteration 5415 : loss : 0.047503, loss_ce: 0.014530
2021-12-14 03:49:20,335 iteration 5416 : loss : 0.054164, loss_ce: 0.019895
2021-12-14 03:49:21,804 iteration 5417 : loss : 0.052348, loss_ce: 0.018547
2021-12-14 03:49:23,303 iteration 5418 : loss : 0.042684, loss_ce: 0.012697
2021-12-14 03:49:24,786 iteration 5419 : loss : 0.040885, loss_ce: 0.015615
2021-12-14 03:49:26,329 iteration 5420 : loss : 0.045212, loss_ce: 0.017359
2021-12-14 03:49:27,879 iteration 5421 : loss : 0.051491, loss_ce: 0.015679
2021-12-14 03:49:29,420 iteration 5422 : loss : 0.052659, loss_ce: 0.015170
2021-12-14 03:49:30,998 iteration 5423 : loss : 0.049033, loss_ce: 0.012273
 80%|███████████████████████▏     | 319/400 [2:30:36<36:04, 26.72s/it]2021-12-14 03:49:32,611 iteration 5424 : loss : 0.044869, loss_ce: 0.014390
2021-12-14 03:49:34,148 iteration 5425 : loss : 0.052132, loss_ce: 0.018685
2021-12-14 03:49:35,710 iteration 5426 : loss : 0.042008, loss_ce: 0.010805
2021-12-14 03:49:37,394 iteration 5427 : loss : 0.058970, loss_ce: 0.020438
2021-12-14 03:49:39,008 iteration 5428 : loss : 0.068232, loss_ce: 0.026334
2021-12-14 03:49:40,475 iteration 5429 : loss : 0.047840, loss_ce: 0.016212
2021-12-14 03:49:41,877 iteration 5430 : loss : 0.044392, loss_ce: 0.016157
2021-12-14 03:49:43,480 iteration 5431 : loss : 0.050874, loss_ce: 0.016561
2021-12-14 03:49:44,957 iteration 5432 : loss : 0.054610, loss_ce: 0.016575
2021-12-14 03:49:46,640 iteration 5433 : loss : 0.062164, loss_ce: 0.020941
2021-12-14 03:49:48,268 iteration 5434 : loss : 0.054035, loss_ce: 0.015510
2021-12-14 03:49:49,832 iteration 5435 : loss : 0.044289, loss_ce: 0.015999
2021-12-14 03:49:51,413 iteration 5436 : loss : 0.053895, loss_ce: 0.021833
2021-12-14 03:49:52,889 iteration 5437 : loss : 0.070847, loss_ce: 0.017615
2021-12-14 03:49:54,424 iteration 5438 : loss : 0.053979, loss_ce: 0.019441
2021-12-14 03:49:55,993 iteration 5439 : loss : 0.062112, loss_ce: 0.017852
2021-12-14 03:49:55,993 Training Data Eval:
2021-12-14 03:50:03,419   Average segmentation loss on training set: 0.0381
2021-12-14 03:50:03,419 Validation Data Eval:
2021-12-14 03:50:05,993   Average segmentation loss on validation set: 0.0916
2021-12-14 03:50:07,516 iteration 5440 : loss : 0.045365, loss_ce: 0.014850
 80%|███████████████████████▏     | 320/400 [2:31:12<39:33, 29.67s/it]2021-12-14 03:50:09,009 iteration 5441 : loss : 0.047529, loss_ce: 0.018284
2021-12-14 03:50:10,688 iteration 5442 : loss : 0.066707, loss_ce: 0.021648
2021-12-14 03:50:12,254 iteration 5443 : loss : 0.057487, loss_ce: 0.016868
2021-12-14 03:50:13,752 iteration 5444 : loss : 0.043886, loss_ce: 0.017250
2021-12-14 03:50:15,238 iteration 5445 : loss : 0.053317, loss_ce: 0.020485
2021-12-14 03:50:16,750 iteration 5446 : loss : 0.050988, loss_ce: 0.017950
2021-12-14 03:50:18,160 iteration 5447 : loss : 0.071331, loss_ce: 0.013225
2021-12-14 03:50:19,710 iteration 5448 : loss : 0.049588, loss_ce: 0.016140
2021-12-14 03:50:21,198 iteration 5449 : loss : 0.047141, loss_ce: 0.012571
2021-12-14 03:50:22,655 iteration 5450 : loss : 0.055235, loss_ce: 0.015815
2021-12-14 03:50:24,191 iteration 5451 : loss : 0.044867, loss_ce: 0.011724
2021-12-14 03:50:25,736 iteration 5452 : loss : 0.040720, loss_ce: 0.013535
2021-12-14 03:50:27,312 iteration 5453 : loss : 0.043218, loss_ce: 0.014061
2021-12-14 03:50:28,862 iteration 5454 : loss : 0.049703, loss_ce: 0.019231
2021-12-14 03:50:30,395 iteration 5455 : loss : 0.045768, loss_ce: 0.018578
2021-12-14 03:50:31,953 iteration 5456 : loss : 0.046069, loss_ce: 0.012481
2021-12-14 03:50:33,503 iteration 5457 : loss : 0.045375, loss_ce: 0.014318
 80%|███████████████████████▎     | 321/400 [2:31:38<37:35, 28.56s/it]2021-12-14 03:50:35,170 iteration 5458 : loss : 0.053734, loss_ce: 0.013753
2021-12-14 03:50:36,632 iteration 5459 : loss : 0.046984, loss_ce: 0.014790
2021-12-14 03:50:38,148 iteration 5460 : loss : 0.049339, loss_ce: 0.018046
2021-12-14 03:50:39,699 iteration 5461 : loss : 0.051273, loss_ce: 0.014786
2021-12-14 03:50:41,280 iteration 5462 : loss : 0.076757, loss_ce: 0.029192
2021-12-14 03:50:42,763 iteration 5463 : loss : 0.046005, loss_ce: 0.012371
2021-12-14 03:50:44,470 iteration 5464 : loss : 0.055181, loss_ce: 0.017355
2021-12-14 03:50:45,945 iteration 5465 : loss : 0.043445, loss_ce: 0.013676
2021-12-14 03:50:47,422 iteration 5466 : loss : 0.041222, loss_ce: 0.013734
2021-12-14 03:50:49,033 iteration 5467 : loss : 0.040013, loss_ce: 0.011473
2021-12-14 03:50:50,627 iteration 5468 : loss : 0.051888, loss_ce: 0.019647
2021-12-14 03:50:52,224 iteration 5469 : loss : 0.051228, loss_ce: 0.017180
2021-12-14 03:50:53,722 iteration 5470 : loss : 0.044279, loss_ce: 0.015766
2021-12-14 03:50:55,207 iteration 5471 : loss : 0.046945, loss_ce: 0.019146
2021-12-14 03:50:56,801 iteration 5472 : loss : 0.049020, loss_ce: 0.019494
2021-12-14 03:50:58,291 iteration 5473 : loss : 0.054250, loss_ce: 0.012891
2021-12-14 03:50:59,893 iteration 5474 : loss : 0.043934, loss_ce: 0.012163
 80%|███████████████████████▎     | 322/400 [2:32:05<36:16, 27.91s/it]2021-12-14 03:51:01,415 iteration 5475 : loss : 0.044133, loss_ce: 0.013765
2021-12-14 03:51:02,912 iteration 5476 : loss : 0.039274, loss_ce: 0.014843
2021-12-14 03:51:04,492 iteration 5477 : loss : 0.040926, loss_ce: 0.012537
2021-12-14 03:51:06,101 iteration 5478 : loss : 0.053230, loss_ce: 0.021450
2021-12-14 03:51:07,574 iteration 5479 : loss : 0.058395, loss_ce: 0.014930
2021-12-14 03:51:09,099 iteration 5480 : loss : 0.052342, loss_ce: 0.012950
2021-12-14 03:51:10,649 iteration 5481 : loss : 0.049966, loss_ce: 0.017457
2021-12-14 03:51:12,172 iteration 5482 : loss : 0.050864, loss_ce: 0.016960
2021-12-14 03:51:13,614 iteration 5483 : loss : 0.055226, loss_ce: 0.016298
2021-12-14 03:51:15,236 iteration 5484 : loss : 0.047638, loss_ce: 0.016587
2021-12-14 03:51:16,676 iteration 5485 : loss : 0.044587, loss_ce: 0.018118
2021-12-14 03:51:18,348 iteration 5486 : loss : 0.047646, loss_ce: 0.013607
2021-12-14 03:51:19,790 iteration 5487 : loss : 0.055884, loss_ce: 0.030416
2021-12-14 03:51:21,366 iteration 5488 : loss : 0.062490, loss_ce: 0.017809
2021-12-14 03:51:22,811 iteration 5489 : loss : 0.050641, loss_ce: 0.013244
2021-12-14 03:51:24,380 iteration 5490 : loss : 0.051387, loss_ce: 0.017832
2021-12-14 03:51:25,845 iteration 5491 : loss : 0.040661, loss_ce: 0.011921
 81%|███████████████████████▍     | 323/400 [2:32:31<35:03, 27.32s/it]2021-12-14 03:51:27,471 iteration 5492 : loss : 0.052530, loss_ce: 0.019853
2021-12-14 03:51:28,902 iteration 5493 : loss : 0.043982, loss_ce: 0.014707
2021-12-14 03:51:30,382 iteration 5494 : loss : 0.048771, loss_ce: 0.018258
2021-12-14 03:51:32,004 iteration 5495 : loss : 0.049194, loss_ce: 0.010346
2021-12-14 03:51:33,454 iteration 5496 : loss : 0.040291, loss_ce: 0.011842
2021-12-14 03:51:34,983 iteration 5497 : loss : 0.054856, loss_ce: 0.020621
2021-12-14 03:51:36,585 iteration 5498 : loss : 0.049059, loss_ce: 0.017936
2021-12-14 03:51:38,126 iteration 5499 : loss : 0.050847, loss_ce: 0.011686
2021-12-14 03:51:39,633 iteration 5500 : loss : 0.041816, loss_ce: 0.012027
2021-12-14 03:51:41,116 iteration 5501 : loss : 0.048068, loss_ce: 0.016837
2021-12-14 03:51:42,590 iteration 5502 : loss : 0.045698, loss_ce: 0.020535
2021-12-14 03:51:44,285 iteration 5503 : loss : 0.050635, loss_ce: 0.012820
2021-12-14 03:51:45,825 iteration 5504 : loss : 0.050008, loss_ce: 0.018173
2021-12-14 03:51:47,253 iteration 5505 : loss : 0.046067, loss_ce: 0.013862
2021-12-14 03:51:48,731 iteration 5506 : loss : 0.042175, loss_ce: 0.013945
2021-12-14 03:51:50,349 iteration 5507 : loss : 0.047087, loss_ce: 0.013751
2021-12-14 03:51:51,925 iteration 5508 : loss : 0.049102, loss_ce: 0.018240
 81%|███████████████████████▍     | 324/400 [2:32:57<34:08, 26.95s/it]2021-12-14 03:51:53,572 iteration 5509 : loss : 0.049863, loss_ce: 0.019203
2021-12-14 03:51:55,078 iteration 5510 : loss : 0.041975, loss_ce: 0.013579
2021-12-14 03:51:56,612 iteration 5511 : loss : 0.058314, loss_ce: 0.019434
2021-12-14 03:51:58,116 iteration 5512 : loss : 0.050887, loss_ce: 0.017824
2021-12-14 03:51:59,624 iteration 5513 : loss : 0.040374, loss_ce: 0.016412
2021-12-14 03:52:01,221 iteration 5514 : loss : 0.056027, loss_ce: 0.018993
2021-12-14 03:52:02,722 iteration 5515 : loss : 0.050944, loss_ce: 0.015874
2021-12-14 03:52:04,235 iteration 5516 : loss : 0.045775, loss_ce: 0.019257
2021-12-14 03:52:05,799 iteration 5517 : loss : 0.058409, loss_ce: 0.018780
2021-12-14 03:52:07,220 iteration 5518 : loss : 0.044403, loss_ce: 0.014109
2021-12-14 03:52:08,849 iteration 5519 : loss : 0.074398, loss_ce: 0.022284
2021-12-14 03:52:10,369 iteration 5520 : loss : 0.049841, loss_ce: 0.009609
2021-12-14 03:52:12,030 iteration 5521 : loss : 0.049682, loss_ce: 0.014933
2021-12-14 03:52:13,541 iteration 5522 : loss : 0.044620, loss_ce: 0.013892
2021-12-14 03:52:15,129 iteration 5523 : loss : 0.052203, loss_ce: 0.019027
2021-12-14 03:52:16,749 iteration 5524 : loss : 0.052625, loss_ce: 0.015200
2021-12-14 03:52:16,749 Training Data Eval:
2021-12-14 03:52:24,184   Average segmentation loss on training set: 0.0372
2021-12-14 03:52:24,185 Validation Data Eval:
2021-12-14 03:52:26,753   Average segmentation loss on validation set: 0.0839
2021-12-14 03:52:28,394 iteration 5525 : loss : 0.052717, loss_ce: 0.020771
 81%|███████████████████████▌     | 325/400 [2:33:33<37:15, 29.80s/it]2021-12-14 03:52:29,968 iteration 5526 : loss : 0.048338, loss_ce: 0.014827
2021-12-14 03:52:31,395 iteration 5527 : loss : 0.041391, loss_ce: 0.013307
2021-12-14 03:52:33,011 iteration 5528 : loss : 0.069075, loss_ce: 0.021616
2021-12-14 03:52:34,488 iteration 5529 : loss : 0.044521, loss_ce: 0.014448
2021-12-14 03:52:35,948 iteration 5530 : loss : 0.043338, loss_ce: 0.014395
2021-12-14 03:52:37,350 iteration 5531 : loss : 0.039732, loss_ce: 0.011248
2021-12-14 03:52:38,780 iteration 5532 : loss : 0.046330, loss_ce: 0.016330
2021-12-14 03:52:40,350 iteration 5533 : loss : 0.048421, loss_ce: 0.018341
2021-12-14 03:52:41,782 iteration 5534 : loss : 0.038896, loss_ce: 0.012159
2021-12-14 03:52:43,252 iteration 5535 : loss : 0.042998, loss_ce: 0.014788
2021-12-14 03:52:44,833 iteration 5536 : loss : 0.058050, loss_ce: 0.016597
2021-12-14 03:52:46,416 iteration 5537 : loss : 0.050245, loss_ce: 0.019891
2021-12-14 03:52:48,053 iteration 5538 : loss : 0.048294, loss_ce: 0.011711
2021-12-14 03:52:49,599 iteration 5539 : loss : 0.044464, loss_ce: 0.013217
2021-12-14 03:52:51,034 iteration 5540 : loss : 0.046139, loss_ce: 0.016383
2021-12-14 03:52:52,707 iteration 5541 : loss : 0.070319, loss_ce: 0.027102
2021-12-14 03:52:54,236 iteration 5542 : loss : 0.049388, loss_ce: 0.015646
 82%|███████████████████████▋     | 326/400 [2:33:59<35:17, 28.62s/it]2021-12-14 03:52:55,918 iteration 5543 : loss : 0.055828, loss_ce: 0.022079
2021-12-14 03:52:57,391 iteration 5544 : loss : 0.049842, loss_ce: 0.015651
2021-12-14 03:52:58,959 iteration 5545 : loss : 0.043451, loss_ce: 0.016838
2021-12-14 03:53:00,601 iteration 5546 : loss : 0.101732, loss_ce: 0.025349
2021-12-14 03:53:02,195 iteration 5547 : loss : 0.039531, loss_ce: 0.012299
2021-12-14 03:53:03,695 iteration 5548 : loss : 0.051980, loss_ce: 0.012312
2021-12-14 03:53:05,187 iteration 5549 : loss : 0.047684, loss_ce: 0.011364
2021-12-14 03:53:06,740 iteration 5550 : loss : 0.050749, loss_ce: 0.015502
2021-12-14 03:53:08,221 iteration 5551 : loss : 0.055380, loss_ce: 0.021934
2021-12-14 03:53:09,585 iteration 5552 : loss : 0.046068, loss_ce: 0.010866
2021-12-14 03:53:11,107 iteration 5553 : loss : 0.046504, loss_ce: 0.017039
2021-12-14 03:53:12,598 iteration 5554 : loss : 0.044082, loss_ce: 0.015737
2021-12-14 03:53:14,006 iteration 5555 : loss : 0.044186, loss_ce: 0.017091
2021-12-14 03:53:15,587 iteration 5556 : loss : 0.052220, loss_ce: 0.017554
2021-12-14 03:53:17,145 iteration 5557 : loss : 0.046987, loss_ce: 0.017037
2021-12-14 03:53:18,677 iteration 5558 : loss : 0.046728, loss_ce: 0.014206
2021-12-14 03:53:20,191 iteration 5559 : loss : 0.057811, loss_ce: 0.014305
 82%|███████████████████████▋     | 327/400 [2:34:25<33:50, 27.82s/it]2021-12-14 03:53:21,793 iteration 5560 : loss : 0.045743, loss_ce: 0.014486
2021-12-14 03:53:23,277 iteration 5561 : loss : 0.050413, loss_ce: 0.015882
2021-12-14 03:53:24,778 iteration 5562 : loss : 0.041320, loss_ce: 0.015943
2021-12-14 03:53:26,266 iteration 5563 : loss : 0.043404, loss_ce: 0.016084
2021-12-14 03:53:27,840 iteration 5564 : loss : 0.069274, loss_ce: 0.026069
2021-12-14 03:53:29,423 iteration 5565 : loss : 0.052704, loss_ce: 0.018753
2021-12-14 03:53:30,970 iteration 5566 : loss : 0.043703, loss_ce: 0.014962
2021-12-14 03:53:32,532 iteration 5567 : loss : 0.043132, loss_ce: 0.016062
2021-12-14 03:53:34,023 iteration 5568 : loss : 0.047181, loss_ce: 0.015479
2021-12-14 03:53:35,554 iteration 5569 : loss : 0.058683, loss_ce: 0.018967
2021-12-14 03:53:37,004 iteration 5570 : loss : 0.039462, loss_ce: 0.010063
2021-12-14 03:53:38,375 iteration 5571 : loss : 0.042394, loss_ce: 0.013933
2021-12-14 03:53:39,828 iteration 5572 : loss : 0.061218, loss_ce: 0.015311
2021-12-14 03:53:41,244 iteration 5573 : loss : 0.038793, loss_ce: 0.009915
2021-12-14 03:53:42,741 iteration 5574 : loss : 0.041395, loss_ce: 0.011335
2021-12-14 03:53:44,394 iteration 5575 : loss : 0.051949, loss_ce: 0.015565
2021-12-14 03:53:45,954 iteration 5576 : loss : 0.051479, loss_ce: 0.016645
 82%|███████████████████████▊     | 328/400 [2:34:51<32:38, 27.20s/it]2021-12-14 03:53:47,558 iteration 5577 : loss : 0.044436, loss_ce: 0.015675
2021-12-14 03:53:49,127 iteration 5578 : loss : 0.047301, loss_ce: 0.016119
2021-12-14 03:53:50,740 iteration 5579 : loss : 0.051164, loss_ce: 0.020459
2021-12-14 03:53:52,227 iteration 5580 : loss : 0.052459, loss_ce: 0.018334
2021-12-14 03:53:53,673 iteration 5581 : loss : 0.043789, loss_ce: 0.015982
2021-12-14 03:53:55,200 iteration 5582 : loss : 0.039185, loss_ce: 0.009738
2021-12-14 03:53:56,693 iteration 5583 : loss : 0.039918, loss_ce: 0.012210
2021-12-14 03:53:58,282 iteration 5584 : loss : 0.063282, loss_ce: 0.026292
2021-12-14 03:53:59,769 iteration 5585 : loss : 0.042668, loss_ce: 0.011232
2021-12-14 03:54:01,376 iteration 5586 : loss : 0.048950, loss_ce: 0.014476
2021-12-14 03:54:02,813 iteration 5587 : loss : 0.047979, loss_ce: 0.016165
2021-12-14 03:54:04,313 iteration 5588 : loss : 0.044296, loss_ce: 0.013917
2021-12-14 03:54:05,742 iteration 5589 : loss : 0.044640, loss_ce: 0.012369
2021-12-14 03:54:07,204 iteration 5590 : loss : 0.043864, loss_ce: 0.009790
2021-12-14 03:54:08,680 iteration 5591 : loss : 0.044528, loss_ce: 0.015178
2021-12-14 03:54:10,293 iteration 5592 : loss : 0.061483, loss_ce: 0.017935
2021-12-14 03:54:11,849 iteration 5593 : loss : 0.050211, loss_ce: 0.018693
 82%|███████████████████████▊     | 329/400 [2:35:17<31:43, 26.81s/it]2021-12-14 03:54:13,368 iteration 5594 : loss : 0.047919, loss_ce: 0.011786
2021-12-14 03:54:14,952 iteration 5595 : loss : 0.056236, loss_ce: 0.021446
2021-12-14 03:54:16,447 iteration 5596 : loss : 0.043043, loss_ce: 0.014723
2021-12-14 03:54:18,041 iteration 5597 : loss : 0.046502, loss_ce: 0.015198
2021-12-14 03:54:19,475 iteration 5598 : loss : 0.039173, loss_ce: 0.013605
2021-12-14 03:54:20,987 iteration 5599 : loss : 0.062860, loss_ce: 0.022048
2021-12-14 03:54:22,480 iteration 5600 : loss : 0.039603, loss_ce: 0.013488
2021-12-14 03:54:23,964 iteration 5601 : loss : 0.038021, loss_ce: 0.011789
2021-12-14 03:54:25,505 iteration 5602 : loss : 0.044295, loss_ce: 0.016991
2021-12-14 03:54:26,944 iteration 5603 : loss : 0.040239, loss_ce: 0.014283
2021-12-14 03:54:28,495 iteration 5604 : loss : 0.040233, loss_ce: 0.009669
2021-12-14 03:54:30,074 iteration 5605 : loss : 0.053114, loss_ce: 0.017638
2021-12-14 03:54:31,613 iteration 5606 : loss : 0.050235, loss_ce: 0.014915
2021-12-14 03:54:33,125 iteration 5607 : loss : 0.042154, loss_ce: 0.012082
2021-12-14 03:54:34,641 iteration 5608 : loss : 0.046818, loss_ce: 0.013929
2021-12-14 03:54:36,232 iteration 5609 : loss : 0.050605, loss_ce: 0.020036
2021-12-14 03:54:36,232 Training Data Eval:
2021-12-14 03:54:43,672   Average segmentation loss on training set: 0.0363
2021-12-14 03:54:43,672 Validation Data Eval:
2021-12-14 03:54:46,241   Average segmentation loss on validation set: 0.0827
2021-12-14 03:54:52,106 Found new lowest validation loss at iteration 5609! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/REVISED_SGD_best_val_loss_seed2.pth
2021-12-14 03:54:53,599 iteration 5610 : loss : 0.042917, loss_ce: 0.013921
 82%|███████████████████████▉     | 330/400 [2:35:58<36:30, 31.29s/it]2021-12-14 03:54:55,166 iteration 5611 : loss : 0.052898, loss_ce: 0.016023
2021-12-14 03:54:56,687 iteration 5612 : loss : 0.077896, loss_ce: 0.012643
2021-12-14 03:54:58,207 iteration 5613 : loss : 0.044144, loss_ce: 0.014036
2021-12-14 03:54:59,732 iteration 5614 : loss : 0.043102, loss_ce: 0.015064
2021-12-14 03:55:01,128 iteration 5615 : loss : 0.039797, loss_ce: 0.014112
2021-12-14 03:55:02,680 iteration 5616 : loss : 0.047821, loss_ce: 0.018587
2021-12-14 03:55:04,276 iteration 5617 : loss : 0.050787, loss_ce: 0.016960
2021-12-14 03:55:05,836 iteration 5618 : loss : 0.046625, loss_ce: 0.016904
2021-12-14 03:55:07,306 iteration 5619 : loss : 0.041738, loss_ce: 0.010642
2021-12-14 03:55:08,925 iteration 5620 : loss : 0.043714, loss_ce: 0.013814
2021-12-14 03:55:10,353 iteration 5621 : loss : 0.046719, loss_ce: 0.014212
2021-12-14 03:55:11,871 iteration 5622 : loss : 0.053437, loss_ce: 0.015163
2021-12-14 03:55:13,490 iteration 5623 : loss : 0.058412, loss_ce: 0.022141
2021-12-14 03:55:14,935 iteration 5624 : loss : 0.054876, loss_ce: 0.014326
2021-12-14 03:55:16,369 iteration 5625 : loss : 0.048808, loss_ce: 0.018034
2021-12-14 03:55:17,840 iteration 5626 : loss : 0.044449, loss_ce: 0.011065
2021-12-14 03:55:19,390 iteration 5627 : loss : 0.046008, loss_ce: 0.016219
 83%|███████████████████████▉     | 331/400 [2:36:24<34:05, 29.64s/it]2021-12-14 03:55:21,115 iteration 5628 : loss : 0.054418, loss_ce: 0.022616
2021-12-14 03:55:22,568 iteration 5629 : loss : 0.050161, loss_ce: 0.018224
2021-12-14 03:55:24,124 iteration 5630 : loss : 0.049238, loss_ce: 0.017501
2021-12-14 03:55:25,649 iteration 5631 : loss : 0.044551, loss_ce: 0.014288
2021-12-14 03:55:27,230 iteration 5632 : loss : 0.048822, loss_ce: 0.020085
2021-12-14 03:55:28,832 iteration 5633 : loss : 0.046509, loss_ce: 0.014012
2021-12-14 03:55:30,362 iteration 5634 : loss : 0.037575, loss_ce: 0.012375
2021-12-14 03:55:31,865 iteration 5635 : loss : 0.041889, loss_ce: 0.012120
2021-12-14 03:55:33,397 iteration 5636 : loss : 0.051537, loss_ce: 0.012988
2021-12-14 03:55:34,892 iteration 5637 : loss : 0.053181, loss_ce: 0.015042
2021-12-14 03:55:36,437 iteration 5638 : loss : 0.049987, loss_ce: 0.018580
2021-12-14 03:55:38,002 iteration 5639 : loss : 0.043426, loss_ce: 0.014982
2021-12-14 03:55:39,551 iteration 5640 : loss : 0.064327, loss_ce: 0.023238
2021-12-14 03:55:40,984 iteration 5641 : loss : 0.045006, loss_ce: 0.011478
2021-12-14 03:55:42,439 iteration 5642 : loss : 0.044346, loss_ce: 0.015467
2021-12-14 03:55:43,927 iteration 5643 : loss : 0.051927, loss_ce: 0.015622
2021-12-14 03:55:45,408 iteration 5644 : loss : 0.038195, loss_ce: 0.012968
 83%|████████████████████████     | 332/400 [2:36:50<32:21, 28.55s/it]2021-12-14 03:55:46,945 iteration 5645 : loss : 0.047796, loss_ce: 0.014000
2021-12-14 03:55:48,453 iteration 5646 : loss : 0.040766, loss_ce: 0.010456
2021-12-14 03:55:50,019 iteration 5647 : loss : 0.044480, loss_ce: 0.012315
2021-12-14 03:55:51,561 iteration 5648 : loss : 0.048721, loss_ce: 0.013721
2021-12-14 03:55:53,072 iteration 5649 : loss : 0.041552, loss_ce: 0.012606
2021-12-14 03:55:54,644 iteration 5650 : loss : 0.054882, loss_ce: 0.013515
2021-12-14 03:55:56,145 iteration 5651 : loss : 0.049587, loss_ce: 0.021287
2021-12-14 03:55:57,627 iteration 5652 : loss : 0.042581, loss_ce: 0.014912
2021-12-14 03:55:59,118 iteration 5653 : loss : 0.038674, loss_ce: 0.012052
2021-12-14 03:56:00,738 iteration 5654 : loss : 0.046553, loss_ce: 0.017244
2021-12-14 03:56:02,237 iteration 5655 : loss : 0.051820, loss_ce: 0.016340
2021-12-14 03:56:03,792 iteration 5656 : loss : 0.053793, loss_ce: 0.021558
2021-12-14 03:56:05,273 iteration 5657 : loss : 0.049196, loss_ce: 0.021687
2021-12-14 03:56:06,868 iteration 5658 : loss : 0.066034, loss_ce: 0.017602
2021-12-14 03:56:08,505 iteration 5659 : loss : 0.050192, loss_ce: 0.020501
2021-12-14 03:56:09,902 iteration 5660 : loss : 0.037290, loss_ce: 0.012226
2021-12-14 03:56:11,450 iteration 5661 : loss : 0.052418, loss_ce: 0.017837
 83%|████████████████████████▏    | 333/400 [2:37:16<31:02, 27.80s/it]2021-12-14 03:56:12,971 iteration 5662 : loss : 0.040581, loss_ce: 0.014023
2021-12-14 03:56:14,548 iteration 5663 : loss : 0.044077, loss_ce: 0.016685
2021-12-14 03:56:16,151 iteration 5664 : loss : 0.056641, loss_ce: 0.021960
2021-12-14 03:56:17,638 iteration 5665 : loss : 0.043209, loss_ce: 0.011991
2021-12-14 03:56:19,250 iteration 5666 : loss : 0.047927, loss_ce: 0.016200
2021-12-14 03:56:20,804 iteration 5667 : loss : 0.047266, loss_ce: 0.013179
2021-12-14 03:56:22,357 iteration 5668 : loss : 0.048497, loss_ce: 0.014396
2021-12-14 03:56:23,981 iteration 5669 : loss : 0.048626, loss_ce: 0.019909
2021-12-14 03:56:25,525 iteration 5670 : loss : 0.049022, loss_ce: 0.015991
2021-12-14 03:56:27,144 iteration 5671 : loss : 0.055475, loss_ce: 0.013132
2021-12-14 03:56:28,554 iteration 5672 : loss : 0.051990, loss_ce: 0.014477
2021-12-14 03:56:30,065 iteration 5673 : loss : 0.045436, loss_ce: 0.018069
2021-12-14 03:56:31,515 iteration 5674 : loss : 0.057921, loss_ce: 0.016228
2021-12-14 03:56:33,180 iteration 5675 : loss : 0.060348, loss_ce: 0.020850
2021-12-14 03:56:34,692 iteration 5676 : loss : 0.053317, loss_ce: 0.025597
2021-12-14 03:56:36,183 iteration 5677 : loss : 0.047869, loss_ce: 0.014800
2021-12-14 03:56:37,678 iteration 5678 : loss : 0.047152, loss_ce: 0.015947
 84%|████████████████████████▏    | 334/400 [2:37:42<30:03, 27.33s/it]2021-12-14 03:56:39,283 iteration 5679 : loss : 0.042510, loss_ce: 0.012503
2021-12-14 03:56:40,791 iteration 5680 : loss : 0.044490, loss_ce: 0.016850
2021-12-14 03:56:42,370 iteration 5681 : loss : 0.053169, loss_ce: 0.015249
2021-12-14 03:56:43,788 iteration 5682 : loss : 0.044843, loss_ce: 0.014435
2021-12-14 03:56:45,195 iteration 5683 : loss : 0.040184, loss_ce: 0.014850
2021-12-14 03:56:46,794 iteration 5684 : loss : 0.054826, loss_ce: 0.024958
2021-12-14 03:56:48,342 iteration 5685 : loss : 0.048487, loss_ce: 0.014144
2021-12-14 03:56:49,855 iteration 5686 : loss : 0.046420, loss_ce: 0.014185
2021-12-14 03:56:51,416 iteration 5687 : loss : 0.056223, loss_ce: 0.014341
2021-12-14 03:56:53,039 iteration 5688 : loss : 0.052197, loss_ce: 0.016078
2021-12-14 03:56:54,530 iteration 5689 : loss : 0.043704, loss_ce: 0.016032
2021-12-14 03:56:55,963 iteration 5690 : loss : 0.039891, loss_ce: 0.011555
2021-12-14 03:56:57,511 iteration 5691 : loss : 0.055857, loss_ce: 0.022054
2021-12-14 03:56:59,021 iteration 5692 : loss : 0.045755, loss_ce: 0.012330
2021-12-14 03:57:00,375 iteration 5693 : loss : 0.040761, loss_ce: 0.014250
2021-12-14 03:57:01,907 iteration 5694 : loss : 0.045103, loss_ce: 0.016899
2021-12-14 03:57:01,908 Training Data Eval:
2021-12-14 03:57:09,328   Average segmentation loss on training set: 0.0360
2021-12-14 03:57:09,328 Validation Data Eval:
2021-12-14 03:57:11,879   Average segmentation loss on validation set: 0.0862
2021-12-14 03:57:13,369 iteration 5695 : loss : 0.048326, loss_ce: 0.017498
 84%|████████████████████████▎    | 335/400 [2:38:18<32:19, 29.84s/it]2021-12-14 03:57:14,978 iteration 5696 : loss : 0.054122, loss_ce: 0.015253
2021-12-14 03:57:16,433 iteration 5697 : loss : 0.041021, loss_ce: 0.010746
2021-12-14 03:57:18,049 iteration 5698 : loss : 0.045283, loss_ce: 0.014804
2021-12-14 03:57:19,660 iteration 5699 : loss : 0.048387, loss_ce: 0.013013
2021-12-14 03:57:21,060 iteration 5700 : loss : 0.043788, loss_ce: 0.016171
2021-12-14 03:57:22,709 iteration 5701 : loss : 0.052505, loss_ce: 0.011001
2021-12-14 03:57:24,273 iteration 5702 : loss : 0.048295, loss_ce: 0.016755
2021-12-14 03:57:25,884 iteration 5703 : loss : 0.055562, loss_ce: 0.019806
2021-12-14 03:57:27,364 iteration 5704 : loss : 0.044767, loss_ce: 0.014938
2021-12-14 03:57:28,854 iteration 5705 : loss : 0.041641, loss_ce: 0.014551
2021-12-14 03:57:30,303 iteration 5706 : loss : 0.044797, loss_ce: 0.014509
2021-12-14 03:57:31,860 iteration 5707 : loss : 0.060164, loss_ce: 0.015211
2021-12-14 03:57:33,372 iteration 5708 : loss : 0.043567, loss_ce: 0.017553
2021-12-14 03:57:34,822 iteration 5709 : loss : 0.042580, loss_ce: 0.011838
2021-12-14 03:57:36,307 iteration 5710 : loss : 0.046670, loss_ce: 0.019615
2021-12-14 03:57:37,830 iteration 5711 : loss : 0.040511, loss_ce: 0.014110
2021-12-14 03:57:39,344 iteration 5712 : loss : 0.048852, loss_ce: 0.018650
 84%|████████████████████████▎    | 336/400 [2:38:44<30:35, 28.68s/it]2021-12-14 03:57:40,931 iteration 5713 : loss : 0.039567, loss_ce: 0.015491
2021-12-14 03:57:42,504 iteration 5714 : loss : 0.054510, loss_ce: 0.014068
2021-12-14 03:57:43,942 iteration 5715 : loss : 0.048442, loss_ce: 0.017480
2021-12-14 03:57:45,517 iteration 5716 : loss : 0.049940, loss_ce: 0.016268
2021-12-14 03:57:46,943 iteration 5717 : loss : 0.036974, loss_ce: 0.010415
2021-12-14 03:57:48,393 iteration 5718 : loss : 0.056874, loss_ce: 0.022921
2021-12-14 03:57:49,957 iteration 5719 : loss : 0.050716, loss_ce: 0.012060
2021-12-14 03:57:51,551 iteration 5720 : loss : 0.052486, loss_ce: 0.019947
2021-12-14 03:57:53,000 iteration 5721 : loss : 0.045111, loss_ce: 0.012633
2021-12-14 03:57:54,565 iteration 5722 : loss : 0.048515, loss_ce: 0.017323
2021-12-14 03:57:56,176 iteration 5723 : loss : 0.070022, loss_ce: 0.022208
2021-12-14 03:57:57,721 iteration 5724 : loss : 0.041463, loss_ce: 0.013555
2021-12-14 03:57:59,202 iteration 5725 : loss : 0.044747, loss_ce: 0.015691
2021-12-14 03:58:00,773 iteration 5726 : loss : 0.040205, loss_ce: 0.012938
2021-12-14 03:58:02,323 iteration 5727 : loss : 0.048401, loss_ce: 0.020447
2021-12-14 03:58:03,795 iteration 5728 : loss : 0.044344, loss_ce: 0.012542
2021-12-14 03:58:05,204 iteration 5729 : loss : 0.051321, loss_ce: 0.012865
 84%|████████████████████████▍    | 337/400 [2:39:10<29:13, 27.83s/it]2021-12-14 03:58:06,889 iteration 5730 : loss : 0.056319, loss_ce: 0.019625
2021-12-14 03:58:08,493 iteration 5731 : loss : 0.058427, loss_ce: 0.019571
2021-12-14 03:58:10,074 iteration 5732 : loss : 0.052999, loss_ce: 0.011614
2021-12-14 03:58:11,592 iteration 5733 : loss : 0.046382, loss_ce: 0.015820
2021-12-14 03:58:13,078 iteration 5734 : loss : 0.045793, loss_ce: 0.016840
2021-12-14 03:58:14,729 iteration 5735 : loss : 0.063854, loss_ce: 0.020612
2021-12-14 03:58:16,327 iteration 5736 : loss : 0.048731, loss_ce: 0.017800
2021-12-14 03:58:17,843 iteration 5737 : loss : 0.042354, loss_ce: 0.012998
2021-12-14 03:58:19,332 iteration 5738 : loss : 0.043652, loss_ce: 0.016704
2021-12-14 03:58:20,879 iteration 5739 : loss : 0.041465, loss_ce: 0.012146
2021-12-14 03:58:22,473 iteration 5740 : loss : 0.061641, loss_ce: 0.025238
2021-12-14 03:58:24,003 iteration 5741 : loss : 0.041574, loss_ce: 0.014191
2021-12-14 03:58:25,491 iteration 5742 : loss : 0.064638, loss_ce: 0.012184
2021-12-14 03:58:27,015 iteration 5743 : loss : 0.052138, loss_ce: 0.015757
2021-12-14 03:58:28,491 iteration 5744 : loss : 0.046434, loss_ce: 0.017772
2021-12-14 03:58:30,047 iteration 5745 : loss : 0.041157, loss_ce: 0.011741
2021-12-14 03:58:31,521 iteration 5746 : loss : 0.048993, loss_ce: 0.019529
 84%|████████████████████████▌    | 338/400 [2:39:36<28:17, 27.38s/it]2021-12-14 03:58:33,135 iteration 5747 : loss : 0.070835, loss_ce: 0.025310
2021-12-14 03:58:34,617 iteration 5748 : loss : 0.046223, loss_ce: 0.017392
2021-12-14 03:58:36,207 iteration 5749 : loss : 0.059013, loss_ce: 0.026707
2021-12-14 03:58:37,748 iteration 5750 : loss : 0.047066, loss_ce: 0.011391
2021-12-14 03:58:39,346 iteration 5751 : loss : 0.060929, loss_ce: 0.022492
2021-12-14 03:58:40,888 iteration 5752 : loss : 0.041347, loss_ce: 0.009413
2021-12-14 03:58:42,469 iteration 5753 : loss : 0.051197, loss_ce: 0.023376
2021-12-14 03:58:43,966 iteration 5754 : loss : 0.042775, loss_ce: 0.012553
2021-12-14 03:58:45,458 iteration 5755 : loss : 0.046277, loss_ce: 0.012992
2021-12-14 03:58:46,938 iteration 5756 : loss : 0.052982, loss_ce: 0.023200
2021-12-14 03:58:48,469 iteration 5757 : loss : 0.044575, loss_ce: 0.012750
2021-12-14 03:58:49,891 iteration 5758 : loss : 0.034586, loss_ce: 0.009123
2021-12-14 03:58:51,489 iteration 5759 : loss : 0.049199, loss_ce: 0.012613
2021-12-14 03:58:52,993 iteration 5760 : loss : 0.040333, loss_ce: 0.012536
2021-12-14 03:58:54,536 iteration 5761 : loss : 0.043516, loss_ce: 0.013034
2021-12-14 03:58:56,154 iteration 5762 : loss : 0.044099, loss_ce: 0.016241
2021-12-14 03:58:57,743 iteration 5763 : loss : 0.051175, loss_ce: 0.018090
 85%|████████████████████████▌    | 339/400 [2:40:02<27:28, 27.03s/it]2021-12-14 03:58:59,412 iteration 5764 : loss : 0.053406, loss_ce: 0.020566
2021-12-14 03:59:00,954 iteration 5765 : loss : 0.049216, loss_ce: 0.013076
2021-12-14 03:59:02,437 iteration 5766 : loss : 0.045502, loss_ce: 0.013196
2021-12-14 03:59:04,029 iteration 5767 : loss : 0.046562, loss_ce: 0.015131
2021-12-14 03:59:05,598 iteration 5768 : loss : 0.059427, loss_ce: 0.017423
2021-12-14 03:59:07,151 iteration 5769 : loss : 0.039994, loss_ce: 0.010206
2021-12-14 03:59:08,717 iteration 5770 : loss : 0.051741, loss_ce: 0.018895
2021-12-14 03:59:10,138 iteration 5771 : loss : 0.041980, loss_ce: 0.015642
2021-12-14 03:59:11,672 iteration 5772 : loss : 0.050518, loss_ce: 0.016113
2021-12-14 03:59:13,095 iteration 5773 : loss : 0.042023, loss_ce: 0.013036
2021-12-14 03:59:14,572 iteration 5774 : loss : 0.045138, loss_ce: 0.016306
2021-12-14 03:59:16,107 iteration 5775 : loss : 0.058324, loss_ce: 0.017841
2021-12-14 03:59:17,490 iteration 5776 : loss : 0.046383, loss_ce: 0.015302
2021-12-14 03:59:18,984 iteration 5777 : loss : 0.041737, loss_ce: 0.012479
2021-12-14 03:59:20,520 iteration 5778 : loss : 0.049272, loss_ce: 0.016801
2021-12-14 03:59:22,043 iteration 5779 : loss : 0.045795, loss_ce: 0.014361
2021-12-14 03:59:22,043 Training Data Eval:
2021-12-14 03:59:29,478   Average segmentation loss on training set: 0.0363
2021-12-14 03:59:29,478 Validation Data Eval:
2021-12-14 03:59:32,041   Average segmentation loss on validation set: 0.0893
2021-12-14 03:59:33,532 iteration 5780 : loss : 0.043082, loss_ce: 0.015684
 85%|████████████████████████▋    | 340/400 [2:40:38<29:39, 29.66s/it]2021-12-14 03:59:35,107 iteration 5781 : loss : 0.049704, loss_ce: 0.017090
2021-12-14 03:59:36,515 iteration 5782 : loss : 0.042889, loss_ce: 0.014223
2021-12-14 03:59:38,071 iteration 5783 : loss : 0.046258, loss_ce: 0.013178
2021-12-14 03:59:39,624 iteration 5784 : loss : 0.046634, loss_ce: 0.013262
2021-12-14 03:59:41,168 iteration 5785 : loss : 0.038159, loss_ce: 0.013858
2021-12-14 03:59:42,775 iteration 5786 : loss : 0.046246, loss_ce: 0.015967
2021-12-14 03:59:44,293 iteration 5787 : loss : 0.047209, loss_ce: 0.012966
2021-12-14 03:59:45,823 iteration 5788 : loss : 0.048132, loss_ce: 0.016652
2021-12-14 03:59:47,345 iteration 5789 : loss : 0.043277, loss_ce: 0.012601
2021-12-14 03:59:48,909 iteration 5790 : loss : 0.057162, loss_ce: 0.019314
2021-12-14 03:59:50,487 iteration 5791 : loss : 0.043156, loss_ce: 0.014598
2021-12-14 03:59:52,119 iteration 5792 : loss : 0.050561, loss_ce: 0.013176
2021-12-14 03:59:53,593 iteration 5793 : loss : 0.041497, loss_ce: 0.014362
2021-12-14 03:59:55,065 iteration 5794 : loss : 0.047658, loss_ce: 0.014370
2021-12-14 03:59:56,558 iteration 5795 : loss : 0.048633, loss_ce: 0.018466
2021-12-14 03:59:58,053 iteration 5796 : loss : 0.040355, loss_ce: 0.013981
2021-12-14 03:59:59,537 iteration 5797 : loss : 0.042182, loss_ce: 0.011524
 85%|████████████████████████▋    | 341/400 [2:41:04<28:05, 28.56s/it]2021-12-14 04:00:01,035 iteration 5798 : loss : 0.044361, loss_ce: 0.013293
2021-12-14 04:00:02,499 iteration 5799 : loss : 0.043098, loss_ce: 0.014591
2021-12-14 04:00:03,886 iteration 5800 : loss : 0.037289, loss_ce: 0.012241
2021-12-14 04:00:05,395 iteration 5801 : loss : 0.049207, loss_ce: 0.017791
2021-12-14 04:00:06,835 iteration 5802 : loss : 0.040321, loss_ce: 0.013968
2021-12-14 04:00:08,404 iteration 5803 : loss : 0.051185, loss_ce: 0.015210
2021-12-14 04:00:09,866 iteration 5804 : loss : 0.045090, loss_ce: 0.013932
2021-12-14 04:00:11,309 iteration 5805 : loss : 0.054584, loss_ce: 0.013533
2021-12-14 04:00:12,731 iteration 5806 : loss : 0.040803, loss_ce: 0.015262
2021-12-14 04:00:14,276 iteration 5807 : loss : 0.055121, loss_ce: 0.016950
2021-12-14 04:00:15,833 iteration 5808 : loss : 0.050328, loss_ce: 0.015360
2021-12-14 04:00:17,406 iteration 5809 : loss : 0.051818, loss_ce: 0.017402
2021-12-14 04:00:19,060 iteration 5810 : loss : 0.049980, loss_ce: 0.014922
2021-12-14 04:00:20,646 iteration 5811 : loss : 0.052797, loss_ce: 0.020539
2021-12-14 04:00:22,128 iteration 5812 : loss : 0.059399, loss_ce: 0.022955
2021-12-14 04:00:23,583 iteration 5813 : loss : 0.042718, loss_ce: 0.011919
2021-12-14 04:00:25,072 iteration 5814 : loss : 0.063706, loss_ce: 0.021062
 86%|████████████████████████▊    | 342/400 [2:41:30<26:44, 27.66s/it]2021-12-14 04:00:26,724 iteration 5815 : loss : 0.058352, loss_ce: 0.017986
2021-12-14 04:00:28,216 iteration 5816 : loss : 0.042683, loss_ce: 0.014230
2021-12-14 04:00:29,831 iteration 5817 : loss : 0.047919, loss_ce: 0.018697
2021-12-14 04:00:31,400 iteration 5818 : loss : 0.050826, loss_ce: 0.018818
2021-12-14 04:00:32,880 iteration 5819 : loss : 0.042509, loss_ce: 0.011207
2021-12-14 04:00:34,353 iteration 5820 : loss : 0.051389, loss_ce: 0.015920
2021-12-14 04:00:35,897 iteration 5821 : loss : 0.045189, loss_ce: 0.014687
2021-12-14 04:00:37,530 iteration 5822 : loss : 0.052166, loss_ce: 0.013626
2021-12-14 04:00:38,972 iteration 5823 : loss : 0.042765, loss_ce: 0.018190
2021-12-14 04:00:40,604 iteration 5824 : loss : 0.062443, loss_ce: 0.013684
2021-12-14 04:00:42,141 iteration 5825 : loss : 0.040003, loss_ce: 0.012181
2021-12-14 04:00:43,667 iteration 5826 : loss : 0.051178, loss_ce: 0.019344
2021-12-14 04:00:45,112 iteration 5827 : loss : 0.048117, loss_ce: 0.016860
2021-12-14 04:00:46,738 iteration 5828 : loss : 0.060494, loss_ce: 0.012332
2021-12-14 04:00:48,244 iteration 5829 : loss : 0.048991, loss_ce: 0.014264
2021-12-14 04:00:49,684 iteration 5830 : loss : 0.043433, loss_ce: 0.013128
2021-12-14 04:00:51,283 iteration 5831 : loss : 0.055326, loss_ce: 0.020039
 86%|████████████████████████▊    | 343/400 [2:41:56<25:51, 27.22s/it]2021-12-14 04:00:52,901 iteration 5832 : loss : 0.050516, loss_ce: 0.018029
2021-12-14 04:00:54,519 iteration 5833 : loss : 0.058647, loss_ce: 0.017097
2021-12-14 04:00:56,032 iteration 5834 : loss : 0.055718, loss_ce: 0.022188
2021-12-14 04:00:57,545 iteration 5835 : loss : 0.047169, loss_ce: 0.014420
2021-12-14 04:00:59,033 iteration 5836 : loss : 0.057719, loss_ce: 0.017267
2021-12-14 04:01:00,631 iteration 5837 : loss : 0.044742, loss_ce: 0.014671
2021-12-14 04:01:02,168 iteration 5838 : loss : 0.049823, loss_ce: 0.013409
2021-12-14 04:01:03,696 iteration 5839 : loss : 0.079474, loss_ce: 0.024034
2021-12-14 04:01:05,212 iteration 5840 : loss : 0.051949, loss_ce: 0.015058
2021-12-14 04:01:06,789 iteration 5841 : loss : 0.052584, loss_ce: 0.015768
2021-12-14 04:01:08,240 iteration 5842 : loss : 0.047330, loss_ce: 0.013502
2021-12-14 04:01:09,683 iteration 5843 : loss : 0.052587, loss_ce: 0.017417
2021-12-14 04:01:11,209 iteration 5844 : loss : 0.052001, loss_ce: 0.017716
2021-12-14 04:01:12,647 iteration 5845 : loss : 0.043541, loss_ce: 0.014237
2021-12-14 04:01:14,094 iteration 5846 : loss : 0.040086, loss_ce: 0.014470
2021-12-14 04:01:15,556 iteration 5847 : loss : 0.046398, loss_ce: 0.015647
2021-12-14 04:01:17,036 iteration 5848 : loss : 0.044804, loss_ce: 0.013780
 86%|████████████████████████▉    | 344/400 [2:42:22<24:59, 26.78s/it]2021-12-14 04:01:18,615 iteration 5849 : loss : 0.052950, loss_ce: 0.014023
2021-12-14 04:01:20,217 iteration 5850 : loss : 0.055684, loss_ce: 0.022531
2021-12-14 04:01:21,789 iteration 5851 : loss : 0.044192, loss_ce: 0.010154
2021-12-14 04:01:23,327 iteration 5852 : loss : 0.046541, loss_ce: 0.016991
2021-12-14 04:01:24,787 iteration 5853 : loss : 0.046924, loss_ce: 0.013540
2021-12-14 04:01:26,363 iteration 5854 : loss : 0.044226, loss_ce: 0.014068
2021-12-14 04:01:27,871 iteration 5855 : loss : 0.050281, loss_ce: 0.021835
2021-12-14 04:01:29,389 iteration 5856 : loss : 0.059850, loss_ce: 0.020926
2021-12-14 04:01:30,939 iteration 5857 : loss : 0.045415, loss_ce: 0.014389
2021-12-14 04:01:32,510 iteration 5858 : loss : 0.049293, loss_ce: 0.015031
2021-12-14 04:01:34,156 iteration 5859 : loss : 0.051485, loss_ce: 0.016372
2021-12-14 04:01:35,690 iteration 5860 : loss : 0.049176, loss_ce: 0.014843
2021-12-14 04:01:37,185 iteration 5861 : loss : 0.051725, loss_ce: 0.017878
2021-12-14 04:01:38,723 iteration 5862 : loss : 0.046728, loss_ce: 0.018630
2021-12-14 04:01:40,252 iteration 5863 : loss : 0.077621, loss_ce: 0.022235
2021-12-14 04:01:41,905 iteration 5864 : loss : 0.049934, loss_ce: 0.019373
2021-12-14 04:01:41,905 Training Data Eval:
2021-12-14 04:01:49,340   Average segmentation loss on training set: 0.0355
2021-12-14 04:01:49,340 Validation Data Eval:
2021-12-14 04:01:51,907   Average segmentation loss on validation set: 0.0885
2021-12-14 04:01:53,566 iteration 5865 : loss : 0.068304, loss_ce: 0.019917
 86%|█████████████████████████    | 345/400 [2:42:58<27:13, 29.71s/it]2021-12-14 04:01:55,072 iteration 5866 : loss : 0.048423, loss_ce: 0.012937
2021-12-14 04:01:56,555 iteration 5867 : loss : 0.040532, loss_ce: 0.014280
2021-12-14 04:01:58,093 iteration 5868 : loss : 0.043077, loss_ce: 0.014511
2021-12-14 04:01:59,590 iteration 5869 : loss : 0.044953, loss_ce: 0.011849
2021-12-14 04:02:01,240 iteration 5870 : loss : 0.055356, loss_ce: 0.018397
2021-12-14 04:02:02,743 iteration 5871 : loss : 0.041205, loss_ce: 0.013062
2021-12-14 04:02:04,209 iteration 5872 : loss : 0.062570, loss_ce: 0.019569
2021-12-14 04:02:05,737 iteration 5873 : loss : 0.054242, loss_ce: 0.026719
2021-12-14 04:02:07,287 iteration 5874 : loss : 0.048347, loss_ce: 0.016008
2021-12-14 04:02:08,829 iteration 5875 : loss : 0.040595, loss_ce: 0.016045
2021-12-14 04:02:10,466 iteration 5876 : loss : 0.041931, loss_ce: 0.013985
2021-12-14 04:02:12,046 iteration 5877 : loss : 0.065456, loss_ce: 0.024550
2021-12-14 04:02:13,492 iteration 5878 : loss : 0.048997, loss_ce: 0.015067
2021-12-14 04:02:14,998 iteration 5879 : loss : 0.048691, loss_ce: 0.016019
2021-12-14 04:02:16,546 iteration 5880 : loss : 0.061352, loss_ce: 0.016047
2021-12-14 04:02:18,010 iteration 5881 : loss : 0.046542, loss_ce: 0.016724
2021-12-14 04:02:19,452 iteration 5882 : loss : 0.046224, loss_ce: 0.014004
 86%|█████████████████████████    | 346/400 [2:43:24<25:42, 28.56s/it]2021-12-14 04:02:20,983 iteration 5883 : loss : 0.041762, loss_ce: 0.011607
2021-12-14 04:02:22,392 iteration 5884 : loss : 0.040626, loss_ce: 0.012533
2021-12-14 04:02:23,975 iteration 5885 : loss : 0.045891, loss_ce: 0.010629
2021-12-14 04:02:25,470 iteration 5886 : loss : 0.057606, loss_ce: 0.016909
2021-12-14 04:02:27,028 iteration 5887 : loss : 0.044805, loss_ce: 0.015236
2021-12-14 04:02:28,550 iteration 5888 : loss : 0.035416, loss_ce: 0.011233
2021-12-14 04:02:30,155 iteration 5889 : loss : 0.041444, loss_ce: 0.012532
2021-12-14 04:02:31,660 iteration 5890 : loss : 0.048539, loss_ce: 0.016555
2021-12-14 04:02:33,174 iteration 5891 : loss : 0.050946, loss_ce: 0.013254
2021-12-14 04:02:34,721 iteration 5892 : loss : 0.041861, loss_ce: 0.011522
2021-12-14 04:02:36,207 iteration 5893 : loss : 0.060481, loss_ce: 0.023609
2021-12-14 04:02:37,630 iteration 5894 : loss : 0.053209, loss_ce: 0.020463
2021-12-14 04:02:39,064 iteration 5895 : loss : 0.040074, loss_ce: 0.013774
2021-12-14 04:02:40,517 iteration 5896 : loss : 0.045682, loss_ce: 0.015218
2021-12-14 04:02:42,018 iteration 5897 : loss : 0.044520, loss_ce: 0.016421
2021-12-14 04:02:43,479 iteration 5898 : loss : 0.066926, loss_ce: 0.019322
2021-12-14 04:02:45,055 iteration 5899 : loss : 0.049976, loss_ce: 0.018863
 87%|█████████████████████████▏   | 347/400 [2:43:50<24:26, 27.67s/it]2021-12-14 04:02:46,520 iteration 5900 : loss : 0.042193, loss_ce: 0.012169
2021-12-14 04:02:48,158 iteration 5901 : loss : 0.046842, loss_ce: 0.012766
2021-12-14 04:02:49,801 iteration 5902 : loss : 0.049664, loss_ce: 0.019342
2021-12-14 04:02:51,312 iteration 5903 : loss : 0.052557, loss_ce: 0.015630
2021-12-14 04:02:52,838 iteration 5904 : loss : 0.053637, loss_ce: 0.019323
2021-12-14 04:02:54,275 iteration 5905 : loss : 0.042620, loss_ce: 0.013758
2021-12-14 04:02:55,769 iteration 5906 : loss : 0.044069, loss_ce: 0.015417
2021-12-14 04:02:57,294 iteration 5907 : loss : 0.047029, loss_ce: 0.013944
2021-12-14 04:02:58,792 iteration 5908 : loss : 0.054354, loss_ce: 0.016413
2021-12-14 04:03:00,251 iteration 5909 : loss : 0.039114, loss_ce: 0.013962
2021-12-14 04:03:01,733 iteration 5910 : loss : 0.046031, loss_ce: 0.017451
2021-12-14 04:03:03,222 iteration 5911 : loss : 0.046951, loss_ce: 0.015825
2021-12-14 04:03:04,894 iteration 5912 : loss : 0.100674, loss_ce: 0.018773
2021-12-14 04:03:06,328 iteration 5913 : loss : 0.047503, loss_ce: 0.015358
2021-12-14 04:03:07,929 iteration 5914 : loss : 0.043191, loss_ce: 0.014850
2021-12-14 04:03:09,501 iteration 5915 : loss : 0.048746, loss_ce: 0.018443
2021-12-14 04:03:11,025 iteration 5916 : loss : 0.047496, loss_ce: 0.016189
 87%|█████████████████████████▏   | 348/400 [2:44:16<23:32, 27.16s/it]2021-12-14 04:03:12,588 iteration 5917 : loss : 0.050726, loss_ce: 0.010540
2021-12-14 04:03:14,211 iteration 5918 : loss : 0.054487, loss_ce: 0.018272
2021-12-14 04:03:15,674 iteration 5919 : loss : 0.046121, loss_ce: 0.021395
2021-12-14 04:03:17,351 iteration 5920 : loss : 0.050722, loss_ce: 0.018236
2021-12-14 04:03:18,861 iteration 5921 : loss : 0.057570, loss_ce: 0.016732
2021-12-14 04:03:20,421 iteration 5922 : loss : 0.054464, loss_ce: 0.022667
2021-12-14 04:03:21,912 iteration 5923 : loss : 0.052176, loss_ce: 0.013278
2021-12-14 04:03:23,375 iteration 5924 : loss : 0.041845, loss_ce: 0.014568
2021-12-14 04:03:24,851 iteration 5925 : loss : 0.041637, loss_ce: 0.011988
2021-12-14 04:03:26,348 iteration 5926 : loss : 0.040298, loss_ce: 0.013377
2021-12-14 04:03:27,955 iteration 5927 : loss : 0.064191, loss_ce: 0.023405
2021-12-14 04:03:29,358 iteration 5928 : loss : 0.039743, loss_ce: 0.014691
2021-12-14 04:03:30,803 iteration 5929 : loss : 0.040437, loss_ce: 0.010266
2021-12-14 04:03:32,339 iteration 5930 : loss : 0.053477, loss_ce: 0.016369
2021-12-14 04:03:33,875 iteration 5931 : loss : 0.045230, loss_ce: 0.018298
2021-12-14 04:03:35,358 iteration 5932 : loss : 0.051517, loss_ce: 0.016131
2021-12-14 04:03:36,816 iteration 5933 : loss : 0.039265, loss_ce: 0.012525
 87%|█████████████████████████▎   | 349/400 [2:44:42<22:44, 26.75s/it]2021-12-14 04:03:38,318 iteration 5934 : loss : 0.044708, loss_ce: 0.015110
2021-12-14 04:03:39,735 iteration 5935 : loss : 0.048760, loss_ce: 0.020017
2021-12-14 04:03:41,144 iteration 5936 : loss : 0.046042, loss_ce: 0.015129
2021-12-14 04:03:42,702 iteration 5937 : loss : 0.052273, loss_ce: 0.020206
2021-12-14 04:03:44,239 iteration 5938 : loss : 0.039126, loss_ce: 0.013687
2021-12-14 04:03:45,834 iteration 5939 : loss : 0.064692, loss_ce: 0.022411
2021-12-14 04:03:47,306 iteration 5940 : loss : 0.035420, loss_ce: 0.011724
2021-12-14 04:03:48,885 iteration 5941 : loss : 0.045800, loss_ce: 0.015038
2021-12-14 04:03:50,402 iteration 5942 : loss : 0.043242, loss_ce: 0.015744
2021-12-14 04:03:51,975 iteration 5943 : loss : 0.043846, loss_ce: 0.013869
2021-12-14 04:03:53,378 iteration 5944 : loss : 0.048726, loss_ce: 0.016750
2021-12-14 04:03:55,044 iteration 5945 : loss : 0.059471, loss_ce: 0.015971
2021-12-14 04:03:56,576 iteration 5946 : loss : 0.041875, loss_ce: 0.013731
2021-12-14 04:03:58,241 iteration 5947 : loss : 0.057181, loss_ce: 0.015803
2021-12-14 04:03:59,856 iteration 5948 : loss : 0.053419, loss_ce: 0.015534
2021-12-14 04:04:01,367 iteration 5949 : loss : 0.059645, loss_ce: 0.012890
2021-12-14 04:04:01,367 Training Data Eval:
2021-12-14 04:04:08,800   Average segmentation loss on training set: 0.0359
2021-12-14 04:04:08,801 Validation Data Eval:
2021-12-14 04:04:11,371   Average segmentation loss on validation set: 0.0837
2021-12-14 04:04:12,808 iteration 5950 : loss : 0.040310, loss_ce: 0.011901
 88%|█████████████████████████▍   | 350/400 [2:45:18<24:36, 29.53s/it]2021-12-14 04:04:14,282 iteration 5951 : loss : 0.049448, loss_ce: 0.013810
2021-12-14 04:04:15,806 iteration 5952 : loss : 0.048105, loss_ce: 0.020103
2021-12-14 04:04:17,446 iteration 5953 : loss : 0.060557, loss_ce: 0.027933
2021-12-14 04:04:18,926 iteration 5954 : loss : 0.055284, loss_ce: 0.012987
2021-12-14 04:04:20,604 iteration 5955 : loss : 0.061999, loss_ce: 0.017230
2021-12-14 04:04:22,088 iteration 5956 : loss : 0.064317, loss_ce: 0.017743
2021-12-14 04:04:23,661 iteration 5957 : loss : 0.055029, loss_ce: 0.021113
2021-12-14 04:04:25,232 iteration 5958 : loss : 0.051271, loss_ce: 0.019415
2021-12-14 04:04:26,804 iteration 5959 : loss : 0.051278, loss_ce: 0.012927
2021-12-14 04:04:28,272 iteration 5960 : loss : 0.044213, loss_ce: 0.010202
2021-12-14 04:04:29,833 iteration 5961 : loss : 0.057701, loss_ce: 0.026478
2021-12-14 04:04:31,391 iteration 5962 : loss : 0.046922, loss_ce: 0.015020
2021-12-14 04:04:32,849 iteration 5963 : loss : 0.044941, loss_ce: 0.015388
2021-12-14 04:04:34,439 iteration 5964 : loss : 0.060941, loss_ce: 0.022840
2021-12-14 04:04:35,995 iteration 5965 : loss : 0.044184, loss_ce: 0.018596
2021-12-14 04:04:37,490 iteration 5966 : loss : 0.038510, loss_ce: 0.012169
2021-12-14 04:04:39,104 iteration 5967 : loss : 0.050373, loss_ce: 0.016172
 88%|█████████████████████████▍   | 351/400 [2:45:44<23:19, 28.55s/it]2021-12-14 04:04:40,645 iteration 5968 : loss : 0.046278, loss_ce: 0.015908
2021-12-14 04:04:42,147 iteration 5969 : loss : 0.049637, loss_ce: 0.019749
2021-12-14 04:04:43,703 iteration 5970 : loss : 0.048554, loss_ce: 0.016589
2021-12-14 04:04:45,161 iteration 5971 : loss : 0.040742, loss_ce: 0.014455
2021-12-14 04:04:46,609 iteration 5972 : loss : 0.050154, loss_ce: 0.014204
2021-12-14 04:04:48,069 iteration 5973 : loss : 0.047294, loss_ce: 0.015018
2021-12-14 04:04:49,560 iteration 5974 : loss : 0.046659, loss_ce: 0.013353
2021-12-14 04:04:51,087 iteration 5975 : loss : 0.057016, loss_ce: 0.029056
2021-12-14 04:04:52,644 iteration 5976 : loss : 0.049031, loss_ce: 0.014345
2021-12-14 04:04:54,088 iteration 5977 : loss : 0.044917, loss_ce: 0.014354
2021-12-14 04:04:55,573 iteration 5978 : loss : 0.046072, loss_ce: 0.012466
2021-12-14 04:04:57,077 iteration 5979 : loss : 0.043451, loss_ce: 0.012393
2021-12-14 04:04:58,697 iteration 5980 : loss : 0.058240, loss_ce: 0.012731
2021-12-14 04:05:00,310 iteration 5981 : loss : 0.047532, loss_ce: 0.015496
2021-12-14 04:05:01,843 iteration 5982 : loss : 0.070763, loss_ce: 0.031239
2021-12-14 04:05:03,386 iteration 5983 : loss : 0.057395, loss_ce: 0.015896
2021-12-14 04:05:04,996 iteration 5984 : loss : 0.054004, loss_ce: 0.016235
 88%|█████████████████████████▌   | 352/400 [2:46:10<22:12, 27.76s/it]2021-12-14 04:05:06,625 iteration 5985 : loss : 0.056944, loss_ce: 0.019979
2021-12-14 04:05:08,006 iteration 5986 : loss : 0.047493, loss_ce: 0.020089
2021-12-14 04:05:09,610 iteration 5987 : loss : 0.066014, loss_ce: 0.015705
2021-12-14 04:05:11,024 iteration 5988 : loss : 0.041318, loss_ce: 0.015104
2021-12-14 04:05:12,529 iteration 5989 : loss : 0.046870, loss_ce: 0.015576
2021-12-14 04:05:14,022 iteration 5990 : loss : 0.078046, loss_ce: 0.025572
2021-12-14 04:05:15,648 iteration 5991 : loss : 0.046251, loss_ce: 0.011834
2021-12-14 04:05:17,246 iteration 5992 : loss : 0.073032, loss_ce: 0.018236
2021-12-14 04:05:18,727 iteration 5993 : loss : 0.047322, loss_ce: 0.014594
2021-12-14 04:05:20,135 iteration 5994 : loss : 0.036867, loss_ce: 0.014544
2021-12-14 04:05:21,782 iteration 5995 : loss : 0.042118, loss_ce: 0.012031
2021-12-14 04:05:23,346 iteration 5996 : loss : 0.039452, loss_ce: 0.015888
2021-12-14 04:05:24,810 iteration 5997 : loss : 0.043363, loss_ce: 0.012642
2021-12-14 04:05:26,494 iteration 5998 : loss : 0.059589, loss_ce: 0.019492
2021-12-14 04:05:27,982 iteration 5999 : loss : 0.047633, loss_ce: 0.013932
2021-12-14 04:05:29,641 iteration 6000 : loss : 0.051717, loss_ce: 0.018421
2021-12-14 04:05:31,076 iteration 6001 : loss : 0.038644, loss_ce: 0.012964
 88%|█████████████████████████▌   | 353/400 [2:46:36<21:20, 27.25s/it]2021-12-14 04:05:32,588 iteration 6002 : loss : 0.046618, loss_ce: 0.015465
2021-12-14 04:05:34,139 iteration 6003 : loss : 0.043229, loss_ce: 0.017516
2021-12-14 04:05:35,625 iteration 6004 : loss : 0.044363, loss_ce: 0.014017
2021-12-14 04:05:37,094 iteration 6005 : loss : 0.047531, loss_ce: 0.017033
2021-12-14 04:05:38,686 iteration 6006 : loss : 0.047406, loss_ce: 0.012335
2021-12-14 04:05:40,136 iteration 6007 : loss : 0.042948, loss_ce: 0.015301
2021-12-14 04:05:41,637 iteration 6008 : loss : 0.051792, loss_ce: 0.016893
2021-12-14 04:05:43,211 iteration 6009 : loss : 0.055151, loss_ce: 0.014872
2021-12-14 04:05:44,652 iteration 6010 : loss : 0.047744, loss_ce: 0.010941
2021-12-14 04:05:46,200 iteration 6011 : loss : 0.076174, loss_ce: 0.019174
2021-12-14 04:05:47,823 iteration 6012 : loss : 0.046043, loss_ce: 0.016338
2021-12-14 04:05:49,334 iteration 6013 : loss : 0.049812, loss_ce: 0.014960
2021-12-14 04:05:50,785 iteration 6014 : loss : 0.049629, loss_ce: 0.015322
2021-12-14 04:05:52,193 iteration 6015 : loss : 0.038127, loss_ce: 0.015617
2021-12-14 04:05:53,678 iteration 6016 : loss : 0.039536, loss_ce: 0.010380
2021-12-14 04:05:55,191 iteration 6017 : loss : 0.044160, loss_ce: 0.013542
2021-12-14 04:05:56,594 iteration 6018 : loss : 0.044668, loss_ce: 0.016185
 88%|█████████████████████████▋   | 354/400 [2:47:01<20:29, 26.73s/it]2021-12-14 04:05:58,240 iteration 6019 : loss : 0.041841, loss_ce: 0.013267
2021-12-14 04:05:59,781 iteration 6020 : loss : 0.058880, loss_ce: 0.016374
2021-12-14 04:06:01,226 iteration 6021 : loss : 0.039089, loss_ce: 0.012703
2021-12-14 04:06:02,806 iteration 6022 : loss : 0.040630, loss_ce: 0.014390
2021-12-14 04:06:04,389 iteration 6023 : loss : 0.043502, loss_ce: 0.016076
2021-12-14 04:06:05,900 iteration 6024 : loss : 0.043750, loss_ce: 0.014758
2021-12-14 04:06:07,341 iteration 6025 : loss : 0.052082, loss_ce: 0.010880
2021-12-14 04:06:08,839 iteration 6026 : loss : 0.047411, loss_ce: 0.014519
2021-12-14 04:06:10,409 iteration 6027 : loss : 0.040627, loss_ce: 0.013785
2021-12-14 04:06:11,858 iteration 6028 : loss : 0.046939, loss_ce: 0.016992
2021-12-14 04:06:13,378 iteration 6029 : loss : 0.049318, loss_ce: 0.019872
2021-12-14 04:06:14,988 iteration 6030 : loss : 0.056449, loss_ce: 0.019687
2021-12-14 04:06:16,550 iteration 6031 : loss : 0.055584, loss_ce: 0.017437
2021-12-14 04:06:18,081 iteration 6032 : loss : 0.060694, loss_ce: 0.016360
2021-12-14 04:06:19,586 iteration 6033 : loss : 0.068234, loss_ce: 0.023550
2021-12-14 04:06:21,028 iteration 6034 : loss : 0.041308, loss_ce: 0.012474
2021-12-14 04:06:21,028 Training Data Eval:
2021-12-14 04:06:28,461   Average segmentation loss on training set: 0.0358
2021-12-14 04:06:28,462 Validation Data Eval:
2021-12-14 04:06:31,036   Average segmentation loss on validation set: 0.0865
2021-12-14 04:06:32,485 iteration 6035 : loss : 0.054244, loss_ce: 0.022842
 89%|█████████████████████████▋   | 355/400 [2:47:37<22:06, 29.48s/it]2021-12-14 04:06:34,075 iteration 6036 : loss : 0.043189, loss_ce: 0.017801
2021-12-14 04:06:35,501 iteration 6037 : loss : 0.040164, loss_ce: 0.015024
2021-12-14 04:06:36,957 iteration 6038 : loss : 0.042987, loss_ce: 0.014584
2021-12-14 04:06:38,335 iteration 6039 : loss : 0.040222, loss_ce: 0.011625
2021-12-14 04:06:39,784 iteration 6040 : loss : 0.051096, loss_ce: 0.012217
2021-12-14 04:06:41,351 iteration 6041 : loss : 0.045038, loss_ce: 0.015666
2021-12-14 04:06:42,805 iteration 6042 : loss : 0.048491, loss_ce: 0.012462
2021-12-14 04:06:44,202 iteration 6043 : loss : 0.041699, loss_ce: 0.009490
2021-12-14 04:06:45,745 iteration 6044 : loss : 0.046102, loss_ce: 0.012170
2021-12-14 04:06:47,219 iteration 6045 : loss : 0.045554, loss_ce: 0.016613
2021-12-14 04:06:48,721 iteration 6046 : loss : 0.048758, loss_ce: 0.017387
2021-12-14 04:06:50,191 iteration 6047 : loss : 0.039182, loss_ce: 0.012565
2021-12-14 04:06:51,742 iteration 6048 : loss : 0.050722, loss_ce: 0.020191
2021-12-14 04:06:53,230 iteration 6049 : loss : 0.045036, loss_ce: 0.019314
2021-12-14 04:06:54,728 iteration 6050 : loss : 0.045789, loss_ce: 0.015507
2021-12-14 04:06:56,379 iteration 6051 : loss : 0.041736, loss_ce: 0.012787
2021-12-14 04:06:57,884 iteration 6052 : loss : 0.052345, loss_ce: 0.018985
 89%|█████████████████████████▊   | 356/400 [2:48:03<20:43, 28.26s/it]2021-12-14 04:06:59,401 iteration 6053 : loss : 0.051547, loss_ce: 0.015948
2021-12-14 04:07:00,819 iteration 6054 : loss : 0.043977, loss_ce: 0.018705
2021-12-14 04:07:02,402 iteration 6055 : loss : 0.047682, loss_ce: 0.014950
2021-12-14 04:07:03,887 iteration 6056 : loss : 0.048665, loss_ce: 0.017456
2021-12-14 04:07:05,331 iteration 6057 : loss : 0.041407, loss_ce: 0.012341
2021-12-14 04:07:06,860 iteration 6058 : loss : 0.045945, loss_ce: 0.012692
2021-12-14 04:07:08,438 iteration 6059 : loss : 0.046524, loss_ce: 0.018253
2021-12-14 04:07:10,134 iteration 6060 : loss : 0.087367, loss_ce: 0.030418
2021-12-14 04:07:11,644 iteration 6061 : loss : 0.046820, loss_ce: 0.017503
2021-12-14 04:07:13,265 iteration 6062 : loss : 0.046050, loss_ce: 0.014578
2021-12-14 04:07:14,724 iteration 6063 : loss : 0.043237, loss_ce: 0.010336
2021-12-14 04:07:16,326 iteration 6064 : loss : 0.047958, loss_ce: 0.018874
2021-12-14 04:07:17,767 iteration 6065 : loss : 0.037116, loss_ce: 0.010701
2021-12-14 04:07:19,226 iteration 6066 : loss : 0.038942, loss_ce: 0.010459
2021-12-14 04:07:20,726 iteration 6067 : loss : 0.044492, loss_ce: 0.016550
2021-12-14 04:07:22,170 iteration 6068 : loss : 0.040437, loss_ce: 0.009967
2021-12-14 04:07:23,661 iteration 6069 : loss : 0.050563, loss_ce: 0.019114
 89%|█████████████████████████▉   | 357/400 [2:48:28<19:43, 27.51s/it]2021-12-14 04:07:25,214 iteration 6070 : loss : 0.037565, loss_ce: 0.015870
2021-12-14 04:07:26,656 iteration 6071 : loss : 0.041645, loss_ce: 0.011563
2021-12-14 04:07:28,128 iteration 6072 : loss : 0.043031, loss_ce: 0.018228
2021-12-14 04:07:29,636 iteration 6073 : loss : 0.042276, loss_ce: 0.012448
2021-12-14 04:07:31,178 iteration 6074 : loss : 0.042835, loss_ce: 0.014678
2021-12-14 04:07:32,573 iteration 6075 : loss : 0.039860, loss_ce: 0.014724
2021-12-14 04:07:34,046 iteration 6076 : loss : 0.043114, loss_ce: 0.009513
2021-12-14 04:07:35,562 iteration 6077 : loss : 0.050253, loss_ce: 0.017160
2021-12-14 04:07:37,141 iteration 6078 : loss : 0.052853, loss_ce: 0.015689
2021-12-14 04:07:38,808 iteration 6079 : loss : 0.047606, loss_ce: 0.015890
2021-12-14 04:07:40,330 iteration 6080 : loss : 0.047682, loss_ce: 0.015578
2021-12-14 04:07:41,894 iteration 6081 : loss : 0.053911, loss_ce: 0.017780
2021-12-14 04:07:43,305 iteration 6082 : loss : 0.042459, loss_ce: 0.010328
2021-12-14 04:07:44,740 iteration 6083 : loss : 0.049650, loss_ce: 0.013914
2021-12-14 04:07:46,241 iteration 6084 : loss : 0.053784, loss_ce: 0.012531
2021-12-14 04:07:47,728 iteration 6085 : loss : 0.058486, loss_ce: 0.017627
2021-12-14 04:07:49,200 iteration 6086 : loss : 0.041681, loss_ce: 0.012722
 90%|█████████████████████████▉   | 358/400 [2:48:54<18:50, 26.92s/it]2021-12-14 04:07:50,693 iteration 6087 : loss : 0.043721, loss_ce: 0.013226
2021-12-14 04:07:52,252 iteration 6088 : loss : 0.044496, loss_ce: 0.015298
2021-12-14 04:07:53,742 iteration 6089 : loss : 0.040727, loss_ce: 0.011295
2021-12-14 04:07:55,107 iteration 6090 : loss : 0.039834, loss_ce: 0.015262
2021-12-14 04:07:56,638 iteration 6091 : loss : 0.044669, loss_ce: 0.015124
2021-12-14 04:07:58,173 iteration 6092 : loss : 0.054160, loss_ce: 0.014375
2021-12-14 04:07:59,669 iteration 6093 : loss : 0.053522, loss_ce: 0.020513
2021-12-14 04:08:01,116 iteration 6094 : loss : 0.050108, loss_ce: 0.015831
2021-12-14 04:08:02,570 iteration 6095 : loss : 0.047873, loss_ce: 0.013510
2021-12-14 04:08:04,087 iteration 6096 : loss : 0.047011, loss_ce: 0.012158
2021-12-14 04:08:05,611 iteration 6097 : loss : 0.039286, loss_ce: 0.013617
2021-12-14 04:08:07,236 iteration 6098 : loss : 0.046892, loss_ce: 0.016820
2021-12-14 04:08:08,828 iteration 6099 : loss : 0.043980, loss_ce: 0.016467
2021-12-14 04:08:10,375 iteration 6100 : loss : 0.044366, loss_ce: 0.018444
2021-12-14 04:08:11,919 iteration 6101 : loss : 0.059186, loss_ce: 0.021791
2021-12-14 04:08:13,485 iteration 6102 : loss : 0.056712, loss_ce: 0.025395
2021-12-14 04:08:15,060 iteration 6103 : loss : 0.060350, loss_ce: 0.015902
 90%|██████████████████████████   | 359/400 [2:49:20<18:10, 26.61s/it]2021-12-14 04:08:16,718 iteration 6104 : loss : 0.052432, loss_ce: 0.020770
2021-12-14 04:08:18,296 iteration 6105 : loss : 0.046012, loss_ce: 0.018158
2021-12-14 04:08:19,857 iteration 6106 : loss : 0.061325, loss_ce: 0.025386
2021-12-14 04:08:21,381 iteration 6107 : loss : 0.047237, loss_ce: 0.016189
2021-12-14 04:08:22,860 iteration 6108 : loss : 0.047361, loss_ce: 0.016729
2021-12-14 04:08:24,360 iteration 6109 : loss : 0.047641, loss_ce: 0.011539
2021-12-14 04:08:25,837 iteration 6110 : loss : 0.046863, loss_ce: 0.016048
2021-12-14 04:08:27,310 iteration 6111 : loss : 0.048934, loss_ce: 0.014423
2021-12-14 04:08:28,811 iteration 6112 : loss : 0.054340, loss_ce: 0.013437
2021-12-14 04:08:30,330 iteration 6113 : loss : 0.044187, loss_ce: 0.017072
2021-12-14 04:08:31,880 iteration 6114 : loss : 0.045510, loss_ce: 0.012641
2021-12-14 04:08:33,377 iteration 6115 : loss : 0.045212, loss_ce: 0.015845
2021-12-14 04:08:34,931 iteration 6116 : loss : 0.048304, loss_ce: 0.014497
2021-12-14 04:08:36,387 iteration 6117 : loss : 0.047110, loss_ce: 0.015572
2021-12-14 04:08:37,815 iteration 6118 : loss : 0.039022, loss_ce: 0.011025
2021-12-14 04:08:39,448 iteration 6119 : loss : 0.048024, loss_ce: 0.018471
2021-12-14 04:08:39,449 Training Data Eval:
2021-12-14 04:08:46,875   Average segmentation loss on training set: 0.0355
2021-12-14 04:08:46,876 Validation Data Eval:
2021-12-14 04:08:49,439   Average segmentation loss on validation set: 0.0852
2021-12-14 04:08:50,929 iteration 6120 : loss : 0.048139, loss_ce: 0.013698
 90%|██████████████████████████   | 360/400 [2:49:56<19:35, 29.38s/it]2021-12-14 04:08:52,477 iteration 6121 : loss : 0.053793, loss_ce: 0.014828
2021-12-14 04:08:53,993 iteration 6122 : loss : 0.041922, loss_ce: 0.015170
2021-12-14 04:08:55,497 iteration 6123 : loss : 0.054353, loss_ce: 0.018286
2021-12-14 04:08:56,951 iteration 6124 : loss : 0.037202, loss_ce: 0.011438
2021-12-14 04:08:58,475 iteration 6125 : loss : 0.059108, loss_ce: 0.020857
2021-12-14 04:08:59,933 iteration 6126 : loss : 0.046310, loss_ce: 0.020883
2021-12-14 04:09:01,490 iteration 6127 : loss : 0.040679, loss_ce: 0.012079
2021-12-14 04:09:02,974 iteration 6128 : loss : 0.046680, loss_ce: 0.014448
2021-12-14 04:09:04,618 iteration 6129 : loss : 0.052199, loss_ce: 0.015988
2021-12-14 04:09:06,085 iteration 6130 : loss : 0.043094, loss_ce: 0.010401
2021-12-14 04:09:07,696 iteration 6131 : loss : 0.050033, loss_ce: 0.022162
2021-12-14 04:09:09,186 iteration 6132 : loss : 0.052122, loss_ce: 0.024375
2021-12-14 04:09:10,741 iteration 6133 : loss : 0.055975, loss_ce: 0.015913
2021-12-14 04:09:12,262 iteration 6134 : loss : 0.045308, loss_ce: 0.013070
2021-12-14 04:09:13,901 iteration 6135 : loss : 0.055259, loss_ce: 0.018247
2021-12-14 04:09:15,419 iteration 6136 : loss : 0.055455, loss_ce: 0.014416
2021-12-14 04:09:16,882 iteration 6137 : loss : 0.050795, loss_ce: 0.018968
 90%|██████████████████████████▏  | 361/400 [2:50:22<18:25, 28.35s/it]2021-12-14 04:09:18,390 iteration 6138 : loss : 0.043806, loss_ce: 0.012899
2021-12-14 04:09:19,906 iteration 6139 : loss : 0.042839, loss_ce: 0.014368
2021-12-14 04:09:21,387 iteration 6140 : loss : 0.050216, loss_ce: 0.021665
2021-12-14 04:09:22,787 iteration 6141 : loss : 0.041245, loss_ce: 0.013200
2021-12-14 04:09:24,179 iteration 6142 : loss : 0.038445, loss_ce: 0.013198
2021-12-14 04:09:25,750 iteration 6143 : loss : 0.045199, loss_ce: 0.011090
2021-12-14 04:09:27,236 iteration 6144 : loss : 0.040374, loss_ce: 0.012919
2021-12-14 04:09:28,702 iteration 6145 : loss : 0.040839, loss_ce: 0.014942
2021-12-14 04:09:30,158 iteration 6146 : loss : 0.068379, loss_ce: 0.017258
2021-12-14 04:09:31,645 iteration 6147 : loss : 0.042308, loss_ce: 0.015058
2021-12-14 04:09:33,205 iteration 6148 : loss : 0.047155, loss_ce: 0.015529
2021-12-14 04:09:34,755 iteration 6149 : loss : 0.046167, loss_ce: 0.015293
2021-12-14 04:09:36,376 iteration 6150 : loss : 0.042748, loss_ce: 0.013494
2021-12-14 04:09:37,981 iteration 6151 : loss : 0.044170, loss_ce: 0.010109
2021-12-14 04:09:39,433 iteration 6152 : loss : 0.042521, loss_ce: 0.015205
2021-12-14 04:09:40,971 iteration 6153 : loss : 0.065291, loss_ce: 0.009814
2021-12-14 04:09:42,521 iteration 6154 : loss : 0.054389, loss_ce: 0.019394
 90%|██████████████████████████▏  | 362/400 [2:50:47<17:26, 27.54s/it]2021-12-14 04:09:44,144 iteration 6155 : loss : 0.055349, loss_ce: 0.017899
2021-12-14 04:09:45,700 iteration 6156 : loss : 0.047361, loss_ce: 0.018222
2021-12-14 04:09:47,245 iteration 6157 : loss : 0.052080, loss_ce: 0.018088
2021-12-14 04:09:48,861 iteration 6158 : loss : 0.056380, loss_ce: 0.014239
2021-12-14 04:09:50,325 iteration 6159 : loss : 0.038434, loss_ce: 0.012013
2021-12-14 04:09:51,811 iteration 6160 : loss : 0.038406, loss_ce: 0.012857
2021-12-14 04:09:53,369 iteration 6161 : loss : 0.046173, loss_ce: 0.013286
2021-12-14 04:09:54,969 iteration 6162 : loss : 0.062494, loss_ce: 0.016501
2021-12-14 04:09:56,496 iteration 6163 : loss : 0.043149, loss_ce: 0.015255
2021-12-14 04:09:57,911 iteration 6164 : loss : 0.041499, loss_ce: 0.010987
2021-12-14 04:09:59,500 iteration 6165 : loss : 0.046128, loss_ce: 0.015015
2021-12-14 04:10:00,967 iteration 6166 : loss : 0.040986, loss_ce: 0.013155
2021-12-14 04:10:02,576 iteration 6167 : loss : 0.052929, loss_ce: 0.023391
2021-12-14 04:10:04,119 iteration 6168 : loss : 0.049558, loss_ce: 0.017139
2021-12-14 04:10:05,627 iteration 6169 : loss : 0.053913, loss_ce: 0.016602
2021-12-14 04:10:07,088 iteration 6170 : loss : 0.045880, loss_ce: 0.019248
2021-12-14 04:10:08,564 iteration 6171 : loss : 0.052209, loss_ce: 0.018920
 91%|██████████████████████████▎  | 363/400 [2:51:13<16:42, 27.09s/it]2021-12-14 04:10:10,102 iteration 6172 : loss : 0.055240, loss_ce: 0.015166
2021-12-14 04:10:11,710 iteration 6173 : loss : 0.061172, loss_ce: 0.015046
2021-12-14 04:10:13,255 iteration 6174 : loss : 0.045774, loss_ce: 0.016529
2021-12-14 04:10:14,917 iteration 6175 : loss : 0.043124, loss_ce: 0.012691
2021-12-14 04:10:16,466 iteration 6176 : loss : 0.040501, loss_ce: 0.012672
2021-12-14 04:10:17,971 iteration 6177 : loss : 0.043340, loss_ce: 0.015334
2021-12-14 04:10:19,517 iteration 6178 : loss : 0.048187, loss_ce: 0.014434
2021-12-14 04:10:20,988 iteration 6179 : loss : 0.055114, loss_ce: 0.016005
2021-12-14 04:10:22,573 iteration 6180 : loss : 0.049657, loss_ce: 0.019606
2021-12-14 04:10:24,046 iteration 6181 : loss : 0.040312, loss_ce: 0.011242
2021-12-14 04:10:25,512 iteration 6182 : loss : 0.049170, loss_ce: 0.012782
2021-12-14 04:10:27,095 iteration 6183 : loss : 0.052716, loss_ce: 0.019571
2021-12-14 04:10:28,634 iteration 6184 : loss : 0.051557, loss_ce: 0.020404
2021-12-14 04:10:30,228 iteration 6185 : loss : 0.055696, loss_ce: 0.014250
2021-12-14 04:10:31,724 iteration 6186 : loss : 0.041626, loss_ce: 0.013118
2021-12-14 04:10:33,263 iteration 6187 : loss : 0.045288, loss_ce: 0.018524
2021-12-14 04:10:34,886 iteration 6188 : loss : 0.056309, loss_ce: 0.023752
 91%|██████████████████████████▍  | 364/400 [2:51:40<16:07, 26.86s/it]2021-12-14 04:10:36,546 iteration 6189 : loss : 0.051479, loss_ce: 0.010477
2021-12-14 04:10:38,152 iteration 6190 : loss : 0.055254, loss_ce: 0.013345
2021-12-14 04:10:39,643 iteration 6191 : loss : 0.048138, loss_ce: 0.021482
2021-12-14 04:10:41,083 iteration 6192 : loss : 0.040317, loss_ce: 0.013042
2021-12-14 04:10:42,577 iteration 6193 : loss : 0.047557, loss_ce: 0.013446
2021-12-14 04:10:44,026 iteration 6194 : loss : 0.055024, loss_ce: 0.018330
2021-12-14 04:10:45,655 iteration 6195 : loss : 0.044024, loss_ce: 0.012096
2021-12-14 04:10:47,149 iteration 6196 : loss : 0.046673, loss_ce: 0.013989
2021-12-14 04:10:48,597 iteration 6197 : loss : 0.046702, loss_ce: 0.018619
2021-12-14 04:10:50,273 iteration 6198 : loss : 0.067289, loss_ce: 0.016468
2021-12-14 04:10:51,773 iteration 6199 : loss : 0.046706, loss_ce: 0.017386
2021-12-14 04:10:53,251 iteration 6200 : loss : 0.041993, loss_ce: 0.015503
2021-12-14 04:10:54,782 iteration 6201 : loss : 0.043737, loss_ce: 0.014420
2021-12-14 04:10:56,215 iteration 6202 : loss : 0.042219, loss_ce: 0.012940
2021-12-14 04:10:57,937 iteration 6203 : loss : 0.047485, loss_ce: 0.016551
2021-12-14 04:10:59,386 iteration 6204 : loss : 0.039981, loss_ce: 0.014797
2021-12-14 04:10:59,386 Training Data Eval:
2021-12-14 04:11:06,819   Average segmentation loss on training set: 0.0355
2021-12-14 04:11:06,819 Validation Data Eval:
2021-12-14 04:11:09,386   Average segmentation loss on validation set: 0.0837
2021-12-14 04:11:10,978 iteration 6205 : loss : 0.053127, loss_ce: 0.015205
 91%|██████████████████████████▍  | 365/400 [2:52:16<17:17, 29.63s/it]2021-12-14 04:11:12,568 iteration 6206 : loss : 0.046370, loss_ce: 0.017506
2021-12-14 04:11:14,120 iteration 6207 : loss : 0.041781, loss_ce: 0.015373
2021-12-14 04:11:15,701 iteration 6208 : loss : 0.057973, loss_ce: 0.019107
2021-12-14 04:11:17,231 iteration 6209 : loss : 0.053553, loss_ce: 0.020199
2021-12-14 04:11:18,763 iteration 6210 : loss : 0.039182, loss_ce: 0.013339
2021-12-14 04:11:20,259 iteration 6211 : loss : 0.052719, loss_ce: 0.022182
2021-12-14 04:11:21,724 iteration 6212 : loss : 0.044079, loss_ce: 0.013758
2021-12-14 04:11:23,116 iteration 6213 : loss : 0.039180, loss_ce: 0.012201
2021-12-14 04:11:24,733 iteration 6214 : loss : 0.069963, loss_ce: 0.023194
2021-12-14 04:11:26,242 iteration 6215 : loss : 0.051298, loss_ce: 0.013665
2021-12-14 04:11:27,764 iteration 6216 : loss : 0.043574, loss_ce: 0.012484
2021-12-14 04:11:29,327 iteration 6217 : loss : 0.045593, loss_ce: 0.015486
2021-12-14 04:11:30,782 iteration 6218 : loss : 0.050336, loss_ce: 0.018864
2021-12-14 04:11:32,318 iteration 6219 : loss : 0.050513, loss_ce: 0.015576
2021-12-14 04:11:33,729 iteration 6220 : loss : 0.042193, loss_ce: 0.010980
2021-12-14 04:11:35,365 iteration 6221 : loss : 0.045887, loss_ce: 0.014022
2021-12-14 04:11:36,894 iteration 6222 : loss : 0.042934, loss_ce: 0.015785
 92%|██████████████████████████▌  | 366/400 [2:52:42<16:09, 28.51s/it]2021-12-14 04:11:38,498 iteration 6223 : loss : 0.054082, loss_ce: 0.021593
2021-12-14 04:11:40,071 iteration 6224 : loss : 0.046356, loss_ce: 0.017988
2021-12-14 04:11:41,626 iteration 6225 : loss : 0.043101, loss_ce: 0.016850
2021-12-14 04:11:43,139 iteration 6226 : loss : 0.041326, loss_ce: 0.013440
2021-12-14 04:11:44,750 iteration 6227 : loss : 0.039020, loss_ce: 0.011514
2021-12-14 04:11:46,253 iteration 6228 : loss : 0.046280, loss_ce: 0.015791
2021-12-14 04:11:47,832 iteration 6229 : loss : 0.050587, loss_ce: 0.013620
2021-12-14 04:11:49,414 iteration 6230 : loss : 0.052753, loss_ce: 0.010535
2021-12-14 04:11:50,863 iteration 6231 : loss : 0.056843, loss_ce: 0.023981
2021-12-14 04:11:52,352 iteration 6232 : loss : 0.044401, loss_ce: 0.014190
2021-12-14 04:11:53,979 iteration 6233 : loss : 0.066640, loss_ce: 0.020038
2021-12-14 04:11:55,474 iteration 6234 : loss : 0.052573, loss_ce: 0.018144
2021-12-14 04:11:56,985 iteration 6235 : loss : 0.042344, loss_ce: 0.011511
2021-12-14 04:11:58,580 iteration 6236 : loss : 0.052182, loss_ce: 0.017782
2021-12-14 04:12:00,132 iteration 6237 : loss : 0.052839, loss_ce: 0.017915
2021-12-14 04:12:01,720 iteration 6238 : loss : 0.044429, loss_ce: 0.016227
2021-12-14 04:12:03,342 iteration 6239 : loss : 0.045985, loss_ce: 0.015529
 92%|██████████████████████████▌  | 367/400 [2:53:08<15:20, 27.90s/it]2021-12-14 04:12:04,880 iteration 6240 : loss : 0.058683, loss_ce: 0.018469
2021-12-14 04:12:06,320 iteration 6241 : loss : 0.052921, loss_ce: 0.020532
2021-12-14 04:12:07,868 iteration 6242 : loss : 0.041815, loss_ce: 0.016123
2021-12-14 04:12:09,384 iteration 6243 : loss : 0.042754, loss_ce: 0.013739
2021-12-14 04:12:10,918 iteration 6244 : loss : 0.055350, loss_ce: 0.018439
2021-12-14 04:12:12,465 iteration 6245 : loss : 0.056934, loss_ce: 0.020193
2021-12-14 04:12:13,951 iteration 6246 : loss : 0.043358, loss_ce: 0.014100
2021-12-14 04:12:15,425 iteration 6247 : loss : 0.049581, loss_ce: 0.015800
2021-12-14 04:12:16,970 iteration 6248 : loss : 0.069602, loss_ce: 0.015446
2021-12-14 04:12:18,546 iteration 6249 : loss : 0.075313, loss_ce: 0.024305
2021-12-14 04:12:19,938 iteration 6250 : loss : 0.044853, loss_ce: 0.009643
2021-12-14 04:12:21,507 iteration 6251 : loss : 0.068624, loss_ce: 0.037417
2021-12-14 04:12:22,917 iteration 6252 : loss : 0.041139, loss_ce: 0.011735
2021-12-14 04:12:24,559 iteration 6253 : loss : 0.050976, loss_ce: 0.018560
2021-12-14 04:12:25,972 iteration 6254 : loss : 0.037451, loss_ce: 0.013071
2021-12-14 04:12:27,661 iteration 6255 : loss : 0.056690, loss_ce: 0.018879
2021-12-14 04:12:29,133 iteration 6256 : loss : 0.048307, loss_ce: 0.017240
 92%|██████████████████████████▋  | 368/400 [2:53:34<14:32, 27.26s/it]2021-12-14 04:12:30,781 iteration 6257 : loss : 0.048156, loss_ce: 0.016712
2021-12-14 04:12:32,277 iteration 6258 : loss : 0.037254, loss_ce: 0.014950
2021-12-14 04:12:33,816 iteration 6259 : loss : 0.046663, loss_ce: 0.017242
2021-12-14 04:12:35,321 iteration 6260 : loss : 0.053709, loss_ce: 0.014922
2021-12-14 04:12:36,793 iteration 6261 : loss : 0.039332, loss_ce: 0.013973
2021-12-14 04:12:38,332 iteration 6262 : loss : 0.051070, loss_ce: 0.018433
2021-12-14 04:12:39,898 iteration 6263 : loss : 0.052769, loss_ce: 0.013699
2021-12-14 04:12:41,410 iteration 6264 : loss : 0.043681, loss_ce: 0.017034
2021-12-14 04:12:42,867 iteration 6265 : loss : 0.047297, loss_ce: 0.018442
2021-12-14 04:12:44,380 iteration 6266 : loss : 0.042268, loss_ce: 0.015798
2021-12-14 04:12:45,888 iteration 6267 : loss : 0.059066, loss_ce: 0.020699
2021-12-14 04:12:47,398 iteration 6268 : loss : 0.046404, loss_ce: 0.015014
2021-12-14 04:12:48,867 iteration 6269 : loss : 0.059623, loss_ce: 0.022393
2021-12-14 04:12:50,403 iteration 6270 : loss : 0.059519, loss_ce: 0.019221
2021-12-14 04:12:51,925 iteration 6271 : loss : 0.046553, loss_ce: 0.010541
2021-12-14 04:12:53,407 iteration 6272 : loss : 0.038794, loss_ce: 0.010241
2021-12-14 04:12:54,803 iteration 6273 : loss : 0.037683, loss_ce: 0.012001
 92%|██████████████████████████▊  | 369/400 [2:54:00<13:50, 26.79s/it]2021-12-14 04:12:56,358 iteration 6274 : loss : 0.050664, loss_ce: 0.015070
2021-12-14 04:12:57,864 iteration 6275 : loss : 0.045982, loss_ce: 0.017682
2021-12-14 04:12:59,344 iteration 6276 : loss : 0.051370, loss_ce: 0.017220
2021-12-14 04:13:00,923 iteration 6277 : loss : 0.050547, loss_ce: 0.012175
2021-12-14 04:13:02,543 iteration 6278 : loss : 0.048014, loss_ce: 0.017133
2021-12-14 04:13:04,205 iteration 6279 : loss : 0.059992, loss_ce: 0.014595
2021-12-14 04:13:05,731 iteration 6280 : loss : 0.046333, loss_ce: 0.018104
2021-12-14 04:13:07,239 iteration 6281 : loss : 0.040105, loss_ce: 0.011565
2021-12-14 04:13:08,715 iteration 6282 : loss : 0.041980, loss_ce: 0.014337
2021-12-14 04:13:10,293 iteration 6283 : loss : 0.056971, loss_ce: 0.016194
2021-12-14 04:13:11,925 iteration 6284 : loss : 0.042273, loss_ce: 0.017407
2021-12-14 04:13:13,457 iteration 6285 : loss : 0.043641, loss_ce: 0.012973
2021-12-14 04:13:14,974 iteration 6286 : loss : 0.051890, loss_ce: 0.021356
2021-12-14 04:13:16,552 iteration 6287 : loss : 0.038906, loss_ce: 0.010793
2021-12-14 04:13:18,180 iteration 6288 : loss : 0.065625, loss_ce: 0.019349
2021-12-14 04:13:19,679 iteration 6289 : loss : 0.042178, loss_ce: 0.013002
2021-12-14 04:13:19,680 Training Data Eval:
2021-12-14 04:13:27,095   Average segmentation loss on training set: 0.0355
2021-12-14 04:13:27,096 Validation Data Eval:
2021-12-14 04:13:29,669   Average segmentation loss on validation set: 0.0934
2021-12-14 04:13:31,138 iteration 6290 : loss : 0.043935, loss_ce: 0.014519
 92%|██████████████████████████▊  | 370/400 [2:54:36<14:49, 29.65s/it]2021-12-14 04:13:32,702 iteration 6291 : loss : 0.047448, loss_ce: 0.011613
2021-12-14 04:13:34,347 iteration 6292 : loss : 0.042813, loss_ce: 0.014527
2021-12-14 04:13:35,835 iteration 6293 : loss : 0.049588, loss_ce: 0.015842
2021-12-14 04:13:37,382 iteration 6294 : loss : 0.049975, loss_ce: 0.017111
2021-12-14 04:13:38,954 iteration 6295 : loss : 0.053516, loss_ce: 0.017765
2021-12-14 04:13:40,444 iteration 6296 : loss : 0.037310, loss_ce: 0.011688
2021-12-14 04:13:41,947 iteration 6297 : loss : 0.047633, loss_ce: 0.012316
2021-12-14 04:13:43,420 iteration 6298 : loss : 0.039180, loss_ce: 0.011664
2021-12-14 04:13:45,006 iteration 6299 : loss : 0.048127, loss_ce: 0.015754
2021-12-14 04:13:46,513 iteration 6300 : loss : 0.044935, loss_ce: 0.014454
2021-12-14 04:13:47,974 iteration 6301 : loss : 0.053615, loss_ce: 0.018977
2021-12-14 04:13:49,426 iteration 6302 : loss : 0.044053, loss_ce: 0.016298
2021-12-14 04:13:50,967 iteration 6303 : loss : 0.046495, loss_ce: 0.018101
2021-12-14 04:13:52,441 iteration 6304 : loss : 0.045328, loss_ce: 0.015998
2021-12-14 04:13:53,872 iteration 6305 : loss : 0.040414, loss_ce: 0.015657
2021-12-14 04:13:55,307 iteration 6306 : loss : 0.040480, loss_ce: 0.012916
2021-12-14 04:13:56,905 iteration 6307 : loss : 0.046659, loss_ce: 0.014587
 93%|██████████████████████████▉  | 371/400 [2:55:02<13:46, 28.48s/it]2021-12-14 04:13:58,428 iteration 6308 : loss : 0.041310, loss_ce: 0.014273
2021-12-14 04:13:59,971 iteration 6309 : loss : 0.056817, loss_ce: 0.021857
2021-12-14 04:14:01,497 iteration 6310 : loss : 0.048961, loss_ce: 0.016266
2021-12-14 04:14:02,972 iteration 6311 : loss : 0.051713, loss_ce: 0.013892
2021-12-14 04:14:04,542 iteration 6312 : loss : 0.048104, loss_ce: 0.016293
2021-12-14 04:14:06,030 iteration 6313 : loss : 0.040402, loss_ce: 0.008959
2021-12-14 04:14:07,589 iteration 6314 : loss : 0.053871, loss_ce: 0.019419
2021-12-14 04:14:09,199 iteration 6315 : loss : 0.048507, loss_ce: 0.015777
2021-12-14 04:14:10,700 iteration 6316 : loss : 0.048391, loss_ce: 0.020285
2021-12-14 04:14:12,249 iteration 6317 : loss : 0.040739, loss_ce: 0.012628
2021-12-14 04:14:13,857 iteration 6318 : loss : 0.051523, loss_ce: 0.020021
2021-12-14 04:14:15,506 iteration 6319 : loss : 0.046873, loss_ce: 0.012695
2021-12-14 04:14:17,160 iteration 6320 : loss : 0.043420, loss_ce: 0.014679
2021-12-14 04:14:18,744 iteration 6321 : loss : 0.066236, loss_ce: 0.021202
2021-12-14 04:14:20,363 iteration 6322 : loss : 0.041048, loss_ce: 0.013861
2021-12-14 04:14:21,713 iteration 6323 : loss : 0.040977, loss_ce: 0.015441
2021-12-14 04:14:23,254 iteration 6324 : loss : 0.048533, loss_ce: 0.012944
 93%|██████████████████████████▉  | 372/400 [2:55:28<12:59, 27.84s/it]2021-12-14 04:14:24,734 iteration 6325 : loss : 0.047975, loss_ce: 0.013159
2021-12-14 04:14:26,165 iteration 6326 : loss : 0.038659, loss_ce: 0.013174
2021-12-14 04:14:27,566 iteration 6327 : loss : 0.040540, loss_ce: 0.012694
2021-12-14 04:14:29,157 iteration 6328 : loss : 0.045685, loss_ce: 0.016597
2021-12-14 04:14:30,808 iteration 6329 : loss : 0.052613, loss_ce: 0.015821
2021-12-14 04:14:32,365 iteration 6330 : loss : 0.045600, loss_ce: 0.014746
2021-12-14 04:14:33,959 iteration 6331 : loss : 0.058564, loss_ce: 0.023247
2021-12-14 04:14:35,444 iteration 6332 : loss : 0.042532, loss_ce: 0.013944
2021-12-14 04:14:36,945 iteration 6333 : loss : 0.043860, loss_ce: 0.015356
2021-12-14 04:14:38,489 iteration 6334 : loss : 0.040990, loss_ce: 0.014050
2021-12-14 04:14:40,221 iteration 6335 : loss : 0.051595, loss_ce: 0.021284
2021-12-14 04:14:41,778 iteration 6336 : loss : 0.044402, loss_ce: 0.013491
2021-12-14 04:14:43,195 iteration 6337 : loss : 0.047923, loss_ce: 0.016793
2021-12-14 04:14:44,805 iteration 6338 : loss : 0.046139, loss_ce: 0.013953
2021-12-14 04:14:46,289 iteration 6339 : loss : 0.045661, loss_ce: 0.012781
2021-12-14 04:14:47,810 iteration 6340 : loss : 0.047390, loss_ce: 0.018269
2021-12-14 04:14:49,364 iteration 6341 : loss : 0.047689, loss_ce: 0.013218
 93%|███████████████████████████  | 373/400 [2:55:54<12:17, 27.32s/it]2021-12-14 04:14:51,085 iteration 6342 : loss : 0.046641, loss_ce: 0.013076
2021-12-14 04:14:52,600 iteration 6343 : loss : 0.041846, loss_ce: 0.012091
2021-12-14 04:14:54,134 iteration 6344 : loss : 0.042988, loss_ce: 0.015621
2021-12-14 04:14:55,668 iteration 6345 : loss : 0.058336, loss_ce: 0.023281
2021-12-14 04:14:57,130 iteration 6346 : loss : 0.040945, loss_ce: 0.011405
2021-12-14 04:14:58,650 iteration 6347 : loss : 0.052190, loss_ce: 0.016516
2021-12-14 04:15:00,301 iteration 6348 : loss : 0.056062, loss_ce: 0.017096
2021-12-14 04:15:01,766 iteration 6349 : loss : 0.040393, loss_ce: 0.014670
2021-12-14 04:15:03,261 iteration 6350 : loss : 0.044584, loss_ce: 0.011875
2021-12-14 04:15:04,751 iteration 6351 : loss : 0.042940, loss_ce: 0.013415
2021-12-14 04:15:06,341 iteration 6352 : loss : 0.045458, loss_ce: 0.016629
2021-12-14 04:15:07,935 iteration 6353 : loss : 0.049714, loss_ce: 0.016074
2021-12-14 04:15:09,589 iteration 6354 : loss : 0.049153, loss_ce: 0.015974
2021-12-14 04:15:11,059 iteration 6355 : loss : 0.051800, loss_ce: 0.022505
2021-12-14 04:15:12,605 iteration 6356 : loss : 0.047686, loss_ce: 0.019301
2021-12-14 04:15:14,118 iteration 6357 : loss : 0.049033, loss_ce: 0.014485
2021-12-14 04:15:15,736 iteration 6358 : loss : 0.046377, loss_ce: 0.014995
 94%|███████████████████████████  | 374/400 [2:56:20<11:43, 27.04s/it]2021-12-14 04:15:17,308 iteration 6359 : loss : 0.046717, loss_ce: 0.013231
2021-12-14 04:15:18,776 iteration 6360 : loss : 0.048327, loss_ce: 0.012454
2021-12-14 04:15:20,320 iteration 6361 : loss : 0.050555, loss_ce: 0.013759
2021-12-14 04:15:21,887 iteration 6362 : loss : 0.044326, loss_ce: 0.017030
2021-12-14 04:15:23,509 iteration 6363 : loss : 0.043080, loss_ce: 0.014972
2021-12-14 04:15:24,962 iteration 6364 : loss : 0.039294, loss_ce: 0.013812
2021-12-14 04:15:26,399 iteration 6365 : loss : 0.041419, loss_ce: 0.013527
2021-12-14 04:15:27,967 iteration 6366 : loss : 0.048509, loss_ce: 0.017395
2021-12-14 04:15:29,479 iteration 6367 : loss : 0.040741, loss_ce: 0.014672
2021-12-14 04:15:30,961 iteration 6368 : loss : 0.062482, loss_ce: 0.022180
2021-12-14 04:15:32,502 iteration 6369 : loss : 0.049989, loss_ce: 0.020572
2021-12-14 04:15:34,069 iteration 6370 : loss : 0.049731, loss_ce: 0.013864
2021-12-14 04:15:35,645 iteration 6371 : loss : 0.056881, loss_ce: 0.018724
2021-12-14 04:15:37,181 iteration 6372 : loss : 0.051854, loss_ce: 0.023875
2021-12-14 04:15:38,531 iteration 6373 : loss : 0.039424, loss_ce: 0.010052
2021-12-14 04:15:39,992 iteration 6374 : loss : 0.037267, loss_ce: 0.013451
2021-12-14 04:15:39,992 Training Data Eval:
2021-12-14 04:15:47,414   Average segmentation loss on training set: 0.0352
2021-12-14 04:15:47,415 Validation Data Eval:
2021-12-14 04:15:49,974   Average segmentation loss on validation set: 0.0830
2021-12-14 04:15:51,467 iteration 6375 : loss : 0.043025, loss_ce: 0.012960
 94%|███████████████████████████▏ | 375/400 [2:56:56<12:21, 29.65s/it]2021-12-14 04:15:53,311 iteration 6376 : loss : 0.048938, loss_ce: 0.016831
2021-12-14 04:15:54,847 iteration 6377 : loss : 0.046506, loss_ce: 0.015796
2021-12-14 04:15:56,323 iteration 6378 : loss : 0.047959, loss_ce: 0.016684
2021-12-14 04:15:57,877 iteration 6379 : loss : 0.050637, loss_ce: 0.012161
2021-12-14 04:15:59,292 iteration 6380 : loss : 0.037933, loss_ce: 0.013824
2021-12-14 04:16:00,714 iteration 6381 : loss : 0.046989, loss_ce: 0.013309
2021-12-14 04:16:02,249 iteration 6382 : loss : 0.051598, loss_ce: 0.017063
2021-12-14 04:16:03,808 iteration 6383 : loss : 0.046484, loss_ce: 0.015521
2021-12-14 04:16:05,318 iteration 6384 : loss : 0.043236, loss_ce: 0.015559
2021-12-14 04:16:06,945 iteration 6385 : loss : 0.061934, loss_ce: 0.023581
2021-12-14 04:16:08,451 iteration 6386 : loss : 0.040005, loss_ce: 0.013304
2021-12-14 04:16:10,127 iteration 6387 : loss : 0.070678, loss_ce: 0.030639
2021-12-14 04:16:11,617 iteration 6388 : loss : 0.038960, loss_ce: 0.012555
2021-12-14 04:16:12,996 iteration 6389 : loss : 0.042107, loss_ce: 0.011953
2021-12-14 04:16:14,479 iteration 6390 : loss : 0.051937, loss_ce: 0.017080
2021-12-14 04:16:16,133 iteration 6391 : loss : 0.075634, loss_ce: 0.018108
2021-12-14 04:16:17,572 iteration 6392 : loss : 0.037782, loss_ce: 0.011943
 94%|███████████████████████████▎ | 376/400 [2:57:22<11:26, 28.58s/it]2021-12-14 04:16:19,134 iteration 6393 : loss : 0.044389, loss_ce: 0.013162
2021-12-14 04:16:20,686 iteration 6394 : loss : 0.040628, loss_ce: 0.013114
2021-12-14 04:16:22,166 iteration 6395 : loss : 0.045684, loss_ce: 0.018964
2021-12-14 04:16:23,793 iteration 6396 : loss : 0.045734, loss_ce: 0.016277
2021-12-14 04:16:25,258 iteration 6397 : loss : 0.045924, loss_ce: 0.014946
2021-12-14 04:16:26,694 iteration 6398 : loss : 0.039867, loss_ce: 0.010629
2021-12-14 04:16:28,214 iteration 6399 : loss : 0.045139, loss_ce: 0.013162
2021-12-14 04:16:29,735 iteration 6400 : loss : 0.046066, loss_ce: 0.019433
2021-12-14 04:16:31,168 iteration 6401 : loss : 0.040241, loss_ce: 0.013550
2021-12-14 04:16:32,705 iteration 6402 : loss : 0.045601, loss_ce: 0.014313
2021-12-14 04:16:34,370 iteration 6403 : loss : 0.053185, loss_ce: 0.017952
2021-12-14 04:16:35,864 iteration 6404 : loss : 0.040983, loss_ce: 0.011033
2021-12-14 04:16:37,371 iteration 6405 : loss : 0.050866, loss_ce: 0.019031
2021-12-14 04:16:39,108 iteration 6406 : loss : 0.055055, loss_ce: 0.020456
2021-12-14 04:16:40,544 iteration 6407 : loss : 0.047814, loss_ce: 0.013928
2021-12-14 04:16:42,054 iteration 6408 : loss : 0.051621, loss_ce: 0.013209
2021-12-14 04:16:43,542 iteration 6409 : loss : 0.044602, loss_ce: 0.015114
 94%|███████████████████████████▎ | 377/400 [2:57:48<10:39, 27.80s/it]2021-12-14 04:16:45,285 iteration 6410 : loss : 0.074888, loss_ce: 0.025294
2021-12-14 04:16:46,929 iteration 6411 : loss : 0.048142, loss_ce: 0.017456
2021-12-14 04:16:48,483 iteration 6412 : loss : 0.045539, loss_ce: 0.018311
2021-12-14 04:16:50,023 iteration 6413 : loss : 0.044953, loss_ce: 0.013550
2021-12-14 04:16:51,587 iteration 6414 : loss : 0.046948, loss_ce: 0.015754
2021-12-14 04:16:53,067 iteration 6415 : loss : 0.043946, loss_ce: 0.012703
2021-12-14 04:16:54,573 iteration 6416 : loss : 0.057579, loss_ce: 0.014327
2021-12-14 04:16:56,143 iteration 6417 : loss : 0.048499, loss_ce: 0.020708
2021-12-14 04:16:57,693 iteration 6418 : loss : 0.044260, loss_ce: 0.013701
2021-12-14 04:16:59,205 iteration 6419 : loss : 0.048524, loss_ce: 0.013762
2021-12-14 04:17:00,801 iteration 6420 : loss : 0.053788, loss_ce: 0.015764
2021-12-14 04:17:02,330 iteration 6421 : loss : 0.043446, loss_ce: 0.014519
2021-12-14 04:17:03,763 iteration 6422 : loss : 0.046779, loss_ce: 0.016269
2021-12-14 04:17:05,330 iteration 6423 : loss : 0.056068, loss_ce: 0.015880
2021-12-14 04:17:06,919 iteration 6424 : loss : 0.047556, loss_ce: 0.019326
2021-12-14 04:17:08,323 iteration 6425 : loss : 0.042367, loss_ce: 0.012596
2021-12-14 04:17:09,895 iteration 6426 : loss : 0.049563, loss_ce: 0.018108
 94%|███████████████████████████▍ | 378/400 [2:58:15<10:02, 27.37s/it]2021-12-14 04:17:11,506 iteration 6427 : loss : 0.050142, loss_ce: 0.018617
2021-12-14 04:17:12,921 iteration 6428 : loss : 0.040288, loss_ce: 0.016761
2021-12-14 04:17:14,480 iteration 6429 : loss : 0.050580, loss_ce: 0.016202
2021-12-14 04:17:15,910 iteration 6430 : loss : 0.042428, loss_ce: 0.011070
2021-12-14 04:17:17,432 iteration 6431 : loss : 0.045637, loss_ce: 0.012739
2021-12-14 04:17:18,951 iteration 6432 : loss : 0.046407, loss_ce: 0.016390
2021-12-14 04:17:20,563 iteration 6433 : loss : 0.044841, loss_ce: 0.015145
2021-12-14 04:17:21,973 iteration 6434 : loss : 0.039757, loss_ce: 0.011870
2021-12-14 04:17:23,488 iteration 6435 : loss : 0.041668, loss_ce: 0.017097
2021-12-14 04:17:24,982 iteration 6436 : loss : 0.044688, loss_ce: 0.014685
2021-12-14 04:17:26,552 iteration 6437 : loss : 0.056333, loss_ce: 0.014889
2021-12-14 04:17:28,128 iteration 6438 : loss : 0.043668, loss_ce: 0.014499
2021-12-14 04:17:29,684 iteration 6439 : loss : 0.047992, loss_ce: 0.015529
2021-12-14 04:17:31,308 iteration 6440 : loss : 0.051128, loss_ce: 0.017252
2021-12-14 04:17:32,853 iteration 6441 : loss : 0.047461, loss_ce: 0.013269
2021-12-14 04:17:34,380 iteration 6442 : loss : 0.050788, loss_ce: 0.019354
2021-12-14 04:17:35,938 iteration 6443 : loss : 0.052538, loss_ce: 0.018958
 95%|███████████████████████████▍ | 379/400 [2:58:41<09:26, 26.97s/it]2021-12-14 04:17:37,593 iteration 6444 : loss : 0.041718, loss_ce: 0.014638
2021-12-14 04:17:39,230 iteration 6445 : loss : 0.045244, loss_ce: 0.015144
2021-12-14 04:17:40,781 iteration 6446 : loss : 0.051090, loss_ce: 0.014889
2021-12-14 04:17:42,292 iteration 6447 : loss : 0.055824, loss_ce: 0.027038
2021-12-14 04:17:43,828 iteration 6448 : loss : 0.043160, loss_ce: 0.016509
2021-12-14 04:17:45,423 iteration 6449 : loss : 0.045368, loss_ce: 0.014598
2021-12-14 04:17:46,892 iteration 6450 : loss : 0.044252, loss_ce: 0.016255
2021-12-14 04:17:48,330 iteration 6451 : loss : 0.041554, loss_ce: 0.013000
2021-12-14 04:17:49,895 iteration 6452 : loss : 0.042689, loss_ce: 0.016043
2021-12-14 04:17:51,434 iteration 6453 : loss : 0.042150, loss_ce: 0.015556
2021-12-14 04:17:52,952 iteration 6454 : loss : 0.038625, loss_ce: 0.010959
2021-12-14 04:17:54,458 iteration 6455 : loss : 0.042520, loss_ce: 0.011360
2021-12-14 04:17:56,118 iteration 6456 : loss : 0.043262, loss_ce: 0.014166
2021-12-14 04:17:57,648 iteration 6457 : loss : 0.041088, loss_ce: 0.010502
2021-12-14 04:17:59,120 iteration 6458 : loss : 0.042434, loss_ce: 0.010629
2021-12-14 04:18:00,556 iteration 6459 : loss : 0.043614, loss_ce: 0.012819
2021-12-14 04:18:00,556 Training Data Eval:
2021-12-14 04:18:07,979   Average segmentation loss on training set: 0.0350
2021-12-14 04:18:07,979 Validation Data Eval:
2021-12-14 04:18:10,536   Average segmentation loss on validation set: 0.0882
2021-12-14 04:18:12,095 iteration 6460 : loss : 0.052327, loss_ce: 0.012869
 95%|███████████████████████████▌ | 380/400 [2:59:17<09:54, 29.72s/it]2021-12-14 04:18:13,687 iteration 6461 : loss : 0.049407, loss_ce: 0.012746
2021-12-14 04:18:15,226 iteration 6462 : loss : 0.046581, loss_ce: 0.013461
2021-12-14 04:18:16,687 iteration 6463 : loss : 0.037401, loss_ce: 0.009150
2021-12-14 04:18:18,141 iteration 6464 : loss : 0.042645, loss_ce: 0.013380
2021-12-14 04:18:19,627 iteration 6465 : loss : 0.059969, loss_ce: 0.014915
2021-12-14 04:18:21,200 iteration 6466 : loss : 0.045209, loss_ce: 0.016303
2021-12-14 04:18:22,791 iteration 6467 : loss : 0.041884, loss_ce: 0.014265
2021-12-14 04:18:24,404 iteration 6468 : loss : 0.052889, loss_ce: 0.022445
2021-12-14 04:18:25,919 iteration 6469 : loss : 0.050467, loss_ce: 0.019266
2021-12-14 04:18:27,417 iteration 6470 : loss : 0.063668, loss_ce: 0.017556
2021-12-14 04:18:28,910 iteration 6471 : loss : 0.046109, loss_ce: 0.014814
2021-12-14 04:18:30,405 iteration 6472 : loss : 0.049142, loss_ce: 0.012820
2021-12-14 04:18:31,833 iteration 6473 : loss : 0.048542, loss_ce: 0.021784
2021-12-14 04:18:33,442 iteration 6474 : loss : 0.056794, loss_ce: 0.024379
2021-12-14 04:18:34,856 iteration 6475 : loss : 0.038548, loss_ce: 0.012259
2021-12-14 04:18:36,332 iteration 6476 : loss : 0.041070, loss_ce: 0.013245
2021-12-14 04:18:37,759 iteration 6477 : loss : 0.042004, loss_ce: 0.014235
 95%|███████████████████████████▌ | 381/400 [2:59:43<09:01, 28.51s/it]2021-12-14 04:18:39,391 iteration 6478 : loss : 0.043729, loss_ce: 0.014848
2021-12-14 04:18:41,128 iteration 6479 : loss : 0.058935, loss_ce: 0.027902
2021-12-14 04:18:42,712 iteration 6480 : loss : 0.053378, loss_ce: 0.012000
2021-12-14 04:18:44,271 iteration 6481 : loss : 0.056922, loss_ce: 0.020445
2021-12-14 04:18:45,824 iteration 6482 : loss : 0.058889, loss_ce: 0.021605
2021-12-14 04:18:47,306 iteration 6483 : loss : 0.042982, loss_ce: 0.013479
2021-12-14 04:18:48,814 iteration 6484 : loss : 0.041580, loss_ce: 0.011430
2021-12-14 04:18:50,365 iteration 6485 : loss : 0.045794, loss_ce: 0.016539
2021-12-14 04:18:51,986 iteration 6486 : loss : 0.043110, loss_ce: 0.011626
2021-12-14 04:18:53,542 iteration 6487 : loss : 0.046524, loss_ce: 0.012776
2021-12-14 04:18:54,948 iteration 6488 : loss : 0.038563, loss_ce: 0.014428
2021-12-14 04:18:56,532 iteration 6489 : loss : 0.042184, loss_ce: 0.009354
2021-12-14 04:18:57,936 iteration 6490 : loss : 0.041529, loss_ce: 0.013362
2021-12-14 04:18:59,503 iteration 6491 : loss : 0.052513, loss_ce: 0.014919
2021-12-14 04:19:00,992 iteration 6492 : loss : 0.040241, loss_ce: 0.012951
2021-12-14 04:19:02,544 iteration 6493 : loss : 0.061108, loss_ce: 0.017716
2021-12-14 04:19:04,069 iteration 6494 : loss : 0.041793, loss_ce: 0.012785
 96%|███████████████████████████▋ | 382/400 [3:00:09<08:21, 27.85s/it]2021-12-14 04:19:05,715 iteration 6495 : loss : 0.041361, loss_ce: 0.009550
2021-12-14 04:19:07,208 iteration 6496 : loss : 0.040333, loss_ce: 0.013418
2021-12-14 04:19:08,763 iteration 6497 : loss : 0.043765, loss_ce: 0.015225
2021-12-14 04:19:10,313 iteration 6498 : loss : 0.057501, loss_ce: 0.024538
2021-12-14 04:19:11,997 iteration 6499 : loss : 0.050056, loss_ce: 0.014949
2021-12-14 04:19:13,576 iteration 6500 : loss : 0.045432, loss_ce: 0.017533
2021-12-14 04:19:15,190 iteration 6501 : loss : 0.041869, loss_ce: 0.009368
2021-12-14 04:19:16,794 iteration 6502 : loss : 0.047432, loss_ce: 0.017556
2021-12-14 04:19:18,468 iteration 6503 : loss : 0.046977, loss_ce: 0.014942
2021-12-14 04:19:19,931 iteration 6504 : loss : 0.041158, loss_ce: 0.016379
2021-12-14 04:19:21,432 iteration 6505 : loss : 0.047475, loss_ce: 0.014398
2021-12-14 04:19:22,940 iteration 6506 : loss : 0.047074, loss_ce: 0.014236
2021-12-14 04:19:24,447 iteration 6507 : loss : 0.046353, loss_ce: 0.016137
2021-12-14 04:19:25,962 iteration 6508 : loss : 0.039798, loss_ce: 0.010949
2021-12-14 04:19:27,480 iteration 6509 : loss : 0.040425, loss_ce: 0.014373
2021-12-14 04:19:28,978 iteration 6510 : loss : 0.042527, loss_ce: 0.012654
2021-12-14 04:19:30,498 iteration 6511 : loss : 0.046782, loss_ce: 0.017514
 96%|███████████████████████████▊ | 383/400 [3:00:35<07:46, 27.42s/it]2021-12-14 04:19:32,071 iteration 6512 : loss : 0.046376, loss_ce: 0.017607
2021-12-14 04:19:33,524 iteration 6513 : loss : 0.046549, loss_ce: 0.015542
2021-12-14 04:19:35,018 iteration 6514 : loss : 0.045854, loss_ce: 0.010424
2021-12-14 04:19:36,524 iteration 6515 : loss : 0.047208, loss_ce: 0.012629
2021-12-14 04:19:38,049 iteration 6516 : loss : 0.045734, loss_ce: 0.012861
2021-12-14 04:19:39,679 iteration 6517 : loss : 0.048398, loss_ce: 0.020515
2021-12-14 04:19:41,118 iteration 6518 : loss : 0.053346, loss_ce: 0.018591
2021-12-14 04:19:42,758 iteration 6519 : loss : 0.066012, loss_ce: 0.019992
2021-12-14 04:19:44,193 iteration 6520 : loss : 0.043373, loss_ce: 0.017118
2021-12-14 04:19:45,775 iteration 6521 : loss : 0.041647, loss_ce: 0.015743
2021-12-14 04:19:47,276 iteration 6522 : loss : 0.048620, loss_ce: 0.017971
2021-12-14 04:19:48,717 iteration 6523 : loss : 0.045833, loss_ce: 0.013137
2021-12-14 04:19:50,247 iteration 6524 : loss : 0.056992, loss_ce: 0.019660
2021-12-14 04:19:51,734 iteration 6525 : loss : 0.045035, loss_ce: 0.014082
2021-12-14 04:19:53,280 iteration 6526 : loss : 0.041689, loss_ce: 0.013448
2021-12-14 04:19:54,888 iteration 6527 : loss : 0.045052, loss_ce: 0.012625
2021-12-14 04:19:56,441 iteration 6528 : loss : 0.050023, loss_ce: 0.017320
 96%|███████████████████████████▊ | 384/400 [3:01:01<07:11, 26.98s/it]2021-12-14 04:19:57,960 iteration 6529 : loss : 0.043229, loss_ce: 0.014018
2021-12-14 04:19:59,374 iteration 6530 : loss : 0.043154, loss_ce: 0.017879
2021-12-14 04:20:00,907 iteration 6531 : loss : 0.046346, loss_ce: 0.009518
2021-12-14 04:20:02,497 iteration 6532 : loss : 0.038296, loss_ce: 0.009922
2021-12-14 04:20:03,966 iteration 6533 : loss : 0.038867, loss_ce: 0.013776
2021-12-14 04:20:05,539 iteration 6534 : loss : 0.053862, loss_ce: 0.016592
2021-12-14 04:20:07,071 iteration 6535 : loss : 0.052458, loss_ce: 0.017739
2021-12-14 04:20:08,643 iteration 6536 : loss : 0.052110, loss_ce: 0.018663
2021-12-14 04:20:10,314 iteration 6537 : loss : 0.054769, loss_ce: 0.016811
2021-12-14 04:20:11,790 iteration 6538 : loss : 0.044910, loss_ce: 0.013542
2021-12-14 04:20:13,469 iteration 6539 : loss : 0.048002, loss_ce: 0.016717
2021-12-14 04:20:14,931 iteration 6540 : loss : 0.047575, loss_ce: 0.018386
2021-12-14 04:20:16,362 iteration 6541 : loss : 0.044061, loss_ce: 0.015005
2021-12-14 04:20:17,857 iteration 6542 : loss : 0.049807, loss_ce: 0.017572
2021-12-14 04:20:19,467 iteration 6543 : loss : 0.040985, loss_ce: 0.012409
2021-12-14 04:20:20,977 iteration 6544 : loss : 0.054606, loss_ce: 0.019640
2021-12-14 04:20:20,977 Training Data Eval:
2021-12-14 04:20:28,399   Average segmentation loss on training set: 0.0352
2021-12-14 04:20:28,400 Validation Data Eval:
2021-12-14 04:20:30,959   Average segmentation loss on validation set: 0.0888
2021-12-14 04:20:32,470 iteration 6545 : loss : 0.038453, loss_ce: 0.009318
 96%|███████████████████████████▉ | 385/400 [3:01:37<07:25, 29.69s/it]2021-12-14 04:20:34,135 iteration 6546 : loss : 0.048468, loss_ce: 0.015459
2021-12-14 04:20:35,584 iteration 6547 : loss : 0.041450, loss_ce: 0.009608
2021-12-14 04:20:37,134 iteration 6548 : loss : 0.079320, loss_ce: 0.021224
2021-12-14 04:20:38,786 iteration 6549 : loss : 0.060020, loss_ce: 0.016582
2021-12-14 04:20:40,303 iteration 6550 : loss : 0.049339, loss_ce: 0.020868
2021-12-14 04:20:41,923 iteration 6551 : loss : 0.056295, loss_ce: 0.020173
2021-12-14 04:20:43,585 iteration 6552 : loss : 0.073528, loss_ce: 0.024731
2021-12-14 04:20:45,094 iteration 6553 : loss : 0.064426, loss_ce: 0.021472
2021-12-14 04:20:46,797 iteration 6554 : loss : 0.051409, loss_ce: 0.015918
2021-12-14 04:20:48,289 iteration 6555 : loss : 0.042406, loss_ce: 0.014946
2021-12-14 04:20:49,852 iteration 6556 : loss : 0.046843, loss_ce: 0.015361
2021-12-14 04:20:51,272 iteration 6557 : loss : 0.037623, loss_ce: 0.011145
2021-12-14 04:20:52,874 iteration 6558 : loss : 0.046471, loss_ce: 0.016613
2021-12-14 04:20:54,315 iteration 6559 : loss : 0.039735, loss_ce: 0.012595
2021-12-14 04:20:55,764 iteration 6560 : loss : 0.039632, loss_ce: 0.015703
2021-12-14 04:20:57,328 iteration 6561 : loss : 0.045990, loss_ce: 0.013511
2021-12-14 04:20:58,863 iteration 6562 : loss : 0.053887, loss_ce: 0.018465
 96%|███████████████████████████▉ | 386/400 [3:02:04<06:41, 28.70s/it]2021-12-14 04:21:00,478 iteration 6563 : loss : 0.047803, loss_ce: 0.019014
2021-12-14 04:21:02,087 iteration 6564 : loss : 0.053227, loss_ce: 0.017598
2021-12-14 04:21:03,571 iteration 6565 : loss : 0.052189, loss_ce: 0.013024
2021-12-14 04:21:05,197 iteration 6566 : loss : 0.050415, loss_ce: 0.016091
2021-12-14 04:21:06,736 iteration 6567 : loss : 0.065236, loss_ce: 0.015431
2021-12-14 04:21:08,260 iteration 6568 : loss : 0.039529, loss_ce: 0.012506
2021-12-14 04:21:09,742 iteration 6569 : loss : 0.044130, loss_ce: 0.012375
2021-12-14 04:21:11,397 iteration 6570 : loss : 0.052677, loss_ce: 0.020594
2021-12-14 04:21:12,810 iteration 6571 : loss : 0.042192, loss_ce: 0.015134
2021-12-14 04:21:14,287 iteration 6572 : loss : 0.043582, loss_ce: 0.012696
2021-12-14 04:21:15,728 iteration 6573 : loss : 0.047368, loss_ce: 0.016078
2021-12-14 04:21:17,246 iteration 6574 : loss : 0.048007, loss_ce: 0.017532
2021-12-14 04:21:18,637 iteration 6575 : loss : 0.039675, loss_ce: 0.014639
2021-12-14 04:21:20,172 iteration 6576 : loss : 0.049369, loss_ce: 0.017318
2021-12-14 04:21:21,740 iteration 6577 : loss : 0.049966, loss_ce: 0.015334
2021-12-14 04:21:23,290 iteration 6578 : loss : 0.048687, loss_ce: 0.017741
2021-12-14 04:21:24,800 iteration 6579 : loss : 0.046962, loss_ce: 0.011268
 97%|████████████████████████████ | 387/400 [3:02:30<06:02, 27.87s/it]2021-12-14 04:21:26,445 iteration 6580 : loss : 0.054822, loss_ce: 0.018589
2021-12-14 04:21:28,021 iteration 6581 : loss : 0.049790, loss_ce: 0.013535
2021-12-14 04:21:29,625 iteration 6582 : loss : 0.060123, loss_ce: 0.022695
2021-12-14 04:21:31,168 iteration 6583 : loss : 0.043257, loss_ce: 0.014378
2021-12-14 04:21:32,713 iteration 6584 : loss : 0.048106, loss_ce: 0.015413
2021-12-14 04:21:34,168 iteration 6585 : loss : 0.041613, loss_ce: 0.013147
2021-12-14 04:21:35,719 iteration 6586 : loss : 0.045417, loss_ce: 0.014878
2021-12-14 04:21:37,161 iteration 6587 : loss : 0.047525, loss_ce: 0.018978
2021-12-14 04:21:38,747 iteration 6588 : loss : 0.049603, loss_ce: 0.015762
2021-12-14 04:21:40,258 iteration 6589 : loss : 0.043180, loss_ce: 0.013454
2021-12-14 04:21:41,760 iteration 6590 : loss : 0.042123, loss_ce: 0.014915
2021-12-14 04:21:43,227 iteration 6591 : loss : 0.044563, loss_ce: 0.016488
2021-12-14 04:21:44,741 iteration 6592 : loss : 0.041639, loss_ce: 0.010834
2021-12-14 04:21:46,343 iteration 6593 : loss : 0.050459, loss_ce: 0.019721
2021-12-14 04:21:47,840 iteration 6594 : loss : 0.043153, loss_ce: 0.014843
2021-12-14 04:21:49,273 iteration 6595 : loss : 0.045012, loss_ce: 0.012063
2021-12-14 04:21:50,753 iteration 6596 : loss : 0.035902, loss_ce: 0.010921
 97%|████████████████████████████▏| 388/400 [3:02:56<05:27, 27.30s/it]2021-12-14 04:21:52,426 iteration 6597 : loss : 0.060326, loss_ce: 0.024961
2021-12-14 04:21:54,054 iteration 6598 : loss : 0.054547, loss_ce: 0.014377
2021-12-14 04:21:55,508 iteration 6599 : loss : 0.044771, loss_ce: 0.015390
2021-12-14 04:21:57,078 iteration 6600 : loss : 0.055342, loss_ce: 0.020112
2021-12-14 04:21:58,524 iteration 6601 : loss : 0.041045, loss_ce: 0.014550
2021-12-14 04:21:59,910 iteration 6602 : loss : 0.038666, loss_ce: 0.011438
2021-12-14 04:22:01,472 iteration 6603 : loss : 0.055229, loss_ce: 0.017644
2021-12-14 04:22:03,123 iteration 6604 : loss : 0.046268, loss_ce: 0.014752
2021-12-14 04:22:04,679 iteration 6605 : loss : 0.058899, loss_ce: 0.018380
2021-12-14 04:22:06,227 iteration 6606 : loss : 0.044541, loss_ce: 0.019617
2021-12-14 04:22:07,716 iteration 6607 : loss : 0.058773, loss_ce: 0.016974
2021-12-14 04:22:09,276 iteration 6608 : loss : 0.044692, loss_ce: 0.014758
2021-12-14 04:22:10,925 iteration 6609 : loss : 0.043410, loss_ce: 0.014787
2021-12-14 04:22:12,423 iteration 6610 : loss : 0.054233, loss_ce: 0.014655
2021-12-14 04:22:13,817 iteration 6611 : loss : 0.042492, loss_ce: 0.015641
2021-12-14 04:22:15,342 iteration 6612 : loss : 0.048307, loss_ce: 0.016591
2021-12-14 04:22:16,927 iteration 6613 : loss : 0.059921, loss_ce: 0.015583
 97%|████████████████████████████▏| 389/400 [3:03:22<04:56, 26.96s/it]2021-12-14 04:22:18,367 iteration 6614 : loss : 0.040912, loss_ce: 0.013637
2021-12-14 04:22:19,912 iteration 6615 : loss : 0.051320, loss_ce: 0.017936
2021-12-14 04:22:21,473 iteration 6616 : loss : 0.041760, loss_ce: 0.014515
2021-12-14 04:22:22,950 iteration 6617 : loss : 0.050948, loss_ce: 0.011277
2021-12-14 04:22:24,478 iteration 6618 : loss : 0.043577, loss_ce: 0.011786
2021-12-14 04:22:26,056 iteration 6619 : loss : 0.047585, loss_ce: 0.014376
2021-12-14 04:22:27,582 iteration 6620 : loss : 0.047552, loss_ce: 0.013526
2021-12-14 04:22:29,010 iteration 6621 : loss : 0.045535, loss_ce: 0.017027
2021-12-14 04:22:30,372 iteration 6622 : loss : 0.036377, loss_ce: 0.010849
2021-12-14 04:22:31,896 iteration 6623 : loss : 0.050989, loss_ce: 0.022245
2021-12-14 04:22:33,260 iteration 6624 : loss : 0.039198, loss_ce: 0.012681
2021-12-14 04:22:34,628 iteration 6625 : loss : 0.038155, loss_ce: 0.013135
2021-12-14 04:22:36,141 iteration 6626 : loss : 0.042499, loss_ce: 0.015066
2021-12-14 04:22:37,576 iteration 6627 : loss : 0.041626, loss_ce: 0.013422
2021-12-14 04:22:39,125 iteration 6628 : loss : 0.046885, loss_ce: 0.016363
2021-12-14 04:22:40,584 iteration 6629 : loss : 0.041639, loss_ce: 0.013429
2021-12-14 04:22:40,585 Training Data Eval:
2021-12-14 04:22:48,023   Average segmentation loss on training set: 0.0355
2021-12-14 04:22:48,023 Validation Data Eval:
2021-12-14 04:22:50,588   Average segmentation loss on validation set: 0.0863
2021-12-14 04:22:52,104 iteration 6630 : loss : 0.056833, loss_ce: 0.021464
 98%|████████████████████████████▎| 390/400 [3:03:57<04:54, 29.42s/it]2021-12-14 04:22:53,559 iteration 6631 : loss : 0.040837, loss_ce: 0.014274
2021-12-14 04:22:55,116 iteration 6632 : loss : 0.052996, loss_ce: 0.011576
2021-12-14 04:22:56,602 iteration 6633 : loss : 0.041383, loss_ce: 0.012342
2021-12-14 04:22:58,052 iteration 6634 : loss : 0.044740, loss_ce: 0.015078
2021-12-14 04:22:59,627 iteration 6635 : loss : 0.037323, loss_ce: 0.011922
2021-12-14 04:23:01,093 iteration 6636 : loss : 0.042469, loss_ce: 0.018126
2021-12-14 04:23:02,631 iteration 6637 : loss : 0.040415, loss_ce: 0.011617
2021-12-14 04:23:04,170 iteration 6638 : loss : 0.038615, loss_ce: 0.011235
2021-12-14 04:23:05,713 iteration 6639 : loss : 0.057306, loss_ce: 0.020430
2021-12-14 04:23:07,277 iteration 6640 : loss : 0.074832, loss_ce: 0.019659
2021-12-14 04:23:08,765 iteration 6641 : loss : 0.046311, loss_ce: 0.016130
2021-12-14 04:23:10,288 iteration 6642 : loss : 0.042104, loss_ce: 0.012592
2021-12-14 04:23:11,915 iteration 6643 : loss : 0.046984, loss_ce: 0.017009
2021-12-14 04:23:13,539 iteration 6644 : loss : 0.050546, loss_ce: 0.019246
2021-12-14 04:23:15,056 iteration 6645 : loss : 0.051677, loss_ce: 0.020184
2021-12-14 04:23:16,583 iteration 6646 : loss : 0.048004, loss_ce: 0.019549
2021-12-14 04:23:18,104 iteration 6647 : loss : 0.067810, loss_ce: 0.014328
 98%|████████████████████████████▎| 391/400 [3:04:23<04:15, 28.39s/it]2021-12-14 04:23:19,716 iteration 6648 : loss : 0.062281, loss_ce: 0.020825
2021-12-14 04:23:21,294 iteration 6649 : loss : 0.043142, loss_ce: 0.010497
2021-12-14 04:23:22,749 iteration 6650 : loss : 0.039455, loss_ce: 0.013467
2021-12-14 04:23:24,230 iteration 6651 : loss : 0.045918, loss_ce: 0.016946
2021-12-14 04:23:25,788 iteration 6652 : loss : 0.045839, loss_ce: 0.014308
2021-12-14 04:23:27,396 iteration 6653 : loss : 0.048099, loss_ce: 0.014295
2021-12-14 04:23:29,104 iteration 6654 : loss : 0.064643, loss_ce: 0.023864
2021-12-14 04:23:30,595 iteration 6655 : loss : 0.042181, loss_ce: 0.013827
2021-12-14 04:23:32,230 iteration 6656 : loss : 0.055899, loss_ce: 0.018771
2021-12-14 04:23:33,792 iteration 6657 : loss : 0.049070, loss_ce: 0.014375
2021-12-14 04:23:35,409 iteration 6658 : loss : 0.049612, loss_ce: 0.016233
2021-12-14 04:23:36,937 iteration 6659 : loss : 0.049125, loss_ce: 0.013708
2021-12-14 04:23:38,456 iteration 6660 : loss : 0.042991, loss_ce: 0.016054
2021-12-14 04:23:39,921 iteration 6661 : loss : 0.040826, loss_ce: 0.012709
2021-12-14 04:23:41,476 iteration 6662 : loss : 0.051738, loss_ce: 0.016815
2021-12-14 04:23:42,950 iteration 6663 : loss : 0.042429, loss_ce: 0.014779
2021-12-14 04:23:44,527 iteration 6664 : loss : 0.041228, loss_ce: 0.014250
 98%|████████████████████████████▍| 392/400 [3:04:49<03:42, 27.81s/it]2021-12-14 04:23:46,143 iteration 6665 : loss : 0.067586, loss_ce: 0.020587
2021-12-14 04:23:47,717 iteration 6666 : loss : 0.037170, loss_ce: 0.011142
2021-12-14 04:23:49,236 iteration 6667 : loss : 0.047116, loss_ce: 0.017377
2021-12-14 04:23:50,942 iteration 6668 : loss : 0.050531, loss_ce: 0.021484
2021-12-14 04:23:52,397 iteration 6669 : loss : 0.047561, loss_ce: 0.015667
2021-12-14 04:23:53,854 iteration 6670 : loss : 0.043057, loss_ce: 0.015181
2021-12-14 04:23:55,339 iteration 6671 : loss : 0.043078, loss_ce: 0.014008
2021-12-14 04:23:56,762 iteration 6672 : loss : 0.037195, loss_ce: 0.009240
2021-12-14 04:23:58,330 iteration 6673 : loss : 0.051349, loss_ce: 0.016094
2021-12-14 04:23:59,842 iteration 6674 : loss : 0.040815, loss_ce: 0.014166
2021-12-14 04:24:01,435 iteration 6675 : loss : 0.043942, loss_ce: 0.012533
2021-12-14 04:24:02,873 iteration 6676 : loss : 0.040455, loss_ce: 0.011263
2021-12-14 04:24:04,362 iteration 6677 : loss : 0.043000, loss_ce: 0.011091
2021-12-14 04:24:05,732 iteration 6678 : loss : 0.041953, loss_ce: 0.015099
2021-12-14 04:24:07,405 iteration 6679 : loss : 0.043667, loss_ce: 0.015399
2021-12-14 04:24:08,934 iteration 6680 : loss : 0.044248, loss_ce: 0.014604
2021-12-14 04:24:10,522 iteration 6681 : loss : 0.039546, loss_ce: 0.014016
 98%|████████████████████████████▍| 393/400 [3:05:15<03:10, 27.26s/it]2021-12-14 04:24:12,132 iteration 6682 : loss : 0.041168, loss_ce: 0.015827
2021-12-14 04:24:13,776 iteration 6683 : loss : 0.041167, loss_ce: 0.011692
2021-12-14 04:24:15,230 iteration 6684 : loss : 0.040149, loss_ce: 0.012153
2021-12-14 04:24:16,830 iteration 6685 : loss : 0.050838, loss_ce: 0.019218
2021-12-14 04:24:18,289 iteration 6686 : loss : 0.048864, loss_ce: 0.020351
2021-12-14 04:24:19,788 iteration 6687 : loss : 0.071449, loss_ce: 0.015718
2021-12-14 04:24:21,372 iteration 6688 : loss : 0.053228, loss_ce: 0.018915
2021-12-14 04:24:22,862 iteration 6689 : loss : 0.046045, loss_ce: 0.013239
2021-12-14 04:24:24,337 iteration 6690 : loss : 0.050270, loss_ce: 0.017350
2021-12-14 04:24:25,929 iteration 6691 : loss : 0.050731, loss_ce: 0.017706
2021-12-14 04:24:27,492 iteration 6692 : loss : 0.055418, loss_ce: 0.016445
2021-12-14 04:24:29,096 iteration 6693 : loss : 0.042471, loss_ce: 0.012232
2021-12-14 04:24:30,651 iteration 6694 : loss : 0.057829, loss_ce: 0.021100
2021-12-14 04:24:32,248 iteration 6695 : loss : 0.045385, loss_ce: 0.017077
2021-12-14 04:24:33,713 iteration 6696 : loss : 0.045097, loss_ce: 0.019329
2021-12-14 04:24:35,312 iteration 6697 : loss : 0.046942, loss_ce: 0.013861
2021-12-14 04:24:36,834 iteration 6698 : loss : 0.042690, loss_ce: 0.013193
 98%|████████████████████████████▌| 394/400 [3:05:42<02:41, 26.98s/it]2021-12-14 04:24:38,371 iteration 6699 : loss : 0.042013, loss_ce: 0.019127
2021-12-14 04:24:40,003 iteration 6700 : loss : 0.054775, loss_ce: 0.024760
2021-12-14 04:24:41,514 iteration 6701 : loss : 0.044861, loss_ce: 0.015820
2021-12-14 04:24:42,981 iteration 6702 : loss : 0.066526, loss_ce: 0.020521
2021-12-14 04:24:44,490 iteration 6703 : loss : 0.042512, loss_ce: 0.011617
2021-12-14 04:24:46,064 iteration 6704 : loss : 0.046101, loss_ce: 0.013298
2021-12-14 04:24:47,530 iteration 6705 : loss : 0.057849, loss_ce: 0.016751
2021-12-14 04:24:48,983 iteration 6706 : loss : 0.039669, loss_ce: 0.014902
2021-12-14 04:24:50,463 iteration 6707 : loss : 0.047810, loss_ce: 0.012824
2021-12-14 04:24:51,874 iteration 6708 : loss : 0.041457, loss_ce: 0.014003
2021-12-14 04:24:53,322 iteration 6709 : loss : 0.036239, loss_ce: 0.009455
2021-12-14 04:24:54,798 iteration 6710 : loss : 0.045491, loss_ce: 0.013881
2021-12-14 04:24:56,257 iteration 6711 : loss : 0.062120, loss_ce: 0.013262
2021-12-14 04:24:57,802 iteration 6712 : loss : 0.058696, loss_ce: 0.020057
2021-12-14 04:24:59,423 iteration 6713 : loss : 0.043446, loss_ce: 0.014378
2021-12-14 04:25:00,974 iteration 6714 : loss : 0.049759, loss_ce: 0.020580
2021-12-14 04:25:00,975 Training Data Eval:
2021-12-14 04:25:08,407   Average segmentation loss on training set: 0.0350
2021-12-14 04:25:08,407 Validation Data Eval:
2021-12-14 04:25:10,973   Average segmentation loss on validation set: 0.0884
2021-12-14 04:25:12,547 iteration 6715 : loss : 0.040342, loss_ce: 0.011546
 99%|████████████████████████████▋| 395/400 [3:06:17<02:27, 29.59s/it]2021-12-14 04:25:14,126 iteration 6716 : loss : 0.037460, loss_ce: 0.012790
2021-12-14 04:25:15,661 iteration 6717 : loss : 0.051097, loss_ce: 0.016965
2021-12-14 04:25:17,092 iteration 6718 : loss : 0.036564, loss_ce: 0.010642
2021-12-14 04:25:18,578 iteration 6719 : loss : 0.042024, loss_ce: 0.011937
2021-12-14 04:25:20,084 iteration 6720 : loss : 0.041503, loss_ce: 0.013759
2021-12-14 04:25:21,655 iteration 6721 : loss : 0.049529, loss_ce: 0.016285
2021-12-14 04:25:23,235 iteration 6722 : loss : 0.054990, loss_ce: 0.015435
2021-12-14 04:25:24,742 iteration 6723 : loss : 0.044153, loss_ce: 0.011299
2021-12-14 04:25:26,218 iteration 6724 : loss : 0.042755, loss_ce: 0.015211
2021-12-14 04:25:27,781 iteration 6725 : loss : 0.043302, loss_ce: 0.013789
2021-12-14 04:25:29,301 iteration 6726 : loss : 0.046204, loss_ce: 0.013789
2021-12-14 04:25:30,870 iteration 6727 : loss : 0.045959, loss_ce: 0.017134
2021-12-14 04:25:32,440 iteration 6728 : loss : 0.045489, loss_ce: 0.018824
2021-12-14 04:25:33,882 iteration 6729 : loss : 0.039891, loss_ce: 0.010473
2021-12-14 04:25:35,359 iteration 6730 : loss : 0.039720, loss_ce: 0.011818
2021-12-14 04:25:36,839 iteration 6731 : loss : 0.045039, loss_ce: 0.015938
2021-12-14 04:25:38,361 iteration 6732 : loss : 0.047964, loss_ce: 0.022213
 99%|████████████████████████████▋| 396/400 [3:06:43<01:53, 28.46s/it]2021-12-14 04:25:39,996 iteration 6733 : loss : 0.047878, loss_ce: 0.018311
2021-12-14 04:25:41,463 iteration 6734 : loss : 0.042541, loss_ce: 0.010525
2021-12-14 04:25:42,994 iteration 6735 : loss : 0.044429, loss_ce: 0.018432
2021-12-14 04:25:44,503 iteration 6736 : loss : 0.054171, loss_ce: 0.015814
2021-12-14 04:25:45,970 iteration 6737 : loss : 0.043482, loss_ce: 0.016942
2021-12-14 04:25:47,467 iteration 6738 : loss : 0.041961, loss_ce: 0.013462
2021-12-14 04:25:49,025 iteration 6739 : loss : 0.052122, loss_ce: 0.019819
2021-12-14 04:25:50,651 iteration 6740 : loss : 0.054871, loss_ce: 0.018818
2021-12-14 04:25:52,090 iteration 6741 : loss : 0.037303, loss_ce: 0.013197
2021-12-14 04:25:53,677 iteration 6742 : loss : 0.046886, loss_ce: 0.018674
2021-12-14 04:25:55,228 iteration 6743 : loss : 0.051873, loss_ce: 0.015077
2021-12-14 04:25:56,857 iteration 6744 : loss : 0.039445, loss_ce: 0.011905
2021-12-14 04:25:58,350 iteration 6745 : loss : 0.058208, loss_ce: 0.015743
2021-12-14 04:25:59,839 iteration 6746 : loss : 0.056144, loss_ce: 0.021077
2021-12-14 04:26:01,343 iteration 6747 : loss : 0.045546, loss_ce: 0.014853
2021-12-14 04:26:02,881 iteration 6748 : loss : 0.040802, loss_ce: 0.013989
2021-12-14 04:26:04,445 iteration 6749 : loss : 0.042146, loss_ce: 0.013145
 99%|████████████████████████████▊| 397/400 [3:07:09<01:23, 27.75s/it]2021-12-14 04:26:06,002 iteration 6750 : loss : 0.041179, loss_ce: 0.013508
2021-12-14 04:26:07,574 iteration 6751 : loss : 0.052750, loss_ce: 0.021869
2021-12-14 04:26:09,144 iteration 6752 : loss : 0.068485, loss_ce: 0.033782
2021-12-14 04:26:10,685 iteration 6753 : loss : 0.045829, loss_ce: 0.015013
2021-12-14 04:26:12,282 iteration 6754 : loss : 0.049257, loss_ce: 0.012843
2021-12-14 04:26:13,810 iteration 6755 : loss : 0.036278, loss_ce: 0.009370
2021-12-14 04:26:15,351 iteration 6756 : loss : 0.046740, loss_ce: 0.015941
2021-12-14 04:26:16,884 iteration 6757 : loss : 0.051306, loss_ce: 0.018742
2021-12-14 04:26:18,339 iteration 6758 : loss : 0.040743, loss_ce: 0.015621
2021-12-14 04:26:19,917 iteration 6759 : loss : 0.049018, loss_ce: 0.016223
2021-12-14 04:26:21,417 iteration 6760 : loss : 0.047096, loss_ce: 0.016583
2021-12-14 04:26:22,981 iteration 6761 : loss : 0.043888, loss_ce: 0.015144
2021-12-14 04:26:24,375 iteration 6762 : loss : 0.040251, loss_ce: 0.013600
2021-12-14 04:26:25,894 iteration 6763 : loss : 0.049919, loss_ce: 0.012385
2021-12-14 04:26:27,389 iteration 6764 : loss : 0.044335, loss_ce: 0.013856
2021-12-14 04:26:28,845 iteration 6765 : loss : 0.042094, loss_ce: 0.011634
2021-12-14 04:26:30,336 iteration 6766 : loss : 0.066742, loss_ce: 0.023459
100%|████████████████████████████▊| 398/400 [3:07:35<00:54, 27.19s/it]2021-12-14 04:26:32,087 iteration 6767 : loss : 0.048116, loss_ce: 0.015249
2021-12-14 04:26:33,520 iteration 6768 : loss : 0.047360, loss_ce: 0.018453
2021-12-14 04:26:35,046 iteration 6769 : loss : 0.042071, loss_ce: 0.010334
2021-12-14 04:26:36,480 iteration 6770 : loss : 0.036753, loss_ce: 0.013052
2021-12-14 04:26:37,980 iteration 6771 : loss : 0.040404, loss_ce: 0.011178
2021-12-14 04:26:39,588 iteration 6772 : loss : 0.064611, loss_ce: 0.015456
2021-12-14 04:26:41,141 iteration 6773 : loss : 0.044735, loss_ce: 0.016662
2021-12-14 04:26:42,658 iteration 6774 : loss : 0.052833, loss_ce: 0.020735
2021-12-14 04:26:44,160 iteration 6775 : loss : 0.049475, loss_ce: 0.015075
2021-12-14 04:26:45,751 iteration 6776 : loss : 0.054480, loss_ce: 0.020815
2021-12-14 04:26:47,269 iteration 6777 : loss : 0.042225, loss_ce: 0.014214
2021-12-14 04:26:48,739 iteration 6778 : loss : 0.044366, loss_ce: 0.012068
2021-12-14 04:26:50,233 iteration 6779 : loss : 0.039584, loss_ce: 0.011005
2021-12-14 04:26:51,657 iteration 6780 : loss : 0.037897, loss_ce: 0.010815
2021-12-14 04:26:53,105 iteration 6781 : loss : 0.047299, loss_ce: 0.019062
2021-12-14 04:26:54,613 iteration 6782 : loss : 0.038058, loss_ce: 0.014274
2021-12-14 04:26:56,137 iteration 6783 : loss : 0.043408, loss_ce: 0.013768
100%|████████████████████████████▉| 399/400 [3:08:01<00:26, 26.78s/it]2021-12-14 04:26:57,838 iteration 6784 : loss : 0.054828, loss_ce: 0.015845
2021-12-14 04:26:59,265 iteration 6785 : loss : 0.051654, loss_ce: 0.021134
2021-12-14 04:27:00,649 iteration 6786 : loss : 0.042075, loss_ce: 0.014353
2021-12-14 04:27:02,185 iteration 6787 : loss : 0.054441, loss_ce: 0.017784
2021-12-14 04:27:03,600 iteration 6788 : loss : 0.060031, loss_ce: 0.014876
2021-12-14 04:27:05,137 iteration 6789 : loss : 0.038686, loss_ce: 0.013735
2021-12-14 04:27:06,686 iteration 6790 : loss : 0.039934, loss_ce: 0.012124
2021-12-14 04:27:08,272 iteration 6791 : loss : 0.053657, loss_ce: 0.015572
2021-12-14 04:27:09,845 iteration 6792 : loss : 0.043762, loss_ce: 0.014747
2021-12-14 04:27:11,362 iteration 6793 : loss : 0.047155, loss_ce: 0.014902
2021-12-14 04:27:12,899 iteration 6794 : loss : 0.041603, loss_ce: 0.013883
2021-12-14 04:27:14,396 iteration 6795 : loss : 0.041509, loss_ce: 0.012563
2021-12-14 04:27:15,913 iteration 6796 : loss : 0.040149, loss_ce: 0.012998
2021-12-14 04:27:17,366 iteration 6797 : loss : 0.050914, loss_ce: 0.015831
2021-12-14 04:27:18,776 iteration 6798 : loss : 0.044984, loss_ce: 0.015380
2021-12-14 04:27:20,293 iteration 6799 : loss : 0.050821, loss_ce: 0.019214
2021-12-14 04:27:20,293 Training Data Eval:
2021-12-14 04:27:27,716   Average segmentation loss on training set: 0.0351
2021-12-14 04:27:27,717 Validation Data Eval:
2021-12-14 04:27:30,282   Average segmentation loss on validation set: 0.0844
2021-12-14 04:27:31,780 iteration 6800 : loss : 0.047016, loss_ce: 0.017964
100%|█████████████████████████████| 400/400 [3:08:37<00:00, 29.44s/it]100%|█████████████████████████████| 400/400 [3:08:37<00:00, 28.29s/it]
