2021-12-10 10:15:48,518 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-10 10:15:48,519 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-10 10:15:48,519 ============================================================
2021-12-10 10:15:48,519 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-10 10:15:48,519 ============================================================
2021-12-10 10:15:48,519 Loading data...
2021-12-10 10:15:48,519 Reading NCI - RUNMC images...
2021-12-10 10:15:48,519 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-10 10:15:48,522 Already preprocessed this configuration. Loading now!
2021-12-10 10:15:48,543 Training Images: (256, 256, 286)
2021-12-10 10:15:48,544 Training Labels: (256, 256, 286)
2021-12-10 10:15:48,544 Validation Images: (256, 256, 98)
2021-12-10 10:15:48,544 Validation Labels: (256, 256, 98)
2021-12-10 10:15:48,544 ============================================================
2021-12-10 10:15:48,575 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-10 10:15:51,428 iteration 1 : loss : 0.902121, loss_ce: 1.072191
2021-12-10 10:15:52,874 iteration 2 : loss : 0.848945, loss_ce: 0.983815
2021-12-10 10:15:54,428 iteration 3 : loss : 0.792486, loss_ce: 0.889101
2021-12-10 10:15:55,895 iteration 4 : loss : 0.739587, loss_ce: 0.799797
2021-12-10 10:15:57,364 iteration 5 : loss : 0.687877, loss_ce: 0.729071
2021-12-10 10:15:58,848 iteration 6 : loss : 0.645884, loss_ce: 0.651259
2021-12-10 10:16:00,383 iteration 7 : loss : 0.610173, loss_ce: 0.603645
2021-12-10 10:16:01,878 iteration 8 : loss : 0.586407, loss_ce: 0.540477
2021-12-10 10:16:03,393 iteration 9 : loss : 0.548571, loss_ce: 0.536546
2021-12-10 10:16:04,935 iteration 10 : loss : 0.532529, loss_ce: 0.454587
2021-12-10 10:16:06,534 iteration 11 : loss : 0.492825, loss_ce: 0.429760
2021-12-10 10:16:08,021 iteration 12 : loss : 0.471869, loss_ce: 0.390369
2021-12-10 10:16:09,490 iteration 13 : loss : 0.468143, loss_ce: 0.367342
2021-12-10 10:16:10,933 iteration 14 : loss : 0.449263, loss_ce: 0.344603
2021-12-10 10:16:12,445 iteration 15 : loss : 0.405093, loss_ce: 0.303176
2021-12-10 10:16:13,944 iteration 16 : loss : 0.417983, loss_ce: 0.294427
2021-12-10 10:16:15,437 iteration 17 : loss : 0.366497, loss_ce: 0.263559
  0%|                               | 1/400 [00:26<2:59:12, 26.95s/it]2021-12-10 10:16:17,051 iteration 18 : loss : 0.400511, loss_ce: 0.241458
2021-12-10 10:16:18,487 iteration 19 : loss : 0.337167, loss_ce: 0.213371
2021-12-10 10:16:20,050 iteration 20 : loss : 0.329841, loss_ce: 0.195432
2021-12-10 10:16:21,525 iteration 21 : loss : 0.362814, loss_ce: 0.190054
2021-12-10 10:16:23,019 iteration 22 : loss : 0.316653, loss_ce: 0.192018
2021-12-10 10:16:24,588 iteration 23 : loss : 0.325740, loss_ce: 0.166497
2021-12-10 10:16:26,083 iteration 24 : loss : 0.311728, loss_ce: 0.170779
2021-12-10 10:16:27,634 iteration 25 : loss : 0.375662, loss_ce: 0.222930
2021-12-10 10:16:29,113 iteration 26 : loss : 0.289553, loss_ce: 0.145803
2021-12-10 10:16:30,540 iteration 27 : loss : 0.286871, loss_ce: 0.150764
2021-12-10 10:16:31,981 iteration 28 : loss : 0.284702, loss_ce: 0.140838
2021-12-10 10:16:33,515 iteration 29 : loss : 0.287249, loss_ce: 0.139453
2021-12-10 10:16:35,040 iteration 30 : loss : 0.277375, loss_ce: 0.139637
2021-12-10 10:16:36,485 iteration 31 : loss : 0.267019, loss_ce: 0.133791
2021-12-10 10:16:38,038 iteration 32 : loss : 0.282932, loss_ce: 0.153578
2021-12-10 10:16:39,574 iteration 33 : loss : 0.280380, loss_ce: 0.156677
2021-12-10 10:16:41,108 iteration 34 : loss : 0.284187, loss_ce: 0.158201
  0%|▏                              | 2/400 [00:52<2:53:40, 26.18s/it]2021-12-10 10:16:42,697 iteration 35 : loss : 0.256784, loss_ce: 0.119751
2021-12-10 10:16:44,252 iteration 36 : loss : 0.283573, loss_ce: 0.146814
2021-12-10 10:16:45,812 iteration 37 : loss : 0.283014, loss_ce: 0.127699
2021-12-10 10:16:47,290 iteration 38 : loss : 0.264059, loss_ce: 0.129884
2021-12-10 10:16:48,780 iteration 39 : loss : 0.237643, loss_ce: 0.110843
2021-12-10 10:16:50,343 iteration 40 : loss : 0.263559, loss_ce: 0.126316
2021-12-10 10:16:51,896 iteration 41 : loss : 0.334088, loss_ce: 0.163152
2021-12-10 10:16:53,429 iteration 42 : loss : 0.257360, loss_ce: 0.123805
2021-12-10 10:16:54,875 iteration 43 : loss : 0.260091, loss_ce: 0.119590
2021-12-10 10:16:56,457 iteration 44 : loss : 0.222719, loss_ce: 0.106398
2021-12-10 10:16:57,969 iteration 45 : loss : 0.239822, loss_ce: 0.113367
2021-12-10 10:16:59,492 iteration 46 : loss : 0.251085, loss_ce: 0.103496
2021-12-10 10:17:01,052 iteration 47 : loss : 0.200807, loss_ce: 0.077202
2021-12-10 10:17:02,583 iteration 48 : loss : 0.221858, loss_ce: 0.095758
2021-12-10 10:17:04,157 iteration 49 : loss : 0.312911, loss_ce: 0.150204
2021-12-10 10:17:05,636 iteration 50 : loss : 0.307963, loss_ce: 0.137211
2021-12-10 10:17:07,097 iteration 51 : loss : 0.250680, loss_ce: 0.118405
  1%|▏                              | 3/400 [01:18<2:52:38, 26.09s/it]2021-12-10 10:17:08,717 iteration 52 : loss : 0.297480, loss_ce: 0.151215
2021-12-10 10:17:10,261 iteration 53 : loss : 0.258408, loss_ce: 0.123129
2021-12-10 10:17:11,777 iteration 54 : loss : 0.256382, loss_ce: 0.116450
2021-12-10 10:17:13,307 iteration 55 : loss : 0.309558, loss_ce: 0.161680
2021-12-10 10:17:14,832 iteration 56 : loss : 0.264426, loss_ce: 0.118967
2021-12-10 10:17:16,368 iteration 57 : loss : 0.233046, loss_ce: 0.098885
2021-12-10 10:17:17,906 iteration 58 : loss : 0.294551, loss_ce: 0.122154
2021-12-10 10:17:19,411 iteration 59 : loss : 0.233820, loss_ce: 0.108100
2021-12-10 10:17:20,948 iteration 60 : loss : 0.281402, loss_ce: 0.115609
2021-12-10 10:17:22,478 iteration 61 : loss : 0.255327, loss_ce: 0.124169
2021-12-10 10:17:23,995 iteration 62 : loss : 0.341580, loss_ce: 0.131313
2021-12-10 10:17:25,439 iteration 63 : loss : 0.305704, loss_ce: 0.153683
2021-12-10 10:17:26,940 iteration 64 : loss : 0.309822, loss_ce: 0.140723
2021-12-10 10:17:28,401 iteration 65 : loss : 0.262312, loss_ce: 0.101432
2021-12-10 10:17:29,899 iteration 66 : loss : 0.217110, loss_ce: 0.089386
2021-12-10 10:17:31,469 iteration 67 : loss : 0.264799, loss_ce: 0.094715
2021-12-10 10:17:32,982 iteration 68 : loss : 0.255431, loss_ce: 0.111047
  1%|▎                              | 4/400 [01:44<2:51:39, 26.01s/it]2021-12-10 10:17:34,576 iteration 69 : loss : 0.231290, loss_ce: 0.097468
2021-12-10 10:17:36,172 iteration 70 : loss : 0.229245, loss_ce: 0.093510
2021-12-10 10:17:37,662 iteration 71 : loss : 0.240962, loss_ce: 0.104578
2021-12-10 10:17:39,184 iteration 72 : loss : 0.236463, loss_ce: 0.099255
2021-12-10 10:17:40,660 iteration 73 : loss : 0.245928, loss_ce: 0.116657
2021-12-10 10:17:42,107 iteration 74 : loss : 0.226251, loss_ce: 0.095365
2021-12-10 10:17:43,583 iteration 75 : loss : 0.220683, loss_ce: 0.094465
2021-12-10 10:17:45,055 iteration 76 : loss : 0.240538, loss_ce: 0.103073
2021-12-10 10:17:46,452 iteration 77 : loss : 0.218332, loss_ce: 0.094888
2021-12-10 10:17:47,947 iteration 78 : loss : 0.259258, loss_ce: 0.111725
2021-12-10 10:17:49,414 iteration 79 : loss : 0.260843, loss_ce: 0.095245
2021-12-10 10:17:50,870 iteration 80 : loss : 0.226055, loss_ce: 0.094588
2021-12-10 10:17:52,320 iteration 81 : loss : 0.236378, loss_ce: 0.094587
2021-12-10 10:17:53,794 iteration 82 : loss : 0.230607, loss_ce: 0.088511
2021-12-10 10:17:55,261 iteration 83 : loss : 0.254692, loss_ce: 0.093689
2021-12-10 10:17:56,821 iteration 84 : loss : 0.247289, loss_ce: 0.130740
2021-12-10 10:17:56,821 Training Data Eval:
2021-12-10 10:18:04,364   Average segmentation loss on training set: 0.6490
2021-12-10 10:18:04,364 Validation Data Eval:
2021-12-10 10:18:07,119   Average segmentation loss on validation set: 0.6157
2021-12-10 10:18:12,821 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:18:14,342 iteration 85 : loss : 0.274494, loss_ce: 0.114428
  1%|▍                              | 5/400 [02:25<3:27:38, 31.54s/it]2021-12-10 10:18:15,895 iteration 86 : loss : 0.288764, loss_ce: 0.109897
2021-12-10 10:18:17,517 iteration 87 : loss : 0.233651, loss_ce: 0.101154
2021-12-10 10:18:18,974 iteration 88 : loss : 0.239889, loss_ce: 0.103165
2021-12-10 10:18:20,505 iteration 89 : loss : 0.276691, loss_ce: 0.115551
2021-12-10 10:18:22,026 iteration 90 : loss : 0.230846, loss_ce: 0.088087
2021-12-10 10:18:23,606 iteration 91 : loss : 0.225327, loss_ce: 0.101389
2021-12-10 10:18:25,052 iteration 92 : loss : 0.224823, loss_ce: 0.094767
2021-12-10 10:18:26,543 iteration 93 : loss : 0.244557, loss_ce: 0.091459
2021-12-10 10:18:28,037 iteration 94 : loss : 0.246909, loss_ce: 0.099639
2021-12-10 10:18:29,654 iteration 95 : loss : 0.229535, loss_ce: 0.098589
2021-12-10 10:18:31,137 iteration 96 : loss : 0.229271, loss_ce: 0.100507
2021-12-10 10:18:32,621 iteration 97 : loss : 0.247934, loss_ce: 0.101874
2021-12-10 10:18:34,120 iteration 98 : loss : 0.248305, loss_ce: 0.105915
2021-12-10 10:18:35,698 iteration 99 : loss : 0.233557, loss_ce: 0.098438
2021-12-10 10:18:37,223 iteration 100 : loss : 0.230241, loss_ce: 0.091484
2021-12-10 10:18:38,728 iteration 101 : loss : 0.160742, loss_ce: 0.058023
2021-12-10 10:18:40,169 iteration 102 : loss : 0.220708, loss_ce: 0.081194
  2%|▍                              | 6/400 [02:51<3:14:24, 29.60s/it]2021-12-10 10:18:41,822 iteration 103 : loss : 0.243644, loss_ce: 0.097608
2021-12-10 10:18:43,399 iteration 104 : loss : 0.215056, loss_ce: 0.079738
2021-12-10 10:18:45,033 iteration 105 : loss : 0.261632, loss_ce: 0.105214
2021-12-10 10:18:46,507 iteration 106 : loss : 0.244086, loss_ce: 0.101748
2021-12-10 10:18:48,158 iteration 107 : loss : 0.224378, loss_ce: 0.101530
2021-12-10 10:18:49,611 iteration 108 : loss : 0.291931, loss_ce: 0.128761
2021-12-10 10:18:51,094 iteration 109 : loss : 0.227638, loss_ce: 0.105524
2021-12-10 10:18:52,528 iteration 110 : loss : 0.201294, loss_ce: 0.084413
2021-12-10 10:18:54,053 iteration 111 : loss : 0.260618, loss_ce: 0.122747
2021-12-10 10:18:55,496 iteration 112 : loss : 0.208303, loss_ce: 0.080936
2021-12-10 10:18:57,004 iteration 113 : loss : 0.284650, loss_ce: 0.145335
2021-12-10 10:18:58,480 iteration 114 : loss : 0.257362, loss_ce: 0.087755
2021-12-10 10:18:59,976 iteration 115 : loss : 0.210301, loss_ce: 0.084691
2021-12-10 10:19:01,524 iteration 116 : loss : 0.294545, loss_ce: 0.127487
2021-12-10 10:19:03,072 iteration 117 : loss : 0.223320, loss_ce: 0.091685
2021-12-10 10:19:04,587 iteration 118 : loss : 0.286739, loss_ce: 0.130455
2021-12-10 10:19:06,114 iteration 119 : loss : 0.209689, loss_ce: 0.086309
  2%|▌                              | 7/400 [03:17<3:06:04, 28.41s/it]2021-12-10 10:19:07,645 iteration 120 : loss : 0.301051, loss_ce: 0.131771
2021-12-10 10:19:09,095 iteration 121 : loss : 0.236938, loss_ce: 0.103675
2021-12-10 10:19:10,651 iteration 122 : loss : 0.278086, loss_ce: 0.119131
2021-12-10 10:19:12,174 iteration 123 : loss : 0.223866, loss_ce: 0.094918
2021-12-10 10:19:13,670 iteration 124 : loss : 0.236785, loss_ce: 0.091251
2021-12-10 10:19:15,130 iteration 125 : loss : 0.227549, loss_ce: 0.104794
2021-12-10 10:19:16,652 iteration 126 : loss : 0.232580, loss_ce: 0.083826
2021-12-10 10:19:18,104 iteration 127 : loss : 0.221666, loss_ce: 0.092364
2021-12-10 10:19:19,581 iteration 128 : loss : 0.213321, loss_ce: 0.086075
2021-12-10 10:19:21,130 iteration 129 : loss : 0.226775, loss_ce: 0.083396
2021-12-10 10:19:22,622 iteration 130 : loss : 0.224079, loss_ce: 0.085922
2021-12-10 10:19:24,207 iteration 131 : loss : 0.242165, loss_ce: 0.110099
2021-12-10 10:19:25,815 iteration 132 : loss : 0.199728, loss_ce: 0.058616
2021-12-10 10:19:27,298 iteration 133 : loss : 0.217529, loss_ce: 0.079117
2021-12-10 10:19:28,873 iteration 134 : loss : 0.243002, loss_ce: 0.102879
2021-12-10 10:19:30,460 iteration 135 : loss : 0.243702, loss_ce: 0.110792
2021-12-10 10:19:31,961 iteration 136 : loss : 0.191688, loss_ce: 0.083787
  2%|▌                              | 8/400 [03:43<3:00:14, 27.59s/it]2021-12-10 10:19:33,584 iteration 137 : loss : 0.233989, loss_ce: 0.085871
2021-12-10 10:19:35,067 iteration 138 : loss : 0.245310, loss_ce: 0.126100
2021-12-10 10:19:36,606 iteration 139 : loss : 0.261532, loss_ce: 0.108123
2021-12-10 10:19:38,115 iteration 140 : loss : 0.207784, loss_ce: 0.071879
2021-12-10 10:19:39,665 iteration 141 : loss : 0.218757, loss_ce: 0.101985
2021-12-10 10:19:41,229 iteration 142 : loss : 0.228901, loss_ce: 0.088806
2021-12-10 10:19:42,820 iteration 143 : loss : 0.242528, loss_ce: 0.100235
2021-12-10 10:19:44,380 iteration 144 : loss : 0.252396, loss_ce: 0.096568
2021-12-10 10:19:45,879 iteration 145 : loss : 0.220720, loss_ce: 0.082168
2021-12-10 10:19:47,425 iteration 146 : loss : 0.212811, loss_ce: 0.095766
2021-12-10 10:19:48,984 iteration 147 : loss : 0.212179, loss_ce: 0.087495
2021-12-10 10:19:50,412 iteration 148 : loss : 0.250411, loss_ce: 0.108173
2021-12-10 10:19:51,908 iteration 149 : loss : 0.279217, loss_ce: 0.126441
2021-12-10 10:19:53,383 iteration 150 : loss : 0.273671, loss_ce: 0.102611
2021-12-10 10:19:54,862 iteration 151 : loss : 0.216619, loss_ce: 0.095121
2021-12-10 10:19:56,347 iteration 152 : loss : 0.230569, loss_ce: 0.077001
2021-12-10 10:19:57,878 iteration 153 : loss : 0.251308, loss_ce: 0.110270
  2%|▋                              | 9/400 [04:09<2:56:24, 27.07s/it]2021-12-10 10:19:59,390 iteration 154 : loss : 0.267829, loss_ce: 0.113770
2021-12-10 10:20:00,907 iteration 155 : loss : 0.218858, loss_ce: 0.076694
2021-12-10 10:20:02,499 iteration 156 : loss : 0.207253, loss_ce: 0.075060
2021-12-10 10:20:04,025 iteration 157 : loss : 0.236343, loss_ce: 0.082531
2021-12-10 10:20:05,658 iteration 158 : loss : 0.215225, loss_ce: 0.090613
2021-12-10 10:20:07,061 iteration 159 : loss : 0.205519, loss_ce: 0.086543
2021-12-10 10:20:08,649 iteration 160 : loss : 0.216030, loss_ce: 0.073648
2021-12-10 10:20:10,225 iteration 161 : loss : 0.265889, loss_ce: 0.103264
2021-12-10 10:20:11,804 iteration 162 : loss : 0.220144, loss_ce: 0.103599
2021-12-10 10:20:13,317 iteration 163 : loss : 0.230288, loss_ce: 0.089179
2021-12-10 10:20:14,857 iteration 164 : loss : 0.218117, loss_ce: 0.075531
2021-12-10 10:20:16,357 iteration 165 : loss : 0.263237, loss_ce: 0.115105
2021-12-10 10:20:17,845 iteration 166 : loss : 0.230121, loss_ce: 0.088565
2021-12-10 10:20:19,349 iteration 167 : loss : 0.205155, loss_ce: 0.077521
2021-12-10 10:20:20,897 iteration 168 : loss : 0.279659, loss_ce: 0.138263
2021-12-10 10:20:22,405 iteration 169 : loss : 0.205170, loss_ce: 0.093068
2021-12-10 10:20:22,405 Training Data Eval:
2021-12-10 10:20:29,965   Average segmentation loss on training set: 0.2608
2021-12-10 10:20:29,965 Validation Data Eval:
2021-12-10 10:20:32,585   Average segmentation loss on validation set: 0.2416
2021-12-10 10:20:38,399 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:20:39,996 iteration 170 : loss : 0.198809, loss_ce: 0.080664
  2%|▊                             | 10/400 [04:51<3:26:07, 31.71s/it]2021-12-10 10:20:41,577 iteration 171 : loss : 0.221176, loss_ce: 0.087595
2021-12-10 10:20:43,111 iteration 172 : loss : 0.235748, loss_ce: 0.100690
2021-12-10 10:20:44,666 iteration 173 : loss : 0.207076, loss_ce: 0.085145
2021-12-10 10:20:46,136 iteration 174 : loss : 0.235352, loss_ce: 0.099358
2021-12-10 10:20:47,592 iteration 175 : loss : 0.277133, loss_ce: 0.116593
2021-12-10 10:20:49,121 iteration 176 : loss : 0.207879, loss_ce: 0.093906
2021-12-10 10:20:50,620 iteration 177 : loss : 0.216416, loss_ce: 0.080595
2021-12-10 10:20:52,121 iteration 178 : loss : 0.177821, loss_ce: 0.075048
2021-12-10 10:20:53,621 iteration 179 : loss : 0.231568, loss_ce: 0.093469
2021-12-10 10:20:55,107 iteration 180 : loss : 0.201396, loss_ce: 0.071206
2021-12-10 10:20:56,639 iteration 181 : loss : 0.201801, loss_ce: 0.076360
2021-12-10 10:20:58,109 iteration 182 : loss : 0.187447, loss_ce: 0.068942
2021-12-10 10:20:59,566 iteration 183 : loss : 0.206624, loss_ce: 0.070251
2021-12-10 10:21:00,991 iteration 184 : loss : 0.211932, loss_ce: 0.071145
2021-12-10 10:21:02,523 iteration 185 : loss : 0.268809, loss_ce: 0.094771
2021-12-10 10:21:04,058 iteration 186 : loss : 0.242268, loss_ce: 0.105375
2021-12-10 10:21:05,628 iteration 187 : loss : 0.221997, loss_ce: 0.092246
  3%|▊                             | 11/400 [05:17<3:13:31, 29.85s/it]2021-12-10 10:21:07,216 iteration 188 : loss : 0.300033, loss_ce: 0.130902
2021-12-10 10:21:08,744 iteration 189 : loss : 0.205387, loss_ce: 0.083789
2021-12-10 10:21:10,276 iteration 190 : loss : 0.195469, loss_ce: 0.072112
2021-12-10 10:21:11,765 iteration 191 : loss : 0.180945, loss_ce: 0.068492
2021-12-10 10:21:13,208 iteration 192 : loss : 0.203790, loss_ce: 0.088298
2021-12-10 10:21:14,774 iteration 193 : loss : 0.228565, loss_ce: 0.098183
2021-12-10 10:21:16,271 iteration 194 : loss : 0.249306, loss_ce: 0.072720
2021-12-10 10:21:17,743 iteration 195 : loss : 0.235615, loss_ce: 0.095434
2021-12-10 10:21:19,177 iteration 196 : loss : 0.230306, loss_ce: 0.074605
2021-12-10 10:21:20,693 iteration 197 : loss : 0.266530, loss_ce: 0.102021
2021-12-10 10:21:22,234 iteration 198 : loss : 0.209250, loss_ce: 0.090574
2021-12-10 10:21:23,708 iteration 199 : loss : 0.230110, loss_ce: 0.095693
2021-12-10 10:21:25,200 iteration 200 : loss : 0.229642, loss_ce: 0.096594
2021-12-10 10:21:26,725 iteration 201 : loss : 0.170498, loss_ce: 0.072160
2021-12-10 10:21:28,267 iteration 202 : loss : 0.209916, loss_ce: 0.095860
2021-12-10 10:21:29,739 iteration 203 : loss : 0.185041, loss_ce: 0.072778
2021-12-10 10:21:31,340 iteration 204 : loss : 0.218239, loss_ce: 0.085042
  3%|▉                             | 12/400 [05:42<3:04:53, 28.59s/it]2021-12-10 10:21:32,869 iteration 205 : loss : 0.183616, loss_ce: 0.066582
2021-12-10 10:21:34,370 iteration 206 : loss : 0.184406, loss_ce: 0.056227
2021-12-10 10:21:35,895 iteration 207 : loss : 0.200002, loss_ce: 0.085127
2021-12-10 10:21:37,385 iteration 208 : loss : 0.238884, loss_ce: 0.078360
2021-12-10 10:21:38,967 iteration 209 : loss : 0.284816, loss_ce: 0.145774
2021-12-10 10:21:40,395 iteration 210 : loss : 0.185165, loss_ce: 0.068901
2021-12-10 10:21:41,938 iteration 211 : loss : 0.228435, loss_ce: 0.109721
2021-12-10 10:21:43,466 iteration 212 : loss : 0.207882, loss_ce: 0.081562
2021-12-10 10:21:45,086 iteration 213 : loss : 0.195430, loss_ce: 0.090164
2021-12-10 10:21:46,600 iteration 214 : loss : 0.203047, loss_ce: 0.066567
2021-12-10 10:21:48,113 iteration 215 : loss : 0.234944, loss_ce: 0.095457
2021-12-10 10:21:49,785 iteration 216 : loss : 0.222398, loss_ce: 0.083668
2021-12-10 10:21:51,390 iteration 217 : loss : 0.207569, loss_ce: 0.080799
2021-12-10 10:21:52,920 iteration 218 : loss : 0.197624, loss_ce: 0.088706
2021-12-10 10:21:54,341 iteration 219 : loss : 0.189660, loss_ce: 0.075408
2021-12-10 10:21:55,878 iteration 220 : loss : 0.179395, loss_ce: 0.077060
2021-12-10 10:21:57,399 iteration 221 : loss : 0.254560, loss_ce: 0.094938
  3%|▉                             | 13/400 [06:08<2:59:28, 27.83s/it]2021-12-10 10:21:58,988 iteration 222 : loss : 0.199699, loss_ce: 0.089213
2021-12-10 10:22:00,550 iteration 223 : loss : 0.180998, loss_ce: 0.074681
2021-12-10 10:22:02,062 iteration 224 : loss : 0.337420, loss_ce: 0.161581
2021-12-10 10:22:03,668 iteration 225 : loss : 0.308297, loss_ce: 0.097507
2021-12-10 10:22:05,176 iteration 226 : loss : 0.218530, loss_ce: 0.077975
2021-12-10 10:22:06,733 iteration 227 : loss : 0.222027, loss_ce: 0.098819
2021-12-10 10:22:08,250 iteration 228 : loss : 0.221295, loss_ce: 0.096964
2021-12-10 10:22:09,717 iteration 229 : loss : 0.209667, loss_ce: 0.072473
2021-12-10 10:22:11,240 iteration 230 : loss : 0.188013, loss_ce: 0.075369
2021-12-10 10:22:12,799 iteration 231 : loss : 0.272724, loss_ce: 0.107962
2021-12-10 10:22:14,351 iteration 232 : loss : 0.176797, loss_ce: 0.071681
2021-12-10 10:22:15,828 iteration 233 : loss : 0.269815, loss_ce: 0.116701
2021-12-10 10:22:17,408 iteration 234 : loss : 0.234558, loss_ce: 0.087018
2021-12-10 10:22:18,907 iteration 235 : loss : 0.215790, loss_ce: 0.091063
2021-12-10 10:22:20,455 iteration 236 : loss : 0.221296, loss_ce: 0.089089
2021-12-10 10:22:21,950 iteration 237 : loss : 0.187458, loss_ce: 0.074743
2021-12-10 10:22:23,459 iteration 238 : loss : 0.209357, loss_ce: 0.097506
  4%|█                             | 14/400 [06:34<2:55:35, 27.29s/it]2021-12-10 10:22:24,979 iteration 239 : loss : 0.214000, loss_ce: 0.081262
2021-12-10 10:22:26,524 iteration 240 : loss : 0.185376, loss_ce: 0.090769
2021-12-10 10:22:28,078 iteration 241 : loss : 0.262236, loss_ce: 0.106971
2021-12-10 10:22:29,610 iteration 242 : loss : 0.218394, loss_ce: 0.117233
2021-12-10 10:22:31,265 iteration 243 : loss : 0.264163, loss_ce: 0.110999
2021-12-10 10:22:32,738 iteration 244 : loss : 0.241324, loss_ce: 0.071344
2021-12-10 10:22:34,272 iteration 245 : loss : 0.197692, loss_ce: 0.091135
2021-12-10 10:22:35,843 iteration 246 : loss : 0.184962, loss_ce: 0.072451
2021-12-10 10:22:37,349 iteration 247 : loss : 0.240126, loss_ce: 0.085448
2021-12-10 10:22:38,854 iteration 248 : loss : 0.228941, loss_ce: 0.079776
2021-12-10 10:22:40,341 iteration 249 : loss : 0.246085, loss_ce: 0.131360
2021-12-10 10:22:41,847 iteration 250 : loss : 0.232207, loss_ce: 0.094018
2021-12-10 10:22:43,300 iteration 251 : loss : 0.232157, loss_ce: 0.079759
2021-12-10 10:22:44,802 iteration 252 : loss : 0.150409, loss_ce: 0.058021
2021-12-10 10:22:46,345 iteration 253 : loss : 0.200573, loss_ce: 0.069855
2021-12-10 10:22:47,938 iteration 254 : loss : 0.304586, loss_ce: 0.104424
2021-12-10 10:22:47,938 Training Data Eval:
2021-12-10 10:22:55,503   Average segmentation loss on training set: 1.1584
2021-12-10 10:22:55,503 Validation Data Eval:
2021-12-10 10:22:58,116   Average segmentation loss on validation set: 1.1335
2021-12-10 10:22:59,598 iteration 255 : loss : 0.222316, loss_ce: 0.086116
  4%|█▏                            | 15/400 [07:11<3:12:15, 29.96s/it]2021-12-10 10:23:01,198 iteration 256 : loss : 0.198346, loss_ce: 0.078563
2021-12-10 10:23:02,770 iteration 257 : loss : 0.202717, loss_ce: 0.078746
2021-12-10 10:23:04,384 iteration 258 : loss : 0.180897, loss_ce: 0.068109
2021-12-10 10:23:05,828 iteration 259 : loss : 0.159933, loss_ce: 0.069602
2021-12-10 10:23:07,404 iteration 260 : loss : 0.181488, loss_ce: 0.076418
2021-12-10 10:23:08,943 iteration 261 : loss : 0.240077, loss_ce: 0.083392
2021-12-10 10:23:10,565 iteration 262 : loss : 0.189692, loss_ce: 0.074146
2021-12-10 10:23:12,084 iteration 263 : loss : 0.204652, loss_ce: 0.079248
2021-12-10 10:23:13,633 iteration 264 : loss : 0.253937, loss_ce: 0.124899
2021-12-10 10:23:15,121 iteration 265 : loss : 0.169725, loss_ce: 0.070021
2021-12-10 10:23:16,674 iteration 266 : loss : 0.203170, loss_ce: 0.094435
2021-12-10 10:23:18,187 iteration 267 : loss : 0.237281, loss_ce: 0.083241
2021-12-10 10:23:19,714 iteration 268 : loss : 0.229463, loss_ce: 0.106966
2021-12-10 10:23:21,428 iteration 269 : loss : 0.255172, loss_ce: 0.091845
2021-12-10 10:23:23,051 iteration 270 : loss : 0.181226, loss_ce: 0.071527
2021-12-10 10:23:24,457 iteration 271 : loss : 0.195799, loss_ce: 0.057634
2021-12-10 10:23:25,984 iteration 272 : loss : 0.208466, loss_ce: 0.099263
  4%|█▏                            | 16/400 [07:37<3:04:51, 28.88s/it]2021-12-10 10:23:27,512 iteration 273 : loss : 0.194438, loss_ce: 0.064689
2021-12-10 10:23:28,972 iteration 274 : loss : 0.146060, loss_ce: 0.055353
2021-12-10 10:23:30,437 iteration 275 : loss : 0.162752, loss_ce: 0.064443
2021-12-10 10:23:31,956 iteration 276 : loss : 0.165619, loss_ce: 0.073983
2021-12-10 10:23:33,497 iteration 277 : loss : 0.166534, loss_ce: 0.063839
2021-12-10 10:23:34,897 iteration 278 : loss : 0.217966, loss_ce: 0.080211
2021-12-10 10:23:36,360 iteration 279 : loss : 0.228476, loss_ce: 0.086575
2021-12-10 10:23:37,818 iteration 280 : loss : 0.203022, loss_ce: 0.088913
2021-12-10 10:23:39,334 iteration 281 : loss : 0.221306, loss_ce: 0.099242
2021-12-10 10:23:40,826 iteration 282 : loss : 0.253326, loss_ce: 0.098689
2021-12-10 10:23:42,301 iteration 283 : loss : 0.235167, loss_ce: 0.113410
2021-12-10 10:23:43,870 iteration 284 : loss : 0.236613, loss_ce: 0.112475
2021-12-10 10:23:45,324 iteration 285 : loss : 0.211611, loss_ce: 0.072459
2021-12-10 10:23:46,800 iteration 286 : loss : 0.184830, loss_ce: 0.075772
2021-12-10 10:23:48,385 iteration 287 : loss : 0.198027, loss_ce: 0.088850
2021-12-10 10:23:49,956 iteration 288 : loss : 0.207642, loss_ce: 0.082270
2021-12-10 10:23:51,447 iteration 289 : loss : 0.183853, loss_ce: 0.065632
  4%|█▎                            | 17/400 [08:02<2:57:48, 27.85s/it]2021-12-10 10:23:53,026 iteration 290 : loss : 0.168600, loss_ce: 0.065290
2021-12-10 10:23:54,501 iteration 291 : loss : 0.226891, loss_ce: 0.084682
2021-12-10 10:23:55,988 iteration 292 : loss : 0.161456, loss_ce: 0.066105
2021-12-10 10:23:57,480 iteration 293 : loss : 0.249427, loss_ce: 0.105151
2021-12-10 10:23:58,998 iteration 294 : loss : 0.191181, loss_ce: 0.077992
2021-12-10 10:24:00,609 iteration 295 : loss : 0.192719, loss_ce: 0.067725
2021-12-10 10:24:02,094 iteration 296 : loss : 0.184097, loss_ce: 0.072597
2021-12-10 10:24:03,611 iteration 297 : loss : 0.183000, loss_ce: 0.066445
2021-12-10 10:24:05,090 iteration 298 : loss : 0.168147, loss_ce: 0.058241
2021-12-10 10:24:06,600 iteration 299 : loss : 0.188503, loss_ce: 0.062990
2021-12-10 10:24:08,116 iteration 300 : loss : 0.207327, loss_ce: 0.068069
2021-12-10 10:24:09,639 iteration 301 : loss : 0.253394, loss_ce: 0.120641
2021-12-10 10:24:11,214 iteration 302 : loss : 0.183036, loss_ce: 0.074438
2021-12-10 10:24:12,769 iteration 303 : loss : 0.205969, loss_ce: 0.093000
2021-12-10 10:24:14,303 iteration 304 : loss : 0.271617, loss_ce: 0.132676
2021-12-10 10:24:15,878 iteration 305 : loss : 0.199850, loss_ce: 0.084933
2021-12-10 10:24:17,442 iteration 306 : loss : 0.159050, loss_ce: 0.074075
  4%|█▎                            | 18/400 [08:28<2:53:47, 27.30s/it]2021-12-10 10:24:19,030 iteration 307 : loss : 0.210177, loss_ce: 0.083927
2021-12-10 10:24:20,510 iteration 308 : loss : 0.191893, loss_ce: 0.092070
2021-12-10 10:24:22,049 iteration 309 : loss : 0.274344, loss_ce: 0.108484
2021-12-10 10:24:23,601 iteration 310 : loss : 0.198726, loss_ce: 0.084865
2021-12-10 10:24:25,079 iteration 311 : loss : 0.242868, loss_ce: 0.079489
2021-12-10 10:24:26,586 iteration 312 : loss : 0.192045, loss_ce: 0.085579
2021-12-10 10:24:28,108 iteration 313 : loss : 0.204393, loss_ce: 0.098885
2021-12-10 10:24:29,550 iteration 314 : loss : 0.164471, loss_ce: 0.074433
2021-12-10 10:24:31,049 iteration 315 : loss : 0.241268, loss_ce: 0.093734
2021-12-10 10:24:32,580 iteration 316 : loss : 0.221079, loss_ce: 0.087035
2021-12-10 10:24:34,102 iteration 317 : loss : 0.201874, loss_ce: 0.082597
2021-12-10 10:24:35,648 iteration 318 : loss : 0.158689, loss_ce: 0.074024
2021-12-10 10:24:37,112 iteration 319 : loss : 0.171247, loss_ce: 0.075974
2021-12-10 10:24:38,731 iteration 320 : loss : 0.171944, loss_ce: 0.061805
2021-12-10 10:24:40,293 iteration 321 : loss : 0.180463, loss_ce: 0.060586
2021-12-10 10:24:41,814 iteration 322 : loss : 0.236288, loss_ce: 0.115222
2021-12-10 10:24:43,418 iteration 323 : loss : 0.176572, loss_ce: 0.057281
  5%|█▍                            | 19/400 [08:54<2:50:47, 26.90s/it]2021-12-10 10:24:44,981 iteration 324 : loss : 0.176333, loss_ce: 0.062377
2021-12-10 10:24:46,520 iteration 325 : loss : 0.244223, loss_ce: 0.084524
2021-12-10 10:24:48,087 iteration 326 : loss : 0.195439, loss_ce: 0.083693
2021-12-10 10:24:49,725 iteration 327 : loss : 0.221619, loss_ce: 0.078932
2021-12-10 10:24:51,249 iteration 328 : loss : 0.161460, loss_ce: 0.065821
2021-12-10 10:24:52,821 iteration 329 : loss : 0.203129, loss_ce: 0.098865
2021-12-10 10:24:54,415 iteration 330 : loss : 0.231528, loss_ce: 0.107870
2021-12-10 10:24:55,902 iteration 331 : loss : 0.184197, loss_ce: 0.087434
2021-12-10 10:24:57,417 iteration 332 : loss : 0.164713, loss_ce: 0.059421
2021-12-10 10:24:58,986 iteration 333 : loss : 0.131310, loss_ce: 0.060892
2021-12-10 10:25:00,539 iteration 334 : loss : 0.200652, loss_ce: 0.090264
2021-12-10 10:25:02,051 iteration 335 : loss : 0.232709, loss_ce: 0.080174
2021-12-10 10:25:03,647 iteration 336 : loss : 0.183712, loss_ce: 0.071632
2021-12-10 10:25:05,182 iteration 337 : loss : 0.166582, loss_ce: 0.052535
2021-12-10 10:25:06,660 iteration 338 : loss : 0.257817, loss_ce: 0.134427
2021-12-10 10:25:08,161 iteration 339 : loss : 0.216973, loss_ce: 0.082922
2021-12-10 10:25:08,162 Training Data Eval:
2021-12-10 10:25:15,756   Average segmentation loss on training set: 0.3737
2021-12-10 10:25:15,757 Validation Data Eval:
2021-12-10 10:25:18,391   Average segmentation loss on validation set: 0.4671
2021-12-10 10:25:19,979 iteration 340 : loss : 0.194856, loss_ce: 0.082862
  5%|█▌                            | 20/400 [09:31<3:08:42, 29.80s/it]2021-12-10 10:25:21,610 iteration 341 : loss : 0.152197, loss_ce: 0.067285
2021-12-10 10:25:23,189 iteration 342 : loss : 0.169499, loss_ce: 0.055249
2021-12-10 10:25:24,721 iteration 343 : loss : 0.210759, loss_ce: 0.082702
2021-12-10 10:25:26,292 iteration 344 : loss : 0.238185, loss_ce: 0.109126
2021-12-10 10:25:27,814 iteration 345 : loss : 0.162057, loss_ce: 0.055738
2021-12-10 10:25:29,406 iteration 346 : loss : 0.201942, loss_ce: 0.083737
2021-12-10 10:25:30,883 iteration 347 : loss : 0.201928, loss_ce: 0.101986
2021-12-10 10:25:32,438 iteration 348 : loss : 0.189642, loss_ce: 0.070474
2021-12-10 10:25:34,102 iteration 349 : loss : 0.259296, loss_ce: 0.142848
2021-12-10 10:25:35,629 iteration 350 : loss : 0.178251, loss_ce: 0.071150
2021-12-10 10:25:37,214 iteration 351 : loss : 0.184428, loss_ce: 0.088595
2021-12-10 10:25:38,781 iteration 352 : loss : 0.175356, loss_ce: 0.076385
2021-12-10 10:25:40,267 iteration 353 : loss : 0.194940, loss_ce: 0.077574
2021-12-10 10:25:41,819 iteration 354 : loss : 0.221134, loss_ce: 0.080476
2021-12-10 10:25:43,420 iteration 355 : loss : 0.213025, loss_ce: 0.082896
2021-12-10 10:25:45,097 iteration 356 : loss : 0.167440, loss_ce: 0.072372
2021-12-10 10:25:46,561 iteration 357 : loss : 0.150238, loss_ce: 0.058592
  5%|█▌                            | 21/400 [09:58<3:02:07, 28.83s/it]2021-12-10 10:25:48,184 iteration 358 : loss : 0.175018, loss_ce: 0.079488
2021-12-10 10:25:49,805 iteration 359 : loss : 0.178802, loss_ce: 0.066608
2021-12-10 10:25:51,286 iteration 360 : loss : 0.138657, loss_ce: 0.052231
2021-12-10 10:25:52,862 iteration 361 : loss : 0.173508, loss_ce: 0.058861
2021-12-10 10:25:54,496 iteration 362 : loss : 0.168472, loss_ce: 0.056734
2021-12-10 10:25:56,113 iteration 363 : loss : 0.229579, loss_ce: 0.087615
2021-12-10 10:25:57,688 iteration 364 : loss : 0.193417, loss_ce: 0.075537
2021-12-10 10:25:59,133 iteration 365 : loss : 0.199669, loss_ce: 0.086360
2021-12-10 10:26:00,711 iteration 366 : loss : 0.212830, loss_ce: 0.091661
2021-12-10 10:26:02,177 iteration 367 : loss : 0.185313, loss_ce: 0.072046
2021-12-10 10:26:03,758 iteration 368 : loss : 0.218275, loss_ce: 0.076368
2021-12-10 10:26:05,388 iteration 369 : loss : 0.196432, loss_ce: 0.064434
2021-12-10 10:26:06,994 iteration 370 : loss : 0.147683, loss_ce: 0.069766
2021-12-10 10:26:08,561 iteration 371 : loss : 0.243394, loss_ce: 0.081731
2021-12-10 10:26:10,131 iteration 372 : loss : 0.248893, loss_ce: 0.128188
2021-12-10 10:26:11,613 iteration 373 : loss : 0.197123, loss_ce: 0.067852
2021-12-10 10:26:13,128 iteration 374 : loss : 0.182753, loss_ce: 0.071610
  6%|█▋                            | 22/400 [10:24<2:57:22, 28.15s/it]2021-12-10 10:26:14,778 iteration 375 : loss : 0.287495, loss_ce: 0.128107
2021-12-10 10:26:16,276 iteration 376 : loss : 0.147644, loss_ce: 0.055662
2021-12-10 10:26:17,806 iteration 377 : loss : 0.196225, loss_ce: 0.078482
2021-12-10 10:26:19,433 iteration 378 : loss : 0.199688, loss_ce: 0.092283
2021-12-10 10:26:20,887 iteration 379 : loss : 0.189782, loss_ce: 0.081749
2021-12-10 10:26:22,466 iteration 380 : loss : 0.179889, loss_ce: 0.063709
2021-12-10 10:26:23,995 iteration 381 : loss : 0.157543, loss_ce: 0.052612
2021-12-10 10:26:25,442 iteration 382 : loss : 0.179440, loss_ce: 0.077081
2021-12-10 10:26:26,971 iteration 383 : loss : 0.209981, loss_ce: 0.082741
2021-12-10 10:26:28,528 iteration 384 : loss : 0.167173, loss_ce: 0.069339
2021-12-10 10:26:30,065 iteration 385 : loss : 0.130358, loss_ce: 0.060901
2021-12-10 10:26:31,609 iteration 386 : loss : 0.263046, loss_ce: 0.098380
2021-12-10 10:26:33,175 iteration 387 : loss : 0.244928, loss_ce: 0.084451
2021-12-10 10:26:34,757 iteration 388 : loss : 0.210060, loss_ce: 0.090356
2021-12-10 10:26:36,325 iteration 389 : loss : 0.273376, loss_ce: 0.143072
2021-12-10 10:26:37,848 iteration 390 : loss : 0.141622, loss_ce: 0.061289
2021-12-10 10:26:39,690 iteration 391 : loss : 0.255127, loss_ce: 0.155017
  6%|█▋                            | 23/400 [10:51<2:53:52, 27.67s/it]2021-12-10 10:26:41,295 iteration 392 : loss : 0.190977, loss_ce: 0.106582
2021-12-10 10:26:42,785 iteration 393 : loss : 0.153740, loss_ce: 0.058665
2021-12-10 10:26:44,371 iteration 394 : loss : 0.156211, loss_ce: 0.052700
2021-12-10 10:26:45,937 iteration 395 : loss : 0.198184, loss_ce: 0.088575
2021-12-10 10:26:47,453 iteration 396 : loss : 0.173706, loss_ce: 0.061433
2021-12-10 10:26:49,002 iteration 397 : loss : 0.193678, loss_ce: 0.079356
2021-12-10 10:26:50,586 iteration 398 : loss : 0.153057, loss_ce: 0.057854
2021-12-10 10:26:52,028 iteration 399 : loss : 0.187673, loss_ce: 0.077221
2021-12-10 10:26:53,589 iteration 400 : loss : 0.177399, loss_ce: 0.064277
2021-12-10 10:26:55,205 iteration 401 : loss : 0.191820, loss_ce: 0.080421
2021-12-10 10:26:56,734 iteration 402 : loss : 0.138574, loss_ce: 0.064915
2021-12-10 10:26:58,258 iteration 403 : loss : 0.137550, loss_ce: 0.055313
2021-12-10 10:26:59,842 iteration 404 : loss : 0.202913, loss_ce: 0.087040
2021-12-10 10:27:01,468 iteration 405 : loss : 0.193630, loss_ce: 0.084192
2021-12-10 10:27:02,990 iteration 406 : loss : 0.203402, loss_ce: 0.089891
2021-12-10 10:27:04,473 iteration 407 : loss : 0.188850, loss_ce: 0.072236
2021-12-10 10:27:06,005 iteration 408 : loss : 0.190360, loss_ce: 0.070845
  6%|█▊                            | 24/400 [11:17<2:50:53, 27.27s/it]2021-12-10 10:27:07,627 iteration 409 : loss : 0.159552, loss_ce: 0.073167
2021-12-10 10:27:09,196 iteration 410 : loss : 0.182041, loss_ce: 0.074194
2021-12-10 10:27:10,732 iteration 411 : loss : 0.276389, loss_ce: 0.085209
2021-12-10 10:27:12,175 iteration 412 : loss : 0.161035, loss_ce: 0.059352
2021-12-10 10:27:13,711 iteration 413 : loss : 0.178772, loss_ce: 0.065110
2021-12-10 10:27:15,191 iteration 414 : loss : 0.192508, loss_ce: 0.095840
2021-12-10 10:27:16,616 iteration 415 : loss : 0.161087, loss_ce: 0.062132
2021-12-10 10:27:18,143 iteration 416 : loss : 0.188513, loss_ce: 0.094712
2021-12-10 10:27:19,643 iteration 417 : loss : 0.213376, loss_ce: 0.089108
2021-12-10 10:27:21,246 iteration 418 : loss : 0.152677, loss_ce: 0.069206
2021-12-10 10:27:22,757 iteration 419 : loss : 0.170397, loss_ce: 0.084708
2021-12-10 10:27:24,313 iteration 420 : loss : 0.178961, loss_ce: 0.074490
2021-12-10 10:27:25,803 iteration 421 : loss : 0.208459, loss_ce: 0.093169
2021-12-10 10:27:27,285 iteration 422 : loss : 0.192637, loss_ce: 0.079820
2021-12-10 10:27:28,783 iteration 423 : loss : 0.205389, loss_ce: 0.069108
2021-12-10 10:27:30,335 iteration 424 : loss : 0.159918, loss_ce: 0.069786
2021-12-10 10:27:30,335 Training Data Eval:
2021-12-10 10:27:38,036   Average segmentation loss on training set: 0.2192
2021-12-10 10:27:38,036 Validation Data Eval:
2021-12-10 10:27:40,812   Average segmentation loss on validation set: 0.2039
2021-12-10 10:27:47,182 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:27:48,739 iteration 425 : loss : 0.194710, loss_ce: 0.070648
  6%|█▉                            | 25/400 [12:00<3:19:25, 31.91s/it]2021-12-10 10:27:50,263 iteration 426 : loss : 0.157836, loss_ce: 0.055272
2021-12-10 10:27:51,829 iteration 427 : loss : 0.161260, loss_ce: 0.055870
2021-12-10 10:27:53,358 iteration 428 : loss : 0.199328, loss_ce: 0.077699
2021-12-10 10:27:54,835 iteration 429 : loss : 0.207548, loss_ce: 0.110559
2021-12-10 10:27:56,299 iteration 430 : loss : 0.172365, loss_ce: 0.061666
2021-12-10 10:27:57,793 iteration 431 : loss : 0.249744, loss_ce: 0.098307
2021-12-10 10:27:59,351 iteration 432 : loss : 0.130586, loss_ce: 0.047927
2021-12-10 10:28:00,950 iteration 433 : loss : 0.151383, loss_ce: 0.062235
2021-12-10 10:28:02,493 iteration 434 : loss : 0.142167, loss_ce: 0.053573
2021-12-10 10:28:03,969 iteration 435 : loss : 0.167791, loss_ce: 0.073977
2021-12-10 10:28:05,489 iteration 436 : loss : 0.158036, loss_ce: 0.072081
2021-12-10 10:28:07,015 iteration 437 : loss : 0.236695, loss_ce: 0.134297
2021-12-10 10:28:08,493 iteration 438 : loss : 0.182118, loss_ce: 0.069879
2021-12-10 10:28:10,038 iteration 439 : loss : 0.186831, loss_ce: 0.066363
2021-12-10 10:28:11,552 iteration 440 : loss : 0.191945, loss_ce: 0.080619
2021-12-10 10:28:13,136 iteration 441 : loss : 0.185021, loss_ce: 0.076156
2021-12-10 10:28:14,693 iteration 442 : loss : 0.154924, loss_ce: 0.067739
  6%|█▉                            | 26/400 [12:26<3:07:46, 30.13s/it]2021-12-10 10:28:16,264 iteration 443 : loss : 0.167747, loss_ce: 0.082155
2021-12-10 10:28:17,746 iteration 444 : loss : 0.172183, loss_ce: 0.065629
2021-12-10 10:28:19,268 iteration 445 : loss : 0.186637, loss_ce: 0.066427
2021-12-10 10:28:20,936 iteration 446 : loss : 0.154654, loss_ce: 0.060861
2021-12-10 10:28:22,538 iteration 447 : loss : 0.189195, loss_ce: 0.102142
2021-12-10 10:28:24,124 iteration 448 : loss : 0.272961, loss_ce: 0.083250
2021-12-10 10:28:25,676 iteration 449 : loss : 0.181591, loss_ce: 0.086743
2021-12-10 10:28:27,197 iteration 450 : loss : 0.155349, loss_ce: 0.058674
2021-12-10 10:28:28,820 iteration 451 : loss : 0.111745, loss_ce: 0.048848
2021-12-10 10:28:30,400 iteration 452 : loss : 0.137948, loss_ce: 0.060260
2021-12-10 10:28:31,973 iteration 453 : loss : 0.228578, loss_ce: 0.096922
2021-12-10 10:28:33,540 iteration 454 : loss : 0.174395, loss_ce: 0.059193
2021-12-10 10:28:35,128 iteration 455 : loss : 0.131028, loss_ce: 0.053833
2021-12-10 10:28:36,678 iteration 456 : loss : 0.144551, loss_ce: 0.052455
2021-12-10 10:28:38,213 iteration 457 : loss : 0.148677, loss_ce: 0.064547
2021-12-10 10:28:39,829 iteration 458 : loss : 0.202824, loss_ce: 0.093277
2021-12-10 10:28:41,301 iteration 459 : loss : 0.115236, loss_ce: 0.046746
  7%|██                            | 27/400 [12:52<3:00:41, 29.07s/it]2021-12-10 10:28:42,903 iteration 460 : loss : 0.182623, loss_ce: 0.089519
2021-12-10 10:28:44,460 iteration 461 : loss : 0.148700, loss_ce: 0.071463
2021-12-10 10:28:45,993 iteration 462 : loss : 0.175950, loss_ce: 0.076934
2021-12-10 10:28:47,613 iteration 463 : loss : 0.175021, loss_ce: 0.077196
2021-12-10 10:28:49,175 iteration 464 : loss : 0.148800, loss_ce: 0.057500
2021-12-10 10:28:50,680 iteration 465 : loss : 0.150531, loss_ce: 0.047909
2021-12-10 10:28:52,224 iteration 466 : loss : 0.156416, loss_ce: 0.055950
2021-12-10 10:28:53,754 iteration 467 : loss : 0.169746, loss_ce: 0.056226
2021-12-10 10:28:55,416 iteration 468 : loss : 0.180571, loss_ce: 0.073074
2021-12-10 10:28:56,957 iteration 469 : loss : 0.170204, loss_ce: 0.055377
2021-12-10 10:28:58,511 iteration 470 : loss : 0.187469, loss_ce: 0.071143
2021-12-10 10:29:00,055 iteration 471 : loss : 0.165810, loss_ce: 0.059171
2021-12-10 10:29:01,657 iteration 472 : loss : 0.163996, loss_ce: 0.066378
2021-12-10 10:29:03,360 iteration 473 : loss : 0.201316, loss_ce: 0.087027
2021-12-10 10:29:05,011 iteration 474 : loss : 0.237719, loss_ce: 0.119511
2021-12-10 10:29:06,531 iteration 475 : loss : 0.100253, loss_ce: 0.039858
2021-12-10 10:29:08,136 iteration 476 : loss : 0.181572, loss_ce: 0.094380
  7%|██                            | 28/400 [13:19<2:56:03, 28.40s/it]2021-12-10 10:29:09,727 iteration 477 : loss : 0.162665, loss_ce: 0.053549
2021-12-10 10:29:11,322 iteration 478 : loss : 0.119881, loss_ce: 0.044292
2021-12-10 10:29:12,866 iteration 479 : loss : 0.135721, loss_ce: 0.059957
2021-12-10 10:29:14,432 iteration 480 : loss : 0.158571, loss_ce: 0.067748
2021-12-10 10:29:15,892 iteration 481 : loss : 0.178228, loss_ce: 0.070764
2021-12-10 10:29:17,450 iteration 482 : loss : 0.146020, loss_ce: 0.038897
2021-12-10 10:29:19,017 iteration 483 : loss : 0.187727, loss_ce: 0.068298
2021-12-10 10:29:20,610 iteration 484 : loss : 0.177539, loss_ce: 0.073348
2021-12-10 10:29:22,141 iteration 485 : loss : 0.119153, loss_ce: 0.052984
2021-12-10 10:29:23,658 iteration 486 : loss : 0.196821, loss_ce: 0.064772
2021-12-10 10:29:25,260 iteration 487 : loss : 0.146181, loss_ce: 0.056034
2021-12-10 10:29:26,744 iteration 488 : loss : 0.140822, loss_ce: 0.062477
2021-12-10 10:29:28,292 iteration 489 : loss : 0.149099, loss_ce: 0.064669
2021-12-10 10:29:29,726 iteration 490 : loss : 0.168489, loss_ce: 0.070003
2021-12-10 10:29:31,286 iteration 491 : loss : 0.179001, loss_ce: 0.080382
2021-12-10 10:29:32,812 iteration 492 : loss : 0.106648, loss_ce: 0.051685
2021-12-10 10:29:34,391 iteration 493 : loss : 0.151573, loss_ce: 0.073745
  7%|██▏                           | 29/400 [13:45<2:51:38, 27.76s/it]2021-12-10 10:29:35,984 iteration 494 : loss : 0.137401, loss_ce: 0.059557
2021-12-10 10:29:37,557 iteration 495 : loss : 0.118191, loss_ce: 0.040120
2021-12-10 10:29:39,091 iteration 496 : loss : 0.218698, loss_ce: 0.102974
2021-12-10 10:29:40,653 iteration 497 : loss : 0.156946, loss_ce: 0.070479
2021-12-10 10:29:42,255 iteration 498 : loss : 0.177559, loss_ce: 0.077689
2021-12-10 10:29:43,724 iteration 499 : loss : 0.186539, loss_ce: 0.089178
2021-12-10 10:29:45,211 iteration 500 : loss : 0.146987, loss_ce: 0.056498
2021-12-10 10:29:46,704 iteration 501 : loss : 0.139573, loss_ce: 0.056580
2021-12-10 10:29:48,297 iteration 502 : loss : 0.136587, loss_ce: 0.054382
2021-12-10 10:29:49,793 iteration 503 : loss : 0.162554, loss_ce: 0.051538
2021-12-10 10:29:51,358 iteration 504 : loss : 0.339408, loss_ce: 0.155789
2021-12-10 10:29:52,852 iteration 505 : loss : 0.101468, loss_ce: 0.040123
2021-12-10 10:29:54,525 iteration 506 : loss : 0.126350, loss_ce: 0.048257
2021-12-10 10:29:56,083 iteration 507 : loss : 0.213874, loss_ce: 0.084055
2021-12-10 10:29:57,637 iteration 508 : loss : 0.228336, loss_ce: 0.104513
2021-12-10 10:29:59,241 iteration 509 : loss : 0.167861, loss_ce: 0.062486
2021-12-10 10:29:59,241 Training Data Eval:
2021-12-10 10:30:06,920   Average segmentation loss on training set: 0.4419
2021-12-10 10:30:06,921 Validation Data Eval:
2021-12-10 10:30:09,564   Average segmentation loss on validation set: 0.5068
2021-12-10 10:30:11,149 iteration 510 : loss : 0.152935, loss_ce: 0.069776
  8%|██▎                           | 30/400 [14:22<3:07:48, 30.46s/it]2021-12-10 10:30:12,758 iteration 511 : loss : 0.207940, loss_ce: 0.099679
2021-12-10 10:30:14,246 iteration 512 : loss : 0.224528, loss_ce: 0.104939
2021-12-10 10:30:15,755 iteration 513 : loss : 0.138645, loss_ce: 0.042986
2021-12-10 10:30:17,288 iteration 514 : loss : 0.133966, loss_ce: 0.054844
2021-12-10 10:30:18,807 iteration 515 : loss : 0.193586, loss_ce: 0.080224
2021-12-10 10:30:20,365 iteration 516 : loss : 0.115773, loss_ce: 0.044229
2021-12-10 10:30:21,957 iteration 517 : loss : 0.195107, loss_ce: 0.094086
2021-12-10 10:30:23,442 iteration 518 : loss : 0.154534, loss_ce: 0.063065
2021-12-10 10:30:24,983 iteration 519 : loss : 0.201513, loss_ce: 0.090064
2021-12-10 10:30:26,467 iteration 520 : loss : 0.151839, loss_ce: 0.066011
2021-12-10 10:30:27,999 iteration 521 : loss : 0.174129, loss_ce: 0.071787
2021-12-10 10:30:29,577 iteration 522 : loss : 0.129171, loss_ce: 0.051911
2021-12-10 10:30:31,192 iteration 523 : loss : 0.144301, loss_ce: 0.067406
2021-12-10 10:30:32,874 iteration 524 : loss : 0.130171, loss_ce: 0.056094
2021-12-10 10:30:34,428 iteration 525 : loss : 0.200810, loss_ce: 0.096618
2021-12-10 10:30:35,975 iteration 526 : loss : 0.162468, loss_ce: 0.076002
2021-12-10 10:30:37,518 iteration 527 : loss : 0.157739, loss_ce: 0.058980
  8%|██▎                           | 31/400 [14:48<2:59:44, 29.23s/it]2021-12-10 10:30:39,085 iteration 528 : loss : 0.121078, loss_ce: 0.054591
2021-12-10 10:30:40,649 iteration 529 : loss : 0.170616, loss_ce: 0.054656
2021-12-10 10:30:42,161 iteration 530 : loss : 0.160673, loss_ce: 0.067726
2021-12-10 10:30:43,654 iteration 531 : loss : 0.181223, loss_ce: 0.055534
2021-12-10 10:30:45,153 iteration 532 : loss : 0.144550, loss_ce: 0.066880
2021-12-10 10:30:46,798 iteration 533 : loss : 0.126550, loss_ce: 0.049025
2021-12-10 10:30:48,291 iteration 534 : loss : 0.127207, loss_ce: 0.056593
2021-12-10 10:30:49,889 iteration 535 : loss : 0.140853, loss_ce: 0.053947
2021-12-10 10:30:51,520 iteration 536 : loss : 0.184401, loss_ce: 0.079668
2021-12-10 10:30:53,165 iteration 537 : loss : 0.170944, loss_ce: 0.056338
2021-12-10 10:30:54,739 iteration 538 : loss : 0.142300, loss_ce: 0.063854
2021-12-10 10:30:56,277 iteration 539 : loss : 0.147395, loss_ce: 0.062663
2021-12-10 10:30:57,858 iteration 540 : loss : 0.119607, loss_ce: 0.045028
2021-12-10 10:30:59,381 iteration 541 : loss : 0.123343, loss_ce: 0.053194
2021-12-10 10:31:00,928 iteration 542 : loss : 0.178465, loss_ce: 0.076931
2021-12-10 10:31:02,422 iteration 543 : loss : 0.098004, loss_ce: 0.041894
2021-12-10 10:31:03,943 iteration 544 : loss : 0.147812, loss_ce: 0.061776
  8%|██▍                           | 32/400 [15:15<2:54:06, 28.39s/it]2021-12-10 10:31:05,557 iteration 545 : loss : 0.113415, loss_ce: 0.054195
2021-12-10 10:31:07,107 iteration 546 : loss : 0.126051, loss_ce: 0.045503
2021-12-10 10:31:08,659 iteration 547 : loss : 0.126325, loss_ce: 0.049170
2021-12-10 10:31:10,194 iteration 548 : loss : 0.183285, loss_ce: 0.063102
2021-12-10 10:31:11,769 iteration 549 : loss : 0.111918, loss_ce: 0.051087
2021-12-10 10:31:13,286 iteration 550 : loss : 0.117170, loss_ce: 0.048235
2021-12-10 10:31:14,827 iteration 551 : loss : 0.136175, loss_ce: 0.062067
2021-12-10 10:31:16,342 iteration 552 : loss : 0.125199, loss_ce: 0.052453
2021-12-10 10:31:17,927 iteration 553 : loss : 0.150020, loss_ce: 0.052273
2021-12-10 10:31:19,408 iteration 554 : loss : 0.127163, loss_ce: 0.065505
2021-12-10 10:31:20,952 iteration 555 : loss : 0.104705, loss_ce: 0.031922
2021-12-10 10:31:22,539 iteration 556 : loss : 0.165183, loss_ce: 0.074071
2021-12-10 10:31:24,002 iteration 557 : loss : 0.161120, loss_ce: 0.056606
2021-12-10 10:31:25,584 iteration 558 : loss : 0.158275, loss_ce: 0.047950
2021-12-10 10:31:27,119 iteration 559 : loss : 0.130558, loss_ce: 0.051172
2021-12-10 10:31:28,678 iteration 560 : loss : 0.125850, loss_ce: 0.037956
2021-12-10 10:31:30,260 iteration 561 : loss : 0.176843, loss_ce: 0.089064
  8%|██▍                           | 33/400 [15:41<2:49:50, 27.77s/it]2021-12-10 10:31:31,961 iteration 562 : loss : 0.177905, loss_ce: 0.086203
2021-12-10 10:31:33,406 iteration 563 : loss : 0.125734, loss_ce: 0.059236
2021-12-10 10:31:34,963 iteration 564 : loss : 0.162012, loss_ce: 0.079675
2021-12-10 10:31:36,519 iteration 565 : loss : 0.138120, loss_ce: 0.061619
2021-12-10 10:31:38,112 iteration 566 : loss : 0.117037, loss_ce: 0.051851
2021-12-10 10:31:39,655 iteration 567 : loss : 0.148112, loss_ce: 0.057909
2021-12-10 10:31:41,168 iteration 568 : loss : 0.200136, loss_ce: 0.069876
2021-12-10 10:31:42,745 iteration 569 : loss : 0.192948, loss_ce: 0.084246
2021-12-10 10:31:44,332 iteration 570 : loss : 0.109810, loss_ce: 0.054232
2021-12-10 10:31:45,858 iteration 571 : loss : 0.235410, loss_ce: 0.096121
2021-12-10 10:31:47,430 iteration 572 : loss : 0.115641, loss_ce: 0.043293
2021-12-10 10:31:48,939 iteration 573 : loss : 0.123154, loss_ce: 0.051339
2021-12-10 10:31:50,493 iteration 574 : loss : 0.159176, loss_ce: 0.062565
2021-12-10 10:31:52,097 iteration 575 : loss : 0.142272, loss_ce: 0.047130
2021-12-10 10:31:53,671 iteration 576 : loss : 0.157746, loss_ce: 0.071163
2021-12-10 10:31:55,214 iteration 577 : loss : 0.096406, loss_ce: 0.041694
2021-12-10 10:31:56,701 iteration 578 : loss : 0.127072, loss_ce: 0.052592
  8%|██▌                           | 34/400 [16:08<2:46:56, 27.37s/it]2021-12-10 10:31:58,428 iteration 579 : loss : 0.131487, loss_ce: 0.053702
2021-12-10 10:32:00,002 iteration 580 : loss : 0.132551, loss_ce: 0.054485
2021-12-10 10:32:01,613 iteration 581 : loss : 0.145782, loss_ce: 0.042920
2021-12-10 10:32:03,157 iteration 582 : loss : 0.125469, loss_ce: 0.054750
2021-12-10 10:32:04,714 iteration 583 : loss : 0.206885, loss_ce: 0.071433
2021-12-10 10:32:06,228 iteration 584 : loss : 0.083844, loss_ce: 0.036588
2021-12-10 10:32:07,833 iteration 585 : loss : 0.109740, loss_ce: 0.045285
2021-12-10 10:32:09,339 iteration 586 : loss : 0.182762, loss_ce: 0.071863
2021-12-10 10:32:10,838 iteration 587 : loss : 0.105224, loss_ce: 0.048865
2021-12-10 10:32:12,410 iteration 588 : loss : 0.168701, loss_ce: 0.063333
2021-12-10 10:32:13,950 iteration 589 : loss : 0.119899, loss_ce: 0.040477
2021-12-10 10:32:15,495 iteration 590 : loss : 0.117170, loss_ce: 0.043753
2021-12-10 10:32:17,052 iteration 591 : loss : 0.121081, loss_ce: 0.044518
2021-12-10 10:32:18,603 iteration 592 : loss : 0.132143, loss_ce: 0.050734
2021-12-10 10:32:20,191 iteration 593 : loss : 0.093325, loss_ce: 0.035264
2021-12-10 10:32:21,756 iteration 594 : loss : 0.109852, loss_ce: 0.050120
2021-12-10 10:32:21,757 Training Data Eval:
2021-12-10 10:32:29,449   Average segmentation loss on training set: 0.1322
2021-12-10 10:32:29,449 Validation Data Eval:
2021-12-10 10:32:32,104   Average segmentation loss on validation set: 0.1463
2021-12-10 10:32:39,775 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:32:41,435 iteration 595 : loss : 0.158255, loss_ce: 0.081811
  9%|██▋                           | 35/400 [16:52<3:18:10, 32.58s/it]2021-12-10 10:32:43,028 iteration 596 : loss : 0.107738, loss_ce: 0.044773
2021-12-10 10:32:44,532 iteration 597 : loss : 0.132492, loss_ce: 0.044699
2021-12-10 10:32:46,023 iteration 598 : loss : 0.120862, loss_ce: 0.052262
2021-12-10 10:32:47,575 iteration 599 : loss : 0.162725, loss_ce: 0.063064
2021-12-10 10:32:49,090 iteration 600 : loss : 0.177081, loss_ce: 0.088159
2021-12-10 10:32:50,641 iteration 601 : loss : 0.137176, loss_ce: 0.049301
2021-12-10 10:32:52,209 iteration 602 : loss : 0.110450, loss_ce: 0.042659
2021-12-10 10:32:53,680 iteration 603 : loss : 0.138429, loss_ce: 0.052512
2021-12-10 10:32:55,162 iteration 604 : loss : 0.124166, loss_ce: 0.053245
2021-12-10 10:32:56,635 iteration 605 : loss : 0.115275, loss_ce: 0.045637
2021-12-10 10:32:58,321 iteration 606 : loss : 0.111534, loss_ce: 0.052571
2021-12-10 10:32:59,853 iteration 607 : loss : 0.167129, loss_ce: 0.078700
2021-12-10 10:33:01,391 iteration 608 : loss : 0.129499, loss_ce: 0.059645
2021-12-10 10:33:02,848 iteration 609 : loss : 0.118931, loss_ce: 0.046882
2021-12-10 10:33:04,438 iteration 610 : loss : 0.141906, loss_ce: 0.063724
2021-12-10 10:33:06,089 iteration 611 : loss : 0.153866, loss_ce: 0.073354
2021-12-10 10:33:07,647 iteration 612 : loss : 0.117507, loss_ce: 0.040498
  9%|██▋                           | 36/400 [17:19<3:06:04, 30.67s/it]2021-12-10 10:33:09,267 iteration 613 : loss : 0.132119, loss_ce: 0.056359
2021-12-10 10:33:10,768 iteration 614 : loss : 0.163914, loss_ce: 0.059414
2021-12-10 10:33:12,262 iteration 615 : loss : 0.203724, loss_ce: 0.095505
2021-12-10 10:33:13,888 iteration 616 : loss : 0.131754, loss_ce: 0.059202
2021-12-10 10:33:15,389 iteration 617 : loss : 0.115309, loss_ce: 0.057836
2021-12-10 10:33:16,946 iteration 618 : loss : 0.186504, loss_ce: 0.051856
2021-12-10 10:33:18,499 iteration 619 : loss : 0.211006, loss_ce: 0.087520
2021-12-10 10:33:20,149 iteration 620 : loss : 0.227963, loss_ce: 0.067511
2021-12-10 10:33:21,714 iteration 621 : loss : 0.102030, loss_ce: 0.037203
2021-12-10 10:33:23,386 iteration 622 : loss : 0.158948, loss_ce: 0.065160
2021-12-10 10:33:25,034 iteration 623 : loss : 0.167224, loss_ce: 0.086966
2021-12-10 10:33:26,566 iteration 624 : loss : 0.136854, loss_ce: 0.046165
2021-12-10 10:33:28,056 iteration 625 : loss : 0.130522, loss_ce: 0.054512
2021-12-10 10:33:29,641 iteration 626 : loss : 0.145066, loss_ce: 0.058710
2021-12-10 10:33:31,290 iteration 627 : loss : 0.181102, loss_ce: 0.060485
2021-12-10 10:33:32,955 iteration 628 : loss : 0.171476, loss_ce: 0.064377
2021-12-10 10:33:34,495 iteration 629 : loss : 0.116842, loss_ce: 0.046700
  9%|██▊                           | 37/400 [17:45<2:58:36, 29.52s/it]2021-12-10 10:33:36,134 iteration 630 : loss : 0.151556, loss_ce: 0.075264
2021-12-10 10:33:37,659 iteration 631 : loss : 0.094352, loss_ce: 0.041891
2021-12-10 10:33:39,189 iteration 632 : loss : 0.123515, loss_ce: 0.048796
2021-12-10 10:33:40,834 iteration 633 : loss : 0.137064, loss_ce: 0.057778
2021-12-10 10:33:42,397 iteration 634 : loss : 0.166652, loss_ce: 0.058016
2021-12-10 10:33:44,059 iteration 635 : loss : 0.138989, loss_ce: 0.057532
2021-12-10 10:33:45,633 iteration 636 : loss : 0.160300, loss_ce: 0.073596
2021-12-10 10:33:47,111 iteration 637 : loss : 0.124880, loss_ce: 0.055393
2021-12-10 10:33:48,742 iteration 638 : loss : 0.166896, loss_ce: 0.054602
2021-12-10 10:33:50,251 iteration 639 : loss : 0.107394, loss_ce: 0.055804
2021-12-10 10:33:51,735 iteration 640 : loss : 0.147380, loss_ce: 0.043533
2021-12-10 10:33:53,220 iteration 641 : loss : 0.129539, loss_ce: 0.057206
2021-12-10 10:33:54,712 iteration 642 : loss : 0.137006, loss_ce: 0.042140
2021-12-10 10:33:56,234 iteration 643 : loss : 0.130723, loss_ce: 0.047850
2021-12-10 10:33:57,768 iteration 644 : loss : 0.119001, loss_ce: 0.052935
2021-12-10 10:33:59,268 iteration 645 : loss : 0.100142, loss_ce: 0.033815
2021-12-10 10:34:00,888 iteration 646 : loss : 0.124306, loss_ce: 0.057566
 10%|██▊                           | 38/400 [18:12<2:52:27, 28.58s/it]2021-12-10 10:34:02,458 iteration 647 : loss : 0.155988, loss_ce: 0.068207
2021-12-10 10:34:04,006 iteration 648 : loss : 0.093084, loss_ce: 0.038286
2021-12-10 10:34:05,582 iteration 649 : loss : 0.116374, loss_ce: 0.049355
2021-12-10 10:34:07,210 iteration 650 : loss : 0.109854, loss_ce: 0.043219
2021-12-10 10:34:08,748 iteration 651 : loss : 0.087025, loss_ce: 0.035690
2021-12-10 10:34:10,184 iteration 652 : loss : 0.077110, loss_ce: 0.027434
2021-12-10 10:34:11,800 iteration 653 : loss : 0.115347, loss_ce: 0.046912
2021-12-10 10:34:13,296 iteration 654 : loss : 0.120249, loss_ce: 0.045106
2021-12-10 10:34:14,836 iteration 655 : loss : 0.186998, loss_ce: 0.069404
2021-12-10 10:34:16,418 iteration 656 : loss : 0.093067, loss_ce: 0.039938
2021-12-10 10:34:18,055 iteration 657 : loss : 0.082418, loss_ce: 0.033045
2021-12-10 10:34:19,637 iteration 658 : loss : 0.127290, loss_ce: 0.045299
2021-12-10 10:34:21,230 iteration 659 : loss : 0.134267, loss_ce: 0.053959
2021-12-10 10:34:22,757 iteration 660 : loss : 0.117145, loss_ce: 0.057490
2021-12-10 10:34:24,340 iteration 661 : loss : 0.102350, loss_ce: 0.044136
2021-12-10 10:34:26,055 iteration 662 : loss : 0.192603, loss_ce: 0.051124
2021-12-10 10:34:27,614 iteration 663 : loss : 0.110590, loss_ce: 0.049111
 10%|██▉                           | 39/400 [18:39<2:48:36, 28.02s/it]2021-12-10 10:34:29,236 iteration 664 : loss : 0.101188, loss_ce: 0.043966
2021-12-10 10:34:30,704 iteration 665 : loss : 0.107806, loss_ce: 0.059174
2021-12-10 10:34:32,241 iteration 666 : loss : 0.086991, loss_ce: 0.033672
2021-12-10 10:34:33,823 iteration 667 : loss : 0.072171, loss_ce: 0.032518
2021-12-10 10:34:35,379 iteration 668 : loss : 0.148531, loss_ce: 0.057759
2021-12-10 10:34:36,903 iteration 669 : loss : 0.104449, loss_ce: 0.040581
2021-12-10 10:34:38,583 iteration 670 : loss : 0.098414, loss_ce: 0.034709
2021-12-10 10:34:40,116 iteration 671 : loss : 0.119529, loss_ce: 0.043624
2021-12-10 10:34:41,738 iteration 672 : loss : 0.097960, loss_ce: 0.034261
2021-12-10 10:34:43,326 iteration 673 : loss : 0.096681, loss_ce: 0.043081
2021-12-10 10:34:44,904 iteration 674 : loss : 0.101712, loss_ce: 0.046028
2021-12-10 10:34:46,507 iteration 675 : loss : 0.121448, loss_ce: 0.045529
2021-12-10 10:34:48,058 iteration 676 : loss : 0.112056, loss_ce: 0.042288
2021-12-10 10:34:49,626 iteration 677 : loss : 0.078967, loss_ce: 0.035654
2021-12-10 10:34:51,217 iteration 678 : loss : 0.164256, loss_ce: 0.059320
2021-12-10 10:34:52,785 iteration 679 : loss : 0.129782, loss_ce: 0.059376
2021-12-10 10:34:52,785 Training Data Eval:
2021-12-10 10:35:00,527   Average segmentation loss on training set: 0.1204
2021-12-10 10:35:00,528 Validation Data Eval:
2021-12-10 10:35:03,181   Average segmentation loss on validation set: 0.1591
2021-12-10 10:35:04,735 iteration 680 : loss : 0.115250, loss_ce: 0.044543
 10%|███                           | 40/400 [19:16<3:04:33, 30.76s/it]2021-12-10 10:35:06,371 iteration 681 : loss : 0.083086, loss_ce: 0.033206
2021-12-10 10:35:07,839 iteration 682 : loss : 0.141847, loss_ce: 0.041152
2021-12-10 10:35:09,383 iteration 683 : loss : 0.111555, loss_ce: 0.052522
2021-12-10 10:35:10,886 iteration 684 : loss : 0.115019, loss_ce: 0.043400
2021-12-10 10:35:12,499 iteration 685 : loss : 0.113533, loss_ce: 0.047190
2021-12-10 10:35:14,049 iteration 686 : loss : 0.141488, loss_ce: 0.058394
2021-12-10 10:35:15,594 iteration 687 : loss : 0.095490, loss_ce: 0.041983
2021-12-10 10:35:17,116 iteration 688 : loss : 0.131743, loss_ce: 0.044476
2021-12-10 10:35:18,694 iteration 689 : loss : 0.106502, loss_ce: 0.047122
2021-12-10 10:35:20,236 iteration 690 : loss : 0.091128, loss_ce: 0.031942
2021-12-10 10:35:21,792 iteration 691 : loss : 0.118075, loss_ce: 0.048389
2021-12-10 10:35:23,406 iteration 692 : loss : 0.086485, loss_ce: 0.030761
2021-12-10 10:35:24,900 iteration 693 : loss : 0.113846, loss_ce: 0.052931
2021-12-10 10:35:26,464 iteration 694 : loss : 0.103820, loss_ce: 0.048472
2021-12-10 10:35:27,980 iteration 695 : loss : 0.141648, loss_ce: 0.069324
2021-12-10 10:35:29,603 iteration 696 : loss : 0.085809, loss_ce: 0.036703
2021-12-10 10:35:31,158 iteration 697 : loss : 0.090639, loss_ce: 0.038998
 10%|███                           | 41/400 [19:42<2:56:15, 29.46s/it]2021-12-10 10:35:32,729 iteration 698 : loss : 0.178641, loss_ce: 0.050701
2021-12-10 10:35:34,317 iteration 699 : loss : 0.114545, loss_ce: 0.050985
2021-12-10 10:35:35,847 iteration 700 : loss : 0.123843, loss_ce: 0.054370
2021-12-10 10:35:37,373 iteration 701 : loss : 0.111289, loss_ce: 0.054959
2021-12-10 10:35:38,955 iteration 702 : loss : 0.136502, loss_ce: 0.050082
2021-12-10 10:35:40,584 iteration 703 : loss : 0.061824, loss_ce: 0.026825
2021-12-10 10:35:42,056 iteration 704 : loss : 0.086803, loss_ce: 0.037867
2021-12-10 10:35:43,596 iteration 705 : loss : 0.134081, loss_ce: 0.051938
2021-12-10 10:35:45,169 iteration 706 : loss : 0.083048, loss_ce: 0.033873
2021-12-10 10:35:46,645 iteration 707 : loss : 0.073253, loss_ce: 0.035045
2021-12-10 10:35:48,172 iteration 708 : loss : 0.079862, loss_ce: 0.032506
2021-12-10 10:35:49,699 iteration 709 : loss : 0.109974, loss_ce: 0.046228
2021-12-10 10:35:51,265 iteration 710 : loss : 0.104742, loss_ce: 0.039332
2021-12-10 10:35:52,830 iteration 711 : loss : 0.105945, loss_ce: 0.046078
2021-12-10 10:35:54,506 iteration 712 : loss : 0.090157, loss_ce: 0.032076
2021-12-10 10:35:56,054 iteration 713 : loss : 0.079297, loss_ce: 0.033565
2021-12-10 10:35:57,684 iteration 714 : loss : 0.124122, loss_ce: 0.042389
 10%|███▏                          | 42/400 [20:09<2:50:30, 28.58s/it]2021-12-10 10:35:59,340 iteration 715 : loss : 0.092453, loss_ce: 0.037783
2021-12-10 10:36:00,948 iteration 716 : loss : 0.081148, loss_ce: 0.037894
2021-12-10 10:36:02,501 iteration 717 : loss : 0.083517, loss_ce: 0.028947
2021-12-10 10:36:04,070 iteration 718 : loss : 0.100746, loss_ce: 0.044812
2021-12-10 10:36:05,687 iteration 719 : loss : 0.113691, loss_ce: 0.046780
2021-12-10 10:36:07,238 iteration 720 : loss : 0.111297, loss_ce: 0.040280
2021-12-10 10:36:08,785 iteration 721 : loss : 0.088191, loss_ce: 0.031179
2021-12-10 10:36:10,322 iteration 722 : loss : 0.112210, loss_ce: 0.039099
2021-12-10 10:36:11,922 iteration 723 : loss : 0.115355, loss_ce: 0.051844
2021-12-10 10:36:13,447 iteration 724 : loss : 0.158763, loss_ce: 0.077356
2021-12-10 10:36:15,058 iteration 725 : loss : 0.077623, loss_ce: 0.026424
2021-12-10 10:36:16,603 iteration 726 : loss : 0.115664, loss_ce: 0.046550
2021-12-10 10:36:18,077 iteration 727 : loss : 0.073264, loss_ce: 0.028550
2021-12-10 10:36:19,661 iteration 728 : loss : 0.103786, loss_ce: 0.043759
2021-12-10 10:36:21,254 iteration 729 : loss : 0.068708, loss_ce: 0.031219
2021-12-10 10:36:22,818 iteration 730 : loss : 0.096626, loss_ce: 0.039196
2021-12-10 10:36:24,279 iteration 731 : loss : 0.054675, loss_ce: 0.023042
 11%|███▏                          | 43/400 [20:35<2:46:29, 27.98s/it]2021-12-10 10:36:25,803 iteration 732 : loss : 0.084015, loss_ce: 0.039391
2021-12-10 10:36:27,262 iteration 733 : loss : 0.095325, loss_ce: 0.046628
2021-12-10 10:36:28,857 iteration 734 : loss : 0.072186, loss_ce: 0.029766
2021-12-10 10:36:30,392 iteration 735 : loss : 0.105795, loss_ce: 0.045602
2021-12-10 10:36:31,904 iteration 736 : loss : 0.081301, loss_ce: 0.035521
2021-12-10 10:36:33,584 iteration 737 : loss : 0.089086, loss_ce: 0.040794
2021-12-10 10:36:35,047 iteration 738 : loss : 0.077451, loss_ce: 0.033755
2021-12-10 10:36:36,630 iteration 739 : loss : 0.108707, loss_ce: 0.035974
2021-12-10 10:36:38,159 iteration 740 : loss : 0.100454, loss_ce: 0.038605
2021-12-10 10:36:39,673 iteration 741 : loss : 0.084568, loss_ce: 0.033352
2021-12-10 10:36:41,135 iteration 742 : loss : 0.102185, loss_ce: 0.050645
2021-12-10 10:36:42,686 iteration 743 : loss : 0.088393, loss_ce: 0.034415
2021-12-10 10:36:44,270 iteration 744 : loss : 0.091005, loss_ce: 0.035256
2021-12-10 10:36:45,780 iteration 745 : loss : 0.130476, loss_ce: 0.033167
2021-12-10 10:36:47,294 iteration 746 : loss : 0.100809, loss_ce: 0.038947
2021-12-10 10:36:48,802 iteration 747 : loss : 0.080670, loss_ce: 0.033568
2021-12-10 10:36:50,298 iteration 748 : loss : 0.079237, loss_ce: 0.035738
 11%|███▎                          | 44/400 [21:01<2:42:33, 27.40s/it]2021-12-10 10:36:51,850 iteration 749 : loss : 0.173565, loss_ce: 0.028455
2021-12-10 10:36:53,379 iteration 750 : loss : 0.066806, loss_ce: 0.023311
2021-12-10 10:36:54,934 iteration 751 : loss : 0.063822, loss_ce: 0.020421
2021-12-10 10:36:56,458 iteration 752 : loss : 0.137626, loss_ce: 0.062416
2021-12-10 10:36:57,942 iteration 753 : loss : 0.115773, loss_ce: 0.050434
2021-12-10 10:36:59,434 iteration 754 : loss : 0.114638, loss_ce: 0.041114
2021-12-10 10:37:00,878 iteration 755 : loss : 0.121099, loss_ce: 0.059278
2021-12-10 10:37:02,335 iteration 756 : loss : 0.062897, loss_ce: 0.025199
2021-12-10 10:37:03,861 iteration 757 : loss : 0.124267, loss_ce: 0.061552
2021-12-10 10:37:05,484 iteration 758 : loss : 0.088104, loss_ce: 0.039077
2021-12-10 10:37:07,162 iteration 759 : loss : 0.137426, loss_ce: 0.060068
2021-12-10 10:37:08,681 iteration 760 : loss : 0.132841, loss_ce: 0.088497
2021-12-10 10:37:10,239 iteration 761 : loss : 0.123292, loss_ce: 0.056365
2021-12-10 10:37:11,819 iteration 762 : loss : 0.139678, loss_ce: 0.058628
2021-12-10 10:37:13,433 iteration 763 : loss : 0.128318, loss_ce: 0.060591
2021-12-10 10:37:14,948 iteration 764 : loss : 0.135611, loss_ce: 0.061552
2021-12-10 10:37:14,948 Training Data Eval:
2021-12-10 10:37:22,686   Average segmentation loss on training set: 0.1103
2021-12-10 10:37:22,687 Validation Data Eval:
2021-12-10 10:37:25,337   Average segmentation loss on validation set: 0.1270
2021-12-10 10:37:31,109 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:37:32,860 iteration 765 : loss : 0.150394, loss_ce: 0.067250
 11%|███▍                          | 45/400 [21:44<3:09:01, 31.95s/it]2021-12-10 10:37:34,507 iteration 766 : loss : 0.138068, loss_ce: 0.058336
2021-12-10 10:37:36,072 iteration 767 : loss : 0.122598, loss_ce: 0.048766
2021-12-10 10:37:37,623 iteration 768 : loss : 0.130936, loss_ce: 0.047931
2021-12-10 10:37:39,200 iteration 769 : loss : 0.126029, loss_ce: 0.055741
2021-12-10 10:37:40,647 iteration 770 : loss : 0.101184, loss_ce: 0.043745
2021-12-10 10:37:42,188 iteration 771 : loss : 0.148656, loss_ce: 0.042543
2021-12-10 10:37:43,741 iteration 772 : loss : 0.077263, loss_ce: 0.029544
2021-12-10 10:37:45,300 iteration 773 : loss : 0.114518, loss_ce: 0.030723
2021-12-10 10:37:46,946 iteration 774 : loss : 0.112707, loss_ce: 0.046856
2021-12-10 10:37:48,459 iteration 775 : loss : 0.138139, loss_ce: 0.069731
2021-12-10 10:37:49,954 iteration 776 : loss : 0.095069, loss_ce: 0.039063
2021-12-10 10:37:51,676 iteration 777 : loss : 0.138269, loss_ce: 0.068622
2021-12-10 10:37:53,150 iteration 778 : loss : 0.129027, loss_ce: 0.040768
2021-12-10 10:37:54,762 iteration 779 : loss : 0.118691, loss_ce: 0.054792
2021-12-10 10:37:56,375 iteration 780 : loss : 0.107916, loss_ce: 0.043904
2021-12-10 10:37:57,881 iteration 781 : loss : 0.104739, loss_ce: 0.051493
2021-12-10 10:37:59,343 iteration 782 : loss : 0.093044, loss_ce: 0.048824
 12%|███▍                          | 46/400 [22:10<2:58:48, 30.31s/it]2021-12-10 10:38:00,931 iteration 783 : loss : 0.114253, loss_ce: 0.055857
2021-12-10 10:38:02,442 iteration 784 : loss : 0.127005, loss_ce: 0.046418
2021-12-10 10:38:03,999 iteration 785 : loss : 0.124010, loss_ce: 0.057147
2021-12-10 10:38:05,538 iteration 786 : loss : 0.136504, loss_ce: 0.050943
2021-12-10 10:38:07,073 iteration 787 : loss : 0.098846, loss_ce: 0.035905
2021-12-10 10:38:08,692 iteration 788 : loss : 0.110632, loss_ce: 0.049640
2021-12-10 10:38:10,153 iteration 789 : loss : 0.123007, loss_ce: 0.046887
2021-12-10 10:38:11,753 iteration 790 : loss : 0.124800, loss_ce: 0.046623
2021-12-10 10:38:13,296 iteration 791 : loss : 0.069120, loss_ce: 0.027237
2021-12-10 10:38:14,791 iteration 792 : loss : 0.096281, loss_ce: 0.044015
2021-12-10 10:38:16,410 iteration 793 : loss : 0.106608, loss_ce: 0.054575
2021-12-10 10:38:17,862 iteration 794 : loss : 0.065163, loss_ce: 0.027643
2021-12-10 10:38:19,344 iteration 795 : loss : 0.093959, loss_ce: 0.037624
2021-12-10 10:38:20,827 iteration 796 : loss : 0.097354, loss_ce: 0.047700
2021-12-10 10:38:22,407 iteration 797 : loss : 0.142012, loss_ce: 0.057629
2021-12-10 10:38:23,929 iteration 798 : loss : 0.118591, loss_ce: 0.040715
2021-12-10 10:38:25,396 iteration 799 : loss : 0.101348, loss_ce: 0.048345
 12%|███▌                          | 47/400 [22:36<2:50:46, 29.03s/it]2021-12-10 10:38:27,087 iteration 800 : loss : 0.111102, loss_ce: 0.038289
2021-12-10 10:38:28,656 iteration 801 : loss : 0.087934, loss_ce: 0.037165
2021-12-10 10:38:30,206 iteration 802 : loss : 0.094945, loss_ce: 0.032556
2021-12-10 10:38:31,771 iteration 803 : loss : 0.104929, loss_ce: 0.060399
2021-12-10 10:38:33,411 iteration 804 : loss : 0.204110, loss_ce: 0.104275
2021-12-10 10:38:35,120 iteration 805 : loss : 0.075843, loss_ce: 0.025156
2021-12-10 10:38:36,642 iteration 806 : loss : 0.099716, loss_ce: 0.049270
2021-12-10 10:38:38,137 iteration 807 : loss : 0.079785, loss_ce: 0.031570
2021-12-10 10:38:39,723 iteration 808 : loss : 0.107271, loss_ce: 0.050693
2021-12-10 10:38:41,273 iteration 809 : loss : 0.101861, loss_ce: 0.041372
2021-12-10 10:38:42,775 iteration 810 : loss : 0.111517, loss_ce: 0.040769
2021-12-10 10:38:44,247 iteration 811 : loss : 0.122467, loss_ce: 0.069423
2021-12-10 10:38:45,758 iteration 812 : loss : 0.088598, loss_ce: 0.043187
2021-12-10 10:38:47,293 iteration 813 : loss : 0.125068, loss_ce: 0.038426
2021-12-10 10:38:48,951 iteration 814 : loss : 0.111854, loss_ce: 0.038877
2021-12-10 10:38:50,560 iteration 815 : loss : 0.126583, loss_ce: 0.060680
2021-12-10 10:38:52,114 iteration 816 : loss : 0.085581, loss_ce: 0.037548
 12%|███▌                          | 48/400 [23:03<2:46:14, 28.34s/it]2021-12-10 10:38:53,702 iteration 817 : loss : 0.094881, loss_ce: 0.040682
2021-12-10 10:38:55,178 iteration 818 : loss : 0.083810, loss_ce: 0.034359
2021-12-10 10:38:56,709 iteration 819 : loss : 0.074363, loss_ce: 0.027565
2021-12-10 10:38:58,172 iteration 820 : loss : 0.080460, loss_ce: 0.036345
2021-12-10 10:38:59,763 iteration 821 : loss : 0.086000, loss_ce: 0.032320
2021-12-10 10:39:01,330 iteration 822 : loss : 0.118629, loss_ce: 0.042304
2021-12-10 10:39:02,814 iteration 823 : loss : 0.073372, loss_ce: 0.027224
2021-12-10 10:39:04,297 iteration 824 : loss : 0.100503, loss_ce: 0.039942
2021-12-10 10:39:05,823 iteration 825 : loss : 0.080956, loss_ce: 0.031956
2021-12-10 10:39:07,338 iteration 826 : loss : 0.122847, loss_ce: 0.034355
2021-12-10 10:39:08,861 iteration 827 : loss : 0.164466, loss_ce: 0.059546
2021-12-10 10:39:10,388 iteration 828 : loss : 0.098832, loss_ce: 0.035998
2021-12-10 10:39:11,938 iteration 829 : loss : 0.115252, loss_ce: 0.048649
2021-12-10 10:39:13,522 iteration 830 : loss : 0.071307, loss_ce: 0.027834
2021-12-10 10:39:15,050 iteration 831 : loss : 0.134633, loss_ce: 0.061541
2021-12-10 10:39:16,558 iteration 832 : loss : 0.058487, loss_ce: 0.020250
2021-12-10 10:39:18,145 iteration 833 : loss : 0.117363, loss_ce: 0.061569
 12%|███▋                          | 49/400 [23:29<2:41:43, 27.65s/it]2021-12-10 10:39:19,734 iteration 834 : loss : 0.083703, loss_ce: 0.036930
2021-12-10 10:39:21,171 iteration 835 : loss : 0.122841, loss_ce: 0.041866
2021-12-10 10:39:22,703 iteration 836 : loss : 0.072726, loss_ce: 0.033797
2021-12-10 10:39:24,178 iteration 837 : loss : 0.080162, loss_ce: 0.041738
2021-12-10 10:39:25,631 iteration 838 : loss : 0.080679, loss_ce: 0.032470
2021-12-10 10:39:27,183 iteration 839 : loss : 0.116469, loss_ce: 0.051071
2021-12-10 10:39:28,705 iteration 840 : loss : 0.105580, loss_ce: 0.040497
2021-12-10 10:39:30,194 iteration 841 : loss : 0.097356, loss_ce: 0.042776
2021-12-10 10:39:31,712 iteration 842 : loss : 0.088511, loss_ce: 0.039052
2021-12-10 10:39:33,347 iteration 843 : loss : 0.092993, loss_ce: 0.036686
2021-12-10 10:39:34,864 iteration 844 : loss : 0.107745, loss_ce: 0.039022
2021-12-10 10:39:36,421 iteration 845 : loss : 0.116937, loss_ce: 0.044140
2021-12-10 10:39:38,076 iteration 846 : loss : 0.073311, loss_ce: 0.037045
2021-12-10 10:39:39,625 iteration 847 : loss : 0.079071, loss_ce: 0.033212
2021-12-10 10:39:41,066 iteration 848 : loss : 0.079129, loss_ce: 0.034939
2021-12-10 10:39:42,601 iteration 849 : loss : 0.083378, loss_ce: 0.032479
2021-12-10 10:39:42,601 Training Data Eval:
2021-12-10 10:39:50,338   Average segmentation loss on training set: 0.1114
2021-12-10 10:39:50,338 Validation Data Eval:
2021-12-10 10:39:52,986   Average segmentation loss on validation set: 0.1576
2021-12-10 10:39:54,578 iteration 850 : loss : 0.094916, loss_ce: 0.034193
 12%|███▊                          | 50/400 [24:06<2:56:38, 30.28s/it]2021-12-10 10:39:56,202 iteration 851 : loss : 0.084488, loss_ce: 0.034430
2021-12-10 10:39:57,725 iteration 852 : loss : 0.059679, loss_ce: 0.025166
2021-12-10 10:39:59,342 iteration 853 : loss : 0.083823, loss_ce: 0.034871
2021-12-10 10:40:00,917 iteration 854 : loss : 0.081743, loss_ce: 0.024603
2021-12-10 10:40:02,483 iteration 855 : loss : 0.083973, loss_ce: 0.037002
2021-12-10 10:40:04,076 iteration 856 : loss : 0.102492, loss_ce: 0.039091
2021-12-10 10:40:05,586 iteration 857 : loss : 0.088797, loss_ce: 0.047610
2021-12-10 10:40:07,031 iteration 858 : loss : 0.078159, loss_ce: 0.036535
2021-12-10 10:40:08,561 iteration 859 : loss : 0.091706, loss_ce: 0.030251
2021-12-10 10:40:10,041 iteration 860 : loss : 0.087469, loss_ce: 0.027225
2021-12-10 10:40:11,650 iteration 861 : loss : 0.080156, loss_ce: 0.033327
2021-12-10 10:40:13,115 iteration 862 : loss : 0.101005, loss_ce: 0.032948
2021-12-10 10:40:14,724 iteration 863 : loss : 0.133768, loss_ce: 0.069981
2021-12-10 10:40:16,306 iteration 864 : loss : 0.061512, loss_ce: 0.027657
2021-12-10 10:40:17,765 iteration 865 : loss : 0.068053, loss_ce: 0.027723
2021-12-10 10:40:19,365 iteration 866 : loss : 0.100587, loss_ce: 0.045945
2021-12-10 10:40:20,843 iteration 867 : loss : 0.052783, loss_ce: 0.020275
 13%|███▊                          | 51/400 [24:32<2:49:07, 29.08s/it]2021-12-10 10:40:22,472 iteration 868 : loss : 0.134433, loss_ce: 0.049019
2021-12-10 10:40:24,011 iteration 869 : loss : 0.087594, loss_ce: 0.036923
2021-12-10 10:40:25,457 iteration 870 : loss : 0.069088, loss_ce: 0.025286
2021-12-10 10:40:26,938 iteration 871 : loss : 0.068702, loss_ce: 0.026979
2021-12-10 10:40:28,441 iteration 872 : loss : 0.064322, loss_ce: 0.033952
2021-12-10 10:40:30,044 iteration 873 : loss : 0.071970, loss_ce: 0.023619
2021-12-10 10:40:31,494 iteration 874 : loss : 0.057978, loss_ce: 0.025953
2021-12-10 10:40:33,186 iteration 875 : loss : 0.099592, loss_ce: 0.033071
2021-12-10 10:40:34,728 iteration 876 : loss : 0.053015, loss_ce: 0.024492
2021-12-10 10:40:36,170 iteration 877 : loss : 0.054754, loss_ce: 0.020418
2021-12-10 10:40:37,776 iteration 878 : loss : 0.088237, loss_ce: 0.039642
2021-12-10 10:40:39,293 iteration 879 : loss : 0.083109, loss_ce: 0.038463
2021-12-10 10:40:40,867 iteration 880 : loss : 0.056998, loss_ce: 0.021253
2021-12-10 10:40:42,368 iteration 881 : loss : 0.096110, loss_ce: 0.045746
2021-12-10 10:40:43,955 iteration 882 : loss : 0.083725, loss_ce: 0.032895
2021-12-10 10:40:45,485 iteration 883 : loss : 0.075290, loss_ce: 0.034344
2021-12-10 10:40:47,134 iteration 884 : loss : 0.103752, loss_ce: 0.056209
 13%|███▉                          | 52/400 [24:58<2:43:47, 28.24s/it]2021-12-10 10:40:48,770 iteration 885 : loss : 0.086181, loss_ce: 0.036313
2021-12-10 10:40:50,358 iteration 886 : loss : 0.089433, loss_ce: 0.034733
2021-12-10 10:40:51,939 iteration 887 : loss : 0.109742, loss_ce: 0.046537
2021-12-10 10:40:53,501 iteration 888 : loss : 0.078155, loss_ce: 0.029503
2021-12-10 10:40:55,123 iteration 889 : loss : 0.079430, loss_ce: 0.028136
2021-12-10 10:40:56,795 iteration 890 : loss : 0.100496, loss_ce: 0.036235
2021-12-10 10:40:58,363 iteration 891 : loss : 0.053430, loss_ce: 0.020116
2021-12-10 10:40:59,917 iteration 892 : loss : 0.063403, loss_ce: 0.032220
2021-12-10 10:41:01,450 iteration 893 : loss : 0.076181, loss_ce: 0.026504
2021-12-10 10:41:03,116 iteration 894 : loss : 0.076350, loss_ce: 0.030147
2021-12-10 10:41:04,634 iteration 895 : loss : 0.096924, loss_ce: 0.030240
2021-12-10 10:41:06,249 iteration 896 : loss : 0.109578, loss_ce: 0.042901
2021-12-10 10:41:07,902 iteration 897 : loss : 0.096777, loss_ce: 0.049153
2021-12-10 10:41:09,438 iteration 898 : loss : 0.106788, loss_ce: 0.057579
2021-12-10 10:41:10,976 iteration 899 : loss : 0.083706, loss_ce: 0.037507
2021-12-10 10:41:12,463 iteration 900 : loss : 0.064736, loss_ce: 0.029218
2021-12-10 10:41:13,981 iteration 901 : loss : 0.081294, loss_ce: 0.030077
 13%|███▉                          | 53/400 [25:25<2:40:54, 27.82s/it]2021-12-10 10:41:15,617 iteration 902 : loss : 0.087757, loss_ce: 0.036507
2021-12-10 10:41:17,275 iteration 903 : loss : 0.106709, loss_ce: 0.041988
2021-12-10 10:41:18,869 iteration 904 : loss : 0.094296, loss_ce: 0.028203
2021-12-10 10:41:20,428 iteration 905 : loss : 0.106146, loss_ce: 0.047576
2021-12-10 10:41:21,966 iteration 906 : loss : 0.066063, loss_ce: 0.030390
2021-12-10 10:41:23,580 iteration 907 : loss : 0.103205, loss_ce: 0.040147
2021-12-10 10:41:25,020 iteration 908 : loss : 0.079573, loss_ce: 0.036818
2021-12-10 10:41:26,586 iteration 909 : loss : 0.094383, loss_ce: 0.040480
2021-12-10 10:41:28,058 iteration 910 : loss : 0.088546, loss_ce: 0.036485
2021-12-10 10:41:29,594 iteration 911 : loss : 0.061249, loss_ce: 0.024379
2021-12-10 10:41:31,115 iteration 912 : loss : 0.069224, loss_ce: 0.026996
2021-12-10 10:41:32,630 iteration 913 : loss : 0.083514, loss_ce: 0.028127
2021-12-10 10:41:34,156 iteration 914 : loss : 0.121749, loss_ce: 0.054967
2021-12-10 10:41:35,655 iteration 915 : loss : 0.140977, loss_ce: 0.034746
2021-12-10 10:41:37,164 iteration 916 : loss : 0.054835, loss_ce: 0.019776
2021-12-10 10:41:38,740 iteration 917 : loss : 0.097770, loss_ce: 0.038838
2021-12-10 10:41:40,327 iteration 918 : loss : 0.107740, loss_ce: 0.040666
 14%|████                          | 54/400 [25:51<2:37:51, 27.37s/it]2021-12-10 10:41:41,958 iteration 919 : loss : 0.065399, loss_ce: 0.029811
2021-12-10 10:41:43,524 iteration 920 : loss : 0.070415, loss_ce: 0.030768
2021-12-10 10:41:45,116 iteration 921 : loss : 0.082724, loss_ce: 0.033344
2021-12-10 10:41:46,730 iteration 922 : loss : 0.087346, loss_ce: 0.042375
2021-12-10 10:41:48,248 iteration 923 : loss : 0.065650, loss_ce: 0.032396
2021-12-10 10:41:49,852 iteration 924 : loss : 0.148388, loss_ce: 0.046420
2021-12-10 10:41:51,359 iteration 925 : loss : 0.066125, loss_ce: 0.023529
2021-12-10 10:41:52,957 iteration 926 : loss : 0.064379, loss_ce: 0.026905
2021-12-10 10:41:54,432 iteration 927 : loss : 0.091930, loss_ce: 0.031353
2021-12-10 10:41:55,962 iteration 928 : loss : 0.061896, loss_ce: 0.026457
2021-12-10 10:41:57,573 iteration 929 : loss : 0.089054, loss_ce: 0.033031
2021-12-10 10:41:59,140 iteration 930 : loss : 0.080647, loss_ce: 0.032822
2021-12-10 10:42:00,702 iteration 931 : loss : 0.121460, loss_ce: 0.028825
2021-12-10 10:42:02,246 iteration 932 : loss : 0.070917, loss_ce: 0.025626
2021-12-10 10:42:03,760 iteration 933 : loss : 0.095357, loss_ce: 0.037437
2021-12-10 10:42:05,307 iteration 934 : loss : 0.064450, loss_ce: 0.029764
2021-12-10 10:42:05,307 Training Data Eval:
2021-12-10 10:42:13,049   Average segmentation loss on training set: 0.0645
2021-12-10 10:42:13,049 Validation Data Eval:
2021-12-10 10:42:15,708   Average segmentation loss on validation set: 0.0984
2021-12-10 10:42:21,541 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:42:23,239 iteration 935 : loss : 0.121646, loss_ce: 0.037986
 14%|████▏                         | 55/400 [26:34<3:04:13, 32.04s/it]2021-12-10 10:42:24,811 iteration 936 : loss : 0.079526, loss_ce: 0.024962
2021-12-10 10:42:26,365 iteration 937 : loss : 0.070730, loss_ce: 0.020713
2021-12-10 10:42:27,957 iteration 938 : loss : 0.085578, loss_ce: 0.029901
2021-12-10 10:42:29,450 iteration 939 : loss : 0.067526, loss_ce: 0.022405
2021-12-10 10:42:31,013 iteration 940 : loss : 0.082552, loss_ce: 0.033789
2021-12-10 10:42:32,663 iteration 941 : loss : 0.103808, loss_ce: 0.047108
2021-12-10 10:42:34,160 iteration 942 : loss : 0.061382, loss_ce: 0.025099
2021-12-10 10:42:35,686 iteration 943 : loss : 0.066995, loss_ce: 0.030839
2021-12-10 10:42:37,164 iteration 944 : loss : 0.075887, loss_ce: 0.028585
2021-12-10 10:42:38,673 iteration 945 : loss : 0.074511, loss_ce: 0.029232
2021-12-10 10:42:40,189 iteration 946 : loss : 0.063971, loss_ce: 0.030089
2021-12-10 10:42:41,687 iteration 947 : loss : 0.063128, loss_ce: 0.022681
2021-12-10 10:42:43,169 iteration 948 : loss : 0.088934, loss_ce: 0.032044
2021-12-10 10:42:44,696 iteration 949 : loss : 0.067673, loss_ce: 0.024690
2021-12-10 10:42:46,205 iteration 950 : loss : 0.091843, loss_ce: 0.037772
2021-12-10 10:42:47,794 iteration 951 : loss : 0.058754, loss_ce: 0.027256
2021-12-10 10:42:49,285 iteration 952 : loss : 0.066339, loss_ce: 0.028104
 14%|████▏                         | 56/400 [27:00<2:53:22, 30.24s/it]2021-12-10 10:42:50,909 iteration 953 : loss : 0.072211, loss_ce: 0.025192
2021-12-10 10:42:52,504 iteration 954 : loss : 0.091310, loss_ce: 0.039164
2021-12-10 10:42:53,963 iteration 955 : loss : 0.052971, loss_ce: 0.021108
2021-12-10 10:42:55,550 iteration 956 : loss : 0.102858, loss_ce: 0.049177
2021-12-10 10:42:57,110 iteration 957 : loss : 0.068286, loss_ce: 0.024856
2021-12-10 10:42:58,683 iteration 958 : loss : 0.080782, loss_ce: 0.028280
2021-12-10 10:43:00,329 iteration 959 : loss : 0.084477, loss_ce: 0.038751
2021-12-10 10:43:02,052 iteration 960 : loss : 0.079032, loss_ce: 0.037871
2021-12-10 10:43:03,563 iteration 961 : loss : 0.124931, loss_ce: 0.036260
2021-12-10 10:43:05,040 iteration 962 : loss : 0.081731, loss_ce: 0.026588
2021-12-10 10:43:06,663 iteration 963 : loss : 0.088005, loss_ce: 0.032718
2021-12-10 10:43:08,256 iteration 964 : loss : 0.066082, loss_ce: 0.032890
2021-12-10 10:43:09,782 iteration 965 : loss : 0.058437, loss_ce: 0.026607
2021-12-10 10:43:11,323 iteration 966 : loss : 0.066304, loss_ce: 0.029124
2021-12-10 10:43:12,886 iteration 967 : loss : 0.076454, loss_ce: 0.031024
2021-12-10 10:43:14,379 iteration 968 : loss : 0.120765, loss_ce: 0.043282
2021-12-10 10:43:15,952 iteration 969 : loss : 0.059869, loss_ce: 0.023788
 14%|████▎                         | 57/400 [27:27<2:46:45, 29.17s/it]2021-12-10 10:43:17,534 iteration 970 : loss : 0.072263, loss_ce: 0.034957
2021-12-10 10:43:19,100 iteration 971 : loss : 0.098583, loss_ce: 0.030123
2021-12-10 10:43:20,580 iteration 972 : loss : 0.070175, loss_ce: 0.031844
2021-12-10 10:43:22,135 iteration 973 : loss : 0.070214, loss_ce: 0.021143
2021-12-10 10:43:23,619 iteration 974 : loss : 0.068212, loss_ce: 0.026983
2021-12-10 10:43:25,217 iteration 975 : loss : 0.100283, loss_ce: 0.038096
2021-12-10 10:43:26,734 iteration 976 : loss : 0.077280, loss_ce: 0.031082
2021-12-10 10:43:28,265 iteration 977 : loss : 0.064877, loss_ce: 0.022553
2021-12-10 10:43:29,818 iteration 978 : loss : 0.047557, loss_ce: 0.017018
2021-12-10 10:43:31,334 iteration 979 : loss : 0.111715, loss_ce: 0.055684
2021-12-10 10:43:32,862 iteration 980 : loss : 0.055926, loss_ce: 0.020045
2021-12-10 10:43:34,505 iteration 981 : loss : 0.062956, loss_ce: 0.028454
2021-12-10 10:43:36,027 iteration 982 : loss : 0.060970, loss_ce: 0.029622
2021-12-10 10:43:37,618 iteration 983 : loss : 0.139489, loss_ce: 0.054638
2021-12-10 10:43:39,085 iteration 984 : loss : 0.074363, loss_ce: 0.034339
2021-12-10 10:43:40,633 iteration 985 : loss : 0.066449, loss_ce: 0.023047
2021-12-10 10:43:42,229 iteration 986 : loss : 0.098085, loss_ce: 0.040438
 14%|████▎                         | 58/400 [27:53<2:41:20, 28.30s/it]2021-12-10 10:43:43,915 iteration 987 : loss : 0.063307, loss_ce: 0.030269
2021-12-10 10:43:45,481 iteration 988 : loss : 0.075201, loss_ce: 0.036821
2021-12-10 10:43:47,047 iteration 989 : loss : 0.139800, loss_ce: 0.069569
2021-12-10 10:43:48,597 iteration 990 : loss : 0.095717, loss_ce: 0.043673
2021-12-10 10:43:50,131 iteration 991 : loss : 0.064896, loss_ce: 0.029632
2021-12-10 10:43:51,763 iteration 992 : loss : 0.068682, loss_ce: 0.032866
2021-12-10 10:43:53,364 iteration 993 : loss : 0.080561, loss_ce: 0.032788
2021-12-10 10:43:55,034 iteration 994 : loss : 0.160525, loss_ce: 0.095913
2021-12-10 10:43:56,596 iteration 995 : loss : 0.120927, loss_ce: 0.042337
2021-12-10 10:43:58,215 iteration 996 : loss : 0.052299, loss_ce: 0.022551
2021-12-10 10:43:59,825 iteration 997 : loss : 0.151197, loss_ce: 0.078745
2021-12-10 10:44:01,325 iteration 998 : loss : 0.112569, loss_ce: 0.050538
2021-12-10 10:44:02,924 iteration 999 : loss : 0.090161, loss_ce: 0.039251
2021-12-10 10:44:04,440 iteration 1000 : loss : 0.122328, loss_ce: 0.037314
2021-12-10 10:44:05,948 iteration 1001 : loss : 0.132306, loss_ce: 0.032086
2021-12-10 10:44:07,605 iteration 1002 : loss : 0.091562, loss_ce: 0.034593
2021-12-10 10:44:09,235 iteration 1003 : loss : 0.129477, loss_ce: 0.056498
 15%|████▍                         | 59/400 [28:20<2:38:38, 27.91s/it]2021-12-10 10:44:10,844 iteration 1004 : loss : 0.158175, loss_ce: 0.066911
2021-12-10 10:44:12,369 iteration 1005 : loss : 0.087861, loss_ce: 0.034121
2021-12-10 10:44:14,012 iteration 1006 : loss : 0.089703, loss_ce: 0.037143
2021-12-10 10:44:15,521 iteration 1007 : loss : 0.073324, loss_ce: 0.036995
2021-12-10 10:44:17,012 iteration 1008 : loss : 0.157828, loss_ce: 0.070434
2021-12-10 10:44:18,511 iteration 1009 : loss : 0.078794, loss_ce: 0.030129
2021-12-10 10:44:20,015 iteration 1010 : loss : 0.071738, loss_ce: 0.028784
2021-12-10 10:44:21,614 iteration 1011 : loss : 0.084063, loss_ce: 0.037935
2021-12-10 10:44:23,141 iteration 1012 : loss : 0.063750, loss_ce: 0.025303
2021-12-10 10:44:24,626 iteration 1013 : loss : 0.071493, loss_ce: 0.026523
2021-12-10 10:44:26,179 iteration 1014 : loss : 0.100500, loss_ce: 0.036603
2021-12-10 10:44:27,661 iteration 1015 : loss : 0.065339, loss_ce: 0.028034
2021-12-10 10:44:29,210 iteration 1016 : loss : 0.090667, loss_ce: 0.037531
2021-12-10 10:44:30,661 iteration 1017 : loss : 0.068056, loss_ce: 0.027093
2021-12-10 10:44:32,101 iteration 1018 : loss : 0.081452, loss_ce: 0.030723
2021-12-10 10:44:33,623 iteration 1019 : loss : 0.086743, loss_ce: 0.038139
2021-12-10 10:44:33,704 Training Data Eval:
2021-12-10 10:44:41,451   Average segmentation loss on training set: 0.0529
2021-12-10 10:44:41,451 Validation Data Eval:
2021-12-10 10:44:44,108   Average segmentation loss on validation set: 0.0941
2021-12-10 10:44:51,772 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:44:53,279 iteration 1020 : loss : 0.058565, loss_ce: 0.020908
 15%|████▌                         | 60/400 [29:04<3:05:36, 32.75s/it]2021-12-10 10:44:54,956 iteration 1021 : loss : 0.110688, loss_ce: 0.030942
2021-12-10 10:44:56,479 iteration 1022 : loss : 0.081849, loss_ce: 0.038104
2021-12-10 10:44:58,018 iteration 1023 : loss : 0.139197, loss_ce: 0.040196
2021-12-10 10:44:59,622 iteration 1024 : loss : 0.051403, loss_ce: 0.020017
2021-12-10 10:45:01,207 iteration 1025 : loss : 0.056321, loss_ce: 0.025517
2021-12-10 10:45:02,653 iteration 1026 : loss : 0.051686, loss_ce: 0.018255
2021-12-10 10:45:04,240 iteration 1027 : loss : 0.096618, loss_ce: 0.029614
2021-12-10 10:45:05,866 iteration 1028 : loss : 0.082884, loss_ce: 0.034405
2021-12-10 10:45:07,392 iteration 1029 : loss : 0.063212, loss_ce: 0.028112
2021-12-10 10:45:08,929 iteration 1030 : loss : 0.068725, loss_ce: 0.025569
2021-12-10 10:45:10,533 iteration 1031 : loss : 0.094688, loss_ce: 0.038478
2021-12-10 10:45:12,101 iteration 1032 : loss : 0.080405, loss_ce: 0.039034
2021-12-10 10:45:13,623 iteration 1033 : loss : 0.067153, loss_ce: 0.024443
2021-12-10 10:45:15,227 iteration 1034 : loss : 0.105199, loss_ce: 0.045123
2021-12-10 10:45:16,785 iteration 1035 : loss : 0.071765, loss_ce: 0.029841
2021-12-10 10:45:18,348 iteration 1036 : loss : 0.068447, loss_ce: 0.032241
2021-12-10 10:45:19,849 iteration 1037 : loss : 0.096186, loss_ce: 0.037872
 15%|████▌                         | 61/400 [29:31<2:54:33, 30.89s/it]2021-12-10 10:45:21,462 iteration 1038 : loss : 0.049303, loss_ce: 0.019400
2021-12-10 10:45:22,998 iteration 1039 : loss : 0.077449, loss_ce: 0.037817
2021-12-10 10:45:24,568 iteration 1040 : loss : 0.093215, loss_ce: 0.039407
2021-12-10 10:45:26,121 iteration 1041 : loss : 0.071963, loss_ce: 0.032798
2021-12-10 10:45:27,692 iteration 1042 : loss : 0.061970, loss_ce: 0.024784
2021-12-10 10:45:29,232 iteration 1043 : loss : 0.100760, loss_ce: 0.032078
2021-12-10 10:45:30,802 iteration 1044 : loss : 0.073487, loss_ce: 0.027899
2021-12-10 10:45:32,245 iteration 1045 : loss : 0.062947, loss_ce: 0.030008
2021-12-10 10:45:33,745 iteration 1046 : loss : 0.101425, loss_ce: 0.025273
2021-12-10 10:45:35,340 iteration 1047 : loss : 0.108763, loss_ce: 0.042462
2021-12-10 10:45:36,890 iteration 1048 : loss : 0.091995, loss_ce: 0.031038
2021-12-10 10:45:38,444 iteration 1049 : loss : 0.103219, loss_ce: 0.038304
2021-12-10 10:45:40,042 iteration 1050 : loss : 0.090226, loss_ce: 0.030465
2021-12-10 10:45:41,589 iteration 1051 : loss : 0.074038, loss_ce: 0.028056
2021-12-10 10:45:43,137 iteration 1052 : loss : 0.116977, loss_ce: 0.044013
2021-12-10 10:45:44,607 iteration 1053 : loss : 0.083335, loss_ce: 0.026742
2021-12-10 10:45:46,233 iteration 1054 : loss : 0.067875, loss_ce: 0.030354
 16%|████▋                         | 62/400 [29:57<2:46:26, 29.55s/it]2021-12-10 10:45:47,841 iteration 1055 : loss : 0.056559, loss_ce: 0.018595
2021-12-10 10:45:49,366 iteration 1056 : loss : 0.090886, loss_ce: 0.047460
2021-12-10 10:45:50,883 iteration 1057 : loss : 0.099960, loss_ce: 0.048415
2021-12-10 10:45:52,421 iteration 1058 : loss : 0.085303, loss_ce: 0.040231
2021-12-10 10:45:53,881 iteration 1059 : loss : 0.094623, loss_ce: 0.037593
2021-12-10 10:45:55,412 iteration 1060 : loss : 0.053760, loss_ce: 0.020771
2021-12-10 10:45:56,989 iteration 1061 : loss : 0.075874, loss_ce: 0.032627
2021-12-10 10:45:58,551 iteration 1062 : loss : 0.088348, loss_ce: 0.036619
2021-12-10 10:46:00,175 iteration 1063 : loss : 0.132635, loss_ce: 0.047369
2021-12-10 10:46:01,707 iteration 1064 : loss : 0.094119, loss_ce: 0.030012
2021-12-10 10:46:03,184 iteration 1065 : loss : 0.063701, loss_ce: 0.023014
2021-12-10 10:46:04,778 iteration 1066 : loss : 0.077967, loss_ce: 0.030754
2021-12-10 10:46:06,305 iteration 1067 : loss : 0.175545, loss_ce: 0.049205
2021-12-10 10:46:07,902 iteration 1068 : loss : 0.083731, loss_ce: 0.040168
2021-12-10 10:46:09,479 iteration 1069 : loss : 0.111931, loss_ce: 0.046252
2021-12-10 10:46:11,028 iteration 1070 : loss : 0.059015, loss_ce: 0.023700
2021-12-10 10:46:12,567 iteration 1071 : loss : 0.064343, loss_ce: 0.030078
 16%|████▋                         | 63/400 [30:24<2:40:31, 28.58s/it]2021-12-10 10:46:14,282 iteration 1072 : loss : 0.056856, loss_ce: 0.019431
2021-12-10 10:46:15,816 iteration 1073 : loss : 0.139660, loss_ce: 0.032995
2021-12-10 10:46:17,341 iteration 1074 : loss : 0.073865, loss_ce: 0.028708
2021-12-10 10:46:18,918 iteration 1075 : loss : 0.072636, loss_ce: 0.026835
2021-12-10 10:46:20,409 iteration 1076 : loss : 0.067959, loss_ce: 0.024514
2021-12-10 10:46:21,944 iteration 1077 : loss : 0.058351, loss_ce: 0.019071
2021-12-10 10:46:23,551 iteration 1078 : loss : 0.122163, loss_ce: 0.058398
2021-12-10 10:46:25,057 iteration 1079 : loss : 0.062769, loss_ce: 0.021931
2021-12-10 10:46:26,549 iteration 1080 : loss : 0.049931, loss_ce: 0.024391
2021-12-10 10:46:28,120 iteration 1081 : loss : 0.068652, loss_ce: 0.022370
2021-12-10 10:46:29,697 iteration 1082 : loss : 0.076901, loss_ce: 0.039186
2021-12-10 10:46:31,299 iteration 1083 : loss : 0.083489, loss_ce: 0.034942
2021-12-10 10:46:32,827 iteration 1084 : loss : 0.086934, loss_ce: 0.045734
2021-12-10 10:46:34,453 iteration 1085 : loss : 0.085657, loss_ce: 0.030278
2021-12-10 10:46:35,974 iteration 1086 : loss : 0.067185, loss_ce: 0.030210
2021-12-10 10:46:37,508 iteration 1087 : loss : 0.074078, loss_ce: 0.029692
2021-12-10 10:46:39,092 iteration 1088 : loss : 0.062816, loss_ce: 0.028863
 16%|████▊                         | 64/400 [30:50<2:36:36, 27.96s/it]2021-12-10 10:46:40,653 iteration 1089 : loss : 0.098215, loss_ce: 0.034576
2021-12-10 10:46:42,185 iteration 1090 : loss : 0.072694, loss_ce: 0.034276
2021-12-10 10:46:43,728 iteration 1091 : loss : 0.068256, loss_ce: 0.032620
2021-12-10 10:46:45,282 iteration 1092 : loss : 0.060055, loss_ce: 0.026067
2021-12-10 10:46:46,852 iteration 1093 : loss : 0.079393, loss_ce: 0.031540
2021-12-10 10:46:48,477 iteration 1094 : loss : 0.066406, loss_ce: 0.026582
2021-12-10 10:46:49,975 iteration 1095 : loss : 0.054663, loss_ce: 0.025174
2021-12-10 10:46:51,627 iteration 1096 : loss : 0.068071, loss_ce: 0.031439
2021-12-10 10:46:53,191 iteration 1097 : loss : 0.079302, loss_ce: 0.031591
2021-12-10 10:46:54,699 iteration 1098 : loss : 0.043949, loss_ce: 0.019782
2021-12-10 10:46:56,277 iteration 1099 : loss : 0.074827, loss_ce: 0.023864
2021-12-10 10:46:57,914 iteration 1100 : loss : 0.071675, loss_ce: 0.025400
2021-12-10 10:46:59,445 iteration 1101 : loss : 0.072766, loss_ce: 0.027026
2021-12-10 10:47:01,085 iteration 1102 : loss : 0.096489, loss_ce: 0.030254
2021-12-10 10:47:02,612 iteration 1103 : loss : 0.082312, loss_ce: 0.028696
2021-12-10 10:47:04,140 iteration 1104 : loss : 0.072554, loss_ce: 0.027428
2021-12-10 10:47:04,141 Training Data Eval:
2021-12-10 10:47:11,883   Average segmentation loss on training set: 0.0766
2021-12-10 10:47:11,883 Validation Data Eval:
2021-12-10 10:47:14,545   Average segmentation loss on validation set: 0.1612
2021-12-10 10:47:16,144 iteration 1105 : loss : 0.074764, loss_ce: 0.026426
 16%|████▉                         | 65/400 [31:27<2:51:20, 30.69s/it]2021-12-10 10:47:17,694 iteration 1106 : loss : 0.080607, loss_ce: 0.029030
2021-12-10 10:47:19,215 iteration 1107 : loss : 0.061736, loss_ce: 0.031056
2021-12-10 10:47:20,770 iteration 1108 : loss : 0.086944, loss_ce: 0.022104
2021-12-10 10:47:22,261 iteration 1109 : loss : 0.055368, loss_ce: 0.023697
2021-12-10 10:47:23,805 iteration 1110 : loss : 0.070622, loss_ce: 0.032548
2021-12-10 10:47:25,324 iteration 1111 : loss : 0.056430, loss_ce: 0.023114
2021-12-10 10:47:26,853 iteration 1112 : loss : 0.073812, loss_ce: 0.032241
2021-12-10 10:47:28,358 iteration 1113 : loss : 0.073715, loss_ce: 0.024101
2021-12-10 10:47:29,961 iteration 1114 : loss : 0.075618, loss_ce: 0.034771
2021-12-10 10:47:31,629 iteration 1115 : loss : 0.071598, loss_ce: 0.035325
2021-12-10 10:47:33,233 iteration 1116 : loss : 0.098648, loss_ce: 0.032932
2021-12-10 10:47:34,903 iteration 1117 : loss : 0.073528, loss_ce: 0.029608
2021-12-10 10:47:36,505 iteration 1118 : loss : 0.105189, loss_ce: 0.035276
2021-12-10 10:47:38,030 iteration 1119 : loss : 0.057254, loss_ce: 0.023464
2021-12-10 10:47:39,544 iteration 1120 : loss : 0.071889, loss_ce: 0.021526
2021-12-10 10:47:41,107 iteration 1121 : loss : 0.081430, loss_ce: 0.023329
2021-12-10 10:47:42,659 iteration 1122 : loss : 0.086903, loss_ce: 0.039630
 16%|████▉                         | 66/400 [31:54<2:43:52, 29.44s/it]2021-12-10 10:47:44,210 iteration 1123 : loss : 0.082012, loss_ce: 0.031727
2021-12-10 10:47:45,778 iteration 1124 : loss : 0.072835, loss_ce: 0.034314
2021-12-10 10:47:47,327 iteration 1125 : loss : 0.047380, loss_ce: 0.014284
2021-12-10 10:47:48,859 iteration 1126 : loss : 0.087912, loss_ce: 0.034660
2021-12-10 10:47:50,375 iteration 1127 : loss : 0.086908, loss_ce: 0.033950
2021-12-10 10:47:51,973 iteration 1128 : loss : 0.078247, loss_ce: 0.029447
2021-12-10 10:47:53,591 iteration 1129 : loss : 0.072895, loss_ce: 0.025813
2021-12-10 10:47:55,120 iteration 1130 : loss : 0.070997, loss_ce: 0.033392
2021-12-10 10:47:56,648 iteration 1131 : loss : 0.072875, loss_ce: 0.029987
2021-12-10 10:47:58,234 iteration 1132 : loss : 0.067016, loss_ce: 0.025404
2021-12-10 10:47:59,707 iteration 1133 : loss : 0.053618, loss_ce: 0.023640
2021-12-10 10:48:01,251 iteration 1134 : loss : 0.089975, loss_ce: 0.030878
2021-12-10 10:48:02,761 iteration 1135 : loss : 0.075732, loss_ce: 0.031194
2021-12-10 10:48:04,293 iteration 1136 : loss : 0.044674, loss_ce: 0.016844
2021-12-10 10:48:05,809 iteration 1137 : loss : 0.094564, loss_ce: 0.040217
2021-12-10 10:48:07,390 iteration 1138 : loss : 0.065643, loss_ce: 0.029725
2021-12-10 10:48:08,958 iteration 1139 : loss : 0.084350, loss_ce: 0.030623
 17%|█████                         | 67/400 [32:20<2:38:09, 28.50s/it]2021-12-10 10:48:10,560 iteration 1140 : loss : 0.062407, loss_ce: 0.023537
2021-12-10 10:48:12,062 iteration 1141 : loss : 0.062890, loss_ce: 0.025448
2021-12-10 10:48:13,673 iteration 1142 : loss : 0.075304, loss_ce: 0.033411
2021-12-10 10:48:15,214 iteration 1143 : loss : 0.065610, loss_ce: 0.024709
2021-12-10 10:48:16,802 iteration 1144 : loss : 0.081182, loss_ce: 0.042633
2021-12-10 10:48:18,299 iteration 1145 : loss : 0.084978, loss_ce: 0.037430
2021-12-10 10:48:19,857 iteration 1146 : loss : 0.098890, loss_ce: 0.044842
2021-12-10 10:48:21,314 iteration 1147 : loss : 0.073049, loss_ce: 0.030944
2021-12-10 10:48:22,908 iteration 1148 : loss : 0.064821, loss_ce: 0.024291
2021-12-10 10:48:24,400 iteration 1149 : loss : 0.056095, loss_ce: 0.027213
2021-12-10 10:48:25,944 iteration 1150 : loss : 0.057790, loss_ce: 0.025564
2021-12-10 10:48:27,524 iteration 1151 : loss : 0.074491, loss_ce: 0.030453
2021-12-10 10:48:29,202 iteration 1152 : loss : 0.090546, loss_ce: 0.037107
2021-12-10 10:48:30,664 iteration 1153 : loss : 0.069998, loss_ce: 0.026049
2021-12-10 10:48:32,250 iteration 1154 : loss : 0.080358, loss_ce: 0.028319
2021-12-10 10:48:33,749 iteration 1155 : loss : 0.102956, loss_ce: 0.032263
2021-12-10 10:48:35,354 iteration 1156 : loss : 0.077076, loss_ce: 0.040237
 17%|█████                         | 68/400 [32:46<2:34:10, 27.86s/it]2021-12-10 10:48:36,930 iteration 1157 : loss : 0.113951, loss_ce: 0.033300
2021-12-10 10:48:38,495 iteration 1158 : loss : 0.071358, loss_ce: 0.027463
2021-12-10 10:48:40,120 iteration 1159 : loss : 0.052275, loss_ce: 0.017580
2021-12-10 10:48:41,805 iteration 1160 : loss : 0.115001, loss_ce: 0.056092
2021-12-10 10:48:43,416 iteration 1161 : loss : 0.048686, loss_ce: 0.021281
2021-12-10 10:48:44,997 iteration 1162 : loss : 0.082050, loss_ce: 0.030587
2021-12-10 10:48:46,519 iteration 1163 : loss : 0.065450, loss_ce: 0.031166
2021-12-10 10:48:48,059 iteration 1164 : loss : 0.079059, loss_ce: 0.031298
2021-12-10 10:48:49,606 iteration 1165 : loss : 0.068019, loss_ce: 0.029748
2021-12-10 10:48:51,232 iteration 1166 : loss : 0.054460, loss_ce: 0.018425
2021-12-10 10:48:52,742 iteration 1167 : loss : 0.057302, loss_ce: 0.026294
2021-12-10 10:48:54,278 iteration 1168 : loss : 0.065957, loss_ce: 0.026382
2021-12-10 10:48:55,790 iteration 1169 : loss : 0.064749, loss_ce: 0.026804
2021-12-10 10:48:57,305 iteration 1170 : loss : 0.087269, loss_ce: 0.038989
2021-12-10 10:48:58,870 iteration 1171 : loss : 0.078551, loss_ce: 0.031121
2021-12-10 10:49:00,426 iteration 1172 : loss : 0.081211, loss_ce: 0.042375
2021-12-10 10:49:02,009 iteration 1173 : loss : 0.070570, loss_ce: 0.026640
 17%|█████▏                        | 69/400 [33:13<2:31:42, 27.50s/it]2021-12-10 10:49:03,583 iteration 1174 : loss : 0.078019, loss_ce: 0.024645
2021-12-10 10:49:05,137 iteration 1175 : loss : 0.070010, loss_ce: 0.027038
2021-12-10 10:49:06,673 iteration 1176 : loss : 0.068450, loss_ce: 0.028228
2021-12-10 10:49:08,174 iteration 1177 : loss : 0.064472, loss_ce: 0.025833
2021-12-10 10:49:09,760 iteration 1178 : loss : 0.047817, loss_ce: 0.015188
2021-12-10 10:49:11,405 iteration 1179 : loss : 0.069617, loss_ce: 0.031541
2021-12-10 10:49:12,925 iteration 1180 : loss : 0.074698, loss_ce: 0.036426
2021-12-10 10:49:14,466 iteration 1181 : loss : 0.083822, loss_ce: 0.031282
2021-12-10 10:49:16,027 iteration 1182 : loss : 0.061195, loss_ce: 0.025571
2021-12-10 10:49:17,514 iteration 1183 : loss : 0.062392, loss_ce: 0.026960
2021-12-10 10:49:19,012 iteration 1184 : loss : 0.040540, loss_ce: 0.018975
2021-12-10 10:49:20,595 iteration 1185 : loss : 0.061230, loss_ce: 0.022751
2021-12-10 10:49:22,099 iteration 1186 : loss : 0.059794, loss_ce: 0.028600
2021-12-10 10:49:23,707 iteration 1187 : loss : 0.070324, loss_ce: 0.028164
2021-12-10 10:49:25,205 iteration 1188 : loss : 0.102392, loss_ce: 0.037566
2021-12-10 10:49:26,812 iteration 1189 : loss : 0.059490, loss_ce: 0.026029
2021-12-10 10:49:26,812 Training Data Eval:
2021-12-10 10:49:34,556   Average segmentation loss on training set: 0.1481
2021-12-10 10:49:34,556 Validation Data Eval:
2021-12-10 10:49:37,217   Average segmentation loss on validation set: 0.1585
2021-12-10 10:49:38,771 iteration 1190 : loss : 0.074905, loss_ce: 0.034311
 18%|█████▎                        | 70/400 [33:50<2:46:32, 30.28s/it]2021-12-10 10:49:40,430 iteration 1191 : loss : 0.083414, loss_ce: 0.033553
2021-12-10 10:49:41,928 iteration 1192 : loss : 0.049647, loss_ce: 0.022601
2021-12-10 10:49:43,559 iteration 1193 : loss : 0.063275, loss_ce: 0.021274
2021-12-10 10:49:45,092 iteration 1194 : loss : 0.067080, loss_ce: 0.025038
2021-12-10 10:49:46,579 iteration 1195 : loss : 0.051771, loss_ce: 0.024324
2021-12-10 10:49:48,066 iteration 1196 : loss : 0.052265, loss_ce: 0.021825
2021-12-10 10:49:49,526 iteration 1197 : loss : 0.059295, loss_ce: 0.021927
2021-12-10 10:49:51,111 iteration 1198 : loss : 0.058323, loss_ce: 0.028576
2021-12-10 10:49:52,663 iteration 1199 : loss : 0.058570, loss_ce: 0.023150
2021-12-10 10:49:54,185 iteration 1200 : loss : 0.087964, loss_ce: 0.029246
2021-12-10 10:49:55,669 iteration 1201 : loss : 0.056970, loss_ce: 0.025430
2021-12-10 10:49:57,239 iteration 1202 : loss : 0.075973, loss_ce: 0.031120
2021-12-10 10:49:58,785 iteration 1203 : loss : 0.072570, loss_ce: 0.024087
2021-12-10 10:50:00,329 iteration 1204 : loss : 0.071126, loss_ce: 0.022452
2021-12-10 10:50:01,887 iteration 1205 : loss : 0.114411, loss_ce: 0.051854
2021-12-10 10:50:03,444 iteration 1206 : loss : 0.073094, loss_ce: 0.030232
2021-12-10 10:50:05,050 iteration 1207 : loss : 0.049263, loss_ce: 0.017145
 18%|█████▎                        | 71/400 [34:16<2:39:27, 29.08s/it]2021-12-10 10:50:06,676 iteration 1208 : loss : 0.069837, loss_ce: 0.030783
2021-12-10 10:50:08,235 iteration 1209 : loss : 0.062622, loss_ce: 0.024356
2021-12-10 10:50:09,786 iteration 1210 : loss : 0.058585, loss_ce: 0.022987
2021-12-10 10:50:11,279 iteration 1211 : loss : 0.047758, loss_ce: 0.019489
2021-12-10 10:50:12,761 iteration 1212 : loss : 0.092643, loss_ce: 0.029625
2021-12-10 10:50:14,421 iteration 1213 : loss : 0.051957, loss_ce: 0.021086
2021-12-10 10:50:15,967 iteration 1214 : loss : 0.067457, loss_ce: 0.026708
2021-12-10 10:50:17,511 iteration 1215 : loss : 0.080120, loss_ce: 0.029208
2021-12-10 10:50:19,189 iteration 1216 : loss : 0.060161, loss_ce: 0.022755
2021-12-10 10:50:20,736 iteration 1217 : loss : 0.039952, loss_ce: 0.014190
2021-12-10 10:50:22,240 iteration 1218 : loss : 0.058078, loss_ce: 0.021891
2021-12-10 10:50:23,707 iteration 1219 : loss : 0.052215, loss_ce: 0.016978
2021-12-10 10:50:25,236 iteration 1220 : loss : 0.079886, loss_ce: 0.028787
2021-12-10 10:50:26,733 iteration 1221 : loss : 0.067603, loss_ce: 0.028092
2021-12-10 10:50:28,338 iteration 1222 : loss : 0.070390, loss_ce: 0.023049
2021-12-10 10:50:29,879 iteration 1223 : loss : 0.050882, loss_ce: 0.023766
2021-12-10 10:50:31,469 iteration 1224 : loss : 0.091510, loss_ce: 0.039115
 18%|█████▍                        | 72/400 [34:42<2:34:36, 28.28s/it]2021-12-10 10:50:33,035 iteration 1225 : loss : 0.072777, loss_ce: 0.024697
2021-12-10 10:50:34,616 iteration 1226 : loss : 0.080365, loss_ce: 0.038319
2021-12-10 10:50:36,101 iteration 1227 : loss : 0.058553, loss_ce: 0.021615
2021-12-10 10:50:37,622 iteration 1228 : loss : 0.056091, loss_ce: 0.021523
2021-12-10 10:50:39,089 iteration 1229 : loss : 0.062267, loss_ce: 0.019122
2021-12-10 10:50:40,589 iteration 1230 : loss : 0.061922, loss_ce: 0.026242
2021-12-10 10:50:42,166 iteration 1231 : loss : 0.054858, loss_ce: 0.025662
2021-12-10 10:50:43,665 iteration 1232 : loss : 0.065693, loss_ce: 0.031500
2021-12-10 10:50:45,167 iteration 1233 : loss : 0.043262, loss_ce: 0.019290
2021-12-10 10:50:46,744 iteration 1234 : loss : 0.064117, loss_ce: 0.027717
2021-12-10 10:50:48,316 iteration 1235 : loss : 0.108881, loss_ce: 0.032320
2021-12-10 10:50:49,810 iteration 1236 : loss : 0.062901, loss_ce: 0.024509
2021-12-10 10:50:51,256 iteration 1237 : loss : 0.089228, loss_ce: 0.040830
2021-12-10 10:50:52,847 iteration 1238 : loss : 0.050808, loss_ce: 0.017088
2021-12-10 10:50:54,327 iteration 1239 : loss : 0.050877, loss_ce: 0.018485
2021-12-10 10:50:55,821 iteration 1240 : loss : 0.049164, loss_ce: 0.019322
2021-12-10 10:50:57,314 iteration 1241 : loss : 0.066240, loss_ce: 0.031313
 18%|█████▍                        | 73/400 [35:08<2:30:09, 27.55s/it]2021-12-10 10:50:58,927 iteration 1242 : loss : 0.092148, loss_ce: 0.050555
2021-12-10 10:51:00,436 iteration 1243 : loss : 0.086539, loss_ce: 0.027143
2021-12-10 10:51:01,943 iteration 1244 : loss : 0.062777, loss_ce: 0.024270
2021-12-10 10:51:03,498 iteration 1245 : loss : 0.063398, loss_ce: 0.023614
2021-12-10 10:51:05,051 iteration 1246 : loss : 0.068765, loss_ce: 0.026931
2021-12-10 10:51:06,544 iteration 1247 : loss : 0.049428, loss_ce: 0.020191
2021-12-10 10:51:08,103 iteration 1248 : loss : 0.094047, loss_ce: 0.031459
2021-12-10 10:51:09,592 iteration 1249 : loss : 0.036951, loss_ce: 0.012673
2021-12-10 10:51:11,241 iteration 1250 : loss : 0.061939, loss_ce: 0.025145
2021-12-10 10:51:12,914 iteration 1251 : loss : 0.077675, loss_ce: 0.040605
2021-12-10 10:51:14,491 iteration 1252 : loss : 0.056047, loss_ce: 0.022296
2021-12-10 10:51:15,950 iteration 1253 : loss : 0.049639, loss_ce: 0.017872
2021-12-10 10:51:17,486 iteration 1254 : loss : 0.044429, loss_ce: 0.023284
2021-12-10 10:51:19,047 iteration 1255 : loss : 0.066278, loss_ce: 0.024559
2021-12-10 10:51:20,571 iteration 1256 : loss : 0.057928, loss_ce: 0.026098
2021-12-10 10:51:22,105 iteration 1257 : loss : 0.069483, loss_ce: 0.020225
2021-12-10 10:51:23,666 iteration 1258 : loss : 0.043540, loss_ce: 0.017936
 18%|█████▌                        | 74/400 [35:35<2:27:43, 27.19s/it]2021-12-10 10:51:25,205 iteration 1259 : loss : 0.047262, loss_ce: 0.020500
2021-12-10 10:51:26,811 iteration 1260 : loss : 0.051710, loss_ce: 0.021906
2021-12-10 10:51:28,327 iteration 1261 : loss : 0.045218, loss_ce: 0.014788
2021-12-10 10:51:29,962 iteration 1262 : loss : 0.069222, loss_ce: 0.024133
2021-12-10 10:51:31,611 iteration 1263 : loss : 0.125572, loss_ce: 0.052461
2021-12-10 10:51:33,142 iteration 1264 : loss : 0.045334, loss_ce: 0.020295
2021-12-10 10:51:34,745 iteration 1265 : loss : 0.058481, loss_ce: 0.031489
2021-12-10 10:51:36,345 iteration 1266 : loss : 0.070878, loss_ce: 0.027846
2021-12-10 10:51:37,908 iteration 1267 : loss : 0.071611, loss_ce: 0.029879
2021-12-10 10:51:39,416 iteration 1268 : loss : 0.092581, loss_ce: 0.035892
2021-12-10 10:51:41,042 iteration 1269 : loss : 0.106668, loss_ce: 0.031462
2021-12-10 10:51:42,621 iteration 1270 : loss : 0.061456, loss_ce: 0.029147
2021-12-10 10:51:44,165 iteration 1271 : loss : 0.068056, loss_ce: 0.031397
2021-12-10 10:51:45,614 iteration 1272 : loss : 0.062246, loss_ce: 0.023205
2021-12-10 10:51:47,125 iteration 1273 : loss : 0.054924, loss_ce: 0.022180
2021-12-10 10:51:48,668 iteration 1274 : loss : 0.059726, loss_ce: 0.019189
2021-12-10 10:51:48,669 Training Data Eval:
2021-12-10 10:51:56,415   Average segmentation loss on training set: 0.0465
2021-12-10 10:51:56,416 Validation Data Eval:
2021-12-10 10:51:59,075   Average segmentation loss on validation set: 0.0817
2021-12-10 10:52:04,807 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 10:52:06,382 iteration 1275 : loss : 0.067809, loss_ce: 0.023958
 19%|█████▋                        | 75/400 [36:17<2:52:30, 31.85s/it]2021-12-10 10:52:07,880 iteration 1276 : loss : 0.053002, loss_ce: 0.022021
2021-12-10 10:52:09,525 iteration 1277 : loss : 0.064457, loss_ce: 0.026980
2021-12-10 10:52:11,011 iteration 1278 : loss : 0.042413, loss_ce: 0.014798
2021-12-10 10:52:12,641 iteration 1279 : loss : 0.059675, loss_ce: 0.018198
2021-12-10 10:52:14,212 iteration 1280 : loss : 0.076784, loss_ce: 0.035514
2021-12-10 10:52:15,770 iteration 1281 : loss : 0.074255, loss_ce: 0.031710
2021-12-10 10:52:17,248 iteration 1282 : loss : 0.038182, loss_ce: 0.016644
2021-12-10 10:52:18,839 iteration 1283 : loss : 0.101775, loss_ce: 0.033397
2021-12-10 10:52:20,325 iteration 1284 : loss : 0.059682, loss_ce: 0.023191
2021-12-10 10:52:21,939 iteration 1285 : loss : 0.053994, loss_ce: 0.017228
2021-12-10 10:52:23,569 iteration 1286 : loss : 0.125958, loss_ce: 0.036189
2021-12-10 10:52:25,085 iteration 1287 : loss : 0.047347, loss_ce: 0.024843
2021-12-10 10:52:26,584 iteration 1288 : loss : 0.071392, loss_ce: 0.033109
2021-12-10 10:52:28,118 iteration 1289 : loss : 0.081705, loss_ce: 0.031995
2021-12-10 10:52:29,700 iteration 1290 : loss : 0.080384, loss_ce: 0.028294
2021-12-10 10:52:31,290 iteration 1291 : loss : 0.080139, loss_ce: 0.034817
2021-12-10 10:52:32,893 iteration 1292 : loss : 0.078617, loss_ce: 0.030998
 19%|█████▋                        | 76/400 [36:44<2:43:20, 30.25s/it]2021-12-10 10:52:34,520 iteration 1293 : loss : 0.065954, loss_ce: 0.025622
2021-12-10 10:52:36,109 iteration 1294 : loss : 0.064810, loss_ce: 0.024055
2021-12-10 10:52:37,740 iteration 1295 : loss : 0.065392, loss_ce: 0.019804
2021-12-10 10:52:39,311 iteration 1296 : loss : 0.079734, loss_ce: 0.028266
2021-12-10 10:52:40,796 iteration 1297 : loss : 0.081004, loss_ce: 0.045191
2021-12-10 10:52:42,255 iteration 1298 : loss : 0.045053, loss_ce: 0.016947
2021-12-10 10:52:43,784 iteration 1299 : loss : 0.054026, loss_ce: 0.025783
2021-12-10 10:52:45,321 iteration 1300 : loss : 0.071083, loss_ce: 0.019113
2021-12-10 10:52:46,898 iteration 1301 : loss : 0.033687, loss_ce: 0.013822
2021-12-10 10:52:48,412 iteration 1302 : loss : 0.061016, loss_ce: 0.028315
2021-12-10 10:52:49,928 iteration 1303 : loss : 0.055967, loss_ce: 0.023388
2021-12-10 10:52:51,487 iteration 1304 : loss : 0.055458, loss_ce: 0.020238
2021-12-10 10:52:53,027 iteration 1305 : loss : 0.079406, loss_ce: 0.032131
2021-12-10 10:52:54,614 iteration 1306 : loss : 0.103124, loss_ce: 0.032667
2021-12-10 10:52:56,206 iteration 1307 : loss : 0.045760, loss_ce: 0.022618
2021-12-10 10:52:57,771 iteration 1308 : loss : 0.111999, loss_ce: 0.032835
2021-12-10 10:52:59,247 iteration 1309 : loss : 0.056525, loss_ce: 0.019615
 19%|█████▊                        | 77/400 [37:10<2:36:33, 29.08s/it]2021-12-10 10:53:00,926 iteration 1310 : loss : 0.075671, loss_ce: 0.024651
2021-12-10 10:53:02,443 iteration 1311 : loss : 0.054731, loss_ce: 0.024189
2021-12-10 10:53:03,951 iteration 1312 : loss : 0.052564, loss_ce: 0.019275
2021-12-10 10:53:05,466 iteration 1313 : loss : 0.070546, loss_ce: 0.018712
2021-12-10 10:53:07,014 iteration 1314 : loss : 0.060846, loss_ce: 0.024928
2021-12-10 10:53:08,598 iteration 1315 : loss : 0.090352, loss_ce: 0.032222
2021-12-10 10:53:10,268 iteration 1316 : loss : 0.066912, loss_ce: 0.029515
2021-12-10 10:53:11,797 iteration 1317 : loss : 0.068489, loss_ce: 0.038214
2021-12-10 10:53:13,429 iteration 1318 : loss : 0.180172, loss_ce: 0.027858
2021-12-10 10:53:15,011 iteration 1319 : loss : 0.056666, loss_ce: 0.025221
2021-12-10 10:53:16,524 iteration 1320 : loss : 0.043340, loss_ce: 0.017087
2021-12-10 10:53:18,082 iteration 1321 : loss : 0.109619, loss_ce: 0.031667
2021-12-10 10:53:19,564 iteration 1322 : loss : 0.062862, loss_ce: 0.029567
2021-12-10 10:53:21,094 iteration 1323 : loss : 0.072157, loss_ce: 0.026418
2021-12-10 10:53:22,654 iteration 1324 : loss : 0.046571, loss_ce: 0.019977
2021-12-10 10:53:24,249 iteration 1325 : loss : 0.078938, loss_ce: 0.028439
2021-12-10 10:53:25,694 iteration 1326 : loss : 0.066491, loss_ce: 0.024899
 20%|█████▊                        | 78/400 [37:37<2:31:49, 28.29s/it]2021-12-10 10:53:27,250 iteration 1327 : loss : 0.073533, loss_ce: 0.025980
2021-12-10 10:53:28,826 iteration 1328 : loss : 0.081719, loss_ce: 0.043292
2021-12-10 10:53:30,371 iteration 1329 : loss : 0.043523, loss_ce: 0.018070
2021-12-10 10:53:31,877 iteration 1330 : loss : 0.099176, loss_ce: 0.028412
2021-12-10 10:53:33,353 iteration 1331 : loss : 0.057688, loss_ce: 0.028640
2021-12-10 10:53:34,844 iteration 1332 : loss : 0.049855, loss_ce: 0.015879
2021-12-10 10:53:36,371 iteration 1333 : loss : 0.048152, loss_ce: 0.014938
2021-12-10 10:53:37,903 iteration 1334 : loss : 0.084710, loss_ce: 0.032629
2021-12-10 10:53:39,409 iteration 1335 : loss : 0.048039, loss_ce: 0.016075
2021-12-10 10:53:40,921 iteration 1336 : loss : 0.052860, loss_ce: 0.022561
2021-12-10 10:53:42,523 iteration 1337 : loss : 0.089055, loss_ce: 0.042176
2021-12-10 10:53:44,106 iteration 1338 : loss : 0.078863, loss_ce: 0.026151
2021-12-10 10:53:45,672 iteration 1339 : loss : 0.064049, loss_ce: 0.029482
2021-12-10 10:53:47,242 iteration 1340 : loss : 0.056963, loss_ce: 0.025677
2021-12-10 10:53:48,790 iteration 1341 : loss : 0.081075, loss_ce: 0.034628
2021-12-10 10:53:50,323 iteration 1342 : loss : 0.090195, loss_ce: 0.037518
2021-12-10 10:53:51,817 iteration 1343 : loss : 0.051189, loss_ce: 0.019614
 20%|█████▉                        | 79/400 [38:03<2:27:51, 27.64s/it]2021-12-10 10:53:53,404 iteration 1344 : loss : 0.059374, loss_ce: 0.024406
2021-12-10 10:53:55,009 iteration 1345 : loss : 0.071885, loss_ce: 0.029680
2021-12-10 10:53:56,524 iteration 1346 : loss : 0.088748, loss_ce: 0.041146
2021-12-10 10:53:58,141 iteration 1347 : loss : 0.035172, loss_ce: 0.015396
2021-12-10 10:53:59,808 iteration 1348 : loss : 0.075132, loss_ce: 0.031322
2021-12-10 10:54:01,347 iteration 1349 : loss : 0.063417, loss_ce: 0.025890
2021-12-10 10:54:02,903 iteration 1350 : loss : 0.108189, loss_ce: 0.054257
2021-12-10 10:54:04,453 iteration 1351 : loss : 0.060219, loss_ce: 0.027233
2021-12-10 10:54:06,052 iteration 1352 : loss : 0.062205, loss_ce: 0.028472
2021-12-10 10:54:07,630 iteration 1353 : loss : 0.070599, loss_ce: 0.026595
2021-12-10 10:54:09,217 iteration 1354 : loss : 0.065998, loss_ce: 0.023964
2021-12-10 10:54:10,877 iteration 1355 : loss : 0.117670, loss_ce: 0.028663
2021-12-10 10:54:12,451 iteration 1356 : loss : 0.051460, loss_ce: 0.023379
2021-12-10 10:54:14,042 iteration 1357 : loss : 0.047641, loss_ce: 0.019954
2021-12-10 10:54:15,643 iteration 1358 : loss : 0.079315, loss_ce: 0.035629
2021-12-10 10:54:17,200 iteration 1359 : loss : 0.085636, loss_ce: 0.036946
2021-12-10 10:54:17,200 Training Data Eval:
2021-12-10 10:54:24,954   Average segmentation loss on training set: 0.0702
2021-12-10 10:54:24,954 Validation Data Eval:
2021-12-10 10:54:27,610   Average segmentation loss on validation set: 0.1758
2021-12-10 10:54:29,214 iteration 1360 : loss : 0.056259, loss_ce: 0.016130
 20%|██████                        | 80/400 [38:40<2:43:00, 30.56s/it]2021-12-10 10:54:30,913 iteration 1361 : loss : 0.069808, loss_ce: 0.030819
2021-12-10 10:54:32,473 iteration 1362 : loss : 0.050569, loss_ce: 0.016535
2021-12-10 10:54:34,210 iteration 1363 : loss : 0.095804, loss_ce: 0.038503
2021-12-10 10:54:35,635 iteration 1364 : loss : 0.073748, loss_ce: 0.019911
2021-12-10 10:54:37,253 iteration 1365 : loss : 0.064513, loss_ce: 0.026967
2021-12-10 10:54:38,830 iteration 1366 : loss : 0.074201, loss_ce: 0.032174
2021-12-10 10:54:40,375 iteration 1367 : loss : 0.068916, loss_ce: 0.027295
2021-12-10 10:54:41,939 iteration 1368 : loss : 0.049504, loss_ce: 0.024969
2021-12-10 10:54:43,462 iteration 1369 : loss : 0.065749, loss_ce: 0.024029
2021-12-10 10:54:45,056 iteration 1370 : loss : 0.067353, loss_ce: 0.031871
2021-12-10 10:54:46,575 iteration 1371 : loss : 0.050479, loss_ce: 0.018734
2021-12-10 10:54:48,091 iteration 1372 : loss : 0.075513, loss_ce: 0.029087
2021-12-10 10:54:49,603 iteration 1373 : loss : 0.059718, loss_ce: 0.025974
2021-12-10 10:54:51,160 iteration 1374 : loss : 0.051747, loss_ce: 0.018553
2021-12-10 10:54:52,730 iteration 1375 : loss : 0.056987, loss_ce: 0.027158
2021-12-10 10:54:54,286 iteration 1376 : loss : 0.062516, loss_ce: 0.021339
2021-12-10 10:54:55,827 iteration 1377 : loss : 0.035656, loss_ce: 0.013972
 20%|██████                        | 81/400 [39:07<2:36:12, 29.38s/it]2021-12-10 10:54:57,351 iteration 1378 : loss : 0.063824, loss_ce: 0.024732
2021-12-10 10:54:58,940 iteration 1379 : loss : 0.043957, loss_ce: 0.018627
2021-12-10 10:55:00,506 iteration 1380 : loss : 0.055949, loss_ce: 0.023304
2021-12-10 10:55:02,139 iteration 1381 : loss : 0.055068, loss_ce: 0.024017
2021-12-10 10:55:03,608 iteration 1382 : loss : 0.047309, loss_ce: 0.018450
2021-12-10 10:55:05,237 iteration 1383 : loss : 0.045063, loss_ce: 0.016218
2021-12-10 10:55:06,795 iteration 1384 : loss : 0.068509, loss_ce: 0.025864
2021-12-10 10:55:08,284 iteration 1385 : loss : 0.084608, loss_ce: 0.026929
2021-12-10 10:55:09,797 iteration 1386 : loss : 0.051920, loss_ce: 0.020197
2021-12-10 10:55:11,330 iteration 1387 : loss : 0.061056, loss_ce: 0.023291
2021-12-10 10:55:12,885 iteration 1388 : loss : 0.060288, loss_ce: 0.018088
2021-12-10 10:55:14,422 iteration 1389 : loss : 0.060483, loss_ce: 0.025372
2021-12-10 10:55:16,018 iteration 1390 : loss : 0.045173, loss_ce: 0.019593
2021-12-10 10:55:17,634 iteration 1391 : loss : 0.061682, loss_ce: 0.023255
2021-12-10 10:55:19,233 iteration 1392 : loss : 0.047751, loss_ce: 0.024913
2021-12-10 10:55:20,748 iteration 1393 : loss : 0.055713, loss_ce: 0.019619
2021-12-10 10:55:22,362 iteration 1394 : loss : 0.074180, loss_ce: 0.034464
 20%|██████▏                       | 82/400 [39:33<2:31:11, 28.53s/it]2021-12-10 10:55:23,935 iteration 1395 : loss : 0.052821, loss_ce: 0.020782
2021-12-10 10:55:25,462 iteration 1396 : loss : 0.051390, loss_ce: 0.024106
2021-12-10 10:55:27,075 iteration 1397 : loss : 0.075832, loss_ce: 0.029527
2021-12-10 10:55:28,695 iteration 1398 : loss : 0.046481, loss_ce: 0.020713
2021-12-10 10:55:30,162 iteration 1399 : loss : 0.044261, loss_ce: 0.017978
2021-12-10 10:55:31,621 iteration 1400 : loss : 0.064087, loss_ce: 0.021258
2021-12-10 10:55:33,232 iteration 1401 : loss : 0.054100, loss_ce: 0.019897
2021-12-10 10:55:34,798 iteration 1402 : loss : 0.055679, loss_ce: 0.022205
2021-12-10 10:55:36,290 iteration 1403 : loss : 0.061498, loss_ce: 0.021722
2021-12-10 10:55:37,772 iteration 1404 : loss : 0.041933, loss_ce: 0.019608
2021-12-10 10:55:39,317 iteration 1405 : loss : 0.048709, loss_ce: 0.018118
2021-12-10 10:55:40,866 iteration 1406 : loss : 0.059908, loss_ce: 0.020977
2021-12-10 10:55:42,467 iteration 1407 : loss : 0.042366, loss_ce: 0.018317
2021-12-10 10:55:44,007 iteration 1408 : loss : 0.064719, loss_ce: 0.021367
2021-12-10 10:55:45,563 iteration 1409 : loss : 0.078388, loss_ce: 0.024767
2021-12-10 10:55:47,184 iteration 1410 : loss : 0.067700, loss_ce: 0.026177
2021-12-10 10:55:48,709 iteration 1411 : loss : 0.079083, loss_ce: 0.028003
 21%|██████▏                       | 83/400 [40:00<2:27:16, 27.88s/it]2021-12-10 10:55:50,283 iteration 1412 : loss : 0.063103, loss_ce: 0.022597
2021-12-10 10:55:51,898 iteration 1413 : loss : 0.098120, loss_ce: 0.033436
2021-12-10 10:55:53,429 iteration 1414 : loss : 0.042912, loss_ce: 0.015497
2021-12-10 10:55:55,015 iteration 1415 : loss : 0.080432, loss_ce: 0.023852
2021-12-10 10:55:56,546 iteration 1416 : loss : 0.054621, loss_ce: 0.023244
2021-12-10 10:55:58,062 iteration 1417 : loss : 0.056405, loss_ce: 0.020501
2021-12-10 10:55:59,575 iteration 1418 : loss : 0.067390, loss_ce: 0.028876
2021-12-10 10:56:01,065 iteration 1419 : loss : 0.051817, loss_ce: 0.019284
2021-12-10 10:56:02,646 iteration 1420 : loss : 0.067143, loss_ce: 0.022001
2021-12-10 10:56:04,290 iteration 1421 : loss : 0.070754, loss_ce: 0.029149
2021-12-10 10:56:05,865 iteration 1422 : loss : 0.048883, loss_ce: 0.015368
2021-12-10 10:56:07,344 iteration 1423 : loss : 0.056482, loss_ce: 0.023375
2021-12-10 10:56:08,925 iteration 1424 : loss : 0.050227, loss_ce: 0.021391
2021-12-10 10:56:10,492 iteration 1425 : loss : 0.031335, loss_ce: 0.014660
2021-12-10 10:56:12,004 iteration 1426 : loss : 0.058072, loss_ce: 0.026184
2021-12-10 10:56:13,545 iteration 1427 : loss : 0.063453, loss_ce: 0.026487
2021-12-10 10:56:14,992 iteration 1428 : loss : 0.082736, loss_ce: 0.031515
 21%|██████▎                       | 84/400 [40:26<2:24:18, 27.40s/it]2021-12-10 10:56:16,679 iteration 1429 : loss : 0.066802, loss_ce: 0.031755
2021-12-10 10:56:18,181 iteration 1430 : loss : 0.148098, loss_ce: 0.037231
2021-12-10 10:56:19,729 iteration 1431 : loss : 0.065898, loss_ce: 0.030752
2021-12-10 10:56:21,287 iteration 1432 : loss : 0.061711, loss_ce: 0.028018
2021-12-10 10:56:22,891 iteration 1433 : loss : 0.053866, loss_ce: 0.016723
2021-12-10 10:56:24,418 iteration 1434 : loss : 0.063289, loss_ce: 0.028337
2021-12-10 10:56:25,992 iteration 1435 : loss : 0.062575, loss_ce: 0.028084
2021-12-10 10:56:27,586 iteration 1436 : loss : 0.065579, loss_ce: 0.025120
2021-12-10 10:56:29,179 iteration 1437 : loss : 0.067458, loss_ce: 0.023570
2021-12-10 10:56:30,744 iteration 1438 : loss : 0.046734, loss_ce: 0.019619
2021-12-10 10:56:32,343 iteration 1439 : loss : 0.055343, loss_ce: 0.022260
2021-12-10 10:56:33,934 iteration 1440 : loss : 0.062749, loss_ce: 0.028799
2021-12-10 10:56:35,467 iteration 1441 : loss : 0.042478, loss_ce: 0.019278
2021-12-10 10:56:37,025 iteration 1442 : loss : 0.048596, loss_ce: 0.021115
2021-12-10 10:56:38,605 iteration 1443 : loss : 0.076879, loss_ce: 0.026546
2021-12-10 10:56:40,158 iteration 1444 : loss : 0.106968, loss_ce: 0.033162
2021-12-10 10:56:40,158 Training Data Eval:
2021-12-10 10:56:47,888   Average segmentation loss on training set: 0.0442
2021-12-10 10:56:47,888 Validation Data Eval:
2021-12-10 10:56:50,537   Average segmentation loss on validation set: 0.1022
2021-12-10 10:56:52,083 iteration 1445 : loss : 0.052366, loss_ce: 0.017228
 21%|██████▍                       | 85/400 [41:03<2:39:05, 30.30s/it]2021-12-10 10:56:53,787 iteration 1446 : loss : 0.067456, loss_ce: 0.021240
2021-12-10 10:56:55,321 iteration 1447 : loss : 0.073926, loss_ce: 0.025357
2021-12-10 10:56:56,802 iteration 1448 : loss : 0.055149, loss_ce: 0.027962
2021-12-10 10:56:58,379 iteration 1449 : loss : 0.050619, loss_ce: 0.018432
2021-12-10 10:57:00,038 iteration 1450 : loss : 0.057779, loss_ce: 0.030146
2021-12-10 10:57:01,711 iteration 1451 : loss : 0.095480, loss_ce: 0.035986
2021-12-10 10:57:03,233 iteration 1452 : loss : 0.067351, loss_ce: 0.019104
2021-12-10 10:57:04,770 iteration 1453 : loss : 0.058999, loss_ce: 0.027821
2021-12-10 10:57:06,351 iteration 1454 : loss : 0.073329, loss_ce: 0.026309
2021-12-10 10:57:07,874 iteration 1455 : loss : 0.039508, loss_ce: 0.017311
2021-12-10 10:57:09,501 iteration 1456 : loss : 0.104228, loss_ce: 0.035371
2021-12-10 10:57:11,044 iteration 1457 : loss : 0.051060, loss_ce: 0.021378
2021-12-10 10:57:12,571 iteration 1458 : loss : 0.044161, loss_ce: 0.015036
2021-12-10 10:57:14,069 iteration 1459 : loss : 0.057116, loss_ce: 0.015200
2021-12-10 10:57:15,679 iteration 1460 : loss : 0.096148, loss_ce: 0.044958
2021-12-10 10:57:17,225 iteration 1461 : loss : 0.085914, loss_ce: 0.035755
2021-12-10 10:57:18,819 iteration 1462 : loss : 0.070250, loss_ce: 0.032895
 22%|██████▍                       | 86/400 [41:30<2:32:59, 29.24s/it]2021-12-10 10:57:20,411 iteration 1463 : loss : 0.051945, loss_ce: 0.023599
2021-12-10 10:57:21,924 iteration 1464 : loss : 0.048584, loss_ce: 0.018137
2021-12-10 10:57:23,511 iteration 1465 : loss : 0.063246, loss_ce: 0.019695
2021-12-10 10:57:25,089 iteration 1466 : loss : 0.046240, loss_ce: 0.019650
2021-12-10 10:57:26,653 iteration 1467 : loss : 0.061062, loss_ce: 0.027978
2021-12-10 10:57:28,176 iteration 1468 : loss : 0.041445, loss_ce: 0.020665
2021-12-10 10:57:29,727 iteration 1469 : loss : 0.046761, loss_ce: 0.016622
2021-12-10 10:57:31,310 iteration 1470 : loss : 0.068568, loss_ce: 0.026360
2021-12-10 10:57:32,889 iteration 1471 : loss : 0.081080, loss_ce: 0.055343
2021-12-10 10:57:34,332 iteration 1472 : loss : 0.053934, loss_ce: 0.018805
2021-12-10 10:57:35,970 iteration 1473 : loss : 0.052277, loss_ce: 0.019435
2021-12-10 10:57:37,571 iteration 1474 : loss : 0.072352, loss_ce: 0.024438
2021-12-10 10:57:39,116 iteration 1475 : loss : 0.057207, loss_ce: 0.027311
2021-12-10 10:57:40,756 iteration 1476 : loss : 0.082378, loss_ce: 0.030888
2021-12-10 10:57:42,353 iteration 1477 : loss : 0.049699, loss_ce: 0.017735
2021-12-10 10:57:43,984 iteration 1478 : loss : 0.069102, loss_ce: 0.031533
2021-12-10 10:57:45,496 iteration 1479 : loss : 0.052403, loss_ce: 0.019217
 22%|██████▌                       | 87/400 [41:56<2:28:30, 28.47s/it]2021-12-10 10:57:47,118 iteration 1480 : loss : 0.064780, loss_ce: 0.027520
2021-12-10 10:57:48,641 iteration 1481 : loss : 0.056225, loss_ce: 0.024563
2021-12-10 10:57:50,191 iteration 1482 : loss : 0.057758, loss_ce: 0.022265
2021-12-10 10:57:51,813 iteration 1483 : loss : 0.057386, loss_ce: 0.021079
2021-12-10 10:57:53,518 iteration 1484 : loss : 0.080384, loss_ce: 0.025289
2021-12-10 10:57:55,139 iteration 1485 : loss : 0.064997, loss_ce: 0.027949
2021-12-10 10:57:56,679 iteration 1486 : loss : 0.068130, loss_ce: 0.030046
2021-12-10 10:57:58,225 iteration 1487 : loss : 0.113586, loss_ce: 0.064933
2021-12-10 10:57:59,799 iteration 1488 : loss : 0.054400, loss_ce: 0.023179
2021-12-10 10:58:01,384 iteration 1489 : loss : 0.052491, loss_ce: 0.022856
2021-12-10 10:58:02,980 iteration 1490 : loss : 0.071799, loss_ce: 0.031010
2021-12-10 10:58:04,611 iteration 1491 : loss : 0.055883, loss_ce: 0.024655
2021-12-10 10:58:06,124 iteration 1492 : loss : 0.047448, loss_ce: 0.020274
2021-12-10 10:58:07,729 iteration 1493 : loss : 0.078356, loss_ce: 0.037988
2021-12-10 10:58:09,247 iteration 1494 : loss : 0.050915, loss_ce: 0.022815
2021-12-10 10:58:10,774 iteration 1495 : loss : 0.061074, loss_ce: 0.025257
2021-12-10 10:58:12,325 iteration 1496 : loss : 0.095264, loss_ce: 0.029668
 22%|██████▌                       | 88/400 [42:23<2:25:27, 27.97s/it]2021-12-10 10:58:13,888 iteration 1497 : loss : 0.078382, loss_ce: 0.045091
2021-12-10 10:58:15,409 iteration 1498 : loss : 0.041420, loss_ce: 0.014835
2021-12-10 10:58:16,996 iteration 1499 : loss : 0.087466, loss_ce: 0.040886
2021-12-10 10:58:18,474 iteration 1500 : loss : 0.056278, loss_ce: 0.020566
2021-12-10 10:58:20,010 iteration 1501 : loss : 0.078026, loss_ce: 0.025050
2021-12-10 10:58:21,589 iteration 1502 : loss : 0.052709, loss_ce: 0.020684
2021-12-10 10:58:23,123 iteration 1503 : loss : 0.028269, loss_ce: 0.012909
2021-12-10 10:58:24,656 iteration 1504 : loss : 0.056160, loss_ce: 0.018704
2021-12-10 10:58:26,138 iteration 1505 : loss : 0.049024, loss_ce: 0.017343
2021-12-10 10:58:27,674 iteration 1506 : loss : 0.052517, loss_ce: 0.020201
2021-12-10 10:58:29,222 iteration 1507 : loss : 0.058792, loss_ce: 0.022467
2021-12-10 10:58:30,729 iteration 1508 : loss : 0.084591, loss_ce: 0.039312
2021-12-10 10:58:32,267 iteration 1509 : loss : 0.072506, loss_ce: 0.026814
2021-12-10 10:58:33,767 iteration 1510 : loss : 0.031900, loss_ce: 0.012935
2021-12-10 10:58:35,328 iteration 1511 : loss : 0.051896, loss_ce: 0.024590
2021-12-10 10:58:36,833 iteration 1512 : loss : 0.044400, loss_ce: 0.018826
2021-12-10 10:58:38,384 iteration 1513 : loss : 0.089940, loss_ce: 0.038334
 22%|██████▋                       | 89/400 [42:49<2:22:01, 27.40s/it]2021-12-10 10:58:39,973 iteration 1514 : loss : 0.066258, loss_ce: 0.023654
2021-12-10 10:58:41,512 iteration 1515 : loss : 0.061063, loss_ce: 0.026376
2021-12-10 10:58:43,078 iteration 1516 : loss : 0.057768, loss_ce: 0.024988
2021-12-10 10:58:44,625 iteration 1517 : loss : 0.034809, loss_ce: 0.014911
2021-12-10 10:58:46,200 iteration 1518 : loss : 0.044491, loss_ce: 0.013821
2021-12-10 10:58:47,725 iteration 1519 : loss : 0.046257, loss_ce: 0.017324
2021-12-10 10:58:49,238 iteration 1520 : loss : 0.035674, loss_ce: 0.012303
2021-12-10 10:58:50,761 iteration 1521 : loss : 0.059892, loss_ce: 0.019567
2021-12-10 10:58:52,416 iteration 1522 : loss : 0.049486, loss_ce: 0.017646
2021-12-10 10:58:53,907 iteration 1523 : loss : 0.058935, loss_ce: 0.026916
2021-12-10 10:58:55,490 iteration 1524 : loss : 0.089712, loss_ce: 0.030489
2021-12-10 10:58:57,005 iteration 1525 : loss : 0.045246, loss_ce: 0.019882
2021-12-10 10:58:58,613 iteration 1526 : loss : 0.044338, loss_ce: 0.019596
2021-12-10 10:59:00,225 iteration 1527 : loss : 0.082382, loss_ce: 0.042168
2021-12-10 10:59:01,820 iteration 1528 : loss : 0.045070, loss_ce: 0.017497
2021-12-10 10:59:03,335 iteration 1529 : loss : 0.044891, loss_ce: 0.017574
2021-12-10 10:59:03,335 Training Data Eval:
2021-12-10 10:59:11,079   Average segmentation loss on training set: 0.0382
2021-12-10 10:59:11,079 Validation Data Eval:
2021-12-10 10:59:13,734   Average segmentation loss on validation set: 0.0880
2021-12-10 10:59:15,265 iteration 1530 : loss : 0.057481, loss_ce: 0.025367
 22%|██████▊                       | 90/400 [43:26<2:36:16, 30.25s/it]2021-12-10 10:59:16,997 iteration 1531 : loss : 0.050542, loss_ce: 0.021058
2021-12-10 10:59:18,597 iteration 1532 : loss : 0.071470, loss_ce: 0.025113
2021-12-10 10:59:20,107 iteration 1533 : loss : 0.041453, loss_ce: 0.019080
2021-12-10 10:59:21,707 iteration 1534 : loss : 0.079327, loss_ce: 0.029040
2021-12-10 10:59:23,245 iteration 1535 : loss : 0.042333, loss_ce: 0.016256
2021-12-10 10:59:24,750 iteration 1536 : loss : 0.076001, loss_ce: 0.042389
2021-12-10 10:59:26,255 iteration 1537 : loss : 0.075530, loss_ce: 0.027391
2021-12-10 10:59:27,740 iteration 1538 : loss : 0.158850, loss_ce: 0.035633
2021-12-10 10:59:29,252 iteration 1539 : loss : 0.047663, loss_ce: 0.018673
2021-12-10 10:59:30,785 iteration 1540 : loss : 0.064056, loss_ce: 0.028934
2021-12-10 10:59:32,228 iteration 1541 : loss : 0.039965, loss_ce: 0.013337
2021-12-10 10:59:33,755 iteration 1542 : loss : 0.077794, loss_ce: 0.037915
2021-12-10 10:59:35,268 iteration 1543 : loss : 0.042866, loss_ce: 0.013009
2021-12-10 10:59:36,746 iteration 1544 : loss : 0.061693, loss_ce: 0.021989
2021-12-10 10:59:38,284 iteration 1545 : loss : 0.059898, loss_ce: 0.024765
2021-12-10 10:59:39,804 iteration 1546 : loss : 0.048611, loss_ce: 0.020806
2021-12-10 10:59:41,343 iteration 1547 : loss : 0.057816, loss_ce: 0.022886
 23%|██████▊                       | 91/400 [43:52<2:29:19, 28.99s/it]2021-12-10 10:59:42,934 iteration 1548 : loss : 0.039638, loss_ce: 0.014706
2021-12-10 10:59:44,414 iteration 1549 : loss : 0.038108, loss_ce: 0.016493
2021-12-10 10:59:46,054 iteration 1550 : loss : 0.056359, loss_ce: 0.024703
2021-12-10 10:59:47,590 iteration 1551 : loss : 0.069024, loss_ce: 0.028962
2021-12-10 10:59:49,141 iteration 1552 : loss : 0.066708, loss_ce: 0.032884
2021-12-10 10:59:50,592 iteration 1553 : loss : 0.033376, loss_ce: 0.017422
2021-12-10 10:59:52,091 iteration 1554 : loss : 0.060088, loss_ce: 0.023158
2021-12-10 10:59:53,695 iteration 1555 : loss : 0.061138, loss_ce: 0.023339
2021-12-10 10:59:55,368 iteration 1556 : loss : 0.084049, loss_ce: 0.034288
2021-12-10 10:59:56,970 iteration 1557 : loss : 0.086691, loss_ce: 0.022189
2021-12-10 10:59:58,523 iteration 1558 : loss : 0.059082, loss_ce: 0.018155
2021-12-10 11:00:00,183 iteration 1559 : loss : 0.057807, loss_ce: 0.024967
2021-12-10 11:00:01,705 iteration 1560 : loss : 0.049451, loss_ce: 0.014016
2021-12-10 11:00:03,241 iteration 1561 : loss : 0.063835, loss_ce: 0.025514
2021-12-10 11:00:04,788 iteration 1562 : loss : 0.060096, loss_ce: 0.026243
2021-12-10 11:00:06,318 iteration 1563 : loss : 0.052656, loss_ce: 0.028603
2021-12-10 11:00:07,872 iteration 1564 : loss : 0.055081, loss_ce: 0.018663
 23%|██████▉                       | 92/400 [44:19<2:25:02, 28.26s/it]2021-12-10 11:00:09,499 iteration 1565 : loss : 0.065909, loss_ce: 0.027002
2021-12-10 11:00:11,023 iteration 1566 : loss : 0.049701, loss_ce: 0.021413
2021-12-10 11:00:12,597 iteration 1567 : loss : 0.083262, loss_ce: 0.022387
2021-12-10 11:00:14,260 iteration 1568 : loss : 0.042960, loss_ce: 0.019518
2021-12-10 11:00:15,776 iteration 1569 : loss : 0.046373, loss_ce: 0.021454
2021-12-10 11:00:17,328 iteration 1570 : loss : 0.067336, loss_ce: 0.028563
2021-12-10 11:00:18,845 iteration 1571 : loss : 0.054402, loss_ce: 0.023470
2021-12-10 11:00:20,388 iteration 1572 : loss : 0.076655, loss_ce: 0.040394
2021-12-10 11:00:21,947 iteration 1573 : loss : 0.074167, loss_ce: 0.020610
2021-12-10 11:00:23,501 iteration 1574 : loss : 0.055907, loss_ce: 0.027835
2021-12-10 11:00:25,074 iteration 1575 : loss : 0.066651, loss_ce: 0.026978
2021-12-10 11:00:26,601 iteration 1576 : loss : 0.071330, loss_ce: 0.024551
2021-12-10 11:00:28,102 iteration 1577 : loss : 0.070736, loss_ce: 0.024390
2021-12-10 11:00:29,547 iteration 1578 : loss : 0.039387, loss_ce: 0.015490
2021-12-10 11:00:31,070 iteration 1579 : loss : 0.038443, loss_ce: 0.014190
2021-12-10 11:00:32,633 iteration 1580 : loss : 0.050345, loss_ce: 0.016718
2021-12-10 11:00:34,193 iteration 1581 : loss : 0.047176, loss_ce: 0.022251
 23%|██████▉                       | 93/400 [44:45<2:21:36, 27.68s/it]2021-12-10 11:00:35,838 iteration 1582 : loss : 0.064530, loss_ce: 0.035281
2021-12-10 11:00:37,385 iteration 1583 : loss : 0.066866, loss_ce: 0.020578
2021-12-10 11:00:38,884 iteration 1584 : loss : 0.043147, loss_ce: 0.016054
2021-12-10 11:00:40,406 iteration 1585 : loss : 0.040879, loss_ce: 0.017904
2021-12-10 11:00:41,859 iteration 1586 : loss : 0.047845, loss_ce: 0.020859
2021-12-10 11:00:43,368 iteration 1587 : loss : 0.056970, loss_ce: 0.019097
2021-12-10 11:00:44,890 iteration 1588 : loss : 0.041571, loss_ce: 0.012680
2021-12-10 11:00:46,430 iteration 1589 : loss : 0.050057, loss_ce: 0.022637
2021-12-10 11:00:48,055 iteration 1590 : loss : 0.052817, loss_ce: 0.017611
2021-12-10 11:00:49,570 iteration 1591 : loss : 0.052960, loss_ce: 0.025099
2021-12-10 11:00:51,025 iteration 1592 : loss : 0.036161, loss_ce: 0.016131
2021-12-10 11:00:52,571 iteration 1593 : loss : 0.059082, loss_ce: 0.020513
2021-12-10 11:00:54,095 iteration 1594 : loss : 0.050642, loss_ce: 0.016227
2021-12-10 11:00:55,572 iteration 1595 : loss : 0.048496, loss_ce: 0.026087
2021-12-10 11:00:57,027 iteration 1596 : loss : 0.062165, loss_ce: 0.019607
2021-12-10 11:00:58,576 iteration 1597 : loss : 0.074258, loss_ce: 0.020304
2021-12-10 11:01:00,153 iteration 1598 : loss : 0.051455, loss_ce: 0.017229
 24%|███████                       | 94/400 [45:11<2:18:30, 27.16s/it]2021-12-10 11:01:01,794 iteration 1599 : loss : 0.044228, loss_ce: 0.019045
2021-12-10 11:01:03,325 iteration 1600 : loss : 0.050489, loss_ce: 0.020494
2021-12-10 11:01:04,907 iteration 1601 : loss : 0.058119, loss_ce: 0.021824
2021-12-10 11:01:06,453 iteration 1602 : loss : 0.061798, loss_ce: 0.019526
2021-12-10 11:01:07,977 iteration 1603 : loss : 0.046679, loss_ce: 0.017702
2021-12-10 11:01:09,483 iteration 1604 : loss : 0.053919, loss_ce: 0.014635
2021-12-10 11:01:11,003 iteration 1605 : loss : 0.058057, loss_ce: 0.024228
2021-12-10 11:01:12,544 iteration 1606 : loss : 0.038706, loss_ce: 0.017566
2021-12-10 11:01:14,075 iteration 1607 : loss : 0.038723, loss_ce: 0.013086
2021-12-10 11:01:15,689 iteration 1608 : loss : 0.062524, loss_ce: 0.030661
2021-12-10 11:01:17,207 iteration 1609 : loss : 0.045484, loss_ce: 0.016967
2021-12-10 11:01:18,837 iteration 1610 : loss : 0.049515, loss_ce: 0.018946
2021-12-10 11:01:20,471 iteration 1611 : loss : 0.061681, loss_ce: 0.030189
2021-12-10 11:01:22,117 iteration 1612 : loss : 0.043539, loss_ce: 0.016472
2021-12-10 11:01:23,677 iteration 1613 : loss : 0.040906, loss_ce: 0.016401
2021-12-10 11:01:25,281 iteration 1614 : loss : 0.052320, loss_ce: 0.026524
2021-12-10 11:01:25,281 Training Data Eval:
2021-12-10 11:01:32,996   Average segmentation loss on training set: 0.0414
2021-12-10 11:01:32,997 Validation Data Eval:
2021-12-10 11:01:35,653   Average segmentation loss on validation set: 0.0837
2021-12-10 11:01:37,249 iteration 1615 : loss : 0.077504, loss_ce: 0.025290
 24%|███████▏                      | 95/400 [45:48<2:33:13, 30.14s/it]2021-12-10 11:01:38,860 iteration 1616 : loss : 0.050283, loss_ce: 0.019095
2021-12-10 11:01:40,387 iteration 1617 : loss : 0.054620, loss_ce: 0.022734
2021-12-10 11:01:41,869 iteration 1618 : loss : 0.046713, loss_ce: 0.016842
2021-12-10 11:01:43,405 iteration 1619 : loss : 0.050920, loss_ce: 0.027909
2021-12-10 11:01:45,078 iteration 1620 : loss : 0.049080, loss_ce: 0.016642
2021-12-10 11:01:46,748 iteration 1621 : loss : 0.047285, loss_ce: 0.018721
2021-12-10 11:01:48,288 iteration 1622 : loss : 0.044783, loss_ce: 0.019264
2021-12-10 11:01:49,785 iteration 1623 : loss : 0.043599, loss_ce: 0.015542
2021-12-10 11:01:51,348 iteration 1624 : loss : 0.046042, loss_ce: 0.020958
2021-12-10 11:01:52,826 iteration 1625 : loss : 0.043955, loss_ce: 0.014201
2021-12-10 11:01:54,348 iteration 1626 : loss : 0.040522, loss_ce: 0.017019
2021-12-10 11:01:56,010 iteration 1627 : loss : 0.072449, loss_ce: 0.028902
2021-12-10 11:01:57,647 iteration 1628 : loss : 0.068285, loss_ce: 0.024779
2021-12-10 11:01:59,166 iteration 1629 : loss : 0.052690, loss_ce: 0.017255
2021-12-10 11:02:00,666 iteration 1630 : loss : 0.032701, loss_ce: 0.012165
2021-12-10 11:02:02,167 iteration 1631 : loss : 0.059601, loss_ce: 0.020281
2021-12-10 11:02:03,682 iteration 1632 : loss : 0.037540, loss_ce: 0.014823
 24%|███████▏                      | 96/400 [46:15<2:27:04, 29.03s/it]2021-12-10 11:02:05,290 iteration 1633 : loss : 0.056130, loss_ce: 0.017560
2021-12-10 11:02:06,864 iteration 1634 : loss : 0.073735, loss_ce: 0.034763
2021-12-10 11:02:08,388 iteration 1635 : loss : 0.053600, loss_ce: 0.015957
2021-12-10 11:02:09,858 iteration 1636 : loss : 0.045977, loss_ce: 0.020754
2021-12-10 11:02:11,419 iteration 1637 : loss : 0.056852, loss_ce: 0.020730
2021-12-10 11:02:12,955 iteration 1638 : loss : 0.062002, loss_ce: 0.028090
2021-12-10 11:02:14,555 iteration 1639 : loss : 0.049524, loss_ce: 0.024718
2021-12-10 11:02:16,069 iteration 1640 : loss : 0.054268, loss_ce: 0.017410
2021-12-10 11:02:17,688 iteration 1641 : loss : 0.052694, loss_ce: 0.020653
2021-12-10 11:02:19,184 iteration 1642 : loss : 0.045193, loss_ce: 0.017056
2021-12-10 11:02:20,666 iteration 1643 : loss : 0.046285, loss_ce: 0.015786
2021-12-10 11:02:22,269 iteration 1644 : loss : 0.062507, loss_ce: 0.024828
2021-12-10 11:02:23,910 iteration 1645 : loss : 0.058512, loss_ce: 0.028252
2021-12-10 11:02:25,414 iteration 1646 : loss : 0.070873, loss_ce: 0.027377
2021-12-10 11:02:26,934 iteration 1647 : loss : 0.048963, loss_ce: 0.017667
2021-12-10 11:02:28,399 iteration 1648 : loss : 0.043657, loss_ce: 0.018411
2021-12-10 11:02:29,867 iteration 1649 : loss : 0.041083, loss_ce: 0.016072
 24%|███████▎                      | 97/400 [46:41<2:22:17, 28.18s/it]2021-12-10 11:02:31,599 iteration 1650 : loss : 0.079642, loss_ce: 0.042237
2021-12-10 11:02:33,122 iteration 1651 : loss : 0.077329, loss_ce: 0.022273
2021-12-10 11:02:34,681 iteration 1652 : loss : 0.083300, loss_ce: 0.025738
2021-12-10 11:02:36,195 iteration 1653 : loss : 0.042761, loss_ce: 0.015557
2021-12-10 11:02:37,723 iteration 1654 : loss : 0.063697, loss_ce: 0.022280
2021-12-10 11:02:39,220 iteration 1655 : loss : 0.061565, loss_ce: 0.022710
2021-12-10 11:02:40,805 iteration 1656 : loss : 0.059286, loss_ce: 0.022401
2021-12-10 11:02:42,337 iteration 1657 : loss : 0.040032, loss_ce: 0.017068
2021-12-10 11:02:43,930 iteration 1658 : loss : 0.071687, loss_ce: 0.041099
2021-12-10 11:02:45,565 iteration 1659 : loss : 0.053909, loss_ce: 0.025424
2021-12-10 11:02:47,125 iteration 1660 : loss : 0.031832, loss_ce: 0.012319
2021-12-10 11:02:48,607 iteration 1661 : loss : 0.045485, loss_ce: 0.017483
2021-12-10 11:02:50,199 iteration 1662 : loss : 0.048368, loss_ce: 0.017926
2021-12-10 11:02:51,807 iteration 1663 : loss : 0.047821, loss_ce: 0.021665
2021-12-10 11:02:53,361 iteration 1664 : loss : 0.078913, loss_ce: 0.026907
2021-12-10 11:02:54,888 iteration 1665 : loss : 0.045634, loss_ce: 0.020422
2021-12-10 11:02:56,450 iteration 1666 : loss : 0.045050, loss_ce: 0.015760
 24%|███████▎                      | 98/400 [47:07<2:19:23, 27.69s/it]2021-12-10 11:02:57,995 iteration 1667 : loss : 0.039520, loss_ce: 0.018951
2021-12-10 11:02:59,623 iteration 1668 : loss : 0.059912, loss_ce: 0.019691
2021-12-10 11:03:01,212 iteration 1669 : loss : 0.061059, loss_ce: 0.020770
2021-12-10 11:03:02,682 iteration 1670 : loss : 0.038970, loss_ce: 0.012093
2021-12-10 11:03:04,161 iteration 1671 : loss : 0.050050, loss_ce: 0.022340
2021-12-10 11:03:05,757 iteration 1672 : loss : 0.085258, loss_ce: 0.034449
2021-12-10 11:03:07,349 iteration 1673 : loss : 0.044598, loss_ce: 0.012786
2021-12-10 11:03:08,993 iteration 1674 : loss : 0.070475, loss_ce: 0.026830
2021-12-10 11:03:10,508 iteration 1675 : loss : 0.077379, loss_ce: 0.028399
2021-12-10 11:03:12,112 iteration 1676 : loss : 0.055848, loss_ce: 0.025361
2021-12-10 11:03:13,685 iteration 1677 : loss : 0.067237, loss_ce: 0.023251
2021-12-10 11:03:15,280 iteration 1678 : loss : 0.064953, loss_ce: 0.026327
2021-12-10 11:03:16,810 iteration 1679 : loss : 0.088094, loss_ce: 0.044895
2021-12-10 11:03:18,393 iteration 1680 : loss : 0.051505, loss_ce: 0.023888
2021-12-10 11:03:19,924 iteration 1681 : loss : 0.070507, loss_ce: 0.026917
2021-12-10 11:03:21,663 iteration 1682 : loss : 0.049708, loss_ce: 0.021876
2021-12-10 11:03:23,173 iteration 1683 : loss : 0.046628, loss_ce: 0.023021
 25%|███████▍                      | 99/400 [47:34<2:17:29, 27.41s/it]2021-12-10 11:03:24,811 iteration 1684 : loss : 0.074282, loss_ce: 0.029890
2021-12-10 11:03:26,314 iteration 1685 : loss : 0.042663, loss_ce: 0.020721
2021-12-10 11:03:27,784 iteration 1686 : loss : 0.039671, loss_ce: 0.014731
2021-12-10 11:03:29,300 iteration 1687 : loss : 0.065411, loss_ce: 0.026211
2021-12-10 11:03:30,850 iteration 1688 : loss : 0.053549, loss_ce: 0.021955
2021-12-10 11:03:32,354 iteration 1689 : loss : 0.053368, loss_ce: 0.019780
2021-12-10 11:03:33,926 iteration 1690 : loss : 0.076868, loss_ce: 0.027759
2021-12-10 11:03:35,451 iteration 1691 : loss : 0.041242, loss_ce: 0.017611
2021-12-10 11:03:37,051 iteration 1692 : loss : 0.067321, loss_ce: 0.023888
2021-12-10 11:03:38,663 iteration 1693 : loss : 0.048894, loss_ce: 0.025463
2021-12-10 11:03:40,246 iteration 1694 : loss : 0.049105, loss_ce: 0.017508
2021-12-10 11:03:41,707 iteration 1695 : loss : 0.043907, loss_ce: 0.014467
2021-12-10 11:03:43,235 iteration 1696 : loss : 0.069843, loss_ce: 0.024433
2021-12-10 11:03:44,833 iteration 1697 : loss : 0.061284, loss_ce: 0.017515
2021-12-10 11:03:46,357 iteration 1698 : loss : 0.040938, loss_ce: 0.014938
2021-12-10 11:03:47,791 iteration 1699 : loss : 0.044302, loss_ce: 0.021949
2021-12-10 11:03:47,791 Training Data Eval:
2021-12-10 11:03:55,539   Average segmentation loss on training set: 0.0343
2021-12-10 11:03:55,539 Validation Data Eval:
2021-12-10 11:03:58,190   Average segmentation loss on validation set: 0.0900
2021-12-10 11:03:59,756 iteration 1700 : loss : 0.052766, loss_ce: 0.016909
 25%|███████▎                     | 100/400 [48:11<2:30:47, 30.16s/it]2021-12-10 11:04:01,398 iteration 1701 : loss : 0.056934, loss_ce: 0.022489
2021-12-10 11:04:02,956 iteration 1702 : loss : 0.043868, loss_ce: 0.018337
2021-12-10 11:04:04,442 iteration 1703 : loss : 0.038009, loss_ce: 0.014976
2021-12-10 11:04:06,071 iteration 1704 : loss : 0.042446, loss_ce: 0.018217
2021-12-10 11:04:07,610 iteration 1705 : loss : 0.052188, loss_ce: 0.023701
2021-12-10 11:04:09,183 iteration 1706 : loss : 0.050344, loss_ce: 0.027124
2021-12-10 11:04:10,723 iteration 1707 : loss : 0.045819, loss_ce: 0.016288
2021-12-10 11:04:12,312 iteration 1708 : loss : 0.046293, loss_ce: 0.014118
2021-12-10 11:04:13,787 iteration 1709 : loss : 0.033746, loss_ce: 0.014593
2021-12-10 11:04:15,242 iteration 1710 : loss : 0.040710, loss_ce: 0.018180
2021-12-10 11:04:16,801 iteration 1711 : loss : 0.046652, loss_ce: 0.017063
2021-12-10 11:04:18,293 iteration 1712 : loss : 0.045968, loss_ce: 0.015096
2021-12-10 11:04:19,773 iteration 1713 : loss : 0.041363, loss_ce: 0.013482
2021-12-10 11:04:21,406 iteration 1714 : loss : 0.067069, loss_ce: 0.023935
2021-12-10 11:04:22,985 iteration 1715 : loss : 0.074908, loss_ce: 0.020529
2021-12-10 11:04:24,617 iteration 1716 : loss : 0.061808, loss_ce: 0.021371
2021-12-10 11:04:26,160 iteration 1717 : loss : 0.048803, loss_ce: 0.018866
 25%|███████▎                     | 101/400 [48:37<2:24:41, 29.03s/it]2021-12-10 11:04:27,735 iteration 1718 : loss : 0.057811, loss_ce: 0.021565
2021-12-10 11:04:29,305 iteration 1719 : loss : 0.060669, loss_ce: 0.026534
2021-12-10 11:04:30,754 iteration 1720 : loss : 0.034168, loss_ce: 0.012458
2021-12-10 11:04:32,287 iteration 1721 : loss : 0.048090, loss_ce: 0.020962
2021-12-10 11:04:33,889 iteration 1722 : loss : 0.037883, loss_ce: 0.012668
2021-12-10 11:04:35,432 iteration 1723 : loss : 0.071535, loss_ce: 0.033022
2021-12-10 11:04:37,020 iteration 1724 : loss : 0.052913, loss_ce: 0.016717
2021-12-10 11:04:38,699 iteration 1725 : loss : 0.095207, loss_ce: 0.028941
2021-12-10 11:04:40,330 iteration 1726 : loss : 0.073539, loss_ce: 0.022784
2021-12-10 11:04:41,894 iteration 1727 : loss : 0.044233, loss_ce: 0.020451
2021-12-10 11:04:43,435 iteration 1728 : loss : 0.040052, loss_ce: 0.013549
2021-12-10 11:04:44,972 iteration 1729 : loss : 0.053313, loss_ce: 0.020419
2021-12-10 11:04:46,545 iteration 1730 : loss : 0.048192, loss_ce: 0.019177
2021-12-10 11:04:48,168 iteration 1731 : loss : 0.045269, loss_ce: 0.015771
2021-12-10 11:04:49,725 iteration 1732 : loss : 0.035385, loss_ce: 0.016871
2021-12-10 11:04:51,362 iteration 1733 : loss : 0.072858, loss_ce: 0.028920
2021-12-10 11:04:52,872 iteration 1734 : loss : 0.049400, loss_ce: 0.015416
 26%|███████▍                     | 102/400 [49:04<2:20:43, 28.33s/it]2021-12-10 11:04:54,430 iteration 1735 : loss : 0.060037, loss_ce: 0.021647
2021-12-10 11:04:55,969 iteration 1736 : loss : 0.050100, loss_ce: 0.018579
2021-12-10 11:04:57,510 iteration 1737 : loss : 0.031159, loss_ce: 0.012330
2021-12-10 11:04:59,016 iteration 1738 : loss : 0.051453, loss_ce: 0.017460
2021-12-10 11:05:00,650 iteration 1739 : loss : 0.047589, loss_ce: 0.023019
2021-12-10 11:05:02,233 iteration 1740 : loss : 0.055389, loss_ce: 0.020666
2021-12-10 11:05:03,762 iteration 1741 : loss : 0.041334, loss_ce: 0.014192
2021-12-10 11:05:05,405 iteration 1742 : loss : 0.052387, loss_ce: 0.022770
2021-12-10 11:05:06,934 iteration 1743 : loss : 0.046312, loss_ce: 0.013570
2021-12-10 11:05:08,507 iteration 1744 : loss : 0.053490, loss_ce: 0.021317
2021-12-10 11:05:10,200 iteration 1745 : loss : 0.052928, loss_ce: 0.026715
2021-12-10 11:05:11,732 iteration 1746 : loss : 0.032533, loss_ce: 0.012708
2021-12-10 11:05:13,257 iteration 1747 : loss : 0.040153, loss_ce: 0.016961
2021-12-10 11:05:14,815 iteration 1748 : loss : 0.034957, loss_ce: 0.014536
2021-12-10 11:05:16,367 iteration 1749 : loss : 0.068237, loss_ce: 0.022229
2021-12-10 11:05:17,861 iteration 1750 : loss : 0.043459, loss_ce: 0.020845
2021-12-10 11:05:19,514 iteration 1751 : loss : 0.087815, loss_ce: 0.033903
 26%|███████▍                     | 103/400 [49:30<2:17:44, 27.83s/it]2021-12-10 11:05:21,093 iteration 1752 : loss : 0.033103, loss_ce: 0.012242
2021-12-10 11:05:22,596 iteration 1753 : loss : 0.042901, loss_ce: 0.019896
2021-12-10 11:05:24,118 iteration 1754 : loss : 0.035862, loss_ce: 0.014257
2021-12-10 11:05:25,650 iteration 1755 : loss : 0.052284, loss_ce: 0.020207
2021-12-10 11:05:27,215 iteration 1756 : loss : 0.056231, loss_ce: 0.026720
2021-12-10 11:05:28,835 iteration 1757 : loss : 0.056078, loss_ce: 0.031688
2021-12-10 11:05:30,422 iteration 1758 : loss : 0.077086, loss_ce: 0.027694
2021-12-10 11:05:31,901 iteration 1759 : loss : 0.083240, loss_ce: 0.023450
2021-12-10 11:05:33,425 iteration 1760 : loss : 0.061326, loss_ce: 0.022427
2021-12-10 11:05:34,934 iteration 1761 : loss : 0.041227, loss_ce: 0.015183
2021-12-10 11:05:36,472 iteration 1762 : loss : 0.051672, loss_ce: 0.018977
2021-12-10 11:05:37,931 iteration 1763 : loss : 0.073843, loss_ce: 0.033008
2021-12-10 11:05:39,579 iteration 1764 : loss : 0.041230, loss_ce: 0.012857
2021-12-10 11:05:41,124 iteration 1765 : loss : 0.056795, loss_ce: 0.018502
2021-12-10 11:05:42,737 iteration 1766 : loss : 0.040001, loss_ce: 0.014297
2021-12-10 11:05:44,316 iteration 1767 : loss : 0.061480, loss_ce: 0.021310
2021-12-10 11:05:45,854 iteration 1768 : loss : 0.066942, loss_ce: 0.024891
 26%|███████▌                     | 104/400 [49:57<2:15:05, 27.38s/it]2021-12-10 11:05:47,498 iteration 1769 : loss : 0.047863, loss_ce: 0.016881
2021-12-10 11:05:49,029 iteration 1770 : loss : 0.034387, loss_ce: 0.012491
2021-12-10 11:05:50,538 iteration 1771 : loss : 0.039397, loss_ce: 0.013027
2021-12-10 11:05:52,146 iteration 1772 : loss : 0.067128, loss_ce: 0.028855
2021-12-10 11:05:53,715 iteration 1773 : loss : 0.075410, loss_ce: 0.031995
2021-12-10 11:05:55,227 iteration 1774 : loss : 0.051767, loss_ce: 0.016999
2021-12-10 11:05:56,750 iteration 1775 : loss : 0.044787, loss_ce: 0.015717
2021-12-10 11:05:58,264 iteration 1776 : loss : 0.057245, loss_ce: 0.019405
2021-12-10 11:05:59,755 iteration 1777 : loss : 0.046526, loss_ce: 0.018390
2021-12-10 11:06:01,338 iteration 1778 : loss : 0.036561, loss_ce: 0.015629
2021-12-10 11:06:02,894 iteration 1779 : loss : 0.043165, loss_ce: 0.017878
2021-12-10 11:06:04,465 iteration 1780 : loss : 0.073890, loss_ce: 0.022266
2021-12-10 11:06:06,034 iteration 1781 : loss : 0.051971, loss_ce: 0.019252
2021-12-10 11:06:07,506 iteration 1782 : loss : 0.068347, loss_ce: 0.018241
2021-12-10 11:06:09,011 iteration 1783 : loss : 0.056709, loss_ce: 0.030347
2021-12-10 11:06:10,591 iteration 1784 : loss : 0.058096, loss_ce: 0.029530
2021-12-10 11:06:10,591 Training Data Eval:
2021-12-10 11:06:18,289   Average segmentation loss on training set: 0.0340
2021-12-10 11:06:18,290 Validation Data Eval:
2021-12-10 11:06:20,936   Average segmentation loss on validation set: 0.0880
2021-12-10 11:06:22,473 iteration 1785 : loss : 0.057548, loss_ce: 0.027372
 26%|███████▌                     | 105/400 [50:33<2:28:15, 30.15s/it]2021-12-10 11:06:24,125 iteration 1786 : loss : 0.057249, loss_ce: 0.019481
2021-12-10 11:06:25,614 iteration 1787 : loss : 0.050350, loss_ce: 0.013823
2021-12-10 11:06:27,170 iteration 1788 : loss : 0.043228, loss_ce: 0.015209
2021-12-10 11:06:28,732 iteration 1789 : loss : 0.043544, loss_ce: 0.021714
2021-12-10 11:06:30,429 iteration 1790 : loss : 0.042352, loss_ce: 0.014812
2021-12-10 11:06:32,002 iteration 1791 : loss : 0.054670, loss_ce: 0.025856
2021-12-10 11:06:33,569 iteration 1792 : loss : 0.047750, loss_ce: 0.020313
2021-12-10 11:06:35,153 iteration 1793 : loss : 0.089887, loss_ce: 0.042447
2021-12-10 11:06:36,688 iteration 1794 : loss : 0.047864, loss_ce: 0.026008
2021-12-10 11:06:38,131 iteration 1795 : loss : 0.032712, loss_ce: 0.013394
2021-12-10 11:06:39,751 iteration 1796 : loss : 0.058475, loss_ce: 0.024775
2021-12-10 11:06:41,248 iteration 1797 : loss : 0.044536, loss_ce: 0.018111
2021-12-10 11:06:42,804 iteration 1798 : loss : 0.049349, loss_ce: 0.017188
2021-12-10 11:06:44,418 iteration 1799 : loss : 0.050049, loss_ce: 0.019499
2021-12-10 11:06:45,914 iteration 1800 : loss : 0.050030, loss_ce: 0.016363
2021-12-10 11:06:47,454 iteration 1801 : loss : 0.065186, loss_ce: 0.019995
2021-12-10 11:06:49,055 iteration 1802 : loss : 0.055347, loss_ce: 0.018921
 26%|███████▋                     | 106/400 [51:00<2:22:29, 29.08s/it]2021-12-10 11:06:50,701 iteration 1803 : loss : 0.061930, loss_ce: 0.023316
2021-12-10 11:06:52,182 iteration 1804 : loss : 0.062727, loss_ce: 0.020068
2021-12-10 11:06:53,867 iteration 1805 : loss : 0.057159, loss_ce: 0.021580
2021-12-10 11:06:55,510 iteration 1806 : loss : 0.054451, loss_ce: 0.027244
2021-12-10 11:06:57,047 iteration 1807 : loss : 0.046342, loss_ce: 0.018957
2021-12-10 11:06:58,644 iteration 1808 : loss : 0.032954, loss_ce: 0.014135
2021-12-10 11:07:00,175 iteration 1809 : loss : 0.042547, loss_ce: 0.019413
2021-12-10 11:07:01,751 iteration 1810 : loss : 0.056934, loss_ce: 0.029808
2021-12-10 11:07:03,281 iteration 1811 : loss : 0.063932, loss_ce: 0.023315
2021-12-10 11:07:04,796 iteration 1812 : loss : 0.046186, loss_ce: 0.015026
2021-12-10 11:07:06,348 iteration 1813 : loss : 0.052119, loss_ce: 0.024849
2021-12-10 11:07:07,872 iteration 1814 : loss : 0.052580, loss_ce: 0.018049
2021-12-10 11:07:09,496 iteration 1815 : loss : 0.057414, loss_ce: 0.018388
2021-12-10 11:07:11,057 iteration 1816 : loss : 0.037555, loss_ce: 0.015074
2021-12-10 11:07:12,689 iteration 1817 : loss : 0.049477, loss_ce: 0.019253
2021-12-10 11:07:14,185 iteration 1818 : loss : 0.037079, loss_ce: 0.013099
2021-12-10 11:07:15,780 iteration 1819 : loss : 0.040505, loss_ce: 0.014472
 27%|███████▊                     | 107/400 [51:27<2:18:33, 28.37s/it]2021-12-10 11:07:17,272 iteration 1820 : loss : 0.036626, loss_ce: 0.017665
2021-12-10 11:07:18,923 iteration 1821 : loss : 0.052676, loss_ce: 0.017149
2021-12-10 11:07:20,529 iteration 1822 : loss : 0.059233, loss_ce: 0.033366
2021-12-10 11:07:22,160 iteration 1823 : loss : 0.054240, loss_ce: 0.020372
2021-12-10 11:07:23,741 iteration 1824 : loss : 0.057305, loss_ce: 0.016260
2021-12-10 11:07:25,249 iteration 1825 : loss : 0.053650, loss_ce: 0.020849
2021-12-10 11:07:26,866 iteration 1826 : loss : 0.044149, loss_ce: 0.016236
2021-12-10 11:07:28,375 iteration 1827 : loss : 0.039817, loss_ce: 0.016455
2021-12-10 11:07:29,936 iteration 1828 : loss : 0.042627, loss_ce: 0.016356
2021-12-10 11:07:31,447 iteration 1829 : loss : 0.059034, loss_ce: 0.031008
2021-12-10 11:07:33,090 iteration 1830 : loss : 0.056448, loss_ce: 0.020025
2021-12-10 11:07:34,665 iteration 1831 : loss : 0.048105, loss_ce: 0.018479
2021-12-10 11:07:36,193 iteration 1832 : loss : 0.043050, loss_ce: 0.017351
2021-12-10 11:07:37,680 iteration 1833 : loss : 0.053210, loss_ce: 0.022061
2021-12-10 11:07:39,213 iteration 1834 : loss : 0.051766, loss_ce: 0.019350
2021-12-10 11:07:40,760 iteration 1835 : loss : 0.035180, loss_ce: 0.014037
2021-12-10 11:07:42,271 iteration 1836 : loss : 0.087251, loss_ce: 0.034461
 27%|███████▊                     | 108/400 [51:53<2:15:20, 27.81s/it]2021-12-10 11:07:43,919 iteration 1837 : loss : 0.052409, loss_ce: 0.018950
2021-12-10 11:07:45,381 iteration 1838 : loss : 0.038762, loss_ce: 0.016424
2021-12-10 11:07:46,884 iteration 1839 : loss : 0.060999, loss_ce: 0.025199
2021-12-10 11:07:48,440 iteration 1840 : loss : 0.038408, loss_ce: 0.017480
2021-12-10 11:07:49,927 iteration 1841 : loss : 0.047867, loss_ce: 0.021019
2021-12-10 11:07:51,459 iteration 1842 : loss : 0.034469, loss_ce: 0.011595
2021-12-10 11:07:53,031 iteration 1843 : loss : 0.039650, loss_ce: 0.020197
2021-12-10 11:07:54,553 iteration 1844 : loss : 0.049336, loss_ce: 0.015606
2021-12-10 11:07:56,074 iteration 1845 : loss : 0.039267, loss_ce: 0.011732
2021-12-10 11:07:57,692 iteration 1846 : loss : 0.051155, loss_ce: 0.023495
2021-12-10 11:07:59,210 iteration 1847 : loss : 0.043325, loss_ce: 0.015730
2021-12-10 11:08:00,736 iteration 1848 : loss : 0.052845, loss_ce: 0.022096
2021-12-10 11:08:02,243 iteration 1849 : loss : 0.074822, loss_ce: 0.032747
2021-12-10 11:08:03,914 iteration 1850 : loss : 0.065901, loss_ce: 0.026290
2021-12-10 11:08:05,460 iteration 1851 : loss : 0.065393, loss_ce: 0.020908
2021-12-10 11:08:07,030 iteration 1852 : loss : 0.050890, loss_ce: 0.021484
2021-12-10 11:08:08,542 iteration 1853 : loss : 0.050881, loss_ce: 0.020268
 27%|███████▉                     | 109/400 [52:20<2:12:38, 27.35s/it]2021-12-10 11:08:10,117 iteration 1854 : loss : 0.037017, loss_ce: 0.013924
2021-12-10 11:08:11,713 iteration 1855 : loss : 0.039005, loss_ce: 0.014658
2021-12-10 11:08:13,331 iteration 1856 : loss : 0.056728, loss_ce: 0.017883
2021-12-10 11:08:14,943 iteration 1857 : loss : 0.028105, loss_ce: 0.011312
2021-12-10 11:08:16,514 iteration 1858 : loss : 0.060457, loss_ce: 0.026749
2021-12-10 11:08:18,079 iteration 1859 : loss : 0.049325, loss_ce: 0.018518
2021-12-10 11:08:19,589 iteration 1860 : loss : 0.042334, loss_ce: 0.015140
2021-12-10 11:08:21,199 iteration 1861 : loss : 0.032664, loss_ce: 0.011764
2021-12-10 11:08:22,704 iteration 1862 : loss : 0.044311, loss_ce: 0.020282
2021-12-10 11:08:24,264 iteration 1863 : loss : 0.065108, loss_ce: 0.030681
2021-12-10 11:08:25,849 iteration 1864 : loss : 0.078778, loss_ce: 0.019187
2021-12-10 11:08:27,304 iteration 1865 : loss : 0.039506, loss_ce: 0.017046
2021-12-10 11:08:28,929 iteration 1866 : loss : 0.030518, loss_ce: 0.013807
2021-12-10 11:08:30,480 iteration 1867 : loss : 0.028416, loss_ce: 0.012665
2021-12-10 11:08:31,990 iteration 1868 : loss : 0.051205, loss_ce: 0.020773
2021-12-10 11:08:33,496 iteration 1869 : loss : 0.095324, loss_ce: 0.033633
2021-12-10 11:08:33,497 Training Data Eval:
2021-12-10 11:08:41,225   Average segmentation loss on training set: 0.0334
2021-12-10 11:08:41,225 Validation Data Eval:
2021-12-10 11:08:43,885   Average segmentation loss on validation set: 0.1040
2021-12-10 11:08:45,480 iteration 1870 : loss : 0.052147, loss_ce: 0.018740
 28%|███████▉                     | 110/400 [52:56<2:26:05, 30.23s/it]2021-12-10 11:08:47,145 iteration 1871 : loss : 0.047819, loss_ce: 0.019090
2021-12-10 11:08:48,812 iteration 1872 : loss : 0.090943, loss_ce: 0.022779
2021-12-10 11:08:50,301 iteration 1873 : loss : 0.059247, loss_ce: 0.023984
2021-12-10 11:08:51,920 iteration 1874 : loss : 0.057695, loss_ce: 0.028262
2021-12-10 11:08:53,379 iteration 1875 : loss : 0.047491, loss_ce: 0.016127
2021-12-10 11:08:54,997 iteration 1876 : loss : 0.038107, loss_ce: 0.011901
2021-12-10 11:08:56,586 iteration 1877 : loss : 0.066631, loss_ce: 0.028142
2021-12-10 11:08:58,098 iteration 1878 : loss : 0.039223, loss_ce: 0.016023
2021-12-10 11:08:59,607 iteration 1879 : loss : 0.040860, loss_ce: 0.015452
2021-12-10 11:09:01,110 iteration 1880 : loss : 0.064016, loss_ce: 0.029160
2021-12-10 11:09:02,648 iteration 1881 : loss : 0.066661, loss_ce: 0.021361
2021-12-10 11:09:04,137 iteration 1882 : loss : 0.038521, loss_ce: 0.014719
2021-12-10 11:09:05,594 iteration 1883 : loss : 0.049615, loss_ce: 0.016566
2021-12-10 11:09:07,181 iteration 1884 : loss : 0.045341, loss_ce: 0.016786
2021-12-10 11:09:08,636 iteration 1885 : loss : 0.036767, loss_ce: 0.015342
2021-12-10 11:09:10,262 iteration 1886 : loss : 0.035988, loss_ce: 0.015736
2021-12-10 11:09:11,879 iteration 1887 : loss : 0.057339, loss_ce: 0.025147
 28%|████████                     | 111/400 [53:23<2:20:03, 29.08s/it]2021-12-10 11:09:13,467 iteration 1888 : loss : 0.042929, loss_ce: 0.018188
2021-12-10 11:09:15,075 iteration 1889 : loss : 0.043494, loss_ce: 0.017771
2021-12-10 11:09:16,670 iteration 1890 : loss : 0.041367, loss_ce: 0.013716
2021-12-10 11:09:18,273 iteration 1891 : loss : 0.035695, loss_ce: 0.014462
2021-12-10 11:09:19,841 iteration 1892 : loss : 0.041493, loss_ce: 0.017481
2021-12-10 11:09:21,414 iteration 1893 : loss : 0.047343, loss_ce: 0.026956
2021-12-10 11:09:22,957 iteration 1894 : loss : 0.056104, loss_ce: 0.024004
2021-12-10 11:09:24,488 iteration 1895 : loss : 0.051101, loss_ce: 0.018806
2021-12-10 11:09:26,173 iteration 1896 : loss : 0.050179, loss_ce: 0.024055
2021-12-10 11:09:27,708 iteration 1897 : loss : 0.067404, loss_ce: 0.022300
2021-12-10 11:09:29,319 iteration 1898 : loss : 0.048280, loss_ce: 0.016315
2021-12-10 11:09:30,868 iteration 1899 : loss : 0.053846, loss_ce: 0.026976
2021-12-10 11:09:32,330 iteration 1900 : loss : 0.035776, loss_ce: 0.014542
2021-12-10 11:09:33,876 iteration 1901 : loss : 0.039963, loss_ce: 0.013684
2021-12-10 11:09:35,452 iteration 1902 : loss : 0.042506, loss_ce: 0.018274
2021-12-10 11:09:37,049 iteration 1903 : loss : 0.060065, loss_ce: 0.018299
2021-12-10 11:09:38,711 iteration 1904 : loss : 0.056174, loss_ce: 0.020856
 28%|████████                     | 112/400 [53:50<2:16:19, 28.40s/it]2021-12-10 11:09:40,263 iteration 1905 : loss : 0.029992, loss_ce: 0.012642
2021-12-10 11:09:41,884 iteration 1906 : loss : 0.053977, loss_ce: 0.016009
2021-12-10 11:09:43,546 iteration 1907 : loss : 0.071143, loss_ce: 0.025238
2021-12-10 11:09:45,139 iteration 1908 : loss : 0.038377, loss_ce: 0.015593
2021-12-10 11:09:46,768 iteration 1909 : loss : 0.054590, loss_ce: 0.029053
2021-12-10 11:09:48,377 iteration 1910 : loss : 0.037217, loss_ce: 0.016471
2021-12-10 11:09:50,063 iteration 1911 : loss : 0.039603, loss_ce: 0.015271
2021-12-10 11:09:51,652 iteration 1912 : loss : 0.068088, loss_ce: 0.019068
2021-12-10 11:09:53,203 iteration 1913 : loss : 0.044485, loss_ce: 0.016653
2021-12-10 11:09:54,717 iteration 1914 : loss : 0.047741, loss_ce: 0.020317
2021-12-10 11:09:56,271 iteration 1915 : loss : 0.058035, loss_ce: 0.020361
2021-12-10 11:09:57,820 iteration 1916 : loss : 0.040708, loss_ce: 0.015726
2021-12-10 11:09:59,398 iteration 1917 : loss : 0.051006, loss_ce: 0.019927
2021-12-10 11:10:00,909 iteration 1918 : loss : 0.043793, loss_ce: 0.018575
2021-12-10 11:10:02,445 iteration 1919 : loss : 0.041071, loss_ce: 0.020064
2021-12-10 11:10:03,979 iteration 1920 : loss : 0.036134, loss_ce: 0.012269
2021-12-10 11:10:05,574 iteration 1921 : loss : 0.048037, loss_ce: 0.015474
 28%|████████▏                    | 113/400 [54:17<2:13:39, 27.94s/it]2021-12-10 11:10:07,122 iteration 1922 : loss : 0.040299, loss_ce: 0.015001
2021-12-10 11:10:08,590 iteration 1923 : loss : 0.033015, loss_ce: 0.014692
2021-12-10 11:10:10,165 iteration 1924 : loss : 0.056721, loss_ce: 0.029535
2021-12-10 11:10:11,659 iteration 1925 : loss : 0.049869, loss_ce: 0.021606
2021-12-10 11:10:13,166 iteration 1926 : loss : 0.038871, loss_ce: 0.016656
2021-12-10 11:10:14,751 iteration 1927 : loss : 0.049622, loss_ce: 0.020483
2021-12-10 11:10:16,343 iteration 1928 : loss : 0.047984, loss_ce: 0.018525
2021-12-10 11:10:17,867 iteration 1929 : loss : 0.044481, loss_ce: 0.019575
2021-12-10 11:10:19,421 iteration 1930 : loss : 0.058080, loss_ce: 0.018790
2021-12-10 11:10:20,936 iteration 1931 : loss : 0.049877, loss_ce: 0.014935
2021-12-10 11:10:22,481 iteration 1932 : loss : 0.057816, loss_ce: 0.017662
2021-12-10 11:10:24,022 iteration 1933 : loss : 0.060968, loss_ce: 0.019599
2021-12-10 11:10:25,443 iteration 1934 : loss : 0.029623, loss_ce: 0.013417
2021-12-10 11:10:26,954 iteration 1935 : loss : 0.046509, loss_ce: 0.023220
2021-12-10 11:10:28,544 iteration 1936 : loss : 0.049514, loss_ce: 0.018728
2021-12-10 11:10:30,122 iteration 1937 : loss : 0.039791, loss_ce: 0.016803
2021-12-10 11:10:31,702 iteration 1938 : loss : 0.045215, loss_ce: 0.014670
 28%|████████▎                    | 114/400 [54:43<2:10:36, 27.40s/it]2021-12-10 11:10:33,241 iteration 1939 : loss : 0.037507, loss_ce: 0.016888
2021-12-10 11:10:34,768 iteration 1940 : loss : 0.034958, loss_ce: 0.013917
2021-12-10 11:10:36,361 iteration 1941 : loss : 0.039291, loss_ce: 0.017951
2021-12-10 11:10:37,905 iteration 1942 : loss : 0.045813, loss_ce: 0.016676
2021-12-10 11:10:39,369 iteration 1943 : loss : 0.059705, loss_ce: 0.031668
2021-12-10 11:10:40,875 iteration 1944 : loss : 0.039432, loss_ce: 0.013844
2021-12-10 11:10:42,412 iteration 1945 : loss : 0.049600, loss_ce: 0.029515
2021-12-10 11:10:43,944 iteration 1946 : loss : 0.058136, loss_ce: 0.021425
2021-12-10 11:10:45,458 iteration 1947 : loss : 0.061379, loss_ce: 0.023544
2021-12-10 11:10:46,978 iteration 1948 : loss : 0.038450, loss_ce: 0.016873
2021-12-10 11:10:48,438 iteration 1949 : loss : 0.039145, loss_ce: 0.021846
2021-12-10 11:10:50,022 iteration 1950 : loss : 0.053972, loss_ce: 0.023904
2021-12-10 11:10:51,679 iteration 1951 : loss : 0.059753, loss_ce: 0.021376
2021-12-10 11:10:53,167 iteration 1952 : loss : 0.038415, loss_ce: 0.011811
2021-12-10 11:10:54,734 iteration 1953 : loss : 0.057586, loss_ce: 0.036250
2021-12-10 11:10:56,349 iteration 1954 : loss : 0.054897, loss_ce: 0.018494
2021-12-10 11:10:56,349 Training Data Eval:
2021-12-10 11:11:04,087   Average segmentation loss on training set: 0.0313
2021-12-10 11:11:04,087 Validation Data Eval:
2021-12-10 11:11:06,740   Average segmentation loss on validation set: 0.0784
2021-12-10 11:11:12,571 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 11:11:14,141 iteration 1955 : loss : 0.033793, loss_ce: 0.012536
 29%|████████▎                    | 115/400 [55:25<2:31:34, 31.91s/it]2021-12-10 11:11:15,784 iteration 1956 : loss : 0.053368, loss_ce: 0.022122
2021-12-10 11:11:17,268 iteration 1957 : loss : 0.033327, loss_ce: 0.014599
2021-12-10 11:11:18,774 iteration 1958 : loss : 0.029416, loss_ce: 0.012691
2021-12-10 11:11:20,393 iteration 1959 : loss : 0.059334, loss_ce: 0.017447
2021-12-10 11:11:21,909 iteration 1960 : loss : 0.075813, loss_ce: 0.024032
2021-12-10 11:11:23,459 iteration 1961 : loss : 0.063066, loss_ce: 0.026185
2021-12-10 11:11:24,992 iteration 1962 : loss : 0.045075, loss_ce: 0.018923
2021-12-10 11:11:26,545 iteration 1963 : loss : 0.046909, loss_ce: 0.020705
2021-12-10 11:11:28,071 iteration 1964 : loss : 0.033767, loss_ce: 0.009891
2021-12-10 11:11:29,573 iteration 1965 : loss : 0.041713, loss_ce: 0.017832
2021-12-10 11:11:31,066 iteration 1966 : loss : 0.041854, loss_ce: 0.019144
2021-12-10 11:11:32,554 iteration 1967 : loss : 0.067920, loss_ce: 0.020100
2021-12-10 11:11:34,018 iteration 1968 : loss : 0.045983, loss_ce: 0.024595
2021-12-10 11:11:35,580 iteration 1969 : loss : 0.035953, loss_ce: 0.013005
2021-12-10 11:11:37,265 iteration 1970 : loss : 0.046166, loss_ce: 0.017581
2021-12-10 11:11:38,710 iteration 1971 : loss : 0.046588, loss_ce: 0.014035
2021-12-10 11:11:40,375 iteration 1972 : loss : 0.065558, loss_ce: 0.025855
 29%|████████▍                    | 116/400 [55:51<2:22:59, 30.21s/it]2021-12-10 11:11:41,889 iteration 1973 : loss : 0.031211, loss_ce: 0.012640
2021-12-10 11:11:43,359 iteration 1974 : loss : 0.038050, loss_ce: 0.015572
2021-12-10 11:11:44,979 iteration 1975 : loss : 0.049303, loss_ce: 0.019089
2021-12-10 11:11:46,431 iteration 1976 : loss : 0.040395, loss_ce: 0.017741
2021-12-10 11:11:48,057 iteration 1977 : loss : 0.063170, loss_ce: 0.027770
2021-12-10 11:11:49,552 iteration 1978 : loss : 0.036767, loss_ce: 0.016158
2021-12-10 11:11:51,068 iteration 1979 : loss : 0.039225, loss_ce: 0.019932
2021-12-10 11:11:52,653 iteration 1980 : loss : 0.052250, loss_ce: 0.017719
2021-12-10 11:11:54,139 iteration 1981 : loss : 0.037466, loss_ce: 0.014307
2021-12-10 11:11:55,746 iteration 1982 : loss : 0.042085, loss_ce: 0.016723
2021-12-10 11:11:57,376 iteration 1983 : loss : 0.050368, loss_ce: 0.023709
2021-12-10 11:11:58,872 iteration 1984 : loss : 0.049409, loss_ce: 0.014963
2021-12-10 11:12:00,384 iteration 1985 : loss : 0.041862, loss_ce: 0.013945
2021-12-10 11:12:01,881 iteration 1986 : loss : 0.042906, loss_ce: 0.013302
2021-12-10 11:12:03,377 iteration 1987 : loss : 0.029940, loss_ce: 0.013284
2021-12-10 11:12:05,012 iteration 1988 : loss : 0.037273, loss_ce: 0.015432
2021-12-10 11:12:06,549 iteration 1989 : loss : 0.039768, loss_ce: 0.017836
 29%|████████▍                    | 117/400 [56:18<2:16:45, 28.99s/it]2021-12-10 11:12:08,133 iteration 1990 : loss : 0.055622, loss_ce: 0.023536
2021-12-10 11:12:09,579 iteration 1991 : loss : 0.035526, loss_ce: 0.015978
2021-12-10 11:12:11,156 iteration 1992 : loss : 0.049733, loss_ce: 0.022616
2021-12-10 11:12:12,681 iteration 1993 : loss : 0.047843, loss_ce: 0.013292
2021-12-10 11:12:14,252 iteration 1994 : loss : 0.038375, loss_ce: 0.014820
2021-12-10 11:12:15,795 iteration 1995 : loss : 0.054409, loss_ce: 0.023328
2021-12-10 11:12:17,327 iteration 1996 : loss : 0.039265, loss_ce: 0.018514
2021-12-10 11:12:18,863 iteration 1997 : loss : 0.048589, loss_ce: 0.021634
2021-12-10 11:12:20,418 iteration 1998 : loss : 0.059142, loss_ce: 0.025476
2021-12-10 11:12:21,966 iteration 1999 : loss : 0.055820, loss_ce: 0.026127
2021-12-10 11:12:23,637 iteration 2000 : loss : 0.050508, loss_ce: 0.013085
2021-12-10 11:12:25,191 iteration 2001 : loss : 0.048290, loss_ce: 0.018628
2021-12-10 11:12:26,665 iteration 2002 : loss : 0.044540, loss_ce: 0.018064
2021-12-10 11:12:28,075 iteration 2003 : loss : 0.027663, loss_ce: 0.013687
2021-12-10 11:12:29,571 iteration 2004 : loss : 0.052466, loss_ce: 0.013308
2021-12-10 11:12:31,152 iteration 2005 : loss : 0.026818, loss_ce: 0.009351
2021-12-10 11:12:32,727 iteration 2006 : loss : 0.047339, loss_ce: 0.017646
 30%|████████▌                    | 118/400 [56:44<2:12:18, 28.15s/it]2021-12-10 11:12:34,398 iteration 2007 : loss : 0.052923, loss_ce: 0.021347
2021-12-10 11:12:36,072 iteration 2008 : loss : 0.035134, loss_ce: 0.012850
2021-12-10 11:12:37,624 iteration 2009 : loss : 0.042290, loss_ce: 0.017500
2021-12-10 11:12:39,166 iteration 2010 : loss : 0.044266, loss_ce: 0.020727
2021-12-10 11:12:40,809 iteration 2011 : loss : 0.051136, loss_ce: 0.018626
2021-12-10 11:12:42,373 iteration 2012 : loss : 0.041187, loss_ce: 0.018109
2021-12-10 11:12:43,844 iteration 2013 : loss : 0.030087, loss_ce: 0.012355
2021-12-10 11:12:45,368 iteration 2014 : loss : 0.044947, loss_ce: 0.015759
2021-12-10 11:12:46,964 iteration 2015 : loss : 0.031515, loss_ce: 0.013588
2021-12-10 11:12:48,503 iteration 2016 : loss : 0.056190, loss_ce: 0.021648
2021-12-10 11:12:50,085 iteration 2017 : loss : 0.029586, loss_ce: 0.009157
2021-12-10 11:12:51,738 iteration 2018 : loss : 0.050507, loss_ce: 0.021999
2021-12-10 11:12:53,267 iteration 2019 : loss : 0.046242, loss_ce: 0.015571
2021-12-10 11:12:54,775 iteration 2020 : loss : 0.029355, loss_ce: 0.010350
2021-12-10 11:12:56,336 iteration 2021 : loss : 0.043042, loss_ce: 0.013288
2021-12-10 11:12:57,910 iteration 2022 : loss : 0.039079, loss_ce: 0.018216
2021-12-10 11:12:59,518 iteration 2023 : loss : 0.065729, loss_ce: 0.026018
 30%|████████▋                    | 119/400 [57:10<2:09:54, 27.74s/it]2021-12-10 11:13:01,051 iteration 2024 : loss : 0.040825, loss_ce: 0.012716
2021-12-10 11:13:02,613 iteration 2025 : loss : 0.043236, loss_ce: 0.021168
2021-12-10 11:13:04,208 iteration 2026 : loss : 0.044554, loss_ce: 0.017045
2021-12-10 11:13:05,740 iteration 2027 : loss : 0.028927, loss_ce: 0.008907
2021-12-10 11:13:07,235 iteration 2028 : loss : 0.031087, loss_ce: 0.015309
2021-12-10 11:13:08,752 iteration 2029 : loss : 0.039726, loss_ce: 0.015740
2021-12-10 11:13:10,278 iteration 2030 : loss : 0.046071, loss_ce: 0.019135
2021-12-10 11:13:11,820 iteration 2031 : loss : 0.034554, loss_ce: 0.012090
2021-12-10 11:13:13,463 iteration 2032 : loss : 0.046355, loss_ce: 0.018697
2021-12-10 11:13:15,134 iteration 2033 : loss : 0.050329, loss_ce: 0.022583
2021-12-10 11:13:16,636 iteration 2034 : loss : 0.031883, loss_ce: 0.012956
2021-12-10 11:13:18,200 iteration 2035 : loss : 0.039170, loss_ce: 0.014357
2021-12-10 11:13:19,804 iteration 2036 : loss : 0.046182, loss_ce: 0.023645
2021-12-10 11:13:21,352 iteration 2037 : loss : 0.101299, loss_ce: 0.025521
2021-12-10 11:13:22,945 iteration 2038 : loss : 0.053684, loss_ce: 0.019855
2021-12-10 11:13:24,588 iteration 2039 : loss : 0.044871, loss_ce: 0.016833
2021-12-10 11:13:24,589 Training Data Eval:
2021-12-10 11:13:32,300   Average segmentation loss on training set: 0.0274
2021-12-10 11:13:32,300 Validation Data Eval:
2021-12-10 11:13:34,944   Average segmentation loss on validation set: 0.0840
2021-12-10 11:13:36,572 iteration 2040 : loss : 0.078147, loss_ce: 0.035515
 30%|████████▋                    | 120/400 [57:48<2:22:31, 30.54s/it]2021-12-10 11:13:38,223 iteration 2041 : loss : 0.060782, loss_ce: 0.016692
2021-12-10 11:13:39,750 iteration 2042 : loss : 0.043897, loss_ce: 0.017387
2021-12-10 11:13:41,268 iteration 2043 : loss : 0.032761, loss_ce: 0.010413
2021-12-10 11:13:42,810 iteration 2044 : loss : 0.091457, loss_ce: 0.046748
2021-12-10 11:13:44,328 iteration 2045 : loss : 0.032732, loss_ce: 0.009634
2021-12-10 11:13:45,881 iteration 2046 : loss : 0.065936, loss_ce: 0.031679
2021-12-10 11:13:47,403 iteration 2047 : loss : 0.045619, loss_ce: 0.019420
2021-12-10 11:13:48,945 iteration 2048 : loss : 0.040890, loss_ce: 0.016235
2021-12-10 11:13:50,461 iteration 2049 : loss : 0.042857, loss_ce: 0.012319
2021-12-10 11:13:52,029 iteration 2050 : loss : 0.050940, loss_ce: 0.021248
2021-12-10 11:13:53,591 iteration 2051 : loss : 0.043705, loss_ce: 0.021219
2021-12-10 11:13:55,078 iteration 2052 : loss : 0.034208, loss_ce: 0.014332
2021-12-10 11:13:56,630 iteration 2053 : loss : 0.062341, loss_ce: 0.023540
2021-12-10 11:13:58,152 iteration 2054 : loss : 0.038307, loss_ce: 0.016819
2021-12-10 11:13:59,689 iteration 2055 : loss : 0.059520, loss_ce: 0.018514
2021-12-10 11:14:01,279 iteration 2056 : loss : 0.045357, loss_ce: 0.022555
2021-12-10 11:14:02,773 iteration 2057 : loss : 0.041301, loss_ce: 0.016991
 30%|████████▊                    | 121/400 [58:14<2:15:56, 29.23s/it]2021-12-10 11:14:04,376 iteration 2058 : loss : 0.040883, loss_ce: 0.018798
2021-12-10 11:14:05,979 iteration 2059 : loss : 0.072680, loss_ce: 0.026598
2021-12-10 11:14:07,435 iteration 2060 : loss : 0.036739, loss_ce: 0.012399
2021-12-10 11:14:09,006 iteration 2061 : loss : 0.054372, loss_ce: 0.021625
2021-12-10 11:14:10,526 iteration 2062 : loss : 0.053689, loss_ce: 0.023085
2021-12-10 11:14:12,057 iteration 2063 : loss : 0.086936, loss_ce: 0.018035
2021-12-10 11:14:13,544 iteration 2064 : loss : 0.033014, loss_ce: 0.012246
2021-12-10 11:14:15,056 iteration 2065 : loss : 0.052281, loss_ce: 0.015938
2021-12-10 11:14:16,598 iteration 2066 : loss : 0.037535, loss_ce: 0.013919
2021-12-10 11:14:18,166 iteration 2067 : loss : 0.044471, loss_ce: 0.018719
2021-12-10 11:14:19,779 iteration 2068 : loss : 0.027368, loss_ce: 0.012384
2021-12-10 11:14:21,291 iteration 2069 : loss : 0.051054, loss_ce: 0.013270
2021-12-10 11:14:22,891 iteration 2070 : loss : 0.041382, loss_ce: 0.016317
2021-12-10 11:14:24,505 iteration 2071 : loss : 0.054653, loss_ce: 0.021254
2021-12-10 11:14:26,059 iteration 2072 : loss : 0.050514, loss_ce: 0.017820
2021-12-10 11:14:27,657 iteration 2073 : loss : 0.047202, loss_ce: 0.014618
2021-12-10 11:14:29,244 iteration 2074 : loss : 0.035813, loss_ce: 0.018621
 30%|████████▊                    | 122/400 [58:40<2:11:37, 28.41s/it]2021-12-10 11:14:30,821 iteration 2075 : loss : 0.036388, loss_ce: 0.013196
2021-12-10 11:14:32,375 iteration 2076 : loss : 0.041410, loss_ce: 0.012541
2021-12-10 11:14:33,956 iteration 2077 : loss : 0.042002, loss_ce: 0.020025
2021-12-10 11:14:35,671 iteration 2078 : loss : 0.048871, loss_ce: 0.017446
2021-12-10 11:14:37,206 iteration 2079 : loss : 0.051874, loss_ce: 0.016379
2021-12-10 11:14:38,813 iteration 2080 : loss : 0.054122, loss_ce: 0.017409
2021-12-10 11:14:40,269 iteration 2081 : loss : 0.041362, loss_ce: 0.015091
2021-12-10 11:14:41,704 iteration 2082 : loss : 0.027883, loss_ce: 0.010897
2021-12-10 11:14:43,228 iteration 2083 : loss : 0.059284, loss_ce: 0.034804
2021-12-10 11:14:44,760 iteration 2084 : loss : 0.051636, loss_ce: 0.023838
2021-12-10 11:14:46,258 iteration 2085 : loss : 0.056101, loss_ce: 0.015867
2021-12-10 11:14:47,792 iteration 2086 : loss : 0.056398, loss_ce: 0.024748
2021-12-10 11:14:49,299 iteration 2087 : loss : 0.037845, loss_ce: 0.015206
2021-12-10 11:14:50,906 iteration 2088 : loss : 0.044457, loss_ce: 0.016633
2021-12-10 11:14:52,504 iteration 2089 : loss : 0.037044, loss_ce: 0.018070
2021-12-10 11:14:53,979 iteration 2090 : loss : 0.035033, loss_ce: 0.014792
2021-12-10 11:14:55,563 iteration 2091 : loss : 0.039668, loss_ce: 0.016668
 31%|████████▉                    | 123/400 [59:07<2:08:14, 27.78s/it]2021-12-10 11:14:57,090 iteration 2092 : loss : 0.026393, loss_ce: 0.011541
2021-12-10 11:14:58,604 iteration 2093 : loss : 0.048177, loss_ce: 0.021561
2021-12-10 11:15:00,152 iteration 2094 : loss : 0.050563, loss_ce: 0.013257
2021-12-10 11:15:01,640 iteration 2095 : loss : 0.033682, loss_ce: 0.014884
2021-12-10 11:15:03,271 iteration 2096 : loss : 0.035338, loss_ce: 0.017551
2021-12-10 11:15:04,838 iteration 2097 : loss : 0.078714, loss_ce: 0.027646
2021-12-10 11:15:06,396 iteration 2098 : loss : 0.049213, loss_ce: 0.018587
2021-12-10 11:15:07,965 iteration 2099 : loss : 0.037500, loss_ce: 0.011603
2021-12-10 11:15:09,557 iteration 2100 : loss : 0.041827, loss_ce: 0.021994
2021-12-10 11:15:11,120 iteration 2101 : loss : 0.032668, loss_ce: 0.011315
2021-12-10 11:15:12,721 iteration 2102 : loss : 0.042445, loss_ce: 0.019358
2021-12-10 11:15:14,178 iteration 2103 : loss : 0.036446, loss_ce: 0.014209
2021-12-10 11:15:15,663 iteration 2104 : loss : 0.070842, loss_ce: 0.019754
2021-12-10 11:15:17,310 iteration 2105 : loss : 0.064542, loss_ce: 0.019852
2021-12-10 11:15:18,819 iteration 2106 : loss : 0.026711, loss_ce: 0.011502
2021-12-10 11:15:20,455 iteration 2107 : loss : 0.050883, loss_ce: 0.019041
2021-12-10 11:15:22,024 iteration 2108 : loss : 0.052856, loss_ce: 0.019191
 31%|████████▉                    | 124/400 [59:33<2:05:58, 27.39s/it]2021-12-10 11:15:23,635 iteration 2109 : loss : 0.042066, loss_ce: 0.017015
2021-12-10 11:15:25,224 iteration 2110 : loss : 0.044602, loss_ce: 0.016199
2021-12-10 11:15:26,871 iteration 2111 : loss : 0.053476, loss_ce: 0.014113
2021-12-10 11:15:28,439 iteration 2112 : loss : 0.055108, loss_ce: 0.024476
2021-12-10 11:15:29,953 iteration 2113 : loss : 0.045599, loss_ce: 0.021856
2021-12-10 11:15:31,530 iteration 2114 : loss : 0.034570, loss_ce: 0.016010
2021-12-10 11:15:33,114 iteration 2115 : loss : 0.059342, loss_ce: 0.019127
2021-12-10 11:15:34,679 iteration 2116 : loss : 0.056033, loss_ce: 0.019352
2021-12-10 11:15:36,245 iteration 2117 : loss : 0.042012, loss_ce: 0.018668
2021-12-10 11:15:37,842 iteration 2118 : loss : 0.042196, loss_ce: 0.012811
2021-12-10 11:15:39,438 iteration 2119 : loss : 0.115686, loss_ce: 0.040759
2021-12-10 11:15:40,993 iteration 2120 : loss : 0.051356, loss_ce: 0.018346
2021-12-10 11:15:42,433 iteration 2121 : loss : 0.038784, loss_ce: 0.014558
2021-12-10 11:15:43,970 iteration 2122 : loss : 0.048611, loss_ce: 0.017704
2021-12-10 11:15:45,583 iteration 2123 : loss : 0.057220, loss_ce: 0.025335
2021-12-10 11:15:47,219 iteration 2124 : loss : 0.044249, loss_ce: 0.017862
2021-12-10 11:15:47,219 Training Data Eval:
2021-12-10 11:15:54,955   Average segmentation loss on training set: 0.0279
2021-12-10 11:15:54,955 Validation Data Eval:
2021-12-10 11:15:57,603   Average segmentation loss on validation set: 0.0949
2021-12-10 11:15:59,173 iteration 2125 : loss : 0.049748, loss_ce: 0.024496
 31%|████████▍                  | 125/400 [1:00:10<2:18:57, 30.32s/it]2021-12-10 11:16:00,841 iteration 2126 : loss : 0.036885, loss_ce: 0.014011
2021-12-10 11:16:02,413 iteration 2127 : loss : 0.050913, loss_ce: 0.025594
2021-12-10 11:16:03,991 iteration 2128 : loss : 0.037980, loss_ce: 0.013469
2021-12-10 11:16:05,494 iteration 2129 : loss : 0.068745, loss_ce: 0.025673
2021-12-10 11:16:07,095 iteration 2130 : loss : 0.080775, loss_ce: 0.025698
2021-12-10 11:16:08,626 iteration 2131 : loss : 0.048139, loss_ce: 0.015776
2021-12-10 11:16:10,175 iteration 2132 : loss : 0.029145, loss_ce: 0.011608
2021-12-10 11:16:11,801 iteration 2133 : loss : 0.050307, loss_ce: 0.018235
2021-12-10 11:16:13,271 iteration 2134 : loss : 0.039433, loss_ce: 0.018910
2021-12-10 11:16:14,824 iteration 2135 : loss : 0.047230, loss_ce: 0.017841
2021-12-10 11:16:16,371 iteration 2136 : loss : 0.040566, loss_ce: 0.016698
2021-12-10 11:16:17,918 iteration 2137 : loss : 0.054980, loss_ce: 0.023169
2021-12-10 11:16:19,427 iteration 2138 : loss : 0.052870, loss_ce: 0.020108
2021-12-10 11:16:21,025 iteration 2139 : loss : 0.043427, loss_ce: 0.022836
2021-12-10 11:16:22,575 iteration 2140 : loss : 0.060022, loss_ce: 0.034323
2021-12-10 11:16:24,198 iteration 2141 : loss : 0.037695, loss_ce: 0.012973
2021-12-10 11:16:25,711 iteration 2142 : loss : 0.041071, loss_ce: 0.013271
 32%|████████▌                  | 126/400 [1:00:37<2:13:15, 29.18s/it]2021-12-10 11:16:27,248 iteration 2143 : loss : 0.042677, loss_ce: 0.016736
2021-12-10 11:16:28,821 iteration 2144 : loss : 0.039301, loss_ce: 0.014266
2021-12-10 11:16:30,415 iteration 2145 : loss : 0.046597, loss_ce: 0.017324
2021-12-10 11:16:31,912 iteration 2146 : loss : 0.024617, loss_ce: 0.010760
2021-12-10 11:16:33,480 iteration 2147 : loss : 0.070133, loss_ce: 0.025022
2021-12-10 11:16:35,008 iteration 2148 : loss : 0.054467, loss_ce: 0.020745
2021-12-10 11:16:36,563 iteration 2149 : loss : 0.049325, loss_ce: 0.022622
2021-12-10 11:16:38,093 iteration 2150 : loss : 0.026825, loss_ce: 0.010581
2021-12-10 11:16:39,698 iteration 2151 : loss : 0.052629, loss_ce: 0.022166
2021-12-10 11:16:41,192 iteration 2152 : loss : 0.039419, loss_ce: 0.014816
2021-12-10 11:16:42,682 iteration 2153 : loss : 0.032179, loss_ce: 0.013674
2021-12-10 11:16:44,357 iteration 2154 : loss : 0.062495, loss_ce: 0.021619
2021-12-10 11:16:45,900 iteration 2155 : loss : 0.038740, loss_ce: 0.013943
2021-12-10 11:16:47,387 iteration 2156 : loss : 0.053006, loss_ce: 0.025482
2021-12-10 11:16:49,077 iteration 2157 : loss : 0.089046, loss_ce: 0.031330
2021-12-10 11:16:50,725 iteration 2158 : loss : 0.048747, loss_ce: 0.023437
2021-12-10 11:16:52,297 iteration 2159 : loss : 0.063521, loss_ce: 0.019549
 32%|████████▌                  | 127/400 [1:01:03<2:09:13, 28.40s/it]2021-12-10 11:16:53,857 iteration 2160 : loss : 0.039072, loss_ce: 0.016761
2021-12-10 11:16:55,337 iteration 2161 : loss : 0.048927, loss_ce: 0.015636
2021-12-10 11:16:56,848 iteration 2162 : loss : 0.052108, loss_ce: 0.018805
2021-12-10 11:16:58,354 iteration 2163 : loss : 0.039435, loss_ce: 0.014238
2021-12-10 11:16:59,947 iteration 2164 : loss : 0.039539, loss_ce: 0.019210
2021-12-10 11:17:01,509 iteration 2165 : loss : 0.050760, loss_ce: 0.018536
2021-12-10 11:17:03,006 iteration 2166 : loss : 0.041635, loss_ce: 0.017598
2021-12-10 11:17:04,467 iteration 2167 : loss : 0.034820, loss_ce: 0.012646
2021-12-10 11:17:05,986 iteration 2168 : loss : 0.034034, loss_ce: 0.013866
2021-12-10 11:17:07,554 iteration 2169 : loss : 0.064911, loss_ce: 0.025245
2021-12-10 11:17:08,984 iteration 2170 : loss : 0.032898, loss_ce: 0.010946
2021-12-10 11:17:10,503 iteration 2171 : loss : 0.062868, loss_ce: 0.023698
2021-12-10 11:17:12,008 iteration 2172 : loss : 0.070188, loss_ce: 0.026939
2021-12-10 11:17:13,508 iteration 2173 : loss : 0.044900, loss_ce: 0.012322
2021-12-10 11:17:15,054 iteration 2174 : loss : 0.041239, loss_ce: 0.016136
2021-12-10 11:17:16,682 iteration 2175 : loss : 0.048439, loss_ce: 0.024517
2021-12-10 11:17:18,111 iteration 2176 : loss : 0.036076, loss_ce: 0.018179
 32%|████████▋                  | 128/400 [1:01:29<2:05:14, 27.63s/it]2021-12-10 11:17:19,637 iteration 2177 : loss : 0.054408, loss_ce: 0.029733
2021-12-10 11:17:21,169 iteration 2178 : loss : 0.040253, loss_ce: 0.012152
2021-12-10 11:17:22,795 iteration 2179 : loss : 0.047005, loss_ce: 0.020612
2021-12-10 11:17:24,380 iteration 2180 : loss : 0.047909, loss_ce: 0.023068
2021-12-10 11:17:25,848 iteration 2181 : loss : 0.038557, loss_ce: 0.013744
2021-12-10 11:17:27,389 iteration 2182 : loss : 0.063074, loss_ce: 0.030238
2021-12-10 11:17:28,942 iteration 2183 : loss : 0.065030, loss_ce: 0.021829
2021-12-10 11:17:30,429 iteration 2184 : loss : 0.039768, loss_ce: 0.019603
2021-12-10 11:17:31,918 iteration 2185 : loss : 0.039904, loss_ce: 0.014077
2021-12-10 11:17:33,541 iteration 2186 : loss : 0.032188, loss_ce: 0.012907
2021-12-10 11:17:35,182 iteration 2187 : loss : 0.042536, loss_ce: 0.014643
2021-12-10 11:17:36,898 iteration 2188 : loss : 0.062870, loss_ce: 0.027788
2021-12-10 11:17:38,596 iteration 2189 : loss : 0.066926, loss_ce: 0.021848
2021-12-10 11:17:40,158 iteration 2190 : loss : 0.064170, loss_ce: 0.032001
2021-12-10 11:17:41,728 iteration 2191 : loss : 0.034291, loss_ce: 0.011603
2021-12-10 11:17:43,247 iteration 2192 : loss : 0.039165, loss_ce: 0.013602
2021-12-10 11:17:44,820 iteration 2193 : loss : 0.035102, loss_ce: 0.012848
 32%|████████▋                  | 129/400 [1:01:56<2:03:32, 27.35s/it]2021-12-10 11:17:46,459 iteration 2194 : loss : 0.048292, loss_ce: 0.018455
2021-12-10 11:17:48,038 iteration 2195 : loss : 0.051820, loss_ce: 0.024742
2021-12-10 11:17:49,639 iteration 2196 : loss : 0.041021, loss_ce: 0.016908
2021-12-10 11:17:51,288 iteration 2197 : loss : 0.038491, loss_ce: 0.013559
2021-12-10 11:17:52,838 iteration 2198 : loss : 0.054485, loss_ce: 0.019094
2021-12-10 11:17:54,409 iteration 2199 : loss : 0.035933, loss_ce: 0.015060
2021-12-10 11:17:56,038 iteration 2200 : loss : 0.122974, loss_ce: 0.038923
2021-12-10 11:17:57,532 iteration 2201 : loss : 0.041727, loss_ce: 0.018131
2021-12-10 11:17:59,205 iteration 2202 : loss : 0.045286, loss_ce: 0.019045
2021-12-10 11:18:00,785 iteration 2203 : loss : 0.051214, loss_ce: 0.014116
2021-12-10 11:18:02,273 iteration 2204 : loss : 0.041452, loss_ce: 0.011008
2021-12-10 11:18:03,823 iteration 2205 : loss : 0.051688, loss_ce: 0.025515
2021-12-10 11:18:05,473 iteration 2206 : loss : 0.049039, loss_ce: 0.021088
2021-12-10 11:18:07,055 iteration 2207 : loss : 0.071245, loss_ce: 0.021221
2021-12-10 11:18:08,680 iteration 2208 : loss : 0.054017, loss_ce: 0.015837
2021-12-10 11:18:10,228 iteration 2209 : loss : 0.065523, loss_ce: 0.026992
2021-12-10 11:18:10,228 Training Data Eval:
2021-12-10 11:18:17,961   Average segmentation loss on training set: 0.0343
2021-12-10 11:18:17,962 Validation Data Eval:
2021-12-10 11:18:20,622   Average segmentation loss on validation set: 0.0826
2021-12-10 11:18:22,210 iteration 2210 : loss : 0.051639, loss_ce: 0.027406
 32%|████████▊                  | 130/400 [1:02:33<2:16:37, 30.36s/it]2021-12-10 11:18:23,816 iteration 2211 : loss : 0.050733, loss_ce: 0.013517
2021-12-10 11:18:25,322 iteration 2212 : loss : 0.050184, loss_ce: 0.022513
2021-12-10 11:18:26,873 iteration 2213 : loss : 0.078401, loss_ce: 0.017769
2021-12-10 11:18:28,344 iteration 2214 : loss : 0.048037, loss_ce: 0.016063
2021-12-10 11:18:29,813 iteration 2215 : loss : 0.032369, loss_ce: 0.012154
2021-12-10 11:18:31,322 iteration 2216 : loss : 0.057660, loss_ce: 0.034907
2021-12-10 11:18:32,815 iteration 2217 : loss : 0.046502, loss_ce: 0.022373
2021-12-10 11:18:34,335 iteration 2218 : loss : 0.030241, loss_ce: 0.010408
2021-12-10 11:18:35,901 iteration 2219 : loss : 0.048867, loss_ce: 0.023062
2021-12-10 11:18:37,547 iteration 2220 : loss : 0.055411, loss_ce: 0.027219
2021-12-10 11:18:39,166 iteration 2221 : loss : 0.041002, loss_ce: 0.013264
2021-12-10 11:18:40,623 iteration 2222 : loss : 0.041178, loss_ce: 0.015967
2021-12-10 11:18:42,113 iteration 2223 : loss : 0.042139, loss_ce: 0.014146
2021-12-10 11:18:43,722 iteration 2224 : loss : 0.043233, loss_ce: 0.017310
2021-12-10 11:18:45,293 iteration 2225 : loss : 0.051808, loss_ce: 0.016974
2021-12-10 11:18:46,911 iteration 2226 : loss : 0.050962, loss_ce: 0.023874
2021-12-10 11:18:48,510 iteration 2227 : loss : 0.045858, loss_ce: 0.014171
 33%|████████▊                  | 131/400 [1:02:59<2:10:39, 29.14s/it]2021-12-10 11:18:50,199 iteration 2228 : loss : 0.050628, loss_ce: 0.021867
2021-12-10 11:18:51,768 iteration 2229 : loss : 0.046445, loss_ce: 0.017850
2021-12-10 11:18:53,508 iteration 2230 : loss : 0.042326, loss_ce: 0.016124
2021-12-10 11:18:55,039 iteration 2231 : loss : 0.063387, loss_ce: 0.033743
2021-12-10 11:18:56,580 iteration 2232 : loss : 0.041330, loss_ce: 0.019994
2021-12-10 11:18:58,343 iteration 2233 : loss : 0.111083, loss_ce: 0.026793
2021-12-10 11:18:59,931 iteration 2234 : loss : 0.053046, loss_ce: 0.015158
2021-12-10 11:19:01,487 iteration 2235 : loss : 0.039782, loss_ce: 0.015289
2021-12-10 11:19:03,014 iteration 2236 : loss : 0.038345, loss_ce: 0.014709
2021-12-10 11:19:04,560 iteration 2237 : loss : 0.043331, loss_ce: 0.020396
2021-12-10 11:19:06,047 iteration 2238 : loss : 0.041290, loss_ce: 0.012002
2021-12-10 11:19:07,553 iteration 2239 : loss : 0.033097, loss_ce: 0.009646
2021-12-10 11:19:09,015 iteration 2240 : loss : 0.039104, loss_ce: 0.011407
2021-12-10 11:19:10,556 iteration 2241 : loss : 0.037129, loss_ce: 0.013066
2021-12-10 11:19:12,171 iteration 2242 : loss : 0.062067, loss_ce: 0.019050
2021-12-10 11:19:13,760 iteration 2243 : loss : 0.080346, loss_ce: 0.040947
2021-12-10 11:19:15,293 iteration 2244 : loss : 0.023784, loss_ce: 0.008314
 33%|████████▉                  | 132/400 [1:03:26<2:07:00, 28.44s/it]2021-12-10 11:19:16,895 iteration 2245 : loss : 0.029511, loss_ce: 0.010014
2021-12-10 11:19:18,340 iteration 2246 : loss : 0.031158, loss_ce: 0.009122
2021-12-10 11:19:19,903 iteration 2247 : loss : 0.048908, loss_ce: 0.024046
2021-12-10 11:19:21,526 iteration 2248 : loss : 0.087188, loss_ce: 0.038190
2021-12-10 11:19:23,085 iteration 2249 : loss : 0.033416, loss_ce: 0.016155
2021-12-10 11:19:24,632 iteration 2250 : loss : 0.034157, loss_ce: 0.013399
2021-12-10 11:19:26,236 iteration 2251 : loss : 0.037505, loss_ce: 0.016646
2021-12-10 11:19:27,794 iteration 2252 : loss : 0.049799, loss_ce: 0.017167
2021-12-10 11:19:29,442 iteration 2253 : loss : 0.070078, loss_ce: 0.028775
2021-12-10 11:19:31,042 iteration 2254 : loss : 0.033430, loss_ce: 0.014125
2021-12-10 11:19:32,599 iteration 2255 : loss : 0.035375, loss_ce: 0.013772
2021-12-10 11:19:34,135 iteration 2256 : loss : 0.036751, loss_ce: 0.016523
2021-12-10 11:19:35,631 iteration 2257 : loss : 0.055115, loss_ce: 0.018384
2021-12-10 11:19:37,125 iteration 2258 : loss : 0.048879, loss_ce: 0.019029
2021-12-10 11:19:38,730 iteration 2259 : loss : 0.047612, loss_ce: 0.019873
2021-12-10 11:19:40,201 iteration 2260 : loss : 0.044506, loss_ce: 0.018217
2021-12-10 11:19:41,772 iteration 2261 : loss : 0.076083, loss_ce: 0.033280
 33%|████████▉                  | 133/400 [1:03:53<2:03:55, 27.85s/it]2021-12-10 11:19:43,321 iteration 2262 : loss : 0.041119, loss_ce: 0.020517
2021-12-10 11:19:44,934 iteration 2263 : loss : 0.050520, loss_ce: 0.016512
2021-12-10 11:19:46,586 iteration 2264 : loss : 0.044673, loss_ce: 0.013804
2021-12-10 11:19:48,172 iteration 2265 : loss : 0.036503, loss_ce: 0.013547
2021-12-10 11:19:49,690 iteration 2266 : loss : 0.038244, loss_ce: 0.014869
2021-12-10 11:19:51,215 iteration 2267 : loss : 0.039100, loss_ce: 0.015393
2021-12-10 11:19:52,770 iteration 2268 : loss : 0.043968, loss_ce: 0.018398
2021-12-10 11:19:54,271 iteration 2269 : loss : 0.036867, loss_ce: 0.021660
2021-12-10 11:19:55,820 iteration 2270 : loss : 0.062680, loss_ce: 0.023511
2021-12-10 11:19:57,340 iteration 2271 : loss : 0.047412, loss_ce: 0.018823
2021-12-10 11:19:58,868 iteration 2272 : loss : 0.052331, loss_ce: 0.027311
2021-12-10 11:20:00,442 iteration 2273 : loss : 0.041101, loss_ce: 0.014284
2021-12-10 11:20:02,007 iteration 2274 : loss : 0.044014, loss_ce: 0.014513
2021-12-10 11:20:03,607 iteration 2275 : loss : 0.065002, loss_ce: 0.023855
2021-12-10 11:20:05,092 iteration 2276 : loss : 0.035026, loss_ce: 0.013495
2021-12-10 11:20:06,656 iteration 2277 : loss : 0.051663, loss_ce: 0.018375
2021-12-10 11:20:08,166 iteration 2278 : loss : 0.028650, loss_ce: 0.010492
 34%|█████████                  | 134/400 [1:04:19<2:01:30, 27.41s/it]2021-12-10 11:20:09,688 iteration 2279 : loss : 0.081499, loss_ce: 0.036685
2021-12-10 11:20:11,238 iteration 2280 : loss : 0.044259, loss_ce: 0.020660
2021-12-10 11:20:12,778 iteration 2281 : loss : 0.043264, loss_ce: 0.011593
2021-12-10 11:20:14,360 iteration 2282 : loss : 0.045821, loss_ce: 0.018830
2021-12-10 11:20:15,985 iteration 2283 : loss : 0.084087, loss_ce: 0.051439
2021-12-10 11:20:17,510 iteration 2284 : loss : 0.043612, loss_ce: 0.020596
2021-12-10 11:20:19,037 iteration 2285 : loss : 0.044844, loss_ce: 0.019001
2021-12-10 11:20:20,569 iteration 2286 : loss : 0.044740, loss_ce: 0.018286
2021-12-10 11:20:22,107 iteration 2287 : loss : 0.042604, loss_ce: 0.016702
2021-12-10 11:20:23,697 iteration 2288 : loss : 0.049802, loss_ce: 0.018588
2021-12-10 11:20:25,198 iteration 2289 : loss : 0.052685, loss_ce: 0.015721
2021-12-10 11:20:26,804 iteration 2290 : loss : 0.062880, loss_ce: 0.033415
2021-12-10 11:20:28,344 iteration 2291 : loss : 0.033129, loss_ce: 0.012465
2021-12-10 11:20:29,878 iteration 2292 : loss : 0.056174, loss_ce: 0.026300
2021-12-10 11:20:31,342 iteration 2293 : loss : 0.060766, loss_ce: 0.036146
2021-12-10 11:20:32,926 iteration 2294 : loss : 0.085492, loss_ce: 0.034221
2021-12-10 11:20:32,926 Training Data Eval:
2021-12-10 11:20:40,664   Average segmentation loss on training set: 0.0397
2021-12-10 11:20:40,664 Validation Data Eval:
2021-12-10 11:20:43,324   Average segmentation loss on validation set: 0.1060
2021-12-10 11:20:44,949 iteration 2295 : loss : 0.045269, loss_ce: 0.020192
 34%|█████████                  | 135/400 [1:04:56<2:13:29, 30.22s/it]2021-12-10 11:20:46,467 iteration 2296 : loss : 0.037754, loss_ce: 0.016264
2021-12-10 11:20:47,992 iteration 2297 : loss : 0.042516, loss_ce: 0.021296
2021-12-10 11:20:49,516 iteration 2298 : loss : 0.037742, loss_ce: 0.017850
2021-12-10 11:20:51,125 iteration 2299 : loss : 0.075337, loss_ce: 0.035791
2021-12-10 11:20:52,632 iteration 2300 : loss : 0.041594, loss_ce: 0.018019
2021-12-10 11:20:54,247 iteration 2301 : loss : 0.045445, loss_ce: 0.013265
2021-12-10 11:20:55,828 iteration 2302 : loss : 0.086121, loss_ce: 0.028890
2021-12-10 11:20:57,392 iteration 2303 : loss : 0.044706, loss_ce: 0.016482
2021-12-10 11:20:59,031 iteration 2304 : loss : 0.043597, loss_ce: 0.014790
2021-12-10 11:21:00,625 iteration 2305 : loss : 0.044627, loss_ce: 0.017916
2021-12-10 11:21:02,283 iteration 2306 : loss : 0.042793, loss_ce: 0.019759
2021-12-10 11:21:03,818 iteration 2307 : loss : 0.078791, loss_ce: 0.030228
2021-12-10 11:21:05,317 iteration 2308 : loss : 0.035772, loss_ce: 0.012614
2021-12-10 11:21:06,836 iteration 2309 : loss : 0.043945, loss_ce: 0.019341
2021-12-10 11:21:08,452 iteration 2310 : loss : 0.034167, loss_ce: 0.013932
2021-12-10 11:21:09,920 iteration 2311 : loss : 0.054059, loss_ce: 0.017817
2021-12-10 11:21:11,479 iteration 2312 : loss : 0.074945, loss_ce: 0.025508
 34%|█████████▏                 | 136/400 [1:05:22<2:08:05, 29.11s/it]2021-12-10 11:21:13,115 iteration 2313 : loss : 0.040190, loss_ce: 0.014889
2021-12-10 11:21:14,561 iteration 2314 : loss : 0.039513, loss_ce: 0.012613
2021-12-10 11:21:16,052 iteration 2315 : loss : 0.035669, loss_ce: 0.012348
2021-12-10 11:21:17,691 iteration 2316 : loss : 0.049205, loss_ce: 0.018117
2021-12-10 11:21:19,174 iteration 2317 : loss : 0.035682, loss_ce: 0.012458
2021-12-10 11:21:20,688 iteration 2318 : loss : 0.042042, loss_ce: 0.019326
2021-12-10 11:21:22,229 iteration 2319 : loss : 0.061224, loss_ce: 0.033642
2021-12-10 11:21:23,848 iteration 2320 : loss : 0.050193, loss_ce: 0.019605
2021-12-10 11:21:25,397 iteration 2321 : loss : 0.049549, loss_ce: 0.022082
2021-12-10 11:21:26,963 iteration 2322 : loss : 0.041262, loss_ce: 0.017581
2021-12-10 11:21:28,417 iteration 2323 : loss : 0.034243, loss_ce: 0.012853
2021-12-10 11:21:29,940 iteration 2324 : loss : 0.035202, loss_ce: 0.015141
2021-12-10 11:21:31,364 iteration 2325 : loss : 0.030933, loss_ce: 0.014134
2021-12-10 11:21:32,880 iteration 2326 : loss : 0.064232, loss_ce: 0.015059
2021-12-10 11:21:34,378 iteration 2327 : loss : 0.052406, loss_ce: 0.020844
2021-12-10 11:21:35,923 iteration 2328 : loss : 0.074144, loss_ce: 0.037523
2021-12-10 11:21:37,404 iteration 2329 : loss : 0.037706, loss_ce: 0.015356
 34%|█████████▏                 | 137/400 [1:05:48<2:03:25, 28.16s/it]2021-12-10 11:21:39,005 iteration 2330 : loss : 0.069572, loss_ce: 0.031574
2021-12-10 11:21:40,494 iteration 2331 : loss : 0.057133, loss_ce: 0.022565
2021-12-10 11:21:42,127 iteration 2332 : loss : 0.044274, loss_ce: 0.018869
2021-12-10 11:21:43,676 iteration 2333 : loss : 0.054756, loss_ce: 0.024357
2021-12-10 11:21:45,345 iteration 2334 : loss : 0.048126, loss_ce: 0.020212
2021-12-10 11:21:47,009 iteration 2335 : loss : 0.058947, loss_ce: 0.029198
2021-12-10 11:21:48,641 iteration 2336 : loss : 0.044118, loss_ce: 0.020478
2021-12-10 11:21:50,200 iteration 2337 : loss : 0.059129, loss_ce: 0.019666
2021-12-10 11:21:51,787 iteration 2338 : loss : 0.051650, loss_ce: 0.019677
2021-12-10 11:21:53,368 iteration 2339 : loss : 0.070073, loss_ce: 0.023388
2021-12-10 11:21:54,850 iteration 2340 : loss : 0.043219, loss_ce: 0.017041
2021-12-10 11:21:56,413 iteration 2341 : loss : 0.036749, loss_ce: 0.016239
2021-12-10 11:21:57,990 iteration 2342 : loss : 0.038493, loss_ce: 0.015437
2021-12-10 11:21:59,674 iteration 2343 : loss : 0.065058, loss_ce: 0.023183
2021-12-10 11:22:01,176 iteration 2344 : loss : 0.066683, loss_ce: 0.019462
2021-12-10 11:22:02,683 iteration 2345 : loss : 0.058147, loss_ce: 0.026223
2021-12-10 11:22:04,228 iteration 2346 : loss : 0.061351, loss_ce: 0.022867
 34%|█████████▎                 | 138/400 [1:06:15<2:01:13, 27.76s/it]2021-12-10 11:22:05,928 iteration 2347 : loss : 0.047546, loss_ce: 0.018879
2021-12-10 11:22:07,501 iteration 2348 : loss : 0.044043, loss_ce: 0.014262
2021-12-10 11:22:09,018 iteration 2349 : loss : 0.034396, loss_ce: 0.013061
2021-12-10 11:22:10,553 iteration 2350 : loss : 0.061743, loss_ce: 0.022073
2021-12-10 11:22:12,189 iteration 2351 : loss : 0.053738, loss_ce: 0.026200
2021-12-10 11:22:13,691 iteration 2352 : loss : 0.031570, loss_ce: 0.016088
2021-12-10 11:22:15,203 iteration 2353 : loss : 0.034145, loss_ce: 0.014873
2021-12-10 11:22:16,694 iteration 2354 : loss : 0.026618, loss_ce: 0.012416
2021-12-10 11:22:18,203 iteration 2355 : loss : 0.047942, loss_ce: 0.018441
2021-12-10 11:22:19,811 iteration 2356 : loss : 0.053133, loss_ce: 0.020192
2021-12-10 11:22:21,363 iteration 2357 : loss : 0.070219, loss_ce: 0.022848
2021-12-10 11:22:22,929 iteration 2358 : loss : 0.044906, loss_ce: 0.019668
2021-12-10 11:22:24,439 iteration 2359 : loss : 0.070530, loss_ce: 0.028671
2021-12-10 11:22:25,932 iteration 2360 : loss : 0.057991, loss_ce: 0.016837
2021-12-10 11:22:27,481 iteration 2361 : loss : 0.044287, loss_ce: 0.015104
2021-12-10 11:22:29,146 iteration 2362 : loss : 0.053414, loss_ce: 0.024916
2021-12-10 11:22:30,706 iteration 2363 : loss : 0.037901, loss_ce: 0.017129
 35%|█████████▍                 | 139/400 [1:06:42<1:59:05, 27.38s/it]2021-12-10 11:22:32,391 iteration 2364 : loss : 0.034346, loss_ce: 0.013510
2021-12-10 11:22:34,045 iteration 2365 : loss : 0.051980, loss_ce: 0.017154
2021-12-10 11:22:35,645 iteration 2366 : loss : 0.069323, loss_ce: 0.031741
2021-12-10 11:22:37,140 iteration 2367 : loss : 0.041831, loss_ce: 0.010959
2021-12-10 11:22:38,627 iteration 2368 : loss : 0.032740, loss_ce: 0.013037
2021-12-10 11:22:40,181 iteration 2369 : loss : 0.068598, loss_ce: 0.022180
2021-12-10 11:22:41,724 iteration 2370 : loss : 0.060932, loss_ce: 0.022765
2021-12-10 11:22:43,307 iteration 2371 : loss : 0.037467, loss_ce: 0.016021
2021-12-10 11:22:44,814 iteration 2372 : loss : 0.032550, loss_ce: 0.011431
2021-12-10 11:22:46,333 iteration 2373 : loss : 0.047265, loss_ce: 0.018701
2021-12-10 11:22:47,822 iteration 2374 : loss : 0.041307, loss_ce: 0.018359
2021-12-10 11:22:49,327 iteration 2375 : loss : 0.030239, loss_ce: 0.011056
2021-12-10 11:22:50,890 iteration 2376 : loss : 0.051045, loss_ce: 0.026984
2021-12-10 11:22:52,445 iteration 2377 : loss : 0.053788, loss_ce: 0.027534
2021-12-10 11:22:54,009 iteration 2378 : loss : 0.034250, loss_ce: 0.013909
2021-12-10 11:22:55,596 iteration 2379 : loss : 0.050564, loss_ce: 0.021838
2021-12-10 11:22:55,596 Training Data Eval:
2021-12-10 11:23:03,342   Average segmentation loss on training set: 0.0258
2021-12-10 11:23:03,342 Validation Data Eval:
2021-12-10 11:23:05,995   Average segmentation loss on validation set: 0.0766
2021-12-10 11:23:11,728 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 11:23:13,268 iteration 2380 : loss : 0.033872, loss_ce: 0.017149
 35%|█████████▍                 | 140/400 [1:07:24<2:18:21, 31.93s/it]2021-12-10 11:23:14,805 iteration 2381 : loss : 0.051911, loss_ce: 0.018128
2021-12-10 11:23:16,387 iteration 2382 : loss : 0.042760, loss_ce: 0.016154
2021-12-10 11:23:17,885 iteration 2383 : loss : 0.031820, loss_ce: 0.011764
2021-12-10 11:23:19,475 iteration 2384 : loss : 0.045216, loss_ce: 0.017847
2021-12-10 11:23:21,083 iteration 2385 : loss : 0.036216, loss_ce: 0.014576
2021-12-10 11:23:22,613 iteration 2386 : loss : 0.040061, loss_ce: 0.012891
2021-12-10 11:23:24,128 iteration 2387 : loss : 0.046780, loss_ce: 0.015249
2021-12-10 11:23:25,666 iteration 2388 : loss : 0.041622, loss_ce: 0.018367
2021-12-10 11:23:27,137 iteration 2389 : loss : 0.021251, loss_ce: 0.007192
2021-12-10 11:23:28,689 iteration 2390 : loss : 0.034751, loss_ce: 0.018050
2021-12-10 11:23:30,205 iteration 2391 : loss : 0.039552, loss_ce: 0.023452
2021-12-10 11:23:31,783 iteration 2392 : loss : 0.047957, loss_ce: 0.020342
2021-12-10 11:23:33,347 iteration 2393 : loss : 0.049004, loss_ce: 0.015819
2021-12-10 11:23:34,789 iteration 2394 : loss : 0.031563, loss_ce: 0.010101
2021-12-10 11:23:36,390 iteration 2395 : loss : 0.031344, loss_ce: 0.013392
2021-12-10 11:23:37,882 iteration 2396 : loss : 0.026143, loss_ce: 0.011780
2021-12-10 11:23:39,460 iteration 2397 : loss : 0.036849, loss_ce: 0.013061
 35%|█████████▌                 | 141/400 [1:07:50<2:10:24, 30.21s/it]2021-12-10 11:23:41,053 iteration 2398 : loss : 0.049990, loss_ce: 0.018896
2021-12-10 11:23:42,561 iteration 2399 : loss : 0.039507, loss_ce: 0.012375
2021-12-10 11:23:44,168 iteration 2400 : loss : 0.043851, loss_ce: 0.019777
2021-12-10 11:23:45,716 iteration 2401 : loss : 0.036687, loss_ce: 0.012742
2021-12-10 11:23:47,321 iteration 2402 : loss : 0.049473, loss_ce: 0.027850
2021-12-10 11:23:48,823 iteration 2403 : loss : 0.039093, loss_ce: 0.016809
2021-12-10 11:23:50,311 iteration 2404 : loss : 0.033866, loss_ce: 0.014954
2021-12-10 11:23:51,771 iteration 2405 : loss : 0.037005, loss_ce: 0.012693
2021-12-10 11:23:53,438 iteration 2406 : loss : 0.038173, loss_ce: 0.013610
2021-12-10 11:23:54,921 iteration 2407 : loss : 0.040116, loss_ce: 0.020465
2021-12-10 11:23:56,404 iteration 2408 : loss : 0.026569, loss_ce: 0.011461
2021-12-10 11:23:57,988 iteration 2409 : loss : 0.033914, loss_ce: 0.011665
2021-12-10 11:23:59,589 iteration 2410 : loss : 0.048689, loss_ce: 0.020507
2021-12-10 11:24:01,167 iteration 2411 : loss : 0.048456, loss_ce: 0.013634
2021-12-10 11:24:02,666 iteration 2412 : loss : 0.024941, loss_ce: 0.010231
2021-12-10 11:24:04,285 iteration 2413 : loss : 0.053557, loss_ce: 0.021190
2021-12-10 11:24:05,835 iteration 2414 : loss : 0.032047, loss_ce: 0.012393
 36%|█████████▌                 | 142/400 [1:08:17<2:04:57, 29.06s/it]2021-12-10 11:24:07,468 iteration 2415 : loss : 0.043171, loss_ce: 0.015228
2021-12-10 11:24:08,996 iteration 2416 : loss : 0.036515, loss_ce: 0.013919
2021-12-10 11:24:10,537 iteration 2417 : loss : 0.036342, loss_ce: 0.011368
2021-12-10 11:24:12,175 iteration 2418 : loss : 0.049474, loss_ce: 0.017117
2021-12-10 11:24:13,736 iteration 2419 : loss : 0.041723, loss_ce: 0.020181
2021-12-10 11:24:15,397 iteration 2420 : loss : 0.047235, loss_ce: 0.023740
2021-12-10 11:24:17,033 iteration 2421 : loss : 0.068269, loss_ce: 0.024374
2021-12-10 11:24:18,642 iteration 2422 : loss : 0.049735, loss_ce: 0.023352
2021-12-10 11:24:20,191 iteration 2423 : loss : 0.041825, loss_ce: 0.013928
2021-12-10 11:24:21,719 iteration 2424 : loss : 0.030346, loss_ce: 0.012513
2021-12-10 11:24:23,386 iteration 2425 : loss : 0.040918, loss_ce: 0.015710
2021-12-10 11:24:24,921 iteration 2426 : loss : 0.044092, loss_ce: 0.015751
2021-12-10 11:24:26,367 iteration 2427 : loss : 0.034411, loss_ce: 0.016101
2021-12-10 11:24:27,866 iteration 2428 : loss : 0.033012, loss_ce: 0.010668
2021-12-10 11:24:29,372 iteration 2429 : loss : 0.044354, loss_ce: 0.018248
2021-12-10 11:24:30,881 iteration 2430 : loss : 0.022316, loss_ce: 0.007735
2021-12-10 11:24:32,428 iteration 2431 : loss : 0.040563, loss_ce: 0.022560
 36%|█████████▋                 | 143/400 [1:08:43<2:01:17, 28.32s/it]2021-12-10 11:24:33,992 iteration 2432 : loss : 0.035964, loss_ce: 0.010973
2021-12-10 11:24:35,513 iteration 2433 : loss : 0.042073, loss_ce: 0.017399
2021-12-10 11:24:37,053 iteration 2434 : loss : 0.035684, loss_ce: 0.011182
2021-12-10 11:24:38,681 iteration 2435 : loss : 0.059800, loss_ce: 0.033528
2021-12-10 11:24:40,135 iteration 2436 : loss : 0.032169, loss_ce: 0.013379
2021-12-10 11:24:41,713 iteration 2437 : loss : 0.030872, loss_ce: 0.010763
2021-12-10 11:24:43,308 iteration 2438 : loss : 0.043080, loss_ce: 0.013308
2021-12-10 11:24:44,882 iteration 2439 : loss : 0.029768, loss_ce: 0.011484
2021-12-10 11:24:46,472 iteration 2440 : loss : 0.055135, loss_ce: 0.023706
2021-12-10 11:24:47,998 iteration 2441 : loss : 0.032118, loss_ce: 0.011024
2021-12-10 11:24:49,519 iteration 2442 : loss : 0.037341, loss_ce: 0.014468
2021-12-10 11:24:50,987 iteration 2443 : loss : 0.035457, loss_ce: 0.013679
2021-12-10 11:24:52,520 iteration 2444 : loss : 0.038398, loss_ce: 0.014903
2021-12-10 11:24:54,082 iteration 2445 : loss : 0.033721, loss_ce: 0.013866
2021-12-10 11:24:55,716 iteration 2446 : loss : 0.056405, loss_ce: 0.027234
2021-12-10 11:24:57,197 iteration 2447 : loss : 0.030771, loss_ce: 0.009740
2021-12-10 11:24:58,782 iteration 2448 : loss : 0.038216, loss_ce: 0.013702
 36%|█████████▋                 | 144/400 [1:09:10<1:58:18, 27.73s/it]2021-12-10 11:25:00,314 iteration 2449 : loss : 0.046252, loss_ce: 0.016736
2021-12-10 11:25:01,797 iteration 2450 : loss : 0.030291, loss_ce: 0.016092
2021-12-10 11:25:03,314 iteration 2451 : loss : 0.042342, loss_ce: 0.014776
2021-12-10 11:25:04,808 iteration 2452 : loss : 0.034711, loss_ce: 0.012506
2021-12-10 11:25:06,361 iteration 2453 : loss : 0.047216, loss_ce: 0.014980
2021-12-10 11:25:07,881 iteration 2454 : loss : 0.041536, loss_ce: 0.014717
2021-12-10 11:25:09,374 iteration 2455 : loss : 0.035759, loss_ce: 0.017292
2021-12-10 11:25:10,845 iteration 2456 : loss : 0.037177, loss_ce: 0.019231
2021-12-10 11:25:12,361 iteration 2457 : loss : 0.036176, loss_ce: 0.014300
2021-12-10 11:25:13,842 iteration 2458 : loss : 0.027769, loss_ce: 0.010999
2021-12-10 11:25:15,288 iteration 2459 : loss : 0.023788, loss_ce: 0.009356
2021-12-10 11:25:16,785 iteration 2460 : loss : 0.038896, loss_ce: 0.009948
2021-12-10 11:25:18,401 iteration 2461 : loss : 0.034122, loss_ce: 0.012369
2021-12-10 11:25:19,975 iteration 2462 : loss : 0.073545, loss_ce: 0.024139
2021-12-10 11:25:21,488 iteration 2463 : loss : 0.034369, loss_ce: 0.014519
2021-12-10 11:25:23,054 iteration 2464 : loss : 0.031465, loss_ce: 0.012558
2021-12-10 11:25:23,054 Training Data Eval:
2021-12-10 11:25:30,805   Average segmentation loss on training set: 0.0245
2021-12-10 11:25:30,806 Validation Data Eval:
2021-12-10 11:25:33,472   Average segmentation loss on validation set: 0.0883
2021-12-10 11:25:34,989 iteration 2465 : loss : 0.032625, loss_ce: 0.013572
 36%|█████████▊                 | 145/400 [1:09:46<2:08:38, 30.27s/it]2021-12-10 11:25:36,646 iteration 2466 : loss : 0.044141, loss_ce: 0.015957
2021-12-10 11:25:38,263 iteration 2467 : loss : 0.039378, loss_ce: 0.016793
2021-12-10 11:25:39,786 iteration 2468 : loss : 0.034184, loss_ce: 0.014157
2021-12-10 11:25:41,271 iteration 2469 : loss : 0.031737, loss_ce: 0.013753
2021-12-10 11:25:42,800 iteration 2470 : loss : 0.039874, loss_ce: 0.013047
2021-12-10 11:25:44,442 iteration 2471 : loss : 0.047679, loss_ce: 0.016542
2021-12-10 11:25:45,949 iteration 2472 : loss : 0.054639, loss_ce: 0.022137
2021-12-10 11:25:47,555 iteration 2473 : loss : 0.036555, loss_ce: 0.015118
2021-12-10 11:25:49,059 iteration 2474 : loss : 0.036745, loss_ce: 0.013595
2021-12-10 11:25:50,604 iteration 2475 : loss : 0.038424, loss_ce: 0.014552
2021-12-10 11:25:52,083 iteration 2476 : loss : 0.037944, loss_ce: 0.020371
2021-12-10 11:25:53,688 iteration 2477 : loss : 0.049502, loss_ce: 0.020895
2021-12-10 11:25:55,249 iteration 2478 : loss : 0.031124, loss_ce: 0.011223
2021-12-10 11:25:56,700 iteration 2479 : loss : 0.031576, loss_ce: 0.010031
2021-12-10 11:25:58,248 iteration 2480 : loss : 0.035788, loss_ce: 0.014318
2021-12-10 11:25:59,859 iteration 2481 : loss : 0.030595, loss_ce: 0.012395
2021-12-10 11:26:01,377 iteration 2482 : loss : 0.032643, loss_ce: 0.013573
 36%|█████████▊                 | 146/400 [1:10:12<2:03:12, 29.10s/it]2021-12-10 11:26:03,047 iteration 2483 : loss : 0.043605, loss_ce: 0.017776
2021-12-10 11:26:04,622 iteration 2484 : loss : 0.045429, loss_ce: 0.009998
2021-12-10 11:26:06,134 iteration 2485 : loss : 0.033042, loss_ce: 0.013188
2021-12-10 11:26:07,672 iteration 2486 : loss : 0.038575, loss_ce: 0.017652
2021-12-10 11:26:09,193 iteration 2487 : loss : 0.045129, loss_ce: 0.013649
2021-12-10 11:26:10,802 iteration 2488 : loss : 0.047186, loss_ce: 0.024971
2021-12-10 11:26:12,320 iteration 2489 : loss : 0.035603, loss_ce: 0.015992
2021-12-10 11:26:13,925 iteration 2490 : loss : 0.050103, loss_ce: 0.019293
2021-12-10 11:26:15,557 iteration 2491 : loss : 0.040198, loss_ce: 0.017107
2021-12-10 11:26:17,007 iteration 2492 : loss : 0.032707, loss_ce: 0.011594
2021-12-10 11:26:18,572 iteration 2493 : loss : 0.034131, loss_ce: 0.014956
2021-12-10 11:26:20,089 iteration 2494 : loss : 0.049264, loss_ce: 0.014109
2021-12-10 11:26:21,610 iteration 2495 : loss : 0.037080, loss_ce: 0.017775
2021-12-10 11:26:23,342 iteration 2496 : loss : 0.054050, loss_ce: 0.015114
2021-12-10 11:26:24,941 iteration 2497 : loss : 0.048531, loss_ce: 0.019315
2021-12-10 11:26:26,541 iteration 2498 : loss : 0.039306, loss_ce: 0.015544
2021-12-10 11:26:28,023 iteration 2499 : loss : 0.025897, loss_ce: 0.006321
 37%|█████████▉                 | 147/400 [1:10:39<1:59:36, 28.37s/it]2021-12-10 11:26:29,602 iteration 2500 : loss : 0.051752, loss_ce: 0.019395
2021-12-10 11:26:31,133 iteration 2501 : loss : 0.028702, loss_ce: 0.007746
2021-12-10 11:26:32,758 iteration 2502 : loss : 0.065305, loss_ce: 0.024354
2021-12-10 11:26:34,234 iteration 2503 : loss : 0.040602, loss_ce: 0.014397
2021-12-10 11:26:35,741 iteration 2504 : loss : 0.025257, loss_ce: 0.008720
2021-12-10 11:26:37,329 iteration 2505 : loss : 0.040995, loss_ce: 0.015058
2021-12-10 11:26:38,864 iteration 2506 : loss : 0.037019, loss_ce: 0.011739
2021-12-10 11:26:40,353 iteration 2507 : loss : 0.038246, loss_ce: 0.014751
2021-12-10 11:26:41,864 iteration 2508 : loss : 0.035669, loss_ce: 0.012705
2021-12-10 11:26:43,386 iteration 2509 : loss : 0.062152, loss_ce: 0.021648
2021-12-10 11:26:44,892 iteration 2510 : loss : 0.031041, loss_ce: 0.014390
2021-12-10 11:26:46,439 iteration 2511 : loss : 0.033282, loss_ce: 0.014761
2021-12-10 11:26:47,998 iteration 2512 : loss : 0.046858, loss_ce: 0.018249
2021-12-10 11:26:49,600 iteration 2513 : loss : 0.039435, loss_ce: 0.012670
2021-12-10 11:26:51,158 iteration 2514 : loss : 0.042372, loss_ce: 0.012911
2021-12-10 11:26:52,700 iteration 2515 : loss : 0.027658, loss_ce: 0.015954
2021-12-10 11:26:54,220 iteration 2516 : loss : 0.030802, loss_ce: 0.014578
 37%|█████████▉                 | 148/400 [1:11:05<1:56:24, 27.72s/it]2021-12-10 11:26:55,780 iteration 2517 : loss : 0.034246, loss_ce: 0.013284
2021-12-10 11:26:57,315 iteration 2518 : loss : 0.046776, loss_ce: 0.013969
2021-12-10 11:26:58,877 iteration 2519 : loss : 0.038700, loss_ce: 0.015599
2021-12-10 11:27:00,421 iteration 2520 : loss : 0.049780, loss_ce: 0.020137
2021-12-10 11:27:01,948 iteration 2521 : loss : 0.035975, loss_ce: 0.012510
2021-12-10 11:27:03,503 iteration 2522 : loss : 0.033676, loss_ce: 0.017216
2021-12-10 11:27:05,102 iteration 2523 : loss : 0.066294, loss_ce: 0.017904
2021-12-10 11:27:06,621 iteration 2524 : loss : 0.034191, loss_ce: 0.013732
2021-12-10 11:27:08,176 iteration 2525 : loss : 0.043775, loss_ce: 0.017219
2021-12-10 11:27:09,739 iteration 2526 : loss : 0.043609, loss_ce: 0.016764
2021-12-10 11:27:11,286 iteration 2527 : loss : 0.029265, loss_ce: 0.010330
2021-12-10 11:27:12,852 iteration 2528 : loss : 0.039464, loss_ce: 0.013151
2021-12-10 11:27:14,407 iteration 2529 : loss : 0.041746, loss_ce: 0.015722
2021-12-10 11:27:15,975 iteration 2530 : loss : 0.035231, loss_ce: 0.017063
2021-12-10 11:27:17,600 iteration 2531 : loss : 0.034333, loss_ce: 0.014760
2021-12-10 11:27:19,143 iteration 2532 : loss : 0.047551, loss_ce: 0.016603
2021-12-10 11:27:20,721 iteration 2533 : loss : 0.044073, loss_ce: 0.012567
 37%|██████████                 | 149/400 [1:11:32<1:54:24, 27.35s/it]2021-12-10 11:27:22,233 iteration 2534 : loss : 0.032270, loss_ce: 0.013431
2021-12-10 11:27:23,855 iteration 2535 : loss : 0.032819, loss_ce: 0.010931
2021-12-10 11:27:25,359 iteration 2536 : loss : 0.046363, loss_ce: 0.021492
2021-12-10 11:27:26,868 iteration 2537 : loss : 0.036648, loss_ce: 0.013697
2021-12-10 11:27:28,298 iteration 2538 : loss : 0.024990, loss_ce: 0.011297
2021-12-10 11:27:29,877 iteration 2539 : loss : 0.040082, loss_ce: 0.016794
2021-12-10 11:27:31,375 iteration 2540 : loss : 0.026088, loss_ce: 0.008805
2021-12-10 11:27:32,886 iteration 2541 : loss : 0.039896, loss_ce: 0.017281
2021-12-10 11:27:34,360 iteration 2542 : loss : 0.024489, loss_ce: 0.008735
2021-12-10 11:27:35,843 iteration 2543 : loss : 0.031606, loss_ce: 0.011255
2021-12-10 11:27:37,377 iteration 2544 : loss : 0.048450, loss_ce: 0.017911
2021-12-10 11:27:39,044 iteration 2545 : loss : 0.031802, loss_ce: 0.012752
2021-12-10 11:27:40,716 iteration 2546 : loss : 0.051391, loss_ce: 0.023316
2021-12-10 11:27:42,201 iteration 2547 : loss : 0.023835, loss_ce: 0.011407
2021-12-10 11:27:43,766 iteration 2548 : loss : 0.030920, loss_ce: 0.013919
2021-12-10 11:27:45,324 iteration 2549 : loss : 0.041612, loss_ce: 0.013027
2021-12-10 11:27:45,325 Training Data Eval:
2021-12-10 11:27:53,037   Average segmentation loss on training set: 0.0258
2021-12-10 11:27:53,037 Validation Data Eval:
2021-12-10 11:27:55,677   Average segmentation loss on validation set: 0.0746
2021-12-10 11:28:01,404 Found new lowest validation loss at iteration 2549! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 11:28:02,945 iteration 2550 : loss : 0.041037, loss_ce: 0.014825
2021-12-10 11:28:08,898 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234epoch_149.pth
 38%|██████████▏                | 150/400 [1:12:20<2:19:56, 33.59s/it]2021-12-10 11:28:10,417 iteration 2551 : loss : 0.030071, loss_ce: 0.014997
2021-12-10 11:28:12,009 iteration 2552 : loss : 0.031490, loss_ce: 0.012616
2021-12-10 11:28:13,463 iteration 2553 : loss : 0.023706, loss_ce: 0.008110
2021-12-10 11:28:14,994 iteration 2554 : loss : 0.025581, loss_ce: 0.009069
2021-12-10 11:28:16,503 iteration 2555 : loss : 0.047811, loss_ce: 0.014287
2021-12-10 11:28:18,085 iteration 2556 : loss : 0.035811, loss_ce: 0.016716
2021-12-10 11:28:19,607 iteration 2557 : loss : 0.042475, loss_ce: 0.018651
2021-12-10 11:28:21,152 iteration 2558 : loss : 0.038296, loss_ce: 0.021557
2021-12-10 11:28:22,778 iteration 2559 : loss : 0.032677, loss_ce: 0.012076
2021-12-10 11:28:24,313 iteration 2560 : loss : 0.030772, loss_ce: 0.015709
2021-12-10 11:28:25,941 iteration 2561 : loss : 0.036944, loss_ce: 0.012836
2021-12-10 11:28:27,520 iteration 2562 : loss : 0.045194, loss_ce: 0.017125
2021-12-10 11:28:29,106 iteration 2563 : loss : 0.042617, loss_ce: 0.018388
2021-12-10 11:28:30,605 iteration 2564 : loss : 0.035302, loss_ce: 0.014850
2021-12-10 11:28:32,092 iteration 2565 : loss : 0.039878, loss_ce: 0.014423
2021-12-10 11:28:33,609 iteration 2566 : loss : 0.041947, loss_ce: 0.015946
2021-12-10 11:28:35,149 iteration 2567 : loss : 0.060802, loss_ce: 0.019098
 38%|██████████▏                | 151/400 [1:12:46<2:10:19, 31.40s/it]2021-12-10 11:28:36,760 iteration 2568 : loss : 0.052679, loss_ce: 0.027296
2021-12-10 11:28:38,272 iteration 2569 : loss : 0.035256, loss_ce: 0.018054
2021-12-10 11:28:39,788 iteration 2570 : loss : 0.038104, loss_ce: 0.014825
2021-12-10 11:28:41,314 iteration 2571 : loss : 0.027721, loss_ce: 0.010464
2021-12-10 11:28:42,781 iteration 2572 : loss : 0.038397, loss_ce: 0.010586
2021-12-10 11:28:44,260 iteration 2573 : loss : 0.035328, loss_ce: 0.013454
2021-12-10 11:28:45,774 iteration 2574 : loss : 0.038347, loss_ce: 0.012798
2021-12-10 11:28:47,429 iteration 2575 : loss : 0.055723, loss_ce: 0.021670
2021-12-10 11:28:48,990 iteration 2576 : loss : 0.037446, loss_ce: 0.013682
2021-12-10 11:28:50,534 iteration 2577 : loss : 0.046442, loss_ce: 0.019852
2021-12-10 11:28:52,092 iteration 2578 : loss : 0.058987, loss_ce: 0.021108
2021-12-10 11:28:53,567 iteration 2579 : loss : 0.034939, loss_ce: 0.009278
2021-12-10 11:28:55,169 iteration 2580 : loss : 0.044118, loss_ce: 0.012612
2021-12-10 11:28:56,743 iteration 2581 : loss : 0.032290, loss_ce: 0.013038
2021-12-10 11:28:58,375 iteration 2582 : loss : 0.059460, loss_ce: 0.021744
2021-12-10 11:28:59,909 iteration 2583 : loss : 0.030674, loss_ce: 0.011433
2021-12-10 11:29:01,354 iteration 2584 : loss : 0.044182, loss_ce: 0.017168
 38%|██████████▎                | 152/400 [1:13:12<2:03:21, 29.84s/it]2021-12-10 11:29:02,948 iteration 2585 : loss : 0.035377, loss_ce: 0.008992
2021-12-10 11:29:04,494 iteration 2586 : loss : 0.040976, loss_ce: 0.020093
2021-12-10 11:29:05,966 iteration 2587 : loss : 0.034938, loss_ce: 0.012775
2021-12-10 11:29:07,480 iteration 2588 : loss : 0.030474, loss_ce: 0.014777
2021-12-10 11:29:09,059 iteration 2589 : loss : 0.039381, loss_ce: 0.012885
2021-12-10 11:29:10,644 iteration 2590 : loss : 0.048220, loss_ce: 0.023091
2021-12-10 11:29:12,153 iteration 2591 : loss : 0.041942, loss_ce: 0.013792
2021-12-10 11:29:13,657 iteration 2592 : loss : 0.034519, loss_ce: 0.012025
2021-12-10 11:29:15,174 iteration 2593 : loss : 0.029514, loss_ce: 0.012976
2021-12-10 11:29:16,855 iteration 2594 : loss : 0.052732, loss_ce: 0.024807
2021-12-10 11:29:18,460 iteration 2595 : loss : 0.047501, loss_ce: 0.017310
2021-12-10 11:29:19,954 iteration 2596 : loss : 0.027161, loss_ce: 0.012006
2021-12-10 11:29:21,431 iteration 2597 : loss : 0.030314, loss_ce: 0.011792
2021-12-10 11:29:22,945 iteration 2598 : loss : 0.026752, loss_ce: 0.011566
2021-12-10 11:29:24,465 iteration 2599 : loss : 0.036703, loss_ce: 0.009461
2021-12-10 11:29:25,994 iteration 2600 : loss : 0.046593, loss_ce: 0.017571
2021-12-10 11:29:27,477 iteration 2601 : loss : 0.027297, loss_ce: 0.011342
 38%|██████████▎                | 153/400 [1:13:38<1:58:15, 28.73s/it]2021-12-10 11:29:29,093 iteration 2602 : loss : 0.043435, loss_ce: 0.019162
2021-12-10 11:29:30,554 iteration 2603 : loss : 0.024826, loss_ce: 0.009336
2021-12-10 11:29:32,076 iteration 2604 : loss : 0.028627, loss_ce: 0.010511
2021-12-10 11:29:33,746 iteration 2605 : loss : 0.036020, loss_ce: 0.011598
2021-12-10 11:29:35,286 iteration 2606 : loss : 0.041231, loss_ce: 0.017722
2021-12-10 11:29:36,825 iteration 2607 : loss : 0.033914, loss_ce: 0.013197
2021-12-10 11:29:38,315 iteration 2608 : loss : 0.033109, loss_ce: 0.016828
2021-12-10 11:29:39,817 iteration 2609 : loss : 0.035283, loss_ce: 0.010358
2021-12-10 11:29:41,475 iteration 2610 : loss : 0.049980, loss_ce: 0.021128
2021-12-10 11:29:42,990 iteration 2611 : loss : 0.037094, loss_ce: 0.013383
2021-12-10 11:29:44,427 iteration 2612 : loss : 0.033744, loss_ce: 0.016891
2021-12-10 11:29:45,927 iteration 2613 : loss : 0.030202, loss_ce: 0.009832
2021-12-10 11:29:47,527 iteration 2614 : loss : 0.058208, loss_ce: 0.018089
2021-12-10 11:29:49,028 iteration 2615 : loss : 0.034833, loss_ce: 0.014048
2021-12-10 11:29:50,532 iteration 2616 : loss : 0.034134, loss_ce: 0.013560
2021-12-10 11:29:52,159 iteration 2617 : loss : 0.039517, loss_ce: 0.012530
2021-12-10 11:29:53,710 iteration 2618 : loss : 0.048880, loss_ce: 0.022979
 38%|██████████▍                | 154/400 [1:14:05<1:54:42, 27.98s/it]2021-12-10 11:29:55,371 iteration 2619 : loss : 0.049105, loss_ce: 0.012752
2021-12-10 11:29:56,880 iteration 2620 : loss : 0.042139, loss_ce: 0.017900
2021-12-10 11:29:58,444 iteration 2621 : loss : 0.035279, loss_ce: 0.011978
2021-12-10 11:30:00,018 iteration 2622 : loss : 0.051116, loss_ce: 0.033092
2021-12-10 11:30:01,605 iteration 2623 : loss : 0.042527, loss_ce: 0.018450
2021-12-10 11:30:03,113 iteration 2624 : loss : 0.027898, loss_ce: 0.008821
2021-12-10 11:30:04,628 iteration 2625 : loss : 0.031435, loss_ce: 0.014415
2021-12-10 11:30:06,240 iteration 2626 : loss : 0.044594, loss_ce: 0.018661
2021-12-10 11:30:07,800 iteration 2627 : loss : 0.052364, loss_ce: 0.014358
2021-12-10 11:30:09,301 iteration 2628 : loss : 0.030771, loss_ce: 0.011023
2021-12-10 11:30:10,915 iteration 2629 : loss : 0.040650, loss_ce: 0.012609
2021-12-10 11:30:12,390 iteration 2630 : loss : 0.029616, loss_ce: 0.008436
2021-12-10 11:30:13,942 iteration 2631 : loss : 0.040283, loss_ce: 0.019861
2021-12-10 11:30:15,499 iteration 2632 : loss : 0.047525, loss_ce: 0.017690
2021-12-10 11:30:17,007 iteration 2633 : loss : 0.033220, loss_ce: 0.014446
2021-12-10 11:30:18,573 iteration 2634 : loss : 0.030345, loss_ce: 0.010257
2021-12-10 11:30:18,573 Training Data Eval:
2021-12-10 11:30:26,297   Average segmentation loss on training set: 0.0241
2021-12-10 11:30:26,298 Validation Data Eval:
2021-12-10 11:30:28,950   Average segmentation loss on validation set: 0.0659
2021-12-10 11:30:34,728 Found new lowest validation loss at iteration 2634! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 11:30:36,373 iteration 2635 : loss : 0.048633, loss_ce: 0.019978
 39%|██████████▍                | 155/400 [1:14:47<2:12:13, 32.38s/it]2021-12-10 11:30:37,930 iteration 2636 : loss : 0.028380, loss_ce: 0.009116
2021-12-10 11:30:39,598 iteration 2637 : loss : 0.043206, loss_ce: 0.012497
2021-12-10 11:30:41,142 iteration 2638 : loss : 0.027400, loss_ce: 0.009903
2021-12-10 11:30:42,573 iteration 2639 : loss : 0.025032, loss_ce: 0.008976
2021-12-10 11:30:44,052 iteration 2640 : loss : 0.036558, loss_ce: 0.014114
2021-12-10 11:30:45,675 iteration 2641 : loss : 0.049813, loss_ce: 0.019944
2021-12-10 11:30:47,262 iteration 2642 : loss : 0.050306, loss_ce: 0.015220
2021-12-10 11:30:48,837 iteration 2643 : loss : 0.046173, loss_ce: 0.014796
2021-12-10 11:30:50,334 iteration 2644 : loss : 0.034718, loss_ce: 0.009968
2021-12-10 11:30:51,831 iteration 2645 : loss : 0.032838, loss_ce: 0.015584
2021-12-10 11:30:53,343 iteration 2646 : loss : 0.032781, loss_ce: 0.010482
2021-12-10 11:30:54,925 iteration 2647 : loss : 0.046406, loss_ce: 0.025227
2021-12-10 11:30:56,372 iteration 2648 : loss : 0.023173, loss_ce: 0.010723
2021-12-10 11:30:57,943 iteration 2649 : loss : 0.037275, loss_ce: 0.015570
2021-12-10 11:30:59,514 iteration 2650 : loss : 0.043562, loss_ce: 0.019694
2021-12-10 11:31:01,026 iteration 2651 : loss : 0.044058, loss_ce: 0.014276
2021-12-10 11:31:02,558 iteration 2652 : loss : 0.035105, loss_ce: 0.015090
 39%|██████████▌                | 156/400 [1:15:14<2:04:07, 30.52s/it]2021-12-10 11:31:04,243 iteration 2653 : loss : 0.049886, loss_ce: 0.015358
2021-12-10 11:31:05,809 iteration 2654 : loss : 0.030486, loss_ce: 0.011854
2021-12-10 11:31:07,295 iteration 2655 : loss : 0.024674, loss_ce: 0.008948
2021-12-10 11:31:08,752 iteration 2656 : loss : 0.026932, loss_ce: 0.011860
2021-12-10 11:31:10,230 iteration 2657 : loss : 0.027144, loss_ce: 0.009874
2021-12-10 11:31:11,724 iteration 2658 : loss : 0.028162, loss_ce: 0.011624
2021-12-10 11:31:13,384 iteration 2659 : loss : 0.039118, loss_ce: 0.019599
2021-12-10 11:31:14,922 iteration 2660 : loss : 0.029083, loss_ce: 0.009872
2021-12-10 11:31:16,372 iteration 2661 : loss : 0.028367, loss_ce: 0.010378
2021-12-10 11:31:17,948 iteration 2662 : loss : 0.032661, loss_ce: 0.013709
2021-12-10 11:31:19,432 iteration 2663 : loss : 0.039869, loss_ce: 0.015106
2021-12-10 11:31:21,022 iteration 2664 : loss : 0.033396, loss_ce: 0.011452
2021-12-10 11:31:22,534 iteration 2665 : loss : 0.034956, loss_ce: 0.012767
2021-12-10 11:31:24,086 iteration 2666 : loss : 0.052247, loss_ce: 0.015609
2021-12-10 11:31:25,654 iteration 2667 : loss : 0.022892, loss_ce: 0.008186
2021-12-10 11:31:27,216 iteration 2668 : loss : 0.038369, loss_ce: 0.013926
2021-12-10 11:31:28,799 iteration 2669 : loss : 0.027133, loss_ce: 0.010878
 39%|██████████▌                | 157/400 [1:15:40<1:58:25, 29.24s/it]2021-12-10 11:31:30,431 iteration 2670 : loss : 0.047858, loss_ce: 0.012579
2021-12-10 11:31:31,988 iteration 2671 : loss : 0.048182, loss_ce: 0.016439
2021-12-10 11:31:33,559 iteration 2672 : loss : 0.035754, loss_ce: 0.014787
2021-12-10 11:31:35,157 iteration 2673 : loss : 0.060385, loss_ce: 0.022061
2021-12-10 11:31:36,660 iteration 2674 : loss : 0.036692, loss_ce: 0.018296
2021-12-10 11:31:38,267 iteration 2675 : loss : 0.046721, loss_ce: 0.016888
2021-12-10 11:31:39,821 iteration 2676 : loss : 0.045124, loss_ce: 0.013055
2021-12-10 11:31:41,300 iteration 2677 : loss : 0.023544, loss_ce: 0.010798
2021-12-10 11:31:42,762 iteration 2678 : loss : 0.032425, loss_ce: 0.010182
2021-12-10 11:31:44,322 iteration 2679 : loss : 0.049767, loss_ce: 0.022045
2021-12-10 11:31:45,933 iteration 2680 : loss : 0.045312, loss_ce: 0.023498
2021-12-10 11:31:47,462 iteration 2681 : loss : 0.035523, loss_ce: 0.019053
2021-12-10 11:31:48,937 iteration 2682 : loss : 0.028889, loss_ce: 0.012597
2021-12-10 11:31:50,490 iteration 2683 : loss : 0.038155, loss_ce: 0.018555
2021-12-10 11:31:52,020 iteration 2684 : loss : 0.041683, loss_ce: 0.012234
2021-12-10 11:31:53,566 iteration 2685 : loss : 0.033320, loss_ce: 0.014620
2021-12-10 11:31:55,078 iteration 2686 : loss : 0.033117, loss_ce: 0.013049
 40%|██████████▋                | 158/400 [1:16:06<1:54:21, 28.35s/it]2021-12-10 11:31:56,634 iteration 2687 : loss : 0.020671, loss_ce: 0.008743
2021-12-10 11:31:58,134 iteration 2688 : loss : 0.050827, loss_ce: 0.019316
2021-12-10 11:31:59,547 iteration 2689 : loss : 0.024635, loss_ce: 0.009267
2021-12-10 11:32:01,046 iteration 2690 : loss : 0.036342, loss_ce: 0.016568
2021-12-10 11:32:02,581 iteration 2691 : loss : 0.039458, loss_ce: 0.013026
2021-12-10 11:32:04,091 iteration 2692 : loss : 0.031118, loss_ce: 0.009808
2021-12-10 11:32:05,572 iteration 2693 : loss : 0.034043, loss_ce: 0.013019
2021-12-10 11:32:07,008 iteration 2694 : loss : 0.049355, loss_ce: 0.018189
2021-12-10 11:32:08,567 iteration 2695 : loss : 0.060484, loss_ce: 0.022238
2021-12-10 11:32:10,187 iteration 2696 : loss : 0.051633, loss_ce: 0.019498
2021-12-10 11:32:11,764 iteration 2697 : loss : 0.032424, loss_ce: 0.016418
2021-12-10 11:32:13,231 iteration 2698 : loss : 0.027551, loss_ce: 0.010458
2021-12-10 11:32:14,716 iteration 2699 : loss : 0.029660, loss_ce: 0.010573
2021-12-10 11:32:16,198 iteration 2700 : loss : 0.041619, loss_ce: 0.011355
2021-12-10 11:32:17,720 iteration 2701 : loss : 0.053331, loss_ce: 0.023930
2021-12-10 11:32:19,277 iteration 2702 : loss : 0.055482, loss_ce: 0.013020
2021-12-10 11:32:20,834 iteration 2703 : loss : 0.055178, loss_ce: 0.020188
 40%|██████████▋                | 159/400 [1:16:32<1:50:44, 27.57s/it]2021-12-10 11:32:22,352 iteration 2704 : loss : 0.029190, loss_ce: 0.008752
2021-12-10 11:32:23,825 iteration 2705 : loss : 0.048328, loss_ce: 0.015837
2021-12-10 11:32:25,370 iteration 2706 : loss : 0.045659, loss_ce: 0.019685
2021-12-10 11:32:26,885 iteration 2707 : loss : 0.030251, loss_ce: 0.010332
2021-12-10 11:32:28,387 iteration 2708 : loss : 0.049354, loss_ce: 0.015605
2021-12-10 11:32:29,974 iteration 2709 : loss : 0.049601, loss_ce: 0.017180
2021-12-10 11:32:31,537 iteration 2710 : loss : 0.037412, loss_ce: 0.016109
2021-12-10 11:32:33,032 iteration 2711 : loss : 0.034303, loss_ce: 0.012996
2021-12-10 11:32:34,538 iteration 2712 : loss : 0.046628, loss_ce: 0.017475
2021-12-10 11:32:36,067 iteration 2713 : loss : 0.032184, loss_ce: 0.011079
2021-12-10 11:32:37,591 iteration 2714 : loss : 0.039587, loss_ce: 0.015763
2021-12-10 11:32:39,099 iteration 2715 : loss : 0.038371, loss_ce: 0.021624
2021-12-10 11:32:40,603 iteration 2716 : loss : 0.047137, loss_ce: 0.010586
2021-12-10 11:32:42,067 iteration 2717 : loss : 0.035330, loss_ce: 0.012201
2021-12-10 11:32:43,614 iteration 2718 : loss : 0.033168, loss_ce: 0.012797
2021-12-10 11:32:45,102 iteration 2719 : loss : 0.028704, loss_ce: 0.011756
2021-12-10 11:32:45,102 Training Data Eval:
2021-12-10 11:32:52,800   Average segmentation loss on training set: 0.0230
2021-12-10 11:32:52,800 Validation Data Eval:
2021-12-10 11:32:55,442   Average segmentation loss on validation set: 0.0711
2021-12-10 11:32:56,941 iteration 2720 : loss : 0.030333, loss_ce: 0.013441
 40%|██████████▊                | 160/400 [1:17:08<2:00:31, 30.13s/it]2021-12-10 11:32:58,517 iteration 2721 : loss : 0.036983, loss_ce: 0.012316
2021-12-10 11:33:00,058 iteration 2722 : loss : 0.025027, loss_ce: 0.012201
2021-12-10 11:33:01,652 iteration 2723 : loss : 0.047982, loss_ce: 0.020482
2021-12-10 11:33:03,120 iteration 2724 : loss : 0.053704, loss_ce: 0.018260
2021-12-10 11:33:04,617 iteration 2725 : loss : 0.038228, loss_ce: 0.014971
2021-12-10 11:33:06,205 iteration 2726 : loss : 0.039360, loss_ce: 0.013347
2021-12-10 11:33:07,716 iteration 2727 : loss : 0.039602, loss_ce: 0.014398
2021-12-10 11:33:09,276 iteration 2728 : loss : 0.038277, loss_ce: 0.015105
2021-12-10 11:33:10,827 iteration 2729 : loss : 0.053799, loss_ce: 0.032352
2021-12-10 11:33:12,417 iteration 2730 : loss : 0.077188, loss_ce: 0.037277
2021-12-10 11:33:13,929 iteration 2731 : loss : 0.038084, loss_ce: 0.014564
2021-12-10 11:33:15,361 iteration 2732 : loss : 0.037775, loss_ce: 0.015639
2021-12-10 11:33:16,870 iteration 2733 : loss : 0.022704, loss_ce: 0.010218
2021-12-10 11:33:18,398 iteration 2734 : loss : 0.056172, loss_ce: 0.012952
2021-12-10 11:33:19,924 iteration 2735 : loss : 0.032592, loss_ce: 0.015530
2021-12-10 11:33:21,429 iteration 2736 : loss : 0.036221, loss_ce: 0.011981
2021-12-10 11:33:22,933 iteration 2737 : loss : 0.035509, loss_ce: 0.009096
 40%|██████████▊                | 161/400 [1:17:34<1:55:04, 28.89s/it]2021-12-10 11:33:24,547 iteration 2738 : loss : 0.050915, loss_ce: 0.023660
2021-12-10 11:33:26,022 iteration 2739 : loss : 0.046100, loss_ce: 0.011600
2021-12-10 11:33:27,620 iteration 2740 : loss : 0.042373, loss_ce: 0.017996
2021-12-10 11:33:29,133 iteration 2741 : loss : 0.035854, loss_ce: 0.016048
2021-12-10 11:33:30,664 iteration 2742 : loss : 0.055884, loss_ce: 0.025432
2021-12-10 11:33:32,129 iteration 2743 : loss : 0.047254, loss_ce: 0.019176
2021-12-10 11:33:33,642 iteration 2744 : loss : 0.033664, loss_ce: 0.011260
2021-12-10 11:33:35,119 iteration 2745 : loss : 0.031431, loss_ce: 0.011821
2021-12-10 11:33:36,728 iteration 2746 : loss : 0.097834, loss_ce: 0.027667
2021-12-10 11:33:38,222 iteration 2747 : loss : 0.036890, loss_ce: 0.013900
2021-12-10 11:33:39,781 iteration 2748 : loss : 0.038224, loss_ce: 0.011182
2021-12-10 11:33:41,370 iteration 2749 : loss : 0.057979, loss_ce: 0.022359
2021-12-10 11:33:42,878 iteration 2750 : loss : 0.037594, loss_ce: 0.014731
2021-12-10 11:33:44,394 iteration 2751 : loss : 0.056798, loss_ce: 0.016698
2021-12-10 11:33:46,008 iteration 2752 : loss : 0.045307, loss_ce: 0.016197
2021-12-10 11:33:47,630 iteration 2753 : loss : 0.044451, loss_ce: 0.017819
2021-12-10 11:33:49,164 iteration 2754 : loss : 0.031454, loss_ce: 0.016262
 40%|██████████▉                | 162/400 [1:18:00<1:51:25, 28.09s/it]2021-12-10 11:33:50,621 iteration 2755 : loss : 0.029149, loss_ce: 0.009126
2021-12-10 11:33:52,148 iteration 2756 : loss : 0.031130, loss_ce: 0.011679
2021-12-10 11:33:53,665 iteration 2757 : loss : 0.033276, loss_ce: 0.013537
2021-12-10 11:33:55,182 iteration 2758 : loss : 0.032717, loss_ce: 0.012423
2021-12-10 11:33:56,700 iteration 2759 : loss : 0.043036, loss_ce: 0.016604
2021-12-10 11:33:58,217 iteration 2760 : loss : 0.042672, loss_ce: 0.020708
2021-12-10 11:33:59,772 iteration 2761 : loss : 0.037304, loss_ce: 0.012928
2021-12-10 11:34:01,286 iteration 2762 : loss : 0.030005, loss_ce: 0.012439
2021-12-10 11:34:02,834 iteration 2763 : loss : 0.048311, loss_ce: 0.017820
2021-12-10 11:34:04,293 iteration 2764 : loss : 0.023327, loss_ce: 0.008816
2021-12-10 11:34:05,915 iteration 2765 : loss : 0.029498, loss_ce: 0.010390
2021-12-10 11:34:07,364 iteration 2766 : loss : 0.030792, loss_ce: 0.010593
2021-12-10 11:34:08,899 iteration 2767 : loss : 0.037864, loss_ce: 0.015892
2021-12-10 11:34:10,392 iteration 2768 : loss : 0.042743, loss_ce: 0.013327
2021-12-10 11:34:11,846 iteration 2769 : loss : 0.028641, loss_ce: 0.013088
2021-12-10 11:34:13,329 iteration 2770 : loss : 0.041489, loss_ce: 0.018105
2021-12-10 11:34:14,842 iteration 2771 : loss : 0.036400, loss_ce: 0.015863
 41%|███████████                | 163/400 [1:18:26<1:48:06, 27.37s/it]2021-12-10 11:34:16,347 iteration 2772 : loss : 0.035523, loss_ce: 0.011823
2021-12-10 11:34:17,871 iteration 2773 : loss : 0.036874, loss_ce: 0.014861
2021-12-10 11:34:19,391 iteration 2774 : loss : 0.061296, loss_ce: 0.012507
2021-12-10 11:34:20,922 iteration 2775 : loss : 0.046688, loss_ce: 0.016342
2021-12-10 11:34:22,418 iteration 2776 : loss : 0.037636, loss_ce: 0.013709
2021-12-10 11:34:23,988 iteration 2777 : loss : 0.026931, loss_ce: 0.009478
2021-12-10 11:34:25,467 iteration 2778 : loss : 0.026363, loss_ce: 0.009560
2021-12-10 11:34:26,945 iteration 2779 : loss : 0.030163, loss_ce: 0.012074
2021-12-10 11:34:28,447 iteration 2780 : loss : 0.041105, loss_ce: 0.019530
2021-12-10 11:34:30,074 iteration 2781 : loss : 0.036505, loss_ce: 0.014199
2021-12-10 11:34:31,661 iteration 2782 : loss : 0.035440, loss_ce: 0.017164
2021-12-10 11:34:33,168 iteration 2783 : loss : 0.032545, loss_ce: 0.009609
2021-12-10 11:34:34,583 iteration 2784 : loss : 0.029042, loss_ce: 0.007537
2021-12-10 11:34:36,047 iteration 2785 : loss : 0.028753, loss_ce: 0.013804
2021-12-10 11:34:37,506 iteration 2786 : loss : 0.024912, loss_ce: 0.010966
2021-12-10 11:34:38,985 iteration 2787 : loss : 0.026810, loss_ce: 0.010378
2021-12-10 11:34:40,625 iteration 2788 : loss : 0.046746, loss_ce: 0.019201
 41%|███████████                | 164/400 [1:18:52<1:45:47, 26.89s/it]2021-12-10 11:34:42,220 iteration 2789 : loss : 0.027168, loss_ce: 0.008744
2021-12-10 11:34:43,826 iteration 2790 : loss : 0.057061, loss_ce: 0.026927
2021-12-10 11:34:45,287 iteration 2791 : loss : 0.020483, loss_ce: 0.006378
2021-12-10 11:34:46,790 iteration 2792 : loss : 0.027168, loss_ce: 0.011394
2021-12-10 11:34:48,309 iteration 2793 : loss : 0.031962, loss_ce: 0.011577
2021-12-10 11:34:49,881 iteration 2794 : loss : 0.029536, loss_ce: 0.013919
2021-12-10 11:34:51,393 iteration 2795 : loss : 0.038147, loss_ce: 0.015100
2021-12-10 11:34:52,882 iteration 2796 : loss : 0.048697, loss_ce: 0.016240
2021-12-10 11:34:54,444 iteration 2797 : loss : 0.033713, loss_ce: 0.016574
2021-12-10 11:34:55,986 iteration 2798 : loss : 0.041774, loss_ce: 0.012613
2021-12-10 11:34:57,590 iteration 2799 : loss : 0.034881, loss_ce: 0.012828
2021-12-10 11:34:59,123 iteration 2800 : loss : 0.038441, loss_ce: 0.016935
2021-12-10 11:35:00,561 iteration 2801 : loss : 0.045294, loss_ce: 0.012310
2021-12-10 11:35:02,035 iteration 2802 : loss : 0.023355, loss_ce: 0.007768
2021-12-10 11:35:03,568 iteration 2803 : loss : 0.039399, loss_ce: 0.016747
2021-12-10 11:35:05,003 iteration 2804 : loss : 0.032296, loss_ce: 0.012709
2021-12-10 11:35:05,004 Training Data Eval:
2021-12-10 11:35:12,683   Average segmentation loss on training set: 0.0218
2021-12-10 11:35:12,683 Validation Data Eval:
2021-12-10 11:35:15,312   Average segmentation loss on validation set: 0.0654
2021-12-10 11:35:21,073 Found new lowest validation loss at iteration 2804! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 11:35:22,727 iteration 2805 : loss : 0.070258, loss_ce: 0.026643
 41%|███████████▏               | 165/400 [1:19:34<2:03:12, 31.46s/it]2021-12-10 11:35:24,369 iteration 2806 : loss : 0.049645, loss_ce: 0.019709
2021-12-10 11:35:25,957 iteration 2807 : loss : 0.054850, loss_ce: 0.017011
2021-12-10 11:35:27,517 iteration 2808 : loss : 0.039340, loss_ce: 0.012587
2021-12-10 11:35:29,052 iteration 2809 : loss : 0.036888, loss_ce: 0.013987
2021-12-10 11:35:30,505 iteration 2810 : loss : 0.040680, loss_ce: 0.014754
2021-12-10 11:35:32,059 iteration 2811 : loss : 0.031338, loss_ce: 0.014866
2021-12-10 11:35:33,510 iteration 2812 : loss : 0.020423, loss_ce: 0.008861
2021-12-10 11:35:35,090 iteration 2813 : loss : 0.043560, loss_ce: 0.019238
2021-12-10 11:35:36,623 iteration 2814 : loss : 0.033390, loss_ce: 0.013373
2021-12-10 11:35:38,131 iteration 2815 : loss : 0.041880, loss_ce: 0.021164
2021-12-10 11:35:39,642 iteration 2816 : loss : 0.043514, loss_ce: 0.017695
2021-12-10 11:35:41,236 iteration 2817 : loss : 0.061770, loss_ce: 0.012661
2021-12-10 11:35:42,811 iteration 2818 : loss : 0.040757, loss_ce: 0.018516
2021-12-10 11:35:44,314 iteration 2819 : loss : 0.038471, loss_ce: 0.019660
2021-12-10 11:35:45,928 iteration 2820 : loss : 0.041786, loss_ce: 0.012538
2021-12-10 11:35:47,523 iteration 2821 : loss : 0.060336, loss_ce: 0.022836
2021-12-10 11:35:49,079 iteration 2822 : loss : 0.030328, loss_ce: 0.010768
 42%|███████████▏               | 166/400 [1:20:00<1:56:42, 29.92s/it]2021-12-10 11:35:50,755 iteration 2823 : loss : 0.045968, loss_ce: 0.020634
2021-12-10 11:35:52,249 iteration 2824 : loss : 0.029341, loss_ce: 0.014242
2021-12-10 11:35:53,782 iteration 2825 : loss : 0.031463, loss_ce: 0.012829
2021-12-10 11:35:55,406 iteration 2826 : loss : 0.038727, loss_ce: 0.013438
2021-12-10 11:35:57,039 iteration 2827 : loss : 0.049090, loss_ce: 0.014378
2021-12-10 11:35:58,583 iteration 2828 : loss : 0.038026, loss_ce: 0.012945
2021-12-10 11:36:00,102 iteration 2829 : loss : 0.035821, loss_ce: 0.018114
2021-12-10 11:36:01,610 iteration 2830 : loss : 0.052660, loss_ce: 0.017104
2021-12-10 11:36:03,043 iteration 2831 : loss : 0.032070, loss_ce: 0.012998
2021-12-10 11:36:04,686 iteration 2832 : loss : 0.040276, loss_ce: 0.018284
2021-12-10 11:36:06,191 iteration 2833 : loss : 0.028955, loss_ce: 0.009894
2021-12-10 11:36:07,776 iteration 2834 : loss : 0.042263, loss_ce: 0.013632
2021-12-10 11:36:09,328 iteration 2835 : loss : 0.052627, loss_ce: 0.016325
2021-12-10 11:36:10,848 iteration 2836 : loss : 0.041806, loss_ce: 0.014468
2021-12-10 11:36:12,431 iteration 2837 : loss : 0.033753, loss_ce: 0.013151
2021-12-10 11:36:13,893 iteration 2838 : loss : 0.030240, loss_ce: 0.013075
2021-12-10 11:36:15,445 iteration 2839 : loss : 0.031666, loss_ce: 0.012713
 42%|███████████▎               | 167/400 [1:20:26<1:52:03, 28.86s/it]2021-12-10 11:36:17,081 iteration 2840 : loss : 0.040437, loss_ce: 0.013561
2021-12-10 11:36:18,592 iteration 2841 : loss : 0.032203, loss_ce: 0.010756
2021-12-10 11:36:20,095 iteration 2842 : loss : 0.027480, loss_ce: 0.010912
2021-12-10 11:36:21,658 iteration 2843 : loss : 0.032890, loss_ce: 0.009123
2021-12-10 11:36:23,197 iteration 2844 : loss : 0.040261, loss_ce: 0.017709
2021-12-10 11:36:24,716 iteration 2845 : loss : 0.043002, loss_ce: 0.016534
2021-12-10 11:36:26,242 iteration 2846 : loss : 0.024372, loss_ce: 0.008580
2021-12-10 11:36:27,642 iteration 2847 : loss : 0.019090, loss_ce: 0.009993
2021-12-10 11:36:29,171 iteration 2848 : loss : 0.042064, loss_ce: 0.014858
2021-12-10 11:36:30,743 iteration 2849 : loss : 0.041335, loss_ce: 0.015834
2021-12-10 11:36:32,307 iteration 2850 : loss : 0.034154, loss_ce: 0.012581
2021-12-10 11:36:33,882 iteration 2851 : loss : 0.038817, loss_ce: 0.015597
2021-12-10 11:36:35,425 iteration 2852 : loss : 0.046898, loss_ce: 0.014603
2021-12-10 11:36:37,008 iteration 2853 : loss : 0.029677, loss_ce: 0.012006
2021-12-10 11:36:38,562 iteration 2854 : loss : 0.035829, loss_ce: 0.013444
2021-12-10 11:36:40,046 iteration 2855 : loss : 0.029620, loss_ce: 0.014729
2021-12-10 11:36:41,607 iteration 2856 : loss : 0.056113, loss_ce: 0.029320
 42%|███████████▎               | 168/400 [1:20:53<1:48:27, 28.05s/it]2021-12-10 11:36:43,108 iteration 2857 : loss : 0.026696, loss_ce: 0.009113
2021-12-10 11:36:44,636 iteration 2858 : loss : 0.026721, loss_ce: 0.011594
2021-12-10 11:36:46,127 iteration 2859 : loss : 0.025383, loss_ce: 0.010486
2021-12-10 11:36:47,691 iteration 2860 : loss : 0.044006, loss_ce: 0.013429
2021-12-10 11:36:49,134 iteration 2861 : loss : 0.030324, loss_ce: 0.013121
2021-12-10 11:36:50,735 iteration 2862 : loss : 0.068285, loss_ce: 0.018885
2021-12-10 11:36:52,209 iteration 2863 : loss : 0.033453, loss_ce: 0.009134
2021-12-10 11:36:53,758 iteration 2864 : loss : 0.031067, loss_ce: 0.012343
2021-12-10 11:36:55,320 iteration 2865 : loss : 0.034887, loss_ce: 0.012426
2021-12-10 11:36:56,824 iteration 2866 : loss : 0.040566, loss_ce: 0.016322
2021-12-10 11:36:58,448 iteration 2867 : loss : 0.032563, loss_ce: 0.013680
2021-12-10 11:36:59,932 iteration 2868 : loss : 0.025926, loss_ce: 0.009240
2021-12-10 11:37:01,535 iteration 2869 : loss : 0.041716, loss_ce: 0.016476
2021-12-10 11:37:03,092 iteration 2870 : loss : 0.025944, loss_ce: 0.010061
2021-12-10 11:37:04,587 iteration 2871 : loss : 0.032489, loss_ce: 0.011760
2021-12-10 11:37:06,038 iteration 2872 : loss : 0.028840, loss_ce: 0.011428
2021-12-10 11:37:07,604 iteration 2873 : loss : 0.068526, loss_ce: 0.015714
 42%|███████████▍               | 169/400 [1:21:19<1:45:37, 27.44s/it]2021-12-10 11:37:09,225 iteration 2874 : loss : 0.030749, loss_ce: 0.009930
2021-12-10 11:37:10,762 iteration 2875 : loss : 0.029607, loss_ce: 0.011445
2021-12-10 11:37:12,293 iteration 2876 : loss : 0.044965, loss_ce: 0.016312
2021-12-10 11:37:13,874 iteration 2877 : loss : 0.058777, loss_ce: 0.016955
2021-12-10 11:37:15,397 iteration 2878 : loss : 0.034037, loss_ce: 0.015708
2021-12-10 11:37:16,966 iteration 2879 : loss : 0.031831, loss_ce: 0.012664
2021-12-10 11:37:18,547 iteration 2880 : loss : 0.044001, loss_ce: 0.013649
2021-12-10 11:37:20,091 iteration 2881 : loss : 0.028606, loss_ce: 0.011748
2021-12-10 11:37:21,676 iteration 2882 : loss : 0.034632, loss_ce: 0.017541
2021-12-10 11:37:23,170 iteration 2883 : loss : 0.055108, loss_ce: 0.030719
2021-12-10 11:37:24,677 iteration 2884 : loss : 0.039987, loss_ce: 0.016702
2021-12-10 11:37:26,225 iteration 2885 : loss : 0.035163, loss_ce: 0.015444
2021-12-10 11:37:27,664 iteration 2886 : loss : 0.038190, loss_ce: 0.011209
2021-12-10 11:37:29,256 iteration 2887 : loss : 0.038228, loss_ce: 0.019096
2021-12-10 11:37:30,796 iteration 2888 : loss : 0.067224, loss_ce: 0.019048
2021-12-10 11:37:32,428 iteration 2889 : loss : 0.033700, loss_ce: 0.011299
2021-12-10 11:37:32,428 Training Data Eval:
2021-12-10 11:37:40,099   Average segmentation loss on training set: 0.0240
2021-12-10 11:37:40,100 Validation Data Eval:
2021-12-10 11:37:42,726   Average segmentation loss on validation set: 0.0677
2021-12-10 11:37:44,303 iteration 2890 : loss : 0.044721, loss_ce: 0.016707
 42%|███████████▍               | 170/400 [1:21:55<1:55:48, 30.21s/it]2021-12-10 11:37:45,917 iteration 2891 : loss : 0.032143, loss_ce: 0.012667
2021-12-10 11:37:47,524 iteration 2892 : loss : 0.041877, loss_ce: 0.011593
2021-12-10 11:37:49,014 iteration 2893 : loss : 0.026381, loss_ce: 0.008680
2021-12-10 11:37:50,613 iteration 2894 : loss : 0.043796, loss_ce: 0.013751
2021-12-10 11:37:52,198 iteration 2895 : loss : 0.047592, loss_ce: 0.023297
2021-12-10 11:37:53,695 iteration 2896 : loss : 0.026194, loss_ce: 0.008382
2021-12-10 11:37:55,224 iteration 2897 : loss : 0.038930, loss_ce: 0.016211
2021-12-10 11:37:56,695 iteration 2898 : loss : 0.031641, loss_ce: 0.014156
2021-12-10 11:37:58,244 iteration 2899 : loss : 0.036244, loss_ce: 0.012825
2021-12-10 11:37:59,761 iteration 2900 : loss : 0.030248, loss_ce: 0.011571
2021-12-10 11:38:01,295 iteration 2901 : loss : 0.034214, loss_ce: 0.012899
2021-12-10 11:38:02,752 iteration 2902 : loss : 0.049459, loss_ce: 0.019353
2021-12-10 11:38:04,235 iteration 2903 : loss : 0.034000, loss_ce: 0.017495
2021-12-10 11:38:05,719 iteration 2904 : loss : 0.049616, loss_ce: 0.021853
2021-12-10 11:38:07,170 iteration 2905 : loss : 0.032992, loss_ce: 0.019540
2021-12-10 11:38:08,727 iteration 2906 : loss : 0.042044, loss_ce: 0.021185
2021-12-10 11:38:10,217 iteration 2907 : loss : 0.033862, loss_ce: 0.012014
 43%|███████████▌               | 171/400 [1:22:21<1:50:23, 28.93s/it]2021-12-10 11:38:11,831 iteration 2908 : loss : 0.065508, loss_ce: 0.034046
2021-12-10 11:38:13,412 iteration 2909 : loss : 0.033478, loss_ce: 0.015442
2021-12-10 11:38:14,943 iteration 2910 : loss : 0.034755, loss_ce: 0.013947
2021-12-10 11:38:16,515 iteration 2911 : loss : 0.030740, loss_ce: 0.010488
2021-12-10 11:38:18,014 iteration 2912 : loss : 0.030369, loss_ce: 0.011725
2021-12-10 11:38:19,603 iteration 2913 : loss : 0.038155, loss_ce: 0.018105
2021-12-10 11:38:21,104 iteration 2914 : loss : 0.040955, loss_ce: 0.017524
2021-12-10 11:38:22,617 iteration 2915 : loss : 0.030291, loss_ce: 0.012846
2021-12-10 11:38:24,154 iteration 2916 : loss : 0.028976, loss_ce: 0.013296
2021-12-10 11:38:25,615 iteration 2917 : loss : 0.032849, loss_ce: 0.013469
2021-12-10 11:38:27,099 iteration 2918 : loss : 0.026377, loss_ce: 0.007619
2021-12-10 11:38:28,622 iteration 2919 : loss : 0.040833, loss_ce: 0.011881
2021-12-10 11:38:30,166 iteration 2920 : loss : 0.030210, loss_ce: 0.011443
2021-12-10 11:38:31,678 iteration 2921 : loss : 0.036315, loss_ce: 0.018032
2021-12-10 11:38:33,128 iteration 2922 : loss : 0.032878, loss_ce: 0.010960
2021-12-10 11:38:34,622 iteration 2923 : loss : 0.032016, loss_ce: 0.010037
2021-12-10 11:38:36,144 iteration 2924 : loss : 0.041977, loss_ce: 0.014597
 43%|███████████▌               | 172/400 [1:22:47<1:46:29, 28.02s/it]2021-12-10 11:38:37,623 iteration 2925 : loss : 0.023460, loss_ce: 0.011324
2021-12-10 11:38:39,224 iteration 2926 : loss : 0.044942, loss_ce: 0.018647
2021-12-10 11:38:40,737 iteration 2927 : loss : 0.033364, loss_ce: 0.014017
2021-12-10 11:38:42,144 iteration 2928 : loss : 0.030756, loss_ce: 0.009899
2021-12-10 11:38:43,636 iteration 2929 : loss : 0.027666, loss_ce: 0.011612
2021-12-10 11:38:45,230 iteration 2930 : loss : 0.039116, loss_ce: 0.017550
2021-12-10 11:38:46,722 iteration 2931 : loss : 0.030028, loss_ce: 0.010725
2021-12-10 11:38:48,191 iteration 2932 : loss : 0.032047, loss_ce: 0.012442
2021-12-10 11:38:49,782 iteration 2933 : loss : 0.040707, loss_ce: 0.012753
2021-12-10 11:38:51,299 iteration 2934 : loss : 0.030213, loss_ce: 0.009777
2021-12-10 11:38:52,831 iteration 2935 : loss : 0.028454, loss_ce: 0.009405
2021-12-10 11:38:54,340 iteration 2936 : loss : 0.021199, loss_ce: 0.007089
2021-12-10 11:38:55,881 iteration 2937 : loss : 0.025811, loss_ce: 0.012734
2021-12-10 11:38:57,437 iteration 2938 : loss : 0.041588, loss_ce: 0.014337
2021-12-10 11:38:59,003 iteration 2939 : loss : 0.027468, loss_ce: 0.008437
2021-12-10 11:39:00,625 iteration 2940 : loss : 0.057191, loss_ce: 0.029775
2021-12-10 11:39:02,103 iteration 2941 : loss : 0.031172, loss_ce: 0.011211
 43%|███████████▋               | 173/400 [1:23:13<1:43:41, 27.41s/it]2021-12-10 11:39:03,630 iteration 2942 : loss : 0.023285, loss_ce: 0.007495
2021-12-10 11:39:05,178 iteration 2943 : loss : 0.042426, loss_ce: 0.013510
2021-12-10 11:39:06,662 iteration 2944 : loss : 0.025311, loss_ce: 0.012838
2021-12-10 11:39:08,192 iteration 2945 : loss : 0.041354, loss_ce: 0.013332
2021-12-10 11:39:09,617 iteration 2946 : loss : 0.033499, loss_ce: 0.012674
2021-12-10 11:39:11,108 iteration 2947 : loss : 0.027994, loss_ce: 0.010924
2021-12-10 11:39:12,591 iteration 2948 : loss : 0.030617, loss_ce: 0.009087
2021-12-10 11:39:14,164 iteration 2949 : loss : 0.044519, loss_ce: 0.015245
2021-12-10 11:39:15,700 iteration 2950 : loss : 0.026455, loss_ce: 0.011411
2021-12-10 11:39:17,256 iteration 2951 : loss : 0.028275, loss_ce: 0.012952
2021-12-10 11:39:18,805 iteration 2952 : loss : 0.025918, loss_ce: 0.009206
2021-12-10 11:39:20,385 iteration 2953 : loss : 0.046293, loss_ce: 0.022868
2021-12-10 11:39:22,005 iteration 2954 : loss : 0.059217, loss_ce: 0.016961
2021-12-10 11:39:23,490 iteration 2955 : loss : 0.033570, loss_ce: 0.016612
2021-12-10 11:39:24,987 iteration 2956 : loss : 0.040393, loss_ce: 0.022012
2021-12-10 11:39:26,456 iteration 2957 : loss : 0.038092, loss_ce: 0.016141
2021-12-10 11:39:27,982 iteration 2958 : loss : 0.046496, loss_ce: 0.022602
 44%|███████████▋               | 174/400 [1:23:39<1:41:29, 26.94s/it]2021-12-10 11:39:29,521 iteration 2959 : loss : 0.031653, loss_ce: 0.011170
2021-12-10 11:39:31,020 iteration 2960 : loss : 0.034766, loss_ce: 0.015538
2021-12-10 11:39:32,547 iteration 2961 : loss : 0.032958, loss_ce: 0.012062
2021-12-10 11:39:34,220 iteration 2962 : loss : 0.027470, loss_ce: 0.009984
2021-12-10 11:39:35,765 iteration 2963 : loss : 0.045801, loss_ce: 0.020111
2021-12-10 11:39:37,194 iteration 2964 : loss : 0.035016, loss_ce: 0.013201
2021-12-10 11:39:38,721 iteration 2965 : loss : 0.028612, loss_ce: 0.013974
2021-12-10 11:39:40,283 iteration 2966 : loss : 0.032206, loss_ce: 0.011752
2021-12-10 11:39:41,790 iteration 2967 : loss : 0.032180, loss_ce: 0.012530
2021-12-10 11:39:43,320 iteration 2968 : loss : 0.028337, loss_ce: 0.012140
2021-12-10 11:39:44,821 iteration 2969 : loss : 0.033270, loss_ce: 0.013380
2021-12-10 11:39:46,348 iteration 2970 : loss : 0.057309, loss_ce: 0.022880
2021-12-10 11:39:47,847 iteration 2971 : loss : 0.027394, loss_ce: 0.010750
2021-12-10 11:39:49,351 iteration 2972 : loss : 0.032172, loss_ce: 0.014192
2021-12-10 11:39:50,822 iteration 2973 : loss : 0.025276, loss_ce: 0.006236
2021-12-10 11:39:52,392 iteration 2974 : loss : 0.054463, loss_ce: 0.016439
2021-12-10 11:39:52,393 Training Data Eval:
2021-12-10 11:40:00,050   Average segmentation loss on training set: 0.0209
2021-12-10 11:40:00,050 Validation Data Eval:
2021-12-10 11:40:02,689   Average segmentation loss on validation set: 0.0800
2021-12-10 11:40:04,181 iteration 2975 : loss : 0.028419, loss_ce: 0.011305
 44%|███████████▊               | 175/400 [1:24:15<1:51:27, 29.72s/it]2021-12-10 11:40:05,669 iteration 2976 : loss : 0.025590, loss_ce: 0.011103
2021-12-10 11:40:07,221 iteration 2977 : loss : 0.044771, loss_ce: 0.023146
2021-12-10 11:40:08,747 iteration 2978 : loss : 0.034477, loss_ce: 0.011698
2021-12-10 11:40:10,316 iteration 2979 : loss : 0.063208, loss_ce: 0.024246
2021-12-10 11:40:11,872 iteration 2980 : loss : 0.027644, loss_ce: 0.007807
2021-12-10 11:40:13,484 iteration 2981 : loss : 0.045653, loss_ce: 0.017286
2021-12-10 11:40:15,016 iteration 2982 : loss : 0.028853, loss_ce: 0.012440
2021-12-10 11:40:16,547 iteration 2983 : loss : 0.037430, loss_ce: 0.015824
2021-12-10 11:40:18,081 iteration 2984 : loss : 0.039546, loss_ce: 0.014116
2021-12-10 11:40:19,636 iteration 2985 : loss : 0.050695, loss_ce: 0.020423
2021-12-10 11:40:21,094 iteration 2986 : loss : 0.033534, loss_ce: 0.013539
2021-12-10 11:40:22,619 iteration 2987 : loss : 0.040634, loss_ce: 0.014184
2021-12-10 11:40:24,188 iteration 2988 : loss : 0.038257, loss_ce: 0.018287
2021-12-10 11:40:25,748 iteration 2989 : loss : 0.035370, loss_ce: 0.013362
2021-12-10 11:40:27,212 iteration 2990 : loss : 0.025919, loss_ce: 0.012229
2021-12-10 11:40:28,732 iteration 2991 : loss : 0.028729, loss_ce: 0.011637
2021-12-10 11:40:30,317 iteration 2992 : loss : 0.039368, loss_ce: 0.019109
 44%|███████████▉               | 176/400 [1:24:41<1:46:56, 28.65s/it]2021-12-10 11:40:31,837 iteration 2993 : loss : 0.036093, loss_ce: 0.020925
2021-12-10 11:40:33,367 iteration 2994 : loss : 0.060813, loss_ce: 0.012995
2021-12-10 11:40:34,862 iteration 2995 : loss : 0.030262, loss_ce: 0.010504
2021-12-10 11:40:36,376 iteration 2996 : loss : 0.032829, loss_ce: 0.018881
2021-12-10 11:40:37,885 iteration 2997 : loss : 0.059675, loss_ce: 0.018449
2021-12-10 11:40:39,413 iteration 2998 : loss : 0.034467, loss_ce: 0.014345
2021-12-10 11:40:40,983 iteration 2999 : loss : 0.071123, loss_ce: 0.014826
2021-12-10 11:40:42,579 iteration 3000 : loss : 0.079760, loss_ce: 0.028348
2021-12-10 11:40:44,169 iteration 3001 : loss : 0.056705, loss_ce: 0.015172
2021-12-10 11:40:45,638 iteration 3002 : loss : 0.025461, loss_ce: 0.009862
2021-12-10 11:40:47,131 iteration 3003 : loss : 0.037012, loss_ce: 0.014916
2021-12-10 11:40:48,634 iteration 3004 : loss : 0.021924, loss_ce: 0.009370
2021-12-10 11:40:50,155 iteration 3005 : loss : 0.035281, loss_ce: 0.015229
2021-12-10 11:40:51,710 iteration 3006 : loss : 0.036435, loss_ce: 0.015324
2021-12-10 11:40:53,257 iteration 3007 : loss : 0.042690, loss_ce: 0.017500
2021-12-10 11:40:54,816 iteration 3008 : loss : 0.064965, loss_ce: 0.024456
2021-12-10 11:40:56,269 iteration 3009 : loss : 0.044628, loss_ce: 0.018225
 44%|███████████▉               | 177/400 [1:25:07<1:43:27, 27.84s/it]2021-12-10 11:40:57,954 iteration 3010 : loss : 0.043161, loss_ce: 0.015685
2021-12-10 11:40:59,520 iteration 3011 : loss : 0.034247, loss_ce: 0.017291
2021-12-10 11:41:00,995 iteration 3012 : loss : 0.028195, loss_ce: 0.012527
2021-12-10 11:41:02,449 iteration 3013 : loss : 0.056756, loss_ce: 0.017593
2021-12-10 11:41:03,980 iteration 3014 : loss : 0.035053, loss_ce: 0.014891
2021-12-10 11:41:05,486 iteration 3015 : loss : 0.055468, loss_ce: 0.013099
2021-12-10 11:41:06,990 iteration 3016 : loss : 0.075641, loss_ce: 0.031303
2021-12-10 11:41:08,481 iteration 3017 : loss : 0.031601, loss_ce: 0.016241
2021-12-10 11:41:09,966 iteration 3018 : loss : 0.021237, loss_ce: 0.009288
2021-12-10 11:41:11,420 iteration 3019 : loss : 0.027227, loss_ce: 0.009148
2021-12-10 11:41:12,960 iteration 3020 : loss : 0.040074, loss_ce: 0.012342
2021-12-10 11:41:14,488 iteration 3021 : loss : 0.022560, loss_ce: 0.007942
2021-12-10 11:41:15,986 iteration 3022 : loss : 0.022568, loss_ce: 0.007902
2021-12-10 11:41:17,515 iteration 3023 : loss : 0.030425, loss_ce: 0.010600
2021-12-10 11:41:19,114 iteration 3024 : loss : 0.036677, loss_ce: 0.014557
2021-12-10 11:41:20,689 iteration 3025 : loss : 0.054985, loss_ce: 0.021847
2021-12-10 11:41:22,164 iteration 3026 : loss : 0.026351, loss_ce: 0.010573
 44%|████████████               | 178/400 [1:25:33<1:40:50, 27.25s/it]2021-12-10 11:41:23,784 iteration 3027 : loss : 0.050201, loss_ce: 0.017777
2021-12-10 11:41:25,265 iteration 3028 : loss : 0.030432, loss_ce: 0.013055
2021-12-10 11:41:26,804 iteration 3029 : loss : 0.047188, loss_ce: 0.020087
2021-12-10 11:41:28,295 iteration 3030 : loss : 0.024288, loss_ce: 0.010144
2021-12-10 11:41:29,818 iteration 3031 : loss : 0.037012, loss_ce: 0.013213
2021-12-10 11:41:31,295 iteration 3032 : loss : 0.035864, loss_ce: 0.013007
2021-12-10 11:41:32,842 iteration 3033 : loss : 0.047858, loss_ce: 0.015874
2021-12-10 11:41:34,412 iteration 3034 : loss : 0.037026, loss_ce: 0.012382
2021-12-10 11:41:35,949 iteration 3035 : loss : 0.028802, loss_ce: 0.012778
2021-12-10 11:41:37,450 iteration 3036 : loss : 0.046480, loss_ce: 0.025155
2021-12-10 11:41:38,971 iteration 3037 : loss : 0.026759, loss_ce: 0.010208
2021-12-10 11:41:40,524 iteration 3038 : loss : 0.028438, loss_ce: 0.009772
2021-12-10 11:41:41,983 iteration 3039 : loss : 0.030878, loss_ce: 0.009030
2021-12-10 11:41:43,510 iteration 3040 : loss : 0.056666, loss_ce: 0.013383
2021-12-10 11:41:45,071 iteration 3041 : loss : 0.035210, loss_ce: 0.013640
2021-12-10 11:41:46,585 iteration 3042 : loss : 0.043176, loss_ce: 0.023639
2021-12-10 11:41:48,275 iteration 3043 : loss : 0.059180, loss_ce: 0.018376
 45%|████████████               | 179/400 [1:25:59<1:39:07, 26.91s/it]2021-12-10 11:41:49,867 iteration 3044 : loss : 0.042061, loss_ce: 0.018757
2021-12-10 11:41:51,338 iteration 3045 : loss : 0.030610, loss_ce: 0.011490
2021-12-10 11:41:52,828 iteration 3046 : loss : 0.029355, loss_ce: 0.009593
2021-12-10 11:41:54,452 iteration 3047 : loss : 0.053099, loss_ce: 0.032241
2021-12-10 11:41:55,931 iteration 3048 : loss : 0.037968, loss_ce: 0.012385
2021-12-10 11:41:57,448 iteration 3049 : loss : 0.041528, loss_ce: 0.016698
2021-12-10 11:41:58,998 iteration 3050 : loss : 0.037081, loss_ce: 0.017324
2021-12-10 11:42:00,527 iteration 3051 : loss : 0.034519, loss_ce: 0.009074
2021-12-10 11:42:02,037 iteration 3052 : loss : 0.032044, loss_ce: 0.011342
2021-12-10 11:42:03,634 iteration 3053 : loss : 0.026930, loss_ce: 0.010893
2021-12-10 11:42:05,112 iteration 3054 : loss : 0.035117, loss_ce: 0.010283
2021-12-10 11:42:06,649 iteration 3055 : loss : 0.046277, loss_ce: 0.016255
2021-12-10 11:42:08,139 iteration 3056 : loss : 0.028444, loss_ce: 0.012660
2021-12-10 11:42:09,598 iteration 3057 : loss : 0.029013, loss_ce: 0.014073
2021-12-10 11:42:11,131 iteration 3058 : loss : 0.030552, loss_ce: 0.011655
2021-12-10 11:42:12,686 iteration 3059 : loss : 0.034080, loss_ce: 0.009210
2021-12-10 11:42:12,687 Training Data Eval:
2021-12-10 11:42:20,344   Average segmentation loss on training set: 0.0234
2021-12-10 11:42:20,345 Validation Data Eval:
2021-12-10 11:42:22,982   Average segmentation loss on validation set: 0.0819
2021-12-10 11:42:24,467 iteration 3060 : loss : 0.024138, loss_ce: 0.011028
 45%|████████████▏              | 180/400 [1:26:35<1:48:53, 29.70s/it]2021-12-10 11:42:25,963 iteration 3061 : loss : 0.025921, loss_ce: 0.009444
2021-12-10 11:42:27,475 iteration 3062 : loss : 0.034782, loss_ce: 0.013930
2021-12-10 11:42:29,027 iteration 3063 : loss : 0.032175, loss_ce: 0.011126
2021-12-10 11:42:30,582 iteration 3064 : loss : 0.025346, loss_ce: 0.010334
2021-12-10 11:42:32,012 iteration 3065 : loss : 0.022204, loss_ce: 0.007464
2021-12-10 11:42:33,495 iteration 3066 : loss : 0.025950, loss_ce: 0.011619
2021-12-10 11:42:35,036 iteration 3067 : loss : 0.042241, loss_ce: 0.021153
2021-12-10 11:42:36,569 iteration 3068 : loss : 0.044377, loss_ce: 0.016863
2021-12-10 11:42:38,090 iteration 3069 : loss : 0.045175, loss_ce: 0.012483
2021-12-10 11:42:39,621 iteration 3070 : loss : 0.030021, loss_ce: 0.018425
2021-12-10 11:42:41,088 iteration 3071 : loss : 0.027754, loss_ce: 0.010789
2021-12-10 11:42:42,554 iteration 3072 : loss : 0.036573, loss_ce: 0.012496
2021-12-10 11:42:44,049 iteration 3073 : loss : 0.030523, loss_ce: 0.011675
2021-12-10 11:42:45,634 iteration 3074 : loss : 0.048798, loss_ce: 0.019184
2021-12-10 11:42:47,184 iteration 3075 : loss : 0.033290, loss_ce: 0.011360
2021-12-10 11:42:48,763 iteration 3076 : loss : 0.037760, loss_ce: 0.014257
2021-12-10 11:42:50,238 iteration 3077 : loss : 0.043969, loss_ce: 0.020012
 45%|████████████▏              | 181/400 [1:27:01<1:44:05, 28.52s/it]2021-12-10 11:42:51,756 iteration 3078 : loss : 0.030923, loss_ce: 0.011945
2021-12-10 11:42:53,378 iteration 3079 : loss : 0.034383, loss_ce: 0.014783
2021-12-10 11:42:54,827 iteration 3080 : loss : 0.028348, loss_ce: 0.008465
2021-12-10 11:42:56,370 iteration 3081 : loss : 0.045318, loss_ce: 0.015595
2021-12-10 11:42:57,872 iteration 3082 : loss : 0.037686, loss_ce: 0.008971
2021-12-10 11:42:59,434 iteration 3083 : loss : 0.026380, loss_ce: 0.009735
2021-12-10 11:43:00,843 iteration 3084 : loss : 0.026375, loss_ce: 0.011521
2021-12-10 11:43:02,380 iteration 3085 : loss : 0.029162, loss_ce: 0.013764
2021-12-10 11:43:03,992 iteration 3086 : loss : 0.033103, loss_ce: 0.017026
2021-12-10 11:43:05,493 iteration 3087 : loss : 0.040668, loss_ce: 0.016979
2021-12-10 11:43:07,027 iteration 3088 : loss : 0.024670, loss_ce: 0.007366
2021-12-10 11:43:08,635 iteration 3089 : loss : 0.037894, loss_ce: 0.012151
2021-12-10 11:43:10,082 iteration 3090 : loss : 0.029703, loss_ce: 0.013097
2021-12-10 11:43:11,593 iteration 3091 : loss : 0.037723, loss_ce: 0.019063
2021-12-10 11:43:13,244 iteration 3092 : loss : 0.033928, loss_ce: 0.014006
2021-12-10 11:43:14,735 iteration 3093 : loss : 0.027213, loss_ce: 0.011159
2021-12-10 11:43:16,267 iteration 3094 : loss : 0.035497, loss_ce: 0.017531
 46%|████████████▎              | 182/400 [1:27:27<1:40:54, 27.77s/it]2021-12-10 11:43:17,836 iteration 3095 : loss : 0.024466, loss_ce: 0.009981
2021-12-10 11:43:19,369 iteration 3096 : loss : 0.030853, loss_ce: 0.013843
2021-12-10 11:43:20,870 iteration 3097 : loss : 0.023812, loss_ce: 0.009198
2021-12-10 11:43:22,341 iteration 3098 : loss : 0.025120, loss_ce: 0.010722
2021-12-10 11:43:23,849 iteration 3099 : loss : 0.026036, loss_ce: 0.009000
2021-12-10 11:43:25,317 iteration 3100 : loss : 0.031032, loss_ce: 0.010323
2021-12-10 11:43:26,882 iteration 3101 : loss : 0.024528, loss_ce: 0.008913
2021-12-10 11:43:28,400 iteration 3102 : loss : 0.026272, loss_ce: 0.009972
2021-12-10 11:43:29,931 iteration 3103 : loss : 0.036776, loss_ce: 0.013546
2021-12-10 11:43:31,410 iteration 3104 : loss : 0.027393, loss_ce: 0.010915
2021-12-10 11:43:32,864 iteration 3105 : loss : 0.024374, loss_ce: 0.011664
2021-12-10 11:43:34,365 iteration 3106 : loss : 0.025777, loss_ce: 0.011749
2021-12-10 11:43:35,857 iteration 3107 : loss : 0.029458, loss_ce: 0.008945
2021-12-10 11:43:37,390 iteration 3108 : loss : 0.037601, loss_ce: 0.012177
2021-12-10 11:43:38,937 iteration 3109 : loss : 0.026398, loss_ce: 0.008777
2021-12-10 11:43:40,488 iteration 3110 : loss : 0.046116, loss_ce: 0.019364
2021-12-10 11:43:42,024 iteration 3111 : loss : 0.033648, loss_ce: 0.013340
 46%|████████████▎              | 183/400 [1:27:53<1:38:14, 27.16s/it]2021-12-10 11:43:43,598 iteration 3112 : loss : 0.028961, loss_ce: 0.010769
2021-12-10 11:43:45,078 iteration 3113 : loss : 0.036452, loss_ce: 0.014018
2021-12-10 11:43:46,634 iteration 3114 : loss : 0.030735, loss_ce: 0.012910
2021-12-10 11:43:48,154 iteration 3115 : loss : 0.030196, loss_ce: 0.012599
2021-12-10 11:43:49,659 iteration 3116 : loss : 0.021612, loss_ce: 0.009301
2021-12-10 11:43:51,237 iteration 3117 : loss : 0.023031, loss_ce: 0.009363
2021-12-10 11:43:52,734 iteration 3118 : loss : 0.032572, loss_ce: 0.011453
2021-12-10 11:43:54,347 iteration 3119 : loss : 0.035554, loss_ce: 0.013038
2021-12-10 11:43:55,819 iteration 3120 : loss : 0.022907, loss_ce: 0.009111
2021-12-10 11:43:57,398 iteration 3121 : loss : 0.024958, loss_ce: 0.010679
2021-12-10 11:43:58,900 iteration 3122 : loss : 0.031286, loss_ce: 0.007841
2021-12-10 11:44:00,468 iteration 3123 : loss : 0.028390, loss_ce: 0.011881
2021-12-10 11:44:01,919 iteration 3124 : loss : 0.021687, loss_ce: 0.008692
2021-12-10 11:44:03,432 iteration 3125 : loss : 0.026777, loss_ce: 0.008778
2021-12-10 11:44:05,005 iteration 3126 : loss : 0.025046, loss_ce: 0.011403
2021-12-10 11:44:06,592 iteration 3127 : loss : 0.028026, loss_ce: 0.009249
2021-12-10 11:44:08,168 iteration 3128 : loss : 0.038171, loss_ce: 0.013323
 46%|████████████▍              | 184/400 [1:28:19<1:36:42, 26.86s/it]2021-12-10 11:44:09,713 iteration 3129 : loss : 0.030813, loss_ce: 0.011796
2021-12-10 11:44:11,324 iteration 3130 : loss : 0.028324, loss_ce: 0.012629
2021-12-10 11:44:12,835 iteration 3131 : loss : 0.034045, loss_ce: 0.014012
2021-12-10 11:44:14,352 iteration 3132 : loss : 0.026253, loss_ce: 0.007251
2021-12-10 11:44:15,868 iteration 3133 : loss : 0.036649, loss_ce: 0.013212
2021-12-10 11:44:17,352 iteration 3134 : loss : 0.026285, loss_ce: 0.013112
2021-12-10 11:44:18,865 iteration 3135 : loss : 0.028956, loss_ce: 0.013454
2021-12-10 11:44:20,356 iteration 3136 : loss : 0.025309, loss_ce: 0.010102
2021-12-10 11:44:21,984 iteration 3137 : loss : 0.029282, loss_ce: 0.012641
2021-12-10 11:44:23,563 iteration 3138 : loss : 0.048251, loss_ce: 0.019225
2021-12-10 11:44:25,024 iteration 3139 : loss : 0.025207, loss_ce: 0.008874
2021-12-10 11:44:26,492 iteration 3140 : loss : 0.030995, loss_ce: 0.014021
2021-12-10 11:44:28,027 iteration 3141 : loss : 0.042528, loss_ce: 0.019614
2021-12-10 11:44:29,527 iteration 3142 : loss : 0.037746, loss_ce: 0.012563
2021-12-10 11:44:31,087 iteration 3143 : loss : 0.036459, loss_ce: 0.013529
2021-12-10 11:44:32,591 iteration 3144 : loss : 0.023638, loss_ce: 0.008782
2021-12-10 11:44:32,591 Training Data Eval:
2021-12-10 11:44:40,259   Average segmentation loss on training set: 0.0202
2021-12-10 11:44:40,259 Validation Data Eval:
2021-12-10 11:44:42,880   Average segmentation loss on validation set: 0.0821
2021-12-10 11:44:44,359 iteration 3145 : loss : 0.023741, loss_ce: 0.009662
 46%|████████████▍              | 185/400 [1:28:55<1:46:16, 29.66s/it]2021-12-10 11:44:46,070 iteration 3146 : loss : 0.031206, loss_ce: 0.009228
2021-12-10 11:44:47,636 iteration 3147 : loss : 0.038092, loss_ce: 0.021038
2021-12-10 11:44:49,099 iteration 3148 : loss : 0.023865, loss_ce: 0.009134
2021-12-10 11:44:50,653 iteration 3149 : loss : 0.025181, loss_ce: 0.008073
2021-12-10 11:44:52,207 iteration 3150 : loss : 0.027922, loss_ce: 0.007234
2021-12-10 11:44:53,760 iteration 3151 : loss : 0.033313, loss_ce: 0.012078
2021-12-10 11:44:55,307 iteration 3152 : loss : 0.029709, loss_ce: 0.009637
2021-12-10 11:44:56,840 iteration 3153 : loss : 0.026514, loss_ce: 0.011878
2021-12-10 11:44:58,436 iteration 3154 : loss : 0.036163, loss_ce: 0.013976
2021-12-10 11:44:59,991 iteration 3155 : loss : 0.027365, loss_ce: 0.009098
2021-12-10 11:45:01,453 iteration 3156 : loss : 0.025521, loss_ce: 0.008731
2021-12-10 11:45:02,986 iteration 3157 : loss : 0.025636, loss_ce: 0.010700
2021-12-10 11:45:04,466 iteration 3158 : loss : 0.051612, loss_ce: 0.010740
2021-12-10 11:45:06,011 iteration 3159 : loss : 0.031835, loss_ce: 0.015852
2021-12-10 11:45:07,558 iteration 3160 : loss : 0.033481, loss_ce: 0.015792
2021-12-10 11:45:09,152 iteration 3161 : loss : 0.039010, loss_ce: 0.014675
2021-12-10 11:45:10,688 iteration 3162 : loss : 0.035705, loss_ce: 0.012700
 46%|████████████▌              | 186/400 [1:29:22<1:42:13, 28.66s/it]2021-12-10 11:45:12,218 iteration 3163 : loss : 0.035117, loss_ce: 0.011720
2021-12-10 11:45:13,835 iteration 3164 : loss : 0.043321, loss_ce: 0.018226
2021-12-10 11:45:15,414 iteration 3165 : loss : 0.022831, loss_ce: 0.008716
2021-12-10 11:45:16,902 iteration 3166 : loss : 0.030333, loss_ce: 0.012410
2021-12-10 11:45:18,473 iteration 3167 : loss : 0.025177, loss_ce: 0.008829
2021-12-10 11:45:19,990 iteration 3168 : loss : 0.032227, loss_ce: 0.013009
2021-12-10 11:45:21,536 iteration 3169 : loss : 0.051168, loss_ce: 0.029735
2021-12-10 11:45:23,060 iteration 3170 : loss : 0.034019, loss_ce: 0.016346
2021-12-10 11:45:24,475 iteration 3171 : loss : 0.032659, loss_ce: 0.010539
2021-12-10 11:45:25,962 iteration 3172 : loss : 0.035844, loss_ce: 0.016823
2021-12-10 11:45:27,483 iteration 3173 : loss : 0.035006, loss_ce: 0.011896
2021-12-10 11:45:28,975 iteration 3174 : loss : 0.034443, loss_ce: 0.013574
2021-12-10 11:45:30,439 iteration 3175 : loss : 0.043451, loss_ce: 0.015902
2021-12-10 11:45:32,033 iteration 3176 : loss : 0.041230, loss_ce: 0.013750
2021-12-10 11:45:33,555 iteration 3177 : loss : 0.039416, loss_ce: 0.015726
2021-12-10 11:45:35,161 iteration 3178 : loss : 0.038728, loss_ce: 0.011776
2021-12-10 11:45:36,695 iteration 3179 : loss : 0.030523, loss_ce: 0.013576
 47%|████████████▌              | 187/400 [1:29:48<1:38:55, 27.87s/it]2021-12-10 11:45:38,293 iteration 3180 : loss : 0.093203, loss_ce: 0.039900
2021-12-10 11:45:39,793 iteration 3181 : loss : 0.027996, loss_ce: 0.012638
2021-12-10 11:45:41,262 iteration 3182 : loss : 0.042329, loss_ce: 0.024017
2021-12-10 11:45:42,838 iteration 3183 : loss : 0.060169, loss_ce: 0.023765
2021-12-10 11:45:44,358 iteration 3184 : loss : 0.034819, loss_ce: 0.011648
2021-12-10 11:45:45,889 iteration 3185 : loss : 0.032393, loss_ce: 0.010177
2021-12-10 11:45:47,446 iteration 3186 : loss : 0.036051, loss_ce: 0.015508
2021-12-10 11:45:49,019 iteration 3187 : loss : 0.030534, loss_ce: 0.012150
2021-12-10 11:45:50,591 iteration 3188 : loss : 0.033077, loss_ce: 0.013387
2021-12-10 11:45:52,103 iteration 3189 : loss : 0.029887, loss_ce: 0.010939
2021-12-10 11:45:53,722 iteration 3190 : loss : 0.035772, loss_ce: 0.013358
2021-12-10 11:45:55,296 iteration 3191 : loss : 0.030079, loss_ce: 0.011450
2021-12-10 11:45:56,758 iteration 3192 : loss : 0.045550, loss_ce: 0.010233
2021-12-10 11:45:58,281 iteration 3193 : loss : 0.034238, loss_ce: 0.014191
2021-12-10 11:45:59,921 iteration 3194 : loss : 0.060083, loss_ce: 0.027751
2021-12-10 11:46:01,523 iteration 3195 : loss : 0.033268, loss_ce: 0.015068
2021-12-10 11:46:03,051 iteration 3196 : loss : 0.035970, loss_ce: 0.017500
 47%|████████████▋              | 188/400 [1:30:14<1:36:51, 27.41s/it]2021-12-10 11:46:04,625 iteration 3197 : loss : 0.027863, loss_ce: 0.012155
2021-12-10 11:46:06,184 iteration 3198 : loss : 0.035863, loss_ce: 0.016452
2021-12-10 11:46:07,734 iteration 3199 : loss : 0.035768, loss_ce: 0.011140
2021-12-10 11:46:09,299 iteration 3200 : loss : 0.038913, loss_ce: 0.013983
2021-12-10 11:46:10,866 iteration 3201 : loss : 0.035259, loss_ce: 0.014439
2021-12-10 11:46:12,439 iteration 3202 : loss : 0.040648, loss_ce: 0.012052
2021-12-10 11:46:13,895 iteration 3203 : loss : 0.024464, loss_ce: 0.010401
2021-12-10 11:46:15,336 iteration 3204 : loss : 0.029554, loss_ce: 0.012110
2021-12-10 11:46:16,782 iteration 3205 : loss : 0.029320, loss_ce: 0.011713
2021-12-10 11:46:18,198 iteration 3206 : loss : 0.025277, loss_ce: 0.008135
2021-12-10 11:46:19,745 iteration 3207 : loss : 0.044502, loss_ce: 0.018300
2021-12-10 11:46:21,262 iteration 3208 : loss : 0.034701, loss_ce: 0.015199
2021-12-10 11:46:22,755 iteration 3209 : loss : 0.058458, loss_ce: 0.025829
2021-12-10 11:46:24,300 iteration 3210 : loss : 0.026543, loss_ce: 0.012331
2021-12-10 11:46:25,765 iteration 3211 : loss : 0.024579, loss_ce: 0.007321
2021-12-10 11:46:27,354 iteration 3212 : loss : 0.065086, loss_ce: 0.031280
2021-12-10 11:46:28,954 iteration 3213 : loss : 0.039855, loss_ce: 0.013225
 47%|████████████▊              | 189/400 [1:30:40<1:34:48, 26.96s/it]2021-12-10 11:46:30,481 iteration 3214 : loss : 0.035594, loss_ce: 0.019727
2021-12-10 11:46:31,997 iteration 3215 : loss : 0.024042, loss_ce: 0.010182
2021-12-10 11:46:33,517 iteration 3216 : loss : 0.029215, loss_ce: 0.012279
2021-12-10 11:46:35,070 iteration 3217 : loss : 0.032708, loss_ce: 0.014567
2021-12-10 11:46:36,598 iteration 3218 : loss : 0.056274, loss_ce: 0.021277
2021-12-10 11:46:38,114 iteration 3219 : loss : 0.054685, loss_ce: 0.022956
2021-12-10 11:46:39,593 iteration 3220 : loss : 0.025264, loss_ce: 0.010587
2021-12-10 11:46:41,200 iteration 3221 : loss : 0.048699, loss_ce: 0.021611
2021-12-10 11:46:42,692 iteration 3222 : loss : 0.026528, loss_ce: 0.007464
2021-12-10 11:46:44,237 iteration 3223 : loss : 0.024157, loss_ce: 0.009138
2021-12-10 11:46:45,840 iteration 3224 : loss : 0.057844, loss_ce: 0.020700
2021-12-10 11:46:47,363 iteration 3225 : loss : 0.047876, loss_ce: 0.025207
2021-12-10 11:46:48,886 iteration 3226 : loss : 0.029057, loss_ce: 0.012233
2021-12-10 11:46:50,423 iteration 3227 : loss : 0.026268, loss_ce: 0.010552
2021-12-10 11:46:51,919 iteration 3228 : loss : 0.044342, loss_ce: 0.014158
2021-12-10 11:46:53,387 iteration 3229 : loss : 0.033547, loss_ce: 0.009859
2021-12-10 11:46:53,387 Training Data Eval:
2021-12-10 11:47:01,045   Average segmentation loss on training set: 0.0188
2021-12-10 11:47:01,045 Validation Data Eval:
2021-12-10 11:47:03,674   Average segmentation loss on validation set: 0.0824
2021-12-10 11:47:05,134 iteration 3230 : loss : 0.025243, loss_ce: 0.008335
 48%|████████████▊              | 190/400 [1:31:16<1:44:02, 29.73s/it]2021-12-10 11:47:06,670 iteration 3231 : loss : 0.031540, loss_ce: 0.008162
2021-12-10 11:47:08,172 iteration 3232 : loss : 0.026878, loss_ce: 0.009178
2021-12-10 11:47:09,694 iteration 3233 : loss : 0.031553, loss_ce: 0.013915
2021-12-10 11:47:11,240 iteration 3234 : loss : 0.023008, loss_ce: 0.008759
2021-12-10 11:47:12,780 iteration 3235 : loss : 0.043394, loss_ce: 0.014728
2021-12-10 11:47:14,242 iteration 3236 : loss : 0.024772, loss_ce: 0.013019
2021-12-10 11:47:15,853 iteration 3237 : loss : 0.028883, loss_ce: 0.012969
2021-12-10 11:47:17,387 iteration 3238 : loss : 0.030569, loss_ce: 0.015548
2021-12-10 11:47:18,912 iteration 3239 : loss : 0.022810, loss_ce: 0.008793
2021-12-10 11:47:20,385 iteration 3240 : loss : 0.030207, loss_ce: 0.007630
2021-12-10 11:47:21,837 iteration 3241 : loss : 0.031651, loss_ce: 0.007368
2021-12-10 11:47:23,365 iteration 3242 : loss : 0.037313, loss_ce: 0.014893
2021-12-10 11:47:24,826 iteration 3243 : loss : 0.038891, loss_ce: 0.012590
2021-12-10 11:47:26,371 iteration 3244 : loss : 0.027466, loss_ce: 0.011189
2021-12-10 11:47:27,852 iteration 3245 : loss : 0.020241, loss_ce: 0.009500
2021-12-10 11:47:29,437 iteration 3246 : loss : 0.038554, loss_ce: 0.022499
2021-12-10 11:47:30,922 iteration 3247 : loss : 0.034985, loss_ce: 0.013719
 48%|████████████▉              | 191/400 [1:31:42<1:39:25, 28.54s/it]2021-12-10 11:47:32,450 iteration 3248 : loss : 0.017976, loss_ce: 0.006637
2021-12-10 11:47:33,925 iteration 3249 : loss : 0.025354, loss_ce: 0.009700
2021-12-10 11:47:35,422 iteration 3250 : loss : 0.028292, loss_ce: 0.008666
2021-12-10 11:47:36,922 iteration 3251 : loss : 0.026695, loss_ce: 0.011928
2021-12-10 11:47:38,442 iteration 3252 : loss : 0.026526, loss_ce: 0.008205
2021-12-10 11:47:39,941 iteration 3253 : loss : 0.021376, loss_ce: 0.009362
2021-12-10 11:47:41,434 iteration 3254 : loss : 0.029017, loss_ce: 0.011069
2021-12-10 11:47:42,866 iteration 3255 : loss : 0.028326, loss_ce: 0.011146
2021-12-10 11:47:44,360 iteration 3256 : loss : 0.029710, loss_ce: 0.012346
2021-12-10 11:47:45,836 iteration 3257 : loss : 0.023963, loss_ce: 0.009357
2021-12-10 11:47:47,359 iteration 3258 : loss : 0.031756, loss_ce: 0.013515
2021-12-10 11:47:48,826 iteration 3259 : loss : 0.031484, loss_ce: 0.011903
2021-12-10 11:47:50,349 iteration 3260 : loss : 0.029986, loss_ce: 0.012027
2021-12-10 11:47:51,833 iteration 3261 : loss : 0.036699, loss_ce: 0.009883
2021-12-10 11:47:53,385 iteration 3262 : loss : 0.030216, loss_ce: 0.011394
2021-12-10 11:47:55,009 iteration 3263 : loss : 0.035093, loss_ce: 0.009969
2021-12-10 11:47:56,537 iteration 3264 : loss : 0.031769, loss_ce: 0.012882
 48%|████████████▉              | 192/400 [1:32:08<1:35:55, 27.67s/it]2021-12-10 11:47:58,058 iteration 3265 : loss : 0.023112, loss_ce: 0.009386
2021-12-10 11:47:59,626 iteration 3266 : loss : 0.030469, loss_ce: 0.013530
2021-12-10 11:48:01,157 iteration 3267 : loss : 0.022116, loss_ce: 0.009117
2021-12-10 11:48:02,635 iteration 3268 : loss : 0.026627, loss_ce: 0.010257
2021-12-10 11:48:04,200 iteration 3269 : loss : 0.031949, loss_ce: 0.013806
2021-12-10 11:48:05,795 iteration 3270 : loss : 0.046679, loss_ce: 0.017382
2021-12-10 11:48:07,361 iteration 3271 : loss : 0.035807, loss_ce: 0.009927
2021-12-10 11:48:08,935 iteration 3272 : loss : 0.027730, loss_ce: 0.012072
2021-12-10 11:48:10,400 iteration 3273 : loss : 0.029204, loss_ce: 0.008775
2021-12-10 11:48:11,910 iteration 3274 : loss : 0.019808, loss_ce: 0.010046
2021-12-10 11:48:13,487 iteration 3275 : loss : 0.035414, loss_ce: 0.009880
2021-12-10 11:48:14,982 iteration 3276 : loss : 0.025225, loss_ce: 0.010390
2021-12-10 11:48:16,533 iteration 3277 : loss : 0.030155, loss_ce: 0.015869
2021-12-10 11:48:18,056 iteration 3278 : loss : 0.041854, loss_ce: 0.017184
2021-12-10 11:48:19,537 iteration 3279 : loss : 0.027044, loss_ce: 0.010323
2021-12-10 11:48:21,038 iteration 3280 : loss : 0.032396, loss_ce: 0.011065
2021-12-10 11:48:22,497 iteration 3281 : loss : 0.026537, loss_ce: 0.008243
 48%|█████████████              | 193/400 [1:32:33<1:33:40, 27.15s/it]2021-12-10 11:48:24,094 iteration 3282 : loss : 0.033871, loss_ce: 0.014863
2021-12-10 11:48:25,605 iteration 3283 : loss : 0.032476, loss_ce: 0.012147
2021-12-10 11:48:27,124 iteration 3284 : loss : 0.030619, loss_ce: 0.013397
2021-12-10 11:48:28,629 iteration 3285 : loss : 0.050238, loss_ce: 0.025673
2021-12-10 11:48:30,131 iteration 3286 : loss : 0.019196, loss_ce: 0.006721
2021-12-10 11:48:31,657 iteration 3287 : loss : 0.048318, loss_ce: 0.016914
2021-12-10 11:48:33,125 iteration 3288 : loss : 0.045547, loss_ce: 0.025955
2021-12-10 11:48:34,600 iteration 3289 : loss : 0.028831, loss_ce: 0.008765
2021-12-10 11:48:36,166 iteration 3290 : loss : 0.033112, loss_ce: 0.009898
2021-12-10 11:48:37,740 iteration 3291 : loss : 0.046810, loss_ce: 0.019950
2021-12-10 11:48:39,271 iteration 3292 : loss : 0.038992, loss_ce: 0.011546
2021-12-10 11:48:40,787 iteration 3293 : loss : 0.027811, loss_ce: 0.012791
2021-12-10 11:48:42,271 iteration 3294 : loss : 0.023385, loss_ce: 0.011669
2021-12-10 11:48:43,865 iteration 3295 : loss : 0.037023, loss_ce: 0.015326
2021-12-10 11:48:45,415 iteration 3296 : loss : 0.040946, loss_ce: 0.011533
2021-12-10 11:48:46,868 iteration 3297 : loss : 0.024433, loss_ce: 0.009866
2021-12-10 11:48:48,424 iteration 3298 : loss : 0.036240, loss_ce: 0.016115
 48%|█████████████              | 194/400 [1:32:59<1:31:57, 26.78s/it]2021-12-10 11:48:49,931 iteration 3299 : loss : 0.025603, loss_ce: 0.011140
2021-12-10 11:48:51,417 iteration 3300 : loss : 0.044366, loss_ce: 0.018271
2021-12-10 11:48:52,985 iteration 3301 : loss : 0.029899, loss_ce: 0.013131
2021-12-10 11:48:54,497 iteration 3302 : loss : 0.028588, loss_ce: 0.011245
2021-12-10 11:48:55,995 iteration 3303 : loss : 0.027526, loss_ce: 0.011211
2021-12-10 11:48:57,520 iteration 3304 : loss : 0.031569, loss_ce: 0.011925
2021-12-10 11:48:59,064 iteration 3305 : loss : 0.039743, loss_ce: 0.013990
2021-12-10 11:49:00,629 iteration 3306 : loss : 0.032136, loss_ce: 0.013121
2021-12-10 11:49:02,122 iteration 3307 : loss : 0.033427, loss_ce: 0.011629
2021-12-10 11:49:03,644 iteration 3308 : loss : 0.031536, loss_ce: 0.013704
2021-12-10 11:49:05,154 iteration 3309 : loss : 0.036148, loss_ce: 0.008323
2021-12-10 11:49:06,737 iteration 3310 : loss : 0.073971, loss_ce: 0.035789
2021-12-10 11:49:08,344 iteration 3311 : loss : 0.029095, loss_ce: 0.010209
2021-12-10 11:49:09,817 iteration 3312 : loss : 0.027837, loss_ce: 0.009748
2021-12-10 11:49:11,293 iteration 3313 : loss : 0.022539, loss_ce: 0.008278
2021-12-10 11:49:12,871 iteration 3314 : loss : 0.028854, loss_ce: 0.009493
2021-12-10 11:49:12,871 Training Data Eval:
2021-12-10 11:49:20,528   Average segmentation loss on training set: 0.0188
2021-12-10 11:49:20,528 Validation Data Eval:
2021-12-10 11:49:23,171   Average segmentation loss on validation set: 0.0650
2021-12-10 11:49:28,900 Found new lowest validation loss at iteration 3314! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 11:49:30,415 iteration 3315 : loss : 0.021581, loss_ce: 0.010555
 49%|█████████████▏             | 195/400 [1:33:41<1:47:06, 31.35s/it]2021-12-10 11:49:31,928 iteration 3316 : loss : 0.018661, loss_ce: 0.007298
2021-12-10 11:49:33,411 iteration 3317 : loss : 0.028477, loss_ce: 0.010964
2021-12-10 11:49:35,017 iteration 3318 : loss : 0.034702, loss_ce: 0.015585
2021-12-10 11:49:36,502 iteration 3319 : loss : 0.031949, loss_ce: 0.011734
2021-12-10 11:49:37,992 iteration 3320 : loss : 0.022048, loss_ce: 0.008397
2021-12-10 11:49:39,515 iteration 3321 : loss : 0.019399, loss_ce: 0.005759
2021-12-10 11:49:41,032 iteration 3322 : loss : 0.045556, loss_ce: 0.020986
2021-12-10 11:49:42,494 iteration 3323 : loss : 0.028445, loss_ce: 0.009749
2021-12-10 11:49:44,079 iteration 3324 : loss : 0.041872, loss_ce: 0.017827
2021-12-10 11:49:45,545 iteration 3325 : loss : 0.030171, loss_ce: 0.010659
2021-12-10 11:49:47,083 iteration 3326 : loss : 0.027993, loss_ce: 0.010830
2021-12-10 11:49:48,689 iteration 3327 : loss : 0.061859, loss_ce: 0.022493
2021-12-10 11:49:50,200 iteration 3328 : loss : 0.027398, loss_ce: 0.009703
2021-12-10 11:49:51,686 iteration 3329 : loss : 0.022689, loss_ce: 0.009482
2021-12-10 11:49:53,187 iteration 3330 : loss : 0.055234, loss_ce: 0.016627
2021-12-10 11:49:54,712 iteration 3331 : loss : 0.029508, loss_ce: 0.011434
2021-12-10 11:49:56,144 iteration 3332 : loss : 0.020454, loss_ce: 0.009637
 49%|█████████████▏             | 196/400 [1:34:07<1:40:51, 29.66s/it]2021-12-10 11:49:57,690 iteration 3333 : loss : 0.023815, loss_ce: 0.009821
2021-12-10 11:49:59,221 iteration 3334 : loss : 0.017190, loss_ce: 0.007669
2021-12-10 11:50:00,661 iteration 3335 : loss : 0.018656, loss_ce: 0.007983
2021-12-10 11:50:02,175 iteration 3336 : loss : 0.057957, loss_ce: 0.018955
2021-12-10 11:50:03,735 iteration 3337 : loss : 0.045566, loss_ce: 0.018483
2021-12-10 11:50:05,340 iteration 3338 : loss : 0.053180, loss_ce: 0.032549
2021-12-10 11:50:06,845 iteration 3339 : loss : 0.044056, loss_ce: 0.011931
2021-12-10 11:50:08,334 iteration 3340 : loss : 0.025525, loss_ce: 0.008011
2021-12-10 11:50:09,841 iteration 3341 : loss : 0.023241, loss_ce: 0.008811
2021-12-10 11:50:11,400 iteration 3342 : loss : 0.045411, loss_ce: 0.022010
2021-12-10 11:50:12,937 iteration 3343 : loss : 0.041958, loss_ce: 0.016981
2021-12-10 11:50:14,461 iteration 3344 : loss : 0.043594, loss_ce: 0.015724
2021-12-10 11:50:15,958 iteration 3345 : loss : 0.026393, loss_ce: 0.009592
2021-12-10 11:50:17,482 iteration 3346 : loss : 0.022428, loss_ce: 0.010779
2021-12-10 11:50:19,030 iteration 3347 : loss : 0.053920, loss_ce: 0.013933
2021-12-10 11:50:20,638 iteration 3348 : loss : 0.033092, loss_ce: 0.010892
2021-12-10 11:50:22,178 iteration 3349 : loss : 0.034486, loss_ce: 0.013649
 49%|█████████████▎             | 197/400 [1:34:33<1:36:40, 28.57s/it]2021-12-10 11:50:23,710 iteration 3350 : loss : 0.022029, loss_ce: 0.008740
2021-12-10 11:50:25,186 iteration 3351 : loss : 0.027892, loss_ce: 0.010741
2021-12-10 11:50:26,682 iteration 3352 : loss : 0.025660, loss_ce: 0.010764
2021-12-10 11:50:28,219 iteration 3353 : loss : 0.033578, loss_ce: 0.013284
2021-12-10 11:50:29,748 iteration 3354 : loss : 0.028066, loss_ce: 0.009776
2021-12-10 11:50:31,338 iteration 3355 : loss : 0.032471, loss_ce: 0.017886
2021-12-10 11:50:32,901 iteration 3356 : loss : 0.041453, loss_ce: 0.011409
2021-12-10 11:50:34,474 iteration 3357 : loss : 0.032274, loss_ce: 0.010744
2021-12-10 11:50:36,060 iteration 3358 : loss : 0.028610, loss_ce: 0.009815
2021-12-10 11:50:37,615 iteration 3359 : loss : 0.033195, loss_ce: 0.014715
2021-12-10 11:50:39,220 iteration 3360 : loss : 0.032481, loss_ce: 0.015457
2021-12-10 11:50:40,691 iteration 3361 : loss : 0.046717, loss_ce: 0.013192
2021-12-10 11:50:42,171 iteration 3362 : loss : 0.026079, loss_ce: 0.010970
2021-12-10 11:50:43,641 iteration 3363 : loss : 0.024182, loss_ce: 0.011446
2021-12-10 11:50:45,178 iteration 3364 : loss : 0.032856, loss_ce: 0.011223
2021-12-10 11:50:46,651 iteration 3365 : loss : 0.025640, loss_ce: 0.013293
2021-12-10 11:50:48,155 iteration 3366 : loss : 0.024287, loss_ce: 0.008927
 50%|█████████████▎             | 198/400 [1:34:59<1:33:34, 27.79s/it]2021-12-10 11:50:49,723 iteration 3367 : loss : 0.029756, loss_ce: 0.011380
2021-12-10 11:50:51,229 iteration 3368 : loss : 0.030341, loss_ce: 0.014771
2021-12-10 11:50:52,762 iteration 3369 : loss : 0.026515, loss_ce: 0.009059
2021-12-10 11:50:54,302 iteration 3370 : loss : 0.032483, loss_ce: 0.013889
2021-12-10 11:50:55,736 iteration 3371 : loss : 0.018499, loss_ce: 0.007808
2021-12-10 11:50:57,237 iteration 3372 : loss : 0.031696, loss_ce: 0.014160
2021-12-10 11:50:58,739 iteration 3373 : loss : 0.028503, loss_ce: 0.014224
2021-12-10 11:51:00,197 iteration 3374 : loss : 0.021121, loss_ce: 0.008746
2021-12-10 11:51:01,670 iteration 3375 : loss : 0.024134, loss_ce: 0.010341
2021-12-10 11:51:03,152 iteration 3376 : loss : 0.028295, loss_ce: 0.012268
2021-12-10 11:51:04,708 iteration 3377 : loss : 0.046427, loss_ce: 0.015032
2021-12-10 11:51:06,216 iteration 3378 : loss : 0.036113, loss_ce: 0.013318
2021-12-10 11:51:07,645 iteration 3379 : loss : 0.021992, loss_ce: 0.009606
2021-12-10 11:51:09,218 iteration 3380 : loss : 0.044664, loss_ce: 0.016655
2021-12-10 11:51:10,670 iteration 3381 : loss : 0.053715, loss_ce: 0.008747
2021-12-10 11:51:12,185 iteration 3382 : loss : 0.034270, loss_ce: 0.013837
2021-12-10 11:51:13,686 iteration 3383 : loss : 0.027304, loss_ce: 0.009819
 50%|█████████████▍             | 199/400 [1:35:25<1:30:50, 27.12s/it]2021-12-10 11:51:15,198 iteration 3384 : loss : 0.025672, loss_ce: 0.009765
2021-12-10 11:51:16,761 iteration 3385 : loss : 0.038303, loss_ce: 0.018291
2021-12-10 11:51:18,333 iteration 3386 : loss : 0.036677, loss_ce: 0.018942
2021-12-10 11:51:19,887 iteration 3387 : loss : 0.032862, loss_ce: 0.013006
2021-12-10 11:51:21,345 iteration 3388 : loss : 0.028358, loss_ce: 0.011170
2021-12-10 11:51:22,890 iteration 3389 : loss : 0.036443, loss_ce: 0.013458
2021-12-10 11:51:24,343 iteration 3390 : loss : 0.038545, loss_ce: 0.010141
2021-12-10 11:51:25,955 iteration 3391 : loss : 0.049928, loss_ce: 0.017737
2021-12-10 11:51:27,510 iteration 3392 : loss : 0.031342, loss_ce: 0.012807
2021-12-10 11:51:29,057 iteration 3393 : loss : 0.027602, loss_ce: 0.010242
2021-12-10 11:51:30,494 iteration 3394 : loss : 0.025706, loss_ce: 0.009805
2021-12-10 11:51:32,110 iteration 3395 : loss : 0.064675, loss_ce: 0.030547
2021-12-10 11:51:33,639 iteration 3396 : loss : 0.048318, loss_ce: 0.017638
2021-12-10 11:51:35,138 iteration 3397 : loss : 0.032525, loss_ce: 0.015329
2021-12-10 11:51:36,692 iteration 3398 : loss : 0.028308, loss_ce: 0.009425
2021-12-10 11:51:38,224 iteration 3399 : loss : 0.026318, loss_ce: 0.010376
2021-12-10 11:51:38,224 Training Data Eval:
2021-12-10 11:51:45,876   Average segmentation loss on training set: 0.0227
2021-12-10 11:51:45,876 Validation Data Eval:
2021-12-10 11:51:48,505   Average segmentation loss on validation set: 0.1016
2021-12-10 11:51:50,024 iteration 3400 : loss : 0.031411, loss_ce: 0.009819
2021-12-10 11:51:55,730 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234epoch_199.pth
 50%|█████████████▌             | 200/400 [1:36:07<1:45:15, 31.58s/it]2021-12-10 11:51:57,417 iteration 3401 : loss : 0.037927, loss_ce: 0.016483
2021-12-10 11:51:58,987 iteration 3402 : loss : 0.029693, loss_ce: 0.010958
2021-12-10 11:52:00,475 iteration 3403 : loss : 0.048335, loss_ce: 0.022483
2021-12-10 11:52:01,963 iteration 3404 : loss : 0.024665, loss_ce: 0.008285
2021-12-10 11:52:03,456 iteration 3405 : loss : 0.024087, loss_ce: 0.009230
2021-12-10 11:52:05,016 iteration 3406 : loss : 0.037914, loss_ce: 0.013294
2021-12-10 11:52:06,536 iteration 3407 : loss : 0.033917, loss_ce: 0.015125
2021-12-10 11:52:08,069 iteration 3408 : loss : 0.026007, loss_ce: 0.009930
2021-12-10 11:52:09,612 iteration 3409 : loss : 0.042632, loss_ce: 0.018896
2021-12-10 11:52:11,147 iteration 3410 : loss : 0.032428, loss_ce: 0.011784
2021-12-10 11:52:12,721 iteration 3411 : loss : 0.034598, loss_ce: 0.013468
2021-12-10 11:52:14,185 iteration 3412 : loss : 0.032828, loss_ce: 0.011091
2021-12-10 11:52:15,631 iteration 3413 : loss : 0.018809, loss_ce: 0.008288
2021-12-10 11:52:17,164 iteration 3414 : loss : 0.035053, loss_ce: 0.009665
2021-12-10 11:52:18,723 iteration 3415 : loss : 0.037334, loss_ce: 0.014090
2021-12-10 11:52:20,288 iteration 3416 : loss : 0.028406, loss_ce: 0.008862
2021-12-10 11:52:21,893 iteration 3417 : loss : 0.038829, loss_ce: 0.015024
 50%|█████████████▌             | 201/400 [1:36:33<1:39:23, 29.97s/it]2021-12-10 11:52:23,475 iteration 3418 : loss : 0.023618, loss_ce: 0.010302
2021-12-10 11:52:25,030 iteration 3419 : loss : 0.025219, loss_ce: 0.008761
2021-12-10 11:52:26,640 iteration 3420 : loss : 0.049271, loss_ce: 0.018672
2021-12-10 11:52:28,186 iteration 3421 : loss : 0.029846, loss_ce: 0.010372
2021-12-10 11:52:29,648 iteration 3422 : loss : 0.024427, loss_ce: 0.007389
2021-12-10 11:52:31,180 iteration 3423 : loss : 0.021394, loss_ce: 0.009210
2021-12-10 11:52:32,693 iteration 3424 : loss : 0.024550, loss_ce: 0.009915
2021-12-10 11:52:34,163 iteration 3425 : loss : 0.029588, loss_ce: 0.015198
2021-12-10 11:52:35,690 iteration 3426 : loss : 0.035946, loss_ce: 0.011593
2021-12-10 11:52:37,235 iteration 3427 : loss : 0.038649, loss_ce: 0.012390
2021-12-10 11:52:38,777 iteration 3428 : loss : 0.030093, loss_ce: 0.011850
2021-12-10 11:52:40,344 iteration 3429 : loss : 0.029527, loss_ce: 0.013101
2021-12-10 11:52:41,917 iteration 3430 : loss : 0.040348, loss_ce: 0.017190
2021-12-10 11:52:43,362 iteration 3431 : loss : 0.030388, loss_ce: 0.012787
2021-12-10 11:52:44,840 iteration 3432 : loss : 0.021454, loss_ce: 0.006911
2021-12-10 11:52:46,325 iteration 3433 : loss : 0.039490, loss_ce: 0.014521
2021-12-10 11:52:47,895 iteration 3434 : loss : 0.035576, loss_ce: 0.012186
 50%|█████████████▋             | 202/400 [1:36:59<1:34:58, 28.78s/it]2021-12-10 11:52:49,389 iteration 3435 : loss : 0.025854, loss_ce: 0.007472
2021-12-10 11:52:50,876 iteration 3436 : loss : 0.021142, loss_ce: 0.007757
2021-12-10 11:52:52,491 iteration 3437 : loss : 0.029464, loss_ce: 0.013522
2021-12-10 11:52:54,085 iteration 3438 : loss : 0.027348, loss_ce: 0.013531
2021-12-10 11:52:55,648 iteration 3439 : loss : 0.049033, loss_ce: 0.016286
2021-12-10 11:52:57,138 iteration 3440 : loss : 0.028511, loss_ce: 0.010969
2021-12-10 11:52:58,651 iteration 3441 : loss : 0.021893, loss_ce: 0.008470
2021-12-10 11:53:00,279 iteration 3442 : loss : 0.037171, loss_ce: 0.013006
2021-12-10 11:53:01,845 iteration 3443 : loss : 0.025304, loss_ce: 0.008146
2021-12-10 11:53:03,416 iteration 3444 : loss : 0.028031, loss_ce: 0.011179
2021-12-10 11:53:04,944 iteration 3445 : loss : 0.034408, loss_ce: 0.010530
2021-12-10 11:53:06,457 iteration 3446 : loss : 0.029254, loss_ce: 0.011767
2021-12-10 11:53:07,960 iteration 3447 : loss : 0.033415, loss_ce: 0.011444
2021-12-10 11:53:09,533 iteration 3448 : loss : 0.041117, loss_ce: 0.009258
2021-12-10 11:53:11,080 iteration 3449 : loss : 0.030121, loss_ce: 0.012082
2021-12-10 11:53:12,603 iteration 3450 : loss : 0.047111, loss_ce: 0.022871
2021-12-10 11:53:14,206 iteration 3451 : loss : 0.030956, loss_ce: 0.011889
 51%|█████████████▋             | 203/400 [1:37:25<1:32:03, 28.04s/it]2021-12-10 11:53:15,785 iteration 3452 : loss : 0.024654, loss_ce: 0.009546
2021-12-10 11:53:17,289 iteration 3453 : loss : 0.023979, loss_ce: 0.009589
2021-12-10 11:53:18,775 iteration 3454 : loss : 0.024907, loss_ce: 0.007983
2021-12-10 11:53:20,361 iteration 3455 : loss : 0.029305, loss_ce: 0.012870
2021-12-10 11:53:21,844 iteration 3456 : loss : 0.020489, loss_ce: 0.006285
2021-12-10 11:53:23,459 iteration 3457 : loss : 0.030627, loss_ce: 0.012480
2021-12-10 11:53:25,016 iteration 3458 : loss : 0.030322, loss_ce: 0.011711
2021-12-10 11:53:26,536 iteration 3459 : loss : 0.025424, loss_ce: 0.010077
2021-12-10 11:53:28,044 iteration 3460 : loss : 0.022531, loss_ce: 0.009874
2021-12-10 11:53:29,557 iteration 3461 : loss : 0.025678, loss_ce: 0.008357
2021-12-10 11:53:31,056 iteration 3462 : loss : 0.030483, loss_ce: 0.013417
2021-12-10 11:53:32,614 iteration 3463 : loss : 0.037981, loss_ce: 0.015242
2021-12-10 11:53:34,085 iteration 3464 : loss : 0.020710, loss_ce: 0.007383
2021-12-10 11:53:35,651 iteration 3465 : loss : 0.028371, loss_ce: 0.009151
2021-12-10 11:53:37,194 iteration 3466 : loss : 0.021974, loss_ce: 0.007058
2021-12-10 11:53:38,719 iteration 3467 : loss : 0.031150, loss_ce: 0.015944
2021-12-10 11:53:40,234 iteration 3468 : loss : 0.026445, loss_ce: 0.012561
 51%|█████████████▊             | 204/400 [1:37:51<1:29:37, 27.43s/it]2021-12-10 11:53:41,768 iteration 3469 : loss : 0.027534, loss_ce: 0.007657
2021-12-10 11:53:43,341 iteration 3470 : loss : 0.028104, loss_ce: 0.010059
2021-12-10 11:53:44,792 iteration 3471 : loss : 0.023419, loss_ce: 0.008657
2021-12-10 11:53:46,335 iteration 3472 : loss : 0.030395, loss_ce: 0.012999
2021-12-10 11:53:47,967 iteration 3473 : loss : 0.044095, loss_ce: 0.018741
2021-12-10 11:53:49,488 iteration 3474 : loss : 0.025591, loss_ce: 0.008422
2021-12-10 11:53:51,079 iteration 3475 : loss : 0.046910, loss_ce: 0.013195
2021-12-10 11:53:52,567 iteration 3476 : loss : 0.028615, loss_ce: 0.008499
2021-12-10 11:53:54,122 iteration 3477 : loss : 0.051861, loss_ce: 0.016971
2021-12-10 11:53:55,637 iteration 3478 : loss : 0.023448, loss_ce: 0.009165
2021-12-10 11:53:57,124 iteration 3479 : loss : 0.026184, loss_ce: 0.010784
2021-12-10 11:53:58,565 iteration 3480 : loss : 0.027760, loss_ce: 0.011971
2021-12-10 11:54:00,068 iteration 3481 : loss : 0.033598, loss_ce: 0.011491
2021-12-10 11:54:01,589 iteration 3482 : loss : 0.032534, loss_ce: 0.012103
2021-12-10 11:54:03,167 iteration 3483 : loss : 0.025270, loss_ce: 0.011195
2021-12-10 11:54:04,613 iteration 3484 : loss : 0.024356, loss_ce: 0.009177
2021-12-10 11:54:04,613 Training Data Eval:
2021-12-10 11:54:12,259   Average segmentation loss on training set: 0.0181
2021-12-10 11:54:12,260 Validation Data Eval:
2021-12-10 11:54:14,897   Average segmentation loss on validation set: 0.0655
2021-12-10 11:54:16,506 iteration 3485 : loss : 0.063715, loss_ce: 0.034080
 51%|█████████████▊             | 205/400 [1:38:27<1:37:47, 30.09s/it]2021-12-10 11:54:18,116 iteration 3486 : loss : 0.038104, loss_ce: 0.018480
2021-12-10 11:54:19,580 iteration 3487 : loss : 0.025149, loss_ce: 0.011222
2021-12-10 11:54:21,071 iteration 3488 : loss : 0.043713, loss_ce: 0.018259
2021-12-10 11:54:22,581 iteration 3489 : loss : 0.039571, loss_ce: 0.014812
2021-12-10 11:54:24,116 iteration 3490 : loss : 0.034589, loss_ce: 0.013388
2021-12-10 11:54:25,691 iteration 3491 : loss : 0.035301, loss_ce: 0.014995
2021-12-10 11:54:27,152 iteration 3492 : loss : 0.029859, loss_ce: 0.011460
2021-12-10 11:54:28,768 iteration 3493 : loss : 0.029370, loss_ce: 0.010847
2021-12-10 11:54:30,319 iteration 3494 : loss : 0.024156, loss_ce: 0.006605
2021-12-10 11:54:31,831 iteration 3495 : loss : 0.036463, loss_ce: 0.012786
2021-12-10 11:54:33,383 iteration 3496 : loss : 0.037488, loss_ce: 0.018794
2021-12-10 11:54:34,930 iteration 3497 : loss : 0.045253, loss_ce: 0.022334
2021-12-10 11:54:36,555 iteration 3498 : loss : 0.030943, loss_ce: 0.014925
2021-12-10 11:54:38,045 iteration 3499 : loss : 0.024667, loss_ce: 0.009258
2021-12-10 11:54:39,485 iteration 3500 : loss : 0.019555, loss_ce: 0.006506
2021-12-10 11:54:40,959 iteration 3501 : loss : 0.027975, loss_ce: 0.010816
2021-12-10 11:54:42,492 iteration 3502 : loss : 0.034805, loss_ce: 0.014716
 52%|█████████████▉             | 206/400 [1:38:53<1:33:18, 28.86s/it]2021-12-10 11:54:44,085 iteration 3503 : loss : 0.024730, loss_ce: 0.009053
2021-12-10 11:54:45,581 iteration 3504 : loss : 0.028438, loss_ce: 0.009890
2021-12-10 11:54:47,002 iteration 3505 : loss : 0.022691, loss_ce: 0.010942
2021-12-10 11:54:48,536 iteration 3506 : loss : 0.033142, loss_ce: 0.010938
2021-12-10 11:54:50,038 iteration 3507 : loss : 0.033739, loss_ce: 0.010598
2021-12-10 11:54:51,666 iteration 3508 : loss : 0.033012, loss_ce: 0.015323
2021-12-10 11:54:53,205 iteration 3509 : loss : 0.022339, loss_ce: 0.008904
2021-12-10 11:54:54,674 iteration 3510 : loss : 0.025828, loss_ce: 0.010521
2021-12-10 11:54:56,136 iteration 3511 : loss : 0.020494, loss_ce: 0.009673
2021-12-10 11:54:57,720 iteration 3512 : loss : 0.029634, loss_ce: 0.008710
2021-12-10 11:54:59,244 iteration 3513 : loss : 0.026969, loss_ce: 0.007345
2021-12-10 11:55:00,882 iteration 3514 : loss : 0.041353, loss_ce: 0.021253
2021-12-10 11:55:02,388 iteration 3515 : loss : 0.025495, loss_ce: 0.008549
2021-12-10 11:55:03,883 iteration 3516 : loss : 0.028276, loss_ce: 0.011580
2021-12-10 11:55:05,378 iteration 3517 : loss : 0.028844, loss_ce: 0.010858
2021-12-10 11:55:06,882 iteration 3518 : loss : 0.030920, loss_ce: 0.016982
2021-12-10 11:55:08,419 iteration 3519 : loss : 0.025866, loss_ce: 0.008092
 52%|█████████████▉             | 207/400 [1:39:19<1:29:59, 27.98s/it]2021-12-10 11:55:10,003 iteration 3520 : loss : 0.037955, loss_ce: 0.014299
2021-12-10 11:55:11,491 iteration 3521 : loss : 0.040579, loss_ce: 0.018465
2021-12-10 11:55:12,945 iteration 3522 : loss : 0.019259, loss_ce: 0.008750
2021-12-10 11:55:14,444 iteration 3523 : loss : 0.022498, loss_ce: 0.008359
2021-12-10 11:55:15,990 iteration 3524 : loss : 0.026623, loss_ce: 0.010651
2021-12-10 11:55:17,600 iteration 3525 : loss : 0.037001, loss_ce: 0.015635
2021-12-10 11:55:19,142 iteration 3526 : loss : 0.027571, loss_ce: 0.010377
2021-12-10 11:55:20,712 iteration 3527 : loss : 0.040145, loss_ce: 0.012982
2021-12-10 11:55:22,356 iteration 3528 : loss : 0.059903, loss_ce: 0.028928
2021-12-10 11:55:23,904 iteration 3529 : loss : 0.032827, loss_ce: 0.009633
2021-12-10 11:55:25,445 iteration 3530 : loss : 0.020869, loss_ce: 0.008499
2021-12-10 11:55:26,922 iteration 3531 : loss : 0.026224, loss_ce: 0.007301
2021-12-10 11:55:28,517 iteration 3532 : loss : 0.026956, loss_ce: 0.011248
2021-12-10 11:55:30,023 iteration 3533 : loss : 0.028129, loss_ce: 0.007671
2021-12-10 11:55:31,568 iteration 3534 : loss : 0.030234, loss_ce: 0.012154
2021-12-10 11:55:33,156 iteration 3535 : loss : 0.028928, loss_ce: 0.011451
2021-12-10 11:55:34,720 iteration 3536 : loss : 0.020592, loss_ce: 0.007916
 52%|██████████████             | 208/400 [1:39:46<1:27:54, 27.47s/it]2021-12-10 11:55:36,219 iteration 3537 : loss : 0.024527, loss_ce: 0.011071
2021-12-10 11:55:37,672 iteration 3538 : loss : 0.021001, loss_ce: 0.009198
2021-12-10 11:55:39,144 iteration 3539 : loss : 0.020871, loss_ce: 0.010139
2021-12-10 11:55:40,557 iteration 3540 : loss : 0.019941, loss_ce: 0.005999
2021-12-10 11:55:42,142 iteration 3541 : loss : 0.030327, loss_ce: 0.011446
2021-12-10 11:55:43,658 iteration 3542 : loss : 0.024290, loss_ce: 0.010665
2021-12-10 11:55:45,289 iteration 3543 : loss : 0.101559, loss_ce: 0.037219
2021-12-10 11:55:46,739 iteration 3544 : loss : 0.016666, loss_ce: 0.006829
2021-12-10 11:55:48,246 iteration 3545 : loss : 0.022341, loss_ce: 0.009885
2021-12-10 11:55:49,699 iteration 3546 : loss : 0.023842, loss_ce: 0.008647
2021-12-10 11:55:51,219 iteration 3547 : loss : 0.029709, loss_ce: 0.014537
2021-12-10 11:55:52,687 iteration 3548 : loss : 0.026417, loss_ce: 0.008871
2021-12-10 11:55:54,218 iteration 3549 : loss : 0.024890, loss_ce: 0.009321
2021-12-10 11:55:55,776 iteration 3550 : loss : 0.020338, loss_ce: 0.008916
2021-12-10 11:55:57,355 iteration 3551 : loss : 0.040871, loss_ce: 0.012321
2021-12-10 11:55:58,937 iteration 3552 : loss : 0.047578, loss_ce: 0.017292
2021-12-10 11:56:00,521 iteration 3553 : loss : 0.043501, loss_ce: 0.021126
 52%|██████████████             | 209/400 [1:40:11<1:25:51, 26.97s/it]2021-12-10 11:56:02,104 iteration 3554 : loss : 0.023482, loss_ce: 0.009540
2021-12-10 11:56:03,597 iteration 3555 : loss : 0.021802, loss_ce: 0.006921
2021-12-10 11:56:05,095 iteration 3556 : loss : 0.022564, loss_ce: 0.010169
2021-12-10 11:56:06,699 iteration 3557 : loss : 0.029245, loss_ce: 0.008817
2021-12-10 11:56:08,167 iteration 3558 : loss : 0.036123, loss_ce: 0.010628
2021-12-10 11:56:09,664 iteration 3559 : loss : 0.024466, loss_ce: 0.008137
2021-12-10 11:56:11,078 iteration 3560 : loss : 0.021985, loss_ce: 0.011003
2021-12-10 11:56:12,666 iteration 3561 : loss : 0.039742, loss_ce: 0.018891
2021-12-10 11:56:14,150 iteration 3562 : loss : 0.025856, loss_ce: 0.010898
2021-12-10 11:56:15,698 iteration 3563 : loss : 0.025996, loss_ce: 0.009526
2021-12-10 11:56:17,227 iteration 3564 : loss : 0.034386, loss_ce: 0.012347
2021-12-10 11:56:18,852 iteration 3565 : loss : 0.074338, loss_ce: 0.025101
2021-12-10 11:56:20,387 iteration 3566 : loss : 0.035167, loss_ce: 0.013315
2021-12-10 11:56:21,989 iteration 3567 : loss : 0.039142, loss_ce: 0.014779
2021-12-10 11:56:23,572 iteration 3568 : loss : 0.035074, loss_ce: 0.014179
2021-12-10 11:56:25,142 iteration 3569 : loss : 0.029108, loss_ce: 0.007195
2021-12-10 11:56:25,142 Training Data Eval:
2021-12-10 11:56:32,796   Average segmentation loss on training set: 0.0166
2021-12-10 11:56:32,797 Validation Data Eval:
2021-12-10 11:56:35,438   Average segmentation loss on validation set: 0.0717
2021-12-10 11:56:36,975 iteration 3570 : loss : 0.027390, loss_ce: 0.009782
 52%|██████████████▏            | 210/400 [1:40:48<1:34:25, 29.82s/it]2021-12-10 11:56:38,542 iteration 3571 : loss : 0.024849, loss_ce: 0.010016
2021-12-10 11:56:40,068 iteration 3572 : loss : 0.021499, loss_ce: 0.006166
2021-12-10 11:56:41,588 iteration 3573 : loss : 0.035177, loss_ce: 0.014259
2021-12-10 11:56:43,081 iteration 3574 : loss : 0.025203, loss_ce: 0.010403
2021-12-10 11:56:44,580 iteration 3575 : loss : 0.027715, loss_ce: 0.012150
2021-12-10 11:56:46,108 iteration 3576 : loss : 0.034564, loss_ce: 0.012172
2021-12-10 11:56:47,683 iteration 3577 : loss : 0.025171, loss_ce: 0.010051
2021-12-10 11:56:49,247 iteration 3578 : loss : 0.033894, loss_ce: 0.014558
2021-12-10 11:56:50,743 iteration 3579 : loss : 0.036960, loss_ce: 0.016960
2021-12-10 11:56:52,296 iteration 3580 : loss : 0.032126, loss_ce: 0.010019
2021-12-10 11:56:53,784 iteration 3581 : loss : 0.035187, loss_ce: 0.009208
2021-12-10 11:56:55,301 iteration 3582 : loss : 0.020925, loss_ce: 0.008233
2021-12-10 11:56:56,851 iteration 3583 : loss : 0.025451, loss_ce: 0.010274
2021-12-10 11:56:58,341 iteration 3584 : loss : 0.023814, loss_ce: 0.008847
2021-12-10 11:56:59,847 iteration 3585 : loss : 0.020320, loss_ce: 0.006702
2021-12-10 11:57:01,307 iteration 3586 : loss : 0.024522, loss_ce: 0.009276
2021-12-10 11:57:02,814 iteration 3587 : loss : 0.045582, loss_ce: 0.023269
 53%|██████████████▏            | 211/400 [1:41:14<1:30:10, 28.62s/it]2021-12-10 11:57:04,310 iteration 3588 : loss : 0.028025, loss_ce: 0.009197
2021-12-10 11:57:05,865 iteration 3589 : loss : 0.029916, loss_ce: 0.009927
2021-12-10 11:57:07,386 iteration 3590 : loss : 0.035233, loss_ce: 0.017107
2021-12-10 11:57:08,890 iteration 3591 : loss : 0.020830, loss_ce: 0.006817
2021-12-10 11:57:10,462 iteration 3592 : loss : 0.026276, loss_ce: 0.011118
2021-12-10 11:57:12,002 iteration 3593 : loss : 0.032471, loss_ce: 0.009845
2021-12-10 11:57:13,537 iteration 3594 : loss : 0.022171, loss_ce: 0.006325
2021-12-10 11:57:15,182 iteration 3595 : loss : 0.063780, loss_ce: 0.013449
2021-12-10 11:57:16,638 iteration 3596 : loss : 0.027702, loss_ce: 0.012773
2021-12-10 11:57:18,250 iteration 3597 : loss : 0.036789, loss_ce: 0.012369
2021-12-10 11:57:19,788 iteration 3598 : loss : 0.034544, loss_ce: 0.016207
2021-12-10 11:57:21,319 iteration 3599 : loss : 0.029088, loss_ce: 0.012172
2021-12-10 11:57:22,828 iteration 3600 : loss : 0.029071, loss_ce: 0.013207
2021-12-10 11:57:24,354 iteration 3601 : loss : 0.025557, loss_ce: 0.012292
2021-12-10 11:57:25,858 iteration 3602 : loss : 0.026897, loss_ce: 0.012264
2021-12-10 11:57:27,336 iteration 3603 : loss : 0.019878, loss_ce: 0.008518
2021-12-10 11:57:28,807 iteration 3604 : loss : 0.019176, loss_ce: 0.007576
 53%|██████████████▎            | 212/400 [1:41:40<1:27:13, 27.84s/it]2021-12-10 11:57:30,375 iteration 3605 : loss : 0.023118, loss_ce: 0.009241
2021-12-10 11:57:31,906 iteration 3606 : loss : 0.027483, loss_ce: 0.010571
2021-12-10 11:57:33,362 iteration 3607 : loss : 0.022292, loss_ce: 0.008055
2021-12-10 11:57:34,826 iteration 3608 : loss : 0.025075, loss_ce: 0.010348
2021-12-10 11:57:36,365 iteration 3609 : loss : 0.031668, loss_ce: 0.008960
2021-12-10 11:57:37,849 iteration 3610 : loss : 0.026185, loss_ce: 0.011698
2021-12-10 11:57:39,405 iteration 3611 : loss : 0.029918, loss_ce: 0.013416
2021-12-10 11:57:40,985 iteration 3612 : loss : 0.023405, loss_ce: 0.008399
2021-12-10 11:57:42,510 iteration 3613 : loss : 0.036117, loss_ce: 0.011369
2021-12-10 11:57:44,074 iteration 3614 : loss : 0.018781, loss_ce: 0.005640
2021-12-10 11:57:45,583 iteration 3615 : loss : 0.031102, loss_ce: 0.008760
2021-12-10 11:57:47,184 iteration 3616 : loss : 0.036759, loss_ce: 0.008822
2021-12-10 11:57:48,697 iteration 3617 : loss : 0.026965, loss_ce: 0.010592
2021-12-10 11:57:50,211 iteration 3618 : loss : 0.022932, loss_ce: 0.010014
2021-12-10 11:57:51,725 iteration 3619 : loss : 0.024022, loss_ce: 0.010586
2021-12-10 11:57:53,273 iteration 3620 : loss : 0.027341, loss_ce: 0.010054
2021-12-10 11:57:54,792 iteration 3621 : loss : 0.029231, loss_ce: 0.012731
 53%|██████████████▍            | 213/400 [1:42:06<1:25:01, 27.28s/it]2021-12-10 11:57:56,460 iteration 3622 : loss : 0.028797, loss_ce: 0.011215
2021-12-10 11:57:58,006 iteration 3623 : loss : 0.030485, loss_ce: 0.012982
2021-12-10 11:57:59,635 iteration 3624 : loss : 0.022759, loss_ce: 0.007300
2021-12-10 11:58:01,257 iteration 3625 : loss : 0.043602, loss_ce: 0.019408
2021-12-10 11:58:02,797 iteration 3626 : loss : 0.024018, loss_ce: 0.009861
2021-12-10 11:58:04,382 iteration 3627 : loss : 0.026537, loss_ce: 0.012816
2021-12-10 11:58:05,943 iteration 3628 : loss : 0.021881, loss_ce: 0.006825
2021-12-10 11:58:07,565 iteration 3629 : loss : 0.022439, loss_ce: 0.009251
2021-12-10 11:58:09,112 iteration 3630 : loss : 0.026576, loss_ce: 0.011079
2021-12-10 11:58:10,588 iteration 3631 : loss : 0.021146, loss_ce: 0.008528
2021-12-10 11:58:12,060 iteration 3632 : loss : 0.027839, loss_ce: 0.011531
2021-12-10 11:58:13,652 iteration 3633 : loss : 0.060759, loss_ce: 0.021211
2021-12-10 11:58:15,187 iteration 3634 : loss : 0.029237, loss_ce: 0.011476
2021-12-10 11:58:16,673 iteration 3635 : loss : 0.034991, loss_ce: 0.011446
2021-12-10 11:58:18,166 iteration 3636 : loss : 0.025879, loss_ce: 0.010934
2021-12-10 11:58:19,766 iteration 3637 : loss : 0.035060, loss_ce: 0.011064
2021-12-10 11:58:21,241 iteration 3638 : loss : 0.023306, loss_ce: 0.007752
 54%|██████████████▍            | 214/400 [1:42:32<1:23:47, 27.03s/it]2021-12-10 11:58:22,813 iteration 3639 : loss : 0.018980, loss_ce: 0.008549
2021-12-10 11:58:24,400 iteration 3640 : loss : 0.024900, loss_ce: 0.009071
2021-12-10 11:58:25,943 iteration 3641 : loss : 0.030517, loss_ce: 0.010822
2021-12-10 11:58:27,532 iteration 3642 : loss : 0.026282, loss_ce: 0.011097
2021-12-10 11:58:29,068 iteration 3643 : loss : 0.027825, loss_ce: 0.012636
2021-12-10 11:58:30,593 iteration 3644 : loss : 0.024519, loss_ce: 0.010976
2021-12-10 11:58:32,090 iteration 3645 : loss : 0.026332, loss_ce: 0.009683
2021-12-10 11:58:33,642 iteration 3646 : loss : 0.023924, loss_ce: 0.008894
2021-12-10 11:58:35,225 iteration 3647 : loss : 0.033787, loss_ce: 0.013487
2021-12-10 11:58:36,890 iteration 3648 : loss : 0.033703, loss_ce: 0.014571
2021-12-10 11:58:38,455 iteration 3649 : loss : 0.026333, loss_ce: 0.009416
2021-12-10 11:58:40,004 iteration 3650 : loss : 0.035670, loss_ce: 0.011991
2021-12-10 11:58:41,580 iteration 3651 : loss : 0.022820, loss_ce: 0.008583
2021-12-10 11:58:43,090 iteration 3652 : loss : 0.023952, loss_ce: 0.011249
2021-12-10 11:58:44,705 iteration 3653 : loss : 0.043287, loss_ce: 0.008089
2021-12-10 11:58:46,275 iteration 3654 : loss : 0.025540, loss_ce: 0.008002
2021-12-10 11:58:46,276 Training Data Eval:
2021-12-10 11:58:53,966   Average segmentation loss on training set: 0.0174
2021-12-10 11:58:53,966 Validation Data Eval:
2021-12-10 11:58:56,609   Average segmentation loss on validation set: 0.0695
2021-12-10 11:58:58,049 iteration 3655 : loss : 0.022976, loss_ce: 0.007618
 54%|██████████████▌            | 215/400 [1:43:09<1:32:23, 29.96s/it]2021-12-10 11:58:59,703 iteration 3656 : loss : 0.032631, loss_ce: 0.007179
2021-12-10 11:59:01,214 iteration 3657 : loss : 0.024381, loss_ce: 0.012006
2021-12-10 11:59:02,760 iteration 3658 : loss : 0.038233, loss_ce: 0.017051
2021-12-10 11:59:04,346 iteration 3659 : loss : 0.049116, loss_ce: 0.013196
2021-12-10 11:59:05,994 iteration 3660 : loss : 0.044069, loss_ce: 0.014123
2021-12-10 11:59:07,653 iteration 3661 : loss : 0.029785, loss_ce: 0.014862
2021-12-10 11:59:09,112 iteration 3662 : loss : 0.025588, loss_ce: 0.009225
2021-12-10 11:59:10,618 iteration 3663 : loss : 0.019058, loss_ce: 0.006223
2021-12-10 11:59:12,137 iteration 3664 : loss : 0.046549, loss_ce: 0.013567
2021-12-10 11:59:13,667 iteration 3665 : loss : 0.021195, loss_ce: 0.008900
2021-12-10 11:59:15,333 iteration 3666 : loss : 0.048772, loss_ce: 0.021515
2021-12-10 11:59:16,935 iteration 3667 : loss : 0.033968, loss_ce: 0.013190
2021-12-10 11:59:18,533 iteration 3668 : loss : 0.027033, loss_ce: 0.011160
2021-12-10 11:59:20,097 iteration 3669 : loss : 0.035806, loss_ce: 0.016014
2021-12-10 11:59:21,625 iteration 3670 : loss : 0.037431, loss_ce: 0.011949
2021-12-10 11:59:23,218 iteration 3671 : loss : 0.032745, loss_ce: 0.013557
2021-12-10 11:59:24,705 iteration 3672 : loss : 0.027182, loss_ce: 0.010789
 54%|██████████████▌            | 216/400 [1:43:36<1:28:50, 28.97s/it]2021-12-10 11:59:26,277 iteration 3673 : loss : 0.025048, loss_ce: 0.012175
2021-12-10 11:59:27,828 iteration 3674 : loss : 0.031928, loss_ce: 0.013434
2021-12-10 11:59:29,347 iteration 3675 : loss : 0.022314, loss_ce: 0.010808
2021-12-10 11:59:30,867 iteration 3676 : loss : 0.017519, loss_ce: 0.005637
2021-12-10 11:59:32,394 iteration 3677 : loss : 0.033555, loss_ce: 0.018372
2021-12-10 11:59:34,024 iteration 3678 : loss : 0.042948, loss_ce: 0.013728
2021-12-10 11:59:35,553 iteration 3679 : loss : 0.026567, loss_ce: 0.010251
2021-12-10 11:59:37,062 iteration 3680 : loss : 0.037034, loss_ce: 0.013111
2021-12-10 11:59:38,653 iteration 3681 : loss : 0.033425, loss_ce: 0.011140
2021-12-10 11:59:40,173 iteration 3682 : loss : 0.027853, loss_ce: 0.011089
2021-12-10 11:59:41,764 iteration 3683 : loss : 0.084371, loss_ce: 0.022374
2021-12-10 11:59:43,278 iteration 3684 : loss : 0.015902, loss_ce: 0.005140
2021-12-10 11:59:44,795 iteration 3685 : loss : 0.034466, loss_ce: 0.015002
2021-12-10 11:59:46,359 iteration 3686 : loss : 0.023622, loss_ce: 0.009011
2021-12-10 11:59:47,904 iteration 3687 : loss : 0.027651, loss_ce: 0.008321
2021-12-10 11:59:49,436 iteration 3688 : loss : 0.031816, loss_ce: 0.015347
2021-12-10 11:59:50,906 iteration 3689 : loss : 0.026700, loss_ce: 0.009712
 54%|██████████████▋            | 217/400 [1:44:02<1:25:50, 28.14s/it]2021-12-10 11:59:52,453 iteration 3690 : loss : 0.022389, loss_ce: 0.005291
2021-12-10 11:59:54,076 iteration 3691 : loss : 0.039705, loss_ce: 0.007551
2021-12-10 11:59:55,630 iteration 3692 : loss : 0.023418, loss_ce: 0.010248
2021-12-10 11:59:57,251 iteration 3693 : loss : 0.039111, loss_ce: 0.015028
2021-12-10 11:59:58,807 iteration 3694 : loss : 0.022604, loss_ce: 0.009487
2021-12-10 12:00:00,303 iteration 3695 : loss : 0.024114, loss_ce: 0.010014
2021-12-10 12:00:01,890 iteration 3696 : loss : 0.032488, loss_ce: 0.015901
2021-12-10 12:00:03,418 iteration 3697 : loss : 0.025278, loss_ce: 0.008992
2021-12-10 12:00:04,961 iteration 3698 : loss : 0.027638, loss_ce: 0.010687
2021-12-10 12:00:06,580 iteration 3699 : loss : 0.033691, loss_ce: 0.011665
2021-12-10 12:00:08,130 iteration 3700 : loss : 0.031911, loss_ce: 0.015369
2021-12-10 12:00:09,645 iteration 3701 : loss : 0.022768, loss_ce: 0.009195
2021-12-10 12:00:11,151 iteration 3702 : loss : 0.035256, loss_ce: 0.013023
2021-12-10 12:00:12,811 iteration 3703 : loss : 0.042422, loss_ce: 0.021300
2021-12-10 12:00:14,319 iteration 3704 : loss : 0.024246, loss_ce: 0.007275
2021-12-10 12:00:15,811 iteration 3705 : loss : 0.020010, loss_ce: 0.006759
2021-12-10 12:00:17,295 iteration 3706 : loss : 0.020983, loss_ce: 0.005535
 55%|██████████████▋            | 218/400 [1:44:28<1:23:44, 27.61s/it]2021-12-10 12:00:18,870 iteration 3707 : loss : 0.040568, loss_ce: 0.014444
2021-12-10 12:00:20,414 iteration 3708 : loss : 0.032430, loss_ce: 0.012941
2021-12-10 12:00:21,962 iteration 3709 : loss : 0.027983, loss_ce: 0.008768
2021-12-10 12:00:23,558 iteration 3710 : loss : 0.026135, loss_ce: 0.008316
2021-12-10 12:00:25,077 iteration 3711 : loss : 0.021795, loss_ce: 0.008324
2021-12-10 12:00:26,651 iteration 3712 : loss : 0.026210, loss_ce: 0.008828
2021-12-10 12:00:28,145 iteration 3713 : loss : 0.024312, loss_ce: 0.009099
2021-12-10 12:00:29,651 iteration 3714 : loss : 0.021244, loss_ce: 0.007722
2021-12-10 12:00:31,205 iteration 3715 : loss : 0.028092, loss_ce: 0.010908
2021-12-10 12:00:32,711 iteration 3716 : loss : 0.027147, loss_ce: 0.010862
2021-12-10 12:00:34,269 iteration 3717 : loss : 0.029984, loss_ce: 0.011809
2021-12-10 12:00:35,872 iteration 3718 : loss : 0.030547, loss_ce: 0.015333
2021-12-10 12:00:37,358 iteration 3719 : loss : 0.023252, loss_ce: 0.006287
2021-12-10 12:00:38,928 iteration 3720 : loss : 0.021541, loss_ce: 0.010792
2021-12-10 12:00:40,485 iteration 3721 : loss : 0.022896, loss_ce: 0.009909
2021-12-10 12:00:42,006 iteration 3722 : loss : 0.022427, loss_ce: 0.008724
2021-12-10 12:00:43,505 iteration 3723 : loss : 0.029250, loss_ce: 0.008173
 55%|██████████████▊            | 219/400 [1:44:54<1:22:02, 27.19s/it]2021-12-10 12:00:45,029 iteration 3724 : loss : 0.019121, loss_ce: 0.008609
2021-12-10 12:00:46,528 iteration 3725 : loss : 0.019249, loss_ce: 0.008284
2021-12-10 12:00:48,140 iteration 3726 : loss : 0.034178, loss_ce: 0.017826
2021-12-10 12:00:49,694 iteration 3727 : loss : 0.034255, loss_ce: 0.015674
2021-12-10 12:00:51,257 iteration 3728 : loss : 0.026959, loss_ce: 0.006990
2021-12-10 12:00:52,752 iteration 3729 : loss : 0.020773, loss_ce: 0.005711
2021-12-10 12:00:54,274 iteration 3730 : loss : 0.020600, loss_ce: 0.008213
2021-12-10 12:00:55,795 iteration 3731 : loss : 0.020528, loss_ce: 0.007629
2021-12-10 12:00:57,367 iteration 3732 : loss : 0.038040, loss_ce: 0.013259
2021-12-10 12:00:58,858 iteration 3733 : loss : 0.045607, loss_ce: 0.022271
2021-12-10 12:01:00,416 iteration 3734 : loss : 0.035777, loss_ce: 0.020438
2021-12-10 12:01:01,964 iteration 3735 : loss : 0.025508, loss_ce: 0.007448
2021-12-10 12:01:03,562 iteration 3736 : loss : 0.025872, loss_ce: 0.012123
2021-12-10 12:01:05,065 iteration 3737 : loss : 0.022621, loss_ce: 0.007643
2021-12-10 12:01:06,604 iteration 3738 : loss : 0.021874, loss_ce: 0.007629
2021-12-10 12:01:08,099 iteration 3739 : loss : 0.024798, loss_ce: 0.010845
2021-12-10 12:01:08,099 Training Data Eval:
2021-12-10 12:01:15,830   Average segmentation loss on training set: 0.0177
2021-12-10 12:01:15,831 Validation Data Eval:
2021-12-10 12:01:18,478   Average segmentation loss on validation set: 0.0661
2021-12-10 12:01:20,184 iteration 3740 : loss : 0.040049, loss_ce: 0.018899
 55%|██████████████▊            | 220/400 [1:45:31<1:30:06, 30.04s/it]2021-12-10 12:01:21,920 iteration 3741 : loss : 0.052774, loss_ce: 0.017609
2021-12-10 12:01:23,451 iteration 3742 : loss : 0.029911, loss_ce: 0.015055
2021-12-10 12:01:24,993 iteration 3743 : loss : 0.032056, loss_ce: 0.012236
2021-12-10 12:01:26,590 iteration 3744 : loss : 0.034464, loss_ce: 0.012508
2021-12-10 12:01:28,210 iteration 3745 : loss : 0.028120, loss_ce: 0.009457
2021-12-10 12:01:29,836 iteration 3746 : loss : 0.026489, loss_ce: 0.010375
2021-12-10 12:01:31,375 iteration 3747 : loss : 0.027690, loss_ce: 0.009131
2021-12-10 12:01:32,896 iteration 3748 : loss : 0.021397, loss_ce: 0.010487
2021-12-10 12:01:34,499 iteration 3749 : loss : 0.028049, loss_ce: 0.009916
2021-12-10 12:01:36,137 iteration 3750 : loss : 0.027633, loss_ce: 0.009297
2021-12-10 12:01:37,718 iteration 3751 : loss : 0.036868, loss_ce: 0.012610
2021-12-10 12:01:39,246 iteration 3752 : loss : 0.030423, loss_ce: 0.008585
2021-12-10 12:01:40,748 iteration 3753 : loss : 0.030722, loss_ce: 0.009287
2021-12-10 12:01:42,304 iteration 3754 : loss : 0.020123, loss_ce: 0.006795
2021-12-10 12:01:43,929 iteration 3755 : loss : 0.024361, loss_ce: 0.011427
2021-12-10 12:01:45,404 iteration 3756 : loss : 0.034306, loss_ce: 0.017444
2021-12-10 12:01:46,902 iteration 3757 : loss : 0.021469, loss_ce: 0.009430
 55%|██████████████▉            | 221/400 [1:45:58<1:26:39, 29.04s/it]2021-12-10 12:01:48,583 iteration 3758 : loss : 0.020978, loss_ce: 0.006957
2021-12-10 12:01:50,082 iteration 3759 : loss : 0.021983, loss_ce: 0.008030
2021-12-10 12:01:51,603 iteration 3760 : loss : 0.021900, loss_ce: 0.008944
2021-12-10 12:01:53,197 iteration 3761 : loss : 0.033329, loss_ce: 0.013158
2021-12-10 12:01:54,816 iteration 3762 : loss : 0.031162, loss_ce: 0.015696
2021-12-10 12:01:56,470 iteration 3763 : loss : 0.030746, loss_ce: 0.010524
2021-12-10 12:01:58,009 iteration 3764 : loss : 0.028179, loss_ce: 0.010472
2021-12-10 12:01:59,505 iteration 3765 : loss : 0.030055, loss_ce: 0.012098
2021-12-10 12:02:01,108 iteration 3766 : loss : 0.031803, loss_ce: 0.011994
2021-12-10 12:02:02,657 iteration 3767 : loss : 0.017728, loss_ce: 0.006652
2021-12-10 12:02:04,157 iteration 3768 : loss : 0.024439, loss_ce: 0.007550
2021-12-10 12:02:05,665 iteration 3769 : loss : 0.020919, loss_ce: 0.009279
2021-12-10 12:02:07,247 iteration 3770 : loss : 0.033340, loss_ce: 0.007406
2021-12-10 12:02:08,934 iteration 3771 : loss : 0.055288, loss_ce: 0.022906
2021-12-10 12:02:10,555 iteration 3772 : loss : 0.027591, loss_ce: 0.008282
2021-12-10 12:02:12,134 iteration 3773 : loss : 0.021088, loss_ce: 0.007923
2021-12-10 12:02:13,781 iteration 3774 : loss : 0.032961, loss_ce: 0.015618
 56%|██████████████▉            | 222/400 [1:46:25<1:24:13, 28.39s/it]2021-12-10 12:02:15,357 iteration 3775 : loss : 0.024022, loss_ce: 0.009787
2021-12-10 12:02:16,822 iteration 3776 : loss : 0.028277, loss_ce: 0.011976
2021-12-10 12:02:18,358 iteration 3777 : loss : 0.029443, loss_ce: 0.007372
2021-12-10 12:02:19,862 iteration 3778 : loss : 0.019435, loss_ce: 0.008341
2021-12-10 12:02:21,372 iteration 3779 : loss : 0.019600, loss_ce: 0.008962
2021-12-10 12:02:22,937 iteration 3780 : loss : 0.031045, loss_ce: 0.012051
2021-12-10 12:02:24,493 iteration 3781 : loss : 0.034783, loss_ce: 0.015273
2021-12-10 12:02:26,067 iteration 3782 : loss : 0.056527, loss_ce: 0.010237
2021-12-10 12:02:27,637 iteration 3783 : loss : 0.032797, loss_ce: 0.014417
2021-12-10 12:02:29,222 iteration 3784 : loss : 0.033873, loss_ce: 0.019108
2021-12-10 12:02:30,739 iteration 3785 : loss : 0.034103, loss_ce: 0.015148
2021-12-10 12:02:32,253 iteration 3786 : loss : 0.018243, loss_ce: 0.007244
2021-12-10 12:02:33,759 iteration 3787 : loss : 0.022755, loss_ce: 0.007490
2021-12-10 12:02:35,378 iteration 3788 : loss : 0.027753, loss_ce: 0.006939
2021-12-10 12:02:36,922 iteration 3789 : loss : 0.023101, loss_ce: 0.006056
2021-12-10 12:02:38,514 iteration 3790 : loss : 0.036997, loss_ce: 0.013896
2021-12-10 12:02:40,093 iteration 3791 : loss : 0.028622, loss_ce: 0.012994
 56%|███████████████            | 223/400 [1:46:51<1:21:55, 27.77s/it]2021-12-10 12:02:41,645 iteration 3792 : loss : 0.022146, loss_ce: 0.007323
2021-12-10 12:02:43,249 iteration 3793 : loss : 0.026598, loss_ce: 0.008675
2021-12-10 12:02:44,832 iteration 3794 : loss : 0.040260, loss_ce: 0.016022
2021-12-10 12:02:46,383 iteration 3795 : loss : 0.019412, loss_ce: 0.005915
2021-12-10 12:02:47,835 iteration 3796 : loss : 0.019985, loss_ce: 0.006572
2021-12-10 12:02:49,358 iteration 3797 : loss : 0.021492, loss_ce: 0.007690
2021-12-10 12:02:50,836 iteration 3798 : loss : 0.024022, loss_ce: 0.008573
2021-12-10 12:02:52,360 iteration 3799 : loss : 0.029786, loss_ce: 0.011454
2021-12-10 12:02:53,887 iteration 3800 : loss : 0.019033, loss_ce: 0.005290
2021-12-10 12:02:55,409 iteration 3801 : loss : 0.036656, loss_ce: 0.011762
2021-12-10 12:02:56,915 iteration 3802 : loss : 0.024216, loss_ce: 0.010417
2021-12-10 12:02:58,448 iteration 3803 : loss : 0.018830, loss_ce: 0.005923
2021-12-10 12:02:59,985 iteration 3804 : loss : 0.037744, loss_ce: 0.015997
2021-12-10 12:03:01,498 iteration 3805 : loss : 0.028315, loss_ce: 0.012717
2021-12-10 12:03:03,006 iteration 3806 : loss : 0.028499, loss_ce: 0.014275
2021-12-10 12:03:04,593 iteration 3807 : loss : 0.030212, loss_ce: 0.011032
2021-12-10 12:03:06,147 iteration 3808 : loss : 0.024641, loss_ce: 0.010152
 56%|███████████████            | 224/400 [1:47:17<1:19:56, 27.25s/it]2021-12-10 12:03:07,666 iteration 3809 : loss : 0.020143, loss_ce: 0.006842
2021-12-10 12:03:09,186 iteration 3810 : loss : 0.020177, loss_ce: 0.008072
2021-12-10 12:03:10,728 iteration 3811 : loss : 0.025679, loss_ce: 0.007194
2021-12-10 12:03:12,290 iteration 3812 : loss : 0.024651, loss_ce: 0.012563
2021-12-10 12:03:13,820 iteration 3813 : loss : 0.018726, loss_ce: 0.008579
2021-12-10 12:03:15,393 iteration 3814 : loss : 0.026247, loss_ce: 0.009220
2021-12-10 12:03:16,935 iteration 3815 : loss : 0.038908, loss_ce: 0.012650
2021-12-10 12:03:18,498 iteration 3816 : loss : 0.025681, loss_ce: 0.010455
2021-12-10 12:03:19,991 iteration 3817 : loss : 0.022192, loss_ce: 0.008040
2021-12-10 12:03:21,565 iteration 3818 : loss : 0.018868, loss_ce: 0.008744
2021-12-10 12:03:23,167 iteration 3819 : loss : 0.026489, loss_ce: 0.013093
2021-12-10 12:03:24,745 iteration 3820 : loss : 0.025374, loss_ce: 0.009899
2021-12-10 12:03:26,328 iteration 3821 : loss : 0.025925, loss_ce: 0.010239
2021-12-10 12:03:27,836 iteration 3822 : loss : 0.032946, loss_ce: 0.009295
2021-12-10 12:03:29,477 iteration 3823 : loss : 0.030670, loss_ce: 0.007917
2021-12-10 12:03:31,034 iteration 3824 : loss : 0.025941, loss_ce: 0.008863
2021-12-10 12:03:31,035 Training Data Eval:
2021-12-10 12:03:38,758   Average segmentation loss on training set: 0.0158
2021-12-10 12:03:38,759 Validation Data Eval:
2021-12-10 12:03:41,428   Average segmentation loss on validation set: 0.0727
2021-12-10 12:03:43,060 iteration 3825 : loss : 0.030162, loss_ce: 0.010331
 56%|███████████████▏           | 225/400 [1:47:54<1:27:56, 30.15s/it]2021-12-10 12:03:44,695 iteration 3826 : loss : 0.023312, loss_ce: 0.010313
2021-12-10 12:03:46,201 iteration 3827 : loss : 0.022375, loss_ce: 0.008166
2021-12-10 12:03:47,768 iteration 3828 : loss : 0.022544, loss_ce: 0.008153
2021-12-10 12:03:49,323 iteration 3829 : loss : 0.025828, loss_ce: 0.008542
2021-12-10 12:03:50,834 iteration 3830 : loss : 0.017538, loss_ce: 0.006426
2021-12-10 12:03:52,328 iteration 3831 : loss : 0.023509, loss_ce: 0.008802
2021-12-10 12:03:53,816 iteration 3832 : loss : 0.024330, loss_ce: 0.006616
2021-12-10 12:03:55,351 iteration 3833 : loss : 0.020980, loss_ce: 0.010375
2021-12-10 12:03:56,923 iteration 3834 : loss : 0.036691, loss_ce: 0.016535
2021-12-10 12:03:58,494 iteration 3835 : loss : 0.033727, loss_ce: 0.010907
2021-12-10 12:04:00,045 iteration 3836 : loss : 0.025943, loss_ce: 0.009788
2021-12-10 12:04:01,621 iteration 3837 : loss : 0.023970, loss_ce: 0.007931
2021-12-10 12:04:03,267 iteration 3838 : loss : 0.026537, loss_ce: 0.009198
2021-12-10 12:04:04,817 iteration 3839 : loss : 0.025125, loss_ce: 0.012557
2021-12-10 12:04:06,381 iteration 3840 : loss : 0.030962, loss_ce: 0.008801
2021-12-10 12:04:07,895 iteration 3841 : loss : 0.019403, loss_ce: 0.007822
2021-12-10 12:04:09,466 iteration 3842 : loss : 0.034280, loss_ce: 0.017535
 56%|███████████████▎           | 226/400 [1:48:20<1:24:11, 29.03s/it]2021-12-10 12:04:11,037 iteration 3843 : loss : 0.022704, loss_ce: 0.009007
2021-12-10 12:04:12,629 iteration 3844 : loss : 0.045923, loss_ce: 0.014701
2021-12-10 12:04:14,203 iteration 3845 : loss : 0.023112, loss_ce: 0.010783
2021-12-10 12:04:15,693 iteration 3846 : loss : 0.019260, loss_ce: 0.007093
2021-12-10 12:04:17,205 iteration 3847 : loss : 0.022640, loss_ce: 0.008417
2021-12-10 12:04:18,804 iteration 3848 : loss : 0.022662, loss_ce: 0.010787
2021-12-10 12:04:20,462 iteration 3849 : loss : 0.027140, loss_ce: 0.012588
2021-12-10 12:04:22,101 iteration 3850 : loss : 0.056176, loss_ce: 0.012954
2021-12-10 12:04:23,663 iteration 3851 : loss : 0.027980, loss_ce: 0.011323
2021-12-10 12:04:25,242 iteration 3852 : loss : 0.030478, loss_ce: 0.010277
2021-12-10 12:04:26,749 iteration 3853 : loss : 0.019788, loss_ce: 0.006473
2021-12-10 12:04:28,328 iteration 3854 : loss : 0.026643, loss_ce: 0.008255
2021-12-10 12:04:30,026 iteration 3855 : loss : 0.025583, loss_ce: 0.011193
2021-12-10 12:04:31,445 iteration 3856 : loss : 0.020168, loss_ce: 0.008888
2021-12-10 12:04:32,971 iteration 3857 : loss : 0.039098, loss_ce: 0.023130
2021-12-10 12:04:34,417 iteration 3858 : loss : 0.021877, loss_ce: 0.008762
2021-12-10 12:04:35,957 iteration 3859 : loss : 0.026631, loss_ce: 0.013071
 57%|███████████████▎           | 227/400 [1:48:47<1:21:30, 28.27s/it]2021-12-10 12:04:37,560 iteration 3860 : loss : 0.023681, loss_ce: 0.009080
2021-12-10 12:04:39,188 iteration 3861 : loss : 0.066003, loss_ce: 0.031968
2021-12-10 12:04:40,764 iteration 3862 : loss : 0.042350, loss_ce: 0.017919
2021-12-10 12:04:42,337 iteration 3863 : loss : 0.023221, loss_ce: 0.008666
2021-12-10 12:04:43,932 iteration 3864 : loss : 0.034433, loss_ce: 0.011826
2021-12-10 12:04:45,476 iteration 3865 : loss : 0.021583, loss_ce: 0.007132
2021-12-10 12:04:47,146 iteration 3866 : loss : 0.031546, loss_ce: 0.009151
2021-12-10 12:04:48,686 iteration 3867 : loss : 0.035918, loss_ce: 0.013092
2021-12-10 12:04:50,292 iteration 3868 : loss : 0.086192, loss_ce: 0.030555
2021-12-10 12:04:51,880 iteration 3869 : loss : 0.027156, loss_ce: 0.012225
2021-12-10 12:04:53,493 iteration 3870 : loss : 0.030569, loss_ce: 0.011689
2021-12-10 12:04:55,072 iteration 3871 : loss : 0.028955, loss_ce: 0.009170
2021-12-10 12:04:56,589 iteration 3872 : loss : 0.029475, loss_ce: 0.009838
2021-12-10 12:04:58,102 iteration 3873 : loss : 0.023808, loss_ce: 0.012303
2021-12-10 12:04:59,676 iteration 3874 : loss : 0.026692, loss_ce: 0.011401
2021-12-10 12:05:01,242 iteration 3875 : loss : 0.029556, loss_ce: 0.012279
2021-12-10 12:05:02,822 iteration 3876 : loss : 0.031463, loss_ce: 0.010690
 57%|███████████████▍           | 228/400 [1:49:14<1:19:49, 27.85s/it]2021-12-10 12:05:04,403 iteration 3877 : loss : 0.029696, loss_ce: 0.011816
2021-12-10 12:05:05,987 iteration 3878 : loss : 0.030395, loss_ce: 0.012433
2021-12-10 12:05:07,515 iteration 3879 : loss : 0.024054, loss_ce: 0.008563
2021-12-10 12:05:09,106 iteration 3880 : loss : 0.027443, loss_ce: 0.011864
2021-12-10 12:05:10,629 iteration 3881 : loss : 0.022328, loss_ce: 0.009937
2021-12-10 12:05:12,279 iteration 3882 : loss : 0.036286, loss_ce: 0.011074
2021-12-10 12:05:13,890 iteration 3883 : loss : 0.037145, loss_ce: 0.013044
2021-12-10 12:05:15,464 iteration 3884 : loss : 0.025047, loss_ce: 0.009318
2021-12-10 12:05:17,072 iteration 3885 : loss : 0.045149, loss_ce: 0.011745
2021-12-10 12:05:18,672 iteration 3886 : loss : 0.041245, loss_ce: 0.018896
2021-12-10 12:05:20,175 iteration 3887 : loss : 0.023063, loss_ce: 0.009076
2021-12-10 12:05:21,769 iteration 3888 : loss : 0.044420, loss_ce: 0.020956
2021-12-10 12:05:23,336 iteration 3889 : loss : 0.021850, loss_ce: 0.008616
2021-12-10 12:05:25,009 iteration 3890 : loss : 0.028360, loss_ce: 0.008607
2021-12-10 12:05:26,538 iteration 3891 : loss : 0.030333, loss_ce: 0.012053
2021-12-10 12:05:28,104 iteration 3892 : loss : 0.028145, loss_ce: 0.011800
2021-12-10 12:05:29,695 iteration 3893 : loss : 0.039087, loss_ce: 0.013640
 57%|███████████████▍           | 229/400 [1:49:41<1:18:31, 27.55s/it]2021-12-10 12:05:31,289 iteration 3894 : loss : 0.019127, loss_ce: 0.005427
2021-12-10 12:05:32,801 iteration 3895 : loss : 0.019835, loss_ce: 0.007478
2021-12-10 12:05:34,348 iteration 3896 : loss : 0.036871, loss_ce: 0.015717
2021-12-10 12:05:35,945 iteration 3897 : loss : 0.028156, loss_ce: 0.011599
2021-12-10 12:05:37,536 iteration 3898 : loss : 0.033582, loss_ce: 0.012058
2021-12-10 12:05:39,018 iteration 3899 : loss : 0.025463, loss_ce: 0.008905
2021-12-10 12:05:40,539 iteration 3900 : loss : 0.025447, loss_ce: 0.009788
2021-12-10 12:05:42,039 iteration 3901 : loss : 0.024300, loss_ce: 0.009491
2021-12-10 12:05:43,547 iteration 3902 : loss : 0.026667, loss_ce: 0.010323
2021-12-10 12:05:45,017 iteration 3903 : loss : 0.025581, loss_ce: 0.007366
2021-12-10 12:05:46,545 iteration 3904 : loss : 0.022161, loss_ce: 0.007172
2021-12-10 12:05:48,081 iteration 3905 : loss : 0.029663, loss_ce: 0.010235
2021-12-10 12:05:49,542 iteration 3906 : loss : 0.016350, loss_ce: 0.006684
2021-12-10 12:05:50,987 iteration 3907 : loss : 0.016948, loss_ce: 0.006242
2021-12-10 12:05:52,448 iteration 3908 : loss : 0.021678, loss_ce: 0.007728
2021-12-10 12:05:53,983 iteration 3909 : loss : 0.039940, loss_ce: 0.025873
2021-12-10 12:05:53,984 Training Data Eval:
2021-12-10 12:06:01,724   Average segmentation loss on training set: 0.0154
2021-12-10 12:06:01,724 Validation Data Eval:
2021-12-10 12:06:04,374   Average segmentation loss on validation set: 0.0899
2021-12-10 12:06:05,993 iteration 3910 : loss : 0.026736, loss_ce: 0.010223
 57%|███████████████▌           | 230/400 [1:50:17<1:25:30, 30.18s/it]2021-12-10 12:06:07,546 iteration 3911 : loss : 0.019912, loss_ce: 0.008647
2021-12-10 12:06:09,126 iteration 3912 : loss : 0.022900, loss_ce: 0.008366
2021-12-10 12:06:10,661 iteration 3913 : loss : 0.043184, loss_ce: 0.020537
2021-12-10 12:06:12,189 iteration 3914 : loss : 0.028818, loss_ce: 0.014851
2021-12-10 12:06:13,724 iteration 3915 : loss : 0.022800, loss_ce: 0.009719
2021-12-10 12:06:15,221 iteration 3916 : loss : 0.022996, loss_ce: 0.008625
2021-12-10 12:06:16,800 iteration 3917 : loss : 0.027593, loss_ce: 0.010780
2021-12-10 12:06:18,376 iteration 3918 : loss : 0.045511, loss_ce: 0.015301
2021-12-10 12:06:20,056 iteration 3919 : loss : 0.031761, loss_ce: 0.009572
2021-12-10 12:06:21,560 iteration 3920 : loss : 0.024030, loss_ce: 0.009936
2021-12-10 12:06:23,103 iteration 3921 : loss : 0.034310, loss_ce: 0.014515
2021-12-10 12:06:24,695 iteration 3922 : loss : 0.036652, loss_ce: 0.012793
2021-12-10 12:06:26,218 iteration 3923 : loss : 0.027534, loss_ce: 0.012067
2021-12-10 12:06:27,706 iteration 3924 : loss : 0.028345, loss_ce: 0.006731
2021-12-10 12:06:29,329 iteration 3925 : loss : 0.030608, loss_ce: 0.011474
2021-12-10 12:06:30,934 iteration 3926 : loss : 0.023562, loss_ce: 0.008626
2021-12-10 12:06:32,478 iteration 3927 : loss : 0.027387, loss_ce: 0.010013
 58%|███████████████▌           | 231/400 [1:50:43<1:21:52, 29.07s/it]2021-12-10 12:06:34,127 iteration 3928 : loss : 0.050786, loss_ce: 0.021114
2021-12-10 12:06:35,685 iteration 3929 : loss : 0.027734, loss_ce: 0.014674
2021-12-10 12:06:37,297 iteration 3930 : loss : 0.034413, loss_ce: 0.015022
2021-12-10 12:06:38,895 iteration 3931 : loss : 0.027896, loss_ce: 0.011149
2021-12-10 12:06:40,486 iteration 3932 : loss : 0.051079, loss_ce: 0.014734
2021-12-10 12:06:42,124 iteration 3933 : loss : 0.031491, loss_ce: 0.013667
2021-12-10 12:06:43,716 iteration 3934 : loss : 0.019170, loss_ce: 0.007582
2021-12-10 12:06:45,192 iteration 3935 : loss : 0.022104, loss_ce: 0.008947
2021-12-10 12:06:46,885 iteration 3936 : loss : 0.036116, loss_ce: 0.015745
2021-12-10 12:06:48,392 iteration 3937 : loss : 0.025890, loss_ce: 0.011483
2021-12-10 12:06:50,003 iteration 3938 : loss : 0.072380, loss_ce: 0.013520
2021-12-10 12:06:51,479 iteration 3939 : loss : 0.034395, loss_ce: 0.012250
2021-12-10 12:06:53,001 iteration 3940 : loss : 0.022893, loss_ce: 0.008039
2021-12-10 12:06:54,546 iteration 3941 : loss : 0.022846, loss_ce: 0.009060
2021-12-10 12:06:56,154 iteration 3942 : loss : 0.051836, loss_ce: 0.022046
2021-12-10 12:06:57,662 iteration 3943 : loss : 0.026501, loss_ce: 0.008215
2021-12-10 12:06:59,279 iteration 3944 : loss : 0.027548, loss_ce: 0.010314
 58%|███████████████▋           | 232/400 [1:51:10<1:19:28, 28.39s/it]2021-12-10 12:07:00,895 iteration 3945 : loss : 0.032993, loss_ce: 0.016079
2021-12-10 12:07:02,347 iteration 3946 : loss : 0.022287, loss_ce: 0.011344
2021-12-10 12:07:03,882 iteration 3947 : loss : 0.026757, loss_ce: 0.008072
2021-12-10 12:07:05,573 iteration 3948 : loss : 0.039742, loss_ce: 0.012793
2021-12-10 12:07:07,171 iteration 3949 : loss : 0.052301, loss_ce: 0.023088
2021-12-10 12:07:08,804 iteration 3950 : loss : 0.025535, loss_ce: 0.007740
2021-12-10 12:07:10,289 iteration 3951 : loss : 0.026496, loss_ce: 0.011732
2021-12-10 12:07:11,881 iteration 3952 : loss : 0.026485, loss_ce: 0.009627
2021-12-10 12:07:13,500 iteration 3953 : loss : 0.033399, loss_ce: 0.012447
2021-12-10 12:07:15,045 iteration 3954 : loss : 0.028572, loss_ce: 0.009770
2021-12-10 12:07:16,581 iteration 3955 : loss : 0.017149, loss_ce: 0.006274
2021-12-10 12:07:18,269 iteration 3956 : loss : 0.043048, loss_ce: 0.019612
2021-12-10 12:07:19,781 iteration 3957 : loss : 0.023976, loss_ce: 0.010165
2021-12-10 12:07:21,297 iteration 3958 : loss : 0.024209, loss_ce: 0.009323
2021-12-10 12:07:22,935 iteration 3959 : loss : 0.033834, loss_ce: 0.010876
2021-12-10 12:07:24,464 iteration 3960 : loss : 0.021596, loss_ce: 0.010246
2021-12-10 12:07:26,016 iteration 3961 : loss : 0.021519, loss_ce: 0.007694
 58%|███████████████▋           | 233/400 [1:51:37<1:17:37, 27.89s/it]2021-12-10 12:07:27,643 iteration 3962 : loss : 0.029226, loss_ce: 0.011347
2021-12-10 12:07:29,194 iteration 3963 : loss : 0.030274, loss_ce: 0.013285
2021-12-10 12:07:30,844 iteration 3964 : loss : 0.028254, loss_ce: 0.012314
2021-12-10 12:07:32,350 iteration 3965 : loss : 0.020087, loss_ce: 0.005786
2021-12-10 12:07:33,954 iteration 3966 : loss : 0.045226, loss_ce: 0.014429
2021-12-10 12:07:35,508 iteration 3967 : loss : 0.025748, loss_ce: 0.009834
2021-12-10 12:07:36,953 iteration 3968 : loss : 0.033347, loss_ce: 0.008798
2021-12-10 12:07:38,516 iteration 3969 : loss : 0.030911, loss_ce: 0.009169
2021-12-10 12:07:40,048 iteration 3970 : loss : 0.027272, loss_ce: 0.009646
2021-12-10 12:07:41,494 iteration 3971 : loss : 0.018076, loss_ce: 0.007079
2021-12-10 12:07:43,070 iteration 3972 : loss : 0.027520, loss_ce: 0.007223
2021-12-10 12:07:44,566 iteration 3973 : loss : 0.034131, loss_ce: 0.016734
2021-12-10 12:07:46,024 iteration 3974 : loss : 0.020796, loss_ce: 0.006617
2021-12-10 12:07:47,584 iteration 3975 : loss : 0.020361, loss_ce: 0.007711
2021-12-10 12:07:49,205 iteration 3976 : loss : 0.032153, loss_ce: 0.013436
2021-12-10 12:07:50,815 iteration 3977 : loss : 0.031920, loss_ce: 0.014021
2021-12-10 12:07:52,453 iteration 3978 : loss : 0.032631, loss_ce: 0.011778
 58%|███████████████▊           | 234/400 [1:52:03<1:15:57, 27.46s/it]2021-12-10 12:07:54,053 iteration 3979 : loss : 0.027332, loss_ce: 0.010711
2021-12-10 12:07:55,642 iteration 3980 : loss : 0.033161, loss_ce: 0.010658
2021-12-10 12:07:57,176 iteration 3981 : loss : 0.023889, loss_ce: 0.008899
2021-12-10 12:07:58,618 iteration 3982 : loss : 0.019038, loss_ce: 0.006859
2021-12-10 12:08:00,085 iteration 3983 : loss : 0.019292, loss_ce: 0.008651
2021-12-10 12:08:01,589 iteration 3984 : loss : 0.019443, loss_ce: 0.007995
2021-12-10 12:08:03,157 iteration 3985 : loss : 0.030940, loss_ce: 0.017327
2021-12-10 12:08:04,796 iteration 3986 : loss : 0.028808, loss_ce: 0.012500
2021-12-10 12:08:06,377 iteration 3987 : loss : 0.029060, loss_ce: 0.011630
2021-12-10 12:08:07,924 iteration 3988 : loss : 0.031619, loss_ce: 0.015911
2021-12-10 12:08:09,442 iteration 3989 : loss : 0.029538, loss_ce: 0.006294
2021-12-10 12:08:10,960 iteration 3990 : loss : 0.038917, loss_ce: 0.014189
2021-12-10 12:08:12,570 iteration 3991 : loss : 0.031954, loss_ce: 0.006868
2021-12-10 12:08:14,141 iteration 3992 : loss : 0.026677, loss_ce: 0.008146
2021-12-10 12:08:15,746 iteration 3993 : loss : 0.027245, loss_ce: 0.009739
2021-12-10 12:08:17,272 iteration 3994 : loss : 0.022241, loss_ce: 0.011350
2021-12-10 12:08:17,273 Training Data Eval:
2021-12-10 12:08:25,002   Average segmentation loss on training set: 0.0159
2021-12-10 12:08:25,002 Validation Data Eval:
2021-12-10 12:08:27,667   Average segmentation loss on validation set: 0.0802
2021-12-10 12:08:29,160 iteration 3995 : loss : 0.020962, loss_ce: 0.008874
 59%|███████████████▊           | 235/400 [1:52:40<1:23:08, 30.23s/it]2021-12-10 12:08:30,822 iteration 3996 : loss : 0.023603, loss_ce: 0.006944
2021-12-10 12:08:32,307 iteration 3997 : loss : 0.041008, loss_ce: 0.011766
2021-12-10 12:08:33,875 iteration 3998 : loss : 0.030453, loss_ce: 0.013361
2021-12-10 12:08:35,403 iteration 3999 : loss : 0.036067, loss_ce: 0.017572
2021-12-10 12:08:37,008 iteration 4000 : loss : 0.024436, loss_ce: 0.012435
2021-12-10 12:08:38,485 iteration 4001 : loss : 0.020845, loss_ce: 0.007813
2021-12-10 12:08:40,041 iteration 4002 : loss : 0.019598, loss_ce: 0.008390
2021-12-10 12:08:41,601 iteration 4003 : loss : 0.027937, loss_ce: 0.012644
2021-12-10 12:08:43,188 iteration 4004 : loss : 0.039506, loss_ce: 0.009341
2021-12-10 12:08:44,741 iteration 4005 : loss : 0.027849, loss_ce: 0.012724
2021-12-10 12:08:46,231 iteration 4006 : loss : 0.024733, loss_ce: 0.010411
2021-12-10 12:08:47,830 iteration 4007 : loss : 0.027860, loss_ce: 0.009899
2021-12-10 12:08:49,342 iteration 4008 : loss : 0.027745, loss_ce: 0.011745
2021-12-10 12:08:50,882 iteration 4009 : loss : 0.037980, loss_ce: 0.017605
2021-12-10 12:08:52,497 iteration 4010 : loss : 0.035431, loss_ce: 0.016149
2021-12-10 12:08:53,989 iteration 4011 : loss : 0.027838, loss_ce: 0.008768
2021-12-10 12:08:55,612 iteration 4012 : loss : 0.027271, loss_ce: 0.011032
 59%|███████████████▉           | 236/400 [1:53:07<1:19:32, 29.10s/it]2021-12-10 12:08:57,296 iteration 4013 : loss : 0.040666, loss_ce: 0.013998
2021-12-10 12:08:58,789 iteration 4014 : loss : 0.020987, loss_ce: 0.006988
2021-12-10 12:09:00,379 iteration 4015 : loss : 0.035628, loss_ce: 0.014659
2021-12-10 12:09:01,968 iteration 4016 : loss : 0.019587, loss_ce: 0.006851
2021-12-10 12:09:03,578 iteration 4017 : loss : 0.028976, loss_ce: 0.010198
2021-12-10 12:09:05,083 iteration 4018 : loss : 0.024326, loss_ce: 0.008528
2021-12-10 12:09:06,628 iteration 4019 : loss : 0.030265, loss_ce: 0.014972
2021-12-10 12:09:08,126 iteration 4020 : loss : 0.022180, loss_ce: 0.012384
2021-12-10 12:09:09,642 iteration 4021 : loss : 0.022888, loss_ce: 0.009997
2021-12-10 12:09:11,223 iteration 4022 : loss : 0.026939, loss_ce: 0.013555
2021-12-10 12:09:12,773 iteration 4023 : loss : 0.021193, loss_ce: 0.007093
2021-12-10 12:09:14,248 iteration 4024 : loss : 0.022563, loss_ce: 0.008334
2021-12-10 12:09:15,748 iteration 4025 : loss : 0.018886, loss_ce: 0.006318
2021-12-10 12:09:17,328 iteration 4026 : loss : 0.024493, loss_ce: 0.010038
2021-12-10 12:09:18,900 iteration 4027 : loss : 0.030769, loss_ce: 0.009575
2021-12-10 12:09:20,509 iteration 4028 : loss : 0.031838, loss_ce: 0.010268
2021-12-10 12:09:22,008 iteration 4029 : loss : 0.020985, loss_ce: 0.008672
 59%|███████████████▉           | 237/400 [1:53:33<1:16:50, 28.29s/it]2021-12-10 12:09:23,670 iteration 4030 : loss : 0.031935, loss_ce: 0.013090
2021-12-10 12:09:25,242 iteration 4031 : loss : 0.035342, loss_ce: 0.012497
2021-12-10 12:09:26,785 iteration 4032 : loss : 0.027577, loss_ce: 0.011906
2021-12-10 12:09:28,330 iteration 4033 : loss : 0.029172, loss_ce: 0.009554
2021-12-10 12:09:29,814 iteration 4034 : loss : 0.029605, loss_ce: 0.009159
2021-12-10 12:09:31,341 iteration 4035 : loss : 0.017719, loss_ce: 0.005358
2021-12-10 12:09:32,927 iteration 4036 : loss : 0.035672, loss_ce: 0.012526
2021-12-10 12:09:34,418 iteration 4037 : loss : 0.019187, loss_ce: 0.009013
2021-12-10 12:09:36,032 iteration 4038 : loss : 0.026928, loss_ce: 0.009750
2021-12-10 12:09:37,679 iteration 4039 : loss : 0.034629, loss_ce: 0.012406
2021-12-10 12:09:39,326 iteration 4040 : loss : 0.027415, loss_ce: 0.012180
2021-12-10 12:09:40,950 iteration 4041 : loss : 0.022223, loss_ce: 0.006862
2021-12-10 12:09:42,467 iteration 4042 : loss : 0.025791, loss_ce: 0.009420
2021-12-10 12:09:44,032 iteration 4043 : loss : 0.179265, loss_ce: 0.007708
2021-12-10 12:09:45,548 iteration 4044 : loss : 0.023637, loss_ce: 0.009020
2021-12-10 12:09:47,077 iteration 4045 : loss : 0.021565, loss_ce: 0.009574
2021-12-10 12:09:48,682 iteration 4046 : loss : 0.024717, loss_ce: 0.011430
 60%|████████████████           | 238/400 [1:54:00<1:15:03, 27.80s/it]2021-12-10 12:09:50,366 iteration 4047 : loss : 0.028092, loss_ce: 0.015183
2021-12-10 12:09:51,972 iteration 4048 : loss : 0.030955, loss_ce: 0.012032
2021-12-10 12:09:53,491 iteration 4049 : loss : 0.023334, loss_ce: 0.008284
2021-12-10 12:09:55,073 iteration 4050 : loss : 0.016230, loss_ce: 0.005915
2021-12-10 12:09:56,745 iteration 4051 : loss : 0.043440, loss_ce: 0.007960
2021-12-10 12:09:58,228 iteration 4052 : loss : 0.023279, loss_ce: 0.008698
2021-12-10 12:09:59,685 iteration 4053 : loss : 0.021493, loss_ce: 0.007183
2021-12-10 12:10:01,183 iteration 4054 : loss : 0.027587, loss_ce: 0.007140
2021-12-10 12:10:02,717 iteration 4055 : loss : 0.021716, loss_ce: 0.009335
2021-12-10 12:10:04,278 iteration 4056 : loss : 0.034170, loss_ce: 0.018693
2021-12-10 12:10:05,777 iteration 4057 : loss : 0.020889, loss_ce: 0.005198
2021-12-10 12:10:07,304 iteration 4058 : loss : 0.017547, loss_ce: 0.006709
2021-12-10 12:10:08,951 iteration 4059 : loss : 0.038444, loss_ce: 0.017221
2021-12-10 12:10:10,510 iteration 4060 : loss : 0.035030, loss_ce: 0.020130
2021-12-10 12:10:12,058 iteration 4061 : loss : 0.029422, loss_ce: 0.012820
2021-12-10 12:10:13,637 iteration 4062 : loss : 0.038823, loss_ce: 0.015918
2021-12-10 12:10:15,207 iteration 4063 : loss : 0.031551, loss_ce: 0.009753
 60%|████████████████▏          | 239/400 [1:54:26<1:13:33, 27.42s/it]2021-12-10 12:10:16,770 iteration 4064 : loss : 0.025331, loss_ce: 0.006264
2021-12-10 12:10:18,286 iteration 4065 : loss : 0.017802, loss_ce: 0.006308
2021-12-10 12:10:19,897 iteration 4066 : loss : 0.040953, loss_ce: 0.015757
2021-12-10 12:10:21,410 iteration 4067 : loss : 0.025960, loss_ce: 0.011774
2021-12-10 12:10:22,950 iteration 4068 : loss : 0.026063, loss_ce: 0.009543
2021-12-10 12:10:24,529 iteration 4069 : loss : 0.025863, loss_ce: 0.011034
2021-12-10 12:10:26,098 iteration 4070 : loss : 0.024192, loss_ce: 0.010530
2021-12-10 12:10:27,705 iteration 4071 : loss : 0.050272, loss_ce: 0.018206
2021-12-10 12:10:29,244 iteration 4072 : loss : 0.019186, loss_ce: 0.005951
2021-12-10 12:10:30,755 iteration 4073 : loss : 0.020993, loss_ce: 0.007267
2021-12-10 12:10:32,303 iteration 4074 : loss : 0.021921, loss_ce: 0.009712
2021-12-10 12:10:33,895 iteration 4075 : loss : 0.019829, loss_ce: 0.006746
2021-12-10 12:10:35,391 iteration 4076 : loss : 0.025682, loss_ce: 0.010497
2021-12-10 12:10:36,922 iteration 4077 : loss : 0.021832, loss_ce: 0.007801
2021-12-10 12:10:38,529 iteration 4078 : loss : 0.055100, loss_ce: 0.023076
2021-12-10 12:10:40,115 iteration 4079 : loss : 0.027878, loss_ce: 0.013337
2021-12-10 12:10:40,115 Training Data Eval:
2021-12-10 12:10:47,850   Average segmentation loss on training set: 0.0159
2021-12-10 12:10:47,850 Validation Data Eval:
2021-12-10 12:10:50,498   Average segmentation loss on validation set: 0.0641
2021-12-10 12:10:56,333 Found new lowest validation loss at iteration 4079! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 12:10:57,971 iteration 4080 : loss : 0.037337, loss_ce: 0.015576
 60%|████████████████▏          | 240/400 [1:55:09<1:25:23, 32.02s/it]2021-12-10 12:10:59,587 iteration 4081 : loss : 0.033449, loss_ce: 0.013253
2021-12-10 12:11:01,143 iteration 4082 : loss : 0.021063, loss_ce: 0.008498
2021-12-10 12:11:02,636 iteration 4083 : loss : 0.019528, loss_ce: 0.007708
2021-12-10 12:11:04,172 iteration 4084 : loss : 0.023522, loss_ce: 0.007152
2021-12-10 12:11:05,664 iteration 4085 : loss : 0.025362, loss_ce: 0.007879
2021-12-10 12:11:07,332 iteration 4086 : loss : 0.047708, loss_ce: 0.016768
2021-12-10 12:11:08,896 iteration 4087 : loss : 0.068057, loss_ce: 0.010537
2021-12-10 12:11:10,366 iteration 4088 : loss : 0.020499, loss_ce: 0.010154
2021-12-10 12:11:11,906 iteration 4089 : loss : 0.028146, loss_ce: 0.009259
2021-12-10 12:11:13,354 iteration 4090 : loss : 0.022537, loss_ce: 0.007349
2021-12-10 12:11:14,881 iteration 4091 : loss : 0.046047, loss_ce: 0.017547
2021-12-10 12:11:16,435 iteration 4092 : loss : 0.028382, loss_ce: 0.011809
2021-12-10 12:11:17,988 iteration 4093 : loss : 0.049140, loss_ce: 0.015757
2021-12-10 12:11:19,499 iteration 4094 : loss : 0.026681, loss_ce: 0.009623
2021-12-10 12:11:21,053 iteration 4095 : loss : 0.025752, loss_ce: 0.011725
2021-12-10 12:11:22,557 iteration 4096 : loss : 0.020448, loss_ce: 0.011001
2021-12-10 12:11:24,079 iteration 4097 : loss : 0.024511, loss_ce: 0.008801
 60%|████████████████▎          | 241/400 [1:55:35<1:20:09, 30.25s/it]2021-12-10 12:11:25,635 iteration 4098 : loss : 0.037246, loss_ce: 0.016788
2021-12-10 12:11:27,144 iteration 4099 : loss : 0.030065, loss_ce: 0.008212
2021-12-10 12:11:28,693 iteration 4100 : loss : 0.030019, loss_ce: 0.010010
2021-12-10 12:11:30,281 iteration 4101 : loss : 0.036837, loss_ce: 0.013406
2021-12-10 12:11:31,866 iteration 4102 : loss : 0.029211, loss_ce: 0.011683
2021-12-10 12:11:33,435 iteration 4103 : loss : 0.039443, loss_ce: 0.017500
2021-12-10 12:11:34,985 iteration 4104 : loss : 0.028674, loss_ce: 0.011891
2021-12-10 12:11:36,550 iteration 4105 : loss : 0.023150, loss_ce: 0.010192
2021-12-10 12:11:38,081 iteration 4106 : loss : 0.026125, loss_ce: 0.010078
2021-12-10 12:11:39,604 iteration 4107 : loss : 0.020542, loss_ce: 0.007958
2021-12-10 12:11:41,151 iteration 4108 : loss : 0.022150, loss_ce: 0.009063
2021-12-10 12:11:42,638 iteration 4109 : loss : 0.019412, loss_ce: 0.006845
2021-12-10 12:11:44,220 iteration 4110 : loss : 0.029658, loss_ce: 0.014364
2021-12-10 12:11:45,930 iteration 4111 : loss : 0.037312, loss_ce: 0.019058
2021-12-10 12:11:47,444 iteration 4112 : loss : 0.021057, loss_ce: 0.007026
2021-12-10 12:11:49,028 iteration 4113 : loss : 0.027192, loss_ce: 0.007320
2021-12-10 12:11:50,570 iteration 4114 : loss : 0.021648, loss_ce: 0.009650
 60%|████████████████▎          | 242/400 [1:56:02<1:16:40, 29.12s/it]2021-12-10 12:11:52,114 iteration 4115 : loss : 0.024530, loss_ce: 0.012057
2021-12-10 12:11:53,717 iteration 4116 : loss : 0.029542, loss_ce: 0.010299
2021-12-10 12:11:55,200 iteration 4117 : loss : 0.016923, loss_ce: 0.005982
2021-12-10 12:11:56,808 iteration 4118 : loss : 0.039296, loss_ce: 0.017631
2021-12-10 12:11:58,478 iteration 4119 : loss : 0.032680, loss_ce: 0.009096
2021-12-10 12:12:00,041 iteration 4120 : loss : 0.025603, loss_ce: 0.007812
2021-12-10 12:12:01,553 iteration 4121 : loss : 0.029257, loss_ce: 0.009470
2021-12-10 12:12:03,099 iteration 4122 : loss : 0.032594, loss_ce: 0.009543
2021-12-10 12:12:04,584 iteration 4123 : loss : 0.015297, loss_ce: 0.006273
2021-12-10 12:12:06,168 iteration 4124 : loss : 0.030691, loss_ce: 0.015550
2021-12-10 12:12:07,738 iteration 4125 : loss : 0.033411, loss_ce: 0.016815
2021-12-10 12:12:09,298 iteration 4126 : loss : 0.025657, loss_ce: 0.010453
2021-12-10 12:12:10,799 iteration 4127 : loss : 0.018142, loss_ce: 0.009267
2021-12-10 12:12:12,453 iteration 4128 : loss : 0.040086, loss_ce: 0.011431
2021-12-10 12:12:13,938 iteration 4129 : loss : 0.036458, loss_ce: 0.008338
2021-12-10 12:12:15,410 iteration 4130 : loss : 0.030637, loss_ce: 0.009003
2021-12-10 12:12:16,930 iteration 4131 : loss : 0.023191, loss_ce: 0.010206
 61%|████████████████▍          | 243/400 [1:56:28<1:14:01, 28.29s/it]2021-12-10 12:12:18,568 iteration 4132 : loss : 0.026372, loss_ce: 0.008175
2021-12-10 12:12:20,131 iteration 4133 : loss : 0.026524, loss_ce: 0.008398
2021-12-10 12:12:21,720 iteration 4134 : loss : 0.043855, loss_ce: 0.021543
2021-12-10 12:12:23,186 iteration 4135 : loss : 0.024686, loss_ce: 0.011742
2021-12-10 12:12:24,727 iteration 4136 : loss : 0.023771, loss_ce: 0.011162
2021-12-10 12:12:26,193 iteration 4137 : loss : 0.022658, loss_ce: 0.008853
2021-12-10 12:12:27,765 iteration 4138 : loss : 0.027199, loss_ce: 0.011528
2021-12-10 12:12:29,338 iteration 4139 : loss : 0.040174, loss_ce: 0.019746
2021-12-10 12:12:30,904 iteration 4140 : loss : 0.023359, loss_ce: 0.010386
2021-12-10 12:12:32,466 iteration 4141 : loss : 0.023810, loss_ce: 0.008627
2021-12-10 12:12:34,093 iteration 4142 : loss : 0.041813, loss_ce: 0.015030
2021-12-10 12:12:35,548 iteration 4143 : loss : 0.032758, loss_ce: 0.010143
2021-12-10 12:12:37,023 iteration 4144 : loss : 0.021133, loss_ce: 0.005076
2021-12-10 12:12:38,619 iteration 4145 : loss : 0.022913, loss_ce: 0.008786
2021-12-10 12:12:40,131 iteration 4146 : loss : 0.023689, loss_ce: 0.011253
2021-12-10 12:12:41,699 iteration 4147 : loss : 0.024337, loss_ce: 0.008484
2021-12-10 12:12:43,216 iteration 4148 : loss : 0.031743, loss_ce: 0.013654
 61%|████████████████▍          | 244/400 [1:56:54<1:11:59, 27.69s/it]2021-12-10 12:12:44,713 iteration 4149 : loss : 0.018825, loss_ce: 0.006714
2021-12-10 12:12:46,278 iteration 4150 : loss : 0.019427, loss_ce: 0.005680
2021-12-10 12:12:47,870 iteration 4151 : loss : 0.038905, loss_ce: 0.011327
2021-12-10 12:12:49,424 iteration 4152 : loss : 0.024363, loss_ce: 0.010404
2021-12-10 12:12:50,892 iteration 4153 : loss : 0.017918, loss_ce: 0.006786
2021-12-10 12:12:52,449 iteration 4154 : loss : 0.021064, loss_ce: 0.007476
2021-12-10 12:12:53,980 iteration 4155 : loss : 0.026045, loss_ce: 0.008262
2021-12-10 12:12:55,455 iteration 4156 : loss : 0.017503, loss_ce: 0.005985
2021-12-10 12:12:57,052 iteration 4157 : loss : 0.029876, loss_ce: 0.017530
2021-12-10 12:12:58,553 iteration 4158 : loss : 0.020543, loss_ce: 0.007672
2021-12-10 12:13:00,073 iteration 4159 : loss : 0.021446, loss_ce: 0.008511
2021-12-10 12:13:01,737 iteration 4160 : loss : 0.038150, loss_ce: 0.015272
2021-12-10 12:13:03,374 iteration 4161 : loss : 0.027954, loss_ce: 0.008312
2021-12-10 12:13:05,007 iteration 4162 : loss : 0.037310, loss_ce: 0.012303
2021-12-10 12:13:06,612 iteration 4163 : loss : 0.035944, loss_ce: 0.021194
2021-12-10 12:13:08,172 iteration 4164 : loss : 0.028282, loss_ce: 0.011692
2021-12-10 12:13:08,173 Training Data Eval:
2021-12-10 12:13:15,900   Average segmentation loss on training set: 0.0166
2021-12-10 12:13:15,901 Validation Data Eval:
2021-12-10 12:13:18,561   Average segmentation loss on validation set: 0.0720
2021-12-10 12:13:20,136 iteration 4165 : loss : 0.031152, loss_ce: 0.009886
 61%|████████████████▌          | 245/400 [1:57:31<1:18:41, 30.46s/it]2021-12-10 12:13:21,722 iteration 4166 : loss : 0.022590, loss_ce: 0.008967
2021-12-10 12:13:23,192 iteration 4167 : loss : 0.020991, loss_ce: 0.007190
2021-12-10 12:13:24,682 iteration 4168 : loss : 0.018807, loss_ce: 0.007855
2021-12-10 12:13:26,177 iteration 4169 : loss : 0.017220, loss_ce: 0.007996
2021-12-10 12:13:27,829 iteration 4170 : loss : 0.028167, loss_ce: 0.011728
2021-12-10 12:13:29,296 iteration 4171 : loss : 0.017329, loss_ce: 0.005984
2021-12-10 12:13:30,829 iteration 4172 : loss : 0.022964, loss_ce: 0.010794
2021-12-10 12:13:32,409 iteration 4173 : loss : 0.026608, loss_ce: 0.007589
2021-12-10 12:13:33,939 iteration 4174 : loss : 0.022066, loss_ce: 0.007090
2021-12-10 12:13:35,430 iteration 4175 : loss : 0.020120, loss_ce: 0.008347
2021-12-10 12:13:36,945 iteration 4176 : loss : 0.021037, loss_ce: 0.009010
2021-12-10 12:13:38,530 iteration 4177 : loss : 0.020837, loss_ce: 0.006401
2021-12-10 12:13:40,023 iteration 4178 : loss : 0.031168, loss_ce: 0.012701
2021-12-10 12:13:41,538 iteration 4179 : loss : 0.027017, loss_ce: 0.012209
2021-12-10 12:13:43,044 iteration 4180 : loss : 0.017766, loss_ce: 0.005795
2021-12-10 12:13:44,566 iteration 4181 : loss : 0.028206, loss_ce: 0.012019
2021-12-10 12:13:46,104 iteration 4182 : loss : 0.024817, loss_ce: 0.006505
 62%|████████████████▌          | 246/400 [1:57:57<1:14:44, 29.12s/it]2021-12-10 12:13:47,714 iteration 4183 : loss : 0.022388, loss_ce: 0.007674
2021-12-10 12:13:49,292 iteration 4184 : loss : 0.027001, loss_ce: 0.011699
2021-12-10 12:13:50,834 iteration 4185 : loss : 0.020549, loss_ce: 0.009053
2021-12-10 12:13:52,359 iteration 4186 : loss : 0.021647, loss_ce: 0.006433
2021-12-10 12:13:53,953 iteration 4187 : loss : 0.028378, loss_ce: 0.009238
2021-12-10 12:13:55,461 iteration 4188 : loss : 0.021914, loss_ce: 0.006706
2021-12-10 12:13:57,112 iteration 4189 : loss : 0.020223, loss_ce: 0.009080
2021-12-10 12:13:58,714 iteration 4190 : loss : 0.028898, loss_ce: 0.012738
2021-12-10 12:14:00,335 iteration 4191 : loss : 0.032247, loss_ce: 0.014238
2021-12-10 12:14:01,785 iteration 4192 : loss : 0.014930, loss_ce: 0.004354
2021-12-10 12:14:03,348 iteration 4193 : loss : 0.027961, loss_ce: 0.015826
2021-12-10 12:14:04,943 iteration 4194 : loss : 0.021195, loss_ce: 0.007587
2021-12-10 12:14:06,467 iteration 4195 : loss : 0.022171, loss_ce: 0.006538
2021-12-10 12:14:08,052 iteration 4196 : loss : 0.020805, loss_ce: 0.008357
2021-12-10 12:14:09,589 iteration 4197 : loss : 0.025463, loss_ce: 0.007129
2021-12-10 12:14:11,117 iteration 4198 : loss : 0.019823, loss_ce: 0.007791
2021-12-10 12:14:12,599 iteration 4199 : loss : 0.020562, loss_ce: 0.007801
 62%|████████████████▋          | 247/400 [1:58:24<1:12:14, 28.33s/it]2021-12-10 12:14:14,194 iteration 4200 : loss : 0.020927, loss_ce: 0.008328
2021-12-10 12:14:15,774 iteration 4201 : loss : 0.025408, loss_ce: 0.010554
2021-12-10 12:14:17,340 iteration 4202 : loss : 0.019625, loss_ce: 0.008251
2021-12-10 12:14:18,989 iteration 4203 : loss : 0.022488, loss_ce: 0.009667
2021-12-10 12:14:20,521 iteration 4204 : loss : 0.018196, loss_ce: 0.007398
2021-12-10 12:14:22,058 iteration 4205 : loss : 0.021261, loss_ce: 0.008718
2021-12-10 12:14:23,728 iteration 4206 : loss : 0.030590, loss_ce: 0.010025
2021-12-10 12:14:25,322 iteration 4207 : loss : 0.028552, loss_ce: 0.011296
2021-12-10 12:14:26,777 iteration 4208 : loss : 0.014965, loss_ce: 0.005597
2021-12-10 12:14:28,292 iteration 4209 : loss : 0.023700, loss_ce: 0.010037
2021-12-10 12:14:29,801 iteration 4210 : loss : 0.019449, loss_ce: 0.007755
2021-12-10 12:14:31,365 iteration 4211 : loss : 0.022213, loss_ce: 0.008689
2021-12-10 12:14:32,953 iteration 4212 : loss : 0.024073, loss_ce: 0.009399
2021-12-10 12:14:34,464 iteration 4213 : loss : 0.022276, loss_ce: 0.007281
2021-12-10 12:14:36,045 iteration 4214 : loss : 0.021936, loss_ce: 0.006917
2021-12-10 12:14:37,583 iteration 4215 : loss : 0.020283, loss_ce: 0.006329
2021-12-10 12:14:39,114 iteration 4216 : loss : 0.021764, loss_ce: 0.008547
 62%|████████████████▋          | 248/400 [1:58:50<1:10:22, 27.78s/it]2021-12-10 12:14:40,741 iteration 4217 : loss : 0.026730, loss_ce: 0.008973
2021-12-10 12:14:42,267 iteration 4218 : loss : 0.020397, loss_ce: 0.006887
2021-12-10 12:14:43,775 iteration 4219 : loss : 0.019894, loss_ce: 0.008288
2021-12-10 12:14:45,219 iteration 4220 : loss : 0.022328, loss_ce: 0.005436
2021-12-10 12:14:46,856 iteration 4221 : loss : 0.022233, loss_ce: 0.009238
2021-12-10 12:14:48,502 iteration 4222 : loss : 0.031210, loss_ce: 0.010171
2021-12-10 12:14:50,020 iteration 4223 : loss : 0.018082, loss_ce: 0.005930
2021-12-10 12:14:51,626 iteration 4224 : loss : 0.027748, loss_ce: 0.006612
2021-12-10 12:14:53,200 iteration 4225 : loss : 0.032403, loss_ce: 0.011322
2021-12-10 12:14:54,799 iteration 4226 : loss : 0.021441, loss_ce: 0.009862
2021-12-10 12:14:56,372 iteration 4227 : loss : 0.020545, loss_ce: 0.008832
2021-12-10 12:14:57,865 iteration 4228 : loss : 0.028613, loss_ce: 0.013492
2021-12-10 12:14:59,398 iteration 4229 : loss : 0.026930, loss_ce: 0.009707
2021-12-10 12:15:00,919 iteration 4230 : loss : 0.034785, loss_ce: 0.016264
2021-12-10 12:15:02,513 iteration 4231 : loss : 0.025720, loss_ce: 0.010017
2021-12-10 12:15:04,101 iteration 4232 : loss : 0.025280, loss_ce: 0.009141
2021-12-10 12:15:05,641 iteration 4233 : loss : 0.021290, loss_ce: 0.011291
 62%|████████████████▊          | 249/400 [1:59:17<1:08:58, 27.41s/it]2021-12-10 12:15:07,142 iteration 4234 : loss : 0.022753, loss_ce: 0.005206
2021-12-10 12:15:08,613 iteration 4235 : loss : 0.013498, loss_ce: 0.005053
2021-12-10 12:15:10,181 iteration 4236 : loss : 0.026437, loss_ce: 0.010772
2021-12-10 12:15:11,673 iteration 4237 : loss : 0.022579, loss_ce: 0.009530
2021-12-10 12:15:13,203 iteration 4238 : loss : 0.034128, loss_ce: 0.017069
2021-12-10 12:15:14,891 iteration 4239 : loss : 0.028174, loss_ce: 0.011027
2021-12-10 12:15:16,451 iteration 4240 : loss : 0.023483, loss_ce: 0.007713
2021-12-10 12:15:17,907 iteration 4241 : loss : 0.019672, loss_ce: 0.008934
2021-12-10 12:15:19,461 iteration 4242 : loss : 0.019203, loss_ce: 0.005139
2021-12-10 12:15:20,976 iteration 4243 : loss : 0.022362, loss_ce: 0.008654
2021-12-10 12:15:22,443 iteration 4244 : loss : 0.017355, loss_ce: 0.008153
2021-12-10 12:15:24,034 iteration 4245 : loss : 0.032435, loss_ce: 0.014465
2021-12-10 12:15:25,665 iteration 4246 : loss : 0.030347, loss_ce: 0.006612
2021-12-10 12:15:27,253 iteration 4247 : loss : 0.023837, loss_ce: 0.010119
2021-12-10 12:15:28,739 iteration 4248 : loss : 0.029898, loss_ce: 0.012066
2021-12-10 12:15:30,358 iteration 4249 : loss : 0.039146, loss_ce: 0.015262
2021-12-10 12:15:30,358 Training Data Eval:
2021-12-10 12:15:38,094   Average segmentation loss on training set: 0.0157
2021-12-10 12:15:38,094 Validation Data Eval:
2021-12-10 12:15:40,748   Average segmentation loss on validation set: 0.0728
2021-12-10 12:15:42,290 iteration 4250 : loss : 0.022211, loss_ce: 0.006645
2021-12-10 12:15:48,038 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234epoch_249.pth
 62%|████████████████▉          | 250/400 [1:59:59<1:19:43, 31.89s/it]2021-12-10 12:15:49,693 iteration 4251 : loss : 0.028848, loss_ce: 0.008669
2021-12-10 12:15:51,280 iteration 4252 : loss : 0.023396, loss_ce: 0.010757
2021-12-10 12:15:52,815 iteration 4253 : loss : 0.026123, loss_ce: 0.008401
2021-12-10 12:15:54,400 iteration 4254 : loss : 0.022261, loss_ce: 0.008919
2021-12-10 12:15:55,990 iteration 4255 : loss : 0.023348, loss_ce: 0.009251
2021-12-10 12:15:57,437 iteration 4256 : loss : 0.021922, loss_ce: 0.009284
2021-12-10 12:15:58,976 iteration 4257 : loss : 0.032535, loss_ce: 0.011579
2021-12-10 12:16:00,441 iteration 4258 : loss : 0.035474, loss_ce: 0.011388
2021-12-10 12:16:02,003 iteration 4259 : loss : 0.024849, loss_ce: 0.010853
2021-12-10 12:16:03,556 iteration 4260 : loss : 0.030051, loss_ce: 0.009065
2021-12-10 12:16:05,125 iteration 4261 : loss : 0.023288, loss_ce: 0.009199
2021-12-10 12:16:06,624 iteration 4262 : loss : 0.019506, loss_ce: 0.008362
2021-12-10 12:16:08,190 iteration 4263 : loss : 0.022794, loss_ce: 0.010249
2021-12-10 12:16:09,789 iteration 4264 : loss : 0.039185, loss_ce: 0.016602
2021-12-10 12:16:11,327 iteration 4265 : loss : 0.027423, loss_ce: 0.006838
2021-12-10 12:16:12,905 iteration 4266 : loss : 0.023210, loss_ce: 0.007057
2021-12-10 12:16:14,502 iteration 4267 : loss : 0.031146, loss_ce: 0.011724
 63%|████████████████▉          | 251/400 [2:00:25<1:15:10, 30.27s/it]2021-12-10 12:16:16,092 iteration 4268 : loss : 0.017768, loss_ce: 0.004140
2021-12-10 12:16:17,623 iteration 4269 : loss : 0.023897, loss_ce: 0.007855
2021-12-10 12:16:19,133 iteration 4270 : loss : 0.020081, loss_ce: 0.010242
2021-12-10 12:16:20,597 iteration 4271 : loss : 0.019267, loss_ce: 0.007275
2021-12-10 12:16:22,130 iteration 4272 : loss : 0.020609, loss_ce: 0.010143
2021-12-10 12:16:23,606 iteration 4273 : loss : 0.016568, loss_ce: 0.007181
2021-12-10 12:16:25,240 iteration 4274 : loss : 0.030398, loss_ce: 0.018414
2021-12-10 12:16:26,760 iteration 4275 : loss : 0.023485, loss_ce: 0.008812
2021-12-10 12:16:28,356 iteration 4276 : loss : 0.027269, loss_ce: 0.007794
2021-12-10 12:16:29,956 iteration 4277 : loss : 0.024945, loss_ce: 0.007591
2021-12-10 12:16:31,542 iteration 4278 : loss : 0.025812, loss_ce: 0.008877
2021-12-10 12:16:33,067 iteration 4279 : loss : 0.021167, loss_ce: 0.010598
2021-12-10 12:16:34,625 iteration 4280 : loss : 0.020731, loss_ce: 0.006714
2021-12-10 12:16:36,179 iteration 4281 : loss : 0.030397, loss_ce: 0.009180
2021-12-10 12:16:37,653 iteration 4282 : loss : 0.017718, loss_ce: 0.006949
2021-12-10 12:16:39,183 iteration 4283 : loss : 0.026477, loss_ce: 0.007876
2021-12-10 12:16:40,691 iteration 4284 : loss : 0.017788, loss_ce: 0.006953
 63%|█████████████████          | 252/400 [2:00:52<1:11:39, 29.05s/it]2021-12-10 12:16:42,207 iteration 4285 : loss : 0.019885, loss_ce: 0.005865
2021-12-10 12:16:43,793 iteration 4286 : loss : 0.021955, loss_ce: 0.007996
2021-12-10 12:16:45,288 iteration 4287 : loss : 0.023196, loss_ce: 0.010081
2021-12-10 12:16:46,785 iteration 4288 : loss : 0.021017, loss_ce: 0.009478
2021-12-10 12:16:48,331 iteration 4289 : loss : 0.020161, loss_ce: 0.008682
2021-12-10 12:16:49,859 iteration 4290 : loss : 0.037609, loss_ce: 0.008367
2021-12-10 12:16:51,435 iteration 4291 : loss : 0.026060, loss_ce: 0.009298
2021-12-10 12:16:53,001 iteration 4292 : loss : 0.023053, loss_ce: 0.011818
2021-12-10 12:16:54,552 iteration 4293 : loss : 0.032996, loss_ce: 0.008895
2021-12-10 12:16:56,065 iteration 4294 : loss : 0.031886, loss_ce: 0.008350
2021-12-10 12:16:57,738 iteration 4295 : loss : 0.027873, loss_ce: 0.009714
2021-12-10 12:16:59,293 iteration 4296 : loss : 0.021332, loss_ce: 0.006172
2021-12-10 12:17:00,860 iteration 4297 : loss : 0.032903, loss_ce: 0.011235
2021-12-10 12:17:02,373 iteration 4298 : loss : 0.016126, loss_ce: 0.007647
2021-12-10 12:17:03,968 iteration 4299 : loss : 0.019096, loss_ce: 0.008415
2021-12-10 12:17:05,594 iteration 4300 : loss : 0.025927, loss_ce: 0.009898
2021-12-10 12:17:07,214 iteration 4301 : loss : 0.023824, loss_ce: 0.010231
 63%|█████████████████          | 253/400 [2:01:18<1:09:19, 28.30s/it]2021-12-10 12:17:08,866 iteration 4302 : loss : 0.036043, loss_ce: 0.015819
2021-12-10 12:17:10,482 iteration 4303 : loss : 0.042380, loss_ce: 0.006797
2021-12-10 12:17:11,988 iteration 4304 : loss : 0.020912, loss_ce: 0.008442
2021-12-10 12:17:13,508 iteration 4305 : loss : 0.023923, loss_ce: 0.009338
2021-12-10 12:17:15,028 iteration 4306 : loss : 0.018222, loss_ce: 0.005827
2021-12-10 12:17:16,509 iteration 4307 : loss : 0.021869, loss_ce: 0.010174
2021-12-10 12:17:18,079 iteration 4308 : loss : 0.024644, loss_ce: 0.008342
2021-12-10 12:17:19,691 iteration 4309 : loss : 0.024314, loss_ce: 0.007380
2021-12-10 12:17:21,246 iteration 4310 : loss : 0.022876, loss_ce: 0.009898
2021-12-10 12:17:22,750 iteration 4311 : loss : 0.034226, loss_ce: 0.015721
2021-12-10 12:17:24,237 iteration 4312 : loss : 0.024355, loss_ce: 0.008361
2021-12-10 12:17:25,740 iteration 4313 : loss : 0.018746, loss_ce: 0.009213
2021-12-10 12:17:27,245 iteration 4314 : loss : 0.020431, loss_ce: 0.006448
2021-12-10 12:17:28,832 iteration 4315 : loss : 0.025395, loss_ce: 0.010021
2021-12-10 12:17:30,342 iteration 4316 : loss : 0.021326, loss_ce: 0.007222
2021-12-10 12:17:31,944 iteration 4317 : loss : 0.020537, loss_ce: 0.008777
2021-12-10 12:17:33,437 iteration 4318 : loss : 0.020957, loss_ce: 0.008071
 64%|█████████████████▏         | 254/400 [2:01:44<1:07:19, 27.67s/it]2021-12-10 12:17:35,086 iteration 4319 : loss : 0.027518, loss_ce: 0.009560
2021-12-10 12:17:36,680 iteration 4320 : loss : 0.024259, loss_ce: 0.010251
2021-12-10 12:17:38,123 iteration 4321 : loss : 0.020104, loss_ce: 0.005952
2021-12-10 12:17:39,671 iteration 4322 : loss : 0.018662, loss_ce: 0.006253
2021-12-10 12:17:41,155 iteration 4323 : loss : 0.019386, loss_ce: 0.009307
2021-12-10 12:17:42,822 iteration 4324 : loss : 0.043688, loss_ce: 0.021341
2021-12-10 12:17:44,379 iteration 4325 : loss : 0.038986, loss_ce: 0.018458
2021-12-10 12:17:45,901 iteration 4326 : loss : 0.024457, loss_ce: 0.011539
2021-12-10 12:17:47,481 iteration 4327 : loss : 0.023117, loss_ce: 0.006844
2021-12-10 12:17:48,990 iteration 4328 : loss : 0.047644, loss_ce: 0.022943
2021-12-10 12:17:50,601 iteration 4329 : loss : 0.052093, loss_ce: 0.014120
2021-12-10 12:17:52,188 iteration 4330 : loss : 0.020897, loss_ce: 0.009394
2021-12-10 12:17:53,831 iteration 4331 : loss : 0.044806, loss_ce: 0.013937
2021-12-10 12:17:55,427 iteration 4332 : loss : 0.033912, loss_ce: 0.011570
2021-12-10 12:17:57,053 iteration 4333 : loss : 0.028442, loss_ce: 0.011431
2021-12-10 12:17:58,612 iteration 4334 : loss : 0.021143, loss_ce: 0.010160
2021-12-10 12:17:58,612 Training Data Eval:
2021-12-10 12:18:06,360   Average segmentation loss on training set: 0.0162
2021-12-10 12:18:06,361 Validation Data Eval:
2021-12-10 12:18:09,010   Average segmentation loss on validation set: 0.0842
2021-12-10 12:18:10,611 iteration 4335 : loss : 0.026902, loss_ce: 0.007159
 64%|█████████████████▏         | 255/400 [2:02:22<1:13:45, 30.52s/it]2021-12-10 12:18:12,089 iteration 4336 : loss : 0.016843, loss_ce: 0.008031
2021-12-10 12:18:13,725 iteration 4337 : loss : 0.026378, loss_ce: 0.011472
2021-12-10 12:18:15,269 iteration 4338 : loss : 0.020290, loss_ce: 0.007098
2021-12-10 12:18:16,766 iteration 4339 : loss : 0.019796, loss_ce: 0.006932
2021-12-10 12:18:18,353 iteration 4340 : loss : 0.027409, loss_ce: 0.011777
2021-12-10 12:18:19,842 iteration 4341 : loss : 0.021058, loss_ce: 0.006697
2021-12-10 12:18:21,438 iteration 4342 : loss : 0.027242, loss_ce: 0.009147
2021-12-10 12:18:23,030 iteration 4343 : loss : 0.025078, loss_ce: 0.007213
2021-12-10 12:18:24,616 iteration 4344 : loss : 0.022361, loss_ce: 0.010001
2021-12-10 12:18:26,265 iteration 4345 : loss : 0.023101, loss_ce: 0.009553
2021-12-10 12:18:27,745 iteration 4346 : loss : 0.024180, loss_ce: 0.007458
2021-12-10 12:18:29,299 iteration 4347 : loss : 0.024740, loss_ce: 0.009743
2021-12-10 12:18:30,791 iteration 4348 : loss : 0.021030, loss_ce: 0.010819
2021-12-10 12:18:32,241 iteration 4349 : loss : 0.017083, loss_ce: 0.004533
2021-12-10 12:18:33,690 iteration 4350 : loss : 0.024489, loss_ce: 0.008847
2021-12-10 12:18:35,231 iteration 4351 : loss : 0.032637, loss_ce: 0.009543
2021-12-10 12:18:36,784 iteration 4352 : loss : 0.035965, loss_ce: 0.017023
 64%|█████████████████▎         | 256/400 [2:02:48<1:10:07, 29.22s/it]2021-12-10 12:18:38,328 iteration 4353 : loss : 0.022918, loss_ce: 0.007173
2021-12-10 12:18:39,960 iteration 4354 : loss : 0.025002, loss_ce: 0.011257
2021-12-10 12:18:41,554 iteration 4355 : loss : 0.023004, loss_ce: 0.010332
2021-12-10 12:18:43,193 iteration 4356 : loss : 0.033489, loss_ce: 0.009606
2021-12-10 12:18:44,785 iteration 4357 : loss : 0.019514, loss_ce: 0.009096
2021-12-10 12:18:46,394 iteration 4358 : loss : 0.031473, loss_ce: 0.012134
2021-12-10 12:18:47,970 iteration 4359 : loss : 0.027700, loss_ce: 0.009369
2021-12-10 12:18:49,503 iteration 4360 : loss : 0.034895, loss_ce: 0.016555
2021-12-10 12:18:51,111 iteration 4361 : loss : 0.021467, loss_ce: 0.008276
2021-12-10 12:18:52,659 iteration 4362 : loss : 0.027578, loss_ce: 0.012371
2021-12-10 12:18:54,208 iteration 4363 : loss : 0.019653, loss_ce: 0.007939
2021-12-10 12:18:55,785 iteration 4364 : loss : 0.033851, loss_ce: 0.015580
2021-12-10 12:18:57,438 iteration 4365 : loss : 0.027029, loss_ce: 0.011854
2021-12-10 12:18:58,936 iteration 4366 : loss : 0.022177, loss_ce: 0.006139
2021-12-10 12:19:00,369 iteration 4367 : loss : 0.020768, loss_ce: 0.008252
2021-12-10 12:19:01,842 iteration 4368 : loss : 0.022147, loss_ce: 0.007525
2021-12-10 12:19:03,397 iteration 4369 : loss : 0.023836, loss_ce: 0.008663
 64%|█████████████████▎         | 257/400 [2:03:14<1:07:46, 28.44s/it]2021-12-10 12:19:05,003 iteration 4370 : loss : 0.019659, loss_ce: 0.006875
2021-12-10 12:19:06,570 iteration 4371 : loss : 0.028529, loss_ce: 0.014396
2021-12-10 12:19:08,148 iteration 4372 : loss : 0.026250, loss_ce: 0.009261
2021-12-10 12:19:09,725 iteration 4373 : loss : 0.020160, loss_ce: 0.009822
2021-12-10 12:19:11,312 iteration 4374 : loss : 0.025984, loss_ce: 0.009503
2021-12-10 12:19:12,898 iteration 4375 : loss : 0.023314, loss_ce: 0.011219
2021-12-10 12:19:14,419 iteration 4376 : loss : 0.027980, loss_ce: 0.010367
2021-12-10 12:19:15,939 iteration 4377 : loss : 0.020981, loss_ce: 0.005985
2021-12-10 12:19:17,414 iteration 4378 : loss : 0.017458, loss_ce: 0.006182
2021-12-10 12:19:18,898 iteration 4379 : loss : 0.016393, loss_ce: 0.005390
2021-12-10 12:19:20,354 iteration 4380 : loss : 0.017107, loss_ce: 0.006109
2021-12-10 12:19:21,919 iteration 4381 : loss : 0.045210, loss_ce: 0.015758
2021-12-10 12:19:23,457 iteration 4382 : loss : 0.034124, loss_ce: 0.008264
2021-12-10 12:19:24,971 iteration 4383 : loss : 0.025206, loss_ce: 0.007351
2021-12-10 12:19:26,580 iteration 4384 : loss : 0.021572, loss_ce: 0.009336
2021-12-10 12:19:28,180 iteration 4385 : loss : 0.028276, loss_ce: 0.009411
2021-12-10 12:19:29,686 iteration 4386 : loss : 0.017012, loss_ce: 0.007540
 64%|█████████████████▍         | 258/400 [2:03:41<1:05:46, 27.80s/it]2021-12-10 12:19:31,224 iteration 4387 : loss : 0.019519, loss_ce: 0.006508
2021-12-10 12:19:32,767 iteration 4388 : loss : 0.031205, loss_ce: 0.013273
2021-12-10 12:19:34,319 iteration 4389 : loss : 0.029049, loss_ce: 0.008469
2021-12-10 12:19:35,806 iteration 4390 : loss : 0.020912, loss_ce: 0.006643
2021-12-10 12:19:37,369 iteration 4391 : loss : 0.030032, loss_ce: 0.009908
2021-12-10 12:19:38,908 iteration 4392 : loss : 0.026918, loss_ce: 0.007950
2021-12-10 12:19:40,534 iteration 4393 : loss : 0.034607, loss_ce: 0.016536
2021-12-10 12:19:42,124 iteration 4394 : loss : 0.027038, loss_ce: 0.011388
2021-12-10 12:19:43,779 iteration 4395 : loss : 0.027172, loss_ce: 0.008978
2021-12-10 12:19:45,297 iteration 4396 : loss : 0.018914, loss_ce: 0.006852
2021-12-10 12:19:46,959 iteration 4397 : loss : 0.029399, loss_ce: 0.015918
2021-12-10 12:19:48,457 iteration 4398 : loss : 0.021188, loss_ce: 0.009365
2021-12-10 12:19:50,050 iteration 4399 : loss : 0.039997, loss_ce: 0.023687
2021-12-10 12:19:51,621 iteration 4400 : loss : 0.031872, loss_ce: 0.010311
2021-12-10 12:19:53,318 iteration 4401 : loss : 0.040484, loss_ce: 0.015231
2021-12-10 12:19:54,885 iteration 4402 : loss : 0.030045, loss_ce: 0.008781
2021-12-10 12:19:56,460 iteration 4403 : loss : 0.024861, loss_ce: 0.008745
 65%|█████████████████▍         | 259/400 [2:04:07<1:04:35, 27.49s/it]2021-12-10 12:19:58,033 iteration 4404 : loss : 0.018514, loss_ce: 0.007895
2021-12-10 12:19:59,619 iteration 4405 : loss : 0.023538, loss_ce: 0.010632
2021-12-10 12:20:01,202 iteration 4406 : loss : 0.029028, loss_ce: 0.013720
2021-12-10 12:20:02,827 iteration 4407 : loss : 0.033138, loss_ce: 0.014091
2021-12-10 12:20:04,359 iteration 4408 : loss : 0.019377, loss_ce: 0.008007
2021-12-10 12:20:05,942 iteration 4409 : loss : 0.029451, loss_ce: 0.010783
2021-12-10 12:20:07,654 iteration 4410 : loss : 0.033079, loss_ce: 0.010864
2021-12-10 12:20:09,268 iteration 4411 : loss : 0.025590, loss_ce: 0.011305
2021-12-10 12:20:10,815 iteration 4412 : loss : 0.027851, loss_ce: 0.012158
2021-12-10 12:20:12,391 iteration 4413 : loss : 0.020808, loss_ce: 0.007532
2021-12-10 12:20:13,887 iteration 4414 : loss : 0.018114, loss_ce: 0.006051
2021-12-10 12:20:15,472 iteration 4415 : loss : 0.021031, loss_ce: 0.007684
2021-12-10 12:20:17,085 iteration 4416 : loss : 0.031966, loss_ce: 0.011205
2021-12-10 12:20:18,636 iteration 4417 : loss : 0.022308, loss_ce: 0.006976
2021-12-10 12:20:20,202 iteration 4418 : loss : 0.019885, loss_ce: 0.008923
2021-12-10 12:20:21,807 iteration 4419 : loss : 0.020331, loss_ce: 0.007010
2021-12-10 12:20:21,807 Training Data Eval:
2021-12-10 12:20:29,541   Average segmentation loss on training set: 0.0148
2021-12-10 12:20:29,542 Validation Data Eval:
2021-12-10 12:20:32,197   Average segmentation loss on validation set: 0.0873
2021-12-10 12:20:33,688 iteration 4420 : loss : 0.017138, loss_ce: 0.008131
 65%|█████████████████▌         | 260/400 [2:04:45<1:10:57, 30.41s/it]2021-12-10 12:20:35,263 iteration 4421 : loss : 0.020036, loss_ce: 0.007175
2021-12-10 12:20:36,833 iteration 4422 : loss : 0.028912, loss_ce: 0.012640
2021-12-10 12:20:38,448 iteration 4423 : loss : 0.024840, loss_ce: 0.009296
2021-12-10 12:20:39,935 iteration 4424 : loss : 0.019933, loss_ce: 0.007895
2021-12-10 12:20:41,415 iteration 4425 : loss : 0.021764, loss_ce: 0.007620
2021-12-10 12:20:43,027 iteration 4426 : loss : 0.018192, loss_ce: 0.007601
2021-12-10 12:20:44,512 iteration 4427 : loss : 0.017568, loss_ce: 0.007377
2021-12-10 12:20:45,954 iteration 4428 : loss : 0.015614, loss_ce: 0.007293
2021-12-10 12:20:47,414 iteration 4429 : loss : 0.025471, loss_ce: 0.009711
2021-12-10 12:20:48,883 iteration 4430 : loss : 0.024117, loss_ce: 0.012994
2021-12-10 12:20:50,443 iteration 4431 : loss : 0.031767, loss_ce: 0.013565
2021-12-10 12:20:52,033 iteration 4432 : loss : 0.024172, loss_ce: 0.009810
2021-12-10 12:20:53,551 iteration 4433 : loss : 0.033700, loss_ce: 0.007747
2021-12-10 12:20:55,028 iteration 4434 : loss : 0.020721, loss_ce: 0.008020
2021-12-10 12:20:56,573 iteration 4435 : loss : 0.031326, loss_ce: 0.006439
2021-12-10 12:20:58,103 iteration 4436 : loss : 0.020588, loss_ce: 0.008254
2021-12-10 12:20:59,708 iteration 4437 : loss : 0.022029, loss_ce: 0.008037
 65%|█████████████████▌         | 261/400 [2:05:11<1:07:24, 29.09s/it]2021-12-10 12:21:01,382 iteration 4438 : loss : 0.056335, loss_ce: 0.013856
2021-12-10 12:21:02,963 iteration 4439 : loss : 0.022719, loss_ce: 0.008997
2021-12-10 12:21:04,521 iteration 4440 : loss : 0.023911, loss_ce: 0.009288
2021-12-10 12:21:06,193 iteration 4441 : loss : 0.026212, loss_ce: 0.009012
2021-12-10 12:21:07,814 iteration 4442 : loss : 0.016685, loss_ce: 0.008343
2021-12-10 12:21:09,388 iteration 4443 : loss : 0.025449, loss_ce: 0.011009
2021-12-10 12:21:10,910 iteration 4444 : loss : 0.022275, loss_ce: 0.007636
2021-12-10 12:21:12,437 iteration 4445 : loss : 0.036780, loss_ce: 0.014836
2021-12-10 12:21:14,018 iteration 4446 : loss : 0.025863, loss_ce: 0.011490
2021-12-10 12:21:15,541 iteration 4447 : loss : 0.018667, loss_ce: 0.006425
2021-12-10 12:21:17,116 iteration 4448 : loss : 0.036602, loss_ce: 0.013686
2021-12-10 12:21:18,670 iteration 4449 : loss : 0.026096, loss_ce: 0.010268
2021-12-10 12:21:20,286 iteration 4450 : loss : 0.026151, loss_ce: 0.008583
2021-12-10 12:21:21,799 iteration 4451 : loss : 0.030263, loss_ce: 0.012244
2021-12-10 12:21:23,360 iteration 4452 : loss : 0.020270, loss_ce: 0.009064
2021-12-10 12:21:24,878 iteration 4453 : loss : 0.024212, loss_ce: 0.008691
2021-12-10 12:21:26,399 iteration 4454 : loss : 0.028195, loss_ce: 0.010942
 66%|█████████████████▋         | 262/400 [2:05:37<1:05:15, 28.37s/it]2021-12-10 12:21:28,016 iteration 4455 : loss : 0.023642, loss_ce: 0.006359
2021-12-10 12:21:29,474 iteration 4456 : loss : 0.018364, loss_ce: 0.006833
2021-12-10 12:21:31,039 iteration 4457 : loss : 0.024173, loss_ce: 0.009836
2021-12-10 12:21:32,693 iteration 4458 : loss : 0.059858, loss_ce: 0.027474
2021-12-10 12:21:34,421 iteration 4459 : loss : 0.027485, loss_ce: 0.012507
2021-12-10 12:21:35,934 iteration 4460 : loss : 0.021663, loss_ce: 0.007733
2021-12-10 12:21:37,496 iteration 4461 : loss : 0.024780, loss_ce: 0.007890
2021-12-10 12:21:39,090 iteration 4462 : loss : 0.027976, loss_ce: 0.013113
2021-12-10 12:21:40,625 iteration 4463 : loss : 0.031227, loss_ce: 0.012985
2021-12-10 12:21:42,147 iteration 4464 : loss : 0.022187, loss_ce: 0.007468
2021-12-10 12:21:43,610 iteration 4465 : loss : 0.022237, loss_ce: 0.004793
2021-12-10 12:21:45,094 iteration 4466 : loss : 0.025605, loss_ce: 0.006728
2021-12-10 12:21:46,640 iteration 4467 : loss : 0.039676, loss_ce: 0.019672
2021-12-10 12:21:48,226 iteration 4468 : loss : 0.024974, loss_ce: 0.010491
2021-12-10 12:21:49,849 iteration 4469 : loss : 0.027917, loss_ce: 0.013851
2021-12-10 12:21:51,446 iteration 4470 : loss : 0.027693, loss_ce: 0.011287
2021-12-10 12:21:53,084 iteration 4471 : loss : 0.028121, loss_ce: 0.008627
 66%|█████████████████▊         | 263/400 [2:06:04<1:03:37, 27.86s/it]2021-12-10 12:21:54,652 iteration 4472 : loss : 0.021722, loss_ce: 0.010490
2021-12-10 12:21:56,153 iteration 4473 : loss : 0.021984, loss_ce: 0.009363
2021-12-10 12:21:57,714 iteration 4474 : loss : 0.030686, loss_ce: 0.014711
2021-12-10 12:21:59,253 iteration 4475 : loss : 0.018247, loss_ce: 0.005889
2021-12-10 12:22:00,760 iteration 4476 : loss : 0.020328, loss_ce: 0.006434
2021-12-10 12:22:02,280 iteration 4477 : loss : 0.028623, loss_ce: 0.011126
2021-12-10 12:22:03,944 iteration 4478 : loss : 0.025190, loss_ce: 0.012848
2021-12-10 12:22:05,489 iteration 4479 : loss : 0.033722, loss_ce: 0.009940
2021-12-10 12:22:07,058 iteration 4480 : loss : 0.031857, loss_ce: 0.011063
2021-12-10 12:22:08,558 iteration 4481 : loss : 0.022377, loss_ce: 0.008030
2021-12-10 12:22:10,049 iteration 4482 : loss : 0.017701, loss_ce: 0.004994
2021-12-10 12:22:11,557 iteration 4483 : loss : 0.021607, loss_ce: 0.006970
2021-12-10 12:22:13,106 iteration 4484 : loss : 0.014125, loss_ce: 0.004337
2021-12-10 12:22:14,577 iteration 4485 : loss : 0.019557, loss_ce: 0.007406
2021-12-10 12:22:16,182 iteration 4486 : loss : 0.017307, loss_ce: 0.006428
2021-12-10 12:22:17,763 iteration 4487 : loss : 0.024863, loss_ce: 0.010108
2021-12-10 12:22:19,256 iteration 4488 : loss : 0.021419, loss_ce: 0.007650
 66%|█████████████████▊         | 264/400 [2:06:30<1:02:00, 27.36s/it]2021-12-10 12:22:20,886 iteration 4489 : loss : 0.020902, loss_ce: 0.008152
2021-12-10 12:22:22,421 iteration 4490 : loss : 0.017869, loss_ce: 0.008894
2021-12-10 12:22:24,071 iteration 4491 : loss : 0.041485, loss_ce: 0.013533
2021-12-10 12:22:25,588 iteration 4492 : loss : 0.024275, loss_ce: 0.006002
2021-12-10 12:22:27,224 iteration 4493 : loss : 0.027435, loss_ce: 0.016567
2021-12-10 12:22:28,732 iteration 4494 : loss : 0.028524, loss_ce: 0.009937
2021-12-10 12:22:30,289 iteration 4495 : loss : 0.031125, loss_ce: 0.006219
2021-12-10 12:22:31,854 iteration 4496 : loss : 0.033343, loss_ce: 0.009203
2021-12-10 12:22:33,292 iteration 4497 : loss : 0.024405, loss_ce: 0.011669
2021-12-10 12:22:34,833 iteration 4498 : loss : 0.021711, loss_ce: 0.007273
2021-12-10 12:22:36,346 iteration 4499 : loss : 0.017508, loss_ce: 0.007064
2021-12-10 12:22:37,887 iteration 4500 : loss : 0.037945, loss_ce: 0.011069
2021-12-10 12:22:39,402 iteration 4501 : loss : 0.020956, loss_ce: 0.009597
2021-12-10 12:22:40,929 iteration 4502 : loss : 0.021622, loss_ce: 0.007728
2021-12-10 12:22:42,559 iteration 4503 : loss : 0.020249, loss_ce: 0.007451
2021-12-10 12:22:44,014 iteration 4504 : loss : 0.019561, loss_ce: 0.007948
2021-12-10 12:22:44,014 Training Data Eval:
2021-12-10 12:22:51,743   Average segmentation loss on training set: 0.0137
2021-12-10 12:22:51,743 Validation Data Eval:
2021-12-10 12:22:54,414   Average segmentation loss on validation set: 0.0627
2021-12-10 12:23:00,128 Found new lowest validation loss at iteration 4504! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 12:23:01,717 iteration 4505 : loss : 0.030660, loss_ce: 0.014551
 66%|█████████████████▉         | 265/400 [2:07:13<1:11:45, 31.89s/it]2021-12-10 12:23:03,344 iteration 4506 : loss : 0.019668, loss_ce: 0.007877
2021-12-10 12:23:04,956 iteration 4507 : loss : 0.025453, loss_ce: 0.009805
2021-12-10 12:23:06,506 iteration 4508 : loss : 0.024429, loss_ce: 0.008417
2021-12-10 12:23:07,971 iteration 4509 : loss : 0.019886, loss_ce: 0.006259
2021-12-10 12:23:09,524 iteration 4510 : loss : 0.019089, loss_ce: 0.006700
2021-12-10 12:23:11,163 iteration 4511 : loss : 0.027922, loss_ce: 0.013277
2021-12-10 12:23:12,610 iteration 4512 : loss : 0.016670, loss_ce: 0.005894
2021-12-10 12:23:14,124 iteration 4513 : loss : 0.022191, loss_ce: 0.008415
2021-12-10 12:23:15,633 iteration 4514 : loss : 0.022041, loss_ce: 0.008280
2021-12-10 12:23:17,163 iteration 4515 : loss : 0.017449, loss_ce: 0.006889
2021-12-10 12:23:18,713 iteration 4516 : loss : 0.022810, loss_ce: 0.010487
2021-12-10 12:23:20,286 iteration 4517 : loss : 0.021993, loss_ce: 0.008913
2021-12-10 12:23:21,808 iteration 4518 : loss : 0.028798, loss_ce: 0.011807
2021-12-10 12:23:23,270 iteration 4519 : loss : 0.029381, loss_ce: 0.009267
2021-12-10 12:23:24,814 iteration 4520 : loss : 0.028604, loss_ce: 0.011252
2021-12-10 12:23:26,376 iteration 4521 : loss : 0.022378, loss_ce: 0.008736
2021-12-10 12:23:27,979 iteration 4522 : loss : 0.027054, loss_ce: 0.010912
 66%|█████████████████▉         | 266/400 [2:07:39<1:07:27, 30.20s/it]2021-12-10 12:23:29,662 iteration 4523 : loss : 0.027916, loss_ce: 0.013478
2021-12-10 12:23:31,222 iteration 4524 : loss : 0.023547, loss_ce: 0.008792
2021-12-10 12:23:32,797 iteration 4525 : loss : 0.033647, loss_ce: 0.015360
2021-12-10 12:23:34,340 iteration 4526 : loss : 0.020171, loss_ce: 0.006243
2021-12-10 12:23:35,804 iteration 4527 : loss : 0.019967, loss_ce: 0.007214
2021-12-10 12:23:37,305 iteration 4528 : loss : 0.017455, loss_ce: 0.005781
2021-12-10 12:23:38,868 iteration 4529 : loss : 0.019944, loss_ce: 0.008540
2021-12-10 12:23:40,371 iteration 4530 : loss : 0.025540, loss_ce: 0.006263
2021-12-10 12:23:41,917 iteration 4531 : loss : 0.019002, loss_ce: 0.006682
2021-12-10 12:23:43,487 iteration 4532 : loss : 0.017622, loss_ce: 0.005881
2021-12-10 12:23:45,003 iteration 4533 : loss : 0.021037, loss_ce: 0.009380
2021-12-10 12:23:46,525 iteration 4534 : loss : 0.022669, loss_ce: 0.006209
2021-12-10 12:23:48,101 iteration 4535 : loss : 0.023965, loss_ce: 0.008847
2021-12-10 12:23:49,659 iteration 4536 : loss : 0.023724, loss_ce: 0.009233
2021-12-10 12:23:51,208 iteration 4537 : loss : 0.033920, loss_ce: 0.015032
2021-12-10 12:23:52,752 iteration 4538 : loss : 0.024445, loss_ce: 0.009170
2021-12-10 12:23:54,289 iteration 4539 : loss : 0.031928, loss_ce: 0.013109
 67%|██████████████████         | 267/400 [2:08:05<1:04:21, 29.03s/it]2021-12-10 12:23:55,862 iteration 4540 : loss : 0.016408, loss_ce: 0.006248
2021-12-10 12:23:57,436 iteration 4541 : loss : 0.022365, loss_ce: 0.009891
2021-12-10 12:23:58,928 iteration 4542 : loss : 0.031184, loss_ce: 0.010724
2021-12-10 12:24:00,444 iteration 4543 : loss : 0.029421, loss_ce: 0.011459
2021-12-10 12:24:01,942 iteration 4544 : loss : 0.021016, loss_ce: 0.007471
2021-12-10 12:24:03,553 iteration 4545 : loss : 0.022437, loss_ce: 0.009300
2021-12-10 12:24:05,214 iteration 4546 : loss : 0.027027, loss_ce: 0.012430
2021-12-10 12:24:06,862 iteration 4547 : loss : 0.020372, loss_ce: 0.007580
2021-12-10 12:24:08,338 iteration 4548 : loss : 0.024890, loss_ce: 0.009769
2021-12-10 12:24:09,827 iteration 4549 : loss : 0.019343, loss_ce: 0.005690
2021-12-10 12:24:11,372 iteration 4550 : loss : 0.036319, loss_ce: 0.018968
2021-12-10 12:24:12,948 iteration 4551 : loss : 0.030101, loss_ce: 0.012673
2021-12-10 12:24:14,593 iteration 4552 : loss : 0.027253, loss_ce: 0.007362
2021-12-10 12:24:16,156 iteration 4553 : loss : 0.019262, loss_ce: 0.006564
2021-12-10 12:24:17,652 iteration 4554 : loss : 0.024848, loss_ce: 0.011326
2021-12-10 12:24:19,175 iteration 4555 : loss : 0.021864, loss_ce: 0.008395
2021-12-10 12:24:20,706 iteration 4556 : loss : 0.040983, loss_ce: 0.016051
 67%|██████████████████         | 268/400 [2:08:32<1:02:08, 28.25s/it]2021-12-10 12:24:22,275 iteration 4557 : loss : 0.021888, loss_ce: 0.008970
2021-12-10 12:24:23,858 iteration 4558 : loss : 0.027145, loss_ce: 0.012541
2021-12-10 12:24:25,480 iteration 4559 : loss : 0.022681, loss_ce: 0.008671
2021-12-10 12:24:27,055 iteration 4560 : loss : 0.017234, loss_ce: 0.008723
2021-12-10 12:24:28,561 iteration 4561 : loss : 0.017077, loss_ce: 0.006109
2021-12-10 12:24:30,121 iteration 4562 : loss : 0.026738, loss_ce: 0.010740
2021-12-10 12:24:31,650 iteration 4563 : loss : 0.023365, loss_ce: 0.008485
2021-12-10 12:24:33,163 iteration 4564 : loss : 0.018319, loss_ce: 0.008077
2021-12-10 12:24:34,697 iteration 4565 : loss : 0.023537, loss_ce: 0.009858
2021-12-10 12:24:36,248 iteration 4566 : loss : 0.020060, loss_ce: 0.008592
2021-12-10 12:24:37,790 iteration 4567 : loss : 0.020100, loss_ce: 0.007982
2021-12-10 12:24:39,248 iteration 4568 : loss : 0.018328, loss_ce: 0.006035
2021-12-10 12:24:40,733 iteration 4569 : loss : 0.022109, loss_ce: 0.008936
2021-12-10 12:24:42,228 iteration 4570 : loss : 0.018950, loss_ce: 0.006823
2021-12-10 12:24:43,806 iteration 4571 : loss : 0.023133, loss_ce: 0.009752
2021-12-10 12:24:45,384 iteration 4572 : loss : 0.025798, loss_ce: 0.009266
2021-12-10 12:24:46,983 iteration 4573 : loss : 0.025202, loss_ce: 0.008655
 67%|██████████████████▏        | 269/400 [2:08:58<1:00:22, 27.65s/it]2021-12-10 12:24:48,517 iteration 4574 : loss : 0.013822, loss_ce: 0.004384
2021-12-10 12:24:50,089 iteration 4575 : loss : 0.018581, loss_ce: 0.005222
2021-12-10 12:24:51,561 iteration 4576 : loss : 0.025450, loss_ce: 0.009345
2021-12-10 12:24:53,046 iteration 4577 : loss : 0.018175, loss_ce: 0.008446
2021-12-10 12:24:54,586 iteration 4578 : loss : 0.018051, loss_ce: 0.007189
2021-12-10 12:24:56,079 iteration 4579 : loss : 0.019270, loss_ce: 0.008624
2021-12-10 12:24:57,591 iteration 4580 : loss : 0.019442, loss_ce: 0.007125
2021-12-10 12:24:59,132 iteration 4581 : loss : 0.026509, loss_ce: 0.011922
2021-12-10 12:25:00,667 iteration 4582 : loss : 0.025030, loss_ce: 0.011026
2021-12-10 12:25:02,197 iteration 4583 : loss : 0.018542, loss_ce: 0.007297
2021-12-10 12:25:03,716 iteration 4584 : loss : 0.016069, loss_ce: 0.005476
2021-12-10 12:25:05,269 iteration 4585 : loss : 0.025432, loss_ce: 0.008069
2021-12-10 12:25:06,755 iteration 4586 : loss : 0.018567, loss_ce: 0.007712
2021-12-10 12:25:08,266 iteration 4587 : loss : 0.018718, loss_ce: 0.005693
2021-12-10 12:25:09,771 iteration 4588 : loss : 0.023637, loss_ce: 0.009137
2021-12-10 12:25:11,331 iteration 4589 : loss : 0.028728, loss_ce: 0.007751
2021-12-10 12:25:11,331 Training Data Eval:
2021-12-10 12:25:19,073   Average segmentation loss on training set: 0.0134
2021-12-10 12:25:19,074 Validation Data Eval:
2021-12-10 12:25:21,730   Average segmentation loss on validation set: 0.0673
2021-12-10 12:25:23,253 iteration 4590 : loss : 0.022203, loss_ce: 0.009860
 68%|██████████████████▏        | 270/400 [2:09:34<1:05:31, 30.24s/it]2021-12-10 12:25:24,858 iteration 4591 : loss : 0.038180, loss_ce: 0.009528
2021-12-10 12:25:26,456 iteration 4592 : loss : 0.028132, loss_ce: 0.009417
2021-12-10 12:25:28,031 iteration 4593 : loss : 0.023389, loss_ce: 0.010698
2021-12-10 12:25:29,650 iteration 4594 : loss : 0.052780, loss_ce: 0.015951
2021-12-10 12:25:31,188 iteration 4595 : loss : 0.020905, loss_ce: 0.006668
2021-12-10 12:25:32,700 iteration 4596 : loss : 0.026905, loss_ce: 0.006970
2021-12-10 12:25:34,264 iteration 4597 : loss : 0.020658, loss_ce: 0.009486
2021-12-10 12:25:35,872 iteration 4598 : loss : 0.042714, loss_ce: 0.018259
2021-12-10 12:25:37,459 iteration 4599 : loss : 0.029511, loss_ce: 0.013888
2021-12-10 12:25:38,988 iteration 4600 : loss : 0.025022, loss_ce: 0.007692
2021-12-10 12:25:40,553 iteration 4601 : loss : 0.030901, loss_ce: 0.013270
2021-12-10 12:25:42,209 iteration 4602 : loss : 0.029916, loss_ce: 0.008721
2021-12-10 12:25:43,774 iteration 4603 : loss : 0.027923, loss_ce: 0.010500
2021-12-10 12:25:45,365 iteration 4604 : loss : 0.020626, loss_ce: 0.009733
2021-12-10 12:25:46,968 iteration 4605 : loss : 0.044731, loss_ce: 0.008094
2021-12-10 12:25:48,560 iteration 4606 : loss : 0.021004, loss_ce: 0.008411
2021-12-10 12:25:50,161 iteration 4607 : loss : 0.023826, loss_ce: 0.012390
 68%|██████████████████▎        | 271/400 [2:10:01<1:02:52, 29.24s/it]2021-12-10 12:25:51,725 iteration 4608 : loss : 0.018227, loss_ce: 0.007304
2021-12-10 12:25:53,274 iteration 4609 : loss : 0.026840, loss_ce: 0.011127
2021-12-10 12:25:54,767 iteration 4610 : loss : 0.023089, loss_ce: 0.007310
2021-12-10 12:25:56,255 iteration 4611 : loss : 0.025875, loss_ce: 0.010695
2021-12-10 12:25:57,710 iteration 4612 : loss : 0.017233, loss_ce: 0.005240
2021-12-10 12:25:59,265 iteration 4613 : loss : 0.026953, loss_ce: 0.009629
2021-12-10 12:26:00,814 iteration 4614 : loss : 0.018356, loss_ce: 0.008069
2021-12-10 12:26:02,415 iteration 4615 : loss : 0.027969, loss_ce: 0.010865
2021-12-10 12:26:04,089 iteration 4616 : loss : 0.022383, loss_ce: 0.008593
2021-12-10 12:26:05,661 iteration 4617 : loss : 0.034136, loss_ce: 0.011915
2021-12-10 12:26:07,168 iteration 4618 : loss : 0.015899, loss_ce: 0.004611
2021-12-10 12:26:08,681 iteration 4619 : loss : 0.017801, loss_ce: 0.006913
2021-12-10 12:26:10,292 iteration 4620 : loss : 0.024241, loss_ce: 0.007405
2021-12-10 12:26:11,835 iteration 4621 : loss : 0.034072, loss_ce: 0.018045
2021-12-10 12:26:13,397 iteration 4622 : loss : 0.033723, loss_ce: 0.011459
2021-12-10 12:26:14,957 iteration 4623 : loss : 0.017548, loss_ce: 0.005456
2021-12-10 12:26:16,511 iteration 4624 : loss : 0.023940, loss_ce: 0.009849
 68%|██████████████████▎        | 272/400 [2:10:27<1:00:31, 28.37s/it]2021-12-10 12:26:18,211 iteration 4625 : loss : 0.019972, loss_ce: 0.006775
2021-12-10 12:26:19,835 iteration 4626 : loss : 0.023098, loss_ce: 0.010621
2021-12-10 12:26:21,504 iteration 4627 : loss : 0.024849, loss_ce: 0.009440
2021-12-10 12:26:23,027 iteration 4628 : loss : 0.018805, loss_ce: 0.006821
2021-12-10 12:26:24,508 iteration 4629 : loss : 0.021679, loss_ce: 0.006691
2021-12-10 12:26:26,047 iteration 4630 : loss : 0.017781, loss_ce: 0.006464
2021-12-10 12:26:27,603 iteration 4631 : loss : 0.035113, loss_ce: 0.012939
2021-12-10 12:26:29,163 iteration 4632 : loss : 0.025994, loss_ce: 0.007514
2021-12-10 12:26:30,691 iteration 4633 : loss : 0.020998, loss_ce: 0.006742
2021-12-10 12:26:32,196 iteration 4634 : loss : 0.016693, loss_ce: 0.007584
2021-12-10 12:26:33,655 iteration 4635 : loss : 0.016712, loss_ce: 0.006720
2021-12-10 12:26:35,315 iteration 4636 : loss : 0.029604, loss_ce: 0.014342
2021-12-10 12:26:36,841 iteration 4637 : loss : 0.028877, loss_ce: 0.008918
2021-12-10 12:26:38,516 iteration 4638 : loss : 0.032478, loss_ce: 0.014731
2021-12-10 12:26:40,124 iteration 4639 : loss : 0.029260, loss_ce: 0.011934
2021-12-10 12:26:41,816 iteration 4640 : loss : 0.033860, loss_ce: 0.015609
2021-12-10 12:26:43,420 iteration 4641 : loss : 0.022301, loss_ce: 0.008282
 68%|███████████████████▊         | 273/400 [2:10:54<59:07, 27.93s/it]2021-12-10 12:26:44,999 iteration 4642 : loss : 0.022317, loss_ce: 0.004893
2021-12-10 12:26:46,554 iteration 4643 : loss : 0.020056, loss_ce: 0.007066
2021-12-10 12:26:48,167 iteration 4644 : loss : 0.022299, loss_ce: 0.007129
2021-12-10 12:26:49,800 iteration 4645 : loss : 0.024147, loss_ce: 0.011272
2021-12-10 12:26:51,385 iteration 4646 : loss : 0.028982, loss_ce: 0.008230
2021-12-10 12:26:52,858 iteration 4647 : loss : 0.017504, loss_ce: 0.005867
2021-12-10 12:26:54,381 iteration 4648 : loss : 0.038816, loss_ce: 0.012439
2021-12-10 12:26:55,951 iteration 4649 : loss : 0.024229, loss_ce: 0.010952
2021-12-10 12:26:57,572 iteration 4650 : loss : 0.034362, loss_ce: 0.009881
2021-12-10 12:26:59,067 iteration 4651 : loss : 0.027017, loss_ce: 0.012760
2021-12-10 12:27:00,709 iteration 4652 : loss : 0.035516, loss_ce: 0.014970
2021-12-10 12:27:02,240 iteration 4653 : loss : 0.023628, loss_ce: 0.010439
2021-12-10 12:27:03,772 iteration 4654 : loss : 0.023312, loss_ce: 0.006648
2021-12-10 12:27:05,390 iteration 4655 : loss : 0.027829, loss_ce: 0.010629
2021-12-10 12:27:07,006 iteration 4656 : loss : 0.073323, loss_ce: 0.029622
2021-12-10 12:27:08,609 iteration 4657 : loss : 0.043835, loss_ce: 0.019119
2021-12-10 12:27:10,210 iteration 4658 : loss : 0.051825, loss_ce: 0.028056
 68%|███████████████████▊         | 274/400 [2:11:21<57:56, 27.59s/it]2021-12-10 12:27:11,839 iteration 4659 : loss : 0.026934, loss_ce: 0.011480
2021-12-10 12:27:13,455 iteration 4660 : loss : 0.036357, loss_ce: 0.014688
2021-12-10 12:27:15,038 iteration 4661 : loss : 0.035283, loss_ce: 0.015617
2021-12-10 12:27:16,539 iteration 4662 : loss : 0.022697, loss_ce: 0.008756
2021-12-10 12:27:18,112 iteration 4663 : loss : 0.026716, loss_ce: 0.010048
2021-12-10 12:27:19,640 iteration 4664 : loss : 0.024346, loss_ce: 0.009660
2021-12-10 12:27:21,178 iteration 4665 : loss : 0.027734, loss_ce: 0.011697
2021-12-10 12:27:22,618 iteration 4666 : loss : 0.017675, loss_ce: 0.006069
2021-12-10 12:27:24,126 iteration 4667 : loss : 0.017216, loss_ce: 0.006993
2021-12-10 12:27:25,805 iteration 4668 : loss : 0.032393, loss_ce: 0.016578
2021-12-10 12:27:27,305 iteration 4669 : loss : 0.023712, loss_ce: 0.012937
2021-12-10 12:27:28,816 iteration 4670 : loss : 0.025742, loss_ce: 0.009927
2021-12-10 12:27:30,306 iteration 4671 : loss : 0.023533, loss_ce: 0.007879
2021-12-10 12:27:31,960 iteration 4672 : loss : 0.043579, loss_ce: 0.019084
2021-12-10 12:27:33,574 iteration 4673 : loss : 0.033213, loss_ce: 0.014441
2021-12-10 12:27:35,058 iteration 4674 : loss : 0.019158, loss_ce: 0.005592
2021-12-10 12:27:35,059 Training Data Eval:
2021-12-10 12:27:42,801   Average segmentation loss on training set: 0.0202
2021-12-10 12:27:42,801 Validation Data Eval:
2021-12-10 12:27:45,457   Average segmentation loss on validation set: 0.0828
2021-12-10 12:27:47,063 iteration 4675 : loss : 0.027510, loss_ce: 0.012612
 69%|██████████████████▌        | 275/400 [2:11:58<1:03:16, 30.37s/it]2021-12-10 12:27:48,759 iteration 4676 : loss : 0.025264, loss_ce: 0.009199
2021-12-10 12:27:50,291 iteration 4677 : loss : 0.021430, loss_ce: 0.007317
2021-12-10 12:27:51,870 iteration 4678 : loss : 0.029245, loss_ce: 0.009137
2021-12-10 12:27:53,497 iteration 4679 : loss : 0.040307, loss_ce: 0.011512
2021-12-10 12:27:55,047 iteration 4680 : loss : 0.019329, loss_ce: 0.007377
2021-12-10 12:27:56,587 iteration 4681 : loss : 0.053569, loss_ce: 0.014519
2021-12-10 12:27:58,112 iteration 4682 : loss : 0.023701, loss_ce: 0.009093
2021-12-10 12:27:59,554 iteration 4683 : loss : 0.023453, loss_ce: 0.006846
2021-12-10 12:28:01,157 iteration 4684 : loss : 0.023029, loss_ce: 0.010317
2021-12-10 12:28:02,743 iteration 4685 : loss : 0.041287, loss_ce: 0.014086
2021-12-10 12:28:04,285 iteration 4686 : loss : 0.027323, loss_ce: 0.007924
2021-12-10 12:28:05,806 iteration 4687 : loss : 0.020860, loss_ce: 0.010468
2021-12-10 12:28:07,266 iteration 4688 : loss : 0.019867, loss_ce: 0.008190
2021-12-10 12:28:08,741 iteration 4689 : loss : 0.014249, loss_ce: 0.006252
2021-12-10 12:28:10,238 iteration 4690 : loss : 0.023138, loss_ce: 0.009815
2021-12-10 12:28:11,826 iteration 4691 : loss : 0.032726, loss_ce: 0.018981
2021-12-10 12:28:13,351 iteration 4692 : loss : 0.021347, loss_ce: 0.006480
 69%|██████████████████▋        | 276/400 [2:12:24<1:00:13, 29.14s/it]2021-12-10 12:28:15,002 iteration 4693 : loss : 0.031051, loss_ce: 0.011057
2021-12-10 12:28:16,580 iteration 4694 : loss : 0.035872, loss_ce: 0.012409
2021-12-10 12:28:17,998 iteration 4695 : loss : 0.016715, loss_ce: 0.005507
2021-12-10 12:28:19,619 iteration 4696 : loss : 0.036401, loss_ce: 0.016406
2021-12-10 12:28:21,135 iteration 4697 : loss : 0.026594, loss_ce: 0.009117
2021-12-10 12:28:22,688 iteration 4698 : loss : 0.026055, loss_ce: 0.013393
2021-12-10 12:28:24,300 iteration 4699 : loss : 0.024454, loss_ce: 0.012186
2021-12-10 12:28:25,801 iteration 4700 : loss : 0.018730, loss_ce: 0.008710
2021-12-10 12:28:27,454 iteration 4701 : loss : 0.025461, loss_ce: 0.009488
2021-12-10 12:28:28,984 iteration 4702 : loss : 0.020178, loss_ce: 0.008711
2021-12-10 12:28:30,494 iteration 4703 : loss : 0.024613, loss_ce: 0.006362
2021-12-10 12:28:32,042 iteration 4704 : loss : 0.029600, loss_ce: 0.009824
2021-12-10 12:28:33,454 iteration 4705 : loss : 0.015544, loss_ce: 0.006823
2021-12-10 12:28:34,997 iteration 4706 : loss : 0.028022, loss_ce: 0.006948
2021-12-10 12:28:36,598 iteration 4707 : loss : 0.021396, loss_ce: 0.009798
2021-12-10 12:28:38,223 iteration 4708 : loss : 0.018093, loss_ce: 0.005702
2021-12-10 12:28:39,813 iteration 4709 : loss : 0.027403, loss_ce: 0.008883
 69%|████████████████████         | 277/400 [2:12:51<58:06, 28.34s/it]2021-12-10 12:28:41,448 iteration 4710 : loss : 0.036800, loss_ce: 0.007315
2021-12-10 12:28:43,149 iteration 4711 : loss : 0.030653, loss_ce: 0.011991
2021-12-10 12:28:44,680 iteration 4712 : loss : 0.026660, loss_ce: 0.011116
2021-12-10 12:28:46,226 iteration 4713 : loss : 0.020915, loss_ce: 0.008163
2021-12-10 12:28:47,794 iteration 4714 : loss : 0.027277, loss_ce: 0.009635
2021-12-10 12:28:49,417 iteration 4715 : loss : 0.026075, loss_ce: 0.009710
2021-12-10 12:28:50,994 iteration 4716 : loss : 0.025486, loss_ce: 0.011007
2021-12-10 12:28:52,535 iteration 4717 : loss : 0.023381, loss_ce: 0.009148
2021-12-10 12:28:54,018 iteration 4718 : loss : 0.016243, loss_ce: 0.005876
2021-12-10 12:28:55,502 iteration 4719 : loss : 0.019321, loss_ce: 0.009258
2021-12-10 12:28:57,006 iteration 4720 : loss : 0.018299, loss_ce: 0.007254
2021-12-10 12:28:58,537 iteration 4721 : loss : 0.023391, loss_ce: 0.009831
2021-12-10 12:29:00,140 iteration 4722 : loss : 0.030818, loss_ce: 0.008902
2021-12-10 12:29:01,685 iteration 4723 : loss : 0.019287, loss_ce: 0.007324
2021-12-10 12:29:03,161 iteration 4724 : loss : 0.017682, loss_ce: 0.006804
2021-12-10 12:29:04,636 iteration 4725 : loss : 0.019806, loss_ce: 0.008152
2021-12-10 12:29:06,179 iteration 4726 : loss : 0.021725, loss_ce: 0.008546
 70%|████████████████████▏        | 278/400 [2:13:17<56:25, 27.75s/it]2021-12-10 12:29:07,847 iteration 4727 : loss : 0.028221, loss_ce: 0.008880
2021-12-10 12:29:09,338 iteration 4728 : loss : 0.021441, loss_ce: 0.007995
2021-12-10 12:29:10,839 iteration 4729 : loss : 0.018070, loss_ce: 0.006528
2021-12-10 12:29:12,344 iteration 4730 : loss : 0.017837, loss_ce: 0.005530
2021-12-10 12:29:13,942 iteration 4731 : loss : 0.021231, loss_ce: 0.007536
2021-12-10 12:29:15,499 iteration 4732 : loss : 0.023225, loss_ce: 0.007107
2021-12-10 12:29:17,048 iteration 4733 : loss : 0.018512, loss_ce: 0.007914
2021-12-10 12:29:18,569 iteration 4734 : loss : 0.018757, loss_ce: 0.007167
2021-12-10 12:29:20,211 iteration 4735 : loss : 0.036681, loss_ce: 0.011170
2021-12-10 12:29:21,687 iteration 4736 : loss : 0.026464, loss_ce: 0.010991
2021-12-10 12:29:23,316 iteration 4737 : loss : 0.039128, loss_ce: 0.014242
2021-12-10 12:29:24,862 iteration 4738 : loss : 0.025045, loss_ce: 0.008755
2021-12-10 12:29:26,404 iteration 4739 : loss : 0.023568, loss_ce: 0.008838
2021-12-10 12:29:27,999 iteration 4740 : loss : 0.023993, loss_ce: 0.010565
2021-12-10 12:29:29,522 iteration 4741 : loss : 0.018621, loss_ce: 0.006103
2021-12-10 12:29:31,057 iteration 4742 : loss : 0.023876, loss_ce: 0.011254
2021-12-10 12:29:32,697 iteration 4743 : loss : 0.025506, loss_ce: 0.009158
 70%|████████████████████▏        | 279/400 [2:13:44<55:12, 27.38s/it]2021-12-10 12:29:34,349 iteration 4744 : loss : 0.028194, loss_ce: 0.009107
2021-12-10 12:29:35,905 iteration 4745 : loss : 0.042798, loss_ce: 0.013768
2021-12-10 12:29:37,408 iteration 4746 : loss : 0.020792, loss_ce: 0.010574
2021-12-10 12:29:38,930 iteration 4747 : loss : 0.023733, loss_ce: 0.007280
2021-12-10 12:29:40,485 iteration 4748 : loss : 0.029109, loss_ce: 0.010384
2021-12-10 12:29:42,054 iteration 4749 : loss : 0.023223, loss_ce: 0.007393
2021-12-10 12:29:43,656 iteration 4750 : loss : 0.021183, loss_ce: 0.007801
2021-12-10 12:29:45,182 iteration 4751 : loss : 0.030195, loss_ce: 0.011420
2021-12-10 12:29:46,763 iteration 4752 : loss : 0.020216, loss_ce: 0.007431
2021-12-10 12:29:48,366 iteration 4753 : loss : 0.021684, loss_ce: 0.007977
2021-12-10 12:29:49,943 iteration 4754 : loss : 0.019420, loss_ce: 0.007024
2021-12-10 12:29:51,611 iteration 4755 : loss : 0.024533, loss_ce: 0.008022
2021-12-10 12:29:53,166 iteration 4756 : loss : 0.018780, loss_ce: 0.008995
2021-12-10 12:29:54,698 iteration 4757 : loss : 0.029761, loss_ce: 0.012269
2021-12-10 12:29:56,210 iteration 4758 : loss : 0.021652, loss_ce: 0.006498
2021-12-10 12:29:57,754 iteration 4759 : loss : 0.014154, loss_ce: 0.004943
2021-12-10 12:29:57,754 Training Data Eval:
2021-12-10 12:30:05,499   Average segmentation loss on training set: 0.0148
2021-12-10 12:30:05,499 Validation Data Eval:
2021-12-10 12:30:08,155   Average segmentation loss on validation set: 0.1028
2021-12-10 12:30:09,667 iteration 4760 : loss : 0.023903, loss_ce: 0.009479
 70%|██████████████████▉        | 280/400 [2:14:21<1:00:31, 30.26s/it]2021-12-10 12:30:11,258 iteration 4761 : loss : 0.018677, loss_ce: 0.006405
2021-12-10 12:30:12,843 iteration 4762 : loss : 0.035285, loss_ce: 0.013245
2021-12-10 12:30:14,330 iteration 4763 : loss : 0.018103, loss_ce: 0.006895
2021-12-10 12:30:15,911 iteration 4764 : loss : 0.018157, loss_ce: 0.007103
2021-12-10 12:30:17,440 iteration 4765 : loss : 0.027091, loss_ce: 0.012010
2021-12-10 12:30:19,061 iteration 4766 : loss : 0.025454, loss_ce: 0.009501
2021-12-10 12:30:20,634 iteration 4767 : loss : 0.020217, loss_ce: 0.008127
2021-12-10 12:30:22,136 iteration 4768 : loss : 0.022119, loss_ce: 0.007527
2021-12-10 12:30:23,728 iteration 4769 : loss : 0.035713, loss_ce: 0.018153
2021-12-10 12:30:25,320 iteration 4770 : loss : 0.020796, loss_ce: 0.007365
2021-12-10 12:30:26,805 iteration 4771 : loss : 0.017424, loss_ce: 0.005925
2021-12-10 12:30:28,410 iteration 4772 : loss : 0.020933, loss_ce: 0.008395
2021-12-10 12:30:29,995 iteration 4773 : loss : 0.020188, loss_ce: 0.007323
2021-12-10 12:30:31,573 iteration 4774 : loss : 0.031713, loss_ce: 0.016710
2021-12-10 12:30:33,088 iteration 4775 : loss : 0.027812, loss_ce: 0.008105
2021-12-10 12:30:34,630 iteration 4776 : loss : 0.030623, loss_ce: 0.020185
2021-12-10 12:30:36,332 iteration 4777 : loss : 0.019564, loss_ce: 0.008510
 70%|████████████████████▎        | 281/400 [2:14:47<57:52, 29.18s/it]2021-12-10 12:30:37,854 iteration 4778 : loss : 0.013565, loss_ce: 0.003872
2021-12-10 12:30:39,378 iteration 4779 : loss : 0.022529, loss_ce: 0.008513
2021-12-10 12:30:40,850 iteration 4780 : loss : 0.016826, loss_ce: 0.006114
2021-12-10 12:30:42,370 iteration 4781 : loss : 0.025841, loss_ce: 0.008215
2021-12-10 12:30:43,975 iteration 4782 : loss : 0.026851, loss_ce: 0.012119
2021-12-10 12:30:45,526 iteration 4783 : loss : 0.013338, loss_ce: 0.006270
2021-12-10 12:30:47,013 iteration 4784 : loss : 0.019030, loss_ce: 0.007626
2021-12-10 12:30:48,636 iteration 4785 : loss : 0.024222, loss_ce: 0.010140
2021-12-10 12:30:50,217 iteration 4786 : loss : 0.021081, loss_ce: 0.008542
2021-12-10 12:30:51,798 iteration 4787 : loss : 0.025504, loss_ce: 0.008366
2021-12-10 12:30:53,389 iteration 4788 : loss : 0.021965, loss_ce: 0.008143
2021-12-10 12:30:54,875 iteration 4789 : loss : 0.018061, loss_ce: 0.009497
2021-12-10 12:30:56,532 iteration 4790 : loss : 0.029683, loss_ce: 0.009647
2021-12-10 12:30:58,061 iteration 4791 : loss : 0.025441, loss_ce: 0.011454
2021-12-10 12:30:59,661 iteration 4792 : loss : 0.032333, loss_ce: 0.009785
2021-12-10 12:31:01,168 iteration 4793 : loss : 0.018294, loss_ce: 0.006993
2021-12-10 12:31:02,630 iteration 4794 : loss : 0.024117, loss_ce: 0.007766
 70%|████████████████████▍        | 282/400 [2:15:14<55:41, 28.31s/it]2021-12-10 12:31:04,256 iteration 4795 : loss : 0.025931, loss_ce: 0.008105
2021-12-10 12:31:05,817 iteration 4796 : loss : 0.015883, loss_ce: 0.005819
2021-12-10 12:31:07,409 iteration 4797 : loss : 0.034409, loss_ce: 0.013135
2021-12-10 12:31:09,035 iteration 4798 : loss : 0.030875, loss_ce: 0.009323
2021-12-10 12:31:10,592 iteration 4799 : loss : 0.015108, loss_ce: 0.004920
2021-12-10 12:31:12,150 iteration 4800 : loss : 0.029686, loss_ce: 0.008284
2021-12-10 12:31:13,789 iteration 4801 : loss : 0.022184, loss_ce: 0.009263
2021-12-10 12:31:15,267 iteration 4802 : loss : 0.014879, loss_ce: 0.005990
2021-12-10 12:31:16,791 iteration 4803 : loss : 0.017033, loss_ce: 0.007709
2021-12-10 12:31:18,413 iteration 4804 : loss : 0.046900, loss_ce: 0.010436
2021-12-10 12:31:20,026 iteration 4805 : loss : 0.026846, loss_ce: 0.009452
2021-12-10 12:31:21,653 iteration 4806 : loss : 0.024957, loss_ce: 0.009811
2021-12-10 12:31:23,130 iteration 4807 : loss : 0.023069, loss_ce: 0.009848
2021-12-10 12:31:24,597 iteration 4808 : loss : 0.017090, loss_ce: 0.007748
2021-12-10 12:31:26,165 iteration 4809 : loss : 0.029167, loss_ce: 0.014656
2021-12-10 12:31:27,715 iteration 4810 : loss : 0.028867, loss_ce: 0.008654
2021-12-10 12:31:29,281 iteration 4811 : loss : 0.020626, loss_ce: 0.007159
 71%|████████████████████▌        | 283/400 [2:15:40<54:13, 27.81s/it]2021-12-10 12:31:30,816 iteration 4812 : loss : 0.019571, loss_ce: 0.007642
2021-12-10 12:31:32,379 iteration 4813 : loss : 0.022658, loss_ce: 0.005598
2021-12-10 12:31:33,976 iteration 4814 : loss : 0.031651, loss_ce: 0.007944
2021-12-10 12:31:35,462 iteration 4815 : loss : 0.018676, loss_ce: 0.007475
2021-12-10 12:31:37,127 iteration 4816 : loss : 0.032830, loss_ce: 0.012971
2021-12-10 12:31:38,667 iteration 4817 : loss : 0.027381, loss_ce: 0.009214
2021-12-10 12:31:40,189 iteration 4818 : loss : 0.021312, loss_ce: 0.008758
2021-12-10 12:31:41,647 iteration 4819 : loss : 0.025965, loss_ce: 0.009952
2021-12-10 12:31:43,159 iteration 4820 : loss : 0.020654, loss_ce: 0.007833
2021-12-10 12:31:44,810 iteration 4821 : loss : 0.039473, loss_ce: 0.020397
2021-12-10 12:31:46,447 iteration 4822 : loss : 0.035666, loss_ce: 0.011618
2021-12-10 12:31:47,997 iteration 4823 : loss : 0.022059, loss_ce: 0.009801
2021-12-10 12:31:49,579 iteration 4824 : loss : 0.027993, loss_ce: 0.013027
2021-12-10 12:31:51,100 iteration 4825 : loss : 0.022943, loss_ce: 0.008763
2021-12-10 12:31:52,619 iteration 4826 : loss : 0.019795, loss_ce: 0.005847
2021-12-10 12:31:54,149 iteration 4827 : loss : 0.017973, loss_ce: 0.007192
2021-12-10 12:31:55,665 iteration 4828 : loss : 0.021466, loss_ce: 0.008685
 71%|████████████████████▌        | 284/400 [2:16:07<52:56, 27.39s/it]2021-12-10 12:31:57,196 iteration 4829 : loss : 0.023885, loss_ce: 0.009634
2021-12-10 12:31:58,778 iteration 4830 : loss : 0.018541, loss_ce: 0.007920
2021-12-10 12:32:00,344 iteration 4831 : loss : 0.022780, loss_ce: 0.009616
2021-12-10 12:32:01,883 iteration 4832 : loss : 0.032731, loss_ce: 0.011413
2021-12-10 12:32:03,474 iteration 4833 : loss : 0.029149, loss_ce: 0.011122
2021-12-10 12:32:04,953 iteration 4834 : loss : 0.016805, loss_ce: 0.005737
2021-12-10 12:32:06,617 iteration 4835 : loss : 0.028640, loss_ce: 0.014134
2021-12-10 12:32:08,179 iteration 4836 : loss : 0.037834, loss_ce: 0.009785
2021-12-10 12:32:09,779 iteration 4837 : loss : 0.025248, loss_ce: 0.006759
2021-12-10 12:32:11,299 iteration 4838 : loss : 0.017329, loss_ce: 0.005551
2021-12-10 12:32:12,876 iteration 4839 : loss : 0.025154, loss_ce: 0.009768
2021-12-10 12:32:14,432 iteration 4840 : loss : 0.019092, loss_ce: 0.008800
2021-12-10 12:32:15,910 iteration 4841 : loss : 0.014665, loss_ce: 0.005155
2021-12-10 12:32:17,463 iteration 4842 : loss : 0.019969, loss_ce: 0.006829
2021-12-10 12:32:19,109 iteration 4843 : loss : 0.028649, loss_ce: 0.010248
2021-12-10 12:32:20,658 iteration 4844 : loss : 0.031147, loss_ce: 0.011991
2021-12-10 12:32:20,658 Training Data Eval:
2021-12-10 12:32:28,396   Average segmentation loss on training set: 0.0140
2021-12-10 12:32:28,396 Validation Data Eval:
2021-12-10 12:32:31,060   Average segmentation loss on validation set: 0.0799
2021-12-10 12:32:32,661 iteration 4845 : loss : 0.027750, loss_ce: 0.012668
 71%|████████████████████▋        | 285/400 [2:16:44<58:00, 30.27s/it]2021-12-10 12:32:34,217 iteration 4846 : loss : 0.023358, loss_ce: 0.009384
2021-12-10 12:32:35,731 iteration 4847 : loss : 0.031899, loss_ce: 0.010361
2021-12-10 12:32:37,340 iteration 4848 : loss : 0.028081, loss_ce: 0.013835
2021-12-10 12:32:38,925 iteration 4849 : loss : 0.026587, loss_ce: 0.009177
2021-12-10 12:32:40,445 iteration 4850 : loss : 0.020170, loss_ce: 0.006119
2021-12-10 12:32:42,112 iteration 4851 : loss : 0.021489, loss_ce: 0.009675
2021-12-10 12:32:43,651 iteration 4852 : loss : 0.017515, loss_ce: 0.006025
2021-12-10 12:32:45,209 iteration 4853 : loss : 0.024428, loss_ce: 0.011473
2021-12-10 12:32:46,772 iteration 4854 : loss : 0.019478, loss_ce: 0.007818
2021-12-10 12:32:48,290 iteration 4855 : loss : 0.030813, loss_ce: 0.009219
2021-12-10 12:32:49,943 iteration 4856 : loss : 0.042041, loss_ce: 0.017441
2021-12-10 12:32:51,464 iteration 4857 : loss : 0.018188, loss_ce: 0.006676
2021-12-10 12:32:53,102 iteration 4858 : loss : 0.021893, loss_ce: 0.007883
2021-12-10 12:32:54,589 iteration 4859 : loss : 0.014789, loss_ce: 0.006385
2021-12-10 12:32:56,180 iteration 4860 : loss : 0.020008, loss_ce: 0.008511
2021-12-10 12:32:57,698 iteration 4861 : loss : 0.028257, loss_ce: 0.010479
2021-12-10 12:32:59,292 iteration 4862 : loss : 0.021518, loss_ce: 0.010623
 72%|████████████████████▋        | 286/400 [2:17:10<55:25, 29.18s/it]2021-12-10 12:33:00,975 iteration 4863 : loss : 0.023806, loss_ce: 0.007229
2021-12-10 12:33:02,536 iteration 4864 : loss : 0.018484, loss_ce: 0.007326
2021-12-10 12:33:04,063 iteration 4865 : loss : 0.018643, loss_ce: 0.009188
2021-12-10 12:33:05,679 iteration 4866 : loss : 0.026508, loss_ce: 0.007478
2021-12-10 12:33:07,233 iteration 4867 : loss : 0.021945, loss_ce: 0.007363
2021-12-10 12:33:08,682 iteration 4868 : loss : 0.021802, loss_ce: 0.008622
2021-12-10 12:33:10,329 iteration 4869 : loss : 0.043502, loss_ce: 0.020763
2021-12-10 12:33:11,875 iteration 4870 : loss : 0.015897, loss_ce: 0.005786
2021-12-10 12:33:13,536 iteration 4871 : loss : 0.038061, loss_ce: 0.015020
2021-12-10 12:33:15,014 iteration 4872 : loss : 0.014925, loss_ce: 0.004915
2021-12-10 12:33:16,665 iteration 4873 : loss : 0.020184, loss_ce: 0.007807
2021-12-10 12:33:18,252 iteration 4874 : loss : 0.032910, loss_ce: 0.010608
2021-12-10 12:33:19,791 iteration 4875 : loss : 0.024395, loss_ce: 0.010816
2021-12-10 12:33:21,249 iteration 4876 : loss : 0.022225, loss_ce: 0.007197
2021-12-10 12:33:22,856 iteration 4877 : loss : 0.026051, loss_ce: 0.013401
2021-12-10 12:33:24,496 iteration 4878 : loss : 0.034077, loss_ce: 0.011160
2021-12-10 12:33:26,046 iteration 4879 : loss : 0.015640, loss_ce: 0.005563
 72%|████████████████████▊        | 287/400 [2:17:37<53:35, 28.45s/it]2021-12-10 12:33:27,626 iteration 4880 : loss : 0.022588, loss_ce: 0.008898
2021-12-10 12:33:29,113 iteration 4881 : loss : 0.018782, loss_ce: 0.007710
2021-12-10 12:33:30,561 iteration 4882 : loss : 0.015573, loss_ce: 0.006869
2021-12-10 12:33:32,134 iteration 4883 : loss : 0.024364, loss_ce: 0.010120
2021-12-10 12:33:33,723 iteration 4884 : loss : 0.053523, loss_ce: 0.017036
2021-12-10 12:33:35,158 iteration 4885 : loss : 0.015525, loss_ce: 0.006197
2021-12-10 12:33:36,697 iteration 4886 : loss : 0.030290, loss_ce: 0.008402
2021-12-10 12:33:38,173 iteration 4887 : loss : 0.016699, loss_ce: 0.005266
2021-12-10 12:33:39,744 iteration 4888 : loss : 0.023237, loss_ce: 0.006917
2021-12-10 12:33:41,295 iteration 4889 : loss : 0.048093, loss_ce: 0.030351
2021-12-10 12:33:42,792 iteration 4890 : loss : 0.019008, loss_ce: 0.010011
2021-12-10 12:33:44,217 iteration 4891 : loss : 0.013864, loss_ce: 0.005119
2021-12-10 12:33:45,825 iteration 4892 : loss : 0.019563, loss_ce: 0.007684
2021-12-10 12:33:47,376 iteration 4893 : loss : 0.022931, loss_ce: 0.009995
2021-12-10 12:33:48,907 iteration 4894 : loss : 0.018780, loss_ce: 0.008691
2021-12-10 12:33:50,425 iteration 4895 : loss : 0.034690, loss_ce: 0.011167
2021-12-10 12:33:51,923 iteration 4896 : loss : 0.027559, loss_ce: 0.008669
 72%|████████████████████▉        | 288/400 [2:18:03<51:40, 27.68s/it]2021-12-10 12:33:53,494 iteration 4897 : loss : 0.017982, loss_ce: 0.007536
2021-12-10 12:33:55,106 iteration 4898 : loss : 0.026785, loss_ce: 0.013027
2021-12-10 12:33:56,649 iteration 4899 : loss : 0.015579, loss_ce: 0.005224
2021-12-10 12:33:58,154 iteration 4900 : loss : 0.024149, loss_ce: 0.008995
2021-12-10 12:33:59,677 iteration 4901 : loss : 0.032578, loss_ce: 0.010755
2021-12-10 12:34:01,200 iteration 4902 : loss : 0.021714, loss_ce: 0.008011
2021-12-10 12:34:02,766 iteration 4903 : loss : 0.025701, loss_ce: 0.012245
2021-12-10 12:34:04,202 iteration 4904 : loss : 0.018805, loss_ce: 0.005015
2021-12-10 12:34:05,694 iteration 4905 : loss : 0.021733, loss_ce: 0.006930
2021-12-10 12:34:07,261 iteration 4906 : loss : 0.021785, loss_ce: 0.007808
2021-12-10 12:34:08,759 iteration 4907 : loss : 0.023383, loss_ce: 0.010173
2021-12-10 12:34:10,378 iteration 4908 : loss : 0.022407, loss_ce: 0.010217
2021-12-10 12:34:11,955 iteration 4909 : loss : 0.020339, loss_ce: 0.006645
2021-12-10 12:34:13,450 iteration 4910 : loss : 0.020574, loss_ce: 0.009465
2021-12-10 12:34:14,960 iteration 4911 : loss : 0.015235, loss_ce: 0.005887
2021-12-10 12:34:16,508 iteration 4912 : loss : 0.020006, loss_ce: 0.009632
2021-12-10 12:34:18,042 iteration 4913 : loss : 0.029346, loss_ce: 0.011366
 72%|████████████████████▉        | 289/400 [2:18:29<50:20, 27.21s/it]2021-12-10 12:34:19,677 iteration 4914 : loss : 0.024065, loss_ce: 0.009698
2021-12-10 12:34:21,176 iteration 4915 : loss : 0.030580, loss_ce: 0.011884
2021-12-10 12:34:22,690 iteration 4916 : loss : 0.016468, loss_ce: 0.004420
2021-12-10 12:34:24,239 iteration 4917 : loss : 0.017230, loss_ce: 0.005326
2021-12-10 12:34:25,809 iteration 4918 : loss : 0.022081, loss_ce: 0.008184
2021-12-10 12:34:27,485 iteration 4919 : loss : 0.042134, loss_ce: 0.018141
2021-12-10 12:34:29,020 iteration 4920 : loss : 0.018967, loss_ce: 0.008392
2021-12-10 12:34:30,520 iteration 4921 : loss : 0.016731, loss_ce: 0.008342
2021-12-10 12:34:31,996 iteration 4922 : loss : 0.015770, loss_ce: 0.004157
2021-12-10 12:34:33,591 iteration 4923 : loss : 0.028036, loss_ce: 0.010218
2021-12-10 12:34:35,214 iteration 4924 : loss : 0.044924, loss_ce: 0.028881
2021-12-10 12:34:36,780 iteration 4925 : loss : 0.026368, loss_ce: 0.010784
2021-12-10 12:34:38,388 iteration 4926 : loss : 0.024599, loss_ce: 0.010694
2021-12-10 12:34:39,909 iteration 4927 : loss : 0.017347, loss_ce: 0.005792
2021-12-10 12:34:41,519 iteration 4928 : loss : 0.027197, loss_ce: 0.009857
2021-12-10 12:34:43,168 iteration 4929 : loss : 0.031224, loss_ce: 0.017338
2021-12-10 12:34:43,168 Training Data Eval:
2021-12-10 12:34:50,914   Average segmentation loss on training set: 0.0134
2021-12-10 12:34:50,915 Validation Data Eval:
2021-12-10 12:34:53,584   Average segmentation loss on validation set: 0.0603
2021-12-10 12:34:59,412 Found new lowest validation loss at iteration 4929! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_best_val_loss_seed1234.pth
2021-12-10 12:35:01,005 iteration 4930 : loss : 0.029045, loss_ce: 0.008365
 72%|█████████████████████        | 290/400 [2:19:12<58:32, 31.93s/it]2021-12-10 12:35:02,576 iteration 4931 : loss : 0.032189, loss_ce: 0.016901
2021-12-10 12:35:04,148 iteration 4932 : loss : 0.020747, loss_ce: 0.010129
2021-12-10 12:35:05,625 iteration 4933 : loss : 0.017002, loss_ce: 0.008402
2021-12-10 12:35:07,269 iteration 4934 : loss : 0.026857, loss_ce: 0.009296
2021-12-10 12:35:08,817 iteration 4935 : loss : 0.029311, loss_ce: 0.010010
2021-12-10 12:35:10,422 iteration 4936 : loss : 0.016212, loss_ce: 0.005841
2021-12-10 12:35:11,986 iteration 4937 : loss : 0.017270, loss_ce: 0.007643
2021-12-10 12:35:13,597 iteration 4938 : loss : 0.031682, loss_ce: 0.011331
2021-12-10 12:35:15,204 iteration 4939 : loss : 0.034994, loss_ce: 0.013923
2021-12-10 12:35:16,733 iteration 4940 : loss : 0.023784, loss_ce: 0.009861
2021-12-10 12:35:18,302 iteration 4941 : loss : 0.021067, loss_ce: 0.009258
2021-12-10 12:35:19,865 iteration 4942 : loss : 0.020662, loss_ce: 0.006667
2021-12-10 12:35:21,523 iteration 4943 : loss : 0.034851, loss_ce: 0.008041
2021-12-10 12:35:23,076 iteration 4944 : loss : 0.033104, loss_ce: 0.009215
2021-12-10 12:35:24,682 iteration 4945 : loss : 0.019239, loss_ce: 0.007248
2021-12-10 12:35:26,301 iteration 4946 : loss : 0.025188, loss_ce: 0.007784
2021-12-10 12:35:27,832 iteration 4947 : loss : 0.023847, loss_ce: 0.008159
 73%|█████████████████████        | 291/400 [2:19:39<55:13, 30.40s/it]2021-12-10 12:35:29,457 iteration 4948 : loss : 0.033074, loss_ce: 0.012686
2021-12-10 12:35:30,991 iteration 4949 : loss : 0.024156, loss_ce: 0.009993
2021-12-10 12:35:32,592 iteration 4950 : loss : 0.025885, loss_ce: 0.010414
2021-12-10 12:35:34,177 iteration 4951 : loss : 0.017680, loss_ce: 0.005763
2021-12-10 12:35:35,759 iteration 4952 : loss : 0.017876, loss_ce: 0.010549
2021-12-10 12:35:37,369 iteration 4953 : loss : 0.021045, loss_ce: 0.010152
2021-12-10 12:35:38,896 iteration 4954 : loss : 0.015744, loss_ce: 0.004934
2021-12-10 12:35:40,379 iteration 4955 : loss : 0.027613, loss_ce: 0.007697
2021-12-10 12:35:41,919 iteration 4956 : loss : 0.021636, loss_ce: 0.007728
2021-12-10 12:35:43,372 iteration 4957 : loss : 0.016228, loss_ce: 0.006517
2021-12-10 12:35:44,934 iteration 4958 : loss : 0.023721, loss_ce: 0.012785
2021-12-10 12:35:46,491 iteration 4959 : loss : 0.021967, loss_ce: 0.008706
2021-12-10 12:35:47,964 iteration 4960 : loss : 0.018317, loss_ce: 0.006921
2021-12-10 12:35:49,532 iteration 4961 : loss : 0.019154, loss_ce: 0.007596
2021-12-10 12:35:51,021 iteration 4962 : loss : 0.020830, loss_ce: 0.004360
2021-12-10 12:35:52,544 iteration 4963 : loss : 0.017982, loss_ce: 0.006654
2021-12-10 12:35:54,149 iteration 4964 : loss : 0.026913, loss_ce: 0.009596
 73%|█████████████████████▏       | 292/400 [2:20:05<52:31, 29.18s/it]2021-12-10 12:35:55,813 iteration 4965 : loss : 0.021925, loss_ce: 0.008929
2021-12-10 12:35:57,431 iteration 4966 : loss : 0.023366, loss_ce: 0.009128
2021-12-10 12:35:58,995 iteration 4967 : loss : 0.034684, loss_ce: 0.014801
2021-12-10 12:36:00,579 iteration 4968 : loss : 0.017831, loss_ce: 0.008090
2021-12-10 12:36:02,251 iteration 4969 : loss : 0.034583, loss_ce: 0.011346
2021-12-10 12:36:03,750 iteration 4970 : loss : 0.017582, loss_ce: 0.007306
2021-12-10 12:36:05,274 iteration 4971 : loss : 0.021602, loss_ce: 0.012822
2021-12-10 12:36:06,861 iteration 4972 : loss : 0.023860, loss_ce: 0.010360
2021-12-10 12:36:08,417 iteration 4973 : loss : 0.025164, loss_ce: 0.009344
2021-12-10 12:36:10,099 iteration 4974 : loss : 0.024314, loss_ce: 0.008832
2021-12-10 12:36:11,637 iteration 4975 : loss : 0.015885, loss_ce: 0.004717
2021-12-10 12:36:13,119 iteration 4976 : loss : 0.016264, loss_ce: 0.006079
2021-12-10 12:36:14,698 iteration 4977 : loss : 0.037651, loss_ce: 0.008519
2021-12-10 12:36:16,238 iteration 4978 : loss : 0.016819, loss_ce: 0.004720
2021-12-10 12:36:17,786 iteration 4979 : loss : 0.023688, loss_ce: 0.009065
2021-12-10 12:36:19,346 iteration 4980 : loss : 0.027305, loss_ce: 0.008307
2021-12-10 12:36:20,893 iteration 4981 : loss : 0.025732, loss_ce: 0.007867
 73%|█████████████████████▏       | 293/400 [2:20:32<50:44, 28.45s/it]2021-12-10 12:36:22,475 iteration 4982 : loss : 0.017843, loss_ce: 0.008178
2021-12-10 12:36:24,000 iteration 4983 : loss : 0.018372, loss_ce: 0.007467
2021-12-10 12:36:25,648 iteration 4984 : loss : 0.025958, loss_ce: 0.011471
2021-12-10 12:36:27,119 iteration 4985 : loss : 0.018325, loss_ce: 0.004808
2021-12-10 12:36:28,754 iteration 4986 : loss : 0.028107, loss_ce: 0.014518
2021-12-10 12:36:30,251 iteration 4987 : loss : 0.016224, loss_ce: 0.005078
2021-12-10 12:36:31,821 iteration 4988 : loss : 0.022448, loss_ce: 0.006645
2021-12-10 12:36:33,438 iteration 4989 : loss : 0.019683, loss_ce: 0.007425
2021-12-10 12:36:35,072 iteration 4990 : loss : 0.018280, loss_ce: 0.008051
2021-12-10 12:36:36,642 iteration 4991 : loss : 0.025614, loss_ce: 0.008348
2021-12-10 12:36:38,098 iteration 4992 : loss : 0.015451, loss_ce: 0.007052
2021-12-10 12:36:39,624 iteration 4993 : loss : 0.019584, loss_ce: 0.006840
2021-12-10 12:36:41,119 iteration 4994 : loss : 0.019597, loss_ce: 0.005988
2021-12-10 12:36:42,634 iteration 4995 : loss : 0.023475, loss_ce: 0.010612
2021-12-10 12:36:44,248 iteration 4996 : loss : 0.024689, loss_ce: 0.006841
2021-12-10 12:36:45,726 iteration 4997 : loss : 0.015692, loss_ce: 0.004629
2021-12-10 12:36:47,216 iteration 4998 : loss : 0.019622, loss_ce: 0.007653
 74%|█████████████████████▎       | 294/400 [2:20:58<49:08, 27.81s/it]2021-12-10 12:36:48,790 iteration 4999 : loss : 0.016160, loss_ce: 0.005775
2021-12-10 12:36:50,314 iteration 5000 : loss : 0.018847, loss_ce: 0.007304
2021-12-10 12:36:51,845 iteration 5001 : loss : 0.026818, loss_ce: 0.012222
2021-12-10 12:36:53,365 iteration 5002 : loss : 0.014756, loss_ce: 0.005050
2021-12-10 12:36:54,937 iteration 5003 : loss : 0.034751, loss_ce: 0.007793
2021-12-10 12:36:56,477 iteration 5004 : loss : 0.023450, loss_ce: 0.009898
2021-12-10 12:36:58,014 iteration 5005 : loss : 0.025301, loss_ce: 0.010596
2021-12-10 12:36:59,621 iteration 5006 : loss : 0.023504, loss_ce: 0.010171
2021-12-10 12:37:01,207 iteration 5007 : loss : 0.034448, loss_ce: 0.014199
2021-12-10 12:37:02,806 iteration 5008 : loss : 0.025040, loss_ce: 0.009798
2021-12-10 12:37:04,398 iteration 5009 : loss : 0.018936, loss_ce: 0.004843
2021-12-10 12:37:05,972 iteration 5010 : loss : 0.056250, loss_ce: 0.020173
2021-12-10 12:37:07,497 iteration 5011 : loss : 0.015629, loss_ce: 0.007096
2021-12-10 12:37:09,062 iteration 5012 : loss : 0.022520, loss_ce: 0.010055
2021-12-10 12:37:10,545 iteration 5013 : loss : 0.022640, loss_ce: 0.008368
2021-12-10 12:37:12,083 iteration 5014 : loss : 0.028813, loss_ce: 0.010397
2021-12-10 12:37:12,084 Training Data Eval:
2021-12-10 12:37:19,825   Average segmentation loss on training set: 0.0118
2021-12-10 12:37:19,825 Validation Data Eval:
2021-12-10 12:37:22,487   Average segmentation loss on validation set: 0.0756
2021-12-10 12:37:24,036 iteration 5015 : loss : 0.022989, loss_ce: 0.008129
 74%|█████████████████████▍       | 295/400 [2:21:35<53:23, 30.51s/it]2021-12-10 12:37:25,622 iteration 5016 : loss : 0.025009, loss_ce: 0.012133
2021-12-10 12:37:27,145 iteration 5017 : loss : 0.017726, loss_ce: 0.006539
2021-12-10 12:37:28,675 iteration 5018 : loss : 0.018713, loss_ce: 0.007772
2021-12-10 12:37:30,245 iteration 5019 : loss : 0.015371, loss_ce: 0.005414
2021-12-10 12:37:31,819 iteration 5020 : loss : 0.021730, loss_ce: 0.006591
2021-12-10 12:37:33,422 iteration 5021 : loss : 0.021727, loss_ce: 0.011965
2021-12-10 12:37:34,913 iteration 5022 : loss : 0.017463, loss_ce: 0.005466
2021-12-10 12:37:36,453 iteration 5023 : loss : 0.026265, loss_ce: 0.007127
2021-12-10 12:37:38,106 iteration 5024 : loss : 0.030496, loss_ce: 0.007923
2021-12-10 12:37:39,728 iteration 5025 : loss : 0.037021, loss_ce: 0.007079
2021-12-10 12:37:41,284 iteration 5026 : loss : 0.022801, loss_ce: 0.008607
2021-12-10 12:37:42,796 iteration 5027 : loss : 0.021572, loss_ce: 0.009152
2021-12-10 12:37:44,325 iteration 5028 : loss : 0.021217, loss_ce: 0.008477
2021-12-10 12:37:45,971 iteration 5029 : loss : 0.037261, loss_ce: 0.006451
2021-12-10 12:37:47,524 iteration 5030 : loss : 0.022390, loss_ce: 0.010405
2021-12-10 12:37:49,146 iteration 5031 : loss : 0.028176, loss_ce: 0.012178
2021-12-10 12:37:50,705 iteration 5032 : loss : 0.030375, loss_ce: 0.014485
 74%|█████████████████████▍       | 296/400 [2:22:02<50:53, 29.36s/it]2021-12-10 12:37:52,426 iteration 5033 : loss : 0.037262, loss_ce: 0.011886
2021-12-10 12:37:53,962 iteration 5034 : loss : 0.033305, loss_ce: 0.009989
2021-12-10 12:37:55,480 iteration 5035 : loss : 0.024385, loss_ce: 0.009972
2021-12-10 12:37:57,008 iteration 5036 : loss : 0.025865, loss_ce: 0.010783
2021-12-10 12:37:58,565 iteration 5037 : loss : 0.020683, loss_ce: 0.007045
2021-12-10 12:38:00,083 iteration 5038 : loss : 0.026772, loss_ce: 0.006977
2021-12-10 12:38:01,726 iteration 5039 : loss : 0.020644, loss_ce: 0.010801
2021-12-10 12:38:03,289 iteration 5040 : loss : 0.021930, loss_ce: 0.006331
2021-12-10 12:38:04,917 iteration 5041 : loss : 0.025449, loss_ce: 0.009865
2021-12-10 12:38:06,425 iteration 5042 : loss : 0.030222, loss_ce: 0.014085
2021-12-10 12:38:07,980 iteration 5043 : loss : 0.025703, loss_ce: 0.013293
2021-12-10 12:38:09,543 iteration 5044 : loss : 0.052359, loss_ce: 0.034511
2021-12-10 12:38:11,151 iteration 5045 : loss : 0.030328, loss_ce: 0.012769
2021-12-10 12:38:12,725 iteration 5046 : loss : 0.021095, loss_ce: 0.005875
2021-12-10 12:38:14,257 iteration 5047 : loss : 0.028709, loss_ce: 0.009630
2021-12-10 12:38:15,781 iteration 5048 : loss : 0.024731, loss_ce: 0.009834
2021-12-10 12:38:17,304 iteration 5049 : loss : 0.023668, loss_ce: 0.012108
 74%|█████████████████████▌       | 297/400 [2:22:28<48:58, 28.53s/it]2021-12-10 12:38:18,901 iteration 5050 : loss : 0.035545, loss_ce: 0.012700
2021-12-10 12:38:20,436 iteration 5051 : loss : 0.031960, loss_ce: 0.012268
2021-12-10 12:38:21,983 iteration 5052 : loss : 0.018336, loss_ce: 0.007805
2021-12-10 12:38:23,509 iteration 5053 : loss : 0.017722, loss_ce: 0.006597
2021-12-10 12:38:25,054 iteration 5054 : loss : 0.020721, loss_ce: 0.006796
2021-12-10 12:38:26,579 iteration 5055 : loss : 0.017295, loss_ce: 0.006087
2021-12-10 12:38:28,095 iteration 5056 : loss : 0.023484, loss_ce: 0.006093
2021-12-10 12:38:29,698 iteration 5057 : loss : 0.026314, loss_ce: 0.013171
2021-12-10 12:38:31,319 iteration 5058 : loss : 0.024226, loss_ce: 0.009369
2021-12-10 12:38:32,750 iteration 5059 : loss : 0.018006, loss_ce: 0.004901
2021-12-10 12:38:34,299 iteration 5060 : loss : 0.037526, loss_ce: 0.010332
2021-12-10 12:38:35,878 iteration 5061 : loss : 0.024010, loss_ce: 0.010088
2021-12-10 12:38:37,451 iteration 5062 : loss : 0.034010, loss_ce: 0.010966
2021-12-10 12:38:39,071 iteration 5063 : loss : 0.022476, loss_ce: 0.009034
2021-12-10 12:38:40,580 iteration 5064 : loss : 0.019261, loss_ce: 0.007680
2021-12-10 12:38:42,099 iteration 5065 : loss : 0.025231, loss_ce: 0.009312
2021-12-10 12:38:43,647 iteration 5066 : loss : 0.017694, loss_ce: 0.008233
 74%|█████████████████████▌       | 298/400 [2:22:55<47:23, 27.87s/it]2021-12-10 12:38:45,336 iteration 5067 : loss : 0.026116, loss_ce: 0.010280
2021-12-10 12:38:46,921 iteration 5068 : loss : 0.019949, loss_ce: 0.008182
2021-12-10 12:38:48,490 iteration 5069 : loss : 0.033181, loss_ce: 0.011134
2021-12-10 12:38:50,034 iteration 5070 : loss : 0.019906, loss_ce: 0.006164
2021-12-10 12:38:51,662 iteration 5071 : loss : 0.028759, loss_ce: 0.011441
2021-12-10 12:38:53,092 iteration 5072 : loss : 0.018378, loss_ce: 0.006041
2021-12-10 12:38:54,627 iteration 5073 : loss : 0.021319, loss_ce: 0.010051
2021-12-10 12:38:56,220 iteration 5074 : loss : 0.022547, loss_ce: 0.007863
2021-12-10 12:38:57,770 iteration 5075 : loss : 0.023397, loss_ce: 0.009812
2021-12-10 12:38:59,381 iteration 5076 : loss : 0.017662, loss_ce: 0.007502
2021-12-10 12:39:00,902 iteration 5077 : loss : 0.019500, loss_ce: 0.007289
2021-12-10 12:39:02,457 iteration 5078 : loss : 0.014391, loss_ce: 0.004131
2021-12-10 12:39:03,978 iteration 5079 : loss : 0.019769, loss_ce: 0.006861
2021-12-10 12:39:05,542 iteration 5080 : loss : 0.024819, loss_ce: 0.007936
2021-12-10 12:39:07,127 iteration 5081 : loss : 0.022826, loss_ce: 0.009871
2021-12-10 12:39:08,740 iteration 5082 : loss : 0.033417, loss_ce: 0.016262
2021-12-10 12:39:10,317 iteration 5083 : loss : 0.021750, loss_ce: 0.006919
 75%|█████████████████████▋       | 299/400 [2:23:21<46:18, 27.51s/it]2021-12-10 12:39:11,881 iteration 5084 : loss : 0.018705, loss_ce: 0.006743
2021-12-10 12:39:13,446 iteration 5085 : loss : 0.024893, loss_ce: 0.009677
2021-12-10 12:39:14,959 iteration 5086 : loss : 0.015634, loss_ce: 0.006059
2021-12-10 12:39:16,568 iteration 5087 : loss : 0.030543, loss_ce: 0.014070
2021-12-10 12:39:18,136 iteration 5088 : loss : 0.020646, loss_ce: 0.008087
2021-12-10 12:39:19,640 iteration 5089 : loss : 0.016990, loss_ce: 0.005197
2021-12-10 12:39:21,157 iteration 5090 : loss : 0.019555, loss_ce: 0.006905
2021-12-10 12:39:22,814 iteration 5091 : loss : 0.027415, loss_ce: 0.010734
2021-12-10 12:39:24,368 iteration 5092 : loss : 0.014137, loss_ce: 0.006761
2021-12-10 12:39:25,881 iteration 5093 : loss : 0.018673, loss_ce: 0.008201
2021-12-10 12:39:27,365 iteration 5094 : loss : 0.013884, loss_ce: 0.005091
2021-12-10 12:39:28,958 iteration 5095 : loss : 0.032433, loss_ce: 0.010287
2021-12-10 12:39:30,457 iteration 5096 : loss : 0.014007, loss_ce: 0.005576
2021-12-10 12:39:31,967 iteration 5097 : loss : 0.024028, loss_ce: 0.011716
2021-12-10 12:39:33,535 iteration 5098 : loss : 0.026310, loss_ce: 0.009962
2021-12-10 12:39:35,069 iteration 5099 : loss : 0.017792, loss_ce: 0.005580
2021-12-10 12:39:35,070 Training Data Eval:
2021-12-10 12:39:42,817   Average segmentation loss on training set: 0.0118
2021-12-10 12:39:42,817 Validation Data Eval:
2021-12-10 12:39:45,483   Average segmentation loss on validation set: 0.0666
2021-12-10 12:39:47,027 iteration 5100 : loss : 0.019576, loss_ce: 0.009838
2021-12-10 12:39:53,020 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234epoch_299.pth
 75%|█████████████████████▊       | 300/400 [2:24:04<53:25, 32.06s/it]2021-12-10 12:39:54,613 iteration 5101 : loss : 0.019676, loss_ce: 0.008554
2021-12-10 12:39:56,121 iteration 5102 : loss : 0.015876, loss_ce: 0.005696
2021-12-10 12:39:57,680 iteration 5103 : loss : 0.022582, loss_ce: 0.008320
2021-12-10 12:39:59,299 iteration 5104 : loss : 0.018810, loss_ce: 0.007711
2021-12-10 12:40:00,787 iteration 5105 : loss : 0.019802, loss_ce: 0.006877
2021-12-10 12:40:02,406 iteration 5106 : loss : 0.016118, loss_ce: 0.005989
2021-12-10 12:40:03,895 iteration 5107 : loss : 0.014014, loss_ce: 0.005299
2021-12-10 12:40:05,470 iteration 5108 : loss : 0.039691, loss_ce: 0.013466
2021-12-10 12:40:07,021 iteration 5109 : loss : 0.025776, loss_ce: 0.009237
2021-12-10 12:40:08,555 iteration 5110 : loss : 0.023749, loss_ce: 0.010732
2021-12-10 12:40:10,137 iteration 5111 : loss : 0.017773, loss_ce: 0.005704
2021-12-10 12:40:11,634 iteration 5112 : loss : 0.025879, loss_ce: 0.007767
2021-12-10 12:40:13,245 iteration 5113 : loss : 0.022683, loss_ce: 0.005437
2021-12-10 12:40:14,770 iteration 5114 : loss : 0.020780, loss_ce: 0.011034
2021-12-10 12:40:16,277 iteration 5115 : loss : 0.025793, loss_ce: 0.007192
2021-12-10 12:40:17,789 iteration 5116 : loss : 0.019775, loss_ce: 0.007907
2021-12-10 12:40:19,394 iteration 5117 : loss : 0.025914, loss_ce: 0.010853
 75%|█████████████████████▊       | 301/400 [2:24:30<50:06, 30.37s/it]2021-12-10 12:40:21,013 iteration 5118 : loss : 0.012612, loss_ce: 0.004749
2021-12-10 12:40:22,582 iteration 5119 : loss : 0.026129, loss_ce: 0.007880
2021-12-10 12:40:24,092 iteration 5120 : loss : 0.026088, loss_ce: 0.007023
2021-12-10 12:40:25,645 iteration 5121 : loss : 0.027737, loss_ce: 0.012724
2021-12-10 12:40:27,147 iteration 5122 : loss : 0.016674, loss_ce: 0.006236
2021-12-10 12:40:28,680 iteration 5123 : loss : 0.026066, loss_ce: 0.007441
2021-12-10 12:40:30,253 iteration 5124 : loss : 0.036082, loss_ce: 0.018325
2021-12-10 12:40:31,698 iteration 5125 : loss : 0.019109, loss_ce: 0.009584
2021-12-10 12:40:33,184 iteration 5126 : loss : 0.020336, loss_ce: 0.006833
2021-12-10 12:40:34,774 iteration 5127 : loss : 0.027202, loss_ce: 0.009157
2021-12-10 12:40:36,287 iteration 5128 : loss : 0.014813, loss_ce: 0.006303
2021-12-10 12:40:37,859 iteration 5129 : loss : 0.021127, loss_ce: 0.007660
2021-12-10 12:40:39,407 iteration 5130 : loss : 0.019859, loss_ce: 0.006259
2021-12-10 12:40:40,866 iteration 5131 : loss : 0.013140, loss_ce: 0.004782
2021-12-10 12:40:42,400 iteration 5132 : loss : 0.020630, loss_ce: 0.008719
2021-12-10 12:40:43,898 iteration 5133 : loss : 0.020658, loss_ce: 0.006138
2021-12-10 12:40:45,383 iteration 5134 : loss : 0.017688, loss_ce: 0.007142
 76%|█████████████████████▉       | 302/400 [2:24:56<47:27, 29.05s/it]2021-12-10 12:40:47,128 iteration 5135 : loss : 0.023932, loss_ce: 0.009772
2021-12-10 12:40:48,662 iteration 5136 : loss : 0.023539, loss_ce: 0.007509
2021-12-10 12:40:50,258 iteration 5137 : loss : 0.026109, loss_ce: 0.009014
2021-12-10 12:40:51,766 iteration 5138 : loss : 0.015620, loss_ce: 0.006993
2021-12-10 12:40:53,313 iteration 5139 : loss : 0.019281, loss_ce: 0.007471
2021-12-10 12:40:54,951 iteration 5140 : loss : 0.016249, loss_ce: 0.007163
2021-12-10 12:40:56,439 iteration 5141 : loss : 0.024656, loss_ce: 0.009394
2021-12-10 12:40:57,997 iteration 5142 : loss : 0.031574, loss_ce: 0.010157
2021-12-10 12:40:59,458 iteration 5143 : loss : 0.015846, loss_ce: 0.006226
2021-12-10 12:41:01,034 iteration 5144 : loss : 0.018384, loss_ce: 0.009602
2021-12-10 12:41:02,491 iteration 5145 : loss : 0.019592, loss_ce: 0.007401
2021-12-10 12:41:04,106 iteration 5146 : loss : 0.022948, loss_ce: 0.009963
2021-12-10 12:41:05,726 iteration 5147 : loss : 0.019917, loss_ce: 0.008172
2021-12-10 12:41:07,252 iteration 5148 : loss : 0.017786, loss_ce: 0.006977
2021-12-10 12:41:08,778 iteration 5149 : loss : 0.033271, loss_ce: 0.008336
2021-12-10 12:41:10,314 iteration 5150 : loss : 0.014481, loss_ce: 0.005950
2021-12-10 12:41:11,867 iteration 5151 : loss : 0.035120, loss_ce: 0.006651
 76%|█████████████████████▉       | 303/400 [2:25:23<45:43, 28.29s/it]2021-12-10 12:41:13,420 iteration 5152 : loss : 0.022869, loss_ce: 0.004050
2021-12-10 12:41:14,871 iteration 5153 : loss : 0.013229, loss_ce: 0.005160
2021-12-10 12:41:16,488 iteration 5154 : loss : 0.028783, loss_ce: 0.012679
2021-12-10 12:41:17,969 iteration 5155 : loss : 0.014891, loss_ce: 0.005114
2021-12-10 12:41:19,500 iteration 5156 : loss : 0.030159, loss_ce: 0.012739
2021-12-10 12:41:20,973 iteration 5157 : loss : 0.015010, loss_ce: 0.004659
2021-12-10 12:41:22,487 iteration 5158 : loss : 0.022217, loss_ce: 0.008272
2021-12-10 12:41:24,089 iteration 5159 : loss : 0.019070, loss_ce: 0.006916
2021-12-10 12:41:25,572 iteration 5160 : loss : 0.015238, loss_ce: 0.005294
2021-12-10 12:41:27,103 iteration 5161 : loss : 0.023932, loss_ce: 0.008512
2021-12-10 12:41:28,586 iteration 5162 : loss : 0.017092, loss_ce: 0.007054
2021-12-10 12:41:30,138 iteration 5163 : loss : 0.017030, loss_ce: 0.007118
2021-12-10 12:41:31,696 iteration 5164 : loss : 0.032914, loss_ce: 0.017773
2021-12-10 12:41:33,170 iteration 5165 : loss : 0.022547, loss_ce: 0.006987
2021-12-10 12:41:34,704 iteration 5166 : loss : 0.015841, loss_ce: 0.006772
2021-12-10 12:41:36,256 iteration 5167 : loss : 0.035480, loss_ce: 0.011956
2021-12-10 12:41:37,855 iteration 5168 : loss : 0.029310, loss_ce: 0.013399
 76%|██████████████████████       | 304/400 [2:25:49<44:09, 27.60s/it]2021-12-10 12:41:39,576 iteration 5169 : loss : 0.031575, loss_ce: 0.013513
2021-12-10 12:41:41,067 iteration 5170 : loss : 0.024512, loss_ce: 0.007519
2021-12-10 12:41:42,678 iteration 5171 : loss : 0.019525, loss_ce: 0.007933
2021-12-10 12:41:44,147 iteration 5172 : loss : 0.015885, loss_ce: 0.004798
2021-12-10 12:41:45,555 iteration 5173 : loss : 0.013409, loss_ce: 0.005658
2021-12-10 12:41:47,164 iteration 5174 : loss : 0.032690, loss_ce: 0.011716
2021-12-10 12:41:48,667 iteration 5175 : loss : 0.019718, loss_ce: 0.008733
2021-12-10 12:41:50,350 iteration 5176 : loss : 0.031971, loss_ce: 0.013032
2021-12-10 12:41:51,852 iteration 5177 : loss : 0.021302, loss_ce: 0.009153
2021-12-10 12:41:53,373 iteration 5178 : loss : 0.013674, loss_ce: 0.003850
2021-12-10 12:41:54,976 iteration 5179 : loss : 0.017804, loss_ce: 0.005502
2021-12-10 12:41:56,522 iteration 5180 : loss : 0.019309, loss_ce: 0.007400
2021-12-10 12:41:58,019 iteration 5181 : loss : 0.016007, loss_ce: 0.004520
2021-12-10 12:41:59,559 iteration 5182 : loss : 0.020002, loss_ce: 0.007370
2021-12-10 12:42:01,073 iteration 5183 : loss : 0.017811, loss_ce: 0.007897
2021-12-10 12:42:02,571 iteration 5184 : loss : 0.024331, loss_ce: 0.009066
2021-12-10 12:42:02,571 Training Data Eval:
2021-12-10 12:42:10,309   Average segmentation loss on training set: 0.0122
2021-12-10 12:42:10,309 Validation Data Eval:
2021-12-10 12:42:12,965   Average segmentation loss on validation set: 0.0725
2021-12-10 12:42:14,495 iteration 5185 : loss : 0.022433, loss_ce: 0.008922
 76%|██████████████████████       | 305/400 [2:26:25<47:59, 30.31s/it]2021-12-10 12:42:16,096 iteration 5186 : loss : 0.016122, loss_ce: 0.007501
2021-12-10 12:42:17,578 iteration 5187 : loss : 0.018574, loss_ce: 0.007879
2021-12-10 12:42:19,070 iteration 5188 : loss : 0.018741, loss_ce: 0.008639
2021-12-10 12:42:20,571 iteration 5189 : loss : 0.015438, loss_ce: 0.007540
2021-12-10 12:42:22,053 iteration 5190 : loss : 0.019038, loss_ce: 0.008801
2021-12-10 12:42:23,646 iteration 5191 : loss : 0.022956, loss_ce: 0.008295
2021-12-10 12:42:25,219 iteration 5192 : loss : 0.021060, loss_ce: 0.006795
2021-12-10 12:42:26,708 iteration 5193 : loss : 0.013540, loss_ce: 0.004809
2021-12-10 12:42:28,278 iteration 5194 : loss : 0.018868, loss_ce: 0.007242
2021-12-10 12:42:29,782 iteration 5195 : loss : 0.016159, loss_ce: 0.005199
2021-12-10 12:42:31,215 iteration 5196 : loss : 0.015088, loss_ce: 0.003642
2021-12-10 12:42:32,689 iteration 5197 : loss : 0.014655, loss_ce: 0.004787
2021-12-10 12:42:34,182 iteration 5198 : loss : 0.015770, loss_ce: 0.007016
2021-12-10 12:42:35,749 iteration 5199 : loss : 0.015866, loss_ce: 0.005472
2021-12-10 12:42:37,272 iteration 5200 : loss : 0.021054, loss_ce: 0.006275
2021-12-10 12:42:38,828 iteration 5201 : loss : 0.023844, loss_ce: 0.008849
2021-12-10 12:42:40,455 iteration 5202 : loss : 0.027344, loss_ce: 0.012204
 76%|██████████████████████▏      | 306/400 [2:26:51<45:26, 29.00s/it]2021-12-10 12:42:42,016 iteration 5203 : loss : 0.015780, loss_ce: 0.006150
2021-12-10 12:42:43,529 iteration 5204 : loss : 0.019736, loss_ce: 0.008436
2021-12-10 12:42:45,206 iteration 5205 : loss : 0.025560, loss_ce: 0.009396
2021-12-10 12:42:46,751 iteration 5206 : loss : 0.020381, loss_ce: 0.007069
2021-12-10 12:42:48,305 iteration 5207 : loss : 0.024048, loss_ce: 0.011278
2021-12-10 12:42:49,927 iteration 5208 : loss : 0.022411, loss_ce: 0.008368
2021-12-10 12:42:51,418 iteration 5209 : loss : 0.017477, loss_ce: 0.006974
2021-12-10 12:42:53,012 iteration 5210 : loss : 0.019878, loss_ce: 0.006787
2021-12-10 12:42:54,570 iteration 5211 : loss : 0.018628, loss_ce: 0.007266
2021-12-10 12:42:56,116 iteration 5212 : loss : 0.026651, loss_ce: 0.010818
2021-12-10 12:42:57,553 iteration 5213 : loss : 0.014673, loss_ce: 0.005486
2021-12-10 12:42:59,200 iteration 5214 : loss : 0.028287, loss_ce: 0.012139
2021-12-10 12:43:00,783 iteration 5215 : loss : 0.018686, loss_ce: 0.006608
2021-12-10 12:43:02,388 iteration 5216 : loss : 0.020125, loss_ce: 0.006750
2021-12-10 12:43:04,030 iteration 5217 : loss : 0.032687, loss_ce: 0.013532
2021-12-10 12:43:05,541 iteration 5218 : loss : 0.021823, loss_ce: 0.003961
2021-12-10 12:43:07,188 iteration 5219 : loss : 0.021735, loss_ce: 0.007685
 77%|██████████████████████▎      | 307/400 [2:27:18<43:54, 28.33s/it]2021-12-10 12:43:08,781 iteration 5220 : loss : 0.024586, loss_ce: 0.007135
2021-12-10 12:43:10,320 iteration 5221 : loss : 0.019119, loss_ce: 0.006535
2021-12-10 12:43:11,867 iteration 5222 : loss : 0.015464, loss_ce: 0.005794
2021-12-10 12:43:13,461 iteration 5223 : loss : 0.019811, loss_ce: 0.007476
2021-12-10 12:43:14,995 iteration 5224 : loss : 0.025675, loss_ce: 0.007580
2021-12-10 12:43:16,616 iteration 5225 : loss : 0.020876, loss_ce: 0.007189
2021-12-10 12:43:18,151 iteration 5226 : loss : 0.034361, loss_ce: 0.012576
2021-12-10 12:43:19,787 iteration 5227 : loss : 0.024974, loss_ce: 0.010620
2021-12-10 12:43:21,302 iteration 5228 : loss : 0.022046, loss_ce: 0.006739
2021-12-10 12:43:22,977 iteration 5229 : loss : 0.043474, loss_ce: 0.021562
2021-12-10 12:43:24,421 iteration 5230 : loss : 0.012654, loss_ce: 0.005643
2021-12-10 12:43:25,993 iteration 5231 : loss : 0.023287, loss_ce: 0.009227
2021-12-10 12:43:27,562 iteration 5232 : loss : 0.021263, loss_ce: 0.007353
2021-12-10 12:43:29,151 iteration 5233 : loss : 0.023342, loss_ce: 0.010283
2021-12-10 12:43:30,654 iteration 5234 : loss : 0.017355, loss_ce: 0.007805
2021-12-10 12:43:32,218 iteration 5235 : loss : 0.020891, loss_ce: 0.007317
2021-12-10 12:43:33,819 iteration 5236 : loss : 0.026509, loss_ce: 0.010129
 77%|██████████████████████▎      | 308/400 [2:27:45<42:38, 27.81s/it]2021-12-10 12:43:35,279 iteration 5237 : loss : 0.015695, loss_ce: 0.006574
2021-12-10 12:43:36,888 iteration 5238 : loss : 0.021654, loss_ce: 0.008925
2021-12-10 12:43:38,458 iteration 5239 : loss : 0.020438, loss_ce: 0.006567
2021-12-10 12:43:40,050 iteration 5240 : loss : 0.177462, loss_ce: 0.006805
2021-12-10 12:43:41,562 iteration 5241 : loss : 0.018154, loss_ce: 0.007980
2021-12-10 12:43:43,115 iteration 5242 : loss : 0.021616, loss_ce: 0.008745
2021-12-10 12:43:44,761 iteration 5243 : loss : 0.021111, loss_ce: 0.007192
2021-12-10 12:43:46,350 iteration 5244 : loss : 0.017417, loss_ce: 0.007008
2021-12-10 12:43:47,920 iteration 5245 : loss : 0.019434, loss_ce: 0.006864
2021-12-10 12:43:49,502 iteration 5246 : loss : 0.028314, loss_ce: 0.008852
2021-12-10 12:43:50,965 iteration 5247 : loss : 0.014895, loss_ce: 0.006337
2021-12-10 12:43:52,554 iteration 5248 : loss : 0.014759, loss_ce: 0.005022
2021-12-10 12:43:54,200 iteration 5249 : loss : 0.027761, loss_ce: 0.010204
2021-12-10 12:43:55,786 iteration 5250 : loss : 0.023054, loss_ce: 0.011283
2021-12-10 12:43:57,252 iteration 5251 : loss : 0.015097, loss_ce: 0.005009
2021-12-10 12:43:58,815 iteration 5252 : loss : 0.017153, loss_ce: 0.006712
2021-12-10 12:44:00,396 iteration 5253 : loss : 0.038828, loss_ce: 0.009622
 77%|██████████████████████▍      | 309/400 [2:28:11<41:37, 27.44s/it]2021-12-10 12:44:02,005 iteration 5254 : loss : 0.017950, loss_ce: 0.006501
2021-12-10 12:44:03,551 iteration 5255 : loss : 0.025881, loss_ce: 0.014137
2021-12-10 12:44:05,018 iteration 5256 : loss : 0.015759, loss_ce: 0.006746
2021-12-10 12:44:06,574 iteration 5257 : loss : 0.016736, loss_ce: 0.006667
2021-12-10 12:44:08,162 iteration 5258 : loss : 0.017912, loss_ce: 0.005344
2021-12-10 12:44:09,655 iteration 5259 : loss : 0.020104, loss_ce: 0.005102
2021-12-10 12:44:11,216 iteration 5260 : loss : 0.014010, loss_ce: 0.004951
2021-12-10 12:44:12,788 iteration 5261 : loss : 0.022577, loss_ce: 0.010565
2021-12-10 12:44:14,333 iteration 5262 : loss : 0.015885, loss_ce: 0.006924
2021-12-10 12:44:15,884 iteration 5263 : loss : 0.025914, loss_ce: 0.013251
2021-12-10 12:44:17,372 iteration 5264 : loss : 0.015103, loss_ce: 0.006564
2021-12-10 12:44:18,962 iteration 5265 : loss : 0.024364, loss_ce: 0.008398
2021-12-10 12:44:20,599 iteration 5266 : loss : 0.026841, loss_ce: 0.011723
2021-12-10 12:44:22,156 iteration 5267 : loss : 0.029683, loss_ce: 0.007951
2021-12-10 12:44:23,722 iteration 5268 : loss : 0.030038, loss_ce: 0.008537
2021-12-10 12:44:25,391 iteration 5269 : loss : 0.026121, loss_ce: 0.006552
2021-12-10 12:44:25,392 Training Data Eval:
2021-12-10 12:44:33,139   Average segmentation loss on training set: 0.0116
2021-12-10 12:44:33,139 Validation Data Eval:
2021-12-10 12:44:35,792   Average segmentation loss on validation set: 0.0750
2021-12-10 12:44:37,335 iteration 5270 : loss : 0.017151, loss_ce: 0.008275
 78%|██████████████████████▍      | 310/400 [2:28:48<45:25, 30.29s/it]2021-12-10 12:44:38,895 iteration 5271 : loss : 0.017012, loss_ce: 0.006670
2021-12-10 12:44:40,464 iteration 5272 : loss : 0.019938, loss_ce: 0.009019
2021-12-10 12:44:41,971 iteration 5273 : loss : 0.015018, loss_ce: 0.004633
2021-12-10 12:44:43,496 iteration 5274 : loss : 0.018592, loss_ce: 0.007749
2021-12-10 12:44:44,955 iteration 5275 : loss : 0.014971, loss_ce: 0.006549
2021-12-10 12:44:46,524 iteration 5276 : loss : 0.033448, loss_ce: 0.016830
2021-12-10 12:44:48,082 iteration 5277 : loss : 0.018443, loss_ce: 0.006641
2021-12-10 12:44:49,533 iteration 5278 : loss : 0.014654, loss_ce: 0.005934
2021-12-10 12:44:51,073 iteration 5279 : loss : 0.032377, loss_ce: 0.015839
2021-12-10 12:44:52,757 iteration 5280 : loss : 0.027199, loss_ce: 0.012143
2021-12-10 12:44:54,288 iteration 5281 : loss : 0.018735, loss_ce: 0.006526
2021-12-10 12:44:55,763 iteration 5282 : loss : 0.013361, loss_ce: 0.004334
2021-12-10 12:44:57,312 iteration 5283 : loss : 0.022188, loss_ce: 0.008074
2021-12-10 12:44:58,878 iteration 5284 : loss : 0.040013, loss_ce: 0.013526
2021-12-10 12:45:00,415 iteration 5285 : loss : 0.016276, loss_ce: 0.007023
2021-12-10 12:45:01,873 iteration 5286 : loss : 0.015908, loss_ce: 0.006959
2021-12-10 12:45:03,397 iteration 5287 : loss : 0.020788, loss_ce: 0.004152
 78%|██████████████████████▌      | 311/400 [2:29:14<43:03, 29.03s/it]2021-12-10 12:45:05,039 iteration 5288 : loss : 0.018476, loss_ce: 0.007210
2021-12-10 12:45:06,630 iteration 5289 : loss : 0.024657, loss_ce: 0.007608
2021-12-10 12:45:08,163 iteration 5290 : loss : 0.019885, loss_ce: 0.004935
2021-12-10 12:45:09,681 iteration 5291 : loss : 0.029527, loss_ce: 0.011813
2021-12-10 12:45:11,264 iteration 5292 : loss : 0.020947, loss_ce: 0.008502
2021-12-10 12:45:12,823 iteration 5293 : loss : 0.019357, loss_ce: 0.008668
2021-12-10 12:45:14,416 iteration 5294 : loss : 0.030103, loss_ce: 0.013465
2021-12-10 12:45:16,060 iteration 5295 : loss : 0.022397, loss_ce: 0.009463
2021-12-10 12:45:17,659 iteration 5296 : loss : 0.045581, loss_ce: 0.010208
2021-12-10 12:45:19,259 iteration 5297 : loss : 0.016349, loss_ce: 0.005222
2021-12-10 12:45:20,861 iteration 5298 : loss : 0.026828, loss_ce: 0.011092
2021-12-10 12:45:22,452 iteration 5299 : loss : 0.018393, loss_ce: 0.006317
2021-12-10 12:45:24,056 iteration 5300 : loss : 0.027166, loss_ce: 0.009504
2021-12-10 12:45:25,543 iteration 5301 : loss : 0.015800, loss_ce: 0.005857
2021-12-10 12:45:27,025 iteration 5302 : loss : 0.014779, loss_ce: 0.007345
2021-12-10 12:45:28,518 iteration 5303 : loss : 0.019647, loss_ce: 0.007548
2021-12-10 12:45:29,993 iteration 5304 : loss : 0.020765, loss_ce: 0.007947
 78%|██████████████████████▌      | 312/400 [2:29:41<41:30, 28.30s/it]2021-12-10 12:45:31,624 iteration 5305 : loss : 0.027556, loss_ce: 0.010317
2021-12-10 12:45:33,274 iteration 5306 : loss : 0.024151, loss_ce: 0.010415
2021-12-10 12:45:34,954 iteration 5307 : loss : 0.032014, loss_ce: 0.012419
2021-12-10 12:45:36,586 iteration 5308 : loss : 0.030393, loss_ce: 0.010794
2021-12-10 12:45:38,205 iteration 5309 : loss : 0.029293, loss_ce: 0.012290
2021-12-10 12:45:39,732 iteration 5310 : loss : 0.018401, loss_ce: 0.009457
2021-12-10 12:45:41,239 iteration 5311 : loss : 0.029168, loss_ce: 0.008246
2021-12-10 12:45:42,851 iteration 5312 : loss : 0.019005, loss_ce: 0.008587
2021-12-10 12:45:44,509 iteration 5313 : loss : 0.024424, loss_ce: 0.006800
2021-12-10 12:45:46,073 iteration 5314 : loss : 0.018286, loss_ce: 0.006331
2021-12-10 12:45:47,697 iteration 5315 : loss : 0.033732, loss_ce: 0.008156
2021-12-10 12:45:49,296 iteration 5316 : loss : 0.020595, loss_ce: 0.008725
2021-12-10 12:45:50,839 iteration 5317 : loss : 0.020884, loss_ce: 0.010221
2021-12-10 12:45:52,356 iteration 5318 : loss : 0.014231, loss_ce: 0.005530
2021-12-10 12:45:53,963 iteration 5319 : loss : 0.029746, loss_ce: 0.012997
2021-12-10 12:45:55,562 iteration 5320 : loss : 0.041099, loss_ce: 0.017063
2021-12-10 12:45:57,184 iteration 5321 : loss : 0.025860, loss_ce: 0.010895
 78%|██████████████████████▋      | 313/400 [2:30:08<40:32, 27.96s/it]2021-12-10 12:45:58,704 iteration 5322 : loss : 0.014529, loss_ce: 0.006121
2021-12-10 12:46:00,262 iteration 5323 : loss : 0.022303, loss_ce: 0.009073
2021-12-10 12:46:01,748 iteration 5324 : loss : 0.020349, loss_ce: 0.006550
2021-12-10 12:46:03,260 iteration 5325 : loss : 0.026904, loss_ce: 0.006243
2021-12-10 12:46:04,844 iteration 5326 : loss : 0.023349, loss_ce: 0.008596
2021-12-10 12:46:06,354 iteration 5327 : loss : 0.022280, loss_ce: 0.009002
2021-12-10 12:46:07,880 iteration 5328 : loss : 0.021954, loss_ce: 0.011616
2021-12-10 12:46:09,478 iteration 5329 : loss : 0.028410, loss_ce: 0.010239
2021-12-10 12:46:11,057 iteration 5330 : loss : 0.023094, loss_ce: 0.008553
2021-12-10 12:46:12,604 iteration 5331 : loss : 0.015964, loss_ce: 0.005487
2021-12-10 12:46:14,169 iteration 5332 : loss : 0.022113, loss_ce: 0.008714
2021-12-10 12:46:15,765 iteration 5333 : loss : 0.023659, loss_ce: 0.010232
2021-12-10 12:46:17,341 iteration 5334 : loss : 0.049594, loss_ce: 0.018370
2021-12-10 12:46:18,936 iteration 5335 : loss : 0.024028, loss_ce: 0.007504
2021-12-10 12:46:20,501 iteration 5336 : loss : 0.017166, loss_ce: 0.006418
2021-12-10 12:46:22,015 iteration 5337 : loss : 0.018496, loss_ce: 0.006651
2021-12-10 12:46:23,530 iteration 5338 : loss : 0.017997, loss_ce: 0.007319
 78%|██████████████████████▊      | 314/400 [2:30:34<39:22, 27.47s/it]2021-12-10 12:46:25,299 iteration 5339 : loss : 0.020017, loss_ce: 0.009141
2021-12-10 12:46:26,914 iteration 5340 : loss : 0.029442, loss_ce: 0.018019
2021-12-10 12:46:28,493 iteration 5341 : loss : 0.024922, loss_ce: 0.005543
2021-12-10 12:46:30,060 iteration 5342 : loss : 0.018234, loss_ce: 0.009469
2021-12-10 12:46:31,579 iteration 5343 : loss : 0.017823, loss_ce: 0.005759
2021-12-10 12:46:33,156 iteration 5344 : loss : 0.025309, loss_ce: 0.009917
2021-12-10 12:46:34,702 iteration 5345 : loss : 0.018911, loss_ce: 0.006300
2021-12-10 12:46:36,304 iteration 5346 : loss : 0.025657, loss_ce: 0.008451
2021-12-10 12:46:37,902 iteration 5347 : loss : 0.015782, loss_ce: 0.004575
2021-12-10 12:46:39,509 iteration 5348 : loss : 0.020982, loss_ce: 0.005866
2021-12-10 12:46:41,079 iteration 5349 : loss : 0.024447, loss_ce: 0.008376
2021-12-10 12:46:42,561 iteration 5350 : loss : 0.013899, loss_ce: 0.005345
2021-12-10 12:46:44,052 iteration 5351 : loss : 0.025966, loss_ce: 0.009720
2021-12-10 12:46:45,645 iteration 5352 : loss : 0.023616, loss_ce: 0.009099
2021-12-10 12:46:47,248 iteration 5353 : loss : 0.016223, loss_ce: 0.006196
2021-12-10 12:46:48,776 iteration 5354 : loss : 0.028495, loss_ce: 0.015347
2021-12-10 12:46:48,776 Training Data Eval:
2021-12-10 12:46:56,518   Average segmentation loss on training set: 0.0120
2021-12-10 12:46:56,518 Validation Data Eval:
2021-12-10 12:46:59,180   Average segmentation loss on validation set: 0.0754
2021-12-10 12:47:00,661 iteration 5355 : loss : 0.016457, loss_ce: 0.005903
 79%|██████████████████████▊      | 315/400 [2:31:12<43:02, 30.38s/it]2021-12-10 12:47:02,276 iteration 5356 : loss : 0.019884, loss_ce: 0.009294
2021-12-10 12:47:03,759 iteration 5357 : loss : 0.017091, loss_ce: 0.003418
2021-12-10 12:47:05,454 iteration 5358 : loss : 0.031707, loss_ce: 0.014480
2021-12-10 12:47:06,933 iteration 5359 : loss : 0.014233, loss_ce: 0.005176
2021-12-10 12:47:08,504 iteration 5360 : loss : 0.019452, loss_ce: 0.008127
2021-12-10 12:47:10,070 iteration 5361 : loss : 0.022647, loss_ce: 0.008195
2021-12-10 12:47:11,657 iteration 5362 : loss : 0.024244, loss_ce: 0.006772
2021-12-10 12:47:13,214 iteration 5363 : loss : 0.025726, loss_ce: 0.011416
2021-12-10 12:47:14,765 iteration 5364 : loss : 0.030926, loss_ce: 0.005851
2021-12-10 12:47:16,301 iteration 5365 : loss : 0.019063, loss_ce: 0.007558
2021-12-10 12:47:17,876 iteration 5366 : loss : 0.020315, loss_ce: 0.008525
2021-12-10 12:47:19,483 iteration 5367 : loss : 0.018521, loss_ce: 0.007969
2021-12-10 12:47:21,023 iteration 5368 : loss : 0.017482, loss_ce: 0.009206
2021-12-10 12:47:22,597 iteration 5369 : loss : 0.014208, loss_ce: 0.004997
2021-12-10 12:47:24,139 iteration 5370 : loss : 0.013179, loss_ce: 0.005097
2021-12-10 12:47:25,698 iteration 5371 : loss : 0.021868, loss_ce: 0.010403
2021-12-10 12:47:27,220 iteration 5372 : loss : 0.019467, loss_ce: 0.006026
 79%|██████████████████████▉      | 316/400 [2:31:38<40:55, 29.23s/it]2021-12-10 12:47:28,826 iteration 5373 : loss : 0.017517, loss_ce: 0.008881
2021-12-10 12:47:30,339 iteration 5374 : loss : 0.017225, loss_ce: 0.006689
2021-12-10 12:47:31,918 iteration 5375 : loss : 0.022129, loss_ce: 0.007117
2021-12-10 12:47:33,445 iteration 5376 : loss : 0.018652, loss_ce: 0.006963
2021-12-10 12:47:34,956 iteration 5377 : loss : 0.014361, loss_ce: 0.004563
2021-12-10 12:47:36,506 iteration 5378 : loss : 0.017540, loss_ce: 0.006050
2021-12-10 12:47:37,987 iteration 5379 : loss : 0.014032, loss_ce: 0.005125
2021-12-10 12:47:39,541 iteration 5380 : loss : 0.016550, loss_ce: 0.006343
2021-12-10 12:47:41,061 iteration 5381 : loss : 0.019200, loss_ce: 0.009249
2021-12-10 12:47:42,624 iteration 5382 : loss : 0.017372, loss_ce: 0.005232
2021-12-10 12:47:44,266 iteration 5383 : loss : 0.023270, loss_ce: 0.011151
2021-12-10 12:47:45,984 iteration 5384 : loss : 0.020735, loss_ce: 0.007997
2021-12-10 12:47:47,517 iteration 5385 : loss : 0.015556, loss_ce: 0.005785
2021-12-10 12:47:48,983 iteration 5386 : loss : 0.015186, loss_ce: 0.004771
2021-12-10 12:47:50,504 iteration 5387 : loss : 0.019685, loss_ce: 0.008377
2021-12-10 12:47:52,112 iteration 5388 : loss : 0.025581, loss_ce: 0.009034
2021-12-10 12:47:53,785 iteration 5389 : loss : 0.029460, loss_ce: 0.008655
 79%|██████████████████████▉      | 317/400 [2:32:05<39:19, 28.43s/it]2021-12-10 12:47:55,357 iteration 5390 : loss : 0.023622, loss_ce: 0.007462
2021-12-10 12:47:56,960 iteration 5391 : loss : 0.022413, loss_ce: 0.007005
2021-12-10 12:47:58,574 iteration 5392 : loss : 0.017387, loss_ce: 0.008871
2021-12-10 12:48:00,133 iteration 5393 : loss : 0.028340, loss_ce: 0.011696
2021-12-10 12:48:01,660 iteration 5394 : loss : 0.017633, loss_ce: 0.008091
2021-12-10 12:48:03,239 iteration 5395 : loss : 0.015965, loss_ce: 0.004803
2021-12-10 12:48:04,742 iteration 5396 : loss : 0.020667, loss_ce: 0.010604
2021-12-10 12:48:06,361 iteration 5397 : loss : 0.021968, loss_ce: 0.007028
2021-12-10 12:48:07,924 iteration 5398 : loss : 0.018434, loss_ce: 0.006054
2021-12-10 12:48:09,404 iteration 5399 : loss : 0.026937, loss_ce: 0.007387
2021-12-10 12:48:11,051 iteration 5400 : loss : 0.026299, loss_ce: 0.008313
2021-12-10 12:48:12,637 iteration 5401 : loss : 0.030790, loss_ce: 0.013770
2021-12-10 12:48:14,198 iteration 5402 : loss : 0.018496, loss_ce: 0.006213
2021-12-10 12:48:15,727 iteration 5403 : loss : 0.024099, loss_ce: 0.009587
2021-12-10 12:48:17,232 iteration 5404 : loss : 0.014723, loss_ce: 0.004165
2021-12-10 12:48:18,754 iteration 5405 : loss : 0.017431, loss_ce: 0.007278
2021-12-10 12:48:20,354 iteration 5406 : loss : 0.017449, loss_ce: 0.004976
 80%|███████████████████████      | 318/400 [2:32:31<38:05, 27.87s/it]2021-12-10 12:48:21,991 iteration 5407 : loss : 0.029596, loss_ce: 0.010697
2021-12-10 12:48:23,543 iteration 5408 : loss : 0.020938, loss_ce: 0.006840
2021-12-10 12:48:25,180 iteration 5409 : loss : 0.020629, loss_ce: 0.009433
2021-12-10 12:48:26,697 iteration 5410 : loss : 0.024998, loss_ce: 0.011569
2021-12-10 12:48:28,252 iteration 5411 : loss : 0.018299, loss_ce: 0.007672
2021-12-10 12:48:29,819 iteration 5412 : loss : 0.020431, loss_ce: 0.008735
2021-12-10 12:48:31,347 iteration 5413 : loss : 0.018399, loss_ce: 0.008978
2021-12-10 12:48:32,913 iteration 5414 : loss : 0.017896, loss_ce: 0.008122
2021-12-10 12:48:34,560 iteration 5415 : loss : 0.036371, loss_ce: 0.014763
2021-12-10 12:48:36,056 iteration 5416 : loss : 0.014097, loss_ce: 0.004838
2021-12-10 12:48:37,644 iteration 5417 : loss : 0.017689, loss_ce: 0.005221
2021-12-10 12:48:39,179 iteration 5418 : loss : 0.018105, loss_ce: 0.006802
2021-12-10 12:48:40,771 iteration 5419 : loss : 0.019808, loss_ce: 0.005055
2021-12-10 12:48:42,394 iteration 5420 : loss : 0.025005, loss_ce: 0.007694
2021-12-10 12:48:43,979 iteration 5421 : loss : 0.025595, loss_ce: 0.011178
2021-12-10 12:48:45,409 iteration 5422 : loss : 0.014941, loss_ce: 0.006818
2021-12-10 12:48:46,993 iteration 5423 : loss : 0.043574, loss_ce: 0.010315
 80%|███████████████████████▏     | 319/400 [2:32:58<37:07, 27.50s/it]2021-12-10 12:48:48,671 iteration 5424 : loss : 0.022602, loss_ce: 0.008379
2021-12-10 12:48:50,184 iteration 5425 : loss : 0.017414, loss_ce: 0.005060
2021-12-10 12:48:51,731 iteration 5426 : loss : 0.026434, loss_ce: 0.008315
2021-12-10 12:48:53,190 iteration 5427 : loss : 0.016002, loss_ce: 0.006097
2021-12-10 12:48:54,705 iteration 5428 : loss : 0.021220, loss_ce: 0.008737
2021-12-10 12:48:56,274 iteration 5429 : loss : 0.015714, loss_ce: 0.005250
2021-12-10 12:48:57,834 iteration 5430 : loss : 0.018606, loss_ce: 0.007473
2021-12-10 12:48:59,322 iteration 5431 : loss : 0.022683, loss_ce: 0.008007
2021-12-10 12:49:00,959 iteration 5432 : loss : 0.022743, loss_ce: 0.009780
2021-12-10 12:49:02,597 iteration 5433 : loss : 0.018629, loss_ce: 0.007045
2021-12-10 12:49:04,090 iteration 5434 : loss : 0.018196, loss_ce: 0.007916
2021-12-10 12:49:05,712 iteration 5435 : loss : 0.023059, loss_ce: 0.009555
2021-12-10 12:49:07,278 iteration 5436 : loss : 0.014989, loss_ce: 0.005397
2021-12-10 12:49:08,877 iteration 5437 : loss : 0.034582, loss_ce: 0.009458
2021-12-10 12:49:10,482 iteration 5438 : loss : 0.020998, loss_ce: 0.010030
2021-12-10 12:49:12,021 iteration 5439 : loss : 0.020805, loss_ce: 0.009386
2021-12-10 12:49:12,021 Training Data Eval:
2021-12-10 12:49:19,773   Average segmentation loss on training set: 0.0110
2021-12-10 12:49:19,773 Validation Data Eval:
2021-12-10 12:49:22,423   Average segmentation loss on validation set: 0.0696
2021-12-10 12:49:23,915 iteration 5440 : loss : 0.018368, loss_ce: 0.006036
 80%|███████████████████████▏     | 320/400 [2:33:35<40:26, 30.33s/it]2021-12-10 12:49:25,495 iteration 5441 : loss : 0.021470, loss_ce: 0.007740
2021-12-10 12:49:26,987 iteration 5442 : loss : 0.018200, loss_ce: 0.006243
2021-12-10 12:49:28,522 iteration 5443 : loss : 0.016990, loss_ce: 0.005410
2021-12-10 12:49:29,981 iteration 5444 : loss : 0.017748, loss_ce: 0.005932
2021-12-10 12:49:31,543 iteration 5445 : loss : 0.019044, loss_ce: 0.007031
2021-12-10 12:49:33,043 iteration 5446 : loss : 0.016658, loss_ce: 0.007856
2021-12-10 12:49:34,689 iteration 5447 : loss : 0.021702, loss_ce: 0.007177
2021-12-10 12:49:36,188 iteration 5448 : loss : 0.016527, loss_ce: 0.007708
2021-12-10 12:49:37,744 iteration 5449 : loss : 0.026033, loss_ce: 0.014222
2021-12-10 12:49:39,284 iteration 5450 : loss : 0.017836, loss_ce: 0.007322
2021-12-10 12:49:40,766 iteration 5451 : loss : 0.017946, loss_ce: 0.005750
2021-12-10 12:49:42,329 iteration 5452 : loss : 0.019421, loss_ce: 0.006758
2021-12-10 12:49:43,832 iteration 5453 : loss : 0.013943, loss_ce: 0.005470
2021-12-10 12:49:45,436 iteration 5454 : loss : 0.023662, loss_ce: 0.011674
2021-12-10 12:49:47,018 iteration 5455 : loss : 0.026666, loss_ce: 0.008763
2021-12-10 12:49:48,571 iteration 5456 : loss : 0.016238, loss_ce: 0.003560
2021-12-10 12:49:50,071 iteration 5457 : loss : 0.018332, loss_ce: 0.006417
 80%|███████████████████████▎     | 321/400 [2:34:01<38:17, 29.08s/it]2021-12-10 12:49:51,661 iteration 5458 : loss : 0.024093, loss_ce: 0.007451
2021-12-10 12:49:53,146 iteration 5459 : loss : 0.017301, loss_ce: 0.007512
2021-12-10 12:49:54,697 iteration 5460 : loss : 0.013858, loss_ce: 0.004603
2021-12-10 12:49:56,229 iteration 5461 : loss : 0.021430, loss_ce: 0.007921
2021-12-10 12:49:57,756 iteration 5462 : loss : 0.040567, loss_ce: 0.014996
2021-12-10 12:49:59,313 iteration 5463 : loss : 0.020770, loss_ce: 0.005804
2021-12-10 12:50:00,870 iteration 5464 : loss : 0.017603, loss_ce: 0.008022
2021-12-10 12:50:02,492 iteration 5465 : loss : 0.022086, loss_ce: 0.008408
2021-12-10 12:50:04,096 iteration 5466 : loss : 0.018033, loss_ce: 0.006223
2021-12-10 12:50:05,670 iteration 5467 : loss : 0.021693, loss_ce: 0.008815
2021-12-10 12:50:07,245 iteration 5468 : loss : 0.018109, loss_ce: 0.007351
2021-12-10 12:50:08,722 iteration 5469 : loss : 0.020241, loss_ce: 0.006090
2021-12-10 12:50:10,252 iteration 5470 : loss : 0.011986, loss_ce: 0.004066
2021-12-10 12:50:11,787 iteration 5471 : loss : 0.026258, loss_ce: 0.008895
2021-12-10 12:50:13,359 iteration 5472 : loss : 0.026323, loss_ce: 0.009182
2021-12-10 12:50:14,850 iteration 5473 : loss : 0.015178, loss_ce: 0.005303
2021-12-10 12:50:16,342 iteration 5474 : loss : 0.018386, loss_ce: 0.006197
 80%|███████████████████████▎     | 322/400 [2:34:27<36:42, 28.23s/it]2021-12-10 12:50:17,965 iteration 5475 : loss : 0.025311, loss_ce: 0.008658
2021-12-10 12:50:19,577 iteration 5476 : loss : 0.027683, loss_ce: 0.012452
2021-12-10 12:50:21,129 iteration 5477 : loss : 0.025928, loss_ce: 0.003570
2021-12-10 12:50:22,596 iteration 5478 : loss : 0.020924, loss_ce: 0.006248
2021-12-10 12:50:24,134 iteration 5479 : loss : 0.015816, loss_ce: 0.006778
2021-12-10 12:50:25,671 iteration 5480 : loss : 0.022075, loss_ce: 0.007466
2021-12-10 12:50:27,178 iteration 5481 : loss : 0.019742, loss_ce: 0.006815
2021-12-10 12:50:28,815 iteration 5482 : loss : 0.032307, loss_ce: 0.006880
2021-12-10 12:50:30,274 iteration 5483 : loss : 0.013186, loss_ce: 0.005281
2021-12-10 12:50:31,831 iteration 5484 : loss : 0.028162, loss_ce: 0.010399
2021-12-10 12:50:33,376 iteration 5485 : loss : 0.016061, loss_ce: 0.006436
2021-12-10 12:50:34,921 iteration 5486 : loss : 0.026473, loss_ce: 0.011067
2021-12-10 12:50:36,481 iteration 5487 : loss : 0.022590, loss_ce: 0.007701
2021-12-10 12:50:37,992 iteration 5488 : loss : 0.021314, loss_ce: 0.009996
2021-12-10 12:50:39,490 iteration 5489 : loss : 0.015668, loss_ce: 0.008338
2021-12-10 12:50:41,118 iteration 5490 : loss : 0.021735, loss_ce: 0.008061
2021-12-10 12:50:42,632 iteration 5491 : loss : 0.015521, loss_ce: 0.004396
 81%|███████████████████████▍     | 323/400 [2:34:54<35:29, 27.65s/it]2021-12-10 12:50:44,135 iteration 5492 : loss : 0.016339, loss_ce: 0.006205
2021-12-10 12:50:45,705 iteration 5493 : loss : 0.027437, loss_ce: 0.009341
2021-12-10 12:50:47,211 iteration 5494 : loss : 0.017539, loss_ce: 0.005181
2021-12-10 12:50:48,764 iteration 5495 : loss : 0.015328, loss_ce: 0.004238
2021-12-10 12:50:50,325 iteration 5496 : loss : 0.018295, loss_ce: 0.005130
2021-12-10 12:50:51,891 iteration 5497 : loss : 0.024336, loss_ce: 0.009468
2021-12-10 12:50:53,491 iteration 5498 : loss : 0.029894, loss_ce: 0.009817
2021-12-10 12:50:55,071 iteration 5499 : loss : 0.025509, loss_ce: 0.013725
2021-12-10 12:50:56,554 iteration 5500 : loss : 0.016307, loss_ce: 0.006597
2021-12-10 12:50:58,112 iteration 5501 : loss : 0.020983, loss_ce: 0.009051
2021-12-10 12:50:59,611 iteration 5502 : loss : 0.013049, loss_ce: 0.005580
2021-12-10 12:51:01,154 iteration 5503 : loss : 0.020127, loss_ce: 0.005482
2021-12-10 12:51:02,653 iteration 5504 : loss : 0.018147, loss_ce: 0.006524
2021-12-10 12:51:04,190 iteration 5505 : loss : 0.019733, loss_ce: 0.007230
2021-12-10 12:51:05,771 iteration 5506 : loss : 0.030721, loss_ce: 0.010599
2021-12-10 12:51:07,308 iteration 5507 : loss : 0.019232, loss_ce: 0.008043
2021-12-10 12:51:08,862 iteration 5508 : loss : 0.026812, loss_ce: 0.008363
 81%|███████████████████████▍     | 324/400 [2:35:20<34:29, 27.23s/it]2021-12-10 12:51:10,477 iteration 5509 : loss : 0.023103, loss_ce: 0.007086
2021-12-10 12:51:12,120 iteration 5510 : loss : 0.020469, loss_ce: 0.007544
2021-12-10 12:51:13,650 iteration 5511 : loss : 0.015081, loss_ce: 0.005411
2021-12-10 12:51:15,255 iteration 5512 : loss : 0.023525, loss_ce: 0.008618
2021-12-10 12:51:16,776 iteration 5513 : loss : 0.014261, loss_ce: 0.005955
2021-12-10 12:51:18,251 iteration 5514 : loss : 0.015485, loss_ce: 0.006220
2021-12-10 12:51:19,859 iteration 5515 : loss : 0.038824, loss_ce: 0.008775
2021-12-10 12:51:21,372 iteration 5516 : loss : 0.018284, loss_ce: 0.007594
2021-12-10 12:51:22,923 iteration 5517 : loss : 0.017932, loss_ce: 0.007685
2021-12-10 12:51:24,459 iteration 5518 : loss : 0.029127, loss_ce: 0.009204
2021-12-10 12:51:26,037 iteration 5519 : loss : 0.019538, loss_ce: 0.007461
2021-12-10 12:51:27,584 iteration 5520 : loss : 0.015077, loss_ce: 0.006118
2021-12-10 12:51:29,157 iteration 5521 : loss : 0.024446, loss_ce: 0.008896
2021-12-10 12:51:30,710 iteration 5522 : loss : 0.019125, loss_ce: 0.006329
2021-12-10 12:51:32,226 iteration 5523 : loss : 0.012260, loss_ce: 0.004329
2021-12-10 12:51:33,752 iteration 5524 : loss : 0.022726, loss_ce: 0.010074
2021-12-10 12:51:33,752 Training Data Eval:
2021-12-10 12:51:41,501   Average segmentation loss on training set: 0.0108
2021-12-10 12:51:41,501 Validation Data Eval:
2021-12-10 12:51:44,168   Average segmentation loss on validation set: 0.0668
2021-12-10 12:51:45,707 iteration 5525 : loss : 0.029304, loss_ce: 0.014709
 81%|███████████████████████▌     | 325/400 [2:35:57<37:38, 30.11s/it]2021-12-10 12:51:47,361 iteration 5526 : loss : 0.030277, loss_ce: 0.009041
2021-12-10 12:51:48,924 iteration 5527 : loss : 0.018050, loss_ce: 0.007957
2021-12-10 12:51:50,475 iteration 5528 : loss : 0.025458, loss_ce: 0.010328
2021-12-10 12:51:52,061 iteration 5529 : loss : 0.027149, loss_ce: 0.011033
2021-12-10 12:51:53,549 iteration 5530 : loss : 0.016522, loss_ce: 0.007541
2021-12-10 12:51:55,066 iteration 5531 : loss : 0.019859, loss_ce: 0.009149
2021-12-10 12:51:56,565 iteration 5532 : loss : 0.016392, loss_ce: 0.007509
2021-12-10 12:51:58,175 iteration 5533 : loss : 0.023235, loss_ce: 0.007302
2021-12-10 12:51:59,718 iteration 5534 : loss : 0.019536, loss_ce: 0.006936
2021-12-10 12:52:01,333 iteration 5535 : loss : 0.020121, loss_ce: 0.007417
2021-12-10 12:52:02,997 iteration 5536 : loss : 0.016721, loss_ce: 0.007258
2021-12-10 12:52:04,580 iteration 5537 : loss : 0.021933, loss_ce: 0.006963
2021-12-10 12:52:06,157 iteration 5538 : loss : 0.019491, loss_ce: 0.006941
2021-12-10 12:52:07,818 iteration 5539 : loss : 0.023324, loss_ce: 0.005293
2021-12-10 12:52:09,333 iteration 5540 : loss : 0.016841, loss_ce: 0.007749
2021-12-10 12:52:10,893 iteration 5541 : loss : 0.019715, loss_ce: 0.006732
2021-12-10 12:52:12,423 iteration 5542 : loss : 0.015130, loss_ce: 0.005741
 82%|███████████████████████▋     | 326/400 [2:36:23<35:52, 29.09s/it]2021-12-10 12:52:14,052 iteration 5543 : loss : 0.020834, loss_ce: 0.007488
2021-12-10 12:52:15,616 iteration 5544 : loss : 0.019109, loss_ce: 0.008329
2021-12-10 12:52:17,138 iteration 5545 : loss : 0.017948, loss_ce: 0.006954
2021-12-10 12:52:18,635 iteration 5546 : loss : 0.015438, loss_ce: 0.005270
2021-12-10 12:52:20,192 iteration 5547 : loss : 0.019526, loss_ce: 0.007671
2021-12-10 12:52:21,795 iteration 5548 : loss : 0.040991, loss_ce: 0.013520
2021-12-10 12:52:23,278 iteration 5549 : loss : 0.016931, loss_ce: 0.006706
2021-12-10 12:52:24,798 iteration 5550 : loss : 0.017869, loss_ce: 0.006543
2021-12-10 12:52:26,357 iteration 5551 : loss : 0.040755, loss_ce: 0.016080
2021-12-10 12:52:27,847 iteration 5552 : loss : 0.014784, loss_ce: 0.005764
2021-12-10 12:52:29,415 iteration 5553 : loss : 0.021911, loss_ce: 0.009606
2021-12-10 12:52:31,017 iteration 5554 : loss : 0.018828, loss_ce: 0.006110
2021-12-10 12:52:32,589 iteration 5555 : loss : 0.038410, loss_ce: 0.011739
2021-12-10 12:52:34,052 iteration 5556 : loss : 0.018874, loss_ce: 0.006993
2021-12-10 12:52:35,670 iteration 5557 : loss : 0.025905, loss_ce: 0.007417
2021-12-10 12:52:37,231 iteration 5558 : loss : 0.017827, loss_ce: 0.005886
2021-12-10 12:52:38,680 iteration 5559 : loss : 0.013594, loss_ce: 0.005302
 82%|███████████████████████▋     | 327/400 [2:36:50<34:21, 28.24s/it]2021-12-10 12:52:40,457 iteration 5560 : loss : 0.032398, loss_ce: 0.011968
2021-12-10 12:52:41,988 iteration 5561 : loss : 0.018987, loss_ce: 0.006323
2021-12-10 12:52:43,528 iteration 5562 : loss : 0.027819, loss_ce: 0.007767
2021-12-10 12:52:45,068 iteration 5563 : loss : 0.015472, loss_ce: 0.005939
2021-12-10 12:52:46,709 iteration 5564 : loss : 0.020748, loss_ce: 0.006443
2021-12-10 12:52:48,265 iteration 5565 : loss : 0.014854, loss_ce: 0.005824
2021-12-10 12:52:49,865 iteration 5566 : loss : 0.021255, loss_ce: 0.011015
2021-12-10 12:52:51,519 iteration 5567 : loss : 0.022369, loss_ce: 0.010961
2021-12-10 12:52:53,072 iteration 5568 : loss : 0.024906, loss_ce: 0.009799
2021-12-10 12:52:54,673 iteration 5569 : loss : 0.023851, loss_ce: 0.010057
2021-12-10 12:52:56,248 iteration 5570 : loss : 0.014365, loss_ce: 0.005079
2021-12-10 12:52:57,851 iteration 5571 : loss : 0.022351, loss_ce: 0.009408
2021-12-10 12:52:59,402 iteration 5572 : loss : 0.018999, loss_ce: 0.007103
2021-12-10 12:53:00,936 iteration 5573 : loss : 0.016631, loss_ce: 0.005008
2021-12-10 12:53:02,593 iteration 5574 : loss : 0.017684, loss_ce: 0.005858
2021-12-10 12:53:04,030 iteration 5575 : loss : 0.012724, loss_ce: 0.005604
2021-12-10 12:53:05,442 iteration 5576 : loss : 0.014493, loss_ce: 0.004519
 82%|███████████████████████▊     | 328/400 [2:37:16<33:21, 27.80s/it]2021-12-10 12:53:07,017 iteration 5577 : loss : 0.016399, loss_ce: 0.005751
2021-12-10 12:53:08,530 iteration 5578 : loss : 0.026141, loss_ce: 0.007073
2021-12-10 12:53:10,077 iteration 5579 : loss : 0.020658, loss_ce: 0.006060
2021-12-10 12:53:11,676 iteration 5580 : loss : 0.012900, loss_ce: 0.004533
2021-12-10 12:53:13,203 iteration 5581 : loss : 0.017624, loss_ce: 0.006481
2021-12-10 12:53:14,799 iteration 5582 : loss : 0.019787, loss_ce: 0.006032
2021-12-10 12:53:16,329 iteration 5583 : loss : 0.023925, loss_ce: 0.006749
2021-12-10 12:53:17,971 iteration 5584 : loss : 0.024974, loss_ce: 0.011068
2021-12-10 12:53:19,496 iteration 5585 : loss : 0.022847, loss_ce: 0.008698
2021-12-10 12:53:21,043 iteration 5586 : loss : 0.020158, loss_ce: 0.009054
2021-12-10 12:53:22,597 iteration 5587 : loss : 0.020060, loss_ce: 0.008787
2021-12-10 12:53:24,234 iteration 5588 : loss : 0.023941, loss_ce: 0.008460
2021-12-10 12:53:25,848 iteration 5589 : loss : 0.018224, loss_ce: 0.007271
2021-12-10 12:53:27,410 iteration 5590 : loss : 0.020693, loss_ce: 0.008184
2021-12-10 12:53:28,961 iteration 5591 : loss : 0.018519, loss_ce: 0.008400
2021-12-10 12:53:30,497 iteration 5592 : loss : 0.017152, loss_ce: 0.005729
2021-12-10 12:53:32,037 iteration 5593 : loss : 0.015522, loss_ce: 0.009068
 82%|███████████████████████▊     | 329/400 [2:37:43<32:27, 27.44s/it]2021-12-10 12:53:33,659 iteration 5594 : loss : 0.016994, loss_ce: 0.006570
2021-12-10 12:53:35,183 iteration 5595 : loss : 0.017118, loss_ce: 0.008554
2021-12-10 12:53:36,700 iteration 5596 : loss : 0.013571, loss_ce: 0.004396
2021-12-10 12:53:38,269 iteration 5597 : loss : 0.015071, loss_ce: 0.004742
2021-12-10 12:53:39,895 iteration 5598 : loss : 0.020457, loss_ce: 0.008062
2021-12-10 12:53:41,498 iteration 5599 : loss : 0.015732, loss_ce: 0.005812
2021-12-10 12:53:43,090 iteration 5600 : loss : 0.020503, loss_ce: 0.008520
2021-12-10 12:53:44,687 iteration 5601 : loss : 0.018747, loss_ce: 0.006010
2021-12-10 12:53:46,198 iteration 5602 : loss : 0.021646, loss_ce: 0.005108
2021-12-10 12:53:47,804 iteration 5603 : loss : 0.020869, loss_ce: 0.009182
2021-12-10 12:53:49,319 iteration 5604 : loss : 0.015238, loss_ce: 0.006690
2021-12-10 12:53:50,838 iteration 5605 : loss : 0.015480, loss_ce: 0.004904
2021-12-10 12:53:52,465 iteration 5606 : loss : 0.024954, loss_ce: 0.008183
2021-12-10 12:53:54,020 iteration 5607 : loss : 0.023062, loss_ce: 0.008529
2021-12-10 12:53:55,702 iteration 5608 : loss : 0.023546, loss_ce: 0.010468
2021-12-10 12:53:57,222 iteration 5609 : loss : 0.025180, loss_ce: 0.015299
2021-12-10 12:53:57,222 Training Data Eval:
2021-12-10 12:54:04,976   Average segmentation loss on training set: 0.0101
2021-12-10 12:54:04,977 Validation Data Eval:
2021-12-10 12:54:07,632   Average segmentation loss on validation set: 0.0698
2021-12-10 12:54:09,218 iteration 5610 : loss : 0.016006, loss_ce: 0.005885
 82%|███████████████████████▉     | 330/400 [2:38:20<35:25, 30.36s/it]2021-12-10 12:54:10,868 iteration 5611 : loss : 0.020223, loss_ce: 0.009381
2021-12-10 12:54:12,431 iteration 5612 : loss : 0.015456, loss_ce: 0.004834
2021-12-10 12:54:13,980 iteration 5613 : loss : 0.025361, loss_ce: 0.010896
2021-12-10 12:54:15,521 iteration 5614 : loss : 0.018008, loss_ce: 0.006201
2021-12-10 12:54:17,093 iteration 5615 : loss : 0.019312, loss_ce: 0.006746
2021-12-10 12:54:18,690 iteration 5616 : loss : 0.036951, loss_ce: 0.014255
2021-12-10 12:54:20,248 iteration 5617 : loss : 0.018902, loss_ce: 0.008425
2021-12-10 12:54:21,742 iteration 5618 : loss : 0.017329, loss_ce: 0.007904
2021-12-10 12:54:23,336 iteration 5619 : loss : 0.027837, loss_ce: 0.008741
2021-12-10 12:54:24,937 iteration 5620 : loss : 0.015884, loss_ce: 0.004641
2021-12-10 12:54:26,462 iteration 5621 : loss : 0.028515, loss_ce: 0.014183
2021-12-10 12:54:28,109 iteration 5622 : loss : 0.023137, loss_ce: 0.009500
2021-12-10 12:54:29,624 iteration 5623 : loss : 0.020795, loss_ce: 0.006093
2021-12-10 12:54:31,204 iteration 5624 : loss : 0.020281, loss_ce: 0.008825
2021-12-10 12:54:32,797 iteration 5625 : loss : 0.019326, loss_ce: 0.007938
2021-12-10 12:54:34,352 iteration 5626 : loss : 0.018899, loss_ce: 0.006923
2021-12-10 12:54:35,895 iteration 5627 : loss : 0.026533, loss_ce: 0.008543
 83%|███████████████████████▉     | 331/400 [2:38:47<33:38, 29.26s/it]2021-12-10 12:54:37,402 iteration 5628 : loss : 0.014313, loss_ce: 0.005259
2021-12-10 12:54:38,981 iteration 5629 : loss : 0.023572, loss_ce: 0.010636
2021-12-10 12:54:40,533 iteration 5630 : loss : 0.014480, loss_ce: 0.004543
2021-12-10 12:54:42,198 iteration 5631 : loss : 0.031504, loss_ce: 0.015286
2021-12-10 12:54:43,668 iteration 5632 : loss : 0.022830, loss_ce: 0.010962
2021-12-10 12:54:45,275 iteration 5633 : loss : 0.028680, loss_ce: 0.010271
2021-12-10 12:54:46,778 iteration 5634 : loss : 0.018855, loss_ce: 0.007266
2021-12-10 12:54:48,361 iteration 5635 : loss : 0.032957, loss_ce: 0.007433
2021-12-10 12:54:49,856 iteration 5636 : loss : 0.014046, loss_ce: 0.006329
2021-12-10 12:54:51,427 iteration 5637 : loss : 0.022622, loss_ce: 0.011196
2021-12-10 12:54:52,867 iteration 5638 : loss : 0.015140, loss_ce: 0.004559
2021-12-10 12:54:54,362 iteration 5639 : loss : 0.024978, loss_ce: 0.006394
2021-12-10 12:54:55,896 iteration 5640 : loss : 0.018129, loss_ce: 0.009170
2021-12-10 12:54:57,481 iteration 5641 : loss : 0.021275, loss_ce: 0.009981
2021-12-10 12:54:59,047 iteration 5642 : loss : 0.013470, loss_ce: 0.002569
2021-12-10 12:55:00,647 iteration 5643 : loss : 0.020681, loss_ce: 0.005595
2021-12-10 12:55:02,225 iteration 5644 : loss : 0.025563, loss_ce: 0.009271
 83%|████████████████████████     | 332/400 [2:39:13<32:09, 28.38s/it]2021-12-10 12:55:03,957 iteration 5645 : loss : 0.031144, loss_ce: 0.012959
2021-12-10 12:55:05,471 iteration 5646 : loss : 0.030629, loss_ce: 0.010862
2021-12-10 12:55:07,019 iteration 5647 : loss : 0.022820, loss_ce: 0.012011
2021-12-10 12:55:08,618 iteration 5648 : loss : 0.023996, loss_ce: 0.007556
2021-12-10 12:55:10,215 iteration 5649 : loss : 0.017771, loss_ce: 0.007941
2021-12-10 12:55:11,781 iteration 5650 : loss : 0.019625, loss_ce: 0.007480
2021-12-10 12:55:13,334 iteration 5651 : loss : 0.019610, loss_ce: 0.010197
2021-12-10 12:55:14,808 iteration 5652 : loss : 0.014182, loss_ce: 0.004990
2021-12-10 12:55:16,330 iteration 5653 : loss : 0.019107, loss_ce: 0.007236
2021-12-10 12:55:17,815 iteration 5654 : loss : 0.018508, loss_ce: 0.005502
2021-12-10 12:55:19,383 iteration 5655 : loss : 0.028380, loss_ce: 0.010332
2021-12-10 12:55:20,931 iteration 5656 : loss : 0.016984, loss_ce: 0.005602
2021-12-10 12:55:22,481 iteration 5657 : loss : 0.015392, loss_ce: 0.005760
2021-12-10 12:55:24,072 iteration 5658 : loss : 0.022717, loss_ce: 0.011203
2021-12-10 12:55:25,596 iteration 5659 : loss : 0.014676, loss_ce: 0.004318
2021-12-10 12:55:27,082 iteration 5660 : loss : 0.012735, loss_ce: 0.004761
2021-12-10 12:55:28,729 iteration 5661 : loss : 0.025144, loss_ce: 0.009156
 83%|████████████████████████▏    | 333/400 [2:39:40<31:03, 27.82s/it]2021-12-10 12:55:30,334 iteration 5662 : loss : 0.020855, loss_ce: 0.005165
2021-12-10 12:55:31,887 iteration 5663 : loss : 0.017617, loss_ce: 0.006779
2021-12-10 12:55:33,460 iteration 5664 : loss : 0.028898, loss_ce: 0.008984
2021-12-10 12:55:34,919 iteration 5665 : loss : 0.017261, loss_ce: 0.005823
2021-12-10 12:55:36,491 iteration 5666 : loss : 0.017877, loss_ce: 0.005820
2021-12-10 12:55:38,094 iteration 5667 : loss : 0.020921, loss_ce: 0.007969
2021-12-10 12:55:39,636 iteration 5668 : loss : 0.014539, loss_ce: 0.006382
2021-12-10 12:55:41,228 iteration 5669 : loss : 0.017411, loss_ce: 0.008545
2021-12-10 12:55:42,788 iteration 5670 : loss : 0.014450, loss_ce: 0.004839
2021-12-10 12:55:44,348 iteration 5671 : loss : 0.016438, loss_ce: 0.006003
2021-12-10 12:55:45,902 iteration 5672 : loss : 0.021657, loss_ce: 0.006459
2021-12-10 12:55:47,433 iteration 5673 : loss : 0.014984, loss_ce: 0.004704
2021-12-10 12:55:49,074 iteration 5674 : loss : 0.016339, loss_ce: 0.007605
2021-12-10 12:55:50,594 iteration 5675 : loss : 0.017161, loss_ce: 0.007003
2021-12-10 12:55:52,208 iteration 5676 : loss : 0.021722, loss_ce: 0.007417
2021-12-10 12:55:53,810 iteration 5677 : loss : 0.015447, loss_ce: 0.007757
2021-12-10 12:55:55,379 iteration 5678 : loss : 0.027849, loss_ce: 0.009180
 84%|████████████████████████▏    | 334/400 [2:40:06<30:12, 27.46s/it]2021-12-10 12:55:56,998 iteration 5679 : loss : 0.024602, loss_ce: 0.012027
2021-12-10 12:55:58,439 iteration 5680 : loss : 0.014790, loss_ce: 0.004093
2021-12-10 12:56:00,038 iteration 5681 : loss : 0.020833, loss_ce: 0.006910
2021-12-10 12:56:01,646 iteration 5682 : loss : 0.025539, loss_ce: 0.013026
2021-12-10 12:56:03,164 iteration 5683 : loss : 0.013148, loss_ce: 0.004596
2021-12-10 12:56:04,669 iteration 5684 : loss : 0.014415, loss_ce: 0.007115
2021-12-10 12:56:06,243 iteration 5685 : loss : 0.019198, loss_ce: 0.008117
2021-12-10 12:56:07,770 iteration 5686 : loss : 0.015667, loss_ce: 0.005846
2021-12-10 12:56:09,313 iteration 5687 : loss : 0.013853, loss_ce: 0.005637
2021-12-10 12:56:10,957 iteration 5688 : loss : 0.025319, loss_ce: 0.010798
2021-12-10 12:56:12,513 iteration 5689 : loss : 0.019502, loss_ce: 0.005517
2021-12-10 12:56:14,077 iteration 5690 : loss : 0.017822, loss_ce: 0.007669
2021-12-10 12:56:15,664 iteration 5691 : loss : 0.020429, loss_ce: 0.008129
2021-12-10 12:56:17,246 iteration 5692 : loss : 0.025367, loss_ce: 0.011599
2021-12-10 12:56:18,812 iteration 5693 : loss : 0.023985, loss_ce: 0.005616
2021-12-10 12:56:20,347 iteration 5694 : loss : 0.026571, loss_ce: 0.011991
2021-12-10 12:56:20,348 Training Data Eval:
2021-12-10 12:56:28,091   Average segmentation loss on training set: 0.0099
2021-12-10 12:56:28,091 Validation Data Eval:
2021-12-10 12:56:30,741   Average segmentation loss on validation set: 0.0698
2021-12-10 12:56:32,243 iteration 5695 : loss : 0.014272, loss_ce: 0.004456
 84%|████████████████████████▎    | 335/400 [2:40:43<32:48, 30.28s/it]2021-12-10 12:56:33,790 iteration 5696 : loss : 0.012656, loss_ce: 0.006413
2021-12-10 12:56:35,276 iteration 5697 : loss : 0.013970, loss_ce: 0.006117
2021-12-10 12:56:36,879 iteration 5698 : loss : 0.024629, loss_ce: 0.008497
2021-12-10 12:56:38,350 iteration 5699 : loss : 0.014526, loss_ce: 0.006168
2021-12-10 12:56:39,870 iteration 5700 : loss : 0.015959, loss_ce: 0.005606
2021-12-10 12:56:41,355 iteration 5701 : loss : 0.014636, loss_ce: 0.006586
2021-12-10 12:56:43,007 iteration 5702 : loss : 0.017368, loss_ce: 0.006829
2021-12-10 12:56:44,594 iteration 5703 : loss : 0.021387, loss_ce: 0.009302
2021-12-10 12:56:46,160 iteration 5704 : loss : 0.022719, loss_ce: 0.009116
2021-12-10 12:56:47,743 iteration 5705 : loss : 0.016272, loss_ce: 0.005073
2021-12-10 12:56:49,201 iteration 5706 : loss : 0.013514, loss_ce: 0.005000
2021-12-10 12:56:50,726 iteration 5707 : loss : 0.017949, loss_ce: 0.006246
2021-12-10 12:56:52,220 iteration 5708 : loss : 0.016553, loss_ce: 0.006238
2021-12-10 12:56:53,775 iteration 5709 : loss : 0.014456, loss_ce: 0.004608
2021-12-10 12:56:55,311 iteration 5710 : loss : 0.030649, loss_ce: 0.009802
2021-12-10 12:56:56,779 iteration 5711 : loss : 0.016666, loss_ce: 0.005739
2021-12-10 12:56:58,338 iteration 5712 : loss : 0.022373, loss_ce: 0.009818
 84%|████████████████████████▎    | 336/400 [2:41:09<30:57, 29.03s/it]2021-12-10 12:56:59,986 iteration 5713 : loss : 0.020512, loss_ce: 0.007666
2021-12-10 12:57:01,585 iteration 5714 : loss : 0.022677, loss_ce: 0.010071
2021-12-10 12:57:03,206 iteration 5715 : loss : 0.018171, loss_ce: 0.006577
2021-12-10 12:57:04,729 iteration 5716 : loss : 0.018770, loss_ce: 0.007787
2021-12-10 12:57:06,372 iteration 5717 : loss : 0.023129, loss_ce: 0.008983
2021-12-10 12:57:07,870 iteration 5718 : loss : 0.018531, loss_ce: 0.005937
2021-12-10 12:57:09,361 iteration 5719 : loss : 0.013690, loss_ce: 0.005489
2021-12-10 12:57:10,957 iteration 5720 : loss : 0.017585, loss_ce: 0.007233
2021-12-10 12:57:12,518 iteration 5721 : loss : 0.023735, loss_ce: 0.011405
2021-12-10 12:57:14,063 iteration 5722 : loss : 0.021663, loss_ce: 0.008766
2021-12-10 12:57:15,622 iteration 5723 : loss : 0.021564, loss_ce: 0.008063
2021-12-10 12:57:17,221 iteration 5724 : loss : 0.017738, loss_ce: 0.006049
2021-12-10 12:57:18,775 iteration 5725 : loss : 0.013771, loss_ce: 0.004940
2021-12-10 12:57:20,278 iteration 5726 : loss : 0.019159, loss_ce: 0.004558
2021-12-10 12:57:21,850 iteration 5727 : loss : 0.015657, loss_ce: 0.004623
2021-12-10 12:57:23,378 iteration 5728 : loss : 0.016258, loss_ce: 0.005306
2021-12-10 12:57:24,998 iteration 5729 : loss : 0.019395, loss_ce: 0.007797
 84%|████████████████████████▍    | 337/400 [2:41:36<29:43, 28.32s/it]2021-12-10 12:57:26,542 iteration 5730 : loss : 0.017208, loss_ce: 0.008579
2021-12-10 12:57:28,150 iteration 5731 : loss : 0.021628, loss_ce: 0.010183
2021-12-10 12:57:29,651 iteration 5732 : loss : 0.013422, loss_ce: 0.005140
2021-12-10 12:57:31,265 iteration 5733 : loss : 0.035963, loss_ce: 0.010226
2021-12-10 12:57:32,873 iteration 5734 : loss : 0.019515, loss_ce: 0.008817
2021-12-10 12:57:34,395 iteration 5735 : loss : 0.018655, loss_ce: 0.006194
2021-12-10 12:57:35,914 iteration 5736 : loss : 0.024495, loss_ce: 0.010312
2021-12-10 12:57:37,543 iteration 5737 : loss : 0.033814, loss_ce: 0.011774
2021-12-10 12:57:39,057 iteration 5738 : loss : 0.017247, loss_ce: 0.006016
2021-12-10 12:57:40,567 iteration 5739 : loss : 0.015612, loss_ce: 0.005381
2021-12-10 12:57:42,108 iteration 5740 : loss : 0.023894, loss_ce: 0.010180
2021-12-10 12:57:43,653 iteration 5741 : loss : 0.018079, loss_ce: 0.008832
2021-12-10 12:57:45,216 iteration 5742 : loss : 0.014751, loss_ce: 0.003183
2021-12-10 12:57:46,795 iteration 5743 : loss : 0.014833, loss_ce: 0.006403
2021-12-10 12:57:48,428 iteration 5744 : loss : 0.028863, loss_ce: 0.011780
2021-12-10 12:57:50,052 iteration 5745 : loss : 0.017948, loss_ce: 0.007348
2021-12-10 12:57:51,564 iteration 5746 : loss : 0.019287, loss_ce: 0.005424
 84%|████████████████████████▌    | 338/400 [2:42:03<28:43, 27.80s/it]2021-12-10 12:57:53,169 iteration 5747 : loss : 0.018342, loss_ce: 0.006250
2021-12-10 12:57:54,736 iteration 5748 : loss : 0.021106, loss_ce: 0.008747
2021-12-10 12:57:56,285 iteration 5749 : loss : 0.020441, loss_ce: 0.008597
2021-12-10 12:57:57,827 iteration 5750 : loss : 0.016835, loss_ce: 0.005884
2021-12-10 12:57:59,305 iteration 5751 : loss : 0.016753, loss_ce: 0.005635
2021-12-10 12:58:00,824 iteration 5752 : loss : 0.019903, loss_ce: 0.006511
2021-12-10 12:58:02,404 iteration 5753 : loss : 0.013404, loss_ce: 0.004725
2021-12-10 12:58:04,021 iteration 5754 : loss : 0.022653, loss_ce: 0.006142
2021-12-10 12:58:05,570 iteration 5755 : loss : 0.013568, loss_ce: 0.005070
2021-12-10 12:58:07,073 iteration 5756 : loss : 0.015887, loss_ce: 0.005967
2021-12-10 12:58:08,503 iteration 5757 : loss : 0.013083, loss_ce: 0.005224
2021-12-10 12:58:10,085 iteration 5758 : loss : 0.029086, loss_ce: 0.011128
2021-12-10 12:58:11,681 iteration 5759 : loss : 0.015139, loss_ce: 0.006407
2021-12-10 12:58:13,301 iteration 5760 : loss : 0.026675, loss_ce: 0.018158
2021-12-10 12:58:14,941 iteration 5761 : loss : 0.030109, loss_ce: 0.011983
2021-12-10 12:58:16,427 iteration 5762 : loss : 0.014341, loss_ce: 0.006348
2021-12-10 12:58:18,007 iteration 5763 : loss : 0.015232, loss_ce: 0.006375
 85%|████████████████████████▌    | 339/400 [2:42:29<27:50, 27.39s/it]2021-12-10 12:58:19,603 iteration 5764 : loss : 0.015414, loss_ce: 0.005435
2021-12-10 12:58:21,203 iteration 5765 : loss : 0.028634, loss_ce: 0.006644
2021-12-10 12:58:22,768 iteration 5766 : loss : 0.022027, loss_ce: 0.011006
2021-12-10 12:58:24,313 iteration 5767 : loss : 0.015958, loss_ce: 0.008850
2021-12-10 12:58:25,970 iteration 5768 : loss : 0.019942, loss_ce: 0.007430
2021-12-10 12:58:27,566 iteration 5769 : loss : 0.026461, loss_ce: 0.008125
2021-12-10 12:58:29,070 iteration 5770 : loss : 0.014903, loss_ce: 0.005389
2021-12-10 12:58:30,636 iteration 5771 : loss : 0.019990, loss_ce: 0.007890
2021-12-10 12:58:32,172 iteration 5772 : loss : 0.017721, loss_ce: 0.006123
2021-12-10 12:58:33,637 iteration 5773 : loss : 0.017967, loss_ce: 0.005720
2021-12-10 12:58:35,099 iteration 5774 : loss : 0.016153, loss_ce: 0.004426
2021-12-10 12:58:36,661 iteration 5775 : loss : 0.020341, loss_ce: 0.008581
2021-12-10 12:58:38,273 iteration 5776 : loss : 0.033791, loss_ce: 0.018922
2021-12-10 12:58:39,731 iteration 5777 : loss : 0.018042, loss_ce: 0.007488
2021-12-10 12:58:41,241 iteration 5778 : loss : 0.025182, loss_ce: 0.009657
2021-12-10 12:58:42,761 iteration 5779 : loss : 0.019548, loss_ce: 0.006500
2021-12-10 12:58:42,762 Training Data Eval:
2021-12-10 12:58:50,515   Average segmentation loss on training set: 0.0099
2021-12-10 12:58:50,515 Validation Data Eval:
2021-12-10 12:58:53,170   Average segmentation loss on validation set: 0.0618
2021-12-10 12:58:54,695 iteration 5780 : loss : 0.021313, loss_ce: 0.007143
 85%|████████████████████████▋    | 340/400 [2:43:06<30:10, 30.18s/it]2021-12-10 12:58:56,265 iteration 5781 : loss : 0.025942, loss_ce: 0.007445
2021-12-10 12:58:57,875 iteration 5782 : loss : 0.023283, loss_ce: 0.010777
2021-12-10 12:58:59,424 iteration 5783 : loss : 0.018275, loss_ce: 0.006415
2021-12-10 12:59:00,994 iteration 5784 : loss : 0.015846, loss_ce: 0.008685
2021-12-10 12:59:02,498 iteration 5785 : loss : 0.011733, loss_ce: 0.004117
2021-12-10 12:59:04,003 iteration 5786 : loss : 0.019567, loss_ce: 0.008851
2021-12-10 12:59:05,504 iteration 5787 : loss : 0.014586, loss_ce: 0.005418
2021-12-10 12:59:07,165 iteration 5788 : loss : 0.019106, loss_ce: 0.008423
2021-12-10 12:59:08,714 iteration 5789 : loss : 0.015644, loss_ce: 0.006020
2021-12-10 12:59:10,253 iteration 5790 : loss : 0.016500, loss_ce: 0.004918
2021-12-10 12:59:11,750 iteration 5791 : loss : 0.014497, loss_ce: 0.005294
2021-12-10 12:59:13,319 iteration 5792 : loss : 0.018433, loss_ce: 0.006282
2021-12-10 12:59:14,987 iteration 5793 : loss : 0.016891, loss_ce: 0.006214
2021-12-10 12:59:16,549 iteration 5794 : loss : 0.018316, loss_ce: 0.008228
2021-12-10 12:59:18,093 iteration 5795 : loss : 0.014820, loss_ce: 0.005315
2021-12-10 12:59:19,593 iteration 5796 : loss : 0.012164, loss_ce: 0.003436
2021-12-10 12:59:21,163 iteration 5797 : loss : 0.019573, loss_ce: 0.007829
 85%|████████████████████████▋    | 341/400 [2:43:32<28:34, 29.06s/it]2021-12-10 12:59:22,791 iteration 5798 : loss : 0.020861, loss_ce: 0.008354
2021-12-10 12:59:24,353 iteration 5799 : loss : 0.018287, loss_ce: 0.007043
2021-12-10 12:59:25,888 iteration 5800 : loss : 0.013999, loss_ce: 0.005986
2021-12-10 12:59:27,420 iteration 5801 : loss : 0.027900, loss_ce: 0.010588
2021-12-10 12:59:28,892 iteration 5802 : loss : 0.011336, loss_ce: 0.004436
2021-12-10 12:59:30,394 iteration 5803 : loss : 0.013944, loss_ce: 0.006272
2021-12-10 12:59:31,937 iteration 5804 : loss : 0.018665, loss_ce: 0.007242
2021-12-10 12:59:33,568 iteration 5805 : loss : 0.023939, loss_ce: 0.008621
2021-12-10 12:59:35,086 iteration 5806 : loss : 0.026650, loss_ce: 0.007588
2021-12-10 12:59:36,703 iteration 5807 : loss : 0.032742, loss_ce: 0.011803
2021-12-10 12:59:38,270 iteration 5808 : loss : 0.025416, loss_ce: 0.013764
2021-12-10 12:59:39,754 iteration 5809 : loss : 0.012671, loss_ce: 0.003266
2021-12-10 12:59:41,256 iteration 5810 : loss : 0.020241, loss_ce: 0.007424
2021-12-10 12:59:42,717 iteration 5811 : loss : 0.012581, loss_ce: 0.003750
2021-12-10 12:59:44,249 iteration 5812 : loss : 0.015906, loss_ce: 0.005303
2021-12-10 12:59:45,715 iteration 5813 : loss : 0.017490, loss_ce: 0.007885
2021-12-10 12:59:47,262 iteration 5814 : loss : 0.021618, loss_ce: 0.009261
 86%|████████████████████████▊    | 342/400 [2:43:58<27:14, 28.18s/it]2021-12-10 12:59:48,789 iteration 5815 : loss : 0.012443, loss_ce: 0.004169
2021-12-10 12:59:50,296 iteration 5816 : loss : 0.012277, loss_ce: 0.005726
2021-12-10 12:59:51,798 iteration 5817 : loss : 0.012800, loss_ce: 0.004887
2021-12-10 12:59:53,237 iteration 5818 : loss : 0.017272, loss_ce: 0.007167
2021-12-10 12:59:54,829 iteration 5819 : loss : 0.025038, loss_ce: 0.012006
2021-12-10 12:59:56,461 iteration 5820 : loss : 0.022944, loss_ce: 0.010266
2021-12-10 12:59:57,932 iteration 5821 : loss : 0.018124, loss_ce: 0.005696
2021-12-10 12:59:59,428 iteration 5822 : loss : 0.016863, loss_ce: 0.007842
2021-12-10 13:00:01,062 iteration 5823 : loss : 0.018620, loss_ce: 0.007955
2021-12-10 13:00:02,598 iteration 5824 : loss : 0.015846, loss_ce: 0.004733
2021-12-10 13:00:04,176 iteration 5825 : loss : 0.018468, loss_ce: 0.007290
2021-12-10 13:00:05,758 iteration 5826 : loss : 0.019570, loss_ce: 0.004669
2021-12-10 13:00:07,301 iteration 5827 : loss : 0.018986, loss_ce: 0.005564
2021-12-10 13:00:08,961 iteration 5828 : loss : 0.026612, loss_ce: 0.010715
2021-12-10 13:00:10,511 iteration 5829 : loss : 0.016297, loss_ce: 0.006423
2021-12-10 13:00:12,016 iteration 5830 : loss : 0.023704, loss_ce: 0.009523
2021-12-10 13:00:13,539 iteration 5831 : loss : 0.021501, loss_ce: 0.007675
 86%|████████████████████████▊    | 343/400 [2:44:25<26:13, 27.60s/it]2021-12-10 13:00:15,125 iteration 5832 : loss : 0.014827, loss_ce: 0.004042
2021-12-10 13:00:16,705 iteration 5833 : loss : 0.017770, loss_ce: 0.008110
2021-12-10 13:00:18,184 iteration 5834 : loss : 0.013455, loss_ce: 0.004660
2021-12-10 13:00:19,664 iteration 5835 : loss : 0.020901, loss_ce: 0.005919
2021-12-10 13:00:21,264 iteration 5836 : loss : 0.020851, loss_ce: 0.010947
2021-12-10 13:00:22,807 iteration 5837 : loss : 0.015197, loss_ce: 0.003702
2021-12-10 13:00:24,259 iteration 5838 : loss : 0.011676, loss_ce: 0.003515
2021-12-10 13:00:25,785 iteration 5839 : loss : 0.016974, loss_ce: 0.005533
2021-12-10 13:00:27,370 iteration 5840 : loss : 0.034451, loss_ce: 0.012721
2021-12-10 13:00:28,877 iteration 5841 : loss : 0.020865, loss_ce: 0.009206
2021-12-10 13:00:30,384 iteration 5842 : loss : 0.012556, loss_ce: 0.004595
2021-12-10 13:00:31,877 iteration 5843 : loss : 0.015954, loss_ce: 0.006728
2021-12-10 13:00:33,537 iteration 5844 : loss : 0.021444, loss_ce: 0.006044
2021-12-10 13:00:35,072 iteration 5845 : loss : 0.020666, loss_ce: 0.008556
2021-12-10 13:00:36,621 iteration 5846 : loss : 0.026873, loss_ce: 0.010094
2021-12-10 13:00:38,182 iteration 5847 : loss : 0.022854, loss_ce: 0.008600
2021-12-10 13:00:39,724 iteration 5848 : loss : 0.015241, loss_ce: 0.005170
 86%|████████████████████████▉    | 344/400 [2:44:51<25:22, 27.18s/it]2021-12-10 13:00:41,330 iteration 5849 : loss : 0.020848, loss_ce: 0.007996
2021-12-10 13:00:42,807 iteration 5850 : loss : 0.013522, loss_ce: 0.005392
2021-12-10 13:00:44,344 iteration 5851 : loss : 0.016184, loss_ce: 0.006768
2021-12-10 13:00:45,857 iteration 5852 : loss : 0.014368, loss_ce: 0.005155
2021-12-10 13:00:47,313 iteration 5853 : loss : 0.014581, loss_ce: 0.004803
2021-12-10 13:00:48,819 iteration 5854 : loss : 0.030425, loss_ce: 0.009620
2021-12-10 13:00:50,424 iteration 5855 : loss : 0.020238, loss_ce: 0.008378
2021-12-10 13:00:51,970 iteration 5856 : loss : 0.020283, loss_ce: 0.008088
2021-12-10 13:00:53,527 iteration 5857 : loss : 0.018619, loss_ce: 0.006543
2021-12-10 13:00:54,990 iteration 5858 : loss : 0.014786, loss_ce: 0.005660
2021-12-10 13:00:56,580 iteration 5859 : loss : 0.014833, loss_ce: 0.005890
2021-12-10 13:00:58,173 iteration 5860 : loss : 0.019649, loss_ce: 0.005780
2021-12-10 13:00:59,686 iteration 5861 : loss : 0.020453, loss_ce: 0.005706
2021-12-10 13:01:01,257 iteration 5862 : loss : 0.016650, loss_ce: 0.007729
2021-12-10 13:01:02,696 iteration 5863 : loss : 0.011188, loss_ce: 0.003633
2021-12-10 13:01:04,241 iteration 5864 : loss : 0.022479, loss_ce: 0.007626
2021-12-10 13:01:04,242 Training Data Eval:
2021-12-10 13:01:11,973   Average segmentation loss on training set: 0.0098
2021-12-10 13:01:11,973 Validation Data Eval:
2021-12-10 13:01:14,617   Average segmentation loss on validation set: 0.0712
2021-12-10 13:01:16,099 iteration 5865 : loss : 0.015872, loss_ce: 0.005146
 86%|█████████████████████████    | 345/400 [2:45:27<27:26, 29.94s/it]2021-12-10 13:01:17,758 iteration 5866 : loss : 0.024111, loss_ce: 0.012167
2021-12-10 13:01:19,337 iteration 5867 : loss : 0.020673, loss_ce: 0.006004
2021-12-10 13:01:20,915 iteration 5868 : loss : 0.020817, loss_ce: 0.008099
2021-12-10 13:01:22,372 iteration 5869 : loss : 0.014598, loss_ce: 0.005863
2021-12-10 13:01:23,995 iteration 5870 : loss : 0.022011, loss_ce: 0.005800
2021-12-10 13:01:25,566 iteration 5871 : loss : 0.013869, loss_ce: 0.004615
2021-12-10 13:01:27,143 iteration 5872 : loss : 0.021515, loss_ce: 0.008936
2021-12-10 13:01:28,800 iteration 5873 : loss : 0.025338, loss_ce: 0.008070
2021-12-10 13:01:30,300 iteration 5874 : loss : 0.015679, loss_ce: 0.005717
2021-12-10 13:01:31,821 iteration 5875 : loss : 0.015764, loss_ce: 0.007814
2021-12-10 13:01:33,374 iteration 5876 : loss : 0.023842, loss_ce: 0.010808
2021-12-10 13:01:34,923 iteration 5877 : loss : 0.020262, loss_ce: 0.007764
2021-12-10 13:01:36,498 iteration 5878 : loss : 0.019694, loss_ce: 0.008387
2021-12-10 13:01:37,993 iteration 5879 : loss : 0.014736, loss_ce: 0.006347
2021-12-10 13:01:39,631 iteration 5880 : loss : 0.025261, loss_ce: 0.007253
2021-12-10 13:01:41,140 iteration 5881 : loss : 0.014204, loss_ce: 0.005910
2021-12-10 13:01:42,651 iteration 5882 : loss : 0.014673, loss_ce: 0.006491
 86%|█████████████████████████    | 346/400 [2:45:54<26:01, 28.92s/it]2021-12-10 13:01:44,205 iteration 5883 : loss : 0.014623, loss_ce: 0.004563
2021-12-10 13:01:45,717 iteration 5884 : loss : 0.033023, loss_ce: 0.015650
2021-12-10 13:01:47,382 iteration 5885 : loss : 0.021172, loss_ce: 0.007390
2021-12-10 13:01:48,898 iteration 5886 : loss : 0.016864, loss_ce: 0.005252
2021-12-10 13:01:50,401 iteration 5887 : loss : 0.014409, loss_ce: 0.005648
2021-12-10 13:01:52,013 iteration 5888 : loss : 0.018241, loss_ce: 0.006190
2021-12-10 13:01:53,624 iteration 5889 : loss : 0.015374, loss_ce: 0.005785
2021-12-10 13:01:55,174 iteration 5890 : loss : 0.013016, loss_ce: 0.004312
2021-12-10 13:01:56,766 iteration 5891 : loss : 0.025322, loss_ce: 0.009841
2021-12-10 13:01:58,417 iteration 5892 : loss : 0.023128, loss_ce: 0.009339
2021-12-10 13:01:59,929 iteration 5893 : loss : 0.012632, loss_ce: 0.004234
2021-12-10 13:02:01,556 iteration 5894 : loss : 0.016825, loss_ce: 0.007235
2021-12-10 13:02:03,141 iteration 5895 : loss : 0.041052, loss_ce: 0.012327
2021-12-10 13:02:04,673 iteration 5896 : loss : 0.015073, loss_ce: 0.007240
2021-12-10 13:02:06,282 iteration 5897 : loss : 0.031528, loss_ce: 0.010422
2021-12-10 13:02:07,874 iteration 5898 : loss : 0.016498, loss_ce: 0.006195
2021-12-10 13:02:09,392 iteration 5899 : loss : 0.020594, loss_ce: 0.007148
 87%|█████████████████████████▏   | 347/400 [2:46:20<24:58, 28.26s/it]2021-12-10 13:02:10,998 iteration 5900 : loss : 0.019409, loss_ce: 0.006537
2021-12-10 13:02:12,614 iteration 5901 : loss : 0.021953, loss_ce: 0.007262
2021-12-10 13:02:14,157 iteration 5902 : loss : 0.016205, loss_ce: 0.006043
2021-12-10 13:02:15,764 iteration 5903 : loss : 0.016959, loss_ce: 0.008990
2021-12-10 13:02:17,287 iteration 5904 : loss : 0.025282, loss_ce: 0.009041
2021-12-10 13:02:18,878 iteration 5905 : loss : 0.027745, loss_ce: 0.006583
2021-12-10 13:02:20,366 iteration 5906 : loss : 0.016426, loss_ce: 0.006208
2021-12-10 13:02:21,935 iteration 5907 : loss : 0.011925, loss_ce: 0.004214
2021-12-10 13:02:23,482 iteration 5908 : loss : 0.020933, loss_ce: 0.008144
2021-12-10 13:02:24,932 iteration 5909 : loss : 0.018274, loss_ce: 0.005163
2021-12-10 13:02:26,476 iteration 5910 : loss : 0.021207, loss_ce: 0.007011
2021-12-10 13:02:28,056 iteration 5911 : loss : 0.023817, loss_ce: 0.010769
2021-12-10 13:02:29,536 iteration 5912 : loss : 0.021330, loss_ce: 0.007495
2021-12-10 13:02:31,045 iteration 5913 : loss : 0.017431, loss_ce: 0.008165
2021-12-10 13:02:32,595 iteration 5914 : loss : 0.041502, loss_ce: 0.015170
2021-12-10 13:02:34,107 iteration 5915 : loss : 0.016876, loss_ce: 0.006558
2021-12-10 13:02:35,708 iteration 5916 : loss : 0.025232, loss_ce: 0.009377
 87%|█████████████████████████▏   | 348/400 [2:46:47<23:59, 27.68s/it]2021-12-10 13:02:37,280 iteration 5917 : loss : 0.016071, loss_ce: 0.007006
2021-12-10 13:02:38,753 iteration 5918 : loss : 0.016944, loss_ce: 0.006340
2021-12-10 13:02:40,348 iteration 5919 : loss : 0.023868, loss_ce: 0.010871
2021-12-10 13:02:41,958 iteration 5920 : loss : 0.028939, loss_ce: 0.018274
2021-12-10 13:02:43,671 iteration 5921 : loss : 0.033468, loss_ce: 0.009384
2021-12-10 13:02:45,203 iteration 5922 : loss : 0.015689, loss_ce: 0.004634
2021-12-10 13:02:46,778 iteration 5923 : loss : 0.020039, loss_ce: 0.006824
2021-12-10 13:02:48,448 iteration 5924 : loss : 0.022897, loss_ce: 0.005616
2021-12-10 13:02:50,021 iteration 5925 : loss : 0.017631, loss_ce: 0.006388
2021-12-10 13:02:51,583 iteration 5926 : loss : 0.026245, loss_ce: 0.011255
2021-12-10 13:02:53,171 iteration 5927 : loss : 0.016250, loss_ce: 0.006549
2021-12-10 13:02:54,664 iteration 5928 : loss : 0.014878, loss_ce: 0.004008
2021-12-10 13:02:56,152 iteration 5929 : loss : 0.012516, loss_ce: 0.005683
2021-12-10 13:02:57,642 iteration 5930 : loss : 0.017375, loss_ce: 0.008005
2021-12-10 13:02:59,200 iteration 5931 : loss : 0.026556, loss_ce: 0.006705
2021-12-10 13:03:00,804 iteration 5932 : loss : 0.015357, loss_ce: 0.004700
2021-12-10 13:03:02,346 iteration 5933 : loss : 0.016036, loss_ce: 0.005999
 87%|█████████████████████████▎   | 349/400 [2:47:13<23:15, 27.37s/it]2021-12-10 13:03:03,905 iteration 5934 : loss : 0.017214, loss_ce: 0.005758
2021-12-10 13:03:05,598 iteration 5935 : loss : 0.016986, loss_ce: 0.005768
2021-12-10 13:03:07,157 iteration 5936 : loss : 0.013234, loss_ce: 0.005289
2021-12-10 13:03:08,676 iteration 5937 : loss : 0.015711, loss_ce: 0.005397
2021-12-10 13:03:10,142 iteration 5938 : loss : 0.010057, loss_ce: 0.003733
2021-12-10 13:03:11,730 iteration 5939 : loss : 0.017937, loss_ce: 0.008204
2021-12-10 13:03:13,219 iteration 5940 : loss : 0.013269, loss_ce: 0.005029
2021-12-10 13:03:14,732 iteration 5941 : loss : 0.015349, loss_ce: 0.006126
2021-12-10 13:03:16,253 iteration 5942 : loss : 0.013043, loss_ce: 0.005658
2021-12-10 13:03:17,817 iteration 5943 : loss : 0.016202, loss_ce: 0.004390
2021-12-10 13:03:19,379 iteration 5944 : loss : 0.014861, loss_ce: 0.007007
2021-12-10 13:03:20,899 iteration 5945 : loss : 0.017940, loss_ce: 0.004125
2021-12-10 13:03:22,558 iteration 5946 : loss : 0.024881, loss_ce: 0.010520
2021-12-10 13:03:24,149 iteration 5947 : loss : 0.023951, loss_ce: 0.008348
2021-12-10 13:03:25,673 iteration 5948 : loss : 0.018232, loss_ce: 0.007386
2021-12-10 13:03:27,278 iteration 5949 : loss : 0.015100, loss_ce: 0.004908
2021-12-10 13:03:27,278 Training Data Eval:
2021-12-10 13:03:35,016   Average segmentation loss on training set: 0.0092
2021-12-10 13:03:35,016 Validation Data Eval:
2021-12-10 13:03:37,678   Average segmentation loss on validation set: 0.0674
2021-12-10 13:03:39,235 iteration 5950 : loss : 0.032980, loss_ce: 0.009088
2021-12-10 13:03:45,306 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234epoch_349.pth
 88%|█████████████████████████▍   | 350/400 [2:47:56<26:41, 32.03s/it]2021-12-10 13:03:46,824 iteration 5951 : loss : 0.015496, loss_ce: 0.004989
2021-12-10 13:03:48,369 iteration 5952 : loss : 0.019101, loss_ce: 0.008788
2021-12-10 13:03:49,911 iteration 5953 : loss : 0.020602, loss_ce: 0.008623
2021-12-10 13:03:51,420 iteration 5954 : loss : 0.016390, loss_ce: 0.006108
2021-12-10 13:03:52,960 iteration 5955 : loss : 0.013334, loss_ce: 0.004066
2021-12-10 13:03:54,535 iteration 5956 : loss : 0.022733, loss_ce: 0.011942
2021-12-10 13:03:56,090 iteration 5957 : loss : 0.015870, loss_ce: 0.006802
2021-12-10 13:03:57,587 iteration 5958 : loss : 0.013233, loss_ce: 0.004911
2021-12-10 13:03:59,115 iteration 5959 : loss : 0.019976, loss_ce: 0.008065
2021-12-10 13:04:00,608 iteration 5960 : loss : 0.025834, loss_ce: 0.008701
2021-12-10 13:04:02,093 iteration 5961 : loss : 0.019105, loss_ce: 0.004401
2021-12-10 13:04:03,614 iteration 5962 : loss : 0.022431, loss_ce: 0.005750
2021-12-10 13:04:05,185 iteration 5963 : loss : 0.021391, loss_ce: 0.008542
2021-12-10 13:04:06,701 iteration 5964 : loss : 0.011781, loss_ce: 0.005133
2021-12-10 13:04:08,181 iteration 5965 : loss : 0.012022, loss_ce: 0.005352
2021-12-10 13:04:09,773 iteration 5966 : loss : 0.022423, loss_ce: 0.006142
2021-12-10 13:04:11,341 iteration 5967 : loss : 0.014932, loss_ce: 0.006043
 88%|█████████████████████████▍   | 351/400 [2:48:22<24:42, 30.25s/it]2021-12-10 13:04:13,016 iteration 5968 : loss : 0.021323, loss_ce: 0.008018
2021-12-10 13:04:14,528 iteration 5969 : loss : 0.016373, loss_ce: 0.006931
2021-12-10 13:04:16,111 iteration 5970 : loss : 0.022520, loss_ce: 0.011959
2021-12-10 13:04:17,586 iteration 5971 : loss : 0.012442, loss_ce: 0.004058
2021-12-10 13:04:19,028 iteration 5972 : loss : 0.013888, loss_ce: 0.004211
2021-12-10 13:04:20,580 iteration 5973 : loss : 0.017083, loss_ce: 0.008589
2021-12-10 13:04:22,229 iteration 5974 : loss : 0.032932, loss_ce: 0.013600
2021-12-10 13:04:23,720 iteration 5975 : loss : 0.033286, loss_ce: 0.014625
2021-12-10 13:04:25,234 iteration 5976 : loss : 0.015546, loss_ce: 0.004583
2021-12-10 13:04:26,735 iteration 5977 : loss : 0.022479, loss_ce: 0.006239
2021-12-10 13:04:28,217 iteration 5978 : loss : 0.026298, loss_ce: 0.012717
2021-12-10 13:04:29,759 iteration 5979 : loss : 0.012036, loss_ce: 0.005002
2021-12-10 13:04:31,378 iteration 5980 : loss : 0.012431, loss_ce: 0.004456
2021-12-10 13:04:32,881 iteration 5981 : loss : 0.017757, loss_ce: 0.007687
2021-12-10 13:04:34,423 iteration 5982 : loss : 0.020355, loss_ce: 0.008128
2021-12-10 13:04:36,033 iteration 5983 : loss : 0.026320, loss_ce: 0.007277
2021-12-10 13:04:37,545 iteration 5984 : loss : 0.020380, loss_ce: 0.006854
 88%|█████████████████████████▌   | 352/400 [2:48:49<23:13, 29.04s/it]2021-12-10 13:04:39,153 iteration 5985 : loss : 0.017091, loss_ce: 0.005424
2021-12-10 13:04:40,602 iteration 5986 : loss : 0.013492, loss_ce: 0.004251
2021-12-10 13:04:42,198 iteration 5987 : loss : 0.023336, loss_ce: 0.011344
2021-12-10 13:04:43,798 iteration 5988 : loss : 0.020576, loss_ce: 0.007649
2021-12-10 13:04:45,361 iteration 5989 : loss : 0.012802, loss_ce: 0.004901
2021-12-10 13:04:46,882 iteration 5990 : loss : 0.013777, loss_ce: 0.004693
2021-12-10 13:04:48,451 iteration 5991 : loss : 0.020872, loss_ce: 0.007024
2021-12-10 13:04:50,007 iteration 5992 : loss : 0.018568, loss_ce: 0.006695
2021-12-10 13:04:51,547 iteration 5993 : loss : 0.013278, loss_ce: 0.005441
2021-12-10 13:04:53,139 iteration 5994 : loss : 0.026103, loss_ce: 0.010991
2021-12-10 13:04:54,669 iteration 5995 : loss : 0.014107, loss_ce: 0.005342
2021-12-10 13:04:56,163 iteration 5996 : loss : 0.012757, loss_ce: 0.004094
2021-12-10 13:04:57,732 iteration 5997 : loss : 0.019268, loss_ce: 0.007184
2021-12-10 13:04:59,345 iteration 5998 : loss : 0.015832, loss_ce: 0.005537
2021-12-10 13:05:00,999 iteration 5999 : loss : 0.027900, loss_ce: 0.008625
2021-12-10 13:05:02,601 iteration 6000 : loss : 0.022960, loss_ce: 0.010604
2021-12-10 13:05:04,066 iteration 6001 : loss : 0.015569, loss_ce: 0.007004
 88%|█████████████████████████▌   | 353/400 [2:49:15<22:09, 28.28s/it]2021-12-10 13:05:05,683 iteration 6002 : loss : 0.014421, loss_ce: 0.004926
2021-12-10 13:05:07,194 iteration 6003 : loss : 0.018259, loss_ce: 0.006693
2021-12-10 13:05:08,799 iteration 6004 : loss : 0.019516, loss_ce: 0.008913
2021-12-10 13:05:10,385 iteration 6005 : loss : 0.018083, loss_ce: 0.006243
2021-12-10 13:05:12,049 iteration 6006 : loss : 0.017339, loss_ce: 0.007384
2021-12-10 13:05:13,623 iteration 6007 : loss : 0.013000, loss_ce: 0.005314
2021-12-10 13:05:15,187 iteration 6008 : loss : 0.020366, loss_ce: 0.008012
2021-12-10 13:05:16,649 iteration 6009 : loss : 0.012840, loss_ce: 0.006012
2021-12-10 13:05:18,137 iteration 6010 : loss : 0.014071, loss_ce: 0.005845
2021-12-10 13:05:19,720 iteration 6011 : loss : 0.027298, loss_ce: 0.008736
2021-12-10 13:05:21,334 iteration 6012 : loss : 0.020954, loss_ce: 0.005436
2021-12-10 13:05:22,923 iteration 6013 : loss : 0.019170, loss_ce: 0.006389
2021-12-10 13:05:24,502 iteration 6014 : loss : 0.017698, loss_ce: 0.005094
2021-12-10 13:05:26,017 iteration 6015 : loss : 0.018052, loss_ce: 0.006755
2021-12-10 13:05:27,565 iteration 6016 : loss : 0.014289, loss_ce: 0.005124
2021-12-10 13:05:29,106 iteration 6017 : loss : 0.023394, loss_ce: 0.010129
2021-12-10 13:05:30,673 iteration 6018 : loss : 0.037973, loss_ce: 0.011029
 88%|█████████████████████████▋   | 354/400 [2:49:42<21:17, 27.78s/it]2021-12-10 13:05:32,292 iteration 6019 : loss : 0.018005, loss_ce: 0.008628
2021-12-10 13:05:33,819 iteration 6020 : loss : 0.015527, loss_ce: 0.006968
2021-12-10 13:05:35,391 iteration 6021 : loss : 0.024869, loss_ce: 0.007359
2021-12-10 13:05:36,882 iteration 6022 : loss : 0.016243, loss_ce: 0.006738
2021-12-10 13:05:38,516 iteration 6023 : loss : 0.016158, loss_ce: 0.006547
2021-12-10 13:05:40,040 iteration 6024 : loss : 0.017133, loss_ce: 0.006072
2021-12-10 13:05:41,551 iteration 6025 : loss : 0.017702, loss_ce: 0.007387
2021-12-10 13:05:43,121 iteration 6026 : loss : 0.020130, loss_ce: 0.007613
2021-12-10 13:05:44,685 iteration 6027 : loss : 0.020974, loss_ce: 0.007417
2021-12-10 13:05:46,271 iteration 6028 : loss : 0.018587, loss_ce: 0.006966
2021-12-10 13:05:47,800 iteration 6029 : loss : 0.022382, loss_ce: 0.006252
2021-12-10 13:05:49,278 iteration 6030 : loss : 0.015200, loss_ce: 0.006554
2021-12-10 13:05:50,845 iteration 6031 : loss : 0.016542, loss_ce: 0.008322
2021-12-10 13:05:52,342 iteration 6032 : loss : 0.015208, loss_ce: 0.004621
2021-12-10 13:05:53,943 iteration 6033 : loss : 0.015478, loss_ce: 0.005315
2021-12-10 13:05:55,493 iteration 6034 : loss : 0.014835, loss_ce: 0.005849
2021-12-10 13:05:55,493 Training Data Eval:
2021-12-10 13:06:03,237   Average segmentation loss on training set: 0.0095
2021-12-10 13:06:03,237 Validation Data Eval:
2021-12-10 13:06:05,899   Average segmentation loss on validation set: 0.0639
2021-12-10 13:06:07,321 iteration 6035 : loss : 0.011879, loss_ce: 0.004368
 89%|█████████████████████████▋   | 355/400 [2:50:18<22:49, 30.44s/it]2021-12-10 13:06:09,013 iteration 6036 : loss : 0.026178, loss_ce: 0.008296
2021-12-10 13:06:10,612 iteration 6037 : loss : 0.023345, loss_ce: 0.007449
2021-12-10 13:06:12,142 iteration 6038 : loss : 0.015887, loss_ce: 0.005523
2021-12-10 13:06:13,657 iteration 6039 : loss : 0.016851, loss_ce: 0.005077
2021-12-10 13:06:15,206 iteration 6040 : loss : 0.018108, loss_ce: 0.006819
2021-12-10 13:06:16,717 iteration 6041 : loss : 0.026370, loss_ce: 0.010375
2021-12-10 13:06:18,281 iteration 6042 : loss : 0.014410, loss_ce: 0.007053
2021-12-10 13:06:19,772 iteration 6043 : loss : 0.014163, loss_ce: 0.006473
2021-12-10 13:06:21,249 iteration 6044 : loss : 0.012882, loss_ce: 0.005215
2021-12-10 13:06:22,871 iteration 6045 : loss : 0.023451, loss_ce: 0.009637
2021-12-10 13:06:24,351 iteration 6046 : loss : 0.014711, loss_ce: 0.006494
2021-12-10 13:06:25,828 iteration 6047 : loss : 0.011519, loss_ce: 0.004854
2021-12-10 13:06:27,447 iteration 6048 : loss : 0.017855, loss_ce: 0.005657
2021-12-10 13:06:28,914 iteration 6049 : loss : 0.015392, loss_ce: 0.005546
2021-12-10 13:06:30,387 iteration 6050 : loss : 0.016525, loss_ce: 0.004050
2021-12-10 13:06:31,860 iteration 6051 : loss : 0.012124, loss_ce: 0.005196
2021-12-10 13:06:33,431 iteration 6052 : loss : 0.013546, loss_ce: 0.005086
 89%|█████████████████████████▊   | 356/400 [2:50:44<21:22, 29.14s/it]2021-12-10 13:06:35,002 iteration 6053 : loss : 0.016188, loss_ce: 0.005360
2021-12-10 13:06:36,503 iteration 6054 : loss : 0.014614, loss_ce: 0.004750
2021-12-10 13:06:38,066 iteration 6055 : loss : 0.017025, loss_ce: 0.007666
2021-12-10 13:06:39,577 iteration 6056 : loss : 0.013612, loss_ce: 0.004521
2021-12-10 13:06:41,029 iteration 6057 : loss : 0.018378, loss_ce: 0.006872
2021-12-10 13:06:42,506 iteration 6058 : loss : 0.011956, loss_ce: 0.006186
2021-12-10 13:06:44,112 iteration 6059 : loss : 0.024151, loss_ce: 0.007869
2021-12-10 13:06:45,666 iteration 6060 : loss : 0.018094, loss_ce: 0.005222
2021-12-10 13:06:47,157 iteration 6061 : loss : 0.017991, loss_ce: 0.008124
2021-12-10 13:06:48,833 iteration 6062 : loss : 0.027640, loss_ce: 0.010091
2021-12-10 13:06:50,315 iteration 6063 : loss : 0.016132, loss_ce: 0.007121
2021-12-10 13:06:51,817 iteration 6064 : loss : 0.015562, loss_ce: 0.006055
2021-12-10 13:06:53,382 iteration 6065 : loss : 0.022438, loss_ce: 0.008398
2021-12-10 13:06:54,852 iteration 6066 : loss : 0.018624, loss_ce: 0.007435
2021-12-10 13:06:56,419 iteration 6067 : loss : 0.026853, loss_ce: 0.008531
2021-12-10 13:06:57,963 iteration 6068 : loss : 0.019745, loss_ce: 0.004020
2021-12-10 13:06:59,592 iteration 6069 : loss : 0.023244, loss_ce: 0.011752
 89%|█████████████████████████▉   | 357/400 [2:51:11<20:14, 28.25s/it]2021-12-10 13:07:01,209 iteration 6070 : loss : 0.016267, loss_ce: 0.007702
2021-12-10 13:07:02,758 iteration 6071 : loss : 0.014196, loss_ce: 0.005631
2021-12-10 13:07:04,285 iteration 6072 : loss : 0.017849, loss_ce: 0.006355
2021-12-10 13:07:05,829 iteration 6073 : loss : 0.018017, loss_ce: 0.005193
2021-12-10 13:07:07,285 iteration 6074 : loss : 0.014869, loss_ce: 0.006964
2021-12-10 13:07:08,863 iteration 6075 : loss : 0.021977, loss_ce: 0.010066
2021-12-10 13:07:10,410 iteration 6076 : loss : 0.013044, loss_ce: 0.005286
2021-12-10 13:07:11,833 iteration 6077 : loss : 0.011708, loss_ce: 0.004384
2021-12-10 13:07:13,351 iteration 6078 : loss : 0.018171, loss_ce: 0.009115
2021-12-10 13:07:14,961 iteration 6079 : loss : 0.022692, loss_ce: 0.011173
2021-12-10 13:07:16,427 iteration 6080 : loss : 0.014043, loss_ce: 0.005160
2021-12-10 13:07:18,052 iteration 6081 : loss : 0.025739, loss_ce: 0.010220
2021-12-10 13:07:19,586 iteration 6082 : loss : 0.020586, loss_ce: 0.004409
2021-12-10 13:07:21,168 iteration 6083 : loss : 0.021045, loss_ce: 0.005523
2021-12-10 13:07:22,663 iteration 6084 : loss : 0.015011, loss_ce: 0.004117
2021-12-10 13:07:24,148 iteration 6085 : loss : 0.015473, loss_ce: 0.005828
2021-12-10 13:07:25,852 iteration 6086 : loss : 0.027113, loss_ce: 0.007921
 90%|█████████████████████████▉   | 358/400 [2:51:37<19:21, 27.65s/it]2021-12-10 13:07:27,395 iteration 6087 : loss : 0.014119, loss_ce: 0.005591
2021-12-10 13:07:28,951 iteration 6088 : loss : 0.014549, loss_ce: 0.006363
2021-12-10 13:07:30,478 iteration 6089 : loss : 0.026750, loss_ce: 0.012963
2021-12-10 13:07:32,000 iteration 6090 : loss : 0.012842, loss_ce: 0.003771
2021-12-10 13:07:33,534 iteration 6091 : loss : 0.014981, loss_ce: 0.007250
2021-12-10 13:07:35,077 iteration 6092 : loss : 0.014505, loss_ce: 0.005935
2021-12-10 13:07:36,534 iteration 6093 : loss : 0.013715, loss_ce: 0.004675
2021-12-10 13:07:38,014 iteration 6094 : loss : 0.016556, loss_ce: 0.005635
2021-12-10 13:07:39,579 iteration 6095 : loss : 0.021100, loss_ce: 0.009680
2021-12-10 13:07:41,148 iteration 6096 : loss : 0.022147, loss_ce: 0.007337
2021-12-10 13:07:42,604 iteration 6097 : loss : 0.018059, loss_ce: 0.007591
2021-12-10 13:07:44,153 iteration 6098 : loss : 0.019750, loss_ce: 0.007885
2021-12-10 13:07:45,735 iteration 6099 : loss : 0.019787, loss_ce: 0.004896
2021-12-10 13:07:47,358 iteration 6100 : loss : 0.026979, loss_ce: 0.008806
2021-12-10 13:07:48,948 iteration 6101 : loss : 0.022323, loss_ce: 0.009889
2021-12-10 13:07:50,452 iteration 6102 : loss : 0.014034, loss_ce: 0.004168
2021-12-10 13:07:51,880 iteration 6103 : loss : 0.011287, loss_ce: 0.004518
 90%|██████████████████████████   | 359/400 [2:52:03<18:33, 27.16s/it]2021-12-10 13:07:53,524 iteration 6104 : loss : 0.021695, loss_ce: 0.006425
2021-12-10 13:07:55,005 iteration 6105 : loss : 0.018713, loss_ce: 0.006276
2021-12-10 13:07:56,456 iteration 6106 : loss : 0.012016, loss_ce: 0.004195
2021-12-10 13:07:57,936 iteration 6107 : loss : 0.014280, loss_ce: 0.004922
2021-12-10 13:07:59,522 iteration 6108 : loss : 0.017192, loss_ce: 0.005774
2021-12-10 13:08:01,025 iteration 6109 : loss : 0.012779, loss_ce: 0.004644
2021-12-10 13:08:02,580 iteration 6110 : loss : 0.012725, loss_ce: 0.005628
2021-12-10 13:08:04,179 iteration 6111 : loss : 0.020175, loss_ce: 0.007916
2021-12-10 13:08:05,761 iteration 6112 : loss : 0.019293, loss_ce: 0.006331
2021-12-10 13:08:07,372 iteration 6113 : loss : 0.016355, loss_ce: 0.005589
2021-12-10 13:08:08,896 iteration 6114 : loss : 0.019077, loss_ce: 0.007768
2021-12-10 13:08:10,518 iteration 6115 : loss : 0.025342, loss_ce: 0.008862
2021-12-10 13:08:12,096 iteration 6116 : loss : 0.013504, loss_ce: 0.005836
2021-12-10 13:08:13,603 iteration 6117 : loss : 0.018981, loss_ce: 0.007802
2021-12-10 13:08:15,185 iteration 6118 : loss : 0.018279, loss_ce: 0.007432
2021-12-10 13:08:16,713 iteration 6119 : loss : 0.037374, loss_ce: 0.017445
2021-12-10 13:08:16,713 Training Data Eval:
2021-12-10 13:08:24,449   Average segmentation loss on training set: 0.0090
2021-12-10 13:08:24,449 Validation Data Eval:
2021-12-10 13:08:27,101   Average segmentation loss on validation set: 0.0684
2021-12-10 13:08:28,626 iteration 6120 : loss : 0.012193, loss_ce: 0.005207
 90%|██████████████████████████   | 360/400 [2:52:40<20:01, 30.04s/it]2021-12-10 13:08:30,244 iteration 6121 : loss : 0.018124, loss_ce: 0.008361
2021-12-10 13:08:31,831 iteration 6122 : loss : 0.019600, loss_ce: 0.006906
2021-12-10 13:08:33,453 iteration 6123 : loss : 0.016679, loss_ce: 0.006500
2021-12-10 13:08:35,005 iteration 6124 : loss : 0.018322, loss_ce: 0.005539
2021-12-10 13:08:36,651 iteration 6125 : loss : 0.034602, loss_ce: 0.012429
2021-12-10 13:08:38,183 iteration 6126 : loss : 0.033324, loss_ce: 0.009031
2021-12-10 13:08:39,695 iteration 6127 : loss : 0.020204, loss_ce: 0.007993
2021-12-10 13:08:41,317 iteration 6128 : loss : 0.023857, loss_ce: 0.007719
2021-12-10 13:08:42,874 iteration 6129 : loss : 0.017516, loss_ce: 0.007657
2021-12-10 13:08:44,507 iteration 6130 : loss : 0.016824, loss_ce: 0.006701
2021-12-10 13:08:46,075 iteration 6131 : loss : 0.027313, loss_ce: 0.012927
2021-12-10 13:08:47,630 iteration 6132 : loss : 0.027813, loss_ce: 0.005547
2021-12-10 13:08:49,135 iteration 6133 : loss : 0.013735, loss_ce: 0.006531
2021-12-10 13:08:50,603 iteration 6134 : loss : 0.010318, loss_ce: 0.004517
2021-12-10 13:08:52,072 iteration 6135 : loss : 0.013253, loss_ce: 0.005639
2021-12-10 13:08:53,631 iteration 6136 : loss : 0.014054, loss_ce: 0.004697
2021-12-10 13:08:55,149 iteration 6137 : loss : 0.018577, loss_ce: 0.006837
 90%|██████████████████████████▏  | 361/400 [2:53:06<18:50, 28.98s/it]2021-12-10 13:08:56,696 iteration 6138 : loss : 0.013299, loss_ce: 0.004812
2021-12-10 13:08:58,275 iteration 6139 : loss : 0.019418, loss_ce: 0.008414
2021-12-10 13:08:59,815 iteration 6140 : loss : 0.011561, loss_ce: 0.004215
2021-12-10 13:09:01,388 iteration 6141 : loss : 0.017398, loss_ce: 0.006448
2021-12-10 13:09:03,094 iteration 6142 : loss : 0.034671, loss_ce: 0.013113
2021-12-10 13:09:04,578 iteration 6143 : loss : 0.013574, loss_ce: 0.006247
2021-12-10 13:09:06,142 iteration 6144 : loss : 0.014243, loss_ce: 0.006349
2021-12-10 13:09:07,702 iteration 6145 : loss : 0.021399, loss_ce: 0.008347
2021-12-10 13:09:09,240 iteration 6146 : loss : 0.014706, loss_ce: 0.006275
2021-12-10 13:09:10,780 iteration 6147 : loss : 0.014368, loss_ce: 0.003791
2021-12-10 13:09:12,271 iteration 6148 : loss : 0.014011, loss_ce: 0.005362
2021-12-10 13:09:13,758 iteration 6149 : loss : 0.020269, loss_ce: 0.007653
2021-12-10 13:09:15,274 iteration 6150 : loss : 0.017733, loss_ce: 0.005730
2021-12-10 13:09:16,804 iteration 6151 : loss : 0.016751, loss_ce: 0.003918
2021-12-10 13:09:18,295 iteration 6152 : loss : 0.024212, loss_ce: 0.009879
2021-12-10 13:09:19,904 iteration 6153 : loss : 0.026961, loss_ce: 0.014127
2021-12-10 13:09:21,548 iteration 6154 : loss : 0.042965, loss_ce: 0.020469
 90%|██████████████████████████▏  | 362/400 [2:53:33<17:51, 28.21s/it]2021-12-10 13:09:23,121 iteration 6155 : loss : 0.016901, loss_ce: 0.007015
2021-12-10 13:09:24,651 iteration 6156 : loss : 0.012608, loss_ce: 0.005612
2021-12-10 13:09:26,245 iteration 6157 : loss : 0.018242, loss_ce: 0.005825
2021-12-10 13:09:27,758 iteration 6158 : loss : 0.015362, loss_ce: 0.005430
2021-12-10 13:09:29,208 iteration 6159 : loss : 0.012329, loss_ce: 0.004666
2021-12-10 13:09:30,954 iteration 6160 : loss : 0.030735, loss_ce: 0.015361
2021-12-10 13:09:32,422 iteration 6161 : loss : 0.015645, loss_ce: 0.005104
2021-12-10 13:09:33,980 iteration 6162 : loss : 0.012134, loss_ce: 0.004574
2021-12-10 13:09:35,511 iteration 6163 : loss : 0.033114, loss_ce: 0.010813
2021-12-10 13:09:37,007 iteration 6164 : loss : 0.016540, loss_ce: 0.005429
2021-12-10 13:09:38,564 iteration 6165 : loss : 0.015490, loss_ce: 0.005988
2021-12-10 13:09:40,146 iteration 6166 : loss : 0.017357, loss_ce: 0.007757
2021-12-10 13:09:41,609 iteration 6167 : loss : 0.012114, loss_ce: 0.003987
2021-12-10 13:09:43,262 iteration 6168 : loss : 0.032582, loss_ce: 0.009638
2021-12-10 13:09:44,789 iteration 6169 : loss : 0.014561, loss_ce: 0.006003
2021-12-10 13:09:46,367 iteration 6170 : loss : 0.015036, loss_ce: 0.006343
2021-12-10 13:09:47,906 iteration 6171 : loss : 0.017834, loss_ce: 0.005230
 91%|██████████████████████████▎  | 363/400 [2:53:59<17:03, 27.65s/it]2021-12-10 13:09:49,501 iteration 6172 : loss : 0.016943, loss_ce: 0.005497
2021-12-10 13:09:50,943 iteration 6173 : loss : 0.014232, loss_ce: 0.005123
2021-12-10 13:09:52,454 iteration 6174 : loss : 0.018615, loss_ce: 0.008601
2021-12-10 13:09:53,922 iteration 6175 : loss : 0.010851, loss_ce: 0.002885
2021-12-10 13:09:55,480 iteration 6176 : loss : 0.023209, loss_ce: 0.010706
2021-12-10 13:09:57,129 iteration 6177 : loss : 0.022160, loss_ce: 0.010863
2021-12-10 13:09:58,735 iteration 6178 : loss : 0.024985, loss_ce: 0.008771
2021-12-10 13:10:00,309 iteration 6179 : loss : 0.017988, loss_ce: 0.005720
2021-12-10 13:10:01,886 iteration 6180 : loss : 0.027877, loss_ce: 0.004641
2021-12-10 13:10:03,408 iteration 6181 : loss : 0.021827, loss_ce: 0.008424
2021-12-10 13:10:04,972 iteration 6182 : loss : 0.014354, loss_ce: 0.005893
2021-12-10 13:10:06,473 iteration 6183 : loss : 0.019043, loss_ce: 0.006379
2021-12-10 13:10:07,971 iteration 6184 : loss : 0.014466, loss_ce: 0.005878
2021-12-10 13:10:09,589 iteration 6185 : loss : 0.018437, loss_ce: 0.006391
2021-12-10 13:10:11,060 iteration 6186 : loss : 0.012249, loss_ce: 0.004614
2021-12-10 13:10:12,550 iteration 6187 : loss : 0.015908, loss_ce: 0.004733
2021-12-10 13:10:14,038 iteration 6188 : loss : 0.017468, loss_ce: 0.005926
 91%|██████████████████████████▍  | 364/400 [2:54:25<16:19, 27.20s/it]2021-12-10 13:10:15,726 iteration 6189 : loss : 0.023973, loss_ce: 0.008805
2021-12-10 13:10:17,277 iteration 6190 : loss : 0.015143, loss_ce: 0.006002
2021-12-10 13:10:18,891 iteration 6191 : loss : 0.021679, loss_ce: 0.005900
2021-12-10 13:10:20,469 iteration 6192 : loss : 0.019098, loss_ce: 0.006630
2021-12-10 13:10:21,968 iteration 6193 : loss : 0.012647, loss_ce: 0.004022
2021-12-10 13:10:23,550 iteration 6194 : loss : 0.016448, loss_ce: 0.006497
2021-12-10 13:10:25,173 iteration 6195 : loss : 0.028809, loss_ce: 0.011474
2021-12-10 13:10:26,671 iteration 6196 : loss : 0.024171, loss_ce: 0.005985
2021-12-10 13:10:28,333 iteration 6197 : loss : 0.023976, loss_ce: 0.007665
2021-12-10 13:10:29,978 iteration 6198 : loss : 0.021207, loss_ce: 0.008317
2021-12-10 13:10:31,492 iteration 6199 : loss : 0.011875, loss_ce: 0.004521
2021-12-10 13:10:33,069 iteration 6200 : loss : 0.021519, loss_ce: 0.008137
2021-12-10 13:10:34,617 iteration 6201 : loss : 0.019168, loss_ce: 0.007530
2021-12-10 13:10:36,148 iteration 6202 : loss : 0.015099, loss_ce: 0.004519
2021-12-10 13:10:37,671 iteration 6203 : loss : 0.023350, loss_ce: 0.007043
2021-12-10 13:10:39,263 iteration 6204 : loss : 0.014505, loss_ce: 0.006263
2021-12-10 13:10:39,264 Training Data Eval:
2021-12-10 13:10:47,012   Average segmentation loss on training set: 0.0091
2021-12-10 13:10:47,013 Validation Data Eval:
2021-12-10 13:10:49,661   Average segmentation loss on validation set: 0.0683
2021-12-10 13:10:51,316 iteration 6205 : loss : 0.023162, loss_ce: 0.010860
 91%|██████████████████████████▍  | 365/400 [2:55:02<17:37, 30.22s/it]2021-12-10 13:10:52,945 iteration 6206 : loss : 0.014367, loss_ce: 0.006758
2021-12-10 13:10:54,498 iteration 6207 : loss : 0.017534, loss_ce: 0.008990
2021-12-10 13:10:56,075 iteration 6208 : loss : 0.017358, loss_ce: 0.006203
2021-12-10 13:10:57,645 iteration 6209 : loss : 0.018575, loss_ce: 0.006364
2021-12-10 13:10:59,172 iteration 6210 : loss : 0.024471, loss_ce: 0.009362
2021-12-10 13:11:00,655 iteration 6211 : loss : 0.014211, loss_ce: 0.004915
2021-12-10 13:11:02,172 iteration 6212 : loss : 0.016275, loss_ce: 0.006047
2021-12-10 13:11:03,719 iteration 6213 : loss : 0.013040, loss_ce: 0.004864
2021-12-10 13:11:05,237 iteration 6214 : loss : 0.011943, loss_ce: 0.004411
2021-12-10 13:11:06,840 iteration 6215 : loss : 0.020998, loss_ce: 0.006978
2021-12-10 13:11:08,374 iteration 6216 : loss : 0.013038, loss_ce: 0.005500
2021-12-10 13:11:09,840 iteration 6217 : loss : 0.018966, loss_ce: 0.006996
2021-12-10 13:11:11,401 iteration 6218 : loss : 0.021819, loss_ce: 0.008544
2021-12-10 13:11:12,931 iteration 6219 : loss : 0.014198, loss_ce: 0.004859
2021-12-10 13:11:14,441 iteration 6220 : loss : 0.012839, loss_ce: 0.002826
2021-12-10 13:11:16,001 iteration 6221 : loss : 0.015394, loss_ce: 0.004311
2021-12-10 13:11:17,493 iteration 6222 : loss : 0.012454, loss_ce: 0.005933
 92%|██████████████████████████▌  | 366/400 [2:55:28<16:26, 29.01s/it]2021-12-10 13:11:19,122 iteration 6223 : loss : 0.014502, loss_ce: 0.005951
2021-12-10 13:11:20,660 iteration 6224 : loss : 0.019343, loss_ce: 0.008160
2021-12-10 13:11:22,214 iteration 6225 : loss : 0.016671, loss_ce: 0.004875
2021-12-10 13:11:23,716 iteration 6226 : loss : 0.012640, loss_ce: 0.004158
2021-12-10 13:11:25,198 iteration 6227 : loss : 0.014675, loss_ce: 0.006153
2021-12-10 13:11:26,753 iteration 6228 : loss : 0.019720, loss_ce: 0.006986
2021-12-10 13:11:28,310 iteration 6229 : loss : 0.014242, loss_ce: 0.007330
2021-12-10 13:11:29,894 iteration 6230 : loss : 0.024059, loss_ce: 0.007130
2021-12-10 13:11:31,491 iteration 6231 : loss : 0.024644, loss_ce: 0.010299
2021-12-10 13:11:33,057 iteration 6232 : loss : 0.016764, loss_ce: 0.007037
2021-12-10 13:11:34,602 iteration 6233 : loss : 0.015985, loss_ce: 0.006909
2021-12-10 13:11:36,141 iteration 6234 : loss : 0.014399, loss_ce: 0.002977
2021-12-10 13:11:37,636 iteration 6235 : loss : 0.018577, loss_ce: 0.009905
2021-12-10 13:11:39,180 iteration 6236 : loss : 0.014770, loss_ce: 0.006885
2021-12-10 13:11:40,744 iteration 6237 : loss : 0.016566, loss_ce: 0.007042
2021-12-10 13:11:42,369 iteration 6238 : loss : 0.023624, loss_ce: 0.007037
2021-12-10 13:11:43,927 iteration 6239 : loss : 0.024972, loss_ce: 0.007502
 92%|██████████████████████████▌  | 367/400 [2:55:55<15:31, 28.24s/it]2021-12-10 13:11:45,509 iteration 6240 : loss : 0.012193, loss_ce: 0.003953
2021-12-10 13:11:47,004 iteration 6241 : loss : 0.012867, loss_ce: 0.006230
2021-12-10 13:11:48,635 iteration 6242 : loss : 0.023262, loss_ce: 0.007339
2021-12-10 13:11:50,166 iteration 6243 : loss : 0.014410, loss_ce: 0.005827
2021-12-10 13:11:51,800 iteration 6244 : loss : 0.015432, loss_ce: 0.006185
2021-12-10 13:11:53,334 iteration 6245 : loss : 0.015043, loss_ce: 0.005239
2021-12-10 13:11:54,859 iteration 6246 : loss : 0.015955, loss_ce: 0.006487
2021-12-10 13:11:56,445 iteration 6247 : loss : 0.017223, loss_ce: 0.004384
2021-12-10 13:11:57,964 iteration 6248 : loss : 0.013825, loss_ce: 0.005016
2021-12-10 13:11:59,494 iteration 6249 : loss : 0.015168, loss_ce: 0.004617
2021-12-10 13:12:01,077 iteration 6250 : loss : 0.015506, loss_ce: 0.005703
2021-12-10 13:12:02,717 iteration 6251 : loss : 0.018271, loss_ce: 0.008005
2021-12-10 13:12:04,212 iteration 6252 : loss : 0.013784, loss_ce: 0.006264
2021-12-10 13:12:05,807 iteration 6253 : loss : 0.015257, loss_ce: 0.005184
2021-12-10 13:12:07,321 iteration 6254 : loss : 0.012773, loss_ce: 0.005672
2021-12-10 13:12:08,879 iteration 6255 : loss : 0.016681, loss_ce: 0.007756
2021-12-10 13:12:10,507 iteration 6256 : loss : 0.016437, loss_ce: 0.006681
 92%|██████████████████████████▋  | 368/400 [2:56:21<14:47, 27.74s/it]2021-12-10 13:12:12,151 iteration 6257 : loss : 0.015867, loss_ce: 0.004936
2021-12-10 13:12:13,749 iteration 6258 : loss : 0.019265, loss_ce: 0.007384
2021-12-10 13:12:15,368 iteration 6259 : loss : 0.024260, loss_ce: 0.013126
2021-12-10 13:12:16,903 iteration 6260 : loss : 0.013260, loss_ce: 0.005222
2021-12-10 13:12:18,430 iteration 6261 : loss : 0.017065, loss_ce: 0.006010
2021-12-10 13:12:19,998 iteration 6262 : loss : 0.020528, loss_ce: 0.005967
2021-12-10 13:12:21,596 iteration 6263 : loss : 0.021755, loss_ce: 0.005022
2021-12-10 13:12:23,162 iteration 6264 : loss : 0.024686, loss_ce: 0.010640
2021-12-10 13:12:24,726 iteration 6265 : loss : 0.017325, loss_ce: 0.006361
2021-12-10 13:12:26,246 iteration 6266 : loss : 0.018730, loss_ce: 0.009527
2021-12-10 13:12:27,749 iteration 6267 : loss : 0.018038, loss_ce: 0.007709
2021-12-10 13:12:29,290 iteration 6268 : loss : 0.016042, loss_ce: 0.006390
2021-12-10 13:12:30,693 iteration 6269 : loss : 0.011291, loss_ce: 0.003899
2021-12-10 13:12:32,217 iteration 6270 : loss : 0.013217, loss_ce: 0.005970
2021-12-10 13:12:33,761 iteration 6271 : loss : 0.013250, loss_ce: 0.003495
2021-12-10 13:12:35,346 iteration 6272 : loss : 0.023492, loss_ce: 0.008600
2021-12-10 13:12:36,925 iteration 6273 : loss : 0.014252, loss_ce: 0.005641
 92%|██████████████████████████▊  | 369/400 [2:56:48<14:07, 27.34s/it]2021-12-10 13:12:38,667 iteration 6274 : loss : 0.035694, loss_ce: 0.012603
2021-12-10 13:12:40,245 iteration 6275 : loss : 0.015716, loss_ce: 0.008134
2021-12-10 13:12:41,803 iteration 6276 : loss : 0.013355, loss_ce: 0.005082
2021-12-10 13:12:43,307 iteration 6277 : loss : 0.012812, loss_ce: 0.003561
2021-12-10 13:12:44,865 iteration 6278 : loss : 0.018371, loss_ce: 0.005941
2021-12-10 13:12:46,407 iteration 6279 : loss : 0.028229, loss_ce: 0.010959
2021-12-10 13:12:47,919 iteration 6280 : loss : 0.017055, loss_ce: 0.006162
2021-12-10 13:12:49,592 iteration 6281 : loss : 0.026223, loss_ce: 0.007494
2021-12-10 13:12:51,122 iteration 6282 : loss : 0.011839, loss_ce: 0.004586
2021-12-10 13:12:52,634 iteration 6283 : loss : 0.011494, loss_ce: 0.004930
2021-12-10 13:12:54,183 iteration 6284 : loss : 0.023103, loss_ce: 0.009806
2021-12-10 13:12:55,773 iteration 6285 : loss : 0.016592, loss_ce: 0.005525
2021-12-10 13:12:57,293 iteration 6286 : loss : 0.014088, loss_ce: 0.004244
2021-12-10 13:12:58,807 iteration 6287 : loss : 0.017577, loss_ce: 0.004904
2021-12-10 13:13:00,256 iteration 6288 : loss : 0.012747, loss_ce: 0.004405
2021-12-10 13:13:01,844 iteration 6289 : loss : 0.020161, loss_ce: 0.010793
2021-12-10 13:13:01,845 Training Data Eval:
2021-12-10 13:13:09,590   Average segmentation loss on training set: 0.0088
2021-12-10 13:13:09,591 Validation Data Eval:
2021-12-10 13:13:12,254   Average segmentation loss on validation set: 0.0623
2021-12-10 13:13:13,845 iteration 6290 : loss : 0.023976, loss_ce: 0.011422
 92%|██████████████████████████▊  | 370/400 [2:57:25<15:06, 30.21s/it]2021-12-10 13:13:15,443 iteration 6291 : loss : 0.019535, loss_ce: 0.009681
2021-12-10 13:13:16,989 iteration 6292 : loss : 0.017698, loss_ce: 0.005878
2021-12-10 13:13:18,564 iteration 6293 : loss : 0.026843, loss_ce: 0.013690
2021-12-10 13:13:20,151 iteration 6294 : loss : 0.016353, loss_ce: 0.004592
2021-12-10 13:13:21,682 iteration 6295 : loss : 0.013466, loss_ce: 0.005711
2021-12-10 13:13:23,309 iteration 6296 : loss : 0.019396, loss_ce: 0.006672
2021-12-10 13:13:24,868 iteration 6297 : loss : 0.019617, loss_ce: 0.007151
2021-12-10 13:13:26,465 iteration 6298 : loss : 0.026911, loss_ce: 0.010423
2021-12-10 13:13:28,006 iteration 6299 : loss : 0.015886, loss_ce: 0.005325
2021-12-10 13:13:29,520 iteration 6300 : loss : 0.015617, loss_ce: 0.005283
2021-12-10 13:13:31,022 iteration 6301 : loss : 0.017205, loss_ce: 0.012108
2021-12-10 13:13:32,578 iteration 6302 : loss : 0.015353, loss_ce: 0.005453
2021-12-10 13:13:34,035 iteration 6303 : loss : 0.016029, loss_ce: 0.003611
2021-12-10 13:13:35,501 iteration 6304 : loss : 0.016970, loss_ce: 0.004919
2021-12-10 13:13:37,063 iteration 6305 : loss : 0.016665, loss_ce: 0.007279
2021-12-10 13:13:38,584 iteration 6306 : loss : 0.019349, loss_ce: 0.004273
2021-12-10 13:13:40,115 iteration 6307 : loss : 0.014886, loss_ce: 0.006747
 93%|██████████████████████████▉  | 371/400 [2:57:51<14:01, 29.03s/it]2021-12-10 13:13:41,655 iteration 6308 : loss : 0.014593, loss_ce: 0.003211
2021-12-10 13:13:43,211 iteration 6309 : loss : 0.016822, loss_ce: 0.006506
2021-12-10 13:13:44,743 iteration 6310 : loss : 0.015470, loss_ce: 0.007034
2021-12-10 13:13:46,301 iteration 6311 : loss : 0.014991, loss_ce: 0.006480
2021-12-10 13:13:47,876 iteration 6312 : loss : 0.033852, loss_ce: 0.011430
2021-12-10 13:13:49,500 iteration 6313 : loss : 0.027702, loss_ce: 0.013776
2021-12-10 13:13:51,044 iteration 6314 : loss : 0.011936, loss_ce: 0.003920
2021-12-10 13:13:52,549 iteration 6315 : loss : 0.017504, loss_ce: 0.006829
2021-12-10 13:13:54,087 iteration 6316 : loss : 0.013952, loss_ce: 0.004982
2021-12-10 13:13:55,614 iteration 6317 : loss : 0.018345, loss_ce: 0.005042
2021-12-10 13:13:57,228 iteration 6318 : loss : 0.028060, loss_ce: 0.012640
2021-12-10 13:13:58,796 iteration 6319 : loss : 0.013387, loss_ce: 0.004422
2021-12-10 13:14:00,325 iteration 6320 : loss : 0.017160, loss_ce: 0.006094
2021-12-10 13:14:01,920 iteration 6321 : loss : 0.015754, loss_ce: 0.007677
2021-12-10 13:14:03,527 iteration 6322 : loss : 0.014323, loss_ce: 0.006283
2021-12-10 13:14:05,222 iteration 6323 : loss : 0.029569, loss_ce: 0.008964
2021-12-10 13:14:06,859 iteration 6324 : loss : 0.021504, loss_ce: 0.010372
 93%|██████████████████████████▉  | 372/400 [2:58:18<13:13, 28.35s/it]2021-12-10 13:14:08,541 iteration 6325 : loss : 0.022031, loss_ce: 0.006733
2021-12-10 13:14:10,059 iteration 6326 : loss : 0.016105, loss_ce: 0.006868
2021-12-10 13:14:11,598 iteration 6327 : loss : 0.020096, loss_ce: 0.006090
2021-12-10 13:14:13,196 iteration 6328 : loss : 0.015370, loss_ce: 0.007887
2021-12-10 13:14:14,673 iteration 6329 : loss : 0.016414, loss_ce: 0.009132
2021-12-10 13:14:16,203 iteration 6330 : loss : 0.018397, loss_ce: 0.006717
2021-12-10 13:14:17,809 iteration 6331 : loss : 0.013492, loss_ce: 0.004937
2021-12-10 13:14:19,387 iteration 6332 : loss : 0.013680, loss_ce: 0.003870
2021-12-10 13:14:20,936 iteration 6333 : loss : 0.020933, loss_ce: 0.012160
2021-12-10 13:14:22,480 iteration 6334 : loss : 0.016334, loss_ce: 0.004340
2021-12-10 13:14:24,119 iteration 6335 : loss : 0.021479, loss_ce: 0.010280
2021-12-10 13:14:25,632 iteration 6336 : loss : 0.015637, loss_ce: 0.006643
2021-12-10 13:14:27,197 iteration 6337 : loss : 0.022515, loss_ce: 0.008012
2021-12-10 13:14:28,743 iteration 6338 : loss : 0.014891, loss_ce: 0.004654
2021-12-10 13:14:30,288 iteration 6339 : loss : 0.014139, loss_ce: 0.004621
2021-12-10 13:14:31,835 iteration 6340 : loss : 0.014767, loss_ce: 0.006462
2021-12-10 13:14:33,297 iteration 6341 : loss : 0.011954, loss_ce: 0.004055
 93%|███████████████████████████  | 373/400 [2:58:44<12:29, 27.77s/it]2021-12-10 13:14:34,943 iteration 6342 : loss : 0.029659, loss_ce: 0.009377
2021-12-10 13:14:36,471 iteration 6343 : loss : 0.013172, loss_ce: 0.004784
2021-12-10 13:14:37,993 iteration 6344 : loss : 0.015496, loss_ce: 0.004507
2021-12-10 13:14:39,504 iteration 6345 : loss : 0.020812, loss_ce: 0.003175
2021-12-10 13:14:41,066 iteration 6346 : loss : 0.020996, loss_ce: 0.007099
2021-12-10 13:14:42,617 iteration 6347 : loss : 0.018356, loss_ce: 0.006556
2021-12-10 13:14:44,063 iteration 6348 : loss : 0.009980, loss_ce: 0.004224
2021-12-10 13:14:45,651 iteration 6349 : loss : 0.026894, loss_ce: 0.013697
2021-12-10 13:14:47,311 iteration 6350 : loss : 0.027794, loss_ce: 0.009714
2021-12-10 13:14:48,916 iteration 6351 : loss : 0.014829, loss_ce: 0.006449
2021-12-10 13:14:50,459 iteration 6352 : loss : 0.019825, loss_ce: 0.005585
2021-12-10 13:14:52,019 iteration 6353 : loss : 0.016159, loss_ce: 0.005943
2021-12-10 13:14:53,566 iteration 6354 : loss : 0.014436, loss_ce: 0.005977
2021-12-10 13:14:55,084 iteration 6355 : loss : 0.016403, loss_ce: 0.005755
2021-12-10 13:14:56,693 iteration 6356 : loss : 0.018346, loss_ce: 0.004652
2021-12-10 13:14:58,207 iteration 6357 : loss : 0.020483, loss_ce: 0.007129
2021-12-10 13:14:59,866 iteration 6358 : loss : 0.016075, loss_ce: 0.006608
 94%|███████████████████████████  | 374/400 [2:59:11<11:52, 27.41s/it]2021-12-10 13:15:01,529 iteration 6359 : loss : 0.024452, loss_ce: 0.005800
2021-12-10 13:15:03,020 iteration 6360 : loss : 0.016163, loss_ce: 0.007105
2021-12-10 13:15:04,590 iteration 6361 : loss : 0.014140, loss_ce: 0.004979
2021-12-10 13:15:06,171 iteration 6362 : loss : 0.016803, loss_ce: 0.006516
2021-12-10 13:15:07,779 iteration 6363 : loss : 0.019908, loss_ce: 0.007728
2021-12-10 13:15:09,289 iteration 6364 : loss : 0.012818, loss_ce: 0.003342
2021-12-10 13:15:10,843 iteration 6365 : loss : 0.028101, loss_ce: 0.013512
2021-12-10 13:15:12,493 iteration 6366 : loss : 0.022407, loss_ce: 0.009316
2021-12-10 13:15:14,162 iteration 6367 : loss : 0.022458, loss_ce: 0.008948
2021-12-10 13:15:15,767 iteration 6368 : loss : 0.027153, loss_ce: 0.010154
2021-12-10 13:15:17,321 iteration 6369 : loss : 0.013471, loss_ce: 0.005361
2021-12-10 13:15:18,882 iteration 6370 : loss : 0.018897, loss_ce: 0.006494
2021-12-10 13:15:20,534 iteration 6371 : loss : 0.030917, loss_ce: 0.010389
2021-12-10 13:15:22,042 iteration 6372 : loss : 0.010136, loss_ce: 0.004221
2021-12-10 13:15:23,541 iteration 6373 : loss : 0.012505, loss_ce: 0.004777
2021-12-10 13:15:25,089 iteration 6374 : loss : 0.018314, loss_ce: 0.007418
2021-12-10 13:15:25,089 Training Data Eval:
2021-12-10 13:15:32,818   Average segmentation loss on training set: 0.0087
2021-12-10 13:15:32,819 Validation Data Eval:
2021-12-10 13:15:35,478   Average segmentation loss on validation set: 0.0632
2021-12-10 13:15:37,039 iteration 6375 : loss : 0.022586, loss_ce: 0.007202
 94%|███████████████████████████▏ | 375/400 [2:59:48<12:38, 30.34s/it]2021-12-10 13:15:38,680 iteration 6376 : loss : 0.020167, loss_ce: 0.005970
2021-12-10 13:15:40,234 iteration 6377 : loss : 0.025601, loss_ce: 0.009683
2021-12-10 13:15:41,682 iteration 6378 : loss : 0.012277, loss_ce: 0.005359
2021-12-10 13:15:43,217 iteration 6379 : loss : 0.021956, loss_ce: 0.005982
2021-12-10 13:15:44,725 iteration 6380 : loss : 0.019327, loss_ce: 0.007737
2021-12-10 13:15:46,218 iteration 6381 : loss : 0.010693, loss_ce: 0.003611
2021-12-10 13:15:47,664 iteration 6382 : loss : 0.017811, loss_ce: 0.006295
2021-12-10 13:15:49,252 iteration 6383 : loss : 0.021506, loss_ce: 0.008657
2021-12-10 13:15:50,759 iteration 6384 : loss : 0.016729, loss_ce: 0.005989
2021-12-10 13:15:52,337 iteration 6385 : loss : 0.016946, loss_ce: 0.005869
2021-12-10 13:15:53,936 iteration 6386 : loss : 0.016181, loss_ce: 0.005306
2021-12-10 13:15:55,584 iteration 6387 : loss : 0.021466, loss_ce: 0.010026
2021-12-10 13:15:57,169 iteration 6388 : loss : 0.016711, loss_ce: 0.006742
2021-12-10 13:15:58,598 iteration 6389 : loss : 0.014582, loss_ce: 0.005128
2021-12-10 13:16:00,149 iteration 6390 : loss : 0.013555, loss_ce: 0.006046
2021-12-10 13:16:01,644 iteration 6391 : loss : 0.014793, loss_ce: 0.008316
2021-12-10 13:16:03,255 iteration 6392 : loss : 0.021921, loss_ce: 0.006976
 94%|███████████████████████████▎ | 376/400 [3:00:14<11:38, 29.10s/it]2021-12-10 13:16:04,853 iteration 6393 : loss : 0.014803, loss_ce: 0.005725
2021-12-10 13:16:06,447 iteration 6394 : loss : 0.020196, loss_ce: 0.007261
2021-12-10 13:16:07,980 iteration 6395 : loss : 0.014966, loss_ce: 0.004396
2021-12-10 13:16:09,524 iteration 6396 : loss : 0.014597, loss_ce: 0.004613
2021-12-10 13:16:11,093 iteration 6397 : loss : 0.014703, loss_ce: 0.005542
2021-12-10 13:16:12,668 iteration 6398 : loss : 0.015272, loss_ce: 0.005895
2021-12-10 13:16:14,203 iteration 6399 : loss : 0.016523, loss_ce: 0.005228
2021-12-10 13:16:15,723 iteration 6400 : loss : 0.012776, loss_ce: 0.005179
2021-12-10 13:16:17,297 iteration 6401 : loss : 0.014058, loss_ce: 0.005525
2021-12-10 13:16:18,825 iteration 6402 : loss : 0.016792, loss_ce: 0.008602
2021-12-10 13:16:20,457 iteration 6403 : loss : 0.021047, loss_ce: 0.008646
2021-12-10 13:16:21,992 iteration 6404 : loss : 0.014056, loss_ce: 0.005820
2021-12-10 13:16:23,504 iteration 6405 : loss : 0.030636, loss_ce: 0.007108
2021-12-10 13:16:25,213 iteration 6406 : loss : 0.044955, loss_ce: 0.011593
2021-12-10 13:16:26,800 iteration 6407 : loss : 0.019391, loss_ce: 0.005227
2021-12-10 13:16:28,241 iteration 6408 : loss : 0.011845, loss_ce: 0.004051
2021-12-10 13:16:29,773 iteration 6409 : loss : 0.018547, loss_ce: 0.009560
 94%|███████████████████████████▎ | 377/400 [3:00:41<10:51, 28.33s/it]2021-12-10 13:16:31,335 iteration 6410 : loss : 0.012485, loss_ce: 0.004016
2021-12-10 13:16:32,910 iteration 6411 : loss : 0.016383, loss_ce: 0.006542
2021-12-10 13:16:34,488 iteration 6412 : loss : 0.015090, loss_ce: 0.006062
2021-12-10 13:16:36,020 iteration 6413 : loss : 0.019424, loss_ce: 0.009692
2021-12-10 13:16:37,537 iteration 6414 : loss : 0.017271, loss_ce: 0.007713
2021-12-10 13:16:39,029 iteration 6415 : loss : 0.012220, loss_ce: 0.004081
2021-12-10 13:16:40,579 iteration 6416 : loss : 0.012312, loss_ce: 0.005063
2021-12-10 13:16:42,055 iteration 6417 : loss : 0.015601, loss_ce: 0.006433
2021-12-10 13:16:43,568 iteration 6418 : loss : 0.014201, loss_ce: 0.006566
2021-12-10 13:16:45,204 iteration 6419 : loss : 0.021043, loss_ce: 0.008164
2021-12-10 13:16:46,822 iteration 6420 : loss : 0.022880, loss_ce: 0.005168
2021-12-10 13:16:48,402 iteration 6421 : loss : 0.016290, loss_ce: 0.006309
2021-12-10 13:16:49,951 iteration 6422 : loss : 0.017867, loss_ce: 0.005607
2021-12-10 13:16:51,535 iteration 6423 : loss : 0.015550, loss_ce: 0.006311
2021-12-10 13:16:53,184 iteration 6424 : loss : 0.026517, loss_ce: 0.015534
2021-12-10 13:16:54,718 iteration 6425 : loss : 0.016544, loss_ce: 0.004903
2021-12-10 13:16:56,340 iteration 6426 : loss : 0.025928, loss_ce: 0.008909
 94%|███████████████████████████▍ | 378/400 [3:01:07<10:11, 27.80s/it]2021-12-10 13:16:57,975 iteration 6427 : loss : 0.019552, loss_ce: 0.007823
2021-12-10 13:16:59,527 iteration 6428 : loss : 0.020142, loss_ce: 0.005868
2021-12-10 13:17:01,091 iteration 6429 : loss : 0.013935, loss_ce: 0.004699
2021-12-10 13:17:02,699 iteration 6430 : loss : 0.017195, loss_ce: 0.007161
2021-12-10 13:17:04,181 iteration 6431 : loss : 0.013702, loss_ce: 0.005094
2021-12-10 13:17:05,738 iteration 6432 : loss : 0.017560, loss_ce: 0.008269
2021-12-10 13:17:07,281 iteration 6433 : loss : 0.011628, loss_ce: 0.003727
2021-12-10 13:17:08,791 iteration 6434 : loss : 0.016212, loss_ce: 0.006776
2021-12-10 13:17:10,323 iteration 6435 : loss : 0.020610, loss_ce: 0.009658
2021-12-10 13:17:11,845 iteration 6436 : loss : 0.012991, loss_ce: 0.005338
2021-12-10 13:17:13,393 iteration 6437 : loss : 0.027200, loss_ce: 0.010276
2021-12-10 13:17:14,979 iteration 6438 : loss : 0.031423, loss_ce: 0.012004
2021-12-10 13:17:16,482 iteration 6439 : loss : 0.016401, loss_ce: 0.008072
2021-12-10 13:17:18,075 iteration 6440 : loss : 0.021329, loss_ce: 0.009138
2021-12-10 13:17:19,555 iteration 6441 : loss : 0.013879, loss_ce: 0.006766
2021-12-10 13:17:21,113 iteration 6442 : loss : 0.014480, loss_ce: 0.004417
2021-12-10 13:17:22,573 iteration 6443 : loss : 0.011971, loss_ce: 0.003975
 95%|███████████████████████████▍ | 379/400 [3:01:34<09:33, 27.33s/it]2021-12-10 13:17:24,195 iteration 6444 : loss : 0.013935, loss_ce: 0.006842
2021-12-10 13:17:25,744 iteration 6445 : loss : 0.022981, loss_ce: 0.008750
2021-12-10 13:17:27,306 iteration 6446 : loss : 0.020758, loss_ce: 0.008396
2021-12-10 13:17:28,887 iteration 6447 : loss : 0.019845, loss_ce: 0.004267
2021-12-10 13:17:30,473 iteration 6448 : loss : 0.017753, loss_ce: 0.006316
2021-12-10 13:17:31,986 iteration 6449 : loss : 0.013638, loss_ce: 0.003065
2021-12-10 13:17:33,478 iteration 6450 : loss : 0.015396, loss_ce: 0.006761
2021-12-10 13:17:35,025 iteration 6451 : loss : 0.014690, loss_ce: 0.005108
2021-12-10 13:17:36,644 iteration 6452 : loss : 0.022220, loss_ce: 0.007573
2021-12-10 13:17:38,170 iteration 6453 : loss : 0.019740, loss_ce: 0.007578
2021-12-10 13:17:39,647 iteration 6454 : loss : 0.017130, loss_ce: 0.006611
2021-12-10 13:17:41,232 iteration 6455 : loss : 0.016913, loss_ce: 0.007734
2021-12-10 13:17:42,769 iteration 6456 : loss : 0.028500, loss_ce: 0.010605
2021-12-10 13:17:44,339 iteration 6457 : loss : 0.024789, loss_ce: 0.008001
2021-12-10 13:17:45,830 iteration 6458 : loss : 0.013455, loss_ce: 0.005173
2021-12-10 13:17:47,351 iteration 6459 : loss : 0.009734, loss_ce: 0.002383
2021-12-10 13:17:47,352 Training Data Eval:
2021-12-10 13:17:55,075   Average segmentation loss on training set: 0.0087
2021-12-10 13:17:55,075 Validation Data Eval:
2021-12-10 13:17:57,727   Average segmentation loss on validation set: 0.0640
2021-12-10 13:17:59,310 iteration 6460 : loss : 0.019748, loss_ce: 0.011208
 95%|███████████████████████████▌ | 380/400 [3:02:10<10:03, 30.15s/it]2021-12-10 13:18:00,978 iteration 6461 : loss : 0.018962, loss_ce: 0.007805
2021-12-10 13:18:02,501 iteration 6462 : loss : 0.014395, loss_ce: 0.005749
2021-12-10 13:18:04,098 iteration 6463 : loss : 0.019841, loss_ce: 0.008088
2021-12-10 13:18:05,651 iteration 6464 : loss : 0.023142, loss_ce: 0.006041
2021-12-10 13:18:07,238 iteration 6465 : loss : 0.015555, loss_ce: 0.005648
2021-12-10 13:18:08,732 iteration 6466 : loss : 0.016598, loss_ce: 0.005660
2021-12-10 13:18:10,250 iteration 6467 : loss : 0.014551, loss_ce: 0.005938
2021-12-10 13:18:11,857 iteration 6468 : loss : 0.023198, loss_ce: 0.009215
2021-12-10 13:18:13,389 iteration 6469 : loss : 0.015735, loss_ce: 0.006589
2021-12-10 13:18:14,898 iteration 6470 : loss : 0.012512, loss_ce: 0.003632
2021-12-10 13:18:16,446 iteration 6471 : loss : 0.013305, loss_ce: 0.004768
2021-12-10 13:18:17,999 iteration 6472 : loss : 0.027548, loss_ce: 0.009357
2021-12-10 13:18:19,511 iteration 6473 : loss : 0.016046, loss_ce: 0.005882
2021-12-10 13:18:21,129 iteration 6474 : loss : 0.015263, loss_ce: 0.006959
2021-12-10 13:18:22,697 iteration 6475 : loss : 0.020952, loss_ce: 0.011470
2021-12-10 13:18:24,129 iteration 6476 : loss : 0.019467, loss_ce: 0.006489
2021-12-10 13:18:25,777 iteration 6477 : loss : 0.020205, loss_ce: 0.007745
 95%|███████████████████████████▌ | 381/400 [3:02:37<09:11, 29.04s/it]2021-12-10 13:18:27,443 iteration 6478 : loss : 0.020313, loss_ce: 0.006382
2021-12-10 13:18:28,965 iteration 6479 : loss : 0.017127, loss_ce: 0.006080
2021-12-10 13:18:30,492 iteration 6480 : loss : 0.014163, loss_ce: 0.006448
2021-12-10 13:18:32,072 iteration 6481 : loss : 0.016485, loss_ce: 0.006362
2021-12-10 13:18:33,540 iteration 6482 : loss : 0.011651, loss_ce: 0.004082
2021-12-10 13:18:35,114 iteration 6483 : loss : 0.020314, loss_ce: 0.005273
2021-12-10 13:18:36,610 iteration 6484 : loss : 0.014445, loss_ce: 0.006384
2021-12-10 13:18:38,137 iteration 6485 : loss : 0.015810, loss_ce: 0.006897
2021-12-10 13:18:39,729 iteration 6486 : loss : 0.015340, loss_ce: 0.005441
2021-12-10 13:18:41,389 iteration 6487 : loss : 0.027821, loss_ce: 0.011151
2021-12-10 13:18:42,979 iteration 6488 : loss : 0.026871, loss_ce: 0.010354
2021-12-10 13:18:44,487 iteration 6489 : loss : 0.011979, loss_ce: 0.005845
2021-12-10 13:18:46,056 iteration 6490 : loss : 0.018137, loss_ce: 0.004888
2021-12-10 13:18:47,580 iteration 6491 : loss : 0.012558, loss_ce: 0.004457
2021-12-10 13:18:49,217 iteration 6492 : loss : 0.016674, loss_ce: 0.007445
2021-12-10 13:18:50,793 iteration 6493 : loss : 0.021914, loss_ce: 0.007900
2021-12-10 13:18:52,234 iteration 6494 : loss : 0.009556, loss_ce: 0.003797
 96%|███████████████████████████▋ | 382/400 [3:03:03<08:28, 28.27s/it]2021-12-10 13:18:53,808 iteration 6495 : loss : 0.014763, loss_ce: 0.005667
2021-12-10 13:18:55,351 iteration 6496 : loss : 0.021051, loss_ce: 0.005763
2021-12-10 13:18:56,947 iteration 6497 : loss : 0.015365, loss_ce: 0.005552
2021-12-10 13:18:58,534 iteration 6498 : loss : 0.019030, loss_ce: 0.007353
2021-12-10 13:19:00,121 iteration 6499 : loss : 0.018555, loss_ce: 0.008416
2021-12-10 13:19:01,660 iteration 6500 : loss : 0.016458, loss_ce: 0.006855
2021-12-10 13:19:03,234 iteration 6501 : loss : 0.020444, loss_ce: 0.008248
2021-12-10 13:19:04,841 iteration 6502 : loss : 0.014407, loss_ce: 0.007773
2021-12-10 13:19:06,359 iteration 6503 : loss : 0.010989, loss_ce: 0.002792
2021-12-10 13:19:07,847 iteration 6504 : loss : 0.013552, loss_ce: 0.004842
2021-12-10 13:19:09,264 iteration 6505 : loss : 0.011251, loss_ce: 0.005280
2021-12-10 13:19:10,784 iteration 6506 : loss : 0.020675, loss_ce: 0.005635
2021-12-10 13:19:12,399 iteration 6507 : loss : 0.018627, loss_ce: 0.009030
2021-12-10 13:19:13,980 iteration 6508 : loss : 0.017670, loss_ce: 0.006053
2021-12-10 13:19:15,545 iteration 6509 : loss : 0.018383, loss_ce: 0.007094
2021-12-10 13:19:17,109 iteration 6510 : loss : 0.015352, loss_ce: 0.004862
2021-12-10 13:19:18,573 iteration 6511 : loss : 0.013791, loss_ce: 0.005091
 96%|███████████████████████████▊ | 383/400 [3:03:30<07:50, 27.69s/it]2021-12-10 13:19:20,129 iteration 6512 : loss : 0.020592, loss_ce: 0.007114
2021-12-10 13:19:21,688 iteration 6513 : loss : 0.013285, loss_ce: 0.004413
2021-12-10 13:19:23,348 iteration 6514 : loss : 0.016745, loss_ce: 0.005290
2021-12-10 13:19:24,967 iteration 6515 : loss : 0.031306, loss_ce: 0.010345
2021-12-10 13:19:26,552 iteration 6516 : loss : 0.021703, loss_ce: 0.008942
2021-12-10 13:19:28,094 iteration 6517 : loss : 0.032572, loss_ce: 0.005392
2021-12-10 13:19:29,653 iteration 6518 : loss : 0.014124, loss_ce: 0.004931
2021-12-10 13:19:31,200 iteration 6519 : loss : 0.016686, loss_ce: 0.005625
2021-12-10 13:19:32,804 iteration 6520 : loss : 0.019023, loss_ce: 0.006053
2021-12-10 13:19:34,311 iteration 6521 : loss : 0.015997, loss_ce: 0.007119
2021-12-10 13:19:35,873 iteration 6522 : loss : 0.011794, loss_ce: 0.004885
2021-12-10 13:19:37,350 iteration 6523 : loss : 0.011344, loss_ce: 0.004620
2021-12-10 13:19:38,950 iteration 6524 : loss : 0.018343, loss_ce: 0.008198
2021-12-10 13:19:40,515 iteration 6525 : loss : 0.017372, loss_ce: 0.006504
2021-12-10 13:19:42,078 iteration 6526 : loss : 0.025738, loss_ce: 0.009136
2021-12-10 13:19:43,544 iteration 6527 : loss : 0.013525, loss_ce: 0.005905
2021-12-10 13:19:45,048 iteration 6528 : loss : 0.014240, loss_ce: 0.004563
 96%|███████████████████████████▊ | 384/400 [3:03:56<07:17, 27.33s/it]2021-12-10 13:19:46,715 iteration 6529 : loss : 0.029511, loss_ce: 0.013432
2021-12-10 13:19:48,296 iteration 6530 : loss : 0.014418, loss_ce: 0.004824
2021-12-10 13:19:49,784 iteration 6531 : loss : 0.015891, loss_ce: 0.005195
2021-12-10 13:19:51,364 iteration 6532 : loss : 0.015544, loss_ce: 0.005921
2021-12-10 13:19:52,842 iteration 6533 : loss : 0.009842, loss_ce: 0.003731
2021-12-10 13:19:54,394 iteration 6534 : loss : 0.018235, loss_ce: 0.008664
2021-12-10 13:19:55,968 iteration 6535 : loss : 0.021297, loss_ce: 0.008471
2021-12-10 13:19:57,551 iteration 6536 : loss : 0.013695, loss_ce: 0.004589
2021-12-10 13:19:59,125 iteration 6537 : loss : 0.018450, loss_ce: 0.007046
2021-12-10 13:20:00,698 iteration 6538 : loss : 0.017182, loss_ce: 0.005153
2021-12-10 13:20:02,299 iteration 6539 : loss : 0.013781, loss_ce: 0.006084
2021-12-10 13:20:03,762 iteration 6540 : loss : 0.011285, loss_ce: 0.004631
2021-12-10 13:20:05,277 iteration 6541 : loss : 0.017002, loss_ce: 0.009991
2021-12-10 13:20:06,925 iteration 6542 : loss : 0.014572, loss_ce: 0.005047
2021-12-10 13:20:08,447 iteration 6543 : loss : 0.011551, loss_ce: 0.003662
2021-12-10 13:20:10,031 iteration 6544 : loss : 0.016917, loss_ce: 0.006584
2021-12-10 13:20:10,032 Training Data Eval:
2021-12-10 13:20:17,783   Average segmentation loss on training set: 0.0084
2021-12-10 13:20:17,783 Validation Data Eval:
2021-12-10 13:20:20,450   Average segmentation loss on validation set: 0.0706
2021-12-10 13:20:22,086 iteration 6545 : loss : 0.027080, loss_ce: 0.012622
 96%|███████████████████████████▉ | 385/400 [3:04:33<07:33, 30.24s/it]2021-12-10 13:20:23,886 iteration 6546 : loss : 0.020658, loss_ce: 0.008405
2021-12-10 13:20:25,434 iteration 6547 : loss : 0.015448, loss_ce: 0.006736
2021-12-10 13:20:27,014 iteration 6548 : loss : 0.019236, loss_ce: 0.009978
2021-12-10 13:20:28,507 iteration 6549 : loss : 0.015702, loss_ce: 0.006089
2021-12-10 13:20:30,107 iteration 6550 : loss : 0.017722, loss_ce: 0.005808
2021-12-10 13:20:31,727 iteration 6551 : loss : 0.019747, loss_ce: 0.007717
2021-12-10 13:20:33,389 iteration 6552 : loss : 0.024657, loss_ce: 0.009435
2021-12-10 13:20:35,076 iteration 6553 : loss : 0.020732, loss_ce: 0.006003
2021-12-10 13:20:36,654 iteration 6554 : loss : 0.023800, loss_ce: 0.007556
2021-12-10 13:20:38,221 iteration 6555 : loss : 0.012867, loss_ce: 0.005588
2021-12-10 13:20:39,771 iteration 6556 : loss : 0.017783, loss_ce: 0.004327
2021-12-10 13:20:41,214 iteration 6557 : loss : 0.009732, loss_ce: 0.003987
2021-12-10 13:20:42,753 iteration 6558 : loss : 0.017949, loss_ce: 0.006195
2021-12-10 13:20:44,216 iteration 6559 : loss : 0.012882, loss_ce: 0.004426
2021-12-10 13:20:45,763 iteration 6560 : loss : 0.018045, loss_ce: 0.008395
2021-12-10 13:20:47,352 iteration 6561 : loss : 0.019291, loss_ce: 0.005776
2021-12-10 13:20:48,856 iteration 6562 : loss : 0.015051, loss_ce: 0.005479
 96%|███████████████████████████▉ | 386/400 [3:05:00<06:48, 29.20s/it]2021-12-10 13:20:50,591 iteration 6563 : loss : 0.031102, loss_ce: 0.013886
2021-12-10 13:20:52,113 iteration 6564 : loss : 0.015849, loss_ce: 0.007079
2021-12-10 13:20:53,606 iteration 6565 : loss : 0.026227, loss_ce: 0.005290
2021-12-10 13:20:55,090 iteration 6566 : loss : 0.015477, loss_ce: 0.006506
2021-12-10 13:20:56,549 iteration 6567 : loss : 0.013825, loss_ce: 0.006057
2021-12-10 13:20:58,067 iteration 6568 : loss : 0.013530, loss_ce: 0.005691
2021-12-10 13:20:59,611 iteration 6569 : loss : 0.010908, loss_ce: 0.004147
2021-12-10 13:21:01,099 iteration 6570 : loss : 0.013559, loss_ce: 0.006444
2021-12-10 13:21:02,625 iteration 6571 : loss : 0.019422, loss_ce: 0.005518
2021-12-10 13:21:04,080 iteration 6572 : loss : 0.011239, loss_ce: 0.004719
2021-12-10 13:21:05,690 iteration 6573 : loss : 0.016946, loss_ce: 0.005346
2021-12-10 13:21:07,312 iteration 6574 : loss : 0.012963, loss_ce: 0.006096
2021-12-10 13:21:08,945 iteration 6575 : loss : 0.026597, loss_ce: 0.008960
2021-12-10 13:21:10,446 iteration 6576 : loss : 0.017157, loss_ce: 0.007355
2021-12-10 13:21:12,011 iteration 6577 : loss : 0.022879, loss_ce: 0.005178
2021-12-10 13:21:13,500 iteration 6578 : loss : 0.013691, loss_ce: 0.005316
2021-12-10 13:21:15,049 iteration 6579 : loss : 0.017794, loss_ce: 0.006020
 97%|████████████████████████████ | 387/400 [3:05:26<06:07, 28.30s/it]2021-12-10 13:21:16,666 iteration 6580 : loss : 0.014723, loss_ce: 0.004408
2021-12-10 13:21:18,189 iteration 6581 : loss : 0.013750, loss_ce: 0.004203
2021-12-10 13:21:19,807 iteration 6582 : loss : 0.018492, loss_ce: 0.006725
2021-12-10 13:21:21,361 iteration 6583 : loss : 0.020556, loss_ce: 0.008489
2021-12-10 13:21:22,929 iteration 6584 : loss : 0.015376, loss_ce: 0.007030
2021-12-10 13:21:24,533 iteration 6585 : loss : 0.020899, loss_ce: 0.007239
2021-12-10 13:21:26,116 iteration 6586 : loss : 0.026038, loss_ce: 0.007442
2021-12-10 13:21:27,645 iteration 6587 : loss : 0.013225, loss_ce: 0.006666
2021-12-10 13:21:29,201 iteration 6588 : loss : 0.016931, loss_ce: 0.007257
2021-12-10 13:21:30,686 iteration 6589 : loss : 0.013463, loss_ce: 0.005332
2021-12-10 13:21:32,297 iteration 6590 : loss : 0.016671, loss_ce: 0.007422
2021-12-10 13:21:33,908 iteration 6591 : loss : 0.017987, loss_ce: 0.007624
2021-12-10 13:21:35,430 iteration 6592 : loss : 0.014424, loss_ce: 0.005631
2021-12-10 13:21:37,063 iteration 6593 : loss : 0.024684, loss_ce: 0.004770
2021-12-10 13:21:38,602 iteration 6594 : loss : 0.011611, loss_ce: 0.005478
2021-12-10 13:21:40,121 iteration 6595 : loss : 0.017303, loss_ce: 0.007114
2021-12-10 13:21:41,722 iteration 6596 : loss : 0.014558, loss_ce: 0.004548
 97%|████████████████████████████▏| 388/400 [3:05:53<05:33, 27.81s/it]2021-12-10 13:21:43,320 iteration 6597 : loss : 0.016611, loss_ce: 0.007017
2021-12-10 13:21:44,809 iteration 6598 : loss : 0.022688, loss_ce: 0.004206
2021-12-10 13:21:46,368 iteration 6599 : loss : 0.014092, loss_ce: 0.005659
2021-12-10 13:21:47,794 iteration 6600 : loss : 0.010622, loss_ce: 0.004405
2021-12-10 13:21:49,326 iteration 6601 : loss : 0.014405, loss_ce: 0.004854
2021-12-10 13:21:50,826 iteration 6602 : loss : 0.012124, loss_ce: 0.004464
2021-12-10 13:21:52,358 iteration 6603 : loss : 0.017629, loss_ce: 0.006051
2021-12-10 13:21:53,809 iteration 6604 : loss : 0.009210, loss_ce: 0.003700
2021-12-10 13:21:55,361 iteration 6605 : loss : 0.019228, loss_ce: 0.006877
2021-12-10 13:21:56,932 iteration 6606 : loss : 0.018828, loss_ce: 0.009247
2021-12-10 13:21:58,509 iteration 6607 : loss : 0.019614, loss_ce: 0.007943
2021-12-10 13:22:00,077 iteration 6608 : loss : 0.017028, loss_ce: 0.008797
2021-12-10 13:22:01,573 iteration 6609 : loss : 0.013542, loss_ce: 0.004861
2021-12-10 13:22:03,085 iteration 6610 : loss : 0.016533, loss_ce: 0.007794
2021-12-10 13:22:04,597 iteration 6611 : loss : 0.012881, loss_ce: 0.003145
2021-12-10 13:22:06,188 iteration 6612 : loss : 0.029195, loss_ce: 0.010866
2021-12-10 13:22:07,615 iteration 6613 : loss : 0.012459, loss_ce: 0.004811
 97%|████████████████████████████▏| 389/400 [3:06:19<04:59, 27.24s/it]2021-12-10 13:22:09,257 iteration 6614 : loss : 0.016621, loss_ce: 0.006215
2021-12-10 13:22:10,815 iteration 6615 : loss : 0.016493, loss_ce: 0.006836
2021-12-10 13:22:12,348 iteration 6616 : loss : 0.017532, loss_ce: 0.005968
2021-12-10 13:22:14,031 iteration 6617 : loss : 0.018441, loss_ce: 0.006478
2021-12-10 13:22:15,597 iteration 6618 : loss : 0.030176, loss_ce: 0.010083
2021-12-10 13:22:17,247 iteration 6619 : loss : 0.021033, loss_ce: 0.007847
2021-12-10 13:22:18,848 iteration 6620 : loss : 0.029708, loss_ce: 0.014049
2021-12-10 13:22:20,389 iteration 6621 : loss : 0.022417, loss_ce: 0.006730
2021-12-10 13:22:21,919 iteration 6622 : loss : 0.018083, loss_ce: 0.008497
2021-12-10 13:22:23,462 iteration 6623 : loss : 0.015696, loss_ce: 0.005616
2021-12-10 13:22:25,055 iteration 6624 : loss : 0.027712, loss_ce: 0.012815
2021-12-10 13:22:26,665 iteration 6625 : loss : 0.013283, loss_ce: 0.005267
2021-12-10 13:22:28,204 iteration 6626 : loss : 0.021304, loss_ce: 0.006451
2021-12-10 13:22:29,665 iteration 6627 : loss : 0.012854, loss_ce: 0.004536
2021-12-10 13:22:31,195 iteration 6628 : loss : 0.014425, loss_ce: 0.006632
2021-12-10 13:22:32,725 iteration 6629 : loss : 0.014362, loss_ce: 0.006842
2021-12-10 13:22:32,725 Training Data Eval:
2021-12-10 13:22:40,461   Average segmentation loss on training set: 0.0086
2021-12-10 13:22:40,461 Validation Data Eval:
2021-12-10 13:22:43,121   Average segmentation loss on validation set: 0.0634
2021-12-10 13:22:44,710 iteration 6630 : loss : 0.019656, loss_ce: 0.005860
 98%|████████████████████████████▎| 390/400 [3:06:56<05:01, 30.19s/it]2021-12-10 13:22:46,399 iteration 6631 : loss : 0.015898, loss_ce: 0.005608
2021-12-10 13:22:47,965 iteration 6632 : loss : 0.037339, loss_ce: 0.016878
2021-12-10 13:22:49,515 iteration 6633 : loss : 0.018018, loss_ce: 0.004293
2021-12-10 13:22:50,931 iteration 6634 : loss : 0.011188, loss_ce: 0.003611
2021-12-10 13:22:52,427 iteration 6635 : loss : 0.017408, loss_ce: 0.004487
2021-12-10 13:22:54,033 iteration 6636 : loss : 0.014938, loss_ce: 0.005862
2021-12-10 13:22:55,609 iteration 6637 : loss : 0.014868, loss_ce: 0.006829
2021-12-10 13:22:57,203 iteration 6638 : loss : 0.018208, loss_ce: 0.007570
2021-12-10 13:22:58,834 iteration 6639 : loss : 0.024945, loss_ce: 0.009295
2021-12-10 13:23:00,378 iteration 6640 : loss : 0.016415, loss_ce: 0.004769
2021-12-10 13:23:01,888 iteration 6641 : loss : 0.013188, loss_ce: 0.006759
2021-12-10 13:23:03,516 iteration 6642 : loss : 0.015748, loss_ce: 0.006862
2021-12-10 13:23:05,097 iteration 6643 : loss : 0.018828, loss_ce: 0.007747
2021-12-10 13:23:06,652 iteration 6644 : loss : 0.016270, loss_ce: 0.005556
2021-12-10 13:23:08,135 iteration 6645 : loss : 0.012266, loss_ce: 0.005932
2021-12-10 13:23:09,656 iteration 6646 : loss : 0.012526, loss_ce: 0.005276
2021-12-10 13:23:11,103 iteration 6647 : loss : 0.012139, loss_ce: 0.003846
 98%|████████████████████████████▎| 391/400 [3:07:22<04:21, 29.05s/it]2021-12-10 13:23:12,661 iteration 6648 : loss : 0.013987, loss_ce: 0.004692
2021-12-10 13:23:14,276 iteration 6649 : loss : 0.015851, loss_ce: 0.006304
2021-12-10 13:23:15,758 iteration 6650 : loss : 0.016756, loss_ce: 0.005913
2021-12-10 13:23:17,256 iteration 6651 : loss : 0.010342, loss_ce: 0.003599
2021-12-10 13:23:18,879 iteration 6652 : loss : 0.024138, loss_ce: 0.008205
2021-12-10 13:23:20,491 iteration 6653 : loss : 0.018657, loss_ce: 0.007610
2021-12-10 13:23:21,998 iteration 6654 : loss : 0.013579, loss_ce: 0.005513
2021-12-10 13:23:23,568 iteration 6655 : loss : 0.016961, loss_ce: 0.007427
2021-12-10 13:23:25,152 iteration 6656 : loss : 0.011694, loss_ce: 0.004660
2021-12-10 13:23:26,801 iteration 6657 : loss : 0.031210, loss_ce: 0.012979
2021-12-10 13:23:28,378 iteration 6658 : loss : 0.021670, loss_ce: 0.007568
2021-12-10 13:23:29,985 iteration 6659 : loss : 0.023763, loss_ce: 0.007920
2021-12-10 13:23:31,498 iteration 6660 : loss : 0.013241, loss_ce: 0.004378
2021-12-10 13:23:32,960 iteration 6661 : loss : 0.010351, loss_ce: 0.003854
2021-12-10 13:23:34,516 iteration 6662 : loss : 0.014278, loss_ce: 0.005209
2021-12-10 13:23:36,124 iteration 6663 : loss : 0.016634, loss_ce: 0.006132
2021-12-10 13:23:37,665 iteration 6664 : loss : 0.018407, loss_ce: 0.006534
 98%|████████████████████████████▍| 392/400 [3:07:49<03:46, 28.31s/it]2021-12-10 13:23:39,299 iteration 6665 : loss : 0.014608, loss_ce: 0.005271
2021-12-10 13:23:40,870 iteration 6666 : loss : 0.019793, loss_ce: 0.007405
2021-12-10 13:23:42,383 iteration 6667 : loss : 0.013918, loss_ce: 0.004935
2021-12-10 13:23:43,817 iteration 6668 : loss : 0.009376, loss_ce: 0.003847
2021-12-10 13:23:45,383 iteration 6669 : loss : 0.016524, loss_ce: 0.005597
2021-12-10 13:23:46,859 iteration 6670 : loss : 0.018295, loss_ce: 0.006184
2021-12-10 13:23:48,487 iteration 6671 : loss : 0.019095, loss_ce: 0.007512
2021-12-10 13:23:50,034 iteration 6672 : loss : 0.016138, loss_ce: 0.007940
2021-12-10 13:23:51,665 iteration 6673 : loss : 0.018401, loss_ce: 0.008620
2021-12-10 13:23:53,285 iteration 6674 : loss : 0.015318, loss_ce: 0.005850
2021-12-10 13:23:54,805 iteration 6675 : loss : 0.017591, loss_ce: 0.006339
2021-12-10 13:23:56,274 iteration 6676 : loss : 0.010015, loss_ce: 0.003730
2021-12-10 13:23:57,840 iteration 6677 : loss : 0.012202, loss_ce: 0.002808
2021-12-10 13:23:59,481 iteration 6678 : loss : 0.015192, loss_ce: 0.006778
2021-12-10 13:24:01,062 iteration 6679 : loss : 0.015620, loss_ce: 0.005210
2021-12-10 13:24:02,598 iteration 6680 : loss : 0.020933, loss_ce: 0.009200
2021-12-10 13:24:04,094 iteration 6681 : loss : 0.013435, loss_ce: 0.004526
 98%|████████████████████████████▍| 393/400 [3:08:15<03:14, 27.74s/it]2021-12-10 13:24:05,699 iteration 6682 : loss : 0.014323, loss_ce: 0.004421
2021-12-10 13:24:07,298 iteration 6683 : loss : 0.017020, loss_ce: 0.005379
2021-12-10 13:24:08,871 iteration 6684 : loss : 0.031069, loss_ce: 0.004754
2021-12-10 13:24:10,406 iteration 6685 : loss : 0.012084, loss_ce: 0.004406
2021-12-10 13:24:11,979 iteration 6686 : loss : 0.017328, loss_ce: 0.005751
2021-12-10 13:24:13,540 iteration 6687 : loss : 0.018463, loss_ce: 0.007572
2021-12-10 13:24:15,103 iteration 6688 : loss : 0.015490, loss_ce: 0.005621
2021-12-10 13:24:16,617 iteration 6689 : loss : 0.014933, loss_ce: 0.005967
2021-12-10 13:24:18,230 iteration 6690 : loss : 0.015926, loss_ce: 0.005805
2021-12-10 13:24:19,715 iteration 6691 : loss : 0.011885, loss_ce: 0.004577
2021-12-10 13:24:21,199 iteration 6692 : loss : 0.016169, loss_ce: 0.010489
2021-12-10 13:24:22,762 iteration 6693 : loss : 0.020972, loss_ce: 0.009856
2021-12-10 13:24:24,234 iteration 6694 : loss : 0.011106, loss_ce: 0.004667
2021-12-10 13:24:25,742 iteration 6695 : loss : 0.013481, loss_ce: 0.004136
2021-12-10 13:24:27,267 iteration 6696 : loss : 0.021692, loss_ce: 0.012421
2021-12-10 13:24:28,814 iteration 6697 : loss : 0.020463, loss_ce: 0.007987
2021-12-10 13:24:30,276 iteration 6698 : loss : 0.017484, loss_ce: 0.006531
 98%|████████████████████████████▌| 394/400 [3:08:41<02:43, 27.27s/it]2021-12-10 13:24:31,891 iteration 6699 : loss : 0.015138, loss_ce: 0.004367
2021-12-10 13:24:33,498 iteration 6700 : loss : 0.018995, loss_ce: 0.008170
2021-12-10 13:24:35,134 iteration 6701 : loss : 0.030211, loss_ce: 0.010300
2021-12-10 13:24:36,650 iteration 6702 : loss : 0.013986, loss_ce: 0.004541
2021-12-10 13:24:38,303 iteration 6703 : loss : 0.019377, loss_ce: 0.007220
2021-12-10 13:24:39,867 iteration 6704 : loss : 0.023643, loss_ce: 0.011599
2021-12-10 13:24:41,349 iteration 6705 : loss : 0.012870, loss_ce: 0.003951
2021-12-10 13:24:42,865 iteration 6706 : loss : 0.015859, loss_ce: 0.005771
2021-12-10 13:24:44,400 iteration 6707 : loss : 0.013429, loss_ce: 0.004603
2021-12-10 13:24:45,856 iteration 6708 : loss : 0.010247, loss_ce: 0.002963
2021-12-10 13:24:47,352 iteration 6709 : loss : 0.013011, loss_ce: 0.003619
2021-12-10 13:24:48,920 iteration 6710 : loss : 0.019113, loss_ce: 0.007777
2021-12-10 13:24:50,458 iteration 6711 : loss : 0.016886, loss_ce: 0.007023
2021-12-10 13:24:52,041 iteration 6712 : loss : 0.014385, loss_ce: 0.005625
2021-12-10 13:24:53,549 iteration 6713 : loss : 0.013779, loss_ce: 0.004431
2021-12-10 13:24:55,077 iteration 6714 : loss : 0.020454, loss_ce: 0.008141
2021-12-10 13:24:55,077 Training Data Eval:
2021-12-10 13:25:02,804   Average segmentation loss on training set: 0.0084
2021-12-10 13:25:02,805 Validation Data Eval:
2021-12-10 13:25:05,458   Average segmentation loss on validation set: 0.0650
2021-12-10 13:25:06,959 iteration 6715 : loss : 0.009643, loss_ce: 0.002749
 99%|████████████████████████████▋| 395/400 [3:09:18<02:30, 30.10s/it]2021-12-10 13:25:08,474 iteration 6716 : loss : 0.011949, loss_ce: 0.003954
2021-12-10 13:25:10,047 iteration 6717 : loss : 0.026696, loss_ce: 0.006797
2021-12-10 13:25:11,660 iteration 6718 : loss : 0.022802, loss_ce: 0.011812
2021-12-10 13:25:13,259 iteration 6719 : loss : 0.023739, loss_ce: 0.008317
2021-12-10 13:25:14,834 iteration 6720 : loss : 0.036604, loss_ce: 0.006750
2021-12-10 13:25:16,417 iteration 6721 : loss : 0.024164, loss_ce: 0.012134
2021-12-10 13:25:17,950 iteration 6722 : loss : 0.011903, loss_ce: 0.004885
2021-12-10 13:25:19,499 iteration 6723 : loss : 0.023318, loss_ce: 0.010094
2021-12-10 13:25:20,988 iteration 6724 : loss : 0.014837, loss_ce: 0.006172
2021-12-10 13:25:22,517 iteration 6725 : loss : 0.010972, loss_ce: 0.003709
2021-12-10 13:25:23,974 iteration 6726 : loss : 0.008917, loss_ce: 0.002905
2021-12-10 13:25:25,624 iteration 6727 : loss : 0.030686, loss_ce: 0.011988
2021-12-10 13:25:27,119 iteration 6728 : loss : 0.015722, loss_ce: 0.006529
2021-12-10 13:25:28,718 iteration 6729 : loss : 0.021148, loss_ce: 0.007389
2021-12-10 13:25:30,368 iteration 6730 : loss : 0.022386, loss_ce: 0.008065
2021-12-10 13:25:31,963 iteration 6731 : loss : 0.019446, loss_ce: 0.006303
2021-12-10 13:25:33,520 iteration 6732 : loss : 0.011211, loss_ce: 0.004933
 99%|████████████████████████████▋| 396/400 [3:09:44<01:56, 29.03s/it]2021-12-10 13:25:35,059 iteration 6733 : loss : 0.010034, loss_ce: 0.003988
2021-12-10 13:25:36,590 iteration 6734 : loss : 0.017623, loss_ce: 0.004570
2021-12-10 13:25:38,170 iteration 6735 : loss : 0.019336, loss_ce: 0.006301
2021-12-10 13:25:39,698 iteration 6736 : loss : 0.013558, loss_ce: 0.006300
2021-12-10 13:25:41,182 iteration 6737 : loss : 0.012976, loss_ce: 0.006177
2021-12-10 13:25:42,651 iteration 6738 : loss : 0.012253, loss_ce: 0.003720
2021-12-10 13:25:44,190 iteration 6739 : loss : 0.015650, loss_ce: 0.006882
2021-12-10 13:25:45,775 iteration 6740 : loss : 0.022723, loss_ce: 0.008311
2021-12-10 13:25:47,339 iteration 6741 : loss : 0.021169, loss_ce: 0.009100
2021-12-10 13:25:48,857 iteration 6742 : loss : 0.014177, loss_ce: 0.006962
2021-12-10 13:25:50,342 iteration 6743 : loss : 0.012834, loss_ce: 0.003030
2021-12-10 13:25:51,936 iteration 6744 : loss : 0.020749, loss_ce: 0.008746
2021-12-10 13:25:53,481 iteration 6745 : loss : 0.014079, loss_ce: 0.006838
2021-12-10 13:25:54,949 iteration 6746 : loss : 0.009485, loss_ce: 0.002620
2021-12-10 13:25:56,451 iteration 6747 : loss : 0.011612, loss_ce: 0.003547
2021-12-10 13:25:58,019 iteration 6748 : loss : 0.011470, loss_ce: 0.004924
2021-12-10 13:25:59,542 iteration 6749 : loss : 0.012157, loss_ce: 0.003229
 99%|████████████████████████████▊| 397/400 [3:10:11<01:24, 28.13s/it]2021-12-10 13:26:01,121 iteration 6750 : loss : 0.014167, loss_ce: 0.006928
2021-12-10 13:26:02,733 iteration 6751 : loss : 0.011804, loss_ce: 0.004464
2021-12-10 13:26:04,203 iteration 6752 : loss : 0.016817, loss_ce: 0.005481
2021-12-10 13:26:05,747 iteration 6753 : loss : 0.016365, loss_ce: 0.007024
2021-12-10 13:26:07,322 iteration 6754 : loss : 0.012403, loss_ce: 0.004289
2021-12-10 13:26:08,828 iteration 6755 : loss : 0.014429, loss_ce: 0.004410
2021-12-10 13:26:10,337 iteration 6756 : loss : 0.013601, loss_ce: 0.006182
2021-12-10 13:26:11,950 iteration 6757 : loss : 0.019818, loss_ce: 0.006081
2021-12-10 13:26:13,461 iteration 6758 : loss : 0.013379, loss_ce: 0.005789
2021-12-10 13:26:15,016 iteration 6759 : loss : 0.012082, loss_ce: 0.005241
2021-12-10 13:26:16,628 iteration 6760 : loss : 0.025955, loss_ce: 0.005730
2021-12-10 13:26:18,169 iteration 6761 : loss : 0.016566, loss_ce: 0.005476
2021-12-10 13:26:19,691 iteration 6762 : loss : 0.017524, loss_ce: 0.005308
2021-12-10 13:26:21,290 iteration 6763 : loss : 0.013903, loss_ce: 0.005662
2021-12-10 13:26:22,796 iteration 6764 : loss : 0.016032, loss_ce: 0.006639
2021-12-10 13:26:24,400 iteration 6765 : loss : 0.018264, loss_ce: 0.007059
2021-12-10 13:26:25,911 iteration 6766 : loss : 0.010888, loss_ce: 0.004874
100%|████████████████████████████▊| 398/400 [3:10:37<00:55, 27.60s/it]2021-12-10 13:26:27,494 iteration 6767 : loss : 0.021612, loss_ce: 0.007099
2021-12-10 13:26:29,133 iteration 6768 : loss : 0.019160, loss_ce: 0.006472
2021-12-10 13:26:30,695 iteration 6769 : loss : 0.016925, loss_ce: 0.007215
2021-12-10 13:26:32,214 iteration 6770 : loss : 0.014814, loss_ce: 0.007220
2021-12-10 13:26:33,860 iteration 6771 : loss : 0.020993, loss_ce: 0.004127
2021-12-10 13:26:35,376 iteration 6772 : loss : 0.016029, loss_ce: 0.006300
2021-12-10 13:26:36,784 iteration 6773 : loss : 0.011404, loss_ce: 0.003432
2021-12-10 13:26:38,350 iteration 6774 : loss : 0.021461, loss_ce: 0.005256
2021-12-10 13:26:39,925 iteration 6775 : loss : 0.022240, loss_ce: 0.007474
2021-12-10 13:26:41,456 iteration 6776 : loss : 0.013942, loss_ce: 0.004068
2021-12-10 13:26:43,082 iteration 6777 : loss : 0.023349, loss_ce: 0.012038
2021-12-10 13:26:44,607 iteration 6778 : loss : 0.015281, loss_ce: 0.004665
2021-12-10 13:26:46,237 iteration 6779 : loss : 0.016066, loss_ce: 0.006055
2021-12-10 13:26:47,793 iteration 6780 : loss : 0.012941, loss_ce: 0.006088
2021-12-10 13:26:49,389 iteration 6781 : loss : 0.017912, loss_ce: 0.007776
2021-12-10 13:26:50,982 iteration 6782 : loss : 0.014144, loss_ce: 0.005468
2021-12-10 13:26:52,492 iteration 6783 : loss : 0.014025, loss_ce: 0.005048
100%|████████████████████████████▉| 399/400 [3:11:03<00:27, 27.30s/it]2021-12-10 13:26:54,175 iteration 6784 : loss : 0.018148, loss_ce: 0.006423
2021-12-10 13:26:55,751 iteration 6785 : loss : 0.018249, loss_ce: 0.006735
2021-12-10 13:26:57,246 iteration 6786 : loss : 0.011439, loss_ce: 0.004489
2021-12-10 13:26:58,751 iteration 6787 : loss : 0.011924, loss_ce: 0.003896
2021-12-10 13:27:00,316 iteration 6788 : loss : 0.016941, loss_ce: 0.007222
2021-12-10 13:27:01,869 iteration 6789 : loss : 0.020918, loss_ce: 0.005916
2021-12-10 13:27:03,388 iteration 6790 : loss : 0.018074, loss_ce: 0.007996
2021-12-10 13:27:04,955 iteration 6791 : loss : 0.013898, loss_ce: 0.005127
2021-12-10 13:27:06,440 iteration 6792 : loss : 0.012749, loss_ce: 0.005762
2021-12-10 13:27:08,056 iteration 6793 : loss : 0.021099, loss_ce: 0.006797
2021-12-10 13:27:09,597 iteration 6794 : loss : 0.019674, loss_ce: 0.006323
2021-12-10 13:27:11,180 iteration 6795 : loss : 0.013573, loss_ce: 0.004592
2021-12-10 13:27:12,790 iteration 6796 : loss : 0.016770, loss_ce: 0.009594
2021-12-10 13:27:14,253 iteration 6797 : loss : 0.020344, loss_ce: 0.005826
2021-12-10 13:27:15,833 iteration 6798 : loss : 0.021965, loss_ce: 0.007478
2021-12-10 13:27:17,476 iteration 6799 : loss : 0.026212, loss_ce: 0.010487
2021-12-10 13:27:17,476 Training Data Eval:
2021-12-10 13:27:25,214   Average segmentation loss on training set: 0.0081
2021-12-10 13:27:25,215 Validation Data Eval:
2021-12-10 13:27:27,866   Average segmentation loss on validation set: 0.0636
2021-12-10 13:27:29,358 iteration 6800 : loss : 0.011324, loss_ce: 0.002873
2021-12-10 13:27:39,335 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234epoch_399.pth
2021-12-10 13:27:48,914 save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/NEW_TU/NEW_TU_ADAM_seed1234epoch_399.pth
100%|████████████████████████████▉| 399/400 [3:12:00<00:28, 28.87s/it]
